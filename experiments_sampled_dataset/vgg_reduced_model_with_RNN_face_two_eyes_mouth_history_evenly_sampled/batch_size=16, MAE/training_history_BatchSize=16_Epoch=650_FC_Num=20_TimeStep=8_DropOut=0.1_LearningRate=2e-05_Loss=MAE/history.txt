Epoch: 1| Step: 0
Training loss: 6.190201759338379
Validation loss: 5.20239060412171

Epoch: 6| Step: 1
Training loss: 5.229898452758789
Validation loss: 5.176091050588957

Epoch: 6| Step: 2
Training loss: 4.507445812225342
Validation loss: 5.150826043980096

Epoch: 6| Step: 3
Training loss: 4.854352951049805
Validation loss: 5.124394914155365

Epoch: 6| Step: 4
Training loss: 4.737746238708496
Validation loss: 5.094895906345819

Epoch: 6| Step: 5
Training loss: 4.541162967681885
Validation loss: 5.061756446797361

Epoch: 6| Step: 6
Training loss: 3.8513894081115723
Validation loss: 5.023903657031315

Epoch: 6| Step: 7
Training loss: 4.337890625
Validation loss: 4.981927471776163

Epoch: 6| Step: 8
Training loss: 4.355002403259277
Validation loss: 4.9354172470749065

Epoch: 6| Step: 9
Training loss: 5.838261127471924
Validation loss: 4.884507656097412

Epoch: 6| Step: 10
Training loss: 4.61341667175293
Validation loss: 4.831158309854487

Epoch: 6| Step: 11
Training loss: 4.465391159057617
Validation loss: 4.773282153632051

Epoch: 6| Step: 12
Training loss: 4.236674785614014
Validation loss: 4.712737929436468

Epoch: 6| Step: 13
Training loss: 5.1759772300720215
Validation loss: 4.651219834563553

Epoch: 2| Step: 0
Training loss: 2.7081656455993652
Validation loss: 4.5872999750157835

Epoch: 6| Step: 1
Training loss: 3.730836868286133
Validation loss: 4.5229628162999305

Epoch: 6| Step: 2
Training loss: 3.6849770545959473
Validation loss: 4.4559151049583186

Epoch: 6| Step: 3
Training loss: 3.70888090133667
Validation loss: 4.390590770270235

Epoch: 6| Step: 4
Training loss: 5.16250467300415
Validation loss: 4.330172564393731

Epoch: 6| Step: 5
Training loss: 5.596471786499023
Validation loss: 4.274806950681953

Epoch: 6| Step: 6
Training loss: 3.868729591369629
Validation loss: 4.223020830462056

Epoch: 6| Step: 7
Training loss: 3.8711233139038086
Validation loss: 4.172675004569433

Epoch: 6| Step: 8
Training loss: 4.0537590980529785
Validation loss: 4.123485721567626

Epoch: 6| Step: 9
Training loss: 3.8720481395721436
Validation loss: 4.078689923850439

Epoch: 6| Step: 10
Training loss: 4.742902755737305
Validation loss: 4.034527952953051

Epoch: 6| Step: 11
Training loss: 3.4666225910186768
Validation loss: 3.994484737355222

Epoch: 6| Step: 12
Training loss: 4.249573707580566
Validation loss: 3.956693744146696

Epoch: 6| Step: 13
Training loss: 3.9061155319213867
Validation loss: 3.9166353261598976

Epoch: 3| Step: 0
Training loss: 5.058176040649414
Validation loss: 3.8701453670378654

Epoch: 6| Step: 1
Training loss: 3.8745439052581787
Validation loss: 3.8325875548906225

Epoch: 6| Step: 2
Training loss: 3.824535846710205
Validation loss: 3.799732028797109

Epoch: 6| Step: 3
Training loss: 4.539729118347168
Validation loss: 3.768895036430769

Epoch: 6| Step: 4
Training loss: 2.193286180496216
Validation loss: 3.732852784536218

Epoch: 6| Step: 5
Training loss: 3.5350680351257324
Validation loss: 3.7000121608857186

Epoch: 6| Step: 6
Training loss: 3.411590576171875
Validation loss: 3.662080157187677

Epoch: 6| Step: 7
Training loss: 2.4179303646087646
Validation loss: 3.625610177234937

Epoch: 6| Step: 8
Training loss: 2.9041786193847656
Validation loss: 3.5939260221296743

Epoch: 6| Step: 9
Training loss: 3.9635157585144043
Validation loss: 3.563211005221131

Epoch: 6| Step: 10
Training loss: 3.531309127807617
Validation loss: 3.532999425806025

Epoch: 6| Step: 11
Training loss: 4.130356311798096
Validation loss: 3.504665546519782

Epoch: 6| Step: 12
Training loss: 2.8944902420043945
Validation loss: 3.481583946494646

Epoch: 6| Step: 13
Training loss: 3.6098005771636963
Validation loss: 3.461902177462014

Epoch: 4| Step: 0
Training loss: 2.8296868801116943
Validation loss: 3.438326351104244

Epoch: 6| Step: 1
Training loss: 4.122272491455078
Validation loss: 3.420020877674062

Epoch: 6| Step: 2
Training loss: 3.6336565017700195
Validation loss: 3.3932955059953915

Epoch: 6| Step: 3
Training loss: 2.517108678817749
Validation loss: 3.3694256582567768

Epoch: 6| Step: 4
Training loss: 2.1448287963867188
Validation loss: 3.3552881312626663

Epoch: 6| Step: 5
Training loss: 2.8427233695983887
Validation loss: 3.345830807121851

Epoch: 6| Step: 6
Training loss: 3.307539463043213
Validation loss: 3.3142334209975375

Epoch: 6| Step: 7
Training loss: 3.474155902862549
Validation loss: 3.298030435398061

Epoch: 6| Step: 8
Training loss: 3.3963427543640137
Validation loss: 3.285884823850406

Epoch: 6| Step: 9
Training loss: 3.1079134941101074
Validation loss: 3.2660915415774108

Epoch: 6| Step: 10
Training loss: 4.347332954406738
Validation loss: 3.23979188037175

Epoch: 6| Step: 11
Training loss: 3.3500051498413086
Validation loss: 3.2232218916698168

Epoch: 6| Step: 12
Training loss: 3.664275646209717
Validation loss: 3.212434325166928

Epoch: 6| Step: 13
Training loss: 3.3218331336975098
Validation loss: 3.2024005305382515

Epoch: 5| Step: 0
Training loss: 2.835808515548706
Validation loss: 3.203222918254073

Epoch: 6| Step: 1
Training loss: 3.332916736602783
Validation loss: 3.18379831570451

Epoch: 6| Step: 2
Training loss: 4.0078630447387695
Validation loss: 3.1835147001410045

Epoch: 6| Step: 3
Training loss: 2.6122074127197266
Validation loss: 3.181923122816188

Epoch: 6| Step: 4
Training loss: 3.333153486251831
Validation loss: 3.17733952306932

Epoch: 6| Step: 5
Training loss: 2.0206782817840576
Validation loss: 3.1645772867305304

Epoch: 6| Step: 6
Training loss: 3.4784085750579834
Validation loss: 3.1506371985199633

Epoch: 6| Step: 7
Training loss: 3.503652811050415
Validation loss: 3.129291037077545

Epoch: 6| Step: 8
Training loss: 3.2701168060302734
Validation loss: 3.1176904439926147

Epoch: 6| Step: 9
Training loss: 3.8158771991729736
Validation loss: 3.1126688782886793

Epoch: 6| Step: 10
Training loss: 2.5959503650665283
Validation loss: 3.101638627308671

Epoch: 6| Step: 11
Training loss: 2.5515050888061523
Validation loss: 3.09620173259448

Epoch: 6| Step: 12
Training loss: 3.684906482696533
Validation loss: 3.0965670616396013

Epoch: 6| Step: 13
Training loss: 3.214184284210205
Validation loss: 3.089078467379334

Epoch: 6| Step: 0
Training loss: 2.644595146179199
Validation loss: 3.072982895758844

Epoch: 6| Step: 1
Training loss: 3.1956517696380615
Validation loss: 3.080768092986076

Epoch: 6| Step: 2
Training loss: 3.7218308448791504
Validation loss: 3.068491630656745

Epoch: 6| Step: 3
Training loss: 2.56514310836792
Validation loss: 3.0562414405166463

Epoch: 6| Step: 4
Training loss: 3.2126076221466064
Validation loss: 3.0502978063398793

Epoch: 6| Step: 5
Training loss: 2.9411840438842773
Validation loss: 3.0381281965522358

Epoch: 6| Step: 6
Training loss: 2.229548454284668
Validation loss: 3.0349843450771865

Epoch: 6| Step: 7
Training loss: 2.651270627975464
Validation loss: 3.027831403158044

Epoch: 6| Step: 8
Training loss: 3.4099197387695312
Validation loss: 3.020119123561408

Epoch: 6| Step: 9
Training loss: 3.3876514434814453
Validation loss: 3.0085007964923816

Epoch: 6| Step: 10
Training loss: 3.304837465286255
Validation loss: 2.998844905566144

Epoch: 6| Step: 11
Training loss: 3.74570369720459
Validation loss: 2.993611171681394

Epoch: 6| Step: 12
Training loss: 2.8599305152893066
Validation loss: 2.995080365929552

Epoch: 6| Step: 13
Training loss: 3.474717378616333
Validation loss: 2.9895264512749127

Epoch: 7| Step: 0
Training loss: 3.7469754219055176
Validation loss: 2.9772323972435406

Epoch: 6| Step: 1
Training loss: 3.0047554969787598
Validation loss: 2.971048124374882

Epoch: 6| Step: 2
Training loss: 2.8837108612060547
Validation loss: 2.964455517389441

Epoch: 6| Step: 3
Training loss: 3.62239408493042
Validation loss: 2.9594241034600044

Epoch: 6| Step: 4
Training loss: 2.8482487201690674
Validation loss: 2.9516051610310874

Epoch: 6| Step: 5
Training loss: 2.7167344093322754
Validation loss: 2.9461761418209282

Epoch: 6| Step: 6
Training loss: 2.086215019226074
Validation loss: 2.9355826967506

Epoch: 6| Step: 7
Training loss: 2.8502421379089355
Validation loss: 2.9328667527885846

Epoch: 6| Step: 8
Training loss: 2.4976282119750977
Validation loss: 2.9319756748855754

Epoch: 6| Step: 9
Training loss: 3.1267240047454834
Validation loss: 2.9265892172372467

Epoch: 6| Step: 10
Training loss: 4.139430999755859
Validation loss: 2.9194392029957106

Epoch: 6| Step: 11
Training loss: 2.6292200088500977
Validation loss: 2.914338675878381

Epoch: 6| Step: 12
Training loss: 3.4048497676849365
Validation loss: 2.9142466770705355

Epoch: 6| Step: 13
Training loss: 2.6324541568756104
Validation loss: 2.906404072238553

Epoch: 8| Step: 0
Training loss: 3.4533534049987793
Validation loss: 2.9025483797955256

Epoch: 6| Step: 1
Training loss: 2.8214688301086426
Validation loss: 2.9019431093687653

Epoch: 6| Step: 2
Training loss: 2.423844814300537
Validation loss: 2.8952322595862934

Epoch: 6| Step: 3
Training loss: 3.4220023155212402
Validation loss: 2.889834242482339

Epoch: 6| Step: 4
Training loss: 2.5933241844177246
Validation loss: 2.8852627303010676

Epoch: 6| Step: 5
Training loss: 3.0359551906585693
Validation loss: 2.8807243377931657

Epoch: 6| Step: 6
Training loss: 2.6758556365966797
Validation loss: 2.868267382344892

Epoch: 6| Step: 7
Training loss: 3.069681167602539
Validation loss: 2.861320162332186

Epoch: 6| Step: 8
Training loss: 3.233706474304199
Validation loss: 2.8574045909348356

Epoch: 6| Step: 9
Training loss: 2.20231294631958
Validation loss: 2.8509010320068686

Epoch: 6| Step: 10
Training loss: 3.158999443054199
Validation loss: 2.8510980541988085

Epoch: 6| Step: 11
Training loss: 2.8367860317230225
Validation loss: 2.8504616265655844

Epoch: 6| Step: 12
Training loss: 3.8202152252197266
Validation loss: 2.8430494775054274

Epoch: 6| Step: 13
Training loss: 2.9366390705108643
Validation loss: 2.8381235650790635

Epoch: 9| Step: 0
Training loss: 2.8890366554260254
Validation loss: 2.8336883821795062

Epoch: 6| Step: 1
Training loss: 2.2926206588745117
Validation loss: 2.8230072298357562

Epoch: 6| Step: 2
Training loss: 2.4542901515960693
Validation loss: 2.820464477744154

Epoch: 6| Step: 3
Training loss: 2.1956987380981445
Validation loss: 2.8148215534866496

Epoch: 6| Step: 4
Training loss: 3.3471384048461914
Validation loss: 2.807243759914111

Epoch: 6| Step: 5
Training loss: 2.988389492034912
Validation loss: 2.8076473846230456

Epoch: 6| Step: 6
Training loss: 2.886397361755371
Validation loss: 2.806021982623685

Epoch: 6| Step: 7
Training loss: 3.301368236541748
Validation loss: 2.7954270532054286

Epoch: 6| Step: 8
Training loss: 3.968855142593384
Validation loss: 2.8013137181599936

Epoch: 6| Step: 9
Training loss: 2.765221357345581
Validation loss: 2.7973075323207404

Epoch: 6| Step: 10
Training loss: 2.9049735069274902
Validation loss: 2.8060567148270144

Epoch: 6| Step: 11
Training loss: 3.807560920715332
Validation loss: 2.80331781859039

Epoch: 6| Step: 12
Training loss: 1.7939367294311523
Validation loss: 2.8105727677704184

Epoch: 6| Step: 13
Training loss: 4.006803512573242
Validation loss: 2.8370240067922943

Epoch: 10| Step: 0
Training loss: 2.550361394882202
Validation loss: 2.8519581697320424

Epoch: 6| Step: 1
Training loss: 2.7675621509552
Validation loss: 2.8346528930048787

Epoch: 6| Step: 2
Training loss: 3.108018398284912
Validation loss: 2.8059240028422368

Epoch: 6| Step: 3
Training loss: 3.2209057807922363
Validation loss: 2.794081534108808

Epoch: 6| Step: 4
Training loss: 3.230926990509033
Validation loss: 2.786905598896806

Epoch: 6| Step: 5
Training loss: 3.4773716926574707
Validation loss: 2.780775080444992

Epoch: 6| Step: 6
Training loss: 3.7582221031188965
Validation loss: 2.7865277644126647

Epoch: 6| Step: 7
Training loss: 3.067012071609497
Validation loss: 2.760539459925826

Epoch: 6| Step: 8
Training loss: 3.0037951469421387
Validation loss: 2.750102945553359

Epoch: 6| Step: 9
Training loss: 2.7103872299194336
Validation loss: 2.740479653881442

Epoch: 6| Step: 10
Training loss: 2.518496513366699
Validation loss: 2.747268171720607

Epoch: 6| Step: 11
Training loss: 2.765347957611084
Validation loss: 2.753487156283471

Epoch: 6| Step: 12
Training loss: 2.158574104309082
Validation loss: 2.7525590850460913

Epoch: 6| Step: 13
Training loss: 2.4162986278533936
Validation loss: 2.7559187258443525

Epoch: 11| Step: 0
Training loss: 2.7731404304504395
Validation loss: 2.7382217427735687

Epoch: 6| Step: 1
Training loss: 2.369894504547119
Validation loss: 2.736616716589979

Epoch: 6| Step: 2
Training loss: 3.553652286529541
Validation loss: 2.734017369567707

Epoch: 6| Step: 3
Training loss: 2.388284206390381
Validation loss: 2.723663886388143

Epoch: 6| Step: 4
Training loss: 2.8890676498413086
Validation loss: 2.716522455215454

Epoch: 6| Step: 5
Training loss: 2.3983216285705566
Validation loss: 2.7117797354216218

Epoch: 6| Step: 6
Training loss: 3.2743263244628906
Validation loss: 2.705097734287221

Epoch: 6| Step: 7
Training loss: 3.007930278778076
Validation loss: 2.700732664395404

Epoch: 6| Step: 8
Training loss: 2.0824689865112305
Validation loss: 2.6935073342374576

Epoch: 6| Step: 9
Training loss: 3.371314525604248
Validation loss: 2.693710850131127

Epoch: 6| Step: 10
Training loss: 3.7082643508911133
Validation loss: 2.694037163129417

Epoch: 6| Step: 11
Training loss: 3.7915191650390625
Validation loss: 2.6916413589190413

Epoch: 6| Step: 12
Training loss: 2.0681450366973877
Validation loss: 2.68379783374007

Epoch: 6| Step: 13
Training loss: 2.2477149963378906
Validation loss: 2.686937819245041

Epoch: 12| Step: 0
Training loss: 3.0387516021728516
Validation loss: 2.680424387736987

Epoch: 6| Step: 1
Training loss: 3.4875106811523438
Validation loss: 2.6779847093807754

Epoch: 6| Step: 2
Training loss: 3.5573208332061768
Validation loss: 2.671384531964538

Epoch: 6| Step: 3
Training loss: 2.392784595489502
Validation loss: 2.6702160630174863

Epoch: 6| Step: 4
Training loss: 2.799253225326538
Validation loss: 2.673402235072146

Epoch: 6| Step: 5
Training loss: 3.6562142372131348
Validation loss: 2.673478682835897

Epoch: 6| Step: 6
Training loss: 2.2804036140441895
Validation loss: 2.670201893775694

Epoch: 6| Step: 7
Training loss: 2.751950263977051
Validation loss: 2.668409232170351

Epoch: 6| Step: 8
Training loss: 2.481487512588501
Validation loss: 2.6662492828984417

Epoch: 6| Step: 9
Training loss: 2.637834310531616
Validation loss: 2.659384230131744

Epoch: 6| Step: 10
Training loss: 2.925795078277588
Validation loss: 2.6556553109999625

Epoch: 6| Step: 11
Training loss: 2.7791683673858643
Validation loss: 2.649764119937856

Epoch: 6| Step: 12
Training loss: 2.6746175289154053
Validation loss: 2.6510500625897477

Epoch: 6| Step: 13
Training loss: 2.0340592861175537
Validation loss: 2.650867098121233

Epoch: 13| Step: 0
Training loss: 2.573145627975464
Validation loss: 2.6428855183303996

Epoch: 6| Step: 1
Training loss: 2.235403060913086
Validation loss: 2.63780306231591

Epoch: 6| Step: 2
Training loss: 3.4800195693969727
Validation loss: 2.641404846663116

Epoch: 6| Step: 3
Training loss: 2.0728816986083984
Validation loss: 2.640569334389061

Epoch: 6| Step: 4
Training loss: 2.377631664276123
Validation loss: 2.636411110560099

Epoch: 6| Step: 5
Training loss: 3.119422435760498
Validation loss: 2.641795445513982

Epoch: 6| Step: 6
Training loss: 2.7865471839904785
Validation loss: 2.6342587599190335

Epoch: 6| Step: 7
Training loss: 3.370649814605713
Validation loss: 2.634357726702126

Epoch: 6| Step: 8
Training loss: 2.9520199298858643
Validation loss: 2.6423304516782045

Epoch: 6| Step: 9
Training loss: 3.4741387367248535
Validation loss: 2.6414140988421697

Epoch: 6| Step: 10
Training loss: 2.6829922199249268
Validation loss: 2.6311846830511607

Epoch: 6| Step: 11
Training loss: 2.7358274459838867
Validation loss: 2.6305472978981594

Epoch: 6| Step: 12
Training loss: 2.970165729522705
Validation loss: 2.6245377807207007

Epoch: 6| Step: 13
Training loss: 2.593174934387207
Validation loss: 2.629096725935577

Epoch: 14| Step: 0
Training loss: 2.5551998615264893
Validation loss: 2.624876981140465

Epoch: 6| Step: 1
Training loss: 3.352445602416992
Validation loss: 2.6265766056635047

Epoch: 6| Step: 2
Training loss: 2.930027723312378
Validation loss: 2.6227968944016324

Epoch: 6| Step: 3
Training loss: 2.7087626457214355
Validation loss: 2.618889170308267

Epoch: 6| Step: 4
Training loss: 2.2046937942504883
Validation loss: 2.6305304932337936

Epoch: 6| Step: 5
Training loss: 3.023406982421875
Validation loss: 2.6205404496962026

Epoch: 6| Step: 6
Training loss: 3.221303939819336
Validation loss: 2.618216670969481

Epoch: 6| Step: 7
Training loss: 2.5564894676208496
Validation loss: 2.6158172904804187

Epoch: 6| Step: 8
Training loss: 2.6951375007629395
Validation loss: 2.6227193929815806

Epoch: 6| Step: 9
Training loss: 2.8395628929138184
Validation loss: 2.647599832985991

Epoch: 6| Step: 10
Training loss: 2.4778690338134766
Validation loss: 2.704245421194261

Epoch: 6| Step: 11
Training loss: 3.3067798614501953
Validation loss: 2.7513141965353363

Epoch: 6| Step: 12
Training loss: 2.757575750350952
Validation loss: 2.7293864321965042

Epoch: 6| Step: 13
Training loss: 2.913196563720703
Validation loss: 2.635308240049629

Epoch: 15| Step: 0
Training loss: 3.111110210418701
Validation loss: 2.6160688041358866

Epoch: 6| Step: 1
Training loss: 2.6298117637634277
Validation loss: 2.6325169071074455

Epoch: 6| Step: 2
Training loss: 2.3384547233581543
Validation loss: 2.6720716338003836

Epoch: 6| Step: 3
Training loss: 2.9819490909576416
Validation loss: 2.660183004153672

Epoch: 6| Step: 4
Training loss: 2.237765312194824
Validation loss: 2.6329142406422603

Epoch: 6| Step: 5
Training loss: 2.64605975151062
Validation loss: 2.623312096441946

Epoch: 6| Step: 6
Training loss: 3.34574294090271
Validation loss: 2.6267523381017868

Epoch: 6| Step: 7
Training loss: 2.762176036834717
Validation loss: 2.6300991837696364

Epoch: 6| Step: 8
Training loss: 2.9077625274658203
Validation loss: 2.6383640637961765

Epoch: 6| Step: 9
Training loss: 3.314093828201294
Validation loss: 2.6221074314527613

Epoch: 6| Step: 10
Training loss: 2.303600788116455
Validation loss: 2.6070373263410342

Epoch: 6| Step: 11
Training loss: 3.5137414932250977
Validation loss: 2.6091886540894866

Epoch: 6| Step: 12
Training loss: 2.523068428039551
Validation loss: 2.5959655059281217

Epoch: 6| Step: 13
Training loss: 2.926441192626953
Validation loss: 2.5938806456904255

Epoch: 16| Step: 0
Training loss: 2.7700355052948
Validation loss: 2.6185825640155422

Epoch: 6| Step: 1
Training loss: 2.495699644088745
Validation loss: 2.652127896585772

Epoch: 6| Step: 2
Training loss: 1.9393224716186523
Validation loss: 2.7387735766749226

Epoch: 6| Step: 3
Training loss: 2.947037935256958
Validation loss: 2.728024390435988

Epoch: 6| Step: 4
Training loss: 3.5237669944763184
Validation loss: 2.683368198333248

Epoch: 6| Step: 5
Training loss: 2.3353466987609863
Validation loss: 2.671411793719056

Epoch: 6| Step: 6
Training loss: 2.766101360321045
Validation loss: 2.6193553042668167

Epoch: 6| Step: 7
Training loss: 2.956430196762085
Validation loss: 2.5919676211572464

Epoch: 6| Step: 8
Training loss: 2.316610097885132
Validation loss: 2.5996322375471874

Epoch: 6| Step: 9
Training loss: 2.956421375274658
Validation loss: 2.6584514187228296

Epoch: 6| Step: 10
Training loss: 3.639383554458618
Validation loss: 2.687362422225296

Epoch: 6| Step: 11
Training loss: 2.2252793312072754
Validation loss: 2.667998788177326

Epoch: 6| Step: 12
Training loss: 3.5145413875579834
Validation loss: 2.659111035767422

Epoch: 6| Step: 13
Training loss: 3.34266996383667
Validation loss: 2.5853576801156484

Epoch: 17| Step: 0
Training loss: 3.780543565750122
Validation loss: 2.5839948064537457

Epoch: 6| Step: 1
Training loss: 2.4882190227508545
Validation loss: 2.591112285531977

Epoch: 6| Step: 2
Training loss: 2.9862220287323
Validation loss: 2.60961151635775

Epoch: 6| Step: 3
Training loss: 2.7428019046783447
Validation loss: 2.6362470144866617

Epoch: 6| Step: 4
Training loss: 2.437709331512451
Validation loss: 2.638242237029537

Epoch: 6| Step: 5
Training loss: 3.2299001216888428
Validation loss: 2.6461881283790833

Epoch: 6| Step: 6
Training loss: 3.0000457763671875
Validation loss: 2.640231288889403

Epoch: 6| Step: 7
Training loss: 2.3456625938415527
Validation loss: 2.6319931578892533

Epoch: 6| Step: 8
Training loss: 2.9919815063476562
Validation loss: 2.6138366806891655

Epoch: 6| Step: 9
Training loss: 3.318812847137451
Validation loss: 2.6032686771885043

Epoch: 6| Step: 10
Training loss: 2.086515188217163
Validation loss: 2.5899109276392127

Epoch: 6| Step: 11
Training loss: 2.4704179763793945
Validation loss: 2.585626281717772

Epoch: 6| Step: 12
Training loss: 2.467832088470459
Validation loss: 2.5805103599384265

Epoch: 6| Step: 13
Training loss: 2.8450894355773926
Validation loss: 2.5793761873757965

Epoch: 18| Step: 0
Training loss: 2.642082691192627
Validation loss: 2.590325468329973

Epoch: 6| Step: 1
Training loss: 3.103790283203125
Validation loss: 2.5877480763261036

Epoch: 6| Step: 2
Training loss: 2.9499826431274414
Validation loss: 2.5804505655842442

Epoch: 6| Step: 3
Training loss: 2.6920268535614014
Validation loss: 2.580920752658639

Epoch: 6| Step: 4
Training loss: 3.4220314025878906
Validation loss: 2.571673636795372

Epoch: 6| Step: 5
Training loss: 2.5580873489379883
Validation loss: 2.5651742617289224

Epoch: 6| Step: 6
Training loss: 1.7659811973571777
Validation loss: 2.567869952929917

Epoch: 6| Step: 7
Training loss: 3.1818270683288574
Validation loss: 2.5721876339245866

Epoch: 6| Step: 8
Training loss: 2.4278335571289062
Validation loss: 2.5721799276208364

Epoch: 6| Step: 9
Training loss: 3.5227251052856445
Validation loss: 2.5688367582136586

Epoch: 6| Step: 10
Training loss: 2.453965663909912
Validation loss: 2.5693022204983618

Epoch: 6| Step: 11
Training loss: 2.353093147277832
Validation loss: 2.5525026962321293

Epoch: 6| Step: 12
Training loss: 2.9907443523406982
Validation loss: 2.5517413564907607

Epoch: 6| Step: 13
Training loss: 2.632925510406494
Validation loss: 2.551619347705636

Epoch: 19| Step: 0
Training loss: 3.570626974105835
Validation loss: 2.552850572011804

Epoch: 6| Step: 1
Training loss: 3.2001166343688965
Validation loss: 2.5539912613489295

Epoch: 6| Step: 2
Training loss: 2.298161268234253
Validation loss: 2.550839175460159

Epoch: 6| Step: 3
Training loss: 2.977348804473877
Validation loss: 2.5486892833504626

Epoch: 6| Step: 4
Training loss: 2.9039411544799805
Validation loss: 2.546754252526068

Epoch: 6| Step: 5
Training loss: 2.9442849159240723
Validation loss: 2.550113876660665

Epoch: 6| Step: 6
Training loss: 2.1063473224639893
Validation loss: 2.5481306429832213

Epoch: 6| Step: 7
Training loss: 2.255254030227661
Validation loss: 2.543460715201593

Epoch: 6| Step: 8
Training loss: 2.547903060913086
Validation loss: 2.5443801956792034

Epoch: 6| Step: 9
Training loss: 2.5741944313049316
Validation loss: 2.5455132838218444

Epoch: 6| Step: 10
Training loss: 2.7278695106506348
Validation loss: 2.54400642841093

Epoch: 6| Step: 11
Training loss: 2.6846141815185547
Validation loss: 2.5463397246535107

Epoch: 6| Step: 12
Training loss: 2.940598726272583
Validation loss: 2.54537034034729

Epoch: 6| Step: 13
Training loss: 2.8449671268463135
Validation loss: 2.5389674632780013

Epoch: 20| Step: 0
Training loss: 3.303293228149414
Validation loss: 2.5401735075058474

Epoch: 6| Step: 1
Training loss: 3.217451572418213
Validation loss: 2.545050190341088

Epoch: 6| Step: 2
Training loss: 2.901524305343628
Validation loss: 2.534047286997559

Epoch: 6| Step: 3
Training loss: 2.196166753768921
Validation loss: 2.5330605917079474

Epoch: 6| Step: 4
Training loss: 3.0177698135375977
Validation loss: 2.531629646978071

Epoch: 6| Step: 5
Training loss: 2.2894394397735596
Validation loss: 2.5307765340292327

Epoch: 6| Step: 6
Training loss: 3.178637981414795
Validation loss: 2.535354862930954

Epoch: 6| Step: 7
Training loss: 3.242401361465454
Validation loss: 2.5377814205743934

Epoch: 6| Step: 8
Training loss: 2.7064435482025146
Validation loss: 2.5436913480040846

Epoch: 6| Step: 9
Training loss: 2.5675597190856934
Validation loss: 2.5460988424157582

Epoch: 6| Step: 10
Training loss: 2.1192615032196045
Validation loss: 2.5538603285307526

Epoch: 6| Step: 11
Training loss: 2.892948627471924
Validation loss: 2.566449224307973

Epoch: 6| Step: 12
Training loss: 2.4648427963256836
Validation loss: 2.557203064682663

Epoch: 6| Step: 13
Training loss: 2.2412071228027344
Validation loss: 2.5437261622439147

Epoch: 21| Step: 0
Training loss: 2.7169504165649414
Validation loss: 2.5463567421000493

Epoch: 6| Step: 1
Training loss: 3.1604251861572266
Validation loss: 2.5710252664422475

Epoch: 6| Step: 2
Training loss: 2.8368606567382812
Validation loss: 2.6196737699611212

Epoch: 6| Step: 3
Training loss: 2.8991940021514893
Validation loss: 2.633453607559204

Epoch: 6| Step: 4
Training loss: 2.476710081100464
Validation loss: 2.6400409283176547

Epoch: 6| Step: 5
Training loss: 3.502596378326416
Validation loss: 2.610282923585625

Epoch: 6| Step: 6
Training loss: 3.1027793884277344
Validation loss: 2.5624941600266324

Epoch: 6| Step: 7
Training loss: 2.7057602405548096
Validation loss: 2.5264241336494364

Epoch: 6| Step: 8
Training loss: 2.0202016830444336
Validation loss: 2.5224978795615574

Epoch: 6| Step: 9
Training loss: 2.3336021900177
Validation loss: 2.543229100524738

Epoch: 6| Step: 10
Training loss: 2.7293176651000977
Validation loss: 2.5763991443059777

Epoch: 6| Step: 11
Training loss: 2.563122272491455
Validation loss: 2.552653927956858

Epoch: 6| Step: 12
Training loss: 2.8595921993255615
Validation loss: 2.5463436239509174

Epoch: 6| Step: 13
Training loss: 2.6708121299743652
Validation loss: 2.535947161336099

Epoch: 22| Step: 0
Training loss: 2.1097447872161865
Validation loss: 2.5360998030631774

Epoch: 6| Step: 1
Training loss: 2.7988767623901367
Validation loss: 2.5417739114453717

Epoch: 6| Step: 2
Training loss: 2.553908109664917
Validation loss: 2.5250925094850603

Epoch: 6| Step: 3
Training loss: 2.821993827819824
Validation loss: 2.5236220744348343

Epoch: 6| Step: 4
Training loss: 2.548034191131592
Validation loss: 2.5134728057410127

Epoch: 6| Step: 5
Training loss: 3.119023084640503
Validation loss: 2.5187164070785686

Epoch: 6| Step: 6
Training loss: 2.5127086639404297
Validation loss: 2.518685133226456

Epoch: 6| Step: 7
Training loss: 2.5533666610717773
Validation loss: 2.521104546003444

Epoch: 6| Step: 8
Training loss: 2.411428928375244
Validation loss: 2.530715411709201

Epoch: 6| Step: 9
Training loss: 3.0854012966156006
Validation loss: 2.5454186624096287

Epoch: 6| Step: 10
Training loss: 2.8653528690338135
Validation loss: 2.5474466790435133

Epoch: 6| Step: 11
Training loss: 2.37477970123291
Validation loss: 2.56270355819374

Epoch: 6| Step: 12
Training loss: 3.6117916107177734
Validation loss: 2.579638642649497

Epoch: 6| Step: 13
Training loss: 2.998396396636963
Validation loss: 2.5487434812771377

Epoch: 23| Step: 0
Training loss: 2.643031597137451
Validation loss: 2.5215369527057936

Epoch: 6| Step: 1
Training loss: 2.635643482208252
Validation loss: 2.5029173461339806

Epoch: 6| Step: 2
Training loss: 2.6296706199645996
Validation loss: 2.506758133570353

Epoch: 6| Step: 3
Training loss: 3.278252601623535
Validation loss: 2.5128490001924577

Epoch: 6| Step: 4
Training loss: 2.9013986587524414
Validation loss: 2.514472128242575

Epoch: 6| Step: 5
Training loss: 3.4513282775878906
Validation loss: 2.509351776492211

Epoch: 6| Step: 6
Training loss: 3.166861057281494
Validation loss: 2.518224967423306

Epoch: 6| Step: 7
Training loss: 3.0122320652008057
Validation loss: 2.5192189524250646

Epoch: 6| Step: 8
Training loss: 2.5828723907470703
Validation loss: 2.522267608232396

Epoch: 6| Step: 9
Training loss: 2.880417823791504
Validation loss: 2.5194937593193463

Epoch: 6| Step: 10
Training loss: 1.8175514936447144
Validation loss: 2.5197076207848004

Epoch: 6| Step: 11
Training loss: 2.524421215057373
Validation loss: 2.519418534412179

Epoch: 6| Step: 12
Training loss: 1.990088701248169
Validation loss: 2.5175277392069497

Epoch: 6| Step: 13
Training loss: 2.5640034675598145
Validation loss: 2.520067213684

Epoch: 24| Step: 0
Training loss: 3.1404623985290527
Validation loss: 2.5298240389875186

Epoch: 6| Step: 1
Training loss: 1.723315715789795
Validation loss: 2.5162060696591615

Epoch: 6| Step: 2
Training loss: 3.5501694679260254
Validation loss: 2.508864277152605

Epoch: 6| Step: 3
Training loss: 2.819380283355713
Validation loss: 2.5112801700510006

Epoch: 6| Step: 4
Training loss: 2.740339756011963
Validation loss: 2.5117496495605796

Epoch: 6| Step: 5
Training loss: 2.8149831295013428
Validation loss: 2.5098761409841557

Epoch: 6| Step: 6
Training loss: 1.7647287845611572
Validation loss: 2.509596742609496

Epoch: 6| Step: 7
Training loss: 2.6599318981170654
Validation loss: 2.5127006833271315

Epoch: 6| Step: 8
Training loss: 2.3277273178100586
Validation loss: 2.5045933723449707

Epoch: 6| Step: 9
Training loss: 2.658754825592041
Validation loss: 2.5224319683608187

Epoch: 6| Step: 10
Training loss: 3.543229103088379
Validation loss: 2.534779812700005

Epoch: 6| Step: 11
Training loss: 2.3134055137634277
Validation loss: 2.549724576293781

Epoch: 6| Step: 12
Training loss: 2.9037015438079834
Validation loss: 2.55382417350687

Epoch: 6| Step: 13
Training loss: 3.4287235736846924
Validation loss: 2.536512259514101

Epoch: 25| Step: 0
Training loss: 2.694740056991577
Validation loss: 2.5120549253238145

Epoch: 6| Step: 1
Training loss: 2.241159439086914
Validation loss: 2.5105715131246917

Epoch: 6| Step: 2
Training loss: 2.9517745971679688
Validation loss: 2.512132590816867

Epoch: 6| Step: 3
Training loss: 2.3102807998657227
Validation loss: 2.5312296011114634

Epoch: 6| Step: 4
Training loss: 3.099548816680908
Validation loss: 2.5546929477363505

Epoch: 6| Step: 5
Training loss: 2.8235764503479004
Validation loss: 2.5541081095254548

Epoch: 6| Step: 6
Training loss: 3.145016670227051
Validation loss: 2.5260787753648657

Epoch: 6| Step: 7
Training loss: 2.8544068336486816
Validation loss: 2.5077682823263188

Epoch: 6| Step: 8
Training loss: 2.3412680625915527
Validation loss: 2.502291835764403

Epoch: 6| Step: 9
Training loss: 3.0677781105041504
Validation loss: 2.5105119469345256

Epoch: 6| Step: 10
Training loss: 2.267867088317871
Validation loss: 2.506901697445941

Epoch: 6| Step: 11
Training loss: 2.1500377655029297
Validation loss: 2.508027602267522

Epoch: 6| Step: 12
Training loss: 3.771078109741211
Validation loss: 2.516218000842679

Epoch: 6| Step: 13
Training loss: 1.9779014587402344
Validation loss: 2.510079845305412

Epoch: 26| Step: 0
Training loss: 3.204942464828491
Validation loss: 2.501431898404193

Epoch: 6| Step: 1
Training loss: 2.613178014755249
Validation loss: 2.4992905175814064

Epoch: 6| Step: 2
Training loss: 2.579162120819092
Validation loss: 2.487945020839732

Epoch: 6| Step: 3
Training loss: 2.97981333732605
Validation loss: 2.4825674949153775

Epoch: 6| Step: 4
Training loss: 1.910644292831421
Validation loss: 2.48089329401652

Epoch: 6| Step: 5
Training loss: 3.385286569595337
Validation loss: 2.478191033486397

Epoch: 6| Step: 6
Training loss: 2.7168500423431396
Validation loss: 2.4821128332486717

Epoch: 6| Step: 7
Training loss: 2.8731119632720947
Validation loss: 2.480634504748929

Epoch: 6| Step: 8
Training loss: 3.423046112060547
Validation loss: 2.479152253879014

Epoch: 6| Step: 9
Training loss: 2.06514573097229
Validation loss: 2.482099220316897

Epoch: 6| Step: 10
Training loss: 2.294135570526123
Validation loss: 2.502808916953302

Epoch: 6| Step: 11
Training loss: 2.3341619968414307
Validation loss: 2.531988772012854

Epoch: 6| Step: 12
Training loss: 2.9794020652770996
Validation loss: 2.51124656328591

Epoch: 6| Step: 13
Training loss: 2.3358144760131836
Validation loss: 2.4822654775393906

Epoch: 27| Step: 0
Training loss: 1.6751255989074707
Validation loss: 2.4779757351003666

Epoch: 6| Step: 1
Training loss: 2.358713150024414
Validation loss: 2.479540482644112

Epoch: 6| Step: 2
Training loss: 2.5000858306884766
Validation loss: 2.4863025962665515

Epoch: 6| Step: 3
Training loss: 2.4532313346862793
Validation loss: 2.491224668359244

Epoch: 6| Step: 4
Training loss: 2.834940195083618
Validation loss: 2.500651067303073

Epoch: 6| Step: 5
Training loss: 2.944242477416992
Validation loss: 2.492672251116845

Epoch: 6| Step: 6
Training loss: 2.7183899879455566
Validation loss: 2.485405029789094

Epoch: 6| Step: 7
Training loss: 3.138178825378418
Validation loss: 2.4752104128560712

Epoch: 6| Step: 8
Training loss: 3.5319457054138184
Validation loss: 2.4728452928604616

Epoch: 6| Step: 9
Training loss: 2.7119433879852295
Validation loss: 2.482323520927019

Epoch: 6| Step: 10
Training loss: 2.9366631507873535
Validation loss: 2.4950050564222437

Epoch: 6| Step: 11
Training loss: 2.4384028911590576
Validation loss: 2.4973828279843895

Epoch: 6| Step: 12
Training loss: 2.7155675888061523
Validation loss: 2.4741439691153904

Epoch: 6| Step: 13
Training loss: 2.9787685871124268
Validation loss: 2.4680615240527737

Epoch: 28| Step: 0
Training loss: 2.2105512619018555
Validation loss: 2.4624364606795774

Epoch: 6| Step: 1
Training loss: 3.184157371520996
Validation loss: 2.457984583352202

Epoch: 6| Step: 2
Training loss: 2.1370201110839844
Validation loss: 2.460003691334878

Epoch: 6| Step: 3
Training loss: 3.3814711570739746
Validation loss: 2.465576402602657

Epoch: 6| Step: 4
Training loss: 3.1147966384887695
Validation loss: 2.477733555660453

Epoch: 6| Step: 5
Training loss: 3.074326992034912
Validation loss: 2.4852430179554927

Epoch: 6| Step: 6
Training loss: 3.038841724395752
Validation loss: 2.4861274585928967

Epoch: 6| Step: 7
Training loss: 2.0851006507873535
Validation loss: 2.481729253645866

Epoch: 6| Step: 8
Training loss: 3.1484007835388184
Validation loss: 2.480125622082782

Epoch: 6| Step: 9
Training loss: 2.3263721466064453
Validation loss: 2.4751499686189877

Epoch: 6| Step: 10
Training loss: 2.3002185821533203
Validation loss: 2.4717362542306223

Epoch: 6| Step: 11
Training loss: 2.344355583190918
Validation loss: 2.4676558715040966

Epoch: 6| Step: 12
Training loss: 2.4374961853027344
Validation loss: 2.46145188167531

Epoch: 6| Step: 13
Training loss: 2.778701066970825
Validation loss: 2.4697525116705124

Epoch: 29| Step: 0
Training loss: 2.559889316558838
Validation loss: 2.4589307269742413

Epoch: 6| Step: 1
Training loss: 1.6684296131134033
Validation loss: 2.447703307674777

Epoch: 6| Step: 2
Training loss: 2.7877037525177
Validation loss: 2.4481308870418097

Epoch: 6| Step: 3
Training loss: 2.9180965423583984
Validation loss: 2.4395232149349746

Epoch: 6| Step: 4
Training loss: 3.3856494426727295
Validation loss: 2.4393047466072986

Epoch: 6| Step: 5
Training loss: 3.3391876220703125
Validation loss: 2.4391243996158725

Epoch: 6| Step: 6
Training loss: 2.568842887878418
Validation loss: 2.4411183582839144

Epoch: 6| Step: 7
Training loss: 2.8057782649993896
Validation loss: 2.4348023501775597

Epoch: 6| Step: 8
Training loss: 2.6474311351776123
Validation loss: 2.429671543900685

Epoch: 6| Step: 9
Training loss: 2.0354151725769043
Validation loss: 2.431622600042692

Epoch: 6| Step: 10
Training loss: 2.3289506435394287
Validation loss: 2.428729852040609

Epoch: 6| Step: 11
Training loss: 3.0575013160705566
Validation loss: 2.4277525589030278

Epoch: 6| Step: 12
Training loss: 2.809664249420166
Validation loss: 2.4332490787711194

Epoch: 6| Step: 13
Training loss: 2.356389284133911
Validation loss: 2.4256537165693057

Epoch: 30| Step: 0
Training loss: 3.365786075592041
Validation loss: 2.432783288340415

Epoch: 6| Step: 1
Training loss: 3.1062188148498535
Validation loss: 2.4331224836328977

Epoch: 6| Step: 2
Training loss: 1.7143797874450684
Validation loss: 2.4279432963299494

Epoch: 6| Step: 3
Training loss: 2.643909215927124
Validation loss: 2.4468535197678434

Epoch: 6| Step: 4
Training loss: 2.998452663421631
Validation loss: 2.462889063742853

Epoch: 6| Step: 5
Training loss: 2.828855037689209
Validation loss: 2.479600860226539

Epoch: 6| Step: 6
Training loss: 2.6985809803009033
Validation loss: 2.4700173844573317

Epoch: 6| Step: 7
Training loss: 2.3705220222473145
Validation loss: 2.461296555816486

Epoch: 6| Step: 8
Training loss: 2.89877986907959
Validation loss: 2.451064081602199

Epoch: 6| Step: 9
Training loss: 2.2411093711853027
Validation loss: 2.427768494493218

Epoch: 6| Step: 10
Training loss: 2.6189980506896973
Validation loss: 2.419011897938226

Epoch: 6| Step: 11
Training loss: 2.3640952110290527
Validation loss: 2.417026740248485

Epoch: 6| Step: 12
Training loss: 2.8209664821624756
Validation loss: 2.4146218504956973

Epoch: 6| Step: 13
Training loss: 2.9220409393310547
Validation loss: 2.416332814001268

Epoch: 31| Step: 0
Training loss: 2.032766819000244
Validation loss: 2.415263324655512

Epoch: 6| Step: 1
Training loss: 2.877023458480835
Validation loss: 2.4152197376374276

Epoch: 6| Step: 2
Training loss: 2.761652946472168
Validation loss: 2.4199176578111548

Epoch: 6| Step: 3
Training loss: 2.702209711074829
Validation loss: 2.4208636488965762

Epoch: 6| Step: 4
Training loss: 2.1847102642059326
Validation loss: 2.431129901639877

Epoch: 6| Step: 5
Training loss: 2.848191976547241
Validation loss: 2.430024164979176

Epoch: 6| Step: 6
Training loss: 3.0774240493774414
Validation loss: 2.4280866230687788

Epoch: 6| Step: 7
Training loss: 2.7989988327026367
Validation loss: 2.4266817774823917

Epoch: 6| Step: 8
Training loss: 2.350015878677368
Validation loss: 2.430513830595119

Epoch: 6| Step: 9
Training loss: 2.072463035583496
Validation loss: 2.4297330635850147

Epoch: 6| Step: 10
Training loss: 2.6010022163391113
Validation loss: 2.4254070687037643

Epoch: 6| Step: 11
Training loss: 3.3765041828155518
Validation loss: 2.423211056699035

Epoch: 6| Step: 12
Training loss: 2.9766502380371094
Validation loss: 2.4345422098713536

Epoch: 6| Step: 13
Training loss: 2.3357791900634766
Validation loss: 2.436749537785848

Epoch: 32| Step: 0
Training loss: 2.489464044570923
Validation loss: 2.437460781425558

Epoch: 6| Step: 1
Training loss: 2.4743399620056152
Validation loss: 2.4381386541551158

Epoch: 6| Step: 2
Training loss: 2.5113778114318848
Validation loss: 2.438370768741895

Epoch: 6| Step: 3
Training loss: 3.243281841278076
Validation loss: 2.4309440530756468

Epoch: 6| Step: 4
Training loss: 2.618558883666992
Validation loss: 2.425518922908332

Epoch: 6| Step: 5
Training loss: 2.6065914630889893
Validation loss: 2.4207129863000687

Epoch: 6| Step: 6
Training loss: 3.1020233631134033
Validation loss: 2.406654324582828

Epoch: 6| Step: 7
Training loss: 2.7029144763946533
Validation loss: 2.4134489849049556

Epoch: 6| Step: 8
Training loss: 2.1760082244873047
Validation loss: 2.4082923422577562

Epoch: 6| Step: 9
Training loss: 2.6422605514526367
Validation loss: 2.402484163161247

Epoch: 6| Step: 10
Training loss: 2.3409907817840576
Validation loss: 2.404800071511217

Epoch: 6| Step: 11
Training loss: 2.412238597869873
Validation loss: 2.406807073982813

Epoch: 6| Step: 12
Training loss: 3.142176389694214
Validation loss: 2.403813495430895

Epoch: 6| Step: 13
Training loss: 2.454434871673584
Validation loss: 2.4010559512722875

Epoch: 33| Step: 0
Training loss: 2.29878568649292
Validation loss: 2.4005989951472126

Epoch: 6| Step: 1
Training loss: 2.77101731300354
Validation loss: 2.4029924433718444

Epoch: 6| Step: 2
Training loss: 2.562631130218506
Validation loss: 2.4184264316353747

Epoch: 6| Step: 3
Training loss: 2.090819835662842
Validation loss: 2.444784261847055

Epoch: 6| Step: 4
Training loss: 2.432997226715088
Validation loss: 2.438624756310576

Epoch: 6| Step: 5
Training loss: 2.652768850326538
Validation loss: 2.4512545908651044

Epoch: 6| Step: 6
Training loss: 3.24812912940979
Validation loss: 2.47315703668902

Epoch: 6| Step: 7
Training loss: 3.3198459148406982
Validation loss: 2.4503189466332875

Epoch: 6| Step: 8
Training loss: 2.481663227081299
Validation loss: 2.4065092097046556

Epoch: 6| Step: 9
Training loss: 2.2113070487976074
Validation loss: 2.398662608156922

Epoch: 6| Step: 10
Training loss: 3.14028263092041
Validation loss: 2.3930620429336384

Epoch: 6| Step: 11
Training loss: 2.7793469429016113
Validation loss: 2.4078684827332855

Epoch: 6| Step: 12
Training loss: 2.9559528827667236
Validation loss: 2.420299035246654

Epoch: 6| Step: 13
Training loss: 1.8294486999511719
Validation loss: 2.42002361307862

Epoch: 34| Step: 0
Training loss: 2.8406662940979004
Validation loss: 2.408817809115174

Epoch: 6| Step: 1
Training loss: 3.0079565048217773
Validation loss: 2.402230703702537

Epoch: 6| Step: 2
Training loss: 2.9790337085723877
Validation loss: 2.3966624070239324

Epoch: 6| Step: 3
Training loss: 1.715627908706665
Validation loss: 2.392574515393985

Epoch: 6| Step: 4
Training loss: 2.774312734603882
Validation loss: 2.4141712637357813

Epoch: 6| Step: 5
Training loss: 2.3632264137268066
Validation loss: 2.421712536965647

Epoch: 6| Step: 6
Training loss: 2.349965810775757
Validation loss: 2.449530045191447

Epoch: 6| Step: 7
Training loss: 2.2881922721862793
Validation loss: 2.470674337879304

Epoch: 6| Step: 8
Training loss: 2.6076579093933105
Validation loss: 2.4886997028063704

Epoch: 6| Step: 9
Training loss: 2.742156982421875
Validation loss: 2.466253815158721

Epoch: 6| Step: 10
Training loss: 3.131237506866455
Validation loss: 2.433475702039657

Epoch: 6| Step: 11
Training loss: 2.618668556213379
Validation loss: 2.409737656193395

Epoch: 6| Step: 12
Training loss: 3.4001519680023193
Validation loss: 2.3891632326187624

Epoch: 6| Step: 13
Training loss: 2.1326534748077393
Validation loss: 2.3805661188658847

Epoch: 35| Step: 0
Training loss: 2.5767064094543457
Validation loss: 2.3811819348283993

Epoch: 6| Step: 1
Training loss: 2.8015875816345215
Validation loss: 2.3821241163438365

Epoch: 6| Step: 2
Training loss: 2.4669063091278076
Validation loss: 2.383200207064229

Epoch: 6| Step: 3
Training loss: 2.9271535873413086
Validation loss: 2.3815932453319593

Epoch: 6| Step: 4
Training loss: 2.648951768875122
Validation loss: 2.3799412122336765

Epoch: 6| Step: 5
Training loss: 2.729541063308716
Validation loss: 2.382161714697397

Epoch: 6| Step: 6
Training loss: 2.9690146446228027
Validation loss: 2.3803839478441464

Epoch: 6| Step: 7
Training loss: 2.7424914836883545
Validation loss: 2.380591961645311

Epoch: 6| Step: 8
Training loss: 2.906832218170166
Validation loss: 2.374605522360853

Epoch: 6| Step: 9
Training loss: 2.5207717418670654
Validation loss: 2.3809662839417816

Epoch: 6| Step: 10
Training loss: 2.487679958343506
Validation loss: 2.3869859556997977

Epoch: 6| Step: 11
Training loss: 2.654242753982544
Validation loss: 2.4058320137762252

Epoch: 6| Step: 12
Training loss: 2.0946850776672363
Validation loss: 2.427538646164761

Epoch: 6| Step: 13
Training loss: 2.288863182067871
Validation loss: 2.4500748700993036

Epoch: 36| Step: 0
Training loss: 3.0557148456573486
Validation loss: 2.4509597234828497

Epoch: 6| Step: 1
Training loss: 2.944427728652954
Validation loss: 2.4498026037728913

Epoch: 6| Step: 2
Training loss: 2.2543110847473145
Validation loss: 2.4349714453502367

Epoch: 6| Step: 3
Training loss: 3.2169249057769775
Validation loss: 2.4382098362010014

Epoch: 6| Step: 4
Training loss: 2.811723232269287
Validation loss: 2.419090845251596

Epoch: 6| Step: 5
Training loss: 2.048393726348877
Validation loss: 2.402078932331454

Epoch: 6| Step: 6
Training loss: 2.5227768421173096
Validation loss: 2.377311703979328

Epoch: 6| Step: 7
Training loss: 2.102721691131592
Validation loss: 2.36842107260099

Epoch: 6| Step: 8
Training loss: 2.1678104400634766
Validation loss: 2.374988868672361

Epoch: 6| Step: 9
Training loss: 2.887692928314209
Validation loss: 2.3704028283396075

Epoch: 6| Step: 10
Training loss: 2.390615463256836
Validation loss: 2.3804201772136073

Epoch: 6| Step: 11
Training loss: 2.7715563774108887
Validation loss: 2.3722942362549486

Epoch: 6| Step: 12
Training loss: 2.459969997406006
Validation loss: 2.381292966104323

Epoch: 6| Step: 13
Training loss: 3.89162015914917
Validation loss: 2.3820886329938005

Epoch: 37| Step: 0
Training loss: 2.690272808074951
Validation loss: 2.3752397619267946

Epoch: 6| Step: 1
Training loss: 2.8944685459136963
Validation loss: 2.3776554394793767

Epoch: 6| Step: 2
Training loss: 2.7057836055755615
Validation loss: 2.3910749599497807

Epoch: 6| Step: 3
Training loss: 2.223942756652832
Validation loss: 2.3860872484022573

Epoch: 6| Step: 4
Training loss: 2.6551692485809326
Validation loss: 2.389724467390327

Epoch: 6| Step: 5
Training loss: 2.5377368927001953
Validation loss: 2.381948494142102

Epoch: 6| Step: 6
Training loss: 2.6271586418151855
Validation loss: 2.3910387536530853

Epoch: 6| Step: 7
Training loss: 2.1285533905029297
Validation loss: 2.4024134323161137

Epoch: 6| Step: 8
Training loss: 2.3901896476745605
Validation loss: 2.405583832853584

Epoch: 6| Step: 9
Training loss: 3.573049783706665
Validation loss: 2.406890038521059

Epoch: 6| Step: 10
Training loss: 2.942369222640991
Validation loss: 2.4084645317446802

Epoch: 6| Step: 11
Training loss: 2.8630411624908447
Validation loss: 2.405032398880169

Epoch: 6| Step: 12
Training loss: 2.3024115562438965
Validation loss: 2.4127743654353644

Epoch: 6| Step: 13
Training loss: 1.9090486764907837
Validation loss: 2.4132433834896294

Epoch: 38| Step: 0
Training loss: 2.869816780090332
Validation loss: 2.4212146318087013

Epoch: 6| Step: 1
Training loss: 3.311702251434326
Validation loss: 2.4048236826414704

Epoch: 6| Step: 2
Training loss: 2.9290378093719482
Validation loss: 2.4048468758982997

Epoch: 6| Step: 3
Training loss: 2.033618450164795
Validation loss: 2.4016133482738207

Epoch: 6| Step: 4
Training loss: 2.546046733856201
Validation loss: 2.4224068144316315

Epoch: 6| Step: 5
Training loss: 2.889420509338379
Validation loss: 2.488626205792991

Epoch: 6| Step: 6
Training loss: 1.9804842472076416
Validation loss: 2.4847323125408542

Epoch: 6| Step: 7
Training loss: 2.5432934761047363
Validation loss: 2.4001594794693815

Epoch: 6| Step: 8
Training loss: 1.8603801727294922
Validation loss: 2.389308024478215

Epoch: 6| Step: 9
Training loss: 2.8444204330444336
Validation loss: 2.36376497309695

Epoch: 6| Step: 10
Training loss: 2.9701108932495117
Validation loss: 2.35810713870551

Epoch: 6| Step: 11
Training loss: 2.9810445308685303
Validation loss: 2.375599568889987

Epoch: 6| Step: 12
Training loss: 2.6218433380126953
Validation loss: 2.4044425846428

Epoch: 6| Step: 13
Training loss: 2.270801305770874
Validation loss: 2.426407673025644

Epoch: 39| Step: 0
Training loss: 1.883151650428772
Validation loss: 2.4317201465688725

Epoch: 6| Step: 1
Training loss: 3.002713203430176
Validation loss: 2.462223518279291

Epoch: 6| Step: 2
Training loss: 2.426072597503662
Validation loss: 2.5038676902812016

Epoch: 6| Step: 3
Training loss: 3.4555773735046387
Validation loss: 2.5188104285988757

Epoch: 6| Step: 4
Training loss: 2.783205509185791
Validation loss: 2.5123434323136524

Epoch: 6| Step: 5
Training loss: 2.638955593109131
Validation loss: 2.489678587964786

Epoch: 6| Step: 6
Training loss: 2.672243595123291
Validation loss: 2.4428530431562856

Epoch: 6| Step: 7
Training loss: 2.724886655807495
Validation loss: 2.3966814189828853

Epoch: 6| Step: 8
Training loss: 2.489929437637329
Validation loss: 2.4146166565597698

Epoch: 6| Step: 9
Training loss: 2.7531445026397705
Validation loss: 2.3893027254330215

Epoch: 6| Step: 10
Training loss: 2.569882869720459
Validation loss: 2.3855666729711715

Epoch: 6| Step: 11
Training loss: 2.7084102630615234
Validation loss: 2.3791264641669487

Epoch: 6| Step: 12
Training loss: 3.123128652572632
Validation loss: 2.401919854584561

Epoch: 6| Step: 13
Training loss: 1.9282177686691284
Validation loss: 2.4030919639013146

Epoch: 40| Step: 0
Training loss: 2.6500277519226074
Validation loss: 2.428636740612727

Epoch: 6| Step: 1
Training loss: 3.3899190425872803
Validation loss: 2.4708055603888726

Epoch: 6| Step: 2
Training loss: 2.755685806274414
Validation loss: 2.456533952425885

Epoch: 6| Step: 3
Training loss: 2.488097667694092
Validation loss: 2.5088351093312746

Epoch: 6| Step: 4
Training loss: 2.9850258827209473
Validation loss: 2.532441964713476

Epoch: 6| Step: 5
Training loss: 2.765193462371826
Validation loss: 2.4387359132048902

Epoch: 6| Step: 6
Training loss: 2.6082229614257812
Validation loss: 2.4084012790392806

Epoch: 6| Step: 7
Training loss: 2.4517717361450195
Validation loss: 2.4032542423535417

Epoch: 6| Step: 8
Training loss: 2.2603836059570312
Validation loss: 2.4063692477441605

Epoch: 6| Step: 9
Training loss: 2.6475343704223633
Validation loss: 2.433204561151484

Epoch: 6| Step: 10
Training loss: 2.7019948959350586
Validation loss: 2.447643538957001

Epoch: 6| Step: 11
Training loss: 2.9995245933532715
Validation loss: 2.47287646929423

Epoch: 6| Step: 12
Training loss: 2.1005125045776367
Validation loss: 2.453670419672484

Epoch: 6| Step: 13
Training loss: 2.6806225776672363
Validation loss: 2.424341896528839

Epoch: 41| Step: 0
Training loss: 2.8003227710723877
Validation loss: 2.402748018182734

Epoch: 6| Step: 1
Training loss: 2.485140323638916
Validation loss: 2.3936151227643414

Epoch: 6| Step: 2
Training loss: 1.979919672012329
Validation loss: 2.3956516686306206

Epoch: 6| Step: 3
Training loss: 2.6874561309814453
Validation loss: 2.4116703182138424

Epoch: 6| Step: 4
Training loss: 2.730802536010742
Validation loss: 2.3994890566795104

Epoch: 6| Step: 5
Training loss: 3.1403422355651855
Validation loss: 2.3995822809075795

Epoch: 6| Step: 6
Training loss: 2.8971238136291504
Validation loss: 2.4001309871673584

Epoch: 6| Step: 7
Training loss: 2.4393458366394043
Validation loss: 2.400060256322225

Epoch: 6| Step: 8
Training loss: 2.3954153060913086
Validation loss: 2.4094658769587034

Epoch: 6| Step: 9
Training loss: 3.277475357055664
Validation loss: 2.440191222775367

Epoch: 6| Step: 10
Training loss: 2.351032018661499
Validation loss: 2.4831952074522614

Epoch: 6| Step: 11
Training loss: 2.735924482345581
Validation loss: 2.51644955911944

Epoch: 6| Step: 12
Training loss: 2.471735954284668
Validation loss: 2.5473922760255876

Epoch: 6| Step: 13
Training loss: 3.070152759552002
Validation loss: 2.5592219393740416

Epoch: 42| Step: 0
Training loss: 2.872701406478882
Validation loss: 2.522743219970375

Epoch: 6| Step: 1
Training loss: 3.1960320472717285
Validation loss: 2.5274235304965766

Epoch: 6| Step: 2
Training loss: 3.383759021759033
Validation loss: 2.490583227526757

Epoch: 6| Step: 3
Training loss: 2.669908285140991
Validation loss: 2.4783243081902944

Epoch: 6| Step: 4
Training loss: 2.5321505069732666
Validation loss: 2.481719281083794

Epoch: 6| Step: 5
Training loss: 3.218475818634033
Validation loss: 2.4990552676621305

Epoch: 6| Step: 6
Training loss: 2.8972880840301514
Validation loss: 2.485912715235064

Epoch: 6| Step: 7
Training loss: 3.074845552444458
Validation loss: 2.446444665232012

Epoch: 6| Step: 8
Training loss: 2.0111446380615234
Validation loss: 2.40569975555584

Epoch: 6| Step: 9
Training loss: 2.45711088180542
Validation loss: 2.3971416693861767

Epoch: 6| Step: 10
Training loss: 2.176321029663086
Validation loss: 2.3929458254127094

Epoch: 6| Step: 11
Training loss: 2.0446388721466064
Validation loss: 2.373041599027572

Epoch: 6| Step: 12
Training loss: 2.273334503173828
Validation loss: 2.3746997156450824

Epoch: 6| Step: 13
Training loss: 2.2650301456451416
Validation loss: 2.3643806442137687

Epoch: 43| Step: 0
Training loss: 1.9723219871520996
Validation loss: 2.357423628530195

Epoch: 6| Step: 1
Training loss: 2.5990469455718994
Validation loss: 2.3506242844366256

Epoch: 6| Step: 2
Training loss: 2.869575023651123
Validation loss: 2.350642514485185

Epoch: 6| Step: 3
Training loss: 1.9781835079193115
Validation loss: 2.3536737580453195

Epoch: 6| Step: 4
Training loss: 2.6329054832458496
Validation loss: 2.343875172317669

Epoch: 6| Step: 5
Training loss: 2.890639066696167
Validation loss: 2.339454604733375

Epoch: 6| Step: 6
Training loss: 2.478005886077881
Validation loss: 2.33813145852858

Epoch: 6| Step: 7
Training loss: 3.0856688022613525
Validation loss: 2.3402451776689097

Epoch: 6| Step: 8
Training loss: 2.235583782196045
Validation loss: 2.347359365032565

Epoch: 6| Step: 9
Training loss: 2.766664981842041
Validation loss: 2.3528082524576495

Epoch: 6| Step: 10
Training loss: 2.970343589782715
Validation loss: 2.3522175665824645

Epoch: 6| Step: 11
Training loss: 2.782240390777588
Validation loss: 2.357440789540609

Epoch: 6| Step: 12
Training loss: 2.4258880615234375
Validation loss: 2.3509560759349535

Epoch: 6| Step: 13
Training loss: 2.982858419418335
Validation loss: 2.3557723388876965

Epoch: 44| Step: 0
Training loss: 1.856408953666687
Validation loss: 2.3516565061384633

Epoch: 6| Step: 1
Training loss: 2.3815383911132812
Validation loss: 2.359022391739712

Epoch: 6| Step: 2
Training loss: 3.012444019317627
Validation loss: 2.3426771266486055

Epoch: 6| Step: 3
Training loss: 2.4843952655792236
Validation loss: 2.3225142263597056

Epoch: 6| Step: 4
Training loss: 2.4022698402404785
Validation loss: 2.320553784729332

Epoch: 6| Step: 5
Training loss: 2.7282814979553223
Validation loss: 2.3192364195341706

Epoch: 6| Step: 6
Training loss: 3.0167365074157715
Validation loss: 2.311951211703721

Epoch: 6| Step: 7
Training loss: 3.202476978302002
Validation loss: 2.312124821447557

Epoch: 6| Step: 8
Training loss: 2.496218681335449
Validation loss: 2.3104140438059324

Epoch: 6| Step: 9
Training loss: 2.8346619606018066
Validation loss: 2.311985787524972

Epoch: 6| Step: 10
Training loss: 2.355773448944092
Validation loss: 2.311350950630762

Epoch: 6| Step: 11
Training loss: 2.8196606636047363
Validation loss: 2.313453415388702

Epoch: 6| Step: 12
Training loss: 2.752498149871826
Validation loss: 2.3057144047111593

Epoch: 6| Step: 13
Training loss: 1.7438722848892212
Validation loss: 2.3165027787608485

Epoch: 45| Step: 0
Training loss: 2.248502492904663
Validation loss: 2.3145215178048737

Epoch: 6| Step: 1
Training loss: 3.086178779602051
Validation loss: 2.3228155489890807

Epoch: 6| Step: 2
Training loss: 3.0388479232788086
Validation loss: 2.3176480211237425

Epoch: 6| Step: 3
Training loss: 2.585588216781616
Validation loss: 2.3147605055121967

Epoch: 6| Step: 4
Training loss: 2.176697254180908
Validation loss: 2.30965333343834

Epoch: 6| Step: 5
Training loss: 2.581357002258301
Validation loss: 2.306560444575484

Epoch: 6| Step: 6
Training loss: 1.504391074180603
Validation loss: 2.29981892852373

Epoch: 6| Step: 7
Training loss: 2.5208897590637207
Validation loss: 2.298560534754107

Epoch: 6| Step: 8
Training loss: 2.6008458137512207
Validation loss: 2.3035339129868375

Epoch: 6| Step: 9
Training loss: 2.8633854389190674
Validation loss: 2.3065185649420625

Epoch: 6| Step: 10
Training loss: 3.015183687210083
Validation loss: 2.318169293865081

Epoch: 6| Step: 11
Training loss: 2.498627185821533
Validation loss: 2.314603001840653

Epoch: 6| Step: 12
Training loss: 2.9779105186462402
Validation loss: 2.317319857176914

Epoch: 6| Step: 13
Training loss: 2.5490119457244873
Validation loss: 2.3138947973969164

Epoch: 46| Step: 0
Training loss: 2.731790781021118
Validation loss: 2.32238438821608

Epoch: 6| Step: 1
Training loss: 1.941941738128662
Validation loss: 2.3280645467901744

Epoch: 6| Step: 2
Training loss: 1.8121206760406494
Validation loss: 2.3270714693172003

Epoch: 6| Step: 3
Training loss: 2.7463455200195312
Validation loss: 2.320174155696746

Epoch: 6| Step: 4
Training loss: 2.379941701889038
Validation loss: 2.305399271749681

Epoch: 6| Step: 5
Training loss: 2.4344139099121094
Validation loss: 2.316165098579981

Epoch: 6| Step: 6
Training loss: 2.1508941650390625
Validation loss: 2.3162091855079896

Epoch: 6| Step: 7
Training loss: 2.619466781616211
Validation loss: 2.299916046921925

Epoch: 6| Step: 8
Training loss: 2.400026321411133
Validation loss: 2.3027510771187405

Epoch: 6| Step: 9
Training loss: 3.1008005142211914
Validation loss: 2.3081695725840907

Epoch: 6| Step: 10
Training loss: 2.804570436477661
Validation loss: 2.2999286395247265

Epoch: 6| Step: 11
Training loss: 3.1006155014038086
Validation loss: 2.3065828149036696

Epoch: 6| Step: 12
Training loss: 2.9407474994659424
Validation loss: 2.30253852311001

Epoch: 6| Step: 13
Training loss: 3.4395179748535156
Validation loss: 2.3034501588472756

Epoch: 47| Step: 0
Training loss: 2.5564117431640625
Validation loss: 2.3135561122689197

Epoch: 6| Step: 1
Training loss: 2.7019448280334473
Validation loss: 2.331969053514542

Epoch: 6| Step: 2
Training loss: 2.8182787895202637
Validation loss: 2.3403363535481114

Epoch: 6| Step: 3
Training loss: 2.0613083839416504
Validation loss: 2.3506949358088995

Epoch: 6| Step: 4
Training loss: 1.9951910972595215
Validation loss: 2.3854285260682464

Epoch: 6| Step: 5
Training loss: 2.549530029296875
Validation loss: 2.4205683508226947

Epoch: 6| Step: 6
Training loss: 3.087120294570923
Validation loss: 2.469441011387815

Epoch: 6| Step: 7
Training loss: 2.7169113159179688
Validation loss: 2.4519113955959195

Epoch: 6| Step: 8
Training loss: 3.237001895904541
Validation loss: 2.419668354013915

Epoch: 6| Step: 9
Training loss: 2.4857635498046875
Validation loss: 2.3988936562691965

Epoch: 6| Step: 10
Training loss: 2.5958237648010254
Validation loss: 2.3871377360436226

Epoch: 6| Step: 11
Training loss: 2.177222967147827
Validation loss: 2.3651831291055165

Epoch: 6| Step: 12
Training loss: 2.472832679748535
Validation loss: 2.353127392389441

Epoch: 6| Step: 13
Training loss: 3.5319836139678955
Validation loss: 2.3420863920642483

Epoch: 48| Step: 0
Training loss: 2.543922185897827
Validation loss: 2.3155687726953977

Epoch: 6| Step: 1
Training loss: 2.4282164573669434
Validation loss: 2.30653537729735

Epoch: 6| Step: 2
Training loss: 3.3053677082061768
Validation loss: 2.2943653445090018

Epoch: 6| Step: 3
Training loss: 2.578511953353882
Validation loss: 2.286989412000102

Epoch: 6| Step: 4
Training loss: 2.7481441497802734
Validation loss: 2.292975947421084

Epoch: 6| Step: 5
Training loss: 2.6220149993896484
Validation loss: 2.2936226706351004

Epoch: 6| Step: 6
Training loss: 2.812167167663574
Validation loss: 2.292916246639785

Epoch: 6| Step: 7
Training loss: 2.2753915786743164
Validation loss: 2.286187187317879

Epoch: 6| Step: 8
Training loss: 2.2190585136413574
Validation loss: 2.297384568440017

Epoch: 6| Step: 9
Training loss: 2.780888795852661
Validation loss: 2.294246268528764

Epoch: 6| Step: 10
Training loss: 2.485841989517212
Validation loss: 2.2920420810740483

Epoch: 6| Step: 11
Training loss: 2.44925856590271
Validation loss: 2.293088697618054

Epoch: 6| Step: 12
Training loss: 2.3850388526916504
Validation loss: 2.297916466189969

Epoch: 6| Step: 13
Training loss: 2.5716519355773926
Validation loss: 2.301993577711044

Epoch: 49| Step: 0
Training loss: 1.938610315322876
Validation loss: 2.3136801424846856

Epoch: 6| Step: 1
Training loss: 2.394260883331299
Validation loss: 2.318056329604118

Epoch: 6| Step: 2
Training loss: 2.591365098953247
Validation loss: 2.3287965225917038

Epoch: 6| Step: 3
Training loss: 2.4353647232055664
Validation loss: 2.346413427783597

Epoch: 6| Step: 4
Training loss: 3.1194448471069336
Validation loss: 2.3532919396636305

Epoch: 6| Step: 5
Training loss: 2.573558807373047
Validation loss: 2.364924817956904

Epoch: 6| Step: 6
Training loss: 2.7071752548217773
Validation loss: 2.3420726894050516

Epoch: 6| Step: 7
Training loss: 2.731966257095337
Validation loss: 2.307503818183817

Epoch: 6| Step: 8
Training loss: 2.787883758544922
Validation loss: 2.2921372664872037

Epoch: 6| Step: 9
Training loss: 3.3084025382995605
Validation loss: 2.280092821326307

Epoch: 6| Step: 10
Training loss: 2.5223307609558105
Validation loss: 2.2754114135619132

Epoch: 6| Step: 11
Training loss: 2.278979539871216
Validation loss: 2.275415699969056

Epoch: 6| Step: 12
Training loss: 2.396243095397949
Validation loss: 2.2731833175946305

Epoch: 6| Step: 13
Training loss: 2.144075393676758
Validation loss: 2.272670779176938

Epoch: 50| Step: 0
Training loss: 2.3851003646850586
Validation loss: 2.276582069294427

Epoch: 6| Step: 1
Training loss: 2.5995306968688965
Validation loss: 2.2810685737158662

Epoch: 6| Step: 2
Training loss: 2.8520240783691406
Validation loss: 2.2812357615399104

Epoch: 6| Step: 3
Training loss: 2.625398635864258
Validation loss: 2.279518573514877

Epoch: 6| Step: 4
Training loss: 2.079167366027832
Validation loss: 2.2965112809211976

Epoch: 6| Step: 5
Training loss: 1.8809404373168945
Validation loss: 2.306748761925646

Epoch: 6| Step: 6
Training loss: 1.739400029182434
Validation loss: 2.3283401176493657

Epoch: 6| Step: 7
Training loss: 3.19286847114563
Validation loss: 2.3504938669102167

Epoch: 6| Step: 8
Training loss: 2.6681599617004395
Validation loss: 2.3571309351151988

Epoch: 6| Step: 9
Training loss: 3.2934532165527344
Validation loss: 2.341750934559812

Epoch: 6| Step: 10
Training loss: 2.7171919345855713
Validation loss: 2.322052945372879

Epoch: 6| Step: 11
Training loss: 2.9782252311706543
Validation loss: 2.310734615531019

Epoch: 6| Step: 12
Training loss: 2.3617851734161377
Validation loss: 2.284933961847777

Epoch: 6| Step: 13
Training loss: 2.7493715286254883
Validation loss: 2.284633146819248

Epoch: 51| Step: 0
Training loss: 2.454594612121582
Validation loss: 2.2801043038727133

Epoch: 6| Step: 1
Training loss: 2.169857978820801
Validation loss: 2.2783944632417414

Epoch: 6| Step: 2
Training loss: 2.0895495414733887
Validation loss: 2.2806102306612077

Epoch: 6| Step: 3
Training loss: 3.006948471069336
Validation loss: 2.284482652141202

Epoch: 6| Step: 4
Training loss: 1.9607198238372803
Validation loss: 2.2834387389562463

Epoch: 6| Step: 5
Training loss: 2.574460029602051
Validation loss: 2.3197774938357774

Epoch: 6| Step: 6
Training loss: 3.0965569019317627
Validation loss: 2.2952745870877336

Epoch: 6| Step: 7
Training loss: 3.1246159076690674
Validation loss: 2.3012152846141527

Epoch: 6| Step: 8
Training loss: 2.174178123474121
Validation loss: 2.3070552143999326

Epoch: 6| Step: 9
Training loss: 2.391512870788574
Validation loss: 2.2968596232834684

Epoch: 6| Step: 10
Training loss: 2.524470806121826
Validation loss: 2.291804623860185

Epoch: 6| Step: 11
Training loss: 3.362395763397217
Validation loss: 2.291230090202824

Epoch: 6| Step: 12
Training loss: 2.5243754386901855
Validation loss: 2.282191648278185

Epoch: 6| Step: 13
Training loss: 2.4952964782714844
Validation loss: 2.2841059315589165

Epoch: 52| Step: 0
Training loss: 2.3924922943115234
Validation loss: 2.290053918797483

Epoch: 6| Step: 1
Training loss: 2.2803561687469482
Validation loss: 2.297717616122256

Epoch: 6| Step: 2
Training loss: 3.4971442222595215
Validation loss: 2.3103038290495514

Epoch: 6| Step: 3
Training loss: 2.524618625640869
Validation loss: 2.309489434765231

Epoch: 6| Step: 4
Training loss: 2.813812732696533
Validation loss: 2.3084355464545627

Epoch: 6| Step: 5
Training loss: 2.4419679641723633
Validation loss: 2.296004156912527

Epoch: 6| Step: 6
Training loss: 2.5076634883880615
Validation loss: 2.2899744741378294

Epoch: 6| Step: 7
Training loss: 3.1488494873046875
Validation loss: 2.2784217711417907

Epoch: 6| Step: 8
Training loss: 2.0950169563293457
Validation loss: 2.290243741004698

Epoch: 6| Step: 9
Training loss: 2.354917049407959
Validation loss: 2.2853094736735025

Epoch: 6| Step: 10
Training loss: 2.239173650741577
Validation loss: 2.3040573776409192

Epoch: 6| Step: 11
Training loss: 2.874312162399292
Validation loss: 2.3047059582125757

Epoch: 6| Step: 12
Training loss: 2.3377935886383057
Validation loss: 2.304226145949415

Epoch: 6| Step: 13
Training loss: 2.204263925552368
Validation loss: 2.3048816163052797

Epoch: 53| Step: 0
Training loss: 2.2277016639709473
Validation loss: 2.2932888871879986

Epoch: 6| Step: 1
Training loss: 2.9049293994903564
Validation loss: 2.2876977023258003

Epoch: 6| Step: 2
Training loss: 2.5347037315368652
Validation loss: 2.283023231772966

Epoch: 6| Step: 3
Training loss: 2.075617551803589
Validation loss: 2.2733763751163276

Epoch: 6| Step: 4
Training loss: 3.128469705581665
Validation loss: 2.2808645361213276

Epoch: 6| Step: 5
Training loss: 2.730226993560791
Validation loss: 2.2770784003760225

Epoch: 6| Step: 6
Training loss: 3.0123348236083984
Validation loss: 2.2793225549882457

Epoch: 6| Step: 7
Training loss: 2.36460018157959
Validation loss: 2.2784247808558966

Epoch: 6| Step: 8
Training loss: 2.5133938789367676
Validation loss: 2.267643513218049

Epoch: 6| Step: 9
Training loss: 2.0829520225524902
Validation loss: 2.283201450942665

Epoch: 6| Step: 10
Training loss: 2.8425326347351074
Validation loss: 2.2800845740943827

Epoch: 6| Step: 11
Training loss: 2.2692761421203613
Validation loss: 2.2669616309545373

Epoch: 6| Step: 12
Training loss: 2.954364776611328
Validation loss: 2.2644448562334945

Epoch: 6| Step: 13
Training loss: 1.8281331062316895
Validation loss: 2.2749438965192406

Epoch: 54| Step: 0
Training loss: 2.7443125247955322
Validation loss: 2.2693316269946355

Epoch: 6| Step: 1
Training loss: 1.8108618259429932
Validation loss: 2.285620415082542

Epoch: 6| Step: 2
Training loss: 2.3615992069244385
Validation loss: 2.2835872147672918

Epoch: 6| Step: 3
Training loss: 2.7929275035858154
Validation loss: 2.293632617560766

Epoch: 6| Step: 4
Training loss: 2.1420841217041016
Validation loss: 2.309374079909376

Epoch: 6| Step: 5
Training loss: 2.342803955078125
Validation loss: 2.30097205920886

Epoch: 6| Step: 6
Training loss: 2.4774153232574463
Validation loss: 2.3007646145359164

Epoch: 6| Step: 7
Training loss: 3.2574524879455566
Validation loss: 2.2903915759055846

Epoch: 6| Step: 8
Training loss: 2.728440761566162
Validation loss: 2.266627033551534

Epoch: 6| Step: 9
Training loss: 2.69970703125
Validation loss: 2.2611360985745668

Epoch: 6| Step: 10
Training loss: 2.5293946266174316
Validation loss: 2.2555218614557737

Epoch: 6| Step: 11
Training loss: 2.8948540687561035
Validation loss: 2.252188967120263

Epoch: 6| Step: 12
Training loss: 2.5640206336975098
Validation loss: 2.254159891477195

Epoch: 6| Step: 13
Training loss: 2.1161956787109375
Validation loss: 2.250079949696859

Epoch: 55| Step: 0
Training loss: 2.211442470550537
Validation loss: 2.249014715994558

Epoch: 6| Step: 1
Training loss: 2.7480249404907227
Validation loss: 2.2528437029930855

Epoch: 6| Step: 2
Training loss: 2.315009117126465
Validation loss: 2.2527425340426865

Epoch: 6| Step: 3
Training loss: 2.1778218746185303
Validation loss: 2.2607193121346096

Epoch: 6| Step: 4
Training loss: 2.127951145172119
Validation loss: 2.2625017576320197

Epoch: 6| Step: 5
Training loss: 1.951741099357605
Validation loss: 2.2768402817428752

Epoch: 6| Step: 6
Training loss: 2.257028341293335
Validation loss: 2.3010358579697145

Epoch: 6| Step: 7
Training loss: 2.9804999828338623
Validation loss: 2.3396528767001246

Epoch: 6| Step: 8
Training loss: 2.709670066833496
Validation loss: 2.3522534601150022

Epoch: 6| Step: 9
Training loss: 2.2345352172851562
Validation loss: 2.3080926351649786

Epoch: 6| Step: 10
Training loss: 2.7740821838378906
Validation loss: 2.2872795263926187

Epoch: 6| Step: 11
Training loss: 3.5789356231689453
Validation loss: 2.2710611615129697

Epoch: 6| Step: 12
Training loss: 3.0128109455108643
Validation loss: 2.261868248703659

Epoch: 6| Step: 13
Training loss: 2.782818078994751
Validation loss: 2.2529643889396422

Epoch: 56| Step: 0
Training loss: 2.3251891136169434
Validation loss: 2.2394000586643013

Epoch: 6| Step: 1
Training loss: 2.7504758834838867
Validation loss: 2.234419540692401

Epoch: 6| Step: 2
Training loss: 2.1634011268615723
Validation loss: 2.2311305333209295

Epoch: 6| Step: 3
Training loss: 2.3537378311157227
Validation loss: 2.2317946700639624

Epoch: 6| Step: 4
Training loss: 2.965610980987549
Validation loss: 2.2320975718959684

Epoch: 6| Step: 5
Training loss: 2.3051400184631348
Validation loss: 2.238249067337282

Epoch: 6| Step: 6
Training loss: 2.9133243560791016
Validation loss: 2.2411738634109497

Epoch: 6| Step: 7
Training loss: 3.044715404510498
Validation loss: 2.253635155257358

Epoch: 6| Step: 8
Training loss: 3.1103100776672363
Validation loss: 2.25972657562584

Epoch: 6| Step: 9
Training loss: 1.5477186441421509
Validation loss: 2.270281045667587

Epoch: 6| Step: 10
Training loss: 2.535440444946289
Validation loss: 2.266357252674718

Epoch: 6| Step: 11
Training loss: 3.3136844635009766
Validation loss: 2.2838334716776365

Epoch: 6| Step: 12
Training loss: 2.3664026260375977
Validation loss: 2.312926450083333

Epoch: 6| Step: 13
Training loss: 1.4166393280029297
Validation loss: 2.320392659915391

Epoch: 57| Step: 0
Training loss: 2.1506168842315674
Validation loss: 2.331839156407182

Epoch: 6| Step: 1
Training loss: 2.9559974670410156
Validation loss: 2.355856898010418

Epoch: 6| Step: 2
Training loss: 2.745307445526123
Validation loss: 2.338938074727212

Epoch: 6| Step: 3
Training loss: 2.676314353942871
Validation loss: 2.2866084319289013

Epoch: 6| Step: 4
Training loss: 2.359929084777832
Validation loss: 2.245521415946304

Epoch: 6| Step: 5
Training loss: 2.7393972873687744
Validation loss: 2.2396673925461306

Epoch: 6| Step: 6
Training loss: 2.687715530395508
Validation loss: 2.2300760899820635

Epoch: 6| Step: 7
Training loss: 2.570894479751587
Validation loss: 2.2341250245289137

Epoch: 6| Step: 8
Training loss: 2.555887222290039
Validation loss: 2.246611151643979

Epoch: 6| Step: 9
Training loss: 2.5054547786712646
Validation loss: 2.264965708537768

Epoch: 6| Step: 10
Training loss: 2.6579272747039795
Validation loss: 2.264884070683551

Epoch: 6| Step: 11
Training loss: 2.315321445465088
Validation loss: 2.2758823646012174

Epoch: 6| Step: 12
Training loss: 2.3136565685272217
Validation loss: 2.296514586735797

Epoch: 6| Step: 13
Training loss: 2.3847768306732178
Validation loss: 2.2967429904527563

Epoch: 58| Step: 0
Training loss: 3.2623138427734375
Validation loss: 2.2977669931227163

Epoch: 6| Step: 1
Training loss: 2.122499704360962
Validation loss: 2.2754859488497496

Epoch: 6| Step: 2
Training loss: 2.9317209720611572
Validation loss: 2.249495449886527

Epoch: 6| Step: 3
Training loss: 2.807157039642334
Validation loss: 2.228584735624252

Epoch: 6| Step: 4
Training loss: 2.3845341205596924
Validation loss: 2.225324483327968

Epoch: 6| Step: 5
Training loss: 2.210862159729004
Validation loss: 2.2282010047666487

Epoch: 6| Step: 6
Training loss: 2.6253504753112793
Validation loss: 2.230574959067888

Epoch: 6| Step: 7
Training loss: 2.7525057792663574
Validation loss: 2.2427463198220856

Epoch: 6| Step: 8
Training loss: 2.16217041015625
Validation loss: 2.2709668169739428

Epoch: 6| Step: 9
Training loss: 2.191727638244629
Validation loss: 2.3141393071861676

Epoch: 6| Step: 10
Training loss: 1.9616286754608154
Validation loss: 2.34058617648258

Epoch: 6| Step: 11
Training loss: 2.318368434906006
Validation loss: 2.3644057038009807

Epoch: 6| Step: 12
Training loss: 3.1012215614318848
Validation loss: 2.3355064827908754

Epoch: 6| Step: 13
Training loss: 3.039407968521118
Validation loss: 2.347470106617097

Epoch: 59| Step: 0
Training loss: 2.4138736724853516
Validation loss: 2.324233739606796

Epoch: 6| Step: 1
Training loss: 2.2309751510620117
Validation loss: 2.2470422098713536

Epoch: 6| Step: 2
Training loss: 2.434774398803711
Validation loss: 2.223776363557385

Epoch: 6| Step: 3
Training loss: 2.7827930450439453
Validation loss: 2.2139865531716296

Epoch: 6| Step: 4
Training loss: 2.965830087661743
Validation loss: 2.210968663615565

Epoch: 6| Step: 5
Training loss: 2.1938953399658203
Validation loss: 2.213838792616321

Epoch: 6| Step: 6
Training loss: 2.4562692642211914
Validation loss: 2.217182441424298

Epoch: 6| Step: 7
Training loss: 2.6145083904266357
Validation loss: 2.2291310115527083

Epoch: 6| Step: 8
Training loss: 2.7943389415740967
Validation loss: 2.248373682780932

Epoch: 6| Step: 9
Training loss: 1.9854785203933716
Validation loss: 2.265295533723729

Epoch: 6| Step: 10
Training loss: 3.0071873664855957
Validation loss: 2.2782940813290176

Epoch: 6| Step: 11
Training loss: 2.5078234672546387
Validation loss: 2.2724708177710093

Epoch: 6| Step: 12
Training loss: 2.7078752517700195
Validation loss: 2.286729848513039

Epoch: 6| Step: 13
Training loss: 2.8297626972198486
Validation loss: 2.2687983820515294

Epoch: 60| Step: 0
Training loss: 1.5092723369598389
Validation loss: 2.26746956763729

Epoch: 6| Step: 1
Training loss: 2.6723499298095703
Validation loss: 2.252949522387597

Epoch: 6| Step: 2
Training loss: 2.738924264907837
Validation loss: 2.243572997790511

Epoch: 6| Step: 3
Training loss: 2.9351699352264404
Validation loss: 2.2456384961323073

Epoch: 6| Step: 4
Training loss: 2.4164493083953857
Validation loss: 2.270292084704163

Epoch: 6| Step: 5
Training loss: 2.528006076812744
Validation loss: 2.2666679659197406

Epoch: 6| Step: 6
Training loss: 2.979029655456543
Validation loss: 2.2665345643156316

Epoch: 6| Step: 7
Training loss: 2.75266432762146
Validation loss: 2.2760596454784436

Epoch: 6| Step: 8
Training loss: 2.1469831466674805
Validation loss: 2.315192207213371

Epoch: 6| Step: 9
Training loss: 2.376957654953003
Validation loss: 2.3404630717410835

Epoch: 6| Step: 10
Training loss: 2.3296170234680176
Validation loss: 2.3435746328805083

Epoch: 6| Step: 11
Training loss: 2.4839863777160645
Validation loss: 2.2919973365722166

Epoch: 6| Step: 12
Training loss: 2.487773895263672
Validation loss: 2.2421339814380934

Epoch: 6| Step: 13
Training loss: 3.9069929122924805
Validation loss: 2.21494294751075

Epoch: 61| Step: 0
Training loss: 3.0627050399780273
Validation loss: 2.2059744417026477

Epoch: 6| Step: 1
Training loss: 2.927746534347534
Validation loss: 2.2040709346853276

Epoch: 6| Step: 2
Training loss: 3.408229351043701
Validation loss: 2.210941122424218

Epoch: 6| Step: 3
Training loss: 1.883293867111206
Validation loss: 2.2142965626972977

Epoch: 6| Step: 4
Training loss: 1.9946088790893555
Validation loss: 2.2210908807734007

Epoch: 6| Step: 5
Training loss: 2.3126540184020996
Validation loss: 2.2158285930592525

Epoch: 6| Step: 6
Training loss: 2.744875192642212
Validation loss: 2.2143598910300963

Epoch: 6| Step: 7
Training loss: 2.813660144805908
Validation loss: 2.1998770288241807

Epoch: 6| Step: 8
Training loss: 2.254678249359131
Validation loss: 2.2013003005776355

Epoch: 6| Step: 9
Training loss: 1.8943848609924316
Validation loss: 2.2000712630569295

Epoch: 6| Step: 10
Training loss: 2.2245898246765137
Validation loss: 2.201578677341502

Epoch: 6| Step: 11
Training loss: 2.8237457275390625
Validation loss: 2.1981186456577753

Epoch: 6| Step: 12
Training loss: 2.903641700744629
Validation loss: 2.199526661185808

Epoch: 6| Step: 13
Training loss: 2.341546058654785
Validation loss: 2.2083873620597263

Epoch: 62| Step: 0
Training loss: 2.2808427810668945
Validation loss: 2.2205959571305143

Epoch: 6| Step: 1
Training loss: 2.6291942596435547
Validation loss: 2.2380177974700928

Epoch: 6| Step: 2
Training loss: 2.6432416439056396
Validation loss: 2.263958295186361

Epoch: 6| Step: 3
Training loss: 2.926649570465088
Validation loss: 2.2663116480714534

Epoch: 6| Step: 4
Training loss: 2.384730339050293
Validation loss: 2.2730012363003147

Epoch: 6| Step: 5
Training loss: 2.9221982955932617
Validation loss: 2.272212605322561

Epoch: 6| Step: 6
Training loss: 2.6688809394836426
Validation loss: 2.2434779418412076

Epoch: 6| Step: 7
Training loss: 3.0013866424560547
Validation loss: 2.2318019495215466

Epoch: 6| Step: 8
Training loss: 2.059109926223755
Validation loss: 2.2216650747483775

Epoch: 6| Step: 9
Training loss: 1.9811433553695679
Validation loss: 2.2366481160604827

Epoch: 6| Step: 10
Training loss: 2.6605567932128906
Validation loss: 2.260174407753893

Epoch: 6| Step: 11
Training loss: 1.8224503993988037
Validation loss: 2.296164184488276

Epoch: 6| Step: 12
Training loss: 2.578625202178955
Validation loss: 2.31934537682482

Epoch: 6| Step: 13
Training loss: 2.8340036869049072
Validation loss: 2.3216940792657996

Epoch: 63| Step: 0
Training loss: 2.590282917022705
Validation loss: 2.2355864330004622

Epoch: 6| Step: 1
Training loss: 3.440047025680542
Validation loss: 2.213999168847197

Epoch: 6| Step: 2
Training loss: 2.2843449115753174
Validation loss: 2.206793236476119

Epoch: 6| Step: 3
Training loss: 2.5916261672973633
Validation loss: 2.2075973505614908

Epoch: 6| Step: 4
Training loss: 2.97568416595459
Validation loss: 2.231479071801709

Epoch: 6| Step: 5
Training loss: 3.200110673904419
Validation loss: 2.244429090971588

Epoch: 6| Step: 6
Training loss: 2.680074691772461
Validation loss: 2.2521426011157293

Epoch: 6| Step: 7
Training loss: 2.578608989715576
Validation loss: 2.2193621896928355

Epoch: 6| Step: 8
Training loss: 1.9479045867919922
Validation loss: 2.2251582325145765

Epoch: 6| Step: 9
Training loss: 2.4867217540740967
Validation loss: 2.325717592752108

Epoch: 6| Step: 10
Training loss: 2.069382667541504
Validation loss: 2.4681548585173902

Epoch: 6| Step: 11
Training loss: 2.1960253715515137
Validation loss: 2.612421194712321

Epoch: 6| Step: 12
Training loss: 2.658871650695801
Validation loss: 2.680389778588408

Epoch: 6| Step: 13
Training loss: 2.4014415740966797
Validation loss: 2.6255805312946277

Epoch: 64| Step: 0
Training loss: 2.6883323192596436
Validation loss: 2.5884513111524683

Epoch: 6| Step: 1
Training loss: 1.9526402950286865
Validation loss: 2.5681258093926216

Epoch: 6| Step: 2
Training loss: 3.103586196899414
Validation loss: 2.496313653966432

Epoch: 6| Step: 3
Training loss: 3.0360283851623535
Validation loss: 2.4536059043740712

Epoch: 6| Step: 4
Training loss: 2.6536917686462402
Validation loss: 2.4680455961535053

Epoch: 6| Step: 5
Training loss: 3.485015869140625
Validation loss: 2.5429242733986146

Epoch: 6| Step: 6
Training loss: 2.7987945079803467
Validation loss: 2.627410081125075

Epoch: 6| Step: 7
Training loss: 2.889699935913086
Validation loss: 2.6573932478504796

Epoch: 6| Step: 8
Training loss: 2.4922099113464355
Validation loss: 2.5479541824709986

Epoch: 6| Step: 9
Training loss: 2.435180187225342
Validation loss: 2.489697428159816

Epoch: 6| Step: 10
Training loss: 2.4924745559692383
Validation loss: 2.434210854191934

Epoch: 6| Step: 11
Training loss: 2.709995746612549
Validation loss: 2.3949642335214922

Epoch: 6| Step: 12
Training loss: 1.9912811517715454
Validation loss: 2.359618620205951

Epoch: 6| Step: 13
Training loss: 2.628567695617676
Validation loss: 2.2789757354285127

Epoch: 65| Step: 0
Training loss: 1.2920401096343994
Validation loss: 2.2471582248646724

Epoch: 6| Step: 1
Training loss: 2.80838942527771
Validation loss: 2.238011719078146

Epoch: 6| Step: 2
Training loss: 3.058962345123291
Validation loss: 2.2391438971283617

Epoch: 6| Step: 3
Training loss: 2.6857922077178955
Validation loss: 2.2336062205735074

Epoch: 6| Step: 4
Training loss: 2.5749974250793457
Validation loss: 2.2230632869146203

Epoch: 6| Step: 5
Training loss: 2.5525588989257812
Validation loss: 2.2241547966516144

Epoch: 6| Step: 6
Training loss: 3.0657005310058594
Validation loss: 2.2308125585638066

Epoch: 6| Step: 7
Training loss: 2.4948954582214355
Validation loss: 2.2201954703177176

Epoch: 6| Step: 8
Training loss: 1.7617661952972412
Validation loss: 2.2305836011004705

Epoch: 6| Step: 9
Training loss: 2.7796692848205566
Validation loss: 2.2128418337914253

Epoch: 6| Step: 10
Training loss: 2.5580828189849854
Validation loss: 2.2032793080934914

Epoch: 6| Step: 11
Training loss: 2.371605157852173
Validation loss: 2.187194647327546

Epoch: 6| Step: 12
Training loss: 3.0089564323425293
Validation loss: 2.1711105941444315

Epoch: 6| Step: 13
Training loss: 2.9145498275756836
Validation loss: 2.1731287561437136

Epoch: 66| Step: 0
Training loss: 2.3078436851501465
Validation loss: 2.172575291766915

Epoch: 6| Step: 1
Training loss: 2.3826537132263184
Validation loss: 2.1981140387955533

Epoch: 6| Step: 2
Training loss: 2.845974922180176
Validation loss: 2.2249881041947233

Epoch: 6| Step: 3
Training loss: 2.6051502227783203
Validation loss: 2.229398130088724

Epoch: 6| Step: 4
Training loss: 2.283613681793213
Validation loss: 2.212069919032435

Epoch: 6| Step: 5
Training loss: 2.5616960525512695
Validation loss: 2.2018413184791483

Epoch: 6| Step: 6
Training loss: 1.9855602979660034
Validation loss: 2.177644516832085

Epoch: 6| Step: 7
Training loss: 2.9800705909729004
Validation loss: 2.1643825923242876

Epoch: 6| Step: 8
Training loss: 2.936556339263916
Validation loss: 2.169210457032727

Epoch: 6| Step: 9
Training loss: 2.462899923324585
Validation loss: 2.171129334357477

Epoch: 6| Step: 10
Training loss: 2.1161389350891113
Validation loss: 2.1687246830232683

Epoch: 6| Step: 11
Training loss: 1.5840598344802856
Validation loss: 2.1768631806937595

Epoch: 6| Step: 12
Training loss: 3.242469072341919
Validation loss: 2.182554106558523

Epoch: 6| Step: 13
Training loss: 3.042102336883545
Validation loss: 2.1839574934333883

Epoch: 67| Step: 0
Training loss: 2.9367125034332275
Validation loss: 2.1737113665508967

Epoch: 6| Step: 1
Training loss: 2.7548937797546387
Validation loss: 2.165357203893764

Epoch: 6| Step: 2
Training loss: 1.8989620208740234
Validation loss: 2.165086438578944

Epoch: 6| Step: 3
Training loss: 2.364018678665161
Validation loss: 2.165070855489341

Epoch: 6| Step: 4
Training loss: 2.341069459915161
Validation loss: 2.1662810566604778

Epoch: 6| Step: 5
Training loss: 2.3232674598693848
Validation loss: 2.1696437533183763

Epoch: 6| Step: 6
Training loss: 3.15932559967041
Validation loss: 2.17548692610956

Epoch: 6| Step: 7
Training loss: 2.168830394744873
Validation loss: 2.193958949017268

Epoch: 6| Step: 8
Training loss: 2.344724655151367
Validation loss: 2.1857303470693608

Epoch: 6| Step: 9
Training loss: 2.9414641857147217
Validation loss: 2.1697004995038434

Epoch: 6| Step: 10
Training loss: 3.0749564170837402
Validation loss: 2.1644871593803487

Epoch: 6| Step: 11
Training loss: 2.2334532737731934
Validation loss: 2.1567781663710073

Epoch: 6| Step: 12
Training loss: 2.190659523010254
Validation loss: 2.1564313801386024

Epoch: 6| Step: 13
Training loss: 1.7389674186706543
Validation loss: 2.164190520522415

Epoch: 68| Step: 0
Training loss: 2.1682000160217285
Validation loss: 2.162473593988726

Epoch: 6| Step: 1
Training loss: 2.5075759887695312
Validation loss: 2.1466331712661253

Epoch: 6| Step: 2
Training loss: 1.9165128469467163
Validation loss: 2.1438991151830202

Epoch: 6| Step: 3
Training loss: 2.334810256958008
Validation loss: 2.1440062125523887

Epoch: 6| Step: 4
Training loss: 3.022258758544922
Validation loss: 2.142990036677289

Epoch: 6| Step: 5
Training loss: 2.7571239471435547
Validation loss: 2.1494014006789013

Epoch: 6| Step: 6
Training loss: 2.4348270893096924
Validation loss: 2.1507394749631166

Epoch: 6| Step: 7
Training loss: 2.1333084106445312
Validation loss: 2.1568002470078005

Epoch: 6| Step: 8
Training loss: 3.2772116661071777
Validation loss: 2.1628078683730094

Epoch: 6| Step: 9
Training loss: 2.871654748916626
Validation loss: 2.1561851296373593

Epoch: 6| Step: 10
Training loss: 2.477029323577881
Validation loss: 2.144858432072465

Epoch: 6| Step: 11
Training loss: 1.5950913429260254
Validation loss: 2.1380013137735348

Epoch: 6| Step: 12
Training loss: 2.804965019226074
Validation loss: 2.153408363301267

Epoch: 6| Step: 13
Training loss: 3.039982795715332
Validation loss: 2.1502503400207846

Epoch: 69| Step: 0
Training loss: 3.017829418182373
Validation loss: 2.1561088254374843

Epoch: 6| Step: 1
Training loss: 2.090933322906494
Validation loss: 2.1668514295290877

Epoch: 6| Step: 2
Training loss: 2.5041680335998535
Validation loss: 2.1785241032159455

Epoch: 6| Step: 3
Training loss: 3.1180758476257324
Validation loss: 2.1661028144180134

Epoch: 6| Step: 4
Training loss: 2.9326865673065186
Validation loss: 2.1667174626422185

Epoch: 6| Step: 5
Training loss: 2.252960443496704
Validation loss: 2.163732574832055

Epoch: 6| Step: 6
Training loss: 2.3794853687286377
Validation loss: 2.1582571793627996

Epoch: 6| Step: 7
Training loss: 2.5321738719940186
Validation loss: 2.146864188614712

Epoch: 6| Step: 8
Training loss: 2.0788984298706055
Validation loss: 2.141147918598626

Epoch: 6| Step: 9
Training loss: 2.525928258895874
Validation loss: 2.13807080125296

Epoch: 6| Step: 10
Training loss: 2.746509552001953
Validation loss: 2.1414866780722015

Epoch: 6| Step: 11
Training loss: 2.262937545776367
Validation loss: 2.1390827650664956

Epoch: 6| Step: 12
Training loss: 2.1728265285491943
Validation loss: 2.1442427686465684

Epoch: 6| Step: 13
Training loss: 1.7570723295211792
Validation loss: 2.150661999179471

Epoch: 70| Step: 0
Training loss: 2.9081873893737793
Validation loss: 2.1716364122206167

Epoch: 6| Step: 1
Training loss: 2.868943214416504
Validation loss: 2.1803725727142824

Epoch: 6| Step: 2
Training loss: 3.2274885177612305
Validation loss: 2.1968907028116207

Epoch: 6| Step: 3
Training loss: 2.4759159088134766
Validation loss: 2.1970846396620556

Epoch: 6| Step: 4
Training loss: 2.109753131866455
Validation loss: 2.201473328375047

Epoch: 6| Step: 5
Training loss: 2.7443580627441406
Validation loss: 2.2060405695310203

Epoch: 6| Step: 6
Training loss: 2.486934185028076
Validation loss: 2.195726179307507

Epoch: 6| Step: 7
Training loss: 1.4283835887908936
Validation loss: 2.174976264276812

Epoch: 6| Step: 8
Training loss: 2.7325797080993652
Validation loss: 2.167714706031225

Epoch: 6| Step: 9
Training loss: 2.484649896621704
Validation loss: 2.1652687595736597

Epoch: 6| Step: 10
Training loss: 2.9376559257507324
Validation loss: 2.1807659313242924

Epoch: 6| Step: 11
Training loss: 2.3222999572753906
Validation loss: 2.1793778250294347

Epoch: 6| Step: 12
Training loss: 1.9273930788040161
Validation loss: 2.1874797139116513

Epoch: 6| Step: 13
Training loss: 1.5560662746429443
Validation loss: 2.1844240157834944

Epoch: 71| Step: 0
Training loss: 2.913806438446045
Validation loss: 2.180088658486643

Epoch: 6| Step: 1
Training loss: 2.31439208984375
Validation loss: 2.1856554015990226

Epoch: 6| Step: 2
Training loss: 1.9998395442962646
Validation loss: 2.1943334866595525

Epoch: 6| Step: 3
Training loss: 2.654384136199951
Validation loss: 2.1911303202311196

Epoch: 6| Step: 4
Training loss: 2.560059070587158
Validation loss: 2.1800033635990594

Epoch: 6| Step: 5
Training loss: 2.089750289916992
Validation loss: 2.1658703242578814

Epoch: 6| Step: 6
Training loss: 2.5643668174743652
Validation loss: 2.1586121359179096

Epoch: 6| Step: 7
Training loss: 3.2105765342712402
Validation loss: 2.1603540938387633

Epoch: 6| Step: 8
Training loss: 1.914501428604126
Validation loss: 2.15077777190875

Epoch: 6| Step: 9
Training loss: 2.523869514465332
Validation loss: 2.143741815320907

Epoch: 6| Step: 10
Training loss: 3.23058819770813
Validation loss: 2.136776243486712

Epoch: 6| Step: 11
Training loss: 2.5292091369628906
Validation loss: 2.1348514108247656

Epoch: 6| Step: 12
Training loss: 1.3068443536758423
Validation loss: 2.134077879690355

Epoch: 6| Step: 13
Training loss: 2.5256669521331787
Validation loss: 2.1344736212043354

Epoch: 72| Step: 0
Training loss: 2.4526638984680176
Validation loss: 2.126533608282766

Epoch: 6| Step: 1
Training loss: 2.917975902557373
Validation loss: 2.129275709070185

Epoch: 6| Step: 2
Training loss: 2.772247314453125
Validation loss: 2.122573293665404

Epoch: 6| Step: 3
Training loss: 2.1852362155914307
Validation loss: 2.123723554354842

Epoch: 6| Step: 4
Training loss: 2.14846134185791
Validation loss: 2.1172663806587138

Epoch: 6| Step: 5
Training loss: 1.5730427503585815
Validation loss: 2.1218702664939304

Epoch: 6| Step: 6
Training loss: 2.3548660278320312
Validation loss: 2.130494994501914

Epoch: 6| Step: 7
Training loss: 2.6458933353424072
Validation loss: 2.1257606783220844

Epoch: 6| Step: 8
Training loss: 2.497666835784912
Validation loss: 2.129639123075752

Epoch: 6| Step: 9
Training loss: 2.718977451324463
Validation loss: 2.1296630559429044

Epoch: 6| Step: 10
Training loss: 2.5478157997131348
Validation loss: 2.1310558754910707

Epoch: 6| Step: 11
Training loss: 2.229015588760376
Validation loss: 2.139405858132147

Epoch: 6| Step: 12
Training loss: 2.8211450576782227
Validation loss: 2.150458506358567

Epoch: 6| Step: 13
Training loss: 2.3645732402801514
Validation loss: 2.160744972126458

Epoch: 73| Step: 0
Training loss: 2.836458206176758
Validation loss: 2.1571147493136826

Epoch: 6| Step: 1
Training loss: 3.1181480884552
Validation loss: 2.168415184943907

Epoch: 6| Step: 2
Training loss: 1.288918375968933
Validation loss: 2.1710796010109688

Epoch: 6| Step: 3
Training loss: 2.5414280891418457
Validation loss: 2.1742479314086256

Epoch: 6| Step: 4
Training loss: 2.6615428924560547
Validation loss: 2.173858939960439

Epoch: 6| Step: 5
Training loss: 3.1879196166992188
Validation loss: 2.178475897799256

Epoch: 6| Step: 6
Training loss: 2.3098816871643066
Validation loss: 2.1695815850329656

Epoch: 6| Step: 7
Training loss: 2.8284668922424316
Validation loss: 2.148635243856779

Epoch: 6| Step: 8
Training loss: 2.5599634647369385
Validation loss: 2.1296201303441036

Epoch: 6| Step: 9
Training loss: 2.6200625896453857
Validation loss: 2.1189223976545435

Epoch: 6| Step: 10
Training loss: 2.122559070587158
Validation loss: 2.121542628093432

Epoch: 6| Step: 11
Training loss: 1.8783695697784424
Validation loss: 2.134798094790469

Epoch: 6| Step: 12
Training loss: 1.7253577709197998
Validation loss: 2.1481346366226033

Epoch: 6| Step: 13
Training loss: 2.7578227519989014
Validation loss: 2.1759982929434827

Epoch: 74| Step: 0
Training loss: 2.74816632270813
Validation loss: 2.182340483511648

Epoch: 6| Step: 1
Training loss: 2.4712507724761963
Validation loss: 2.18777721928012

Epoch: 6| Step: 2
Training loss: 2.6110334396362305
Validation loss: 2.180837354352397

Epoch: 6| Step: 3
Training loss: 2.550950765609741
Validation loss: 2.1565644882058583

Epoch: 6| Step: 4
Training loss: 2.6919913291931152
Validation loss: 2.1355730179817445

Epoch: 6| Step: 5
Training loss: 2.708420515060425
Validation loss: 2.124172346566313

Epoch: 6| Step: 6
Training loss: 2.7393476963043213
Validation loss: 2.119091142890274

Epoch: 6| Step: 7
Training loss: 2.091933012008667
Validation loss: 2.118720982664375

Epoch: 6| Step: 8
Training loss: 2.1094374656677246
Validation loss: 2.124491112206572

Epoch: 6| Step: 9
Training loss: 2.583961009979248
Validation loss: 2.127838048883664

Epoch: 6| Step: 10
Training loss: 2.4905481338500977
Validation loss: 2.1555967125841367

Epoch: 6| Step: 11
Training loss: 1.8981709480285645
Validation loss: 2.1706718398678686

Epoch: 6| Step: 12
Training loss: 1.9756698608398438
Validation loss: 2.1756414777489117

Epoch: 6| Step: 13
Training loss: 2.6457223892211914
Validation loss: 2.16667277197684

Epoch: 75| Step: 0
Training loss: 1.8314828872680664
Validation loss: 2.1640327874050347

Epoch: 6| Step: 1
Training loss: 2.6326074600219727
Validation loss: 2.178563379472302

Epoch: 6| Step: 2
Training loss: 1.8649930953979492
Validation loss: 2.201499613382483

Epoch: 6| Step: 3
Training loss: 2.7505722045898438
Validation loss: 2.2039081563231764

Epoch: 6| Step: 4
Training loss: 2.5011982917785645
Validation loss: 2.1662063675542034

Epoch: 6| Step: 5
Training loss: 2.519651412963867
Validation loss: 2.1446950102365143

Epoch: 6| Step: 6
Training loss: 2.6729769706726074
Validation loss: 2.1317099166172806

Epoch: 6| Step: 7
Training loss: 2.3247857093811035
Validation loss: 2.1145276715678554

Epoch: 6| Step: 8
Training loss: 2.8454840183258057
Validation loss: 2.1198464093669767

Epoch: 6| Step: 9
Training loss: 2.4791760444641113
Validation loss: 2.110532881111227

Epoch: 6| Step: 10
Training loss: 2.16251802444458
Validation loss: 2.1035645033723567

Epoch: 6| Step: 11
Training loss: 2.418245315551758
Validation loss: 2.1026878331297185

Epoch: 6| Step: 12
Training loss: 3.01291561126709
Validation loss: 2.11349985676427

Epoch: 6| Step: 13
Training loss: 2.083714485168457
Validation loss: 2.120585472353043

Epoch: 76| Step: 0
Training loss: 2.1753687858581543
Validation loss: 2.1358294128089823

Epoch: 6| Step: 1
Training loss: 2.733752965927124
Validation loss: 2.1574043612326346

Epoch: 6| Step: 2
Training loss: 2.206861972808838
Validation loss: 2.1695901886109383

Epoch: 6| Step: 3
Training loss: 2.442106246948242
Validation loss: 2.1856021829830703

Epoch: 6| Step: 4
Training loss: 2.762218952178955
Validation loss: 2.1955165465672812

Epoch: 6| Step: 5
Training loss: 2.468817710876465
Validation loss: 2.1533484356377715

Epoch: 6| Step: 6
Training loss: 2.885625123977661
Validation loss: 2.133109220894434

Epoch: 6| Step: 7
Training loss: 1.7793469429016113
Validation loss: 2.1266754301645423

Epoch: 6| Step: 8
Training loss: 2.0772933959960938
Validation loss: 2.113520250525526

Epoch: 6| Step: 9
Training loss: 2.5815157890319824
Validation loss: 2.0968690303064164

Epoch: 6| Step: 10
Training loss: 2.2695531845092773
Validation loss: 2.099553938834898

Epoch: 6| Step: 11
Training loss: 2.571711540222168
Validation loss: 2.1075692048636814

Epoch: 6| Step: 12
Training loss: 2.503756046295166
Validation loss: 2.1015670043165966

Epoch: 6| Step: 13
Training loss: 2.4177043437957764
Validation loss: 2.0989085499958327

Epoch: 77| Step: 0
Training loss: 2.4209978580474854
Validation loss: 2.1015384466417375

Epoch: 6| Step: 1
Training loss: 2.412202835083008
Validation loss: 2.094808240090647

Epoch: 6| Step: 2
Training loss: 2.355340003967285
Validation loss: 2.0912110446601786

Epoch: 6| Step: 3
Training loss: 2.552978515625
Validation loss: 2.0943979909343104

Epoch: 6| Step: 4
Training loss: 2.544717788696289
Validation loss: 2.09049085135101

Epoch: 6| Step: 5
Training loss: 2.9726884365081787
Validation loss: 2.0970043136227514

Epoch: 6| Step: 6
Training loss: 2.085725784301758
Validation loss: 2.095044920521398

Epoch: 6| Step: 7
Training loss: 2.6892476081848145
Validation loss: 2.0889626818318523

Epoch: 6| Step: 8
Training loss: 2.139902114868164
Validation loss: 2.0931585552871868

Epoch: 6| Step: 9
Training loss: 2.5345304012298584
Validation loss: 2.096025841210478

Epoch: 6| Step: 10
Training loss: 2.6883327960968018
Validation loss: 2.1051411795359787

Epoch: 6| Step: 11
Training loss: 2.7370376586914062
Validation loss: 2.0989251905871975

Epoch: 6| Step: 12
Training loss: 2.0963034629821777
Validation loss: 2.098871736116307

Epoch: 6| Step: 13
Training loss: 1.5593318939208984
Validation loss: 2.1185902690374725

Epoch: 78| Step: 0
Training loss: 2.7926478385925293
Validation loss: 2.139289315028857

Epoch: 6| Step: 1
Training loss: 3.26309871673584
Validation loss: 2.175162030804542

Epoch: 6| Step: 2
Training loss: 2.3610007762908936
Validation loss: 2.204695186307353

Epoch: 6| Step: 3
Training loss: 2.2194395065307617
Validation loss: 2.2100945185589533

Epoch: 6| Step: 4
Training loss: 2.688232898712158
Validation loss: 2.175934196800314

Epoch: 6| Step: 5
Training loss: 1.9157524108886719
Validation loss: 2.157075928103539

Epoch: 6| Step: 6
Training loss: 3.1516168117523193
Validation loss: 2.1467422900661344

Epoch: 6| Step: 7
Training loss: 2.1588528156280518
Validation loss: 2.101838804060413

Epoch: 6| Step: 8
Training loss: 1.5077629089355469
Validation loss: 2.0940203884596467

Epoch: 6| Step: 9
Training loss: 2.9761173725128174
Validation loss: 2.0751314881027385

Epoch: 6| Step: 10
Training loss: 2.401074171066284
Validation loss: 2.087396588376773

Epoch: 6| Step: 11
Training loss: 2.3484411239624023
Validation loss: 2.081092806272609

Epoch: 6| Step: 12
Training loss: 2.031761884689331
Validation loss: 2.087405567528099

Epoch: 6| Step: 13
Training loss: 2.2753236293792725
Validation loss: 2.0843446844367572

Epoch: 79| Step: 0
Training loss: 2.0277767181396484
Validation loss: 2.088511179852229

Epoch: 6| Step: 1
Training loss: 2.4545845985412598
Validation loss: 2.0863633207095567

Epoch: 6| Step: 2
Training loss: 1.5439810752868652
Validation loss: 2.09026139525957

Epoch: 6| Step: 3
Training loss: 2.769754409790039
Validation loss: 2.088532140178065

Epoch: 6| Step: 4
Training loss: 2.513820171356201
Validation loss: 2.097257275735178

Epoch: 6| Step: 5
Training loss: 2.812375068664551
Validation loss: 2.106746409528999

Epoch: 6| Step: 6
Training loss: 2.4680540561676025
Validation loss: 2.125267428736533

Epoch: 6| Step: 7
Training loss: 2.868962526321411
Validation loss: 2.1478317809361283

Epoch: 6| Step: 8
Training loss: 2.312117576599121
Validation loss: 2.1490922602274085

Epoch: 6| Step: 9
Training loss: 1.8851773738861084
Validation loss: 2.1366629164705992

Epoch: 6| Step: 10
Training loss: 2.187683582305908
Validation loss: 2.157772705119143

Epoch: 6| Step: 11
Training loss: 2.3821468353271484
Validation loss: 2.1818058401025753

Epoch: 6| Step: 12
Training loss: 2.9785637855529785
Validation loss: 2.1562154959606867

Epoch: 6| Step: 13
Training loss: 2.600705146789551
Validation loss: 2.134231198218561

Epoch: 80| Step: 0
Training loss: 2.150322914123535
Validation loss: 2.1253494370368218

Epoch: 6| Step: 1
Training loss: 3.0500824451446533
Validation loss: 2.1204948015110467

Epoch: 6| Step: 2
Training loss: 2.2430427074432373
Validation loss: 2.1106832578618038

Epoch: 6| Step: 3
Training loss: 1.7868229150772095
Validation loss: 2.1076893473184235

Epoch: 6| Step: 4
Training loss: 2.4665751457214355
Validation loss: 2.10446415152601

Epoch: 6| Step: 5
Training loss: 2.667245864868164
Validation loss: 2.09369477405343

Epoch: 6| Step: 6
Training loss: 2.302912712097168
Validation loss: 2.1008137861887612

Epoch: 6| Step: 7
Training loss: 2.83709716796875
Validation loss: 2.098892065786546

Epoch: 6| Step: 8
Training loss: 2.94291353225708
Validation loss: 2.0997285560895036

Epoch: 6| Step: 9
Training loss: 2.7675435543060303
Validation loss: 2.1220497085202124

Epoch: 6| Step: 10
Training loss: 2.585113048553467
Validation loss: 2.137812570859027

Epoch: 6| Step: 11
Training loss: 2.2816779613494873
Validation loss: 2.1417296342952277

Epoch: 6| Step: 12
Training loss: 1.619960069656372
Validation loss: 2.175187997920539

Epoch: 6| Step: 13
Training loss: 1.5916588306427002
Validation loss: 2.146714384837817

Epoch: 81| Step: 0
Training loss: 2.6316652297973633
Validation loss: 2.136549791982097

Epoch: 6| Step: 1
Training loss: 2.6946959495544434
Validation loss: 2.08798740243399

Epoch: 6| Step: 2
Training loss: 2.971067428588867
Validation loss: 2.0766562851526404

Epoch: 6| Step: 3
Training loss: 1.9530351161956787
Validation loss: 2.0792238327764694

Epoch: 6| Step: 4
Training loss: 3.2645299434661865
Validation loss: 2.072131141539543

Epoch: 6| Step: 5
Training loss: 2.4413704872131348
Validation loss: 2.079972005659534

Epoch: 6| Step: 6
Training loss: 2.0344629287719727
Validation loss: 2.073164310506595

Epoch: 6| Step: 7
Training loss: 2.391089916229248
Validation loss: 2.0720792342257757

Epoch: 6| Step: 8
Training loss: 1.6409673690795898
Validation loss: 2.072817171773603

Epoch: 6| Step: 9
Training loss: 2.2904648780822754
Validation loss: 2.0857524948735393

Epoch: 6| Step: 10
Training loss: 2.643949508666992
Validation loss: 2.092797533158333

Epoch: 6| Step: 11
Training loss: 1.77345609664917
Validation loss: 2.1236867468844176

Epoch: 6| Step: 12
Training loss: 3.0074288845062256
Validation loss: 2.142124142698062

Epoch: 6| Step: 13
Training loss: 1.94240403175354
Validation loss: 2.121545873662477

Epoch: 82| Step: 0
Training loss: 3.4456071853637695
Validation loss: 2.110769074450257

Epoch: 6| Step: 1
Training loss: 2.3055477142333984
Validation loss: 2.094746164096299

Epoch: 6| Step: 2
Training loss: 2.2714920043945312
Validation loss: 2.083328447034282

Epoch: 6| Step: 3
Training loss: 2.8739616870880127
Validation loss: 2.0800158541689635

Epoch: 6| Step: 4
Training loss: 2.4672656059265137
Validation loss: 2.0800468690933718

Epoch: 6| Step: 5
Training loss: 2.1884467601776123
Validation loss: 2.080097767614549

Epoch: 6| Step: 6
Training loss: 2.285160779953003
Validation loss: 2.087674411394263

Epoch: 6| Step: 7
Training loss: 1.265080451965332
Validation loss: 2.0901823248914493

Epoch: 6| Step: 8
Training loss: 2.0285911560058594
Validation loss: 2.0983861530980756

Epoch: 6| Step: 9
Training loss: 2.545036792755127
Validation loss: 2.119550694701492

Epoch: 6| Step: 10
Training loss: 2.972320556640625
Validation loss: 2.160854918982393

Epoch: 6| Step: 11
Training loss: 1.5314528942108154
Validation loss: 2.157100239107686

Epoch: 6| Step: 12
Training loss: 2.5502912998199463
Validation loss: 2.1938993546270553

Epoch: 6| Step: 13
Training loss: 3.2002956867218018
Validation loss: 2.1842880197750625

Epoch: 83| Step: 0
Training loss: 2.1309773921966553
Validation loss: 2.1823692680687032

Epoch: 6| Step: 1
Training loss: 2.186296224594116
Validation loss: 2.1854243791231545

Epoch: 6| Step: 2
Training loss: 2.1073570251464844
Validation loss: 2.1642934917121806

Epoch: 6| Step: 3
Training loss: 2.619145393371582
Validation loss: 2.148976631062005

Epoch: 6| Step: 4
Training loss: 3.109226703643799
Validation loss: 2.127548366464594

Epoch: 6| Step: 5
Training loss: 2.8887434005737305
Validation loss: 2.1041323702822448

Epoch: 6| Step: 6
Training loss: 2.5012502670288086
Validation loss: 2.0941604234839

Epoch: 6| Step: 7
Training loss: 2.308840751647949
Validation loss: 2.087750739948724

Epoch: 6| Step: 8
Training loss: 2.510305881500244
Validation loss: 2.089177834090366

Epoch: 6| Step: 9
Training loss: 2.3951151371002197
Validation loss: 2.0754724369254163

Epoch: 6| Step: 10
Training loss: 2.0315074920654297
Validation loss: 2.098374253960066

Epoch: 6| Step: 11
Training loss: 2.2331314086914062
Validation loss: 2.103943391512799

Epoch: 6| Step: 12
Training loss: 2.152538299560547
Validation loss: 2.101349994700442

Epoch: 6| Step: 13
Training loss: 2.155061960220337
Validation loss: 2.116232215717275

Epoch: 84| Step: 0
Training loss: 1.914393663406372
Validation loss: 2.1054534091744372

Epoch: 6| Step: 1
Training loss: 2.2763750553131104
Validation loss: 2.0971199671427407

Epoch: 6| Step: 2
Training loss: 2.5973551273345947
Validation loss: 2.092739624361838

Epoch: 6| Step: 3
Training loss: 2.9673657417297363
Validation loss: 2.0977073587397093

Epoch: 6| Step: 4
Training loss: 2.7397541999816895
Validation loss: 2.081700026348073

Epoch: 6| Step: 5
Training loss: 2.5437583923339844
Validation loss: 2.071495256116313

Epoch: 6| Step: 6
Training loss: 1.705769419670105
Validation loss: 2.061804363804479

Epoch: 6| Step: 7
Training loss: 2.529036521911621
Validation loss: 2.0645347436269126

Epoch: 6| Step: 8
Training loss: 1.8948631286621094
Validation loss: 2.0516552732836817

Epoch: 6| Step: 9
Training loss: 2.3922088146209717
Validation loss: 2.0623369986011135

Epoch: 6| Step: 10
Training loss: 2.5373096466064453
Validation loss: 2.076661871325585

Epoch: 6| Step: 11
Training loss: 2.456963062286377
Validation loss: 2.0738483218736548

Epoch: 6| Step: 12
Training loss: 2.410477876663208
Validation loss: 2.0795845254775016

Epoch: 6| Step: 13
Training loss: 2.4022040367126465
Validation loss: 2.0862544890372985

Epoch: 85| Step: 0
Training loss: 2.5666005611419678
Validation loss: 2.095490663282333

Epoch: 6| Step: 1
Training loss: 2.310100793838501
Validation loss: 2.112234038691367

Epoch: 6| Step: 2
Training loss: 1.8573200702667236
Validation loss: 2.0987457895791657

Epoch: 6| Step: 3
Training loss: 2.3041229248046875
Validation loss: 2.0808086215808825

Epoch: 6| Step: 4
Training loss: 2.7971134185791016
Validation loss: 2.078930111341579

Epoch: 6| Step: 5
Training loss: 2.0977749824523926
Validation loss: 2.0742214392590266

Epoch: 6| Step: 6
Training loss: 1.884547472000122
Validation loss: 2.059103940122871

Epoch: 6| Step: 7
Training loss: 2.5670793056488037
Validation loss: 2.062603945373207

Epoch: 6| Step: 8
Training loss: 2.520885467529297
Validation loss: 2.076831167744052

Epoch: 6| Step: 9
Training loss: 3.2470827102661133
Validation loss: 2.0846229868550457

Epoch: 6| Step: 10
Training loss: 2.033421277999878
Validation loss: 2.1101434717896166

Epoch: 6| Step: 11
Training loss: 2.5923924446105957
Validation loss: 2.1561788897360525

Epoch: 6| Step: 12
Training loss: 2.026113748550415
Validation loss: 2.144525385672046

Epoch: 6| Step: 13
Training loss: 2.7837300300598145
Validation loss: 2.1232813840271323

Epoch: 86| Step: 0
Training loss: 1.5475404262542725
Validation loss: 2.1134595973517305

Epoch: 6| Step: 1
Training loss: 2.5950396060943604
Validation loss: 2.1143718047808577

Epoch: 6| Step: 2
Training loss: 2.1065855026245117
Validation loss: 2.1119536994605936

Epoch: 6| Step: 3
Training loss: 3.478287696838379
Validation loss: 2.0996593685560327

Epoch: 6| Step: 4
Training loss: 2.3266031742095947
Validation loss: 2.0883046375807894

Epoch: 6| Step: 5
Training loss: 2.7547214031219482
Validation loss: 2.065750264352368

Epoch: 6| Step: 6
Training loss: 2.4186649322509766
Validation loss: 2.051882017043329

Epoch: 6| Step: 7
Training loss: 2.1157846450805664
Validation loss: 2.044870145859257

Epoch: 6| Step: 8
Training loss: 2.577401638031006
Validation loss: 2.046831105345039

Epoch: 6| Step: 9
Training loss: 2.1535868644714355
Validation loss: 2.0530613083993234

Epoch: 6| Step: 10
Training loss: 2.0576491355895996
Validation loss: 2.0692925940277758

Epoch: 6| Step: 11
Training loss: 2.3147366046905518
Validation loss: 2.100658965367143

Epoch: 6| Step: 12
Training loss: 2.6652426719665527
Validation loss: 2.128170123664282

Epoch: 6| Step: 13
Training loss: 2.008545398712158
Validation loss: 2.2005304649312007

Epoch: 87| Step: 0
Training loss: 2.83665132522583
Validation loss: 2.2207356447814615

Epoch: 6| Step: 1
Training loss: 2.4454407691955566
Validation loss: 2.175732248572893

Epoch: 6| Step: 2
Training loss: 2.3121070861816406
Validation loss: 2.142316097854286

Epoch: 6| Step: 3
Training loss: 2.6967697143554688
Validation loss: 2.0986993389744915

Epoch: 6| Step: 4
Training loss: 2.8121161460876465
Validation loss: 2.0625949995492094

Epoch: 6| Step: 5
Training loss: 1.7106908559799194
Validation loss: 2.0535854267817673

Epoch: 6| Step: 6
Training loss: 2.806931734085083
Validation loss: 2.0453441040490263

Epoch: 6| Step: 7
Training loss: 2.469912052154541
Validation loss: 2.0327531650502193

Epoch: 6| Step: 8
Training loss: 2.327741861343384
Validation loss: 2.021298821254443

Epoch: 6| Step: 9
Training loss: 2.581721067428589
Validation loss: 2.0420449395333566

Epoch: 6| Step: 10
Training loss: 1.440169334411621
Validation loss: 2.06296105282281

Epoch: 6| Step: 11
Training loss: 2.544351577758789
Validation loss: 2.1048094354650027

Epoch: 6| Step: 12
Training loss: 2.1594455242156982
Validation loss: 2.1333498608681465

Epoch: 6| Step: 13
Training loss: 2.0770201683044434
Validation loss: 2.1345235404147895

Epoch: 88| Step: 0
Training loss: 2.7184152603149414
Validation loss: 2.154022878216159

Epoch: 6| Step: 1
Training loss: 2.5923047065734863
Validation loss: 2.1253034350692586

Epoch: 6| Step: 2
Training loss: 2.1580824851989746
Validation loss: 2.0890188870891446

Epoch: 6| Step: 3
Training loss: 1.8056144714355469
Validation loss: 2.06316953064293

Epoch: 6| Step: 4
Training loss: 2.196943759918213
Validation loss: 2.0574599953107935

Epoch: 6| Step: 5
Training loss: 3.2011680603027344
Validation loss: 2.0471060327304307

Epoch: 6| Step: 6
Training loss: 1.9530282020568848
Validation loss: 2.0373425458067205

Epoch: 6| Step: 7
Training loss: 2.7848596572875977
Validation loss: 2.036067937010078

Epoch: 6| Step: 8
Training loss: 2.824129819869995
Validation loss: 2.0408707869950162

Epoch: 6| Step: 9
Training loss: 2.446774959564209
Validation loss: 2.039460587245162

Epoch: 6| Step: 10
Training loss: 1.9131479263305664
Validation loss: 2.0379154477068173

Epoch: 6| Step: 11
Training loss: 2.41265606880188
Validation loss: 2.0506523732216126

Epoch: 6| Step: 12
Training loss: 2.138763904571533
Validation loss: 2.0614830742600145

Epoch: 6| Step: 13
Training loss: 1.7204023599624634
Validation loss: 2.080777613065576

Epoch: 89| Step: 0
Training loss: 2.227853775024414
Validation loss: 2.120725986778095

Epoch: 6| Step: 1
Training loss: 2.0772459506988525
Validation loss: 2.1854576526149625

Epoch: 6| Step: 2
Training loss: 2.7628254890441895
Validation loss: 2.1780620800551547

Epoch: 6| Step: 3
Training loss: 2.4249000549316406
Validation loss: 2.147970473894509

Epoch: 6| Step: 4
Training loss: 2.573030948638916
Validation loss: 2.1014727366867887

Epoch: 6| Step: 5
Training loss: 1.9724512100219727
Validation loss: 2.081706718731952

Epoch: 6| Step: 6
Training loss: 2.4523537158966064
Validation loss: 2.0721520723835116

Epoch: 6| Step: 7
Training loss: 1.729355812072754
Validation loss: 2.0728561596203874

Epoch: 6| Step: 8
Training loss: 2.726747512817383
Validation loss: 2.0795624743225756

Epoch: 6| Step: 9
Training loss: 2.1749777793884277
Validation loss: 2.0772962313826366

Epoch: 6| Step: 10
Training loss: 3.174208879470825
Validation loss: 2.068103458291741

Epoch: 6| Step: 11
Training loss: 2.5081701278686523
Validation loss: 2.0730094281576013

Epoch: 6| Step: 12
Training loss: 2.11179256439209
Validation loss: 2.056797432643111

Epoch: 6| Step: 13
Training loss: 2.083062171936035
Validation loss: 2.0690767559953915

Epoch: 90| Step: 0
Training loss: 2.605536699295044
Validation loss: 2.0610813402360484

Epoch: 6| Step: 1
Training loss: 1.9337012767791748
Validation loss: 2.0698200656521704

Epoch: 6| Step: 2
Training loss: 2.1034951210021973
Validation loss: 2.0781752653019403

Epoch: 6| Step: 3
Training loss: 2.6172854900360107
Validation loss: 2.0619609150835263

Epoch: 6| Step: 4
Training loss: 2.75435471534729
Validation loss: 2.079307756116313

Epoch: 6| Step: 5
Training loss: 2.2182507514953613
Validation loss: 2.1015264859763523

Epoch: 6| Step: 6
Training loss: 2.7593066692352295
Validation loss: 2.1304689171493694

Epoch: 6| Step: 7
Training loss: 2.9860422611236572
Validation loss: 2.1432221064003567

Epoch: 6| Step: 8
Training loss: 2.2224764823913574
Validation loss: 2.1254080905709216

Epoch: 6| Step: 9
Training loss: 1.9420068264007568
Validation loss: 2.090500843140387

Epoch: 6| Step: 10
Training loss: 2.296173095703125
Validation loss: 2.062865731536701

Epoch: 6| Step: 11
Training loss: 2.3732283115386963
Validation loss: 2.0224200833228325

Epoch: 6| Step: 12
Training loss: 2.065624237060547
Validation loss: 2.0302413971193376

Epoch: 6| Step: 13
Training loss: 2.296976327896118
Validation loss: 2.0391138958674606

Epoch: 91| Step: 0
Training loss: 1.9668629169464111
Validation loss: 2.0459436985754196

Epoch: 6| Step: 1
Training loss: 2.318317413330078
Validation loss: 2.039888257621437

Epoch: 6| Step: 2
Training loss: 2.941497325897217
Validation loss: 2.041930781897678

Epoch: 6| Step: 3
Training loss: 2.9224934577941895
Validation loss: 2.049064555475789

Epoch: 6| Step: 4
Training loss: 2.56844162940979
Validation loss: 2.0547374320286576

Epoch: 6| Step: 5
Training loss: 2.5024003982543945
Validation loss: 2.0621964162395847

Epoch: 6| Step: 6
Training loss: 2.5785441398620605
Validation loss: 2.062297796690336

Epoch: 6| Step: 7
Training loss: 2.6346428394317627
Validation loss: 2.0986051533811834

Epoch: 6| Step: 8
Training loss: 2.579789876937866
Validation loss: 2.0978929496580556

Epoch: 6| Step: 9
Training loss: 2.522906541824341
Validation loss: 2.0770236023010744

Epoch: 6| Step: 10
Training loss: 2.2212743759155273
Validation loss: 2.0755188644573255

Epoch: 6| Step: 11
Training loss: 1.417588233947754
Validation loss: 2.0499446827878236

Epoch: 6| Step: 12
Training loss: 1.9505616426467896
Validation loss: 2.073201064140566

Epoch: 6| Step: 13
Training loss: 1.1137202978134155
Validation loss: 2.0560103642043246

Epoch: 92| Step: 0
Training loss: 1.8862972259521484
Validation loss: 2.0583002310927196

Epoch: 6| Step: 1
Training loss: 2.134243965148926
Validation loss: 2.058486436002998

Epoch: 6| Step: 2
Training loss: 2.487968921661377
Validation loss: 2.0378981021142777

Epoch: 6| Step: 3
Training loss: 2.848005533218384
Validation loss: 2.032108373539422

Epoch: 6| Step: 4
Training loss: 2.493406295776367
Validation loss: 2.031168326254814

Epoch: 6| Step: 5
Training loss: 1.9340256452560425
Validation loss: 2.037563121446999

Epoch: 6| Step: 6
Training loss: 2.0852460861206055
Validation loss: 2.04201013811173

Epoch: 6| Step: 7
Training loss: 3.0992584228515625
Validation loss: 2.040403351988844

Epoch: 6| Step: 8
Training loss: 2.3144125938415527
Validation loss: 2.0352953172499135

Epoch: 6| Step: 9
Training loss: 2.195052146911621
Validation loss: 2.03953569422486

Epoch: 6| Step: 10
Training loss: 2.2285265922546387
Validation loss: 2.050844453996228

Epoch: 6| Step: 11
Training loss: 2.3008010387420654
Validation loss: 2.0889440223734868

Epoch: 6| Step: 12
Training loss: 2.589355945587158
Validation loss: 2.1169359017443914

Epoch: 6| Step: 13
Training loss: 2.6154592037200928
Validation loss: 2.130784660257319

Epoch: 93| Step: 0
Training loss: 2.6068027019500732
Validation loss: 2.1202396103130874

Epoch: 6| Step: 1
Training loss: 2.816987991333008
Validation loss: 2.092230587877253

Epoch: 6| Step: 2
Training loss: 2.4696364402770996
Validation loss: 2.0653778404317875

Epoch: 6| Step: 3
Training loss: 2.2971529960632324
Validation loss: 2.0787476211465816

Epoch: 6| Step: 4
Training loss: 1.5425866842269897
Validation loss: 2.0654211813403713

Epoch: 6| Step: 5
Training loss: 3.1201305389404297
Validation loss: 2.0697445074717202

Epoch: 6| Step: 6
Training loss: 2.5532634258270264
Validation loss: 2.0601616713308517

Epoch: 6| Step: 7
Training loss: 2.2739765644073486
Validation loss: 2.047766896986192

Epoch: 6| Step: 8
Training loss: 1.973997950553894
Validation loss: 2.0511516101898684

Epoch: 6| Step: 9
Training loss: 2.524996519088745
Validation loss: 2.0642716833340224

Epoch: 6| Step: 10
Training loss: 2.6092042922973633
Validation loss: 2.068810280933175

Epoch: 6| Step: 11
Training loss: 1.6784372329711914
Validation loss: 2.064027246608529

Epoch: 6| Step: 12
Training loss: 2.0058350563049316
Validation loss: 2.0770886675004037

Epoch: 6| Step: 13
Training loss: 2.2853612899780273
Validation loss: 2.0817346521603164

Epoch: 94| Step: 0
Training loss: 2.4163014888763428
Validation loss: 2.0920150856817923

Epoch: 6| Step: 1
Training loss: 2.309209108352661
Validation loss: 2.0904615053566555

Epoch: 6| Step: 2
Training loss: 2.630615234375
Validation loss: 2.0920979592107956

Epoch: 6| Step: 3
Training loss: 1.7056128978729248
Validation loss: 2.0770400313920874

Epoch: 6| Step: 4
Training loss: 2.2992749214172363
Validation loss: 2.0641976838470786

Epoch: 6| Step: 5
Training loss: 2.639559745788574
Validation loss: 2.051237230659813

Epoch: 6| Step: 6
Training loss: 2.436100959777832
Validation loss: 2.0291445511643604

Epoch: 6| Step: 7
Training loss: 3.040215015411377
Validation loss: 2.021403992047874

Epoch: 6| Step: 8
Training loss: 2.234163284301758
Validation loss: 2.020946402703562

Epoch: 6| Step: 9
Training loss: 1.5956799983978271
Validation loss: 2.0136595208157777

Epoch: 6| Step: 10
Training loss: 2.570827007293701
Validation loss: 2.0068122186968402

Epoch: 6| Step: 11
Training loss: 1.973996639251709
Validation loss: 2.0119661079939974

Epoch: 6| Step: 12
Training loss: 2.380354881286621
Validation loss: 2.0156978612305014

Epoch: 6| Step: 13
Training loss: 2.207031011581421
Validation loss: 2.019177234301003

Epoch: 95| Step: 0
Training loss: 2.6828155517578125
Validation loss: 2.0220331043325444

Epoch: 6| Step: 1
Training loss: 1.586287260055542
Validation loss: 2.0265434890665035

Epoch: 6| Step: 2
Training loss: 1.9707772731781006
Validation loss: 2.067806496415087

Epoch: 6| Step: 3
Training loss: 2.650075912475586
Validation loss: 2.0593335602873113

Epoch: 6| Step: 4
Training loss: 2.865501880645752
Validation loss: 2.0562042805456344

Epoch: 6| Step: 5
Training loss: 2.108187437057495
Validation loss: 2.0532175635778778

Epoch: 6| Step: 6
Training loss: 2.4501402378082275
Validation loss: 2.05301300684611

Epoch: 6| Step: 7
Training loss: 2.3002233505249023
Validation loss: 2.0711665896959204

Epoch: 6| Step: 8
Training loss: 2.6634418964385986
Validation loss: 2.039408326148987

Epoch: 6| Step: 9
Training loss: 2.2895383834838867
Validation loss: 2.027336338514923

Epoch: 6| Step: 10
Training loss: 2.8702681064605713
Validation loss: 2.0043630843521445

Epoch: 6| Step: 11
Training loss: 1.8380712270736694
Validation loss: 2.0147518368177515

Epoch: 6| Step: 12
Training loss: 2.392803192138672
Validation loss: 2.014456332370799

Epoch: 6| Step: 13
Training loss: 1.2051339149475098
Validation loss: 2.021661812259305

Epoch: 96| Step: 0
Training loss: 2.288879156112671
Validation loss: 2.0247368684379

Epoch: 6| Step: 1
Training loss: 1.7156875133514404
Validation loss: 2.0334130230770318

Epoch: 6| Step: 2
Training loss: 2.12326717376709
Validation loss: 2.059090773264567

Epoch: 6| Step: 3
Training loss: 2.5799078941345215
Validation loss: 2.070061409345237

Epoch: 6| Step: 4
Training loss: 2.767066717147827
Validation loss: 2.0667738427398024

Epoch: 6| Step: 5
Training loss: 2.802572250366211
Validation loss: 2.09517744792405

Epoch: 6| Step: 6
Training loss: 1.8512450456619263
Validation loss: 2.081686721053175

Epoch: 6| Step: 7
Training loss: 2.2491724491119385
Validation loss: 2.0614527758731636

Epoch: 6| Step: 8
Training loss: 2.816920518875122
Validation loss: 2.0240532634078816

Epoch: 6| Step: 9
Training loss: 2.711362361907959
Validation loss: 2.0130652048254527

Epoch: 6| Step: 10
Training loss: 2.714535713195801
Validation loss: 2.031428865207139

Epoch: 6| Step: 11
Training loss: 2.3365392684936523
Validation loss: 2.045270430144443

Epoch: 6| Step: 12
Training loss: 2.1886773109436035
Validation loss: 2.076753152314053

Epoch: 6| Step: 13
Training loss: 1.7227656841278076
Validation loss: 2.082498264569108

Epoch: 97| Step: 0
Training loss: 1.9228315353393555
Validation loss: 2.069772885691735

Epoch: 6| Step: 1
Training loss: 2.689892053604126
Validation loss: 2.051188761188138

Epoch: 6| Step: 2
Training loss: 2.4410176277160645
Validation loss: 2.022531194071616

Epoch: 6| Step: 3
Training loss: 2.8482606410980225
Validation loss: 1.9949670632680256

Epoch: 6| Step: 4
Training loss: 2.9351072311401367
Validation loss: 1.997921625773112

Epoch: 6| Step: 5
Training loss: 1.7768975496292114
Validation loss: 2.00224728738108

Epoch: 6| Step: 6
Training loss: 2.1933517456054688
Validation loss: 2.0156810181115263

Epoch: 6| Step: 7
Training loss: 1.804410457611084
Validation loss: 2.014353798281762

Epoch: 6| Step: 8
Training loss: 1.61397123336792
Validation loss: 2.0054439780532674

Epoch: 6| Step: 9
Training loss: 2.5362987518310547
Validation loss: 1.9983018034247941

Epoch: 6| Step: 10
Training loss: 2.653076171875
Validation loss: 2.0190308888753257

Epoch: 6| Step: 11
Training loss: 2.181096076965332
Validation loss: 2.037831493603286

Epoch: 6| Step: 12
Training loss: 2.5223002433776855
Validation loss: 2.0589310187165455

Epoch: 6| Step: 13
Training loss: 2.2815115451812744
Validation loss: 2.0571407169424076

Epoch: 98| Step: 0
Training loss: 1.8063969612121582
Validation loss: 2.0773148049590406

Epoch: 6| Step: 1
Training loss: 3.0403833389282227
Validation loss: 2.060989154282437

Epoch: 6| Step: 2
Training loss: 2.18015718460083
Validation loss: 2.0604096317803986

Epoch: 6| Step: 3
Training loss: 2.622502326965332
Validation loss: 2.0532080255528933

Epoch: 6| Step: 4
Training loss: 2.142665147781372
Validation loss: 2.0435929631674163

Epoch: 6| Step: 5
Training loss: 2.4020378589630127
Validation loss: 2.029148604280205

Epoch: 6| Step: 6
Training loss: 2.288369655609131
Validation loss: 2.022814525071011

Epoch: 6| Step: 7
Training loss: 2.4983181953430176
Validation loss: 2.0124252227044876

Epoch: 6| Step: 8
Training loss: 2.412832498550415
Validation loss: 2.009402302003676

Epoch: 6| Step: 9
Training loss: 2.124483108520508
Validation loss: 2.0071967801740094

Epoch: 6| Step: 10
Training loss: 2.0091309547424316
Validation loss: 2.0026029925192557

Epoch: 6| Step: 11
Training loss: 1.9804942607879639
Validation loss: 1.9984251055666196

Epoch: 6| Step: 12
Training loss: 2.2780284881591797
Validation loss: 2.0162347080887004

Epoch: 6| Step: 13
Training loss: 2.6705739498138428
Validation loss: 2.0203738545858734

Epoch: 99| Step: 0
Training loss: 1.8874645233154297
Validation loss: 2.025655681087125

Epoch: 6| Step: 1
Training loss: 2.28478741645813
Validation loss: 2.016231653510883

Epoch: 6| Step: 2
Training loss: 2.704981803894043
Validation loss: 2.018130088365206

Epoch: 6| Step: 3
Training loss: 2.3221595287323
Validation loss: 2.020958626142112

Epoch: 6| Step: 4
Training loss: 2.1062865257263184
Validation loss: 2.011194754672307

Epoch: 6| Step: 5
Training loss: 1.9440195560455322
Validation loss: 2.0209764254990445

Epoch: 6| Step: 6
Training loss: 1.934201717376709
Validation loss: 2.0202317212217595

Epoch: 6| Step: 7
Training loss: 2.7835731506347656
Validation loss: 2.0104849838441416

Epoch: 6| Step: 8
Training loss: 2.5470995903015137
Validation loss: 1.9958234140949864

Epoch: 6| Step: 9
Training loss: 1.8416497707366943
Validation loss: 1.999136403042783

Epoch: 6| Step: 10
Training loss: 2.1516709327697754
Validation loss: 2.0014561760810112

Epoch: 6| Step: 11
Training loss: 2.416599750518799
Validation loss: 2.0058911256892706

Epoch: 6| Step: 12
Training loss: 2.291832685470581
Validation loss: 2.019074114420081

Epoch: 6| Step: 13
Training loss: 3.069167137145996
Validation loss: 2.008943150120397

Epoch: 100| Step: 0
Training loss: 3.062612295150757
Validation loss: 2.0392677014873875

Epoch: 6| Step: 1
Training loss: 2.4434032440185547
Validation loss: 2.035500849446943

Epoch: 6| Step: 2
Training loss: 2.367248773574829
Validation loss: 2.041670366000104

Epoch: 6| Step: 3
Training loss: 1.4654432535171509
Validation loss: 2.0468020541693575

Epoch: 6| Step: 4
Training loss: 2.374567985534668
Validation loss: 2.062859058380127

Epoch: 6| Step: 5
Training loss: 1.9169483184814453
Validation loss: 2.066921494340384

Epoch: 6| Step: 6
Training loss: 1.7531049251556396
Validation loss: 2.0805163691120763

Epoch: 6| Step: 7
Training loss: 1.9968335628509521
Validation loss: 2.0611536067019225

Epoch: 6| Step: 8
Training loss: 2.3698248863220215
Validation loss: 2.063045317126859

Epoch: 6| Step: 9
Training loss: 2.4019241333007812
Validation loss: 2.049459339469992

Epoch: 6| Step: 10
Training loss: 2.4810426235198975
Validation loss: 2.1034241055929535

Epoch: 6| Step: 11
Training loss: 2.3574368953704834
Validation loss: 2.127498783091063

Epoch: 6| Step: 12
Training loss: 2.250974655151367
Validation loss: 2.1231681236656765

Epoch: 6| Step: 13
Training loss: 3.060727119445801
Validation loss: 2.10829653791202

Epoch: 101| Step: 0
Training loss: 2.690758228302002
Validation loss: 2.1041014040670087

Epoch: 6| Step: 1
Training loss: 2.385307788848877
Validation loss: 2.082918756751604

Epoch: 6| Step: 2
Training loss: 2.3701090812683105
Validation loss: 2.0557098388671875

Epoch: 6| Step: 3
Training loss: 2.2877774238586426
Validation loss: 2.041755901869907

Epoch: 6| Step: 4
Training loss: 2.969837188720703
Validation loss: 2.0126623235723025

Epoch: 6| Step: 5
Training loss: 2.359377861022949
Validation loss: 2.0160433118061354

Epoch: 6| Step: 6
Training loss: 1.6719504594802856
Validation loss: 2.0250325126032673

Epoch: 6| Step: 7
Training loss: 1.9719207286834717
Validation loss: 2.0198168190576697

Epoch: 6| Step: 8
Training loss: 1.7398900985717773
Validation loss: 2.0319926354192916

Epoch: 6| Step: 9
Training loss: 2.466961145401001
Validation loss: 2.0155844970416

Epoch: 6| Step: 10
Training loss: 2.4317893981933594
Validation loss: 1.9991061443923621

Epoch: 6| Step: 11
Training loss: 2.6099350452423096
Validation loss: 1.9940911262266097

Epoch: 6| Step: 12
Training loss: 1.9732415676116943
Validation loss: 2.000738218266477

Epoch: 6| Step: 13
Training loss: 2.1947038173675537
Validation loss: 1.9985042387439358

Epoch: 102| Step: 0
Training loss: 2.5948004722595215
Validation loss: 2.002077338516071

Epoch: 6| Step: 1
Training loss: 1.9651097059249878
Validation loss: 1.9976434874278244

Epoch: 6| Step: 2
Training loss: 2.555800437927246
Validation loss: 2.0039717074363463

Epoch: 6| Step: 3
Training loss: 2.7084624767303467
Validation loss: 2.0068882947326987

Epoch: 6| Step: 4
Training loss: 2.3129258155822754
Validation loss: 2.0038105672405613

Epoch: 6| Step: 5
Training loss: 2.1037139892578125
Validation loss: 2.0033260955605456

Epoch: 6| Step: 6
Training loss: 2.0185627937316895
Validation loss: 2.0004753425557125

Epoch: 6| Step: 7
Training loss: 2.0878093242645264
Validation loss: 2.012447678914634

Epoch: 6| Step: 8
Training loss: 2.39143705368042
Validation loss: 2.016252210063319

Epoch: 6| Step: 9
Training loss: 2.324817419052124
Validation loss: 2.00448840407915

Epoch: 6| Step: 10
Training loss: 2.207197666168213
Validation loss: 1.9980078871532152

Epoch: 6| Step: 11
Training loss: 1.8483473062515259
Validation loss: 1.9991809039987543

Epoch: 6| Step: 12
Training loss: 2.378004550933838
Validation loss: 1.9870946920046242

Epoch: 6| Step: 13
Training loss: 2.583308458328247
Validation loss: 1.9984849691390991

Epoch: 103| Step: 0
Training loss: 2.1653330326080322
Validation loss: 2.006129237913316

Epoch: 6| Step: 1
Training loss: 1.8550009727478027
Validation loss: 1.9973325806279336

Epoch: 6| Step: 2
Training loss: 2.4558792114257812
Validation loss: 1.9924178713111467

Epoch: 6| Step: 3
Training loss: 2.298480987548828
Validation loss: 1.9854013637829853

Epoch: 6| Step: 4
Training loss: 2.1035196781158447
Validation loss: 1.9756285272618777

Epoch: 6| Step: 5
Training loss: 2.2461345195770264
Validation loss: 1.973591161030595

Epoch: 6| Step: 6
Training loss: 3.005389451980591
Validation loss: 1.9782626833966983

Epoch: 6| Step: 7
Training loss: 1.9949606657028198
Validation loss: 1.9767782201049149

Epoch: 6| Step: 8
Training loss: 2.103602170944214
Validation loss: 1.9882629814968313

Epoch: 6| Step: 9
Training loss: 2.0019032955169678
Validation loss: 1.9738683828743555

Epoch: 6| Step: 10
Training loss: 2.7783284187316895
Validation loss: 1.973491120082076

Epoch: 6| Step: 11
Training loss: 2.8373966217041016
Validation loss: 1.9756200928841867

Epoch: 6| Step: 12
Training loss: 1.171797513961792
Validation loss: 1.974532478599138

Epoch: 6| Step: 13
Training loss: 3.2009096145629883
Validation loss: 1.984026962710965

Epoch: 104| Step: 0
Training loss: 1.964694619178772
Validation loss: 1.9927203668061124

Epoch: 6| Step: 1
Training loss: 2.647467613220215
Validation loss: 1.9815777527388705

Epoch: 6| Step: 2
Training loss: 2.268310070037842
Validation loss: 1.9912165762275778

Epoch: 6| Step: 3
Training loss: 2.724608898162842
Validation loss: 1.9849532342726184

Epoch: 6| Step: 4
Training loss: 1.970143437385559
Validation loss: 1.999459905009116

Epoch: 6| Step: 5
Training loss: 2.489556074142456
Validation loss: 2.0047087054098807

Epoch: 6| Step: 6
Training loss: 2.1604971885681152
Validation loss: 2.018252198414136

Epoch: 6| Step: 7
Training loss: 2.4642386436462402
Validation loss: 2.0186943969418927

Epoch: 6| Step: 8
Training loss: 2.469521999359131
Validation loss: 2.0073255877340994

Epoch: 6| Step: 9
Training loss: 2.0348496437072754
Validation loss: 2.0120891550535798

Epoch: 6| Step: 10
Training loss: 1.9858461618423462
Validation loss: 2.0066265649692987

Epoch: 6| Step: 11
Training loss: 1.9442757368087769
Validation loss: 2.032644725614978

Epoch: 6| Step: 12
Training loss: 1.7627052068710327
Validation loss: 2.0136208226603847

Epoch: 6| Step: 13
Training loss: 2.839587688446045
Validation loss: 2.0075841539649555

Epoch: 105| Step: 0
Training loss: 1.6217964887619019
Validation loss: 1.9978512692195114

Epoch: 6| Step: 1
Training loss: 2.9315013885498047
Validation loss: 2.0163939229903685

Epoch: 6| Step: 2
Training loss: 2.3679487705230713
Validation loss: 2.029319595265132

Epoch: 6| Step: 3
Training loss: 1.2832553386688232
Validation loss: 2.0397913981509466

Epoch: 6| Step: 4
Training loss: 2.379040002822876
Validation loss: 2.042403277530465

Epoch: 6| Step: 5
Training loss: 2.9776182174682617
Validation loss: 2.042469452786189

Epoch: 6| Step: 6
Training loss: 2.356379270553589
Validation loss: 2.0353995638508953

Epoch: 6| Step: 7
Training loss: 2.3815484046936035
Validation loss: 2.0224634703769477

Epoch: 6| Step: 8
Training loss: 2.523345470428467
Validation loss: 2.036390250728976

Epoch: 6| Step: 9
Training loss: 1.4124987125396729
Validation loss: 2.0203589021518664

Epoch: 6| Step: 10
Training loss: 2.452754020690918
Validation loss: 2.038459954723235

Epoch: 6| Step: 11
Training loss: 1.954514503479004
Validation loss: 2.0521897526197534

Epoch: 6| Step: 12
Training loss: 1.942090630531311
Validation loss: 2.0354674298276185

Epoch: 6| Step: 13
Training loss: 3.2143099308013916
Validation loss: 2.0379743012048865

Epoch: 106| Step: 0
Training loss: 2.2339611053466797
Validation loss: 2.0185544888178506

Epoch: 6| Step: 1
Training loss: 2.601051092147827
Validation loss: 2.0061589646083053

Epoch: 6| Step: 2
Training loss: 3.080866813659668
Validation loss: 2.00407729353956

Epoch: 6| Step: 3
Training loss: 2.3045756816864014
Validation loss: 2.00705188064165

Epoch: 6| Step: 4
Training loss: 2.566986083984375
Validation loss: 2.0217594151855796

Epoch: 6| Step: 5
Training loss: 1.868834376335144
Validation loss: 2.0135571597724833

Epoch: 6| Step: 6
Training loss: 2.3107471466064453
Validation loss: 2.00455742497598

Epoch: 6| Step: 7
Training loss: 1.754246473312378
Validation loss: 1.997474096154654

Epoch: 6| Step: 8
Training loss: 2.646491050720215
Validation loss: 1.969724730778766

Epoch: 6| Step: 9
Training loss: 1.7142492532730103
Validation loss: 1.982472086465487

Epoch: 6| Step: 10
Training loss: 2.409860849380493
Validation loss: 1.9864035037256056

Epoch: 6| Step: 11
Training loss: 2.1265788078308105
Validation loss: 1.9909649151627735

Epoch: 6| Step: 12
Training loss: 1.7301363945007324
Validation loss: 2.024816988616861

Epoch: 6| Step: 13
Training loss: 1.8047442436218262
Validation loss: 2.038144443624763

Epoch: 107| Step: 0
Training loss: 2.028799533843994
Validation loss: 2.079201057393064

Epoch: 6| Step: 1
Training loss: 2.286884307861328
Validation loss: 2.066834339531519

Epoch: 6| Step: 2
Training loss: 1.9426383972167969
Validation loss: 2.075776743632491

Epoch: 6| Step: 3
Training loss: 2.5709517002105713
Validation loss: 2.0694868974788214

Epoch: 6| Step: 4
Training loss: 1.5280383825302124
Validation loss: 2.0582027153302263

Epoch: 6| Step: 5
Training loss: 2.1797404289245605
Validation loss: 2.0606161099608227

Epoch: 6| Step: 6
Training loss: 1.840570330619812
Validation loss: 2.0729332764943442

Epoch: 6| Step: 7
Training loss: 2.365013599395752
Validation loss: 2.1017015595589914

Epoch: 6| Step: 8
Training loss: 2.3535866737365723
Validation loss: 2.0902032698354414

Epoch: 6| Step: 9
Training loss: 3.275874376296997
Validation loss: 2.103770148369574

Epoch: 6| Step: 10
Training loss: 2.617095470428467
Validation loss: 2.0884110799399753

Epoch: 6| Step: 11
Training loss: 2.2466189861297607
Validation loss: 2.055393744540471

Epoch: 6| Step: 12
Training loss: 2.3206334114074707
Validation loss: 1.9961762684647755

Epoch: 6| Step: 13
Training loss: 2.703716278076172
Validation loss: 1.9823705637326805

Epoch: 108| Step: 0
Training loss: 1.455742359161377
Validation loss: 1.98185593851151

Epoch: 6| Step: 1
Training loss: 1.2634936571121216
Validation loss: 1.9977810203388173

Epoch: 6| Step: 2
Training loss: 2.478048324584961
Validation loss: 2.0014647488952964

Epoch: 6| Step: 3
Training loss: 2.4419424533843994
Validation loss: 2.0157648517239477

Epoch: 6| Step: 4
Training loss: 3.051814556121826
Validation loss: 2.021418120271416

Epoch: 6| Step: 5
Training loss: 2.3943610191345215
Validation loss: 1.9905433218966249

Epoch: 6| Step: 6
Training loss: 2.636002779006958
Validation loss: 1.9698106345310007

Epoch: 6| Step: 7
Training loss: 1.776816725730896
Validation loss: 1.9569640800517092

Epoch: 6| Step: 8
Training loss: 2.137676954269409
Validation loss: 1.9704444267416512

Epoch: 6| Step: 9
Training loss: 2.4937312602996826
Validation loss: 1.963098031218334

Epoch: 6| Step: 10
Training loss: 2.2849879264831543
Validation loss: 1.9657670169748285

Epoch: 6| Step: 11
Training loss: 2.4425268173217773
Validation loss: 1.9690018917924614

Epoch: 6| Step: 12
Training loss: 2.5046560764312744
Validation loss: 1.9726421217764578

Epoch: 6| Step: 13
Training loss: 2.270277976989746
Validation loss: 1.9857831988283383

Epoch: 109| Step: 0
Training loss: 2.0899810791015625
Validation loss: 1.9997813240174325

Epoch: 6| Step: 1
Training loss: 2.712486505508423
Validation loss: 2.006489228176814

Epoch: 6| Step: 2
Training loss: 2.436107635498047
Validation loss: 2.0169888004179923

Epoch: 6| Step: 3
Training loss: 2.0184683799743652
Validation loss: 2.0212836265563965

Epoch: 6| Step: 4
Training loss: 2.283168077468872
Validation loss: 2.0413904190063477

Epoch: 6| Step: 5
Training loss: 2.105496644973755
Validation loss: 2.0457678097550587

Epoch: 6| Step: 6
Training loss: 2.9126083850860596
Validation loss: 2.0556677477334135

Epoch: 6| Step: 7
Training loss: 2.1681737899780273
Validation loss: 2.0578976933674147

Epoch: 6| Step: 8
Training loss: 1.7007249593734741
Validation loss: 2.0499848588820426

Epoch: 6| Step: 9
Training loss: 1.8020267486572266
Validation loss: 2.044500150988179

Epoch: 6| Step: 10
Training loss: 2.6400880813598633
Validation loss: 2.0803191610561904

Epoch: 6| Step: 11
Training loss: 2.5716640949249268
Validation loss: 2.0773185324925247

Epoch: 6| Step: 12
Training loss: 2.053542375564575
Validation loss: 2.07963328976785

Epoch: 6| Step: 13
Training loss: 2.177504301071167
Validation loss: 2.076529436213996

Epoch: 110| Step: 0
Training loss: 2.386962413787842
Validation loss: 2.0681561334158785

Epoch: 6| Step: 1
Training loss: 2.6448447704315186
Validation loss: 2.080111834310716

Epoch: 6| Step: 2
Training loss: 1.9537001848220825
Validation loss: 2.05169540707783

Epoch: 6| Step: 3
Training loss: 2.600745677947998
Validation loss: 2.0447634086813977

Epoch: 6| Step: 4
Training loss: 1.933982253074646
Validation loss: 2.0185831490383355

Epoch: 6| Step: 5
Training loss: 2.0337367057800293
Validation loss: 2.0140148670442644

Epoch: 6| Step: 6
Training loss: 2.4418084621429443
Validation loss: 1.9934862762369134

Epoch: 6| Step: 7
Training loss: 1.81700599193573
Validation loss: 1.9752174974769674

Epoch: 6| Step: 8
Training loss: 2.22843599319458
Validation loss: 1.98149884388011

Epoch: 6| Step: 9
Training loss: 1.838111162185669
Validation loss: 1.9700256880893503

Epoch: 6| Step: 10
Training loss: 2.5229644775390625
Validation loss: 1.9769890616017003

Epoch: 6| Step: 11
Training loss: 1.8708844184875488
Validation loss: 1.9791654348373413

Epoch: 6| Step: 12
Training loss: 2.1176393032073975
Validation loss: 1.9751819897723455

Epoch: 6| Step: 13
Training loss: 2.9452946186065674
Validation loss: 1.978711002616472

Epoch: 111| Step: 0
Training loss: 2.427299976348877
Validation loss: 1.9743972350192327

Epoch: 6| Step: 1
Training loss: 1.540644884109497
Validation loss: 2.0078126999639694

Epoch: 6| Step: 2
Training loss: 2.424328088760376
Validation loss: 2.010096840961005

Epoch: 6| Step: 3
Training loss: 2.7218878269195557
Validation loss: 2.0121926889624646

Epoch: 6| Step: 4
Training loss: 1.9184011220932007
Validation loss: 2.035236200978679

Epoch: 6| Step: 5
Training loss: 2.70151948928833
Validation loss: 2.0461661354187997

Epoch: 6| Step: 6
Training loss: 2.4108457565307617
Validation loss: 2.0269011207806167

Epoch: 6| Step: 7
Training loss: 1.803352952003479
Validation loss: 2.029668131182271

Epoch: 6| Step: 8
Training loss: 2.303959369659424
Validation loss: 2.0231209877998597

Epoch: 6| Step: 9
Training loss: 1.79520583152771
Validation loss: 2.0145360026308285

Epoch: 6| Step: 10
Training loss: 2.9120287895202637
Validation loss: 2.0485995777191652

Epoch: 6| Step: 11
Training loss: 2.078835964202881
Validation loss: 2.064278769236739

Epoch: 6| Step: 12
Training loss: 1.42998206615448
Validation loss: 2.062223724139634

Epoch: 6| Step: 13
Training loss: 2.8516628742218018
Validation loss: 2.06905298848306

Epoch: 112| Step: 0
Training loss: 2.790076732635498
Validation loss: 2.100970523331755

Epoch: 6| Step: 1
Training loss: 1.9447574615478516
Validation loss: 2.1049726688733665

Epoch: 6| Step: 2
Training loss: 2.4508533477783203
Validation loss: 2.1066548875583115

Epoch: 6| Step: 3
Training loss: 2.6985154151916504
Validation loss: 2.0868952761414232

Epoch: 6| Step: 4
Training loss: 2.0333642959594727
Validation loss: 2.0727880359977804

Epoch: 6| Step: 5
Training loss: 2.4744582176208496
Validation loss: 2.0435033023998304

Epoch: 6| Step: 6
Training loss: 1.7818676233291626
Validation loss: 2.0302807925849833

Epoch: 6| Step: 7
Training loss: 1.6147336959838867
Validation loss: 2.0108243880733365

Epoch: 6| Step: 8
Training loss: 2.5653953552246094
Validation loss: 1.9977278119774275

Epoch: 6| Step: 9
Training loss: 2.3697092533111572
Validation loss: 2.0017386892790436

Epoch: 6| Step: 10
Training loss: 1.850359559059143
Validation loss: 2.000642937998618

Epoch: 6| Step: 11
Training loss: 2.271860361099243
Validation loss: 1.9845585720513457

Epoch: 6| Step: 12
Training loss: 2.2837843894958496
Validation loss: 1.9766016442288634

Epoch: 6| Step: 13
Training loss: 1.6156013011932373
Validation loss: 1.9847118585340437

Epoch: 113| Step: 0
Training loss: 1.7680604457855225
Validation loss: 1.9822927649303148

Epoch: 6| Step: 1
Training loss: 3.2677199840545654
Validation loss: 1.9954923647706226

Epoch: 6| Step: 2
Training loss: 2.0538697242736816
Validation loss: 1.9981428500144713

Epoch: 6| Step: 3
Training loss: 1.7813812494277954
Validation loss: 2.0317463644089235

Epoch: 6| Step: 4
Training loss: 2.0353424549102783
Validation loss: 2.0147011305696223

Epoch: 6| Step: 5
Training loss: 3.024763584136963
Validation loss: 2.0155942093941475

Epoch: 6| Step: 6
Training loss: 2.230342149734497
Validation loss: 2.0215068632556545

Epoch: 6| Step: 7
Training loss: 1.8767732381820679
Validation loss: 2.0271101818289807

Epoch: 6| Step: 8
Training loss: 2.9501657485961914
Validation loss: 2.064415888119769

Epoch: 6| Step: 9
Training loss: 2.0894501209259033
Validation loss: 2.068784636835898

Epoch: 6| Step: 10
Training loss: 2.339787006378174
Validation loss: 2.0661324659983316

Epoch: 6| Step: 11
Training loss: 2.005462408065796
Validation loss: 2.053496665852044

Epoch: 6| Step: 12
Training loss: 1.5266742706298828
Validation loss: 2.0329395827426704

Epoch: 6| Step: 13
Training loss: 2.1542816162109375
Validation loss: 2.0624044056861632

Epoch: 114| Step: 0
Training loss: 2.2615063190460205
Validation loss: 2.0675325624404417

Epoch: 6| Step: 1
Training loss: 2.8147876262664795
Validation loss: 2.0656530395630868

Epoch: 6| Step: 2
Training loss: 1.89900803565979
Validation loss: 2.0596097438566145

Epoch: 6| Step: 3
Training loss: 1.7436832189559937
Validation loss: 2.0154704047787573

Epoch: 6| Step: 4
Training loss: 2.1052346229553223
Validation loss: 1.9807727529156594

Epoch: 6| Step: 5
Training loss: 2.562558650970459
Validation loss: 1.98538339138031

Epoch: 6| Step: 6
Training loss: 1.9118459224700928
Validation loss: 1.9849456971691501

Epoch: 6| Step: 7
Training loss: 2.6022896766662598
Validation loss: 1.9945120093643025

Epoch: 6| Step: 8
Training loss: 2.157553195953369
Validation loss: 2.004248592161363

Epoch: 6| Step: 9
Training loss: 2.5451717376708984
Validation loss: 1.994277718246624

Epoch: 6| Step: 10
Training loss: 1.6012864112854004
Validation loss: 1.9930963567508164

Epoch: 6| Step: 11
Training loss: 2.4474544525146484
Validation loss: 2.014063919744184

Epoch: 6| Step: 12
Training loss: 2.671220064163208
Validation loss: 2.0219466865703626

Epoch: 6| Step: 13
Training loss: 1.409199595451355
Validation loss: 2.055633011684623

Epoch: 115| Step: 0
Training loss: 1.94419527053833
Validation loss: 2.059262128286464

Epoch: 6| Step: 1
Training loss: 1.9027433395385742
Validation loss: 2.032980557410948

Epoch: 6| Step: 2
Training loss: 2.706582546234131
Validation loss: 2.0106909621146416

Epoch: 6| Step: 3
Training loss: 2.264202117919922
Validation loss: 2.0109638962694394

Epoch: 6| Step: 4
Training loss: 1.221887469291687
Validation loss: 2.020625852769421

Epoch: 6| Step: 5
Training loss: 2.0252156257629395
Validation loss: 2.020316159853371

Epoch: 6| Step: 6
Training loss: 2.7378010749816895
Validation loss: 2.0387102403948383

Epoch: 6| Step: 7
Training loss: 1.852447271347046
Validation loss: 2.0497123861825592

Epoch: 6| Step: 8
Training loss: 2.5576229095458984
Validation loss: 2.0658785104751587

Epoch: 6| Step: 9
Training loss: 2.336439371109009
Validation loss: 2.0795724827756166

Epoch: 6| Step: 10
Training loss: 2.257233142852783
Validation loss: 2.073800169011598

Epoch: 6| Step: 11
Training loss: 2.6887686252593994
Validation loss: 2.0550561130687757

Epoch: 6| Step: 12
Training loss: 2.209233522415161
Validation loss: 2.0475437102779264

Epoch: 6| Step: 13
Training loss: 2.722529888153076
Validation loss: 2.049511073738016

Epoch: 116| Step: 0
Training loss: 1.8297336101531982
Validation loss: 2.021358484862953

Epoch: 6| Step: 1
Training loss: 2.3471667766571045
Validation loss: 2.021449141604926

Epoch: 6| Step: 2
Training loss: 2.9667646884918213
Validation loss: 2.010020402169997

Epoch: 6| Step: 3
Training loss: 1.6632810831069946
Validation loss: 1.9875859445141209

Epoch: 6| Step: 4
Training loss: 2.170349597930908
Validation loss: 1.971618180633873

Epoch: 6| Step: 5
Training loss: 1.7929408550262451
Validation loss: 1.9822059510856547

Epoch: 6| Step: 6
Training loss: 1.959469199180603
Validation loss: 1.9836752312157744

Epoch: 6| Step: 7
Training loss: 2.4349982738494873
Validation loss: 1.9972132303381478

Epoch: 6| Step: 8
Training loss: 2.392590045928955
Validation loss: 1.9942691826051282

Epoch: 6| Step: 9
Training loss: 2.9590306282043457
Validation loss: 2.011536305950534

Epoch: 6| Step: 10
Training loss: 1.862929105758667
Validation loss: 2.0175756536504275

Epoch: 6| Step: 11
Training loss: 2.078983783721924
Validation loss: 2.0264333883921304

Epoch: 6| Step: 12
Training loss: 1.0459665060043335
Validation loss: 2.0419043674263904

Epoch: 6| Step: 13
Training loss: 3.1892917156219482
Validation loss: 2.0748613803617415

Epoch: 117| Step: 0
Training loss: 2.1607723236083984
Validation loss: 2.0398020641778105

Epoch: 6| Step: 1
Training loss: 2.31441068649292
Validation loss: 2.0181243342737996

Epoch: 6| Step: 2
Training loss: 1.9195644855499268
Validation loss: 1.9978806998140068

Epoch: 6| Step: 3
Training loss: 2.4229016304016113
Validation loss: 1.9913549987218713

Epoch: 6| Step: 4
Training loss: 2.664837121963501
Validation loss: 1.997885686095043

Epoch: 6| Step: 5
Training loss: 1.909136176109314
Validation loss: 1.9908178698632024

Epoch: 6| Step: 6
Training loss: 1.9570485353469849
Validation loss: 1.9812474173884238

Epoch: 6| Step: 7
Training loss: 1.863067626953125
Validation loss: 1.9894927881097282

Epoch: 6| Step: 8
Training loss: 2.1082372665405273
Validation loss: 1.9764768256936023

Epoch: 6| Step: 9
Training loss: 2.3852219581604004
Validation loss: 1.9650374151045276

Epoch: 6| Step: 10
Training loss: 2.5659003257751465
Validation loss: 1.9582931354481687

Epoch: 6| Step: 11
Training loss: 1.928325891494751
Validation loss: 1.9631649345479987

Epoch: 6| Step: 12
Training loss: 2.4657115936279297
Validation loss: 1.9615351794868388

Epoch: 6| Step: 13
Training loss: 2.0446853637695312
Validation loss: 1.9641293146276986

Epoch: 118| Step: 0
Training loss: 2.1042556762695312
Validation loss: 1.9737181740422403

Epoch: 6| Step: 1
Training loss: 2.001704692840576
Validation loss: 1.9589021257174912

Epoch: 6| Step: 2
Training loss: 3.157376289367676
Validation loss: 1.9619897668079664

Epoch: 6| Step: 3
Training loss: 2.2712156772613525
Validation loss: 1.9517812562245194

Epoch: 6| Step: 4
Training loss: 1.9707870483398438
Validation loss: 1.9367984084672825

Epoch: 6| Step: 5
Training loss: 1.9774396419525146
Validation loss: 1.9405908533321914

Epoch: 6| Step: 6
Training loss: 1.8632493019104004
Validation loss: 1.9491103259466027

Epoch: 6| Step: 7
Training loss: 2.186643123626709
Validation loss: 1.9534602395949825

Epoch: 6| Step: 8
Training loss: 2.874752998352051
Validation loss: 1.963966642656634

Epoch: 6| Step: 9
Training loss: 1.7200818061828613
Validation loss: 1.9753503825074883

Epoch: 6| Step: 10
Training loss: 2.731595039367676
Validation loss: 1.9909136743955715

Epoch: 6| Step: 11
Training loss: 1.5967326164245605
Validation loss: 2.023626786406322

Epoch: 6| Step: 12
Training loss: 1.7802278995513916
Validation loss: 2.0436256854764876

Epoch: 6| Step: 13
Training loss: 2.6120522022247314
Validation loss: 2.0503785174380065

Epoch: 119| Step: 0
Training loss: 2.4161412715911865
Validation loss: 1.99174851499578

Epoch: 6| Step: 1
Training loss: 1.2041676044464111
Validation loss: 1.979332488070252

Epoch: 6| Step: 2
Training loss: 2.3901994228363037
Validation loss: 1.9856276614691621

Epoch: 6| Step: 3
Training loss: 2.418670177459717
Validation loss: 1.989261878434048

Epoch: 6| Step: 4
Training loss: 2.2487754821777344
Validation loss: 1.9853283089976157

Epoch: 6| Step: 5
Training loss: 2.2918784618377686
Validation loss: 1.9997267517992245

Epoch: 6| Step: 6
Training loss: 2.3646135330200195
Validation loss: 1.9977676842802314

Epoch: 6| Step: 7
Training loss: 2.021115303039551
Validation loss: 2.00506712800713

Epoch: 6| Step: 8
Training loss: 1.7875487804412842
Validation loss: 1.9873357165244319

Epoch: 6| Step: 9
Training loss: 2.4299044609069824
Validation loss: 1.9721682661323137

Epoch: 6| Step: 10
Training loss: 2.447437047958374
Validation loss: 1.962386187686715

Epoch: 6| Step: 11
Training loss: 2.1190881729125977
Validation loss: 1.9618017288946337

Epoch: 6| Step: 12
Training loss: 2.4173271656036377
Validation loss: 1.975169712497342

Epoch: 6| Step: 13
Training loss: 1.9579980373382568
Validation loss: 2.0030556648008284

Epoch: 120| Step: 0
Training loss: 1.718541145324707
Validation loss: 2.0422912374619515

Epoch: 6| Step: 1
Training loss: 2.6083226203918457
Validation loss: 2.0623581114635674

Epoch: 6| Step: 2
Training loss: 2.761295795440674
Validation loss: 2.0808361371358237

Epoch: 6| Step: 3
Training loss: 2.1530256271362305
Validation loss: 2.074239715453117

Epoch: 6| Step: 4
Training loss: 1.7643687725067139
Validation loss: 2.0673028320394535

Epoch: 6| Step: 5
Training loss: 2.772073268890381
Validation loss: 2.0303155875975087

Epoch: 6| Step: 6
Training loss: 2.2033004760742188
Validation loss: 2.007058790934983

Epoch: 6| Step: 7
Training loss: 1.8517389297485352
Validation loss: 1.9886986158227409

Epoch: 6| Step: 8
Training loss: 1.906770944595337
Validation loss: 1.9785946543498705

Epoch: 6| Step: 9
Training loss: 2.637484073638916
Validation loss: 1.9888326391097038

Epoch: 6| Step: 10
Training loss: 2.3222341537475586
Validation loss: 2.0058913205259588

Epoch: 6| Step: 11
Training loss: 2.1706368923187256
Validation loss: 2.0016608763766546

Epoch: 6| Step: 12
Training loss: 1.8972561359405518
Validation loss: 2.014291572314437

Epoch: 6| Step: 13
Training loss: 2.048893928527832
Validation loss: 2.012631462466332

Epoch: 121| Step: 0
Training loss: 2.3834657669067383
Validation loss: 2.0143691775619343

Epoch: 6| Step: 1
Training loss: 2.6783175468444824
Validation loss: 2.001469381393925

Epoch: 6| Step: 2
Training loss: 2.031228542327881
Validation loss: 2.007657535614506

Epoch: 6| Step: 3
Training loss: 2.5559768676757812
Validation loss: 2.025144596253672

Epoch: 6| Step: 4
Training loss: 2.043701171875
Validation loss: 2.0420370076292302

Epoch: 6| Step: 5
Training loss: 2.624317169189453
Validation loss: 2.062798136024065

Epoch: 6| Step: 6
Training loss: 1.8950074911117554
Validation loss: 2.0606589304503573

Epoch: 6| Step: 7
Training loss: 1.6257867813110352
Validation loss: 2.0658174381461194

Epoch: 6| Step: 8
Training loss: 2.6448817253112793
Validation loss: 2.030493659357871

Epoch: 6| Step: 9
Training loss: 2.345945358276367
Validation loss: 2.0084765380428684

Epoch: 6| Step: 10
Training loss: 2.1670970916748047
Validation loss: 2.001398681312479

Epoch: 6| Step: 11
Training loss: 0.7885009050369263
Validation loss: 1.9860584223142235

Epoch: 6| Step: 12
Training loss: 1.910302758216858
Validation loss: 1.9981322262876777

Epoch: 6| Step: 13
Training loss: 3.153561592102051
Validation loss: 1.9784215009340675

Epoch: 122| Step: 0
Training loss: 2.256085157394409
Validation loss: 1.979257345199585

Epoch: 6| Step: 1
Training loss: 1.5785114765167236
Validation loss: 1.9864100935638591

Epoch: 6| Step: 2
Training loss: 1.9464261531829834
Validation loss: 1.9825980304389872

Epoch: 6| Step: 3
Training loss: 2.251880168914795
Validation loss: 1.9782748222351074

Epoch: 6| Step: 4
Training loss: 2.0069336891174316
Validation loss: 1.9772988186087659

Epoch: 6| Step: 5
Training loss: 2.240933418273926
Validation loss: 1.9698014195247362

Epoch: 6| Step: 6
Training loss: 2.4509458541870117
Validation loss: 1.9497030153069446

Epoch: 6| Step: 7
Training loss: 2.064042806625366
Validation loss: 1.963612876912599

Epoch: 6| Step: 8
Training loss: 2.7598791122436523
Validation loss: 1.9787014428005423

Epoch: 6| Step: 9
Training loss: 2.177931070327759
Validation loss: 1.979720025934199

Epoch: 6| Step: 10
Training loss: 1.8786015510559082
Validation loss: 1.974547327205699

Epoch: 6| Step: 11
Training loss: 1.8660180568695068
Validation loss: 2.0029783992357153

Epoch: 6| Step: 12
Training loss: 2.3300843238830566
Validation loss: 2.0128000628563667

Epoch: 6| Step: 13
Training loss: 2.0565261840820312
Validation loss: 2.0387328260688373

Epoch: 123| Step: 0
Training loss: 2.3019137382507324
Validation loss: 1.994617195539577

Epoch: 6| Step: 1
Training loss: 1.9271912574768066
Validation loss: 1.9891923307090678

Epoch: 6| Step: 2
Training loss: 1.1972875595092773
Validation loss: 2.00515462634384

Epoch: 6| Step: 3
Training loss: 1.7246780395507812
Validation loss: 2.0071992092235114

Epoch: 6| Step: 4
Training loss: 2.652174234390259
Validation loss: 1.9982840091951433

Epoch: 6| Step: 5
Training loss: 1.6444871425628662
Validation loss: 2.0001905656629995

Epoch: 6| Step: 6
Training loss: 2.7840144634246826
Validation loss: 1.9888087293153167

Epoch: 6| Step: 7
Training loss: 2.5109450817108154
Validation loss: 1.996261691534391

Epoch: 6| Step: 8
Training loss: 1.9611704349517822
Validation loss: 2.0002438714427333

Epoch: 6| Step: 9
Training loss: 2.2210311889648438
Validation loss: 2.0110914181637507

Epoch: 6| Step: 10
Training loss: 2.5075578689575195
Validation loss: 1.9900599705275668

Epoch: 6| Step: 11
Training loss: 1.9853899478912354
Validation loss: 1.9639219648094588

Epoch: 6| Step: 12
Training loss: 2.5207502841949463
Validation loss: 1.9569253434417069

Epoch: 6| Step: 13
Training loss: 1.526012659072876
Validation loss: 1.959782882403302

Epoch: 124| Step: 0
Training loss: 1.6714614629745483
Validation loss: 1.9615657214195497

Epoch: 6| Step: 1
Training loss: 2.031705856323242
Validation loss: 1.9942003629540885

Epoch: 6| Step: 2
Training loss: 2.1441426277160645
Validation loss: 2.0356380426755516

Epoch: 6| Step: 3
Training loss: 2.1108293533325195
Validation loss: 2.0388281242821806

Epoch: 6| Step: 4
Training loss: 2.236346960067749
Validation loss: 2.0720976450109996

Epoch: 6| Step: 5
Training loss: 2.3117141723632812
Validation loss: 2.0419437731465986

Epoch: 6| Step: 6
Training loss: 2.3731131553649902
Validation loss: 2.006545214242833

Epoch: 6| Step: 7
Training loss: 2.321747303009033
Validation loss: 1.9772588078693678

Epoch: 6| Step: 8
Training loss: 2.258303642272949
Validation loss: 1.9803332513378513

Epoch: 6| Step: 9
Training loss: 2.4619088172912598
Validation loss: 1.9847291643901537

Epoch: 6| Step: 10
Training loss: 2.1410112380981445
Validation loss: 1.9689866060851722

Epoch: 6| Step: 11
Training loss: 1.4884593486785889
Validation loss: 1.9970089209977018

Epoch: 6| Step: 12
Training loss: 2.301239490509033
Validation loss: 1.9848811613616122

Epoch: 6| Step: 13
Training loss: 2.1727004051208496
Validation loss: 1.9636169864285378

Epoch: 125| Step: 0
Training loss: 2.374293804168701
Validation loss: 1.9410090151653494

Epoch: 6| Step: 1
Training loss: 1.8213804960250854
Validation loss: 1.9252029298454203

Epoch: 6| Step: 2
Training loss: 2.042853832244873
Validation loss: 1.9453106798151487

Epoch: 6| Step: 3
Training loss: 2.3834497928619385
Validation loss: 1.9391176944137902

Epoch: 6| Step: 4
Training loss: 2.295307159423828
Validation loss: 1.9642358018505959

Epoch: 6| Step: 5
Training loss: 2.549694061279297
Validation loss: 1.9517517987117972

Epoch: 6| Step: 6
Training loss: 1.6668040752410889
Validation loss: 1.9534404047073857

Epoch: 6| Step: 7
Training loss: 3.028592824935913
Validation loss: 1.9630831415935228

Epoch: 6| Step: 8
Training loss: 1.5101861953735352
Validation loss: 1.9560299393951253

Epoch: 6| Step: 9
Training loss: 1.9852659702301025
Validation loss: 1.9461045034470097

Epoch: 6| Step: 10
Training loss: 1.8453342914581299
Validation loss: 1.9195555922805623

Epoch: 6| Step: 11
Training loss: 2.271467685699463
Validation loss: 1.9269487473272509

Epoch: 6| Step: 12
Training loss: 2.247328281402588
Validation loss: 1.9443681727173507

Epoch: 6| Step: 13
Training loss: 1.7312233448028564
Validation loss: 1.9505963197318457

Epoch: 126| Step: 0
Training loss: 2.2215003967285156
Validation loss: 1.969661194791076

Epoch: 6| Step: 1
Training loss: 1.937098503112793
Validation loss: 1.9889263196658062

Epoch: 6| Step: 2
Training loss: 2.440948486328125
Validation loss: 2.0447281611863004

Epoch: 6| Step: 3
Training loss: 2.2942492961883545
Validation loss: 2.1359751327063448

Epoch: 6| Step: 4
Training loss: 1.9055202007293701
Validation loss: 2.2051679908588366

Epoch: 6| Step: 5
Training loss: 3.1931424140930176
Validation loss: 2.2274131133992183

Epoch: 6| Step: 6
Training loss: 2.589547634124756
Validation loss: 2.2196857852320515

Epoch: 6| Step: 7
Training loss: 2.278813123703003
Validation loss: 2.1696368417432232

Epoch: 6| Step: 8
Training loss: 1.809251308441162
Validation loss: 2.1542750173999416

Epoch: 6| Step: 9
Training loss: 1.8472802639007568
Validation loss: 2.1152076644282185

Epoch: 6| Step: 10
Training loss: 1.6352219581604004
Validation loss: 2.098824898401896

Epoch: 6| Step: 11
Training loss: 2.075834274291992
Validation loss: 2.047088102627826

Epoch: 6| Step: 12
Training loss: 2.2172670364379883
Validation loss: 2.032408978349419

Epoch: 6| Step: 13
Training loss: 2.9838685989379883
Validation loss: 2.034674152251213

Epoch: 127| Step: 0
Training loss: 2.21443247795105
Validation loss: 2.0287681343734905

Epoch: 6| Step: 1
Training loss: 1.939967155456543
Validation loss: 2.0239430294241956

Epoch: 6| Step: 2
Training loss: 2.112196207046509
Validation loss: 1.9805360596667054

Epoch: 6| Step: 3
Training loss: 2.2689523696899414
Validation loss: 1.9462663050620788

Epoch: 6| Step: 4
Training loss: 2.156137466430664
Validation loss: 1.931377318597609

Epoch: 6| Step: 5
Training loss: 1.8998595476150513
Validation loss: 1.920403843284935

Epoch: 6| Step: 6
Training loss: 2.6578965187072754
Validation loss: 1.9141140778859456

Epoch: 6| Step: 7
Training loss: 2.1322736740112305
Validation loss: 1.929960407236571

Epoch: 6| Step: 8
Training loss: 2.0615339279174805
Validation loss: 1.948068500846945

Epoch: 6| Step: 9
Training loss: 2.349764823913574
Validation loss: 1.9797768208288378

Epoch: 6| Step: 10
Training loss: 2.8023035526275635
Validation loss: 1.997244042734946

Epoch: 6| Step: 11
Training loss: 1.4450219869613647
Validation loss: 2.0411167977958597

Epoch: 6| Step: 12
Training loss: 2.1204495429992676
Validation loss: 2.042997124374554

Epoch: 6| Step: 13
Training loss: 2.1331427097320557
Validation loss: 2.049026217511905

Epoch: 128| Step: 0
Training loss: 2.539773941040039
Validation loss: 2.027019387932234

Epoch: 6| Step: 1
Training loss: 1.7706612348556519
Validation loss: 2.0150841436078473

Epoch: 6| Step: 2
Training loss: 1.9141814708709717
Validation loss: 1.9957066274458362

Epoch: 6| Step: 3
Training loss: 2.070671319961548
Validation loss: 1.982456845621909

Epoch: 6| Step: 4
Training loss: 2.735783576965332
Validation loss: 1.974036032153714

Epoch: 6| Step: 5
Training loss: 2.2049789428710938
Validation loss: 1.941359478940246

Epoch: 6| Step: 6
Training loss: 2.5241732597351074
Validation loss: 1.9369570619316512

Epoch: 6| Step: 7
Training loss: 1.8159867525100708
Validation loss: 1.9334697364478983

Epoch: 6| Step: 8
Training loss: 2.782869577407837
Validation loss: 1.945065370170019

Epoch: 6| Step: 9
Training loss: 2.0994670391082764
Validation loss: 1.9539282770567044

Epoch: 6| Step: 10
Training loss: 2.0039162635803223
Validation loss: 1.9679020861143708

Epoch: 6| Step: 11
Training loss: 1.9023107290267944
Validation loss: 1.967765446632139

Epoch: 6| Step: 12
Training loss: 1.8494672775268555
Validation loss: 1.9845059148726925

Epoch: 6| Step: 13
Training loss: 1.6922730207443237
Validation loss: 1.9866879678541614

Epoch: 129| Step: 0
Training loss: 2.0182504653930664
Validation loss: 1.9916835023510842

Epoch: 6| Step: 1
Training loss: 1.800722360610962
Validation loss: 1.9747967220121814

Epoch: 6| Step: 2
Training loss: 1.9793517589569092
Validation loss: 1.947914433735673

Epoch: 6| Step: 3
Training loss: 1.996671438217163
Validation loss: 1.9562456159181492

Epoch: 6| Step: 4
Training loss: 2.0444512367248535
Validation loss: 1.9674992971522833

Epoch: 6| Step: 5
Training loss: 2.4327430725097656
Validation loss: 1.9806245629505446

Epoch: 6| Step: 6
Training loss: 2.0048716068267822
Validation loss: 1.9938070927896807

Epoch: 6| Step: 7
Training loss: 2.1660642623901367
Validation loss: 2.0051561991373696

Epoch: 6| Step: 8
Training loss: 1.722978949546814
Validation loss: 2.0150880544416365

Epoch: 6| Step: 9
Training loss: 2.0105884075164795
Validation loss: 2.0476139386494956

Epoch: 6| Step: 10
Training loss: 2.3110005855560303
Validation loss: 2.065032074528356

Epoch: 6| Step: 11
Training loss: 2.450164794921875
Validation loss: 2.041586168350712

Epoch: 6| Step: 12
Training loss: 2.4342668056488037
Validation loss: 2.0420764287312827

Epoch: 6| Step: 13
Training loss: 2.4676718711853027
Validation loss: 1.9855228470217796

Epoch: 130| Step: 0
Training loss: 2.556199073791504
Validation loss: 1.9842248744862054

Epoch: 6| Step: 1
Training loss: 2.3558387756347656
Validation loss: 1.9962743777100758

Epoch: 6| Step: 2
Training loss: 2.6179075241088867
Validation loss: 1.9908784576641616

Epoch: 6| Step: 3
Training loss: 1.2779951095581055
Validation loss: 1.997688861303432

Epoch: 6| Step: 4
Training loss: 1.7735010385513306
Validation loss: 1.971381559166857

Epoch: 6| Step: 5
Training loss: 1.6128966808319092
Validation loss: 1.9777756967852194

Epoch: 6| Step: 6
Training loss: 1.8970657587051392
Validation loss: 1.970381752137215

Epoch: 6| Step: 7
Training loss: 2.2628889083862305
Validation loss: 1.944576827428674

Epoch: 6| Step: 8
Training loss: 2.265838146209717
Validation loss: 1.9516610125059723

Epoch: 6| Step: 9
Training loss: 1.9611332416534424
Validation loss: 1.9687070026192615

Epoch: 6| Step: 10
Training loss: 2.41475510597229
Validation loss: 1.9523941265639437

Epoch: 6| Step: 11
Training loss: 2.250309467315674
Validation loss: 1.9449922307845084

Epoch: 6| Step: 12
Training loss: 2.5639827251434326
Validation loss: 1.9393794869863858

Epoch: 6| Step: 13
Training loss: 1.800597071647644
Validation loss: 1.939269450403029

Epoch: 131| Step: 0
Training loss: 2.764371395111084
Validation loss: 1.9627971508169686

Epoch: 6| Step: 1
Training loss: 1.6607224941253662
Validation loss: 1.9754224964367446

Epoch: 6| Step: 2
Training loss: 1.5946156978607178
Validation loss: 1.9769964974413636

Epoch: 6| Step: 3
Training loss: 1.3938794136047363
Validation loss: 1.9838084072195075

Epoch: 6| Step: 4
Training loss: 1.7986667156219482
Validation loss: 1.9998569052706483

Epoch: 6| Step: 5
Training loss: 2.2170827388763428
Validation loss: 2.0017024881096295

Epoch: 6| Step: 6
Training loss: 2.23915958404541
Validation loss: 2.0194994993107294

Epoch: 6| Step: 7
Training loss: 2.3881776332855225
Validation loss: 2.006237529939221

Epoch: 6| Step: 8
Training loss: 2.1485443115234375
Validation loss: 1.9962238034894388

Epoch: 6| Step: 9
Training loss: 2.093998908996582
Validation loss: 1.9749547550755162

Epoch: 6| Step: 10
Training loss: 2.3390023708343506
Validation loss: 1.97111754263601

Epoch: 6| Step: 11
Training loss: 2.6986231803894043
Validation loss: 1.9631556208415697

Epoch: 6| Step: 12
Training loss: 1.8751230239868164
Validation loss: 1.9704776758788733

Epoch: 6| Step: 13
Training loss: 1.734528660774231
Validation loss: 1.989806878951288

Epoch: 132| Step: 0
Training loss: 1.7901171445846558
Validation loss: 1.965889976870629

Epoch: 6| Step: 1
Training loss: 2.5708322525024414
Validation loss: 1.9847756624221802

Epoch: 6| Step: 2
Training loss: 2.6770694255828857
Validation loss: 1.9897838664311234

Epoch: 6| Step: 3
Training loss: 2.8573708534240723
Validation loss: 1.960648718700614

Epoch: 6| Step: 4
Training loss: 1.8740105628967285
Validation loss: 1.954478717619373

Epoch: 6| Step: 5
Training loss: 1.8411993980407715
Validation loss: 1.9621137252417944

Epoch: 6| Step: 6
Training loss: 2.0538434982299805
Validation loss: 1.9652279115492297

Epoch: 6| Step: 7
Training loss: 2.223254680633545
Validation loss: 1.94758011961496

Epoch: 6| Step: 8
Training loss: 1.734635591506958
Validation loss: 1.9554117623195852

Epoch: 6| Step: 9
Training loss: 1.978841781616211
Validation loss: 1.950932264328003

Epoch: 6| Step: 10
Training loss: 1.3838874101638794
Validation loss: 1.9460744114332302

Epoch: 6| Step: 11
Training loss: 2.367715835571289
Validation loss: 1.9696482637877106

Epoch: 6| Step: 12
Training loss: 1.774133563041687
Validation loss: 1.9546861494741132

Epoch: 6| Step: 13
Training loss: 1.2973333597183228
Validation loss: 1.981350383450908

Epoch: 133| Step: 0
Training loss: 2.1526050567626953
Validation loss: 2.0147807482750184

Epoch: 6| Step: 1
Training loss: 2.82437801361084
Validation loss: 2.01721106806109

Epoch: 6| Step: 2
Training loss: 2.002423048019409
Validation loss: 1.979995773684594

Epoch: 6| Step: 3
Training loss: 2.3626811504364014
Validation loss: 2.0002301892926617

Epoch: 6| Step: 4
Training loss: 2.042591094970703
Validation loss: 1.9979495258741482

Epoch: 6| Step: 5
Training loss: 1.9020246267318726
Validation loss: 1.974967292560044

Epoch: 6| Step: 6
Training loss: 2.203786611557007
Validation loss: 1.9686558913159113

Epoch: 6| Step: 7
Training loss: 2.1087403297424316
Validation loss: 1.961632005630001

Epoch: 6| Step: 8
Training loss: 1.7910441160202026
Validation loss: 1.9758154756279402

Epoch: 6| Step: 9
Training loss: 2.1810660362243652
Validation loss: 1.964368776608539

Epoch: 6| Step: 10
Training loss: 1.6983158588409424
Validation loss: 1.9581268436165267

Epoch: 6| Step: 11
Training loss: 1.1373645067214966
Validation loss: 1.953172629879367

Epoch: 6| Step: 12
Training loss: 2.1672117710113525
Validation loss: 1.9426550852355136

Epoch: 6| Step: 13
Training loss: 2.1510305404663086
Validation loss: 1.9367173564049505

Epoch: 134| Step: 0
Training loss: 2.47011399269104
Validation loss: 1.944694467770156

Epoch: 6| Step: 1
Training loss: 2.05118989944458
Validation loss: 1.9647661280888382

Epoch: 6| Step: 2
Training loss: 2.250483512878418
Validation loss: 1.9742347476302937

Epoch: 6| Step: 3
Training loss: 2.3244376182556152
Validation loss: 1.9731274574033675

Epoch: 6| Step: 4
Training loss: 1.7235004901885986
Validation loss: 1.970813787111672

Epoch: 6| Step: 5
Training loss: 1.6037318706512451
Validation loss: 1.9818372059893865

Epoch: 6| Step: 6
Training loss: 1.7940635681152344
Validation loss: 1.9788250038700719

Epoch: 6| Step: 7
Training loss: 1.2466413974761963
Validation loss: 1.980623806676557

Epoch: 6| Step: 8
Training loss: 2.330678939819336
Validation loss: 1.968841960353236

Epoch: 6| Step: 9
Training loss: 2.116262912750244
Validation loss: 1.9564537079103532

Epoch: 6| Step: 10
Training loss: 1.6678814888000488
Validation loss: 1.962417894794095

Epoch: 6| Step: 11
Training loss: 2.193650722503662
Validation loss: 1.960054438601258

Epoch: 6| Step: 12
Training loss: 2.073173999786377
Validation loss: 1.968497012251167

Epoch: 6| Step: 13
Training loss: 2.7279303073883057
Validation loss: 2.0382544122716433

Epoch: 135| Step: 0
Training loss: 2.040083408355713
Validation loss: 1.9613785089985016

Epoch: 6| Step: 1
Training loss: 1.8991025686264038
Validation loss: 1.9346869466125325

Epoch: 6| Step: 2
Training loss: 2.2571945190429688
Validation loss: 1.9412044658455798

Epoch: 6| Step: 3
Training loss: 2.0774106979370117
Validation loss: 1.9544633357755599

Epoch: 6| Step: 4
Training loss: 1.946600079536438
Validation loss: 1.959460509720669

Epoch: 6| Step: 5
Training loss: 1.9998915195465088
Validation loss: 1.9519321123758953

Epoch: 6| Step: 6
Training loss: 1.431728482246399
Validation loss: 1.9428243675539572

Epoch: 6| Step: 7
Training loss: 1.8730297088623047
Validation loss: 1.941900412241618

Epoch: 6| Step: 8
Training loss: 1.1954560279846191
Validation loss: 1.9425601472136795

Epoch: 6| Step: 9
Training loss: 2.5872397422790527
Validation loss: 1.9449909630642142

Epoch: 6| Step: 10
Training loss: 2.0151913166046143
Validation loss: 1.9683602856051536

Epoch: 6| Step: 11
Training loss: 2.7317874431610107
Validation loss: 1.9729388439527122

Epoch: 6| Step: 12
Training loss: 1.6426753997802734
Validation loss: 1.9661026667523127

Epoch: 6| Step: 13
Training loss: 3.0975570678710938
Validation loss: 1.953787629322339

Epoch: 136| Step: 0
Training loss: 1.2397340536117554
Validation loss: 1.9306509674236338

Epoch: 6| Step: 1
Training loss: 2.1561620235443115
Validation loss: 1.9666624210214103

Epoch: 6| Step: 2
Training loss: 1.5948015451431274
Validation loss: 1.9532262791869461

Epoch: 6| Step: 3
Training loss: 1.8958996534347534
Validation loss: 1.9576530469361173

Epoch: 6| Step: 4
Training loss: 1.811310887336731
Validation loss: 1.967913987816021

Epoch: 6| Step: 5
Training loss: 1.7250885963439941
Validation loss: 1.9716803079010339

Epoch: 6| Step: 6
Training loss: 1.462977647781372
Validation loss: 1.9565680616645402

Epoch: 6| Step: 7
Training loss: 2.3812201023101807
Validation loss: 1.945642493104422

Epoch: 6| Step: 8
Training loss: 2.935650587081909
Validation loss: 1.9527377851547734

Epoch: 6| Step: 9
Training loss: 2.550711154937744
Validation loss: 1.9413046631761777

Epoch: 6| Step: 10
Training loss: 1.9814549684524536
Validation loss: 1.9349509926252468

Epoch: 6| Step: 11
Training loss: 2.1758501529693604
Validation loss: 1.933213956894413

Epoch: 6| Step: 12
Training loss: 2.5246191024780273
Validation loss: 1.9348461986869894

Epoch: 6| Step: 13
Training loss: 1.5670275688171387
Validation loss: 1.9435240453289402

Epoch: 137| Step: 0
Training loss: 1.7230736017227173
Validation loss: 1.9414331400266258

Epoch: 6| Step: 1
Training loss: 2.1054868698120117
Validation loss: 1.9438497815080868

Epoch: 6| Step: 2
Training loss: 2.1500515937805176
Validation loss: 1.948700527991018

Epoch: 6| Step: 3
Training loss: 2.74288272857666
Validation loss: 1.9605967331958074

Epoch: 6| Step: 4
Training loss: 2.3230371475219727
Validation loss: 1.9852351321968982

Epoch: 6| Step: 5
Training loss: 1.9350879192352295
Validation loss: 2.002213616524973

Epoch: 6| Step: 6
Training loss: 1.8873357772827148
Validation loss: 2.0610493306190736

Epoch: 6| Step: 7
Training loss: 2.3920950889587402
Validation loss: 2.090134902666974

Epoch: 6| Step: 8
Training loss: 2.124545097351074
Validation loss: 2.0871477050165974

Epoch: 6| Step: 9
Training loss: 2.2911431789398193
Validation loss: 2.0522701637719267

Epoch: 6| Step: 10
Training loss: 1.8236292600631714
Validation loss: 1.9911824400706957

Epoch: 6| Step: 11
Training loss: 2.2897372245788574
Validation loss: 1.9682026896425473

Epoch: 6| Step: 12
Training loss: 0.8094602823257446
Validation loss: 1.9777157716853644

Epoch: 6| Step: 13
Training loss: 1.6939260959625244
Validation loss: 1.9888584895800518

Epoch: 138| Step: 0
Training loss: 2.87174129486084
Validation loss: 1.9690173313181887

Epoch: 6| Step: 1
Training loss: 2.1744396686553955
Validation loss: 1.9663108446264779

Epoch: 6| Step: 2
Training loss: 1.5363861322402954
Validation loss: 1.9739037226605158

Epoch: 6| Step: 3
Training loss: 2.3856396675109863
Validation loss: 1.9889781526339951

Epoch: 6| Step: 4
Training loss: 1.4586576223373413
Validation loss: 1.9919035742359776

Epoch: 6| Step: 5
Training loss: 1.7766199111938477
Validation loss: 1.9621389271110616

Epoch: 6| Step: 6
Training loss: 2.0535802841186523
Validation loss: 1.9630145167791715

Epoch: 6| Step: 7
Training loss: 1.8942937850952148
Validation loss: 1.9560267168988463

Epoch: 6| Step: 8
Training loss: 1.8021808862686157
Validation loss: 1.9604924122492473

Epoch: 6| Step: 9
Training loss: 2.187098264694214
Validation loss: 1.9618844396324568

Epoch: 6| Step: 10
Training loss: 1.2260024547576904
Validation loss: 1.9412715229936826

Epoch: 6| Step: 11
Training loss: 2.2616326808929443
Validation loss: 1.947944466785718

Epoch: 6| Step: 12
Training loss: 2.1596503257751465
Validation loss: 1.9493744475867159

Epoch: 6| Step: 13
Training loss: 2.3803014755249023
Validation loss: 1.9774220617868568

Epoch: 139| Step: 0
Training loss: 2.01092529296875
Validation loss: 2.0571263503002863

Epoch: 6| Step: 1
Training loss: 1.9257129430770874
Validation loss: 2.087774781770604

Epoch: 6| Step: 2
Training loss: 2.5711216926574707
Validation loss: 2.1097090731384935

Epoch: 6| Step: 3
Training loss: 2.454622507095337
Validation loss: 2.089857033503953

Epoch: 6| Step: 4
Training loss: 2.192119598388672
Validation loss: 2.012756742456908

Epoch: 6| Step: 5
Training loss: 2.118694305419922
Validation loss: 1.96523271324814

Epoch: 6| Step: 6
Training loss: 1.6895321607589722
Validation loss: 1.9374041788039669

Epoch: 6| Step: 7
Training loss: 1.6164824962615967
Validation loss: 1.945477222883573

Epoch: 6| Step: 8
Training loss: 1.3978080749511719
Validation loss: 1.9475565469393166

Epoch: 6| Step: 9
Training loss: 1.6639823913574219
Validation loss: 1.9534175908693703

Epoch: 6| Step: 10
Training loss: 1.7392396926879883
Validation loss: 1.9320049080797421

Epoch: 6| Step: 11
Training loss: 1.364223837852478
Validation loss: 1.9338105327339583

Epoch: 6| Step: 12
Training loss: 2.9943253993988037
Validation loss: 1.9473204330731464

Epoch: 6| Step: 13
Training loss: 2.639869213104248
Validation loss: 1.9488812031284455

Epoch: 140| Step: 0
Training loss: 2.151283025741577
Validation loss: 1.9418212252278482

Epoch: 6| Step: 1
Training loss: 2.2376203536987305
Validation loss: 1.9734477253370388

Epoch: 6| Step: 2
Training loss: 1.9965003728866577
Validation loss: 1.9788705610459851

Epoch: 6| Step: 3
Training loss: 1.6961283683776855
Validation loss: 2.0048722041550504

Epoch: 6| Step: 4
Training loss: 1.8586705923080444
Validation loss: 2.0316086007702734

Epoch: 6| Step: 5
Training loss: 2.1236350536346436
Validation loss: 2.0171663594502274

Epoch: 6| Step: 6
Training loss: 2.177628517150879
Validation loss: 2.0247483945661977

Epoch: 6| Step: 7
Training loss: 1.2728480100631714
Validation loss: 2.0207615385773363

Epoch: 6| Step: 8
Training loss: 2.418186664581299
Validation loss: 2.054870702887094

Epoch: 6| Step: 9
Training loss: 1.9735374450683594
Validation loss: 2.092171246005643

Epoch: 6| Step: 10
Training loss: 2.0850255489349365
Validation loss: 2.1435112363548687

Epoch: 6| Step: 11
Training loss: 2.3369197845458984
Validation loss: 2.1683219248248684

Epoch: 6| Step: 12
Training loss: 1.9786911010742188
Validation loss: 2.150777050243911

Epoch: 6| Step: 13
Training loss: 2.3274693489074707
Validation loss: 2.1151485289296796

Epoch: 141| Step: 0
Training loss: 2.0813329219818115
Validation loss: 2.0376879451095418

Epoch: 6| Step: 1
Training loss: 2.600369930267334
Validation loss: 1.9813565079883864

Epoch: 6| Step: 2
Training loss: 1.753476858139038
Validation loss: 1.9456562380636893

Epoch: 6| Step: 3
Training loss: 2.288435935974121
Validation loss: 1.9464662536498039

Epoch: 6| Step: 4
Training loss: 1.7482433319091797
Validation loss: 1.9507822810962636

Epoch: 6| Step: 5
Training loss: 2.551003932952881
Validation loss: 1.9556988849434802

Epoch: 6| Step: 6
Training loss: 2.0111494064331055
Validation loss: 1.9658243874067902

Epoch: 6| Step: 7
Training loss: 2.767892360687256
Validation loss: 1.9444114777349657

Epoch: 6| Step: 8
Training loss: 1.4990229606628418
Validation loss: 1.9613825877507527

Epoch: 6| Step: 9
Training loss: 1.5667608976364136
Validation loss: 1.969347938414543

Epoch: 6| Step: 10
Training loss: 1.5548617839813232
Validation loss: 1.981071731095673

Epoch: 6| Step: 11
Training loss: 2.124875068664551
Validation loss: 2.004706394287848

Epoch: 6| Step: 12
Training loss: 1.5630823373794556
Validation loss: 2.0192504044502013

Epoch: 6| Step: 13
Training loss: 1.7906434535980225
Validation loss: 2.025420443986052

Epoch: 142| Step: 0
Training loss: 2.067014217376709
Validation loss: 2.0546081053313388

Epoch: 6| Step: 1
Training loss: 2.171382427215576
Validation loss: 2.0578896666085846

Epoch: 6| Step: 2
Training loss: 1.1877682209014893
Validation loss: 2.0618354646108483

Epoch: 6| Step: 3
Training loss: 1.535794973373413
Validation loss: 2.0590678953355357

Epoch: 6| Step: 4
Training loss: 2.6230077743530273
Validation loss: 2.049372103906447

Epoch: 6| Step: 5
Training loss: 2.257622718811035
Validation loss: 2.054183577978483

Epoch: 6| Step: 6
Training loss: 2.0441956520080566
Validation loss: 2.0277554347950923

Epoch: 6| Step: 7
Training loss: 2.075955629348755
Validation loss: 1.9796544223703363

Epoch: 6| Step: 8
Training loss: 1.549415111541748
Validation loss: 2.0174804169644593

Epoch: 6| Step: 9
Training loss: 1.7970367670059204
Validation loss: 1.9940115149303148

Epoch: 6| Step: 10
Training loss: 2.451215982437134
Validation loss: 1.9694271023555467

Epoch: 6| Step: 11
Training loss: 2.210693597793579
Validation loss: 1.9988830256205734

Epoch: 6| Step: 12
Training loss: 1.9864393472671509
Validation loss: 2.024354354027779

Epoch: 6| Step: 13
Training loss: 2.8730173110961914
Validation loss: 2.063459957799604

Epoch: 143| Step: 0
Training loss: 2.6350996494293213
Validation loss: 2.05903600364603

Epoch: 6| Step: 1
Training loss: 1.5297801494598389
Validation loss: 2.023446700906241

Epoch: 6| Step: 2
Training loss: 2.2851672172546387
Validation loss: 2.0124862091515654

Epoch: 6| Step: 3
Training loss: 2.161184310913086
Validation loss: 1.9816658330220047

Epoch: 6| Step: 4
Training loss: 1.992361307144165
Validation loss: 1.9505276449265019

Epoch: 6| Step: 5
Training loss: 2.1535825729370117
Validation loss: 1.9375862254891345

Epoch: 6| Step: 6
Training loss: 1.8138350248336792
Validation loss: 1.9307688154200071

Epoch: 6| Step: 7
Training loss: 1.8490322828292847
Validation loss: 1.9208591061253701

Epoch: 6| Step: 8
Training loss: 2.0361874103546143
Validation loss: 1.9119735571645922

Epoch: 6| Step: 9
Training loss: 2.281245231628418
Validation loss: 1.9157921524458035

Epoch: 6| Step: 10
Training loss: 1.7232491970062256
Validation loss: 1.9428374510939403

Epoch: 6| Step: 11
Training loss: 1.7946749925613403
Validation loss: 1.9226048864344114

Epoch: 6| Step: 12
Training loss: 2.430428981781006
Validation loss: 1.9353357271481586

Epoch: 6| Step: 13
Training loss: 2.255878448486328
Validation loss: 1.9836551630368797

Epoch: 144| Step: 0
Training loss: 1.582389235496521
Validation loss: 2.0328992541118334

Epoch: 6| Step: 1
Training loss: 1.4314448833465576
Validation loss: 2.033679485321045

Epoch: 6| Step: 2
Training loss: 2.7751784324645996
Validation loss: 2.05467277573001

Epoch: 6| Step: 3
Training loss: 2.1245651245117188
Validation loss: 2.009795376049575

Epoch: 6| Step: 4
Training loss: 2.357417106628418
Validation loss: 1.9586259088208597

Epoch: 6| Step: 5
Training loss: 1.6219420433044434
Validation loss: 1.9372229024928103

Epoch: 6| Step: 6
Training loss: 1.9443871974945068
Validation loss: 1.9151070053859423

Epoch: 6| Step: 7
Training loss: 1.8923792839050293
Validation loss: 1.9086799929218907

Epoch: 6| Step: 8
Training loss: 1.5493934154510498
Validation loss: 1.9174560821184548

Epoch: 6| Step: 9
Training loss: 2.54060697555542
Validation loss: 1.9205161333084106

Epoch: 6| Step: 10
Training loss: 1.6451857089996338
Validation loss: 1.9303965671088106

Epoch: 6| Step: 11
Training loss: 1.9224472045898438
Validation loss: 1.9496345161109843

Epoch: 6| Step: 12
Training loss: 2.4288790225982666
Validation loss: 1.9681256355777863

Epoch: 6| Step: 13
Training loss: 2.262115955352783
Validation loss: 2.006192902083038

Epoch: 145| Step: 0
Training loss: 2.1886520385742188
Validation loss: 1.9994719925747122

Epoch: 6| Step: 1
Training loss: 1.7638270854949951
Validation loss: 2.0046499211301088

Epoch: 6| Step: 2
Training loss: 2.2101480960845947
Validation loss: 2.0065156593117663

Epoch: 6| Step: 3
Training loss: 2.026733875274658
Validation loss: 2.022038067540815

Epoch: 6| Step: 4
Training loss: 2.018888473510742
Validation loss: 2.0452360696690057

Epoch: 6| Step: 5
Training loss: 1.8261581659317017
Validation loss: 2.051940107858309

Epoch: 6| Step: 6
Training loss: 1.7448052167892456
Validation loss: 2.0408567984898887

Epoch: 6| Step: 7
Training loss: 1.4311537742614746
Validation loss: 2.0082414586056947

Epoch: 6| Step: 8
Training loss: 1.9262137413024902
Validation loss: 1.9933988176366335

Epoch: 6| Step: 9
Training loss: 2.810235023498535
Validation loss: 1.989377244826286

Epoch: 6| Step: 10
Training loss: 2.16438627243042
Validation loss: 1.989906552017376

Epoch: 6| Step: 11
Training loss: 1.3082613945007324
Validation loss: 1.981412942691516

Epoch: 6| Step: 12
Training loss: 2.163719892501831
Validation loss: 1.9838691155115764

Epoch: 6| Step: 13
Training loss: 1.8967552185058594
Validation loss: 1.9924596125079739

Epoch: 146| Step: 0
Training loss: 1.749496579170227
Validation loss: 1.973102746471282

Epoch: 6| Step: 1
Training loss: 2.5868406295776367
Validation loss: 1.9920672485905309

Epoch: 6| Step: 2
Training loss: 2.050443649291992
Validation loss: 1.9855582252625497

Epoch: 6| Step: 3
Training loss: 2.00058913230896
Validation loss: 1.9720084641569404

Epoch: 6| Step: 4
Training loss: 2.27663254737854
Validation loss: 1.9804179283880419

Epoch: 6| Step: 5
Training loss: 2.320793390274048
Validation loss: 1.9642206520162604

Epoch: 6| Step: 6
Training loss: 1.725137710571289
Validation loss: 1.9787206765144103

Epoch: 6| Step: 7
Training loss: 2.060499429702759
Validation loss: 1.9641013017264746

Epoch: 6| Step: 8
Training loss: 2.056593894958496
Validation loss: 1.9595567269991803

Epoch: 6| Step: 9
Training loss: 1.8371944427490234
Validation loss: 1.954413644729122

Epoch: 6| Step: 10
Training loss: 1.2462191581726074
Validation loss: 1.9751459578032136

Epoch: 6| Step: 11
Training loss: 1.8726074695587158
Validation loss: 1.992516525330082

Epoch: 6| Step: 12
Training loss: 1.5715259313583374
Validation loss: 2.065469680293914

Epoch: 6| Step: 13
Training loss: 1.6943360567092896
Validation loss: 2.111650343864195

Epoch: 147| Step: 0
Training loss: 1.7732665538787842
Validation loss: 2.1022401214927755

Epoch: 6| Step: 1
Training loss: 1.2520060539245605
Validation loss: 2.0656629300886586

Epoch: 6| Step: 2
Training loss: 1.7365119457244873
Validation loss: 1.998343119057276

Epoch: 6| Step: 3
Training loss: 1.810774326324463
Validation loss: 1.9957409533121253

Epoch: 6| Step: 4
Training loss: 2.0149993896484375
Validation loss: 2.0193050702412925

Epoch: 6| Step: 5
Training loss: 1.5128941535949707
Validation loss: 2.038400052696146

Epoch: 6| Step: 6
Training loss: 2.1508572101593018
Validation loss: 2.041246665421353

Epoch: 6| Step: 7
Training loss: 1.8025315999984741
Validation loss: 2.049645029088502

Epoch: 6| Step: 8
Training loss: 2.0685830116271973
Validation loss: 2.0367560719931

Epoch: 6| Step: 9
Training loss: 2.6414966583251953
Validation loss: 2.02797031915316

Epoch: 6| Step: 10
Training loss: 2.5340685844421387
Validation loss: 2.023232134439612

Epoch: 6| Step: 11
Training loss: 2.0761196613311768
Validation loss: 2.0183021573610205

Epoch: 6| Step: 12
Training loss: 2.039212226867676
Validation loss: 2.0420399288977347

Epoch: 6| Step: 13
Training loss: 2.0022172927856445
Validation loss: 2.0383562810959353

Epoch: 148| Step: 0
Training loss: 1.7201848030090332
Validation loss: 2.0098707855388684

Epoch: 6| Step: 1
Training loss: 1.9316375255584717
Validation loss: 1.9723945433093655

Epoch: 6| Step: 2
Training loss: 1.6473942995071411
Validation loss: 1.9561783165060065

Epoch: 6| Step: 3
Training loss: 1.4740231037139893
Validation loss: 1.9629661447258406

Epoch: 6| Step: 4
Training loss: 2.5591676235198975
Validation loss: 1.9753458192271571

Epoch: 6| Step: 5
Training loss: 1.3412246704101562
Validation loss: 1.9808382757248417

Epoch: 6| Step: 6
Training loss: 2.255016326904297
Validation loss: 2.0096974552318616

Epoch: 6| Step: 7
Training loss: 2.3470654487609863
Validation loss: 1.9910790010165142

Epoch: 6| Step: 8
Training loss: 1.4640145301818848
Validation loss: 1.9593707105164886

Epoch: 6| Step: 9
Training loss: 2.199770927429199
Validation loss: 1.9529601322707308

Epoch: 6| Step: 10
Training loss: 2.371135950088501
Validation loss: 1.9360405437407955

Epoch: 6| Step: 11
Training loss: 1.6146304607391357
Validation loss: 1.9500853066803308

Epoch: 6| Step: 12
Training loss: 2.0819027423858643
Validation loss: 1.9600707971921532

Epoch: 6| Step: 13
Training loss: 1.625273585319519
Validation loss: 1.9500531419630973

Epoch: 149| Step: 0
Training loss: 0.9888750910758972
Validation loss: 1.9732691293121667

Epoch: 6| Step: 1
Training loss: 1.6457579135894775
Validation loss: 2.008440545810166

Epoch: 6| Step: 2
Training loss: 1.616431713104248
Validation loss: 2.0223598352042575

Epoch: 6| Step: 3
Training loss: 2.3555898666381836
Validation loss: 2.0513998077761744

Epoch: 6| Step: 4
Training loss: 1.924330472946167
Validation loss: 2.0737677133211525

Epoch: 6| Step: 5
Training loss: 2.0382494926452637
Validation loss: 2.045801167847008

Epoch: 6| Step: 6
Training loss: 2.025268793106079
Validation loss: 1.981739564608502

Epoch: 6| Step: 7
Training loss: 2.352205753326416
Validation loss: 1.9586830972343363

Epoch: 6| Step: 8
Training loss: 2.0816307067871094
Validation loss: 1.9440380463036158

Epoch: 6| Step: 9
Training loss: 1.9529142379760742
Validation loss: 1.9595996269615747

Epoch: 6| Step: 10
Training loss: 1.6490330696105957
Validation loss: 1.9598907296375563

Epoch: 6| Step: 11
Training loss: 1.9346389770507812
Validation loss: 1.9526987793625041

Epoch: 6| Step: 12
Training loss: 2.3024637699127197
Validation loss: 1.943861863946402

Epoch: 6| Step: 13
Training loss: 2.2797491550445557
Validation loss: 1.9437480485567482

Epoch: 150| Step: 0
Training loss: 1.4972048997879028
Validation loss: 1.9595099982394968

Epoch: 6| Step: 1
Training loss: 1.8180367946624756
Validation loss: 1.989682569298693

Epoch: 6| Step: 2
Training loss: 1.660898208618164
Validation loss: 2.054477260958764

Epoch: 6| Step: 3
Training loss: 2.0583105087280273
Validation loss: 2.1009384919238347

Epoch: 6| Step: 4
Training loss: 2.4424967765808105
Validation loss: 2.139725967120099

Epoch: 6| Step: 5
Training loss: 2.290304183959961
Validation loss: 2.1354742614171838

Epoch: 6| Step: 6
Training loss: 2.0909602642059326
Validation loss: 2.1529848191045944

Epoch: 6| Step: 7
Training loss: 2.037673234939575
Validation loss: 2.1348098529282438

Epoch: 6| Step: 8
Training loss: 1.6316146850585938
Validation loss: 2.081534356199285

Epoch: 6| Step: 9
Training loss: 2.256777763366699
Validation loss: 2.0292753865641933

Epoch: 6| Step: 10
Training loss: 2.7165298461914062
Validation loss: 2.0146841618322555

Epoch: 6| Step: 11
Training loss: 1.9299392700195312
Validation loss: 1.9953181384712138

Epoch: 6| Step: 12
Training loss: 1.0822687149047852
Validation loss: 1.9837577432714484

Epoch: 6| Step: 13
Training loss: 1.1718419790267944
Validation loss: 1.980357405959919

Epoch: 151| Step: 0
Training loss: 1.5357439517974854
Validation loss: 1.9863648606884865

Epoch: 6| Step: 1
Training loss: 1.6737456321716309
Validation loss: 1.9727578983511975

Epoch: 6| Step: 2
Training loss: 2.1474063396453857
Validation loss: 1.995286887691867

Epoch: 6| Step: 3
Training loss: 2.606809616088867
Validation loss: 1.9795762672219226

Epoch: 6| Step: 4
Training loss: 2.71687388420105
Validation loss: 2.0075531851860786

Epoch: 6| Step: 5
Training loss: 1.715584635734558
Validation loss: 1.9928851460897794

Epoch: 6| Step: 6
Training loss: 2.1022233963012695
Validation loss: 2.013908291375765

Epoch: 6| Step: 7
Training loss: 1.0715314149856567
Validation loss: 2.0460010292709514

Epoch: 6| Step: 8
Training loss: 1.357666254043579
Validation loss: 2.065132728186987

Epoch: 6| Step: 9
Training loss: 1.600017786026001
Validation loss: 2.0669085492369947

Epoch: 6| Step: 10
Training loss: 1.74835205078125
Validation loss: 2.069688481669272

Epoch: 6| Step: 11
Training loss: 1.9784542322158813
Validation loss: 2.0461555001556233

Epoch: 6| Step: 12
Training loss: 2.6412572860717773
Validation loss: 2.012296340798819

Epoch: 6| Step: 13
Training loss: 1.402475357055664
Validation loss: 1.9907236278698008

Epoch: 152| Step: 0
Training loss: 2.3064756393432617
Validation loss: 1.9884991722722207

Epoch: 6| Step: 1
Training loss: 2.673673629760742
Validation loss: 1.9906410453140095

Epoch: 6| Step: 2
Training loss: 1.8290934562683105
Validation loss: 1.9846280633762319

Epoch: 6| Step: 3
Training loss: 2.4558520317077637
Validation loss: 1.975128568628783

Epoch: 6| Step: 4
Training loss: 1.659670352935791
Validation loss: 1.9847834238442041

Epoch: 6| Step: 5
Training loss: 1.602405071258545
Validation loss: 1.9838707959780129

Epoch: 6| Step: 6
Training loss: 1.691099762916565
Validation loss: 1.996725223397696

Epoch: 6| Step: 7
Training loss: 1.0481234788894653
Validation loss: 2.0246944683854298

Epoch: 6| Step: 8
Training loss: 1.628783941268921
Validation loss: 2.056664656567317

Epoch: 6| Step: 9
Training loss: 1.916111946105957
Validation loss: 2.0298830847586355

Epoch: 6| Step: 10
Training loss: 2.238516330718994
Validation loss: 2.044672284075009

Epoch: 6| Step: 11
Training loss: 1.9868299961090088
Validation loss: 2.013036561268632

Epoch: 6| Step: 12
Training loss: 1.6897156238555908
Validation loss: 2.0182160280084096

Epoch: 6| Step: 13
Training loss: 1.6670424938201904
Validation loss: 2.0070533778077815

Epoch: 153| Step: 0
Training loss: 2.562620162963867
Validation loss: 2.012327383923274

Epoch: 6| Step: 1
Training loss: 1.7847578525543213
Validation loss: 2.0258063552200154

Epoch: 6| Step: 2
Training loss: 2.014040946960449
Validation loss: 2.0415478188504457

Epoch: 6| Step: 3
Training loss: 2.133472204208374
Validation loss: 2.038597624789002

Epoch: 6| Step: 4
Training loss: 1.6477959156036377
Validation loss: 1.9965072985618346

Epoch: 6| Step: 5
Training loss: 2.174252510070801
Validation loss: 2.007550867654944

Epoch: 6| Step: 6
Training loss: 2.285081386566162
Validation loss: 1.9697036512436406

Epoch: 6| Step: 7
Training loss: 2.1026816368103027
Validation loss: 1.9627575874328613

Epoch: 6| Step: 8
Training loss: 2.2057762145996094
Validation loss: 1.9732063585712063

Epoch: 6| Step: 9
Training loss: 2.0135092735290527
Validation loss: 1.994967068395307

Epoch: 6| Step: 10
Training loss: 1.6049082279205322
Validation loss: 2.0013860528187086

Epoch: 6| Step: 11
Training loss: 1.3250795602798462
Validation loss: 2.0142176561458136

Epoch: 6| Step: 12
Training loss: 1.4768917560577393
Validation loss: 2.011264383151967

Epoch: 6| Step: 13
Training loss: 0.9564075469970703
Validation loss: 1.9898429173295216

Epoch: 154| Step: 0
Training loss: 1.6949435472488403
Validation loss: 1.9805165003704768

Epoch: 6| Step: 1
Training loss: 1.6666429042816162
Validation loss: 1.9792797642369424

Epoch: 6| Step: 2
Training loss: 2.25561261177063
Validation loss: 1.993833803361462

Epoch: 6| Step: 3
Training loss: 1.8953804969787598
Validation loss: 1.9869525817132765

Epoch: 6| Step: 4
Training loss: 2.7365365028381348
Validation loss: 2.0096032542567097

Epoch: 6| Step: 5
Training loss: 1.9688276052474976
Validation loss: 2.025462829938499

Epoch: 6| Step: 6
Training loss: 1.9985872507095337
Validation loss: 1.9944573602368754

Epoch: 6| Step: 7
Training loss: 1.6678061485290527
Validation loss: 1.9736912788883332

Epoch: 6| Step: 8
Training loss: 2.3549911975860596
Validation loss: 1.9711837922373125

Epoch: 6| Step: 9
Training loss: 1.5512192249298096
Validation loss: 1.9701074246437318

Epoch: 6| Step: 10
Training loss: 1.4822235107421875
Validation loss: 1.9562709587876514

Epoch: 6| Step: 11
Training loss: 2.118502140045166
Validation loss: 1.9710056243404266

Epoch: 6| Step: 12
Training loss: 1.3119934797286987
Validation loss: 1.9870067963036158

Epoch: 6| Step: 13
Training loss: 1.4603381156921387
Validation loss: 2.03223337922045

Epoch: 155| Step: 0
Training loss: 1.5884296894073486
Validation loss: 2.070351195591752

Epoch: 6| Step: 1
Training loss: 2.5376179218292236
Validation loss: 2.0390634331651913

Epoch: 6| Step: 2
Training loss: 1.7147204875946045
Validation loss: 2.010497825120085

Epoch: 6| Step: 3
Training loss: 1.7317943572998047
Validation loss: 1.984980526790824

Epoch: 6| Step: 4
Training loss: 1.9968960285186768
Validation loss: 1.9746915909551805

Epoch: 6| Step: 5
Training loss: 1.8052462339401245
Validation loss: 1.9928078959065099

Epoch: 6| Step: 6
Training loss: 2.049022674560547
Validation loss: 1.9929327682782245

Epoch: 6| Step: 7
Training loss: 2.2145791053771973
Validation loss: 1.9936388333638508

Epoch: 6| Step: 8
Training loss: 1.0551267862319946
Validation loss: 1.995555249593591

Epoch: 6| Step: 9
Training loss: 2.4280998706817627
Validation loss: 1.9880843572719122

Epoch: 6| Step: 10
Training loss: 1.6494313478469849
Validation loss: 1.9760445266641595

Epoch: 6| Step: 11
Training loss: 1.8411487340927124
Validation loss: 1.9923171920161094

Epoch: 6| Step: 12
Training loss: 1.8385246992111206
Validation loss: 2.004635677542738

Epoch: 6| Step: 13
Training loss: 1.835896611213684
Validation loss: 2.010751034623833

Epoch: 156| Step: 0
Training loss: 1.8862848281860352
Validation loss: 2.04109981624029

Epoch: 6| Step: 1
Training loss: 2.0754659175872803
Validation loss: 2.074576647050919

Epoch: 6| Step: 2
Training loss: 1.4260880947113037
Validation loss: 2.083394208262044

Epoch: 6| Step: 3
Training loss: 1.786851406097412
Validation loss: 2.0523875169856574

Epoch: 6| Step: 4
Training loss: 2.011784076690674
Validation loss: 2.041851225719657

Epoch: 6| Step: 5
Training loss: 1.6945414543151855
Validation loss: 2.022691531847882

Epoch: 6| Step: 6
Training loss: 1.6322290897369385
Validation loss: 2.041983599303871

Epoch: 6| Step: 7
Training loss: 2.258495807647705
Validation loss: 2.0481577034919494

Epoch: 6| Step: 8
Training loss: 2.092179298400879
Validation loss: 2.078312050911688

Epoch: 6| Step: 9
Training loss: 2.5179738998413086
Validation loss: 2.086265604983094

Epoch: 6| Step: 10
Training loss: 2.2258481979370117
Validation loss: 2.0688262203688264

Epoch: 6| Step: 11
Training loss: 1.6157103776931763
Validation loss: 2.060473342095652

Epoch: 6| Step: 12
Training loss: 1.4237215518951416
Validation loss: 2.04894918780173

Epoch: 6| Step: 13
Training loss: 1.9472707509994507
Validation loss: 2.0459544466387842

Epoch: 157| Step: 0
Training loss: 2.0145912170410156
Validation loss: 2.0564099845065864

Epoch: 6| Step: 1
Training loss: 2.26474928855896
Validation loss: 2.008859298562491

Epoch: 6| Step: 2
Training loss: 2.4165167808532715
Validation loss: 1.9676458476692118

Epoch: 6| Step: 3
Training loss: 1.2551636695861816
Validation loss: 1.9462310678215438

Epoch: 6| Step: 4
Training loss: 1.8036749362945557
Validation loss: 1.9347259793230283

Epoch: 6| Step: 5
Training loss: 2.4449009895324707
Validation loss: 1.9508229045457737

Epoch: 6| Step: 6
Training loss: 2.351055860519409
Validation loss: 1.940007318732559

Epoch: 6| Step: 7
Training loss: 1.9788296222686768
Validation loss: 1.9579241455242198

Epoch: 6| Step: 8
Training loss: 1.7096248865127563
Validation loss: 1.9625319075840775

Epoch: 6| Step: 9
Training loss: 1.1379774808883667
Validation loss: 1.9672324926622453

Epoch: 6| Step: 10
Training loss: 2.285006284713745
Validation loss: 1.9564115052582116

Epoch: 6| Step: 11
Training loss: 1.8826651573181152
Validation loss: 1.9530872196279547

Epoch: 6| Step: 12
Training loss: 1.4536092281341553
Validation loss: 1.97470385284834

Epoch: 6| Step: 13
Training loss: 2.1798229217529297
Validation loss: 2.0031305564347135

Epoch: 158| Step: 0
Training loss: 1.401885747909546
Validation loss: 2.0182056247547107

Epoch: 6| Step: 1
Training loss: 2.0402939319610596
Validation loss: 2.0399869257403958

Epoch: 6| Step: 2
Training loss: 2.59112548828125
Validation loss: 2.0313664123576176

Epoch: 6| Step: 3
Training loss: 1.453711986541748
Validation loss: 2.026324942547788

Epoch: 6| Step: 4
Training loss: 1.910874843597412
Validation loss: 2.052139038680702

Epoch: 6| Step: 5
Training loss: 2.273320198059082
Validation loss: 2.1421388887589976

Epoch: 6| Step: 6
Training loss: 1.9099767208099365
Validation loss: 2.1650251444949897

Epoch: 6| Step: 7
Training loss: 1.9234035015106201
Validation loss: 2.1600966171551774

Epoch: 6| Step: 8
Training loss: 2.550053596496582
Validation loss: 2.1495061407807055

Epoch: 6| Step: 9
Training loss: 1.7399545907974243
Validation loss: 2.1111525527892576

Epoch: 6| Step: 10
Training loss: 1.514253854751587
Validation loss: 2.0540605539916665

Epoch: 6| Step: 11
Training loss: 1.9445829391479492
Validation loss: 2.0629399258603334

Epoch: 6| Step: 12
Training loss: 1.993652105331421
Validation loss: 2.0356923559660554

Epoch: 6| Step: 13
Training loss: 1.1069632768630981
Validation loss: 2.0106610072556363

Epoch: 159| Step: 0
Training loss: 2.1427087783813477
Validation loss: 1.9714041397135744

Epoch: 6| Step: 1
Training loss: 2.2058162689208984
Validation loss: 1.9689251120372484

Epoch: 6| Step: 2
Training loss: 2.1547882556915283
Validation loss: 1.9639717712197253

Epoch: 6| Step: 3
Training loss: 2.0674171447753906
Validation loss: 1.940254767735799

Epoch: 6| Step: 4
Training loss: 2.0734894275665283
Validation loss: 1.9302771296552432

Epoch: 6| Step: 5
Training loss: 1.936437964439392
Validation loss: 1.9200723017415693

Epoch: 6| Step: 6
Training loss: 1.1681067943572998
Validation loss: 1.922917245536722

Epoch: 6| Step: 7
Training loss: 2.2304446697235107
Validation loss: 1.910429823783136

Epoch: 6| Step: 8
Training loss: 1.5727676153182983
Validation loss: 1.9439443234474427

Epoch: 6| Step: 9
Training loss: 1.6128880977630615
Validation loss: 1.9767788366604877

Epoch: 6| Step: 10
Training loss: 1.9813345670700073
Validation loss: 1.9862779827528103

Epoch: 6| Step: 11
Training loss: 1.6324219703674316
Validation loss: 2.010700915449409

Epoch: 6| Step: 12
Training loss: 1.894162893295288
Validation loss: 2.0306093154415006

Epoch: 6| Step: 13
Training loss: 1.7173031568527222
Validation loss: 2.0530352489922636

Epoch: 160| Step: 0
Training loss: 1.7978732585906982
Validation loss: 2.0731065478376163

Epoch: 6| Step: 1
Training loss: 2.077777862548828
Validation loss: 2.07693862530493

Epoch: 6| Step: 2
Training loss: 1.5248284339904785
Validation loss: 2.0442946585275794

Epoch: 6| Step: 3
Training loss: 2.0629003047943115
Validation loss: 2.060098760871477

Epoch: 6| Step: 4
Training loss: 1.7991863489151
Validation loss: 2.108109063999627

Epoch: 6| Step: 5
Training loss: 1.5220507383346558
Validation loss: 2.1140439728254914

Epoch: 6| Step: 6
Training loss: 2.328275203704834
Validation loss: 2.1297850378098024

Epoch: 6| Step: 7
Training loss: 2.0354466438293457
Validation loss: 2.1231064437538065

Epoch: 6| Step: 8
Training loss: 1.3340837955474854
Validation loss: 2.1254726955967564

Epoch: 6| Step: 9
Training loss: 2.378615617752075
Validation loss: 2.0916551723275134

Epoch: 6| Step: 10
Training loss: 1.8421783447265625
Validation loss: 2.036834732178719

Epoch: 6| Step: 11
Training loss: 1.8913533687591553
Validation loss: 2.015418742292671

Epoch: 6| Step: 12
Training loss: 1.7668125629425049
Validation loss: 1.9699505554732455

Epoch: 6| Step: 13
Training loss: 1.6034575700759888
Validation loss: 1.9423609049089494

Epoch: 161| Step: 0
Training loss: 2.1956539154052734
Validation loss: 1.9252684834182903

Epoch: 6| Step: 1
Training loss: 2.140960216522217
Validation loss: 1.9338782359195013

Epoch: 6| Step: 2
Training loss: 1.8239600658416748
Validation loss: 1.9674129460447578

Epoch: 6| Step: 3
Training loss: 1.8678357601165771
Validation loss: 2.0051613366732033

Epoch: 6| Step: 4
Training loss: 1.6711249351501465
Validation loss: 2.0338242669259348

Epoch: 6| Step: 5
Training loss: 1.540156602859497
Validation loss: 2.0605213860029816

Epoch: 6| Step: 6
Training loss: 2.5556132793426514
Validation loss: 2.0642133118003927

Epoch: 6| Step: 7
Training loss: 1.4648343324661255
Validation loss: 2.0164268311633857

Epoch: 6| Step: 8
Training loss: 2.071329355239868
Validation loss: 1.9943077769330753

Epoch: 6| Step: 9
Training loss: 1.253720998764038
Validation loss: 1.9867217207467684

Epoch: 6| Step: 10
Training loss: 1.9226503372192383
Validation loss: 1.9707309892100673

Epoch: 6| Step: 11
Training loss: 2.0092005729675293
Validation loss: 1.9903798180241739

Epoch: 6| Step: 12
Training loss: 2.4741787910461426
Validation loss: 1.971990757091071

Epoch: 6| Step: 13
Training loss: 1.783982753753662
Validation loss: 2.0092494744126514

Epoch: 162| Step: 0
Training loss: 2.0393271446228027
Validation loss: 2.0180307306269163

Epoch: 6| Step: 1
Training loss: 1.9146355390548706
Validation loss: 2.0522578685514388

Epoch: 6| Step: 2
Training loss: 3.0219779014587402
Validation loss: 2.035496687376371

Epoch: 6| Step: 3
Training loss: 1.2884323596954346
Validation loss: 2.077948534360496

Epoch: 6| Step: 4
Training loss: 1.2026827335357666
Validation loss: 2.0493680148996334

Epoch: 6| Step: 5
Training loss: 1.7159154415130615
Validation loss: 2.02738376843032

Epoch: 6| Step: 6
Training loss: 2.262561321258545
Validation loss: 2.025056667225335

Epoch: 6| Step: 7
Training loss: 1.3838969469070435
Validation loss: 2.0226099004027662

Epoch: 6| Step: 8
Training loss: 2.130908966064453
Validation loss: 2.01806523594805

Epoch: 6| Step: 9
Training loss: 2.25551176071167
Validation loss: 2.008399014831871

Epoch: 6| Step: 10
Training loss: 1.7313017845153809
Validation loss: 1.9780866189669537

Epoch: 6| Step: 11
Training loss: 1.9139230251312256
Validation loss: 1.9717423556953348

Epoch: 6| Step: 12
Training loss: 1.3838034868240356
Validation loss: 1.9598654213772024

Epoch: 6| Step: 13
Training loss: 2.012526512145996
Validation loss: 1.9807510170885312

Epoch: 163| Step: 0
Training loss: 1.588036060333252
Validation loss: 2.010276843142766

Epoch: 6| Step: 1
Training loss: 1.2150599956512451
Validation loss: 2.0445521159838607

Epoch: 6| Step: 2
Training loss: 1.3344850540161133
Validation loss: 2.0862648564000286

Epoch: 6| Step: 3
Training loss: 2.1568446159362793
Validation loss: 2.0571639576265888

Epoch: 6| Step: 4
Training loss: 1.7966521978378296
Validation loss: 2.0091384969731814

Epoch: 6| Step: 5
Training loss: 1.6280851364135742
Validation loss: 1.9932144341930267

Epoch: 6| Step: 6
Training loss: 1.7425481081008911
Validation loss: 1.9606164732287008

Epoch: 6| Step: 7
Training loss: 1.6827163696289062
Validation loss: 1.9474766767153175

Epoch: 6| Step: 8
Training loss: 2.5695180892944336
Validation loss: 1.9540142731000019

Epoch: 6| Step: 9
Training loss: 1.5096781253814697
Validation loss: 1.94353683276843

Epoch: 6| Step: 10
Training loss: 1.7497000694274902
Validation loss: 1.9406008143578806

Epoch: 6| Step: 11
Training loss: 2.129587411880493
Validation loss: 1.9505310071411954

Epoch: 6| Step: 12
Training loss: 2.0153608322143555
Validation loss: 1.9861146942261727

Epoch: 6| Step: 13
Training loss: 2.520714521408081
Validation loss: 2.013830950183253

Epoch: 164| Step: 0
Training loss: 1.1050368547439575
Validation loss: 2.0792158495995308

Epoch: 6| Step: 1
Training loss: 1.8835951089859009
Validation loss: 2.139899625573107

Epoch: 6| Step: 2
Training loss: 1.846850872039795
Validation loss: 2.2062469131203106

Epoch: 6| Step: 3
Training loss: 2.07145357131958
Validation loss: 2.210040787214874

Epoch: 6| Step: 4
Training loss: 1.3769681453704834
Validation loss: 2.202588491542365

Epoch: 6| Step: 5
Training loss: 1.9464919567108154
Validation loss: 2.1505974005627375

Epoch: 6| Step: 6
Training loss: 1.6497986316680908
Validation loss: 2.067282147304986

Epoch: 6| Step: 7
Training loss: 1.203935980796814
Validation loss: 2.034382744501996

Epoch: 6| Step: 8
Training loss: 1.973111629486084
Validation loss: 2.0066075119920956

Epoch: 6| Step: 9
Training loss: 2.3404722213745117
Validation loss: 2.000228992072485

Epoch: 6| Step: 10
Training loss: 1.6359047889709473
Validation loss: 2.02106765777834

Epoch: 6| Step: 11
Training loss: 2.4043803215026855
Validation loss: 2.002910339704124

Epoch: 6| Step: 12
Training loss: 2.125204086303711
Validation loss: 1.978284482033022

Epoch: 6| Step: 13
Training loss: 1.7404003143310547
Validation loss: 1.9727038337338356

Epoch: 165| Step: 0
Training loss: 1.8290094137191772
Validation loss: 1.9688941996584657

Epoch: 6| Step: 1
Training loss: 2.1922712326049805
Validation loss: 1.9751340214924147

Epoch: 6| Step: 2
Training loss: 2.138882637023926
Validation loss: 1.977308577106845

Epoch: 6| Step: 3
Training loss: 2.1625797748565674
Validation loss: 1.9879290929404638

Epoch: 6| Step: 4
Training loss: 1.4107762575149536
Validation loss: 2.038272919193391

Epoch: 6| Step: 5
Training loss: 0.9156373143196106
Validation loss: 2.055711192469443

Epoch: 6| Step: 6
Training loss: 1.8443669080734253
Validation loss: 2.0708767957584833

Epoch: 6| Step: 7
Training loss: 2.338833808898926
Validation loss: 2.0632490752845682

Epoch: 6| Step: 8
Training loss: 2.0423672199249268
Validation loss: 2.0205329297691264

Epoch: 6| Step: 9
Training loss: 1.5245949029922485
Validation loss: 1.9803151520349647

Epoch: 6| Step: 10
Training loss: 2.010207176208496
Validation loss: 1.94531282301872

Epoch: 6| Step: 11
Training loss: 1.901236653327942
Validation loss: 1.9638462297378048

Epoch: 6| Step: 12
Training loss: 1.9634418487548828
Validation loss: 1.981062671189667

Epoch: 6| Step: 13
Training loss: 1.3570910692214966
Validation loss: 1.9737925311570526

Epoch: 166| Step: 0
Training loss: 1.5728421211242676
Validation loss: 1.9780218408953758

Epoch: 6| Step: 1
Training loss: 1.6508347988128662
Validation loss: 1.997386441435865

Epoch: 6| Step: 2
Training loss: 2.055560350418091
Validation loss: 1.9871544530314784

Epoch: 6| Step: 3
Training loss: 1.8926856517791748
Validation loss: 2.0170569432679044

Epoch: 6| Step: 4
Training loss: 1.5531662702560425
Validation loss: 2.0183417694542998

Epoch: 6| Step: 5
Training loss: 2.0063507556915283
Validation loss: 2.0422359230697795

Epoch: 6| Step: 6
Training loss: 1.945939064025879
Validation loss: 2.0478941804619244

Epoch: 6| Step: 7
Training loss: 1.9674606323242188
Validation loss: 2.103649259895407

Epoch: 6| Step: 8
Training loss: 2.3792455196380615
Validation loss: 2.1280140620405956

Epoch: 6| Step: 9
Training loss: 1.2328344583511353
Validation loss: 2.111342836451787

Epoch: 6| Step: 10
Training loss: 1.9878178834915161
Validation loss: 2.0930444066242506

Epoch: 6| Step: 11
Training loss: 1.0271902084350586
Validation loss: 2.068643787855743

Epoch: 6| Step: 12
Training loss: 1.537477731704712
Validation loss: 2.04026843783676

Epoch: 6| Step: 13
Training loss: 2.3218612670898438
Validation loss: 2.0087195557932698

Epoch: 167| Step: 0
Training loss: 1.502030611038208
Validation loss: 1.9856185528539843

Epoch: 6| Step: 1
Training loss: 2.347414016723633
Validation loss: 1.9882717722205705

Epoch: 6| Step: 2
Training loss: 1.8789689540863037
Validation loss: 2.0033355669308732

Epoch: 6| Step: 3
Training loss: 1.6311384439468384
Validation loss: 2.038876656563051

Epoch: 6| Step: 4
Training loss: 1.760572910308838
Validation loss: 2.032065277458519

Epoch: 6| Step: 5
Training loss: 2.11860990524292
Validation loss: 2.024859477114934

Epoch: 6| Step: 6
Training loss: 1.6331162452697754
Validation loss: 1.9964675275228356

Epoch: 6| Step: 7
Training loss: 1.6099460124969482
Validation loss: 1.9918237911757601

Epoch: 6| Step: 8
Training loss: 1.4224679470062256
Validation loss: 1.9906180943212202

Epoch: 6| Step: 9
Training loss: 2.3254356384277344
Validation loss: 1.9829732756460867

Epoch: 6| Step: 10
Training loss: 1.6304750442504883
Validation loss: 1.9840953183430496

Epoch: 6| Step: 11
Training loss: 1.7554887533187866
Validation loss: 1.9652490564571914

Epoch: 6| Step: 12
Training loss: 1.6564602851867676
Validation loss: 1.9870497129296745

Epoch: 6| Step: 13
Training loss: 1.8424146175384521
Validation loss: 1.9933479011699717

Epoch: 168| Step: 0
Training loss: 1.7759462594985962
Validation loss: 2.0035214244678454

Epoch: 6| Step: 1
Training loss: 2.2932534217834473
Validation loss: 2.00420517177992

Epoch: 6| Step: 2
Training loss: 2.365647315979004
Validation loss: 1.999598826131513

Epoch: 6| Step: 3
Training loss: 1.7124543190002441
Validation loss: 1.998654814176662

Epoch: 6| Step: 4
Training loss: 1.28121018409729
Validation loss: 1.9921535676525486

Epoch: 6| Step: 5
Training loss: 1.4690451622009277
Validation loss: 2.000242430676696

Epoch: 6| Step: 6
Training loss: 1.834995150566101
Validation loss: 1.9729969924496067

Epoch: 6| Step: 7
Training loss: 1.579972743988037
Validation loss: 1.9508261552420996

Epoch: 6| Step: 8
Training loss: 1.6180241107940674
Validation loss: 1.9468486065505652

Epoch: 6| Step: 9
Training loss: 2.021243095397949
Validation loss: 1.9504155523033553

Epoch: 6| Step: 10
Training loss: 1.8528952598571777
Validation loss: 2.0044144584286596

Epoch: 6| Step: 11
Training loss: 1.6702051162719727
Validation loss: 2.0356821590854275

Epoch: 6| Step: 12
Training loss: 1.7191483974456787
Validation loss: 2.1014901925158758

Epoch: 6| Step: 13
Training loss: 1.56639564037323
Validation loss: 2.157791317150157

Epoch: 169| Step: 0
Training loss: 1.7588378190994263
Validation loss: 2.244069130189957

Epoch: 6| Step: 1
Training loss: 1.9531748294830322
Validation loss: 2.2549749471807994

Epoch: 6| Step: 2
Training loss: 2.0397815704345703
Validation loss: 2.2072393919831965

Epoch: 6| Step: 3
Training loss: 1.6793031692504883
Validation loss: 2.1199564638958184

Epoch: 6| Step: 4
Training loss: 1.7033334970474243
Validation loss: 2.049146242039178

Epoch: 6| Step: 5
Training loss: 2.043599843978882
Validation loss: 2.0151529658225273

Epoch: 6| Step: 6
Training loss: 2.0639283657073975
Validation loss: 2.003142410709012

Epoch: 6| Step: 7
Training loss: 1.7594530582427979
Validation loss: 2.0007928058665287

Epoch: 6| Step: 8
Training loss: 1.8089791536331177
Validation loss: 2.003355021117836

Epoch: 6| Step: 9
Training loss: 1.9216196537017822
Validation loss: 1.982641153438117

Epoch: 6| Step: 10
Training loss: 1.5439645051956177
Validation loss: 1.9770718018213909

Epoch: 6| Step: 11
Training loss: 2.3240702152252197
Validation loss: 1.9606258035987936

Epoch: 6| Step: 12
Training loss: 1.794298768043518
Validation loss: 1.9496585553692234

Epoch: 6| Step: 13
Training loss: 1.4814711809158325
Validation loss: 1.9727796969875213

Epoch: 170| Step: 0
Training loss: 1.86362886428833
Validation loss: 2.0275324365144134

Epoch: 6| Step: 1
Training loss: 2.102734088897705
Validation loss: 2.0775748593832857

Epoch: 6| Step: 2
Training loss: 1.6259617805480957
Validation loss: 2.16079124840357

Epoch: 6| Step: 3
Training loss: 2.0899200439453125
Validation loss: 2.1475527953076106

Epoch: 6| Step: 4
Training loss: 1.708279013633728
Validation loss: 2.129606049547913

Epoch: 6| Step: 5
Training loss: 1.9180452823638916
Validation loss: 2.114405655091809

Epoch: 6| Step: 6
Training loss: 1.6251790523529053
Validation loss: 2.0764055277711604

Epoch: 6| Step: 7
Training loss: 2.4234704971313477
Validation loss: 2.0630294417822235

Epoch: 6| Step: 8
Training loss: 2.010280132293701
Validation loss: 2.0208298288365847

Epoch: 6| Step: 9
Training loss: 1.92124605178833
Validation loss: 2.030043177707221

Epoch: 6| Step: 10
Training loss: 1.3754984140396118
Validation loss: 2.0366248187198432

Epoch: 6| Step: 11
Training loss: 1.7803056240081787
Validation loss: 2.0477266696191605

Epoch: 6| Step: 12
Training loss: 1.9944391250610352
Validation loss: 2.050642118659071

Epoch: 6| Step: 13
Training loss: 1.3097484111785889
Validation loss: 2.0417915390383814

Epoch: 171| Step: 0
Training loss: 2.479482412338257
Validation loss: 2.0206236634203183

Epoch: 6| Step: 1
Training loss: 2.3402509689331055
Validation loss: 1.9936263868885655

Epoch: 6| Step: 2
Training loss: 1.4124118089675903
Validation loss: 1.941197354306457

Epoch: 6| Step: 3
Training loss: 1.6269958019256592
Validation loss: 1.9369790400228193

Epoch: 6| Step: 4
Training loss: 1.4939039945602417
Validation loss: 1.9178429418994534

Epoch: 6| Step: 5
Training loss: 1.935774326324463
Validation loss: 1.945098623152702

Epoch: 6| Step: 6
Training loss: 1.9444119930267334
Validation loss: 1.9757322534438102

Epoch: 6| Step: 7
Training loss: 1.3677842617034912
Validation loss: 2.0285680447855303

Epoch: 6| Step: 8
Training loss: 1.8830904960632324
Validation loss: 2.099202077875855

Epoch: 6| Step: 9
Training loss: 1.8452987670898438
Validation loss: 2.1927199773890997

Epoch: 6| Step: 10
Training loss: 2.29905366897583
Validation loss: 2.2773151295159453

Epoch: 6| Step: 11
Training loss: 1.7641252279281616
Validation loss: 2.260075589661957

Epoch: 6| Step: 12
Training loss: 1.4329562187194824
Validation loss: 2.2571822058769966

Epoch: 6| Step: 13
Training loss: 2.399881362915039
Validation loss: 2.2381555713633055

Epoch: 172| Step: 0
Training loss: 1.6805638074874878
Validation loss: 2.144301070961901

Epoch: 6| Step: 1
Training loss: 1.4357625246047974
Validation loss: 2.106170828624438

Epoch: 6| Step: 2
Training loss: 1.5461325645446777
Validation loss: 2.054776453202771

Epoch: 6| Step: 3
Training loss: 2.284191608428955
Validation loss: 2.015133644944878

Epoch: 6| Step: 4
Training loss: 1.5648815631866455
Validation loss: 2.0148005024079354

Epoch: 6| Step: 5
Training loss: 1.9470888376235962
Validation loss: 2.011865594053781

Epoch: 6| Step: 6
Training loss: 1.9186153411865234
Validation loss: 2.0222888082586308

Epoch: 6| Step: 7
Training loss: 2.0244174003601074
Validation loss: 1.9810740434995262

Epoch: 6| Step: 8
Training loss: 1.727578043937683
Validation loss: 1.9889456225979714

Epoch: 6| Step: 9
Training loss: 2.09840726852417
Validation loss: 1.9711633061849942

Epoch: 6| Step: 10
Training loss: 1.8430598974227905
Validation loss: 1.9436232146396433

Epoch: 6| Step: 11
Training loss: 1.7619948387145996
Validation loss: 1.9836163495176582

Epoch: 6| Step: 12
Training loss: 1.442143440246582
Validation loss: 2.033148956555192

Epoch: 6| Step: 13
Training loss: 1.8694169521331787
Validation loss: 2.0723506891599266

Epoch: 173| Step: 0
Training loss: 2.314683437347412
Validation loss: 2.1598465981022006

Epoch: 6| Step: 1
Training loss: 1.3969173431396484
Validation loss: 2.15569959404648

Epoch: 6| Step: 2
Training loss: 1.1703604459762573
Validation loss: 2.1262983481089273

Epoch: 6| Step: 3
Training loss: 2.218872308731079
Validation loss: 2.0840087372769593

Epoch: 6| Step: 4
Training loss: 2.070624351501465
Validation loss: 2.043304345941031

Epoch: 6| Step: 5
Training loss: 2.544963836669922
Validation loss: 2.00696280822959

Epoch: 6| Step: 6
Training loss: 1.7130966186523438
Validation loss: 1.9913972680286696

Epoch: 6| Step: 7
Training loss: 1.6628227233886719
Validation loss: 1.9900844276592295

Epoch: 6| Step: 8
Training loss: 1.9851651191711426
Validation loss: 1.9797387507654005

Epoch: 6| Step: 9
Training loss: 2.1306986808776855
Validation loss: 2.000475304101103

Epoch: 6| Step: 10
Training loss: 2.3418736457824707
Validation loss: 1.9916008826225036

Epoch: 6| Step: 11
Training loss: 1.0901364088058472
Validation loss: 2.0001977246294738

Epoch: 6| Step: 12
Training loss: 1.2569702863693237
Validation loss: 2.00439912913948

Epoch: 6| Step: 13
Training loss: 1.6498302221298218
Validation loss: 2.0167082560959684

Epoch: 174| Step: 0
Training loss: 1.5045409202575684
Validation loss: 2.0212256421325026

Epoch: 6| Step: 1
Training loss: 1.7457252740859985
Validation loss: 2.0431341919847714

Epoch: 6| Step: 2
Training loss: 1.5266400575637817
Validation loss: 2.0181061067888812

Epoch: 6| Step: 3
Training loss: 1.7549335956573486
Validation loss: 2.0018842092124363

Epoch: 6| Step: 4
Training loss: 1.7977783679962158
Validation loss: 1.9865248523732668

Epoch: 6| Step: 5
Training loss: 1.9119479656219482
Validation loss: 1.9561368509005475

Epoch: 6| Step: 6
Training loss: 1.5336296558380127
Validation loss: 1.9570629032709266

Epoch: 6| Step: 7
Training loss: 2.1842379570007324
Validation loss: 1.9464177136780114

Epoch: 6| Step: 8
Training loss: 2.046140670776367
Validation loss: 1.9460310512973416

Epoch: 6| Step: 9
Training loss: 1.6625170707702637
Validation loss: 1.95117151224485

Epoch: 6| Step: 10
Training loss: 1.7200329303741455
Validation loss: 1.9431791818270119

Epoch: 6| Step: 11
Training loss: 2.2445225715637207
Validation loss: 1.9518332789021153

Epoch: 6| Step: 12
Training loss: 0.8803398609161377
Validation loss: 1.96259932620551

Epoch: 6| Step: 13
Training loss: 1.920259952545166
Validation loss: 1.958031810739989

Epoch: 175| Step: 0
Training loss: 2.1022684574127197
Validation loss: 1.9231721470432896

Epoch: 6| Step: 1
Training loss: 1.6507360935211182
Validation loss: 1.9342630319697882

Epoch: 6| Step: 2
Training loss: 1.5603652000427246
Validation loss: 1.917093389777727

Epoch: 6| Step: 3
Training loss: 2.2567734718322754
Validation loss: 1.905637796207141

Epoch: 6| Step: 4
Training loss: 1.0742391347885132
Validation loss: 1.898309548695882

Epoch: 6| Step: 5
Training loss: 1.1112425327301025
Validation loss: 1.8987294294500863

Epoch: 6| Step: 6
Training loss: 1.9760456085205078
Validation loss: 1.915734455149661

Epoch: 6| Step: 7
Training loss: 1.8306177854537964
Validation loss: 1.9424816126464515

Epoch: 6| Step: 8
Training loss: 1.4410889148712158
Validation loss: 1.9549371324559695

Epoch: 6| Step: 9
Training loss: 2.1106534004211426
Validation loss: 2.0043687435888473

Epoch: 6| Step: 10
Training loss: 2.3643250465393066
Validation loss: 2.0466860353305774

Epoch: 6| Step: 11
Training loss: 1.6205013990402222
Validation loss: 2.120269621572187

Epoch: 6| Step: 12
Training loss: 1.5755853652954102
Validation loss: 2.1463521385705597

Epoch: 6| Step: 13
Training loss: 1.8090962171554565
Validation loss: 2.125297925805533

Epoch: 176| Step: 0
Training loss: 2.173792600631714
Validation loss: 2.0770863474056287

Epoch: 6| Step: 1
Training loss: 1.815138816833496
Validation loss: 2.056944006232805

Epoch: 6| Step: 2
Training loss: 1.711222767829895
Validation loss: 2.0314969093568864

Epoch: 6| Step: 3
Training loss: 1.5413711071014404
Validation loss: 2.0330126183007353

Epoch: 6| Step: 4
Training loss: 1.6515374183654785
Validation loss: 2.0378385384877524

Epoch: 6| Step: 5
Training loss: 1.403630256652832
Validation loss: 2.029649297396342

Epoch: 6| Step: 6
Training loss: 2.4881396293640137
Validation loss: 2.02858829498291

Epoch: 6| Step: 7
Training loss: 2.1612229347229004
Validation loss: 2.032746176565847

Epoch: 6| Step: 8
Training loss: 1.9580599069595337
Validation loss: 2.0531880906833115

Epoch: 6| Step: 9
Training loss: 1.6483380794525146
Validation loss: 2.0518786317558697

Epoch: 6| Step: 10
Training loss: 1.527879238128662
Validation loss: 2.0846337221002065

Epoch: 6| Step: 11
Training loss: 2.092458486557007
Validation loss: 2.09247766130714

Epoch: 6| Step: 12
Training loss: 1.3060481548309326
Validation loss: 2.099213091276025

Epoch: 6| Step: 13
Training loss: 1.3439096212387085
Validation loss: 2.1113130482294227

Epoch: 177| Step: 0
Training loss: 1.8152225017547607
Validation loss: 2.1159419013607885

Epoch: 6| Step: 1
Training loss: 1.8156949281692505
Validation loss: 2.0569419989021878

Epoch: 6| Step: 2
Training loss: 1.929758071899414
Validation loss: 2.0193206905036845

Epoch: 6| Step: 3
Training loss: 1.2499120235443115
Validation loss: 1.9725829247505433

Epoch: 6| Step: 4
Training loss: 1.9101431369781494
Validation loss: 1.9274290428366712

Epoch: 6| Step: 5
Training loss: 1.4063122272491455
Validation loss: 1.9101812685689619

Epoch: 6| Step: 6
Training loss: 2.221544027328491
Validation loss: 1.9134434769230504

Epoch: 6| Step: 7
Training loss: 2.191220760345459
Validation loss: 1.9254521990335116

Epoch: 6| Step: 8
Training loss: 1.0640136003494263
Validation loss: 1.9001869437515095

Epoch: 6| Step: 9
Training loss: 1.517716646194458
Validation loss: 1.9009216421393937

Epoch: 6| Step: 10
Training loss: 2.3290767669677734
Validation loss: 1.9156711127168389

Epoch: 6| Step: 11
Training loss: 1.8577771186828613
Validation loss: 1.9530677051954373

Epoch: 6| Step: 12
Training loss: 1.4519081115722656
Validation loss: 1.9700257085984754

Epoch: 6| Step: 13
Training loss: 1.6862874031066895
Validation loss: 2.0330070129004856

Epoch: 178| Step: 0
Training loss: 1.237913966178894
Validation loss: 2.0964125305093746

Epoch: 6| Step: 1
Training loss: 2.221789598464966
Validation loss: 2.1613962214480162

Epoch: 6| Step: 2
Training loss: 2.3534913063049316
Validation loss: 2.145176156874626

Epoch: 6| Step: 3
Training loss: 2.507204294204712
Validation loss: 2.1317385294104136

Epoch: 6| Step: 4
Training loss: 1.5274569988250732
Validation loss: 2.073186948735227

Epoch: 6| Step: 5
Training loss: 1.2991480827331543
Validation loss: 2.0382819291084044

Epoch: 6| Step: 6
Training loss: 1.3121436834335327
Validation loss: 1.986596586883709

Epoch: 6| Step: 7
Training loss: 1.887058973312378
Validation loss: 1.9687529276776057

Epoch: 6| Step: 8
Training loss: 1.6041967868804932
Validation loss: 1.9618843165777062

Epoch: 6| Step: 9
Training loss: 1.8378870487213135
Validation loss: 1.946388042101296

Epoch: 6| Step: 10
Training loss: 1.2075873613357544
Validation loss: 1.9482384753483597

Epoch: 6| Step: 11
Training loss: 2.3165817260742188
Validation loss: 1.9328830703612296

Epoch: 6| Step: 12
Training loss: 1.2611154317855835
Validation loss: 1.9149150431797068

Epoch: 6| Step: 13
Training loss: 2.5188701152801514
Validation loss: 1.9041877023635372

Epoch: 179| Step: 0
Training loss: 2.284221649169922
Validation loss: 1.9077993977454402

Epoch: 6| Step: 1
Training loss: 1.372446060180664
Validation loss: 1.9151054172105686

Epoch: 6| Step: 2
Training loss: 1.0699349641799927
Validation loss: 1.8933133553433161

Epoch: 6| Step: 3
Training loss: 2.055176258087158
Validation loss: 1.889990229760447

Epoch: 6| Step: 4
Training loss: 1.1031849384307861
Validation loss: 1.92162888280807

Epoch: 6| Step: 5
Training loss: 2.0620758533477783
Validation loss: 1.9393104430167907

Epoch: 6| Step: 6
Training loss: 1.1388572454452515
Validation loss: 1.9566311836242676

Epoch: 6| Step: 7
Training loss: 1.4838619232177734
Validation loss: 1.9961238086864512

Epoch: 6| Step: 8
Training loss: 1.838111400604248
Validation loss: 1.9987431546693206

Epoch: 6| Step: 9
Training loss: 1.7359097003936768
Validation loss: 2.0324654809890257

Epoch: 6| Step: 10
Training loss: 2.19802188873291
Validation loss: 2.0344569106255808

Epoch: 6| Step: 11
Training loss: 1.4290801286697388
Validation loss: 2.0007995661868843

Epoch: 6| Step: 12
Training loss: 2.000303030014038
Validation loss: 1.9927008908282045

Epoch: 6| Step: 13
Training loss: 1.8370620012283325
Validation loss: 1.998703090093469

Epoch: 180| Step: 0
Training loss: 1.8073391914367676
Validation loss: 1.9704979568399408

Epoch: 6| Step: 1
Training loss: 2.0152320861816406
Validation loss: 1.9627290720580726

Epoch: 6| Step: 2
Training loss: 2.109227180480957
Validation loss: 1.9373283437503281

Epoch: 6| Step: 3
Training loss: 1.5101059675216675
Validation loss: 1.951116269634616

Epoch: 6| Step: 4
Training loss: 1.3264055252075195
Validation loss: 1.9555320996110157

Epoch: 6| Step: 5
Training loss: 1.6353404521942139
Validation loss: 1.9552115240404684

Epoch: 6| Step: 6
Training loss: 2.165729522705078
Validation loss: 1.9741114301066245

Epoch: 6| Step: 7
Training loss: 2.2493319511413574
Validation loss: 1.9516243114266345

Epoch: 6| Step: 8
Training loss: 1.5533421039581299
Validation loss: 1.9617464991026028

Epoch: 6| Step: 9
Training loss: 1.6598997116088867
Validation loss: 1.9609725962403

Epoch: 6| Step: 10
Training loss: 1.2260255813598633
Validation loss: 1.9611510845922655

Epoch: 6| Step: 11
Training loss: 1.2959805727005005
Validation loss: 1.9722729805977113

Epoch: 6| Step: 12
Training loss: 1.6313469409942627
Validation loss: 1.9964174468030211

Epoch: 6| Step: 13
Training loss: 1.0855443477630615
Validation loss: 1.9865626032634447

Epoch: 181| Step: 0
Training loss: 1.5820001363754272
Validation loss: 1.987380822499593

Epoch: 6| Step: 1
Training loss: 2.5893337726593018
Validation loss: 1.9943498155122161

Epoch: 6| Step: 2
Training loss: 1.1705375909805298
Validation loss: 1.9787796376853861

Epoch: 6| Step: 3
Training loss: 1.5045496225357056
Validation loss: 1.9944784102901336

Epoch: 6| Step: 4
Training loss: 1.1858850717544556
Validation loss: 1.999694626818421

Epoch: 6| Step: 5
Training loss: 1.344523310661316
Validation loss: 1.986886703839866

Epoch: 6| Step: 6
Training loss: 1.8031853437423706
Validation loss: 1.9840131959607523

Epoch: 6| Step: 7
Training loss: 2.1658778190612793
Validation loss: 1.9626994056086386

Epoch: 6| Step: 8
Training loss: 1.3463859558105469
Validation loss: 1.966525234201903

Epoch: 6| Step: 9
Training loss: 1.633070468902588
Validation loss: 1.9428688441553423

Epoch: 6| Step: 10
Training loss: 1.4965436458587646
Validation loss: 1.9328379887406544

Epoch: 6| Step: 11
Training loss: 1.8710193634033203
Validation loss: 1.9047614425741217

Epoch: 6| Step: 12
Training loss: 1.9221616983413696
Validation loss: 1.9107940709719093

Epoch: 6| Step: 13
Training loss: 1.958254098892212
Validation loss: 1.8985168267321844

Epoch: 182| Step: 0
Training loss: 1.139681100845337
Validation loss: 1.914464432706115

Epoch: 6| Step: 1
Training loss: 1.1217646598815918
Validation loss: 1.9361059204224618

Epoch: 6| Step: 2
Training loss: 2.39951491355896
Validation loss: 1.943000985730079

Epoch: 6| Step: 3
Training loss: 2.076948642730713
Validation loss: 2.000096821015881

Epoch: 6| Step: 4
Training loss: 1.8155087232589722
Validation loss: 2.0000668956387426

Epoch: 6| Step: 5
Training loss: 1.3461204767227173
Validation loss: 1.9793336916995306

Epoch: 6| Step: 6
Training loss: 1.7525694370269775
Validation loss: 1.9506447122943016

Epoch: 6| Step: 7
Training loss: 1.8376532793045044
Validation loss: 1.9249163353314964

Epoch: 6| Step: 8
Training loss: 1.3667211532592773
Validation loss: 1.9147030409946237

Epoch: 6| Step: 9
Training loss: 2.734719753265381
Validation loss: 1.9182326960307297

Epoch: 6| Step: 10
Training loss: 0.9314883947372437
Validation loss: 1.9072962563524964

Epoch: 6| Step: 11
Training loss: 1.6239538192749023
Validation loss: 1.9224818432202904

Epoch: 6| Step: 12
Training loss: 1.4563509225845337
Validation loss: 1.9515430094093404

Epoch: 6| Step: 13
Training loss: 1.4451403617858887
Validation loss: 1.9580466221737605

Epoch: 183| Step: 0
Training loss: 1.4201117753982544
Validation loss: 2.005645300752373

Epoch: 6| Step: 1
Training loss: 2.2715659141540527
Validation loss: 2.0658357322856946

Epoch: 6| Step: 2
Training loss: 1.8451229333877563
Validation loss: 2.1121151857478644

Epoch: 6| Step: 3
Training loss: 1.6730846166610718
Validation loss: 2.0973538147505892

Epoch: 6| Step: 4
Training loss: 1.8958075046539307
Validation loss: 2.0987884190774735

Epoch: 6| Step: 5
Training loss: 2.172084093093872
Validation loss: 2.068190501582238

Epoch: 6| Step: 6
Training loss: 1.3567485809326172
Validation loss: 2.0427181361823954

Epoch: 6| Step: 7
Training loss: 1.8167628049850464
Validation loss: 1.9975954832569245

Epoch: 6| Step: 8
Training loss: 1.1359210014343262
Validation loss: 1.9751827332281298

Epoch: 6| Step: 9
Training loss: 2.2163891792297363
Validation loss: 1.9599927010074738

Epoch: 6| Step: 10
Training loss: 1.6015207767486572
Validation loss: 1.9583853239654212

Epoch: 6| Step: 11
Training loss: 1.2528820037841797
Validation loss: 1.9373615121328702

Epoch: 6| Step: 12
Training loss: 1.4290552139282227
Validation loss: 1.9735091552939465

Epoch: 6| Step: 13
Training loss: 1.1520887613296509
Validation loss: 1.9551973163440663

Epoch: 184| Step: 0
Training loss: 1.397873878479004
Validation loss: 1.938473960404755

Epoch: 6| Step: 1
Training loss: 1.653102159500122
Validation loss: 1.944508873006349

Epoch: 6| Step: 2
Training loss: 1.6999833583831787
Validation loss: 1.9289557549261278

Epoch: 6| Step: 3
Training loss: 2.263206958770752
Validation loss: 1.9426012090457383

Epoch: 6| Step: 4
Training loss: 1.2940726280212402
Validation loss: 1.9031656378058976

Epoch: 6| Step: 5
Training loss: 0.4620160162448883
Validation loss: 1.932310232552149

Epoch: 6| Step: 6
Training loss: 2.1962013244628906
Validation loss: 1.9566971922433505

Epoch: 6| Step: 7
Training loss: 1.2933225631713867
Validation loss: 1.9654651457263577

Epoch: 6| Step: 8
Training loss: 2.191634178161621
Validation loss: 1.9702914376412668

Epoch: 6| Step: 9
Training loss: 1.6555774211883545
Validation loss: 1.9562659801975373

Epoch: 6| Step: 10
Training loss: 1.4843318462371826
Validation loss: 1.9835716306522329

Epoch: 6| Step: 11
Training loss: 1.4565129280090332
Validation loss: 1.9635939059718963

Epoch: 6| Step: 12
Training loss: 2.201792001724243
Validation loss: 1.9733871298451577

Epoch: 6| Step: 13
Training loss: 1.3914375305175781
Validation loss: 1.9669857794238674

Epoch: 185| Step: 0
Training loss: 2.401604652404785
Validation loss: 1.9576578204349806

Epoch: 6| Step: 1
Training loss: 1.387770652770996
Validation loss: 1.9749787212699972

Epoch: 6| Step: 2
Training loss: 1.1013922691345215
Validation loss: 1.978880702808339

Epoch: 6| Step: 3
Training loss: 1.6105170249938965
Validation loss: 1.9392309560570666

Epoch: 6| Step: 4
Training loss: 0.929438591003418
Validation loss: 1.9317384150720411

Epoch: 6| Step: 5
Training loss: 1.1731936931610107
Validation loss: 1.9191521726628786

Epoch: 6| Step: 6
Training loss: 1.5986641645431519
Validation loss: 1.887057759428537

Epoch: 6| Step: 7
Training loss: 2.1621339321136475
Validation loss: 1.878999912610618

Epoch: 6| Step: 8
Training loss: 1.7322719097137451
Validation loss: 1.8604045708974202

Epoch: 6| Step: 9
Training loss: 1.3631234169006348
Validation loss: 1.8805407260053901

Epoch: 6| Step: 10
Training loss: 1.4445102214813232
Validation loss: 1.8751119836684196

Epoch: 6| Step: 11
Training loss: 2.367487907409668
Validation loss: 1.896627362056445

Epoch: 6| Step: 12
Training loss: 1.7412062883377075
Validation loss: 1.972647342630612

Epoch: 6| Step: 13
Training loss: 1.655770182609558
Validation loss: 2.040300835845291

Epoch: 186| Step: 0
Training loss: 1.489323377609253
Validation loss: 2.0399091307834913

Epoch: 6| Step: 1
Training loss: 1.771340250968933
Validation loss: 2.0362901149257535

Epoch: 6| Step: 2
Training loss: 1.1743355989456177
Validation loss: 1.9800555834206202

Epoch: 6| Step: 3
Training loss: 1.8647977113723755
Validation loss: 1.9195488293965657

Epoch: 6| Step: 4
Training loss: 1.5376851558685303
Validation loss: 1.9036924672383133

Epoch: 6| Step: 5
Training loss: 1.833078145980835
Validation loss: 1.9015446785957582

Epoch: 6| Step: 6
Training loss: 1.4152768850326538
Validation loss: 1.9141865353430472

Epoch: 6| Step: 7
Training loss: 1.6970041990280151
Validation loss: 1.909778054042529

Epoch: 6| Step: 8
Training loss: 1.2996774911880493
Validation loss: 1.9257019360860188

Epoch: 6| Step: 9
Training loss: 1.5921274423599243
Validation loss: 1.9493098233335762

Epoch: 6| Step: 10
Training loss: 1.5415780544281006
Validation loss: 1.9867581205983316

Epoch: 6| Step: 11
Training loss: 1.3837780952453613
Validation loss: 2.0392835717047415

Epoch: 6| Step: 12
Training loss: 2.504160165786743
Validation loss: 2.104353553505354

Epoch: 6| Step: 13
Training loss: 2.2647593021392822
Validation loss: 2.0702161724849413

Epoch: 187| Step: 0
Training loss: 1.876602053642273
Validation loss: 2.0052473365619616

Epoch: 6| Step: 1
Training loss: 1.8506596088409424
Validation loss: 1.9522499730510097

Epoch: 6| Step: 2
Training loss: 1.4892175197601318
Validation loss: 1.9346330858046008

Epoch: 6| Step: 3
Training loss: 1.7669179439544678
Validation loss: 1.9166302578423613

Epoch: 6| Step: 4
Training loss: 1.8295060396194458
Validation loss: 1.8977111744624313

Epoch: 6| Step: 5
Training loss: 1.1202049255371094
Validation loss: 1.9076134004900533

Epoch: 6| Step: 6
Training loss: 2.0030336380004883
Validation loss: 1.917369540019702

Epoch: 6| Step: 7
Training loss: 1.5128673315048218
Validation loss: 1.9190050555813698

Epoch: 6| Step: 8
Training loss: 1.9184850454330444
Validation loss: 1.95667463989668

Epoch: 6| Step: 9
Training loss: 1.240443468093872
Validation loss: 2.0008489829237743

Epoch: 6| Step: 10
Training loss: 1.821724772453308
Validation loss: 2.014095124377999

Epoch: 6| Step: 11
Training loss: 1.3192203044891357
Validation loss: 1.9784045629603888

Epoch: 6| Step: 12
Training loss: 1.1007723808288574
Validation loss: 1.9584364737233808

Epoch: 6| Step: 13
Training loss: 2.231328010559082
Validation loss: 1.92171444431428

Epoch: 188| Step: 0
Training loss: 1.999733328819275
Validation loss: 1.9185119751961

Epoch: 6| Step: 1
Training loss: 0.7871559858322144
Validation loss: 1.8888864876121603

Epoch: 6| Step: 2
Training loss: 1.6176586151123047
Validation loss: 1.8891397124977523

Epoch: 6| Step: 3
Training loss: 1.5638036727905273
Validation loss: 1.88189790069416

Epoch: 6| Step: 4
Training loss: 2.3171544075012207
Validation loss: 1.9007034558121876

Epoch: 6| Step: 5
Training loss: 2.2814297676086426
Validation loss: 1.9248751440355856

Epoch: 6| Step: 6
Training loss: 1.1558935642242432
Validation loss: 1.90944762896466

Epoch: 6| Step: 7
Training loss: 1.3723289966583252
Validation loss: 1.9390229127740348

Epoch: 6| Step: 8
Training loss: 1.3261970281600952
Validation loss: 1.9483594548317693

Epoch: 6| Step: 9
Training loss: 1.9823646545410156
Validation loss: 1.967740430626818

Epoch: 6| Step: 10
Training loss: 1.2773292064666748
Validation loss: 1.9625099205201673

Epoch: 6| Step: 11
Training loss: 1.5933680534362793
Validation loss: 1.9358654227308048

Epoch: 6| Step: 12
Training loss: 1.5599753856658936
Validation loss: 1.8954372252187421

Epoch: 6| Step: 13
Training loss: 1.8438606262207031
Validation loss: 1.8959943902107976

Epoch: 189| Step: 0
Training loss: 1.5392988920211792
Validation loss: 1.8895037840771418

Epoch: 6| Step: 1
Training loss: 0.9607558846473694
Validation loss: 1.888837319548412

Epoch: 6| Step: 2
Training loss: 1.0127310752868652
Validation loss: 1.8806259465473953

Epoch: 6| Step: 3
Training loss: 1.5181992053985596
Validation loss: 1.9104319169957151

Epoch: 6| Step: 4
Training loss: 1.9010140895843506
Validation loss: 1.9213945698994461

Epoch: 6| Step: 5
Training loss: 1.2543983459472656
Validation loss: 1.955024903820407

Epoch: 6| Step: 6
Training loss: 2.3917200565338135
Validation loss: 1.962880120482496

Epoch: 6| Step: 7
Training loss: 1.593189001083374
Validation loss: 1.9658309631450201

Epoch: 6| Step: 8
Training loss: 0.984502375125885
Validation loss: 1.9753379667958906

Epoch: 6| Step: 9
Training loss: 2.0155439376831055
Validation loss: 1.9942372229791456

Epoch: 6| Step: 10
Training loss: 2.5411627292633057
Validation loss: 2.024694373530726

Epoch: 6| Step: 11
Training loss: 1.3239686489105225
Validation loss: 2.0387731341905493

Epoch: 6| Step: 12
Training loss: 1.5325227975845337
Validation loss: 2.064715116254745

Epoch: 6| Step: 13
Training loss: 1.3613427877426147
Validation loss: 2.0637588577885784

Epoch: 190| Step: 0
Training loss: 1.3572607040405273
Validation loss: 2.043866039604269

Epoch: 6| Step: 1
Training loss: 1.714187741279602
Validation loss: 2.011299588346994

Epoch: 6| Step: 2
Training loss: 1.4565675258636475
Validation loss: 1.9772202955779208

Epoch: 6| Step: 3
Training loss: 1.909399390220642
Validation loss: 1.9383582530483123

Epoch: 6| Step: 4
Training loss: 0.7757912278175354
Validation loss: 1.9042885790589035

Epoch: 6| Step: 5
Training loss: 1.6936168670654297
Validation loss: 1.8957257360540412

Epoch: 6| Step: 6
Training loss: 1.305372953414917
Validation loss: 1.906193584524175

Epoch: 6| Step: 7
Training loss: 1.9025771617889404
Validation loss: 1.8990656996286044

Epoch: 6| Step: 8
Training loss: 1.3678807020187378
Validation loss: 1.8918893388522569

Epoch: 6| Step: 9
Training loss: 3.1351401805877686
Validation loss: 1.918389561355755

Epoch: 6| Step: 10
Training loss: 1.6143865585327148
Validation loss: 1.9769274983354794

Epoch: 6| Step: 11
Training loss: 1.1760027408599854
Validation loss: 2.0159914916561497

Epoch: 6| Step: 12
Training loss: 1.5568854808807373
Validation loss: 2.0178431003324446

Epoch: 6| Step: 13
Training loss: 1.0001232624053955
Validation loss: 2.008448084195455

Epoch: 191| Step: 0
Training loss: 1.8120185136795044
Validation loss: 1.9719669024149578

Epoch: 6| Step: 1
Training loss: 1.5306837558746338
Validation loss: 1.9176640728468537

Epoch: 6| Step: 2
Training loss: 1.6239349842071533
Validation loss: 1.9067313030201902

Epoch: 6| Step: 3
Training loss: 2.073896884918213
Validation loss: 1.9099930717099098

Epoch: 6| Step: 4
Training loss: 1.5472036600112915
Validation loss: 1.9258912032650364

Epoch: 6| Step: 5
Training loss: 1.4079419374465942
Validation loss: 1.9537307652094031

Epoch: 6| Step: 6
Training loss: 1.6294538974761963
Validation loss: 1.9476467383805143

Epoch: 6| Step: 7
Training loss: 1.4250695705413818
Validation loss: 1.9688781448589858

Epoch: 6| Step: 8
Training loss: 1.8399784564971924
Validation loss: 1.9811954780291485

Epoch: 6| Step: 9
Training loss: 1.3129690885543823
Validation loss: 1.9494642673000213

Epoch: 6| Step: 10
Training loss: 1.2645320892333984
Validation loss: 1.9580900592188681

Epoch: 6| Step: 11
Training loss: 2.0392727851867676
Validation loss: 1.9455812823387884

Epoch: 6| Step: 12
Training loss: 1.0966475009918213
Validation loss: 1.9512356917063396

Epoch: 6| Step: 13
Training loss: 0.8403671979904175
Validation loss: 1.954812607457561

Epoch: 192| Step: 0
Training loss: 1.5726933479309082
Validation loss: 2.01347876492367

Epoch: 6| Step: 1
Training loss: 1.758011817932129
Validation loss: 2.0640967994607906

Epoch: 6| Step: 2
Training loss: 1.591468095779419
Validation loss: 2.077193287111098

Epoch: 6| Step: 3
Training loss: 1.9158625602722168
Validation loss: 2.04277785875464

Epoch: 6| Step: 4
Training loss: 1.2030093669891357
Validation loss: 1.9847684880738616

Epoch: 6| Step: 5
Training loss: 1.5711643695831299
Validation loss: 1.9047270872259652

Epoch: 6| Step: 6
Training loss: 0.9979602098464966
Validation loss: 1.8767452701445548

Epoch: 6| Step: 7
Training loss: 1.725013256072998
Validation loss: 1.8550703628088838

Epoch: 6| Step: 8
Training loss: 2.108675003051758
Validation loss: 1.8423735044335807

Epoch: 6| Step: 9
Training loss: 2.195878744125366
Validation loss: 1.8388805261222265

Epoch: 6| Step: 10
Training loss: 1.6546850204467773
Validation loss: 1.812557722932549

Epoch: 6| Step: 11
Training loss: 1.7672152519226074
Validation loss: 1.849770599795926

Epoch: 6| Step: 12
Training loss: 1.4337728023529053
Validation loss: 1.8497048616409302

Epoch: 6| Step: 13
Training loss: 1.8181424140930176
Validation loss: 1.8922309516578593

Epoch: 193| Step: 0
Training loss: 1.7657784223556519
Validation loss: 2.007078460467759

Epoch: 6| Step: 1
Training loss: 0.8952224850654602
Validation loss: 2.0881020394704675

Epoch: 6| Step: 2
Training loss: 1.9684754610061646
Validation loss: 2.0997921677045923

Epoch: 6| Step: 3
Training loss: 1.9525755643844604
Validation loss: 2.096246225859529

Epoch: 6| Step: 4
Training loss: 1.4873957633972168
Validation loss: 2.037081544117261

Epoch: 6| Step: 5
Training loss: 2.04593825340271
Validation loss: 1.9762393351524108

Epoch: 6| Step: 6
Training loss: 1.2925865650177002
Validation loss: 1.9498809742671188

Epoch: 6| Step: 7
Training loss: 1.905748963356018
Validation loss: 1.9399302108313448

Epoch: 6| Step: 8
Training loss: 1.3559107780456543
Validation loss: 1.933360574065998

Epoch: 6| Step: 9
Training loss: 2.222362995147705
Validation loss: 1.9609039906532533

Epoch: 6| Step: 10
Training loss: 1.985949158668518
Validation loss: 1.9374565783367361

Epoch: 6| Step: 11
Training loss: 2.0539417266845703
Validation loss: 1.9226519446219168

Epoch: 6| Step: 12
Training loss: 2.17684268951416
Validation loss: 1.9071961756675475

Epoch: 6| Step: 13
Training loss: 0.610156774520874
Validation loss: 1.891363871994839

Epoch: 194| Step: 0
Training loss: 1.6652870178222656
Validation loss: 1.9178010879024383

Epoch: 6| Step: 1
Training loss: 2.22236967086792
Validation loss: 2.0081528514944096

Epoch: 6| Step: 2
Training loss: 1.8685898780822754
Validation loss: 2.0904793893137286

Epoch: 6| Step: 3
Training loss: 1.4026408195495605
Validation loss: 2.1563455725228913

Epoch: 6| Step: 4
Training loss: 1.238999605178833
Validation loss: 2.1704893676183556

Epoch: 6| Step: 5
Training loss: 2.017746925354004
Validation loss: 2.157081752695063

Epoch: 6| Step: 6
Training loss: 0.8554672002792358
Validation loss: 2.080851206215479

Epoch: 6| Step: 7
Training loss: 1.9288749694824219
Validation loss: 1.9524118438843758

Epoch: 6| Step: 8
Training loss: 1.649099349975586
Validation loss: 1.91216492396529

Epoch: 6| Step: 9
Training loss: 1.7485558986663818
Validation loss: 1.8465416457063408

Epoch: 6| Step: 10
Training loss: 1.4807713031768799
Validation loss: 1.8546931346257527

Epoch: 6| Step: 11
Training loss: 1.6031079292297363
Validation loss: 1.8528287872191398

Epoch: 6| Step: 12
Training loss: 2.228043794631958
Validation loss: 1.8508027535612865

Epoch: 6| Step: 13
Training loss: 2.0256381034851074
Validation loss: 1.8636142233366608

Epoch: 195| Step: 0
Training loss: 2.017866611480713
Validation loss: 1.85288703954348

Epoch: 6| Step: 1
Training loss: 2.0766358375549316
Validation loss: 1.8526252495345248

Epoch: 6| Step: 2
Training loss: 1.8859689235687256
Validation loss: 1.834969397514097

Epoch: 6| Step: 3
Training loss: 1.344428300857544
Validation loss: 1.823416979082169

Epoch: 6| Step: 4
Training loss: 1.5376465320587158
Validation loss: 1.8693661305212206

Epoch: 6| Step: 5
Training loss: 1.8221700191497803
Validation loss: 1.8920996740300169

Epoch: 6| Step: 6
Training loss: 1.6950905323028564
Validation loss: 1.9694435801557315

Epoch: 6| Step: 7
Training loss: 1.9247440099716187
Validation loss: 2.00614869722756

Epoch: 6| Step: 8
Training loss: 1.2262327671051025
Validation loss: 2.0774219471921205

Epoch: 6| Step: 9
Training loss: 1.4201089143753052
Validation loss: 2.0880845208321848

Epoch: 6| Step: 10
Training loss: 1.986765742301941
Validation loss: 2.0776457030286073

Epoch: 6| Step: 11
Training loss: 1.8046919107437134
Validation loss: 2.0559856058448873

Epoch: 6| Step: 12
Training loss: 1.3666975498199463
Validation loss: 1.9954455373107747

Epoch: 6| Step: 13
Training loss: 0.6738335490226746
Validation loss: 1.9776634375254314

Epoch: 196| Step: 0
Training loss: 1.3946605920791626
Validation loss: 1.930210034052531

Epoch: 6| Step: 1
Training loss: 2.1932644844055176
Validation loss: 1.9049479358939714

Epoch: 6| Step: 2
Training loss: 1.3830441236495972
Validation loss: 1.9380480525314168

Epoch: 6| Step: 3
Training loss: 1.4313077926635742
Validation loss: 1.9064425806845389

Epoch: 6| Step: 4
Training loss: 1.535125970840454
Validation loss: 1.9182139186448948

Epoch: 6| Step: 5
Training loss: 1.3403111696243286
Validation loss: 1.936329972359442

Epoch: 6| Step: 6
Training loss: 1.810671091079712
Validation loss: 1.956215480322479

Epoch: 6| Step: 7
Training loss: 1.7506710290908813
Validation loss: 1.984568440785972

Epoch: 6| Step: 8
Training loss: 1.880470871925354
Validation loss: 1.9820058332976473

Epoch: 6| Step: 9
Training loss: 1.450810432434082
Validation loss: 2.0025438236933883

Epoch: 6| Step: 10
Training loss: 1.6125290393829346
Validation loss: 1.9838901207011232

Epoch: 6| Step: 11
Training loss: 1.1908217668533325
Validation loss: 1.9943589177182925

Epoch: 6| Step: 12
Training loss: 1.7475513219833374
Validation loss: 2.0076778742574874

Epoch: 6| Step: 13
Training loss: 0.7606948614120483
Validation loss: 1.9546262038651334

Epoch: 197| Step: 0
Training loss: 1.6841998100280762
Validation loss: 1.9071739540305188

Epoch: 6| Step: 1
Training loss: 1.1640712022781372
Validation loss: 1.8967974801217355

Epoch: 6| Step: 2
Training loss: 0.9144424200057983
Validation loss: 1.8840083435017576

Epoch: 6| Step: 3
Training loss: 1.9558923244476318
Validation loss: 1.8664247707654071

Epoch: 6| Step: 4
Training loss: 1.6545506715774536
Validation loss: 1.8848015698053504

Epoch: 6| Step: 5
Training loss: 1.329394817352295
Validation loss: 1.8951130695240472

Epoch: 6| Step: 6
Training loss: 1.391074538230896
Validation loss: 1.915169910718036

Epoch: 6| Step: 7
Training loss: 2.3112664222717285
Validation loss: 1.8978045730180637

Epoch: 6| Step: 8
Training loss: 1.4664409160614014
Validation loss: 1.936869582822246

Epoch: 6| Step: 9
Training loss: 1.373637318611145
Validation loss: 1.9267326606217252

Epoch: 6| Step: 10
Training loss: 1.2107871770858765
Validation loss: 1.9288550089764338

Epoch: 6| Step: 11
Training loss: 1.6325112581253052
Validation loss: 1.9309352879883142

Epoch: 6| Step: 12
Training loss: 1.481301188468933
Validation loss: 1.9231498292697373

Epoch: 6| Step: 13
Training loss: 1.345188021659851
Validation loss: 1.9293673794756654

Epoch: 198| Step: 0
Training loss: 1.1619923114776611
Validation loss: 1.9300286846776162

Epoch: 6| Step: 1
Training loss: 1.6520252227783203
Validation loss: 1.9188127825337071

Epoch: 6| Step: 2
Training loss: 1.3913838863372803
Validation loss: 1.9263712757377214

Epoch: 6| Step: 3
Training loss: 1.6003665924072266
Validation loss: 1.9299642808975712

Epoch: 6| Step: 4
Training loss: 1.5388548374176025
Validation loss: 1.9384117395647111

Epoch: 6| Step: 5
Training loss: 1.3665635585784912
Validation loss: 1.9653548412425543

Epoch: 6| Step: 6
Training loss: 1.6370749473571777
Validation loss: 1.9499809126700125

Epoch: 6| Step: 7
Training loss: 0.9769613146781921
Validation loss: 1.9271580173123268

Epoch: 6| Step: 8
Training loss: 1.9765986204147339
Validation loss: 1.935478961595925

Epoch: 6| Step: 9
Training loss: 1.6139256954193115
Validation loss: 1.9193764784002816

Epoch: 6| Step: 10
Training loss: 2.031445264816284
Validation loss: 1.8766952970976472

Epoch: 6| Step: 11
Training loss: 1.5662825107574463
Validation loss: 1.8883393797823178

Epoch: 6| Step: 12
Training loss: 0.936714231967926
Validation loss: 1.9135414990045692

Epoch: 6| Step: 13
Training loss: 1.1712098121643066
Validation loss: 1.9167680971084102

Epoch: 199| Step: 0
Training loss: 1.1572221517562866
Validation loss: 1.9190028534140637

Epoch: 6| Step: 1
Training loss: 1.472644567489624
Validation loss: 1.9492960527379026

Epoch: 6| Step: 2
Training loss: 1.902432918548584
Validation loss: 1.9624275289556032

Epoch: 6| Step: 3
Training loss: 1.4949058294296265
Validation loss: 1.9871027097907117

Epoch: 6| Step: 4
Training loss: 1.106101155281067
Validation loss: 1.9775281721545803

Epoch: 6| Step: 5
Training loss: 1.6595118045806885
Validation loss: 1.961070711894702

Epoch: 6| Step: 6
Training loss: 1.3136122226715088
Validation loss: 1.9372326891909364

Epoch: 6| Step: 7
Training loss: 1.5118889808654785
Validation loss: 1.9268605452711864

Epoch: 6| Step: 8
Training loss: 1.7314563989639282
Validation loss: 1.8959261448152605

Epoch: 6| Step: 9
Training loss: 0.7617409229278564
Validation loss: 1.895602100638933

Epoch: 6| Step: 10
Training loss: 1.4776759147644043
Validation loss: 1.8817545816462526

Epoch: 6| Step: 11
Training loss: 1.78355872631073
Validation loss: 1.8557659233770063

Epoch: 6| Step: 12
Training loss: 2.109734535217285
Validation loss: 1.8478590044924008

Epoch: 6| Step: 13
Training loss: 1.0954954624176025
Validation loss: 1.8700861123300367

Epoch: 200| Step: 0
Training loss: 1.360123634338379
Validation loss: 1.8818701031387493

Epoch: 6| Step: 1
Training loss: 1.4038608074188232
Validation loss: 1.9065543502889655

Epoch: 6| Step: 2
Training loss: 1.4463045597076416
Validation loss: 1.9446474736736667

Epoch: 6| Step: 3
Training loss: 1.625422716140747
Validation loss: 1.9823864749682847

Epoch: 6| Step: 4
Training loss: 1.5939630270004272
Validation loss: 1.9721397238392984

Epoch: 6| Step: 5
Training loss: 1.2924002408981323
Validation loss: 1.9507273602229294

Epoch: 6| Step: 6
Training loss: 1.0756515264511108
Validation loss: 1.9281788346587971

Epoch: 6| Step: 7
Training loss: 2.103954553604126
Validation loss: 1.8879672891350203

Epoch: 6| Step: 8
Training loss: 1.4072644710540771
Validation loss: 1.8522089783863356

Epoch: 6| Step: 9
Training loss: 1.0908446311950684
Validation loss: 1.8489678623855754

Epoch: 6| Step: 10
Training loss: 1.8105499744415283
Validation loss: 1.8192155117629676

Epoch: 6| Step: 11
Training loss: 1.4860410690307617
Validation loss: 1.8338029076976161

Epoch: 6| Step: 12
Training loss: 1.563604474067688
Validation loss: 1.8318676538364862

Epoch: 6| Step: 13
Training loss: 1.4402014017105103
Validation loss: 1.8380009628111316

Epoch: 201| Step: 0
Training loss: 2.0711727142333984
Validation loss: 1.8314946133603331

Epoch: 6| Step: 1
Training loss: 1.2809929847717285
Validation loss: 1.8337484457159554

Epoch: 6| Step: 2
Training loss: 0.8101444244384766
Validation loss: 1.8645032669908257

Epoch: 6| Step: 3
Training loss: 1.6513128280639648
Validation loss: 1.923626353663783

Epoch: 6| Step: 4
Training loss: 1.3906824588775635
Validation loss: 1.9431508279615832

Epoch: 6| Step: 5
Training loss: 2.0416417121887207
Validation loss: 1.9144389437090965

Epoch: 6| Step: 6
Training loss: 0.8691062331199646
Validation loss: 1.9174164956615818

Epoch: 6| Step: 7
Training loss: 1.1576905250549316
Validation loss: 1.9080881457174979

Epoch: 6| Step: 8
Training loss: 1.414402723312378
Validation loss: 1.8805067000850555

Epoch: 6| Step: 9
Training loss: 1.538895606994629
Validation loss: 1.8639634475913098

Epoch: 6| Step: 10
Training loss: 1.492883324623108
Validation loss: 1.8392276302460702

Epoch: 6| Step: 11
Training loss: 1.6581428050994873
Validation loss: 1.8645126447882703

Epoch: 6| Step: 12
Training loss: 1.8997602462768555
Validation loss: 1.8437831709461827

Epoch: 6| Step: 13
Training loss: 1.0886890888214111
Validation loss: 1.8709767441595755

Epoch: 202| Step: 0
Training loss: 1.8615992069244385
Validation loss: 1.890056679325719

Epoch: 6| Step: 1
Training loss: 1.3432214260101318
Validation loss: 1.8668337996288011

Epoch: 6| Step: 2
Training loss: 1.1132917404174805
Validation loss: 1.8467501491628668

Epoch: 6| Step: 3
Training loss: 1.4639971256256104
Validation loss: 1.879161935980602

Epoch: 6| Step: 4
Training loss: 1.4096949100494385
Validation loss: 1.8858812598771946

Epoch: 6| Step: 5
Training loss: 1.278891921043396
Validation loss: 1.8800809665392804

Epoch: 6| Step: 6
Training loss: 1.8694028854370117
Validation loss: 1.905552743583597

Epoch: 6| Step: 7
Training loss: 1.438067078590393
Validation loss: 1.9326254590865104

Epoch: 6| Step: 8
Training loss: 1.5185974836349487
Validation loss: 1.9468538120228758

Epoch: 6| Step: 9
Training loss: 1.532773733139038
Validation loss: 1.935619806730619

Epoch: 6| Step: 10
Training loss: 1.9373681545257568
Validation loss: 1.907068573018556

Epoch: 6| Step: 11
Training loss: 1.073984146118164
Validation loss: 1.889607971714389

Epoch: 6| Step: 12
Training loss: 1.0808396339416504
Validation loss: 1.8709582897924608

Epoch: 6| Step: 13
Training loss: 1.375346064567566
Validation loss: 1.8846826514890116

Epoch: 203| Step: 0
Training loss: 1.194379210472107
Validation loss: 1.9083170570353025

Epoch: 6| Step: 1
Training loss: 1.901170253753662
Validation loss: 1.891728369138574

Epoch: 6| Step: 2
Training loss: 1.5737768411636353
Validation loss: 1.8951756338919363

Epoch: 6| Step: 3
Training loss: 0.7753440141677856
Validation loss: 1.8887049485278387

Epoch: 6| Step: 4
Training loss: 0.9263654947280884
Validation loss: 1.911403908524462

Epoch: 6| Step: 5
Training loss: 1.2621358633041382
Validation loss: 1.9185160129301009

Epoch: 6| Step: 6
Training loss: 1.583359718322754
Validation loss: 1.9159984383531796

Epoch: 6| Step: 7
Training loss: 1.3131581544876099
Validation loss: 1.9120930343545892

Epoch: 6| Step: 8
Training loss: 1.5422465801239014
Validation loss: 1.9302743865597634

Epoch: 6| Step: 9
Training loss: 1.302207350730896
Validation loss: 1.92585386255736

Epoch: 6| Step: 10
Training loss: 2.119342803955078
Validation loss: 1.866226165525375

Epoch: 6| Step: 11
Training loss: 1.8229868412017822
Validation loss: 1.8743127546002787

Epoch: 6| Step: 12
Training loss: 1.0442354679107666
Validation loss: 1.8527004411143642

Epoch: 6| Step: 13
Training loss: 2.000494956970215
Validation loss: 1.8376468612301735

Epoch: 204| Step: 0
Training loss: 1.652079463005066
Validation loss: 1.8353389411844232

Epoch: 6| Step: 1
Training loss: 1.1973453760147095
Validation loss: 1.836964270120026

Epoch: 6| Step: 2
Training loss: 2.1745247840881348
Validation loss: 1.8406860495126376

Epoch: 6| Step: 3
Training loss: 1.199515700340271
Validation loss: 1.8699484384188088

Epoch: 6| Step: 4
Training loss: 1.3711559772491455
Validation loss: 1.920129390173061

Epoch: 6| Step: 5
Training loss: 2.421595573425293
Validation loss: 1.9060820712838122

Epoch: 6| Step: 6
Training loss: 0.7088372707366943
Validation loss: 1.8912440141042073

Epoch: 6| Step: 7
Training loss: 1.2369844913482666
Validation loss: 1.8752843846556961

Epoch: 6| Step: 8
Training loss: 1.6545307636260986
Validation loss: 1.8660403246520667

Epoch: 6| Step: 9
Training loss: 1.1833932399749756
Validation loss: 1.8679143600566412

Epoch: 6| Step: 10
Training loss: 0.5187959671020508
Validation loss: 1.8671693686516053

Epoch: 6| Step: 11
Training loss: 1.8650784492492676
Validation loss: 1.8660447700049287

Epoch: 6| Step: 12
Training loss: 1.0393075942993164
Validation loss: 1.8333200254747946

Epoch: 6| Step: 13
Training loss: 1.5970559120178223
Validation loss: 1.8428210237974763

Epoch: 205| Step: 0
Training loss: 1.0714282989501953
Validation loss: 1.8237530082784674

Epoch: 6| Step: 1
Training loss: 1.0549379587173462
Validation loss: 1.8654568964435208

Epoch: 6| Step: 2
Training loss: 1.094714641571045
Validation loss: 1.8779230233161681

Epoch: 6| Step: 3
Training loss: 1.3672711849212646
Validation loss: 1.8887820154108026

Epoch: 6| Step: 4
Training loss: 1.1916043758392334
Validation loss: 1.8943968203759962

Epoch: 6| Step: 5
Training loss: 1.141865611076355
Validation loss: 1.8832508812668503

Epoch: 6| Step: 6
Training loss: 1.6107574701309204
Validation loss: 1.8612881065696798

Epoch: 6| Step: 7
Training loss: 1.4574928283691406
Validation loss: 1.8324215783867785

Epoch: 6| Step: 8
Training loss: 1.5794451236724854
Validation loss: 1.8489112995004142

Epoch: 6| Step: 9
Training loss: 1.4237645864486694
Validation loss: 1.8711867358094902

Epoch: 6| Step: 10
Training loss: 1.735022783279419
Validation loss: 1.8777110089537918

Epoch: 6| Step: 11
Training loss: 1.896637201309204
Validation loss: 1.8793728825866536

Epoch: 6| Step: 12
Training loss: 1.3513855934143066
Validation loss: 1.8656251840693976

Epoch: 6| Step: 13
Training loss: 2.362349510192871
Validation loss: 1.8666578108264553

Epoch: 206| Step: 0
Training loss: 1.5947426557540894
Validation loss: 1.8118430645235124

Epoch: 6| Step: 1
Training loss: 1.8464629650115967
Validation loss: 1.8120507065967848

Epoch: 6| Step: 2
Training loss: 1.1012629270553589
Validation loss: 1.8249771236091532

Epoch: 6| Step: 3
Training loss: 1.2138149738311768
Validation loss: 1.8007344840675272

Epoch: 6| Step: 4
Training loss: 0.9759100079536438
Validation loss: 1.8025493468007734

Epoch: 6| Step: 5
Training loss: 1.464045524597168
Validation loss: 1.850620562030423

Epoch: 6| Step: 6
Training loss: 1.3621463775634766
Validation loss: 1.847212960643153

Epoch: 6| Step: 7
Training loss: 1.3883116245269775
Validation loss: 1.8710307998041953

Epoch: 6| Step: 8
Training loss: 1.506683111190796
Validation loss: 1.8798407072662024

Epoch: 6| Step: 9
Training loss: 1.7365219593048096
Validation loss: 1.8879663546880086

Epoch: 6| Step: 10
Training loss: 1.6451679468154907
Validation loss: 1.8965070401468584

Epoch: 6| Step: 11
Training loss: 1.4758470058441162
Validation loss: 1.868347898606331

Epoch: 6| Step: 12
Training loss: 1.2612876892089844
Validation loss: 1.8428538665976575

Epoch: 6| Step: 13
Training loss: 0.785935640335083
Validation loss: 1.8702268305645193

Epoch: 207| Step: 0
Training loss: 1.6087087392807007
Validation loss: 1.8451620583893151

Epoch: 6| Step: 1
Training loss: 1.4660817384719849
Validation loss: 1.8392657861914685

Epoch: 6| Step: 2
Training loss: 1.5376241207122803
Validation loss: 1.806438740863595

Epoch: 6| Step: 3
Training loss: 1.068068027496338
Validation loss: 1.8255054079076296

Epoch: 6| Step: 4
Training loss: 1.837963342666626
Validation loss: 1.821686610098808

Epoch: 6| Step: 5
Training loss: 1.4932467937469482
Validation loss: 1.8643850562393025

Epoch: 6| Step: 6
Training loss: 1.2331175804138184
Validation loss: 1.8835032434873684

Epoch: 6| Step: 7
Training loss: 1.1116605997085571
Validation loss: 1.8963348942418252

Epoch: 6| Step: 8
Training loss: 1.848841667175293
Validation loss: 1.8960289929502754

Epoch: 6| Step: 9
Training loss: 1.2820266485214233
Validation loss: 1.882025937880239

Epoch: 6| Step: 10
Training loss: 1.3673789501190186
Validation loss: 1.8601505102649811

Epoch: 6| Step: 11
Training loss: 1.0523086786270142
Validation loss: 1.8379252687577279

Epoch: 6| Step: 12
Training loss: 1.3293042182922363
Validation loss: 1.8126042619828255

Epoch: 6| Step: 13
Training loss: 1.5106852054595947
Validation loss: 1.8094835794100197

Epoch: 208| Step: 0
Training loss: 1.50272536277771
Validation loss: 1.793866556177857

Epoch: 6| Step: 1
Training loss: 1.760448932647705
Validation loss: 1.814613688376642

Epoch: 6| Step: 2
Training loss: 1.536668300628662
Validation loss: 1.806035364827802

Epoch: 6| Step: 3
Training loss: 1.224084734916687
Validation loss: 1.8184971412022908

Epoch: 6| Step: 4
Training loss: 1.2129336595535278
Validation loss: 1.8382878406073457

Epoch: 6| Step: 5
Training loss: 1.0813982486724854
Validation loss: 1.8586413732139013

Epoch: 6| Step: 6
Training loss: 1.4737658500671387
Validation loss: 1.8659414527236775

Epoch: 6| Step: 7
Training loss: 1.0610942840576172
Validation loss: 1.864912776536839

Epoch: 6| Step: 8
Training loss: 1.2402422428131104
Validation loss: 1.8493783358604676

Epoch: 6| Step: 9
Training loss: 1.0385421514511108
Validation loss: 1.8407395732018255

Epoch: 6| Step: 10
Training loss: 1.4159671068191528
Validation loss: 1.826629768135727

Epoch: 6| Step: 11
Training loss: 1.7156273126602173
Validation loss: 1.844113439641973

Epoch: 6| Step: 12
Training loss: 1.4911282062530518
Validation loss: 1.8830211816295501

Epoch: 6| Step: 13
Training loss: 1.6856473684310913
Validation loss: 1.9207246649649836

Epoch: 209| Step: 0
Training loss: 1.5685081481933594
Validation loss: 2.0068517807991273

Epoch: 6| Step: 1
Training loss: 1.797332763671875
Validation loss: 2.0166577536572694

Epoch: 6| Step: 2
Training loss: 0.8189082145690918
Validation loss: 2.021748786331505

Epoch: 6| Step: 3
Training loss: 1.1763660907745361
Validation loss: 2.0129685722371584

Epoch: 6| Step: 4
Training loss: 1.3476969003677368
Validation loss: 1.9922128428695023

Epoch: 6| Step: 5
Training loss: 1.4498400688171387
Validation loss: 1.9638297109193699

Epoch: 6| Step: 6
Training loss: 1.351261019706726
Validation loss: 1.9219956167282597

Epoch: 6| Step: 7
Training loss: 1.5471901893615723
Validation loss: 1.910483419254262

Epoch: 6| Step: 8
Training loss: 1.1064436435699463
Validation loss: 1.838554129805616

Epoch: 6| Step: 9
Training loss: 1.1923227310180664
Validation loss: 1.830764662834906

Epoch: 6| Step: 10
Training loss: 1.1642091274261475
Validation loss: 1.820441674160701

Epoch: 6| Step: 11
Training loss: 1.4052271842956543
Validation loss: 1.8076169952269523

Epoch: 6| Step: 12
Training loss: 1.9893443584442139
Validation loss: 1.7977060105210991

Epoch: 6| Step: 13
Training loss: 1.5789027214050293
Validation loss: 1.8011771376414965

Epoch: 210| Step: 0
Training loss: 1.3802134990692139
Validation loss: 1.7970232809743574

Epoch: 6| Step: 1
Training loss: 1.230657696723938
Validation loss: 1.8009151412594704

Epoch: 6| Step: 2
Training loss: 0.886201798915863
Validation loss: 1.8485715145705848

Epoch: 6| Step: 3
Training loss: 1.5891667604446411
Validation loss: 1.8503256869572464

Epoch: 6| Step: 4
Training loss: 1.0456174612045288
Validation loss: 1.8573423649675103

Epoch: 6| Step: 5
Training loss: 1.5726903676986694
Validation loss: 1.8722942067730812

Epoch: 6| Step: 6
Training loss: 0.9714151620864868
Validation loss: 1.8363089894735685

Epoch: 6| Step: 7
Training loss: 1.1875560283660889
Validation loss: 1.810770700054784

Epoch: 6| Step: 8
Training loss: 1.5295703411102295
Validation loss: 1.822146269582933

Epoch: 6| Step: 9
Training loss: 1.27495276927948
Validation loss: 1.8653712836644982

Epoch: 6| Step: 10
Training loss: 1.9214131832122803
Validation loss: 1.845166052541425

Epoch: 6| Step: 11
Training loss: 1.9284248352050781
Validation loss: 1.8837939462354105

Epoch: 6| Step: 12
Training loss: 1.5529381036758423
Validation loss: 1.9057690174348894

Epoch: 6| Step: 13
Training loss: 1.595436930656433
Validation loss: 1.9481711592725528

Epoch: 211| Step: 0
Training loss: 1.0871193408966064
Validation loss: 1.9853167251874042

Epoch: 6| Step: 1
Training loss: 1.6312108039855957
Validation loss: 2.0638571682796685

Epoch: 6| Step: 2
Training loss: 1.330338716506958
Validation loss: 2.0366359039019515

Epoch: 6| Step: 3
Training loss: 1.4170074462890625
Validation loss: 1.9765228045884

Epoch: 6| Step: 4
Training loss: 1.1745069026947021
Validation loss: 1.9110615766176613

Epoch: 6| Step: 5
Training loss: 1.7330656051635742
Validation loss: 1.8597292925721856

Epoch: 6| Step: 6
Training loss: 0.9227407574653625
Validation loss: 1.8123553260680167

Epoch: 6| Step: 7
Training loss: 1.855316400527954
Validation loss: 1.8038375839110343

Epoch: 6| Step: 8
Training loss: 1.8031606674194336
Validation loss: 1.7907736237331102

Epoch: 6| Step: 9
Training loss: 0.9435250163078308
Validation loss: 1.7845488773879183

Epoch: 6| Step: 10
Training loss: 1.737898588180542
Validation loss: 1.7688520428954915

Epoch: 6| Step: 11
Training loss: 1.385353922843933
Validation loss: 1.7662458009617303

Epoch: 6| Step: 12
Training loss: 1.1852259635925293
Validation loss: 1.7944365893640826

Epoch: 6| Step: 13
Training loss: 2.0792922973632812
Validation loss: 1.7941894967068908

Epoch: 212| Step: 0
Training loss: 1.2097078561782837
Validation loss: 1.7866224422249743

Epoch: 6| Step: 1
Training loss: 1.1543995141983032
Validation loss: 1.8171191010423886

Epoch: 6| Step: 2
Training loss: 1.5193147659301758
Validation loss: 1.808479275754703

Epoch: 6| Step: 3
Training loss: 1.019449234008789
Validation loss: 1.8002593235302997

Epoch: 6| Step: 4
Training loss: 1.1353671550750732
Validation loss: 1.8261040115869174

Epoch: 6| Step: 5
Training loss: 1.7433232069015503
Validation loss: 1.8063493492782756

Epoch: 6| Step: 6
Training loss: 1.2759664058685303
Validation loss: 1.8323278965488556

Epoch: 6| Step: 7
Training loss: 1.3364346027374268
Validation loss: 1.8677785370939521

Epoch: 6| Step: 8
Training loss: 1.444501519203186
Validation loss: 1.8594887897532473

Epoch: 6| Step: 9
Training loss: 1.0240423679351807
Validation loss: 1.8865919164431992

Epoch: 6| Step: 10
Training loss: 2.3126111030578613
Validation loss: 1.9125058740697882

Epoch: 6| Step: 11
Training loss: 1.4096972942352295
Validation loss: 1.9341947109468522

Epoch: 6| Step: 12
Training loss: 0.8962106704711914
Validation loss: 1.9233264641095233

Epoch: 6| Step: 13
Training loss: 1.6796376705169678
Validation loss: 1.9548555163926975

Epoch: 213| Step: 0
Training loss: 1.684747576713562
Validation loss: 1.937563902588301

Epoch: 6| Step: 1
Training loss: 1.9023611545562744
Validation loss: 1.936784590444257

Epoch: 6| Step: 2
Training loss: 1.2069050073623657
Validation loss: 1.9069661581388084

Epoch: 6| Step: 3
Training loss: 1.6939940452575684
Validation loss: 1.9099023598496632

Epoch: 6| Step: 4
Training loss: 1.4817869663238525
Validation loss: 1.91708246995044

Epoch: 6| Step: 5
Training loss: 1.250950574874878
Validation loss: 1.8384766655583535

Epoch: 6| Step: 6
Training loss: 0.984084963798523
Validation loss: 1.8035879378677697

Epoch: 6| Step: 7
Training loss: 0.6208797693252563
Validation loss: 1.7851777384358067

Epoch: 6| Step: 8
Training loss: 1.1445399522781372
Validation loss: 1.7760415564301193

Epoch: 6| Step: 9
Training loss: 1.1546080112457275
Validation loss: 1.7680681546529133

Epoch: 6| Step: 10
Training loss: 1.588897705078125
Validation loss: 1.7647717255418018

Epoch: 6| Step: 11
Training loss: 1.6688272953033447
Validation loss: 1.7655543332458825

Epoch: 6| Step: 12
Training loss: 1.8270971775054932
Validation loss: 1.7426537365041754

Epoch: 6| Step: 13
Training loss: 0.9437887668609619
Validation loss: 1.7385571438779113

Epoch: 214| Step: 0
Training loss: 1.0944594144821167
Validation loss: 1.7842766572070379

Epoch: 6| Step: 1
Training loss: 1.2424275875091553
Validation loss: 1.8057938609071957

Epoch: 6| Step: 2
Training loss: 1.8547414541244507
Validation loss: 1.82093592228428

Epoch: 6| Step: 3
Training loss: 1.3535221815109253
Validation loss: 1.8245285659708002

Epoch: 6| Step: 4
Training loss: 1.325676441192627
Validation loss: 1.8492143961691088

Epoch: 6| Step: 5
Training loss: 0.8161954879760742
Validation loss: 1.8260756192668792

Epoch: 6| Step: 6
Training loss: 1.0838675498962402
Validation loss: 1.8118018181093278

Epoch: 6| Step: 7
Training loss: 1.7090840339660645
Validation loss: 1.7683801958637853

Epoch: 6| Step: 8
Training loss: 1.1057859659194946
Validation loss: 1.8113149519889586

Epoch: 6| Step: 9
Training loss: 1.2822788953781128
Validation loss: 1.8118310807853617

Epoch: 6| Step: 10
Training loss: 1.8655675649642944
Validation loss: 1.8051488553324053

Epoch: 6| Step: 11
Training loss: 1.0542161464691162
Validation loss: 1.7637930159927697

Epoch: 6| Step: 12
Training loss: 1.409583568572998
Validation loss: 1.7817113450778428

Epoch: 6| Step: 13
Training loss: 1.3716179132461548
Validation loss: 1.8353904562611734

Epoch: 215| Step: 0
Training loss: 1.0531806945800781
Validation loss: 1.8961971703396048

Epoch: 6| Step: 1
Training loss: 1.4617406129837036
Validation loss: 1.9448809162262948

Epoch: 6| Step: 2
Training loss: 1.1693611145019531
Validation loss: 1.996232912104617

Epoch: 6| Step: 3
Training loss: 1.1280474662780762
Validation loss: 1.9517551570810296

Epoch: 6| Step: 4
Training loss: 1.8317283391952515
Validation loss: 1.9921548469092256

Epoch: 6| Step: 5
Training loss: 1.4614477157592773
Validation loss: 1.9336444383026452

Epoch: 6| Step: 6
Training loss: 1.3835868835449219
Validation loss: 1.8768138500951952

Epoch: 6| Step: 7
Training loss: 0.8343935012817383
Validation loss: 1.8234672802750782

Epoch: 6| Step: 8
Training loss: 1.4943604469299316
Validation loss: 1.7761482256715015

Epoch: 6| Step: 9
Training loss: 1.1146801710128784
Validation loss: 1.7969119087342293

Epoch: 6| Step: 10
Training loss: 1.7286529541015625
Validation loss: 1.7706513699664865

Epoch: 6| Step: 11
Training loss: 1.2023224830627441
Validation loss: 1.7776763259723622

Epoch: 6| Step: 12
Training loss: 1.4675410985946655
Validation loss: 1.7607256109996507

Epoch: 6| Step: 13
Training loss: 0.9939517974853516
Validation loss: 1.7750499120322607

Epoch: 216| Step: 0
Training loss: 0.7978003621101379
Validation loss: 1.7757693183037542

Epoch: 6| Step: 1
Training loss: 1.6390119791030884
Validation loss: 1.8070286384192846

Epoch: 6| Step: 2
Training loss: 1.4436410665512085
Validation loss: 1.8047947268332205

Epoch: 6| Step: 3
Training loss: 1.8450145721435547
Validation loss: 1.8238208499006046

Epoch: 6| Step: 4
Training loss: 0.7683765292167664
Validation loss: 1.8581428450922812

Epoch: 6| Step: 5
Training loss: 1.0096559524536133
Validation loss: 1.9335854412407003

Epoch: 6| Step: 6
Training loss: 2.1021881103515625
Validation loss: 1.9556949125823153

Epoch: 6| Step: 7
Training loss: 1.8340553045272827
Validation loss: 1.9670707000199186

Epoch: 6| Step: 8
Training loss: 1.6286122798919678
Validation loss: 1.9476056855211976

Epoch: 6| Step: 9
Training loss: 1.5459271669387817
Validation loss: 1.8859778142744494

Epoch: 6| Step: 10
Training loss: 1.0973572731018066
Validation loss: 1.8194691186310143

Epoch: 6| Step: 11
Training loss: 0.553388237953186
Validation loss: 1.786005962279535

Epoch: 6| Step: 12
Training loss: 1.520608901977539
Validation loss: 1.780752892135292

Epoch: 6| Step: 13
Training loss: 0.5444584488868713
Validation loss: 1.7761747926794074

Epoch: 217| Step: 0
Training loss: 1.565752387046814
Validation loss: 1.7713394293221094

Epoch: 6| Step: 1
Training loss: 1.3481075763702393
Validation loss: 1.7537896389602332

Epoch: 6| Step: 2
Training loss: 1.5013009309768677
Validation loss: 1.7233228555289648

Epoch: 6| Step: 3
Training loss: 1.1281226873397827
Validation loss: 1.7441703222131217

Epoch: 6| Step: 4
Training loss: 1.5360232591629028
Validation loss: 1.7439030370404642

Epoch: 6| Step: 5
Training loss: 1.1989980936050415
Validation loss: 1.7634344447043635

Epoch: 6| Step: 6
Training loss: 1.5325247049331665
Validation loss: 1.7694524090777162

Epoch: 6| Step: 7
Training loss: 1.3763737678527832
Validation loss: 1.812104828896061

Epoch: 6| Step: 8
Training loss: 1.1762324571609497
Validation loss: 1.8227638301029

Epoch: 6| Step: 9
Training loss: 1.2988204956054688
Validation loss: 1.8451865603846889

Epoch: 6| Step: 10
Training loss: 1.571692943572998
Validation loss: 1.8135848942623343

Epoch: 6| Step: 11
Training loss: 1.2977631092071533
Validation loss: 1.7723006548420075

Epoch: 6| Step: 12
Training loss: 0.9065911173820496
Validation loss: 1.7706363803596907

Epoch: 6| Step: 13
Training loss: 0.5790228843688965
Validation loss: 1.7807024883967575

Epoch: 218| Step: 0
Training loss: 1.1325433254241943
Validation loss: 1.7714146439747145

Epoch: 6| Step: 1
Training loss: 1.4074394702911377
Validation loss: 1.7906037479318597

Epoch: 6| Step: 2
Training loss: 1.1787796020507812
Validation loss: 1.8107192606054328

Epoch: 6| Step: 3
Training loss: 1.5656309127807617
Validation loss: 1.8492010549832416

Epoch: 6| Step: 4
Training loss: 1.3040707111358643
Validation loss: 1.8768487463715255

Epoch: 6| Step: 5
Training loss: 2.11543607711792
Validation loss: 1.9015637854094147

Epoch: 6| Step: 6
Training loss: 0.8401340842247009
Validation loss: 1.9025385072154384

Epoch: 6| Step: 7
Training loss: 1.531883716583252
Validation loss: 1.8760473728179932

Epoch: 6| Step: 8
Training loss: 1.5492393970489502
Validation loss: 1.811007898340943

Epoch: 6| Step: 9
Training loss: 0.8941432237625122
Validation loss: 1.7896188907725836

Epoch: 6| Step: 10
Training loss: 1.5089795589447021
Validation loss: 1.7757035609214538

Epoch: 6| Step: 11
Training loss: 0.9927716255187988
Validation loss: 1.7939794576296242

Epoch: 6| Step: 12
Training loss: 1.2140644788742065
Validation loss: 1.7779090622419953

Epoch: 6| Step: 13
Training loss: 1.2492728233337402
Validation loss: 1.7929924072757844

Epoch: 219| Step: 0
Training loss: 2.179269790649414
Validation loss: 1.8099424685201337

Epoch: 6| Step: 1
Training loss: 0.8194032311439514
Validation loss: 1.8127822235066404

Epoch: 6| Step: 2
Training loss: 1.4279603958129883
Validation loss: 1.8373353032655613

Epoch: 6| Step: 3
Training loss: 0.7950453758239746
Validation loss: 1.8558268572694512

Epoch: 6| Step: 4
Training loss: 1.0895353555679321
Validation loss: 1.8824392287961897

Epoch: 6| Step: 5
Training loss: 1.6258565187454224
Validation loss: 1.8923215776361444

Epoch: 6| Step: 6
Training loss: 0.9124929308891296
Validation loss: 1.8669424415916525

Epoch: 6| Step: 7
Training loss: 1.4518120288848877
Validation loss: 1.7902072616802749

Epoch: 6| Step: 8
Training loss: 0.9549859762191772
Validation loss: 1.793594911534299

Epoch: 6| Step: 9
Training loss: 1.313299298286438
Validation loss: 1.793881788048693

Epoch: 6| Step: 10
Training loss: 0.9172834157943726
Validation loss: 1.7641638491743354

Epoch: 6| Step: 11
Training loss: 1.2741189002990723
Validation loss: 1.7694223721822102

Epoch: 6| Step: 12
Training loss: 1.7387715578079224
Validation loss: 1.758488578181113

Epoch: 6| Step: 13
Training loss: 1.3048162460327148
Validation loss: 1.7824876154622724

Epoch: 220| Step: 0
Training loss: 1.1057097911834717
Validation loss: 1.81014915820091

Epoch: 6| Step: 1
Training loss: 1.1407042741775513
Validation loss: 1.8430028487277288

Epoch: 6| Step: 2
Training loss: 1.8913507461547852
Validation loss: 1.8481884387231642

Epoch: 6| Step: 3
Training loss: 1.2554166316986084
Validation loss: 1.8121258263946862

Epoch: 6| Step: 4
Training loss: 1.2275046110153198
Validation loss: 1.8333246361824773

Epoch: 6| Step: 5
Training loss: 1.3294496536254883
Validation loss: 1.827286180629525

Epoch: 6| Step: 6
Training loss: 1.2170891761779785
Validation loss: 1.8002672887617541

Epoch: 6| Step: 7
Training loss: 1.4380215406417847
Validation loss: 1.7637970062994188

Epoch: 6| Step: 8
Training loss: 1.0550007820129395
Validation loss: 1.755094394888929

Epoch: 6| Step: 9
Training loss: 1.2070153951644897
Validation loss: 1.7702134591276928

Epoch: 6| Step: 10
Training loss: 0.7464704513549805
Validation loss: 1.7838692883009553

Epoch: 6| Step: 11
Training loss: 1.4476699829101562
Validation loss: 1.7624296808755526

Epoch: 6| Step: 12
Training loss: 1.0102125406265259
Validation loss: 1.7714246319186302

Epoch: 6| Step: 13
Training loss: 1.6973817348480225
Validation loss: 1.7683005832856702

Epoch: 221| Step: 0
Training loss: 1.1796278953552246
Validation loss: 1.7630058962811705

Epoch: 6| Step: 1
Training loss: 1.0415328741073608
Validation loss: 1.7407984483626582

Epoch: 6| Step: 2
Training loss: 1.2061101198196411
Validation loss: 1.7256028101008425

Epoch: 6| Step: 3
Training loss: 1.26659095287323
Validation loss: 1.7667009945838683

Epoch: 6| Step: 4
Training loss: 1.0358577966690063
Validation loss: 1.803596588873094

Epoch: 6| Step: 5
Training loss: 1.5717097520828247
Validation loss: 1.8149934545640023

Epoch: 6| Step: 6
Training loss: 2.2036452293395996
Validation loss: 1.834611056953348

Epoch: 6| Step: 7
Training loss: 1.1415866613388062
Validation loss: 1.8139996220988612

Epoch: 6| Step: 8
Training loss: 1.2708103656768799
Validation loss: 1.8013390366749098

Epoch: 6| Step: 9
Training loss: 0.7149617671966553
Validation loss: 1.7901174099214616

Epoch: 6| Step: 10
Training loss: 0.6476305723190308
Validation loss: 1.7858617331392022

Epoch: 6| Step: 11
Training loss: 1.752694845199585
Validation loss: 1.8144065013495825

Epoch: 6| Step: 12
Training loss: 1.2193728685379028
Validation loss: 1.84448209885628

Epoch: 6| Step: 13
Training loss: 1.2737464904785156
Validation loss: 1.8602601917841102

Epoch: 222| Step: 0
Training loss: 1.2315573692321777
Validation loss: 1.8279725108095395

Epoch: 6| Step: 1
Training loss: 1.9694992303848267
Validation loss: 1.8168244387513848

Epoch: 6| Step: 2
Training loss: 0.9623106122016907
Validation loss: 1.7801794018796695

Epoch: 6| Step: 3
Training loss: 1.440377950668335
Validation loss: 1.7561692409617926

Epoch: 6| Step: 4
Training loss: 1.1898852586746216
Validation loss: 1.7557381250525033

Epoch: 6| Step: 5
Training loss: 1.681488275527954
Validation loss: 1.7641206774660336

Epoch: 6| Step: 6
Training loss: 1.1474449634552002
Validation loss: 1.7902850694553827

Epoch: 6| Step: 7
Training loss: 1.1649281978607178
Validation loss: 1.8258945839379424

Epoch: 6| Step: 8
Training loss: 1.129823923110962
Validation loss: 1.904254440338381

Epoch: 6| Step: 9
Training loss: 0.8745332956314087
Validation loss: 1.930821043188854

Epoch: 6| Step: 10
Training loss: 1.0857431888580322
Validation loss: 1.946742767928749

Epoch: 6| Step: 11
Training loss: 1.031731367111206
Validation loss: 1.9584611731190835

Epoch: 6| Step: 12
Training loss: 1.0024715662002563
Validation loss: 1.932888529633963

Epoch: 6| Step: 13
Training loss: 1.4255080223083496
Validation loss: 1.867132531699314

Epoch: 223| Step: 0
Training loss: 1.3656865358352661
Validation loss: 1.803356429582001

Epoch: 6| Step: 1
Training loss: 1.6940778493881226
Validation loss: 1.765966062904686

Epoch: 6| Step: 2
Training loss: 0.6619271636009216
Validation loss: 1.7469838537195677

Epoch: 6| Step: 3
Training loss: 1.4811573028564453
Validation loss: 1.7374381352496404

Epoch: 6| Step: 4
Training loss: 1.246050477027893
Validation loss: 1.7263917128245037

Epoch: 6| Step: 5
Training loss: 1.3208754062652588
Validation loss: 1.698724747985922

Epoch: 6| Step: 6
Training loss: 1.1619491577148438
Validation loss: 1.7210155212751

Epoch: 6| Step: 7
Training loss: 1.4685176610946655
Validation loss: 1.7714052937364066

Epoch: 6| Step: 8
Training loss: 1.2621403932571411
Validation loss: 1.8687361696714997

Epoch: 6| Step: 9
Training loss: 1.268465280532837
Validation loss: 1.937971681676885

Epoch: 6| Step: 10
Training loss: 0.9660283327102661
Validation loss: 1.9620054447522728

Epoch: 6| Step: 11
Training loss: 1.622083306312561
Validation loss: 1.9595216781862321

Epoch: 6| Step: 12
Training loss: 1.2706611156463623
Validation loss: 1.9510999648801741

Epoch: 6| Step: 13
Training loss: 0.61513751745224
Validation loss: 1.925869264910298

Epoch: 224| Step: 0
Training loss: 1.0779675245285034
Validation loss: 1.865537969655888

Epoch: 6| Step: 1
Training loss: 1.18033766746521
Validation loss: 1.8160637963202693

Epoch: 6| Step: 2
Training loss: 1.6002126932144165
Validation loss: 1.766137997309367

Epoch: 6| Step: 3
Training loss: 1.330047845840454
Validation loss: 1.735146628913059

Epoch: 6| Step: 4
Training loss: 1.2594780921936035
Validation loss: 1.7512989467190159

Epoch: 6| Step: 5
Training loss: 1.318878412246704
Validation loss: 1.757441052826502

Epoch: 6| Step: 6
Training loss: 1.7312405109405518
Validation loss: 1.7438938310069423

Epoch: 6| Step: 7
Training loss: 1.4009292125701904
Validation loss: 1.809155100135393

Epoch: 6| Step: 8
Training loss: 0.9458194971084595
Validation loss: 1.816041031191426

Epoch: 6| Step: 9
Training loss: 1.1716651916503906
Validation loss: 1.812108620520561

Epoch: 6| Step: 10
Training loss: 1.1144448518753052
Validation loss: 1.7954662102524952

Epoch: 6| Step: 11
Training loss: 0.7962855100631714
Validation loss: 1.7938717526774253

Epoch: 6| Step: 12
Training loss: 0.9783835411071777
Validation loss: 1.7702752415851881

Epoch: 6| Step: 13
Training loss: 0.9119898676872253
Validation loss: 1.748935753299344

Epoch: 225| Step: 0
Training loss: 1.3563594818115234
Validation loss: 1.7034392062053885

Epoch: 6| Step: 1
Training loss: 1.7883585691452026
Validation loss: 1.7122955514538674

Epoch: 6| Step: 2
Training loss: 1.1238011121749878
Validation loss: 1.7388879073563444

Epoch: 6| Step: 3
Training loss: 1.3463904857635498
Validation loss: 1.7703757914163734

Epoch: 6| Step: 4
Training loss: 0.685711145401001
Validation loss: 1.8225635046600013

Epoch: 6| Step: 5
Training loss: 1.2329726219177246
Validation loss: 1.826186828715827

Epoch: 6| Step: 6
Training loss: 0.9122682809829712
Validation loss: 1.8431562172469271

Epoch: 6| Step: 7
Training loss: 1.122791051864624
Validation loss: 1.8804943356462704

Epoch: 6| Step: 8
Training loss: 1.7186875343322754
Validation loss: 1.8359087603066557

Epoch: 6| Step: 9
Training loss: 0.5277950763702393
Validation loss: 1.7950336228134811

Epoch: 6| Step: 10
Training loss: 0.858492374420166
Validation loss: 1.7525431981650732

Epoch: 6| Step: 11
Training loss: 1.7649998664855957
Validation loss: 1.723972817902924

Epoch: 6| Step: 12
Training loss: 1.2077820301055908
Validation loss: 1.7147267198049894

Epoch: 6| Step: 13
Training loss: 0.9691369533538818
Validation loss: 1.7021180352857035

Epoch: 226| Step: 0
Training loss: 1.5268535614013672
Validation loss: 1.7205058259348716

Epoch: 6| Step: 1
Training loss: 1.360403299331665
Validation loss: 1.7018422529261599

Epoch: 6| Step: 2
Training loss: 0.9220138192176819
Validation loss: 1.7558683964513964

Epoch: 6| Step: 3
Training loss: 1.476601481437683
Validation loss: 1.7720171623332526

Epoch: 6| Step: 4
Training loss: 0.9416255354881287
Validation loss: 1.8198548875829226

Epoch: 6| Step: 5
Training loss: 1.4126724004745483
Validation loss: 1.8276891669919413

Epoch: 6| Step: 6
Training loss: 0.7118556499481201
Validation loss: 1.799620512993105

Epoch: 6| Step: 7
Training loss: 0.8719401359558105
Validation loss: 1.747123820807344

Epoch: 6| Step: 8
Training loss: 1.7602720260620117
Validation loss: 1.7321751092069892

Epoch: 6| Step: 9
Training loss: 0.9767682552337646
Validation loss: 1.721692333939255

Epoch: 6| Step: 10
Training loss: 1.1448017358779907
Validation loss: 1.7407713282492854

Epoch: 6| Step: 11
Training loss: 1.1214096546173096
Validation loss: 1.7595100889923752

Epoch: 6| Step: 12
Training loss: 1.7711783647537231
Validation loss: 1.7804017707865725

Epoch: 6| Step: 13
Training loss: 1.0963190793991089
Validation loss: 1.7822575492243613

Epoch: 227| Step: 0
Training loss: 1.412022590637207
Validation loss: 1.7866277810065978

Epoch: 6| Step: 1
Training loss: 0.7696236371994019
Validation loss: 1.8007992954664334

Epoch: 6| Step: 2
Training loss: 1.7549941539764404
Validation loss: 1.7740598506824945

Epoch: 6| Step: 3
Training loss: 1.0222821235656738
Validation loss: 1.7698898905067033

Epoch: 6| Step: 4
Training loss: 0.8820991516113281
Validation loss: 1.7744424496927569

Epoch: 6| Step: 5
Training loss: 0.7426451444625854
Validation loss: 1.7894503403735418

Epoch: 6| Step: 6
Training loss: 1.5665959119796753
Validation loss: 1.7578560139543267

Epoch: 6| Step: 7
Training loss: 1.202444076538086
Validation loss: 1.7684720793078024

Epoch: 6| Step: 8
Training loss: 0.6319671869277954
Validation loss: 1.7888180696836082

Epoch: 6| Step: 9
Training loss: 1.3088791370391846
Validation loss: 1.7944033248450166

Epoch: 6| Step: 10
Training loss: 1.4059598445892334
Validation loss: 1.8339884076067197

Epoch: 6| Step: 11
Training loss: 1.3083419799804688
Validation loss: 1.782819826115844

Epoch: 6| Step: 12
Training loss: 1.107380986213684
Validation loss: 1.7832737622722503

Epoch: 6| Step: 13
Training loss: 1.680160641670227
Validation loss: 1.7784933505519744

Epoch: 228| Step: 0
Training loss: 1.0620880126953125
Validation loss: 1.7433395129378124

Epoch: 6| Step: 1
Training loss: 1.028781533241272
Validation loss: 1.7436192676585207

Epoch: 6| Step: 2
Training loss: 1.417948603630066
Validation loss: 1.732579820899553

Epoch: 6| Step: 3
Training loss: 0.8546460270881653
Validation loss: 1.7887177723710255

Epoch: 6| Step: 4
Training loss: 0.7935474514961243
Validation loss: 1.817790864616312

Epoch: 6| Step: 5
Training loss: 0.771830677986145
Validation loss: 1.8096350572442497

Epoch: 6| Step: 6
Training loss: 1.4886289834976196
Validation loss: 1.7783652467112387

Epoch: 6| Step: 7
Training loss: 1.030517578125
Validation loss: 1.7711683780916276

Epoch: 6| Step: 8
Training loss: 0.9126003384590149
Validation loss: 1.7409800021879134

Epoch: 6| Step: 9
Training loss: 1.1462488174438477
Validation loss: 1.7386781771977742

Epoch: 6| Step: 10
Training loss: 1.35111665725708
Validation loss: 1.710298470271531

Epoch: 6| Step: 11
Training loss: 0.8423317670822144
Validation loss: 1.7122015837700135

Epoch: 6| Step: 12
Training loss: 2.1185903549194336
Validation loss: 1.7386813907213108

Epoch: 6| Step: 13
Training loss: 1.7957566976547241
Validation loss: 1.7752234410214167

Epoch: 229| Step: 0
Training loss: 1.571428656578064
Validation loss: 1.8013505525486444

Epoch: 6| Step: 1
Training loss: 1.8032712936401367
Validation loss: 1.8425897731575915

Epoch: 6| Step: 2
Training loss: 1.202090859413147
Validation loss: 1.8109180017184185

Epoch: 6| Step: 3
Training loss: 1.9195812940597534
Validation loss: 1.7948521696111208

Epoch: 6| Step: 4
Training loss: 0.9933154582977295
Validation loss: 1.7838224390501618

Epoch: 6| Step: 5
Training loss: 0.8865497708320618
Validation loss: 1.7695204019546509

Epoch: 6| Step: 6
Training loss: 1.2097842693328857
Validation loss: 1.781236098658654

Epoch: 6| Step: 7
Training loss: 0.6232261657714844
Validation loss: 1.7643707503554642

Epoch: 6| Step: 8
Training loss: 1.1960362195968628
Validation loss: 1.75079390054108

Epoch: 6| Step: 9
Training loss: 1.4808285236358643
Validation loss: 1.7743703216634772

Epoch: 6| Step: 10
Training loss: 0.912682056427002
Validation loss: 1.7895865517277871

Epoch: 6| Step: 11
Training loss: 0.5670911073684692
Validation loss: 1.7798507175137919

Epoch: 6| Step: 12
Training loss: 1.068879246711731
Validation loss: 1.7807645246546755

Epoch: 6| Step: 13
Training loss: 0.6725098490715027
Validation loss: 1.769600724661222

Epoch: 230| Step: 0
Training loss: 0.9406582117080688
Validation loss: 1.7595815940569806

Epoch: 6| Step: 1
Training loss: 0.9946311712265015
Validation loss: 1.7582147223975069

Epoch: 6| Step: 2
Training loss: 1.8888132572174072
Validation loss: 1.7573971030532674

Epoch: 6| Step: 3
Training loss: 1.4866158962249756
Validation loss: 1.7845890355366532

Epoch: 6| Step: 4
Training loss: 1.3568140268325806
Validation loss: 1.7987372644485966

Epoch: 6| Step: 5
Training loss: 1.2195672988891602
Validation loss: 1.812498177251508

Epoch: 6| Step: 6
Training loss: 0.8508274555206299
Validation loss: 1.7973588435880599

Epoch: 6| Step: 7
Training loss: 0.8955034017562866
Validation loss: 1.8163079010543002

Epoch: 6| Step: 8
Training loss: 0.5574032068252563
Validation loss: 1.8054767872697564

Epoch: 6| Step: 9
Training loss: 1.239044427871704
Validation loss: 1.7646599008191017

Epoch: 6| Step: 10
Training loss: 1.8181118965148926
Validation loss: 1.7308641428588538

Epoch: 6| Step: 11
Training loss: 0.7117444276809692
Validation loss: 1.6882026016071279

Epoch: 6| Step: 12
Training loss: 0.9380675554275513
Validation loss: 1.6690408722046883

Epoch: 6| Step: 13
Training loss: 0.9339155554771423
Validation loss: 1.6659975103152695

Epoch: 231| Step: 0
Training loss: 1.0784014463424683
Validation loss: 1.6654173545939948

Epoch: 6| Step: 1
Training loss: 0.8253800868988037
Validation loss: 1.7347675138904202

Epoch: 6| Step: 2
Training loss: 0.930801510810852
Validation loss: 1.7952995377202188

Epoch: 6| Step: 3
Training loss: 1.254215955734253
Validation loss: 1.793025420558068

Epoch: 6| Step: 4
Training loss: 1.460424542427063
Validation loss: 1.7947537488834833

Epoch: 6| Step: 5
Training loss: 1.2116007804870605
Validation loss: 1.8010580565339775

Epoch: 6| Step: 6
Training loss: 1.3283538818359375
Validation loss: 1.8060887487985755

Epoch: 6| Step: 7
Training loss: 1.1924161911010742
Validation loss: 1.8022763921368508

Epoch: 6| Step: 8
Training loss: 1.4209814071655273
Validation loss: 1.7672488035694245

Epoch: 6| Step: 9
Training loss: 1.1377830505371094
Validation loss: 1.7567494146285518

Epoch: 6| Step: 10
Training loss: 0.6188115477561951
Validation loss: 1.7401455538247221

Epoch: 6| Step: 11
Training loss: 1.4895367622375488
Validation loss: 1.7145845928499777

Epoch: 6| Step: 12
Training loss: 1.0330179929733276
Validation loss: 1.7099198192678473

Epoch: 6| Step: 13
Training loss: 1.0707250833511353
Validation loss: 1.7048733542042394

Epoch: 232| Step: 0
Training loss: 1.6840559244155884
Validation loss: 1.7817518185543757

Epoch: 6| Step: 1
Training loss: 1.0987513065338135
Validation loss: 1.8276047988604474

Epoch: 6| Step: 2
Training loss: 1.179433822631836
Validation loss: 1.7965053512204079

Epoch: 6| Step: 3
Training loss: 1.3212579488754272
Validation loss: 1.7690755744134226

Epoch: 6| Step: 4
Training loss: 1.0785771608352661
Validation loss: 1.709250751362052

Epoch: 6| Step: 5
Training loss: 1.2486636638641357
Validation loss: 1.714466307752876

Epoch: 6| Step: 6
Training loss: 1.0190401077270508
Validation loss: 1.6850183522829445

Epoch: 6| Step: 7
Training loss: 0.4385833144187927
Validation loss: 1.7096047529610254

Epoch: 6| Step: 8
Training loss: 1.0295443534851074
Validation loss: 1.7045558883297829

Epoch: 6| Step: 9
Training loss: 0.7668424844741821
Validation loss: 1.738132051242295

Epoch: 6| Step: 10
Training loss: 1.5508075952529907
Validation loss: 1.8170153684513544

Epoch: 6| Step: 11
Training loss: 0.8166442513465881
Validation loss: 1.856604440237886

Epoch: 6| Step: 12
Training loss: 1.4589366912841797
Validation loss: 1.906108904910344

Epoch: 6| Step: 13
Training loss: 1.1419100761413574
Validation loss: 1.9784019044650498

Epoch: 233| Step: 0
Training loss: 2.0110597610473633
Validation loss: 2.061168259830885

Epoch: 6| Step: 1
Training loss: 1.1950154304504395
Validation loss: 1.9353874947435112

Epoch: 6| Step: 2
Training loss: 0.7370535135269165
Validation loss: 1.8419996487197055

Epoch: 6| Step: 3
Training loss: 1.0857884883880615
Validation loss: 1.7681933346615042

Epoch: 6| Step: 4
Training loss: 1.2633979320526123
Validation loss: 1.7258722525770946

Epoch: 6| Step: 5
Training loss: 1.4073679447174072
Validation loss: 1.7069927466812955

Epoch: 6| Step: 6
Training loss: 1.392963171005249
Validation loss: 1.7200243011597665

Epoch: 6| Step: 7
Training loss: 1.35262930393219
Validation loss: 1.68664538732139

Epoch: 6| Step: 8
Training loss: 1.3096857070922852
Validation loss: 1.6918494278384792

Epoch: 6| Step: 9
Training loss: 1.1584174633026123
Validation loss: 1.682266055896718

Epoch: 6| Step: 10
Training loss: 1.0149075984954834
Validation loss: 1.7362067007249402

Epoch: 6| Step: 11
Training loss: 0.9161776304244995
Validation loss: 1.8162877816025929

Epoch: 6| Step: 12
Training loss: 0.9441022872924805
Validation loss: 1.8937476091487433

Epoch: 6| Step: 13
Training loss: 1.3502038717269897
Validation loss: 1.9493213712528188

Epoch: 234| Step: 0
Training loss: 0.9899932146072388
Validation loss: 1.9174450212909329

Epoch: 6| Step: 1
Training loss: 1.34250807762146
Validation loss: 1.8944055636723836

Epoch: 6| Step: 2
Training loss: 0.9180572032928467
Validation loss: 1.838474556963931

Epoch: 6| Step: 3
Training loss: 1.1911592483520508
Validation loss: 1.7351303946587346

Epoch: 6| Step: 4
Training loss: 0.9443093538284302
Validation loss: 1.7088290350411528

Epoch: 6| Step: 5
Training loss: 0.9064006209373474
Validation loss: 1.6805977513713222

Epoch: 6| Step: 6
Training loss: 1.0993212461471558
Validation loss: 1.6787481987348167

Epoch: 6| Step: 7
Training loss: 1.0994327068328857
Validation loss: 1.6943671395701747

Epoch: 6| Step: 8
Training loss: 0.6951232552528381
Validation loss: 1.714209980862115

Epoch: 6| Step: 9
Training loss: 0.8713934421539307
Validation loss: 1.6977827638708136

Epoch: 6| Step: 10
Training loss: 1.4431931972503662
Validation loss: 1.7194056767289356

Epoch: 6| Step: 11
Training loss: 0.7222633957862854
Validation loss: 1.7510074697515017

Epoch: 6| Step: 12
Training loss: 1.3982584476470947
Validation loss: 1.8171547253926594

Epoch: 6| Step: 13
Training loss: 2.6250123977661133
Validation loss: 1.8659730765127367

Epoch: 235| Step: 0
Training loss: 1.3822284936904907
Validation loss: 1.9137573255005704

Epoch: 6| Step: 1
Training loss: 1.0100904703140259
Validation loss: 1.8642710793402888

Epoch: 6| Step: 2
Training loss: 1.2985643148422241
Validation loss: 1.8108245762445594

Epoch: 6| Step: 3
Training loss: 0.8368396162986755
Validation loss: 1.7813798971073602

Epoch: 6| Step: 4
Training loss: 0.9950577020645142
Validation loss: 1.7579512314129901

Epoch: 6| Step: 5
Training loss: 1.3528048992156982
Validation loss: 1.7172813171981482

Epoch: 6| Step: 6
Training loss: 1.099299430847168
Validation loss: 1.6828764459138275

Epoch: 6| Step: 7
Training loss: 1.566411018371582
Validation loss: 1.678529377906553

Epoch: 6| Step: 8
Training loss: 0.9347060322761536
Validation loss: 1.6819928000050206

Epoch: 6| Step: 9
Training loss: 1.5257536172866821
Validation loss: 1.6826545743532078

Epoch: 6| Step: 10
Training loss: 0.6286219358444214
Validation loss: 1.7010772817878312

Epoch: 6| Step: 11
Training loss: 1.1665279865264893
Validation loss: 1.7280924153584305

Epoch: 6| Step: 12
Training loss: 0.7623447775840759
Validation loss: 1.7783735285523117

Epoch: 6| Step: 13
Training loss: 1.2319540977478027
Validation loss: 1.8272620183165356

Epoch: 236| Step: 0
Training loss: 0.997384786605835
Validation loss: 1.8143718050372215

Epoch: 6| Step: 1
Training loss: 1.1323399543762207
Validation loss: 1.8183153688266713

Epoch: 6| Step: 2
Training loss: 1.1099728345870972
Validation loss: 1.7946108938545309

Epoch: 6| Step: 3
Training loss: 0.9576942324638367
Validation loss: 1.7892694716812463

Epoch: 6| Step: 4
Training loss: 1.5545628070831299
Validation loss: 1.7207701116479852

Epoch: 6| Step: 5
Training loss: 0.47485047578811646
Validation loss: 1.7083417984747118

Epoch: 6| Step: 6
Training loss: 1.6455209255218506
Validation loss: 1.6956156761415544

Epoch: 6| Step: 7
Training loss: 1.391089916229248
Validation loss: 1.6887896112216416

Epoch: 6| Step: 8
Training loss: 1.398818016052246
Validation loss: 1.7225234072695497

Epoch: 6| Step: 9
Training loss: 0.9653458595275879
Validation loss: 1.7428398734779769

Epoch: 6| Step: 10
Training loss: 1.0997192859649658
Validation loss: 1.7912595528428272

Epoch: 6| Step: 11
Training loss: 0.8904545307159424
Validation loss: 1.8578281825588596

Epoch: 6| Step: 12
Training loss: 0.9755175709724426
Validation loss: 1.867329889728177

Epoch: 6| Step: 13
Training loss: 1.5235127210617065
Validation loss: 1.7773737407499743

Epoch: 237| Step: 0
Training loss: 1.1148277521133423
Validation loss: 1.7062285279714933

Epoch: 6| Step: 1
Training loss: 1.617335557937622
Validation loss: 1.6423029720142324

Epoch: 6| Step: 2
Training loss: 1.2350921630859375
Validation loss: 1.6423741463691957

Epoch: 6| Step: 3
Training loss: 1.3359732627868652
Validation loss: 1.6145729108523297

Epoch: 6| Step: 4
Training loss: 1.065128207206726
Validation loss: 1.6409901252356909

Epoch: 6| Step: 5
Training loss: 0.8249181509017944
Validation loss: 1.6605835178846955

Epoch: 6| Step: 6
Training loss: 0.8930516242980957
Validation loss: 1.721378739162158

Epoch: 6| Step: 7
Training loss: 1.172876000404358
Validation loss: 1.7323651813691663

Epoch: 6| Step: 8
Training loss: 1.0346944332122803
Validation loss: 1.7866572744102889

Epoch: 6| Step: 9
Training loss: 0.42073923349380493
Validation loss: 1.8158097805515412

Epoch: 6| Step: 10
Training loss: 0.8691766262054443
Validation loss: 1.8364553336174256

Epoch: 6| Step: 11
Training loss: 1.6806764602661133
Validation loss: 1.8452642271595616

Epoch: 6| Step: 12
Training loss: 1.2659268379211426
Validation loss: 1.8489953446131882

Epoch: 6| Step: 13
Training loss: 0.5719765424728394
Validation loss: 1.8226954629344325

Epoch: 238| Step: 0
Training loss: 1.1367125511169434
Validation loss: 1.836181777779774

Epoch: 6| Step: 1
Training loss: 0.7988942861557007
Validation loss: 1.8375648542117047

Epoch: 6| Step: 2
Training loss: 1.3477002382278442
Validation loss: 1.7961786472669212

Epoch: 6| Step: 3
Training loss: 1.7171084880828857
Validation loss: 1.7490092708218483

Epoch: 6| Step: 4
Training loss: 1.1345205307006836
Validation loss: 1.7114090304220877

Epoch: 6| Step: 5
Training loss: 0.8968383073806763
Validation loss: 1.6990106515986945

Epoch: 6| Step: 6
Training loss: 0.9576213359832764
Validation loss: 1.6847360826307727

Epoch: 6| Step: 7
Training loss: 1.2636131048202515
Validation loss: 1.7251382361176193

Epoch: 6| Step: 8
Training loss: 0.7808629274368286
Validation loss: 1.770409700691059

Epoch: 6| Step: 9
Training loss: 0.9474858641624451
Validation loss: 1.7935358093630882

Epoch: 6| Step: 10
Training loss: 1.3276019096374512
Validation loss: 1.7893004007236932

Epoch: 6| Step: 11
Training loss: 0.8649299740791321
Validation loss: 1.7355197411711498

Epoch: 6| Step: 12
Training loss: 1.0587127208709717
Validation loss: 1.714542878571377

Epoch: 6| Step: 13
Training loss: 1.3761613368988037
Validation loss: 1.7062804416943622

Epoch: 239| Step: 0
Training loss: 1.2885030508041382
Validation loss: 1.698650630571509

Epoch: 6| Step: 1
Training loss: 1.2658950090408325
Validation loss: 1.725598305784246

Epoch: 6| Step: 2
Training loss: 0.810050368309021
Validation loss: 1.7327192021954445

Epoch: 6| Step: 3
Training loss: 0.7394675016403198
Validation loss: 1.7574721100509807

Epoch: 6| Step: 4
Training loss: 1.4718017578125
Validation loss: 1.7835231083695606

Epoch: 6| Step: 5
Training loss: 0.7590018510818481
Validation loss: 1.8037480154345114

Epoch: 6| Step: 6
Training loss: 1.0601943731307983
Validation loss: 1.8079219659169514

Epoch: 6| Step: 7
Training loss: 0.5418168902397156
Validation loss: 1.8592492277904222

Epoch: 6| Step: 8
Training loss: 1.8148791790008545
Validation loss: 1.8573201638396069

Epoch: 6| Step: 9
Training loss: 1.1878567934036255
Validation loss: 1.8593290377688665

Epoch: 6| Step: 10
Training loss: 0.7703226208686829
Validation loss: 1.7415447453016877

Epoch: 6| Step: 11
Training loss: 1.4813028573989868
Validation loss: 1.6925640439474454

Epoch: 6| Step: 12
Training loss: 1.6446022987365723
Validation loss: 1.681596523971968

Epoch: 6| Step: 13
Training loss: 0.4755336046218872
Validation loss: 1.6583739506301058

Epoch: 240| Step: 0
Training loss: 1.546241283416748
Validation loss: 1.658172538203578

Epoch: 6| Step: 1
Training loss: 0.5873153209686279
Validation loss: 1.6603143702271164

Epoch: 6| Step: 2
Training loss: 0.9603691101074219
Validation loss: 1.6836999629133491

Epoch: 6| Step: 3
Training loss: 1.0774787664413452
Validation loss: 1.8451516756447413

Epoch: 6| Step: 4
Training loss: 1.0602983236312866
Validation loss: 2.0215970572604927

Epoch: 6| Step: 5
Training loss: 1.910560131072998
Validation loss: 2.0603360129940893

Epoch: 6| Step: 6
Training loss: 0.7029809951782227
Validation loss: 2.0642689402385423

Epoch: 6| Step: 7
Training loss: 0.8938425779342651
Validation loss: 1.9837376186924596

Epoch: 6| Step: 8
Training loss: 1.2066627740859985
Validation loss: 1.877285720199667

Epoch: 6| Step: 9
Training loss: 1.3038344383239746
Validation loss: 1.7783922995290449

Epoch: 6| Step: 10
Training loss: 1.1779210567474365
Validation loss: 1.764192940086447

Epoch: 6| Step: 11
Training loss: 1.3103567361831665
Validation loss: 1.7555179147310154

Epoch: 6| Step: 12
Training loss: 1.4837915897369385
Validation loss: 1.7279603814566007

Epoch: 6| Step: 13
Training loss: 0.5219685435295105
Validation loss: 1.6935431841881043

Epoch: 241| Step: 0
Training loss: 1.1437864303588867
Validation loss: 1.7136435995819748

Epoch: 6| Step: 1
Training loss: 0.9075469970703125
Validation loss: 1.7439015501288957

Epoch: 6| Step: 2
Training loss: 0.5508862733840942
Validation loss: 1.7905833708342684

Epoch: 6| Step: 3
Training loss: 0.5608759522438049
Validation loss: 1.8445207970116728

Epoch: 6| Step: 4
Training loss: 1.3440691232681274
Validation loss: 1.8866032964439803

Epoch: 6| Step: 5
Training loss: 1.3436087369918823
Validation loss: 1.8800800090195031

Epoch: 6| Step: 6
Training loss: 1.4545841217041016
Validation loss: 1.8152490623535649

Epoch: 6| Step: 7
Training loss: 1.503435730934143
Validation loss: 1.7803107256530433

Epoch: 6| Step: 8
Training loss: 0.7573186159133911
Validation loss: 1.7153688528204476

Epoch: 6| Step: 9
Training loss: 1.1403837203979492
Validation loss: 1.6649177535887687

Epoch: 6| Step: 10
Training loss: 0.9350252151489258
Validation loss: 1.6711579112596409

Epoch: 6| Step: 11
Training loss: 1.0949718952178955
Validation loss: 1.671294976306218

Epoch: 6| Step: 12
Training loss: 1.599825382232666
Validation loss: 1.6781605187282767

Epoch: 6| Step: 13
Training loss: 0.33692118525505066
Validation loss: 1.6809589209095124

Epoch: 242| Step: 0
Training loss: 0.84501051902771
Validation loss: 1.732271336740063

Epoch: 6| Step: 1
Training loss: 1.0494240522384644
Validation loss: 1.756923822946446

Epoch: 6| Step: 2
Training loss: 0.7275232076644897
Validation loss: 1.771212504756066

Epoch: 6| Step: 3
Training loss: 1.5940721035003662
Validation loss: 1.7686395388777538

Epoch: 6| Step: 4
Training loss: 0.9289682507514954
Validation loss: 1.7857004198976743

Epoch: 6| Step: 5
Training loss: 1.6779969930648804
Validation loss: 1.8052306431595997

Epoch: 6| Step: 6
Training loss: 0.7776263356208801
Validation loss: 1.7755592382082375

Epoch: 6| Step: 7
Training loss: 1.0169365406036377
Validation loss: 1.7354205013603292

Epoch: 6| Step: 8
Training loss: 0.46044886112213135
Validation loss: 1.6890826750827093

Epoch: 6| Step: 9
Training loss: 1.092934489250183
Validation loss: 1.7075799498506772

Epoch: 6| Step: 10
Training loss: 1.505859613418579
Validation loss: 1.706669456215315

Epoch: 6| Step: 11
Training loss: 1.489138126373291
Validation loss: 1.7351438999176025

Epoch: 6| Step: 12
Training loss: 0.8701691627502441
Validation loss: 1.7438911545661189

Epoch: 6| Step: 13
Training loss: 1.0469515323638916
Validation loss: 1.7238089326889283

Epoch: 243| Step: 0
Training loss: 1.158666968345642
Validation loss: 1.764847247831283

Epoch: 6| Step: 1
Training loss: 1.3038055896759033
Validation loss: 1.8787569102420603

Epoch: 6| Step: 2
Training loss: 0.8700089454650879
Validation loss: 1.99651554963922

Epoch: 6| Step: 3
Training loss: 0.9532491564750671
Validation loss: 2.0727403894547494

Epoch: 6| Step: 4
Training loss: 1.564335584640503
Validation loss: 2.1631203287391254

Epoch: 6| Step: 5
Training loss: 1.1323268413543701
Validation loss: 2.089534833867063

Epoch: 6| Step: 6
Training loss: 0.9463486075401306
Validation loss: 1.9078401288678568

Epoch: 6| Step: 7
Training loss: 1.2597427368164062
Validation loss: 1.7461673444317234

Epoch: 6| Step: 8
Training loss: 1.043679118156433
Validation loss: 1.6693333861648396

Epoch: 6| Step: 9
Training loss: 1.0274415016174316
Validation loss: 1.6880546064787014

Epoch: 6| Step: 10
Training loss: 1.339455485343933
Validation loss: 1.6807397411715599

Epoch: 6| Step: 11
Training loss: 1.3546288013458252
Validation loss: 1.6962650693872923

Epoch: 6| Step: 12
Training loss: 1.5136923789978027
Validation loss: 1.7462925231584938

Epoch: 6| Step: 13
Training loss: 1.4572296142578125
Validation loss: 1.717656498314232

Epoch: 244| Step: 0
Training loss: 0.9741154909133911
Validation loss: 1.7360276945175663

Epoch: 6| Step: 1
Training loss: 1.1734050512313843
Validation loss: 1.703569733968345

Epoch: 6| Step: 2
Training loss: 0.9519079923629761
Validation loss: 1.7108185752745597

Epoch: 6| Step: 3
Training loss: 0.8502019643783569
Validation loss: 1.7722636756076608

Epoch: 6| Step: 4
Training loss: 1.6138508319854736
Validation loss: 1.8741473818338046

Epoch: 6| Step: 5
Training loss: 0.90157151222229
Validation loss: 1.9929188348913704

Epoch: 6| Step: 6
Training loss: 1.0141760110855103
Validation loss: 2.055067536651447

Epoch: 6| Step: 7
Training loss: 1.2623167037963867
Validation loss: 2.0176685010233233

Epoch: 6| Step: 8
Training loss: 0.7925866842269897
Validation loss: 2.0016132503427486

Epoch: 6| Step: 9
Training loss: 1.1396859884262085
Validation loss: 1.961483109381891

Epoch: 6| Step: 10
Training loss: 1.590707778930664
Validation loss: 1.9133893776965398

Epoch: 6| Step: 11
Training loss: 0.8524643182754517
Validation loss: 1.8424332603331535

Epoch: 6| Step: 12
Training loss: 1.0615837574005127
Validation loss: 1.8024098309137488

Epoch: 6| Step: 13
Training loss: 1.4226521253585815
Validation loss: 1.7472279071807861

Epoch: 245| Step: 0
Training loss: 1.1900393962860107
Validation loss: 1.7302351882380824

Epoch: 6| Step: 1
Training loss: 1.0023483037948608
Validation loss: 1.7412699871165778

Epoch: 6| Step: 2
Training loss: 0.8606925010681152
Validation loss: 1.72778594622048

Epoch: 6| Step: 3
Training loss: 0.8702000975608826
Validation loss: 1.7242355811339554

Epoch: 6| Step: 4
Training loss: 0.7636625170707703
Validation loss: 1.7729859659748692

Epoch: 6| Step: 5
Training loss: 0.7202207446098328
Validation loss: 1.850462801994816

Epoch: 6| Step: 6
Training loss: 1.846204161643982
Validation loss: 1.942224734572954

Epoch: 6| Step: 7
Training loss: 1.4783052206039429
Validation loss: 2.041290852331346

Epoch: 6| Step: 8
Training loss: 1.5049594640731812
Validation loss: 2.112792750840546

Epoch: 6| Step: 9
Training loss: 1.400305151939392
Validation loss: 2.0548815752870295

Epoch: 6| Step: 10
Training loss: 0.6386924386024475
Validation loss: 1.9091672243610505

Epoch: 6| Step: 11
Training loss: 1.2780441045761108
Validation loss: 1.780598525078066

Epoch: 6| Step: 12
Training loss: 0.9265444278717041
Validation loss: 1.6930254018434914

Epoch: 6| Step: 13
Training loss: 1.372215747833252
Validation loss: 1.7256749265937394

Epoch: 246| Step: 0
Training loss: 1.685607671737671
Validation loss: 1.7553202183015886

Epoch: 6| Step: 1
Training loss: 1.069946050643921
Validation loss: 1.7664473274702668

Epoch: 6| Step: 2
Training loss: 1.4430413246154785
Validation loss: 1.7785438773452595

Epoch: 6| Step: 3
Training loss: 0.766712486743927
Validation loss: 1.7614572919825071

Epoch: 6| Step: 4
Training loss: 1.5796535015106201
Validation loss: 1.748048109392966

Epoch: 6| Step: 5
Training loss: 1.3613333702087402
Validation loss: 1.702081303442678

Epoch: 6| Step: 6
Training loss: 1.038256049156189
Validation loss: 1.7261185928057599

Epoch: 6| Step: 7
Training loss: 0.8887628316879272
Validation loss: 1.7747656722222604

Epoch: 6| Step: 8
Training loss: 1.0492632389068604
Validation loss: 1.8884470360253447

Epoch: 6| Step: 9
Training loss: 1.2073944807052612
Validation loss: 1.9719358400631977

Epoch: 6| Step: 10
Training loss: 1.0091558694839478
Validation loss: 1.9815806470891482

Epoch: 6| Step: 11
Training loss: 1.2156708240509033
Validation loss: 1.9567696612368348

Epoch: 6| Step: 12
Training loss: 1.0702440738677979
Validation loss: 1.9162853366585189

Epoch: 6| Step: 13
Training loss: 1.0129387378692627
Validation loss: 1.831539975699558

Epoch: 247| Step: 0
Training loss: 1.5592763423919678
Validation loss: 1.767748345610916

Epoch: 6| Step: 1
Training loss: 0.7654772400856018
Validation loss: 1.71006993709072

Epoch: 6| Step: 2
Training loss: 0.8851013779640198
Validation loss: 1.7163889972112512

Epoch: 6| Step: 3
Training loss: 0.7549856305122375
Validation loss: 1.7254484097162883

Epoch: 6| Step: 4
Training loss: 1.0777668952941895
Validation loss: 1.7137009225865847

Epoch: 6| Step: 5
Training loss: 0.8962337970733643
Validation loss: 1.7259877676604896

Epoch: 6| Step: 6
Training loss: 1.108028769493103
Validation loss: 1.7393711805343628

Epoch: 6| Step: 7
Training loss: 1.2928075790405273
Validation loss: 1.7828978184730775

Epoch: 6| Step: 8
Training loss: 1.0302948951721191
Validation loss: 1.7634272780469669

Epoch: 6| Step: 9
Training loss: 0.5340827703475952
Validation loss: 1.771227539226573

Epoch: 6| Step: 10
Training loss: 1.0023242235183716
Validation loss: 1.7395304633725075

Epoch: 6| Step: 11
Training loss: 1.3718210458755493
Validation loss: 1.6983955598646594

Epoch: 6| Step: 12
Training loss: 0.8685785531997681
Validation loss: 1.6598034263938986

Epoch: 6| Step: 13
Training loss: 0.8519997000694275
Validation loss: 1.6626119741829493

Epoch: 248| Step: 0
Training loss: 1.368873953819275
Validation loss: 1.6591933337591027

Epoch: 6| Step: 1
Training loss: 0.8781473636627197
Validation loss: 1.636429525190784

Epoch: 6| Step: 2
Training loss: 0.9443451166152954
Validation loss: 1.6450636938054075

Epoch: 6| Step: 3
Training loss: 0.9529762268066406
Validation loss: 1.6899990856006581

Epoch: 6| Step: 4
Training loss: 0.5285281538963318
Validation loss: 1.7880056545298586

Epoch: 6| Step: 5
Training loss: 1.1108062267303467
Validation loss: 1.8310963338421238

Epoch: 6| Step: 6
Training loss: 1.0003201961517334
Validation loss: 1.897514759853322

Epoch: 6| Step: 7
Training loss: 1.0846867561340332
Validation loss: 1.8910659948984783

Epoch: 6| Step: 8
Training loss: 1.2370803356170654
Validation loss: 1.8973064486698439

Epoch: 6| Step: 9
Training loss: 1.3027520179748535
Validation loss: 1.8747055146002

Epoch: 6| Step: 10
Training loss: 1.0544893741607666
Validation loss: 1.873438827453121

Epoch: 6| Step: 11
Training loss: 0.48869186639785767
Validation loss: 1.8614881423211866

Epoch: 6| Step: 12
Training loss: 1.4691203832626343
Validation loss: 1.769882417494251

Epoch: 6| Step: 13
Training loss: 0.9825230836868286
Validation loss: 1.7275892053881

Epoch: 249| Step: 0
Training loss: 0.8546113967895508
Validation loss: 1.674617003369075

Epoch: 6| Step: 1
Training loss: 1.043733835220337
Validation loss: 1.654511869594615

Epoch: 6| Step: 2
Training loss: 1.0167250633239746
Validation loss: 1.615564125840382

Epoch: 6| Step: 3
Training loss: 1.013575792312622
Validation loss: 1.6411934270653674

Epoch: 6| Step: 4
Training loss: 1.0161728858947754
Validation loss: 1.6144567804951822

Epoch: 6| Step: 5
Training loss: 1.3926864862442017
Validation loss: 1.6340187877737067

Epoch: 6| Step: 6
Training loss: 1.1161246299743652
Validation loss: 1.6573998312796316

Epoch: 6| Step: 7
Training loss: 0.6618409156799316
Validation loss: 1.6774211006779824

Epoch: 6| Step: 8
Training loss: 0.6963106393814087
Validation loss: 1.7531619751325218

Epoch: 6| Step: 9
Training loss: 1.25288724899292
Validation loss: 1.7843542227181055

Epoch: 6| Step: 10
Training loss: 1.4883558750152588
Validation loss: 1.8140002642908404

Epoch: 6| Step: 11
Training loss: 0.5198934674263
Validation loss: 1.8528854065043951

Epoch: 6| Step: 12
Training loss: 0.8981812000274658
Validation loss: 1.8131761217630038

Epoch: 6| Step: 13
Training loss: 1.5803143978118896
Validation loss: 1.7858470011782903

Epoch: 250| Step: 0
Training loss: 0.8997135758399963
Validation loss: 1.7740532223896315

Epoch: 6| Step: 1
Training loss: 1.0853320360183716
Validation loss: 1.7248612424378753

Epoch: 6| Step: 2
Training loss: 0.7681211829185486
Validation loss: 1.6831893062078824

Epoch: 6| Step: 3
Training loss: 0.8002979755401611
Validation loss: 1.70211350276906

Epoch: 6| Step: 4
Training loss: 1.1596286296844482
Validation loss: 1.6886353851646505

Epoch: 6| Step: 5
Training loss: 1.4298088550567627
Validation loss: 1.6633697837911627

Epoch: 6| Step: 6
Training loss: 0.9049513339996338
Validation loss: 1.6949640051011117

Epoch: 6| Step: 7
Training loss: 0.7297970056533813
Validation loss: 1.741859237353007

Epoch: 6| Step: 8
Training loss: 0.5580152273178101
Validation loss: 1.801582626117173

Epoch: 6| Step: 9
Training loss: 0.7927922606468201
Validation loss: 1.850994267771321

Epoch: 6| Step: 10
Training loss: 1.1093562841415405
Validation loss: 1.9296956844227289

Epoch: 6| Step: 11
Training loss: 1.5129365921020508
Validation loss: 1.9580404835362588

Epoch: 6| Step: 12
Training loss: 1.3726184368133545
Validation loss: 1.9456247463021228

Epoch: 6| Step: 13
Training loss: 1.0264756679534912
Validation loss: 1.90828921205254

Epoch: 251| Step: 0
Training loss: 0.6951737403869629
Validation loss: 1.8032651703844789

Epoch: 6| Step: 1
Training loss: 0.5465304851531982
Validation loss: 1.7278951791024977

Epoch: 6| Step: 2
Training loss: 1.3445611000061035
Validation loss: 1.687803432505618

Epoch: 6| Step: 3
Training loss: 1.3624002933502197
Validation loss: 1.6887000491542201

Epoch: 6| Step: 4
Training loss: 1.2921696901321411
Validation loss: 1.6924833507948025

Epoch: 6| Step: 5
Training loss: 1.1179805994033813
Validation loss: 1.6789551152977893

Epoch: 6| Step: 6
Training loss: 0.9607072472572327
Validation loss: 1.667693050958777

Epoch: 6| Step: 7
Training loss: 1.3080037832260132
Validation loss: 1.6541049403529013

Epoch: 6| Step: 8
Training loss: 0.8915201425552368
Validation loss: 1.6675048323087795

Epoch: 6| Step: 9
Training loss: 1.0022324323654175
Validation loss: 1.6606089280497642

Epoch: 6| Step: 10
Training loss: 0.6099624037742615
Validation loss: 1.6836516959692842

Epoch: 6| Step: 11
Training loss: 1.0163815021514893
Validation loss: 1.7082543347471504

Epoch: 6| Step: 12
Training loss: 0.912030816078186
Validation loss: 1.7535186941905687

Epoch: 6| Step: 13
Training loss: 1.464415431022644
Validation loss: 1.7746094670346988

Epoch: 252| Step: 0
Training loss: 1.1079468727111816
Validation loss: 1.8783766787539247

Epoch: 6| Step: 1
Training loss: 0.7514598369598389
Validation loss: 1.929846049636923

Epoch: 6| Step: 2
Training loss: 0.9175674319267273
Validation loss: 1.8931223397613854

Epoch: 6| Step: 3
Training loss: 1.5568931102752686
Validation loss: 1.8531175557003225

Epoch: 6| Step: 4
Training loss: 1.0851778984069824
Validation loss: 1.8721758140030729

Epoch: 6| Step: 5
Training loss: 0.7532901167869568
Validation loss: 1.82413693910004

Epoch: 6| Step: 6
Training loss: 1.0933516025543213
Validation loss: 1.7528283378129363

Epoch: 6| Step: 7
Training loss: 0.7596719264984131
Validation loss: 1.707487170414258

Epoch: 6| Step: 8
Training loss: 0.8332956433296204
Validation loss: 1.7164625461383531

Epoch: 6| Step: 9
Training loss: 1.1505014896392822
Validation loss: 1.69360605747469

Epoch: 6| Step: 10
Training loss: 1.0166478157043457
Validation loss: 1.6653615998965439

Epoch: 6| Step: 11
Training loss: 0.7812085151672363
Validation loss: 1.6821294817873227

Epoch: 6| Step: 12
Training loss: 1.2459170818328857
Validation loss: 1.7026778959458875

Epoch: 6| Step: 13
Training loss: 0.7456576228141785
Validation loss: 1.7170110235932052

Epoch: 253| Step: 0
Training loss: 1.2288520336151123
Validation loss: 1.7169129707479989

Epoch: 6| Step: 1
Training loss: 1.1127512454986572
Validation loss: 1.7509227914194907

Epoch: 6| Step: 2
Training loss: 0.8215044736862183
Validation loss: 1.715440091266427

Epoch: 6| Step: 3
Training loss: 0.9305067658424377
Validation loss: 1.744584019466113

Epoch: 6| Step: 4
Training loss: 0.6891865134239197
Validation loss: 1.7777188798432708

Epoch: 6| Step: 5
Training loss: 0.6528739929199219
Validation loss: 1.8001840024866083

Epoch: 6| Step: 6
Training loss: 1.5465620756149292
Validation loss: 1.7544764882774764

Epoch: 6| Step: 7
Training loss: 1.4807685613632202
Validation loss: 1.7007924895132742

Epoch: 6| Step: 8
Training loss: 1.0612573623657227
Validation loss: 1.6831399932984383

Epoch: 6| Step: 9
Training loss: 0.417237788438797
Validation loss: 1.661061216426152

Epoch: 6| Step: 10
Training loss: 0.8269423246383667
Validation loss: 1.6526787229763564

Epoch: 6| Step: 11
Training loss: 0.8170351982116699
Validation loss: 1.6283579116226525

Epoch: 6| Step: 12
Training loss: 1.0749762058258057
Validation loss: 1.6335938835656771

Epoch: 6| Step: 13
Training loss: 0.9291532039642334
Validation loss: 1.6426745986425748

Epoch: 254| Step: 0
Training loss: 0.8587369918823242
Validation loss: 1.6770717495231218

Epoch: 6| Step: 1
Training loss: 0.8115326166152954
Validation loss: 1.7356412872191398

Epoch: 6| Step: 2
Training loss: 0.9000452756881714
Validation loss: 1.8041909868999193

Epoch: 6| Step: 3
Training loss: 1.135392189025879
Validation loss: 1.7944918755562074

Epoch: 6| Step: 4
Training loss: 0.8617528080940247
Validation loss: 1.8261551369902909

Epoch: 6| Step: 5
Training loss: 1.200174331665039
Validation loss: 1.8187298082536267

Epoch: 6| Step: 6
Training loss: 0.7354626655578613
Validation loss: 1.7343832421046432

Epoch: 6| Step: 7
Training loss: 0.9817922115325928
Validation loss: 1.6742671779406968

Epoch: 6| Step: 8
Training loss: 1.0306334495544434
Validation loss: 1.6852679432079356

Epoch: 6| Step: 9
Training loss: 0.8775128722190857
Validation loss: 1.6823272833260157

Epoch: 6| Step: 10
Training loss: 0.8571488857269287
Validation loss: 1.7034171883777907

Epoch: 6| Step: 11
Training loss: 0.822997510433197
Validation loss: 1.6957376874903196

Epoch: 6| Step: 12
Training loss: 1.4408044815063477
Validation loss: 1.7615384094176754

Epoch: 6| Step: 13
Training loss: 0.8756551146507263
Validation loss: 1.7713105806740381

Epoch: 255| Step: 0
Training loss: 1.3030052185058594
Validation loss: 1.8163554232607606

Epoch: 6| Step: 1
Training loss: 0.7000705599784851
Validation loss: 1.8085895443475375

Epoch: 6| Step: 2
Training loss: 1.4913039207458496
Validation loss: 1.8086683442515712

Epoch: 6| Step: 3
Training loss: 0.6469712257385254
Validation loss: 1.7693830843894713

Epoch: 6| Step: 4
Training loss: 1.1105655431747437
Validation loss: 1.7364659424751037

Epoch: 6| Step: 5
Training loss: 0.8464371562004089
Validation loss: 1.6844762166341145

Epoch: 6| Step: 6
Training loss: 0.7316323518753052
Validation loss: 1.6730916077090847

Epoch: 6| Step: 7
Training loss: 1.3679580688476562
Validation loss: 1.645136990854817

Epoch: 6| Step: 8
Training loss: 0.6783207058906555
Validation loss: 1.6425606460981472

Epoch: 6| Step: 9
Training loss: 1.3859119415283203
Validation loss: 1.649966586020685

Epoch: 6| Step: 10
Training loss: 0.32086181640625
Validation loss: 1.639390044314887

Epoch: 6| Step: 11
Training loss: 0.6304787397384644
Validation loss: 1.6658761219311786

Epoch: 6| Step: 12
Training loss: 0.8648335337638855
Validation loss: 1.7250190499008342

Epoch: 6| Step: 13
Training loss: 0.9616587162017822
Validation loss: 1.7743369251169183

Epoch: 256| Step: 0
Training loss: 0.954521656036377
Validation loss: 1.8460011430965957

Epoch: 6| Step: 1
Training loss: 0.7709927558898926
Validation loss: 1.8570369225676342

Epoch: 6| Step: 2
Training loss: 1.1456451416015625
Validation loss: 1.8242457118085635

Epoch: 6| Step: 3
Training loss: 1.2524926662445068
Validation loss: 1.7473810847087572

Epoch: 6| Step: 4
Training loss: 0.7191033959388733
Validation loss: 1.6267875702150407

Epoch: 6| Step: 5
Training loss: 0.8583954572677612
Validation loss: 1.604697230041668

Epoch: 6| Step: 6
Training loss: 0.9683966636657715
Validation loss: 1.6241373682534823

Epoch: 6| Step: 7
Training loss: 0.8170730471611023
Validation loss: 1.6226029895967053

Epoch: 6| Step: 8
Training loss: 1.2519358396530151
Validation loss: 1.6350667681745303

Epoch: 6| Step: 9
Training loss: 1.0393288135528564
Validation loss: 1.60949795733216

Epoch: 6| Step: 10
Training loss: 0.8102751970291138
Validation loss: 1.6084636590814079

Epoch: 6| Step: 11
Training loss: 0.8728402256965637
Validation loss: 1.6547103171707482

Epoch: 6| Step: 12
Training loss: 1.3469781875610352
Validation loss: 1.7258502655131842

Epoch: 6| Step: 13
Training loss: 0.3285529911518097
Validation loss: 1.8169375350398402

Epoch: 257| Step: 0
Training loss: 0.9391189813613892
Validation loss: 1.905951443538871

Epoch: 6| Step: 1
Training loss: 1.128357172012329
Validation loss: 1.890150979001035

Epoch: 6| Step: 2
Training loss: 0.9696708917617798
Validation loss: 1.7504155341015066

Epoch: 6| Step: 3
Training loss: 1.4250932931900024
Validation loss: 1.6712387466943392

Epoch: 6| Step: 4
Training loss: 0.8594807982444763
Validation loss: 1.6436655034301102

Epoch: 6| Step: 5
Training loss: 0.9582226276397705
Validation loss: 1.661743821636323

Epoch: 6| Step: 6
Training loss: 0.778852641582489
Validation loss: 1.636868760149966

Epoch: 6| Step: 7
Training loss: 0.8137785792350769
Validation loss: 1.6663963153798094

Epoch: 6| Step: 8
Training loss: 1.1234230995178223
Validation loss: 1.6548109913385043

Epoch: 6| Step: 9
Training loss: 0.6215518712997437
Validation loss: 1.665882533596408

Epoch: 6| Step: 10
Training loss: 0.8367612361907959
Validation loss: 1.7217227438444733

Epoch: 6| Step: 11
Training loss: 0.967931866645813
Validation loss: 1.7582094118159304

Epoch: 6| Step: 12
Training loss: 1.27776038646698
Validation loss: 1.7595396221324962

Epoch: 6| Step: 13
Training loss: 0.44186994433403015
Validation loss: 1.7369951009750366

Epoch: 258| Step: 0
Training loss: 0.7708636522293091
Validation loss: 1.739002263674172

Epoch: 6| Step: 1
Training loss: 0.47733446955680847
Validation loss: 1.7295665048783826

Epoch: 6| Step: 2
Training loss: 0.9107319116592407
Validation loss: 1.7131556272506714

Epoch: 6| Step: 3
Training loss: 0.47320300340652466
Validation loss: 1.6526113754959517

Epoch: 6| Step: 4
Training loss: 0.6709815263748169
Validation loss: 1.6459733927121727

Epoch: 6| Step: 5
Training loss: 1.0429658889770508
Validation loss: 1.6635506371016144

Epoch: 6| Step: 6
Training loss: 0.8637934327125549
Validation loss: 1.6760314036441106

Epoch: 6| Step: 7
Training loss: 0.9354344606399536
Validation loss: 1.7219163858762352

Epoch: 6| Step: 8
Training loss: 0.8529250621795654
Validation loss: 1.7604704364653556

Epoch: 6| Step: 9
Training loss: 1.5502533912658691
Validation loss: 1.8135734758069437

Epoch: 6| Step: 10
Training loss: 1.6640610694885254
Validation loss: 1.8285761007698633

Epoch: 6| Step: 11
Training loss: 0.8623344898223877
Validation loss: 1.8310587431794854

Epoch: 6| Step: 12
Training loss: 0.7244905829429626
Validation loss: 1.79771892357898

Epoch: 6| Step: 13
Training loss: 1.4129960536956787
Validation loss: 1.723719737863028

Epoch: 259| Step: 0
Training loss: 0.5269342660903931
Validation loss: 1.6745474338531494

Epoch: 6| Step: 1
Training loss: 0.4757618010044098
Validation loss: 1.6544674981024958

Epoch: 6| Step: 2
Training loss: 1.1759800910949707
Validation loss: 1.628157272133776

Epoch: 6| Step: 3
Training loss: 1.1773312091827393
Validation loss: 1.63606769551513

Epoch: 6| Step: 4
Training loss: 0.9557791948318481
Validation loss: 1.6419455274458854

Epoch: 6| Step: 5
Training loss: 0.5716302990913391
Validation loss: 1.6192527612050374

Epoch: 6| Step: 6
Training loss: 0.7055994272232056
Validation loss: 1.6082498899070166

Epoch: 6| Step: 7
Training loss: 1.0247762203216553
Validation loss: 1.596567387221962

Epoch: 6| Step: 8
Training loss: 0.6896125674247742
Validation loss: 1.6207375577701035

Epoch: 6| Step: 9
Training loss: 1.543384313583374
Validation loss: 1.687143716760861

Epoch: 6| Step: 10
Training loss: 0.5971709489822388
Validation loss: 1.7591997218388382

Epoch: 6| Step: 11
Training loss: 0.7767907977104187
Validation loss: 1.7903639552413777

Epoch: 6| Step: 12
Training loss: 1.4078471660614014
Validation loss: 1.8329556757403958

Epoch: 6| Step: 13
Training loss: 1.2878128290176392
Validation loss: 1.8010164448010024

Epoch: 260| Step: 0
Training loss: 1.4957358837127686
Validation loss: 1.7249342036503617

Epoch: 6| Step: 1
Training loss: 1.1025904417037964
Validation loss: 1.7274397188617336

Epoch: 6| Step: 2
Training loss: 0.6483620405197144
Validation loss: 1.7065897859552854

Epoch: 6| Step: 3
Training loss: 0.6691914796829224
Validation loss: 1.6902302439494798

Epoch: 6| Step: 4
Training loss: 0.5690412521362305
Validation loss: 1.6755298645265642

Epoch: 6| Step: 5
Training loss: 1.1629345417022705
Validation loss: 1.7023590739055345

Epoch: 6| Step: 6
Training loss: 1.2195707559585571
Validation loss: 1.7200649079456125

Epoch: 6| Step: 7
Training loss: 1.001366138458252
Validation loss: 1.7316417963274064

Epoch: 6| Step: 8
Training loss: 0.6715928316116333
Validation loss: 1.7257342043743338

Epoch: 6| Step: 9
Training loss: 0.691633939743042
Validation loss: 1.786112214929314

Epoch: 6| Step: 10
Training loss: 1.2805089950561523
Validation loss: 1.84331759073401

Epoch: 6| Step: 11
Training loss: 0.9653092622756958
Validation loss: 1.866601961915211

Epoch: 6| Step: 12
Training loss: 0.7892389297485352
Validation loss: 1.8329754042369064

Epoch: 6| Step: 13
Training loss: 0.4994546175003052
Validation loss: 1.7661287579485165

Epoch: 261| Step: 0
Training loss: 1.4560052156448364
Validation loss: 1.683332044591186

Epoch: 6| Step: 1
Training loss: 0.9933148622512817
Validation loss: 1.635252054019641

Epoch: 6| Step: 2
Training loss: 0.8128602504730225
Validation loss: 1.5951618340707594

Epoch: 6| Step: 3
Training loss: 0.7098989486694336
Validation loss: 1.6121055080044655

Epoch: 6| Step: 4
Training loss: 0.8570235967636108
Validation loss: 1.6263523319716096

Epoch: 6| Step: 5
Training loss: 0.8583275675773621
Validation loss: 1.625876433105879

Epoch: 6| Step: 6
Training loss: 0.9062626361846924
Validation loss: 1.6198157982159687

Epoch: 6| Step: 7
Training loss: 1.0714046955108643
Validation loss: 1.6547366060236448

Epoch: 6| Step: 8
Training loss: 0.8462530970573425
Validation loss: 1.6938423648957284

Epoch: 6| Step: 9
Training loss: 0.6261997818946838
Validation loss: 1.716585696384471

Epoch: 6| Step: 10
Training loss: 1.2883802652359009
Validation loss: 1.7149826352314284

Epoch: 6| Step: 11
Training loss: 0.4135426878929138
Validation loss: 1.7070103960652505

Epoch: 6| Step: 12
Training loss: 1.2828505039215088
Validation loss: 1.7708149956118675

Epoch: 6| Step: 13
Training loss: 0.37980204820632935
Validation loss: 1.7473040921713716

Epoch: 262| Step: 0
Training loss: 1.3193562030792236
Validation loss: 1.7668781536881641

Epoch: 6| Step: 1
Training loss: 0.9582348465919495
Validation loss: 1.7682700618620841

Epoch: 6| Step: 2
Training loss: 0.7905008792877197
Validation loss: 1.731147901986235

Epoch: 6| Step: 3
Training loss: 0.4167555272579193
Validation loss: 1.7266758270161127

Epoch: 6| Step: 4
Training loss: 0.8424618244171143
Validation loss: 1.7252323524926299

Epoch: 6| Step: 5
Training loss: 1.2214057445526123
Validation loss: 1.689758377690469

Epoch: 6| Step: 6
Training loss: 0.9853323101997375
Validation loss: 1.6638681888580322

Epoch: 6| Step: 7
Training loss: 0.763701856136322
Validation loss: 1.6473117323331936

Epoch: 6| Step: 8
Training loss: 0.7032098174095154
Validation loss: 1.6379965851383824

Epoch: 6| Step: 9
Training loss: 1.165022611618042
Validation loss: 1.6432898557314308

Epoch: 6| Step: 10
Training loss: 0.6575889587402344
Validation loss: 1.6593818408186718

Epoch: 6| Step: 11
Training loss: 0.8084535002708435
Validation loss: 1.7148267825444539

Epoch: 6| Step: 12
Training loss: 0.8641476631164551
Validation loss: 1.7186951509086035

Epoch: 6| Step: 13
Training loss: 0.7985725402832031
Validation loss: 1.7385810267540716

Epoch: 263| Step: 0
Training loss: 1.1880284547805786
Validation loss: 1.7377140214366298

Epoch: 6| Step: 1
Training loss: 0.9591799378395081
Validation loss: 1.7110504219608922

Epoch: 6| Step: 2
Training loss: 0.5248720645904541
Validation loss: 1.672787397138534

Epoch: 6| Step: 3
Training loss: 0.7214410305023193
Validation loss: 1.6394567092259724

Epoch: 6| Step: 4
Training loss: 0.5990239381790161
Validation loss: 1.63804199875042

Epoch: 6| Step: 5
Training loss: 0.6618328094482422
Validation loss: 1.6303752519751107

Epoch: 6| Step: 6
Training loss: 0.7601345777511597
Validation loss: 1.6130025309901084

Epoch: 6| Step: 7
Training loss: 0.9176985025405884
Validation loss: 1.6157130989977109

Epoch: 6| Step: 8
Training loss: 0.573204517364502
Validation loss: 1.6072895039794266

Epoch: 6| Step: 9
Training loss: 0.9396824836730957
Validation loss: 1.6055714558529597

Epoch: 6| Step: 10
Training loss: 1.1781086921691895
Validation loss: 1.669329135648666

Epoch: 6| Step: 11
Training loss: 0.8585031032562256
Validation loss: 1.655336562023368

Epoch: 6| Step: 12
Training loss: 1.338458776473999
Validation loss: 1.6970892208878712

Epoch: 6| Step: 13
Training loss: 0.7481165528297424
Validation loss: 1.7158727504873788

Epoch: 264| Step: 0
Training loss: 0.9231640100479126
Validation loss: 1.6748235533314366

Epoch: 6| Step: 1
Training loss: 1.0870764255523682
Validation loss: 1.6901333793517082

Epoch: 6| Step: 2
Training loss: 0.9232639074325562
Validation loss: 1.691547232289468

Epoch: 6| Step: 3
Training loss: 1.0449268817901611
Validation loss: 1.6850372681053736

Epoch: 6| Step: 4
Training loss: 0.4731101989746094
Validation loss: 1.6981732947852022

Epoch: 6| Step: 5
Training loss: 0.9606621265411377
Validation loss: 1.6899558908195906

Epoch: 6| Step: 6
Training loss: 0.525810718536377
Validation loss: 1.6842687283792803

Epoch: 6| Step: 7
Training loss: 0.9489311575889587
Validation loss: 1.6874179417087185

Epoch: 6| Step: 8
Training loss: 0.6840025186538696
Validation loss: 1.7064103798199726

Epoch: 6| Step: 9
Training loss: 1.0831880569458008
Validation loss: 1.721117970763996

Epoch: 6| Step: 10
Training loss: 1.0126357078552246
Validation loss: 1.7307584836918821

Epoch: 6| Step: 11
Training loss: 0.4711674451828003
Validation loss: 1.7617693742116292

Epoch: 6| Step: 12
Training loss: 0.9111253023147583
Validation loss: 1.7506856585061679

Epoch: 6| Step: 13
Training loss: 0.5771594643592834
Validation loss: 1.7568557275238859

Epoch: 265| Step: 0
Training loss: 0.8069595098495483
Validation loss: 1.7351378497257028

Epoch: 6| Step: 1
Training loss: 0.839426577091217
Validation loss: 1.7357319990793865

Epoch: 6| Step: 2
Training loss: 1.3727235794067383
Validation loss: 1.708560150156739

Epoch: 6| Step: 3
Training loss: 1.1349005699157715
Validation loss: 1.7424017229387838

Epoch: 6| Step: 4
Training loss: 0.9216493368148804
Validation loss: 1.7266836230472853

Epoch: 6| Step: 5
Training loss: 0.9949743151664734
Validation loss: 1.7250877516244048

Epoch: 6| Step: 6
Training loss: 0.7943152189254761
Validation loss: 1.7107783338075042

Epoch: 6| Step: 7
Training loss: 0.5447138547897339
Validation loss: 1.6672918476084226

Epoch: 6| Step: 8
Training loss: 0.4535074234008789
Validation loss: 1.6991403859148744

Epoch: 6| Step: 9
Training loss: 0.3769000470638275
Validation loss: 1.671540811497678

Epoch: 6| Step: 10
Training loss: 0.8570691347122192
Validation loss: 1.6649358054643035

Epoch: 6| Step: 11
Training loss: 0.7249993681907654
Validation loss: 1.6425185831644202

Epoch: 6| Step: 12
Training loss: 0.8556050658226013
Validation loss: 1.6317590052081692

Epoch: 6| Step: 13
Training loss: 0.879461407661438
Validation loss: 1.6536723465047858

Epoch: 266| Step: 0
Training loss: 0.7865704298019409
Validation loss: 1.6758348813620947

Epoch: 6| Step: 1
Training loss: 0.7585982084274292
Validation loss: 1.7059634391979506

Epoch: 6| Step: 2
Training loss: 0.7067114114761353
Validation loss: 1.702209049655545

Epoch: 6| Step: 3
Training loss: 0.7034450173377991
Validation loss: 1.7023161867613434

Epoch: 6| Step: 4
Training loss: 0.8768144845962524
Validation loss: 1.677560124346005

Epoch: 6| Step: 5
Training loss: 0.535618782043457
Validation loss: 1.6613747330122097

Epoch: 6| Step: 6
Training loss: 0.9931042194366455
Validation loss: 1.6742818470924132

Epoch: 6| Step: 7
Training loss: 0.5536133050918579
Validation loss: 1.6844581109221264

Epoch: 6| Step: 8
Training loss: 0.6967369318008423
Validation loss: 1.7553061285326559

Epoch: 6| Step: 9
Training loss: 0.6045615077018738
Validation loss: 1.7754925591971285

Epoch: 6| Step: 10
Training loss: 1.1822128295898438
Validation loss: 1.7877773802767518

Epoch: 6| Step: 11
Training loss: 1.091401219367981
Validation loss: 1.7866772964436521

Epoch: 6| Step: 12
Training loss: 1.3080759048461914
Validation loss: 1.78719671182735

Epoch: 6| Step: 13
Training loss: 0.6540796756744385
Validation loss: 1.7026205960140433

Epoch: 267| Step: 0
Training loss: 0.41174519062042236
Validation loss: 1.6969807071070517

Epoch: 6| Step: 1
Training loss: 1.0090067386627197
Validation loss: 1.6734982536685081

Epoch: 6| Step: 2
Training loss: 1.2258450984954834
Validation loss: 1.6871248009384319

Epoch: 6| Step: 3
Training loss: 0.2903348207473755
Validation loss: 1.7220659179072226

Epoch: 6| Step: 4
Training loss: 0.5500600337982178
Validation loss: 1.791611740666051

Epoch: 6| Step: 5
Training loss: 0.6206948161125183
Validation loss: 1.7851377482055335

Epoch: 6| Step: 6
Training loss: 1.0394186973571777
Validation loss: 1.7890900386277067

Epoch: 6| Step: 7
Training loss: 0.9496052861213684
Validation loss: 1.7006136217424948

Epoch: 6| Step: 8
Training loss: 0.9770467281341553
Validation loss: 1.6874109096424554

Epoch: 6| Step: 9
Training loss: 0.6165265440940857
Validation loss: 1.6485161332673923

Epoch: 6| Step: 10
Training loss: 1.6629493236541748
Validation loss: 1.6605054934819539

Epoch: 6| Step: 11
Training loss: 0.7152711153030396
Validation loss: 1.6952256810280584

Epoch: 6| Step: 12
Training loss: 0.5452684164047241
Validation loss: 1.7537676249780962

Epoch: 6| Step: 13
Training loss: 1.116514801979065
Validation loss: 1.8172640864567091

Epoch: 268| Step: 0
Training loss: 1.1056725978851318
Validation loss: 1.738341725000771

Epoch: 6| Step: 1
Training loss: 1.026648759841919
Validation loss: 1.6989110285235989

Epoch: 6| Step: 2
Training loss: 1.5607937574386597
Validation loss: 1.6395377625701248

Epoch: 6| Step: 3
Training loss: 1.000226378440857
Validation loss: 1.6455852088107858

Epoch: 6| Step: 4
Training loss: 0.3598499894142151
Validation loss: 1.6603160519753732

Epoch: 6| Step: 5
Training loss: 0.501893937587738
Validation loss: 1.6471781038468885

Epoch: 6| Step: 6
Training loss: 0.42768868803977966
Validation loss: 1.700496309547014

Epoch: 6| Step: 7
Training loss: 0.968442440032959
Validation loss: 1.7576800930884577

Epoch: 6| Step: 8
Training loss: 0.7841376066207886
Validation loss: 1.7939469814300537

Epoch: 6| Step: 9
Training loss: 0.7684029340744019
Validation loss: 1.7573555336203626

Epoch: 6| Step: 10
Training loss: 1.0725922584533691
Validation loss: 1.7357614771012337

Epoch: 6| Step: 11
Training loss: 0.5668059587478638
Validation loss: 1.6807020787269837

Epoch: 6| Step: 12
Training loss: 0.7690462470054626
Validation loss: 1.6704680765828779

Epoch: 6| Step: 13
Training loss: 0.45066410303115845
Validation loss: 1.6908495990178918

Epoch: 269| Step: 0
Training loss: 1.0663259029388428
Validation loss: 1.702835484217572

Epoch: 6| Step: 1
Training loss: 0.9044846892356873
Validation loss: 1.7357696115329702

Epoch: 6| Step: 2
Training loss: 0.5628914833068848
Validation loss: 1.7331334237129457

Epoch: 6| Step: 3
Training loss: 0.7888650298118591
Validation loss: 1.730795124525665

Epoch: 6| Step: 4
Training loss: 0.8851584792137146
Validation loss: 1.7234589951012724

Epoch: 6| Step: 5
Training loss: 0.3460778295993805
Validation loss: 1.7371367690383748

Epoch: 6| Step: 6
Training loss: 0.6718529462814331
Validation loss: 1.692674421495007

Epoch: 6| Step: 7
Training loss: 0.9702595472335815
Validation loss: 1.709951235402015

Epoch: 6| Step: 8
Training loss: 0.5345642566680908
Validation loss: 1.6921750678811023

Epoch: 6| Step: 9
Training loss: 1.6167852878570557
Validation loss: 1.6536198662173363

Epoch: 6| Step: 10
Training loss: 0.9661464691162109
Validation loss: 1.637258307908171

Epoch: 6| Step: 11
Training loss: 0.9698611497879028
Validation loss: 1.6554215710650209

Epoch: 6| Step: 12
Training loss: 0.7106205224990845
Validation loss: 1.6766770847382084

Epoch: 6| Step: 13
Training loss: 0.23922188580036163
Validation loss: 1.6810000147870792

Epoch: 270| Step: 0
Training loss: 0.4614710211753845
Validation loss: 1.6769823425559587

Epoch: 6| Step: 1
Training loss: 0.5704479217529297
Validation loss: 1.68594075915634

Epoch: 6| Step: 2
Training loss: 0.9980091452598572
Validation loss: 1.6631834301897275

Epoch: 6| Step: 3
Training loss: 0.7979925870895386
Validation loss: 1.682539132333571

Epoch: 6| Step: 4
Training loss: 0.7730026245117188
Validation loss: 1.6820381149168937

Epoch: 6| Step: 5
Training loss: 0.7191267609596252
Validation loss: 1.6785458428885347

Epoch: 6| Step: 6
Training loss: 1.2030870914459229
Validation loss: 1.6905928709173714

Epoch: 6| Step: 7
Training loss: 0.9284635782241821
Validation loss: 1.6756230964455554

Epoch: 6| Step: 8
Training loss: 1.0907398462295532
Validation loss: 1.6892938959983088

Epoch: 6| Step: 9
Training loss: 0.8536931872367859
Validation loss: 1.6873087075448805

Epoch: 6| Step: 10
Training loss: 0.7443253993988037
Validation loss: 1.7286475960926344

Epoch: 6| Step: 11
Training loss: 0.779949426651001
Validation loss: 1.7203404083046863

Epoch: 6| Step: 12
Training loss: 0.5569525361061096
Validation loss: 1.7393741069301483

Epoch: 6| Step: 13
Training loss: 1.0206971168518066
Validation loss: 1.7000933129300353

Epoch: 271| Step: 0
Training loss: 0.8365330696105957
Validation loss: 1.7253067903621222

Epoch: 6| Step: 1
Training loss: 0.8489930629730225
Validation loss: 1.6775022052949475

Epoch: 6| Step: 2
Training loss: 0.7132678627967834
Validation loss: 1.6728655651051512

Epoch: 6| Step: 3
Training loss: 1.2453579902648926
Validation loss: 1.6972065600015784

Epoch: 6| Step: 4
Training loss: 0.4046650528907776
Validation loss: 1.6868921941326511

Epoch: 6| Step: 5
Training loss: 0.9753804206848145
Validation loss: 1.6853096587683565

Epoch: 6| Step: 6
Training loss: 0.8355845212936401
Validation loss: 1.71723235038019

Epoch: 6| Step: 7
Training loss: 1.0489749908447266
Validation loss: 1.8191166154799923

Epoch: 6| Step: 8
Training loss: 0.803674578666687
Validation loss: 1.8836520000170636

Epoch: 6| Step: 9
Training loss: 0.8017898201942444
Validation loss: 1.8978959924431258

Epoch: 6| Step: 10
Training loss: 0.9550611972808838
Validation loss: 1.8737141624573739

Epoch: 6| Step: 11
Training loss: 0.5219475030899048
Validation loss: 1.7143777455053022

Epoch: 6| Step: 12
Training loss: 1.1668701171875
Validation loss: 1.6307068101821407

Epoch: 6| Step: 13
Training loss: 0.42908263206481934
Validation loss: 1.6291847023912656

Epoch: 272| Step: 0
Training loss: 0.7600332498550415
Validation loss: 1.6136936256962437

Epoch: 6| Step: 1
Training loss: 1.0298100709915161
Validation loss: 1.6134137991935975

Epoch: 6| Step: 2
Training loss: 1.0694434642791748
Validation loss: 1.6154108047485352

Epoch: 6| Step: 3
Training loss: 0.6957453489303589
Validation loss: 1.638688248972739

Epoch: 6| Step: 4
Training loss: 0.825976550579071
Validation loss: 1.7153727905724638

Epoch: 6| Step: 5
Training loss: 0.7425951957702637
Validation loss: 1.7679200685152443

Epoch: 6| Step: 6
Training loss: 0.7209571003913879
Validation loss: 1.7481956379387968

Epoch: 6| Step: 7
Training loss: 0.2983781397342682
Validation loss: 1.7033007234655402

Epoch: 6| Step: 8
Training loss: 0.9948344230651855
Validation loss: 1.706014475514812

Epoch: 6| Step: 9
Training loss: 0.7655344605445862
Validation loss: 1.702448429599885

Epoch: 6| Step: 10
Training loss: 1.0748798847198486
Validation loss: 1.7196908381677443

Epoch: 6| Step: 11
Training loss: 0.843479335308075
Validation loss: 1.7027072560402654

Epoch: 6| Step: 12
Training loss: 0.8513701558113098
Validation loss: 1.7049845367349603

Epoch: 6| Step: 13
Training loss: 0.3999748229980469
Validation loss: 1.6899288803018548

Epoch: 273| Step: 0
Training loss: 0.9854906797409058
Validation loss: 1.716008799050444

Epoch: 6| Step: 1
Training loss: 0.7363170981407166
Validation loss: 1.684414444431182

Epoch: 6| Step: 2
Training loss: 0.5822568535804749
Validation loss: 1.7308672781913512

Epoch: 6| Step: 3
Training loss: 0.6330435872077942
Validation loss: 1.7329676189730245

Epoch: 6| Step: 4
Training loss: 0.7629000544548035
Validation loss: 1.7026982012615408

Epoch: 6| Step: 5
Training loss: 0.9391077756881714
Validation loss: 1.6775030448872557

Epoch: 6| Step: 6
Training loss: 0.4764277935028076
Validation loss: 1.669354610545661

Epoch: 6| Step: 7
Training loss: 0.5602940320968628
Validation loss: 1.641722640683574

Epoch: 6| Step: 8
Training loss: 0.7443631887435913
Validation loss: 1.6320697927987704

Epoch: 6| Step: 9
Training loss: 0.9008288383483887
Validation loss: 1.6219689435856317

Epoch: 6| Step: 10
Training loss: 0.8293176293373108
Validation loss: 1.6200126178802983

Epoch: 6| Step: 11
Training loss: 1.130270004272461
Validation loss: 1.6333699675016506

Epoch: 6| Step: 12
Training loss: 0.8272969722747803
Validation loss: 1.6443008927888767

Epoch: 6| Step: 13
Training loss: 0.8997839689254761
Validation loss: 1.6614867461624967

Epoch: 274| Step: 0
Training loss: 0.7023812532424927
Validation loss: 1.6631733691820534

Epoch: 6| Step: 1
Training loss: 0.72894287109375
Validation loss: 1.7447514533996582

Epoch: 6| Step: 2
Training loss: 0.7795872688293457
Validation loss: 1.8733195194634058

Epoch: 6| Step: 3
Training loss: 0.6887314319610596
Validation loss: 1.9243903775368967

Epoch: 6| Step: 4
Training loss: 1.016775131225586
Validation loss: 1.8923931749918128

Epoch: 6| Step: 5
Training loss: 0.8472026586532593
Validation loss: 1.7890622359450146

Epoch: 6| Step: 6
Training loss: 0.4472333490848541
Validation loss: 1.675014147194483

Epoch: 6| Step: 7
Training loss: 0.7882689833641052
Validation loss: 1.6100042596940072

Epoch: 6| Step: 8
Training loss: 0.6996486186981201
Validation loss: 1.6256813926081504

Epoch: 6| Step: 9
Training loss: 0.9292169809341431
Validation loss: 1.606900768895303

Epoch: 6| Step: 10
Training loss: 0.830009400844574
Validation loss: 1.6000431878592378

Epoch: 6| Step: 11
Training loss: 1.40342378616333
Validation loss: 1.593742883974506

Epoch: 6| Step: 12
Training loss: 0.6907030344009399
Validation loss: 1.599691960119432

Epoch: 6| Step: 13
Training loss: 0.9272973537445068
Validation loss: 1.6696131511401104

Epoch: 275| Step: 0
Training loss: 1.218898892402649
Validation loss: 1.7683326223845124

Epoch: 6| Step: 1
Training loss: 0.7594317197799683
Validation loss: 1.7926303725088797

Epoch: 6| Step: 2
Training loss: 0.9008594751358032
Validation loss: 1.749295852517569

Epoch: 6| Step: 3
Training loss: 0.6836397647857666
Validation loss: 1.7159886590896114

Epoch: 6| Step: 4
Training loss: 1.050506830215454
Validation loss: 1.707195907510737

Epoch: 6| Step: 5
Training loss: 0.32770857214927673
Validation loss: 1.6802322710714033

Epoch: 6| Step: 6
Training loss: 0.8123248219490051
Validation loss: 1.685711310755822

Epoch: 6| Step: 7
Training loss: 0.5618991851806641
Validation loss: 1.6621962465265745

Epoch: 6| Step: 8
Training loss: 0.5373867750167847
Validation loss: 1.7172138806312316

Epoch: 6| Step: 9
Training loss: 1.0392000675201416
Validation loss: 1.6693175659384778

Epoch: 6| Step: 10
Training loss: 1.155337929725647
Validation loss: 1.7499568411099014

Epoch: 6| Step: 11
Training loss: 0.8910391330718994
Validation loss: 1.7654383451707902

Epoch: 6| Step: 12
Training loss: 0.6994339227676392
Validation loss: 1.7753133837894728

Epoch: 6| Step: 13
Training loss: 0.46059247851371765
Validation loss: 1.7677499171226256

Epoch: 276| Step: 0
Training loss: 0.6156286001205444
Validation loss: 1.7603044471433085

Epoch: 6| Step: 1
Training loss: 0.7125850319862366
Validation loss: 1.7971964177264963

Epoch: 6| Step: 2
Training loss: 0.7049567699432373
Validation loss: 1.7613813287468367

Epoch: 6| Step: 3
Training loss: 0.6730847358703613
Validation loss: 1.7251123330926383

Epoch: 6| Step: 4
Training loss: 0.7839657068252563
Validation loss: 1.697776513714944

Epoch: 6| Step: 5
Training loss: 0.7534193992614746
Validation loss: 1.654165191035117

Epoch: 6| Step: 6
Training loss: 0.7283684015274048
Validation loss: 1.6698031630567325

Epoch: 6| Step: 7
Training loss: 1.2826987504959106
Validation loss: 1.6665262817054667

Epoch: 6| Step: 8
Training loss: 0.7448010444641113
Validation loss: 1.6906192546249719

Epoch: 6| Step: 9
Training loss: 0.7260117530822754
Validation loss: 1.68681037938723

Epoch: 6| Step: 10
Training loss: 0.5204657316207886
Validation loss: 1.6792761382236276

Epoch: 6| Step: 11
Training loss: 1.2292590141296387
Validation loss: 1.7414345959181428

Epoch: 6| Step: 12
Training loss: 0.32264071702957153
Validation loss: 1.7310523986816406

Epoch: 6| Step: 13
Training loss: 0.5172926783561707
Validation loss: 1.7117988999171923

Epoch: 277| Step: 0
Training loss: 0.9245074987411499
Validation loss: 1.7214571250382291

Epoch: 6| Step: 1
Training loss: 0.5795496702194214
Validation loss: 1.678951741546713

Epoch: 6| Step: 2
Training loss: 1.3364405632019043
Validation loss: 1.6379034673013995

Epoch: 6| Step: 3
Training loss: 0.31296318769454956
Validation loss: 1.6614109636634908

Epoch: 6| Step: 4
Training loss: 0.8756614923477173
Validation loss: 1.641787258527612

Epoch: 6| Step: 5
Training loss: 0.3762565851211548
Validation loss: 1.6518830048140658

Epoch: 6| Step: 6
Training loss: 0.5099899768829346
Validation loss: 1.6669946537222913

Epoch: 6| Step: 7
Training loss: 0.7328441143035889
Validation loss: 1.6497694676922214

Epoch: 6| Step: 8
Training loss: 0.6425421237945557
Validation loss: 1.711563218024469

Epoch: 6| Step: 9
Training loss: 0.5902742743492126
Validation loss: 1.78401695400156

Epoch: 6| Step: 10
Training loss: 0.7549970149993896
Validation loss: 1.845441892582883

Epoch: 6| Step: 11
Training loss: 0.9838764667510986
Validation loss: 1.8308197580358034

Epoch: 6| Step: 12
Training loss: 1.2716729640960693
Validation loss: 1.7384589192687825

Epoch: 6| Step: 13
Training loss: 0.7225527763366699
Validation loss: 1.6860574650508102

Epoch: 278| Step: 0
Training loss: 0.6313291788101196
Validation loss: 1.6793198867510724

Epoch: 6| Step: 1
Training loss: 0.5538215637207031
Validation loss: 1.6718172834765526

Epoch: 6| Step: 2
Training loss: 1.0258450508117676
Validation loss: 1.6728319698764431

Epoch: 6| Step: 3
Training loss: 0.7950484752655029
Validation loss: 1.7115120477573846

Epoch: 6| Step: 4
Training loss: 0.817385733127594
Validation loss: 1.739782396183219

Epoch: 6| Step: 5
Training loss: 0.6420120000839233
Validation loss: 1.7918564837466004

Epoch: 6| Step: 6
Training loss: 0.6259018182754517
Validation loss: 1.841775389127834

Epoch: 6| Step: 7
Training loss: 0.19147807359695435
Validation loss: 1.8581719744590022

Epoch: 6| Step: 8
Training loss: 0.6493852138519287
Validation loss: 1.8656418913154191

Epoch: 6| Step: 9
Training loss: 0.8550232648849487
Validation loss: 1.8146307173595633

Epoch: 6| Step: 10
Training loss: 0.796995997428894
Validation loss: 1.8033439741339734

Epoch: 6| Step: 11
Training loss: 0.9878613352775574
Validation loss: 1.7692081979525986

Epoch: 6| Step: 12
Training loss: 1.4936671257019043
Validation loss: 1.7126483507053827

Epoch: 6| Step: 13
Training loss: 0.45537763833999634
Validation loss: 1.693884349638416

Epoch: 279| Step: 0
Training loss: 0.6575170159339905
Validation loss: 1.663187369223564

Epoch: 6| Step: 1
Training loss: 0.6843962669372559
Validation loss: 1.6891216372930875

Epoch: 6| Step: 2
Training loss: 1.0231541395187378
Validation loss: 1.720139818806802

Epoch: 6| Step: 3
Training loss: 0.7184809446334839
Validation loss: 1.7283316863480436

Epoch: 6| Step: 4
Training loss: 0.9481178522109985
Validation loss: 1.6894989064944688

Epoch: 6| Step: 5
Training loss: 0.7200024127960205
Validation loss: 1.736847239155923

Epoch: 6| Step: 6
Training loss: 0.6831552386283875
Validation loss: 1.6869321048900645

Epoch: 6| Step: 7
Training loss: 0.39823830127716064
Validation loss: 1.6765648998239988

Epoch: 6| Step: 8
Training loss: 0.6626887321472168
Validation loss: 1.6955575173900974

Epoch: 6| Step: 9
Training loss: 1.019303798675537
Validation loss: 1.687015059173748

Epoch: 6| Step: 10
Training loss: 0.4549490809440613
Validation loss: 1.6407319512418521

Epoch: 6| Step: 11
Training loss: 0.6312958002090454
Validation loss: 1.5691921108512468

Epoch: 6| Step: 12
Training loss: 1.1698479652404785
Validation loss: 1.5412918662512174

Epoch: 6| Step: 13
Training loss: 0.27590036392211914
Validation loss: 1.5660325096499534

Epoch: 280| Step: 0
Training loss: 0.7997651696205139
Validation loss: 1.582674826345136

Epoch: 6| Step: 1
Training loss: 0.5217939615249634
Validation loss: 1.5919521393314484

Epoch: 6| Step: 2
Training loss: 0.4593147039413452
Validation loss: 1.6260214223656604

Epoch: 6| Step: 3
Training loss: 0.7091464996337891
Validation loss: 1.692998924563008

Epoch: 6| Step: 4
Training loss: 0.8514385223388672
Validation loss: 1.7237594217382453

Epoch: 6| Step: 5
Training loss: 1.1157630681991577
Validation loss: 1.7167138579071208

Epoch: 6| Step: 6
Training loss: 0.8332902193069458
Validation loss: 1.7340794865803053

Epoch: 6| Step: 7
Training loss: 0.5575870275497437
Validation loss: 1.6940238501435967

Epoch: 6| Step: 8
Training loss: 1.3338775634765625
Validation loss: 1.6912220293475735

Epoch: 6| Step: 9
Training loss: 0.6215671300888062
Validation loss: 1.7237662525587185

Epoch: 6| Step: 10
Training loss: 1.2164688110351562
Validation loss: 1.7136846255230647

Epoch: 6| Step: 11
Training loss: 0.9541521072387695
Validation loss: 1.7563529514497327

Epoch: 6| Step: 12
Training loss: 0.45222583413124084
Validation loss: 1.7336212088984828

Epoch: 6| Step: 13
Training loss: 0.4700142443180084
Validation loss: 1.7582389718742781

Epoch: 281| Step: 0
Training loss: 0.573685884475708
Validation loss: 1.7939086050115607

Epoch: 6| Step: 1
Training loss: 0.6977720260620117
Validation loss: 1.8694292550445886

Epoch: 6| Step: 2
Training loss: 0.8370429277420044
Validation loss: 1.9367559507328977

Epoch: 6| Step: 3
Training loss: 0.7262607216835022
Validation loss: 1.8893373486816243

Epoch: 6| Step: 4
Training loss: 0.46726909279823303
Validation loss: 1.7661124390940512

Epoch: 6| Step: 5
Training loss: 0.8261740803718567
Validation loss: 1.6846477267562703

Epoch: 6| Step: 6
Training loss: 0.6248177886009216
Validation loss: 1.631205403676597

Epoch: 6| Step: 7
Training loss: 0.8327816128730774
Validation loss: 1.5871702586450884

Epoch: 6| Step: 8
Training loss: 1.4008479118347168
Validation loss: 1.5935337876760831

Epoch: 6| Step: 9
Training loss: 0.7981115579605103
Validation loss: 1.573726547661648

Epoch: 6| Step: 10
Training loss: 1.237221598625183
Validation loss: 1.5733357565377348

Epoch: 6| Step: 11
Training loss: 0.6551157236099243
Validation loss: 1.6242214313117407

Epoch: 6| Step: 12
Training loss: 0.9666017293930054
Validation loss: 1.7086989674516904

Epoch: 6| Step: 13
Training loss: 0.9045703411102295
Validation loss: 1.7561920586452688

Epoch: 282| Step: 0
Training loss: 0.671249270439148
Validation loss: 1.8674900493314188

Epoch: 6| Step: 1
Training loss: 0.7587834596633911
Validation loss: 1.8178458316351778

Epoch: 6| Step: 2
Training loss: 0.8004946708679199
Validation loss: 1.8034047311352146

Epoch: 6| Step: 3
Training loss: 0.70750892162323
Validation loss: 1.7439923196710565

Epoch: 6| Step: 4
Training loss: 0.4073546826839447
Validation loss: 1.739572927515994

Epoch: 6| Step: 5
Training loss: 0.7933927774429321
Validation loss: 1.678157514141452

Epoch: 6| Step: 6
Training loss: 0.44599106907844543
Validation loss: 1.6770292943523777

Epoch: 6| Step: 7
Training loss: 0.9846935868263245
Validation loss: 1.6805658404545119

Epoch: 6| Step: 8
Training loss: 0.5533862113952637
Validation loss: 1.6375314138268913

Epoch: 6| Step: 9
Training loss: 0.9260786175727844
Validation loss: 1.6758342648065219

Epoch: 6| Step: 10
Training loss: 1.0656521320343018
Validation loss: 1.651289806571058

Epoch: 6| Step: 11
Training loss: 0.6972423791885376
Validation loss: 1.6288694771387244

Epoch: 6| Step: 12
Training loss: 1.1053634881973267
Validation loss: 1.6022702545248053

Epoch: 6| Step: 13
Training loss: 0.5434806942939758
Validation loss: 1.6311876056014851

Epoch: 283| Step: 0
Training loss: 0.9668164253234863
Validation loss: 1.6400744556098856

Epoch: 6| Step: 1
Training loss: 0.7298809289932251
Validation loss: 1.6941515681564168

Epoch: 6| Step: 2
Training loss: 0.6720299124717712
Validation loss: 1.6727117133396927

Epoch: 6| Step: 3
Training loss: 0.19116254150867462
Validation loss: 1.7104986329232492

Epoch: 6| Step: 4
Training loss: 1.0347566604614258
Validation loss: 1.7628559893177402

Epoch: 6| Step: 5
Training loss: 0.48026955127716064
Validation loss: 1.78335250577619

Epoch: 6| Step: 6
Training loss: 0.8957313299179077
Validation loss: 1.7900830276550785

Epoch: 6| Step: 7
Training loss: 0.5775600671768188
Validation loss: 1.780013212593653

Epoch: 6| Step: 8
Training loss: 0.4853941798210144
Validation loss: 1.7079205936001194

Epoch: 6| Step: 9
Training loss: 0.6733372807502747
Validation loss: 1.6617160868901077

Epoch: 6| Step: 10
Training loss: 0.9225434064865112
Validation loss: 1.6315946630252305

Epoch: 6| Step: 11
Training loss: 1.0445704460144043
Validation loss: 1.6201542859436364

Epoch: 6| Step: 12
Training loss: 0.612884521484375
Validation loss: 1.5954764632768528

Epoch: 6| Step: 13
Training loss: 1.3323854207992554
Validation loss: 1.5872422110649846

Epoch: 284| Step: 0
Training loss: 0.3995700478553772
Validation loss: 1.5899621209790629

Epoch: 6| Step: 1
Training loss: 0.635847270488739
Validation loss: 1.6251806841101697

Epoch: 6| Step: 2
Training loss: 0.630987286567688
Validation loss: 1.6572322037912184

Epoch: 6| Step: 3
Training loss: 0.9140706062316895
Validation loss: 1.674975952794475

Epoch: 6| Step: 4
Training loss: 0.7626007199287415
Validation loss: 1.6878542759085213

Epoch: 6| Step: 5
Training loss: 0.5183854103088379
Validation loss: 1.7186376651128132

Epoch: 6| Step: 6
Training loss: 0.8676575422286987
Validation loss: 1.7303694486618042

Epoch: 6| Step: 7
Training loss: 0.4040091633796692
Validation loss: 1.7233018080393474

Epoch: 6| Step: 8
Training loss: 0.7335509657859802
Validation loss: 1.714870378535281

Epoch: 6| Step: 9
Training loss: 0.6191776990890503
Validation loss: 1.7058961352994364

Epoch: 6| Step: 10
Training loss: 0.740931510925293
Validation loss: 1.6865604436525734

Epoch: 6| Step: 11
Training loss: 1.0207780599594116
Validation loss: 1.6832276915991178

Epoch: 6| Step: 12
Training loss: 0.7235469818115234
Validation loss: 1.6507919514051048

Epoch: 6| Step: 13
Training loss: 1.0389251708984375
Validation loss: 1.687057819417728

Epoch: 285| Step: 0
Training loss: 0.5958571434020996
Validation loss: 1.677076296139789

Epoch: 6| Step: 1
Training loss: 1.216888189315796
Validation loss: 1.6581185248590284

Epoch: 6| Step: 2
Training loss: 0.6532599925994873
Validation loss: 1.7250160658231346

Epoch: 6| Step: 3
Training loss: 0.43576979637145996
Validation loss: 1.79936287864562

Epoch: 6| Step: 4
Training loss: 0.6935967206954956
Validation loss: 1.8317359403897358

Epoch: 6| Step: 5
Training loss: 0.8552250862121582
Validation loss: 1.8175568990809943

Epoch: 6| Step: 6
Training loss: 0.7404825091362
Validation loss: 1.721155007680257

Epoch: 6| Step: 7
Training loss: 1.0326118469238281
Validation loss: 1.690012478059338

Epoch: 6| Step: 8
Training loss: 0.3829994201660156
Validation loss: 1.6699624369221349

Epoch: 6| Step: 9
Training loss: 1.0922514200210571
Validation loss: 1.6565680990936935

Epoch: 6| Step: 10
Training loss: 0.8505315780639648
Validation loss: 1.6416937522990729

Epoch: 6| Step: 11
Training loss: 0.5309407711029053
Validation loss: 1.6429016487572783

Epoch: 6| Step: 12
Training loss: 0.643136203289032
Validation loss: 1.6753916612235449

Epoch: 6| Step: 13
Training loss: 0.5280541777610779
Validation loss: 1.6781878509829122

Epoch: 286| Step: 0
Training loss: 0.612035870552063
Validation loss: 1.7521369457244873

Epoch: 6| Step: 1
Training loss: 1.1847938299179077
Validation loss: 1.8313784086576073

Epoch: 6| Step: 2
Training loss: 0.9385932683944702
Validation loss: 1.8672087436081262

Epoch: 6| Step: 3
Training loss: 0.8573240041732788
Validation loss: 1.8956960324318177

Epoch: 6| Step: 4
Training loss: 0.6872868537902832
Validation loss: 1.909324816478196

Epoch: 6| Step: 5
Training loss: 0.7248458862304688
Validation loss: 1.8059218839932514

Epoch: 6| Step: 6
Training loss: 0.4301511347293854
Validation loss: 1.7604003798577093

Epoch: 6| Step: 7
Training loss: 0.7401503324508667
Validation loss: 1.7134759297934912

Epoch: 6| Step: 8
Training loss: 0.624259352684021
Validation loss: 1.688079728875109

Epoch: 6| Step: 9
Training loss: 0.6851388216018677
Validation loss: 1.6623090710691226

Epoch: 6| Step: 10
Training loss: 0.8240747451782227
Validation loss: 1.663694526559563

Epoch: 6| Step: 11
Training loss: 0.4757525622844696
Validation loss: 1.6504324764333747

Epoch: 6| Step: 12
Training loss: 0.7954627871513367
Validation loss: 1.651334975355415

Epoch: 6| Step: 13
Training loss: 1.255210280418396
Validation loss: 1.6363242172425794

Epoch: 287| Step: 0
Training loss: 0.9296824336051941
Validation loss: 1.63594259882486

Epoch: 6| Step: 1
Training loss: 0.9138532280921936
Validation loss: 1.6509821286765478

Epoch: 6| Step: 2
Training loss: 1.437479019165039
Validation loss: 1.7118225084838046

Epoch: 6| Step: 3
Training loss: 0.5037240982055664
Validation loss: 1.7021387610384213

Epoch: 6| Step: 4
Training loss: 0.711227297782898
Validation loss: 1.661153159474814

Epoch: 6| Step: 5
Training loss: 0.8292595148086548
Validation loss: 1.639706902606513

Epoch: 6| Step: 6
Training loss: 0.8262146711349487
Validation loss: 1.6462372349154564

Epoch: 6| Step: 7
Training loss: 1.0634464025497437
Validation loss: 1.6338561760481967

Epoch: 6| Step: 8
Training loss: 0.34950849413871765
Validation loss: 1.606139995718515

Epoch: 6| Step: 9
Training loss: 0.5708175897598267
Validation loss: 1.63924087760269

Epoch: 6| Step: 10
Training loss: 0.39220404624938965
Validation loss: 1.6292708061074699

Epoch: 6| Step: 11
Training loss: 0.7079389691352844
Validation loss: 1.6597595753208283

Epoch: 6| Step: 12
Training loss: 0.9492697715759277
Validation loss: 1.6772255589885097

Epoch: 6| Step: 13
Training loss: 0.6186392903327942
Validation loss: 1.773646270075152

Epoch: 288| Step: 0
Training loss: 0.3185705542564392
Validation loss: 1.772277488503405

Epoch: 6| Step: 1
Training loss: 0.7620499730110168
Validation loss: 1.816652250546281

Epoch: 6| Step: 2
Training loss: 0.3611554503440857
Validation loss: 1.8260856892472954

Epoch: 6| Step: 3
Training loss: 0.8756591081619263
Validation loss: 1.8289255736976542

Epoch: 6| Step: 4
Training loss: 0.6873629093170166
Validation loss: 1.810537871494088

Epoch: 6| Step: 5
Training loss: 0.6036520004272461
Validation loss: 1.785525724452029

Epoch: 6| Step: 6
Training loss: 0.964783787727356
Validation loss: 1.7058744917633712

Epoch: 6| Step: 7
Training loss: 0.5645708441734314
Validation loss: 1.6798377549776466

Epoch: 6| Step: 8
Training loss: 0.740324854850769
Validation loss: 1.6326713536375312

Epoch: 6| Step: 9
Training loss: 0.9024600982666016
Validation loss: 1.677443019805416

Epoch: 6| Step: 10
Training loss: 1.182077169418335
Validation loss: 1.6232050567544916

Epoch: 6| Step: 11
Training loss: 0.8959562182426453
Validation loss: 1.6635893801207184

Epoch: 6| Step: 12
Training loss: 0.5592333674430847
Validation loss: 1.6127227692193882

Epoch: 6| Step: 13
Training loss: 0.8155553340911865
Validation loss: 1.6170275929153606

Epoch: 289| Step: 0
Training loss: 0.5361627340316772
Validation loss: 1.6511275934916672

Epoch: 6| Step: 1
Training loss: 0.8308143615722656
Validation loss: 1.696264684841197

Epoch: 6| Step: 2
Training loss: 0.8820350170135498
Validation loss: 1.8508585050541868

Epoch: 6| Step: 3
Training loss: 0.8878962993621826
Validation loss: 1.9466476107156405

Epoch: 6| Step: 4
Training loss: 0.6108224987983704
Validation loss: 1.9528252411914129

Epoch: 6| Step: 5
Training loss: 0.8459485173225403
Validation loss: 1.885563927312051

Epoch: 6| Step: 6
Training loss: 1.010390281677246
Validation loss: 1.7565562776339951

Epoch: 6| Step: 7
Training loss: 0.80706387758255
Validation loss: 1.6877080984013055

Epoch: 6| Step: 8
Training loss: 0.8895934224128723
Validation loss: 1.684139156854281

Epoch: 6| Step: 9
Training loss: 0.5917232036590576
Validation loss: 1.6959498082437823

Epoch: 6| Step: 10
Training loss: 0.7467317581176758
Validation loss: 1.6998614380436559

Epoch: 6| Step: 11
Training loss: 0.6416524648666382
Validation loss: 1.7066162254220696

Epoch: 6| Step: 12
Training loss: 0.9110205173492432
Validation loss: 1.6962892291366414

Epoch: 6| Step: 13
Training loss: 0.7372863292694092
Validation loss: 1.6792154209588164

Epoch: 290| Step: 0
Training loss: 0.9119015336036682
Validation loss: 1.7136039836432344

Epoch: 6| Step: 1
Training loss: 0.5481510162353516
Validation loss: 1.7819904960611814

Epoch: 6| Step: 2
Training loss: 0.6609613299369812
Validation loss: 1.8138238165968208

Epoch: 6| Step: 3
Training loss: 0.7640354633331299
Validation loss: 1.794948588135422

Epoch: 6| Step: 4
Training loss: 0.7683771252632141
Validation loss: 1.8013105033546366

Epoch: 6| Step: 5
Training loss: 0.5998706817626953
Validation loss: 1.7719210411912651

Epoch: 6| Step: 6
Training loss: 0.7144200205802917
Validation loss: 1.7406393956112605

Epoch: 6| Step: 7
Training loss: 1.3022027015686035
Validation loss: 1.6941666628724785

Epoch: 6| Step: 8
Training loss: 0.6658639907836914
Validation loss: 1.6767170224138486

Epoch: 6| Step: 9
Training loss: 0.6193177103996277
Validation loss: 1.675977260835709

Epoch: 6| Step: 10
Training loss: 0.4207841157913208
Validation loss: 1.7039689684426913

Epoch: 6| Step: 11
Training loss: 0.5012831687927246
Validation loss: 1.6851908750431512

Epoch: 6| Step: 12
Training loss: 0.5521563291549683
Validation loss: 1.7240363154360043

Epoch: 6| Step: 13
Training loss: 0.5857014060020447
Validation loss: 1.77002283962824

Epoch: 291| Step: 0
Training loss: 0.6919282674789429
Validation loss: 1.8091028877483901

Epoch: 6| Step: 1
Training loss: 0.7231732606887817
Validation loss: 1.7797234481380833

Epoch: 6| Step: 2
Training loss: 0.5227302312850952
Validation loss: 1.7738138219361663

Epoch: 6| Step: 3
Training loss: 1.2756729125976562
Validation loss: 1.7811690735560592

Epoch: 6| Step: 4
Training loss: 0.38827618956565857
Validation loss: 1.7623745267109205

Epoch: 6| Step: 5
Training loss: 0.6056681275367737
Validation loss: 1.7097736174060452

Epoch: 6| Step: 6
Training loss: 0.5102418065071106
Validation loss: 1.6631673459083802

Epoch: 6| Step: 7
Training loss: 0.9946511387825012
Validation loss: 1.6808602527905536

Epoch: 6| Step: 8
Training loss: 0.44705432653427124
Validation loss: 1.643756744682148

Epoch: 6| Step: 9
Training loss: 0.5246188640594482
Validation loss: 1.6404038270314534

Epoch: 6| Step: 10
Training loss: 0.6975550651550293
Validation loss: 1.619426187648568

Epoch: 6| Step: 11
Training loss: 0.8360416889190674
Validation loss: 1.6362445175006826

Epoch: 6| Step: 12
Training loss: 0.5872448682785034
Validation loss: 1.644667959982349

Epoch: 6| Step: 13
Training loss: 0.9057324528694153
Validation loss: 1.717553920643304

Epoch: 292| Step: 0
Training loss: 0.8877649903297424
Validation loss: 1.6679138483539704

Epoch: 6| Step: 1
Training loss: 0.7443598508834839
Validation loss: 1.6260659220398113

Epoch: 6| Step: 2
Training loss: 0.7198638916015625
Validation loss: 1.6191906441924393

Epoch: 6| Step: 3
Training loss: 0.8376435041427612
Validation loss: 1.6428441014341129

Epoch: 6| Step: 4
Training loss: 0.5043355822563171
Validation loss: 1.6029365254986672

Epoch: 6| Step: 5
Training loss: 0.6681803464889526
Validation loss: 1.6092373401887956

Epoch: 6| Step: 6
Training loss: 0.9393511414527893
Validation loss: 1.617336473157329

Epoch: 6| Step: 7
Training loss: 0.7966001033782959
Validation loss: 1.6610273026650952

Epoch: 6| Step: 8
Training loss: 0.858991801738739
Validation loss: 1.684077723051912

Epoch: 6| Step: 9
Training loss: 0.4731729030609131
Validation loss: 1.7187510267380746

Epoch: 6| Step: 10
Training loss: 0.37187543511390686
Validation loss: 1.7341822834425076

Epoch: 6| Step: 11
Training loss: 0.6071897745132446
Validation loss: 1.733270219577256

Epoch: 6| Step: 12
Training loss: 0.5379204750061035
Validation loss: 1.7186083473185056

Epoch: 6| Step: 13
Training loss: 0.3260299265384674
Validation loss: 1.6408717939930577

Epoch: 293| Step: 0
Training loss: 0.7643200755119324
Validation loss: 1.6688669202148274

Epoch: 6| Step: 1
Training loss: 0.7201722264289856
Validation loss: 1.6730201923719017

Epoch: 6| Step: 2
Training loss: 0.4990151524543762
Validation loss: 1.6669273953283987

Epoch: 6| Step: 3
Training loss: 0.41786929965019226
Validation loss: 1.6492596659609067

Epoch: 6| Step: 4
Training loss: 0.6325049996376038
Validation loss: 1.6586177297817764

Epoch: 6| Step: 5
Training loss: 0.7686361074447632
Validation loss: 1.675885385082614

Epoch: 6| Step: 6
Training loss: 0.2923020124435425
Validation loss: 1.6821044375819545

Epoch: 6| Step: 7
Training loss: 0.6567318439483643
Validation loss: 1.7142983354547972

Epoch: 6| Step: 8
Training loss: 0.4968385696411133
Validation loss: 1.7329905045929777

Epoch: 6| Step: 9
Training loss: 0.8269772529602051
Validation loss: 1.722211895450469

Epoch: 6| Step: 10
Training loss: 0.7063364386558533
Validation loss: 1.651626625368672

Epoch: 6| Step: 11
Training loss: 0.8629621863365173
Validation loss: 1.6644263280335294

Epoch: 6| Step: 12
Training loss: 0.38523557782173157
Validation loss: 1.673882499817879

Epoch: 6| Step: 13
Training loss: 1.0202398300170898
Validation loss: 1.66222075493105

Epoch: 294| Step: 0
Training loss: 0.7918320298194885
Validation loss: 1.6751738696969964

Epoch: 6| Step: 1
Training loss: 0.765637993812561
Validation loss: 1.7003508639591995

Epoch: 6| Step: 2
Training loss: 0.7073682546615601
Validation loss: 1.7332219410968084

Epoch: 6| Step: 3
Training loss: 0.7355943918228149
Validation loss: 1.7664288218303392

Epoch: 6| Step: 4
Training loss: 1.0540410280227661
Validation loss: 1.7748569532107281

Epoch: 6| Step: 5
Training loss: 0.4088883697986603
Validation loss: 1.7294534752445836

Epoch: 6| Step: 6
Training loss: 0.4983225464820862
Validation loss: 1.694537308908278

Epoch: 6| Step: 7
Training loss: 0.5481016635894775
Validation loss: 1.6764185787529073

Epoch: 6| Step: 8
Training loss: 0.4416119158267975
Validation loss: 1.636984504679198

Epoch: 6| Step: 9
Training loss: 0.4603676497936249
Validation loss: 1.6141890607854372

Epoch: 6| Step: 10
Training loss: 0.40107461810112
Validation loss: 1.6033576739731656

Epoch: 6| Step: 11
Training loss: 0.5337748527526855
Validation loss: 1.5976959582298034

Epoch: 6| Step: 12
Training loss: 1.2105481624603271
Validation loss: 1.5899293743154055

Epoch: 6| Step: 13
Training loss: 0.8671903014183044
Validation loss: 1.586453119913737

Epoch: 295| Step: 0
Training loss: 0.6461825966835022
Validation loss: 1.6755026258448118

Epoch: 6| Step: 1
Training loss: 0.5913317203521729
Validation loss: 1.6832797219676356

Epoch: 6| Step: 2
Training loss: 0.5963592529296875
Validation loss: 1.7541621449173137

Epoch: 6| Step: 3
Training loss: 1.0668327808380127
Validation loss: 1.7441488632591822

Epoch: 6| Step: 4
Training loss: 0.8212147951126099
Validation loss: 1.7234159618295648

Epoch: 6| Step: 5
Training loss: 0.6920665502548218
Validation loss: 1.6960516116952384

Epoch: 6| Step: 6
Training loss: 0.7942289113998413
Validation loss: 1.6933787638141262

Epoch: 6| Step: 7
Training loss: 0.42615243792533875
Validation loss: 1.6760199826250795

Epoch: 6| Step: 8
Training loss: 0.5831242203712463
Validation loss: 1.6914578958224225

Epoch: 6| Step: 9
Training loss: 0.598625898361206
Validation loss: 1.7088493019021966

Epoch: 6| Step: 10
Training loss: 0.6276401281356812
Validation loss: 1.6766400965311195

Epoch: 6| Step: 11
Training loss: 0.7696534395217896
Validation loss: 1.674413965594384

Epoch: 6| Step: 12
Training loss: 0.43728792667388916
Validation loss: 1.6941862631869573

Epoch: 6| Step: 13
Training loss: 0.5167064070701599
Validation loss: 1.7065299877556421

Epoch: 296| Step: 0
Training loss: 0.59438157081604
Validation loss: 1.666014204743088

Epoch: 6| Step: 1
Training loss: 0.6716482639312744
Validation loss: 1.6725152820669196

Epoch: 6| Step: 2
Training loss: 0.6637570858001709
Validation loss: 1.676304413426307

Epoch: 6| Step: 3
Training loss: 0.8484125137329102
Validation loss: 1.7152659194443816

Epoch: 6| Step: 4
Training loss: 0.722815752029419
Validation loss: 1.751862310594128

Epoch: 6| Step: 5
Training loss: 0.45762282609939575
Validation loss: 1.8396717335588189

Epoch: 6| Step: 6
Training loss: 0.757605254650116
Validation loss: 1.8835606152011501

Epoch: 6| Step: 7
Training loss: 0.6571659445762634
Validation loss: 1.9327025823695685

Epoch: 6| Step: 8
Training loss: 0.7137983441352844
Validation loss: 1.9173822044044413

Epoch: 6| Step: 9
Training loss: 1.1811310052871704
Validation loss: 1.7416113909854685

Epoch: 6| Step: 10
Training loss: 0.5091269016265869
Validation loss: 1.6612758085291872

Epoch: 6| Step: 11
Training loss: 0.4051786959171295
Validation loss: 1.6350412291865195

Epoch: 6| Step: 12
Training loss: 0.8960351347923279
Validation loss: 1.644308828538464

Epoch: 6| Step: 13
Training loss: 1.3214372396469116
Validation loss: 1.6290816440377185

Epoch: 297| Step: 0
Training loss: 0.7083268165588379
Validation loss: 1.671009563630627

Epoch: 6| Step: 1
Training loss: 0.16139492392539978
Validation loss: 1.6819090766291465

Epoch: 6| Step: 2
Training loss: 0.6192047595977783
Validation loss: 1.721921169629661

Epoch: 6| Step: 3
Training loss: 1.3450524806976318
Validation loss: 1.7621774852916758

Epoch: 6| Step: 4
Training loss: 0.3729945719242096
Validation loss: 1.763130836589362

Epoch: 6| Step: 5
Training loss: 0.3764086365699768
Validation loss: 1.787428961005262

Epoch: 6| Step: 6
Training loss: 0.7208994030952454
Validation loss: 1.8004961417567344

Epoch: 6| Step: 7
Training loss: 0.5298621654510498
Validation loss: 1.775285425365612

Epoch: 6| Step: 8
Training loss: 0.451079785823822
Validation loss: 1.7137940276053645

Epoch: 6| Step: 9
Training loss: 0.8639498949050903
Validation loss: 1.6656878930266186

Epoch: 6| Step: 10
Training loss: 0.32233312726020813
Validation loss: 1.6429194519596715

Epoch: 6| Step: 11
Training loss: 0.9262315034866333
Validation loss: 1.648710226499906

Epoch: 6| Step: 12
Training loss: 0.7550899982452393
Validation loss: 1.6324876803223805

Epoch: 6| Step: 13
Training loss: 0.7271196246147156
Validation loss: 1.5925853047319638

Epoch: 298| Step: 0
Training loss: 0.7181960344314575
Validation loss: 1.6376192518459853

Epoch: 6| Step: 1
Training loss: 0.2863922119140625
Validation loss: 1.6474806672783309

Epoch: 6| Step: 2
Training loss: 0.402548611164093
Validation loss: 1.6723409416855022

Epoch: 6| Step: 3
Training loss: 0.9577658176422119
Validation loss: 1.7034058596498223

Epoch: 6| Step: 4
Training loss: 0.5168627500534058
Validation loss: 1.7391712563012236

Epoch: 6| Step: 5
Training loss: 0.4741223156452179
Validation loss: 1.735548436000783

Epoch: 6| Step: 6
Training loss: 0.5133951902389526
Validation loss: 1.7203375857363465

Epoch: 6| Step: 7
Training loss: 0.3363025188446045
Validation loss: 1.7163107420808525

Epoch: 6| Step: 8
Training loss: 0.950343668460846
Validation loss: 1.6986932395606913

Epoch: 6| Step: 9
Training loss: 0.7470933198928833
Validation loss: 1.652854154186864

Epoch: 6| Step: 10
Training loss: 0.8540847301483154
Validation loss: 1.603772791483069

Epoch: 6| Step: 11
Training loss: 0.7085314393043518
Validation loss: 1.629335384215078

Epoch: 6| Step: 12
Training loss: 0.5860176086425781
Validation loss: 1.6141970888260873

Epoch: 6| Step: 13
Training loss: 0.6150195598602295
Validation loss: 1.6381936393758303

Epoch: 299| Step: 0
Training loss: 0.9207504987716675
Validation loss: 1.6394902275454613

Epoch: 6| Step: 1
Training loss: 0.46103429794311523
Validation loss: 1.6349261986312045

Epoch: 6| Step: 2
Training loss: 0.23166000843048096
Validation loss: 1.6610620688366633

Epoch: 6| Step: 3
Training loss: 0.9976542592048645
Validation loss: 1.6933489666190198

Epoch: 6| Step: 4
Training loss: 0.6078099608421326
Validation loss: 1.7440788104969969

Epoch: 6| Step: 5
Training loss: 0.5813776850700378
Validation loss: 1.8157555800612255

Epoch: 6| Step: 6
Training loss: 0.432346373796463
Validation loss: 1.8013959302697131

Epoch: 6| Step: 7
Training loss: 0.8348500728607178
Validation loss: 1.7460835774739583

Epoch: 6| Step: 8
Training loss: 0.5235921740531921
Validation loss: 1.717179242000785

Epoch: 6| Step: 9
Training loss: 0.5037332773208618
Validation loss: 1.657734776055941

Epoch: 6| Step: 10
Training loss: 0.9305858016014099
Validation loss: 1.6358132157274472

Epoch: 6| Step: 11
Training loss: 0.8920679688453674
Validation loss: 1.6715887208138742

Epoch: 6| Step: 12
Training loss: 0.5264921188354492
Validation loss: 1.6525016535994828

Epoch: 6| Step: 13
Training loss: 0.3803524971008301
Validation loss: 1.62803400716474

Epoch: 300| Step: 0
Training loss: 0.5792507529258728
Validation loss: 1.6227643489837646

Epoch: 6| Step: 1
Training loss: 0.3914368152618408
Validation loss: 1.6636082651794597

Epoch: 6| Step: 2
Training loss: 0.8116066455841064
Validation loss: 1.7459437949683076

Epoch: 6| Step: 3
Training loss: 1.2932658195495605
Validation loss: 1.8073193757764754

Epoch: 6| Step: 4
Training loss: 0.9463270306587219
Validation loss: 1.8560416044727448

Epoch: 6| Step: 5
Training loss: 0.3318761885166168
Validation loss: 1.8222840268124816

Epoch: 6| Step: 6
Training loss: 0.6720033288002014
Validation loss: 1.7747398089337092

Epoch: 6| Step: 7
Training loss: 0.35785675048828125
Validation loss: 1.699628658192132

Epoch: 6| Step: 8
Training loss: 0.5307120084762573
Validation loss: 1.6503235332427486

Epoch: 6| Step: 9
Training loss: 0.3639507293701172
Validation loss: 1.60375298864098

Epoch: 6| Step: 10
Training loss: 0.8954935669898987
Validation loss: 1.5926046679096837

Epoch: 6| Step: 11
Training loss: 0.39501869678497314
Validation loss: 1.598398090690695

Epoch: 6| Step: 12
Training loss: 0.750322699546814
Validation loss: 1.5946345611285138

Epoch: 6| Step: 13
Training loss: 0.2083452343940735
Validation loss: 1.618431342545376

Epoch: 301| Step: 0
Training loss: 0.6743478178977966
Validation loss: 1.6296811616548927

Epoch: 6| Step: 1
Training loss: 0.4256875514984131
Validation loss: 1.6449592933859876

Epoch: 6| Step: 2
Training loss: 0.5138593912124634
Validation loss: 1.6807762576687721

Epoch: 6| Step: 3
Training loss: 0.716218113899231
Validation loss: 1.6765129630283644

Epoch: 6| Step: 4
Training loss: 0.6620222330093384
Validation loss: 1.683472333415862

Epoch: 6| Step: 5
Training loss: 0.15162301063537598
Validation loss: 1.662251236618206

Epoch: 6| Step: 6
Training loss: 0.8112623691558838
Validation loss: 1.6481488814917944

Epoch: 6| Step: 7
Training loss: 0.4646722078323364
Validation loss: 1.6221049190849386

Epoch: 6| Step: 8
Training loss: 0.3065027594566345
Validation loss: 1.631458729825994

Epoch: 6| Step: 9
Training loss: 0.5911744832992554
Validation loss: 1.6254105914023615

Epoch: 6| Step: 10
Training loss: 1.257917046546936
Validation loss: 1.6114209467364895

Epoch: 6| Step: 11
Training loss: 0.6107610464096069
Validation loss: 1.6253544322906002

Epoch: 6| Step: 12
Training loss: 0.6282205581665039
Validation loss: 1.6185575890284714

Epoch: 6| Step: 13
Training loss: 0.8120247721672058
Validation loss: 1.6218261282931092

Epoch: 302| Step: 0
Training loss: 0.6728411316871643
Validation loss: 1.637794763811173

Epoch: 6| Step: 1
Training loss: 0.5845698118209839
Validation loss: 1.6673682594812045

Epoch: 6| Step: 2
Training loss: 0.29225847125053406
Validation loss: 1.6742865923912293

Epoch: 6| Step: 3
Training loss: 0.25383347272872925
Validation loss: 1.675877086577877

Epoch: 6| Step: 4
Training loss: 0.798742413520813
Validation loss: 1.690093635230936

Epoch: 6| Step: 5
Training loss: 0.40219974517822266
Validation loss: 1.642550181317073

Epoch: 6| Step: 6
Training loss: 0.9624911546707153
Validation loss: 1.6593427529899023

Epoch: 6| Step: 7
Training loss: 0.8828105926513672
Validation loss: 1.6794425672100437

Epoch: 6| Step: 8
Training loss: 0.7268236875534058
Validation loss: 1.6588572314990464

Epoch: 6| Step: 9
Training loss: 0.67305988073349
Validation loss: 1.6840842846901185

Epoch: 6| Step: 10
Training loss: 0.5894575119018555
Validation loss: 1.6963587037978634

Epoch: 6| Step: 11
Training loss: 0.7238332033157349
Validation loss: 1.6885958281896447

Epoch: 6| Step: 12
Training loss: 0.2886461913585663
Validation loss: 1.698287029420176

Epoch: 6| Step: 13
Training loss: 0.44310688972473145
Validation loss: 1.7265916396212835

Epoch: 303| Step: 0
Training loss: 0.419910728931427
Validation loss: 1.756589807489867

Epoch: 6| Step: 1
Training loss: 0.6978592872619629
Validation loss: 1.836020669629497

Epoch: 6| Step: 2
Training loss: 0.7840315699577332
Validation loss: 1.8149111168358916

Epoch: 6| Step: 3
Training loss: 0.9722203016281128
Validation loss: 1.722572124132546

Epoch: 6| Step: 4
Training loss: 0.72887122631073
Validation loss: 1.6779022383433517

Epoch: 6| Step: 5
Training loss: 0.6198681592941284
Validation loss: 1.6381384211201822

Epoch: 6| Step: 6
Training loss: 0.5725264549255371
Validation loss: 1.6215954108904767

Epoch: 6| Step: 7
Training loss: 0.6091738343238831
Validation loss: 1.6137852745671426

Epoch: 6| Step: 8
Training loss: 0.5283166170120239
Validation loss: 1.6070364098395071

Epoch: 6| Step: 9
Training loss: 0.225679412484169
Validation loss: 1.612337600800299

Epoch: 6| Step: 10
Training loss: 0.5218156576156616
Validation loss: 1.6409304026634461

Epoch: 6| Step: 11
Training loss: 0.8978843092918396
Validation loss: 1.6721367925725958

Epoch: 6| Step: 12
Training loss: 0.5767963528633118
Validation loss: 1.7397539718176729

Epoch: 6| Step: 13
Training loss: 0.7645809650421143
Validation loss: 1.7322560215509066

Epoch: 304| Step: 0
Training loss: 0.7033151388168335
Validation loss: 1.694997492656913

Epoch: 6| Step: 1
Training loss: 0.6594641208648682
Validation loss: 1.604875700448149

Epoch: 6| Step: 2
Training loss: 0.5733516216278076
Validation loss: 1.5949299784116848

Epoch: 6| Step: 3
Training loss: 0.7034845352172852
Validation loss: 1.6017570072604763

Epoch: 6| Step: 4
Training loss: 0.5183157920837402
Validation loss: 1.620583499631574

Epoch: 6| Step: 5
Training loss: 0.9085391163825989
Validation loss: 1.6339221481354005

Epoch: 6| Step: 6
Training loss: 0.6447858810424805
Validation loss: 1.625666618347168

Epoch: 6| Step: 7
Training loss: 0.3989235758781433
Validation loss: 1.6493304416697512

Epoch: 6| Step: 8
Training loss: 0.6222784519195557
Validation loss: 1.6471073473653486

Epoch: 6| Step: 9
Training loss: 0.6957064867019653
Validation loss: 1.691706529227636

Epoch: 6| Step: 10
Training loss: 0.7347376346588135
Validation loss: 1.7272251562405658

Epoch: 6| Step: 11
Training loss: 0.3708363175392151
Validation loss: 1.7490797786302463

Epoch: 6| Step: 12
Training loss: 0.4868820905685425
Validation loss: 1.7783001238299954

Epoch: 6| Step: 13
Training loss: 0.4540519714355469
Validation loss: 1.7140768112674836

Epoch: 305| Step: 0
Training loss: 0.5122830867767334
Validation loss: 1.6681210456355926

Epoch: 6| Step: 1
Training loss: 0.5817786455154419
Validation loss: 1.663021849047753

Epoch: 6| Step: 2
Training loss: 0.6240692138671875
Validation loss: 1.6782400479880712

Epoch: 6| Step: 3
Training loss: 0.44344672560691833
Validation loss: 1.6713342730716994

Epoch: 6| Step: 4
Training loss: 0.6578552722930908
Validation loss: 1.6658377647399902

Epoch: 6| Step: 5
Training loss: 0.40868890285491943
Validation loss: 1.6785301546896658

Epoch: 6| Step: 6
Training loss: 0.4577159881591797
Validation loss: 1.6791592797925394

Epoch: 6| Step: 7
Training loss: 0.9962365627288818
Validation loss: 1.6750337616089852

Epoch: 6| Step: 8
Training loss: 0.6965674161911011
Validation loss: 1.6593177908210344

Epoch: 6| Step: 9
Training loss: 0.6173261404037476
Validation loss: 1.6439553742767663

Epoch: 6| Step: 10
Training loss: 0.5795549750328064
Validation loss: 1.7097228022031887

Epoch: 6| Step: 11
Training loss: 0.5369250774383545
Validation loss: 1.7055853515542962

Epoch: 6| Step: 12
Training loss: 0.4617149829864502
Validation loss: 1.6734981947047736

Epoch: 6| Step: 13
Training loss: 0.646577775478363
Validation loss: 1.689892340731877

Epoch: 306| Step: 0
Training loss: 0.7423933148384094
Validation loss: 1.683660622565977

Epoch: 6| Step: 1
Training loss: 0.48007747530937195
Validation loss: 1.7060095597338933

Epoch: 6| Step: 2
Training loss: 0.46395838260650635
Validation loss: 1.7023100711966073

Epoch: 6| Step: 3
Training loss: 1.2078204154968262
Validation loss: 1.6932435638161116

Epoch: 6| Step: 4
Training loss: 0.39555153250694275
Validation loss: 1.6623813042076685

Epoch: 6| Step: 5
Training loss: 0.6135740280151367
Validation loss: 1.6388188844086022

Epoch: 6| Step: 6
Training loss: 0.4870935082435608
Validation loss: 1.6198039900872014

Epoch: 6| Step: 7
Training loss: 0.4636634886264801
Validation loss: 1.6145043783290411

Epoch: 6| Step: 8
Training loss: 1.0246376991271973
Validation loss: 1.6138661035927393

Epoch: 6| Step: 9
Training loss: 0.6590810418128967
Validation loss: 1.655209674630114

Epoch: 6| Step: 10
Training loss: 0.479072630405426
Validation loss: 1.6948217909823182

Epoch: 6| Step: 11
Training loss: 0.27896231412887573
Validation loss: 1.736171873666907

Epoch: 6| Step: 12
Training loss: 0.5715705156326294
Validation loss: 1.7397352815956197

Epoch: 6| Step: 13
Training loss: 0.6740473508834839
Validation loss: 1.7511032819747925

Epoch: 307| Step: 0
Training loss: 0.7797639966011047
Validation loss: 1.6754092106255152

Epoch: 6| Step: 1
Training loss: 0.448946475982666
Validation loss: 1.6103509549171693

Epoch: 6| Step: 2
Training loss: 1.3702917098999023
Validation loss: 1.6194828223156672

Epoch: 6| Step: 3
Training loss: 0.24327997863292694
Validation loss: 1.601795687470385

Epoch: 6| Step: 4
Training loss: 0.5224676132202148
Validation loss: 1.581798880330978

Epoch: 6| Step: 5
Training loss: 0.8542953133583069
Validation loss: 1.6088792252284225

Epoch: 6| Step: 6
Training loss: 0.8700670003890991
Validation loss: 1.6044677393410796

Epoch: 6| Step: 7
Training loss: 0.5128351449966431
Validation loss: 1.597442711553266

Epoch: 6| Step: 8
Training loss: 0.5155491828918457
Validation loss: 1.6109579340104134

Epoch: 6| Step: 9
Training loss: 0.47730764746665955
Validation loss: 1.615135556908064

Epoch: 6| Step: 10
Training loss: 0.6047789454460144
Validation loss: 1.6302636118345364

Epoch: 6| Step: 11
Training loss: 0.30339515209198
Validation loss: 1.6919581338923464

Epoch: 6| Step: 12
Training loss: 0.26601362228393555
Validation loss: 1.7219915082377772

Epoch: 6| Step: 13
Training loss: 0.4599287211894989
Validation loss: 1.8076166004262946

Epoch: 308| Step: 0
Training loss: 0.44211331009864807
Validation loss: 1.7811221256051013

Epoch: 6| Step: 1
Training loss: 0.5817995667457581
Validation loss: 1.7400677665587394

Epoch: 6| Step: 2
Training loss: 0.4369536340236664
Validation loss: 1.712835551590048

Epoch: 6| Step: 3
Training loss: 0.6774621605873108
Validation loss: 1.6664283762695968

Epoch: 6| Step: 4
Training loss: 0.45914676785469055
Validation loss: 1.65307762417742

Epoch: 6| Step: 5
Training loss: 0.568264365196228
Validation loss: 1.647368270863769

Epoch: 6| Step: 6
Training loss: 0.913117527961731
Validation loss: 1.641051902565905

Epoch: 6| Step: 7
Training loss: 0.7680274248123169
Validation loss: 1.6390144568617626

Epoch: 6| Step: 8
Training loss: 0.566413164138794
Validation loss: 1.643831761934424

Epoch: 6| Step: 9
Training loss: 0.4956185519695282
Validation loss: 1.6774700341686126

Epoch: 6| Step: 10
Training loss: 0.9292301535606384
Validation loss: 1.6983859795396046

Epoch: 6| Step: 11
Training loss: 0.43962812423706055
Validation loss: 1.733911560427758

Epoch: 6| Step: 12
Training loss: 0.3993067145347595
Validation loss: 1.7188807866906608

Epoch: 6| Step: 13
Training loss: 0.5613581538200378
Validation loss: 1.6857241815136326

Epoch: 309| Step: 0
Training loss: 0.8624056577682495
Validation loss: 1.6931518636724001

Epoch: 6| Step: 1
Training loss: 0.7619657516479492
Validation loss: 1.6545828106582805

Epoch: 6| Step: 2
Training loss: 0.642378032207489
Validation loss: 1.617848386046707

Epoch: 6| Step: 3
Training loss: 0.357035756111145
Validation loss: 1.640825807407338

Epoch: 6| Step: 4
Training loss: 1.100430965423584
Validation loss: 1.6546795586104035

Epoch: 6| Step: 5
Training loss: 0.4702470302581787
Validation loss: 1.62132994333903

Epoch: 6| Step: 6
Training loss: 0.5627433061599731
Validation loss: 1.6321784860344344

Epoch: 6| Step: 7
Training loss: 0.756193220615387
Validation loss: 1.6822353101545764

Epoch: 6| Step: 8
Training loss: 0.2521441578865051
Validation loss: 1.6755055971043085

Epoch: 6| Step: 9
Training loss: 0.6142186522483826
Validation loss: 1.661484210721908

Epoch: 6| Step: 10
Training loss: 0.3226947784423828
Validation loss: 1.7263260477332658

Epoch: 6| Step: 11
Training loss: 0.43730291724205017
Validation loss: 1.791942786144954

Epoch: 6| Step: 12
Training loss: 0.2961558699607849
Validation loss: 1.763550719907207

Epoch: 6| Step: 13
Training loss: 0.37979575991630554
Validation loss: 1.7762510917520011

Epoch: 310| Step: 0
Training loss: 0.4928649067878723
Validation loss: 1.7205432409881263

Epoch: 6| Step: 1
Training loss: 0.4366888999938965
Validation loss: 1.6435199322239045

Epoch: 6| Step: 2
Training loss: 1.063726544380188
Validation loss: 1.6673650280121834

Epoch: 6| Step: 3
Training loss: 0.6044847965240479
Validation loss: 1.6668119968906525

Epoch: 6| Step: 4
Training loss: 0.6368398666381836
Validation loss: 1.6521219694486229

Epoch: 6| Step: 5
Training loss: 0.6538764834403992
Validation loss: 1.6593195238421041

Epoch: 6| Step: 6
Training loss: 0.9406434297561646
Validation loss: 1.6667742242095291

Epoch: 6| Step: 7
Training loss: 0.6208730936050415
Validation loss: 1.6411391253112464

Epoch: 6| Step: 8
Training loss: 0.23490376770496368
Validation loss: 1.636067633987755

Epoch: 6| Step: 9
Training loss: 0.4703066647052765
Validation loss: 1.6132081708600443

Epoch: 6| Step: 10
Training loss: 0.7861018180847168
Validation loss: 1.6124075164077103

Epoch: 6| Step: 11
Training loss: 0.49193835258483887
Validation loss: 1.646308995062305

Epoch: 6| Step: 12
Training loss: 0.3695026636123657
Validation loss: 1.6933826297842047

Epoch: 6| Step: 13
Training loss: 0.2974091172218323
Validation loss: 1.732336824940097

Epoch: 311| Step: 0
Training loss: 0.28522932529449463
Validation loss: 1.7375264103694628

Epoch: 6| Step: 1
Training loss: 0.5306873321533203
Validation loss: 1.7294420465346305

Epoch: 6| Step: 2
Training loss: 0.45338931679725647
Validation loss: 1.693364361281036

Epoch: 6| Step: 3
Training loss: 0.46654701232910156
Validation loss: 1.6408638351707048

Epoch: 6| Step: 4
Training loss: 0.7385507225990295
Validation loss: 1.6442680499886955

Epoch: 6| Step: 5
Training loss: 0.7419554591178894
Validation loss: 1.6037463244571482

Epoch: 6| Step: 6
Training loss: 0.8878301382064819
Validation loss: 1.5787795051451652

Epoch: 6| Step: 7
Training loss: 0.9210779666900635
Validation loss: 1.5886941366298224

Epoch: 6| Step: 8
Training loss: 0.29609382152557373
Validation loss: 1.6205530871627152

Epoch: 6| Step: 9
Training loss: 1.0377042293548584
Validation loss: 1.6257307990904777

Epoch: 6| Step: 10
Training loss: 0.44580215215682983
Validation loss: 1.6629491403538694

Epoch: 6| Step: 11
Training loss: 0.5873774290084839
Validation loss: 1.7246446340314803

Epoch: 6| Step: 12
Training loss: 0.604119598865509
Validation loss: 1.807012184973686

Epoch: 6| Step: 13
Training loss: 0.2856464684009552
Validation loss: 1.7540937854397682

Epoch: 312| Step: 0
Training loss: 0.5889698266983032
Validation loss: 1.7011916598966044

Epoch: 6| Step: 1
Training loss: 0.5274587273597717
Validation loss: 1.6497255474008539

Epoch: 6| Step: 2
Training loss: 0.2941993176937103
Validation loss: 1.6095121868195073

Epoch: 6| Step: 3
Training loss: 0.38814693689346313
Validation loss: 1.5904161827538603

Epoch: 6| Step: 4
Training loss: 0.43343210220336914
Validation loss: 1.621190937616492

Epoch: 6| Step: 5
Training loss: 0.5442898273468018
Validation loss: 1.6165927251180012

Epoch: 6| Step: 6
Training loss: 0.7805873155593872
Validation loss: 1.616871347991369

Epoch: 6| Step: 7
Training loss: 0.7658010721206665
Validation loss: 1.624891984847284

Epoch: 6| Step: 8
Training loss: 0.41278523206710815
Validation loss: 1.6186258408331102

Epoch: 6| Step: 9
Training loss: 0.8658134341239929
Validation loss: 1.6590992981387722

Epoch: 6| Step: 10
Training loss: 0.5048614740371704
Validation loss: 1.7588663216560119

Epoch: 6| Step: 11
Training loss: 0.8939083218574524
Validation loss: 1.8411303002347228

Epoch: 6| Step: 12
Training loss: 0.9627714157104492
Validation loss: 1.7752098703897128

Epoch: 6| Step: 13
Training loss: 0.41203993558883667
Validation loss: 1.7773948305396623

Epoch: 313| Step: 0
Training loss: 0.89267897605896
Validation loss: 1.7565275084587835

Epoch: 6| Step: 1
Training loss: 0.7483686804771423
Validation loss: 1.6974982266784997

Epoch: 6| Step: 2
Training loss: 0.6223340630531311
Validation loss: 1.6188160398954987

Epoch: 6| Step: 3
Training loss: 0.597529411315918
Validation loss: 1.626415729522705

Epoch: 6| Step: 4
Training loss: 0.5159107446670532
Validation loss: 1.631829656580443

Epoch: 6| Step: 5
Training loss: 0.6258547306060791
Validation loss: 1.6213816570979294

Epoch: 6| Step: 6
Training loss: 0.36616051197052
Validation loss: 1.5989461355311896

Epoch: 6| Step: 7
Training loss: 0.6872862577438354
Validation loss: 1.6203761510951544

Epoch: 6| Step: 8
Training loss: 0.2793397307395935
Validation loss: 1.6096198315261512

Epoch: 6| Step: 9
Training loss: 0.8031035661697388
Validation loss: 1.6461026027638426

Epoch: 6| Step: 10
Training loss: 0.28662869334220886
Validation loss: 1.6851432784911125

Epoch: 6| Step: 11
Training loss: 0.5108966827392578
Validation loss: 1.7054496503645373

Epoch: 6| Step: 12
Training loss: 0.5536392331123352
Validation loss: 1.7619702469918035

Epoch: 6| Step: 13
Training loss: 1.044276475906372
Validation loss: 1.7522532350273543

Epoch: 314| Step: 0
Training loss: 0.8252298831939697
Validation loss: 1.7460746944591563

Epoch: 6| Step: 1
Training loss: 0.3976404666900635
Validation loss: 1.640055670533129

Epoch: 6| Step: 2
Training loss: 0.3993145823478699
Validation loss: 1.6012632975014307

Epoch: 6| Step: 3
Training loss: 0.7232866883277893
Validation loss: 1.5821903879924486

Epoch: 6| Step: 4
Training loss: 0.6568537354469299
Validation loss: 1.5691768456530828

Epoch: 6| Step: 5
Training loss: 0.5061056613922119
Validation loss: 1.607885795254861

Epoch: 6| Step: 6
Training loss: 0.670347273349762
Validation loss: 1.5978691103637859

Epoch: 6| Step: 7
Training loss: 0.401299387216568
Validation loss: 1.6165643289525022

Epoch: 6| Step: 8
Training loss: 0.6102871894836426
Validation loss: 1.5883404836859754

Epoch: 6| Step: 9
Training loss: 0.5647799372673035
Validation loss: 1.5622753327892673

Epoch: 6| Step: 10
Training loss: 0.6378012299537659
Validation loss: 1.6010234202108076

Epoch: 6| Step: 11
Training loss: 0.5858914852142334
Validation loss: 1.6362395363469278

Epoch: 6| Step: 12
Training loss: 0.6001600027084351
Validation loss: 1.6900215072016562

Epoch: 6| Step: 13
Training loss: 0.41775572299957275
Validation loss: 1.7205732983927573

Epoch: 315| Step: 0
Training loss: 0.3651980757713318
Validation loss: 1.722238125339631

Epoch: 6| Step: 1
Training loss: 0.691017746925354
Validation loss: 1.7118565215859363

Epoch: 6| Step: 2
Training loss: 0.5056945085525513
Validation loss: 1.6861616103879866

Epoch: 6| Step: 3
Training loss: 0.5050050616264343
Validation loss: 1.6705497452007827

Epoch: 6| Step: 4
Training loss: 0.5381130576133728
Validation loss: 1.6405988380473147

Epoch: 6| Step: 5
Training loss: 0.9778391122817993
Validation loss: 1.6282916056212557

Epoch: 6| Step: 6
Training loss: 0.3448837399482727
Validation loss: 1.6228202632678452

Epoch: 6| Step: 7
Training loss: 0.938742995262146
Validation loss: 1.6203893512807868

Epoch: 6| Step: 8
Training loss: 0.33378469944000244
Validation loss: 1.6099599176837551

Epoch: 6| Step: 9
Training loss: 0.7761690020561218
Validation loss: 1.6309291713981218

Epoch: 6| Step: 10
Training loss: 0.5724077224731445
Validation loss: 1.628454380137946

Epoch: 6| Step: 11
Training loss: 0.24605770409107208
Validation loss: 1.6777324522695234

Epoch: 6| Step: 12
Training loss: 0.5421267747879028
Validation loss: 1.739463189596771

Epoch: 6| Step: 13
Training loss: 0.5476136207580566
Validation loss: 1.697825757406091

Epoch: 316| Step: 0
Training loss: 0.5246453285217285
Validation loss: 1.6666028038147958

Epoch: 6| Step: 1
Training loss: 0.2801727056503296
Validation loss: 1.6500072427975234

Epoch: 6| Step: 2
Training loss: 0.23512881994247437
Validation loss: 1.5684459683715657

Epoch: 6| Step: 3
Training loss: 0.7709088325500488
Validation loss: 1.5785163820430796

Epoch: 6| Step: 4
Training loss: 0.48643049597740173
Validation loss: 1.5709064109351045

Epoch: 6| Step: 5
Training loss: 0.7448821067810059
Validation loss: 1.6074758896263697

Epoch: 6| Step: 6
Training loss: 0.6699543595314026
Validation loss: 1.5814308709995721

Epoch: 6| Step: 7
Training loss: 0.6278631091117859
Validation loss: 1.5694637234492967

Epoch: 6| Step: 8
Training loss: 0.44683074951171875
Validation loss: 1.5603760186062063

Epoch: 6| Step: 9
Training loss: 0.3344026207923889
Validation loss: 1.5673016335374566

Epoch: 6| Step: 10
Training loss: 0.6743776798248291
Validation loss: 1.6062917952896447

Epoch: 6| Step: 11
Training loss: 0.6294785141944885
Validation loss: 1.6191894764541297

Epoch: 6| Step: 12
Training loss: 0.514860212802887
Validation loss: 1.6220143674522318

Epoch: 6| Step: 13
Training loss: 0.27965113520622253
Validation loss: 1.655169375481144

Epoch: 317| Step: 0
Training loss: 0.4887186586856842
Validation loss: 1.6741122763643983

Epoch: 6| Step: 1
Training loss: 0.4212043583393097
Validation loss: 1.7076131066968363

Epoch: 6| Step: 2
Training loss: 0.22357776761054993
Validation loss: 1.715641797229808

Epoch: 6| Step: 3
Training loss: 0.4156005382537842
Validation loss: 1.6712269372837518

Epoch: 6| Step: 4
Training loss: 0.41203802824020386
Validation loss: 1.6706440455170088

Epoch: 6| Step: 5
Training loss: 0.8916302919387817
Validation loss: 1.6395577910125896

Epoch: 6| Step: 6
Training loss: 0.49378830194473267
Validation loss: 1.6502854798429756

Epoch: 6| Step: 7
Training loss: 0.3807680904865265
Validation loss: 1.6243248562658987

Epoch: 6| Step: 8
Training loss: 0.6066766977310181
Validation loss: 1.5939870444677209

Epoch: 6| Step: 9
Training loss: 0.4364626109600067
Validation loss: 1.611169509990241

Epoch: 6| Step: 10
Training loss: 0.6939551830291748
Validation loss: 1.5978235839515604

Epoch: 6| Step: 11
Training loss: 0.46013227105140686
Validation loss: 1.5944784828411636

Epoch: 6| Step: 12
Training loss: 1.0316518545150757
Validation loss: 1.620002277435795

Epoch: 6| Step: 13
Training loss: 0.7190167307853699
Validation loss: 1.6649935694151028

Epoch: 318| Step: 0
Training loss: 0.7263382077217102
Validation loss: 1.6381987974207888

Epoch: 6| Step: 1
Training loss: 0.444446325302124
Validation loss: 1.643892695826869

Epoch: 6| Step: 2
Training loss: 0.5723513960838318
Validation loss: 1.6368220775358138

Epoch: 6| Step: 3
Training loss: 0.2939307689666748
Validation loss: 1.6557341801222933

Epoch: 6| Step: 4
Training loss: 0.3538486361503601
Validation loss: 1.660329641834382

Epoch: 6| Step: 5
Training loss: 0.6556061506271362
Validation loss: 1.668793434737831

Epoch: 6| Step: 6
Training loss: 0.3260364532470703
Validation loss: 1.6981918952798332

Epoch: 6| Step: 7
Training loss: 0.3715561628341675
Validation loss: 1.6973814682293964

Epoch: 6| Step: 8
Training loss: 0.6165701746940613
Validation loss: 1.69730725596028

Epoch: 6| Step: 9
Training loss: 0.9160847663879395
Validation loss: 1.690198044623098

Epoch: 6| Step: 10
Training loss: 0.27234846353530884
Validation loss: 1.6824688847346971

Epoch: 6| Step: 11
Training loss: 0.40046393871307373
Validation loss: 1.6882060138128137

Epoch: 6| Step: 12
Training loss: 0.5116764903068542
Validation loss: 1.6864891026609687

Epoch: 6| Step: 13
Training loss: 1.361518383026123
Validation loss: 1.703817016334944

Epoch: 319| Step: 0
Training loss: 0.366252064704895
Validation loss: 1.690275348642821

Epoch: 6| Step: 1
Training loss: 0.35863709449768066
Validation loss: 1.672844297142439

Epoch: 6| Step: 2
Training loss: 0.5478677153587341
Validation loss: 1.6903473741264754

Epoch: 6| Step: 3
Training loss: 0.4798957109451294
Validation loss: 1.6958777212327527

Epoch: 6| Step: 4
Training loss: 0.7313191890716553
Validation loss: 1.7021799971980434

Epoch: 6| Step: 5
Training loss: 0.8385087251663208
Validation loss: 1.6863280906472156

Epoch: 6| Step: 6
Training loss: 0.5207775235176086
Validation loss: 1.6547587212695871

Epoch: 6| Step: 7
Training loss: 0.5486758947372437
Validation loss: 1.6090199383356238

Epoch: 6| Step: 8
Training loss: 0.3724574148654938
Validation loss: 1.6104690861958328

Epoch: 6| Step: 9
Training loss: 0.5507321357727051
Validation loss: 1.608820911376707

Epoch: 6| Step: 10
Training loss: 0.6186431646347046
Validation loss: 1.6223475471619637

Epoch: 6| Step: 11
Training loss: 0.24914786219596863
Validation loss: 1.5950255714437014

Epoch: 6| Step: 12
Training loss: 0.6526715755462646
Validation loss: 1.626295744731862

Epoch: 6| Step: 13
Training loss: 0.5316038727760315
Validation loss: 1.6152599037334483

Epoch: 320| Step: 0
Training loss: 0.4310285449028015
Validation loss: 1.629232633498407

Epoch: 6| Step: 1
Training loss: 0.4587520956993103
Validation loss: 1.6617986386822117

Epoch: 6| Step: 2
Training loss: 0.7809686064720154
Validation loss: 1.6666227566298617

Epoch: 6| Step: 3
Training loss: 0.5568581819534302
Validation loss: 1.678731172315536

Epoch: 6| Step: 4
Training loss: 0.3564106523990631
Validation loss: 1.710463995574623

Epoch: 6| Step: 5
Training loss: 0.4680868089199066
Validation loss: 1.7101347138804774

Epoch: 6| Step: 6
Training loss: 0.5029187202453613
Validation loss: 1.7411449340081984

Epoch: 6| Step: 7
Training loss: 0.5681188702583313
Validation loss: 1.7308416661395822

Epoch: 6| Step: 8
Training loss: 0.394411563873291
Validation loss: 1.717258845606158

Epoch: 6| Step: 9
Training loss: 0.3682294189929962
Validation loss: 1.688968825083907

Epoch: 6| Step: 10
Training loss: 0.5965235829353333
Validation loss: 1.6771224570530716

Epoch: 6| Step: 11
Training loss: 0.853818953037262
Validation loss: 1.6756986469350836

Epoch: 6| Step: 12
Training loss: 0.20863881707191467
Validation loss: 1.6438832500929474

Epoch: 6| Step: 13
Training loss: 0.5057819485664368
Validation loss: 1.6663062316115185

Epoch: 321| Step: 0
Training loss: 0.4105290174484253
Validation loss: 1.6464493172143095

Epoch: 6| Step: 1
Training loss: 0.45768624544143677
Validation loss: 1.6166083389712917

Epoch: 6| Step: 2
Training loss: 0.5036736726760864
Validation loss: 1.5738405758334744

Epoch: 6| Step: 3
Training loss: 0.2757275104522705
Validation loss: 1.5894331816704041

Epoch: 6| Step: 4
Training loss: 0.9839621782302856
Validation loss: 1.5902256081181187

Epoch: 6| Step: 5
Training loss: 0.4587109684944153
Validation loss: 1.5725904075048303

Epoch: 6| Step: 6
Training loss: 0.8758901357650757
Validation loss: 1.5670423046235116

Epoch: 6| Step: 7
Training loss: 0.6583123207092285
Validation loss: 1.596746552375055

Epoch: 6| Step: 8
Training loss: 0.289889931678772
Validation loss: 1.632125921146844

Epoch: 6| Step: 9
Training loss: 0.3804439306259155
Validation loss: 1.6833379986465618

Epoch: 6| Step: 10
Training loss: 0.4513501524925232
Validation loss: 1.7282038222077072

Epoch: 6| Step: 11
Training loss: 0.7700506448745728
Validation loss: 1.7285241952506445

Epoch: 6| Step: 12
Training loss: 0.47679728269577026
Validation loss: 1.692307460692621

Epoch: 6| Step: 13
Training loss: 0.3594927191734314
Validation loss: 1.7044722085357995

Epoch: 322| Step: 0
Training loss: 0.5295416116714478
Validation loss: 1.6662726402282715

Epoch: 6| Step: 1
Training loss: 0.32400691509246826
Validation loss: 1.6744176418550554

Epoch: 6| Step: 2
Training loss: 0.7479060888290405
Validation loss: 1.669766786277935

Epoch: 6| Step: 3
Training loss: 0.41114628314971924
Validation loss: 1.6846518554995138

Epoch: 6| Step: 4
Training loss: 0.3737529516220093
Validation loss: 1.6804701141131821

Epoch: 6| Step: 5
Training loss: 0.4977754056453705
Validation loss: 1.6961799103726622

Epoch: 6| Step: 6
Training loss: 0.8694866895675659
Validation loss: 1.691925146246469

Epoch: 6| Step: 7
Training loss: 0.4753384590148926
Validation loss: 1.7257747047690934

Epoch: 6| Step: 8
Training loss: 0.7750086784362793
Validation loss: 1.778588310364754

Epoch: 6| Step: 9
Training loss: 0.6823734045028687
Validation loss: 1.8125342117842806

Epoch: 6| Step: 10
Training loss: 0.3155757784843445
Validation loss: 1.761491854985555

Epoch: 6| Step: 11
Training loss: 0.7307628989219666
Validation loss: 1.745641416118991

Epoch: 6| Step: 12
Training loss: 0.11784505099058151
Validation loss: 1.6568888336099603

Epoch: 6| Step: 13
Training loss: 0.5988473892211914
Validation loss: 1.6188338982161654

Epoch: 323| Step: 0
Training loss: 0.40824371576309204
Validation loss: 1.6207529908867293

Epoch: 6| Step: 1
Training loss: 0.4859503507614136
Validation loss: 1.6005586770273024

Epoch: 6| Step: 2
Training loss: 0.5681849122047424
Validation loss: 1.6341466185867146

Epoch: 6| Step: 3
Training loss: 0.39943230152130127
Validation loss: 1.604521603994472

Epoch: 6| Step: 4
Training loss: 0.36209771037101746
Validation loss: 1.6373792976461432

Epoch: 6| Step: 5
Training loss: 0.5822088718414307
Validation loss: 1.6387759434279574

Epoch: 6| Step: 6
Training loss: 0.48890334367752075
Validation loss: 1.6583211806512648

Epoch: 6| Step: 7
Training loss: 0.4563487470149994
Validation loss: 1.6634766978602256

Epoch: 6| Step: 8
Training loss: 0.6846640110015869
Validation loss: 1.682395947876797

Epoch: 6| Step: 9
Training loss: 0.35660797357559204
Validation loss: 1.6750350088201544

Epoch: 6| Step: 10
Training loss: 0.8518726229667664
Validation loss: 1.7086337163884153

Epoch: 6| Step: 11
Training loss: 0.6624401807785034
Validation loss: 1.701639844525245

Epoch: 6| Step: 12
Training loss: 0.4843617379665375
Validation loss: 1.70503859109776

Epoch: 6| Step: 13
Training loss: 0.7655546069145203
Validation loss: 1.7039183070582729

Epoch: 324| Step: 0
Training loss: 0.35281041264533997
Validation loss: 1.7067111897212204

Epoch: 6| Step: 1
Training loss: 0.5469412803649902
Validation loss: 1.6720759419984714

Epoch: 6| Step: 2
Training loss: 0.5711685419082642
Validation loss: 1.6480945284648607

Epoch: 6| Step: 3
Training loss: 0.3311464488506317
Validation loss: 1.6474370174510504

Epoch: 6| Step: 4
Training loss: 0.3611331582069397
Validation loss: 1.6436113965126775

Epoch: 6| Step: 5
Training loss: 0.5766077041625977
Validation loss: 1.613892516782207

Epoch: 6| Step: 6
Training loss: 0.31962695717811584
Validation loss: 1.6351903561622865

Epoch: 6| Step: 7
Training loss: 0.4826655387878418
Validation loss: 1.6234104684604111

Epoch: 6| Step: 8
Training loss: 0.559310257434845
Validation loss: 1.656419042618044

Epoch: 6| Step: 9
Training loss: 0.7385566234588623
Validation loss: 1.6791588311554284

Epoch: 6| Step: 10
Training loss: 0.43360602855682373
Validation loss: 1.6789623537371237

Epoch: 6| Step: 11
Training loss: 0.5042994022369385
Validation loss: 1.6798130735274284

Epoch: 6| Step: 12
Training loss: 0.3894374370574951
Validation loss: 1.6797230692319973

Epoch: 6| Step: 13
Training loss: 0.42111697793006897
Validation loss: 1.6647010285367247

Epoch: 325| Step: 0
Training loss: 0.4926299750804901
Validation loss: 1.644216655403055

Epoch: 6| Step: 1
Training loss: 0.49742770195007324
Validation loss: 1.638982642081476

Epoch: 6| Step: 2
Training loss: 0.6327275633811951
Validation loss: 1.654385111665213

Epoch: 6| Step: 3
Training loss: 0.48226040601730347
Validation loss: 1.6618357384076683

Epoch: 6| Step: 4
Training loss: 0.42319029569625854
Validation loss: 1.6587862596716931

Epoch: 6| Step: 5
Training loss: 0.36130964756011963
Validation loss: 1.6772315527803154

Epoch: 6| Step: 6
Training loss: 0.23794309794902802
Validation loss: 1.697094814751738

Epoch: 6| Step: 7
Training loss: 0.3794063925743103
Validation loss: 1.6765569474107476

Epoch: 6| Step: 8
Training loss: 0.5572041869163513
Validation loss: 1.665735674160783

Epoch: 6| Step: 9
Training loss: 0.619820237159729
Validation loss: 1.6478310733713128

Epoch: 6| Step: 10
Training loss: 0.35298413038253784
Validation loss: 1.644511184384746

Epoch: 6| Step: 11
Training loss: 0.569705605506897
Validation loss: 1.6147203701798634

Epoch: 6| Step: 12
Training loss: 0.476199209690094
Validation loss: 1.596845733222141

Epoch: 6| Step: 13
Training loss: 0.3854296803474426
Validation loss: 1.6297351070629653

Epoch: 326| Step: 0
Training loss: 0.4278244376182556
Validation loss: 1.611171991594376

Epoch: 6| Step: 1
Training loss: 0.7498142719268799
Validation loss: 1.587279619709138

Epoch: 6| Step: 2
Training loss: 0.4303111433982849
Validation loss: 1.558154595795498

Epoch: 6| Step: 3
Training loss: 0.39282628893852234
Validation loss: 1.569915948375579

Epoch: 6| Step: 4
Training loss: 0.37865057587623596
Validation loss: 1.585446964028061

Epoch: 6| Step: 5
Training loss: 0.48591348528862
Validation loss: 1.5510903378968597

Epoch: 6| Step: 6
Training loss: 0.4223252534866333
Validation loss: 1.529902914518951

Epoch: 6| Step: 7
Training loss: 0.387387752532959
Validation loss: 1.5725519682771416

Epoch: 6| Step: 8
Training loss: 0.5031642317771912
Validation loss: 1.579348773084661

Epoch: 6| Step: 9
Training loss: 0.44925349950790405
Validation loss: 1.5692001337646155

Epoch: 6| Step: 10
Training loss: 0.6590776443481445
Validation loss: 1.5704589748895297

Epoch: 6| Step: 11
Training loss: 0.4629727602005005
Validation loss: 1.5870519735479867

Epoch: 6| Step: 12
Training loss: 0.41182661056518555
Validation loss: 1.5936671521074028

Epoch: 6| Step: 13
Training loss: 0.40416643023490906
Validation loss: 1.5958039619589364

Epoch: 327| Step: 0
Training loss: 0.8733693361282349
Validation loss: 1.6188365554296842

Epoch: 6| Step: 1
Training loss: 0.842717707157135
Validation loss: 1.6360319686192337

Epoch: 6| Step: 2
Training loss: 0.27662813663482666
Validation loss: 1.6223915943535425

Epoch: 6| Step: 3
Training loss: 0.5542001724243164
Validation loss: 1.6666002517105432

Epoch: 6| Step: 4
Training loss: 0.5167842507362366
Validation loss: 1.6719865081130818

Epoch: 6| Step: 5
Training loss: 0.7123005390167236
Validation loss: 1.6637107326138405

Epoch: 6| Step: 6
Training loss: 0.555094301700592
Validation loss: 1.6581842322503366

Epoch: 6| Step: 7
Training loss: 0.5726450681686401
Validation loss: 1.6530080790160804

Epoch: 6| Step: 8
Training loss: 0.2618628442287445
Validation loss: 1.6520497478464597

Epoch: 6| Step: 9
Training loss: 0.20256519317626953
Validation loss: 1.6281468957983039

Epoch: 6| Step: 10
Training loss: 0.2386035919189453
Validation loss: 1.6481728130771267

Epoch: 6| Step: 11
Training loss: 0.20166528224945068
Validation loss: 1.6435543580721783

Epoch: 6| Step: 12
Training loss: 0.2844861149787903
Validation loss: 1.6264657051332536

Epoch: 6| Step: 13
Training loss: 0.3207806348800659
Validation loss: 1.6234876212253366

Epoch: 328| Step: 0
Training loss: 0.3667505979537964
Validation loss: 1.625067251984791

Epoch: 6| Step: 1
Training loss: 0.2258106917142868
Validation loss: 1.6158642948314708

Epoch: 6| Step: 2
Training loss: 0.5662369728088379
Validation loss: 1.6179464824738041

Epoch: 6| Step: 3
Training loss: 0.325370192527771
Validation loss: 1.6137487208971413

Epoch: 6| Step: 4
Training loss: 0.5245070457458496
Validation loss: 1.6539143413625739

Epoch: 6| Step: 5
Training loss: 0.6506276726722717
Validation loss: 1.650329650089305

Epoch: 6| Step: 6
Training loss: 0.31330883502960205
Validation loss: 1.6731330886963875

Epoch: 6| Step: 7
Training loss: 0.3535892963409424
Validation loss: 1.679784854253133

Epoch: 6| Step: 8
Training loss: 0.39865052700042725
Validation loss: 1.6965110237880419

Epoch: 6| Step: 9
Training loss: 0.46164387464523315
Validation loss: 1.679531039730195

Epoch: 6| Step: 10
Training loss: 0.3640775680541992
Validation loss: 1.682361392564671

Epoch: 6| Step: 11
Training loss: 0.473825603723526
Validation loss: 1.6859563255822787

Epoch: 6| Step: 12
Training loss: 0.8329421281814575
Validation loss: 1.6692296535738054

Epoch: 6| Step: 13
Training loss: 0.7566602826118469
Validation loss: 1.6490278218382148

Epoch: 329| Step: 0
Training loss: 0.32694172859191895
Validation loss: 1.6431763543877551

Epoch: 6| Step: 1
Training loss: 0.36082327365875244
Validation loss: 1.6001753384067166

Epoch: 6| Step: 2
Training loss: 0.5272902250289917
Validation loss: 1.605723705343021

Epoch: 6| Step: 3
Training loss: 0.2665088474750519
Validation loss: 1.6193284834584882

Epoch: 6| Step: 4
Training loss: 0.5201488137245178
Validation loss: 1.6129242745778893

Epoch: 6| Step: 5
Training loss: 0.8643699884414673
Validation loss: 1.604753384026148

Epoch: 6| Step: 6
Training loss: 0.354220986366272
Validation loss: 1.6001529283421014

Epoch: 6| Step: 7
Training loss: 0.7452614307403564
Validation loss: 1.6362263464158582

Epoch: 6| Step: 8
Training loss: 0.4597626328468323
Validation loss: 1.6154360360996698

Epoch: 6| Step: 9
Training loss: 0.30180978775024414
Validation loss: 1.6111732670055923

Epoch: 6| Step: 10
Training loss: 0.7107743620872498
Validation loss: 1.5899769208764518

Epoch: 6| Step: 11
Training loss: 0.32672709226608276
Validation loss: 1.5973745033305178

Epoch: 6| Step: 12
Training loss: 0.30152344703674316
Validation loss: 1.595099473512301

Epoch: 6| Step: 13
Training loss: 0.4729336202144623
Validation loss: 1.6108354009607786

Epoch: 330| Step: 0
Training loss: 0.2380804419517517
Validation loss: 1.6264784374544698

Epoch: 6| Step: 1
Training loss: 0.5003340244293213
Validation loss: 1.635186033864175

Epoch: 6| Step: 2
Training loss: 0.26701804995536804
Validation loss: 1.6285045326396983

Epoch: 6| Step: 3
Training loss: 0.4152452349662781
Validation loss: 1.6454920038100211

Epoch: 6| Step: 4
Training loss: 0.8165415525436401
Validation loss: 1.6299279806434468

Epoch: 6| Step: 5
Training loss: 0.5152953267097473
Validation loss: 1.6609516079707811

Epoch: 6| Step: 6
Training loss: 0.35041123628616333
Validation loss: 1.6733978358648156

Epoch: 6| Step: 7
Training loss: 0.302322655916214
Validation loss: 1.6511020468127342

Epoch: 6| Step: 8
Training loss: 0.4258514642715454
Validation loss: 1.6895370791035313

Epoch: 6| Step: 9
Training loss: 0.5449293851852417
Validation loss: 1.6452904491014377

Epoch: 6| Step: 10
Training loss: 0.2907703220844269
Validation loss: 1.6324395389967068

Epoch: 6| Step: 11
Training loss: 0.5389699935913086
Validation loss: 1.6448534611732728

Epoch: 6| Step: 12
Training loss: 0.6205297112464905
Validation loss: 1.636568445031361

Epoch: 6| Step: 13
Training loss: 0.27700626850128174
Validation loss: 1.6398038915408555

Epoch: 331| Step: 0
Training loss: 0.4595611095428467
Validation loss: 1.6455183503448323

Epoch: 6| Step: 1
Training loss: 0.17977213859558105
Validation loss: 1.6241604929329247

Epoch: 6| Step: 2
Training loss: 0.25047606229782104
Validation loss: 1.6596007475288965

Epoch: 6| Step: 3
Training loss: 0.3072319030761719
Validation loss: 1.6267504153713104

Epoch: 6| Step: 4
Training loss: 0.6380418539047241
Validation loss: 1.618511124323773

Epoch: 6| Step: 5
Training loss: 0.7028324007987976
Validation loss: 1.627654653723522

Epoch: 6| Step: 6
Training loss: 0.41690850257873535
Validation loss: 1.6045944741977158

Epoch: 6| Step: 7
Training loss: 0.4185940623283386
Validation loss: 1.6418118079503377

Epoch: 6| Step: 8
Training loss: 0.29058295488357544
Validation loss: 1.6336740511719898

Epoch: 6| Step: 9
Training loss: 0.4531296491622925
Validation loss: 1.6148877900133851

Epoch: 6| Step: 10
Training loss: 0.47362637519836426
Validation loss: 1.6348281944951704

Epoch: 6| Step: 11
Training loss: 0.7281398773193359
Validation loss: 1.6373884882978214

Epoch: 6| Step: 12
Training loss: 0.44564956426620483
Validation loss: 1.616623652878628

Epoch: 6| Step: 13
Training loss: 0.32653936743736267
Validation loss: 1.605144425105023

Epoch: 332| Step: 0
Training loss: 0.30430158972740173
Validation loss: 1.624936847276585

Epoch: 6| Step: 1
Training loss: 0.24994924664497375
Validation loss: 1.6529208024342854

Epoch: 6| Step: 2
Training loss: 0.4063960909843445
Validation loss: 1.6392946179195116

Epoch: 6| Step: 3
Training loss: 0.4725075960159302
Validation loss: 1.6828340356067946

Epoch: 6| Step: 4
Training loss: 0.45738711953163147
Validation loss: 1.6404741707668509

Epoch: 6| Step: 5
Training loss: 0.48184388875961304
Validation loss: 1.6417601390551495

Epoch: 6| Step: 6
Training loss: 0.6580319404602051
Validation loss: 1.6229506666942308

Epoch: 6| Step: 7
Training loss: 0.45988819003105164
Validation loss: 1.6560085127430577

Epoch: 6| Step: 8
Training loss: 0.6284011006355286
Validation loss: 1.6305348860320223

Epoch: 6| Step: 9
Training loss: 0.4637746214866638
Validation loss: 1.6430063119498632

Epoch: 6| Step: 10
Training loss: 0.2540391683578491
Validation loss: 1.6171072106207571

Epoch: 6| Step: 11
Training loss: 0.4298909306526184
Validation loss: 1.6431214732508506

Epoch: 6| Step: 12
Training loss: 0.37233084440231323
Validation loss: 1.592687201756303

Epoch: 6| Step: 13
Training loss: 0.5239546298980713
Validation loss: 1.647245619886665

Epoch: 333| Step: 0
Training loss: 0.30262261629104614
Validation loss: 1.5957509292069303

Epoch: 6| Step: 1
Training loss: 0.5338862538337708
Validation loss: 1.6402421741075413

Epoch: 6| Step: 2
Training loss: 0.6434485912322998
Validation loss: 1.6535646402707664

Epoch: 6| Step: 3
Training loss: 0.8057405948638916
Validation loss: 1.6177443163369292

Epoch: 6| Step: 4
Training loss: 0.24459967017173767
Validation loss: 1.6345144984542683

Epoch: 6| Step: 5
Training loss: 0.5025294423103333
Validation loss: 1.6202097208269182

Epoch: 6| Step: 6
Training loss: 0.6927546262741089
Validation loss: 1.63142196337382

Epoch: 6| Step: 7
Training loss: 0.2724266052246094
Validation loss: 1.6242912456553469

Epoch: 6| Step: 8
Training loss: 0.5855278372764587
Validation loss: 1.6291192782822477

Epoch: 6| Step: 9
Training loss: 0.20092064142227173
Validation loss: 1.6744923655704786

Epoch: 6| Step: 10
Training loss: 0.3329477310180664
Validation loss: 1.6595383664613128

Epoch: 6| Step: 11
Training loss: 0.2996959686279297
Validation loss: 1.6893238688027987

Epoch: 6| Step: 12
Training loss: 0.4373514652252197
Validation loss: 1.6807400770084833

Epoch: 6| Step: 13
Training loss: 0.2978326380252838
Validation loss: 1.636148097694561

Epoch: 334| Step: 0
Training loss: 0.43764856457710266
Validation loss: 1.6612430657109907

Epoch: 6| Step: 1
Training loss: 0.763137698173523
Validation loss: 1.651294921034126

Epoch: 6| Step: 2
Training loss: 0.27284908294677734
Validation loss: 1.6414645333443918

Epoch: 6| Step: 3
Training loss: 0.5268244743347168
Validation loss: 1.6788474488001999

Epoch: 6| Step: 4
Training loss: 0.2393285483121872
Validation loss: 1.6812483264553932

Epoch: 6| Step: 5
Training loss: 0.5376718044281006
Validation loss: 1.7283341218066472

Epoch: 6| Step: 6
Training loss: 0.7918459177017212
Validation loss: 1.6863291353307746

Epoch: 6| Step: 7
Training loss: 0.3651796579360962
Validation loss: 1.658626010341029

Epoch: 6| Step: 8
Training loss: 0.5524190068244934
Validation loss: 1.6468969109237834

Epoch: 6| Step: 9
Training loss: 0.284168004989624
Validation loss: 1.6423394372386317

Epoch: 6| Step: 10
Training loss: 0.4837747812271118
Validation loss: 1.6603197897634199

Epoch: 6| Step: 11
Training loss: 0.41815125942230225
Validation loss: 1.6381047169367473

Epoch: 6| Step: 12
Training loss: 0.2795608639717102
Validation loss: 1.62360934288271

Epoch: 6| Step: 13
Training loss: 0.534437358379364
Validation loss: 1.6205464563062113

Epoch: 335| Step: 0
Training loss: 0.5294510126113892
Validation loss: 1.660738496370213

Epoch: 6| Step: 1
Training loss: 0.7100663185119629
Validation loss: 1.6434498486980316

Epoch: 6| Step: 2
Training loss: 0.5568259358406067
Validation loss: 1.6314057560377224

Epoch: 6| Step: 3
Training loss: 0.8863497972488403
Validation loss: 1.6408580016064387

Epoch: 6| Step: 4
Training loss: 0.32384783029556274
Validation loss: 1.6277982278536725

Epoch: 6| Step: 5
Training loss: 0.6411907076835632
Validation loss: 1.5983149954067764

Epoch: 6| Step: 6
Training loss: 0.2857377529144287
Validation loss: 1.6257044282010806

Epoch: 6| Step: 7
Training loss: 0.6116693019866943
Validation loss: 1.644768484177128

Epoch: 6| Step: 8
Training loss: 0.14684101939201355
Validation loss: 1.6308434156961338

Epoch: 6| Step: 9
Training loss: 0.5175598859786987
Validation loss: 1.6304327634073073

Epoch: 6| Step: 10
Training loss: 0.44616806507110596
Validation loss: 1.677965561548869

Epoch: 6| Step: 11
Training loss: 0.33501482009887695
Validation loss: 1.7299125630368468

Epoch: 6| Step: 12
Training loss: 0.3994523882865906
Validation loss: 1.736691556951051

Epoch: 6| Step: 13
Training loss: 0.26279178261756897
Validation loss: 1.744584083557129

Epoch: 336| Step: 0
Training loss: 0.555682897567749
Validation loss: 1.7611070422716038

Epoch: 6| Step: 1
Training loss: 0.31742194294929504
Validation loss: 1.7634970962360341

Epoch: 6| Step: 2
Training loss: 0.5497567057609558
Validation loss: 1.750252373756901

Epoch: 6| Step: 3
Training loss: 0.19476741552352905
Validation loss: 1.7066994072288595

Epoch: 6| Step: 4
Training loss: 0.49208948016166687
Validation loss: 1.6999708208986508

Epoch: 6| Step: 5
Training loss: 0.533443808555603
Validation loss: 1.6865853609577302

Epoch: 6| Step: 6
Training loss: 0.2761678695678711
Validation loss: 1.6502274710644957

Epoch: 6| Step: 7
Training loss: 0.4813508093357086
Validation loss: 1.60042364751139

Epoch: 6| Step: 8
Training loss: 0.5230952501296997
Validation loss: 1.6035915702901862

Epoch: 6| Step: 9
Training loss: 0.4062690734863281
Validation loss: 1.5937515330571

Epoch: 6| Step: 10
Training loss: 0.7903156280517578
Validation loss: 1.5807886892749416

Epoch: 6| Step: 11
Training loss: 0.6359142065048218
Validation loss: 1.5813592480074974

Epoch: 6| Step: 12
Training loss: 0.35812559723854065
Validation loss: 1.6031530223866945

Epoch: 6| Step: 13
Training loss: 0.8214352130889893
Validation loss: 1.6005326009565783

Epoch: 337| Step: 0
Training loss: 0.4011448323726654
Validation loss: 1.6868706287876252

Epoch: 6| Step: 1
Training loss: 0.36703723669052124
Validation loss: 1.682860469305387

Epoch: 6| Step: 2
Training loss: 0.5261099338531494
Validation loss: 1.6700809399286907

Epoch: 6| Step: 3
Training loss: 0.5702279806137085
Validation loss: 1.638285477956136

Epoch: 6| Step: 4
Training loss: 0.5114208459854126
Validation loss: 1.5779284482361169

Epoch: 6| Step: 5
Training loss: 0.4186707139015198
Validation loss: 1.624335970929874

Epoch: 6| Step: 6
Training loss: 0.35662642121315
Validation loss: 1.5934611366641136

Epoch: 6| Step: 7
Training loss: 0.40387672185897827
Validation loss: 1.6105061551576019

Epoch: 6| Step: 8
Training loss: 0.8335064649581909
Validation loss: 1.6184549562392696

Epoch: 6| Step: 9
Training loss: 0.36223888397216797
Validation loss: 1.606882490137572

Epoch: 6| Step: 10
Training loss: 0.2422807514667511
Validation loss: 1.5963171605140931

Epoch: 6| Step: 11
Training loss: 0.38280147314071655
Validation loss: 1.6050096340076898

Epoch: 6| Step: 12
Training loss: 0.38487303256988525
Validation loss: 1.6156075436581847

Epoch: 6| Step: 13
Training loss: 0.7005670070648193
Validation loss: 1.6181856393814087

Epoch: 338| Step: 0
Training loss: 0.24212247133255005
Validation loss: 1.5789530507979854

Epoch: 6| Step: 1
Training loss: 0.7074443101882935
Validation loss: 1.5901540658807243

Epoch: 6| Step: 2
Training loss: 0.26547956466674805
Validation loss: 1.6125743901857765

Epoch: 6| Step: 3
Training loss: 0.25266873836517334
Validation loss: 1.607189533531025

Epoch: 6| Step: 4
Training loss: 0.5671597123146057
Validation loss: 1.5880742688332834

Epoch: 6| Step: 5
Training loss: 0.25425875186920166
Validation loss: 1.6200965841611226

Epoch: 6| Step: 6
Training loss: 0.27811795473098755
Validation loss: 1.629026912873791

Epoch: 6| Step: 7
Training loss: 0.7269027233123779
Validation loss: 1.5940312544504802

Epoch: 6| Step: 8
Training loss: 0.33463001251220703
Validation loss: 1.6062007245197092

Epoch: 6| Step: 9
Training loss: 0.6578089594841003
Validation loss: 1.6225000363524242

Epoch: 6| Step: 10
Training loss: 0.3319852352142334
Validation loss: 1.6088171338522306

Epoch: 6| Step: 11
Training loss: 0.5924267768859863
Validation loss: 1.618824790882808

Epoch: 6| Step: 12
Training loss: 0.5968434810638428
Validation loss: 1.5816327974360476

Epoch: 6| Step: 13
Training loss: 0.316861093044281
Validation loss: 1.5904410603225871

Epoch: 339| Step: 0
Training loss: 0.28262025117874146
Validation loss: 1.5770887431278025

Epoch: 6| Step: 1
Training loss: 0.45232972502708435
Validation loss: 1.5773410489482265

Epoch: 6| Step: 2
Training loss: 0.39628157019615173
Validation loss: 1.5853610500212638

Epoch: 6| Step: 3
Training loss: 0.310299813747406
Validation loss: 1.5815930571607364

Epoch: 6| Step: 4
Training loss: 0.30401405692100525
Validation loss: 1.5758507585012784

Epoch: 6| Step: 5
Training loss: 0.6373075246810913
Validation loss: 1.57243085932988

Epoch: 6| Step: 6
Training loss: 0.19039380550384521
Validation loss: 1.6229949907589984

Epoch: 6| Step: 7
Training loss: 0.7086889743804932
Validation loss: 1.6692811372459575

Epoch: 6| Step: 8
Training loss: 0.4403071403503418
Validation loss: 1.639453839230281

Epoch: 6| Step: 9
Training loss: 0.7993171811103821
Validation loss: 1.6005548700209586

Epoch: 6| Step: 10
Training loss: 0.27531641721725464
Validation loss: 1.565214764687323

Epoch: 6| Step: 11
Training loss: 0.5389692187309265
Validation loss: 1.574830698710616

Epoch: 6| Step: 12
Training loss: 0.6664633750915527
Validation loss: 1.5438008705774944

Epoch: 6| Step: 13
Training loss: 0.3268486559391022
Validation loss: 1.5530685263295327

Epoch: 340| Step: 0
Training loss: 0.6057600378990173
Validation loss: 1.5659053274380264

Epoch: 6| Step: 1
Training loss: 0.42320501804351807
Validation loss: 1.6087769295579644

Epoch: 6| Step: 2
Training loss: 0.371116578578949
Validation loss: 1.5661401953748477

Epoch: 6| Step: 3
Training loss: 0.3882416784763336
Validation loss: 1.5876202480767363

Epoch: 6| Step: 4
Training loss: 0.3683379888534546
Validation loss: 1.5927391936702113

Epoch: 6| Step: 5
Training loss: 0.3481591045856476
Validation loss: 1.6218098235386673

Epoch: 6| Step: 6
Training loss: 0.5766994953155518
Validation loss: 1.6976796734717585

Epoch: 6| Step: 7
Training loss: 0.8107846975326538
Validation loss: 1.7188637794986847

Epoch: 6| Step: 8
Training loss: 0.36202630400657654
Validation loss: 1.6543969851668163

Epoch: 6| Step: 9
Training loss: 0.4399136006832123
Validation loss: 1.634598558948886

Epoch: 6| Step: 10
Training loss: 0.4899887442588806
Validation loss: 1.5585295384930027

Epoch: 6| Step: 11
Training loss: 0.35805848240852356
Validation loss: 1.5419097664535686

Epoch: 6| Step: 12
Training loss: 0.45911872386932373
Validation loss: 1.555002300970016

Epoch: 6| Step: 13
Training loss: 0.14412598311901093
Validation loss: 1.5285431441440378

Epoch: 341| Step: 0
Training loss: 0.6578822135925293
Validation loss: 1.5852837972743536

Epoch: 6| Step: 1
Training loss: 0.5035064816474915
Validation loss: 1.5598321858272757

Epoch: 6| Step: 2
Training loss: 0.3610045611858368
Validation loss: 1.5566936551883657

Epoch: 6| Step: 3
Training loss: 0.9447511434555054
Validation loss: 1.5373126678569342

Epoch: 6| Step: 4
Training loss: 0.3580527901649475
Validation loss: 1.5451881629164501

Epoch: 6| Step: 5
Training loss: 0.24289317429065704
Validation loss: 1.5834783046476302

Epoch: 6| Step: 6
Training loss: 0.28398364782333374
Validation loss: 1.6081363552360124

Epoch: 6| Step: 7
Training loss: 0.4472636282444
Validation loss: 1.6778714926012102

Epoch: 6| Step: 8
Training loss: 0.45039382576942444
Validation loss: 1.6772604732103245

Epoch: 6| Step: 9
Training loss: 0.435738742351532
Validation loss: 1.6322778174954076

Epoch: 6| Step: 10
Training loss: 0.44209063053131104
Validation loss: 1.6025936565091532

Epoch: 6| Step: 11
Training loss: 0.19905325770378113
Validation loss: 1.5789508447852185

Epoch: 6| Step: 12
Training loss: 0.590506374835968
Validation loss: 1.5936373177395071

Epoch: 6| Step: 13
Training loss: 0.38837194442749023
Validation loss: 1.6020164271836639

Epoch: 342| Step: 0
Training loss: 0.7917664647102356
Validation loss: 1.6069668749327302

Epoch: 6| Step: 1
Training loss: 0.4219178259372711
Validation loss: 1.6298096320962394

Epoch: 6| Step: 2
Training loss: 0.2840142846107483
Validation loss: 1.6168057290456628

Epoch: 6| Step: 3
Training loss: 0.43428489565849304
Validation loss: 1.6084433755566996

Epoch: 6| Step: 4
Training loss: 0.47630247473716736
Validation loss: 1.6171927849451702

Epoch: 6| Step: 5
Training loss: 0.26476556062698364
Validation loss: 1.6195242635665401

Epoch: 6| Step: 6
Training loss: 0.2963094115257263
Validation loss: 1.596313536808055

Epoch: 6| Step: 7
Training loss: 0.4956245422363281
Validation loss: 1.6436352447796894

Epoch: 6| Step: 8
Training loss: 0.3235255479812622
Validation loss: 1.5989786501853698

Epoch: 6| Step: 9
Training loss: 0.41145533323287964
Validation loss: 1.6001601949814828

Epoch: 6| Step: 10
Training loss: 0.3283674716949463
Validation loss: 1.5743907997685094

Epoch: 6| Step: 11
Training loss: 0.2835175693035126
Validation loss: 1.5167355306686894

Epoch: 6| Step: 12
Training loss: 0.7154685258865356
Validation loss: 1.5359129713427635

Epoch: 6| Step: 13
Training loss: 0.5954861640930176
Validation loss: 1.5330900338388258

Epoch: 343| Step: 0
Training loss: 0.29949110746383667
Validation loss: 1.5100563341571438

Epoch: 6| Step: 1
Training loss: 0.25644659996032715
Validation loss: 1.540079116821289

Epoch: 6| Step: 2
Training loss: 0.39870643615722656
Validation loss: 1.547914380668312

Epoch: 6| Step: 3
Training loss: 0.2572801113128662
Validation loss: 1.5695441038377824

Epoch: 6| Step: 4
Training loss: 0.3629489243030548
Validation loss: 1.6357731985789474

Epoch: 6| Step: 5
Training loss: 0.39047354459762573
Validation loss: 1.635888212470598

Epoch: 6| Step: 6
Training loss: 0.3615575432777405
Validation loss: 1.6670240458621775

Epoch: 6| Step: 7
Training loss: 0.3501738905906677
Validation loss: 1.67522612438407

Epoch: 6| Step: 8
Training loss: 0.442513644695282
Validation loss: 1.6743651936131139

Epoch: 6| Step: 9
Training loss: 0.34080252051353455
Validation loss: 1.6827202227807814

Epoch: 6| Step: 10
Training loss: 0.6062276363372803
Validation loss: 1.6365869045257568

Epoch: 6| Step: 11
Training loss: 0.6211947202682495
Validation loss: 1.623304597793087

Epoch: 6| Step: 12
Training loss: 0.4162212014198303
Validation loss: 1.6416637000217233

Epoch: 6| Step: 13
Training loss: 1.7202980518341064
Validation loss: 1.6221876798137542

Epoch: 344| Step: 0
Training loss: 0.5255600214004517
Validation loss: 1.6762044737415929

Epoch: 6| Step: 1
Training loss: 0.5813312530517578
Validation loss: 1.6823118373911867

Epoch: 6| Step: 2
Training loss: 0.41639676690101624
Validation loss: 1.6562965377684562

Epoch: 6| Step: 3
Training loss: 0.2801496982574463
Validation loss: 1.636758223656685

Epoch: 6| Step: 4
Training loss: 0.4321650266647339
Validation loss: 1.6126171670934206

Epoch: 6| Step: 5
Training loss: 0.23795092105865479
Validation loss: 1.5766396983977287

Epoch: 6| Step: 6
Training loss: 0.635554313659668
Validation loss: 1.5557374044131207

Epoch: 6| Step: 7
Training loss: 0.3563274145126343
Validation loss: 1.5506614510731032

Epoch: 6| Step: 8
Training loss: 0.9351052641868591
Validation loss: 1.570234728115861

Epoch: 6| Step: 9
Training loss: 0.5937467813491821
Validation loss: 1.593242658081875

Epoch: 6| Step: 10
Training loss: 0.5188243389129639
Validation loss: 1.576770620961343

Epoch: 6| Step: 11
Training loss: 0.3690582513809204
Validation loss: 1.5872398409792172

Epoch: 6| Step: 12
Training loss: 0.405093252658844
Validation loss: 1.6136562055157078

Epoch: 6| Step: 13
Training loss: 0.21889728307724
Validation loss: 1.6342808905468191

Epoch: 345| Step: 0
Training loss: 0.36283570528030396
Validation loss: 1.6060163500488445

Epoch: 6| Step: 1
Training loss: 0.35310280323028564
Validation loss: 1.6021751614027127

Epoch: 6| Step: 2
Training loss: 0.3925844430923462
Validation loss: 1.5855388872085079

Epoch: 6| Step: 3
Training loss: 0.5783882141113281
Validation loss: 1.5786168972651164

Epoch: 6| Step: 4
Training loss: 0.2888560891151428
Validation loss: 1.5689055522282918

Epoch: 6| Step: 5
Training loss: 0.24857546389102936
Validation loss: 1.576160930818127

Epoch: 6| Step: 6
Training loss: 0.4939667880535126
Validation loss: 1.5822370654793196

Epoch: 6| Step: 7
Training loss: 0.4375
Validation loss: 1.5638381037660825

Epoch: 6| Step: 8
Training loss: 0.2921905517578125
Validation loss: 1.5595276099379345

Epoch: 6| Step: 9
Training loss: 0.2572069764137268
Validation loss: 1.607478771158444

Epoch: 6| Step: 10
Training loss: 0.6570085287094116
Validation loss: 1.589492137714099

Epoch: 6| Step: 11
Training loss: 0.7211242914199829
Validation loss: 1.618257802019837

Epoch: 6| Step: 12
Training loss: 0.33913570642471313
Validation loss: 1.5724223365065872

Epoch: 6| Step: 13
Training loss: 0.4476807415485382
Validation loss: 1.6101085447495984

Epoch: 346| Step: 0
Training loss: 0.37007611989974976
Validation loss: 1.6185325345685404

Epoch: 6| Step: 1
Training loss: 0.29375529289245605
Validation loss: 1.582797311967419

Epoch: 6| Step: 2
Training loss: 0.46377497911453247
Validation loss: 1.5504004609200261

Epoch: 6| Step: 3
Training loss: 0.4643094539642334
Validation loss: 1.5583037727622575

Epoch: 6| Step: 4
Training loss: 1.0460143089294434
Validation loss: 1.5438062580682899

Epoch: 6| Step: 5
Training loss: 0.6060104966163635
Validation loss: 1.5888797403663717

Epoch: 6| Step: 6
Training loss: 0.4655475616455078
Validation loss: 1.5742245169096096

Epoch: 6| Step: 7
Training loss: 0.33813464641571045
Validation loss: 1.5769576539275467

Epoch: 6| Step: 8
Training loss: 0.2993415296077728
Validation loss: 1.5633537730863016

Epoch: 6| Step: 9
Training loss: 0.2517451345920563
Validation loss: 1.589998318303016

Epoch: 6| Step: 10
Training loss: 0.4543042480945587
Validation loss: 1.664663722438197

Epoch: 6| Step: 11
Training loss: 0.570637583732605
Validation loss: 1.6834442628327237

Epoch: 6| Step: 12
Training loss: 0.505845308303833
Validation loss: 1.687535769195967

Epoch: 6| Step: 13
Training loss: 0.3748878240585327
Validation loss: 1.6480417738678634

Epoch: 347| Step: 0
Training loss: 0.5003726482391357
Validation loss: 1.6102142769803283

Epoch: 6| Step: 1
Training loss: 0.32513731718063354
Validation loss: 1.5855959410308509

Epoch: 6| Step: 2
Training loss: 0.3538815379142761
Validation loss: 1.5867165544981598

Epoch: 6| Step: 3
Training loss: 0.916235625743866
Validation loss: 1.5816257679334251

Epoch: 6| Step: 4
Training loss: 0.3913964629173279
Validation loss: 1.5977939815931423

Epoch: 6| Step: 5
Training loss: 0.29443204402923584
Validation loss: 1.595291986260363

Epoch: 6| Step: 6
Training loss: 0.22148728370666504
Validation loss: 1.6069218971396004

Epoch: 6| Step: 7
Training loss: 0.32859891653060913
Validation loss: 1.5937906080676663

Epoch: 6| Step: 8
Training loss: 0.6224803924560547
Validation loss: 1.6081446293861634

Epoch: 6| Step: 9
Training loss: 0.3189149796962738
Validation loss: 1.5886048988629413

Epoch: 6| Step: 10
Training loss: 0.34656739234924316
Validation loss: 1.6166413355899114

Epoch: 6| Step: 11
Training loss: 0.18935225903987885
Validation loss: 1.6076205020309777

Epoch: 6| Step: 12
Training loss: 0.49826887249946594
Validation loss: 1.6242708852214198

Epoch: 6| Step: 13
Training loss: 0.8318781852722168
Validation loss: 1.6046480414687947

Epoch: 348| Step: 0
Training loss: 0.3007339835166931
Validation loss: 1.6090121717863186

Epoch: 6| Step: 1
Training loss: 0.8592790961265564
Validation loss: 1.6550048858888688

Epoch: 6| Step: 2
Training loss: 0.5229266881942749
Validation loss: 1.6841806224597398

Epoch: 6| Step: 3
Training loss: 0.4598698318004608
Validation loss: 1.6652290756984423

Epoch: 6| Step: 4
Training loss: 0.3476186692714691
Validation loss: 1.6155089460393435

Epoch: 6| Step: 5
Training loss: 0.41073521971702576
Validation loss: 1.6078259868006552

Epoch: 6| Step: 6
Training loss: 0.2757332921028137
Validation loss: 1.5842504988434494

Epoch: 6| Step: 7
Training loss: 0.38665157556533813
Validation loss: 1.6150859581526888

Epoch: 6| Step: 8
Training loss: 0.44530999660491943
Validation loss: 1.6044806549626012

Epoch: 6| Step: 9
Training loss: 0.5307371020317078
Validation loss: 1.6249438229427542

Epoch: 6| Step: 10
Training loss: 0.3421344757080078
Validation loss: 1.6131637275859874

Epoch: 6| Step: 11
Training loss: 0.7002016305923462
Validation loss: 1.615413027424966

Epoch: 6| Step: 12
Training loss: 0.1800413429737091
Validation loss: 1.6534967563485587

Epoch: 6| Step: 13
Training loss: 0.3650411367416382
Validation loss: 1.7437458294694141

Epoch: 349| Step: 0
Training loss: 0.3484600782394409
Validation loss: 1.7760535901592625

Epoch: 6| Step: 1
Training loss: 0.43015140295028687
Validation loss: 1.7739855268950104

Epoch: 6| Step: 2
Training loss: 0.3329557776451111
Validation loss: 1.6567543873222925

Epoch: 6| Step: 3
Training loss: 0.3287506103515625
Validation loss: 1.6101277707725443

Epoch: 6| Step: 4
Training loss: 0.6558783054351807
Validation loss: 1.5823197710898615

Epoch: 6| Step: 5
Training loss: 0.4182523787021637
Validation loss: 1.5731861488793486

Epoch: 6| Step: 6
Training loss: 0.4135954976081848
Validation loss: 1.5555419460419686

Epoch: 6| Step: 7
Training loss: 0.4858742952346802
Validation loss: 1.5445557230262346

Epoch: 6| Step: 8
Training loss: 0.7584028840065002
Validation loss: 1.5412838792288175

Epoch: 6| Step: 9
Training loss: 0.5334492921829224
Validation loss: 1.560604610750752

Epoch: 6| Step: 10
Training loss: 0.45601052045822144
Validation loss: 1.5700848000023955

Epoch: 6| Step: 11
Training loss: 0.40596216917037964
Validation loss: 1.5470009209007345

Epoch: 6| Step: 12
Training loss: 0.31170544028282166
Validation loss: 1.5634152389341784

Epoch: 6| Step: 13
Training loss: 0.18980924785137177
Validation loss: 1.5819314564428022

Epoch: 350| Step: 0
Training loss: 0.3891071677207947
Validation loss: 1.6264362822296798

Epoch: 6| Step: 1
Training loss: 0.6358264684677124
Validation loss: 1.692259027111915

Epoch: 6| Step: 2
Training loss: 0.4975452125072479
Validation loss: 1.7238751483219925

Epoch: 6| Step: 3
Training loss: 0.5778367519378662
Validation loss: 1.7057897583130868

Epoch: 6| Step: 4
Training loss: 0.38554370403289795
Validation loss: 1.6078715388492872

Epoch: 6| Step: 5
Training loss: 0.4318622350692749
Validation loss: 1.594574773183433

Epoch: 6| Step: 6
Training loss: 0.325016051530838
Validation loss: 1.565103195687776

Epoch: 6| Step: 7
Training loss: 0.22765415906906128
Validation loss: 1.5505851840460172

Epoch: 6| Step: 8
Training loss: 0.413001149892807
Validation loss: 1.5635355044436712

Epoch: 6| Step: 9
Training loss: 0.9302372336387634
Validation loss: 1.56407251281123

Epoch: 6| Step: 10
Training loss: 0.3212551474571228
Validation loss: 1.5467531450333134

Epoch: 6| Step: 11
Training loss: 0.5316532254219055
Validation loss: 1.585690676525075

Epoch: 6| Step: 12
Training loss: 0.2490338534116745
Validation loss: 1.581026296461782

Epoch: 6| Step: 13
Training loss: 0.2938171625137329
Validation loss: 1.5634165771545903

Epoch: 351| Step: 0
Training loss: 0.3057054281234741
Validation loss: 1.5840626532031643

Epoch: 6| Step: 1
Training loss: 0.34316903352737427
Validation loss: 1.5726050279473747

Epoch: 6| Step: 2
Training loss: 0.3441723585128784
Validation loss: 1.577204901684997

Epoch: 6| Step: 3
Training loss: 0.204178124666214
Validation loss: 1.5664281076000584

Epoch: 6| Step: 4
Training loss: 0.462888240814209
Validation loss: 1.59315626916065

Epoch: 6| Step: 5
Training loss: 0.7434659600257874
Validation loss: 1.5747334880213584

Epoch: 6| Step: 6
Training loss: 0.3769461214542389
Validation loss: 1.5564121866738925

Epoch: 6| Step: 7
Training loss: 0.4463174045085907
Validation loss: 1.5371001433300715

Epoch: 6| Step: 8
Training loss: 0.37686753273010254
Validation loss: 1.5377700739009406

Epoch: 6| Step: 9
Training loss: 0.27329644560813904
Validation loss: 1.5131614477403703

Epoch: 6| Step: 10
Training loss: 0.79490727186203
Validation loss: 1.5243203780984367

Epoch: 6| Step: 11
Training loss: 0.47309696674346924
Validation loss: 1.5250847621630597

Epoch: 6| Step: 12
Training loss: 0.4246159493923187
Validation loss: 1.5216451127042052

Epoch: 6| Step: 13
Training loss: 0.5217726230621338
Validation loss: 1.5016872177841842

Epoch: 352| Step: 0
Training loss: 0.37974342703819275
Validation loss: 1.5431439235646238

Epoch: 6| Step: 1
Training loss: 0.8064301013946533
Validation loss: 1.5406172454998057

Epoch: 6| Step: 2
Training loss: 0.22669826447963715
Validation loss: 1.5530397917634697

Epoch: 6| Step: 3
Training loss: 0.27268368005752563
Validation loss: 1.546043763878525

Epoch: 6| Step: 4
Training loss: 0.32757288217544556
Validation loss: 1.5509502374997703

Epoch: 6| Step: 5
Training loss: 0.3851955533027649
Validation loss: 1.5457447299393274

Epoch: 6| Step: 6
Training loss: 0.8419886827468872
Validation loss: 1.541791808220648

Epoch: 6| Step: 7
Training loss: 0.352744460105896
Validation loss: 1.5329434025672175

Epoch: 6| Step: 8
Training loss: 0.4943605363368988
Validation loss: 1.521034541950431

Epoch: 6| Step: 9
Training loss: 0.29294663667678833
Validation loss: 1.503826291330399

Epoch: 6| Step: 10
Training loss: 0.28366121649742126
Validation loss: 1.512856234786331

Epoch: 6| Step: 11
Training loss: 0.2142907679080963
Validation loss: 1.496995004274512

Epoch: 6| Step: 12
Training loss: 0.21931177377700806
Validation loss: 1.5110334363034976

Epoch: 6| Step: 13
Training loss: 0.3700207769870758
Validation loss: 1.5206896335847917

Epoch: 353| Step: 0
Training loss: 0.4974289834499359
Validation loss: 1.5370682349769018

Epoch: 6| Step: 1
Training loss: 0.22840338945388794
Validation loss: 1.5545783773545296

Epoch: 6| Step: 2
Training loss: 0.34607210755348206
Validation loss: 1.5598032730881886

Epoch: 6| Step: 3
Training loss: 0.3310653865337372
Validation loss: 1.5929646043367283

Epoch: 6| Step: 4
Training loss: 0.39680224657058716
Validation loss: 1.5945643724933747

Epoch: 6| Step: 5
Training loss: 0.3575093746185303
Validation loss: 1.5987735076617169

Epoch: 6| Step: 6
Training loss: 0.2529297471046448
Validation loss: 1.5610736147049935

Epoch: 6| Step: 7
Training loss: 0.2527623176574707
Validation loss: 1.5415627648753505

Epoch: 6| Step: 8
Training loss: 0.31813204288482666
Validation loss: 1.554995048430658

Epoch: 6| Step: 9
Training loss: 0.15684252977371216
Validation loss: 1.5522401486673663

Epoch: 6| Step: 10
Training loss: 0.4408854842185974
Validation loss: 1.542059084420563

Epoch: 6| Step: 11
Training loss: 0.31325334310531616
Validation loss: 1.5082908381697953

Epoch: 6| Step: 12
Training loss: 0.8353738784790039
Validation loss: 1.542894394167008

Epoch: 6| Step: 13
Training loss: 0.7880304455757141
Validation loss: 1.5394411830491916

Epoch: 354| Step: 0
Training loss: 0.4194175601005554
Validation loss: 1.5415287363913752

Epoch: 6| Step: 1
Training loss: 0.45965173840522766
Validation loss: 1.510951562594342

Epoch: 6| Step: 2
Training loss: 0.24382753670215607
Validation loss: 1.5217693005838702

Epoch: 6| Step: 3
Training loss: 0.254793643951416
Validation loss: 1.5282305094503588

Epoch: 6| Step: 4
Training loss: 0.2945454716682434
Validation loss: 1.5159035421186877

Epoch: 6| Step: 5
Training loss: 0.4462897777557373
Validation loss: 1.517132479657409

Epoch: 6| Step: 6
Training loss: 0.6528167724609375
Validation loss: 1.5296078279454222

Epoch: 6| Step: 7
Training loss: 0.4802316725254059
Validation loss: 1.570986436259362

Epoch: 6| Step: 8
Training loss: 0.6117276549339294
Validation loss: 1.5780993430845198

Epoch: 6| Step: 9
Training loss: 0.2453644573688507
Validation loss: 1.6018787878815846

Epoch: 6| Step: 10
Training loss: 0.5045379400253296
Validation loss: 1.5779296018744027

Epoch: 6| Step: 11
Training loss: 0.2713952660560608
Validation loss: 1.5856277071019655

Epoch: 6| Step: 12
Training loss: 0.25688108801841736
Validation loss: 1.5813505034292898

Epoch: 6| Step: 13
Training loss: 0.33521372079849243
Validation loss: 1.5576952401027884

Epoch: 355| Step: 0
Training loss: 0.316959410905838
Validation loss: 1.5651227517794537

Epoch: 6| Step: 1
Training loss: 0.9506323337554932
Validation loss: 1.5561062238549674

Epoch: 6| Step: 2
Training loss: 0.24047161638736725
Validation loss: 1.5357270650966193

Epoch: 6| Step: 3
Training loss: 0.46707063913345337
Validation loss: 1.575260901963839

Epoch: 6| Step: 4
Training loss: 0.333648681640625
Validation loss: 1.5667509366107244

Epoch: 6| Step: 5
Training loss: 0.22258318960666656
Validation loss: 1.5275193414380472

Epoch: 6| Step: 6
Training loss: 0.2582368552684784
Validation loss: 1.5608056463221067

Epoch: 6| Step: 7
Training loss: 0.3887680172920227
Validation loss: 1.5980667542385798

Epoch: 6| Step: 8
Training loss: 0.256481409072876
Validation loss: 1.6326045836171796

Epoch: 6| Step: 9
Training loss: 0.3243168592453003
Validation loss: 1.6283488004438338

Epoch: 6| Step: 10
Training loss: 0.38305962085723877
Validation loss: 1.5439186698646956

Epoch: 6| Step: 11
Training loss: 0.5302452445030212
Validation loss: 1.5093008959165184

Epoch: 6| Step: 12
Training loss: 0.3089416027069092
Validation loss: 1.519078536700177

Epoch: 6| Step: 13
Training loss: 0.3235413730144501
Validation loss: 1.4928532492729925

Epoch: 356| Step: 0
Training loss: 0.7508580088615417
Validation loss: 1.50392968808451

Epoch: 6| Step: 1
Training loss: 0.6101321578025818
Validation loss: 1.4693897014023156

Epoch: 6| Step: 2
Training loss: 0.3382255733013153
Validation loss: 1.4816364716458064

Epoch: 6| Step: 3
Training loss: 0.31584668159484863
Validation loss: 1.463506817817688

Epoch: 6| Step: 4
Training loss: 0.2663339078426361
Validation loss: 1.4930635049778929

Epoch: 6| Step: 5
Training loss: 0.31476640701293945
Validation loss: 1.5079752142711351

Epoch: 6| Step: 6
Training loss: 0.44173291325569153
Validation loss: 1.5348613159630888

Epoch: 6| Step: 7
Training loss: 0.32079970836639404
Validation loss: 1.5218562156923356

Epoch: 6| Step: 8
Training loss: 0.2399284690618515
Validation loss: 1.527425019971786

Epoch: 6| Step: 9
Training loss: 0.25961101055145264
Validation loss: 1.5277471478267381

Epoch: 6| Step: 10
Training loss: 0.36419427394866943
Validation loss: 1.530949769481536

Epoch: 6| Step: 11
Training loss: 0.3212535083293915
Validation loss: 1.5127237958292807

Epoch: 6| Step: 12
Training loss: 0.27203071117401123
Validation loss: 1.5619253029105484

Epoch: 6| Step: 13
Training loss: 0.4074779152870178
Validation loss: 1.550940909693318

Epoch: 357| Step: 0
Training loss: 0.26482823491096497
Validation loss: 1.5590768244958693

Epoch: 6| Step: 1
Training loss: 0.46744829416275024
Validation loss: 1.5429177463695567

Epoch: 6| Step: 2
Training loss: 0.30365365743637085
Validation loss: 1.557255450115409

Epoch: 6| Step: 3
Training loss: 0.8562434911727905
Validation loss: 1.5420170791687504

Epoch: 6| Step: 4
Training loss: 0.27222323417663574
Validation loss: 1.558125279283011

Epoch: 6| Step: 5
Training loss: 0.5119297504425049
Validation loss: 1.5578836907622635

Epoch: 6| Step: 6
Training loss: 0.24592715501785278
Validation loss: 1.5580056816019037

Epoch: 6| Step: 7
Training loss: 0.3055933713912964
Validation loss: 1.543373627047385

Epoch: 6| Step: 8
Training loss: 0.23728397488594055
Validation loss: 1.5643674353117585

Epoch: 6| Step: 9
Training loss: 0.19718636572360992
Validation loss: 1.5372668645715202

Epoch: 6| Step: 10
Training loss: 0.2674967646598816
Validation loss: 1.560601713836834

Epoch: 6| Step: 11
Training loss: 0.2088836431503296
Validation loss: 1.5550889827871834

Epoch: 6| Step: 12
Training loss: 0.3751055598258972
Validation loss: 1.5340633930698517

Epoch: 6| Step: 13
Training loss: 0.5012784600257874
Validation loss: 1.5668260115449146

Epoch: 358| Step: 0
Training loss: 0.2638550400733948
Validation loss: 1.5417443090869534

Epoch: 6| Step: 1
Training loss: 0.2913359999656677
Validation loss: 1.5328721577121365

Epoch: 6| Step: 2
Training loss: 0.22457915544509888
Validation loss: 1.5523521182357625

Epoch: 6| Step: 3
Training loss: 0.5563027858734131
Validation loss: 1.5582892587107997

Epoch: 6| Step: 4
Training loss: 0.3626224994659424
Validation loss: 1.550624301356654

Epoch: 6| Step: 5
Training loss: 0.2571108043193817
Validation loss: 1.569036740128712

Epoch: 6| Step: 6
Training loss: 0.6407994031906128
Validation loss: 1.5498853627071585

Epoch: 6| Step: 7
Training loss: 0.3580016493797302
Validation loss: 1.5591903232759046

Epoch: 6| Step: 8
Training loss: 0.2908477187156677
Validation loss: 1.5495139834701375

Epoch: 6| Step: 9
Training loss: 0.24164870381355286
Validation loss: 1.5412633290854834

Epoch: 6| Step: 10
Training loss: 0.2906714677810669
Validation loss: 1.5257286878042324

Epoch: 6| Step: 11
Training loss: 0.5108180046081543
Validation loss: 1.5346563234124133

Epoch: 6| Step: 12
Training loss: 0.31243982911109924
Validation loss: 1.5445128679275513

Epoch: 6| Step: 13
Training loss: 0.061014626175165176
Validation loss: 1.5602830917604509

Epoch: 359| Step: 0
Training loss: 0.13615743815898895
Validation loss: 1.5522897038408505

Epoch: 6| Step: 1
Training loss: 0.2823411524295807
Validation loss: 1.53511377175649

Epoch: 6| Step: 2
Training loss: 0.27674388885498047
Validation loss: 1.5174704687569731

Epoch: 6| Step: 3
Training loss: 0.37069255113601685
Validation loss: 1.522837588863988

Epoch: 6| Step: 4
Training loss: 0.5826892256736755
Validation loss: 1.5502421125288932

Epoch: 6| Step: 5
Training loss: 0.3206894099712372
Validation loss: 1.528930414107538

Epoch: 6| Step: 6
Training loss: 0.2098059356212616
Validation loss: 1.5246008878113122

Epoch: 6| Step: 7
Training loss: 0.3931896686553955
Validation loss: 1.5283590004008303

Epoch: 6| Step: 8
Training loss: 0.7965500354766846
Validation loss: 1.550678272401133

Epoch: 6| Step: 9
Training loss: 0.4358232915401459
Validation loss: 1.5011597923053208

Epoch: 6| Step: 10
Training loss: 0.28255581855773926
Validation loss: 1.5064948361407045

Epoch: 6| Step: 11
Training loss: 0.1812053620815277
Validation loss: 1.5327124903278966

Epoch: 6| Step: 12
Training loss: 0.2262652963399887
Validation loss: 1.5168823042223532

Epoch: 6| Step: 13
Training loss: 0.2706610858440399
Validation loss: 1.5069791911750712

Epoch: 360| Step: 0
Training loss: 0.22714149951934814
Validation loss: 1.5298412275570694

Epoch: 6| Step: 1
Training loss: 0.29411959648132324
Validation loss: 1.4976067337938535

Epoch: 6| Step: 2
Training loss: 0.27275440096855164
Validation loss: 1.5116684872617003

Epoch: 6| Step: 3
Training loss: 0.30663496255874634
Validation loss: 1.5102853339205506

Epoch: 6| Step: 4
Training loss: 0.38660433888435364
Validation loss: 1.4922623813793223

Epoch: 6| Step: 5
Training loss: 0.17341074347496033
Validation loss: 1.5015409467040852

Epoch: 6| Step: 6
Training loss: 0.4217783212661743
Validation loss: 1.4954394743006716

Epoch: 6| Step: 7
Training loss: 0.3265075981616974
Validation loss: 1.5009029014136201

Epoch: 6| Step: 8
Training loss: 0.3067835569381714
Validation loss: 1.5137704777461227

Epoch: 6| Step: 9
Training loss: 0.5600506067276001
Validation loss: 1.533374814577

Epoch: 6| Step: 10
Training loss: 0.4248705506324768
Validation loss: 1.53850128317392

Epoch: 6| Step: 11
Training loss: 0.36964842677116394
Validation loss: 1.5797491611972931

Epoch: 6| Step: 12
Training loss: 0.227868914604187
Validation loss: 1.5777681309689757

Epoch: 6| Step: 13
Training loss: 0.8746677041053772
Validation loss: 1.6021335624879407

Epoch: 361| Step: 0
Training loss: 0.24556705355644226
Validation loss: 1.6164991676166494

Epoch: 6| Step: 1
Training loss: 0.4992649555206299
Validation loss: 1.6516878912525792

Epoch: 6| Step: 2
Training loss: 0.8365346789360046
Validation loss: 1.666107807108151

Epoch: 6| Step: 3
Training loss: 0.6624447703361511
Validation loss: 1.6407441310985114

Epoch: 6| Step: 4
Training loss: 0.5108116865158081
Validation loss: 1.586768478475591

Epoch: 6| Step: 5
Training loss: 0.3596495985984802
Validation loss: 1.5869006597867577

Epoch: 6| Step: 6
Training loss: 0.26307281851768494
Validation loss: 1.5730684957196635

Epoch: 6| Step: 7
Training loss: 0.309222936630249
Validation loss: 1.5695287354530827

Epoch: 6| Step: 8
Training loss: 0.2676199674606323
Validation loss: 1.5799454521107417

Epoch: 6| Step: 9
Training loss: 0.4763641953468323
Validation loss: 1.5790241834937886

Epoch: 6| Step: 10
Training loss: 0.2524294853210449
Validation loss: 1.5932184624415573

Epoch: 6| Step: 11
Training loss: 0.23359596729278564
Validation loss: 1.6122404067747054

Epoch: 6| Step: 12
Training loss: 0.2744719386100769
Validation loss: 1.6040208788328274

Epoch: 6| Step: 13
Training loss: 0.287690669298172
Validation loss: 1.580082942080754

Epoch: 362| Step: 0
Training loss: 0.2731437087059021
Validation loss: 1.5916050018802765

Epoch: 6| Step: 1
Training loss: 0.3325568437576294
Validation loss: 1.5779744361036567

Epoch: 6| Step: 2
Training loss: 0.2640497088432312
Validation loss: 1.5454518115648659

Epoch: 6| Step: 3
Training loss: 0.557367742061615
Validation loss: 1.5655428722340574

Epoch: 6| Step: 4
Training loss: 0.260854035615921
Validation loss: 1.5511215976489487

Epoch: 6| Step: 5
Training loss: 0.21717791259288788
Validation loss: 1.5500538720879504

Epoch: 6| Step: 6
Training loss: 0.28083479404449463
Validation loss: 1.559257726515493

Epoch: 6| Step: 7
Training loss: 0.7454802393913269
Validation loss: 1.567104531872657

Epoch: 6| Step: 8
Training loss: 0.2592476010322571
Validation loss: 1.5351962094665856

Epoch: 6| Step: 9
Training loss: 0.5037552118301392
Validation loss: 1.5742449324618104

Epoch: 6| Step: 10
Training loss: 0.3130996823310852
Validation loss: 1.5533937869533416

Epoch: 6| Step: 11
Training loss: 0.16452017426490784
Validation loss: 1.563712684057092

Epoch: 6| Step: 12
Training loss: 0.44212543964385986
Validation loss: 1.5653190446156326

Epoch: 6| Step: 13
Training loss: 0.1394757777452469
Validation loss: 1.5724277265610234

Epoch: 363| Step: 0
Training loss: 0.5778329372406006
Validation loss: 1.5386279795759468

Epoch: 6| Step: 1
Training loss: 0.40603387355804443
Validation loss: 1.517044145573852

Epoch: 6| Step: 2
Training loss: 0.4127570390701294
Validation loss: 1.5313645998636882

Epoch: 6| Step: 3
Training loss: 0.21360908448696136
Validation loss: 1.5015289783477783

Epoch: 6| Step: 4
Training loss: 0.23662468791007996
Validation loss: 1.525770882124542

Epoch: 6| Step: 5
Training loss: 0.28307807445526123
Validation loss: 1.511473536491394

Epoch: 6| Step: 6
Training loss: 0.24993714690208435
Validation loss: 1.503190662271233

Epoch: 6| Step: 7
Training loss: 0.2590062618255615
Validation loss: 1.533658516022467

Epoch: 6| Step: 8
Training loss: 0.20051653683185577
Validation loss: 1.5459103148470643

Epoch: 6| Step: 9
Training loss: 0.2005910873413086
Validation loss: 1.5522283533568024

Epoch: 6| Step: 10
Training loss: 0.4598129391670227
Validation loss: 1.5553275039119105

Epoch: 6| Step: 11
Training loss: 0.17380565404891968
Validation loss: 1.5346031163328437

Epoch: 6| Step: 12
Training loss: 0.4504207372665405
Validation loss: 1.5925332884634695

Epoch: 6| Step: 13
Training loss: 0.8213055729866028
Validation loss: 1.5645779717353083

Epoch: 364| Step: 0
Training loss: 0.2335071563720703
Validation loss: 1.556858116580594

Epoch: 6| Step: 1
Training loss: 0.42422252893447876
Validation loss: 1.5955264837511125

Epoch: 6| Step: 2
Training loss: 0.38075679540634155
Validation loss: 1.6255157980867612

Epoch: 6| Step: 3
Training loss: 0.2575674057006836
Validation loss: 1.6138732125682216

Epoch: 6| Step: 4
Training loss: 0.2610155940055847
Validation loss: 1.6160982936941168

Epoch: 6| Step: 5
Training loss: 0.2929917573928833
Validation loss: 1.6060745741731377

Epoch: 6| Step: 6
Training loss: 0.4616033434867859
Validation loss: 1.5582223079537834

Epoch: 6| Step: 7
Training loss: 0.15793372690677643
Validation loss: 1.5290907044564523

Epoch: 6| Step: 8
Training loss: 0.20038661360740662
Validation loss: 1.5444982615850305

Epoch: 6| Step: 9
Training loss: 0.45585310459136963
Validation loss: 1.5253678265438284

Epoch: 6| Step: 10
Training loss: 0.2991427481174469
Validation loss: 1.519083378135517

Epoch: 6| Step: 11
Training loss: 0.6071765422821045
Validation loss: 1.517131059400497

Epoch: 6| Step: 12
Training loss: 0.2126697152853012
Validation loss: 1.4889258582104918

Epoch: 6| Step: 13
Training loss: 0.2995573878288269
Validation loss: 1.4783978757037912

Epoch: 365| Step: 0
Training loss: 0.1516120731830597
Validation loss: 1.4898213071207846

Epoch: 6| Step: 1
Training loss: 0.3061892092227936
Validation loss: 1.4860594311068136

Epoch: 6| Step: 2
Training loss: 0.35131970047950745
Validation loss: 1.5056119811150335

Epoch: 6| Step: 3
Training loss: 0.4515293836593628
Validation loss: 1.4741460341279224

Epoch: 6| Step: 4
Training loss: 0.5519733428955078
Validation loss: 1.5249825959564538

Epoch: 6| Step: 5
Training loss: 0.319588840007782
Validation loss: 1.5022334283398044

Epoch: 6| Step: 6
Training loss: 0.3329166769981384
Validation loss: 1.517267038745265

Epoch: 6| Step: 7
Training loss: 0.34471696615219116
Validation loss: 1.5054331928171136

Epoch: 6| Step: 8
Training loss: 0.3711567223072052
Validation loss: 1.5383721782315163

Epoch: 6| Step: 9
Training loss: 0.24184516072273254
Validation loss: 1.5223724162706764

Epoch: 6| Step: 10
Training loss: 0.33747488260269165
Validation loss: 1.5373213137349775

Epoch: 6| Step: 11
Training loss: 0.1654713749885559
Validation loss: 1.4876778471854426

Epoch: 6| Step: 12
Training loss: 0.5257731676101685
Validation loss: 1.5060338768907773

Epoch: 6| Step: 13
Training loss: 0.30906713008880615
Validation loss: 1.485143756994637

Epoch: 366| Step: 0
Training loss: 0.2285190224647522
Validation loss: 1.4926391308025648

Epoch: 6| Step: 1
Training loss: 0.3647990822792053
Validation loss: 1.4919962472813104

Epoch: 6| Step: 2
Training loss: 0.3378722667694092
Validation loss: 1.502013946092257

Epoch: 6| Step: 3
Training loss: 0.583393394947052
Validation loss: 1.489736891561939

Epoch: 6| Step: 4
Training loss: 0.5248160362243652
Validation loss: 1.472996856576653

Epoch: 6| Step: 5
Training loss: 0.43457362055778503
Validation loss: 1.479825444118951

Epoch: 6| Step: 6
Training loss: 0.27639949321746826
Validation loss: 1.5387999985807685

Epoch: 6| Step: 7
Training loss: 0.4326086640357971
Validation loss: 1.5133719457093107

Epoch: 6| Step: 8
Training loss: 0.42098742723464966
Validation loss: 1.4783746247650476

Epoch: 6| Step: 9
Training loss: 0.17507213354110718
Validation loss: 1.4509431982553134

Epoch: 6| Step: 10
Training loss: 0.34718191623687744
Validation loss: 1.4813909671639884

Epoch: 6| Step: 11
Training loss: 0.27474287152290344
Validation loss: 1.4830686751232351

Epoch: 6| Step: 12
Training loss: 0.2167218178510666
Validation loss: 1.5088145963607296

Epoch: 6| Step: 13
Training loss: 0.3541584014892578
Validation loss: 1.4893594288056897

Epoch: 367| Step: 0
Training loss: 0.19987790286540985
Validation loss: 1.5055910259164789

Epoch: 6| Step: 1
Training loss: 0.38297975063323975
Validation loss: 1.5104085245440084

Epoch: 6| Step: 2
Training loss: 0.12683641910552979
Validation loss: 1.5107403788515317

Epoch: 6| Step: 3
Training loss: 0.3559279441833496
Validation loss: 1.5195161475930163

Epoch: 6| Step: 4
Training loss: 0.3634074330329895
Validation loss: 1.5436987171890915

Epoch: 6| Step: 5
Training loss: 0.3424193859100342
Validation loss: 1.522648456276104

Epoch: 6| Step: 6
Training loss: 0.6068843603134155
Validation loss: 1.527932313180739

Epoch: 6| Step: 7
Training loss: 0.35398852825164795
Validation loss: 1.501284053248744

Epoch: 6| Step: 8
Training loss: 0.241520494222641
Validation loss: 1.4873777871490808

Epoch: 6| Step: 9
Training loss: 0.20785854756832123
Validation loss: 1.4841601528147215

Epoch: 6| Step: 10
Training loss: 0.4812558591365814
Validation loss: 1.48468017578125

Epoch: 6| Step: 11
Training loss: 0.19746971130371094
Validation loss: 1.4890317545142224

Epoch: 6| Step: 12
Training loss: 0.24773889780044556
Validation loss: 1.4982691746886059

Epoch: 6| Step: 13
Training loss: 0.41349053382873535
Validation loss: 1.4892834540336364

Epoch: 368| Step: 0
Training loss: 0.24218803644180298
Validation loss: 1.4795358206636162

Epoch: 6| Step: 1
Training loss: 0.44357332587242126
Validation loss: 1.4777970647299161

Epoch: 6| Step: 2
Training loss: 0.2805801033973694
Validation loss: 1.4809009836566063

Epoch: 6| Step: 3
Training loss: 0.24758100509643555
Validation loss: 1.4881640544501684

Epoch: 6| Step: 4
Training loss: 0.36968064308166504
Validation loss: 1.5119131072874992

Epoch: 6| Step: 5
Training loss: 0.10166187584400177
Validation loss: 1.5560675103177306

Epoch: 6| Step: 6
Training loss: 0.5431702136993408
Validation loss: 1.5554822132151613

Epoch: 6| Step: 7
Training loss: 0.20560351014137268
Validation loss: 1.5709753280044885

Epoch: 6| Step: 8
Training loss: 0.3520694375038147
Validation loss: 1.600036068629193

Epoch: 6| Step: 9
Training loss: 0.4659372568130493
Validation loss: 1.6272960952533189

Epoch: 6| Step: 10
Training loss: 0.12960033118724823
Validation loss: 1.6098296949940343

Epoch: 6| Step: 11
Training loss: 0.6087612509727478
Validation loss: 1.574118823133489

Epoch: 6| Step: 12
Training loss: 0.24647869169712067
Validation loss: 1.5821102985771753

Epoch: 6| Step: 13
Training loss: 0.39810240268707275
Validation loss: 1.5715739278383152

Epoch: 369| Step: 0
Training loss: 0.24094857275485992
Validation loss: 1.5315126180648804

Epoch: 6| Step: 1
Training loss: 0.1317855566740036
Validation loss: 1.5150771987053655

Epoch: 6| Step: 2
Training loss: 0.21109609305858612
Validation loss: 1.5236434654522968

Epoch: 6| Step: 3
Training loss: 0.6879698038101196
Validation loss: 1.5368155176921556

Epoch: 6| Step: 4
Training loss: 0.2716566026210785
Validation loss: 1.5276157971351378

Epoch: 6| Step: 5
Training loss: 0.23824289441108704
Validation loss: 1.5495322571005872

Epoch: 6| Step: 6
Training loss: 0.2672941982746124
Validation loss: 1.5230579453129922

Epoch: 6| Step: 7
Training loss: 0.3714129328727722
Validation loss: 1.5345933642438663

Epoch: 6| Step: 8
Training loss: 0.2037978619337082
Validation loss: 1.5470083439221947

Epoch: 6| Step: 9
Training loss: 0.31076109409332275
Validation loss: 1.5099872645511423

Epoch: 6| Step: 10
Training loss: 0.2126588374376297
Validation loss: 1.5412612076728576

Epoch: 6| Step: 11
Training loss: 0.23263037204742432
Validation loss: 1.5451615369448097

Epoch: 6| Step: 12
Training loss: 0.5941972136497498
Validation loss: 1.5244198306914298

Epoch: 6| Step: 13
Training loss: 0.29017865657806396
Validation loss: 1.5216416530711676

Epoch: 370| Step: 0
Training loss: 0.20135663449764252
Validation loss: 1.5323427825845697

Epoch: 6| Step: 1
Training loss: 0.278152197599411
Validation loss: 1.4956419801199308

Epoch: 6| Step: 2
Training loss: 0.22838278114795685
Validation loss: 1.523577590142527

Epoch: 6| Step: 3
Training loss: 0.25232386589050293
Validation loss: 1.5413552804659771

Epoch: 6| Step: 4
Training loss: 0.28455936908721924
Validation loss: 1.5283960898717244

Epoch: 6| Step: 5
Training loss: 0.20820528268814087
Validation loss: 1.5290195442015124

Epoch: 6| Step: 6
Training loss: 0.2499256581068039
Validation loss: 1.5165200361641504

Epoch: 6| Step: 7
Training loss: 0.398892879486084
Validation loss: 1.4857979282256095

Epoch: 6| Step: 8
Training loss: 0.6333272457122803
Validation loss: 1.5087872743606567

Epoch: 6| Step: 9
Training loss: 0.19967535138130188
Validation loss: 1.4978278721532514

Epoch: 6| Step: 10
Training loss: 0.20605364441871643
Validation loss: 1.5122329304295201

Epoch: 6| Step: 11
Training loss: 0.5328206419944763
Validation loss: 1.531897037259994

Epoch: 6| Step: 12
Training loss: 0.41712430119514465
Validation loss: 1.522384105190154

Epoch: 6| Step: 13
Training loss: 0.18432895839214325
Validation loss: 1.5097944633935088

Epoch: 371| Step: 0
Training loss: 0.26174795627593994
Validation loss: 1.4927250877503426

Epoch: 6| Step: 1
Training loss: 0.2010522335767746
Validation loss: 1.5153931629273198

Epoch: 6| Step: 2
Training loss: 0.35040077567100525
Validation loss: 1.4848119943372664

Epoch: 6| Step: 3
Training loss: 0.23272721469402313
Validation loss: 1.5039220266444708

Epoch: 6| Step: 4
Training loss: 0.29309433698654175
Validation loss: 1.5078986402480834

Epoch: 6| Step: 5
Training loss: 0.523825466632843
Validation loss: 1.5030698494244648

Epoch: 6| Step: 6
Training loss: 0.15768808126449585
Validation loss: 1.5338941043423069

Epoch: 6| Step: 7
Training loss: 0.21331395208835602
Validation loss: 1.506772715558288

Epoch: 6| Step: 8
Training loss: 0.6475569009780884
Validation loss: 1.500304486161919

Epoch: 6| Step: 9
Training loss: 0.3348176181316376
Validation loss: 1.505089848272262

Epoch: 6| Step: 10
Training loss: 0.16731297969818115
Validation loss: 1.5126431013948174

Epoch: 6| Step: 11
Training loss: 0.30473360419273376
Validation loss: 1.510080801543369

Epoch: 6| Step: 12
Training loss: 0.19094911217689514
Validation loss: 1.5032184918721516

Epoch: 6| Step: 13
Training loss: 0.7338688969612122
Validation loss: 1.5336399873097737

Epoch: 372| Step: 0
Training loss: 0.20024248957633972
Validation loss: 1.5792379635636524

Epoch: 6| Step: 1
Training loss: 0.24927584826946259
Validation loss: 1.5220051311677503

Epoch: 6| Step: 2
Training loss: 0.5496995449066162
Validation loss: 1.5245488715428177

Epoch: 6| Step: 3
Training loss: 0.564272403717041
Validation loss: 1.4923097728401102

Epoch: 6| Step: 4
Training loss: 0.14671194553375244
Validation loss: 1.5215234756469727

Epoch: 6| Step: 5
Training loss: 0.4084256887435913
Validation loss: 1.519817442022344

Epoch: 6| Step: 6
Training loss: 0.2941824197769165
Validation loss: 1.5251026640656173

Epoch: 6| Step: 7
Training loss: 0.3161015212535858
Validation loss: 1.52659402226889

Epoch: 6| Step: 8
Training loss: 0.15568110346794128
Validation loss: 1.5117972832854076

Epoch: 6| Step: 9
Training loss: 0.27828964591026306
Validation loss: 1.4948302763764576

Epoch: 6| Step: 10
Training loss: 0.3749914765357971
Validation loss: 1.487119379223034

Epoch: 6| Step: 11
Training loss: 0.26923272013664246
Validation loss: 1.5257846501565748

Epoch: 6| Step: 12
Training loss: 0.23572838306427002
Validation loss: 1.526271999523204

Epoch: 6| Step: 13
Training loss: 0.25700220465660095
Validation loss: 1.4977841633622364

Epoch: 373| Step: 0
Training loss: 0.13384892046451569
Validation loss: 1.5355438391367595

Epoch: 6| Step: 1
Training loss: 0.20936176180839539
Validation loss: 1.5255116147379721

Epoch: 6| Step: 2
Training loss: 0.248774915933609
Validation loss: 1.5127097534876999

Epoch: 6| Step: 3
Training loss: 0.35525792837142944
Validation loss: 1.5293995911075222

Epoch: 6| Step: 4
Training loss: 0.19543612003326416
Validation loss: 1.5156837547979047

Epoch: 6| Step: 5
Training loss: 0.18659880757331848
Validation loss: 1.52690424073127

Epoch: 6| Step: 6
Training loss: 0.6874747276306152
Validation loss: 1.547022875919137

Epoch: 6| Step: 7
Training loss: 0.23487906157970428
Validation loss: 1.5929213390555432

Epoch: 6| Step: 8
Training loss: 0.4928027391433716
Validation loss: 1.5766561441524054

Epoch: 6| Step: 9
Training loss: 0.47521737217903137
Validation loss: 1.6277707879261305

Epoch: 6| Step: 10
Training loss: 0.41626399755477905
Validation loss: 1.5787447114144602

Epoch: 6| Step: 11
Training loss: 0.2013169527053833
Validation loss: 1.565529989939864

Epoch: 6| Step: 12
Training loss: 0.3026486039161682
Validation loss: 1.5176701109896424

Epoch: 6| Step: 13
Training loss: 0.07102200388908386
Validation loss: 1.5204363830627934

Epoch: 374| Step: 0
Training loss: 0.3677002787590027
Validation loss: 1.5249638941980177

Epoch: 6| Step: 1
Training loss: 0.6539183855056763
Validation loss: 1.542390945137188

Epoch: 6| Step: 2
Training loss: 0.2761515974998474
Validation loss: 1.5746246178944905

Epoch: 6| Step: 3
Training loss: 0.30195316672325134
Validation loss: 1.569479097602188

Epoch: 6| Step: 4
Training loss: 0.4084877371788025
Validation loss: 1.5889252308876283

Epoch: 6| Step: 5
Training loss: 0.2536545991897583
Validation loss: 1.6216208921965731

Epoch: 6| Step: 6
Training loss: 0.4761737585067749
Validation loss: 1.5479355537763206

Epoch: 6| Step: 7
Training loss: 0.3293304741382599
Validation loss: 1.5370178094474218

Epoch: 6| Step: 8
Training loss: 0.2616259455680847
Validation loss: 1.5104646913466915

Epoch: 6| Step: 9
Training loss: 0.18063482642173767
Validation loss: 1.5250951282439693

Epoch: 6| Step: 10
Training loss: 0.2795393764972687
Validation loss: 1.5372731660002021

Epoch: 6| Step: 11
Training loss: 0.20607291162014008
Validation loss: 1.5215362579591813

Epoch: 6| Step: 12
Training loss: 0.2345140278339386
Validation loss: 1.5237412542425177

Epoch: 6| Step: 13
Training loss: 0.13924603164196014
Validation loss: 1.511857436549279

Epoch: 375| Step: 0
Training loss: 0.1610761284828186
Validation loss: 1.5458369370429748

Epoch: 6| Step: 1
Training loss: 0.40518903732299805
Validation loss: 1.5527655155427995

Epoch: 6| Step: 2
Training loss: 0.15277063846588135
Validation loss: 1.5533667072173087

Epoch: 6| Step: 3
Training loss: 0.3135383427143097
Validation loss: 1.5606295677923387

Epoch: 6| Step: 4
Training loss: 0.31341737508773804
Validation loss: 1.5613476473798034

Epoch: 6| Step: 5
Training loss: 0.20325101912021637
Validation loss: 1.5537748798247306

Epoch: 6| Step: 6
Training loss: 0.2930668890476227
Validation loss: 1.5480266386462795

Epoch: 6| Step: 7
Training loss: 0.39023101329803467
Validation loss: 1.588109193309661

Epoch: 6| Step: 8
Training loss: 0.3482489585876465
Validation loss: 1.5665232071312525

Epoch: 6| Step: 9
Training loss: 0.25100526213645935
Validation loss: 1.5287131224909136

Epoch: 6| Step: 10
Training loss: 0.31152617931365967
Validation loss: 1.538054294483636

Epoch: 6| Step: 11
Training loss: 0.32115641236305237
Validation loss: 1.521748447930941

Epoch: 6| Step: 12
Training loss: 0.5069224238395691
Validation loss: 1.5187633806659329

Epoch: 6| Step: 13
Training loss: 0.21205991506576538
Validation loss: 1.499866493286625

Epoch: 376| Step: 0
Training loss: 0.2337413877248764
Validation loss: 1.522850169930407

Epoch: 6| Step: 1
Training loss: 0.3548441529273987
Validation loss: 1.5314350410174298

Epoch: 6| Step: 2
Training loss: 0.5790390372276306
Validation loss: 1.5102073428451375

Epoch: 6| Step: 3
Training loss: 0.18806543946266174
Validation loss: 1.5285427108887704

Epoch: 6| Step: 4
Training loss: 0.15222087502479553
Validation loss: 1.4768603283871886

Epoch: 6| Step: 5
Training loss: 0.22382581233978271
Validation loss: 1.4875445955543107

Epoch: 6| Step: 6
Training loss: 0.34355154633522034
Validation loss: 1.4799651458699217

Epoch: 6| Step: 7
Training loss: 0.49252504110336304
Validation loss: 1.480907520940227

Epoch: 6| Step: 8
Training loss: 0.1562005877494812
Validation loss: 1.496543288230896

Epoch: 6| Step: 9
Training loss: 0.2280898094177246
Validation loss: 1.4736799693876697

Epoch: 6| Step: 10
Training loss: 0.375820517539978
Validation loss: 1.4814513626918997

Epoch: 6| Step: 11
Training loss: 0.2850397229194641
Validation loss: 1.4618098787082139

Epoch: 6| Step: 12
Training loss: 0.26100027561187744
Validation loss: 1.445733117800887

Epoch: 6| Step: 13
Training loss: 0.2349131852388382
Validation loss: 1.4327424546723724

Epoch: 377| Step: 0
Training loss: 0.39771491289138794
Validation loss: 1.4472026812132968

Epoch: 6| Step: 1
Training loss: 0.20207402110099792
Validation loss: 1.4149887382343251

Epoch: 6| Step: 2
Training loss: 0.2031378298997879
Validation loss: 1.4302478669792094

Epoch: 6| Step: 3
Training loss: 0.27314674854278564
Validation loss: 1.4360057730828562

Epoch: 6| Step: 4
Training loss: 0.25575217604637146
Validation loss: 1.4527127332584833

Epoch: 6| Step: 5
Training loss: 0.3984065651893616
Validation loss: 1.4588766751750823

Epoch: 6| Step: 6
Training loss: 0.30771398544311523
Validation loss: 1.5009581453056746

Epoch: 6| Step: 7
Training loss: 0.26615941524505615
Validation loss: 1.5156343572883195

Epoch: 6| Step: 8
Training loss: 0.19777077436447144
Validation loss: 1.4912084225685365

Epoch: 6| Step: 9
Training loss: 0.1357881724834442
Validation loss: 1.4875641510050783

Epoch: 6| Step: 10
Training loss: 0.5366320610046387
Validation loss: 1.4777618967076784

Epoch: 6| Step: 11
Training loss: 0.7785463333129883
Validation loss: 1.5031698660183979

Epoch: 6| Step: 12
Training loss: 0.23918068408966064
Validation loss: 1.4994191354320896

Epoch: 6| Step: 13
Training loss: 0.30278682708740234
Validation loss: 1.501343455365909

Epoch: 378| Step: 0
Training loss: 0.3143465518951416
Validation loss: 1.4948258220508535

Epoch: 6| Step: 1
Training loss: 0.23143446445465088
Validation loss: 1.5054421758139005

Epoch: 6| Step: 2
Training loss: 0.17977124452590942
Validation loss: 1.5007814816249314

Epoch: 6| Step: 3
Training loss: 0.3609907627105713
Validation loss: 1.4836160162443757

Epoch: 6| Step: 4
Training loss: 0.32094573974609375
Validation loss: 1.5488882885184339

Epoch: 6| Step: 5
Training loss: 0.24972344934940338
Validation loss: 1.5712340800992903

Epoch: 6| Step: 6
Training loss: 0.2646878957748413
Validation loss: 1.4997921964173675

Epoch: 6| Step: 7
Training loss: 0.8389933109283447
Validation loss: 1.505405451661797

Epoch: 6| Step: 8
Training loss: 0.13168078660964966
Validation loss: 1.5050045988892997

Epoch: 6| Step: 9
Training loss: 0.25527751445770264
Validation loss: 1.5168353870350828

Epoch: 6| Step: 10
Training loss: 0.16983187198638916
Validation loss: 1.5079252822424776

Epoch: 6| Step: 11
Training loss: 0.2119157612323761
Validation loss: 1.516385720622155

Epoch: 6| Step: 12
Training loss: 0.299896240234375
Validation loss: 1.4973003710469892

Epoch: 6| Step: 13
Training loss: 0.2813548147678375
Validation loss: 1.5026022913635417

Epoch: 379| Step: 0
Training loss: 0.2756245732307434
Validation loss: 1.4765915678393455

Epoch: 6| Step: 1
Training loss: 0.25464022159576416
Validation loss: 1.4767922201464254

Epoch: 6| Step: 2
Training loss: 0.5799978375434875
Validation loss: 1.5050268288581603

Epoch: 6| Step: 3
Training loss: 0.32357802987098694
Validation loss: 1.476887882396739

Epoch: 6| Step: 4
Training loss: 0.2985159456729889
Validation loss: 1.4607454525527133

Epoch: 6| Step: 5
Training loss: 0.2406056821346283
Validation loss: 1.4819831412325624

Epoch: 6| Step: 6
Training loss: 0.1869591772556305
Validation loss: 1.4914498354799004

Epoch: 6| Step: 7
Training loss: 0.23236122727394104
Validation loss: 1.4839256707058157

Epoch: 6| Step: 8
Training loss: 0.2922722101211548
Validation loss: 1.5009666719744283

Epoch: 6| Step: 9
Training loss: 0.23275654017925262
Validation loss: 1.4926005717246764

Epoch: 6| Step: 10
Training loss: 0.17378385365009308
Validation loss: 1.4869219378758503

Epoch: 6| Step: 11
Training loss: 0.18653708696365356
Validation loss: 1.4824090606422835

Epoch: 6| Step: 12
Training loss: 0.21249467134475708
Validation loss: 1.4804414561999741

Epoch: 6| Step: 13
Training loss: 0.6151204109191895
Validation loss: 1.5250626872944575

Epoch: 380| Step: 0
Training loss: 0.2766020894050598
Validation loss: 1.5369556103983233

Epoch: 6| Step: 1
Training loss: 0.2647895812988281
Validation loss: 1.509663466484316

Epoch: 6| Step: 2
Training loss: 0.12468938529491425
Validation loss: 1.522886017317413

Epoch: 6| Step: 3
Training loss: 0.3039683699607849
Validation loss: 1.4998339664551519

Epoch: 6| Step: 4
Training loss: 0.4094284474849701
Validation loss: 1.4875896348748157

Epoch: 6| Step: 5
Training loss: 0.3921443819999695
Validation loss: 1.4808758766420427

Epoch: 6| Step: 6
Training loss: 0.48953497409820557
Validation loss: 1.473487166948216

Epoch: 6| Step: 7
Training loss: 0.6271032691001892
Validation loss: 1.4780625745814333

Epoch: 6| Step: 8
Training loss: 0.16569358110427856
Validation loss: 1.4770881463122625

Epoch: 6| Step: 9
Training loss: 0.23215463757514954
Validation loss: 1.4550033051480529

Epoch: 6| Step: 10
Training loss: 0.16472269594669342
Validation loss: 1.463473266170871

Epoch: 6| Step: 11
Training loss: 0.1742936372756958
Validation loss: 1.4862493302232476

Epoch: 6| Step: 12
Training loss: 0.16512387990951538
Validation loss: 1.4743423859278362

Epoch: 6| Step: 13
Training loss: 0.19837979972362518
Validation loss: 1.4755640196543869

Epoch: 381| Step: 0
Training loss: 0.23626255989074707
Validation loss: 1.4671382506688435

Epoch: 6| Step: 1
Training loss: 0.24101459980010986
Validation loss: 1.4811948409644506

Epoch: 6| Step: 2
Training loss: 0.19515161216259003
Validation loss: 1.4866989235724173

Epoch: 6| Step: 3
Training loss: 0.19580374658107758
Validation loss: 1.521438838333212

Epoch: 6| Step: 4
Training loss: 0.8376578688621521
Validation loss: 1.5117728440992293

Epoch: 6| Step: 5
Training loss: 0.31790605187416077
Validation loss: 1.5257153594365684

Epoch: 6| Step: 6
Training loss: 0.23572465777397156
Validation loss: 1.5449949695217995

Epoch: 6| Step: 7
Training loss: 0.19958306849002838
Validation loss: 1.5310452330497004

Epoch: 6| Step: 8
Training loss: 0.19084593653678894
Validation loss: 1.5107886573319793

Epoch: 6| Step: 9
Training loss: 0.20878034830093384
Validation loss: 1.4982974144720262

Epoch: 6| Step: 10
Training loss: 0.4718255400657654
Validation loss: 1.4526737659208235

Epoch: 6| Step: 11
Training loss: 0.37513595819473267
Validation loss: 1.4513822704233148

Epoch: 6| Step: 12
Training loss: 0.3116946816444397
Validation loss: 1.4729643765316214

Epoch: 6| Step: 13
Training loss: 0.38207530975341797
Validation loss: 1.4234187679906045

Epoch: 382| Step: 0
Training loss: 0.11709991097450256
Validation loss: 1.444878952798023

Epoch: 6| Step: 1
Training loss: 0.15262755751609802
Validation loss: 1.447254918595796

Epoch: 6| Step: 2
Training loss: 0.3340080976486206
Validation loss: 1.4507258579295168

Epoch: 6| Step: 3
Training loss: 0.5301865935325623
Validation loss: 1.4553298258012342

Epoch: 6| Step: 4
Training loss: 0.4812946319580078
Validation loss: 1.4823442787252448

Epoch: 6| Step: 5
Training loss: 0.31028425693511963
Validation loss: 1.5074869278938539

Epoch: 6| Step: 6
Training loss: 0.156983882188797
Validation loss: 1.50337064907115

Epoch: 6| Step: 7
Training loss: 0.42157885432243347
Validation loss: 1.4723502769265124

Epoch: 6| Step: 8
Training loss: 0.21607983112335205
Validation loss: 1.4745634537871166

Epoch: 6| Step: 9
Training loss: 0.1834401786327362
Validation loss: 1.4419298633452384

Epoch: 6| Step: 10
Training loss: 0.2490987628698349
Validation loss: 1.4439331626379361

Epoch: 6| Step: 11
Training loss: 0.333051472902298
Validation loss: 1.4540771028046966

Epoch: 6| Step: 12
Training loss: 0.23266418278217316
Validation loss: 1.4773874654564807

Epoch: 6| Step: 13
Training loss: 0.45104673504829407
Validation loss: 1.4448149716982277

Epoch: 383| Step: 0
Training loss: 0.32458245754241943
Validation loss: 1.4667711847571916

Epoch: 6| Step: 1
Training loss: 0.29649174213409424
Validation loss: 1.4741464712286507

Epoch: 6| Step: 2
Training loss: 0.18732950091362
Validation loss: 1.5261815850452711

Epoch: 6| Step: 3
Training loss: 0.25432682037353516
Validation loss: 1.5314176800430461

Epoch: 6| Step: 4
Training loss: 0.5397299528121948
Validation loss: 1.5215144862410843

Epoch: 6| Step: 5
Training loss: 0.2674499750137329
Validation loss: 1.5157677717106317

Epoch: 6| Step: 6
Training loss: 0.4288223385810852
Validation loss: 1.4993450635222978

Epoch: 6| Step: 7
Training loss: 0.29233241081237793
Validation loss: 1.4468726214542185

Epoch: 6| Step: 8
Training loss: 0.2648932933807373
Validation loss: 1.456605125499028

Epoch: 6| Step: 9
Training loss: 0.17495492100715637
Validation loss: 1.4213012585075953

Epoch: 6| Step: 10
Training loss: 0.17367446422576904
Validation loss: 1.4432462248750912

Epoch: 6| Step: 11
Training loss: 0.3532067537307739
Validation loss: 1.4511338446729927

Epoch: 6| Step: 12
Training loss: 0.4052395224571228
Validation loss: 1.4185011034370751

Epoch: 6| Step: 13
Training loss: 0.13940754532814026
Validation loss: 1.44753223593517

Epoch: 384| Step: 0
Training loss: 0.24500572681427002
Validation loss: 1.477467288253128

Epoch: 6| Step: 1
Training loss: 0.36843931674957275
Validation loss: 1.4829814331505888

Epoch: 6| Step: 2
Training loss: 0.27643656730651855
Validation loss: 1.4793184726468978

Epoch: 6| Step: 3
Training loss: 0.3096635341644287
Validation loss: 1.5353674452791932

Epoch: 6| Step: 4
Training loss: 0.3334350287914276
Validation loss: 1.5218886380554528

Epoch: 6| Step: 5
Training loss: 0.20132362842559814
Validation loss: 1.5257030828024751

Epoch: 6| Step: 6
Training loss: 0.2335510551929474
Validation loss: 1.5558307850232689

Epoch: 6| Step: 7
Training loss: 0.1631203144788742
Validation loss: 1.5834569085028865

Epoch: 6| Step: 8
Training loss: 0.3003528118133545
Validation loss: 1.6032397170220651

Epoch: 6| Step: 9
Training loss: 0.4549723267555237
Validation loss: 1.6170858811306696

Epoch: 6| Step: 10
Training loss: 0.32645946741104126
Validation loss: 1.5837796093315206

Epoch: 6| Step: 11
Training loss: 0.3087277114391327
Validation loss: 1.5448722089490583

Epoch: 6| Step: 12
Training loss: 0.5464907288551331
Validation loss: 1.5418370026414112

Epoch: 6| Step: 13
Training loss: 0.28270742297172546
Validation loss: 1.5425881448612417

Epoch: 385| Step: 0
Training loss: 0.3216008245944977
Validation loss: 1.5296380648048975

Epoch: 6| Step: 1
Training loss: 0.14649763703346252
Validation loss: 1.5016404877426803

Epoch: 6| Step: 2
Training loss: 0.1346399188041687
Validation loss: 1.5429922880664948

Epoch: 6| Step: 3
Training loss: 0.16421353816986084
Validation loss: 1.5355857277429232

Epoch: 6| Step: 4
Training loss: 0.283480703830719
Validation loss: 1.5926355443974978

Epoch: 6| Step: 5
Training loss: 0.3708697557449341
Validation loss: 1.5186664968408563

Epoch: 6| Step: 6
Training loss: 0.21304315328598022
Validation loss: 1.5849818965440154

Epoch: 6| Step: 7
Training loss: 0.29225820302963257
Validation loss: 1.5231437452377812

Epoch: 6| Step: 8
Training loss: 0.35850125551223755
Validation loss: 1.4927568608714687

Epoch: 6| Step: 9
Training loss: 0.3082083761692047
Validation loss: 1.4865577515735422

Epoch: 6| Step: 10
Training loss: 0.308483362197876
Validation loss: 1.494242783515684

Epoch: 6| Step: 11
Training loss: 0.2990151047706604
Validation loss: 1.5008778136263612

Epoch: 6| Step: 12
Training loss: 0.48362648487091064
Validation loss: 1.4885033804883239

Epoch: 6| Step: 13
Training loss: 0.749817430973053
Validation loss: 1.5189529388181624

Epoch: 386| Step: 0
Training loss: 0.22277939319610596
Validation loss: 1.491494821604862

Epoch: 6| Step: 1
Training loss: 0.2626838982105255
Validation loss: 1.4730031464689521

Epoch: 6| Step: 2
Training loss: 0.2926356792449951
Validation loss: 1.5076276768920243

Epoch: 6| Step: 3
Training loss: 0.5480469465255737
Validation loss: 1.5951921292530593

Epoch: 6| Step: 4
Training loss: 0.4348409175872803
Validation loss: 1.6265826532917638

Epoch: 6| Step: 5
Training loss: 0.6827355623245239
Validation loss: 1.6124349999171432

Epoch: 6| Step: 6
Training loss: 0.2822497487068176
Validation loss: 1.560017902364013

Epoch: 6| Step: 7
Training loss: 0.20926110446453094
Validation loss: 1.5645546079963766

Epoch: 6| Step: 8
Training loss: 0.2981228828430176
Validation loss: 1.4981068231726204

Epoch: 6| Step: 9
Training loss: 0.2676875591278076
Validation loss: 1.4669647755161408

Epoch: 6| Step: 10
Training loss: 0.15478792786598206
Validation loss: 1.4634555565413607

Epoch: 6| Step: 11
Training loss: 0.32254093885421753
Validation loss: 1.4520878522626814

Epoch: 6| Step: 12
Training loss: 0.20405696332454681
Validation loss: 1.4648252725601196

Epoch: 6| Step: 13
Training loss: 0.3498638868331909
Validation loss: 1.4936504107649609

Epoch: 387| Step: 0
Training loss: 0.3318898379802704
Validation loss: 1.4613311277922763

Epoch: 6| Step: 1
Training loss: 0.3030262291431427
Validation loss: 1.4626979738153436

Epoch: 6| Step: 2
Training loss: 0.1137714684009552
Validation loss: 1.5043396001221032

Epoch: 6| Step: 3
Training loss: 0.24784116446971893
Validation loss: 1.4636071817849272

Epoch: 6| Step: 4
Training loss: 0.1467527449131012
Validation loss: 1.4638489119468197

Epoch: 6| Step: 5
Training loss: 0.28720593452453613
Validation loss: 1.46212338888517

Epoch: 6| Step: 6
Training loss: 0.18497875332832336
Validation loss: 1.4948821606174592

Epoch: 6| Step: 7
Training loss: 0.2554130554199219
Validation loss: 1.5364942076385661

Epoch: 6| Step: 8
Training loss: 0.2938828766345978
Validation loss: 1.5339490264974616

Epoch: 6| Step: 9
Training loss: 0.5395293235778809
Validation loss: 1.5011753638585408

Epoch: 6| Step: 10
Training loss: 0.24122445285320282
Validation loss: 1.4749835421962123

Epoch: 6| Step: 11
Training loss: 0.1667424589395523
Validation loss: 1.5221706000707482

Epoch: 6| Step: 12
Training loss: 0.3300769329071045
Validation loss: 1.5400412223672355

Epoch: 6| Step: 13
Training loss: 0.7000777125358582
Validation loss: 1.487500302253231

Epoch: 388| Step: 0
Training loss: 0.34167933464050293
Validation loss: 1.505918884790072

Epoch: 6| Step: 1
Training loss: 0.37686413526535034
Validation loss: 1.4976387254653438

Epoch: 6| Step: 2
Training loss: 0.14522702991962433
Validation loss: 1.4845416353594871

Epoch: 6| Step: 3
Training loss: 0.16085100173950195
Validation loss: 1.4782003048927552

Epoch: 6| Step: 4
Training loss: 0.15061935782432556
Validation loss: 1.4633050605814943

Epoch: 6| Step: 5
Training loss: 0.19046437740325928
Validation loss: 1.4661289761143346

Epoch: 6| Step: 6
Training loss: 0.13457469642162323
Validation loss: 1.449624107730004

Epoch: 6| Step: 7
Training loss: 0.3558410406112671
Validation loss: 1.4622223351591377

Epoch: 6| Step: 8
Training loss: 0.30859994888305664
Validation loss: 1.4609908378252419

Epoch: 6| Step: 9
Training loss: 0.27276402711868286
Validation loss: 1.4421562135860484

Epoch: 6| Step: 10
Training loss: 0.38248804211616516
Validation loss: 1.4478133788672827

Epoch: 6| Step: 11
Training loss: 0.3987516760826111
Validation loss: 1.4539984900464293

Epoch: 6| Step: 12
Training loss: 0.17686542868614197
Validation loss: 1.460841748022264

Epoch: 6| Step: 13
Training loss: 0.19962458312511444
Validation loss: 1.449980584524011

Epoch: 389| Step: 0
Training loss: 0.24621859192848206
Validation loss: 1.4205173113012826

Epoch: 6| Step: 1
Training loss: 0.40081414580345154
Validation loss: 1.4294778800779773

Epoch: 6| Step: 2
Training loss: 0.1425221711397171
Validation loss: 1.4564968937186784

Epoch: 6| Step: 3
Training loss: 0.3123985230922699
Validation loss: 1.4850732344453053

Epoch: 6| Step: 4
Training loss: 0.20517709851264954
Validation loss: 1.4798679479988672

Epoch: 6| Step: 5
Training loss: 0.19260570406913757
Validation loss: 1.502405797281573

Epoch: 6| Step: 6
Training loss: 0.2589555084705353
Validation loss: 1.5195660411670644

Epoch: 6| Step: 7
Training loss: 0.2131558656692505
Validation loss: 1.5000740815234441

Epoch: 6| Step: 8
Training loss: 0.3454733192920685
Validation loss: 1.5113834129866732

Epoch: 6| Step: 9
Training loss: 0.350479394197464
Validation loss: 1.528563182841065

Epoch: 6| Step: 10
Training loss: 0.13703811168670654
Validation loss: 1.4904197428816108

Epoch: 6| Step: 11
Training loss: 0.27360042929649353
Validation loss: 1.4811139106750488

Epoch: 6| Step: 12
Training loss: 0.375007301568985
Validation loss: 1.477000085256433

Epoch: 6| Step: 13
Training loss: 0.17616057395935059
Validation loss: 1.4632592752415647

Epoch: 390| Step: 0
Training loss: 0.2410264015197754
Validation loss: 1.4603738259243708

Epoch: 6| Step: 1
Training loss: 0.1806533932685852
Validation loss: 1.4623524194122643

Epoch: 6| Step: 2
Training loss: 0.21576134860515594
Validation loss: 1.4783605657598025

Epoch: 6| Step: 3
Training loss: 0.1628604531288147
Validation loss: 1.44554276363824

Epoch: 6| Step: 4
Training loss: 0.203335702419281
Validation loss: 1.484045817006019

Epoch: 6| Step: 5
Training loss: 0.3018827438354492
Validation loss: 1.504902857606129

Epoch: 6| Step: 6
Training loss: 0.19652757048606873
Validation loss: 1.4859171580242854

Epoch: 6| Step: 7
Training loss: 0.15284928679466248
Validation loss: 1.5022895515605967

Epoch: 6| Step: 8
Training loss: 0.24321281909942627
Validation loss: 1.5057585508592668

Epoch: 6| Step: 9
Training loss: 0.19248338043689728
Validation loss: 1.4835639845940374

Epoch: 6| Step: 10
Training loss: 0.38903385400772095
Validation loss: 1.4714513324922132

Epoch: 6| Step: 11
Training loss: 0.2923126816749573
Validation loss: 1.5118227940733715

Epoch: 6| Step: 12
Training loss: 0.5999672412872314
Validation loss: 1.491234406989108

Epoch: 6| Step: 13
Training loss: 0.09422148764133453
Validation loss: 1.4662704698501094

Epoch: 391| Step: 0
Training loss: 0.5251073241233826
Validation loss: 1.4878323539610832

Epoch: 6| Step: 1
Training loss: 0.09014874696731567
Validation loss: 1.4947842423633864

Epoch: 6| Step: 2
Training loss: 0.26345545053482056
Validation loss: 1.476794227477043

Epoch: 6| Step: 3
Training loss: 0.25717124342918396
Validation loss: 1.4601178258977912

Epoch: 6| Step: 4
Training loss: 0.32056888937950134
Validation loss: 1.50017729625907

Epoch: 6| Step: 5
Training loss: 0.22051553428173065
Validation loss: 1.4773328919564523

Epoch: 6| Step: 6
Training loss: 0.371150940656662
Validation loss: 1.4880409202268046

Epoch: 6| Step: 7
Training loss: 0.15996797382831573
Validation loss: 1.503053972798009

Epoch: 6| Step: 8
Training loss: 0.31137678027153015
Validation loss: 1.4899136917565459

Epoch: 6| Step: 9
Training loss: 0.3192562460899353
Validation loss: 1.466654089830255

Epoch: 6| Step: 10
Training loss: 0.13856597244739532
Validation loss: 1.4632906093392322

Epoch: 6| Step: 11
Training loss: 0.29305994510650635
Validation loss: 1.455148204680412

Epoch: 6| Step: 12
Training loss: 0.16789460182189941
Validation loss: 1.4513695893749115

Epoch: 6| Step: 13
Training loss: 0.23183482885360718
Validation loss: 1.4826681267830633

Epoch: 392| Step: 0
Training loss: 0.19815436005592346
Validation loss: 1.470768238908501

Epoch: 6| Step: 1
Training loss: 0.2831784784793854
Validation loss: 1.477635411806004

Epoch: 6| Step: 2
Training loss: 0.21820931136608124
Validation loss: 1.4815112019097934

Epoch: 6| Step: 3
Training loss: 0.2979930341243744
Validation loss: 1.4708540234514462

Epoch: 6| Step: 4
Training loss: 0.1811893880367279
Validation loss: 1.5237893968500116

Epoch: 6| Step: 5
Training loss: 0.2735822796821594
Validation loss: 1.5283350136972242

Epoch: 6| Step: 6
Training loss: 0.18763291835784912
Validation loss: 1.4918928594999417

Epoch: 6| Step: 7
Training loss: 0.15022015571594238
Validation loss: 1.5184430838913046

Epoch: 6| Step: 8
Training loss: 0.3755495548248291
Validation loss: 1.5021615528291272

Epoch: 6| Step: 9
Training loss: 0.3011917769908905
Validation loss: 1.4909507869392313

Epoch: 6| Step: 10
Training loss: 0.3470097482204437
Validation loss: 1.478819921452512

Epoch: 6| Step: 11
Training loss: 0.1958608627319336
Validation loss: 1.484404787581454

Epoch: 6| Step: 12
Training loss: 0.6989169716835022
Validation loss: 1.4679130905417985

Epoch: 6| Step: 13
Training loss: 0.16714823246002197
Validation loss: 1.5070057402374923

Epoch: 393| Step: 0
Training loss: 0.48161858320236206
Validation loss: 1.5518103286784182

Epoch: 6| Step: 1
Training loss: 0.25373539328575134
Validation loss: 1.4921626314040153

Epoch: 6| Step: 2
Training loss: 0.1983683705329895
Validation loss: 1.4647886291626961

Epoch: 6| Step: 3
Training loss: 0.19211331009864807
Validation loss: 1.4792630467363583

Epoch: 6| Step: 4
Training loss: 0.1827864944934845
Validation loss: 1.4465431577415877

Epoch: 6| Step: 5
Training loss: 0.5366395711898804
Validation loss: 1.4667426616914812

Epoch: 6| Step: 6
Training loss: 0.14186236262321472
Validation loss: 1.4993627987882143

Epoch: 6| Step: 7
Training loss: 0.2763293385505676
Validation loss: 1.5022594774923017

Epoch: 6| Step: 8
Training loss: 0.313744455575943
Validation loss: 1.4742335664328707

Epoch: 6| Step: 9
Training loss: 0.17807191610336304
Validation loss: 1.5316171530754334

Epoch: 6| Step: 10
Training loss: 0.13983944058418274
Validation loss: 1.5639482249495804

Epoch: 6| Step: 11
Training loss: 0.47188177704811096
Validation loss: 1.5385356846676077

Epoch: 6| Step: 12
Training loss: 0.16610965132713318
Validation loss: 1.5494097317418745

Epoch: 6| Step: 13
Training loss: 0.1879395842552185
Validation loss: 1.5029388589243735

Epoch: 394| Step: 0
Training loss: 0.36768853664398193
Validation loss: 1.454981045056415

Epoch: 6| Step: 1
Training loss: 0.258109450340271
Validation loss: 1.498177593754184

Epoch: 6| Step: 2
Training loss: 0.13242065906524658
Validation loss: 1.4696808656056721

Epoch: 6| Step: 3
Training loss: 0.3674711287021637
Validation loss: 1.4880448054241877

Epoch: 6| Step: 4
Training loss: 0.27028322219848633
Validation loss: 1.4729410422745572

Epoch: 6| Step: 5
Training loss: 0.20144891738891602
Validation loss: 1.4464954227529547

Epoch: 6| Step: 6
Training loss: 0.15422949194908142
Validation loss: 1.4643660309494182

Epoch: 6| Step: 7
Training loss: 0.25634756684303284
Validation loss: 1.4870772336118965

Epoch: 6| Step: 8
Training loss: 0.23279866576194763
Validation loss: 1.4674803864571355

Epoch: 6| Step: 9
Training loss: 0.1452500820159912
Validation loss: 1.4728196564541067

Epoch: 6| Step: 10
Training loss: 0.37646907567977905
Validation loss: 1.5059865751574117

Epoch: 6| Step: 11
Training loss: 0.13143378496170044
Validation loss: 1.4999988758435814

Epoch: 6| Step: 12
Training loss: 0.3063396215438843
Validation loss: 1.5355377325447657

Epoch: 6| Step: 13
Training loss: 0.2966585159301758
Validation loss: 1.50866473297919

Epoch: 395| Step: 0
Training loss: 0.20540711283683777
Validation loss: 1.5409355067437696

Epoch: 6| Step: 1
Training loss: 0.15885215997695923
Validation loss: 1.5261752566983622

Epoch: 6| Step: 2
Training loss: 0.2963274121284485
Validation loss: 1.506622483653407

Epoch: 6| Step: 3
Training loss: 0.4378419518470764
Validation loss: 1.4933765972814252

Epoch: 6| Step: 4
Training loss: 0.22847148776054382
Validation loss: 1.5040010816307479

Epoch: 6| Step: 5
Training loss: 0.4895347058773041
Validation loss: 1.4820855176577004

Epoch: 6| Step: 6
Training loss: 0.23513878881931305
Validation loss: 1.4918533576432096

Epoch: 6| Step: 7
Training loss: 0.18258905410766602
Validation loss: 1.503982255535741

Epoch: 6| Step: 8
Training loss: 0.2717389762401581
Validation loss: 1.5047079029903616

Epoch: 6| Step: 9
Training loss: 0.17581357061862946
Validation loss: 1.501287168072116

Epoch: 6| Step: 10
Training loss: 0.20971855521202087
Validation loss: 1.5271642759282102

Epoch: 6| Step: 11
Training loss: 0.16781218349933624
Validation loss: 1.5458785987669421

Epoch: 6| Step: 12
Training loss: 0.25542882084846497
Validation loss: 1.5668349317325059

Epoch: 6| Step: 13
Training loss: 0.3016315996646881
Validation loss: 1.5412989636903167

Epoch: 396| Step: 0
Training loss: 0.15882684290409088
Validation loss: 1.5178340929810719

Epoch: 6| Step: 1
Training loss: 0.7311109900474548
Validation loss: 1.4925543108294088

Epoch: 6| Step: 2
Training loss: 0.18786653876304626
Validation loss: 1.4942297768849198

Epoch: 6| Step: 3
Training loss: 0.1913374960422516
Validation loss: 1.526129235503494

Epoch: 6| Step: 4
Training loss: 0.23696938157081604
Validation loss: 1.5005377043959915

Epoch: 6| Step: 5
Training loss: 0.15279333293437958
Validation loss: 1.4941658473783923

Epoch: 6| Step: 6
Training loss: 0.31941309571266174
Validation loss: 1.5264020466035413

Epoch: 6| Step: 7
Training loss: 0.23782777786254883
Validation loss: 1.5401527855985908

Epoch: 6| Step: 8
Training loss: 0.21140462160110474
Validation loss: 1.5573179106558523

Epoch: 6| Step: 9
Training loss: 0.35517585277557373
Validation loss: 1.5649066881466938

Epoch: 6| Step: 10
Training loss: 0.14484581351280212
Validation loss: 1.5307319420640186

Epoch: 6| Step: 11
Training loss: 0.30090707540512085
Validation loss: 1.5067989236565047

Epoch: 6| Step: 12
Training loss: 0.2737644910812378
Validation loss: 1.498995538680784

Epoch: 6| Step: 13
Training loss: 0.0955733209848404
Validation loss: 1.4860123588192848

Epoch: 397| Step: 0
Training loss: 0.1918223798274994
Validation loss: 1.4947332207874586

Epoch: 6| Step: 1
Training loss: 0.13368256390094757
Validation loss: 1.488584808124009

Epoch: 6| Step: 2
Training loss: 0.311869740486145
Validation loss: 1.4577697541124077

Epoch: 6| Step: 3
Training loss: 0.4149603247642517
Validation loss: 1.4728847959990143

Epoch: 6| Step: 4
Training loss: 0.24296388030052185
Validation loss: 1.438396143656905

Epoch: 6| Step: 5
Training loss: 0.4121103286743164
Validation loss: 1.443836614649783

Epoch: 6| Step: 6
Training loss: 0.22974808514118195
Validation loss: 1.4570287325048958

Epoch: 6| Step: 7
Training loss: 0.25921744108200073
Validation loss: 1.440199314907033

Epoch: 6| Step: 8
Training loss: 0.28971540927886963
Validation loss: 1.4299710553179505

Epoch: 6| Step: 9
Training loss: 0.17115019261837006
Validation loss: 1.4599351370206444

Epoch: 6| Step: 10
Training loss: 0.17802324891090393
Validation loss: 1.5124908698502408

Epoch: 6| Step: 11
Training loss: 0.1471347212791443
Validation loss: 1.5234926298100462

Epoch: 6| Step: 12
Training loss: 0.27370479702949524
Validation loss: 1.5562804911726265

Epoch: 6| Step: 13
Training loss: 0.6052396297454834
Validation loss: 1.5504693664530271

Epoch: 398| Step: 0
Training loss: 0.13824869692325592
Validation loss: 1.5413502698303552

Epoch: 6| Step: 1
Training loss: 0.1558995097875595
Validation loss: 1.5021267475620392

Epoch: 6| Step: 2
Training loss: 0.23094260692596436
Validation loss: 1.5465167337848293

Epoch: 6| Step: 3
Training loss: 0.4453922510147095
Validation loss: 1.5135043680026967

Epoch: 6| Step: 4
Training loss: 0.31593549251556396
Validation loss: 1.5508793079724876

Epoch: 6| Step: 5
Training loss: 0.29424864053726196
Validation loss: 1.5074427486747823

Epoch: 6| Step: 6
Training loss: 0.30434173345565796
Validation loss: 1.5354639945491668

Epoch: 6| Step: 7
Training loss: 0.5825334191322327
Validation loss: 1.5634729452030633

Epoch: 6| Step: 8
Training loss: 0.39055171608924866
Validation loss: 1.5730500951890023

Epoch: 6| Step: 9
Training loss: 0.2844153046607971
Validation loss: 1.5482199012592275

Epoch: 6| Step: 10
Training loss: 0.24331410229206085
Validation loss: 1.505304713403025

Epoch: 6| Step: 11
Training loss: 0.22628358006477356
Validation loss: 1.5138049689672326

Epoch: 6| Step: 12
Training loss: 0.15446677803993225
Validation loss: 1.534100829914052

Epoch: 6| Step: 13
Training loss: 0.20246458053588867
Validation loss: 1.5010275302394744

Epoch: 399| Step: 0
Training loss: 0.25150778889656067
Validation loss: 1.4799726393914991

Epoch: 6| Step: 1
Training loss: 0.19821487367153168
Validation loss: 1.4678060418816024

Epoch: 6| Step: 2
Training loss: 0.26891636848449707
Validation loss: 1.458818853542369

Epoch: 6| Step: 3
Training loss: 0.22444450855255127
Validation loss: 1.4674130729449693

Epoch: 6| Step: 4
Training loss: 0.2886931300163269
Validation loss: 1.4836409348313526

Epoch: 6| Step: 5
Training loss: 0.2762371301651001
Validation loss: 1.4796331960667846

Epoch: 6| Step: 6
Training loss: 0.18414416909217834
Validation loss: 1.4666542019895328

Epoch: 6| Step: 7
Training loss: 0.3339669108390808
Validation loss: 1.5426872789218862

Epoch: 6| Step: 8
Training loss: 0.4593963921070099
Validation loss: 1.557226880904167

Epoch: 6| Step: 9
Training loss: 0.262079119682312
Validation loss: 1.5292412555345924

Epoch: 6| Step: 10
Training loss: 0.22358189523220062
Validation loss: 1.5242095070500528

Epoch: 6| Step: 11
Training loss: 0.39052948355674744
Validation loss: 1.5042693807232765

Epoch: 6| Step: 12
Training loss: 0.21540376543998718
Validation loss: 1.4709203268892022

Epoch: 6| Step: 13
Training loss: 0.3003603518009186
Validation loss: 1.4478436528995473

Epoch: 400| Step: 0
Training loss: 0.3725491464138031
Validation loss: 1.42333355065315

Epoch: 6| Step: 1
Training loss: 0.2960626482963562
Validation loss: 1.4211472721510037

Epoch: 6| Step: 2
Training loss: 0.16084477305412292
Validation loss: 1.4388787310610536

Epoch: 6| Step: 3
Training loss: 0.16252845525741577
Validation loss: 1.4663175600831226

Epoch: 6| Step: 4
Training loss: 0.21356402337551117
Validation loss: 1.432461065630759

Epoch: 6| Step: 5
Training loss: 0.3896409869194031
Validation loss: 1.452447856626203

Epoch: 6| Step: 6
Training loss: 0.1632542759180069
Validation loss: 1.497099659776175

Epoch: 6| Step: 7
Training loss: 0.3437557816505432
Validation loss: 1.4922053429388231

Epoch: 6| Step: 8
Training loss: 0.36441880464553833
Validation loss: 1.5088732357948058

Epoch: 6| Step: 9
Training loss: 0.19016887247562408
Validation loss: 1.5030145260595507

Epoch: 6| Step: 10
Training loss: 0.22879983484745026
Validation loss: 1.5329585575288343

Epoch: 6| Step: 11
Training loss: 0.1938619315624237
Validation loss: 1.524477207532493

Epoch: 6| Step: 12
Training loss: 0.16438695788383484
Validation loss: 1.4809355351232714

Epoch: 6| Step: 13
Training loss: 0.24106107652187347
Validation loss: 1.465919078037303

Epoch: 401| Step: 0
Training loss: 0.27589738368988037
Validation loss: 1.4389510090633104

Epoch: 6| Step: 1
Training loss: 0.1707320511341095
Validation loss: 1.4526800981131933

Epoch: 6| Step: 2
Training loss: 0.22572708129882812
Validation loss: 1.4388305487171296

Epoch: 6| Step: 3
Training loss: 0.3940657079219818
Validation loss: 1.4404125367441485

Epoch: 6| Step: 4
Training loss: 0.25682175159454346
Validation loss: 1.4466489220178256

Epoch: 6| Step: 5
Training loss: 0.37239885330200195
Validation loss: 1.44640661439588

Epoch: 6| Step: 6
Training loss: 0.3746376037597656
Validation loss: 1.4532889909641717

Epoch: 6| Step: 7
Training loss: 0.24674242734909058
Validation loss: 1.4887721794907764

Epoch: 6| Step: 8
Training loss: 0.5517670512199402
Validation loss: 1.5402696183932725

Epoch: 6| Step: 9
Training loss: 0.216109961271286
Validation loss: 1.5880356078506799

Epoch: 6| Step: 10
Training loss: 0.21386189758777618
Validation loss: 1.5630895732551493

Epoch: 6| Step: 11
Training loss: 0.3004996180534363
Validation loss: 1.5134883016668341

Epoch: 6| Step: 12
Training loss: 0.23563678562641144
Validation loss: 1.5077083469719015

Epoch: 6| Step: 13
Training loss: 0.2721247971057892
Validation loss: 1.5026969845576952

Epoch: 402| Step: 0
Training loss: 0.2674146890640259
Validation loss: 1.5178824829798874

Epoch: 6| Step: 1
Training loss: 0.1219601109623909
Validation loss: 1.5285079043398622

Epoch: 6| Step: 2
Training loss: 0.27914416790008545
Validation loss: 1.5174537666382328

Epoch: 6| Step: 3
Training loss: 0.14079535007476807
Validation loss: 1.5006358892686906

Epoch: 6| Step: 4
Training loss: 0.37715864181518555
Validation loss: 1.5579537345517067

Epoch: 6| Step: 5
Training loss: 0.27719390392303467
Validation loss: 1.590585588127054

Epoch: 6| Step: 6
Training loss: 0.16983553767204285
Validation loss: 1.5976396734996507

Epoch: 6| Step: 7
Training loss: 0.170962393283844
Validation loss: 1.5621669510359406

Epoch: 6| Step: 8
Training loss: 0.18440157175064087
Validation loss: 1.558558335868261

Epoch: 6| Step: 9
Training loss: 0.4449835419654846
Validation loss: 1.5435709030397478

Epoch: 6| Step: 10
Training loss: 0.18099427223205566
Validation loss: 1.527671464027897

Epoch: 6| Step: 11
Training loss: 0.3769865036010742
Validation loss: 1.534794912543348

Epoch: 6| Step: 12
Training loss: 0.3916226029396057
Validation loss: 1.5186645292466687

Epoch: 6| Step: 13
Training loss: 0.24812552332878113
Validation loss: 1.4946926665562454

Epoch: 403| Step: 0
Training loss: 0.367044597864151
Validation loss: 1.4341948775834934

Epoch: 6| Step: 1
Training loss: 0.15988518297672272
Validation loss: 1.4432200770224295

Epoch: 6| Step: 2
Training loss: 0.26831531524658203
Validation loss: 1.4171460392654582

Epoch: 6| Step: 3
Training loss: 0.279615581035614
Validation loss: 1.4530442107108332

Epoch: 6| Step: 4
Training loss: 0.23976007103919983
Validation loss: 1.4608364951226018

Epoch: 6| Step: 5
Training loss: 0.2237006574869156
Validation loss: 1.4493805490514284

Epoch: 6| Step: 6
Training loss: 0.37035995721817017
Validation loss: 1.4680730527447117

Epoch: 6| Step: 7
Training loss: 0.1563887596130371
Validation loss: 1.5031633530893633

Epoch: 6| Step: 8
Training loss: 0.42379358410835266
Validation loss: 1.5053951701810282

Epoch: 6| Step: 9
Training loss: 0.25705140829086304
Validation loss: 1.5358375169897591

Epoch: 6| Step: 10
Training loss: 0.22357599437236786
Validation loss: 1.512573319096719

Epoch: 6| Step: 11
Training loss: 0.3114195466041565
Validation loss: 1.5402033405919229

Epoch: 6| Step: 12
Training loss: 0.1749284416437149
Validation loss: 1.4994643452346965

Epoch: 6| Step: 13
Training loss: 0.07033899426460266
Validation loss: 1.456319760250789

Epoch: 404| Step: 0
Training loss: 0.3227856457233429
Validation loss: 1.4653910180573821

Epoch: 6| Step: 1
Training loss: 0.21994781494140625
Validation loss: 1.4350088315625344

Epoch: 6| Step: 2
Training loss: 0.25853419303894043
Validation loss: 1.4377253158118135

Epoch: 6| Step: 3
Training loss: 0.27406325936317444
Validation loss: 1.4462168024432274

Epoch: 6| Step: 4
Training loss: 0.1970527470111847
Validation loss: 1.4466837990668513

Epoch: 6| Step: 5
Training loss: 0.4280845522880554
Validation loss: 1.4672650111618863

Epoch: 6| Step: 6
Training loss: 0.21893027424812317
Validation loss: 1.4942592997704782

Epoch: 6| Step: 7
Training loss: 0.15100084245204926
Validation loss: 1.5038331234326927

Epoch: 6| Step: 8
Training loss: 0.1386410892009735
Validation loss: 1.497879921749074

Epoch: 6| Step: 9
Training loss: 0.14831694960594177
Validation loss: 1.543670545342148

Epoch: 6| Step: 10
Training loss: 0.2220652997493744
Validation loss: 1.5242414743669572

Epoch: 6| Step: 11
Training loss: 0.4421430230140686
Validation loss: 1.5357194613384944

Epoch: 6| Step: 12
Training loss: 0.21555085480213165
Validation loss: 1.513416551774548

Epoch: 6| Step: 13
Training loss: 0.14494729042053223
Validation loss: 1.5362676125700756

Epoch: 405| Step: 0
Training loss: 0.2530306577682495
Validation loss: 1.4863831650826238

Epoch: 6| Step: 1
Training loss: 0.305669903755188
Validation loss: 1.502961331157274

Epoch: 6| Step: 2
Training loss: 0.3206275403499603
Validation loss: 1.4898907337137448

Epoch: 6| Step: 3
Training loss: 0.16295599937438965
Validation loss: 1.5123359913467078

Epoch: 6| Step: 4
Training loss: 0.5551304817199707
Validation loss: 1.510107910120359

Epoch: 6| Step: 5
Training loss: 0.10812298953533173
Validation loss: 1.5122288542409097

Epoch: 6| Step: 6
Training loss: 0.18295632302761078
Validation loss: 1.5263394463446833

Epoch: 6| Step: 7
Training loss: 0.25213897228240967
Validation loss: 1.5564121315556187

Epoch: 6| Step: 8
Training loss: 0.34244388341903687
Validation loss: 1.531144457478677

Epoch: 6| Step: 9
Training loss: 0.15202200412750244
Validation loss: 1.5256411401174401

Epoch: 6| Step: 10
Training loss: 0.18403759598731995
Validation loss: 1.5047641838750532

Epoch: 6| Step: 11
Training loss: 0.09222837537527084
Validation loss: 1.4837326003659157

Epoch: 6| Step: 12
Training loss: 0.32362329959869385
Validation loss: 1.4565032592383764

Epoch: 6| Step: 13
Training loss: 0.12628914415836334
Validation loss: 1.4283898504831458

Epoch: 406| Step: 0
Training loss: 0.13985106348991394
Validation loss: 1.4465033482479792

Epoch: 6| Step: 1
Training loss: 0.2868267893791199
Validation loss: 1.448114666887509

Epoch: 6| Step: 2
Training loss: 0.21609872579574585
Validation loss: 1.452319928394851

Epoch: 6| Step: 3
Training loss: 0.202759250998497
Validation loss: 1.4476852160628124

Epoch: 6| Step: 4
Training loss: 0.1463971734046936
Validation loss: 1.4675367211782804

Epoch: 6| Step: 5
Training loss: 0.18467360734939575
Validation loss: 1.4573456779603036

Epoch: 6| Step: 6
Training loss: 0.17412763833999634
Validation loss: 1.4619937237872873

Epoch: 6| Step: 7
Training loss: 0.18897506594657898
Validation loss: 1.429970177271033

Epoch: 6| Step: 8
Training loss: 0.2723115086555481
Validation loss: 1.5461529666377651

Epoch: 6| Step: 9
Training loss: 0.18439233303070068
Validation loss: 1.4979429155267694

Epoch: 6| Step: 10
Training loss: 0.39139747619628906
Validation loss: 1.5328382522829118

Epoch: 6| Step: 11
Training loss: 0.09527820348739624
Validation loss: 1.531453191593129

Epoch: 6| Step: 12
Training loss: 0.3463454246520996
Validation loss: 1.5182598085813626

Epoch: 6| Step: 13
Training loss: 0.21094340085983276
Validation loss: 1.4835157496954805

Epoch: 407| Step: 0
Training loss: 0.2418329268693924
Validation loss: 1.4402680371397285

Epoch: 6| Step: 1
Training loss: 0.12417131662368774
Validation loss: 1.4429862755601124

Epoch: 6| Step: 2
Training loss: 0.31102612614631653
Validation loss: 1.4538402634282266

Epoch: 6| Step: 3
Training loss: 0.3800998628139496
Validation loss: 1.454499836890928

Epoch: 6| Step: 4
Training loss: 0.3141677677631378
Validation loss: 1.402698879600853

Epoch: 6| Step: 5
Training loss: 0.3255447745323181
Validation loss: 1.4609962150614748

Epoch: 6| Step: 6
Training loss: 0.1567477285861969
Validation loss: 1.4923343530265234

Epoch: 6| Step: 7
Training loss: 0.4149697422981262
Validation loss: 1.5321101744969685

Epoch: 6| Step: 8
Training loss: 0.22487731277942657
Validation loss: 1.5960925676489388

Epoch: 6| Step: 9
Training loss: 0.152226984500885
Validation loss: 1.5959440085195726

Epoch: 6| Step: 10
Training loss: 0.23224462568759918
Validation loss: 1.585268437221486

Epoch: 6| Step: 11
Training loss: 0.20017015933990479
Validation loss: 1.5222965837806783

Epoch: 6| Step: 12
Training loss: 0.18180876970291138
Validation loss: 1.508192559724213

Epoch: 6| Step: 13
Training loss: 0.24680158495903015
Validation loss: 1.5220172264242684

Epoch: 408| Step: 0
Training loss: 0.4361695647239685
Validation loss: 1.501287651959286

Epoch: 6| Step: 1
Training loss: 0.35404491424560547
Validation loss: 1.5205706678411013

Epoch: 6| Step: 2
Training loss: 0.155130997300148
Validation loss: 1.5259753696380123

Epoch: 6| Step: 3
Training loss: 0.18318651616573334
Validation loss: 1.5190624985643613

Epoch: 6| Step: 4
Training loss: 0.10753224045038223
Validation loss: 1.4964226817571988

Epoch: 6| Step: 5
Training loss: 0.18750737607479095
Validation loss: 1.4939550443362164

Epoch: 6| Step: 6
Training loss: 0.2073453962802887
Validation loss: 1.5013500003404514

Epoch: 6| Step: 7
Training loss: 0.23107784986495972
Validation loss: 1.5040075009868992

Epoch: 6| Step: 8
Training loss: 0.22301343083381653
Validation loss: 1.6015633665105349

Epoch: 6| Step: 9
Training loss: 0.13164430856704712
Validation loss: 1.5518542284606605

Epoch: 6| Step: 10
Training loss: 0.20271071791648865
Validation loss: 1.5231234232584636

Epoch: 6| Step: 11
Training loss: 0.24596159160137177
Validation loss: 1.478358345647012

Epoch: 6| Step: 12
Training loss: 0.21163475513458252
Validation loss: 1.4449038902918498

Epoch: 6| Step: 13
Training loss: 0.742285966873169
Validation loss: 1.4378988025008992

Epoch: 409| Step: 0
Training loss: 0.10237298905849457
Validation loss: 1.4107572109468522

Epoch: 6| Step: 1
Training loss: 0.26410624384880066
Validation loss: 1.416881070342115

Epoch: 6| Step: 2
Training loss: 0.12592917680740356
Validation loss: 1.4477806860400784

Epoch: 6| Step: 3
Training loss: 0.4336084723472595
Validation loss: 1.4704668291153447

Epoch: 6| Step: 4
Training loss: 0.13987299799919128
Validation loss: 1.4895064587234168

Epoch: 6| Step: 5
Training loss: 0.3387437164783478
Validation loss: 1.535217296692633

Epoch: 6| Step: 6
Training loss: 0.13835042715072632
Validation loss: 1.4564869032111218

Epoch: 6| Step: 7
Training loss: 0.09987284243106842
Validation loss: 1.4608807474054315

Epoch: 6| Step: 8
Training loss: 0.2495318055152893
Validation loss: 1.479996072348728

Epoch: 6| Step: 9
Training loss: 0.24353815615177155
Validation loss: 1.4786860622385496

Epoch: 6| Step: 10
Training loss: 0.12749068439006805
Validation loss: 1.4750788570732198

Epoch: 6| Step: 11
Training loss: 0.33637022972106934
Validation loss: 1.4769339458916777

Epoch: 6| Step: 12
Training loss: 0.2786668539047241
Validation loss: 1.4675011327189784

Epoch: 6| Step: 13
Training loss: 0.269220232963562
Validation loss: 1.4762527609384188

Epoch: 410| Step: 0
Training loss: 0.25002527236938477
Validation loss: 1.4681877448994627

Epoch: 6| Step: 1
Training loss: 0.18908506631851196
Validation loss: 1.4870232215491674

Epoch: 6| Step: 2
Training loss: 0.13439063727855682
Validation loss: 1.4799104467515023

Epoch: 6| Step: 3
Training loss: 0.35537976026535034
Validation loss: 1.4804835524610294

Epoch: 6| Step: 4
Training loss: 0.13666225969791412
Validation loss: 1.492321983460457

Epoch: 6| Step: 5
Training loss: 0.18862789869308472
Validation loss: 1.5072496514166556

Epoch: 6| Step: 6
Training loss: 0.24540908634662628
Validation loss: 1.5174008389954925

Epoch: 6| Step: 7
Training loss: 0.19723820686340332
Validation loss: 1.487174883965523

Epoch: 6| Step: 8
Training loss: 0.2939457893371582
Validation loss: 1.4829649579140447

Epoch: 6| Step: 9
Training loss: 0.19149407744407654
Validation loss: 1.4566665003376622

Epoch: 6| Step: 10
Training loss: 0.30120849609375
Validation loss: 1.4416812645491732

Epoch: 6| Step: 11
Training loss: 0.08829056471586227
Validation loss: 1.4253083172664847

Epoch: 6| Step: 12
Training loss: 0.25972750782966614
Validation loss: 1.409900535819351

Epoch: 6| Step: 13
Training loss: 0.5913309454917908
Validation loss: 1.4381771164555703

Epoch: 411| Step: 0
Training loss: 0.27541521191596985
Validation loss: 1.4190030059506815

Epoch: 6| Step: 1
Training loss: 0.14157569408416748
Validation loss: 1.437794852641321

Epoch: 6| Step: 2
Training loss: 0.4340364336967468
Validation loss: 1.458801172112906

Epoch: 6| Step: 3
Training loss: 0.23520684242248535
Validation loss: 1.5156530186694155

Epoch: 6| Step: 4
Training loss: 0.1863706111907959
Validation loss: 1.5067346967676634

Epoch: 6| Step: 5
Training loss: 0.5245398879051208
Validation loss: 1.5476425796426752

Epoch: 6| Step: 6
Training loss: 0.07277560234069824
Validation loss: 1.5090812137050014

Epoch: 6| Step: 7
Training loss: 0.22223253548145294
Validation loss: 1.462580632137996

Epoch: 6| Step: 8
Training loss: 0.25966769456863403
Validation loss: 1.4743699232737224

Epoch: 6| Step: 9
Training loss: 0.11608031392097473
Validation loss: 1.417589802895823

Epoch: 6| Step: 10
Training loss: 0.21212893724441528
Validation loss: 1.3915792716446744

Epoch: 6| Step: 11
Training loss: 0.1882142424583435
Validation loss: 1.4138279377773244

Epoch: 6| Step: 12
Training loss: 0.22147905826568604
Validation loss: 1.4219881257703226

Epoch: 6| Step: 13
Training loss: 0.19153572618961334
Validation loss: 1.4157662712117678

Epoch: 412| Step: 0
Training loss: 0.4271795153617859
Validation loss: 1.4328079544087893

Epoch: 6| Step: 1
Training loss: 0.2782534956932068
Validation loss: 1.4739910799969909

Epoch: 6| Step: 2
Training loss: 0.3072105050086975
Validation loss: 1.5060995906911872

Epoch: 6| Step: 3
Training loss: 0.351108193397522
Validation loss: 1.5477541697922574

Epoch: 6| Step: 4
Training loss: 0.2719784379005432
Validation loss: 1.567569512192921

Epoch: 6| Step: 5
Training loss: 0.44612157344818115
Validation loss: 1.5778868236849386

Epoch: 6| Step: 6
Training loss: 0.2607172131538391
Validation loss: 1.5955423373048023

Epoch: 6| Step: 7
Training loss: 0.18682560324668884
Validation loss: 1.5367416630509079

Epoch: 6| Step: 8
Training loss: 0.11810123175382614
Validation loss: 1.545085278890466

Epoch: 6| Step: 9
Training loss: 0.15734858810901642
Validation loss: 1.501101715590364

Epoch: 6| Step: 10
Training loss: 0.27850914001464844
Validation loss: 1.4833391020374913

Epoch: 6| Step: 11
Training loss: 0.29884353280067444
Validation loss: 1.469186911018946

Epoch: 6| Step: 12
Training loss: 0.23642048239707947
Validation loss: 1.4797099867174703

Epoch: 6| Step: 13
Training loss: 0.1917039006948471
Validation loss: 1.491732680669395

Epoch: 413| Step: 0
Training loss: 0.32055872678756714
Validation loss: 1.50179426388074

Epoch: 6| Step: 1
Training loss: 0.3225345313549042
Validation loss: 1.5164364666067145

Epoch: 6| Step: 2
Training loss: 0.24082426726818085
Validation loss: 1.487939775630992

Epoch: 6| Step: 3
Training loss: 0.44164085388183594
Validation loss: 1.4993228989262735

Epoch: 6| Step: 4
Training loss: 0.18828555941581726
Validation loss: 1.5003648175988147

Epoch: 6| Step: 5
Training loss: 0.25268930196762085
Validation loss: 1.49434313466472

Epoch: 6| Step: 6
Training loss: 0.16172270476818085
Validation loss: 1.4472150315520584

Epoch: 6| Step: 7
Training loss: 0.32054346799850464
Validation loss: 1.4449796702272149

Epoch: 6| Step: 8
Training loss: 0.2189251035451889
Validation loss: 1.4304082970465384

Epoch: 6| Step: 9
Training loss: 0.2438877522945404
Validation loss: 1.4570771622401413

Epoch: 6| Step: 10
Training loss: 0.09096808731555939
Validation loss: 1.4387013014926706

Epoch: 6| Step: 11
Training loss: 0.07447575032711029
Validation loss: 1.4716808847201768

Epoch: 6| Step: 12
Training loss: 0.1981232911348343
Validation loss: 1.4757651859714138

Epoch: 6| Step: 13
Training loss: 0.13257385790348053
Validation loss: 1.4963938408000494

Epoch: 414| Step: 0
Training loss: 0.24438825249671936
Validation loss: 1.4973016759400726

Epoch: 6| Step: 1
Training loss: 0.2092810869216919
Validation loss: 1.522921835222552

Epoch: 6| Step: 2
Training loss: 0.2408290058374405
Validation loss: 1.5305485533129783

Epoch: 6| Step: 3
Training loss: 0.21427790820598602
Validation loss: 1.554649833709963

Epoch: 6| Step: 4
Training loss: 0.14872892200946808
Validation loss: 1.5831278126726869

Epoch: 6| Step: 5
Training loss: 0.4611777663230896
Validation loss: 1.5695893264585925

Epoch: 6| Step: 6
Training loss: 0.23198068141937256
Validation loss: 1.5762842291144914

Epoch: 6| Step: 7
Training loss: 0.4757579565048218
Validation loss: 1.6256511852305422

Epoch: 6| Step: 8
Training loss: 0.2468770444393158
Validation loss: 1.5946252346038818

Epoch: 6| Step: 9
Training loss: 0.19370849430561066
Validation loss: 1.5164110763098604

Epoch: 6| Step: 10
Training loss: 0.24219241738319397
Validation loss: 1.4713715660956599

Epoch: 6| Step: 11
Training loss: 0.22594282031059265
Validation loss: 1.4365200919489707

Epoch: 6| Step: 12
Training loss: 0.12502428889274597
Validation loss: 1.4341621398925781

Epoch: 6| Step: 13
Training loss: 0.11540227383375168
Validation loss: 1.3959858032964891

Epoch: 415| Step: 0
Training loss: 0.5004543662071228
Validation loss: 1.4058178496617142

Epoch: 6| Step: 1
Training loss: 0.27742886543273926
Validation loss: 1.3941399910116707

Epoch: 6| Step: 2
Training loss: 0.1830107867717743
Validation loss: 1.4094410910401294

Epoch: 6| Step: 3
Training loss: 0.11968338489532471
Validation loss: 1.4063741737796414

Epoch: 6| Step: 4
Training loss: 0.19588471949100494
Validation loss: 1.4262595253605996

Epoch: 6| Step: 5
Training loss: 0.2695772647857666
Validation loss: 1.4533481162081483

Epoch: 6| Step: 6
Training loss: 0.22668394446372986
Validation loss: 1.451230202951739

Epoch: 6| Step: 7
Training loss: 0.40017107129096985
Validation loss: 1.431954768396193

Epoch: 6| Step: 8
Training loss: 0.3216542601585388
Validation loss: 1.4237965076200423

Epoch: 6| Step: 9
Training loss: 0.340202271938324
Validation loss: 1.3999134007320608

Epoch: 6| Step: 10
Training loss: 0.20600321888923645
Validation loss: 1.414778470993042

Epoch: 6| Step: 11
Training loss: 0.20886865258216858
Validation loss: 1.4089110384705246

Epoch: 6| Step: 12
Training loss: 0.1845410317182541
Validation loss: 1.406983926732053

Epoch: 6| Step: 13
Training loss: 0.20675179362297058
Validation loss: 1.41892590830403

Epoch: 416| Step: 0
Training loss: 0.1303257942199707
Validation loss: 1.4118198194811422

Epoch: 6| Step: 1
Training loss: 0.1092236116528511
Validation loss: 1.45089203311551

Epoch: 6| Step: 2
Training loss: 0.11335694789886475
Validation loss: 1.4413751966209822

Epoch: 6| Step: 3
Training loss: 0.30110907554626465
Validation loss: 1.424673867482011

Epoch: 6| Step: 4
Training loss: 0.4626142084598541
Validation loss: 1.397800140483405

Epoch: 6| Step: 5
Training loss: 0.17455218732357025
Validation loss: 1.3965432477253739

Epoch: 6| Step: 6
Training loss: 0.21829795837402344
Validation loss: 1.3770281819887058

Epoch: 6| Step: 7
Training loss: 0.1654318869113922
Validation loss: 1.3813030630029657

Epoch: 6| Step: 8
Training loss: 0.14821898937225342
Validation loss: 1.376416617183275

Epoch: 6| Step: 9
Training loss: 0.14632666110992432
Validation loss: 1.3859758812894103

Epoch: 6| Step: 10
Training loss: 0.260723352432251
Validation loss: 1.4031151545945035

Epoch: 6| Step: 11
Training loss: 0.17900241911411285
Validation loss: 1.407517021702182

Epoch: 6| Step: 12
Training loss: 0.29695817828178406
Validation loss: 1.4270938532326811

Epoch: 6| Step: 13
Training loss: 0.21139518916606903
Validation loss: 1.4894800596339728

Epoch: 417| Step: 0
Training loss: 0.22926633059978485
Validation loss: 1.5156585183194888

Epoch: 6| Step: 1
Training loss: 0.38738131523132324
Validation loss: 1.5474925259108185

Epoch: 6| Step: 2
Training loss: 0.200624018907547
Validation loss: 1.51515955181532

Epoch: 6| Step: 3
Training loss: 0.2866078019142151
Validation loss: 1.4903506220027964

Epoch: 6| Step: 4
Training loss: 0.23772385716438293
Validation loss: 1.4664345069598126

Epoch: 6| Step: 5
Training loss: 0.3293265104293823
Validation loss: 1.4500114956209738

Epoch: 6| Step: 6
Training loss: 0.2245517373085022
Validation loss: 1.420321854211951

Epoch: 6| Step: 7
Training loss: 0.17780223488807678
Validation loss: 1.4341043490235523

Epoch: 6| Step: 8
Training loss: 0.22901394963264465
Validation loss: 1.4206780381100153

Epoch: 6| Step: 9
Training loss: 0.24461422860622406
Validation loss: 1.4177938866358932

Epoch: 6| Step: 10
Training loss: 0.17461320757865906
Validation loss: 1.42610369190093

Epoch: 6| Step: 11
Training loss: 0.30810272693634033
Validation loss: 1.496611447744472

Epoch: 6| Step: 12
Training loss: 0.1518484652042389
Validation loss: 1.5593311953288254

Epoch: 6| Step: 13
Training loss: 0.23157858848571777
Validation loss: 1.579411357961675

Epoch: 418| Step: 0
Training loss: 0.1761195957660675
Validation loss: 1.5496636757286646

Epoch: 6| Step: 1
Training loss: 0.1862613409757614
Validation loss: 1.4909596058630175

Epoch: 6| Step: 2
Training loss: 0.2538069486618042
Validation loss: 1.511303464571635

Epoch: 6| Step: 3
Training loss: 0.17807257175445557
Validation loss: 1.4831805818824357

Epoch: 6| Step: 4
Training loss: 0.24566829204559326
Validation loss: 1.4790593321605394

Epoch: 6| Step: 5
Training loss: 0.12913626432418823
Validation loss: 1.4495252152924896

Epoch: 6| Step: 6
Training loss: 0.16723713278770447
Validation loss: 1.437738795434275

Epoch: 6| Step: 7
Training loss: 0.19355250895023346
Validation loss: 1.4701411544635732

Epoch: 6| Step: 8
Training loss: 0.6142539381980896
Validation loss: 1.4614786768472323

Epoch: 6| Step: 9
Training loss: 0.20805492997169495
Validation loss: 1.4555290847696283

Epoch: 6| Step: 10
Training loss: 0.35882118344306946
Validation loss: 1.4690726264830558

Epoch: 6| Step: 11
Training loss: 0.16375994682312012
Validation loss: 1.5267774328108756

Epoch: 6| Step: 12
Training loss: 0.3620050251483917
Validation loss: 1.5337835454171704

Epoch: 6| Step: 13
Training loss: 0.11448539793491364
Validation loss: 1.5162000797128166

Epoch: 419| Step: 0
Training loss: 0.1482730209827423
Validation loss: 1.4609389651206233

Epoch: 6| Step: 1
Training loss: 0.18723660707473755
Validation loss: 1.4481155968481494

Epoch: 6| Step: 2
Training loss: 0.1901804506778717
Validation loss: 1.4560705205445648

Epoch: 6| Step: 3
Training loss: 0.2792339026927948
Validation loss: 1.4670492064568303

Epoch: 6| Step: 4
Training loss: 0.3067457377910614
Validation loss: 1.493023012274055

Epoch: 6| Step: 5
Training loss: 0.40213826298713684
Validation loss: 1.4928495980078174

Epoch: 6| Step: 6
Training loss: 0.3716851472854614
Validation loss: 1.4750736913373392

Epoch: 6| Step: 7
Training loss: 0.31378310918807983
Validation loss: 1.4660346405480498

Epoch: 6| Step: 8
Training loss: 0.16254550218582153
Validation loss: 1.4803645713354951

Epoch: 6| Step: 9
Training loss: 0.32543936371803284
Validation loss: 1.5131904822523876

Epoch: 6| Step: 10
Training loss: 0.22296196222305298
Validation loss: 1.5630329437153314

Epoch: 6| Step: 11
Training loss: 0.15560543537139893
Validation loss: 1.5422014139031852

Epoch: 6| Step: 12
Training loss: 0.2738993167877197
Validation loss: 1.5669053998044742

Epoch: 6| Step: 13
Training loss: 0.28405773639678955
Validation loss: 1.5044256307745492

Epoch: 420| Step: 0
Training loss: 0.16598857939243317
Validation loss: 1.483742699828199

Epoch: 6| Step: 1
Training loss: 0.21599681675434113
Validation loss: 1.4470975091380458

Epoch: 6| Step: 2
Training loss: 0.15179333090782166
Validation loss: 1.4543651009118685

Epoch: 6| Step: 3
Training loss: 0.15697157382965088
Validation loss: 1.461504332480892

Epoch: 6| Step: 4
Training loss: 0.3055611550807953
Validation loss: 1.4372246816594114

Epoch: 6| Step: 5
Training loss: 0.2653581202030182
Validation loss: 1.418724388204595

Epoch: 6| Step: 6
Training loss: 0.2444934844970703
Validation loss: 1.4190151973437237

Epoch: 6| Step: 7
Training loss: 0.20878049731254578
Validation loss: 1.4495488917955788

Epoch: 6| Step: 8
Training loss: 0.20293521881103516
Validation loss: 1.4329170898724628

Epoch: 6| Step: 9
Training loss: 0.1912824511528015
Validation loss: 1.445292475402996

Epoch: 6| Step: 10
Training loss: 0.3856845498085022
Validation loss: 1.421761638374739

Epoch: 6| Step: 11
Training loss: 0.09091722965240479
Validation loss: 1.438943124586536

Epoch: 6| Step: 12
Training loss: 0.5315132141113281
Validation loss: 1.4155118670514835

Epoch: 6| Step: 13
Training loss: 0.12358522415161133
Validation loss: 1.3990283627663889

Epoch: 421| Step: 0
Training loss: 0.16491298377513885
Validation loss: 1.3588667467076292

Epoch: 6| Step: 1
Training loss: 0.21677231788635254
Validation loss: 1.369722608597048

Epoch: 6| Step: 2
Training loss: 0.19707125425338745
Validation loss: 1.4033755076828824

Epoch: 6| Step: 3
Training loss: 0.3321321904659271
Validation loss: 1.3687807065184399

Epoch: 6| Step: 4
Training loss: 0.231085866689682
Validation loss: 1.379123576225773

Epoch: 6| Step: 5
Training loss: 0.3578656315803528
Validation loss: 1.3913757993328957

Epoch: 6| Step: 6
Training loss: 0.13944581151008606
Validation loss: 1.3711756326818978

Epoch: 6| Step: 7
Training loss: 0.20546039938926697
Validation loss: 1.3842930338715995

Epoch: 6| Step: 8
Training loss: 0.14845600724220276
Validation loss: 1.4764229802675144

Epoch: 6| Step: 9
Training loss: 0.280643105506897
Validation loss: 1.5773240712381178

Epoch: 6| Step: 10
Training loss: 0.4867543578147888
Validation loss: 1.6134011886453117

Epoch: 6| Step: 11
Training loss: 0.40280795097351074
Validation loss: 1.5906539476045998

Epoch: 6| Step: 12
Training loss: 0.31455889344215393
Validation loss: 1.518258289624286

Epoch: 6| Step: 13
Training loss: 0.2185247391462326
Validation loss: 1.506945006309017

Epoch: 422| Step: 0
Training loss: 0.19426265358924866
Validation loss: 1.5434891100852721

Epoch: 6| Step: 1
Training loss: 0.26469045877456665
Validation loss: 1.5421046774874452

Epoch: 6| Step: 2
Training loss: 0.2064974457025528
Validation loss: 1.5409971014145882

Epoch: 6| Step: 3
Training loss: 0.41667822003364563
Validation loss: 1.5233979225158691

Epoch: 6| Step: 4
Training loss: 0.20315730571746826
Validation loss: 1.5269187727282125

Epoch: 6| Step: 5
Training loss: 0.15428954362869263
Validation loss: 1.5348497180528538

Epoch: 6| Step: 6
Training loss: 0.14805150032043457
Validation loss: 1.551147630137782

Epoch: 6| Step: 7
Training loss: 0.21322277188301086
Validation loss: 1.565792343949759

Epoch: 6| Step: 8
Training loss: 0.19526061415672302
Validation loss: 1.5896904083990282

Epoch: 6| Step: 9
Training loss: 0.37229517102241516
Validation loss: 1.560849364085864

Epoch: 6| Step: 10
Training loss: 0.2000730335712433
Validation loss: 1.5580709480470227

Epoch: 6| Step: 11
Training loss: 0.2979286015033722
Validation loss: 1.579317085204586

Epoch: 6| Step: 12
Training loss: 0.18223220109939575
Validation loss: 1.570350867445751

Epoch: 6| Step: 13
Training loss: 0.4328753352165222
Validation loss: 1.51324495192497

Epoch: 423| Step: 0
Training loss: 0.1912274956703186
Validation loss: 1.5045458706476356

Epoch: 6| Step: 1
Training loss: 0.3199213147163391
Validation loss: 1.5151950620835828

Epoch: 6| Step: 2
Training loss: 0.15069764852523804
Validation loss: 1.5080552383135724

Epoch: 6| Step: 3
Training loss: 0.28842902183532715
Validation loss: 1.531628744576567

Epoch: 6| Step: 4
Training loss: 0.3468155264854431
Validation loss: 1.5134274472472489

Epoch: 6| Step: 5
Training loss: 0.4731586277484894
Validation loss: 1.539988745925247

Epoch: 6| Step: 6
Training loss: 0.38235539197921753
Validation loss: 1.522494795501873

Epoch: 6| Step: 7
Training loss: 0.24746565520763397
Validation loss: 1.5151270563884447

Epoch: 6| Step: 8
Training loss: 0.2686808109283447
Validation loss: 1.5322270957372521

Epoch: 6| Step: 9
Training loss: 0.20933371782302856
Validation loss: 1.5144472801557152

Epoch: 6| Step: 10
Training loss: 0.33014512062072754
Validation loss: 1.4938608933520574

Epoch: 6| Step: 11
Training loss: 0.13140681385993958
Validation loss: 1.4997412158596901

Epoch: 6| Step: 12
Training loss: 0.1791898012161255
Validation loss: 1.4644320921231342

Epoch: 6| Step: 13
Training loss: 0.15331000089645386
Validation loss: 1.4502756390520322

Epoch: 424| Step: 0
Training loss: 0.27806901931762695
Validation loss: 1.4110406368009505

Epoch: 6| Step: 1
Training loss: 0.19790536165237427
Validation loss: 1.4538469673484884

Epoch: 6| Step: 2
Training loss: 0.3326677083969116
Validation loss: 1.4314910147779731

Epoch: 6| Step: 3
Training loss: 0.16694535315036774
Validation loss: 1.4291338356592322

Epoch: 6| Step: 4
Training loss: 0.2738267183303833
Validation loss: 1.4276663680230417

Epoch: 6| Step: 5
Training loss: 0.4037536084651947
Validation loss: 1.4652674672424153

Epoch: 6| Step: 6
Training loss: 0.20183292031288147
Validation loss: 1.5057187811020882

Epoch: 6| Step: 7
Training loss: 0.30173826217651367
Validation loss: 1.5535457300883468

Epoch: 6| Step: 8
Training loss: 0.3120519518852234
Validation loss: 1.611668735422114

Epoch: 6| Step: 9
Training loss: 0.13450320065021515
Validation loss: 1.5817134944341515

Epoch: 6| Step: 10
Training loss: 0.11892084777355194
Validation loss: 1.5497737007756387

Epoch: 6| Step: 11
Training loss: 0.26251620054244995
Validation loss: 1.516144416024608

Epoch: 6| Step: 12
Training loss: 0.11088784784078598
Validation loss: 1.4913430662565335

Epoch: 6| Step: 13
Training loss: 0.1299455165863037
Validation loss: 1.5060159749882196

Epoch: 425| Step: 0
Training loss: 0.20475918054580688
Validation loss: 1.50136229812458

Epoch: 6| Step: 1
Training loss: 0.17366990447044373
Validation loss: 1.5087164448153587

Epoch: 6| Step: 2
Training loss: 0.26148664951324463
Validation loss: 1.4746607734311012

Epoch: 6| Step: 3
Training loss: 0.1395052820444107
Validation loss: 1.4788351969052387

Epoch: 6| Step: 4
Training loss: 0.3571183383464813
Validation loss: 1.438157417440927

Epoch: 6| Step: 5
Training loss: 0.14373141527175903
Validation loss: 1.4658099515463716

Epoch: 6| Step: 6
Training loss: 0.24841684103012085
Validation loss: 1.4593368678964593

Epoch: 6| Step: 7
Training loss: 0.1873941719532013
Validation loss: 1.5084931632523895

Epoch: 6| Step: 8
Training loss: 0.19990134239196777
Validation loss: 1.5239962954674997

Epoch: 6| Step: 9
Training loss: 0.13587267696857452
Validation loss: 1.5261158045902048

Epoch: 6| Step: 10
Training loss: 0.32182103395462036
Validation loss: 1.466760999412947

Epoch: 6| Step: 11
Training loss: 0.26953965425491333
Validation loss: 1.4876260552355038

Epoch: 6| Step: 12
Training loss: 0.1891404539346695
Validation loss: 1.499248355947515

Epoch: 6| Step: 13
Training loss: 0.21826688945293427
Validation loss: 1.460673503978278

Epoch: 426| Step: 0
Training loss: 0.14878857135772705
Validation loss: 1.4794342722944034

Epoch: 6| Step: 1
Training loss: 0.1916041523218155
Validation loss: 1.4900496775104153

Epoch: 6| Step: 2
Training loss: 0.07680387794971466
Validation loss: 1.4564946902695524

Epoch: 6| Step: 3
Training loss: 0.11302224546670914
Validation loss: 1.5126631106099775

Epoch: 6| Step: 4
Training loss: 0.25566232204437256
Validation loss: 1.4977121327513008

Epoch: 6| Step: 5
Training loss: 0.18983083963394165
Validation loss: 1.5119425199365104

Epoch: 6| Step: 6
Training loss: 0.20239832997322083
Validation loss: 1.5221552951361543

Epoch: 6| Step: 7
Training loss: 0.44870901107788086
Validation loss: 1.5117079698911278

Epoch: 6| Step: 8
Training loss: 0.231070876121521
Validation loss: 1.5159543547579037

Epoch: 6| Step: 9
Training loss: 0.16741731762886047
Validation loss: 1.4837200692904893

Epoch: 6| Step: 10
Training loss: 0.12351708859205246
Validation loss: 1.4799060154986639

Epoch: 6| Step: 11
Training loss: 0.2210312932729721
Validation loss: 1.453202365547098

Epoch: 6| Step: 12
Training loss: 0.14133833348751068
Validation loss: 1.4275581887973252

Epoch: 6| Step: 13
Training loss: 0.20643852651119232
Validation loss: 1.4423054854075115

Epoch: 427| Step: 0
Training loss: 0.1989329755306244
Validation loss: 1.4433290971222745

Epoch: 6| Step: 1
Training loss: 0.3187412619590759
Validation loss: 1.4318503077312181

Epoch: 6| Step: 2
Training loss: 0.20671474933624268
Validation loss: 1.4335772907862099

Epoch: 6| Step: 3
Training loss: 0.15980881452560425
Validation loss: 1.4539185647041566

Epoch: 6| Step: 4
Training loss: 0.3679344058036804
Validation loss: 1.4403532102543821

Epoch: 6| Step: 5
Training loss: 0.3597267270088196
Validation loss: 1.458871950385391

Epoch: 6| Step: 6
Training loss: 0.16123081743717194
Validation loss: 1.475771035558434

Epoch: 6| Step: 7
Training loss: 0.11427997052669525
Validation loss: 1.4971654120311941

Epoch: 6| Step: 8
Training loss: 0.16020552814006805
Validation loss: 1.5063572596478205

Epoch: 6| Step: 9
Training loss: 0.16447846591472626
Validation loss: 1.5127689043680828

Epoch: 6| Step: 10
Training loss: 0.11136411875486374
Validation loss: 1.463124272643879

Epoch: 6| Step: 11
Training loss: 0.18828870356082916
Validation loss: 1.4646930028033514

Epoch: 6| Step: 12
Training loss: 0.1403515487909317
Validation loss: 1.5059907628643898

Epoch: 6| Step: 13
Training loss: 0.22138731181621552
Validation loss: 1.4565883490347094

Epoch: 428| Step: 0
Training loss: 0.19634096324443817
Validation loss: 1.5074181889974942

Epoch: 6| Step: 1
Training loss: 0.25315213203430176
Validation loss: 1.4833176571835753

Epoch: 6| Step: 2
Training loss: 0.26164326071739197
Validation loss: 1.495255579230606

Epoch: 6| Step: 3
Training loss: 0.11594372987747192
Validation loss: 1.4961732472142866

Epoch: 6| Step: 4
Training loss: 0.2778913676738739
Validation loss: 1.523152167438179

Epoch: 6| Step: 5
Training loss: 0.18097595870494843
Validation loss: 1.5697323840151551

Epoch: 6| Step: 6
Training loss: 0.3858603835105896
Validation loss: 1.604560379059084

Epoch: 6| Step: 7
Training loss: 0.3044748902320862
Validation loss: 1.6008832518772413

Epoch: 6| Step: 8
Training loss: 0.111728735268116
Validation loss: 1.5219465340337446

Epoch: 6| Step: 9
Training loss: 0.17331060767173767
Validation loss: 1.477123684780572

Epoch: 6| Step: 10
Training loss: 0.26085686683654785
Validation loss: 1.5118836126019877

Epoch: 6| Step: 11
Training loss: 0.19838117063045502
Validation loss: 1.5019443727308703

Epoch: 6| Step: 12
Training loss: 0.27632224559783936
Validation loss: 1.4634653406758462

Epoch: 6| Step: 13
Training loss: 0.29121318459510803
Validation loss: 1.4693363789589173

Epoch: 429| Step: 0
Training loss: 0.11394023895263672
Validation loss: 1.422086376015858

Epoch: 6| Step: 1
Training loss: 0.16841283440589905
Validation loss: 1.423059521182891

Epoch: 6| Step: 2
Training loss: 0.09970615059137344
Validation loss: 1.3896422181078183

Epoch: 6| Step: 3
Training loss: 0.15005525946617126
Validation loss: 1.4172725690308439

Epoch: 6| Step: 4
Training loss: 0.3547065258026123
Validation loss: 1.4099409682776338

Epoch: 6| Step: 5
Training loss: 0.15367388725280762
Validation loss: 1.4269501227204517

Epoch: 6| Step: 6
Training loss: 0.4075205326080322
Validation loss: 1.4467353538800312

Epoch: 6| Step: 7
Training loss: 0.12387113273143768
Validation loss: 1.4555536598287604

Epoch: 6| Step: 8
Training loss: 0.12519937753677368
Validation loss: 1.4668591060946066

Epoch: 6| Step: 9
Training loss: 0.2625201344490051
Validation loss: 1.4536425336714713

Epoch: 6| Step: 10
Training loss: 0.12953978776931763
Validation loss: 1.4262593689785208

Epoch: 6| Step: 11
Training loss: 0.19310438632965088
Validation loss: 1.485804097626799

Epoch: 6| Step: 12
Training loss: 0.2705255150794983
Validation loss: 1.4683153770303214

Epoch: 6| Step: 13
Training loss: 0.41339030861854553
Validation loss: 1.4542933420468402

Epoch: 430| Step: 0
Training loss: 0.1418253779411316
Validation loss: 1.4519256596924157

Epoch: 6| Step: 1
Training loss: 0.18843692541122437
Validation loss: 1.4908864844229914

Epoch: 6| Step: 2
Training loss: 0.10970401018857956
Validation loss: 1.4896613884997625

Epoch: 6| Step: 3
Training loss: 0.36923032999038696
Validation loss: 1.4938174338750942

Epoch: 6| Step: 4
Training loss: 0.1981590986251831
Validation loss: 1.4925350476336736

Epoch: 6| Step: 5
Training loss: 0.24682694673538208
Validation loss: 1.482976410978584

Epoch: 6| Step: 6
Training loss: 0.1763327419757843
Validation loss: 1.5050446256514518

Epoch: 6| Step: 7
Training loss: 0.0866851806640625
Validation loss: 1.475440853385515

Epoch: 6| Step: 8
Training loss: 0.29431354999542236
Validation loss: 1.501555271046136

Epoch: 6| Step: 9
Training loss: 0.20259599387645721
Validation loss: 1.5355873441183439

Epoch: 6| Step: 10
Training loss: 0.3361198902130127
Validation loss: 1.5041550038963236

Epoch: 6| Step: 11
Training loss: 0.20312775671482086
Validation loss: 1.4991707789000643

Epoch: 6| Step: 12
Training loss: 0.12052254378795624
Validation loss: 1.4685184724869267

Epoch: 6| Step: 13
Training loss: 0.08649040758609772
Validation loss: 1.4860007801363546

Epoch: 431| Step: 0
Training loss: 0.23875948786735535
Validation loss: 1.4663722207469325

Epoch: 6| Step: 1
Training loss: 0.1920350044965744
Validation loss: 1.4585241733058807

Epoch: 6| Step: 2
Training loss: 0.13293500244617462
Validation loss: 1.498949280349157

Epoch: 6| Step: 3
Training loss: 0.11559230089187622
Validation loss: 1.4689500075514599

Epoch: 6| Step: 4
Training loss: 0.2717541456222534
Validation loss: 1.486433015074781

Epoch: 6| Step: 5
Training loss: 0.263441801071167
Validation loss: 1.4738486441232825

Epoch: 6| Step: 6
Training loss: 0.2016897201538086
Validation loss: 1.4614862665053336

Epoch: 6| Step: 7
Training loss: 0.2138446569442749
Validation loss: 1.4821420010700022

Epoch: 6| Step: 8
Training loss: 0.16960260272026062
Validation loss: 1.4973087182608984

Epoch: 6| Step: 9
Training loss: 0.19054952263832092
Validation loss: 1.4935046037038167

Epoch: 6| Step: 10
Training loss: 0.1271636188030243
Validation loss: 1.4883316050293625

Epoch: 6| Step: 11
Training loss: 0.3377261459827423
Validation loss: 1.4539173251839095

Epoch: 6| Step: 12
Training loss: 0.27901381254196167
Validation loss: 1.4957521333489368

Epoch: 6| Step: 13
Training loss: 0.1749935746192932
Validation loss: 1.4843135162066388

Epoch: 432| Step: 0
Training loss: 0.15825307369232178
Validation loss: 1.5015421067514727

Epoch: 6| Step: 1
Training loss: 0.27773916721343994
Validation loss: 1.4966209684648821

Epoch: 6| Step: 2
Training loss: 0.14571261405944824
Validation loss: 1.5156279507503714

Epoch: 6| Step: 3
Training loss: 0.1660325825214386
Validation loss: 1.4831438910576604

Epoch: 6| Step: 4
Training loss: 0.10860581696033478
Validation loss: 1.4688778961858442

Epoch: 6| Step: 5
Training loss: 0.18408572673797607
Validation loss: 1.4672133576485418

Epoch: 6| Step: 6
Training loss: 0.213420107960701
Validation loss: 1.4565955823467625

Epoch: 6| Step: 7
Training loss: 0.32258880138397217
Validation loss: 1.4800098173079952

Epoch: 6| Step: 8
Training loss: 0.3878479599952698
Validation loss: 1.474942539327888

Epoch: 6| Step: 9
Training loss: 0.23485998809337616
Validation loss: 1.4954966873891893

Epoch: 6| Step: 10
Training loss: 0.2150896042585373
Validation loss: 1.541883522464383

Epoch: 6| Step: 11
Training loss: 0.10983897745609283
Validation loss: 1.5330882572358655

Epoch: 6| Step: 12
Training loss: 0.34730687737464905
Validation loss: 1.5467811681891

Epoch: 6| Step: 13
Training loss: 0.1731661558151245
Validation loss: 1.553482699137862

Epoch: 433| Step: 0
Training loss: 0.13531893491744995
Validation loss: 1.59874217484587

Epoch: 6| Step: 1
Training loss: 0.24815717339515686
Validation loss: 1.6611286542748893

Epoch: 6| Step: 2
Training loss: 0.19652363657951355
Validation loss: 1.645856822690656

Epoch: 6| Step: 3
Training loss: 0.1507243663072586
Validation loss: 1.6003423429304553

Epoch: 6| Step: 4
Training loss: 0.2191496044397354
Validation loss: 1.541814700890613

Epoch: 6| Step: 5
Training loss: 0.15304997563362122
Validation loss: 1.5029872194413216

Epoch: 6| Step: 6
Training loss: 0.1566016674041748
Validation loss: 1.4450606851167576

Epoch: 6| Step: 7
Training loss: 0.4760773181915283
Validation loss: 1.4373745482455018

Epoch: 6| Step: 8
Training loss: 0.2383802831172943
Validation loss: 1.4116031841565204

Epoch: 6| Step: 9
Training loss: 0.5228544473648071
Validation loss: 1.4301503319894113

Epoch: 6| Step: 10
Training loss: 0.25902223587036133
Validation loss: 1.4141100247701008

Epoch: 6| Step: 11
Training loss: 0.1849748194217682
Validation loss: 1.4099314892163841

Epoch: 6| Step: 12
Training loss: 0.20858553051948547
Validation loss: 1.3853362228280754

Epoch: 6| Step: 13
Training loss: 0.1601012945175171
Validation loss: 1.41095362042868

Epoch: 434| Step: 0
Training loss: 0.22012487053871155
Validation loss: 1.4636174209656254

Epoch: 6| Step: 1
Training loss: 0.25080186128616333
Validation loss: 1.5416624956233527

Epoch: 6| Step: 2
Training loss: 0.29362019896507263
Validation loss: 1.6042432656852148

Epoch: 6| Step: 3
Training loss: 0.2687360644340515
Validation loss: 1.6584849613969044

Epoch: 6| Step: 4
Training loss: 0.583934485912323
Validation loss: 1.661146120358539

Epoch: 6| Step: 5
Training loss: 0.4119802713394165
Validation loss: 1.6467800768472816

Epoch: 6| Step: 6
Training loss: 0.24095627665519714
Validation loss: 1.5246707995732625

Epoch: 6| Step: 7
Training loss: 0.10334333032369614
Validation loss: 1.431627711942119

Epoch: 6| Step: 8
Training loss: 0.331046998500824
Validation loss: 1.4507565075351345

Epoch: 6| Step: 9
Training loss: 0.32615232467651367
Validation loss: 1.4428154255754204

Epoch: 6| Step: 10
Training loss: 0.3898184895515442
Validation loss: 1.4663751445790774

Epoch: 6| Step: 11
Training loss: 0.17397356033325195
Validation loss: 1.4557638424699024

Epoch: 6| Step: 12
Training loss: 0.2153659462928772
Validation loss: 1.4306802403542302

Epoch: 6| Step: 13
Training loss: 0.21159453690052032
Validation loss: 1.4297581411177112

Epoch: 435| Step: 0
Training loss: 0.19009721279144287
Validation loss: 1.4698283313423075

Epoch: 6| Step: 1
Training loss: 0.3141283690929413
Validation loss: 1.5297191002035653

Epoch: 6| Step: 2
Training loss: 0.24544420838356018
Validation loss: 1.5287484225406442

Epoch: 6| Step: 3
Training loss: 0.1907670497894287
Validation loss: 1.510960235390612

Epoch: 6| Step: 4
Training loss: 0.26919984817504883
Validation loss: 1.528384235597426

Epoch: 6| Step: 5
Training loss: 0.18062356114387512
Validation loss: 1.526638348897298

Epoch: 6| Step: 6
Training loss: 0.38815176486968994
Validation loss: 1.4965095699474376

Epoch: 6| Step: 7
Training loss: 0.27063894271850586
Validation loss: 1.49304058026242

Epoch: 6| Step: 8
Training loss: 0.21809782087802887
Validation loss: 1.444063828837487

Epoch: 6| Step: 9
Training loss: 0.175147145986557
Validation loss: 1.4399719071644608

Epoch: 6| Step: 10
Training loss: 0.17565521597862244
Validation loss: 1.427671173567413

Epoch: 6| Step: 11
Training loss: 0.17242850363254547
Validation loss: 1.4192178172449912

Epoch: 6| Step: 12
Training loss: 0.24475297331809998
Validation loss: 1.4211541414260864

Epoch: 6| Step: 13
Training loss: 0.19206711649894714
Validation loss: 1.4154559591765046

Epoch: 436| Step: 0
Training loss: 0.22326773405075073
Validation loss: 1.4023644988254835

Epoch: 6| Step: 1
Training loss: 0.14446577429771423
Validation loss: 1.418322350389214

Epoch: 6| Step: 2
Training loss: 0.19607484340667725
Validation loss: 1.4022661985889557

Epoch: 6| Step: 3
Training loss: 0.12045132368803024
Validation loss: 1.4266111504647039

Epoch: 6| Step: 4
Training loss: 0.14431054890155792
Validation loss: 1.409935994814801

Epoch: 6| Step: 5
Training loss: 0.1316172033548355
Validation loss: 1.4531938863056961

Epoch: 6| Step: 6
Training loss: 0.33835774660110474
Validation loss: 1.4501598996500815

Epoch: 6| Step: 7
Training loss: 0.18200518190860748
Validation loss: 1.4611555748088385

Epoch: 6| Step: 8
Training loss: 0.32174718379974365
Validation loss: 1.4568310835028206

Epoch: 6| Step: 9
Training loss: 0.19072923064231873
Validation loss: 1.4615279410475044

Epoch: 6| Step: 10
Training loss: 0.16743233799934387
Validation loss: 1.4531872823674192

Epoch: 6| Step: 11
Training loss: 0.09312900900840759
Validation loss: 1.4871636629104614

Epoch: 6| Step: 12
Training loss: 0.3058389723300934
Validation loss: 1.495006017146572

Epoch: 6| Step: 13
Training loss: 0.1189797967672348
Validation loss: 1.49332796630039

Epoch: 437| Step: 0
Training loss: 0.22061586380004883
Validation loss: 1.449644688637026

Epoch: 6| Step: 1
Training loss: 0.09983184188604355
Validation loss: 1.4639381452273297

Epoch: 6| Step: 2
Training loss: 0.2952425479888916
Validation loss: 1.465733120518346

Epoch: 6| Step: 3
Training loss: 0.2158937156200409
Validation loss: 1.463741696009072

Epoch: 6| Step: 4
Training loss: 0.2899411916732788
Validation loss: 1.4530762613460582

Epoch: 6| Step: 5
Training loss: 0.23683607578277588
Validation loss: 1.4532700059234456

Epoch: 6| Step: 6
Training loss: 0.1795482039451599
Validation loss: 1.455029095372846

Epoch: 6| Step: 7
Training loss: 0.21042099595069885
Validation loss: 1.4955377988917853

Epoch: 6| Step: 8
Training loss: 0.21632298827171326
Validation loss: 1.551340723550448

Epoch: 6| Step: 9
Training loss: 0.18837954103946686
Validation loss: 1.5165223293406989

Epoch: 6| Step: 10
Training loss: 0.19912177324295044
Validation loss: 1.5696187314166818

Epoch: 6| Step: 11
Training loss: 0.2940800189971924
Validation loss: 1.4904736729078396

Epoch: 6| Step: 12
Training loss: 0.28067731857299805
Validation loss: 1.4744824927340272

Epoch: 6| Step: 13
Training loss: 0.11907137930393219
Validation loss: 1.4059171176725818

Epoch: 438| Step: 0
Training loss: 0.09532372653484344
Validation loss: 1.3732970376168527

Epoch: 6| Step: 1
Training loss: 0.14594405889511108
Validation loss: 1.351861310261552

Epoch: 6| Step: 2
Training loss: 0.6496834754943848
Validation loss: 1.336230262633293

Epoch: 6| Step: 3
Training loss: 0.35527974367141724
Validation loss: 1.373076113962358

Epoch: 6| Step: 4
Training loss: 0.15213696658611298
Validation loss: 1.354257067044576

Epoch: 6| Step: 5
Training loss: 0.2553486227989197
Validation loss: 1.3653617930668656

Epoch: 6| Step: 6
Training loss: 0.21749365329742432
Validation loss: 1.4040185225907194

Epoch: 6| Step: 7
Training loss: 0.1547352820634842
Validation loss: 1.4099761926999657

Epoch: 6| Step: 8
Training loss: 0.18842342495918274
Validation loss: 1.4569646094435005

Epoch: 6| Step: 9
Training loss: 0.29895836114883423
Validation loss: 1.452532942577075

Epoch: 6| Step: 10
Training loss: 0.19817163050174713
Validation loss: 1.4329167489082582

Epoch: 6| Step: 11
Training loss: 0.25365912914276123
Validation loss: 1.4089360032030331

Epoch: 6| Step: 12
Training loss: 0.23277568817138672
Validation loss: 1.4177639638223956

Epoch: 6| Step: 13
Training loss: 0.17051082849502563
Validation loss: 1.3690665498856576

Epoch: 439| Step: 0
Training loss: 0.15900149941444397
Validation loss: 1.4112463676801292

Epoch: 6| Step: 1
Training loss: 0.13085368275642395
Validation loss: 1.4282278258313414

Epoch: 6| Step: 2
Training loss: 0.3834421634674072
Validation loss: 1.4410099483305407

Epoch: 6| Step: 3
Training loss: 0.1692093461751938
Validation loss: 1.4544789175833426

Epoch: 6| Step: 4
Training loss: 0.23794029653072357
Validation loss: 1.5192565277058592

Epoch: 6| Step: 5
Training loss: 0.24958820641040802
Validation loss: 1.5224069831191853

Epoch: 6| Step: 6
Training loss: 0.14554363489151
Validation loss: 1.5430039282768004

Epoch: 6| Step: 7
Training loss: 0.2651534676551819
Validation loss: 1.5206907263366125

Epoch: 6| Step: 8
Training loss: 0.10792602598667145
Validation loss: 1.5426436970310826

Epoch: 6| Step: 9
Training loss: 0.2710316479206085
Validation loss: 1.5266707610058528

Epoch: 6| Step: 10
Training loss: 0.2197706401348114
Validation loss: 1.516831801783654

Epoch: 6| Step: 11
Training loss: 0.22227974236011505
Validation loss: 1.4971091978011593

Epoch: 6| Step: 12
Training loss: 0.2144167125225067
Validation loss: 1.4978796820486746

Epoch: 6| Step: 13
Training loss: 0.20125633478164673
Validation loss: 1.4728905667540848

Epoch: 440| Step: 0
Training loss: 0.3603816032409668
Validation loss: 1.4517780606464674

Epoch: 6| Step: 1
Training loss: 0.21927323937416077
Validation loss: 1.419029526813056

Epoch: 6| Step: 2
Training loss: 0.22971954941749573
Validation loss: 1.4478265239346413

Epoch: 6| Step: 3
Training loss: 0.2424006462097168
Validation loss: 1.4682118559396395

Epoch: 6| Step: 4
Training loss: 0.34842073917388916
Validation loss: 1.4836086162956812

Epoch: 6| Step: 5
Training loss: 0.1782381385564804
Validation loss: 1.4956707646769862

Epoch: 6| Step: 6
Training loss: 0.37077969312667847
Validation loss: 1.5037317224728164

Epoch: 6| Step: 7
Training loss: 0.1374744027853012
Validation loss: 1.4774228478631666

Epoch: 6| Step: 8
Training loss: 0.17850813269615173
Validation loss: 1.4468322825688187

Epoch: 6| Step: 9
Training loss: 0.12430738657712936
Validation loss: 1.4633165123642131

Epoch: 6| Step: 10
Training loss: 0.17437583208084106
Validation loss: 1.4140974116581742

Epoch: 6| Step: 11
Training loss: 0.14907293021678925
Validation loss: 1.3863859785500394

Epoch: 6| Step: 12
Training loss: 0.11048150062561035
Validation loss: 1.3651586553101898

Epoch: 6| Step: 13
Training loss: 0.21559175848960876
Validation loss: 1.3749508460362752

Epoch: 441| Step: 0
Training loss: 0.2145431935787201
Validation loss: 1.403903853508734

Epoch: 6| Step: 1
Training loss: 0.32710450887680054
Validation loss: 1.3983216272887362

Epoch: 6| Step: 2
Training loss: 0.15833674371242523
Validation loss: 1.4182647146204466

Epoch: 6| Step: 3
Training loss: 0.2086215317249298
Validation loss: 1.4620365301767986

Epoch: 6| Step: 4
Training loss: 0.28699764609336853
Validation loss: 1.4948042631149292

Epoch: 6| Step: 5
Training loss: 0.20572997629642487
Validation loss: 1.4768522644555697

Epoch: 6| Step: 6
Training loss: 0.36370718479156494
Validation loss: 1.4197816845550333

Epoch: 6| Step: 7
Training loss: 0.14499439299106598
Validation loss: 1.429821861687527

Epoch: 6| Step: 8
Training loss: 0.1459956020116806
Validation loss: 1.4235255743867608

Epoch: 6| Step: 9
Training loss: 0.18108665943145752
Validation loss: 1.457643514038414

Epoch: 6| Step: 10
Training loss: 0.1975264847278595
Validation loss: 1.439508217637257

Epoch: 6| Step: 11
Training loss: 0.36105042695999146
Validation loss: 1.484720386484618

Epoch: 6| Step: 12
Training loss: 0.22249436378479004
Validation loss: 1.4744212012137137

Epoch: 6| Step: 13
Training loss: 0.15965500473976135
Validation loss: 1.4648322430990075

Epoch: 442| Step: 0
Training loss: 0.09550347924232483
Validation loss: 1.4949235454682381

Epoch: 6| Step: 1
Training loss: 0.334828644990921
Validation loss: 1.504859426970123

Epoch: 6| Step: 2
Training loss: 0.14421415328979492
Validation loss: 1.5413522835700744

Epoch: 6| Step: 3
Training loss: 0.25990283489227295
Validation loss: 1.528437364485956

Epoch: 6| Step: 4
Training loss: 0.22228746116161346
Validation loss: 1.55684051206035

Epoch: 6| Step: 5
Training loss: 0.26451629400253296
Validation loss: 1.5774532274533344

Epoch: 6| Step: 6
Training loss: 0.12340694665908813
Validation loss: 1.57634061895391

Epoch: 6| Step: 7
Training loss: 0.15718460083007812
Validation loss: 1.5820453346416514

Epoch: 6| Step: 8
Training loss: 0.33479389548301697
Validation loss: 1.601525196465113

Epoch: 6| Step: 9
Training loss: 0.18342941999435425
Validation loss: 1.5720777678233322

Epoch: 6| Step: 10
Training loss: 0.1704171746969223
Validation loss: 1.5545741063292309

Epoch: 6| Step: 11
Training loss: 0.213704451918602
Validation loss: 1.5413110192104051

Epoch: 6| Step: 12
Training loss: 0.3048904836177826
Validation loss: 1.508922666631719

Epoch: 6| Step: 13
Training loss: 0.07778745144605637
Validation loss: 1.524649404710339

Epoch: 443| Step: 0
Training loss: 0.36684590578079224
Validation loss: 1.4854614644922235

Epoch: 6| Step: 1
Training loss: 0.231641486287117
Validation loss: 1.4807402869706512

Epoch: 6| Step: 2
Training loss: 0.12955938279628754
Validation loss: 1.4837634589082451

Epoch: 6| Step: 3
Training loss: 0.2639033794403076
Validation loss: 1.4960873485893331

Epoch: 6| Step: 4
Training loss: 0.13582956790924072
Validation loss: 1.4752815436291438

Epoch: 6| Step: 5
Training loss: 0.26456549763679504
Validation loss: 1.4694675117410638

Epoch: 6| Step: 6
Training loss: 0.19149696826934814
Validation loss: 1.4531551125229045

Epoch: 6| Step: 7
Training loss: 0.27911606431007385
Validation loss: 1.4143363211744575

Epoch: 6| Step: 8
Training loss: 0.1664142906665802
Validation loss: 1.412833975207421

Epoch: 6| Step: 9
Training loss: 0.35219085216522217
Validation loss: 1.3805189767191488

Epoch: 6| Step: 10
Training loss: 0.22524787485599518
Validation loss: 1.4032372787434568

Epoch: 6| Step: 11
Training loss: 0.139370858669281
Validation loss: 1.3679199346932032

Epoch: 6| Step: 12
Training loss: 0.11843177676200867
Validation loss: 1.382694831458471

Epoch: 6| Step: 13
Training loss: 0.12534983456134796
Validation loss: 1.3926380167725265

Epoch: 444| Step: 0
Training loss: 0.14624249935150146
Validation loss: 1.4121835911145775

Epoch: 6| Step: 1
Training loss: 0.14843904972076416
Validation loss: 1.4068277574354602

Epoch: 6| Step: 2
Training loss: 0.1610434651374817
Validation loss: 1.3794834177981141

Epoch: 6| Step: 3
Training loss: 0.29338574409484863
Validation loss: 1.3954211217100903

Epoch: 6| Step: 4
Training loss: 0.13541001081466675
Validation loss: 1.397732759034762

Epoch: 6| Step: 5
Training loss: 0.24192212522029877
Validation loss: 1.3825195989301127

Epoch: 6| Step: 6
Training loss: 0.3184056878089905
Validation loss: 1.409110633275842

Epoch: 6| Step: 7
Training loss: 0.24077199399471283
Validation loss: 1.4049991497429468

Epoch: 6| Step: 8
Training loss: 0.20340442657470703
Validation loss: 1.3707308371861775

Epoch: 6| Step: 9
Training loss: 0.14493857324123383
Validation loss: 1.4028372623587166

Epoch: 6| Step: 10
Training loss: 0.1425715684890747
Validation loss: 1.418542823483867

Epoch: 6| Step: 11
Training loss: 0.16285014152526855
Validation loss: 1.4461372475470267

Epoch: 6| Step: 12
Training loss: 0.1995818316936493
Validation loss: 1.428761084233561

Epoch: 6| Step: 13
Training loss: 0.16693215072155
Validation loss: 1.480665777319221

Epoch: 445| Step: 0
Training loss: 0.10852941870689392
Validation loss: 1.4872062539541593

Epoch: 6| Step: 1
Training loss: 0.13336747884750366
Validation loss: 1.5064940350030058

Epoch: 6| Step: 2
Training loss: 0.15095199644565582
Validation loss: 1.5026812540587557

Epoch: 6| Step: 3
Training loss: 0.12135020643472672
Validation loss: 1.4902425299408615

Epoch: 6| Step: 4
Training loss: 0.18543219566345215
Validation loss: 1.4703421887531076

Epoch: 6| Step: 5
Training loss: 0.31341680884361267
Validation loss: 1.4975319075328049

Epoch: 6| Step: 6
Training loss: 0.17777115106582642
Validation loss: 1.5009344726480462

Epoch: 6| Step: 7
Training loss: 0.1771547943353653
Validation loss: 1.4949020736960954

Epoch: 6| Step: 8
Training loss: 0.1319471299648285
Validation loss: 1.5351414475389706

Epoch: 6| Step: 9
Training loss: 0.2753671705722809
Validation loss: 1.560986106113721

Epoch: 6| Step: 10
Training loss: 0.32807260751724243
Validation loss: 1.5827049465589627

Epoch: 6| Step: 11
Training loss: 0.2989654839038849
Validation loss: 1.592303285034754

Epoch: 6| Step: 12
Training loss: 0.16845238208770752
Validation loss: 1.5855496250173098

Epoch: 6| Step: 13
Training loss: 0.17500700056552887
Validation loss: 1.553999444489838

Epoch: 446| Step: 0
Training loss: 0.18469902873039246
Validation loss: 1.5378155246857674

Epoch: 6| Step: 1
Training loss: 0.09720338135957718
Validation loss: 1.5002602531063942

Epoch: 6| Step: 2
Training loss: 0.1476978361606598
Validation loss: 1.490955852693127

Epoch: 6| Step: 3
Training loss: 0.19183723628520966
Validation loss: 1.4684679469754618

Epoch: 6| Step: 4
Training loss: 0.3939776122570038
Validation loss: 1.4579023673970213

Epoch: 6| Step: 5
Training loss: 0.23654583096504211
Validation loss: 1.4273579992273802

Epoch: 6| Step: 6
Training loss: 0.19547826051712036
Validation loss: 1.4373728600881432

Epoch: 6| Step: 7
Training loss: 0.1731259524822235
Validation loss: 1.4326274561625656

Epoch: 6| Step: 8
Training loss: 0.19266673922538757
Validation loss: 1.4521229638848254

Epoch: 6| Step: 9
Training loss: 0.4555841386318207
Validation loss: 1.4300077243517804

Epoch: 6| Step: 10
Training loss: 0.161992609500885
Validation loss: 1.4924693517787482

Epoch: 6| Step: 11
Training loss: 0.17766107618808746
Validation loss: 1.5016463892434233

Epoch: 6| Step: 12
Training loss: 0.1566779911518097
Validation loss: 1.5287518270554081

Epoch: 6| Step: 13
Training loss: 0.291036993265152
Validation loss: 1.5188855778786443

Epoch: 447| Step: 0
Training loss: 0.2106364220380783
Validation loss: 1.4833460610399964

Epoch: 6| Step: 1
Training loss: 0.09252624213695526
Validation loss: 1.5109379624807706

Epoch: 6| Step: 2
Training loss: 0.13771407306194305
Validation loss: 1.427688531978156

Epoch: 6| Step: 3
Training loss: 0.1388595998287201
Validation loss: 1.458524698852211

Epoch: 6| Step: 4
Training loss: 0.2049371302127838
Validation loss: 1.447942349218553

Epoch: 6| Step: 5
Training loss: 0.30783218145370483
Validation loss: 1.4294806795735513

Epoch: 6| Step: 6
Training loss: 0.11921238154172897
Validation loss: 1.4324707446559783

Epoch: 6| Step: 7
Training loss: 0.3225313723087311
Validation loss: 1.4356335927081365

Epoch: 6| Step: 8
Training loss: 0.21686244010925293
Validation loss: 1.4763164539490976

Epoch: 6| Step: 9
Training loss: 0.15704089403152466
Validation loss: 1.4706395531213412

Epoch: 6| Step: 10
Training loss: 0.2077406346797943
Validation loss: 1.4738590448133406

Epoch: 6| Step: 11
Training loss: 0.18687911331653595
Validation loss: 1.4744823055882608

Epoch: 6| Step: 12
Training loss: 0.2854241132736206
Validation loss: 1.4907422732281428

Epoch: 6| Step: 13
Training loss: 0.14192967116832733
Validation loss: 1.5205224252516223

Epoch: 448| Step: 0
Training loss: 0.17881856858730316
Validation loss: 1.5272176060625302

Epoch: 6| Step: 1
Training loss: 0.2759825587272644
Validation loss: 1.5208329013598862

Epoch: 6| Step: 2
Training loss: 0.1307113766670227
Validation loss: 1.4814440870797763

Epoch: 6| Step: 3
Training loss: 0.09830794483423233
Validation loss: 1.4274015721454416

Epoch: 6| Step: 4
Training loss: 0.16741269826889038
Validation loss: 1.4158893778759947

Epoch: 6| Step: 5
Training loss: 0.24090653657913208
Validation loss: 1.4015541961116176

Epoch: 6| Step: 6
Training loss: 0.20177549123764038
Validation loss: 1.428459103389453

Epoch: 6| Step: 7
Training loss: 0.12791836261749268
Validation loss: 1.4145333959210304

Epoch: 6| Step: 8
Training loss: 0.24705439805984497
Validation loss: 1.4192503344628118

Epoch: 6| Step: 9
Training loss: 0.2685376703739166
Validation loss: 1.4404476381117297

Epoch: 6| Step: 10
Training loss: 0.17093956470489502
Validation loss: 1.472247621064545

Epoch: 6| Step: 11
Training loss: 0.30375978350639343
Validation loss: 1.473840626337195

Epoch: 6| Step: 12
Training loss: 0.2948610782623291
Validation loss: 1.5062157825757099

Epoch: 6| Step: 13
Training loss: 0.13179409503936768
Validation loss: 1.4982519277962305

Epoch: 449| Step: 0
Training loss: 0.08471733331680298
Validation loss: 1.4792834661340202

Epoch: 6| Step: 1
Training loss: 0.16741162538528442
Validation loss: 1.5189206965508

Epoch: 6| Step: 2
Training loss: 0.29052266478538513
Validation loss: 1.505108097548126

Epoch: 6| Step: 3
Training loss: 0.09162332862615585
Validation loss: 1.4843962205353605

Epoch: 6| Step: 4
Training loss: 0.2151654064655304
Validation loss: 1.4960356258576917

Epoch: 6| Step: 5
Training loss: 0.09900997579097748
Validation loss: 1.4535045136687577

Epoch: 6| Step: 6
Training loss: 0.25784093141555786
Validation loss: 1.4531554227234216

Epoch: 6| Step: 7
Training loss: 0.07945245504379272
Validation loss: 1.4590399906199465

Epoch: 6| Step: 8
Training loss: 0.3073570132255554
Validation loss: 1.4573100587373138

Epoch: 6| Step: 9
Training loss: 0.13301286101341248
Validation loss: 1.4627026768140896

Epoch: 6| Step: 10
Training loss: 0.13070686161518097
Validation loss: 1.429968294276986

Epoch: 6| Step: 11
Training loss: 0.14966191351413727
Validation loss: 1.4379927381392448

Epoch: 6| Step: 12
Training loss: 0.042265571653842926
Validation loss: 1.427482117888748

Epoch: 6| Step: 13
Training loss: 0.18589656054973602
Validation loss: 1.4228145730110906

Epoch: 450| Step: 0
Training loss: 0.109652578830719
Validation loss: 1.4276192047262704

Epoch: 6| Step: 1
Training loss: 0.09571047127246857
Validation loss: 1.4431686311639764

Epoch: 6| Step: 2
Training loss: 0.17583264410495758
Validation loss: 1.4203680471707416

Epoch: 6| Step: 3
Training loss: 0.12927401065826416
Validation loss: 1.4409049223828059

Epoch: 6| Step: 4
Training loss: 0.20941109955310822
Validation loss: 1.4342421498349918

Epoch: 6| Step: 5
Training loss: 0.13255029916763306
Validation loss: 1.439076167280956

Epoch: 6| Step: 6
Training loss: 0.25081709027290344
Validation loss: 1.4259170383535407

Epoch: 6| Step: 7
Training loss: 0.08096158504486084
Validation loss: 1.4404159668953187

Epoch: 6| Step: 8
Training loss: 0.24493636190891266
Validation loss: 1.405619934041013

Epoch: 6| Step: 9
Training loss: 0.13251180946826935
Validation loss: 1.4092813550785024

Epoch: 6| Step: 10
Training loss: 0.10801245272159576
Validation loss: 1.4004127312732

Epoch: 6| Step: 11
Training loss: 0.11247117817401886
Validation loss: 1.403606709613595

Epoch: 6| Step: 12
Training loss: 0.28130435943603516
Validation loss: 1.394788303682881

Epoch: 6| Step: 13
Training loss: 0.27090340852737427
Validation loss: 1.4091962422094038

Epoch: 451| Step: 0
Training loss: 0.1683531403541565
Validation loss: 1.409103601209579

Epoch: 6| Step: 1
Training loss: 0.09093167632818222
Validation loss: 1.3787074089050293

Epoch: 6| Step: 2
Training loss: 0.1208067387342453
Validation loss: 1.4192954974789773

Epoch: 6| Step: 3
Training loss: 0.16072580218315125
Validation loss: 1.3910766083707091

Epoch: 6| Step: 4
Training loss: 0.18788346648216248
Validation loss: 1.4175992627297678

Epoch: 6| Step: 5
Training loss: 0.30978378653526306
Validation loss: 1.4207842439733527

Epoch: 6| Step: 6
Training loss: 0.10521718114614487
Validation loss: 1.4311605909819245

Epoch: 6| Step: 7
Training loss: 0.11228062212467194
Validation loss: 1.3992399361825758

Epoch: 6| Step: 8
Training loss: 0.12578144669532776
Validation loss: 1.4115847079984603

Epoch: 6| Step: 9
Training loss: 0.27583932876586914
Validation loss: 1.4374051696510726

Epoch: 6| Step: 10
Training loss: 0.21512357890605927
Validation loss: 1.406668201569588

Epoch: 6| Step: 11
Training loss: 0.12224271893501282
Validation loss: 1.4423117150542557

Epoch: 6| Step: 12
Training loss: 0.1544371247291565
Validation loss: 1.447481793101116

Epoch: 6| Step: 13
Training loss: 0.07152268290519714
Validation loss: 1.45167528429339

Epoch: 452| Step: 0
Training loss: 0.14717957377433777
Validation loss: 1.4186170703621321

Epoch: 6| Step: 1
Training loss: 0.12439817190170288
Validation loss: 1.4547486125781972

Epoch: 6| Step: 2
Training loss: 0.2678244411945343
Validation loss: 1.4745059885004514

Epoch: 6| Step: 3
Training loss: 0.19968855381011963
Validation loss: 1.4747189706371677

Epoch: 6| Step: 4
Training loss: 0.15680119395256042
Validation loss: 1.4711368378772531

Epoch: 6| Step: 5
Training loss: 0.15414635837078094
Validation loss: 1.4541947995462725

Epoch: 6| Step: 6
Training loss: 0.12397745996713638
Validation loss: 1.4520361154310164

Epoch: 6| Step: 7
Training loss: 0.22169558703899384
Validation loss: 1.4409317662639003

Epoch: 6| Step: 8
Training loss: 0.27884870767593384
Validation loss: 1.4505221497627996

Epoch: 6| Step: 9
Training loss: 0.3267620801925659
Validation loss: 1.4045864984553347

Epoch: 6| Step: 10
Training loss: 0.11467665433883667
Validation loss: 1.4075187803596578

Epoch: 6| Step: 11
Training loss: 0.22187677025794983
Validation loss: 1.4219409624735515

Epoch: 6| Step: 12
Training loss: 0.27553969621658325
Validation loss: 1.4265710307705788

Epoch: 6| Step: 13
Training loss: 0.13774792850017548
Validation loss: 1.448374843084684

Epoch: 453| Step: 0
Training loss: 0.2091948688030243
Validation loss: 1.4515463267603228

Epoch: 6| Step: 1
Training loss: 0.10265480726957321
Validation loss: 1.4523467543304607

Epoch: 6| Step: 2
Training loss: 0.11744167655706406
Validation loss: 1.457667480232895

Epoch: 6| Step: 3
Training loss: 0.26391178369522095
Validation loss: 1.4279727166698826

Epoch: 6| Step: 4
Training loss: 0.17011359333992004
Validation loss: 1.4019518347196682

Epoch: 6| Step: 5
Training loss: 0.11403863877058029
Validation loss: 1.40427642227501

Epoch: 6| Step: 6
Training loss: 0.10813849419355392
Validation loss: 1.396779780746788

Epoch: 6| Step: 7
Training loss: 0.43861764669418335
Validation loss: 1.4068688327266323

Epoch: 6| Step: 8
Training loss: 0.13869106769561768
Validation loss: 1.4164089464372205

Epoch: 6| Step: 9
Training loss: 0.29600054025650024
Validation loss: 1.4336117557300034

Epoch: 6| Step: 10
Training loss: 0.12213629484176636
Validation loss: 1.4053364312776955

Epoch: 6| Step: 11
Training loss: 0.10862849652767181
Validation loss: 1.41592772224898

Epoch: 6| Step: 12
Training loss: 0.17753095924854279
Validation loss: 1.4473123858051915

Epoch: 6| Step: 13
Training loss: 0.1054593026638031
Validation loss: 1.4582869557924167

Epoch: 454| Step: 0
Training loss: 0.10296770930290222
Validation loss: 1.4868914863114715

Epoch: 6| Step: 1
Training loss: 0.15501251816749573
Validation loss: 1.5299604413329915

Epoch: 6| Step: 2
Training loss: 0.1388624757528305
Validation loss: 1.5260727072274813

Epoch: 6| Step: 3
Training loss: 0.2533313035964966
Validation loss: 1.5097971052251837

Epoch: 6| Step: 4
Training loss: 0.16653841733932495
Validation loss: 1.512231312772279

Epoch: 6| Step: 5
Training loss: 0.10752412676811218
Validation loss: 1.478777563700112

Epoch: 6| Step: 6
Training loss: 0.19059506058692932
Validation loss: 1.4938918493127311

Epoch: 6| Step: 7
Training loss: 0.09973932802677155
Validation loss: 1.4785996457581878

Epoch: 6| Step: 8
Training loss: 0.27311915159225464
Validation loss: 1.4729500303986252

Epoch: 6| Step: 9
Training loss: 0.134526327252388
Validation loss: 1.472067940619684

Epoch: 6| Step: 10
Training loss: 0.18148273229599
Validation loss: 1.4592410274731216

Epoch: 6| Step: 11
Training loss: 0.11224699020385742
Validation loss: 1.4214291662298224

Epoch: 6| Step: 12
Training loss: 0.18309345841407776
Validation loss: 1.455025008929673

Epoch: 6| Step: 13
Training loss: 0.5605674386024475
Validation loss: 1.4134901723554056

Epoch: 455| Step: 0
Training loss: 0.09633740037679672
Validation loss: 1.4232749618509764

Epoch: 6| Step: 1
Training loss: 0.16575491428375244
Validation loss: 1.4233804620722288

Epoch: 6| Step: 2
Training loss: 0.28397735953330994
Validation loss: 1.4005446510930215

Epoch: 6| Step: 3
Training loss: 0.15051841735839844
Validation loss: 1.4621920047267791

Epoch: 6| Step: 4
Training loss: 0.23556172847747803
Validation loss: 1.4490172683551747

Epoch: 6| Step: 5
Training loss: 0.16949021816253662
Validation loss: 1.478461580891763

Epoch: 6| Step: 6
Training loss: 0.33087462186813354
Validation loss: 1.4502210668338242

Epoch: 6| Step: 7
Training loss: 0.18844854831695557
Validation loss: 1.4082119734056535

Epoch: 6| Step: 8
Training loss: 0.11738036572933197
Validation loss: 1.4140987601331485

Epoch: 6| Step: 9
Training loss: 0.19215887784957886
Validation loss: 1.408033259453312

Epoch: 6| Step: 10
Training loss: 0.15837377309799194
Validation loss: 1.3703003544961252

Epoch: 6| Step: 11
Training loss: 0.12917181849479675
Validation loss: 1.4055568877086844

Epoch: 6| Step: 12
Training loss: 0.1533735990524292
Validation loss: 1.411448331289394

Epoch: 6| Step: 13
Training loss: 0.23316267132759094
Validation loss: 1.4069052204009025

Epoch: 456| Step: 0
Training loss: 0.21304449439048767
Validation loss: 1.4257833060397898

Epoch: 6| Step: 1
Training loss: 0.13902965188026428
Validation loss: 1.4724036006517307

Epoch: 6| Step: 2
Training loss: 0.22828498482704163
Validation loss: 1.476960934618468

Epoch: 6| Step: 3
Training loss: 0.08130711317062378
Validation loss: 1.482512956024498

Epoch: 6| Step: 4
Training loss: 0.23690427839756012
Validation loss: 1.5098125793600594

Epoch: 6| Step: 5
Training loss: 0.18170210719108582
Validation loss: 1.5058947109406995

Epoch: 6| Step: 6
Training loss: 0.19144582748413086
Validation loss: 1.52012122959219

Epoch: 6| Step: 7
Training loss: 0.21134547889232635
Validation loss: 1.5304266573280416

Epoch: 6| Step: 8
Training loss: 0.20983658730983734
Validation loss: 1.4941174419977332

Epoch: 6| Step: 9
Training loss: 0.21151518821716309
Validation loss: 1.476783739623203

Epoch: 6| Step: 10
Training loss: 0.12379630655050278
Validation loss: 1.4367820626945906

Epoch: 6| Step: 11
Training loss: 0.17857730388641357
Validation loss: 1.4289329058380538

Epoch: 6| Step: 12
Training loss: 0.14916715025901794
Validation loss: 1.3885933756828308

Epoch: 6| Step: 13
Training loss: 0.12101313471794128
Validation loss: 1.4042752032638879

Epoch: 457| Step: 0
Training loss: 0.12468621134757996
Validation loss: 1.3556140353602748

Epoch: 6| Step: 1
Training loss: 0.07362332940101624
Validation loss: 1.3632365638209927

Epoch: 6| Step: 2
Training loss: 0.11986102908849716
Validation loss: 1.3540168654534124

Epoch: 6| Step: 3
Training loss: 0.25515466928482056
Validation loss: 1.328226912406183

Epoch: 6| Step: 4
Training loss: 0.13328653573989868
Validation loss: 1.3325490797719648

Epoch: 6| Step: 5
Training loss: 0.15431547164916992
Validation loss: 1.3250377229464951

Epoch: 6| Step: 6
Training loss: 0.17145279049873352
Validation loss: 1.3474907798151816

Epoch: 6| Step: 7
Training loss: 0.20109710097312927
Validation loss: 1.3460111105313866

Epoch: 6| Step: 8
Training loss: 0.21150611340999603
Validation loss: 1.3826134948320286

Epoch: 6| Step: 9
Training loss: 0.16246667504310608
Validation loss: 1.4199005814008816

Epoch: 6| Step: 10
Training loss: 0.16281580924987793
Validation loss: 1.402886272758566

Epoch: 6| Step: 11
Training loss: 0.26984870433807373
Validation loss: 1.4166112381924865

Epoch: 6| Step: 12
Training loss: 0.31821268796920776
Validation loss: 1.426703748523548

Epoch: 6| Step: 13
Training loss: 0.22934307157993317
Validation loss: 1.4722949407433952

Epoch: 458| Step: 0
Training loss: 0.11425165086984634
Validation loss: 1.4640702483474568

Epoch: 6| Step: 1
Training loss: 0.34118854999542236
Validation loss: 1.4617496446896625

Epoch: 6| Step: 2
Training loss: 0.27603593468666077
Validation loss: 1.4579906239304492

Epoch: 6| Step: 3
Training loss: 0.11407704651355743
Validation loss: 1.4528764550403883

Epoch: 6| Step: 4
Training loss: 0.16343431174755096
Validation loss: 1.4578784915708727

Epoch: 6| Step: 5
Training loss: 0.11985991150140762
Validation loss: 1.421651812009914

Epoch: 6| Step: 6
Training loss: 0.11197157204151154
Validation loss: 1.4522561693704257

Epoch: 6| Step: 7
Training loss: 0.19951236248016357
Validation loss: 1.4201921211775912

Epoch: 6| Step: 8
Training loss: 0.14374899864196777
Validation loss: 1.4276257753372192

Epoch: 6| Step: 9
Training loss: 0.1596546471118927
Validation loss: 1.435143546391559

Epoch: 6| Step: 10
Training loss: 0.09490332007408142
Validation loss: 1.4393772168826031

Epoch: 6| Step: 11
Training loss: 0.08307129889726639
Validation loss: 1.4176904078452819

Epoch: 6| Step: 12
Training loss: 0.12662994861602783
Validation loss: 1.4356773014991515

Epoch: 6| Step: 13
Training loss: 0.27992570400238037
Validation loss: 1.4299039244651794

Epoch: 459| Step: 0
Training loss: 0.08017456531524658
Validation loss: 1.4301860383761826

Epoch: 6| Step: 1
Training loss: 0.2722737193107605
Validation loss: 1.5115190103489866

Epoch: 6| Step: 2
Training loss: 0.11980985105037689
Validation loss: 1.5152837819950555

Epoch: 6| Step: 3
Training loss: 0.34614646434783936
Validation loss: 1.5328882086661555

Epoch: 6| Step: 4
Training loss: 0.10770093649625778
Validation loss: 1.559512702367639

Epoch: 6| Step: 5
Training loss: 0.19125831127166748
Validation loss: 1.5403498039450696

Epoch: 6| Step: 6
Training loss: 0.10148359090089798
Validation loss: 1.5211882815566113

Epoch: 6| Step: 7
Training loss: 0.18320836126804352
Validation loss: 1.4776696787085584

Epoch: 6| Step: 8
Training loss: 0.11550302058458328
Validation loss: 1.4587986905087706

Epoch: 6| Step: 9
Training loss: 0.20836643874645233
Validation loss: 1.4554711682822115

Epoch: 6| Step: 10
Training loss: 0.14003607630729675
Validation loss: 1.4256240731926375

Epoch: 6| Step: 11
Training loss: 0.09387902915477753
Validation loss: 1.3829110694187943

Epoch: 6| Step: 12
Training loss: 0.10019074380397797
Validation loss: 1.388211747651459

Epoch: 6| Step: 13
Training loss: 0.15109875798225403
Validation loss: 1.3587098313916115

Epoch: 460| Step: 0
Training loss: 0.12388969212770462
Validation loss: 1.3609422163296772

Epoch: 6| Step: 1
Training loss: 0.06320786476135254
Validation loss: 1.3278246227131094

Epoch: 6| Step: 2
Training loss: 0.18227387964725494
Validation loss: 1.3654998810060563

Epoch: 6| Step: 3
Training loss: 0.0715215727686882
Validation loss: 1.359201608165618

Epoch: 6| Step: 4
Training loss: 0.36693522334098816
Validation loss: 1.3897581779828636

Epoch: 6| Step: 5
Training loss: 0.2784324586391449
Validation loss: 1.3774439929634013

Epoch: 6| Step: 6
Training loss: 0.20257194340229034
Validation loss: 1.4052019753763754

Epoch: 6| Step: 7
Training loss: 0.17019157111644745
Validation loss: 1.3981335804026613

Epoch: 6| Step: 8
Training loss: 0.1495097577571869
Validation loss: 1.430018545478903

Epoch: 6| Step: 9
Training loss: 0.21598409116268158
Validation loss: 1.4615792061692925

Epoch: 6| Step: 10
Training loss: 0.203068807721138
Validation loss: 1.4603838959047872

Epoch: 6| Step: 11
Training loss: 0.11061886698007584
Validation loss: 1.447350630196192

Epoch: 6| Step: 12
Training loss: 0.1306336671113968
Validation loss: 1.42737659587655

Epoch: 6| Step: 13
Training loss: 0.09088517725467682
Validation loss: 1.4226414766362918

Epoch: 461| Step: 0
Training loss: 0.08703567832708359
Validation loss: 1.4458512721523162

Epoch: 6| Step: 1
Training loss: 0.14342862367630005
Validation loss: 1.4136357935526038

Epoch: 6| Step: 2
Training loss: 0.20553328096866608
Validation loss: 1.4184037280339066

Epoch: 6| Step: 3
Training loss: 0.18413861095905304
Validation loss: 1.4035174615921513

Epoch: 6| Step: 4
Training loss: 0.10811403393745422
Validation loss: 1.386230900723447

Epoch: 6| Step: 5
Training loss: 0.17542627453804016
Validation loss: 1.4069352752418929

Epoch: 6| Step: 6
Training loss: 0.28271597623825073
Validation loss: 1.4624214313363517

Epoch: 6| Step: 7
Training loss: 0.16700072586536407
Validation loss: 1.4655162877933954

Epoch: 6| Step: 8
Training loss: 0.21916137635707855
Validation loss: 1.49642131533674

Epoch: 6| Step: 9
Training loss: 0.12669962644577026
Validation loss: 1.4760877906635244

Epoch: 6| Step: 10
Training loss: 0.11321920901536942
Validation loss: 1.467556744493464

Epoch: 6| Step: 11
Training loss: 0.0883769541978836
Validation loss: 1.4871059002414826

Epoch: 6| Step: 12
Training loss: 0.1470913141965866
Validation loss: 1.431852021524983

Epoch: 6| Step: 13
Training loss: 0.10725458711385727
Validation loss: 1.4281994168476393

Epoch: 462| Step: 0
Training loss: 0.09314151108264923
Validation loss: 1.3818456844616962

Epoch: 6| Step: 1
Training loss: 0.2747993767261505
Validation loss: 1.374174544888158

Epoch: 6| Step: 2
Training loss: 0.16292767226696014
Validation loss: 1.3815010529692455

Epoch: 6| Step: 3
Training loss: 0.1052471250295639
Validation loss: 1.3922182372821275

Epoch: 6| Step: 4
Training loss: 0.14040574431419373
Validation loss: 1.4006382355126001

Epoch: 6| Step: 5
Training loss: 0.22485075891017914
Validation loss: 1.4114687545325166

Epoch: 6| Step: 6
Training loss: 0.11528503149747849
Validation loss: 1.4109556918503137

Epoch: 6| Step: 7
Training loss: 0.10902579128742218
Validation loss: 1.431501143722124

Epoch: 6| Step: 8
Training loss: 0.10585585981607437
Validation loss: 1.4339538633182485

Epoch: 6| Step: 9
Training loss: 0.17474976181983948
Validation loss: 1.457864519088499

Epoch: 6| Step: 10
Training loss: 0.22151201963424683
Validation loss: 1.4783403142806022

Epoch: 6| Step: 11
Training loss: 0.10605797171592712
Validation loss: 1.4598266693853563

Epoch: 6| Step: 12
Training loss: 0.23037932813167572
Validation loss: 1.4190627310865669

Epoch: 6| Step: 13
Training loss: 0.23826895654201508
Validation loss: 1.4522268092760475

Epoch: 463| Step: 0
Training loss: 0.19357427954673767
Validation loss: 1.410789910183158

Epoch: 6| Step: 1
Training loss: 0.278546005487442
Validation loss: 1.3972228534760014

Epoch: 6| Step: 2
Training loss: 0.15064239501953125
Validation loss: 1.4234158364675378

Epoch: 6| Step: 3
Training loss: 0.16885919868946075
Validation loss: 1.412336730187939

Epoch: 6| Step: 4
Training loss: 0.16313351690769196
Validation loss: 1.463279124229185

Epoch: 6| Step: 5
Training loss: 0.1889970302581787
Validation loss: 1.4577153651945052

Epoch: 6| Step: 6
Training loss: 0.27234983444213867
Validation loss: 1.46966508383392

Epoch: 6| Step: 7
Training loss: 0.12157687544822693
Validation loss: 1.457660513539468

Epoch: 6| Step: 8
Training loss: 0.13637202978134155
Validation loss: 1.4418166234929075

Epoch: 6| Step: 9
Training loss: 0.2037828117609024
Validation loss: 1.4428139912184847

Epoch: 6| Step: 10
Training loss: 0.13043223321437836
Validation loss: 1.4234967129204863

Epoch: 6| Step: 11
Training loss: 0.15015244483947754
Validation loss: 1.3872397830409389

Epoch: 6| Step: 12
Training loss: 0.09993821382522583
Validation loss: 1.3757296198157853

Epoch: 6| Step: 13
Training loss: 0.040829963982105255
Validation loss: 1.3775879862487956

Epoch: 464| Step: 0
Training loss: 0.15156644582748413
Validation loss: 1.3811227070387972

Epoch: 6| Step: 1
Training loss: 0.09636326134204865
Validation loss: 1.4086337691994124

Epoch: 6| Step: 2
Training loss: 0.10681630671024323
Validation loss: 1.409900547355734

Epoch: 6| Step: 3
Training loss: 0.14989127218723297
Validation loss: 1.4340960876916045

Epoch: 6| Step: 4
Training loss: 0.23542234301567078
Validation loss: 1.4769090619138492

Epoch: 6| Step: 5
Training loss: 0.09120883792638779
Validation loss: 1.475505845521086

Epoch: 6| Step: 6
Training loss: 0.16539961099624634
Validation loss: 1.4720936513716174

Epoch: 6| Step: 7
Training loss: 0.26022598147392273
Validation loss: 1.461170163205875

Epoch: 6| Step: 8
Training loss: 0.20404666662216187
Validation loss: 1.4619413845000728

Epoch: 6| Step: 9
Training loss: 0.1910373568534851
Validation loss: 1.499646641874826

Epoch: 6| Step: 10
Training loss: 0.14252692461013794
Validation loss: 1.4875677221564836

Epoch: 6| Step: 11
Training loss: 0.10526196658611298
Validation loss: 1.4427131632322907

Epoch: 6| Step: 12
Training loss: 0.14490462839603424
Validation loss: 1.463301771430559

Epoch: 6| Step: 13
Training loss: 0.0641128197312355
Validation loss: 1.4368377975238267

Epoch: 465| Step: 0
Training loss: 0.10508966445922852
Validation loss: 1.4488880307443681

Epoch: 6| Step: 1
Training loss: 0.2928048372268677
Validation loss: 1.4235989714181552

Epoch: 6| Step: 2
Training loss: 0.25337815284729004
Validation loss: 1.420595411972333

Epoch: 6| Step: 3
Training loss: 0.09020038694143295
Validation loss: 1.3942530911455873

Epoch: 6| Step: 4
Training loss: 0.11940433830022812
Validation loss: 1.3809379608400407

Epoch: 6| Step: 5
Training loss: 0.13105179369449615
Validation loss: 1.3875409569791568

Epoch: 6| Step: 6
Training loss: 0.2161206603050232
Validation loss: 1.420365423284551

Epoch: 6| Step: 7
Training loss: 0.1270778328180313
Validation loss: 1.3884506430677188

Epoch: 6| Step: 8
Training loss: 0.09758360683917999
Validation loss: 1.3712022214807489

Epoch: 6| Step: 9
Training loss: 0.19410337507724762
Validation loss: 1.398905941235122

Epoch: 6| Step: 10
Training loss: 0.06691937148571014
Validation loss: 1.3880059026902722

Epoch: 6| Step: 11
Training loss: 0.11517369002103806
Validation loss: 1.3932481965711039

Epoch: 6| Step: 12
Training loss: 0.11446838825941086
Validation loss: 1.4037213645955569

Epoch: 6| Step: 13
Training loss: 0.15211373567581177
Validation loss: 1.4134999705899147

Epoch: 466| Step: 0
Training loss: 0.1266205906867981
Validation loss: 1.3796195163521716

Epoch: 6| Step: 1
Training loss: 0.08294884860515594
Validation loss: 1.3893000618104012

Epoch: 6| Step: 2
Training loss: 0.08448991924524307
Validation loss: 1.3529910067076325

Epoch: 6| Step: 3
Training loss: 0.14632749557495117
Validation loss: 1.3825750889316681

Epoch: 6| Step: 4
Training loss: 0.19541305303573608
Validation loss: 1.3981520309243152

Epoch: 6| Step: 5
Training loss: 0.1643301546573639
Validation loss: 1.399284142319874

Epoch: 6| Step: 6
Training loss: 0.21065789461135864
Validation loss: 1.4079139668454406

Epoch: 6| Step: 7
Training loss: 0.18935507535934448
Validation loss: 1.4190826416015625

Epoch: 6| Step: 8
Training loss: 0.12939205765724182
Validation loss: 1.4193656816277453

Epoch: 6| Step: 9
Training loss: 0.22761298716068268
Validation loss: 1.4492433417227961

Epoch: 6| Step: 10
Training loss: 0.07826253771781921
Validation loss: 1.4365040602222565

Epoch: 6| Step: 11
Training loss: 0.08287857472896576
Validation loss: 1.4511472704590007

Epoch: 6| Step: 12
Training loss: 0.09501618891954422
Validation loss: 1.4489807236579157

Epoch: 6| Step: 13
Training loss: 0.1509549915790558
Validation loss: 1.4615534204308704

Epoch: 467| Step: 0
Training loss: 0.1493467390537262
Validation loss: 1.4451747402068107

Epoch: 6| Step: 1
Training loss: 0.12413138896226883
Validation loss: 1.428801159704885

Epoch: 6| Step: 2
Training loss: 0.28461870551109314
Validation loss: 1.377265671248077

Epoch: 6| Step: 3
Training loss: 0.18304623663425446
Validation loss: 1.412326858889672

Epoch: 6| Step: 4
Training loss: 0.3108818531036377
Validation loss: 1.4117085023592877

Epoch: 6| Step: 5
Training loss: 0.24005891382694244
Validation loss: 1.408262054125468

Epoch: 6| Step: 6
Training loss: 0.15542922914028168
Validation loss: 1.4013346395184916

Epoch: 6| Step: 7
Training loss: 0.11296399682760239
Validation loss: 1.4094860797287316

Epoch: 6| Step: 8
Training loss: 0.13821683824062347
Validation loss: 1.4429325185796267

Epoch: 6| Step: 9
Training loss: 0.36051610112190247
Validation loss: 1.4843554381401307

Epoch: 6| Step: 10
Training loss: 0.20821742713451385
Validation loss: 1.5078094902858938

Epoch: 6| Step: 11
Training loss: 0.12128643691539764
Validation loss: 1.4846518860068372

Epoch: 6| Step: 12
Training loss: 0.18004977703094482
Validation loss: 1.5086046162471975

Epoch: 6| Step: 13
Training loss: 0.15257516503334045
Validation loss: 1.451621606785764

Epoch: 468| Step: 0
Training loss: 0.17776794731616974
Validation loss: 1.4591810331549695

Epoch: 6| Step: 1
Training loss: 0.11068671196699142
Validation loss: 1.4267740544452463

Epoch: 6| Step: 2
Training loss: 0.23623238503932953
Validation loss: 1.4098138834840508

Epoch: 6| Step: 3
Training loss: 0.1102723702788353
Validation loss: 1.3967593575036654

Epoch: 6| Step: 4
Training loss: 0.12301693856716156
Validation loss: 1.3886930968171807

Epoch: 6| Step: 5
Training loss: 0.22292296588420868
Validation loss: 1.3737465168840142

Epoch: 6| Step: 6
Training loss: 0.17595168948173523
Validation loss: 1.387464895043322

Epoch: 6| Step: 7
Training loss: 0.2616046667098999
Validation loss: 1.3819350017014371

Epoch: 6| Step: 8
Training loss: 0.3047139644622803
Validation loss: 1.3789776384189565

Epoch: 6| Step: 9
Training loss: 0.15122273564338684
Validation loss: 1.4002356561281348

Epoch: 6| Step: 10
Training loss: 0.15037325024604797
Validation loss: 1.3812173848511071

Epoch: 6| Step: 11
Training loss: 0.10188861936330795
Validation loss: 1.3865603400814919

Epoch: 6| Step: 12
Training loss: 0.1181713193655014
Validation loss: 1.4047357664313367

Epoch: 6| Step: 13
Training loss: 0.1169424057006836
Validation loss: 1.4238063225182154

Epoch: 469| Step: 0
Training loss: 0.14333942532539368
Validation loss: 1.4341857035954793

Epoch: 6| Step: 1
Training loss: 0.09705239534378052
Validation loss: 1.4230014867680048

Epoch: 6| Step: 2
Training loss: 0.23927736282348633
Validation loss: 1.4258047316664009

Epoch: 6| Step: 3
Training loss: 0.07969440519809723
Validation loss: 1.426382557038338

Epoch: 6| Step: 4
Training loss: 0.23305416107177734
Validation loss: 1.4284665366654754

Epoch: 6| Step: 5
Training loss: 0.0956183671951294
Validation loss: 1.4082240814803748

Epoch: 6| Step: 6
Training loss: 0.104315385222435
Validation loss: 1.447605445820798

Epoch: 6| Step: 7
Training loss: 0.14836382865905762
Validation loss: 1.462629537428579

Epoch: 6| Step: 8
Training loss: 0.12767556309700012
Validation loss: 1.493546091100221

Epoch: 6| Step: 9
Training loss: 0.11260339617729187
Validation loss: 1.5182438653002504

Epoch: 6| Step: 10
Training loss: 0.12761113047599792
Validation loss: 1.4836390095372354

Epoch: 6| Step: 11
Training loss: 0.27840399742126465
Validation loss: 1.4617885440908454

Epoch: 6| Step: 12
Training loss: 0.14295610785484314
Validation loss: 1.4246513638445126

Epoch: 6| Step: 13
Training loss: 0.3180927038192749
Validation loss: 1.4214666056376632

Epoch: 470| Step: 0
Training loss: 0.12952019274234772
Validation loss: 1.4084164557918426

Epoch: 6| Step: 1
Training loss: 0.34510084986686707
Validation loss: 1.402931897870956

Epoch: 6| Step: 2
Training loss: 0.11650370061397552
Validation loss: 1.348345055375048

Epoch: 6| Step: 3
Training loss: 0.22617773711681366
Validation loss: 1.3631612190636255

Epoch: 6| Step: 4
Training loss: 0.10599391162395477
Validation loss: 1.3755487459962086

Epoch: 6| Step: 5
Training loss: 0.08079754561185837
Validation loss: 1.4163634059249715

Epoch: 6| Step: 6
Training loss: 0.09767810255289078
Validation loss: 1.4456046127503919

Epoch: 6| Step: 7
Training loss: 0.1447046548128128
Validation loss: 1.4950324822497625

Epoch: 6| Step: 8
Training loss: 0.18748797476291656
Validation loss: 1.497979046196066

Epoch: 6| Step: 9
Training loss: 0.21792766451835632
Validation loss: 1.460467028361495

Epoch: 6| Step: 10
Training loss: 0.0985770970582962
Validation loss: 1.4312459512423443

Epoch: 6| Step: 11
Training loss: 0.1149187758564949
Validation loss: 1.4018550188310686

Epoch: 6| Step: 12
Training loss: 0.16372685134410858
Validation loss: 1.393769266784832

Epoch: 6| Step: 13
Training loss: 0.14285802841186523
Validation loss: 1.3394741550568612

Epoch: 471| Step: 0
Training loss: 0.10994119942188263
Validation loss: 1.3719603086030612

Epoch: 6| Step: 1
Training loss: 0.09612549096345901
Validation loss: 1.363924975036293

Epoch: 6| Step: 2
Training loss: 0.22969290614128113
Validation loss: 1.3464443722078878

Epoch: 6| Step: 3
Training loss: 0.34087610244750977
Validation loss: 1.3552942916911135

Epoch: 6| Step: 4
Training loss: 0.17851069569587708
Validation loss: 1.35463624359459

Epoch: 6| Step: 5
Training loss: 0.14971274137496948
Validation loss: 1.3512217870322607

Epoch: 6| Step: 6
Training loss: 0.11539006233215332
Validation loss: 1.4011025133953299

Epoch: 6| Step: 7
Training loss: 0.2806706428527832
Validation loss: 1.4459274199701124

Epoch: 6| Step: 8
Training loss: 0.1075560674071312
Validation loss: 1.5023339422800208

Epoch: 6| Step: 9
Training loss: 0.2259524166584015
Validation loss: 1.486339367846007

Epoch: 6| Step: 10
Training loss: 0.11063531786203384
Validation loss: 1.4885487620548536

Epoch: 6| Step: 11
Training loss: 0.20609647035598755
Validation loss: 1.4889676570892334

Epoch: 6| Step: 12
Training loss: 0.11396536976099014
Validation loss: 1.4464194210626746

Epoch: 6| Step: 13
Training loss: 0.1188071072101593
Validation loss: 1.451680015492183

Epoch: 472| Step: 0
Training loss: 0.27732381224632263
Validation loss: 1.4358470401456278

Epoch: 6| Step: 1
Training loss: 0.11537279933691025
Validation loss: 1.4380712983428792

Epoch: 6| Step: 2
Training loss: 0.16240470111370087
Validation loss: 1.4096334954743743

Epoch: 6| Step: 3
Training loss: 0.2475491762161255
Validation loss: 1.4137702911130843

Epoch: 6| Step: 4
Training loss: 0.16207841038703918
Validation loss: 1.4057593653278966

Epoch: 6| Step: 5
Training loss: 0.1376790702342987
Validation loss: 1.4074497235718595

Epoch: 6| Step: 6
Training loss: 0.13745976984500885
Validation loss: 1.4592761788316952

Epoch: 6| Step: 7
Training loss: 0.13961011171340942
Validation loss: 1.4610565605983938

Epoch: 6| Step: 8
Training loss: 0.09137330204248428
Validation loss: 1.4671770872608307

Epoch: 6| Step: 9
Training loss: 0.18762049078941345
Validation loss: 1.4986360008998583

Epoch: 6| Step: 10
Training loss: 0.1063569039106369
Validation loss: 1.5157133404926588

Epoch: 6| Step: 11
Training loss: 0.17474937438964844
Validation loss: 1.5094807955526537

Epoch: 6| Step: 12
Training loss: 0.2425934076309204
Validation loss: 1.4442927222098074

Epoch: 6| Step: 13
Training loss: 0.07355475425720215
Validation loss: 1.415175276417886

Epoch: 473| Step: 0
Training loss: 0.1507103145122528
Validation loss: 1.3751431959931568

Epoch: 6| Step: 1
Training loss: 0.2550838589668274
Validation loss: 1.3531176428641043

Epoch: 6| Step: 2
Training loss: 0.16910988092422485
Validation loss: 1.3490821430760045

Epoch: 6| Step: 3
Training loss: 0.239709734916687
Validation loss: 1.3572703676839029

Epoch: 6| Step: 4
Training loss: 0.20828968286514282
Validation loss: 1.3702044608772441

Epoch: 6| Step: 5
Training loss: 0.14049115777015686
Validation loss: 1.3799736038331063

Epoch: 6| Step: 6
Training loss: 0.12326060980558395
Validation loss: 1.4038003824090446

Epoch: 6| Step: 7
Training loss: 0.09868716448545456
Validation loss: 1.43511381969657

Epoch: 6| Step: 8
Training loss: 0.2975085377693176
Validation loss: 1.4561657456941501

Epoch: 6| Step: 9
Training loss: 0.16317519545555115
Validation loss: 1.4912067574839438

Epoch: 6| Step: 10
Training loss: 0.18461768329143524
Validation loss: 1.5340107076911516

Epoch: 6| Step: 11
Training loss: 0.15314731001853943
Validation loss: 1.5203198040685346

Epoch: 6| Step: 12
Training loss: 0.13787484169006348
Validation loss: 1.5502958067001835

Epoch: 6| Step: 13
Training loss: 0.18645994365215302
Validation loss: 1.4930034568232875

Epoch: 474| Step: 0
Training loss: 0.10029873996973038
Validation loss: 1.438500412048832

Epoch: 6| Step: 1
Training loss: 0.24243129789829254
Validation loss: 1.430647744286445

Epoch: 6| Step: 2
Training loss: 0.0884886234998703
Validation loss: 1.424921549776549

Epoch: 6| Step: 3
Training loss: 0.1567162275314331
Validation loss: 1.4225644603852303

Epoch: 6| Step: 4
Training loss: 0.16752028465270996
Validation loss: 1.4017707686270438

Epoch: 6| Step: 5
Training loss: 0.12969879806041718
Validation loss: 1.4383328806969427

Epoch: 6| Step: 6
Training loss: 0.17104969918727875
Validation loss: 1.4034708238417102

Epoch: 6| Step: 7
Training loss: 0.14228588342666626
Validation loss: 1.4205980236812303

Epoch: 6| Step: 8
Training loss: 0.15151028335094452
Validation loss: 1.4298087307201919

Epoch: 6| Step: 9
Training loss: 0.16021627187728882
Validation loss: 1.465729381448479

Epoch: 6| Step: 10
Training loss: 0.1752794235944748
Validation loss: 1.4687792216577837

Epoch: 6| Step: 11
Training loss: 0.1298065036535263
Validation loss: 1.4657972115342335

Epoch: 6| Step: 12
Training loss: 0.23949980735778809
Validation loss: 1.4613334555779733

Epoch: 6| Step: 13
Training loss: 0.08424045145511627
Validation loss: 1.4886972699114072

Epoch: 475| Step: 0
Training loss: 0.11719381809234619
Validation loss: 1.461756585746683

Epoch: 6| Step: 1
Training loss: 0.13002848625183105
Validation loss: 1.4284980668816516

Epoch: 6| Step: 2
Training loss: 0.16798587143421173
Validation loss: 1.4676209995823521

Epoch: 6| Step: 3
Training loss: 0.15171709656715393
Validation loss: 1.4404563301353044

Epoch: 6| Step: 4
Training loss: 0.11960969865322113
Validation loss: 1.4416436674774333

Epoch: 6| Step: 5
Training loss: 0.17564153671264648
Validation loss: 1.4061463827727942

Epoch: 6| Step: 6
Training loss: 0.24143098294734955
Validation loss: 1.4264128464524464

Epoch: 6| Step: 7
Training loss: 0.11166319251060486
Validation loss: 1.3741862991804719

Epoch: 6| Step: 8
Training loss: 0.161700040102005
Validation loss: 1.4039785990151026

Epoch: 6| Step: 9
Training loss: 0.15444763004779816
Validation loss: 1.4296658019865713

Epoch: 6| Step: 10
Training loss: 0.1716051697731018
Validation loss: 1.4259747689770115

Epoch: 6| Step: 11
Training loss: 0.15745380520820618
Validation loss: 1.4419452387799498

Epoch: 6| Step: 12
Training loss: 0.10695140063762665
Validation loss: 1.4747359887246163

Epoch: 6| Step: 13
Training loss: 0.3471825122833252
Validation loss: 1.4604162093131774

Epoch: 476| Step: 0
Training loss: 0.23650506138801575
Validation loss: 1.4568702367044264

Epoch: 6| Step: 1
Training loss: 0.2900649309158325
Validation loss: 1.479399755436887

Epoch: 6| Step: 2
Training loss: 0.08099940419197083
Validation loss: 1.4489536029036327

Epoch: 6| Step: 3
Training loss: 0.2532222867012024
Validation loss: 1.4609281683480868

Epoch: 6| Step: 4
Training loss: 0.21243855357170105
Validation loss: 1.4418532912449171

Epoch: 6| Step: 5
Training loss: 0.10511450469493866
Validation loss: 1.446385734824724

Epoch: 6| Step: 6
Training loss: 0.1576625406742096
Validation loss: 1.4607471919828845

Epoch: 6| Step: 7
Training loss: 0.13207823038101196
Validation loss: 1.4585737336066462

Epoch: 6| Step: 8
Training loss: 0.1386042833328247
Validation loss: 1.4553214721782233

Epoch: 6| Step: 9
Training loss: 0.09890923649072647
Validation loss: 1.4724800086790515

Epoch: 6| Step: 10
Training loss: 0.2638086676597595
Validation loss: 1.4723219512611307

Epoch: 6| Step: 11
Training loss: 0.10598619282245636
Validation loss: 1.4711171145080237

Epoch: 6| Step: 12
Training loss: 0.1300891935825348
Validation loss: 1.4523876290167532

Epoch: 6| Step: 13
Training loss: 0.0767158567905426
Validation loss: 1.462506526900876

Epoch: 477| Step: 0
Training loss: 0.07044509053230286
Validation loss: 1.4391960097897438

Epoch: 6| Step: 1
Training loss: 0.07759390771389008
Validation loss: 1.3932632086097554

Epoch: 6| Step: 2
Training loss: 0.14082249999046326
Validation loss: 1.4004993682266564

Epoch: 6| Step: 3
Training loss: 0.23674100637435913
Validation loss: 1.3958033015651088

Epoch: 6| Step: 4
Training loss: 0.09978120028972626
Validation loss: 1.3798815441387955

Epoch: 6| Step: 5
Training loss: 0.3127034902572632
Validation loss: 1.399567231055229

Epoch: 6| Step: 6
Training loss: 0.1202484592795372
Validation loss: 1.4080610326541367

Epoch: 6| Step: 7
Training loss: 0.10428398102521896
Validation loss: 1.4334793770185081

Epoch: 6| Step: 8
Training loss: 0.27391675114631653
Validation loss: 1.4541621874737483

Epoch: 6| Step: 9
Training loss: 0.15246880054473877
Validation loss: 1.4397582110538278

Epoch: 6| Step: 10
Training loss: 0.1707581877708435
Validation loss: 1.4581880108002694

Epoch: 6| Step: 11
Training loss: 0.08596085011959076
Validation loss: 1.4524374751634495

Epoch: 6| Step: 12
Training loss: 0.10861899703741074
Validation loss: 1.4706102404543149

Epoch: 6| Step: 13
Training loss: 0.13988405466079712
Validation loss: 1.4314844326306415

Epoch: 478| Step: 0
Training loss: 0.42622506618499756
Validation loss: 1.4503719499034267

Epoch: 6| Step: 1
Training loss: 0.12929099798202515
Validation loss: 1.4387609292102117

Epoch: 6| Step: 2
Training loss: 0.15774746239185333
Validation loss: 1.4267656905676729

Epoch: 6| Step: 3
Training loss: 0.13472425937652588
Validation loss: 1.428630171283599

Epoch: 6| Step: 4
Training loss: 0.09900352358818054
Validation loss: 1.4301513561638453

Epoch: 6| Step: 5
Training loss: 0.11298207938671112
Validation loss: 1.439903837378307

Epoch: 6| Step: 6
Training loss: 0.09665574133396149
Validation loss: 1.4226770324091758

Epoch: 6| Step: 7
Training loss: 0.09989672899246216
Validation loss: 1.4380724135265555

Epoch: 6| Step: 8
Training loss: 0.21850794553756714
Validation loss: 1.4584064970734298

Epoch: 6| Step: 9
Training loss: 0.12448911368846893
Validation loss: 1.4475507684933242

Epoch: 6| Step: 10
Training loss: 0.10592107474803925
Validation loss: 1.4461025050891343

Epoch: 6| Step: 11
Training loss: 0.11644753813743591
Validation loss: 1.4069383157196866

Epoch: 6| Step: 12
Training loss: 0.09307914972305298
Validation loss: 1.389996967008037

Epoch: 6| Step: 13
Training loss: 0.12805525958538055
Validation loss: 1.4113856951395671

Epoch: 479| Step: 0
Training loss: 0.09401364624500275
Validation loss: 1.3857812009831911

Epoch: 6| Step: 1
Training loss: 0.29568153619766235
Validation loss: 1.3966755738822363

Epoch: 6| Step: 2
Training loss: 0.12855184078216553
Validation loss: 1.3874068567829747

Epoch: 6| Step: 3
Training loss: 0.1477324664592743
Validation loss: 1.4057511642415037

Epoch: 6| Step: 4
Training loss: 0.08924385905265808
Validation loss: 1.38056735069521

Epoch: 6| Step: 5
Training loss: 0.16127373278141022
Validation loss: 1.3801236844831897

Epoch: 6| Step: 6
Training loss: 0.28348273038864136
Validation loss: 1.3868077378119192

Epoch: 6| Step: 7
Training loss: 0.12040290236473083
Validation loss: 1.3635430951272287

Epoch: 6| Step: 8
Training loss: 0.1537361741065979
Validation loss: 1.3866121871497041

Epoch: 6| Step: 9
Training loss: 0.11416605114936829
Validation loss: 1.372711258549844

Epoch: 6| Step: 10
Training loss: 0.10771045833826065
Validation loss: 1.3777330101177256

Epoch: 6| Step: 11
Training loss: 0.0964231789112091
Validation loss: 1.3885630497368433

Epoch: 6| Step: 12
Training loss: 0.09768112003803253
Validation loss: 1.4272421277979368

Epoch: 6| Step: 13
Training loss: 0.11975100636482239
Validation loss: 1.4788943644492858

Epoch: 480| Step: 0
Training loss: 0.11225760728120804
Validation loss: 1.464853266234039

Epoch: 6| Step: 1
Training loss: 0.1958855390548706
Validation loss: 1.5134867647642731

Epoch: 6| Step: 2
Training loss: 0.11801569163799286
Validation loss: 1.462297119120116

Epoch: 6| Step: 3
Training loss: 0.19196847081184387
Validation loss: 1.4212083649891678

Epoch: 6| Step: 4
Training loss: 0.10762114822864532
Validation loss: 1.4038002939634426

Epoch: 6| Step: 5
Training loss: 0.10081367939710617
Validation loss: 1.39469745274513

Epoch: 6| Step: 6
Training loss: 0.19339650869369507
Validation loss: 1.3746496579980338

Epoch: 6| Step: 7
Training loss: 0.09924648702144623
Validation loss: 1.3890259701718566

Epoch: 6| Step: 8
Training loss: 0.09164315462112427
Validation loss: 1.3848093927547496

Epoch: 6| Step: 9
Training loss: 0.11292602866888046
Validation loss: 1.41173941217443

Epoch: 6| Step: 10
Training loss: 0.0870559960603714
Validation loss: 1.4161276676321541

Epoch: 6| Step: 11
Training loss: 0.11774677783250809
Validation loss: 1.4312997300137755

Epoch: 6| Step: 12
Training loss: 0.35459887981414795
Validation loss: 1.4247957141168657

Epoch: 6| Step: 13
Training loss: 0.20067381858825684
Validation loss: 1.4500198979531564

Epoch: 481| Step: 0
Training loss: 0.07497507333755493
Validation loss: 1.4852295549966956

Epoch: 6| Step: 1
Training loss: 0.2993745803833008
Validation loss: 1.4979746264796103

Epoch: 6| Step: 2
Training loss: 0.11587415635585785
Validation loss: 1.5155429250450545

Epoch: 6| Step: 3
Training loss: 0.22124499082565308
Validation loss: 1.4853780513168664

Epoch: 6| Step: 4
Training loss: 0.08715947717428207
Validation loss: 1.439109440772764

Epoch: 6| Step: 5
Training loss: 0.0741250067949295
Validation loss: 1.406949980284578

Epoch: 6| Step: 6
Training loss: 0.1649107187986374
Validation loss: 1.370939104787765

Epoch: 6| Step: 7
Training loss: 0.1312035173177719
Validation loss: 1.3876609597154843

Epoch: 6| Step: 8
Training loss: 0.10846365243196487
Validation loss: 1.3606143331014982

Epoch: 6| Step: 9
Training loss: 0.12262193113565445
Validation loss: 1.326804187990004

Epoch: 6| Step: 10
Training loss: 0.28312361240386963
Validation loss: 1.3464493084979314

Epoch: 6| Step: 11
Training loss: 0.07203540205955505
Validation loss: 1.344627898226502

Epoch: 6| Step: 12
Training loss: 0.13222701847553253
Validation loss: 1.3736711471311507

Epoch: 6| Step: 13
Training loss: 0.36720550060272217
Validation loss: 1.398647451913485

Epoch: 482| Step: 0
Training loss: 0.23959249258041382
Validation loss: 1.4388715836309618

Epoch: 6| Step: 1
Training loss: 0.3585052788257599
Validation loss: 1.468105557144329

Epoch: 6| Step: 2
Training loss: 0.13620126247406006
Validation loss: 1.4349185612893873

Epoch: 6| Step: 3
Training loss: 0.2417609691619873
Validation loss: 1.3802333788205219

Epoch: 6| Step: 4
Training loss: 0.0695352703332901
Validation loss: 1.368223124934781

Epoch: 6| Step: 5
Training loss: 0.09453441947698593
Validation loss: 1.3337618151018698

Epoch: 6| Step: 6
Training loss: 0.1444958746433258
Validation loss: 1.3585012702531711

Epoch: 6| Step: 7
Training loss: 0.278751403093338
Validation loss: 1.3537454720466369

Epoch: 6| Step: 8
Training loss: 0.11524278670549393
Validation loss: 1.348092403463138

Epoch: 6| Step: 9
Training loss: 0.11830037087202072
Validation loss: 1.3629614935126355

Epoch: 6| Step: 10
Training loss: 0.12072165310382843
Validation loss: 1.3754031863263858

Epoch: 6| Step: 11
Training loss: 0.17370383441448212
Validation loss: 1.377698847042617

Epoch: 6| Step: 12
Training loss: 0.12892577052116394
Validation loss: 1.4159975192880119

Epoch: 6| Step: 13
Training loss: 0.13098731637001038
Validation loss: 1.407125743486548

Epoch: 483| Step: 0
Training loss: 0.09041646867990494
Validation loss: 1.4164300785269788

Epoch: 6| Step: 1
Training loss: 0.248764768242836
Validation loss: 1.4242281183119743

Epoch: 6| Step: 2
Training loss: 0.14900965988636017
Validation loss: 1.4389857207575152

Epoch: 6| Step: 3
Training loss: 0.1566518098115921
Validation loss: 1.47975678084999

Epoch: 6| Step: 4
Training loss: 0.14324116706848145
Validation loss: 1.455259205192648

Epoch: 6| Step: 5
Training loss: 0.15935814380645752
Validation loss: 1.4439601462374452

Epoch: 6| Step: 6
Training loss: 0.12639854848384857
Validation loss: 1.4469307571329095

Epoch: 6| Step: 7
Training loss: 0.1360514909029007
Validation loss: 1.4317324405075402

Epoch: 6| Step: 8
Training loss: 0.17825111746788025
Validation loss: 1.4492067111435758

Epoch: 6| Step: 9
Training loss: 0.18455204367637634
Validation loss: 1.4650995603171728

Epoch: 6| Step: 10
Training loss: 0.29896193742752075
Validation loss: 1.465608521174359

Epoch: 6| Step: 11
Training loss: 0.16662445664405823
Validation loss: 1.4530181807856406

Epoch: 6| Step: 12
Training loss: 0.051878537982702255
Validation loss: 1.4902779498407919

Epoch: 6| Step: 13
Training loss: 0.33368009328842163
Validation loss: 1.4927455276571295

Epoch: 484| Step: 0
Training loss: 0.2289172112941742
Validation loss: 1.5079944447804523

Epoch: 6| Step: 1
Training loss: 0.13146762549877167
Validation loss: 1.5234992978393391

Epoch: 6| Step: 2
Training loss: 0.20145511627197266
Validation loss: 1.5526181151790004

Epoch: 6| Step: 3
Training loss: 0.24915850162506104
Validation loss: 1.524443112393861

Epoch: 6| Step: 4
Training loss: 0.25866463780403137
Validation loss: 1.431732484089431

Epoch: 6| Step: 5
Training loss: 0.26377105712890625
Validation loss: 1.4074135711116176

Epoch: 6| Step: 6
Training loss: 0.24414804577827454
Validation loss: 1.369893939264359

Epoch: 6| Step: 7
Training loss: 0.2800420820713043
Validation loss: 1.3475712582629213

Epoch: 6| Step: 8
Training loss: 0.1903817057609558
Validation loss: 1.3412946706177087

Epoch: 6| Step: 9
Training loss: 0.12191818654537201
Validation loss: 1.3499057940257493

Epoch: 6| Step: 10
Training loss: 0.19057363271713257
Validation loss: 1.3304291405985433

Epoch: 6| Step: 11
Training loss: 0.08187371492385864
Validation loss: 1.336807345831266

Epoch: 6| Step: 12
Training loss: 0.1086675375699997
Validation loss: 1.3935773962287492

Epoch: 6| Step: 13
Training loss: 0.10672730952501297
Validation loss: 1.3859513780122161

Epoch: 485| Step: 0
Training loss: 0.2591153085231781
Validation loss: 1.4064715113691104

Epoch: 6| Step: 1
Training loss: 0.17034518718719482
Validation loss: 1.4706626143506778

Epoch: 6| Step: 2
Training loss: 0.17997723817825317
Validation loss: 1.449205429323258

Epoch: 6| Step: 3
Training loss: 0.20449650287628174
Validation loss: 1.4475701637165521

Epoch: 6| Step: 4
Training loss: 0.12680533528327942
Validation loss: 1.4204756553455065

Epoch: 6| Step: 5
Training loss: 0.19898279011249542
Validation loss: 1.3963491557746806

Epoch: 6| Step: 6
Training loss: 0.1471855640411377
Validation loss: 1.3770806648397957

Epoch: 6| Step: 7
Training loss: 0.12988820672035217
Validation loss: 1.3553566753223378

Epoch: 6| Step: 8
Training loss: 0.22098444402217865
Validation loss: 1.3422796354498914

Epoch: 6| Step: 9
Training loss: 0.14395608007907867
Validation loss: 1.3454207694658669

Epoch: 6| Step: 10
Training loss: 0.1094454750418663
Validation loss: 1.3068103226282264

Epoch: 6| Step: 11
Training loss: 0.11680751293897629
Validation loss: 1.3388793526157257

Epoch: 6| Step: 12
Training loss: 0.23462247848510742
Validation loss: 1.3705301387335664

Epoch: 6| Step: 13
Training loss: 0.07395921647548676
Validation loss: 1.3843406708009782

Epoch: 486| Step: 0
Training loss: 0.11183339357376099
Validation loss: 1.4289660530705606

Epoch: 6| Step: 1
Training loss: 0.14594179391860962
Validation loss: 1.4458003928584438

Epoch: 6| Step: 2
Training loss: 0.13738366961479187
Validation loss: 1.4431765028225478

Epoch: 6| Step: 3
Training loss: 0.1462498903274536
Validation loss: 1.4594177763949159

Epoch: 6| Step: 4
Training loss: 0.23714154958724976
Validation loss: 1.4320486117434759

Epoch: 6| Step: 5
Training loss: 0.14196757972240448
Validation loss: 1.4301914989307363

Epoch: 6| Step: 6
Training loss: 0.10093088448047638
Validation loss: 1.406640048949949

Epoch: 6| Step: 7
Training loss: 0.3402498960494995
Validation loss: 1.4156810801516297

Epoch: 6| Step: 8
Training loss: 0.22428487241268158
Validation loss: 1.4095513974466631

Epoch: 6| Step: 9
Training loss: 0.206377774477005
Validation loss: 1.419603491342196

Epoch: 6| Step: 10
Training loss: 0.2776283621788025
Validation loss: 1.456860880697927

Epoch: 6| Step: 11
Training loss: 0.2385070025920868
Validation loss: 1.4501746431473763

Epoch: 6| Step: 12
Training loss: 0.17187409102916718
Validation loss: 1.4593247034216439

Epoch: 6| Step: 13
Training loss: 0.14677385985851288
Validation loss: 1.514680452244256

Epoch: 487| Step: 0
Training loss: 0.19201399385929108
Validation loss: 1.5367132322762602

Epoch: 6| Step: 1
Training loss: 0.1569589078426361
Validation loss: 1.5429832730242001

Epoch: 6| Step: 2
Training loss: 0.07403546571731567
Validation loss: 1.4817661264891266

Epoch: 6| Step: 3
Training loss: 0.27550071477890015
Validation loss: 1.422837499649294

Epoch: 6| Step: 4
Training loss: 0.14081893861293793
Validation loss: 1.3916996320088704

Epoch: 6| Step: 5
Training loss: 0.1478407382965088
Validation loss: 1.3714928216831659

Epoch: 6| Step: 6
Training loss: 0.09145854413509369
Validation loss: 1.3595283268600382

Epoch: 6| Step: 7
Training loss: 0.12976977229118347
Validation loss: 1.36150562378668

Epoch: 6| Step: 8
Training loss: 0.13346385955810547
Validation loss: 1.3745157455885282

Epoch: 6| Step: 9
Training loss: 0.31347137689590454
Validation loss: 1.3664153647679154

Epoch: 6| Step: 10
Training loss: 0.2155735194683075
Validation loss: 1.3501831652015768

Epoch: 6| Step: 11
Training loss: 0.1126369833946228
Validation loss: 1.3633689611188826

Epoch: 6| Step: 12
Training loss: 0.16769640147686005
Validation loss: 1.3918084803447928

Epoch: 6| Step: 13
Training loss: 0.0878964364528656
Validation loss: 1.4113166998791438

Epoch: 488| Step: 0
Training loss: 0.24868044257164001
Validation loss: 1.4092398138456448

Epoch: 6| Step: 1
Training loss: 0.17843836545944214
Validation loss: 1.3800758238761657

Epoch: 6| Step: 2
Training loss: 0.40269532799720764
Validation loss: 1.4290822000913723

Epoch: 6| Step: 3
Training loss: 0.08397790789604187
Validation loss: 1.4163706225733603

Epoch: 6| Step: 4
Training loss: 0.14806091785430908
Validation loss: 1.3865347523843088

Epoch: 6| Step: 5
Training loss: 0.13822481036186218
Validation loss: 1.3810366738227107

Epoch: 6| Step: 6
Training loss: 0.1344032883644104
Validation loss: 1.4014249642690022

Epoch: 6| Step: 7
Training loss: 0.10827025771141052
Validation loss: 1.3826089430880804

Epoch: 6| Step: 8
Training loss: 0.11051367223262787
Validation loss: 1.4017396562842912

Epoch: 6| Step: 9
Training loss: 0.11497630178928375
Validation loss: 1.3762912596425703

Epoch: 6| Step: 10
Training loss: 0.0841258317232132
Validation loss: 1.3829531502980057

Epoch: 6| Step: 11
Training loss: 0.1252630352973938
Validation loss: 1.3990191605783278

Epoch: 6| Step: 12
Training loss: 0.09316658973693848
Validation loss: 1.4024898646980204

Epoch: 6| Step: 13
Training loss: 0.15079915523529053
Validation loss: 1.4321984949932303

Epoch: 489| Step: 0
Training loss: 0.13998040556907654
Validation loss: 1.4473408524708082

Epoch: 6| Step: 1
Training loss: 0.10439667105674744
Validation loss: 1.4435274806073917

Epoch: 6| Step: 2
Training loss: 0.10489521920681
Validation loss: 1.4745482302481128

Epoch: 6| Step: 3
Training loss: 0.1837150752544403
Validation loss: 1.4652121342638487

Epoch: 6| Step: 4
Training loss: 0.14523856341838837
Validation loss: 1.4817487315465045

Epoch: 6| Step: 5
Training loss: 0.1437571495771408
Validation loss: 1.48023812360661

Epoch: 6| Step: 6
Training loss: 0.12664958834648132
Validation loss: 1.4770129957506735

Epoch: 6| Step: 7
Training loss: 0.15726041793823242
Validation loss: 1.4967366098075785

Epoch: 6| Step: 8
Training loss: 0.12408082187175751
Validation loss: 1.4710526684279084

Epoch: 6| Step: 9
Training loss: 0.07628914713859558
Validation loss: 1.4687432448069255

Epoch: 6| Step: 10
Training loss: 0.1444489061832428
Validation loss: 1.4175734558413107

Epoch: 6| Step: 11
Training loss: 0.2697771489620209
Validation loss: 1.4483561079989198

Epoch: 6| Step: 12
Training loss: 0.2439529001712799
Validation loss: 1.4440472542598684

Epoch: 6| Step: 13
Training loss: 0.11527056246995926
Validation loss: 1.4534795156089209

Epoch: 490| Step: 0
Training loss: 0.09375673532485962
Validation loss: 1.4652631987807572

Epoch: 6| Step: 1
Training loss: 0.09136980772018433
Validation loss: 1.4782250581249115

Epoch: 6| Step: 2
Training loss: 0.15364444255828857
Validation loss: 1.5061973000085482

Epoch: 6| Step: 3
Training loss: 0.1577865183353424
Validation loss: 1.5045430749975226

Epoch: 6| Step: 4
Training loss: 0.11645945906639099
Validation loss: 1.5096875211243987

Epoch: 6| Step: 5
Training loss: 0.22505776584148407
Validation loss: 1.4837559596184762

Epoch: 6| Step: 6
Training loss: 0.08370096236467361
Validation loss: 1.4735525615753666

Epoch: 6| Step: 7
Training loss: 0.16196753084659576
Validation loss: 1.4504872560501099

Epoch: 6| Step: 8
Training loss: 0.10291383415460587
Validation loss: 1.440152621397408

Epoch: 6| Step: 9
Training loss: 0.12324927002191544
Validation loss: 1.4238233899557462

Epoch: 6| Step: 10
Training loss: 0.3886694312095642
Validation loss: 1.4285106979390627

Epoch: 6| Step: 11
Training loss: 0.12404090166091919
Validation loss: 1.4354491926008655

Epoch: 6| Step: 12
Training loss: 0.13061396777629852
Validation loss: 1.4414502561733287

Epoch: 6| Step: 13
Training loss: 0.08604941517114639
Validation loss: 1.4248627674195073

Epoch: 491| Step: 0
Training loss: 0.09667806327342987
Validation loss: 1.4399238389025453

Epoch: 6| Step: 1
Training loss: 0.08348063379526138
Validation loss: 1.4262896635199105

Epoch: 6| Step: 2
Training loss: 0.09586004912853241
Validation loss: 1.444963438536531

Epoch: 6| Step: 3
Training loss: 0.20663714408874512
Validation loss: 1.438089539927821

Epoch: 6| Step: 4
Training loss: 0.13819491863250732
Validation loss: 1.4623891974008212

Epoch: 6| Step: 5
Training loss: 0.05408117547631264
Validation loss: 1.4437949529258154

Epoch: 6| Step: 6
Training loss: 0.17246511578559875
Validation loss: 1.4427061465478712

Epoch: 6| Step: 7
Training loss: 0.09342820942401886
Validation loss: 1.4262867781423754

Epoch: 6| Step: 8
Training loss: 0.13835862278938293
Validation loss: 1.4116025278645177

Epoch: 6| Step: 9
Training loss: 0.11824803054332733
Validation loss: 1.4231092814476258

Epoch: 6| Step: 10
Training loss: 0.27437806129455566
Validation loss: 1.398694694683116

Epoch: 6| Step: 11
Training loss: 0.06547806411981583
Validation loss: 1.4354237215493315

Epoch: 6| Step: 12
Training loss: 0.1521252691745758
Validation loss: 1.4534819946494153

Epoch: 6| Step: 13
Training loss: 0.09241411089897156
Validation loss: 1.4364525156636392

Epoch: 492| Step: 0
Training loss: 0.08615357428789139
Validation loss: 1.4579290113141459

Epoch: 6| Step: 1
Training loss: 0.10824690759181976
Validation loss: 1.4334522126823344

Epoch: 6| Step: 2
Training loss: 0.07197488844394684
Validation loss: 1.4474220557879376

Epoch: 6| Step: 3
Training loss: 0.17023205757141113
Validation loss: 1.4386538395317652

Epoch: 6| Step: 4
Training loss: 0.10728811472654343
Validation loss: 1.4293658271912606

Epoch: 6| Step: 5
Training loss: 0.11854902654886246
Validation loss: 1.4105772741379277

Epoch: 6| Step: 6
Training loss: 0.12640532851219177
Validation loss: 1.4233954683426888

Epoch: 6| Step: 7
Training loss: 0.10146103799343109
Validation loss: 1.4107225543709212

Epoch: 6| Step: 8
Training loss: 0.1264369636774063
Validation loss: 1.4085025582262265

Epoch: 6| Step: 9
Training loss: 0.102816641330719
Validation loss: 1.4257846929693734

Epoch: 6| Step: 10
Training loss: 0.07386770099401474
Validation loss: 1.4127216935157776

Epoch: 6| Step: 11
Training loss: 0.20588569343090057
Validation loss: 1.4315162179290608

Epoch: 6| Step: 12
Training loss: 0.2679506540298462
Validation loss: 1.4295162564964705

Epoch: 6| Step: 13
Training loss: 0.07183252274990082
Validation loss: 1.4025383059696486

Epoch: 493| Step: 0
Training loss: 0.18726173043251038
Validation loss: 1.4544479693135908

Epoch: 6| Step: 1
Training loss: 0.06559932976961136
Validation loss: 1.4383217865420925

Epoch: 6| Step: 2
Training loss: 0.07851283252239227
Validation loss: 1.4448122811573807

Epoch: 6| Step: 3
Training loss: 0.06484690308570862
Validation loss: 1.4350984711800852

Epoch: 6| Step: 4
Training loss: 0.10911907255649567
Validation loss: 1.4182915610651816

Epoch: 6| Step: 5
Training loss: 0.10501851886510849
Validation loss: 1.409158678464992

Epoch: 6| Step: 6
Training loss: 0.1026463657617569
Validation loss: 1.4028769205975276

Epoch: 6| Step: 7
Training loss: 0.2351352572441101
Validation loss: 1.4095201710219025

Epoch: 6| Step: 8
Training loss: 0.19578424096107483
Validation loss: 1.4358840706527873

Epoch: 6| Step: 9
Training loss: 0.0425974540412426
Validation loss: 1.4201801835849721

Epoch: 6| Step: 10
Training loss: 0.10217510908842087
Validation loss: 1.4254499199569866

Epoch: 6| Step: 11
Training loss: 0.13107247650623322
Validation loss: 1.429189625606742

Epoch: 6| Step: 12
Training loss: 0.10050185769796371
Validation loss: 1.4525893490801576

Epoch: 6| Step: 13
Training loss: 0.08722366392612457
Validation loss: 1.4259049841152724

Epoch: 494| Step: 0
Training loss: 0.08252567052841187
Validation loss: 1.4403775456131145

Epoch: 6| Step: 1
Training loss: 0.14438901841640472
Validation loss: 1.423202919703658

Epoch: 6| Step: 2
Training loss: 0.1337299942970276
Validation loss: 1.4213335847341886

Epoch: 6| Step: 3
Training loss: 0.08786910772323608
Validation loss: 1.3865789636488883

Epoch: 6| Step: 4
Training loss: 0.24506233632564545
Validation loss: 1.3969811034458939

Epoch: 6| Step: 5
Training loss: 0.11383473873138428
Validation loss: 1.3866816438654417

Epoch: 6| Step: 6
Training loss: 0.09621033817529678
Validation loss: 1.391428711593792

Epoch: 6| Step: 7
Training loss: 0.11665263772010803
Validation loss: 1.395457208797496

Epoch: 6| Step: 8
Training loss: 0.25050780177116394
Validation loss: 1.4028613836534563

Epoch: 6| Step: 9
Training loss: 0.10670170187950134
Validation loss: 1.4367870451301656

Epoch: 6| Step: 10
Training loss: 0.11218629032373428
Validation loss: 1.4106221750218382

Epoch: 6| Step: 11
Training loss: 0.14374125003814697
Validation loss: 1.4284654881364556

Epoch: 6| Step: 12
Training loss: 0.11554018408060074
Validation loss: 1.4418512634051743

Epoch: 6| Step: 13
Training loss: 0.04565975442528725
Validation loss: 1.4333028536970898

Epoch: 495| Step: 0
Training loss: 0.16447770595550537
Validation loss: 1.44744788318552

Epoch: 6| Step: 1
Training loss: 0.0760887935757637
Validation loss: 1.4470428920561267

Epoch: 6| Step: 2
Training loss: 0.17431870102882385
Validation loss: 1.4303137845890497

Epoch: 6| Step: 3
Training loss: 0.05926596373319626
Validation loss: 1.4164336971057359

Epoch: 6| Step: 4
Training loss: 0.10225972533226013
Validation loss: 1.4369788182679044

Epoch: 6| Step: 5
Training loss: 0.07798363268375397
Validation loss: 1.4374191305970634

Epoch: 6| Step: 6
Training loss: 0.1010129302740097
Validation loss: 1.449533973970721

Epoch: 6| Step: 7
Training loss: 0.29877522587776184
Validation loss: 1.4344338986181444

Epoch: 6| Step: 8
Training loss: 0.13488338887691498
Validation loss: 1.4388123237958519

Epoch: 6| Step: 9
Training loss: 0.10617678612470627
Validation loss: 1.449976331444197

Epoch: 6| Step: 10
Training loss: 0.20473581552505493
Validation loss: 1.4661452436959872

Epoch: 6| Step: 11
Training loss: 0.13842424750328064
Validation loss: 1.4699156527878137

Epoch: 6| Step: 12
Training loss: 0.13649028539657593
Validation loss: 1.46343994140625

Epoch: 6| Step: 13
Training loss: 0.11313916742801666
Validation loss: 1.4134466186646493

Epoch: 496| Step: 0
Training loss: 0.11766090244054794
Validation loss: 1.4217983843177877

Epoch: 6| Step: 1
Training loss: 0.16691191494464874
Validation loss: 1.4039284067769204

Epoch: 6| Step: 2
Training loss: 0.11882499605417252
Validation loss: 1.3855807781219482

Epoch: 6| Step: 3
Training loss: 0.17794054746627808
Validation loss: 1.4011900142956806

Epoch: 6| Step: 4
Training loss: 0.10844332724809647
Validation loss: 1.3805487271278136

Epoch: 6| Step: 5
Training loss: 0.08841867744922638
Validation loss: 1.3805979169825071

Epoch: 6| Step: 6
Training loss: 0.18355344235897064
Validation loss: 1.3927925837937223

Epoch: 6| Step: 7
Training loss: 0.13483475148677826
Validation loss: 1.3938364828786542

Epoch: 6| Step: 8
Training loss: 0.08076266944408417
Validation loss: 1.3743840020190004

Epoch: 6| Step: 9
Training loss: 0.0700143501162529
Validation loss: 1.3831924520513064

Epoch: 6| Step: 10
Training loss: 0.14092910289764404
Validation loss: 1.376834943730344

Epoch: 6| Step: 11
Training loss: 0.1351878046989441
Validation loss: 1.378756352650222

Epoch: 6| Step: 12
Training loss: 0.15101467072963715
Validation loss: 1.3804740892943514

Epoch: 6| Step: 13
Training loss: 0.2696961760520935
Validation loss: 1.3980592450787943

Epoch: 497| Step: 0
Training loss: 0.19010630249977112
Validation loss: 1.4065891555560532

Epoch: 6| Step: 1
Training loss: 0.22755345702171326
Validation loss: 1.4313278762243127

Epoch: 6| Step: 2
Training loss: 0.1163935512304306
Validation loss: 1.4343681361085625

Epoch: 6| Step: 3
Training loss: 0.12450319528579712
Validation loss: 1.437335609107889

Epoch: 6| Step: 4
Training loss: 0.17861421406269073
Validation loss: 1.4553495683977682

Epoch: 6| Step: 5
Training loss: 0.11262694001197815
Validation loss: 1.473940824949613

Epoch: 6| Step: 6
Training loss: 0.07502081990242004
Validation loss: 1.4601911588381695

Epoch: 6| Step: 7
Training loss: 0.10616756975650787
Validation loss: 1.4719332994953278

Epoch: 6| Step: 8
Training loss: 0.17686903476715088
Validation loss: 1.4680334893606042

Epoch: 6| Step: 9
Training loss: 0.09373153746128082
Validation loss: 1.4439437684192453

Epoch: 6| Step: 10
Training loss: 0.12326143682003021
Validation loss: 1.4396043041700959

Epoch: 6| Step: 11
Training loss: 0.15358895063400269
Validation loss: 1.4641157504050963

Epoch: 6| Step: 12
Training loss: 0.09395118802785873
Validation loss: 1.480156983098676

Epoch: 6| Step: 13
Training loss: 0.06832604855298996
Validation loss: 1.4531352404625184

Epoch: 498| Step: 0
Training loss: 0.09850334376096725
Validation loss: 1.434376585868097

Epoch: 6| Step: 1
Training loss: 0.1462627351284027
Validation loss: 1.4446098266109344

Epoch: 6| Step: 2
Training loss: 0.13979747891426086
Validation loss: 1.4335337172272384

Epoch: 6| Step: 3
Training loss: 0.11959324032068253
Validation loss: 1.4559478708492812

Epoch: 6| Step: 4
Training loss: 0.23207861185073853
Validation loss: 1.4442322715636222

Epoch: 6| Step: 5
Training loss: 0.12364450097084045
Validation loss: 1.4606867708185667

Epoch: 6| Step: 6
Training loss: 0.14265179634094238
Validation loss: 1.4651051772538053

Epoch: 6| Step: 7
Training loss: 0.08423611521720886
Validation loss: 1.4629851169483636

Epoch: 6| Step: 8
Training loss: 0.1582203209400177
Validation loss: 1.512250413176834

Epoch: 6| Step: 9
Training loss: 0.12700247764587402
Validation loss: 1.4929105004956644

Epoch: 6| Step: 10
Training loss: 0.22713586688041687
Validation loss: 1.5011167282699256

Epoch: 6| Step: 11
Training loss: 0.16594508290290833
Validation loss: 1.4921814715990456

Epoch: 6| Step: 12
Training loss: 0.07086920738220215
Validation loss: 1.5224013572098107

Epoch: 6| Step: 13
Training loss: 0.09177161753177643
Validation loss: 1.4903245382411505

Epoch: 499| Step: 0
Training loss: 0.2865751385688782
Validation loss: 1.487507434301479

Epoch: 6| Step: 1
Training loss: 0.19736936688423157
Validation loss: 1.454700784016681

Epoch: 6| Step: 2
Training loss: 0.14462672173976898
Validation loss: 1.45717772681226

Epoch: 6| Step: 3
Training loss: 0.13445360958576202
Validation loss: 1.441467974775581

Epoch: 6| Step: 4
Training loss: 0.09566131234169006
Validation loss: 1.4627003823557208

Epoch: 6| Step: 5
Training loss: 0.09502720832824707
Validation loss: 1.4372499565924368

Epoch: 6| Step: 6
Training loss: 0.11685335636138916
Validation loss: 1.4338671225373463

Epoch: 6| Step: 7
Training loss: 0.13185551762580872
Validation loss: 1.4226242265393656

Epoch: 6| Step: 8
Training loss: 0.17760705947875977
Validation loss: 1.4405859234512493

Epoch: 6| Step: 9
Training loss: 0.1960310935974121
Validation loss: 1.4338843168750885

Epoch: 6| Step: 10
Training loss: 0.19742250442504883
Validation loss: 1.4541393082628968

Epoch: 6| Step: 11
Training loss: 0.09562249481678009
Validation loss: 1.4509885490581553

Epoch: 6| Step: 12
Training loss: 0.14675191044807434
Validation loss: 1.4509546410652898

Epoch: 6| Step: 13
Training loss: 0.08971622586250305
Validation loss: 1.4394211128193846

Epoch: 500| Step: 0
Training loss: 0.11228182911872864
Validation loss: 1.434842291698661

Epoch: 6| Step: 1
Training loss: 0.116850845515728
Validation loss: 1.3903342203427387

Epoch: 6| Step: 2
Training loss: 0.16641786694526672
Validation loss: 1.4015021759976622

Epoch: 6| Step: 3
Training loss: 0.15286943316459656
Validation loss: 1.3760210294877329

Epoch: 6| Step: 4
Training loss: 0.21363919973373413
Validation loss: 1.3986391521269275

Epoch: 6| Step: 5
Training loss: 0.11223316937685013
Validation loss: 1.3799988012160025

Epoch: 6| Step: 6
Training loss: 0.0802937000989914
Validation loss: 1.394006036943005

Epoch: 6| Step: 7
Training loss: 0.06907659024000168
Validation loss: 1.40687422854926

Epoch: 6| Step: 8
Training loss: 0.093637615442276
Validation loss: 1.42992740549067

Epoch: 6| Step: 9
Training loss: 0.14618732035160065
Validation loss: 1.413803178776977

Epoch: 6| Step: 10
Training loss: 0.15670864284038544
Validation loss: 1.412787865566951

Epoch: 6| Step: 11
Training loss: 0.26370519399642944
Validation loss: 1.4415656610201764

Epoch: 6| Step: 12
Training loss: 0.1840018332004547
Validation loss: 1.479740458790974

Epoch: 6| Step: 13
Training loss: 0.3842700719833374
Validation loss: 1.4251222097745506

Epoch: 501| Step: 0
Training loss: 0.15439054369926453
Validation loss: 1.4732356981564594

Epoch: 6| Step: 1
Training loss: 0.2203124463558197
Validation loss: 1.4377703077049666

Epoch: 6| Step: 2
Training loss: 0.1568240225315094
Validation loss: 1.4130741210394009

Epoch: 6| Step: 3
Training loss: 0.06427271664142609
Validation loss: 1.3746078629647531

Epoch: 6| Step: 4
Training loss: 0.12223045527935028
Validation loss: 1.3746563696092176

Epoch: 6| Step: 5
Training loss: 0.1221436858177185
Validation loss: 1.366281045380459

Epoch: 6| Step: 6
Training loss: 0.14059937000274658
Validation loss: 1.3764785284637122

Epoch: 6| Step: 7
Training loss: 0.25676649808883667
Validation loss: 1.3801690288769302

Epoch: 6| Step: 8
Training loss: 0.16391398012638092
Validation loss: 1.374179522196452

Epoch: 6| Step: 9
Training loss: 0.11496289819478989
Validation loss: 1.3927634518633607

Epoch: 6| Step: 10
Training loss: 0.21804510056972504
Validation loss: 1.4343026075311887

Epoch: 6| Step: 11
Training loss: 0.0671943873167038
Validation loss: 1.4601332327371002

Epoch: 6| Step: 12
Training loss: 0.10504678636789322
Validation loss: 1.4993750638859247

Epoch: 6| Step: 13
Training loss: 0.12368912249803543
Validation loss: 1.4685331788114322

Epoch: 502| Step: 0
Training loss: 0.2506304383277893
Validation loss: 1.4996055979882517

Epoch: 6| Step: 1
Training loss: 0.15719899535179138
Validation loss: 1.5181633054569204

Epoch: 6| Step: 2
Training loss: 0.32470524311065674
Validation loss: 1.474233768319571

Epoch: 6| Step: 3
Training loss: 0.07081636041402817
Validation loss: 1.4468088829389183

Epoch: 6| Step: 4
Training loss: 0.17197006940841675
Validation loss: 1.4632371523047005

Epoch: 6| Step: 5
Training loss: 0.07826104760169983
Validation loss: 1.4607639697290236

Epoch: 6| Step: 6
Training loss: 0.1362479329109192
Validation loss: 1.4735565057364843

Epoch: 6| Step: 7
Training loss: 0.16527320444583893
Validation loss: 1.457795489218927

Epoch: 6| Step: 8
Training loss: 0.13087595999240875
Validation loss: 1.4595439049505419

Epoch: 6| Step: 9
Training loss: 0.16365814208984375
Validation loss: 1.4531648787119056

Epoch: 6| Step: 10
Training loss: 0.1188775897026062
Validation loss: 1.4566937082557267

Epoch: 6| Step: 11
Training loss: 0.24388530850410461
Validation loss: 1.4500398174408944

Epoch: 6| Step: 12
Training loss: 0.11703023314476013
Validation loss: 1.4320475004052604

Epoch: 6| Step: 13
Training loss: 0.09105261415243149
Validation loss: 1.4168048558696624

Epoch: 503| Step: 0
Training loss: 0.15440106391906738
Validation loss: 1.4324945775411462

Epoch: 6| Step: 1
Training loss: 0.09758973121643066
Validation loss: 1.4428751814749934

Epoch: 6| Step: 2
Training loss: 0.1668042093515396
Validation loss: 1.4087879555199736

Epoch: 6| Step: 3
Training loss: 0.2078046202659607
Validation loss: 1.4192036319804449

Epoch: 6| Step: 4
Training loss: 0.21582165360450745
Validation loss: 1.4261926412582397

Epoch: 6| Step: 5
Training loss: 0.136222243309021
Validation loss: 1.4507120232428274

Epoch: 6| Step: 6
Training loss: 0.12015194445848465
Validation loss: 1.4320783038293161

Epoch: 6| Step: 7
Training loss: 0.10666172951459885
Validation loss: 1.4488391594220233

Epoch: 6| Step: 8
Training loss: 0.058176957070827484
Validation loss: 1.4528073905616679

Epoch: 6| Step: 9
Training loss: 0.07151594758033752
Validation loss: 1.4447372587778236

Epoch: 6| Step: 10
Training loss: 0.14930230379104614
Validation loss: 1.4473434571296937

Epoch: 6| Step: 11
Training loss: 0.33163994550704956
Validation loss: 1.4414927023713306

Epoch: 6| Step: 12
Training loss: 0.06646613776683807
Validation loss: 1.4600041873993412

Epoch: 6| Step: 13
Training loss: 0.08365872502326965
Validation loss: 1.480276135988133

Epoch: 504| Step: 0
Training loss: 0.10820241272449493
Validation loss: 1.4518890303950156

Epoch: 6| Step: 1
Training loss: 0.10858877748250961
Validation loss: 1.470002926805968

Epoch: 6| Step: 2
Training loss: 0.08763159811496735
Validation loss: 1.4458917148651615

Epoch: 6| Step: 3
Training loss: 0.13508746027946472
Validation loss: 1.4861651761557466

Epoch: 6| Step: 4
Training loss: 0.1576002985239029
Validation loss: 1.4779672379134803

Epoch: 6| Step: 5
Training loss: 0.19057732820510864
Validation loss: 1.448171705328008

Epoch: 6| Step: 6
Training loss: 0.10826615989208221
Validation loss: 1.4878005571262811

Epoch: 6| Step: 7
Training loss: 0.16440901160240173
Validation loss: 1.4569244666766095

Epoch: 6| Step: 8
Training loss: 0.08576168864965439
Validation loss: 1.4560944175207486

Epoch: 6| Step: 9
Training loss: 0.12229488044977188
Validation loss: 1.4434569240898214

Epoch: 6| Step: 10
Training loss: 0.1734805703163147
Validation loss: 1.434662752254035

Epoch: 6| Step: 11
Training loss: 0.22627748548984528
Validation loss: 1.4332275518807032

Epoch: 6| Step: 12
Training loss: 0.08525826036930084
Validation loss: 1.4216749283575243

Epoch: 6| Step: 13
Training loss: 0.07357177138328552
Validation loss: 1.4295629301378805

Epoch: 505| Step: 0
Training loss: 0.1179276630282402
Validation loss: 1.4197712136853127

Epoch: 6| Step: 1
Training loss: 0.20339669287204742
Validation loss: 1.4134680699276667

Epoch: 6| Step: 2
Training loss: 0.07961302250623703
Validation loss: 1.3744408148591236

Epoch: 6| Step: 3
Training loss: 0.11225008964538574
Validation loss: 1.400452293375487

Epoch: 6| Step: 4
Training loss: 0.10945054888725281
Validation loss: 1.4121037381951527

Epoch: 6| Step: 5
Training loss: 0.0812562108039856
Validation loss: 1.4296105074626144

Epoch: 6| Step: 6
Training loss: 0.06873802840709686
Validation loss: 1.3867783674629786

Epoch: 6| Step: 7
Training loss: 0.22756537795066833
Validation loss: 1.432841540664755

Epoch: 6| Step: 8
Training loss: 0.1273491233587265
Validation loss: 1.4351830149209628

Epoch: 6| Step: 9
Training loss: 0.09873786568641663
Validation loss: 1.4140604939512027

Epoch: 6| Step: 10
Training loss: 0.19838449358940125
Validation loss: 1.3994138356178039

Epoch: 6| Step: 11
Training loss: 0.09770083427429199
Validation loss: 1.412144555840441

Epoch: 6| Step: 12
Training loss: 0.12132707238197327
Validation loss: 1.441853044494506

Epoch: 6| Step: 13
Training loss: 0.07631213217973709
Validation loss: 1.4462122955629904

Epoch: 506| Step: 0
Training loss: 0.22098854184150696
Validation loss: 1.4425258207064804

Epoch: 6| Step: 1
Training loss: 0.18347811698913574
Validation loss: 1.4330634840073124

Epoch: 6| Step: 2
Training loss: 0.14474360644817352
Validation loss: 1.4273497494318153

Epoch: 6| Step: 3
Training loss: 0.14430788159370422
Validation loss: 1.4213542669050154

Epoch: 6| Step: 4
Training loss: 0.10133832693099976
Validation loss: 1.4302290985661168

Epoch: 6| Step: 5
Training loss: 0.10957440733909607
Validation loss: 1.4373887508146224

Epoch: 6| Step: 6
Training loss: 0.09422441571950912
Validation loss: 1.421473514649176

Epoch: 6| Step: 7
Training loss: 0.10946953296661377
Validation loss: 1.4409820815568328

Epoch: 6| Step: 8
Training loss: 0.08395910263061523
Validation loss: 1.413061616241291

Epoch: 6| Step: 9
Training loss: 0.115763358771801
Validation loss: 1.4262615275639359

Epoch: 6| Step: 10
Training loss: 0.1271333247423172
Validation loss: 1.4045308187443724

Epoch: 6| Step: 11
Training loss: 0.11508872359991074
Validation loss: 1.3671373192982008

Epoch: 6| Step: 12
Training loss: 0.08892454206943512
Validation loss: 1.351589874554706

Epoch: 6| Step: 13
Training loss: 0.0857938602566719
Validation loss: 1.3652521218022993

Epoch: 507| Step: 0
Training loss: 0.1413707435131073
Validation loss: 1.3596878103030625

Epoch: 6| Step: 1
Training loss: 0.16415011882781982
Validation loss: 1.3427357699281426

Epoch: 6| Step: 2
Training loss: 0.2634296119213104
Validation loss: 1.3608336935761154

Epoch: 6| Step: 3
Training loss: 0.11739067733287811
Validation loss: 1.3525663037453928

Epoch: 6| Step: 4
Training loss: 0.18767154216766357
Validation loss: 1.3573054895606091

Epoch: 6| Step: 5
Training loss: 0.07719942927360535
Validation loss: 1.4002286029118363

Epoch: 6| Step: 6
Training loss: 0.07725939154624939
Validation loss: 1.4273040602284093

Epoch: 6| Step: 7
Training loss: 0.14034289121627808
Validation loss: 1.4427619223953576

Epoch: 6| Step: 8
Training loss: 0.15910887718200684
Validation loss: 1.470437309434337

Epoch: 6| Step: 9
Training loss: 0.12480026483535767
Validation loss: 1.486582726560613

Epoch: 6| Step: 10
Training loss: 0.11262282729148865
Validation loss: 1.4776148616626699

Epoch: 6| Step: 11
Training loss: 0.07885505259037018
Validation loss: 1.4392217551508257

Epoch: 6| Step: 12
Training loss: 0.14050015807151794
Validation loss: 1.448406457901001

Epoch: 6| Step: 13
Training loss: 0.05954417958855629
Validation loss: 1.4194721611597205

Epoch: 508| Step: 0
Training loss: 0.12935525178909302
Validation loss: 1.4788858403441727

Epoch: 6| Step: 1
Training loss: 0.10050410032272339
Validation loss: 1.4837044169825893

Epoch: 6| Step: 2
Training loss: 0.09822165966033936
Validation loss: 1.513406180566357

Epoch: 6| Step: 3
Training loss: 0.1546379029750824
Validation loss: 1.4893624218561317

Epoch: 6| Step: 4
Training loss: 0.2541014850139618
Validation loss: 1.496215525493827

Epoch: 6| Step: 5
Training loss: 0.1034620851278305
Validation loss: 1.45053739957912

Epoch: 6| Step: 6
Training loss: 0.0844431221485138
Validation loss: 1.4555066862413961

Epoch: 6| Step: 7
Training loss: 0.12385538220405579
Validation loss: 1.4793363072538888

Epoch: 6| Step: 8
Training loss: 0.11429212987422943
Validation loss: 1.4525071485068208

Epoch: 6| Step: 9
Training loss: 0.26271480321884155
Validation loss: 1.4925829672044324

Epoch: 6| Step: 10
Training loss: 0.1727345883846283
Validation loss: 1.5029387345878027

Epoch: 6| Step: 11
Training loss: 0.09466368705034256
Validation loss: 1.4915894180215814

Epoch: 6| Step: 12
Training loss: 0.07083030045032501
Validation loss: 1.458632662732114

Epoch: 6| Step: 13
Training loss: 0.19152086973190308
Validation loss: 1.4479094743728638

Epoch: 509| Step: 0
Training loss: 0.2379072904586792
Validation loss: 1.4562483590136293

Epoch: 6| Step: 1
Training loss: 0.21906405687332153
Validation loss: 1.4445839274314143

Epoch: 6| Step: 2
Training loss: 0.11495397239923477
Validation loss: 1.4311150517514957

Epoch: 6| Step: 3
Training loss: 0.10912585258483887
Validation loss: 1.448634728308647

Epoch: 6| Step: 4
Training loss: 0.11078600585460663
Validation loss: 1.437242352834312

Epoch: 6| Step: 5
Training loss: 0.11180464178323746
Validation loss: 1.415852221109534

Epoch: 6| Step: 6
Training loss: 0.06669780611991882
Validation loss: 1.3951714192667315

Epoch: 6| Step: 7
Training loss: 0.2105838805437088
Validation loss: 1.4014884092474496

Epoch: 6| Step: 8
Training loss: 0.12182371318340302
Validation loss: 1.415389427574732

Epoch: 6| Step: 9
Training loss: 0.10670521855354309
Validation loss: 1.4045508023231261

Epoch: 6| Step: 10
Training loss: 0.0708848237991333
Validation loss: 1.4341470868356767

Epoch: 6| Step: 11
Training loss: 0.07414156198501587
Validation loss: 1.44453090365215

Epoch: 6| Step: 12
Training loss: 0.130447655916214
Validation loss: 1.4625080580352454

Epoch: 6| Step: 13
Training loss: 0.06922069936990738
Validation loss: 1.4330502248579455

Epoch: 510| Step: 0
Training loss: 0.10183911770582199
Validation loss: 1.434379659673219

Epoch: 6| Step: 1
Training loss: 0.1684708595275879
Validation loss: 1.4198163350423176

Epoch: 6| Step: 2
Training loss: 0.1022113487124443
Validation loss: 1.426822736699094

Epoch: 6| Step: 3
Training loss: 0.19505994021892548
Validation loss: 1.4076313780200096

Epoch: 6| Step: 4
Training loss: 0.19314779341220856
Validation loss: 1.390727436670693

Epoch: 6| Step: 5
Training loss: 0.09203934669494629
Validation loss: 1.4159233435507743

Epoch: 6| Step: 6
Training loss: 0.08543945848941803
Validation loss: 1.3729574500873525

Epoch: 6| Step: 7
Training loss: 0.11098881810903549
Validation loss: 1.4197377825296054

Epoch: 6| Step: 8
Training loss: 0.14360910654067993
Validation loss: 1.4102192437776955

Epoch: 6| Step: 9
Training loss: 0.10694575309753418
Validation loss: 1.403050345759238

Epoch: 6| Step: 10
Training loss: 0.08135329186916351
Validation loss: 1.4429160305248794

Epoch: 6| Step: 11
Training loss: 0.21043729782104492
Validation loss: 1.4370684687809279

Epoch: 6| Step: 12
Training loss: 0.1139972060918808
Validation loss: 1.4529315656231296

Epoch: 6| Step: 13
Training loss: 0.08361896872520447
Validation loss: 1.46157028085442

Epoch: 511| Step: 0
Training loss: 0.1027238667011261
Validation loss: 1.4129234372928579

Epoch: 6| Step: 1
Training loss: 0.10795629024505615
Validation loss: 1.409969409306844

Epoch: 6| Step: 2
Training loss: 0.09515529870986938
Validation loss: 1.4147433388617732

Epoch: 6| Step: 3
Training loss: 0.1378052979707718
Validation loss: 1.4359351165833012

Epoch: 6| Step: 4
Training loss: 0.09967255592346191
Validation loss: 1.4323467977585331

Epoch: 6| Step: 5
Training loss: 0.15222974121570587
Validation loss: 1.4177156045872679

Epoch: 6| Step: 6
Training loss: 0.12604022026062012
Validation loss: 1.4653003741336126

Epoch: 6| Step: 7
Training loss: 0.11788257956504822
Validation loss: 1.4415199115712156

Epoch: 6| Step: 8
Training loss: 0.07555817067623138
Validation loss: 1.4503920193641417

Epoch: 6| Step: 9
Training loss: 0.2493605613708496
Validation loss: 1.470381361182018

Epoch: 6| Step: 10
Training loss: 0.18677261471748352
Validation loss: 1.4301246968648766

Epoch: 6| Step: 11
Training loss: 0.18196779489517212
Validation loss: 1.424656965399301

Epoch: 6| Step: 12
Training loss: 0.12568166851997375
Validation loss: 1.4371798634529114

Epoch: 6| Step: 13
Training loss: 0.1071605384349823
Validation loss: 1.4168449717183267

Epoch: 512| Step: 0
Training loss: 0.09896387159824371
Validation loss: 1.4113166498881515

Epoch: 6| Step: 1
Training loss: 0.09624098986387253
Validation loss: 1.4012309646093717

Epoch: 6| Step: 2
Training loss: 0.08884049952030182
Validation loss: 1.3955762796504523

Epoch: 6| Step: 3
Training loss: 0.12660719454288483
Validation loss: 1.3910743946670203

Epoch: 6| Step: 4
Training loss: 0.09278278797864914
Validation loss: 1.3857055530753186

Epoch: 6| Step: 5
Training loss: 0.19882437586784363
Validation loss: 1.4229721958919237

Epoch: 6| Step: 6
Training loss: 0.210075244307518
Validation loss: 1.445124497977636

Epoch: 6| Step: 7
Training loss: 0.09423518925905228
Validation loss: 1.4410269670588995

Epoch: 6| Step: 8
Training loss: 0.0952516719698906
Validation loss: 1.4475109615633566

Epoch: 6| Step: 9
Training loss: 0.19494163990020752
Validation loss: 1.4402183358387282

Epoch: 6| Step: 10
Training loss: 0.08823906630277634
Validation loss: 1.4288160076705358

Epoch: 6| Step: 11
Training loss: 0.1170186698436737
Validation loss: 1.410431303003783

Epoch: 6| Step: 12
Training loss: 0.11161188781261444
Validation loss: 1.3990224176837551

Epoch: 6| Step: 13
Training loss: 0.13589051365852356
Validation loss: 1.3826037606885355

Epoch: 513| Step: 0
Training loss: 0.13823489844799042
Validation loss: 1.378971392108548

Epoch: 6| Step: 1
Training loss: 0.05416152998805046
Validation loss: 1.3842706705934258

Epoch: 6| Step: 2
Training loss: 0.08834033459424973
Validation loss: 1.3991873828313683

Epoch: 6| Step: 3
Training loss: 0.16835880279541016
Validation loss: 1.3873208504851147

Epoch: 6| Step: 4
Training loss: 0.18935486674308777
Validation loss: 1.3888277699870448

Epoch: 6| Step: 5
Training loss: 0.11186724901199341
Validation loss: 1.3855134889643679

Epoch: 6| Step: 6
Training loss: 0.0731872171163559
Validation loss: 1.4153866806337911

Epoch: 6| Step: 7
Training loss: 0.2133311927318573
Validation loss: 1.427299327747796

Epoch: 6| Step: 8
Training loss: 0.15765218436717987
Validation loss: 1.4374595233189162

Epoch: 6| Step: 9
Training loss: 0.06611700356006622
Validation loss: 1.4502289115741689

Epoch: 6| Step: 10
Training loss: 0.10516847670078278
Validation loss: 1.4428695132655482

Epoch: 6| Step: 11
Training loss: 0.0989445298910141
Validation loss: 1.4126494315362745

Epoch: 6| Step: 12
Training loss: 0.14095714688301086
Validation loss: 1.4718748331069946

Epoch: 6| Step: 13
Training loss: 0.13961060345172882
Validation loss: 1.4499078309664162

Epoch: 514| Step: 0
Training loss: 0.10286656022071838
Validation loss: 1.4728913512281192

Epoch: 6| Step: 1
Training loss: 0.10819713771343231
Validation loss: 1.468567721305355

Epoch: 6| Step: 2
Training loss: 0.11346261203289032
Validation loss: 1.4646825636586835

Epoch: 6| Step: 3
Training loss: 0.0823616161942482
Validation loss: 1.465607411117964

Epoch: 6| Step: 4
Training loss: 0.10369542986154556
Validation loss: 1.4693846074483727

Epoch: 6| Step: 5
Training loss: 0.09753228724002838
Validation loss: 1.4716665988327355

Epoch: 6| Step: 6
Training loss: 0.1333860158920288
Validation loss: 1.4685310150987358

Epoch: 6| Step: 7
Training loss: 0.12974542379379272
Validation loss: 1.4777144808923044

Epoch: 6| Step: 8
Training loss: 0.10016867518424988
Validation loss: 1.4681994863735732

Epoch: 6| Step: 9
Training loss: 0.20632967352867126
Validation loss: 1.4785535873905304

Epoch: 6| Step: 10
Training loss: 0.09357821941375732
Validation loss: 1.465177938502322

Epoch: 6| Step: 11
Training loss: 0.1408315747976303
Validation loss: 1.4343773241966002

Epoch: 6| Step: 12
Training loss: 0.12068524956703186
Validation loss: 1.4345866723727154

Epoch: 6| Step: 13
Training loss: 0.2398339956998825
Validation loss: 1.4356647601691626

Epoch: 515| Step: 0
Training loss: 0.1468612551689148
Validation loss: 1.386531417087842

Epoch: 6| Step: 1
Training loss: 0.10331806540489197
Validation loss: 1.3869578697348153

Epoch: 6| Step: 2
Training loss: 0.1519525647163391
Validation loss: 1.3742405913209403

Epoch: 6| Step: 3
Training loss: 0.21468985080718994
Validation loss: 1.3888628085454304

Epoch: 6| Step: 4
Training loss: 0.09572962671518326
Validation loss: 1.3713839823199856

Epoch: 6| Step: 5
Training loss: 0.16522686183452606
Validation loss: 1.3975802454897153

Epoch: 6| Step: 6
Training loss: 0.09583733230829239
Validation loss: 1.4130987159667476

Epoch: 6| Step: 7
Training loss: 0.14095452427864075
Validation loss: 1.430428667735028

Epoch: 6| Step: 8
Training loss: 0.11728602647781372
Validation loss: 1.4232706241710211

Epoch: 6| Step: 9
Training loss: 0.07687034457921982
Validation loss: 1.444612822225017

Epoch: 6| Step: 10
Training loss: 0.06805367022752762
Validation loss: 1.461943458485347

Epoch: 6| Step: 11
Training loss: 0.1592838019132614
Validation loss: 1.4482940858410251

Epoch: 6| Step: 12
Training loss: 0.13133083283901215
Validation loss: 1.4330877809114353

Epoch: 6| Step: 13
Training loss: 0.07616415619850159
Validation loss: 1.4189752109589115

Epoch: 516| Step: 0
Training loss: 0.1305118203163147
Validation loss: 1.3824647600932787

Epoch: 6| Step: 1
Training loss: 0.09881123155355453
Validation loss: 1.3640798964808065

Epoch: 6| Step: 2
Training loss: 0.1380108892917633
Validation loss: 1.3598604753453245

Epoch: 6| Step: 3
Training loss: 0.1155090257525444
Validation loss: 1.3484416539951036

Epoch: 6| Step: 4
Training loss: 0.1050860732793808
Validation loss: 1.372527592925615

Epoch: 6| Step: 5
Training loss: 0.20978617668151855
Validation loss: 1.3518384015688332

Epoch: 6| Step: 6
Training loss: 0.09972693771123886
Validation loss: 1.3841843938314786

Epoch: 6| Step: 7
Training loss: 0.10971487313508987
Validation loss: 1.4465628118925198

Epoch: 6| Step: 8
Training loss: 0.10322269052267075
Validation loss: 1.4292739463108841

Epoch: 6| Step: 9
Training loss: 0.24416831135749817
Validation loss: 1.448861470786474

Epoch: 6| Step: 10
Training loss: 0.10336961597204208
Validation loss: 1.409943199926807

Epoch: 6| Step: 11
Training loss: 0.2547779381275177
Validation loss: 1.3988085626274027

Epoch: 6| Step: 12
Training loss: 0.09778396785259247
Validation loss: 1.3639948919255247

Epoch: 6| Step: 13
Training loss: 0.1372021585702896
Validation loss: 1.3772080380429503

Epoch: 517| Step: 0
Training loss: 0.17024749517440796
Validation loss: 1.3796473510803715

Epoch: 6| Step: 1
Training loss: 0.06709848344326019
Validation loss: 1.3609020376718173

Epoch: 6| Step: 2
Training loss: 0.1613216996192932
Validation loss: 1.360277525840267

Epoch: 6| Step: 3
Training loss: 0.10798013210296631
Validation loss: 1.3724469010547926

Epoch: 6| Step: 4
Training loss: 0.154842346906662
Validation loss: 1.3656446613291258

Epoch: 6| Step: 5
Training loss: 0.08480115234851837
Validation loss: 1.3622410092302548

Epoch: 6| Step: 6
Training loss: 0.0687713772058487
Validation loss: 1.434801842576714

Epoch: 6| Step: 7
Training loss: 0.07952512800693512
Validation loss: 1.4068748233138875

Epoch: 6| Step: 8
Training loss: 0.11773681640625
Validation loss: 1.4525247402088617

Epoch: 6| Step: 9
Training loss: 0.19841426610946655
Validation loss: 1.4491186898241761

Epoch: 6| Step: 10
Training loss: 0.11418737471103668
Validation loss: 1.482756692876098

Epoch: 6| Step: 11
Training loss: 0.15682972967624664
Validation loss: 1.4710594031118578

Epoch: 6| Step: 12
Training loss: 0.17909303307533264
Validation loss: 1.5063648967332737

Epoch: 6| Step: 13
Training loss: 0.08746697008609772
Validation loss: 1.4971005198776082

Epoch: 518| Step: 0
Training loss: 0.12288770079612732
Validation loss: 1.4711098658141268

Epoch: 6| Step: 1
Training loss: 0.06735106557607651
Validation loss: 1.4902595012418685

Epoch: 6| Step: 2
Training loss: 0.12556876242160797
Validation loss: 1.4438667073044726

Epoch: 6| Step: 3
Training loss: 0.17442375421524048
Validation loss: 1.4279504822146507

Epoch: 6| Step: 4
Training loss: 0.18984106183052063
Validation loss: 1.4362100426868727

Epoch: 6| Step: 5
Training loss: 0.13849148154258728
Validation loss: 1.4145035653985956

Epoch: 6| Step: 6
Training loss: 0.12463156878948212
Validation loss: 1.4304748517210766

Epoch: 6| Step: 7
Training loss: 0.18611150979995728
Validation loss: 1.4302883866012737

Epoch: 6| Step: 8
Training loss: 0.08695980906486511
Validation loss: 1.4540583305461432

Epoch: 6| Step: 9
Training loss: 0.2285255789756775
Validation loss: 1.4747764295147312

Epoch: 6| Step: 10
Training loss: 0.2485116571187973
Validation loss: 1.508099716196778

Epoch: 6| Step: 11
Training loss: 0.2628016173839569
Validation loss: 1.4671038209751088

Epoch: 6| Step: 12
Training loss: 0.0665866807103157
Validation loss: 1.447187380124164

Epoch: 6| Step: 13
Training loss: 0.10287564247846603
Validation loss: 1.419796582191221

Epoch: 519| Step: 0
Training loss: 0.18010234832763672
Validation loss: 1.3893224231658443

Epoch: 6| Step: 1
Training loss: 0.09695257246494293
Validation loss: 1.3700715162420785

Epoch: 6| Step: 2
Training loss: 0.18479713797569275
Validation loss: 1.3527104175218971

Epoch: 6| Step: 3
Training loss: 0.17733749747276306
Validation loss: 1.3575088195903326

Epoch: 6| Step: 4
Training loss: 0.11891169100999832
Validation loss: 1.3793886656402259

Epoch: 6| Step: 5
Training loss: 0.098121277987957
Validation loss: 1.3925143608482935

Epoch: 6| Step: 6
Training loss: 0.11033908277750015
Validation loss: 1.4486636910387265

Epoch: 6| Step: 7
Training loss: 0.08919410407543182
Validation loss: 1.4622690164914696

Epoch: 6| Step: 8
Training loss: 0.11329379677772522
Validation loss: 1.4711447979814263

Epoch: 6| Step: 9
Training loss: 0.28858426213264465
Validation loss: 1.5178245395742438

Epoch: 6| Step: 10
Training loss: 0.22128340601921082
Validation loss: 1.4933513056847356

Epoch: 6| Step: 11
Training loss: 0.10914477705955505
Validation loss: 1.4538856834493659

Epoch: 6| Step: 12
Training loss: 0.10687405616044998
Validation loss: 1.419039298129338

Epoch: 6| Step: 13
Training loss: 0.10283774882555008
Validation loss: 1.4010611875082857

Epoch: 520| Step: 0
Training loss: 0.13712090253829956
Validation loss: 1.3804619145649735

Epoch: 6| Step: 1
Training loss: 0.12427583336830139
Validation loss: 1.391945481300354

Epoch: 6| Step: 2
Training loss: 0.09042154252529144
Validation loss: 1.4078606527338746

Epoch: 6| Step: 3
Training loss: 0.1454537957906723
Validation loss: 1.4095020781281173

Epoch: 6| Step: 4
Training loss: 0.11970789730548859
Validation loss: 1.4148863566819059

Epoch: 6| Step: 5
Training loss: 0.20789456367492676
Validation loss: 1.4433409501147527

Epoch: 6| Step: 6
Training loss: 0.06884988397359848
Validation loss: 1.4509021312959733

Epoch: 6| Step: 7
Training loss: 0.14546529948711395
Validation loss: 1.4306846754525298

Epoch: 6| Step: 8
Training loss: 0.30168604850769043
Validation loss: 1.4434716611780145

Epoch: 6| Step: 9
Training loss: 0.05112222582101822
Validation loss: 1.4530937261478876

Epoch: 6| Step: 10
Training loss: 0.11537861824035645
Validation loss: 1.4370993234777962

Epoch: 6| Step: 11
Training loss: 0.07016481459140778
Validation loss: 1.46462236168564

Epoch: 6| Step: 12
Training loss: 0.111864373087883
Validation loss: 1.4390877254547612

Epoch: 6| Step: 13
Training loss: 0.10313323140144348
Validation loss: 1.4235411600400043

Epoch: 521| Step: 0
Training loss: 0.17356504499912262
Validation loss: 1.428773077585364

Epoch: 6| Step: 1
Training loss: 0.1252259612083435
Validation loss: 1.411377494053174

Epoch: 6| Step: 2
Training loss: 0.24580679833889008
Validation loss: 1.3850759972808182

Epoch: 6| Step: 3
Training loss: 0.1726042479276657
Validation loss: 1.4147293542021064

Epoch: 6| Step: 4
Training loss: 0.16654132306575775
Validation loss: 1.422315771861743

Epoch: 6| Step: 5
Training loss: 0.12304040789604187
Validation loss: 1.4343431790669758

Epoch: 6| Step: 6
Training loss: 0.1305558979511261
Validation loss: 1.4439424417352165

Epoch: 6| Step: 7
Training loss: 0.12053962796926498
Validation loss: 1.4497444988578878

Epoch: 6| Step: 8
Training loss: 0.10635651648044586
Validation loss: 1.4092176985997025

Epoch: 6| Step: 9
Training loss: 0.10667429119348526
Validation loss: 1.4450144998488887

Epoch: 6| Step: 10
Training loss: 0.0805959701538086
Validation loss: 1.4487926280626686

Epoch: 6| Step: 11
Training loss: 0.09970399737358093
Validation loss: 1.4354537026856535

Epoch: 6| Step: 12
Training loss: 0.11513790488243103
Validation loss: 1.4421124125039706

Epoch: 6| Step: 13
Training loss: 0.1595526486635208
Validation loss: 1.4114556466379473

Epoch: 522| Step: 0
Training loss: 0.17131707072257996
Validation loss: 1.4049095530663767

Epoch: 6| Step: 1
Training loss: 0.10033220797777176
Validation loss: 1.389567357237621

Epoch: 6| Step: 2
Training loss: 0.185764878988266
Validation loss: 1.4103948147066179

Epoch: 6| Step: 3
Training loss: 0.07882201671600342
Validation loss: 1.4232672965654762

Epoch: 6| Step: 4
Training loss: 0.11914947628974915
Validation loss: 1.4153882995728524

Epoch: 6| Step: 5
Training loss: 0.09868620336055756
Validation loss: 1.4088661747594033

Epoch: 6| Step: 6
Training loss: 0.05689022317528725
Validation loss: 1.4290041692795292

Epoch: 6| Step: 7
Training loss: 0.15331721305847168
Validation loss: 1.4156263887241323

Epoch: 6| Step: 8
Training loss: 0.13187849521636963
Validation loss: 1.4019687547478625

Epoch: 6| Step: 9
Training loss: 0.06270454823970795
Validation loss: 1.4240800026924378

Epoch: 6| Step: 10
Training loss: 0.08323206007480621
Validation loss: 1.4132790052762596

Epoch: 6| Step: 11
Training loss: 0.1811555027961731
Validation loss: 1.4173106672943279

Epoch: 6| Step: 12
Training loss: 0.1758061945438385
Validation loss: 1.423005125855887

Epoch: 6| Step: 13
Training loss: 0.1288367658853531
Validation loss: 1.4132710938812585

Epoch: 523| Step: 0
Training loss: 0.14386001229286194
Validation loss: 1.4262957611391622

Epoch: 6| Step: 1
Training loss: 0.09607215970754623
Validation loss: 1.4216100092857116

Epoch: 6| Step: 2
Training loss: 0.09617899358272552
Validation loss: 1.4172742366790771

Epoch: 6| Step: 3
Training loss: 0.07288925349712372
Validation loss: 1.4474866441501084

Epoch: 6| Step: 4
Training loss: 0.12844565510749817
Validation loss: 1.4543343731152114

Epoch: 6| Step: 5
Training loss: 0.07081206887960434
Validation loss: 1.4554358874597857

Epoch: 6| Step: 6
Training loss: 0.11905021965503693
Validation loss: 1.484923901096467

Epoch: 6| Step: 7
Training loss: 0.30458247661590576
Validation loss: 1.4755785849786573

Epoch: 6| Step: 8
Training loss: 0.1661510467529297
Validation loss: 1.4618229571209158

Epoch: 6| Step: 9
Training loss: 0.2015792727470398
Validation loss: 1.4741062271979548

Epoch: 6| Step: 10
Training loss: 0.15552684664726257
Validation loss: 1.425988862591405

Epoch: 6| Step: 11
Training loss: 0.10811591148376465
Validation loss: 1.4114116366191576

Epoch: 6| Step: 12
Training loss: 0.1481758952140808
Validation loss: 1.3606749260297386

Epoch: 6| Step: 13
Training loss: 0.14636345207691193
Validation loss: 1.3929343928572953

Epoch: 524| Step: 0
Training loss: 0.08955658972263336
Validation loss: 1.3846918895680418

Epoch: 6| Step: 1
Training loss: 0.1282600462436676
Validation loss: 1.3596500350582985

Epoch: 6| Step: 2
Training loss: 0.22716346383094788
Validation loss: 1.379747397156172

Epoch: 6| Step: 3
Training loss: 0.1928999423980713
Validation loss: 1.378023309092368

Epoch: 6| Step: 4
Training loss: 0.1477113515138626
Validation loss: 1.4108878950918875

Epoch: 6| Step: 5
Training loss: 0.1365484893321991
Validation loss: 1.4253660504535963

Epoch: 6| Step: 6
Training loss: 0.07538831233978271
Validation loss: 1.4493660132090251

Epoch: 6| Step: 7
Training loss: 0.11820302903652191
Validation loss: 1.4535522076391405

Epoch: 6| Step: 8
Training loss: 0.1557222306728363
Validation loss: 1.4431090931738577

Epoch: 6| Step: 9
Training loss: 0.20021897554397583
Validation loss: 1.4153454329377861

Epoch: 6| Step: 10
Training loss: 0.10085930675268173
Validation loss: 1.3967036649744997

Epoch: 6| Step: 11
Training loss: 0.19604435563087463
Validation loss: 1.397523498022428

Epoch: 6| Step: 12
Training loss: 0.056579962372779846
Validation loss: 1.3850729721848682

Epoch: 6| Step: 13
Training loss: 0.1200057789683342
Validation loss: 1.3774609206825175

Epoch: 525| Step: 0
Training loss: 0.10638774931430817
Validation loss: 1.3701554716274302

Epoch: 6| Step: 1
Training loss: 0.15601645410060883
Validation loss: 1.3477948730991733

Epoch: 6| Step: 2
Training loss: 0.1402324140071869
Validation loss: 1.3686285390648791

Epoch: 6| Step: 3
Training loss: 0.15721195936203003
Validation loss: 1.3834515925376647

Epoch: 6| Step: 4
Training loss: 0.17477576434612274
Validation loss: 1.3880693399777977

Epoch: 6| Step: 5
Training loss: 0.14980143308639526
Validation loss: 1.4093982404278171

Epoch: 6| Step: 6
Training loss: 0.10120020806789398
Validation loss: 1.4376813173294067

Epoch: 6| Step: 7
Training loss: 0.18219450116157532
Validation loss: 1.4290593029350362

Epoch: 6| Step: 8
Training loss: 0.19494393467903137
Validation loss: 1.4503694362537836

Epoch: 6| Step: 9
Training loss: 0.18724778294563293
Validation loss: 1.482215460910592

Epoch: 6| Step: 10
Training loss: 0.1228603646159172
Validation loss: 1.4533900342961794

Epoch: 6| Step: 11
Training loss: 0.09886720031499863
Validation loss: 1.4412960980528144

Epoch: 6| Step: 12
Training loss: 0.19584234058856964
Validation loss: 1.4185234564606861

Epoch: 6| Step: 13
Training loss: 0.08937560021877289
Validation loss: 1.3999799284883725

Epoch: 526| Step: 0
Training loss: 0.11010678112506866
Validation loss: 1.4095723103451472

Epoch: 6| Step: 1
Training loss: 0.14460763335227966
Validation loss: 1.3878578498799314

Epoch: 6| Step: 2
Training loss: 0.10218657553195953
Validation loss: 1.4158346396620556

Epoch: 6| Step: 3
Training loss: 0.10784243047237396
Validation loss: 1.4018473714910529

Epoch: 6| Step: 4
Training loss: 0.26184719800949097
Validation loss: 1.398936774141045

Epoch: 6| Step: 5
Training loss: 0.08724196255207062
Validation loss: 1.4013124101905412

Epoch: 6| Step: 6
Training loss: 0.07760731130838394
Validation loss: 1.421977496916248

Epoch: 6| Step: 7
Training loss: 0.15176600217819214
Validation loss: 1.4309376055194485

Epoch: 6| Step: 8
Training loss: 0.08409556746482849
Validation loss: 1.4486504857258131

Epoch: 6| Step: 9
Training loss: 0.1457728147506714
Validation loss: 1.4100076024250319

Epoch: 6| Step: 10
Training loss: 0.2131025493144989
Validation loss: 1.442088432209466

Epoch: 6| Step: 11
Training loss: 0.08041621744632721
Validation loss: 1.4278746599792151

Epoch: 6| Step: 12
Training loss: 0.09293495118618011
Validation loss: 1.4294773429952643

Epoch: 6| Step: 13
Training loss: 0.11988376080989838
Validation loss: 1.4414314038010054

Epoch: 527| Step: 0
Training loss: 0.1139860600233078
Validation loss: 1.4127459346607167

Epoch: 6| Step: 1
Training loss: 0.1463220715522766
Validation loss: 1.3732546157734369

Epoch: 6| Step: 2
Training loss: 0.06390857696533203
Validation loss: 1.380767382601256

Epoch: 6| Step: 3
Training loss: 0.10517854988574982
Validation loss: 1.388353716942572

Epoch: 6| Step: 4
Training loss: 0.1011291965842247
Validation loss: 1.3846567792277182

Epoch: 6| Step: 5
Training loss: 0.19741082191467285
Validation loss: 1.3937017533086962

Epoch: 6| Step: 6
Training loss: 0.1429072469472885
Validation loss: 1.388048473224845

Epoch: 6| Step: 7
Training loss: 0.1505824774503708
Validation loss: 1.3698186579570975

Epoch: 6| Step: 8
Training loss: 0.13439711928367615
Validation loss: 1.3592451516018118

Epoch: 6| Step: 9
Training loss: 0.1535557359457016
Validation loss: 1.3439044670392108

Epoch: 6| Step: 10
Training loss: 0.15999647974967957
Validation loss: 1.3529091432530393

Epoch: 6| Step: 11
Training loss: 0.16043482720851898
Validation loss: 1.3649935568532636

Epoch: 6| Step: 12
Training loss: 0.08889850974082947
Validation loss: 1.3593981330112745

Epoch: 6| Step: 13
Training loss: 0.3194958567619324
Validation loss: 1.3629963321070517

Epoch: 528| Step: 0
Training loss: 0.14287447929382324
Validation loss: 1.363626391656937

Epoch: 6| Step: 1
Training loss: 0.14260083436965942
Validation loss: 1.3825113811800558

Epoch: 6| Step: 2
Training loss: 0.13090138137340546
Validation loss: 1.4245477350809241

Epoch: 6| Step: 3
Training loss: 0.13182391226291656
Validation loss: 1.450290326149233

Epoch: 6| Step: 4
Training loss: 0.10713616013526917
Validation loss: 1.4636679682680356

Epoch: 6| Step: 5
Training loss: 0.1807214468717575
Validation loss: 1.4960105662704797

Epoch: 6| Step: 6
Training loss: 0.156417578458786
Validation loss: 1.512144846300925

Epoch: 6| Step: 7
Training loss: 0.0917726382613182
Validation loss: 1.4848940808285949

Epoch: 6| Step: 8
Training loss: 0.1230209544301033
Validation loss: 1.4673206575455204

Epoch: 6| Step: 9
Training loss: 0.09550613909959793
Validation loss: 1.4297276607123754

Epoch: 6| Step: 10
Training loss: 0.0841035544872284
Validation loss: 1.416777632569754

Epoch: 6| Step: 11
Training loss: 0.18072441220283508
Validation loss: 1.3823805162983556

Epoch: 6| Step: 12
Training loss: 0.12438266724348068
Validation loss: 1.3465201136886433

Epoch: 6| Step: 13
Training loss: 0.2450033277273178
Validation loss: 1.33413137543586

Epoch: 529| Step: 0
Training loss: 0.2488526552915573
Validation loss: 1.3387291072517313

Epoch: 6| Step: 1
Training loss: 0.10822142660617828
Validation loss: 1.3242591657946188

Epoch: 6| Step: 2
Training loss: 0.14386536180973053
Validation loss: 1.3318600462329002

Epoch: 6| Step: 3
Training loss: 0.13651420176029205
Validation loss: 1.340101900921073

Epoch: 6| Step: 4
Training loss: 0.12300027906894684
Validation loss: 1.364062992475366

Epoch: 6| Step: 5
Training loss: 0.15680396556854248
Validation loss: 1.3791020698444818

Epoch: 6| Step: 6
Training loss: 0.1039373055100441
Validation loss: 1.3697446725701774

Epoch: 6| Step: 7
Training loss: 0.07560159265995026
Validation loss: 1.3512291690354705

Epoch: 6| Step: 8
Training loss: 0.09671853482723236
Validation loss: 1.3708460420690558

Epoch: 6| Step: 9
Training loss: 0.14622095227241516
Validation loss: 1.3574708533543411

Epoch: 6| Step: 10
Training loss: 0.09952090680599213
Validation loss: 1.3591936403705227

Epoch: 6| Step: 11
Training loss: 0.18625520169734955
Validation loss: 1.3346204655144804

Epoch: 6| Step: 12
Training loss: 0.05820513516664505
Validation loss: 1.3533509905620287

Epoch: 6| Step: 13
Training loss: 0.17459158599376678
Validation loss: 1.3256114541843373

Epoch: 530| Step: 0
Training loss: 0.10111191868782043
Validation loss: 1.350970716886623

Epoch: 6| Step: 1
Training loss: 0.0929177775979042
Validation loss: 1.369619720725603

Epoch: 6| Step: 2
Training loss: 0.1921006739139557
Validation loss: 1.3145680325005644

Epoch: 6| Step: 3
Training loss: 0.11589188128709793
Validation loss: 1.3545645161341595

Epoch: 6| Step: 4
Training loss: 0.11732624471187592
Validation loss: 1.3245519463733961

Epoch: 6| Step: 5
Training loss: 0.08840671181678772
Validation loss: 1.3530864446393904

Epoch: 6| Step: 6
Training loss: 0.10134147107601166
Validation loss: 1.3751771180860457

Epoch: 6| Step: 7
Training loss: 0.13866421580314636
Validation loss: 1.3933090561179704

Epoch: 6| Step: 8
Training loss: 0.1887768805027008
Validation loss: 1.3898643537234234

Epoch: 6| Step: 9
Training loss: 0.1899946630001068
Validation loss: 1.3957999919050483

Epoch: 6| Step: 10
Training loss: 0.12093423306941986
Validation loss: 1.38555097323592

Epoch: 6| Step: 11
Training loss: 0.09730349481105804
Validation loss: 1.3631878950262581

Epoch: 6| Step: 12
Training loss: 0.09640257060527802
Validation loss: 1.3733890479610813

Epoch: 6| Step: 13
Training loss: 0.1631036400794983
Validation loss: 1.3434127312834545

Epoch: 531| Step: 0
Training loss: 0.18442504107952118
Validation loss: 1.3322527709827627

Epoch: 6| Step: 1
Training loss: 0.17067298293113708
Validation loss: 1.3511777475316038

Epoch: 6| Step: 2
Training loss: 0.12389180064201355
Validation loss: 1.3394068723083825

Epoch: 6| Step: 3
Training loss: 0.09409013390541077
Validation loss: 1.3314600785573323

Epoch: 6| Step: 4
Training loss: 0.1916399747133255
Validation loss: 1.359423747626684

Epoch: 6| Step: 5
Training loss: 0.08177652955055237
Validation loss: 1.3654802524915306

Epoch: 6| Step: 6
Training loss: 0.07762832939624786
Validation loss: 1.3678107556476389

Epoch: 6| Step: 7
Training loss: 0.10361834615468979
Validation loss: 1.3786315418058825

Epoch: 6| Step: 8
Training loss: 0.1635040044784546
Validation loss: 1.3726957869786087

Epoch: 6| Step: 9
Training loss: 0.1683860868215561
Validation loss: 1.3852972868950135

Epoch: 6| Step: 10
Training loss: 0.09809082746505737
Validation loss: 1.3857172484038978

Epoch: 6| Step: 11
Training loss: 0.09420982748270035
Validation loss: 1.3940248989289807

Epoch: 6| Step: 12
Training loss: 0.07467912137508392
Validation loss: 1.4142502956492926

Epoch: 6| Step: 13
Training loss: 0.14076611399650574
Validation loss: 1.4064595596764677

Epoch: 532| Step: 0
Training loss: 0.11463436484336853
Validation loss: 1.3693040237631848

Epoch: 6| Step: 1
Training loss: 0.14986726641654968
Validation loss: 1.3774950299211728

Epoch: 6| Step: 2
Training loss: 0.143027663230896
Validation loss: 1.387766218954517

Epoch: 6| Step: 3
Training loss: 0.15779553353786469
Validation loss: 1.3837586090128908

Epoch: 6| Step: 4
Training loss: 0.09740041196346283
Validation loss: 1.3912489106578212

Epoch: 6| Step: 5
Training loss: 0.08939804136753082
Validation loss: 1.3794445568515408

Epoch: 6| Step: 6
Training loss: 0.0692724883556366
Validation loss: 1.4094469983090636

Epoch: 6| Step: 7
Training loss: 0.19493865966796875
Validation loss: 1.4094649719935592

Epoch: 6| Step: 8
Training loss: 0.09835709631443024
Validation loss: 1.4255924263308126

Epoch: 6| Step: 9
Training loss: 0.1385805308818817
Validation loss: 1.4385618676421463

Epoch: 6| Step: 10
Training loss: 0.07909707725048065
Validation loss: 1.447630419526049

Epoch: 6| Step: 11
Training loss: 0.15680190920829773
Validation loss: 1.4033050255108905

Epoch: 6| Step: 12
Training loss: 0.13059668242931366
Validation loss: 1.4063851705161474

Epoch: 6| Step: 13
Training loss: 0.26085805892944336
Validation loss: 1.3745465765717209

Epoch: 533| Step: 0
Training loss: 0.1128479391336441
Validation loss: 1.381905464715855

Epoch: 6| Step: 1
Training loss: 0.10458268225193024
Validation loss: 1.365180177073325

Epoch: 6| Step: 2
Training loss: 0.12207286804914474
Validation loss: 1.3784323315466604

Epoch: 6| Step: 3
Training loss: 0.13162359595298767
Validation loss: 1.3887390769937986

Epoch: 6| Step: 4
Training loss: 0.10850410163402557
Validation loss: 1.3593848302800169

Epoch: 6| Step: 5
Training loss: 0.10361839830875397
Validation loss: 1.4043446811296607

Epoch: 6| Step: 6
Training loss: 0.1870897114276886
Validation loss: 1.4403301618432487

Epoch: 6| Step: 7
Training loss: 0.14545215666294098
Validation loss: 1.4818114901101718

Epoch: 6| Step: 8
Training loss: 0.2846534848213196
Validation loss: 1.4603117640300463

Epoch: 6| Step: 9
Training loss: 0.10453757643699646
Validation loss: 1.4622905946546985

Epoch: 6| Step: 10
Training loss: 0.18115289509296417
Validation loss: 1.449312291478598

Epoch: 6| Step: 11
Training loss: 0.10676808655261993
Validation loss: 1.4195366290307814

Epoch: 6| Step: 12
Training loss: 0.1308227777481079
Validation loss: 1.379531354032537

Epoch: 6| Step: 13
Training loss: 0.12317731976509094
Validation loss: 1.4059952189845424

Epoch: 534| Step: 0
Training loss: 0.08870138972997665
Validation loss: 1.374152542442404

Epoch: 6| Step: 1
Training loss: 0.09365515410900116
Validation loss: 1.35727358377108

Epoch: 6| Step: 2
Training loss: 0.19254589080810547
Validation loss: 1.3798287850554272

Epoch: 6| Step: 3
Training loss: 0.19229656457901
Validation loss: 1.3773452043533325

Epoch: 6| Step: 4
Training loss: 0.0801023468375206
Validation loss: 1.3916826735260666

Epoch: 6| Step: 5
Training loss: 0.1813625991344452
Validation loss: 1.4203127955877652

Epoch: 6| Step: 6
Training loss: 0.18430134654045105
Validation loss: 1.4198803030034548

Epoch: 6| Step: 7
Training loss: 0.11348196864128113
Validation loss: 1.4084204409712104

Epoch: 6| Step: 8
Training loss: 0.18606142699718475
Validation loss: 1.3726447718117827

Epoch: 6| Step: 9
Training loss: 0.10139438509941101
Validation loss: 1.376340252096935

Epoch: 6| Step: 10
Training loss: 0.1303086280822754
Validation loss: 1.3349243979300223

Epoch: 6| Step: 11
Training loss: 0.11589343845844269
Validation loss: 1.3175035881739792

Epoch: 6| Step: 12
Training loss: 0.11630566418170929
Validation loss: 1.2988848301672167

Epoch: 6| Step: 13
Training loss: 0.057346608489751816
Validation loss: 1.3135797285264539

Epoch: 535| Step: 0
Training loss: 0.22940745949745178
Validation loss: 1.2942452578134434

Epoch: 6| Step: 1
Training loss: 0.17018690705299377
Validation loss: 1.328730062771869

Epoch: 6| Step: 2
Training loss: 0.12947234511375427
Validation loss: 1.3560133762257074

Epoch: 6| Step: 3
Training loss: 0.09634236246347427
Validation loss: 1.3794678770085818

Epoch: 6| Step: 4
Training loss: 0.07496203482151031
Validation loss: 1.42925751081077

Epoch: 6| Step: 5
Training loss: 0.11492934823036194
Validation loss: 1.4478460063216507

Epoch: 6| Step: 6
Training loss: 0.16847942769527435
Validation loss: 1.4390202811969224

Epoch: 6| Step: 7
Training loss: 0.04775121062994003
Validation loss: 1.4588099859094108

Epoch: 6| Step: 8
Training loss: 0.11578528583049774
Validation loss: 1.4481482403252715

Epoch: 6| Step: 9
Training loss: 0.13666769862174988
Validation loss: 1.4206211131106141

Epoch: 6| Step: 10
Training loss: 0.1914399415254593
Validation loss: 1.3694519330096502

Epoch: 6| Step: 11
Training loss: 0.157983660697937
Validation loss: 1.31511672594214

Epoch: 6| Step: 12
Training loss: 0.12247419357299805
Validation loss: 1.320757596723495

Epoch: 6| Step: 13
Training loss: 0.09042713046073914
Validation loss: 1.2711844021274197

Epoch: 536| Step: 0
Training loss: 0.18121689558029175
Validation loss: 1.2559434636946647

Epoch: 6| Step: 1
Training loss: 0.18107938766479492
Validation loss: 1.2921885251998901

Epoch: 6| Step: 2
Training loss: 0.19744637608528137
Validation loss: 1.3076874133079284

Epoch: 6| Step: 3
Training loss: 0.13539403676986694
Validation loss: 1.3560883088778424

Epoch: 6| Step: 4
Training loss: 0.099403515458107
Validation loss: 1.3684861358775888

Epoch: 6| Step: 5
Training loss: 0.08001023530960083
Validation loss: 1.3708076130959295

Epoch: 6| Step: 6
Training loss: 0.07508599013090134
Validation loss: 1.3681317157642816

Epoch: 6| Step: 7
Training loss: 0.20496362447738647
Validation loss: 1.397332238894637

Epoch: 6| Step: 8
Training loss: 0.07475222647190094
Validation loss: 1.397328225515222

Epoch: 6| Step: 9
Training loss: 0.14682243764400482
Validation loss: 1.3720911472074446

Epoch: 6| Step: 10
Training loss: 0.108683280646801
Validation loss: 1.3951295806515602

Epoch: 6| Step: 11
Training loss: 0.10805416852235794
Validation loss: 1.3844078266492454

Epoch: 6| Step: 12
Training loss: 0.2029813677072525
Validation loss: 1.362031154735114

Epoch: 6| Step: 13
Training loss: 0.13195458054542542
Validation loss: 1.3604860626241213

Epoch: 537| Step: 0
Training loss: 0.12569937109947205
Validation loss: 1.3191262047777894

Epoch: 6| Step: 1
Training loss: 0.15777438879013062
Validation loss: 1.3476266386688396

Epoch: 6| Step: 2
Training loss: 0.08271566033363342
Validation loss: 1.30717949328884

Epoch: 6| Step: 3
Training loss: 0.11911565065383911
Validation loss: 1.3276593210876628

Epoch: 6| Step: 4
Training loss: 0.2717089056968689
Validation loss: 1.3277925977142908

Epoch: 6| Step: 5
Training loss: 0.13066479563713074
Validation loss: 1.3541971637356667

Epoch: 6| Step: 6
Training loss: 0.11181525886058807
Validation loss: 1.341640305775468

Epoch: 6| Step: 7
Training loss: 0.1341187059879303
Validation loss: 1.3325597111896803

Epoch: 6| Step: 8
Training loss: 0.09960053116083145
Validation loss: 1.3304345569302958

Epoch: 6| Step: 9
Training loss: 0.12016178667545319
Validation loss: 1.3547085741514802

Epoch: 6| Step: 10
Training loss: 0.1349332481622696
Validation loss: 1.3748267594204153

Epoch: 6| Step: 11
Training loss: 0.12103955447673798
Validation loss: 1.3790694257264495

Epoch: 6| Step: 12
Training loss: 0.21735155582427979
Validation loss: 1.4175892042857345

Epoch: 6| Step: 13
Training loss: 0.2059868574142456
Validation loss: 1.4034127022630425

Epoch: 538| Step: 0
Training loss: 0.15846309065818787
Validation loss: 1.3978992828758814

Epoch: 6| Step: 1
Training loss: 0.2932404577732086
Validation loss: 1.3936627270073019

Epoch: 6| Step: 2
Training loss: 0.08577750623226166
Validation loss: 1.3728845350203975

Epoch: 6| Step: 3
Training loss: 0.08169454336166382
Validation loss: 1.387527589515973

Epoch: 6| Step: 4
Training loss: 0.1004975363612175
Validation loss: 1.3876203734387633

Epoch: 6| Step: 5
Training loss: 0.08190120756626129
Validation loss: 1.4308509128068083

Epoch: 6| Step: 6
Training loss: 0.11067409068346024
Validation loss: 1.452811542377677

Epoch: 6| Step: 7
Training loss: 0.22726799547672272
Validation loss: 1.4262469481396418

Epoch: 6| Step: 8
Training loss: 0.1543983519077301
Validation loss: 1.4258678984898392

Epoch: 6| Step: 9
Training loss: 0.13034990429878235
Validation loss: 1.3641686349786737

Epoch: 6| Step: 10
Training loss: 0.0773211419582367
Validation loss: 1.3400174430621568

Epoch: 6| Step: 11
Training loss: 0.16823497414588928
Validation loss: 1.374403320333009

Epoch: 6| Step: 12
Training loss: 0.1235160380601883
Validation loss: 1.3563283669051303

Epoch: 6| Step: 13
Training loss: 0.21916630864143372
Validation loss: 1.3808317876631213

Epoch: 539| Step: 0
Training loss: 0.09562075883150101
Validation loss: 1.3921235569061772

Epoch: 6| Step: 1
Training loss: 0.1120777428150177
Validation loss: 1.3763820984030282

Epoch: 6| Step: 2
Training loss: 0.10628832876682281
Validation loss: 1.3974748490959086

Epoch: 6| Step: 3
Training loss: 0.18065498769283295
Validation loss: 1.4335457176290534

Epoch: 6| Step: 4
Training loss: 0.12255051732063293
Validation loss: 1.4399161941261702

Epoch: 6| Step: 5
Training loss: 0.14488713443279266
Validation loss: 1.4151293257231354

Epoch: 6| Step: 6
Training loss: 0.16759434342384338
Validation loss: 1.4539298229320075

Epoch: 6| Step: 7
Training loss: 0.11226660013198853
Validation loss: 1.4456638149035874

Epoch: 6| Step: 8
Training loss: 0.16724282503128052
Validation loss: 1.4401860455031037

Epoch: 6| Step: 9
Training loss: 0.2063993513584137
Validation loss: 1.4547507314271824

Epoch: 6| Step: 10
Training loss: 0.12380217015743256
Validation loss: 1.4715457565041

Epoch: 6| Step: 11
Training loss: 0.15827888250350952
Validation loss: 1.4381065573743594

Epoch: 6| Step: 12
Training loss: 0.07181595265865326
Validation loss: 1.4433078048049763

Epoch: 6| Step: 13
Training loss: 0.07287774980068207
Validation loss: 1.4322989076696417

Epoch: 540| Step: 0
Training loss: 0.09585011005401611
Validation loss: 1.4363994342024609

Epoch: 6| Step: 1
Training loss: 0.18009257316589355
Validation loss: 1.3973522070915467

Epoch: 6| Step: 2
Training loss: 0.14382395148277283
Validation loss: 1.4098941177450202

Epoch: 6| Step: 3
Training loss: 0.09355387091636658
Validation loss: 1.3668725477751864

Epoch: 6| Step: 4
Training loss: 0.11156043410301208
Validation loss: 1.3870389999881867

Epoch: 6| Step: 5
Training loss: 0.11035921424627304
Validation loss: 1.4163886513761295

Epoch: 6| Step: 6
Training loss: 0.11844873428344727
Validation loss: 1.4051011057310208

Epoch: 6| Step: 7
Training loss: 0.12493705004453659
Validation loss: 1.4028047079681067

Epoch: 6| Step: 8
Training loss: 0.11969974637031555
Validation loss: 1.3769408848977858

Epoch: 6| Step: 9
Training loss: 0.1318565011024475
Validation loss: 1.399905361155028

Epoch: 6| Step: 10
Training loss: 0.12690633535385132
Validation loss: 1.4248647023272771

Epoch: 6| Step: 11
Training loss: 0.18371036648750305
Validation loss: 1.4284078177585398

Epoch: 6| Step: 12
Training loss: 0.11437363922595978
Validation loss: 1.439685906133344

Epoch: 6| Step: 13
Training loss: 0.10871811211109161
Validation loss: 1.4465373510955482

Epoch: 541| Step: 0
Training loss: 0.10684847086668015
Validation loss: 1.4690905091583089

Epoch: 6| Step: 1
Training loss: 0.11580909788608551
Validation loss: 1.4719754649746803

Epoch: 6| Step: 2
Training loss: 0.12755566835403442
Validation loss: 1.4819712010763024

Epoch: 6| Step: 3
Training loss: 0.24689868092536926
Validation loss: 1.4935730618815268

Epoch: 6| Step: 4
Training loss: 0.08370959758758545
Validation loss: 1.4703000732647475

Epoch: 6| Step: 5
Training loss: 0.09659944474697113
Validation loss: 1.4434607772416965

Epoch: 6| Step: 6
Training loss: 0.14885351061820984
Validation loss: 1.44256325562795

Epoch: 6| Step: 7
Training loss: 0.13452735543251038
Validation loss: 1.4310999442172307

Epoch: 6| Step: 8
Training loss: 0.0896085649728775
Validation loss: 1.4313277531695623

Epoch: 6| Step: 9
Training loss: 0.08337812125682831
Validation loss: 1.38005397781249

Epoch: 6| Step: 10
Training loss: 0.19680732488632202
Validation loss: 1.4134418669567312

Epoch: 6| Step: 11
Training loss: 0.06986213475465775
Validation loss: 1.4071522438397972

Epoch: 6| Step: 12
Training loss: 0.10613489151000977
Validation loss: 1.4225056273962862

Epoch: 6| Step: 13
Training loss: 0.14074914157390594
Validation loss: 1.3874215002982848

Epoch: 542| Step: 0
Training loss: 0.13204950094223022
Validation loss: 1.3934622528732463

Epoch: 6| Step: 1
Training loss: 0.07520020753145218
Validation loss: 1.3968223294904154

Epoch: 6| Step: 2
Training loss: 0.07407601922750473
Validation loss: 1.4061588856481737

Epoch: 6| Step: 3
Training loss: 0.06855642050504684
Validation loss: 1.4142669170133528

Epoch: 6| Step: 4
Training loss: 0.12968552112579346
Validation loss: 1.4024661497403217

Epoch: 6| Step: 5
Training loss: 0.08248645812273026
Validation loss: 1.4204120507804296

Epoch: 6| Step: 6
Training loss: 0.10121172666549683
Validation loss: 1.4284541965812765

Epoch: 6| Step: 7
Training loss: 0.10482865571975708
Validation loss: 1.4214404167667511

Epoch: 6| Step: 8
Training loss: 0.15915533900260925
Validation loss: 1.437591939844111

Epoch: 6| Step: 9
Training loss: 0.10296013951301575
Validation loss: 1.4374136617106776

Epoch: 6| Step: 10
Training loss: 0.11730693280696869
Validation loss: 1.4481953523492301

Epoch: 6| Step: 11
Training loss: 0.2652835547924042
Validation loss: 1.4100238020702074

Epoch: 6| Step: 12
Training loss: 0.09817813336849213
Validation loss: 1.4342008047206427

Epoch: 6| Step: 13
Training loss: 0.25085341930389404
Validation loss: 1.4061262453756025

Epoch: 543| Step: 0
Training loss: 0.079449862241745
Validation loss: 1.3896486156730241

Epoch: 6| Step: 1
Training loss: 0.11394961923360825
Validation loss: 1.3683128087751326

Epoch: 6| Step: 2
Training loss: 0.18442818522453308
Validation loss: 1.3672787797066472

Epoch: 6| Step: 3
Training loss: 0.16598179936408997
Validation loss: 1.3726609060841222

Epoch: 6| Step: 4
Training loss: 0.0805676281452179
Validation loss: 1.3687326395383446

Epoch: 6| Step: 5
Training loss: 0.11058933287858963
Validation loss: 1.3771208960522887

Epoch: 6| Step: 6
Training loss: 0.07744331657886505
Validation loss: 1.3731945150641984

Epoch: 6| Step: 7
Training loss: 0.1833648383617401
Validation loss: 1.4101940752357565

Epoch: 6| Step: 8
Training loss: 0.08916287124156952
Validation loss: 1.4368249011296097

Epoch: 6| Step: 9
Training loss: 0.08158589899539948
Validation loss: 1.4293529910425986

Epoch: 6| Step: 10
Training loss: 0.2452976405620575
Validation loss: 1.4188670727514452

Epoch: 6| Step: 11
Training loss: 0.04774380475282669
Validation loss: 1.4118361549992715

Epoch: 6| Step: 12
Training loss: 0.19257983565330505
Validation loss: 1.3995988266442412

Epoch: 6| Step: 13
Training loss: 0.07684317976236343
Validation loss: 1.4016628919109222

Epoch: 544| Step: 0
Training loss: 0.08766023814678192
Validation loss: 1.3952688965746152

Epoch: 6| Step: 1
Training loss: 0.15892204642295837
Validation loss: 1.3981759714823898

Epoch: 6| Step: 2
Training loss: 0.11178036779165268
Validation loss: 1.3998268881151754

Epoch: 6| Step: 3
Training loss: 0.16143423318862915
Validation loss: 1.4383454732997443

Epoch: 6| Step: 4
Training loss: 0.10774196684360504
Validation loss: 1.4243892155667788

Epoch: 6| Step: 5
Training loss: 0.1450563222169876
Validation loss: 1.3917109838096045

Epoch: 6| Step: 6
Training loss: 0.06827789545059204
Validation loss: 1.391557628108609

Epoch: 6| Step: 7
Training loss: 0.10061023384332657
Validation loss: 1.3961493533144715

Epoch: 6| Step: 8
Training loss: 0.1671174019575119
Validation loss: 1.3822974594690467

Epoch: 6| Step: 9
Training loss: 0.07867425680160522
Validation loss: 1.3966428220912974

Epoch: 6| Step: 10
Training loss: 0.14536866545677185
Validation loss: 1.3919797328210646

Epoch: 6| Step: 11
Training loss: 0.12165527045726776
Validation loss: 1.3776731503907071

Epoch: 6| Step: 12
Training loss: 0.15872035920619965
Validation loss: 1.403684526361445

Epoch: 6| Step: 13
Training loss: 0.1691918671131134
Validation loss: 1.4309519881843238

Epoch: 545| Step: 0
Training loss: 0.10836854577064514
Validation loss: 1.416137344093733

Epoch: 6| Step: 1
Training loss: 0.15311801433563232
Validation loss: 1.4550936568167903

Epoch: 6| Step: 2
Training loss: 0.13879460096359253
Validation loss: 1.4397012879771571

Epoch: 6| Step: 3
Training loss: 0.1251409649848938
Validation loss: 1.4537843670896304

Epoch: 6| Step: 4
Training loss: 0.11473176628351212
Validation loss: 1.4765092224203131

Epoch: 6| Step: 5
Training loss: 0.1257367879152298
Validation loss: 1.4804084480449717

Epoch: 6| Step: 6
Training loss: 0.19206826388835907
Validation loss: 1.4665138080555906

Epoch: 6| Step: 7
Training loss: 0.23328688740730286
Validation loss: 1.469175560500032

Epoch: 6| Step: 8
Training loss: 0.1380077302455902
Validation loss: 1.4236131034871584

Epoch: 6| Step: 9
Training loss: 0.14615148305892944
Validation loss: 1.3939354958072785

Epoch: 6| Step: 10
Training loss: 0.15050728619098663
Validation loss: 1.4126527655509211

Epoch: 6| Step: 11
Training loss: 0.11545013636350632
Validation loss: 1.416612608458406

Epoch: 6| Step: 12
Training loss: 0.21533116698265076
Validation loss: 1.374344136125298

Epoch: 6| Step: 13
Training loss: 0.11877655982971191
Validation loss: 1.3557361928365563

Epoch: 546| Step: 0
Training loss: 0.09245361387729645
Validation loss: 1.3772145189264768

Epoch: 6| Step: 1
Training loss: 0.16164106130599976
Validation loss: 1.360035728382808

Epoch: 6| Step: 2
Training loss: 0.06820859760046005
Validation loss: 1.3919085635933826

Epoch: 6| Step: 3
Training loss: 0.10541937500238419
Validation loss: 1.3708967457535446

Epoch: 6| Step: 4
Training loss: 0.08461880683898926
Validation loss: 1.387980310506718

Epoch: 6| Step: 5
Training loss: 0.09948859363794327
Validation loss: 1.4148248113611692

Epoch: 6| Step: 6
Training loss: 0.0883607566356659
Validation loss: 1.4262706938610281

Epoch: 6| Step: 7
Training loss: 0.10548240691423416
Validation loss: 1.4349973791389055

Epoch: 6| Step: 8
Training loss: 0.2799842655658722
Validation loss: 1.4581615489016297

Epoch: 6| Step: 9
Training loss: 0.1837266981601715
Validation loss: 1.4324825297119796

Epoch: 6| Step: 10
Training loss: 0.08423299342393875
Validation loss: 1.4117626028676187

Epoch: 6| Step: 11
Training loss: 0.09888767451047897
Validation loss: 1.3862574997768606

Epoch: 6| Step: 12
Training loss: 0.09320041537284851
Validation loss: 1.3957373044824088

Epoch: 6| Step: 13
Training loss: 0.1440882384777069
Validation loss: 1.384810870693576

Epoch: 547| Step: 0
Training loss: 0.11786111444234848
Validation loss: 1.374995655910943

Epoch: 6| Step: 1
Training loss: 0.10589093714952469
Validation loss: 1.3855581232296523

Epoch: 6| Step: 2
Training loss: 0.20599797368049622
Validation loss: 1.4188653640849616

Epoch: 6| Step: 3
Training loss: 0.06029532104730606
Validation loss: 1.4134511498994724

Epoch: 6| Step: 4
Training loss: 0.07564325630664825
Validation loss: 1.4198280201163342

Epoch: 6| Step: 5
Training loss: 0.19715911149978638
Validation loss: 1.4568213237229215

Epoch: 6| Step: 6
Training loss: 0.10900551080703735
Validation loss: 1.489738191327741

Epoch: 6| Step: 7
Training loss: 0.169409841299057
Validation loss: 1.463999326511096

Epoch: 6| Step: 8
Training loss: 0.06629271805286407
Validation loss: 1.4754546393630326

Epoch: 6| Step: 9
Training loss: 0.08775268495082855
Validation loss: 1.4579711780753186

Epoch: 6| Step: 10
Training loss: 0.08581147342920303
Validation loss: 1.4394877174849152

Epoch: 6| Step: 11
Training loss: 0.09681279957294464
Validation loss: 1.4261276068225983

Epoch: 6| Step: 12
Training loss: 0.08982975780963898
Validation loss: 1.4164314859656877

Epoch: 6| Step: 13
Training loss: 0.055505115538835526
Validation loss: 1.4069859366263113

Epoch: 548| Step: 0
Training loss: 0.06694985926151276
Validation loss: 1.3975851689615557

Epoch: 6| Step: 1
Training loss: 0.12006177753210068
Validation loss: 1.381481752600721

Epoch: 6| Step: 2
Training loss: 0.16928263008594513
Validation loss: 1.3276819215025952

Epoch: 6| Step: 3
Training loss: 0.22590738534927368
Validation loss: 1.3567605672344085

Epoch: 6| Step: 4
Training loss: 0.14144966006278992
Validation loss: 1.339789907137553

Epoch: 6| Step: 5
Training loss: 0.06301331520080566
Validation loss: 1.3494953493918143

Epoch: 6| Step: 6
Training loss: 0.06397683918476105
Validation loss: 1.3390856494185746

Epoch: 6| Step: 7
Training loss: 0.1076122298836708
Validation loss: 1.3737553729805896

Epoch: 6| Step: 8
Training loss: 0.11968030780553818
Validation loss: 1.390352399118485

Epoch: 6| Step: 9
Training loss: 0.08631961047649384
Validation loss: 1.4021561286782707

Epoch: 6| Step: 10
Training loss: 0.2268618941307068
Validation loss: 1.4038306449049263

Epoch: 6| Step: 11
Training loss: 0.09750919044017792
Validation loss: 1.3849910023391887

Epoch: 6| Step: 12
Training loss: 0.08819998800754547
Validation loss: 1.3465732028407436

Epoch: 6| Step: 13
Training loss: 0.0544603131711483
Validation loss: 1.327239428797076

Epoch: 549| Step: 0
Training loss: 0.11920750141143799
Validation loss: 1.3514984051386516

Epoch: 6| Step: 1
Training loss: 0.06864815950393677
Validation loss: 1.3091215087521462

Epoch: 6| Step: 2
Training loss: 0.0890432819724083
Validation loss: 1.2966456413269043

Epoch: 6| Step: 3
Training loss: 0.13896222412586212
Validation loss: 1.3210362965060818

Epoch: 6| Step: 4
Training loss: 0.2307681441307068
Validation loss: 1.3505107241292154

Epoch: 6| Step: 5
Training loss: 0.06980004161596298
Validation loss: 1.3913990925717097

Epoch: 6| Step: 6
Training loss: 0.09596876800060272
Validation loss: 1.4102130602764826

Epoch: 6| Step: 7
Training loss: 0.0994642972946167
Validation loss: 1.4304517969008415

Epoch: 6| Step: 8
Training loss: 0.14157617092132568
Validation loss: 1.440076994639571

Epoch: 6| Step: 9
Training loss: 0.1084708645939827
Validation loss: 1.421031286639552

Epoch: 6| Step: 10
Training loss: 0.14580556750297546
Validation loss: 1.4040061837883406

Epoch: 6| Step: 11
Training loss: 0.12576338648796082
Validation loss: 1.3746196967299267

Epoch: 6| Step: 12
Training loss: 0.12543164193630219
Validation loss: 1.4051791006518948

Epoch: 6| Step: 13
Training loss: 0.08918412774801254
Validation loss: 1.3835727989032705

Epoch: 550| Step: 0
Training loss: 0.08868987113237381
Validation loss: 1.3880764386987174

Epoch: 6| Step: 1
Training loss: 0.11628492176532745
Validation loss: 1.3910382582295326

Epoch: 6| Step: 2
Training loss: 0.1446915715932846
Validation loss: 1.3949505141986314

Epoch: 6| Step: 3
Training loss: 0.05715527385473251
Validation loss: 1.3942907946084135

Epoch: 6| Step: 4
Training loss: 0.08482646942138672
Validation loss: 1.4645684688322005

Epoch: 6| Step: 5
Training loss: 0.09670688211917877
Validation loss: 1.442588553633741

Epoch: 6| Step: 6
Training loss: 0.20795193314552307
Validation loss: 1.4780175544882332

Epoch: 6| Step: 7
Training loss: 0.228532612323761
Validation loss: 1.4539140514148179

Epoch: 6| Step: 8
Training loss: 0.16733749210834503
Validation loss: 1.4358568012073476

Epoch: 6| Step: 9
Training loss: 0.07583968341350555
Validation loss: 1.4117402620213007

Epoch: 6| Step: 10
Training loss: 0.08368885517120361
Validation loss: 1.3800112425640065

Epoch: 6| Step: 11
Training loss: 0.10364566743373871
Validation loss: 1.3931079885011077

Epoch: 6| Step: 12
Training loss: 0.08544556796550751
Validation loss: 1.3635877383652555

Epoch: 6| Step: 13
Training loss: 0.0713931992650032
Validation loss: 1.3794977754674933

Epoch: 551| Step: 0
Training loss: 0.16838175058364868
Validation loss: 1.368441233070948

Epoch: 6| Step: 1
Training loss: 0.10007668286561966
Validation loss: 1.3946762764325706

Epoch: 6| Step: 2
Training loss: 0.06539833545684814
Validation loss: 1.3838405557858047

Epoch: 6| Step: 3
Training loss: 0.09800553321838379
Validation loss: 1.374184585386707

Epoch: 6| Step: 4
Training loss: 0.08322037756443024
Validation loss: 1.4198489407057404

Epoch: 6| Step: 5
Training loss: 0.1876501739025116
Validation loss: 1.4087196191151936

Epoch: 6| Step: 6
Training loss: 0.07959935069084167
Validation loss: 1.4285541247296076

Epoch: 6| Step: 7
Training loss: 0.1026911586523056
Validation loss: 1.4344957541393977

Epoch: 6| Step: 8
Training loss: 0.08482863008975983
Validation loss: 1.414808847570932

Epoch: 6| Step: 9
Training loss: 0.05526581034064293
Validation loss: 1.4072787582233388

Epoch: 6| Step: 10
Training loss: 0.0446888729929924
Validation loss: 1.3808930099651378

Epoch: 6| Step: 11
Training loss: 0.1493964046239853
Validation loss: 1.3728453933551747

Epoch: 6| Step: 12
Training loss: 0.28310906887054443
Validation loss: 1.3823453162306099

Epoch: 6| Step: 13
Training loss: 0.10491335391998291
Validation loss: 1.3799435156647877

Epoch: 552| Step: 0
Training loss: 0.08329403400421143
Validation loss: 1.3425507558289396

Epoch: 6| Step: 1
Training loss: 0.1042964905500412
Validation loss: 1.3343208041242374

Epoch: 6| Step: 2
Training loss: 0.08692500740289688
Validation loss: 1.3144255799631919

Epoch: 6| Step: 3
Training loss: 0.07495192438364029
Validation loss: 1.3155056020264984

Epoch: 6| Step: 4
Training loss: 0.11115224659442902
Validation loss: 1.3135148389365083

Epoch: 6| Step: 5
Training loss: 0.15741664171218872
Validation loss: 1.3456552015837802

Epoch: 6| Step: 6
Training loss: 0.06805265694856644
Validation loss: 1.327516589113461

Epoch: 6| Step: 7
Training loss: 0.15947169065475464
Validation loss: 1.3612309091834611

Epoch: 6| Step: 8
Training loss: 0.1914292722940445
Validation loss: 1.3806128412164667

Epoch: 6| Step: 9
Training loss: 0.09430500119924545
Validation loss: 1.3672012334228845

Epoch: 6| Step: 10
Training loss: 0.10091209411621094
Validation loss: 1.4059764339077858

Epoch: 6| Step: 11
Training loss: 0.08879149705171585
Validation loss: 1.4242023062962357

Epoch: 6| Step: 12
Training loss: 0.14532476663589478
Validation loss: 1.4234054101410734

Epoch: 6| Step: 13
Training loss: 0.07224085927009583
Validation loss: 1.4308441928637925

Epoch: 553| Step: 0
Training loss: 0.0740818902850151
Validation loss: 1.4037774044980285

Epoch: 6| Step: 1
Training loss: 0.09273599088191986
Validation loss: 1.400305328830596

Epoch: 6| Step: 2
Training loss: 0.07221037149429321
Validation loss: 1.3982197110370924

Epoch: 6| Step: 3
Training loss: 0.10704873502254486
Validation loss: 1.3757235606511433

Epoch: 6| Step: 4
Training loss: 0.09394299983978271
Validation loss: 1.3985789334902199

Epoch: 6| Step: 5
Training loss: 0.15761011838912964
Validation loss: 1.374115995181504

Epoch: 6| Step: 6
Training loss: 0.13572503626346588
Validation loss: 1.3904691639766897

Epoch: 6| Step: 7
Training loss: 0.11074353754520416
Validation loss: 1.3578429004197479

Epoch: 6| Step: 8
Training loss: 0.12456697970628738
Validation loss: 1.3874298654576784

Epoch: 6| Step: 9
Training loss: 0.05728382617235184
Validation loss: 1.374533869886911

Epoch: 6| Step: 10
Training loss: 0.16269339621067047
Validation loss: 1.417257260250789

Epoch: 6| Step: 11
Training loss: 0.10012055933475494
Validation loss: 1.4069978126915552

Epoch: 6| Step: 12
Training loss: 0.07778296619653702
Validation loss: 1.3849552882614957

Epoch: 6| Step: 13
Training loss: 0.17441900074481964
Validation loss: 1.3793159896327603

Epoch: 554| Step: 0
Training loss: 0.06653441488742828
Validation loss: 1.3912848125221908

Epoch: 6| Step: 1
Training loss: 0.11689210683107376
Validation loss: 1.4075198147886543

Epoch: 6| Step: 2
Training loss: 0.1241832748055458
Validation loss: 1.391484889932858

Epoch: 6| Step: 3
Training loss: 0.11151155829429626
Validation loss: 1.432278859999872

Epoch: 6| Step: 4
Training loss: 0.08932864665985107
Validation loss: 1.4177638253858011

Epoch: 6| Step: 5
Training loss: 0.11928857117891312
Validation loss: 1.423758625984192

Epoch: 6| Step: 6
Training loss: 0.14834707975387573
Validation loss: 1.3905215622276388

Epoch: 6| Step: 7
Training loss: 0.09409362077713013
Validation loss: 1.3984093883986115

Epoch: 6| Step: 8
Training loss: 0.10797736048698425
Validation loss: 1.3963230758584955

Epoch: 6| Step: 9
Training loss: 0.11951771378517151
Validation loss: 1.3631443272354782

Epoch: 6| Step: 10
Training loss: 0.11033344268798828
Validation loss: 1.342705854805567

Epoch: 6| Step: 11
Training loss: 0.14837028086185455
Validation loss: 1.3666277290672384

Epoch: 6| Step: 12
Training loss: 0.08418574184179306
Validation loss: 1.3556735759140344

Epoch: 6| Step: 13
Training loss: 0.21060241758823395
Validation loss: 1.3523337789761123

Epoch: 555| Step: 0
Training loss: 0.12889742851257324
Validation loss: 1.3527844208543018

Epoch: 6| Step: 1
Training loss: 0.09639622271060944
Validation loss: 1.3290523841816893

Epoch: 6| Step: 2
Training loss: 0.11716124415397644
Validation loss: 1.3571468476326234

Epoch: 6| Step: 3
Training loss: 0.0759095847606659
Validation loss: 1.3558063532716484

Epoch: 6| Step: 4
Training loss: 0.07984216511249542
Validation loss: 1.3416439410178893

Epoch: 6| Step: 5
Training loss: 0.10128547996282578
Validation loss: 1.3685000968235794

Epoch: 6| Step: 6
Training loss: 0.12100419402122498
Validation loss: 1.408306852463753

Epoch: 6| Step: 7
Training loss: 0.06866985559463501
Validation loss: 1.366299113919658

Epoch: 6| Step: 8
Training loss: 0.09253502637147903
Validation loss: 1.3683064227463098

Epoch: 6| Step: 9
Training loss: 0.09165751188993454
Validation loss: 1.40404664316485

Epoch: 6| Step: 10
Training loss: 0.09728114306926727
Validation loss: 1.3687591886007657

Epoch: 6| Step: 11
Training loss: 0.07726693898439407
Validation loss: 1.3644903821329917

Epoch: 6| Step: 12
Training loss: 0.19677424430847168
Validation loss: 1.3346175160459293

Epoch: 6| Step: 13
Training loss: 0.08295215666294098
Validation loss: 1.3461215483245028

Epoch: 556| Step: 0
Training loss: 0.1290304809808731
Validation loss: 1.3122800242516302

Epoch: 6| Step: 1
Training loss: 0.07068721950054169
Validation loss: 1.331164385682793

Epoch: 6| Step: 2
Training loss: 0.06838880479335785
Validation loss: 1.338801723013642

Epoch: 6| Step: 3
Training loss: 0.1279599368572235
Validation loss: 1.3422276332814207

Epoch: 6| Step: 4
Training loss: 0.0617346428334713
Validation loss: 1.3596332291121125

Epoch: 6| Step: 5
Training loss: 0.17302687466144562
Validation loss: 1.3470290739049193

Epoch: 6| Step: 6
Training loss: 0.1045084297657013
Validation loss: 1.3591581006203928

Epoch: 6| Step: 7
Training loss: 0.3088802993297577
Validation loss: 1.3539600244132421

Epoch: 6| Step: 8
Training loss: 0.15423357486724854
Validation loss: 1.3938074137574883

Epoch: 6| Step: 9
Training loss: 0.09900741279125214
Validation loss: 1.3639973543023551

Epoch: 6| Step: 10
Training loss: 0.1536342203617096
Validation loss: 1.3680846998768468

Epoch: 6| Step: 11
Training loss: 0.1038556769490242
Validation loss: 1.332325226517134

Epoch: 6| Step: 12
Training loss: 0.0978778600692749
Validation loss: 1.3211364284638436

Epoch: 6| Step: 13
Training loss: 0.10151217877864838
Validation loss: 1.339908488335148

Epoch: 557| Step: 0
Training loss: 0.1300784945487976
Validation loss: 1.3423675023099428

Epoch: 6| Step: 1
Training loss: 0.11630071699619293
Validation loss: 1.3510993424282278

Epoch: 6| Step: 2
Training loss: 0.18057361245155334
Validation loss: 1.3521555469882103

Epoch: 6| Step: 3
Training loss: 0.11681056022644043
Validation loss: 1.4137255286657682

Epoch: 6| Step: 4
Training loss: 0.04119298607110977
Validation loss: 1.4072024565871044

Epoch: 6| Step: 5
Training loss: 0.08984057605266571
Validation loss: 1.4331016796891407

Epoch: 6| Step: 6
Training loss: 0.11713559925556183
Validation loss: 1.4263787064501035

Epoch: 6| Step: 7
Training loss: 0.08672959357500076
Validation loss: 1.426687890483487

Epoch: 6| Step: 8
Training loss: 0.1035008430480957
Validation loss: 1.4192448450673012

Epoch: 6| Step: 9
Training loss: 0.07786682993173599
Validation loss: 1.3835955640321136

Epoch: 6| Step: 10
Training loss: 0.07621665298938751
Validation loss: 1.3580003733276038

Epoch: 6| Step: 11
Training loss: 0.10312646627426147
Validation loss: 1.330070040559256

Epoch: 6| Step: 12
Training loss: 0.09256233274936676
Validation loss: 1.3046249164048063

Epoch: 6| Step: 13
Training loss: 0.2644922435283661
Validation loss: 1.316749180516889

Epoch: 558| Step: 0
Training loss: 0.11423750221729279
Validation loss: 1.3244061745623106

Epoch: 6| Step: 1
Training loss: 0.06371753662824631
Validation loss: 1.3358647989970382

Epoch: 6| Step: 2
Training loss: 0.07902856171131134
Validation loss: 1.3591093837573964

Epoch: 6| Step: 3
Training loss: 0.0616641491651535
Validation loss: 1.3505027082658583

Epoch: 6| Step: 4
Training loss: 0.06643547862768173
Validation loss: 1.3747125428210023

Epoch: 6| Step: 5
Training loss: 0.2258099615573883
Validation loss: 1.4137819274779289

Epoch: 6| Step: 6
Training loss: 0.10664127767086029
Validation loss: 1.4053413214222077

Epoch: 6| Step: 7
Training loss: 0.15768423676490784
Validation loss: 1.4572347697391306

Epoch: 6| Step: 8
Training loss: 0.08437734842300415
Validation loss: 1.4631634963456022

Epoch: 6| Step: 9
Training loss: 0.18433025479316711
Validation loss: 1.4690747632775256

Epoch: 6| Step: 10
Training loss: 0.14066055417060852
Validation loss: 1.4091272200307539

Epoch: 6| Step: 11
Training loss: 0.1184917688369751
Validation loss: 1.3340155398973854

Epoch: 6| Step: 12
Training loss: 0.16044367849826813
Validation loss: 1.2911205842930784

Epoch: 6| Step: 13
Training loss: 0.12188634276390076
Validation loss: 1.2839868158422492

Epoch: 559| Step: 0
Training loss: 0.1253572702407837
Validation loss: 1.2632603030050955

Epoch: 6| Step: 1
Training loss: 0.14031089842319489
Validation loss: 1.2743912076437345

Epoch: 6| Step: 2
Training loss: 0.20304062962532043
Validation loss: 1.2555872573647449

Epoch: 6| Step: 3
Training loss: 0.1994519978761673
Validation loss: 1.2875519824284378

Epoch: 6| Step: 4
Training loss: 0.10888941586017609
Validation loss: 1.2663529444766302

Epoch: 6| Step: 5
Training loss: 0.07706377655267715
Validation loss: 1.28337380578441

Epoch: 6| Step: 6
Training loss: 0.1087736040353775
Validation loss: 1.3184221745819173

Epoch: 6| Step: 7
Training loss: 0.10472041368484497
Validation loss: 1.3446906535856185

Epoch: 6| Step: 8
Training loss: 0.1251341998577118
Validation loss: 1.3776915073394775

Epoch: 6| Step: 9
Training loss: 0.10912495851516724
Validation loss: 1.3661731366188294

Epoch: 6| Step: 10
Training loss: 0.05151008814573288
Validation loss: 1.3905012889574933

Epoch: 6| Step: 11
Training loss: 0.06072472035884857
Validation loss: 1.3768518855494838

Epoch: 6| Step: 12
Training loss: 0.13030609488487244
Validation loss: 1.3728743342943088

Epoch: 6| Step: 13
Training loss: 0.2178286761045456
Validation loss: 1.3551664454962618

Epoch: 560| Step: 0
Training loss: 0.23036319017410278
Validation loss: 1.3396610470228298

Epoch: 6| Step: 1
Training loss: 0.05449190363287926
Validation loss: 1.3295702062627321

Epoch: 6| Step: 2
Training loss: 0.09123141318559647
Validation loss: 1.339275336393746

Epoch: 6| Step: 3
Training loss: 0.06823067367076874
Validation loss: 1.3520520976794663

Epoch: 6| Step: 4
Training loss: 0.12172488868236542
Validation loss: 1.316887722220472

Epoch: 6| Step: 5
Training loss: 0.13021519780158997
Validation loss: 1.3127878276250695

Epoch: 6| Step: 6
Training loss: 0.07675255089998245
Validation loss: 1.3251774503338722

Epoch: 6| Step: 7
Training loss: 0.07796745002269745
Validation loss: 1.3157400764444822

Epoch: 6| Step: 8
Training loss: 0.1247842013835907
Validation loss: 1.3331721790375248

Epoch: 6| Step: 9
Training loss: 0.09816774725914001
Validation loss: 1.3440978873160578

Epoch: 6| Step: 10
Training loss: 0.0753105953335762
Validation loss: 1.3139253611205726

Epoch: 6| Step: 11
Training loss: 0.12061735987663269
Validation loss: 1.2975243278729018

Epoch: 6| Step: 12
Training loss: 0.06024046614766121
Validation loss: 1.3557522899361067

Epoch: 6| Step: 13
Training loss: 0.07468719035387039
Validation loss: 1.3300695419311523

Epoch: 561| Step: 0
Training loss: 0.1632455736398697
Validation loss: 1.335938572883606

Epoch: 6| Step: 1
Training loss: 0.04720994830131531
Validation loss: 1.3347857504762628

Epoch: 6| Step: 2
Training loss: 0.12945738434791565
Validation loss: 1.3439260772479478

Epoch: 6| Step: 3
Training loss: 0.0759376734495163
Validation loss: 1.3578059173399402

Epoch: 6| Step: 4
Training loss: 0.11954234540462494
Validation loss: 1.345135437544956

Epoch: 6| Step: 5
Training loss: 0.1478765606880188
Validation loss: 1.3471050839270315

Epoch: 6| Step: 6
Training loss: 0.08125860244035721
Validation loss: 1.3378492016946115

Epoch: 6| Step: 7
Training loss: 0.141915425658226
Validation loss: 1.3336801490476053

Epoch: 6| Step: 8
Training loss: 0.06712361425161362
Validation loss: 1.339209871907388

Epoch: 6| Step: 9
Training loss: 0.08500704169273376
Validation loss: 1.3852871246235345

Epoch: 6| Step: 10
Training loss: 0.0558428056538105
Validation loss: 1.3497479410581692

Epoch: 6| Step: 11
Training loss: 0.1465785801410675
Validation loss: 1.3499462514795282

Epoch: 6| Step: 12
Training loss: 0.17047333717346191
Validation loss: 1.3560455896521126

Epoch: 6| Step: 13
Training loss: 0.0822446346282959
Validation loss: 1.371233030032086

Epoch: 562| Step: 0
Training loss: 0.08512287586927414
Validation loss: 1.3776288173531974

Epoch: 6| Step: 1
Training loss: 0.147691011428833
Validation loss: 1.3686471998050649

Epoch: 6| Step: 2
Training loss: 0.08644825220108032
Validation loss: 1.398746339223718

Epoch: 6| Step: 3
Training loss: 0.07964092493057251
Validation loss: 1.4050881183275612

Epoch: 6| Step: 4
Training loss: 0.06910587102174759
Validation loss: 1.4120971272068639

Epoch: 6| Step: 5
Training loss: 0.20467528700828552
Validation loss: 1.3711167368837582

Epoch: 6| Step: 6
Training loss: 0.12977178394794464
Validation loss: 1.3706596519357415

Epoch: 6| Step: 7
Training loss: 0.17929774522781372
Validation loss: 1.3395565978942379

Epoch: 6| Step: 8
Training loss: 0.13232767581939697
Validation loss: 1.3294498100075671

Epoch: 6| Step: 9
Training loss: 0.08565089106559753
Validation loss: 1.318401043133069

Epoch: 6| Step: 10
Training loss: 0.10908941924571991
Validation loss: 1.3334855751324726

Epoch: 6| Step: 11
Training loss: 0.08099241554737091
Validation loss: 1.3800626621451428

Epoch: 6| Step: 12
Training loss: 0.06627991050481796
Validation loss: 1.3772600267523079

Epoch: 6| Step: 13
Training loss: 0.0878838300704956
Validation loss: 1.3979109141134447

Epoch: 563| Step: 0
Training loss: 0.11550156027078629
Validation loss: 1.4113588551039338

Epoch: 6| Step: 1
Training loss: 0.22057560086250305
Validation loss: 1.4368879077255086

Epoch: 6| Step: 2
Training loss: 0.10450230538845062
Validation loss: 1.445560448913164

Epoch: 6| Step: 3
Training loss: 0.10766193270683289
Validation loss: 1.474695990162511

Epoch: 6| Step: 4
Training loss: 0.12598249316215515
Validation loss: 1.438444745156073

Epoch: 6| Step: 5
Training loss: 0.14557896554470062
Validation loss: 1.4218319590373705

Epoch: 6| Step: 6
Training loss: 0.10834945738315582
Validation loss: 1.3826733834000045

Epoch: 6| Step: 7
Training loss: 0.11095421761274338
Validation loss: 1.371358467686561

Epoch: 6| Step: 8
Training loss: 0.10713499784469604
Validation loss: 1.3753455428666965

Epoch: 6| Step: 9
Training loss: 0.07423502206802368
Validation loss: 1.3590557921317317

Epoch: 6| Step: 10
Training loss: 0.183700293302536
Validation loss: 1.358651985404312

Epoch: 6| Step: 11
Training loss: 0.08361360430717468
Validation loss: 1.363378523498453

Epoch: 6| Step: 12
Training loss: 0.11146967113018036
Validation loss: 1.3662145849197143

Epoch: 6| Step: 13
Training loss: 0.08065531402826309
Validation loss: 1.3355494699170511

Epoch: 564| Step: 0
Training loss: 0.06468445062637329
Validation loss: 1.3571742760237826

Epoch: 6| Step: 1
Training loss: 0.12737664580345154
Validation loss: 1.3513511060386576

Epoch: 6| Step: 2
Training loss: 0.077132448554039
Validation loss: 1.3345220473504835

Epoch: 6| Step: 3
Training loss: 0.15457069873809814
Validation loss: 1.3316068098109255

Epoch: 6| Step: 4
Training loss: 0.09314216673374176
Validation loss: 1.3089454468860422

Epoch: 6| Step: 5
Training loss: 0.16668148338794708
Validation loss: 1.3370494470801404

Epoch: 6| Step: 6
Training loss: 0.08599326014518738
Validation loss: 1.330154654800251

Epoch: 6| Step: 7
Training loss: 0.11026529967784882
Validation loss: 1.326879532106461

Epoch: 6| Step: 8
Training loss: 0.06352411955595016
Validation loss: 1.314418371005725

Epoch: 6| Step: 9
Training loss: 0.0574897937476635
Validation loss: 1.3410135462719908

Epoch: 6| Step: 10
Training loss: 0.1216997355222702
Validation loss: 1.3406338518665684

Epoch: 6| Step: 11
Training loss: 0.08433925360441208
Validation loss: 1.328589698319794

Epoch: 6| Step: 12
Training loss: 0.09070034325122833
Validation loss: 1.3178025573812506

Epoch: 6| Step: 13
Training loss: 0.11346428841352463
Validation loss: 1.344761521585526

Epoch: 565| Step: 0
Training loss: 0.08305282890796661
Validation loss: 1.3453043250627414

Epoch: 6| Step: 1
Training loss: 0.08324062824249268
Validation loss: 1.3184590006387362

Epoch: 6| Step: 2
Training loss: 0.21736285090446472
Validation loss: 1.3542753637477916

Epoch: 6| Step: 3
Training loss: 0.07369565963745117
Validation loss: 1.3346826934045362

Epoch: 6| Step: 4
Training loss: 0.07697055488824844
Validation loss: 1.3547942218601063

Epoch: 6| Step: 5
Training loss: 0.10267914086580276
Validation loss: 1.3378087115544144

Epoch: 6| Step: 6
Training loss: 0.10922136902809143
Validation loss: 1.3633998337612356

Epoch: 6| Step: 7
Training loss: 0.08104871958494186
Validation loss: 1.3552994189723846

Epoch: 6| Step: 8
Training loss: 0.09840476512908936
Validation loss: 1.3504174922102241

Epoch: 6| Step: 9
Training loss: 0.08150984346866608
Validation loss: 1.345083285403508

Epoch: 6| Step: 10
Training loss: 0.12917637825012207
Validation loss: 1.3226360761991112

Epoch: 6| Step: 11
Training loss: 0.10758712142705917
Validation loss: 1.3481954425893805

Epoch: 6| Step: 12
Training loss: 0.06470119953155518
Validation loss: 1.3416009885008617

Epoch: 6| Step: 13
Training loss: 0.064083993434906
Validation loss: 1.3686483290887648

Epoch: 566| Step: 0
Training loss: 0.09481245279312134
Validation loss: 1.4014132298449034

Epoch: 6| Step: 1
Training loss: 0.07426370680332184
Validation loss: 1.4104868577372642

Epoch: 6| Step: 2
Training loss: 0.0732998475432396
Validation loss: 1.403448982905316

Epoch: 6| Step: 3
Training loss: 0.09808257967233658
Validation loss: 1.4021919542743313

Epoch: 6| Step: 4
Training loss: 0.05496101453900337
Validation loss: 1.3796763202195526

Epoch: 6| Step: 5
Training loss: 0.16490641236305237
Validation loss: 1.355578343073527

Epoch: 6| Step: 6
Training loss: 0.0914856567978859
Validation loss: 1.377665206950198

Epoch: 6| Step: 7
Training loss: 0.0808744803071022
Validation loss: 1.3502370093458442

Epoch: 6| Step: 8
Training loss: 0.08111107349395752
Validation loss: 1.3605167314570437

Epoch: 6| Step: 9
Training loss: 0.11733956634998322
Validation loss: 1.3706482674485894

Epoch: 6| Step: 10
Training loss: 0.19388991594314575
Validation loss: 1.359229838976296

Epoch: 6| Step: 11
Training loss: 0.14352405071258545
Validation loss: 1.3814833792307044

Epoch: 6| Step: 12
Training loss: 0.05283302813768387
Validation loss: 1.3772150342182448

Epoch: 6| Step: 13
Training loss: 0.14146947860717773
Validation loss: 1.427814818197681

Epoch: 567| Step: 0
Training loss: 0.10318043828010559
Validation loss: 1.4210884712075675

Epoch: 6| Step: 1
Training loss: 0.08239317685365677
Validation loss: 1.3966955151609195

Epoch: 6| Step: 2
Training loss: 0.06630539149045944
Validation loss: 1.3915058130859046

Epoch: 6| Step: 3
Training loss: 0.08888287842273712
Validation loss: 1.3967173214881652

Epoch: 6| Step: 4
Training loss: 0.08599526435136795
Validation loss: 1.3642005433318436

Epoch: 6| Step: 5
Training loss: 0.07718688994646072
Validation loss: 1.3667399075723463

Epoch: 6| Step: 6
Training loss: 0.11361440271139145
Validation loss: 1.3491897954735705

Epoch: 6| Step: 7
Training loss: 0.16177994012832642
Validation loss: 1.3356321934730775

Epoch: 6| Step: 8
Training loss: 0.15923315286636353
Validation loss: 1.3653587436163297

Epoch: 6| Step: 9
Training loss: 0.06381581723690033
Validation loss: 1.3647765780007968

Epoch: 6| Step: 10
Training loss: 0.09319208562374115
Validation loss: 1.3318194330379527

Epoch: 6| Step: 11
Training loss: 0.08503727614879608
Validation loss: 1.3326640116271151

Epoch: 6| Step: 12
Training loss: 0.1241307407617569
Validation loss: 1.316183413228681

Epoch: 6| Step: 13
Training loss: 0.054905619472265244
Validation loss: 1.3209648927052815

Epoch: 568| Step: 0
Training loss: 0.07655253261327744
Validation loss: 1.3169439505505305

Epoch: 6| Step: 1
Training loss: 0.035557545721530914
Validation loss: 1.3411949123105695

Epoch: 6| Step: 2
Training loss: 0.058439694344997406
Validation loss: 1.3271016984857538

Epoch: 6| Step: 3
Training loss: 0.11089116334915161
Validation loss: 1.3308328044029973

Epoch: 6| Step: 4
Training loss: 0.09284952282905579
Validation loss: 1.3362530739076677

Epoch: 6| Step: 5
Training loss: 0.17428064346313477
Validation loss: 1.3283586463620585

Epoch: 6| Step: 6
Training loss: 0.14410875737667084
Validation loss: 1.338484901253895

Epoch: 6| Step: 7
Training loss: 0.15352080762386322
Validation loss: 1.3773017737173265

Epoch: 6| Step: 8
Training loss: 0.07378539443016052
Validation loss: 1.3597232936530985

Epoch: 6| Step: 9
Training loss: 0.07315116375684738
Validation loss: 1.3394820151790496

Epoch: 6| Step: 10
Training loss: 0.06325611472129822
Validation loss: 1.3501253166506368

Epoch: 6| Step: 11
Training loss: 0.10025627166032791
Validation loss: 1.3247131775784236

Epoch: 6| Step: 12
Training loss: 0.0867748111486435
Validation loss: 1.3340067299463416

Epoch: 6| Step: 13
Training loss: 0.08431106060743332
Validation loss: 1.3460814363212996

Epoch: 569| Step: 0
Training loss: 0.05605320259928703
Validation loss: 1.3525200684865315

Epoch: 6| Step: 1
Training loss: 0.04694820195436478
Validation loss: 1.364958893227321

Epoch: 6| Step: 2
Training loss: 0.12215661257505417
Validation loss: 1.3733318941567534

Epoch: 6| Step: 3
Training loss: 0.06874486058950424
Validation loss: 1.3857830230907728

Epoch: 6| Step: 4
Training loss: 0.16819675266742706
Validation loss: 1.3620099867543867

Epoch: 6| Step: 5
Training loss: 0.14428797364234924
Validation loss: 1.345134634484527

Epoch: 6| Step: 6
Training loss: 0.06655015796422958
Validation loss: 1.3364390480902888

Epoch: 6| Step: 7
Training loss: 0.08153139799833298
Validation loss: 1.3662998548118017

Epoch: 6| Step: 8
Training loss: 0.04668411239981651
Validation loss: 1.3750959891144947

Epoch: 6| Step: 9
Training loss: 0.10271966457366943
Validation loss: 1.3669612510229951

Epoch: 6| Step: 10
Training loss: 0.09726254642009735
Validation loss: 1.3607161500120675

Epoch: 6| Step: 11
Training loss: 0.07176963984966278
Validation loss: 1.3766780989144438

Epoch: 6| Step: 12
Training loss: 0.12840460240840912
Validation loss: 1.3640313680453966

Epoch: 6| Step: 13
Training loss: 0.07321026921272278
Validation loss: 1.3722531122546042

Epoch: 570| Step: 0
Training loss: 0.1697026938199997
Validation loss: 1.3656635322878439

Epoch: 6| Step: 1
Training loss: 0.09292271733283997
Validation loss: 1.349959736229271

Epoch: 6| Step: 2
Training loss: 0.11258845776319504
Validation loss: 1.3766753987599445

Epoch: 6| Step: 3
Training loss: 0.031244788318872452
Validation loss: 1.3502270008928032

Epoch: 6| Step: 4
Training loss: 0.10881020128726959
Validation loss: 1.3623826080752957

Epoch: 6| Step: 5
Training loss: 0.06434138119220734
Validation loss: 1.3647146289066603

Epoch: 6| Step: 6
Training loss: 0.10492276400327682
Validation loss: 1.3712949932262462

Epoch: 6| Step: 7
Training loss: 0.06273201107978821
Validation loss: 1.3459489525005381

Epoch: 6| Step: 8
Training loss: 0.06056031957268715
Validation loss: 1.3729962187428628

Epoch: 6| Step: 9
Training loss: 0.05164496973156929
Validation loss: 1.3459324343230135

Epoch: 6| Step: 10
Training loss: 0.21389657258987427
Validation loss: 1.3279068495637627

Epoch: 6| Step: 11
Training loss: 0.10366837680339813
Validation loss: 1.3470206055589902

Epoch: 6| Step: 12
Training loss: 0.0732610821723938
Validation loss: 1.3379412607480121

Epoch: 6| Step: 13
Training loss: 0.13058581948280334
Validation loss: 1.3391836894455778

Epoch: 571| Step: 0
Training loss: 0.09312419593334198
Validation loss: 1.3182671230326417

Epoch: 6| Step: 1
Training loss: 0.07496944069862366
Validation loss: 1.3363302740999448

Epoch: 6| Step: 2
Training loss: 0.08105164766311646
Validation loss: 1.319527159455002

Epoch: 6| Step: 3
Training loss: 0.09607155621051788
Validation loss: 1.314591238575597

Epoch: 6| Step: 4
Training loss: 0.122706338763237
Validation loss: 1.3087439831867014

Epoch: 6| Step: 5
Training loss: 0.08917652070522308
Validation loss: 1.3162552528483893

Epoch: 6| Step: 6
Training loss: 0.17252638936042786
Validation loss: 1.3135279340128745

Epoch: 6| Step: 7
Training loss: 0.14370450377464294
Validation loss: 1.3502096719639276

Epoch: 6| Step: 8
Training loss: 0.11317035555839539
Validation loss: 1.336575263289995

Epoch: 6| Step: 9
Training loss: 0.09166209399700165
Validation loss: 1.3916384302159792

Epoch: 6| Step: 10
Training loss: 0.08701950311660767
Validation loss: 1.381830100090273

Epoch: 6| Step: 11
Training loss: 0.08126552402973175
Validation loss: 1.3989569512746667

Epoch: 6| Step: 12
Training loss: 0.0906352549791336
Validation loss: 1.385732340556319

Epoch: 6| Step: 13
Training loss: 0.056452181190252304
Validation loss: 1.375771176430487

Epoch: 572| Step: 0
Training loss: 0.18103031814098358
Validation loss: 1.3709910922153021

Epoch: 6| Step: 1
Training loss: 0.07733175158500671
Validation loss: 1.4143016389621201

Epoch: 6| Step: 2
Training loss: 0.062201350927352905
Validation loss: 1.406083644077342

Epoch: 6| Step: 3
Training loss: 0.06939397007226944
Validation loss: 1.3888624695039564

Epoch: 6| Step: 4
Training loss: 0.0778021365404129
Validation loss: 1.3841327569817985

Epoch: 6| Step: 5
Training loss: 0.1013869196176529
Validation loss: 1.3717119745028916

Epoch: 6| Step: 6
Training loss: 0.081779845058918
Validation loss: 1.3502704892107236

Epoch: 6| Step: 7
Training loss: 0.0683726817369461
Validation loss: 1.350431510197219

Epoch: 6| Step: 8
Training loss: 0.07091502845287323
Validation loss: 1.3598085949497838

Epoch: 6| Step: 9
Training loss: 0.11173995584249496
Validation loss: 1.3532855151801981

Epoch: 6| Step: 10
Training loss: 0.08745333552360535
Validation loss: 1.3511581715717111

Epoch: 6| Step: 11
Training loss: 0.05869890749454498
Validation loss: 1.3640510882100751

Epoch: 6| Step: 12
Training loss: 0.10752582550048828
Validation loss: 1.3558979611242972

Epoch: 6| Step: 13
Training loss: 0.08270842581987381
Validation loss: 1.3501647441617903

Epoch: 573| Step: 0
Training loss: 0.12633828818798065
Validation loss: 1.3896382085738643

Epoch: 6| Step: 1
Training loss: 0.1343221813440323
Validation loss: 1.4307789956369708

Epoch: 6| Step: 2
Training loss: 0.1348157525062561
Validation loss: 1.4220625918398622

Epoch: 6| Step: 3
Training loss: 0.14912347495555878
Validation loss: 1.4496187804847636

Epoch: 6| Step: 4
Training loss: 0.23624564707279205
Validation loss: 1.4222539817133257

Epoch: 6| Step: 5
Training loss: 0.1121891438961029
Validation loss: 1.3592663817508246

Epoch: 6| Step: 6
Training loss: 0.2162114977836609
Validation loss: 1.3365724650762414

Epoch: 6| Step: 7
Training loss: 0.08533766865730286
Validation loss: 1.2931227222565682

Epoch: 6| Step: 8
Training loss: 0.1870342642068863
Validation loss: 1.2857400166091097

Epoch: 6| Step: 9
Training loss: 0.09235605597496033
Validation loss: 1.2788451730564077

Epoch: 6| Step: 10
Training loss: 0.17540699243545532
Validation loss: 1.285589200194164

Epoch: 6| Step: 11
Training loss: 0.1605261266231537
Validation loss: 1.316449854322659

Epoch: 6| Step: 12
Training loss: 0.12157260626554489
Validation loss: 1.3131455042028939

Epoch: 6| Step: 13
Training loss: 0.11571228504180908
Validation loss: 1.318480574315594

Epoch: 574| Step: 0
Training loss: 0.0927770584821701
Validation loss: 1.357178775213098

Epoch: 6| Step: 1
Training loss: 0.1681169867515564
Validation loss: 1.4166657181196316

Epoch: 6| Step: 2
Training loss: 0.10454072058200836
Validation loss: 1.4525042477474417

Epoch: 6| Step: 3
Training loss: 0.12969879806041718
Validation loss: 1.476442321654289

Epoch: 6| Step: 4
Training loss: 0.19161517918109894
Validation loss: 1.489661342354231

Epoch: 6| Step: 5
Training loss: 0.12536373734474182
Validation loss: 1.4937513207876554

Epoch: 6| Step: 6
Training loss: 0.2332274615764618
Validation loss: 1.4742812559168825

Epoch: 6| Step: 7
Training loss: 0.11681002378463745
Validation loss: 1.4555751867191766

Epoch: 6| Step: 8
Training loss: 0.20180410146713257
Validation loss: 1.4390251264777234

Epoch: 6| Step: 9
Training loss: 0.17495481669902802
Validation loss: 1.3844112798731814

Epoch: 6| Step: 10
Training loss: 0.05066833645105362
Validation loss: 1.3601245213580389

Epoch: 6| Step: 11
Training loss: 0.10652311891317368
Validation loss: 1.3710904518763225

Epoch: 6| Step: 12
Training loss: 0.1150389239192009
Validation loss: 1.372337596390837

Epoch: 6| Step: 13
Training loss: 0.15088626742362976
Validation loss: 1.33522129443384

Epoch: 575| Step: 0
Training loss: 0.09917528182268143
Validation loss: 1.3480711611368323

Epoch: 6| Step: 1
Training loss: 0.14126056432724
Validation loss: 1.3753573945773545

Epoch: 6| Step: 2
Training loss: 0.1555182933807373
Validation loss: 1.3913331397118107

Epoch: 6| Step: 3
Training loss: 0.1315855085849762
Validation loss: 1.3558479611591627

Epoch: 6| Step: 4
Training loss: 0.11392924189567566
Validation loss: 1.351416039210494

Epoch: 6| Step: 5
Training loss: 0.13329486548900604
Validation loss: 1.3375926838126233

Epoch: 6| Step: 6
Training loss: 0.12656372785568237
Validation loss: 1.3340356696036555

Epoch: 6| Step: 7
Training loss: 0.1319882720708847
Validation loss: 1.3212223296524377

Epoch: 6| Step: 8
Training loss: 0.11621983349323273
Validation loss: 1.3044641876733432

Epoch: 6| Step: 9
Training loss: 0.09997124969959259
Validation loss: 1.3038447544138918

Epoch: 6| Step: 10
Training loss: 0.2567301392555237
Validation loss: 1.2940429628536265

Epoch: 6| Step: 11
Training loss: 0.085129514336586
Validation loss: 1.3269448139334237

Epoch: 6| Step: 12
Training loss: 0.08661855757236481
Validation loss: 1.3188813437697708

Epoch: 6| Step: 13
Training loss: 0.18209804594516754
Validation loss: 1.3734127180550688

Epoch: 576| Step: 0
Training loss: 0.05740276724100113
Validation loss: 1.3984764699013001

Epoch: 6| Step: 1
Training loss: 0.08574029058218002
Validation loss: 1.4253288430552329

Epoch: 6| Step: 2
Training loss: 0.12597742676734924
Validation loss: 1.4233513955147035

Epoch: 6| Step: 3
Training loss: 0.1376439929008484
Validation loss: 1.4437338325285143

Epoch: 6| Step: 4
Training loss: 0.0734691396355629
Validation loss: 1.4185067376782816

Epoch: 6| Step: 5
Training loss: 0.10567046701908112
Validation loss: 1.4535009719992196

Epoch: 6| Step: 6
Training loss: 0.08451547473669052
Validation loss: 1.4191426448924567

Epoch: 6| Step: 7
Training loss: 0.16099810600280762
Validation loss: 1.448730448240875

Epoch: 6| Step: 8
Training loss: 0.10584501922130585
Validation loss: 1.424570378436837

Epoch: 6| Step: 9
Training loss: 0.08982526510953903
Validation loss: 1.4421480458269837

Epoch: 6| Step: 10
Training loss: 0.23721006512641907
Validation loss: 1.4254032501610376

Epoch: 6| Step: 11
Training loss: 0.07308503985404968
Validation loss: 1.442908202448199

Epoch: 6| Step: 12
Training loss: 0.10040133446455002
Validation loss: 1.4424467535429104

Epoch: 6| Step: 13
Training loss: 0.07219121605157852
Validation loss: 1.4148473816533242

Epoch: 577| Step: 0
Training loss: 0.1205795407295227
Validation loss: 1.3959856597326135

Epoch: 6| Step: 1
Training loss: 0.15111607313156128
Validation loss: 1.3974894426202262

Epoch: 6| Step: 2
Training loss: 0.1280420869588852
Validation loss: 1.358770158983046

Epoch: 6| Step: 3
Training loss: 0.1091424971818924
Validation loss: 1.3741864106988395

Epoch: 6| Step: 4
Training loss: 0.09008871763944626
Validation loss: 1.343378802781464

Epoch: 6| Step: 5
Training loss: 0.0839797779917717
Validation loss: 1.3582353873919415

Epoch: 6| Step: 6
Training loss: 0.11971789598464966
Validation loss: 1.3693274426203903

Epoch: 6| Step: 7
Training loss: 0.07191349565982819
Validation loss: 1.3802406275144188

Epoch: 6| Step: 8
Training loss: 0.2026766538619995
Validation loss: 1.4194394721779773

Epoch: 6| Step: 9
Training loss: 0.1387956291437149
Validation loss: 1.4006389225682905

Epoch: 6| Step: 10
Training loss: 0.06964175403118134
Validation loss: 1.4113565741046783

Epoch: 6| Step: 11
Training loss: 0.08521901816129684
Validation loss: 1.4094464125171784

Epoch: 6| Step: 12
Training loss: 0.11653900146484375
Validation loss: 1.4224698876821866

Epoch: 6| Step: 13
Training loss: 0.06929776072502136
Validation loss: 1.4150099356969197

Epoch: 578| Step: 0
Training loss: 0.1357455551624298
Validation loss: 1.4238068390918035

Epoch: 6| Step: 1
Training loss: 0.20873494446277618
Validation loss: 1.3665654146543114

Epoch: 6| Step: 2
Training loss: 0.17812642455101013
Validation loss: 1.4053579094589397

Epoch: 6| Step: 3
Training loss: 0.117630735039711
Validation loss: 1.4083103185058923

Epoch: 6| Step: 4
Training loss: 0.11297984421253204
Validation loss: 1.4037542304685038

Epoch: 6| Step: 5
Training loss: 0.09055108577013016
Validation loss: 1.387981653213501

Epoch: 6| Step: 6
Training loss: 0.12139427661895752
Validation loss: 1.386089918433979

Epoch: 6| Step: 7
Training loss: 0.0735655203461647
Validation loss: 1.379792756290846

Epoch: 6| Step: 8
Training loss: 0.10636112093925476
Validation loss: 1.3785052825045843

Epoch: 6| Step: 9
Training loss: 0.08862369507551193
Validation loss: 1.4066281216118925

Epoch: 6| Step: 10
Training loss: 0.07951658219099045
Validation loss: 1.413794090670924

Epoch: 6| Step: 11
Training loss: 0.10352658480405807
Validation loss: 1.3975380851376442

Epoch: 6| Step: 12
Training loss: 0.12486475706100464
Validation loss: 1.4031458811093402

Epoch: 6| Step: 13
Training loss: 0.06486071646213531
Validation loss: 1.4123149815426077

Epoch: 579| Step: 0
Training loss: 0.07327129691839218
Validation loss: 1.4091393434873192

Epoch: 6| Step: 1
Training loss: 0.07838483899831772
Validation loss: 1.4261273158493863

Epoch: 6| Step: 2
Training loss: 0.09390580654144287
Validation loss: 1.408708567260414

Epoch: 6| Step: 3
Training loss: 0.1095055416226387
Validation loss: 1.4407874820052937

Epoch: 6| Step: 4
Training loss: 0.09793999791145325
Validation loss: 1.4448766759646836

Epoch: 6| Step: 5
Training loss: 0.06230492144823074
Validation loss: 1.4489123129075574

Epoch: 6| Step: 6
Training loss: 0.05987628921866417
Validation loss: 1.4628559825240925

Epoch: 6| Step: 7
Training loss: 0.19305990636348724
Validation loss: 1.4269114963469967

Epoch: 6| Step: 8
Training loss: 0.12072212994098663
Validation loss: 1.4441286376727525

Epoch: 6| Step: 9
Training loss: 0.1386718899011612
Validation loss: 1.4137441291603992

Epoch: 6| Step: 10
Training loss: 0.1857548952102661
Validation loss: 1.4379326079481392

Epoch: 6| Step: 11
Training loss: 0.0846647322177887
Validation loss: 1.4195326271877493

Epoch: 6| Step: 12
Training loss: 0.0807315856218338
Validation loss: 1.413920630690872

Epoch: 6| Step: 13
Training loss: 0.057113487273454666
Validation loss: 1.4013564561002998

Epoch: 580| Step: 0
Training loss: 0.16649970412254333
Validation loss: 1.3791261488391506

Epoch: 6| Step: 1
Training loss: 0.08214475214481354
Validation loss: 1.3756400257028558

Epoch: 6| Step: 2
Training loss: 0.14884239435195923
Validation loss: 1.3311018392603884

Epoch: 6| Step: 3
Training loss: 0.10202935338020325
Validation loss: 1.3758483061226465

Epoch: 6| Step: 4
Training loss: 0.12758900225162506
Validation loss: 1.3323550685759513

Epoch: 6| Step: 5
Training loss: 0.08213232457637787
Validation loss: 1.361052566959012

Epoch: 6| Step: 6
Training loss: 0.11759603023529053
Validation loss: 1.3568422050886257

Epoch: 6| Step: 7
Training loss: 0.0887528732419014
Validation loss: 1.3773274062782206

Epoch: 6| Step: 8
Training loss: 0.11671169102191925
Validation loss: 1.3941754743617067

Epoch: 6| Step: 9
Training loss: 0.09269935637712479
Validation loss: 1.366500755792023

Epoch: 6| Step: 10
Training loss: 0.06693828105926514
Validation loss: 1.3692613096647366

Epoch: 6| Step: 11
Training loss: 0.08115005493164062
Validation loss: 1.38145064538525

Epoch: 6| Step: 12
Training loss: 0.11493785679340363
Validation loss: 1.3766939370862898

Epoch: 6| Step: 13
Training loss: 0.0848199650645256
Validation loss: 1.3747429245261735

Epoch: 581| Step: 0
Training loss: 0.13390854001045227
Validation loss: 1.3445265857122277

Epoch: 6| Step: 1
Training loss: 0.05097139626741409
Validation loss: 1.3492455251755253

Epoch: 6| Step: 2
Training loss: 0.11460183560848236
Validation loss: 1.3658048158050866

Epoch: 6| Step: 3
Training loss: 0.08089254796504974
Validation loss: 1.3670534164674821

Epoch: 6| Step: 4
Training loss: 0.05542411655187607
Validation loss: 1.3577003222639843

Epoch: 6| Step: 5
Training loss: 0.11254220455884933
Validation loss: 1.399168747727589

Epoch: 6| Step: 6
Training loss: 0.13571806252002716
Validation loss: 1.4091313705649426

Epoch: 6| Step: 7
Training loss: 0.07846024632453918
Validation loss: 1.3851662835767191

Epoch: 6| Step: 8
Training loss: 0.09435923397541046
Validation loss: 1.3583510434755715

Epoch: 6| Step: 9
Training loss: 0.10055409371852875
Validation loss: 1.3551865995571177

Epoch: 6| Step: 10
Training loss: 0.12995681166648865
Validation loss: 1.3254609338698848

Epoch: 6| Step: 11
Training loss: 0.15276256203651428
Validation loss: 1.3462367801256077

Epoch: 6| Step: 12
Training loss: 0.06483445316553116
Validation loss: 1.3356586233262093

Epoch: 6| Step: 13
Training loss: 0.05912389978766441
Validation loss: 1.325194457525848

Epoch: 582| Step: 0
Training loss: 0.13394811749458313
Validation loss: 1.319236029860794

Epoch: 6| Step: 1
Training loss: 0.07964526861906052
Validation loss: 1.3624470092917

Epoch: 6| Step: 2
Training loss: 0.12009172141551971
Validation loss: 1.3862272757355885

Epoch: 6| Step: 3
Training loss: 0.09371711313724518
Validation loss: 1.3706601691502396

Epoch: 6| Step: 4
Training loss: 0.07309731096029282
Validation loss: 1.3708636337710964

Epoch: 6| Step: 5
Training loss: 0.09111171960830688
Validation loss: 1.3738301851416146

Epoch: 6| Step: 6
Training loss: 0.0837286040186882
Validation loss: 1.3786773963641095

Epoch: 6| Step: 7
Training loss: 0.11040108650922775
Validation loss: 1.3807135487115512

Epoch: 6| Step: 8
Training loss: 0.131060391664505
Validation loss: 1.3697265271217591

Epoch: 6| Step: 9
Training loss: 0.1571604311466217
Validation loss: 1.358207187344951

Epoch: 6| Step: 10
Training loss: 0.10660132765769958
Validation loss: 1.3523601831928376

Epoch: 6| Step: 11
Training loss: 0.060604870319366455
Validation loss: 1.3704131598113685

Epoch: 6| Step: 12
Training loss: 0.08463818579912186
Validation loss: 1.3621784512714674

Epoch: 6| Step: 13
Training loss: 0.11348465085029602
Validation loss: 1.3360562375796738

Epoch: 583| Step: 0
Training loss: 0.18106091022491455
Validation loss: 1.373583693658152

Epoch: 6| Step: 1
Training loss: 0.08072943985462189
Validation loss: 1.367997109249074

Epoch: 6| Step: 2
Training loss: 0.08099236339330673
Validation loss: 1.3627308530192221

Epoch: 6| Step: 3
Training loss: 0.07905271649360657
Validation loss: 1.3899935368568666

Epoch: 6| Step: 4
Training loss: 0.07513660192489624
Validation loss: 1.356260174064226

Epoch: 6| Step: 5
Training loss: 0.07848094403743744
Validation loss: 1.389003215297576

Epoch: 6| Step: 6
Training loss: 0.11439970135688782
Validation loss: 1.3991520558634112

Epoch: 6| Step: 7
Training loss: 0.15976619720458984
Validation loss: 1.3873951819635206

Epoch: 6| Step: 8
Training loss: 0.14404408633708954
Validation loss: 1.360866714549321

Epoch: 6| Step: 9
Training loss: 0.08828386664390564
Validation loss: 1.3818874628313127

Epoch: 6| Step: 10
Training loss: 0.07379195839166641
Validation loss: 1.379262020511012

Epoch: 6| Step: 11
Training loss: 0.09493978321552277
Validation loss: 1.3584877560215611

Epoch: 6| Step: 12
Training loss: 0.16727200150489807
Validation loss: 1.3735977462542954

Epoch: 6| Step: 13
Training loss: 0.06327177584171295
Validation loss: 1.3682257180572839

Epoch: 584| Step: 0
Training loss: 0.17449799180030823
Validation loss: 1.371775084926236

Epoch: 6| Step: 1
Training loss: 0.14075152575969696
Validation loss: 1.3838059902191162

Epoch: 6| Step: 2
Training loss: 0.07581590116024017
Validation loss: 1.402224749647161

Epoch: 6| Step: 3
Training loss: 0.09264439344406128
Validation loss: 1.4341524160036476

Epoch: 6| Step: 4
Training loss: 0.10427053272724152
Validation loss: 1.4247044324874878

Epoch: 6| Step: 5
Training loss: 0.14879347383975983
Validation loss: 1.4161910427513944

Epoch: 6| Step: 6
Training loss: 0.04674594849348068
Validation loss: 1.413912591113839

Epoch: 6| Step: 7
Training loss: 0.08696023374795914
Validation loss: 1.3785572257093204

Epoch: 6| Step: 8
Training loss: 0.10285580903291702
Validation loss: 1.336609632738175

Epoch: 6| Step: 9
Training loss: 0.08578994125127792
Validation loss: 1.3084246894364715

Epoch: 6| Step: 10
Training loss: 0.12029187381267548
Validation loss: 1.2972142747653428

Epoch: 6| Step: 11
Training loss: 0.09281651675701141
Validation loss: 1.3207263177441013

Epoch: 6| Step: 12
Training loss: 0.07651295512914658
Validation loss: 1.3382248237568846

Epoch: 6| Step: 13
Training loss: 0.20604795217514038
Validation loss: 1.3731115838532806

Epoch: 585| Step: 0
Training loss: 0.18575984239578247
Validation loss: 1.356181590787826

Epoch: 6| Step: 1
Training loss: 0.07311706244945526
Validation loss: 1.3641013214665074

Epoch: 6| Step: 2
Training loss: 0.06854811310768127
Validation loss: 1.3870397934349634

Epoch: 6| Step: 3
Training loss: 0.0805240049958229
Validation loss: 1.397128261545653

Epoch: 6| Step: 4
Training loss: 0.06450095772743225
Validation loss: 1.3940147533211658

Epoch: 6| Step: 5
Training loss: 0.08745362609624863
Validation loss: 1.3953923557394294

Epoch: 6| Step: 6
Training loss: 0.09233789891004562
Validation loss: 1.4124548037846882

Epoch: 6| Step: 7
Training loss: 0.07914740592241287
Validation loss: 1.411759675190013

Epoch: 6| Step: 8
Training loss: 0.10343460738658905
Validation loss: 1.4203153861466276

Epoch: 6| Step: 9
Training loss: 0.08983542770147324
Validation loss: 1.40255880548108

Epoch: 6| Step: 10
Training loss: 0.128090038895607
Validation loss: 1.4223042726516724

Epoch: 6| Step: 11
Training loss: 0.07628114521503448
Validation loss: 1.39366824652559

Epoch: 6| Step: 12
Training loss: 0.11698450893163681
Validation loss: 1.3708113399885034

Epoch: 6| Step: 13
Training loss: 0.11305806040763855
Validation loss: 1.3768871202263782

Epoch: 586| Step: 0
Training loss: 0.07063620537519455
Validation loss: 1.3418176468982492

Epoch: 6| Step: 1
Training loss: 0.12231937050819397
Validation loss: 1.363506499157157

Epoch: 6| Step: 2
Training loss: 0.1452164351940155
Validation loss: 1.3319644671614452

Epoch: 6| Step: 3
Training loss: 0.10953521728515625
Validation loss: 1.3405652341022287

Epoch: 6| Step: 4
Training loss: 0.08003406971693039
Validation loss: 1.3400688825115081

Epoch: 6| Step: 5
Training loss: 0.12506383657455444
Validation loss: 1.357992987478933

Epoch: 6| Step: 6
Training loss: 0.1289016604423523
Validation loss: 1.3598064543098531

Epoch: 6| Step: 7
Training loss: 0.0869625136256218
Validation loss: 1.3295560536846038

Epoch: 6| Step: 8
Training loss: 0.07306042313575745
Validation loss: 1.3462619358493435

Epoch: 6| Step: 9
Training loss: 0.2309381514787674
Validation loss: 1.3590335999765704

Epoch: 6| Step: 10
Training loss: 0.11912088841199875
Validation loss: 1.3767505730352094

Epoch: 6| Step: 11
Training loss: 0.10304025560617447
Validation loss: 1.337643865616091

Epoch: 6| Step: 12
Training loss: 0.0680818259716034
Validation loss: 1.3573976883324244

Epoch: 6| Step: 13
Training loss: 0.06341082602739334
Validation loss: 1.3379949690193258

Epoch: 587| Step: 0
Training loss: 0.06739962100982666
Validation loss: 1.3619107712981522

Epoch: 6| Step: 1
Training loss: 0.1029723584651947
Validation loss: 1.3609367750024284

Epoch: 6| Step: 2
Training loss: 0.09921158850193024
Validation loss: 1.346617962724419

Epoch: 6| Step: 3
Training loss: 0.20183758437633514
Validation loss: 1.3733023597348122

Epoch: 6| Step: 4
Training loss: 0.06127699837088585
Validation loss: 1.3501875182633758

Epoch: 6| Step: 5
Training loss: 0.08360825479030609
Validation loss: 1.370167052874001

Epoch: 6| Step: 6
Training loss: 0.05762244015932083
Validation loss: 1.3494045144768172

Epoch: 6| Step: 7
Training loss: 0.10691934078931808
Validation loss: 1.3985955997179913

Epoch: 6| Step: 8
Training loss: 0.08629860728979111
Validation loss: 1.3652479687044698

Epoch: 6| Step: 9
Training loss: 0.08207489550113678
Validation loss: 1.3576738719017274

Epoch: 6| Step: 10
Training loss: 0.061053887009620667
Validation loss: 1.3484514567159838

Epoch: 6| Step: 11
Training loss: 0.14362534880638123
Validation loss: 1.3332510866144651

Epoch: 6| Step: 12
Training loss: 0.09883017838001251
Validation loss: 1.3458692694223056

Epoch: 6| Step: 13
Training loss: 0.04070335254073143
Validation loss: 1.31990296353576

Epoch: 588| Step: 0
Training loss: 0.09068789333105087
Validation loss: 1.3280031809242823

Epoch: 6| Step: 1
Training loss: 0.05761024355888367
Validation loss: 1.3383615894984173

Epoch: 6| Step: 2
Training loss: 0.04627947509288788
Validation loss: 1.31160218228576

Epoch: 6| Step: 3
Training loss: 0.06369655579328537
Validation loss: 1.325005405692644

Epoch: 6| Step: 4
Training loss: 0.11844228208065033
Validation loss: 1.314467264119015

Epoch: 6| Step: 5
Training loss: 0.07851328700780869
Validation loss: 1.3251941614253546

Epoch: 6| Step: 6
Training loss: 0.11291250586509705
Validation loss: 1.3052428627526889

Epoch: 6| Step: 7
Training loss: 0.05425388738512993
Validation loss: 1.3256586700357416

Epoch: 6| Step: 8
Training loss: 0.08655332028865814
Validation loss: 1.3053401388147825

Epoch: 6| Step: 9
Training loss: 0.08994553238153458
Validation loss: 1.3437176622370237

Epoch: 6| Step: 10
Training loss: 0.11558128893375397
Validation loss: 1.3173576272943968

Epoch: 6| Step: 11
Training loss: 0.0699072927236557
Validation loss: 1.347001068053707

Epoch: 6| Step: 12
Training loss: 0.1421225368976593
Validation loss: 1.3295446134382678

Epoch: 6| Step: 13
Training loss: 0.07622583955526352
Validation loss: 1.351106184785084

Epoch: 589| Step: 0
Training loss: 0.0695355162024498
Validation loss: 1.3353567200322305

Epoch: 6| Step: 1
Training loss: 0.07353208214044571
Validation loss: 1.3545250764457129

Epoch: 6| Step: 2
Training loss: 0.04514123499393463
Validation loss: 1.355753114146571

Epoch: 6| Step: 3
Training loss: 0.08649183064699173
Validation loss: 1.318695274732446

Epoch: 6| Step: 4
Training loss: 0.18702608346939087
Validation loss: 1.345337055062735

Epoch: 6| Step: 5
Training loss: 0.1369868367910385
Validation loss: 1.3236375938179672

Epoch: 6| Step: 6
Training loss: 0.08747635781764984
Validation loss: 1.3517105797285676

Epoch: 6| Step: 7
Training loss: 0.07410383224487305
Validation loss: 1.3571589416073215

Epoch: 6| Step: 8
Training loss: 0.11920426040887833
Validation loss: 1.362734092179165

Epoch: 6| Step: 9
Training loss: 0.06814843416213989
Validation loss: 1.3517935827214231

Epoch: 6| Step: 10
Training loss: 0.058150820434093475
Validation loss: 1.3510052862987723

Epoch: 6| Step: 11
Training loss: 0.10099057853221893
Validation loss: 1.3405660608763337

Epoch: 6| Step: 12
Training loss: 0.05107346177101135
Validation loss: 1.3230738768013575

Epoch: 6| Step: 13
Training loss: 0.2206113040447235
Validation loss: 1.342447232174617

Epoch: 590| Step: 0
Training loss: 0.18798871338367462
Validation loss: 1.3571712804097

Epoch: 6| Step: 1
Training loss: 0.0961681678891182
Validation loss: 1.3258705523706251

Epoch: 6| Step: 2
Training loss: 0.06213894486427307
Validation loss: 1.3789092456140826

Epoch: 6| Step: 3
Training loss: 0.05534840375185013
Validation loss: 1.4104693602490168

Epoch: 6| Step: 4
Training loss: 0.05767197906970978
Validation loss: 1.3936010035135413

Epoch: 6| Step: 5
Training loss: 0.06772835552692413
Validation loss: 1.4151078039600002

Epoch: 6| Step: 6
Training loss: 0.07558664679527283
Validation loss: 1.4027554463314753

Epoch: 6| Step: 7
Training loss: 0.09846091270446777
Validation loss: 1.3826776730116976

Epoch: 6| Step: 8
Training loss: 0.08258423209190369
Validation loss: 1.346555749254842

Epoch: 6| Step: 9
Training loss: 0.08002496510744095
Validation loss: 1.3350070638041343

Epoch: 6| Step: 10
Training loss: 0.08708851784467697
Validation loss: 1.322877836483781

Epoch: 6| Step: 11
Training loss: 0.0632869303226471
Validation loss: 1.2945903501202982

Epoch: 6| Step: 12
Training loss: 0.09313183277845383
Validation loss: 1.300613909639338

Epoch: 6| Step: 13
Training loss: 0.11021973937749863
Validation loss: 1.3049021062030588

Epoch: 591| Step: 0
Training loss: 0.12771926820278168
Validation loss: 1.2771413313445223

Epoch: 6| Step: 1
Training loss: 0.07551837712526321
Validation loss: 1.3133327960968018

Epoch: 6| Step: 2
Training loss: 0.10896226763725281
Validation loss: 1.354408912761237

Epoch: 6| Step: 3
Training loss: 0.0991901308298111
Validation loss: 1.3602051465742049

Epoch: 6| Step: 4
Training loss: 0.07188402861356735
Validation loss: 1.333964014566073

Epoch: 6| Step: 5
Training loss: 0.1438627541065216
Validation loss: 1.3567523981935234

Epoch: 6| Step: 6
Training loss: 0.05521314591169357
Validation loss: 1.3170106205888974

Epoch: 6| Step: 7
Training loss: 0.08447661250829697
Validation loss: 1.3188461244747203

Epoch: 6| Step: 8
Training loss: 0.058384403586387634
Validation loss: 1.318581695197731

Epoch: 6| Step: 9
Training loss: 0.10854142159223557
Validation loss: 1.313052095392699

Epoch: 6| Step: 10
Training loss: 0.05151774734258652
Validation loss: 1.3325132528940837

Epoch: 6| Step: 11
Training loss: 0.11063307523727417
Validation loss: 1.3164314134146577

Epoch: 6| Step: 12
Training loss: 0.11948847025632858
Validation loss: 1.2931994238207418

Epoch: 6| Step: 13
Training loss: 0.05227658525109291
Validation loss: 1.3149664504553682

Epoch: 592| Step: 0
Training loss: 0.16844740509986877
Validation loss: 1.318624122168428

Epoch: 6| Step: 1
Training loss: 0.07186013460159302
Validation loss: 1.322244680056008

Epoch: 6| Step: 2
Training loss: 0.0863914042711258
Validation loss: 1.3464834177365868

Epoch: 6| Step: 3
Training loss: 0.06256667524576187
Validation loss: 1.3601407620214647

Epoch: 6| Step: 4
Training loss: 0.09682808816432953
Validation loss: 1.39083477117682

Epoch: 6| Step: 5
Training loss: 0.076128289103508
Validation loss: 1.3521986828055432

Epoch: 6| Step: 6
Training loss: 0.1457388699054718
Validation loss: 1.3679671973310492

Epoch: 6| Step: 7
Training loss: 0.06597618013620377
Validation loss: 1.3460039951468026

Epoch: 6| Step: 8
Training loss: 0.07880531996488571
Validation loss: 1.321981074989483

Epoch: 6| Step: 9
Training loss: 0.06875453889369965
Validation loss: 1.337880374282919

Epoch: 6| Step: 10
Training loss: 0.12800151109695435
Validation loss: 1.3244657849752774

Epoch: 6| Step: 11
Training loss: 0.07993772625923157
Validation loss: 1.3539674333346787

Epoch: 6| Step: 12
Training loss: 0.07890985906124115
Validation loss: 1.3521665821793258

Epoch: 6| Step: 13
Training loss: 0.11144828796386719
Validation loss: 1.3413121905378116

Epoch: 593| Step: 0
Training loss: 0.07953602075576782
Validation loss: 1.3880302329217233

Epoch: 6| Step: 1
Training loss: 0.14659002423286438
Validation loss: 1.3685779930442892

Epoch: 6| Step: 2
Training loss: 0.049461282789707184
Validation loss: 1.3818010796782791

Epoch: 6| Step: 3
Training loss: 0.06548654288053513
Validation loss: 1.3693303972162225

Epoch: 6| Step: 4
Training loss: 0.0892118513584137
Validation loss: 1.3545736984540058

Epoch: 6| Step: 5
Training loss: 0.07236987352371216
Validation loss: 1.3728690647309827

Epoch: 6| Step: 6
Training loss: 0.1288832426071167
Validation loss: 1.340532797639088

Epoch: 6| Step: 7
Training loss: 0.042408689856529236
Validation loss: 1.3511571935428086

Epoch: 6| Step: 8
Training loss: 0.11145102977752686
Validation loss: 1.3707179997556953

Epoch: 6| Step: 9
Training loss: 0.07873283326625824
Validation loss: 1.3595981687627814

Epoch: 6| Step: 10
Training loss: 0.1068950891494751
Validation loss: 1.3549498511898903

Epoch: 6| Step: 11
Training loss: 0.1090913712978363
Validation loss: 1.3699157814825735

Epoch: 6| Step: 12
Training loss: 0.12305331230163574
Validation loss: 1.342649052220006

Epoch: 6| Step: 13
Training loss: 0.13663403689861298
Validation loss: 1.370176556289837

Epoch: 594| Step: 0
Training loss: 0.05486353486776352
Validation loss: 1.385421868293516

Epoch: 6| Step: 1
Training loss: 0.1084621325135231
Validation loss: 1.4024287475052701

Epoch: 6| Step: 2
Training loss: 0.05927114933729172
Validation loss: 1.3618553569239955

Epoch: 6| Step: 3
Training loss: 0.0509323924779892
Validation loss: 1.4024929602940877

Epoch: 6| Step: 4
Training loss: 0.13984785974025726
Validation loss: 1.386660074674955

Epoch: 6| Step: 5
Training loss: 0.07881307601928711
Validation loss: 1.3874765224354242

Epoch: 6| Step: 6
Training loss: 0.07070644199848175
Validation loss: 1.3949149988030876

Epoch: 6| Step: 7
Training loss: 0.053520966321229935
Validation loss: 1.3880392069457679

Epoch: 6| Step: 8
Training loss: 0.0956951230764389
Validation loss: 1.3667603551700551

Epoch: 6| Step: 9
Training loss: 0.06939692795276642
Validation loss: 1.397672091760943

Epoch: 6| Step: 10
Training loss: 0.14413806796073914
Validation loss: 1.3903922291212185

Epoch: 6| Step: 11
Training loss: 0.06122530996799469
Validation loss: 1.3827419934734222

Epoch: 6| Step: 12
Training loss: 0.17673742771148682
Validation loss: 1.3715622066169657

Epoch: 6| Step: 13
Training loss: 0.10140366107225418
Validation loss: 1.4103677247160225

Epoch: 595| Step: 0
Training loss: 0.07901106774806976
Validation loss: 1.3939928893120057

Epoch: 6| Step: 1
Training loss: 0.10014547407627106
Validation loss: 1.3959721493464645

Epoch: 6| Step: 2
Training loss: 0.09736669063568115
Validation loss: 1.3621692708743516

Epoch: 6| Step: 3
Training loss: 0.13880014419555664
Validation loss: 1.3930190493983607

Epoch: 6| Step: 4
Training loss: 0.1742897778749466
Validation loss: 1.3747374421806746

Epoch: 6| Step: 5
Training loss: 0.13089820742607117
Validation loss: 1.3712646179301764

Epoch: 6| Step: 6
Training loss: 0.11452727019786835
Validation loss: 1.34706276078378

Epoch: 6| Step: 7
Training loss: 0.054148584604263306
Validation loss: 1.365453532947007

Epoch: 6| Step: 8
Training loss: 0.06403075903654099
Validation loss: 1.3618635657013103

Epoch: 6| Step: 9
Training loss: 0.07731585204601288
Validation loss: 1.3730604366589618

Epoch: 6| Step: 10
Training loss: 0.069505974650383
Validation loss: 1.3597547713146414

Epoch: 6| Step: 11
Training loss: 0.06848528981208801
Validation loss: 1.4059307831589893

Epoch: 6| Step: 12
Training loss: 0.1365046501159668
Validation loss: 1.3999006427744383

Epoch: 6| Step: 13
Training loss: 0.11325424164533615
Validation loss: 1.4077722795547978

Epoch: 596| Step: 0
Training loss: 0.05481584370136261
Validation loss: 1.3818772441597396

Epoch: 6| Step: 1
Training loss: 0.0754951685667038
Validation loss: 1.401053008212838

Epoch: 6| Step: 2
Training loss: 0.06784925609827042
Validation loss: 1.3900128218435472

Epoch: 6| Step: 3
Training loss: 0.0990900844335556
Validation loss: 1.3911330969102922

Epoch: 6| Step: 4
Training loss: 0.04874831810593605
Validation loss: 1.3989791306116248

Epoch: 6| Step: 5
Training loss: 0.1589439958333969
Validation loss: 1.411135833750489

Epoch: 6| Step: 6
Training loss: 0.15442202985286713
Validation loss: 1.4002255252612534

Epoch: 6| Step: 7
Training loss: 0.1456267535686493
Validation loss: 1.3922760236647822

Epoch: 6| Step: 8
Training loss: 0.08826670795679092
Validation loss: 1.4019499472392503

Epoch: 6| Step: 9
Training loss: 0.08128981292247772
Validation loss: 1.4038606100184943

Epoch: 6| Step: 10
Training loss: 0.12039997428655624
Validation loss: 1.3890160206825501

Epoch: 6| Step: 11
Training loss: 0.11526228487491608
Validation loss: 1.3892711298440092

Epoch: 6| Step: 12
Training loss: 0.12759405374526978
Validation loss: 1.3966297917468573

Epoch: 6| Step: 13
Training loss: 0.09091917425394058
Validation loss: 1.394420967307142

Epoch: 597| Step: 0
Training loss: 0.1649308055639267
Validation loss: 1.4004552415622178

Epoch: 6| Step: 1
Training loss: 0.091669961810112
Validation loss: 1.3751058687445938

Epoch: 6| Step: 2
Training loss: 0.08261512219905853
Validation loss: 1.4064831925976662

Epoch: 6| Step: 3
Training loss: 0.08292324095964432
Validation loss: 1.400501593466728

Epoch: 6| Step: 4
Training loss: 0.08246606588363647
Validation loss: 1.3986334262355682

Epoch: 6| Step: 5
Training loss: 0.06321452558040619
Validation loss: 1.3881061166845343

Epoch: 6| Step: 6
Training loss: 0.09016908705234528
Validation loss: 1.4096782412580264

Epoch: 6| Step: 7
Training loss: 0.16094970703125
Validation loss: 1.4013145213486047

Epoch: 6| Step: 8
Training loss: 0.08299517631530762
Validation loss: 1.3865019621387604

Epoch: 6| Step: 9
Training loss: 0.11695908010005951
Validation loss: 1.4338627271754767

Epoch: 6| Step: 10
Training loss: 0.1045025959610939
Validation loss: 1.4150577411856702

Epoch: 6| Step: 11
Training loss: 0.06371809542179108
Validation loss: 1.3950480530338902

Epoch: 6| Step: 12
Training loss: 0.051130250096321106
Validation loss: 1.419477811423681

Epoch: 6| Step: 13
Training loss: 0.07990798354148865
Validation loss: 1.429432975348606

Epoch: 598| Step: 0
Training loss: 0.0612872876226902
Validation loss: 1.397283374622304

Epoch: 6| Step: 1
Training loss: 0.13798892498016357
Validation loss: 1.408193903584634

Epoch: 6| Step: 2
Training loss: 0.05682370439171791
Validation loss: 1.375043975409641

Epoch: 6| Step: 3
Training loss: 0.07011514157056808
Validation loss: 1.3826782472672001

Epoch: 6| Step: 4
Training loss: 0.07745907455682755
Validation loss: 1.3799905200158396

Epoch: 6| Step: 5
Training loss: 0.2219875305891037
Validation loss: 1.3789271359802575

Epoch: 6| Step: 6
Training loss: 0.1108270138502121
Validation loss: 1.4006736470806984

Epoch: 6| Step: 7
Training loss: 0.10911978781223297
Validation loss: 1.4005122992300219

Epoch: 6| Step: 8
Training loss: 0.12306758016347885
Validation loss: 1.3949011384799916

Epoch: 6| Step: 9
Training loss: 0.10737581551074982
Validation loss: 1.3944635032325663

Epoch: 6| Step: 10
Training loss: 0.0955977737903595
Validation loss: 1.41859951326924

Epoch: 6| Step: 11
Training loss: 0.07284398376941681
Validation loss: 1.3793057241747457

Epoch: 6| Step: 12
Training loss: 0.09010963141918182
Validation loss: 1.3682719033251527

Epoch: 6| Step: 13
Training loss: 0.05787992477416992
Validation loss: 1.3546795960395568

Epoch: 599| Step: 0
Training loss: 0.07496523857116699
Validation loss: 1.3762267251168527

Epoch: 6| Step: 1
Training loss: 0.06191644445061684
Validation loss: 1.3934951751462874

Epoch: 6| Step: 2
Training loss: 0.10535645484924316
Validation loss: 1.3882196026463662

Epoch: 6| Step: 3
Training loss: 0.041767194867134094
Validation loss: 1.3991509881070865

Epoch: 6| Step: 4
Training loss: 0.13652466237545013
Validation loss: 1.4097126671063003

Epoch: 6| Step: 5
Training loss: 0.06860356032848358
Validation loss: 1.4229722202465098

Epoch: 6| Step: 6
Training loss: 0.0578790120780468
Validation loss: 1.4311354365400089

Epoch: 6| Step: 7
Training loss: 0.11490050703287125
Validation loss: 1.4296771903191843

Epoch: 6| Step: 8
Training loss: 0.06762829422950745
Validation loss: 1.4386216376417427

Epoch: 6| Step: 9
Training loss: 0.07133512198925018
Validation loss: 1.4337647820031771

Epoch: 6| Step: 10
Training loss: 0.13006825745105743
Validation loss: 1.4204067414806736

Epoch: 6| Step: 11
Training loss: 0.12982109189033508
Validation loss: 1.4451685220964494

Epoch: 6| Step: 12
Training loss: 0.09159477800130844
Validation loss: 1.4104608822894353

Epoch: 6| Step: 13
Training loss: 0.07390782237052917
Validation loss: 1.4395204385121663

Epoch: 600| Step: 0
Training loss: 0.1331425905227661
Validation loss: 1.4631170880409978

Epoch: 6| Step: 1
Training loss: 0.10997121036052704
Validation loss: 1.4321093841265606

Epoch: 6| Step: 2
Training loss: 0.08393426239490509
Validation loss: 1.447123642890684

Epoch: 6| Step: 3
Training loss: 0.0600118488073349
Validation loss: 1.4276520090718423

Epoch: 6| Step: 4
Training loss: 0.07659745216369629
Validation loss: 1.417664397147394

Epoch: 6| Step: 5
Training loss: 0.09611723572015762
Validation loss: 1.3977676924838816

Epoch: 6| Step: 6
Training loss: 0.1311139315366745
Validation loss: 1.401325205320953

Epoch: 6| Step: 7
Training loss: 0.12685316801071167
Validation loss: 1.4092080721291163

Epoch: 6| Step: 8
Training loss: 0.10137732326984406
Validation loss: 1.3870211147492932

Epoch: 6| Step: 9
Training loss: 0.1097070723772049
Validation loss: 1.373193274262131

Epoch: 6| Step: 10
Training loss: 0.09792027622461319
Validation loss: 1.3935223164096955

Epoch: 6| Step: 11
Training loss: 0.05313673987984657
Validation loss: 1.4113969469583163

Epoch: 6| Step: 12
Training loss: 0.14959478378295898
Validation loss: 1.376615887047142

Epoch: 6| Step: 13
Training loss: 0.12797164916992188
Validation loss: 1.3909588468972074

Epoch: 601| Step: 0
Training loss: 0.13100194931030273
Validation loss: 1.3948616725142284

Epoch: 6| Step: 1
Training loss: 0.06773100793361664
Validation loss: 1.3848970667008431

Epoch: 6| Step: 2
Training loss: 0.08566848933696747
Validation loss: 1.3771028595585977

Epoch: 6| Step: 3
Training loss: 0.08474436402320862
Validation loss: 1.3921834640605475

Epoch: 6| Step: 4
Training loss: 0.12710458040237427
Validation loss: 1.3701197998498076

Epoch: 6| Step: 5
Training loss: 0.05185001343488693
Validation loss: 1.3745133915255148

Epoch: 6| Step: 6
Training loss: 0.10779010504484177
Validation loss: 1.3939800223996561

Epoch: 6| Step: 7
Training loss: 0.15627732872962952
Validation loss: 1.4068397245099467

Epoch: 6| Step: 8
Training loss: 0.09650266915559769
Validation loss: 1.3841213769810174

Epoch: 6| Step: 9
Training loss: 0.051020774990320206
Validation loss: 1.373018737762205

Epoch: 6| Step: 10
Training loss: 0.051463112235069275
Validation loss: 1.378519138341309

Epoch: 6| Step: 11
Training loss: 0.06179439276456833
Validation loss: 1.3772232301773564

Epoch: 6| Step: 12
Training loss: 0.1938418298959732
Validation loss: 1.392596330693973

Epoch: 6| Step: 13
Training loss: 0.040033552795648575
Validation loss: 1.3809319497436605

Epoch: 602| Step: 0
Training loss: 0.1516132801771164
Validation loss: 1.3923923546268093

Epoch: 6| Step: 1
Training loss: 0.07915535569190979
Validation loss: 1.3939257052636915

Epoch: 6| Step: 2
Training loss: 0.15526145696640015
Validation loss: 1.3898247275301205

Epoch: 6| Step: 3
Training loss: 0.09949491173028946
Validation loss: 1.3920163819866795

Epoch: 6| Step: 4
Training loss: 0.053041283041238785
Validation loss: 1.3701350522297684

Epoch: 6| Step: 5
Training loss: 0.07460181415081024
Validation loss: 1.3600317765307683

Epoch: 6| Step: 6
Training loss: 0.07953034341335297
Validation loss: 1.3801813343519806

Epoch: 6| Step: 7
Training loss: 0.06112159043550491
Validation loss: 1.3766150320729902

Epoch: 6| Step: 8
Training loss: 0.08463619649410248
Validation loss: 1.3646704830149168

Epoch: 6| Step: 9
Training loss: 0.06943894922733307
Validation loss: 1.407695888191141

Epoch: 6| Step: 10
Training loss: 0.1308297961950302
Validation loss: 1.3897370548658474

Epoch: 6| Step: 11
Training loss: 0.06072099134325981
Validation loss: 1.360882342502635

Epoch: 6| Step: 12
Training loss: 0.11708977818489075
Validation loss: 1.371151968997012

Epoch: 6| Step: 13
Training loss: 0.07164919376373291
Validation loss: 1.3733425396744923

Epoch: 603| Step: 0
Training loss: 0.05997674912214279
Validation loss: 1.3620665829668763

Epoch: 6| Step: 1
Training loss: 0.07233161479234695
Validation loss: 1.3390815924572688

Epoch: 6| Step: 2
Training loss: 0.07158587872982025
Validation loss: 1.330317097966389

Epoch: 6| Step: 3
Training loss: 0.08956821262836456
Validation loss: 1.3437438741807015

Epoch: 6| Step: 4
Training loss: 0.1191888377070427
Validation loss: 1.3541855119889783

Epoch: 6| Step: 5
Training loss: 0.10708895325660706
Validation loss: 1.3425445242594647

Epoch: 6| Step: 6
Training loss: 0.16164696216583252
Validation loss: 1.3334998866563201

Epoch: 6| Step: 7
Training loss: 0.09510277956724167
Validation loss: 1.3563533470194826

Epoch: 6| Step: 8
Training loss: 0.07972786575555801
Validation loss: 1.3853066134196457

Epoch: 6| Step: 9
Training loss: 0.11402221024036407
Validation loss: 1.4060662100392003

Epoch: 6| Step: 10
Training loss: 0.10579574108123779
Validation loss: 1.433179832273914

Epoch: 6| Step: 11
Training loss: 0.1558624804019928
Validation loss: 1.3928272339605516

Epoch: 6| Step: 12
Training loss: 0.12713178992271423
Validation loss: 1.400549598919448

Epoch: 6| Step: 13
Training loss: 0.047486502677202225
Validation loss: 1.3836217529030257

Epoch: 604| Step: 0
Training loss: 0.07269719243049622
Validation loss: 1.3923686832510016

Epoch: 6| Step: 1
Training loss: 0.12268456816673279
Validation loss: 1.3797481342028546

Epoch: 6| Step: 2
Training loss: 0.11093635112047195
Validation loss: 1.3756310080969205

Epoch: 6| Step: 3
Training loss: 0.1348607987165451
Validation loss: 1.3645124871243712

Epoch: 6| Step: 4
Training loss: 0.12296334654092789
Validation loss: 1.366570315053386

Epoch: 6| Step: 5
Training loss: 0.06727674603462219
Validation loss: 1.3757809618467927

Epoch: 6| Step: 6
Training loss: 0.11897017061710358
Validation loss: 1.3892133312840615

Epoch: 6| Step: 7
Training loss: 0.1231151819229126
Validation loss: 1.3685956392236935

Epoch: 6| Step: 8
Training loss: 0.06903225183486938
Validation loss: 1.3901855663586689

Epoch: 6| Step: 9
Training loss: 0.05242125317454338
Validation loss: 1.422111221539077

Epoch: 6| Step: 10
Training loss: 0.0337272509932518
Validation loss: 1.4056025294847385

Epoch: 6| Step: 11
Training loss: 0.06885935366153717
Validation loss: 1.411550425714062

Epoch: 6| Step: 12
Training loss: 0.17226585745811462
Validation loss: 1.4182465435356222

Epoch: 6| Step: 13
Training loss: 0.09070735424757004
Validation loss: 1.406435461454494

Epoch: 605| Step: 0
Training loss: 0.051682181656360626
Validation loss: 1.3777408330671248

Epoch: 6| Step: 1
Training loss: 0.18971937894821167
Validation loss: 1.399178107579549

Epoch: 6| Step: 2
Training loss: 0.15324190258979797
Validation loss: 1.4017175275792357

Epoch: 6| Step: 3
Training loss: 0.12177307903766632
Validation loss: 1.4002811754903486

Epoch: 6| Step: 4
Training loss: 0.17888441681861877
Validation loss: 1.3772808742779556

Epoch: 6| Step: 5
Training loss: 0.22835145890712738
Validation loss: 1.4055848006279237

Epoch: 6| Step: 6
Training loss: 0.12386472523212433
Validation loss: 1.4015074622246526

Epoch: 6| Step: 7
Training loss: 0.27684730291366577
Validation loss: 1.434619806146109

Epoch: 6| Step: 8
Training loss: 0.27782702445983887
Validation loss: 1.423294355792384

Epoch: 6| Step: 9
Training loss: 0.11540034413337708
Validation loss: 1.4211971170158797

Epoch: 6| Step: 10
Training loss: 0.21160206198692322
Validation loss: 1.4259526909038585

Epoch: 6| Step: 11
Training loss: 0.08647678792476654
Validation loss: 1.4501263794078623

Epoch: 6| Step: 12
Training loss: 0.2839110493659973
Validation loss: 1.5012778146292574

Epoch: 6| Step: 13
Training loss: 0.09504200518131256
Validation loss: 1.5131424485996205

Epoch: 606| Step: 0
Training loss: 0.13537541031837463
Validation loss: 1.5024237607115059

Epoch: 6| Step: 1
Training loss: 0.11891454458236694
Validation loss: 1.47815272244074

Epoch: 6| Step: 2
Training loss: 0.1516137719154358
Validation loss: 1.4572426452431628

Epoch: 6| Step: 3
Training loss: 0.16967518627643585
Validation loss: 1.3754884760866883

Epoch: 6| Step: 4
Training loss: 0.1637524962425232
Validation loss: 1.384411419591596

Epoch: 6| Step: 5
Training loss: 0.13845840096473694
Validation loss: 1.3568699738030792

Epoch: 6| Step: 6
Training loss: 0.15212532877922058
Validation loss: 1.3442005201052594

Epoch: 6| Step: 7
Training loss: 0.12367193400859833
Validation loss: 1.3800615136341383

Epoch: 6| Step: 8
Training loss: 0.18601226806640625
Validation loss: 1.3926131007491902

Epoch: 6| Step: 9
Training loss: 0.25661590695381165
Validation loss: 1.3852657118151266

Epoch: 6| Step: 10
Training loss: 0.15506771206855774
Validation loss: 1.3586705871807632

Epoch: 6| Step: 11
Training loss: 0.1549474596977234
Validation loss: 1.3600561234258837

Epoch: 6| Step: 12
Training loss: 0.0970468670129776
Validation loss: 1.375565037932447

Epoch: 6| Step: 13
Training loss: 0.2649182975292206
Validation loss: 1.4257111857014317

Epoch: 607| Step: 0
Training loss: 0.14822110533714294
Validation loss: 1.5227158697702552

Epoch: 6| Step: 1
Training loss: 0.1187133640050888
Validation loss: 1.4973064802026237

Epoch: 6| Step: 2
Training loss: 0.16405504941940308
Validation loss: 1.4918258241427842

Epoch: 6| Step: 3
Training loss: 0.11543463170528412
Validation loss: 1.4543249632722588

Epoch: 6| Step: 4
Training loss: 0.0848272442817688
Validation loss: 1.392414189154102

Epoch: 6| Step: 5
Training loss: 0.09292744100093842
Validation loss: 1.357118772563114

Epoch: 6| Step: 6
Training loss: 0.15215444564819336
Validation loss: 1.3237370111609017

Epoch: 6| Step: 7
Training loss: 0.3029671013355255
Validation loss: 1.3464859544589955

Epoch: 6| Step: 8
Training loss: 0.1453251838684082
Validation loss: 1.326587171964748

Epoch: 6| Step: 9
Training loss: 0.1264420747756958
Validation loss: 1.3308816366298224

Epoch: 6| Step: 10
Training loss: 0.08980263769626617
Validation loss: 1.317958745905148

Epoch: 6| Step: 11
Training loss: 0.1188020408153534
Validation loss: 1.3125053387816235

Epoch: 6| Step: 12
Training loss: 0.13672712445259094
Validation loss: 1.3125928409637944

Epoch: 6| Step: 13
Training loss: 0.13642801344394684
Validation loss: 1.3286719129931541

Epoch: 608| Step: 0
Training loss: 0.18473637104034424
Validation loss: 1.3824467261632283

Epoch: 6| Step: 1
Training loss: 0.16817620396614075
Validation loss: 1.3929831584294636

Epoch: 6| Step: 2
Training loss: 0.1395561844110489
Validation loss: 1.3757177245232366

Epoch: 6| Step: 3
Training loss: 0.1893766224384308
Validation loss: 1.3427142020194762

Epoch: 6| Step: 4
Training loss: 0.20341995358467102
Validation loss: 1.3634441309077765

Epoch: 6| Step: 5
Training loss: 0.23614338040351868
Validation loss: 1.3353300991878714

Epoch: 6| Step: 6
Training loss: 0.15625812113285065
Validation loss: 1.380771457508046

Epoch: 6| Step: 7
Training loss: 0.14776885509490967
Validation loss: 1.3724365683012112

Epoch: 6| Step: 8
Training loss: 0.2615119218826294
Validation loss: 1.379877442954689

Epoch: 6| Step: 9
Training loss: 0.16306060552597046
Validation loss: 1.4011248516780075

Epoch: 6| Step: 10
Training loss: 0.17344942688941956
Validation loss: 1.4310006890245663

Epoch: 6| Step: 11
Training loss: 0.19805777072906494
Validation loss: 1.4315395406497422

Epoch: 6| Step: 12
Training loss: 0.1116156280040741
Validation loss: 1.4350742191396735

Epoch: 6| Step: 13
Training loss: 0.14864856004714966
Validation loss: 1.439206797589538

Epoch: 609| Step: 0
Training loss: 0.05177666246891022
Validation loss: 1.4518604560564923

Epoch: 6| Step: 1
Training loss: 0.14800989627838135
Validation loss: 1.4025317789405904

Epoch: 6| Step: 2
Training loss: 0.22069990634918213
Validation loss: 1.3931964731985522

Epoch: 6| Step: 3
Training loss: 0.27870413661003113
Validation loss: 1.403064763674172

Epoch: 6| Step: 4
Training loss: 0.2517629861831665
Validation loss: 1.3655115417254868

Epoch: 6| Step: 5
Training loss: 0.13942140340805054
Validation loss: 1.3738470820970432

Epoch: 6| Step: 6
Training loss: 0.1072981059551239
Validation loss: 1.37553697247659

Epoch: 6| Step: 7
Training loss: 0.11221146583557129
Validation loss: 1.3751132142159246

Epoch: 6| Step: 8
Training loss: 0.10405087471008301
Validation loss: 1.3913042340227353

Epoch: 6| Step: 9
Training loss: 0.09592028707265854
Validation loss: 1.4050517646215295

Epoch: 6| Step: 10
Training loss: 0.09543204307556152
Validation loss: 1.4055906162467053

Epoch: 6| Step: 11
Training loss: 0.26062655448913574
Validation loss: 1.4253291814557967

Epoch: 6| Step: 12
Training loss: 0.09560636430978775
Validation loss: 1.4707253940643803

Epoch: 6| Step: 13
Training loss: 0.22770945727825165
Validation loss: 1.460171603387402

Epoch: 610| Step: 0
Training loss: 0.1509382277727127
Validation loss: 1.4570158873834917

Epoch: 6| Step: 1
Training loss: 0.08585284650325775
Validation loss: 1.4174076587923112

Epoch: 6| Step: 2
Training loss: 0.11714066565036774
Validation loss: 1.3691533547575756

Epoch: 6| Step: 3
Training loss: 0.11749790608882904
Validation loss: 1.3254935510696904

Epoch: 6| Step: 4
Training loss: 0.07540379464626312
Validation loss: 1.2979104582981398

Epoch: 6| Step: 5
Training loss: 0.15080425143241882
Validation loss: 1.3018662237351941

Epoch: 6| Step: 6
Training loss: 0.19235914945602417
Validation loss: 1.3043740000776065

Epoch: 6| Step: 7
Training loss: 0.12174670398235321
Validation loss: 1.2764949555038123

Epoch: 6| Step: 8
Training loss: 0.07778473943471909
Validation loss: 1.262826713182593

Epoch: 6| Step: 9
Training loss: 0.15221086144447327
Validation loss: 1.267350959521468

Epoch: 6| Step: 10
Training loss: 0.17690256237983704
Validation loss: 1.320363284439169

Epoch: 6| Step: 11
Training loss: 0.18574969470500946
Validation loss: 1.3486874090727938

Epoch: 6| Step: 12
Training loss: 0.10386128723621368
Validation loss: 1.3665627933317614

Epoch: 6| Step: 13
Training loss: 0.13008636236190796
Validation loss: 1.4191796856541787

Epoch: 611| Step: 0
Training loss: 0.2566600739955902
Validation loss: 1.4065035607225151

Epoch: 6| Step: 1
Training loss: 0.17120197415351868
Validation loss: 1.4381036040603474

Epoch: 6| Step: 2
Training loss: 0.19641658663749695
Validation loss: 1.4197499085498113

Epoch: 6| Step: 3
Training loss: 0.1176721528172493
Validation loss: 1.382450952324816

Epoch: 6| Step: 4
Training loss: 0.11873626708984375
Validation loss: 1.4014218930275208

Epoch: 6| Step: 5
Training loss: 0.11024187505245209
Validation loss: 1.385804848004413

Epoch: 6| Step: 6
Training loss: 0.0973888710141182
Validation loss: 1.3763281030039634

Epoch: 6| Step: 7
Training loss: 0.1613583266735077
Validation loss: 1.3834564884503682

Epoch: 6| Step: 8
Training loss: 0.15549598634243011
Validation loss: 1.3670107869691746

Epoch: 6| Step: 9
Training loss: 0.11804481595754623
Validation loss: 1.3874454100926716

Epoch: 6| Step: 10
Training loss: 0.09518257528543472
Validation loss: 1.3542119392784693

Epoch: 6| Step: 11
Training loss: 0.09630394726991653
Validation loss: 1.371875173302107

Epoch: 6| Step: 12
Training loss: 0.10868631303310394
Validation loss: 1.3840921642959758

Epoch: 6| Step: 13
Training loss: 0.08205170184373856
Validation loss: 1.3775794929073704

Epoch: 612| Step: 0
Training loss: 0.08570389449596405
Validation loss: 1.363736146239824

Epoch: 6| Step: 1
Training loss: 0.14425137639045715
Validation loss: 1.3680129487027404

Epoch: 6| Step: 2
Training loss: 0.09083887189626694
Validation loss: 1.3696747031263126

Epoch: 6| Step: 3
Training loss: 0.10096780955791473
Validation loss: 1.3884294590642374

Epoch: 6| Step: 4
Training loss: 0.15383629500865936
Validation loss: 1.3797096372932516

Epoch: 6| Step: 5
Training loss: 0.09082900732755661
Validation loss: 1.3692791679854035

Epoch: 6| Step: 6
Training loss: 0.1599525809288025
Validation loss: 1.3783115533090406

Epoch: 6| Step: 7
Training loss: 0.22555118799209595
Validation loss: 1.374024853911451

Epoch: 6| Step: 8
Training loss: 0.09724774956703186
Validation loss: 1.3660366291640906

Epoch: 6| Step: 9
Training loss: 0.10616950690746307
Validation loss: 1.3748644603196012

Epoch: 6| Step: 10
Training loss: 0.09074529260396957
Validation loss: 1.3628083570029146

Epoch: 6| Step: 11
Training loss: 0.10339328646659851
Validation loss: 1.3622651600068616

Epoch: 6| Step: 12
Training loss: 0.11792588233947754
Validation loss: 1.3581749098275298

Epoch: 6| Step: 13
Training loss: 0.1783178746700287
Validation loss: 1.3294502022445842

Epoch: 613| Step: 0
Training loss: 0.10477271676063538
Validation loss: 1.3168347875277202

Epoch: 6| Step: 1
Training loss: 0.12275032699108124
Validation loss: 1.3585296715459516

Epoch: 6| Step: 2
Training loss: 0.13210833072662354
Validation loss: 1.3597093577026038

Epoch: 6| Step: 3
Training loss: 0.11117222905158997
Validation loss: 1.3780055161445373

Epoch: 6| Step: 4
Training loss: 0.08272174000740051
Validation loss: 1.3764374897044191

Epoch: 6| Step: 5
Training loss: 0.10383449494838715
Validation loss: 1.391598964250216

Epoch: 6| Step: 6
Training loss: 0.07465793192386627
Validation loss: 1.3530549919733437

Epoch: 6| Step: 7
Training loss: 0.1369508057832718
Validation loss: 1.3427251231285833

Epoch: 6| Step: 8
Training loss: 0.07329058647155762
Validation loss: 1.3105174174872778

Epoch: 6| Step: 9
Training loss: 0.10660412907600403
Validation loss: 1.332414210483592

Epoch: 6| Step: 10
Training loss: 0.07366025447845459
Validation loss: 1.360253272518035

Epoch: 6| Step: 11
Training loss: 0.1858798712491989
Validation loss: 1.3266128429802515

Epoch: 6| Step: 12
Training loss: 0.15537606179714203
Validation loss: 1.320736623579456

Epoch: 6| Step: 13
Training loss: 0.10354120284318924
Validation loss: 1.312050341277994

Epoch: 614| Step: 0
Training loss: 0.0751926600933075
Validation loss: 1.336538948038573

Epoch: 6| Step: 1
Training loss: 0.10956404358148575
Validation loss: 1.328997895281802

Epoch: 6| Step: 2
Training loss: 0.1828974485397339
Validation loss: 1.3665231402202318

Epoch: 6| Step: 3
Training loss: 0.08614892512559891
Validation loss: 1.3680717342643327

Epoch: 6| Step: 4
Training loss: 0.08450713753700256
Validation loss: 1.3850849866867065

Epoch: 6| Step: 5
Training loss: 0.1020050123333931
Validation loss: 1.3925736886198803

Epoch: 6| Step: 6
Training loss: 0.16694624722003937
Validation loss: 1.4034490514827032

Epoch: 6| Step: 7
Training loss: 0.11569766700267792
Validation loss: 1.3603590085942259

Epoch: 6| Step: 8
Training loss: 0.06727966666221619
Validation loss: 1.4192168545979325

Epoch: 6| Step: 9
Training loss: 0.12839606404304504
Validation loss: 1.395674931105747

Epoch: 6| Step: 10
Training loss: 0.08243042975664139
Validation loss: 1.4238566301202262

Epoch: 6| Step: 11
Training loss: 0.08348561823368073
Validation loss: 1.4146955333730227

Epoch: 6| Step: 12
Training loss: 0.08574865013360977
Validation loss: 1.3995912485225226

Epoch: 6| Step: 13
Training loss: 0.06466282904148102
Validation loss: 1.421135506322307

Epoch: 615| Step: 0
Training loss: 0.13800537586212158
Validation loss: 1.393394761188056

Epoch: 6| Step: 1
Training loss: 0.10618457943201065
Validation loss: 1.4003120994055143

Epoch: 6| Step: 2
Training loss: 0.09739002585411072
Validation loss: 1.392857902793474

Epoch: 6| Step: 3
Training loss: 0.11268774420022964
Validation loss: 1.3672339339410104

Epoch: 6| Step: 4
Training loss: 0.20618873834609985
Validation loss: 1.3938025146402337

Epoch: 6| Step: 5
Training loss: 0.13900451362133026
Validation loss: 1.3850993084651169

Epoch: 6| Step: 6
Training loss: 0.09139391034841537
Validation loss: 1.3609778291435652

Epoch: 6| Step: 7
Training loss: 0.11145386844873428
Validation loss: 1.3821076282890894

Epoch: 6| Step: 8
Training loss: 0.06929855048656464
Validation loss: 1.3848941787596671

Epoch: 6| Step: 9
Training loss: 0.07942279428243637
Validation loss: 1.383586875854

Epoch: 6| Step: 10
Training loss: 0.06010931357741356
Validation loss: 1.414017927262091

Epoch: 6| Step: 11
Training loss: 0.11027992516756058
Validation loss: 1.419755926696203

Epoch: 6| Step: 12
Training loss: 0.13283121585845947
Validation loss: 1.4118587701551375

Epoch: 6| Step: 13
Training loss: 0.10935167223215103
Validation loss: 1.3568190169590775

Epoch: 616| Step: 0
Training loss: 0.08230304718017578
Validation loss: 1.3679134281732703

Epoch: 6| Step: 1
Training loss: 0.05981627479195595
Validation loss: 1.3474828722656413

Epoch: 6| Step: 2
Training loss: 0.045074108988046646
Validation loss: 1.320321563751467

Epoch: 6| Step: 3
Training loss: 0.09380577504634857
Validation loss: 1.31438494882276

Epoch: 6| Step: 4
Training loss: 0.10247865319252014
Validation loss: 1.323118366861856

Epoch: 6| Step: 5
Training loss: 0.15275481343269348
Validation loss: 1.3067484824888167

Epoch: 6| Step: 6
Training loss: 0.1345178782939911
Validation loss: 1.3118481712956582

Epoch: 6| Step: 7
Training loss: 0.1658337563276291
Validation loss: 1.3106909041763635

Epoch: 6| Step: 8
Training loss: 0.0652247816324234
Validation loss: 1.315197668408835

Epoch: 6| Step: 9
Training loss: 0.14367720484733582
Validation loss: 1.337888874033446

Epoch: 6| Step: 10
Training loss: 0.2004842758178711
Validation loss: 1.3470873332792712

Epoch: 6| Step: 11
Training loss: 0.14517121016979218
Validation loss: 1.424429993475637

Epoch: 6| Step: 12
Training loss: 0.056471895426511765
Validation loss: 1.401413361231486

Epoch: 6| Step: 13
Training loss: 0.14121560752391815
Validation loss: 1.4294300758710472

Epoch: 617| Step: 0
Training loss: 0.10176736116409302
Validation loss: 1.3541864656632947

Epoch: 6| Step: 1
Training loss: 0.11662743985652924
Validation loss: 1.3612813295856598

Epoch: 6| Step: 2
Training loss: 0.13506940007209778
Validation loss: 1.370209854136231

Epoch: 6| Step: 3
Training loss: 0.156126007437706
Validation loss: 1.3523132006327312

Epoch: 6| Step: 4
Training loss: 0.14800119400024414
Validation loss: 1.3414019884601716

Epoch: 6| Step: 5
Training loss: 0.042313139885663986
Validation loss: 1.3173035806225193

Epoch: 6| Step: 6
Training loss: 0.06881307810544968
Validation loss: 1.3598323534893733

Epoch: 6| Step: 7
Training loss: 0.11548589169979095
Validation loss: 1.3277392259208105

Epoch: 6| Step: 8
Training loss: 0.09276024997234344
Validation loss: 1.347180660052966

Epoch: 6| Step: 9
Training loss: 0.0816149041056633
Validation loss: 1.3649694009493756

Epoch: 6| Step: 10
Training loss: 0.07064233720302582
Validation loss: 1.3448238629166798

Epoch: 6| Step: 11
Training loss: 0.10307662189006805
Validation loss: 1.3837895098552908

Epoch: 6| Step: 12
Training loss: 0.0990438237786293
Validation loss: 1.3956663057368288

Epoch: 6| Step: 13
Training loss: 0.12895384430885315
Validation loss: 1.3687741320620301

Epoch: 618| Step: 0
Training loss: 0.07867756485939026
Validation loss: 1.3728633279441504

Epoch: 6| Step: 1
Training loss: 0.06682121753692627
Validation loss: 1.365706201522581

Epoch: 6| Step: 2
Training loss: 0.0616169236600399
Validation loss: 1.3297997584906958

Epoch: 6| Step: 3
Training loss: 0.1421823501586914
Validation loss: 1.333335026617973

Epoch: 6| Step: 4
Training loss: 0.13125769793987274
Validation loss: 1.3181066795061993

Epoch: 6| Step: 5
Training loss: 0.07443924248218536
Validation loss: 1.3219858779702136

Epoch: 6| Step: 6
Training loss: 0.0961141288280487
Validation loss: 1.341030349013626

Epoch: 6| Step: 7
Training loss: 0.12453442811965942
Validation loss: 1.3239637677387526

Epoch: 6| Step: 8
Training loss: 0.20339778065681458
Validation loss: 1.3104467930332306

Epoch: 6| Step: 9
Training loss: 0.1297861933708191
Validation loss: 1.3062960857986121

Epoch: 6| Step: 10
Training loss: 0.11476302146911621
Validation loss: 1.3249018102563836

Epoch: 6| Step: 11
Training loss: 0.053117845207452774
Validation loss: 1.3231964803511096

Epoch: 6| Step: 12
Training loss: 0.09384338557720184
Validation loss: 1.338866263948461

Epoch: 6| Step: 13
Training loss: 0.05778299272060394
Validation loss: 1.3709152968980933

Epoch: 619| Step: 0
Training loss: 0.11680563539266586
Validation loss: 1.391962400687638

Epoch: 6| Step: 1
Training loss: 0.1346193253993988
Validation loss: 1.4118254351359543

Epoch: 6| Step: 2
Training loss: 0.16060283780097961
Validation loss: 1.4156104121156918

Epoch: 6| Step: 3
Training loss: 0.07879665493965149
Validation loss: 1.4518148309441024

Epoch: 6| Step: 4
Training loss: 0.20064088702201843
Validation loss: 1.4536391663294967

Epoch: 6| Step: 5
Training loss: 0.10640883445739746
Validation loss: 1.436603698679196

Epoch: 6| Step: 6
Training loss: 0.1316036731004715
Validation loss: 1.4278193933348502

Epoch: 6| Step: 7
Training loss: 0.14840787649154663
Validation loss: 1.3972342501404464

Epoch: 6| Step: 8
Training loss: 0.11975298821926117
Validation loss: 1.390613296980499

Epoch: 6| Step: 9
Training loss: 0.23748379945755005
Validation loss: 1.3689959382498136

Epoch: 6| Step: 10
Training loss: 0.10450493544340134
Validation loss: 1.3764614764080252

Epoch: 6| Step: 11
Training loss: 0.06595909595489502
Validation loss: 1.427061342423962

Epoch: 6| Step: 12
Training loss: 0.10807061195373535
Validation loss: 1.4134111724874026

Epoch: 6| Step: 13
Training loss: 0.0758727490901947
Validation loss: 1.3966382677837084

Epoch: 620| Step: 0
Training loss: 0.0831649973988533
Validation loss: 1.3813595637198417

Epoch: 6| Step: 1
Training loss: 0.08163699507713318
Validation loss: 1.4056323253980247

Epoch: 6| Step: 2
Training loss: 0.11533930152654648
Validation loss: 1.4235971525151243

Epoch: 6| Step: 3
Training loss: 0.13752052187919617
Validation loss: 1.3747532072887625

Epoch: 6| Step: 4
Training loss: 0.10616383701562881
Validation loss: 1.3875793282703688

Epoch: 6| Step: 5
Training loss: 0.219979390501976
Validation loss: 1.4247076152473368

Epoch: 6| Step: 6
Training loss: 0.07544632256031036
Validation loss: 1.373420689695625

Epoch: 6| Step: 7
Training loss: 0.10098005086183548
Validation loss: 1.3674857834334015

Epoch: 6| Step: 8
Training loss: 0.13511884212493896
Validation loss: 1.3414729500329623

Epoch: 6| Step: 9
Training loss: 0.1672372967004776
Validation loss: 1.3350681668968611

Epoch: 6| Step: 10
Training loss: 0.09772271662950516
Validation loss: 1.3557066725146385

Epoch: 6| Step: 11
Training loss: 0.0715828537940979
Validation loss: 1.3284208056747273

Epoch: 6| Step: 12
Training loss: 0.16682501137256622
Validation loss: 1.325344176702602

Epoch: 6| Step: 13
Training loss: 0.0350596159696579
Validation loss: 1.3128187246220087

Epoch: 621| Step: 0
Training loss: 0.04644346237182617
Validation loss: 1.3437245584303332

Epoch: 6| Step: 1
Training loss: 0.10593096166849136
Validation loss: 1.327239776170382

Epoch: 6| Step: 2
Training loss: 0.09592378884553909
Validation loss: 1.356404225031535

Epoch: 6| Step: 3
Training loss: 0.11172308027744293
Validation loss: 1.3474258062660054

Epoch: 6| Step: 4
Training loss: 0.15197300910949707
Validation loss: 1.3417026439020712

Epoch: 6| Step: 5
Training loss: 0.11198921501636505
Validation loss: 1.339037860593488

Epoch: 6| Step: 6
Training loss: 0.08735404908657074
Validation loss: 1.3511368584248327

Epoch: 6| Step: 7
Training loss: 0.10425756126642227
Validation loss: 1.3699533131814772

Epoch: 6| Step: 8
Training loss: 0.09659464657306671
Validation loss: 1.3804484035379143

Epoch: 6| Step: 9
Training loss: 0.08686505258083344
Validation loss: 1.3577428389621038

Epoch: 6| Step: 10
Training loss: 0.06920351088047028
Validation loss: 1.3401721959472985

Epoch: 6| Step: 11
Training loss: 0.09395642578601837
Validation loss: 1.347715171434546

Epoch: 6| Step: 12
Training loss: 0.07573522627353668
Validation loss: 1.3079114819085726

Epoch: 6| Step: 13
Training loss: 0.09012003242969513
Validation loss: 1.310360832880902

Epoch: 622| Step: 0
Training loss: 0.07024133205413818
Validation loss: 1.3171920994276642

Epoch: 6| Step: 1
Training loss: 0.08659972995519638
Validation loss: 1.31824880197484

Epoch: 6| Step: 2
Training loss: 0.1275355964899063
Validation loss: 1.3310992294742214

Epoch: 6| Step: 3
Training loss: 0.09239846467971802
Validation loss: 1.302983917215819

Epoch: 6| Step: 4
Training loss: 0.08057510107755661
Validation loss: 1.3257613899887248

Epoch: 6| Step: 5
Training loss: 0.08086977899074554
Validation loss: 1.3355719363817604

Epoch: 6| Step: 6
Training loss: 0.08057305216789246
Validation loss: 1.359226119133734

Epoch: 6| Step: 7
Training loss: 0.17171430587768555
Validation loss: 1.3489309190421976

Epoch: 6| Step: 8
Training loss: 0.08958902955055237
Validation loss: 1.3576297324190858

Epoch: 6| Step: 9
Training loss: 0.08458124846220016
Validation loss: 1.33704262779605

Epoch: 6| Step: 10
Training loss: 0.08598128706216812
Validation loss: 1.3814005492835917

Epoch: 6| Step: 11
Training loss: 0.12430942803621292
Validation loss: 1.3691522152193132

Epoch: 6| Step: 12
Training loss: 0.154940664768219
Validation loss: 1.4028959690883596

Epoch: 6| Step: 13
Training loss: 0.09039958566427231
Validation loss: 1.3646125332001717

Epoch: 623| Step: 0
Training loss: 0.11316436529159546
Validation loss: 1.3612829767247683

Epoch: 6| Step: 1
Training loss: 0.04670773074030876
Validation loss: 1.3510805752969557

Epoch: 6| Step: 2
Training loss: 0.14367446303367615
Validation loss: 1.3426438057294456

Epoch: 6| Step: 3
Training loss: 0.12978754937648773
Validation loss: 1.3691311901615513

Epoch: 6| Step: 4
Training loss: 0.0921303778886795
Validation loss: 1.3518303581463393

Epoch: 6| Step: 5
Training loss: 0.049011796712875366
Validation loss: 1.3696500024487894

Epoch: 6| Step: 6
Training loss: 0.13722093403339386
Validation loss: 1.3427364339110672

Epoch: 6| Step: 7
Training loss: 0.13530085980892181
Validation loss: 1.3947790425310853

Epoch: 6| Step: 8
Training loss: 0.10310415178537369
Validation loss: 1.3452081129115114

Epoch: 6| Step: 9
Training loss: 0.1140923723578453
Validation loss: 1.3523396317676832

Epoch: 6| Step: 10
Training loss: 0.07472702860832214
Validation loss: 1.3912754866384691

Epoch: 6| Step: 11
Training loss: 0.06154749542474747
Validation loss: 1.3860161772338293

Epoch: 6| Step: 12
Training loss: 0.09317445755004883
Validation loss: 1.3821816117532792

Epoch: 6| Step: 13
Training loss: 0.09263864159584045
Validation loss: 1.3833188991392813

Epoch: 624| Step: 0
Training loss: 0.060954444110393524
Validation loss: 1.3894621402986589

Epoch: 6| Step: 1
Training loss: 0.07040873169898987
Validation loss: 1.3616991914728636

Epoch: 6| Step: 2
Training loss: 0.06988194584846497
Validation loss: 1.359526413743214

Epoch: 6| Step: 3
Training loss: 0.056380342692136765
Validation loss: 1.3445645846346372

Epoch: 6| Step: 4
Training loss: 0.13598166406154633
Validation loss: 1.3543568349653674

Epoch: 6| Step: 5
Training loss: 0.07570578157901764
Validation loss: 1.3615576836370653

Epoch: 6| Step: 6
Training loss: 0.1808491349220276
Validation loss: 1.3597635094837477

Epoch: 6| Step: 7
Training loss: 0.049392834305763245
Validation loss: 1.3893780849313224

Epoch: 6| Step: 8
Training loss: 0.06306998431682587
Validation loss: 1.3979805195203392

Epoch: 6| Step: 9
Training loss: 0.103889599442482
Validation loss: 1.3896053926919096

Epoch: 6| Step: 10
Training loss: 0.09953327476978302
Validation loss: 1.4014271959181754

Epoch: 6| Step: 11
Training loss: 0.0654221922159195
Validation loss: 1.4079666054376991

Epoch: 6| Step: 12
Training loss: 0.09758000820875168
Validation loss: 1.3956692782781457

Epoch: 6| Step: 13
Training loss: 0.05629453435540199
Validation loss: 1.3788008894971622

Epoch: 625| Step: 0
Training loss: 0.05466839671134949
Validation loss: 1.419980941921152

Epoch: 6| Step: 1
Training loss: 0.06676657497882843
Validation loss: 1.4245664804212508

Epoch: 6| Step: 2
Training loss: 0.08943954110145569
Validation loss: 1.4212261425551547

Epoch: 6| Step: 3
Training loss: 0.07123175263404846
Validation loss: 1.447727023914296

Epoch: 6| Step: 4
Training loss: 0.09224973618984222
Validation loss: 1.4299552222733856

Epoch: 6| Step: 5
Training loss: 0.0833754763007164
Validation loss: 1.4224668254134476

Epoch: 6| Step: 6
Training loss: 0.22192876040935516
Validation loss: 1.4253429776878768

Epoch: 6| Step: 7
Training loss: 0.05899124592542648
Validation loss: 1.4181725671214442

Epoch: 6| Step: 8
Training loss: 0.07851716130971909
Validation loss: 1.3947994221923172

Epoch: 6| Step: 9
Training loss: 0.1219419315457344
Validation loss: 1.4157870982282905

Epoch: 6| Step: 10
Training loss: 0.07964061945676804
Validation loss: 1.4301248096650647

Epoch: 6| Step: 11
Training loss: 0.0760510042309761
Validation loss: 1.4239548085838236

Epoch: 6| Step: 12
Training loss: 0.06731881946325302
Validation loss: 1.4425352747722338

Epoch: 6| Step: 13
Training loss: 0.1599990576505661
Validation loss: 1.4358967786194177

Epoch: 626| Step: 0
Training loss: 0.08884528279304504
Validation loss: 1.4325305185010355

Epoch: 6| Step: 1
Training loss: 0.1670498251914978
Validation loss: 1.3994832013242988

Epoch: 6| Step: 2
Training loss: 0.08666347712278366
Validation loss: 1.4009190599123638

Epoch: 6| Step: 3
Training loss: 0.07582704722881317
Validation loss: 1.4017536165893718

Epoch: 6| Step: 4
Training loss: 0.11442065238952637
Validation loss: 1.4036925608111965

Epoch: 6| Step: 5
Training loss: 0.05499911308288574
Validation loss: 1.4096921284993489

Epoch: 6| Step: 6
Training loss: 0.08201877027750015
Validation loss: 1.425569567629086

Epoch: 6| Step: 7
Training loss: 0.09958112239837646
Validation loss: 1.435847584919263

Epoch: 6| Step: 8
Training loss: 0.10305359959602356
Validation loss: 1.4400290968597576

Epoch: 6| Step: 9
Training loss: 0.08782561123371124
Validation loss: 1.4386092411574496

Epoch: 6| Step: 10
Training loss: 0.08368157595396042
Validation loss: 1.4626967099405104

Epoch: 6| Step: 11
Training loss: 0.07913363724946976
Validation loss: 1.4046195694195327

Epoch: 6| Step: 12
Training loss: 0.04930157959461212
Validation loss: 1.4045859972635906

Epoch: 6| Step: 13
Training loss: 0.11578372865915298
Validation loss: 1.3469766814221618

Epoch: 627| Step: 0
Training loss: 0.12251082807779312
Validation loss: 1.3814421033346524

Epoch: 6| Step: 1
Training loss: 0.07832974195480347
Validation loss: 1.3612375579854494

Epoch: 6| Step: 2
Training loss: 0.07756233960390091
Validation loss: 1.3622475157501877

Epoch: 6| Step: 3
Training loss: 0.05401531234383583
Validation loss: 1.388368579649156

Epoch: 6| Step: 4
Training loss: 0.08654830604791641
Validation loss: 1.3925755895594114

Epoch: 6| Step: 5
Training loss: 0.10218895971775055
Validation loss: 1.3941285059016237

Epoch: 6| Step: 6
Training loss: 0.06548430770635605
Validation loss: 1.4031692781756002

Epoch: 6| Step: 7
Training loss: 0.1051391214132309
Validation loss: 1.3799982109377462

Epoch: 6| Step: 8
Training loss: 0.09959754347801208
Validation loss: 1.4161997847659613

Epoch: 6| Step: 9
Training loss: 0.08298077434301376
Validation loss: 1.3901775267816359

Epoch: 6| Step: 10
Training loss: 0.13233953714370728
Validation loss: 1.3733217331670946

Epoch: 6| Step: 11
Training loss: 0.09828531742095947
Validation loss: 1.4204792950742988

Epoch: 6| Step: 12
Training loss: 0.13141971826553345
Validation loss: 1.4279634138589263

Epoch: 6| Step: 13
Training loss: 0.12606890499591827
Validation loss: 1.446830899484696

Epoch: 628| Step: 0
Training loss: 0.13579659163951874
Validation loss: 1.4904892188246532

Epoch: 6| Step: 1
Training loss: 0.0996745154261589
Validation loss: 1.446219007174174

Epoch: 6| Step: 2
Training loss: 0.0972817912697792
Validation loss: 1.4393512984757781

Epoch: 6| Step: 3
Training loss: 0.057081952691078186
Validation loss: 1.4106301940897459

Epoch: 6| Step: 4
Training loss: 0.10978733748197556
Validation loss: 1.3772849197028785

Epoch: 6| Step: 5
Training loss: 0.08387171477079391
Validation loss: 1.3799717477572861

Epoch: 6| Step: 6
Training loss: 0.1974996030330658
Validation loss: 1.35274185416519

Epoch: 6| Step: 7
Training loss: 0.21017688512802124
Validation loss: 1.3578368720187937

Epoch: 6| Step: 8
Training loss: 0.11994403600692749
Validation loss: 1.322801241310694

Epoch: 6| Step: 9
Training loss: 0.13708695769309998
Validation loss: 1.2975501565523044

Epoch: 6| Step: 10
Training loss: 0.08910322189331055
Validation loss: 1.3648889128879835

Epoch: 6| Step: 11
Training loss: 0.07774956524372101
Validation loss: 1.3641740548354324

Epoch: 6| Step: 12
Training loss: 0.1331622302532196
Validation loss: 1.3954414898349392

Epoch: 6| Step: 13
Training loss: 0.18823106586933136
Validation loss: 1.4116632553838915

Epoch: 629| Step: 0
Training loss: 0.14749018847942352
Validation loss: 1.4200097168645551

Epoch: 6| Step: 1
Training loss: 0.07213158905506134
Validation loss: 1.3880914154873099

Epoch: 6| Step: 2
Training loss: 0.06983543932437897
Validation loss: 1.3940470500658917

Epoch: 6| Step: 3
Training loss: 0.06954733282327652
Validation loss: 1.3831842753194994

Epoch: 6| Step: 4
Training loss: 0.13422571122646332
Validation loss: 1.399701827315874

Epoch: 6| Step: 5
Training loss: 0.13336925208568573
Validation loss: 1.3992830040634319

Epoch: 6| Step: 6
Training loss: 0.10507597029209137
Validation loss: 1.3699485063552856

Epoch: 6| Step: 7
Training loss: 0.14620128273963928
Validation loss: 1.4115327865846696

Epoch: 6| Step: 8
Training loss: 0.11880870908498764
Validation loss: 1.4178310927524362

Epoch: 6| Step: 9
Training loss: 0.12526604533195496
Validation loss: 1.4243489593587897

Epoch: 6| Step: 10
Training loss: 0.06182878091931343
Validation loss: 1.4049307223289245

Epoch: 6| Step: 11
Training loss: 0.0966644287109375
Validation loss: 1.380575277472055

Epoch: 6| Step: 12
Training loss: 0.12702780961990356
Validation loss: 1.3752642767403715

Epoch: 6| Step: 13
Training loss: 0.10044273734092712
Validation loss: 1.4203247767622753

Epoch: 630| Step: 0
Training loss: 0.09900544583797455
Validation loss: 1.4232040143782092

Epoch: 6| Step: 1
Training loss: 0.11346837878227234
Validation loss: 1.4105841395675496

Epoch: 6| Step: 2
Training loss: 0.16620148718357086
Validation loss: 1.409751748525968

Epoch: 6| Step: 3
Training loss: 0.047966793179512024
Validation loss: 1.364166666743576

Epoch: 6| Step: 4
Training loss: 0.1304786652326584
Validation loss: 1.3428701880157634

Epoch: 6| Step: 5
Training loss: 0.18970987200737
Validation loss: 1.3635500490024526

Epoch: 6| Step: 6
Training loss: 0.07349788397550583
Validation loss: 1.3728372666143602

Epoch: 6| Step: 7
Training loss: 0.10101745277643204
Validation loss: 1.3639280840914736

Epoch: 6| Step: 8
Training loss: 0.06819748133420944
Validation loss: 1.3402854729724187

Epoch: 6| Step: 9
Training loss: 0.10040812939405441
Validation loss: 1.3527743668966397

Epoch: 6| Step: 10
Training loss: 0.0966988056898117
Validation loss: 1.3496853433629519

Epoch: 6| Step: 11
Training loss: 0.10998374223709106
Validation loss: 1.3616525562860633

Epoch: 6| Step: 12
Training loss: 0.0535070039331913
Validation loss: 1.3677379206944538

Epoch: 6| Step: 13
Training loss: 0.07084284722805023
Validation loss: 1.3690862066002303

Epoch: 631| Step: 0
Training loss: 0.0815257877111435
Validation loss: 1.3786164534989225

Epoch: 6| Step: 1
Training loss: 0.08504030853509903
Validation loss: 1.4023445062739874

Epoch: 6| Step: 2
Training loss: 0.053304582834243774
Validation loss: 1.3897065347240818

Epoch: 6| Step: 3
Training loss: 0.0833980143070221
Validation loss: 1.3951058887666272

Epoch: 6| Step: 4
Training loss: 0.12331950664520264
Validation loss: 1.4631173892687726

Epoch: 6| Step: 5
Training loss: 0.12024515122175217
Validation loss: 1.4218477600364274

Epoch: 6| Step: 6
Training loss: 0.07125793397426605
Validation loss: 1.3929639875247914

Epoch: 6| Step: 7
Training loss: 0.06609904766082764
Validation loss: 1.3323609982767413

Epoch: 6| Step: 8
Training loss: 0.06007401645183563
Validation loss: 1.3580995798110962

Epoch: 6| Step: 9
Training loss: 0.1352861523628235
Validation loss: 1.32081094736694

Epoch: 6| Step: 10
Training loss: 0.1065492108464241
Validation loss: 1.3292219920824933

Epoch: 6| Step: 11
Training loss: 0.12588220834732056
Validation loss: 1.338746424644224

Epoch: 6| Step: 12
Training loss: 0.22633108496665955
Validation loss: 1.3581905082989765

Epoch: 6| Step: 13
Training loss: 0.09212083369493484
Validation loss: 1.3625374609424221

Epoch: 632| Step: 0
Training loss: 0.12008944153785706
Validation loss: 1.400424406092654

Epoch: 6| Step: 1
Training loss: 0.07755432277917862
Validation loss: 1.413402421500093

Epoch: 6| Step: 2
Training loss: 0.07203405350446701
Validation loss: 1.4141125012469549

Epoch: 6| Step: 3
Training loss: 0.07362031936645508
Validation loss: 1.4181369023938333

Epoch: 6| Step: 4
Training loss: 0.06891538947820663
Validation loss: 1.410623364551093

Epoch: 6| Step: 5
Training loss: 0.06612467765808105
Validation loss: 1.3593460436790221

Epoch: 6| Step: 6
Training loss: 0.11539631336927414
Validation loss: 1.375953120570029

Epoch: 6| Step: 7
Training loss: 0.1120583638548851
Validation loss: 1.401079786080186

Epoch: 6| Step: 8
Training loss: 0.07996034622192383
Validation loss: 1.3838716706921976

Epoch: 6| Step: 9
Training loss: 0.12277865409851074
Validation loss: 1.3951110019478747

Epoch: 6| Step: 10
Training loss: 0.09172879904508591
Validation loss: 1.4166753599720616

Epoch: 6| Step: 11
Training loss: 0.159575417637825
Validation loss: 1.4071369799234534

Epoch: 6| Step: 12
Training loss: 0.10389689356088638
Validation loss: 1.4179805273650794

Epoch: 6| Step: 13
Training loss: 0.22997909784317017
Validation loss: 1.414501033803468

Epoch: 633| Step: 0
Training loss: 0.07704822719097137
Validation loss: 1.4080263222417524

Epoch: 6| Step: 1
Training loss: 0.06790028512477875
Validation loss: 1.3820451895395915

Epoch: 6| Step: 2
Training loss: 0.09181448817253113
Validation loss: 1.389955392447851

Epoch: 6| Step: 3
Training loss: 0.1008370965719223
Validation loss: 1.4122191193283244

Epoch: 6| Step: 4
Training loss: 0.11799081414937973
Validation loss: 1.3755390285163798

Epoch: 6| Step: 5
Training loss: 0.09920483827590942
Validation loss: 1.3733657495949858

Epoch: 6| Step: 6
Training loss: 0.08597757667303085
Validation loss: 1.3809072638070712

Epoch: 6| Step: 7
Training loss: 0.1581285148859024
Validation loss: 1.4195580021027596

Epoch: 6| Step: 8
Training loss: 0.0573955662548542
Validation loss: 1.4225877087603334

Epoch: 6| Step: 9
Training loss: 0.095060333609581
Validation loss: 1.461120092740623

Epoch: 6| Step: 10
Training loss: 0.14630547165870667
Validation loss: 1.4500289373500372

Epoch: 6| Step: 11
Training loss: 0.10304120182991028
Validation loss: 1.449999085036657

Epoch: 6| Step: 12
Training loss: 0.10176992416381836
Validation loss: 1.4598876853143015

Epoch: 6| Step: 13
Training loss: 0.0847538411617279
Validation loss: 1.4769079018664617

Epoch: 634| Step: 0
Training loss: 0.12312823534011841
Validation loss: 1.4329062418271137

Epoch: 6| Step: 1
Training loss: 0.07446153461933136
Validation loss: 1.3991374995118828

Epoch: 6| Step: 2
Training loss: 0.12392540276050568
Validation loss: 1.422852978270541

Epoch: 6| Step: 3
Training loss: 0.09884501248598099
Validation loss: 1.3799570119509132

Epoch: 6| Step: 4
Training loss: 0.10794384777545929
Validation loss: 1.3850506915841052

Epoch: 6| Step: 5
Training loss: 0.15222513675689697
Validation loss: 1.380232552046417

Epoch: 6| Step: 6
Training loss: 0.08566399663686752
Validation loss: 1.371261212133592

Epoch: 6| Step: 7
Training loss: 0.08953884243965149
Validation loss: 1.394324129627597

Epoch: 6| Step: 8
Training loss: 0.11503995954990387
Validation loss: 1.4206155807741228

Epoch: 6| Step: 9
Training loss: 0.08761706948280334
Validation loss: 1.4287576572869414

Epoch: 6| Step: 10
Training loss: 0.07590894401073456
Validation loss: 1.4128852493019515

Epoch: 6| Step: 11
Training loss: 0.07750682532787323
Validation loss: 1.4156927703529276

Epoch: 6| Step: 12
Training loss: 0.09404824674129486
Validation loss: 1.4048346127233198

Epoch: 6| Step: 13
Training loss: 0.16099292039871216
Validation loss: 1.3701200908230198

Epoch: 635| Step: 0
Training loss: 0.10254701226949692
Validation loss: 1.339638795903934

Epoch: 6| Step: 1
Training loss: 0.058653347194194794
Validation loss: 1.3597050366863128

Epoch: 6| Step: 2
Training loss: 0.07801458239555359
Validation loss: 1.3192229296571465

Epoch: 6| Step: 3
Training loss: 0.14489701390266418
Validation loss: 1.306557821971114

Epoch: 6| Step: 4
Training loss: 0.11653518676757812
Validation loss: 1.2982824989544448

Epoch: 6| Step: 5
Training loss: 0.08266547322273254
Validation loss: 1.2921866825831834

Epoch: 6| Step: 6
Training loss: 0.06587839871644974
Validation loss: 1.3340336058729438

Epoch: 6| Step: 7
Training loss: 0.09122291952371597
Validation loss: 1.332956301268711

Epoch: 6| Step: 8
Training loss: 0.12376971542835236
Validation loss: 1.3588739556650962

Epoch: 6| Step: 9
Training loss: 0.14870643615722656
Validation loss: 1.3404815760991906

Epoch: 6| Step: 10
Training loss: 0.10596828162670135
Validation loss: 1.362878155964677

Epoch: 6| Step: 11
Training loss: 0.07604366540908813
Validation loss: 1.3395583180971042

Epoch: 6| Step: 12
Training loss: 0.11738084256649017
Validation loss: 1.3778831099951139

Epoch: 6| Step: 13
Training loss: 0.1305631846189499
Validation loss: 1.3824393595418623

Epoch: 636| Step: 0
Training loss: 0.10023364424705505
Validation loss: 1.370584584051563

Epoch: 6| Step: 1
Training loss: 0.05661388859152794
Validation loss: 1.3621300638362925

Epoch: 6| Step: 2
Training loss: 0.07593995332717896
Validation loss: 1.3628861019688268

Epoch: 6| Step: 3
Training loss: 0.053710129112005234
Validation loss: 1.3814914790532922

Epoch: 6| Step: 4
Training loss: 0.0783371776342392
Validation loss: 1.3812603014771656

Epoch: 6| Step: 5
Training loss: 0.04864230751991272
Validation loss: 1.4255605359231271

Epoch: 6| Step: 6
Training loss: 0.09241222590208054
Validation loss: 1.4093386498830651

Epoch: 6| Step: 7
Training loss: 0.08124499022960663
Validation loss: 1.4456199766487203

Epoch: 6| Step: 8
Training loss: 0.1619108021259308
Validation loss: 1.403903752244929

Epoch: 6| Step: 9
Training loss: 0.07042089849710464
Validation loss: 1.382300596083364

Epoch: 6| Step: 10
Training loss: 0.05468989163637161
Validation loss: 1.3678983642208962

Epoch: 6| Step: 11
Training loss: 0.07752079516649246
Validation loss: 1.3563378075117707

Epoch: 6| Step: 12
Training loss: 0.0660000741481781
Validation loss: 1.3818419633373138

Epoch: 6| Step: 13
Training loss: 0.12437960505485535
Validation loss: 1.3606627231003137

Epoch: 637| Step: 0
Training loss: 0.09595072269439697
Validation loss: 1.3349782420742897

Epoch: 6| Step: 1
Training loss: 0.1259405016899109
Validation loss: 1.3284553148413216

Epoch: 6| Step: 2
Training loss: 0.08154285699129105
Validation loss: 1.320067226245839

Epoch: 6| Step: 3
Training loss: 0.13208049535751343
Validation loss: 1.353967015461255

Epoch: 6| Step: 4
Training loss: 0.1253851056098938
Validation loss: 1.3885593747579923

Epoch: 6| Step: 5
Training loss: 0.07788525521755219
Validation loss: 1.3787115491846555

Epoch: 6| Step: 6
Training loss: 0.08546032011508942
Validation loss: 1.4050901884673743

Epoch: 6| Step: 7
Training loss: 0.038959164172410965
Validation loss: 1.4137728893628685

Epoch: 6| Step: 8
Training loss: 0.19789010286331177
Validation loss: 1.447581115589347

Epoch: 6| Step: 9
Training loss: 0.10870569944381714
Validation loss: 1.4331537690213931

Epoch: 6| Step: 10
Training loss: 0.07779879122972488
Validation loss: 1.3878842681966803

Epoch: 6| Step: 11
Training loss: 0.17160528898239136
Validation loss: 1.3601318969521472

Epoch: 6| Step: 12
Training loss: 0.11139421164989471
Validation loss: 1.3260545422953944

Epoch: 6| Step: 13
Training loss: 0.07692787051200867
Validation loss: 1.2983208061546407

Epoch: 638| Step: 0
Training loss: 0.08353181183338165
Validation loss: 1.3256024865693943

Epoch: 6| Step: 1
Training loss: 0.12090301513671875
Validation loss: 1.3220245248527938

Epoch: 6| Step: 2
Training loss: 0.057659126818180084
Validation loss: 1.32720898940999

Epoch: 6| Step: 3
Training loss: 0.08199291676282883
Validation loss: 1.3386794482508013

Epoch: 6| Step: 4
Training loss: 0.16861110925674438
Validation loss: 1.39081960211518

Epoch: 6| Step: 5
Training loss: 0.08023261278867722
Validation loss: 1.3754373404287523

Epoch: 6| Step: 6
Training loss: 0.06696192920207977
Validation loss: 1.3917793535417127

Epoch: 6| Step: 7
Training loss: 0.07015545666217804
Validation loss: 1.4123765614724928

Epoch: 6| Step: 8
Training loss: 0.1039772555232048
Validation loss: 1.411924110945835

Epoch: 6| Step: 9
Training loss: 0.07546719163656235
Validation loss: 1.4143578422966825

Epoch: 6| Step: 10
Training loss: 0.07461021840572357
Validation loss: 1.3903800172190512

Epoch: 6| Step: 11
Training loss: 0.09090180695056915
Validation loss: 1.404128397664716

Epoch: 6| Step: 12
Training loss: 0.07619179785251617
Validation loss: 1.3970948585899927

Epoch: 6| Step: 13
Training loss: 0.07531601190567017
Validation loss: 1.4073014656702678

Epoch: 639| Step: 0
Training loss: 0.08282913267612457
Validation loss: 1.3790744222620481

Epoch: 6| Step: 1
Training loss: 0.15877003967761993
Validation loss: 1.4009475874644455

Epoch: 6| Step: 2
Training loss: 0.12975509464740753
Validation loss: 1.372061328221393

Epoch: 6| Step: 3
Training loss: 0.12297151237726212
Validation loss: 1.3820827404658

Epoch: 6| Step: 4
Training loss: 0.1178024560213089
Validation loss: 1.3828698140318676

Epoch: 6| Step: 5
Training loss: 0.05714398995041847
Validation loss: 1.384917797580842

Epoch: 6| Step: 6
Training loss: 0.07437336444854736
Validation loss: 1.401188688893472

Epoch: 6| Step: 7
Training loss: 0.10668181627988815
Validation loss: 1.366797116494948

Epoch: 6| Step: 8
Training loss: 0.09887571632862091
Validation loss: 1.3812627241175661

Epoch: 6| Step: 9
Training loss: 0.08047949522733688
Validation loss: 1.4132738587676839

Epoch: 6| Step: 10
Training loss: 0.09741374850273132
Validation loss: 1.424546649379115

Epoch: 6| Step: 11
Training loss: 0.07994164526462555
Validation loss: 1.4141437353626374

Epoch: 6| Step: 12
Training loss: 0.03466803580522537
Validation loss: 1.416373279786879

Epoch: 6| Step: 13
Training loss: 0.07697293162345886
Validation loss: 1.4234543833681332

Epoch: 640| Step: 0
Training loss: 0.12710914015769958
Validation loss: 1.3829668260389758

Epoch: 6| Step: 1
Training loss: 0.12175025045871735
Validation loss: 1.3810326424978112

Epoch: 6| Step: 2
Training loss: 0.02883625589311123
Validation loss: 1.3863143779898202

Epoch: 6| Step: 3
Training loss: 0.07570891082286835
Validation loss: 1.3886123703372093

Epoch: 6| Step: 4
Training loss: 0.05494172126054764
Validation loss: 1.3922284597991614

Epoch: 6| Step: 5
Training loss: 0.11420285701751709
Validation loss: 1.3761778005989649

Epoch: 6| Step: 6
Training loss: 0.16951344907283783
Validation loss: 1.3459782715766662

Epoch: 6| Step: 7
Training loss: 0.11159849911928177
Validation loss: 1.3731938613358365

Epoch: 6| Step: 8
Training loss: 0.08358313143253326
Validation loss: 1.4016405074827132

Epoch: 6| Step: 9
Training loss: 0.05162360519170761
Validation loss: 1.3583113576776238

Epoch: 6| Step: 10
Training loss: 0.08598186075687408
Validation loss: 1.3461978012515652

Epoch: 6| Step: 11
Training loss: 0.08252321183681488
Validation loss: 1.358555309234127

Epoch: 6| Step: 12
Training loss: 0.11083821207284927
Validation loss: 1.3868976100798576

Epoch: 6| Step: 13
Training loss: 0.07860985398292542
Validation loss: 1.3481691659137767

Epoch: 641| Step: 0
Training loss: 0.13573965430259705
Validation loss: 1.3579501657075779

Epoch: 6| Step: 1
Training loss: 0.06757070124149323
Validation loss: 1.3491132701596906

Epoch: 6| Step: 2
Training loss: 0.09555455297231674
Validation loss: 1.3685833420804752

Epoch: 6| Step: 3
Training loss: 0.07864968478679657
Validation loss: 1.381068750094342

Epoch: 6| Step: 4
Training loss: 0.05987481027841568
Validation loss: 1.3958237286536925

Epoch: 6| Step: 5
Training loss: 0.0818299651145935
Validation loss: 1.3932788974495345

Epoch: 6| Step: 6
Training loss: 0.08926181495189667
Validation loss: 1.387135318530503

Epoch: 6| Step: 7
Training loss: 0.06219738721847534
Validation loss: 1.3684325025927635

Epoch: 6| Step: 8
Training loss: 0.09427706152200699
Validation loss: 1.3973066678611181

Epoch: 6| Step: 9
Training loss: 0.0758158415555954
Validation loss: 1.393343388393361

Epoch: 6| Step: 10
Training loss: 0.06683322042226791
Validation loss: 1.3992192411935458

Epoch: 6| Step: 11
Training loss: 0.08116258680820465
Validation loss: 1.427881867654862

Epoch: 6| Step: 12
Training loss: 0.130595400929451
Validation loss: 1.4424106574827624

Epoch: 6| Step: 13
Training loss: 0.11572340130805969
Validation loss: 1.414685853065983

Epoch: 642| Step: 0
Training loss: 0.09957203269004822
Validation loss: 1.4198830819899035

Epoch: 6| Step: 1
Training loss: 0.06355556845664978
Validation loss: 1.4181395961392311

Epoch: 6| Step: 2
Training loss: 0.13153892755508423
Validation loss: 1.3951136553159325

Epoch: 6| Step: 3
Training loss: 0.07571262121200562
Validation loss: 1.3945494851758402

Epoch: 6| Step: 4
Training loss: 0.11056946218013763
Validation loss: 1.4036080580885693

Epoch: 6| Step: 5
Training loss: 0.10264240205287933
Validation loss: 1.3942937261314803

Epoch: 6| Step: 6
Training loss: 0.07845728099346161
Validation loss: 1.4014199273560637

Epoch: 6| Step: 7
Training loss: 0.09237255156040192
Validation loss: 1.37565654195765

Epoch: 6| Step: 8
Training loss: 0.06281495094299316
Validation loss: 1.3725840519833308

Epoch: 6| Step: 9
Training loss: 0.10553064942359924
Validation loss: 1.372905445355241

Epoch: 6| Step: 10
Training loss: 0.11994700133800507
Validation loss: 1.3649733463923137

Epoch: 6| Step: 11
Training loss: 0.10001254826784134
Validation loss: 1.3741292197217223

Epoch: 6| Step: 12
Training loss: 0.07617709040641785
Validation loss: 1.369274898241925

Epoch: 6| Step: 13
Training loss: 0.10033522546291351
Validation loss: 1.3581315791735085

Epoch: 643| Step: 0
Training loss: 0.10058098286390305
Validation loss: 1.3630176385243733

Epoch: 6| Step: 1
Training loss: 0.2037416398525238
Validation loss: 1.372520008394795

Epoch: 6| Step: 2
Training loss: 0.0778542309999466
Validation loss: 1.3397752777222665

Epoch: 6| Step: 3
Training loss: 0.0918646827340126
Validation loss: 1.3500447914164553

Epoch: 6| Step: 4
Training loss: 0.09031462669372559
Validation loss: 1.3252134925575667

Epoch: 6| Step: 5
Training loss: 0.08498427271842957
Validation loss: 1.3050934819764988

Epoch: 6| Step: 6
Training loss: 0.07295113801956177
Validation loss: 1.337230033771966

Epoch: 6| Step: 7
Training loss: 0.08688132464885712
Validation loss: 1.3375313102558095

Epoch: 6| Step: 8
Training loss: 0.0765589103102684
Validation loss: 1.340624124773087

Epoch: 6| Step: 9
Training loss: 0.09466329216957092
Validation loss: 1.3324593972134333

Epoch: 6| Step: 10
Training loss: 0.09980429708957672
Validation loss: 1.3664958156565183

Epoch: 6| Step: 11
Training loss: 0.16136839985847473
Validation loss: 1.3415799897204164

Epoch: 6| Step: 12
Training loss: 0.07756633311510086
Validation loss: 1.376588418919553

Epoch: 6| Step: 13
Training loss: 0.06637758761644363
Validation loss: 1.3753411359684442

Epoch: 644| Step: 0
Training loss: 0.09175580739974976
Validation loss: 1.4000384499949794

Epoch: 6| Step: 1
Training loss: 0.07586416602134705
Validation loss: 1.4248485834367814

Epoch: 6| Step: 2
Training loss: 0.11441368609666824
Validation loss: 1.429326254834411

Epoch: 6| Step: 3
Training loss: 0.10749629139900208
Validation loss: 1.4295598986328288

Epoch: 6| Step: 4
Training loss: 0.07237489521503448
Validation loss: 1.4158941750885339

Epoch: 6| Step: 5
Training loss: 0.07095345854759216
Validation loss: 1.4051257897448797

Epoch: 6| Step: 6
Training loss: 0.1964951455593109
Validation loss: 1.3905096002804336

Epoch: 6| Step: 7
Training loss: 0.09156764298677444
Validation loss: 1.3723068884623948

Epoch: 6| Step: 8
Training loss: 0.12330801039934158
Validation loss: 1.3579654046284255

Epoch: 6| Step: 9
Training loss: 0.06470800936222076
Validation loss: 1.378475381482032

Epoch: 6| Step: 10
Training loss: 0.09920551627874374
Validation loss: 1.3761444937798284

Epoch: 6| Step: 11
Training loss: 0.0384984165430069
Validation loss: 1.3512236149080339

Epoch: 6| Step: 12
Training loss: 0.1069597527384758
Validation loss: 1.3721162067946566

Epoch: 6| Step: 13
Training loss: 0.09824102371931076
Validation loss: 1.3739265831567908

Epoch: 645| Step: 0
Training loss: 0.10667000710964203
Validation loss: 1.389723729061824

Epoch: 6| Step: 1
Training loss: 0.0933215320110321
Validation loss: 1.3752694719581193

Epoch: 6| Step: 2
Training loss: 0.09112867712974548
Validation loss: 1.3534543616797334

Epoch: 6| Step: 3
Training loss: 0.10416871309280396
Validation loss: 1.3836989428407402

Epoch: 6| Step: 4
Training loss: 0.14794841408729553
Validation loss: 1.3617887535402853

Epoch: 6| Step: 5
Training loss: 0.16412481665611267
Validation loss: 1.3454736266084897

Epoch: 6| Step: 6
Training loss: 0.08908060193061829
Validation loss: 1.3457263567114388

Epoch: 6| Step: 7
Training loss: 0.06601002812385559
Validation loss: 1.3562288156119726

Epoch: 6| Step: 8
Training loss: 0.0808824747800827
Validation loss: 1.3604564102747108

Epoch: 6| Step: 9
Training loss: 0.10106563568115234
Validation loss: 1.3718441237685501

Epoch: 6| Step: 10
Training loss: 0.07959534972906113
Validation loss: 1.3563941345419934

Epoch: 6| Step: 11
Training loss: 0.17360836267471313
Validation loss: 1.3592881618007537

Epoch: 6| Step: 12
Training loss: 0.06479881703853607
Validation loss: 1.3799404034050562

Epoch: 6| Step: 13
Training loss: 0.07590996474027634
Validation loss: 1.4160271107509572

Epoch: 646| Step: 0
Training loss: 0.08168800175189972
Validation loss: 1.4155000627681773

Epoch: 6| Step: 1
Training loss: 0.17468097805976868
Validation loss: 1.4139473899718253

Epoch: 6| Step: 2
Training loss: 0.07608120143413544
Validation loss: 1.416184268971925

Epoch: 6| Step: 3
Training loss: 0.07026568055152893
Validation loss: 1.3930479480374245

Epoch: 6| Step: 4
Training loss: 0.10930274426937103
Validation loss: 1.3543268506244948

Epoch: 6| Step: 5
Training loss: 0.10758095979690552
Validation loss: 1.3801405109385008

Epoch: 6| Step: 6
Training loss: 0.11612237244844437
Validation loss: 1.3601001385719544

Epoch: 6| Step: 7
Training loss: 0.07339522987604141
Validation loss: 1.3676284032483255

Epoch: 6| Step: 8
Training loss: 0.09037090837955475
Validation loss: 1.3635818766009422

Epoch: 6| Step: 9
Training loss: 0.07453646510839462
Validation loss: 1.348508055492114

Epoch: 6| Step: 10
Training loss: 0.06980166584253311
Validation loss: 1.3407120217559159

Epoch: 6| Step: 11
Training loss: 0.15854930877685547
Validation loss: 1.3458857606816035

Epoch: 6| Step: 12
Training loss: 0.057862963527441025
Validation loss: 1.3361766594712452

Epoch: 6| Step: 13
Training loss: 0.07939973473548889
Validation loss: 1.3115378810513405

Epoch: 647| Step: 0
Training loss: 0.11999383568763733
Validation loss: 1.327116277910048

Epoch: 6| Step: 1
Training loss: 0.06969234347343445
Validation loss: 1.34952050511555

Epoch: 6| Step: 2
Training loss: 0.07042543590068817
Validation loss: 1.3453021741682483

Epoch: 6| Step: 3
Training loss: 0.0955229252576828
Validation loss: 1.3284542765668643

Epoch: 6| Step: 4
Training loss: 0.06798502057790756
Validation loss: 1.3137487621717556

Epoch: 6| Step: 5
Training loss: 0.11587422341108322
Validation loss: 1.297296848348392

Epoch: 6| Step: 6
Training loss: 0.06374721974134445
Validation loss: 1.3190398754612092

Epoch: 6| Step: 7
Training loss: 0.1931728571653366
Validation loss: 1.3205384259582849

Epoch: 6| Step: 8
Training loss: 0.08436895906925201
Validation loss: 1.3157379793864425

Epoch: 6| Step: 9
Training loss: 0.14420783519744873
Validation loss: 1.3284323728212746

Epoch: 6| Step: 10
Training loss: 0.0713348314166069
Validation loss: 1.3578918441649406

Epoch: 6| Step: 11
Training loss: 0.056851908564567566
Validation loss: 1.3801468162126438

Epoch: 6| Step: 12
Training loss: 0.1652902364730835
Validation loss: 1.385286601640845

Epoch: 6| Step: 13
Training loss: 0.07813875377178192
Validation loss: 1.436026002771111

Epoch: 648| Step: 0
Training loss: 0.1578986495733261
Validation loss: 1.453422357959132

Epoch: 6| Step: 1
Training loss: 0.060402560979127884
Validation loss: 1.3866720109857538

Epoch: 6| Step: 2
Training loss: 0.13169798254966736
Validation loss: 1.3751349500430528

Epoch: 6| Step: 3
Training loss: 0.07979582250118256
Validation loss: 1.3751891864243375

Epoch: 6| Step: 4
Training loss: 0.11505679041147232
Validation loss: 1.3666641032823952

Epoch: 6| Step: 5
Training loss: 0.2085614651441574
Validation loss: 1.3600316047668457

Epoch: 6| Step: 6
Training loss: 0.10441745817661285
Validation loss: 1.3444663324663717

Epoch: 6| Step: 7
Training loss: 0.08962602913379669
Validation loss: 1.3667664515074862

Epoch: 6| Step: 8
Training loss: 0.11364729702472687
Validation loss: 1.3744328586004113

Epoch: 6| Step: 9
Training loss: 0.16191715002059937
Validation loss: 1.3795123266917404

Epoch: 6| Step: 10
Training loss: 0.10433980822563171
Validation loss: 1.4469930113002818

Epoch: 6| Step: 11
Training loss: 0.059166811406612396
Validation loss: 1.4691663942029398

Epoch: 6| Step: 12
Training loss: 0.12531797587871552
Validation loss: 1.4832039417759064

Epoch: 6| Step: 13
Training loss: 0.13894227147102356
Validation loss: 1.4646935450133456

Epoch: 649| Step: 0
Training loss: 0.06392157822847366
Validation loss: 1.4562114015702279

Epoch: 6| Step: 1
Training loss: 0.13612593710422516
Validation loss: 1.4626148105949484

Epoch: 6| Step: 2
Training loss: 0.034849636256694794
Validation loss: 1.4168711259800901

Epoch: 6| Step: 3
Training loss: 0.06327331066131592
Validation loss: 1.43043012772837

Epoch: 6| Step: 4
Training loss: 0.11918620765209198
Validation loss: 1.4197156339563348

Epoch: 6| Step: 5
Training loss: 0.09931343048810959
Validation loss: 1.413318525078476

Epoch: 6| Step: 6
Training loss: 0.12745532393455505
Validation loss: 1.4082764182039487

Epoch: 6| Step: 7
Training loss: 0.14542755484580994
Validation loss: 1.43458818363887

Epoch: 6| Step: 8
Training loss: 0.14277108013629913
Validation loss: 1.4427854296981648

Epoch: 6| Step: 9
Training loss: 0.09424000978469849
Validation loss: 1.4329934440633303

Epoch: 6| Step: 10
Training loss: 0.11163636296987534
Validation loss: 1.4658215417656848

Epoch: 6| Step: 11
Training loss: 0.09768049418926239
Validation loss: 1.48461502598178

Epoch: 6| Step: 12
Training loss: 0.06523075699806213
Validation loss: 1.4928744473764974

Epoch: 6| Step: 13
Training loss: 0.09208855032920837
Validation loss: 1.4994092513156194

Epoch: 650| Step: 0
Training loss: 0.06502296030521393
Validation loss: 1.4735881013254966

Epoch: 6| Step: 1
Training loss: 0.09046854078769684
Validation loss: 1.4500966994993147

Epoch: 6| Step: 2
Training loss: 0.05645075440406799
Validation loss: 1.4736373591166672

Epoch: 6| Step: 3
Training loss: 0.11389496922492981
Validation loss: 1.4504446688518728

Epoch: 6| Step: 4
Training loss: 0.06882055848836899
Validation loss: 1.4480669600989229

Epoch: 6| Step: 5
Training loss: 0.20027169585227966
Validation loss: 1.4535747984404206

Epoch: 6| Step: 6
Training loss: 0.18219953775405884
Validation loss: 1.4316718257883543

Epoch: 6| Step: 7
Training loss: 0.14017599821090698
Validation loss: 1.432853292393428

Epoch: 6| Step: 8
Training loss: 0.14345285296440125
Validation loss: 1.4155486873401109

Epoch: 6| Step: 9
Training loss: 0.12120859324932098
Validation loss: 1.4252486741670998

Epoch: 6| Step: 10
Training loss: 0.0534629225730896
Validation loss: 1.3989826722811627

Epoch: 6| Step: 11
Training loss: 0.13712774217128754
Validation loss: 1.4094296860438522

Epoch: 6| Step: 12
Training loss: 0.11389976739883423
Validation loss: 1.4197509301606046

Epoch: 6| Step: 13
Training loss: 0.133132204413414
Validation loss: 1.4127345097962247

Testing loss: 2.536031405131022
