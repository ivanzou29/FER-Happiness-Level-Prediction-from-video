Epoch: 1| Step: 0
Training loss: 3.964970588684082
Validation loss: 5.17483135448989

Epoch: 6| Step: 1
Training loss: 6.0083465576171875
Validation loss: 5.14690290984287

Epoch: 6| Step: 2
Training loss: 6.081506729125977
Validation loss: 5.1224584118012455

Epoch: 6| Step: 3
Training loss: 3.9107155799865723
Validation loss: 5.098249466188492

Epoch: 6| Step: 4
Training loss: 4.740779876708984
Validation loss: 5.072705115041425

Epoch: 6| Step: 5
Training loss: 5.046746253967285
Validation loss: 5.043914610339749

Epoch: 6| Step: 6
Training loss: 5.493679046630859
Validation loss: 5.010735234906597

Epoch: 6| Step: 7
Training loss: 4.134863376617432
Validation loss: 4.9736739281685125

Epoch: 6| Step: 8
Training loss: 4.328113555908203
Validation loss: 4.9319550657785065

Epoch: 6| Step: 9
Training loss: 4.991508483886719
Validation loss: 4.884830577399141

Epoch: 6| Step: 10
Training loss: 4.742047309875488
Validation loss: 4.832877717992311

Epoch: 6| Step: 11
Training loss: 3.953284978866577
Validation loss: 4.774782749914354

Epoch: 6| Step: 12
Training loss: 4.148998260498047
Validation loss: 4.711478971665906

Epoch: 6| Step: 13
Training loss: 5.356973648071289
Validation loss: 4.645490610471335

Epoch: 2| Step: 0
Training loss: 3.987031936645508
Validation loss: 4.5743857660601215

Epoch: 6| Step: 1
Training loss: 5.237994194030762
Validation loss: 4.500011572273829

Epoch: 6| Step: 2
Training loss: 4.526470184326172
Validation loss: 4.424979261172715

Epoch: 6| Step: 3
Training loss: 4.640569686889648
Validation loss: 4.347263059308452

Epoch: 6| Step: 4
Training loss: 2.835120677947998
Validation loss: 4.2602597359688055

Epoch: 6| Step: 5
Training loss: 4.935302734375
Validation loss: 4.168157364732476

Epoch: 6| Step: 6
Training loss: 4.092984199523926
Validation loss: 4.085212094809419

Epoch: 6| Step: 7
Training loss: 3.4788999557495117
Validation loss: 4.013211665614959

Epoch: 6| Step: 8
Training loss: 3.873991012573242
Validation loss: 3.9494317911004506

Epoch: 6| Step: 9
Training loss: 2.906402587890625
Validation loss: 3.8918343667061097

Epoch: 6| Step: 10
Training loss: 4.534721374511719
Validation loss: 3.8413937091827393

Epoch: 6| Step: 11
Training loss: 2.71975040435791
Validation loss: 3.7893365942021853

Epoch: 6| Step: 12
Training loss: 3.8022241592407227
Validation loss: 3.7458308640346734

Epoch: 6| Step: 13
Training loss: 3.6925048828125
Validation loss: 3.7021806880991948

Epoch: 3| Step: 0
Training loss: 4.741603851318359
Validation loss: 3.6624460476700977

Epoch: 6| Step: 1
Training loss: 3.540274143218994
Validation loss: 3.6249412336657123

Epoch: 6| Step: 2
Training loss: 2.055560827255249
Validation loss: 3.588790180862591

Epoch: 6| Step: 3
Training loss: 4.228777885437012
Validation loss: 3.5573888542831584

Epoch: 6| Step: 4
Training loss: 3.9793343544006348
Validation loss: 3.522993831224339

Epoch: 6| Step: 5
Training loss: 3.7106986045837402
Validation loss: 3.487310468509633

Epoch: 6| Step: 6
Training loss: 2.8039488792419434
Validation loss: 3.447412480590164

Epoch: 6| Step: 7
Training loss: 2.9122979640960693
Validation loss: 3.4156969901054137

Epoch: 6| Step: 8
Training loss: 2.3327817916870117
Validation loss: 3.390192908625449

Epoch: 6| Step: 9
Training loss: 3.8679721355438232
Validation loss: 3.3621939510427494

Epoch: 6| Step: 10
Training loss: 3.3788833618164062
Validation loss: 3.3393602832671134

Epoch: 6| Step: 11
Training loss: 2.6948370933532715
Validation loss: 3.3148472437294583

Epoch: 6| Step: 12
Training loss: 4.455961227416992
Validation loss: 3.300406514957387

Epoch: 6| Step: 13
Training loss: 2.285304546356201
Validation loss: 3.2792506628139044

Epoch: 4| Step: 0
Training loss: 3.204928398132324
Validation loss: 3.2664186082860476

Epoch: 6| Step: 1
Training loss: 2.7472405433654785
Validation loss: 3.2461871126646638

Epoch: 6| Step: 2
Training loss: 4.396282196044922
Validation loss: 3.226964968507008

Epoch: 6| Step: 3
Training loss: 2.1021945476531982
Validation loss: 3.1963628235683648

Epoch: 6| Step: 4
Training loss: 3.067533493041992
Validation loss: 3.17418590412345

Epoch: 6| Step: 5
Training loss: 3.2751476764678955
Validation loss: 3.162750874796221

Epoch: 6| Step: 6
Training loss: 3.8311915397644043
Validation loss: 3.1417253196880384

Epoch: 6| Step: 7
Training loss: 3.5462307929992676
Validation loss: 3.1142591097021617

Epoch: 6| Step: 8
Training loss: 1.9206604957580566
Validation loss: 3.0886373571170274

Epoch: 6| Step: 9
Training loss: 3.6175708770751953
Validation loss: 3.110458468878141

Epoch: 6| Step: 10
Training loss: 2.4251387119293213
Validation loss: 3.1002815974655973

Epoch: 6| Step: 11
Training loss: 3.0656542778015137
Validation loss: 3.12815035030406

Epoch: 6| Step: 12
Training loss: 4.002901077270508
Validation loss: 3.129538059234619

Epoch: 6| Step: 13
Training loss: 3.355815887451172
Validation loss: 3.1166207585283505

Epoch: 5| Step: 0
Training loss: 2.7273268699645996
Validation loss: 3.0881302407992783

Epoch: 6| Step: 1
Training loss: 2.438291072845459
Validation loss: 3.0700964056035525

Epoch: 6| Step: 2
Training loss: 3.307910442352295
Validation loss: 3.057264745876353

Epoch: 6| Step: 3
Training loss: 4.510820388793945
Validation loss: 3.0554901117919595

Epoch: 6| Step: 4
Training loss: 2.99057674407959
Validation loss: 3.0437413313055552

Epoch: 6| Step: 5
Training loss: 2.7147250175476074
Validation loss: 3.0358811783534225

Epoch: 6| Step: 6
Training loss: 3.157020092010498
Validation loss: 3.0320083428454656

Epoch: 6| Step: 7
Training loss: 3.2444725036621094
Validation loss: 3.013287364795644

Epoch: 6| Step: 8
Training loss: 2.527968168258667
Validation loss: 2.99797998961582

Epoch: 6| Step: 9
Training loss: 2.4122564792633057
Validation loss: 2.9857193013673187

Epoch: 6| Step: 10
Training loss: 4.48282527923584
Validation loss: 2.9786512723533054

Epoch: 6| Step: 11
Training loss: 3.1658506393432617
Validation loss: 2.972714113932784

Epoch: 6| Step: 12
Training loss: 1.8929535150527954
Validation loss: 2.9599661903996624

Epoch: 6| Step: 13
Training loss: 3.637694835662842
Validation loss: 2.949791234026673

Epoch: 6| Step: 0
Training loss: 3.537565231323242
Validation loss: 2.9388750804367887

Epoch: 6| Step: 1
Training loss: 3.7286248207092285
Validation loss: 2.9251990420843965

Epoch: 6| Step: 2
Training loss: 2.88364839553833
Validation loss: 2.916821320851644

Epoch: 6| Step: 3
Training loss: 2.4115123748779297
Validation loss: 2.904907403453704

Epoch: 6| Step: 4
Training loss: 2.3537044525146484
Validation loss: 2.9010265181141515

Epoch: 6| Step: 5
Training loss: 2.707540988922119
Validation loss: 2.8962384782811648

Epoch: 6| Step: 6
Training loss: 2.861445188522339
Validation loss: 2.8837495875614945

Epoch: 6| Step: 7
Training loss: 2.1150503158569336
Validation loss: 2.882164283465314

Epoch: 6| Step: 8
Training loss: 2.5687952041625977
Validation loss: 2.8790545309743574

Epoch: 6| Step: 9
Training loss: 3.69473934173584
Validation loss: 2.8751540107111775

Epoch: 6| Step: 10
Training loss: 2.419118881225586
Validation loss: 2.8699872288652646

Epoch: 6| Step: 11
Training loss: 3.6678214073181152
Validation loss: 2.854627440052648

Epoch: 6| Step: 12
Training loss: 3.1055195331573486
Validation loss: 2.8556673244763444

Epoch: 6| Step: 13
Training loss: 4.49046516418457
Validation loss: 2.848580170703191

Epoch: 7| Step: 0
Training loss: 2.4737842082977295
Validation loss: 2.8403789612554733

Epoch: 6| Step: 1
Training loss: 2.958686590194702
Validation loss: 2.834430809943907

Epoch: 6| Step: 2
Training loss: 3.043017864227295
Validation loss: 2.835349299574411

Epoch: 6| Step: 3
Training loss: 2.579760789871216
Validation loss: 2.832834759066182

Epoch: 6| Step: 4
Training loss: 3.9706647396087646
Validation loss: 2.820069695031771

Epoch: 6| Step: 5
Training loss: 2.836717367172241
Validation loss: 2.8063521026283182

Epoch: 6| Step: 6
Training loss: 2.71364164352417
Validation loss: 2.799131022986545

Epoch: 6| Step: 7
Training loss: 3.320770263671875
Validation loss: 2.8036881185347036

Epoch: 6| Step: 8
Training loss: 2.4245221614837646
Validation loss: 2.8098129508315877

Epoch: 6| Step: 9
Training loss: 3.3064041137695312
Validation loss: 2.8205681718805784

Epoch: 6| Step: 10
Training loss: 2.500910758972168
Validation loss: 2.818900298046809

Epoch: 6| Step: 11
Training loss: 3.445446252822876
Validation loss: 2.810561421096966

Epoch: 6| Step: 12
Training loss: 2.813514232635498
Validation loss: 2.777209279357746

Epoch: 6| Step: 13
Training loss: 2.6749155521392822
Validation loss: 2.7796293586812992

Epoch: 8| Step: 0
Training loss: 4.585809707641602
Validation loss: 2.797444317930488

Epoch: 6| Step: 1
Training loss: 2.7814502716064453
Validation loss: 2.765392521376251

Epoch: 6| Step: 2
Training loss: 2.5535504817962646
Validation loss: 2.759907232817783

Epoch: 6| Step: 3
Training loss: 2.836604595184326
Validation loss: 2.755719264348348

Epoch: 6| Step: 4
Training loss: 3.0217373371124268
Validation loss: 2.7659770288775043

Epoch: 6| Step: 5
Training loss: 3.0575132369995117
Validation loss: 2.774285852268178

Epoch: 6| Step: 6
Training loss: 2.555041790008545
Validation loss: 2.763629549293108

Epoch: 6| Step: 7
Training loss: 2.532802104949951
Validation loss: 2.757296992886451

Epoch: 6| Step: 8
Training loss: 2.3401987552642822
Validation loss: 2.743098489699825

Epoch: 6| Step: 9
Training loss: 3.0224547386169434
Validation loss: 2.7543300403061735

Epoch: 6| Step: 10
Training loss: 2.1639628410339355
Validation loss: 2.730520879068682

Epoch: 6| Step: 11
Training loss: 2.9292662143707275
Validation loss: 2.7183919158033145

Epoch: 6| Step: 12
Training loss: 2.854987859725952
Validation loss: 2.716177781422933

Epoch: 6| Step: 13
Training loss: 3.7611334323883057
Validation loss: 2.715819074261573

Epoch: 9| Step: 0
Training loss: 3.748230457305908
Validation loss: 2.733662405321675

Epoch: 6| Step: 1
Training loss: 2.676516056060791
Validation loss: 2.732563990418629

Epoch: 6| Step: 2
Training loss: 3.1664347648620605
Validation loss: 2.71562651793162

Epoch: 6| Step: 3
Training loss: 2.718581199645996
Validation loss: 2.707461957008608

Epoch: 6| Step: 4
Training loss: 2.3931679725646973
Validation loss: 2.699851038635418

Epoch: 6| Step: 5
Training loss: 2.185257911682129
Validation loss: 2.702472681640297

Epoch: 6| Step: 6
Training loss: 2.2023792266845703
Validation loss: 2.7027331988016763

Epoch: 6| Step: 7
Training loss: 3.6202635765075684
Validation loss: 2.706836538930093

Epoch: 6| Step: 8
Training loss: 2.8835511207580566
Validation loss: 2.7062791675649662

Epoch: 6| Step: 9
Training loss: 3.502230644226074
Validation loss: 2.695314804712931

Epoch: 6| Step: 10
Training loss: 3.366877555847168
Validation loss: 2.6815717938125774

Epoch: 6| Step: 11
Training loss: 2.218078851699829
Validation loss: 2.675258780038485

Epoch: 6| Step: 12
Training loss: 2.5382509231567383
Validation loss: 2.676735452426377

Epoch: 6| Step: 13
Training loss: 2.966149091720581
Validation loss: 2.6865012363720964

Epoch: 10| Step: 0
Training loss: 3.7465643882751465
Validation loss: 2.6742881087846655

Epoch: 6| Step: 1
Training loss: 2.7926058769226074
Validation loss: 2.665264262947985

Epoch: 6| Step: 2
Training loss: 1.989492416381836
Validation loss: 2.65821688149565

Epoch: 6| Step: 3
Training loss: 3.768723964691162
Validation loss: 2.6571148672411518

Epoch: 6| Step: 4
Training loss: 2.402609348297119
Validation loss: 2.6548870173833703

Epoch: 6| Step: 5
Training loss: 2.4671080112457275
Validation loss: 2.663447013465307

Epoch: 6| Step: 6
Training loss: 3.1802587509155273
Validation loss: 2.657579868070541

Epoch: 6| Step: 7
Training loss: 2.9400148391723633
Validation loss: 2.652095143513013

Epoch: 6| Step: 8
Training loss: 2.5560085773468018
Validation loss: 2.646224847403906

Epoch: 6| Step: 9
Training loss: 2.2331392765045166
Validation loss: 2.644533493185556

Epoch: 6| Step: 10
Training loss: 3.2452845573425293
Validation loss: 2.637593379584692

Epoch: 6| Step: 11
Training loss: 2.345494508743286
Validation loss: 2.635249096860168

Epoch: 6| Step: 12
Training loss: 2.9862875938415527
Validation loss: 2.6366465219887356

Epoch: 6| Step: 13
Training loss: 3.247560977935791
Validation loss: 2.633728616981096

Epoch: 11| Step: 0
Training loss: 3.136974811553955
Validation loss: 2.6329579096968456

Epoch: 6| Step: 1
Training loss: 3.3774800300598145
Validation loss: 2.624471290137178

Epoch: 6| Step: 2
Training loss: 3.0930984020233154
Validation loss: 2.6170152361674974

Epoch: 6| Step: 3
Training loss: 1.9190866947174072
Validation loss: 2.608715905938097

Epoch: 6| Step: 4
Training loss: 2.584097146987915
Validation loss: 2.6118905339189755

Epoch: 6| Step: 5
Training loss: 2.091649293899536
Validation loss: 2.6091523042289158

Epoch: 6| Step: 6
Training loss: 2.770752429962158
Validation loss: 2.6080549968186246

Epoch: 6| Step: 7
Training loss: 3.2104508876800537
Validation loss: 2.604913132165068

Epoch: 6| Step: 8
Training loss: 3.084393262863159
Validation loss: 2.6040449193728867

Epoch: 6| Step: 9
Training loss: 2.841851234436035
Validation loss: 2.602708234581896

Epoch: 6| Step: 10
Training loss: 3.0046353340148926
Validation loss: 2.5943664607181343

Epoch: 6| Step: 11
Training loss: 2.4588677883148193
Validation loss: 2.5945712289502545

Epoch: 6| Step: 12
Training loss: 3.1725893020629883
Validation loss: 2.587850709115305

Epoch: 6| Step: 13
Training loss: 2.380539894104004
Validation loss: 2.5931199596774195

Epoch: 12| Step: 0
Training loss: 2.7322421073913574
Validation loss: 2.5938985168292956

Epoch: 6| Step: 1
Training loss: 2.913389205932617
Validation loss: 2.6101551260999454

Epoch: 6| Step: 2
Training loss: 3.2591841220855713
Validation loss: 2.586049105531426

Epoch: 6| Step: 3
Training loss: 2.5890626907348633
Validation loss: 2.60318346177378

Epoch: 6| Step: 4
Training loss: 2.800915479660034
Validation loss: 2.6452151395941295

Epoch: 6| Step: 5
Training loss: 3.526906728744507
Validation loss: 2.6562195772765786

Epoch: 6| Step: 6
Training loss: 2.8501174449920654
Validation loss: 2.6411219207189416

Epoch: 6| Step: 7
Training loss: 1.8612867593765259
Validation loss: 2.622410879340223

Epoch: 6| Step: 8
Training loss: 2.732168197631836
Validation loss: 2.6260916853463776

Epoch: 6| Step: 9
Training loss: 3.181612491607666
Validation loss: 2.607146140067808

Epoch: 6| Step: 10
Training loss: 2.662208318710327
Validation loss: 2.606102825492941

Epoch: 6| Step: 11
Training loss: 2.898181915283203
Validation loss: 2.6100102650221957

Epoch: 6| Step: 12
Training loss: 2.7972235679626465
Validation loss: 2.609496489647896

Epoch: 6| Step: 13
Training loss: 2.3671464920043945
Validation loss: 2.6088506688353834

Epoch: 13| Step: 0
Training loss: 2.277458667755127
Validation loss: 2.6137187250198854

Epoch: 6| Step: 1
Training loss: 1.4605438709259033
Validation loss: 2.611630109048659

Epoch: 6| Step: 2
Training loss: 3.1939334869384766
Validation loss: 2.6095855159144246

Epoch: 6| Step: 3
Training loss: 3.193936347961426
Validation loss: 2.612225824786771

Epoch: 6| Step: 4
Training loss: 2.975363254547119
Validation loss: 2.608509627721643

Epoch: 6| Step: 5
Training loss: 2.3887503147125244
Validation loss: 2.609447781757642

Epoch: 6| Step: 6
Training loss: 2.23899245262146
Validation loss: 2.626323010331841

Epoch: 6| Step: 7
Training loss: 3.3345224857330322
Validation loss: 2.639226451996834

Epoch: 6| Step: 8
Training loss: 3.6444029808044434
Validation loss: 2.6277544318988757

Epoch: 6| Step: 9
Training loss: 2.5246710777282715
Validation loss: 2.5995074472119732

Epoch: 6| Step: 10
Training loss: 3.1732304096221924
Validation loss: 2.5927135124001452

Epoch: 6| Step: 11
Training loss: 3.3906776905059814
Validation loss: 2.5887327142941055

Epoch: 6| Step: 12
Training loss: 2.6202404499053955
Validation loss: 2.590112288792928

Epoch: 6| Step: 13
Training loss: 2.8065900802612305
Validation loss: 2.59228225164516

Epoch: 14| Step: 0
Training loss: 2.913861036300659
Validation loss: 2.58251158396403

Epoch: 6| Step: 1
Training loss: 3.05783748626709
Validation loss: 2.5758103221975346

Epoch: 6| Step: 2
Training loss: 2.6947426795959473
Validation loss: 2.5675360925735964

Epoch: 6| Step: 3
Training loss: 2.3563592433929443
Validation loss: 2.562902199324741

Epoch: 6| Step: 4
Training loss: 2.008056879043579
Validation loss: 2.560062039283014

Epoch: 6| Step: 5
Training loss: 2.7864890098571777
Validation loss: 2.5620183329428396

Epoch: 6| Step: 6
Training loss: 2.2781362533569336
Validation loss: 2.5741126486050185

Epoch: 6| Step: 7
Training loss: 2.365114212036133
Validation loss: 2.580100349200669

Epoch: 6| Step: 8
Training loss: 3.3775813579559326
Validation loss: 2.577757994333903

Epoch: 6| Step: 9
Training loss: 2.9289731979370117
Validation loss: 2.579596527161137

Epoch: 6| Step: 10
Training loss: 2.725874900817871
Validation loss: 2.558566834336968

Epoch: 6| Step: 11
Training loss: 3.67399263381958
Validation loss: 2.556726058324178

Epoch: 6| Step: 12
Training loss: 2.5367603302001953
Validation loss: 2.550860507513887

Epoch: 6| Step: 13
Training loss: 3.394254446029663
Validation loss: 2.5591702871425177

Epoch: 15| Step: 0
Training loss: 2.3132169246673584
Validation loss: 2.5500774639908985

Epoch: 6| Step: 1
Training loss: 2.9972124099731445
Validation loss: 2.5469176974347842

Epoch: 6| Step: 2
Training loss: 2.758274555206299
Validation loss: 2.541082746239119

Epoch: 6| Step: 3
Training loss: 2.545658826828003
Validation loss: 2.5391356406673307

Epoch: 6| Step: 4
Training loss: 2.7927279472351074
Validation loss: 2.538146080509309

Epoch: 6| Step: 5
Training loss: 3.015637159347534
Validation loss: 2.5425048515360844

Epoch: 6| Step: 6
Training loss: 2.7052319049835205
Validation loss: 2.5420745880373063

Epoch: 6| Step: 7
Training loss: 3.7106595039367676
Validation loss: 2.5430150954954085

Epoch: 6| Step: 8
Training loss: 2.2742457389831543
Validation loss: 2.540333568408925

Epoch: 6| Step: 9
Training loss: 3.2455437183380127
Validation loss: 2.531414101200719

Epoch: 6| Step: 10
Training loss: 2.3522112369537354
Validation loss: 2.5325395881488757

Epoch: 6| Step: 11
Training loss: 1.8000094890594482
Validation loss: 2.5330642705322592

Epoch: 6| Step: 12
Training loss: 2.8265764713287354
Validation loss: 2.539201703122867

Epoch: 6| Step: 13
Training loss: 3.6804449558258057
Validation loss: 2.554465091356667

Epoch: 16| Step: 0
Training loss: 2.7414910793304443
Validation loss: 2.5725028412316435

Epoch: 6| Step: 1
Training loss: 2.0835089683532715
Validation loss: 2.5392862776274323

Epoch: 6| Step: 2
Training loss: 2.411663055419922
Validation loss: 2.5331560463033695

Epoch: 6| Step: 3
Training loss: 2.2783827781677246
Validation loss: 2.5288748843695528

Epoch: 6| Step: 4
Training loss: 3.352163553237915
Validation loss: 2.539597336963941

Epoch: 6| Step: 5
Training loss: 3.3003084659576416
Validation loss: 2.5388893337659937

Epoch: 6| Step: 6
Training loss: 3.6500585079193115
Validation loss: 2.545472311717208

Epoch: 6| Step: 7
Training loss: 2.8383498191833496
Validation loss: 2.547555149242442

Epoch: 6| Step: 8
Training loss: 2.712366819381714
Validation loss: 2.529123665184103

Epoch: 6| Step: 9
Training loss: 2.81644606590271
Validation loss: 2.523244562969413

Epoch: 6| Step: 10
Training loss: 2.6552867889404297
Validation loss: 2.5202157881952103

Epoch: 6| Step: 11
Training loss: 2.955641746520996
Validation loss: 2.5185963979331394

Epoch: 6| Step: 12
Training loss: 1.9646100997924805
Validation loss: 2.5222562231043333

Epoch: 6| Step: 13
Training loss: 2.9112730026245117
Validation loss: 2.5393313874480543

Epoch: 17| Step: 0
Training loss: 2.837393283843994
Validation loss: 2.5440343169755835

Epoch: 6| Step: 1
Training loss: 2.783017158508301
Validation loss: 2.547551690891225

Epoch: 6| Step: 2
Training loss: 2.3097047805786133
Validation loss: 2.5427272806885424

Epoch: 6| Step: 3
Training loss: 2.1502673625946045
Validation loss: 2.5421494771075506

Epoch: 6| Step: 4
Training loss: 3.2231369018554688
Validation loss: 2.5323703058304323

Epoch: 6| Step: 5
Training loss: 2.3595356941223145
Validation loss: 2.51772294762314

Epoch: 6| Step: 6
Training loss: 2.4336416721343994
Validation loss: 2.5185869611719602

Epoch: 6| Step: 7
Training loss: 2.713618278503418
Validation loss: 2.5156526719370196

Epoch: 6| Step: 8
Training loss: 2.5735068321228027
Validation loss: 2.517701315623458

Epoch: 6| Step: 9
Training loss: 3.162949562072754
Validation loss: 2.5639718937617477

Epoch: 6| Step: 10
Training loss: 3.4062461853027344
Validation loss: 2.6000356238375426

Epoch: 6| Step: 11
Training loss: 3.4856173992156982
Validation loss: 2.6070768115341023

Epoch: 6| Step: 12
Training loss: 2.4657342433929443
Validation loss: 2.5876907892124628

Epoch: 6| Step: 13
Training loss: 2.768951654434204
Validation loss: 2.5816878093186246

Epoch: 18| Step: 0
Training loss: 2.38895845413208
Validation loss: 2.5784469522455686

Epoch: 6| Step: 1
Training loss: 2.794656753540039
Validation loss: 2.5806525497026342

Epoch: 6| Step: 2
Training loss: 2.1383209228515625
Validation loss: 2.572157882875012

Epoch: 6| Step: 3
Training loss: 2.39162015914917
Validation loss: 2.5751293038809173

Epoch: 6| Step: 4
Training loss: 2.1413445472717285
Validation loss: 2.5864288063459497

Epoch: 6| Step: 5
Training loss: 2.661170721054077
Validation loss: 2.590721822554065

Epoch: 6| Step: 6
Training loss: 3.2857987880706787
Validation loss: 2.5840202403324906

Epoch: 6| Step: 7
Training loss: 3.867372989654541
Validation loss: 2.5599795003091135

Epoch: 6| Step: 8
Training loss: 1.8041255474090576
Validation loss: 2.5554983974784933

Epoch: 6| Step: 9
Training loss: 2.674880027770996
Validation loss: 2.5479971080697994

Epoch: 6| Step: 10
Training loss: 3.1565380096435547
Validation loss: 2.5477479606546383

Epoch: 6| Step: 11
Training loss: 3.5075864791870117
Validation loss: 2.541338982120637

Epoch: 6| Step: 12
Training loss: 2.960526466369629
Validation loss: 2.5376364620782996

Epoch: 6| Step: 13
Training loss: 2.944542407989502
Validation loss: 2.537631369406177

Epoch: 19| Step: 0
Training loss: 3.1908743381500244
Validation loss: 2.5356378196388163

Epoch: 6| Step: 1
Training loss: 2.8322176933288574
Validation loss: 2.5345693557493147

Epoch: 6| Step: 2
Training loss: 2.8564252853393555
Validation loss: 2.5337481960173576

Epoch: 6| Step: 3
Training loss: 2.6674232482910156
Validation loss: 2.5281008135887886

Epoch: 6| Step: 4
Training loss: 2.9531664848327637
Validation loss: 2.5272983863789547

Epoch: 6| Step: 5
Training loss: 2.868455410003662
Validation loss: 2.527754009410899

Epoch: 6| Step: 6
Training loss: 3.3720755577087402
Validation loss: 2.5276538223348637

Epoch: 6| Step: 7
Training loss: 2.5042014122009277
Validation loss: 2.5252389138744724

Epoch: 6| Step: 8
Training loss: 2.4949560165405273
Validation loss: 2.5247510299887708

Epoch: 6| Step: 9
Training loss: 1.9494166374206543
Validation loss: 2.5301024119059243

Epoch: 6| Step: 10
Training loss: 2.643890142440796
Validation loss: 2.546729480066607

Epoch: 6| Step: 11
Training loss: 2.8432793617248535
Validation loss: 2.5413432326368106

Epoch: 6| Step: 12
Training loss: 2.7835230827331543
Validation loss: 2.5340252589153986

Epoch: 6| Step: 13
Training loss: 2.1206090450286865
Validation loss: 2.5231867092911915

Epoch: 20| Step: 0
Training loss: 2.469088315963745
Validation loss: 2.518332335256761

Epoch: 6| Step: 1
Training loss: 2.957022190093994
Validation loss: 2.516557175626037

Epoch: 6| Step: 2
Training loss: 2.3655176162719727
Validation loss: 2.51538654809357

Epoch: 6| Step: 3
Training loss: 2.845335006713867
Validation loss: 2.511769397284395

Epoch: 6| Step: 4
Training loss: 3.0123119354248047
Validation loss: 2.5324300873664116

Epoch: 6| Step: 5
Training loss: 3.587148666381836
Validation loss: 2.5489785953234603

Epoch: 6| Step: 6
Training loss: 2.323270559310913
Validation loss: 2.5693439847679547

Epoch: 6| Step: 7
Training loss: 2.115396738052368
Validation loss: 2.5557723993896158

Epoch: 6| Step: 8
Training loss: 2.6987738609313965
Validation loss: 2.5458426167888026

Epoch: 6| Step: 9
Training loss: 3.1453933715820312
Validation loss: 2.5206940609921693

Epoch: 6| Step: 10
Training loss: 2.4611663818359375
Validation loss: 2.5067551341108096

Epoch: 6| Step: 11
Training loss: 2.829810380935669
Validation loss: 2.5102428749043453

Epoch: 6| Step: 12
Training loss: 2.7094292640686035
Validation loss: 2.524876591979816

Epoch: 6| Step: 13
Training loss: 2.833604574203491
Validation loss: 2.5211872439230643

Epoch: 21| Step: 0
Training loss: 2.9598751068115234
Validation loss: 2.5297524659864363

Epoch: 6| Step: 1
Training loss: 3.0074996948242188
Validation loss: 2.5305611600158033

Epoch: 6| Step: 2
Training loss: 2.2456107139587402
Validation loss: 2.515375047601679

Epoch: 6| Step: 3
Training loss: 2.4854846000671387
Validation loss: 2.5156874682313655

Epoch: 6| Step: 4
Training loss: 2.1609325408935547
Validation loss: 2.503501484470983

Epoch: 6| Step: 5
Training loss: 3.1987321376800537
Validation loss: 2.504180844112109

Epoch: 6| Step: 6
Training loss: 3.3130674362182617
Validation loss: 2.51709182031693

Epoch: 6| Step: 7
Training loss: 2.637178421020508
Validation loss: 2.5435548469584477

Epoch: 6| Step: 8
Training loss: 3.6876726150512695
Validation loss: 2.5632248309350785

Epoch: 6| Step: 9
Training loss: 2.346045970916748
Validation loss: 2.572790650911229

Epoch: 6| Step: 10
Training loss: 2.4828310012817383
Validation loss: 2.5416096359170894

Epoch: 6| Step: 11
Training loss: 2.8065309524536133
Validation loss: 2.50907487510353

Epoch: 6| Step: 12
Training loss: 2.6933226585388184
Validation loss: 2.498746052865059

Epoch: 6| Step: 13
Training loss: 1.95943021774292
Validation loss: 2.4897408382866972

Epoch: 22| Step: 0
Training loss: 2.497596502304077
Validation loss: 2.4928142332261607

Epoch: 6| Step: 1
Training loss: 2.7747652530670166
Validation loss: 2.529604499058057

Epoch: 6| Step: 2
Training loss: 3.0172781944274902
Validation loss: 2.552951100052044

Epoch: 6| Step: 3
Training loss: 3.4709129333496094
Validation loss: 2.5693400470159387

Epoch: 6| Step: 4
Training loss: 2.2620251178741455
Validation loss: 2.570262908935547

Epoch: 6| Step: 5
Training loss: 3.2592968940734863
Validation loss: 2.5861821430985645

Epoch: 6| Step: 6
Training loss: 2.4772167205810547
Validation loss: 2.5542642660038446

Epoch: 6| Step: 7
Training loss: 2.4913086891174316
Validation loss: 2.537692969845187

Epoch: 6| Step: 8
Training loss: 3.0413758754730225
Validation loss: 2.5414363902102233

Epoch: 6| Step: 9
Training loss: 2.866034984588623
Validation loss: 2.5475805933757494

Epoch: 6| Step: 10
Training loss: 2.8320517539978027
Validation loss: 2.554723854987852

Epoch: 6| Step: 11
Training loss: 2.339451313018799
Validation loss: 2.5650430392193537

Epoch: 6| Step: 12
Training loss: 2.2643191814422607
Validation loss: 2.5953365038799983

Epoch: 6| Step: 13
Training loss: 2.9364941120147705
Validation loss: 2.64202299938407

Epoch: 23| Step: 0
Training loss: 2.9707679748535156
Validation loss: 2.5447605143311205

Epoch: 6| Step: 1
Training loss: 2.3860177993774414
Validation loss: 2.537022962365099

Epoch: 6| Step: 2
Training loss: 2.3532817363739014
Validation loss: 2.548261493764898

Epoch: 6| Step: 3
Training loss: 2.654256582260132
Validation loss: 2.620360066813807

Epoch: 6| Step: 4
Training loss: 3.194638252258301
Validation loss: 2.6683199841489076

Epoch: 6| Step: 5
Training loss: 3.525196075439453
Validation loss: 2.641834864052393

Epoch: 6| Step: 6
Training loss: 2.616886854171753
Validation loss: 2.5370364086602324

Epoch: 6| Step: 7
Training loss: 3.1325011253356934
Validation loss: 2.44370517423076

Epoch: 6| Step: 8
Training loss: 2.2985315322875977
Validation loss: 2.4289858187398603

Epoch: 6| Step: 9
Training loss: 2.975419759750366
Validation loss: 2.4170941537426365

Epoch: 6| Step: 10
Training loss: 2.2974624633789062
Validation loss: 2.4155618042074223

Epoch: 6| Step: 11
Training loss: 2.1273128986358643
Validation loss: 2.421854808766355

Epoch: 6| Step: 12
Training loss: 2.301096200942993
Validation loss: 2.460837246269308

Epoch: 6| Step: 13
Training loss: 3.7620229721069336
Validation loss: 2.516944113598075

Epoch: 24| Step: 0
Training loss: 2.8174514770507812
Validation loss: 2.571656391184817

Epoch: 6| Step: 1
Training loss: 2.440054178237915
Validation loss: 2.601640098838396

Epoch: 6| Step: 2
Training loss: 2.041395902633667
Validation loss: 2.6399415641702633

Epoch: 6| Step: 3
Training loss: 2.825087308883667
Validation loss: 2.6764018151067916

Epoch: 6| Step: 4
Training loss: 2.9856719970703125
Validation loss: 2.668282811359693

Epoch: 6| Step: 5
Training loss: 2.7189085483551025
Validation loss: 2.5985581080118814

Epoch: 6| Step: 6
Training loss: 2.691474676132202
Validation loss: 2.508059961821443

Epoch: 6| Step: 7
Training loss: 2.3183352947235107
Validation loss: 2.4345613551396195

Epoch: 6| Step: 8
Training loss: 2.4358954429626465
Validation loss: 2.4389128710633967

Epoch: 6| Step: 9
Training loss: 2.849180221557617
Validation loss: 2.4654695282700243

Epoch: 6| Step: 10
Training loss: 2.7326161861419678
Validation loss: 2.4865007246694257

Epoch: 6| Step: 11
Training loss: 2.7722039222717285
Validation loss: 2.4896416894851194

Epoch: 6| Step: 12
Training loss: 3.643604040145874
Validation loss: 2.5007048755563717

Epoch: 6| Step: 13
Training loss: 3.1721413135528564
Validation loss: 2.5047803181473927

Epoch: 25| Step: 0
Training loss: 2.6436290740966797
Validation loss: 2.497393028710478

Epoch: 6| Step: 1
Training loss: 1.9116473197937012
Validation loss: 2.4943355975612516

Epoch: 6| Step: 2
Training loss: 2.666316509246826
Validation loss: 2.4858219585111065

Epoch: 6| Step: 3
Training loss: 2.701694965362549
Validation loss: 2.4804349176345335

Epoch: 6| Step: 4
Training loss: 2.8160223960876465
Validation loss: 2.4908898133103565

Epoch: 6| Step: 5
Training loss: 2.6888062953948975
Validation loss: 2.4971620857074694

Epoch: 6| Step: 6
Training loss: 2.7232561111450195
Validation loss: 2.5477217423018588

Epoch: 6| Step: 7
Training loss: 2.184384822845459
Validation loss: 2.546627729169784

Epoch: 6| Step: 8
Training loss: 3.2727842330932617
Validation loss: 2.5002855793122323

Epoch: 6| Step: 9
Training loss: 2.1552348136901855
Validation loss: 2.4506805327630814

Epoch: 6| Step: 10
Training loss: 3.65850830078125
Validation loss: 2.4150767198172947

Epoch: 6| Step: 11
Training loss: 2.722888708114624
Validation loss: 2.3948721078134354

Epoch: 6| Step: 12
Training loss: 3.3347527980804443
Validation loss: 2.3932341478204213

Epoch: 6| Step: 13
Training loss: 2.545382499694824
Validation loss: 2.3978835792951685

Epoch: 26| Step: 0
Training loss: 3.0402321815490723
Validation loss: 2.396577371064053

Epoch: 6| Step: 1
Training loss: 2.728855609893799
Validation loss: 2.4093132916317193

Epoch: 6| Step: 2
Training loss: 2.910353183746338
Validation loss: 2.4055561250255955

Epoch: 6| Step: 3
Training loss: 2.344931125640869
Validation loss: 2.399238327498077

Epoch: 6| Step: 4
Training loss: 1.7104243040084839
Validation loss: 2.4051908959624586

Epoch: 6| Step: 5
Training loss: 2.4537148475646973
Validation loss: 2.408784815060195

Epoch: 6| Step: 6
Training loss: 3.43916392326355
Validation loss: 2.4087874427918465

Epoch: 6| Step: 7
Training loss: 2.6420974731445312
Validation loss: 2.400699154023201

Epoch: 6| Step: 8
Training loss: 2.570314884185791
Validation loss: 2.3896674443316717

Epoch: 6| Step: 9
Training loss: 2.04593563079834
Validation loss: 2.3826142036786644

Epoch: 6| Step: 10
Training loss: 3.1682627201080322
Validation loss: 2.3800488800130863

Epoch: 6| Step: 11
Training loss: 3.220505952835083
Validation loss: 2.3686615510653426

Epoch: 6| Step: 12
Training loss: 2.4214303493499756
Validation loss: 2.3682150430576776

Epoch: 6| Step: 13
Training loss: 2.4407541751861572
Validation loss: 2.3670746331573813

Epoch: 27| Step: 0
Training loss: 2.7148451805114746
Validation loss: 2.366229631567514

Epoch: 6| Step: 1
Training loss: 2.106210708618164
Validation loss: 2.370816256410332

Epoch: 6| Step: 2
Training loss: 2.6877222061157227
Validation loss: 2.384905666433355

Epoch: 6| Step: 3
Training loss: 2.042205810546875
Validation loss: 2.387661603189284

Epoch: 6| Step: 4
Training loss: 2.4080934524536133
Validation loss: 2.387025028146723

Epoch: 6| Step: 5
Training loss: 3.0214905738830566
Validation loss: 2.3939915651916177

Epoch: 6| Step: 6
Training loss: 2.7465949058532715
Validation loss: 2.3690423734726442

Epoch: 6| Step: 7
Training loss: 2.7607641220092773
Validation loss: 2.355926339344312

Epoch: 6| Step: 8
Training loss: 2.7011592388153076
Validation loss: 2.3454354732267317

Epoch: 6| Step: 9
Training loss: 2.6874282360076904
Validation loss: 2.3508200235264276

Epoch: 6| Step: 10
Training loss: 3.0832061767578125
Validation loss: 2.345972307266728

Epoch: 6| Step: 11
Training loss: 2.740187883377075
Validation loss: 2.342503575868504

Epoch: 6| Step: 12
Training loss: 2.447836399078369
Validation loss: 2.349046935317337

Epoch: 6| Step: 13
Training loss: 2.7793760299682617
Validation loss: 2.363138762853479

Epoch: 28| Step: 0
Training loss: 2.634467124938965
Validation loss: 2.3705204186900968

Epoch: 6| Step: 1
Training loss: 2.3601737022399902
Validation loss: 2.380431990469656

Epoch: 6| Step: 2
Training loss: 2.4260897636413574
Validation loss: 2.3824221754586823

Epoch: 6| Step: 3
Training loss: 2.249140739440918
Validation loss: 2.3890737769424275

Epoch: 6| Step: 4
Training loss: 2.6772639751434326
Validation loss: 2.3779567877451577

Epoch: 6| Step: 5
Training loss: 2.2102112770080566
Validation loss: 2.3751381571574877

Epoch: 6| Step: 6
Training loss: 2.679372787475586
Validation loss: 2.375102548189061

Epoch: 6| Step: 7
Training loss: 3.326523542404175
Validation loss: 2.3727848350360827

Epoch: 6| Step: 8
Training loss: 3.0271801948547363
Validation loss: 2.3647360596605527

Epoch: 6| Step: 9
Training loss: 2.9527249336242676
Validation loss: 2.3613307604225735

Epoch: 6| Step: 10
Training loss: 2.514676332473755
Validation loss: 2.3534199832588114

Epoch: 6| Step: 11
Training loss: 1.88971745967865
Validation loss: 2.348260687243554

Epoch: 6| Step: 12
Training loss: 2.9352645874023438
Validation loss: 2.347052699776106

Epoch: 6| Step: 13
Training loss: 2.959803581237793
Validation loss: 2.3435254917349866

Epoch: 29| Step: 0
Training loss: 1.5947297811508179
Validation loss: 2.3431245639760006

Epoch: 6| Step: 1
Training loss: 2.733767509460449
Validation loss: 2.3490715539583595

Epoch: 6| Step: 2
Training loss: 2.233870029449463
Validation loss: 2.3525984979444936

Epoch: 6| Step: 3
Training loss: 2.712124824523926
Validation loss: 2.367080601312781

Epoch: 6| Step: 4
Training loss: 3.118814468383789
Validation loss: 2.3829350958588305

Epoch: 6| Step: 5
Training loss: 3.2736167907714844
Validation loss: 2.402256770800519

Epoch: 6| Step: 6
Training loss: 2.9965357780456543
Validation loss: 2.4176144471732517

Epoch: 6| Step: 7
Training loss: 2.47428297996521
Validation loss: 2.391437430535593

Epoch: 6| Step: 8
Training loss: 2.675741672515869
Validation loss: 2.3723721145301737

Epoch: 6| Step: 9
Training loss: 2.7663397789001465
Validation loss: 2.3570783497184835

Epoch: 6| Step: 10
Training loss: 2.354114532470703
Validation loss: 2.3432238332686888

Epoch: 6| Step: 11
Training loss: 2.809358835220337
Validation loss: 2.3479717213620424

Epoch: 6| Step: 12
Training loss: 2.2224514484405518
Validation loss: 2.3488235729996876

Epoch: 6| Step: 13
Training loss: 2.855358362197876
Validation loss: 2.356382780177619

Epoch: 30| Step: 0
Training loss: 3.2613160610198975
Validation loss: 2.3597027230006393

Epoch: 6| Step: 1
Training loss: 2.1023294925689697
Validation loss: 2.3579667152897006

Epoch: 6| Step: 2
Training loss: 2.43361234664917
Validation loss: 2.3555480690412622

Epoch: 6| Step: 3
Training loss: 2.508467674255371
Validation loss: 2.343850240912489

Epoch: 6| Step: 4
Training loss: 2.72755765914917
Validation loss: 2.3385930138249553

Epoch: 6| Step: 5
Training loss: 2.1915640830993652
Validation loss: 2.3342218219593005

Epoch: 6| Step: 6
Training loss: 1.7300318479537964
Validation loss: 2.333694742571923

Epoch: 6| Step: 7
Training loss: 3.4970035552978516
Validation loss: 2.3362447484847038

Epoch: 6| Step: 8
Training loss: 2.9461324214935303
Validation loss: 2.3378630376631215

Epoch: 6| Step: 9
Training loss: 2.871016502380371
Validation loss: 2.34222444411247

Epoch: 6| Step: 10
Training loss: 2.4395813941955566
Validation loss: 2.3615297220086537

Epoch: 6| Step: 11
Training loss: 2.4755136966705322
Validation loss: 2.3968535084878244

Epoch: 6| Step: 12
Training loss: 2.9709465503692627
Validation loss: 2.411277440286452

Epoch: 6| Step: 13
Training loss: 2.69425368309021
Validation loss: 2.427129381446428

Epoch: 31| Step: 0
Training loss: 2.790576934814453
Validation loss: 2.410487913316296

Epoch: 6| Step: 1
Training loss: 3.867748260498047
Validation loss: 2.4223702851162163

Epoch: 6| Step: 2
Training loss: 2.802117347717285
Validation loss: 2.3869171296396563

Epoch: 6| Step: 3
Training loss: 2.819453001022339
Validation loss: 2.358601898275396

Epoch: 6| Step: 4
Training loss: 2.4991722106933594
Validation loss: 2.3472606699953795

Epoch: 6| Step: 5
Training loss: 2.166577100753784
Validation loss: 2.3308983618213284

Epoch: 6| Step: 6
Training loss: 2.626725912094116
Validation loss: 2.3231653974902247

Epoch: 6| Step: 7
Training loss: 1.9585424661636353
Validation loss: 2.3202246081444526

Epoch: 6| Step: 8
Training loss: 2.7791385650634766
Validation loss: 2.317936102549235

Epoch: 6| Step: 9
Training loss: 2.3644607067108154
Validation loss: 2.3209968100311937

Epoch: 6| Step: 10
Training loss: 2.332869529724121
Validation loss: 2.3231316125521095

Epoch: 6| Step: 11
Training loss: 1.8824108839035034
Validation loss: 2.3218929844517864

Epoch: 6| Step: 12
Training loss: 2.8437583446502686
Validation loss: 2.3270782962922127

Epoch: 6| Step: 13
Training loss: 3.2062270641326904
Validation loss: 2.344462189623105

Epoch: 32| Step: 0
Training loss: 2.6935319900512695
Validation loss: 2.37664734419956

Epoch: 6| Step: 1
Training loss: 2.609017848968506
Validation loss: 2.389678701277702

Epoch: 6| Step: 2
Training loss: 2.5922815799713135
Validation loss: 2.4110837444182365

Epoch: 6| Step: 3
Training loss: 2.432678461074829
Validation loss: 2.383882984038322

Epoch: 6| Step: 4
Training loss: 2.9009623527526855
Validation loss: 2.3779541036134124

Epoch: 6| Step: 5
Training loss: 2.776620388031006
Validation loss: 2.3693570090878393

Epoch: 6| Step: 6
Training loss: 2.953070878982544
Validation loss: 2.3658388019889913

Epoch: 6| Step: 7
Training loss: 2.8747923374176025
Validation loss: 2.3472962405091975

Epoch: 6| Step: 8
Training loss: 2.434812545776367
Validation loss: 2.3323169344214985

Epoch: 6| Step: 9
Training loss: 3.0154993534088135
Validation loss: 2.3300883795625422

Epoch: 6| Step: 10
Training loss: 2.2608532905578613
Validation loss: 2.319394819198116

Epoch: 6| Step: 11
Training loss: 1.922785997390747
Validation loss: 2.316185930723785

Epoch: 6| Step: 12
Training loss: 2.341309070587158
Validation loss: 2.3138620545787196

Epoch: 6| Step: 13
Training loss: 2.9002609252929688
Validation loss: 2.3114927596943353

Epoch: 33| Step: 0
Training loss: 1.9128797054290771
Validation loss: 2.308480985703007

Epoch: 6| Step: 1
Training loss: 2.8626904487609863
Validation loss: 2.3089101019726006

Epoch: 6| Step: 2
Training loss: 3.143655300140381
Validation loss: 2.310841393727128

Epoch: 6| Step: 3
Training loss: 2.67466402053833
Validation loss: 2.308229108010569

Epoch: 6| Step: 4
Training loss: 2.4914255142211914
Validation loss: 2.307702320878224

Epoch: 6| Step: 5
Training loss: 2.694824457168579
Validation loss: 2.306721436080112

Epoch: 6| Step: 6
Training loss: 2.104689836502075
Validation loss: 2.315115108284899

Epoch: 6| Step: 7
Training loss: 2.7274937629699707
Validation loss: 2.3204377017995363

Epoch: 6| Step: 8
Training loss: 2.8373584747314453
Validation loss: 2.3106621362829722

Epoch: 6| Step: 9
Training loss: 2.385819435119629
Validation loss: 2.3098764701556136

Epoch: 6| Step: 10
Training loss: 3.1514692306518555
Validation loss: 2.30388537017248

Epoch: 6| Step: 11
Training loss: 2.564023017883301
Validation loss: 2.3016776782210155

Epoch: 6| Step: 12
Training loss: 2.260704755783081
Validation loss: 2.301170595230595

Epoch: 6| Step: 13
Training loss: 2.5027530193328857
Validation loss: 2.299449728381249

Epoch: 34| Step: 0
Training loss: 2.5236568450927734
Validation loss: 2.3122880138376707

Epoch: 6| Step: 1
Training loss: 2.2853174209594727
Validation loss: 2.3256678427419355

Epoch: 6| Step: 2
Training loss: 2.573838710784912
Validation loss: 2.342785950629942

Epoch: 6| Step: 3
Training loss: 2.7528295516967773
Validation loss: 2.361897296802972

Epoch: 6| Step: 4
Training loss: 2.651658773422241
Validation loss: 2.3789295201660483

Epoch: 6| Step: 5
Training loss: 2.447432518005371
Validation loss: 2.360107224474671

Epoch: 6| Step: 6
Training loss: 3.3223929405212402
Validation loss: 2.3423431227284093

Epoch: 6| Step: 7
Training loss: 2.5857229232788086
Validation loss: 2.317892764204292

Epoch: 6| Step: 8
Training loss: 2.4553985595703125
Validation loss: 2.3048088101930517

Epoch: 6| Step: 9
Training loss: 2.010006904602051
Validation loss: 2.288819697595412

Epoch: 6| Step: 10
Training loss: 2.6336915493011475
Validation loss: 2.2873676015484716

Epoch: 6| Step: 11
Training loss: 3.0039520263671875
Validation loss: 2.2901713540477138

Epoch: 6| Step: 12
Training loss: 2.3468222618103027
Validation loss: 2.297471882194601

Epoch: 6| Step: 13
Training loss: 3.037452220916748
Validation loss: 2.2952026269769155

Epoch: 35| Step: 0
Training loss: 3.0654420852661133
Validation loss: 2.2929359302725842

Epoch: 6| Step: 1
Training loss: 3.4033620357513428
Validation loss: 2.291852007630051

Epoch: 6| Step: 2
Training loss: 2.8754122257232666
Validation loss: 2.2882683994949504

Epoch: 6| Step: 3
Training loss: 2.10945200920105
Validation loss: 2.291798025049189

Epoch: 6| Step: 4
Training loss: 2.3579888343811035
Validation loss: 2.2873661082278014

Epoch: 6| Step: 5
Training loss: 3.1432690620422363
Validation loss: 2.28618594138853

Epoch: 6| Step: 6
Training loss: 2.4560539722442627
Validation loss: 2.2805180011257047

Epoch: 6| Step: 7
Training loss: 2.4812817573547363
Validation loss: 2.279790952641477

Epoch: 6| Step: 8
Training loss: 1.8815633058547974
Validation loss: 2.2768567531339583

Epoch: 6| Step: 9
Training loss: 2.610992908477783
Validation loss: 2.2764648416990876

Epoch: 6| Step: 10
Training loss: 2.5288162231445312
Validation loss: 2.280474308998354

Epoch: 6| Step: 11
Training loss: 2.4278831481933594
Validation loss: 2.290218343016922

Epoch: 6| Step: 12
Training loss: 2.8973262310028076
Validation loss: 2.2989226207938245

Epoch: 6| Step: 13
Training loss: 1.3107939958572388
Validation loss: 2.309041112981817

Epoch: 36| Step: 0
Training loss: 2.5757265090942383
Validation loss: 2.339571342673353

Epoch: 6| Step: 1
Training loss: 3.2232861518859863
Validation loss: 2.3710808600148847

Epoch: 6| Step: 2
Training loss: 2.80686354637146
Validation loss: 2.3777226222458707

Epoch: 6| Step: 3
Training loss: 3.2569313049316406
Validation loss: 2.379980851245183

Epoch: 6| Step: 4
Training loss: 2.444204568862915
Validation loss: 2.3478477078099407

Epoch: 6| Step: 5
Training loss: 2.8739287853240967
Validation loss: 2.313492303253502

Epoch: 6| Step: 6
Training loss: 2.936567783355713
Validation loss: 2.304451198988063

Epoch: 6| Step: 7
Training loss: 1.4041296243667603
Validation loss: 2.2961185209212767

Epoch: 6| Step: 8
Training loss: 2.070561408996582
Validation loss: 2.2857101425047843

Epoch: 6| Step: 9
Training loss: 3.287752151489258
Validation loss: 2.277683024765343

Epoch: 6| Step: 10
Training loss: 2.3629302978515625
Validation loss: 2.2727298454571794

Epoch: 6| Step: 11
Training loss: 1.864094853401184
Validation loss: 2.271053591082173

Epoch: 6| Step: 12
Training loss: 2.2822494506835938
Validation loss: 2.2691962129326275

Epoch: 6| Step: 13
Training loss: 3.2347168922424316
Validation loss: 2.2741396298972507

Epoch: 37| Step: 0
Training loss: 1.7311104536056519
Validation loss: 2.270257091009489

Epoch: 6| Step: 1
Training loss: 2.5594327449798584
Validation loss: 2.2749809654810096

Epoch: 6| Step: 2
Training loss: 2.660811424255371
Validation loss: 2.275305007093696

Epoch: 6| Step: 3
Training loss: 2.8633594512939453
Validation loss: 2.279344251078944

Epoch: 6| Step: 4
Training loss: 2.5738096237182617
Validation loss: 2.281203628868185

Epoch: 6| Step: 5
Training loss: 2.8246026039123535
Validation loss: 2.285182665753108

Epoch: 6| Step: 6
Training loss: 2.8060765266418457
Validation loss: 2.272407131810342

Epoch: 6| Step: 7
Training loss: 2.4917075634002686
Validation loss: 2.2761934393195697

Epoch: 6| Step: 8
Training loss: 2.8105783462524414
Validation loss: 2.290722559857112

Epoch: 6| Step: 9
Training loss: 2.3594751358032227
Validation loss: 2.28223584031546

Epoch: 6| Step: 10
Training loss: 2.3635714054107666
Validation loss: 2.2996626489905903

Epoch: 6| Step: 11
Training loss: 3.419356346130371
Validation loss: 2.31501176023996

Epoch: 6| Step: 12
Training loss: 2.058628559112549
Validation loss: 2.308300041383313

Epoch: 6| Step: 13
Training loss: 2.1279044151306152
Validation loss: 2.317128539085388

Epoch: 38| Step: 0
Training loss: 3.1325325965881348
Validation loss: 2.323522062711818

Epoch: 6| Step: 1
Training loss: 2.847050189971924
Validation loss: 2.316999384151992

Epoch: 6| Step: 2
Training loss: 2.36441707611084
Validation loss: 2.3141283463406306

Epoch: 6| Step: 3
Training loss: 1.7343412637710571
Validation loss: 2.3055932547456477

Epoch: 6| Step: 4
Training loss: 2.5345935821533203
Validation loss: 2.2896570928635134

Epoch: 6| Step: 5
Training loss: 2.237079620361328
Validation loss: 2.2688844524404055

Epoch: 6| Step: 6
Training loss: 2.4272584915161133
Validation loss: 2.265347517946715

Epoch: 6| Step: 7
Training loss: 2.4663023948669434
Validation loss: 2.2614745260566793

Epoch: 6| Step: 8
Training loss: 2.2413413524627686
Validation loss: 2.269766740901496

Epoch: 6| Step: 9
Training loss: 2.7478556632995605
Validation loss: 2.27472181986737

Epoch: 6| Step: 10
Training loss: 2.845654010772705
Validation loss: 2.276001684127315

Epoch: 6| Step: 11
Training loss: 2.7236742973327637
Validation loss: 2.2877377489561677

Epoch: 6| Step: 12
Training loss: 2.8542096614837646
Validation loss: 2.3068516280061457

Epoch: 6| Step: 13
Training loss: 2.9046003818511963
Validation loss: 2.30479028660764

Epoch: 39| Step: 0
Training loss: 2.0663743019104004
Validation loss: 2.3029513205251386

Epoch: 6| Step: 1
Training loss: 2.2184834480285645
Validation loss: 2.284370694109189

Epoch: 6| Step: 2
Training loss: 2.5653371810913086
Validation loss: 2.274214006239368

Epoch: 6| Step: 3
Training loss: 3.1285386085510254
Validation loss: 2.2600013568837154

Epoch: 6| Step: 4
Training loss: 2.0381999015808105
Validation loss: 2.247585806795346

Epoch: 6| Step: 5
Training loss: 2.5224194526672363
Validation loss: 2.2446622989510976

Epoch: 6| Step: 6
Training loss: 3.182223320007324
Validation loss: 2.251531400988179

Epoch: 6| Step: 7
Training loss: 2.3871078491210938
Validation loss: 2.2526574006644626

Epoch: 6| Step: 8
Training loss: 2.282174587249756
Validation loss: 2.2572948163555515

Epoch: 6| Step: 9
Training loss: 2.633533239364624
Validation loss: 2.2565691445463445

Epoch: 6| Step: 10
Training loss: 3.1070334911346436
Validation loss: 2.254202481239073

Epoch: 6| Step: 11
Training loss: 3.256425380706787
Validation loss: 2.25325676959048

Epoch: 6| Step: 12
Training loss: 2.197415590286255
Validation loss: 2.256438475783153

Epoch: 6| Step: 13
Training loss: 2.0951590538024902
Validation loss: 2.265559947618874

Epoch: 40| Step: 0
Training loss: 1.8601709604263306
Validation loss: 2.2754942127453384

Epoch: 6| Step: 1
Training loss: 2.9734067916870117
Validation loss: 2.2898682573790192

Epoch: 6| Step: 2
Training loss: 2.686707019805908
Validation loss: 2.3184387478777158

Epoch: 6| Step: 3
Training loss: 2.873772621154785
Validation loss: 2.348705945476409

Epoch: 6| Step: 4
Training loss: 2.2095844745635986
Validation loss: 2.401792759536415

Epoch: 6| Step: 5
Training loss: 1.9451591968536377
Validation loss: 2.4363545499822146

Epoch: 6| Step: 6
Training loss: 3.5409278869628906
Validation loss: 2.4496118227640786

Epoch: 6| Step: 7
Training loss: 3.1394999027252197
Validation loss: 2.3866230800587642

Epoch: 6| Step: 8
Training loss: 2.6159563064575195
Validation loss: 2.321721012874316

Epoch: 6| Step: 9
Training loss: 3.006516933441162
Validation loss: 2.2695284889590357

Epoch: 6| Step: 10
Training loss: 1.9565761089324951
Validation loss: 2.251705587551158

Epoch: 6| Step: 11
Training loss: 2.71323823928833
Validation loss: 2.241628885269165

Epoch: 6| Step: 12
Training loss: 2.400891065597534
Validation loss: 2.249674750912574

Epoch: 6| Step: 13
Training loss: 2.0908203125
Validation loss: 2.250284864056495

Epoch: 41| Step: 0
Training loss: 2.5545735359191895
Validation loss: 2.2511008503616496

Epoch: 6| Step: 1
Training loss: 1.7587968111038208
Validation loss: 2.2466891991194857

Epoch: 6| Step: 2
Training loss: 2.0439183712005615
Validation loss: 2.2376700165451213

Epoch: 6| Step: 3
Training loss: 2.6934478282928467
Validation loss: 2.2383350992715485

Epoch: 6| Step: 4
Training loss: 2.8421778678894043
Validation loss: 2.2349064760310675

Epoch: 6| Step: 5
Training loss: 3.079615592956543
Validation loss: 2.2278342836646625

Epoch: 6| Step: 6
Training loss: 2.861264228820801
Validation loss: 2.238531792035667

Epoch: 6| Step: 7
Training loss: 2.617398262023926
Validation loss: 2.2515550787730882

Epoch: 6| Step: 8
Training loss: 1.8927834033966064
Validation loss: 2.2575538350689794

Epoch: 6| Step: 9
Training loss: 3.0022504329681396
Validation loss: 2.268966802986719

Epoch: 6| Step: 10
Training loss: 2.326328754425049
Validation loss: 2.2783812246014996

Epoch: 6| Step: 11
Training loss: 2.7418923377990723
Validation loss: 2.2875805977852113

Epoch: 6| Step: 12
Training loss: 2.7353057861328125
Validation loss: 2.286778214157269

Epoch: 6| Step: 13
Training loss: 2.5339081287384033
Validation loss: 2.2885320878797963

Epoch: 42| Step: 0
Training loss: 2.6716294288635254
Validation loss: 2.288431962331136

Epoch: 6| Step: 1
Training loss: 3.189091682434082
Validation loss: 2.268471166651736

Epoch: 6| Step: 2
Training loss: 2.4957432746887207
Validation loss: 2.25116229057312

Epoch: 6| Step: 3
Training loss: 2.6338109970092773
Validation loss: 2.2374870443856842

Epoch: 6| Step: 4
Training loss: 2.4278011322021484
Validation loss: 2.2338656097330074

Epoch: 6| Step: 5
Training loss: 2.15440034866333
Validation loss: 2.2360784776749147

Epoch: 6| Step: 6
Training loss: 2.1755175590515137
Validation loss: 2.232280315891389

Epoch: 6| Step: 7
Training loss: 3.095698356628418
Validation loss: 2.2326990660800727

Epoch: 6| Step: 8
Training loss: 2.3353984355926514
Validation loss: 2.2444520355552755

Epoch: 6| Step: 9
Training loss: 1.5923266410827637
Validation loss: 2.243964332406239

Epoch: 6| Step: 10
Training loss: 3.267190456390381
Validation loss: 2.2300673351492932

Epoch: 6| Step: 11
Training loss: 2.64056396484375
Validation loss: 2.2252018297872236

Epoch: 6| Step: 12
Training loss: 2.482858896255493
Validation loss: 2.224146512246901

Epoch: 6| Step: 13
Training loss: 2.2033510208129883
Validation loss: 2.219029288138113

Epoch: 43| Step: 0
Training loss: 2.8667163848876953
Validation loss: 2.2184050749706965

Epoch: 6| Step: 1
Training loss: 2.5295305252075195
Validation loss: 2.220673766187442

Epoch: 6| Step: 2
Training loss: 2.5401108264923096
Validation loss: 2.2217148298858316

Epoch: 6| Step: 3
Training loss: 2.478454113006592
Validation loss: 2.2182982249926497

Epoch: 6| Step: 4
Training loss: 2.992919921875
Validation loss: 2.2190117361725017

Epoch: 6| Step: 5
Training loss: 2.315035343170166
Validation loss: 2.220060181874101

Epoch: 6| Step: 6
Training loss: 2.6448121070861816
Validation loss: 2.219090546331098

Epoch: 6| Step: 7
Training loss: 3.116809606552124
Validation loss: 2.219194407104164

Epoch: 6| Step: 8
Training loss: 2.5074222087860107
Validation loss: 2.2168454482991207

Epoch: 6| Step: 9
Training loss: 2.534195899963379
Validation loss: 2.2204575295089395

Epoch: 6| Step: 10
Training loss: 2.6033878326416016
Validation loss: 2.2191649072913715

Epoch: 6| Step: 11
Training loss: 2.272447347640991
Validation loss: 2.2244568204367035

Epoch: 6| Step: 12
Training loss: 1.9460029602050781
Validation loss: 2.2170122464497886

Epoch: 6| Step: 13
Training loss: 1.9624977111816406
Validation loss: 2.225724676603912

Epoch: 44| Step: 0
Training loss: 2.5600414276123047
Validation loss: 2.248106130989649

Epoch: 6| Step: 1
Training loss: 2.62180233001709
Validation loss: 2.2626844272818616

Epoch: 6| Step: 2
Training loss: 2.8681797981262207
Validation loss: 2.252615431303619

Epoch: 6| Step: 3
Training loss: 2.925740957260132
Validation loss: 2.2732500248057868

Epoch: 6| Step: 4
Training loss: 2.0080173015594482
Validation loss: 2.2669172850988244

Epoch: 6| Step: 5
Training loss: 3.089059829711914
Validation loss: 2.2701843118154876

Epoch: 6| Step: 6
Training loss: 2.3045647144317627
Validation loss: 2.272598748566002

Epoch: 6| Step: 7
Training loss: 2.664917469024658
Validation loss: 2.290045117819181

Epoch: 6| Step: 8
Training loss: 1.8370742797851562
Validation loss: 2.295297594480617

Epoch: 6| Step: 9
Training loss: 2.1768064498901367
Validation loss: 2.3024846610202583

Epoch: 6| Step: 10
Training loss: 2.670652151107788
Validation loss: 2.246856559989273

Epoch: 6| Step: 11
Training loss: 2.5893445014953613
Validation loss: 2.2377704958761893

Epoch: 6| Step: 12
Training loss: 2.717987298965454
Validation loss: 2.218694740726102

Epoch: 6| Step: 13
Training loss: 2.3440699577331543
Validation loss: 2.2036457625768517

Epoch: 45| Step: 0
Training loss: 2.609442710876465
Validation loss: 2.1975209430981706

Epoch: 6| Step: 1
Training loss: 2.5201516151428223
Validation loss: 2.1923801232409734

Epoch: 6| Step: 2
Training loss: 2.36706805229187
Validation loss: 2.1897230020133396

Epoch: 6| Step: 3
Training loss: 2.6853833198547363
Validation loss: 2.1805917447613132

Epoch: 6| Step: 4
Training loss: 2.9052586555480957
Validation loss: 2.183429297580514

Epoch: 6| Step: 5
Training loss: 2.3902814388275146
Validation loss: 2.1864480241652458

Epoch: 6| Step: 6
Training loss: 2.9480443000793457
Validation loss: 2.178274182863133

Epoch: 6| Step: 7
Training loss: 2.4708690643310547
Validation loss: 2.1715742990534794

Epoch: 6| Step: 8
Training loss: 3.1068620681762695
Validation loss: 2.1713684681923158

Epoch: 6| Step: 9
Training loss: 1.5245530605316162
Validation loss: 2.1698707380602436

Epoch: 6| Step: 10
Training loss: 2.2794222831726074
Validation loss: 2.1785998062420915

Epoch: 6| Step: 11
Training loss: 2.499053955078125
Validation loss: 2.179273054163943

Epoch: 6| Step: 12
Training loss: 2.453753709793091
Validation loss: 2.185598570813415

Epoch: 6| Step: 13
Training loss: 2.124659299850464
Validation loss: 2.190624454970001

Epoch: 46| Step: 0
Training loss: 2.695760488510132
Validation loss: 2.1821689951804375

Epoch: 6| Step: 1
Training loss: 2.3442211151123047
Validation loss: 2.1795025038462814

Epoch: 6| Step: 2
Training loss: 1.7701544761657715
Validation loss: 2.176578078218686

Epoch: 6| Step: 3
Training loss: 2.759087085723877
Validation loss: 2.186702407816405

Epoch: 6| Step: 4
Training loss: 2.7757227420806885
Validation loss: 2.190251981058428

Epoch: 6| Step: 5
Training loss: 2.2644009590148926
Validation loss: 2.1988365380994734

Epoch: 6| Step: 6
Training loss: 1.6481704711914062
Validation loss: 2.190680262862995

Epoch: 6| Step: 7
Training loss: 2.501443386077881
Validation loss: 2.1779247163444437

Epoch: 6| Step: 8
Training loss: 2.8070781230926514
Validation loss: 2.1883579390023344

Epoch: 6| Step: 9
Training loss: 2.505951404571533
Validation loss: 2.211475920933549

Epoch: 6| Step: 10
Training loss: 2.9827988147735596
Validation loss: 2.2138971795317945

Epoch: 6| Step: 11
Training loss: 2.602083683013916
Validation loss: 2.2174223930604997

Epoch: 6| Step: 12
Training loss: 2.6610946655273438
Validation loss: 2.2333266145439556

Epoch: 6| Step: 13
Training loss: 2.6105079650878906
Validation loss: 2.246060632890271

Epoch: 47| Step: 0
Training loss: 2.0127053260803223
Validation loss: 2.2346505734228317

Epoch: 6| Step: 1
Training loss: 1.7821484804153442
Validation loss: 2.2066073494572795

Epoch: 6| Step: 2
Training loss: 3.0747952461242676
Validation loss: 2.189156637396864

Epoch: 6| Step: 3
Training loss: 2.489896774291992
Validation loss: 2.160242590852963

Epoch: 6| Step: 4
Training loss: 3.062575340270996
Validation loss: 2.1524923745022027

Epoch: 6| Step: 5
Training loss: 2.5705418586730957
Validation loss: 2.1463949936692432

Epoch: 6| Step: 6
Training loss: 3.468003273010254
Validation loss: 2.148938073906847

Epoch: 6| Step: 7
Training loss: 2.5620217323303223
Validation loss: 2.1600277500767864

Epoch: 6| Step: 8
Training loss: 2.445453405380249
Validation loss: 2.171104528570688

Epoch: 6| Step: 9
Training loss: 2.5591890811920166
Validation loss: 2.180009772700648

Epoch: 6| Step: 10
Training loss: 2.488314151763916
Validation loss: 2.17636453208103

Epoch: 6| Step: 11
Training loss: 2.208220958709717
Validation loss: 2.17729551048689

Epoch: 6| Step: 12
Training loss: 1.8403643369674683
Validation loss: 2.1713382044146137

Epoch: 6| Step: 13
Training loss: 2.0856971740722656
Validation loss: 2.169523871073159

Epoch: 48| Step: 0
Training loss: 2.0145983695983887
Validation loss: 2.179015072443152

Epoch: 6| Step: 1
Training loss: 2.910372734069824
Validation loss: 2.1646603127961517

Epoch: 6| Step: 2
Training loss: 2.6534273624420166
Validation loss: 2.1494537143297094

Epoch: 6| Step: 3
Training loss: 2.507960796356201
Validation loss: 2.149104428547685

Epoch: 6| Step: 4
Training loss: 2.7611513137817383
Validation loss: 2.1549513929633686

Epoch: 6| Step: 5
Training loss: 1.9108043909072876
Validation loss: 2.1477453836830716

Epoch: 6| Step: 6
Training loss: 2.6168031692504883
Validation loss: 2.137767150837888

Epoch: 6| Step: 7
Training loss: 1.9788169860839844
Validation loss: 2.141107614322375

Epoch: 6| Step: 8
Training loss: 2.7574238777160645
Validation loss: 2.1355501272345103

Epoch: 6| Step: 9
Training loss: 2.0998802185058594
Validation loss: 2.1398048144514843

Epoch: 6| Step: 10
Training loss: 2.4548234939575195
Validation loss: 2.1376150320934992

Epoch: 6| Step: 11
Training loss: 2.8968985080718994
Validation loss: 2.133830806260468

Epoch: 6| Step: 12
Training loss: 2.2079198360443115
Validation loss: 2.131562179134738

Epoch: 6| Step: 13
Training loss: 3.2831850051879883
Validation loss: 2.139521643679629

Epoch: 49| Step: 0
Training loss: 2.572936534881592
Validation loss: 2.1576386305593673

Epoch: 6| Step: 1
Training loss: 3.3020613193511963
Validation loss: 2.1859982334157473

Epoch: 6| Step: 2
Training loss: 2.494530200958252
Validation loss: 2.2185921566460722

Epoch: 6| Step: 3
Training loss: 2.270307779312134
Validation loss: 2.2044653149061304

Epoch: 6| Step: 4
Training loss: 2.000466823577881
Validation loss: 2.211476674643896

Epoch: 6| Step: 5
Training loss: 2.667372703552246
Validation loss: 2.1988236199143114

Epoch: 6| Step: 6
Training loss: 2.4589409828186035
Validation loss: 2.146026744637438

Epoch: 6| Step: 7
Training loss: 2.6245388984680176
Validation loss: 2.128451798551826

Epoch: 6| Step: 8
Training loss: 1.9524893760681152
Validation loss: 2.131323902837692

Epoch: 6| Step: 9
Training loss: 2.7017078399658203
Validation loss: 2.127095014818253

Epoch: 6| Step: 10
Training loss: 2.6438262462615967
Validation loss: 2.1407940336453017

Epoch: 6| Step: 11
Training loss: 1.9940181970596313
Validation loss: 2.1493255297342935

Epoch: 6| Step: 12
Training loss: 2.423992872238159
Validation loss: 2.144169561324581

Epoch: 6| Step: 13
Training loss: 2.4583537578582764
Validation loss: 2.142207537927935

Epoch: 50| Step: 0
Training loss: 2.537008285522461
Validation loss: 2.144618372763357

Epoch: 6| Step: 1
Training loss: 2.4899139404296875
Validation loss: 2.1427073094152633

Epoch: 6| Step: 2
Training loss: 2.946934223175049
Validation loss: 2.1600449687691143

Epoch: 6| Step: 3
Training loss: 2.596163749694824
Validation loss: 2.152493546085973

Epoch: 6| Step: 4
Training loss: 2.3491551876068115
Validation loss: 2.169573941538411

Epoch: 6| Step: 5
Training loss: 2.6307029724121094
Validation loss: 2.1524824878220916

Epoch: 6| Step: 6
Training loss: 1.8831398487091064
Validation loss: 2.143109708703974

Epoch: 6| Step: 7
Training loss: 2.7858734130859375
Validation loss: 2.1435794138139292

Epoch: 6| Step: 8
Training loss: 1.8654136657714844
Validation loss: 2.128648219570037

Epoch: 6| Step: 9
Training loss: 3.112621545791626
Validation loss: 2.128483941478114

Epoch: 6| Step: 10
Training loss: 2.44848370552063
Validation loss: 2.121530775100954

Epoch: 6| Step: 11
Training loss: 1.977909803390503
Validation loss: 2.1249366139852874

Epoch: 6| Step: 12
Training loss: 2.5533697605133057
Validation loss: 2.130867701704784

Epoch: 6| Step: 13
Training loss: 2.387409210205078
Validation loss: 2.1455101146492908

Epoch: 51| Step: 0
Training loss: 2.759469509124756
Validation loss: 2.166951899887413

Epoch: 6| Step: 1
Training loss: 2.148756980895996
Validation loss: 2.1749572266814527

Epoch: 6| Step: 2
Training loss: 2.6388144493103027
Validation loss: 2.177743351587685

Epoch: 6| Step: 3
Training loss: 2.6953935623168945
Validation loss: 2.1784417834333194

Epoch: 6| Step: 4
Training loss: 2.370850086212158
Validation loss: 2.1911778885831117

Epoch: 6| Step: 5
Training loss: 2.4265189170837402
Validation loss: 2.1934414038094143

Epoch: 6| Step: 6
Training loss: 2.3363237380981445
Validation loss: 2.1807261897671606

Epoch: 6| Step: 7
Training loss: 2.803694725036621
Validation loss: 2.1664784800621772

Epoch: 6| Step: 8
Training loss: 2.0102570056915283
Validation loss: 2.1526323467172603

Epoch: 6| Step: 9
Training loss: 2.112595319747925
Validation loss: 2.1357626068976616

Epoch: 6| Step: 10
Training loss: 1.9091098308563232
Validation loss: 2.145191199036055

Epoch: 6| Step: 11
Training loss: 2.405514717102051
Validation loss: 2.1390675472956833

Epoch: 6| Step: 12
Training loss: 3.2540273666381836
Validation loss: 2.1284512166054017

Epoch: 6| Step: 13
Training loss: 2.627802848815918
Validation loss: 2.1271141498319563

Epoch: 52| Step: 0
Training loss: 2.573307752609253
Validation loss: 2.144212689450992

Epoch: 6| Step: 1
Training loss: 1.7832560539245605
Validation loss: 2.1878833258023827

Epoch: 6| Step: 2
Training loss: 2.651329517364502
Validation loss: 2.2162763303326023

Epoch: 6| Step: 3
Training loss: 2.4775233268737793
Validation loss: 2.2285741888066775

Epoch: 6| Step: 4
Training loss: 3.2965402603149414
Validation loss: 2.1892468301198815

Epoch: 6| Step: 5
Training loss: 2.765197277069092
Validation loss: 2.16073336139802

Epoch: 6| Step: 6
Training loss: 2.4151461124420166
Validation loss: 2.124495680614184

Epoch: 6| Step: 7
Training loss: 1.4613887071609497
Validation loss: 2.1260314064641155

Epoch: 6| Step: 8
Training loss: 2.7030420303344727
Validation loss: 2.1224430761029645

Epoch: 6| Step: 9
Training loss: 2.501603841781616
Validation loss: 2.1231628925569597

Epoch: 6| Step: 10
Training loss: 2.972221851348877
Validation loss: 2.1278242167606147

Epoch: 6| Step: 11
Training loss: 3.0234227180480957
Validation loss: 2.1319437052613948

Epoch: 6| Step: 12
Training loss: 1.8559445142745972
Validation loss: 2.1287846385791735

Epoch: 6| Step: 13
Training loss: 2.056408166885376
Validation loss: 2.1338172010196153

Epoch: 53| Step: 0
Training loss: 2.615963935852051
Validation loss: 2.1244713593554754

Epoch: 6| Step: 1
Training loss: 2.3250725269317627
Validation loss: 2.125738118284492

Epoch: 6| Step: 2
Training loss: 2.494067430496216
Validation loss: 2.1410932387075117

Epoch: 6| Step: 3
Training loss: 2.8136098384857178
Validation loss: 2.156032749401626

Epoch: 6| Step: 4
Training loss: 2.594045877456665
Validation loss: 2.1616860615309847

Epoch: 6| Step: 5
Training loss: 2.7746682167053223
Validation loss: 2.139553162359422

Epoch: 6| Step: 6
Training loss: 2.284498929977417
Validation loss: 2.1275161517563688

Epoch: 6| Step: 7
Training loss: 2.9956705570220947
Validation loss: 2.107718439512355

Epoch: 6| Step: 8
Training loss: 1.9874979257583618
Validation loss: 2.109515855389257

Epoch: 6| Step: 9
Training loss: 2.440018892288208
Validation loss: 2.110242824400625

Epoch: 6| Step: 10
Training loss: 2.23806095123291
Validation loss: 2.1141699078262493

Epoch: 6| Step: 11
Training loss: 2.0222487449645996
Validation loss: 2.1048733944533975

Epoch: 6| Step: 12
Training loss: 2.0033249855041504
Validation loss: 2.1144447634297032

Epoch: 6| Step: 13
Training loss: 3.16471529006958
Validation loss: 2.1228448857543287

Epoch: 54| Step: 0
Training loss: 2.5830724239349365
Validation loss: 2.1761982876767396

Epoch: 6| Step: 1
Training loss: 2.5262856483459473
Validation loss: 2.224604659183051

Epoch: 6| Step: 2
Training loss: 1.710017204284668
Validation loss: 2.2472468499214417

Epoch: 6| Step: 3
Training loss: 1.5636839866638184
Validation loss: 2.228554365455463

Epoch: 6| Step: 4
Training loss: 2.1157732009887695
Validation loss: 2.1628337701161704

Epoch: 6| Step: 5
Training loss: 3.021271228790283
Validation loss: 2.133563574924264

Epoch: 6| Step: 6
Training loss: 3.006286144256592
Validation loss: 2.115677781002496

Epoch: 6| Step: 7
Training loss: 2.5104596614837646
Validation loss: 2.1148405126346055

Epoch: 6| Step: 8
Training loss: 2.460783004760742
Validation loss: 2.1169679164886475

Epoch: 6| Step: 9
Training loss: 3.40950083732605
Validation loss: 2.1304943535917547

Epoch: 6| Step: 10
Training loss: 2.2420294284820557
Validation loss: 2.1386311848958335

Epoch: 6| Step: 11
Training loss: 2.3379387855529785
Validation loss: 2.135972305010724

Epoch: 6| Step: 12
Training loss: 2.3570969104766846
Validation loss: 2.1434662918890677

Epoch: 6| Step: 13
Training loss: 2.4818520545959473
Validation loss: 2.132551598292525

Epoch: 55| Step: 0
Training loss: 1.7323408126831055
Validation loss: 2.109292576389928

Epoch: 6| Step: 1
Training loss: 2.599327325820923
Validation loss: 2.1066359140539683

Epoch: 6| Step: 2
Training loss: 1.9520297050476074
Validation loss: 2.1187136993613294

Epoch: 6| Step: 3
Training loss: 3.1847054958343506
Validation loss: 2.1476943057070494

Epoch: 6| Step: 4
Training loss: 2.379824161529541
Validation loss: 2.1746667661974506

Epoch: 6| Step: 5
Training loss: 2.3259010314941406
Validation loss: 2.1980347351361345

Epoch: 6| Step: 6
Training loss: 2.3661913871765137
Validation loss: 2.2267208253183672

Epoch: 6| Step: 7
Training loss: 2.606326103210449
Validation loss: 2.24879442491839

Epoch: 6| Step: 8
Training loss: 3.6202640533447266
Validation loss: 2.2062477257943924

Epoch: 6| Step: 9
Training loss: 2.6710193157196045
Validation loss: 2.165127323519799

Epoch: 6| Step: 10
Training loss: 1.775467872619629
Validation loss: 2.1324808956474386

Epoch: 6| Step: 11
Training loss: 2.8120758533477783
Validation loss: 2.1116780363103396

Epoch: 6| Step: 12
Training loss: 2.498551607131958
Validation loss: 2.101215748376744

Epoch: 6| Step: 13
Training loss: 2.0177676677703857
Validation loss: 2.094897534257622

Epoch: 56| Step: 0
Training loss: 2.386207103729248
Validation loss: 2.094845393652557

Epoch: 6| Step: 1
Training loss: 2.924712896347046
Validation loss: 2.0874510119038243

Epoch: 6| Step: 2
Training loss: 2.6679975986480713
Validation loss: 2.090241784690529

Epoch: 6| Step: 3
Training loss: 2.3471360206604004
Validation loss: 2.0954619505072154

Epoch: 6| Step: 4
Training loss: 2.0447754859924316
Validation loss: 2.099579098404095

Epoch: 6| Step: 5
Training loss: 1.7883272171020508
Validation loss: 2.0886901834959626

Epoch: 6| Step: 6
Training loss: 3.1670570373535156
Validation loss: 2.1009050723045104

Epoch: 6| Step: 7
Training loss: 2.959547519683838
Validation loss: 2.1000091106660905

Epoch: 6| Step: 8
Training loss: 2.5342791080474854
Validation loss: 2.114421203572263

Epoch: 6| Step: 9
Training loss: 2.6585583686828613
Validation loss: 2.1225164833889214

Epoch: 6| Step: 10
Training loss: 2.3147895336151123
Validation loss: 2.1303321725578717

Epoch: 6| Step: 11
Training loss: 1.7947505712509155
Validation loss: 2.153418557618254

Epoch: 6| Step: 12
Training loss: 2.1453394889831543
Validation loss: 2.1693696039979176

Epoch: 6| Step: 13
Training loss: 2.129240036010742
Validation loss: 2.1733660710755216

Epoch: 57| Step: 0
Training loss: 2.4322457313537598
Validation loss: 2.188138488800295

Epoch: 6| Step: 1
Training loss: 1.834017038345337
Validation loss: 2.1873393135686077

Epoch: 6| Step: 2
Training loss: 2.7900521755218506
Validation loss: 2.1681878694923977

Epoch: 6| Step: 3
Training loss: 2.692354679107666
Validation loss: 2.1336965919822775

Epoch: 6| Step: 4
Training loss: 2.88608455657959
Validation loss: 2.111459491073444

Epoch: 6| Step: 5
Training loss: 1.7000677585601807
Validation loss: 2.1027962430830924

Epoch: 6| Step: 6
Training loss: 2.231781482696533
Validation loss: 2.0920322018284954

Epoch: 6| Step: 7
Training loss: 3.0499839782714844
Validation loss: 2.0917108494748353

Epoch: 6| Step: 8
Training loss: 2.5806021690368652
Validation loss: 2.088621844527542

Epoch: 6| Step: 9
Training loss: 2.323580741882324
Validation loss: 2.089588460101876

Epoch: 6| Step: 10
Training loss: 2.8454041481018066
Validation loss: 2.08728696966684

Epoch: 6| Step: 11
Training loss: 1.781714677810669
Validation loss: 2.0808215448933263

Epoch: 6| Step: 12
Training loss: 2.1985349655151367
Validation loss: 2.078210679433679

Epoch: 6| Step: 13
Training loss: 2.940779209136963
Validation loss: 2.093560685393631

Epoch: 58| Step: 0
Training loss: 2.4519100189208984
Validation loss: 2.092844440091041

Epoch: 6| Step: 1
Training loss: 2.0229053497314453
Validation loss: 2.09692879005145

Epoch: 6| Step: 2
Training loss: 1.7108514308929443
Validation loss: 2.0904923177534536

Epoch: 6| Step: 3
Training loss: 2.443563461303711
Validation loss: 2.0810628091135333

Epoch: 6| Step: 4
Training loss: 2.2490310668945312
Validation loss: 2.083806049439215

Epoch: 6| Step: 5
Training loss: 2.2708611488342285
Validation loss: 2.087187199182408

Epoch: 6| Step: 6
Training loss: 2.443211078643799
Validation loss: 2.083055034760506

Epoch: 6| Step: 7
Training loss: 3.1568260192871094
Validation loss: 2.092857345458

Epoch: 6| Step: 8
Training loss: 2.513871669769287
Validation loss: 2.1003964485660678

Epoch: 6| Step: 9
Training loss: 2.6914587020874023
Validation loss: 2.1002356518981276

Epoch: 6| Step: 10
Training loss: 2.767611503601074
Validation loss: 2.091709893236878

Epoch: 6| Step: 11
Training loss: 2.67232084274292
Validation loss: 2.0842524510557934

Epoch: 6| Step: 12
Training loss: 1.4447983503341675
Validation loss: 2.092403076028311

Epoch: 6| Step: 13
Training loss: 3.36769437789917
Validation loss: 2.101882742297265

Epoch: 59| Step: 0
Training loss: 2.5989696979522705
Validation loss: 2.140143471379434

Epoch: 6| Step: 1
Training loss: 2.446244239807129
Validation loss: 2.1351391679497174

Epoch: 6| Step: 2
Training loss: 1.7784178256988525
Validation loss: 2.1158083279927573

Epoch: 6| Step: 3
Training loss: 2.6560158729553223
Validation loss: 2.109767747181718

Epoch: 6| Step: 4
Training loss: 2.406255006790161
Validation loss: 2.0925812182887906

Epoch: 6| Step: 5
Training loss: 2.1015987396240234
Validation loss: 2.085657832443073

Epoch: 6| Step: 6
Training loss: 2.332536220550537
Validation loss: 2.0947243808418192

Epoch: 6| Step: 7
Training loss: 1.83704674243927
Validation loss: 2.0837332484542683

Epoch: 6| Step: 8
Training loss: 2.576544761657715
Validation loss: 2.0888086941934403

Epoch: 6| Step: 9
Training loss: 2.2964563369750977
Validation loss: 2.0720964144634944

Epoch: 6| Step: 10
Training loss: 3.1850972175598145
Validation loss: 2.0795334077650502

Epoch: 6| Step: 11
Training loss: 2.3316502571105957
Validation loss: 2.0767664268452632

Epoch: 6| Step: 12
Training loss: 2.4713826179504395
Validation loss: 2.0887236133698495

Epoch: 6| Step: 13
Training loss: 2.983687400817871
Validation loss: 2.09704529341831

Epoch: 60| Step: 0
Training loss: 1.8480569124221802
Validation loss: 2.1159980758543937

Epoch: 6| Step: 1
Training loss: 3.2033913135528564
Validation loss: 2.1229433064819663

Epoch: 6| Step: 2
Training loss: 3.1069936752319336
Validation loss: 2.1318994055512133

Epoch: 6| Step: 3
Training loss: 1.8030238151550293
Validation loss: 2.1067724048450427

Epoch: 6| Step: 4
Training loss: 1.4928786754608154
Validation loss: 2.0954850976185133

Epoch: 6| Step: 5
Training loss: 2.356126308441162
Validation loss: 2.083747227986654

Epoch: 6| Step: 6
Training loss: 2.422290802001953
Validation loss: 2.095560917290308

Epoch: 6| Step: 7
Training loss: 2.9500370025634766
Validation loss: 2.100456101920015

Epoch: 6| Step: 8
Training loss: 2.049489974975586
Validation loss: 2.1067744762666765

Epoch: 6| Step: 9
Training loss: 2.9677810668945312
Validation loss: 2.105816518106768

Epoch: 6| Step: 10
Training loss: 2.114553213119507
Validation loss: 2.0817008095402874

Epoch: 6| Step: 11
Training loss: 2.2330384254455566
Validation loss: 2.068085633298402

Epoch: 6| Step: 12
Training loss: 2.592729091644287
Validation loss: 2.0626221036398285

Epoch: 6| Step: 13
Training loss: 2.58101487159729
Validation loss: 2.0552982155994703

Epoch: 61| Step: 0
Training loss: 2.5919737815856934
Validation loss: 2.054631256288098

Epoch: 6| Step: 1
Training loss: 2.0931735038757324
Validation loss: 2.0628202128153976

Epoch: 6| Step: 2
Training loss: 2.3795742988586426
Validation loss: 2.078412602024694

Epoch: 6| Step: 3
Training loss: 2.631680965423584
Validation loss: 2.1049829016449633

Epoch: 6| Step: 4
Training loss: 2.1621720790863037
Validation loss: 2.1338886983932985

Epoch: 6| Step: 5
Training loss: 2.441161632537842
Validation loss: 2.167344626560006

Epoch: 6| Step: 6
Training loss: 2.4283289909362793
Validation loss: 2.174622966397193

Epoch: 6| Step: 7
Training loss: 2.455883264541626
Validation loss: 2.1244310076518724

Epoch: 6| Step: 8
Training loss: 2.0019869804382324
Validation loss: 2.09005477095163

Epoch: 6| Step: 9
Training loss: 2.501718044281006
Validation loss: 2.077860188740556

Epoch: 6| Step: 10
Training loss: 1.8533344268798828
Validation loss: 2.072176159069102

Epoch: 6| Step: 11
Training loss: 3.1502392292022705
Validation loss: 2.053953802713784

Epoch: 6| Step: 12
Training loss: 2.338507890701294
Validation loss: 2.0563737423189226

Epoch: 6| Step: 13
Training loss: 2.41778826713562
Validation loss: 2.052984776035432

Epoch: 62| Step: 0
Training loss: 3.1642558574676514
Validation loss: 2.0516916808261665

Epoch: 6| Step: 1
Training loss: 1.851733684539795
Validation loss: 2.0484832486798688

Epoch: 6| Step: 2
Training loss: 2.651789665222168
Validation loss: 2.0540855341060187

Epoch: 6| Step: 3
Training loss: 2.7934372425079346
Validation loss: 2.101762886970274

Epoch: 6| Step: 4
Training loss: 2.4619736671447754
Validation loss: 2.175008132893552

Epoch: 6| Step: 5
Training loss: 2.538083553314209
Validation loss: 2.2119569739987774

Epoch: 6| Step: 6
Training loss: 2.4145188331604004
Validation loss: 2.1849450603608163

Epoch: 6| Step: 7
Training loss: 2.1509153842926025
Validation loss: 2.11862156468053

Epoch: 6| Step: 8
Training loss: 2.598444938659668
Validation loss: 2.1026520549610095

Epoch: 6| Step: 9
Training loss: 2.061868667602539
Validation loss: 2.0987979981207077

Epoch: 6| Step: 10
Training loss: 2.2559070587158203
Validation loss: 2.1039928710588844

Epoch: 6| Step: 11
Training loss: 2.188307762145996
Validation loss: 2.0987364848454795

Epoch: 6| Step: 12
Training loss: 2.275186061859131
Validation loss: 2.075392348791963

Epoch: 6| Step: 13
Training loss: 2.0117225646972656
Validation loss: 2.0564518410672425

Epoch: 63| Step: 0
Training loss: 2.372621536254883
Validation loss: 2.0558611039192445

Epoch: 6| Step: 1
Training loss: 2.38322114944458
Validation loss: 2.0767093243137484

Epoch: 6| Step: 2
Training loss: 3.0014729499816895
Validation loss: 2.0976308084303334

Epoch: 6| Step: 3
Training loss: 3.0531115531921387
Validation loss: 2.097857362480574

Epoch: 6| Step: 4
Training loss: 2.374696731567383
Validation loss: 2.0789501590113484

Epoch: 6| Step: 5
Training loss: 2.039515972137451
Validation loss: 2.067549599114285

Epoch: 6| Step: 6
Training loss: 2.548839569091797
Validation loss: 2.0662897863695697

Epoch: 6| Step: 7
Training loss: 2.641446352005005
Validation loss: 2.063220654764483

Epoch: 6| Step: 8
Training loss: 2.680469274520874
Validation loss: 2.064957771249997

Epoch: 6| Step: 9
Training loss: 2.3972530364990234
Validation loss: 2.0699028917538222

Epoch: 6| Step: 10
Training loss: 2.0368316173553467
Validation loss: 2.099078852643249

Epoch: 6| Step: 11
Training loss: 2.373061180114746
Validation loss: 2.1111608346303306

Epoch: 6| Step: 12
Training loss: 1.5939733982086182
Validation loss: 2.1250238944125432

Epoch: 6| Step: 13
Training loss: 2.025392770767212
Validation loss: 2.116244021282401

Epoch: 64| Step: 0
Training loss: 1.8387188911437988
Validation loss: 2.1029156664366364

Epoch: 6| Step: 1
Training loss: 2.449636936187744
Validation loss: 2.097636825294905

Epoch: 6| Step: 2
Training loss: 2.950056552886963
Validation loss: 2.071613363040391

Epoch: 6| Step: 3
Training loss: 2.187087059020996
Validation loss: 2.055384136015369

Epoch: 6| Step: 4
Training loss: 2.640862464904785
Validation loss: 2.0437919965354343

Epoch: 6| Step: 5
Training loss: 2.2291207313537598
Validation loss: 2.048157815010317

Epoch: 6| Step: 6
Training loss: 2.8563528060913086
Validation loss: 2.055730991466071

Epoch: 6| Step: 7
Training loss: 1.7227058410644531
Validation loss: 2.062852298059771

Epoch: 6| Step: 8
Training loss: 1.9699015617370605
Validation loss: 2.0611464951627996

Epoch: 6| Step: 9
Training loss: 2.8600974082946777
Validation loss: 2.0420238523073095

Epoch: 6| Step: 10
Training loss: 2.304119348526001
Validation loss: 2.0426381326490834

Epoch: 6| Step: 11
Training loss: 1.8378970623016357
Validation loss: 2.042531951781242

Epoch: 6| Step: 12
Training loss: 2.753908634185791
Validation loss: 2.0447142508722123

Epoch: 6| Step: 13
Training loss: 2.9679694175720215
Validation loss: 2.047237966650276

Epoch: 65| Step: 0
Training loss: 2.540433168411255
Validation loss: 2.0393848906281176

Epoch: 6| Step: 1
Training loss: 1.8328443765640259
Validation loss: 2.038920510199762

Epoch: 6| Step: 2
Training loss: 1.6296753883361816
Validation loss: 2.030132885902159

Epoch: 6| Step: 3
Training loss: 2.8714404106140137
Validation loss: 2.0337301428600023

Epoch: 6| Step: 4
Training loss: 2.2836902141571045
Validation loss: 2.0458544326084915

Epoch: 6| Step: 5
Training loss: 2.110455274581909
Validation loss: 2.050719074023667

Epoch: 6| Step: 6
Training loss: 2.9899649620056152
Validation loss: 2.0821757406316777

Epoch: 6| Step: 7
Training loss: 3.043778419494629
Validation loss: 2.1088826630705144

Epoch: 6| Step: 8
Training loss: 3.114387035369873
Validation loss: 2.159080097752233

Epoch: 6| Step: 9
Training loss: 2.0832529067993164
Validation loss: 2.1699507851754465

Epoch: 6| Step: 10
Training loss: 2.4560022354125977
Validation loss: 2.163739360788817

Epoch: 6| Step: 11
Training loss: 1.966275930404663
Validation loss: 2.09138572344216

Epoch: 6| Step: 12
Training loss: 2.137387990951538
Validation loss: 2.0489962306073917

Epoch: 6| Step: 13
Training loss: 2.3882882595062256
Validation loss: 2.0223128334168465

Epoch: 66| Step: 0
Training loss: 2.215388059616089
Validation loss: 2.0365641040186726

Epoch: 6| Step: 1
Training loss: 2.0954065322875977
Validation loss: 2.027881617187172

Epoch: 6| Step: 2
Training loss: 2.24725604057312
Validation loss: 2.04500493695659

Epoch: 6| Step: 3
Training loss: 2.634645462036133
Validation loss: 2.0576475025505148

Epoch: 6| Step: 4
Training loss: 2.281400680541992
Validation loss: 2.0943154583695116

Epoch: 6| Step: 5
Training loss: 3.1431689262390137
Validation loss: 2.095944668657036

Epoch: 6| Step: 6
Training loss: 2.3409218788146973
Validation loss: 2.1164896078007196

Epoch: 6| Step: 7
Training loss: 1.9531171321868896
Validation loss: 2.094408551851908

Epoch: 6| Step: 8
Training loss: 2.0367844104766846
Validation loss: 2.0681517188267042

Epoch: 6| Step: 9
Training loss: 2.486297607421875
Validation loss: 2.0693589974475164

Epoch: 6| Step: 10
Training loss: 2.6380248069763184
Validation loss: 2.054733581440423

Epoch: 6| Step: 11
Training loss: 2.1277365684509277
Validation loss: 2.036645955936883

Epoch: 6| Step: 12
Training loss: 2.9977688789367676
Validation loss: 2.0307368847631637

Epoch: 6| Step: 13
Training loss: 1.7594116926193237
Validation loss: 2.011171151232976

Epoch: 67| Step: 0
Training loss: 2.7191290855407715
Validation loss: 2.0210531450087026

Epoch: 6| Step: 1
Training loss: 2.5662052631378174
Validation loss: 2.0128880777666645

Epoch: 6| Step: 2
Training loss: 2.223217010498047
Validation loss: 2.026471286691645

Epoch: 6| Step: 3
Training loss: 2.591841697692871
Validation loss: 2.0403924078069706

Epoch: 6| Step: 4
Training loss: 2.3131234645843506
Validation loss: 2.05453239205063

Epoch: 6| Step: 5
Training loss: 1.9635694026947021
Validation loss: 2.0821781312265704

Epoch: 6| Step: 6
Training loss: 2.264422655105591
Validation loss: 2.1133621918257846

Epoch: 6| Step: 7
Training loss: 2.06796932220459
Validation loss: 2.1203300876002156

Epoch: 6| Step: 8
Training loss: 1.8895435333251953
Validation loss: 2.135238589779023

Epoch: 6| Step: 9
Training loss: 2.9060158729553223
Validation loss: 2.1183477832425024

Epoch: 6| Step: 10
Training loss: 2.2638039588928223
Validation loss: 2.0711067620144097

Epoch: 6| Step: 11
Training loss: 2.094174385070801
Validation loss: 2.0313640845719205

Epoch: 6| Step: 12
Training loss: 2.531975269317627
Validation loss: 2.026494733748897

Epoch: 6| Step: 13
Training loss: 2.9733781814575195
Validation loss: 2.029850423976939

Epoch: 68| Step: 0
Training loss: 2.1857175827026367
Validation loss: 2.0304456398051274

Epoch: 6| Step: 1
Training loss: 2.10085391998291
Validation loss: 2.0352422191250708

Epoch: 6| Step: 2
Training loss: 2.384589195251465
Validation loss: 2.0195326523114274

Epoch: 6| Step: 3
Training loss: 2.6605148315429688
Validation loss: 2.027440289015411

Epoch: 6| Step: 4
Training loss: 2.643895387649536
Validation loss: 2.0550991642859673

Epoch: 6| Step: 5
Training loss: 1.7881264686584473
Validation loss: 2.0990855232361825

Epoch: 6| Step: 6
Training loss: 2.2023231983184814
Validation loss: 2.108547442702837

Epoch: 6| Step: 7
Training loss: 2.226576328277588
Validation loss: 2.154549347457065

Epoch: 6| Step: 8
Training loss: 2.545647144317627
Validation loss: 2.152997946226469

Epoch: 6| Step: 9
Training loss: 1.6749258041381836
Validation loss: 2.0818393089438

Epoch: 6| Step: 10
Training loss: 2.756441831588745
Validation loss: 2.063263649581581

Epoch: 6| Step: 11
Training loss: 2.651367425918579
Validation loss: 2.0413601270285984

Epoch: 6| Step: 12
Training loss: 2.9865310192108154
Validation loss: 2.012581661183347

Epoch: 6| Step: 13
Training loss: 2.771833896636963
Validation loss: 2.0038710922323246

Epoch: 69| Step: 0
Training loss: 2.4504475593566895
Validation loss: 2.0043830115308046

Epoch: 6| Step: 1
Training loss: 2.760516405105591
Validation loss: 2.002235745870939

Epoch: 6| Step: 2
Training loss: 1.6519122123718262
Validation loss: 2.0087762084058536

Epoch: 6| Step: 3
Training loss: 2.907128095626831
Validation loss: 2.0110517086521273

Epoch: 6| Step: 4
Training loss: 2.413097381591797
Validation loss: 2.012651530645227

Epoch: 6| Step: 5
Training loss: 2.9167051315307617
Validation loss: 2.0269438989700808

Epoch: 6| Step: 6
Training loss: 2.30558180809021
Validation loss: 2.0242106606883388

Epoch: 6| Step: 7
Training loss: 2.199876308441162
Validation loss: 2.025335900245174

Epoch: 6| Step: 8
Training loss: 2.0533320903778076
Validation loss: 2.0233702633970525

Epoch: 6| Step: 9
Training loss: 1.6637673377990723
Validation loss: 2.0235952023536927

Epoch: 6| Step: 10
Training loss: 2.8712525367736816
Validation loss: 2.0194236565661687

Epoch: 6| Step: 11
Training loss: 2.417454719543457
Validation loss: 2.0162386509679977

Epoch: 6| Step: 12
Training loss: 2.0321316719055176
Validation loss: 2.014109557674777

Epoch: 6| Step: 13
Training loss: 1.9143022298812866
Validation loss: 2.0235844581357894

Epoch: 70| Step: 0
Training loss: 1.9947781562805176
Validation loss: 2.0365308741087556

Epoch: 6| Step: 1
Training loss: 2.599935531616211
Validation loss: 2.0332000281221125

Epoch: 6| Step: 2
Training loss: 2.227783203125
Validation loss: 2.0339805362045125

Epoch: 6| Step: 3
Training loss: 3.0311694145202637
Validation loss: 2.0227762165889946

Epoch: 6| Step: 4
Training loss: 2.240220546722412
Validation loss: 2.0198713912758777

Epoch: 6| Step: 5
Training loss: 2.3408870697021484
Validation loss: 2.0190396693445023

Epoch: 6| Step: 6
Training loss: 2.44854998588562
Validation loss: 2.0163253789306967

Epoch: 6| Step: 7
Training loss: 2.4084110260009766
Validation loss: 2.022059356012652

Epoch: 6| Step: 8
Training loss: 2.1837642192840576
Validation loss: 2.0127529841597362

Epoch: 6| Step: 9
Training loss: 1.452986240386963
Validation loss: 2.0175272213515414

Epoch: 6| Step: 10
Training loss: 2.419037342071533
Validation loss: 2.0124572092486965

Epoch: 6| Step: 11
Training loss: 3.1000332832336426
Validation loss: 2.023016188734321

Epoch: 6| Step: 12
Training loss: 1.9015549421310425
Validation loss: 2.021315687446184

Epoch: 6| Step: 13
Training loss: 2.3471336364746094
Validation loss: 2.05616827934019

Epoch: 71| Step: 0
Training loss: 1.7860832214355469
Validation loss: 2.110301617653139

Epoch: 6| Step: 1
Training loss: 2.611827850341797
Validation loss: 2.102090553570819

Epoch: 6| Step: 2
Training loss: 2.351408004760742
Validation loss: 2.0695838761586014

Epoch: 6| Step: 3
Training loss: 2.258784294128418
Validation loss: 2.0332661021140312

Epoch: 6| Step: 4
Training loss: 2.1442694664001465
Validation loss: 2.0172850931844404

Epoch: 6| Step: 5
Training loss: 2.546894073486328
Validation loss: 1.9993461819105252

Epoch: 6| Step: 6
Training loss: 2.4290857315063477
Validation loss: 2.0035447728249336

Epoch: 6| Step: 7
Training loss: 2.4285130500793457
Validation loss: 2.0014753956948557

Epoch: 6| Step: 8
Training loss: 2.1853480339050293
Validation loss: 2.013343507243741

Epoch: 6| Step: 9
Training loss: 2.496967077255249
Validation loss: 1.9992719619504866

Epoch: 6| Step: 10
Training loss: 2.618046998977661
Validation loss: 1.999999096316676

Epoch: 6| Step: 11
Training loss: 1.8121336698532104
Validation loss: 2.023431413917131

Epoch: 6| Step: 12
Training loss: 3.272304058074951
Validation loss: 2.065152964284343

Epoch: 6| Step: 13
Training loss: 2.0592079162597656
Validation loss: 2.0831628025219007

Epoch: 72| Step: 0
Training loss: 2.4333691596984863
Validation loss: 2.049410012460524

Epoch: 6| Step: 1
Training loss: 1.8997701406478882
Validation loss: 2.012544990867697

Epoch: 6| Step: 2
Training loss: 2.747685432434082
Validation loss: 1.9901614701876076

Epoch: 6| Step: 3
Training loss: 1.939605951309204
Validation loss: 1.9874286305519842

Epoch: 6| Step: 4
Training loss: 2.718093156814575
Validation loss: 1.9805835959731892

Epoch: 6| Step: 5
Training loss: 1.9777100086212158
Validation loss: 1.9989597425665906

Epoch: 6| Step: 6
Training loss: 2.744326591491699
Validation loss: 1.9839369238063853

Epoch: 6| Step: 7
Training loss: 2.35929274559021
Validation loss: 1.9881226388357018

Epoch: 6| Step: 8
Training loss: 1.8356672525405884
Validation loss: 1.9873928613560174

Epoch: 6| Step: 9
Training loss: 2.4170563220977783
Validation loss: 1.987782464232496

Epoch: 6| Step: 10
Training loss: 2.702975273132324
Validation loss: 1.993044791683074

Epoch: 6| Step: 11
Training loss: 2.0274040699005127
Validation loss: 1.9771857171930292

Epoch: 6| Step: 12
Training loss: 2.2079155445098877
Validation loss: 2.00963572789264

Epoch: 6| Step: 13
Training loss: 2.5884792804718018
Validation loss: 2.0442623784465175

Epoch: 73| Step: 0
Training loss: 1.8727432489395142
Validation loss: 2.061335996914935

Epoch: 6| Step: 1
Training loss: 2.837851047515869
Validation loss: 2.072354239802207

Epoch: 6| Step: 2
Training loss: 1.5134696960449219
Validation loss: 2.0495856961896344

Epoch: 6| Step: 3
Training loss: 2.312790870666504
Validation loss: 2.0067650207909207

Epoch: 6| Step: 4
Training loss: 2.2694759368896484
Validation loss: 1.98590007135945

Epoch: 6| Step: 5
Training loss: 1.8660438060760498
Validation loss: 1.9940625249698598

Epoch: 6| Step: 6
Training loss: 2.645390510559082
Validation loss: 2.00439469275936

Epoch: 6| Step: 7
Training loss: 3.0910260677337646
Validation loss: 2.0032854362200667

Epoch: 6| Step: 8
Training loss: 2.1461522579193115
Validation loss: 2.0039807878514773

Epoch: 6| Step: 9
Training loss: 2.965578079223633
Validation loss: 2.0131532633176414

Epoch: 6| Step: 10
Training loss: 2.1164212226867676
Validation loss: 2.0135099708393054

Epoch: 6| Step: 11
Training loss: 2.5356526374816895
Validation loss: 2.018116904843238

Epoch: 6| Step: 12
Training loss: 2.4050183296203613
Validation loss: 2.0278019238543767

Epoch: 6| Step: 13
Training loss: 2.038252592086792
Validation loss: 2.0359202956640594

Epoch: 74| Step: 0
Training loss: 1.7797071933746338
Validation loss: 2.017529349173269

Epoch: 6| Step: 1
Training loss: 2.4743666648864746
Validation loss: 2.01876901811169

Epoch: 6| Step: 2
Training loss: 2.588601589202881
Validation loss: 2.0242306852853424

Epoch: 6| Step: 3
Training loss: 2.507110118865967
Validation loss: 2.0270290195301013

Epoch: 6| Step: 4
Training loss: 2.4352774620056152
Validation loss: 2.025594126793646

Epoch: 6| Step: 5
Training loss: 2.087916374206543
Validation loss: 2.024215658505758

Epoch: 6| Step: 6
Training loss: 2.572880268096924
Validation loss: 2.0283706418929563

Epoch: 6| Step: 7
Training loss: 2.088261365890503
Validation loss: 2.0265507980059554

Epoch: 6| Step: 8
Training loss: 1.7024672031402588
Validation loss: 2.0136725697466122

Epoch: 6| Step: 9
Training loss: 2.4200291633605957
Validation loss: 2.009396092866057

Epoch: 6| Step: 10
Training loss: 1.9330391883850098
Validation loss: 2.0141859182747464

Epoch: 6| Step: 11
Training loss: 2.5452466011047363
Validation loss: 2.0085916698619886

Epoch: 6| Step: 12
Training loss: 2.9418249130249023
Validation loss: 1.9955997133767733

Epoch: 6| Step: 13
Training loss: 2.3907525539398193
Validation loss: 1.9949413858434206

Epoch: 75| Step: 0
Training loss: 2.325838088989258
Validation loss: 1.9913499483498194

Epoch: 6| Step: 1
Training loss: 2.079265594482422
Validation loss: 1.9802180926005046

Epoch: 6| Step: 2
Training loss: 2.32515811920166
Validation loss: 1.9968089493372108

Epoch: 6| Step: 3
Training loss: 2.262059211730957
Validation loss: 2.0065572236173894

Epoch: 6| Step: 4
Training loss: 2.926391839981079
Validation loss: 2.01731530568933

Epoch: 6| Step: 5
Training loss: 2.6476054191589355
Validation loss: 2.0427134908655638

Epoch: 6| Step: 6
Training loss: 2.1276092529296875
Validation loss: 2.061076330882247

Epoch: 6| Step: 7
Training loss: 3.0703892707824707
Validation loss: 2.0989279900827715

Epoch: 6| Step: 8
Training loss: 1.9905028343200684
Validation loss: 2.113273310404952

Epoch: 6| Step: 9
Training loss: 1.5102510452270508
Validation loss: 2.037281841360113

Epoch: 6| Step: 10
Training loss: 2.157789707183838
Validation loss: 2.0086265379382717

Epoch: 6| Step: 11
Training loss: 2.4798786640167236
Validation loss: 1.9867256790079095

Epoch: 6| Step: 12
Training loss: 2.3175699710845947
Validation loss: 1.975073278591197

Epoch: 6| Step: 13
Training loss: 2.1722147464752197
Validation loss: 1.9687791357758224

Epoch: 76| Step: 0
Training loss: 2.487264633178711
Validation loss: 1.989956248191095

Epoch: 6| Step: 1
Training loss: 2.433110237121582
Validation loss: 2.0006747156061153

Epoch: 6| Step: 2
Training loss: 2.6751701831817627
Validation loss: 2.0027885975376254

Epoch: 6| Step: 3
Training loss: 2.196415901184082
Validation loss: 2.0231204942990373

Epoch: 6| Step: 4
Training loss: 2.3128581047058105
Validation loss: 2.0404805585902226

Epoch: 6| Step: 5
Training loss: 2.731448173522949
Validation loss: 2.03411365068087

Epoch: 6| Step: 6
Training loss: 2.641535758972168
Validation loss: 2.013229344480781

Epoch: 6| Step: 7
Training loss: 2.445178985595703
Validation loss: 1.999278255688247

Epoch: 6| Step: 8
Training loss: 2.155139923095703
Validation loss: 1.995762449438854

Epoch: 6| Step: 9
Training loss: 2.3373522758483887
Validation loss: 1.9834481285464378

Epoch: 6| Step: 10
Training loss: 1.7044987678527832
Validation loss: 1.9645283645199192

Epoch: 6| Step: 11
Training loss: 1.846963882446289
Validation loss: 2.001172593844834

Epoch: 6| Step: 12
Training loss: 2.2734780311584473
Validation loss: 2.0527548854069044

Epoch: 6| Step: 13
Training loss: 2.517369508743286
Validation loss: 2.0977992268018824

Epoch: 77| Step: 0
Training loss: 1.7183384895324707
Validation loss: 2.1051049745211037

Epoch: 6| Step: 1
Training loss: 2.0466315746307373
Validation loss: 2.0839240550994873

Epoch: 6| Step: 2
Training loss: 2.2108559608459473
Validation loss: 2.0644601109207317

Epoch: 6| Step: 3
Training loss: 2.556088447570801
Validation loss: 2.041728990052336

Epoch: 6| Step: 4
Training loss: 2.624297618865967
Validation loss: 2.0312788614662747

Epoch: 6| Step: 5
Training loss: 1.3800855875015259
Validation loss: 2.0084878731799383

Epoch: 6| Step: 6
Training loss: 2.473604917526245
Validation loss: 2.01338537790442

Epoch: 6| Step: 7
Training loss: 2.655071496963501
Validation loss: 2.016922668744159

Epoch: 6| Step: 8
Training loss: 2.535681962966919
Validation loss: 2.034591346658686

Epoch: 6| Step: 9
Training loss: 2.3262343406677246
Validation loss: 2.0352508573121924

Epoch: 6| Step: 10
Training loss: 2.973167657852173
Validation loss: 2.035149489679644

Epoch: 6| Step: 11
Training loss: 2.045081615447998
Validation loss: 2.022526743591473

Epoch: 6| Step: 12
Training loss: 2.4263203144073486
Validation loss: 1.9998712385854414

Epoch: 6| Step: 13
Training loss: 2.511324644088745
Validation loss: 1.9846320024100683

Epoch: 78| Step: 0
Training loss: 2.5193800926208496
Validation loss: 1.9815809060168523

Epoch: 6| Step: 1
Training loss: 2.309796094894409
Validation loss: 1.967757640346404

Epoch: 6| Step: 2
Training loss: 2.913602352142334
Validation loss: 1.971061901379657

Epoch: 6| Step: 3
Training loss: 2.032355308532715
Validation loss: 1.9636933290830223

Epoch: 6| Step: 4
Training loss: 1.7534945011138916
Validation loss: 1.9546391297412176

Epoch: 6| Step: 5
Training loss: 2.529526710510254
Validation loss: 1.961255887503265

Epoch: 6| Step: 6
Training loss: 2.4107766151428223
Validation loss: 1.975354112604613

Epoch: 6| Step: 7
Training loss: 2.921048879623413
Validation loss: 1.9893717022352322

Epoch: 6| Step: 8
Training loss: 2.8617238998413086
Validation loss: 1.9997337838654876

Epoch: 6| Step: 9
Training loss: 1.6418886184692383
Validation loss: 2.0000225856739986

Epoch: 6| Step: 10
Training loss: 1.614292860031128
Validation loss: 1.9881560981914561

Epoch: 6| Step: 11
Training loss: 2.0044474601745605
Validation loss: 1.99653366304213

Epoch: 6| Step: 12
Training loss: 2.409531593322754
Validation loss: 2.008914727036671

Epoch: 6| Step: 13
Training loss: 2.469235420227051
Validation loss: 2.013693606981667

Epoch: 79| Step: 0
Training loss: 2.3926525115966797
Validation loss: 2.0023709266416487

Epoch: 6| Step: 1
Training loss: 1.839046835899353
Validation loss: 1.997048879182467

Epoch: 6| Step: 2
Training loss: 2.581676721572876
Validation loss: 1.9925404338426487

Epoch: 6| Step: 3
Training loss: 1.8694002628326416
Validation loss: 1.9935797696472497

Epoch: 6| Step: 4
Training loss: 2.7439260482788086
Validation loss: 1.999723562630274

Epoch: 6| Step: 5
Training loss: 3.0199499130249023
Validation loss: 1.9908295575008597

Epoch: 6| Step: 6
Training loss: 2.5245025157928467
Validation loss: 1.9916585901732087

Epoch: 6| Step: 7
Training loss: 1.9250857830047607
Validation loss: 1.9959013692794307

Epoch: 6| Step: 8
Training loss: 2.5344412326812744
Validation loss: 1.991305225638933

Epoch: 6| Step: 9
Training loss: 2.014439105987549
Validation loss: 1.9686167650325324

Epoch: 6| Step: 10
Training loss: 2.115267276763916
Validation loss: 1.9734763612029373

Epoch: 6| Step: 11
Training loss: 2.045063018798828
Validation loss: 1.9762274872872136

Epoch: 6| Step: 12
Training loss: 1.7404781579971313
Validation loss: 2.007539059526177

Epoch: 6| Step: 13
Training loss: 2.5921971797943115
Validation loss: 2.0371596172291744

Epoch: 80| Step: 0
Training loss: 2.157316207885742
Validation loss: 2.0247215840124313

Epoch: 6| Step: 1
Training loss: 1.989266037940979
Validation loss: 2.040693272826492

Epoch: 6| Step: 2
Training loss: 2.8412697315216064
Validation loss: 2.046112609165971

Epoch: 6| Step: 3
Training loss: 2.7480103969573975
Validation loss: 2.0359199739271596

Epoch: 6| Step: 4
Training loss: 1.8768376111984253
Validation loss: 2.030349531481343

Epoch: 6| Step: 5
Training loss: 2.7240891456604004
Validation loss: 2.0063783045737975

Epoch: 6| Step: 6
Training loss: 2.8064699172973633
Validation loss: 1.9678704584798505

Epoch: 6| Step: 7
Training loss: 2.3138766288757324
Validation loss: 1.9576039852634552

Epoch: 6| Step: 8
Training loss: 2.291330337524414
Validation loss: 1.9630705374543385

Epoch: 6| Step: 9
Training loss: 2.2196803092956543
Validation loss: 1.9727415346330213

Epoch: 6| Step: 10
Training loss: 1.0468807220458984
Validation loss: 1.987477171805597

Epoch: 6| Step: 11
Training loss: 2.4874229431152344
Validation loss: 1.9954254037590438

Epoch: 6| Step: 12
Training loss: 2.222170114517212
Validation loss: 1.9982362024245723

Epoch: 6| Step: 13
Training loss: 2.541180372238159
Validation loss: 1.9912309492788007

Epoch: 81| Step: 0
Training loss: 2.030635356903076
Validation loss: 1.9612801651800833

Epoch: 6| Step: 1
Training loss: 2.3326568603515625
Validation loss: 1.9517545828255274

Epoch: 6| Step: 2
Training loss: 2.436349391937256
Validation loss: 2.0182460597766343

Epoch: 6| Step: 3
Training loss: 2.282705783843994
Validation loss: 2.1375726717774586

Epoch: 6| Step: 4
Training loss: 2.677276372909546
Validation loss: 2.245982687960389

Epoch: 6| Step: 5
Training loss: 2.340970993041992
Validation loss: 2.3008382294767644

Epoch: 6| Step: 6
Training loss: 2.0960264205932617
Validation loss: 2.34898437992219

Epoch: 6| Step: 7
Training loss: 2.9461348056793213
Validation loss: 2.261463216556016

Epoch: 6| Step: 8
Training loss: 2.1547188758850098
Validation loss: 2.14964452866585

Epoch: 6| Step: 9
Training loss: 2.3667516708374023
Validation loss: 2.0422380291005617

Epoch: 6| Step: 10
Training loss: 1.7858343124389648
Validation loss: 1.993945570402248

Epoch: 6| Step: 11
Training loss: 3.3264236450195312
Validation loss: 1.9581926535534602

Epoch: 6| Step: 12
Training loss: 1.886411190032959
Validation loss: 1.968207263177441

Epoch: 6| Step: 13
Training loss: 2.6113226413726807
Validation loss: 1.9924860769702541

Epoch: 82| Step: 0
Training loss: 2.171447992324829
Validation loss: 2.0198074707420925

Epoch: 6| Step: 1
Training loss: 2.2162442207336426
Validation loss: 2.015510138644967

Epoch: 6| Step: 2
Training loss: 3.1755125522613525
Validation loss: 2.004819646958382

Epoch: 6| Step: 3
Training loss: 2.807689666748047
Validation loss: 1.9930355241221767

Epoch: 6| Step: 4
Training loss: 2.1528382301330566
Validation loss: 1.97878937567434

Epoch: 6| Step: 5
Training loss: 2.7328546047210693
Validation loss: 1.9787774983272757

Epoch: 6| Step: 6
Training loss: 2.449687957763672
Validation loss: 1.9805925456426476

Epoch: 6| Step: 7
Training loss: 2.2445220947265625
Validation loss: 1.9850321046767696

Epoch: 6| Step: 8
Training loss: 2.5671744346618652
Validation loss: 1.9880737976361347

Epoch: 6| Step: 9
Training loss: 0.833549439907074
Validation loss: 2.021174689774872

Epoch: 6| Step: 10
Training loss: 2.1606760025024414
Validation loss: 2.020454704120595

Epoch: 6| Step: 11
Training loss: 2.5280251502990723
Validation loss: 2.0305111664597706

Epoch: 6| Step: 12
Training loss: 1.8561631441116333
Validation loss: 2.018428776853828

Epoch: 6| Step: 13
Training loss: 2.947382926940918
Validation loss: 2.0345763416700464

Epoch: 83| Step: 0
Training loss: 2.3629634380340576
Validation loss: 2.0315167468081237

Epoch: 6| Step: 1
Training loss: 2.8452816009521484
Validation loss: 2.0487320551308255

Epoch: 6| Step: 2
Training loss: 1.6935412883758545
Validation loss: 2.0499146779378257

Epoch: 6| Step: 3
Training loss: 2.6117966175079346
Validation loss: 2.0482995612646944

Epoch: 6| Step: 4
Training loss: 1.6950552463531494
Validation loss: 2.040074222831316

Epoch: 6| Step: 5
Training loss: 1.8279595375061035
Validation loss: 2.0402056183866275

Epoch: 6| Step: 6
Training loss: 1.1580077409744263
Validation loss: 2.029276861939379

Epoch: 6| Step: 7
Training loss: 2.605381488800049
Validation loss: 2.0162801229825584

Epoch: 6| Step: 8
Training loss: 2.8744101524353027
Validation loss: 1.9968360444550872

Epoch: 6| Step: 9
Training loss: 2.5537192821502686
Validation loss: 1.9700560377490135

Epoch: 6| Step: 10
Training loss: 2.2222070693969727
Validation loss: 1.9506545054015292

Epoch: 6| Step: 11
Training loss: 2.1128203868865967
Validation loss: 1.9606715094658635

Epoch: 6| Step: 12
Training loss: 2.33227276802063
Validation loss: 1.9558850783173756

Epoch: 6| Step: 13
Training loss: 3.1063928604125977
Validation loss: 1.9566100156435402

Epoch: 84| Step: 0
Training loss: 2.1798877716064453
Validation loss: 1.9568694586394935

Epoch: 6| Step: 1
Training loss: 2.53936767578125
Validation loss: 1.9820695461765412

Epoch: 6| Step: 2
Training loss: 2.550549268722534
Validation loss: 2.004497330675843

Epoch: 6| Step: 3
Training loss: 2.2130961418151855
Validation loss: 2.012131146205369

Epoch: 6| Step: 4
Training loss: 2.576874017715454
Validation loss: 2.0027459590665755

Epoch: 6| Step: 5
Training loss: 2.2041757106781006
Validation loss: 2.0112485219073553

Epoch: 6| Step: 6
Training loss: 2.4556217193603516
Validation loss: 1.9966507496372345

Epoch: 6| Step: 7
Training loss: 2.5546951293945312
Validation loss: 2.021392350555748

Epoch: 6| Step: 8
Training loss: 2.167088508605957
Validation loss: 2.05102442156884

Epoch: 6| Step: 9
Training loss: 1.4928395748138428
Validation loss: 2.071781043083437

Epoch: 6| Step: 10
Training loss: 2.764620304107666
Validation loss: 2.0868965553981003

Epoch: 6| Step: 11
Training loss: 2.1141254901885986
Validation loss: 2.0756995549765964

Epoch: 6| Step: 12
Training loss: 2.239136219024658
Validation loss: 2.0520292046249553

Epoch: 6| Step: 13
Training loss: 2.0447616577148438
Validation loss: 2.0279993780197634

Epoch: 85| Step: 0
Training loss: 2.2459163665771484
Validation loss: 2.016108651315012

Epoch: 6| Step: 1
Training loss: 2.257507085800171
Validation loss: 1.994072816705191

Epoch: 6| Step: 2
Training loss: 2.344036340713501
Validation loss: 2.0112213896166895

Epoch: 6| Step: 3
Training loss: 2.355109214782715
Validation loss: 2.024348129508316

Epoch: 6| Step: 4
Training loss: 2.390209436416626
Validation loss: 2.0084497441527662

Epoch: 6| Step: 5
Training loss: 2.28922700881958
Validation loss: 1.9956912238110778

Epoch: 6| Step: 6
Training loss: 2.6341052055358887
Validation loss: 2.0021735186217935

Epoch: 6| Step: 7
Training loss: 1.7833164930343628
Validation loss: 2.014509795814432

Epoch: 6| Step: 8
Training loss: 2.485490083694458
Validation loss: 2.019212697141914

Epoch: 6| Step: 9
Training loss: 2.5792651176452637
Validation loss: 2.0470317050974858

Epoch: 6| Step: 10
Training loss: 2.531412124633789
Validation loss: 2.0518081470202376

Epoch: 6| Step: 11
Training loss: 2.0708069801330566
Validation loss: 2.0348559771814654

Epoch: 6| Step: 12
Training loss: 1.8345067501068115
Validation loss: 2.0557517800279843

Epoch: 6| Step: 13
Training loss: 2.025740623474121
Validation loss: 2.052632035747651

Epoch: 86| Step: 0
Training loss: 3.3815202713012695
Validation loss: 2.0387565640993017

Epoch: 6| Step: 1
Training loss: 1.8011363744735718
Validation loss: 2.035007994662049

Epoch: 6| Step: 2
Training loss: 1.929682731628418
Validation loss: 2.0249945758491434

Epoch: 6| Step: 3
Training loss: 1.2468700408935547
Validation loss: 2.024045532749545

Epoch: 6| Step: 4
Training loss: 1.7287684679031372
Validation loss: 1.9874169493234286

Epoch: 6| Step: 5
Training loss: 3.0214128494262695
Validation loss: 1.9873206589811592

Epoch: 6| Step: 6
Training loss: 1.7875807285308838
Validation loss: 1.9956530832475232

Epoch: 6| Step: 7
Training loss: 2.6884260177612305
Validation loss: 2.01291988741967

Epoch: 6| Step: 8
Training loss: 2.027437210083008
Validation loss: 2.056212441895598

Epoch: 6| Step: 9
Training loss: 2.0584144592285156
Validation loss: 2.0851101644577517

Epoch: 6| Step: 10
Training loss: 2.8928275108337402
Validation loss: 2.056013430318525

Epoch: 6| Step: 11
Training loss: 2.77398681640625
Validation loss: 2.042910183629682

Epoch: 6| Step: 12
Training loss: 2.3158411979675293
Validation loss: 2.0072032020938013

Epoch: 6| Step: 13
Training loss: 2.0643703937530518
Validation loss: 1.9837527364812872

Epoch: 87| Step: 0
Training loss: 2.3489718437194824
Validation loss: 1.9676032835437405

Epoch: 6| Step: 1
Training loss: 1.827318787574768
Validation loss: 1.9477183267634401

Epoch: 6| Step: 2
Training loss: 3.078726291656494
Validation loss: 1.9667798947262507

Epoch: 6| Step: 3
Training loss: 2.474245071411133
Validation loss: 1.9813400647973503

Epoch: 6| Step: 4
Training loss: 1.2556581497192383
Validation loss: 2.0616633071694324

Epoch: 6| Step: 5
Training loss: 2.4272866249084473
Validation loss: 2.1238663927201302

Epoch: 6| Step: 6
Training loss: 3.0928640365600586
Validation loss: 2.171965652896512

Epoch: 6| Step: 7
Training loss: 2.6589877605438232
Validation loss: 2.159329088785315

Epoch: 6| Step: 8
Training loss: 2.375308036804199
Validation loss: 2.1171244472585697

Epoch: 6| Step: 9
Training loss: 1.5173141956329346
Validation loss: 2.0421112942439255

Epoch: 6| Step: 10
Training loss: 2.9221179485321045
Validation loss: 1.979068281829998

Epoch: 6| Step: 11
Training loss: 1.3626196384429932
Validation loss: 1.9218477433727634

Epoch: 6| Step: 12
Training loss: 2.6871957778930664
Validation loss: 1.9305050860169113

Epoch: 6| Step: 13
Training loss: 2.4373254776000977
Validation loss: 1.948149186308666

Epoch: 88| Step: 0
Training loss: 2.4088122844696045
Validation loss: 1.968181953635267

Epoch: 6| Step: 1
Training loss: 2.1347832679748535
Validation loss: 1.982238418312483

Epoch: 6| Step: 2
Training loss: 1.6500004529953003
Validation loss: 1.970845773655881

Epoch: 6| Step: 3
Training loss: 1.938279151916504
Validation loss: 1.9781999459830664

Epoch: 6| Step: 4
Training loss: 2.3367977142333984
Validation loss: 1.9632610826082126

Epoch: 6| Step: 5
Training loss: 2.289691686630249
Validation loss: 1.9640969576374177

Epoch: 6| Step: 6
Training loss: 2.8623576164245605
Validation loss: 1.9584195344678816

Epoch: 6| Step: 7
Training loss: 2.2225499153137207
Validation loss: 1.9612476107894734

Epoch: 6| Step: 8
Training loss: 2.1154603958129883
Validation loss: 1.9795483722481677

Epoch: 6| Step: 9
Training loss: 1.9963090419769287
Validation loss: 2.00803461382466

Epoch: 6| Step: 10
Training loss: 2.949319362640381
Validation loss: 2.051268204565971

Epoch: 6| Step: 11
Training loss: 2.104544162750244
Validation loss: 2.053292638512068

Epoch: 6| Step: 12
Training loss: 2.6345407962799072
Validation loss: 2.0229139904822073

Epoch: 6| Step: 13
Training loss: 3.5212881565093994
Validation loss: 1.9871444804694063

Epoch: 89| Step: 0
Training loss: 2.500458240509033
Validation loss: 1.9757773158370808

Epoch: 6| Step: 1
Training loss: 1.4040533304214478
Validation loss: 1.9642315513344222

Epoch: 6| Step: 2
Training loss: 2.9654948711395264
Validation loss: 1.9736086219869635

Epoch: 6| Step: 3
Training loss: 2.476644992828369
Validation loss: 1.9831795769353067

Epoch: 6| Step: 4
Training loss: 2.157170295715332
Validation loss: 1.991902764125537

Epoch: 6| Step: 5
Training loss: 2.1949636936187744
Validation loss: 1.9868732395992483

Epoch: 6| Step: 6
Training loss: 2.0924572944641113
Validation loss: 1.9596717460181123

Epoch: 6| Step: 7
Training loss: 2.022045850753784
Validation loss: 1.955119627778248

Epoch: 6| Step: 8
Training loss: 1.4460333585739136
Validation loss: 1.9441070582277031

Epoch: 6| Step: 9
Training loss: 2.1985931396484375
Validation loss: 1.9511623728659846

Epoch: 6| Step: 10
Training loss: 2.7779273986816406
Validation loss: 1.9561199090814079

Epoch: 6| Step: 11
Training loss: 2.471193790435791
Validation loss: 1.9628715104954217

Epoch: 6| Step: 12
Training loss: 2.0458743572235107
Validation loss: 1.9626063082807808

Epoch: 6| Step: 13
Training loss: 2.6959388256073
Validation loss: 1.963650712402918

Epoch: 90| Step: 0
Training loss: 2.5301873683929443
Validation loss: 1.9742273771634666

Epoch: 6| Step: 1
Training loss: 1.5873045921325684
Validation loss: 1.9840488882475003

Epoch: 6| Step: 2
Training loss: 2.0403878688812256
Validation loss: 1.9863892139927033

Epoch: 6| Step: 3
Training loss: 1.7887818813323975
Validation loss: 1.9917513888369325

Epoch: 6| Step: 4
Training loss: 2.0353968143463135
Validation loss: 1.9932771254611272

Epoch: 6| Step: 5
Training loss: 2.3144683837890625
Validation loss: 1.9905449728811941

Epoch: 6| Step: 6
Training loss: 2.3157360553741455
Validation loss: 1.9995372321016045

Epoch: 6| Step: 7
Training loss: 2.376521110534668
Validation loss: 1.9948167134356756

Epoch: 6| Step: 8
Training loss: 2.408923625946045
Validation loss: 1.9921532459156488

Epoch: 6| Step: 9
Training loss: 1.5931837558746338
Validation loss: 1.997979369214786

Epoch: 6| Step: 10
Training loss: 2.956618309020996
Validation loss: 1.9769030232583322

Epoch: 6| Step: 11
Training loss: 2.0936691761016846
Validation loss: 1.974018172551227

Epoch: 6| Step: 12
Training loss: 2.7515647411346436
Validation loss: 1.973122299358409

Epoch: 6| Step: 13
Training loss: 2.407701253890991
Validation loss: 1.9685776387491534

Epoch: 91| Step: 0
Training loss: 2.3735437393188477
Validation loss: 1.9689224778964955

Epoch: 6| Step: 1
Training loss: 2.3046813011169434
Validation loss: 1.975228448067942

Epoch: 6| Step: 2
Training loss: 2.4215097427368164
Validation loss: 2.0003194424413864

Epoch: 6| Step: 3
Training loss: 2.2394895553588867
Validation loss: 1.991624254052357

Epoch: 6| Step: 4
Training loss: 3.2859764099121094
Validation loss: 1.9946728880687425

Epoch: 6| Step: 5
Training loss: 1.8798725605010986
Validation loss: 2.005601376615545

Epoch: 6| Step: 6
Training loss: 2.32912015914917
Validation loss: 2.0059733339535293

Epoch: 6| Step: 7
Training loss: 1.6519484519958496
Validation loss: 2.022060486578172

Epoch: 6| Step: 8
Training loss: 2.410656452178955
Validation loss: 2.0170333423922138

Epoch: 6| Step: 9
Training loss: 2.199132204055786
Validation loss: 2.012948883477078

Epoch: 6| Step: 10
Training loss: 1.6314985752105713
Validation loss: 2.0110302484163673

Epoch: 6| Step: 11
Training loss: 1.9834729433059692
Validation loss: 2.012887744493382

Epoch: 6| Step: 12
Training loss: 2.4587244987487793
Validation loss: 2.0038764271684872

Epoch: 6| Step: 13
Training loss: 1.3308277130126953
Validation loss: 1.9982621592860068

Epoch: 92| Step: 0
Training loss: 2.5196657180786133
Validation loss: 1.9914303479656097

Epoch: 6| Step: 1
Training loss: 2.0673115253448486
Validation loss: 1.987740264143995

Epoch: 6| Step: 2
Training loss: 2.197089195251465
Validation loss: 1.9941786053360149

Epoch: 6| Step: 3
Training loss: 2.7406020164489746
Validation loss: 2.0298508136503157

Epoch: 6| Step: 4
Training loss: 2.1758038997650146
Validation loss: 2.046859843756563

Epoch: 6| Step: 5
Training loss: 2.326030731201172
Validation loss: 2.0127272170077086

Epoch: 6| Step: 6
Training loss: 2.636428117752075
Validation loss: 1.9916923635749406

Epoch: 6| Step: 7
Training loss: 1.4095220565795898
Validation loss: 1.974152672675348

Epoch: 6| Step: 8
Training loss: 2.4078216552734375
Validation loss: 1.9794373396904237

Epoch: 6| Step: 9
Training loss: 2.819181442260742
Validation loss: 2.01512356855536

Epoch: 6| Step: 10
Training loss: 2.0609748363494873
Validation loss: 2.037103781136133

Epoch: 6| Step: 11
Training loss: 1.6449648141860962
Validation loss: 2.0492837531592256

Epoch: 6| Step: 12
Training loss: 1.786963939666748
Validation loss: 2.0253908121457664

Epoch: 6| Step: 13
Training loss: 2.7335922718048096
Validation loss: 2.016519543945148

Epoch: 93| Step: 0
Training loss: 2.4114246368408203
Validation loss: 2.000644042927732

Epoch: 6| Step: 1
Training loss: 2.306037187576294
Validation loss: 1.9774485403491604

Epoch: 6| Step: 2
Training loss: 2.061439037322998
Validation loss: 1.9800916564080022

Epoch: 6| Step: 3
Training loss: 2.5734386444091797
Validation loss: 2.001297236770712

Epoch: 6| Step: 4
Training loss: 2.331821918487549
Validation loss: 1.9915551524008475

Epoch: 6| Step: 5
Training loss: 2.1733789443969727
Validation loss: 1.9752537640192176

Epoch: 6| Step: 6
Training loss: 1.9212346076965332
Validation loss: 1.9663080502581853

Epoch: 6| Step: 7
Training loss: 2.3271751403808594
Validation loss: 1.9492480754852295

Epoch: 6| Step: 8
Training loss: 1.5141698122024536
Validation loss: 1.9648619082666212

Epoch: 6| Step: 9
Training loss: 2.4775800704956055
Validation loss: 1.9903932348374398

Epoch: 6| Step: 10
Training loss: 2.1214442253112793
Validation loss: 2.036946823520045

Epoch: 6| Step: 11
Training loss: 2.622835159301758
Validation loss: 2.079658931301486

Epoch: 6| Step: 12
Training loss: 2.6935911178588867
Validation loss: 2.1113505889010686

Epoch: 6| Step: 13
Training loss: 2.0406312942504883
Validation loss: 2.1272929996572514

Epoch: 94| Step: 0
Training loss: 2.309324264526367
Validation loss: 2.1384477846084105

Epoch: 6| Step: 1
Training loss: 1.9782739877700806
Validation loss: 2.1186517489853727

Epoch: 6| Step: 2
Training loss: 2.015885353088379
Validation loss: 2.0739153944036013

Epoch: 6| Step: 3
Training loss: 2.43623423576355
Validation loss: 1.9789248371636996

Epoch: 6| Step: 4
Training loss: 2.4200425148010254
Validation loss: 1.9325048154400242

Epoch: 6| Step: 5
Training loss: 2.7362797260284424
Validation loss: 1.9213179362717496

Epoch: 6| Step: 6
Training loss: 2.3040804862976074
Validation loss: 1.9180124934001634

Epoch: 6| Step: 7
Training loss: 1.8067419528961182
Validation loss: 1.931513342806088

Epoch: 6| Step: 8
Training loss: 2.6288723945617676
Validation loss: 1.9442158988727036

Epoch: 6| Step: 9
Training loss: 2.1318321228027344
Validation loss: 1.9446024971623574

Epoch: 6| Step: 10
Training loss: 1.826308250427246
Validation loss: 1.9426138683031964

Epoch: 6| Step: 11
Training loss: 2.372143030166626
Validation loss: 1.94562860842674

Epoch: 6| Step: 12
Training loss: 3.198904037475586
Validation loss: 1.9440624201169578

Epoch: 6| Step: 13
Training loss: 1.8082414865493774
Validation loss: 1.9333831212853874

Epoch: 95| Step: 0
Training loss: 1.8773071765899658
Validation loss: 1.9370433386935983

Epoch: 6| Step: 1
Training loss: 2.2904651165008545
Validation loss: 1.9645064582106888

Epoch: 6| Step: 2
Training loss: 2.4652721881866455
Validation loss: 1.9869206720782864

Epoch: 6| Step: 3
Training loss: 2.254289150238037
Validation loss: 2.0244051487215105

Epoch: 6| Step: 4
Training loss: 1.670111060142517
Validation loss: 2.043185063587722

Epoch: 6| Step: 5
Training loss: 2.1899168491363525
Validation loss: 2.0592764910831245

Epoch: 6| Step: 6
Training loss: 2.195037364959717
Validation loss: 2.0551211308407527

Epoch: 6| Step: 7
Training loss: 2.0527615547180176
Validation loss: 2.034751772880554

Epoch: 6| Step: 8
Training loss: 2.8657336235046387
Validation loss: 2.0043946786593367

Epoch: 6| Step: 9
Training loss: 2.7701125144958496
Validation loss: 1.9840320207739388

Epoch: 6| Step: 10
Training loss: 1.8888742923736572
Validation loss: 1.9727482026623142

Epoch: 6| Step: 11
Training loss: 2.23237943649292
Validation loss: 1.992809622518478

Epoch: 6| Step: 12
Training loss: 2.5640573501586914
Validation loss: 2.0076351319589922

Epoch: 6| Step: 13
Training loss: 1.9212069511413574
Validation loss: 2.0021147830511934

Epoch: 96| Step: 0
Training loss: 2.1094727516174316
Validation loss: 2.0083512606159335

Epoch: 6| Step: 1
Training loss: 2.564115524291992
Validation loss: 2.0144702926758797

Epoch: 6| Step: 2
Training loss: 2.9501793384552
Validation loss: 2.0504735746691303

Epoch: 6| Step: 3
Training loss: 2.254265069961548
Validation loss: 2.0868177785668323

Epoch: 6| Step: 4
Training loss: 2.3940043449401855
Validation loss: 2.060617011080506

Epoch: 6| Step: 5
Training loss: 2.2310781478881836
Validation loss: 2.05798174488929

Epoch: 6| Step: 6
Training loss: 1.9384675025939941
Validation loss: 2.0111291793084916

Epoch: 6| Step: 7
Training loss: 2.728468418121338
Validation loss: 2.0335427740568757

Epoch: 6| Step: 8
Training loss: 2.336836814880371
Validation loss: 2.0583390920392928

Epoch: 6| Step: 9
Training loss: 2.060697078704834
Validation loss: 2.025148296868929

Epoch: 6| Step: 10
Training loss: 1.76316499710083
Validation loss: 2.0003991114195956

Epoch: 6| Step: 11
Training loss: 2.3878836631774902
Validation loss: 1.9814457175552205

Epoch: 6| Step: 12
Training loss: 2.074986457824707
Validation loss: 1.9885505758306032

Epoch: 6| Step: 13
Training loss: 1.731924057006836
Validation loss: 1.9830635132328156

Epoch: 97| Step: 0
Training loss: 2.9355874061584473
Validation loss: 1.981552477805845

Epoch: 6| Step: 1
Training loss: 1.9465715885162354
Validation loss: 1.964862633776921

Epoch: 6| Step: 2
Training loss: 2.8587286472320557
Validation loss: 1.9773139569067186

Epoch: 6| Step: 3
Training loss: 2.1276321411132812
Validation loss: 1.9755835507505684

Epoch: 6| Step: 4
Training loss: 2.096633195877075
Validation loss: 1.9795853950644051

Epoch: 6| Step: 5
Training loss: 1.8103185892105103
Validation loss: 1.9742172610375188

Epoch: 6| Step: 6
Training loss: 1.9468597173690796
Validation loss: 1.9741036456118348

Epoch: 6| Step: 7
Training loss: 2.9355266094207764
Validation loss: 1.9617688835308116

Epoch: 6| Step: 8
Training loss: 2.675942897796631
Validation loss: 1.9630169971014864

Epoch: 6| Step: 9
Training loss: 1.7601969242095947
Validation loss: 1.9614385276712396

Epoch: 6| Step: 10
Training loss: 1.4577339887619019
Validation loss: 1.9493211084796536

Epoch: 6| Step: 11
Training loss: 2.0027923583984375
Validation loss: 1.9593339274006505

Epoch: 6| Step: 12
Training loss: 2.2062716484069824
Validation loss: 1.9673829360674786

Epoch: 6| Step: 13
Training loss: 1.752402424812317
Validation loss: 1.9509347023502472

Epoch: 98| Step: 0
Training loss: 2.4730567932128906
Validation loss: 1.972690213111139

Epoch: 6| Step: 1
Training loss: 2.442265510559082
Validation loss: 1.9649490412845407

Epoch: 6| Step: 2
Training loss: 1.9294477701187134
Validation loss: 1.9589948705447617

Epoch: 6| Step: 3
Training loss: 2.367443561553955
Validation loss: 1.9268865457145117

Epoch: 6| Step: 4
Training loss: 2.6890406608581543
Validation loss: 1.9081516522233204

Epoch: 6| Step: 5
Training loss: 1.7643152475357056
Validation loss: 1.9005677776951944

Epoch: 6| Step: 6
Training loss: 1.826113224029541
Validation loss: 1.9058640131386377

Epoch: 6| Step: 7
Training loss: 2.02846097946167
Validation loss: 1.8950933769185057

Epoch: 6| Step: 8
Training loss: 2.052313804626465
Validation loss: 1.9009785113796112

Epoch: 6| Step: 9
Training loss: 2.870701551437378
Validation loss: 1.9057356516520183

Epoch: 6| Step: 10
Training loss: 2.1507508754730225
Validation loss: 1.9046227803794287

Epoch: 6| Step: 11
Training loss: 1.9675562381744385
Validation loss: 1.9202925902540966

Epoch: 6| Step: 12
Training loss: 2.0689215660095215
Validation loss: 1.9221763828749299

Epoch: 6| Step: 13
Training loss: 2.0568418502807617
Validation loss: 1.9359081855384253

Epoch: 99| Step: 0
Training loss: 2.787243127822876
Validation loss: 1.9754606523821432

Epoch: 6| Step: 1
Training loss: 2.7208993434906006
Validation loss: 1.998307772862014

Epoch: 6| Step: 2
Training loss: 2.8203635215759277
Validation loss: 2.019535462061564

Epoch: 6| Step: 3
Training loss: 2.0825724601745605
Validation loss: 2.0163121454177366

Epoch: 6| Step: 4
Training loss: 2.185711145401001
Validation loss: 2.034694854931165

Epoch: 6| Step: 5
Training loss: 1.9963572025299072
Validation loss: 2.042640596307734

Epoch: 6| Step: 6
Training loss: 1.6070311069488525
Validation loss: 2.0435599998761247

Epoch: 6| Step: 7
Training loss: 2.218752384185791
Validation loss: 2.032274703825674

Epoch: 6| Step: 8
Training loss: 2.2291553020477295
Validation loss: 2.036008829711586

Epoch: 6| Step: 9
Training loss: 1.4438551664352417
Validation loss: 2.026259285147472

Epoch: 6| Step: 10
Training loss: 2.268171787261963
Validation loss: 1.9985113784831057

Epoch: 6| Step: 11
Training loss: 1.6543552875518799
Validation loss: 1.9924696158337336

Epoch: 6| Step: 12
Training loss: 2.352057933807373
Validation loss: 1.9836042478520384

Epoch: 6| Step: 13
Training loss: 1.843759298324585
Validation loss: 1.9754207121428622

Epoch: 100| Step: 0
Training loss: 1.6357522010803223
Validation loss: 1.9611868012335993

Epoch: 6| Step: 1
Training loss: 2.451573610305786
Validation loss: 1.9578222895181308

Epoch: 6| Step: 2
Training loss: 1.8769726753234863
Validation loss: 1.9504217358045681

Epoch: 6| Step: 3
Training loss: 2.5874762535095215
Validation loss: 1.9414084188399776

Epoch: 6| Step: 4
Training loss: 2.213198184967041
Validation loss: 1.9488947288964384

Epoch: 6| Step: 5
Training loss: 2.3511362075805664
Validation loss: 1.9486108531234085

Epoch: 6| Step: 6
Training loss: 0.9011722207069397
Validation loss: 1.9584111064992926

Epoch: 6| Step: 7
Training loss: 2.479745864868164
Validation loss: 1.968640935036444

Epoch: 6| Step: 8
Training loss: 2.839829921722412
Validation loss: 1.975536113144249

Epoch: 6| Step: 9
Training loss: 2.3531341552734375
Validation loss: 1.9765889644622803

Epoch: 6| Step: 10
Training loss: 1.8188132047653198
Validation loss: 1.9876058998928274

Epoch: 6| Step: 11
Training loss: 1.8504340648651123
Validation loss: 1.9985857445706603

Epoch: 6| Step: 12
Training loss: 2.2151925563812256
Validation loss: 1.99711678489562

Epoch: 6| Step: 13
Training loss: 2.404067039489746
Validation loss: 1.9753675524906447

Epoch: 101| Step: 0
Training loss: 1.8862892389297485
Validation loss: 1.9577162534959855

Epoch: 6| Step: 1
Training loss: 1.392615795135498
Validation loss: 1.9957562492739769

Epoch: 6| Step: 2
Training loss: 2.327702045440674
Validation loss: 2.029253957092121

Epoch: 6| Step: 3
Training loss: 2.455186367034912
Validation loss: 2.0532041852192213

Epoch: 6| Step: 4
Training loss: 2.2299890518188477
Validation loss: 2.068113678245134

Epoch: 6| Step: 5
Training loss: 1.862156629562378
Validation loss: 2.0695423259530017

Epoch: 6| Step: 6
Training loss: 2.095561981201172
Validation loss: 2.093795904549219

Epoch: 6| Step: 7
Training loss: 2.088087797164917
Validation loss: 2.1360631988894556

Epoch: 6| Step: 8
Training loss: 2.7253451347351074
Validation loss: 2.17412704677992

Epoch: 6| Step: 9
Training loss: 1.6980117559432983
Validation loss: 2.1582309020462858

Epoch: 6| Step: 10
Training loss: 2.349424362182617
Validation loss: 2.1420506841392926

Epoch: 6| Step: 11
Training loss: 2.6435956954956055
Validation loss: 2.114396796431593

Epoch: 6| Step: 12
Training loss: 2.001326560974121
Validation loss: 2.084291209456741

Epoch: 6| Step: 13
Training loss: 2.948744773864746
Validation loss: 2.0299810042945285

Epoch: 102| Step: 0
Training loss: 2.5653696060180664
Validation loss: 1.98056209728282

Epoch: 6| Step: 1
Training loss: 2.068612575531006
Validation loss: 1.9448052516547583

Epoch: 6| Step: 2
Training loss: 1.9694130420684814
Validation loss: 1.9321076126508816

Epoch: 6| Step: 3
Training loss: 1.9825170040130615
Validation loss: 1.9128571364187426

Epoch: 6| Step: 4
Training loss: 2.2736573219299316
Validation loss: 1.9003512654253232

Epoch: 6| Step: 5
Training loss: 1.504621982574463
Validation loss: 1.8979875887593916

Epoch: 6| Step: 6
Training loss: 2.548801898956299
Validation loss: 1.9121409667435514

Epoch: 6| Step: 7
Training loss: 2.0313382148742676
Validation loss: 1.9323791919216033

Epoch: 6| Step: 8
Training loss: 2.225316286087036
Validation loss: 1.931162275293822

Epoch: 6| Step: 9
Training loss: 2.0077855587005615
Validation loss: 1.9215865558193577

Epoch: 6| Step: 10
Training loss: 1.6377209424972534
Validation loss: 1.904961896199052

Epoch: 6| Step: 11
Training loss: 3.348097801208496
Validation loss: 1.8993513071408836

Epoch: 6| Step: 12
Training loss: 1.5583508014678955
Validation loss: 1.9015039090187318

Epoch: 6| Step: 13
Training loss: 2.265963554382324
Validation loss: 1.9163899626783145

Epoch: 103| Step: 0
Training loss: 2.445517063140869
Validation loss: 1.9343136049086047

Epoch: 6| Step: 1
Training loss: 1.7744100093841553
Validation loss: 1.9390729140209895

Epoch: 6| Step: 2
Training loss: 2.5866448879241943
Validation loss: 1.9236967332901493

Epoch: 6| Step: 3
Training loss: 1.7874279022216797
Validation loss: 1.9203938168864096

Epoch: 6| Step: 4
Training loss: 1.5251363515853882
Validation loss: 1.9339374649909236

Epoch: 6| Step: 5
Training loss: 2.5471067428588867
Validation loss: 1.945742457143722

Epoch: 6| Step: 6
Training loss: 2.5014686584472656
Validation loss: 1.9809761303727345

Epoch: 6| Step: 7
Training loss: 2.1551597118377686
Validation loss: 2.0067802936800065

Epoch: 6| Step: 8
Training loss: 1.8949462175369263
Validation loss: 2.008620436473559

Epoch: 6| Step: 9
Training loss: 1.5717215538024902
Validation loss: 2.0117559971347934

Epoch: 6| Step: 10
Training loss: 2.4521212577819824
Validation loss: 2.025441610684959

Epoch: 6| Step: 11
Training loss: 1.5420682430267334
Validation loss: 2.015467687319684

Epoch: 6| Step: 12
Training loss: 2.1010308265686035
Validation loss: 2.0172644892046527

Epoch: 6| Step: 13
Training loss: 2.1650936603546143
Validation loss: 1.9902232321359778

Epoch: 104| Step: 0
Training loss: 2.0104854106903076
Validation loss: 1.9758838203645521

Epoch: 6| Step: 1
Training loss: 2.1668753623962402
Validation loss: 1.9774999387802616

Epoch: 6| Step: 2
Training loss: 2.6380362510681152
Validation loss: 1.9777320892580095

Epoch: 6| Step: 3
Training loss: 1.7461299896240234
Validation loss: 1.9679258856722104

Epoch: 6| Step: 4
Training loss: 1.9984599351882935
Validation loss: 1.967268991213973

Epoch: 6| Step: 5
Training loss: 1.6742660999298096
Validation loss: 1.9561459402884207

Epoch: 6| Step: 6
Training loss: 2.0400755405426025
Validation loss: 1.9546681860441804

Epoch: 6| Step: 7
Training loss: 2.0764594078063965
Validation loss: 1.9338247545303837

Epoch: 6| Step: 8
Training loss: 1.8583546876907349
Validation loss: 1.9299237112845145

Epoch: 6| Step: 9
Training loss: 1.4207885265350342
Validation loss: 1.937719229728945

Epoch: 6| Step: 10
Training loss: 2.3465914726257324
Validation loss: 1.936263535612373

Epoch: 6| Step: 11
Training loss: 2.4244048595428467
Validation loss: 1.9585060406756658

Epoch: 6| Step: 12
Training loss: 2.2443442344665527
Validation loss: 1.9575825481004612

Epoch: 6| Step: 13
Training loss: 2.4112071990966797
Validation loss: 1.9374345771728023

Epoch: 105| Step: 0
Training loss: 2.3954501152038574
Validation loss: 1.9433039337076166

Epoch: 6| Step: 1
Training loss: 1.5319199562072754
Validation loss: 1.9378591173438615

Epoch: 6| Step: 2
Training loss: 2.727579116821289
Validation loss: 1.9274924634605326

Epoch: 6| Step: 3
Training loss: 2.2730965614318848
Validation loss: 1.9236951207601896

Epoch: 6| Step: 4
Training loss: 1.93351149559021
Validation loss: 1.9340855254921863

Epoch: 6| Step: 5
Training loss: 1.8160282373428345
Validation loss: 1.9356695836590183

Epoch: 6| Step: 6
Training loss: 2.1583282947540283
Validation loss: 1.9318872087745256

Epoch: 6| Step: 7
Training loss: 1.8474793434143066
Validation loss: 1.9488731353513655

Epoch: 6| Step: 8
Training loss: 2.214448928833008
Validation loss: 1.9623934440715338

Epoch: 6| Step: 9
Training loss: 1.9467716217041016
Validation loss: 1.9693582468135382

Epoch: 6| Step: 10
Training loss: 1.3863863945007324
Validation loss: 1.9526814465881677

Epoch: 6| Step: 11
Training loss: 2.4997520446777344
Validation loss: 1.9712149635437997

Epoch: 6| Step: 12
Training loss: 2.0152029991149902
Validation loss: 1.9585027105064803

Epoch: 6| Step: 13
Training loss: 1.845776915550232
Validation loss: 1.9541805892862298

Epoch: 106| Step: 0
Training loss: 2.171055793762207
Validation loss: 1.9368754689411452

Epoch: 6| Step: 1
Training loss: 2.058560371398926
Validation loss: 1.9514439413624425

Epoch: 6| Step: 2
Training loss: 2.0497846603393555
Validation loss: 1.931445688329717

Epoch: 6| Step: 3
Training loss: 1.999345064163208
Validation loss: 1.9300624914066766

Epoch: 6| Step: 4
Training loss: 2.221841812133789
Validation loss: 1.9209710641573834

Epoch: 6| Step: 5
Training loss: 2.0418879985809326
Validation loss: 1.9194842230889104

Epoch: 6| Step: 6
Training loss: 2.4282891750335693
Validation loss: 1.9210904721290833

Epoch: 6| Step: 7
Training loss: 2.0286781787872314
Validation loss: 1.9350622725743118

Epoch: 6| Step: 8
Training loss: 2.690059185028076
Validation loss: 1.9303380212476176

Epoch: 6| Step: 9
Training loss: 0.9599012136459351
Validation loss: 1.9383994007623324

Epoch: 6| Step: 10
Training loss: 1.9439562559127808
Validation loss: 1.9543915282013595

Epoch: 6| Step: 11
Training loss: 1.7038627862930298
Validation loss: 1.9581117271095194

Epoch: 6| Step: 12
Training loss: 1.9023141860961914
Validation loss: 1.967772017243088

Epoch: 6| Step: 13
Training loss: 2.467986822128296
Validation loss: 1.9792583757831204

Epoch: 107| Step: 0
Training loss: 2.064990997314453
Validation loss: 1.9735516322556363

Epoch: 6| Step: 1
Training loss: 2.1105079650878906
Validation loss: 1.9664850811804495

Epoch: 6| Step: 2
Training loss: 1.8445041179656982
Validation loss: 1.9605976561064362

Epoch: 6| Step: 3
Training loss: 2.015394687652588
Validation loss: 1.9788325755826888

Epoch: 6| Step: 4
Training loss: 2.089747190475464
Validation loss: 1.9558650755113172

Epoch: 6| Step: 5
Training loss: 2.4635167121887207
Validation loss: 1.9608147054590204

Epoch: 6| Step: 6
Training loss: 1.9279260635375977
Validation loss: 1.947482821761921

Epoch: 6| Step: 7
Training loss: 2.513404369354248
Validation loss: 1.9379625781889884

Epoch: 6| Step: 8
Training loss: 1.7888548374176025
Validation loss: 1.9510191691819059

Epoch: 6| Step: 9
Training loss: 1.5534521341323853
Validation loss: 1.9669943650563557

Epoch: 6| Step: 10
Training loss: 1.235160231590271
Validation loss: 1.9782402323138328

Epoch: 6| Step: 11
Training loss: 1.9571878910064697
Validation loss: 1.9996024536830124

Epoch: 6| Step: 12
Training loss: 2.745166778564453
Validation loss: 1.9882526679705548

Epoch: 6| Step: 13
Training loss: 2.592104434967041
Validation loss: 1.9885286310667634

Epoch: 108| Step: 0
Training loss: 1.2270020246505737
Validation loss: 1.9830672843481905

Epoch: 6| Step: 1
Training loss: 1.4420199394226074
Validation loss: 1.9790403971108057

Epoch: 6| Step: 2
Training loss: 2.4237914085388184
Validation loss: 1.9844659374606224

Epoch: 6| Step: 3
Training loss: 1.9191465377807617
Validation loss: 1.9975103716696463

Epoch: 6| Step: 4
Training loss: 1.6619958877563477
Validation loss: 1.9874478578567505

Epoch: 6| Step: 5
Training loss: 2.1875717639923096
Validation loss: 2.012328791361983

Epoch: 6| Step: 6
Training loss: 2.365110397338867
Validation loss: 2.029636033119694

Epoch: 6| Step: 7
Training loss: 1.605863094329834
Validation loss: 2.042388682724327

Epoch: 6| Step: 8
Training loss: 2.1931965351104736
Validation loss: 2.020639938692893

Epoch: 6| Step: 9
Training loss: 2.636888027191162
Validation loss: 2.0121295836664017

Epoch: 6| Step: 10
Training loss: 2.2128405570983887
Validation loss: 1.9959470533555554

Epoch: 6| Step: 11
Training loss: 2.118535280227661
Validation loss: 1.9760486618165047

Epoch: 6| Step: 12
Training loss: 1.9035460948944092
Validation loss: 1.9465637232667656

Epoch: 6| Step: 13
Training loss: 2.346876859664917
Validation loss: 1.9396261963793027

Epoch: 109| Step: 0
Training loss: 2.5115554332733154
Validation loss: 1.9331076170808525

Epoch: 6| Step: 1
Training loss: 1.8385335206985474
Validation loss: 1.933618127658803

Epoch: 6| Step: 2
Training loss: 2.4535257816314697
Validation loss: 1.9428775771971671

Epoch: 6| Step: 3
Training loss: 1.1561102867126465
Validation loss: 1.9436244862053984

Epoch: 6| Step: 4
Training loss: 2.124525785446167
Validation loss: 1.938599540341285

Epoch: 6| Step: 5
Training loss: 1.5424809455871582
Validation loss: 1.927965138548164

Epoch: 6| Step: 6
Training loss: 2.0965511798858643
Validation loss: 1.9327101579276464

Epoch: 6| Step: 7
Training loss: 1.9880553483963013
Validation loss: 1.9438883540450886

Epoch: 6| Step: 8
Training loss: 2.348595380783081
Validation loss: 1.951823224303543

Epoch: 6| Step: 9
Training loss: 2.7290427684783936
Validation loss: 1.9553707530421596

Epoch: 6| Step: 10
Training loss: 1.5521163940429688
Validation loss: 1.9774608253150858

Epoch: 6| Step: 11
Training loss: 1.325953722000122
Validation loss: 1.9848623019392773

Epoch: 6| Step: 12
Training loss: 2.2062723636627197
Validation loss: 2.0208214739317536

Epoch: 6| Step: 13
Training loss: 2.224358558654785
Validation loss: 2.015919905836864

Epoch: 110| Step: 0
Training loss: 2.0624070167541504
Validation loss: 2.0352960760875414

Epoch: 6| Step: 1
Training loss: 2.123215913772583
Validation loss: 2.031637901900917

Epoch: 6| Step: 2
Training loss: 1.953261375427246
Validation loss: 2.008142034212748

Epoch: 6| Step: 3
Training loss: 2.4109716415405273
Validation loss: 2.0217202299384662

Epoch: 6| Step: 4
Training loss: 1.9413424730300903
Validation loss: 2.0049132749598515

Epoch: 6| Step: 5
Training loss: 1.6774320602416992
Validation loss: 1.9815284077839186

Epoch: 6| Step: 6
Training loss: 1.7985491752624512
Validation loss: 1.9835203539940618

Epoch: 6| Step: 7
Training loss: 1.6647411584854126
Validation loss: 1.9649764132756058

Epoch: 6| Step: 8
Training loss: 2.1200666427612305
Validation loss: 1.9569235053113712

Epoch: 6| Step: 9
Training loss: 2.078613519668579
Validation loss: 1.9436903474151448

Epoch: 6| Step: 10
Training loss: 1.7655482292175293
Validation loss: 1.9301051016776793

Epoch: 6| Step: 11
Training loss: 1.3160359859466553
Validation loss: 1.922951780339723

Epoch: 6| Step: 12
Training loss: 2.5361905097961426
Validation loss: 1.9344256424134778

Epoch: 6| Step: 13
Training loss: 2.227205514907837
Validation loss: 1.9508040310234152

Epoch: 111| Step: 0
Training loss: 1.6809141635894775
Validation loss: 1.9648785168124783

Epoch: 6| Step: 1
Training loss: 1.7306792736053467
Validation loss: 2.004217634918869

Epoch: 6| Step: 2
Training loss: 2.1285400390625
Validation loss: 2.0346994041114725

Epoch: 6| Step: 3
Training loss: 1.8324942588806152
Validation loss: 2.048121154949229

Epoch: 6| Step: 4
Training loss: 2.2462596893310547
Validation loss: 2.0695642655895603

Epoch: 6| Step: 5
Training loss: 2.248192310333252
Validation loss: 2.0739382774599138

Epoch: 6| Step: 6
Training loss: 1.7673923969268799
Validation loss: 2.099206542456022

Epoch: 6| Step: 7
Training loss: 2.7334704399108887
Validation loss: 2.066070492549609

Epoch: 6| Step: 8
Training loss: 1.7111538648605347
Validation loss: 2.054201986200066

Epoch: 6| Step: 9
Training loss: 2.057668685913086
Validation loss: 2.0471717260217153

Epoch: 6| Step: 10
Training loss: 1.4947054386138916
Validation loss: 2.0269708120694725

Epoch: 6| Step: 11
Training loss: 1.42055344581604
Validation loss: 2.0181122261990785

Epoch: 6| Step: 12
Training loss: 1.9704616069793701
Validation loss: 2.002616220904935

Epoch: 6| Step: 13
Training loss: 2.8287525177001953
Validation loss: 1.9959890560437274

Epoch: 112| Step: 0
Training loss: 1.939772129058838
Validation loss: 1.9817640499402118

Epoch: 6| Step: 1
Training loss: 2.2349488735198975
Validation loss: 1.9812613789753248

Epoch: 6| Step: 2
Training loss: 1.7286255359649658
Validation loss: 1.9830172177283996

Epoch: 6| Step: 3
Training loss: 2.119479179382324
Validation loss: 1.9818873277274511

Epoch: 6| Step: 4
Training loss: 2.033473014831543
Validation loss: 1.9732802273124777

Epoch: 6| Step: 5
Training loss: 2.142005681991577
Validation loss: 1.9766694807237195

Epoch: 6| Step: 6
Training loss: 1.915247917175293
Validation loss: 1.977216233489334

Epoch: 6| Step: 7
Training loss: 1.7726844549179077
Validation loss: 1.9765838628174157

Epoch: 6| Step: 8
Training loss: 1.2707374095916748
Validation loss: 1.9648428040166055

Epoch: 6| Step: 9
Training loss: 3.096050977706909
Validation loss: 2.0055795869519635

Epoch: 6| Step: 10
Training loss: 1.5157208442687988
Validation loss: 2.0494859308324833

Epoch: 6| Step: 11
Training loss: 1.818021535873413
Validation loss: 2.069468311084214

Epoch: 6| Step: 12
Training loss: 1.893764615058899
Validation loss: 2.0695482761629167

Epoch: 6| Step: 13
Training loss: 2.116380453109741
Validation loss: 2.058005604692685

Epoch: 113| Step: 0
Training loss: 2.453120231628418
Validation loss: 2.0541458386246876

Epoch: 6| Step: 1
Training loss: 2.1956260204315186
Validation loss: 2.010198995631228

Epoch: 6| Step: 2
Training loss: 2.0047786235809326
Validation loss: 1.9851561028470275

Epoch: 6| Step: 3
Training loss: 1.5845998525619507
Validation loss: 1.9588063275942238

Epoch: 6| Step: 4
Training loss: 2.150479316711426
Validation loss: 1.9483259070304133

Epoch: 6| Step: 5
Training loss: 2.0223915576934814
Validation loss: 1.936569962450253

Epoch: 6| Step: 6
Training loss: 1.9992949962615967
Validation loss: 1.9467482977015997

Epoch: 6| Step: 7
Training loss: 1.3429774045944214
Validation loss: 1.9690951467842184

Epoch: 6| Step: 8
Training loss: 0.7011607885360718
Validation loss: 1.9685984144928634

Epoch: 6| Step: 9
Training loss: 2.908060312271118
Validation loss: 1.9986426291927215

Epoch: 6| Step: 10
Training loss: 1.8907276391983032
Validation loss: 2.028397775465442

Epoch: 6| Step: 11
Training loss: 1.3857265710830688
Validation loss: 2.045208728441628

Epoch: 6| Step: 12
Training loss: 2.430546760559082
Validation loss: 2.0479425332879506

Epoch: 6| Step: 13
Training loss: 1.9455032348632812
Validation loss: 2.0514075909891436

Epoch: 114| Step: 0
Training loss: 1.4210622310638428
Validation loss: 2.0662162996107534

Epoch: 6| Step: 1
Training loss: 2.074587106704712
Validation loss: 2.056898227301977

Epoch: 6| Step: 2
Training loss: 1.8684468269348145
Validation loss: 2.059312556379585

Epoch: 6| Step: 3
Training loss: 1.3853154182434082
Validation loss: 2.0218840952842467

Epoch: 6| Step: 4
Training loss: 1.8742003440856934
Validation loss: 2.0161273966553392

Epoch: 6| Step: 5
Training loss: 2.32730770111084
Validation loss: 1.988456908092704

Epoch: 6| Step: 6
Training loss: 2.2933521270751953
Validation loss: 1.9843404216151084

Epoch: 6| Step: 7
Training loss: 1.3617823123931885
Validation loss: 1.9907475684278755

Epoch: 6| Step: 8
Training loss: 1.6494933366775513
Validation loss: 1.962815136037847

Epoch: 6| Step: 9
Training loss: 2.2204463481903076
Validation loss: 1.9700892445861653

Epoch: 6| Step: 10
Training loss: 2.41153621673584
Validation loss: 1.9938919646765596

Epoch: 6| Step: 11
Training loss: 2.0320260524749756
Validation loss: 2.0179101856805945

Epoch: 6| Step: 12
Training loss: 2.0596609115600586
Validation loss: 2.0017225409066803

Epoch: 6| Step: 13
Training loss: 2.8229360580444336
Validation loss: 1.9949573124608686

Epoch: 115| Step: 0
Training loss: 2.0413601398468018
Validation loss: 1.9760808419155818

Epoch: 6| Step: 1
Training loss: 1.3162033557891846
Validation loss: 1.9751607782097274

Epoch: 6| Step: 2
Training loss: 1.6749114990234375
Validation loss: 1.9648775528835993

Epoch: 6| Step: 3
Training loss: 1.8552812337875366
Validation loss: 1.972707397194319

Epoch: 6| Step: 4
Training loss: 1.8373517990112305
Validation loss: 1.9909853243058728

Epoch: 6| Step: 5
Training loss: 1.6412849426269531
Validation loss: 1.9900502748386835

Epoch: 6| Step: 6
Training loss: 1.689514398574829
Validation loss: 1.9985751118711246

Epoch: 6| Step: 7
Training loss: 2.28935170173645
Validation loss: 1.9953311233110325

Epoch: 6| Step: 8
Training loss: 1.9451041221618652
Validation loss: 1.9908897594739032

Epoch: 6| Step: 9
Training loss: 2.7762691974639893
Validation loss: 1.9917393192168205

Epoch: 6| Step: 10
Training loss: 1.3737037181854248
Validation loss: 1.9931580866536787

Epoch: 6| Step: 11
Training loss: 2.7576913833618164
Validation loss: 2.0236799358039774

Epoch: 6| Step: 12
Training loss: 2.015803813934326
Validation loss: 2.024374520906838

Epoch: 6| Step: 13
Training loss: 1.2237237691879272
Validation loss: 2.0077603850313412

Epoch: 116| Step: 0
Training loss: 2.551028251647949
Validation loss: 1.964159034913586

Epoch: 6| Step: 1
Training loss: 1.5937049388885498
Validation loss: 1.9590530331416796

Epoch: 6| Step: 2
Training loss: 2.045884370803833
Validation loss: 1.951557356824157

Epoch: 6| Step: 3
Training loss: 1.7736637592315674
Validation loss: 1.9728901488806612

Epoch: 6| Step: 4
Training loss: 2.1051297187805176
Validation loss: 1.962528641505908

Epoch: 6| Step: 5
Training loss: 2.096243381500244
Validation loss: 1.9389623608640445

Epoch: 6| Step: 6
Training loss: 1.7215008735656738
Validation loss: 1.9494594425283454

Epoch: 6| Step: 7
Training loss: 2.2075109481811523
Validation loss: 1.9616150035653064

Epoch: 6| Step: 8
Training loss: 2.1234240531921387
Validation loss: 1.9626313230042816

Epoch: 6| Step: 9
Training loss: 1.9135394096374512
Validation loss: 1.9500979351741012

Epoch: 6| Step: 10
Training loss: 1.8704335689544678
Validation loss: 1.9370129723702707

Epoch: 6| Step: 11
Training loss: 1.3445336818695068
Validation loss: 1.9258455320071148

Epoch: 6| Step: 12
Training loss: 1.5881571769714355
Validation loss: 1.9165964331678165

Epoch: 6| Step: 13
Training loss: 1.485789179801941
Validation loss: 1.9172913887167489

Epoch: 117| Step: 0
Training loss: 1.7863564491271973
Validation loss: 1.9124289738234652

Epoch: 6| Step: 1
Training loss: 1.7891145944595337
Validation loss: 1.9140918229215889

Epoch: 6| Step: 2
Training loss: 2.4947855472564697
Validation loss: 1.914182125881154

Epoch: 6| Step: 3
Training loss: 2.548004388809204
Validation loss: 1.9197967501096829

Epoch: 6| Step: 4
Training loss: 1.6201547384262085
Validation loss: 1.9409465277066795

Epoch: 6| Step: 5
Training loss: 1.4459648132324219
Validation loss: 1.940222329990838

Epoch: 6| Step: 6
Training loss: 1.682666301727295
Validation loss: 1.9623475151677285

Epoch: 6| Step: 7
Training loss: 1.6413006782531738
Validation loss: 1.9634021123250325

Epoch: 6| Step: 8
Training loss: 2.010814666748047
Validation loss: 1.9622322154301468

Epoch: 6| Step: 9
Training loss: 1.4939079284667969
Validation loss: 1.9727518789229854

Epoch: 6| Step: 10
Training loss: 1.9949666261672974
Validation loss: 1.9789804245835991

Epoch: 6| Step: 11
Training loss: 1.2547032833099365
Validation loss: 1.9824289045026224

Epoch: 6| Step: 12
Training loss: 2.0083370208740234
Validation loss: 1.9858206702816872

Epoch: 6| Step: 13
Training loss: 2.3598763942718506
Validation loss: 1.9995720258323095

Epoch: 118| Step: 0
Training loss: 1.997612714767456
Validation loss: 1.9770719043670162

Epoch: 6| Step: 1
Training loss: 1.3480188846588135
Validation loss: 1.9658846893618185

Epoch: 6| Step: 2
Training loss: 1.884028434753418
Validation loss: 1.9446079730987549

Epoch: 6| Step: 3
Training loss: 1.1226704120635986
Validation loss: 1.9364841445799796

Epoch: 6| Step: 4
Training loss: 1.8439476490020752
Validation loss: 1.930377742295624

Epoch: 6| Step: 5
Training loss: 1.544592261314392
Validation loss: 1.9272152018803421

Epoch: 6| Step: 6
Training loss: 1.6700981855392456
Validation loss: 1.9266949956135084

Epoch: 6| Step: 7
Training loss: 1.8621571063995361
Validation loss: 1.9348303105241509

Epoch: 6| Step: 8
Training loss: 2.0781517028808594
Validation loss: 1.9447225357896538

Epoch: 6| Step: 9
Training loss: 2.311215400695801
Validation loss: 1.955333209806873

Epoch: 6| Step: 10
Training loss: 2.2159035205841064
Validation loss: 1.9417926342256608

Epoch: 6| Step: 11
Training loss: 2.1446824073791504
Validation loss: 1.9274048356599705

Epoch: 6| Step: 12
Training loss: 1.795124888420105
Validation loss: 1.933662332514281

Epoch: 6| Step: 13
Training loss: 2.524592876434326
Validation loss: 1.9367554418502315

Epoch: 119| Step: 0
Training loss: 1.665961742401123
Validation loss: 1.9512155927637571

Epoch: 6| Step: 1
Training loss: 2.705397129058838
Validation loss: 1.9674657583236694

Epoch: 6| Step: 2
Training loss: 1.7425603866577148
Validation loss: 2.031392532010232

Epoch: 6| Step: 3
Training loss: 2.28344464302063
Validation loss: 2.050421158472697

Epoch: 6| Step: 4
Training loss: 1.9634597301483154
Validation loss: 2.0666317247575328

Epoch: 6| Step: 5
Training loss: 2.146923065185547
Validation loss: 2.0783642466350267

Epoch: 6| Step: 6
Training loss: 1.4336172342300415
Validation loss: 2.093416645962705

Epoch: 6| Step: 7
Training loss: 1.6125320196151733
Validation loss: 2.082207815621489

Epoch: 6| Step: 8
Training loss: 1.724977731704712
Validation loss: 2.088882835962439

Epoch: 6| Step: 9
Training loss: 1.9453223943710327
Validation loss: 2.0786857476798435

Epoch: 6| Step: 10
Training loss: 1.561457633972168
Validation loss: 2.063255689477408

Epoch: 6| Step: 11
Training loss: 2.143681526184082
Validation loss: 2.045486909086986

Epoch: 6| Step: 12
Training loss: 1.3263916969299316
Validation loss: 1.9976103177634619

Epoch: 6| Step: 13
Training loss: 2.697755813598633
Validation loss: 1.9367623200980566

Epoch: 120| Step: 0
Training loss: 1.431273102760315
Validation loss: 1.886170656450333

Epoch: 6| Step: 1
Training loss: 1.6590142250061035
Validation loss: 1.858238511188056

Epoch: 6| Step: 2
Training loss: 1.750331163406372
Validation loss: 1.8707846877395466

Epoch: 6| Step: 3
Training loss: 2.3946995735168457
Validation loss: 1.8783416696774062

Epoch: 6| Step: 4
Training loss: 2.1268668174743652
Validation loss: 1.8618371486663818

Epoch: 6| Step: 5
Training loss: 1.7682493925094604
Validation loss: 1.861937520324543

Epoch: 6| Step: 6
Training loss: 2.240062952041626
Validation loss: 1.8864824156607352

Epoch: 6| Step: 7
Training loss: 1.2377034425735474
Validation loss: 1.930297000433809

Epoch: 6| Step: 8
Training loss: 2.0154495239257812
Validation loss: 1.947571862128473

Epoch: 6| Step: 9
Training loss: 1.8647229671478271
Validation loss: 1.9715581542702132

Epoch: 6| Step: 10
Training loss: 2.826610565185547
Validation loss: 1.9642476599703553

Epoch: 6| Step: 11
Training loss: 1.364045262336731
Validation loss: 1.9512057983747093

Epoch: 6| Step: 12
Training loss: 2.26932430267334
Validation loss: 1.94758693633541

Epoch: 6| Step: 13
Training loss: 1.7670931816101074
Validation loss: 1.9398575316193283

Epoch: 121| Step: 0
Training loss: 2.3073313236236572
Validation loss: 1.955871820449829

Epoch: 6| Step: 1
Training loss: 2.2290282249450684
Validation loss: 1.9382093465456398

Epoch: 6| Step: 2
Training loss: 1.6193921566009521
Validation loss: 1.9522222575320993

Epoch: 6| Step: 3
Training loss: 2.0555944442749023
Validation loss: 1.9545461721317743

Epoch: 6| Step: 4
Training loss: 1.2527073621749878
Validation loss: 1.9540734021894393

Epoch: 6| Step: 5
Training loss: 2.28893780708313
Validation loss: 1.9428773362149474

Epoch: 6| Step: 6
Training loss: 1.1854465007781982
Validation loss: 1.946806837153691

Epoch: 6| Step: 7
Training loss: 2.3843026161193848
Validation loss: 1.9625995223240187

Epoch: 6| Step: 8
Training loss: 1.5100091695785522
Validation loss: 1.9787306811219902

Epoch: 6| Step: 9
Training loss: 2.4305315017700195
Validation loss: 1.9779793523973035

Epoch: 6| Step: 10
Training loss: 1.5584347248077393
Validation loss: 1.9746231032956032

Epoch: 6| Step: 11
Training loss: 2.0160536766052246
Validation loss: 1.972101870403495

Epoch: 6| Step: 12
Training loss: 1.0640618801116943
Validation loss: 1.9794220437285721

Epoch: 6| Step: 13
Training loss: 1.5485173463821411
Validation loss: 1.9886528240737094

Epoch: 122| Step: 0
Training loss: 1.5529907941818237
Validation loss: 2.0498728816227247

Epoch: 6| Step: 1
Training loss: 1.405409574508667
Validation loss: 2.0854136533634637

Epoch: 6| Step: 2
Training loss: 1.5943471193313599
Validation loss: 2.0683675017408145

Epoch: 6| Step: 3
Training loss: 1.6878154277801514
Validation loss: 2.049143079788454

Epoch: 6| Step: 4
Training loss: 1.2144253253936768
Validation loss: 2.0097308056328886

Epoch: 6| Step: 5
Training loss: 1.6641333103179932
Validation loss: 2.012179108076198

Epoch: 6| Step: 6
Training loss: 2.044036865234375
Validation loss: 1.9932977858410086

Epoch: 6| Step: 7
Training loss: 2.2342495918273926
Validation loss: 1.9521737624240179

Epoch: 6| Step: 8
Training loss: 2.2892634868621826
Validation loss: 1.9027745839088195

Epoch: 6| Step: 9
Training loss: 1.9502887725830078
Validation loss: 1.8706492634229763

Epoch: 6| Step: 10
Training loss: 2.3135557174682617
Validation loss: 1.8693216628925775

Epoch: 6| Step: 11
Training loss: 1.7923452854156494
Validation loss: 1.9006685608176774

Epoch: 6| Step: 12
Training loss: 2.2941184043884277
Validation loss: 1.9213227059251519

Epoch: 6| Step: 13
Training loss: 2.8723299503326416
Validation loss: 1.930227400154196

Epoch: 123| Step: 0
Training loss: 1.3534235954284668
Validation loss: 1.9452714855952928

Epoch: 6| Step: 1
Training loss: 2.381373405456543
Validation loss: 1.9322736058183896

Epoch: 6| Step: 2
Training loss: 1.7583448886871338
Validation loss: 1.9124203202545003

Epoch: 6| Step: 3
Training loss: 1.6768214702606201
Validation loss: 1.904219841444364

Epoch: 6| Step: 4
Training loss: 1.8164658546447754
Validation loss: 1.9194767475128174

Epoch: 6| Step: 5
Training loss: 1.6824896335601807
Validation loss: 1.9379322259656844

Epoch: 6| Step: 6
Training loss: 1.6438367366790771
Validation loss: 1.9672642536060785

Epoch: 6| Step: 7
Training loss: 2.1222190856933594
Validation loss: 1.9854129834841656

Epoch: 6| Step: 8
Training loss: 2.2009434700012207
Validation loss: 2.0203549990089993

Epoch: 6| Step: 9
Training loss: 1.5832631587982178
Validation loss: 2.032152875777214

Epoch: 6| Step: 10
Training loss: 2.462343692779541
Validation loss: 2.056543650165681

Epoch: 6| Step: 11
Training loss: 1.8785278797149658
Validation loss: 2.0832484127372823

Epoch: 6| Step: 12
Training loss: 1.49334716796875
Validation loss: 2.1498280430352814

Epoch: 6| Step: 13
Training loss: 1.8151476383209229
Validation loss: 2.1572825601024013

Epoch: 124| Step: 0
Training loss: 2.4170525074005127
Validation loss: 2.12632183618443

Epoch: 6| Step: 1
Training loss: 2.4013924598693848
Validation loss: 2.0810152945979947

Epoch: 6| Step: 2
Training loss: 1.9522358179092407
Validation loss: 1.991989448506345

Epoch: 6| Step: 3
Training loss: 1.8110949993133545
Validation loss: 1.96808990868189

Epoch: 6| Step: 4
Training loss: 1.3823578357696533
Validation loss: 1.9566071136023409

Epoch: 6| Step: 5
Training loss: 1.3706103563308716
Validation loss: 1.9489066575163154

Epoch: 6| Step: 6
Training loss: 1.676206350326538
Validation loss: 1.9258161462763304

Epoch: 6| Step: 7
Training loss: 2.131256103515625
Validation loss: 1.9335897353387648

Epoch: 6| Step: 8
Training loss: 1.7012351751327515
Validation loss: 1.9459724560860665

Epoch: 6| Step: 9
Training loss: 1.3646876811981201
Validation loss: 1.9631687030997327

Epoch: 6| Step: 10
Training loss: 1.855310320854187
Validation loss: 1.970574189257878

Epoch: 6| Step: 11
Training loss: 1.8502246141433716
Validation loss: 1.9660382552813458

Epoch: 6| Step: 12
Training loss: 1.7773547172546387
Validation loss: 1.9458636583820466

Epoch: 6| Step: 13
Training loss: 2.168872833251953
Validation loss: 1.9423280198086974

Epoch: 125| Step: 0
Training loss: 2.1594855785369873
Validation loss: 1.9258227476509668

Epoch: 6| Step: 1
Training loss: 1.8524134159088135
Validation loss: 1.918727328700404

Epoch: 6| Step: 2
Training loss: 1.2249624729156494
Validation loss: 1.941255328475788

Epoch: 6| Step: 3
Training loss: 2.503446340560913
Validation loss: 1.9424916005903674

Epoch: 6| Step: 4
Training loss: 2.00530743598938
Validation loss: 1.9412953571606708

Epoch: 6| Step: 5
Training loss: 1.8295785188674927
Validation loss: 1.9650772335708782

Epoch: 6| Step: 6
Training loss: 1.8099311590194702
Validation loss: 1.9999552234526603

Epoch: 6| Step: 7
Training loss: 1.2714457511901855
Validation loss: 2.0390229276431504

Epoch: 6| Step: 8
Training loss: 1.4277775287628174
Validation loss: 2.05706480497955

Epoch: 6| Step: 9
Training loss: 1.7793285846710205
Validation loss: 2.08028668485662

Epoch: 6| Step: 10
Training loss: 2.5641353130340576
Validation loss: 2.063168018094955

Epoch: 6| Step: 11
Training loss: 1.2627358436584473
Validation loss: 2.051284956675704

Epoch: 6| Step: 12
Training loss: 1.7233326435089111
Validation loss: 2.028344685031522

Epoch: 6| Step: 13
Training loss: 1.4356740713119507
Validation loss: 2.0206105042529363

Epoch: 126| Step: 0
Training loss: 1.0261828899383545
Validation loss: 1.996302281656573

Epoch: 6| Step: 1
Training loss: 2.355891704559326
Validation loss: 1.9785360700340682

Epoch: 6| Step: 2
Training loss: 2.0236308574676514
Validation loss: 1.9632145102306078

Epoch: 6| Step: 3
Training loss: 1.3444174528121948
Validation loss: 1.963313220649637

Epoch: 6| Step: 4
Training loss: 1.5713975429534912
Validation loss: 1.9772251241950578

Epoch: 6| Step: 5
Training loss: 2.0777246952056885
Validation loss: 1.9809918916353615

Epoch: 6| Step: 6
Training loss: 0.7926110029220581
Validation loss: 1.985417591628208

Epoch: 6| Step: 7
Training loss: 1.2793548107147217
Validation loss: 2.0061164940557172

Epoch: 6| Step: 8
Training loss: 1.8785473108291626
Validation loss: 2.0079064420474473

Epoch: 6| Step: 9
Training loss: 2.353952407836914
Validation loss: 2.019385532666278

Epoch: 6| Step: 10
Training loss: 1.5185458660125732
Validation loss: 2.0475825173880464

Epoch: 6| Step: 11
Training loss: 1.908089518547058
Validation loss: 2.0458295370942805

Epoch: 6| Step: 12
Training loss: 2.431102752685547
Validation loss: 2.047287453887283

Epoch: 6| Step: 13
Training loss: 2.1956052780151367
Validation loss: 2.029128714274335

Epoch: 127| Step: 0
Training loss: 1.9092838764190674
Validation loss: 1.9997948138944563

Epoch: 6| Step: 1
Training loss: 1.9337249994277954
Validation loss: 1.9751915572791972

Epoch: 6| Step: 2
Training loss: 1.8531720638275146
Validation loss: 1.9336633066977225

Epoch: 6| Step: 3
Training loss: 1.6490398645401
Validation loss: 1.9077032432761243

Epoch: 6| Step: 4
Training loss: 1.1688923835754395
Validation loss: 1.8945527871449788

Epoch: 6| Step: 5
Training loss: 1.6451795101165771
Validation loss: 1.885219274028655

Epoch: 6| Step: 6
Training loss: 2.0704474449157715
Validation loss: 1.8853273930088166

Epoch: 6| Step: 7
Training loss: 1.2452392578125
Validation loss: 1.9087614038939118

Epoch: 6| Step: 8
Training loss: 2.2596001625061035
Validation loss: 1.9497548175114456

Epoch: 6| Step: 9
Training loss: 2.082819700241089
Validation loss: 2.002350684135191

Epoch: 6| Step: 10
Training loss: 2.0865702629089355
Validation loss: 2.035789176981936

Epoch: 6| Step: 11
Training loss: 2.0447769165039062
Validation loss: 2.0569541685042845

Epoch: 6| Step: 12
Training loss: 1.2834241390228271
Validation loss: 2.081627911136996

Epoch: 6| Step: 13
Training loss: 1.5024374723434448
Validation loss: 2.0700670109000257

Epoch: 128| Step: 0
Training loss: 1.7845664024353027
Validation loss: 2.0601434041095037

Epoch: 6| Step: 1
Training loss: 2.014904737472534
Validation loss: 2.090593312376289

Epoch: 6| Step: 2
Training loss: 1.769289255142212
Validation loss: 2.107622411943251

Epoch: 6| Step: 3
Training loss: 1.3449299335479736
Validation loss: 2.106788278907858

Epoch: 6| Step: 4
Training loss: 1.6981127262115479
Validation loss: 2.106346505944447

Epoch: 6| Step: 5
Training loss: 1.1874722242355347
Validation loss: 2.0862792589331187

Epoch: 6| Step: 6
Training loss: 1.5595762729644775
Validation loss: 2.0880652653273715

Epoch: 6| Step: 7
Training loss: 2.701927661895752
Validation loss: 2.0292146910903273

Epoch: 6| Step: 8
Training loss: 1.9786908626556396
Validation loss: 1.998612388487785

Epoch: 6| Step: 9
Training loss: 1.0832077264785767
Validation loss: 2.022196841496293

Epoch: 6| Step: 10
Training loss: 2.1777658462524414
Validation loss: 2.0735051119199364

Epoch: 6| Step: 11
Training loss: 1.3799041509628296
Validation loss: 2.084162499314995

Epoch: 6| Step: 12
Training loss: 1.848332166671753
Validation loss: 2.0883475067794963

Epoch: 6| Step: 13
Training loss: 3.454984188079834
Validation loss: 2.04139462337699

Epoch: 129| Step: 0
Training loss: 1.51973557472229
Validation loss: 2.005336287201092

Epoch: 6| Step: 1
Training loss: 1.620066523551941
Validation loss: 1.9747174862892396

Epoch: 6| Step: 2
Training loss: 1.1587190628051758
Validation loss: 1.9619326847855763

Epoch: 6| Step: 3
Training loss: 0.9414505958557129
Validation loss: 1.9635830874084144

Epoch: 6| Step: 4
Training loss: 1.7966086864471436
Validation loss: 1.9970443966568157

Epoch: 6| Step: 5
Training loss: 1.612929344177246
Validation loss: 2.044861311553627

Epoch: 6| Step: 6
Training loss: 2.418544054031372
Validation loss: 2.0649185462664534

Epoch: 6| Step: 7
Training loss: 2.2686927318573
Validation loss: 2.0403066027549004

Epoch: 6| Step: 8
Training loss: 1.7538139820098877
Validation loss: 2.0202142320653445

Epoch: 6| Step: 9
Training loss: 1.843680739402771
Validation loss: 1.9728472732728528

Epoch: 6| Step: 10
Training loss: 1.6325225830078125
Validation loss: 2.003884901282608

Epoch: 6| Step: 11
Training loss: 2.5105836391448975
Validation loss: 2.0322706161006803

Epoch: 6| Step: 12
Training loss: 1.857640027999878
Validation loss: 2.064841890847811

Epoch: 6| Step: 13
Training loss: 1.9175455570220947
Validation loss: 2.106507388494348

Epoch: 130| Step: 0
Training loss: 2.2755277156829834
Validation loss: 2.1421002982765116

Epoch: 6| Step: 1
Training loss: 1.8953826427459717
Validation loss: 2.1244871590727117

Epoch: 6| Step: 2
Training loss: 2.298506259918213
Validation loss: 2.109276827945504

Epoch: 6| Step: 3
Training loss: 1.8727740049362183
Validation loss: 2.0634743423872095

Epoch: 6| Step: 4
Training loss: 1.9197932481765747
Validation loss: 2.0650793198616273

Epoch: 6| Step: 5
Training loss: 1.149139165878296
Validation loss: 2.0072245315838884

Epoch: 6| Step: 6
Training loss: 1.863781452178955
Validation loss: 1.9652424448279924

Epoch: 6| Step: 7
Training loss: 1.3783695697784424
Validation loss: 1.9758904005891533

Epoch: 6| Step: 8
Training loss: 2.006167411804199
Validation loss: 1.9890599840430803

Epoch: 6| Step: 9
Training loss: 1.8210012912750244
Validation loss: 2.005406295099566

Epoch: 6| Step: 10
Training loss: 1.6536178588867188
Validation loss: 2.008236082651282

Epoch: 6| Step: 11
Training loss: 1.6617534160614014
Validation loss: 2.012495917658652

Epoch: 6| Step: 12
Training loss: 1.7578136920928955
Validation loss: 2.0291889995656986

Epoch: 6| Step: 13
Training loss: 2.076512336730957
Validation loss: 2.0087152052951116

Epoch: 131| Step: 0
Training loss: 1.6041347980499268
Validation loss: 2.013661371764316

Epoch: 6| Step: 1
Training loss: 2.0094637870788574
Validation loss: 2.0128853744076145

Epoch: 6| Step: 2
Training loss: 1.732713222503662
Validation loss: 2.0204999305868663

Epoch: 6| Step: 3
Training loss: 1.2680575847625732
Validation loss: 2.007168726254535

Epoch: 6| Step: 4
Training loss: 1.2626020908355713
Validation loss: 1.9981771079442834

Epoch: 6| Step: 5
Training loss: 1.9264452457427979
Validation loss: 1.989491214034378

Epoch: 6| Step: 6
Training loss: 1.9208036661148071
Validation loss: 1.9979441896561654

Epoch: 6| Step: 7
Training loss: 1.6710760593414307
Validation loss: 1.9919816076114614

Epoch: 6| Step: 8
Training loss: 0.9481625556945801
Validation loss: 1.9880727683344195

Epoch: 6| Step: 9
Training loss: 1.231893539428711
Validation loss: 1.9675988381908787

Epoch: 6| Step: 10
Training loss: 2.6638388633728027
Validation loss: 1.9945262144970637

Epoch: 6| Step: 11
Training loss: 1.7418384552001953
Validation loss: 1.9823598682239492

Epoch: 6| Step: 12
Training loss: 1.8321974277496338
Validation loss: 1.9722071078515822

Epoch: 6| Step: 13
Training loss: 1.98390793800354
Validation loss: 1.955570904157495

Epoch: 132| Step: 0
Training loss: 1.4766368865966797
Validation loss: 1.9575993796830535

Epoch: 6| Step: 1
Training loss: 1.777510404586792
Validation loss: 1.9764705627195296

Epoch: 6| Step: 2
Training loss: 1.6994112730026245
Validation loss: 1.9825457783155545

Epoch: 6| Step: 3
Training loss: 2.3509609699249268
Validation loss: 1.9863993737005419

Epoch: 6| Step: 4
Training loss: 0.6475306153297424
Validation loss: 1.9796071975461897

Epoch: 6| Step: 5
Training loss: 1.623563289642334
Validation loss: 1.9829300475376908

Epoch: 6| Step: 6
Training loss: 1.424392580986023
Validation loss: 1.9769712468629241

Epoch: 6| Step: 7
Training loss: 1.7135425806045532
Validation loss: 1.9847284260616507

Epoch: 6| Step: 8
Training loss: 1.7120816707611084
Validation loss: 1.995611342050696

Epoch: 6| Step: 9
Training loss: 2.783576488494873
Validation loss: 1.9898951976530013

Epoch: 6| Step: 10
Training loss: 1.759016990661621
Validation loss: 2.0025492406660512

Epoch: 6| Step: 11
Training loss: 1.5953880548477173
Validation loss: 2.0255181635579755

Epoch: 6| Step: 12
Training loss: 1.14181649684906
Validation loss: 2.0640273811996623

Epoch: 6| Step: 13
Training loss: 1.633610725402832
Validation loss: 2.0343037959068053

Epoch: 133| Step: 0
Training loss: 2.0826468467712402
Validation loss: 2.0529837941610687

Epoch: 6| Step: 1
Training loss: 1.7443400621414185
Validation loss: 2.0318575341214418

Epoch: 6| Step: 2
Training loss: 1.8657927513122559
Validation loss: 2.0285305566685174

Epoch: 6| Step: 3
Training loss: 1.2158880233764648
Validation loss: 2.01326350755589

Epoch: 6| Step: 4
Training loss: 1.765434741973877
Validation loss: 2.022514194570562

Epoch: 6| Step: 5
Training loss: 1.8522381782531738
Validation loss: 2.0464233095927904

Epoch: 6| Step: 6
Training loss: 1.174537181854248
Validation loss: 2.0465972859372377

Epoch: 6| Step: 7
Training loss: 1.9297122955322266
Validation loss: 2.0313540684279574

Epoch: 6| Step: 8
Training loss: 1.6416797637939453
Validation loss: 2.0185572229405886

Epoch: 6| Step: 9
Training loss: 1.6940696239471436
Validation loss: 2.040275425039312

Epoch: 6| Step: 10
Training loss: 1.7626912593841553
Validation loss: 2.0387772462701284

Epoch: 6| Step: 11
Training loss: 1.5024170875549316
Validation loss: 2.0321919354059363

Epoch: 6| Step: 12
Training loss: 1.5940864086151123
Validation loss: 2.023025348622312

Epoch: 6| Step: 13
Training loss: 2.7482457160949707
Validation loss: 1.987207325555945

Epoch: 134| Step: 0
Training loss: 1.443359136581421
Validation loss: 1.9872213666157057

Epoch: 6| Step: 1
Training loss: 1.2753961086273193
Validation loss: 1.960311597393405

Epoch: 6| Step: 2
Training loss: 1.5477854013442993
Validation loss: 1.9857702575704104

Epoch: 6| Step: 3
Training loss: 1.6363892555236816
Validation loss: 2.0047409329363095

Epoch: 6| Step: 4
Training loss: 1.2584562301635742
Validation loss: 2.0326104894761117

Epoch: 6| Step: 5
Training loss: 2.460041046142578
Validation loss: 2.0608734892260645

Epoch: 6| Step: 6
Training loss: 1.1852353811264038
Validation loss: 2.0430705624241985

Epoch: 6| Step: 7
Training loss: 1.4147449731826782
Validation loss: 2.0415262445326774

Epoch: 6| Step: 8
Training loss: 1.5672533512115479
Validation loss: 2.0377092656268867

Epoch: 6| Step: 9
Training loss: 1.5257456302642822
Validation loss: 2.0458385662365983

Epoch: 6| Step: 10
Training loss: 2.0157084465026855
Validation loss: 1.998538363364435

Epoch: 6| Step: 11
Training loss: 1.5647146701812744
Validation loss: 1.9636470630604734

Epoch: 6| Step: 12
Training loss: 2.66200590133667
Validation loss: 1.960049247228971

Epoch: 6| Step: 13
Training loss: 1.7497529983520508
Validation loss: 1.9375903029595651

Epoch: 135| Step: 0
Training loss: 1.9649442434310913
Validation loss: 1.9238952449572984

Epoch: 6| Step: 1
Training loss: 2.0062875747680664
Validation loss: 1.9189422335675967

Epoch: 6| Step: 2
Training loss: 1.91201651096344
Validation loss: 1.9324660711390997

Epoch: 6| Step: 3
Training loss: 1.6550467014312744
Validation loss: 1.9585105603741062

Epoch: 6| Step: 4
Training loss: 1.915705680847168
Validation loss: 2.000476127029747

Epoch: 6| Step: 5
Training loss: 1.994316816329956
Validation loss: 1.9854488552257579

Epoch: 6| Step: 6
Training loss: 1.4406027793884277
Validation loss: 1.9671874161689513

Epoch: 6| Step: 7
Training loss: 1.3392133712768555
Validation loss: 1.9696320154333626

Epoch: 6| Step: 8
Training loss: 0.9696235656738281
Validation loss: 1.9545390221380419

Epoch: 6| Step: 9
Training loss: 1.5416494607925415
Validation loss: 1.9612808624903362

Epoch: 6| Step: 10
Training loss: 2.058593273162842
Validation loss: 1.9596305688222249

Epoch: 6| Step: 11
Training loss: 1.5384639501571655
Validation loss: 1.9555847337169032

Epoch: 6| Step: 12
Training loss: 1.5360491275787354
Validation loss: 1.9727969477253575

Epoch: 6| Step: 13
Training loss: 1.6118437051773071
Validation loss: 2.025925382491081

Epoch: 136| Step: 0
Training loss: 1.2485089302062988
Validation loss: 2.052684489116874

Epoch: 6| Step: 1
Training loss: 1.7709259986877441
Validation loss: 2.0819502697196057

Epoch: 6| Step: 2
Training loss: 2.035236358642578
Validation loss: 2.077837041629258

Epoch: 6| Step: 3
Training loss: 1.6034877300262451
Validation loss: 2.1096426287005023

Epoch: 6| Step: 4
Training loss: 1.4380435943603516
Validation loss: 2.1081957611986386

Epoch: 6| Step: 5
Training loss: 1.720974087715149
Validation loss: 2.111010733471122

Epoch: 6| Step: 6
Training loss: 1.890228509902954
Validation loss: 2.081341781923848

Epoch: 6| Step: 7
Training loss: 2.1694693565368652
Validation loss: 2.0095822631671862

Epoch: 6| Step: 8
Training loss: 1.4843802452087402
Validation loss: 1.9972901062298847

Epoch: 6| Step: 9
Training loss: 1.463791847229004
Validation loss: 1.9569613292653074

Epoch: 6| Step: 10
Training loss: 1.4621410369873047
Validation loss: 1.945177258983735

Epoch: 6| Step: 11
Training loss: 1.5185260772705078
Validation loss: 1.9560756657713203

Epoch: 6| Step: 12
Training loss: 1.7995572090148926
Validation loss: 1.9597198527346376

Epoch: 6| Step: 13
Training loss: 1.2524394989013672
Validation loss: 1.982533533086059

Epoch: 137| Step: 0
Training loss: 1.4514166116714478
Validation loss: 2.0462191258707354

Epoch: 6| Step: 1
Training loss: 1.584972858428955
Validation loss: 2.1382316568846345

Epoch: 6| Step: 2
Training loss: 1.6345765590667725
Validation loss: 2.1501744460034113

Epoch: 6| Step: 3
Training loss: 2.0926032066345215
Validation loss: 2.146176976542319

Epoch: 6| Step: 4
Training loss: 1.625677227973938
Validation loss: 2.105661371702789

Epoch: 6| Step: 5
Training loss: 1.7357447147369385
Validation loss: 2.0551293178271224

Epoch: 6| Step: 6
Training loss: 1.8993408679962158
Validation loss: 2.018940361597205

Epoch: 6| Step: 7
Training loss: 1.920251488685608
Validation loss: 2.020906709855603

Epoch: 6| Step: 8
Training loss: 2.4386773109436035
Validation loss: 2.029152867614582

Epoch: 6| Step: 9
Training loss: 1.651123285293579
Validation loss: 2.0279335411646033

Epoch: 6| Step: 10
Training loss: 1.351121425628662
Validation loss: 2.011496438775011

Epoch: 6| Step: 11
Training loss: 2.0652880668640137
Validation loss: 2.0396080273453907

Epoch: 6| Step: 12
Training loss: 0.9507031440734863
Validation loss: 2.122460239677019

Epoch: 6| Step: 13
Training loss: 1.729516625404358
Validation loss: 2.1496146366160405

Epoch: 138| Step: 0
Training loss: 1.5095306634902954
Validation loss: 2.2110407480629544

Epoch: 6| Step: 1
Training loss: 2.230496406555176
Validation loss: 2.1706380895389024

Epoch: 6| Step: 2
Training loss: 1.8746227025985718
Validation loss: 2.1004352723398516

Epoch: 6| Step: 3
Training loss: 1.1038082838058472
Validation loss: 1.989797176853303

Epoch: 6| Step: 4
Training loss: 2.3037543296813965
Validation loss: 1.923521598180135

Epoch: 6| Step: 5
Training loss: 2.208456516265869
Validation loss: 1.9288954978348107

Epoch: 6| Step: 6
Training loss: 1.4522732496261597
Validation loss: 1.9324481859002063

Epoch: 6| Step: 7
Training loss: 1.6902966499328613
Validation loss: 1.950260482808595

Epoch: 6| Step: 8
Training loss: 1.736952304840088
Validation loss: 1.9525660084139915

Epoch: 6| Step: 9
Training loss: 1.3039824962615967
Validation loss: 1.9504299035636328

Epoch: 6| Step: 10
Training loss: 1.547158122062683
Validation loss: 1.9583551294060164

Epoch: 6| Step: 11
Training loss: 1.928421974182129
Validation loss: 1.9728565395519297

Epoch: 6| Step: 12
Training loss: 1.1380698680877686
Validation loss: 1.9901945719154932

Epoch: 6| Step: 13
Training loss: 1.9886267185211182
Validation loss: 2.006265501822195

Epoch: 139| Step: 0
Training loss: 1.4246363639831543
Validation loss: 2.0140037382802656

Epoch: 6| Step: 1
Training loss: 1.3576419353485107
Validation loss: 2.0379919262342554

Epoch: 6| Step: 2
Training loss: 1.5182448625564575
Validation loss: 2.071865007441531

Epoch: 6| Step: 3
Training loss: 1.4675965309143066
Validation loss: 2.0844170406300533

Epoch: 6| Step: 4
Training loss: 1.7872734069824219
Validation loss: 2.075804546315183

Epoch: 6| Step: 5
Training loss: 1.567676305770874
Validation loss: 2.0207100658006567

Epoch: 6| Step: 6
Training loss: 1.420564889907837
Validation loss: 1.9980957123541063

Epoch: 6| Step: 7
Training loss: 1.4984418153762817
Validation loss: 1.965996246184072

Epoch: 6| Step: 8
Training loss: 0.9944489598274231
Validation loss: 1.9559531006761777

Epoch: 6| Step: 9
Training loss: 2.7120702266693115
Validation loss: 1.9428545236587524

Epoch: 6| Step: 10
Training loss: 2.119159698486328
Validation loss: 1.9345955925603067

Epoch: 6| Step: 11
Training loss: 1.2746987342834473
Validation loss: 1.9097859500556864

Epoch: 6| Step: 12
Training loss: 1.5636086463928223
Validation loss: 1.8954861471729894

Epoch: 6| Step: 13
Training loss: 1.4253754615783691
Validation loss: 1.9037698058671848

Epoch: 140| Step: 0
Training loss: 1.3819618225097656
Validation loss: 1.880718884929534

Epoch: 6| Step: 1
Training loss: 1.564314842224121
Validation loss: 1.8861807700126403

Epoch: 6| Step: 2
Training loss: 1.4118107557296753
Validation loss: 1.8902720251391012

Epoch: 6| Step: 3
Training loss: 1.8765722513198853
Validation loss: 1.900271184982792

Epoch: 6| Step: 4
Training loss: 1.5665994882583618
Validation loss: 1.9312952769699918

Epoch: 6| Step: 5
Training loss: 1.7934517860412598
Validation loss: 1.952868075780971

Epoch: 6| Step: 6
Training loss: 1.770301342010498
Validation loss: 1.952039695555164

Epoch: 6| Step: 7
Training loss: 1.5580958127975464
Validation loss: 1.9763016367471347

Epoch: 6| Step: 8
Training loss: 1.4413983821868896
Validation loss: 1.987706402296661

Epoch: 6| Step: 9
Training loss: 0.9435638189315796
Validation loss: 2.0300624178301905

Epoch: 6| Step: 10
Training loss: 1.6277408599853516
Validation loss: 2.040029805193665

Epoch: 6| Step: 11
Training loss: 1.6270029544830322
Validation loss: 2.076138227216659

Epoch: 6| Step: 12
Training loss: 1.7444485425949097
Validation loss: 2.083501676077484

Epoch: 6| Step: 13
Training loss: 1.3406702280044556
Validation loss: 2.0475529393842145

Epoch: 141| Step: 0
Training loss: 1.9135299921035767
Validation loss: 2.0348321878781883

Epoch: 6| Step: 1
Training loss: 2.218230724334717
Validation loss: 1.9896520901751775

Epoch: 6| Step: 2
Training loss: 1.105248212814331
Validation loss: 1.9443793835178498

Epoch: 6| Step: 3
Training loss: 1.5751063823699951
Validation loss: 1.9248455339862454

Epoch: 6| Step: 4
Training loss: 2.1244945526123047
Validation loss: 1.902767332651282

Epoch: 6| Step: 5
Training loss: 1.2884726524353027
Validation loss: 1.8999060225743118

Epoch: 6| Step: 6
Training loss: 1.2499010562896729
Validation loss: 1.9056832751920145

Epoch: 6| Step: 7
Training loss: 1.4801032543182373
Validation loss: 1.9258399458341702

Epoch: 6| Step: 8
Training loss: 1.6476285457611084
Validation loss: 1.957642033535947

Epoch: 6| Step: 9
Training loss: 1.6515421867370605
Validation loss: 1.9993107241968955

Epoch: 6| Step: 10
Training loss: 1.4156136512756348
Validation loss: 2.0148156304513254

Epoch: 6| Step: 11
Training loss: 1.9671648740768433
Validation loss: 2.025346427835444

Epoch: 6| Step: 12
Training loss: 0.9716846942901611
Validation loss: 2.0296484783131588

Epoch: 6| Step: 13
Training loss: 1.1795439720153809
Validation loss: 2.003089092111075

Epoch: 142| Step: 0
Training loss: 2.278733730316162
Validation loss: 2.007570405160227

Epoch: 6| Step: 1
Training loss: 1.596768856048584
Validation loss: 2.019430242558961

Epoch: 6| Step: 2
Training loss: 1.3854587078094482
Validation loss: 2.0191971614796627

Epoch: 6| Step: 3
Training loss: 1.9540603160858154
Validation loss: 2.03635214477457

Epoch: 6| Step: 4
Training loss: 1.4836342334747314
Validation loss: 2.0261198141241588

Epoch: 6| Step: 5
Training loss: 1.3864891529083252
Validation loss: 2.0177352812982376

Epoch: 6| Step: 6
Training loss: 1.6195781230926514
Validation loss: 2.0194353262583413

Epoch: 6| Step: 7
Training loss: 1.2499735355377197
Validation loss: 2.0006613269928963

Epoch: 6| Step: 8
Training loss: 1.040564775466919
Validation loss: 2.004615301726967

Epoch: 6| Step: 9
Training loss: 1.3941020965576172
Validation loss: 2.043100781338189

Epoch: 6| Step: 10
Training loss: 1.404177188873291
Validation loss: 2.09494254537808

Epoch: 6| Step: 11
Training loss: 1.4643168449401855
Validation loss: 2.1569721929488646

Epoch: 6| Step: 12
Training loss: 2.271468162536621
Validation loss: 2.1425239757824968

Epoch: 6| Step: 13
Training loss: 2.264547109603882
Validation loss: 2.1123156906456075

Epoch: 143| Step: 0
Training loss: 1.7695856094360352
Validation loss: 2.081099228192401

Epoch: 6| Step: 1
Training loss: 1.0987577438354492
Validation loss: 2.0312895403113416

Epoch: 6| Step: 2
Training loss: 1.7316327095031738
Validation loss: 1.9930295252030896

Epoch: 6| Step: 3
Training loss: 0.9481093287467957
Validation loss: 1.9812902442870601

Epoch: 6| Step: 4
Training loss: 1.9982566833496094
Validation loss: 1.9795690633917367

Epoch: 6| Step: 5
Training loss: 1.6027189493179321
Validation loss: 1.982018466918699

Epoch: 6| Step: 6
Training loss: 1.0843278169631958
Validation loss: 2.006709414143716

Epoch: 6| Step: 7
Training loss: 1.7140676975250244
Validation loss: 1.982110720808788

Epoch: 6| Step: 8
Training loss: 1.534512996673584
Validation loss: 1.9577790434642504

Epoch: 6| Step: 9
Training loss: 1.1634966135025024
Validation loss: 1.93386717765562

Epoch: 6| Step: 10
Training loss: 1.7458314895629883
Validation loss: 1.930644637794905

Epoch: 6| Step: 11
Training loss: 1.8052397966384888
Validation loss: 1.9084700653629918

Epoch: 6| Step: 12
Training loss: 1.8147368431091309
Validation loss: 1.9115791936074533

Epoch: 6| Step: 13
Training loss: 2.023679494857788
Validation loss: 1.9387069004838184

Epoch: 144| Step: 0
Training loss: 1.712848424911499
Validation loss: 1.9271178655726935

Epoch: 6| Step: 1
Training loss: 1.1886588335037231
Validation loss: 1.955016407915341

Epoch: 6| Step: 2
Training loss: 0.8553916811943054
Validation loss: 1.9709024326775664

Epoch: 6| Step: 3
Training loss: 1.488829493522644
Validation loss: 1.9583416561926565

Epoch: 6| Step: 4
Training loss: 1.4879822731018066
Validation loss: 1.9578514176030313

Epoch: 6| Step: 5
Training loss: 1.9983627796173096
Validation loss: 1.9642790030407649

Epoch: 6| Step: 6
Training loss: 2.1357574462890625
Validation loss: 1.9727824375193606

Epoch: 6| Step: 7
Training loss: 1.3440372943878174
Validation loss: 1.9895481089110016

Epoch: 6| Step: 8
Training loss: 1.8116377592086792
Validation loss: 1.9854863907701226

Epoch: 6| Step: 9
Training loss: 1.5808849334716797
Validation loss: 2.008241855969993

Epoch: 6| Step: 10
Training loss: 1.469472050666809
Validation loss: 2.004276321780297

Epoch: 6| Step: 11
Training loss: 1.1548054218292236
Validation loss: 1.987279979131555

Epoch: 6| Step: 12
Training loss: 1.558262586593628
Validation loss: 2.005314193746095

Epoch: 6| Step: 13
Training loss: 1.712543249130249
Validation loss: 2.0290439333966983

Epoch: 145| Step: 0
Training loss: 2.001467704772949
Validation loss: 2.0497838322834303

Epoch: 6| Step: 1
Training loss: 0.8566631078720093
Validation loss: 2.0820863298190537

Epoch: 6| Step: 2
Training loss: 1.652259349822998
Validation loss: 2.0967688175939743

Epoch: 6| Step: 3
Training loss: 2.5063138008117676
Validation loss: 2.075832079815608

Epoch: 6| Step: 4
Training loss: 1.3944566249847412
Validation loss: 2.047090490659078

Epoch: 6| Step: 5
Training loss: 1.465226411819458
Validation loss: 1.9876407730963923

Epoch: 6| Step: 6
Training loss: 1.080789566040039
Validation loss: 1.9409763633563955

Epoch: 6| Step: 7
Training loss: 1.6467586755752563
Validation loss: 1.9214247580497497

Epoch: 6| Step: 8
Training loss: 2.1506876945495605
Validation loss: 1.9221700032552083

Epoch: 6| Step: 9
Training loss: 1.389329433441162
Validation loss: 1.9161714776869743

Epoch: 6| Step: 10
Training loss: 1.4689620733261108
Validation loss: 1.9113426849406252

Epoch: 6| Step: 11
Training loss: 1.4037888050079346
Validation loss: 1.8988311034376903

Epoch: 6| Step: 12
Training loss: 1.062607765197754
Validation loss: 1.9226152461062196

Epoch: 6| Step: 13
Training loss: 1.1668003797531128
Validation loss: 1.9849231960952922

Epoch: 146| Step: 0
Training loss: 1.034564733505249
Validation loss: 2.0070409864507694

Epoch: 6| Step: 1
Training loss: 1.3817832469940186
Validation loss: 2.0443118285107356

Epoch: 6| Step: 2
Training loss: 1.7534126043319702
Validation loss: 2.0347560580058763

Epoch: 6| Step: 3
Training loss: 1.510115385055542
Validation loss: 2.0376282007463518

Epoch: 6| Step: 4
Training loss: 1.3606629371643066
Validation loss: 2.038185142701672

Epoch: 6| Step: 5
Training loss: 1.7484248876571655
Validation loss: 2.028653501182474

Epoch: 6| Step: 6
Training loss: 0.9022552371025085
Validation loss: 1.9949575008884552

Epoch: 6| Step: 7
Training loss: 1.1153644323349
Validation loss: 1.9716903509632233

Epoch: 6| Step: 8
Training loss: 1.736569881439209
Validation loss: 1.9461962253816667

Epoch: 6| Step: 9
Training loss: 1.5400960445404053
Validation loss: 1.9520345785284554

Epoch: 6| Step: 10
Training loss: 1.4931039810180664
Validation loss: 1.9442179517079425

Epoch: 6| Step: 11
Training loss: 1.2615798711776733
Validation loss: 1.9522067116152855

Epoch: 6| Step: 12
Training loss: 1.9441156387329102
Validation loss: 1.955649821988998

Epoch: 6| Step: 13
Training loss: 1.7476727962493896
Validation loss: 1.9482787629609466

Epoch: 147| Step: 0
Training loss: 1.0704877376556396
Validation loss: 1.9569941707836684

Epoch: 6| Step: 1
Training loss: 0.9993468523025513
Validation loss: 1.9742298254402735

Epoch: 6| Step: 2
Training loss: 1.4713492393493652
Validation loss: 1.9822775907413934

Epoch: 6| Step: 3
Training loss: 1.1905649900436401
Validation loss: 1.977019525343372

Epoch: 6| Step: 4
Training loss: 1.5634411573410034
Validation loss: 2.001778628236504

Epoch: 6| Step: 5
Training loss: 1.7986819744110107
Validation loss: 1.9770823588935278

Epoch: 6| Step: 6
Training loss: 0.8845970630645752
Validation loss: 1.9506871418286396

Epoch: 6| Step: 7
Training loss: 1.8815741539001465
Validation loss: 1.9453826014713576

Epoch: 6| Step: 8
Training loss: 0.5994101762771606
Validation loss: 1.9520155537512995

Epoch: 6| Step: 9
Training loss: 1.9891068935394287
Validation loss: 1.9794524856792983

Epoch: 6| Step: 10
Training loss: 2.2230145931243896
Validation loss: 1.9882716594203826

Epoch: 6| Step: 11
Training loss: 1.2818986177444458
Validation loss: 2.026182154173492

Epoch: 6| Step: 12
Training loss: 1.5088069438934326
Validation loss: 2.0255670009120816

Epoch: 6| Step: 13
Training loss: 1.9846627712249756
Validation loss: 2.0397037741958455

Epoch: 148| Step: 0
Training loss: 1.7330785989761353
Validation loss: 2.0312428166789394

Epoch: 6| Step: 1
Training loss: 1.7251372337341309
Validation loss: 2.0265541589388283

Epoch: 6| Step: 2
Training loss: 0.9341243505477905
Validation loss: 1.9805314579317648

Epoch: 6| Step: 3
Training loss: 1.7280560731887817
Validation loss: 1.9786509083163353

Epoch: 6| Step: 4
Training loss: 1.472151279449463
Validation loss: 1.9560635551329582

Epoch: 6| Step: 5
Training loss: 1.1973590850830078
Validation loss: 1.9594545184925038

Epoch: 6| Step: 6
Training loss: 1.3548481464385986
Validation loss: 1.94503402966325

Epoch: 6| Step: 7
Training loss: 1.0481421947479248
Validation loss: 1.9460504619024133

Epoch: 6| Step: 8
Training loss: 0.936100959777832
Validation loss: 1.9436720289209837

Epoch: 6| Step: 9
Training loss: 1.3804795742034912
Validation loss: 1.9320909419367391

Epoch: 6| Step: 10
Training loss: 1.6097511053085327
Validation loss: 1.9147959293857697

Epoch: 6| Step: 11
Training loss: 1.5715279579162598
Validation loss: 1.9129167102998303

Epoch: 6| Step: 12
Training loss: 1.7049098014831543
Validation loss: 1.9095504335177842

Epoch: 6| Step: 13
Training loss: 1.5016536712646484
Validation loss: 1.8940599092873194

Epoch: 149| Step: 0
Training loss: 1.2710477113723755
Validation loss: 1.875936588933391

Epoch: 6| Step: 1
Training loss: 1.6186902523040771
Validation loss: 1.8951825198306833

Epoch: 6| Step: 2
Training loss: 1.5602881908416748
Validation loss: 1.8889078324840916

Epoch: 6| Step: 3
Training loss: 0.6536266803741455
Validation loss: 1.892419763790664

Epoch: 6| Step: 4
Training loss: 2.063692092895508
Validation loss: 1.909575931487545

Epoch: 6| Step: 5
Training loss: 1.0594632625579834
Validation loss: 1.9139284536402712

Epoch: 6| Step: 6
Training loss: 1.3923420906066895
Validation loss: 1.9078082051328433

Epoch: 6| Step: 7
Training loss: 1.097581386566162
Validation loss: 1.9465774669442126

Epoch: 6| Step: 8
Training loss: 1.4489296674728394
Validation loss: 1.9430567179956744

Epoch: 6| Step: 9
Training loss: 0.8707756996154785
Validation loss: 1.925504348611319

Epoch: 6| Step: 10
Training loss: 1.8203883171081543
Validation loss: 1.9258848954272527

Epoch: 6| Step: 11
Training loss: 1.5064911842346191
Validation loss: 1.891163678579433

Epoch: 6| Step: 12
Training loss: 1.6801519393920898
Validation loss: 1.8978497853843115

Epoch: 6| Step: 13
Training loss: 1.2743428945541382
Validation loss: 1.9016541127235658

Epoch: 150| Step: 0
Training loss: 1.2841805219650269
Validation loss: 1.915821624058549

Epoch: 6| Step: 1
Training loss: 1.3290915489196777
Validation loss: 1.927645484606425

Epoch: 6| Step: 2
Training loss: 1.441042184829712
Validation loss: 1.93806847833818

Epoch: 6| Step: 3
Training loss: 1.40602445602417
Validation loss: 1.9391740342622161

Epoch: 6| Step: 4
Training loss: 2.231090545654297
Validation loss: 1.9559085471655733

Epoch: 6| Step: 5
Training loss: 0.9297686219215393
Validation loss: 1.9477099654495076

Epoch: 6| Step: 6
Training loss: 1.384160041809082
Validation loss: 1.9822344895332091

Epoch: 6| Step: 7
Training loss: 1.4524911642074585
Validation loss: 1.9638290033545545

Epoch: 6| Step: 8
Training loss: 1.0697951316833496
Validation loss: 1.9592760762860697

Epoch: 6| Step: 9
Training loss: 1.394385576248169
Validation loss: 1.9729140279113606

Epoch: 6| Step: 10
Training loss: 1.5264651775360107
Validation loss: 1.955679383329166

Epoch: 6| Step: 11
Training loss: 1.1248990297317505
Validation loss: 1.9719480827290525

Epoch: 6| Step: 12
Training loss: 1.2989847660064697
Validation loss: 1.9716591155657204

Epoch: 6| Step: 13
Training loss: 1.4456950426101685
Validation loss: 1.9524059167472265

Epoch: 151| Step: 0
Training loss: 1.3524925708770752
Validation loss: 1.9522577588276198

Epoch: 6| Step: 1
Training loss: 1.0378025770187378
Validation loss: 1.9465645577317925

Epoch: 6| Step: 2
Training loss: 1.2869302034378052
Validation loss: 1.9491480717094996

Epoch: 6| Step: 3
Training loss: 1.5087748765945435
Validation loss: 1.9485399441052509

Epoch: 6| Step: 4
Training loss: 1.760109782218933
Validation loss: 1.9517958600033996

Epoch: 6| Step: 5
Training loss: 1.9074780941009521
Validation loss: 1.9662129558542722

Epoch: 6| Step: 6
Training loss: 1.4779069423675537
Validation loss: 1.929771400267078

Epoch: 6| Step: 7
Training loss: 1.4699928760528564
Validation loss: 1.8834933644981795

Epoch: 6| Step: 8
Training loss: 0.9659740328788757
Validation loss: 1.87874787340882

Epoch: 6| Step: 9
Training loss: 1.1528310775756836
Validation loss: 1.8906060982775945

Epoch: 6| Step: 10
Training loss: 1.4425606727600098
Validation loss: 1.8885362135466708

Epoch: 6| Step: 11
Training loss: 1.7590683698654175
Validation loss: 1.8952144833021267

Epoch: 6| Step: 12
Training loss: 0.9769409894943237
Validation loss: 1.8889665667728712

Epoch: 6| Step: 13
Training loss: 1.2342802286148071
Validation loss: 1.8720561073672386

Epoch: 152| Step: 0
Training loss: 1.5640909671783447
Validation loss: 1.9086772652082546

Epoch: 6| Step: 1
Training loss: 1.1032841205596924
Validation loss: 1.9593854053046114

Epoch: 6| Step: 2
Training loss: 0.9996514916419983
Validation loss: 1.9632980669698408

Epoch: 6| Step: 3
Training loss: 1.5124871730804443
Validation loss: 1.98147415602079

Epoch: 6| Step: 4
Training loss: 1.594697117805481
Validation loss: 1.9815148666340818

Epoch: 6| Step: 5
Training loss: 1.7840861082077026
Validation loss: 1.9363282534383959

Epoch: 6| Step: 6
Training loss: 0.94302898645401
Validation loss: 1.9402938837646155

Epoch: 6| Step: 7
Training loss: 1.2962579727172852
Validation loss: 1.912841866093297

Epoch: 6| Step: 8
Training loss: 1.1012718677520752
Validation loss: 1.916548571278972

Epoch: 6| Step: 9
Training loss: 1.5118708610534668
Validation loss: 1.9085155558842484

Epoch: 6| Step: 10
Training loss: 1.3375355005264282
Validation loss: 1.9129725476746917

Epoch: 6| Step: 11
Training loss: 1.7759917974472046
Validation loss: 1.9054052252923288

Epoch: 6| Step: 12
Training loss: 1.2461273670196533
Validation loss: 1.9015073186607772

Epoch: 6| Step: 13
Training loss: 1.2069780826568604
Validation loss: 1.9008981822639384

Epoch: 153| Step: 0
Training loss: 1.6220425367355347
Validation loss: 1.9305028851314256

Epoch: 6| Step: 1
Training loss: 1.0494898557662964
Validation loss: 1.9402221184904858

Epoch: 6| Step: 2
Training loss: 1.147607684135437
Validation loss: 1.921984064963556

Epoch: 6| Step: 3
Training loss: 0.9763942956924438
Validation loss: 1.9287551026190481

Epoch: 6| Step: 4
Training loss: 1.5405365228652954
Validation loss: 1.9390686737593783

Epoch: 6| Step: 5
Training loss: 1.547271728515625
Validation loss: 1.9336284796396892

Epoch: 6| Step: 6
Training loss: 0.8960352540016174
Validation loss: 1.9469573805409093

Epoch: 6| Step: 7
Training loss: 1.489022135734558
Validation loss: 1.9699756586423485

Epoch: 6| Step: 8
Training loss: 1.5378174781799316
Validation loss: 1.9551033678875174

Epoch: 6| Step: 9
Training loss: 1.7814420461654663
Validation loss: 1.933193293950891

Epoch: 6| Step: 10
Training loss: 1.034359097480774
Validation loss: 1.9129593141617314

Epoch: 6| Step: 11
Training loss: 1.7241032123565674
Validation loss: 1.8960345432322512

Epoch: 6| Step: 12
Training loss: 1.9018418788909912
Validation loss: 1.8765585499425088

Epoch: 6| Step: 13
Training loss: 0.7212951183319092
Validation loss: 1.9005446100747714

Epoch: 154| Step: 0
Training loss: 1.1341400146484375
Validation loss: 1.9407636529655867

Epoch: 6| Step: 1
Training loss: 1.703403353691101
Validation loss: 1.9554264878713956

Epoch: 6| Step: 2
Training loss: 1.7684175968170166
Validation loss: 1.9956513079263831

Epoch: 6| Step: 3
Training loss: 1.4130661487579346
Validation loss: 1.9944657433417536

Epoch: 6| Step: 4
Training loss: 1.2868709564208984
Validation loss: 1.9851027252853557

Epoch: 6| Step: 5
Training loss: 1.3522921800613403
Validation loss: 1.9641674718549174

Epoch: 6| Step: 6
Training loss: 1.6800322532653809
Validation loss: 1.9366903510144962

Epoch: 6| Step: 7
Training loss: 0.7361220121383667
Validation loss: 1.9318850450618292

Epoch: 6| Step: 8
Training loss: 1.419751763343811
Validation loss: 1.9464839966066423

Epoch: 6| Step: 9
Training loss: 0.9024944305419922
Validation loss: 1.9251246247240292

Epoch: 6| Step: 10
Training loss: 1.359474539756775
Validation loss: 1.9299219013542257

Epoch: 6| Step: 11
Training loss: 1.5706392526626587
Validation loss: 1.9446664984508226

Epoch: 6| Step: 12
Training loss: 1.3813731670379639
Validation loss: 1.9548961552240516

Epoch: 6| Step: 13
Training loss: 1.2968183755874634
Validation loss: 1.9566616832569081

Epoch: 155| Step: 0
Training loss: 1.1820838451385498
Validation loss: 1.9802824809987059

Epoch: 6| Step: 1
Training loss: 1.208296298980713
Validation loss: 1.9815079755680536

Epoch: 6| Step: 2
Training loss: 1.5234668254852295
Validation loss: 1.9616546900041643

Epoch: 6| Step: 3
Training loss: 1.5080790519714355
Validation loss: 1.9466537980623142

Epoch: 6| Step: 4
Training loss: 0.796600341796875
Validation loss: 1.909469650637719

Epoch: 6| Step: 5
Training loss: 1.484768033027649
Validation loss: 1.8879997243163407

Epoch: 6| Step: 6
Training loss: 1.4969719648361206
Validation loss: 1.8704037435593144

Epoch: 6| Step: 7
Training loss: 1.0702016353607178
Validation loss: 1.8879312135839974

Epoch: 6| Step: 8
Training loss: 1.1722354888916016
Validation loss: 1.8873808486487276

Epoch: 6| Step: 9
Training loss: 2.0170021057128906
Validation loss: 1.8740424802226405

Epoch: 6| Step: 10
Training loss: 1.3120797872543335
Validation loss: 1.9005932205466813

Epoch: 6| Step: 11
Training loss: 1.2198755741119385
Validation loss: 1.8927614432509228

Epoch: 6| Step: 12
Training loss: 1.1443884372711182
Validation loss: 1.899487510804207

Epoch: 6| Step: 13
Training loss: 1.002693772315979
Validation loss: 1.9219727913538616

Epoch: 156| Step: 0
Training loss: 0.8164258003234863
Validation loss: 1.9220743051139257

Epoch: 6| Step: 1
Training loss: 1.407691240310669
Validation loss: 1.8910752496411722

Epoch: 6| Step: 2
Training loss: 1.3498709201812744
Validation loss: 1.9082477387561594

Epoch: 6| Step: 3
Training loss: 1.2838999032974243
Validation loss: 1.9365216326969925

Epoch: 6| Step: 4
Training loss: 1.3577814102172852
Validation loss: 1.9227053093653854

Epoch: 6| Step: 5
Training loss: 1.166776180267334
Validation loss: 1.9163592143725323

Epoch: 6| Step: 6
Training loss: 0.7471684217453003
Validation loss: 1.908080231758856

Epoch: 6| Step: 7
Training loss: 1.581803798675537
Validation loss: 1.9100975067384782

Epoch: 6| Step: 8
Training loss: 0.7558351755142212
Validation loss: 1.8851828677679903

Epoch: 6| Step: 9
Training loss: 1.5580531358718872
Validation loss: 1.865986208761892

Epoch: 6| Step: 10
Training loss: 1.395583152770996
Validation loss: 1.8921980191302556

Epoch: 6| Step: 11
Training loss: 1.4606199264526367
Validation loss: 1.8900624821262975

Epoch: 6| Step: 12
Training loss: 1.3961095809936523
Validation loss: 1.891762779605004

Epoch: 6| Step: 13
Training loss: 1.860579013824463
Validation loss: 1.8705983956654866

Epoch: 157| Step: 0
Training loss: 1.1340198516845703
Validation loss: 1.8627022004896594

Epoch: 6| Step: 1
Training loss: 1.2845406532287598
Validation loss: 1.8671775300015685

Epoch: 6| Step: 2
Training loss: 1.872809886932373
Validation loss: 1.8664376645959833

Epoch: 6| Step: 3
Training loss: 1.0941739082336426
Validation loss: 1.8743115766074068

Epoch: 6| Step: 4
Training loss: 1.2308305501937866
Validation loss: 1.9166334880295621

Epoch: 6| Step: 5
Training loss: 1.5657274723052979
Validation loss: 1.95409147713774

Epoch: 6| Step: 6
Training loss: 1.5065629482269287
Validation loss: 1.974580403297178

Epoch: 6| Step: 7
Training loss: 1.2148957252502441
Validation loss: 1.9812641400162891

Epoch: 6| Step: 8
Training loss: 1.2033476829528809
Validation loss: 1.9980715141501477

Epoch: 6| Step: 9
Training loss: 1.3421287536621094
Validation loss: 1.9783058474140782

Epoch: 6| Step: 10
Training loss: 0.8289197683334351
Validation loss: 1.9741948907093336

Epoch: 6| Step: 11
Training loss: 1.1077629327774048
Validation loss: 1.9918851980599024

Epoch: 6| Step: 12
Training loss: 1.0101847648620605
Validation loss: 1.986071768627372

Epoch: 6| Step: 13
Training loss: 1.7868502140045166
Validation loss: 1.9527660480109594

Epoch: 158| Step: 0
Training loss: 1.2014212608337402
Validation loss: 1.9453841896467312

Epoch: 6| Step: 1
Training loss: 1.1325745582580566
Validation loss: 1.9062865011153682

Epoch: 6| Step: 2
Training loss: 1.4401262998580933
Validation loss: 1.8988574538179623

Epoch: 6| Step: 3
Training loss: 1.0836299657821655
Validation loss: 1.8801910492681688

Epoch: 6| Step: 4
Training loss: 1.7784485816955566
Validation loss: 1.9123642957338722

Epoch: 6| Step: 5
Training loss: 1.6815654039382935
Validation loss: 1.9255716262325164

Epoch: 6| Step: 6
Training loss: 1.0672404766082764
Validation loss: 1.9722667124963575

Epoch: 6| Step: 7
Training loss: 1.0467886924743652
Validation loss: 1.9875270756342078

Epoch: 6| Step: 8
Training loss: 1.4670722484588623
Validation loss: 1.9545248580235306

Epoch: 6| Step: 9
Training loss: 1.2108255624771118
Validation loss: 1.9243395431067354

Epoch: 6| Step: 10
Training loss: 1.186483383178711
Validation loss: 1.912142583118972

Epoch: 6| Step: 11
Training loss: 1.1844151020050049
Validation loss: 1.9015180103240474

Epoch: 6| Step: 12
Training loss: 1.4249099493026733
Validation loss: 1.8966180368136334

Epoch: 6| Step: 13
Training loss: 1.4447661638259888
Validation loss: 1.8818866424663092

Epoch: 159| Step: 0
Training loss: 1.1597065925598145
Validation loss: 1.8753961818192595

Epoch: 6| Step: 1
Training loss: 1.039514183998108
Validation loss: 1.9040591537311513

Epoch: 6| Step: 2
Training loss: 1.4569892883300781
Validation loss: 1.9225631580557874

Epoch: 6| Step: 3
Training loss: 0.7090710997581482
Validation loss: 1.9447943638729792

Epoch: 6| Step: 4
Training loss: 1.1289678812026978
Validation loss: 1.956848890550675

Epoch: 6| Step: 5
Training loss: 1.0043823719024658
Validation loss: 1.9634474131368822

Epoch: 6| Step: 6
Training loss: 1.5167865753173828
Validation loss: 1.9868949023626183

Epoch: 6| Step: 7
Training loss: 1.8459413051605225
Validation loss: 1.9429416643675936

Epoch: 6| Step: 8
Training loss: 1.3010469675064087
Validation loss: 1.9283264798502768

Epoch: 6| Step: 9
Training loss: 0.802723228931427
Validation loss: 1.9269772550111175

Epoch: 6| Step: 10
Training loss: 1.0528504848480225
Validation loss: 1.8931052454056279

Epoch: 6| Step: 11
Training loss: 1.0636420249938965
Validation loss: 1.8745757918204031

Epoch: 6| Step: 12
Training loss: 1.7671409845352173
Validation loss: 1.8791983127593994

Epoch: 6| Step: 13
Training loss: 1.8583723306655884
Validation loss: 1.8594832510076544

Epoch: 160| Step: 0
Training loss: 1.5274982452392578
Validation loss: 1.8502203469635339

Epoch: 6| Step: 1
Training loss: 1.8580067157745361
Validation loss: 1.8418835939899567

Epoch: 6| Step: 2
Training loss: 0.9064820408821106
Validation loss: 1.8261458002110964

Epoch: 6| Step: 3
Training loss: 0.93311607837677
Validation loss: 1.8354293812987625

Epoch: 6| Step: 4
Training loss: 1.3444857597351074
Validation loss: 1.8566807828923708

Epoch: 6| Step: 5
Training loss: 1.4855725765228271
Validation loss: 1.8744182817397579

Epoch: 6| Step: 6
Training loss: 0.8144930601119995
Validation loss: 1.8980354442391345

Epoch: 6| Step: 7
Training loss: 1.1288501024246216
Validation loss: 1.8913460918652114

Epoch: 6| Step: 8
Training loss: 1.7184240818023682
Validation loss: 1.9098957777023315

Epoch: 6| Step: 9
Training loss: 0.8627316951751709
Validation loss: 1.9241219515441566

Epoch: 6| Step: 10
Training loss: 1.1171263456344604
Validation loss: 1.9182102987843175

Epoch: 6| Step: 11
Training loss: 0.8854069709777832
Validation loss: 1.8911900725415958

Epoch: 6| Step: 12
Training loss: 1.1461563110351562
Validation loss: 1.8755382440423454

Epoch: 6| Step: 13
Training loss: 1.1507254838943481
Validation loss: 1.8698674940293836

Epoch: 161| Step: 0
Training loss: 0.7436203360557556
Validation loss: 1.8921946197427728

Epoch: 6| Step: 1
Training loss: 0.8921329379081726
Validation loss: 1.904195071548544

Epoch: 6| Step: 2
Training loss: 0.633550226688385
Validation loss: 1.9276013771692913

Epoch: 6| Step: 3
Training loss: 1.922949194908142
Validation loss: 1.9287152918436195

Epoch: 6| Step: 4
Training loss: 1.083840012550354
Validation loss: 1.9376189952255578

Epoch: 6| Step: 5
Training loss: 1.0931329727172852
Validation loss: 1.9345436570464924

Epoch: 6| Step: 6
Training loss: 1.4428256750106812
Validation loss: 1.9389854285024828

Epoch: 6| Step: 7
Training loss: 1.8400557041168213
Validation loss: 1.9227640859542354

Epoch: 6| Step: 8
Training loss: 1.1160006523132324
Validation loss: 1.9057917825637325

Epoch: 6| Step: 9
Training loss: 1.1011981964111328
Validation loss: 1.8971781564015213

Epoch: 6| Step: 10
Training loss: 1.590545654296875
Validation loss: 1.8883457388929141

Epoch: 6| Step: 11
Training loss: 1.0945055484771729
Validation loss: 1.8764891893632951

Epoch: 6| Step: 12
Training loss: 1.4464726448059082
Validation loss: 1.854390428912255

Epoch: 6| Step: 13
Training loss: 0.7455230951309204
Validation loss: 1.8588149932123

Epoch: 162| Step: 0
Training loss: 1.3428770303726196
Validation loss: 1.8892577220034856

Epoch: 6| Step: 1
Training loss: 1.8516896963119507
Validation loss: 1.9039718040855982

Epoch: 6| Step: 2
Training loss: 0.883051335811615
Validation loss: 1.9166418942072059

Epoch: 6| Step: 3
Training loss: 0.8318887948989868
Validation loss: 1.9417364123047038

Epoch: 6| Step: 4
Training loss: 0.7618221044540405
Validation loss: 1.9341841013200822

Epoch: 6| Step: 5
Training loss: 0.6241346001625061
Validation loss: 1.9192562462181173

Epoch: 6| Step: 6
Training loss: 1.1021696329116821
Validation loss: 1.909016102872869

Epoch: 6| Step: 7
Training loss: 1.0892009735107422
Validation loss: 1.882867823364914

Epoch: 6| Step: 8
Training loss: 1.8498064279556274
Validation loss: 1.875771531494715

Epoch: 6| Step: 9
Training loss: 0.9766634702682495
Validation loss: 1.868698004753359

Epoch: 6| Step: 10
Training loss: 1.552539587020874
Validation loss: 1.8766079615521174

Epoch: 6| Step: 11
Training loss: 1.4172894954681396
Validation loss: 1.8459042451714958

Epoch: 6| Step: 12
Training loss: 1.2483701705932617
Validation loss: 1.8285261956594323

Epoch: 6| Step: 13
Training loss: 1.2943159341812134
Validation loss: 1.8431715221815212

Epoch: 163| Step: 0
Training loss: 1.1762480735778809
Validation loss: 1.852353790754913

Epoch: 6| Step: 1
Training loss: 0.5676031112670898
Validation loss: 1.8735401976493098

Epoch: 6| Step: 2
Training loss: 1.5313962697982788
Validation loss: 1.908148197717564

Epoch: 6| Step: 3
Training loss: 1.3911399841308594
Validation loss: 1.9249661071326143

Epoch: 6| Step: 4
Training loss: 1.4703818559646606
Validation loss: 1.9188121390599076

Epoch: 6| Step: 5
Training loss: 0.7177818417549133
Validation loss: 1.901448671535779

Epoch: 6| Step: 6
Training loss: 1.809836983680725
Validation loss: 1.893801071310556

Epoch: 6| Step: 7
Training loss: 1.055130958557129
Validation loss: 1.8676317353402414

Epoch: 6| Step: 8
Training loss: 1.6982661485671997
Validation loss: 1.8703520644095637

Epoch: 6| Step: 9
Training loss: 0.8460890650749207
Validation loss: 1.8865022197846444

Epoch: 6| Step: 10
Training loss: 0.919823944568634
Validation loss: 1.8742471484727756

Epoch: 6| Step: 11
Training loss: 1.0047295093536377
Validation loss: 1.863060200086204

Epoch: 6| Step: 12
Training loss: 1.3694045543670654
Validation loss: 1.873803565579076

Epoch: 6| Step: 13
Training loss: 1.3107008934020996
Validation loss: 1.8963409777610534

Epoch: 164| Step: 0
Training loss: 0.663689374923706
Validation loss: 1.9364805298466836

Epoch: 6| Step: 1
Training loss: 1.352178931236267
Validation loss: 1.9358293523070633

Epoch: 6| Step: 2
Training loss: 0.9011771082878113
Validation loss: 1.9318061323576077

Epoch: 6| Step: 3
Training loss: 1.7132117748260498
Validation loss: 1.9213579931566793

Epoch: 6| Step: 4
Training loss: 1.1819396018981934
Validation loss: 1.8912340338512132

Epoch: 6| Step: 5
Training loss: 0.9048271775245667
Validation loss: 1.9042327532204248

Epoch: 6| Step: 6
Training loss: 0.9463248252868652
Validation loss: 1.9051413202798495

Epoch: 6| Step: 7
Training loss: 0.9188006520271301
Validation loss: 1.8957170799214353

Epoch: 6| Step: 8
Training loss: 1.4584782123565674
Validation loss: 1.877258328981297

Epoch: 6| Step: 9
Training loss: 1.4903374910354614
Validation loss: 1.8514976347646406

Epoch: 6| Step: 10
Training loss: 0.6240861415863037
Validation loss: 1.8420553463761524

Epoch: 6| Step: 11
Training loss: 1.1811044216156006
Validation loss: 1.824903957305416

Epoch: 6| Step: 12
Training loss: 1.4004018306732178
Validation loss: 1.8262157042821248

Epoch: 6| Step: 13
Training loss: 2.066329002380371
Validation loss: 1.853806628975817

Epoch: 165| Step: 0
Training loss: 0.6371596455574036
Validation loss: 1.8793151609359249

Epoch: 6| Step: 1
Training loss: 1.1769521236419678
Validation loss: 1.9171065271541636

Epoch: 6| Step: 2
Training loss: 0.9266400337219238
Validation loss: 1.9371302973839544

Epoch: 6| Step: 3
Training loss: 1.2348124980926514
Validation loss: 1.9300072449509815

Epoch: 6| Step: 4
Training loss: 1.2939118146896362
Validation loss: 1.9245012896035307

Epoch: 6| Step: 5
Training loss: 1.3005213737487793
Validation loss: 1.9367355005715483

Epoch: 6| Step: 6
Training loss: 1.2254087924957275
Validation loss: 1.9282364986276115

Epoch: 6| Step: 7
Training loss: 1.184628963470459
Validation loss: 1.92025791188722

Epoch: 6| Step: 8
Training loss: 1.903916597366333
Validation loss: 1.9011551872376473

Epoch: 6| Step: 9
Training loss: 0.8334660530090332
Validation loss: 1.8655841453101045

Epoch: 6| Step: 10
Training loss: 1.1211748123168945
Validation loss: 1.8364958622122323

Epoch: 6| Step: 11
Training loss: 1.169904112815857
Validation loss: 1.8140984235271331

Epoch: 6| Step: 12
Training loss: 1.0780377388000488
Validation loss: 1.8162996999679073

Epoch: 6| Step: 13
Training loss: 1.2844491004943848
Validation loss: 1.8051652062323786

Epoch: 166| Step: 0
Training loss: 0.7270968556404114
Validation loss: 1.8328342976108674

Epoch: 6| Step: 1
Training loss: 0.828830361366272
Validation loss: 1.881671933717625

Epoch: 6| Step: 2
Training loss: 0.9548097252845764
Validation loss: 1.9132655923084547

Epoch: 6| Step: 3
Training loss: 1.5126370191574097
Validation loss: 1.9324979038648709

Epoch: 6| Step: 4
Training loss: 1.5233776569366455
Validation loss: 1.9489109746871456

Epoch: 6| Step: 5
Training loss: 1.1278457641601562
Validation loss: 1.977883344055504

Epoch: 6| Step: 6
Training loss: 1.4899351596832275
Validation loss: 1.9856249709283151

Epoch: 6| Step: 7
Training loss: 1.430030345916748
Validation loss: 1.9619941044879217

Epoch: 6| Step: 8
Training loss: 1.1405997276306152
Validation loss: 1.912392681644809

Epoch: 6| Step: 9
Training loss: 1.0763425827026367
Validation loss: 1.9029145061328847

Epoch: 6| Step: 10
Training loss: 1.1063718795776367
Validation loss: 1.883404803532426

Epoch: 6| Step: 11
Training loss: 0.6572685241699219
Validation loss: 1.863351632190007

Epoch: 6| Step: 12
Training loss: 0.9781789779663086
Validation loss: 1.879392062464068

Epoch: 6| Step: 13
Training loss: 1.6003121137619019
Validation loss: 1.8806975323666808

Epoch: 167| Step: 0
Training loss: 1.4500457048416138
Validation loss: 1.8748154371015486

Epoch: 6| Step: 1
Training loss: 1.0001952648162842
Validation loss: 1.874541122426269

Epoch: 6| Step: 2
Training loss: 1.3088815212249756
Validation loss: 1.8542787157079226

Epoch: 6| Step: 3
Training loss: 1.5182968378067017
Validation loss: 1.8804771272085046

Epoch: 6| Step: 4
Training loss: 1.2162216901779175
Validation loss: 1.8842707680117698

Epoch: 6| Step: 5
Training loss: 0.8321520090103149
Validation loss: 1.875668510313957

Epoch: 6| Step: 6
Training loss: 1.0745060443878174
Validation loss: 1.9000938477054719

Epoch: 6| Step: 7
Training loss: 1.1275893449783325
Validation loss: 1.895844127542229

Epoch: 6| Step: 8
Training loss: 1.537948727607727
Validation loss: 1.9233521235886442

Epoch: 6| Step: 9
Training loss: 0.6542860269546509
Validation loss: 1.938479297904558

Epoch: 6| Step: 10
Training loss: 1.023198127746582
Validation loss: 1.921965870805966

Epoch: 6| Step: 11
Training loss: 1.034674882888794
Validation loss: 1.8934650369869765

Epoch: 6| Step: 12
Training loss: 0.9999455213546753
Validation loss: 1.8833426390924761

Epoch: 6| Step: 13
Training loss: 1.3386753797531128
Validation loss: 1.8870846994461552

Epoch: 168| Step: 0
Training loss: 1.0425822734832764
Validation loss: 1.8643000459158292

Epoch: 6| Step: 1
Training loss: 0.7849524617195129
Validation loss: 1.8611768189296927

Epoch: 6| Step: 2
Training loss: 1.166075587272644
Validation loss: 1.8730137912175988

Epoch: 6| Step: 3
Training loss: 0.4354851245880127
Validation loss: 1.86823949890752

Epoch: 6| Step: 4
Training loss: 0.9642271995544434
Validation loss: 1.866729167199904

Epoch: 6| Step: 5
Training loss: 1.6123721599578857
Validation loss: 1.8625152777600031

Epoch: 6| Step: 6
Training loss: 1.080084204673767
Validation loss: 1.8604771039819206

Epoch: 6| Step: 7
Training loss: 1.356073260307312
Validation loss: 1.8371714443288825

Epoch: 6| Step: 8
Training loss: 1.5443742275238037
Validation loss: 1.8403781139722435

Epoch: 6| Step: 9
Training loss: 1.2658164501190186
Validation loss: 1.8512252889653689

Epoch: 6| Step: 10
Training loss: 1.080292820930481
Validation loss: 1.8469914185103549

Epoch: 6| Step: 11
Training loss: 0.8458631634712219
Validation loss: 1.8496109183116625

Epoch: 6| Step: 12
Training loss: 0.9439704418182373
Validation loss: 1.8619720807639502

Epoch: 6| Step: 13
Training loss: 0.9838675260543823
Validation loss: 1.8597044419216853

Epoch: 169| Step: 0
Training loss: 0.7151623964309692
Validation loss: 1.842316145538002

Epoch: 6| Step: 1
Training loss: 1.1840226650238037
Validation loss: 1.8626865135726107

Epoch: 6| Step: 2
Training loss: 1.1698392629623413
Validation loss: 1.8745897867346322

Epoch: 6| Step: 3
Training loss: 1.1799980401992798
Validation loss: 1.878371492508919

Epoch: 6| Step: 4
Training loss: 0.611411452293396
Validation loss: 1.8756638547425628

Epoch: 6| Step: 5
Training loss: 0.889618992805481
Validation loss: 1.8617338301033102

Epoch: 6| Step: 6
Training loss: 1.0517759323120117
Validation loss: 1.8390007377952657

Epoch: 6| Step: 7
Training loss: 0.776459813117981
Validation loss: 1.8389766652096984

Epoch: 6| Step: 8
Training loss: 0.9678950309753418
Validation loss: 1.8336252589379587

Epoch: 6| Step: 9
Training loss: 1.3511943817138672
Validation loss: 1.8379666882176553

Epoch: 6| Step: 10
Training loss: 0.9481534361839294
Validation loss: 1.855210356814887

Epoch: 6| Step: 11
Training loss: 1.5746970176696777
Validation loss: 1.8639676750347178

Epoch: 6| Step: 12
Training loss: 1.9955519437789917
Validation loss: 1.916708080999313

Epoch: 6| Step: 13
Training loss: 0.8652325868606567
Validation loss: 1.9216131600000526

Epoch: 170| Step: 0
Training loss: 1.0004717111587524
Validation loss: 1.9164943310522264

Epoch: 6| Step: 1
Training loss: 1.2850332260131836
Validation loss: 1.9026379944175802

Epoch: 6| Step: 2
Training loss: 0.6825302839279175
Validation loss: 1.9066259591810164

Epoch: 6| Step: 3
Training loss: 0.9777011275291443
Validation loss: 1.8963518309336838

Epoch: 6| Step: 4
Training loss: 1.190801739692688
Validation loss: 1.9226405594938545

Epoch: 6| Step: 5
Training loss: 0.7718758583068848
Validation loss: 1.8962361710045927

Epoch: 6| Step: 6
Training loss: 1.0855770111083984
Validation loss: 1.8698938674824213

Epoch: 6| Step: 7
Training loss: 1.1928292512893677
Validation loss: 1.8519409510397142

Epoch: 6| Step: 8
Training loss: 1.2710838317871094
Validation loss: 1.8163889185074837

Epoch: 6| Step: 9
Training loss: 1.2632436752319336
Validation loss: 1.7983545821200135

Epoch: 6| Step: 10
Training loss: 1.0268367528915405
Validation loss: 1.8263088362191313

Epoch: 6| Step: 11
Training loss: 1.61678147315979
Validation loss: 1.8318971683902125

Epoch: 6| Step: 12
Training loss: 1.244187355041504
Validation loss: 1.8676656785831656

Epoch: 6| Step: 13
Training loss: 1.0983481407165527
Validation loss: 1.8536383464772215

Epoch: 171| Step: 0
Training loss: 1.0719053745269775
Validation loss: 1.8613798554225633

Epoch: 6| Step: 1
Training loss: 1.0021519660949707
Validation loss: 1.8973235430256012

Epoch: 6| Step: 2
Training loss: 1.5651509761810303
Validation loss: 1.9439112588923464

Epoch: 6| Step: 3
Training loss: 1.2002544403076172
Validation loss: 1.9626155643052952

Epoch: 6| Step: 4
Training loss: 1.2149252891540527
Validation loss: 1.9496132737846785

Epoch: 6| Step: 5
Training loss: 1.1227854490280151
Validation loss: 1.951536242679883

Epoch: 6| Step: 6
Training loss: 1.1094002723693848
Validation loss: 1.921310491459344

Epoch: 6| Step: 7
Training loss: 0.7833836078643799
Validation loss: 1.9207312727487216

Epoch: 6| Step: 8
Training loss: 0.6103863716125488
Validation loss: 1.910456290809057

Epoch: 6| Step: 9
Training loss: 0.7884441614151001
Validation loss: 1.8906158554938532

Epoch: 6| Step: 10
Training loss: 1.3615437746047974
Validation loss: 1.8658127374546503

Epoch: 6| Step: 11
Training loss: 1.2560760974884033
Validation loss: 1.876342793946625

Epoch: 6| Step: 12
Training loss: 1.049226999282837
Validation loss: 1.8671374756802794

Epoch: 6| Step: 13
Training loss: 1.2505340576171875
Validation loss: 1.8524951127267653

Epoch: 172| Step: 0
Training loss: 1.081888198852539
Validation loss: 1.862513683175528

Epoch: 6| Step: 1
Training loss: 1.0705716609954834
Validation loss: 1.867781408371464

Epoch: 6| Step: 2
Training loss: 0.9798535108566284
Validation loss: 1.8480495509280954

Epoch: 6| Step: 3
Training loss: 1.4027316570281982
Validation loss: 1.8377739229509908

Epoch: 6| Step: 4
Training loss: 1.5996346473693848
Validation loss: 1.872301455466978

Epoch: 6| Step: 5
Training loss: 0.7410587072372437
Validation loss: 1.8852466267924155

Epoch: 6| Step: 6
Training loss: 1.3562122583389282
Validation loss: 1.880085111946188

Epoch: 6| Step: 7
Training loss: 0.6395358443260193
Validation loss: 1.8709229500063005

Epoch: 6| Step: 8
Training loss: 1.1304458379745483
Validation loss: 1.8600162600958219

Epoch: 6| Step: 9
Training loss: 1.2812591791152954
Validation loss: 1.8471898724955897

Epoch: 6| Step: 10
Training loss: 0.8671590089797974
Validation loss: 1.8720148353166477

Epoch: 6| Step: 11
Training loss: 1.1631128787994385
Validation loss: 1.8674089626599384

Epoch: 6| Step: 12
Training loss: 0.4287090301513672
Validation loss: 1.8795626958211262

Epoch: 6| Step: 13
Training loss: 1.1978862285614014
Validation loss: 1.8661430035867999

Epoch: 173| Step: 0
Training loss: 1.281235933303833
Validation loss: 1.8858738150647891

Epoch: 6| Step: 1
Training loss: 1.4490574598312378
Validation loss: 1.885556233826504

Epoch: 6| Step: 2
Training loss: 1.3501335382461548
Validation loss: 1.9166490249736334

Epoch: 6| Step: 3
Training loss: 0.7298114895820618
Validation loss: 1.933570170915255

Epoch: 6| Step: 4
Training loss: 0.6504955291748047
Validation loss: 1.9519228102058492

Epoch: 6| Step: 5
Training loss: 1.0094002485275269
Validation loss: 1.9438149018954205

Epoch: 6| Step: 6
Training loss: 1.0917105674743652
Validation loss: 1.922813234790679

Epoch: 6| Step: 7
Training loss: 0.7667665481567383
Validation loss: 1.900074142281727

Epoch: 6| Step: 8
Training loss: 1.1412651538848877
Validation loss: 1.8653241895860242

Epoch: 6| Step: 9
Training loss: 1.0594804286956787
Validation loss: 1.8381989617501535

Epoch: 6| Step: 10
Training loss: 1.2554583549499512
Validation loss: 1.8379231768269693

Epoch: 6| Step: 11
Training loss: 1.015684962272644
Validation loss: 1.8087638975471578

Epoch: 6| Step: 12
Training loss: 0.9337178468704224
Validation loss: 1.7909975141607306

Epoch: 6| Step: 13
Training loss: 0.8939957022666931
Validation loss: 1.8086813316550305

Epoch: 174| Step: 0
Training loss: 0.8609411716461182
Validation loss: 1.812515547198634

Epoch: 6| Step: 1
Training loss: 1.528930902481079
Validation loss: 1.7976116198365406

Epoch: 6| Step: 2
Training loss: 1.1733629703521729
Validation loss: 1.8369112758226291

Epoch: 6| Step: 3
Training loss: 1.5186657905578613
Validation loss: 1.8546710039979668

Epoch: 6| Step: 4
Training loss: 0.9789199829101562
Validation loss: 1.8976735107360347

Epoch: 6| Step: 5
Training loss: 1.2424166202545166
Validation loss: 1.9350006682898409

Epoch: 6| Step: 6
Training loss: 0.7435076236724854
Validation loss: 1.952526935967066

Epoch: 6| Step: 7
Training loss: 0.6725683212280273
Validation loss: 1.9803631664604269

Epoch: 6| Step: 8
Training loss: 1.1823313236236572
Validation loss: 1.9898872016578593

Epoch: 6| Step: 9
Training loss: 0.7261168956756592
Validation loss: 1.9514393191183768

Epoch: 6| Step: 10
Training loss: 1.2923433780670166
Validation loss: 1.9213977065137637

Epoch: 6| Step: 11
Training loss: 0.71903395652771
Validation loss: 1.8842686196809173

Epoch: 6| Step: 12
Training loss: 1.0442776679992676
Validation loss: 1.8479484088959233

Epoch: 6| Step: 13
Training loss: 1.4154045581817627
Validation loss: 1.826919447991156

Epoch: 175| Step: 0
Training loss: 0.9458783864974976
Validation loss: 1.7954846697468911

Epoch: 6| Step: 1
Training loss: 0.994469165802002
Validation loss: 1.7845698812956452

Epoch: 6| Step: 2
Training loss: 0.9511891007423401
Validation loss: 1.7864959842415267

Epoch: 6| Step: 3
Training loss: 0.7272493243217468
Validation loss: 1.7759801110913676

Epoch: 6| Step: 4
Training loss: 0.8452475070953369
Validation loss: 1.7922453752128027

Epoch: 6| Step: 5
Training loss: 0.961083173751831
Validation loss: 1.7831562026854484

Epoch: 6| Step: 6
Training loss: 1.050411343574524
Validation loss: 1.8042598629510531

Epoch: 6| Step: 7
Training loss: 0.934443473815918
Validation loss: 1.8176362809314524

Epoch: 6| Step: 8
Training loss: 1.2186546325683594
Validation loss: 1.8359848978698894

Epoch: 6| Step: 9
Training loss: 0.9535607099533081
Validation loss: 1.8266265981940812

Epoch: 6| Step: 10
Training loss: 1.615631103515625
Validation loss: 1.832130160382999

Epoch: 6| Step: 11
Training loss: 0.704258382320404
Validation loss: 1.8458576074210546

Epoch: 6| Step: 12
Training loss: 1.0559436082839966
Validation loss: 1.8488302730744886

Epoch: 6| Step: 13
Training loss: 1.3912655115127563
Validation loss: 1.8352081903847315

Epoch: 176| Step: 0
Training loss: 1.1522294282913208
Validation loss: 1.8389804670887608

Epoch: 6| Step: 1
Training loss: 0.7920506000518799
Validation loss: 1.8391847995019728

Epoch: 6| Step: 2
Training loss: 1.0008935928344727
Validation loss: 1.8289419527976745

Epoch: 6| Step: 3
Training loss: 1.1745853424072266
Validation loss: 1.8283013220756286

Epoch: 6| Step: 4
Training loss: 0.8160775899887085
Validation loss: 1.8011865846572384

Epoch: 6| Step: 5
Training loss: 1.4186748266220093
Validation loss: 1.7843092103158273

Epoch: 6| Step: 6
Training loss: 0.6693670749664307
Validation loss: 1.8130613103989632

Epoch: 6| Step: 7
Training loss: 0.8264598250389099
Validation loss: 1.8071018624049362

Epoch: 6| Step: 8
Training loss: 0.5681204795837402
Validation loss: 1.8133643493857434

Epoch: 6| Step: 9
Training loss: 1.1096681356430054
Validation loss: 1.814990533295498

Epoch: 6| Step: 10
Training loss: 1.2492706775665283
Validation loss: 1.806138107853551

Epoch: 6| Step: 11
Training loss: 1.3742871284484863
Validation loss: 1.8076069380647393

Epoch: 6| Step: 12
Training loss: 1.1269631385803223
Validation loss: 1.8089683081514092

Epoch: 6| Step: 13
Training loss: 0.5825785398483276
Validation loss: 1.816032112285655

Epoch: 177| Step: 0
Training loss: 0.8485270738601685
Validation loss: 1.7949058061004968

Epoch: 6| Step: 1
Training loss: 1.1503077745437622
Validation loss: 1.8110007086107809

Epoch: 6| Step: 2
Training loss: 0.8235926032066345
Validation loss: 1.8089848192789222

Epoch: 6| Step: 3
Training loss: 0.8423985838890076
Validation loss: 1.8076070803467945

Epoch: 6| Step: 4
Training loss: 1.0399608612060547
Validation loss: 1.8168070867497434

Epoch: 6| Step: 5
Training loss: 0.5796404480934143
Validation loss: 1.8086707784283547

Epoch: 6| Step: 6
Training loss: 0.6691997647285461
Validation loss: 1.8245614010800597

Epoch: 6| Step: 7
Training loss: 1.2480605840682983
Validation loss: 1.7987220184777373

Epoch: 6| Step: 8
Training loss: 1.2835441827774048
Validation loss: 1.7985730735204553

Epoch: 6| Step: 9
Training loss: 1.5428540706634521
Validation loss: 1.8170861787693475

Epoch: 6| Step: 10
Training loss: 0.954105794429779
Validation loss: 1.811618890813602

Epoch: 6| Step: 11
Training loss: 0.6051898002624512
Validation loss: 1.8066603099146197

Epoch: 6| Step: 12
Training loss: 1.00211501121521
Validation loss: 1.8375368451559415

Epoch: 6| Step: 13
Training loss: 1.0741032361984253
Validation loss: 1.8240583660782024

Epoch: 178| Step: 0
Training loss: 1.369372844696045
Validation loss: 1.8171415572525353

Epoch: 6| Step: 1
Training loss: 1.2476308345794678
Validation loss: 1.7894287981012815

Epoch: 6| Step: 2
Training loss: 0.9070197343826294
Validation loss: 1.8072146074746245

Epoch: 6| Step: 3
Training loss: 0.7051512002944946
Validation loss: 1.8037151495615642

Epoch: 6| Step: 4
Training loss: 0.7507972717285156
Validation loss: 1.803002692038013

Epoch: 6| Step: 5
Training loss: 0.6897518634796143
Validation loss: 1.7971318716643958

Epoch: 6| Step: 6
Training loss: 0.73345947265625
Validation loss: 1.7981957088234604

Epoch: 6| Step: 7
Training loss: 1.3197205066680908
Validation loss: 1.7838842368895007

Epoch: 6| Step: 8
Training loss: 1.3455336093902588
Validation loss: 1.7802937338429112

Epoch: 6| Step: 9
Training loss: 0.5863245129585266
Validation loss: 1.7639436747438164

Epoch: 6| Step: 10
Training loss: 0.9167980551719666
Validation loss: 1.7635150904296546

Epoch: 6| Step: 11
Training loss: 0.7163341045379639
Validation loss: 1.7798225982214815

Epoch: 6| Step: 12
Training loss: 0.6569396257400513
Validation loss: 1.786476541590947

Epoch: 6| Step: 13
Training loss: 1.4633983373641968
Validation loss: 1.7950685665171633

Epoch: 179| Step: 0
Training loss: 0.8296304941177368
Validation loss: 1.8391009697350122

Epoch: 6| Step: 1
Training loss: 0.8146126866340637
Validation loss: 1.8265695610354025

Epoch: 6| Step: 2
Training loss: 1.1847057342529297
Validation loss: 1.8144564423509824

Epoch: 6| Step: 3
Training loss: 1.148722767829895
Validation loss: 1.8099282108327395

Epoch: 6| Step: 4
Training loss: 0.8734601736068726
Validation loss: 1.8029751982740176

Epoch: 6| Step: 5
Training loss: 0.8546916246414185
Validation loss: 1.8240339653466338

Epoch: 6| Step: 6
Training loss: 0.8375539779663086
Validation loss: 1.8493427217647593

Epoch: 6| Step: 7
Training loss: 1.0514099597930908
Validation loss: 1.838185074508831

Epoch: 6| Step: 8
Training loss: 1.2814311981201172
Validation loss: 1.8107178416303409

Epoch: 6| Step: 9
Training loss: 1.2380071878433228
Validation loss: 1.8210802808884652

Epoch: 6| Step: 10
Training loss: 0.48764827847480774
Validation loss: 1.8395406328221804

Epoch: 6| Step: 11
Training loss: 1.015100121498108
Validation loss: 1.8406250092291063

Epoch: 6| Step: 12
Training loss: 0.9047967195510864
Validation loss: 1.8003340305820588

Epoch: 6| Step: 13
Training loss: 0.726780891418457
Validation loss: 1.800686526042159

Epoch: 180| Step: 0
Training loss: 1.3040170669555664
Validation loss: 1.7728762101101618

Epoch: 6| Step: 1
Training loss: 0.7318294644355774
Validation loss: 1.7785945425751388

Epoch: 6| Step: 2
Training loss: 1.1451326608657837
Validation loss: 1.8089865740909372

Epoch: 6| Step: 3
Training loss: 0.7690065503120422
Validation loss: 1.8222691371876707

Epoch: 6| Step: 4
Training loss: 1.2729599475860596
Validation loss: 1.8426757012644122

Epoch: 6| Step: 5
Training loss: 0.8327111005783081
Validation loss: 1.820872422187559

Epoch: 6| Step: 6
Training loss: 1.2075350284576416
Validation loss: 1.8321355773556618

Epoch: 6| Step: 7
Training loss: 0.4707683324813843
Validation loss: 1.820785536560961

Epoch: 6| Step: 8
Training loss: 0.7911570072174072
Validation loss: 1.862040263350292

Epoch: 6| Step: 9
Training loss: 1.0451946258544922
Validation loss: 1.8529565244592645

Epoch: 6| Step: 10
Training loss: 1.050479769706726
Validation loss: 1.8498904423047138

Epoch: 6| Step: 11
Training loss: 0.8441629409790039
Validation loss: 1.855937373253607

Epoch: 6| Step: 12
Training loss: 1.050154685974121
Validation loss: 1.882890373147944

Epoch: 6| Step: 13
Training loss: 0.5282580852508545
Validation loss: 1.8547027111053467

Epoch: 181| Step: 0
Training loss: 1.09027099609375
Validation loss: 1.8743413186842395

Epoch: 6| Step: 1
Training loss: 0.533950686454773
Validation loss: 1.8408920790559502

Epoch: 6| Step: 2
Training loss: 1.386338233947754
Validation loss: 1.8077148365718063

Epoch: 6| Step: 3
Training loss: 0.4737245440483093
Validation loss: 1.7984230108158563

Epoch: 6| Step: 4
Training loss: 1.0435569286346436
Validation loss: 1.8103824174532326

Epoch: 6| Step: 5
Training loss: 0.6028421521186829
Validation loss: 1.7994590523422405

Epoch: 6| Step: 6
Training loss: 0.7684407830238342
Validation loss: 1.777176167375298

Epoch: 6| Step: 7
Training loss: 1.1109896898269653
Validation loss: 1.7724094531869377

Epoch: 6| Step: 8
Training loss: 1.0700812339782715
Validation loss: 1.7756254121821413

Epoch: 6| Step: 9
Training loss: 1.4609918594360352
Validation loss: 1.7869256542574974

Epoch: 6| Step: 10
Training loss: 0.8510973453521729
Validation loss: 1.8261098695057694

Epoch: 6| Step: 11
Training loss: 0.6653485298156738
Validation loss: 1.8609075315536991

Epoch: 6| Step: 12
Training loss: 0.9790171384811401
Validation loss: 1.8775691473355858

Epoch: 6| Step: 13
Training loss: 1.3469346761703491
Validation loss: 1.879698666193152

Epoch: 182| Step: 0
Training loss: 0.8001465797424316
Validation loss: 1.851968410194561

Epoch: 6| Step: 1
Training loss: 1.5534166097640991
Validation loss: 1.8434701247881817

Epoch: 6| Step: 2
Training loss: 0.8264570832252502
Validation loss: 1.8577006555372668

Epoch: 6| Step: 3
Training loss: 1.2271289825439453
Validation loss: 1.8812512851530505

Epoch: 6| Step: 4
Training loss: 0.8504363298416138
Validation loss: 1.8611571686242216

Epoch: 6| Step: 5
Training loss: 1.1706713438034058
Validation loss: 1.8585473516935944

Epoch: 6| Step: 6
Training loss: 1.4604507684707642
Validation loss: 1.8575668411870156

Epoch: 6| Step: 7
Training loss: 0.6421933770179749
Validation loss: 1.8463501840509393

Epoch: 6| Step: 8
Training loss: 0.41684773564338684
Validation loss: 1.843147539323376

Epoch: 6| Step: 9
Training loss: 1.0617376565933228
Validation loss: 1.8774223635273595

Epoch: 6| Step: 10
Training loss: 0.7309675216674805
Validation loss: 1.885180175945323

Epoch: 6| Step: 11
Training loss: 1.0392446517944336
Validation loss: 1.8908623726137224

Epoch: 6| Step: 12
Training loss: 0.8611702919006348
Validation loss: 1.8343762889985116

Epoch: 6| Step: 13
Training loss: 0.6275736689567566
Validation loss: 1.7916972444903465

Epoch: 183| Step: 0
Training loss: 0.8327561616897583
Validation loss: 1.7530323036255375

Epoch: 6| Step: 1
Training loss: 0.8875712752342224
Validation loss: 1.7623208825306227

Epoch: 6| Step: 2
Training loss: 0.8591524362564087
Validation loss: 1.7740476272439445

Epoch: 6| Step: 3
Training loss: 1.0445131063461304
Validation loss: 1.7627582614139845

Epoch: 6| Step: 4
Training loss: 0.936111569404602
Validation loss: 1.7581948695644256

Epoch: 6| Step: 5
Training loss: 0.7480263710021973
Validation loss: 1.7807124558315481

Epoch: 6| Step: 6
Training loss: 0.8652145266532898
Validation loss: 1.781772699407352

Epoch: 6| Step: 7
Training loss: 0.9778357744216919
Validation loss: 1.8008229488967566

Epoch: 6| Step: 8
Training loss: 0.7839028835296631
Validation loss: 1.8723178935307327

Epoch: 6| Step: 9
Training loss: 0.9176721572875977
Validation loss: 1.8512725317349998

Epoch: 6| Step: 10
Training loss: 0.9676012992858887
Validation loss: 1.8481381721394037

Epoch: 6| Step: 11
Training loss: 1.84783136844635
Validation loss: 1.8403858036123297

Epoch: 6| Step: 12
Training loss: 0.8231279850006104
Validation loss: 1.752562826679599

Epoch: 6| Step: 13
Training loss: 0.9095631837844849
Validation loss: 1.7515960765141312

Epoch: 184| Step: 0
Training loss: 0.6612913608551025
Validation loss: 1.7809158268795218

Epoch: 6| Step: 1
Training loss: 1.2704761028289795
Validation loss: 1.821121500384423

Epoch: 6| Step: 2
Training loss: 1.0045382976531982
Validation loss: 1.8653870180088987

Epoch: 6| Step: 3
Training loss: 1.0459017753601074
Validation loss: 1.9125661721793554

Epoch: 6| Step: 4
Training loss: 0.7897344827651978
Validation loss: 1.9322125616893973

Epoch: 6| Step: 5
Training loss: 1.1518497467041016
Validation loss: 1.983109951019287

Epoch: 6| Step: 6
Training loss: 0.7624690532684326
Validation loss: 1.9857000048442552

Epoch: 6| Step: 7
Training loss: 1.0451574325561523
Validation loss: 1.9514206891418786

Epoch: 6| Step: 8
Training loss: 0.7212733030319214
Validation loss: 1.882079973015734

Epoch: 6| Step: 9
Training loss: 1.531437873840332
Validation loss: 1.8383574549869826

Epoch: 6| Step: 10
Training loss: 0.8861614465713501
Validation loss: 1.7670959682874783

Epoch: 6| Step: 11
Training loss: 0.8755484819412231
Validation loss: 1.7717912338113273

Epoch: 6| Step: 12
Training loss: 0.4800608158111572
Validation loss: 1.7541012674249628

Epoch: 6| Step: 13
Training loss: 1.358938455581665
Validation loss: 1.7512472842329292

Epoch: 185| Step: 0
Training loss: 0.9390217065811157
Validation loss: 1.7688868276534542

Epoch: 6| Step: 1
Training loss: 1.307598352432251
Validation loss: 1.7513767288577171

Epoch: 6| Step: 2
Training loss: 1.0221548080444336
Validation loss: 1.7711310784022014

Epoch: 6| Step: 3
Training loss: 1.000095009803772
Validation loss: 1.7756889686789563

Epoch: 6| Step: 4
Training loss: 0.8305349349975586
Validation loss: 1.772554175828093

Epoch: 6| Step: 5
Training loss: 0.8648805618286133
Validation loss: 1.7677033793541692

Epoch: 6| Step: 6
Training loss: 0.8336057662963867
Validation loss: 1.7902996232432704

Epoch: 6| Step: 7
Training loss: 0.945502519607544
Validation loss: 1.793382235752639

Epoch: 6| Step: 8
Training loss: 0.7148079872131348
Validation loss: 1.8304549596642936

Epoch: 6| Step: 9
Training loss: 0.8640623092651367
Validation loss: 1.820796437160943

Epoch: 6| Step: 10
Training loss: 0.8458836078643799
Validation loss: 1.824988926610639

Epoch: 6| Step: 11
Training loss: 1.0371980667114258
Validation loss: 1.7826075130893337

Epoch: 6| Step: 12
Training loss: 0.7032918334007263
Validation loss: 1.7860919820365084

Epoch: 6| Step: 13
Training loss: 0.4809111952781677
Validation loss: 1.7808594806219942

Epoch: 186| Step: 0
Training loss: 0.4827498197555542
Validation loss: 1.8122320354625743

Epoch: 6| Step: 1
Training loss: 0.7725115418434143
Validation loss: 1.8160214731770177

Epoch: 6| Step: 2
Training loss: 0.9843051433563232
Validation loss: 1.8467592731598885

Epoch: 6| Step: 3
Training loss: 0.6144636869430542
Validation loss: 1.8423645804005284

Epoch: 6| Step: 4
Training loss: 0.7104233503341675
Validation loss: 1.8489693467335035

Epoch: 6| Step: 5
Training loss: 1.2927350997924805
Validation loss: 1.8662541732993176

Epoch: 6| Step: 6
Training loss: 0.9847042560577393
Validation loss: 1.8641615042122461

Epoch: 6| Step: 7
Training loss: 0.694923996925354
Validation loss: 1.888519217891078

Epoch: 6| Step: 8
Training loss: 1.2357779741287231
Validation loss: 1.8719885400546494

Epoch: 6| Step: 9
Training loss: 0.8556287288665771
Validation loss: 1.8611522515614827

Epoch: 6| Step: 10
Training loss: 1.2554371356964111
Validation loss: 1.8415638554480769

Epoch: 6| Step: 11
Training loss: 1.1118683815002441
Validation loss: 1.8081479277662051

Epoch: 6| Step: 12
Training loss: 1.0399967432022095
Validation loss: 1.7924250184848745

Epoch: 6| Step: 13
Training loss: 0.8047551512718201
Validation loss: 1.777673900768321

Epoch: 187| Step: 0
Training loss: 0.9052132368087769
Validation loss: 1.8109910603492492

Epoch: 6| Step: 1
Training loss: 1.167460560798645
Validation loss: 1.7930007416714904

Epoch: 6| Step: 2
Training loss: 0.819907546043396
Validation loss: 1.7804164553201327

Epoch: 6| Step: 3
Training loss: 0.7895500659942627
Validation loss: 1.7848477953223771

Epoch: 6| Step: 4
Training loss: 1.084107518196106
Validation loss: 1.7937746509428947

Epoch: 6| Step: 5
Training loss: 0.6400482654571533
Validation loss: 1.805041584917294

Epoch: 6| Step: 6
Training loss: 0.5955458879470825
Validation loss: 1.8167509455834665

Epoch: 6| Step: 7
Training loss: 1.0204212665557861
Validation loss: 1.8242434481138825

Epoch: 6| Step: 8
Training loss: 1.30242919921875
Validation loss: 1.8173330355716009

Epoch: 6| Step: 9
Training loss: 0.9039679765701294
Validation loss: 1.8143217743083995

Epoch: 6| Step: 10
Training loss: 0.6679598093032837
Validation loss: 1.7975872870414489

Epoch: 6| Step: 11
Training loss: 1.028540849685669
Validation loss: 1.7710052600470922

Epoch: 6| Step: 12
Training loss: 0.5519698858261108
Validation loss: 1.7752540342269405

Epoch: 6| Step: 13
Training loss: 0.5566965937614441
Validation loss: 1.7727537385879024

Epoch: 188| Step: 0
Training loss: 0.9171141982078552
Validation loss: 1.7466115310627928

Epoch: 6| Step: 1
Training loss: 0.7457965612411499
Validation loss: 1.765143266288183

Epoch: 6| Step: 2
Training loss: 0.6828896999359131
Validation loss: 1.7270207405090332

Epoch: 6| Step: 3
Training loss: 0.7600637078285217
Validation loss: 1.7528828446583082

Epoch: 6| Step: 4
Training loss: 1.0353518724441528
Validation loss: 1.723896252211704

Epoch: 6| Step: 5
Training loss: 1.4067456722259521
Validation loss: 1.7408781051635742

Epoch: 6| Step: 6
Training loss: 0.6497171521186829
Validation loss: 1.7799397104529924

Epoch: 6| Step: 7
Training loss: 0.9752760529518127
Validation loss: 1.783063341212529

Epoch: 6| Step: 8
Training loss: 0.8444559574127197
Validation loss: 1.776819472671837

Epoch: 6| Step: 9
Training loss: 0.6425784230232239
Validation loss: 1.783286948357859

Epoch: 6| Step: 10
Training loss: 0.658903956413269
Validation loss: 1.8118558211993145

Epoch: 6| Step: 11
Training loss: 0.7116561532020569
Validation loss: 1.8060613165619552

Epoch: 6| Step: 12
Training loss: 1.2003498077392578
Validation loss: 1.8223789609888548

Epoch: 6| Step: 13
Training loss: 0.16424793004989624
Validation loss: 1.8316715173823859

Epoch: 189| Step: 0
Training loss: 0.9225126504898071
Validation loss: 1.7951981611149286

Epoch: 6| Step: 1
Training loss: 0.873908281326294
Validation loss: 1.8007915212262062

Epoch: 6| Step: 2
Training loss: 0.6743263602256775
Validation loss: 1.769400824782669

Epoch: 6| Step: 3
Training loss: 0.859406054019928
Validation loss: 1.7632117168877715

Epoch: 6| Step: 4
Training loss: 0.41630810499191284
Validation loss: 1.746064519369474

Epoch: 6| Step: 5
Training loss: 0.9430846571922302
Validation loss: 1.7593407272010722

Epoch: 6| Step: 6
Training loss: 0.5993934869766235
Validation loss: 1.7512181317934425

Epoch: 6| Step: 7
Training loss: 0.6517536044120789
Validation loss: 1.73245951308999

Epoch: 6| Step: 8
Training loss: 1.1788814067840576
Validation loss: 1.7736918093055807

Epoch: 6| Step: 9
Training loss: 0.8564792275428772
Validation loss: 1.7968027796796573

Epoch: 6| Step: 10
Training loss: 0.7091652750968933
Validation loss: 1.7801903268342376

Epoch: 6| Step: 11
Training loss: 1.1267235279083252
Validation loss: 1.8091538965061147

Epoch: 6| Step: 12
Training loss: 1.2525956630706787
Validation loss: 1.7930727979188323

Epoch: 6| Step: 13
Training loss: 0.46320411562919617
Validation loss: 1.8055588929883895

Epoch: 190| Step: 0
Training loss: 0.9807958006858826
Validation loss: 1.7564562059217883

Epoch: 6| Step: 1
Training loss: 0.6860376596450806
Validation loss: 1.7507956617621965

Epoch: 6| Step: 2
Training loss: 0.7844310998916626
Validation loss: 1.744074518962573

Epoch: 6| Step: 3
Training loss: 0.7068813443183899
Validation loss: 1.7341243528550672

Epoch: 6| Step: 4
Training loss: 1.2965030670166016
Validation loss: 1.7703627104400306

Epoch: 6| Step: 5
Training loss: 1.0489742755889893
Validation loss: 1.7760716958712506

Epoch: 6| Step: 6
Training loss: 0.830228328704834
Validation loss: 1.7935753535198908

Epoch: 6| Step: 7
Training loss: 0.3285112977027893
Validation loss: 1.8123222602311002

Epoch: 6| Step: 8
Training loss: 0.7125005722045898
Validation loss: 1.8398781514936877

Epoch: 6| Step: 9
Training loss: 0.7692049145698547
Validation loss: 1.8293984013219033

Epoch: 6| Step: 10
Training loss: 0.5366654396057129
Validation loss: 1.8175333366599133

Epoch: 6| Step: 11
Training loss: 1.1330244541168213
Validation loss: 1.8008854107190204

Epoch: 6| Step: 12
Training loss: 0.950455904006958
Validation loss: 1.7798020634599911

Epoch: 6| Step: 13
Training loss: 0.8538132905960083
Validation loss: 1.7472088965036536

Epoch: 191| Step: 0
Training loss: 1.2175779342651367
Validation loss: 1.7677513809614285

Epoch: 6| Step: 1
Training loss: 0.8683812022209167
Validation loss: 1.7681637502485705

Epoch: 6| Step: 2
Training loss: 0.8385748863220215
Validation loss: 1.7621339803100915

Epoch: 6| Step: 3
Training loss: 0.27215930819511414
Validation loss: 1.8010055736828876

Epoch: 6| Step: 4
Training loss: 0.9263953566551208
Validation loss: 1.790600513899198

Epoch: 6| Step: 5
Training loss: 1.009413242340088
Validation loss: 1.803058019248388

Epoch: 6| Step: 6
Training loss: 0.7111606597900391
Validation loss: 1.8099545560857302

Epoch: 6| Step: 7
Training loss: 1.0066308975219727
Validation loss: 1.8117480688197638

Epoch: 6| Step: 8
Training loss: 0.8835133910179138
Validation loss: 1.833689050007892

Epoch: 6| Step: 9
Training loss: 0.7234913110733032
Validation loss: 1.8631003569531184

Epoch: 6| Step: 10
Training loss: 0.6892299652099609
Validation loss: 1.8126814096204695

Epoch: 6| Step: 11
Training loss: 1.2723579406738281
Validation loss: 1.7913675808137464

Epoch: 6| Step: 12
Training loss: 0.4377993941307068
Validation loss: 1.779432726162736

Epoch: 6| Step: 13
Training loss: 0.5009017586708069
Validation loss: 1.7782231582108365

Epoch: 192| Step: 0
Training loss: 0.8808990716934204
Validation loss: 1.7684862152222665

Epoch: 6| Step: 1
Training loss: 0.417302668094635
Validation loss: 1.7796898157365861

Epoch: 6| Step: 2
Training loss: 1.3541018962860107
Validation loss: 1.7766256152942617

Epoch: 6| Step: 3
Training loss: 0.641508162021637
Validation loss: 1.7820539243759648

Epoch: 6| Step: 4
Training loss: 0.9488123059272766
Validation loss: 1.7917240229986047

Epoch: 6| Step: 5
Training loss: 0.6060622930526733
Validation loss: 1.7942274219246321

Epoch: 6| Step: 6
Training loss: 0.6709299087524414
Validation loss: 1.776272645560644

Epoch: 6| Step: 7
Training loss: 0.6558575630187988
Validation loss: 1.797398929954857

Epoch: 6| Step: 8
Training loss: 0.6820924282073975
Validation loss: 1.8008754202114639

Epoch: 6| Step: 9
Training loss: 0.9362353086471558
Validation loss: 1.8170500980910433

Epoch: 6| Step: 10
Training loss: 0.8189682960510254
Validation loss: 1.8387169299587127

Epoch: 6| Step: 11
Training loss: 1.0161051750183105
Validation loss: 1.8134301131771458

Epoch: 6| Step: 12
Training loss: 0.6884714961051941
Validation loss: 1.8041304721627185

Epoch: 6| Step: 13
Training loss: 1.0902467966079712
Validation loss: 1.8189655093736545

Epoch: 193| Step: 0
Training loss: 0.8071605563163757
Validation loss: 1.8233039661120343

Epoch: 6| Step: 1
Training loss: 0.7328000068664551
Validation loss: 1.8579117892890848

Epoch: 6| Step: 2
Training loss: 0.73180091381073
Validation loss: 1.8929495593552947

Epoch: 6| Step: 3
Training loss: 0.9886745810508728
Validation loss: 1.8791202550293298

Epoch: 6| Step: 4
Training loss: 0.7942864298820496
Validation loss: 1.8460660390956427

Epoch: 6| Step: 5
Training loss: 0.7329109907150269
Validation loss: 1.7941749326644405

Epoch: 6| Step: 6
Training loss: 0.6008257269859314
Validation loss: 1.7761291361624194

Epoch: 6| Step: 7
Training loss: 1.2334985733032227
Validation loss: 1.784077919939513

Epoch: 6| Step: 8
Training loss: 1.135384202003479
Validation loss: 1.792067277816034

Epoch: 6| Step: 9
Training loss: 0.6330676674842834
Validation loss: 1.8030126607546242

Epoch: 6| Step: 10
Training loss: 1.105725646018982
Validation loss: 1.8172076068898684

Epoch: 6| Step: 11
Training loss: 1.0341575145721436
Validation loss: 1.8304396547296995

Epoch: 6| Step: 12
Training loss: 0.4522172510623932
Validation loss: 1.8390717878136584

Epoch: 6| Step: 13
Training loss: 0.544543981552124
Validation loss: 1.8362817713009414

Epoch: 194| Step: 0
Training loss: 1.001527190208435
Validation loss: 1.8379076014282882

Epoch: 6| Step: 1
Training loss: 0.6197628378868103
Validation loss: 1.8140916696158789

Epoch: 6| Step: 2
Training loss: 1.1327215433120728
Validation loss: 1.7829006756505659

Epoch: 6| Step: 3
Training loss: 0.5216801762580872
Validation loss: 1.7437243871791388

Epoch: 6| Step: 4
Training loss: 0.6796072125434875
Validation loss: 1.7220314830862067

Epoch: 6| Step: 5
Training loss: 0.8015957474708557
Validation loss: 1.71786392119623

Epoch: 6| Step: 6
Training loss: 0.8188285827636719
Validation loss: 1.720049835020496

Epoch: 6| Step: 7
Training loss: 0.7485994100570679
Validation loss: 1.721894148857363

Epoch: 6| Step: 8
Training loss: 0.7428850531578064
Validation loss: 1.7631475258898992

Epoch: 6| Step: 9
Training loss: 0.9807778000831604
Validation loss: 1.8111558768057054

Epoch: 6| Step: 10
Training loss: 0.7900879383087158
Validation loss: 1.8710719141908871

Epoch: 6| Step: 11
Training loss: 1.0020787715911865
Validation loss: 1.883492515933129

Epoch: 6| Step: 12
Training loss: 0.9366009831428528
Validation loss: 1.8811985151742094

Epoch: 6| Step: 13
Training loss: 0.5605786442756653
Validation loss: 1.8430675947537987

Epoch: 195| Step: 0
Training loss: 1.0336785316467285
Validation loss: 1.8251178085163076

Epoch: 6| Step: 1
Training loss: 0.6342097520828247
Validation loss: 1.8228770507279264

Epoch: 6| Step: 2
Training loss: 0.9828287959098816
Validation loss: 1.7885017369383125

Epoch: 6| Step: 3
Training loss: 0.3465677499771118
Validation loss: 1.7944267180658156

Epoch: 6| Step: 4
Training loss: 0.9111210107803345
Validation loss: 1.7817941698976743

Epoch: 6| Step: 5
Training loss: 0.866432785987854
Validation loss: 1.799274315116226

Epoch: 6| Step: 6
Training loss: 0.9480435848236084
Validation loss: 1.767713632634891

Epoch: 6| Step: 7
Training loss: 0.691287100315094
Validation loss: 1.7610296972336308

Epoch: 6| Step: 8
Training loss: 0.6675273776054382
Validation loss: 1.7743266808089388

Epoch: 6| Step: 9
Training loss: 0.9824747443199158
Validation loss: 1.771201398423923

Epoch: 6| Step: 10
Training loss: 0.8916934728622437
Validation loss: 1.7892597106195265

Epoch: 6| Step: 11
Training loss: 0.5199644565582275
Validation loss: 1.8094034912765666

Epoch: 6| Step: 12
Training loss: 0.8432642221450806
Validation loss: 1.832609280463188

Epoch: 6| Step: 13
Training loss: 0.5129024386405945
Validation loss: 1.8407504097107918

Epoch: 196| Step: 0
Training loss: 0.49290287494659424
Validation loss: 1.8134654773178922

Epoch: 6| Step: 1
Training loss: 0.3107542395591736
Validation loss: 1.7618646544794883

Epoch: 6| Step: 2
Training loss: 0.8329429030418396
Validation loss: 1.7635442531237038

Epoch: 6| Step: 3
Training loss: 0.8571075797080994
Validation loss: 1.7298028193494326

Epoch: 6| Step: 4
Training loss: 1.0219043493270874
Validation loss: 1.7232967974037252

Epoch: 6| Step: 5
Training loss: 0.7614445686340332
Validation loss: 1.7287656235438522

Epoch: 6| Step: 6
Training loss: 0.6122950315475464
Validation loss: 1.7299135743930776

Epoch: 6| Step: 7
Training loss: 0.9548839926719666
Validation loss: 1.7426307624386204

Epoch: 6| Step: 8
Training loss: 0.7246488332748413
Validation loss: 1.7739353359386485

Epoch: 6| Step: 9
Training loss: 0.43046337366104126
Validation loss: 1.757605436027691

Epoch: 6| Step: 10
Training loss: 0.8958359360694885
Validation loss: 1.7921207310051046

Epoch: 6| Step: 11
Training loss: 0.9116417169570923
Validation loss: 1.8000177824369041

Epoch: 6| Step: 12
Training loss: 1.165377140045166
Validation loss: 1.80272154654226

Epoch: 6| Step: 13
Training loss: 1.2580389976501465
Validation loss: 1.8165456107867661

Epoch: 197| Step: 0
Training loss: 0.6422995328903198
Validation loss: 1.8043126701026835

Epoch: 6| Step: 1
Training loss: 0.5544847249984741
Validation loss: 1.8191773968358194

Epoch: 6| Step: 2
Training loss: 1.1000415086746216
Validation loss: 1.8359186860822863

Epoch: 6| Step: 3
Training loss: 0.7123154401779175
Validation loss: 1.8310778679386261

Epoch: 6| Step: 4
Training loss: 0.5776045322418213
Validation loss: 1.8013943908035115

Epoch: 6| Step: 5
Training loss: 0.48506277799606323
Validation loss: 1.7765753153831727

Epoch: 6| Step: 6
Training loss: 0.6495689153671265
Validation loss: 1.7581542358603528

Epoch: 6| Step: 7
Training loss: 0.9482840895652771
Validation loss: 1.7621898612668436

Epoch: 6| Step: 8
Training loss: 0.6962807774543762
Validation loss: 1.7687759476323281

Epoch: 6| Step: 9
Training loss: 0.7603457570075989
Validation loss: 1.7441911851206133

Epoch: 6| Step: 10
Training loss: 0.9958673119544983
Validation loss: 1.7775443292433215

Epoch: 6| Step: 11
Training loss: 0.7186028957366943
Validation loss: 1.767370012498671

Epoch: 6| Step: 12
Training loss: 1.048732042312622
Validation loss: 1.7780373929649271

Epoch: 6| Step: 13
Training loss: 0.4314590096473694
Validation loss: 1.803514160135741

Epoch: 198| Step: 0
Training loss: 0.578123927116394
Validation loss: 1.8201991101746917

Epoch: 6| Step: 1
Training loss: 0.6046062111854553
Validation loss: 1.8614689944892802

Epoch: 6| Step: 2
Training loss: 0.3496415913105011
Validation loss: 1.860016922796926

Epoch: 6| Step: 3
Training loss: 1.2669764757156372
Validation loss: 1.8856386407729118

Epoch: 6| Step: 4
Training loss: 1.0144996643066406
Validation loss: 1.8572315631374237

Epoch: 6| Step: 5
Training loss: 0.669255256652832
Validation loss: 1.8429590399547289

Epoch: 6| Step: 6
Training loss: 0.3779301047325134
Validation loss: 1.8124313546765236

Epoch: 6| Step: 7
Training loss: 1.0192837715148926
Validation loss: 1.8039699190406389

Epoch: 6| Step: 8
Training loss: 0.9711093902587891
Validation loss: 1.7999353959996214

Epoch: 6| Step: 9
Training loss: 0.5371370911598206
Validation loss: 1.7858369606797413

Epoch: 6| Step: 10
Training loss: 0.6029168367385864
Validation loss: 1.832652497035201

Epoch: 6| Step: 11
Training loss: 0.7349971532821655
Validation loss: 1.8413196417593187

Epoch: 6| Step: 12
Training loss: 1.2537696361541748
Validation loss: 1.831199284522764

Epoch: 6| Step: 13
Training loss: 1.1283400058746338
Validation loss: 1.7588225756922076

Epoch: 199| Step: 0
Training loss: 0.6552790403366089
Validation loss: 1.7625090069668268

Epoch: 6| Step: 1
Training loss: 0.7622365951538086
Validation loss: 1.7805886166070097

Epoch: 6| Step: 2
Training loss: 0.7131896018981934
Validation loss: 1.772789446256494

Epoch: 6| Step: 3
Training loss: 0.6434053778648376
Validation loss: 1.776990564920569

Epoch: 6| Step: 4
Training loss: 0.7453634738922119
Validation loss: 1.7882365872783046

Epoch: 6| Step: 5
Training loss: 0.8772181272506714
Validation loss: 1.800830856446297

Epoch: 6| Step: 6
Training loss: 0.6693942546844482
Validation loss: 1.7710668169042116

Epoch: 6| Step: 7
Training loss: 0.874662458896637
Validation loss: 1.7791477659697175

Epoch: 6| Step: 8
Training loss: 0.5494506359100342
Validation loss: 1.7753794372722667

Epoch: 6| Step: 9
Training loss: 0.6179623603820801
Validation loss: 1.8078363031469367

Epoch: 6| Step: 10
Training loss: 0.8905384540557861
Validation loss: 1.8338878936665033

Epoch: 6| Step: 11
Training loss: 1.0264668464660645
Validation loss: 1.8521215402951805

Epoch: 6| Step: 12
Training loss: 0.7006509900093079
Validation loss: 1.8350492920926822

Epoch: 6| Step: 13
Training loss: 0.9556564688682556
Validation loss: 1.8410078748579948

Epoch: 200| Step: 0
Training loss: 0.6242185235023499
Validation loss: 1.8572185449702765

Epoch: 6| Step: 1
Training loss: 0.5294398069381714
Validation loss: 1.8324181059355378

Epoch: 6| Step: 2
Training loss: 0.3928183317184448
Validation loss: 1.84848286644105

Epoch: 6| Step: 3
Training loss: 0.888190507888794
Validation loss: 1.8507616994201497

Epoch: 6| Step: 4
Training loss: 0.7858489751815796
Validation loss: 1.8583545005449684

Epoch: 6| Step: 5
Training loss: 0.8379161357879639
Validation loss: 1.8420649523376136

Epoch: 6| Step: 6
Training loss: 1.0097520351409912
Validation loss: 1.8226040870912614

Epoch: 6| Step: 7
Training loss: 0.6999436616897583
Validation loss: 1.7905003140049596

Epoch: 6| Step: 8
Training loss: 0.7169229984283447
Validation loss: 1.8044170942357791

Epoch: 6| Step: 9
Training loss: 1.000922441482544
Validation loss: 1.7992849683248868

Epoch: 6| Step: 10
Training loss: 0.6885972023010254
Validation loss: 1.7680304922083372

Epoch: 6| Step: 11
Training loss: 0.715904951095581
Validation loss: 1.7574014714969102

Epoch: 6| Step: 12
Training loss: 0.7866028547286987
Validation loss: 1.7538880609696912

Epoch: 6| Step: 13
Training loss: 0.5457281470298767
Validation loss: 1.7401172409775436

Epoch: 201| Step: 0
Training loss: 0.8150851130485535
Validation loss: 1.7462362576556463

Epoch: 6| Step: 1
Training loss: 0.494671493768692
Validation loss: 1.7680486274021927

Epoch: 6| Step: 2
Training loss: 0.6022894382476807
Validation loss: 1.8056325656111523

Epoch: 6| Step: 3
Training loss: 0.8401641845703125
Validation loss: 1.8626947454226914

Epoch: 6| Step: 4
Training loss: 0.6187846660614014
Validation loss: 1.8647503263206893

Epoch: 6| Step: 5
Training loss: 0.6563647985458374
Validation loss: 1.8329557782860213

Epoch: 6| Step: 6
Training loss: 0.45967555046081543
Validation loss: 1.7698298000520276

Epoch: 6| Step: 7
Training loss: 1.0729652643203735
Validation loss: 1.7067125638326008

Epoch: 6| Step: 8
Training loss: 0.9953625798225403
Validation loss: 1.708542428990846

Epoch: 6| Step: 9
Training loss: 0.5315574407577515
Validation loss: 1.6955153865198935

Epoch: 6| Step: 10
Training loss: 0.6973857879638672
Validation loss: 1.7094483362731112

Epoch: 6| Step: 11
Training loss: 0.9375496506690979
Validation loss: 1.7157149584062639

Epoch: 6| Step: 12
Training loss: 0.8240252733230591
Validation loss: 1.7289382706406295

Epoch: 6| Step: 13
Training loss: 1.2488441467285156
Validation loss: 1.7775132540733583

Epoch: 202| Step: 0
Training loss: 0.5898212790489197
Validation loss: 1.781666116047931

Epoch: 6| Step: 1
Training loss: 0.6443380117416382
Validation loss: 1.8071415680710987

Epoch: 6| Step: 2
Training loss: 0.49538454413414
Validation loss: 1.8582051569415676

Epoch: 6| Step: 3
Training loss: 0.4879152476787567
Validation loss: 1.8657819699215632

Epoch: 6| Step: 4
Training loss: 0.7329254746437073
Validation loss: 1.8813216558066748

Epoch: 6| Step: 5
Training loss: 0.8154677748680115
Validation loss: 1.8824105954939319

Epoch: 6| Step: 6
Training loss: 0.7873159646987915
Validation loss: 1.8564566912189606

Epoch: 6| Step: 7
Training loss: 1.0434961318969727
Validation loss: 1.7555283923302927

Epoch: 6| Step: 8
Training loss: 1.006330966949463
Validation loss: 1.738278027503721

Epoch: 6| Step: 9
Training loss: 0.5860713720321655
Validation loss: 1.7133234829031012

Epoch: 6| Step: 10
Training loss: 0.9769525527954102
Validation loss: 1.6885120561045985

Epoch: 6| Step: 11
Training loss: 0.5352040529251099
Validation loss: 1.680322447130757

Epoch: 6| Step: 12
Training loss: 0.6658966541290283
Validation loss: 1.6667614252336564

Epoch: 6| Step: 13
Training loss: 1.232818603515625
Validation loss: 1.6536316000005251

Epoch: 203| Step: 0
Training loss: 1.0188372135162354
Validation loss: 1.6641603233993694

Epoch: 6| Step: 1
Training loss: 0.5235333442687988
Validation loss: 1.6606405909343431

Epoch: 6| Step: 2
Training loss: 0.9234274625778198
Validation loss: 1.6887189560039069

Epoch: 6| Step: 3
Training loss: 0.6489757299423218
Validation loss: 1.6999006502089962

Epoch: 6| Step: 4
Training loss: 1.0866849422454834
Validation loss: 1.750803796834843

Epoch: 6| Step: 5
Training loss: 0.5180855393409729
Validation loss: 1.7540830578855289

Epoch: 6| Step: 6
Training loss: 0.7476945519447327
Validation loss: 1.7498632246448147

Epoch: 6| Step: 7
Training loss: 0.6524453163146973
Validation loss: 1.7775411746835197

Epoch: 6| Step: 8
Training loss: 0.8671781420707703
Validation loss: 1.7927455594462733

Epoch: 6| Step: 9
Training loss: 0.7548580765724182
Validation loss: 1.786529105196717

Epoch: 6| Step: 10
Training loss: 0.7336543798446655
Validation loss: 1.7660002298252557

Epoch: 6| Step: 11
Training loss: 0.7113934755325317
Validation loss: 1.7472587580321937

Epoch: 6| Step: 12
Training loss: 0.6515970230102539
Validation loss: 1.7724869917797785

Epoch: 6| Step: 13
Training loss: 0.6032100915908813
Validation loss: 1.7457345403650755

Epoch: 204| Step: 0
Training loss: 0.6519849300384521
Validation loss: 1.789720126377639

Epoch: 6| Step: 1
Training loss: 1.1019651889801025
Validation loss: 1.8280096566805275

Epoch: 6| Step: 2
Training loss: 0.3149527907371521
Validation loss: 1.7948258717854817

Epoch: 6| Step: 3
Training loss: 0.707674503326416
Validation loss: 1.815239872983707

Epoch: 6| Step: 4
Training loss: 0.49135300517082214
Validation loss: 1.7618101553250385

Epoch: 6| Step: 5
Training loss: 0.6691985726356506
Validation loss: 1.714340071524343

Epoch: 6| Step: 6
Training loss: 0.6361149549484253
Validation loss: 1.7055877972674627

Epoch: 6| Step: 7
Training loss: 0.7479068040847778
Validation loss: 1.6817828596279185

Epoch: 6| Step: 8
Training loss: 0.5091290473937988
Validation loss: 1.6845996059397215

Epoch: 6| Step: 9
Training loss: 0.7417537569999695
Validation loss: 1.6726716026183097

Epoch: 6| Step: 10
Training loss: 1.0406018495559692
Validation loss: 1.6650752431602889

Epoch: 6| Step: 11
Training loss: 0.811888575553894
Validation loss: 1.7052192957170549

Epoch: 6| Step: 12
Training loss: 0.9093137979507446
Validation loss: 1.6740222489962013

Epoch: 6| Step: 13
Training loss: 0.6730270385742188
Validation loss: 1.6885765778121127

Epoch: 205| Step: 0
Training loss: 0.7534153461456299
Validation loss: 1.6872341427751767

Epoch: 6| Step: 1
Training loss: 0.681699275970459
Validation loss: 1.6919492829230525

Epoch: 6| Step: 2
Training loss: 0.8529627323150635
Validation loss: 1.6927712719927552

Epoch: 6| Step: 3
Training loss: 0.9010754823684692
Validation loss: 1.7378547601802374

Epoch: 6| Step: 4
Training loss: 0.8914144039154053
Validation loss: 1.7430452659565916

Epoch: 6| Step: 5
Training loss: 0.9566171169281006
Validation loss: 1.7612653752808929

Epoch: 6| Step: 6
Training loss: 0.31933456659317017
Validation loss: 1.7706899232761835

Epoch: 6| Step: 7
Training loss: 0.7898340225219727
Validation loss: 1.7587736947562105

Epoch: 6| Step: 8
Training loss: 0.49542638659477234
Validation loss: 1.7290988250445294

Epoch: 6| Step: 9
Training loss: 0.6356461048126221
Validation loss: 1.6919388258329002

Epoch: 6| Step: 10
Training loss: 0.30682939291000366
Validation loss: 1.6783910771851898

Epoch: 6| Step: 11
Training loss: 0.6205765008926392
Validation loss: 1.660113339783043

Epoch: 6| Step: 12
Training loss: 0.7509157657623291
Validation loss: 1.6647203417234524

Epoch: 6| Step: 13
Training loss: 0.44363921880722046
Validation loss: 1.667149220743487

Epoch: 206| Step: 0
Training loss: 0.9052221775054932
Validation loss: 1.7127999990217146

Epoch: 6| Step: 1
Training loss: 0.4336557984352112
Validation loss: 1.7387842644927323

Epoch: 6| Step: 2
Training loss: 0.7551164627075195
Validation loss: 1.746615118877862

Epoch: 6| Step: 3
Training loss: 0.6190207004547119
Validation loss: 1.778719614910823

Epoch: 6| Step: 4
Training loss: 0.5530391931533813
Validation loss: 1.810376307015778

Epoch: 6| Step: 5
Training loss: 0.7444259524345398
Validation loss: 1.8168022055779733

Epoch: 6| Step: 6
Training loss: 0.9409964680671692
Validation loss: 1.812314994873539

Epoch: 6| Step: 7
Training loss: 0.37828344106674194
Validation loss: 1.7541193962097168

Epoch: 6| Step: 8
Training loss: 0.4053344130516052
Validation loss: 1.7495440167765464

Epoch: 6| Step: 9
Training loss: 0.9271233081817627
Validation loss: 1.702670584442795

Epoch: 6| Step: 10
Training loss: 0.5413166284561157
Validation loss: 1.666802034583143

Epoch: 6| Step: 11
Training loss: 0.9193218350410461
Validation loss: 1.6743738394911571

Epoch: 6| Step: 12
Training loss: 0.6722325682640076
Validation loss: 1.6842436854557326

Epoch: 6| Step: 13
Training loss: 0.9799941182136536
Validation loss: 1.670139035870952

Epoch: 207| Step: 0
Training loss: 0.9254937171936035
Validation loss: 1.6884260126339492

Epoch: 6| Step: 1
Training loss: 0.7485640048980713
Validation loss: 1.7150062335434781

Epoch: 6| Step: 2
Training loss: 0.6792389750480652
Validation loss: 1.7549503362306984

Epoch: 6| Step: 3
Training loss: 0.8125999569892883
Validation loss: 1.7508110756515174

Epoch: 6| Step: 4
Training loss: 0.5594186782836914
Validation loss: 1.7790134337640577

Epoch: 6| Step: 5
Training loss: 0.5907484292984009
Validation loss: 1.8209001120700632

Epoch: 6| Step: 6
Training loss: 0.876671314239502
Validation loss: 1.7999245453906316

Epoch: 6| Step: 7
Training loss: 0.3764614462852478
Validation loss: 1.8087060246416318

Epoch: 6| Step: 8
Training loss: 0.47392183542251587
Validation loss: 1.7994646103151384

Epoch: 6| Step: 9
Training loss: 0.7165548801422119
Validation loss: 1.8370995777909473

Epoch: 6| Step: 10
Training loss: 0.8887913227081299
Validation loss: 1.8218045029588925

Epoch: 6| Step: 11
Training loss: 0.6996179223060608
Validation loss: 1.8041359493809361

Epoch: 6| Step: 12
Training loss: 0.5307819247245789
Validation loss: 1.8262184794231127

Epoch: 6| Step: 13
Training loss: 0.44945281744003296
Validation loss: 1.7985263152789044

Epoch: 208| Step: 0
Training loss: 0.8488254547119141
Validation loss: 1.7863744074298489

Epoch: 6| Step: 1
Training loss: 0.5573056936264038
Validation loss: 1.7606459292032386

Epoch: 6| Step: 2
Training loss: 0.4098934829235077
Validation loss: 1.7479555004386491

Epoch: 6| Step: 3
Training loss: 0.7304646968841553
Validation loss: 1.7594681196315314

Epoch: 6| Step: 4
Training loss: 0.7244346141815186
Validation loss: 1.754317625876396

Epoch: 6| Step: 5
Training loss: 0.616923451423645
Validation loss: 1.7638190279724777

Epoch: 6| Step: 6
Training loss: 0.5918248891830444
Validation loss: 1.8199379174940047

Epoch: 6| Step: 7
Training loss: 0.5677974820137024
Validation loss: 1.8587163456024662

Epoch: 6| Step: 8
Training loss: 0.7024238705635071
Validation loss: 1.8746306050208308

Epoch: 6| Step: 9
Training loss: 0.8763574361801147
Validation loss: 1.8347042709268548

Epoch: 6| Step: 10
Training loss: 0.8420155048370361
Validation loss: 1.795895108612635

Epoch: 6| Step: 11
Training loss: 0.8146787881851196
Validation loss: 1.7348988774002239

Epoch: 6| Step: 12
Training loss: 0.5854600071907043
Validation loss: 1.7258239715330062

Epoch: 6| Step: 13
Training loss: 0.9719725847244263
Validation loss: 1.72464919090271

Epoch: 209| Step: 0
Training loss: 0.9756935238838196
Validation loss: 1.7157851829323718

Epoch: 6| Step: 1
Training loss: 0.43620365858078003
Validation loss: 1.696094109166053

Epoch: 6| Step: 2
Training loss: 0.4879094362258911
Validation loss: 1.676588414817728

Epoch: 6| Step: 3
Training loss: 0.8008973598480225
Validation loss: 1.670750685917434

Epoch: 6| Step: 4
Training loss: 0.7926179766654968
Validation loss: 1.702134645113381

Epoch: 6| Step: 5
Training loss: 0.5248337984085083
Validation loss: 1.7564082607146232

Epoch: 6| Step: 6
Training loss: 1.062013864517212
Validation loss: 1.7408637333941717

Epoch: 6| Step: 7
Training loss: 0.5583856701850891
Validation loss: 1.7486554191958519

Epoch: 6| Step: 8
Training loss: 0.5874933004379272
Validation loss: 1.7506543615812897

Epoch: 6| Step: 9
Training loss: 0.5765460133552551
Validation loss: 1.766468123723102

Epoch: 6| Step: 10
Training loss: 0.5616060495376587
Validation loss: 1.7725972193543629

Epoch: 6| Step: 11
Training loss: 0.47930607199668884
Validation loss: 1.7284992728182065

Epoch: 6| Step: 12
Training loss: 0.757342517375946
Validation loss: 1.7231629561352473

Epoch: 6| Step: 13
Training loss: 0.6892163157463074
Validation loss: 1.7126528165673698

Epoch: 210| Step: 0
Training loss: 0.8854633569717407
Validation loss: 1.742730789287116

Epoch: 6| Step: 1
Training loss: 0.7362638115882874
Validation loss: 1.7568438296676965

Epoch: 6| Step: 2
Training loss: 0.7775900363922119
Validation loss: 1.7397785866132347

Epoch: 6| Step: 3
Training loss: 0.24373763799667358
Validation loss: 1.7423872229873494

Epoch: 6| Step: 4
Training loss: 0.29754388332366943
Validation loss: 1.7431694371725923

Epoch: 6| Step: 5
Training loss: 0.7690898180007935
Validation loss: 1.7773762813178442

Epoch: 6| Step: 6
Training loss: 0.9343923330307007
Validation loss: 1.7765079672618578

Epoch: 6| Step: 7
Training loss: 0.8488252758979797
Validation loss: 1.8312310326483943

Epoch: 6| Step: 8
Training loss: 0.3809826970100403
Validation loss: 1.856632427502704

Epoch: 6| Step: 9
Training loss: 0.406585693359375
Validation loss: 1.8727342544063446

Epoch: 6| Step: 10
Training loss: 0.6652571558952332
Validation loss: 1.8501946772298505

Epoch: 6| Step: 11
Training loss: 0.7597418427467346
Validation loss: 1.8306686916658956

Epoch: 6| Step: 12
Training loss: 0.5409179925918579
Validation loss: 1.8042820025515813

Epoch: 6| Step: 13
Training loss: 0.5064509510993958
Validation loss: 1.7757370471954346

Epoch: 211| Step: 0
Training loss: 0.4976901710033417
Validation loss: 1.7025291176252468

Epoch: 6| Step: 1
Training loss: 0.44274574518203735
Validation loss: 1.6895650676501694

Epoch: 6| Step: 2
Training loss: 0.6509302258491516
Validation loss: 1.6660373653134992

Epoch: 6| Step: 3
Training loss: 0.7472889423370361
Validation loss: 1.661214933600477

Epoch: 6| Step: 4
Training loss: 0.5788109302520752
Validation loss: 1.6480520899577806

Epoch: 6| Step: 5
Training loss: 0.5428505539894104
Validation loss: 1.6497072250612321

Epoch: 6| Step: 6
Training loss: 0.8338798880577087
Validation loss: 1.6610047791593818

Epoch: 6| Step: 7
Training loss: 0.8278363943099976
Validation loss: 1.6851539483634375

Epoch: 6| Step: 8
Training loss: 0.9239631295204163
Validation loss: 1.7028525106368526

Epoch: 6| Step: 9
Training loss: 0.6950756311416626
Validation loss: 1.7852599620819092

Epoch: 6| Step: 10
Training loss: 0.7923533916473389
Validation loss: 1.8265025705419562

Epoch: 6| Step: 11
Training loss: 0.3944714367389679
Validation loss: 1.8722476113227107

Epoch: 6| Step: 12
Training loss: 0.34929054975509644
Validation loss: 1.8539791427632815

Epoch: 6| Step: 13
Training loss: 0.7598413825035095
Validation loss: 1.8464265074781192

Epoch: 212| Step: 0
Training loss: 0.6711682081222534
Validation loss: 1.8320140236167497

Epoch: 6| Step: 1
Training loss: 0.7774742841720581
Validation loss: 1.8024316910774476

Epoch: 6| Step: 2
Training loss: 0.836314857006073
Validation loss: 1.789448776552754

Epoch: 6| Step: 3
Training loss: 0.6344419717788696
Validation loss: 1.7552310446257233

Epoch: 6| Step: 4
Training loss: 0.5883573293685913
Validation loss: 1.7483692380689806

Epoch: 6| Step: 5
Training loss: 0.5170451402664185
Validation loss: 1.7214823563893635

Epoch: 6| Step: 6
Training loss: 0.29709866642951965
Validation loss: 1.7343605808032456

Epoch: 6| Step: 7
Training loss: 0.7131953239440918
Validation loss: 1.720409909884135

Epoch: 6| Step: 8
Training loss: 0.5794500112533569
Validation loss: 1.7346015630229827

Epoch: 6| Step: 9
Training loss: 0.46390485763549805
Validation loss: 1.7463455943651096

Epoch: 6| Step: 10
Training loss: 0.6655145883560181
Validation loss: 1.7539738621763004

Epoch: 6| Step: 11
Training loss: 0.9448630213737488
Validation loss: 1.7092320162762877

Epoch: 6| Step: 12
Training loss: 0.6220166087150574
Validation loss: 1.7235069197993125

Epoch: 6| Step: 13
Training loss: 0.41680392622947693
Validation loss: 1.7240056824940506

Epoch: 213| Step: 0
Training loss: 0.371697336435318
Validation loss: 1.7054637888426423

Epoch: 6| Step: 1
Training loss: 0.5751595497131348
Validation loss: 1.6564474016107538

Epoch: 6| Step: 2
Training loss: 0.47127896547317505
Validation loss: 1.6798626248554518

Epoch: 6| Step: 3
Training loss: 0.4859534502029419
Validation loss: 1.682819640764626

Epoch: 6| Step: 4
Training loss: 0.4138839840888977
Validation loss: 1.675937283423639

Epoch: 6| Step: 5
Training loss: 0.45889297127723694
Validation loss: 1.6981366552332395

Epoch: 6| Step: 6
Training loss: 0.6143717765808105
Validation loss: 1.7316542017844416

Epoch: 6| Step: 7
Training loss: 0.5041400194168091
Validation loss: 1.715146041685535

Epoch: 6| Step: 8
Training loss: 0.4342319965362549
Validation loss: 1.7443232190224431

Epoch: 6| Step: 9
Training loss: 0.8501935005187988
Validation loss: 1.7418352685948855

Epoch: 6| Step: 10
Training loss: 0.8061711192131042
Validation loss: 1.7554408734844578

Epoch: 6| Step: 11
Training loss: 0.6361132860183716
Validation loss: 1.7500269156630321

Epoch: 6| Step: 12
Training loss: 0.7770097851753235
Validation loss: 1.757312633657968

Epoch: 6| Step: 13
Training loss: 0.918741762638092
Validation loss: 1.771288574382823

Epoch: 214| Step: 0
Training loss: 0.5866143703460693
Validation loss: 1.7459412274822113

Epoch: 6| Step: 1
Training loss: 0.5412691831588745
Validation loss: 1.756978214427989

Epoch: 6| Step: 2
Training loss: 0.8701211214065552
Validation loss: 1.7463971786601569

Epoch: 6| Step: 3
Training loss: 0.6697629690170288
Validation loss: 1.7536436537260651

Epoch: 6| Step: 4
Training loss: 0.6282781362533569
Validation loss: 1.7303600067733436

Epoch: 6| Step: 5
Training loss: 0.4306161105632782
Validation loss: 1.7482410195053264

Epoch: 6| Step: 6
Training loss: 0.8818212747573853
Validation loss: 1.7208994357816634

Epoch: 6| Step: 7
Training loss: 0.3482956886291504
Validation loss: 1.6903225657760457

Epoch: 6| Step: 8
Training loss: 0.4027569890022278
Validation loss: 1.6886050393504481

Epoch: 6| Step: 9
Training loss: 0.6524591445922852
Validation loss: 1.7004827312243882

Epoch: 6| Step: 10
Training loss: 0.23168298602104187
Validation loss: 1.6891403621242893

Epoch: 6| Step: 11
Training loss: 0.5782500505447388
Validation loss: 1.6666105485731555

Epoch: 6| Step: 12
Training loss: 0.9535496234893799
Validation loss: 1.654266583022251

Epoch: 6| Step: 13
Training loss: 0.2582165598869324
Validation loss: 1.6546425838624277

Epoch: 215| Step: 0
Training loss: 0.5008939504623413
Validation loss: 1.6915617091681368

Epoch: 6| Step: 1
Training loss: 0.2986847162246704
Validation loss: 1.6576433104853476

Epoch: 6| Step: 2
Training loss: 0.5632919669151306
Validation loss: 1.6934335641963507

Epoch: 6| Step: 3
Training loss: 0.5044718384742737
Validation loss: 1.7122097438381565

Epoch: 6| Step: 4
Training loss: 0.39848974347114563
Validation loss: 1.709249093968381

Epoch: 6| Step: 5
Training loss: 0.5488651990890503
Validation loss: 1.704868116686421

Epoch: 6| Step: 6
Training loss: 0.7388153076171875
Validation loss: 1.7290000569435857

Epoch: 6| Step: 7
Training loss: 0.9052797555923462
Validation loss: 1.761618915424552

Epoch: 6| Step: 8
Training loss: 0.6705507040023804
Validation loss: 1.8101283106752621

Epoch: 6| Step: 9
Training loss: 0.8336155414581299
Validation loss: 1.825509354632388

Epoch: 6| Step: 10
Training loss: 0.7534997463226318
Validation loss: 1.7964175080740323

Epoch: 6| Step: 11
Training loss: 0.44833046197891235
Validation loss: 1.7604828444860314

Epoch: 6| Step: 12
Training loss: 0.6874587535858154
Validation loss: 1.7152916551918111

Epoch: 6| Step: 13
Training loss: 0.7485756278038025
Validation loss: 1.6729558565283333

Epoch: 216| Step: 0
Training loss: 0.6908330321311951
Validation loss: 1.6589862659413328

Epoch: 6| Step: 1
Training loss: 0.5884410738945007
Validation loss: 1.6654716486571937

Epoch: 6| Step: 2
Training loss: 0.6713035106658936
Validation loss: 1.6853844504202566

Epoch: 6| Step: 3
Training loss: 0.4364335834980011
Validation loss: 1.7106237770408712

Epoch: 6| Step: 4
Training loss: 0.7146368026733398
Validation loss: 1.7187626515665362

Epoch: 6| Step: 5
Training loss: 0.2821120619773865
Validation loss: 1.7264677311784478

Epoch: 6| Step: 6
Training loss: 0.4788322448730469
Validation loss: 1.7311419863854685

Epoch: 6| Step: 7
Training loss: 0.2693859338760376
Validation loss: 1.7607011666861914

Epoch: 6| Step: 8
Training loss: 0.5260810256004333
Validation loss: 1.7541442737784436

Epoch: 6| Step: 9
Training loss: 0.6593273878097534
Validation loss: 1.7614189258185766

Epoch: 6| Step: 10
Training loss: 0.8515473008155823
Validation loss: 1.750525047702174

Epoch: 6| Step: 11
Training loss: 0.8148353695869446
Validation loss: 1.723820124903033

Epoch: 6| Step: 12
Training loss: 0.5933457612991333
Validation loss: 1.707026825156263

Epoch: 6| Step: 13
Training loss: 1.5620942115783691
Validation loss: 1.6913055655776814

Epoch: 217| Step: 0
Training loss: 0.39262133836746216
Validation loss: 1.7116116157142065

Epoch: 6| Step: 1
Training loss: 0.7056725025177002
Validation loss: 1.7022366677561114

Epoch: 6| Step: 2
Training loss: 0.46577590703964233
Validation loss: 1.7302176490906747

Epoch: 6| Step: 3
Training loss: 0.5543699264526367
Validation loss: 1.7582834638575071

Epoch: 6| Step: 4
Training loss: 0.4002585709095001
Validation loss: 1.7189936535332793

Epoch: 6| Step: 5
Training loss: 0.32659608125686646
Validation loss: 1.7133863766988118

Epoch: 6| Step: 6
Training loss: 0.5694787502288818
Validation loss: 1.7071714426881524

Epoch: 6| Step: 7
Training loss: 0.6484546661376953
Validation loss: 1.6783270092420681

Epoch: 6| Step: 8
Training loss: 0.8431904911994934
Validation loss: 1.6870397213966615

Epoch: 6| Step: 9
Training loss: 0.470989853143692
Validation loss: 1.6701452232176257

Epoch: 6| Step: 10
Training loss: 0.6122063398361206
Validation loss: 1.6808434135170394

Epoch: 6| Step: 11
Training loss: 0.9910926818847656
Validation loss: 1.679829587218582

Epoch: 6| Step: 12
Training loss: 0.5025413036346436
Validation loss: 1.6736630239794332

Epoch: 6| Step: 13
Training loss: 0.5660443902015686
Validation loss: 1.7139387105100898

Epoch: 218| Step: 0
Training loss: 0.7834601998329163
Validation loss: 1.7281737930031233

Epoch: 6| Step: 1
Training loss: 0.361984521150589
Validation loss: 1.7261902645070066

Epoch: 6| Step: 2
Training loss: 0.43659764528274536
Validation loss: 1.7267253732168546

Epoch: 6| Step: 3
Training loss: 0.8972856402397156
Validation loss: 1.7045079956772506

Epoch: 6| Step: 4
Training loss: 0.5808507204055786
Validation loss: 1.709551356172049

Epoch: 6| Step: 5
Training loss: 0.8132296204566956
Validation loss: 1.7208088341579642

Epoch: 6| Step: 6
Training loss: 0.5444142818450928
Validation loss: 1.718520910509171

Epoch: 6| Step: 7
Training loss: 0.4650934934616089
Validation loss: 1.7313963136365336

Epoch: 6| Step: 8
Training loss: 0.8808220028877258
Validation loss: 1.721720487840714

Epoch: 6| Step: 9
Training loss: 0.21616338193416595
Validation loss: 1.692538797214467

Epoch: 6| Step: 10
Training loss: 0.35192611813545227
Validation loss: 1.660622969750435

Epoch: 6| Step: 11
Training loss: 0.525684118270874
Validation loss: 1.6722288849533244

Epoch: 6| Step: 12
Training loss: 0.39438745379447937
Validation loss: 1.657305117576353

Epoch: 6| Step: 13
Training loss: 0.6495217680931091
Validation loss: 1.6631344890081754

Epoch: 219| Step: 0
Training loss: 0.37809211015701294
Validation loss: 1.6571028078756025

Epoch: 6| Step: 1
Training loss: 0.38315725326538086
Validation loss: 1.7003423911268993

Epoch: 6| Step: 2
Training loss: 0.5821923017501831
Validation loss: 1.6806878569305583

Epoch: 6| Step: 3
Training loss: 0.35429802536964417
Validation loss: 1.7466399849102061

Epoch: 6| Step: 4
Training loss: 0.5178282260894775
Validation loss: 1.7656610986237884

Epoch: 6| Step: 5
Training loss: 0.648764967918396
Validation loss: 1.7518346514753116

Epoch: 6| Step: 6
Training loss: 0.6875566840171814
Validation loss: 1.7797413256860548

Epoch: 6| Step: 7
Training loss: 0.3731626272201538
Validation loss: 1.753426016017955

Epoch: 6| Step: 8
Training loss: 0.5517641305923462
Validation loss: 1.7585087899238832

Epoch: 6| Step: 9
Training loss: 0.6017303466796875
Validation loss: 1.7393596749151907

Epoch: 6| Step: 10
Training loss: 0.7977563142776489
Validation loss: 1.7112198132340626

Epoch: 6| Step: 11
Training loss: 0.5879595279693604
Validation loss: 1.7041782115095405

Epoch: 6| Step: 12
Training loss: 0.7454713582992554
Validation loss: 1.69181417329337

Epoch: 6| Step: 13
Training loss: 0.7040877938270569
Validation loss: 1.70606779795821

Epoch: 220| Step: 0
Training loss: 0.6286632418632507
Validation loss: 1.6910339158068421

Epoch: 6| Step: 1
Training loss: 0.5599303245544434
Validation loss: 1.7158102245740994

Epoch: 6| Step: 2
Training loss: 0.4369991421699524
Validation loss: 1.6761067721151537

Epoch: 6| Step: 3
Training loss: 0.5556365847587585
Validation loss: 1.6828156081579064

Epoch: 6| Step: 4
Training loss: 0.663360595703125
Validation loss: 1.7138271126695859

Epoch: 6| Step: 5
Training loss: 0.24683737754821777
Validation loss: 1.6737026835000643

Epoch: 6| Step: 6
Training loss: 0.23717284202575684
Validation loss: 1.680059556038149

Epoch: 6| Step: 7
Training loss: 0.522976279258728
Validation loss: 1.7019125069341352

Epoch: 6| Step: 8
Training loss: 0.3760480284690857
Validation loss: 1.7111670201824558

Epoch: 6| Step: 9
Training loss: 0.663361132144928
Validation loss: 1.6947443100713915

Epoch: 6| Step: 10
Training loss: 0.6688410043716431
Validation loss: 1.7228052411028134

Epoch: 6| Step: 11
Training loss: 0.8153335452079773
Validation loss: 1.764072851468158

Epoch: 6| Step: 12
Training loss: 0.8026166558265686
Validation loss: 1.7919841889412171

Epoch: 6| Step: 13
Training loss: 0.19451864063739777
Validation loss: 1.74557529469972

Epoch: 221| Step: 0
Training loss: 0.6585501432418823
Validation loss: 1.7130575436417774

Epoch: 6| Step: 1
Training loss: 0.660990297794342
Validation loss: 1.6817273785991054

Epoch: 6| Step: 2
Training loss: 0.6150689125061035
Validation loss: 1.662869486757504

Epoch: 6| Step: 3
Training loss: 0.6437824964523315
Validation loss: 1.6608922712264522

Epoch: 6| Step: 4
Training loss: 0.4132359027862549
Validation loss: 1.6459703086524882

Epoch: 6| Step: 5
Training loss: 0.3517003059387207
Validation loss: 1.634130931669666

Epoch: 6| Step: 6
Training loss: 0.5461696982383728
Validation loss: 1.6223551611746512

Epoch: 6| Step: 7
Training loss: 0.5104336738586426
Validation loss: 1.6423343227755638

Epoch: 6| Step: 8
Training loss: 0.577441930770874
Validation loss: 1.6367645372626602

Epoch: 6| Step: 9
Training loss: 0.4362702965736389
Validation loss: 1.6335073183941584

Epoch: 6| Step: 10
Training loss: 0.3510424494743347
Validation loss: 1.6632737446856756

Epoch: 6| Step: 11
Training loss: 0.5961019992828369
Validation loss: 1.6639060730575232

Epoch: 6| Step: 12
Training loss: 0.5159375667572021
Validation loss: 1.6988499728582238

Epoch: 6| Step: 13
Training loss: 0.41478005051612854
Validation loss: 1.7223107276424285

Epoch: 222| Step: 0
Training loss: 0.5647029876708984
Validation loss: 1.720864744596584

Epoch: 6| Step: 1
Training loss: 0.5363699197769165
Validation loss: 1.721166472281179

Epoch: 6| Step: 2
Training loss: 0.4239690899848938
Validation loss: 1.7886683569159558

Epoch: 6| Step: 3
Training loss: 0.36923733353614807
Validation loss: 1.7608915105942757

Epoch: 6| Step: 4
Training loss: 0.5617258548736572
Validation loss: 1.7501289818876533

Epoch: 6| Step: 5
Training loss: 0.5095982551574707
Validation loss: 1.7698403968605945

Epoch: 6| Step: 6
Training loss: 0.3466412127017975
Validation loss: 1.749286315774405

Epoch: 6| Step: 7
Training loss: 0.6827517151832581
Validation loss: 1.7368599086679437

Epoch: 6| Step: 8
Training loss: 0.6554847955703735
Validation loss: 1.7114560104185534

Epoch: 6| Step: 9
Training loss: 0.6600781679153442
Validation loss: 1.6721916160275858

Epoch: 6| Step: 10
Training loss: 0.5221884846687317
Validation loss: 1.6596754750897806

Epoch: 6| Step: 11
Training loss: 0.5913199186325073
Validation loss: 1.6667122340971423

Epoch: 6| Step: 12
Training loss: 0.5013738870620728
Validation loss: 1.64941168215967

Epoch: 6| Step: 13
Training loss: 0.7609750032424927
Validation loss: 1.6484334968751477

Epoch: 223| Step: 0
Training loss: 0.7806321382522583
Validation loss: 1.6820317083789456

Epoch: 6| Step: 1
Training loss: 0.8864147067070007
Validation loss: 1.7017842121021722

Epoch: 6| Step: 2
Training loss: 0.5092576742172241
Validation loss: 1.7247229776074808

Epoch: 6| Step: 3
Training loss: 0.1558193415403366
Validation loss: 1.7192210305121638

Epoch: 6| Step: 4
Training loss: 0.6181690692901611
Validation loss: 1.751354702057377

Epoch: 6| Step: 5
Training loss: 0.6749958395957947
Validation loss: 1.7985482523518224

Epoch: 6| Step: 6
Training loss: 0.7860432863235474
Validation loss: 1.7926454915795276

Epoch: 6| Step: 7
Training loss: 0.5705545544624329
Validation loss: 1.8016027942780526

Epoch: 6| Step: 8
Training loss: 0.6616400480270386
Validation loss: 1.751146811310963

Epoch: 6| Step: 9
Training loss: 0.584797739982605
Validation loss: 1.7399370516500166

Epoch: 6| Step: 10
Training loss: 0.35578224062919617
Validation loss: 1.6873392110229821

Epoch: 6| Step: 11
Training loss: 0.3357463479042053
Validation loss: 1.660354427112046

Epoch: 6| Step: 12
Training loss: 0.5516859292984009
Validation loss: 1.670088550095917

Epoch: 6| Step: 13
Training loss: 0.8578170537948608
Validation loss: 1.6717700548069452

Epoch: 224| Step: 0
Training loss: 0.6589604616165161
Validation loss: 1.7263059744270899

Epoch: 6| Step: 1
Training loss: 0.49648264050483704
Validation loss: 1.7353171622881325

Epoch: 6| Step: 2
Training loss: 0.39841723442077637
Validation loss: 1.7301470323275494

Epoch: 6| Step: 3
Training loss: 0.821395993232727
Validation loss: 1.7125831803967875

Epoch: 6| Step: 4
Training loss: 0.43014347553253174
Validation loss: 1.6871017409909157

Epoch: 6| Step: 5
Training loss: 0.4842474162578583
Validation loss: 1.658261452951739

Epoch: 6| Step: 6
Training loss: 0.6468950510025024
Validation loss: 1.6285081525002756

Epoch: 6| Step: 7
Training loss: 0.8123814463615417
Validation loss: 1.6486306152036112

Epoch: 6| Step: 8
Training loss: 0.7492560148239136
Validation loss: 1.6706998514872726

Epoch: 6| Step: 9
Training loss: 0.4843100905418396
Validation loss: 1.7008404616386659

Epoch: 6| Step: 10
Training loss: 0.37841278314590454
Validation loss: 1.702704748799724

Epoch: 6| Step: 11
Training loss: 0.49495941400527954
Validation loss: 1.6940129046799035

Epoch: 6| Step: 12
Training loss: 0.717265784740448
Validation loss: 1.7175905435316023

Epoch: 6| Step: 13
Training loss: 0.5266368985176086
Validation loss: 1.7456485353490359

Epoch: 225| Step: 0
Training loss: 0.48642584681510925
Validation loss: 1.74390459317033

Epoch: 6| Step: 1
Training loss: 0.7542848587036133
Validation loss: 1.7566319947601647

Epoch: 6| Step: 2
Training loss: 0.34884631633758545
Validation loss: 1.741297624444449

Epoch: 6| Step: 3
Training loss: 0.6292744874954224
Validation loss: 1.733576507978542

Epoch: 6| Step: 4
Training loss: 0.6869444847106934
Validation loss: 1.6975348123940088

Epoch: 6| Step: 5
Training loss: 0.5218784809112549
Validation loss: 1.6880648700139855

Epoch: 6| Step: 6
Training loss: 0.5042610764503479
Validation loss: 1.68189105936276

Epoch: 6| Step: 7
Training loss: 0.5804023146629333
Validation loss: 1.6660062651480398

Epoch: 6| Step: 8
Training loss: 0.46588975191116333
Validation loss: 1.6522407249737812

Epoch: 6| Step: 9
Training loss: 0.6386709213256836
Validation loss: 1.6779563862790343

Epoch: 6| Step: 10
Training loss: 0.5976606607437134
Validation loss: 1.6949542748030795

Epoch: 6| Step: 11
Training loss: 0.28962475061416626
Validation loss: 1.7319853562180714

Epoch: 6| Step: 12
Training loss: 0.3930972218513489
Validation loss: 1.7049804195280998

Epoch: 6| Step: 13
Training loss: 0.4567725956439972
Validation loss: 1.700705925623576

Epoch: 226| Step: 0
Training loss: 0.5260094404220581
Validation loss: 1.6788972962287165

Epoch: 6| Step: 1
Training loss: 0.594308614730835
Validation loss: 1.6616918720224851

Epoch: 6| Step: 2
Training loss: 0.6150535941123962
Validation loss: 1.687683379778298

Epoch: 6| Step: 3
Training loss: 0.22749842703342438
Validation loss: 1.662084089812412

Epoch: 6| Step: 4
Training loss: 0.3594689667224884
Validation loss: 1.648143317109795

Epoch: 6| Step: 5
Training loss: 0.6010931730270386
Validation loss: 1.6587857354071833

Epoch: 6| Step: 6
Training loss: 0.31171122193336487
Validation loss: 1.6746810815667594

Epoch: 6| Step: 7
Training loss: 0.5538202524185181
Validation loss: 1.6827536629092308

Epoch: 6| Step: 8
Training loss: 0.4510417580604553
Validation loss: 1.6553391307912848

Epoch: 6| Step: 9
Training loss: 0.5630320310592651
Validation loss: 1.677713619765415

Epoch: 6| Step: 10
Training loss: 0.5164273977279663
Validation loss: 1.6632357874224264

Epoch: 6| Step: 11
Training loss: 0.3590109944343567
Validation loss: 1.6540873396781184

Epoch: 6| Step: 12
Training loss: 0.5728693008422852
Validation loss: 1.6918829884580386

Epoch: 6| Step: 13
Training loss: 0.8446885347366333
Validation loss: 1.6730406489423526

Epoch: 227| Step: 0
Training loss: 0.42803245782852173
Validation loss: 1.7081162698807255

Epoch: 6| Step: 1
Training loss: 0.7506575584411621
Validation loss: 1.6794748562638477

Epoch: 6| Step: 2
Training loss: 0.5005977153778076
Validation loss: 1.6625279508611208

Epoch: 6| Step: 3
Training loss: 0.577111542224884
Validation loss: 1.6761843004534323

Epoch: 6| Step: 4
Training loss: 0.6455205082893372
Validation loss: 1.6818923552831013

Epoch: 6| Step: 5
Training loss: 0.3749842643737793
Validation loss: 1.6824249580342283

Epoch: 6| Step: 6
Training loss: 0.20600178837776184
Validation loss: 1.6858834810154413

Epoch: 6| Step: 7
Training loss: 0.40577203035354614
Validation loss: 1.6970694500912902

Epoch: 6| Step: 8
Training loss: 0.6774352192878723
Validation loss: 1.745759537143092

Epoch: 6| Step: 9
Training loss: 0.5539537072181702
Validation loss: 1.7752077118042977

Epoch: 6| Step: 10
Training loss: 0.5582040548324585
Validation loss: 1.7986466794885614

Epoch: 6| Step: 11
Training loss: 0.4635867178440094
Validation loss: 1.738559494736374

Epoch: 6| Step: 12
Training loss: 0.36180728673934937
Validation loss: 1.7249826154401224

Epoch: 6| Step: 13
Training loss: 0.473428875207901
Validation loss: 1.7048120908839728

Epoch: 228| Step: 0
Training loss: 0.44613003730773926
Validation loss: 1.6478646365545129

Epoch: 6| Step: 1
Training loss: 0.5636067986488342
Validation loss: 1.639044806521426

Epoch: 6| Step: 2
Training loss: 0.13717620074748993
Validation loss: 1.615519315965714

Epoch: 6| Step: 3
Training loss: 0.43199247121810913
Validation loss: 1.6404399205279607

Epoch: 6| Step: 4
Training loss: 0.6274271607398987
Validation loss: 1.645352118758745

Epoch: 6| Step: 5
Training loss: 0.4727376699447632
Validation loss: 1.6449298038277576

Epoch: 6| Step: 6
Training loss: 0.49190741777420044
Validation loss: 1.6468795230311732

Epoch: 6| Step: 7
Training loss: 0.3192985951900482
Validation loss: 1.6694739915991341

Epoch: 6| Step: 8
Training loss: 0.7628834843635559
Validation loss: 1.7515488542536253

Epoch: 6| Step: 9
Training loss: 0.3597220182418823
Validation loss: 1.7258617198595436

Epoch: 6| Step: 10
Training loss: 0.4504414498806
Validation loss: 1.6928398974480168

Epoch: 6| Step: 11
Training loss: 0.666659951210022
Validation loss: 1.6844032695216518

Epoch: 6| Step: 12
Training loss: 0.36074936389923096
Validation loss: 1.6363972912552536

Epoch: 6| Step: 13
Training loss: 0.7208468317985535
Validation loss: 1.65489964203168

Epoch: 229| Step: 0
Training loss: 0.3456912636756897
Validation loss: 1.6177521085226407

Epoch: 6| Step: 1
Training loss: 0.4127925932407379
Validation loss: 1.610739101645767

Epoch: 6| Step: 2
Training loss: 0.4190649688243866
Validation loss: 1.6070587404312626

Epoch: 6| Step: 3
Training loss: 0.5166455507278442
Validation loss: 1.6222807745779715

Epoch: 6| Step: 4
Training loss: 0.2847185730934143
Validation loss: 1.6484684623697752

Epoch: 6| Step: 5
Training loss: 0.5455843210220337
Validation loss: 1.6269631706258303

Epoch: 6| Step: 6
Training loss: 0.47769269347190857
Validation loss: 1.6586445249536985

Epoch: 6| Step: 7
Training loss: 0.5819257497787476
Validation loss: 1.7076417489718365

Epoch: 6| Step: 8
Training loss: 0.6420546174049377
Validation loss: 1.717989884397035

Epoch: 6| Step: 9
Training loss: 0.6328455209732056
Validation loss: 1.7255288170230003

Epoch: 6| Step: 10
Training loss: 0.5861631631851196
Validation loss: 1.7026862790507655

Epoch: 6| Step: 11
Training loss: 0.38479065895080566
Validation loss: 1.7052350992797523

Epoch: 6| Step: 12
Training loss: 0.5763150453567505
Validation loss: 1.6839880302388182

Epoch: 6| Step: 13
Training loss: 0.2619481682777405
Validation loss: 1.6727389186941168

Epoch: 230| Step: 0
Training loss: 0.3478962182998657
Validation loss: 1.6874156857049594

Epoch: 6| Step: 1
Training loss: 0.5182710886001587
Validation loss: 1.6975688190870388

Epoch: 6| Step: 2
Training loss: 0.5463546514511108
Validation loss: 1.7143106960481214

Epoch: 6| Step: 3
Training loss: 0.4364194869995117
Validation loss: 1.7233802144245436

Epoch: 6| Step: 4
Training loss: 0.5104784965515137
Validation loss: 1.7019173406785535

Epoch: 6| Step: 5
Training loss: 0.35652244091033936
Validation loss: 1.6873921944249062

Epoch: 6| Step: 6
Training loss: 0.4573073387145996
Validation loss: 1.6863404768769459

Epoch: 6| Step: 7
Training loss: 0.8079250454902649
Validation loss: 1.6969216100631221

Epoch: 6| Step: 8
Training loss: 0.25696149468421936
Validation loss: 1.6643126574895715

Epoch: 6| Step: 9
Training loss: 0.31708550453186035
Validation loss: 1.684469804968885

Epoch: 6| Step: 10
Training loss: 0.6389729976654053
Validation loss: 1.6952999971246208

Epoch: 6| Step: 11
Training loss: 0.4443293809890747
Validation loss: 1.7023866650878743

Epoch: 6| Step: 12
Training loss: 0.3587411642074585
Validation loss: 1.7148961867055585

Epoch: 6| Step: 13
Training loss: 0.5606343150138855
Validation loss: 1.7190859638234621

Epoch: 231| Step: 0
Training loss: 0.5418195724487305
Validation loss: 1.740650547448025

Epoch: 6| Step: 1
Training loss: 0.4997738003730774
Validation loss: 1.7125388742775045

Epoch: 6| Step: 2
Training loss: 0.556069016456604
Validation loss: 1.6961310832731185

Epoch: 6| Step: 3
Training loss: 0.5865241289138794
Validation loss: 1.6762130927014094

Epoch: 6| Step: 4
Training loss: 0.39443302154541016
Validation loss: 1.6417241404133458

Epoch: 6| Step: 5
Training loss: 0.3683711290359497
Validation loss: 1.6580610390632384

Epoch: 6| Step: 6
Training loss: 0.5047949552536011
Validation loss: 1.6237735466290546

Epoch: 6| Step: 7
Training loss: 0.5001481771469116
Validation loss: 1.637545967614779

Epoch: 6| Step: 8
Training loss: 0.37502962350845337
Validation loss: 1.6649855567562966

Epoch: 6| Step: 9
Training loss: 0.24850761890411377
Validation loss: 1.6313687332214848

Epoch: 6| Step: 10
Training loss: 0.33970892429351807
Validation loss: 1.6582400811615812

Epoch: 6| Step: 11
Training loss: 0.593513548374176
Validation loss: 1.622558266885819

Epoch: 6| Step: 12
Training loss: 0.4332215189933777
Validation loss: 1.6330503712418258

Epoch: 6| Step: 13
Training loss: 0.28596046566963196
Validation loss: 1.618529212090277

Epoch: 232| Step: 0
Training loss: 0.5393170714378357
Validation loss: 1.620282128293027

Epoch: 6| Step: 1
Training loss: 0.3611578345298767
Validation loss: 1.6425703892143824

Epoch: 6| Step: 2
Training loss: 0.46775224804878235
Validation loss: 1.642962985141303

Epoch: 6| Step: 3
Training loss: 0.7368273735046387
Validation loss: 1.6087636575903943

Epoch: 6| Step: 4
Training loss: 0.36896127462387085
Validation loss: 1.6128908049675725

Epoch: 6| Step: 5
Training loss: 0.476855605840683
Validation loss: 1.6377294063568115

Epoch: 6| Step: 6
Training loss: 0.44865113496780396
Validation loss: 1.649356920232055

Epoch: 6| Step: 7
Training loss: 0.4408944845199585
Validation loss: 1.6742371641179568

Epoch: 6| Step: 8
Training loss: 0.5313180685043335
Validation loss: 1.6925091410195956

Epoch: 6| Step: 9
Training loss: 0.5625171065330505
Validation loss: 1.6885157785108011

Epoch: 6| Step: 10
Training loss: 0.30972132086753845
Validation loss: 1.7113760197034447

Epoch: 6| Step: 11
Training loss: 0.5036921501159668
Validation loss: 1.7132941676724343

Epoch: 6| Step: 12
Training loss: 0.4847945272922516
Validation loss: 1.656325988872077

Epoch: 6| Step: 13
Training loss: 0.8757598400115967
Validation loss: 1.6626285455560172

Epoch: 233| Step: 0
Training loss: 0.3666658401489258
Validation loss: 1.6503994259783017

Epoch: 6| Step: 1
Training loss: 0.19042575359344482
Validation loss: 1.6503818214580577

Epoch: 6| Step: 2
Training loss: 0.5220378637313843
Validation loss: 1.6561849412097727

Epoch: 6| Step: 3
Training loss: 0.708183765411377
Validation loss: 1.6564978937948904

Epoch: 6| Step: 4
Training loss: 0.4886479377746582
Validation loss: 1.6729026917488343

Epoch: 6| Step: 5
Training loss: 0.6383529901504517
Validation loss: 1.6777527819397628

Epoch: 6| Step: 6
Training loss: 0.37106239795684814
Validation loss: 1.7229869391328545

Epoch: 6| Step: 7
Training loss: 0.5917683839797974
Validation loss: 1.7383962510734476

Epoch: 6| Step: 8
Training loss: 0.5363462567329407
Validation loss: 1.7678681855560632

Epoch: 6| Step: 9
Training loss: 0.5009979605674744
Validation loss: 1.7620756049310007

Epoch: 6| Step: 10
Training loss: 0.5800093412399292
Validation loss: 1.7508695215307257

Epoch: 6| Step: 11
Training loss: 0.4561592638492584
Validation loss: 1.7115716639385428

Epoch: 6| Step: 12
Training loss: 0.5661026239395142
Validation loss: 1.6717859775789323

Epoch: 6| Step: 13
Training loss: 0.6750197410583496
Validation loss: 1.6348100759649788

Epoch: 234| Step: 0
Training loss: 0.4916394352912903
Validation loss: 1.6490916526445778

Epoch: 6| Step: 1
Training loss: 0.33846890926361084
Validation loss: 1.6226849632878457

Epoch: 6| Step: 2
Training loss: 0.5398452281951904
Validation loss: 1.6261224772340508

Epoch: 6| Step: 3
Training loss: 0.8546581268310547
Validation loss: 1.6183376530165314

Epoch: 6| Step: 4
Training loss: 0.6211870312690735
Validation loss: 1.604871274322592

Epoch: 6| Step: 5
Training loss: 0.30089569091796875
Validation loss: 1.6131727439101025

Epoch: 6| Step: 6
Training loss: 0.4820716381072998
Validation loss: 1.632942686798752

Epoch: 6| Step: 7
Training loss: 0.6156244277954102
Validation loss: 1.6474670415283532

Epoch: 6| Step: 8
Training loss: 0.38327091932296753
Validation loss: 1.6799761172263854

Epoch: 6| Step: 9
Training loss: 0.4237491488456726
Validation loss: 1.6918382593380508

Epoch: 6| Step: 10
Training loss: 0.3599018156528473
Validation loss: 1.7437557033313218

Epoch: 6| Step: 11
Training loss: 0.583492636680603
Validation loss: 1.742438264431492

Epoch: 6| Step: 12
Training loss: 0.4805121421813965
Validation loss: 1.7454415803314538

Epoch: 6| Step: 13
Training loss: 0.7710960507392883
Validation loss: 1.705123661666788

Epoch: 235| Step: 0
Training loss: 0.5116056203842163
Validation loss: 1.6870935552863664

Epoch: 6| Step: 1
Training loss: 0.4117257595062256
Validation loss: 1.6555512771811536

Epoch: 6| Step: 2
Training loss: 0.5882325172424316
Validation loss: 1.6467551967149139

Epoch: 6| Step: 3
Training loss: 0.5314223766326904
Validation loss: 1.6502566837495374

Epoch: 6| Step: 4
Training loss: 0.5223109722137451
Validation loss: 1.6483539124970794

Epoch: 6| Step: 5
Training loss: 0.4688795804977417
Validation loss: 1.6769300481324554

Epoch: 6| Step: 6
Training loss: 0.4553041160106659
Validation loss: 1.6888999977419454

Epoch: 6| Step: 7
Training loss: 0.5076038837432861
Validation loss: 1.6909903941615936

Epoch: 6| Step: 8
Training loss: 0.5644959807395935
Validation loss: 1.7197819371377268

Epoch: 6| Step: 9
Training loss: 0.5227595567703247
Validation loss: 1.7463289627464869

Epoch: 6| Step: 10
Training loss: 0.5648375749588013
Validation loss: 1.7879412328043292

Epoch: 6| Step: 11
Training loss: 0.5008267164230347
Validation loss: 1.7974560376136535

Epoch: 6| Step: 12
Training loss: 0.397951602935791
Validation loss: 1.7760338808900566

Epoch: 6| Step: 13
Training loss: 0.6328924298286438
Validation loss: 1.7438271853231615

Epoch: 236| Step: 0
Training loss: 0.47447073459625244
Validation loss: 1.716538945833842

Epoch: 6| Step: 1
Training loss: 0.5372580289840698
Validation loss: 1.6910628477732341

Epoch: 6| Step: 2
Training loss: 0.6333179473876953
Validation loss: 1.6816427682035713

Epoch: 6| Step: 3
Training loss: 0.49914228916168213
Validation loss: 1.6953655019883187

Epoch: 6| Step: 4
Training loss: 0.37575820088386536
Validation loss: 1.6790877798552155

Epoch: 6| Step: 5
Training loss: 0.49503758549690247
Validation loss: 1.7056143617117276

Epoch: 6| Step: 6
Training loss: 0.30907294154167175
Validation loss: 1.6641195192131946

Epoch: 6| Step: 7
Training loss: 0.34173139929771423
Validation loss: 1.6668857451408141

Epoch: 6| Step: 8
Training loss: 0.358995258808136
Validation loss: 1.708847277907915

Epoch: 6| Step: 9
Training loss: 0.43986982107162476
Validation loss: 1.6835279157084804

Epoch: 6| Step: 10
Training loss: 0.46826156973838806
Validation loss: 1.6994406420697448

Epoch: 6| Step: 11
Training loss: 0.5309535264968872
Validation loss: 1.7126286004179267

Epoch: 6| Step: 12
Training loss: 0.6783384084701538
Validation loss: 1.7364138877519997

Epoch: 6| Step: 13
Training loss: 0.3135818839073181
Validation loss: 1.7826650322124522

Epoch: 237| Step: 0
Training loss: 0.5259358882904053
Validation loss: 1.7643753815722722

Epoch: 6| Step: 1
Training loss: 0.6805156469345093
Validation loss: 1.714446331865044

Epoch: 6| Step: 2
Training loss: 0.5009906888008118
Validation loss: 1.6799940729653964

Epoch: 6| Step: 3
Training loss: 0.4869782328605652
Validation loss: 1.669578085663498

Epoch: 6| Step: 4
Training loss: 0.33660781383514404
Validation loss: 1.6618210525922879

Epoch: 6| Step: 5
Training loss: 0.4510214328765869
Validation loss: 1.6503685405177455

Epoch: 6| Step: 6
Training loss: 0.40407228469848633
Validation loss: 1.6600741699177732

Epoch: 6| Step: 7
Training loss: 0.4029751420021057
Validation loss: 1.6577189045567666

Epoch: 6| Step: 8
Training loss: 0.441585898399353
Validation loss: 1.686091048743135

Epoch: 6| Step: 9
Training loss: 0.36656254529953003
Validation loss: 1.7087465486218851

Epoch: 6| Step: 10
Training loss: 0.2747553288936615
Validation loss: 1.7735693736742901

Epoch: 6| Step: 11
Training loss: 0.4078189730644226
Validation loss: 1.791648644272999

Epoch: 6| Step: 12
Training loss: 0.6700103282928467
Validation loss: 1.7882691096234065

Epoch: 6| Step: 13
Training loss: 0.21000558137893677
Validation loss: 1.7936175510447512

Epoch: 238| Step: 0
Training loss: 0.3807201683521271
Validation loss: 1.7857682820289367

Epoch: 6| Step: 1
Training loss: 0.3985210955142975
Validation loss: 1.7430915230063981

Epoch: 6| Step: 2
Training loss: 0.48149991035461426
Validation loss: 1.6963063068287347

Epoch: 6| Step: 3
Training loss: 0.3441794216632843
Validation loss: 1.6846127843344083

Epoch: 6| Step: 4
Training loss: 0.3020061254501343
Validation loss: 1.6946634810457948

Epoch: 6| Step: 5
Training loss: 0.2737537622451782
Validation loss: 1.7023208628418625

Epoch: 6| Step: 6
Training loss: 0.42884260416030884
Validation loss: 1.700380189444429

Epoch: 6| Step: 7
Training loss: 0.3328564167022705
Validation loss: 1.6792226747799945

Epoch: 6| Step: 8
Training loss: 0.5854900479316711
Validation loss: 1.6657031659157044

Epoch: 6| Step: 9
Training loss: 0.5490626096725464
Validation loss: 1.6711736930313932

Epoch: 6| Step: 10
Training loss: 0.4354223310947418
Validation loss: 1.6382217381590156

Epoch: 6| Step: 11
Training loss: 0.45880165696144104
Validation loss: 1.6694068703600156

Epoch: 6| Step: 12
Training loss: 0.555436372756958
Validation loss: 1.686099345966052

Epoch: 6| Step: 13
Training loss: 0.8151848912239075
Validation loss: 1.7195320667759064

Epoch: 239| Step: 0
Training loss: 0.5991408824920654
Validation loss: 1.7395632087543447

Epoch: 6| Step: 1
Training loss: 0.24925965070724487
Validation loss: 1.7188518662606516

Epoch: 6| Step: 2
Training loss: 0.45924240350723267
Validation loss: 1.710653740872619

Epoch: 6| Step: 3
Training loss: 0.5996525287628174
Validation loss: 1.7091056428929812

Epoch: 6| Step: 4
Training loss: 0.3863988220691681
Validation loss: 1.7257853669504966

Epoch: 6| Step: 5
Training loss: 0.503474235534668
Validation loss: 1.7309588091347807

Epoch: 6| Step: 6
Training loss: 0.6103944778442383
Validation loss: 1.715315511149745

Epoch: 6| Step: 7
Training loss: 0.3432806432247162
Validation loss: 1.7249855097904

Epoch: 6| Step: 8
Training loss: 0.4421195983886719
Validation loss: 1.7414600874788018

Epoch: 6| Step: 9
Training loss: 0.3344615697860718
Validation loss: 1.6749345910164617

Epoch: 6| Step: 10
Training loss: 0.47561728954315186
Validation loss: 1.6659143112039054

Epoch: 6| Step: 11
Training loss: 0.25678569078445435
Validation loss: 1.6313157645604943

Epoch: 6| Step: 12
Training loss: 0.36352407932281494
Validation loss: 1.6590733284591346

Epoch: 6| Step: 13
Training loss: 0.498273640871048
Validation loss: 1.6765556437994844

Epoch: 240| Step: 0
Training loss: 0.37569373846054077
Validation loss: 1.667347711901511

Epoch: 6| Step: 1
Training loss: 0.3432955741882324
Validation loss: 1.6758323689942718

Epoch: 6| Step: 2
Training loss: 0.5509895086288452
Validation loss: 1.6620640139425955

Epoch: 6| Step: 3
Training loss: 0.35322460532188416
Validation loss: 1.6481755023361535

Epoch: 6| Step: 4
Training loss: 0.4357399344444275
Validation loss: 1.6446304321289062

Epoch: 6| Step: 5
Training loss: 0.5041711330413818
Validation loss: 1.6381545400106778

Epoch: 6| Step: 6
Training loss: 0.4488951563835144
Validation loss: 1.6797641964368923

Epoch: 6| Step: 7
Training loss: 0.4462388753890991
Validation loss: 1.6495501661813388

Epoch: 6| Step: 8
Training loss: 0.41156938672065735
Validation loss: 1.6568409076301

Epoch: 6| Step: 9
Training loss: 0.32866647839546204
Validation loss: 1.6750888670644453

Epoch: 6| Step: 10
Training loss: 0.4927881956100464
Validation loss: 1.712389652447034

Epoch: 6| Step: 11
Training loss: 0.7728627920150757
Validation loss: 1.6981065568103586

Epoch: 6| Step: 12
Training loss: 0.3891616761684418
Validation loss: 1.672536680775304

Epoch: 6| Step: 13
Training loss: 0.582439124584198
Validation loss: 1.6507262824684061

Epoch: 241| Step: 0
Training loss: 0.32076048851013184
Validation loss: 1.624860687922406

Epoch: 6| Step: 1
Training loss: 0.21837005019187927
Validation loss: 1.6220828563936296

Epoch: 6| Step: 2
Training loss: 0.3699631690979004
Validation loss: 1.6052813786332325

Epoch: 6| Step: 3
Training loss: 0.4985215365886688
Validation loss: 1.5964521797754432

Epoch: 6| Step: 4
Training loss: 0.40142661333084106
Validation loss: 1.6318699044566

Epoch: 6| Step: 5
Training loss: 0.3976982831954956
Validation loss: 1.6405419239433863

Epoch: 6| Step: 6
Training loss: 0.34236422181129456
Validation loss: 1.6662781982011692

Epoch: 6| Step: 7
Training loss: 0.40605592727661133
Validation loss: 1.6738297811118505

Epoch: 6| Step: 8
Training loss: 0.41840964555740356
Validation loss: 1.6612664294499222

Epoch: 6| Step: 9
Training loss: 0.47162115573883057
Validation loss: 1.6845532873625397

Epoch: 6| Step: 10
Training loss: 0.518102765083313
Validation loss: 1.6725640937846193

Epoch: 6| Step: 11
Training loss: 0.5400329828262329
Validation loss: 1.6597255917005642

Epoch: 6| Step: 12
Training loss: 0.39671552181243896
Validation loss: 1.6591499428595267

Epoch: 6| Step: 13
Training loss: 0.24406597018241882
Validation loss: 1.6518315961284022

Epoch: 242| Step: 0
Training loss: 0.46279746294021606
Validation loss: 1.6609138788715485

Epoch: 6| Step: 1
Training loss: 0.30083227157592773
Validation loss: 1.6477311593230053

Epoch: 6| Step: 2
Training loss: 0.32413387298583984
Validation loss: 1.6374935873093144

Epoch: 6| Step: 3
Training loss: 0.2686458230018616
Validation loss: 1.6436894593700286

Epoch: 6| Step: 4
Training loss: 0.6062058210372925
Validation loss: 1.652548022167657

Epoch: 6| Step: 5
Training loss: 0.5115071535110474
Validation loss: 1.6445439643757318

Epoch: 6| Step: 6
Training loss: 0.1643112301826477
Validation loss: 1.6367475294297742

Epoch: 6| Step: 7
Training loss: 0.17113113403320312
Validation loss: 1.628164497754907

Epoch: 6| Step: 8
Training loss: 0.39702364802360535
Validation loss: 1.6473939880248039

Epoch: 6| Step: 9
Training loss: 0.506773829460144
Validation loss: 1.630689763253735

Epoch: 6| Step: 10
Training loss: 0.40662682056427
Validation loss: 1.632225162239485

Epoch: 6| Step: 11
Training loss: 0.40214934945106506
Validation loss: 1.6506411952357138

Epoch: 6| Step: 12
Training loss: 0.46282872557640076
Validation loss: 1.6357380510658346

Epoch: 6| Step: 13
Training loss: 0.44444459676742554
Validation loss: 1.645579489328528

Epoch: 243| Step: 0
Training loss: 0.3643874526023865
Validation loss: 1.6335361452512844

Epoch: 6| Step: 1
Training loss: 0.3726066052913666
Validation loss: 1.633936684618714

Epoch: 6| Step: 2
Training loss: 0.21971112489700317
Validation loss: 1.6404335191172938

Epoch: 6| Step: 3
Training loss: 0.47828173637390137
Validation loss: 1.6520539432443597

Epoch: 6| Step: 4
Training loss: 0.43272918462753296
Validation loss: 1.6700407599890104

Epoch: 6| Step: 5
Training loss: 0.40717506408691406
Validation loss: 1.634340173454695

Epoch: 6| Step: 6
Training loss: 0.5615444183349609
Validation loss: 1.6515756166109474

Epoch: 6| Step: 7
Training loss: 0.21018463373184204
Validation loss: 1.6638767975632862

Epoch: 6| Step: 8
Training loss: 0.6503047943115234
Validation loss: 1.6601820466338948

Epoch: 6| Step: 9
Training loss: 0.44863635301589966
Validation loss: 1.6856101219372084

Epoch: 6| Step: 10
Training loss: 0.515477180480957
Validation loss: 1.6836169265931653

Epoch: 6| Step: 11
Training loss: 0.3411140441894531
Validation loss: 1.6765633603577972

Epoch: 6| Step: 12
Training loss: 0.4408409595489502
Validation loss: 1.6630955434614612

Epoch: 6| Step: 13
Training loss: 0.176166832447052
Validation loss: 1.6506882662414222

Epoch: 244| Step: 0
Training loss: 0.3045995235443115
Validation loss: 1.660806143155662

Epoch: 6| Step: 1
Training loss: 0.5291939973831177
Validation loss: 1.6636479298273723

Epoch: 6| Step: 2
Training loss: 0.3977839946746826
Validation loss: 1.608517898026333

Epoch: 6| Step: 3
Training loss: 0.4232301414012909
Validation loss: 1.5979553678984284

Epoch: 6| Step: 4
Training loss: 0.3782334327697754
Validation loss: 1.6250144448331607

Epoch: 6| Step: 5
Training loss: 0.30803102254867554
Validation loss: 1.634009067730237

Epoch: 6| Step: 6
Training loss: 0.45000991225242615
Validation loss: 1.5986940886384697

Epoch: 6| Step: 7
Training loss: 0.38768815994262695
Validation loss: 1.610162022293255

Epoch: 6| Step: 8
Training loss: 0.20790189504623413
Validation loss: 1.6400496498230965

Epoch: 6| Step: 9
Training loss: 0.37157443165779114
Validation loss: 1.6331820205975605

Epoch: 6| Step: 10
Training loss: 0.35909152030944824
Validation loss: 1.6556691469684723

Epoch: 6| Step: 11
Training loss: 0.428554505109787
Validation loss: 1.6591397318788754

Epoch: 6| Step: 12
Training loss: 0.4267471134662628
Validation loss: 1.6928358667640275

Epoch: 6| Step: 13
Training loss: 0.37482503056526184
Validation loss: 1.664741039276123

Epoch: 245| Step: 0
Training loss: 0.5901001691818237
Validation loss: 1.6667226706781695

Epoch: 6| Step: 1
Training loss: 0.22348347306251526
Validation loss: 1.705944348407048

Epoch: 6| Step: 2
Training loss: 0.40056419372558594
Validation loss: 1.688809794764365

Epoch: 6| Step: 3
Training loss: 0.35882818698883057
Validation loss: 1.6453598109624719

Epoch: 6| Step: 4
Training loss: 0.26834163069725037
Validation loss: 1.6659745349678943

Epoch: 6| Step: 5
Training loss: 0.4577212929725647
Validation loss: 1.6329289162030785

Epoch: 6| Step: 6
Training loss: 0.3493797481060028
Validation loss: 1.6368279867274786

Epoch: 6| Step: 7
Training loss: 0.3527788519859314
Validation loss: 1.6456813581528202

Epoch: 6| Step: 8
Training loss: 0.38899174332618713
Validation loss: 1.6348684154531008

Epoch: 6| Step: 9
Training loss: 0.4298381805419922
Validation loss: 1.6103321031857563

Epoch: 6| Step: 10
Training loss: 0.371116578578949
Validation loss: 1.5946543806342668

Epoch: 6| Step: 11
Training loss: 0.4837133288383484
Validation loss: 1.5530846682927941

Epoch: 6| Step: 12
Training loss: 0.2659897804260254
Validation loss: 1.5845521137278566

Epoch: 6| Step: 13
Training loss: 0.2148859202861786
Validation loss: 1.614301819955149

Epoch: 246| Step: 0
Training loss: 0.5132101774215698
Validation loss: 1.6366552947669901

Epoch: 6| Step: 1
Training loss: 0.3587605953216553
Validation loss: 1.6337436501697828

Epoch: 6| Step: 2
Training loss: 0.4060347378253937
Validation loss: 1.6792098975950671

Epoch: 6| Step: 3
Training loss: 0.2601170241832733
Validation loss: 1.6741692084138111

Epoch: 6| Step: 4
Training loss: 0.2708532214164734
Validation loss: 1.6768196116211593

Epoch: 6| Step: 5
Training loss: 0.5190267562866211
Validation loss: 1.6325801764765093

Epoch: 6| Step: 6
Training loss: 0.5348283648490906
Validation loss: 1.6155648660916153

Epoch: 6| Step: 7
Training loss: 0.402565062046051
Validation loss: 1.5891584311762164

Epoch: 6| Step: 8
Training loss: 0.2986423075199127
Validation loss: 1.5900393673168716

Epoch: 6| Step: 9
Training loss: 0.30937692523002625
Validation loss: 1.587730420533047

Epoch: 6| Step: 10
Training loss: 0.45806238055229187
Validation loss: 1.6387516516511158

Epoch: 6| Step: 11
Training loss: 0.582660436630249
Validation loss: 1.6360043377004645

Epoch: 6| Step: 12
Training loss: 0.5326234102249146
Validation loss: 1.6606968231098627

Epoch: 6| Step: 13
Training loss: 0.1894126832485199
Validation loss: 1.6885926159479285

Epoch: 247| Step: 0
Training loss: 0.20118747651576996
Validation loss: 1.6856566782920592

Epoch: 6| Step: 1
Training loss: 0.4135969877243042
Validation loss: 1.7260193901677285

Epoch: 6| Step: 2
Training loss: 0.2847205400466919
Validation loss: 1.724270305325908

Epoch: 6| Step: 3
Training loss: 0.5009863972663879
Validation loss: 1.7376367712533602

Epoch: 6| Step: 4
Training loss: 0.5408838391304016
Validation loss: 1.7574330042767268

Epoch: 6| Step: 5
Training loss: 0.563422679901123
Validation loss: 1.7336752260884931

Epoch: 6| Step: 6
Training loss: 0.3827472925186157
Validation loss: 1.6651107085648404

Epoch: 6| Step: 7
Training loss: 0.558799147605896
Validation loss: 1.6293438262836908

Epoch: 6| Step: 8
Training loss: 0.29839441180229187
Validation loss: 1.6175530931001068

Epoch: 6| Step: 9
Training loss: 0.3616737723350525
Validation loss: 1.6232602365555302

Epoch: 6| Step: 10
Training loss: 0.27372676134109497
Validation loss: 1.5839894920267084

Epoch: 6| Step: 11
Training loss: 0.3750219941139221
Validation loss: 1.5994850268927954

Epoch: 6| Step: 12
Training loss: 0.39643150568008423
Validation loss: 1.6020818807745492

Epoch: 6| Step: 13
Training loss: 0.34292179346084595
Validation loss: 1.5956692016252907

Epoch: 248| Step: 0
Training loss: 0.4078453481197357
Validation loss: 1.6188180959352882

Epoch: 6| Step: 1
Training loss: 0.4126996695995331
Validation loss: 1.6357231370864376

Epoch: 6| Step: 2
Training loss: 0.259677529335022
Validation loss: 1.6415707193395144

Epoch: 6| Step: 3
Training loss: 0.31924158334732056
Validation loss: 1.6296951514418407

Epoch: 6| Step: 4
Training loss: 0.48877251148223877
Validation loss: 1.5883074704036917

Epoch: 6| Step: 5
Training loss: 0.31382083892822266
Validation loss: 1.5766532485203077

Epoch: 6| Step: 6
Training loss: 0.4546877145767212
Validation loss: 1.6068776653658958

Epoch: 6| Step: 7
Training loss: 0.3935920000076294
Validation loss: 1.5929012093492734

Epoch: 6| Step: 8
Training loss: 0.36325603723526
Validation loss: 1.5902931421033797

Epoch: 6| Step: 9
Training loss: 0.3137514591217041
Validation loss: 1.5966010093688965

Epoch: 6| Step: 10
Training loss: 0.2610571086406708
Validation loss: 1.6054915305106872

Epoch: 6| Step: 11
Training loss: 0.28097003698349
Validation loss: 1.5721811812411073

Epoch: 6| Step: 12
Training loss: 0.5605363249778748
Validation loss: 1.5663734392453266

Epoch: 6| Step: 13
Training loss: 0.3021242320537567
Validation loss: 1.5950133544142528

Epoch: 249| Step: 0
Training loss: 0.2550227642059326
Validation loss: 1.6026363584303087

Epoch: 6| Step: 1
Training loss: 0.3209167718887329
Validation loss: 1.6017238273415515

Epoch: 6| Step: 2
Training loss: 0.23148462176322937
Validation loss: 1.60537431316991

Epoch: 6| Step: 3
Training loss: 0.41189050674438477
Validation loss: 1.5887519595443562

Epoch: 6| Step: 4
Training loss: 0.5251110196113586
Validation loss: 1.5915914107394475

Epoch: 6| Step: 5
Training loss: 0.5028783082962036
Validation loss: 1.5783268661909207

Epoch: 6| Step: 6
Training loss: 0.3769979476928711
Validation loss: 1.5786796410878499

Epoch: 6| Step: 7
Training loss: 0.3977952003479004
Validation loss: 1.5902566743153397

Epoch: 6| Step: 8
Training loss: 0.37522879242897034
Validation loss: 1.5862729626317178

Epoch: 6| Step: 9
Training loss: 0.22123631834983826
Validation loss: 1.591935819195163

Epoch: 6| Step: 10
Training loss: 0.22443531453609467
Validation loss: 1.603637255648131

Epoch: 6| Step: 11
Training loss: 0.4521946907043457
Validation loss: 1.5951384844318512

Epoch: 6| Step: 12
Training loss: 0.41089388728141785
Validation loss: 1.596600438958855

Epoch: 6| Step: 13
Training loss: 0.48618924617767334
Validation loss: 1.6176693490756455

Epoch: 250| Step: 0
Training loss: 0.3010939359664917
Validation loss: 1.6044982710192282

Epoch: 6| Step: 1
Training loss: 0.3743659257888794
Validation loss: 1.5926185884783346

Epoch: 6| Step: 2
Training loss: 0.2506945729255676
Validation loss: 1.5690219107494559

Epoch: 6| Step: 3
Training loss: 0.3809086084365845
Validation loss: 1.5771615005308581

Epoch: 6| Step: 4
Training loss: 0.6111544966697693
Validation loss: 1.5650735426974554

Epoch: 6| Step: 5
Training loss: 0.21120646595954895
Validation loss: 1.5464794981864192

Epoch: 6| Step: 6
Training loss: 0.17491291463375092
Validation loss: 1.566411619545311

Epoch: 6| Step: 7
Training loss: 0.4030742943286896
Validation loss: 1.5576379260709208

Epoch: 6| Step: 8
Training loss: 0.36722898483276367
Validation loss: 1.6086843866173939

Epoch: 6| Step: 9
Training loss: 0.5316307544708252
Validation loss: 1.584069343664313

Epoch: 6| Step: 10
Training loss: 0.43612104654312134
Validation loss: 1.6193181930049774

Epoch: 6| Step: 11
Training loss: 0.332851767539978
Validation loss: 1.5983109551091348

Epoch: 6| Step: 12
Training loss: 0.30649733543395996
Validation loss: 1.6007140656953216

Epoch: 6| Step: 13
Training loss: 0.6359171271324158
Validation loss: 1.5648643867943877

Epoch: 251| Step: 0
Training loss: 0.4385969638824463
Validation loss: 1.56041766366651

Epoch: 6| Step: 1
Training loss: 0.4177999496459961
Validation loss: 1.5691269969427457

Epoch: 6| Step: 2
Training loss: 0.20236727595329285
Validation loss: 1.542369383637623

Epoch: 6| Step: 3
Training loss: 0.31162238121032715
Validation loss: 1.5612575982206611

Epoch: 6| Step: 4
Training loss: 0.4189174473285675
Validation loss: 1.563127443354617

Epoch: 6| Step: 5
Training loss: 0.269051730632782
Validation loss: 1.5430023003649969

Epoch: 6| Step: 6
Training loss: 0.2658971846103668
Validation loss: 1.5739347088721491

Epoch: 6| Step: 7
Training loss: 0.44206345081329346
Validation loss: 1.593704362069407

Epoch: 6| Step: 8
Training loss: 0.2061900943517685
Validation loss: 1.554049221418237

Epoch: 6| Step: 9
Training loss: 0.43278563022613525
Validation loss: 1.5894409482197096

Epoch: 6| Step: 10
Training loss: 0.20134471356868744
Validation loss: 1.6019035616228658

Epoch: 6| Step: 11
Training loss: 0.3805522620677948
Validation loss: 1.602074557735074

Epoch: 6| Step: 12
Training loss: 0.5030978918075562
Validation loss: 1.5874611023933656

Epoch: 6| Step: 13
Training loss: 0.22482500970363617
Validation loss: 1.5887760673799822

Epoch: 252| Step: 0
Training loss: 0.2290416806936264
Validation loss: 1.583921468386086

Epoch: 6| Step: 1
Training loss: 0.4805338382720947
Validation loss: 1.6061209888868435

Epoch: 6| Step: 2
Training loss: 0.4245569407939911
Validation loss: 1.6372441386663785

Epoch: 6| Step: 3
Training loss: 0.3085612654685974
Validation loss: 1.6229261198351461

Epoch: 6| Step: 4
Training loss: 0.378523588180542
Validation loss: 1.6032936906301847

Epoch: 6| Step: 5
Training loss: 0.2793622612953186
Validation loss: 1.5741390848672518

Epoch: 6| Step: 6
Training loss: 0.2682810425758362
Validation loss: 1.578467990762444

Epoch: 6| Step: 7
Training loss: 0.23713798820972443
Validation loss: 1.5691144812491633

Epoch: 6| Step: 8
Training loss: 0.32092463970184326
Validation loss: 1.561950457993374

Epoch: 6| Step: 9
Training loss: 0.3799036741256714
Validation loss: 1.5529010565050188

Epoch: 6| Step: 10
Training loss: 0.27291783690452576
Validation loss: 1.5510699774629326

Epoch: 6| Step: 11
Training loss: 0.4246166944503784
Validation loss: 1.5750496823300597

Epoch: 6| Step: 12
Training loss: 0.4432081878185272
Validation loss: 1.5596306631642003

Epoch: 6| Step: 13
Training loss: 0.5170294642448425
Validation loss: 1.6072527708545807

Epoch: 253| Step: 0
Training loss: 0.3375919461250305
Validation loss: 1.6123188464872298

Epoch: 6| Step: 1
Training loss: 0.31342214345932007
Validation loss: 1.6063124543877059

Epoch: 6| Step: 2
Training loss: 0.2861887812614441
Validation loss: 1.6438133421764578

Epoch: 6| Step: 3
Training loss: 0.5150119662284851
Validation loss: 1.6830704398052667

Epoch: 6| Step: 4
Training loss: 0.31945520639419556
Validation loss: 1.656376536174487

Epoch: 6| Step: 5
Training loss: 0.3576858639717102
Validation loss: 1.6642617717865975

Epoch: 6| Step: 6
Training loss: 0.47610586881637573
Validation loss: 1.6427399445605535

Epoch: 6| Step: 7
Training loss: 0.4705457389354706
Validation loss: 1.6167456270546041

Epoch: 6| Step: 8
Training loss: 0.40433764457702637
Validation loss: 1.592202180175371

Epoch: 6| Step: 9
Training loss: 0.3581373691558838
Validation loss: 1.5735287691957207

Epoch: 6| Step: 10
Training loss: 0.1992579996585846
Validation loss: 1.5847377546371952

Epoch: 6| Step: 11
Training loss: 0.35715535283088684
Validation loss: 1.629685394225582

Epoch: 6| Step: 12
Training loss: 0.20985835790634155
Validation loss: 1.643474184056764

Epoch: 6| Step: 13
Training loss: 0.32225725054740906
Validation loss: 1.6604290136726954

Epoch: 254| Step: 0
Training loss: 0.32616204023361206
Validation loss: 1.6520865232713762

Epoch: 6| Step: 1
Training loss: 0.44185906648635864
Validation loss: 1.6461594412403722

Epoch: 6| Step: 2
Training loss: 0.4186505079269409
Validation loss: 1.5877518192414315

Epoch: 6| Step: 3
Training loss: 0.2970443069934845
Validation loss: 1.5611653417669318

Epoch: 6| Step: 4
Training loss: 0.3327407240867615
Validation loss: 1.5666467105188677

Epoch: 6| Step: 5
Training loss: 0.3315112888813019
Validation loss: 1.5639972661131172

Epoch: 6| Step: 6
Training loss: 0.30787450075149536
Validation loss: 1.5343736794687086

Epoch: 6| Step: 7
Training loss: 0.4059491455554962
Validation loss: 1.5370339424379411

Epoch: 6| Step: 8
Training loss: 0.30294331908226013
Validation loss: 1.5179374371805499

Epoch: 6| Step: 9
Training loss: 0.336262583732605
Validation loss: 1.5680684812607304

Epoch: 6| Step: 10
Training loss: 0.28400564193725586
Validation loss: 1.5852534155691824

Epoch: 6| Step: 11
Training loss: 0.39006441831588745
Validation loss: 1.6373891586898475

Epoch: 6| Step: 12
Training loss: 0.36000141501426697
Validation loss: 1.652516424015004

Epoch: 6| Step: 13
Training loss: 0.6316485404968262
Validation loss: 1.6815558056677542

Epoch: 255| Step: 0
Training loss: 0.5516977906227112
Validation loss: 1.723721122228971

Epoch: 6| Step: 1
Training loss: 0.38017934560775757
Validation loss: 1.7237887510689356

Epoch: 6| Step: 2
Training loss: 0.42145541310310364
Validation loss: 1.702639001671986

Epoch: 6| Step: 3
Training loss: 0.36593344807624817
Validation loss: 1.650823655948844

Epoch: 6| Step: 4
Training loss: 0.2815116345882416
Validation loss: 1.6448205901730446

Epoch: 6| Step: 5
Training loss: 0.40470442175865173
Validation loss: 1.597366779081283

Epoch: 6| Step: 6
Training loss: 0.305183082818985
Validation loss: 1.5828094033784763

Epoch: 6| Step: 7
Training loss: 0.35533586144447327
Validation loss: 1.5625574281138759

Epoch: 6| Step: 8
Training loss: 0.3509119153022766
Validation loss: 1.583012947472193

Epoch: 6| Step: 9
Training loss: 0.38166913390159607
Validation loss: 1.5297374712523593

Epoch: 6| Step: 10
Training loss: 0.3303062319755554
Validation loss: 1.5516282499477427

Epoch: 6| Step: 11
Training loss: 0.3730812668800354
Validation loss: 1.5462119220405497

Epoch: 6| Step: 12
Training loss: 0.40643739700317383
Validation loss: 1.5700430267600602

Epoch: 6| Step: 13
Training loss: 0.3439728617668152
Validation loss: 1.5774060603111022

Epoch: 256| Step: 0
Training loss: 0.5005634427070618
Validation loss: 1.6527328734756799

Epoch: 6| Step: 1
Training loss: 0.3073883354663849
Validation loss: 1.678405515609249

Epoch: 6| Step: 2
Training loss: 0.22403770685195923
Validation loss: 1.6501944013821181

Epoch: 6| Step: 3
Training loss: 0.3634899854660034
Validation loss: 1.6529376942624328

Epoch: 6| Step: 4
Training loss: 0.2798980474472046
Validation loss: 1.6386574429850425

Epoch: 6| Step: 5
Training loss: 0.6206582188606262
Validation loss: 1.597930089119942

Epoch: 6| Step: 6
Training loss: 0.2918647229671478
Validation loss: 1.586070200448395

Epoch: 6| Step: 7
Training loss: 0.26354163885116577
Validation loss: 1.5733527957752187

Epoch: 6| Step: 8
Training loss: 0.3490731418132782
Validation loss: 1.5577250924161685

Epoch: 6| Step: 9
Training loss: 0.4314013123512268
Validation loss: 1.550453785927065

Epoch: 6| Step: 10
Training loss: 0.18981266021728516
Validation loss: 1.5651177693438787

Epoch: 6| Step: 11
Training loss: 0.4455925524234772
Validation loss: 1.5710195751600369

Epoch: 6| Step: 12
Training loss: 0.5253976583480835
Validation loss: 1.567682994309292

Epoch: 6| Step: 13
Training loss: 0.29145681858062744
Validation loss: 1.5553596891382688

Epoch: 257| Step: 0
Training loss: 0.23111961781978607
Validation loss: 1.5619815652088453

Epoch: 6| Step: 1
Training loss: 0.3804081678390503
Validation loss: 1.5559134380791777

Epoch: 6| Step: 2
Training loss: 0.445407897233963
Validation loss: 1.572418571800314

Epoch: 6| Step: 3
Training loss: 0.3252325654029846
Validation loss: 1.5808964749818206

Epoch: 6| Step: 4
Training loss: 0.35355573892593384
Validation loss: 1.5824167023422897

Epoch: 6| Step: 5
Training loss: 0.35252195596694946
Validation loss: 1.5823821380574217

Epoch: 6| Step: 6
Training loss: 0.4570605754852295
Validation loss: 1.6216404220109344

Epoch: 6| Step: 7
Training loss: 0.6071502566337585
Validation loss: 1.6747701244969522

Epoch: 6| Step: 8
Training loss: 0.43116143345832825
Validation loss: 1.737063216906722

Epoch: 6| Step: 9
Training loss: 0.26739588379859924
Validation loss: 1.6694949532067904

Epoch: 6| Step: 10
Training loss: 0.4422687292098999
Validation loss: 1.6923677946931572

Epoch: 6| Step: 11
Training loss: 0.4719853699207306
Validation loss: 1.6515518106440061

Epoch: 6| Step: 12
Training loss: 0.1555424928665161
Validation loss: 1.6036565444802726

Epoch: 6| Step: 13
Training loss: 0.1501009613275528
Validation loss: 1.5776965336133075

Epoch: 258| Step: 0
Training loss: 0.3976442813873291
Validation loss: 1.530073537621447

Epoch: 6| Step: 1
Training loss: 0.31451135873794556
Validation loss: 1.521376391892792

Epoch: 6| Step: 2
Training loss: 0.2682715356349945
Validation loss: 1.5264362955606112

Epoch: 6| Step: 3
Training loss: 0.17926882207393646
Validation loss: 1.5310435423287012

Epoch: 6| Step: 4
Training loss: 0.43185675144195557
Validation loss: 1.515140164283014

Epoch: 6| Step: 5
Training loss: 0.28335461020469666
Validation loss: 1.538508439576754

Epoch: 6| Step: 6
Training loss: 0.3677430748939514
Validation loss: 1.5551642423034997

Epoch: 6| Step: 7
Training loss: 0.4346870183944702
Validation loss: 1.5553853563083115

Epoch: 6| Step: 8
Training loss: 0.3559172749519348
Validation loss: 1.5876378026059879

Epoch: 6| Step: 9
Training loss: 0.38312816619873047
Validation loss: 1.6148411048355924

Epoch: 6| Step: 10
Training loss: 0.43886518478393555
Validation loss: 1.6443164835694015

Epoch: 6| Step: 11
Training loss: 0.3728177547454834
Validation loss: 1.6591534204380487

Epoch: 6| Step: 12
Training loss: 0.2735689878463745
Validation loss: 1.6827295877600228

Epoch: 6| Step: 13
Training loss: 0.1782173067331314
Validation loss: 1.6407831375316908

Epoch: 259| Step: 0
Training loss: 0.30617982149124146
Validation loss: 1.6342965608002038

Epoch: 6| Step: 1
Training loss: 0.2853696942329407
Validation loss: 1.604450814185604

Epoch: 6| Step: 2
Training loss: 0.3994702696800232
Validation loss: 1.5937128323380665

Epoch: 6| Step: 3
Training loss: 0.4861834645271301
Validation loss: 1.5578455809623963

Epoch: 6| Step: 4
Training loss: 0.332797110080719
Validation loss: 1.5497640153413177

Epoch: 6| Step: 5
Training loss: 0.38681209087371826
Validation loss: 1.5347213181116248

Epoch: 6| Step: 6
Training loss: 0.279535710811615
Validation loss: 1.5284296851004324

Epoch: 6| Step: 7
Training loss: 0.33648619055747986
Validation loss: 1.5359895979204485

Epoch: 6| Step: 8
Training loss: 0.3472336530685425
Validation loss: 1.5269568902190014

Epoch: 6| Step: 9
Training loss: 0.3707636594772339
Validation loss: 1.5277970388371458

Epoch: 6| Step: 10
Training loss: 0.1999199390411377
Validation loss: 1.5475017306625203

Epoch: 6| Step: 11
Training loss: 0.3205356001853943
Validation loss: 1.538044733385886

Epoch: 6| Step: 12
Training loss: 0.4306136667728424
Validation loss: 1.585811177889506

Epoch: 6| Step: 13
Training loss: 0.4099887013435364
Validation loss: 1.6370496173058786

Epoch: 260| Step: 0
Training loss: 0.3894663155078888
Validation loss: 1.6698920476821162

Epoch: 6| Step: 1
Training loss: 0.37639927864074707
Validation loss: 1.6986641781304472

Epoch: 6| Step: 2
Training loss: 0.5262361764907837
Validation loss: 1.6526105878173665

Epoch: 6| Step: 3
Training loss: 0.34934818744659424
Validation loss: 1.6176531443031885

Epoch: 6| Step: 4
Training loss: 0.38330376148223877
Validation loss: 1.588531437740531

Epoch: 6| Step: 5
Training loss: 0.2645616829395294
Validation loss: 1.5907921124530096

Epoch: 6| Step: 6
Training loss: 0.29160332679748535
Validation loss: 1.5548946152451217

Epoch: 6| Step: 7
Training loss: 0.4645676612854004
Validation loss: 1.547528891153233

Epoch: 6| Step: 8
Training loss: 0.5448845624923706
Validation loss: 1.5516607511428095

Epoch: 6| Step: 9
Training loss: 0.3643783926963806
Validation loss: 1.5272829827441965

Epoch: 6| Step: 10
Training loss: 0.26685264706611633
Validation loss: 1.5273737369045135

Epoch: 6| Step: 11
Training loss: 0.38234394788742065
Validation loss: 1.5261123821299563

Epoch: 6| Step: 12
Training loss: 0.2875988483428955
Validation loss: 1.5037486514737528

Epoch: 6| Step: 13
Training loss: 0.382485032081604
Validation loss: 1.521790071200299

Epoch: 261| Step: 0
Training loss: 0.42221009731292725
Validation loss: 1.5371529299725768

Epoch: 6| Step: 1
Training loss: 0.3709401786327362
Validation loss: 1.553997238477071

Epoch: 6| Step: 2
Training loss: 0.43273213505744934
Validation loss: 1.5291250803137337

Epoch: 6| Step: 3
Training loss: 0.31748732924461365
Validation loss: 1.5569418617474136

Epoch: 6| Step: 4
Training loss: 0.3963949680328369
Validation loss: 1.545721056640789

Epoch: 6| Step: 5
Training loss: 0.38472360372543335
Validation loss: 1.5347663766594344

Epoch: 6| Step: 6
Training loss: 0.27222198247909546
Validation loss: 1.5372990831252067

Epoch: 6| Step: 7
Training loss: 0.2797015905380249
Validation loss: 1.559714990277444

Epoch: 6| Step: 8
Training loss: 0.5553770661354065
Validation loss: 1.5972034982455674

Epoch: 6| Step: 9
Training loss: 0.33222436904907227
Validation loss: 1.5724784225545905

Epoch: 6| Step: 10
Training loss: 0.3936692476272583
Validation loss: 1.5672742820555163

Epoch: 6| Step: 11
Training loss: 0.26091429591178894
Validation loss: 1.5657695185753606

Epoch: 6| Step: 12
Training loss: 0.24530884623527527
Validation loss: 1.5876705056877547

Epoch: 6| Step: 13
Training loss: 0.34255215525627136
Validation loss: 1.5824561176761505

Epoch: 262| Step: 0
Training loss: 0.394864559173584
Validation loss: 1.6453593777072044

Epoch: 6| Step: 1
Training loss: 0.42992669343948364
Validation loss: 1.6671550120076826

Epoch: 6| Step: 2
Training loss: 0.3767053484916687
Validation loss: 1.633139435962964

Epoch: 6| Step: 3
Training loss: 0.22926290333271027
Validation loss: 1.6037597528067968

Epoch: 6| Step: 4
Training loss: 0.2618994116783142
Validation loss: 1.545620245318259

Epoch: 6| Step: 5
Training loss: 0.4400221109390259
Validation loss: 1.5400045994789369

Epoch: 6| Step: 6
Training loss: 0.47540760040283203
Validation loss: 1.512861224912828

Epoch: 6| Step: 7
Training loss: 0.28106558322906494
Validation loss: 1.5682641460049538

Epoch: 6| Step: 8
Training loss: 0.2859951853752136
Validation loss: 1.574814542647331

Epoch: 6| Step: 9
Training loss: 0.3670217990875244
Validation loss: 1.5646103300074095

Epoch: 6| Step: 10
Training loss: 0.2512955069541931
Validation loss: 1.5682203449228758

Epoch: 6| Step: 11
Training loss: 0.3276824653148651
Validation loss: 1.567212829025843

Epoch: 6| Step: 12
Training loss: 0.31240856647491455
Validation loss: 1.580923641881635

Epoch: 6| Step: 13
Training loss: 0.16968800127506256
Validation loss: 1.6032096032173402

Epoch: 263| Step: 0
Training loss: 0.4309958517551422
Validation loss: 1.628657837067881

Epoch: 6| Step: 1
Training loss: 0.22606909275054932
Validation loss: 1.6123224625023462

Epoch: 6| Step: 2
Training loss: 0.24198280274868011
Validation loss: 1.6205245987061532

Epoch: 6| Step: 3
Training loss: 0.31618261337280273
Validation loss: 1.6121415886827695

Epoch: 6| Step: 4
Training loss: 0.3428831100463867
Validation loss: 1.6120799151800012

Epoch: 6| Step: 5
Training loss: 0.243337482213974
Validation loss: 1.6139102059025918

Epoch: 6| Step: 6
Training loss: 0.36884936690330505
Validation loss: 1.6108763948563607

Epoch: 6| Step: 7
Training loss: 0.37515920400619507
Validation loss: 1.61117721116671

Epoch: 6| Step: 8
Training loss: 0.3369421362876892
Validation loss: 1.6105334566485496

Epoch: 6| Step: 9
Training loss: 0.24385952949523926
Validation loss: 1.5801028397775465

Epoch: 6| Step: 10
Training loss: 0.3736046552658081
Validation loss: 1.6018815399498068

Epoch: 6| Step: 11
Training loss: 0.43768399953842163
Validation loss: 1.6005849184528473

Epoch: 6| Step: 12
Training loss: 0.18542349338531494
Validation loss: 1.6302735997784523

Epoch: 6| Step: 13
Training loss: 0.3643844425678253
Validation loss: 1.6216739454577047

Epoch: 264| Step: 0
Training loss: 0.19881334900856018
Validation loss: 1.6208869795645438

Epoch: 6| Step: 1
Training loss: 0.440531462430954
Validation loss: 1.5928890666654032

Epoch: 6| Step: 2
Training loss: 0.2273731678724289
Validation loss: 1.6060453871245026

Epoch: 6| Step: 3
Training loss: 0.4238995909690857
Validation loss: 1.5475699081215808

Epoch: 6| Step: 4
Training loss: 0.26512885093688965
Validation loss: 1.5674767263474003

Epoch: 6| Step: 5
Training loss: 0.34501928091049194
Validation loss: 1.5777255911980905

Epoch: 6| Step: 6
Training loss: 0.5097483992576599
Validation loss: 1.6132793388059061

Epoch: 6| Step: 7
Training loss: 0.26491767168045044
Validation loss: 1.618143787307124

Epoch: 6| Step: 8
Training loss: 0.2510896325111389
Validation loss: 1.6240417732987353

Epoch: 6| Step: 9
Training loss: 0.11539915204048157
Validation loss: 1.5965459692862727

Epoch: 6| Step: 10
Training loss: 0.19673584401607513
Validation loss: 1.5740227442915722

Epoch: 6| Step: 11
Training loss: 0.356026291847229
Validation loss: 1.592103773547757

Epoch: 6| Step: 12
Training loss: 0.21185272932052612
Validation loss: 1.5952874716892038

Epoch: 6| Step: 13
Training loss: 0.25874602794647217
Validation loss: 1.5461400067934425

Epoch: 265| Step: 0
Training loss: 0.4818183481693268
Validation loss: 1.5684112374500563

Epoch: 6| Step: 1
Training loss: 0.23740139603614807
Validation loss: 1.5697142052394089

Epoch: 6| Step: 2
Training loss: 0.3007960915565491
Validation loss: 1.581304415579765

Epoch: 6| Step: 3
Training loss: 0.3591901659965515
Validation loss: 1.5820128328056746

Epoch: 6| Step: 4
Training loss: 0.26324355602264404
Validation loss: 1.5582311025229834

Epoch: 6| Step: 5
Training loss: 0.28547096252441406
Validation loss: 1.578386055525913

Epoch: 6| Step: 6
Training loss: 0.21008095145225525
Validation loss: 1.6091537539676954

Epoch: 6| Step: 7
Training loss: 0.20436310768127441
Validation loss: 1.6080699313071467

Epoch: 6| Step: 8
Training loss: 0.24489377439022064
Validation loss: 1.6468701516428301

Epoch: 6| Step: 9
Training loss: 0.32131898403167725
Validation loss: 1.6431633862116004

Epoch: 6| Step: 10
Training loss: 0.31394898891448975
Validation loss: 1.6387232708674606

Epoch: 6| Step: 11
Training loss: 0.3941177725791931
Validation loss: 1.5992888827477731

Epoch: 6| Step: 12
Training loss: 0.24330337345600128
Validation loss: 1.5633628201741043

Epoch: 6| Step: 13
Training loss: 0.2754257023334503
Validation loss: 1.5514374048479143

Epoch: 266| Step: 0
Training loss: 0.2831033766269684
Validation loss: 1.5453334328948811

Epoch: 6| Step: 1
Training loss: 0.30945831537246704
Validation loss: 1.5043789853331864

Epoch: 6| Step: 2
Training loss: 0.2207109034061432
Validation loss: 1.5257095906042284

Epoch: 6| Step: 3
Training loss: 0.3753833770751953
Validation loss: 1.498616010912003

Epoch: 6| Step: 4
Training loss: 0.3666563034057617
Validation loss: 1.519782022763324

Epoch: 6| Step: 5
Training loss: 0.3241722583770752
Validation loss: 1.5337268870363954

Epoch: 6| Step: 6
Training loss: 0.2955999970436096
Validation loss: 1.5834494611268402

Epoch: 6| Step: 7
Training loss: 0.3440335988998413
Validation loss: 1.573996743848247

Epoch: 6| Step: 8
Training loss: 0.26033923029899597
Validation loss: 1.5992919450165124

Epoch: 6| Step: 9
Training loss: 0.3956422805786133
Validation loss: 1.6262590603161884

Epoch: 6| Step: 10
Training loss: 0.284409761428833
Validation loss: 1.6590584170433782

Epoch: 6| Step: 11
Training loss: 0.31634998321533203
Validation loss: 1.654476337535407

Epoch: 6| Step: 12
Training loss: 0.33898618817329407
Validation loss: 1.6277157157979987

Epoch: 6| Step: 13
Training loss: 0.34739750623703003
Validation loss: 1.5950389856933265

Epoch: 267| Step: 0
Training loss: 0.30923229455947876
Validation loss: 1.5452708396860348

Epoch: 6| Step: 1
Training loss: 0.38542670011520386
Validation loss: 1.5751425809757684

Epoch: 6| Step: 2
Training loss: 0.32644715905189514
Validation loss: 1.5613629779508036

Epoch: 6| Step: 3
Training loss: 0.3113635778427124
Validation loss: 1.5980806748072307

Epoch: 6| Step: 4
Training loss: 0.24988049268722534
Validation loss: 1.5890592785291775

Epoch: 6| Step: 5
Training loss: 0.23252706229686737
Validation loss: 1.6012847385098856

Epoch: 6| Step: 6
Training loss: 0.29063206911087036
Validation loss: 1.5867177747911023

Epoch: 6| Step: 7
Training loss: 0.35850268602371216
Validation loss: 1.601128674322559

Epoch: 6| Step: 8
Training loss: 0.47766655683517456
Validation loss: 1.6197999972169117

Epoch: 6| Step: 9
Training loss: 0.3003762364387512
Validation loss: 1.621289635217318

Epoch: 6| Step: 10
Training loss: 0.18962335586547852
Validation loss: 1.634566177604019

Epoch: 6| Step: 11
Training loss: 0.4050425887107849
Validation loss: 1.6488318827844435

Epoch: 6| Step: 12
Training loss: 0.2629024386405945
Validation loss: 1.6764891173249932

Epoch: 6| Step: 13
Training loss: 0.3045695722103119
Validation loss: 1.6654610313395017

Epoch: 268| Step: 0
Training loss: 0.44232991337776184
Validation loss: 1.6401715765717209

Epoch: 6| Step: 1
Training loss: 0.2569475471973419
Validation loss: 1.636076214492962

Epoch: 6| Step: 2
Training loss: 0.10437708348035812
Validation loss: 1.6626227260917745

Epoch: 6| Step: 3
Training loss: 0.33081483840942383
Validation loss: 1.6088289240355134

Epoch: 6| Step: 4
Training loss: 0.21668028831481934
Validation loss: 1.592022850949277

Epoch: 6| Step: 5
Training loss: 0.5497214794158936
Validation loss: 1.5320940389428088

Epoch: 6| Step: 6
Training loss: 0.2508956789970398
Validation loss: 1.526868631762843

Epoch: 6| Step: 7
Training loss: 0.23562797904014587
Validation loss: 1.5158353415868615

Epoch: 6| Step: 8
Training loss: 0.2900834381580353
Validation loss: 1.4955437542289816

Epoch: 6| Step: 9
Training loss: 0.34736186265945435
Validation loss: 1.4995600049213698

Epoch: 6| Step: 10
Training loss: 0.2918684482574463
Validation loss: 1.5474379485653293

Epoch: 6| Step: 11
Training loss: 0.2329217940568924
Validation loss: 1.557730729861926

Epoch: 6| Step: 12
Training loss: 0.23218432068824768
Validation loss: 1.5459533596551547

Epoch: 6| Step: 13
Training loss: 0.2832202911376953
Validation loss: 1.531630583988723

Epoch: 269| Step: 0
Training loss: 0.3126184940338135
Validation loss: 1.5401767056475404

Epoch: 6| Step: 1
Training loss: 0.2343050241470337
Validation loss: 1.5171229877779562

Epoch: 6| Step: 2
Training loss: 0.26856744289398193
Validation loss: 1.5490130506536013

Epoch: 6| Step: 3
Training loss: 0.26310837268829346
Validation loss: 1.5452334688555809

Epoch: 6| Step: 4
Training loss: 0.2578483521938324
Validation loss: 1.5791684619842037

Epoch: 6| Step: 5
Training loss: 0.3149067163467407
Validation loss: 1.5959889581126552

Epoch: 6| Step: 6
Training loss: 0.36269161105155945
Validation loss: 1.5957513432348929

Epoch: 6| Step: 7
Training loss: 0.3746589422225952
Validation loss: 1.5731087602594847

Epoch: 6| Step: 8
Training loss: 0.2394309937953949
Validation loss: 1.5766703274942213

Epoch: 6| Step: 9
Training loss: 0.2084657847881317
Validation loss: 1.5385202464237009

Epoch: 6| Step: 10
Training loss: 0.31314000487327576
Validation loss: 1.5347896827164518

Epoch: 6| Step: 11
Training loss: 0.14315149188041687
Validation loss: 1.5145263928239063

Epoch: 6| Step: 12
Training loss: 0.3910103142261505
Validation loss: 1.5090149999946676

Epoch: 6| Step: 13
Training loss: 0.2147165685892105
Validation loss: 1.5093932677340764

Epoch: 270| Step: 0
Training loss: 0.2104969620704651
Validation loss: 1.5032212580403974

Epoch: 6| Step: 1
Training loss: 0.3009033203125
Validation loss: 1.5511891021523425

Epoch: 6| Step: 2
Training loss: 0.2090752273797989
Validation loss: 1.555842775170521

Epoch: 6| Step: 3
Training loss: 0.3018432855606079
Validation loss: 1.5584882920788181

Epoch: 6| Step: 4
Training loss: 0.1620582789182663
Validation loss: 1.5699205975378714

Epoch: 6| Step: 5
Training loss: 0.3781827688217163
Validation loss: 1.558688179139168

Epoch: 6| Step: 6
Training loss: 0.16161590814590454
Validation loss: 1.5770174175180414

Epoch: 6| Step: 7
Training loss: 0.3871510922908783
Validation loss: 1.5797589132862706

Epoch: 6| Step: 8
Training loss: 0.3800702691078186
Validation loss: 1.5790907939275105

Epoch: 6| Step: 9
Training loss: 0.20411080121994019
Validation loss: 1.5743823500089749

Epoch: 6| Step: 10
Training loss: 0.2574867904186249
Validation loss: 1.5461352961037749

Epoch: 6| Step: 11
Training loss: 0.3558022379875183
Validation loss: 1.5507324793005501

Epoch: 6| Step: 12
Training loss: 0.3298705816268921
Validation loss: 1.559718652438092

Epoch: 6| Step: 13
Training loss: 0.1569739729166031
Validation loss: 1.5716629656412269

Epoch: 271| Step: 0
Training loss: 0.42942720651626587
Validation loss: 1.573139033009929

Epoch: 6| Step: 1
Training loss: 0.3101547360420227
Validation loss: 1.568857349375243

Epoch: 6| Step: 2
Training loss: 0.14230190217494965
Validation loss: 1.5633789864919518

Epoch: 6| Step: 3
Training loss: 0.3500003218650818
Validation loss: 1.5436417928306005

Epoch: 6| Step: 4
Training loss: 0.2054869532585144
Validation loss: 1.5505542838445274

Epoch: 6| Step: 5
Training loss: 0.30809128284454346
Validation loss: 1.5702213497572048

Epoch: 6| Step: 6
Training loss: 0.31592899560928345
Validation loss: 1.555044238926262

Epoch: 6| Step: 7
Training loss: 0.25893455743789673
Validation loss: 1.5420062772689327

Epoch: 6| Step: 8
Training loss: 0.24005991220474243
Validation loss: 1.5283217417296542

Epoch: 6| Step: 9
Training loss: 0.3093913793563843
Validation loss: 1.5431376618723716

Epoch: 6| Step: 10
Training loss: 0.28473737835884094
Validation loss: 1.5462083226890975

Epoch: 6| Step: 11
Training loss: 0.25196146965026855
Validation loss: 1.5653571518518592

Epoch: 6| Step: 12
Training loss: 0.16426494717597961
Validation loss: 1.5823762275839364

Epoch: 6| Step: 13
Training loss: 0.23864299058914185
Validation loss: 1.6051358029406557

Epoch: 272| Step: 0
Training loss: 0.22490978240966797
Validation loss: 1.6231613723180627

Epoch: 6| Step: 1
Training loss: 0.30718767642974854
Validation loss: 1.6094587156849522

Epoch: 6| Step: 2
Training loss: 0.2337692528963089
Validation loss: 1.644268007688625

Epoch: 6| Step: 3
Training loss: 0.33921223878860474
Validation loss: 1.5953536289994434

Epoch: 6| Step: 4
Training loss: 0.34375083446502686
Validation loss: 1.6031453263375066

Epoch: 6| Step: 5
Training loss: 0.3291018009185791
Validation loss: 1.5691107857611872

Epoch: 6| Step: 6
Training loss: 0.22365298867225647
Validation loss: 1.569098812277599

Epoch: 6| Step: 7
Training loss: 0.2342091053724289
Validation loss: 1.5732215719838296

Epoch: 6| Step: 8
Training loss: 0.23887041211128235
Validation loss: 1.558825203167495

Epoch: 6| Step: 9
Training loss: 0.302240788936615
Validation loss: 1.5272791539469073

Epoch: 6| Step: 10
Training loss: 0.2799195349216461
Validation loss: 1.5395925929469447

Epoch: 6| Step: 11
Training loss: 0.27607864141464233
Validation loss: 1.531633738548525

Epoch: 6| Step: 12
Training loss: 0.3162561357021332
Validation loss: 1.5412487150520406

Epoch: 6| Step: 13
Training loss: 0.16974303126335144
Validation loss: 1.5284775085346674

Epoch: 273| Step: 0
Training loss: 0.17918898165225983
Validation loss: 1.550514933883503

Epoch: 6| Step: 1
Training loss: 0.24627506732940674
Validation loss: 1.5636338546711912

Epoch: 6| Step: 2
Training loss: 0.2289254069328308
Validation loss: 1.5677203362987888

Epoch: 6| Step: 3
Training loss: 0.21237623691558838
Validation loss: 1.5577254192803496

Epoch: 6| Step: 4
Training loss: 0.28240811824798584
Validation loss: 1.6236988511136783

Epoch: 6| Step: 5
Training loss: 0.29145991802215576
Validation loss: 1.5901817352541032

Epoch: 6| Step: 6
Training loss: 0.13876378536224365
Validation loss: 1.5779080980567521

Epoch: 6| Step: 7
Training loss: 0.301864355802536
Validation loss: 1.5861330339985509

Epoch: 6| Step: 8
Training loss: 0.26590776443481445
Validation loss: 1.571869525858151

Epoch: 6| Step: 9
Training loss: 0.2174406349658966
Validation loss: 1.5595510762224916

Epoch: 6| Step: 10
Training loss: 0.31317511200904846
Validation loss: 1.5453960062355123

Epoch: 6| Step: 11
Training loss: 0.31357693672180176
Validation loss: 1.5710214466177008

Epoch: 6| Step: 12
Training loss: 0.2416844367980957
Validation loss: 1.585755951942936

Epoch: 6| Step: 13
Training loss: 0.3265855610370636
Validation loss: 1.575660788884727

Epoch: 274| Step: 0
Training loss: 0.32394155859947205
Validation loss: 1.55716844015224

Epoch: 6| Step: 1
Training loss: 0.276531845331192
Validation loss: 1.5592108452191917

Epoch: 6| Step: 2
Training loss: 0.176249161362648
Validation loss: 1.5861146815361515

Epoch: 6| Step: 3
Training loss: 0.1782921850681305
Validation loss: 1.5862599701009772

Epoch: 6| Step: 4
Training loss: 0.1328403353691101
Validation loss: 1.6223894088499007

Epoch: 6| Step: 5
Training loss: 0.3479878306388855
Validation loss: 1.6368671796655143

Epoch: 6| Step: 6
Training loss: 0.18018293380737305
Validation loss: 1.6333974343474194

Epoch: 6| Step: 7
Training loss: 0.19964534044265747
Validation loss: 1.6257096016278831

Epoch: 6| Step: 8
Training loss: 0.3201242685317993
Validation loss: 1.5739924548774638

Epoch: 6| Step: 9
Training loss: 0.2954849600791931
Validation loss: 1.5289612970044535

Epoch: 6| Step: 10
Training loss: 0.2758026421070099
Validation loss: 1.480513661138473

Epoch: 6| Step: 11
Training loss: 0.1326727271080017
Validation loss: 1.5250786985120466

Epoch: 6| Step: 12
Training loss: 0.3279627561569214
Validation loss: 1.5305327856412498

Epoch: 6| Step: 13
Training loss: 0.3947102725505829
Validation loss: 1.5441592816383607

Epoch: 275| Step: 0
Training loss: 0.14179351925849915
Validation loss: 1.5303942990559403

Epoch: 6| Step: 1
Training loss: 0.3121629059314728
Validation loss: 1.5577471589529386

Epoch: 6| Step: 2
Training loss: 0.28761371970176697
Validation loss: 1.5204433651380642

Epoch: 6| Step: 3
Training loss: 0.27079129219055176
Validation loss: 1.5190649776048557

Epoch: 6| Step: 4
Training loss: 0.23604431748390198
Validation loss: 1.5143921362456454

Epoch: 6| Step: 5
Training loss: 0.20461082458496094
Validation loss: 1.5045531001142276

Epoch: 6| Step: 6
Training loss: 0.3244817852973938
Validation loss: 1.5121907687956286

Epoch: 6| Step: 7
Training loss: 0.1702088713645935
Validation loss: 1.498786428923248

Epoch: 6| Step: 8
Training loss: 0.3923262357711792
Validation loss: 1.522806276557266

Epoch: 6| Step: 9
Training loss: 0.2702929973602295
Validation loss: 1.5495902620336062

Epoch: 6| Step: 10
Training loss: 0.26127171516418457
Validation loss: 1.5227513723475958

Epoch: 6| Step: 11
Training loss: 0.21859420835971832
Validation loss: 1.5556972334461827

Epoch: 6| Step: 12
Training loss: 0.20189884305000305
Validation loss: 1.567956498874131

Epoch: 6| Step: 13
Training loss: 0.20392867922782898
Validation loss: 1.5824103880954046

Epoch: 276| Step: 0
Training loss: 0.3650505840778351
Validation loss: 1.6215769731870262

Epoch: 6| Step: 1
Training loss: 0.3357313275337219
Validation loss: 1.610714151013282

Epoch: 6| Step: 2
Training loss: 0.14966672658920288
Validation loss: 1.6399116759659143

Epoch: 6| Step: 3
Training loss: 0.1701694130897522
Validation loss: 1.6465333918089509

Epoch: 6| Step: 4
Training loss: 0.33059048652648926
Validation loss: 1.593036243992467

Epoch: 6| Step: 5
Training loss: 0.2511177659034729
Validation loss: 1.5686372057084115

Epoch: 6| Step: 6
Training loss: 0.2690615653991699
Validation loss: 1.5278723611626575

Epoch: 6| Step: 7
Training loss: 0.110007144510746
Validation loss: 1.5530969007040865

Epoch: 6| Step: 8
Training loss: 0.27134570479393005
Validation loss: 1.5205371841307609

Epoch: 6| Step: 9
Training loss: 0.13696160912513733
Validation loss: 1.4882617426174942

Epoch: 6| Step: 10
Training loss: 0.26907631754875183
Validation loss: 1.5084343725635159

Epoch: 6| Step: 11
Training loss: 0.3327632546424866
Validation loss: 1.5312508921469412

Epoch: 6| Step: 12
Training loss: 0.32818078994750977
Validation loss: 1.5421435217703543

Epoch: 6| Step: 13
Training loss: 0.2993963956832886
Validation loss: 1.5389162827563543

Epoch: 277| Step: 0
Training loss: 0.14606517553329468
Validation loss: 1.5750348042416316

Epoch: 6| Step: 1
Training loss: 0.12121665477752686
Validation loss: 1.5893504311961513

Epoch: 6| Step: 2
Training loss: 0.16232258081436157
Validation loss: 1.5961605348894674

Epoch: 6| Step: 3
Training loss: 0.28145819902420044
Validation loss: 1.5666674606261715

Epoch: 6| Step: 4
Training loss: 0.3890741169452667
Validation loss: 1.5663136756548317

Epoch: 6| Step: 5
Training loss: 0.28731727600097656
Validation loss: 1.5519413319967126

Epoch: 6| Step: 6
Training loss: 0.07976314425468445
Validation loss: 1.5374086467168664

Epoch: 6| Step: 7
Training loss: 0.3748282194137573
Validation loss: 1.5347566643068868

Epoch: 6| Step: 8
Training loss: 0.21005703508853912
Validation loss: 1.56338789386134

Epoch: 6| Step: 9
Training loss: 0.34217461943626404
Validation loss: 1.574466537403804

Epoch: 6| Step: 10
Training loss: 0.3175339996814728
Validation loss: 1.5999811503194994

Epoch: 6| Step: 11
Training loss: 0.2799602448940277
Validation loss: 1.6432251109871814

Epoch: 6| Step: 12
Training loss: 0.2337237149477005
Validation loss: 1.6794170525766188

Epoch: 6| Step: 13
Training loss: 0.31934845447540283
Validation loss: 1.6543343631170129

Epoch: 278| Step: 0
Training loss: 0.22867842018604279
Validation loss: 1.6440983613332112

Epoch: 6| Step: 1
Training loss: 0.3926756978034973
Validation loss: 1.6412553300139725

Epoch: 6| Step: 2
Training loss: 0.16299375891685486
Validation loss: 1.611663915777719

Epoch: 6| Step: 3
Training loss: 0.32433974742889404
Validation loss: 1.5845310380381923

Epoch: 6| Step: 4
Training loss: 0.13789620995521545
Validation loss: 1.5661722434464322

Epoch: 6| Step: 5
Training loss: 0.2561129927635193
Validation loss: 1.501729433254529

Epoch: 6| Step: 6
Training loss: 0.23458051681518555
Validation loss: 1.4909969452888734

Epoch: 6| Step: 7
Training loss: 0.30468663573265076
Validation loss: 1.5022485794559601

Epoch: 6| Step: 8
Training loss: 0.25157222151756287
Validation loss: 1.5045415996223368

Epoch: 6| Step: 9
Training loss: 0.34859180450439453
Validation loss: 1.519230172198306

Epoch: 6| Step: 10
Training loss: 0.3566894829273224
Validation loss: 1.5142390830542451

Epoch: 6| Step: 11
Training loss: 0.35515183210372925
Validation loss: 1.4983782857976935

Epoch: 6| Step: 12
Training loss: 0.36356037855148315
Validation loss: 1.528482476870219

Epoch: 6| Step: 13
Training loss: 0.2909368872642517
Validation loss: 1.5012581329191885

Epoch: 279| Step: 0
Training loss: 0.45062771439552307
Validation loss: 1.5229321218306018

Epoch: 6| Step: 1
Training loss: 0.1837492138147354
Validation loss: 1.552195519529363

Epoch: 6| Step: 2
Training loss: 0.22254565358161926
Validation loss: 1.5605327813856062

Epoch: 6| Step: 3
Training loss: 0.18747863173484802
Validation loss: 1.5879486696694487

Epoch: 6| Step: 4
Training loss: 0.2248418629169464
Validation loss: 1.5883866253719534

Epoch: 6| Step: 5
Training loss: 0.18878242373466492
Validation loss: 1.5815277432882657

Epoch: 6| Step: 6
Training loss: 0.3128223717212677
Validation loss: 1.5714193396670844

Epoch: 6| Step: 7
Training loss: 0.22453245520591736
Validation loss: 1.578165066498582

Epoch: 6| Step: 8
Training loss: 0.22667285799980164
Validation loss: 1.5433191330202165

Epoch: 6| Step: 9
Training loss: 0.3853187561035156
Validation loss: 1.5023871467959495

Epoch: 6| Step: 10
Training loss: 0.21132603287696838
Validation loss: 1.4839607182369436

Epoch: 6| Step: 11
Training loss: 0.2730993330478668
Validation loss: 1.4643139236716813

Epoch: 6| Step: 12
Training loss: 0.22116154432296753
Validation loss: 1.4576633104714014

Epoch: 6| Step: 13
Training loss: 0.31961119174957275
Validation loss: 1.4720295065192766

Epoch: 280| Step: 0
Training loss: 0.22372104227542877
Validation loss: 1.4883553366507254

Epoch: 6| Step: 1
Training loss: 0.28979185223579407
Validation loss: 1.4967857560803812

Epoch: 6| Step: 2
Training loss: 0.21205157041549683
Validation loss: 1.5217043020391976

Epoch: 6| Step: 3
Training loss: 0.16754257678985596
Validation loss: 1.555192228286497

Epoch: 6| Step: 4
Training loss: 0.20095282793045044
Validation loss: 1.5932989633211525

Epoch: 6| Step: 5
Training loss: 0.32360148429870605
Validation loss: 1.5781031590636059

Epoch: 6| Step: 6
Training loss: 0.32099640369415283
Validation loss: 1.6379452392619143

Epoch: 6| Step: 7
Training loss: 0.3905166983604431
Validation loss: 1.6331186268919258

Epoch: 6| Step: 8
Training loss: 0.1766589730978012
Validation loss: 1.580476559618468

Epoch: 6| Step: 9
Training loss: 0.21112048625946045
Validation loss: 1.5904750567610546

Epoch: 6| Step: 10
Training loss: 0.24288834631443024
Validation loss: 1.5960876352043563

Epoch: 6| Step: 11
Training loss: 0.2385205328464508
Validation loss: 1.559279634747454

Epoch: 6| Step: 12
Training loss: 0.3201509714126587
Validation loss: 1.5277166020485662

Epoch: 6| Step: 13
Training loss: 0.30059152841567993
Validation loss: 1.5093876059337328

Epoch: 281| Step: 0
Training loss: 0.2653349041938782
Validation loss: 1.537844004169587

Epoch: 6| Step: 1
Training loss: 0.1410985291004181
Validation loss: 1.5383481344869059

Epoch: 6| Step: 2
Training loss: 0.3125882148742676
Validation loss: 1.5482226289728636

Epoch: 6| Step: 3
Training loss: 0.2358628660440445
Validation loss: 1.5197840121484572

Epoch: 6| Step: 4
Training loss: 0.2650297284126282
Validation loss: 1.545855083773213

Epoch: 6| Step: 5
Training loss: 0.35964691638946533
Validation loss: 1.5556971770460888

Epoch: 6| Step: 6
Training loss: 0.2575215697288513
Validation loss: 1.5590517418358916

Epoch: 6| Step: 7
Training loss: 0.4097982943058014
Validation loss: 1.5455359720414685

Epoch: 6| Step: 8
Training loss: 0.179618239402771
Validation loss: 1.5359483380471506

Epoch: 6| Step: 9
Training loss: 0.19099470973014832
Validation loss: 1.5298716573305027

Epoch: 6| Step: 10
Training loss: 0.2016216218471527
Validation loss: 1.5281934712522773

Epoch: 6| Step: 11
Training loss: 0.19205984473228455
Validation loss: 1.529168974968695

Epoch: 6| Step: 12
Training loss: 0.26488202810287476
Validation loss: 1.5595089235613424

Epoch: 6| Step: 13
Training loss: 0.30494412779808044
Validation loss: 1.5361551636008806

Epoch: 282| Step: 0
Training loss: 0.20756036043167114
Validation loss: 1.5326561056157595

Epoch: 6| Step: 1
Training loss: 0.1941165179014206
Validation loss: 1.4960555056089997

Epoch: 6| Step: 2
Training loss: 0.3556872606277466
Validation loss: 1.4915005481371315

Epoch: 6| Step: 3
Training loss: 0.30121910572052
Validation loss: 1.5081098771864367

Epoch: 6| Step: 4
Training loss: 0.3006427586078644
Validation loss: 1.5311471916014148

Epoch: 6| Step: 5
Training loss: 0.27238819003105164
Validation loss: 1.4879261370628112

Epoch: 6| Step: 6
Training loss: 0.33350932598114014
Validation loss: 1.5123176446525

Epoch: 6| Step: 7
Training loss: 0.41410061717033386
Validation loss: 1.5173720031656244

Epoch: 6| Step: 8
Training loss: 0.1721532642841339
Validation loss: 1.5027454348020657

Epoch: 6| Step: 9
Training loss: 0.221865713596344
Validation loss: 1.5103150535655279

Epoch: 6| Step: 10
Training loss: 0.2484743744134903
Validation loss: 1.5339771842443815

Epoch: 6| Step: 11
Training loss: 0.2214374989271164
Validation loss: 1.5445718380712694

Epoch: 6| Step: 12
Training loss: 0.24543999135494232
Validation loss: 1.5547080309160295

Epoch: 6| Step: 13
Training loss: 0.2917373478412628
Validation loss: 1.5979746746760544

Epoch: 283| Step: 0
Training loss: 0.2119571566581726
Validation loss: 1.5667381286621094

Epoch: 6| Step: 1
Training loss: 0.14232781529426575
Validation loss: 1.5793597595666045

Epoch: 6| Step: 2
Training loss: 0.1341857761144638
Validation loss: 1.5803801077668385

Epoch: 6| Step: 3
Training loss: 0.3293225169181824
Validation loss: 1.5619977949767985

Epoch: 6| Step: 4
Training loss: 0.24064303934574127
Validation loss: 1.5686124986217869

Epoch: 6| Step: 5
Training loss: 0.23239240050315857
Validation loss: 1.5550890955873715

Epoch: 6| Step: 6
Training loss: 0.36090534925460815
Validation loss: 1.5363344530905447

Epoch: 6| Step: 7
Training loss: 0.20120933651924133
Validation loss: 1.5062384438771073

Epoch: 6| Step: 8
Training loss: 0.3160596787929535
Validation loss: 1.517304620435161

Epoch: 6| Step: 9
Training loss: 0.3438868522644043
Validation loss: 1.5306182574200373

Epoch: 6| Step: 10
Training loss: 0.20712798833847046
Validation loss: 1.5123193264007568

Epoch: 6| Step: 11
Training loss: 0.14827078580856323
Validation loss: 1.5073030674329368

Epoch: 6| Step: 12
Training loss: 0.24208137392997742
Validation loss: 1.5522160273726269

Epoch: 6| Step: 13
Training loss: 0.18725064396858215
Validation loss: 1.549878199895223

Epoch: 284| Step: 0
Training loss: 0.12497129291296005
Validation loss: 1.572276730691233

Epoch: 6| Step: 1
Training loss: 0.27338555455207825
Validation loss: 1.599768691165473

Epoch: 6| Step: 2
Training loss: 0.3198726177215576
Validation loss: 1.6149230772449124

Epoch: 6| Step: 3
Training loss: 0.19757500290870667
Validation loss: 1.6249883892715618

Epoch: 6| Step: 4
Training loss: 0.24824240803718567
Validation loss: 1.626788862289921

Epoch: 6| Step: 5
Training loss: 0.19715873897075653
Validation loss: 1.6419479603408484

Epoch: 6| Step: 6
Training loss: 0.21022099256515503
Validation loss: 1.6199065164853168

Epoch: 6| Step: 7
Training loss: 0.3772999048233032
Validation loss: 1.586462579747682

Epoch: 6| Step: 8
Training loss: 0.29171836376190186
Validation loss: 1.6024726539529779

Epoch: 6| Step: 9
Training loss: 0.22174623608589172
Validation loss: 1.5698203348344373

Epoch: 6| Step: 10
Training loss: 0.24395312368869781
Validation loss: 1.562278139975763

Epoch: 6| Step: 11
Training loss: 0.24455678462982178
Validation loss: 1.5733396660897039

Epoch: 6| Step: 12
Training loss: 0.31689250469207764
Validation loss: 1.5504179295673166

Epoch: 6| Step: 13
Training loss: 0.2910460829734802
Validation loss: 1.6151977559571624

Epoch: 285| Step: 0
Training loss: 0.3263511657714844
Validation loss: 1.596555995043888

Epoch: 6| Step: 1
Training loss: 0.24987247586250305
Validation loss: 1.6146332076800767

Epoch: 6| Step: 2
Training loss: 0.3298737704753876
Validation loss: 1.6099516089244554

Epoch: 6| Step: 3
Training loss: 0.18079307675361633
Validation loss: 1.562516075308605

Epoch: 6| Step: 4
Training loss: 0.23425903916358948
Validation loss: 1.5683415897430912

Epoch: 6| Step: 5
Training loss: 0.15141460299491882
Validation loss: 1.5459279770492225

Epoch: 6| Step: 6
Training loss: 0.2209976762533188
Validation loss: 1.5436825688167284

Epoch: 6| Step: 7
Training loss: 0.19456587731838226
Validation loss: 1.539304917858493

Epoch: 6| Step: 8
Training loss: 0.27304503321647644
Validation loss: 1.541177353551311

Epoch: 6| Step: 9
Training loss: 0.20726105570793152
Validation loss: 1.5928140827404556

Epoch: 6| Step: 10
Training loss: 0.28690218925476074
Validation loss: 1.653428799362593

Epoch: 6| Step: 11
Training loss: 0.3046284019947052
Validation loss: 1.6714039810242192

Epoch: 6| Step: 12
Training loss: 0.21684932708740234
Validation loss: 1.6568549679171654

Epoch: 6| Step: 13
Training loss: 0.28234583139419556
Validation loss: 1.6712432446018342

Epoch: 286| Step: 0
Training loss: 0.2526758015155792
Validation loss: 1.654486188324549

Epoch: 6| Step: 1
Training loss: 0.1756630837917328
Validation loss: 1.6094549516195893

Epoch: 6| Step: 2
Training loss: 0.22421756386756897
Validation loss: 1.598890107806011

Epoch: 6| Step: 3
Training loss: 0.39763057231903076
Validation loss: 1.5435534677197855

Epoch: 6| Step: 4
Training loss: 0.15444162487983704
Validation loss: 1.5039303507856143

Epoch: 6| Step: 5
Training loss: 0.19819815456867218
Validation loss: 1.5129781102621427

Epoch: 6| Step: 6
Training loss: 0.25561895966529846
Validation loss: 1.4629366602948917

Epoch: 6| Step: 7
Training loss: 0.43303370475769043
Validation loss: 1.4823290891544794

Epoch: 6| Step: 8
Training loss: 0.2822762727737427
Validation loss: 1.4747736595010246

Epoch: 6| Step: 9
Training loss: 0.13359417021274567
Validation loss: 1.4570605351078896

Epoch: 6| Step: 10
Training loss: 0.24502375721931458
Validation loss: 1.4760686018133675

Epoch: 6| Step: 11
Training loss: 0.2605038285255432
Validation loss: 1.471810443426973

Epoch: 6| Step: 12
Training loss: 0.16670355200767517
Validation loss: 1.497486287547696

Epoch: 6| Step: 13
Training loss: 0.3752707540988922
Validation loss: 1.527174461272455

Epoch: 287| Step: 0
Training loss: 0.2384367287158966
Validation loss: 1.6056153646079443

Epoch: 6| Step: 1
Training loss: 0.22317329049110413
Validation loss: 1.6056526924974175

Epoch: 6| Step: 2
Training loss: 0.29160231351852417
Validation loss: 1.6148063623777

Epoch: 6| Step: 3
Training loss: 0.3419993817806244
Validation loss: 1.600020876494787

Epoch: 6| Step: 4
Training loss: 0.46602997183799744
Validation loss: 1.5617974253110989

Epoch: 6| Step: 5
Training loss: 0.31983035802841187
Validation loss: 1.5653083426977998

Epoch: 6| Step: 6
Training loss: 0.24000990390777588
Validation loss: 1.5248108486975394

Epoch: 6| Step: 7
Training loss: 0.21361948549747467
Validation loss: 1.4992107646439665

Epoch: 6| Step: 8
Training loss: 0.26123130321502686
Validation loss: 1.498790922985282

Epoch: 6| Step: 9
Training loss: 0.170741468667984
Validation loss: 1.531689037558853

Epoch: 6| Step: 10
Training loss: 0.26738402247428894
Validation loss: 1.5275724600720149

Epoch: 6| Step: 11
Training loss: 0.1617274284362793
Validation loss: 1.5549900506132392

Epoch: 6| Step: 12
Training loss: 0.13347738981246948
Validation loss: 1.5705084826356621

Epoch: 6| Step: 13
Training loss: 0.3045716881752014
Validation loss: 1.589531801080191

Epoch: 288| Step: 0
Training loss: 0.138951376080513
Validation loss: 1.5642294806818808

Epoch: 6| Step: 1
Training loss: 0.18298156559467316
Validation loss: 1.5820089001809396

Epoch: 6| Step: 2
Training loss: 0.2003466784954071
Validation loss: 1.5878038470463087

Epoch: 6| Step: 3
Training loss: 0.25883030891418457
Validation loss: 1.586341804073703

Epoch: 6| Step: 4
Training loss: 0.25479501485824585
Validation loss: 1.5968707069273917

Epoch: 6| Step: 5
Training loss: 0.3112794756889343
Validation loss: 1.5847403080232683

Epoch: 6| Step: 6
Training loss: 0.19254130125045776
Validation loss: 1.5295795599619548

Epoch: 6| Step: 7
Training loss: 0.19923199713230133
Validation loss: 1.5177239089883783

Epoch: 6| Step: 8
Training loss: 0.21964575350284576
Validation loss: 1.4783932098778345

Epoch: 6| Step: 9
Training loss: 0.21613749861717224
Validation loss: 1.4746059551033923

Epoch: 6| Step: 10
Training loss: 0.3284972310066223
Validation loss: 1.4736392254470496

Epoch: 6| Step: 11
Training loss: 0.467187762260437
Validation loss: 1.462075456496208

Epoch: 6| Step: 12
Training loss: 0.15329581499099731
Validation loss: 1.4801896425985521

Epoch: 6| Step: 13
Training loss: 0.24449321627616882
Validation loss: 1.4881452360460836

Epoch: 289| Step: 0
Training loss: 0.2053612768650055
Validation loss: 1.5213157899918095

Epoch: 6| Step: 1
Training loss: 0.2585793733596802
Validation loss: 1.5448936698257283

Epoch: 6| Step: 2
Training loss: 0.1588352620601654
Validation loss: 1.534443450230424

Epoch: 6| Step: 3
Training loss: 0.12086914479732513
Validation loss: 1.5805916940012286

Epoch: 6| Step: 4
Training loss: 0.19163069128990173
Validation loss: 1.6081137977620608

Epoch: 6| Step: 5
Training loss: 0.3370482921600342
Validation loss: 1.5990420669637702

Epoch: 6| Step: 6
Training loss: 0.38049042224884033
Validation loss: 1.5623643911013039

Epoch: 6| Step: 7
Training loss: 0.17259050905704498
Validation loss: 1.5595228627163877

Epoch: 6| Step: 8
Training loss: 0.21398955583572388
Validation loss: 1.5538179259146414

Epoch: 6| Step: 9
Training loss: 0.14023372530937195
Validation loss: 1.5557661940974574

Epoch: 6| Step: 10
Training loss: 0.239406019449234
Validation loss: 1.5644664636222265

Epoch: 6| Step: 11
Training loss: 0.20052959024906158
Validation loss: 1.5313038236351424

Epoch: 6| Step: 12
Training loss: 0.21272411942481995
Validation loss: 1.5520644290472871

Epoch: 6| Step: 13
Training loss: 0.23895566165447235
Validation loss: 1.516021736206547

Epoch: 290| Step: 0
Training loss: 0.21380004286766052
Validation loss: 1.5226522466187835

Epoch: 6| Step: 1
Training loss: 0.20322319865226746
Validation loss: 1.5470978880441317

Epoch: 6| Step: 2
Training loss: 0.1800527274608612
Validation loss: 1.5605790089535456

Epoch: 6| Step: 3
Training loss: 0.3245078921318054
Validation loss: 1.5577752141542331

Epoch: 6| Step: 4
Training loss: 0.3000825047492981
Validation loss: 1.5465960515442716

Epoch: 6| Step: 5
Training loss: 0.16451065242290497
Validation loss: 1.5327194185667141

Epoch: 6| Step: 6
Training loss: 0.26195260882377625
Validation loss: 1.5312168303356375

Epoch: 6| Step: 7
Training loss: 0.14271938800811768
Validation loss: 1.5347145231821204

Epoch: 6| Step: 8
Training loss: 0.19116583466529846
Validation loss: 1.5055409785239928

Epoch: 6| Step: 9
Training loss: 0.249776229262352
Validation loss: 1.49592173740428

Epoch: 6| Step: 10
Training loss: 0.21855682134628296
Validation loss: 1.5119208341003747

Epoch: 6| Step: 11
Training loss: 0.24759496748447418
Validation loss: 1.5373489664446922

Epoch: 6| Step: 12
Training loss: 0.20998114347457886
Validation loss: 1.5062933916686683

Epoch: 6| Step: 13
Training loss: 0.27923470735549927
Validation loss: 1.5328365000345374

Epoch: 291| Step: 0
Training loss: 0.23836618661880493
Validation loss: 1.4908407503558743

Epoch: 6| Step: 1
Training loss: 0.1268395036458969
Validation loss: 1.4866572605666293

Epoch: 6| Step: 2
Training loss: 0.21661053597927094
Validation loss: 1.5049127840226697

Epoch: 6| Step: 3
Training loss: 0.18947629630565643
Validation loss: 1.4887845323931785

Epoch: 6| Step: 4
Training loss: 0.21088318526744843
Validation loss: 1.4877827077783563

Epoch: 6| Step: 5
Training loss: 0.10605326294898987
Validation loss: 1.4913845485256565

Epoch: 6| Step: 6
Training loss: 0.3123493492603302
Validation loss: 1.5381996157348796

Epoch: 6| Step: 7
Training loss: 0.2871958613395691
Validation loss: 1.562414664094166

Epoch: 6| Step: 8
Training loss: 0.18042397499084473
Validation loss: 1.5798204316887805

Epoch: 6| Step: 9
Training loss: 0.23361742496490479
Validation loss: 1.5688602424437

Epoch: 6| Step: 10
Training loss: 0.17999529838562012
Validation loss: 1.5939764258682088

Epoch: 6| Step: 11
Training loss: 0.2145233005285263
Validation loss: 1.5682188926204559

Epoch: 6| Step: 12
Training loss: 0.22914394736289978
Validation loss: 1.5429698856928016

Epoch: 6| Step: 13
Training loss: 0.1972232609987259
Validation loss: 1.5341196342181134

Epoch: 292| Step: 0
Training loss: 0.257271409034729
Validation loss: 1.5453959793172858

Epoch: 6| Step: 1
Training loss: 0.2492629885673523
Validation loss: 1.5183430525564379

Epoch: 6| Step: 2
Training loss: 0.19570648670196533
Validation loss: 1.5397119637458556

Epoch: 6| Step: 3
Training loss: 0.21243605017662048
Validation loss: 1.5073072038671023

Epoch: 6| Step: 4
Training loss: 0.26756563782691956
Validation loss: 1.4786275663683492

Epoch: 6| Step: 5
Training loss: 0.24394188821315765
Validation loss: 1.5021428613252537

Epoch: 6| Step: 6
Training loss: 0.14182746410369873
Validation loss: 1.4832417445798074

Epoch: 6| Step: 7
Training loss: 0.16532109677791595
Validation loss: 1.511105747633083

Epoch: 6| Step: 8
Training loss: 0.1460351198911667
Validation loss: 1.4926351116549583

Epoch: 6| Step: 9
Training loss: 0.20683938264846802
Validation loss: 1.4885422619440223

Epoch: 6| Step: 10
Training loss: 0.13186047971248627
Validation loss: 1.5010977496383011

Epoch: 6| Step: 11
Training loss: 0.18265239894390106
Validation loss: 1.5158665962116693

Epoch: 6| Step: 12
Training loss: 0.2567101716995239
Validation loss: 1.5270637478879703

Epoch: 6| Step: 13
Training loss: 0.21317781507968903
Validation loss: 1.5567109661717569

Epoch: 293| Step: 0
Training loss: 0.1520281732082367
Validation loss: 1.5264034066148984

Epoch: 6| Step: 1
Training loss: 0.2108815312385559
Validation loss: 1.5188526466328611

Epoch: 6| Step: 2
Training loss: 0.21360036730766296
Validation loss: 1.5398360862526843

Epoch: 6| Step: 3
Training loss: 0.23743867874145508
Validation loss: 1.5056632257276965

Epoch: 6| Step: 4
Training loss: 0.3460697531700134
Validation loss: 1.5184295023641279

Epoch: 6| Step: 5
Training loss: 0.11877745389938354
Validation loss: 1.5436063440897132

Epoch: 6| Step: 6
Training loss: 0.2114928662776947
Validation loss: 1.570091805150432

Epoch: 6| Step: 7
Training loss: 0.19135907292366028
Validation loss: 1.5507042343898485

Epoch: 6| Step: 8
Training loss: 0.19829751551151276
Validation loss: 1.5251296733015327

Epoch: 6| Step: 9
Training loss: 0.28844475746154785
Validation loss: 1.4847696904213197

Epoch: 6| Step: 10
Training loss: 0.10753887891769409
Validation loss: 1.4964289883131623

Epoch: 6| Step: 11
Training loss: 0.29116082191467285
Validation loss: 1.5075212165873537

Epoch: 6| Step: 12
Training loss: 0.10153643041849136
Validation loss: 1.4849853336170156

Epoch: 6| Step: 13
Training loss: 0.1749333292245865
Validation loss: 1.510840021153932

Epoch: 294| Step: 0
Training loss: 0.16316381096839905
Validation loss: 1.4792458216349285

Epoch: 6| Step: 1
Training loss: 0.14891135692596436
Validation loss: 1.521313690370129

Epoch: 6| Step: 2
Training loss: 0.2898235321044922
Validation loss: 1.5387760208499046

Epoch: 6| Step: 3
Training loss: 0.23501896858215332
Validation loss: 1.5275750903673069

Epoch: 6| Step: 4
Training loss: 0.19797922670841217
Validation loss: 1.5796652955393637

Epoch: 6| Step: 5
Training loss: 0.20461449027061462
Validation loss: 1.6101692209961593

Epoch: 6| Step: 6
Training loss: 0.1478312909603119
Validation loss: 1.6068641831797938

Epoch: 6| Step: 7
Training loss: 0.17586475610733032
Validation loss: 1.610658038047052

Epoch: 6| Step: 8
Training loss: 0.323822021484375
Validation loss: 1.641684639838434

Epoch: 6| Step: 9
Training loss: 0.2724083960056305
Validation loss: 1.629806951809955

Epoch: 6| Step: 10
Training loss: 0.28897684812545776
Validation loss: 1.6209294372989285

Epoch: 6| Step: 11
Training loss: 0.2954959571361542
Validation loss: 1.5826658689847557

Epoch: 6| Step: 12
Training loss: 0.21099968254566193
Validation loss: 1.5440979414088751

Epoch: 6| Step: 13
Training loss: 0.16919609904289246
Validation loss: 1.523749787320373

Epoch: 295| Step: 0
Training loss: 0.21033388376235962
Validation loss: 1.5177738051260672

Epoch: 6| Step: 1
Training loss: 0.23075075447559357
Validation loss: 1.4700194257561878

Epoch: 6| Step: 2
Training loss: 0.227693572640419
Validation loss: 1.463765985222273

Epoch: 6| Step: 3
Training loss: 0.22217166423797607
Validation loss: 1.4738579014296174

Epoch: 6| Step: 4
Training loss: 0.3629905581474304
Validation loss: 1.4887850739622628

Epoch: 6| Step: 5
Training loss: 0.18258258700370789
Validation loss: 1.5051521101305563

Epoch: 6| Step: 6
Training loss: 0.26675522327423096
Validation loss: 1.496233000550219

Epoch: 6| Step: 7
Training loss: 0.20569530129432678
Validation loss: 1.4899384501159831

Epoch: 6| Step: 8
Training loss: 0.057963885366916656
Validation loss: 1.5147019227345784

Epoch: 6| Step: 9
Training loss: 0.4075477719306946
Validation loss: 1.5544100448649416

Epoch: 6| Step: 10
Training loss: 0.1587587296962738
Validation loss: 1.5183597726206626

Epoch: 6| Step: 11
Training loss: 0.17023663222789764
Validation loss: 1.5175105089782386

Epoch: 6| Step: 12
Training loss: 0.28139856457710266
Validation loss: 1.5558415266775316

Epoch: 6| Step: 13
Training loss: 0.20303313434123993
Validation loss: 1.5462091327995382

Epoch: 296| Step: 0
Training loss: 0.17864051461219788
Validation loss: 1.5235018140526229

Epoch: 6| Step: 1
Training loss: 0.11923427879810333
Validation loss: 1.5028180717140116

Epoch: 6| Step: 2
Training loss: 0.11165568232536316
Validation loss: 1.5567215258075344

Epoch: 6| Step: 3
Training loss: 0.1669611930847168
Validation loss: 1.5011448860168457

Epoch: 6| Step: 4
Training loss: 0.19848313927650452
Validation loss: 1.4865571683452976

Epoch: 6| Step: 5
Training loss: 0.20810219645500183
Validation loss: 1.5028269803652199

Epoch: 6| Step: 6
Training loss: 0.3285212516784668
Validation loss: 1.5011792541832052

Epoch: 6| Step: 7
Training loss: 0.2363150715827942
Validation loss: 1.514174428678328

Epoch: 6| Step: 8
Training loss: 0.27660220861434937
Validation loss: 1.5247182551250662

Epoch: 6| Step: 9
Training loss: 0.15525099635124207
Validation loss: 1.5238708193584154

Epoch: 6| Step: 10
Training loss: 0.35245734453201294
Validation loss: 1.5313385609657533

Epoch: 6| Step: 11
Training loss: 0.18660050630569458
Validation loss: 1.542583865504111

Epoch: 6| Step: 12
Training loss: 0.2299896627664566
Validation loss: 1.5605225563049316

Epoch: 6| Step: 13
Training loss: 0.24696752429008484
Validation loss: 1.5821430029407624

Epoch: 297| Step: 0
Training loss: 0.1637595295906067
Validation loss: 1.5723366711729316

Epoch: 6| Step: 1
Training loss: 0.23352345824241638
Validation loss: 1.5794692834218342

Epoch: 6| Step: 2
Training loss: 0.1985398828983307
Validation loss: 1.5924139791919338

Epoch: 6| Step: 3
Training loss: 0.1798098385334015
Validation loss: 1.5461656496088991

Epoch: 6| Step: 4
Training loss: 0.21715131402015686
Validation loss: 1.5209050806619788

Epoch: 6| Step: 5
Training loss: 0.1766117513179779
Validation loss: 1.5050619584257885

Epoch: 6| Step: 6
Training loss: 0.18355651199817657
Validation loss: 1.4690187579842025

Epoch: 6| Step: 7
Training loss: 0.25495949387550354
Validation loss: 1.4466536865439465

Epoch: 6| Step: 8
Training loss: 0.28228187561035156
Validation loss: 1.4695535026570803

Epoch: 6| Step: 9
Training loss: 0.23749610781669617
Validation loss: 1.4762507023349885

Epoch: 6| Step: 10
Training loss: 0.2711266875267029
Validation loss: 1.5011648490864744

Epoch: 6| Step: 11
Training loss: 0.20762354135513306
Validation loss: 1.5150198577552714

Epoch: 6| Step: 12
Training loss: 0.18720000982284546
Validation loss: 1.5457221590062624

Epoch: 6| Step: 13
Training loss: 0.1139281615614891
Validation loss: 1.5534101557987992

Epoch: 298| Step: 0
Training loss: 0.16678427159786224
Validation loss: 1.512834947596314

Epoch: 6| Step: 1
Training loss: 0.20199079811573029
Validation loss: 1.4668651844865532

Epoch: 6| Step: 2
Training loss: 0.2577887177467346
Validation loss: 1.474484315482519

Epoch: 6| Step: 3
Training loss: 0.23075948655605316
Validation loss: 1.4507260873753538

Epoch: 6| Step: 4
Training loss: 0.12569814920425415
Validation loss: 1.4522511337393074

Epoch: 6| Step: 5
Training loss: 0.15477220714092255
Validation loss: 1.4357801643751

Epoch: 6| Step: 6
Training loss: 0.1353844553232193
Validation loss: 1.4823538635366706

Epoch: 6| Step: 7
Training loss: 0.20430642366409302
Validation loss: 1.5177114727676555

Epoch: 6| Step: 8
Training loss: 0.1835194230079651
Validation loss: 1.520492838275048

Epoch: 6| Step: 9
Training loss: 0.2170724868774414
Validation loss: 1.536708620286757

Epoch: 6| Step: 10
Training loss: 0.3499176800251007
Validation loss: 1.541039994967881

Epoch: 6| Step: 11
Training loss: 0.2872609496116638
Validation loss: 1.5673099025603263

Epoch: 6| Step: 12
Training loss: 0.2624557614326477
Validation loss: 1.5372263731495026

Epoch: 6| Step: 13
Training loss: 0.16891589760780334
Validation loss: 1.5233451140824186

Epoch: 299| Step: 0
Training loss: 0.2912767827510834
Validation loss: 1.5407278621068565

Epoch: 6| Step: 1
Training loss: 0.22971615195274353
Validation loss: 1.5246561111942414

Epoch: 6| Step: 2
Training loss: 0.15811708569526672
Validation loss: 1.555535469003903

Epoch: 6| Step: 3
Training loss: 0.18082761764526367
Validation loss: 1.5456419382044064

Epoch: 6| Step: 4
Training loss: 0.2644079923629761
Validation loss: 1.5338879951866724

Epoch: 6| Step: 5
Training loss: 0.16608265042304993
Validation loss: 1.5253931835133543

Epoch: 6| Step: 6
Training loss: 0.2004578560590744
Validation loss: 1.503982941309611

Epoch: 6| Step: 7
Training loss: 0.202482670545578
Validation loss: 1.521642594568191

Epoch: 6| Step: 8
Training loss: 0.18533454835414886
Validation loss: 1.4976522255969305

Epoch: 6| Step: 9
Training loss: 0.20869114995002747
Validation loss: 1.5022508111051334

Epoch: 6| Step: 10
Training loss: 0.16683754324913025
Validation loss: 1.4714226075398025

Epoch: 6| Step: 11
Training loss: 0.2552187144756317
Validation loss: 1.4647050198688303

Epoch: 6| Step: 12
Training loss: 0.20628683269023895
Validation loss: 1.4505862433423278

Epoch: 6| Step: 13
Training loss: 0.2566014230251312
Validation loss: 1.4484308265870618

Epoch: 300| Step: 0
Training loss: 0.20848339796066284
Validation loss: 1.4435356163209485

Epoch: 6| Step: 1
Training loss: 0.26171934604644775
Validation loss: 1.4626243729745187

Epoch: 6| Step: 2
Training loss: 0.16049905121326447
Validation loss: 1.4566713174184163

Epoch: 6| Step: 3
Training loss: 0.18704648315906525
Validation loss: 1.4482182674510504

Epoch: 6| Step: 4
Training loss: 0.1955820620059967
Validation loss: 1.4639315541072557

Epoch: 6| Step: 5
Training loss: 0.08848854154348373
Validation loss: 1.4863749716871528

Epoch: 6| Step: 6
Training loss: 0.24071283638477325
Validation loss: 1.4697416367069367

Epoch: 6| Step: 7
Training loss: 0.2401927411556244
Validation loss: 1.5246614307485602

Epoch: 6| Step: 8
Training loss: 0.18156948685646057
Validation loss: 1.509483855257752

Epoch: 6| Step: 9
Training loss: 0.20080365240573883
Validation loss: 1.534402520425858

Epoch: 6| Step: 10
Training loss: 0.21213379502296448
Validation loss: 1.506541993028374

Epoch: 6| Step: 11
Training loss: 0.2328629493713379
Validation loss: 1.502581323346784

Epoch: 6| Step: 12
Training loss: 0.12431824952363968
Validation loss: 1.4834586612639888

Epoch: 6| Step: 13
Training loss: 0.17595797777175903
Validation loss: 1.4881640313774027

Epoch: 301| Step: 0
Training loss: 0.13542282581329346
Validation loss: 1.495734049427894

Epoch: 6| Step: 1
Training loss: 0.14149165153503418
Validation loss: 1.4895055108172919

Epoch: 6| Step: 2
Training loss: 0.22687260806560516
Validation loss: 1.5096640881671701

Epoch: 6| Step: 3
Training loss: 0.32332223653793335
Validation loss: 1.4868708349043323

Epoch: 6| Step: 4
Training loss: 0.2919062376022339
Validation loss: 1.5471277647120978

Epoch: 6| Step: 5
Training loss: 0.1179995983839035
Validation loss: 1.5346417657790645

Epoch: 6| Step: 6
Training loss: 0.20475073158740997
Validation loss: 1.5524120369265157

Epoch: 6| Step: 7
Training loss: 0.12588879466056824
Validation loss: 1.5688174604087748

Epoch: 6| Step: 8
Training loss: 0.18974988162517548
Validation loss: 1.5721135274056466

Epoch: 6| Step: 9
Training loss: 0.1968064308166504
Validation loss: 1.5539177643355502

Epoch: 6| Step: 10
Training loss: 0.13223092257976532
Validation loss: 1.5220682133910477

Epoch: 6| Step: 11
Training loss: 0.19027495384216309
Validation loss: 1.5132626384817145

Epoch: 6| Step: 12
Training loss: 0.2546098828315735
Validation loss: 1.5235495182775682

Epoch: 6| Step: 13
Training loss: 0.17484065890312195
Validation loss: 1.529849616430139

Epoch: 302| Step: 0
Training loss: 0.16163775324821472
Validation loss: 1.5091294075853081

Epoch: 6| Step: 1
Training loss: 0.15810251235961914
Validation loss: 1.4889224972776187

Epoch: 6| Step: 2
Training loss: 0.29104459285736084
Validation loss: 1.4674763871777443

Epoch: 6| Step: 3
Training loss: 0.12311003357172012
Validation loss: 1.4637758962569698

Epoch: 6| Step: 4
Training loss: 0.2164333462715149
Validation loss: 1.4609532381898613

Epoch: 6| Step: 5
Training loss: 0.1917368769645691
Validation loss: 1.4935565110175841

Epoch: 6| Step: 6
Training loss: 0.22857800126075745
Validation loss: 1.532090545982443

Epoch: 6| Step: 7
Training loss: 0.21667593717575073
Validation loss: 1.5582500234726937

Epoch: 6| Step: 8
Training loss: 0.3409755229949951
Validation loss: 1.5523826928548916

Epoch: 6| Step: 9
Training loss: 0.30951035022735596
Validation loss: 1.5252079117682673

Epoch: 6| Step: 10
Training loss: 0.14398029446601868
Validation loss: 1.4623004851802703

Epoch: 6| Step: 11
Training loss: 0.18573015928268433
Validation loss: 1.4529452516186623

Epoch: 6| Step: 12
Training loss: 0.11364474892616272
Validation loss: 1.423166723020615

Epoch: 6| Step: 13
Training loss: 0.17026960849761963
Validation loss: 1.4347436017887567

Epoch: 303| Step: 0
Training loss: 0.2207634299993515
Validation loss: 1.3931104387006452

Epoch: 6| Step: 1
Training loss: 0.29657402634620667
Validation loss: 1.4461530895643337

Epoch: 6| Step: 2
Training loss: 0.2159685343503952
Validation loss: 1.4387361195779615

Epoch: 6| Step: 3
Training loss: 0.22893422842025757
Validation loss: 1.401596894828222

Epoch: 6| Step: 4
Training loss: 0.1942887008190155
Validation loss: 1.4259550404805008

Epoch: 6| Step: 5
Training loss: 0.18471506237983704
Validation loss: 1.4850392110886113

Epoch: 6| Step: 6
Training loss: 0.0859949141740799
Validation loss: 1.5323853268418262

Epoch: 6| Step: 7
Training loss: 0.1673147976398468
Validation loss: 1.5304350622238652

Epoch: 6| Step: 8
Training loss: 0.21656787395477295
Validation loss: 1.5419669164124357

Epoch: 6| Step: 9
Training loss: 0.18580925464630127
Validation loss: 1.5419528266435027

Epoch: 6| Step: 10
Training loss: 0.17066915333271027
Validation loss: 1.5413391224799617

Epoch: 6| Step: 11
Training loss: 0.21106229722499847
Validation loss: 1.5327414428034136

Epoch: 6| Step: 12
Training loss: 0.11799290031194687
Validation loss: 1.5436988543438654

Epoch: 6| Step: 13
Training loss: 0.19461897015571594
Validation loss: 1.5302555420065438

Epoch: 304| Step: 0
Training loss: 0.17456361651420593
Validation loss: 1.5164139040054814

Epoch: 6| Step: 1
Training loss: 0.1994858831167221
Validation loss: 1.554241200929047

Epoch: 6| Step: 2
Training loss: 0.27959829568862915
Validation loss: 1.56805670005019

Epoch: 6| Step: 3
Training loss: 0.3255839943885803
Validation loss: 1.5620998656877907

Epoch: 6| Step: 4
Training loss: 0.20004874467849731
Validation loss: 1.5774275026013773

Epoch: 6| Step: 5
Training loss: 0.2599993348121643
Validation loss: 1.5647781702779955

Epoch: 6| Step: 6
Training loss: 0.21198183298110962
Validation loss: 1.5646833873564197

Epoch: 6| Step: 7
Training loss: 0.18268853425979614
Validation loss: 1.5757361137738792

Epoch: 6| Step: 8
Training loss: 0.19235751032829285
Validation loss: 1.6074807900254444

Epoch: 6| Step: 9
Training loss: 0.24006310105323792
Validation loss: 1.5988050968416276

Epoch: 6| Step: 10
Training loss: 0.2987281084060669
Validation loss: 1.5488223491176483

Epoch: 6| Step: 11
Training loss: 0.2706982493400574
Validation loss: 1.538513159880074

Epoch: 6| Step: 12
Training loss: 0.24307557940483093
Validation loss: 1.5015555357420316

Epoch: 6| Step: 13
Training loss: 0.1928054690361023
Validation loss: 1.4779570000146025

Epoch: 305| Step: 0
Training loss: 0.2566443979740143
Validation loss: 1.507594382891091

Epoch: 6| Step: 1
Training loss: 0.17653487622737885
Validation loss: 1.4752972869462864

Epoch: 6| Step: 2
Training loss: 0.27191755175590515
Validation loss: 1.4693105002885223

Epoch: 6| Step: 3
Training loss: 0.3106321394443512
Validation loss: 1.4413322748676423

Epoch: 6| Step: 4
Training loss: 0.21611079573631287
Validation loss: 1.4390035931782057

Epoch: 6| Step: 5
Training loss: 0.17657525837421417
Validation loss: 1.475607305444697

Epoch: 6| Step: 6
Training loss: 0.11203538626432419
Validation loss: 1.523606215753863

Epoch: 6| Step: 7
Training loss: 0.18773967027664185
Validation loss: 1.5502862955934258

Epoch: 6| Step: 8
Training loss: 0.23733574151992798
Validation loss: 1.5890391936866186

Epoch: 6| Step: 9
Training loss: 0.23997411131858826
Validation loss: 1.5767706965887418

Epoch: 6| Step: 10
Training loss: 0.1288822442293167
Validation loss: 1.4942532431694768

Epoch: 6| Step: 11
Training loss: 0.19638898968696594
Validation loss: 1.472542457683112

Epoch: 6| Step: 12
Training loss: 0.23850354552268982
Validation loss: 1.490465561548869

Epoch: 6| Step: 13
Training loss: 0.09063053131103516
Validation loss: 1.4978118737538655

Epoch: 306| Step: 0
Training loss: 0.2619944214820862
Validation loss: 1.4560278077279367

Epoch: 6| Step: 1
Training loss: 0.20026111602783203
Validation loss: 1.4542534069348407

Epoch: 6| Step: 2
Training loss: 0.10984663665294647
Validation loss: 1.4619074354889572

Epoch: 6| Step: 3
Training loss: 0.25917577743530273
Validation loss: 1.483157387343786

Epoch: 6| Step: 4
Training loss: 0.24343806505203247
Validation loss: 1.4801204243013937

Epoch: 6| Step: 5
Training loss: 0.18119306862354279
Validation loss: 1.500482689949774

Epoch: 6| Step: 6
Training loss: 0.20250554382801056
Validation loss: 1.471469186967419

Epoch: 6| Step: 7
Training loss: 0.3170403242111206
Validation loss: 1.4593309061501616

Epoch: 6| Step: 8
Training loss: 0.15768319368362427
Validation loss: 1.442157358251592

Epoch: 6| Step: 9
Training loss: 0.1554901897907257
Validation loss: 1.4367298259530017

Epoch: 6| Step: 10
Training loss: 0.16898198425769806
Validation loss: 1.431337639849673

Epoch: 6| Step: 11
Training loss: 0.17102590203285217
Validation loss: 1.4471959093565583

Epoch: 6| Step: 12
Training loss: 0.23967453837394714
Validation loss: 1.4916461334433606

Epoch: 6| Step: 13
Training loss: 0.2716130018234253
Validation loss: 1.4944587087118497

Epoch: 307| Step: 0
Training loss: 0.14171373844146729
Validation loss: 1.4905167907796881

Epoch: 6| Step: 1
Training loss: 0.26156648993492126
Validation loss: 1.5123233564438359

Epoch: 6| Step: 2
Training loss: 0.11248847097158432
Validation loss: 1.5216351555239769

Epoch: 6| Step: 3
Training loss: 0.24877072870731354
Validation loss: 1.5225247362608552

Epoch: 6| Step: 4
Training loss: 0.15558195114135742
Validation loss: 1.5380265712738037

Epoch: 6| Step: 5
Training loss: 0.1946338564157486
Validation loss: 1.495648782740357

Epoch: 6| Step: 6
Training loss: 0.22731855511665344
Validation loss: 1.5274894570791593

Epoch: 6| Step: 7
Training loss: 0.14538127183914185
Validation loss: 1.5107474339905607

Epoch: 6| Step: 8
Training loss: 0.1733822226524353
Validation loss: 1.481246849542023

Epoch: 6| Step: 9
Training loss: 0.23439155519008636
Validation loss: 1.495573139959766

Epoch: 6| Step: 10
Training loss: 0.26044154167175293
Validation loss: 1.4788817718464842

Epoch: 6| Step: 11
Training loss: 0.18665632605552673
Validation loss: 1.4799265528237948

Epoch: 6| Step: 12
Training loss: 0.2347845733165741
Validation loss: 1.5015969071336972

Epoch: 6| Step: 13
Training loss: 0.11113987863063812
Validation loss: 1.5061978550367459

Epoch: 308| Step: 0
Training loss: 0.19129276275634766
Validation loss: 1.5067619815949471

Epoch: 6| Step: 1
Training loss: 0.19910743832588196
Validation loss: 1.508462216264458

Epoch: 6| Step: 2
Training loss: 0.19976899027824402
Validation loss: 1.511395231370003

Epoch: 6| Step: 3
Training loss: 0.23586875200271606
Validation loss: 1.5055154702996696

Epoch: 6| Step: 4
Training loss: 0.11718609929084778
Validation loss: 1.4765307659743934

Epoch: 6| Step: 5
Training loss: 0.27344244718551636
Validation loss: 1.5072479055773826

Epoch: 6| Step: 6
Training loss: 0.2895534634590149
Validation loss: 1.4874373212937386

Epoch: 6| Step: 7
Training loss: 0.1651667356491089
Validation loss: 1.4581549834179621

Epoch: 6| Step: 8
Training loss: 0.16475656628608704
Validation loss: 1.4609945833042104

Epoch: 6| Step: 9
Training loss: 0.17276939749717712
Validation loss: 1.4796368973229521

Epoch: 6| Step: 10
Training loss: 0.2838219404220581
Validation loss: 1.4874707498858053

Epoch: 6| Step: 11
Training loss: 0.22284649312496185
Validation loss: 1.4930380300808979

Epoch: 6| Step: 12
Training loss: 0.11810803413391113
Validation loss: 1.529523726432554

Epoch: 6| Step: 13
Training loss: 0.11730405688285828
Validation loss: 1.5435855773187452

Epoch: 309| Step: 0
Training loss: 0.26448437571525574
Validation loss: 1.5725859941974762

Epoch: 6| Step: 1
Training loss: 0.15678828954696655
Validation loss: 1.5639284503075384

Epoch: 6| Step: 2
Training loss: 0.14150536060333252
Validation loss: 1.5704859584890387

Epoch: 6| Step: 3
Training loss: 0.13847801089286804
Validation loss: 1.5371426484918083

Epoch: 6| Step: 4
Training loss: 0.23657560348510742
Validation loss: 1.5075027635020595

Epoch: 6| Step: 5
Training loss: 0.2670230269432068
Validation loss: 1.5039248607491935

Epoch: 6| Step: 6
Training loss: 0.1683402955532074
Validation loss: 1.451008806946457

Epoch: 6| Step: 7
Training loss: 0.22556325793266296
Validation loss: 1.446677569420107

Epoch: 6| Step: 8
Training loss: 0.1710754781961441
Validation loss: 1.4729422215492494

Epoch: 6| Step: 9
Training loss: 0.22250443696975708
Validation loss: 1.4678236720382527

Epoch: 6| Step: 10
Training loss: 0.2841911315917969
Validation loss: 1.5045634437632818

Epoch: 6| Step: 11
Training loss: 0.2698138356208801
Validation loss: 1.5081296069647676

Epoch: 6| Step: 12
Training loss: 0.3058047890663147
Validation loss: 1.51503300346354

Epoch: 6| Step: 13
Training loss: 0.2676253616809845
Validation loss: 1.4922543584659536

Epoch: 310| Step: 0
Training loss: 0.3534091114997864
Validation loss: 1.5518713574255667

Epoch: 6| Step: 1
Training loss: 0.2124181091785431
Validation loss: 1.5287247396284533

Epoch: 6| Step: 2
Training loss: 0.27017050981521606
Validation loss: 1.549624434081457

Epoch: 6| Step: 3
Training loss: 0.24044634401798248
Validation loss: 1.523877266914614

Epoch: 6| Step: 4
Training loss: 0.1728481650352478
Validation loss: 1.5614079813803396

Epoch: 6| Step: 5
Training loss: 0.1382489949464798
Validation loss: 1.5128746212169688

Epoch: 6| Step: 6
Training loss: 0.12889224290847778
Validation loss: 1.5101911303817586

Epoch: 6| Step: 7
Training loss: 0.10731921344995499
Validation loss: 1.5036755223428049

Epoch: 6| Step: 8
Training loss: 0.3299465477466583
Validation loss: 1.4901756304566578

Epoch: 6| Step: 9
Training loss: 0.17043393850326538
Validation loss: 1.4962436486315984

Epoch: 6| Step: 10
Training loss: 0.16883686184883118
Validation loss: 1.4809417160608436

Epoch: 6| Step: 11
Training loss: 0.14816570281982422
Validation loss: 1.4730683744594615

Epoch: 6| Step: 12
Training loss: 0.13155290484428406
Validation loss: 1.4278660897285707

Epoch: 6| Step: 13
Training loss: 0.2878211736679077
Validation loss: 1.440629687360538

Epoch: 311| Step: 0
Training loss: 0.18806898593902588
Validation loss: 1.4478093629242272

Epoch: 6| Step: 1
Training loss: 0.1854451596736908
Validation loss: 1.45596182346344

Epoch: 6| Step: 2
Training loss: 0.1419455111026764
Validation loss: 1.5133563190378168

Epoch: 6| Step: 3
Training loss: 0.2543216943740845
Validation loss: 1.5513371024080502

Epoch: 6| Step: 4
Training loss: 0.21196094155311584
Validation loss: 1.5608259721468853

Epoch: 6| Step: 5
Training loss: 0.15206915140151978
Validation loss: 1.5648848356739167

Epoch: 6| Step: 6
Training loss: 0.07470206916332245
Validation loss: 1.5495741431431105

Epoch: 6| Step: 7
Training loss: 0.16196869313716888
Validation loss: 1.5476131016208279

Epoch: 6| Step: 8
Training loss: 0.2568207383155823
Validation loss: 1.5291267530892485

Epoch: 6| Step: 9
Training loss: 0.1962314397096634
Validation loss: 1.5308389074058943

Epoch: 6| Step: 10
Training loss: 0.28336989879608154
Validation loss: 1.509716437708947

Epoch: 6| Step: 11
Training loss: 0.27557164430618286
Validation loss: 1.4728806159829582

Epoch: 6| Step: 12
Training loss: 0.1668054163455963
Validation loss: 1.4553758168733248

Epoch: 6| Step: 13
Training loss: 0.11851154267787933
Validation loss: 1.4840681552886963

Epoch: 312| Step: 0
Training loss: 0.18749204277992249
Validation loss: 1.4779707757375573

Epoch: 6| Step: 1
Training loss: 0.3059391677379608
Validation loss: 1.4714179686320725

Epoch: 6| Step: 2
Training loss: 0.39837944507598877
Validation loss: 1.53875320957553

Epoch: 6| Step: 3
Training loss: 0.33469119668006897
Validation loss: 1.4957206864510812

Epoch: 6| Step: 4
Training loss: 0.19369956851005554
Validation loss: 1.5009528001149495

Epoch: 6| Step: 5
Training loss: 0.2308284342288971
Validation loss: 1.493396718014953

Epoch: 6| Step: 6
Training loss: 0.3100834786891937
Validation loss: 1.4877815233763827

Epoch: 6| Step: 7
Training loss: 0.19324223697185516
Validation loss: 1.5260272308062481

Epoch: 6| Step: 8
Training loss: 0.1914106011390686
Validation loss: 1.4720108111699421

Epoch: 6| Step: 9
Training loss: 0.1548372507095337
Validation loss: 1.5101564699603665

Epoch: 6| Step: 10
Training loss: 0.10460971295833588
Validation loss: 1.4601091415651384

Epoch: 6| Step: 11
Training loss: 0.2014288306236267
Validation loss: 1.4534172114505564

Epoch: 6| Step: 12
Training loss: 0.24976277351379395
Validation loss: 1.4322871431227653

Epoch: 6| Step: 13
Training loss: 0.15289568901062012
Validation loss: 1.4707522866546467

Epoch: 313| Step: 0
Training loss: 0.15023121237754822
Validation loss: 1.4645774787472141

Epoch: 6| Step: 1
Training loss: 0.2321045845746994
Validation loss: 1.4574775259981874

Epoch: 6| Step: 2
Training loss: 0.17304253578186035
Validation loss: 1.4536216323093702

Epoch: 6| Step: 3
Training loss: 0.25661757588386536
Validation loss: 1.4676858007266957

Epoch: 6| Step: 4
Training loss: 0.21281877160072327
Validation loss: 1.5162750521013815

Epoch: 6| Step: 5
Training loss: 0.1655474603176117
Validation loss: 1.5434962023970902

Epoch: 6| Step: 6
Training loss: 0.27078884840011597
Validation loss: 1.5278079496916903

Epoch: 6| Step: 7
Training loss: 0.20171259343624115
Validation loss: 1.544213080278007

Epoch: 6| Step: 8
Training loss: 0.26968324184417725
Validation loss: 1.5464540643076743

Epoch: 6| Step: 9
Training loss: 0.1976519525051117
Validation loss: 1.574663576259408

Epoch: 6| Step: 10
Training loss: 0.15186575055122375
Validation loss: 1.5447161152798643

Epoch: 6| Step: 11
Training loss: 0.1742018461227417
Validation loss: 1.5416930234560402

Epoch: 6| Step: 12
Training loss: 0.2555443346500397
Validation loss: 1.5572904079191145

Epoch: 6| Step: 13
Training loss: 0.23887909948825836
Validation loss: 1.569222613047528

Epoch: 314| Step: 0
Training loss: 0.14170730113983154
Validation loss: 1.5279004343094365

Epoch: 6| Step: 1
Training loss: 0.26680177450180054
Validation loss: 1.5386285845951369

Epoch: 6| Step: 2
Training loss: 0.15285637974739075
Validation loss: 1.5389894926419823

Epoch: 6| Step: 3
Training loss: 0.1564960479736328
Validation loss: 1.5003999625482867

Epoch: 6| Step: 4
Training loss: 0.24950779974460602
Validation loss: 1.5134630228883477

Epoch: 6| Step: 5
Training loss: 0.22849904000759125
Validation loss: 1.496124376532852

Epoch: 6| Step: 6
Training loss: 0.17641161382198334
Validation loss: 1.4641121407990814

Epoch: 6| Step: 7
Training loss: 0.1503143310546875
Validation loss: 1.5135444652649663

Epoch: 6| Step: 8
Training loss: 0.2812747061252594
Validation loss: 1.534386719426801

Epoch: 6| Step: 9
Training loss: 0.181250661611557
Validation loss: 1.5356096580464353

Epoch: 6| Step: 10
Training loss: 0.156332865357399
Validation loss: 1.4761180223957184

Epoch: 6| Step: 11
Training loss: 0.12807483971118927
Validation loss: 1.4921627095950547

Epoch: 6| Step: 12
Training loss: 0.11076579988002777
Validation loss: 1.4927981117720246

Epoch: 6| Step: 13
Training loss: 0.23575933277606964
Validation loss: 1.4804163004762383

Epoch: 315| Step: 0
Training loss: 0.18958638608455658
Validation loss: 1.4695404562898862

Epoch: 6| Step: 1
Training loss: 0.19113227725028992
Validation loss: 1.443176160576523

Epoch: 6| Step: 2
Training loss: 0.28236934542655945
Validation loss: 1.4498771006061184

Epoch: 6| Step: 3
Training loss: 0.1977381855249405
Validation loss: 1.4429155921423307

Epoch: 6| Step: 4
Training loss: 0.10547207295894623
Validation loss: 1.4338119542726906

Epoch: 6| Step: 5
Training loss: 0.23188334703445435
Validation loss: 1.451579842516171

Epoch: 6| Step: 6
Training loss: 0.15526500344276428
Validation loss: 1.4407841723452333

Epoch: 6| Step: 7
Training loss: 0.13944758474826813
Validation loss: 1.4010141254753194

Epoch: 6| Step: 8
Training loss: 0.21362489461898804
Validation loss: 1.4360366687979749

Epoch: 6| Step: 9
Training loss: 0.16837894916534424
Validation loss: 1.4294956832803705

Epoch: 6| Step: 10
Training loss: 0.1879412829875946
Validation loss: 1.420366705104869

Epoch: 6| Step: 11
Training loss: 0.25502336025238037
Validation loss: 1.4363789994229552

Epoch: 6| Step: 12
Training loss: 0.1407393515110016
Validation loss: 1.4511257371594828

Epoch: 6| Step: 13
Training loss: 0.22793695330619812
Validation loss: 1.4202640466792609

Epoch: 316| Step: 0
Training loss: 0.1502704918384552
Validation loss: 1.4494748897449945

Epoch: 6| Step: 1
Training loss: 0.1820039451122284
Validation loss: 1.5062143251460085

Epoch: 6| Step: 2
Training loss: 0.10358279198408127
Validation loss: 1.551552632803558

Epoch: 6| Step: 3
Training loss: 0.16768202185630798
Validation loss: 1.6177043350793983

Epoch: 6| Step: 4
Training loss: 0.2763870358467102
Validation loss: 1.6501655386340233

Epoch: 6| Step: 5
Training loss: 0.20290598273277283
Validation loss: 1.5947225388660227

Epoch: 6| Step: 6
Training loss: 0.29176974296569824
Validation loss: 1.5632156607925252

Epoch: 6| Step: 7
Training loss: 0.23448613286018372
Validation loss: 1.536190813587558

Epoch: 6| Step: 8
Training loss: 0.1911524534225464
Validation loss: 1.479729744695848

Epoch: 6| Step: 9
Training loss: 0.21542324125766754
Validation loss: 1.4692065959335656

Epoch: 6| Step: 10
Training loss: 0.1584838181734085
Validation loss: 1.4718809922536213

Epoch: 6| Step: 11
Training loss: 0.15943343937397003
Validation loss: 1.4808651977969753

Epoch: 6| Step: 12
Training loss: 0.19971095025539398
Validation loss: 1.4820267295324674

Epoch: 6| Step: 13
Training loss: 0.14716854691505432
Validation loss: 1.4767263640639603

Epoch: 317| Step: 0
Training loss: 0.14248616993427277
Validation loss: 1.4474609603164017

Epoch: 6| Step: 1
Training loss: 0.1819334477186203
Validation loss: 1.4896288379546134

Epoch: 6| Step: 2
Training loss: 0.198710098862648
Validation loss: 1.477694643441067

Epoch: 6| Step: 3
Training loss: 0.08038713037967682
Validation loss: 1.502637465794881

Epoch: 6| Step: 4
Training loss: 0.12179537117481232
Validation loss: 1.5220996904116806

Epoch: 6| Step: 5
Training loss: 0.22992219030857086
Validation loss: 1.5196350313002063

Epoch: 6| Step: 6
Training loss: 0.23083944618701935
Validation loss: 1.539161216828131

Epoch: 6| Step: 7
Training loss: 0.24522772431373596
Validation loss: 1.521583003382529

Epoch: 6| Step: 8
Training loss: 0.19778606295585632
Validation loss: 1.519578415860412

Epoch: 6| Step: 9
Training loss: 0.11307331174612045
Validation loss: 1.4678882052821498

Epoch: 6| Step: 10
Training loss: 0.14996978640556335
Validation loss: 1.4794241984685261

Epoch: 6| Step: 11
Training loss: 0.13868942856788635
Validation loss: 1.5038423076752694

Epoch: 6| Step: 12
Training loss: 0.20563705265522003
Validation loss: 1.5454962612480245

Epoch: 6| Step: 13
Training loss: 0.2725962698459625
Validation loss: 1.5171572187895417

Epoch: 318| Step: 0
Training loss: 0.15558108687400818
Validation loss: 1.5228782879408969

Epoch: 6| Step: 1
Training loss: 0.19111648201942444
Validation loss: 1.5739248593648274

Epoch: 6| Step: 2
Training loss: 0.14930766820907593
Validation loss: 1.5299811658038889

Epoch: 6| Step: 3
Training loss: 0.238652765750885
Validation loss: 1.5343135518412436

Epoch: 6| Step: 4
Training loss: 0.1395900398492813
Validation loss: 1.5572540151175631

Epoch: 6| Step: 5
Training loss: 0.2296234667301178
Validation loss: 1.5485695613327848

Epoch: 6| Step: 6
Training loss: 0.1504915952682495
Validation loss: 1.5538149046641525

Epoch: 6| Step: 7
Training loss: 0.14303848147392273
Validation loss: 1.567780634408356

Epoch: 6| Step: 8
Training loss: 0.14229238033294678
Validation loss: 1.553583841170034

Epoch: 6| Step: 9
Training loss: 0.21545028686523438
Validation loss: 1.5561635071231472

Epoch: 6| Step: 10
Training loss: 0.2265528440475464
Validation loss: 1.4977497810958533

Epoch: 6| Step: 11
Training loss: 0.17365267872810364
Validation loss: 1.502624463009578

Epoch: 6| Step: 12
Training loss: 0.17617188394069672
Validation loss: 1.4945509549110167

Epoch: 6| Step: 13
Training loss: 0.15188544988632202
Validation loss: 1.4813483107474543

Epoch: 319| Step: 0
Training loss: 0.13749931752681732
Validation loss: 1.4684718680638138

Epoch: 6| Step: 1
Training loss: 0.1180504560470581
Validation loss: 1.5061894655227661

Epoch: 6| Step: 2
Training loss: 0.09849351644515991
Validation loss: 1.4439626124597364

Epoch: 6| Step: 3
Training loss: 0.14778929948806763
Validation loss: 1.4783872430042555

Epoch: 6| Step: 4
Training loss: 0.16977722942829132
Validation loss: 1.4654697487431187

Epoch: 6| Step: 5
Training loss: 0.18125474452972412
Validation loss: 1.4713197267183693

Epoch: 6| Step: 6
Training loss: 0.19059962034225464
Validation loss: 1.4838049552773918

Epoch: 6| Step: 7
Training loss: 0.2022033929824829
Validation loss: 1.4830579116780271

Epoch: 6| Step: 8
Training loss: 0.17092379927635193
Validation loss: 1.5054843233477684

Epoch: 6| Step: 9
Training loss: 0.15703529119491577
Validation loss: 1.517894144981138

Epoch: 6| Step: 10
Training loss: 0.28101372718811035
Validation loss: 1.539530352879596

Epoch: 6| Step: 11
Training loss: 0.1987151801586151
Validation loss: 1.5078454427821661

Epoch: 6| Step: 12
Training loss: 0.12953819334506989
Validation loss: 1.4541941419724496

Epoch: 6| Step: 13
Training loss: 0.23794391751289368
Validation loss: 1.450412650262156

Epoch: 320| Step: 0
Training loss: 0.14024892449378967
Validation loss: 1.4294793580168037

Epoch: 6| Step: 1
Training loss: 0.23593811690807343
Validation loss: 1.4481867103166477

Epoch: 6| Step: 2
Training loss: 0.2724831998348236
Validation loss: 1.4254613473851194

Epoch: 6| Step: 3
Training loss: 0.19459332525730133
Validation loss: 1.4516630871321565

Epoch: 6| Step: 4
Training loss: 0.18483927845954895
Validation loss: 1.463083246702789

Epoch: 6| Step: 5
Training loss: 0.12237411737442017
Validation loss: 1.4766095030692317

Epoch: 6| Step: 6
Training loss: 0.12447188794612885
Validation loss: 1.4726661136073451

Epoch: 6| Step: 7
Training loss: 0.10691314935684204
Validation loss: 1.4847497465789958

Epoch: 6| Step: 8
Training loss: 0.14567184448242188
Validation loss: 1.4705191510979847

Epoch: 6| Step: 9
Training loss: 0.10212872922420502
Validation loss: 1.4699006868946938

Epoch: 6| Step: 10
Training loss: 0.20899592339992523
Validation loss: 1.4502229203460038

Epoch: 6| Step: 11
Training loss: 0.10632267594337463
Validation loss: 1.5068151463744461

Epoch: 6| Step: 12
Training loss: 0.1699182689189911
Validation loss: 1.51273424138305

Epoch: 6| Step: 13
Training loss: 0.06633131951093674
Validation loss: 1.4754295797758206

Epoch: 321| Step: 0
Training loss: 0.16540196537971497
Validation loss: 1.5111777743985575

Epoch: 6| Step: 1
Training loss: 0.1989908218383789
Validation loss: 1.4783337308514504

Epoch: 6| Step: 2
Training loss: 0.11320976912975311
Validation loss: 1.475998729787847

Epoch: 6| Step: 3
Training loss: 0.21198999881744385
Validation loss: 1.4366779724756877

Epoch: 6| Step: 4
Training loss: 0.11393219232559204
Validation loss: 1.4399731518119894

Epoch: 6| Step: 5
Training loss: 0.16541700065135956
Validation loss: 1.428711675828503

Epoch: 6| Step: 6
Training loss: 0.15474346280097961
Validation loss: 1.4409179975909572

Epoch: 6| Step: 7
Training loss: 0.2560070753097534
Validation loss: 1.3980825818994993

Epoch: 6| Step: 8
Training loss: 0.09518885612487793
Validation loss: 1.427644601432226

Epoch: 6| Step: 9
Training loss: 0.15020035207271576
Validation loss: 1.4346424161746938

Epoch: 6| Step: 10
Training loss: 0.19339124858379364
Validation loss: 1.44343779676704

Epoch: 6| Step: 11
Training loss: 0.2285674810409546
Validation loss: 1.446240222582253

Epoch: 6| Step: 12
Training loss: 0.13402831554412842
Validation loss: 1.4488044349096154

Epoch: 6| Step: 13
Training loss: 0.26411357522010803
Validation loss: 1.4959732294082642

Epoch: 322| Step: 0
Training loss: 0.11716129630804062
Validation loss: 1.5190721128576545

Epoch: 6| Step: 1
Training loss: 0.2956383228302002
Validation loss: 1.6366089274806361

Epoch: 6| Step: 2
Training loss: 0.3002482056617737
Validation loss: 1.621471873534623

Epoch: 6| Step: 3
Training loss: 0.19747966527938843
Validation loss: 1.6277400434658091

Epoch: 6| Step: 4
Training loss: 0.2887762486934662
Validation loss: 1.5850550872023388

Epoch: 6| Step: 5
Training loss: 0.1630895435810089
Validation loss: 1.5248656324160996

Epoch: 6| Step: 6
Training loss: 0.07049442827701569
Validation loss: 1.498587110991119

Epoch: 6| Step: 7
Training loss: 0.20805442333221436
Validation loss: 1.4605198085948985

Epoch: 6| Step: 8
Training loss: 0.12842817604541779
Validation loss: 1.438340038381597

Epoch: 6| Step: 9
Training loss: 0.24682629108428955
Validation loss: 1.432146039060367

Epoch: 6| Step: 10
Training loss: 0.12017770111560822
Validation loss: 1.421046277528168

Epoch: 6| Step: 11
Training loss: 0.21141308546066284
Validation loss: 1.4380518146740493

Epoch: 6| Step: 12
Training loss: 0.19181162118911743
Validation loss: 1.4302731021758048

Epoch: 6| Step: 13
Training loss: 0.261549711227417
Validation loss: 1.4289484370139338

Epoch: 323| Step: 0
Training loss: 0.17019549012184143
Validation loss: 1.4461969521737867

Epoch: 6| Step: 1
Training loss: 0.19302569329738617
Validation loss: 1.4761376073283534

Epoch: 6| Step: 2
Training loss: 0.13474681973457336
Validation loss: 1.5168233327968146

Epoch: 6| Step: 3
Training loss: 0.23532706499099731
Validation loss: 1.5436620866098711

Epoch: 6| Step: 4
Training loss: 0.3576447367668152
Validation loss: 1.5302074006808701

Epoch: 6| Step: 5
Training loss: 0.1424293965101242
Validation loss: 1.5147004454366622

Epoch: 6| Step: 6
Training loss: 0.15936312079429626
Validation loss: 1.4997660460010651

Epoch: 6| Step: 7
Training loss: 0.21318665146827698
Validation loss: 1.4765923587224816

Epoch: 6| Step: 8
Training loss: 0.1325969099998474
Validation loss: 1.4908167200703775

Epoch: 6| Step: 9
Training loss: 0.22558915615081787
Validation loss: 1.4865912955294374

Epoch: 6| Step: 10
Training loss: 0.13806211948394775
Validation loss: 1.4934649249558807

Epoch: 6| Step: 11
Training loss: 0.19619327783584595
Validation loss: 1.4602535745149017

Epoch: 6| Step: 12
Training loss: 0.18517835438251495
Validation loss: 1.4970596849277455

Epoch: 6| Step: 13
Training loss: 0.26833653450012207
Validation loss: 1.491786418422576

Epoch: 324| Step: 0
Training loss: 0.17863057553768158
Validation loss: 1.5013250368897633

Epoch: 6| Step: 1
Training loss: 0.18513274192810059
Validation loss: 1.4684450293100009

Epoch: 6| Step: 2
Training loss: 0.17337998747825623
Validation loss: 1.4988355284096093

Epoch: 6| Step: 3
Training loss: 0.20778286457061768
Validation loss: 1.497234034281905

Epoch: 6| Step: 4
Training loss: 0.2493366003036499
Validation loss: 1.4874481026844313

Epoch: 6| Step: 5
Training loss: 0.19940613210201263
Validation loss: 1.4996023658783204

Epoch: 6| Step: 6
Training loss: 0.14278967678546906
Validation loss: 1.506708239996305

Epoch: 6| Step: 7
Training loss: 0.16073238849639893
Validation loss: 1.4989690755003242

Epoch: 6| Step: 8
Training loss: 0.1596202254295349
Validation loss: 1.5115777420741257

Epoch: 6| Step: 9
Training loss: 0.17882753908634186
Validation loss: 1.440629634805905

Epoch: 6| Step: 10
Training loss: 0.1397346556186676
Validation loss: 1.4571431516319193

Epoch: 6| Step: 11
Training loss: 0.19882892072200775
Validation loss: 1.43461182296917

Epoch: 6| Step: 12
Training loss: 0.12222330272197723
Validation loss: 1.3988562309613792

Epoch: 6| Step: 13
Training loss: 0.15835201740264893
Validation loss: 1.41467377960041

Epoch: 325| Step: 0
Training loss: 0.1957901567220688
Validation loss: 1.4278978045268724

Epoch: 6| Step: 1
Training loss: 0.18654906749725342
Validation loss: 1.4411097944423716

Epoch: 6| Step: 2
Training loss: 0.2070682793855667
Validation loss: 1.4427164793014526

Epoch: 6| Step: 3
Training loss: 0.10304582864046097
Validation loss: 1.475583286695583

Epoch: 6| Step: 4
Training loss: 0.13549399375915527
Validation loss: 1.4911804455582813

Epoch: 6| Step: 5
Training loss: 0.15218409895896912
Validation loss: 1.5524674743734381

Epoch: 6| Step: 6
Training loss: 0.1825096607208252
Validation loss: 1.542051351198586

Epoch: 6| Step: 7
Training loss: 0.23352739214897156
Validation loss: 1.5326964342465965

Epoch: 6| Step: 8
Training loss: 0.3816182017326355
Validation loss: 1.5403004782174223

Epoch: 6| Step: 9
Training loss: 0.2902218997478485
Validation loss: 1.4818034825786468

Epoch: 6| Step: 10
Training loss: 0.24224142730236053
Validation loss: 1.490029061994245

Epoch: 6| Step: 11
Training loss: 0.15592414140701294
Validation loss: 1.4564498246357005

Epoch: 6| Step: 12
Training loss: 0.15340229868888855
Validation loss: 1.4579348006556112

Epoch: 6| Step: 13
Training loss: 0.13248080015182495
Validation loss: 1.463976699818847

Epoch: 326| Step: 0
Training loss: 0.17168019711971283
Validation loss: 1.4917381296875656

Epoch: 6| Step: 1
Training loss: 0.2763080596923828
Validation loss: 1.5100016235023417

Epoch: 6| Step: 2
Training loss: 0.18353435397148132
Validation loss: 1.495245704086878

Epoch: 6| Step: 3
Training loss: 0.25256913900375366
Validation loss: 1.519125597451323

Epoch: 6| Step: 4
Training loss: 0.2778030037879944
Validation loss: 1.502231244117983

Epoch: 6| Step: 5
Training loss: 0.1448662281036377
Validation loss: 1.5104207915644492

Epoch: 6| Step: 6
Training loss: 0.17099794745445251
Validation loss: 1.4894104478179768

Epoch: 6| Step: 7
Training loss: 0.1690208613872528
Validation loss: 1.4740563182420627

Epoch: 6| Step: 8
Training loss: 0.2371220588684082
Validation loss: 1.4804710008764779

Epoch: 6| Step: 9
Training loss: 0.27244579792022705
Validation loss: 1.5061037425071961

Epoch: 6| Step: 10
Training loss: 0.26915243268013
Validation loss: 1.5504221339379587

Epoch: 6| Step: 11
Training loss: 0.19421717524528503
Validation loss: 1.5279841679398731

Epoch: 6| Step: 12
Training loss: 0.18051598966121674
Validation loss: 1.5284677538820493

Epoch: 6| Step: 13
Training loss: 0.26652902364730835
Validation loss: 1.5510854054522771

Epoch: 327| Step: 0
Training loss: 0.20413953065872192
Validation loss: 1.5384632650242056

Epoch: 6| Step: 1
Training loss: 0.12404068559408188
Validation loss: 1.554094950358073

Epoch: 6| Step: 2
Training loss: 0.1668078899383545
Validation loss: 1.5288063531280847

Epoch: 6| Step: 3
Training loss: 0.18046331405639648
Validation loss: 1.4971207611022457

Epoch: 6| Step: 4
Training loss: 0.17402631044387817
Validation loss: 1.4684931270537838

Epoch: 6| Step: 5
Training loss: 0.18236008286476135
Validation loss: 1.4228771091789327

Epoch: 6| Step: 6
Training loss: 0.14883816242218018
Validation loss: 1.4233178246405818

Epoch: 6| Step: 7
Training loss: 0.2030716836452484
Validation loss: 1.414739833083204

Epoch: 6| Step: 8
Training loss: 0.13923993706703186
Validation loss: 1.4073607255053777

Epoch: 6| Step: 9
Training loss: 0.19155824184417725
Validation loss: 1.4024696862825783

Epoch: 6| Step: 10
Training loss: 0.19996188580989838
Validation loss: 1.4234067047795942

Epoch: 6| Step: 11
Training loss: 0.17019714415073395
Validation loss: 1.4413162591636821

Epoch: 6| Step: 12
Training loss: 0.16866251826286316
Validation loss: 1.4274710737248903

Epoch: 6| Step: 13
Training loss: 0.38819795846939087
Validation loss: 1.4405010105461202

Epoch: 328| Step: 0
Training loss: 0.10535252839326859
Validation loss: 1.4391802754453433

Epoch: 6| Step: 1
Training loss: 0.2469787448644638
Validation loss: 1.4688293510867703

Epoch: 6| Step: 2
Training loss: 0.18674656748771667
Validation loss: 1.4569229631013767

Epoch: 6| Step: 3
Training loss: 0.2138889729976654
Validation loss: 1.491832467817491

Epoch: 6| Step: 4
Training loss: 0.23088043928146362
Validation loss: 1.4776969058539278

Epoch: 6| Step: 5
Training loss: 0.1668221801519394
Validation loss: 1.4937504901680896

Epoch: 6| Step: 6
Training loss: 0.07884642481803894
Validation loss: 1.5011078567915066

Epoch: 6| Step: 7
Training loss: 0.18968477845191956
Validation loss: 1.5426746247917094

Epoch: 6| Step: 8
Training loss: 0.18714800477027893
Validation loss: 1.5651932749696957

Epoch: 6| Step: 9
Training loss: 0.2106354832649231
Validation loss: 1.5708488815574235

Epoch: 6| Step: 10
Training loss: 0.15606267750263214
Validation loss: 1.5688434441884358

Epoch: 6| Step: 11
Training loss: 0.11175063252449036
Validation loss: 1.5556140471530218

Epoch: 6| Step: 12
Training loss: 0.16165100038051605
Validation loss: 1.5191319091345674

Epoch: 6| Step: 13
Training loss: 0.17781299352645874
Validation loss: 1.4815115133921306

Epoch: 329| Step: 0
Training loss: 0.06325383484363556
Validation loss: 1.4684903980583273

Epoch: 6| Step: 1
Training loss: 0.09753954410552979
Validation loss: 1.4769655965989636

Epoch: 6| Step: 2
Training loss: 0.1233581155538559
Validation loss: 1.4711726019459386

Epoch: 6| Step: 3
Training loss: 0.13552099466323853
Validation loss: 1.475133220354716

Epoch: 6| Step: 4
Training loss: 0.1509222686290741
Validation loss: 1.484939544431625

Epoch: 6| Step: 5
Training loss: 0.22139030694961548
Validation loss: 1.458869425199365

Epoch: 6| Step: 6
Training loss: 0.17298251390457153
Validation loss: 1.479543221894131

Epoch: 6| Step: 7
Training loss: 0.176537424325943
Validation loss: 1.5165197169908913

Epoch: 6| Step: 8
Training loss: 0.12673436105251312
Validation loss: 1.5300764755536151

Epoch: 6| Step: 9
Training loss: 0.19734665751457214
Validation loss: 1.5576921701431274

Epoch: 6| Step: 10
Training loss: 0.2066207230091095
Validation loss: 1.5884851691543416

Epoch: 6| Step: 11
Training loss: 0.1811172515153885
Validation loss: 1.6068450571388326

Epoch: 6| Step: 12
Training loss: 0.2623389959335327
Validation loss: 1.5911523206259615

Epoch: 6| Step: 13
Training loss: 0.16028891503810883
Validation loss: 1.5174486329478603

Epoch: 330| Step: 0
Training loss: 0.13635790348052979
Validation loss: 1.5167706115271455

Epoch: 6| Step: 1
Training loss: 0.11645738780498505
Validation loss: 1.4863824344450427

Epoch: 6| Step: 2
Training loss: 0.17019793391227722
Validation loss: 1.5013399098509101

Epoch: 6| Step: 3
Training loss: 0.12063786387443542
Validation loss: 1.4403433915107482

Epoch: 6| Step: 4
Training loss: 0.1966266930103302
Validation loss: 1.480205193642647

Epoch: 6| Step: 5
Training loss: 0.2661054730415344
Validation loss: 1.4565861840401926

Epoch: 6| Step: 6
Training loss: 0.12392530590295792
Validation loss: 1.486937097323838

Epoch: 6| Step: 7
Training loss: 0.10512461513280869
Validation loss: 1.5031482513232897

Epoch: 6| Step: 8
Training loss: 0.1901257038116455
Validation loss: 1.504288024799798

Epoch: 6| Step: 9
Training loss: 0.2068442404270172
Validation loss: 1.537377203664472

Epoch: 6| Step: 10
Training loss: 0.19643622636795044
Validation loss: 1.5166209231140793

Epoch: 6| Step: 11
Training loss: 0.18773746490478516
Validation loss: 1.503841362973695

Epoch: 6| Step: 12
Training loss: 0.10371512174606323
Validation loss: 1.5145542877976612

Epoch: 6| Step: 13
Training loss: 0.15592503547668457
Validation loss: 1.492659209876932

Epoch: 331| Step: 0
Training loss: 0.1236049234867096
Validation loss: 1.5072250507211173

Epoch: 6| Step: 1
Training loss: 0.1514711230993271
Validation loss: 1.5151583840770106

Epoch: 6| Step: 2
Training loss: 0.17386342585086823
Validation loss: 1.4998986810766242

Epoch: 6| Step: 3
Training loss: 0.15628506243228912
Validation loss: 1.5068355606448265

Epoch: 6| Step: 4
Training loss: 0.14298035204410553
Validation loss: 1.5058372424494835

Epoch: 6| Step: 5
Training loss: 0.18160398304462433
Validation loss: 1.483621892108712

Epoch: 6| Step: 6
Training loss: 0.164972186088562
Validation loss: 1.4853833977894118

Epoch: 6| Step: 7
Training loss: 0.24576377868652344
Validation loss: 1.4676325821107434

Epoch: 6| Step: 8
Training loss: 0.17257952690124512
Validation loss: 1.4807873361854142

Epoch: 6| Step: 9
Training loss: 0.24637490510940552
Validation loss: 1.4716237386067708

Epoch: 6| Step: 10
Training loss: 0.12222710996866226
Validation loss: 1.4726441739707865

Epoch: 6| Step: 11
Training loss: 0.13322356343269348
Validation loss: 1.4685553440483667

Epoch: 6| Step: 12
Training loss: 0.16312353312969208
Validation loss: 1.441623369852702

Epoch: 6| Step: 13
Training loss: 0.16144834458827972
Validation loss: 1.4814167227796329

Epoch: 332| Step: 0
Training loss: 0.15449336171150208
Validation loss: 1.4678261677424114

Epoch: 6| Step: 1
Training loss: 0.15938705205917358
Validation loss: 1.4776804665083527

Epoch: 6| Step: 2
Training loss: 0.22430959343910217
Validation loss: 1.5141703518488074

Epoch: 6| Step: 3
Training loss: 0.09515976905822754
Validation loss: 1.5385028277674029

Epoch: 6| Step: 4
Training loss: 0.08511142432689667
Validation loss: 1.5097214329627253

Epoch: 6| Step: 5
Training loss: 0.15471449494361877
Validation loss: 1.543135319986651

Epoch: 6| Step: 6
Training loss: 0.1784282922744751
Validation loss: 1.5351613285720989

Epoch: 6| Step: 7
Training loss: 0.16471973061561584
Validation loss: 1.5042521120399557

Epoch: 6| Step: 8
Training loss: 0.1739855259656906
Validation loss: 1.5367531891792052

Epoch: 6| Step: 9
Training loss: 0.13621282577514648
Validation loss: 1.511852159295031

Epoch: 6| Step: 10
Training loss: 0.10651759803295135
Validation loss: 1.5251865130598827

Epoch: 6| Step: 11
Training loss: 0.12284436076879501
Validation loss: 1.4895758757027246

Epoch: 6| Step: 12
Training loss: 0.14355416595935822
Validation loss: 1.5101817987298454

Epoch: 6| Step: 13
Training loss: 0.09894318133592606
Validation loss: 1.4978070451367287

Epoch: 333| Step: 0
Training loss: 0.17052435874938965
Validation loss: 1.5424449879636046

Epoch: 6| Step: 1
Training loss: 0.14705248177051544
Validation loss: 1.5926803529903453

Epoch: 6| Step: 2
Training loss: 0.28039583563804626
Validation loss: 1.6236852074182162

Epoch: 6| Step: 3
Training loss: 0.2936054468154907
Validation loss: 1.6321996822152087

Epoch: 6| Step: 4
Training loss: 0.30487561225891113
Validation loss: 1.5697555593265

Epoch: 6| Step: 5
Training loss: 0.25484395027160645
Validation loss: 1.5302543614500312

Epoch: 6| Step: 6
Training loss: 0.13504180312156677
Validation loss: 1.4746378185928508

Epoch: 6| Step: 7
Training loss: 0.19984683394432068
Validation loss: 1.4200011030320199

Epoch: 6| Step: 8
Training loss: 0.13133567571640015
Validation loss: 1.4389130005272486

Epoch: 6| Step: 9
Training loss: 0.17713552713394165
Validation loss: 1.3933746981364425

Epoch: 6| Step: 10
Training loss: 0.21296754479408264
Validation loss: 1.4020404995128672

Epoch: 6| Step: 11
Training loss: 0.16767770051956177
Validation loss: 1.426788733851525

Epoch: 6| Step: 12
Training loss: 0.20043157041072845
Validation loss: 1.430426610413418

Epoch: 6| Step: 13
Training loss: 0.11638547480106354
Validation loss: 1.408960873080838

Epoch: 334| Step: 0
Training loss: 0.15758919715881348
Validation loss: 1.4658927199661091

Epoch: 6| Step: 1
Training loss: 0.2312297523021698
Validation loss: 1.4941188520000828

Epoch: 6| Step: 2
Training loss: 0.23129700124263763
Validation loss: 1.4939737794219807

Epoch: 6| Step: 3
Training loss: 0.24267756938934326
Validation loss: 1.5477822506299583

Epoch: 6| Step: 4
Training loss: 0.15607251226902008
Validation loss: 1.5163750071679392

Epoch: 6| Step: 5
Training loss: 0.16131699085235596
Validation loss: 1.5059108157311716

Epoch: 6| Step: 6
Training loss: 0.13690824806690216
Validation loss: 1.4840412498802267

Epoch: 6| Step: 7
Training loss: 0.29649806022644043
Validation loss: 1.5161135568413684

Epoch: 6| Step: 8
Training loss: 0.20874282717704773
Validation loss: 1.4903062876834665

Epoch: 6| Step: 9
Training loss: 0.11268284916877747
Validation loss: 1.4972410317390197

Epoch: 6| Step: 10
Training loss: 0.24245905876159668
Validation loss: 1.5087155757411834

Epoch: 6| Step: 11
Training loss: 0.18445253372192383
Validation loss: 1.4615833964399112

Epoch: 6| Step: 12
Training loss: 0.20423196256160736
Validation loss: 1.4634438394218363

Epoch: 6| Step: 13
Training loss: 0.15519677102565765
Validation loss: 1.44610821623956

Epoch: 335| Step: 0
Training loss: 0.1738869547843933
Validation loss: 1.474473681501163

Epoch: 6| Step: 1
Training loss: 0.23122638463974
Validation loss: 1.4855878263391473

Epoch: 6| Step: 2
Training loss: 0.15416750311851501
Validation loss: 1.5194898343855334

Epoch: 6| Step: 3
Training loss: 0.15307195484638214
Validation loss: 1.5468873106023318

Epoch: 6| Step: 4
Training loss: 0.2138669192790985
Validation loss: 1.5745158067313574

Epoch: 6| Step: 5
Training loss: 0.2596883177757263
Validation loss: 1.5712249727659329

Epoch: 6| Step: 6
Training loss: 0.18992432951927185
Validation loss: 1.5351601698065316

Epoch: 6| Step: 7
Training loss: 0.22883009910583496
Validation loss: 1.514643387127948

Epoch: 6| Step: 8
Training loss: 0.23999765515327454
Validation loss: 1.4586577364193496

Epoch: 6| Step: 9
Training loss: 0.16310937702655792
Validation loss: 1.4652716895585418

Epoch: 6| Step: 10
Training loss: 0.20750170946121216
Validation loss: 1.4294556686955113

Epoch: 6| Step: 11
Training loss: 0.2940717935562134
Validation loss: 1.4387229540014779

Epoch: 6| Step: 12
Training loss: 0.1842496693134308
Validation loss: 1.4493157709798505

Epoch: 6| Step: 13
Training loss: 0.08836501091718674
Validation loss: 1.4350383358616983

Epoch: 336| Step: 0
Training loss: 0.15550653636455536
Validation loss: 1.4642630110504806

Epoch: 6| Step: 1
Training loss: 0.14543220400810242
Validation loss: 1.4340751619749172

Epoch: 6| Step: 2
Training loss: 0.1776842176914215
Validation loss: 1.4463037239607943

Epoch: 6| Step: 3
Training loss: 0.11921492964029312
Validation loss: 1.4846545778295046

Epoch: 6| Step: 4
Training loss: 0.12108277529478073
Validation loss: 1.4590598588348718

Epoch: 6| Step: 5
Training loss: 0.13496199250221252
Validation loss: 1.5053471865192536

Epoch: 6| Step: 6
Training loss: 0.2044534981250763
Validation loss: 1.4639988291648127

Epoch: 6| Step: 7
Training loss: 0.1319897621870041
Validation loss: 1.5001441791493406

Epoch: 6| Step: 8
Training loss: 0.2285458743572235
Validation loss: 1.5255151179529005

Epoch: 6| Step: 9
Training loss: 0.21362531185150146
Validation loss: 1.4899207827865437

Epoch: 6| Step: 10
Training loss: 0.1256653219461441
Validation loss: 1.4920292028816797

Epoch: 6| Step: 11
Training loss: 0.19340521097183228
Validation loss: 1.4450627821747974

Epoch: 6| Step: 12
Training loss: 0.0962975025177002
Validation loss: 1.4333668396037111

Epoch: 6| Step: 13
Training loss: 0.16608558595180511
Validation loss: 1.401324692592826

Epoch: 337| Step: 0
Training loss: 0.1853102743625641
Validation loss: 1.402529030076919

Epoch: 6| Step: 1
Training loss: 0.10000132024288177
Validation loss: 1.4097083730082358

Epoch: 6| Step: 2
Training loss: 0.20240728557109833
Validation loss: 1.4395263220674248

Epoch: 6| Step: 3
Training loss: 0.20537136495113373
Validation loss: 1.3853749402107731

Epoch: 6| Step: 4
Training loss: 0.11715902388095856
Validation loss: 1.4234998533802647

Epoch: 6| Step: 5
Training loss: 0.1295592039823532
Validation loss: 1.438383944572941

Epoch: 6| Step: 6
Training loss: 0.08305808901786804
Validation loss: 1.452897644812061

Epoch: 6| Step: 7
Training loss: 0.14806587994098663
Validation loss: 1.4608836955921625

Epoch: 6| Step: 8
Training loss: 0.13789060711860657
Validation loss: 1.4896474499856271

Epoch: 6| Step: 9
Training loss: 0.10641133785247803
Validation loss: 1.504462972764046

Epoch: 6| Step: 10
Training loss: 0.14241960644721985
Validation loss: 1.5112585931695917

Epoch: 6| Step: 11
Training loss: 0.22016149759292603
Validation loss: 1.52782489022901

Epoch: 6| Step: 12
Training loss: 0.15222856402397156
Validation loss: 1.5197200185509139

Epoch: 6| Step: 13
Training loss: 0.21974541246891022
Validation loss: 1.5003534247798305

Epoch: 338| Step: 0
Training loss: 0.1863194704055786
Validation loss: 1.5085374116897583

Epoch: 6| Step: 1
Training loss: 0.11620908975601196
Validation loss: 1.4825249705263364

Epoch: 6| Step: 2
Training loss: 0.1517328917980194
Validation loss: 1.45674471188617

Epoch: 6| Step: 3
Training loss: 0.06806562840938568
Validation loss: 1.429196693563974

Epoch: 6| Step: 4
Training loss: 0.14193320274353027
Validation loss: 1.4458464941670817

Epoch: 6| Step: 5
Training loss: 0.13140875101089478
Validation loss: 1.4454339063295754

Epoch: 6| Step: 6
Training loss: 0.11206415295600891
Validation loss: 1.4510249963370703

Epoch: 6| Step: 7
Training loss: 0.23554004728794098
Validation loss: 1.435925200421323

Epoch: 6| Step: 8
Training loss: 0.15744075179100037
Validation loss: 1.4606169833931872

Epoch: 6| Step: 9
Training loss: 0.186807319521904
Validation loss: 1.4736826073738836

Epoch: 6| Step: 10
Training loss: 0.1720064878463745
Validation loss: 1.503679565204087

Epoch: 6| Step: 11
Training loss: 0.15571099519729614
Validation loss: 1.5436724744817263

Epoch: 6| Step: 12
Training loss: 0.1209673136472702
Validation loss: 1.5205580265291276

Epoch: 6| Step: 13
Training loss: 0.11526017636060715
Validation loss: 1.5337418779250114

Epoch: 339| Step: 0
Training loss: 0.10026304423809052
Validation loss: 1.5459449111774404

Epoch: 6| Step: 1
Training loss: 0.18599173426628113
Validation loss: 1.5331403901500087

Epoch: 6| Step: 2
Training loss: 0.19870612025260925
Validation loss: 1.5119321461646789

Epoch: 6| Step: 3
Training loss: 0.14420601725578308
Validation loss: 1.4716013945559019

Epoch: 6| Step: 4
Training loss: 0.11444858461618423
Validation loss: 1.4141335532229433

Epoch: 6| Step: 5
Training loss: 0.17579707503318787
Validation loss: 1.4407670049257175

Epoch: 6| Step: 6
Training loss: 0.17714887857437134
Validation loss: 1.424075117675207

Epoch: 6| Step: 7
Training loss: 0.08138231933116913
Validation loss: 1.4113604163610807

Epoch: 6| Step: 8
Training loss: 0.2067755162715912
Validation loss: 1.4313966099933912

Epoch: 6| Step: 9
Training loss: 0.1560039073228836
Validation loss: 1.4022726166632868

Epoch: 6| Step: 10
Training loss: 0.1111740693449974
Validation loss: 1.420007953079798

Epoch: 6| Step: 11
Training loss: 0.19372589886188507
Validation loss: 1.44457043627257

Epoch: 6| Step: 12
Training loss: 0.06452128291130066
Validation loss: 1.4650360589386315

Epoch: 6| Step: 13
Training loss: 0.1255670040845871
Validation loss: 1.4895234902699788

Epoch: 340| Step: 0
Training loss: 0.1730794608592987
Validation loss: 1.478452403058288

Epoch: 6| Step: 1
Training loss: 0.15153276920318604
Validation loss: 1.4628649059162344

Epoch: 6| Step: 2
Training loss: 0.15397408604621887
Validation loss: 1.4685812483551681

Epoch: 6| Step: 3
Training loss: 0.11995318531990051
Validation loss: 1.4445552915655158

Epoch: 6| Step: 4
Training loss: 0.13808128237724304
Validation loss: 1.4505802021231702

Epoch: 6| Step: 5
Training loss: 0.1059701219201088
Validation loss: 1.474918729515486

Epoch: 6| Step: 6
Training loss: 0.13816827535629272
Validation loss: 1.4553517398013864

Epoch: 6| Step: 7
Training loss: 0.1661747545003891
Validation loss: 1.4441258561226629

Epoch: 6| Step: 8
Training loss: 0.14254973828792572
Validation loss: 1.4705555733814035

Epoch: 6| Step: 9
Training loss: 0.14216560125350952
Validation loss: 1.465508617380614

Epoch: 6| Step: 10
Training loss: 0.14039894938468933
Validation loss: 1.4770388577574043

Epoch: 6| Step: 11
Training loss: 0.09001930058002472
Validation loss: 1.4736831483020578

Epoch: 6| Step: 12
Training loss: 0.09851494431495667
Validation loss: 1.4839371506885817

Epoch: 6| Step: 13
Training loss: 0.12326884269714355
Validation loss: 1.5185367291973484

Epoch: 341| Step: 0
Training loss: 0.12008234113454819
Validation loss: 1.5139628571848716

Epoch: 6| Step: 1
Training loss: 0.13906162977218628
Validation loss: 1.4853612287070161

Epoch: 6| Step: 2
Training loss: 0.1164807379245758
Validation loss: 1.4963328851166593

Epoch: 6| Step: 3
Training loss: 0.16581055521965027
Validation loss: 1.459335914222143

Epoch: 6| Step: 4
Training loss: 0.1360478401184082
Validation loss: 1.4640926366211267

Epoch: 6| Step: 5
Training loss: 0.10783477127552032
Validation loss: 1.4642703776718469

Epoch: 6| Step: 6
Training loss: 0.11420129239559174
Validation loss: 1.412372617311375

Epoch: 6| Step: 7
Training loss: 0.1713232845067978
Validation loss: 1.425594582352587

Epoch: 6| Step: 8
Training loss: 0.17972347140312195
Validation loss: 1.4210142858566777

Epoch: 6| Step: 9
Training loss: 0.23980063199996948
Validation loss: 1.4301441228517922

Epoch: 6| Step: 10
Training loss: 0.10235364735126495
Validation loss: 1.4419109731592157

Epoch: 6| Step: 11
Training loss: 0.17847943305969238
Validation loss: 1.4285791766258977

Epoch: 6| Step: 12
Training loss: 0.1611996591091156
Validation loss: 1.4610712028318835

Epoch: 6| Step: 13
Training loss: 0.08828719705343246
Validation loss: 1.4610876216683337

Epoch: 342| Step: 0
Training loss: 0.1895183026790619
Validation loss: 1.4502658228720389

Epoch: 6| Step: 1
Training loss: 0.08822314441204071
Validation loss: 1.4472681976133777

Epoch: 6| Step: 2
Training loss: 0.16291873157024384
Validation loss: 1.4467559527325373

Epoch: 6| Step: 3
Training loss: 0.23523034155368805
Validation loss: 1.4749053908932594

Epoch: 6| Step: 4
Training loss: 0.20541426539421082
Validation loss: 1.4847512847633773

Epoch: 6| Step: 5
Training loss: 0.1042923629283905
Validation loss: 1.4837695065365042

Epoch: 6| Step: 6
Training loss: 0.18248251080513
Validation loss: 1.500093788229009

Epoch: 6| Step: 7
Training loss: 0.16574761271476746
Validation loss: 1.4759974697584748

Epoch: 6| Step: 8
Training loss: 0.17185509204864502
Validation loss: 1.526740231821614

Epoch: 6| Step: 9
Training loss: 0.13372594118118286
Validation loss: 1.547069573915133

Epoch: 6| Step: 10
Training loss: 0.1413571834564209
Validation loss: 1.537169377009074

Epoch: 6| Step: 11
Training loss: 0.12294977158308029
Validation loss: 1.5604095728166643

Epoch: 6| Step: 12
Training loss: 0.17338156700134277
Validation loss: 1.5322907509342316

Epoch: 6| Step: 13
Training loss: 0.29565852880477905
Validation loss: 1.5468715172941967

Epoch: 343| Step: 0
Training loss: 0.13500690460205078
Validation loss: 1.5412467500214935

Epoch: 6| Step: 1
Training loss: 0.09960775077342987
Validation loss: 1.5227736112891987

Epoch: 6| Step: 2
Training loss: 0.1726195365190506
Validation loss: 1.5152012955757879

Epoch: 6| Step: 3
Training loss: 0.11652472615242004
Validation loss: 1.484262376703242

Epoch: 6| Step: 4
Training loss: 0.13233095407485962
Validation loss: 1.4795004783138153

Epoch: 6| Step: 5
Training loss: 0.11887521296739578
Validation loss: 1.5037476324266004

Epoch: 6| Step: 6
Training loss: 0.21927569806575775
Validation loss: 1.4602159274521695

Epoch: 6| Step: 7
Training loss: 0.1380331665277481
Validation loss: 1.4731081903621714

Epoch: 6| Step: 8
Training loss: 0.2466224730014801
Validation loss: 1.454539495129739

Epoch: 6| Step: 9
Training loss: 0.16412368416786194
Validation loss: 1.4633666405113794

Epoch: 6| Step: 10
Training loss: 0.0831608846783638
Validation loss: 1.4756106151047574

Epoch: 6| Step: 11
Training loss: 0.17232200503349304
Validation loss: 1.4845465242221791

Epoch: 6| Step: 12
Training loss: 0.1307084858417511
Validation loss: 1.4950352734135044

Epoch: 6| Step: 13
Training loss: 0.23729631304740906
Validation loss: 1.5076261194803382

Epoch: 344| Step: 0
Training loss: 0.10503797978162766
Validation loss: 1.5248221351254372

Epoch: 6| Step: 1
Training loss: 0.18180489540100098
Validation loss: 1.5392373377277004

Epoch: 6| Step: 2
Training loss: 0.1337021142244339
Validation loss: 1.5300874581900976

Epoch: 6| Step: 3
Training loss: 0.1578672230243683
Validation loss: 1.5114903655103458

Epoch: 6| Step: 4
Training loss: 0.10319139063358307
Validation loss: 1.5144545724315028

Epoch: 6| Step: 5
Training loss: 0.16160428524017334
Validation loss: 1.4852453886821706

Epoch: 6| Step: 6
Training loss: 0.14817243814468384
Validation loss: 1.4778562374012445

Epoch: 6| Step: 7
Training loss: 0.25373226404190063
Validation loss: 1.517879903957408

Epoch: 6| Step: 8
Training loss: 0.10134951770305634
Validation loss: 1.508180417040343

Epoch: 6| Step: 9
Training loss: 0.12153728306293488
Validation loss: 1.5066000466705651

Epoch: 6| Step: 10
Training loss: 0.25557371973991394
Validation loss: 1.5418421273590417

Epoch: 6| Step: 11
Training loss: 0.11590062081813812
Validation loss: 1.513221082507923

Epoch: 6| Step: 12
Training loss: 0.09655674546957016
Validation loss: 1.5471344788869221

Epoch: 6| Step: 13
Training loss: 0.19957570731639862
Validation loss: 1.537560773152177

Epoch: 345| Step: 0
Training loss: 0.1928209513425827
Validation loss: 1.524966755220967

Epoch: 6| Step: 1
Training loss: 0.09726066887378693
Validation loss: 1.5187761193962508

Epoch: 6| Step: 2
Training loss: 0.14500731229782104
Validation loss: 1.5154822782803608

Epoch: 6| Step: 3
Training loss: 0.14342083036899567
Validation loss: 1.4801679247169084

Epoch: 6| Step: 4
Training loss: 0.11289694160223007
Validation loss: 1.5248478458773704

Epoch: 6| Step: 5
Training loss: 0.09037552773952484
Validation loss: 1.5373204420971613

Epoch: 6| Step: 6
Training loss: 0.137465238571167
Validation loss: 1.5469179243169806

Epoch: 6| Step: 7
Training loss: 0.13383518159389496
Validation loss: 1.5338327141218289

Epoch: 6| Step: 8
Training loss: 0.12519778311252594
Validation loss: 1.5095309852271952

Epoch: 6| Step: 9
Training loss: 0.16475577652454376
Validation loss: 1.4945601840173044

Epoch: 6| Step: 10
Training loss: 0.15957234799861908
Validation loss: 1.4629794038752073

Epoch: 6| Step: 11
Training loss: 0.14334729313850403
Validation loss: 1.4484738842133553

Epoch: 6| Step: 12
Training loss: 0.09745925664901733
Validation loss: 1.4291320975108812

Epoch: 6| Step: 13
Training loss: 0.05616727098822594
Validation loss: 1.4825076595429452

Epoch: 346| Step: 0
Training loss: 0.1625024974346161
Validation loss: 1.4736263675074424

Epoch: 6| Step: 1
Training loss: 0.18242347240447998
Validation loss: 1.448018991818992

Epoch: 6| Step: 2
Training loss: 0.1630215346813202
Validation loss: 1.484028946968817

Epoch: 6| Step: 3
Training loss: 0.20709505677223206
Validation loss: 1.4869781168558265

Epoch: 6| Step: 4
Training loss: 0.1891639232635498
Validation loss: 1.4802056345888364

Epoch: 6| Step: 5
Training loss: 0.12109000235795975
Validation loss: 1.4684344632651216

Epoch: 6| Step: 6
Training loss: 0.1090947687625885
Validation loss: 1.474520573052027

Epoch: 6| Step: 7
Training loss: 0.1937999129295349
Validation loss: 1.4819715952360502

Epoch: 6| Step: 8
Training loss: 0.28648823499679565
Validation loss: 1.4632177634905743

Epoch: 6| Step: 9
Training loss: 0.1094110980629921
Validation loss: 1.4920023987370152

Epoch: 6| Step: 10
Training loss: 0.1402207911014557
Validation loss: 1.4934836946507937

Epoch: 6| Step: 11
Training loss: 0.21181349456310272
Validation loss: 1.5015119083466069

Epoch: 6| Step: 12
Training loss: 0.12153972685337067
Validation loss: 1.4888091689796858

Epoch: 6| Step: 13
Training loss: 0.20473197102546692
Validation loss: 1.48207192138959

Epoch: 347| Step: 0
Training loss: 0.15809303522109985
Validation loss: 1.4900095590981104

Epoch: 6| Step: 1
Training loss: 0.13167379796504974
Validation loss: 1.4772539715613089

Epoch: 6| Step: 2
Training loss: 0.16187599301338196
Validation loss: 1.472216066493783

Epoch: 6| Step: 3
Training loss: 0.16127867996692657
Validation loss: 1.4766293020658596

Epoch: 6| Step: 4
Training loss: 0.14908307790756226
Validation loss: 1.4613532866201093

Epoch: 6| Step: 5
Training loss: 0.16226372122764587
Validation loss: 1.446515933159859

Epoch: 6| Step: 6
Training loss: 0.15579265356063843
Validation loss: 1.447879292631662

Epoch: 6| Step: 7
Training loss: 0.22280123829841614
Validation loss: 1.4318460328604585

Epoch: 6| Step: 8
Training loss: 0.11940480768680573
Validation loss: 1.4544284478310616

Epoch: 6| Step: 9
Training loss: 0.1351868361234665
Validation loss: 1.4703431155091973

Epoch: 6| Step: 10
Training loss: 0.15435658395290375
Validation loss: 1.5140360106704056

Epoch: 6| Step: 11
Training loss: 0.26439210772514343
Validation loss: 1.5004057262533455

Epoch: 6| Step: 12
Training loss: 0.17745594680309296
Validation loss: 1.5205875801783737

Epoch: 6| Step: 13
Training loss: 0.19585460424423218
Validation loss: 1.5374460335700744

Epoch: 348| Step: 0
Training loss: 0.23908329010009766
Validation loss: 1.538057170888429

Epoch: 6| Step: 1
Training loss: 0.178583025932312
Validation loss: 1.524269014276484

Epoch: 6| Step: 2
Training loss: 0.16129328310489655
Validation loss: 1.5249126431762532

Epoch: 6| Step: 3
Training loss: 0.13009673357009888
Validation loss: 1.524908669533268

Epoch: 6| Step: 4
Training loss: 0.11791279911994934
Validation loss: 1.5057339745183145

Epoch: 6| Step: 5
Training loss: 0.17492277920246124
Validation loss: 1.4672697397970385

Epoch: 6| Step: 6
Training loss: 0.12495778501033783
Validation loss: 1.4696456809197702

Epoch: 6| Step: 7
Training loss: 0.1666518747806549
Validation loss: 1.4557166291821388

Epoch: 6| Step: 8
Training loss: 0.16308565437793732
Validation loss: 1.4735354633741482

Epoch: 6| Step: 9
Training loss: 0.11834467947483063
Validation loss: 1.4614367074863885

Epoch: 6| Step: 10
Training loss: 0.11003319919109344
Validation loss: 1.4650700835771457

Epoch: 6| Step: 11
Training loss: 0.13660100102424622
Validation loss: 1.4854395184465634

Epoch: 6| Step: 12
Training loss: 0.19544890522956848
Validation loss: 1.5167576228418658

Epoch: 6| Step: 13
Training loss: 0.12483429908752441
Validation loss: 1.5033790296123875

Epoch: 349| Step: 0
Training loss: 0.16112980246543884
Validation loss: 1.5188128320119714

Epoch: 6| Step: 1
Training loss: 0.1159883365035057
Validation loss: 1.5185834643661336

Epoch: 6| Step: 2
Training loss: 0.1441234052181244
Validation loss: 1.5736407541459607

Epoch: 6| Step: 3
Training loss: 0.0839751735329628
Validation loss: 1.5474304332528064

Epoch: 6| Step: 4
Training loss: 0.09057725220918655
Validation loss: 1.5650477511908418

Epoch: 6| Step: 5
Training loss: 0.1414547860622406
Validation loss: 1.5550664612042007

Epoch: 6| Step: 6
Training loss: 0.1539541482925415
Validation loss: 1.5354170081435994

Epoch: 6| Step: 7
Training loss: 0.09394146502017975
Validation loss: 1.5252635337973153

Epoch: 6| Step: 8
Training loss: 0.11902552843093872
Validation loss: 1.505278327131784

Epoch: 6| Step: 9
Training loss: 0.14384013414382935
Validation loss: 1.5077421729282667

Epoch: 6| Step: 10
Training loss: 0.1684621125459671
Validation loss: 1.4757729473934378

Epoch: 6| Step: 11
Training loss: 0.20744723081588745
Validation loss: 1.463032740418629

Epoch: 6| Step: 12
Training loss: 0.1701485812664032
Validation loss: 1.462452797159072

Epoch: 6| Step: 13
Training loss: 0.08005989342927933
Validation loss: 1.428229598588841

Epoch: 350| Step: 0
Training loss: 0.1302288919687271
Validation loss: 1.4357695169346307

Epoch: 6| Step: 1
Training loss: 0.12071093916893005
Validation loss: 1.4342210472271006

Epoch: 6| Step: 2
Training loss: 0.15430058538913727
Validation loss: 1.464348436683737

Epoch: 6| Step: 3
Training loss: 0.13975998759269714
Validation loss: 1.4519044763298445

Epoch: 6| Step: 4
Training loss: 0.2018822431564331
Validation loss: 1.4475976741442116

Epoch: 6| Step: 5
Training loss: 0.17504306137561798
Validation loss: 1.5045525604678738

Epoch: 6| Step: 6
Training loss: 0.21063034236431122
Validation loss: 1.50078385555616

Epoch: 6| Step: 7
Training loss: 0.1975090503692627
Validation loss: 1.51510989217348

Epoch: 6| Step: 8
Training loss: 0.21811053156852722
Validation loss: 1.512944103569113

Epoch: 6| Step: 9
Training loss: 0.10929559171199799
Validation loss: 1.4733560136569444

Epoch: 6| Step: 10
Training loss: 0.10503346472978592
Validation loss: 1.486021068788344

Epoch: 6| Step: 11
Training loss: 0.19841119647026062
Validation loss: 1.498411637480541

Epoch: 6| Step: 12
Training loss: 0.2763744592666626
Validation loss: 1.5059753502568891

Epoch: 6| Step: 13
Training loss: 0.15075363218784332
Validation loss: 1.5063521964575655

Testing loss: 2.0343184126747977
