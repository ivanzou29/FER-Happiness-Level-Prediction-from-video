Epoch: 1| Step: 0
Training loss: 4.100649833679199
Validation loss: 5.218453186814503

Epoch: 6| Step: 1
Training loss: 3.908482551574707
Validation loss: 5.190541169976675

Epoch: 6| Step: 2
Training loss: 5.467146873474121
Validation loss: 5.165020732469456

Epoch: 6| Step: 3
Training loss: 5.936938285827637
Validation loss: 5.139093163192913

Epoch: 6| Step: 4
Training loss: 4.572699546813965
Validation loss: 5.11087199693085

Epoch: 6| Step: 5
Training loss: 4.1253662109375
Validation loss: 5.078421236366354

Epoch: 6| Step: 6
Training loss: 5.050589561462402
Validation loss: 5.041339848631171

Epoch: 6| Step: 7
Training loss: 5.322368621826172
Validation loss: 5.000405860203569

Epoch: 6| Step: 8
Training loss: 6.4818644523620605
Validation loss: 4.954835850705383

Epoch: 6| Step: 9
Training loss: 4.387907028198242
Validation loss: 4.905024836140294

Epoch: 6| Step: 10
Training loss: 4.7381978034973145
Validation loss: 4.8506170344609085

Epoch: 6| Step: 11
Training loss: 4.389558792114258
Validation loss: 4.790331999460856

Epoch: 6| Step: 12
Training loss: 3.6811797618865967
Validation loss: 4.723744310358519

Epoch: 6| Step: 13
Training loss: 4.782041549682617
Validation loss: 4.656756949681108

Epoch: 2| Step: 0
Training loss: 4.863427639007568
Validation loss: 4.582432305941018

Epoch: 6| Step: 1
Training loss: 4.92531156539917
Validation loss: 4.5072753352503625

Epoch: 6| Step: 2
Training loss: 5.008035659790039
Validation loss: 4.429246369228568

Epoch: 6| Step: 3
Training loss: 3.243347644805908
Validation loss: 4.3535704151276615

Epoch: 6| Step: 4
Training loss: 3.4933786392211914
Validation loss: 4.280002019738638

Epoch: 6| Step: 5
Training loss: 4.136038780212402
Validation loss: 4.211562156677246

Epoch: 6| Step: 6
Training loss: 3.92574405670166
Validation loss: 4.147225082561534

Epoch: 6| Step: 7
Training loss: 3.5391786098480225
Validation loss: 4.088001533221173

Epoch: 6| Step: 8
Training loss: 4.535181045532227
Validation loss: 4.033220742338447

Epoch: 6| Step: 9
Training loss: 2.923393964767456
Validation loss: 3.980869964886737

Epoch: 6| Step: 10
Training loss: 2.89392352104187
Validation loss: 3.933259687116069

Epoch: 6| Step: 11
Training loss: 4.427290439605713
Validation loss: 3.889716886704968

Epoch: 6| Step: 12
Training loss: 3.588111400604248
Validation loss: 3.848187041539018

Epoch: 6| Step: 13
Training loss: 5.016679763793945
Validation loss: 3.8037345896485033

Epoch: 3| Step: 0
Training loss: 3.2995612621307373
Validation loss: 3.761437113567065

Epoch: 6| Step: 1
Training loss: 2.960606098175049
Validation loss: 3.7173297789789017

Epoch: 6| Step: 2
Training loss: 3.692110538482666
Validation loss: 3.667665748186009

Epoch: 6| Step: 3
Training loss: 2.6136560440063477
Validation loss: 3.628700130729265

Epoch: 6| Step: 4
Training loss: 3.7795238494873047
Validation loss: 3.6009230767526934

Epoch: 6| Step: 5
Training loss: 2.229480028152466
Validation loss: 3.57912274073529

Epoch: 6| Step: 6
Training loss: 4.587282180786133
Validation loss: 3.559871214692311

Epoch: 6| Step: 7
Training loss: 3.018092155456543
Validation loss: 3.539914354201286

Epoch: 6| Step: 8
Training loss: 3.832973003387451
Validation loss: 3.522182300526609

Epoch: 6| Step: 9
Training loss: 3.0809402465820312
Validation loss: 3.504009167353312

Epoch: 6| Step: 10
Training loss: 3.9711689949035645
Validation loss: 3.494076798039098

Epoch: 6| Step: 11
Training loss: 4.029780864715576
Validation loss: 3.4745282485920894

Epoch: 6| Step: 12
Training loss: 3.748178243637085
Validation loss: 3.456727058656754

Epoch: 6| Step: 13
Training loss: 4.343337059020996
Validation loss: 3.4413514444904942

Epoch: 4| Step: 0
Training loss: 4.008793830871582
Validation loss: 3.4238683382670083

Epoch: 6| Step: 1
Training loss: 2.563845634460449
Validation loss: 3.4070218686134583

Epoch: 6| Step: 2
Training loss: 3.5168776512145996
Validation loss: 3.3974344832922823

Epoch: 6| Step: 3
Training loss: 3.016448497772217
Validation loss: 3.3820360552880073

Epoch: 6| Step: 4
Training loss: 3.314094305038452
Validation loss: 3.366853011551724

Epoch: 6| Step: 5
Training loss: 3.570586681365967
Validation loss: 3.351357780477052

Epoch: 6| Step: 6
Training loss: 3.519883632659912
Validation loss: 3.337926831296695

Epoch: 6| Step: 7
Training loss: 2.621232509613037
Validation loss: 3.3281809053113385

Epoch: 6| Step: 8
Training loss: 4.381722450256348
Validation loss: 3.3199851718000186

Epoch: 6| Step: 9
Training loss: 3.160783290863037
Validation loss: 3.309323533888786

Epoch: 6| Step: 10
Training loss: 3.567948341369629
Validation loss: 3.293358302885486

Epoch: 6| Step: 11
Training loss: 2.717071056365967
Validation loss: 3.282551496259628

Epoch: 6| Step: 12
Training loss: 3.128325939178467
Validation loss: 3.268598210427069

Epoch: 6| Step: 13
Training loss: 3.105559825897217
Validation loss: 3.2620137583824897

Epoch: 5| Step: 0
Training loss: 3.8024091720581055
Validation loss: 3.2521382506175707

Epoch: 6| Step: 1
Training loss: 3.1743030548095703
Validation loss: 3.235108624222458

Epoch: 6| Step: 2
Training loss: 3.494185447692871
Validation loss: 3.2230041514160814

Epoch: 6| Step: 3
Training loss: 3.3717284202575684
Validation loss: 3.211439101926742

Epoch: 6| Step: 4
Training loss: 3.5889439582824707
Validation loss: 3.204377697360131

Epoch: 6| Step: 5
Training loss: 3.7130985260009766
Validation loss: 3.1950061244349324

Epoch: 6| Step: 6
Training loss: 3.1110196113586426
Validation loss: 3.1838151408780004

Epoch: 6| Step: 7
Training loss: 2.7361655235290527
Validation loss: 3.1745114993023615

Epoch: 6| Step: 8
Training loss: 3.071338176727295
Validation loss: 3.1640826809790825

Epoch: 6| Step: 9
Training loss: 3.2007548809051514
Validation loss: 3.1568470616494455

Epoch: 6| Step: 10
Training loss: 2.343677520751953
Validation loss: 3.140367256697788

Epoch: 6| Step: 11
Training loss: 3.2365894317626953
Validation loss: 3.1320104675908245

Epoch: 6| Step: 12
Training loss: 2.866791009902954
Validation loss: 3.12506635983785

Epoch: 6| Step: 13
Training loss: 2.7134101390838623
Validation loss: 3.118456494423651

Epoch: 6| Step: 0
Training loss: 2.7913126945495605
Validation loss: 3.112442501129643

Epoch: 6| Step: 1
Training loss: 2.951059341430664
Validation loss: 3.103302994082051

Epoch: 6| Step: 2
Training loss: 3.1448771953582764
Validation loss: 3.094841400782267

Epoch: 6| Step: 3
Training loss: 3.2011773586273193
Validation loss: 3.0859815997462117

Epoch: 6| Step: 4
Training loss: 2.172253131866455
Validation loss: 3.078258668222735

Epoch: 6| Step: 5
Training loss: 3.153475046157837
Validation loss: 3.072469024248021

Epoch: 6| Step: 6
Training loss: 2.545672655105591
Validation loss: 3.0648457619451706

Epoch: 6| Step: 7
Training loss: 4.178926944732666
Validation loss: 3.0591946955650084

Epoch: 6| Step: 8
Training loss: 3.0224833488464355
Validation loss: 3.0503530938138246

Epoch: 6| Step: 9
Training loss: 2.8985071182250977
Validation loss: 3.0453857375729467

Epoch: 6| Step: 10
Training loss: 3.5611276626586914
Validation loss: 3.0421845195113972

Epoch: 6| Step: 11
Training loss: 3.5630064010620117
Validation loss: 3.035178474200669

Epoch: 6| Step: 12
Training loss: 3.5858163833618164
Validation loss: 3.0226679950632076

Epoch: 6| Step: 13
Training loss: 2.44602370262146
Validation loss: 3.013786656882173

Epoch: 7| Step: 0
Training loss: 2.8955087661743164
Validation loss: 3.0077772268684964

Epoch: 6| Step: 1
Training loss: 3.4491302967071533
Validation loss: 3.0049722707399757

Epoch: 6| Step: 2
Training loss: 2.300260066986084
Validation loss: 2.999662555674071

Epoch: 6| Step: 3
Training loss: 3.5895488262176514
Validation loss: 2.995780216750278

Epoch: 6| Step: 4
Training loss: 3.6867451667785645
Validation loss: 2.988379855309763

Epoch: 6| Step: 5
Training loss: 2.6400692462921143
Validation loss: 2.982361529463081

Epoch: 6| Step: 6
Training loss: 3.2935214042663574
Validation loss: 2.98026095667193

Epoch: 6| Step: 7
Training loss: 3.102543354034424
Validation loss: 2.976481801720076

Epoch: 6| Step: 8
Training loss: 1.8847813606262207
Validation loss: 2.9672477629876908

Epoch: 6| Step: 9
Training loss: 3.1374359130859375
Validation loss: 2.961441404076033

Epoch: 6| Step: 10
Training loss: 3.421046733856201
Validation loss: 2.955586561592676

Epoch: 6| Step: 11
Training loss: 2.7505764961242676
Validation loss: 2.949057181676229

Epoch: 6| Step: 12
Training loss: 3.296074628829956
Validation loss: 2.955030423338695

Epoch: 6| Step: 13
Training loss: 3.3920674324035645
Validation loss: 2.9398168492060837

Epoch: 8| Step: 0
Training loss: 2.917292356491089
Validation loss: 2.925803986928796

Epoch: 6| Step: 1
Training loss: 2.9270575046539307
Validation loss: 2.924570155400102

Epoch: 6| Step: 2
Training loss: 3.379542112350464
Validation loss: 2.9220945040384927

Epoch: 6| Step: 3
Training loss: 2.9504051208496094
Validation loss: 2.91747284448275

Epoch: 6| Step: 4
Training loss: 2.014008045196533
Validation loss: 2.9041832980289253

Epoch: 6| Step: 5
Training loss: 3.4918017387390137
Validation loss: 2.9010362932758946

Epoch: 6| Step: 6
Training loss: 3.3746376037597656
Validation loss: 2.8927136749349613

Epoch: 6| Step: 7
Training loss: 2.972667694091797
Validation loss: 2.8830675232794976

Epoch: 6| Step: 8
Training loss: 3.1649935245513916
Validation loss: 2.879545780920213

Epoch: 6| Step: 9
Training loss: 2.770718812942505
Validation loss: 2.8767523201563026

Epoch: 6| Step: 10
Training loss: 3.399768829345703
Validation loss: 2.8691594011040142

Epoch: 6| Step: 11
Training loss: 3.3285775184631348
Validation loss: 2.857218632134058

Epoch: 6| Step: 12
Training loss: 1.6080292463302612
Validation loss: 2.8504603139815794

Epoch: 6| Step: 13
Training loss: 4.006165504455566
Validation loss: 2.8509529124024096

Epoch: 9| Step: 0
Training loss: 2.679924964904785
Validation loss: 2.846117050417008

Epoch: 6| Step: 1
Training loss: 2.7495100498199463
Validation loss: 2.839220900689402

Epoch: 6| Step: 2
Training loss: 3.7400522232055664
Validation loss: 2.829231790317002

Epoch: 6| Step: 3
Training loss: 2.769287586212158
Validation loss: 2.824499758340979

Epoch: 6| Step: 4
Training loss: 3.440943717956543
Validation loss: 2.8271992129664265

Epoch: 6| Step: 5
Training loss: 2.0620288848876953
Validation loss: 2.8156414929256646

Epoch: 6| Step: 6
Training loss: 2.3777151107788086
Validation loss: 2.8136402099363265

Epoch: 6| Step: 7
Training loss: 3.357603073120117
Validation loss: 2.818456203706803

Epoch: 6| Step: 8
Training loss: 3.201035499572754
Validation loss: 2.807755531803254

Epoch: 6| Step: 9
Training loss: 2.8252406120300293
Validation loss: 2.802298222818682

Epoch: 6| Step: 10
Training loss: 3.203450918197632
Validation loss: 2.801100387368151

Epoch: 6| Step: 11
Training loss: 2.7517940998077393
Validation loss: 2.8029424054648286

Epoch: 6| Step: 12
Training loss: 3.2878036499023438
Validation loss: 2.7940861999347644

Epoch: 6| Step: 13
Training loss: 2.7084572315216064
Validation loss: 2.7940412029143302

Epoch: 10| Step: 0
Training loss: 2.8213119506835938
Validation loss: 2.793585220972697

Epoch: 6| Step: 1
Training loss: 1.9555506706237793
Validation loss: 2.7978413822830364

Epoch: 6| Step: 2
Training loss: 2.999594211578369
Validation loss: 2.7972381320050967

Epoch: 6| Step: 3
Training loss: 2.740950107574463
Validation loss: 2.79884603459348

Epoch: 6| Step: 4
Training loss: 3.3855535984039307
Validation loss: 2.795882078909105

Epoch: 6| Step: 5
Training loss: 3.668018341064453
Validation loss: 2.78791828309336

Epoch: 6| Step: 6
Training loss: 2.299675464630127
Validation loss: 2.783674575949228

Epoch: 6| Step: 7
Training loss: 3.0385191440582275
Validation loss: 2.777866609634892

Epoch: 6| Step: 8
Training loss: 2.895369052886963
Validation loss: 2.7727565483380388

Epoch: 6| Step: 9
Training loss: 3.4083757400512695
Validation loss: 2.7702936228885444

Epoch: 6| Step: 10
Training loss: 2.831587553024292
Validation loss: 2.7698594267650316

Epoch: 6| Step: 11
Training loss: 2.6928577423095703
Validation loss: 2.774497434657107

Epoch: 6| Step: 12
Training loss: 2.994663715362549
Validation loss: 2.76260204469004

Epoch: 6| Step: 13
Training loss: 3.3202028274536133
Validation loss: 2.759010809724049

Epoch: 11| Step: 0
Training loss: 3.5312931537628174
Validation loss: 2.7621255420869395

Epoch: 6| Step: 1
Training loss: 3.1326305866241455
Validation loss: 2.7634948299777125

Epoch: 6| Step: 2
Training loss: 3.098417282104492
Validation loss: 2.763946548584969

Epoch: 6| Step: 3
Training loss: 2.475721836090088
Validation loss: 2.749844274213237

Epoch: 6| Step: 4
Training loss: 2.7825207710266113
Validation loss: 2.749185974879931

Epoch: 6| Step: 5
Training loss: 2.5707921981811523
Validation loss: 2.7478152577595045

Epoch: 6| Step: 6
Training loss: 2.6779727935791016
Validation loss: 2.751995094360844

Epoch: 6| Step: 7
Training loss: 2.851027488708496
Validation loss: 2.7469742990309194

Epoch: 6| Step: 8
Training loss: 2.6316521167755127
Validation loss: 2.74223723975561

Epoch: 6| Step: 9
Training loss: 3.676892042160034
Validation loss: 2.7377465463453725

Epoch: 6| Step: 10
Training loss: 2.5183613300323486
Validation loss: 2.7337028070162703

Epoch: 6| Step: 11
Training loss: 2.782650947570801
Validation loss: 2.778750927217545

Epoch: 6| Step: 12
Training loss: 2.9047746658325195
Validation loss: 2.73608628396065

Epoch: 6| Step: 13
Training loss: 3.08646559715271
Validation loss: 2.7328536407921904

Epoch: 12| Step: 0
Training loss: 2.527789831161499
Validation loss: 2.7374955120907036

Epoch: 6| Step: 1
Training loss: 3.0535547733306885
Validation loss: 2.741486026394752

Epoch: 6| Step: 2
Training loss: 3.6632513999938965
Validation loss: 2.7512239435667634

Epoch: 6| Step: 3
Training loss: 3.521494150161743
Validation loss: 2.739835177698443

Epoch: 6| Step: 4
Training loss: 2.315086841583252
Validation loss: 2.7339602772907545

Epoch: 6| Step: 5
Training loss: 2.490846872329712
Validation loss: 2.7300587187531176

Epoch: 6| Step: 6
Training loss: 2.337303638458252
Validation loss: 2.7297576704332904

Epoch: 6| Step: 7
Training loss: 3.645486831665039
Validation loss: 2.7286050447853665

Epoch: 6| Step: 8
Training loss: 3.1619160175323486
Validation loss: 2.732484825195805

Epoch: 6| Step: 9
Training loss: 2.4076826572418213
Validation loss: 2.72409253222968

Epoch: 6| Step: 10
Training loss: 2.7182159423828125
Validation loss: 2.720743517721853

Epoch: 6| Step: 11
Training loss: 2.792264938354492
Validation loss: 2.7167781142778296

Epoch: 6| Step: 12
Training loss: 2.7824740409851074
Validation loss: 2.7171617118261193

Epoch: 6| Step: 13
Training loss: 3.1663424968719482
Validation loss: 2.7157790635221746

Epoch: 13| Step: 0
Training loss: 3.030653238296509
Validation loss: 2.715328739535424

Epoch: 6| Step: 1
Training loss: 3.471860647201538
Validation loss: 2.7127794937420915

Epoch: 6| Step: 2
Training loss: 3.328841209411621
Validation loss: 2.7096217729712047

Epoch: 6| Step: 3
Training loss: 2.393709659576416
Validation loss: 2.7100040553718485

Epoch: 6| Step: 4
Training loss: 2.6002018451690674
Validation loss: 2.705818501851892

Epoch: 6| Step: 5
Training loss: 2.6379289627075195
Validation loss: 2.704675110437537

Epoch: 6| Step: 6
Training loss: 2.1901118755340576
Validation loss: 2.704311260613062

Epoch: 6| Step: 7
Training loss: 3.062528610229492
Validation loss: 2.7021239931865404

Epoch: 6| Step: 8
Training loss: 3.212235450744629
Validation loss: 2.7015610048847813

Epoch: 6| Step: 9
Training loss: 3.3412091732025146
Validation loss: 2.7031466653270106

Epoch: 6| Step: 10
Training loss: 2.8282835483551025
Validation loss: 2.708033541197418

Epoch: 6| Step: 11
Training loss: 2.6590778827667236
Validation loss: 2.7116995498698246

Epoch: 6| Step: 12
Training loss: 2.7508978843688965
Validation loss: 2.706137047019056

Epoch: 6| Step: 13
Training loss: 2.6250100135803223
Validation loss: 2.6959917750409854

Epoch: 14| Step: 0
Training loss: 2.8651809692382812
Validation loss: 2.695034219372657

Epoch: 6| Step: 1
Training loss: 2.704435110092163
Validation loss: 2.6941073145917667

Epoch: 6| Step: 2
Training loss: 2.739297866821289
Validation loss: 2.6947192145932104

Epoch: 6| Step: 3
Training loss: 3.261471748352051
Validation loss: 2.692926460696805

Epoch: 6| Step: 4
Training loss: 3.557495594024658
Validation loss: 2.690435540291571

Epoch: 6| Step: 5
Training loss: 2.0882327556610107
Validation loss: 2.6898494843513734

Epoch: 6| Step: 6
Training loss: 3.7379660606384277
Validation loss: 2.6908763890625327

Epoch: 6| Step: 7
Training loss: 2.612804651260376
Validation loss: 2.6903782941961802

Epoch: 6| Step: 8
Training loss: 2.0845789909362793
Validation loss: 2.6934386171320432

Epoch: 6| Step: 9
Training loss: 2.622640371322632
Validation loss: 2.6915234250407063

Epoch: 6| Step: 10
Training loss: 3.0656750202178955
Validation loss: 2.687133212243357

Epoch: 6| Step: 11
Training loss: 3.105368137359619
Validation loss: 2.6878049758172806

Epoch: 6| Step: 12
Training loss: 2.9874706268310547
Validation loss: 2.685563148990754

Epoch: 6| Step: 13
Training loss: 2.4772074222564697
Validation loss: 2.684729342819542

Epoch: 15| Step: 0
Training loss: 2.6578803062438965
Validation loss: 2.6870863822198685

Epoch: 6| Step: 1
Training loss: 3.2554492950439453
Validation loss: 2.687947170708769

Epoch: 6| Step: 2
Training loss: 2.2222537994384766
Validation loss: 2.6830189971513647

Epoch: 6| Step: 3
Training loss: 3.591505527496338
Validation loss: 2.6818863243185063

Epoch: 6| Step: 4
Training loss: 2.5521745681762695
Validation loss: 2.677598737901257

Epoch: 6| Step: 5
Training loss: 2.215522289276123
Validation loss: 2.675696962623186

Epoch: 6| Step: 6
Training loss: 3.3031930923461914
Validation loss: 2.6759555314176824

Epoch: 6| Step: 7
Training loss: 3.207097291946411
Validation loss: 2.6723750868151264

Epoch: 6| Step: 8
Training loss: 3.3049263954162598
Validation loss: 2.674539037930068

Epoch: 6| Step: 9
Training loss: 3.2819159030914307
Validation loss: 2.6709604622215353

Epoch: 6| Step: 10
Training loss: 3.0290377140045166
Validation loss: 2.67642238063197

Epoch: 6| Step: 11
Training loss: 2.1825027465820312
Validation loss: 2.6905671934927664

Epoch: 6| Step: 12
Training loss: 2.553065538406372
Validation loss: 2.696545554745582

Epoch: 6| Step: 13
Training loss: 2.362882137298584
Validation loss: 2.6956222006069717

Epoch: 16| Step: 0
Training loss: 2.587181568145752
Validation loss: 2.67802418175564

Epoch: 6| Step: 1
Training loss: 2.51715087890625
Validation loss: 2.6672143884884414

Epoch: 6| Step: 2
Training loss: 2.930145740509033
Validation loss: 2.667893389219879

Epoch: 6| Step: 3
Training loss: 3.8049654960632324
Validation loss: 2.6724362552806897

Epoch: 6| Step: 4
Training loss: 3.321882724761963
Validation loss: 2.67600421238971

Epoch: 6| Step: 5
Training loss: 2.8290257453918457
Validation loss: 2.6665945078736994

Epoch: 6| Step: 6
Training loss: 2.2902023792266846
Validation loss: 2.664955646761002

Epoch: 6| Step: 7
Training loss: 2.8368759155273438
Validation loss: 2.6603479334103164

Epoch: 6| Step: 8
Training loss: 2.893312454223633
Validation loss: 2.6639420447811

Epoch: 6| Step: 9
Training loss: 2.1538119316101074
Validation loss: 2.669700120085029

Epoch: 6| Step: 10
Training loss: 3.589014768600464
Validation loss: 2.6717600360993417

Epoch: 6| Step: 11
Training loss: 2.0993716716766357
Validation loss: 2.686192589421426

Epoch: 6| Step: 12
Training loss: 3.1168713569641113
Validation loss: 2.7114110582618305

Epoch: 6| Step: 13
Training loss: 2.933040142059326
Validation loss: 2.6675116451837684

Epoch: 17| Step: 0
Training loss: 2.7131295204162598
Validation loss: 2.6571664656362226

Epoch: 6| Step: 1
Training loss: 2.480072021484375
Validation loss: 2.6563348206140662

Epoch: 6| Step: 2
Training loss: 3.153170585632324
Validation loss: 2.660968775390297

Epoch: 6| Step: 3
Training loss: 2.8288073539733887
Validation loss: 2.6668670946551907

Epoch: 6| Step: 4
Training loss: 3.0667636394500732
Validation loss: 2.684319890955443

Epoch: 6| Step: 5
Training loss: 3.019881248474121
Validation loss: 2.6565102633609565

Epoch: 6| Step: 6
Training loss: 2.4704885482788086
Validation loss: 2.6520246472409976

Epoch: 6| Step: 7
Training loss: 3.4348161220550537
Validation loss: 2.649119997537264

Epoch: 6| Step: 8
Training loss: 2.7923593521118164
Validation loss: 2.6547014918378604

Epoch: 6| Step: 9
Training loss: 3.148280143737793
Validation loss: 2.6624342677413777

Epoch: 6| Step: 10
Training loss: 2.8934168815612793
Validation loss: 2.6940643351565123

Epoch: 6| Step: 11
Training loss: 2.61686372756958
Validation loss: 2.701031418256862

Epoch: 6| Step: 12
Training loss: 2.3969483375549316
Validation loss: 2.6569504173853065

Epoch: 6| Step: 13
Training loss: 2.8237695693969727
Validation loss: 2.641688557081325

Epoch: 18| Step: 0
Training loss: 2.6350831985473633
Validation loss: 2.6415094508919665

Epoch: 6| Step: 1
Training loss: 2.4783387184143066
Validation loss: 2.671024009745608

Epoch: 6| Step: 2
Training loss: 2.985710382461548
Validation loss: 2.71295077313659

Epoch: 6| Step: 3
Training loss: 2.374603509902954
Validation loss: 2.719707040376561

Epoch: 6| Step: 4
Training loss: 2.4556713104248047
Validation loss: 2.6720182793114775

Epoch: 6| Step: 5
Training loss: 2.671473979949951
Validation loss: 2.653997044409475

Epoch: 6| Step: 6
Training loss: 2.2441999912261963
Validation loss: 2.641117021601687

Epoch: 6| Step: 7
Training loss: 3.6123342514038086
Validation loss: 2.643365801021617

Epoch: 6| Step: 8
Training loss: 3.5377087593078613
Validation loss: 2.6428532933676117

Epoch: 6| Step: 9
Training loss: 2.4780147075653076
Validation loss: 2.6432041070794545

Epoch: 6| Step: 10
Training loss: 2.788487434387207
Validation loss: 2.6401632165396087

Epoch: 6| Step: 11
Training loss: 3.809512138366699
Validation loss: 2.647030709892191

Epoch: 6| Step: 12
Training loss: 3.292140483856201
Validation loss: 2.658599950933969

Epoch: 6| Step: 13
Training loss: 2.053363800048828
Validation loss: 2.641989346473448

Epoch: 19| Step: 0
Training loss: 2.2037341594696045
Validation loss: 2.6388757331396944

Epoch: 6| Step: 1
Training loss: 2.9336764812469482
Validation loss: 2.63082197917405

Epoch: 6| Step: 2
Training loss: 2.682037353515625
Validation loss: 2.6300391868878434

Epoch: 6| Step: 3
Training loss: 3.4263193607330322
Validation loss: 2.625771640449442

Epoch: 6| Step: 4
Training loss: 3.4261972904205322
Validation loss: 2.62359453785804

Epoch: 6| Step: 5
Training loss: 2.8237714767456055
Validation loss: 2.62139214751541

Epoch: 6| Step: 6
Training loss: 2.823664903640747
Validation loss: 2.619447059528802

Epoch: 6| Step: 7
Training loss: 3.4583420753479004
Validation loss: 2.618424561715895

Epoch: 6| Step: 8
Training loss: 2.646087408065796
Validation loss: 2.6198584059233307

Epoch: 6| Step: 9
Training loss: 1.8429672718048096
Validation loss: 2.6171898739312285

Epoch: 6| Step: 10
Training loss: 2.8943634033203125
Validation loss: 2.6160302059624785

Epoch: 6| Step: 11
Training loss: 2.6663997173309326
Validation loss: 2.6222568763199674

Epoch: 6| Step: 12
Training loss: 3.214060068130493
Validation loss: 2.622022990257509

Epoch: 6| Step: 13
Training loss: 2.1841111183166504
Validation loss: 2.62150086638748

Epoch: 20| Step: 0
Training loss: 2.2122268676757812
Validation loss: 2.6143663211535384

Epoch: 6| Step: 1
Training loss: 2.926525115966797
Validation loss: 2.6142250696818032

Epoch: 6| Step: 2
Training loss: 2.8348164558410645
Validation loss: 2.6168174230924217

Epoch: 6| Step: 3
Training loss: 2.58243727684021
Validation loss: 2.6173275286151516

Epoch: 6| Step: 4
Training loss: 2.5358147621154785
Validation loss: 2.6180871276445288

Epoch: 6| Step: 5
Training loss: 3.2051663398742676
Validation loss: 2.611858085919452

Epoch: 6| Step: 6
Training loss: 2.8501505851745605
Validation loss: 2.6094170539609847

Epoch: 6| Step: 7
Training loss: 2.865553855895996
Validation loss: 2.610325159565095

Epoch: 6| Step: 8
Training loss: 2.609861373901367
Validation loss: 2.6065218628093763

Epoch: 6| Step: 9
Training loss: 2.810696601867676
Validation loss: 2.6061040509131645

Epoch: 6| Step: 10
Training loss: 1.681570291519165
Validation loss: 2.6050865932177474

Epoch: 6| Step: 11
Training loss: 3.030824661254883
Validation loss: 2.604799239866195

Epoch: 6| Step: 12
Training loss: 4.644750118255615
Validation loss: 2.60318322079156

Epoch: 6| Step: 13
Training loss: 2.2928922176361084
Validation loss: 2.606262050649171

Epoch: 21| Step: 0
Training loss: 2.536668539047241
Validation loss: 2.605560892371721

Epoch: 6| Step: 1
Training loss: 3.2354443073272705
Validation loss: 2.6166706418478363

Epoch: 6| Step: 2
Training loss: 2.2317399978637695
Validation loss: 2.670542396524901

Epoch: 6| Step: 3
Training loss: 3.6361265182495117
Validation loss: 2.6984194709408666

Epoch: 6| Step: 4
Training loss: 2.6537556648254395
Validation loss: 2.6439168299398115

Epoch: 6| Step: 5
Training loss: 3.0624165534973145
Validation loss: 2.6022021693568074

Epoch: 6| Step: 6
Training loss: 2.2281363010406494
Validation loss: 2.6016152110151065

Epoch: 6| Step: 7
Training loss: 3.8485264778137207
Validation loss: 2.630464458978304

Epoch: 6| Step: 8
Training loss: 2.8663530349731445
Validation loss: 2.609445846208962

Epoch: 6| Step: 9
Training loss: 3.0822529792785645
Validation loss: 2.605970034035303

Epoch: 6| Step: 10
Training loss: 1.9427874088287354
Validation loss: 2.6116128993290726

Epoch: 6| Step: 11
Training loss: 2.3116934299468994
Validation loss: 2.6744148474867626

Epoch: 6| Step: 12
Training loss: 3.040219306945801
Validation loss: 2.687459320150396

Epoch: 6| Step: 13
Training loss: 3.101818323135376
Validation loss: 2.615864041031048

Epoch: 22| Step: 0
Training loss: 3.4709343910217285
Validation loss: 2.591534688908567

Epoch: 6| Step: 1
Training loss: 2.6039211750030518
Validation loss: 2.5987340481050554

Epoch: 6| Step: 2
Training loss: 2.744318962097168
Validation loss: 2.62919347516952

Epoch: 6| Step: 3
Training loss: 1.9482152462005615
Validation loss: 2.654060322751281

Epoch: 6| Step: 4
Training loss: 3.595658779144287
Validation loss: 2.705825223717638

Epoch: 6| Step: 5
Training loss: 2.5092339515686035
Validation loss: 2.6674295240832913

Epoch: 6| Step: 6
Training loss: 2.6322357654571533
Validation loss: 2.6396994898396153

Epoch: 6| Step: 7
Training loss: 2.942134141921997
Validation loss: 2.6324724202514975

Epoch: 6| Step: 8
Training loss: 3.1055991649627686
Validation loss: 2.627269611563734

Epoch: 6| Step: 9
Training loss: 3.2100815773010254
Validation loss: 2.6356223142275246

Epoch: 6| Step: 10
Training loss: 2.3822598457336426
Validation loss: 2.6283805319058

Epoch: 6| Step: 11
Training loss: 2.8299005031585693
Validation loss: 2.626315265573481

Epoch: 6| Step: 12
Training loss: 2.814697742462158
Validation loss: 2.6334639364673245

Epoch: 6| Step: 13
Training loss: 2.73531436920166
Validation loss: 2.6261878962157876

Epoch: 23| Step: 0
Training loss: 2.8075408935546875
Validation loss: 2.6043141016396145

Epoch: 6| Step: 1
Training loss: 3.0309062004089355
Validation loss: 2.60091971581982

Epoch: 6| Step: 2
Training loss: 3.2320454120635986
Validation loss: 2.5948451385703137

Epoch: 6| Step: 3
Training loss: 3.0552332401275635
Validation loss: 2.5878317715019308

Epoch: 6| Step: 4
Training loss: 2.9403867721557617
Validation loss: 2.5869642970382527

Epoch: 6| Step: 5
Training loss: 2.492033004760742
Validation loss: 2.58163522904919

Epoch: 6| Step: 6
Training loss: 2.9657540321350098
Validation loss: 2.5790013497875584

Epoch: 6| Step: 7
Training loss: 3.3919050693511963
Validation loss: 2.583891576336276

Epoch: 6| Step: 8
Training loss: 2.522167444229126
Validation loss: 2.582776347796122

Epoch: 6| Step: 9
Training loss: 2.6738126277923584
Validation loss: 2.581168725926389

Epoch: 6| Step: 10
Training loss: 2.3903560638427734
Validation loss: 2.578586386096093

Epoch: 6| Step: 11
Training loss: 2.5242555141448975
Validation loss: 2.578360885702154

Epoch: 6| Step: 12
Training loss: 2.4988865852355957
Validation loss: 2.5731700312706733

Epoch: 6| Step: 13
Training loss: 2.3142731189727783
Validation loss: 2.5737523673683085

Epoch: 24| Step: 0
Training loss: 2.4906258583068848
Validation loss: 2.572276238472231

Epoch: 6| Step: 1
Training loss: 2.878505229949951
Validation loss: 2.5726815167293755

Epoch: 6| Step: 2
Training loss: 3.2973473072052
Validation loss: 2.5667270178435952

Epoch: 6| Step: 3
Training loss: 2.2432119846343994
Validation loss: 2.5671244257239887

Epoch: 6| Step: 4
Training loss: 2.2018749713897705
Validation loss: 2.5649378350985947

Epoch: 6| Step: 5
Training loss: 3.3629212379455566
Validation loss: 2.56455575009828

Epoch: 6| Step: 6
Training loss: 2.6141276359558105
Validation loss: 2.5638886113320627

Epoch: 6| Step: 7
Training loss: 2.9258930683135986
Validation loss: 2.566668196391034

Epoch: 6| Step: 8
Training loss: 2.4389264583587646
Validation loss: 2.565785695147771

Epoch: 6| Step: 9
Training loss: 3.3191347122192383
Validation loss: 2.565418709990799

Epoch: 6| Step: 10
Training loss: 2.9239373207092285
Validation loss: 2.5579621484202724

Epoch: 6| Step: 11
Training loss: 3.084423542022705
Validation loss: 2.5552232470563663

Epoch: 6| Step: 12
Training loss: 2.5031189918518066
Validation loss: 2.555294441920455

Epoch: 6| Step: 13
Training loss: 2.2340638637542725
Validation loss: 2.5587478068567093

Epoch: 25| Step: 0
Training loss: 2.976228952407837
Validation loss: 2.5605175546420518

Epoch: 6| Step: 1
Training loss: 2.115079164505005
Validation loss: 2.558177707015827

Epoch: 6| Step: 2
Training loss: 2.8167080879211426
Validation loss: 2.5649515095577446

Epoch: 6| Step: 3
Training loss: 2.709207534790039
Validation loss: 2.566016415114044

Epoch: 6| Step: 4
Training loss: 2.318941116333008
Validation loss: 2.5610557807389127

Epoch: 6| Step: 5
Training loss: 3.583129644393921
Validation loss: 2.5491707837709816

Epoch: 6| Step: 6
Training loss: 1.7713048458099365
Validation loss: 2.5472815741774855

Epoch: 6| Step: 7
Training loss: 3.643493175506592
Validation loss: 2.556259145018875

Epoch: 6| Step: 8
Training loss: 2.295593738555908
Validation loss: 2.556402160275367

Epoch: 6| Step: 9
Training loss: 3.406947135925293
Validation loss: 2.5597275969802693

Epoch: 6| Step: 10
Training loss: 2.688406467437744
Validation loss: 2.561467447588521

Epoch: 6| Step: 11
Training loss: 3.11037540435791
Validation loss: 2.5471561134502454

Epoch: 6| Step: 12
Training loss: 2.3173370361328125
Validation loss: 2.546597106482393

Epoch: 6| Step: 13
Training loss: 3.1780357360839844
Validation loss: 2.5434175229841665

Epoch: 26| Step: 0
Training loss: 3.0741279125213623
Validation loss: 2.546807478832942

Epoch: 6| Step: 1
Training loss: 2.5613203048706055
Validation loss: 2.56233367612285

Epoch: 6| Step: 2
Training loss: 2.7432384490966797
Validation loss: 2.569502768977996

Epoch: 6| Step: 3
Training loss: 3.030520439147949
Validation loss: 2.553423386748119

Epoch: 6| Step: 4
Training loss: 2.499880075454712
Validation loss: 2.546891261172551

Epoch: 6| Step: 5
Training loss: 2.390363931655884
Validation loss: 2.543885456618442

Epoch: 6| Step: 6
Training loss: 2.946732997894287
Validation loss: 2.538631903227939

Epoch: 6| Step: 7
Training loss: 2.786881685256958
Validation loss: 2.5372596299776466

Epoch: 6| Step: 8
Training loss: 2.4867959022521973
Validation loss: 2.538292349025767

Epoch: 6| Step: 9
Training loss: 2.166623592376709
Validation loss: 2.5489645465727775

Epoch: 6| Step: 10
Training loss: 2.8179025650024414
Validation loss: 2.540409977718066

Epoch: 6| Step: 11
Training loss: 3.313265800476074
Validation loss: 2.5386224228848695

Epoch: 6| Step: 12
Training loss: 3.055598020553589
Validation loss: 2.538392997557117

Epoch: 6| Step: 13
Training loss: 2.5782299041748047
Validation loss: 2.5396064327609156

Epoch: 27| Step: 0
Training loss: 2.870607852935791
Validation loss: 2.5360681574831725

Epoch: 6| Step: 1
Training loss: 2.820997714996338
Validation loss: 2.53593357147709

Epoch: 6| Step: 2
Training loss: 2.4338154792785645
Validation loss: 2.5348613031448854

Epoch: 6| Step: 3
Training loss: 2.0186543464660645
Validation loss: 2.5356534604103333

Epoch: 6| Step: 4
Training loss: 2.5578670501708984
Validation loss: 2.53665752051979

Epoch: 6| Step: 5
Training loss: 3.0831198692321777
Validation loss: 2.537151663534103

Epoch: 6| Step: 6
Training loss: 2.851358413696289
Validation loss: 2.5401019588593514

Epoch: 6| Step: 7
Training loss: 2.8306894302368164
Validation loss: 2.5391670196287093

Epoch: 6| Step: 8
Training loss: 3.583695888519287
Validation loss: 2.5419216412369923

Epoch: 6| Step: 9
Training loss: 2.727522373199463
Validation loss: 2.532938280413228

Epoch: 6| Step: 10
Training loss: 2.8028275966644287
Validation loss: 2.5304431146191013

Epoch: 6| Step: 11
Training loss: 2.2631144523620605
Validation loss: 2.528365178774762

Epoch: 6| Step: 12
Training loss: 2.937256336212158
Validation loss: 2.5271452601237963

Epoch: 6| Step: 13
Training loss: 2.4781782627105713
Validation loss: 2.5247689549640944

Epoch: 28| Step: 0
Training loss: 2.604701042175293
Validation loss: 2.523790292842414

Epoch: 6| Step: 1
Training loss: 2.409883737564087
Validation loss: 2.524158905911189

Epoch: 6| Step: 2
Training loss: 2.277637481689453
Validation loss: 2.5275295472914174

Epoch: 6| Step: 3
Training loss: 2.48494815826416
Validation loss: 2.529322270424135

Epoch: 6| Step: 4
Training loss: 3.130133628845215
Validation loss: 2.5329867280939573

Epoch: 6| Step: 5
Training loss: 2.3020904064178467
Validation loss: 2.5269782773910032

Epoch: 6| Step: 6
Training loss: 2.7456862926483154
Validation loss: 2.5255538417446997

Epoch: 6| Step: 7
Training loss: 2.5931215286254883
Validation loss: 2.526544165867631

Epoch: 6| Step: 8
Training loss: 3.241584300994873
Validation loss: 2.5271179214600594

Epoch: 6| Step: 9
Training loss: 2.713364839553833
Validation loss: 2.5202586804666827

Epoch: 6| Step: 10
Training loss: 3.05192232131958
Validation loss: 2.5200993527648268

Epoch: 6| Step: 11
Training loss: 3.3869216442108154
Validation loss: 2.5203937304917203

Epoch: 6| Step: 12
Training loss: 2.766380786895752
Validation loss: 2.519812627505231

Epoch: 6| Step: 13
Training loss: 2.3325393199920654
Validation loss: 2.5262815516482116

Epoch: 29| Step: 0
Training loss: 2.9814798831939697
Validation loss: 2.5317114245507026

Epoch: 6| Step: 1
Training loss: 2.7884368896484375
Validation loss: 2.526993397743471

Epoch: 6| Step: 2
Training loss: 3.2502665519714355
Validation loss: 2.5335313376560005

Epoch: 6| Step: 3
Training loss: 3.058603286743164
Validation loss: 2.5324439233349216

Epoch: 6| Step: 4
Training loss: 3.2792558670043945
Validation loss: 2.522701681301158

Epoch: 6| Step: 5
Training loss: 3.1332030296325684
Validation loss: 2.518125118747834

Epoch: 6| Step: 6
Training loss: 2.259674072265625
Validation loss: 2.5108216962506695

Epoch: 6| Step: 7
Training loss: 2.6279714107513428
Validation loss: 2.5125705016556608

Epoch: 6| Step: 8
Training loss: 1.8056676387786865
Validation loss: 2.512426189197007

Epoch: 6| Step: 9
Training loss: 3.202988386154175
Validation loss: 2.5082806976892615

Epoch: 6| Step: 10
Training loss: 3.0579729080200195
Validation loss: 2.507961288575203

Epoch: 6| Step: 11
Training loss: 1.855625867843628
Validation loss: 2.507782572059221

Epoch: 6| Step: 12
Training loss: 2.1008830070495605
Validation loss: 2.5072411875570975

Epoch: 6| Step: 13
Training loss: 2.7710580825805664
Validation loss: 2.517890694320843

Epoch: 30| Step: 0
Training loss: 3.0612707138061523
Validation loss: 2.525627456685548

Epoch: 6| Step: 1
Training loss: 2.5291290283203125
Validation loss: 2.5368281461859263

Epoch: 6| Step: 2
Training loss: 2.3720953464508057
Validation loss: 2.5176436772910495

Epoch: 6| Step: 3
Training loss: 2.433856248855591
Validation loss: 2.5149904476699008

Epoch: 6| Step: 4
Training loss: 2.662104368209839
Validation loss: 2.513300816218058

Epoch: 6| Step: 5
Training loss: 2.9922707080841064
Validation loss: 2.517328926312026

Epoch: 6| Step: 6
Training loss: 2.756626844406128
Validation loss: 2.5128054439380603

Epoch: 6| Step: 7
Training loss: 1.882291555404663
Validation loss: 2.5021124014290432

Epoch: 6| Step: 8
Training loss: 2.53364896774292
Validation loss: 2.493534162480344

Epoch: 6| Step: 9
Training loss: 2.7326064109802246
Validation loss: 2.4963159125338317

Epoch: 6| Step: 10
Training loss: 3.8107542991638184
Validation loss: 2.497361634367256

Epoch: 6| Step: 11
Training loss: 2.940011501312256
Validation loss: 2.5025767190482027

Epoch: 6| Step: 12
Training loss: 2.825706958770752
Validation loss: 2.503427351674726

Epoch: 6| Step: 13
Training loss: 2.353728771209717
Validation loss: 2.5044936262151247

Epoch: 31| Step: 0
Training loss: 1.9658823013305664
Validation loss: 2.509775807780604

Epoch: 6| Step: 1
Training loss: 2.9139652252197266
Validation loss: 2.5211669911620436

Epoch: 6| Step: 2
Training loss: 1.8851449489593506
Validation loss: 2.5266244693468978

Epoch: 6| Step: 3
Training loss: 3.631857395172119
Validation loss: 2.5413653337827293

Epoch: 6| Step: 4
Training loss: 2.631913185119629
Validation loss: 2.548108939201601

Epoch: 6| Step: 5
Training loss: 2.9884586334228516
Validation loss: 2.5283384707666214

Epoch: 6| Step: 6
Training loss: 2.5478787422180176
Validation loss: 2.50599766290316

Epoch: 6| Step: 7
Training loss: 2.400794744491577
Validation loss: 2.491830572005241

Epoch: 6| Step: 8
Training loss: 2.3964905738830566
Validation loss: 2.487985457143476

Epoch: 6| Step: 9
Training loss: 2.9162821769714355
Validation loss: 2.4936231554195447

Epoch: 6| Step: 10
Training loss: 2.6077656745910645
Validation loss: 2.5191816770902244

Epoch: 6| Step: 11
Training loss: 3.01216459274292
Validation loss: 2.5528086923783824

Epoch: 6| Step: 12
Training loss: 3.3296725749969482
Validation loss: 2.5112464222856747

Epoch: 6| Step: 13
Training loss: 2.8449463844299316
Validation loss: 2.495255870203818

Epoch: 32| Step: 0
Training loss: 2.2813639640808105
Validation loss: 2.4914221302155526

Epoch: 6| Step: 1
Training loss: 3.1204288005828857
Validation loss: 2.4942813868163736

Epoch: 6| Step: 2
Training loss: 2.8356001377105713
Validation loss: 2.50273286655385

Epoch: 6| Step: 3
Training loss: 2.629128932952881
Validation loss: 2.4979992887025237

Epoch: 6| Step: 4
Training loss: 3.1112043857574463
Validation loss: 2.5010790619798886

Epoch: 6| Step: 5
Training loss: 2.900054454803467
Validation loss: 2.5065102218299784

Epoch: 6| Step: 6
Training loss: 2.208225727081299
Validation loss: 2.5157160502608105

Epoch: 6| Step: 7
Training loss: 2.640866279602051
Validation loss: 2.521480102692881

Epoch: 6| Step: 8
Training loss: 2.2713265419006348
Validation loss: 2.539117779783023

Epoch: 6| Step: 9
Training loss: 3.311328172683716
Validation loss: 2.530071384163313

Epoch: 6| Step: 10
Training loss: 2.985466957092285
Validation loss: 2.523589047052527

Epoch: 6| Step: 11
Training loss: 2.3582112789154053
Validation loss: 2.5094935996558076

Epoch: 6| Step: 12
Training loss: 2.152533531188965
Validation loss: 2.49506571215968

Epoch: 6| Step: 13
Training loss: 3.406635284423828
Validation loss: 2.4914690166391353

Epoch: 33| Step: 0
Training loss: 2.7977285385131836
Validation loss: 2.487376715547295

Epoch: 6| Step: 1
Training loss: 1.8529865741729736
Validation loss: 2.4843165541207917

Epoch: 6| Step: 2
Training loss: 2.770129680633545
Validation loss: 2.494505415680588

Epoch: 6| Step: 3
Training loss: 2.665987968444824
Validation loss: 2.5025165901389173

Epoch: 6| Step: 4
Training loss: 2.7865090370178223
Validation loss: 2.5051029728304957

Epoch: 6| Step: 5
Training loss: 3.3254873752593994
Validation loss: 2.4979959021332445

Epoch: 6| Step: 6
Training loss: 2.5396876335144043
Validation loss: 2.489334624300721

Epoch: 6| Step: 7
Training loss: 2.5531601905822754
Validation loss: 2.4898221569676555

Epoch: 6| Step: 8
Training loss: 2.5192418098449707
Validation loss: 2.49388878063489

Epoch: 6| Step: 9
Training loss: 2.614821672439575
Validation loss: 2.498131139304048

Epoch: 6| Step: 10
Training loss: 2.3190064430236816
Validation loss: 2.4943350027966242

Epoch: 6| Step: 11
Training loss: 3.4797580242156982
Validation loss: 2.4904992964959916

Epoch: 6| Step: 12
Training loss: 3.107247829437256
Validation loss: 2.500641128068329

Epoch: 6| Step: 13
Training loss: 2.7799699306488037
Validation loss: 2.4994457665310112

Epoch: 34| Step: 0
Training loss: 2.3981008529663086
Validation loss: 2.483028542610907

Epoch: 6| Step: 1
Training loss: 3.2421867847442627
Validation loss: 2.486238823142103

Epoch: 6| Step: 2
Training loss: 1.945823311805725
Validation loss: 2.4808778224452848

Epoch: 6| Step: 3
Training loss: 1.6856049299240112
Validation loss: 2.4938602396236953

Epoch: 6| Step: 4
Training loss: 2.6673099994659424
Validation loss: 2.5023735261732534

Epoch: 6| Step: 5
Training loss: 2.9383749961853027
Validation loss: 2.500831106657623

Epoch: 6| Step: 6
Training loss: 3.456550121307373
Validation loss: 2.4984088918214202

Epoch: 6| Step: 7
Training loss: 3.009115219116211
Validation loss: 2.490409920292516

Epoch: 6| Step: 8
Training loss: 3.42989444732666
Validation loss: 2.4919270366750736

Epoch: 6| Step: 9
Training loss: 2.4674549102783203
Validation loss: 2.4873921307184363

Epoch: 6| Step: 10
Training loss: 2.701725482940674
Validation loss: 2.4893212574784473

Epoch: 6| Step: 11
Training loss: 2.801835775375366
Validation loss: 2.5081034245029574

Epoch: 6| Step: 12
Training loss: 2.182631492614746
Validation loss: 2.5090655639607418

Epoch: 6| Step: 13
Training loss: 2.892971992492676
Validation loss: 2.477436298965126

Epoch: 35| Step: 0
Training loss: 2.5686118602752686
Validation loss: 2.4829651258325063

Epoch: 6| Step: 1
Training loss: 2.215479612350464
Validation loss: 2.483496435226933

Epoch: 6| Step: 2
Training loss: 2.7025794982910156
Validation loss: 2.4778858359142015

Epoch: 6| Step: 3
Training loss: 2.8334403038024902
Validation loss: 2.479815608711653

Epoch: 6| Step: 4
Training loss: 2.80429744720459
Validation loss: 2.479282486823297

Epoch: 6| Step: 5
Training loss: 1.943442463874817
Validation loss: 2.489461091256911

Epoch: 6| Step: 6
Training loss: 3.023951530456543
Validation loss: 2.4964612453214583

Epoch: 6| Step: 7
Training loss: 2.6369545459747314
Validation loss: 2.5040671774136123

Epoch: 6| Step: 8
Training loss: 3.511944532394409
Validation loss: 2.498617841351417

Epoch: 6| Step: 9
Training loss: 3.1332342624664307
Validation loss: 2.4801963811279624

Epoch: 6| Step: 10
Training loss: 2.8238179683685303
Validation loss: 2.4656386888155373

Epoch: 6| Step: 11
Training loss: 3.0713846683502197
Validation loss: 2.459603414740614

Epoch: 6| Step: 12
Training loss: 2.180604934692383
Validation loss: 2.4551688394238873

Epoch: 6| Step: 13
Training loss: 1.812645435333252
Validation loss: 2.454457857275522

Epoch: 36| Step: 0
Training loss: 2.702629804611206
Validation loss: 2.4527826924477854

Epoch: 6| Step: 1
Training loss: 2.04840087890625
Validation loss: 2.4502259198055474

Epoch: 6| Step: 2
Training loss: 2.6041440963745117
Validation loss: 2.4501534892666723

Epoch: 6| Step: 3
Training loss: 3.4784462451934814
Validation loss: 2.4864419096259662

Epoch: 6| Step: 4
Training loss: 2.8399603366851807
Validation loss: 2.492806680740849

Epoch: 6| Step: 5
Training loss: 3.3673808574676514
Validation loss: 2.5145188685386413

Epoch: 6| Step: 6
Training loss: 3.133902072906494
Validation loss: 2.5269967638036257

Epoch: 6| Step: 7
Training loss: 2.475944995880127
Validation loss: 2.525666129204535

Epoch: 6| Step: 8
Training loss: 2.857125759124756
Validation loss: 2.5191009788103003

Epoch: 6| Step: 9
Training loss: 3.114978313446045
Validation loss: 2.515617165514218

Epoch: 6| Step: 10
Training loss: 2.1229398250579834
Validation loss: 2.5162918618930283

Epoch: 6| Step: 11
Training loss: 2.1290111541748047
Validation loss: 2.5113769141576623

Epoch: 6| Step: 12
Training loss: 2.5884029865264893
Validation loss: 2.5093280897345593

Epoch: 6| Step: 13
Training loss: 2.2740161418914795
Validation loss: 2.5136387373811457

Epoch: 37| Step: 0
Training loss: 2.7657217979431152
Validation loss: 2.5104824086671234

Epoch: 6| Step: 1
Training loss: 2.393078327178955
Validation loss: 2.5068657500769502

Epoch: 6| Step: 2
Training loss: 3.3536996841430664
Validation loss: 2.5051198954223306

Epoch: 6| Step: 3
Training loss: 3.3789029121398926
Validation loss: 2.5074899119715535

Epoch: 6| Step: 4
Training loss: 2.977778911590576
Validation loss: 2.5116126639868623

Epoch: 6| Step: 5
Training loss: 2.3515195846557617
Validation loss: 2.5087943205269436

Epoch: 6| Step: 6
Training loss: 2.057504653930664
Validation loss: 2.5192973536829792

Epoch: 6| Step: 7
Training loss: 1.9667308330535889
Validation loss: 2.505497455596924

Epoch: 6| Step: 8
Training loss: 3.376236915588379
Validation loss: 2.5104751586914062

Epoch: 6| Step: 9
Training loss: 3.392047882080078
Validation loss: 2.5172244220651607

Epoch: 6| Step: 10
Training loss: 2.7380800247192383
Validation loss: 2.5079840331949215

Epoch: 6| Step: 11
Training loss: 2.000284433364868
Validation loss: 2.4971792133905555

Epoch: 6| Step: 12
Training loss: 2.5919229984283447
Validation loss: 2.5007857789275465

Epoch: 6| Step: 13
Training loss: 2.2895615100860596
Validation loss: 2.50666570150724

Epoch: 38| Step: 0
Training loss: 3.065882682800293
Validation loss: 2.51604038669217

Epoch: 6| Step: 1
Training loss: 2.533738613128662
Validation loss: 2.5246731824772333

Epoch: 6| Step: 2
Training loss: 2.600597858428955
Validation loss: 2.517701700169553

Epoch: 6| Step: 3
Training loss: 2.4492053985595703
Validation loss: 2.5115561844200216

Epoch: 6| Step: 4
Training loss: 2.6684257984161377
Validation loss: 2.5025555523492957

Epoch: 6| Step: 5
Training loss: 2.734865665435791
Validation loss: 2.4957079195207164

Epoch: 6| Step: 6
Training loss: 1.4826923608779907
Validation loss: 2.4955539190641014

Epoch: 6| Step: 7
Training loss: 2.8669254779815674
Validation loss: 2.487884026701732

Epoch: 6| Step: 8
Training loss: 3.251281261444092
Validation loss: 2.4882912481984785

Epoch: 6| Step: 9
Training loss: 2.704477071762085
Validation loss: 2.4906366563612417

Epoch: 6| Step: 10
Training loss: 2.9944443702697754
Validation loss: 2.4927649805622716

Epoch: 6| Step: 11
Training loss: 2.6907780170440674
Validation loss: 2.4954358839219615

Epoch: 6| Step: 12
Training loss: 2.541205406188965
Validation loss: 2.4946667686585458

Epoch: 6| Step: 13
Training loss: 3.3786823749542236
Validation loss: 2.500188304531959

Epoch: 39| Step: 0
Training loss: 2.8176350593566895
Validation loss: 2.495222017329226

Epoch: 6| Step: 1
Training loss: 2.4753293991088867
Validation loss: 2.4878670605280067

Epoch: 6| Step: 2
Training loss: 2.7653350830078125
Validation loss: 2.4840570290883384

Epoch: 6| Step: 3
Training loss: 2.6830296516418457
Validation loss: 2.479182712493404

Epoch: 6| Step: 4
Training loss: 2.676426410675049
Validation loss: 2.4795172599054154

Epoch: 6| Step: 5
Training loss: 2.6167962551116943
Validation loss: 2.4807475356645483

Epoch: 6| Step: 6
Training loss: 3.0023672580718994
Validation loss: 2.4789653542221233

Epoch: 6| Step: 7
Training loss: 2.572509288787842
Validation loss: 2.4833482106526694

Epoch: 6| Step: 8
Training loss: 2.7134809494018555
Validation loss: 2.4889921296027397

Epoch: 6| Step: 9
Training loss: 2.3261187076568604
Validation loss: 2.488590407115157

Epoch: 6| Step: 10
Training loss: 2.987234592437744
Validation loss: 2.490142271082888

Epoch: 6| Step: 11
Training loss: 2.0285613536834717
Validation loss: 2.4804615436061734

Epoch: 6| Step: 12
Training loss: 2.8423426151275635
Validation loss: 2.4761493744388705

Epoch: 6| Step: 13
Training loss: 3.519261360168457
Validation loss: 2.48123977773933

Epoch: 40| Step: 0
Training loss: 3.771984100341797
Validation loss: 2.4820099671681723

Epoch: 6| Step: 1
Training loss: 2.4908828735351562
Validation loss: 2.4812609021381666

Epoch: 6| Step: 2
Training loss: 3.0087409019470215
Validation loss: 2.4762897850364767

Epoch: 6| Step: 3
Training loss: 2.1171367168426514
Validation loss: 2.472651676465106

Epoch: 6| Step: 4
Training loss: 2.475278377532959
Validation loss: 2.472210386747955

Epoch: 6| Step: 5
Training loss: 2.6416122913360596
Validation loss: 2.4699990492995068

Epoch: 6| Step: 6
Training loss: 2.4250752925872803
Validation loss: 2.467383615432247

Epoch: 6| Step: 7
Training loss: 1.7439347505569458
Validation loss: 2.4671333118151595

Epoch: 6| Step: 8
Training loss: 2.7619314193725586
Validation loss: 2.4702189609568608

Epoch: 6| Step: 9
Training loss: 3.0229837894439697
Validation loss: 2.476412832096059

Epoch: 6| Step: 10
Training loss: 3.4272704124450684
Validation loss: 2.48113682962233

Epoch: 6| Step: 11
Training loss: 3.064603805541992
Validation loss: 2.482739847193482

Epoch: 6| Step: 12
Training loss: 1.7885082960128784
Validation loss: 2.4777209322939635

Epoch: 6| Step: 13
Training loss: 2.853598117828369
Validation loss: 2.4711432226242556

Epoch: 41| Step: 0
Training loss: 3.315319538116455
Validation loss: 2.4743369010186966

Epoch: 6| Step: 1
Training loss: 3.0406546592712402
Validation loss: 2.472154909564603

Epoch: 6| Step: 2
Training loss: 3.189587354660034
Validation loss: 2.4773287542404665

Epoch: 6| Step: 3
Training loss: 2.555600881576538
Validation loss: 2.5020513483273086

Epoch: 6| Step: 4
Training loss: 2.7720518112182617
Validation loss: 2.5220703309582126

Epoch: 6| Step: 5
Training loss: 2.341226577758789
Validation loss: 2.509277477059313

Epoch: 6| Step: 6
Training loss: 2.392733097076416
Validation loss: 2.4872922999884493

Epoch: 6| Step: 7
Training loss: 2.235407590866089
Validation loss: 2.4633534800621772

Epoch: 6| Step: 8
Training loss: 1.8100440502166748
Validation loss: 2.458783421465146

Epoch: 6| Step: 9
Training loss: 3.2069106101989746
Validation loss: 2.4592153910667665

Epoch: 6| Step: 10
Training loss: 2.812997341156006
Validation loss: 2.465785975097328

Epoch: 6| Step: 11
Training loss: 2.88287353515625
Validation loss: 2.475066690034764

Epoch: 6| Step: 12
Training loss: 2.48710298538208
Validation loss: 2.469557087908509

Epoch: 6| Step: 13
Training loss: 2.6098811626434326
Validation loss: 2.4588572876427763

Epoch: 42| Step: 0
Training loss: 2.952415943145752
Validation loss: 2.457889555602945

Epoch: 6| Step: 1
Training loss: 1.7803239822387695
Validation loss: 2.4576058541574786

Epoch: 6| Step: 2
Training loss: 2.9517431259155273
Validation loss: 2.4607622418352353

Epoch: 6| Step: 3
Training loss: 2.111908435821533
Validation loss: 2.481081324238931

Epoch: 6| Step: 4
Training loss: 3.005516529083252
Validation loss: 2.5292490528475855

Epoch: 6| Step: 5
Training loss: 1.996068000793457
Validation loss: 2.5593621705168035

Epoch: 6| Step: 6
Training loss: 3.113980770111084
Validation loss: 2.5964872298702115

Epoch: 6| Step: 7
Training loss: 3.1376094818115234
Validation loss: 2.5682498075628795

Epoch: 6| Step: 8
Training loss: 2.7327842712402344
Validation loss: 2.4985957504600607

Epoch: 6| Step: 9
Training loss: 2.8480048179626465
Validation loss: 2.4614488668339227

Epoch: 6| Step: 10
Training loss: 3.219513416290283
Validation loss: 2.452376014442854

Epoch: 6| Step: 11
Training loss: 2.3784470558166504
Validation loss: 2.4421020784685687

Epoch: 6| Step: 12
Training loss: 2.780426025390625
Validation loss: 2.4713079288441646

Epoch: 6| Step: 13
Training loss: 3.0208580493927
Validation loss: 2.5952149129682973

Epoch: 43| Step: 0
Training loss: 3.0638561248779297
Validation loss: 2.5493550992781118

Epoch: 6| Step: 1
Training loss: 2.021488904953003
Validation loss: 2.4830583090423257

Epoch: 6| Step: 2
Training loss: 2.2550196647644043
Validation loss: 2.4431756055483254

Epoch: 6| Step: 3
Training loss: 2.7054150104522705
Validation loss: 2.411277991469188

Epoch: 6| Step: 4
Training loss: 2.6090197563171387
Validation loss: 2.3934233932084936

Epoch: 6| Step: 5
Training loss: 2.8563554286956787
Validation loss: 2.386975513991489

Epoch: 6| Step: 6
Training loss: 2.683868885040283
Validation loss: 2.3853741666322112

Epoch: 6| Step: 7
Training loss: 2.6609861850738525
Validation loss: 2.4235129535839124

Epoch: 6| Step: 8
Training loss: 2.6669468879699707
Validation loss: 2.4488745197173087

Epoch: 6| Step: 9
Training loss: 3.232279062271118
Validation loss: 2.4255649582032235

Epoch: 6| Step: 10
Training loss: 3.0142650604248047
Validation loss: 2.4177024108107372

Epoch: 6| Step: 11
Training loss: 2.6795055866241455
Validation loss: 2.40014563837359

Epoch: 6| Step: 12
Training loss: 2.707756280899048
Validation loss: 2.3968840491387153

Epoch: 6| Step: 13
Training loss: 2.1853928565979004
Validation loss: 2.39073775147879

Epoch: 44| Step: 0
Training loss: 3.5844202041625977
Validation loss: 2.394393023624215

Epoch: 6| Step: 1
Training loss: 3.117978096008301
Validation loss: 2.385708280788955

Epoch: 6| Step: 2
Training loss: 3.243791103363037
Validation loss: 2.3814990956296205

Epoch: 6| Step: 3
Training loss: 2.310159206390381
Validation loss: 2.3835987532010643

Epoch: 6| Step: 4
Training loss: 2.457919120788574
Validation loss: 2.3766448241408153

Epoch: 6| Step: 5
Training loss: 3.118814706802368
Validation loss: 2.3725361670217207

Epoch: 6| Step: 6
Training loss: 2.042816400527954
Validation loss: 2.372226586905859

Epoch: 6| Step: 7
Training loss: 2.4113211631774902
Validation loss: 2.3736546783037085

Epoch: 6| Step: 8
Training loss: 2.777707099914551
Validation loss: 2.373996393654936

Epoch: 6| Step: 9
Training loss: 2.9452953338623047
Validation loss: 2.3715011509515906

Epoch: 6| Step: 10
Training loss: 2.5347251892089844
Validation loss: 2.3713100238512923

Epoch: 6| Step: 11
Training loss: 1.6372754573822021
Validation loss: 2.3791141484373357

Epoch: 6| Step: 12
Training loss: 2.4184861183166504
Validation loss: 2.388301013618387

Epoch: 6| Step: 13
Training loss: 2.2441558837890625
Validation loss: 2.412400209775535

Epoch: 45| Step: 0
Training loss: 1.8558597564697266
Validation loss: 2.4090377515362156

Epoch: 6| Step: 1
Training loss: 2.3963663578033447
Validation loss: 2.407219330469767

Epoch: 6| Step: 2
Training loss: 3.4116177558898926
Validation loss: 2.4100306623725483

Epoch: 6| Step: 3
Training loss: 2.7730093002319336
Validation loss: 2.3939036861542733

Epoch: 6| Step: 4
Training loss: 2.1499645709991455
Validation loss: 2.394892866893481

Epoch: 6| Step: 5
Training loss: 3.2780702114105225
Validation loss: 2.394775272697531

Epoch: 6| Step: 6
Training loss: 2.4365010261535645
Validation loss: 2.410328226704751

Epoch: 6| Step: 7
Training loss: 3.251262903213501
Validation loss: 2.429237534922938

Epoch: 6| Step: 8
Training loss: 2.5255491733551025
Validation loss: 2.4151829955398396

Epoch: 6| Step: 9
Training loss: 2.8083481788635254
Validation loss: 2.39586135648912

Epoch: 6| Step: 10
Training loss: 2.628474712371826
Validation loss: 2.371917388772452

Epoch: 6| Step: 11
Training loss: 2.4061031341552734
Validation loss: 2.366872056838005

Epoch: 6| Step: 12
Training loss: 2.3459277153015137
Validation loss: 2.3757507724146687

Epoch: 6| Step: 13
Training loss: 2.881957769393921
Validation loss: 2.383926337765109

Epoch: 46| Step: 0
Training loss: 3.703939437866211
Validation loss: 2.364842289237566

Epoch: 6| Step: 1
Training loss: 2.915518283843994
Validation loss: 2.365876909225218

Epoch: 6| Step: 2
Training loss: 2.3895249366760254
Validation loss: 2.379292695753036

Epoch: 6| Step: 3
Training loss: 3.1507351398468018
Validation loss: 2.4011896271859445

Epoch: 6| Step: 4
Training loss: 2.6744143962860107
Validation loss: 2.4354826763112056

Epoch: 6| Step: 5
Training loss: 3.164719581604004
Validation loss: 2.4031729826363186

Epoch: 6| Step: 6
Training loss: 2.2266221046447754
Validation loss: 2.401428717438893

Epoch: 6| Step: 7
Training loss: 2.610836982727051
Validation loss: 2.3866756885282454

Epoch: 6| Step: 8
Training loss: 2.117029905319214
Validation loss: 2.3855980211688625

Epoch: 6| Step: 9
Training loss: 2.359518527984619
Validation loss: 2.3780409853945494

Epoch: 6| Step: 10
Training loss: 2.5181334018707275
Validation loss: 2.3813867645878948

Epoch: 6| Step: 11
Training loss: 2.3663511276245117
Validation loss: 2.38560143850183

Epoch: 6| Step: 12
Training loss: 2.1716537475585938
Validation loss: 2.404364016748244

Epoch: 6| Step: 13
Training loss: 2.357771873474121
Validation loss: 2.438491923834688

Epoch: 47| Step: 0
Training loss: 2.402986526489258
Validation loss: 2.4470203845731673

Epoch: 6| Step: 1
Training loss: 2.0629024505615234
Validation loss: 2.4288969578281527

Epoch: 6| Step: 2
Training loss: 2.7513976097106934
Validation loss: 2.417916477367442

Epoch: 6| Step: 3
Training loss: 2.1922218799591064
Validation loss: 2.3916757824600383

Epoch: 6| Step: 4
Training loss: 3.048316478729248
Validation loss: 2.3825080471654094

Epoch: 6| Step: 5
Training loss: 2.635420799255371
Validation loss: 2.373208804797101

Epoch: 6| Step: 6
Training loss: 2.7630910873413086
Validation loss: 2.3716210639604958

Epoch: 6| Step: 7
Training loss: 2.1908018589019775
Validation loss: 2.363194161845792

Epoch: 6| Step: 8
Training loss: 2.1724579334259033
Validation loss: 2.360405545080862

Epoch: 6| Step: 9
Training loss: 2.904827117919922
Validation loss: 2.3559304898785007

Epoch: 6| Step: 10
Training loss: 2.16127347946167
Validation loss: 2.3551934355048725

Epoch: 6| Step: 11
Training loss: 3.504730224609375
Validation loss: 2.3521075351263887

Epoch: 6| Step: 12
Training loss: 3.104228973388672
Validation loss: 2.3436078666358866

Epoch: 6| Step: 13
Training loss: 2.6628825664520264
Validation loss: 2.3377843544047368

Epoch: 48| Step: 0
Training loss: 1.860731840133667
Validation loss: 2.33750831952659

Epoch: 6| Step: 1
Training loss: 2.432065010070801
Validation loss: 2.3410435261264926

Epoch: 6| Step: 2
Training loss: 2.859689235687256
Validation loss: 2.343426881297942

Epoch: 6| Step: 3
Training loss: 3.185640335083008
Validation loss: 2.3613336983547417

Epoch: 6| Step: 4
Training loss: 2.9607443809509277
Validation loss: 2.3966821419295443

Epoch: 6| Step: 5
Training loss: 2.6777849197387695
Validation loss: 2.432833510060464

Epoch: 6| Step: 6
Training loss: 2.628323793411255
Validation loss: 2.421334460217466

Epoch: 6| Step: 7
Training loss: 2.277000904083252
Validation loss: 2.402291444040114

Epoch: 6| Step: 8
Training loss: 2.0341689586639404
Validation loss: 2.3838309831516717

Epoch: 6| Step: 9
Training loss: 2.489633083343506
Validation loss: 2.3769635359446206

Epoch: 6| Step: 10
Training loss: 3.3011293411254883
Validation loss: 2.371467269876952

Epoch: 6| Step: 11
Training loss: 2.4478020668029785
Validation loss: 2.3719358187849804

Epoch: 6| Step: 12
Training loss: 2.7159934043884277
Validation loss: 2.3692605790271553

Epoch: 6| Step: 13
Training loss: 3.38846755027771
Validation loss: 2.3764190314918436

Epoch: 49| Step: 0
Training loss: 2.7305660247802734
Validation loss: 2.3729918977265716

Epoch: 6| Step: 1
Training loss: 3.169640302658081
Validation loss: 2.375003889042844

Epoch: 6| Step: 2
Training loss: 2.281860828399658
Validation loss: 2.375630171068253

Epoch: 6| Step: 3
Training loss: 2.7446892261505127
Validation loss: 2.374231938392885

Epoch: 6| Step: 4
Training loss: 2.915360450744629
Validation loss: 2.374068696011779

Epoch: 6| Step: 5
Training loss: 2.912217617034912
Validation loss: 2.3726119866935154

Epoch: 6| Step: 6
Training loss: 2.558378219604492
Validation loss: 2.3702146327623757

Epoch: 6| Step: 7
Training loss: 2.560760736465454
Validation loss: 2.3670006926341722

Epoch: 6| Step: 8
Training loss: 2.717587471008301
Validation loss: 2.368659128424942

Epoch: 6| Step: 9
Training loss: 3.2646260261535645
Validation loss: 2.375579677602296

Epoch: 6| Step: 10
Training loss: 2.9020938873291016
Validation loss: 2.374373116800862

Epoch: 6| Step: 11
Training loss: 1.7135781049728394
Validation loss: 2.382214679512926

Epoch: 6| Step: 12
Training loss: 1.5791394710540771
Validation loss: 2.384865694148566

Epoch: 6| Step: 13
Training loss: 2.715236186981201
Validation loss: 2.3944790260766142

Epoch: 50| Step: 0
Training loss: 2.2688028812408447
Validation loss: 2.389962319404848

Epoch: 6| Step: 1
Training loss: 2.797159433364868
Validation loss: 2.3848323347747966

Epoch: 6| Step: 2
Training loss: 2.607398509979248
Validation loss: 2.373170901370305

Epoch: 6| Step: 3
Training loss: 2.6084671020507812
Validation loss: 2.3758557483714116

Epoch: 6| Step: 4
Training loss: 2.713876724243164
Validation loss: 2.3789552386089037

Epoch: 6| Step: 5
Training loss: 3.2946157455444336
Validation loss: 2.36552402024628

Epoch: 6| Step: 6
Training loss: 2.4107861518859863
Validation loss: 2.3611649697826755

Epoch: 6| Step: 7
Training loss: 2.356628894805908
Validation loss: 2.360246835216399

Epoch: 6| Step: 8
Training loss: 3.0461294651031494
Validation loss: 2.359710047321935

Epoch: 6| Step: 9
Training loss: 2.842691421508789
Validation loss: 2.3584240610881517

Epoch: 6| Step: 10
Training loss: 2.7743310928344727
Validation loss: 2.359165791542299

Epoch: 6| Step: 11
Training loss: 2.2938129901885986
Validation loss: 2.3565319532989175

Epoch: 6| Step: 12
Training loss: 2.4669814109802246
Validation loss: 2.356696626191498

Epoch: 6| Step: 13
Training loss: 2.2300989627838135
Validation loss: 2.3530586329839562

Epoch: 51| Step: 0
Training loss: 2.500049352645874
Validation loss: 2.356406307989551

Epoch: 6| Step: 1
Training loss: 2.6110806465148926
Validation loss: 2.3625471668858684

Epoch: 6| Step: 2
Training loss: 2.2807486057281494
Validation loss: 2.3823382021278463

Epoch: 6| Step: 3
Training loss: 3.0990257263183594
Validation loss: 2.4008470222514164

Epoch: 6| Step: 4
Training loss: 2.397733211517334
Validation loss: 2.4760757646253033

Epoch: 6| Step: 5
Training loss: 2.7277638912200928
Validation loss: 2.5494036956499984

Epoch: 6| Step: 6
Training loss: 2.4063668251037598
Validation loss: 2.5910791786768104

Epoch: 6| Step: 7
Training loss: 3.678582191467285
Validation loss: 2.584823695562219

Epoch: 6| Step: 8
Training loss: 2.622469186782837
Validation loss: 2.542846941178845

Epoch: 6| Step: 9
Training loss: 2.870196580886841
Validation loss: 2.4780279590237524

Epoch: 6| Step: 10
Training loss: 2.108757972717285
Validation loss: 2.405223423434842

Epoch: 6| Step: 11
Training loss: 2.1446831226348877
Validation loss: 2.367451351176026

Epoch: 6| Step: 12
Training loss: 2.85227370262146
Validation loss: 2.3621409849453996

Epoch: 6| Step: 13
Training loss: 2.9933927059173584
Validation loss: 2.3495293971030944

Epoch: 52| Step: 0
Training loss: 2.281649589538574
Validation loss: 2.339440191945722

Epoch: 6| Step: 1
Training loss: 2.77058744430542
Validation loss: 2.330641444011401

Epoch: 6| Step: 2
Training loss: 2.2124881744384766
Validation loss: 2.3373699444596485

Epoch: 6| Step: 3
Training loss: 2.480039119720459
Validation loss: 2.3430794990190895

Epoch: 6| Step: 4
Training loss: 2.0536317825317383
Validation loss: 2.3498183655482467

Epoch: 6| Step: 5
Training loss: 2.0669326782226562
Validation loss: 2.352227287907754

Epoch: 6| Step: 6
Training loss: 2.7188022136688232
Validation loss: 2.350291887919108

Epoch: 6| Step: 7
Training loss: 3.238341808319092
Validation loss: 2.3436347182079027

Epoch: 6| Step: 8
Training loss: 2.9621071815490723
Validation loss: 2.3263906150735836

Epoch: 6| Step: 9
Training loss: 3.000537395477295
Validation loss: 2.3321626699098976

Epoch: 6| Step: 10
Training loss: 3.4722180366516113
Validation loss: 2.337587553967712

Epoch: 6| Step: 11
Training loss: 2.102116346359253
Validation loss: 2.3307362576966644

Epoch: 6| Step: 12
Training loss: 2.8324105739593506
Validation loss: 2.3393834175602084

Epoch: 6| Step: 13
Training loss: 2.143092393875122
Validation loss: 2.3597257509026477

Epoch: 53| Step: 0
Training loss: 2.5597758293151855
Validation loss: 2.356733610553126

Epoch: 6| Step: 1
Training loss: 2.4775352478027344
Validation loss: 2.3602094086267615

Epoch: 6| Step: 2
Training loss: 2.6139535903930664
Validation loss: 2.3381137783809374

Epoch: 6| Step: 3
Training loss: 3.008481502532959
Validation loss: 2.335689167822561

Epoch: 6| Step: 4
Training loss: 2.608914852142334
Validation loss: 2.329585479151818

Epoch: 6| Step: 5
Training loss: 2.4609951972961426
Validation loss: 2.32820188870994

Epoch: 6| Step: 6
Training loss: 2.476897954940796
Validation loss: 2.3342009052153556

Epoch: 6| Step: 7
Training loss: 2.569207191467285
Validation loss: 2.3287121454874673

Epoch: 6| Step: 8
Training loss: 2.308616876602173
Validation loss: 2.3201357215963383

Epoch: 6| Step: 9
Training loss: 2.5884599685668945
Validation loss: 2.3247448731494207

Epoch: 6| Step: 10
Training loss: 2.9443862438201904
Validation loss: 2.3195629299327893

Epoch: 6| Step: 11
Training loss: 2.338376522064209
Validation loss: 2.3149198998687086

Epoch: 6| Step: 12
Training loss: 2.3361425399780273
Validation loss: 2.310777835948493

Epoch: 6| Step: 13
Training loss: 3.185137987136841
Validation loss: 2.316127005443778

Epoch: 54| Step: 0
Training loss: 2.7052671909332275
Validation loss: 2.308638841875138

Epoch: 6| Step: 1
Training loss: 2.1281771659851074
Validation loss: 2.3002036694557435

Epoch: 6| Step: 2
Training loss: 2.8859496116638184
Validation loss: 2.297556516944721

Epoch: 6| Step: 3
Training loss: 3.252768039703369
Validation loss: 2.298396069516418

Epoch: 6| Step: 4
Training loss: 2.4458413124084473
Validation loss: 2.2984951439724175

Epoch: 6| Step: 5
Training loss: 2.2189149856567383
Validation loss: 2.299797027341781

Epoch: 6| Step: 6
Training loss: 2.781055450439453
Validation loss: 2.298556971293624

Epoch: 6| Step: 7
Training loss: 2.624687671661377
Validation loss: 2.290596039064469

Epoch: 6| Step: 8
Training loss: 2.0787596702575684
Validation loss: 2.294849944371049

Epoch: 6| Step: 9
Training loss: 2.973870277404785
Validation loss: 2.2929016697791313

Epoch: 6| Step: 10
Training loss: 2.4555158615112305
Validation loss: 2.294784338243546

Epoch: 6| Step: 11
Training loss: 2.401798963546753
Validation loss: 2.297731658463837

Epoch: 6| Step: 12
Training loss: 2.984370231628418
Validation loss: 2.3019511545858076

Epoch: 6| Step: 13
Training loss: 2.087947368621826
Validation loss: 2.3000736672391175

Epoch: 55| Step: 0
Training loss: 2.346467971801758
Validation loss: 2.3266512578533542

Epoch: 6| Step: 1
Training loss: 2.5114245414733887
Validation loss: 2.3654432886390278

Epoch: 6| Step: 2
Training loss: 2.963225841522217
Validation loss: 2.4053272867715485

Epoch: 6| Step: 3
Training loss: 2.4554529190063477
Validation loss: 2.3979083581637313

Epoch: 6| Step: 4
Training loss: 2.7990922927856445
Validation loss: 2.383402204000822

Epoch: 6| Step: 5
Training loss: 3.111919403076172
Validation loss: 2.3406290418358258

Epoch: 6| Step: 6
Training loss: 2.795924663543701
Validation loss: 2.306664054111768

Epoch: 6| Step: 7
Training loss: 2.800872802734375
Validation loss: 2.2951877322248233

Epoch: 6| Step: 8
Training loss: 2.504237651824951
Validation loss: 2.285958513136833

Epoch: 6| Step: 9
Training loss: 2.8600525856018066
Validation loss: 2.291168297490766

Epoch: 6| Step: 10
Training loss: 2.6918952465057373
Validation loss: 2.3012899942295526

Epoch: 6| Step: 11
Training loss: 1.5263723134994507
Validation loss: 2.3093030145091396

Epoch: 6| Step: 12
Training loss: 2.767017364501953
Validation loss: 2.3079744846590105

Epoch: 6| Step: 13
Training loss: 1.8728610277175903
Validation loss: 2.319145874310565

Epoch: 56| Step: 0
Training loss: 2.567903757095337
Validation loss: 2.326302525817707

Epoch: 6| Step: 1
Training loss: 2.8349549770355225
Validation loss: 2.3490127901877127

Epoch: 6| Step: 2
Training loss: 3.303043842315674
Validation loss: 2.369017431812902

Epoch: 6| Step: 3
Training loss: 2.882908821105957
Validation loss: 2.401912443099483

Epoch: 6| Step: 4
Training loss: 2.4238815307617188
Validation loss: 2.3866751424727903

Epoch: 6| Step: 5
Training loss: 2.325943946838379
Validation loss: 2.3637551069259644

Epoch: 6| Step: 6
Training loss: 2.733874797821045
Validation loss: 2.371642288341317

Epoch: 6| Step: 7
Training loss: 2.688716411590576
Validation loss: 2.3572718943319013

Epoch: 6| Step: 8
Training loss: 2.2630529403686523
Validation loss: 2.338847409012497

Epoch: 6| Step: 9
Training loss: 2.3290023803710938
Validation loss: 2.340554961594202

Epoch: 6| Step: 10
Training loss: 2.7771129608154297
Validation loss: 2.3180396659399873

Epoch: 6| Step: 11
Training loss: 2.202422618865967
Validation loss: 2.2982143740500174

Epoch: 6| Step: 12
Training loss: 2.3412652015686035
Validation loss: 2.3008953614901473

Epoch: 6| Step: 13
Training loss: 2.660278797149658
Validation loss: 2.308239459991455

Epoch: 57| Step: 0
Training loss: 3.118889331817627
Validation loss: 2.3165344217772126

Epoch: 6| Step: 1
Training loss: 3.0356786251068115
Validation loss: 2.331454505202591

Epoch: 6| Step: 2
Training loss: 2.1625702381134033
Validation loss: 2.3408185115424534

Epoch: 6| Step: 3
Training loss: 3.2032980918884277
Validation loss: 2.338829526337244

Epoch: 6| Step: 4
Training loss: 1.8990592956542969
Validation loss: 2.380958828874814

Epoch: 6| Step: 5
Training loss: 2.9198803901672363
Validation loss: 2.3679089623112834

Epoch: 6| Step: 6
Training loss: 2.6856842041015625
Validation loss: 2.308027751984135

Epoch: 6| Step: 7
Training loss: 2.126943588256836
Validation loss: 2.294484885790015

Epoch: 6| Step: 8
Training loss: 2.729592800140381
Validation loss: 2.290506460333383

Epoch: 6| Step: 9
Training loss: 1.94329035282135
Validation loss: 2.2823594898305912

Epoch: 6| Step: 10
Training loss: 2.625826120376587
Validation loss: 2.296214456199318

Epoch: 6| Step: 11
Training loss: 2.2906227111816406
Validation loss: 2.310256165842856

Epoch: 6| Step: 12
Training loss: 2.305284261703491
Validation loss: 2.356167403600549

Epoch: 6| Step: 13
Training loss: 3.488145351409912
Validation loss: 2.3626373121815343

Epoch: 58| Step: 0
Training loss: 2.1699986457824707
Validation loss: 2.3741567468130462

Epoch: 6| Step: 1
Training loss: 2.4019594192504883
Validation loss: 2.352132116594622

Epoch: 6| Step: 2
Training loss: 2.610541820526123
Validation loss: 2.368483986905826

Epoch: 6| Step: 3
Training loss: 2.527597427368164
Validation loss: 2.3289963609428814

Epoch: 6| Step: 4
Training loss: 2.4393389225006104
Validation loss: 2.3105347335979505

Epoch: 6| Step: 5
Training loss: 1.9274187088012695
Validation loss: 2.2888844551578647

Epoch: 6| Step: 6
Training loss: 2.1070120334625244
Validation loss: 2.2807196852981404

Epoch: 6| Step: 7
Training loss: 2.388859987258911
Validation loss: 2.2778531607761177

Epoch: 6| Step: 8
Training loss: 3.0783255100250244
Validation loss: 2.2753145899823917

Epoch: 6| Step: 9
Training loss: 3.23392915725708
Validation loss: 2.270011753164312

Epoch: 6| Step: 10
Training loss: 1.9648654460906982
Validation loss: 2.268271935883389

Epoch: 6| Step: 11
Training loss: 3.5280938148498535
Validation loss: 2.267937814035723

Epoch: 6| Step: 12
Training loss: 2.8633952140808105
Validation loss: 2.2762042501921296

Epoch: 6| Step: 13
Training loss: 2.8398125171661377
Validation loss: 2.2760467529296875

Epoch: 59| Step: 0
Training loss: 2.52934193611145
Validation loss: 2.2762350215706775

Epoch: 6| Step: 1
Training loss: 1.868722677230835
Validation loss: 2.286794682984711

Epoch: 6| Step: 2
Training loss: 2.7438745498657227
Validation loss: 2.3208917956198416

Epoch: 6| Step: 3
Training loss: 2.302342414855957
Validation loss: 2.333645630908269

Epoch: 6| Step: 4
Training loss: 2.5422301292419434
Validation loss: 2.331906663474216

Epoch: 6| Step: 5
Training loss: 2.720534324645996
Validation loss: 2.3173990787998324

Epoch: 6| Step: 6
Training loss: 3.0103304386138916
Validation loss: 2.328062501004947

Epoch: 6| Step: 7
Training loss: 1.9042656421661377
Validation loss: 2.3655780053907827

Epoch: 6| Step: 8
Training loss: 3.6194045543670654
Validation loss: 2.4353692762313353

Epoch: 6| Step: 9
Training loss: 2.7903800010681152
Validation loss: 2.3636238728800127

Epoch: 6| Step: 10
Training loss: 2.09128737449646
Validation loss: 2.2710004416845178

Epoch: 6| Step: 11
Training loss: 2.7430272102355957
Validation loss: 2.2557308802040676

Epoch: 6| Step: 12
Training loss: 2.603780746459961
Validation loss: 2.2481452752185125

Epoch: 6| Step: 13
Training loss: 2.326814889907837
Validation loss: 2.257016284491426

Epoch: 60| Step: 0
Training loss: 2.965358257293701
Validation loss: 2.268832806617983

Epoch: 6| Step: 1
Training loss: 3.38379168510437
Validation loss: 2.2971488327108402

Epoch: 6| Step: 2
Training loss: 2.2785801887512207
Validation loss: 2.28186676579137

Epoch: 6| Step: 3
Training loss: 2.350576877593994
Validation loss: 2.2754585371222547

Epoch: 6| Step: 4
Training loss: 2.3821542263031006
Validation loss: 2.2769281325801725

Epoch: 6| Step: 5
Training loss: 2.5103743076324463
Validation loss: 2.2738586792381863

Epoch: 6| Step: 6
Training loss: 2.932495594024658
Validation loss: 2.26915806083269

Epoch: 6| Step: 7
Training loss: 2.759504795074463
Validation loss: 2.2617383977418304

Epoch: 6| Step: 8
Training loss: 2.9849698543548584
Validation loss: 2.2678103703324513

Epoch: 6| Step: 9
Training loss: 2.2223315238952637
Validation loss: 2.306891349054152

Epoch: 6| Step: 10
Training loss: 2.541945219039917
Validation loss: 2.324257286646033

Epoch: 6| Step: 11
Training loss: 2.0948898792266846
Validation loss: 2.279180176796452

Epoch: 6| Step: 12
Training loss: 2.580656051635742
Validation loss: 2.2702713704878286

Epoch: 6| Step: 13
Training loss: 1.5589157342910767
Validation loss: 2.274259469842398

Epoch: 61| Step: 0
Training loss: 2.4889557361602783
Validation loss: 2.2743433521639917

Epoch: 6| Step: 1
Training loss: 1.8762927055358887
Validation loss: 2.2757156689961753

Epoch: 6| Step: 2
Training loss: 2.9835290908813477
Validation loss: 2.28993385453378

Epoch: 6| Step: 3
Training loss: 2.7937045097351074
Validation loss: 2.288078341432797

Epoch: 6| Step: 4
Training loss: 2.820281505584717
Validation loss: 2.2800209163337626

Epoch: 6| Step: 5
Training loss: 2.9896998405456543
Validation loss: 2.2790852515928206

Epoch: 6| Step: 6
Training loss: 2.848729133605957
Validation loss: 2.2752720579024284

Epoch: 6| Step: 7
Training loss: 2.1476802825927734
Validation loss: 2.257322821565854

Epoch: 6| Step: 8
Training loss: 2.7990970611572266
Validation loss: 2.2635783021168043

Epoch: 6| Step: 9
Training loss: 1.9147887229919434
Validation loss: 2.256881229339107

Epoch: 6| Step: 10
Training loss: 2.949669122695923
Validation loss: 2.261588283764419

Epoch: 6| Step: 11
Training loss: 2.3020873069763184
Validation loss: 2.272445224946545

Epoch: 6| Step: 12
Training loss: 2.4751179218292236
Validation loss: 2.2823392947514853

Epoch: 6| Step: 13
Training loss: 2.2523910999298096
Validation loss: 2.2913770829477618

Epoch: 62| Step: 0
Training loss: 2.7816572189331055
Validation loss: 2.290506342405914

Epoch: 6| Step: 1
Training loss: 2.967273712158203
Validation loss: 2.299403893050327

Epoch: 6| Step: 2
Training loss: 2.337420701980591
Validation loss: 2.295394438569264

Epoch: 6| Step: 3
Training loss: 3.236154317855835
Validation loss: 2.275918692670843

Epoch: 6| Step: 4
Training loss: 2.5266003608703613
Validation loss: 2.26662645288693

Epoch: 6| Step: 5
Training loss: 1.9461205005645752
Validation loss: 2.254582461490426

Epoch: 6| Step: 6
Training loss: 2.448089599609375
Validation loss: 2.2546542613737044

Epoch: 6| Step: 7
Training loss: 2.369986057281494
Validation loss: 2.2512870321991625

Epoch: 6| Step: 8
Training loss: 2.5897014141082764
Validation loss: 2.2460168253990913

Epoch: 6| Step: 9
Training loss: 2.331002950668335
Validation loss: 2.2368639976747575

Epoch: 6| Step: 10
Training loss: 2.2478699684143066
Validation loss: 2.24201137276106

Epoch: 6| Step: 11
Training loss: 2.5936248302459717
Validation loss: 2.2331531458003546

Epoch: 6| Step: 12
Training loss: 2.839414596557617
Validation loss: 2.23051114748883

Epoch: 6| Step: 13
Training loss: 2.0770328044891357
Validation loss: 2.2283234609070646

Epoch: 63| Step: 0
Training loss: 2.4707162380218506
Validation loss: 2.2319930086853685

Epoch: 6| Step: 1
Training loss: 2.688425302505493
Validation loss: 2.232396956413023

Epoch: 6| Step: 2
Training loss: 2.5351061820983887
Validation loss: 2.2263972028609245

Epoch: 6| Step: 3
Training loss: 2.3282361030578613
Validation loss: 2.227647501935241

Epoch: 6| Step: 4
Training loss: 2.1394290924072266
Validation loss: 2.230664150689238

Epoch: 6| Step: 5
Training loss: 3.212353467941284
Validation loss: 2.225316168159567

Epoch: 6| Step: 6
Training loss: 2.9455747604370117
Validation loss: 2.2270725747590423

Epoch: 6| Step: 7
Training loss: 1.903337001800537
Validation loss: 2.2341204279212543

Epoch: 6| Step: 8
Training loss: 2.408106803894043
Validation loss: 2.240126648256856

Epoch: 6| Step: 9
Training loss: 2.582878589630127
Validation loss: 2.2532899149002565

Epoch: 6| Step: 10
Training loss: 2.700819969177246
Validation loss: 2.264493467987225

Epoch: 6| Step: 11
Training loss: 2.547626495361328
Validation loss: 2.2609668085652013

Epoch: 6| Step: 12
Training loss: 2.6307477951049805
Validation loss: 2.2720781167348227

Epoch: 6| Step: 13
Training loss: 2.431058406829834
Validation loss: 2.270476746302779

Epoch: 64| Step: 0
Training loss: 2.4174411296844482
Validation loss: 2.2750436900764384

Epoch: 6| Step: 1
Training loss: 2.907209873199463
Validation loss: 2.264089563841461

Epoch: 6| Step: 2
Training loss: 2.6863741874694824
Validation loss: 2.2514029882287465

Epoch: 6| Step: 3
Training loss: 3.3541741371154785
Validation loss: 2.2436313372786327

Epoch: 6| Step: 4
Training loss: 2.4232068061828613
Validation loss: 2.2416330011942054

Epoch: 6| Step: 5
Training loss: 2.1071128845214844
Validation loss: 2.2341947683724026

Epoch: 6| Step: 6
Training loss: 2.304088592529297
Validation loss: 2.2331665869682067

Epoch: 6| Step: 7
Training loss: 2.277416229248047
Validation loss: 2.22821073121922

Epoch: 6| Step: 8
Training loss: 2.2908902168273926
Validation loss: 2.2316497448951966

Epoch: 6| Step: 9
Training loss: 3.2679171562194824
Validation loss: 2.228508064823766

Epoch: 6| Step: 10
Training loss: 2.4999523162841797
Validation loss: 2.235462401502876

Epoch: 6| Step: 11
Training loss: 2.4093289375305176
Validation loss: 2.2396438096159246

Epoch: 6| Step: 12
Training loss: 1.9121571779251099
Validation loss: 2.2533379139438754

Epoch: 6| Step: 13
Training loss: 2.6917459964752197
Validation loss: 2.2564534243716987

Epoch: 65| Step: 0
Training loss: 2.6699700355529785
Validation loss: 2.2774751058188816

Epoch: 6| Step: 1
Training loss: 2.3556766510009766
Validation loss: 2.296073288045904

Epoch: 6| Step: 2
Training loss: 1.9822015762329102
Validation loss: 2.3129614655689528

Epoch: 6| Step: 3
Training loss: 3.474602222442627
Validation loss: 2.321080123224566

Epoch: 6| Step: 4
Training loss: 2.8702449798583984
Validation loss: 2.2894921969341975

Epoch: 6| Step: 5
Training loss: 2.0782861709594727
Validation loss: 2.248883026902394

Epoch: 6| Step: 6
Training loss: 1.853848934173584
Validation loss: 2.2315211936991703

Epoch: 6| Step: 7
Training loss: 2.1608314514160156
Validation loss: 2.2203954163418023

Epoch: 6| Step: 8
Training loss: 2.806349992752075
Validation loss: 2.220235509257163

Epoch: 6| Step: 9
Training loss: 2.247758626937866
Validation loss: 2.2140422149371077

Epoch: 6| Step: 10
Training loss: 2.401679754257202
Validation loss: 2.219628269954394

Epoch: 6| Step: 11
Training loss: 3.119479179382324
Validation loss: 2.2220283413446076

Epoch: 6| Step: 12
Training loss: 2.69773268699646
Validation loss: 2.2214119075447

Epoch: 6| Step: 13
Training loss: 2.7684755325317383
Validation loss: 2.2219077464072936

Epoch: 66| Step: 0
Training loss: 2.1515345573425293
Validation loss: 2.2203476992986535

Epoch: 6| Step: 1
Training loss: 2.045884132385254
Validation loss: 2.2240039174274733

Epoch: 6| Step: 2
Training loss: 2.4171435832977295
Validation loss: 2.2225438740945633

Epoch: 6| Step: 3
Training loss: 2.674816131591797
Validation loss: 2.2253022886091665

Epoch: 6| Step: 4
Training loss: 2.5826244354248047
Validation loss: 2.22783842907157

Epoch: 6| Step: 5
Training loss: 2.919563055038452
Validation loss: 2.2414933302069224

Epoch: 6| Step: 6
Training loss: 2.3280725479125977
Validation loss: 2.2469540616517425

Epoch: 6| Step: 7
Training loss: 2.299382448196411
Validation loss: 2.251971367866762

Epoch: 6| Step: 8
Training loss: 2.6700079441070557
Validation loss: 2.2521313031514487

Epoch: 6| Step: 9
Training loss: 2.9599833488464355
Validation loss: 2.24763515944122

Epoch: 6| Step: 10
Training loss: 2.073134660720825
Validation loss: 2.2348316202881517

Epoch: 6| Step: 11
Training loss: 3.340944528579712
Validation loss: 2.226428134467012

Epoch: 6| Step: 12
Training loss: 2.6348049640655518
Validation loss: 2.2180888345164638

Epoch: 6| Step: 13
Training loss: 2.1803345680236816
Validation loss: 2.210974392070565

Epoch: 67| Step: 0
Training loss: 2.462364912033081
Validation loss: 2.21326006356106

Epoch: 6| Step: 1
Training loss: 2.5124406814575195
Validation loss: 2.2140792390351653

Epoch: 6| Step: 2
Training loss: 3.631032943725586
Validation loss: 2.218204939237205

Epoch: 6| Step: 3
Training loss: 2.123783588409424
Validation loss: 2.2091541059555544

Epoch: 6| Step: 4
Training loss: 2.4557785987854004
Validation loss: 2.210683525249522

Epoch: 6| Step: 5
Training loss: 2.6865973472595215
Validation loss: 2.209221250267439

Epoch: 6| Step: 6
Training loss: 2.5607175827026367
Validation loss: 2.2142352647678827

Epoch: 6| Step: 7
Training loss: 2.0353264808654785
Validation loss: 2.2162370476671445

Epoch: 6| Step: 8
Training loss: 3.157160997390747
Validation loss: 2.221562567577567

Epoch: 6| Step: 9
Training loss: 3.033945083618164
Validation loss: 2.236803949520152

Epoch: 6| Step: 10
Training loss: 2.2018086910247803
Validation loss: 2.226507471453759

Epoch: 6| Step: 11
Training loss: 2.3506197929382324
Validation loss: 2.232506089313056

Epoch: 6| Step: 12
Training loss: 2.124079942703247
Validation loss: 2.231763788448867

Epoch: 6| Step: 13
Training loss: 1.4525192975997925
Validation loss: 2.2294347081133115

Epoch: 68| Step: 0
Training loss: 2.189824342727661
Validation loss: 2.245173087684057

Epoch: 6| Step: 1
Training loss: 3.6471664905548096
Validation loss: 2.2667005113376084

Epoch: 6| Step: 2
Training loss: 2.427048683166504
Validation loss: 2.2603859901428223

Epoch: 6| Step: 3
Training loss: 2.1110010147094727
Validation loss: 2.244002931861467

Epoch: 6| Step: 4
Training loss: 2.470693588256836
Validation loss: 2.235368458173608

Epoch: 6| Step: 5
Training loss: 2.1834516525268555
Validation loss: 2.2237799206087665

Epoch: 6| Step: 6
Training loss: 2.7077999114990234
Validation loss: 2.2056972852317234

Epoch: 6| Step: 7
Training loss: 2.7172927856445312
Validation loss: 2.207722476733628

Epoch: 6| Step: 8
Training loss: 2.4240920543670654
Validation loss: 2.1938327307342202

Epoch: 6| Step: 9
Training loss: 2.4168009757995605
Validation loss: 2.1942311589435866

Epoch: 6| Step: 10
Training loss: 2.426163673400879
Validation loss: 2.198348060730965

Epoch: 6| Step: 11
Training loss: 2.2321629524230957
Validation loss: 2.1999270864712295

Epoch: 6| Step: 12
Training loss: 2.443312644958496
Validation loss: 2.208136602114606

Epoch: 6| Step: 13
Training loss: 2.944267988204956
Validation loss: 2.20604355360872

Epoch: 69| Step: 0
Training loss: 2.3155038356781006
Validation loss: 2.217911797185098

Epoch: 6| Step: 1
Training loss: 2.8259639739990234
Validation loss: 2.2187077089022567

Epoch: 6| Step: 2
Training loss: 1.951423168182373
Validation loss: 2.221044586550805

Epoch: 6| Step: 3
Training loss: 2.0384135246276855
Validation loss: 2.208788666673886

Epoch: 6| Step: 4
Training loss: 2.5304548740386963
Validation loss: 2.2142959230689594

Epoch: 6| Step: 5
Training loss: 1.9769262075424194
Validation loss: 2.2255635376899474

Epoch: 6| Step: 6
Training loss: 2.6676197052001953
Validation loss: 2.2430675388664327

Epoch: 6| Step: 7
Training loss: 3.025691270828247
Validation loss: 2.2505627447558987

Epoch: 6| Step: 8
Training loss: 3.0539562702178955
Validation loss: 2.236696526568423

Epoch: 6| Step: 9
Training loss: 2.614389657974243
Validation loss: 2.2199523756580968

Epoch: 6| Step: 10
Training loss: 2.9209682941436768
Validation loss: 2.2149335953497116

Epoch: 6| Step: 11
Training loss: 2.1771240234375
Validation loss: 2.207608761325959

Epoch: 6| Step: 12
Training loss: 2.5833349227905273
Validation loss: 2.1973526323995283

Epoch: 6| Step: 13
Training loss: 2.0977487564086914
Validation loss: 2.1969832835658902

Epoch: 70| Step: 0
Training loss: 1.9100675582885742
Validation loss: 2.1956392385626353

Epoch: 6| Step: 1
Training loss: 2.2552788257598877
Validation loss: 2.209836700911163

Epoch: 6| Step: 2
Training loss: 2.519813060760498
Validation loss: 2.2187977401159142

Epoch: 6| Step: 3
Training loss: 2.2509424686431885
Validation loss: 2.2146470828722884

Epoch: 6| Step: 4
Training loss: 2.480501890182495
Validation loss: 2.2229370173587593

Epoch: 6| Step: 5
Training loss: 2.417762279510498
Validation loss: 2.209796449189545

Epoch: 6| Step: 6
Training loss: 2.8997676372528076
Validation loss: 2.2040990475685365

Epoch: 6| Step: 7
Training loss: 3.35741925239563
Validation loss: 2.1970411577532367

Epoch: 6| Step: 8
Training loss: 1.9270460605621338
Validation loss: 2.1872922399992585

Epoch: 6| Step: 9
Training loss: 2.5078272819519043
Validation loss: 2.1911035737683697

Epoch: 6| Step: 10
Training loss: 2.824718475341797
Validation loss: 2.1974757602137904

Epoch: 6| Step: 11
Training loss: 2.442538261413574
Validation loss: 2.203979999788346

Epoch: 6| Step: 12
Training loss: 2.656423568725586
Validation loss: 2.195581184920444

Epoch: 6| Step: 13
Training loss: 2.333078384399414
Validation loss: 2.1942976315816245

Epoch: 71| Step: 0
Training loss: 2.909712076187134
Validation loss: 2.1938602155254734

Epoch: 6| Step: 1
Training loss: 2.6184959411621094
Validation loss: 2.1913695155933337

Epoch: 6| Step: 2
Training loss: 1.965814471244812
Validation loss: 2.190772415489279

Epoch: 6| Step: 3
Training loss: 2.1361947059631348
Validation loss: 2.1950400183277745

Epoch: 6| Step: 4
Training loss: 2.5804097652435303
Validation loss: 2.2000614673860612

Epoch: 6| Step: 5
Training loss: 2.296030044555664
Validation loss: 2.19843594361377

Epoch: 6| Step: 6
Training loss: 2.422151803970337
Validation loss: 2.19382405793795

Epoch: 6| Step: 7
Training loss: 2.7739756107330322
Validation loss: 2.2033144991884948

Epoch: 6| Step: 8
Training loss: 2.9839019775390625
Validation loss: 2.199507369790026

Epoch: 6| Step: 9
Training loss: 3.247706174850464
Validation loss: 2.205015746496057

Epoch: 6| Step: 10
Training loss: 2.2184133529663086
Validation loss: 2.2245184657394246

Epoch: 6| Step: 11
Training loss: 2.0878381729125977
Validation loss: 2.1914206217694026

Epoch: 6| Step: 12
Training loss: 2.2679965496063232
Validation loss: 2.1989725302624445

Epoch: 6| Step: 13
Training loss: 1.9584383964538574
Validation loss: 2.1881542590356644

Epoch: 72| Step: 0
Training loss: 2.910210132598877
Validation loss: 2.1766896068408923

Epoch: 6| Step: 1
Training loss: 2.184556722640991
Validation loss: 2.17870194168501

Epoch: 6| Step: 2
Training loss: 2.8420588970184326
Validation loss: 2.1753444184539137

Epoch: 6| Step: 3
Training loss: 2.516824722290039
Validation loss: 2.175694052891065

Epoch: 6| Step: 4
Training loss: 2.694246530532837
Validation loss: 2.172148194364322

Epoch: 6| Step: 5
Training loss: 2.508655071258545
Validation loss: 2.1850497850807766

Epoch: 6| Step: 6
Training loss: 2.0697176456451416
Validation loss: 2.182750666013328

Epoch: 6| Step: 7
Training loss: 1.9191513061523438
Validation loss: 2.205736908861386

Epoch: 6| Step: 8
Training loss: 2.408403158187866
Validation loss: 2.2192852548373643

Epoch: 6| Step: 9
Training loss: 2.620023250579834
Validation loss: 2.231295310040956

Epoch: 6| Step: 10
Training loss: 2.5000603199005127
Validation loss: 2.234904848119264

Epoch: 6| Step: 11
Training loss: 2.751162052154541
Validation loss: 2.2406201926610803

Epoch: 6| Step: 12
Training loss: 2.615190029144287
Validation loss: 2.2436691586689284

Epoch: 6| Step: 13
Training loss: 2.112989902496338
Validation loss: 2.253057054294053

Epoch: 73| Step: 0
Training loss: 1.9569777250289917
Validation loss: 2.2709795121223695

Epoch: 6| Step: 1
Training loss: 2.4003427028656006
Validation loss: 2.237764266229445

Epoch: 6| Step: 2
Training loss: 2.7636213302612305
Validation loss: 2.208760881936678

Epoch: 6| Step: 3
Training loss: 2.483933925628662
Validation loss: 2.1840927395769345

Epoch: 6| Step: 4
Training loss: 2.563870906829834
Validation loss: 2.1729616336925055

Epoch: 6| Step: 5
Training loss: 2.250528335571289
Validation loss: 2.1703430760291313

Epoch: 6| Step: 6
Training loss: 3.086709976196289
Validation loss: 2.166924379205191

Epoch: 6| Step: 7
Training loss: 2.211848735809326
Validation loss: 2.166490266399999

Epoch: 6| Step: 8
Training loss: 2.155972480773926
Validation loss: 2.1661539462304886

Epoch: 6| Step: 9
Training loss: 2.209315538406372
Validation loss: 2.1618162303842525

Epoch: 6| Step: 10
Training loss: 2.670499324798584
Validation loss: 2.165184981079512

Epoch: 6| Step: 11
Training loss: 2.1378064155578613
Validation loss: 2.175868994446211

Epoch: 6| Step: 12
Training loss: 3.0575523376464844
Validation loss: 2.169865131378174

Epoch: 6| Step: 13
Training loss: 3.1153886318206787
Validation loss: 2.1679802530555317

Epoch: 74| Step: 0
Training loss: 2.3230466842651367
Validation loss: 2.1636392929220714

Epoch: 6| Step: 1
Training loss: 2.46488356590271
Validation loss: 2.1623882016827984

Epoch: 6| Step: 2
Training loss: 1.7742416858673096
Validation loss: 2.1584582854342718

Epoch: 6| Step: 3
Training loss: 2.8323676586151123
Validation loss: 2.160502677322716

Epoch: 6| Step: 4
Training loss: 2.2408618927001953
Validation loss: 2.1571211943062405

Epoch: 6| Step: 5
Training loss: 2.5280044078826904
Validation loss: 2.1584683490055863

Epoch: 6| Step: 6
Training loss: 2.2518115043640137
Validation loss: 2.16462262727881

Epoch: 6| Step: 7
Training loss: 2.1322507858276367
Validation loss: 2.18302648298202

Epoch: 6| Step: 8
Training loss: 2.448598861694336
Validation loss: 2.19675092030597

Epoch: 6| Step: 9
Training loss: 2.926259994506836
Validation loss: 2.1919187371448805

Epoch: 6| Step: 10
Training loss: 2.5966973304748535
Validation loss: 2.1810962205292075

Epoch: 6| Step: 11
Training loss: 2.634610176086426
Validation loss: 2.1712428139102076

Epoch: 6| Step: 12
Training loss: 2.8484537601470947
Validation loss: 2.154764650970377

Epoch: 6| Step: 13
Training loss: 2.79351544380188
Validation loss: 2.15519703331814

Epoch: 75| Step: 0
Training loss: 2.5624356269836426
Validation loss: 2.1577977057426208

Epoch: 6| Step: 1
Training loss: 2.4486465454101562
Validation loss: 2.15501489434191

Epoch: 6| Step: 2
Training loss: 2.71883487701416
Validation loss: 2.158813266343968

Epoch: 6| Step: 3
Training loss: 1.9171384572982788
Validation loss: 2.167140394128779

Epoch: 6| Step: 4
Training loss: 3.2396438121795654
Validation loss: 2.177984796544557

Epoch: 6| Step: 5
Training loss: 2.7413933277130127
Validation loss: 2.1977372528404318

Epoch: 6| Step: 6
Training loss: 2.6460156440734863
Validation loss: 2.2253244333369757

Epoch: 6| Step: 7
Training loss: 2.4020402431488037
Validation loss: 2.226953285996632

Epoch: 6| Step: 8
Training loss: 2.1177170276641846
Validation loss: 2.2526597925411758

Epoch: 6| Step: 9
Training loss: 2.250030994415283
Validation loss: 2.20202814122682

Epoch: 6| Step: 10
Training loss: 3.0212693214416504
Validation loss: 2.1718783455510295

Epoch: 6| Step: 11
Training loss: 1.932580828666687
Validation loss: 2.1503473866370415

Epoch: 6| Step: 12
Training loss: 2.5815958976745605
Validation loss: 2.145627729354366

Epoch: 6| Step: 13
Training loss: 1.876841425895691
Validation loss: 2.144466433473813

Epoch: 76| Step: 0
Training loss: 2.5118677616119385
Validation loss: 2.1482024090264433

Epoch: 6| Step: 1
Training loss: 2.64170503616333
Validation loss: 2.1502207530442106

Epoch: 6| Step: 2
Training loss: 2.1466832160949707
Validation loss: 2.1499836239763486

Epoch: 6| Step: 3
Training loss: 2.0027921199798584
Validation loss: 2.1615661113492903

Epoch: 6| Step: 4
Training loss: 2.4531033039093018
Validation loss: 2.1712566216786704

Epoch: 6| Step: 5
Training loss: 2.3950729370117188
Validation loss: 2.1699634316147014

Epoch: 6| Step: 6
Training loss: 2.324965238571167
Validation loss: 2.1687633427240516

Epoch: 6| Step: 7
Training loss: 3.181016445159912
Validation loss: 2.1590503133753294

Epoch: 6| Step: 8
Training loss: 1.9798680543899536
Validation loss: 2.1627340611591133

Epoch: 6| Step: 9
Training loss: 2.6082804203033447
Validation loss: 2.1682261600289294

Epoch: 6| Step: 10
Training loss: 3.0780467987060547
Validation loss: 2.1561343234072448

Epoch: 6| Step: 11
Training loss: 2.4604554176330566
Validation loss: 2.1495420202132194

Epoch: 6| Step: 12
Training loss: 1.8954246044158936
Validation loss: 2.1493098043626353

Epoch: 6| Step: 13
Training loss: 2.6788651943206787
Validation loss: 2.1447850350410707

Epoch: 77| Step: 0
Training loss: 2.4226906299591064
Validation loss: 2.148498122410108

Epoch: 6| Step: 1
Training loss: 2.8050808906555176
Validation loss: 2.1452226600339337

Epoch: 6| Step: 2
Training loss: 2.0102014541625977
Validation loss: 2.1517669846934657

Epoch: 6| Step: 3
Training loss: 2.055994749069214
Validation loss: 2.1488095893654773

Epoch: 6| Step: 4
Training loss: 2.3045175075531006
Validation loss: 2.146290571458878

Epoch: 6| Step: 5
Training loss: 2.9150285720825195
Validation loss: 2.1457692294992428

Epoch: 6| Step: 6
Training loss: 2.327942371368408
Validation loss: 2.1541997694200083

Epoch: 6| Step: 7
Training loss: 1.4651596546173096
Validation loss: 2.1808016325837825

Epoch: 6| Step: 8
Training loss: 2.530877113342285
Validation loss: 2.1938056791982343

Epoch: 6| Step: 9
Training loss: 2.4512529373168945
Validation loss: 2.205532790512167

Epoch: 6| Step: 10
Training loss: 2.4406895637512207
Validation loss: 2.2013778917251097

Epoch: 6| Step: 11
Training loss: 2.6552491188049316
Validation loss: 2.209389791693739

Epoch: 6| Step: 12
Training loss: 3.322195529937744
Validation loss: 2.2116590392205024

Epoch: 6| Step: 13
Training loss: 2.841315269470215
Validation loss: 2.176216476707048

Epoch: 78| Step: 0
Training loss: 2.0005035400390625
Validation loss: 2.1728476914026404

Epoch: 6| Step: 1
Training loss: 2.4857115745544434
Validation loss: 2.151683440772436

Epoch: 6| Step: 2
Training loss: 2.2849605083465576
Validation loss: 2.143751172609227

Epoch: 6| Step: 3
Training loss: 2.547675609588623
Validation loss: 2.1445739166710966

Epoch: 6| Step: 4
Training loss: 1.8339664936065674
Validation loss: 2.139815184377855

Epoch: 6| Step: 5
Training loss: 2.1774752140045166
Validation loss: 2.136583753811416

Epoch: 6| Step: 6
Training loss: 3.7225561141967773
Validation loss: 2.1371994582555627

Epoch: 6| Step: 7
Training loss: 1.994760274887085
Validation loss: 2.132122608923143

Epoch: 6| Step: 8
Training loss: 2.70448637008667
Validation loss: 2.1295371978513655

Epoch: 6| Step: 9
Training loss: 2.989734649658203
Validation loss: 2.1300359105551117

Epoch: 6| Step: 10
Training loss: 1.6381924152374268
Validation loss: 2.1303410337817286

Epoch: 6| Step: 11
Training loss: 2.341569423675537
Validation loss: 2.13192238858951

Epoch: 6| Step: 12
Training loss: 3.0032198429107666
Validation loss: 2.1379244648000246

Epoch: 6| Step: 13
Training loss: 2.7193756103515625
Validation loss: 2.1527584547637613

Epoch: 79| Step: 0
Training loss: 1.8850804567337036
Validation loss: 2.1755502403423352

Epoch: 6| Step: 1
Training loss: 2.588991165161133
Validation loss: 2.1919695177385883

Epoch: 6| Step: 2
Training loss: 2.6454362869262695
Validation loss: 2.212047582031578

Epoch: 6| Step: 3
Training loss: 1.6298017501831055
Validation loss: 2.204477874181604

Epoch: 6| Step: 4
Training loss: 2.399258852005005
Validation loss: 2.199673960285802

Epoch: 6| Step: 5
Training loss: 2.8289031982421875
Validation loss: 2.1769745606248097

Epoch: 6| Step: 6
Training loss: 2.6736230850219727
Validation loss: 2.1486630952486427

Epoch: 6| Step: 7
Training loss: 2.6825647354125977
Validation loss: 2.129270489497851

Epoch: 6| Step: 8
Training loss: 2.6750545501708984
Validation loss: 2.1334928979155836

Epoch: 6| Step: 9
Training loss: 2.7209725379943848
Validation loss: 2.1398868406972578

Epoch: 6| Step: 10
Training loss: 2.6122384071350098
Validation loss: 2.146712879980764

Epoch: 6| Step: 11
Training loss: 2.3773770332336426
Validation loss: 2.1456446263097946

Epoch: 6| Step: 12
Training loss: 2.3063998222351074
Validation loss: 2.1417684811417774

Epoch: 6| Step: 13
Training loss: 2.421516180038452
Validation loss: 2.1323868049088346

Epoch: 80| Step: 0
Training loss: 2.9342033863067627
Validation loss: 2.1432988515464206

Epoch: 6| Step: 1
Training loss: 2.236093282699585
Validation loss: 2.153536058241321

Epoch: 6| Step: 2
Training loss: 2.3376564979553223
Validation loss: 2.1733555716852986

Epoch: 6| Step: 3
Training loss: 2.6431570053100586
Validation loss: 2.194502697196058

Epoch: 6| Step: 4
Training loss: 2.3845129013061523
Validation loss: 2.2085152851637972

Epoch: 6| Step: 5
Training loss: 1.7348432540893555
Validation loss: 2.20502051999492

Epoch: 6| Step: 6
Training loss: 2.8803305625915527
Validation loss: 2.183166168069327

Epoch: 6| Step: 7
Training loss: 2.6978423595428467
Validation loss: 2.155780215417185

Epoch: 6| Step: 8
Training loss: 2.4113450050354004
Validation loss: 2.142473623316775

Epoch: 6| Step: 9
Training loss: 1.935712218284607
Validation loss: 2.1289438573263024

Epoch: 6| Step: 10
Training loss: 2.155730962753296
Validation loss: 2.129525375622575

Epoch: 6| Step: 11
Training loss: 2.3561038970947266
Validation loss: 2.1357957291346725

Epoch: 6| Step: 12
Training loss: 3.0227413177490234
Validation loss: 2.124402728132022

Epoch: 6| Step: 13
Training loss: 2.8829658031463623
Validation loss: 2.1298660360356814

Epoch: 81| Step: 0
Training loss: 2.325056552886963
Validation loss: 2.1423171925288376

Epoch: 6| Step: 1
Training loss: 2.3318817615509033
Validation loss: 2.1540522934288107

Epoch: 6| Step: 2
Training loss: 2.6866607666015625
Validation loss: 2.163202771576502

Epoch: 6| Step: 3
Training loss: 2.4065098762512207
Validation loss: 2.1649210453033447

Epoch: 6| Step: 4
Training loss: 2.126567840576172
Validation loss: 2.168136191624467

Epoch: 6| Step: 5
Training loss: 2.955277681350708
Validation loss: 2.176970471617996

Epoch: 6| Step: 6
Training loss: 2.004000186920166
Validation loss: 2.188132429635653

Epoch: 6| Step: 7
Training loss: 2.1881051063537598
Validation loss: 2.165449703893354

Epoch: 6| Step: 8
Training loss: 2.8515355587005615
Validation loss: 2.155206282933553

Epoch: 6| Step: 9
Training loss: 2.0842766761779785
Validation loss: 2.1307194053485827

Epoch: 6| Step: 10
Training loss: 2.6017236709594727
Validation loss: 2.124637531977828

Epoch: 6| Step: 11
Training loss: 2.4313900470733643
Validation loss: 2.119630582870976

Epoch: 6| Step: 12
Training loss: 2.297821044921875
Validation loss: 2.120286408291068

Epoch: 6| Step: 13
Training loss: 3.1069629192352295
Validation loss: 2.1229903031420965

Epoch: 82| Step: 0
Training loss: 3.0621089935302734
Validation loss: 2.1225797258397585

Epoch: 6| Step: 1
Training loss: 2.335085868835449
Validation loss: 2.119522169072141

Epoch: 6| Step: 2
Training loss: 2.5082921981811523
Validation loss: 2.113993296059229

Epoch: 6| Step: 3
Training loss: 2.404283046722412
Validation loss: 2.115560580325383

Epoch: 6| Step: 4
Training loss: 2.532548427581787
Validation loss: 2.1407299785203833

Epoch: 6| Step: 5
Training loss: 1.6679646968841553
Validation loss: 2.163537081851754

Epoch: 6| Step: 6
Training loss: 2.231767177581787
Validation loss: 2.179649852937268

Epoch: 6| Step: 7
Training loss: 1.7472888231277466
Validation loss: 2.1719097347669702

Epoch: 6| Step: 8
Training loss: 3.1517081260681152
Validation loss: 2.203285642849502

Epoch: 6| Step: 9
Training loss: 2.745574474334717
Validation loss: 2.1852056903223835

Epoch: 6| Step: 10
Training loss: 2.607786178588867
Validation loss: 2.186484823944748

Epoch: 6| Step: 11
Training loss: 2.6605374813079834
Validation loss: 2.1629681689764864

Epoch: 6| Step: 12
Training loss: 2.524320602416992
Validation loss: 2.1480857326138403

Epoch: 6| Step: 13
Training loss: 1.5921052694320679
Validation loss: 2.1285972120941326

Epoch: 83| Step: 0
Training loss: 2.652529239654541
Validation loss: 2.1134411750301236

Epoch: 6| Step: 1
Training loss: 3.0302281379699707
Validation loss: 2.1163938788957495

Epoch: 6| Step: 2
Training loss: 2.0109031200408936
Validation loss: 2.1161877878250612

Epoch: 6| Step: 3
Training loss: 1.4997856616973877
Validation loss: 2.1240936607442875

Epoch: 6| Step: 4
Training loss: 2.6146435737609863
Validation loss: 2.1213651651977212

Epoch: 6| Step: 5
Training loss: 2.7337374687194824
Validation loss: 2.1278693650358464

Epoch: 6| Step: 6
Training loss: 3.5824313163757324
Validation loss: 2.119081594610727

Epoch: 6| Step: 7
Training loss: 1.75994074344635
Validation loss: 2.130714052466936

Epoch: 6| Step: 8
Training loss: 2.245779037475586
Validation loss: 2.127687213241413

Epoch: 6| Step: 9
Training loss: 2.1343798637390137
Validation loss: 2.130912975598407

Epoch: 6| Step: 10
Training loss: 2.9872708320617676
Validation loss: 2.1271074292480305

Epoch: 6| Step: 11
Training loss: 1.9052314758300781
Validation loss: 2.133874306114771

Epoch: 6| Step: 12
Training loss: 2.485248565673828
Validation loss: 2.152057001667638

Epoch: 6| Step: 13
Training loss: 2.455911874771118
Validation loss: 2.1701210211682063

Epoch: 84| Step: 0
Training loss: 2.2622175216674805
Validation loss: 2.2028792442814

Epoch: 6| Step: 1
Training loss: 2.7773597240448
Validation loss: 2.241248958854265

Epoch: 6| Step: 2
Training loss: 2.4525442123413086
Validation loss: 2.2347983032144527

Epoch: 6| Step: 3
Training loss: 2.459009885787964
Validation loss: 2.203589190718948

Epoch: 6| Step: 4
Training loss: 2.3826260566711426
Validation loss: 2.177876680128036

Epoch: 6| Step: 5
Training loss: 3.040071964263916
Validation loss: 2.158955486871863

Epoch: 6| Step: 6
Training loss: 1.913191795349121
Validation loss: 2.123948904775804

Epoch: 6| Step: 7
Training loss: 1.9571318626403809
Validation loss: 2.11814776543648

Epoch: 6| Step: 8
Training loss: 2.339858055114746
Validation loss: 2.1184714148121495

Epoch: 6| Step: 9
Training loss: 3.1726913452148438
Validation loss: 2.105708201726278

Epoch: 6| Step: 10
Training loss: 1.691069483757019
Validation loss: 2.1087177466320735

Epoch: 6| Step: 11
Training loss: 2.090195894241333
Validation loss: 2.1082756724408878

Epoch: 6| Step: 12
Training loss: 2.6925406455993652
Validation loss: 2.1158822044249503

Epoch: 6| Step: 13
Training loss: 3.1950409412384033
Validation loss: 2.125265295787524

Epoch: 85| Step: 0
Training loss: 1.9483376741409302
Validation loss: 2.1507323506057903

Epoch: 6| Step: 1
Training loss: 1.9665266275405884
Validation loss: 2.216532455977573

Epoch: 6| Step: 2
Training loss: 2.3654282093048096
Validation loss: 2.2343079043972875

Epoch: 6| Step: 3
Training loss: 2.614738941192627
Validation loss: 2.178498770601006

Epoch: 6| Step: 4
Training loss: 3.2685205936431885
Validation loss: 2.1272598235837874

Epoch: 6| Step: 5
Training loss: 2.0310192108154297
Validation loss: 2.1088105658049225

Epoch: 6| Step: 6
Training loss: 2.4401979446411133
Validation loss: 2.113575602090487

Epoch: 6| Step: 7
Training loss: 2.472977876663208
Validation loss: 2.103587585110818

Epoch: 6| Step: 8
Training loss: 2.604416608810425
Validation loss: 2.1004807513247252

Epoch: 6| Step: 9
Training loss: 2.725541114807129
Validation loss: 2.1052670940276115

Epoch: 6| Step: 10
Training loss: 2.1875879764556885
Validation loss: 2.112566522372666

Epoch: 6| Step: 11
Training loss: 2.385295867919922
Validation loss: 2.118252761902348

Epoch: 6| Step: 12
Training loss: 2.4019510746002197
Validation loss: 2.1309880133598083

Epoch: 6| Step: 13
Training loss: 3.1309986114501953
Validation loss: 2.184214189488401

Epoch: 86| Step: 0
Training loss: 2.2780063152313232
Validation loss: 2.3349584815322713

Epoch: 6| Step: 1
Training loss: 2.584057569503784
Validation loss: 2.3864142535835184

Epoch: 6| Step: 2
Training loss: 2.516972780227661
Validation loss: 2.4123947261482157

Epoch: 6| Step: 3
Training loss: 2.136584758758545
Validation loss: 2.3970740302916496

Epoch: 6| Step: 4
Training loss: 2.1108105182647705
Validation loss: 2.3695961685590845

Epoch: 6| Step: 5
Training loss: 2.008452892303467
Validation loss: 2.346906687623711

Epoch: 6| Step: 6
Training loss: 2.3932952880859375
Validation loss: 2.3256855574987267

Epoch: 6| Step: 7
Training loss: 2.92440128326416
Validation loss: 2.275753628823065

Epoch: 6| Step: 8
Training loss: 3.3475890159606934
Validation loss: 2.214656199178388

Epoch: 6| Step: 9
Training loss: 2.8698086738586426
Validation loss: 2.1803626552704842

Epoch: 6| Step: 10
Training loss: 2.1107892990112305
Validation loss: 2.1656029762760287

Epoch: 6| Step: 11
Training loss: 2.8563008308410645
Validation loss: 2.1552574890916065

Epoch: 6| Step: 12
Training loss: 2.4403204917907715
Validation loss: 2.138345423565116

Epoch: 6| Step: 13
Training loss: 2.70177960395813
Validation loss: 2.0992509677845943

Epoch: 87| Step: 0
Training loss: 1.6334810256958008
Validation loss: 2.0984958551263295

Epoch: 6| Step: 1
Training loss: 1.8152036666870117
Validation loss: 2.111639925228652

Epoch: 6| Step: 2
Training loss: 2.0685577392578125
Validation loss: 2.1605591312531502

Epoch: 6| Step: 3
Training loss: 2.257443428039551
Validation loss: 2.2470735055144115

Epoch: 6| Step: 4
Training loss: 2.4315004348754883
Validation loss: 2.2636659760628977

Epoch: 6| Step: 5
Training loss: 2.755025863647461
Validation loss: 2.2953646336832354

Epoch: 6| Step: 6
Training loss: 2.6937122344970703
Validation loss: 2.34739916042615

Epoch: 6| Step: 7
Training loss: 3.7760448455810547
Validation loss: 2.3877858756690897

Epoch: 6| Step: 8
Training loss: 2.342395782470703
Validation loss: 2.415296298201366

Epoch: 6| Step: 9
Training loss: 3.5071568489074707
Validation loss: 2.3737042488590365

Epoch: 6| Step: 10
Training loss: 1.8446959257125854
Validation loss: 2.2361049036825857

Epoch: 6| Step: 11
Training loss: 2.6583566665649414
Validation loss: 2.1622749784941315

Epoch: 6| Step: 12
Training loss: 2.3435776233673096
Validation loss: 2.126185773521341

Epoch: 6| Step: 13
Training loss: 2.6903839111328125
Validation loss: 2.0875909584824757

Epoch: 88| Step: 0
Training loss: 1.8941779136657715
Validation loss: 2.081953210215415

Epoch: 6| Step: 1
Training loss: 2.6732540130615234
Validation loss: 2.1074460206493253

Epoch: 6| Step: 2
Training loss: 2.555415153503418
Validation loss: 2.141454004472302

Epoch: 6| Step: 3
Training loss: 2.046459913253784
Validation loss: 2.1585245388810352

Epoch: 6| Step: 4
Training loss: 2.8826093673706055
Validation loss: 2.141620892350392

Epoch: 6| Step: 5
Training loss: 2.8149380683898926
Validation loss: 2.1290107696287093

Epoch: 6| Step: 6
Training loss: 2.3563671112060547
Validation loss: 2.109792938796423

Epoch: 6| Step: 7
Training loss: 3.129077196121216
Validation loss: 2.1334286735903834

Epoch: 6| Step: 8
Training loss: 2.230238914489746
Validation loss: 2.1200028158003286

Epoch: 6| Step: 9
Training loss: 1.9102818965911865
Validation loss: 2.1212664829787387

Epoch: 6| Step: 10
Training loss: 2.6732654571533203
Validation loss: 2.1018868389950005

Epoch: 6| Step: 11
Training loss: 2.8118226528167725
Validation loss: 2.110798692190519

Epoch: 6| Step: 12
Training loss: 2.096229314804077
Validation loss: 2.107876234157111

Epoch: 6| Step: 13
Training loss: 1.8912345170974731
Validation loss: 2.095925005533362

Epoch: 89| Step: 0
Training loss: 1.8150964975357056
Validation loss: 2.103539656567317

Epoch: 6| Step: 1
Training loss: 2.2131190299987793
Validation loss: 2.1039258344199068

Epoch: 6| Step: 2
Training loss: 2.5809764862060547
Validation loss: 2.098502041191183

Epoch: 6| Step: 3
Training loss: 2.6589431762695312
Validation loss: 2.0899814123748452

Epoch: 6| Step: 4
Training loss: 2.3454902172088623
Validation loss: 2.0857584502107356

Epoch: 6| Step: 5
Training loss: 2.7251033782958984
Validation loss: 2.0889422547432686

Epoch: 6| Step: 6
Training loss: 1.8859076499938965
Validation loss: 2.0906133754279024

Epoch: 6| Step: 7
Training loss: 2.817617416381836
Validation loss: 2.09504464621185

Epoch: 6| Step: 8
Training loss: 1.9341917037963867
Validation loss: 2.099049452812441

Epoch: 6| Step: 9
Training loss: 2.4721293449401855
Validation loss: 2.11476868455128

Epoch: 6| Step: 10
Training loss: 2.7125120162963867
Validation loss: 2.0987153745466665

Epoch: 6| Step: 11
Training loss: 2.4854300022125244
Validation loss: 2.0864470428036106

Epoch: 6| Step: 12
Training loss: 2.2585558891296387
Validation loss: 2.085548352169734

Epoch: 6| Step: 13
Training loss: 2.796541452407837
Validation loss: 2.0733716141793037

Epoch: 90| Step: 0
Training loss: 2.520303726196289
Validation loss: 2.0778811721391577

Epoch: 6| Step: 1
Training loss: 2.435687780380249
Validation loss: 2.0752948919932046

Epoch: 6| Step: 2
Training loss: 2.5765540599823
Validation loss: 2.078352589761057

Epoch: 6| Step: 3
Training loss: 2.6945137977600098
Validation loss: 2.0811551411946616

Epoch: 6| Step: 4
Training loss: 1.6988873481750488
Validation loss: 2.077066162581085

Epoch: 6| Step: 5
Training loss: 2.6265053749084473
Validation loss: 2.0932263456365114

Epoch: 6| Step: 6
Training loss: 2.827427864074707
Validation loss: 2.0923035170442317

Epoch: 6| Step: 7
Training loss: 2.2505359649658203
Validation loss: 2.096575819036012

Epoch: 6| Step: 8
Training loss: 2.796302080154419
Validation loss: 2.1301623467476136

Epoch: 6| Step: 9
Training loss: 2.101762294769287
Validation loss: 2.169121583302816

Epoch: 6| Step: 10
Training loss: 2.534419059753418
Validation loss: 2.158837943948725

Epoch: 6| Step: 11
Training loss: 1.5137196779251099
Validation loss: 2.1586963322854813

Epoch: 6| Step: 12
Training loss: 2.6469736099243164
Validation loss: 2.137752176612936

Epoch: 6| Step: 13
Training loss: 2.5273232460021973
Validation loss: 2.126456883645827

Epoch: 91| Step: 0
Training loss: 3.2938103675842285
Validation loss: 2.1043564529829126

Epoch: 6| Step: 1
Training loss: 2.2588343620300293
Validation loss: 2.078251314419572

Epoch: 6| Step: 2
Training loss: 2.269667148590088
Validation loss: 2.0735692465177147

Epoch: 6| Step: 3
Training loss: 2.483248233795166
Validation loss: 2.0748647489855365

Epoch: 6| Step: 4
Training loss: 2.414066791534424
Validation loss: 2.067707005367484

Epoch: 6| Step: 5
Training loss: 2.787970781326294
Validation loss: 2.068194430361512

Epoch: 6| Step: 6
Training loss: 2.385516881942749
Validation loss: 2.064283549144704

Epoch: 6| Step: 7
Training loss: 2.3065385818481445
Validation loss: 2.0706583440944715

Epoch: 6| Step: 8
Training loss: 2.4643304347991943
Validation loss: 2.0839677805541665

Epoch: 6| Step: 9
Training loss: 2.0017778873443604
Validation loss: 2.093131116641465

Epoch: 6| Step: 10
Training loss: 2.6860480308532715
Validation loss: 2.1010512562208277

Epoch: 6| Step: 11
Training loss: 1.7463321685791016
Validation loss: 2.096940581516553

Epoch: 6| Step: 12
Training loss: 1.6495423316955566
Validation loss: 2.0895109881636915

Epoch: 6| Step: 13
Training loss: 2.6342086791992188
Validation loss: 2.077830542800247

Epoch: 92| Step: 0
Training loss: 2.8375444412231445
Validation loss: 2.057471231747699

Epoch: 6| Step: 1
Training loss: 2.1174142360687256
Validation loss: 2.0513805189440326

Epoch: 6| Step: 2
Training loss: 2.1591246128082275
Validation loss: 2.0511206324382494

Epoch: 6| Step: 3
Training loss: 2.7808022499084473
Validation loss: 2.054636381005728

Epoch: 6| Step: 4
Training loss: 2.251903533935547
Validation loss: 2.047875701740224

Epoch: 6| Step: 5
Training loss: 2.7092158794403076
Validation loss: 2.0455594421714864

Epoch: 6| Step: 6
Training loss: 2.4133872985839844
Validation loss: 2.045400268288069

Epoch: 6| Step: 7
Training loss: 2.0058188438415527
Validation loss: 2.047563919457056

Epoch: 6| Step: 8
Training loss: 2.1924397945404053
Validation loss: 2.05950302462424

Epoch: 6| Step: 9
Training loss: 2.5468127727508545
Validation loss: 2.06952118104504

Epoch: 6| Step: 10
Training loss: 2.1924214363098145
Validation loss: 2.10375851585019

Epoch: 6| Step: 11
Training loss: 1.8204222917556763
Validation loss: 2.1132579183065765

Epoch: 6| Step: 12
Training loss: 2.2303194999694824
Validation loss: 2.126032942084856

Epoch: 6| Step: 13
Training loss: 3.5734758377075195
Validation loss: 2.1196931946662163

Epoch: 93| Step: 0
Training loss: 2.2540817260742188
Validation loss: 2.1175517817979217

Epoch: 6| Step: 1
Training loss: 2.1430506706237793
Validation loss: 2.0960833628972373

Epoch: 6| Step: 2
Training loss: 2.6489341259002686
Validation loss: 2.0871773099386566

Epoch: 6| Step: 3
Training loss: 2.3836631774902344
Validation loss: 2.0764450873098066

Epoch: 6| Step: 4
Training loss: 2.608663558959961
Validation loss: 2.053743931554979

Epoch: 6| Step: 5
Training loss: 1.565755844116211
Validation loss: 2.0589935984662784

Epoch: 6| Step: 6
Training loss: 2.4743924140930176
Validation loss: 2.0548410095194334

Epoch: 6| Step: 7
Training loss: 2.1321797370910645
Validation loss: 2.0535619694699525

Epoch: 6| Step: 8
Training loss: 2.575441360473633
Validation loss: 2.04782860766175

Epoch: 6| Step: 9
Training loss: 2.3852362632751465
Validation loss: 2.0585396982008413

Epoch: 6| Step: 10
Training loss: 2.3449790477752686
Validation loss: 2.050009944105661

Epoch: 6| Step: 11
Training loss: 1.8988046646118164
Validation loss: 2.0516708499641827

Epoch: 6| Step: 12
Training loss: 3.4111032485961914
Validation loss: 2.066923436298165

Epoch: 6| Step: 13
Training loss: 2.890782356262207
Validation loss: 2.0754058155962216

Epoch: 94| Step: 0
Training loss: 2.9024651050567627
Validation loss: 2.0951678765717374

Epoch: 6| Step: 1
Training loss: 2.857124090194702
Validation loss: 2.104529578198669

Epoch: 6| Step: 2
Training loss: 2.4279863834381104
Validation loss: 2.140986527166059

Epoch: 6| Step: 3
Training loss: 3.2650814056396484
Validation loss: 2.105255880663472

Epoch: 6| Step: 4
Training loss: 2.795213222503662
Validation loss: 2.0808554951862623

Epoch: 6| Step: 5
Training loss: 2.4331912994384766
Validation loss: 2.085075398927094

Epoch: 6| Step: 6
Training loss: 2.5522868633270264
Validation loss: 2.071495338152814

Epoch: 6| Step: 7
Training loss: 2.0058414936065674
Validation loss: 2.063098883116117

Epoch: 6| Step: 8
Training loss: 1.586652398109436
Validation loss: 2.0707970511528755

Epoch: 6| Step: 9
Training loss: 2.0737900733947754
Validation loss: 2.0736560949715237

Epoch: 6| Step: 10
Training loss: 1.943770170211792
Validation loss: 2.059610177111882

Epoch: 6| Step: 11
Training loss: 1.5047717094421387
Validation loss: 2.0560951745638283

Epoch: 6| Step: 12
Training loss: 3.0356693267822266
Validation loss: 2.0507458615046676

Epoch: 6| Step: 13
Training loss: 1.5657902956008911
Validation loss: 2.0560145275567168

Epoch: 95| Step: 0
Training loss: 2.0400588512420654
Validation loss: 2.050057142011581

Epoch: 6| Step: 1
Training loss: 2.7190635204315186
Validation loss: 2.050082434890091

Epoch: 6| Step: 2
Training loss: 2.430532455444336
Validation loss: 2.061084658868851

Epoch: 6| Step: 3
Training loss: 2.8450746536254883
Validation loss: 2.0783606831745436

Epoch: 6| Step: 4
Training loss: 2.707791328430176
Validation loss: 2.086290159533101

Epoch: 6| Step: 5
Training loss: 2.858778715133667
Validation loss: 2.0956347860315794

Epoch: 6| Step: 6
Training loss: 2.0195200443267822
Validation loss: 2.077990813921857

Epoch: 6| Step: 7
Training loss: 2.379549264907837
Validation loss: 2.0541745321725005

Epoch: 6| Step: 8
Training loss: 1.983123779296875
Validation loss: 2.05471097782094

Epoch: 6| Step: 9
Training loss: 2.435312509536743
Validation loss: 2.0611059678498136

Epoch: 6| Step: 10
Training loss: 1.8588975667953491
Validation loss: 2.0612073431732836

Epoch: 6| Step: 11
Training loss: 2.494560956954956
Validation loss: 2.0625738251593804

Epoch: 6| Step: 12
Training loss: 2.1783628463745117
Validation loss: 2.068196345401067

Epoch: 6| Step: 13
Training loss: 2.3092405796051025
Validation loss: 2.062775529840941

Epoch: 96| Step: 0
Training loss: 2.5267186164855957
Validation loss: 2.0598806899080992

Epoch: 6| Step: 1
Training loss: 2.0102782249450684
Validation loss: 2.0597573928935553

Epoch: 6| Step: 2
Training loss: 1.268398404121399
Validation loss: 2.0625900299318376

Epoch: 6| Step: 3
Training loss: 2.610982894897461
Validation loss: 2.0537704626719155

Epoch: 6| Step: 4
Training loss: 2.209165096282959
Validation loss: 2.0396635070923836

Epoch: 6| Step: 5
Training loss: 3.4605960845947266
Validation loss: 2.037589188544981

Epoch: 6| Step: 6
Training loss: 2.66687273979187
Validation loss: 2.037634990548575

Epoch: 6| Step: 7
Training loss: 2.3795371055603027
Validation loss: 2.0413773393118255

Epoch: 6| Step: 8
Training loss: 1.533230185508728
Validation loss: 2.0353597159026773

Epoch: 6| Step: 9
Training loss: 1.7193137407302856
Validation loss: 2.054850447562433

Epoch: 6| Step: 10
Training loss: 2.3389174938201904
Validation loss: 2.06108642778089

Epoch: 6| Step: 11
Training loss: 2.5505475997924805
Validation loss: 2.0707346649580103

Epoch: 6| Step: 12
Training loss: 3.1302080154418945
Validation loss: 2.071451223024758

Epoch: 6| Step: 13
Training loss: 2.8136160373687744
Validation loss: 2.0872902152358845

Epoch: 97| Step: 0
Training loss: 2.5637292861938477
Validation loss: 2.0846974029335925

Epoch: 6| Step: 1
Training loss: 2.0719432830810547
Validation loss: 2.0695091011703655

Epoch: 6| Step: 2
Training loss: 2.1587493419647217
Validation loss: 2.0541017055511475

Epoch: 6| Step: 3
Training loss: 2.0735888481140137
Validation loss: 2.052626804638934

Epoch: 6| Step: 4
Training loss: 2.8406200408935547
Validation loss: 2.0410956118696477

Epoch: 6| Step: 5
Training loss: 2.535977363586426
Validation loss: 2.0398705851647163

Epoch: 6| Step: 6
Training loss: 1.704925775527954
Validation loss: 2.0328392649209626

Epoch: 6| Step: 7
Training loss: 2.8285861015319824
Validation loss: 2.0236552351264545

Epoch: 6| Step: 8
Training loss: 2.4589734077453613
Validation loss: 2.0443680478680517

Epoch: 6| Step: 9
Training loss: 2.269110679626465
Validation loss: 2.0596625215263775

Epoch: 6| Step: 10
Training loss: 2.4154345989227295
Validation loss: 2.064088140764544

Epoch: 6| Step: 11
Training loss: 2.7249951362609863
Validation loss: 2.067637981907014

Epoch: 6| Step: 12
Training loss: 1.8720991611480713
Validation loss: 2.0813773037284933

Epoch: 6| Step: 13
Training loss: 2.447958469390869
Validation loss: 2.092579144303517

Epoch: 98| Step: 0
Training loss: 1.6335548162460327
Validation loss: 2.16612385934399

Epoch: 6| Step: 1
Training loss: 2.612985134124756
Validation loss: 2.201929110352711

Epoch: 6| Step: 2
Training loss: 3.200873851776123
Validation loss: 2.218281299837174

Epoch: 6| Step: 3
Training loss: 2.815523624420166
Validation loss: 2.1966920642442602

Epoch: 6| Step: 4
Training loss: 2.8375861644744873
Validation loss: 2.1797646168739564

Epoch: 6| Step: 5
Training loss: 1.9138561487197876
Validation loss: 2.0965821909648117

Epoch: 6| Step: 6
Training loss: 2.134456157684326
Validation loss: 2.062131888122969

Epoch: 6| Step: 7
Training loss: 2.3385820388793945
Validation loss: 2.033389884938476

Epoch: 6| Step: 8
Training loss: 2.6268186569213867
Validation loss: 2.0517354293536116

Epoch: 6| Step: 9
Training loss: 2.50543475151062
Validation loss: 2.0890346419426704

Epoch: 6| Step: 10
Training loss: 1.948366403579712
Validation loss: 2.142355772756761

Epoch: 6| Step: 11
Training loss: 2.5712714195251465
Validation loss: 2.161511790367865

Epoch: 6| Step: 12
Training loss: 2.6079320907592773
Validation loss: 2.117479185904226

Epoch: 6| Step: 13
Training loss: 2.8860740661621094
Validation loss: 2.096666923133276

Epoch: 99| Step: 0
Training loss: 1.7130286693572998
Validation loss: 2.0841796705799718

Epoch: 6| Step: 1
Training loss: 2.210988998413086
Validation loss: 2.0816576391138057

Epoch: 6| Step: 2
Training loss: 1.9747474193572998
Validation loss: 2.0887932174949237

Epoch: 6| Step: 3
Training loss: 3.2417449951171875
Validation loss: 2.1005961689897763

Epoch: 6| Step: 4
Training loss: 1.9811385869979858
Validation loss: 2.0913710068630915

Epoch: 6| Step: 5
Training loss: 2.7454733848571777
Validation loss: 2.0761541281977007

Epoch: 6| Step: 6
Training loss: 2.1225671768188477
Validation loss: 2.072502928395425

Epoch: 6| Step: 7
Training loss: 2.3545455932617188
Validation loss: 2.0585506821191437

Epoch: 6| Step: 8
Training loss: 2.312466621398926
Validation loss: 2.0468858467635287

Epoch: 6| Step: 9
Training loss: 1.9644362926483154
Validation loss: 2.0255720410295712

Epoch: 6| Step: 10
Training loss: 2.130467414855957
Validation loss: 2.0530976903054023

Epoch: 6| Step: 11
Training loss: 3.0354819297790527
Validation loss: 2.0559285199770363

Epoch: 6| Step: 12
Training loss: 2.474958658218384
Validation loss: 2.123846898796738

Epoch: 6| Step: 13
Training loss: 3.344127655029297
Validation loss: 2.1151088540272047

Epoch: 100| Step: 0
Training loss: 2.813455104827881
Validation loss: 2.0556715432033745

Epoch: 6| Step: 1
Training loss: 1.8114123344421387
Validation loss: 2.036233789177351

Epoch: 6| Step: 2
Training loss: 1.729331374168396
Validation loss: 2.0292277579666465

Epoch: 6| Step: 3
Training loss: 2.851315498352051
Validation loss: 2.022396154301141

Epoch: 6| Step: 4
Training loss: 2.063185453414917
Validation loss: 2.012120073841464

Epoch: 6| Step: 5
Training loss: 2.6695802211761475
Validation loss: 2.0182217782543552

Epoch: 6| Step: 6
Training loss: 2.3683853149414062
Validation loss: 2.0158777980394262

Epoch: 6| Step: 7
Training loss: 2.4511141777038574
Validation loss: 2.021081151500825

Epoch: 6| Step: 8
Training loss: 2.762479305267334
Validation loss: 2.0138597988313243

Epoch: 6| Step: 9
Training loss: 2.2662158012390137
Validation loss: 2.012246384415575

Epoch: 6| Step: 10
Training loss: 2.320786476135254
Validation loss: 2.022955871397449

Epoch: 6| Step: 11
Training loss: 2.075828790664673
Validation loss: 2.0234747086801836

Epoch: 6| Step: 12
Training loss: 2.3318800926208496
Validation loss: 2.0341975663297918

Epoch: 6| Step: 13
Training loss: 2.116765022277832
Validation loss: 2.049485291204145

Epoch: 101| Step: 0
Training loss: 2.691042900085449
Validation loss: 2.0586915195629163

Epoch: 6| Step: 1
Training loss: 2.2731246948242188
Validation loss: 2.0521465322022796

Epoch: 6| Step: 2
Training loss: 2.1418707370758057
Validation loss: 2.030024431085074

Epoch: 6| Step: 3
Training loss: 2.297081232070923
Validation loss: 2.0221268515433035

Epoch: 6| Step: 4
Training loss: 2.114823818206787
Validation loss: 2.0149284229483655

Epoch: 6| Step: 5
Training loss: 2.4059364795684814
Validation loss: 2.0142350991566977

Epoch: 6| Step: 6
Training loss: 2.297398090362549
Validation loss: 2.014279668049146

Epoch: 6| Step: 7
Training loss: 2.540957450866699
Validation loss: 2.017405181802729

Epoch: 6| Step: 8
Training loss: 2.2443583011627197
Validation loss: 2.0209793967585408

Epoch: 6| Step: 9
Training loss: 2.5531599521636963
Validation loss: 2.030583086834159

Epoch: 6| Step: 10
Training loss: 2.5206756591796875
Validation loss: 2.0179440359915457

Epoch: 6| Step: 11
Training loss: 1.9295382499694824
Validation loss: 2.036395744610858

Epoch: 6| Step: 12
Training loss: 2.2825417518615723
Validation loss: 2.025312868497705

Epoch: 6| Step: 13
Training loss: 2.3369462490081787
Validation loss: 2.0177937105137813

Epoch: 102| Step: 0
Training loss: 2.764253616333008
Validation loss: 2.0175805348221973

Epoch: 6| Step: 1
Training loss: 2.14162015914917
Validation loss: 2.020373393130559

Epoch: 6| Step: 2
Training loss: 2.7278547286987305
Validation loss: 2.0172168695798485

Epoch: 6| Step: 3
Training loss: 1.9429570436477661
Validation loss: 2.008903936673236

Epoch: 6| Step: 4
Training loss: 2.8196425437927246
Validation loss: 2.0290528779388755

Epoch: 6| Step: 5
Training loss: 2.179830551147461
Validation loss: 2.0365074296151437

Epoch: 6| Step: 6
Training loss: 2.252678394317627
Validation loss: 2.0423416476095877

Epoch: 6| Step: 7
Training loss: 2.65031099319458
Validation loss: 2.0489918070454753

Epoch: 6| Step: 8
Training loss: 2.014749526977539
Validation loss: 2.0456782246148713

Epoch: 6| Step: 9
Training loss: 2.232991933822632
Validation loss: 2.0328464238874373

Epoch: 6| Step: 10
Training loss: 2.0154500007629395
Validation loss: 2.0244506892337593

Epoch: 6| Step: 11
Training loss: 2.5472469329833984
Validation loss: 2.0129930152687976

Epoch: 6| Step: 12
Training loss: 2.285518169403076
Validation loss: 2.004535203338951

Epoch: 6| Step: 13
Training loss: 1.746614933013916
Validation loss: 2.002831156535815

Epoch: 103| Step: 0
Training loss: 2.2968530654907227
Validation loss: 2.0043410101244525

Epoch: 6| Step: 1
Training loss: 2.16680908203125
Validation loss: 1.9991309219791042

Epoch: 6| Step: 2
Training loss: 1.9124846458435059
Validation loss: 2.005851158531763

Epoch: 6| Step: 3
Training loss: 2.1082983016967773
Validation loss: 2.001753432776338

Epoch: 6| Step: 4
Training loss: 2.1286535263061523
Validation loss: 1.999293137622136

Epoch: 6| Step: 5
Training loss: 2.8430726528167725
Validation loss: 1.9913983024576658

Epoch: 6| Step: 6
Training loss: 2.7298660278320312
Validation loss: 1.996416804611042

Epoch: 6| Step: 7
Training loss: 2.229836940765381
Validation loss: 2.0046370567814

Epoch: 6| Step: 8
Training loss: 1.9992303848266602
Validation loss: 1.9950607463877688

Epoch: 6| Step: 9
Training loss: 2.200373649597168
Validation loss: 1.9905835377272738

Epoch: 6| Step: 10
Training loss: 2.760159969329834
Validation loss: 1.989595277335054

Epoch: 6| Step: 11
Training loss: 2.720543384552002
Validation loss: 1.986540735408824

Epoch: 6| Step: 12
Training loss: 2.0113298892974854
Validation loss: 1.9857066754371888

Epoch: 6| Step: 13
Training loss: 2.1373095512390137
Validation loss: 1.9835819890422206

Epoch: 104| Step: 0
Training loss: 1.6675766706466675
Validation loss: 1.989567745116449

Epoch: 6| Step: 1
Training loss: 2.843975067138672
Validation loss: 2.0089096023190405

Epoch: 6| Step: 2
Training loss: 2.6016879081726074
Validation loss: 2.019218260242093

Epoch: 6| Step: 3
Training loss: 1.5850750207901
Validation loss: 2.0469474382297967

Epoch: 6| Step: 4
Training loss: 2.1376209259033203
Validation loss: 2.05193986943973

Epoch: 6| Step: 5
Training loss: 1.66719651222229
Validation loss: 2.039801081021627

Epoch: 6| Step: 6
Training loss: 2.2300500869750977
Validation loss: 2.034405421185237

Epoch: 6| Step: 7
Training loss: 2.890747308731079
Validation loss: 2.01118298756179

Epoch: 6| Step: 8
Training loss: 2.504910945892334
Validation loss: 2.0027975395161617

Epoch: 6| Step: 9
Training loss: 2.126051425933838
Validation loss: 2.007549794771338

Epoch: 6| Step: 10
Training loss: 2.835076093673706
Validation loss: 1.99928585175545

Epoch: 6| Step: 11
Training loss: 2.9749915599823
Validation loss: 2.0003315530797487

Epoch: 6| Step: 12
Training loss: 2.0815937519073486
Validation loss: 1.998523501939671

Epoch: 6| Step: 13
Training loss: 2.443465232849121
Validation loss: 2.002316080113893

Epoch: 105| Step: 0
Training loss: 2.961729049682617
Validation loss: 2.00084315705043

Epoch: 6| Step: 1
Training loss: 2.0447640419006348
Validation loss: 2.0123363246199903

Epoch: 6| Step: 2
Training loss: 3.0402398109436035
Validation loss: 1.9915886386748283

Epoch: 6| Step: 3
Training loss: 2.1515462398529053
Validation loss: 2.0044026079998223

Epoch: 6| Step: 4
Training loss: 1.8303418159484863
Validation loss: 2.0034635477168585

Epoch: 6| Step: 5
Training loss: 2.2885210514068604
Validation loss: 2.0096489344873736

Epoch: 6| Step: 6
Training loss: 1.8738771677017212
Validation loss: 2.026803183299239

Epoch: 6| Step: 7
Training loss: 2.0898678302764893
Validation loss: 2.033487558364868

Epoch: 6| Step: 8
Training loss: 2.1490366458892822
Validation loss: 2.031812278173303

Epoch: 6| Step: 9
Training loss: 1.9042340517044067
Validation loss: 2.043372020926527

Epoch: 6| Step: 10
Training loss: 2.425419569015503
Validation loss: 2.0446039040883384

Epoch: 6| Step: 11
Training loss: 2.3963871002197266
Validation loss: 2.0410388464568765

Epoch: 6| Step: 12
Training loss: 2.484431028366089
Validation loss: 2.03294175799175

Epoch: 6| Step: 13
Training loss: 2.8991544246673584
Validation loss: 2.0160917389777397

Epoch: 106| Step: 0
Training loss: 2.2791991233825684
Validation loss: 2.014078604277744

Epoch: 6| Step: 1
Training loss: 1.6294333934783936
Validation loss: 2.00270357952323

Epoch: 6| Step: 2
Training loss: 2.0678629875183105
Validation loss: 2.0044359866008965

Epoch: 6| Step: 3
Training loss: 2.2584612369537354
Validation loss: 1.9937248999072659

Epoch: 6| Step: 4
Training loss: 1.9216762781143188
Validation loss: 2.005631567329489

Epoch: 6| Step: 5
Training loss: 2.952916383743286
Validation loss: 2.0214007362242667

Epoch: 6| Step: 6
Training loss: 1.9806841611862183
Validation loss: 2.030777023684594

Epoch: 6| Step: 7
Training loss: 2.4305806159973145
Validation loss: 2.0749329110627532

Epoch: 6| Step: 8
Training loss: 2.730084180831909
Validation loss: 2.1098320407252156

Epoch: 6| Step: 9
Training loss: 2.5331103801727295
Validation loss: 2.115894902137018

Epoch: 6| Step: 10
Training loss: 2.9876415729522705
Validation loss: 2.1048701476025324

Epoch: 6| Step: 11
Training loss: 2.256601572036743
Validation loss: 2.0461322825442076

Epoch: 6| Step: 12
Training loss: 2.153080463409424
Validation loss: 2.0167238891765638

Epoch: 6| Step: 13
Training loss: 2.7715492248535156
Validation loss: 2.0105544828599498

Epoch: 107| Step: 0
Training loss: 2.6373844146728516
Validation loss: 1.9993530883583972

Epoch: 6| Step: 1
Training loss: 1.7516487836837769
Validation loss: 1.9942296679301927

Epoch: 6| Step: 2
Training loss: 2.9423327445983887
Validation loss: 2.000945827012421

Epoch: 6| Step: 3
Training loss: 2.1346728801727295
Validation loss: 2.0002484039593766

Epoch: 6| Step: 4
Training loss: 1.9555516242980957
Validation loss: 1.9959429643487419

Epoch: 6| Step: 5
Training loss: 2.8569607734680176
Validation loss: 2.0037896863875853

Epoch: 6| Step: 6
Training loss: 2.4893574714660645
Validation loss: 2.004595036147743

Epoch: 6| Step: 7
Training loss: 2.301436185836792
Validation loss: 2.028579915723493

Epoch: 6| Step: 8
Training loss: 1.8551535606384277
Validation loss: 2.031902592669251

Epoch: 6| Step: 9
Training loss: 2.3073160648345947
Validation loss: 2.0309028279396797

Epoch: 6| Step: 10
Training loss: 2.3869242668151855
Validation loss: 2.039028416397751

Epoch: 6| Step: 11
Training loss: 2.620448112487793
Validation loss: 2.022531663217852

Epoch: 6| Step: 12
Training loss: 1.8318368196487427
Validation loss: 2.0058786753685243

Epoch: 6| Step: 13
Training loss: 2.171980857849121
Validation loss: 2.00487502672339

Epoch: 108| Step: 0
Training loss: 2.8406105041503906
Validation loss: 2.0015477134335424

Epoch: 6| Step: 1
Training loss: 2.272719144821167
Validation loss: 1.9945371868789836

Epoch: 6| Step: 2
Training loss: 2.070079803466797
Validation loss: 1.9906309932790778

Epoch: 6| Step: 3
Training loss: 1.9262429475784302
Validation loss: 1.984249658482049

Epoch: 6| Step: 4
Training loss: 1.8083581924438477
Validation loss: 2.0033232268466743

Epoch: 6| Step: 5
Training loss: 2.161855936050415
Validation loss: 2.0147557643152054

Epoch: 6| Step: 6
Training loss: 2.166717529296875
Validation loss: 2.0097800557331373

Epoch: 6| Step: 7
Training loss: 2.60611629486084
Validation loss: 2.0290500938251452

Epoch: 6| Step: 8
Training loss: 2.33203125
Validation loss: 2.051899065253555

Epoch: 6| Step: 9
Training loss: 1.698490858078003
Validation loss: 2.0718528147666686

Epoch: 6| Step: 10
Training loss: 3.0507748126983643
Validation loss: 2.073934330735155

Epoch: 6| Step: 11
Training loss: 2.2044034004211426
Validation loss: 2.0795634741424234

Epoch: 6| Step: 12
Training loss: 2.790860176086426
Validation loss: 2.080841895072691

Epoch: 6| Step: 13
Training loss: 2.3948974609375
Validation loss: 2.052117188771566

Epoch: 109| Step: 0
Training loss: 2.8826003074645996
Validation loss: 2.0471625943337717

Epoch: 6| Step: 1
Training loss: 2.4009838104248047
Validation loss: 2.0238551401322886

Epoch: 6| Step: 2
Training loss: 1.837601661682129
Validation loss: 2.017258944049958

Epoch: 6| Step: 3
Training loss: 2.654611110687256
Validation loss: 2.011441902447772

Epoch: 6| Step: 4
Training loss: 2.3480920791625977
Validation loss: 2.0096422292852916

Epoch: 6| Step: 5
Training loss: 1.7999032735824585
Validation loss: 2.0013593114832395

Epoch: 6| Step: 6
Training loss: 2.8768057823181152
Validation loss: 1.9990144596304944

Epoch: 6| Step: 7
Training loss: 2.0848193168640137
Validation loss: 1.9948765898263583

Epoch: 6| Step: 8
Training loss: 1.6985058784484863
Validation loss: 2.0060033849490586

Epoch: 6| Step: 9
Training loss: 2.2024459838867188
Validation loss: 2.0037026405334473

Epoch: 6| Step: 10
Training loss: 2.3498940467834473
Validation loss: 1.9943259198178527

Epoch: 6| Step: 11
Training loss: 2.578901767730713
Validation loss: 1.995984177435598

Epoch: 6| Step: 12
Training loss: 2.3001179695129395
Validation loss: 1.9936156965071155

Epoch: 6| Step: 13
Training loss: 2.2147951126098633
Validation loss: 1.9891116311473231

Epoch: 110| Step: 0
Training loss: 2.3511240482330322
Validation loss: 1.9944414425921697

Epoch: 6| Step: 1
Training loss: 3.2286181449890137
Validation loss: 1.9730283470563992

Epoch: 6| Step: 2
Training loss: 2.608025074005127
Validation loss: 1.9730150084341727

Epoch: 6| Step: 3
Training loss: 2.168030261993408
Validation loss: 1.9760759927893197

Epoch: 6| Step: 4
Training loss: 2.06289005279541
Validation loss: 1.974403505684227

Epoch: 6| Step: 5
Training loss: 2.2369027137756348
Validation loss: 1.9746285382137503

Epoch: 6| Step: 6
Training loss: 2.0093588829040527
Validation loss: 1.9781222138353574

Epoch: 6| Step: 7
Training loss: 2.321932077407837
Validation loss: 1.9830839505759619

Epoch: 6| Step: 8
Training loss: 1.870876431465149
Validation loss: 1.9982163470278504

Epoch: 6| Step: 9
Training loss: 2.1957173347473145
Validation loss: 2.0219468493615427

Epoch: 6| Step: 10
Training loss: 2.4103803634643555
Validation loss: 2.021393523421339

Epoch: 6| Step: 11
Training loss: 1.6354944705963135
Validation loss: 2.024311532256424

Epoch: 6| Step: 12
Training loss: 2.452491044998169
Validation loss: 2.040821442040064

Epoch: 6| Step: 13
Training loss: 2.6708221435546875
Validation loss: 2.052187619670745

Epoch: 111| Step: 0
Training loss: 1.7662899494171143
Validation loss: 2.034787365185317

Epoch: 6| Step: 1
Training loss: 1.5919628143310547
Validation loss: 2.02967482484797

Epoch: 6| Step: 2
Training loss: 2.636927366256714
Validation loss: 2.0262878633314565

Epoch: 6| Step: 3
Training loss: 2.2786946296691895
Validation loss: 2.0104560928960002

Epoch: 6| Step: 4
Training loss: 2.8220901489257812
Validation loss: 1.996460066046766

Epoch: 6| Step: 5
Training loss: 2.4280896186828613
Validation loss: 1.9881568006289903

Epoch: 6| Step: 6
Training loss: 2.1320600509643555
Validation loss: 1.9860427738517843

Epoch: 6| Step: 7
Training loss: 1.9977837800979614
Validation loss: 1.978201699513261

Epoch: 6| Step: 8
Training loss: 2.5765979290008545
Validation loss: 1.9725481515289636

Epoch: 6| Step: 9
Training loss: 2.6195149421691895
Validation loss: 1.9657327526359147

Epoch: 6| Step: 10
Training loss: 2.278244972229004
Validation loss: 1.9651865331075524

Epoch: 6| Step: 11
Training loss: 2.573014736175537
Validation loss: 1.9721539558902863

Epoch: 6| Step: 12
Training loss: 2.1710290908813477
Validation loss: 1.9729779022996143

Epoch: 6| Step: 13
Training loss: 1.5529863834381104
Validation loss: 1.9713278329500588

Epoch: 112| Step: 0
Training loss: 1.7156312465667725
Validation loss: 1.9661393114315566

Epoch: 6| Step: 1
Training loss: 2.5481998920440674
Validation loss: 1.9526979936066495

Epoch: 6| Step: 2
Training loss: 2.541586399078369
Validation loss: 1.9626952935290594

Epoch: 6| Step: 3
Training loss: 1.9558213949203491
Validation loss: 1.9659931377698017

Epoch: 6| Step: 4
Training loss: 2.70957088470459
Validation loss: 1.9684546878260951

Epoch: 6| Step: 5
Training loss: 2.4007740020751953
Validation loss: 1.9714782686643704

Epoch: 6| Step: 6
Training loss: 1.90176522731781
Validation loss: 1.9820208536681307

Epoch: 6| Step: 7
Training loss: 2.6568565368652344
Validation loss: 1.9887452151185723

Epoch: 6| Step: 8
Training loss: 2.5482687950134277
Validation loss: 2.002260100456976

Epoch: 6| Step: 9
Training loss: 1.8390967845916748
Validation loss: 1.9960672804104385

Epoch: 6| Step: 10
Training loss: 2.609567403793335
Validation loss: 1.985950143106522

Epoch: 6| Step: 11
Training loss: 1.8889683485031128
Validation loss: 1.9857034016680974

Epoch: 6| Step: 12
Training loss: 2.399617910385132
Validation loss: 1.9688014317584295

Epoch: 6| Step: 13
Training loss: 2.2675464153289795
Validation loss: 1.9696893666380195

Epoch: 113| Step: 0
Training loss: 2.2707624435424805
Validation loss: 1.9607481623208651

Epoch: 6| Step: 1
Training loss: 1.8313887119293213
Validation loss: 1.9854523469043035

Epoch: 6| Step: 2
Training loss: 2.3013389110565186
Validation loss: 2.0254235934185725

Epoch: 6| Step: 3
Training loss: 2.673591136932373
Validation loss: 2.0351650817419893

Epoch: 6| Step: 4
Training loss: 2.328735113143921
Validation loss: 2.0573296662299865

Epoch: 6| Step: 5
Training loss: 2.1195521354675293
Validation loss: 2.057653206650929

Epoch: 6| Step: 6
Training loss: 1.9892107248306274
Validation loss: 2.06592389845079

Epoch: 6| Step: 7
Training loss: 1.8416273593902588
Validation loss: 2.0694178868365545

Epoch: 6| Step: 8
Training loss: 2.2068614959716797
Validation loss: 2.0468453181687223

Epoch: 6| Step: 9
Training loss: 2.972986936569214
Validation loss: 2.0147616350522606

Epoch: 6| Step: 10
Training loss: 2.2559118270874023
Validation loss: 1.998784262646911

Epoch: 6| Step: 11
Training loss: 2.547852039337158
Validation loss: 1.9844881642249323

Epoch: 6| Step: 12
Training loss: 2.7924132347106934
Validation loss: 1.9795551812776955

Epoch: 6| Step: 13
Training loss: 1.7990926504135132
Validation loss: 1.9575102072890087

Epoch: 114| Step: 0
Training loss: 2.641024351119995
Validation loss: 1.9632652062241749

Epoch: 6| Step: 1
Training loss: 2.576984405517578
Validation loss: 1.9648671727026663

Epoch: 6| Step: 2
Training loss: 2.3260371685028076
Validation loss: 1.9649250635536768

Epoch: 6| Step: 3
Training loss: 1.6049373149871826
Validation loss: 1.9671918140944613

Epoch: 6| Step: 4
Training loss: 2.0394980907440186
Validation loss: 1.9593514524480349

Epoch: 6| Step: 5
Training loss: 2.491575241088867
Validation loss: 1.9665732422182638

Epoch: 6| Step: 6
Training loss: 2.4778192043304443
Validation loss: 1.9744383711968698

Epoch: 6| Step: 7
Training loss: 2.298435688018799
Validation loss: 1.9861015132678452

Epoch: 6| Step: 8
Training loss: 2.505753993988037
Validation loss: 2.005466899564189

Epoch: 6| Step: 9
Training loss: 1.910579800605774
Validation loss: 2.0246738451783375

Epoch: 6| Step: 10
Training loss: 1.763918399810791
Validation loss: 2.031929228895454

Epoch: 6| Step: 11
Training loss: 2.5823540687561035
Validation loss: 2.0347661215771913

Epoch: 6| Step: 12
Training loss: 2.583690643310547
Validation loss: 2.0481235852805515

Epoch: 6| Step: 13
Training loss: 2.3476550579071045
Validation loss: 2.0169692603490685

Epoch: 115| Step: 0
Training loss: 2.4843063354492188
Validation loss: 2.00996539156924

Epoch: 6| Step: 1
Training loss: 2.594663143157959
Validation loss: 1.9761620324145082

Epoch: 6| Step: 2
Training loss: 2.21229887008667
Validation loss: 1.9795198389278945

Epoch: 6| Step: 3
Training loss: 1.77571702003479
Validation loss: 1.963091173479634

Epoch: 6| Step: 4
Training loss: 2.2165536880493164
Validation loss: 1.9546485011295607

Epoch: 6| Step: 5
Training loss: 2.3322761058807373
Validation loss: 1.9405025320668374

Epoch: 6| Step: 6
Training loss: 2.396790027618408
Validation loss: 1.9296349274214877

Epoch: 6| Step: 7
Training loss: 2.3164772987365723
Validation loss: 1.9435134087839434

Epoch: 6| Step: 8
Training loss: 2.505033493041992
Validation loss: 1.941026581230984

Epoch: 6| Step: 9
Training loss: 2.615006923675537
Validation loss: 1.9419685897006784

Epoch: 6| Step: 10
Training loss: 2.0831921100616455
Validation loss: 1.9532907034761162

Epoch: 6| Step: 11
Training loss: 1.8064888715744019
Validation loss: 1.9491138560797578

Epoch: 6| Step: 12
Training loss: 1.9976980686187744
Validation loss: 1.9532056841799008

Epoch: 6| Step: 13
Training loss: 2.344306468963623
Validation loss: 1.9598420409746067

Epoch: 116| Step: 0
Training loss: 1.9895975589752197
Validation loss: 2.0185024738311768

Epoch: 6| Step: 1
Training loss: 2.2347397804260254
Validation loss: 2.0910949399394374

Epoch: 6| Step: 2
Training loss: 2.6830368041992188
Validation loss: 2.192192035336648

Epoch: 6| Step: 3
Training loss: 2.927246332168579
Validation loss: 2.3098016015944944

Epoch: 6| Step: 4
Training loss: 2.5015149116516113
Validation loss: 2.3044150003822903

Epoch: 6| Step: 5
Training loss: 1.7409006357192993
Validation loss: 2.2526523759288173

Epoch: 6| Step: 6
Training loss: 2.2132153511047363
Validation loss: 2.175386505742227

Epoch: 6| Step: 7
Training loss: 2.309790849685669
Validation loss: 2.1327350152436124

Epoch: 6| Step: 8
Training loss: 2.799928665161133
Validation loss: 2.063925932812434

Epoch: 6| Step: 9
Training loss: 1.8987085819244385
Validation loss: 2.019528099285659

Epoch: 6| Step: 10
Training loss: 2.125218629837036
Validation loss: 1.995683967426259

Epoch: 6| Step: 11
Training loss: 2.593356132507324
Validation loss: 1.9889027123810143

Epoch: 6| Step: 12
Training loss: 2.5224616527557373
Validation loss: 1.9821091095606487

Epoch: 6| Step: 13
Training loss: 2.474461078643799
Validation loss: 1.991352019771453

Epoch: 117| Step: 0
Training loss: 2.6198477745056152
Validation loss: 1.9869228178454983

Epoch: 6| Step: 1
Training loss: 1.6310060024261475
Validation loss: 1.9928651971201743

Epoch: 6| Step: 2
Training loss: 2.2065913677215576
Validation loss: 1.985892439401278

Epoch: 6| Step: 3
Training loss: 1.6883856058120728
Validation loss: 1.9927850897594164

Epoch: 6| Step: 4
Training loss: 1.667073369026184
Validation loss: 1.9894013635573848

Epoch: 6| Step: 5
Training loss: 2.495321273803711
Validation loss: 1.9894230558026222

Epoch: 6| Step: 6
Training loss: 3.2952778339385986
Validation loss: 1.9852753198275002

Epoch: 6| Step: 7
Training loss: 2.358689785003662
Validation loss: 1.9850768094421716

Epoch: 6| Step: 8
Training loss: 2.9700286388397217
Validation loss: 1.9733650261355984

Epoch: 6| Step: 9
Training loss: 1.2292046546936035
Validation loss: 1.9809589155258671

Epoch: 6| Step: 10
Training loss: 2.962924003601074
Validation loss: 1.9988026631775724

Epoch: 6| Step: 11
Training loss: 2.3555479049682617
Validation loss: 2.035742736631824

Epoch: 6| Step: 12
Training loss: 2.1929516792297363
Validation loss: 2.0698366421525196

Epoch: 6| Step: 13
Training loss: 2.805081605911255
Validation loss: 2.094141338461189

Epoch: 118| Step: 0
Training loss: 2.4048187732696533
Validation loss: 2.095132702140398

Epoch: 6| Step: 1
Training loss: 2.61842679977417
Validation loss: 2.0890082159349994

Epoch: 6| Step: 2
Training loss: 2.1410138607025146
Validation loss: 2.06780836402729

Epoch: 6| Step: 3
Training loss: 2.839527130126953
Validation loss: 2.025737572741765

Epoch: 6| Step: 4
Training loss: 2.3372414112091064
Validation loss: 1.9756490427960631

Epoch: 6| Step: 5
Training loss: 2.6550097465515137
Validation loss: 1.9556436307968632

Epoch: 6| Step: 6
Training loss: 2.956717014312744
Validation loss: 1.9518105753006474

Epoch: 6| Step: 7
Training loss: 1.5718598365783691
Validation loss: 1.953287519434447

Epoch: 6| Step: 8
Training loss: 2.596224308013916
Validation loss: 1.9515919005999

Epoch: 6| Step: 9
Training loss: 1.7314468622207642
Validation loss: 1.9528894462893087

Epoch: 6| Step: 10
Training loss: 1.7687172889709473
Validation loss: 1.9508120975186747

Epoch: 6| Step: 11
Training loss: 2.132563591003418
Validation loss: 1.9485926679385606

Epoch: 6| Step: 12
Training loss: 1.8607661724090576
Validation loss: 1.9445317547808412

Epoch: 6| Step: 13
Training loss: 2.5641582012176514
Validation loss: 1.9495605114967591

Epoch: 119| Step: 0
Training loss: 2.433018684387207
Validation loss: 1.9412103058189474

Epoch: 6| Step: 1
Training loss: 2.343841552734375
Validation loss: 1.9444174446085447

Epoch: 6| Step: 2
Training loss: 1.6224048137664795
Validation loss: 1.9528959489637805

Epoch: 6| Step: 3
Training loss: 2.7830874919891357
Validation loss: 1.9609580629615373

Epoch: 6| Step: 4
Training loss: 2.394108533859253
Validation loss: 1.961703287657871

Epoch: 6| Step: 5
Training loss: 2.250502586364746
Validation loss: 1.978673804190851

Epoch: 6| Step: 6
Training loss: 2.468235492706299
Validation loss: 1.9843958013801164

Epoch: 6| Step: 7
Training loss: 1.8477113246917725
Validation loss: 1.9715186113952308

Epoch: 6| Step: 8
Training loss: 2.321023464202881
Validation loss: 1.9619318157114007

Epoch: 6| Step: 9
Training loss: 1.7122008800506592
Validation loss: 1.9597434638648905

Epoch: 6| Step: 10
Training loss: 2.486673355102539
Validation loss: 1.952880943975141

Epoch: 6| Step: 11
Training loss: 2.439876079559326
Validation loss: 1.944921067965928

Epoch: 6| Step: 12
Training loss: 1.8594472408294678
Validation loss: 1.950339094285042

Epoch: 6| Step: 13
Training loss: 2.5497782230377197
Validation loss: 1.9419794198005431

Epoch: 120| Step: 0
Training loss: 2.0669052600860596
Validation loss: 1.9604968627293904

Epoch: 6| Step: 1
Training loss: 1.6830999851226807
Validation loss: 1.9480525319294264

Epoch: 6| Step: 2
Training loss: 1.9964908361434937
Validation loss: 1.9578599199171989

Epoch: 6| Step: 3
Training loss: 2.2624197006225586
Validation loss: 1.966860589160714

Epoch: 6| Step: 4
Training loss: 2.667224168777466
Validation loss: 1.9720799666579052

Epoch: 6| Step: 5
Training loss: 2.9207799434661865
Validation loss: 1.953607443840273

Epoch: 6| Step: 6
Training loss: 2.478083848953247
Validation loss: 1.9523419077678392

Epoch: 6| Step: 7
Training loss: 2.1057069301605225
Validation loss: 1.9564191423436648

Epoch: 6| Step: 8
Training loss: 1.9278359413146973
Validation loss: 1.9403352891245196

Epoch: 6| Step: 9
Training loss: 2.279636859893799
Validation loss: 1.9441590129688222

Epoch: 6| Step: 10
Training loss: 2.1486124992370605
Validation loss: 1.947916756394089

Epoch: 6| Step: 11
Training loss: 2.2010793685913086
Validation loss: 1.9398015365805676

Epoch: 6| Step: 12
Training loss: 1.9279301166534424
Validation loss: 1.9418101938821937

Epoch: 6| Step: 13
Training loss: 2.5607011318206787
Validation loss: 1.9488208781006515

Epoch: 121| Step: 0
Training loss: 2.4476890563964844
Validation loss: 1.9575216103625555

Epoch: 6| Step: 1
Training loss: 2.374462842941284
Validation loss: 1.9592855566291398

Epoch: 6| Step: 2
Training loss: 2.7221322059631348
Validation loss: 1.9695597566584104

Epoch: 6| Step: 3
Training loss: 2.331620454788208
Validation loss: 1.9705874727618309

Epoch: 6| Step: 4
Training loss: 2.381169557571411
Validation loss: 1.954992336611594

Epoch: 6| Step: 5
Training loss: 1.2562692165374756
Validation loss: 1.9659778212988248

Epoch: 6| Step: 6
Training loss: 2.0813863277435303
Validation loss: 1.9656124602081955

Epoch: 6| Step: 7
Training loss: 2.130509376525879
Validation loss: 1.9678235156561739

Epoch: 6| Step: 8
Training loss: 1.115751028060913
Validation loss: 1.9605997711099603

Epoch: 6| Step: 9
Training loss: 2.5078513622283936
Validation loss: 1.975072547953616

Epoch: 6| Step: 10
Training loss: 2.235525608062744
Validation loss: 1.951700090080179

Epoch: 6| Step: 11
Training loss: 3.1476221084594727
Validation loss: 1.9440199893007997

Epoch: 6| Step: 12
Training loss: 1.705650806427002
Validation loss: 1.9382342215507262

Epoch: 6| Step: 13
Training loss: 2.3045151233673096
Validation loss: 1.934332473303682

Epoch: 122| Step: 0
Training loss: 2.5921823978424072
Validation loss: 1.9479275134301954

Epoch: 6| Step: 1
Training loss: 1.7971805334091187
Validation loss: 1.9479469124988844

Epoch: 6| Step: 2
Training loss: 1.6752426624298096
Validation loss: 1.943255506536012

Epoch: 6| Step: 3
Training loss: 2.072077512741089
Validation loss: 1.9446523304908507

Epoch: 6| Step: 4
Training loss: 2.6980209350585938
Validation loss: 1.9490798160593996

Epoch: 6| Step: 5
Training loss: 2.406055450439453
Validation loss: 1.953851322973928

Epoch: 6| Step: 6
Training loss: 2.668576240539551
Validation loss: 1.9596171302180136

Epoch: 6| Step: 7
Training loss: 2.3971519470214844
Validation loss: 1.9632118607080111

Epoch: 6| Step: 8
Training loss: 2.4255008697509766
Validation loss: 1.9709806749897618

Epoch: 6| Step: 9
Training loss: 1.8102376461029053
Validation loss: 1.9820894861734042

Epoch: 6| Step: 10
Training loss: 1.6503620147705078
Validation loss: 1.9802981704793952

Epoch: 6| Step: 11
Training loss: 2.3343863487243652
Validation loss: 1.9663999836931947

Epoch: 6| Step: 12
Training loss: 2.227447032928467
Validation loss: 1.9523832439094462

Epoch: 6| Step: 13
Training loss: 2.6593706607818604
Validation loss: 1.9543567011433263

Epoch: 123| Step: 0
Training loss: 2.2278356552124023
Validation loss: 1.9444714259075861

Epoch: 6| Step: 1
Training loss: 1.8426780700683594
Validation loss: 1.9337928038771435

Epoch: 6| Step: 2
Training loss: 1.189568042755127
Validation loss: 1.945086012604416

Epoch: 6| Step: 3
Training loss: 2.8488290309906006
Validation loss: 1.9570026013158983

Epoch: 6| Step: 4
Training loss: 1.8978959321975708
Validation loss: 1.9613568987897647

Epoch: 6| Step: 5
Training loss: 2.296934127807617
Validation loss: 1.9625028346174507

Epoch: 6| Step: 6
Training loss: 1.762718915939331
Validation loss: 1.979338013997642

Epoch: 6| Step: 7
Training loss: 2.23527193069458
Validation loss: 2.0085008785288823

Epoch: 6| Step: 8
Training loss: 1.5733332633972168
Validation loss: 1.9927140461501254

Epoch: 6| Step: 9
Training loss: 2.627978801727295
Validation loss: 1.9591052814196515

Epoch: 6| Step: 10
Training loss: 2.4312498569488525
Validation loss: 1.9450405759196128

Epoch: 6| Step: 11
Training loss: 3.043729782104492
Validation loss: 1.9369185945039153

Epoch: 6| Step: 12
Training loss: 2.2453255653381348
Validation loss: 1.9344088159581667

Epoch: 6| Step: 13
Training loss: 2.9851062297821045
Validation loss: 1.9267368162831953

Epoch: 124| Step: 0
Training loss: 2.32928729057312
Validation loss: 1.9289021492004395

Epoch: 6| Step: 1
Training loss: 1.7547061443328857
Validation loss: 1.924394574216617

Epoch: 6| Step: 2
Training loss: 2.43479585647583
Validation loss: 1.919438321103332

Epoch: 6| Step: 3
Training loss: 2.5762948989868164
Validation loss: 1.9071481189420145

Epoch: 6| Step: 4
Training loss: 2.0476856231689453
Validation loss: 1.915169260835135

Epoch: 6| Step: 5
Training loss: 2.8084235191345215
Validation loss: 1.9170293269618865

Epoch: 6| Step: 6
Training loss: 2.6638686656951904
Validation loss: 1.9114513820217502

Epoch: 6| Step: 7
Training loss: 2.295077085494995
Validation loss: 1.918331051385531

Epoch: 6| Step: 8
Training loss: 1.947561502456665
Validation loss: 1.9602130343837123

Epoch: 6| Step: 9
Training loss: 2.1964523792266846
Validation loss: 2.010438580666819

Epoch: 6| Step: 10
Training loss: 2.2019126415252686
Validation loss: 2.015846767733174

Epoch: 6| Step: 11
Training loss: 2.3493306636810303
Validation loss: 2.024449827850506

Epoch: 6| Step: 12
Training loss: 2.0178170204162598
Validation loss: 2.035097599029541

Epoch: 6| Step: 13
Training loss: 1.1053193807601929
Validation loss: 2.024071970293599

Epoch: 125| Step: 0
Training loss: 2.0211057662963867
Validation loss: 1.9839901898496894

Epoch: 6| Step: 1
Training loss: 2.060091733932495
Validation loss: 1.947818556139546

Epoch: 6| Step: 2
Training loss: 2.0624728202819824
Validation loss: 1.9057543585377354

Epoch: 6| Step: 3
Training loss: 3.1381216049194336
Validation loss: 1.8934887480992142

Epoch: 6| Step: 4
Training loss: 1.8423653841018677
Validation loss: 1.904934247334798

Epoch: 6| Step: 5
Training loss: 2.072444200515747
Validation loss: 1.9128944309808875

Epoch: 6| Step: 6
Training loss: 2.0802626609802246
Validation loss: 1.9197266768383723

Epoch: 6| Step: 7
Training loss: 2.75063419342041
Validation loss: 1.9232004278449601

Epoch: 6| Step: 8
Training loss: 2.2993502616882324
Validation loss: 1.9174550771713257

Epoch: 6| Step: 9
Training loss: 2.7167775630950928
Validation loss: 1.925397257651052

Epoch: 6| Step: 10
Training loss: 1.6947245597839355
Validation loss: 1.942964594851258

Epoch: 6| Step: 11
Training loss: 2.328413963317871
Validation loss: 1.9465934409890124

Epoch: 6| Step: 12
Training loss: 2.184640884399414
Validation loss: 1.9566026631221975

Epoch: 6| Step: 13
Training loss: 2.175913095474243
Validation loss: 1.9807480253199095

Epoch: 126| Step: 0
Training loss: 2.3188676834106445
Validation loss: 1.9707970606383456

Epoch: 6| Step: 1
Training loss: 2.3516016006469727
Validation loss: 1.9628506065696798

Epoch: 6| Step: 2
Training loss: 1.8174188137054443
Validation loss: 1.9609221232834684

Epoch: 6| Step: 3
Training loss: 2.3087921142578125
Validation loss: 1.9697898228963215

Epoch: 6| Step: 4
Training loss: 2.1396141052246094
Validation loss: 1.977049284083869

Epoch: 6| Step: 5
Training loss: 1.9098913669586182
Validation loss: 1.966422987240617

Epoch: 6| Step: 6
Training loss: 2.480818271636963
Validation loss: 1.9411879982999576

Epoch: 6| Step: 7
Training loss: 1.7510836124420166
Validation loss: 1.9327252782801145

Epoch: 6| Step: 8
Training loss: 1.818513035774231
Validation loss: 1.93118929606612

Epoch: 6| Step: 9
Training loss: 2.82492733001709
Validation loss: 1.92705709831689

Epoch: 6| Step: 10
Training loss: 1.6655759811401367
Validation loss: 1.9220124265199066

Epoch: 6| Step: 11
Training loss: 2.5058176517486572
Validation loss: 1.9267628167265205

Epoch: 6| Step: 12
Training loss: 3.0192785263061523
Validation loss: 1.9239081259696715

Epoch: 6| Step: 13
Training loss: 2.2491769790649414
Validation loss: 1.9306919087645829

Epoch: 127| Step: 0
Training loss: 2.1490535736083984
Validation loss: 1.936887805179883

Epoch: 6| Step: 1
Training loss: 2.4866714477539062
Validation loss: 1.9803130216495965

Epoch: 6| Step: 2
Training loss: 2.959689140319824
Validation loss: 2.004691562344951

Epoch: 6| Step: 3
Training loss: 1.682828664779663
Validation loss: 2.0244748182194208

Epoch: 6| Step: 4
Training loss: 1.8139381408691406
Validation loss: 1.9974559173789075

Epoch: 6| Step: 5
Training loss: 2.5354292392730713
Validation loss: 1.9465781796363093

Epoch: 6| Step: 6
Training loss: 2.1759142875671387
Validation loss: 1.9398929636965516

Epoch: 6| Step: 7
Training loss: 2.2928812503814697
Validation loss: 1.937264633435075

Epoch: 6| Step: 8
Training loss: 2.258344888687134
Validation loss: 1.920253440897952

Epoch: 6| Step: 9
Training loss: 1.7323923110961914
Validation loss: 1.9049994432797996

Epoch: 6| Step: 10
Training loss: 2.7508339881896973
Validation loss: 1.9094717835867276

Epoch: 6| Step: 11
Training loss: 1.5071735382080078
Validation loss: 1.9142071636774207

Epoch: 6| Step: 12
Training loss: 2.1002633571624756
Validation loss: 1.9183275161250946

Epoch: 6| Step: 13
Training loss: 3.010047197341919
Validation loss: 1.9072946681771228

Epoch: 128| Step: 0
Training loss: 2.2413148880004883
Validation loss: 1.9047404181572698

Epoch: 6| Step: 1
Training loss: 1.7633304595947266
Validation loss: 1.8972389980029034

Epoch: 6| Step: 2
Training loss: 1.9729235172271729
Validation loss: 1.8916141704846454

Epoch: 6| Step: 3
Training loss: 1.8810675144195557
Validation loss: 1.8983670588462584

Epoch: 6| Step: 4
Training loss: 2.694875478744507
Validation loss: 1.8932546184908958

Epoch: 6| Step: 5
Training loss: 2.661208152770996
Validation loss: 1.9040923272409747

Epoch: 6| Step: 6
Training loss: 1.811988115310669
Validation loss: 1.8975069753585323

Epoch: 6| Step: 7
Training loss: 3.0520591735839844
Validation loss: 1.9106261525102841

Epoch: 6| Step: 8
Training loss: 1.9544323682785034
Validation loss: 1.9177630332208448

Epoch: 6| Step: 9
Training loss: 2.164015769958496
Validation loss: 1.9287174619654173

Epoch: 6| Step: 10
Training loss: 1.8599095344543457
Validation loss: 1.9341634601675055

Epoch: 6| Step: 11
Training loss: 1.920773983001709
Validation loss: 1.9481115751369025

Epoch: 6| Step: 12
Training loss: 1.7885730266571045
Validation loss: 1.9622212968846804

Epoch: 6| Step: 13
Training loss: 2.8683464527130127
Validation loss: 1.9811503694903465

Epoch: 129| Step: 0
Training loss: 2.2583956718444824
Validation loss: 1.9876868417186122

Epoch: 6| Step: 1
Training loss: 2.3986966609954834
Validation loss: 1.979796987707897

Epoch: 6| Step: 2
Training loss: 2.10080623626709
Validation loss: 1.9657798287689046

Epoch: 6| Step: 3
Training loss: 2.0138444900512695
Validation loss: 1.9603361903980214

Epoch: 6| Step: 4
Training loss: 2.132586717605591
Validation loss: 1.947749408342505

Epoch: 6| Step: 5
Training loss: 2.3135037422180176
Validation loss: 1.9437758127848308

Epoch: 6| Step: 6
Training loss: 2.7828943729400635
Validation loss: 1.9328602219140658

Epoch: 6| Step: 7
Training loss: 1.8818557262420654
Validation loss: 1.928476027263108

Epoch: 6| Step: 8
Training loss: 2.723625421524048
Validation loss: 1.9161782149345643

Epoch: 6| Step: 9
Training loss: 1.5627310276031494
Validation loss: 1.9177219636978642

Epoch: 6| Step: 10
Training loss: 2.197620391845703
Validation loss: 1.9114505911386142

Epoch: 6| Step: 11
Training loss: 1.7731009721755981
Validation loss: 1.9114925630630986

Epoch: 6| Step: 12
Training loss: 2.3130791187286377
Validation loss: 1.9074246447573426

Epoch: 6| Step: 13
Training loss: 2.3976945877075195
Validation loss: 1.9118770694219938

Epoch: 130| Step: 0
Training loss: 1.6592122316360474
Validation loss: 1.914352810511025

Epoch: 6| Step: 1
Training loss: 2.008845329284668
Validation loss: 1.904178830885118

Epoch: 6| Step: 2
Training loss: 1.93635094165802
Validation loss: 1.9349546047949022

Epoch: 6| Step: 3
Training loss: 2.603757381439209
Validation loss: 1.9369085168325773

Epoch: 6| Step: 4
Training loss: 2.155050039291382
Validation loss: 1.946966350719493

Epoch: 6| Step: 5
Training loss: 1.9749064445495605
Validation loss: 1.9359234276638235

Epoch: 6| Step: 6
Training loss: 1.778754472732544
Validation loss: 1.921681748923435

Epoch: 6| Step: 7
Training loss: 2.2190699577331543
Validation loss: 1.9178911921798543

Epoch: 6| Step: 8
Training loss: 2.561643600463867
Validation loss: 1.908501382796995

Epoch: 6| Step: 9
Training loss: 2.7697134017944336
Validation loss: 1.9108979163631317

Epoch: 6| Step: 10
Training loss: 2.308964252471924
Validation loss: 1.9117360896961664

Epoch: 6| Step: 11
Training loss: 2.2730977535247803
Validation loss: 1.9039100485463296

Epoch: 6| Step: 12
Training loss: 2.615384578704834
Validation loss: 1.908229338225498

Epoch: 6| Step: 13
Training loss: 1.120995283126831
Validation loss: 1.9151926732832385

Epoch: 131| Step: 0
Training loss: 2.2304275035858154
Validation loss: 1.9123014327018493

Epoch: 6| Step: 1
Training loss: 2.673184394836426
Validation loss: 1.914603482010544

Epoch: 6| Step: 2
Training loss: 2.3022873401641846
Validation loss: 1.9138985654359222

Epoch: 6| Step: 3
Training loss: 1.7046318054199219
Validation loss: 1.9081882789570799

Epoch: 6| Step: 4
Training loss: 1.4078510999679565
Validation loss: 1.9178251207515757

Epoch: 6| Step: 5
Training loss: 2.6558468341827393
Validation loss: 1.9292964217483357

Epoch: 6| Step: 6
Training loss: 3.066077947616577
Validation loss: 1.9375390724469257

Epoch: 6| Step: 7
Training loss: 2.1734347343444824
Validation loss: 1.9579487769834456

Epoch: 6| Step: 8
Training loss: 2.7071280479431152
Validation loss: 1.9628663024594706

Epoch: 6| Step: 9
Training loss: 1.4659662246704102
Validation loss: 1.9652376033926522

Epoch: 6| Step: 10
Training loss: 2.1187524795532227
Validation loss: 1.941269660508761

Epoch: 6| Step: 11
Training loss: 2.0191962718963623
Validation loss: 1.9221979238653695

Epoch: 6| Step: 12
Training loss: 1.870461344718933
Validation loss: 1.9012730262612785

Epoch: 6| Step: 13
Training loss: 2.546879291534424
Validation loss: 1.891876474503548

Epoch: 132| Step: 0
Training loss: 1.8243062496185303
Validation loss: 1.8792985100899973

Epoch: 6| Step: 1
Training loss: 2.2462830543518066
Validation loss: 1.8889428287424066

Epoch: 6| Step: 2
Training loss: 2.156618595123291
Validation loss: 1.9025616632994784

Epoch: 6| Step: 3
Training loss: 1.8451387882232666
Validation loss: 1.922836644675142

Epoch: 6| Step: 4
Training loss: 1.9919934272766113
Validation loss: 1.9266248518420803

Epoch: 6| Step: 5
Training loss: 2.3023369312286377
Validation loss: 1.916413781463459

Epoch: 6| Step: 6
Training loss: 1.390007734298706
Validation loss: 1.8957130460328953

Epoch: 6| Step: 7
Training loss: 2.172913074493408
Validation loss: 1.8906267419938119

Epoch: 6| Step: 8
Training loss: 2.377653121948242
Validation loss: 1.892899062043877

Epoch: 6| Step: 9
Training loss: 1.9587762355804443
Validation loss: 1.892649910783255

Epoch: 6| Step: 10
Training loss: 2.0264439582824707
Validation loss: 1.8987821763561619

Epoch: 6| Step: 11
Training loss: 2.3716039657592773
Validation loss: 1.8952630771103727

Epoch: 6| Step: 12
Training loss: 3.5078482627868652
Validation loss: 1.9018500953592279

Epoch: 6| Step: 13
Training loss: 1.946137547492981
Validation loss: 1.91412514896803

Epoch: 133| Step: 0
Training loss: 2.2536330223083496
Validation loss: 1.917684139743928

Epoch: 6| Step: 1
Training loss: 1.7268540859222412
Validation loss: 1.9194793649899062

Epoch: 6| Step: 2
Training loss: 2.3281331062316895
Validation loss: 1.9242354131514026

Epoch: 6| Step: 3
Training loss: 2.196112632751465
Validation loss: 1.9506998562043714

Epoch: 6| Step: 4
Training loss: 2.0536341667175293
Validation loss: 1.9707370663201937

Epoch: 6| Step: 5
Training loss: 1.4891870021820068
Validation loss: 1.9640765792580062

Epoch: 6| Step: 6
Training loss: 2.798574924468994
Validation loss: 1.9492587479211951

Epoch: 6| Step: 7
Training loss: 2.6211724281311035
Validation loss: 1.9329394884006952

Epoch: 6| Step: 8
Training loss: 2.534721851348877
Validation loss: 1.9094496516771213

Epoch: 6| Step: 9
Training loss: 1.6982990503311157
Validation loss: 1.8963182472413587

Epoch: 6| Step: 10
Training loss: 2.384521484375
Validation loss: 1.9081589201445222

Epoch: 6| Step: 11
Training loss: 2.2476935386657715
Validation loss: 1.9075711978379117

Epoch: 6| Step: 12
Training loss: 2.015130043029785
Validation loss: 1.891405878528472

Epoch: 6| Step: 13
Training loss: 1.7362884283065796
Validation loss: 1.8952729009812879

Epoch: 134| Step: 0
Training loss: 2.77919340133667
Validation loss: 1.8947221822636102

Epoch: 6| Step: 1
Training loss: 1.5397155284881592
Validation loss: 1.8932209219983829

Epoch: 6| Step: 2
Training loss: 2.1489171981811523
Validation loss: 1.903115931377616

Epoch: 6| Step: 3
Training loss: 1.616986632347107
Validation loss: 1.897671381632487

Epoch: 6| Step: 4
Training loss: 1.7309372425079346
Validation loss: 1.924341360727946

Epoch: 6| Step: 5
Training loss: 2.7202627658843994
Validation loss: 1.9736220682820966

Epoch: 6| Step: 6
Training loss: 2.5229365825653076
Validation loss: 2.0184701155590754

Epoch: 6| Step: 7
Training loss: 2.2171127796173096
Validation loss: 2.0508246216722714

Epoch: 6| Step: 8
Training loss: 2.246339797973633
Validation loss: 2.0393004109782558

Epoch: 6| Step: 9
Training loss: 1.9913334846496582
Validation loss: 2.0217532342480076

Epoch: 6| Step: 10
Training loss: 2.4979729652404785
Validation loss: 1.983395215003721

Epoch: 6| Step: 11
Training loss: 2.332495927810669
Validation loss: 1.9298148283394434

Epoch: 6| Step: 12
Training loss: 2.173086404800415
Validation loss: 1.9454961489605647

Epoch: 6| Step: 13
Training loss: 2.118685483932495
Validation loss: 1.9796612903635988

Epoch: 135| Step: 0
Training loss: 2.6608283519744873
Validation loss: 2.033387179015785

Epoch: 6| Step: 1
Training loss: 2.453709602355957
Validation loss: 2.032585628571049

Epoch: 6| Step: 2
Training loss: 2.0615084171295166
Validation loss: 2.0099292429544593

Epoch: 6| Step: 3
Training loss: 2.395184278488159
Validation loss: 1.9571781645538986

Epoch: 6| Step: 4
Training loss: 2.1728267669677734
Validation loss: 1.931761190455447

Epoch: 6| Step: 5
Training loss: 2.347614288330078
Validation loss: 1.9344753860145487

Epoch: 6| Step: 6
Training loss: 3.096372604370117
Validation loss: 1.9465355027106501

Epoch: 6| Step: 7
Training loss: 2.2763729095458984
Validation loss: 1.9668636168203046

Epoch: 6| Step: 8
Training loss: 1.861501693725586
Validation loss: 1.9930396541472404

Epoch: 6| Step: 9
Training loss: 1.8111591339111328
Validation loss: 2.001713134909189

Epoch: 6| Step: 10
Training loss: 2.453181266784668
Validation loss: 1.9876271268372894

Epoch: 6| Step: 11
Training loss: 2.074303150177002
Validation loss: 1.9619275036678518

Epoch: 6| Step: 12
Training loss: 1.3870999813079834
Validation loss: 1.9365059791072723

Epoch: 6| Step: 13
Training loss: 2.1601922512054443
Validation loss: 1.935066779454549

Epoch: 136| Step: 0
Training loss: 1.901726484298706
Validation loss: 1.9218722504954184

Epoch: 6| Step: 1
Training loss: 2.1078412532806396
Validation loss: 1.9066243428055958

Epoch: 6| Step: 2
Training loss: 2.341419219970703
Validation loss: 1.9041096843698972

Epoch: 6| Step: 3
Training loss: 2.0216598510742188
Validation loss: 1.9049230954980338

Epoch: 6| Step: 4
Training loss: 2.4781298637390137
Validation loss: 1.9169099882084837

Epoch: 6| Step: 5
Training loss: 1.3484994173049927
Validation loss: 1.9205721642381401

Epoch: 6| Step: 6
Training loss: 2.349148988723755
Validation loss: 1.9172965006161762

Epoch: 6| Step: 7
Training loss: 2.2780890464782715
Validation loss: 1.9233635830622848

Epoch: 6| Step: 8
Training loss: 2.394152879714966
Validation loss: 1.9369980724908973

Epoch: 6| Step: 9
Training loss: 2.0621252059936523
Validation loss: 1.9498359849376063

Epoch: 6| Step: 10
Training loss: 2.3131704330444336
Validation loss: 1.9757963662506433

Epoch: 6| Step: 11
Training loss: 2.1728930473327637
Validation loss: 1.9726665865990423

Epoch: 6| Step: 12
Training loss: 2.6462411880493164
Validation loss: 1.9740829339591406

Epoch: 6| Step: 13
Training loss: 2.2586214542388916
Validation loss: 1.9550936350258448

Epoch: 137| Step: 0
Training loss: 1.8836904764175415
Validation loss: 1.9349978905852123

Epoch: 6| Step: 1
Training loss: 1.6466988325119019
Validation loss: 1.9205874499454294

Epoch: 6| Step: 2
Training loss: 3.149667739868164
Validation loss: 1.9203262944375314

Epoch: 6| Step: 3
Training loss: 2.4632017612457275
Validation loss: 1.9011907897969729

Epoch: 6| Step: 4
Training loss: 1.970908761024475
Validation loss: 1.8936528916000037

Epoch: 6| Step: 5
Training loss: 2.1851859092712402
Validation loss: 1.8950371280793221

Epoch: 6| Step: 6
Training loss: 2.102534770965576
Validation loss: 1.8986384740439795

Epoch: 6| Step: 7
Training loss: 2.2073004245758057
Validation loss: 1.897586408481803

Epoch: 6| Step: 8
Training loss: 1.950798511505127
Validation loss: 1.8980935876087477

Epoch: 6| Step: 9
Training loss: 2.1362104415893555
Validation loss: 1.89830582885332

Epoch: 6| Step: 10
Training loss: 1.7482500076293945
Validation loss: 1.880072025842564

Epoch: 6| Step: 11
Training loss: 2.5277256965637207
Validation loss: 1.897474096667382

Epoch: 6| Step: 12
Training loss: 1.9475305080413818
Validation loss: 1.9064697193843063

Epoch: 6| Step: 13
Training loss: 1.6790964603424072
Validation loss: 1.9132786489302112

Epoch: 138| Step: 0
Training loss: 2.148749351501465
Validation loss: 1.9043321545406053

Epoch: 6| Step: 1
Training loss: 2.0464935302734375
Validation loss: 1.9156980540162774

Epoch: 6| Step: 2
Training loss: 1.920778512954712
Validation loss: 1.9248718894937986

Epoch: 6| Step: 3
Training loss: 2.7307748794555664
Validation loss: 1.9272658517283778

Epoch: 6| Step: 4
Training loss: 2.1393544673919678
Validation loss: 1.9125969973943566

Epoch: 6| Step: 5
Training loss: 2.2571732997894287
Validation loss: 1.9068425483601068

Epoch: 6| Step: 6
Training loss: 1.6762220859527588
Validation loss: 1.8926089989241732

Epoch: 6| Step: 7
Training loss: 1.5410927534103394
Validation loss: 1.9007555618081042

Epoch: 6| Step: 8
Training loss: 2.6424288749694824
Validation loss: 1.8996323142000424

Epoch: 6| Step: 9
Training loss: 1.497791051864624
Validation loss: 1.9084447712026618

Epoch: 6| Step: 10
Training loss: 1.9993984699249268
Validation loss: 1.9098499180168234

Epoch: 6| Step: 11
Training loss: 2.5303244590759277
Validation loss: 1.9088866403025966

Epoch: 6| Step: 12
Training loss: 2.629884719848633
Validation loss: 1.9169846093782814

Epoch: 6| Step: 13
Training loss: 1.6973363161087036
Validation loss: 1.9208370741977487

Epoch: 139| Step: 0
Training loss: 1.828888177871704
Validation loss: 1.9199255563879525

Epoch: 6| Step: 1
Training loss: 1.9583650827407837
Validation loss: 1.9050634650773899

Epoch: 6| Step: 2
Training loss: 2.3251028060913086
Validation loss: 1.9123818758995301

Epoch: 6| Step: 3
Training loss: 1.7702664136886597
Validation loss: 1.901289197706407

Epoch: 6| Step: 4
Training loss: 2.051161766052246
Validation loss: 1.9005420682250813

Epoch: 6| Step: 5
Training loss: 2.655418872833252
Validation loss: 1.9076437014405445

Epoch: 6| Step: 6
Training loss: 1.9125391244888306
Validation loss: 1.9071428339968446

Epoch: 6| Step: 7
Training loss: 2.2495787143707275
Validation loss: 1.9129724143653788

Epoch: 6| Step: 8
Training loss: 2.3928425312042236
Validation loss: 1.9224956522705734

Epoch: 6| Step: 9
Training loss: 2.1165835857391357
Validation loss: 1.935458719089467

Epoch: 6| Step: 10
Training loss: 2.2200839519500732
Validation loss: 1.9364118947777698

Epoch: 6| Step: 11
Training loss: 2.2360613346099854
Validation loss: 1.9374673622910694

Epoch: 6| Step: 12
Training loss: 2.0384254455566406
Validation loss: 1.9257726336038241

Epoch: 6| Step: 13
Training loss: 1.428438663482666
Validation loss: 1.9225541340407504

Epoch: 140| Step: 0
Training loss: 2.393644094467163
Validation loss: 1.9079594906940256

Epoch: 6| Step: 1
Training loss: 1.3657633066177368
Validation loss: 1.8950943690474316

Epoch: 6| Step: 2
Training loss: 2.0360870361328125
Validation loss: 1.9006654088215162

Epoch: 6| Step: 3
Training loss: 2.380047082901001
Validation loss: 1.8900412795364216

Epoch: 6| Step: 4
Training loss: 2.636300563812256
Validation loss: 1.8768844463491952

Epoch: 6| Step: 5
Training loss: 2.207724094390869
Validation loss: 1.9010624449740174

Epoch: 6| Step: 6
Training loss: 1.7991359233856201
Validation loss: 1.9112541675567627

Epoch: 6| Step: 7
Training loss: 1.6696348190307617
Validation loss: 1.9089206136682981

Epoch: 6| Step: 8
Training loss: 2.154722213745117
Validation loss: 1.9110337290712582

Epoch: 6| Step: 9
Training loss: 1.805572509765625
Validation loss: 1.9423589526966054

Epoch: 6| Step: 10
Training loss: 2.620587110519409
Validation loss: 1.9557858692702426

Epoch: 6| Step: 11
Training loss: 2.005207061767578
Validation loss: 1.9788591297723914

Epoch: 6| Step: 12
Training loss: 2.172678232192993
Validation loss: 1.9730571034134075

Epoch: 6| Step: 13
Training loss: 2.8313794136047363
Validation loss: 1.9338533416871102

Epoch: 141| Step: 0
Training loss: 2.174471855163574
Validation loss: 1.9120964286147908

Epoch: 6| Step: 1
Training loss: 2.200474262237549
Validation loss: 1.906429265135078

Epoch: 6| Step: 2
Training loss: 1.8092763423919678
Validation loss: 1.8977013300823908

Epoch: 6| Step: 3
Training loss: 2.0183796882629395
Validation loss: 1.8987861807628343

Epoch: 6| Step: 4
Training loss: 2.2139134407043457
Validation loss: 1.8898191131571287

Epoch: 6| Step: 5
Training loss: 2.8989219665527344
Validation loss: 1.8856466944499681

Epoch: 6| Step: 6
Training loss: 1.6525609493255615
Validation loss: 1.895277480925283

Epoch: 6| Step: 7
Training loss: 2.557347536087036
Validation loss: 1.8843615285811885

Epoch: 6| Step: 8
Training loss: 2.5487499237060547
Validation loss: 1.8901140382212978

Epoch: 6| Step: 9
Training loss: 1.5608609914779663
Validation loss: 1.929225044865762

Epoch: 6| Step: 10
Training loss: 2.60261869430542
Validation loss: 2.003887668732674

Epoch: 6| Step: 11
Training loss: 2.010235071182251
Validation loss: 2.063592546729631

Epoch: 6| Step: 12
Training loss: 1.908231258392334
Validation loss: 2.0944248296881236

Epoch: 6| Step: 13
Training loss: 2.137354850769043
Validation loss: 2.1091661786520355

Epoch: 142| Step: 0
Training loss: 1.740506887435913
Validation loss: 2.069118949674791

Epoch: 6| Step: 1
Training loss: 2.226369857788086
Validation loss: 2.050234410070604

Epoch: 6| Step: 2
Training loss: 2.36785888671875
Validation loss: 1.9961454842680244

Epoch: 6| Step: 3
Training loss: 2.1691880226135254
Validation loss: 1.9415117066393617

Epoch: 6| Step: 4
Training loss: 1.8006588220596313
Validation loss: 1.9179028311083395

Epoch: 6| Step: 5
Training loss: 2.055150032043457
Validation loss: 1.9192713383705384

Epoch: 6| Step: 6
Training loss: 1.914215326309204
Validation loss: 1.9264662086322744

Epoch: 6| Step: 7
Training loss: 3.340235471725464
Validation loss: 1.9275378898907733

Epoch: 6| Step: 8
Training loss: 2.067976951599121
Validation loss: 1.9324045642729728

Epoch: 6| Step: 9
Training loss: 2.3402457237243652
Validation loss: 1.9323935893274122

Epoch: 6| Step: 10
Training loss: 2.6795010566711426
Validation loss: 1.9201334881526169

Epoch: 6| Step: 11
Training loss: 1.998142957687378
Validation loss: 1.925972718064503

Epoch: 6| Step: 12
Training loss: 1.3080615997314453
Validation loss: 1.9574995604894494

Epoch: 6| Step: 13
Training loss: 3.026747703552246
Validation loss: 1.9677642904302126

Epoch: 143| Step: 0
Training loss: 2.150012493133545
Validation loss: 2.017043282908778

Epoch: 6| Step: 1
Training loss: 2.8200254440307617
Validation loss: 2.061327931701496

Epoch: 6| Step: 2
Training loss: 2.5669050216674805
Validation loss: 2.0532018356425787

Epoch: 6| Step: 3
Training loss: 2.4853360652923584
Validation loss: 2.0265888129511187

Epoch: 6| Step: 4
Training loss: 2.483581304550171
Validation loss: 1.9955179832314933

Epoch: 6| Step: 5
Training loss: 1.9802331924438477
Validation loss: 1.9763235469018259

Epoch: 6| Step: 6
Training loss: 2.299631357192993
Validation loss: 1.9633854319972377

Epoch: 6| Step: 7
Training loss: 1.7466943264007568
Validation loss: 1.954731261858376

Epoch: 6| Step: 8
Training loss: 1.7545251846313477
Validation loss: 1.93915589650472

Epoch: 6| Step: 9
Training loss: 1.566205620765686
Validation loss: 1.9368000799609768

Epoch: 6| Step: 10
Training loss: 2.3079042434692383
Validation loss: 1.9326636047773464

Epoch: 6| Step: 11
Training loss: 2.1385419368743896
Validation loss: 1.9290571789587698

Epoch: 6| Step: 12
Training loss: 2.071314811706543
Validation loss: 1.932608905658927

Epoch: 6| Step: 13
Training loss: 2.2020881175994873
Validation loss: 1.9190396493481052

Epoch: 144| Step: 0
Training loss: 2.252511501312256
Validation loss: 1.9279121480962282

Epoch: 6| Step: 1
Training loss: 1.8677279949188232
Validation loss: 1.9255304426275275

Epoch: 6| Step: 2
Training loss: 1.9507114887237549
Validation loss: 1.92591215461813

Epoch: 6| Step: 3
Training loss: 2.562882900238037
Validation loss: 1.9193015342117639

Epoch: 6| Step: 4
Training loss: 2.319946050643921
Validation loss: 1.9106404755705146

Epoch: 6| Step: 5
Training loss: 2.387545585632324
Validation loss: 1.914001650707696

Epoch: 6| Step: 6
Training loss: 1.8635175228118896
Validation loss: 1.9125827435524232

Epoch: 6| Step: 7
Training loss: 2.0476231575012207
Validation loss: 1.911781228998656

Epoch: 6| Step: 8
Training loss: 2.2531116008758545
Validation loss: 1.9140937661611905

Epoch: 6| Step: 9
Training loss: 2.257646083831787
Validation loss: 1.9241816920618857

Epoch: 6| Step: 10
Training loss: 1.3833277225494385
Validation loss: 1.9121020506787043

Epoch: 6| Step: 11
Training loss: 1.6820452213287354
Validation loss: 1.9049319938946796

Epoch: 6| Step: 12
Training loss: 3.0039710998535156
Validation loss: 1.9098028367565525

Epoch: 6| Step: 13
Training loss: 2.0260908603668213
Validation loss: 1.9272744604336318

Epoch: 145| Step: 0
Training loss: 2.460247278213501
Validation loss: 1.962833212267968

Epoch: 6| Step: 1
Training loss: 1.9643441438674927
Validation loss: 2.0005516057373374

Epoch: 6| Step: 2
Training loss: 1.9865585565567017
Validation loss: 2.041503349939982

Epoch: 6| Step: 3
Training loss: 1.9759533405303955
Validation loss: 2.0673132404204337

Epoch: 6| Step: 4
Training loss: 2.491494655609131
Validation loss: 2.0808214231203963

Epoch: 6| Step: 5
Training loss: 2.1116061210632324
Validation loss: 2.0614959757815123

Epoch: 6| Step: 6
Training loss: 2.0514793395996094
Validation loss: 2.024498344749533

Epoch: 6| Step: 7
Training loss: 2.179173469543457
Validation loss: 1.9619517595537248

Epoch: 6| Step: 8
Training loss: 1.9342089891433716
Validation loss: 1.9098444395167853

Epoch: 6| Step: 9
Training loss: 1.7516992092132568
Validation loss: 1.8890458896595945

Epoch: 6| Step: 10
Training loss: 2.5936965942382812
Validation loss: 1.8957506879683463

Epoch: 6| Step: 11
Training loss: 2.573441982269287
Validation loss: 1.905637853889055

Epoch: 6| Step: 12
Training loss: 1.9930405616760254
Validation loss: 1.9117496244369014

Epoch: 6| Step: 13
Training loss: 2.154289960861206
Validation loss: 1.9179847278902609

Epoch: 146| Step: 0
Training loss: 2.386934518814087
Validation loss: 1.9191590073288127

Epoch: 6| Step: 1
Training loss: 2.9830470085144043
Validation loss: 1.915066852364489

Epoch: 6| Step: 2
Training loss: 1.9024975299835205
Validation loss: 1.8936545195118073

Epoch: 6| Step: 3
Training loss: 2.626157283782959
Validation loss: 1.8990836963858655

Epoch: 6| Step: 4
Training loss: 2.0540404319763184
Validation loss: 1.9272204265799573

Epoch: 6| Step: 5
Training loss: 2.1030757427215576
Validation loss: 1.9818030300960745

Epoch: 6| Step: 6
Training loss: 2.3131103515625
Validation loss: 2.0309290860288884

Epoch: 6| Step: 7
Training loss: 2.260545253753662
Validation loss: 2.060570183620658

Epoch: 6| Step: 8
Training loss: 1.989915370941162
Validation loss: 2.0761596413068872

Epoch: 6| Step: 9
Training loss: 2.5593390464782715
Validation loss: 2.066206814140402

Epoch: 6| Step: 10
Training loss: 1.7465384006500244
Validation loss: 2.014404712184783

Epoch: 6| Step: 11
Training loss: 1.4004344940185547
Validation loss: 1.9519825340599142

Epoch: 6| Step: 12
Training loss: 1.9888570308685303
Validation loss: 1.9164416584917294

Epoch: 6| Step: 13
Training loss: 2.500250816345215
Validation loss: 1.9140932252330165

Epoch: 147| Step: 0
Training loss: 1.8437942266464233
Validation loss: 1.9254162478190597

Epoch: 6| Step: 1
Training loss: 1.998123288154602
Validation loss: 1.9257788478687246

Epoch: 6| Step: 2
Training loss: 2.349409341812134
Validation loss: 1.9265852128305743

Epoch: 6| Step: 3
Training loss: 1.9531316757202148
Validation loss: 1.9339997717129287

Epoch: 6| Step: 4
Training loss: 2.097271203994751
Validation loss: 1.927990641645206

Epoch: 6| Step: 5
Training loss: 2.0656285285949707
Validation loss: 1.9342610720665223

Epoch: 6| Step: 6
Training loss: 2.4630017280578613
Validation loss: 1.9333066171215427

Epoch: 6| Step: 7
Training loss: 2.592210054397583
Validation loss: 1.9406350761331537

Epoch: 6| Step: 8
Training loss: 2.069258213043213
Validation loss: 1.9377999908180648

Epoch: 6| Step: 9
Training loss: 2.0815060138702393
Validation loss: 1.947272826266545

Epoch: 6| Step: 10
Training loss: 2.1216304302215576
Validation loss: 1.9466775899292321

Epoch: 6| Step: 11
Training loss: 2.685405731201172
Validation loss: 1.9398513173544278

Epoch: 6| Step: 12
Training loss: 1.8086129426956177
Validation loss: 1.9402908368777203

Epoch: 6| Step: 13
Training loss: 1.6487396955490112
Validation loss: 1.932634138291882

Epoch: 148| Step: 0
Training loss: 1.9719009399414062
Validation loss: 1.9251511622500677

Epoch: 6| Step: 1
Training loss: 2.2709813117980957
Validation loss: 1.9172703963454052

Epoch: 6| Step: 2
Training loss: 1.2415103912353516
Validation loss: 1.9074214748156968

Epoch: 6| Step: 3
Training loss: 2.013575792312622
Validation loss: 1.9155139256549139

Epoch: 6| Step: 4
Training loss: 2.533895492553711
Validation loss: 1.9170799652735393

Epoch: 6| Step: 5
Training loss: 1.8943886756896973
Validation loss: 1.9144360967861709

Epoch: 6| Step: 6
Training loss: 2.744600296020508
Validation loss: 1.9180512633374942

Epoch: 6| Step: 7
Training loss: 2.077263832092285
Validation loss: 1.9121944058325984

Epoch: 6| Step: 8
Training loss: 2.251372814178467
Validation loss: 1.9093639337888328

Epoch: 6| Step: 9
Training loss: 1.649590015411377
Validation loss: 1.8963136198700115

Epoch: 6| Step: 10
Training loss: 1.8627489805221558
Validation loss: 1.9055033986286452

Epoch: 6| Step: 11
Training loss: 2.2704248428344727
Validation loss: 1.900271934847678

Epoch: 6| Step: 12
Training loss: 2.4263198375701904
Validation loss: 1.8968425719968733

Epoch: 6| Step: 13
Training loss: 2.4984638690948486
Validation loss: 1.917041867010055

Epoch: 149| Step: 0
Training loss: 2.3286681175231934
Validation loss: 1.9184891844308505

Epoch: 6| Step: 1
Training loss: 2.6531784534454346
Validation loss: 1.913078382451047

Epoch: 6| Step: 2
Training loss: 2.0538294315338135
Validation loss: 1.9273462090440976

Epoch: 6| Step: 3
Training loss: 3.151803493499756
Validation loss: 1.9297804627367245

Epoch: 6| Step: 4
Training loss: 1.9890384674072266
Validation loss: 1.936308660814839

Epoch: 6| Step: 5
Training loss: 2.146507740020752
Validation loss: 1.9459020207005162

Epoch: 6| Step: 6
Training loss: 2.071384906768799
Validation loss: 1.9351508822492374

Epoch: 6| Step: 7
Training loss: 2.0324392318725586
Validation loss: 1.9382841715248682

Epoch: 6| Step: 8
Training loss: 1.841186761856079
Validation loss: 1.9386785902002805

Epoch: 6| Step: 9
Training loss: 1.1596996784210205
Validation loss: 1.9205436539906326

Epoch: 6| Step: 10
Training loss: 2.302551746368408
Validation loss: 1.9260529523254724

Epoch: 6| Step: 11
Training loss: 1.706040620803833
Validation loss: 1.9313884409525062

Epoch: 6| Step: 12
Training loss: 1.7529417276382446
Validation loss: 1.9362614513725362

Epoch: 6| Step: 13
Training loss: 2.1815848350524902
Validation loss: 1.9404667372344642

Epoch: 150| Step: 0
Training loss: 2.6223697662353516
Validation loss: 1.9372869486449866

Epoch: 6| Step: 1
Training loss: 2.2524752616882324
Validation loss: 1.935038169225057

Epoch: 6| Step: 2
Training loss: 1.8164628744125366
Validation loss: 1.9306541207016155

Epoch: 6| Step: 3
Training loss: 2.6306068897247314
Validation loss: 1.9434460798899333

Epoch: 6| Step: 4
Training loss: 2.1992087364196777
Validation loss: 1.950300411511493

Epoch: 6| Step: 5
Training loss: 1.6726109981536865
Validation loss: 1.9567898229886127

Epoch: 6| Step: 6
Training loss: 2.285478353500366
Validation loss: 1.9485986207121162

Epoch: 6| Step: 7
Training loss: 2.443676471710205
Validation loss: 1.9382911651365218

Epoch: 6| Step: 8
Training loss: 2.2494468688964844
Validation loss: 1.9577642269031976

Epoch: 6| Step: 9
Training loss: 1.8481152057647705
Validation loss: 1.9513724542433215

Epoch: 6| Step: 10
Training loss: 2.1800379753112793
Validation loss: 1.947271825164877

Epoch: 6| Step: 11
Training loss: 1.6946823596954346
Validation loss: 1.9503967505629345

Epoch: 6| Step: 12
Training loss: 1.6542867422103882
Validation loss: 1.954926008819252

Epoch: 6| Step: 13
Training loss: 1.1421955823898315
Validation loss: 1.926651870050738

Testing loss: 2.3312518861558704
