Epoch: 1| Step: 0
Training loss: 5.181680679321289
Validation loss: 5.16872856181155

Epoch: 6| Step: 1
Training loss: 4.660555362701416
Validation loss: 5.139641954052832

Epoch: 6| Step: 2
Training loss: 5.529360771179199
Validation loss: 5.110865674993043

Epoch: 6| Step: 3
Training loss: 5.082712173461914
Validation loss: 5.080474694569905

Epoch: 6| Step: 4
Training loss: 3.447580337524414
Validation loss: 5.047260074205296

Epoch: 6| Step: 5
Training loss: 4.144777297973633
Validation loss: 5.009565261102492

Epoch: 6| Step: 6
Training loss: 3.649254322052002
Validation loss: 4.967952882089922

Epoch: 6| Step: 7
Training loss: 4.171690940856934
Validation loss: 4.921634356180827

Epoch: 6| Step: 8
Training loss: 5.798559188842773
Validation loss: 4.869487172813826

Epoch: 6| Step: 9
Training loss: 5.022831916809082
Validation loss: 4.81281009797127

Epoch: 6| Step: 10
Training loss: 5.134355545043945
Validation loss: 4.7479500616750405

Epoch: 6| Step: 11
Training loss: 4.85772180557251
Validation loss: 4.682230190564227

Epoch: 6| Step: 12
Training loss: 4.960879802703857
Validation loss: 4.612912854840679

Epoch: 6| Step: 13
Training loss: 3.957885265350342
Validation loss: 4.5432684447175715

Epoch: 2| Step: 0
Training loss: 4.040807247161865
Validation loss: 4.476022489609257

Epoch: 6| Step: 1
Training loss: 4.456361770629883
Validation loss: 4.412412320413897

Epoch: 6| Step: 2
Training loss: 4.050401210784912
Validation loss: 4.3528379701798965

Epoch: 6| Step: 3
Training loss: 4.072942733764648
Validation loss: 4.2982042220331005

Epoch: 6| Step: 4
Training loss: 3.3830413818359375
Validation loss: 4.248673239061909

Epoch: 6| Step: 5
Training loss: 4.777770042419434
Validation loss: 4.19926796677292

Epoch: 6| Step: 6
Training loss: 3.2091543674468994
Validation loss: 4.150529697377195

Epoch: 6| Step: 7
Training loss: 3.2689223289489746
Validation loss: 4.10354648610597

Epoch: 6| Step: 8
Training loss: 2.866178274154663
Validation loss: 4.056003865375314

Epoch: 6| Step: 9
Training loss: 4.201623916625977
Validation loss: 4.006572561879312

Epoch: 6| Step: 10
Training loss: 3.804471969604492
Validation loss: 3.9533339059481056

Epoch: 6| Step: 11
Training loss: 4.797980308532715
Validation loss: 3.8937941879354496

Epoch: 6| Step: 12
Training loss: 4.069903373718262
Validation loss: 3.830350363126365

Epoch: 6| Step: 13
Training loss: 5.052892208099365
Validation loss: 3.7716831340584704

Epoch: 3| Step: 0
Training loss: 3.348912239074707
Validation loss: 3.7271095193842405

Epoch: 6| Step: 1
Training loss: 3.3921360969543457
Validation loss: 3.693267806883781

Epoch: 6| Step: 2
Training loss: 3.1917057037353516
Validation loss: 3.6637771411608626

Epoch: 6| Step: 3
Training loss: 3.756849527359009
Validation loss: 3.629300750711913

Epoch: 6| Step: 4
Training loss: 3.333824634552002
Validation loss: 3.593233782757995

Epoch: 6| Step: 5
Training loss: 3.5558176040649414
Validation loss: 3.5576232197464153

Epoch: 6| Step: 6
Training loss: 3.5171399116516113
Validation loss: 3.5291855976145756

Epoch: 6| Step: 7
Training loss: 3.737351417541504
Validation loss: 3.5062832217062674

Epoch: 6| Step: 8
Training loss: 3.0091702938079834
Validation loss: 3.4910012265687347

Epoch: 6| Step: 9
Training loss: 3.4567031860351562
Validation loss: 3.476125563344648

Epoch: 6| Step: 10
Training loss: 3.6597023010253906
Validation loss: 3.450249882154567

Epoch: 6| Step: 11
Training loss: 3.3438286781311035
Validation loss: 3.4323979552074144

Epoch: 6| Step: 12
Training loss: 4.010648727416992
Validation loss: 3.413794002225322

Epoch: 6| Step: 13
Training loss: 2.8655035495758057
Validation loss: 3.3958623588726087

Epoch: 4| Step: 0
Training loss: 2.8510074615478516
Validation loss: 3.381616702643774

Epoch: 6| Step: 1
Training loss: 3.8536739349365234
Validation loss: 3.3671181355753252

Epoch: 6| Step: 2
Training loss: 4.217348098754883
Validation loss: 3.3554731004981586

Epoch: 6| Step: 3
Training loss: 3.229320526123047
Validation loss: 3.3376841237468104

Epoch: 6| Step: 4
Training loss: 3.12764835357666
Validation loss: 3.320280203255274

Epoch: 6| Step: 5
Training loss: 3.1842217445373535
Validation loss: 3.3079717056725615

Epoch: 6| Step: 6
Training loss: 3.2711181640625
Validation loss: 3.2981183067444833

Epoch: 6| Step: 7
Training loss: 3.4105377197265625
Validation loss: 3.2880776159224974

Epoch: 6| Step: 8
Training loss: 3.0480923652648926
Validation loss: 3.274571377743957

Epoch: 6| Step: 9
Training loss: 3.248302936553955
Validation loss: 3.2666784614645024

Epoch: 6| Step: 10
Training loss: 3.3907086849212646
Validation loss: 3.2548509259377756

Epoch: 6| Step: 11
Training loss: 2.8124232292175293
Validation loss: 3.246433747712002

Epoch: 6| Step: 12
Training loss: 3.1529183387756348
Validation loss: 3.2370843092600503

Epoch: 6| Step: 13
Training loss: 2.936081886291504
Validation loss: 3.229841055408601

Epoch: 5| Step: 0
Training loss: 2.5474600791931152
Validation loss: 3.2203436128554808

Epoch: 6| Step: 1
Training loss: 3.1690542697906494
Validation loss: 3.2102962129859516

Epoch: 6| Step: 2
Training loss: 4.06666374206543
Validation loss: 3.1961938155594694

Epoch: 6| Step: 3
Training loss: 3.1830084323883057
Validation loss: 3.184498697198847

Epoch: 6| Step: 4
Training loss: 2.854233980178833
Validation loss: 3.1732147124505814

Epoch: 6| Step: 5
Training loss: 1.9728703498840332
Validation loss: 3.162259824814335

Epoch: 6| Step: 6
Training loss: 4.314421653747559
Validation loss: 3.1619494294607513

Epoch: 6| Step: 7
Training loss: 3.1508126258850098
Validation loss: 3.142691291788573

Epoch: 6| Step: 8
Training loss: 3.467710018157959
Validation loss: 3.127211550230621

Epoch: 6| Step: 9
Training loss: 1.8571343421936035
Validation loss: 3.1132301335693686

Epoch: 6| Step: 10
Training loss: 4.288290977478027
Validation loss: 3.099390252943962

Epoch: 6| Step: 11
Training loss: 2.9980926513671875
Validation loss: 3.076962794027021

Epoch: 6| Step: 12
Training loss: 3.7632761001586914
Validation loss: 3.067968096784366

Epoch: 6| Step: 13
Training loss: 2.368454933166504
Validation loss: 3.0423134039807063

Epoch: 6| Step: 0
Training loss: 3.3951547145843506
Validation loss: 3.0387079843910794

Epoch: 6| Step: 1
Training loss: 3.2265982627868652
Validation loss: 3.0316127756590485

Epoch: 6| Step: 2
Training loss: 2.668534755706787
Validation loss: 3.0745682742006037

Epoch: 6| Step: 3
Training loss: 3.5298919677734375
Validation loss: 3.007938333736953

Epoch: 6| Step: 4
Training loss: 2.5303030014038086
Validation loss: 2.9869885239549863

Epoch: 6| Step: 5
Training loss: 3.474973440170288
Validation loss: 2.995952634401219

Epoch: 6| Step: 6
Training loss: 2.4683146476745605
Validation loss: 2.9893962516579577

Epoch: 6| Step: 7
Training loss: 3.9214024543762207
Validation loss: 2.9808278801620647

Epoch: 6| Step: 8
Training loss: 3.244415283203125
Validation loss: 2.9630116852380897

Epoch: 6| Step: 9
Training loss: 3.6030826568603516
Validation loss: 2.9468972529134443

Epoch: 6| Step: 10
Training loss: 3.2385284900665283
Validation loss: 2.932215121484572

Epoch: 6| Step: 11
Training loss: 2.7387161254882812
Validation loss: 2.9216361174019436

Epoch: 6| Step: 12
Training loss: 2.0535056591033936
Validation loss: 2.9145216147104898

Epoch: 6| Step: 13
Training loss: 2.3222594261169434
Validation loss: 2.910980337409563

Epoch: 7| Step: 0
Training loss: 2.513789176940918
Validation loss: 2.91547494037177

Epoch: 6| Step: 1
Training loss: 2.471529722213745
Validation loss: 2.9126376028983825

Epoch: 6| Step: 2
Training loss: 4.360408306121826
Validation loss: 2.8987603623379945

Epoch: 6| Step: 3
Training loss: 2.7689545154571533
Validation loss: 2.8900411462271087

Epoch: 6| Step: 4
Training loss: 2.70754337310791
Validation loss: 2.875775396182973

Epoch: 6| Step: 5
Training loss: 2.85227370262146
Validation loss: 2.868307746866698

Epoch: 6| Step: 6
Training loss: 3.1781740188598633
Validation loss: 2.8601495758179696

Epoch: 6| Step: 7
Training loss: 3.173191547393799
Validation loss: 2.854929288228353

Epoch: 6| Step: 8
Training loss: 2.562045097351074
Validation loss: 2.843539725067795

Epoch: 6| Step: 9
Training loss: 2.3327293395996094
Validation loss: 2.8352782572469404

Epoch: 6| Step: 10
Training loss: 3.0202629566192627
Validation loss: 2.8264421134866695

Epoch: 6| Step: 11
Training loss: 3.0956435203552246
Validation loss: 2.816682953988352

Epoch: 6| Step: 12
Training loss: 3.095768928527832
Validation loss: 2.8108755234749085

Epoch: 6| Step: 13
Training loss: 3.8047938346862793
Validation loss: 2.8053587072639057

Epoch: 8| Step: 0
Training loss: 3.274184226989746
Validation loss: 2.8000179285644204

Epoch: 6| Step: 1
Training loss: 3.5658583641052246
Validation loss: 2.7941782935973136

Epoch: 6| Step: 2
Training loss: 3.4889509677886963
Validation loss: 2.7903583639411518

Epoch: 6| Step: 3
Training loss: 2.0157833099365234
Validation loss: 2.791661200984832

Epoch: 6| Step: 4
Training loss: 2.8673095703125
Validation loss: 2.7852061666468138

Epoch: 6| Step: 5
Training loss: 2.7927541732788086
Validation loss: 2.785747845967611

Epoch: 6| Step: 6
Training loss: 3.048232078552246
Validation loss: 2.7847387662497898

Epoch: 6| Step: 7
Training loss: 2.2026376724243164
Validation loss: 2.7866655703513854

Epoch: 6| Step: 8
Training loss: 2.7768917083740234
Validation loss: 2.7828051813187136

Epoch: 6| Step: 9
Training loss: 3.0565669536590576
Validation loss: 2.7912522515942975

Epoch: 6| Step: 10
Training loss: 2.5650835037231445
Validation loss: 2.778190730720438

Epoch: 6| Step: 11
Training loss: 3.2812023162841797
Validation loss: 2.762682722460839

Epoch: 6| Step: 12
Training loss: 3.0524797439575195
Validation loss: 2.7596853010116087

Epoch: 6| Step: 13
Training loss: 2.8821427822113037
Validation loss: 2.7585620675035702

Epoch: 9| Step: 0
Training loss: 2.9709339141845703
Validation loss: 2.759956549572688

Epoch: 6| Step: 1
Training loss: 3.4069321155548096
Validation loss: 2.7494725335028862

Epoch: 6| Step: 2
Training loss: 2.708775281906128
Validation loss: 2.746863736901232

Epoch: 6| Step: 3
Training loss: 2.5622751712799072
Validation loss: 2.7465418897649294

Epoch: 6| Step: 4
Training loss: 2.463804244995117
Validation loss: 2.7416078711068756

Epoch: 6| Step: 5
Training loss: 2.4285969734191895
Validation loss: 2.7388460431047665

Epoch: 6| Step: 6
Training loss: 3.476613998413086
Validation loss: 2.7343218377841416

Epoch: 6| Step: 7
Training loss: 3.3483290672302246
Validation loss: 2.730987338609593

Epoch: 6| Step: 8
Training loss: 1.605010986328125
Validation loss: 2.7271393857976443

Epoch: 6| Step: 9
Training loss: 3.1120848655700684
Validation loss: 2.7288565840772403

Epoch: 6| Step: 10
Training loss: 3.601742744445801
Validation loss: 2.7238651039779826

Epoch: 6| Step: 11
Training loss: 2.389023780822754
Validation loss: 2.723582198542933

Epoch: 6| Step: 12
Training loss: 3.4182543754577637
Validation loss: 2.727383044458205

Epoch: 6| Step: 13
Training loss: 3.1526007652282715
Validation loss: 2.7301263014475503

Epoch: 10| Step: 0
Training loss: 3.4415783882141113
Validation loss: 2.7343076172695366

Epoch: 6| Step: 1
Training loss: 2.5060324668884277
Validation loss: 2.7182042521815144

Epoch: 6| Step: 2
Training loss: 2.8262805938720703
Validation loss: 2.718029019653156

Epoch: 6| Step: 3
Training loss: 2.1986215114593506
Validation loss: 2.715075800495763

Epoch: 6| Step: 4
Training loss: 2.3183531761169434
Validation loss: 2.711258522925838

Epoch: 6| Step: 5
Training loss: 2.854313850402832
Validation loss: 2.712907552719116

Epoch: 6| Step: 6
Training loss: 2.693718910217285
Validation loss: 2.709548924558906

Epoch: 6| Step: 7
Training loss: 2.412895679473877
Validation loss: 2.707727036168498

Epoch: 6| Step: 8
Training loss: 3.9609246253967285
Validation loss: 2.707225138141263

Epoch: 6| Step: 9
Training loss: 3.4454751014709473
Validation loss: 2.703925035333121

Epoch: 6| Step: 10
Training loss: 3.0327367782592773
Validation loss: 2.700025373889554

Epoch: 6| Step: 11
Training loss: 2.7995986938476562
Validation loss: 2.6992832473529282

Epoch: 6| Step: 12
Training loss: 3.02840256690979
Validation loss: 2.7098821670778337

Epoch: 6| Step: 13
Training loss: 2.543181896209717
Validation loss: 2.7002111199081584

Epoch: 11| Step: 0
Training loss: 2.5145368576049805
Validation loss: 2.6995581888383433

Epoch: 6| Step: 1
Training loss: 1.9921127557754517
Validation loss: 2.701277256011963

Epoch: 6| Step: 2
Training loss: 3.293545961380005
Validation loss: 2.698413651476624

Epoch: 6| Step: 3
Training loss: 3.5670595169067383
Validation loss: 2.6952992921234458

Epoch: 6| Step: 4
Training loss: 3.0605015754699707
Validation loss: 2.694624903381512

Epoch: 6| Step: 5
Training loss: 3.1907787322998047
Validation loss: 2.6936862161082606

Epoch: 6| Step: 6
Training loss: 2.9313154220581055
Validation loss: 2.692371247917093

Epoch: 6| Step: 7
Training loss: 2.8200573921203613
Validation loss: 2.6881855764696674

Epoch: 6| Step: 8
Training loss: 2.0838725566864014
Validation loss: 2.6898942506441506

Epoch: 6| Step: 9
Training loss: 2.408499240875244
Validation loss: 2.6860649739542315

Epoch: 6| Step: 10
Training loss: 3.2992660999298096
Validation loss: 2.681524568988431

Epoch: 6| Step: 11
Training loss: 3.0726118087768555
Validation loss: 2.6862691371671614

Epoch: 6| Step: 12
Training loss: 2.7466750144958496
Validation loss: 2.6816010731522755

Epoch: 6| Step: 13
Training loss: 3.139036178588867
Validation loss: 2.679198941876811

Epoch: 12| Step: 0
Training loss: 3.163010835647583
Validation loss: 2.6807555665252027

Epoch: 6| Step: 1
Training loss: 3.029611349105835
Validation loss: 2.6865099322411323

Epoch: 6| Step: 2
Training loss: 2.6772689819335938
Validation loss: 2.683689732705393

Epoch: 6| Step: 3
Training loss: 2.420042037963867
Validation loss: 2.672092855617564

Epoch: 6| Step: 4
Training loss: 3.4474172592163086
Validation loss: 2.6695776472809496

Epoch: 6| Step: 5
Training loss: 3.318844795227051
Validation loss: 2.6699997584025064

Epoch: 6| Step: 6
Training loss: 3.3085179328918457
Validation loss: 2.668825508445822

Epoch: 6| Step: 7
Training loss: 3.451558828353882
Validation loss: 2.667039179032849

Epoch: 6| Step: 8
Training loss: 2.5507493019104004
Validation loss: 2.6681147467705513

Epoch: 6| Step: 9
Training loss: 2.2454285621643066
Validation loss: 2.680346881189654

Epoch: 6| Step: 10
Training loss: 1.8058568239212036
Validation loss: 2.6827560317131782

Epoch: 6| Step: 11
Training loss: 2.8892197608947754
Validation loss: 2.6768518006929787

Epoch: 6| Step: 12
Training loss: 2.4062910079956055
Validation loss: 2.6671615467276624

Epoch: 6| Step: 13
Training loss: 3.2855186462402344
Validation loss: 2.6711057693727556

Epoch: 13| Step: 0
Training loss: 2.402498245239258
Validation loss: 2.6569329436107347

Epoch: 6| Step: 1
Training loss: 3.376331090927124
Validation loss: 2.6691314584465435

Epoch: 6| Step: 2
Training loss: 3.5583813190460205
Validation loss: 2.6537832444713962

Epoch: 6| Step: 3
Training loss: 2.4508163928985596
Validation loss: 2.656700457296064

Epoch: 6| Step: 4
Training loss: 2.970710515975952
Validation loss: 2.664438460462837

Epoch: 6| Step: 5
Training loss: 2.798048973083496
Validation loss: 2.6722017026716665

Epoch: 6| Step: 6
Training loss: 2.372425079345703
Validation loss: 2.668018061627624

Epoch: 6| Step: 7
Training loss: 2.648609161376953
Validation loss: 2.6748188644327144

Epoch: 6| Step: 8
Training loss: 3.013620376586914
Validation loss: 2.662276606405935

Epoch: 6| Step: 9
Training loss: 2.9339394569396973
Validation loss: 2.647736980069068

Epoch: 6| Step: 10
Training loss: 2.5021324157714844
Validation loss: 2.6446100691313386

Epoch: 6| Step: 11
Training loss: 2.8336567878723145
Validation loss: 2.6427434349572785

Epoch: 6| Step: 12
Training loss: 2.9665260314941406
Validation loss: 2.6431403647186937

Epoch: 6| Step: 13
Training loss: 2.7579426765441895
Validation loss: 2.636396961827432

Epoch: 14| Step: 0
Training loss: 2.4072070121765137
Validation loss: 2.6427931811219905

Epoch: 6| Step: 1
Training loss: 2.346700668334961
Validation loss: 2.6214133898417153

Epoch: 6| Step: 2
Training loss: 2.1956233978271484
Validation loss: 2.6223985328469226

Epoch: 6| Step: 3
Training loss: 2.444913387298584
Validation loss: 2.6261606857340825

Epoch: 6| Step: 4
Training loss: 3.447739601135254
Validation loss: 2.6243205993406233

Epoch: 6| Step: 5
Training loss: 3.018101215362549
Validation loss: 2.6138287462213987

Epoch: 6| Step: 6
Training loss: 2.1847801208496094
Validation loss: 2.610142118187361

Epoch: 6| Step: 7
Training loss: 3.3447580337524414
Validation loss: 2.61201145315683

Epoch: 6| Step: 8
Training loss: 3.3691983222961426
Validation loss: 2.620311931897235

Epoch: 6| Step: 9
Training loss: 2.7359352111816406
Validation loss: 2.6139671059064966

Epoch: 6| Step: 10
Training loss: 3.112964153289795
Validation loss: 2.621518647798928

Epoch: 6| Step: 11
Training loss: 2.5050101280212402
Validation loss: 2.627884728934175

Epoch: 6| Step: 12
Training loss: 3.6596198081970215
Validation loss: 2.6208070324313257

Epoch: 6| Step: 13
Training loss: 2.487016201019287
Validation loss: 2.6089300519676617

Epoch: 15| Step: 0
Training loss: 2.8631863594055176
Validation loss: 2.6112688869558354

Epoch: 6| Step: 1
Training loss: 3.4334716796875
Validation loss: 2.6061219220520346

Epoch: 6| Step: 2
Training loss: 2.673543691635132
Validation loss: 2.5905763359480005

Epoch: 6| Step: 3
Training loss: 3.490122079849243
Validation loss: 2.586406374490389

Epoch: 6| Step: 4
Training loss: 2.199892044067383
Validation loss: 2.5716466672958864

Epoch: 6| Step: 5
Training loss: 2.701085090637207
Validation loss: 2.572088113395117

Epoch: 6| Step: 6
Training loss: 2.8723506927490234
Validation loss: 2.5708290171879593

Epoch: 6| Step: 7
Training loss: 2.5528311729431152
Validation loss: 2.572098557667066

Epoch: 6| Step: 8
Training loss: 2.8411998748779297
Validation loss: 2.5739965925934496

Epoch: 6| Step: 9
Training loss: 2.98793888092041
Validation loss: 2.5837886307829168

Epoch: 6| Step: 10
Training loss: 2.813352346420288
Validation loss: 2.5547749355275142

Epoch: 6| Step: 11
Training loss: 2.3253207206726074
Validation loss: 2.5502559549065045

Epoch: 6| Step: 12
Training loss: 2.8171334266662598
Validation loss: 2.5530712373795046

Epoch: 6| Step: 13
Training loss: 2.2943828105926514
Validation loss: 2.5514322352665726

Epoch: 16| Step: 0
Training loss: 2.9865798950195312
Validation loss: 2.5600664666903916

Epoch: 6| Step: 1
Training loss: 2.420412063598633
Validation loss: 2.593096076801259

Epoch: 6| Step: 2
Training loss: 3.1078953742980957
Validation loss: 2.5876113150709417

Epoch: 6| Step: 3
Training loss: 3.454817295074463
Validation loss: 2.576221235336796

Epoch: 6| Step: 4
Training loss: 2.8117263317108154
Validation loss: 2.5434559775936987

Epoch: 6| Step: 5
Training loss: 2.4425454139709473
Validation loss: 2.543134109948271

Epoch: 6| Step: 6
Training loss: 2.679198980331421
Validation loss: 2.5406509625014437

Epoch: 6| Step: 7
Training loss: 3.1269567012786865
Validation loss: 2.5397079170391126

Epoch: 6| Step: 8
Training loss: 1.9700844287872314
Validation loss: 2.5285310078692693

Epoch: 6| Step: 9
Training loss: 2.294610023498535
Validation loss: 2.52226024289285

Epoch: 6| Step: 10
Training loss: 2.1558399200439453
Validation loss: 2.524183460461196

Epoch: 6| Step: 11
Training loss: 3.679290294647217
Validation loss: 2.531803097776187

Epoch: 6| Step: 12
Training loss: 2.5983123779296875
Validation loss: 2.5238621132348174

Epoch: 6| Step: 13
Training loss: 2.9469614028930664
Validation loss: 2.518488350734916

Epoch: 17| Step: 0
Training loss: 2.4598798751831055
Validation loss: 2.5162246201627996

Epoch: 6| Step: 1
Training loss: 2.196380138397217
Validation loss: 2.5170187129769275

Epoch: 6| Step: 2
Training loss: 2.4152936935424805
Validation loss: 2.526733970129362

Epoch: 6| Step: 3
Training loss: 3.0314388275146484
Validation loss: 2.539274725862729

Epoch: 6| Step: 4
Training loss: 3.4417881965637207
Validation loss: 2.5123534689667406

Epoch: 6| Step: 5
Training loss: 3.2446179389953613
Validation loss: 2.515068943782519

Epoch: 6| Step: 6
Training loss: 2.4405879974365234
Validation loss: 2.5127953842122066

Epoch: 6| Step: 7
Training loss: 2.265170097351074
Validation loss: 2.514723131733556

Epoch: 6| Step: 8
Training loss: 2.7821197509765625
Validation loss: 2.5107031483804025

Epoch: 6| Step: 9
Training loss: 3.1352651119232178
Validation loss: 2.5143973365906747

Epoch: 6| Step: 10
Training loss: 2.625124931335449
Validation loss: 2.511869402341945

Epoch: 6| Step: 11
Training loss: 2.342769145965576
Validation loss: 2.516757970215172

Epoch: 6| Step: 12
Training loss: 3.4269680976867676
Validation loss: 2.51843064062057

Epoch: 6| Step: 13
Training loss: 2.4199905395507812
Validation loss: 2.5150068575336086

Epoch: 18| Step: 0
Training loss: 2.1026382446289062
Validation loss: 2.514512631200975

Epoch: 6| Step: 1
Training loss: 2.2383761405944824
Validation loss: 2.5097412986140095

Epoch: 6| Step: 2
Training loss: 2.6704349517822266
Validation loss: 2.5115366058964885

Epoch: 6| Step: 3
Training loss: 3.054072380065918
Validation loss: 2.5149896426867415

Epoch: 6| Step: 4
Training loss: 2.970517873764038
Validation loss: 2.517920365897558

Epoch: 6| Step: 5
Training loss: 3.060626745223999
Validation loss: 2.509439801657072

Epoch: 6| Step: 6
Training loss: 2.5432047843933105
Validation loss: 2.5055755005087903

Epoch: 6| Step: 7
Training loss: 2.1911845207214355
Validation loss: 2.5128677891146753

Epoch: 6| Step: 8
Training loss: 3.267394542694092
Validation loss: 2.5210959475527526

Epoch: 6| Step: 9
Training loss: 3.262258529663086
Validation loss: 2.5272078116734824

Epoch: 6| Step: 10
Training loss: 2.568084716796875
Validation loss: 2.515120385795511

Epoch: 6| Step: 11
Training loss: 3.0152196884155273
Validation loss: 2.504735746691304

Epoch: 6| Step: 12
Training loss: 2.8986666202545166
Validation loss: 2.497974805934455

Epoch: 6| Step: 13
Training loss: 2.152445077896118
Validation loss: 2.4937668923408753

Epoch: 19| Step: 0
Training loss: 2.4452686309814453
Validation loss: 2.4975191803388697

Epoch: 6| Step: 1
Training loss: 2.356627941131592
Validation loss: 2.4956085502460437

Epoch: 6| Step: 2
Training loss: 3.05120849609375
Validation loss: 2.4899873118246756

Epoch: 6| Step: 3
Training loss: 2.742769718170166
Validation loss: 2.4857827232730005

Epoch: 6| Step: 4
Training loss: 3.081437587738037
Validation loss: 2.5103860157792286

Epoch: 6| Step: 5
Training loss: 2.512925386428833
Validation loss: 2.530682971400599

Epoch: 6| Step: 6
Training loss: 2.444110155105591
Validation loss: 2.48467545740066

Epoch: 6| Step: 7
Training loss: 3.3201253414154053
Validation loss: 2.492083557190434

Epoch: 6| Step: 8
Training loss: 2.3946123123168945
Validation loss: 2.498046987800188

Epoch: 6| Step: 9
Training loss: 2.2329020500183105
Validation loss: 2.5049607881935696

Epoch: 6| Step: 10
Training loss: 2.565185070037842
Validation loss: 2.525195142274262

Epoch: 6| Step: 11
Training loss: 3.919511079788208
Validation loss: 2.5194936388282367

Epoch: 6| Step: 12
Training loss: 2.4208593368530273
Validation loss: 2.513178999705981

Epoch: 6| Step: 13
Training loss: 2.6017544269561768
Validation loss: 2.50694872999704

Epoch: 20| Step: 0
Training loss: 2.115178346633911
Validation loss: 2.5215198865500827

Epoch: 6| Step: 1
Training loss: 1.8626024723052979
Validation loss: 2.5596747962377404

Epoch: 6| Step: 2
Training loss: 2.651726722717285
Validation loss: 2.6425087375025593

Epoch: 6| Step: 3
Training loss: 2.687532424926758
Validation loss: 2.7039206386894308

Epoch: 6| Step: 4
Training loss: 2.92561411857605
Validation loss: 2.838461519569479

Epoch: 6| Step: 5
Training loss: 3.025721549987793
Validation loss: 2.841737921519946

Epoch: 6| Step: 6
Training loss: 3.4214067459106445
Validation loss: 2.7354231111464964

Epoch: 6| Step: 7
Training loss: 2.3694002628326416
Validation loss: 2.56374801358869

Epoch: 6| Step: 8
Training loss: 2.334249258041382
Validation loss: 2.4693700344331804

Epoch: 6| Step: 9
Training loss: 2.635960340499878
Validation loss: 2.476985018740418

Epoch: 6| Step: 10
Training loss: 3.2765870094299316
Validation loss: 2.5125800486533874

Epoch: 6| Step: 11
Training loss: 3.593280792236328
Validation loss: 2.52993877216052

Epoch: 6| Step: 12
Training loss: 2.8652262687683105
Validation loss: 2.524776551031297

Epoch: 6| Step: 13
Training loss: 2.939211130142212
Validation loss: 2.527031226824689

Epoch: 21| Step: 0
Training loss: 3.35687518119812
Validation loss: 2.529881413264941

Epoch: 6| Step: 1
Training loss: 2.183400869369507
Validation loss: 2.507637554599393

Epoch: 6| Step: 2
Training loss: 2.2869529724121094
Validation loss: 2.5072341888181624

Epoch: 6| Step: 3
Training loss: 2.264214515686035
Validation loss: 2.4950858854478404

Epoch: 6| Step: 4
Training loss: 3.094289779663086
Validation loss: 2.4922972084373556

Epoch: 6| Step: 5
Training loss: 2.914156913757324
Validation loss: 2.484912626204952

Epoch: 6| Step: 6
Training loss: 2.6120095252990723
Validation loss: 2.474917588695403

Epoch: 6| Step: 7
Training loss: 3.0077314376831055
Validation loss: 2.4732728235183226

Epoch: 6| Step: 8
Training loss: 3.2400879859924316
Validation loss: 2.4641219108335433

Epoch: 6| Step: 9
Training loss: 2.4006171226501465
Validation loss: 2.4591358502705893

Epoch: 6| Step: 10
Training loss: 2.153446912765503
Validation loss: 2.4818965311973327

Epoch: 6| Step: 11
Training loss: 2.606178045272827
Validation loss: 2.5048889344738376

Epoch: 6| Step: 12
Training loss: 2.7484726905822754
Validation loss: 2.5520936776232976

Epoch: 6| Step: 13
Training loss: 3.84987211227417
Validation loss: 2.5463281780160885

Epoch: 22| Step: 0
Training loss: 2.6485085487365723
Validation loss: 2.4982495307922363

Epoch: 6| Step: 1
Training loss: 2.3740949630737305
Validation loss: 2.4547698215771745

Epoch: 6| Step: 2
Training loss: 2.4528486728668213
Validation loss: 2.4452209523929063

Epoch: 6| Step: 3
Training loss: 1.7973930835723877
Validation loss: 2.4441857030314784

Epoch: 6| Step: 4
Training loss: 2.8888158798217773
Validation loss: 2.4493691562324442

Epoch: 6| Step: 5
Training loss: 3.3252499103546143
Validation loss: 2.4473543731115197

Epoch: 6| Step: 6
Training loss: 2.6208879947662354
Validation loss: 2.443600949420724

Epoch: 6| Step: 7
Training loss: 3.4230093955993652
Validation loss: 2.444020027755409

Epoch: 6| Step: 8
Training loss: 3.02437686920166
Validation loss: 2.4499859963693926

Epoch: 6| Step: 9
Training loss: 2.516187906265259
Validation loss: 2.4491143713715258

Epoch: 6| Step: 10
Training loss: 1.8139195442199707
Validation loss: 2.442071294271818

Epoch: 6| Step: 11
Training loss: 2.781536102294922
Validation loss: 2.4319237124535347

Epoch: 6| Step: 12
Training loss: 3.1599369049072266
Validation loss: 2.43524508835167

Epoch: 6| Step: 13
Training loss: 2.9219698905944824
Validation loss: 2.444107896538191

Epoch: 23| Step: 0
Training loss: 2.563417434692383
Validation loss: 2.46416566705191

Epoch: 6| Step: 1
Training loss: 2.284583806991577
Validation loss: 2.4948455979747157

Epoch: 6| Step: 2
Training loss: 2.5498883724212646
Validation loss: 2.5137948220775974

Epoch: 6| Step: 3
Training loss: 2.8361239433288574
Validation loss: 2.55849427048878

Epoch: 6| Step: 4
Training loss: 2.6936192512512207
Validation loss: 2.557055796346357

Epoch: 6| Step: 5
Training loss: 2.4701507091522217
Validation loss: 2.5483419023534304

Epoch: 6| Step: 6
Training loss: 2.7284469604492188
Validation loss: 2.504047350216937

Epoch: 6| Step: 7
Training loss: 3.191707134246826
Validation loss: 2.4540370920652985

Epoch: 6| Step: 8
Training loss: 3.042839765548706
Validation loss: 2.42333568808853

Epoch: 6| Step: 9
Training loss: 2.0732622146606445
Validation loss: 2.4126104693258963

Epoch: 6| Step: 10
Training loss: 2.7472052574157715
Validation loss: 2.424332921222974

Epoch: 6| Step: 11
Training loss: 2.705014228820801
Validation loss: 2.4417572072757188

Epoch: 6| Step: 12
Training loss: 2.964956045150757
Validation loss: 2.452446383814658

Epoch: 6| Step: 13
Training loss: 3.0577592849731445
Validation loss: 2.461093020695512

Epoch: 24| Step: 0
Training loss: 2.530789852142334
Validation loss: 2.458966803807084

Epoch: 6| Step: 1
Training loss: 2.2823033332824707
Validation loss: 2.447775184467275

Epoch: 6| Step: 2
Training loss: 3.1178293228149414
Validation loss: 2.4446791653992026

Epoch: 6| Step: 3
Training loss: 2.1935155391693115
Validation loss: 2.4388559300412416

Epoch: 6| Step: 4
Training loss: 3.0083723068237305
Validation loss: 2.435300632189679

Epoch: 6| Step: 5
Training loss: 2.679719924926758
Validation loss: 2.429568185601183

Epoch: 6| Step: 6
Training loss: 2.025908946990967
Validation loss: 2.4251550500110914

Epoch: 6| Step: 7
Training loss: 3.1692934036254883
Validation loss: 2.4176502368783437

Epoch: 6| Step: 8
Training loss: 2.3268704414367676
Validation loss: 2.4257356710331415

Epoch: 6| Step: 9
Training loss: 2.7111477851867676
Validation loss: 2.431966407324678

Epoch: 6| Step: 10
Training loss: 1.9069347381591797
Validation loss: 2.4467672840241463

Epoch: 6| Step: 11
Training loss: 2.6135849952697754
Validation loss: 2.4800720548117035

Epoch: 6| Step: 12
Training loss: 4.088743686676025
Validation loss: 2.5581637864471762

Epoch: 6| Step: 13
Training loss: 3.1434173583984375
Validation loss: 2.522223154703776

Epoch: 25| Step: 0
Training loss: 2.9869225025177
Validation loss: 2.5017164625147337

Epoch: 6| Step: 1
Training loss: 2.5385994911193848
Validation loss: 2.4940042675182386

Epoch: 6| Step: 2
Training loss: 2.4186787605285645
Validation loss: 2.4710853330550657

Epoch: 6| Step: 3
Training loss: 2.8593239784240723
Validation loss: 2.443852565621817

Epoch: 6| Step: 4
Training loss: 2.1745409965515137
Validation loss: 2.41638377148618

Epoch: 6| Step: 5
Training loss: 2.659855842590332
Validation loss: 2.4110723157082834

Epoch: 6| Step: 6
Training loss: 2.869553804397583
Validation loss: 2.416581294869864

Epoch: 6| Step: 7
Training loss: 2.4533350467681885
Validation loss: 2.4164555200966458

Epoch: 6| Step: 8
Training loss: 2.0943994522094727
Validation loss: 2.4125931083515124

Epoch: 6| Step: 9
Training loss: 3.3902366161346436
Validation loss: 2.407407274810217

Epoch: 6| Step: 10
Training loss: 2.756697416305542
Validation loss: 2.3929005361372426

Epoch: 6| Step: 11
Training loss: 2.836087703704834
Validation loss: 2.3808877647563977

Epoch: 6| Step: 12
Training loss: 2.3677849769592285
Validation loss: 2.375057335822813

Epoch: 6| Step: 13
Training loss: 3.409909248352051
Validation loss: 2.3773432085590978

Epoch: 26| Step: 0
Training loss: 2.9280927181243896
Validation loss: 2.3837925593058267

Epoch: 6| Step: 1
Training loss: 2.9758450984954834
Validation loss: 2.398888696906387

Epoch: 6| Step: 2
Training loss: 2.251005172729492
Validation loss: 2.409249764616771

Epoch: 6| Step: 3
Training loss: 3.5183115005493164
Validation loss: 2.421764942907518

Epoch: 6| Step: 4
Training loss: 2.283684730529785
Validation loss: 2.4356373535689486

Epoch: 6| Step: 5
Training loss: 2.397854804992676
Validation loss: 2.439164597501037

Epoch: 6| Step: 6
Training loss: 3.2787086963653564
Validation loss: 2.4617533119775916

Epoch: 6| Step: 7
Training loss: 2.5257558822631836
Validation loss: 2.439207253917571

Epoch: 6| Step: 8
Training loss: 2.4342079162597656
Validation loss: 2.423039126139815

Epoch: 6| Step: 9
Training loss: 2.3225879669189453
Validation loss: 2.394735159412507

Epoch: 6| Step: 10
Training loss: 2.424015998840332
Validation loss: 2.382925716779565

Epoch: 6| Step: 11
Training loss: 2.3719704151153564
Validation loss: 2.3728313779318206

Epoch: 6| Step: 12
Training loss: 3.0060555934906006
Validation loss: 2.3629947657226236

Epoch: 6| Step: 13
Training loss: 2.3926243782043457
Validation loss: 2.354676615807318

Epoch: 27| Step: 0
Training loss: 2.8427281379699707
Validation loss: 2.3614478649631625

Epoch: 6| Step: 1
Training loss: 2.7270498275756836
Validation loss: 2.3614693764717347

Epoch: 6| Step: 2
Training loss: 2.264132261276245
Validation loss: 2.365822922798895

Epoch: 6| Step: 3
Training loss: 3.1738152503967285
Validation loss: 2.369300337247951

Epoch: 6| Step: 4
Training loss: 2.0202622413635254
Validation loss: 2.378133399512178

Epoch: 6| Step: 5
Training loss: 2.629910469055176
Validation loss: 2.4021816971481487

Epoch: 6| Step: 6
Training loss: 2.557105541229248
Validation loss: 2.4063558219581522

Epoch: 6| Step: 7
Training loss: 2.6964173316955566
Validation loss: 2.410968301116779

Epoch: 6| Step: 8
Training loss: 2.5474653244018555
Validation loss: 2.428770416526384

Epoch: 6| Step: 9
Training loss: 2.45896053314209
Validation loss: 2.474856913730662

Epoch: 6| Step: 10
Training loss: 2.77293062210083
Validation loss: 2.5625343758572816

Epoch: 6| Step: 11
Training loss: 3.098839044570923
Validation loss: 2.563933434024934

Epoch: 6| Step: 12
Training loss: 2.7873587608337402
Validation loss: 2.5630752655767624

Epoch: 6| Step: 13
Training loss: 2.48500657081604
Validation loss: 2.5880916041712605

Epoch: 28| Step: 0
Training loss: 2.898087978363037
Validation loss: 2.5700983308976695

Epoch: 6| Step: 1
Training loss: 2.880093574523926
Validation loss: 2.558847132549491

Epoch: 6| Step: 2
Training loss: 1.7893785238265991
Validation loss: 2.502793042890487

Epoch: 6| Step: 3
Training loss: 2.4086923599243164
Validation loss: 2.473955621001541

Epoch: 6| Step: 4
Training loss: 2.5306601524353027
Validation loss: 2.465020456621724

Epoch: 6| Step: 5
Training loss: 2.5485033988952637
Validation loss: 2.4582962477079002

Epoch: 6| Step: 6
Training loss: 3.1577775478363037
Validation loss: 2.454795468238092

Epoch: 6| Step: 7
Training loss: 3.1210291385650635
Validation loss: 2.4428147756925194

Epoch: 6| Step: 8
Training loss: 2.35493540763855
Validation loss: 2.4396963042597615

Epoch: 6| Step: 9
Training loss: 1.8701237440109253
Validation loss: 2.424054168885754

Epoch: 6| Step: 10
Training loss: 3.054572582244873
Validation loss: 2.412362185857629

Epoch: 6| Step: 11
Training loss: 2.5211844444274902
Validation loss: 2.3911144323246454

Epoch: 6| Step: 12
Training loss: 3.042952537536621
Validation loss: 2.3716251901400986

Epoch: 6| Step: 13
Training loss: 3.6519291400909424
Validation loss: 2.3588289932538102

Epoch: 29| Step: 0
Training loss: 2.4282848834991455
Validation loss: 2.3525658115263908

Epoch: 6| Step: 1
Training loss: 2.504629611968994
Validation loss: 2.3508215078743557

Epoch: 6| Step: 2
Training loss: 1.809734582901001
Validation loss: 2.356740802846929

Epoch: 6| Step: 3
Training loss: 3.0499401092529297
Validation loss: 2.3613020066292054

Epoch: 6| Step: 4
Training loss: 2.4951858520507812
Validation loss: 2.3654695377554944

Epoch: 6| Step: 5
Training loss: 2.6894826889038086
Validation loss: 2.374569603191909

Epoch: 6| Step: 6
Training loss: 2.4918313026428223
Validation loss: 2.374902602164976

Epoch: 6| Step: 7
Training loss: 2.684884548187256
Validation loss: 2.384507753515756

Epoch: 6| Step: 8
Training loss: 2.972653865814209
Validation loss: 2.383803108687042

Epoch: 6| Step: 9
Training loss: 2.725372314453125
Validation loss: 2.3921794532447733

Epoch: 6| Step: 10
Training loss: 2.7999205589294434
Validation loss: 2.3722737437935284

Epoch: 6| Step: 11
Training loss: 2.6255176067352295
Validation loss: 2.359330318307364

Epoch: 6| Step: 12
Training loss: 2.8044073581695557
Validation loss: 2.348439165340957

Epoch: 6| Step: 13
Training loss: 2.8564367294311523
Validation loss: 2.343204061190287

Epoch: 30| Step: 0
Training loss: 2.583192825317383
Validation loss: 2.336005751804639

Epoch: 6| Step: 1
Training loss: 2.1870036125183105
Validation loss: 2.3337180819562686

Epoch: 6| Step: 2
Training loss: 2.732283115386963
Validation loss: 2.3349481064786195

Epoch: 6| Step: 3
Training loss: 3.17215633392334
Validation loss: 2.3515826040698635

Epoch: 6| Step: 4
Training loss: 2.3592216968536377
Validation loss: 2.3564729729006366

Epoch: 6| Step: 5
Training loss: 2.1597790718078613
Validation loss: 2.359146233527891

Epoch: 6| Step: 6
Training loss: 1.7900363206863403
Validation loss: 2.3668342200658654

Epoch: 6| Step: 7
Training loss: 2.8358044624328613
Validation loss: 2.360551958443016

Epoch: 6| Step: 8
Training loss: 3.4253246784210205
Validation loss: 2.3608686770162275

Epoch: 6| Step: 9
Training loss: 2.888211250305176
Validation loss: 2.3542760315761773

Epoch: 6| Step: 10
Training loss: 2.5478196144104004
Validation loss: 2.34438810553602

Epoch: 6| Step: 11
Training loss: 2.8730738162994385
Validation loss: 2.332743106349822

Epoch: 6| Step: 12
Training loss: 2.6739695072174072
Validation loss: 2.3326885008042857

Epoch: 6| Step: 13
Training loss: 2.9043760299682617
Validation loss: 2.332085886309224

Epoch: 31| Step: 0
Training loss: 2.3612060546875
Validation loss: 2.3302499914682038

Epoch: 6| Step: 1
Training loss: 2.634202003479004
Validation loss: 2.3319165757907334

Epoch: 6| Step: 2
Training loss: 2.9051270484924316
Validation loss: 2.338310267335625

Epoch: 6| Step: 3
Training loss: 2.4511513710021973
Validation loss: 2.339503906106436

Epoch: 6| Step: 4
Training loss: 3.493497371673584
Validation loss: 2.3529234163222776

Epoch: 6| Step: 5
Training loss: 3.1541800498962402
Validation loss: 2.348525242138934

Epoch: 6| Step: 6
Training loss: 2.1440610885620117
Validation loss: 2.3509361231198875

Epoch: 6| Step: 7
Training loss: 3.2026984691619873
Validation loss: 2.353712563873619

Epoch: 6| Step: 8
Training loss: 2.245175838470459
Validation loss: 2.372400173576929

Epoch: 6| Step: 9
Training loss: 1.821212887763977
Validation loss: 2.3774235248565674

Epoch: 6| Step: 10
Training loss: 2.6747937202453613
Validation loss: 2.4120492422452537

Epoch: 6| Step: 11
Training loss: 2.3365707397460938
Validation loss: 2.3863006535396782

Epoch: 6| Step: 12
Training loss: 2.6865885257720947
Validation loss: 2.3811832063941547

Epoch: 6| Step: 13
Training loss: 2.5337448120117188
Validation loss: 2.3713738149212253

Epoch: 32| Step: 0
Training loss: 2.9394068717956543
Validation loss: 2.3626832244216756

Epoch: 6| Step: 1
Training loss: 2.625153064727783
Validation loss: 2.348957887259863

Epoch: 6| Step: 2
Training loss: 2.3267433643341064
Validation loss: 2.3450241319594847

Epoch: 6| Step: 3
Training loss: 2.5699760913848877
Validation loss: 2.3379070246091453

Epoch: 6| Step: 4
Training loss: 2.414536476135254
Validation loss: 2.332298095508288

Epoch: 6| Step: 5
Training loss: 2.368044853210449
Validation loss: 2.327470692255164

Epoch: 6| Step: 6
Training loss: 3.1918787956237793
Validation loss: 2.3300118997532833

Epoch: 6| Step: 7
Training loss: 2.720482587814331
Validation loss: 2.3256358895250546

Epoch: 6| Step: 8
Training loss: 2.9093518257141113
Validation loss: 2.3282043292958248

Epoch: 6| Step: 9
Training loss: 3.268899440765381
Validation loss: 2.3275080906447543

Epoch: 6| Step: 10
Training loss: 2.2011024951934814
Validation loss: 2.3262149518535984

Epoch: 6| Step: 11
Training loss: 2.624999523162842
Validation loss: 2.331449847067556

Epoch: 6| Step: 12
Training loss: 2.2554335594177246
Validation loss: 2.324756545405234

Epoch: 6| Step: 13
Training loss: 1.9992345571517944
Validation loss: 2.350975772385956

Epoch: 33| Step: 0
Training loss: 2.803985595703125
Validation loss: 2.321670801408829

Epoch: 6| Step: 1
Training loss: 2.839959144592285
Validation loss: 2.31257692972819

Epoch: 6| Step: 2
Training loss: 3.3597538471221924
Validation loss: 2.3118535152045627

Epoch: 6| Step: 3
Training loss: 2.381383180618286
Validation loss: 2.313712904530187

Epoch: 6| Step: 4
Training loss: 2.190617561340332
Validation loss: 2.3117575030173025

Epoch: 6| Step: 5
Training loss: 2.7126240730285645
Validation loss: 2.31730572126245

Epoch: 6| Step: 6
Training loss: 3.187547206878662
Validation loss: 2.325711606651224

Epoch: 6| Step: 7
Training loss: 1.9696440696716309
Validation loss: 2.342638954039543

Epoch: 6| Step: 8
Training loss: 2.8853888511657715
Validation loss: 2.354655886209139

Epoch: 6| Step: 9
Training loss: 2.1744544506073
Validation loss: 2.3523643580816125

Epoch: 6| Step: 10
Training loss: 2.4930808544158936
Validation loss: 2.3747717718924246

Epoch: 6| Step: 11
Training loss: 1.8530007600784302
Validation loss: 2.3916022059737996

Epoch: 6| Step: 12
Training loss: 2.891242027282715
Validation loss: 2.3774295929939515

Epoch: 6| Step: 13
Training loss: 2.802708625793457
Validation loss: 2.3542264046207553

Epoch: 34| Step: 0
Training loss: 2.524531364440918
Validation loss: 2.3628251347490536

Epoch: 6| Step: 1
Training loss: 2.4909653663635254
Validation loss: 2.4048701588825514

Epoch: 6| Step: 2
Training loss: 2.481844425201416
Validation loss: 2.451758230886152

Epoch: 6| Step: 3
Training loss: 1.7926896810531616
Validation loss: 2.5128490155743015

Epoch: 6| Step: 4
Training loss: 2.876580238342285
Validation loss: 2.500107337069768

Epoch: 6| Step: 5
Training loss: 2.4316582679748535
Validation loss: 2.466619914577853

Epoch: 6| Step: 6
Training loss: 3.0239055156707764
Validation loss: 2.4243308472377

Epoch: 6| Step: 7
Training loss: 2.861100912094116
Validation loss: 2.3843589598132717

Epoch: 6| Step: 8
Training loss: 2.5552852153778076
Validation loss: 2.3470419914491716

Epoch: 6| Step: 9
Training loss: 2.8894598484039307
Validation loss: 2.3186897693141812

Epoch: 6| Step: 10
Training loss: 2.820080280303955
Validation loss: 2.302554812482608

Epoch: 6| Step: 11
Training loss: 2.9772958755493164
Validation loss: 2.2953981814845914

Epoch: 6| Step: 12
Training loss: 2.221851348876953
Validation loss: 2.2927133280743837

Epoch: 6| Step: 13
Training loss: 2.4114315509796143
Validation loss: 2.288789949109477

Epoch: 35| Step: 0
Training loss: 2.3602890968322754
Validation loss: 2.2932825126955585

Epoch: 6| Step: 1
Training loss: 2.547142744064331
Validation loss: 2.295073414361605

Epoch: 6| Step: 2
Training loss: 2.935816526412964
Validation loss: 2.295938067538764

Epoch: 6| Step: 3
Training loss: 2.4696311950683594
Validation loss: 2.2943021353854927

Epoch: 6| Step: 4
Training loss: 2.7390947341918945
Validation loss: 2.2904849795884985

Epoch: 6| Step: 5
Training loss: 2.0905520915985107
Validation loss: 2.2889574804613666

Epoch: 6| Step: 6
Training loss: 2.2942771911621094
Validation loss: 2.284601242311539

Epoch: 6| Step: 7
Training loss: 3.1124682426452637
Validation loss: 2.283775119371312

Epoch: 6| Step: 8
Training loss: 2.737730026245117
Validation loss: 2.2868591559830533

Epoch: 6| Step: 9
Training loss: 2.4464006423950195
Validation loss: 2.2859989648224204

Epoch: 6| Step: 10
Training loss: 2.4514122009277344
Validation loss: 2.295255535392351

Epoch: 6| Step: 11
Training loss: 2.9089303016662598
Validation loss: 2.294657894360122

Epoch: 6| Step: 12
Training loss: 2.86649227142334
Validation loss: 2.3014316661383516

Epoch: 6| Step: 13
Training loss: 2.3371386528015137
Validation loss: 2.315993268002746

Epoch: 36| Step: 0
Training loss: 2.6200718879699707
Validation loss: 2.3426458553601335

Epoch: 6| Step: 1
Training loss: 2.604689598083496
Validation loss: 2.3650542125906995

Epoch: 6| Step: 2
Training loss: 3.3367748260498047
Validation loss: 2.3855395624714513

Epoch: 6| Step: 3
Training loss: 2.777958631515503
Validation loss: 2.4048462580609065

Epoch: 6| Step: 4
Training loss: 2.3129594326019287
Validation loss: 2.4213679426459858

Epoch: 6| Step: 5
Training loss: 1.7738162279129028
Validation loss: 2.4070791429088962

Epoch: 6| Step: 6
Training loss: 2.519960880279541
Validation loss: 2.4239131122507076

Epoch: 6| Step: 7
Training loss: 3.0492630004882812
Validation loss: 2.397826394727153

Epoch: 6| Step: 8
Training loss: 2.544452667236328
Validation loss: 2.3734777614634526

Epoch: 6| Step: 9
Training loss: 3.1205358505249023
Validation loss: 2.3572616295147966

Epoch: 6| Step: 10
Training loss: 2.4556338787078857
Validation loss: 2.344040032356016

Epoch: 6| Step: 11
Training loss: 2.050668239593506
Validation loss: 2.3365888364853395

Epoch: 6| Step: 12
Training loss: 3.282538414001465
Validation loss: 2.3256565909231863

Epoch: 6| Step: 13
Training loss: 2.047013521194458
Validation loss: 2.315097244836951

Epoch: 37| Step: 0
Training loss: 2.788407325744629
Validation loss: 2.31308885030849

Epoch: 6| Step: 1
Training loss: 2.325713634490967
Validation loss: 2.29591110444838

Epoch: 6| Step: 2
Training loss: 2.8310861587524414
Validation loss: 2.294537005885955

Epoch: 6| Step: 3
Training loss: 2.683194875717163
Validation loss: 2.296303323520127

Epoch: 6| Step: 4
Training loss: 2.8085334300994873
Validation loss: 2.2955267813897904

Epoch: 6| Step: 5
Training loss: 2.8793845176696777
Validation loss: 2.2961679991855415

Epoch: 6| Step: 6
Training loss: 2.8633735179901123
Validation loss: 2.3095465808786373

Epoch: 6| Step: 7
Training loss: 2.566848039627075
Validation loss: 2.4057579014890935

Epoch: 6| Step: 8
Training loss: 2.9088125228881836
Validation loss: 2.459694000982469

Epoch: 6| Step: 9
Training loss: 2.889378070831299
Validation loss: 2.4322122822525682

Epoch: 6| Step: 10
Training loss: 2.127261161804199
Validation loss: 2.374412881430759

Epoch: 6| Step: 11
Training loss: 2.201779842376709
Validation loss: 2.3270532469595633

Epoch: 6| Step: 12
Training loss: 2.1101467609405518
Validation loss: 2.273775492945025

Epoch: 6| Step: 13
Training loss: 2.4228765964508057
Validation loss: 2.275984280852861

Epoch: 38| Step: 0
Training loss: 2.0827178955078125
Validation loss: 2.2844380947851364

Epoch: 6| Step: 1
Training loss: 2.829498052597046
Validation loss: 2.330805295257158

Epoch: 6| Step: 2
Training loss: 2.5241904258728027
Validation loss: 2.364121885709865

Epoch: 6| Step: 3
Training loss: 2.313981056213379
Validation loss: 2.3750106519268406

Epoch: 6| Step: 4
Training loss: 3.1579408645629883
Validation loss: 2.4185465663991947

Epoch: 6| Step: 5
Training loss: 2.75351619720459
Validation loss: 2.458081986314507

Epoch: 6| Step: 6
Training loss: 3.199371337890625
Validation loss: 2.4768648506492696

Epoch: 6| Step: 7
Training loss: 2.5034282207489014
Validation loss: 2.463352095696234

Epoch: 6| Step: 8
Training loss: 3.509817600250244
Validation loss: 2.4442918838993197

Epoch: 6| Step: 9
Training loss: 2.342451572418213
Validation loss: 2.3952269349046933

Epoch: 6| Step: 10
Training loss: 3.099726438522339
Validation loss: 2.370065745487008

Epoch: 6| Step: 11
Training loss: 2.180128574371338
Validation loss: 2.3659655073637604

Epoch: 6| Step: 12
Training loss: 2.3304085731506348
Validation loss: 2.3333269601227133

Epoch: 6| Step: 13
Training loss: 1.596915602684021
Validation loss: 2.3284201288735993

Epoch: 39| Step: 0
Training loss: 2.8044040203094482
Validation loss: 2.343297637918944

Epoch: 6| Step: 1
Training loss: 2.6668715476989746
Validation loss: 2.358448269546673

Epoch: 6| Step: 2
Training loss: 2.206068277359009
Validation loss: 2.369083294304468

Epoch: 6| Step: 3
Training loss: 2.420229196548462
Validation loss: 2.3953460416486188

Epoch: 6| Step: 4
Training loss: 2.1084470748901367
Validation loss: 2.411731396951983

Epoch: 6| Step: 5
Training loss: 2.7027347087860107
Validation loss: 2.391546364753477

Epoch: 6| Step: 6
Training loss: 2.887071371078491
Validation loss: 2.3424987664786716

Epoch: 6| Step: 7
Training loss: 2.6874537467956543
Validation loss: 2.316761839774347

Epoch: 6| Step: 8
Training loss: 3.624370574951172
Validation loss: 2.288072188695272

Epoch: 6| Step: 9
Training loss: 2.9684133529663086
Validation loss: 2.287699653256324

Epoch: 6| Step: 10
Training loss: 1.9050946235656738
Validation loss: 2.28703046870488

Epoch: 6| Step: 11
Training loss: 2.0009231567382812
Validation loss: 2.279915919867895

Epoch: 6| Step: 12
Training loss: 3.186826229095459
Validation loss: 2.2797319658340944

Epoch: 6| Step: 13
Training loss: 1.716902494430542
Validation loss: 2.2854096146040064

Epoch: 40| Step: 0
Training loss: 2.967848777770996
Validation loss: 2.2908494882686163

Epoch: 6| Step: 1
Training loss: 2.1499831676483154
Validation loss: 2.3354092233924457

Epoch: 6| Step: 2
Training loss: 2.847031593322754
Validation loss: 2.3640171712444675

Epoch: 6| Step: 3
Training loss: 2.871500015258789
Validation loss: 2.3864946647356917

Epoch: 6| Step: 4
Training loss: 2.001178503036499
Validation loss: 2.3924007210680234

Epoch: 6| Step: 5
Training loss: 2.83146333694458
Validation loss: 2.3802380536192205

Epoch: 6| Step: 6
Training loss: 2.190209150314331
Validation loss: 2.3749981093150314

Epoch: 6| Step: 7
Training loss: 3.4285900592803955
Validation loss: 2.3825754427140757

Epoch: 6| Step: 8
Training loss: 2.287755250930786
Validation loss: 2.3920456927309752

Epoch: 6| Step: 9
Training loss: 2.7390756607055664
Validation loss: 2.4049480397214174

Epoch: 6| Step: 10
Training loss: 3.051363468170166
Validation loss: 2.430117030297556

Epoch: 6| Step: 11
Training loss: 2.526057720184326
Validation loss: 2.4411218063805693

Epoch: 6| Step: 12
Training loss: 2.310361623764038
Validation loss: 2.444103278139586

Epoch: 6| Step: 13
Training loss: 2.5395283699035645
Validation loss: 2.382880805641092

Epoch: 41| Step: 0
Training loss: 2.5378661155700684
Validation loss: 2.347603944040114

Epoch: 6| Step: 1
Training loss: 3.229397773742676
Validation loss: 2.301542558977681

Epoch: 6| Step: 2
Training loss: 2.092994213104248
Validation loss: 2.263701233812558

Epoch: 6| Step: 3
Training loss: 2.3823509216308594
Validation loss: 2.2788492710359636

Epoch: 6| Step: 4
Training loss: 2.2770724296569824
Validation loss: 2.275644535659462

Epoch: 6| Step: 5
Training loss: 2.8810524940490723
Validation loss: 2.2957903146743774

Epoch: 6| Step: 6
Training loss: 1.9274004697799683
Validation loss: 2.291890759621897

Epoch: 6| Step: 7
Training loss: 2.2829880714416504
Validation loss: 2.2808093396566247

Epoch: 6| Step: 8
Training loss: 3.1270368099212646
Validation loss: 2.2795832580135715

Epoch: 6| Step: 9
Training loss: 2.564587116241455
Validation loss: 2.281993043038153

Epoch: 6| Step: 10
Training loss: 2.890618324279785
Validation loss: 2.2849511395218554

Epoch: 6| Step: 11
Training loss: 2.7217297554016113
Validation loss: 2.2916150708352365

Epoch: 6| Step: 12
Training loss: 2.8313841819763184
Validation loss: 2.3071281204941454

Epoch: 6| Step: 13
Training loss: 2.368553638458252
Validation loss: 2.3194871564065256

Epoch: 42| Step: 0
Training loss: 2.8991920948028564
Validation loss: 2.330695665010842

Epoch: 6| Step: 1
Training loss: 2.568476915359497
Validation loss: 2.3265029461153093

Epoch: 6| Step: 2
Training loss: 1.890909194946289
Validation loss: 2.336290690206712

Epoch: 6| Step: 3
Training loss: 2.1634294986724854
Validation loss: 2.3644905756878596

Epoch: 6| Step: 4
Training loss: 2.949591636657715
Validation loss: 2.359398362457111

Epoch: 6| Step: 5
Training loss: 2.5434765815734863
Validation loss: 2.354354373870357

Epoch: 6| Step: 6
Training loss: 2.245485544204712
Validation loss: 2.3048836825996317

Epoch: 6| Step: 7
Training loss: 2.549206256866455
Validation loss: 2.2816531760718233

Epoch: 6| Step: 8
Training loss: 3.297874689102173
Validation loss: 2.2493330047976587

Epoch: 6| Step: 9
Training loss: 2.4458460807800293
Validation loss: 2.2423429219953475

Epoch: 6| Step: 10
Training loss: 2.8517398834228516
Validation loss: 2.2422138644802954

Epoch: 6| Step: 11
Training loss: 1.7439568042755127
Validation loss: 2.241776838097521

Epoch: 6| Step: 12
Training loss: 3.0876755714416504
Validation loss: 2.247865915298462

Epoch: 6| Step: 13
Training loss: 2.8241891860961914
Validation loss: 2.2479093100434993

Epoch: 43| Step: 0
Training loss: 2.2777156829833984
Validation loss: 2.2554158831155426

Epoch: 6| Step: 1
Training loss: 2.7491543292999268
Validation loss: 2.2697392074010705

Epoch: 6| Step: 2
Training loss: 2.1207923889160156
Validation loss: 2.263698306134952

Epoch: 6| Step: 3
Training loss: 2.5824036598205566
Validation loss: 2.2637971139723256

Epoch: 6| Step: 4
Training loss: 1.8969166278839111
Validation loss: 2.258790523775162

Epoch: 6| Step: 5
Training loss: 3.0007119178771973
Validation loss: 2.2520557513801

Epoch: 6| Step: 6
Training loss: 2.105137586593628
Validation loss: 2.254701554134328

Epoch: 6| Step: 7
Training loss: 2.635305643081665
Validation loss: 2.2531485813920216

Epoch: 6| Step: 8
Training loss: 3.0958733558654785
Validation loss: 2.257763719045988

Epoch: 6| Step: 9
Training loss: 2.534795045852661
Validation loss: 2.2554185646836475

Epoch: 6| Step: 10
Training loss: 2.977266311645508
Validation loss: 2.2715858579963766

Epoch: 6| Step: 11
Training loss: 1.9576890468597412
Validation loss: 2.2922008165749173

Epoch: 6| Step: 12
Training loss: 2.9717841148376465
Validation loss: 2.3063413943013837

Epoch: 6| Step: 13
Training loss: 3.5458920001983643
Validation loss: 2.3023060188498548

Epoch: 44| Step: 0
Training loss: 3.0646884441375732
Validation loss: 2.3109348256100892

Epoch: 6| Step: 1
Training loss: 1.9345879554748535
Validation loss: 2.312969607691611

Epoch: 6| Step: 2
Training loss: 2.4229259490966797
Validation loss: 2.3019676644315004

Epoch: 6| Step: 3
Training loss: 2.6476709842681885
Validation loss: 2.2633229276185394

Epoch: 6| Step: 4
Training loss: 2.1782071590423584
Validation loss: 2.2378413831034014

Epoch: 6| Step: 5
Training loss: 2.649139404296875
Validation loss: 2.2326961640388734

Epoch: 6| Step: 6
Training loss: 2.4135148525238037
Validation loss: 2.230973697477771

Epoch: 6| Step: 7
Training loss: 2.7789220809936523
Validation loss: 2.231036804055655

Epoch: 6| Step: 8
Training loss: 2.6093761920928955
Validation loss: 2.2343812834831978

Epoch: 6| Step: 9
Training loss: 3.4112682342529297
Validation loss: 2.240873175282632

Epoch: 6| Step: 10
Training loss: 2.7498788833618164
Validation loss: 2.242317606044072

Epoch: 6| Step: 11
Training loss: 2.432861804962158
Validation loss: 2.243381569462438

Epoch: 6| Step: 12
Training loss: 2.2900643348693848
Validation loss: 2.2471357840363697

Epoch: 6| Step: 13
Training loss: 2.23689341545105
Validation loss: 2.243551956709995

Epoch: 45| Step: 0
Training loss: 2.3297362327575684
Validation loss: 2.238469713477678

Epoch: 6| Step: 1
Training loss: 2.3291029930114746
Validation loss: 2.2378140367487425

Epoch: 6| Step: 2
Training loss: 2.4534990787506104
Validation loss: 2.2343720210495817

Epoch: 6| Step: 3
Training loss: 2.369701385498047
Validation loss: 2.2287768279352496

Epoch: 6| Step: 4
Training loss: 3.4015841484069824
Validation loss: 2.2281320607790382

Epoch: 6| Step: 5
Training loss: 2.606595993041992
Validation loss: 2.2262082202460176

Epoch: 6| Step: 6
Training loss: 2.036027193069458
Validation loss: 2.219897982894733

Epoch: 6| Step: 7
Training loss: 2.283695936203003
Validation loss: 2.21958686203085

Epoch: 6| Step: 8
Training loss: 2.8616299629211426
Validation loss: 2.221986222010787

Epoch: 6| Step: 9
Training loss: 3.023343324661255
Validation loss: 2.225827186338363

Epoch: 6| Step: 10
Training loss: 2.9221932888031006
Validation loss: 2.2323426815771286

Epoch: 6| Step: 11
Training loss: 2.181901454925537
Validation loss: 2.251838509754468

Epoch: 6| Step: 12
Training loss: 2.3917195796966553
Validation loss: 2.26694086546539

Epoch: 6| Step: 13
Training loss: 2.6817636489868164
Validation loss: 2.286281365220265

Epoch: 46| Step: 0
Training loss: 2.9106321334838867
Validation loss: 2.3104887547031527

Epoch: 6| Step: 1
Training loss: 1.7817925214767456
Validation loss: 2.2983358316524054

Epoch: 6| Step: 2
Training loss: 2.85882306098938
Validation loss: 2.2813676454687632

Epoch: 6| Step: 3
Training loss: 2.855252504348755
Validation loss: 2.2706948185479767

Epoch: 6| Step: 4
Training loss: 1.9397165775299072
Validation loss: 2.2724273127894246

Epoch: 6| Step: 5
Training loss: 2.2524261474609375
Validation loss: 2.272913655927104

Epoch: 6| Step: 6
Training loss: 2.3157010078430176
Validation loss: 2.2677226092225764

Epoch: 6| Step: 7
Training loss: 3.1361825466156006
Validation loss: 2.2630210512427875

Epoch: 6| Step: 8
Training loss: 3.965639352798462
Validation loss: 2.273843844731649

Epoch: 6| Step: 9
Training loss: 2.2144031524658203
Validation loss: 2.282821096399779

Epoch: 6| Step: 10
Training loss: 2.4845449924468994
Validation loss: 2.2754580974578857

Epoch: 6| Step: 11
Training loss: 2.2552289962768555
Validation loss: 2.272722872354651

Epoch: 6| Step: 12
Training loss: 2.3877434730529785
Validation loss: 2.260868428855814

Epoch: 6| Step: 13
Training loss: 2.034688949584961
Validation loss: 2.2419282249225083

Epoch: 47| Step: 0
Training loss: 3.3348307609558105
Validation loss: 2.22687933521886

Epoch: 6| Step: 1
Training loss: 1.8656909465789795
Validation loss: 2.2110026036539385

Epoch: 6| Step: 2
Training loss: 2.462893486022949
Validation loss: 2.2115672942130797

Epoch: 6| Step: 3
Training loss: 1.8107538223266602
Validation loss: 2.208307686672416

Epoch: 6| Step: 4
Training loss: 2.6754894256591797
Validation loss: 2.2136044681713147

Epoch: 6| Step: 5
Training loss: 2.812213897705078
Validation loss: 2.211372818998111

Epoch: 6| Step: 6
Training loss: 2.8064382076263428
Validation loss: 2.212810634284891

Epoch: 6| Step: 7
Training loss: 2.6631784439086914
Validation loss: 2.2112380881463327

Epoch: 6| Step: 8
Training loss: 3.2399821281433105
Validation loss: 2.211763612685665

Epoch: 6| Step: 9
Training loss: 2.2243077754974365
Validation loss: 2.2081168672089935

Epoch: 6| Step: 10
Training loss: 3.165278911590576
Validation loss: 2.203281546151766

Epoch: 6| Step: 11
Training loss: 1.8599917888641357
Validation loss: 2.207536853769774

Epoch: 6| Step: 12
Training loss: 2.159623146057129
Validation loss: 2.201978001543271

Epoch: 6| Step: 13
Training loss: 2.6043312549591064
Validation loss: 2.198251093587568

Epoch: 48| Step: 0
Training loss: 1.774053692817688
Validation loss: 2.2026809800055718

Epoch: 6| Step: 1
Training loss: 3.0228261947631836
Validation loss: 2.2018915466082993

Epoch: 6| Step: 2
Training loss: 2.0371522903442383
Validation loss: 2.2045378608088337

Epoch: 6| Step: 3
Training loss: 2.5504398345947266
Validation loss: 2.201454352307063

Epoch: 6| Step: 4
Training loss: 2.2092432975769043
Validation loss: 2.2085256345810427

Epoch: 6| Step: 5
Training loss: 2.028501033782959
Validation loss: 2.2133475144704184

Epoch: 6| Step: 6
Training loss: 2.6378626823425293
Validation loss: 2.209460243102043

Epoch: 6| Step: 7
Training loss: 2.783931016921997
Validation loss: 2.216972122910202

Epoch: 6| Step: 8
Training loss: 2.7133545875549316
Validation loss: 2.2208788664110246

Epoch: 6| Step: 9
Training loss: 2.4580166339874268
Validation loss: 2.213324234049807

Epoch: 6| Step: 10
Training loss: 2.8371152877807617
Validation loss: 2.2246833462868967

Epoch: 6| Step: 11
Training loss: 3.221017599105835
Validation loss: 2.2320734608557915

Epoch: 6| Step: 12
Training loss: 2.571629524230957
Validation loss: 2.2477663973326325

Epoch: 6| Step: 13
Training loss: 2.4905548095703125
Validation loss: 2.2710012876859276

Epoch: 49| Step: 0
Training loss: 3.161241054534912
Validation loss: 2.285881911554644

Epoch: 6| Step: 1
Training loss: 1.99648118019104
Validation loss: 2.29948486692162

Epoch: 6| Step: 2
Training loss: 2.5145106315612793
Validation loss: 2.319005289385396

Epoch: 6| Step: 3
Training loss: 2.388516902923584
Validation loss: 2.337968175129224

Epoch: 6| Step: 4
Training loss: 2.723301410675049
Validation loss: 2.3443360277401504

Epoch: 6| Step: 5
Training loss: 2.578159809112549
Validation loss: 2.3315920522136073

Epoch: 6| Step: 6
Training loss: 2.5085291862487793
Validation loss: 2.322999720932335

Epoch: 6| Step: 7
Training loss: 2.495600461959839
Validation loss: 2.291743295167082

Epoch: 6| Step: 8
Training loss: 2.2687904834747314
Validation loss: 2.267144690277756

Epoch: 6| Step: 9
Training loss: 2.6870875358581543
Validation loss: 2.2535390033516833

Epoch: 6| Step: 10
Training loss: 2.8040199279785156
Validation loss: 2.233409550882155

Epoch: 6| Step: 11
Training loss: 2.32694149017334
Validation loss: 2.225781533025926

Epoch: 6| Step: 12
Training loss: 2.3632423877716064
Validation loss: 2.213697536017305

Epoch: 6| Step: 13
Training loss: 2.9820749759674072
Validation loss: 2.1984239111664476

Epoch: 50| Step: 0
Training loss: 2.094640016555786
Validation loss: 2.1927311010258173

Epoch: 6| Step: 1
Training loss: 2.649204730987549
Validation loss: 2.195612020390008

Epoch: 6| Step: 2
Training loss: 2.732621669769287
Validation loss: 2.189485211526194

Epoch: 6| Step: 3
Training loss: 3.1632080078125
Validation loss: 2.187381813603063

Epoch: 6| Step: 4
Training loss: 2.9158544540405273
Validation loss: 2.185347746777278

Epoch: 6| Step: 5
Training loss: 2.283215045928955
Validation loss: 2.189061951893632

Epoch: 6| Step: 6
Training loss: 3.3261842727661133
Validation loss: 2.1911010870369534

Epoch: 6| Step: 7
Training loss: 2.235367774963379
Validation loss: 2.1923392024091495

Epoch: 6| Step: 8
Training loss: 2.6850686073303223
Validation loss: 2.1976460308156986

Epoch: 6| Step: 9
Training loss: 2.3585622310638428
Validation loss: 2.199310128406812

Epoch: 6| Step: 10
Training loss: 1.969461441040039
Validation loss: 2.2064627857618433

Epoch: 6| Step: 11
Training loss: 2.4572136402130127
Validation loss: 2.217002966070688

Epoch: 6| Step: 12
Training loss: 2.1985931396484375
Validation loss: 2.21984576922591

Epoch: 6| Step: 13
Training loss: 2.233430862426758
Validation loss: 2.213757264998651

Epoch: 51| Step: 0
Training loss: 3.0675225257873535
Validation loss: 2.1994462936155257

Epoch: 6| Step: 1
Training loss: 2.041611671447754
Validation loss: 2.1912835451864425

Epoch: 6| Step: 2
Training loss: 3.131434917449951
Validation loss: 2.1897408308521396

Epoch: 6| Step: 3
Training loss: 2.0866246223449707
Validation loss: 2.1923698789329937

Epoch: 6| Step: 4
Training loss: 2.6302309036254883
Validation loss: 2.191716840190272

Epoch: 6| Step: 5
Training loss: 2.244884729385376
Validation loss: 2.2004491411229616

Epoch: 6| Step: 6
Training loss: 2.9132394790649414
Validation loss: 2.2063099799617643

Epoch: 6| Step: 7
Training loss: 1.9967657327651978
Validation loss: 2.215632700151013

Epoch: 6| Step: 8
Training loss: 2.8988699913024902
Validation loss: 2.2209092724707817

Epoch: 6| Step: 9
Training loss: 2.9082512855529785
Validation loss: 2.2293020525286273

Epoch: 6| Step: 10
Training loss: 2.8108508586883545
Validation loss: 2.2356394183251167

Epoch: 6| Step: 11
Training loss: 2.2903213500976562
Validation loss: 2.225002255491031

Epoch: 6| Step: 12
Training loss: 2.453646421432495
Validation loss: 2.2178493802265455

Epoch: 6| Step: 13
Training loss: 1.2138724327087402
Validation loss: 2.214694315387357

Epoch: 52| Step: 0
Training loss: 2.178783893585205
Validation loss: 2.203360205055565

Epoch: 6| Step: 1
Training loss: 2.910750150680542
Validation loss: 2.2032149248225714

Epoch: 6| Step: 2
Training loss: 2.035651206970215
Validation loss: 2.2045668402025775

Epoch: 6| Step: 3
Training loss: 2.662269353866577
Validation loss: 2.2084325667350524

Epoch: 6| Step: 4
Training loss: 3.0776185989379883
Validation loss: 2.209568203136485

Epoch: 6| Step: 5
Training loss: 2.438800811767578
Validation loss: 2.20901761516448

Epoch: 6| Step: 6
Training loss: 2.5934526920318604
Validation loss: 2.2080836988264516

Epoch: 6| Step: 7
Training loss: 2.3675801753997803
Validation loss: 2.2014727131012948

Epoch: 6| Step: 8
Training loss: 2.5905401706695557
Validation loss: 2.1922732937720513

Epoch: 6| Step: 9
Training loss: 1.8452208042144775
Validation loss: 2.18642242493168

Epoch: 6| Step: 10
Training loss: 2.889533519744873
Validation loss: 2.181639923844286

Epoch: 6| Step: 11
Training loss: 3.0570321083068848
Validation loss: 2.180534299983773

Epoch: 6| Step: 12
Training loss: 2.017817497253418
Validation loss: 2.1780009884988107

Epoch: 6| Step: 13
Training loss: 2.5858161449432373
Validation loss: 2.1832611727458175

Epoch: 53| Step: 0
Training loss: 1.8257465362548828
Validation loss: 2.1842524928431355

Epoch: 6| Step: 1
Training loss: 2.4126381874084473
Validation loss: 2.193594689010292

Epoch: 6| Step: 2
Training loss: 3.4002115726470947
Validation loss: 2.2063896092035438

Epoch: 6| Step: 3
Training loss: 2.379739761352539
Validation loss: 2.2197168001564602

Epoch: 6| Step: 4
Training loss: 3.0424928665161133
Validation loss: 2.21095379706352

Epoch: 6| Step: 5
Training loss: 1.9035699367523193
Validation loss: 2.20013185726699

Epoch: 6| Step: 6
Training loss: 2.7482032775878906
Validation loss: 2.194490063575006

Epoch: 6| Step: 7
Training loss: 2.7981109619140625
Validation loss: 2.1788080712800384

Epoch: 6| Step: 8
Training loss: 2.5609331130981445
Validation loss: 2.1809728504509054

Epoch: 6| Step: 9
Training loss: 2.885658025741577
Validation loss: 2.1896467208862305

Epoch: 6| Step: 10
Training loss: 1.8702105283737183
Validation loss: 2.2045243324772006

Epoch: 6| Step: 11
Training loss: 2.181077003479004
Validation loss: 2.2406959085054297

Epoch: 6| Step: 12
Training loss: 2.2562808990478516
Validation loss: 2.2742564011645574

Epoch: 6| Step: 13
Training loss: 3.311824083328247
Validation loss: 2.3095612423394316

Epoch: 54| Step: 0
Training loss: 2.1093878746032715
Validation loss: 2.285612767742526

Epoch: 6| Step: 1
Training loss: 2.3756017684936523
Validation loss: 2.2496948908734065

Epoch: 6| Step: 2
Training loss: 2.0674242973327637
Validation loss: 2.224373197042814

Epoch: 6| Step: 3
Training loss: 2.3904216289520264
Validation loss: 2.2222799934366697

Epoch: 6| Step: 4
Training loss: 2.5366744995117188
Validation loss: 2.232053315767678

Epoch: 6| Step: 5
Training loss: 3.3756825923919678
Validation loss: 2.2277176867249193

Epoch: 6| Step: 6
Training loss: 2.186627149581909
Validation loss: 2.2242139923957085

Epoch: 6| Step: 7
Training loss: 2.819478750228882
Validation loss: 2.2339366917969077

Epoch: 6| Step: 8
Training loss: 2.3366920948028564
Validation loss: 2.2436023194302797

Epoch: 6| Step: 9
Training loss: 2.5414280891418457
Validation loss: 2.230467332306729

Epoch: 6| Step: 10
Training loss: 2.9178688526153564
Validation loss: 2.2440058492845103

Epoch: 6| Step: 11
Training loss: 2.0941619873046875
Validation loss: 2.1917688436405633

Epoch: 6| Step: 12
Training loss: 3.029129981994629
Validation loss: 2.173002844215721

Epoch: 6| Step: 13
Training loss: 2.344473123550415
Validation loss: 2.1714296161487536

Epoch: 55| Step: 0
Training loss: 2.0996968746185303
Validation loss: 2.165644876418575

Epoch: 6| Step: 1
Training loss: 1.9035698175430298
Validation loss: 2.1618439356486

Epoch: 6| Step: 2
Training loss: 3.150233268737793
Validation loss: 2.1589993751177223

Epoch: 6| Step: 3
Training loss: 2.6058759689331055
Validation loss: 2.162850473516731

Epoch: 6| Step: 4
Training loss: 2.2224483489990234
Validation loss: 2.176259107487176

Epoch: 6| Step: 5
Training loss: 2.6889350414276123
Validation loss: 2.183215341260356

Epoch: 6| Step: 6
Training loss: 2.7844953536987305
Validation loss: 2.203503885576802

Epoch: 6| Step: 7
Training loss: 1.699597716331482
Validation loss: 2.2273250010705765

Epoch: 6| Step: 8
Training loss: 2.488703966140747
Validation loss: 2.2303822348194737

Epoch: 6| Step: 9
Training loss: 2.6327884197235107
Validation loss: 2.23320278557398

Epoch: 6| Step: 10
Training loss: 3.0213756561279297
Validation loss: 2.216631502233526

Epoch: 6| Step: 11
Training loss: 3.1670010089874268
Validation loss: 2.2467327694739065

Epoch: 6| Step: 12
Training loss: 1.9497781991958618
Validation loss: 2.256056958629239

Epoch: 6| Step: 13
Training loss: 2.7344717979431152
Validation loss: 2.269334686699734

Epoch: 56| Step: 0
Training loss: 2.3351502418518066
Validation loss: 2.281264064132526

Epoch: 6| Step: 1
Training loss: 2.825284242630005
Validation loss: 2.2843158783451205

Epoch: 6| Step: 2
Training loss: 3.2135934829711914
Validation loss: 2.266633879753851

Epoch: 6| Step: 3
Training loss: 2.5451698303222656
Validation loss: 2.2427486476077827

Epoch: 6| Step: 4
Training loss: 3.5247249603271484
Validation loss: 2.220922126564928

Epoch: 6| Step: 5
Training loss: 1.8244695663452148
Validation loss: 2.202022660163141

Epoch: 6| Step: 6
Training loss: 2.308199644088745
Validation loss: 2.1950214447513705

Epoch: 6| Step: 7
Training loss: 2.072511911392212
Validation loss: 2.2180118278790544

Epoch: 6| Step: 8
Training loss: 3.067753791809082
Validation loss: 2.2146231435960337

Epoch: 6| Step: 9
Training loss: 2.4652085304260254
Validation loss: 2.203047921580653

Epoch: 6| Step: 10
Training loss: 2.177250385284424
Validation loss: 2.192456396677161

Epoch: 6| Step: 11
Training loss: 2.1687405109405518
Validation loss: 2.1940052637489895

Epoch: 6| Step: 12
Training loss: 2.4815757274627686
Validation loss: 2.1962348363732778

Epoch: 6| Step: 13
Training loss: 2.2845568656921387
Validation loss: 2.1963004578826246

Epoch: 57| Step: 0
Training loss: 2.3823657035827637
Validation loss: 2.1971483615136917

Epoch: 6| Step: 1
Training loss: 2.4137797355651855
Validation loss: 2.2327968305157078

Epoch: 6| Step: 2
Training loss: 2.850186824798584
Validation loss: 2.2424597727355136

Epoch: 6| Step: 3
Training loss: 2.4682846069335938
Validation loss: 2.2296124478822112

Epoch: 6| Step: 4
Training loss: 1.7511982917785645
Validation loss: 2.2079584752359698

Epoch: 6| Step: 5
Training loss: 2.7661943435668945
Validation loss: 2.214831935462131

Epoch: 6| Step: 6
Training loss: 1.8756457567214966
Validation loss: 2.2122649377392185

Epoch: 6| Step: 7
Training loss: 2.5571208000183105
Validation loss: 2.2321120769746843

Epoch: 6| Step: 8
Training loss: 2.1039137840270996
Validation loss: 2.2661712323465655

Epoch: 6| Step: 9
Training loss: 2.881877899169922
Validation loss: 2.293399759518203

Epoch: 6| Step: 10
Training loss: 2.8806991577148438
Validation loss: 2.316663065264302

Epoch: 6| Step: 11
Training loss: 3.455575704574585
Validation loss: 2.378451837006436

Epoch: 6| Step: 12
Training loss: 2.209028720855713
Validation loss: 2.3871553277456634

Epoch: 6| Step: 13
Training loss: 2.954350471496582
Validation loss: 2.3441618104134836

Epoch: 58| Step: 0
Training loss: 3.055248737335205
Validation loss: 2.2741420807376986

Epoch: 6| Step: 1
Training loss: 1.98024582862854
Validation loss: 2.216801748480848

Epoch: 6| Step: 2
Training loss: 2.3389956951141357
Validation loss: 2.1914735276211976

Epoch: 6| Step: 3
Training loss: 2.7715394496917725
Validation loss: 2.1676664288325975

Epoch: 6| Step: 4
Training loss: 1.6954820156097412
Validation loss: 2.1585214163667414

Epoch: 6| Step: 5
Training loss: 2.006364583969116
Validation loss: 2.1476937211969847

Epoch: 6| Step: 6
Training loss: 3.157259941101074
Validation loss: 2.1430259904553814

Epoch: 6| Step: 7
Training loss: 2.5961179733276367
Validation loss: 2.139599105363251

Epoch: 6| Step: 8
Training loss: 2.242285966873169
Validation loss: 2.1422084198203137

Epoch: 6| Step: 9
Training loss: 2.0683321952819824
Validation loss: 2.1480095335232314

Epoch: 6| Step: 10
Training loss: 3.1008434295654297
Validation loss: 2.1574690393222276

Epoch: 6| Step: 11
Training loss: 2.8671605587005615
Validation loss: 2.1494792148631108

Epoch: 6| Step: 12
Training loss: 2.7258682250976562
Validation loss: 2.148257804173295

Epoch: 6| Step: 13
Training loss: 2.0146687030792236
Validation loss: 2.150165475824828

Epoch: 59| Step: 0
Training loss: 2.545511484146118
Validation loss: 2.146985823108304

Epoch: 6| Step: 1
Training loss: 2.6474359035491943
Validation loss: 2.1474403591566187

Epoch: 6| Step: 2
Training loss: 2.3751895427703857
Validation loss: 2.1668778568185787

Epoch: 6| Step: 3
Training loss: 2.5421299934387207
Validation loss: 2.178141035059447

Epoch: 6| Step: 4
Training loss: 2.3053793907165527
Validation loss: 2.2033375514450895

Epoch: 6| Step: 5
Training loss: 2.0896964073181152
Validation loss: 2.2261545324838288

Epoch: 6| Step: 6
Training loss: 2.7331509590148926
Validation loss: 2.2660457318828953

Epoch: 6| Step: 7
Training loss: 3.1015548706054688
Validation loss: 2.317159560418898

Epoch: 6| Step: 8
Training loss: 2.4221177101135254
Validation loss: 2.335600547893073

Epoch: 6| Step: 9
Training loss: 2.9044623374938965
Validation loss: 2.3435812175914807

Epoch: 6| Step: 10
Training loss: 2.358724594116211
Validation loss: 2.3142963481205765

Epoch: 6| Step: 11
Training loss: 2.1701653003692627
Validation loss: 2.28986071771191

Epoch: 6| Step: 12
Training loss: 2.6828136444091797
Validation loss: 2.2506711060001003

Epoch: 6| Step: 13
Training loss: 1.964942455291748
Validation loss: 2.2378816476432224

Epoch: 60| Step: 0
Training loss: 2.989872932434082
Validation loss: 2.1819272464321506

Epoch: 6| Step: 1
Training loss: 2.2304816246032715
Validation loss: 2.1601370150043118

Epoch: 6| Step: 2
Training loss: 2.7995662689208984
Validation loss: 2.144766351228119

Epoch: 6| Step: 3
Training loss: 3.0373318195343018
Validation loss: 2.1359758171983945

Epoch: 6| Step: 4
Training loss: 2.1685426235198975
Validation loss: 2.1341688556055867

Epoch: 6| Step: 5
Training loss: 2.1186718940734863
Validation loss: 2.1345619886152205

Epoch: 6| Step: 6
Training loss: 2.396787166595459
Validation loss: 2.147304465693812

Epoch: 6| Step: 7
Training loss: 3.121670722961426
Validation loss: 2.151722942629168

Epoch: 6| Step: 8
Training loss: 1.700698733329773
Validation loss: 2.1574780402644986

Epoch: 6| Step: 9
Training loss: 2.7032923698425293
Validation loss: 2.160434648554812

Epoch: 6| Step: 10
Training loss: 2.433204174041748
Validation loss: 2.145154999148461

Epoch: 6| Step: 11
Training loss: 2.2490620613098145
Validation loss: 2.1399996870307514

Epoch: 6| Step: 12
Training loss: 2.4409804344177246
Validation loss: 2.13732381789915

Epoch: 6| Step: 13
Training loss: 2.6881959438323975
Validation loss: 2.128835401227397

Epoch: 61| Step: 0
Training loss: 1.9407930374145508
Validation loss: 2.1298940925187964

Epoch: 6| Step: 1
Training loss: 2.3407740592956543
Validation loss: 2.1348795865171697

Epoch: 6| Step: 2
Training loss: 1.9507241249084473
Validation loss: 2.1330318168927263

Epoch: 6| Step: 3
Training loss: 2.031179904937744
Validation loss: 2.14127262689734

Epoch: 6| Step: 4
Training loss: 2.9107959270477295
Validation loss: 2.179348995608668

Epoch: 6| Step: 5
Training loss: 2.9969186782836914
Validation loss: 2.18964123213163

Epoch: 6| Step: 6
Training loss: 2.5046169757843018
Validation loss: 2.149015090798819

Epoch: 6| Step: 7
Training loss: 2.5175981521606445
Validation loss: 2.1414116736381286

Epoch: 6| Step: 8
Training loss: 2.6693639755249023
Validation loss: 2.1395884893273793

Epoch: 6| Step: 9
Training loss: 3.1278204917907715
Validation loss: 2.1380636384410243

Epoch: 6| Step: 10
Training loss: 2.634471893310547
Validation loss: 2.1325542529424033

Epoch: 6| Step: 11
Training loss: 2.1457154750823975
Validation loss: 2.129760883187735

Epoch: 6| Step: 12
Training loss: 2.2683510780334473
Validation loss: 2.121108744734077

Epoch: 6| Step: 13
Training loss: 3.249499797821045
Validation loss: 2.1350369376520955

Epoch: 62| Step: 0
Training loss: 2.9858016967773438
Validation loss: 2.1261469318020727

Epoch: 6| Step: 1
Training loss: 2.5428197383880615
Validation loss: 2.1489844911841938

Epoch: 6| Step: 2
Training loss: 2.5611019134521484
Validation loss: 2.1565053334800144

Epoch: 6| Step: 3
Training loss: 1.6137809753417969
Validation loss: 2.168383188145135

Epoch: 6| Step: 4
Training loss: 1.887312650680542
Validation loss: 2.1681628022142636

Epoch: 6| Step: 5
Training loss: 3.2946932315826416
Validation loss: 2.153326451137502

Epoch: 6| Step: 6
Training loss: 2.831541061401367
Validation loss: 2.1452422859848186

Epoch: 6| Step: 7
Training loss: 1.9292985200881958
Validation loss: 2.1307292343467794

Epoch: 6| Step: 8
Training loss: 2.826265811920166
Validation loss: 2.134678579145862

Epoch: 6| Step: 9
Training loss: 2.674751043319702
Validation loss: 2.1334798336029053

Epoch: 6| Step: 10
Training loss: 2.794309616088867
Validation loss: 2.1355655142056045

Epoch: 6| Step: 11
Training loss: 2.3406505584716797
Validation loss: 2.15174578338541

Epoch: 6| Step: 12
Training loss: 2.2291581630706787
Validation loss: 2.171911111441992

Epoch: 6| Step: 13
Training loss: 1.6439411640167236
Validation loss: 2.2191043156449513

Epoch: 63| Step: 0
Training loss: 2.8910210132598877
Validation loss: 2.2688075316849576

Epoch: 6| Step: 1
Training loss: 2.8182170391082764
Validation loss: 2.248604195092314

Epoch: 6| Step: 2
Training loss: 3.064605236053467
Validation loss: 2.216634340183709

Epoch: 6| Step: 3
Training loss: 2.323533535003662
Validation loss: 2.1685320997750885

Epoch: 6| Step: 4
Training loss: 2.908933162689209
Validation loss: 2.1389783223470054

Epoch: 6| Step: 5
Training loss: 2.0517401695251465
Validation loss: 2.1203521579824467

Epoch: 6| Step: 6
Training loss: 2.6724724769592285
Validation loss: 2.121379536967124

Epoch: 6| Step: 7
Training loss: 2.7163033485412598
Validation loss: 2.111724166459935

Epoch: 6| Step: 8
Training loss: 1.8813667297363281
Validation loss: 2.1160325619482223

Epoch: 6| Step: 9
Training loss: 2.2692677974700928
Validation loss: 2.1113763291348695

Epoch: 6| Step: 10
Training loss: 2.6920242309570312
Validation loss: 2.111297289530436

Epoch: 6| Step: 11
Training loss: 2.0263805389404297
Validation loss: 2.1090472975084857

Epoch: 6| Step: 12
Training loss: 1.9667514562606812
Validation loss: 2.1106476835025254

Epoch: 6| Step: 13
Training loss: 2.546426296234131
Validation loss: 2.1116341249917143

Epoch: 64| Step: 0
Training loss: 2.6598596572875977
Validation loss: 2.1220028938785678

Epoch: 6| Step: 1
Training loss: 2.9423696994781494
Validation loss: 2.1290386953661518

Epoch: 6| Step: 2
Training loss: 2.4885354042053223
Validation loss: 2.1413342081090456

Epoch: 6| Step: 3
Training loss: 2.7047033309936523
Validation loss: 2.1600138218172136

Epoch: 6| Step: 4
Training loss: 2.8608531951904297
Validation loss: 2.175784352005169

Epoch: 6| Step: 5
Training loss: 1.8464539051055908
Validation loss: 2.180977398349393

Epoch: 6| Step: 6
Training loss: 2.769972085952759
Validation loss: 2.216595903519661

Epoch: 6| Step: 7
Training loss: 2.4408457279205322
Validation loss: 2.2460682033210673

Epoch: 6| Step: 8
Training loss: 2.2444887161254883
Validation loss: 2.296155801383398

Epoch: 6| Step: 9
Training loss: 2.231039047241211
Validation loss: 2.317599824679795

Epoch: 6| Step: 10
Training loss: 2.4687395095825195
Validation loss: 2.3039286572446107

Epoch: 6| Step: 11
Training loss: 2.6210083961486816
Validation loss: 2.230693858156922

Epoch: 6| Step: 12
Training loss: 2.063690423965454
Validation loss: 2.185441135078348

Epoch: 6| Step: 13
Training loss: 2.0477800369262695
Validation loss: 2.1463682882247435

Epoch: 65| Step: 0
Training loss: 2.1576738357543945
Validation loss: 2.123941416381508

Epoch: 6| Step: 1
Training loss: 3.0854499340057373
Validation loss: 2.1163030209079867

Epoch: 6| Step: 2
Training loss: 2.119776487350464
Validation loss: 2.119299013127563

Epoch: 6| Step: 3
Training loss: 2.6693830490112305
Validation loss: 2.1224283672148183

Epoch: 6| Step: 4
Training loss: 2.5297396183013916
Validation loss: 2.1357469943261917

Epoch: 6| Step: 5
Training loss: 2.3359880447387695
Validation loss: 2.1302888175492645

Epoch: 6| Step: 6
Training loss: 3.057180166244507
Validation loss: 2.1509257670371764

Epoch: 6| Step: 7
Training loss: 1.8476824760437012
Validation loss: 2.1486948420924525

Epoch: 6| Step: 8
Training loss: 2.4055328369140625
Validation loss: 2.171678602054555

Epoch: 6| Step: 9
Training loss: 2.6021664142608643
Validation loss: 2.1876678415524062

Epoch: 6| Step: 10
Training loss: 2.7196145057678223
Validation loss: 2.176208069247584

Epoch: 6| Step: 11
Training loss: 2.4286749362945557
Validation loss: 2.147500104801629

Epoch: 6| Step: 12
Training loss: 2.2495832443237305
Validation loss: 2.136532293852939

Epoch: 6| Step: 13
Training loss: 2.0950980186462402
Validation loss: 2.1192115737545874

Epoch: 66| Step: 0
Training loss: 2.724792003631592
Validation loss: 2.1134280543173514

Epoch: 6| Step: 1
Training loss: 2.620912551879883
Validation loss: 2.111416111710251

Epoch: 6| Step: 2
Training loss: 2.269056797027588
Validation loss: 2.1133911635286067

Epoch: 6| Step: 3
Training loss: 3.053455114364624
Validation loss: 2.1121925589858845

Epoch: 6| Step: 4
Training loss: 2.342210292816162
Validation loss: 2.113022247950236

Epoch: 6| Step: 5
Training loss: 3.0279221534729004
Validation loss: 2.107608543929233

Epoch: 6| Step: 6
Training loss: 2.31301212310791
Validation loss: 2.1131428390420894

Epoch: 6| Step: 7
Training loss: 2.430537223815918
Validation loss: 2.114303554258039

Epoch: 6| Step: 8
Training loss: 2.2101426124572754
Validation loss: 2.115957252440914

Epoch: 6| Step: 9
Training loss: 1.9353752136230469
Validation loss: 2.1128094529592865

Epoch: 6| Step: 10
Training loss: 2.6794657707214355
Validation loss: 2.1136245855721096

Epoch: 6| Step: 11
Training loss: 2.407201051712036
Validation loss: 2.111952962413911

Epoch: 6| Step: 12
Training loss: 2.3870201110839844
Validation loss: 2.1078394856504215

Epoch: 6| Step: 13
Training loss: 1.7481837272644043
Validation loss: 2.1078869937568583

Epoch: 67| Step: 0
Training loss: 2.1746878623962402
Validation loss: 2.1127910947286956

Epoch: 6| Step: 1
Training loss: 2.3885207176208496
Validation loss: 2.114521018920406

Epoch: 6| Step: 2
Training loss: 2.3229446411132812
Validation loss: 2.1215714344414334

Epoch: 6| Step: 3
Training loss: 3.002466917037964
Validation loss: 2.1212863793937107

Epoch: 6| Step: 4
Training loss: 2.0249688625335693
Validation loss: 2.1299916005903676

Epoch: 6| Step: 5
Training loss: 3.023503065109253
Validation loss: 2.1199759898647184

Epoch: 6| Step: 6
Training loss: 2.071704626083374
Validation loss: 2.1107396361648396

Epoch: 6| Step: 7
Training loss: 2.5039916038513184
Validation loss: 2.1100725896896853

Epoch: 6| Step: 8
Training loss: 2.3563015460968018
Validation loss: 2.0989482248983076

Epoch: 6| Step: 9
Training loss: 2.5987465381622314
Validation loss: 2.0924304428920952

Epoch: 6| Step: 10
Training loss: 2.5630099773406982
Validation loss: 2.089587137263308

Epoch: 6| Step: 11
Training loss: 2.664130687713623
Validation loss: 2.0881142436817126

Epoch: 6| Step: 12
Training loss: 2.3996622562408447
Validation loss: 2.0901192349772297

Epoch: 6| Step: 13
Training loss: 2.002157211303711
Validation loss: 2.097445409785035

Epoch: 68| Step: 0
Training loss: 2.673391342163086
Validation loss: 2.097674838958248

Epoch: 6| Step: 1
Training loss: 2.085911750793457
Validation loss: 2.1056649633633193

Epoch: 6| Step: 2
Training loss: 2.3633570671081543
Validation loss: 2.1201643277240056

Epoch: 6| Step: 3
Training loss: 1.4186779260635376
Validation loss: 2.1309934534052366

Epoch: 6| Step: 4
Training loss: 2.4275519847869873
Validation loss: 2.158663979140661

Epoch: 6| Step: 5
Training loss: 2.0381877422332764
Validation loss: 2.153599205837455

Epoch: 6| Step: 6
Training loss: 2.0215988159179688
Validation loss: 2.1816596600317184

Epoch: 6| Step: 7
Training loss: 2.5150115489959717
Validation loss: 2.2433014762017036

Epoch: 6| Step: 8
Training loss: 2.694192409515381
Validation loss: 2.254420406074934

Epoch: 6| Step: 9
Training loss: 3.480013370513916
Validation loss: 2.213053987872216

Epoch: 6| Step: 10
Training loss: 3.242499828338623
Validation loss: 2.175726403472244

Epoch: 6| Step: 11
Training loss: 2.499803066253662
Validation loss: 2.1605933045828216

Epoch: 6| Step: 12
Training loss: 2.218529224395752
Validation loss: 2.120311620414898

Epoch: 6| Step: 13
Training loss: 3.170253038406372
Validation loss: 2.104273606372136

Epoch: 69| Step: 0
Training loss: 2.2144365310668945
Validation loss: 2.093189162592734

Epoch: 6| Step: 1
Training loss: 2.3929343223571777
Validation loss: 2.103520865081459

Epoch: 6| Step: 2
Training loss: 2.3897173404693604
Validation loss: 2.1148865761295443

Epoch: 6| Step: 3
Training loss: 2.22396183013916
Validation loss: 2.1199560857588247

Epoch: 6| Step: 4
Training loss: 2.902048110961914
Validation loss: 2.1285938729522047

Epoch: 6| Step: 5
Training loss: 1.742608666419983
Validation loss: 2.131734114821239

Epoch: 6| Step: 6
Training loss: 2.919886589050293
Validation loss: 2.1307541875429052

Epoch: 6| Step: 7
Training loss: 3.3492918014526367
Validation loss: 2.1339548275034916

Epoch: 6| Step: 8
Training loss: 2.5584332942962646
Validation loss: 2.121020301695793

Epoch: 6| Step: 9
Training loss: 2.366281509399414
Validation loss: 2.1037318155329716

Epoch: 6| Step: 10
Training loss: 1.8263235092163086
Validation loss: 2.0961018557189615

Epoch: 6| Step: 11
Training loss: 2.264822006225586
Validation loss: 2.0946871106342604

Epoch: 6| Step: 12
Training loss: 2.6739020347595215
Validation loss: 2.103956058461179

Epoch: 6| Step: 13
Training loss: 2.318202495574951
Validation loss: 2.101956836638912

Epoch: 70| Step: 0
Training loss: 2.614931344985962
Validation loss: 2.099881979726976

Epoch: 6| Step: 1
Training loss: 2.412649393081665
Validation loss: 2.0959876045103996

Epoch: 6| Step: 2
Training loss: 2.554192543029785
Validation loss: 2.0887228186412523

Epoch: 6| Step: 3
Training loss: 2.895329236984253
Validation loss: 2.0820432016926427

Epoch: 6| Step: 4
Training loss: 2.0986719131469727
Validation loss: 2.078512801918932

Epoch: 6| Step: 5
Training loss: 2.0561296939849854
Validation loss: 2.0903238840000604

Epoch: 6| Step: 6
Training loss: 2.308302879333496
Validation loss: 2.0841923477829143

Epoch: 6| Step: 7
Training loss: 2.891873359680176
Validation loss: 2.092203635041432

Epoch: 6| Step: 8
Training loss: 2.4825310707092285
Validation loss: 2.0861913619502896

Epoch: 6| Step: 9
Training loss: 2.2435238361358643
Validation loss: 2.1061425516682286

Epoch: 6| Step: 10
Training loss: 1.920710802078247
Validation loss: 2.138833874015398

Epoch: 6| Step: 11
Training loss: 2.980623245239258
Validation loss: 2.1748409758331957

Epoch: 6| Step: 12
Training loss: 2.0687685012817383
Validation loss: 2.184885791552964

Epoch: 6| Step: 13
Training loss: 3.0084645748138428
Validation loss: 2.1845681833964523

Epoch: 71| Step: 0
Training loss: 1.8104190826416016
Validation loss: 2.1884982150088073

Epoch: 6| Step: 1
Training loss: 2.4206795692443848
Validation loss: 2.1858804713013353

Epoch: 6| Step: 2
Training loss: 3.6796040534973145
Validation loss: 2.1569774830213158

Epoch: 6| Step: 3
Training loss: 2.4973089694976807
Validation loss: 2.101265711169089

Epoch: 6| Step: 4
Training loss: 2.5776095390319824
Validation loss: 2.085240646075177

Epoch: 6| Step: 5
Training loss: 2.0585880279541016
Validation loss: 2.07950545126392

Epoch: 6| Step: 6
Training loss: 2.4110336303710938
Validation loss: 2.091596636720883

Epoch: 6| Step: 7
Training loss: 2.709743022918701
Validation loss: 2.1063984696583082

Epoch: 6| Step: 8
Training loss: 2.2173290252685547
Validation loss: 2.118617093691262

Epoch: 6| Step: 9
Training loss: 2.496549606323242
Validation loss: 2.140220998435892

Epoch: 6| Step: 10
Training loss: 2.3391547203063965
Validation loss: 2.1698612295171267

Epoch: 6| Step: 11
Training loss: 2.805128574371338
Validation loss: 2.170837772789822

Epoch: 6| Step: 12
Training loss: 2.330254554748535
Validation loss: 2.179738281875528

Epoch: 6| Step: 13
Training loss: 2.4594569206237793
Validation loss: 2.2316585099825295

Epoch: 72| Step: 0
Training loss: 2.1899261474609375
Validation loss: 2.2859369170281196

Epoch: 6| Step: 1
Training loss: 2.8770148754119873
Validation loss: 2.325089758442294

Epoch: 6| Step: 2
Training loss: 2.91988205909729
Validation loss: 2.4333144157163558

Epoch: 6| Step: 3
Training loss: 2.345465660095215
Validation loss: 2.3180526533434467

Epoch: 6| Step: 4
Training loss: 2.28544545173645
Validation loss: 2.216548435149654

Epoch: 6| Step: 5
Training loss: 2.4530396461486816
Validation loss: 2.154263050325455

Epoch: 6| Step: 6
Training loss: 2.5377659797668457
Validation loss: 2.1305315955992667

Epoch: 6| Step: 7
Training loss: 2.8415958881378174
Validation loss: 2.118473268324329

Epoch: 6| Step: 8
Training loss: 2.369198799133301
Validation loss: 2.1125291957650134

Epoch: 6| Step: 9
Training loss: 2.282646417617798
Validation loss: 2.108853405521762

Epoch: 6| Step: 10
Training loss: 2.0500285625457764
Validation loss: 2.114237149556478

Epoch: 6| Step: 11
Training loss: 2.0765812397003174
Validation loss: 2.130389919845007

Epoch: 6| Step: 12
Training loss: 3.0576071739196777
Validation loss: 2.1393765403378393

Epoch: 6| Step: 13
Training loss: 2.4428224563598633
Validation loss: 2.148078464692639

Epoch: 73| Step: 0
Training loss: 1.917754888534546
Validation loss: 2.163785748584296

Epoch: 6| Step: 1
Training loss: 2.566455841064453
Validation loss: 2.161832394138459

Epoch: 6| Step: 2
Training loss: 3.3214833736419678
Validation loss: 2.171362784601027

Epoch: 6| Step: 3
Training loss: 2.1784801483154297
Validation loss: 2.1335522333780923

Epoch: 6| Step: 4
Training loss: 2.5891261100769043
Validation loss: 2.115890449093234

Epoch: 6| Step: 5
Training loss: 2.0428690910339355
Validation loss: 2.089738990670891

Epoch: 6| Step: 6
Training loss: 2.501232862472534
Validation loss: 2.087053014386085

Epoch: 6| Step: 7
Training loss: 2.349534511566162
Validation loss: 2.0762424007538827

Epoch: 6| Step: 8
Training loss: 2.247626781463623
Validation loss: 2.0798003699189875

Epoch: 6| Step: 9
Training loss: 2.0499396324157715
Validation loss: 2.084733598975725

Epoch: 6| Step: 10
Training loss: 2.4918222427368164
Validation loss: 2.0707761446634927

Epoch: 6| Step: 11
Training loss: 2.7077314853668213
Validation loss: 2.0748603907964562

Epoch: 6| Step: 12
Training loss: 2.853691816329956
Validation loss: 2.0772413976730837

Epoch: 6| Step: 13
Training loss: 2.4529521465301514
Validation loss: 2.090252673754128

Epoch: 74| Step: 0
Training loss: 2.4369287490844727
Validation loss: 2.0991491925331855

Epoch: 6| Step: 1
Training loss: 2.047863245010376
Validation loss: 2.109648378946448

Epoch: 6| Step: 2
Training loss: 2.905177116394043
Validation loss: 2.1203546254865584

Epoch: 6| Step: 3
Training loss: 2.519008159637451
Validation loss: 2.1169060378946285

Epoch: 6| Step: 4
Training loss: 2.036508321762085
Validation loss: 2.12069369387883

Epoch: 6| Step: 5
Training loss: 3.0859179496765137
Validation loss: 2.1188613881347

Epoch: 6| Step: 6
Training loss: 2.1163558959960938
Validation loss: 2.1260848993896158

Epoch: 6| Step: 7
Training loss: 2.6750407218933105
Validation loss: 2.1136798653551327

Epoch: 6| Step: 8
Training loss: 1.9712116718292236
Validation loss: 2.0979434738877

Epoch: 6| Step: 9
Training loss: 1.691572904586792
Validation loss: 2.0756196334797847

Epoch: 6| Step: 10
Training loss: 2.6332080364227295
Validation loss: 2.0746242718030046

Epoch: 6| Step: 11
Training loss: 2.713759422302246
Validation loss: 2.072047072072183

Epoch: 6| Step: 12
Training loss: 2.610259771347046
Validation loss: 2.0683666429212018

Epoch: 6| Step: 13
Training loss: 2.387643337249756
Validation loss: 2.075070542673911

Epoch: 75| Step: 0
Training loss: 1.9638030529022217
Validation loss: 2.0785934155987156

Epoch: 6| Step: 1
Training loss: 2.3119609355926514
Validation loss: 2.0796778202056885

Epoch: 6| Step: 2
Training loss: 2.1970715522766113
Validation loss: 2.0749393534916702

Epoch: 6| Step: 3
Training loss: 2.4146223068237305
Validation loss: 2.085945552395236

Epoch: 6| Step: 4
Training loss: 2.3052031993865967
Validation loss: 2.087834422306348

Epoch: 6| Step: 5
Training loss: 2.750424861907959
Validation loss: 2.1112401959716633

Epoch: 6| Step: 6
Training loss: 2.715705394744873
Validation loss: 2.123148073432266

Epoch: 6| Step: 7
Training loss: 2.7551827430725098
Validation loss: 2.129413672672805

Epoch: 6| Step: 8
Training loss: 1.9251041412353516
Validation loss: 2.1405188704049714

Epoch: 6| Step: 9
Training loss: 2.543285369873047
Validation loss: 2.1694073984699864

Epoch: 6| Step: 10
Training loss: 2.558119773864746
Validation loss: 2.194491720968677

Epoch: 6| Step: 11
Training loss: 2.8030824661254883
Validation loss: 2.2437942104954876

Epoch: 6| Step: 12
Training loss: 2.193876028060913
Validation loss: 2.2182744574803177

Epoch: 6| Step: 13
Training loss: 2.849849224090576
Validation loss: 2.2000510000413462

Epoch: 76| Step: 0
Training loss: 1.8159568309783936
Validation loss: 2.164365468486663

Epoch: 6| Step: 1
Training loss: 2.5518574714660645
Validation loss: 2.1126500688573366

Epoch: 6| Step: 2
Training loss: 2.7707936763763428
Validation loss: 2.102179201700354

Epoch: 6| Step: 3
Training loss: 2.790940761566162
Validation loss: 2.0882252121484406

Epoch: 6| Step: 4
Training loss: 1.830306053161621
Validation loss: 2.0757471797286824

Epoch: 6| Step: 5
Training loss: 2.2472567558288574
Validation loss: 2.069604915957297

Epoch: 6| Step: 6
Training loss: 2.287266254425049
Validation loss: 2.061321887918698

Epoch: 6| Step: 7
Training loss: 2.2783751487731934
Validation loss: 2.062466504753277

Epoch: 6| Step: 8
Training loss: 2.553267002105713
Validation loss: 2.0595781213493756

Epoch: 6| Step: 9
Training loss: 2.5856120586395264
Validation loss: 2.058789001998081

Epoch: 6| Step: 10
Training loss: 2.5873894691467285
Validation loss: 2.0589717716299076

Epoch: 6| Step: 11
Training loss: 2.7749857902526855
Validation loss: 2.061431274619154

Epoch: 6| Step: 12
Training loss: 2.2861456871032715
Validation loss: 2.058659036954244

Epoch: 6| Step: 13
Training loss: 2.6380362510681152
Validation loss: 2.0685067728001583

Epoch: 77| Step: 0
Training loss: 2.5975542068481445
Validation loss: 2.074194936342137

Epoch: 6| Step: 1
Training loss: 2.8559060096740723
Validation loss: 2.0842093677930933

Epoch: 6| Step: 2
Training loss: 2.1515350341796875
Validation loss: 2.0975642435012327

Epoch: 6| Step: 3
Training loss: 2.982922077178955
Validation loss: 2.102034407277261

Epoch: 6| Step: 4
Training loss: 2.71049427986145
Validation loss: 2.1020999980229202

Epoch: 6| Step: 5
Training loss: 1.8999314308166504
Validation loss: 2.1146345984551216

Epoch: 6| Step: 6
Training loss: 2.8533213138580322
Validation loss: 2.1019926763349965

Epoch: 6| Step: 7
Training loss: 1.9374300241470337
Validation loss: 2.1180059909820557

Epoch: 6| Step: 8
Training loss: 1.4143097400665283
Validation loss: 2.116550412229312

Epoch: 6| Step: 9
Training loss: 1.8079771995544434
Validation loss: 2.1172086167079147

Epoch: 6| Step: 10
Training loss: 2.5761852264404297
Validation loss: 2.118571169914738

Epoch: 6| Step: 11
Training loss: 2.402022361755371
Validation loss: 2.1125754310238745

Epoch: 6| Step: 12
Training loss: 2.5245633125305176
Validation loss: 2.110022432060652

Epoch: 6| Step: 13
Training loss: 3.1815783977508545
Validation loss: 2.1015839833085255

Epoch: 78| Step: 0
Training loss: 2.784214496612549
Validation loss: 2.0860509193071755

Epoch: 6| Step: 1
Training loss: 2.633474588394165
Validation loss: 2.0764431748338925

Epoch: 6| Step: 2
Training loss: 3.150860548019409
Validation loss: 2.0594705522701306

Epoch: 6| Step: 3
Training loss: 2.707925796508789
Validation loss: 2.0568769413937806

Epoch: 6| Step: 4
Training loss: 2.201343059539795
Validation loss: 2.050829102916102

Epoch: 6| Step: 5
Training loss: 2.00703763961792
Validation loss: 2.0512432770062516

Epoch: 6| Step: 6
Training loss: 2.3678619861602783
Validation loss: 2.047831896812685

Epoch: 6| Step: 7
Training loss: 2.1590309143066406
Validation loss: 2.0491627877758396

Epoch: 6| Step: 8
Training loss: 1.6132198572158813
Validation loss: 2.061436676209973

Epoch: 6| Step: 9
Training loss: 1.8041061162948608
Validation loss: 2.078369371352657

Epoch: 6| Step: 10
Training loss: 2.287590503692627
Validation loss: 2.096705945589209

Epoch: 6| Step: 11
Training loss: 2.862243890762329
Validation loss: 2.115921364035658

Epoch: 6| Step: 12
Training loss: 2.2867860794067383
Validation loss: 2.1423643583892495

Epoch: 6| Step: 13
Training loss: 2.9558961391448975
Validation loss: 2.1573471100099626

Epoch: 79| Step: 0
Training loss: 2.685664653778076
Validation loss: 2.1982613225137033

Epoch: 6| Step: 1
Training loss: 2.4953742027282715
Validation loss: 2.215037889378045

Epoch: 6| Step: 2
Training loss: 2.68839693069458
Validation loss: 2.185964374132054

Epoch: 6| Step: 3
Training loss: 2.701256036758423
Validation loss: 2.185513732253864

Epoch: 6| Step: 4
Training loss: 2.525158405303955
Validation loss: 2.1552462347092165

Epoch: 6| Step: 5
Training loss: 2.658353567123413
Validation loss: 2.1467117596698064

Epoch: 6| Step: 6
Training loss: 2.897665500640869
Validation loss: 2.099134014498803

Epoch: 6| Step: 7
Training loss: 2.094454050064087
Validation loss: 2.091386710443804

Epoch: 6| Step: 8
Training loss: 2.1253662109375
Validation loss: 2.0785172382990518

Epoch: 6| Step: 9
Training loss: 1.9349654912948608
Validation loss: 2.0677143360978816

Epoch: 6| Step: 10
Training loss: 2.1299891471862793
Validation loss: 2.062151085945868

Epoch: 6| Step: 11
Training loss: 2.1808996200561523
Validation loss: 2.0617027923625004

Epoch: 6| Step: 12
Training loss: 2.2866482734680176
Validation loss: 2.0556270537837857

Epoch: 6| Step: 13
Training loss: 2.0223824977874756
Validation loss: 2.051913804905389

Epoch: 80| Step: 0
Training loss: 2.942711353302002
Validation loss: 2.0612828808446086

Epoch: 6| Step: 1
Training loss: 2.5943210124969482
Validation loss: 2.0648802044571086

Epoch: 6| Step: 2
Training loss: 2.74232816696167
Validation loss: 2.065455513615762

Epoch: 6| Step: 3
Training loss: 1.8056986331939697
Validation loss: 2.0643209565070366

Epoch: 6| Step: 4
Training loss: 2.415160655975342
Validation loss: 2.0698921257449734

Epoch: 6| Step: 5
Training loss: 1.9301297664642334
Validation loss: 2.079684384407536

Epoch: 6| Step: 6
Training loss: 2.3597187995910645
Validation loss: 2.077096608377272

Epoch: 6| Step: 7
Training loss: 1.5716580152511597
Validation loss: 2.0649619461387716

Epoch: 6| Step: 8
Training loss: 2.2511324882507324
Validation loss: 2.0630874774789296

Epoch: 6| Step: 9
Training loss: 2.636348247528076
Validation loss: 2.0633450015898673

Epoch: 6| Step: 10
Training loss: 1.7135200500488281
Validation loss: 2.0652340945377143

Epoch: 6| Step: 11
Training loss: 2.5346031188964844
Validation loss: 2.0557075674815843

Epoch: 6| Step: 12
Training loss: 3.3686270713806152
Validation loss: 2.0506826075174476

Epoch: 6| Step: 13
Training loss: 2.697779655456543
Validation loss: 2.052406705835814

Epoch: 81| Step: 0
Training loss: 2.348228931427002
Validation loss: 2.0448725966997046

Epoch: 6| Step: 1
Training loss: 2.478541612625122
Validation loss: 2.0537046540168022

Epoch: 6| Step: 2
Training loss: 2.706728458404541
Validation loss: 2.0763209353211107

Epoch: 6| Step: 3
Training loss: 2.6041951179504395
Validation loss: 2.0701450840119393

Epoch: 6| Step: 4
Training loss: 2.0275890827178955
Validation loss: 2.0776746119222333

Epoch: 6| Step: 5
Training loss: 2.331934928894043
Validation loss: 2.085930011605704

Epoch: 6| Step: 6
Training loss: 2.2620136737823486
Validation loss: 2.110790078357984

Epoch: 6| Step: 7
Training loss: 1.9848672151565552
Validation loss: 2.1358968750123055

Epoch: 6| Step: 8
Training loss: 1.791938066482544
Validation loss: 2.139496736629035

Epoch: 6| Step: 9
Training loss: 2.8401553630828857
Validation loss: 2.145050620519987

Epoch: 6| Step: 10
Training loss: 2.8431899547576904
Validation loss: 2.144212847114891

Epoch: 6| Step: 11
Training loss: 1.931735873222351
Validation loss: 2.1474088597041305

Epoch: 6| Step: 12
Training loss: 2.25923752784729
Validation loss: 2.1423978087722615

Epoch: 6| Step: 13
Training loss: 3.261303424835205
Validation loss: 2.145953380933372

Epoch: 82| Step: 0
Training loss: 2.7316625118255615
Validation loss: 2.158238367367816

Epoch: 6| Step: 1
Training loss: 2.3662428855895996
Validation loss: 2.176671960020578

Epoch: 6| Step: 2
Training loss: 2.2597622871398926
Validation loss: 2.220147023918808

Epoch: 6| Step: 3
Training loss: 2.0443766117095947
Validation loss: 2.1949565705432685

Epoch: 6| Step: 4
Training loss: 1.8930399417877197
Validation loss: 2.2013157054942143

Epoch: 6| Step: 5
Training loss: 1.7909252643585205
Validation loss: 2.1733550743390153

Epoch: 6| Step: 6
Training loss: 3.140821933746338
Validation loss: 2.1741773108000397

Epoch: 6| Step: 7
Training loss: 2.9685540199279785
Validation loss: 2.1329010609657533

Epoch: 6| Step: 8
Training loss: 1.8706516027450562
Validation loss: 2.120484303402644

Epoch: 6| Step: 9
Training loss: 2.924743175506592
Validation loss: 2.0937078909207414

Epoch: 6| Step: 10
Training loss: 2.438974380493164
Validation loss: 2.0905854189267723

Epoch: 6| Step: 11
Training loss: 2.2508747577667236
Validation loss: 2.080327092960317

Epoch: 6| Step: 12
Training loss: 2.124574899673462
Validation loss: 2.0718479489767425

Epoch: 6| Step: 13
Training loss: 2.98726749420166
Validation loss: 2.0438812407114173

Epoch: 83| Step: 0
Training loss: 3.018751621246338
Validation loss: 2.042439760700349

Epoch: 6| Step: 1
Training loss: 2.1828460693359375
Validation loss: 2.0385312367511053

Epoch: 6| Step: 2
Training loss: 2.1988253593444824
Validation loss: 2.045559169143759

Epoch: 6| Step: 3
Training loss: 2.223135471343994
Validation loss: 2.0457664074436313

Epoch: 6| Step: 4
Training loss: 2.3229482173919678
Validation loss: 2.0574358791433354

Epoch: 6| Step: 5
Training loss: 1.92388916015625
Validation loss: 2.0567857526963755

Epoch: 6| Step: 6
Training loss: 2.010108232498169
Validation loss: 2.0631182014301257

Epoch: 6| Step: 7
Training loss: 2.2440521717071533
Validation loss: 2.060602536765478

Epoch: 6| Step: 8
Training loss: 2.665712356567383
Validation loss: 2.068532710434288

Epoch: 6| Step: 9
Training loss: 2.438235282897949
Validation loss: 2.0854764625590336

Epoch: 6| Step: 10
Training loss: 2.227611541748047
Validation loss: 2.096992410639281

Epoch: 6| Step: 11
Training loss: 3.009406328201294
Validation loss: 2.0991196452930407

Epoch: 6| Step: 12
Training loss: 2.5820045471191406
Validation loss: 2.110674479956268

Epoch: 6| Step: 13
Training loss: 2.2094860076904297
Validation loss: 2.1300475238471903

Epoch: 84| Step: 0
Training loss: 1.8073534965515137
Validation loss: 2.1053958964604202

Epoch: 6| Step: 1
Training loss: 2.280083179473877
Validation loss: 2.085347108943488

Epoch: 6| Step: 2
Training loss: 2.5668349266052246
Validation loss: 2.0718030980838242

Epoch: 6| Step: 3
Training loss: 2.231106758117676
Validation loss: 2.050278763617239

Epoch: 6| Step: 4
Training loss: 1.6566615104675293
Validation loss: 2.0374797146807433

Epoch: 6| Step: 5
Training loss: 2.838465690612793
Validation loss: 2.033605396106679

Epoch: 6| Step: 6
Training loss: 2.332470417022705
Validation loss: 2.024552204275644

Epoch: 6| Step: 7
Training loss: 3.4090795516967773
Validation loss: 2.0193353109462286

Epoch: 6| Step: 8
Training loss: 2.216071128845215
Validation loss: 2.0236596445883475

Epoch: 6| Step: 9
Training loss: 2.2333264350891113
Validation loss: 2.0336711765617452

Epoch: 6| Step: 10
Training loss: 2.4793877601623535
Validation loss: 2.048170519131486

Epoch: 6| Step: 11
Training loss: 2.058570384979248
Validation loss: 2.055629550769765

Epoch: 6| Step: 12
Training loss: 2.8001627922058105
Validation loss: 2.095315925536617

Epoch: 6| Step: 13
Training loss: 2.518894672393799
Validation loss: 2.120892918238076

Epoch: 85| Step: 0
Training loss: 2.3592209815979004
Validation loss: 2.09152978210039

Epoch: 6| Step: 1
Training loss: 1.641249179840088
Validation loss: 2.082656370696201

Epoch: 6| Step: 2
Training loss: 2.73746919631958
Validation loss: 2.075309948254657

Epoch: 6| Step: 3
Training loss: 1.517071008682251
Validation loss: 2.052695897317702

Epoch: 6| Step: 4
Training loss: 3.0511770248413086
Validation loss: 2.059996215246057

Epoch: 6| Step: 5
Training loss: 2.10817813873291
Validation loss: 2.062207224548504

Epoch: 6| Step: 6
Training loss: 2.644594430923462
Validation loss: 2.054483225268702

Epoch: 6| Step: 7
Training loss: 2.202181100845337
Validation loss: 2.0487016208710207

Epoch: 6| Step: 8
Training loss: 2.5117695331573486
Validation loss: 2.0522790647322133

Epoch: 6| Step: 9
Training loss: 2.5442399978637695
Validation loss: 2.0628941187294583

Epoch: 6| Step: 10
Training loss: 2.33627986907959
Validation loss: 2.051782573423078

Epoch: 6| Step: 11
Training loss: 2.6958096027374268
Validation loss: 2.0512675521194295

Epoch: 6| Step: 12
Training loss: 2.474614143371582
Validation loss: 2.0516147434070544

Epoch: 6| Step: 13
Training loss: 1.7659955024719238
Validation loss: 2.0378190343097975

Epoch: 86| Step: 0
Training loss: 2.3943333625793457
Validation loss: 2.0449239925671647

Epoch: 6| Step: 1
Training loss: 2.3784847259521484
Validation loss: 2.0464288034746723

Epoch: 6| Step: 2
Training loss: 2.2125110626220703
Validation loss: 2.07517243969825

Epoch: 6| Step: 3
Training loss: 2.6244864463806152
Validation loss: 2.0690892819435365

Epoch: 6| Step: 4
Training loss: 1.943312644958496
Validation loss: 2.097106779775312

Epoch: 6| Step: 5
Training loss: 2.2260055541992188
Validation loss: 2.0901314417521157

Epoch: 6| Step: 6
Training loss: 2.250293731689453
Validation loss: 2.0807562797300276

Epoch: 6| Step: 7
Training loss: 2.2768630981445312
Validation loss: 2.0677647462455173

Epoch: 6| Step: 8
Training loss: 2.012648105621338
Validation loss: 2.043904093004042

Epoch: 6| Step: 9
Training loss: 1.8975889682769775
Validation loss: 2.0220483041578725

Epoch: 6| Step: 10
Training loss: 2.7309954166412354
Validation loss: 2.013724168141683

Epoch: 6| Step: 11
Training loss: 2.9351749420166016
Validation loss: 2.0074105211483535

Epoch: 6| Step: 12
Training loss: 2.9150941371917725
Validation loss: 2.013445979805403

Epoch: 6| Step: 13
Training loss: 1.791656732559204
Validation loss: 2.029696064610635

Epoch: 87| Step: 0
Training loss: 2.286316156387329
Validation loss: 2.0354638612398537

Epoch: 6| Step: 1
Training loss: 2.86307954788208
Validation loss: 2.040911853954356

Epoch: 6| Step: 2
Training loss: 2.8804824352264404
Validation loss: 2.043104338389571

Epoch: 6| Step: 3
Training loss: 1.5005195140838623
Validation loss: 2.032528213275376

Epoch: 6| Step: 4
Training loss: 2.1864733695983887
Validation loss: 2.0192305375170965

Epoch: 6| Step: 5
Training loss: 2.5934348106384277
Validation loss: 2.0103514835398686

Epoch: 6| Step: 6
Training loss: 3.0882365703582764
Validation loss: 2.0150866867393575

Epoch: 6| Step: 7
Training loss: 2.60382342338562
Validation loss: 2.044513956193001

Epoch: 6| Step: 8
Training loss: 2.330368995666504
Validation loss: 2.0691030179300616

Epoch: 6| Step: 9
Training loss: 2.6970276832580566
Validation loss: 2.068732659022013

Epoch: 6| Step: 10
Training loss: 2.079962730407715
Validation loss: 2.0867449839909873

Epoch: 6| Step: 11
Training loss: 2.393085479736328
Validation loss: 2.1378242713148876

Epoch: 6| Step: 12
Training loss: 1.939305305480957
Validation loss: 2.1833157129185174

Epoch: 6| Step: 13
Training loss: 1.8935593366622925
Validation loss: 2.1902113704271216

Epoch: 88| Step: 0
Training loss: 3.2074098587036133
Validation loss: 2.1573500402512087

Epoch: 6| Step: 1
Training loss: 1.929295539855957
Validation loss: 2.0835327743202128

Epoch: 6| Step: 2
Training loss: 2.434854030609131
Validation loss: 2.050625402440307

Epoch: 6| Step: 3
Training loss: 2.2901864051818848
Validation loss: 2.0377464704616095

Epoch: 6| Step: 4
Training loss: 1.9237009286880493
Validation loss: 2.0267002685095674

Epoch: 6| Step: 5
Training loss: 2.734783172607422
Validation loss: 2.0141902687729045

Epoch: 6| Step: 6
Training loss: 2.2810308933258057
Validation loss: 2.006732399745654

Epoch: 6| Step: 7
Training loss: 2.49251651763916
Validation loss: 2.0000543235450663

Epoch: 6| Step: 8
Training loss: 2.3931350708007812
Validation loss: 1.9955513913144347

Epoch: 6| Step: 9
Training loss: 2.1430106163024902
Validation loss: 2.0037848436704246

Epoch: 6| Step: 10
Training loss: 2.864467144012451
Validation loss: 2.0082563392577635

Epoch: 6| Step: 11
Training loss: 1.7188026905059814
Validation loss: 2.00676477596324

Epoch: 6| Step: 12
Training loss: 2.289201498031616
Validation loss: 2.0175640890675206

Epoch: 6| Step: 13
Training loss: 2.9382803440093994
Validation loss: 2.0107416901537167

Epoch: 89| Step: 0
Training loss: 2.046452522277832
Validation loss: 2.015992510703302

Epoch: 6| Step: 1
Training loss: 1.794777750968933
Validation loss: 2.0433047843235794

Epoch: 6| Step: 2
Training loss: 2.4058644771575928
Validation loss: 2.081483056468348

Epoch: 6| Step: 3
Training loss: 2.2487857341766357
Validation loss: 2.1615069758507515

Epoch: 6| Step: 4
Training loss: 2.490234136581421
Validation loss: 2.2316079229436894

Epoch: 6| Step: 5
Training loss: 2.586207151412964
Validation loss: 2.3385407437560377

Epoch: 6| Step: 6
Training loss: 3.2347474098205566
Validation loss: 2.420478582382202

Epoch: 6| Step: 7
Training loss: 2.591811180114746
Validation loss: 2.4371400802366194

Epoch: 6| Step: 8
Training loss: 3.040222644805908
Validation loss: 2.405496290934983

Epoch: 6| Step: 9
Training loss: 2.2619423866271973
Validation loss: 2.3143165290996595

Epoch: 6| Step: 10
Training loss: 2.1032912731170654
Validation loss: 2.208138532536004

Epoch: 6| Step: 11
Training loss: 2.509498357772827
Validation loss: 2.1310828552451184

Epoch: 6| Step: 12
Training loss: 2.711700916290283
Validation loss: 2.0499702858668503

Epoch: 6| Step: 13
Training loss: 2.0477511882781982
Validation loss: 2.0222004331568235

Epoch: 90| Step: 0
Training loss: 1.9210593700408936
Validation loss: 2.0158859042711157

Epoch: 6| Step: 1
Training loss: 2.3427228927612305
Validation loss: 2.0240033929065993

Epoch: 6| Step: 2
Training loss: 2.353795289993286
Validation loss: 2.0181373716682516

Epoch: 6| Step: 3
Training loss: 2.281855583190918
Validation loss: 2.0155048883089455

Epoch: 6| Step: 4
Training loss: 2.5803794860839844
Validation loss: 2.016754142699703

Epoch: 6| Step: 5
Training loss: 2.4912304878234863
Validation loss: 2.018810179925734

Epoch: 6| Step: 6
Training loss: 2.179396152496338
Validation loss: 2.013566719588413

Epoch: 6| Step: 7
Training loss: 2.4687516689300537
Validation loss: 2.013546439909166

Epoch: 6| Step: 8
Training loss: 2.5337917804718018
Validation loss: 2.018920612591569

Epoch: 6| Step: 9
Training loss: 2.6885430812835693
Validation loss: 2.031936204561623

Epoch: 6| Step: 10
Training loss: 1.7855100631713867
Validation loss: 2.0378543176958637

Epoch: 6| Step: 11
Training loss: 2.8004109859466553
Validation loss: 2.068800428862213

Epoch: 6| Step: 12
Training loss: 2.7926197052001953
Validation loss: 2.112918564068374

Epoch: 6| Step: 13
Training loss: 1.8423587083816528
Validation loss: 2.138711675520866

Epoch: 91| Step: 0
Training loss: 2.267016649246216
Validation loss: 2.141351986956853

Epoch: 6| Step: 1
Training loss: 2.9759747982025146
Validation loss: 2.1379739340915473

Epoch: 6| Step: 2
Training loss: 2.154754161834717
Validation loss: 2.0892774212744927

Epoch: 6| Step: 3
Training loss: 2.7358920574188232
Validation loss: 2.0713530227702153

Epoch: 6| Step: 4
Training loss: 2.381052017211914
Validation loss: 2.0469884487890426

Epoch: 6| Step: 5
Training loss: 2.1064281463623047
Validation loss: 2.0324102319696897

Epoch: 6| Step: 6
Training loss: 2.087773323059082
Validation loss: 2.0267330420914518

Epoch: 6| Step: 7
Training loss: 2.4682912826538086
Validation loss: 2.0327321508879304

Epoch: 6| Step: 8
Training loss: 3.1815309524536133
Validation loss: 2.0309159550615536

Epoch: 6| Step: 9
Training loss: 2.059805154800415
Validation loss: 2.0323767085229196

Epoch: 6| Step: 10
Training loss: 1.7293815612792969
Validation loss: 2.023055725200202

Epoch: 6| Step: 11
Training loss: 1.5767271518707275
Validation loss: 2.0212682254852785

Epoch: 6| Step: 12
Training loss: 2.320221424102783
Validation loss: 2.0252079643229

Epoch: 6| Step: 13
Training loss: 2.638514995574951
Validation loss: 2.0308808216484646

Epoch: 92| Step: 0
Training loss: 2.3525638580322266
Validation loss: 2.033800559659158

Epoch: 6| Step: 1
Training loss: 2.7785449028015137
Validation loss: 2.040476019664477

Epoch: 6| Step: 2
Training loss: 2.614297866821289
Validation loss: 2.050181442691434

Epoch: 6| Step: 3
Training loss: 2.3226380348205566
Validation loss: 2.0618852056482786

Epoch: 6| Step: 4
Training loss: 2.6539149284362793
Validation loss: 2.074198025529103

Epoch: 6| Step: 5
Training loss: 2.4312705993652344
Validation loss: 2.072374733545447

Epoch: 6| Step: 6
Training loss: 2.2417287826538086
Validation loss: 2.0907167491092475

Epoch: 6| Step: 7
Training loss: 2.955183506011963
Validation loss: 2.0827447496434695

Epoch: 6| Step: 8
Training loss: 1.8119466304779053
Validation loss: 2.0536345666454685

Epoch: 6| Step: 9
Training loss: 2.099396228790283
Validation loss: 2.0214862772213515

Epoch: 6| Step: 10
Training loss: 2.1685266494750977
Validation loss: 2.013395858067338

Epoch: 6| Step: 11
Training loss: 1.8272452354431152
Validation loss: 2.018233473582934

Epoch: 6| Step: 12
Training loss: 1.8151966333389282
Validation loss: 2.024666219629267

Epoch: 6| Step: 13
Training loss: 2.7879679203033447
Validation loss: 2.0292647628374

Epoch: 93| Step: 0
Training loss: 2.7295408248901367
Validation loss: 2.035381970867034

Epoch: 6| Step: 1
Training loss: 1.7689616680145264
Validation loss: 2.0633528514574935

Epoch: 6| Step: 2
Training loss: 2.4143333435058594
Validation loss: 2.06057983316401

Epoch: 6| Step: 3
Training loss: 1.9149805307388306
Validation loss: 2.0519320093175417

Epoch: 6| Step: 4
Training loss: 2.2981410026550293
Validation loss: 2.0561211468071066

Epoch: 6| Step: 5
Training loss: 2.7373623847961426
Validation loss: 2.0388620092022802

Epoch: 6| Step: 6
Training loss: 1.4887187480926514
Validation loss: 2.0328701644815426

Epoch: 6| Step: 7
Training loss: 2.4817373752593994
Validation loss: 2.0309494118536673

Epoch: 6| Step: 8
Training loss: 2.461937665939331
Validation loss: 2.0271927195210613

Epoch: 6| Step: 9
Training loss: 2.0189363956451416
Validation loss: 2.033573058343703

Epoch: 6| Step: 10
Training loss: 2.6347131729125977
Validation loss: 2.0237195017517253

Epoch: 6| Step: 11
Training loss: 3.0325117111206055
Validation loss: 2.0280273268299718

Epoch: 6| Step: 12
Training loss: 1.9761905670166016
Validation loss: 2.025782057034072

Epoch: 6| Step: 13
Training loss: 2.6885628700256348
Validation loss: 2.019821333628829

Epoch: 94| Step: 0
Training loss: 2.6583988666534424
Validation loss: 2.027393517955657

Epoch: 6| Step: 1
Training loss: 2.5691096782684326
Validation loss: 2.0234351696506625

Epoch: 6| Step: 2
Training loss: 1.7224429845809937
Validation loss: 2.0219177135857205

Epoch: 6| Step: 3
Training loss: 1.9942580461502075
Validation loss: 2.0457699734677552

Epoch: 6| Step: 4
Training loss: 2.617107391357422
Validation loss: 2.0906793930197276

Epoch: 6| Step: 5
Training loss: 1.9972829818725586
Validation loss: 2.1535955295767835

Epoch: 6| Step: 6
Training loss: 2.6761627197265625
Validation loss: 2.2291557224847938

Epoch: 6| Step: 7
Training loss: 2.570498466491699
Validation loss: 2.2634087916343444

Epoch: 6| Step: 8
Training loss: 3.103398561477661
Validation loss: 2.225461180492114

Epoch: 6| Step: 9
Training loss: 2.418984889984131
Validation loss: 2.1936247887149936

Epoch: 6| Step: 10
Training loss: 1.7853829860687256
Validation loss: 2.1392863745330484

Epoch: 6| Step: 11
Training loss: 1.9638042449951172
Validation loss: 2.0885643907772597

Epoch: 6| Step: 12
Training loss: 2.811532974243164
Validation loss: 2.0531407684408207

Epoch: 6| Step: 13
Training loss: 2.7180070877075195
Validation loss: 2.015946198535222

Epoch: 95| Step: 0
Training loss: 1.9102803468704224
Validation loss: 2.0158444835293676

Epoch: 6| Step: 1
Training loss: 3.0317471027374268
Validation loss: 2.0018554502917874

Epoch: 6| Step: 2
Training loss: 2.105424404144287
Validation loss: 2.0005936007345877

Epoch: 6| Step: 3
Training loss: 2.727440357208252
Validation loss: 1.9966558884548884

Epoch: 6| Step: 4
Training loss: 2.032848834991455
Validation loss: 1.995509632172123

Epoch: 6| Step: 5
Training loss: 3.293410301208496
Validation loss: 1.9981283372448337

Epoch: 6| Step: 6
Training loss: 2.3950724601745605
Validation loss: 2.0014727525813605

Epoch: 6| Step: 7
Training loss: 2.225435733795166
Validation loss: 2.0041153918030443

Epoch: 6| Step: 8
Training loss: 2.3125720024108887
Validation loss: 2.015204219407933

Epoch: 6| Step: 9
Training loss: 1.877366542816162
Validation loss: 2.0366824288522043

Epoch: 6| Step: 10
Training loss: 1.698368787765503
Validation loss: 2.0487264356305523

Epoch: 6| Step: 11
Training loss: 2.358114004135132
Validation loss: 2.0490839699263215

Epoch: 6| Step: 12
Training loss: 2.5310208797454834
Validation loss: 2.03536489189312

Epoch: 6| Step: 13
Training loss: 2.4226369857788086
Validation loss: 2.024246951585175

Epoch: 96| Step: 0
Training loss: 2.397873878479004
Validation loss: 2.0064875912922684

Epoch: 6| Step: 1
Training loss: 1.7828413248062134
Validation loss: 2.000066380346975

Epoch: 6| Step: 2
Training loss: 2.645616054534912
Validation loss: 1.9971755191843996

Epoch: 6| Step: 3
Training loss: 1.9701260328292847
Validation loss: 2.005121236206383

Epoch: 6| Step: 4
Training loss: 3.0948822498321533
Validation loss: 2.0007868889839417

Epoch: 6| Step: 5
Training loss: 2.4760541915893555
Validation loss: 1.9992969651376047

Epoch: 6| Step: 6
Training loss: 2.116534948348999
Validation loss: 2.00250328740766

Epoch: 6| Step: 7
Training loss: 2.7321383953094482
Validation loss: 2.00250220042403

Epoch: 6| Step: 8
Training loss: 1.9896504878997803
Validation loss: 2.006159079972134

Epoch: 6| Step: 9
Training loss: 2.2941431999206543
Validation loss: 2.0248777097271335

Epoch: 6| Step: 10
Training loss: 2.4579100608825684
Validation loss: 2.081935223712716

Epoch: 6| Step: 11
Training loss: 2.7845816612243652
Validation loss: 2.1122897824933453

Epoch: 6| Step: 12
Training loss: 2.02500581741333
Validation loss: 2.1393835954768683

Epoch: 6| Step: 13
Training loss: 2.135843276977539
Validation loss: 2.153410114267821

Epoch: 97| Step: 0
Training loss: 2.056957721710205
Validation loss: 2.1504829391356437

Epoch: 6| Step: 1
Training loss: 2.8200998306274414
Validation loss: 2.138892756995334

Epoch: 6| Step: 2
Training loss: 2.6860382556915283
Validation loss: 2.113092671158493

Epoch: 6| Step: 3
Training loss: 2.7712864875793457
Validation loss: 2.0858526896404963

Epoch: 6| Step: 4
Training loss: 2.2779884338378906
Validation loss: 2.064787495520807

Epoch: 6| Step: 5
Training loss: 2.056912899017334
Validation loss: 2.053050087344262

Epoch: 6| Step: 6
Training loss: 2.786060333251953
Validation loss: 2.0412353469479467

Epoch: 6| Step: 7
Training loss: 2.17398738861084
Validation loss: 2.060482721174917

Epoch: 6| Step: 8
Training loss: 2.050971031188965
Validation loss: 2.088104360847063

Epoch: 6| Step: 9
Training loss: 2.418606758117676
Validation loss: 2.0754422962024646

Epoch: 6| Step: 10
Training loss: 2.9808759689331055
Validation loss: 2.0682369227050454

Epoch: 6| Step: 11
Training loss: 1.6072949171066284
Validation loss: 2.031534746129026

Epoch: 6| Step: 12
Training loss: 2.33524227142334
Validation loss: 2.0152267461181967

Epoch: 6| Step: 13
Training loss: 1.523537516593933
Validation loss: 2.0064148928529475

Epoch: 98| Step: 0
Training loss: 2.0116641521453857
Validation loss: 1.9905264992867746

Epoch: 6| Step: 1
Training loss: 2.177076816558838
Validation loss: 1.996945119673206

Epoch: 6| Step: 2
Training loss: 1.9781863689422607
Validation loss: 1.9924579820325297

Epoch: 6| Step: 3
Training loss: 2.210721015930176
Validation loss: 1.999324239710326

Epoch: 6| Step: 4
Training loss: 2.781156063079834
Validation loss: 2.0079519479505477

Epoch: 6| Step: 5
Training loss: 2.5167646408081055
Validation loss: 2.0252350709771596

Epoch: 6| Step: 6
Training loss: 1.8333277702331543
Validation loss: 2.0351119989989908

Epoch: 6| Step: 7
Training loss: 2.2557408809661865
Validation loss: 2.04292994160806

Epoch: 6| Step: 8
Training loss: 2.616640090942383
Validation loss: 2.050954936653055

Epoch: 6| Step: 9
Training loss: 2.358096122741699
Validation loss: 2.0839373680853073

Epoch: 6| Step: 10
Training loss: 2.4226179122924805
Validation loss: 2.1034431188337264

Epoch: 6| Step: 11
Training loss: 2.2579474449157715
Validation loss: 2.150527920774234

Epoch: 6| Step: 12
Training loss: 1.7647597789764404
Validation loss: 2.2025997074701453

Epoch: 6| Step: 13
Training loss: 3.827070951461792
Validation loss: 2.2799377774679535

Epoch: 99| Step: 0
Training loss: 2.5188796520233154
Validation loss: 2.2407127785426315

Epoch: 6| Step: 1
Training loss: 2.9699792861938477
Validation loss: 2.1587024734866236

Epoch: 6| Step: 2
Training loss: 1.439821720123291
Validation loss: 2.052088345250776

Epoch: 6| Step: 3
Training loss: 2.1570000648498535
Validation loss: 2.0121710941355717

Epoch: 6| Step: 4
Training loss: 3.2168402671813965
Validation loss: 2.0018678121669318

Epoch: 6| Step: 5
Training loss: 2.438072681427002
Validation loss: 1.982362316500756

Epoch: 6| Step: 6
Training loss: 2.187314033508301
Validation loss: 1.9859806670937488

Epoch: 6| Step: 7
Training loss: 2.3921968936920166
Validation loss: 1.986349530117486

Epoch: 6| Step: 8
Training loss: 3.176025867462158
Validation loss: 1.994238079235118

Epoch: 6| Step: 9
Training loss: 2.060920476913452
Validation loss: 1.998509935153428

Epoch: 6| Step: 10
Training loss: 2.2676889896392822
Validation loss: 1.9961407197419034

Epoch: 6| Step: 11
Training loss: 2.558502197265625
Validation loss: 2.003926210505988

Epoch: 6| Step: 12
Training loss: 2.0230109691619873
Validation loss: 2.0131987730662027

Epoch: 6| Step: 13
Training loss: 1.7364567518234253
Validation loss: 2.0469869464956303

Epoch: 100| Step: 0
Training loss: 1.7357213497161865
Validation loss: 2.08918019007611

Epoch: 6| Step: 1
Training loss: 1.9563934803009033
Validation loss: 2.0981204048279793

Epoch: 6| Step: 2
Training loss: 3.0730621814727783
Validation loss: 2.1209268826310352

Epoch: 6| Step: 3
Training loss: 2.3197576999664307
Validation loss: 2.105160972123505

Epoch: 6| Step: 4
Training loss: 2.213672637939453
Validation loss: 2.0626759272749706

Epoch: 6| Step: 5
Training loss: 2.4999523162841797
Validation loss: 2.025747929849932

Epoch: 6| Step: 6
Training loss: 2.2738888263702393
Validation loss: 2.019237023527904

Epoch: 6| Step: 7
Training loss: 2.736776828765869
Validation loss: 1.9954547907716484

Epoch: 6| Step: 8
Training loss: 2.3813109397888184
Validation loss: 1.995079477628072

Epoch: 6| Step: 9
Training loss: 2.1661081314086914
Validation loss: 1.9923725589629142

Epoch: 6| Step: 10
Training loss: 2.3396806716918945
Validation loss: 1.993291340848451

Epoch: 6| Step: 11
Training loss: 2.025153398513794
Validation loss: 1.9976007771748368

Epoch: 6| Step: 12
Training loss: 2.8221702575683594
Validation loss: 2.0187097672493226

Epoch: 6| Step: 13
Training loss: 1.6130338907241821
Validation loss: 2.046198709036714

Epoch: 101| Step: 0
Training loss: 2.516880750656128
Validation loss: 2.105129021470265

Epoch: 6| Step: 1
Training loss: 1.4628084897994995
Validation loss: 2.12723619450805

Epoch: 6| Step: 2
Training loss: 1.9086172580718994
Validation loss: 2.0864598597249677

Epoch: 6| Step: 3
Training loss: 2.698206663131714
Validation loss: 2.0638867257743754

Epoch: 6| Step: 4
Training loss: 2.4303932189941406
Validation loss: 2.0165256274643766

Epoch: 6| Step: 5
Training loss: 2.702559471130371
Validation loss: 1.9939458511208976

Epoch: 6| Step: 6
Training loss: 2.3878564834594727
Validation loss: 1.9838073843268937

Epoch: 6| Step: 7
Training loss: 1.9608639478683472
Validation loss: 1.9813113853495607

Epoch: 6| Step: 8
Training loss: 2.530622959136963
Validation loss: 1.9838015187171198

Epoch: 6| Step: 9
Training loss: 2.610954761505127
Validation loss: 1.978270608891723

Epoch: 6| Step: 10
Training loss: 2.379636287689209
Validation loss: 1.9855910244808401

Epoch: 6| Step: 11
Training loss: 2.3626365661621094
Validation loss: 1.9918987315188172

Epoch: 6| Step: 12
Training loss: 1.8892128467559814
Validation loss: 1.9986783996705086

Epoch: 6| Step: 13
Training loss: 2.586705207824707
Validation loss: 1.9952032719888995

Epoch: 102| Step: 0
Training loss: 2.294111728668213
Validation loss: 2.0046801336349978

Epoch: 6| Step: 1
Training loss: 2.780709743499756
Validation loss: 2.0072863640323764

Epoch: 6| Step: 2
Training loss: 2.1569788455963135
Validation loss: 2.003191266008603

Epoch: 6| Step: 3
Training loss: 2.201747417449951
Validation loss: 2.009977140734273

Epoch: 6| Step: 4
Training loss: 1.7634596824645996
Validation loss: 1.99688373842547

Epoch: 6| Step: 5
Training loss: 2.464665412902832
Validation loss: 1.9924816892993065

Epoch: 6| Step: 6
Training loss: 1.5692193508148193
Validation loss: 2.0003897182403074

Epoch: 6| Step: 7
Training loss: 2.2804694175720215
Validation loss: 2.0057247325938237

Epoch: 6| Step: 8
Training loss: 2.1837503910064697
Validation loss: 2.0148468786670315

Epoch: 6| Step: 9
Training loss: 2.4197185039520264
Validation loss: 2.0209886207375476

Epoch: 6| Step: 10
Training loss: 2.824981451034546
Validation loss: 2.0000079883042203

Epoch: 6| Step: 11
Training loss: 2.3557565212249756
Validation loss: 1.9877865673393331

Epoch: 6| Step: 12
Training loss: 2.3831677436828613
Validation loss: 2.0042117577727123

Epoch: 6| Step: 13
Training loss: 2.218982458114624
Validation loss: 1.983183151932173

Epoch: 103| Step: 0
Training loss: 2.3635716438293457
Validation loss: 1.976548110285113

Epoch: 6| Step: 1
Training loss: 2.2526626586914062
Validation loss: 1.9818711485914005

Epoch: 6| Step: 2
Training loss: 2.767723560333252
Validation loss: 1.9902513975738196

Epoch: 6| Step: 3
Training loss: 3.1000452041625977
Validation loss: 2.0055408554692424

Epoch: 6| Step: 4
Training loss: 2.40006685256958
Validation loss: 2.0337563714673443

Epoch: 6| Step: 5
Training loss: 1.990860939025879
Validation loss: 2.0191849252229095

Epoch: 6| Step: 6
Training loss: 1.8111436367034912
Validation loss: 2.0239690913948962

Epoch: 6| Step: 7
Training loss: 2.517949104309082
Validation loss: 2.0079676553767216

Epoch: 6| Step: 8
Training loss: 1.6976661682128906
Validation loss: 2.005795427547988

Epoch: 6| Step: 9
Training loss: 2.897916316986084
Validation loss: 1.988978801235076

Epoch: 6| Step: 10
Training loss: 2.1466329097747803
Validation loss: 1.9863368157417542

Epoch: 6| Step: 11
Training loss: 2.2854270935058594
Validation loss: 2.006692518470108

Epoch: 6| Step: 12
Training loss: 1.8567218780517578
Validation loss: 2.0349323249632314

Epoch: 6| Step: 13
Training loss: 2.318480968475342
Validation loss: 2.069312290478778

Epoch: 104| Step: 0
Training loss: 3.148521661758423
Validation loss: 2.0556435482476347

Epoch: 6| Step: 1
Training loss: 1.3208774328231812
Validation loss: 1.9987680630017353

Epoch: 6| Step: 2
Training loss: 2.7618601322174072
Validation loss: 1.9730320592080393

Epoch: 6| Step: 3
Training loss: 2.423038959503174
Validation loss: 1.9641809104591288

Epoch: 6| Step: 4
Training loss: 1.9345346689224243
Validation loss: 1.956235904847422

Epoch: 6| Step: 5
Training loss: 2.2319183349609375
Validation loss: 1.9489032119833014

Epoch: 6| Step: 6
Training loss: 1.6383050680160522
Validation loss: 1.95253126851974

Epoch: 6| Step: 7
Training loss: 2.378408193588257
Validation loss: 1.9523816185612832

Epoch: 6| Step: 8
Training loss: 2.311556816101074
Validation loss: 1.9617417820038334

Epoch: 6| Step: 9
Training loss: 2.3381803035736084
Validation loss: 1.96343534223495

Epoch: 6| Step: 10
Training loss: 2.118051528930664
Validation loss: 1.9820033299025668

Epoch: 6| Step: 11
Training loss: 1.8137834072113037
Validation loss: 1.9960028817576747

Epoch: 6| Step: 12
Training loss: 2.6533989906311035
Validation loss: 2.0262480243559806

Epoch: 6| Step: 13
Training loss: 3.449493885040283
Validation loss: 2.0660021343538837

Epoch: 105| Step: 0
Training loss: 2.296879768371582
Validation loss: 2.0654555828340593

Epoch: 6| Step: 1
Training loss: 2.0653867721557617
Validation loss: 2.0377598757384927

Epoch: 6| Step: 2
Training loss: 2.011486053466797
Validation loss: 2.025527423427951

Epoch: 6| Step: 3
Training loss: 2.6545979976654053
Validation loss: 2.0063615152912755

Epoch: 6| Step: 4
Training loss: 2.252073049545288
Validation loss: 1.997693971921039

Epoch: 6| Step: 5
Training loss: 2.8031132221221924
Validation loss: 1.968034493025913

Epoch: 6| Step: 6
Training loss: 1.9374377727508545
Validation loss: 1.955939700526576

Epoch: 6| Step: 7
Training loss: 1.6713274717330933
Validation loss: 1.954952811682096

Epoch: 6| Step: 8
Training loss: 2.444337844848633
Validation loss: 1.963377070683305

Epoch: 6| Step: 9
Training loss: 2.106776714324951
Validation loss: 1.961344559987386

Epoch: 6| Step: 10
Training loss: 2.291184663772583
Validation loss: 1.964111053815452

Epoch: 6| Step: 11
Training loss: 2.730581760406494
Validation loss: 1.9599053218800535

Epoch: 6| Step: 12
Training loss: 1.9143495559692383
Validation loss: 1.9563812055895407

Epoch: 6| Step: 13
Training loss: 3.1139988899230957
Validation loss: 1.9566152557249992

Epoch: 106| Step: 0
Training loss: 2.4116618633270264
Validation loss: 1.9705611915998562

Epoch: 6| Step: 1
Training loss: 2.752516269683838
Validation loss: 1.9687230228095927

Epoch: 6| Step: 2
Training loss: 2.2785658836364746
Validation loss: 1.9780938984245382

Epoch: 6| Step: 3
Training loss: 2.130462646484375
Validation loss: 1.9822311824367893

Epoch: 6| Step: 4
Training loss: 2.5635251998901367
Validation loss: 1.9892414859546128

Epoch: 6| Step: 5
Training loss: 1.8688645362854004
Validation loss: 1.9942584499236076

Epoch: 6| Step: 6
Training loss: 1.8398916721343994
Validation loss: 1.9860311913233932

Epoch: 6| Step: 7
Training loss: 2.404179573059082
Validation loss: 1.9984553283260715

Epoch: 6| Step: 8
Training loss: 1.7392706871032715
Validation loss: 1.9844789646005119

Epoch: 6| Step: 9
Training loss: 2.075533390045166
Validation loss: 1.9768042872028966

Epoch: 6| Step: 10
Training loss: 1.7314164638519287
Validation loss: 1.988417847182161

Epoch: 6| Step: 11
Training loss: 2.511557102203369
Validation loss: 2.001873972595379

Epoch: 6| Step: 12
Training loss: 2.37056827545166
Validation loss: 2.00681157137758

Epoch: 6| Step: 13
Training loss: 2.9647538661956787
Validation loss: 2.0370931317729335

Epoch: 107| Step: 0
Training loss: 2.669361114501953
Validation loss: 2.026654234496496

Epoch: 6| Step: 1
Training loss: 2.397430419921875
Validation loss: 2.0255778553665325

Epoch: 6| Step: 2
Training loss: 1.9254459142684937
Validation loss: 2.030075416770033

Epoch: 6| Step: 3
Training loss: 2.848538875579834
Validation loss: 2.016082448344077

Epoch: 6| Step: 4
Training loss: 2.1511993408203125
Validation loss: 1.9923944165629726

Epoch: 6| Step: 5
Training loss: 1.9750745296478271
Validation loss: 1.9907001372306579

Epoch: 6| Step: 6
Training loss: 3.13986873626709
Validation loss: 1.9788769598930114

Epoch: 6| Step: 7
Training loss: 1.5821844339370728
Validation loss: 1.9704758287757955

Epoch: 6| Step: 8
Training loss: 1.9285941123962402
Validation loss: 1.972722202218989

Epoch: 6| Step: 9
Training loss: 1.562833309173584
Validation loss: 1.9928571126794303

Epoch: 6| Step: 10
Training loss: 1.981472373008728
Validation loss: 1.9740188173068467

Epoch: 6| Step: 11
Training loss: 2.134070873260498
Validation loss: 1.9873001114014657

Epoch: 6| Step: 12
Training loss: 2.4400060176849365
Validation loss: 1.9675623063118226

Epoch: 6| Step: 13
Training loss: 2.8234105110168457
Validation loss: 1.966695165121427

Epoch: 108| Step: 0
Training loss: 1.5704059600830078
Validation loss: 1.9675593068522792

Epoch: 6| Step: 1
Training loss: 2.551785469055176
Validation loss: 1.9862390923243698

Epoch: 6| Step: 2
Training loss: 2.1984763145446777
Validation loss: 2.021514522132053

Epoch: 6| Step: 3
Training loss: 2.0619702339172363
Validation loss: 2.057892435340471

Epoch: 6| Step: 4
Training loss: 3.291783094406128
Validation loss: 2.073037606413646

Epoch: 6| Step: 5
Training loss: 2.2842087745666504
Validation loss: 2.069680501055974

Epoch: 6| Step: 6
Training loss: 2.4529306888580322
Validation loss: 2.046462300003216

Epoch: 6| Step: 7
Training loss: 2.1463494300842285
Validation loss: 2.0148471324674544

Epoch: 6| Step: 8
Training loss: 1.509055733680725
Validation loss: 1.984573600112751

Epoch: 6| Step: 9
Training loss: 1.951819896697998
Validation loss: 1.9563476142062937

Epoch: 6| Step: 10
Training loss: 2.6957359313964844
Validation loss: 1.9504691541835826

Epoch: 6| Step: 11
Training loss: 2.258679151535034
Validation loss: 1.940991973364225

Epoch: 6| Step: 12
Training loss: 1.7523739337921143
Validation loss: 1.9353949908287293

Epoch: 6| Step: 13
Training loss: 2.8515801429748535
Validation loss: 1.9346221313681653

Epoch: 109| Step: 0
Training loss: 1.8303000926971436
Validation loss: 1.9428901159635155

Epoch: 6| Step: 1
Training loss: 2.434344530105591
Validation loss: 1.9415875711748678

Epoch: 6| Step: 2
Training loss: 2.2650442123413086
Validation loss: 1.9374093009579567

Epoch: 6| Step: 3
Training loss: 2.24391770362854
Validation loss: 1.9369285388659405

Epoch: 6| Step: 4
Training loss: 2.5145034790039062
Validation loss: 1.9513817051405549

Epoch: 6| Step: 5
Training loss: 3.0134005546569824
Validation loss: 1.962888511278296

Epoch: 6| Step: 6
Training loss: 1.7205129861831665
Validation loss: 1.9772397689921881

Epoch: 6| Step: 7
Training loss: 2.208627700805664
Validation loss: 1.9899047587507515

Epoch: 6| Step: 8
Training loss: 2.139414072036743
Validation loss: 1.9620120474087295

Epoch: 6| Step: 9
Training loss: 2.385680675506592
Validation loss: 1.9581452108198596

Epoch: 6| Step: 10
Training loss: 2.0364415645599365
Validation loss: 1.9659388885703137

Epoch: 6| Step: 11
Training loss: 1.562088966369629
Validation loss: 1.960474221937118

Epoch: 6| Step: 12
Training loss: 2.5736031532287598
Validation loss: 1.9555837569698211

Epoch: 6| Step: 13
Training loss: 2.418398857116699
Validation loss: 1.959235027272214

Epoch: 110| Step: 0
Training loss: 2.5803887844085693
Validation loss: 1.9534994312511977

Epoch: 6| Step: 1
Training loss: 2.5360302925109863
Validation loss: 1.9429197131946523

Epoch: 6| Step: 2
Training loss: 2.321253776550293
Validation loss: 1.9528632894639046

Epoch: 6| Step: 3
Training loss: 2.3898911476135254
Validation loss: 1.938941099310434

Epoch: 6| Step: 4
Training loss: 2.7241334915161133
Validation loss: 1.9454083929779709

Epoch: 6| Step: 5
Training loss: 1.0122473239898682
Validation loss: 1.9480069811626146

Epoch: 6| Step: 6
Training loss: 2.20444393157959
Validation loss: 1.954149801244018

Epoch: 6| Step: 7
Training loss: 2.3086941242218018
Validation loss: 1.964673529389084

Epoch: 6| Step: 8
Training loss: 1.9128117561340332
Validation loss: 1.9848789515033844

Epoch: 6| Step: 9
Training loss: 2.2366843223571777
Validation loss: 2.0114779882533576

Epoch: 6| Step: 10
Training loss: 2.3271069526672363
Validation loss: 2.0247195587363294

Epoch: 6| Step: 11
Training loss: 2.2377889156341553
Validation loss: 2.055001089649816

Epoch: 6| Step: 12
Training loss: 2.0937094688415527
Validation loss: 2.0797083300928914

Epoch: 6| Step: 13
Training loss: 1.822784662246704
Validation loss: 2.061317143901702

Epoch: 111| Step: 0
Training loss: 1.9863967895507812
Validation loss: 2.071533028797437

Epoch: 6| Step: 1
Training loss: 2.2043144702911377
Validation loss: 2.0825170534913258

Epoch: 6| Step: 2
Training loss: 2.123209238052368
Validation loss: 2.1370840457177933

Epoch: 6| Step: 3
Training loss: 2.4039387702941895
Validation loss: 2.1654739136336953

Epoch: 6| Step: 4
Training loss: 1.6115450859069824
Validation loss: 2.1266673149601107

Epoch: 6| Step: 5
Training loss: 2.0550267696380615
Validation loss: 2.1288877315418695

Epoch: 6| Step: 6
Training loss: 1.8932554721832275
Validation loss: 2.106874704360962

Epoch: 6| Step: 7
Training loss: 2.066843032836914
Validation loss: 2.08016941624303

Epoch: 6| Step: 8
Training loss: 2.9336698055267334
Validation loss: 2.069914041026946

Epoch: 6| Step: 9
Training loss: 2.5597434043884277
Validation loss: 2.039282291166244

Epoch: 6| Step: 10
Training loss: 2.3671960830688477
Validation loss: 1.986253526902968

Epoch: 6| Step: 11
Training loss: 2.346076726913452
Validation loss: 1.9564894758244997

Epoch: 6| Step: 12
Training loss: 2.460475444793701
Validation loss: 1.9449798560911609

Epoch: 6| Step: 13
Training loss: 2.6632251739501953
Validation loss: 1.9370554506137807

Epoch: 112| Step: 0
Training loss: 2.3028564453125
Validation loss: 1.9386246960650209

Epoch: 6| Step: 1
Training loss: 2.6187639236450195
Validation loss: 1.9303897721793062

Epoch: 6| Step: 2
Training loss: 2.5125818252563477
Validation loss: 1.9385312218819895

Epoch: 6| Step: 3
Training loss: 2.2375502586364746
Validation loss: 1.9499949524479527

Epoch: 6| Step: 4
Training loss: 2.0135135650634766
Validation loss: 1.9537724782061834

Epoch: 6| Step: 5
Training loss: 2.510500431060791
Validation loss: 1.9704828005965038

Epoch: 6| Step: 6
Training loss: 2.063823938369751
Validation loss: 1.965367858127881

Epoch: 6| Step: 7
Training loss: 1.935909628868103
Validation loss: 1.9591589255999493

Epoch: 6| Step: 8
Training loss: 1.3109042644500732
Validation loss: 1.9571526999114661

Epoch: 6| Step: 9
Training loss: 2.4451842308044434
Validation loss: 1.9666167510453092

Epoch: 6| Step: 10
Training loss: 2.0074262619018555
Validation loss: 1.9536579655062767

Epoch: 6| Step: 11
Training loss: 2.624110221862793
Validation loss: 1.9634217651941444

Epoch: 6| Step: 12
Training loss: 2.758298397064209
Validation loss: 1.9539951611590642

Epoch: 6| Step: 13
Training loss: 1.870185375213623
Validation loss: 1.9452910654006466

Epoch: 113| Step: 0
Training loss: 2.353055477142334
Validation loss: 1.9430301779059953

Epoch: 6| Step: 1
Training loss: 2.731372356414795
Validation loss: 1.9420793569216164

Epoch: 6| Step: 2
Training loss: 2.0655384063720703
Validation loss: 1.9514651836887482

Epoch: 6| Step: 3
Training loss: 2.501889705657959
Validation loss: 1.9458241898526427

Epoch: 6| Step: 4
Training loss: 1.8153965473175049
Validation loss: 1.965407048502276

Epoch: 6| Step: 5
Training loss: 2.6137757301330566
Validation loss: 1.9722732702891033

Epoch: 6| Step: 6
Training loss: 2.4148452281951904
Validation loss: 1.9713951003166936

Epoch: 6| Step: 7
Training loss: 2.187861442565918
Validation loss: 1.989022966354124

Epoch: 6| Step: 8
Training loss: 2.035369873046875
Validation loss: 2.0419180803401495

Epoch: 6| Step: 9
Training loss: 1.328695297241211
Validation loss: 2.066660505469127

Epoch: 6| Step: 10
Training loss: 2.4770233631134033
Validation loss: 2.1069261284284693

Epoch: 6| Step: 11
Training loss: 2.055783748626709
Validation loss: 2.1363804801817863

Epoch: 6| Step: 12
Training loss: 2.1435818672180176
Validation loss: 2.150651216506958

Epoch: 6| Step: 13
Training loss: 2.131707191467285
Validation loss: 2.0903892645271878

Epoch: 114| Step: 0
Training loss: 2.0582425594329834
Validation loss: 2.086599939612932

Epoch: 6| Step: 1
Training loss: 2.476041078567505
Validation loss: 2.0352740979963735

Epoch: 6| Step: 2
Training loss: 1.5286834239959717
Validation loss: 2.0259604633495374

Epoch: 6| Step: 3
Training loss: 2.1226677894592285
Validation loss: 2.0042594094430246

Epoch: 6| Step: 4
Training loss: 1.8141882419586182
Validation loss: 1.9775960432585848

Epoch: 6| Step: 5
Training loss: 2.8389365673065186
Validation loss: 1.9653746825392528

Epoch: 6| Step: 6
Training loss: 2.001922607421875
Validation loss: 1.9567959667533956

Epoch: 6| Step: 7
Training loss: 2.1164774894714355
Validation loss: 1.952674347867248

Epoch: 6| Step: 8
Training loss: 2.3223190307617188
Validation loss: 1.9584842112756544

Epoch: 6| Step: 9
Training loss: 2.5194132328033447
Validation loss: 1.9634566819795998

Epoch: 6| Step: 10
Training loss: 1.9747674465179443
Validation loss: 1.9572331431091472

Epoch: 6| Step: 11
Training loss: 1.9414985179901123
Validation loss: 1.9561948237880584

Epoch: 6| Step: 12
Training loss: 2.8687052726745605
Validation loss: 1.966542229857496

Epoch: 6| Step: 13
Training loss: 2.2561752796173096
Validation loss: 1.9649454701331355

Epoch: 115| Step: 0
Training loss: 1.8976848125457764
Validation loss: 1.9768318822306972

Epoch: 6| Step: 1
Training loss: 1.484398603439331
Validation loss: 1.9989677680436002

Epoch: 6| Step: 2
Training loss: 2.3228745460510254
Validation loss: 2.0205501843524236

Epoch: 6| Step: 3
Training loss: 2.0703372955322266
Validation loss: 2.0501738491878716

Epoch: 6| Step: 4
Training loss: 1.9700188636779785
Validation loss: 2.0949831137093167

Epoch: 6| Step: 5
Training loss: 2.320444107055664
Validation loss: 2.1380002370444675

Epoch: 6| Step: 6
Training loss: 1.4915844202041626
Validation loss: 2.1964375408746863

Epoch: 6| Step: 7
Training loss: 2.815802574157715
Validation loss: 2.2872152200309177

Epoch: 6| Step: 8
Training loss: 2.8053150177001953
Validation loss: 2.2792095599635953

Epoch: 6| Step: 9
Training loss: 2.799701690673828
Validation loss: 2.1836810445272796

Epoch: 6| Step: 10
Training loss: 1.8683911561965942
Validation loss: 2.0942734774722847

Epoch: 6| Step: 11
Training loss: 2.0251097679138184
Validation loss: 2.0283140367077244

Epoch: 6| Step: 12
Training loss: 2.698256015777588
Validation loss: 1.9929289920355684

Epoch: 6| Step: 13
Training loss: 1.6941895484924316
Validation loss: 1.9676796390164284

Epoch: 116| Step: 0
Training loss: 2.3197267055511475
Validation loss: 1.9601171452512023

Epoch: 6| Step: 1
Training loss: 2.1927337646484375
Validation loss: 1.9577566474996588

Epoch: 6| Step: 2
Training loss: 2.4470529556274414
Validation loss: 1.9476865786378101

Epoch: 6| Step: 3
Training loss: 2.7238192558288574
Validation loss: 1.9387940950291132

Epoch: 6| Step: 4
Training loss: 2.1395351886749268
Validation loss: 1.9467549272762832

Epoch: 6| Step: 5
Training loss: 2.107846736907959
Validation loss: 1.9389702953318113

Epoch: 6| Step: 6
Training loss: 2.079214096069336
Validation loss: 1.9530455502130653

Epoch: 6| Step: 7
Training loss: 2.3070285320281982
Validation loss: 1.9647255341211955

Epoch: 6| Step: 8
Training loss: 1.8511199951171875
Validation loss: 1.9528990189234416

Epoch: 6| Step: 9
Training loss: 1.661978006362915
Validation loss: 1.9662284915165236

Epoch: 6| Step: 10
Training loss: 1.8030487298965454
Validation loss: 1.9666190352491153

Epoch: 6| Step: 11
Training loss: 2.1652960777282715
Validation loss: 1.975295418052263

Epoch: 6| Step: 12
Training loss: 2.287093162536621
Validation loss: 1.9677876375054801

Epoch: 6| Step: 13
Training loss: 2.2046849727630615
Validation loss: 2.005967115843168

Epoch: 117| Step: 0
Training loss: 2.3689794540405273
Validation loss: 2.035226736017453

Epoch: 6| Step: 1
Training loss: 2.1451220512390137
Validation loss: 2.100794933175528

Epoch: 6| Step: 2
Training loss: 2.9316353797912598
Validation loss: 2.1037602232348536

Epoch: 6| Step: 3
Training loss: 2.6732940673828125
Validation loss: 2.1123832656491186

Epoch: 6| Step: 4
Training loss: 2.1984763145446777
Validation loss: 2.0801144210241174

Epoch: 6| Step: 5
Training loss: 2.576888084411621
Validation loss: 2.064693199690952

Epoch: 6| Step: 6
Training loss: 1.5446498394012451
Validation loss: 2.058542861733385

Epoch: 6| Step: 7
Training loss: 2.0146143436431885
Validation loss: 2.0492762134921167

Epoch: 6| Step: 8
Training loss: 2.061628818511963
Validation loss: 2.0332267976576284

Epoch: 6| Step: 9
Training loss: 1.9737581014633179
Validation loss: 2.0177201224911596

Epoch: 6| Step: 10
Training loss: 1.6532869338989258
Validation loss: 1.9916139635988461

Epoch: 6| Step: 11
Training loss: 1.9795361757278442
Validation loss: 1.9900073005307106

Epoch: 6| Step: 12
Training loss: 2.0590128898620605
Validation loss: 1.97265657301872

Epoch: 6| Step: 13
Training loss: 2.0724854469299316
Validation loss: 1.9816588278739684

Epoch: 118| Step: 0
Training loss: 1.7946813106536865
Validation loss: 1.99153007102269

Epoch: 6| Step: 1
Training loss: 1.7154475450515747
Validation loss: 1.9975266354058379

Epoch: 6| Step: 2
Training loss: 1.1549456119537354
Validation loss: 2.0060082507389847

Epoch: 6| Step: 3
Training loss: 2.150424003601074
Validation loss: 2.0136115961177374

Epoch: 6| Step: 4
Training loss: 2.525256872177124
Validation loss: 2.037267998982501

Epoch: 6| Step: 5
Training loss: 1.7964568138122559
Validation loss: 2.0251618931370396

Epoch: 6| Step: 6
Training loss: 1.936417579650879
Validation loss: 2.035885077650829

Epoch: 6| Step: 7
Training loss: 2.4261789321899414
Validation loss: 2.060567666125554

Epoch: 6| Step: 8
Training loss: 2.3871548175811768
Validation loss: 2.0187402489364787

Epoch: 6| Step: 9
Training loss: 2.26434326171875
Validation loss: 1.9935762356686335

Epoch: 6| Step: 10
Training loss: 2.994311809539795
Validation loss: 1.97880050956562

Epoch: 6| Step: 11
Training loss: 2.16131854057312
Validation loss: 1.9572728141661613

Epoch: 6| Step: 12
Training loss: 2.1208691596984863
Validation loss: 1.9618122975031536

Epoch: 6| Step: 13
Training loss: 2.668145179748535
Validation loss: 1.9629562362547843

Epoch: 119| Step: 0
Training loss: 1.6568427085876465
Validation loss: 1.9744007613069268

Epoch: 6| Step: 1
Training loss: 1.8967461585998535
Validation loss: 2.0061318810268114

Epoch: 6| Step: 2
Training loss: 2.1931467056274414
Validation loss: 2.026945701209448

Epoch: 6| Step: 3
Training loss: 1.4299861192703247
Validation loss: 2.0202963249657744

Epoch: 6| Step: 4
Training loss: 2.0168042182922363
Validation loss: 2.03290573499536

Epoch: 6| Step: 5
Training loss: 1.7651453018188477
Validation loss: 2.0209037693597938

Epoch: 6| Step: 6
Training loss: 2.6819581985473633
Validation loss: 2.022701942792503

Epoch: 6| Step: 7
Training loss: 1.9338569641113281
Validation loss: 2.014061709885956

Epoch: 6| Step: 8
Training loss: 1.9470970630645752
Validation loss: 1.9996705337237286

Epoch: 6| Step: 9
Training loss: 2.9956393241882324
Validation loss: 1.9746831488865677

Epoch: 6| Step: 10
Training loss: 2.7389981746673584
Validation loss: 1.9776743329981321

Epoch: 6| Step: 11
Training loss: 1.6930745840072632
Validation loss: 1.9706427525448542

Epoch: 6| Step: 12
Training loss: 2.434596538543701
Validation loss: 1.9729739645475983

Epoch: 6| Step: 13
Training loss: 2.7951149940490723
Validation loss: 1.972414296160462

Epoch: 120| Step: 0
Training loss: 2.2710795402526855
Validation loss: 1.965161112047011

Epoch: 6| Step: 1
Training loss: 1.9926167726516724
Validation loss: 1.9904026664713377

Epoch: 6| Step: 2
Training loss: 1.5630873441696167
Validation loss: 2.0204145844264696

Epoch: 6| Step: 3
Training loss: 2.843337059020996
Validation loss: 2.047847952893985

Epoch: 6| Step: 4
Training loss: 1.9060803651809692
Validation loss: 2.120822614239108

Epoch: 6| Step: 5
Training loss: 1.9763846397399902
Validation loss: 2.1722942039530766

Epoch: 6| Step: 6
Training loss: 3.0211873054504395
Validation loss: 2.2273969381086287

Epoch: 6| Step: 7
Training loss: 2.4590189456939697
Validation loss: 2.2280288742434595

Epoch: 6| Step: 8
Training loss: 2.3943824768066406
Validation loss: 2.242300166878649

Epoch: 6| Step: 9
Training loss: 2.1251542568206787
Validation loss: 2.2339559421744397

Epoch: 6| Step: 10
Training loss: 1.7003765106201172
Validation loss: 2.1976952809159473

Epoch: 6| Step: 11
Training loss: 2.148536205291748
Validation loss: 2.1613892919273785

Epoch: 6| Step: 12
Training loss: 2.0004115104675293
Validation loss: 2.111725770017152

Epoch: 6| Step: 13
Training loss: 1.7544530630111694
Validation loss: 2.1019196920497443

Epoch: 121| Step: 0
Training loss: 2.304445743560791
Validation loss: 2.0994512188819145

Epoch: 6| Step: 1
Training loss: 2.139214515686035
Validation loss: 2.0709947719368884

Epoch: 6| Step: 2
Training loss: 2.9783785343170166
Validation loss: 2.064136142371803

Epoch: 6| Step: 3
Training loss: 1.6856470108032227
Validation loss: 2.0471170615124445

Epoch: 6| Step: 4
Training loss: 2.098477840423584
Validation loss: 2.0136124241736626

Epoch: 6| Step: 5
Training loss: 2.394023895263672
Validation loss: 2.0044083338911816

Epoch: 6| Step: 6
Training loss: 2.42111873626709
Validation loss: 1.9931906256624448

Epoch: 6| Step: 7
Training loss: 2.0034260749816895
Validation loss: 1.9954133931026663

Epoch: 6| Step: 8
Training loss: 2.15860652923584
Validation loss: 1.9886625838536087

Epoch: 6| Step: 9
Training loss: 1.5689890384674072
Validation loss: 1.9769489111438874

Epoch: 6| Step: 10
Training loss: 1.3980448246002197
Validation loss: 1.9824910984244397

Epoch: 6| Step: 11
Training loss: 2.643308162689209
Validation loss: 1.9870446740940053

Epoch: 6| Step: 12
Training loss: 1.9645881652832031
Validation loss: 1.9911022006824453

Epoch: 6| Step: 13
Training loss: 1.9388773441314697
Validation loss: 1.9999112377884567

Epoch: 122| Step: 0
Training loss: 3.0618205070495605
Validation loss: 2.046565621129928

Epoch: 6| Step: 1
Training loss: 1.8736720085144043
Validation loss: 2.1101413016678183

Epoch: 6| Step: 2
Training loss: 2.10518741607666
Validation loss: 2.1504537687506726

Epoch: 6| Step: 3
Training loss: 2.0940003395080566
Validation loss: 2.215095866111017

Epoch: 6| Step: 4
Training loss: 2.056151866912842
Validation loss: 2.211228447575723

Epoch: 6| Step: 5
Training loss: 1.4302029609680176
Validation loss: 2.166357976134105

Epoch: 6| Step: 6
Training loss: 2.2828261852264404
Validation loss: 2.157717865000489

Epoch: 6| Step: 7
Training loss: 1.8979344367980957
Validation loss: 2.128483774841473

Epoch: 6| Step: 8
Training loss: 2.020537853240967
Validation loss: 2.066259054727452

Epoch: 6| Step: 9
Training loss: 2.082388162612915
Validation loss: 2.01674231149817

Epoch: 6| Step: 10
Training loss: 1.8373262882232666
Validation loss: 1.9962511806077854

Epoch: 6| Step: 11
Training loss: 2.5413906574249268
Validation loss: 1.9652484809198687

Epoch: 6| Step: 12
Training loss: 2.4560508728027344
Validation loss: 1.9520777643367808

Epoch: 6| Step: 13
Training loss: 1.7116254568099976
Validation loss: 1.951247581871607

Epoch: 123| Step: 0
Training loss: 2.4598264694213867
Validation loss: 1.9584941787104453

Epoch: 6| Step: 1
Training loss: 1.6216721534729004
Validation loss: 1.9384261074886526

Epoch: 6| Step: 2
Training loss: 2.408079147338867
Validation loss: 1.9370332789677445

Epoch: 6| Step: 3
Training loss: 1.977613925933838
Validation loss: 1.9392468493471864

Epoch: 6| Step: 4
Training loss: 2.4307920932769775
Validation loss: 1.9453317606320946

Epoch: 6| Step: 5
Training loss: 2.1973283290863037
Validation loss: 1.9566781341388662

Epoch: 6| Step: 6
Training loss: 2.098522186279297
Validation loss: 1.9699869335338633

Epoch: 6| Step: 7
Training loss: 1.7707433700561523
Validation loss: 1.960530129812097

Epoch: 6| Step: 8
Training loss: 2.257697582244873
Validation loss: 1.9571618367266912

Epoch: 6| Step: 9
Training loss: 2.9080002307891846
Validation loss: 1.9534816126669607

Epoch: 6| Step: 10
Training loss: 1.4484505653381348
Validation loss: 1.9424639722352386

Epoch: 6| Step: 11
Training loss: 1.8477541208267212
Validation loss: 1.956284757583372

Epoch: 6| Step: 12
Training loss: 2.1067285537719727
Validation loss: 1.9637778907693841

Epoch: 6| Step: 13
Training loss: 2.315319299697876
Validation loss: 1.9785011288940266

Epoch: 124| Step: 0
Training loss: 1.8010129928588867
Validation loss: 1.9796421040770829

Epoch: 6| Step: 1
Training loss: 2.1079277992248535
Validation loss: 1.9781492064076085

Epoch: 6| Step: 2
Training loss: 2.35134220123291
Validation loss: 2.0020584931937595

Epoch: 6| Step: 3
Training loss: 2.2406694889068604
Validation loss: 1.992420317024313

Epoch: 6| Step: 4
Training loss: 1.8506953716278076
Validation loss: 1.99761781384868

Epoch: 6| Step: 5
Training loss: 2.519594192504883
Validation loss: 1.9949401604231967

Epoch: 6| Step: 6
Training loss: 2.151062488555908
Validation loss: 1.9787709379708895

Epoch: 6| Step: 7
Training loss: 1.8099299669265747
Validation loss: 1.9917906586841871

Epoch: 6| Step: 8
Training loss: 2.3969008922576904
Validation loss: 1.9845109562720022

Epoch: 6| Step: 9
Training loss: 1.6921451091766357
Validation loss: 1.996399998664856

Epoch: 6| Step: 10
Training loss: 1.7228240966796875
Validation loss: 2.018304269800904

Epoch: 6| Step: 11
Training loss: 2.103471040725708
Validation loss: 2.0544635800905127

Epoch: 6| Step: 12
Training loss: 2.537788152694702
Validation loss: 2.044674260641939

Epoch: 6| Step: 13
Training loss: 1.9019508361816406
Validation loss: 2.0161239036949734

Epoch: 125| Step: 0
Training loss: 2.409877061843872
Validation loss: 2.002064288303416

Epoch: 6| Step: 1
Training loss: 1.61710524559021
Validation loss: 1.9952003866113641

Epoch: 6| Step: 2
Training loss: 2.074765205383301
Validation loss: 1.9830467521503408

Epoch: 6| Step: 3
Training loss: 3.078303337097168
Validation loss: 1.9980251455819735

Epoch: 6| Step: 4
Training loss: 1.6618330478668213
Validation loss: 1.9953277213599092

Epoch: 6| Step: 5
Training loss: 1.939111590385437
Validation loss: 1.993516916869789

Epoch: 6| Step: 6
Training loss: 2.098360538482666
Validation loss: 2.004205947281212

Epoch: 6| Step: 7
Training loss: 1.8076750040054321
Validation loss: 2.012845047058598

Epoch: 6| Step: 8
Training loss: 1.6061978340148926
Validation loss: 2.0339570942745415

Epoch: 6| Step: 9
Training loss: 2.110769033432007
Validation loss: 2.064210158522411

Epoch: 6| Step: 10
Training loss: 1.9302160739898682
Validation loss: 2.11516305451752

Epoch: 6| Step: 11
Training loss: 1.8388137817382812
Validation loss: 2.1408238359676894

Epoch: 6| Step: 12
Training loss: 2.4944725036621094
Validation loss: 2.1655681133270264

Epoch: 6| Step: 13
Training loss: 1.91312575340271
Validation loss: 2.1911455303110103

Epoch: 126| Step: 0
Training loss: 1.0218021869659424
Validation loss: 2.1463711659113565

Epoch: 6| Step: 1
Training loss: 2.3377327919006348
Validation loss: 2.1170670986175537

Epoch: 6| Step: 2
Training loss: 2.5575366020202637
Validation loss: 2.0928999480380805

Epoch: 6| Step: 3
Training loss: 2.6981468200683594
Validation loss: 2.033854994722592

Epoch: 6| Step: 4
Training loss: 2.386009693145752
Validation loss: 1.9952372145909134

Epoch: 6| Step: 5
Training loss: 1.5788543224334717
Validation loss: 1.97955661178917

Epoch: 6| Step: 6
Training loss: 1.7394191026687622
Validation loss: 1.9654588032794256

Epoch: 6| Step: 7
Training loss: 1.4009712934494019
Validation loss: 1.9687789550391577

Epoch: 6| Step: 8
Training loss: 2.157419443130493
Validation loss: 1.9575350425576652

Epoch: 6| Step: 9
Training loss: 2.235657215118408
Validation loss: 1.9651714601824362

Epoch: 6| Step: 10
Training loss: 1.926589012145996
Validation loss: 1.960812851946841

Epoch: 6| Step: 11
Training loss: 1.9399195909500122
Validation loss: 1.9762830042069959

Epoch: 6| Step: 12
Training loss: 2.4064276218414307
Validation loss: 1.9823394770263343

Epoch: 6| Step: 13
Training loss: 2.1783132553100586
Validation loss: 1.976384844831241

Epoch: 127| Step: 0
Training loss: 2.000047206878662
Validation loss: 1.9821616090754026

Epoch: 6| Step: 1
Training loss: 2.2102651596069336
Validation loss: 2.000481970848576

Epoch: 6| Step: 2
Training loss: 1.9208674430847168
Validation loss: 2.0113118297310284

Epoch: 6| Step: 3
Training loss: 1.6307437419891357
Validation loss: 2.0241472951827513

Epoch: 6| Step: 4
Training loss: 2.2563300132751465
Validation loss: 2.044605517900118

Epoch: 6| Step: 5
Training loss: 1.86859130859375
Validation loss: 2.0463935021431214

Epoch: 6| Step: 6
Training loss: 2.350493907928467
Validation loss: 2.0649864724887315

Epoch: 6| Step: 7
Training loss: 1.8530776500701904
Validation loss: 2.1047091894252326

Epoch: 6| Step: 8
Training loss: 1.936808705329895
Validation loss: 2.1232295395225607

Epoch: 6| Step: 9
Training loss: 2.4353652000427246
Validation loss: 2.149339988667478

Epoch: 6| Step: 10
Training loss: 1.7865386009216309
Validation loss: 2.1493328873829176

Epoch: 6| Step: 11
Training loss: 2.0007574558258057
Validation loss: 2.1075881578589

Epoch: 6| Step: 12
Training loss: 2.3681492805480957
Validation loss: 2.102676994057112

Epoch: 6| Step: 13
Training loss: 1.7587774991989136
Validation loss: 2.0699553643503497

Epoch: 128| Step: 0
Training loss: 2.8674349784851074
Validation loss: 2.0499388505053777

Epoch: 6| Step: 1
Training loss: 2.569949150085449
Validation loss: 2.0431985880738948

Epoch: 6| Step: 2
Training loss: 1.5668461322784424
Validation loss: 2.0360282723621657

Epoch: 6| Step: 3
Training loss: 2.4059529304504395
Validation loss: 2.0157174000176052

Epoch: 6| Step: 4
Training loss: 2.056647539138794
Validation loss: 1.989764339180403

Epoch: 6| Step: 5
Training loss: 1.1350042819976807
Validation loss: 1.9765331911784347

Epoch: 6| Step: 6
Training loss: 2.577063798904419
Validation loss: 1.9559427563862135

Epoch: 6| Step: 7
Training loss: 1.3042593002319336
Validation loss: 1.948978203599171

Epoch: 6| Step: 8
Training loss: 1.973023533821106
Validation loss: 1.9440300285175283

Epoch: 6| Step: 9
Training loss: 2.211790084838867
Validation loss: 1.9650662932344662

Epoch: 6| Step: 10
Training loss: 2.242234468460083
Validation loss: 1.9544657994342107

Epoch: 6| Step: 11
Training loss: 1.775921106338501
Validation loss: 1.9624446361295638

Epoch: 6| Step: 12
Training loss: 1.8523764610290527
Validation loss: 1.97328346390878

Epoch: 6| Step: 13
Training loss: 2.1223413944244385
Validation loss: 1.9790438093164915

Epoch: 129| Step: 0
Training loss: 1.8509896993637085
Validation loss: 1.9891710178826445

Epoch: 6| Step: 1
Training loss: 2.1774368286132812
Validation loss: 2.0002842052008516

Epoch: 6| Step: 2
Training loss: 1.3420419692993164
Validation loss: 2.0123832764164096

Epoch: 6| Step: 3
Training loss: 2.249838352203369
Validation loss: 2.0260229072263165

Epoch: 6| Step: 4
Training loss: 2.169750452041626
Validation loss: 2.0187538234136437

Epoch: 6| Step: 5
Training loss: 1.7717797756195068
Validation loss: 2.0210915047635316

Epoch: 6| Step: 6
Training loss: 2.302476167678833
Validation loss: 2.032066536206071

Epoch: 6| Step: 7
Training loss: 2.4442620277404785
Validation loss: 2.053630885257516

Epoch: 6| Step: 8
Training loss: 1.6823241710662842
Validation loss: 2.067072426119158

Epoch: 6| Step: 9
Training loss: 1.1535587310791016
Validation loss: 2.0470885128103276

Epoch: 6| Step: 10
Training loss: 2.146183729171753
Validation loss: 2.0368961723901893

Epoch: 6| Step: 11
Training loss: 2.3590526580810547
Validation loss: 2.0397145671229207

Epoch: 6| Step: 12
Training loss: 2.048948049545288
Validation loss: 2.0479135538942073

Epoch: 6| Step: 13
Training loss: 1.8892476558685303
Validation loss: 2.0559285045951925

Epoch: 130| Step: 0
Training loss: 2.4489059448242188
Validation loss: 2.0325894650592597

Epoch: 6| Step: 1
Training loss: 2.245464324951172
Validation loss: 2.0095148753094416

Epoch: 6| Step: 2
Training loss: 1.1226437091827393
Validation loss: 2.0266558098536667

Epoch: 6| Step: 3
Training loss: 2.000548839569092
Validation loss: 2.030826880085853

Epoch: 6| Step: 4
Training loss: 1.2368724346160889
Validation loss: 2.037003295395964

Epoch: 6| Step: 5
Training loss: 1.0129637718200684
Validation loss: 2.0373505366745817

Epoch: 6| Step: 6
Training loss: 2.988880157470703
Validation loss: 2.0533910400124005

Epoch: 6| Step: 7
Training loss: 1.57870352268219
Validation loss: 2.0584220604229997

Epoch: 6| Step: 8
Training loss: 2.1388068199157715
Validation loss: 2.0591967785230247

Epoch: 6| Step: 9
Training loss: 2.4368996620178223
Validation loss: 2.06488440498229

Epoch: 6| Step: 10
Training loss: 2.370495319366455
Validation loss: 2.0594618192283054

Epoch: 6| Step: 11
Training loss: 2.0020554065704346
Validation loss: 2.0581407495724258

Epoch: 6| Step: 12
Training loss: 2.2587594985961914
Validation loss: 2.042192050205764

Epoch: 6| Step: 13
Training loss: 1.6032403707504272
Validation loss: 2.0273317534436464

Epoch: 131| Step: 0
Training loss: 1.5824631452560425
Validation loss: 2.0355193358595653

Epoch: 6| Step: 1
Training loss: 2.3051838874816895
Validation loss: 2.0338760781031784

Epoch: 6| Step: 2
Training loss: 2.4465150833129883
Validation loss: 2.0405387622053905

Epoch: 6| Step: 3
Training loss: 2.031508684158325
Validation loss: 2.024365012363721

Epoch: 6| Step: 4
Training loss: 1.5496103763580322
Validation loss: 2.01187644209913

Epoch: 6| Step: 5
Training loss: 1.0159366130828857
Validation loss: 2.0179615789844143

Epoch: 6| Step: 6
Training loss: 2.281975746154785
Validation loss: 1.9992607229499406

Epoch: 6| Step: 7
Training loss: 2.4385385513305664
Validation loss: 1.9976380384096535

Epoch: 6| Step: 8
Training loss: 1.7609763145446777
Validation loss: 1.996675149086983

Epoch: 6| Step: 9
Training loss: 2.0666556358337402
Validation loss: 1.9841153813946633

Epoch: 6| Step: 10
Training loss: 1.7620580196380615
Validation loss: 1.980539350099461

Epoch: 6| Step: 11
Training loss: 2.6135635375976562
Validation loss: 1.9780799804195281

Epoch: 6| Step: 12
Training loss: 1.7083919048309326
Validation loss: 1.9753711095420263

Epoch: 6| Step: 13
Training loss: 1.9022581577301025
Validation loss: 1.9724182877489316

Epoch: 132| Step: 0
Training loss: 1.7004127502441406
Validation loss: 1.9693970436690955

Epoch: 6| Step: 1
Training loss: 1.9768035411834717
Validation loss: 1.9874096057748283

Epoch: 6| Step: 2
Training loss: 1.581725001335144
Validation loss: 1.9918076633125223

Epoch: 6| Step: 3
Training loss: 2.278167247772217
Validation loss: 2.014320583753688

Epoch: 6| Step: 4
Training loss: 1.76887845993042
Validation loss: 2.0592368187442904

Epoch: 6| Step: 5
Training loss: 2.2944774627685547
Validation loss: 2.0931301783489924

Epoch: 6| Step: 6
Training loss: 1.2289721965789795
Validation loss: 2.115866773871965

Epoch: 6| Step: 7
Training loss: 1.7667059898376465
Validation loss: 2.137812024803572

Epoch: 6| Step: 8
Training loss: 1.5859365463256836
Validation loss: 2.106388420187017

Epoch: 6| Step: 9
Training loss: 2.8705103397369385
Validation loss: 2.0941810197727655

Epoch: 6| Step: 10
Training loss: 1.8445848226547241
Validation loss: 2.069306504341864

Epoch: 6| Step: 11
Training loss: 2.1780879497528076
Validation loss: 2.0545838391909035

Epoch: 6| Step: 12
Training loss: 2.5251917839050293
Validation loss: 2.0559344099413965

Epoch: 6| Step: 13
Training loss: 1.7380620241165161
Validation loss: 2.046630479956186

Epoch: 133| Step: 0
Training loss: 2.192971706390381
Validation loss: 2.0082402639491583

Epoch: 6| Step: 1
Training loss: 2.0983848571777344
Validation loss: 2.0033195595587454

Epoch: 6| Step: 2
Training loss: 2.180389881134033
Validation loss: 1.980379440451181

Epoch: 6| Step: 3
Training loss: 2.234829902648926
Validation loss: 1.9782889363586262

Epoch: 6| Step: 4
Training loss: 1.7632603645324707
Validation loss: 1.9679846712338027

Epoch: 6| Step: 5
Training loss: 2.0113563537597656
Validation loss: 1.9735350275552401

Epoch: 6| Step: 6
Training loss: 1.7168859243392944
Validation loss: 1.9812545212366248

Epoch: 6| Step: 7
Training loss: 1.0268934965133667
Validation loss: 1.999127108563659

Epoch: 6| Step: 8
Training loss: 2.479642868041992
Validation loss: 2.0237774874574397

Epoch: 6| Step: 9
Training loss: 2.3037075996398926
Validation loss: 2.026071499752742

Epoch: 6| Step: 10
Training loss: 1.8453941345214844
Validation loss: 2.0354458144916

Epoch: 6| Step: 11
Training loss: 1.5788003206253052
Validation loss: 2.0544872501845

Epoch: 6| Step: 12
Training loss: 1.9574713706970215
Validation loss: 2.0779778752275693

Epoch: 6| Step: 13
Training loss: 1.9530798196792603
Validation loss: 2.0730258521213325

Epoch: 134| Step: 0
Training loss: 2.150144100189209
Validation loss: 2.0421668803820046

Epoch: 6| Step: 1
Training loss: 1.7565346956253052
Validation loss: 2.03305321867748

Epoch: 6| Step: 2
Training loss: 1.8410390615463257
Validation loss: 2.0476278156362553

Epoch: 6| Step: 3
Training loss: 1.5438456535339355
Validation loss: 2.072845466675297

Epoch: 6| Step: 4
Training loss: 2.037713050842285
Validation loss: 2.0797989919621456

Epoch: 6| Step: 5
Training loss: 1.9234678745269775
Validation loss: 2.1214733841598674

Epoch: 6| Step: 6
Training loss: 2.0410497188568115
Validation loss: 2.1282365527204288

Epoch: 6| Step: 7
Training loss: 2.332170248031616
Validation loss: 2.1033417230011313

Epoch: 6| Step: 8
Training loss: 1.6819417476654053
Validation loss: 2.0617106191573606

Epoch: 6| Step: 9
Training loss: 2.0099809169769287
Validation loss: 2.0213542907468733

Epoch: 6| Step: 10
Training loss: 1.5897119045257568
Validation loss: 1.9905361001209547

Epoch: 6| Step: 11
Training loss: 2.1408514976501465
Validation loss: 1.9777215116767473

Epoch: 6| Step: 12
Training loss: 2.163820743560791
Validation loss: 1.9757894187845209

Epoch: 6| Step: 13
Training loss: 1.8832354545593262
Validation loss: 1.9636290829668763

Epoch: 135| Step: 0
Training loss: 1.413585901260376
Validation loss: 1.9639307696332213

Epoch: 6| Step: 1
Training loss: 2.1679470539093018
Validation loss: 1.9665314689759286

Epoch: 6| Step: 2
Training loss: 1.6878935098648071
Validation loss: 1.9647323687871296

Epoch: 6| Step: 3
Training loss: 1.8901386260986328
Validation loss: 1.9820179490632908

Epoch: 6| Step: 4
Training loss: 2.6315293312072754
Validation loss: 1.984435503200818

Epoch: 6| Step: 5
Training loss: 2.1611812114715576
Validation loss: 2.0121200623050814

Epoch: 6| Step: 6
Training loss: 2.4816854000091553
Validation loss: 1.9901108690487441

Epoch: 6| Step: 7
Training loss: 1.5340332984924316
Validation loss: 1.9794450344577912

Epoch: 6| Step: 8
Training loss: 2.2640514373779297
Validation loss: 1.9841687128108034

Epoch: 6| Step: 9
Training loss: 1.361374855041504
Validation loss: 1.9887723153637302

Epoch: 6| Step: 10
Training loss: 1.0907187461853027
Validation loss: 1.987064520517985

Epoch: 6| Step: 11
Training loss: 2.046085834503174
Validation loss: 1.9919798399812432

Epoch: 6| Step: 12
Training loss: 2.3760647773742676
Validation loss: 1.9874793893547469

Epoch: 6| Step: 13
Training loss: 2.062502861022949
Validation loss: 2.0175048317960513

Epoch: 136| Step: 0
Training loss: 1.8434476852416992
Validation loss: 2.0274311906547955

Epoch: 6| Step: 1
Training loss: 1.949547529220581
Validation loss: 2.0731032650957824

Epoch: 6| Step: 2
Training loss: 2.678971767425537
Validation loss: 2.086080333238007

Epoch: 6| Step: 3
Training loss: 2.5139267444610596
Validation loss: 2.091912160637558

Epoch: 6| Step: 4
Training loss: 2.3368749618530273
Validation loss: 2.077846388663015

Epoch: 6| Step: 5
Training loss: 1.2386760711669922
Validation loss: 2.066562324441889

Epoch: 6| Step: 6
Training loss: 1.1249282360076904
Validation loss: 2.0559760857653875

Epoch: 6| Step: 7
Training loss: 2.369633913040161
Validation loss: 2.055473264827523

Epoch: 6| Step: 8
Training loss: 0.8747797012329102
Validation loss: 2.0411533899204706

Epoch: 6| Step: 9
Training loss: 1.735058069229126
Validation loss: 2.034527660698019

Epoch: 6| Step: 10
Training loss: 2.3521809577941895
Validation loss: 2.0320282059331096

Epoch: 6| Step: 11
Training loss: 1.875731110572815
Validation loss: 2.0251717567443848

Epoch: 6| Step: 12
Training loss: 1.8911653757095337
Validation loss: 2.017083442339333

Epoch: 6| Step: 13
Training loss: 1.7978577613830566
Validation loss: 2.007409426473802

Epoch: 137| Step: 0
Training loss: 2.2502222061157227
Validation loss: 1.9987598901153893

Epoch: 6| Step: 1
Training loss: 1.9956859350204468
Validation loss: 1.9861503493401311

Epoch: 6| Step: 2
Training loss: 1.5755932331085205
Validation loss: 1.98881620489141

Epoch: 6| Step: 3
Training loss: 1.338315486907959
Validation loss: 2.001443483496225

Epoch: 6| Step: 4
Training loss: 2.4835305213928223
Validation loss: 1.9888201964798795

Epoch: 6| Step: 5
Training loss: 1.623457431793213
Validation loss: 1.9987370916592178

Epoch: 6| Step: 6
Training loss: 1.6226112842559814
Validation loss: 1.975007236644786

Epoch: 6| Step: 7
Training loss: 2.22864031791687
Validation loss: 1.9838681477372364

Epoch: 6| Step: 8
Training loss: 2.4843735694885254
Validation loss: 1.9989862621471446

Epoch: 6| Step: 9
Training loss: 2.4151663780212402
Validation loss: 2.002226621873917

Epoch: 6| Step: 10
Training loss: 1.5892369747161865
Validation loss: 2.001763951393866

Epoch: 6| Step: 11
Training loss: 1.2875319719314575
Validation loss: 2.009632001640976

Epoch: 6| Step: 12
Training loss: 1.3552489280700684
Validation loss: 1.9943179238227107

Epoch: 6| Step: 13
Training loss: 1.976387858390808
Validation loss: 2.012371127323438

Epoch: 138| Step: 0
Training loss: 2.131925582885742
Validation loss: 2.0156367901832826

Epoch: 6| Step: 1
Training loss: 2.066551685333252
Validation loss: 2.037687768218338

Epoch: 6| Step: 2
Training loss: 1.6802735328674316
Validation loss: 2.0183704783839564

Epoch: 6| Step: 3
Training loss: 2.185570478439331
Validation loss: 2.0132397323526363

Epoch: 6| Step: 4
Training loss: 1.473733901977539
Validation loss: 2.003515169184695

Epoch: 6| Step: 5
Training loss: 1.8748658895492554
Validation loss: 2.0081148416765275

Epoch: 6| Step: 6
Training loss: 1.860417366027832
Validation loss: 1.998988546350951

Epoch: 6| Step: 7
Training loss: 1.3943440914154053
Validation loss: 1.99598224957784

Epoch: 6| Step: 8
Training loss: 2.1410346031188965
Validation loss: 1.9946801380444599

Epoch: 6| Step: 9
Training loss: 1.8933448791503906
Validation loss: 1.9844305746016964

Epoch: 6| Step: 10
Training loss: 2.079986572265625
Validation loss: 1.9635593057960592

Epoch: 6| Step: 11
Training loss: 1.5272939205169678
Validation loss: 1.9704519023177445

Epoch: 6| Step: 12
Training loss: 1.9242417812347412
Validation loss: 1.9769556778733448

Epoch: 6| Step: 13
Training loss: 1.914711594581604
Validation loss: 1.9930157199982674

Epoch: 139| Step: 0
Training loss: 1.87530517578125
Validation loss: 2.0123721463705904

Epoch: 6| Step: 1
Training loss: 1.5996304750442505
Validation loss: 2.0343079067045644

Epoch: 6| Step: 2
Training loss: 1.8033884763717651
Validation loss: 2.0715170598799184

Epoch: 6| Step: 3
Training loss: 2.153331756591797
Validation loss: 2.0573024698483047

Epoch: 6| Step: 4
Training loss: 1.820904016494751
Validation loss: 2.024725703782933

Epoch: 6| Step: 5
Training loss: 2.2529618740081787
Validation loss: 2.0094963914604596

Epoch: 6| Step: 6
Training loss: 1.9067153930664062
Validation loss: 2.0042014045100056

Epoch: 6| Step: 7
Training loss: 2.133385181427002
Validation loss: 2.0079438148006314

Epoch: 6| Step: 8
Training loss: 2.144670248031616
Validation loss: 2.0046799131619033

Epoch: 6| Step: 9
Training loss: 1.7138009071350098
Validation loss: 2.015119036038717

Epoch: 6| Step: 10
Training loss: 1.3699203729629517
Validation loss: 2.0091927436090287

Epoch: 6| Step: 11
Training loss: 2.159945487976074
Validation loss: 2.010200499206461

Epoch: 6| Step: 12
Training loss: 1.4165112972259521
Validation loss: 2.001828264164668

Epoch: 6| Step: 13
Training loss: 1.3717150688171387
Validation loss: 2.0014441910610405

Epoch: 140| Step: 0
Training loss: 1.3080227375030518
Validation loss: 2.0070364795705324

Epoch: 6| Step: 1
Training loss: 2.7690811157226562
Validation loss: 2.023795809797061

Epoch: 6| Step: 2
Training loss: 1.4249954223632812
Validation loss: 2.0116747322902886

Epoch: 6| Step: 3
Training loss: 2.2376904487609863
Validation loss: 2.0192222287577968

Epoch: 6| Step: 4
Training loss: 1.7141667604446411
Validation loss: 2.0461143575688845

Epoch: 6| Step: 5
Training loss: 1.0485308170318604
Validation loss: 2.0735729279056674

Epoch: 6| Step: 6
Training loss: 2.3576292991638184
Validation loss: 2.068911060210197

Epoch: 6| Step: 7
Training loss: 1.6844847202301025
Validation loss: 2.1103790575458157

Epoch: 6| Step: 8
Training loss: 1.609581708908081
Validation loss: 2.1297575773731356

Epoch: 6| Step: 9
Training loss: 1.9587465524673462
Validation loss: 2.1162176721839496

Epoch: 6| Step: 10
Training loss: 2.531393527984619
Validation loss: 2.0914252778535247

Epoch: 6| Step: 11
Training loss: 1.7629237174987793
Validation loss: 2.0440594534720145

Epoch: 6| Step: 12
Training loss: 1.3269366025924683
Validation loss: 2.0150280421780002

Epoch: 6| Step: 13
Training loss: 1.998228669166565
Validation loss: 1.9927494397727392

Epoch: 141| Step: 0
Training loss: 1.5516421794891357
Validation loss: 1.976407467678029

Epoch: 6| Step: 1
Training loss: 1.233091115951538
Validation loss: 1.9595820519231981

Epoch: 6| Step: 2
Training loss: 1.1254688501358032
Validation loss: 1.9714847636479202

Epoch: 6| Step: 3
Training loss: 2.3432960510253906
Validation loss: 1.9642452796300252

Epoch: 6| Step: 4
Training loss: 2.306514263153076
Validation loss: 1.968725573632025

Epoch: 6| Step: 5
Training loss: 2.4426913261413574
Validation loss: 1.9591083321520077

Epoch: 6| Step: 6
Training loss: 1.7663261890411377
Validation loss: 1.9715388949199388

Epoch: 6| Step: 7
Training loss: 1.6162309646606445
Validation loss: 1.9709404514681907

Epoch: 6| Step: 8
Training loss: 1.3677881956100464
Validation loss: 1.9875227251360494

Epoch: 6| Step: 9
Training loss: 2.0720934867858887
Validation loss: 1.9960915016871628

Epoch: 6| Step: 10
Training loss: 1.941719889640808
Validation loss: 2.0141024179356073

Epoch: 6| Step: 11
Training loss: 2.556246757507324
Validation loss: 2.0302112538327455

Epoch: 6| Step: 12
Training loss: 1.7466943264007568
Validation loss: 2.0395107782015236

Epoch: 6| Step: 13
Training loss: 1.4676405191421509
Validation loss: 2.032807691122896

Epoch: 142| Step: 0
Training loss: 0.9913451671600342
Validation loss: 2.0276513932853617

Epoch: 6| Step: 1
Training loss: 2.217451333999634
Validation loss: 2.0268493877944125

Epoch: 6| Step: 2
Training loss: 1.760295033454895
Validation loss: 2.0186829041409236

Epoch: 6| Step: 3
Training loss: 1.921899676322937
Validation loss: 2.0034571898880826

Epoch: 6| Step: 4
Training loss: 2.2150561809539795
Validation loss: 1.9925222678851056

Epoch: 6| Step: 5
Training loss: 1.955061674118042
Validation loss: 1.9801740941180979

Epoch: 6| Step: 6
Training loss: 1.9576683044433594
Validation loss: 1.984799083843026

Epoch: 6| Step: 7
Training loss: 1.7840427160263062
Validation loss: 1.9812351298588577

Epoch: 6| Step: 8
Training loss: 2.0156044960021973
Validation loss: 1.9779494167656027

Epoch: 6| Step: 9
Training loss: 1.2953495979309082
Validation loss: 1.9890083561661422

Epoch: 6| Step: 10
Training loss: 1.7061645984649658
Validation loss: 1.9762344719261251

Epoch: 6| Step: 11
Training loss: 1.3688884973526
Validation loss: 1.987398991020777

Epoch: 6| Step: 12
Training loss: 2.239401340484619
Validation loss: 1.9816328581943308

Epoch: 6| Step: 13
Training loss: 1.5800341367721558
Validation loss: 2.009451143203243

Epoch: 143| Step: 0
Training loss: 1.9954161643981934
Validation loss: 1.9949462875243156

Epoch: 6| Step: 1
Training loss: 2.3209433555603027
Validation loss: 2.016497299235354

Epoch: 6| Step: 2
Training loss: 2.2489876747131348
Validation loss: 2.0271687097446893

Epoch: 6| Step: 3
Training loss: 1.574272632598877
Validation loss: 2.007286271741313

Epoch: 6| Step: 4
Training loss: 1.2932016849517822
Validation loss: 1.9961792858698035

Epoch: 6| Step: 5
Training loss: 2.2358412742614746
Validation loss: 1.9964934138841526

Epoch: 6| Step: 6
Training loss: 1.6102979183197021
Validation loss: 1.9988668375117804

Epoch: 6| Step: 7
Training loss: 1.15775728225708
Validation loss: 1.9908620208822272

Epoch: 6| Step: 8
Training loss: 1.8455160856246948
Validation loss: 1.995393955579368

Epoch: 6| Step: 9
Training loss: 1.331989049911499
Validation loss: 2.0224386389537523

Epoch: 6| Step: 10
Training loss: 1.5964269638061523
Validation loss: 2.031447741293138

Epoch: 6| Step: 11
Training loss: 2.5811142921447754
Validation loss: 2.0624763632333405

Epoch: 6| Step: 12
Training loss: 2.2125916481018066
Validation loss: 2.0524151658499115

Epoch: 6| Step: 13
Training loss: 0.884855329990387
Validation loss: 2.053122515319496

Epoch: 144| Step: 0
Training loss: 0.6868876814842224
Validation loss: 2.0607652407820507

Epoch: 6| Step: 1
Training loss: 2.055731773376465
Validation loss: 2.0774229649574525

Epoch: 6| Step: 2
Training loss: 1.7332626581192017
Validation loss: 2.110086920440838

Epoch: 6| Step: 3
Training loss: 2.228610038757324
Validation loss: 2.122632303545552

Epoch: 6| Step: 4
Training loss: 1.6497119665145874
Validation loss: 2.123015785730013

Epoch: 6| Step: 5
Training loss: 2.189387798309326
Validation loss: 2.0828667879104614

Epoch: 6| Step: 6
Training loss: 1.6458169221878052
Validation loss: 2.026179290586902

Epoch: 6| Step: 7
Training loss: 2.3565471172332764
Validation loss: 2.026135654859645

Epoch: 6| Step: 8
Training loss: 1.772298812866211
Validation loss: 1.9793234845643402

Epoch: 6| Step: 9
Training loss: 1.541355848312378
Validation loss: 1.9893130089647026

Epoch: 6| Step: 10
Training loss: 1.9105098247528076
Validation loss: 1.9830420145424463

Epoch: 6| Step: 11
Training loss: 2.2323946952819824
Validation loss: 1.9822095927371775

Epoch: 6| Step: 12
Training loss: 1.6129262447357178
Validation loss: 1.9722430039477605

Epoch: 6| Step: 13
Training loss: 0.8293151259422302
Validation loss: 1.966337521870931

Epoch: 145| Step: 0
Training loss: 1.331005573272705
Validation loss: 1.944070036693286

Epoch: 6| Step: 1
Training loss: 1.9076673984527588
Validation loss: 1.9637180989788425

Epoch: 6| Step: 2
Training loss: 1.2373919486999512
Validation loss: 1.9560730226578251

Epoch: 6| Step: 3
Training loss: 1.4190629720687866
Validation loss: 1.9557674033667451

Epoch: 6| Step: 4
Training loss: 1.8781356811523438
Validation loss: 1.9708560743639547

Epoch: 6| Step: 5
Training loss: 2.2120797634124756
Validation loss: 1.985869728108888

Epoch: 6| Step: 6
Training loss: 2.090428352355957
Validation loss: 1.994905828147806

Epoch: 6| Step: 7
Training loss: 1.9445767402648926
Validation loss: 2.017803438248173

Epoch: 6| Step: 8
Training loss: 2.052245855331421
Validation loss: 2.0094584867518437

Epoch: 6| Step: 9
Training loss: 1.786588430404663
Validation loss: 2.003725258252954

Epoch: 6| Step: 10
Training loss: 1.4965219497680664
Validation loss: 2.022911412741548

Epoch: 6| Step: 11
Training loss: 1.3599779605865479
Validation loss: 2.035587364627469

Epoch: 6| Step: 12
Training loss: 1.6664557456970215
Validation loss: 2.0608267668754823

Epoch: 6| Step: 13
Training loss: 2.074101448059082
Validation loss: 2.094672196654863

Epoch: 146| Step: 0
Training loss: 1.7471407651901245
Validation loss: 2.1260925108386624

Epoch: 6| Step: 1
Training loss: 1.6743948459625244
Validation loss: 2.165080711405764

Epoch: 6| Step: 2
Training loss: 1.4809705018997192
Validation loss: 2.1689668445176977

Epoch: 6| Step: 3
Training loss: 1.2479248046875
Validation loss: 2.1661157992578324

Epoch: 6| Step: 4
Training loss: 1.7565641403198242
Validation loss: 2.1614815958084597

Epoch: 6| Step: 5
Training loss: 2.185011625289917
Validation loss: 2.171141496268652

Epoch: 6| Step: 6
Training loss: 1.7065913677215576
Validation loss: 2.136276314335485

Epoch: 6| Step: 7
Training loss: 1.5024727582931519
Validation loss: 2.1062473186882595

Epoch: 6| Step: 8
Training loss: 1.840814232826233
Validation loss: 2.0751752622665895

Epoch: 6| Step: 9
Training loss: 1.808459758758545
Validation loss: 2.0283269061837146

Epoch: 6| Step: 10
Training loss: 1.7294178009033203
Validation loss: 1.998649908650306

Epoch: 6| Step: 11
Training loss: 1.9209856986999512
Validation loss: 1.990321929736804

Epoch: 6| Step: 12
Training loss: 2.148540496826172
Validation loss: 1.956049951173926

Epoch: 6| Step: 13
Training loss: 1.8625311851501465
Validation loss: 1.9630130593494703

Epoch: 147| Step: 0
Training loss: 1.883695363998413
Validation loss: 1.9618339282210155

Epoch: 6| Step: 1
Training loss: 1.8953349590301514
Validation loss: 1.9667041878546438

Epoch: 6| Step: 2
Training loss: 1.549940586090088
Validation loss: 1.9985191078596218

Epoch: 6| Step: 3
Training loss: 1.2641431093215942
Validation loss: 2.0209736849672053

Epoch: 6| Step: 4
Training loss: 1.7658144235610962
Validation loss: 1.999041126620385

Epoch: 6| Step: 5
Training loss: 2.0153274536132812
Validation loss: 2.0107811061284875

Epoch: 6| Step: 6
Training loss: 1.5865674018859863
Validation loss: 2.0090189236466602

Epoch: 6| Step: 7
Training loss: 2.126739501953125
Validation loss: 2.023829242234589

Epoch: 6| Step: 8
Training loss: 1.7495970726013184
Validation loss: 2.0431802131796397

Epoch: 6| Step: 9
Training loss: 1.5974786281585693
Validation loss: 2.101407548432709

Epoch: 6| Step: 10
Training loss: 1.9589945077896118
Validation loss: 2.1701287146537536

Epoch: 6| Step: 11
Training loss: 2.028244972229004
Validation loss: 2.180918549978605

Epoch: 6| Step: 12
Training loss: 1.9752368927001953
Validation loss: 2.160994518187738

Epoch: 6| Step: 13
Training loss: 1.449425220489502
Validation loss: 2.078825919858871

Epoch: 148| Step: 0
Training loss: 2.4788174629211426
Validation loss: 1.9900799207789923

Epoch: 6| Step: 1
Training loss: 2.108602523803711
Validation loss: 1.981558527997745

Epoch: 6| Step: 2
Training loss: 1.6745660305023193
Validation loss: 1.970968456678493

Epoch: 6| Step: 3
Training loss: 0.9246928095817566
Validation loss: 1.9602571546390493

Epoch: 6| Step: 4
Training loss: 1.3796498775482178
Validation loss: 1.9657177771291425

Epoch: 6| Step: 5
Training loss: 2.493429183959961
Validation loss: 1.9693604964081959

Epoch: 6| Step: 6
Training loss: 1.643911600112915
Validation loss: 1.9594789679332445

Epoch: 6| Step: 7
Training loss: 2.1102817058563232
Validation loss: 1.9588949757237588

Epoch: 6| Step: 8
Training loss: 2.167384624481201
Validation loss: 1.9722953650259203

Epoch: 6| Step: 9
Training loss: 1.1950129270553589
Validation loss: 1.978882662711605

Epoch: 6| Step: 10
Training loss: 1.0626345872879028
Validation loss: 2.0028837252688665

Epoch: 6| Step: 11
Training loss: 2.0049407482147217
Validation loss: 2.033776192254918

Epoch: 6| Step: 12
Training loss: 1.079301357269287
Validation loss: 2.054087560663941

Epoch: 6| Step: 13
Training loss: 2.0854203701019287
Validation loss: 2.0884504202873475

Epoch: 149| Step: 0
Training loss: 1.6020886898040771
Validation loss: 2.117330274274272

Epoch: 6| Step: 1
Training loss: 1.8197828531265259
Validation loss: 2.1377257339416014

Epoch: 6| Step: 2
Training loss: 1.5224084854125977
Validation loss: 2.1404386976713776

Epoch: 6| Step: 3
Training loss: 1.8480302095413208
Validation loss: 2.154270225955594

Epoch: 6| Step: 4
Training loss: 2.0991876125335693
Validation loss: 2.1690802651066936

Epoch: 6| Step: 5
Training loss: 2.115939140319824
Validation loss: 2.171494786457349

Epoch: 6| Step: 6
Training loss: 1.3948304653167725
Validation loss: 2.152889831091768

Epoch: 6| Step: 7
Training loss: 1.8571631908416748
Validation loss: 2.1258118332073255

Epoch: 6| Step: 8
Training loss: 1.6769556999206543
Validation loss: 2.0991240214276057

Epoch: 6| Step: 9
Training loss: 1.1590335369110107
Validation loss: 2.090135548704414

Epoch: 6| Step: 10
Training loss: 1.6879651546478271
Validation loss: 2.068169725838528

Epoch: 6| Step: 11
Training loss: 2.3688454627990723
Validation loss: 2.025115869378531

Epoch: 6| Step: 12
Training loss: 1.1778700351715088
Validation loss: 1.9870609314210954

Epoch: 6| Step: 13
Training loss: 2.1162302494049072
Validation loss: 1.9638264973958333

Epoch: 150| Step: 0
Training loss: 1.447465419769287
Validation loss: 1.9590481519699097

Epoch: 6| Step: 1
Training loss: 1.4199755191802979
Validation loss: 1.9570383410299979

Epoch: 6| Step: 2
Training loss: 1.4965856075286865
Validation loss: 1.9689257644837903

Epoch: 6| Step: 3
Training loss: 2.0002193450927734
Validation loss: 1.9719760981939172

Epoch: 6| Step: 4
Training loss: 1.887729287147522
Validation loss: 1.9997493220913796

Epoch: 6| Step: 5
Training loss: 2.120248317718506
Validation loss: 2.0043140406249673

Epoch: 6| Step: 6
Training loss: 1.4622855186462402
Validation loss: 2.0099058305063555

Epoch: 6| Step: 7
Training loss: 1.8552452325820923
Validation loss: 2.0684668646063855

Epoch: 6| Step: 8
Training loss: 0.9835837483406067
Validation loss: 2.0820955179070912

Epoch: 6| Step: 9
Training loss: 2.0181446075439453
Validation loss: 2.09847161334048

Epoch: 6| Step: 10
Training loss: 1.8672934770584106
Validation loss: 2.105615909381579

Epoch: 6| Step: 11
Training loss: 1.7273547649383545
Validation loss: 2.1168165591455277

Epoch: 6| Step: 12
Training loss: 1.8405194282531738
Validation loss: 2.1462559648739394

Epoch: 6| Step: 13
Training loss: 2.0316147804260254
Validation loss: 2.1565475848413285

Epoch: 151| Step: 0
Training loss: 1.6871557235717773
Validation loss: 2.136117104561098

Epoch: 6| Step: 1
Training loss: 2.1033382415771484
Validation loss: 2.089329114524267

Epoch: 6| Step: 2
Training loss: 2.1203854084014893
Validation loss: 2.0287802552664154

Epoch: 6| Step: 3
Training loss: 2.0399205684661865
Validation loss: 2.0124231333373697

Epoch: 6| Step: 4
Training loss: 2.122866630554199
Validation loss: 1.99791927747829

Epoch: 6| Step: 5
Training loss: 1.3858786821365356
Validation loss: 1.9761332478574527

Epoch: 6| Step: 6
Training loss: 1.6229944229125977
Validation loss: 1.9655285804502425

Epoch: 6| Step: 7
Training loss: 1.465317726135254
Validation loss: 1.9626265982145905

Epoch: 6| Step: 8
Training loss: 1.6880234479904175
Validation loss: 1.9595481323939499

Epoch: 6| Step: 9
Training loss: 1.523066520690918
Validation loss: 1.961502944269488

Epoch: 6| Step: 10
Training loss: 1.438976526260376
Validation loss: 1.9695400871256346

Epoch: 6| Step: 11
Training loss: 1.5575263500213623
Validation loss: 1.9734558982233847

Epoch: 6| Step: 12
Training loss: 1.6740071773529053
Validation loss: 1.9922536162919895

Epoch: 6| Step: 13
Training loss: 1.4038066864013672
Validation loss: 2.014489289252989

Epoch: 152| Step: 0
Training loss: 1.1152422428131104
Validation loss: 2.045530956278565

Epoch: 6| Step: 1
Training loss: 1.6578800678253174
Validation loss: 2.0598340931759087

Epoch: 6| Step: 2
Training loss: 1.0626620054244995
Validation loss: 2.0660305715376333

Epoch: 6| Step: 3
Training loss: 1.1828725337982178
Validation loss: 2.060016550043578

Epoch: 6| Step: 4
Training loss: 1.8555684089660645
Validation loss: 2.0647751567184285

Epoch: 6| Step: 5
Training loss: 2.3026440143585205
Validation loss: 2.0574014289404756

Epoch: 6| Step: 6
Training loss: 1.7025480270385742
Validation loss: 2.045785568093741

Epoch: 6| Step: 7
Training loss: 1.8935904502868652
Validation loss: 2.026357966084634

Epoch: 6| Step: 8
Training loss: 1.8194578886032104
Validation loss: 2.0020175390346076

Epoch: 6| Step: 9
Training loss: 1.5866410732269287
Validation loss: 1.9818555052562425

Epoch: 6| Step: 10
Training loss: 1.85932457447052
Validation loss: 1.976592194649481

Epoch: 6| Step: 11
Training loss: 1.4272842407226562
Validation loss: 1.9823812412959274

Epoch: 6| Step: 12
Training loss: 2.09277606010437
Validation loss: 1.993739216558395

Epoch: 6| Step: 13
Training loss: 1.2400784492492676
Validation loss: 1.986680515350834

Epoch: 153| Step: 0
Training loss: 1.825378179550171
Validation loss: 1.9974721952151226

Epoch: 6| Step: 1
Training loss: 2.30424165725708
Validation loss: 1.992850770232498

Epoch: 6| Step: 2
Training loss: 1.8374016284942627
Validation loss: 2.006764886199787

Epoch: 6| Step: 3
Training loss: 1.6707658767700195
Validation loss: 2.0182074872396325

Epoch: 6| Step: 4
Training loss: 1.6206594705581665
Validation loss: 2.042156339973532

Epoch: 6| Step: 5
Training loss: 0.969606876373291
Validation loss: 2.079784301019484

Epoch: 6| Step: 6
Training loss: 1.3743562698364258
Validation loss: 2.116326141101058

Epoch: 6| Step: 7
Training loss: 1.8583719730377197
Validation loss: 2.1441422572699924

Epoch: 6| Step: 8
Training loss: 1.6291415691375732
Validation loss: 2.169839882081555

Epoch: 6| Step: 9
Training loss: 1.5092357397079468
Validation loss: 2.17450039873841

Epoch: 6| Step: 10
Training loss: 1.6636769771575928
Validation loss: 2.1483158680700485

Epoch: 6| Step: 11
Training loss: 1.4424214363098145
Validation loss: 2.1100225038425897

Epoch: 6| Step: 12
Training loss: 2.0222880840301514
Validation loss: 2.0342853966579644

Epoch: 6| Step: 13
Training loss: 1.0485401153564453
Validation loss: 1.9990860800589285

Epoch: 154| Step: 0
Training loss: 1.5050148963928223
Validation loss: 1.9909579471875263

Epoch: 6| Step: 1
Training loss: 1.3366005420684814
Validation loss: 1.979013168683616

Epoch: 6| Step: 2
Training loss: 1.336031436920166
Validation loss: 1.9843087785987443

Epoch: 6| Step: 3
Training loss: 2.1768336296081543
Validation loss: 1.9974036024462791

Epoch: 6| Step: 4
Training loss: 1.5355544090270996
Validation loss: 2.009329911201231

Epoch: 6| Step: 5
Training loss: 1.4862041473388672
Validation loss: 2.022771748163367

Epoch: 6| Step: 6
Training loss: 1.3373522758483887
Validation loss: 2.0394612640462895

Epoch: 6| Step: 7
Training loss: 1.8952839374542236
Validation loss: 2.0965846712871263

Epoch: 6| Step: 8
Training loss: 1.4090063571929932
Validation loss: 2.120684331463229

Epoch: 6| Step: 9
Training loss: 1.717988133430481
Validation loss: 2.108161421232326

Epoch: 6| Step: 10
Training loss: 2.1312594413757324
Validation loss: 2.0962208611990816

Epoch: 6| Step: 11
Training loss: 1.9938215017318726
Validation loss: 2.073266287003794

Epoch: 6| Step: 12
Training loss: 1.8936879634857178
Validation loss: 2.0714758929385932

Epoch: 6| Step: 13
Training loss: 1.3031901121139526
Validation loss: 2.0393977344677015

Epoch: 155| Step: 0
Training loss: 1.001218557357788
Validation loss: 1.9940485467192948

Epoch: 6| Step: 1
Training loss: 1.4460155963897705
Validation loss: 1.9717574427204747

Epoch: 6| Step: 2
Training loss: 1.7162864208221436
Validation loss: 1.9549648505385204

Epoch: 6| Step: 3
Training loss: 2.04853892326355
Validation loss: 1.9604193779730028

Epoch: 6| Step: 4
Training loss: 1.541797399520874
Validation loss: 1.9611067310456307

Epoch: 6| Step: 5
Training loss: 2.380824089050293
Validation loss: 1.9673953030699043

Epoch: 6| Step: 6
Training loss: 1.654965877532959
Validation loss: 1.9609917799631755

Epoch: 6| Step: 7
Training loss: 1.790439486503601
Validation loss: 1.9565274971787647

Epoch: 6| Step: 8
Training loss: 2.0366744995117188
Validation loss: 1.9879283738392655

Epoch: 6| Step: 9
Training loss: 1.4597320556640625
Validation loss: 2.009799685529483

Epoch: 6| Step: 10
Training loss: 1.3903369903564453
Validation loss: 2.035274872215845

Epoch: 6| Step: 11
Training loss: 1.0049221515655518
Validation loss: 2.0431963410428775

Epoch: 6| Step: 12
Training loss: 1.3116014003753662
Validation loss: 2.047557096327505

Epoch: 6| Step: 13
Training loss: 2.2308883666992188
Validation loss: 2.047765710020578

Epoch: 156| Step: 0
Training loss: 1.9488178491592407
Validation loss: 2.061965480927498

Epoch: 6| Step: 1
Training loss: 1.7686032056808472
Validation loss: 2.0552276129363687

Epoch: 6| Step: 2
Training loss: 1.9991363286972046
Validation loss: 2.093084232781523

Epoch: 6| Step: 3
Training loss: 1.1468658447265625
Validation loss: 2.120732679161974

Epoch: 6| Step: 4
Training loss: 1.4838942289352417
Validation loss: 2.1118236485347954

Epoch: 6| Step: 5
Training loss: 1.225966453552246
Validation loss: 2.1049248223663657

Epoch: 6| Step: 6
Training loss: 1.2105331420898438
Validation loss: 2.1344802866699877

Epoch: 6| Step: 7
Training loss: 1.5616538524627686
Validation loss: 2.114667448946225

Epoch: 6| Step: 8
Training loss: 1.5613508224487305
Validation loss: 2.10807692363698

Epoch: 6| Step: 9
Training loss: 1.5237693786621094
Validation loss: 2.0683454518677085

Epoch: 6| Step: 10
Training loss: 1.9861805438995361
Validation loss: 2.0393411087733444

Epoch: 6| Step: 11
Training loss: 1.9792929887771606
Validation loss: 2.0036301817945255

Epoch: 6| Step: 12
Training loss: 0.9125481843948364
Validation loss: 1.9701828302875641

Epoch: 6| Step: 13
Training loss: 1.4774373769760132
Validation loss: 1.967046107015302

Epoch: 157| Step: 0
Training loss: 2.1566221714019775
Validation loss: 1.9473249117533367

Epoch: 6| Step: 1
Training loss: 1.1277413368225098
Validation loss: 1.9452916524743522

Epoch: 6| Step: 2
Training loss: 1.6439118385314941
Validation loss: 1.9362596222149429

Epoch: 6| Step: 3
Training loss: 1.649247169494629
Validation loss: 1.9588398138682048

Epoch: 6| Step: 4
Training loss: 1.5273871421813965
Validation loss: 1.9969760756338797

Epoch: 6| Step: 5
Training loss: 1.5725867748260498
Validation loss: 2.048124517163923

Epoch: 6| Step: 6
Training loss: 0.7534394264221191
Validation loss: 2.1099590845005487

Epoch: 6| Step: 7
Training loss: 1.9120385646820068
Validation loss: 2.0945059509687525

Epoch: 6| Step: 8
Training loss: 1.1296820640563965
Validation loss: 2.048769122810774

Epoch: 6| Step: 9
Training loss: 1.742147445678711
Validation loss: 2.0380245741977485

Epoch: 6| Step: 10
Training loss: 2.1456797122955322
Validation loss: 2.0078206036680486

Epoch: 6| Step: 11
Training loss: 1.521212100982666
Validation loss: 2.0096614078808854

Epoch: 6| Step: 12
Training loss: 1.1331818103790283
Validation loss: 2.0171474923369703

Epoch: 6| Step: 13
Training loss: 2.2101247310638428
Validation loss: 2.025994857152303

Epoch: 158| Step: 0
Training loss: 1.241485595703125
Validation loss: 2.02096111800081

Epoch: 6| Step: 1
Training loss: 1.1247453689575195
Validation loss: 2.026412372948021

Epoch: 6| Step: 2
Training loss: 2.391202211380005
Validation loss: 2.046644713288994

Epoch: 6| Step: 3
Training loss: 1.3545098304748535
Validation loss: 2.045879243522562

Epoch: 6| Step: 4
Training loss: 2.071024179458618
Validation loss: 2.06412499566232

Epoch: 6| Step: 5
Training loss: 1.6566005945205688
Validation loss: 2.0609111478251796

Epoch: 6| Step: 6
Training loss: 1.5717121362686157
Validation loss: 2.044622177718788

Epoch: 6| Step: 7
Training loss: 1.4645886421203613
Validation loss: 2.0393048396674534

Epoch: 6| Step: 8
Training loss: 1.4873602390289307
Validation loss: 2.0187345602179088

Epoch: 6| Step: 9
Training loss: 1.9259591102600098
Validation loss: 1.9829172254890524

Epoch: 6| Step: 10
Training loss: 0.9720719456672668
Validation loss: 1.9808400215641144

Epoch: 6| Step: 11
Training loss: 1.339410662651062
Validation loss: 2.009187816291727

Epoch: 6| Step: 12
Training loss: 1.599932074546814
Validation loss: 1.987179810001004

Epoch: 6| Step: 13
Training loss: 1.1274199485778809
Validation loss: 2.022753072041337

Epoch: 159| Step: 0
Training loss: 1.222832441329956
Validation loss: 2.0166992884810253

Epoch: 6| Step: 1
Training loss: 1.4368441104888916
Validation loss: 1.9983294087071573

Epoch: 6| Step: 2
Training loss: 1.6680774688720703
Validation loss: 1.999083495909168

Epoch: 6| Step: 3
Training loss: 1.4215344190597534
Validation loss: 1.9839353023036834

Epoch: 6| Step: 4
Training loss: 0.6506823301315308
Validation loss: 2.0150592839846047

Epoch: 6| Step: 5
Training loss: 2.0359530448913574
Validation loss: 2.0759191602788944

Epoch: 6| Step: 6
Training loss: 1.5465730428695679
Validation loss: 2.112267517274426

Epoch: 6| Step: 7
Training loss: 1.7479808330535889
Validation loss: 2.05796383273217

Epoch: 6| Step: 8
Training loss: 1.7048977613449097
Validation loss: 2.0363057249335834

Epoch: 6| Step: 9
Training loss: 1.96744966506958
Validation loss: 2.0179443526011642

Epoch: 6| Step: 10
Training loss: 1.0965619087219238
Validation loss: 2.002088374989007

Epoch: 6| Step: 11
Training loss: 2.4513802528381348
Validation loss: 1.9758337351583666

Epoch: 6| Step: 12
Training loss: 0.7271242737770081
Validation loss: 1.977577579918728

Epoch: 6| Step: 13
Training loss: 1.702965259552002
Validation loss: 1.965504361737159

Epoch: 160| Step: 0
Training loss: 1.163597822189331
Validation loss: 2.026597164010489

Epoch: 6| Step: 1
Training loss: 1.6460539102554321
Validation loss: 2.0694415236032135

Epoch: 6| Step: 2
Training loss: 1.3459268808364868
Validation loss: 2.106916566048899

Epoch: 6| Step: 3
Training loss: 1.812873125076294
Validation loss: 2.11866565673582

Epoch: 6| Step: 4
Training loss: 1.6164156198501587
Validation loss: 2.1102726985049505

Epoch: 6| Step: 5
Training loss: 1.880927562713623
Validation loss: 2.0519651969273887

Epoch: 6| Step: 6
Training loss: 1.533879280090332
Validation loss: 1.9780373996303928

Epoch: 6| Step: 7
Training loss: 0.976333498954773
Validation loss: 1.971863877388739

Epoch: 6| Step: 8
Training loss: 1.4792693853378296
Validation loss: 1.946789349279096

Epoch: 6| Step: 9
Training loss: 1.6574546098709106
Validation loss: 1.9601350574083225

Epoch: 6| Step: 10
Training loss: 1.490058422088623
Validation loss: 1.9941513563997002

Epoch: 6| Step: 11
Training loss: 1.6375441551208496
Validation loss: 2.050833358559557

Epoch: 6| Step: 12
Training loss: 1.78961181640625
Validation loss: 2.1065297254952053

Epoch: 6| Step: 13
Training loss: 0.9556567072868347
Validation loss: 2.1221719275238695

Epoch: 161| Step: 0
Training loss: 1.6475416421890259
Validation loss: 2.0938201130077405

Epoch: 6| Step: 1
Training loss: 1.6671571731567383
Validation loss: 2.0984392601956605

Epoch: 6| Step: 2
Training loss: 2.1158394813537598
Validation loss: 2.0973598982698176

Epoch: 6| Step: 3
Training loss: 1.3224422931671143
Validation loss: 2.0534705461994296

Epoch: 6| Step: 4
Training loss: 1.1092952489852905
Validation loss: 2.0382019589024205

Epoch: 6| Step: 5
Training loss: 1.2777385711669922
Validation loss: 1.998757726402693

Epoch: 6| Step: 6
Training loss: 1.4515972137451172
Validation loss: 1.9781245134210075

Epoch: 6| Step: 7
Training loss: 1.7003545761108398
Validation loss: 1.9603721916034658

Epoch: 6| Step: 8
Training loss: 1.7274506092071533
Validation loss: 1.9726631436296689

Epoch: 6| Step: 9
Training loss: 1.4566540718078613
Validation loss: 2.0210646993370465

Epoch: 6| Step: 10
Training loss: 1.5443228483200073
Validation loss: 2.0919593123979467

Epoch: 6| Step: 11
Training loss: 1.5298534631729126
Validation loss: 2.1600746159912436

Epoch: 6| Step: 12
Training loss: 1.1458274126052856
Validation loss: 2.1867671397424515

Epoch: 6| Step: 13
Training loss: 1.0809881687164307
Validation loss: 2.2222695965920725

Epoch: 162| Step: 0
Training loss: 1.4154353141784668
Validation loss: 2.1653333197357836

Epoch: 6| Step: 1
Training loss: 1.458947777748108
Validation loss: 2.124574843273368

Epoch: 6| Step: 2
Training loss: 1.0593234300613403
Validation loss: 2.0854314142657864

Epoch: 6| Step: 3
Training loss: 1.5883443355560303
Validation loss: 2.025928174295733

Epoch: 6| Step: 4
Training loss: 1.3796511888504028
Validation loss: 2.032439313909059

Epoch: 6| Step: 5
Training loss: 1.2930034399032593
Validation loss: 2.0068658910771853

Epoch: 6| Step: 6
Training loss: 1.6693060398101807
Validation loss: 2.0182732984583867

Epoch: 6| Step: 7
Training loss: 2.0053467750549316
Validation loss: 1.9933108116990776

Epoch: 6| Step: 8
Training loss: 1.5178247690200806
Validation loss: 1.9707031314091017

Epoch: 6| Step: 9
Training loss: 1.1706194877624512
Validation loss: 1.9565302120741976

Epoch: 6| Step: 10
Training loss: 1.2020354270935059
Validation loss: 1.969442852081791

Epoch: 6| Step: 11
Training loss: 2.270169734954834
Validation loss: 1.9979532200803038

Epoch: 6| Step: 12
Training loss: 1.492464303970337
Validation loss: 2.0486998814408497

Epoch: 6| Step: 13
Training loss: 1.4763981103897095
Validation loss: 2.0825745264689126

Epoch: 163| Step: 0
Training loss: 1.7850909233093262
Validation loss: 2.113934246442651

Epoch: 6| Step: 1
Training loss: 1.419750452041626
Validation loss: 2.1370620573720625

Epoch: 6| Step: 2
Training loss: 1.5058119297027588
Validation loss: 2.136018749206297

Epoch: 6| Step: 3
Training loss: 1.877431869506836
Validation loss: 2.0991900467103526

Epoch: 6| Step: 4
Training loss: 0.9569365382194519
Validation loss: 2.0893756343472387

Epoch: 6| Step: 5
Training loss: 1.084653377532959
Validation loss: 2.040881447894599

Epoch: 6| Step: 6
Training loss: 1.4667401313781738
Validation loss: 2.040502437981226

Epoch: 6| Step: 7
Training loss: 1.647773265838623
Validation loss: 2.0488368285599576

Epoch: 6| Step: 8
Training loss: 1.6479134559631348
Validation loss: 2.060435543778122

Epoch: 6| Step: 9
Training loss: 1.641435146331787
Validation loss: 2.056280266854071

Epoch: 6| Step: 10
Training loss: 1.1882820129394531
Validation loss: 2.0565736268156316

Epoch: 6| Step: 11
Training loss: 1.5430352687835693
Validation loss: 2.0920756504099858

Epoch: 6| Step: 12
Training loss: 1.6990776062011719
Validation loss: 2.1063483761202906

Epoch: 6| Step: 13
Training loss: 1.305956244468689
Validation loss: 2.088947915261792

Epoch: 164| Step: 0
Training loss: 1.7211291790008545
Validation loss: 2.0487730067263366

Epoch: 6| Step: 1
Training loss: 1.410426378250122
Validation loss: 2.0282984702817854

Epoch: 6| Step: 2
Training loss: 1.217759609222412
Validation loss: 2.0221226138453328

Epoch: 6| Step: 3
Training loss: 1.631966233253479
Validation loss: 2.0393761909136208

Epoch: 6| Step: 4
Training loss: 1.2977573871612549
Validation loss: 2.032756923347391

Epoch: 6| Step: 5
Training loss: 1.3064522743225098
Validation loss: 2.0271920709199804

Epoch: 6| Step: 6
Training loss: 1.2936947345733643
Validation loss: 2.0341608267958446

Epoch: 6| Step: 7
Training loss: 1.9905544519424438
Validation loss: 2.0530039443764636

Epoch: 6| Step: 8
Training loss: 1.7304664850234985
Validation loss: 2.0964322692604473

Epoch: 6| Step: 9
Training loss: 2.092418909072876
Validation loss: 2.1302483722727787

Epoch: 6| Step: 10
Training loss: 1.9223743677139282
Validation loss: 2.144657786174487

Epoch: 6| Step: 11
Training loss: 1.395127296447754
Validation loss: 2.1316369630957164

Epoch: 6| Step: 12
Training loss: 1.3182237148284912
Validation loss: 2.0955142282670542

Epoch: 6| Step: 13
Training loss: 1.546296238899231
Validation loss: 2.0648540604499077

Epoch: 165| Step: 0
Training loss: 1.8389687538146973
Validation loss: 1.9816744404454385

Epoch: 6| Step: 1
Training loss: 1.7066547870635986
Validation loss: 1.9659500750162269

Epoch: 6| Step: 2
Training loss: 1.358803629875183
Validation loss: 2.0039212472977175

Epoch: 6| Step: 3
Training loss: 1.3685132265090942
Validation loss: 1.980003172351468

Epoch: 6| Step: 4
Training loss: 1.7083438634872437
Validation loss: 1.981593665256295

Epoch: 6| Step: 5
Training loss: 1.368361473083496
Validation loss: 2.0079620474128315

Epoch: 6| Step: 6
Training loss: 1.4012740850448608
Validation loss: 2.043094176118092

Epoch: 6| Step: 7
Training loss: 1.455078363418579
Validation loss: 2.060889997789937

Epoch: 6| Step: 8
Training loss: 1.4555203914642334
Validation loss: 2.076571738848122

Epoch: 6| Step: 9
Training loss: 1.6682910919189453
Validation loss: 2.110082685306508

Epoch: 6| Step: 10
Training loss: 1.4464993476867676
Validation loss: 2.147282782421317

Epoch: 6| Step: 11
Training loss: 1.7345821857452393
Validation loss: 2.1449416837384625

Epoch: 6| Step: 12
Training loss: 1.568894863128662
Validation loss: 2.172999844756178

Epoch: 6| Step: 13
Training loss: 0.7247142791748047
Validation loss: 2.109356250814212

Epoch: 166| Step: 0
Training loss: 1.8689320087432861
Validation loss: 2.0748936860792098

Epoch: 6| Step: 1
Training loss: 1.235089659690857
Validation loss: 2.044013040040129

Epoch: 6| Step: 2
Training loss: 1.4260848760604858
Validation loss: 2.039415301815156

Epoch: 6| Step: 3
Training loss: 1.4203124046325684
Validation loss: 2.0361435528724425

Epoch: 6| Step: 4
Training loss: 1.8187036514282227
Validation loss: 2.0224707677800167

Epoch: 6| Step: 5
Training loss: 1.3196358680725098
Validation loss: 1.9850820995146228

Epoch: 6| Step: 6
Training loss: 1.5167176723480225
Validation loss: 1.9839947736391457

Epoch: 6| Step: 7
Training loss: 1.901329755783081
Validation loss: 1.9770908406985703

Epoch: 6| Step: 8
Training loss: 1.2760145664215088
Validation loss: 1.9618625807505783

Epoch: 6| Step: 9
Training loss: 1.4785490036010742
Validation loss: 1.9687224511177308

Epoch: 6| Step: 10
Training loss: 1.4677528142929077
Validation loss: 1.9794547814194874

Epoch: 6| Step: 11
Training loss: 1.0066795349121094
Validation loss: 1.9991739872963197

Epoch: 6| Step: 12
Training loss: 1.3944212198257446
Validation loss: 2.0527663794896935

Epoch: 6| Step: 13
Training loss: 1.1115208864212036
Validation loss: 2.0937577703947663

Epoch: 167| Step: 0
Training loss: 1.1799120903015137
Validation loss: 2.15303873759444

Epoch: 6| Step: 1
Training loss: 1.3707835674285889
Validation loss: 2.16168390294557

Epoch: 6| Step: 2
Training loss: 1.339123010635376
Validation loss: 2.1165292621940694

Epoch: 6| Step: 3
Training loss: 1.659069538116455
Validation loss: 2.0597891910101778

Epoch: 6| Step: 4
Training loss: 1.4289230108261108
Validation loss: 2.0197593217254965

Epoch: 6| Step: 5
Training loss: 1.0927793979644775
Validation loss: 1.9924766658454813

Epoch: 6| Step: 6
Training loss: 0.8100742697715759
Validation loss: 1.9950058460235596

Epoch: 6| Step: 7
Training loss: 2.1866869926452637
Validation loss: 2.016262900444769

Epoch: 6| Step: 8
Training loss: 1.1505717039108276
Validation loss: 2.0170706830998903

Epoch: 6| Step: 9
Training loss: 1.3673276901245117
Validation loss: 2.004060476056991

Epoch: 6| Step: 10
Training loss: 1.3205524682998657
Validation loss: 1.9876355548058786

Epoch: 6| Step: 11
Training loss: 1.9108856916427612
Validation loss: 1.9694045256542903

Epoch: 6| Step: 12
Training loss: 1.7177789211273193
Validation loss: 2.0204795073437434

Epoch: 6| Step: 13
Training loss: 0.9085708260536194
Validation loss: 2.0316722175126434

Epoch: 168| Step: 0
Training loss: 1.386509895324707
Validation loss: 2.0251644221685265

Epoch: 6| Step: 1
Training loss: 1.1853562593460083
Validation loss: 2.026845419278709

Epoch: 6| Step: 2
Training loss: 2.075706958770752
Validation loss: 2.0313243519875313

Epoch: 6| Step: 3
Training loss: 1.828906536102295
Validation loss: 2.0085550046736196

Epoch: 6| Step: 4
Training loss: 1.2104448080062866
Validation loss: 2.028573848867929

Epoch: 6| Step: 5
Training loss: 1.5655384063720703
Validation loss: 2.0064778827851817

Epoch: 6| Step: 6
Training loss: 1.7147693634033203
Validation loss: 2.001330191089261

Epoch: 6| Step: 7
Training loss: 1.1924145221710205
Validation loss: 1.9891016765307354

Epoch: 6| Step: 8
Training loss: 1.481797456741333
Validation loss: 2.023129032504174

Epoch: 6| Step: 9
Training loss: 1.431984543800354
Validation loss: 2.0355878863283383

Epoch: 6| Step: 10
Training loss: 1.089860439300537
Validation loss: 2.0481246979005876

Epoch: 6| Step: 11
Training loss: 1.3216416835784912
Validation loss: 2.0347637591823453

Epoch: 6| Step: 12
Training loss: 1.0036649703979492
Validation loss: 2.073682403051725

Epoch: 6| Step: 13
Training loss: 1.2681689262390137
Validation loss: 2.070370184477939

Epoch: 169| Step: 0
Training loss: 1.2567732334136963
Validation loss: 2.0825631541590535

Epoch: 6| Step: 1
Training loss: 2.1493148803710938
Validation loss: 2.062241987515521

Epoch: 6| Step: 2
Training loss: 0.9074093699455261
Validation loss: 2.0549546005905315

Epoch: 6| Step: 3
Training loss: 1.5179524421691895
Validation loss: 2.0365424745826313

Epoch: 6| Step: 4
Training loss: 1.5322493314743042
Validation loss: 2.0389870136014876

Epoch: 6| Step: 5
Training loss: 1.7504429817199707
Validation loss: 2.038648674564977

Epoch: 6| Step: 6
Training loss: 1.295151710510254
Validation loss: 2.0478873842506

Epoch: 6| Step: 7
Training loss: 0.8012925982475281
Validation loss: 2.0481046579217397

Epoch: 6| Step: 8
Training loss: 1.004822015762329
Validation loss: 2.0558149609514462

Epoch: 6| Step: 9
Training loss: 0.8196031451225281
Validation loss: 2.0559794825892292

Epoch: 6| Step: 10
Training loss: 1.289482831954956
Validation loss: 2.0810137089862617

Epoch: 6| Step: 11
Training loss: 1.8912259340286255
Validation loss: 2.0598050804548365

Epoch: 6| Step: 12
Training loss: 1.4251527786254883
Validation loss: 2.0250892869887815

Epoch: 6| Step: 13
Training loss: 2.3182835578918457
Validation loss: 1.9846852825533958

Epoch: 170| Step: 0
Training loss: 1.9820952415466309
Validation loss: 1.9688914347720403

Epoch: 6| Step: 1
Training loss: 1.3576604127883911
Validation loss: 1.9536595946999007

Epoch: 6| Step: 2
Training loss: 1.5587584972381592
Validation loss: 1.9620739824028426

Epoch: 6| Step: 3
Training loss: 1.1819239854812622
Validation loss: 1.960430149109133

Epoch: 6| Step: 4
Training loss: 1.8309208154678345
Validation loss: 1.9880039999561925

Epoch: 6| Step: 5
Training loss: 1.5056958198547363
Validation loss: 2.0252727718763452

Epoch: 6| Step: 6
Training loss: 1.389906644821167
Validation loss: 2.0691540087423017

Epoch: 6| Step: 7
Training loss: 1.484212040901184
Validation loss: 2.0727902458560084

Epoch: 6| Step: 8
Training loss: 1.0473051071166992
Validation loss: 2.0878109124399002

Epoch: 6| Step: 9
Training loss: 0.8120352625846863
Validation loss: 2.11064976005144

Epoch: 6| Step: 10
Training loss: 1.2101969718933105
Validation loss: 2.1151251510907243

Epoch: 6| Step: 11
Training loss: 1.5743169784545898
Validation loss: 2.0827257761391262

Epoch: 6| Step: 12
Training loss: 1.104250192642212
Validation loss: 2.0418876550530873

Epoch: 6| Step: 13
Training loss: 1.7987736463546753
Validation loss: 1.9968175118969334

Epoch: 171| Step: 0
Training loss: 1.3832560777664185
Validation loss: 1.9684327699804818

Epoch: 6| Step: 1
Training loss: 1.0876562595367432
Validation loss: 1.9582634484896095

Epoch: 6| Step: 2
Training loss: 1.6623404026031494
Validation loss: 1.9578678761759112

Epoch: 6| Step: 3
Training loss: 1.2780787944793701
Validation loss: 1.959787602065712

Epoch: 6| Step: 4
Training loss: 1.989485263824463
Validation loss: 1.9563436892724806

Epoch: 6| Step: 5
Training loss: 1.3006585836410522
Validation loss: 1.9504212153855192

Epoch: 6| Step: 6
Training loss: 1.3804785013198853
Validation loss: 1.9536018063945155

Epoch: 6| Step: 7
Training loss: 1.3589470386505127
Validation loss: 1.9909774488018406

Epoch: 6| Step: 8
Training loss: 1.4739670753479004
Validation loss: 2.0202019727358254

Epoch: 6| Step: 9
Training loss: 1.3748652935028076
Validation loss: 2.0520160454575733

Epoch: 6| Step: 10
Training loss: 1.0656596422195435
Validation loss: 2.1051829502146733

Epoch: 6| Step: 11
Training loss: 1.944279670715332
Validation loss: 2.1057079351076515

Epoch: 6| Step: 12
Training loss: 0.9630376100540161
Validation loss: 2.0454597524417344

Epoch: 6| Step: 13
Training loss: 1.343996524810791
Validation loss: 2.008188521990212

Epoch: 172| Step: 0
Training loss: 1.0512135028839111
Validation loss: 1.9952582966896795

Epoch: 6| Step: 1
Training loss: 1.7533117532730103
Validation loss: 1.9606771417843398

Epoch: 6| Step: 2
Training loss: 1.4225389957427979
Validation loss: 1.9368981289607223

Epoch: 6| Step: 3
Training loss: 0.97467041015625
Validation loss: 1.9422866413670201

Epoch: 6| Step: 4
Training loss: 1.3734139204025269
Validation loss: 1.9604257909200524

Epoch: 6| Step: 5
Training loss: 1.3390802145004272
Validation loss: 1.9712054191097137

Epoch: 6| Step: 6
Training loss: 1.2985094785690308
Validation loss: 2.000666860611208

Epoch: 6| Step: 7
Training loss: 1.514606237411499
Validation loss: 2.0221980771710797

Epoch: 6| Step: 8
Training loss: 1.5157217979431152
Validation loss: 2.0613242599271957

Epoch: 6| Step: 9
Training loss: 1.5504429340362549
Validation loss: 2.103664876312338

Epoch: 6| Step: 10
Training loss: 1.0207571983337402
Validation loss: 2.149819959876358

Epoch: 6| Step: 11
Training loss: 1.544245958328247
Validation loss: 2.16278136673794

Epoch: 6| Step: 12
Training loss: 1.1884773969650269
Validation loss: 2.159029233840204

Epoch: 6| Step: 13
Training loss: 1.7367706298828125
Validation loss: 2.1146919112051688

Epoch: 173| Step: 0
Training loss: 1.5655487775802612
Validation loss: 2.0500565011014222

Epoch: 6| Step: 1
Training loss: 1.3654067516326904
Validation loss: 1.9965311993834793

Epoch: 6| Step: 2
Training loss: 0.9061038494110107
Validation loss: 1.9469681670588832

Epoch: 6| Step: 3
Training loss: 1.536865234375
Validation loss: 1.929655417319267

Epoch: 6| Step: 4
Training loss: 1.8270536661148071
Validation loss: 1.9202083028772825

Epoch: 6| Step: 5
Training loss: 0.8832239508628845
Validation loss: 1.9158805313930716

Epoch: 6| Step: 6
Training loss: 1.216277837753296
Validation loss: 1.9097156127293904

Epoch: 6| Step: 7
Training loss: 1.3437901735305786
Validation loss: 1.9297101882196241

Epoch: 6| Step: 8
Training loss: 1.0536627769470215
Validation loss: 1.9269692827296514

Epoch: 6| Step: 9
Training loss: 2.087075710296631
Validation loss: 1.9504732598540604

Epoch: 6| Step: 10
Training loss: 1.55216646194458
Validation loss: 1.9858615706043858

Epoch: 6| Step: 11
Training loss: 1.6691590547561646
Validation loss: 2.027161746896723

Epoch: 6| Step: 12
Training loss: 0.9617268443107605
Validation loss: 2.044353861962595

Epoch: 6| Step: 13
Training loss: 1.1778982877731323
Validation loss: 2.0171203074916715

Epoch: 174| Step: 0
Training loss: 1.2454185485839844
Validation loss: 2.0737681132490917

Epoch: 6| Step: 1
Training loss: 1.260617733001709
Validation loss: 2.085693028665358

Epoch: 6| Step: 2
Training loss: 0.7997284531593323
Validation loss: 2.0558893488299463

Epoch: 6| Step: 3
Training loss: 1.2186572551727295
Validation loss: 2.0389493639751146

Epoch: 6| Step: 4
Training loss: 1.7021939754486084
Validation loss: 2.0087656820974042

Epoch: 6| Step: 5
Training loss: 1.2842984199523926
Validation loss: 1.9738372936043689

Epoch: 6| Step: 6
Training loss: 1.3915057182312012
Validation loss: 1.9382532194096556

Epoch: 6| Step: 7
Training loss: 1.8965842723846436
Validation loss: 1.9359604889346707

Epoch: 6| Step: 8
Training loss: 0.9940094351768494
Validation loss: 1.9317442422272058

Epoch: 6| Step: 9
Training loss: 1.2108820676803589
Validation loss: 1.9404060391969578

Epoch: 6| Step: 10
Training loss: 1.1347618103027344
Validation loss: 1.972880478828184

Epoch: 6| Step: 11
Training loss: 1.6217622756958008
Validation loss: 1.971100531598573

Epoch: 6| Step: 12
Training loss: 1.3603551387786865
Validation loss: 1.9779542966555523

Epoch: 6| Step: 13
Training loss: 1.473146915435791
Validation loss: 2.021424998519241

Epoch: 175| Step: 0
Training loss: 1.3363511562347412
Validation loss: 2.050254547467796

Epoch: 6| Step: 1
Training loss: 1.1859405040740967
Validation loss: 2.053407633176414

Epoch: 6| Step: 2
Training loss: 1.53928542137146
Validation loss: 2.033681067087317

Epoch: 6| Step: 3
Training loss: 1.304330587387085
Validation loss: 2.01254044553285

Epoch: 6| Step: 4
Training loss: 0.7395918369293213
Validation loss: 1.992127990209928

Epoch: 6| Step: 5
Training loss: 1.2319037914276123
Validation loss: 1.9705769067169518

Epoch: 6| Step: 6
Training loss: 1.6969587802886963
Validation loss: 1.9884076400469708

Epoch: 6| Step: 7
Training loss: 0.9620181322097778
Validation loss: 1.98792463989668

Epoch: 6| Step: 8
Training loss: 1.337423324584961
Validation loss: 2.0155671206853722

Epoch: 6| Step: 9
Training loss: 1.580987572669983
Validation loss: 2.041145290097883

Epoch: 6| Step: 10
Training loss: 1.7285188436508179
Validation loss: 2.0646998369565575

Epoch: 6| Step: 11
Training loss: 1.5303908586502075
Validation loss: 2.04859879068149

Epoch: 6| Step: 12
Training loss: 0.6930657625198364
Validation loss: 2.0677109687559065

Epoch: 6| Step: 13
Training loss: 1.0786792039871216
Validation loss: 2.070145030175486

Epoch: 176| Step: 0
Training loss: 0.9093141555786133
Validation loss: 2.0438417632092714

Epoch: 6| Step: 1
Training loss: 1.3978767395019531
Validation loss: 2.004891913424256

Epoch: 6| Step: 2
Training loss: 0.41555914282798767
Validation loss: 1.9641478061676025

Epoch: 6| Step: 3
Training loss: 1.3462798595428467
Validation loss: 1.9682297437421736

Epoch: 6| Step: 4
Training loss: 1.9819276332855225
Validation loss: 1.9569558866562382

Epoch: 6| Step: 5
Training loss: 1.6422669887542725
Validation loss: 1.9622539781755017

Epoch: 6| Step: 6
Training loss: 1.4486916065216064
Validation loss: 1.974549372990926

Epoch: 6| Step: 7
Training loss: 1.3937745094299316
Validation loss: 1.990007544076571

Epoch: 6| Step: 8
Training loss: 1.532945156097412
Validation loss: 1.997225369176557

Epoch: 6| Step: 9
Training loss: 0.9985554218292236
Validation loss: 1.9879153441357356

Epoch: 6| Step: 10
Training loss: 1.108689785003662
Validation loss: 2.0107966199997933

Epoch: 6| Step: 11
Training loss: 0.804041862487793
Validation loss: 2.0012387024459017

Epoch: 6| Step: 12
Training loss: 1.4524118900299072
Validation loss: 2.0329705451124456

Epoch: 6| Step: 13
Training loss: 1.7769427299499512
Validation loss: 2.051689019767187

Epoch: 177| Step: 0
Training loss: 1.3188689947128296
Validation loss: 2.0501410153604325

Epoch: 6| Step: 1
Training loss: 1.5145502090454102
Validation loss: 2.026254238620881

Epoch: 6| Step: 2
Training loss: 1.5288853645324707
Validation loss: 2.0224289099375405

Epoch: 6| Step: 3
Training loss: 0.958717942237854
Validation loss: 2.0175918917502127

Epoch: 6| Step: 4
Training loss: 1.1471264362335205
Validation loss: 1.987575836079095

Epoch: 6| Step: 5
Training loss: 1.2116392850875854
Validation loss: 1.95665200935897

Epoch: 6| Step: 6
Training loss: 0.9580898284912109
Validation loss: 1.9875287368733396

Epoch: 6| Step: 7
Training loss: 1.1966201066970825
Validation loss: 1.997554886725641

Epoch: 6| Step: 8
Training loss: 1.6068191528320312
Validation loss: 2.004114076655398

Epoch: 6| Step: 9
Training loss: 1.543313980102539
Validation loss: 2.0302886168162027

Epoch: 6| Step: 10
Training loss: 1.1142337322235107
Validation loss: 2.004828727373513

Epoch: 6| Step: 11
Training loss: 1.0674023628234863
Validation loss: 1.9963802829865487

Epoch: 6| Step: 12
Training loss: 1.4502904415130615
Validation loss: 1.9786141713460286

Epoch: 6| Step: 13
Training loss: 0.8905242085456848
Validation loss: 1.9890548721436532

Epoch: 178| Step: 0
Training loss: 1.8317053318023682
Validation loss: 1.9474852418386808

Epoch: 6| Step: 1
Training loss: 1.3851021528244019
Validation loss: 1.9371727000000656

Epoch: 6| Step: 2
Training loss: 1.1696290969848633
Validation loss: 1.9514334945268528

Epoch: 6| Step: 3
Training loss: 0.9219884276390076
Validation loss: 1.9668839182904971

Epoch: 6| Step: 4
Training loss: 1.152578592300415
Validation loss: 1.972152615106234

Epoch: 6| Step: 5
Training loss: 0.9381691217422485
Validation loss: 1.9692455337893577

Epoch: 6| Step: 6
Training loss: 1.1671011447906494
Validation loss: 1.9885839493043962

Epoch: 6| Step: 7
Training loss: 1.3455078601837158
Validation loss: 2.010319707214191

Epoch: 6| Step: 8
Training loss: 1.2645854949951172
Validation loss: 2.0319646660999586

Epoch: 6| Step: 9
Training loss: 1.1602511405944824
Validation loss: 2.0791625156197497

Epoch: 6| Step: 10
Training loss: 2.030378818511963
Validation loss: 2.1059137313596663

Epoch: 6| Step: 11
Training loss: 0.8863184452056885
Validation loss: 2.060528747497066

Epoch: 6| Step: 12
Training loss: 1.1839754581451416
Validation loss: 2.0521530182130876

Epoch: 6| Step: 13
Training loss: 0.9044606685638428
Validation loss: 2.0613483498173375

Epoch: 179| Step: 0
Training loss: 1.4958992004394531
Validation loss: 2.0562025436791043

Epoch: 6| Step: 1
Training loss: 1.464010238647461
Validation loss: 2.04566538974803

Epoch: 6| Step: 2
Training loss: 2.0130391120910645
Validation loss: 2.0239672583918416

Epoch: 6| Step: 3
Training loss: 1.2235534191131592
Validation loss: 2.041870346633337

Epoch: 6| Step: 4
Training loss: 1.0896557569503784
Validation loss: 1.9749027170160764

Epoch: 6| Step: 5
Training loss: 1.3626327514648438
Validation loss: 1.9431401350164925

Epoch: 6| Step: 6
Training loss: 1.4287124872207642
Validation loss: 1.9182944887427873

Epoch: 6| Step: 7
Training loss: 1.0667017698287964
Validation loss: 1.9079050376851072

Epoch: 6| Step: 8
Training loss: 2.167299747467041
Validation loss: 1.8897435101129676

Epoch: 6| Step: 9
Training loss: 0.9294654130935669
Validation loss: 1.9071939786275227

Epoch: 6| Step: 10
Training loss: 0.7718939781188965
Validation loss: 1.9371941653631066

Epoch: 6| Step: 11
Training loss: 0.6917725801467896
Validation loss: 1.9726703397689327

Epoch: 6| Step: 12
Training loss: 1.0756386518478394
Validation loss: 2.0049154822544386

Epoch: 6| Step: 13
Training loss: 0.8836610913276672
Validation loss: 2.0191002750909455

Epoch: 180| Step: 0
Training loss: 1.450416922569275
Validation loss: 2.076165430007442

Epoch: 6| Step: 1
Training loss: 0.8079583644866943
Validation loss: 2.038308233343145

Epoch: 6| Step: 2
Training loss: 1.0524495840072632
Validation loss: 2.0116314682909238

Epoch: 6| Step: 3
Training loss: 0.953174352645874
Validation loss: 1.9360084328600156

Epoch: 6| Step: 4
Training loss: 1.030352234840393
Validation loss: 1.9106554882500761

Epoch: 6| Step: 5
Training loss: 0.8854592442512512
Validation loss: 1.8988040813835718

Epoch: 6| Step: 6
Training loss: 1.4249134063720703
Validation loss: 1.8621145807286745

Epoch: 6| Step: 7
Training loss: 2.2689294815063477
Validation loss: 1.8704805374145508

Epoch: 6| Step: 8
Training loss: 1.7548651695251465
Validation loss: 1.8881536837547057

Epoch: 6| Step: 9
Training loss: 0.9639978408813477
Validation loss: 1.8964146875566052

Epoch: 6| Step: 10
Training loss: 1.324244737625122
Validation loss: 1.9240153310119466

Epoch: 6| Step: 11
Training loss: 1.0821142196655273
Validation loss: 1.951970467003443

Epoch: 6| Step: 12
Training loss: 0.8122929334640503
Validation loss: 1.996162708087634

Epoch: 6| Step: 13
Training loss: 1.900795578956604
Validation loss: 2.116427101114745

Epoch: 181| Step: 0
Training loss: 1.5800886154174805
Validation loss: 2.219988848573418

Epoch: 6| Step: 1
Training loss: 1.7439311742782593
Validation loss: 2.2015215068735103

Epoch: 6| Step: 2
Training loss: 1.3063805103302002
Validation loss: 2.0678082768635084

Epoch: 6| Step: 3
Training loss: 1.3745253086090088
Validation loss: 1.9628565849796418

Epoch: 6| Step: 4
Training loss: 1.3408722877502441
Validation loss: 1.9087307978701848

Epoch: 6| Step: 5
Training loss: 1.4247019290924072
Validation loss: 1.9166986685927196

Epoch: 6| Step: 6
Training loss: 1.2419323921203613
Validation loss: 1.9525398746613534

Epoch: 6| Step: 7
Training loss: 2.183039665222168
Validation loss: 1.9493107846988145

Epoch: 6| Step: 8
Training loss: 1.4605841636657715
Validation loss: 1.959533909315704

Epoch: 6| Step: 9
Training loss: 1.1007250547409058
Validation loss: 1.9577551246971212

Epoch: 6| Step: 10
Training loss: 1.734068751335144
Validation loss: 1.9313377718771658

Epoch: 6| Step: 11
Training loss: 0.6642140746116638
Validation loss: 1.923567174583353

Epoch: 6| Step: 12
Training loss: 1.1600337028503418
Validation loss: 1.9565707406690043

Epoch: 6| Step: 13
Training loss: 1.0083184242248535
Validation loss: 1.9731951195706603

Epoch: 182| Step: 0
Training loss: 1.3853466510772705
Validation loss: 2.0121125713471444

Epoch: 6| Step: 1
Training loss: 1.0744402408599854
Validation loss: 2.071824527555896

Epoch: 6| Step: 2
Training loss: 1.6838428974151611
Validation loss: 2.117185918233728

Epoch: 6| Step: 3
Training loss: 0.9429395794868469
Validation loss: 2.109391775182498

Epoch: 6| Step: 4
Training loss: 1.124767541885376
Validation loss: 2.1535286890563143

Epoch: 6| Step: 5
Training loss: 1.9897199869155884
Validation loss: 2.13155198097229

Epoch: 6| Step: 6
Training loss: 1.3125877380371094
Validation loss: 2.127919404737411

Epoch: 6| Step: 7
Training loss: 1.608439326286316
Validation loss: 2.0488310398594027

Epoch: 6| Step: 8
Training loss: 1.1279953718185425
Validation loss: 2.0035082473549792

Epoch: 6| Step: 9
Training loss: 1.3358184099197388
Validation loss: 1.9468848577109716

Epoch: 6| Step: 10
Training loss: 0.8732916116714478
Validation loss: 1.9023272375906668

Epoch: 6| Step: 11
Training loss: 1.0897817611694336
Validation loss: 1.8545982324948875

Epoch: 6| Step: 12
Training loss: 0.9740052223205566
Validation loss: 1.8585377790594613

Epoch: 6| Step: 13
Training loss: 1.1045351028442383
Validation loss: 1.854823084287746

Epoch: 183| Step: 0
Training loss: 1.0465210676193237
Validation loss: 1.826747404631748

Epoch: 6| Step: 1
Training loss: 1.5919418334960938
Validation loss: 1.8483609717379335

Epoch: 6| Step: 2
Training loss: 1.1317991018295288
Validation loss: 1.857939738099293

Epoch: 6| Step: 3
Training loss: 1.4842545986175537
Validation loss: 1.8974676978203557

Epoch: 6| Step: 4
Training loss: 0.8809055089950562
Validation loss: 1.9822796672903082

Epoch: 6| Step: 5
Training loss: 1.5410263538360596
Validation loss: 2.014989350431709

Epoch: 6| Step: 6
Training loss: 0.8898729681968689
Validation loss: 2.076763940113847

Epoch: 6| Step: 7
Training loss: 1.3668453693389893
Validation loss: 2.1398748941318964

Epoch: 6| Step: 8
Training loss: 0.9211896657943726
Validation loss: 2.117716985364114

Epoch: 6| Step: 9
Training loss: 0.9988160729408264
Validation loss: 2.102957481979042

Epoch: 6| Step: 10
Training loss: 1.428593635559082
Validation loss: 2.067879935746552

Epoch: 6| Step: 11
Training loss: 1.601606011390686
Validation loss: 2.0390530991297897

Epoch: 6| Step: 12
Training loss: 0.928969144821167
Validation loss: 2.02207552361232

Epoch: 6| Step: 13
Training loss: 1.7550528049468994
Validation loss: 1.9468359857477167

Epoch: 184| Step: 0
Training loss: 1.3681704998016357
Validation loss: 1.9004361757668116

Epoch: 6| Step: 1
Training loss: 0.5328274965286255
Validation loss: 1.8664048615322317

Epoch: 6| Step: 2
Training loss: 1.3905959129333496
Validation loss: 1.8610459527661722

Epoch: 6| Step: 3
Training loss: 1.1794869899749756
Validation loss: 1.844901091309004

Epoch: 6| Step: 4
Training loss: 1.8454748392105103
Validation loss: 1.8663801185546383

Epoch: 6| Step: 5
Training loss: 1.3855795860290527
Validation loss: 1.854545784252946

Epoch: 6| Step: 6
Training loss: 0.9758644104003906
Validation loss: 1.8834756176958802

Epoch: 6| Step: 7
Training loss: 0.8369060754776001
Validation loss: 1.9422799143739926

Epoch: 6| Step: 8
Training loss: 1.0661604404449463
Validation loss: 2.016434789985739

Epoch: 6| Step: 9
Training loss: 1.0962203741073608
Validation loss: 2.0508562646886355

Epoch: 6| Step: 10
Training loss: 1.4952465295791626
Validation loss: 2.1399344731402654

Epoch: 6| Step: 11
Training loss: 1.5213693380355835
Validation loss: 2.171065704796904

Epoch: 6| Step: 12
Training loss: 1.3374297618865967
Validation loss: 2.185741924470471

Epoch: 6| Step: 13
Training loss: 2.1811110973358154
Validation loss: 2.164072072634133

Epoch: 185| Step: 0
Training loss: 1.0968761444091797
Validation loss: 2.085949868284246

Epoch: 6| Step: 1
Training loss: 1.3852460384368896
Validation loss: 1.9800021238224481

Epoch: 6| Step: 2
Training loss: 0.7704548239707947
Validation loss: 1.9157156636638026

Epoch: 6| Step: 3
Training loss: 1.8139832019805908
Validation loss: 1.8958884695524811

Epoch: 6| Step: 4
Training loss: 0.9877207279205322
Validation loss: 1.891405713173651

Epoch: 6| Step: 5
Training loss: 1.127246618270874
Validation loss: 1.9054982200745614

Epoch: 6| Step: 6
Training loss: 1.7952042818069458
Validation loss: 1.904309198420535

Epoch: 6| Step: 7
Training loss: 1.904301643371582
Validation loss: 1.9000498992140575

Epoch: 6| Step: 8
Training loss: 1.150094747543335
Validation loss: 1.848609733325179

Epoch: 6| Step: 9
Training loss: 1.4763126373291016
Validation loss: 1.8333739978010937

Epoch: 6| Step: 10
Training loss: 1.405648946762085
Validation loss: 1.8291703924056022

Epoch: 6| Step: 11
Training loss: 1.3298380374908447
Validation loss: 1.8411584541361818

Epoch: 6| Step: 12
Training loss: 1.2932090759277344
Validation loss: 1.9079566924802718

Epoch: 6| Step: 13
Training loss: 1.4178926944732666
Validation loss: 2.000287071351082

Epoch: 186| Step: 0
Training loss: 1.5100092887878418
Validation loss: 2.1332078338951193

Epoch: 6| Step: 1
Training loss: 0.9933654069900513
Validation loss: 2.2204439383681103

Epoch: 6| Step: 2
Training loss: 1.6474655866622925
Validation loss: 2.2290968959049513

Epoch: 6| Step: 3
Training loss: 0.8731436729431152
Validation loss: 2.208733263836112

Epoch: 6| Step: 4
Training loss: 1.2891985177993774
Validation loss: 2.1354647195467384

Epoch: 6| Step: 5
Training loss: 1.2398571968078613
Validation loss: 2.0766811024758125

Epoch: 6| Step: 6
Training loss: 1.4550607204437256
Validation loss: 2.0203975823617752

Epoch: 6| Step: 7
Training loss: 1.4634454250335693
Validation loss: 2.001183532899426

Epoch: 6| Step: 8
Training loss: 1.1200631856918335
Validation loss: 1.9642123522297028

Epoch: 6| Step: 9
Training loss: 1.600697636604309
Validation loss: 1.9389365232118996

Epoch: 6| Step: 10
Training loss: 1.5893702507019043
Validation loss: 1.9382409305982693

Epoch: 6| Step: 11
Training loss: 1.2016196250915527
Validation loss: 1.9386197136294456

Epoch: 6| Step: 12
Training loss: 1.0329418182373047
Validation loss: 1.924996470892301

Epoch: 6| Step: 13
Training loss: 1.0464725494384766
Validation loss: 1.9299180289750457

Epoch: 187| Step: 0
Training loss: 1.3263318538665771
Validation loss: 1.910391967783692

Epoch: 6| Step: 1
Training loss: 1.289140224456787
Validation loss: 1.933474071564213

Epoch: 6| Step: 2
Training loss: 1.2359925508499146
Validation loss: 1.9693300185665008

Epoch: 6| Step: 3
Training loss: 1.688002347946167
Validation loss: 1.9617000754161547

Epoch: 6| Step: 4
Training loss: 0.869997501373291
Validation loss: 2.0119792261431293

Epoch: 6| Step: 5
Training loss: 0.9479467868804932
Validation loss: 2.0387477503027966

Epoch: 6| Step: 6
Training loss: 1.628416657447815
Validation loss: 2.0399459664539625

Epoch: 6| Step: 7
Training loss: 1.393535852432251
Validation loss: 2.0444542874572096

Epoch: 6| Step: 8
Training loss: 0.9639899730682373
Validation loss: 2.048622449239095

Epoch: 6| Step: 9
Training loss: 1.2831525802612305
Validation loss: 2.0399287490434546

Epoch: 6| Step: 10
Training loss: 1.200165033340454
Validation loss: 2.014806435954186

Epoch: 6| Step: 11
Training loss: 0.9060119390487671
Validation loss: 2.006023835110408

Epoch: 6| Step: 12
Training loss: 0.81369948387146
Validation loss: 1.9825316449647308

Epoch: 6| Step: 13
Training loss: 0.5165109634399414
Validation loss: 1.9712451991214548

Epoch: 188| Step: 0
Training loss: 1.7153308391571045
Validation loss: 1.9510426495664863

Epoch: 6| Step: 1
Training loss: 1.3721479177474976
Validation loss: 1.9407082655096566

Epoch: 6| Step: 2
Training loss: 1.3754167556762695
Validation loss: 1.9432693963409753

Epoch: 6| Step: 3
Training loss: 1.1146255731582642
Validation loss: 1.953666986957673

Epoch: 6| Step: 4
Training loss: 1.008208990097046
Validation loss: 1.9669191132309616

Epoch: 6| Step: 5
Training loss: 1.287937045097351
Validation loss: 1.9794674868224769

Epoch: 6| Step: 6
Training loss: 1.2609590291976929
Validation loss: 2.0185514111672678

Epoch: 6| Step: 7
Training loss: 0.7242851257324219
Validation loss: 2.065662399415047

Epoch: 6| Step: 8
Training loss: 1.1529897451400757
Validation loss: 2.070233024576659

Epoch: 6| Step: 9
Training loss: 1.0147994756698608
Validation loss: 2.032857523169569

Epoch: 6| Step: 10
Training loss: 0.8421987891197205
Validation loss: 1.996753102989607

Epoch: 6| Step: 11
Training loss: 1.0263681411743164
Validation loss: 1.981247499424924

Epoch: 6| Step: 12
Training loss: 1.2319903373718262
Validation loss: 1.9810531408556047

Epoch: 6| Step: 13
Training loss: 0.8907244205474854
Validation loss: 1.9492766434146511

Epoch: 189| Step: 0
Training loss: 0.9387175440788269
Validation loss: 1.930759850368705

Epoch: 6| Step: 1
Training loss: 0.6221152544021606
Validation loss: 1.925675683124091

Epoch: 6| Step: 2
Training loss: 0.9416402578353882
Validation loss: 1.9229827798822874

Epoch: 6| Step: 3
Training loss: 1.7616699934005737
Validation loss: 1.9337342131522395

Epoch: 6| Step: 4
Training loss: 1.006675362586975
Validation loss: 1.954886846644904

Epoch: 6| Step: 5
Training loss: 1.1471344232559204
Validation loss: 1.990759943121223

Epoch: 6| Step: 6
Training loss: 1.3111820220947266
Validation loss: 1.9843640788908927

Epoch: 6| Step: 7
Training loss: 1.2495067119598389
Validation loss: 1.9773395779312297

Epoch: 6| Step: 8
Training loss: 0.9444060325622559
Validation loss: 2.0303204187782864

Epoch: 6| Step: 9
Training loss: 1.1791632175445557
Validation loss: 2.0265412663900726

Epoch: 6| Step: 10
Training loss: 0.9694355726242065
Validation loss: 2.0270346146757885

Epoch: 6| Step: 11
Training loss: 1.3338708877563477
Validation loss: 2.0254090498852473

Epoch: 6| Step: 12
Training loss: 1.3484082221984863
Validation loss: 1.9848605253363167

Epoch: 6| Step: 13
Training loss: 1.592000126838684
Validation loss: 1.95646805660699

Epoch: 190| Step: 0
Training loss: 0.9086769819259644
Validation loss: 1.952003825095392

Epoch: 6| Step: 1
Training loss: 0.651709794998169
Validation loss: 1.9254227466480707

Epoch: 6| Step: 2
Training loss: 1.00770902633667
Validation loss: 1.9179138457903298

Epoch: 6| Step: 3
Training loss: 1.4585461616516113
Validation loss: 1.9162954361208024

Epoch: 6| Step: 4
Training loss: 1.4375507831573486
Validation loss: 1.920567568912301

Epoch: 6| Step: 5
Training loss: 1.2127267122268677
Validation loss: 1.939991311360431

Epoch: 6| Step: 6
Training loss: 1.1163766384124756
Validation loss: 1.9577617337626796

Epoch: 6| Step: 7
Training loss: 1.3832530975341797
Validation loss: 1.9771241026539956

Epoch: 6| Step: 8
Training loss: 1.2227612733840942
Validation loss: 1.9676573814884308

Epoch: 6| Step: 9
Training loss: 1.1264026165008545
Validation loss: 1.947164144567264

Epoch: 6| Step: 10
Training loss: 0.7562372088432312
Validation loss: 1.9386414686838787

Epoch: 6| Step: 11
Training loss: 0.7583577632904053
Validation loss: 1.9396112324089132

Epoch: 6| Step: 12
Training loss: 1.1974427700042725
Validation loss: 1.9040953549005653

Epoch: 6| Step: 13
Training loss: 0.9947125911712646
Validation loss: 1.8915581498094785

Epoch: 191| Step: 0
Training loss: 0.7887306213378906
Validation loss: 1.8911292770857453

Epoch: 6| Step: 1
Training loss: 1.3891100883483887
Validation loss: 1.9247108633800218

Epoch: 6| Step: 2
Training loss: 1.2685593366622925
Validation loss: 1.9402485278344923

Epoch: 6| Step: 3
Training loss: 1.0578835010528564
Validation loss: 1.9897261922077467

Epoch: 6| Step: 4
Training loss: 0.9931158423423767
Validation loss: 2.0090751750494844

Epoch: 6| Step: 5
Training loss: 1.1131693124771118
Validation loss: 2.0151248721666235

Epoch: 6| Step: 6
Training loss: 1.1072990894317627
Validation loss: 1.999719040368193

Epoch: 6| Step: 7
Training loss: 1.2573788166046143
Validation loss: 1.9664578924896896

Epoch: 6| Step: 8
Training loss: 1.4227062463760376
Validation loss: 1.9454902064415716

Epoch: 6| Step: 9
Training loss: 0.8386327028274536
Validation loss: 1.9169483825724611

Epoch: 6| Step: 10
Training loss: 1.2178255319595337
Validation loss: 1.8985240433805732

Epoch: 6| Step: 11
Training loss: 1.2500035762786865
Validation loss: 1.880342387383984

Epoch: 6| Step: 12
Training loss: 1.248676061630249
Validation loss: 1.853392449758386

Epoch: 6| Step: 13
Training loss: 0.6680458784103394
Validation loss: 1.8230407020097137

Epoch: 192| Step: 0
Training loss: 1.5410761833190918
Validation loss: 1.8667971498222762

Epoch: 6| Step: 1
Training loss: 1.0640246868133545
Validation loss: 1.8955758463951848

Epoch: 6| Step: 2
Training loss: 1.3625197410583496
Validation loss: 1.9577217076414375

Epoch: 6| Step: 3
Training loss: 1.136721134185791
Validation loss: 2.0306144581046155

Epoch: 6| Step: 4
Training loss: 0.6590991020202637
Validation loss: 2.081449039520756

Epoch: 6| Step: 5
Training loss: 1.4666450023651123
Validation loss: 2.0902412655533

Epoch: 6| Step: 6
Training loss: 1.3450310230255127
Validation loss: 2.0064701700723298

Epoch: 6| Step: 7
Training loss: 1.0656157732009888
Validation loss: 1.9286006291707356

Epoch: 6| Step: 8
Training loss: 0.5336933135986328
Validation loss: 1.884909463185136

Epoch: 6| Step: 9
Training loss: 1.17396879196167
Validation loss: 1.8728126120823685

Epoch: 6| Step: 10
Training loss: 1.7447658777236938
Validation loss: 1.9095812189963557

Epoch: 6| Step: 11
Training loss: 0.9740050435066223
Validation loss: 1.9153104392431115

Epoch: 6| Step: 12
Training loss: 1.0906906127929688
Validation loss: 1.910903989627797

Epoch: 6| Step: 13
Training loss: 0.890277624130249
Validation loss: 1.8537936646451232

Epoch: 193| Step: 0
Training loss: 1.07480788230896
Validation loss: 1.8811321181635703

Epoch: 6| Step: 1
Training loss: 1.0022443532943726
Validation loss: 1.919281291705306

Epoch: 6| Step: 2
Training loss: 1.2197777032852173
Validation loss: 1.9864066082944152

Epoch: 6| Step: 3
Training loss: 0.7280292510986328
Validation loss: 2.0303312270872054

Epoch: 6| Step: 4
Training loss: 1.672931432723999
Validation loss: 2.0536577522113757

Epoch: 6| Step: 5
Training loss: 0.7523601055145264
Validation loss: 2.0383486940014746

Epoch: 6| Step: 6
Training loss: 0.7584776878356934
Validation loss: 1.9985813966361425

Epoch: 6| Step: 7
Training loss: 2.0338544845581055
Validation loss: 1.9745412795774397

Epoch: 6| Step: 8
Training loss: 1.3339803218841553
Validation loss: 1.9298533752400389

Epoch: 6| Step: 9
Training loss: 0.8020167350769043
Validation loss: 1.9219147261752878

Epoch: 6| Step: 10
Training loss: 0.8765260577201843
Validation loss: 1.8705960755707116

Epoch: 6| Step: 11
Training loss: 1.29296875
Validation loss: 1.8477447481565579

Epoch: 6| Step: 12
Training loss: 1.3731038570404053
Validation loss: 1.8439632295280375

Epoch: 6| Step: 13
Training loss: 1.1513371467590332
Validation loss: 1.8351587941569667

Epoch: 194| Step: 0
Training loss: 1.1479496955871582
Validation loss: 1.830590889018069

Epoch: 6| Step: 1
Training loss: 0.9442312121391296
Validation loss: 1.847126328816978

Epoch: 6| Step: 2
Training loss: 1.5060527324676514
Validation loss: 1.830775071215886

Epoch: 6| Step: 3
Training loss: 0.8962644338607788
Validation loss: 1.85463757412408

Epoch: 6| Step: 4
Training loss: 1.0090070962905884
Validation loss: 1.894124956541164

Epoch: 6| Step: 5
Training loss: 1.0856627225875854
Validation loss: 1.9675697716333533

Epoch: 6| Step: 6
Training loss: 1.0925424098968506
Validation loss: 2.0028838957509687

Epoch: 6| Step: 7
Training loss: 0.9077978730201721
Validation loss: 2.0445079675284763

Epoch: 6| Step: 8
Training loss: 1.4357088804244995
Validation loss: 2.019785850278793

Epoch: 6| Step: 9
Training loss: 0.9352335929870605
Validation loss: 1.975477385264571

Epoch: 6| Step: 10
Training loss: 0.9199610948562622
Validation loss: 1.8991132987442838

Epoch: 6| Step: 11
Training loss: 0.7700732350349426
Validation loss: 1.8756609014285508

Epoch: 6| Step: 12
Training loss: 1.530806064605713
Validation loss: 1.8752197514298141

Epoch: 6| Step: 13
Training loss: 1.7156835794448853
Validation loss: 1.8708935591482347

Epoch: 195| Step: 0
Training loss: 1.1139235496520996
Validation loss: 1.843602663727217

Epoch: 6| Step: 1
Training loss: 1.160780906677246
Validation loss: 1.8400672597269858

Epoch: 6| Step: 2
Training loss: 1.3918670415878296
Validation loss: 1.8172558558884488

Epoch: 6| Step: 3
Training loss: 1.1343307495117188
Validation loss: 1.8229467868804932

Epoch: 6| Step: 4
Training loss: 0.7173478007316589
Validation loss: 1.8249442013361121

Epoch: 6| Step: 5
Training loss: 0.9245685338973999
Validation loss: 1.8363820224679925

Epoch: 6| Step: 6
Training loss: 0.6475510597229004
Validation loss: 1.8278366442649596

Epoch: 6| Step: 7
Training loss: 0.9148457050323486
Validation loss: 1.8938412204865487

Epoch: 6| Step: 8
Training loss: 1.1930748224258423
Validation loss: 1.9228651613317511

Epoch: 6| Step: 9
Training loss: 1.0222059488296509
Validation loss: 1.907422806627007

Epoch: 6| Step: 10
Training loss: 1.2863508462905884
Validation loss: 1.9316824328514837

Epoch: 6| Step: 11
Training loss: 0.8900066614151001
Validation loss: 1.9106219763396888

Epoch: 6| Step: 12
Training loss: 1.623610019683838
Validation loss: 1.9210803252394482

Epoch: 6| Step: 13
Training loss: 0.9258079528808594
Validation loss: 1.9208188672219553

Epoch: 196| Step: 0
Training loss: 0.8786643147468567
Validation loss: 1.884920940604261

Epoch: 6| Step: 1
Training loss: 1.3190031051635742
Validation loss: 1.846132516860962

Epoch: 6| Step: 2
Training loss: 1.4764654636383057
Validation loss: 1.8123523599358016

Epoch: 6| Step: 3
Training loss: 1.0744091272354126
Validation loss: 1.7945351280191892

Epoch: 6| Step: 4
Training loss: 0.9895522594451904
Validation loss: 1.8033293229277416

Epoch: 6| Step: 5
Training loss: 0.6680740714073181
Validation loss: 1.8147587455729002

Epoch: 6| Step: 6
Training loss: 1.023072361946106
Validation loss: 1.8396811510926934

Epoch: 6| Step: 7
Training loss: 1.1074223518371582
Validation loss: 1.8625850267307733

Epoch: 6| Step: 8
Training loss: 1.0233707427978516
Validation loss: 1.9078692646436795

Epoch: 6| Step: 9
Training loss: 0.7907094955444336
Validation loss: 1.9330187702691684

Epoch: 6| Step: 10
Training loss: 1.1444169282913208
Validation loss: 1.929835142627839

Epoch: 6| Step: 11
Training loss: 1.4404813051223755
Validation loss: 1.918219256144698

Epoch: 6| Step: 12
Training loss: 0.9736031293869019
Validation loss: 1.9071336612906507

Epoch: 6| Step: 13
Training loss: 0.44699615240097046
Validation loss: 1.897938479659378

Epoch: 197| Step: 0
Training loss: 1.3698694705963135
Validation loss: 1.8759904548686037

Epoch: 6| Step: 1
Training loss: 1.3019936084747314
Validation loss: 1.8853412507682719

Epoch: 6| Step: 2
Training loss: 0.5021476745605469
Validation loss: 1.8771894337028585

Epoch: 6| Step: 3
Training loss: 1.1142154932022095
Validation loss: 1.891509784165249

Epoch: 6| Step: 4
Training loss: 0.8730058670043945
Validation loss: 1.8702997648587791

Epoch: 6| Step: 5
Training loss: 0.9433590769767761
Validation loss: 1.8876019267625705

Epoch: 6| Step: 6
Training loss: 1.2943702936172485
Validation loss: 1.862374173697605

Epoch: 6| Step: 7
Training loss: 1.021659255027771
Validation loss: 1.8557893473614928

Epoch: 6| Step: 8
Training loss: 1.0455600023269653
Validation loss: 1.8782823829240696

Epoch: 6| Step: 9
Training loss: 0.9228052496910095
Validation loss: 1.9076881793237501

Epoch: 6| Step: 10
Training loss: 0.8547462821006775
Validation loss: 1.892844114252316

Epoch: 6| Step: 11
Training loss: 1.0388438701629639
Validation loss: 1.9227125157592118

Epoch: 6| Step: 12
Training loss: 1.2850240468978882
Validation loss: 1.9025043749040174

Epoch: 6| Step: 13
Training loss: 1.064281940460205
Validation loss: 1.8866918894552416

Epoch: 198| Step: 0
Training loss: 0.9524579644203186
Validation loss: 1.8713915040416103

Epoch: 6| Step: 1
Training loss: 1.3580563068389893
Validation loss: 1.8684553254035212

Epoch: 6| Step: 2
Training loss: 1.2522618770599365
Validation loss: 1.847353107185774

Epoch: 6| Step: 3
Training loss: 0.7554782629013062
Validation loss: 1.8398804690248223

Epoch: 6| Step: 4
Training loss: 0.8120166063308716
Validation loss: 1.7916543419643114

Epoch: 6| Step: 5
Training loss: 1.1682802438735962
Validation loss: 1.7869457391000563

Epoch: 6| Step: 6
Training loss: 1.0807732343673706
Validation loss: 1.7970665949647144

Epoch: 6| Step: 7
Training loss: 1.0633420944213867
Validation loss: 1.7931917444352181

Epoch: 6| Step: 8
Training loss: 0.9822779297828674
Validation loss: 1.826167324537872

Epoch: 6| Step: 9
Training loss: 0.8390483260154724
Validation loss: 1.8740805579769997

Epoch: 6| Step: 10
Training loss: 0.6826674938201904
Validation loss: 1.8826424434620848

Epoch: 6| Step: 11
Training loss: 1.1283667087554932
Validation loss: 1.9331400663621965

Epoch: 6| Step: 12
Training loss: 1.0186128616333008
Validation loss: 1.949533590706446

Epoch: 6| Step: 13
Training loss: 1.3254797458648682
Validation loss: 1.9394655022569882

Epoch: 199| Step: 0
Training loss: 0.8494174480438232
Validation loss: 1.9407282337065666

Epoch: 6| Step: 1
Training loss: 0.4329778850078583
Validation loss: 1.9763900541490125

Epoch: 6| Step: 2
Training loss: 0.8520785570144653
Validation loss: 1.9586425571031467

Epoch: 6| Step: 3
Training loss: 1.2952464818954468
Validation loss: 1.9441828522630917

Epoch: 6| Step: 4
Training loss: 1.002372145652771
Validation loss: 1.920452476829611

Epoch: 6| Step: 5
Training loss: 1.5966360569000244
Validation loss: 1.9023266966624925

Epoch: 6| Step: 6
Training loss: 1.026387095451355
Validation loss: 1.892539164071442

Epoch: 6| Step: 7
Training loss: 1.2455873489379883
Validation loss: 1.8892241908657936

Epoch: 6| Step: 8
Training loss: 1.2530412673950195
Validation loss: 1.8846213407413934

Epoch: 6| Step: 9
Training loss: 0.7571538686752319
Validation loss: 1.867310006131408

Epoch: 6| Step: 10
Training loss: 0.9060283303260803
Validation loss: 1.8646230569449804

Epoch: 6| Step: 11
Training loss: 0.9703296422958374
Validation loss: 1.8657161971574188

Epoch: 6| Step: 12
Training loss: 0.9978020191192627
Validation loss: 1.8683715533184748

Epoch: 6| Step: 13
Training loss: 0.8527485728263855
Validation loss: 1.868472776105327

Epoch: 200| Step: 0
Training loss: 1.1861145496368408
Validation loss: 1.874418031784796

Epoch: 6| Step: 1
Training loss: 0.3728572428226471
Validation loss: 1.8828216880880377

Epoch: 6| Step: 2
Training loss: 0.9747253656387329
Validation loss: 1.8353266293002712

Epoch: 6| Step: 3
Training loss: 1.1343889236450195
Validation loss: 1.8315666362803469

Epoch: 6| Step: 4
Training loss: 1.4344878196716309
Validation loss: 1.8284550892409457

Epoch: 6| Step: 5
Training loss: 0.793592095375061
Validation loss: 1.8171622855688936

Epoch: 6| Step: 6
Training loss: 1.0288481712341309
Validation loss: 1.8220997715509066

Epoch: 6| Step: 7
Training loss: 1.281109094619751
Validation loss: 1.832350077167634

Epoch: 6| Step: 8
Training loss: 0.8748476505279541
Validation loss: 1.8497946775087746

Epoch: 6| Step: 9
Training loss: 1.0887982845306396
Validation loss: 1.846750287599461

Epoch: 6| Step: 10
Training loss: 0.7241770625114441
Validation loss: 1.9072006799841439

Epoch: 6| Step: 11
Training loss: 1.266396403312683
Validation loss: 1.9199932518825735

Epoch: 6| Step: 12
Training loss: 0.5985037684440613
Validation loss: 1.9607660744779853

Epoch: 6| Step: 13
Training loss: 1.0535149574279785
Validation loss: 1.9440426775204238

Epoch: 201| Step: 0
Training loss: 1.0872802734375
Validation loss: 1.9632701309778358

Epoch: 6| Step: 1
Training loss: 0.687030017375946
Validation loss: 1.9316646681037

Epoch: 6| Step: 2
Training loss: 1.2367310523986816
Validation loss: 1.8977033194675241

Epoch: 6| Step: 3
Training loss: 0.8770737648010254
Validation loss: 1.8485021886005197

Epoch: 6| Step: 4
Training loss: 1.4474122524261475
Validation loss: 1.8379320047234977

Epoch: 6| Step: 5
Training loss: 0.6867492198944092
Validation loss: 1.8190791735085108

Epoch: 6| Step: 6
Training loss: 1.24241042137146
Validation loss: 1.828820848977694

Epoch: 6| Step: 7
Training loss: 1.6743204593658447
Validation loss: 1.8497381594873243

Epoch: 6| Step: 8
Training loss: 0.44818976521492004
Validation loss: 1.8764421324576102

Epoch: 6| Step: 9
Training loss: 1.3294026851654053
Validation loss: 1.9036414661715109

Epoch: 6| Step: 10
Training loss: 1.0605976581573486
Validation loss: 1.8830861430014334

Epoch: 6| Step: 11
Training loss: 0.7858072519302368
Validation loss: 1.8849115692159182

Epoch: 6| Step: 12
Training loss: 0.6887521743774414
Validation loss: 1.838433555377427

Epoch: 6| Step: 13
Training loss: 0.832330584526062
Validation loss: 1.8498968539699432

Epoch: 202| Step: 0
Training loss: 1.1094273328781128
Validation loss: 1.848749610685533

Epoch: 6| Step: 1
Training loss: 1.1646541357040405
Validation loss: 1.8431683676217192

Epoch: 6| Step: 2
Training loss: 0.9946444034576416
Validation loss: 1.8361502873000277

Epoch: 6| Step: 3
Training loss: 0.8728561401367188
Validation loss: 1.8425332884634695

Epoch: 6| Step: 4
Training loss: 0.9745998382568359
Validation loss: 1.8392990699378393

Epoch: 6| Step: 5
Training loss: 1.3433728218078613
Validation loss: 1.8715551694234211

Epoch: 6| Step: 6
Training loss: 0.8785204291343689
Validation loss: 1.8614369912814068

Epoch: 6| Step: 7
Training loss: 0.8071527481079102
Validation loss: 1.874551183433943

Epoch: 6| Step: 8
Training loss: 0.8875476121902466
Validation loss: 1.8819709275999377

Epoch: 6| Step: 9
Training loss: 1.0875650644302368
Validation loss: 1.8964241499541907

Epoch: 6| Step: 10
Training loss: 0.6994419097900391
Validation loss: 1.9045407887428039

Epoch: 6| Step: 11
Training loss: 0.7203741669654846
Validation loss: 1.9278295232403664

Epoch: 6| Step: 12
Training loss: 1.1552069187164307
Validation loss: 1.953923708649092

Epoch: 6| Step: 13
Training loss: 0.9601399302482605
Validation loss: 1.8914257736616238

Epoch: 203| Step: 0
Training loss: 0.9664139747619629
Validation loss: 1.8436088356920468

Epoch: 6| Step: 1
Training loss: 0.5985651612281799
Validation loss: 1.8148200986205891

Epoch: 6| Step: 2
Training loss: 1.0705560445785522
Validation loss: 1.8168403076869186

Epoch: 6| Step: 3
Training loss: 1.4446157217025757
Validation loss: 1.8182920768696775

Epoch: 6| Step: 4
Training loss: 0.8353323340415955
Validation loss: 1.8398207631162418

Epoch: 6| Step: 5
Training loss: 0.7246525287628174
Validation loss: 1.9187574694233556

Epoch: 6| Step: 6
Training loss: 0.6835142374038696
Validation loss: 1.942145412968051

Epoch: 6| Step: 7
Training loss: 1.0829100608825684
Validation loss: 1.970710600576093

Epoch: 6| Step: 8
Training loss: 0.7593010067939758
Validation loss: 1.9396060577002905

Epoch: 6| Step: 9
Training loss: 1.5055437088012695
Validation loss: 1.9247320057243429

Epoch: 6| Step: 10
Training loss: 0.7161369323730469
Validation loss: 1.9050492343082224

Epoch: 6| Step: 11
Training loss: 1.5635201930999756
Validation loss: 1.8334801658507316

Epoch: 6| Step: 12
Training loss: 0.7052856683731079
Validation loss: 1.8360258251108148

Epoch: 6| Step: 13
Training loss: 1.0862144231796265
Validation loss: 1.8108967273466048

Epoch: 204| Step: 0
Training loss: 1.2419036626815796
Validation loss: 1.8400237355180966

Epoch: 6| Step: 1
Training loss: 0.9176359176635742
Validation loss: 1.880159015296608

Epoch: 6| Step: 2
Training loss: 0.7446954250335693
Validation loss: 1.9275296477861301

Epoch: 6| Step: 3
Training loss: 1.192612648010254
Validation loss: 1.9157074677046908

Epoch: 6| Step: 4
Training loss: 0.8960098028182983
Validation loss: 1.9385383667484406

Epoch: 6| Step: 5
Training loss: 0.39766788482666016
Validation loss: 1.9511254461862708

Epoch: 6| Step: 6
Training loss: 0.8003240823745728
Validation loss: 1.9406446744036931

Epoch: 6| Step: 7
Training loss: 1.229941964149475
Validation loss: 1.933192285158301

Epoch: 6| Step: 8
Training loss: 1.131587266921997
Validation loss: 1.8875036329351447

Epoch: 6| Step: 9
Training loss: 1.1369197368621826
Validation loss: 1.8607771883728683

Epoch: 6| Step: 10
Training loss: 0.9823604822158813
Validation loss: 1.823175863553119

Epoch: 6| Step: 11
Training loss: 1.2024953365325928
Validation loss: 1.7955919414438226

Epoch: 6| Step: 12
Training loss: 1.1902806758880615
Validation loss: 1.7868332670580955

Epoch: 6| Step: 13
Training loss: 0.9390378594398499
Validation loss: 1.803028211798719

Epoch: 205| Step: 0
Training loss: 1.0780577659606934
Validation loss: 1.8308302978033661

Epoch: 6| Step: 1
Training loss: 1.0632760524749756
Validation loss: 1.9083038760769753

Epoch: 6| Step: 2
Training loss: 0.6201052665710449
Validation loss: 1.9450521379388788

Epoch: 6| Step: 3
Training loss: 0.7299820184707642
Validation loss: 2.0118456912297074

Epoch: 6| Step: 4
Training loss: 1.2047553062438965
Validation loss: 2.0019886583410282

Epoch: 6| Step: 5
Training loss: 1.114449381828308
Validation loss: 1.9758643258002497

Epoch: 6| Step: 6
Training loss: 1.1865777969360352
Validation loss: 1.930941427907636

Epoch: 6| Step: 7
Training loss: 0.599114716053009
Validation loss: 1.8573660363433182

Epoch: 6| Step: 8
Training loss: 0.8006477355957031
Validation loss: 1.8328384763451033

Epoch: 6| Step: 9
Training loss: 0.8569437265396118
Validation loss: 1.8062283159584127

Epoch: 6| Step: 10
Training loss: 0.7195905447006226
Validation loss: 1.7894980702348935

Epoch: 6| Step: 11
Training loss: 1.4804178476333618
Validation loss: 1.8086334864298503

Epoch: 6| Step: 12
Training loss: 1.0569477081298828
Validation loss: 1.7960165892877886

Epoch: 6| Step: 13
Training loss: 0.6968392133712769
Validation loss: 1.8344532353903658

Epoch: 206| Step: 0
Training loss: 1.520254135131836
Validation loss: 1.8503227669705626

Epoch: 6| Step: 1
Training loss: 0.40367865562438965
Validation loss: 1.8742157182385843

Epoch: 6| Step: 2
Training loss: 0.8821030259132385
Validation loss: 1.8759322371534122

Epoch: 6| Step: 3
Training loss: 0.549281895160675
Validation loss: 1.9066773486393753

Epoch: 6| Step: 4
Training loss: 0.8673163056373596
Validation loss: 1.914585542935197

Epoch: 6| Step: 5
Training loss: 1.6570498943328857
Validation loss: 1.93623701987728

Epoch: 6| Step: 6
Training loss: 0.5737909078598022
Validation loss: 1.9306474872814712

Epoch: 6| Step: 7
Training loss: 1.212846040725708
Validation loss: 1.9117067885655228

Epoch: 6| Step: 8
Training loss: 0.8642475605010986
Validation loss: 1.8701439724173596

Epoch: 6| Step: 9
Training loss: 0.9523987174034119
Validation loss: 1.8310757362714378

Epoch: 6| Step: 10
Training loss: 0.6780990362167358
Validation loss: 1.8188138931028304

Epoch: 6| Step: 11
Training loss: 0.9943837523460388
Validation loss: 1.781835881612634

Epoch: 6| Step: 12
Training loss: 1.0054900646209717
Validation loss: 1.8024686754390757

Epoch: 6| Step: 13
Training loss: 1.0414767265319824
Validation loss: 1.8000358214942358

Epoch: 207| Step: 0
Training loss: 0.6859854459762573
Validation loss: 1.8351480858300322

Epoch: 6| Step: 1
Training loss: 1.0258530378341675
Validation loss: 1.8519904587858467

Epoch: 6| Step: 2
Training loss: 1.1148892641067505
Validation loss: 1.8815352121988933

Epoch: 6| Step: 3
Training loss: 1.0367300510406494
Validation loss: 1.9305609144190305

Epoch: 6| Step: 4
Training loss: 0.9231038093566895
Validation loss: 1.952195180359707

Epoch: 6| Step: 5
Training loss: 0.7781690955162048
Validation loss: 1.9578369535425657

Epoch: 6| Step: 6
Training loss: 0.6562665700912476
Validation loss: 1.956065236881215

Epoch: 6| Step: 7
Training loss: 0.5452329516410828
Validation loss: 1.9306585096543836

Epoch: 6| Step: 8
Training loss: 0.9746494889259338
Validation loss: 1.8826069293483612

Epoch: 6| Step: 9
Training loss: 1.3141300678253174
Validation loss: 1.8471157871266848

Epoch: 6| Step: 10
Training loss: 1.1263246536254883
Validation loss: 1.798733575369722

Epoch: 6| Step: 11
Training loss: 0.9332962036132812
Validation loss: 1.7789175433497275

Epoch: 6| Step: 12
Training loss: 0.7753373384475708
Validation loss: 1.7708456029174149

Epoch: 6| Step: 13
Training loss: 0.8375313878059387
Validation loss: 1.7779970617704495

Epoch: 208| Step: 0
Training loss: 0.6395503282546997
Validation loss: 1.7603597256445116

Epoch: 6| Step: 1
Training loss: 0.7696501016616821
Validation loss: 1.8114539487387544

Epoch: 6| Step: 2
Training loss: 0.8146213293075562
Validation loss: 1.8435761172284362

Epoch: 6| Step: 3
Training loss: 0.9597516059875488
Validation loss: 1.90946630636851

Epoch: 6| Step: 4
Training loss: 0.9354711174964905
Validation loss: 1.992219930054039

Epoch: 6| Step: 5
Training loss: 1.467530369758606
Validation loss: 1.9625796271908669

Epoch: 6| Step: 6
Training loss: 0.7796468138694763
Validation loss: 1.9249626090449672

Epoch: 6| Step: 7
Training loss: 1.0898061990737915
Validation loss: 1.8791318811396116

Epoch: 6| Step: 8
Training loss: 1.024523377418518
Validation loss: 1.8556916380441317

Epoch: 6| Step: 9
Training loss: 0.624257504940033
Validation loss: 1.830904955505043

Epoch: 6| Step: 10
Training loss: 1.1709191799163818
Validation loss: 1.828089544850011

Epoch: 6| Step: 11
Training loss: 0.9615678787231445
Validation loss: 1.819330911482534

Epoch: 6| Step: 12
Training loss: 0.8026493191719055
Validation loss: 1.783023262536654

Epoch: 6| Step: 13
Training loss: 0.704139769077301
Validation loss: 1.7759808955654022

Epoch: 209| Step: 0
Training loss: 0.7735023498535156
Validation loss: 1.7818864827514977

Epoch: 6| Step: 1
Training loss: 0.8331966400146484
Validation loss: 1.8177609623119395

Epoch: 6| Step: 2
Training loss: 0.5288788676261902
Validation loss: 1.8127365061031875

Epoch: 6| Step: 3
Training loss: 1.0242338180541992
Validation loss: 1.8695917706335745

Epoch: 6| Step: 4
Training loss: 0.7529957294464111
Validation loss: 1.905130050515616

Epoch: 6| Step: 5
Training loss: 1.0317156314849854
Validation loss: 1.9196394182020617

Epoch: 6| Step: 6
Training loss: 1.0663402080535889
Validation loss: 1.9217691011326288

Epoch: 6| Step: 7
Training loss: 1.0425513982772827
Validation loss: 1.9077536098418697

Epoch: 6| Step: 8
Training loss: 0.9315563440322876
Validation loss: 1.880780784032678

Epoch: 6| Step: 9
Training loss: 0.9198228120803833
Validation loss: 1.8331526235867572

Epoch: 6| Step: 10
Training loss: 1.2896552085876465
Validation loss: 1.8154815755864626

Epoch: 6| Step: 11
Training loss: 0.7742118835449219
Validation loss: 1.7957509397178568

Epoch: 6| Step: 12
Training loss: 0.6919103264808655
Validation loss: 1.7982060729816396

Epoch: 6| Step: 13
Training loss: 0.9824330806732178
Validation loss: 1.8093562626069593

Epoch: 210| Step: 0
Training loss: 0.7686607837677002
Validation loss: 1.787687986127792

Epoch: 6| Step: 1
Training loss: 0.8989191055297852
Validation loss: 1.7919384869196082

Epoch: 6| Step: 2
Training loss: 1.2424211502075195
Validation loss: 1.8071078779876872

Epoch: 6| Step: 3
Training loss: 0.9138158559799194
Validation loss: 1.8229314127276022

Epoch: 6| Step: 4
Training loss: 0.9476142525672913
Validation loss: 1.8626419113528343

Epoch: 6| Step: 5
Training loss: 0.7278754115104675
Validation loss: 1.8802203478351716

Epoch: 6| Step: 6
Training loss: 0.6247547268867493
Validation loss: 1.8602254070261472

Epoch: 6| Step: 7
Training loss: 0.9026752710342407
Validation loss: 1.8825743403486026

Epoch: 6| Step: 8
Training loss: 1.0179493427276611
Validation loss: 1.898002116910873

Epoch: 6| Step: 9
Training loss: 0.8617367148399353
Validation loss: 1.9254651185004943

Epoch: 6| Step: 10
Training loss: 0.6748385429382324
Validation loss: 1.955822778004472

Epoch: 6| Step: 11
Training loss: 0.7792659997940063
Validation loss: 1.894699578644127

Epoch: 6| Step: 12
Training loss: 1.1303505897521973
Validation loss: 1.8617086730977541

Epoch: 6| Step: 13
Training loss: 0.9370365142822266
Validation loss: 1.8455934011808006

Epoch: 211| Step: 0
Training loss: 0.5112730264663696
Validation loss: 1.8248823022329679

Epoch: 6| Step: 1
Training loss: 0.853344738483429
Validation loss: 1.8214805715827531

Epoch: 6| Step: 2
Training loss: 1.0798213481903076
Validation loss: 1.807182611957673

Epoch: 6| Step: 3
Training loss: 1.0237071514129639
Validation loss: 1.8263678114901307

Epoch: 6| Step: 4
Training loss: 1.1244630813598633
Validation loss: 1.8408699343281407

Epoch: 6| Step: 5
Training loss: 0.588126540184021
Validation loss: 1.8521725644347489

Epoch: 6| Step: 6
Training loss: 0.6121744513511658
Validation loss: 1.8548844860446068

Epoch: 6| Step: 7
Training loss: 0.9241563677787781
Validation loss: 1.885842784758537

Epoch: 6| Step: 8
Training loss: 1.1785609722137451
Validation loss: 1.9048947608599098

Epoch: 6| Step: 9
Training loss: 1.1311033964157104
Validation loss: 1.9235966564506612

Epoch: 6| Step: 10
Training loss: 0.9637681245803833
Validation loss: 1.9222459613635976

Epoch: 6| Step: 11
Training loss: 0.8903351426124573
Validation loss: 1.891529102479258

Epoch: 6| Step: 12
Training loss: 0.6138807535171509
Validation loss: 1.873637160947246

Epoch: 6| Step: 13
Training loss: 0.9724246263504028
Validation loss: 1.8432080514969365

Epoch: 212| Step: 0
Training loss: 0.7366461753845215
Validation loss: 1.84626599537429

Epoch: 6| Step: 1
Training loss: 0.8127074837684631
Validation loss: 1.8329595711923414

Epoch: 6| Step: 2
Training loss: 0.7422774434089661
Validation loss: 1.791559459060751

Epoch: 6| Step: 3
Training loss: 0.8963154554367065
Validation loss: 1.7793169675334808

Epoch: 6| Step: 4
Training loss: 1.5125948190689087
Validation loss: 1.7653856008283553

Epoch: 6| Step: 5
Training loss: 0.6907795071601868
Validation loss: 1.7768013733689503

Epoch: 6| Step: 6
Training loss: 0.8088402152061462
Validation loss: 1.7816666274942377

Epoch: 6| Step: 7
Training loss: 0.8849703669548035
Validation loss: 1.8151647365221413

Epoch: 6| Step: 8
Training loss: 0.9549471139907837
Validation loss: 1.871214843565418

Epoch: 6| Step: 9
Training loss: 0.9840357899665833
Validation loss: 1.9064205487569172

Epoch: 6| Step: 10
Training loss: 0.7847899198532104
Validation loss: 1.926415233201878

Epoch: 6| Step: 11
Training loss: 0.8496750593185425
Validation loss: 1.875799330331946

Epoch: 6| Step: 12
Training loss: 0.934755802154541
Validation loss: 1.845788550633256

Epoch: 6| Step: 13
Training loss: 1.2968482971191406
Validation loss: 1.8163318275123514

Epoch: 213| Step: 0
Training loss: 0.9539632201194763
Validation loss: 1.8132241105520597

Epoch: 6| Step: 1
Training loss: 0.8268154859542847
Validation loss: 1.8103118788811468

Epoch: 6| Step: 2
Training loss: 0.680971622467041
Validation loss: 1.8136434414053475

Epoch: 6| Step: 3
Training loss: 0.8856128454208374
Validation loss: 1.8153587400272329

Epoch: 6| Step: 4
Training loss: 1.1233206987380981
Validation loss: 1.8358057032349289

Epoch: 6| Step: 5
Training loss: 1.2315940856933594
Validation loss: 1.8712031354186356

Epoch: 6| Step: 6
Training loss: 0.7200444936752319
Validation loss: 1.9123100208979782

Epoch: 6| Step: 7
Training loss: 1.187784194946289
Validation loss: 1.9891420897617136

Epoch: 6| Step: 8
Training loss: 1.002539873123169
Validation loss: 2.021797263494102

Epoch: 6| Step: 9
Training loss: 0.8570277690887451
Validation loss: 2.0138701136394213

Epoch: 6| Step: 10
Training loss: 0.7100991010665894
Validation loss: 1.9441650862334876

Epoch: 6| Step: 11
Training loss: 0.7984706163406372
Validation loss: 1.8821141642908896

Epoch: 6| Step: 12
Training loss: 0.7422068119049072
Validation loss: 1.8356113562019922

Epoch: 6| Step: 13
Training loss: 0.9302956461906433
Validation loss: 1.8296598721575994

Epoch: 214| Step: 0
Training loss: 0.87273108959198
Validation loss: 1.8180773309482041

Epoch: 6| Step: 1
Training loss: 0.7695823907852173
Validation loss: 1.7794765682630642

Epoch: 6| Step: 2
Training loss: 0.9905029535293579
Validation loss: 1.768807812403607

Epoch: 6| Step: 3
Training loss: 0.5849879384040833
Validation loss: 1.769744796137656

Epoch: 6| Step: 4
Training loss: 0.8563645482063293
Validation loss: 1.7640117176117436

Epoch: 6| Step: 5
Training loss: 0.6843452453613281
Validation loss: 1.7721056733080136

Epoch: 6| Step: 6
Training loss: 1.0444689989089966
Validation loss: 1.7714243832454886

Epoch: 6| Step: 7
Training loss: 0.6853196024894714
Validation loss: 1.8315440070244573

Epoch: 6| Step: 8
Training loss: 0.9255290627479553
Validation loss: 1.8876282399700535

Epoch: 6| Step: 9
Training loss: 0.9823307991027832
Validation loss: 1.920529701376474

Epoch: 6| Step: 10
Training loss: 1.1778157949447632
Validation loss: 1.9556161049873597

Epoch: 6| Step: 11
Training loss: 1.1572147607803345
Validation loss: 1.938002242836901

Epoch: 6| Step: 12
Training loss: 0.6315298080444336
Validation loss: 1.9022478685584119

Epoch: 6| Step: 13
Training loss: 1.1040854454040527
Validation loss: 1.8607545539896975

Epoch: 215| Step: 0
Training loss: 0.9591470956802368
Validation loss: 1.8594162130868563

Epoch: 6| Step: 1
Training loss: 0.9349979758262634
Validation loss: 1.8533986409505208

Epoch: 6| Step: 2
Training loss: 0.5594972968101501
Validation loss: 1.8195248457693285

Epoch: 6| Step: 3
Training loss: 0.7176032066345215
Validation loss: 1.804474025644282

Epoch: 6| Step: 4
Training loss: 0.9271758794784546
Validation loss: 1.766442411689348

Epoch: 6| Step: 5
Training loss: 1.1647655963897705
Validation loss: 1.7510204469003985

Epoch: 6| Step: 6
Training loss: 1.4827942848205566
Validation loss: 1.7549762905284922

Epoch: 6| Step: 7
Training loss: 0.8544204235076904
Validation loss: 1.7718900121668333

Epoch: 6| Step: 8
Training loss: 0.41378164291381836
Validation loss: 1.7912720031635736

Epoch: 6| Step: 9
Training loss: 0.8999104499816895
Validation loss: 1.7945409487652522

Epoch: 6| Step: 10
Training loss: 0.4976601004600525
Validation loss: 1.7760538234505603

Epoch: 6| Step: 11
Training loss: 0.5688216686248779
Validation loss: 1.8106394429360666

Epoch: 6| Step: 12
Training loss: 1.006284475326538
Validation loss: 1.801246279029436

Epoch: 6| Step: 13
Training loss: 0.6999415159225464
Validation loss: 1.7550909134649462

Epoch: 216| Step: 0
Training loss: 0.7034890651702881
Validation loss: 1.7506034835692375

Epoch: 6| Step: 1
Training loss: 0.7216522693634033
Validation loss: 1.7764428456624348

Epoch: 6| Step: 2
Training loss: 0.8570505380630493
Validation loss: 1.7768750934190647

Epoch: 6| Step: 3
Training loss: 0.45849594473838806
Validation loss: 1.8030058440341745

Epoch: 6| Step: 4
Training loss: 1.252979040145874
Validation loss: 1.8246633493772118

Epoch: 6| Step: 5
Training loss: 0.9145029783248901
Validation loss: 1.7922292704223304

Epoch: 6| Step: 6
Training loss: 0.6385800242424011
Validation loss: 1.7970289427747008

Epoch: 6| Step: 7
Training loss: 0.415730357170105
Validation loss: 1.8475019790792977

Epoch: 6| Step: 8
Training loss: 0.9756724238395691
Validation loss: 1.839027589367282

Epoch: 6| Step: 9
Training loss: 1.311028003692627
Validation loss: 1.8519226504910378

Epoch: 6| Step: 10
Training loss: 1.096430778503418
Validation loss: 1.8456875572922409

Epoch: 6| Step: 11
Training loss: 0.6857299208641052
Validation loss: 1.8353619652409707

Epoch: 6| Step: 12
Training loss: 0.5960925817489624
Validation loss: 1.8390467243809854

Epoch: 6| Step: 13
Training loss: 0.2556387484073639
Validation loss: 1.8118407751924248

Epoch: 217| Step: 0
Training loss: 0.4701428711414337
Validation loss: 1.7879084502497027

Epoch: 6| Step: 1
Training loss: 0.8464016914367676
Validation loss: 1.7741226880781111

Epoch: 6| Step: 2
Training loss: 1.0156397819519043
Validation loss: 1.7876502826649656

Epoch: 6| Step: 3
Training loss: 0.5368201732635498
Validation loss: 1.7837085711058749

Epoch: 6| Step: 4
Training loss: 0.7115308046340942
Validation loss: 1.8054551424518708

Epoch: 6| Step: 5
Training loss: 1.0670469999313354
Validation loss: 1.8188234913733698

Epoch: 6| Step: 6
Training loss: 1.0107743740081787
Validation loss: 1.846125054103072

Epoch: 6| Step: 7
Training loss: 1.1550214290618896
Validation loss: 1.8867551498515631

Epoch: 6| Step: 8
Training loss: 0.8332476615905762
Validation loss: 1.9035721158468595

Epoch: 6| Step: 9
Training loss: 0.8554272651672363
Validation loss: 1.882827866461969

Epoch: 6| Step: 10
Training loss: 0.9369776844978333
Validation loss: 1.8774863840431295

Epoch: 6| Step: 11
Training loss: 0.44881129264831543
Validation loss: 1.861176747147755

Epoch: 6| Step: 12
Training loss: 0.6639968156814575
Validation loss: 1.8267489863980202

Epoch: 6| Step: 13
Training loss: 0.8833320140838623
Validation loss: 1.8068477748542704

Epoch: 218| Step: 0
Training loss: 0.6345267295837402
Validation loss: 1.7717802191293368

Epoch: 6| Step: 1
Training loss: 1.2365621328353882
Validation loss: 1.7551075553381315

Epoch: 6| Step: 2
Training loss: 0.5315526723861694
Validation loss: 1.7486679912895284

Epoch: 6| Step: 3
Training loss: 0.7698836326599121
Validation loss: 1.7710318257731776

Epoch: 6| Step: 4
Training loss: 0.5115360021591187
Validation loss: 1.7878055008508826

Epoch: 6| Step: 5
Training loss: 0.9548263549804688
Validation loss: 1.7892147943537722

Epoch: 6| Step: 6
Training loss: 0.3949175775051117
Validation loss: 1.8150567508512927

Epoch: 6| Step: 7
Training loss: 0.9260969758033752
Validation loss: 1.8371699010172198

Epoch: 6| Step: 8
Training loss: 1.3392140865325928
Validation loss: 1.8539863363389046

Epoch: 6| Step: 9
Training loss: 0.6134102940559387
Validation loss: 1.8361239202560917

Epoch: 6| Step: 10
Training loss: 0.9244171380996704
Validation loss: 1.8798219106530631

Epoch: 6| Step: 11
Training loss: 1.1204543113708496
Validation loss: 1.872426071474629

Epoch: 6| Step: 12
Training loss: 0.724428653717041
Validation loss: 1.8561003554251887

Epoch: 6| Step: 13
Training loss: 0.6256623864173889
Validation loss: 1.8449797681582871

Epoch: 219| Step: 0
Training loss: 1.138851523399353
Validation loss: 1.8316480011068366

Epoch: 6| Step: 1
Training loss: 0.9037694931030273
Validation loss: 1.8036914961312407

Epoch: 6| Step: 2
Training loss: 0.5499923229217529
Validation loss: 1.7690365032483173

Epoch: 6| Step: 3
Training loss: 0.724834680557251
Validation loss: 1.7670260962619577

Epoch: 6| Step: 4
Training loss: 0.6506308317184448
Validation loss: 1.7709426315881873

Epoch: 6| Step: 5
Training loss: 0.888041615486145
Validation loss: 1.7643676419411936

Epoch: 6| Step: 6
Training loss: 0.4087555408477783
Validation loss: 1.7765847329170472

Epoch: 6| Step: 7
Training loss: 0.7790946960449219
Validation loss: 1.7926339667330506

Epoch: 6| Step: 8
Training loss: 0.9250877499580383
Validation loss: 1.8244819218112576

Epoch: 6| Step: 9
Training loss: 0.5632925629615784
Validation loss: 1.8545299165992326

Epoch: 6| Step: 10
Training loss: 0.5147253274917603
Validation loss: 1.8651697904832902

Epoch: 6| Step: 11
Training loss: 0.7001969218254089
Validation loss: 1.8948392598859725

Epoch: 6| Step: 12
Training loss: 1.000494122505188
Validation loss: 1.9009900016169394

Epoch: 6| Step: 13
Training loss: 1.353554606437683
Validation loss: 1.8948855412903653

Epoch: 220| Step: 0
Training loss: 0.8772655725479126
Validation loss: 1.8582039289577033

Epoch: 6| Step: 1
Training loss: 1.0207552909851074
Validation loss: 1.8338992634127218

Epoch: 6| Step: 2
Training loss: 0.7363077998161316
Validation loss: 1.8350118308938959

Epoch: 6| Step: 3
Training loss: 0.6411513090133667
Validation loss: 1.7967978715896606

Epoch: 6| Step: 4
Training loss: 0.976952075958252
Validation loss: 1.7956116840403566

Epoch: 6| Step: 5
Training loss: 0.39060211181640625
Validation loss: 1.7880924670926985

Epoch: 6| Step: 6
Training loss: 0.7933021783828735
Validation loss: 1.7906466645579184

Epoch: 6| Step: 7
Training loss: 0.4504333436489105
Validation loss: 1.807304310542281

Epoch: 6| Step: 8
Training loss: 0.6648349761962891
Validation loss: 1.8134957167410082

Epoch: 6| Step: 9
Training loss: 1.308493733406067
Validation loss: 1.83296109784034

Epoch: 6| Step: 10
Training loss: 0.7019340991973877
Validation loss: 1.8541527640435003

Epoch: 6| Step: 11
Training loss: 0.5265138745307922
Validation loss: 1.8662699371255853

Epoch: 6| Step: 12
Training loss: 1.0590813159942627
Validation loss: 1.9110982264241865

Epoch: 6| Step: 13
Training loss: 0.6933006644248962
Validation loss: 1.912676784300035

Epoch: 221| Step: 0
Training loss: 0.8100836873054504
Validation loss: 1.9084290073763939

Epoch: 6| Step: 1
Training loss: 0.7230756282806396
Validation loss: 1.9442817652097313

Epoch: 6| Step: 2
Training loss: 0.6193116903305054
Validation loss: 1.8879609659153929

Epoch: 6| Step: 3
Training loss: 0.8667104244232178
Validation loss: 1.8555675027190999

Epoch: 6| Step: 4
Training loss: 0.90644770860672
Validation loss: 1.827509290428572

Epoch: 6| Step: 5
Training loss: 0.7684120535850525
Validation loss: 1.830470451744654

Epoch: 6| Step: 6
Training loss: 1.0191799402236938
Validation loss: 1.8119260700800086

Epoch: 6| Step: 7
Training loss: 1.0562810897827148
Validation loss: 1.8086522984248337

Epoch: 6| Step: 8
Training loss: 0.6981775760650635
Validation loss: 1.825392828192762

Epoch: 6| Step: 9
Training loss: 1.2005525827407837
Validation loss: 1.8299943503513132

Epoch: 6| Step: 10
Training loss: 0.43395769596099854
Validation loss: 1.8367494831803024

Epoch: 6| Step: 11
Training loss: 0.6223596334457397
Validation loss: 1.8256473054168045

Epoch: 6| Step: 12
Training loss: 0.4904446005821228
Validation loss: 1.8156888843864523

Epoch: 6| Step: 13
Training loss: 0.2288474291563034
Validation loss: 1.8326572705340642

Epoch: 222| Step: 0
Training loss: 0.7812663316726685
Validation loss: 1.8328462134125412

Epoch: 6| Step: 1
Training loss: 0.46935659646987915
Validation loss: 1.8616783926563878

Epoch: 6| Step: 2
Training loss: 1.0187780857086182
Validation loss: 1.8411416212717693

Epoch: 6| Step: 3
Training loss: 0.900484561920166
Validation loss: 1.871719201405843

Epoch: 6| Step: 4
Training loss: 0.9035433530807495
Validation loss: 1.8576678563189764

Epoch: 6| Step: 5
Training loss: 0.5322309732437134
Validation loss: 1.8426307401349467

Epoch: 6| Step: 6
Training loss: 0.4280513823032379
Validation loss: 1.8212975789141912

Epoch: 6| Step: 7
Training loss: 0.8572825193405151
Validation loss: 1.7797400002838464

Epoch: 6| Step: 8
Training loss: 0.6700280904769897
Validation loss: 1.779201284531624

Epoch: 6| Step: 9
Training loss: 0.8379130363464355
Validation loss: 1.7878047343223327

Epoch: 6| Step: 10
Training loss: 0.7657301425933838
Validation loss: 1.7736332467807236

Epoch: 6| Step: 11
Training loss: 0.6907466650009155
Validation loss: 1.7997549785080778

Epoch: 6| Step: 12
Training loss: 0.4758230447769165
Validation loss: 1.812318758297992

Epoch: 6| Step: 13
Training loss: 1.2232394218444824
Validation loss: 1.8565144872152677

Epoch: 223| Step: 0
Training loss: 0.8584499955177307
Validation loss: 1.8576255857303579

Epoch: 6| Step: 1
Training loss: 0.6730570793151855
Validation loss: 1.8783879209590215

Epoch: 6| Step: 2
Training loss: 0.6712380051612854
Validation loss: 1.8986796332943825

Epoch: 6| Step: 3
Training loss: 0.6730122566223145
Validation loss: 1.891886482956589

Epoch: 6| Step: 4
Training loss: 1.1530427932739258
Validation loss: 1.8494397786355787

Epoch: 6| Step: 5
Training loss: 0.8920614719390869
Validation loss: 1.8042367786489508

Epoch: 6| Step: 6
Training loss: 0.4887164235115051
Validation loss: 1.8017389364140008

Epoch: 6| Step: 7
Training loss: 0.6710554957389832
Validation loss: 1.7764660466101863

Epoch: 6| Step: 8
Training loss: 0.7324092388153076
Validation loss: 1.781749875314774

Epoch: 6| Step: 9
Training loss: 0.7770386934280396
Validation loss: 1.7613984974481727

Epoch: 6| Step: 10
Training loss: 0.7826378345489502
Validation loss: 1.7757354820928266

Epoch: 6| Step: 11
Training loss: 0.6633684635162354
Validation loss: 1.7770087193417292

Epoch: 6| Step: 12
Training loss: 0.6777945756912231
Validation loss: 1.8182299008933447

Epoch: 6| Step: 13
Training loss: 0.8441169261932373
Validation loss: 1.8506063748431463

Epoch: 224| Step: 0
Training loss: 0.6281018257141113
Validation loss: 1.8611428865822413

Epoch: 6| Step: 1
Training loss: 0.9623754620552063
Validation loss: 1.8878706680831088

Epoch: 6| Step: 2
Training loss: 1.1190980672836304
Validation loss: 1.8374180101579236

Epoch: 6| Step: 3
Training loss: 0.2566131353378296
Validation loss: 1.8332952632698962

Epoch: 6| Step: 4
Training loss: 0.831000804901123
Validation loss: 1.8247410167929947

Epoch: 6| Step: 5
Training loss: 0.9541152715682983
Validation loss: 1.8161766541901456

Epoch: 6| Step: 6
Training loss: 0.26508828997612
Validation loss: 1.820628216189723

Epoch: 6| Step: 7
Training loss: 0.8066214919090271
Validation loss: 1.8038477333643104

Epoch: 6| Step: 8
Training loss: 0.7432079315185547
Validation loss: 1.7997298971299203

Epoch: 6| Step: 9
Training loss: 0.5698328614234924
Validation loss: 1.8224877542065037

Epoch: 6| Step: 10
Training loss: 0.6634763479232788
Validation loss: 1.8325821174088346

Epoch: 6| Step: 11
Training loss: 0.8175519704818726
Validation loss: 1.823117511246794

Epoch: 6| Step: 12
Training loss: 1.0404915809631348
Validation loss: 1.8260685756642332

Epoch: 6| Step: 13
Training loss: 0.4108753204345703
Validation loss: 1.8087590663663802

Epoch: 225| Step: 0
Training loss: 0.5983024835586548
Validation loss: 1.8101054340280511

Epoch: 6| Step: 1
Training loss: 0.5400373339653015
Validation loss: 1.7748622971196328

Epoch: 6| Step: 2
Training loss: 0.6517467498779297
Validation loss: 1.804543383659855

Epoch: 6| Step: 3
Training loss: 1.5572773218154907
Validation loss: 1.8043144966966362

Epoch: 6| Step: 4
Training loss: 0.651746392250061
Validation loss: 1.808651296041345

Epoch: 6| Step: 5
Training loss: 0.8399814963340759
Validation loss: 1.8118675729279876

Epoch: 6| Step: 6
Training loss: 0.6381615996360779
Validation loss: 1.8146303725498978

Epoch: 6| Step: 7
Training loss: 0.41602593660354614
Validation loss: 1.7987855313926615

Epoch: 6| Step: 8
Training loss: 0.6800799369812012
Validation loss: 1.8013583960071686

Epoch: 6| Step: 9
Training loss: 0.6265321373939514
Validation loss: 1.8276744606674358

Epoch: 6| Step: 10
Training loss: 0.5179834961891174
Validation loss: 1.823278311760195

Epoch: 6| Step: 11
Training loss: 0.7033125162124634
Validation loss: 1.8438052246647496

Epoch: 6| Step: 12
Training loss: 1.061669111251831
Validation loss: 1.8262957219154603

Epoch: 6| Step: 13
Training loss: 0.2518101632595062
Validation loss: 1.8057145187931676

Epoch: 226| Step: 0
Training loss: 0.9831023216247559
Validation loss: 1.8172790209452312

Epoch: 6| Step: 1
Training loss: 0.34007662534713745
Validation loss: 1.834610318624845

Epoch: 6| Step: 2
Training loss: 0.7961117029190063
Validation loss: 1.8370399500734063

Epoch: 6| Step: 3
Training loss: 0.53473299741745
Validation loss: 1.8196229691146522

Epoch: 6| Step: 4
Training loss: 0.5839037895202637
Validation loss: 1.8094877812170214

Epoch: 6| Step: 5
Training loss: 0.8610349297523499
Validation loss: 1.7814803815657092

Epoch: 6| Step: 6
Training loss: 0.4837603271007538
Validation loss: 1.7790099920765046

Epoch: 6| Step: 7
Training loss: 1.3397232294082642
Validation loss: 1.785193315116308

Epoch: 6| Step: 8
Training loss: 0.7941070199012756
Validation loss: 1.7841246538264777

Epoch: 6| Step: 9
Training loss: 0.7567771673202515
Validation loss: 1.7858319308168145

Epoch: 6| Step: 10
Training loss: 0.4263874888420105
Validation loss: 1.8165271154014013

Epoch: 6| Step: 11
Training loss: 0.52381831407547
Validation loss: 1.8488385574792021

Epoch: 6| Step: 12
Training loss: 0.7177271842956543
Validation loss: 1.9117410849499445

Epoch: 6| Step: 13
Training loss: 0.902888298034668
Validation loss: 1.9505696578692364

Epoch: 227| Step: 0
Training loss: 0.7055395841598511
Validation loss: 1.957973405879031

Epoch: 6| Step: 1
Training loss: 0.8955760598182678
Validation loss: 1.9287278780373194

Epoch: 6| Step: 2
Training loss: 0.6544955372810364
Validation loss: 1.8956873506628058

Epoch: 6| Step: 3
Training loss: 0.5654650330543518
Validation loss: 1.8823226344200872

Epoch: 6| Step: 4
Training loss: 1.1522010564804077
Validation loss: 1.8279281700811079

Epoch: 6| Step: 5
Training loss: 0.7552993297576904
Validation loss: 1.8038355458167292

Epoch: 6| Step: 6
Training loss: 0.507369875907898
Validation loss: 1.7901375691095989

Epoch: 6| Step: 7
Training loss: 0.6605771780014038
Validation loss: 1.8046822253093924

Epoch: 6| Step: 8
Training loss: 0.5752174854278564
Validation loss: 1.7860923659416936

Epoch: 6| Step: 9
Training loss: 0.5763024091720581
Validation loss: 1.784967609631118

Epoch: 6| Step: 10
Training loss: 0.5492265820503235
Validation loss: 1.8064249882134058

Epoch: 6| Step: 11
Training loss: 0.7594699859619141
Validation loss: 1.8301250703873173

Epoch: 6| Step: 12
Training loss: 0.8805702924728394
Validation loss: 1.902688859611429

Epoch: 6| Step: 13
Training loss: 0.519340991973877
Validation loss: 1.9239034088709022

Epoch: 228| Step: 0
Training loss: 0.6111134886741638
Validation loss: 1.9266758016360703

Epoch: 6| Step: 1
Training loss: 0.5015733242034912
Validation loss: 1.8747194928507651

Epoch: 6| Step: 2
Training loss: 0.6602794528007507
Validation loss: 1.8856350760306082

Epoch: 6| Step: 3
Training loss: 0.5565035939216614
Validation loss: 1.876867518630079

Epoch: 6| Step: 4
Training loss: 0.8251859545707703
Validation loss: 1.881292381594258

Epoch: 6| Step: 5
Training loss: 0.6403076648712158
Validation loss: 1.889330622970417

Epoch: 6| Step: 6
Training loss: 0.7387421131134033
Validation loss: 1.842937739946509

Epoch: 6| Step: 7
Training loss: 0.6369515061378479
Validation loss: 1.8474247827324817

Epoch: 6| Step: 8
Training loss: 0.6979267001152039
Validation loss: 1.835064379117822

Epoch: 6| Step: 9
Training loss: 1.071207880973816
Validation loss: 1.817427860793247

Epoch: 6| Step: 10
Training loss: 0.5323308110237122
Validation loss: 1.8256552680846183

Epoch: 6| Step: 11
Training loss: 0.7837166786193848
Validation loss: 1.801807334346156

Epoch: 6| Step: 12
Training loss: 0.5858070850372314
Validation loss: 1.8163740993827902

Epoch: 6| Step: 13
Training loss: 0.438414067029953
Validation loss: 1.7855294532673334

Epoch: 229| Step: 0
Training loss: 0.483670175075531
Validation loss: 1.8181137166997439

Epoch: 6| Step: 1
Training loss: 1.1415669918060303
Validation loss: 1.8083570323964602

Epoch: 6| Step: 2
Training loss: 0.668343186378479
Validation loss: 1.808344228293306

Epoch: 6| Step: 3
Training loss: 0.6256093382835388
Validation loss: 1.8227165540059407

Epoch: 6| Step: 4
Training loss: 0.6381667852401733
Validation loss: 1.82306848161964

Epoch: 6| Step: 5
Training loss: 0.43283596634864807
Validation loss: 1.837374379557948

Epoch: 6| Step: 6
Training loss: 0.677828311920166
Validation loss: 1.81061843902834

Epoch: 6| Step: 7
Training loss: 0.8163905143737793
Validation loss: 1.7946720405291485

Epoch: 6| Step: 8
Training loss: 0.6448520421981812
Validation loss: 1.797698974609375

Epoch: 6| Step: 9
Training loss: 0.623694121837616
Validation loss: 1.8352594824247463

Epoch: 6| Step: 10
Training loss: 0.45206719636917114
Validation loss: 1.8248160808317122

Epoch: 6| Step: 11
Training loss: 0.5699062943458557
Validation loss: 1.856974841446005

Epoch: 6| Step: 12
Training loss: 0.7365663051605225
Validation loss: 1.8723968318713609

Epoch: 6| Step: 13
Training loss: 0.8228009939193726
Validation loss: 1.897181721143825

Epoch: 230| Step: 0
Training loss: 1.0964083671569824
Validation loss: 1.8658703040051203

Epoch: 6| Step: 1
Training loss: 0.3939233422279358
Validation loss: 1.8608912062901322

Epoch: 6| Step: 2
Training loss: 0.6999317407608032
Validation loss: 1.8348508381074475

Epoch: 6| Step: 3
Training loss: 0.5149061679840088
Validation loss: 1.7909726327465427

Epoch: 6| Step: 4
Training loss: 0.4948108196258545
Validation loss: 1.7924242365744807

Epoch: 6| Step: 5
Training loss: 0.6675495505332947
Validation loss: 1.8053601300844582

Epoch: 6| Step: 6
Training loss: 0.8597266674041748
Validation loss: 1.8219055911546111

Epoch: 6| Step: 7
Training loss: 0.6868555545806885
Validation loss: 1.783699938046035

Epoch: 6| Step: 8
Training loss: 0.9102111458778381
Validation loss: 1.792601978907021

Epoch: 6| Step: 9
Training loss: 0.7080769538879395
Validation loss: 1.7966155941768358

Epoch: 6| Step: 10
Training loss: 0.5902681946754456
Validation loss: 1.8123485234475905

Epoch: 6| Step: 11
Training loss: 0.4666999578475952
Validation loss: 1.8387279331043203

Epoch: 6| Step: 12
Training loss: 0.915157675743103
Validation loss: 1.826724672830233

Epoch: 6| Step: 13
Training loss: 0.6217107772827148
Validation loss: 1.8330095987166128

Epoch: 231| Step: 0
Training loss: 0.9666880369186401
Validation loss: 1.799488224009032

Epoch: 6| Step: 1
Training loss: 0.5992634296417236
Validation loss: 1.8182251171399189

Epoch: 6| Step: 2
Training loss: 1.0481681823730469
Validation loss: 1.782151637538787

Epoch: 6| Step: 3
Training loss: 0.31894662976264954
Validation loss: 1.8101885472574542

Epoch: 6| Step: 4
Training loss: 0.9087756872177124
Validation loss: 1.8006287415822346

Epoch: 6| Step: 5
Training loss: 0.4848688542842865
Validation loss: 1.800349291934762

Epoch: 6| Step: 6
Training loss: 0.40359508991241455
Validation loss: 1.8439638742836573

Epoch: 6| Step: 7
Training loss: 0.7910749912261963
Validation loss: 1.8262715878025177

Epoch: 6| Step: 8
Training loss: 0.4443838596343994
Validation loss: 1.8362727460040842

Epoch: 6| Step: 9
Training loss: 0.3935757577419281
Validation loss: 1.8390083569352345

Epoch: 6| Step: 10
Training loss: 0.7342433929443359
Validation loss: 1.8295617975214475

Epoch: 6| Step: 11
Training loss: 0.6576401591300964
Validation loss: 1.8194275620163127

Epoch: 6| Step: 12
Training loss: 0.4963979721069336
Validation loss: 1.7802591054670271

Epoch: 6| Step: 13
Training loss: 0.9994133710861206
Validation loss: 1.7773999373118083

Epoch: 232| Step: 0
Training loss: 0.4958118200302124
Validation loss: 1.8108412988724247

Epoch: 6| Step: 1
Training loss: 0.4278939366340637
Validation loss: 1.8086250110339093

Epoch: 6| Step: 2
Training loss: 0.795991063117981
Validation loss: 1.7989635211165234

Epoch: 6| Step: 3
Training loss: 0.6196465492248535
Validation loss: 1.8325012358286048

Epoch: 6| Step: 4
Training loss: 0.592620313167572
Validation loss: 1.8591202664118942

Epoch: 6| Step: 5
Training loss: 0.7087520360946655
Validation loss: 1.8657244341347807

Epoch: 6| Step: 6
Training loss: 0.49620896577835083
Validation loss: 1.8939276767033402

Epoch: 6| Step: 7
Training loss: 0.5587486028671265
Validation loss: 1.845335014404789

Epoch: 6| Step: 8
Training loss: 0.6546637415885925
Validation loss: 1.844900022270859

Epoch: 6| Step: 9
Training loss: 0.41597050428390503
Validation loss: 1.826612505861508

Epoch: 6| Step: 10
Training loss: 0.7462751865386963
Validation loss: 1.8122076347310057

Epoch: 6| Step: 11
Training loss: 0.807785153388977
Validation loss: 1.8420062654761857

Epoch: 6| Step: 12
Training loss: 0.8720033168792725
Validation loss: 1.8439431305854552

Epoch: 6| Step: 13
Training loss: 1.1475927829742432
Validation loss: 1.8660545810576408

Epoch: 233| Step: 0
Training loss: 0.6372382640838623
Validation loss: 1.9011875480733893

Epoch: 6| Step: 1
Training loss: 0.7322602868080139
Validation loss: 1.9456445452987507

Epoch: 6| Step: 2
Training loss: 1.0056476593017578
Validation loss: 1.9198945388999036

Epoch: 6| Step: 3
Training loss: 0.31778061389923096
Validation loss: 1.9277530818857171

Epoch: 6| Step: 4
Training loss: 0.8180938363075256
Validation loss: 1.8902576661879016

Epoch: 6| Step: 5
Training loss: 0.5087411403656006
Validation loss: 1.8565935293833415

Epoch: 6| Step: 6
Training loss: 0.6091654896736145
Validation loss: 1.8562278401467107

Epoch: 6| Step: 7
Training loss: 0.4205200970172882
Validation loss: 1.847589982453213

Epoch: 6| Step: 8
Training loss: 0.5608861446380615
Validation loss: 1.8623972105723556

Epoch: 6| Step: 9
Training loss: 1.1043133735656738
Validation loss: 1.8599279952305618

Epoch: 6| Step: 10
Training loss: 0.9803705215454102
Validation loss: 1.8834273302426903

Epoch: 6| Step: 11
Training loss: 0.5125717520713806
Validation loss: 1.8664013493445613

Epoch: 6| Step: 12
Training loss: 0.3431936204433441
Validation loss: 1.8615599550226682

Epoch: 6| Step: 13
Training loss: 0.2643987238407135
Validation loss: 1.866723528472326

Epoch: 234| Step: 0
Training loss: 0.7335602641105652
Validation loss: 1.9051739720888035

Epoch: 6| Step: 1
Training loss: 0.6749149560928345
Validation loss: 1.9124105745746243

Epoch: 6| Step: 2
Training loss: 0.5091807246208191
Validation loss: 1.8959713264178204

Epoch: 6| Step: 3
Training loss: 0.8885877132415771
Validation loss: 1.9131199249657251

Epoch: 6| Step: 4
Training loss: 0.4123225808143616
Validation loss: 1.8586373008707517

Epoch: 6| Step: 5
Training loss: 0.6100053787231445
Validation loss: 1.8252632464132001

Epoch: 6| Step: 6
Training loss: 0.5704142451286316
Validation loss: 1.813479882414623

Epoch: 6| Step: 7
Training loss: 0.7883699536323547
Validation loss: 1.7895484765370686

Epoch: 6| Step: 8
Training loss: 0.5062576532363892
Validation loss: 1.79247397376645

Epoch: 6| Step: 9
Training loss: 0.4058174788951874
Validation loss: 1.8090039376289613

Epoch: 6| Step: 10
Training loss: 0.6174666285514832
Validation loss: 1.8274912859803887

Epoch: 6| Step: 11
Training loss: 0.37933459877967834
Validation loss: 1.8311488961660733

Epoch: 6| Step: 12
Training loss: 0.5987914800643921
Validation loss: 1.8713035301495624

Epoch: 6| Step: 13
Training loss: 0.948637843132019
Validation loss: 1.864544496741346

Epoch: 235| Step: 0
Training loss: 0.22635966539382935
Validation loss: 1.8707965894411969

Epoch: 6| Step: 1
Training loss: 0.578137218952179
Validation loss: 1.851030759913947

Epoch: 6| Step: 2
Training loss: 0.6184152960777283
Validation loss: 1.8240849305224676

Epoch: 6| Step: 3
Training loss: 0.5377565026283264
Validation loss: 1.8177661818842734

Epoch: 6| Step: 4
Training loss: 0.33162277936935425
Validation loss: 1.7968113435212003

Epoch: 6| Step: 5
Training loss: 1.2128612995147705
Validation loss: 1.8260409434636433

Epoch: 6| Step: 6
Training loss: 0.5987904071807861
Validation loss: 1.8123628772715086

Epoch: 6| Step: 7
Training loss: 0.6743347644805908
Validation loss: 1.8431905392677552

Epoch: 6| Step: 8
Training loss: 0.3048572838306427
Validation loss: 1.8590197370898338

Epoch: 6| Step: 9
Training loss: 0.4555581212043762
Validation loss: 1.8541040805078322

Epoch: 6| Step: 10
Training loss: 0.47697222232818604
Validation loss: 1.8684774086039553

Epoch: 6| Step: 11
Training loss: 1.1496055126190186
Validation loss: 1.884416966028111

Epoch: 6| Step: 12
Training loss: 0.5180431008338928
Validation loss: 1.8571354407136158

Epoch: 6| Step: 13
Training loss: 0.8358645439147949
Validation loss: 1.826992610449432

Epoch: 236| Step: 0
Training loss: 0.48095911741256714
Validation loss: 1.8108699424292451

Epoch: 6| Step: 1
Training loss: 0.4616960287094116
Validation loss: 1.8119433772179387

Epoch: 6| Step: 2
Training loss: 0.619614839553833
Validation loss: 1.8029143656453779

Epoch: 6| Step: 3
Training loss: 0.6856573820114136
Validation loss: 1.7986190549788936

Epoch: 6| Step: 4
Training loss: 0.4718341529369354
Validation loss: 1.7946643598618046

Epoch: 6| Step: 5
Training loss: 0.5018974542617798
Validation loss: 1.8022985548101447

Epoch: 6| Step: 6
Training loss: 0.41792693734169006
Validation loss: 1.8161131412752214

Epoch: 6| Step: 7
Training loss: 0.604088544845581
Validation loss: 1.849130771493399

Epoch: 6| Step: 8
Training loss: 0.7587689161300659
Validation loss: 1.8675715474672214

Epoch: 6| Step: 9
Training loss: 0.5087772011756897
Validation loss: 1.8670923030504616

Epoch: 6| Step: 10
Training loss: 0.4965322017669678
Validation loss: 1.8616438437533636

Epoch: 6| Step: 11
Training loss: 1.099562406539917
Validation loss: 1.8172538062577606

Epoch: 6| Step: 12
Training loss: 0.8480026125907898
Validation loss: 1.747516716680219

Epoch: 6| Step: 13
Training loss: 0.40139612555503845
Validation loss: 1.7808597728770266

Epoch: 237| Step: 0
Training loss: 0.4219265580177307
Validation loss: 1.7589778502782185

Epoch: 6| Step: 1
Training loss: 0.4965539276599884
Validation loss: 1.7462205207476051

Epoch: 6| Step: 2
Training loss: 0.5376245975494385
Validation loss: 1.748803533533568

Epoch: 6| Step: 3
Training loss: 0.6188074350357056
Validation loss: 1.7911612154335104

Epoch: 6| Step: 4
Training loss: 0.8273419737815857
Validation loss: 1.8250373255821966

Epoch: 6| Step: 5
Training loss: 0.34198176860809326
Validation loss: 1.8344830287400113

Epoch: 6| Step: 6
Training loss: 0.3823537230491638
Validation loss: 1.848332901154795

Epoch: 6| Step: 7
Training loss: 0.8158395290374756
Validation loss: 1.8329670147229267

Epoch: 6| Step: 8
Training loss: 0.6021614670753479
Validation loss: 1.8395125917209092

Epoch: 6| Step: 9
Training loss: 0.5597417950630188
Validation loss: 1.8258125192375594

Epoch: 6| Step: 10
Training loss: 0.6636697053909302
Validation loss: 1.8628970807598484

Epoch: 6| Step: 11
Training loss: 0.8764351010322571
Validation loss: 1.8430292260262273

Epoch: 6| Step: 12
Training loss: 0.5022817850112915
Validation loss: 1.8603145999293174

Epoch: 6| Step: 13
Training loss: 0.47810566425323486
Validation loss: 1.8499365609179261

Epoch: 238| Step: 0
Training loss: 0.9809669256210327
Validation loss: 1.8189109627918532

Epoch: 6| Step: 1
Training loss: 0.4071095287799835
Validation loss: 1.7680587691645469

Epoch: 6| Step: 2
Training loss: 0.3392027020454407
Validation loss: 1.8034106980087936

Epoch: 6| Step: 3
Training loss: 0.780113160610199
Validation loss: 1.8269136105814288

Epoch: 6| Step: 4
Training loss: 0.40046045184135437
Validation loss: 1.8379594177328131

Epoch: 6| Step: 5
Training loss: 0.6176848411560059
Validation loss: 1.8336454232533772

Epoch: 6| Step: 6
Training loss: 0.6446112394332886
Validation loss: 1.8276825950991722

Epoch: 6| Step: 7
Training loss: 0.5973010659217834
Validation loss: 1.834241528664866

Epoch: 6| Step: 8
Training loss: 0.562323808670044
Validation loss: 1.851842655930468

Epoch: 6| Step: 9
Training loss: 0.8234195113182068
Validation loss: 1.852995546915198

Epoch: 6| Step: 10
Training loss: 0.4891759753227234
Validation loss: 1.8143992449647637

Epoch: 6| Step: 11
Training loss: 0.2928221821784973
Validation loss: 1.828660632974358

Epoch: 6| Step: 12
Training loss: 0.3965071737766266
Validation loss: 1.833019002791374

Epoch: 6| Step: 13
Training loss: 0.5912779569625854
Validation loss: 1.8375062622049803

Epoch: 239| Step: 0
Training loss: 0.31448671221733093
Validation loss: 1.8418041313848188

Epoch: 6| Step: 1
Training loss: 0.5117340087890625
Validation loss: 1.845248382578614

Epoch: 6| Step: 2
Training loss: 0.37522053718566895
Validation loss: 1.853593131547333

Epoch: 6| Step: 3
Training loss: 0.6280444860458374
Validation loss: 1.880456119455317

Epoch: 6| Step: 4
Training loss: 0.7555215358734131
Validation loss: 1.839003873127763

Epoch: 6| Step: 5
Training loss: 0.5700446367263794
Validation loss: 1.8058500853917931

Epoch: 6| Step: 6
Training loss: 0.4526638984680176
Validation loss: 1.800697285000996

Epoch: 6| Step: 7
Training loss: 0.5970289707183838
Validation loss: 1.7845949421646774

Epoch: 6| Step: 8
Training loss: 0.45170146226882935
Validation loss: 1.7742028338934785

Epoch: 6| Step: 9
Training loss: 0.5004013180732727
Validation loss: 1.771339037085092

Epoch: 6| Step: 10
Training loss: 0.6060459613800049
Validation loss: 1.7634674477320846

Epoch: 6| Step: 11
Training loss: 1.0834407806396484
Validation loss: 1.767554868933975

Epoch: 6| Step: 12
Training loss: 0.5242820978164673
Validation loss: 1.772817615539797

Epoch: 6| Step: 13
Training loss: 0.6032964587211609
Validation loss: 1.7848683505929925

Epoch: 240| Step: 0
Training loss: 0.4154077172279358
Validation loss: 1.812850825248226

Epoch: 6| Step: 1
Training loss: 0.7070128917694092
Validation loss: 1.8253850898435038

Epoch: 6| Step: 2
Training loss: 0.45055270195007324
Validation loss: 1.8238828130947646

Epoch: 6| Step: 3
Training loss: 0.538737416267395
Validation loss: 1.8708796603705293

Epoch: 6| Step: 4
Training loss: 0.5035371780395508
Validation loss: 1.8962191702217184

Epoch: 6| Step: 5
Training loss: 0.49814456701278687
Validation loss: 1.9079293717620194

Epoch: 6| Step: 6
Training loss: 0.5573080778121948
Validation loss: 1.8325054414810673

Epoch: 6| Step: 7
Training loss: 0.790645956993103
Validation loss: 1.812110206132294

Epoch: 6| Step: 8
Training loss: 0.6584837436676025
Validation loss: 1.797363112049718

Epoch: 6| Step: 9
Training loss: 0.550615668296814
Validation loss: 1.770264776804114

Epoch: 6| Step: 10
Training loss: 0.5323107242584229
Validation loss: 1.7655966140890633

Epoch: 6| Step: 11
Training loss: 0.6294615268707275
Validation loss: 1.7821554778724589

Epoch: 6| Step: 12
Training loss: 0.531602144241333
Validation loss: 1.7733291259375952

Epoch: 6| Step: 13
Training loss: 0.9034058451652527
Validation loss: 1.7838921880209317

Epoch: 241| Step: 0
Training loss: 0.3908587098121643
Validation loss: 1.7675408163378317

Epoch: 6| Step: 1
Training loss: 0.5808308124542236
Validation loss: 1.8250310267171552

Epoch: 6| Step: 2
Training loss: 0.671262264251709
Validation loss: 1.8405380466932892

Epoch: 6| Step: 3
Training loss: 0.44329768419265747
Validation loss: 1.8614763213742165

Epoch: 6| Step: 4
Training loss: 0.28394681215286255
Validation loss: 1.8551051873032764

Epoch: 6| Step: 5
Training loss: 0.6593236327171326
Validation loss: 1.8482619254819808

Epoch: 6| Step: 6
Training loss: 0.5307886600494385
Validation loss: 1.8414999464506745

Epoch: 6| Step: 7
Training loss: 0.4566062092781067
Validation loss: 1.842394301968236

Epoch: 6| Step: 8
Training loss: 0.5177333354949951
Validation loss: 1.827568038817375

Epoch: 6| Step: 9
Training loss: 0.30180859565734863
Validation loss: 1.8024341906270673

Epoch: 6| Step: 10
Training loss: 0.771842360496521
Validation loss: 1.8327919296039048

Epoch: 6| Step: 11
Training loss: 0.8846077919006348
Validation loss: 1.8189315052442654

Epoch: 6| Step: 12
Training loss: 0.6719805002212524
Validation loss: 1.8331386171361452

Epoch: 6| Step: 13
Training loss: 0.21258644759655
Validation loss: 1.8470576142752042

Epoch: 242| Step: 0
Training loss: 0.4480031728744507
Validation loss: 1.8628522542215162

Epoch: 6| Step: 1
Training loss: 0.7521791458129883
Validation loss: 1.9125794492742068

Epoch: 6| Step: 2
Training loss: 0.7012209296226501
Validation loss: 1.9153853206224338

Epoch: 6| Step: 3
Training loss: 0.5026407241821289
Validation loss: 1.889273185883799

Epoch: 6| Step: 4
Training loss: 0.5142096877098083
Validation loss: 1.842641330534412

Epoch: 6| Step: 5
Training loss: 0.49505120515823364
Validation loss: 1.807936668395996

Epoch: 6| Step: 6
Training loss: 0.5311944484710693
Validation loss: 1.7651906000670565

Epoch: 6| Step: 7
Training loss: 0.6757947206497192
Validation loss: 1.7492602371400403

Epoch: 6| Step: 8
Training loss: 0.6394880414009094
Validation loss: 1.763222917433708

Epoch: 6| Step: 9
Training loss: 0.4453929662704468
Validation loss: 1.7654341446456088

Epoch: 6| Step: 10
Training loss: 0.7674124240875244
Validation loss: 1.774764818529929

Epoch: 6| Step: 11
Training loss: 0.4026423692703247
Validation loss: 1.8098360851246824

Epoch: 6| Step: 12
Training loss: 0.2701958417892456
Validation loss: 1.8027266404962028

Epoch: 6| Step: 13
Training loss: 0.4340316951274872
Validation loss: 1.8003884259090628

Epoch: 243| Step: 0
Training loss: 0.35254019498825073
Validation loss: 1.8438118388575893

Epoch: 6| Step: 1
Training loss: 0.4399110972881317
Validation loss: 1.866351555752498

Epoch: 6| Step: 2
Training loss: 0.6173121929168701
Validation loss: 1.8465876771557717

Epoch: 6| Step: 3
Training loss: 0.6494496464729309
Validation loss: 1.8523084309793287

Epoch: 6| Step: 4
Training loss: 0.8351061344146729
Validation loss: 1.8591026426643453

Epoch: 6| Step: 5
Training loss: 0.4726986885070801
Validation loss: 1.8727244279717887

Epoch: 6| Step: 6
Training loss: 0.3175560534000397
Validation loss: 1.8630055842861053

Epoch: 6| Step: 7
Training loss: 0.4797602891921997
Validation loss: 1.866655001076319

Epoch: 6| Step: 8
Training loss: 0.6073129773139954
Validation loss: 1.8591610270161782

Epoch: 6| Step: 9
Training loss: 0.3684394061565399
Validation loss: 1.8145395248166976

Epoch: 6| Step: 10
Training loss: 0.4203822910785675
Validation loss: 1.816401784138013

Epoch: 6| Step: 11
Training loss: 0.6652345657348633
Validation loss: 1.7794898171578684

Epoch: 6| Step: 12
Training loss: 0.8796736001968384
Validation loss: 1.8123359167447655

Epoch: 6| Step: 13
Training loss: 0.33047330379486084
Validation loss: 1.814695672322345

Epoch: 244| Step: 0
Training loss: 0.5398166179656982
Validation loss: 1.8205200741367955

Epoch: 6| Step: 1
Training loss: 0.6926631331443787
Validation loss: 1.8363025278173468

Epoch: 6| Step: 2
Training loss: 0.8143382668495178
Validation loss: 1.8604814416618758

Epoch: 6| Step: 3
Training loss: 0.37223541736602783
Validation loss: 1.8553936007202312

Epoch: 6| Step: 4
Training loss: 0.3458375632762909
Validation loss: 1.8834327638790171

Epoch: 6| Step: 5
Training loss: 0.322095662355423
Validation loss: 1.8690546251112414

Epoch: 6| Step: 6
Training loss: 0.47306379675865173
Validation loss: 1.8397745393937635

Epoch: 6| Step: 7
Training loss: 0.555039644241333
Validation loss: 1.8065403366601596

Epoch: 6| Step: 8
Training loss: 0.5474792718887329
Validation loss: 1.774721937794839

Epoch: 6| Step: 9
Training loss: 0.4323365092277527
Validation loss: 1.773791584917294

Epoch: 6| Step: 10
Training loss: 0.7548120617866516
Validation loss: 1.7475363234037995

Epoch: 6| Step: 11
Training loss: 0.4565090239048004
Validation loss: 1.7439111253266693

Epoch: 6| Step: 12
Training loss: 0.4505217671394348
Validation loss: 1.7680999668695594

Epoch: 6| Step: 13
Training loss: 0.5792920589447021
Validation loss: 1.782638096040295

Epoch: 245| Step: 0
Training loss: 0.19346554577350616
Validation loss: 1.8083975353548605

Epoch: 6| Step: 1
Training loss: 0.6070554256439209
Validation loss: 1.8229133211156374

Epoch: 6| Step: 2
Training loss: 0.7655558586120605
Validation loss: 1.8313543232538367

Epoch: 6| Step: 3
Training loss: 0.8088769316673279
Validation loss: 1.8666296453886135

Epoch: 6| Step: 4
Training loss: 0.5601201057434082
Validation loss: 1.8337242705847627

Epoch: 6| Step: 5
Training loss: 0.36191481351852417
Validation loss: 1.8075458747084423

Epoch: 6| Step: 6
Training loss: 0.36229339241981506
Validation loss: 1.8045640914670882

Epoch: 6| Step: 7
Training loss: 0.7569558024406433
Validation loss: 1.7994381061164282

Epoch: 6| Step: 8
Training loss: 0.3763865828514099
Validation loss: 1.804111872949908

Epoch: 6| Step: 9
Training loss: 0.4858522415161133
Validation loss: 1.8325454304295201

Epoch: 6| Step: 10
Training loss: 0.43430373072624207
Validation loss: 1.8396668946871193

Epoch: 6| Step: 11
Training loss: 0.45423781871795654
Validation loss: 1.8413498363187235

Epoch: 6| Step: 12
Training loss: 0.35771721601486206
Validation loss: 1.8493984373666907

Epoch: 6| Step: 13
Training loss: 0.49319028854370117
Validation loss: 1.8267958856398059

Epoch: 246| Step: 0
Training loss: 0.37894129753112793
Validation loss: 1.8100410443480297

Epoch: 6| Step: 1
Training loss: 0.23328375816345215
Validation loss: 1.795742424585486

Epoch: 6| Step: 2
Training loss: 0.3702355921268463
Validation loss: 1.8234344900295298

Epoch: 6| Step: 3
Training loss: 0.6583157777786255
Validation loss: 1.8062882820765178

Epoch: 6| Step: 4
Training loss: 0.36149996519088745
Validation loss: 1.8200633500211982

Epoch: 6| Step: 5
Training loss: 0.45704445242881775
Validation loss: 1.8061025860489055

Epoch: 6| Step: 6
Training loss: 0.666904091835022
Validation loss: 1.815758555166183

Epoch: 6| Step: 7
Training loss: 0.46877384185791016
Validation loss: 1.83401321852079

Epoch: 6| Step: 8
Training loss: 0.39859098196029663
Validation loss: 1.8660568473159627

Epoch: 6| Step: 9
Training loss: 0.5463814735412598
Validation loss: 1.8407373300162695

Epoch: 6| Step: 10
Training loss: 0.7061160802841187
Validation loss: 1.8466613779785812

Epoch: 6| Step: 11
Training loss: 0.6467069387435913
Validation loss: 1.8455138014208885

Epoch: 6| Step: 12
Training loss: 0.6452310681343079
Validation loss: 1.7998843673736817

Epoch: 6| Step: 13
Training loss: 0.6039181351661682
Validation loss: 1.808700740978282

Epoch: 247| Step: 0
Training loss: 0.46991533041000366
Validation loss: 1.8056380594930341

Epoch: 6| Step: 1
Training loss: 0.30829328298568726
Validation loss: 1.7950275739034016

Epoch: 6| Step: 2
Training loss: 0.6375958323478699
Validation loss: 1.8091445071722871

Epoch: 6| Step: 3
Training loss: 0.5477020740509033
Validation loss: 1.7924063282628213

Epoch: 6| Step: 4
Training loss: 0.576028048992157
Validation loss: 1.7805405098904845

Epoch: 6| Step: 5
Training loss: 0.3971918225288391
Validation loss: 1.7958640988155077

Epoch: 6| Step: 6
Training loss: 0.36600106954574585
Validation loss: 1.7784703200863254

Epoch: 6| Step: 7
Training loss: 0.5527784824371338
Validation loss: 1.787636984420079

Epoch: 6| Step: 8
Training loss: 0.3552280068397522
Validation loss: 1.8355613754641624

Epoch: 6| Step: 9
Training loss: 0.6591202616691589
Validation loss: 1.8052262054976596

Epoch: 6| Step: 10
Training loss: 0.5271903872489929
Validation loss: 1.7724065960094493

Epoch: 6| Step: 11
Training loss: 0.7783722281455994
Validation loss: 1.763021711380251

Epoch: 6| Step: 12
Training loss: 0.44555187225341797
Validation loss: 1.7485459184133878

Epoch: 6| Step: 13
Training loss: 0.3831291198730469
Validation loss: 1.7505189141919535

Epoch: 248| Step: 0
Training loss: 0.29708290100097656
Validation loss: 1.7352935985852314

Epoch: 6| Step: 1
Training loss: 0.5604225397109985
Validation loss: 1.7496114533434632

Epoch: 6| Step: 2
Training loss: 0.30142438411712646
Validation loss: 1.7750215684213946

Epoch: 6| Step: 3
Training loss: 0.7516418099403381
Validation loss: 1.7825846108057166

Epoch: 6| Step: 4
Training loss: 0.4483233690261841
Validation loss: 1.8127806109766806

Epoch: 6| Step: 5
Training loss: 0.3618227541446686
Validation loss: 1.7848127375366867

Epoch: 6| Step: 6
Training loss: 0.33747920393943787
Validation loss: 1.7829469532094977

Epoch: 6| Step: 7
Training loss: 0.633069634437561
Validation loss: 1.8072191790867878

Epoch: 6| Step: 8
Training loss: 0.47545233368873596
Validation loss: 1.792368337672244

Epoch: 6| Step: 9
Training loss: 0.6363896131515503
Validation loss: 1.7897152022648883

Epoch: 6| Step: 10
Training loss: 0.8921124935150146
Validation loss: 1.8098540075363652

Epoch: 6| Step: 11
Training loss: 0.16147610545158386
Validation loss: 1.7719513216326315

Epoch: 6| Step: 12
Training loss: 0.32632485032081604
Validation loss: 1.77559563549616

Epoch: 6| Step: 13
Training loss: 0.4653548002243042
Validation loss: 1.7628046094730336

Epoch: 249| Step: 0
Training loss: 0.3914552330970764
Validation loss: 1.7509997198658604

Epoch: 6| Step: 1
Training loss: 0.5719749927520752
Validation loss: 1.7743313722713019

Epoch: 6| Step: 2
Training loss: 0.36737895011901855
Validation loss: 1.7651000945798812

Epoch: 6| Step: 3
Training loss: 0.44369855523109436
Validation loss: 1.7612549284453034

Epoch: 6| Step: 4
Training loss: 0.46401992440223694
Validation loss: 1.77526076891089

Epoch: 6| Step: 5
Training loss: 0.25872379541397095
Validation loss: 1.7721764945214795

Epoch: 6| Step: 6
Training loss: 0.4129640460014343
Validation loss: 1.796905340686921

Epoch: 6| Step: 7
Training loss: 0.5200068950653076
Validation loss: 1.7933284467266453

Epoch: 6| Step: 8
Training loss: 0.6597084999084473
Validation loss: 1.8087133463992868

Epoch: 6| Step: 9
Training loss: 0.434085875749588
Validation loss: 1.776131538934605

Epoch: 6| Step: 10
Training loss: 0.2211526483297348
Validation loss: 1.7789142977806829

Epoch: 6| Step: 11
Training loss: 0.7778747081756592
Validation loss: 1.7685151907705492

Epoch: 6| Step: 12
Training loss: 0.7334282398223877
Validation loss: 1.7568011950421076

Epoch: 6| Step: 13
Training loss: 0.6777188181877136
Validation loss: 1.7396264717143068

Epoch: 250| Step: 0
Training loss: 0.5024163722991943
Validation loss: 1.695210623484786

Epoch: 6| Step: 1
Training loss: 0.3948037624359131
Validation loss: 1.661840118387694

Epoch: 6| Step: 2
Training loss: 0.5752931237220764
Validation loss: 1.6730533107634513

Epoch: 6| Step: 3
Training loss: 0.45102205872535706
Validation loss: 1.694663672037022

Epoch: 6| Step: 4
Training loss: 0.3280032277107239
Validation loss: 1.6994778789499754

Epoch: 6| Step: 5
Training loss: 0.4782564043998718
Validation loss: 1.7164557108315088

Epoch: 6| Step: 6
Training loss: 0.47007322311401367
Validation loss: 1.7264268936649445

Epoch: 6| Step: 7
Training loss: 0.48272788524627686
Validation loss: 1.7676194752416303

Epoch: 6| Step: 8
Training loss: 0.5691968202590942
Validation loss: 1.7448415461406912

Epoch: 6| Step: 9
Training loss: 0.49014735221862793
Validation loss: 1.7540419537533996

Epoch: 6| Step: 10
Training loss: 0.43862056732177734
Validation loss: 1.7668931484222412

Epoch: 6| Step: 11
Training loss: 0.8658303022384644
Validation loss: 1.7509615062385477

Epoch: 6| Step: 12
Training loss: 0.4198625087738037
Validation loss: 1.75125458932692

Epoch: 6| Step: 13
Training loss: 0.38192734122276306
Validation loss: 1.7729427147937078

Epoch: 251| Step: 0
Training loss: 0.41248372197151184
Validation loss: 1.7303379812548239

Epoch: 6| Step: 1
Training loss: 0.7147413492202759
Validation loss: 1.7560870903794483

Epoch: 6| Step: 2
Training loss: 0.42904162406921387
Validation loss: 1.7568524960548646

Epoch: 6| Step: 3
Training loss: 0.37673234939575195
Validation loss: 1.7527254653233353

Epoch: 6| Step: 4
Training loss: 0.4409647583961487
Validation loss: 1.7541472911834717

Epoch: 6| Step: 5
Training loss: 0.518075704574585
Validation loss: 1.762485736159868

Epoch: 6| Step: 6
Training loss: 0.397453635931015
Validation loss: 1.7602890050539406

Epoch: 6| Step: 7
Training loss: 0.6618582606315613
Validation loss: 1.7919387637927968

Epoch: 6| Step: 8
Training loss: 0.5063340663909912
Validation loss: 1.7798278677848078

Epoch: 6| Step: 9
Training loss: 0.43077367544174194
Validation loss: 1.7838911343646306

Epoch: 6| Step: 10
Training loss: 0.46196645498275757
Validation loss: 1.778272891557345

Epoch: 6| Step: 11
Training loss: 0.6595807075500488
Validation loss: 1.7477957138451197

Epoch: 6| Step: 12
Training loss: 0.42859745025634766
Validation loss: 1.7446557398765319

Epoch: 6| Step: 13
Training loss: 0.4398175776004791
Validation loss: 1.7314910068306872

Epoch: 252| Step: 0
Training loss: 0.28077229857444763
Validation loss: 1.7418387025915167

Epoch: 6| Step: 1
Training loss: 0.3091672658920288
Validation loss: 1.7204066732878327

Epoch: 6| Step: 2
Training loss: 0.39170485734939575
Validation loss: 1.7362761318042714

Epoch: 6| Step: 3
Training loss: 0.48850080370903015
Validation loss: 1.760288215452625

Epoch: 6| Step: 4
Training loss: 0.691204845905304
Validation loss: 1.800438150282829

Epoch: 6| Step: 5
Training loss: 0.7509051561355591
Validation loss: 1.806478351675054

Epoch: 6| Step: 6
Training loss: 0.47956007719039917
Validation loss: 1.7721877944084905

Epoch: 6| Step: 7
Training loss: 0.46250319480895996
Validation loss: 1.7570059222559775

Epoch: 6| Step: 8
Training loss: 0.5602074861526489
Validation loss: 1.7438688175652617

Epoch: 6| Step: 9
Training loss: 0.38177746534347534
Validation loss: 1.714248498280843

Epoch: 6| Step: 10
Training loss: 0.6232079267501831
Validation loss: 1.7117335539992138

Epoch: 6| Step: 11
Training loss: 0.6269479990005493
Validation loss: 1.7271925364771197

Epoch: 6| Step: 12
Training loss: 0.1763186752796173
Validation loss: 1.7351420233326573

Epoch: 6| Step: 13
Training loss: 0.1193062886595726
Validation loss: 1.6964446049864574

Epoch: 253| Step: 0
Training loss: 0.7073718309402466
Validation loss: 1.7153069742264286

Epoch: 6| Step: 1
Training loss: 0.23961007595062256
Validation loss: 1.7316601712216613

Epoch: 6| Step: 2
Training loss: 0.3834943473339081
Validation loss: 1.7330136517042756

Epoch: 6| Step: 3
Training loss: 0.2984919548034668
Validation loss: 1.7246497267036027

Epoch: 6| Step: 4
Training loss: 0.36670058965682983
Validation loss: 1.6758931042045675

Epoch: 6| Step: 5
Training loss: 0.6280391216278076
Validation loss: 1.6940842943806802

Epoch: 6| Step: 6
Training loss: 0.44255027174949646
Validation loss: 1.6997013989315237

Epoch: 6| Step: 7
Training loss: 0.5854411721229553
Validation loss: 1.6938329332618303

Epoch: 6| Step: 8
Training loss: 0.6626867651939392
Validation loss: 1.7257339210920437

Epoch: 6| Step: 9
Training loss: 0.5897191762924194
Validation loss: 1.7222195133086173

Epoch: 6| Step: 10
Training loss: 0.2680296003818512
Validation loss: 1.708165176453129

Epoch: 6| Step: 11
Training loss: 0.5002166032791138
Validation loss: 1.7214618754643265

Epoch: 6| Step: 12
Training loss: 0.2361341416835785
Validation loss: 1.7419541023110832

Epoch: 6| Step: 13
Training loss: 0.5452041029930115
Validation loss: 1.7687009431982552

Epoch: 254| Step: 0
Training loss: 0.5215721130371094
Validation loss: 1.7168380496322468

Epoch: 6| Step: 1
Training loss: 0.33717775344848633
Validation loss: 1.7303364058976531

Epoch: 6| Step: 2
Training loss: 0.5227481722831726
Validation loss: 1.722701241893153

Epoch: 6| Step: 3
Training loss: 0.5053915977478027
Validation loss: 1.732410979527299

Epoch: 6| Step: 4
Training loss: 0.39282917976379395
Validation loss: 1.7565390704780497

Epoch: 6| Step: 5
Training loss: 0.34337615966796875
Validation loss: 1.784241263584424

Epoch: 6| Step: 6
Training loss: 0.46726977825164795
Validation loss: 1.7929466360358781

Epoch: 6| Step: 7
Training loss: 0.5306100845336914
Validation loss: 1.7818842177749963

Epoch: 6| Step: 8
Training loss: 0.2343720942735672
Validation loss: 1.7576580944881643

Epoch: 6| Step: 9
Training loss: 0.7359880208969116
Validation loss: 1.7176576429797756

Epoch: 6| Step: 10
Training loss: 0.4471222162246704
Validation loss: 1.712971673216871

Epoch: 6| Step: 11
Training loss: 0.33410370349884033
Validation loss: 1.6721310846267208

Epoch: 6| Step: 12
Training loss: 0.3470480442047119
Validation loss: 1.7153158508321291

Epoch: 6| Step: 13
Training loss: 0.4504718780517578
Validation loss: 1.7176739028705064

Epoch: 255| Step: 0
Training loss: 0.38222721219062805
Validation loss: 1.7342432903987106

Epoch: 6| Step: 1
Training loss: 0.47317418456077576
Validation loss: 1.7594980475723103

Epoch: 6| Step: 2
Training loss: 0.29456257820129395
Validation loss: 1.7956505180687032

Epoch: 6| Step: 3
Training loss: 0.3426949977874756
Validation loss: 1.7954435604874805

Epoch: 6| Step: 4
Training loss: 0.1737433671951294
Validation loss: 1.7498574269715177

Epoch: 6| Step: 5
Training loss: 0.446411669254303
Validation loss: 1.767501183735427

Epoch: 6| Step: 6
Training loss: 0.6292709708213806
Validation loss: 1.7332017703722882

Epoch: 6| Step: 7
Training loss: 0.7455745935440063
Validation loss: 1.7328136441528157

Epoch: 6| Step: 8
Training loss: 0.4489378035068512
Validation loss: 1.728527251110282

Epoch: 6| Step: 9
Training loss: 0.3421090841293335
Validation loss: 1.7309571466138285

Epoch: 6| Step: 10
Training loss: 0.27842068672180176
Validation loss: 1.7252083260525939

Epoch: 6| Step: 11
Training loss: 0.5457016229629517
Validation loss: 1.7489812848388508

Epoch: 6| Step: 12
Training loss: 0.43430057168006897
Validation loss: 1.737376409192239

Epoch: 6| Step: 13
Training loss: 0.34041357040405273
Validation loss: 1.7481424821320402

Epoch: 256| Step: 0
Training loss: 0.2795242667198181
Validation loss: 1.7637008390118998

Epoch: 6| Step: 1
Training loss: 0.5050350427627563
Validation loss: 1.786793294773307

Epoch: 6| Step: 2
Training loss: 0.40398234128952026
Validation loss: 1.7867914143429007

Epoch: 6| Step: 3
Training loss: 0.30527257919311523
Validation loss: 1.7826324021944435

Epoch: 6| Step: 4
Training loss: 0.5893274545669556
Validation loss: 1.7747575185632194

Epoch: 6| Step: 5
Training loss: 0.4213021993637085
Validation loss: 1.7676847968050229

Epoch: 6| Step: 6
Training loss: 0.3029320538043976
Validation loss: 1.7512809256071686

Epoch: 6| Step: 7
Training loss: 0.5329643487930298
Validation loss: 1.7242482439164193

Epoch: 6| Step: 8
Training loss: 0.21706533432006836
Validation loss: 1.7309147388704362

Epoch: 6| Step: 9
Training loss: 0.48524075746536255
Validation loss: 1.7262133782909763

Epoch: 6| Step: 10
Training loss: 0.3820585012435913
Validation loss: 1.755617223760133

Epoch: 6| Step: 11
Training loss: 0.5051013231277466
Validation loss: 1.7797089161411408

Epoch: 6| Step: 12
Training loss: 0.7512003183364868
Validation loss: 1.7780068164230676

Epoch: 6| Step: 13
Training loss: 0.3131256401538849
Validation loss: 1.805379061288731

Epoch: 257| Step: 0
Training loss: 0.32212167978286743
Validation loss: 1.7928858905710199

Epoch: 6| Step: 1
Training loss: 0.47436386346817017
Validation loss: 1.7990495812508367

Epoch: 6| Step: 2
Training loss: 0.42684781551361084
Validation loss: 1.7851760464329873

Epoch: 6| Step: 3
Training loss: 0.32868441939353943
Validation loss: 1.765606668687636

Epoch: 6| Step: 4
Training loss: 0.5363370776176453
Validation loss: 1.7451670733831262

Epoch: 6| Step: 5
Training loss: 0.5820761919021606
Validation loss: 1.718168148430445

Epoch: 6| Step: 6
Training loss: 0.36974143981933594
Validation loss: 1.7265493997963526

Epoch: 6| Step: 7
Training loss: 0.3722463548183441
Validation loss: 1.7108158039790329

Epoch: 6| Step: 8
Training loss: 0.20482929050922394
Validation loss: 1.7170618541779057

Epoch: 6| Step: 9
Training loss: 0.6588930487632751
Validation loss: 1.738129695256551

Epoch: 6| Step: 10
Training loss: 0.7696508765220642
Validation loss: 1.7460674637107438

Epoch: 6| Step: 11
Training loss: 0.32071882486343384
Validation loss: 1.7349239485238188

Epoch: 6| Step: 12
Training loss: 0.417336106300354
Validation loss: 1.7127179650850193

Epoch: 6| Step: 13
Training loss: 0.34461304545402527
Validation loss: 1.736134034331127

Epoch: 258| Step: 0
Training loss: 0.3856930732727051
Validation loss: 1.7239327725543772

Epoch: 6| Step: 1
Training loss: 0.4184788465499878
Validation loss: 1.711264891009177

Epoch: 6| Step: 2
Training loss: 0.513006865978241
Validation loss: 1.7435489700686546

Epoch: 6| Step: 3
Training loss: 0.35061323642730713
Validation loss: 1.739946153856093

Epoch: 6| Step: 4
Training loss: 0.3798007369041443
Validation loss: 1.7344957538830337

Epoch: 6| Step: 5
Training loss: 0.3346971869468689
Validation loss: 1.7298651690124183

Epoch: 6| Step: 6
Training loss: 0.2738311290740967
Validation loss: 1.7648881866085915

Epoch: 6| Step: 7
Training loss: 0.46236929297447205
Validation loss: 1.7514416684386551

Epoch: 6| Step: 8
Training loss: 0.5191943645477295
Validation loss: 1.7721615517011253

Epoch: 6| Step: 9
Training loss: 0.23276491463184357
Validation loss: 1.781169754202648

Epoch: 6| Step: 10
Training loss: 0.500082790851593
Validation loss: 1.7732025756630847

Epoch: 6| Step: 11
Training loss: 0.3248520493507385
Validation loss: 1.7993218860318583

Epoch: 6| Step: 12
Training loss: 0.759554386138916
Validation loss: 1.7838109090764036

Epoch: 6| Step: 13
Training loss: 0.5410609245300293
Validation loss: 1.7868454853693645

Epoch: 259| Step: 0
Training loss: 0.333299458026886
Validation loss: 1.78795027220121

Epoch: 6| Step: 1
Training loss: 0.4172569513320923
Validation loss: 1.7460323027385178

Epoch: 6| Step: 2
Training loss: 0.3424185514450073
Validation loss: 1.7440223014482887

Epoch: 6| Step: 3
Training loss: 0.37989670038223267
Validation loss: 1.7019676316169001

Epoch: 6| Step: 4
Training loss: 0.2931576371192932
Validation loss: 1.724815704489267

Epoch: 6| Step: 5
Training loss: 0.5243222713470459
Validation loss: 1.7104691965605623

Epoch: 6| Step: 6
Training loss: 0.841098964214325
Validation loss: 1.6926318945423249

Epoch: 6| Step: 7
Training loss: 0.3664722740650177
Validation loss: 1.6875117696741575

Epoch: 6| Step: 8
Training loss: 0.657889723777771
Validation loss: 1.7166749764514226

Epoch: 6| Step: 9
Training loss: 0.25654420256614685
Validation loss: 1.7355644138910438

Epoch: 6| Step: 10
Training loss: 0.47443050146102905
Validation loss: 1.7423958650199316

Epoch: 6| Step: 11
Training loss: 0.3742362856864929
Validation loss: 1.7462372728573379

Epoch: 6| Step: 12
Training loss: 0.35564565658569336
Validation loss: 1.7510486495110296

Epoch: 6| Step: 13
Training loss: 0.4040926694869995
Validation loss: 1.7285695998899397

Epoch: 260| Step: 0
Training loss: 0.6425179839134216
Validation loss: 1.727111788206203

Epoch: 6| Step: 1
Training loss: 0.25543099641799927
Validation loss: 1.757560840217016

Epoch: 6| Step: 2
Training loss: 0.5449498295783997
Validation loss: 1.7159123138714862

Epoch: 6| Step: 3
Training loss: 0.44483697414398193
Validation loss: 1.7185713552659558

Epoch: 6| Step: 4
Training loss: 0.3057838976383209
Validation loss: 1.703329788741245

Epoch: 6| Step: 5
Training loss: 0.36261966824531555
Validation loss: 1.7095276860780613

Epoch: 6| Step: 6
Training loss: 0.34240061044692993
Validation loss: 1.7084020818433454

Epoch: 6| Step: 7
Training loss: 0.5653468370437622
Validation loss: 1.6929597527750078

Epoch: 6| Step: 8
Training loss: 0.5368019342422485
Validation loss: 1.6899818425537438

Epoch: 6| Step: 9
Training loss: 0.4738444685935974
Validation loss: 1.7380880027688959

Epoch: 6| Step: 10
Training loss: 0.46634694933891296
Validation loss: 1.7463472479133195

Epoch: 6| Step: 11
Training loss: 0.32255974411964417
Validation loss: 1.792362182371078

Epoch: 6| Step: 12
Training loss: 0.3748791813850403
Validation loss: 1.7908431791490125

Epoch: 6| Step: 13
Training loss: 0.29043176770210266
Validation loss: 1.791230619594615

Epoch: 261| Step: 0
Training loss: 0.5869917869567871
Validation loss: 1.8261292929290442

Epoch: 6| Step: 1
Training loss: 0.3703920245170593
Validation loss: 1.828849143879388

Epoch: 6| Step: 2
Training loss: 0.6822749376296997
Validation loss: 1.8171074698048253

Epoch: 6| Step: 3
Training loss: 0.21325954794883728
Validation loss: 1.8329863227823728

Epoch: 6| Step: 4
Training loss: 0.41469013690948486
Validation loss: 1.794236477985177

Epoch: 6| Step: 5
Training loss: 0.3062041103839874
Validation loss: 1.781049697629867

Epoch: 6| Step: 6
Training loss: 0.5780758261680603
Validation loss: 1.741117149270991

Epoch: 6| Step: 7
Training loss: 0.6050219535827637
Validation loss: 1.715919594610891

Epoch: 6| Step: 8
Training loss: 0.31197240948677063
Validation loss: 1.6788673362424296

Epoch: 6| Step: 9
Training loss: 0.5114015936851501
Validation loss: 1.6580291935192641

Epoch: 6| Step: 10
Training loss: 0.4303390383720398
Validation loss: 1.6492518917206795

Epoch: 6| Step: 11
Training loss: 0.422837495803833
Validation loss: 1.6909117173123103

Epoch: 6| Step: 12
Training loss: 0.49529048800468445
Validation loss: 1.7239092126969369

Epoch: 6| Step: 13
Training loss: 0.43774959444999695
Validation loss: 1.7599809759406633

Epoch: 262| Step: 0
Training loss: 0.30715012550354004
Validation loss: 1.7412010790199361

Epoch: 6| Step: 1
Training loss: 1.0571861267089844
Validation loss: 1.729516222912778

Epoch: 6| Step: 2
Training loss: 0.5346328616142273
Validation loss: 1.7179995967495827

Epoch: 6| Step: 3
Training loss: 0.28187522292137146
Validation loss: 1.6932460236293014

Epoch: 6| Step: 4
Training loss: 0.31944501399993896
Validation loss: 1.6955740861995245

Epoch: 6| Step: 5
Training loss: 0.4050140380859375
Validation loss: 1.7065008058342883

Epoch: 6| Step: 6
Training loss: 0.46131736040115356
Validation loss: 1.7137048564931399

Epoch: 6| Step: 7
Training loss: 0.40434104204177856
Validation loss: 1.7566037568994748

Epoch: 6| Step: 8
Training loss: 0.41730397939682007
Validation loss: 1.747423061760523

Epoch: 6| Step: 9
Training loss: 0.366720050573349
Validation loss: 1.7772409851833055

Epoch: 6| Step: 10
Training loss: 0.35964828729629517
Validation loss: 1.7872814363048923

Epoch: 6| Step: 11
Training loss: 0.3126757740974426
Validation loss: 1.8026024974802488

Epoch: 6| Step: 12
Training loss: 0.491516649723053
Validation loss: 1.7801586543360064

Epoch: 6| Step: 13
Training loss: 0.3849412202835083
Validation loss: 1.7793332530606178

Epoch: 263| Step: 0
Training loss: 0.41658538579940796
Validation loss: 1.7517206220216648

Epoch: 6| Step: 1
Training loss: 0.42634204030036926
Validation loss: 1.7632991639516686

Epoch: 6| Step: 2
Training loss: 0.34616512060165405
Validation loss: 1.7413557473049368

Epoch: 6| Step: 3
Training loss: 0.41732901334762573
Validation loss: 1.7347688162198631

Epoch: 6| Step: 4
Training loss: 0.4127144515514374
Validation loss: 1.7502671492997037

Epoch: 6| Step: 5
Training loss: 0.2634006440639496
Validation loss: 1.766929188082295

Epoch: 6| Step: 6
Training loss: 0.3906610608100891
Validation loss: 1.7732059910733213

Epoch: 6| Step: 7
Training loss: 0.6167162656784058
Validation loss: 1.7608537212494881

Epoch: 6| Step: 8
Training loss: 0.5649563670158386
Validation loss: 1.780424617951916

Epoch: 6| Step: 9
Training loss: 0.4592703878879547
Validation loss: 1.7594908424603042

Epoch: 6| Step: 10
Training loss: 0.5929308533668518
Validation loss: 1.7626183763627084

Epoch: 6| Step: 11
Training loss: 0.34962642192840576
Validation loss: 1.7082991587218417

Epoch: 6| Step: 12
Training loss: 0.33696141839027405
Validation loss: 1.7305119499083488

Epoch: 6| Step: 13
Training loss: 0.17563043534755707
Validation loss: 1.685264100310623

Epoch: 264| Step: 0
Training loss: 0.4433133602142334
Validation loss: 1.6934887824519989

Epoch: 6| Step: 1
Training loss: 0.45949801802635193
Validation loss: 1.6997872783291725

Epoch: 6| Step: 2
Training loss: 0.43336600065231323
Validation loss: 1.7002245277486823

Epoch: 6| Step: 3
Training loss: 0.33252352476119995
Validation loss: 1.694436998777492

Epoch: 6| Step: 4
Training loss: 0.9138387441635132
Validation loss: 1.7010520760731032

Epoch: 6| Step: 5
Training loss: 0.4165523052215576
Validation loss: 1.7241202323667464

Epoch: 6| Step: 6
Training loss: 0.28437089920043945
Validation loss: 1.7505526055571854

Epoch: 6| Step: 7
Training loss: 0.31973427534103394
Validation loss: 1.7957958675199939

Epoch: 6| Step: 8
Training loss: 0.30061280727386475
Validation loss: 1.811071280510195

Epoch: 6| Step: 9
Training loss: 0.4184633195400238
Validation loss: 1.7976101739432222

Epoch: 6| Step: 10
Training loss: 0.3522833287715912
Validation loss: 1.7665609813505603

Epoch: 6| Step: 11
Training loss: 0.1234210878610611
Validation loss: 1.7039735112138974

Epoch: 6| Step: 12
Training loss: 0.3054833710193634
Validation loss: 1.6750553807904642

Epoch: 6| Step: 13
Training loss: 0.5181095004081726
Validation loss: 1.6729910694142824

Epoch: 265| Step: 0
Training loss: 0.4524334669113159
Validation loss: 1.6779371070605453

Epoch: 6| Step: 1
Training loss: 0.26976317167282104
Validation loss: 1.671498239681285

Epoch: 6| Step: 2
Training loss: 0.3594682812690735
Validation loss: 1.6701763650422454

Epoch: 6| Step: 3
Training loss: 0.426075279712677
Validation loss: 1.6599119696565854

Epoch: 6| Step: 4
Training loss: 0.4232833981513977
Validation loss: 1.6692745647122782

Epoch: 6| Step: 5
Training loss: 0.4228857755661011
Validation loss: 1.7019864282300394

Epoch: 6| Step: 6
Training loss: 0.333274245262146
Validation loss: 1.734306808440916

Epoch: 6| Step: 7
Training loss: 0.27383241057395935
Validation loss: 1.7128830366237189

Epoch: 6| Step: 8
Training loss: 0.4252304136753082
Validation loss: 1.6843674708438177

Epoch: 6| Step: 9
Training loss: 0.24027982354164124
Validation loss: 1.7135448455810547

Epoch: 6| Step: 10
Training loss: 0.19027209281921387
Validation loss: 1.73358198647858

Epoch: 6| Step: 11
Training loss: 0.5236175060272217
Validation loss: 1.7127914492801954

Epoch: 6| Step: 12
Training loss: 0.6824762225151062
Validation loss: 1.73169574686276

Epoch: 6| Step: 13
Training loss: 0.23965072631835938
Validation loss: 1.7242565847212268

Epoch: 266| Step: 0
Training loss: 0.23194146156311035
Validation loss: 1.7523428534948697

Epoch: 6| Step: 1
Training loss: 0.6844601631164551
Validation loss: 1.7462198747101652

Epoch: 6| Step: 2
Training loss: 0.3570899963378906
Validation loss: 1.7336441855276785

Epoch: 6| Step: 3
Training loss: 0.3760074973106384
Validation loss: 1.7247558665531937

Epoch: 6| Step: 4
Training loss: 0.3490643799304962
Validation loss: 1.7019367051380936

Epoch: 6| Step: 5
Training loss: 0.2608409523963928
Validation loss: 1.713066747111659

Epoch: 6| Step: 6
Training loss: 0.17255178093910217
Validation loss: 1.714410311432295

Epoch: 6| Step: 7
Training loss: 0.40747711062431335
Validation loss: 1.7255683791252874

Epoch: 6| Step: 8
Training loss: 0.3241739571094513
Validation loss: 1.733784338479401

Epoch: 6| Step: 9
Training loss: 0.3194867968559265
Validation loss: 1.757857350892918

Epoch: 6| Step: 10
Training loss: 0.23908528685569763
Validation loss: 1.7168403697270218

Epoch: 6| Step: 11
Training loss: 0.5937595963478088
Validation loss: 1.7157135830130628

Epoch: 6| Step: 12
Training loss: 0.33199062943458557
Validation loss: 1.7091511359778784

Epoch: 6| Step: 13
Training loss: 0.5243117213249207
Validation loss: 1.6822378750770324

Epoch: 267| Step: 0
Training loss: 0.46434760093688965
Validation loss: 1.6704709504240303

Epoch: 6| Step: 1
Training loss: 0.16439510881900787
Validation loss: 1.677232414163569

Epoch: 6| Step: 2
Training loss: 0.22984936833381653
Validation loss: 1.6446326778781029

Epoch: 6| Step: 3
Training loss: 0.5699344873428345
Validation loss: 1.6508499441608306

Epoch: 6| Step: 4
Training loss: 0.25474122166633606
Validation loss: 1.6831324831131966

Epoch: 6| Step: 5
Training loss: 0.5691820979118347
Validation loss: 1.6996617445381739

Epoch: 6| Step: 6
Training loss: 0.29644498229026794
Validation loss: 1.6996414674225675

Epoch: 6| Step: 7
Training loss: 0.46107178926467896
Validation loss: 1.7472233746641426

Epoch: 6| Step: 8
Training loss: 0.4578074514865875
Validation loss: 1.8046076720760715

Epoch: 6| Step: 9
Training loss: 0.22082190215587616
Validation loss: 1.7935642991014706

Epoch: 6| Step: 10
Training loss: 0.49383723735809326
Validation loss: 1.7861130833625793

Epoch: 6| Step: 11
Training loss: 0.40320315957069397
Validation loss: 1.779729086865661

Epoch: 6| Step: 12
Training loss: 0.3391845226287842
Validation loss: 1.6911786781844271

Epoch: 6| Step: 13
Training loss: 0.3363977074623108
Validation loss: 1.6785882070500364

Epoch: 268| Step: 0
Training loss: 0.40356194972991943
Validation loss: 1.6622180900266093

Epoch: 6| Step: 1
Training loss: 0.7025082111358643
Validation loss: 1.6220702343089606

Epoch: 6| Step: 2
Training loss: 0.34647515416145325
Validation loss: 1.6538289529021069

Epoch: 6| Step: 3
Training loss: 0.8338611125946045
Validation loss: 1.6670792512996222

Epoch: 6| Step: 4
Training loss: 0.3523617684841156
Validation loss: 1.6949240699891122

Epoch: 6| Step: 5
Training loss: 0.15290188789367676
Validation loss: 1.7274419479472662

Epoch: 6| Step: 6
Training loss: 0.35909003019332886
Validation loss: 1.7527831036557433

Epoch: 6| Step: 7
Training loss: 0.4022289514541626
Validation loss: 1.8076330551537134

Epoch: 6| Step: 8
Training loss: 0.23320439457893372
Validation loss: 1.8027791797473867

Epoch: 6| Step: 9
Training loss: 0.39350032806396484
Validation loss: 1.7928462413049513

Epoch: 6| Step: 10
Training loss: 0.3527469038963318
Validation loss: 1.7610550183121876

Epoch: 6| Step: 11
Training loss: 0.5618760585784912
Validation loss: 1.7284271204343407

Epoch: 6| Step: 12
Training loss: 0.2177290916442871
Validation loss: 1.7105235156192575

Epoch: 6| Step: 13
Training loss: 0.15438467264175415
Validation loss: 1.6943612073057441

Epoch: 269| Step: 0
Training loss: 0.4961465895175934
Validation loss: 1.6769688808789818

Epoch: 6| Step: 1
Training loss: 0.28024548292160034
Validation loss: 1.6845345368949316

Epoch: 6| Step: 2
Training loss: 0.4209012985229492
Validation loss: 1.6987848333133164

Epoch: 6| Step: 3
Training loss: 0.4348863959312439
Validation loss: 1.7301187976714103

Epoch: 6| Step: 4
Training loss: 0.30222219228744507
Validation loss: 1.7410904399810299

Epoch: 6| Step: 5
Training loss: 0.43548038601875305
Validation loss: 1.7700191608039282

Epoch: 6| Step: 6
Training loss: 0.637027382850647
Validation loss: 1.7681160755054925

Epoch: 6| Step: 7
Training loss: 0.3947839140892029
Validation loss: 1.782089300053094

Epoch: 6| Step: 8
Training loss: 0.32320982217788696
Validation loss: 1.7961814711170812

Epoch: 6| Step: 9
Training loss: 0.34805363416671753
Validation loss: 1.794669456379388

Epoch: 6| Step: 10
Training loss: 0.4577714502811432
Validation loss: 1.7751544701155795

Epoch: 6| Step: 11
Training loss: 0.1841002106666565
Validation loss: 1.761965488874784

Epoch: 6| Step: 12
Training loss: 0.2397201657295227
Validation loss: 1.7357812889160649

Epoch: 6| Step: 13
Training loss: 0.45099931955337524
Validation loss: 1.756857015753305

Epoch: 270| Step: 0
Training loss: 0.33126187324523926
Validation loss: 1.746636349667785

Epoch: 6| Step: 1
Training loss: 0.24996228516101837
Validation loss: 1.754882070326036

Epoch: 6| Step: 2
Training loss: 0.2757261395454407
Validation loss: 1.7468428663028184

Epoch: 6| Step: 3
Training loss: 0.38518649339675903
Validation loss: 1.7561312311439103

Epoch: 6| Step: 4
Training loss: 0.20537275075912476
Validation loss: 1.734333884331488

Epoch: 6| Step: 5
Training loss: 0.150532528758049
Validation loss: 1.7636911074320476

Epoch: 6| Step: 6
Training loss: 0.7341874837875366
Validation loss: 1.743581380895389

Epoch: 6| Step: 7
Training loss: 0.3095664381980896
Validation loss: 1.7672883643898913

Epoch: 6| Step: 8
Training loss: 0.40497222542762756
Validation loss: 1.7612620938208796

Epoch: 6| Step: 9
Training loss: 0.40773284435272217
Validation loss: 1.7675100757229714

Epoch: 6| Step: 10
Training loss: 0.31348806619644165
Validation loss: 1.7860534152676981

Epoch: 6| Step: 11
Training loss: 0.4935069680213928
Validation loss: 1.7803566814750753

Epoch: 6| Step: 12
Training loss: 0.3698914051055908
Validation loss: 1.7599139021288963

Epoch: 6| Step: 13
Training loss: 0.31044551730155945
Validation loss: 1.7536847860582414

Epoch: 271| Step: 0
Training loss: 0.20824837684631348
Validation loss: 1.7663778861363728

Epoch: 6| Step: 1
Training loss: 0.5051239728927612
Validation loss: 1.779120527287965

Epoch: 6| Step: 2
Training loss: 0.4501999616622925
Validation loss: 1.7203503744576567

Epoch: 6| Step: 3
Training loss: 0.6588512659072876
Validation loss: 1.749702686904579

Epoch: 6| Step: 4
Training loss: 0.35904717445373535
Validation loss: 1.766389149491505

Epoch: 6| Step: 5
Training loss: 0.5318965911865234
Validation loss: 1.7483090854460193

Epoch: 6| Step: 6
Training loss: 0.3761284053325653
Validation loss: 1.7925501843934417

Epoch: 6| Step: 7
Training loss: 0.2898644804954529
Validation loss: 1.8127991217438892

Epoch: 6| Step: 8
Training loss: 0.4125826060771942
Validation loss: 1.8099015015427784

Epoch: 6| Step: 9
Training loss: 0.2865639626979828
Validation loss: 1.8063067979710077

Epoch: 6| Step: 10
Training loss: 0.34582263231277466
Validation loss: 1.7990784747626192

Epoch: 6| Step: 11
Training loss: 0.39613285660743713
Validation loss: 1.7674622817706036

Epoch: 6| Step: 12
Training loss: 0.16630269587039948
Validation loss: 1.7522647368010653

Epoch: 6| Step: 13
Training loss: 0.14347387850284576
Validation loss: 1.7257572694491314

Epoch: 272| Step: 0
Training loss: 0.383455753326416
Validation loss: 1.6982746585722892

Epoch: 6| Step: 1
Training loss: 0.22294630110263824
Validation loss: 1.6812767854300879

Epoch: 6| Step: 2
Training loss: 0.38244953751564026
Validation loss: 1.658232222321213

Epoch: 6| Step: 3
Training loss: 0.5850178003311157
Validation loss: 1.66361334887884

Epoch: 6| Step: 4
Training loss: 0.4016300439834595
Validation loss: 1.6691859614464544

Epoch: 6| Step: 5
Training loss: 0.8324182033538818
Validation loss: 1.6975781635571552

Epoch: 6| Step: 6
Training loss: 0.330805242061615
Validation loss: 1.6879410564258535

Epoch: 6| Step: 7
Training loss: 0.31233084201812744
Validation loss: 1.7155643560553109

Epoch: 6| Step: 8
Training loss: 0.19675305485725403
Validation loss: 1.7767979662905458

Epoch: 6| Step: 9
Training loss: 0.32126620411872864
Validation loss: 1.7644546570316437

Epoch: 6| Step: 10
Training loss: 0.3851950168609619
Validation loss: 1.7852581162606516

Epoch: 6| Step: 11
Training loss: 0.4488060474395752
Validation loss: 1.7609468916411042

Epoch: 6| Step: 12
Training loss: 0.5511868596076965
Validation loss: 1.77025060115322

Epoch: 6| Step: 13
Training loss: 0.23318004608154297
Validation loss: 1.7287308682677567

Epoch: 273| Step: 0
Training loss: 0.4044860005378723
Validation loss: 1.7203443550294446

Epoch: 6| Step: 1
Training loss: 0.33397579193115234
Validation loss: 1.7349711413024573

Epoch: 6| Step: 2
Training loss: 0.28960517048835754
Validation loss: 1.7123118536446684

Epoch: 6| Step: 3
Training loss: 0.3600696325302124
Validation loss: 1.7152619656696115

Epoch: 6| Step: 4
Training loss: 0.23216275870800018
Validation loss: 1.7430511161845217

Epoch: 6| Step: 5
Training loss: 0.4870440363883972
Validation loss: 1.7160195919775194

Epoch: 6| Step: 6
Training loss: 0.42946657538414
Validation loss: 1.75105385498334

Epoch: 6| Step: 7
Training loss: 0.29796504974365234
Validation loss: 1.7529422788209812

Epoch: 6| Step: 8
Training loss: 0.3761399984359741
Validation loss: 1.7918644284689298

Epoch: 6| Step: 9
Training loss: 0.25764572620391846
Validation loss: 1.7765526053726033

Epoch: 6| Step: 10
Training loss: 0.479972779750824
Validation loss: 1.7863191455923102

Epoch: 6| Step: 11
Training loss: 0.638792872428894
Validation loss: 1.7695936310675837

Epoch: 6| Step: 12
Training loss: 0.37341833114624023
Validation loss: 1.7577042656560098

Epoch: 6| Step: 13
Training loss: 0.35466405749320984
Validation loss: 1.745429790148171

Epoch: 274| Step: 0
Training loss: 0.2569778859615326
Validation loss: 1.748664121473989

Epoch: 6| Step: 1
Training loss: 0.5179787874221802
Validation loss: 1.7612912206239597

Epoch: 6| Step: 2
Training loss: 0.33446618914604187
Validation loss: 1.7685109646089616

Epoch: 6| Step: 3
Training loss: 0.24963107705116272
Validation loss: 1.7749113908378027

Epoch: 6| Step: 4
Training loss: 0.38941502571105957
Validation loss: 1.7938790295713691

Epoch: 6| Step: 5
Training loss: 0.34975549578666687
Validation loss: 1.7891468668496737

Epoch: 6| Step: 6
Training loss: 0.2505480647087097
Validation loss: 1.7956413748443767

Epoch: 6| Step: 7
Training loss: 0.2861943244934082
Validation loss: 1.7678490505423596

Epoch: 6| Step: 8
Training loss: 0.6323490738868713
Validation loss: 1.7584217927789176

Epoch: 6| Step: 9
Training loss: 0.3228192627429962
Validation loss: 1.7318455532032957

Epoch: 6| Step: 10
Training loss: 0.30046546459198
Validation loss: 1.7291445193752166

Epoch: 6| Step: 11
Training loss: 0.27552440762519836
Validation loss: 1.7288297824962164

Epoch: 6| Step: 12
Training loss: 0.29480308294296265
Validation loss: 1.7392082150264452

Epoch: 6| Step: 13
Training loss: 0.2837173640727997
Validation loss: 1.7526085979195052

Epoch: 275| Step: 0
Training loss: 0.2918913960456848
Validation loss: 1.7699287719624017

Epoch: 6| Step: 1
Training loss: 0.40652140974998474
Validation loss: 1.7931375888086134

Epoch: 6| Step: 2
Training loss: 0.6950080990791321
Validation loss: 1.7917085065636584

Epoch: 6| Step: 3
Training loss: 0.3193444311618805
Validation loss: 1.789373379881664

Epoch: 6| Step: 4
Training loss: 0.22544865310192108
Validation loss: 1.7685544644632647

Epoch: 6| Step: 5
Training loss: 0.28204768896102905
Validation loss: 1.8090420692197737

Epoch: 6| Step: 6
Training loss: 0.5090146660804749
Validation loss: 1.788686575428132

Epoch: 6| Step: 7
Training loss: 0.24218149483203888
Validation loss: 1.7794347783570648

Epoch: 6| Step: 8
Training loss: 0.45423364639282227
Validation loss: 1.7605066735257384

Epoch: 6| Step: 9
Training loss: 0.3254925608634949
Validation loss: 1.764373287077873

Epoch: 6| Step: 10
Training loss: 0.3594018518924713
Validation loss: 1.7433625087943128

Epoch: 6| Step: 11
Training loss: 0.3519269824028015
Validation loss: 1.7111163344434512

Epoch: 6| Step: 12
Training loss: 0.25678008794784546
Validation loss: 1.6873162972029818

Epoch: 6| Step: 13
Training loss: 0.32250356674194336
Validation loss: 1.6890630465681835

Epoch: 276| Step: 0
Training loss: 0.7104091048240662
Validation loss: 1.7066783969120314

Epoch: 6| Step: 1
Training loss: 0.32025742530822754
Validation loss: 1.6898526504475584

Epoch: 6| Step: 2
Training loss: 0.2830738425254822
Validation loss: 1.7106653259646507

Epoch: 6| Step: 3
Training loss: 0.45936208963394165
Validation loss: 1.7391394210118118

Epoch: 6| Step: 4
Training loss: 0.1513715535402298
Validation loss: 1.725277913514004

Epoch: 6| Step: 5
Training loss: 0.5677010416984558
Validation loss: 1.7254257894331408

Epoch: 6| Step: 6
Training loss: 0.4029309153556824
Validation loss: 1.7771990709407355

Epoch: 6| Step: 7
Training loss: 0.2073136270046234
Validation loss: 1.7738645666389055

Epoch: 6| Step: 8
Training loss: 0.3941805362701416
Validation loss: 1.7669369020769674

Epoch: 6| Step: 9
Training loss: 0.3396908640861511
Validation loss: 1.7488692960431498

Epoch: 6| Step: 10
Training loss: 0.3242262005805969
Validation loss: 1.7153263527859923

Epoch: 6| Step: 11
Training loss: 0.39784181118011475
Validation loss: 1.7454964589047175

Epoch: 6| Step: 12
Training loss: 0.5145381689071655
Validation loss: 1.720506944964009

Epoch: 6| Step: 13
Training loss: 0.1914471536874771
Validation loss: 1.7315327121365456

Epoch: 277| Step: 0
Training loss: 0.3855896592140198
Validation loss: 1.7028890207249632

Epoch: 6| Step: 1
Training loss: 0.4584276080131531
Validation loss: 1.7048425430892615

Epoch: 6| Step: 2
Training loss: 0.2198190689086914
Validation loss: 1.6893203617424093

Epoch: 6| Step: 3
Training loss: 0.3518076539039612
Validation loss: 1.7016880102055048

Epoch: 6| Step: 4
Training loss: 0.33336398005485535
Validation loss: 1.7192721828337638

Epoch: 6| Step: 5
Training loss: 0.3913424611091614
Validation loss: 1.7339949172030213

Epoch: 6| Step: 6
Training loss: 0.35473936796188354
Validation loss: 1.7609542697988532

Epoch: 6| Step: 7
Training loss: 0.5768955945968628
Validation loss: 1.7508087004384687

Epoch: 6| Step: 8
Training loss: 0.33239462971687317
Validation loss: 1.7327705557628343

Epoch: 6| Step: 9
Training loss: 0.415702760219574
Validation loss: 1.7059203706761843

Epoch: 6| Step: 10
Training loss: 0.24720263481140137
Validation loss: 1.7020045057419808

Epoch: 6| Step: 11
Training loss: 0.24687014520168304
Validation loss: 1.7259238073902745

Epoch: 6| Step: 12
Training loss: 0.3165075480937958
Validation loss: 1.7031578389547204

Epoch: 6| Step: 13
Training loss: 0.10667859762907028
Validation loss: 1.6824888619043494

Epoch: 278| Step: 0
Training loss: 0.2986150085926056
Validation loss: 1.6406900908357354

Epoch: 6| Step: 1
Training loss: 0.5240417718887329
Validation loss: 1.6739696174539545

Epoch: 6| Step: 2
Training loss: 0.27983224391937256
Validation loss: 1.6710226651160949

Epoch: 6| Step: 3
Training loss: 0.3712090253829956
Validation loss: 1.69451686515603

Epoch: 6| Step: 4
Training loss: 0.1800212264060974
Validation loss: 1.7220708913700555

Epoch: 6| Step: 5
Training loss: 0.3761136531829834
Validation loss: 1.755809582689757

Epoch: 6| Step: 6
Training loss: 0.5865907669067383
Validation loss: 1.8285783747191071

Epoch: 6| Step: 7
Training loss: 0.5517317056655884
Validation loss: 1.8219339860382902

Epoch: 6| Step: 8
Training loss: 0.3680915832519531
Validation loss: 1.8760905778536232

Epoch: 6| Step: 9
Training loss: 0.5017945766448975
Validation loss: 1.8262997942586099

Epoch: 6| Step: 10
Training loss: 0.19410166144371033
Validation loss: 1.7671646174564157

Epoch: 6| Step: 11
Training loss: 0.2569277286529541
Validation loss: 1.7386458766075872

Epoch: 6| Step: 12
Training loss: 0.3299866020679474
Validation loss: 1.669016574018745

Epoch: 6| Step: 13
Training loss: 0.35185351967811584
Validation loss: 1.672396852124122

Epoch: 279| Step: 0
Training loss: 0.20018330216407776
Validation loss: 1.6461873365345823

Epoch: 6| Step: 1
Training loss: 0.49630606174468994
Validation loss: 1.6442568507245792

Epoch: 6| Step: 2
Training loss: 0.2609812617301941
Validation loss: 1.6533573737708471

Epoch: 6| Step: 3
Training loss: 0.21588119864463806
Validation loss: 1.6887024884582849

Epoch: 6| Step: 4
Training loss: 0.36325111985206604
Validation loss: 1.686855435371399

Epoch: 6| Step: 5
Training loss: 0.670293390750885
Validation loss: 1.7459061453419347

Epoch: 6| Step: 6
Training loss: 0.36301225423812866
Validation loss: 1.7927739850936397

Epoch: 6| Step: 7
Training loss: 0.37494152784347534
Validation loss: 1.8477268488176408

Epoch: 6| Step: 8
Training loss: 0.32353460788726807
Validation loss: 1.8447029488061064

Epoch: 6| Step: 9
Training loss: 0.46011221408843994
Validation loss: 1.8261673283833328

Epoch: 6| Step: 10
Training loss: 0.28862202167510986
Validation loss: 1.7743055935828917

Epoch: 6| Step: 11
Training loss: 0.40436673164367676
Validation loss: 1.7424570129763695

Epoch: 6| Step: 12
Training loss: 0.16453909873962402
Validation loss: 1.6811994942285682

Epoch: 6| Step: 13
Training loss: 0.4037493169307709
Validation loss: 1.6563093790443995

Epoch: 280| Step: 0
Training loss: 0.27276504039764404
Validation loss: 1.6365671696201447

Epoch: 6| Step: 1
Training loss: 0.39369451999664307
Validation loss: 1.654145735566334

Epoch: 6| Step: 2
Training loss: 0.5275278091430664
Validation loss: 1.6790720044925649

Epoch: 6| Step: 3
Training loss: 0.2950255274772644
Validation loss: 1.7004573755366827

Epoch: 6| Step: 4
Training loss: 0.21773482859134674
Validation loss: 1.7323627574469453

Epoch: 6| Step: 5
Training loss: 0.4311092495918274
Validation loss: 1.7271713338872439

Epoch: 6| Step: 6
Training loss: 0.594261646270752
Validation loss: 1.7510302899986185

Epoch: 6| Step: 7
Training loss: 0.384631872177124
Validation loss: 1.7889593967827417

Epoch: 6| Step: 8
Training loss: 0.2975773215293884
Validation loss: 1.7581830345174319

Epoch: 6| Step: 9
Training loss: 0.18165349960327148
Validation loss: 1.7583578837815153

Epoch: 6| Step: 10
Training loss: 0.39144837856292725
Validation loss: 1.7728223621204335

Epoch: 6| Step: 11
Training loss: 0.34071463346481323
Validation loss: 1.7330846991590274

Epoch: 6| Step: 12
Training loss: 0.3795357346534729
Validation loss: 1.739815019792126

Epoch: 6| Step: 13
Training loss: 0.33127933740615845
Validation loss: 1.7295972480568835

Epoch: 281| Step: 0
Training loss: 0.43099305033683777
Validation loss: 1.694087577122514

Epoch: 6| Step: 1
Training loss: 0.2389649748802185
Validation loss: 1.7240250020898797

Epoch: 6| Step: 2
Training loss: 0.38167110085487366
Validation loss: 1.7140444888863513

Epoch: 6| Step: 3
Training loss: 0.30322030186653137
Validation loss: 1.7032344136186826

Epoch: 6| Step: 4
Training loss: 0.2981141209602356
Validation loss: 1.7311724757635465

Epoch: 6| Step: 5
Training loss: 0.20309165120124817
Validation loss: 1.7360849470220587

Epoch: 6| Step: 6
Training loss: 0.34593722224235535
Validation loss: 1.7237913416277977

Epoch: 6| Step: 7
Training loss: 0.8018940687179565
Validation loss: 1.7413590172285676

Epoch: 6| Step: 8
Training loss: 0.20145389437675476
Validation loss: 1.6926744112404444

Epoch: 6| Step: 9
Training loss: 0.30980223417282104
Validation loss: 1.7242132604763072

Epoch: 6| Step: 10
Training loss: 0.4740596413612366
Validation loss: 1.7300931740832586

Epoch: 6| Step: 11
Training loss: 0.2809533476829529
Validation loss: 1.7428461402975104

Epoch: 6| Step: 12
Training loss: 0.2851102352142334
Validation loss: 1.7626667118841601

Epoch: 6| Step: 13
Training loss: 0.39709582924842834
Validation loss: 1.8077393231853363

Epoch: 282| Step: 0
Training loss: 0.4718151092529297
Validation loss: 1.8074877326206495

Epoch: 6| Step: 1
Training loss: 0.22107623517513275
Validation loss: 1.7716573720337243

Epoch: 6| Step: 2
Training loss: 0.3420516848564148
Validation loss: 1.7592923974478116

Epoch: 6| Step: 3
Training loss: 0.513604998588562
Validation loss: 1.7265625153818438

Epoch: 6| Step: 4
Training loss: 0.3018290102481842
Validation loss: 1.7084746899143342

Epoch: 6| Step: 5
Training loss: 0.3719858229160309
Validation loss: 1.6945073540492723

Epoch: 6| Step: 6
Training loss: 0.610092282295227
Validation loss: 1.7049823678949827

Epoch: 6| Step: 7
Training loss: 0.3218829333782196
Validation loss: 1.7323351342190978

Epoch: 6| Step: 8
Training loss: 0.1780499666929245
Validation loss: 1.7334637789316074

Epoch: 6| Step: 9
Training loss: 0.23217812180519104
Validation loss: 1.771178094289636

Epoch: 6| Step: 10
Training loss: 0.28946051001548767
Validation loss: 1.760757693680384

Epoch: 6| Step: 11
Training loss: 0.29452404379844666
Validation loss: 1.7698918363099456

Epoch: 6| Step: 12
Training loss: 0.23865604400634766
Validation loss: 1.7757875816796416

Epoch: 6| Step: 13
Training loss: 0.3999139368534088
Validation loss: 1.7696295861274964

Epoch: 283| Step: 0
Training loss: 0.13987691700458527
Validation loss: 1.7636041820690196

Epoch: 6| Step: 1
Training loss: 0.19052329659461975
Validation loss: 1.7280138948912263

Epoch: 6| Step: 2
Training loss: 0.4438241720199585
Validation loss: 1.711138544544097

Epoch: 6| Step: 3
Training loss: 0.20052459836006165
Validation loss: 1.7134646734883707

Epoch: 6| Step: 4
Training loss: 0.21724796295166016
Validation loss: 1.6811969754516438

Epoch: 6| Step: 5
Training loss: 0.6365072727203369
Validation loss: 1.6893291050387966

Epoch: 6| Step: 6
Training loss: 0.46028852462768555
Validation loss: 1.6936653878099175

Epoch: 6| Step: 7
Training loss: 0.5385843515396118
Validation loss: 1.6949205770287463

Epoch: 6| Step: 8
Training loss: 0.1971568912267685
Validation loss: 1.7240929795849709

Epoch: 6| Step: 9
Training loss: 0.277909517288208
Validation loss: 1.74386046009679

Epoch: 6| Step: 10
Training loss: 0.25723591446876526
Validation loss: 1.7556667404790078

Epoch: 6| Step: 11
Training loss: 0.25863662362098694
Validation loss: 1.7726343549707884

Epoch: 6| Step: 12
Training loss: 0.24705444276332855
Validation loss: 1.8240708971536288

Epoch: 6| Step: 13
Training loss: 0.24050739407539368
Validation loss: 1.8139222642426849

Epoch: 284| Step: 0
Training loss: 0.295957088470459
Validation loss: 1.7902505461887648

Epoch: 6| Step: 1
Training loss: 0.21562963724136353
Validation loss: 1.79094026934716

Epoch: 6| Step: 2
Training loss: 0.25699687004089355
Validation loss: 1.7560741491215204

Epoch: 6| Step: 3
Training loss: 0.31133201718330383
Validation loss: 1.749248290574679

Epoch: 6| Step: 4
Training loss: 0.3690003752708435
Validation loss: 1.7267497175483293

Epoch: 6| Step: 5
Training loss: 0.35060957074165344
Validation loss: 1.7393926215428177

Epoch: 6| Step: 6
Training loss: 0.587204098701477
Validation loss: 1.6744719961638093

Epoch: 6| Step: 7
Training loss: 0.22230559587478638
Validation loss: 1.687568167204498

Epoch: 6| Step: 8
Training loss: 0.4539521336555481
Validation loss: 1.674269986409013

Epoch: 6| Step: 9
Training loss: 0.2537965774536133
Validation loss: 1.696723226578005

Epoch: 6| Step: 10
Training loss: 0.39388442039489746
Validation loss: 1.7080494703785065

Epoch: 6| Step: 11
Training loss: 0.19047752022743225
Validation loss: 1.7293706222247052

Epoch: 6| Step: 12
Training loss: 0.2752830684185028
Validation loss: 1.7562595054667482

Epoch: 6| Step: 13
Training loss: 0.20535647869110107
Validation loss: 1.776626891987298

Epoch: 285| Step: 0
Training loss: 0.22405192255973816
Validation loss: 1.7553023343445153

Epoch: 6| Step: 1
Training loss: 0.25781744718551636
Validation loss: 1.774594206963816

Epoch: 6| Step: 2
Training loss: 0.14169596135616302
Validation loss: 1.7844914364558395

Epoch: 6| Step: 3
Training loss: 0.296451598405838
Validation loss: 1.7703452328199982

Epoch: 6| Step: 4
Training loss: 0.27315014600753784
Validation loss: 1.7391295317680604

Epoch: 6| Step: 5
Training loss: 0.3480294346809387
Validation loss: 1.726412982069036

Epoch: 6| Step: 6
Training loss: 0.26263606548309326
Validation loss: 1.7347206056758921

Epoch: 6| Step: 7
Training loss: 0.21398457884788513
Validation loss: 1.741906362836079

Epoch: 6| Step: 8
Training loss: 0.15457290410995483
Validation loss: 1.7218997017029793

Epoch: 6| Step: 9
Training loss: 0.3475914001464844
Validation loss: 1.736511089468515

Epoch: 6| Step: 10
Training loss: 0.3035273551940918
Validation loss: 1.7327743986601472

Epoch: 6| Step: 11
Training loss: 0.5134402513504028
Validation loss: 1.7437464408977057

Epoch: 6| Step: 12
Training loss: 0.3175463080406189
Validation loss: 1.758067718116186

Epoch: 6| Step: 13
Training loss: 0.16704978048801422
Validation loss: 1.7539374930884248

Epoch: 286| Step: 0
Training loss: 0.40485435724258423
Validation loss: 1.7539415128769413

Epoch: 6| Step: 1
Training loss: 0.17700126767158508
Validation loss: 1.750799072686062

Epoch: 6| Step: 2
Training loss: 0.42360275983810425
Validation loss: 1.6704136274194206

Epoch: 6| Step: 3
Training loss: 0.4039561152458191
Validation loss: 1.669764757156372

Epoch: 6| Step: 4
Training loss: 0.29554593563079834
Validation loss: 1.6677558293906591

Epoch: 6| Step: 5
Training loss: 0.39904364943504333
Validation loss: 1.6730741518799976

Epoch: 6| Step: 6
Training loss: 0.5100579261779785
Validation loss: 1.7024625706416305

Epoch: 6| Step: 7
Training loss: 0.22541877627372742
Validation loss: 1.7069338393467728

Epoch: 6| Step: 8
Training loss: 0.30396029353141785
Validation loss: 1.7345151337244178

Epoch: 6| Step: 9
Training loss: 0.1474798321723938
Validation loss: 1.7310475585281209

Epoch: 6| Step: 10
Training loss: 0.17473553121089935
Validation loss: 1.7965119500314035

Epoch: 6| Step: 11
Training loss: 0.2265550196170807
Validation loss: 1.8159066323311097

Epoch: 6| Step: 12
Training loss: 0.2560964524745941
Validation loss: 1.800020351204821

Epoch: 6| Step: 13
Training loss: 0.3526027500629425
Validation loss: 1.7998971426358787

Epoch: 287| Step: 0
Training loss: 0.22729063034057617
Validation loss: 1.79588097013453

Epoch: 6| Step: 1
Training loss: 0.2361920177936554
Validation loss: 1.7472465756118938

Epoch: 6| Step: 2
Training loss: 0.24970394372940063
Validation loss: 1.7261320070553852

Epoch: 6| Step: 3
Training loss: 0.23808613419532776
Validation loss: 1.7466836821648382

Epoch: 6| Step: 4
Training loss: 0.21983836591243744
Validation loss: 1.6977999774358605

Epoch: 6| Step: 5
Training loss: 0.4865940511226654
Validation loss: 1.6981845030220606

Epoch: 6| Step: 6
Training loss: 0.45886433124542236
Validation loss: 1.7166137054402342

Epoch: 6| Step: 7
Training loss: 0.3664833903312683
Validation loss: 1.7074753610036706

Epoch: 6| Step: 8
Training loss: 0.2919124364852905
Validation loss: 1.73303142029752

Epoch: 6| Step: 9
Training loss: 0.581498384475708
Validation loss: 1.7178736091941915

Epoch: 6| Step: 10
Training loss: 0.2335481196641922
Validation loss: 1.7248335987009027

Epoch: 6| Step: 11
Training loss: 0.2763376235961914
Validation loss: 1.7413257437367593

Epoch: 6| Step: 12
Training loss: 0.2346722036600113
Validation loss: 1.784752151017548

Epoch: 6| Step: 13
Training loss: 0.2947848439216614
Validation loss: 1.8337881577912198

Epoch: 288| Step: 0
Training loss: 0.22392049431800842
Validation loss: 1.8236508215627363

Epoch: 6| Step: 1
Training loss: 0.2246045470237732
Validation loss: 1.822059347424456

Epoch: 6| Step: 2
Training loss: 0.28589993715286255
Validation loss: 1.8420715165394608

Epoch: 6| Step: 3
Training loss: 0.4121379256248474
Validation loss: 1.8262869555463073

Epoch: 6| Step: 4
Training loss: 0.19246916472911835
Validation loss: 1.7946109284636795

Epoch: 6| Step: 5
Training loss: 0.2437291145324707
Validation loss: 1.7462973107573807

Epoch: 6| Step: 6
Training loss: 0.2379613220691681
Validation loss: 1.7421428336892077

Epoch: 6| Step: 7
Training loss: 0.2876952886581421
Validation loss: 1.7059972516952022

Epoch: 6| Step: 8
Training loss: 0.36222735047340393
Validation loss: 1.6865858736858572

Epoch: 6| Step: 9
Training loss: 0.7175157070159912
Validation loss: 1.6658765116045553

Epoch: 6| Step: 10
Training loss: 0.38094279170036316
Validation loss: 1.666685624148256

Epoch: 6| Step: 11
Training loss: 0.35902154445648193
Validation loss: 1.6672210859996017

Epoch: 6| Step: 12
Training loss: 0.19443011283874512
Validation loss: 1.7046194563629806

Epoch: 6| Step: 13
Training loss: 0.2364376336336136
Validation loss: 1.7282706717009186

Epoch: 289| Step: 0
Training loss: 0.32528600096702576
Validation loss: 1.7972009733159056

Epoch: 6| Step: 1
Training loss: 0.33888542652130127
Validation loss: 1.8305317765922957

Epoch: 6| Step: 2
Training loss: 0.22336265444755554
Validation loss: 1.830292567130058

Epoch: 6| Step: 3
Training loss: 0.22825615108013153
Validation loss: 1.8313709228269515

Epoch: 6| Step: 4
Training loss: 0.2620781362056732
Validation loss: 1.82547317781756

Epoch: 6| Step: 5
Training loss: 0.1676679104566574
Validation loss: 1.7897217869758606

Epoch: 6| Step: 6
Training loss: 0.33649712800979614
Validation loss: 1.7954488749145179

Epoch: 6| Step: 7
Training loss: 0.6509579420089722
Validation loss: 1.7622019372960573

Epoch: 6| Step: 8
Training loss: 0.27340853214263916
Validation loss: 1.7533408518760436

Epoch: 6| Step: 9
Training loss: 0.32240092754364014
Validation loss: 1.7489937915596911

Epoch: 6| Step: 10
Training loss: 0.17810645699501038
Validation loss: 1.7369513921840216

Epoch: 6| Step: 11
Training loss: 0.14077603816986084
Validation loss: 1.7153819684059388

Epoch: 6| Step: 12
Training loss: 0.3878999948501587
Validation loss: 1.7373839129683792

Epoch: 6| Step: 13
Training loss: 0.15707403421401978
Validation loss: 1.7351982388445126

Epoch: 290| Step: 0
Training loss: 0.7035750150680542
Validation loss: 1.7278168791083879

Epoch: 6| Step: 1
Training loss: 0.1640816032886505
Validation loss: 1.7400743243514851

Epoch: 6| Step: 2
Training loss: 0.22141514718532562
Validation loss: 1.7410852139995945

Epoch: 6| Step: 3
Training loss: 0.2154364287853241
Validation loss: 1.7116740185727355

Epoch: 6| Step: 4
Training loss: 0.19363591074943542
Validation loss: 1.744738289104995

Epoch: 6| Step: 5
Training loss: 0.17482076585292816
Validation loss: 1.720186548848306

Epoch: 6| Step: 6
Training loss: 0.21644717454910278
Validation loss: 1.7589595945932532

Epoch: 6| Step: 7
Training loss: 0.2170558124780655
Validation loss: 1.7332776720805834

Epoch: 6| Step: 8
Training loss: 0.41505199670791626
Validation loss: 1.7496012897901638

Epoch: 6| Step: 9
Training loss: 0.36700379848480225
Validation loss: 1.7411424741950086

Epoch: 6| Step: 10
Training loss: 0.3048847019672394
Validation loss: 1.7200273749648884

Epoch: 6| Step: 11
Training loss: 0.19148266315460205
Validation loss: 1.7098721111974409

Epoch: 6| Step: 12
Training loss: 0.36403220891952515
Validation loss: 1.7189246634001374

Epoch: 6| Step: 13
Training loss: 0.19242678582668304
Validation loss: 1.6948416694518058

Epoch: 291| Step: 0
Training loss: 0.3014637231826782
Validation loss: 1.7051109883093065

Epoch: 6| Step: 1
Training loss: 0.3158569931983948
Validation loss: 1.716765175583542

Epoch: 6| Step: 2
Training loss: 0.3658612370491028
Validation loss: 1.7226089533939157

Epoch: 6| Step: 3
Training loss: 0.3241482079029083
Validation loss: 1.7432103567225958

Epoch: 6| Step: 4
Training loss: 0.23035374283790588
Validation loss: 1.7363290658561132

Epoch: 6| Step: 5
Training loss: 0.4526214599609375
Validation loss: 1.7623312819388606

Epoch: 6| Step: 6
Training loss: 0.23728033900260925
Validation loss: 1.778618683097183

Epoch: 6| Step: 7
Training loss: 0.14028248190879822
Validation loss: 1.762511153374949

Epoch: 6| Step: 8
Training loss: 0.5937939286231995
Validation loss: 1.794128276968515

Epoch: 6| Step: 9
Training loss: 0.17447695136070251
Validation loss: 1.764025386943612

Epoch: 6| Step: 10
Training loss: 0.24981826543807983
Validation loss: 1.7913339253394835

Epoch: 6| Step: 11
Training loss: 0.322575181722641
Validation loss: 1.7726866429851902

Epoch: 6| Step: 12
Training loss: 0.26473701000213623
Validation loss: 1.7568154706749866

Epoch: 6| Step: 13
Training loss: 0.21588794887065887
Validation loss: 1.721574919198149

Epoch: 292| Step: 0
Training loss: 0.2608634829521179
Validation loss: 1.6825487831587433

Epoch: 6| Step: 1
Training loss: 0.20220807194709778
Validation loss: 1.7154704883534422

Epoch: 6| Step: 2
Training loss: 0.259816437959671
Validation loss: 1.7243286435322096

Epoch: 6| Step: 3
Training loss: 0.6245664358139038
Validation loss: 1.7141139930294407

Epoch: 6| Step: 4
Training loss: 0.22251109778881073
Validation loss: 1.7303627319233392

Epoch: 6| Step: 5
Training loss: 0.174841970205307
Validation loss: 1.7086283314612605

Epoch: 6| Step: 6
Training loss: 0.28106653690338135
Validation loss: 1.6964642950283584

Epoch: 6| Step: 7
Training loss: 0.291434645652771
Validation loss: 1.699931211369012

Epoch: 6| Step: 8
Training loss: 0.2786809206008911
Validation loss: 1.7117208729508102

Epoch: 6| Step: 9
Training loss: 0.49909311532974243
Validation loss: 1.7210231237514044

Epoch: 6| Step: 10
Training loss: 0.14684927463531494
Validation loss: 1.7507115038492347

Epoch: 6| Step: 11
Training loss: 0.24734628200531006
Validation loss: 1.7417964986575547

Epoch: 6| Step: 12
Training loss: 0.3434827923774719
Validation loss: 1.7308662629896594

Epoch: 6| Step: 13
Training loss: 0.22722643613815308
Validation loss: 1.7708023132816437

Epoch: 293| Step: 0
Training loss: 0.23612090945243835
Validation loss: 1.7534624979060183

Epoch: 6| Step: 1
Training loss: 0.44202396273612976
Validation loss: 1.7534568194420106

Epoch: 6| Step: 2
Training loss: 0.19801941514015198
Validation loss: 1.7236506503115419

Epoch: 6| Step: 3
Training loss: 0.4678038954734802
Validation loss: 1.7340210509556595

Epoch: 6| Step: 4
Training loss: 0.1828153431415558
Validation loss: 1.6910756416218256

Epoch: 6| Step: 5
Training loss: 0.29191040992736816
Validation loss: 1.6819758017857869

Epoch: 6| Step: 6
Training loss: 0.4332345128059387
Validation loss: 1.67903656600624

Epoch: 6| Step: 7
Training loss: 0.2924005389213562
Validation loss: 1.6736365223443637

Epoch: 6| Step: 8
Training loss: 0.3262748122215271
Validation loss: 1.694426021268291

Epoch: 6| Step: 9
Training loss: 0.18277111649513245
Validation loss: 1.7044853548849783

Epoch: 6| Step: 10
Training loss: 0.13100919127464294
Validation loss: 1.7579319810354581

Epoch: 6| Step: 11
Training loss: 0.28398850560188293
Validation loss: 1.7383215722217356

Epoch: 6| Step: 12
Training loss: 0.28515398502349854
Validation loss: 1.7459484005487094

Epoch: 6| Step: 13
Training loss: 0.2082182765007019
Validation loss: 1.787544451734071

Epoch: 294| Step: 0
Training loss: 0.33651164174079895
Validation loss: 1.761143586968863

Epoch: 6| Step: 1
Training loss: 0.1755191683769226
Validation loss: 1.7375768794808337

Epoch: 6| Step: 2
Training loss: 0.3220420479774475
Validation loss: 1.7102681885483444

Epoch: 6| Step: 3
Training loss: 0.2640087604522705
Validation loss: 1.7137252361543718

Epoch: 6| Step: 4
Training loss: 0.16470861434936523
Validation loss: 1.6847242104109896

Epoch: 6| Step: 5
Training loss: 0.28099048137664795
Validation loss: 1.6691565064973728

Epoch: 6| Step: 6
Training loss: 0.25595957040786743
Validation loss: 1.6635549863179524

Epoch: 6| Step: 7
Training loss: 0.2925906777381897
Validation loss: 1.680115948441208

Epoch: 6| Step: 8
Training loss: 0.44423091411590576
Validation loss: 1.6718049023741035

Epoch: 6| Step: 9
Training loss: 0.18960948288440704
Validation loss: 1.7005040901963429

Epoch: 6| Step: 10
Training loss: 0.16480353474617004
Validation loss: 1.7303166684284006

Epoch: 6| Step: 11
Training loss: 0.574901819229126
Validation loss: 1.7794878418727587

Epoch: 6| Step: 12
Training loss: 0.22826552391052246
Validation loss: 1.7963560729898431

Epoch: 6| Step: 13
Training loss: 0.3698073625564575
Validation loss: 1.7910723737491074

Epoch: 295| Step: 0
Training loss: 0.23472605645656586
Validation loss: 1.7981576752919022

Epoch: 6| Step: 1
Training loss: 0.1685764044523239
Validation loss: 1.7890951915453839

Epoch: 6| Step: 2
Training loss: 0.23703007400035858
Validation loss: 1.7664340901118454

Epoch: 6| Step: 3
Training loss: 0.7105101943016052
Validation loss: 1.7474972586477957

Epoch: 6| Step: 4
Training loss: 0.21975159645080566
Validation loss: 1.7255904828348467

Epoch: 6| Step: 5
Training loss: 0.39434731006622314
Validation loss: 1.7322920906928279

Epoch: 6| Step: 6
Training loss: 0.23375923931598663
Validation loss: 1.7122771134299617

Epoch: 6| Step: 7
Training loss: 0.15944737195968628
Validation loss: 1.7034205172651558

Epoch: 6| Step: 8
Training loss: 0.25132647156715393
Validation loss: 1.690738006304669

Epoch: 6| Step: 9
Training loss: 0.31819742918014526
Validation loss: 1.6875576229505642

Epoch: 6| Step: 10
Training loss: 0.25279003381729126
Validation loss: 1.6739272379106092

Epoch: 6| Step: 11
Training loss: 0.26715219020843506
Validation loss: 1.658151239477178

Epoch: 6| Step: 12
Training loss: 0.17141807079315186
Validation loss: 1.6675934996656192

Epoch: 6| Step: 13
Training loss: 0.12091998010873795
Validation loss: 1.6856762811701784

Epoch: 296| Step: 0
Training loss: 0.25197070837020874
Validation loss: 1.7393456838464225

Epoch: 6| Step: 1
Training loss: 0.2563576102256775
Validation loss: 1.733696105659649

Epoch: 6| Step: 2
Training loss: 0.1769936978816986
Validation loss: 1.7618750154331166

Epoch: 6| Step: 3
Training loss: 0.3687209486961365
Validation loss: 1.7529056956691127

Epoch: 6| Step: 4
Training loss: 0.38677990436553955
Validation loss: 1.7418928460408283

Epoch: 6| Step: 5
Training loss: 0.27567818760871887
Validation loss: 1.7277260070206018

Epoch: 6| Step: 6
Training loss: 0.3150840401649475
Validation loss: 1.707983297686423

Epoch: 6| Step: 7
Training loss: 0.3395182490348816
Validation loss: 1.6939644800719393

Epoch: 6| Step: 8
Training loss: 0.15262748301029205
Validation loss: 1.6553745256957186

Epoch: 6| Step: 9
Training loss: 0.25391313433647156
Validation loss: 1.6752624152809061

Epoch: 6| Step: 10
Training loss: 0.2823459506034851
Validation loss: 1.6705964355058567

Epoch: 6| Step: 11
Training loss: 0.3761541247367859
Validation loss: 1.7033433196365193

Epoch: 6| Step: 12
Training loss: 0.31198322772979736
Validation loss: 1.7058645615013697

Epoch: 6| Step: 13
Training loss: 0.2053348422050476
Validation loss: 1.6799845528858963

Epoch: 297| Step: 0
Training loss: 0.1149674579501152
Validation loss: 1.699636036349881

Epoch: 6| Step: 1
Training loss: 0.25047799944877625
Validation loss: 1.6763490246188255

Epoch: 6| Step: 2
Training loss: 0.3283848464488983
Validation loss: 1.6936404038501043

Epoch: 6| Step: 3
Training loss: 0.34466904401779175
Validation loss: 1.7029738746663576

Epoch: 6| Step: 4
Training loss: 0.3095264434814453
Validation loss: 1.7200767391471452

Epoch: 6| Step: 5
Training loss: 0.48450613021850586
Validation loss: 1.7088488571105465

Epoch: 6| Step: 6
Training loss: 0.3384626805782318
Validation loss: 1.7080297713638635

Epoch: 6| Step: 7
Training loss: 0.16728976368904114
Validation loss: 1.7018244240873603

Epoch: 6| Step: 8
Training loss: 0.18324537575244904
Validation loss: 1.7312217322728967

Epoch: 6| Step: 9
Training loss: 0.36938726902008057
Validation loss: 1.7335058771153933

Epoch: 6| Step: 10
Training loss: 0.19347672164440155
Validation loss: 1.7013698918845064

Epoch: 6| Step: 11
Training loss: 0.20770207047462463
Validation loss: 1.6811054342536516

Epoch: 6| Step: 12
Training loss: 0.2577422857284546
Validation loss: 1.6788538707199918

Epoch: 6| Step: 13
Training loss: 0.4002346694469452
Validation loss: 1.6448189109884284

Epoch: 298| Step: 0
Training loss: 0.21925173699855804
Validation loss: 1.6746032084188154

Epoch: 6| Step: 1
Training loss: 0.6147347688674927
Validation loss: 1.701152087539755

Epoch: 6| Step: 2
Training loss: 0.2470870018005371
Validation loss: 1.70600494774439

Epoch: 6| Step: 3
Training loss: 0.24280399084091187
Validation loss: 1.7076110968025782

Epoch: 6| Step: 4
Training loss: 0.29033637046813965
Validation loss: 1.7170327953113023

Epoch: 6| Step: 5
Training loss: 0.31838008761405945
Validation loss: 1.7416751346280497

Epoch: 6| Step: 6
Training loss: 0.1496644914150238
Validation loss: 1.7392291984250468

Epoch: 6| Step: 7
Training loss: 0.2689724564552307
Validation loss: 1.7728135149966004

Epoch: 6| Step: 8
Training loss: 0.2835219204425812
Validation loss: 1.7556376482850762

Epoch: 6| Step: 9
Training loss: 0.19805005192756653
Validation loss: 1.768991804892017

Epoch: 6| Step: 10
Training loss: 0.1959959864616394
Validation loss: 1.7342867697438886

Epoch: 6| Step: 11
Training loss: 0.16328367590904236
Validation loss: 1.7361346983140515

Epoch: 6| Step: 12
Training loss: 0.22046583890914917
Validation loss: 1.7444724523892967

Epoch: 6| Step: 13
Training loss: 0.4780900180339813
Validation loss: 1.7288223851111628

Epoch: 299| Step: 0
Training loss: 0.15309013426303864
Validation loss: 1.713047203197274

Epoch: 6| Step: 1
Training loss: 0.5432330965995789
Validation loss: 1.727227985218007

Epoch: 6| Step: 2
Training loss: 0.2721231281757355
Validation loss: 1.704186595896239

Epoch: 6| Step: 3
Training loss: 0.19864967465400696
Validation loss: 1.710661857358871

Epoch: 6| Step: 4
Training loss: 0.21386846899986267
Validation loss: 1.694550129675096

Epoch: 6| Step: 5
Training loss: 0.1814756989479065
Validation loss: 1.6819521316917994

Epoch: 6| Step: 6
Training loss: 0.3058432936668396
Validation loss: 1.6914269462708504

Epoch: 6| Step: 7
Training loss: 0.26561760902404785
Validation loss: 1.719561405079339

Epoch: 6| Step: 8
Training loss: 0.38415980339050293
Validation loss: 1.7253375784043343

Epoch: 6| Step: 9
Training loss: 0.31471067667007446
Validation loss: 1.724757041341515

Epoch: 6| Step: 10
Training loss: 0.22470395267009735
Validation loss: 1.7306637379430956

Epoch: 6| Step: 11
Training loss: 0.22252912819385529
Validation loss: 1.7023363369767384

Epoch: 6| Step: 12
Training loss: 0.2683192491531372
Validation loss: 1.7060226214829313

Epoch: 6| Step: 13
Training loss: 0.1879577934741974
Validation loss: 1.724552741614721

Epoch: 300| Step: 0
Training loss: 0.3512114882469177
Validation loss: 1.7107268174489338

Epoch: 6| Step: 1
Training loss: 0.12963810563087463
Validation loss: 1.7244230547258932

Epoch: 6| Step: 2
Training loss: 0.25691771507263184
Validation loss: 1.7573423385620117

Epoch: 6| Step: 3
Training loss: 0.32935631275177
Validation loss: 1.747821024669114

Epoch: 6| Step: 4
Training loss: 0.1347673237323761
Validation loss: 1.7098561307435394

Epoch: 6| Step: 5
Training loss: 0.5871670246124268
Validation loss: 1.7374941892521356

Epoch: 6| Step: 6
Training loss: 0.18378086388111115
Validation loss: 1.7400096078072824

Epoch: 6| Step: 7
Training loss: 0.303526908159256
Validation loss: 1.7554943971736456

Epoch: 6| Step: 8
Training loss: 0.14478576183319092
Validation loss: 1.733804689940586

Epoch: 6| Step: 9
Training loss: 0.1542605459690094
Validation loss: 1.7468315016838811

Epoch: 6| Step: 10
Training loss: 0.18656125664710999
Validation loss: 1.7338319939951743

Epoch: 6| Step: 11
Training loss: 0.2013794481754303
Validation loss: 1.7188748262261833

Epoch: 6| Step: 12
Training loss: 0.283450722694397
Validation loss: 1.7084843856032177

Epoch: 6| Step: 13
Training loss: 0.3507428765296936
Validation loss: 1.6842929329923404

Epoch: 301| Step: 0
Training loss: 0.32153502106666565
Validation loss: 1.6805768038636895

Epoch: 6| Step: 1
Training loss: 0.2659545838832855
Validation loss: 1.6896845538129088

Epoch: 6| Step: 2
Training loss: 0.19624601304531097
Validation loss: 1.6829156593609882

Epoch: 6| Step: 3
Training loss: 0.258230596780777
Validation loss: 1.7403550545374553

Epoch: 6| Step: 4
Training loss: 0.20602062344551086
Validation loss: 1.7235957794291998

Epoch: 6| Step: 5
Training loss: 0.24172145128250122
Validation loss: 1.7329954767739901

Epoch: 6| Step: 6
Training loss: 0.10753332078456879
Validation loss: 1.7219010373597503

Epoch: 6| Step: 7
Training loss: 0.5895017981529236
Validation loss: 1.742428606556308

Epoch: 6| Step: 8
Training loss: 0.22088244557380676
Validation loss: 1.7278209117151075

Epoch: 6| Step: 9
Training loss: 0.27559322118759155
Validation loss: 1.709911165057972

Epoch: 6| Step: 10
Training loss: 0.2835634648799896
Validation loss: 1.6723125352654407

Epoch: 6| Step: 11
Training loss: 0.15258142352104187
Validation loss: 1.6654104878825526

Epoch: 6| Step: 12
Training loss: 0.2313660979270935
Validation loss: 1.6617551785643383

Epoch: 6| Step: 13
Training loss: 0.2757219672203064
Validation loss: 1.689782791240241

Epoch: 302| Step: 0
Training loss: 0.1940246820449829
Validation loss: 1.6926973340331868

Epoch: 6| Step: 1
Training loss: 0.43994224071502686
Validation loss: 1.7120034066579675

Epoch: 6| Step: 2
Training loss: 0.22168207168579102
Validation loss: 1.717900381293348

Epoch: 6| Step: 3
Training loss: 0.2685243785381317
Validation loss: 1.7218027813460237

Epoch: 6| Step: 4
Training loss: 0.16738557815551758
Validation loss: 1.7266670516742173

Epoch: 6| Step: 5
Training loss: 0.26965516805648804
Validation loss: 1.7310058762950282

Epoch: 6| Step: 6
Training loss: 0.083428755402565
Validation loss: 1.731324198425457

Epoch: 6| Step: 7
Training loss: 0.2359473705291748
Validation loss: 1.7083738773099837

Epoch: 6| Step: 8
Training loss: 0.19632263481616974
Validation loss: 1.726281774941311

Epoch: 6| Step: 9
Training loss: 0.2293664515018463
Validation loss: 1.7270388475028418

Epoch: 6| Step: 10
Training loss: 0.2967146635055542
Validation loss: 1.7261259331498096

Epoch: 6| Step: 11
Training loss: 0.3075602650642395
Validation loss: 1.7411576547930319

Epoch: 6| Step: 12
Training loss: 0.15432953834533691
Validation loss: 1.703698246709762

Epoch: 6| Step: 13
Training loss: 0.3797610104084015
Validation loss: 1.684060263377364

Epoch: 303| Step: 0
Training loss: 0.1382329761981964
Validation loss: 1.6722193725647465

Epoch: 6| Step: 1
Training loss: 0.351296603679657
Validation loss: 1.6785676171702724

Epoch: 6| Step: 2
Training loss: 0.22583602368831635
Validation loss: 1.6400026698266306

Epoch: 6| Step: 3
Training loss: 0.19965791702270508
Validation loss: 1.6580779424277685

Epoch: 6| Step: 4
Training loss: 0.12868334352970123
Validation loss: 1.6498928339250627

Epoch: 6| Step: 5
Training loss: 0.37362515926361084
Validation loss: 1.6873881175953855

Epoch: 6| Step: 6
Training loss: 0.20764975249767303
Validation loss: 1.684444458253922

Epoch: 6| Step: 7
Training loss: 0.24083973467350006
Validation loss: 1.707178795209495

Epoch: 6| Step: 8
Training loss: 0.11914892494678497
Validation loss: 1.707907461350964

Epoch: 6| Step: 9
Training loss: 0.5349433422088623
Validation loss: 1.7150917437768751

Epoch: 6| Step: 10
Training loss: 0.13994458317756653
Validation loss: 1.7355550566027242

Epoch: 6| Step: 11
Training loss: 0.24229401350021362
Validation loss: 1.7647238213528869

Epoch: 6| Step: 12
Training loss: 0.23762494325637817
Validation loss: 1.7636035873043923

Epoch: 6| Step: 13
Training loss: 0.21044546365737915
Validation loss: 1.7582533987619544

Epoch: 304| Step: 0
Training loss: 0.17729686200618744
Validation loss: 1.7259009384339856

Epoch: 6| Step: 1
Training loss: 0.11292555928230286
Validation loss: 1.7117302456209738

Epoch: 6| Step: 2
Training loss: 0.217733234167099
Validation loss: 1.7052686393901866

Epoch: 6| Step: 3
Training loss: 0.17849531769752502
Validation loss: 1.7090428907384154

Epoch: 6| Step: 4
Training loss: 0.19730816781520844
Validation loss: 1.6998248331008419

Epoch: 6| Step: 5
Training loss: 0.2126540243625641
Validation loss: 1.678085886022096

Epoch: 6| Step: 6
Training loss: 0.20649996399879456
Validation loss: 1.6669667177302863

Epoch: 6| Step: 7
Training loss: 0.20755428075790405
Validation loss: 1.70693334328231

Epoch: 6| Step: 8
Training loss: 0.480663925409317
Validation loss: 1.6906617123593566

Epoch: 6| Step: 9
Training loss: 0.25254496932029724
Validation loss: 1.718237337245736

Epoch: 6| Step: 10
Training loss: 0.2994500994682312
Validation loss: 1.7365436207863592

Epoch: 6| Step: 11
Training loss: 0.19409550726413727
Validation loss: 1.7611155074129823

Epoch: 6| Step: 12
Training loss: 0.23769576847553253
Validation loss: 1.7528361492259528

Epoch: 6| Step: 13
Training loss: 0.35801270604133606
Validation loss: 1.7534008154305079

Epoch: 305| Step: 0
Training loss: 0.0862526148557663
Validation loss: 1.7310441841361344

Epoch: 6| Step: 1
Training loss: 0.14669513702392578
Validation loss: 1.7392103672027588

Epoch: 6| Step: 2
Training loss: 0.15105903148651123
Validation loss: 1.7345453641747917

Epoch: 6| Step: 3
Training loss: 0.2521243691444397
Validation loss: 1.7168062104973743

Epoch: 6| Step: 4
Training loss: 0.42314785718917847
Validation loss: 1.7323620511639504

Epoch: 6| Step: 5
Training loss: 0.162054181098938
Validation loss: 1.7158906716172413

Epoch: 6| Step: 6
Training loss: 0.367931604385376
Validation loss: 1.740361136774863

Epoch: 6| Step: 7
Training loss: 0.24763628840446472
Validation loss: 1.7294264967723558

Epoch: 6| Step: 8
Training loss: 0.2238309234380722
Validation loss: 1.7451812708249657

Epoch: 6| Step: 9
Training loss: 0.18529841303825378
Validation loss: 1.7369597496524933

Epoch: 6| Step: 10
Training loss: 0.1208813339471817
Validation loss: 1.7288496289201962

Epoch: 6| Step: 11
Training loss: 0.3456302881240845
Validation loss: 1.7470563406585364

Epoch: 6| Step: 12
Training loss: 0.32010865211486816
Validation loss: 1.7726352381449875

Epoch: 6| Step: 13
Training loss: 0.1860276311635971
Validation loss: 1.7632203653294554

Epoch: 306| Step: 0
Training loss: 0.3104482889175415
Validation loss: 1.7327905880507601

Epoch: 6| Step: 1
Training loss: 0.18806831538677216
Validation loss: 1.721025945037924

Epoch: 6| Step: 2
Training loss: 0.12324856966733932
Validation loss: 1.7268787481451546

Epoch: 6| Step: 3
Training loss: 0.3245420455932617
Validation loss: 1.731686007591986

Epoch: 6| Step: 4
Training loss: 0.28162604570388794
Validation loss: 1.6937948016710178

Epoch: 6| Step: 5
Training loss: 0.45640331506729126
Validation loss: 1.7020777463912964

Epoch: 6| Step: 6
Training loss: 0.24559417366981506
Validation loss: 1.7015059840294622

Epoch: 6| Step: 7
Training loss: 0.3058485984802246
Validation loss: 1.6878849319232407

Epoch: 6| Step: 8
Training loss: 0.20246556401252747
Validation loss: 1.6710603749880226

Epoch: 6| Step: 9
Training loss: 0.20267623662948608
Validation loss: 1.6587598323822021

Epoch: 6| Step: 10
Training loss: 0.2044064849615097
Validation loss: 1.6489897940748481

Epoch: 6| Step: 11
Training loss: 0.12637487053871155
Validation loss: 1.6788239453428535

Epoch: 6| Step: 12
Training loss: 0.1936531662940979
Validation loss: 1.690161479416714

Epoch: 6| Step: 13
Training loss: 0.31565919518470764
Validation loss: 1.7042794144281777

Epoch: 307| Step: 0
Training loss: 0.35768166184425354
Validation loss: 1.737901464585335

Epoch: 6| Step: 1
Training loss: 0.40803754329681396
Validation loss: 1.7437426761914325

Epoch: 6| Step: 2
Training loss: 0.21749533712863922
Validation loss: 1.761516679999649

Epoch: 6| Step: 3
Training loss: 0.13260862231254578
Validation loss: 1.716637066615525

Epoch: 6| Step: 4
Training loss: 0.2925126552581787
Validation loss: 1.7391690823339647

Epoch: 6| Step: 5
Training loss: 0.2629702389240265
Validation loss: 1.737496993874991

Epoch: 6| Step: 6
Training loss: 0.2124200463294983
Validation loss: 1.752668705037845

Epoch: 6| Step: 7
Training loss: 0.17829951643943787
Validation loss: 1.727667013804118

Epoch: 6| Step: 8
Training loss: 0.33442115783691406
Validation loss: 1.7367829776579333

Epoch: 6| Step: 9
Training loss: 0.17751310765743256
Validation loss: 1.689881520886575

Epoch: 6| Step: 10
Training loss: 0.19829371571540833
Validation loss: 1.719526985640167

Epoch: 6| Step: 11
Training loss: 0.2496470808982849
Validation loss: 1.7287060663264284

Epoch: 6| Step: 12
Training loss: 0.17111527919769287
Validation loss: 1.7219835878700338

Epoch: 6| Step: 13
Training loss: 0.2986742854118347
Validation loss: 1.7424820648726596

Epoch: 308| Step: 0
Training loss: 0.20330649614334106
Validation loss: 1.7369195889401179

Epoch: 6| Step: 1
Training loss: 0.2949146330356598
Validation loss: 1.7132778847089378

Epoch: 6| Step: 2
Training loss: 0.3307928442955017
Validation loss: 1.7048579287785355

Epoch: 6| Step: 3
Training loss: 0.4535485506057739
Validation loss: 1.7030146186069777

Epoch: 6| Step: 4
Training loss: 0.18296992778778076
Validation loss: 1.6538027281402259

Epoch: 6| Step: 5
Training loss: 0.18289493024349213
Validation loss: 1.6609467575626988

Epoch: 6| Step: 6
Training loss: 0.18251723051071167
Validation loss: 1.699330101731003

Epoch: 6| Step: 7
Training loss: 0.28168463706970215
Validation loss: 1.7170893620419245

Epoch: 6| Step: 8
Training loss: 0.28365379571914673
Validation loss: 1.757511769571612

Epoch: 6| Step: 9
Training loss: 0.10694628953933716
Validation loss: 1.786581168892563

Epoch: 6| Step: 10
Training loss: 0.2234514355659485
Validation loss: 1.7820406447174728

Epoch: 6| Step: 11
Training loss: 0.19047558307647705
Validation loss: 1.7879648939255746

Epoch: 6| Step: 12
Training loss: 0.19691836833953857
Validation loss: 1.751819509331898

Epoch: 6| Step: 13
Training loss: 0.22109729051589966
Validation loss: 1.7491661758833035

Epoch: 309| Step: 0
Training loss: 0.17041581869125366
Validation loss: 1.7387813060514388

Epoch: 6| Step: 1
Training loss: 0.37033307552337646
Validation loss: 1.7288666258576095

Epoch: 6| Step: 2
Training loss: 0.44166380167007446
Validation loss: 1.736119572834302

Epoch: 6| Step: 3
Training loss: 0.26694583892822266
Validation loss: 1.7160317346613894

Epoch: 6| Step: 4
Training loss: 0.22881168127059937
Validation loss: 1.7024568896139822

Epoch: 6| Step: 5
Training loss: 0.18216142058372498
Validation loss: 1.723119415262694

Epoch: 6| Step: 6
Training loss: 0.1864936500787735
Validation loss: 1.740916564900388

Epoch: 6| Step: 7
Training loss: 0.19410857558250427
Validation loss: 1.7492166821674635

Epoch: 6| Step: 8
Training loss: 0.19967764616012573
Validation loss: 1.7502941380264938

Epoch: 6| Step: 9
Training loss: 0.2529680132865906
Validation loss: 1.767153497665159

Epoch: 6| Step: 10
Training loss: 0.21357810497283936
Validation loss: 1.748577581938877

Epoch: 6| Step: 11
Training loss: 0.3062516152858734
Validation loss: 1.7236117092511987

Epoch: 6| Step: 12
Training loss: 0.19269688427448273
Validation loss: 1.687809483979338

Epoch: 6| Step: 13
Training loss: 0.23402553796768188
Validation loss: 1.6516552721300433

Epoch: 310| Step: 0
Training loss: 0.2665170431137085
Validation loss: 1.6521621442610217

Epoch: 6| Step: 1
Training loss: 0.2437349557876587
Validation loss: 1.6477326238027183

Epoch: 6| Step: 2
Training loss: 0.13392892479896545
Validation loss: 1.6464801731929983

Epoch: 6| Step: 3
Training loss: 0.24705524742603302
Validation loss: 1.6644261678059895

Epoch: 6| Step: 4
Training loss: 0.31911730766296387
Validation loss: 1.6612065094773487

Epoch: 6| Step: 5
Training loss: 0.22461502254009247
Validation loss: 1.6934441148593862

Epoch: 6| Step: 6
Training loss: 0.18503785133361816
Validation loss: 1.7165644668763684

Epoch: 6| Step: 7
Training loss: 0.22597430646419525
Validation loss: 1.7435800824114072

Epoch: 6| Step: 8
Training loss: 0.2833685278892517
Validation loss: 1.7664022907134025

Epoch: 6| Step: 9
Training loss: 0.15584418177604675
Validation loss: 1.7825876410289476

Epoch: 6| Step: 10
Training loss: 0.4430847764015198
Validation loss: 1.7749120625116492

Epoch: 6| Step: 11
Training loss: 0.1405417025089264
Validation loss: 1.7455735975696194

Epoch: 6| Step: 12
Training loss: 0.09533970803022385
Validation loss: 1.7439235230927825

Epoch: 6| Step: 13
Training loss: 0.2162216454744339
Validation loss: 1.7638555085787209

Epoch: 311| Step: 0
Training loss: 0.2593171000480652
Validation loss: 1.7655393667118524

Epoch: 6| Step: 1
Training loss: 0.13767465949058533
Validation loss: 1.745077469015634

Epoch: 6| Step: 2
Training loss: 0.17074641585350037
Validation loss: 1.719786367108745

Epoch: 6| Step: 3
Training loss: 0.2547496557235718
Validation loss: 1.7009368570902015

Epoch: 6| Step: 4
Training loss: 0.2241121232509613
Validation loss: 1.708167665748186

Epoch: 6| Step: 5
Training loss: 0.24708867073059082
Validation loss: 1.738617781669863

Epoch: 6| Step: 6
Training loss: 0.27033621072769165
Validation loss: 1.769206739241077

Epoch: 6| Step: 7
Training loss: 0.22340071201324463
Validation loss: 1.7683887943144767

Epoch: 6| Step: 8
Training loss: 0.26094937324523926
Validation loss: 1.752122389372959

Epoch: 6| Step: 9
Training loss: 0.47068387269973755
Validation loss: 1.7784912791303409

Epoch: 6| Step: 10
Training loss: 0.2255799025297165
Validation loss: 1.743702442415299

Epoch: 6| Step: 11
Training loss: 0.26592549681663513
Validation loss: 1.7428119438950733

Epoch: 6| Step: 12
Training loss: 0.23208387196063995
Validation loss: 1.7148030163139425

Epoch: 6| Step: 13
Training loss: 0.14156147837638855
Validation loss: 1.720224057474444

Epoch: 312| Step: 0
Training loss: 0.2324725091457367
Validation loss: 1.7479725973580473

Epoch: 6| Step: 1
Training loss: 0.1756066232919693
Validation loss: 1.688243483984342

Epoch: 6| Step: 2
Training loss: 0.12176112830638885
Validation loss: 1.7203882202025382

Epoch: 6| Step: 3
Training loss: 0.22521468997001648
Validation loss: 1.744381917420254

Epoch: 6| Step: 4
Training loss: 0.25445127487182617
Validation loss: 1.7356884415431688

Epoch: 6| Step: 5
Training loss: 0.18990051746368408
Validation loss: 1.7301707575398106

Epoch: 6| Step: 6
Training loss: 0.20663133263587952
Validation loss: 1.7357926548168223

Epoch: 6| Step: 7
Training loss: 0.14375223219394684
Validation loss: 1.7599769881976548

Epoch: 6| Step: 8
Training loss: 0.47482478618621826
Validation loss: 1.7469585031591437

Epoch: 6| Step: 9
Training loss: 0.21610486507415771
Validation loss: 1.7521693475784794

Epoch: 6| Step: 10
Training loss: 0.1662929356098175
Validation loss: 1.7435264805311799

Epoch: 6| Step: 11
Training loss: 0.2730867862701416
Validation loss: 1.783589514352942

Epoch: 6| Step: 12
Training loss: 0.20323532819747925
Validation loss: 1.7748837983736427

Epoch: 6| Step: 13
Training loss: 0.1339617371559143
Validation loss: 1.7430506880565355

Epoch: 313| Step: 0
Training loss: 0.5184604525566101
Validation loss: 1.7569136824659122

Epoch: 6| Step: 1
Training loss: 0.16323897242546082
Validation loss: 1.7990378705404138

Epoch: 6| Step: 2
Training loss: 0.23180732131004333
Validation loss: 1.8280408356779365

Epoch: 6| Step: 3
Training loss: 0.2556305229663849
Validation loss: 1.790345880293077

Epoch: 6| Step: 4
Training loss: 0.2090100646018982
Validation loss: 1.76365537540887

Epoch: 6| Step: 5
Training loss: 0.13569751381874084
Validation loss: 1.7897280467453824

Epoch: 6| Step: 6
Training loss: 0.2517378330230713
Validation loss: 1.7265756130218506

Epoch: 6| Step: 7
Training loss: 0.2896764278411865
Validation loss: 1.7001940755433933

Epoch: 6| Step: 8
Training loss: 0.24146431684494019
Validation loss: 1.6806917370006602

Epoch: 6| Step: 9
Training loss: 0.2395736575126648
Validation loss: 1.665638599344479

Epoch: 6| Step: 10
Training loss: 0.28810346126556396
Validation loss: 1.6663252756159792

Epoch: 6| Step: 11
Training loss: 0.3212140202522278
Validation loss: 1.6777299834835915

Epoch: 6| Step: 12
Training loss: 0.18980541825294495
Validation loss: 1.666899904128044

Epoch: 6| Step: 13
Training loss: 0.255664199590683
Validation loss: 1.7008852779224355

Epoch: 314| Step: 0
Training loss: 0.24450919032096863
Validation loss: 1.7072574887224423

Epoch: 6| Step: 1
Training loss: 0.1341511309146881
Validation loss: 1.7800337806824715

Epoch: 6| Step: 2
Training loss: 0.22869953513145447
Validation loss: 1.765155820436375

Epoch: 6| Step: 3
Training loss: 0.23688361048698425
Validation loss: 1.8102759981668124

Epoch: 6| Step: 4
Training loss: 0.19033163785934448
Validation loss: 1.8116730528493081

Epoch: 6| Step: 5
Training loss: 0.15474694967269897
Validation loss: 1.800178768814251

Epoch: 6| Step: 6
Training loss: 0.14106252789497375
Validation loss: 1.7837441743061107

Epoch: 6| Step: 7
Training loss: 0.5966169834136963
Validation loss: 1.7958694017061623

Epoch: 6| Step: 8
Training loss: 0.25494781136512756
Validation loss: 1.7240524215082969

Epoch: 6| Step: 9
Training loss: 0.16227573156356812
Validation loss: 1.6904503318571276

Epoch: 6| Step: 10
Training loss: 0.23941299319267273
Validation loss: 1.6703160321840675

Epoch: 6| Step: 11
Training loss: 0.20239514112472534
Validation loss: 1.6494603285225489

Epoch: 6| Step: 12
Training loss: 0.25414109230041504
Validation loss: 1.6326861586622012

Epoch: 6| Step: 13
Training loss: 0.1468634307384491
Validation loss: 1.6536722157591133

Epoch: 315| Step: 0
Training loss: 0.1984352469444275
Validation loss: 1.6305738969515728

Epoch: 6| Step: 1
Training loss: 0.18788133561611176
Validation loss: 1.644698319896575

Epoch: 6| Step: 2
Training loss: 0.23820476233959198
Validation loss: 1.674220992672828

Epoch: 6| Step: 3
Training loss: 0.2185477912425995
Validation loss: 1.66427323895116

Epoch: 6| Step: 4
Training loss: 0.3786071240901947
Validation loss: 1.7013785467352918

Epoch: 6| Step: 5
Training loss: 0.1587485373020172
Validation loss: 1.7216000800491662

Epoch: 6| Step: 6
Training loss: 0.216014564037323
Validation loss: 1.7571035662005026

Epoch: 6| Step: 7
Training loss: 0.10065364837646484
Validation loss: 1.736315986802501

Epoch: 6| Step: 8
Training loss: 0.1620272696018219
Validation loss: 1.7351014614105225

Epoch: 6| Step: 9
Training loss: 0.20573030412197113
Validation loss: 1.7438449218708982

Epoch: 6| Step: 10
Training loss: 0.13652436435222626
Validation loss: 1.7284546539347658

Epoch: 6| Step: 11
Training loss: 0.1923236846923828
Validation loss: 1.7286298890267648

Epoch: 6| Step: 12
Training loss: 0.3586863577365875
Validation loss: 1.707384910634769

Epoch: 6| Step: 13
Training loss: 0.09585369378328323
Validation loss: 1.6698289866088538

Epoch: 316| Step: 0
Training loss: 0.12888625264167786
Validation loss: 1.6871762211604784

Epoch: 6| Step: 1
Training loss: 0.17992839217185974
Validation loss: 1.6952026133896203

Epoch: 6| Step: 2
Training loss: 0.1891000121831894
Validation loss: 1.6838351872659498

Epoch: 6| Step: 3
Training loss: 0.16294622421264648
Validation loss: 1.703739156005203

Epoch: 6| Step: 4
Training loss: 0.5258082151412964
Validation loss: 1.7208768411349225

Epoch: 6| Step: 5
Training loss: 0.25076568126678467
Validation loss: 1.7240160537022415

Epoch: 6| Step: 6
Training loss: 0.21771050989627838
Validation loss: 1.7478470904852754

Epoch: 6| Step: 7
Training loss: 0.16483254730701447
Validation loss: 1.745596880553871

Epoch: 6| Step: 8
Training loss: 0.145996555685997
Validation loss: 1.7390541030514626

Epoch: 6| Step: 9
Training loss: 0.22173121571540833
Validation loss: 1.7427730842303204

Epoch: 6| Step: 10
Training loss: 0.150791734457016
Validation loss: 1.7415819597500626

Epoch: 6| Step: 11
Training loss: 0.24289439618587494
Validation loss: 1.7200988185021184

Epoch: 6| Step: 12
Training loss: 0.15484684705734253
Validation loss: 1.7236045445165327

Epoch: 6| Step: 13
Training loss: 0.23136864602565765
Validation loss: 1.679282872907577

Epoch: 317| Step: 0
Training loss: 0.17794647812843323
Validation loss: 1.693473796690664

Epoch: 6| Step: 1
Training loss: 0.14672432839870453
Validation loss: 1.6579747315376037

Epoch: 6| Step: 2
Training loss: 0.19248796999454498
Validation loss: 1.645161077540408

Epoch: 6| Step: 3
Training loss: 0.24969345331192017
Validation loss: 1.6503912691147096

Epoch: 6| Step: 4
Training loss: 0.15555274486541748
Validation loss: 1.6489620785559378

Epoch: 6| Step: 5
Training loss: 0.1799478679895401
Validation loss: 1.679682348364143

Epoch: 6| Step: 6
Training loss: 0.1541648805141449
Validation loss: 1.7230767896098476

Epoch: 6| Step: 7
Training loss: 0.4959542751312256
Validation loss: 1.7678803602854412

Epoch: 6| Step: 8
Training loss: 0.2099677175283432
Validation loss: 1.7753231025511218

Epoch: 6| Step: 9
Training loss: 0.26819494366645813
Validation loss: 1.770897508949362

Epoch: 6| Step: 10
Training loss: 0.25136798620224
Validation loss: 1.7660830482359855

Epoch: 6| Step: 11
Training loss: 0.1292373239994049
Validation loss: 1.7165967315755866

Epoch: 6| Step: 12
Training loss: 0.2766130268573761
Validation loss: 1.7091827597669376

Epoch: 6| Step: 13
Training loss: 0.15337689220905304
Validation loss: 1.7043867226569884

Epoch: 318| Step: 0
Training loss: 0.1449693739414215
Validation loss: 1.6779293744794783

Epoch: 6| Step: 1
Training loss: 0.16962392628192902
Validation loss: 1.6914581252682594

Epoch: 6| Step: 2
Training loss: 0.24609243869781494
Validation loss: 1.6678190410778087

Epoch: 6| Step: 3
Training loss: 0.13248750567436218
Validation loss: 1.6520872180179884

Epoch: 6| Step: 4
Training loss: 0.2052662968635559
Validation loss: 1.6825828962428595

Epoch: 6| Step: 5
Training loss: 0.1435949206352234
Validation loss: 1.6992302287009455

Epoch: 6| Step: 6
Training loss: 0.15780891478061676
Validation loss: 1.7460279977449806

Epoch: 6| Step: 7
Training loss: 0.14495036005973816
Validation loss: 1.7344725055079306

Epoch: 6| Step: 8
Training loss: 0.15817566215991974
Validation loss: 1.7655832472667898

Epoch: 6| Step: 9
Training loss: 0.5020601153373718
Validation loss: 1.7619941042315574

Epoch: 6| Step: 10
Training loss: 0.25087520480155945
Validation loss: 1.8063778377348376

Epoch: 6| Step: 11
Training loss: 0.17852634191513062
Validation loss: 1.801615015152962

Epoch: 6| Step: 12
Training loss: 0.24241039156913757
Validation loss: 1.791471239059202

Epoch: 6| Step: 13
Training loss: 0.2858083248138428
Validation loss: 1.7541436264591832

Epoch: 319| Step: 0
Training loss: 0.450774610042572
Validation loss: 1.7021957135969592

Epoch: 6| Step: 1
Training loss: 0.10160114616155624
Validation loss: 1.7222544531668387

Epoch: 6| Step: 2
Training loss: 0.24374249577522278
Validation loss: 1.7005000678441857

Epoch: 6| Step: 3
Training loss: 0.30071568489074707
Validation loss: 1.6592179242000784

Epoch: 6| Step: 4
Training loss: 0.21457400918006897
Validation loss: 1.648776759383499

Epoch: 6| Step: 5
Training loss: 0.14427819848060608
Validation loss: 1.618077911356444

Epoch: 6| Step: 6
Training loss: 0.16228100657463074
Validation loss: 1.621657456121137

Epoch: 6| Step: 7
Training loss: 0.25092434883117676
Validation loss: 1.655144533803386

Epoch: 6| Step: 8
Training loss: 0.21416710317134857
Validation loss: 1.6351228978044243

Epoch: 6| Step: 9
Training loss: 0.14323364198207855
Validation loss: 1.6549361085378995

Epoch: 6| Step: 10
Training loss: 0.1544140726327896
Validation loss: 1.7038032700938563

Epoch: 6| Step: 11
Training loss: 0.21607112884521484
Validation loss: 1.6918060837253448

Epoch: 6| Step: 12
Training loss: 0.11651443690061569
Validation loss: 1.7250468141289168

Epoch: 6| Step: 13
Training loss: 0.23838642239570618
Validation loss: 1.7712772277093702

Epoch: 320| Step: 0
Training loss: 0.37003350257873535
Validation loss: 1.8130294802368327

Epoch: 6| Step: 1
Training loss: 0.27479714155197144
Validation loss: 1.7576996408483034

Epoch: 6| Step: 2
Training loss: 0.14082708954811096
Validation loss: 1.7056887572811497

Epoch: 6| Step: 3
Training loss: 0.1273515224456787
Validation loss: 1.659095101459052

Epoch: 6| Step: 4
Training loss: 0.18465030193328857
Validation loss: 1.6445983699572984

Epoch: 6| Step: 5
Training loss: 0.5116892457008362
Validation loss: 1.6450798408959502

Epoch: 6| Step: 6
Training loss: 0.2106708139181137
Validation loss: 1.6518876014217254

Epoch: 6| Step: 7
Training loss: 0.17609021067619324
Validation loss: 1.6607809451318556

Epoch: 6| Step: 8
Training loss: 0.21480458974838257
Validation loss: 1.6995404279360207

Epoch: 6| Step: 9
Training loss: 0.19091112911701202
Validation loss: 1.7160379066262195

Epoch: 6| Step: 10
Training loss: 0.24649810791015625
Validation loss: 1.7622763174836353

Epoch: 6| Step: 11
Training loss: 0.1738409698009491
Validation loss: 1.81287811135733

Epoch: 6| Step: 12
Training loss: 0.276678204536438
Validation loss: 1.8352480191056446

Epoch: 6| Step: 13
Training loss: 0.2401222139596939
Validation loss: 1.8088092406590779

Epoch: 321| Step: 0
Training loss: 0.44416695833206177
Validation loss: 1.7646148281712686

Epoch: 6| Step: 1
Training loss: 0.2753932476043701
Validation loss: 1.7467221239561677

Epoch: 6| Step: 2
Training loss: 0.15420562028884888
Validation loss: 1.751884001557545

Epoch: 6| Step: 3
Training loss: 0.3198844790458679
Validation loss: 1.7023034070127754

Epoch: 6| Step: 4
Training loss: 0.22132572531700134
Validation loss: 1.689623849366301

Epoch: 6| Step: 5
Training loss: 0.1912159025669098
Validation loss: 1.6588563790885351

Epoch: 6| Step: 6
Training loss: 0.16399526596069336
Validation loss: 1.6719833356077953

Epoch: 6| Step: 7
Training loss: 0.3152541518211365
Validation loss: 1.6765821992710073

Epoch: 6| Step: 8
Training loss: 0.1148601546883583
Validation loss: 1.7237626955073366

Epoch: 6| Step: 9
Training loss: 0.2690800428390503
Validation loss: 1.7379250616155646

Epoch: 6| Step: 10
Training loss: 0.16835394501686096
Validation loss: 1.747107413507277

Epoch: 6| Step: 11
Training loss: 0.25991350412368774
Validation loss: 1.7987153607030069

Epoch: 6| Step: 12
Training loss: 0.2713695168495178
Validation loss: 1.7805466613461893

Epoch: 6| Step: 13
Training loss: 0.2943635582923889
Validation loss: 1.7454132918388612

Epoch: 322| Step: 0
Training loss: 0.11868894100189209
Validation loss: 1.7034955652811195

Epoch: 6| Step: 1
Training loss: 0.17573001980781555
Validation loss: 1.674861297812513

Epoch: 6| Step: 2
Training loss: 0.5395437479019165
Validation loss: 1.6571202355046426

Epoch: 6| Step: 3
Training loss: 0.13171294331550598
Validation loss: 1.6628145979296776

Epoch: 6| Step: 4
Training loss: 0.18640252947807312
Validation loss: 1.675485994226189

Epoch: 6| Step: 5
Training loss: 0.46289733052253723
Validation loss: 1.6726934832911338

Epoch: 6| Step: 6
Training loss: 0.22484999895095825
Validation loss: 1.6463608011122672

Epoch: 6| Step: 7
Training loss: 0.2570984363555908
Validation loss: 1.67630353794303

Epoch: 6| Step: 8
Training loss: 0.2613365650177002
Validation loss: 1.6511501105882789

Epoch: 6| Step: 9
Training loss: 0.20776847004890442
Validation loss: 1.701183557510376

Epoch: 6| Step: 10
Training loss: 0.21317251026630402
Validation loss: 1.7134715690407702

Epoch: 6| Step: 11
Training loss: 0.17789414525032043
Validation loss: 1.7637106321191276

Epoch: 6| Step: 12
Training loss: 0.22661545872688293
Validation loss: 1.7883414042893278

Epoch: 6| Step: 13
Training loss: 0.3443973958492279
Validation loss: 1.7653712649499216

Epoch: 323| Step: 0
Training loss: 0.19268232583999634
Validation loss: 1.7989660181025022

Epoch: 6| Step: 1
Training loss: 0.24133580923080444
Validation loss: 1.7767807745164441

Epoch: 6| Step: 2
Training loss: 0.26288896799087524
Validation loss: 1.738612139096824

Epoch: 6| Step: 3
Training loss: 0.18466131389141083
Validation loss: 1.7111342158368839

Epoch: 6| Step: 4
Training loss: 0.11696445941925049
Validation loss: 1.664039065760951

Epoch: 6| Step: 5
Training loss: 0.22085866332054138
Validation loss: 1.6716574199738041

Epoch: 6| Step: 6
Training loss: 0.29008036851882935
Validation loss: 1.6382842063903809

Epoch: 6| Step: 7
Training loss: 0.37883344292640686
Validation loss: 1.6359856269692863

Epoch: 6| Step: 8
Training loss: 0.2285386472940445
Validation loss: 1.6035998123948292

Epoch: 6| Step: 9
Training loss: 0.4371647834777832
Validation loss: 1.6290376135098037

Epoch: 6| Step: 10
Training loss: 0.15184006094932556
Validation loss: 1.6310774498088385

Epoch: 6| Step: 11
Training loss: 0.21437013149261475
Validation loss: 1.6537156040950487

Epoch: 6| Step: 12
Training loss: 0.171817809343338
Validation loss: 1.664299241958126

Epoch: 6| Step: 13
Training loss: 0.22504445910453796
Validation loss: 1.704246958096822

Epoch: 324| Step: 0
Training loss: 0.19944705069065094
Validation loss: 1.7401251510907245

Epoch: 6| Step: 1
Training loss: 0.14390933513641357
Validation loss: 1.7460094715959282

Epoch: 6| Step: 2
Training loss: 0.22171851992607117
Validation loss: 1.741459495277815

Epoch: 6| Step: 3
Training loss: 0.4308910071849823
Validation loss: 1.7403522717055453

Epoch: 6| Step: 4
Training loss: 0.17580726742744446
Validation loss: 1.7241569590824906

Epoch: 6| Step: 5
Training loss: 0.2554709315299988
Validation loss: 1.6965751237766717

Epoch: 6| Step: 6
Training loss: 0.1859094500541687
Validation loss: 1.688687534742458

Epoch: 6| Step: 7
Training loss: 0.2338690459728241
Validation loss: 1.7038326314700547

Epoch: 6| Step: 8
Training loss: 0.1259687840938568
Validation loss: 1.6730566486235587

Epoch: 6| Step: 9
Training loss: 0.20033159852027893
Validation loss: 1.678190553060142

Epoch: 6| Step: 10
Training loss: 0.24012227356433868
Validation loss: 1.652068441913974

Epoch: 6| Step: 11
Training loss: 0.28534698486328125
Validation loss: 1.6718989931127077

Epoch: 6| Step: 12
Training loss: 0.21914353966712952
Validation loss: 1.6323903017146613

Epoch: 6| Step: 13
Training loss: 0.22185102105140686
Validation loss: 1.6479068597157795

Epoch: 325| Step: 0
Training loss: 0.157787024974823
Validation loss: 1.6898741132469588

Epoch: 6| Step: 1
Training loss: 0.19869399070739746
Validation loss: 1.7128476481283865

Epoch: 6| Step: 2
Training loss: 0.5171844363212585
Validation loss: 1.7275430130702194

Epoch: 6| Step: 3
Training loss: 0.21969905495643616
Validation loss: 1.7791398443201536

Epoch: 6| Step: 4
Training loss: 0.2323196530342102
Validation loss: 1.776654807470178

Epoch: 6| Step: 5
Training loss: 0.20849241316318512
Validation loss: 1.7640550956931165

Epoch: 6| Step: 6
Training loss: 0.1607617288827896
Validation loss: 1.751910815956772

Epoch: 6| Step: 7
Training loss: 0.19140252470970154
Validation loss: 1.7342333588548886

Epoch: 6| Step: 8
Training loss: 0.24264374375343323
Validation loss: 1.711152579194756

Epoch: 6| Step: 9
Training loss: 0.1687072515487671
Validation loss: 1.695034127081594

Epoch: 6| Step: 10
Training loss: 0.15853524208068848
Validation loss: 1.6631700056855396

Epoch: 6| Step: 11
Training loss: 0.25619176030158997
Validation loss: 1.6639630320251628

Epoch: 6| Step: 12
Training loss: 0.1703472137451172
Validation loss: 1.6759721438090007

Epoch: 6| Step: 13
Training loss: 0.3146399259567261
Validation loss: 1.6614259942885368

Epoch: 326| Step: 0
Training loss: 0.26575911045074463
Validation loss: 1.6715952619429557

Epoch: 6| Step: 1
Training loss: 0.15568846464157104
Validation loss: 1.689602199421134

Epoch: 6| Step: 2
Training loss: 0.1476134955883026
Validation loss: 1.6823528838414017

Epoch: 6| Step: 3
Training loss: 0.28702205419540405
Validation loss: 1.6988036517174012

Epoch: 6| Step: 4
Training loss: 0.39282727241516113
Validation loss: 1.6972524581416961

Epoch: 6| Step: 5
Training loss: 0.31387943029403687
Validation loss: 1.7130321648813063

Epoch: 6| Step: 6
Training loss: 0.18844762444496155
Validation loss: 1.7162787081092916

Epoch: 6| Step: 7
Training loss: 0.09023934602737427
Validation loss: 1.6986859857395131

Epoch: 6| Step: 8
Training loss: 0.1488773226737976
Validation loss: 1.6987455711569837

Epoch: 6| Step: 9
Training loss: 0.16133728623390198
Validation loss: 1.6659244657844625

Epoch: 6| Step: 10
Training loss: 0.16478322446346283
Validation loss: 1.6560033393162552

Epoch: 6| Step: 11
Training loss: 0.09927885234355927
Validation loss: 1.62506954644316

Epoch: 6| Step: 12
Training loss: 0.14283183217048645
Validation loss: 1.6159808584438857

Epoch: 6| Step: 13
Training loss: 0.24585525691509247
Validation loss: 1.61608326050543

Epoch: 327| Step: 0
Training loss: 0.18802759051322937
Validation loss: 1.619351557506028

Epoch: 6| Step: 1
Training loss: 0.2081640660762787
Validation loss: 1.6301395662369267

Epoch: 6| Step: 2
Training loss: 0.1662081927061081
Validation loss: 1.643380113827285

Epoch: 6| Step: 3
Training loss: 0.22229495644569397
Validation loss: 1.66141927114097

Epoch: 6| Step: 4
Training loss: 0.1252325028181076
Validation loss: 1.6543154331945604

Epoch: 6| Step: 5
Training loss: 0.4338894784450531
Validation loss: 1.701091965039571

Epoch: 6| Step: 6
Training loss: 0.08554030954837799
Validation loss: 1.6820735162304294

Epoch: 6| Step: 7
Training loss: 0.09716548770666122
Validation loss: 1.682973305384318

Epoch: 6| Step: 8
Training loss: 0.17072713375091553
Validation loss: 1.6558501592246435

Epoch: 6| Step: 9
Training loss: 0.12541495263576508
Validation loss: 1.6532967731516848

Epoch: 6| Step: 10
Training loss: 0.24160908162593842
Validation loss: 1.6422498892712336

Epoch: 6| Step: 11
Training loss: 0.22850890457630157
Validation loss: 1.6421658505675614

Epoch: 6| Step: 12
Training loss: 0.18463167548179626
Validation loss: 1.6710821890061902

Epoch: 6| Step: 13
Training loss: 0.10676924139261246
Validation loss: 1.664974727938252

Epoch: 328| Step: 0
Training loss: 0.16190338134765625
Validation loss: 1.6787037131606892

Epoch: 6| Step: 1
Training loss: 0.21570217609405518
Validation loss: 1.6836931628565635

Epoch: 6| Step: 2
Training loss: 0.12226958572864532
Validation loss: 1.701743088742738

Epoch: 6| Step: 3
Training loss: 0.5250503420829773
Validation loss: 1.672631936688577

Epoch: 6| Step: 4
Training loss: 0.10872764140367508
Validation loss: 1.6798301537831624

Epoch: 6| Step: 5
Training loss: 0.29289865493774414
Validation loss: 1.6968961518297914

Epoch: 6| Step: 6
Training loss: 0.25274211168289185
Validation loss: 1.6771332948438582

Epoch: 6| Step: 7
Training loss: 0.11894159018993378
Validation loss: 1.6641920394794916

Epoch: 6| Step: 8
Training loss: 0.13723322749137878
Validation loss: 1.6572111293833742

Epoch: 6| Step: 9
Training loss: 0.25720077753067017
Validation loss: 1.6415460199438117

Epoch: 6| Step: 10
Training loss: 0.18946531414985657
Validation loss: 1.6202076494052846

Epoch: 6| Step: 11
Training loss: 0.243893563747406
Validation loss: 1.6371398228470997

Epoch: 6| Step: 12
Training loss: 0.09920090436935425
Validation loss: 1.6299390664664648

Epoch: 6| Step: 13
Training loss: 0.13735288381576538
Validation loss: 1.6603892541700793

Epoch: 329| Step: 0
Training loss: 0.1295226663351059
Validation loss: 1.6707924719779723

Epoch: 6| Step: 1
Training loss: 0.17740479111671448
Validation loss: 1.6615015383689635

Epoch: 6| Step: 2
Training loss: 0.22327646613121033
Validation loss: 1.6852461753352996

Epoch: 6| Step: 3
Training loss: 0.17101101577281952
Validation loss: 1.6878027531408495

Epoch: 6| Step: 4
Training loss: 0.18536663055419922
Validation loss: 1.6847230644636257

Epoch: 6| Step: 5
Training loss: 0.18548163771629333
Validation loss: 1.6758944116612917

Epoch: 6| Step: 6
Training loss: 0.12472984194755554
Validation loss: 1.6512911588914934

Epoch: 6| Step: 7
Training loss: 0.2156360000371933
Validation loss: 1.6495907486125987

Epoch: 6| Step: 8
Training loss: 0.22371947765350342
Validation loss: 1.6758770647869314

Epoch: 6| Step: 9
Training loss: 0.10723543167114258
Validation loss: 1.6779312702917284

Epoch: 6| Step: 10
Training loss: 0.38803625106811523
Validation loss: 1.6615657537214217

Epoch: 6| Step: 11
Training loss: 0.27040576934814453
Validation loss: 1.6671573231297154

Epoch: 6| Step: 12
Training loss: 0.23183271288871765
Validation loss: 1.635874431620362

Epoch: 6| Step: 13
Training loss: 0.14990945160388947
Validation loss: 1.6557678804602673

Epoch: 330| Step: 0
Training loss: 0.09621967375278473
Validation loss: 1.6760835878310665

Epoch: 6| Step: 1
Training loss: 0.14935265481472015
Validation loss: 1.7061149138276295

Epoch: 6| Step: 2
Training loss: 0.22676818072795868
Validation loss: 1.7329579822478756

Epoch: 6| Step: 3
Training loss: 0.4593794047832489
Validation loss: 1.748241339960406

Epoch: 6| Step: 4
Training loss: 0.16527052223682404
Validation loss: 1.7338012290257279

Epoch: 6| Step: 5
Training loss: 0.10486416518688202
Validation loss: 1.717306072993945

Epoch: 6| Step: 6
Training loss: 0.13702596724033356
Validation loss: 1.6892191812556276

Epoch: 6| Step: 7
Training loss: 0.15741324424743652
Validation loss: 1.675322473690074

Epoch: 6| Step: 8
Training loss: 0.23771801590919495
Validation loss: 1.6824205460086945

Epoch: 6| Step: 9
Training loss: 0.11127275228500366
Validation loss: 1.6812445707218622

Epoch: 6| Step: 10
Training loss: 0.16711655259132385
Validation loss: 1.684844115728973

Epoch: 6| Step: 11
Training loss: 0.1588003933429718
Validation loss: 1.6931020880258212

Epoch: 6| Step: 12
Training loss: 0.18684235215187073
Validation loss: 1.6949188811804659

Epoch: 6| Step: 13
Training loss: 0.24123515188694
Validation loss: 1.6918796275251655

Epoch: 331| Step: 0
Training loss: 0.1486114263534546
Validation loss: 1.6817670265833538

Epoch: 6| Step: 1
Training loss: 0.10723458230495453
Validation loss: 1.6856390160899009

Epoch: 6| Step: 2
Training loss: 0.1141585111618042
Validation loss: 1.6807167940242316

Epoch: 6| Step: 3
Training loss: 0.16366323828697205
Validation loss: 1.7158911651180637

Epoch: 6| Step: 4
Training loss: 0.22217415273189545
Validation loss: 1.7055160102023874

Epoch: 6| Step: 5
Training loss: 0.15606021881103516
Validation loss: 1.6912357525158954

Epoch: 6| Step: 6
Training loss: 0.0934155285358429
Validation loss: 1.689067812376125

Epoch: 6| Step: 7
Training loss: 0.16388863325119019
Validation loss: 1.6922350378446682

Epoch: 6| Step: 8
Training loss: 0.1726476550102234
Validation loss: 1.6776738269354707

Epoch: 6| Step: 9
Training loss: 0.24346612393856049
Validation loss: 1.652999407501631

Epoch: 6| Step: 10
Training loss: 0.22228777408599854
Validation loss: 1.662506111206547

Epoch: 6| Step: 11
Training loss: 0.47218358516693115
Validation loss: 1.668519550754178

Epoch: 6| Step: 12
Training loss: 0.17032530903816223
Validation loss: 1.6593064262020973

Epoch: 6| Step: 13
Training loss: 0.19279932975769043
Validation loss: 1.694619253117551

Epoch: 332| Step: 0
Training loss: 0.11495994031429291
Validation loss: 1.710838972881276

Epoch: 6| Step: 1
Training loss: 0.17876368761062622
Validation loss: 1.6998417415926534

Epoch: 6| Step: 2
Training loss: 0.4131523072719574
Validation loss: 1.7221809279534124

Epoch: 6| Step: 3
Training loss: 0.1616663634777069
Validation loss: 1.7283419819288357

Epoch: 6| Step: 4
Training loss: 0.15350577235221863
Validation loss: 1.726905620226296

Epoch: 6| Step: 5
Training loss: 0.2799370586872101
Validation loss: 1.7184513525296283

Epoch: 6| Step: 6
Training loss: 0.182486891746521
Validation loss: 1.6977997595264065

Epoch: 6| Step: 7
Training loss: 0.2491917461156845
Validation loss: 1.6650117917727398

Epoch: 6| Step: 8
Training loss: 0.15838903188705444
Validation loss: 1.6716589209853963

Epoch: 6| Step: 9
Training loss: 0.2220577895641327
Validation loss: 1.6385352611541748

Epoch: 6| Step: 10
Training loss: 0.11052565276622772
Validation loss: 1.6477218186983498

Epoch: 6| Step: 11
Training loss: 0.09358539432287216
Validation loss: 1.6626531411242742

Epoch: 6| Step: 12
Training loss: 0.0988081619143486
Validation loss: 1.675188983640363

Epoch: 6| Step: 13
Training loss: 0.10353957116603851
Validation loss: 1.6816818316777546

Epoch: 333| Step: 0
Training loss: 0.09081603586673737
Validation loss: 1.6866791466230988

Epoch: 6| Step: 1
Training loss: 0.18673545122146606
Validation loss: 1.6704777684263004

Epoch: 6| Step: 2
Training loss: 0.22084710001945496
Validation loss: 1.669879714647929

Epoch: 6| Step: 3
Training loss: 0.23503489792346954
Validation loss: 1.6469109558290052

Epoch: 6| Step: 4
Training loss: 0.2163250893354416
Validation loss: 1.6307008304903585

Epoch: 6| Step: 5
Training loss: 0.15532222390174866
Validation loss: 1.6435631693050425

Epoch: 6| Step: 6
Training loss: 0.23263375461101532
Validation loss: 1.6572620612318798

Epoch: 6| Step: 7
Training loss: 0.12114731967449188
Validation loss: 1.6578651423095374

Epoch: 6| Step: 8
Training loss: 0.1259334534406662
Validation loss: 1.6698213533688617

Epoch: 6| Step: 9
Training loss: 0.13466979563236237
Validation loss: 1.636991843100517

Epoch: 6| Step: 10
Training loss: 0.179555281996727
Validation loss: 1.653619893135563

Epoch: 6| Step: 11
Training loss: 0.11816425621509552
Validation loss: 1.6695879005616712

Epoch: 6| Step: 12
Training loss: 0.4492722749710083
Validation loss: 1.6677546219159198

Epoch: 6| Step: 13
Training loss: 0.11563922464847565
Validation loss: 1.6724715860941077

Epoch: 334| Step: 0
Training loss: 0.21501219272613525
Validation loss: 1.6791531398732176

Epoch: 6| Step: 1
Training loss: 0.08266115188598633
Validation loss: 1.6666765328376525

Epoch: 6| Step: 2
Training loss: 0.09820832312107086
Validation loss: 1.6964154871561195

Epoch: 6| Step: 3
Training loss: 0.1994810551404953
Validation loss: 1.6868331534888155

Epoch: 6| Step: 4
Training loss: 0.10909416526556015
Validation loss: 1.6692429639959847

Epoch: 6| Step: 5
Training loss: 0.10694588720798492
Validation loss: 1.6666918896859693

Epoch: 6| Step: 6
Training loss: 0.2362205535173416
Validation loss: 1.6817196851135583

Epoch: 6| Step: 7
Training loss: 0.18233051896095276
Validation loss: 1.66068777602206

Epoch: 6| Step: 8
Training loss: 0.1395496428012848
Validation loss: 1.6790579775328278

Epoch: 6| Step: 9
Training loss: 0.18322168290615082
Validation loss: 1.6844974628058813

Epoch: 6| Step: 10
Training loss: 0.33274129033088684
Validation loss: 1.694681038138687

Epoch: 6| Step: 11
Training loss: 0.21753612160682678
Validation loss: 1.6898038054025302

Epoch: 6| Step: 12
Training loss: 0.15404380857944489
Validation loss: 1.7306684191508959

Epoch: 6| Step: 13
Training loss: 0.11832676827907562
Validation loss: 1.7056778336084017

Epoch: 335| Step: 0
Training loss: 0.112668976187706
Validation loss: 1.6874238111639535

Epoch: 6| Step: 1
Training loss: 0.16895931959152222
Validation loss: 1.7067028591709752

Epoch: 6| Step: 2
Training loss: 0.15011878311634064
Validation loss: 1.6907431015404322

Epoch: 6| Step: 3
Training loss: 0.187796950340271
Validation loss: 1.710717954943257

Epoch: 6| Step: 4
Training loss: 0.1418750137090683
Validation loss: 1.709902166038431

Epoch: 6| Step: 5
Training loss: 0.14974069595336914
Validation loss: 1.7054185008489957

Epoch: 6| Step: 6
Training loss: 0.17408394813537598
Validation loss: 1.7171681786096225

Epoch: 6| Step: 7
Training loss: 0.09952926635742188
Validation loss: 1.7179635724713724

Epoch: 6| Step: 8
Training loss: 0.07395672053098679
Validation loss: 1.6840766181227982

Epoch: 6| Step: 9
Training loss: 0.36118635535240173
Validation loss: 1.6777780491818663

Epoch: 6| Step: 10
Training loss: 0.144948810338974
Validation loss: 1.6887875987637428

Epoch: 6| Step: 11
Training loss: 0.17444488406181335
Validation loss: 1.6680017978914323

Epoch: 6| Step: 12
Training loss: 0.1537499576807022
Validation loss: 1.6507187940741097

Epoch: 6| Step: 13
Training loss: 0.09807999432086945
Validation loss: 1.6349345535360358

Epoch: 336| Step: 0
Training loss: 0.1515115648508072
Validation loss: 1.642693393973894

Epoch: 6| Step: 1
Training loss: 0.3769468069076538
Validation loss: 1.6182224750518799

Epoch: 6| Step: 2
Training loss: 0.19213804602622986
Validation loss: 1.6079128967818392

Epoch: 6| Step: 3
Training loss: 0.19542628526687622
Validation loss: 1.6601922165962957

Epoch: 6| Step: 4
Training loss: 0.0892329216003418
Validation loss: 1.646777629852295

Epoch: 6| Step: 5
Training loss: 0.16559770703315735
Validation loss: 1.6874016331088157

Epoch: 6| Step: 6
Training loss: 0.17432457208633423
Validation loss: 1.6736952450967604

Epoch: 6| Step: 7
Training loss: 0.10255435854196548
Validation loss: 1.664527835384492

Epoch: 6| Step: 8
Training loss: 0.11537996679544449
Validation loss: 1.6698153018951416

Epoch: 6| Step: 9
Training loss: 0.14451280236244202
Validation loss: 1.691132091706799

Epoch: 6| Step: 10
Training loss: 0.10500271618366241
Validation loss: 1.6831818870318833

Epoch: 6| Step: 11
Training loss: 0.14770761132240295
Validation loss: 1.6416430293872792

Epoch: 6| Step: 12
Training loss: 0.2044914960861206
Validation loss: 1.6490544362734723

Epoch: 6| Step: 13
Training loss: 0.09938304871320724
Validation loss: 1.6691009075410905

Epoch: 337| Step: 0
Training loss: 0.46956121921539307
Validation loss: 1.6513818483198843

Epoch: 6| Step: 1
Training loss: 0.1968516707420349
Validation loss: 1.622915917827237

Epoch: 6| Step: 2
Training loss: 0.19784188270568848
Validation loss: 1.6292275997900194

Epoch: 6| Step: 3
Training loss: 0.10170309990644455
Validation loss: 1.6172122673321796

Epoch: 6| Step: 4
Training loss: 0.11113720387220383
Validation loss: 1.6336173139592653

Epoch: 6| Step: 5
Training loss: 0.1792711764574051
Validation loss: 1.6355037804572814

Epoch: 6| Step: 6
Training loss: 0.12747079133987427
Validation loss: 1.6446217285689486

Epoch: 6| Step: 7
Training loss: 0.17895741760730743
Validation loss: 1.6567087455462384

Epoch: 6| Step: 8
Training loss: 0.1274084448814392
Validation loss: 1.6862566689009308

Epoch: 6| Step: 9
Training loss: 0.17474019527435303
Validation loss: 1.6775145710155528

Epoch: 6| Step: 10
Training loss: 0.20500242710113525
Validation loss: 1.6667629018906625

Epoch: 6| Step: 11
Training loss: 0.14715676009655
Validation loss: 1.6264872397145917

Epoch: 6| Step: 12
Training loss: 0.10962988436222076
Validation loss: 1.644204943410812

Epoch: 6| Step: 13
Training loss: 0.1339932233095169
Validation loss: 1.6422608924168411

Epoch: 338| Step: 0
Training loss: 0.33771926164627075
Validation loss: 1.6361458750181301

Epoch: 6| Step: 1
Training loss: 0.18152979016304016
Validation loss: 1.6695765410700152

Epoch: 6| Step: 2
Training loss: 0.14851759374141693
Validation loss: 1.6625156671770158

Epoch: 6| Step: 3
Training loss: 0.2151022106409073
Validation loss: 1.7015359427339287

Epoch: 6| Step: 4
Training loss: 0.14494767785072327
Validation loss: 1.6854976441270562

Epoch: 6| Step: 5
Training loss: 0.07803168892860413
Validation loss: 1.7090190354213919

Epoch: 6| Step: 6
Training loss: 0.1686573326587677
Validation loss: 1.6863341716028029

Epoch: 6| Step: 7
Training loss: 0.11270960420370102
Validation loss: 1.6946320661934473

Epoch: 6| Step: 8
Training loss: 0.09617605060338974
Validation loss: 1.6743235165073025

Epoch: 6| Step: 9
Training loss: 0.14886803925037384
Validation loss: 1.6547922857346073

Epoch: 6| Step: 10
Training loss: 0.14399951696395874
Validation loss: 1.6476301018909743

Epoch: 6| Step: 11
Training loss: 0.14948488771915436
Validation loss: 1.6534916995674052

Epoch: 6| Step: 12
Training loss: 0.16942743957042694
Validation loss: 1.630190549358245

Epoch: 6| Step: 13
Training loss: 0.09619595110416412
Validation loss: 1.6373889164258075

Epoch: 339| Step: 0
Training loss: 0.20319099724292755
Validation loss: 1.6010634873502998

Epoch: 6| Step: 1
Training loss: 0.1446348875761032
Validation loss: 1.644411434409439

Epoch: 6| Step: 2
Training loss: 0.14134511351585388
Validation loss: 1.6890636413328108

Epoch: 6| Step: 3
Training loss: 0.1430022418498993
Validation loss: 1.659740105752022

Epoch: 6| Step: 4
Training loss: 0.08363647758960724
Validation loss: 1.6701413162292973

Epoch: 6| Step: 5
Training loss: 0.10821583867073059
Validation loss: 1.671039835099251

Epoch: 6| Step: 6
Training loss: 0.1538507342338562
Validation loss: 1.687605522012198

Epoch: 6| Step: 7
Training loss: 0.07697978615760803
Validation loss: 1.6487264940815587

Epoch: 6| Step: 8
Training loss: 0.16646423935890198
Validation loss: 1.6458072687989922

Epoch: 6| Step: 9
Training loss: 0.177664116024971
Validation loss: 1.6641871941986905

Epoch: 6| Step: 10
Training loss: 0.49323493242263794
Validation loss: 1.6677247362752115

Epoch: 6| Step: 11
Training loss: 0.11952270567417145
Validation loss: 1.695959956415238

Epoch: 6| Step: 12
Training loss: 0.08993913233280182
Validation loss: 1.7151675531941075

Epoch: 6| Step: 13
Training loss: 0.15069033205509186
Validation loss: 1.7261539966829362

Epoch: 340| Step: 0
Training loss: 0.211277574300766
Validation loss: 1.719786536309027

Epoch: 6| Step: 1
Training loss: 0.15563839673995972
Validation loss: 1.7150646563499206

Epoch: 6| Step: 2
Training loss: 0.4386841654777527
Validation loss: 1.7078556706828456

Epoch: 6| Step: 3
Training loss: 0.198729008436203
Validation loss: 1.7048861108800417

Epoch: 6| Step: 4
Training loss: 0.1445372849702835
Validation loss: 1.691684058917466

Epoch: 6| Step: 5
Training loss: 0.2004336714744568
Validation loss: 1.6734057459779965

Epoch: 6| Step: 6
Training loss: 0.13497669994831085
Validation loss: 1.7037606034227597

Epoch: 6| Step: 7
Training loss: 0.13570977747440338
Validation loss: 1.68788944777622

Epoch: 6| Step: 8
Training loss: 0.09837192296981812
Validation loss: 1.6895066993210905

Epoch: 6| Step: 9
Training loss: 0.1290961503982544
Validation loss: 1.7097653676104803

Epoch: 6| Step: 10
Training loss: 0.13318423926830292
Validation loss: 1.7323497027479193

Epoch: 6| Step: 11
Training loss: 0.13638761639595032
Validation loss: 1.7333191261496594

Epoch: 6| Step: 12
Training loss: 0.14930735528469086
Validation loss: 1.7659078451894945

Epoch: 6| Step: 13
Training loss: 0.12389179319143295
Validation loss: 1.7955956676954865

Epoch: 341| Step: 0
Training loss: 0.14145344495773315
Validation loss: 1.7634597645010999

Epoch: 6| Step: 1
Training loss: 0.20321905612945557
Validation loss: 1.7657909470219766

Epoch: 6| Step: 2
Training loss: 0.1417490839958191
Validation loss: 1.7348188648941696

Epoch: 6| Step: 3
Training loss: 0.20264071226119995
Validation loss: 1.7154837859574186

Epoch: 6| Step: 4
Training loss: 0.29239559173583984
Validation loss: 1.7146505181507399

Epoch: 6| Step: 5
Training loss: 0.23810815811157227
Validation loss: 1.6901463347096597

Epoch: 6| Step: 6
Training loss: 0.14244487881660461
Validation loss: 1.6571186896293395

Epoch: 6| Step: 7
Training loss: 0.09243260324001312
Validation loss: 1.6123785613685526

Epoch: 6| Step: 8
Training loss: 0.17279629409313202
Validation loss: 1.6124623616536458

Epoch: 6| Step: 9
Training loss: 0.13935911655426025
Validation loss: 1.6228078449926069

Epoch: 6| Step: 10
Training loss: 0.14208634197711945
Validation loss: 1.6009200388385403

Epoch: 6| Step: 11
Training loss: 0.3975631594657898
Validation loss: 1.6166124959145822

Epoch: 6| Step: 12
Training loss: 0.219953253865242
Validation loss: 1.648941845022222

Epoch: 6| Step: 13
Training loss: 0.08941200375556946
Validation loss: 1.6343205757038568

Epoch: 342| Step: 0
Training loss: 0.1911821961402893
Validation loss: 1.6083099611343876

Epoch: 6| Step: 1
Training loss: 0.15491238236427307
Validation loss: 1.596322077576832

Epoch: 6| Step: 2
Training loss: 0.3948199152946472
Validation loss: 1.5800327806062595

Epoch: 6| Step: 3
Training loss: 0.1515420526266098
Validation loss: 1.5951037022375292

Epoch: 6| Step: 4
Training loss: 0.12770453095436096
Validation loss: 1.6112771982787757

Epoch: 6| Step: 5
Training loss: 0.2082221508026123
Validation loss: 1.6149604987072688

Epoch: 6| Step: 6
Training loss: 0.13060438632965088
Validation loss: 1.6323486079451859

Epoch: 6| Step: 7
Training loss: 0.16581839323043823
Validation loss: 1.5921514700817805

Epoch: 6| Step: 8
Training loss: 0.15259753167629242
Validation loss: 1.6108487857285367

Epoch: 6| Step: 9
Training loss: 0.10771110653877258
Validation loss: 1.6149810655142671

Epoch: 6| Step: 10
Training loss: 0.13008517026901245
Validation loss: 1.6483537189422115

Epoch: 6| Step: 11
Training loss: 0.200482577085495
Validation loss: 1.7009259731538835

Epoch: 6| Step: 12
Training loss: 0.10587587207555771
Validation loss: 1.6883148313850485

Epoch: 6| Step: 13
Training loss: 0.14189618825912476
Validation loss: 1.6816566208357453

Epoch: 343| Step: 0
Training loss: 0.34825748205184937
Validation loss: 1.6278284800949918

Epoch: 6| Step: 1
Training loss: 0.1456989347934723
Validation loss: 1.5811795098807222

Epoch: 6| Step: 2
Training loss: 0.21358105540275574
Validation loss: 1.57210724840882

Epoch: 6| Step: 3
Training loss: 0.17113500833511353
Validation loss: 1.5804569618676299

Epoch: 6| Step: 4
Training loss: 0.15840521454811096
Validation loss: 1.553091492704166

Epoch: 6| Step: 5
Training loss: 0.2035071849822998
Validation loss: 1.558279263716872

Epoch: 6| Step: 6
Training loss: 0.21816129982471466
Validation loss: 1.5783629673783497

Epoch: 6| Step: 7
Training loss: 0.13363103568553925
Validation loss: 1.568020168171134

Epoch: 6| Step: 8
Training loss: 0.1309649795293808
Validation loss: 1.6024186085629206

Epoch: 6| Step: 9
Training loss: 0.15867862105369568
Validation loss: 1.6374118405003701

Epoch: 6| Step: 10
Training loss: 0.1370684653520584
Validation loss: 1.6512976436204807

Epoch: 6| Step: 11
Training loss: 0.16726258397102356
Validation loss: 1.6814654578444779

Epoch: 6| Step: 12
Training loss: 0.18294459581375122
Validation loss: 1.6826483767519715

Epoch: 6| Step: 13
Training loss: 0.15453331172466278
Validation loss: 1.6970599594936575

Epoch: 344| Step: 0
Training loss: 0.2800615429878235
Validation loss: 1.6742955715425554

Epoch: 6| Step: 1
Training loss: 0.1671369969844818
Validation loss: 1.6799765690680473

Epoch: 6| Step: 2
Training loss: 0.11925068497657776
Validation loss: 1.6762547108434862

Epoch: 6| Step: 3
Training loss: 0.2105240821838379
Validation loss: 1.7068400716268888

Epoch: 6| Step: 4
Training loss: 0.16095590591430664
Validation loss: 1.6631413877651255

Epoch: 6| Step: 5
Training loss: 0.1402226984500885
Validation loss: 1.6777867988873554

Epoch: 6| Step: 6
Training loss: 0.10404358804225922
Validation loss: 1.6620140639684533

Epoch: 6| Step: 7
Training loss: 0.18151059746742249
Validation loss: 1.650349768259192

Epoch: 6| Step: 8
Training loss: 0.21317441761493683
Validation loss: 1.6535724093837123

Epoch: 6| Step: 9
Training loss: 0.13498634099960327
Validation loss: 1.6462755754429808

Epoch: 6| Step: 10
Training loss: 0.10845765471458435
Validation loss: 1.655703007533986

Epoch: 6| Step: 11
Training loss: 0.1156419888138771
Validation loss: 1.6746658381595407

Epoch: 6| Step: 12
Training loss: 0.4306466579437256
Validation loss: 1.6786328233698362

Epoch: 6| Step: 13
Training loss: 0.23039916157722473
Validation loss: 1.7037929424675562

Epoch: 345| Step: 0
Training loss: 0.18546408414840698
Validation loss: 1.7188197258980042

Epoch: 6| Step: 1
Training loss: 0.09303849935531616
Validation loss: 1.72606917606887

Epoch: 6| Step: 2
Training loss: 0.13781635463237762
Validation loss: 1.7362067878887217

Epoch: 6| Step: 3
Training loss: 0.12705844640731812
Validation loss: 1.700895118457015

Epoch: 6| Step: 4
Training loss: 0.2798750400543213
Validation loss: 1.723294129935644

Epoch: 6| Step: 5
Training loss: 0.18057551980018616
Validation loss: 1.7036257379798478

Epoch: 6| Step: 6
Training loss: 0.10903201997280121
Validation loss: 1.6724644937822897

Epoch: 6| Step: 7
Training loss: 0.15245291590690613
Validation loss: 1.62959062668585

Epoch: 6| Step: 8
Training loss: 0.1999400109052658
Validation loss: 1.6112487521222842

Epoch: 6| Step: 9
Training loss: 0.38414913415908813
Validation loss: 1.6102034827714324

Epoch: 6| Step: 10
Training loss: 0.2376852035522461
Validation loss: 1.611152300270655

Epoch: 6| Step: 11
Training loss: 0.20386946201324463
Validation loss: 1.615860847375726

Epoch: 6| Step: 12
Training loss: 0.24565473198890686
Validation loss: 1.618594955372554

Epoch: 6| Step: 13
Training loss: 0.16245155036449432
Validation loss: 1.6072500546773274

Epoch: 346| Step: 0
Training loss: 0.10841882228851318
Validation loss: 1.6541458714392878

Epoch: 6| Step: 1
Training loss: 0.15460917353630066
Validation loss: 1.6711867727259153

Epoch: 6| Step: 2
Training loss: 0.11579065024852753
Validation loss: 1.660735317455825

Epoch: 6| Step: 3
Training loss: 0.22868822515010834
Validation loss: 1.6754804413805726

Epoch: 6| Step: 4
Training loss: 0.1686585545539856
Validation loss: 1.6517681972954863

Epoch: 6| Step: 5
Training loss: 0.18321743607521057
Validation loss: 1.6647612125642839

Epoch: 6| Step: 6
Training loss: 0.11262757331132889
Validation loss: 1.6320103547906364

Epoch: 6| Step: 7
Training loss: 0.14031505584716797
Validation loss: 1.614405171845549

Epoch: 6| Step: 8
Training loss: 0.4511922001838684
Validation loss: 1.6165176732565767

Epoch: 6| Step: 9
Training loss: 0.09765355288982391
Validation loss: 1.6106511341628207

Epoch: 6| Step: 10
Training loss: 0.13980504870414734
Validation loss: 1.5981590786287863

Epoch: 6| Step: 11
Training loss: 0.1605384647846222
Validation loss: 1.6007583102872294

Epoch: 6| Step: 12
Training loss: 0.15635879337787628
Validation loss: 1.6541993669284287

Epoch: 6| Step: 13
Training loss: 0.2986156642436981
Validation loss: 1.6678511340131041

Epoch: 347| Step: 0
Training loss: 0.14025193452835083
Validation loss: 1.6942639991801272

Epoch: 6| Step: 1
Training loss: 0.3017159402370453
Validation loss: 1.730833747053659

Epoch: 6| Step: 2
Training loss: 0.18103258311748505
Validation loss: 1.7649193374059533

Epoch: 6| Step: 3
Training loss: 0.16909129917621613
Validation loss: 1.730177028204805

Epoch: 6| Step: 4
Training loss: 0.252921998500824
Validation loss: 1.6852957548633698

Epoch: 6| Step: 5
Training loss: 0.1953774094581604
Validation loss: 1.6747019816470403

Epoch: 6| Step: 6
Training loss: 0.34472358226776123
Validation loss: 1.6236631434450868

Epoch: 6| Step: 7
Training loss: 0.2163931429386139
Validation loss: 1.6130081222903343

Epoch: 6| Step: 8
Training loss: 0.10131657123565674
Validation loss: 1.6011326851383332

Epoch: 6| Step: 9
Training loss: 0.15956515073776245
Validation loss: 1.596363083008797

Epoch: 6| Step: 10
Training loss: 0.23407289385795593
Validation loss: 1.6381711549656366

Epoch: 6| Step: 11
Training loss: 0.09332810342311859
Validation loss: 1.6412572591535506

Epoch: 6| Step: 12
Training loss: 0.22301778197288513
Validation loss: 1.6557418864260438

Epoch: 6| Step: 13
Training loss: 0.1646762490272522
Validation loss: 1.70207764000021

Epoch: 348| Step: 0
Training loss: 0.2142503261566162
Validation loss: 1.7077146473751272

Epoch: 6| Step: 1
Training loss: 0.11870118230581284
Validation loss: 1.6728637628657843

Epoch: 6| Step: 2
Training loss: 0.3316064178943634
Validation loss: 1.6733548641204834

Epoch: 6| Step: 3
Training loss: 0.12057275325059891
Validation loss: 1.6678010456023677

Epoch: 6| Step: 4
Training loss: 0.13515394926071167
Validation loss: 1.648279820719073

Epoch: 6| Step: 5
Training loss: 0.1253296434879303
Validation loss: 1.6389991237271218

Epoch: 6| Step: 6
Training loss: 0.17069384455680847
Validation loss: 1.6385540910946426

Epoch: 6| Step: 7
Training loss: 0.1502533107995987
Validation loss: 1.6277128393932054

Epoch: 6| Step: 8
Training loss: 0.11487741768360138
Validation loss: 1.6353960652505197

Epoch: 6| Step: 9
Training loss: 0.09329373389482498
Validation loss: 1.661800035866358

Epoch: 6| Step: 10
Training loss: 0.2900482416152954
Validation loss: 1.6581797894611154

Epoch: 6| Step: 11
Training loss: 0.12799113988876343
Validation loss: 1.6814294989391039

Epoch: 6| Step: 12
Training loss: 0.1310395896434784
Validation loss: 1.6924188893328431

Epoch: 6| Step: 13
Training loss: 0.0951395332813263
Validation loss: 1.6986947828723538

Epoch: 349| Step: 0
Training loss: 0.15248560905456543
Validation loss: 1.7036461381502048

Epoch: 6| Step: 1
Training loss: 0.11897626519203186
Validation loss: 1.6908999828882114

Epoch: 6| Step: 2
Training loss: 0.15904903411865234
Validation loss: 1.7051318114803684

Epoch: 6| Step: 3
Training loss: 0.11796603351831436
Validation loss: 1.7014443156539754

Epoch: 6| Step: 4
Training loss: 0.14200541377067566
Validation loss: 1.7364512771688483

Epoch: 6| Step: 5
Training loss: 0.24560877680778503
Validation loss: 1.7301883223236247

Epoch: 6| Step: 6
Training loss: 0.3668762743473053
Validation loss: 1.703186486997912

Epoch: 6| Step: 7
Training loss: 0.15998895466327667
Validation loss: 1.7056991284893406

Epoch: 6| Step: 8
Training loss: 0.12003584206104279
Validation loss: 1.6824259629813574

Epoch: 6| Step: 9
Training loss: 0.1142546609044075
Validation loss: 1.6818389559304843

Epoch: 6| Step: 10
Training loss: 0.14139121770858765
Validation loss: 1.6791824833039315

Epoch: 6| Step: 11
Training loss: 0.11297690123319626
Validation loss: 1.6697203267005183

Epoch: 6| Step: 12
Training loss: 0.28324151039123535
Validation loss: 1.6653014075371526

Epoch: 6| Step: 13
Training loss: 0.1016358807682991
Validation loss: 1.6679046352704365

Epoch: 350| Step: 0
Training loss: 0.35496941208839417
Validation loss: 1.668111406346803

Epoch: 6| Step: 1
Training loss: 0.20996415615081787
Validation loss: 1.6755617613433509

Epoch: 6| Step: 2
Training loss: 0.1181420087814331
Validation loss: 1.680922439021449

Epoch: 6| Step: 3
Training loss: 0.24407824873924255
Validation loss: 1.6847206187504593

Epoch: 6| Step: 4
Training loss: 0.14146099984645844
Validation loss: 1.7035447448812506

Epoch: 6| Step: 5
Training loss: 0.2276715785264969
Validation loss: 1.704706681671963

Epoch: 6| Step: 6
Training loss: 0.1881127655506134
Validation loss: 1.66995023399271

Epoch: 6| Step: 7
Training loss: 0.10598356276750565
Validation loss: 1.6730011752856675

Epoch: 6| Step: 8
Training loss: 0.09851787239313126
Validation loss: 1.6527183940333705

Epoch: 6| Step: 9
Training loss: 0.17521068453788757
Validation loss: 1.6479541383763796

Epoch: 6| Step: 10
Training loss: 0.13774356245994568
Validation loss: 1.6402523286880986

Epoch: 6| Step: 11
Training loss: 0.12444455176591873
Validation loss: 1.6240514145102551

Epoch: 6| Step: 12
Training loss: 0.11193238198757172
Validation loss: 1.6436550412126767

Epoch: 6| Step: 13
Training loss: 0.21458745002746582
Validation loss: 1.6321178040196818

Epoch: 351| Step: 0
Training loss: 0.15916620194911957
Validation loss: 1.6019750718147523

Epoch: 6| Step: 1
Training loss: 0.16215774416923523
Validation loss: 1.6027147167472429

Epoch: 6| Step: 2
Training loss: 0.21498405933380127
Validation loss: 1.6179821606605285

Epoch: 6| Step: 3
Training loss: 0.1115790605545044
Validation loss: 1.6003094257846955

Epoch: 6| Step: 4
Training loss: 0.2402588129043579
Validation loss: 1.599389805588671

Epoch: 6| Step: 5
Training loss: 0.12316286563873291
Validation loss: 1.6094069891078497

Epoch: 6| Step: 6
Training loss: 0.09624788910150528
Validation loss: 1.5906835320175334

Epoch: 6| Step: 7
Training loss: 0.07095959782600403
Validation loss: 1.5919685607315393

Epoch: 6| Step: 8
Training loss: 0.17823007702827454
Validation loss: 1.6198010342095488

Epoch: 6| Step: 9
Training loss: 0.1901279091835022
Validation loss: 1.6179606068518855

Epoch: 6| Step: 10
Training loss: 0.12753845751285553
Validation loss: 1.6585530568194646

Epoch: 6| Step: 11
Training loss: 0.10405317693948746
Validation loss: 1.6895611709164036

Epoch: 6| Step: 12
Training loss: 0.14184227585792542
Validation loss: 1.7399303541388562

Epoch: 6| Step: 13
Training loss: 0.48309433460235596
Validation loss: 1.7505908243117794

Epoch: 352| Step: 0
Training loss: 0.2649156153202057
Validation loss: 1.7647144358645204

Epoch: 6| Step: 1
Training loss: 0.2449319213628769
Validation loss: 1.7308112600798249

Epoch: 6| Step: 2
Training loss: 0.39854639768600464
Validation loss: 1.7344220120419738

Epoch: 6| Step: 3
Training loss: 0.13655655086040497
Validation loss: 1.7009307979255595

Epoch: 6| Step: 4
Training loss: 0.12921878695487976
Validation loss: 1.6499888884123934

Epoch: 6| Step: 5
Training loss: 0.11157241463661194
Validation loss: 1.649318019549052

Epoch: 6| Step: 6
Training loss: 0.17536288499832153
Validation loss: 1.6108388336755897

Epoch: 6| Step: 7
Training loss: 0.2325747162103653
Validation loss: 1.5987607753405007

Epoch: 6| Step: 8
Training loss: 0.309346079826355
Validation loss: 1.6228889278186265

Epoch: 6| Step: 9
Training loss: 0.17458587884902954
Validation loss: 1.6296587951721684

Epoch: 6| Step: 10
Training loss: 0.19127294421195984
Validation loss: 1.6703971996102283

Epoch: 6| Step: 11
Training loss: 0.10263568162918091
Validation loss: 1.7103870068826983

Epoch: 6| Step: 12
Training loss: 0.23169252276420593
Validation loss: 1.7502078574190858

Epoch: 6| Step: 13
Training loss: 0.19437919557094574
Validation loss: 1.780573195026767

Epoch: 353| Step: 0
Training loss: 0.14241886138916016
Validation loss: 1.7537872791290283

Epoch: 6| Step: 1
Training loss: 0.19776487350463867
Validation loss: 1.8021347958554503

Epoch: 6| Step: 2
Training loss: 0.07713359594345093
Validation loss: 1.7577068472421298

Epoch: 6| Step: 3
Training loss: 0.1402806043624878
Validation loss: 1.7634999675135459

Epoch: 6| Step: 4
Training loss: 0.09148109704256058
Validation loss: 1.721593729911312

Epoch: 6| Step: 5
Training loss: 0.16013826429843903
Validation loss: 1.734968743016643

Epoch: 6| Step: 6
Training loss: 0.1704488843679428
Validation loss: 1.7288625804326867

Epoch: 6| Step: 7
Training loss: 0.18012301623821259
Validation loss: 1.6977364786209599

Epoch: 6| Step: 8
Training loss: 0.1734461486339569
Validation loss: 1.689956570184359

Epoch: 6| Step: 9
Training loss: 0.18125037848949432
Validation loss: 1.6958708775940763

Epoch: 6| Step: 10
Training loss: 0.13981248438358307
Validation loss: 1.6535430044256232

Epoch: 6| Step: 11
Training loss: 0.19765152037143707
Validation loss: 1.664673077162876

Epoch: 6| Step: 12
Training loss: 0.4880642890930176
Validation loss: 1.668483559803296

Epoch: 6| Step: 13
Training loss: 0.16383832693099976
Validation loss: 1.6910628663596285

Epoch: 354| Step: 0
Training loss: 0.4016190767288208
Validation loss: 1.7178278712816135

Epoch: 6| Step: 1
Training loss: 0.14379246532917023
Validation loss: 1.6972868179762235

Epoch: 6| Step: 2
Training loss: 0.15356028079986572
Validation loss: 1.6847168835260535

Epoch: 6| Step: 3
Training loss: 0.12892204523086548
Validation loss: 1.6637231611436414

Epoch: 6| Step: 4
Training loss: 0.12007060647010803
Validation loss: 1.6620013983018938

Epoch: 6| Step: 5
Training loss: 0.15426626801490784
Validation loss: 1.6684979713091286

Epoch: 6| Step: 6
Training loss: 0.17081621289253235
Validation loss: 1.6685590167199411

Epoch: 6| Step: 7
Training loss: 0.15545138716697693
Validation loss: 1.6896518955948532

Epoch: 6| Step: 8
Training loss: 0.23529666662216187
Validation loss: 1.6925734883995467

Epoch: 6| Step: 9
Training loss: 0.20191054046154022
Validation loss: 1.7053269949010623

Epoch: 6| Step: 10
Training loss: 0.09732603281736374
Validation loss: 1.7024879481202813

Epoch: 6| Step: 11
Training loss: 0.13164597749710083
Validation loss: 1.6865440107160998

Epoch: 6| Step: 12
Training loss: 0.15915314853191376
Validation loss: 1.7032327421249882

Epoch: 6| Step: 13
Training loss: 0.14729826152324677
Validation loss: 1.7117485794969785

Epoch: 355| Step: 0
Training loss: 0.1763429045677185
Validation loss: 1.7446631910980388

Epoch: 6| Step: 1
Training loss: 0.14527562260627747
Validation loss: 1.7066966923334266

Epoch: 6| Step: 2
Training loss: 0.15900838375091553
Validation loss: 1.7170116209214734

Epoch: 6| Step: 3
Training loss: 0.09198188781738281
Validation loss: 1.6847627470570226

Epoch: 6| Step: 4
Training loss: 0.3410964608192444
Validation loss: 1.6466382716291694

Epoch: 6| Step: 5
Training loss: 0.12550026178359985
Validation loss: 1.6284614096405685

Epoch: 6| Step: 6
Training loss: 0.17566151916980743
Validation loss: 1.6439105695293796

Epoch: 6| Step: 7
Training loss: 0.1884811818599701
Validation loss: 1.6616893147909513

Epoch: 6| Step: 8
Training loss: 0.15109598636627197
Validation loss: 1.642794192478221

Epoch: 6| Step: 9
Training loss: 0.20661024749279022
Validation loss: 1.6342430871020082

Epoch: 6| Step: 10
Training loss: 0.09272659569978714
Validation loss: 1.665825645128886

Epoch: 6| Step: 11
Training loss: 0.19681517779827118
Validation loss: 1.6694911820914156

Epoch: 6| Step: 12
Training loss: 0.15079058706760406
Validation loss: 1.6729547157082507

Epoch: 6| Step: 13
Training loss: 0.1683860570192337
Validation loss: 1.6804842154184978

Epoch: 356| Step: 0
Training loss: 0.12429732084274292
Validation loss: 1.6784511586671234

Epoch: 6| Step: 1
Training loss: 0.18129168450832367
Validation loss: 1.653425383311446

Epoch: 6| Step: 2
Training loss: 0.11704155802726746
Validation loss: 1.706763103444089

Epoch: 6| Step: 3
Training loss: 0.09302481263875961
Validation loss: 1.6909668522496377

Epoch: 6| Step: 4
Training loss: 0.13274389505386353
Validation loss: 1.6976533653915569

Epoch: 6| Step: 5
Training loss: 0.1613897979259491
Validation loss: 1.6964470455723424

Epoch: 6| Step: 6
Training loss: 0.18035897612571716
Validation loss: 1.716831910994745

Epoch: 6| Step: 7
Training loss: 0.09636053442955017
Validation loss: 1.6967787217068415

Epoch: 6| Step: 8
Training loss: 0.12539413571357727
Validation loss: 1.7313654525305635

Epoch: 6| Step: 9
Training loss: 0.2782282531261444
Validation loss: 1.6667776280833828

Epoch: 6| Step: 10
Training loss: 0.1237366646528244
Validation loss: 1.7127383383371497

Epoch: 6| Step: 11
Training loss: 0.13390061259269714
Validation loss: 1.6984177686834847

Epoch: 6| Step: 12
Training loss: 0.10168454796075821
Validation loss: 1.703252605212632

Epoch: 6| Step: 13
Training loss: 0.14742501080036163
Validation loss: 1.7139595932857965

Epoch: 357| Step: 0
Training loss: 0.1890893578529358
Validation loss: 1.7012400524590605

Epoch: 6| Step: 1
Training loss: 0.08595575392246246
Validation loss: 1.7012921046185236

Epoch: 6| Step: 2
Training loss: 0.3641398847103119
Validation loss: 1.7118688289837172

Epoch: 6| Step: 3
Training loss: 0.1248164176940918
Validation loss: 1.726850648080149

Epoch: 6| Step: 4
Training loss: 0.10892539471387863
Validation loss: 1.7487889336001488

Epoch: 6| Step: 5
Training loss: 0.14100952446460724
Validation loss: 1.728974688437677

Epoch: 6| Step: 6
Training loss: 0.09081298112869263
Validation loss: 1.715262306633816

Epoch: 6| Step: 7
Training loss: 0.13438278436660767
Validation loss: 1.7153816556417814

Epoch: 6| Step: 8
Training loss: 0.1611771434545517
Validation loss: 1.6681949810315204

Epoch: 6| Step: 9
Training loss: 0.1439690887928009
Validation loss: 1.6586450812637166

Epoch: 6| Step: 10
Training loss: 0.15665552020072937
Validation loss: 1.6550982857263217

Epoch: 6| Step: 11
Training loss: 0.19138726592063904
Validation loss: 1.6612254740089498

Epoch: 6| Step: 12
Training loss: 0.13471117615699768
Validation loss: 1.6974297159461564

Epoch: 6| Step: 13
Training loss: 0.255663126707077
Validation loss: 1.6787680361860542

Epoch: 358| Step: 0
Training loss: 0.15509381890296936
Validation loss: 1.671554603884297

Epoch: 6| Step: 1
Training loss: 0.08851245045661926
Validation loss: 1.6962478532586047

Epoch: 6| Step: 2
Training loss: 0.3729509115219116
Validation loss: 1.6902660195545485

Epoch: 6| Step: 3
Training loss: 0.07774277031421661
Validation loss: 1.6714458311757734

Epoch: 6| Step: 4
Training loss: 0.10872761160135269
Validation loss: 1.6943367745286675

Epoch: 6| Step: 5
Training loss: 0.1939980387687683
Validation loss: 1.7119924650397351

Epoch: 6| Step: 6
Training loss: 0.18567298352718353
Validation loss: 1.704365796940301

Epoch: 6| Step: 7
Training loss: 0.1248253732919693
Validation loss: 1.6784734828497774

Epoch: 6| Step: 8
Training loss: 0.1362071931362152
Validation loss: 1.6886455192360827

Epoch: 6| Step: 9
Training loss: 0.19095942378044128
Validation loss: 1.728083138824791

Epoch: 6| Step: 10
Training loss: 0.09555698931217194
Validation loss: 1.7416370389282063

Epoch: 6| Step: 11
Training loss: 0.21719786524772644
Validation loss: 1.767717005104147

Epoch: 6| Step: 12
Training loss: 0.14825725555419922
Validation loss: 1.7666037762036888

Epoch: 6| Step: 13
Training loss: 0.19812552630901337
Validation loss: 1.7368664959425568

Epoch: 359| Step: 0
Training loss: 0.11315614730119705
Validation loss: 1.6920315040055143

Epoch: 6| Step: 1
Training loss: 0.13247254490852356
Validation loss: 1.6671536545599661

Epoch: 6| Step: 2
Training loss: 0.12377764284610748
Validation loss: 1.6658610707970076

Epoch: 6| Step: 3
Training loss: 0.19576236605644226
Validation loss: 1.6796747394787368

Epoch: 6| Step: 4
Training loss: 0.14754003286361694
Validation loss: 1.6700874233758578

Epoch: 6| Step: 5
Training loss: 0.1823602318763733
Validation loss: 1.6346716342433807

Epoch: 6| Step: 6
Training loss: 0.4526304602622986
Validation loss: 1.6363343525958318

Epoch: 6| Step: 7
Training loss: 0.25140517950057983
Validation loss: 1.6699821609322743

Epoch: 6| Step: 8
Training loss: 0.17651361227035522
Validation loss: 1.6592691688127414

Epoch: 6| Step: 9
Training loss: 0.11720648407936096
Validation loss: 1.6784537537123567

Epoch: 6| Step: 10
Training loss: 0.08378450572490692
Validation loss: 1.67669589032409

Epoch: 6| Step: 11
Training loss: 0.11661776155233383
Validation loss: 1.7054082808956024

Epoch: 6| Step: 12
Training loss: 0.13448500633239746
Validation loss: 1.727930599643338

Epoch: 6| Step: 13
Training loss: 0.22862942516803741
Validation loss: 1.7450234595165457

Epoch: 360| Step: 0
Training loss: 0.168977752327919
Validation loss: 1.7392627475082234

Epoch: 6| Step: 1
Training loss: 0.2100324034690857
Validation loss: 1.756244501759929

Epoch: 6| Step: 2
Training loss: 0.1680527776479721
Validation loss: 1.7200402534136208

Epoch: 6| Step: 3
Training loss: 0.18083079159259796
Validation loss: 1.718928878025342

Epoch: 6| Step: 4
Training loss: 0.40800708532333374
Validation loss: 1.6718915124093332

Epoch: 6| Step: 5
Training loss: 0.21221238374710083
Validation loss: 1.6871444614984656

Epoch: 6| Step: 6
Training loss: 0.1768043041229248
Validation loss: 1.6459480421517485

Epoch: 6| Step: 7
Training loss: 0.10649265348911285
Validation loss: 1.633794823000508

Epoch: 6| Step: 8
Training loss: 0.20688477158546448
Validation loss: 1.6336020167155931

Epoch: 6| Step: 9
Training loss: 0.1609107106924057
Validation loss: 1.6128169375081216

Epoch: 6| Step: 10
Training loss: 0.21794012188911438
Validation loss: 1.629261791065175

Epoch: 6| Step: 11
Training loss: 0.11323294043540955
Validation loss: 1.647229274113973

Epoch: 6| Step: 12
Training loss: 0.10023851692676544
Validation loss: 1.6730741147072083

Epoch: 6| Step: 13
Training loss: 0.17545776069164276
Validation loss: 1.6936047807816537

Epoch: 361| Step: 0
Training loss: 0.10881705582141876
Validation loss: 1.705746111049447

Epoch: 6| Step: 1
Training loss: 0.17280393838882446
Validation loss: 1.7049887129055556

Epoch: 6| Step: 2
Training loss: 0.1170644462108612
Validation loss: 1.702810392584852

Epoch: 6| Step: 3
Training loss: 0.2347503900527954
Validation loss: 1.6784124669208322

Epoch: 6| Step: 4
Training loss: 0.1569158136844635
Validation loss: 1.6649307461195095

Epoch: 6| Step: 5
Training loss: 0.09347356855869293
Validation loss: 1.6402609425206338

Epoch: 6| Step: 6
Training loss: 0.14961394667625427
Validation loss: 1.6383015891557098

Epoch: 6| Step: 7
Training loss: 0.10907639563083649
Validation loss: 1.6233122374421807

Epoch: 6| Step: 8
Training loss: 0.10921008884906769
Validation loss: 1.6064486080600369

Epoch: 6| Step: 9
Training loss: 0.4450448453426361
Validation loss: 1.6477020978927612

Epoch: 6| Step: 10
Training loss: 0.1404358297586441
Validation loss: 1.6446898432188137

Epoch: 6| Step: 11
Training loss: 0.10442161560058594
Validation loss: 1.6378765349747033

Epoch: 6| Step: 12
Training loss: 0.11296310275793076
Validation loss: 1.6439841876747787

Epoch: 6| Step: 13
Training loss: 0.04831606522202492
Validation loss: 1.630802191713805

Epoch: 362| Step: 0
Training loss: 0.19316613674163818
Validation loss: 1.6245562799515263

Epoch: 6| Step: 1
Training loss: 0.1859821230173111
Validation loss: 1.6404059984350716

Epoch: 6| Step: 2
Training loss: 0.13145554065704346
Validation loss: 1.6244611611930273

Epoch: 6| Step: 3
Training loss: 0.11064468324184418
Validation loss: 1.6338075207125755

Epoch: 6| Step: 4
Training loss: 0.16217532753944397
Validation loss: 1.632357225623182

Epoch: 6| Step: 5
Training loss: 0.31732210516929626
Validation loss: 1.6257230517684773

Epoch: 6| Step: 6
Training loss: 0.19227439165115356
Validation loss: 1.6166903165078932

Epoch: 6| Step: 7
Training loss: 0.08380229771137238
Validation loss: 1.6178127219600063

Epoch: 6| Step: 8
Training loss: 0.21046856045722961
Validation loss: 1.6076507222267888

Epoch: 6| Step: 9
Training loss: 0.1386069804430008
Validation loss: 1.6135746894344207

Epoch: 6| Step: 10
Training loss: 0.09848365187644958
Validation loss: 1.6287958493796728

Epoch: 6| Step: 11
Training loss: 0.13235250115394592
Validation loss: 1.6205347385457767

Epoch: 6| Step: 12
Training loss: 0.0794176384806633
Validation loss: 1.6315892973253805

Epoch: 6| Step: 13
Training loss: 0.07314606755971909
Validation loss: 1.6388222350869128

Epoch: 363| Step: 0
Training loss: 0.0813019871711731
Validation loss: 1.610536700935774

Epoch: 6| Step: 1
Training loss: 0.11505433917045593
Validation loss: 1.6018769676967333

Epoch: 6| Step: 2
Training loss: 0.17076745629310608
Validation loss: 1.6074669989206458

Epoch: 6| Step: 3
Training loss: 0.11819641292095184
Validation loss: 1.6234664929810392

Epoch: 6| Step: 4
Training loss: 0.12968608736991882
Validation loss: 1.5835943683501212

Epoch: 6| Step: 5
Training loss: 0.1918918341398239
Validation loss: 1.607949737579592

Epoch: 6| Step: 6
Training loss: 0.16002392768859863
Validation loss: 1.5851368981022989

Epoch: 6| Step: 7
Training loss: 0.08375295996665955
Validation loss: 1.6124625000902402

Epoch: 6| Step: 8
Training loss: 0.09375990182161331
Validation loss: 1.6034320580062045

Epoch: 6| Step: 9
Training loss: 0.14000245928764343
Validation loss: 1.6010495411452426

Epoch: 6| Step: 10
Training loss: 0.306476354598999
Validation loss: 1.6330561625060214

Epoch: 6| Step: 11
Training loss: 0.11774109303951263
Validation loss: 1.6127746220557921

Epoch: 6| Step: 12
Training loss: 0.11371438950300217
Validation loss: 1.6428345839182537

Epoch: 6| Step: 13
Training loss: 0.11863920092582703
Validation loss: 1.6274179374018023

Epoch: 364| Step: 0
Training loss: 0.13416875898838043
Validation loss: 1.6532114167367258

Epoch: 6| Step: 1
Training loss: 0.11107821762561798
Validation loss: 1.6578420990256852

Epoch: 6| Step: 2
Training loss: 0.08561108261346817
Validation loss: 1.6382438367412937

Epoch: 6| Step: 3
Training loss: 0.1304507851600647
Validation loss: 1.6485249086092877

Epoch: 6| Step: 4
Training loss: 0.1518341302871704
Validation loss: 1.6226306371791388

Epoch: 6| Step: 5
Training loss: 0.08028006553649902
Validation loss: 1.6198075817477318

Epoch: 6| Step: 6
Training loss: 0.06761600077152252
Validation loss: 1.6202547819383684

Epoch: 6| Step: 7
Training loss: 0.12454909831285477
Validation loss: 1.6197659520692722

Epoch: 6| Step: 8
Training loss: 0.07504377514123917
Validation loss: 1.6033362880829842

Epoch: 6| Step: 9
Training loss: 0.08874146640300751
Validation loss: 1.6289458992660686

Epoch: 6| Step: 10
Training loss: 0.3741494417190552
Validation loss: 1.6383639445868872

Epoch: 6| Step: 11
Training loss: 0.14151017367839813
Validation loss: 1.647114904977942

Epoch: 6| Step: 12
Training loss: 0.14345113933086395
Validation loss: 1.6294600066318308

Epoch: 6| Step: 13
Training loss: 0.14040625095367432
Validation loss: 1.6533577903624503

Epoch: 365| Step: 0
Training loss: 0.17436610162258148
Validation loss: 1.6567921048851424

Epoch: 6| Step: 1
Training loss: 0.09903734922409058
Validation loss: 1.6346186873733357

Epoch: 6| Step: 2
Training loss: 0.1678500473499298
Validation loss: 1.6270855934389177

Epoch: 6| Step: 3
Training loss: 0.14558956027030945
Validation loss: 1.6276814065953737

Epoch: 6| Step: 4
Training loss: 0.17365670204162598
Validation loss: 1.613548049362757

Epoch: 6| Step: 5
Training loss: 0.23567768931388855
Validation loss: 1.6098511962480442

Epoch: 6| Step: 6
Training loss: 0.18793366849422455
Validation loss: 1.6452521521558043

Epoch: 6| Step: 7
Training loss: 0.08947304636240005
Validation loss: 1.6129788673052223

Epoch: 6| Step: 8
Training loss: 0.11232060194015503
Validation loss: 1.6191665959614578

Epoch: 6| Step: 9
Training loss: 0.3243533670902252
Validation loss: 1.6533640917911325

Epoch: 6| Step: 10
Training loss: 0.14396777749061584
Validation loss: 1.6491919006070783

Epoch: 6| Step: 11
Training loss: 0.11742815375328064
Validation loss: 1.6614634888146513

Epoch: 6| Step: 12
Training loss: 0.20510371029376984
Validation loss: 1.6817751212786602

Epoch: 6| Step: 13
Training loss: 0.19504886865615845
Validation loss: 1.6896591596705939

Epoch: 366| Step: 0
Training loss: 0.22372041642665863
Validation loss: 1.721582314019562

Epoch: 6| Step: 1
Training loss: 0.16311746835708618
Validation loss: 1.6884844918404855

Epoch: 6| Step: 2
Training loss: 0.3065626919269562
Validation loss: 1.6840285895973124

Epoch: 6| Step: 3
Training loss: 0.14409562945365906
Validation loss: 1.667776778180112

Epoch: 6| Step: 4
Training loss: 0.11311298608779907
Validation loss: 1.684861913804085

Epoch: 6| Step: 5
Training loss: 0.14797985553741455
Validation loss: 1.6525805342581965

Epoch: 6| Step: 6
Training loss: 0.22408810257911682
Validation loss: 1.6537303745105703

Epoch: 6| Step: 7
Training loss: 0.13014885783195496
Validation loss: 1.6079791559967944

Epoch: 6| Step: 8
Training loss: 0.24891117215156555
Validation loss: 1.5916572540037093

Epoch: 6| Step: 9
Training loss: 0.1515188217163086
Validation loss: 1.5699419065188336

Epoch: 6| Step: 10
Training loss: 0.22752434015274048
Validation loss: 1.60331420488255

Epoch: 6| Step: 11
Training loss: 0.0993209034204483
Validation loss: 1.5998178015473068

Epoch: 6| Step: 12
Training loss: 0.12021856009960175
Validation loss: 1.6419326066970825

Epoch: 6| Step: 13
Training loss: 0.1323443055152893
Validation loss: 1.6385530823020524

Epoch: 367| Step: 0
Training loss: 0.3630655109882355
Validation loss: 1.6526788652584117

Epoch: 6| Step: 1
Training loss: 0.2628799378871918
Validation loss: 1.681845167631744

Epoch: 6| Step: 2
Training loss: 0.1401388794183731
Validation loss: 1.6778402149036367

Epoch: 6| Step: 3
Training loss: 0.13093647360801697
Validation loss: 1.6651326834514577

Epoch: 6| Step: 4
Training loss: 0.08312501013278961
Validation loss: 1.675918561156078

Epoch: 6| Step: 5
Training loss: 0.13622227311134338
Validation loss: 1.6324426397200553

Epoch: 6| Step: 6
Training loss: 0.10337810963392258
Validation loss: 1.6234755964689358

Epoch: 6| Step: 7
Training loss: 0.12897369265556335
Validation loss: 1.6189940514103058

Epoch: 6| Step: 8
Training loss: 0.12600509822368622
Validation loss: 1.61176638449392

Epoch: 6| Step: 9
Training loss: 0.1451210379600525
Validation loss: 1.6201641642919151

Epoch: 6| Step: 10
Training loss: 0.1509970873594284
Validation loss: 1.6484522678518807

Epoch: 6| Step: 11
Training loss: 0.14903517067432404
Validation loss: 1.6321271247761224

Epoch: 6| Step: 12
Training loss: 0.22960010170936584
Validation loss: 1.673489555235832

Epoch: 6| Step: 13
Training loss: 0.1383066624403
Validation loss: 1.661761377447395

Epoch: 368| Step: 0
Training loss: 0.13218164443969727
Validation loss: 1.6896297700943486

Epoch: 6| Step: 1
Training loss: 0.11844614893198013
Validation loss: 1.683946483237769

Epoch: 6| Step: 2
Training loss: 0.16060735285282135
Validation loss: 1.6687884151294667

Epoch: 6| Step: 3
Training loss: 0.06170601397752762
Validation loss: 1.649021153808922

Epoch: 6| Step: 4
Training loss: 0.15143519639968872
Validation loss: 1.6512397912240797

Epoch: 6| Step: 5
Training loss: 0.10076560080051422
Validation loss: 1.6162644509346253

Epoch: 6| Step: 6
Training loss: 0.13659346103668213
Validation loss: 1.6041811948181481

Epoch: 6| Step: 7
Training loss: 0.07597120106220245
Validation loss: 1.603241870480199

Epoch: 6| Step: 8
Training loss: 0.15188190340995789
Validation loss: 1.5898770363100114

Epoch: 6| Step: 9
Training loss: 0.1592983901500702
Validation loss: 1.5821074926724998

Epoch: 6| Step: 10
Training loss: 0.09869742393493652
Validation loss: 1.5890592061063296

Epoch: 6| Step: 11
Training loss: 0.08858384937047958
Validation loss: 1.6082149705579203

Epoch: 6| Step: 12
Training loss: 0.35539907217025757
Validation loss: 1.5927929570597987

Epoch: 6| Step: 13
Training loss: 0.10861293226480484
Validation loss: 1.6550602835993613

Epoch: 369| Step: 0
Training loss: 0.17255333065986633
Validation loss: 1.6498707225245814

Epoch: 6| Step: 1
Training loss: 0.1354273557662964
Validation loss: 1.652043802763826

Epoch: 6| Step: 2
Training loss: 0.20174583792686462
Validation loss: 1.6545690695444744

Epoch: 6| Step: 3
Training loss: 0.176716148853302
Validation loss: 1.6335371655802573

Epoch: 6| Step: 4
Training loss: 0.13730232417583466
Validation loss: 1.6558990196515155

Epoch: 6| Step: 5
Training loss: 0.0770040825009346
Validation loss: 1.6615762646480272

Epoch: 6| Step: 6
Training loss: 0.14001378417015076
Validation loss: 1.6555911520475983

Epoch: 6| Step: 7
Training loss: 0.06471940129995346
Validation loss: 1.6703312012457079

Epoch: 6| Step: 8
Training loss: 0.169343039393425
Validation loss: 1.6812079619335871

Epoch: 6| Step: 9
Training loss: 0.14454828202724457
Validation loss: 1.6768279306350216

Epoch: 6| Step: 10
Training loss: 0.33162251114845276
Validation loss: 1.6656674197925034

Epoch: 6| Step: 11
Training loss: 0.13054494559764862
Validation loss: 1.6842874955105525

Epoch: 6| Step: 12
Training loss: 0.11819544434547424
Validation loss: 1.6785734225344915

Epoch: 6| Step: 13
Training loss: 0.1342434287071228
Validation loss: 1.676146081698838

Epoch: 370| Step: 0
Training loss: 0.07751642912626266
Validation loss: 1.6599389007014613

Epoch: 6| Step: 1
Training loss: 0.1781436800956726
Validation loss: 1.6806843588429112

Epoch: 6| Step: 2
Training loss: 0.21819597482681274
Validation loss: 1.6375411889886344

Epoch: 6| Step: 3
Training loss: 0.3317115008831024
Validation loss: 1.639184332663013

Epoch: 6| Step: 4
Training loss: 0.14080950617790222
Validation loss: 1.6082303818836008

Epoch: 6| Step: 5
Training loss: 0.1391971856355667
Validation loss: 1.6129666964213054

Epoch: 6| Step: 6
Training loss: 0.15002980828285217
Validation loss: 1.5775118168964182

Epoch: 6| Step: 7
Training loss: 0.07200551778078079
Validation loss: 1.572130057119554

Epoch: 6| Step: 8
Training loss: 0.16084244847297668
Validation loss: 1.5922490396807272

Epoch: 6| Step: 9
Training loss: 0.10139593482017517
Validation loss: 1.589907201387549

Epoch: 6| Step: 10
Training loss: 0.17430633306503296
Validation loss: 1.6119686903492096

Epoch: 6| Step: 11
Training loss: 0.13161322474479675
Validation loss: 1.6087790509705902

Epoch: 6| Step: 12
Training loss: 0.10790188610553741
Validation loss: 1.6305460083869197

Epoch: 6| Step: 13
Training loss: 0.1493569165468216
Validation loss: 1.6453488719078802

Epoch: 371| Step: 0
Training loss: 0.1555919200181961
Validation loss: 1.642182824432209

Epoch: 6| Step: 1
Training loss: 0.07601650804281235
Validation loss: 1.6687771633107176

Epoch: 6| Step: 2
Training loss: 0.0724363625049591
Validation loss: 1.657688976615988

Epoch: 6| Step: 3
Training loss: 0.21913671493530273
Validation loss: 1.6696535028437132

Epoch: 6| Step: 4
Training loss: 0.10731567442417145
Validation loss: 1.6784586137340916

Epoch: 6| Step: 5
Training loss: 0.09235543012619019
Validation loss: 1.6368263254883468

Epoch: 6| Step: 6
Training loss: 0.08914486318826675
Validation loss: 1.6300363591922227

Epoch: 6| Step: 7
Training loss: 0.40813422203063965
Validation loss: 1.601961317882743

Epoch: 6| Step: 8
Training loss: 0.11652716994285583
Validation loss: 1.5674353671330277

Epoch: 6| Step: 9
Training loss: 0.15044862031936646
Validation loss: 1.564192448892901

Epoch: 6| Step: 10
Training loss: 0.19428750872612
Validation loss: 1.5141722489428777

Epoch: 6| Step: 11
Training loss: 0.16703614592552185
Validation loss: 1.5289189994976085

Epoch: 6| Step: 12
Training loss: 0.1479521244764328
Validation loss: 1.5172498354347803

Epoch: 6| Step: 13
Training loss: 0.16977109014987946
Validation loss: 1.5511673676070346

Epoch: 372| Step: 0
Training loss: 0.09543853998184204
Validation loss: 1.5593466995864786

Epoch: 6| Step: 1
Training loss: 0.17927534878253937
Validation loss: 1.5747642158180155

Epoch: 6| Step: 2
Training loss: 0.2215437889099121
Validation loss: 1.6213368818324099

Epoch: 6| Step: 3
Training loss: 0.08925357460975647
Validation loss: 1.6392713131443146

Epoch: 6| Step: 4
Training loss: 0.09609049558639526
Validation loss: 1.6442568558518604

Epoch: 6| Step: 5
Training loss: 0.09516346454620361
Validation loss: 1.6717042743518788

Epoch: 6| Step: 6
Training loss: 0.31144461035728455
Validation loss: 1.6848153414264802

Epoch: 6| Step: 7
Training loss: 0.1548740267753601
Validation loss: 1.69302103980895

Epoch: 6| Step: 8
Training loss: 0.24910342693328857
Validation loss: 1.7176381106017737

Epoch: 6| Step: 9
Training loss: 0.23241201043128967
Validation loss: 1.7062897989826817

Epoch: 6| Step: 10
Training loss: 0.22751069068908691
Validation loss: 1.6908275722175516

Epoch: 6| Step: 11
Training loss: 0.11572688817977905
Validation loss: 1.6568034361767512

Epoch: 6| Step: 12
Training loss: 0.15599209070205688
Validation loss: 1.638078457565718

Epoch: 6| Step: 13
Training loss: 0.1223115399479866
Validation loss: 1.6055182667188748

Epoch: 373| Step: 0
Training loss: 0.12600597739219666
Validation loss: 1.629944585984753

Epoch: 6| Step: 1
Training loss: 0.16070571541786194
Validation loss: 1.6079508982678896

Epoch: 6| Step: 2
Training loss: 0.14727047085762024
Validation loss: 1.6187187945970924

Epoch: 6| Step: 3
Training loss: 0.16164156794548035
Validation loss: 1.6527393928138159

Epoch: 6| Step: 4
Training loss: 0.14807593822479248
Validation loss: 1.6302853694526098

Epoch: 6| Step: 5
Training loss: 0.1384970247745514
Validation loss: 1.6434290332178916

Epoch: 6| Step: 6
Training loss: 0.1253463625907898
Validation loss: 1.6631777901803293

Epoch: 6| Step: 7
Training loss: 0.20937232673168182
Validation loss: 1.647942135410924

Epoch: 6| Step: 8
Training loss: 0.11091563105583191
Validation loss: 1.6772238977493779

Epoch: 6| Step: 9
Training loss: 0.2153976857662201
Validation loss: 1.7176576711798226

Epoch: 6| Step: 10
Training loss: 0.3489450216293335
Validation loss: 1.71290321055279

Epoch: 6| Step: 11
Training loss: 0.18575279414653778
Validation loss: 1.7041011061719669

Epoch: 6| Step: 12
Training loss: 0.2047690898180008
Validation loss: 1.676503498067138

Epoch: 6| Step: 13
Training loss: 0.1512986123561859
Validation loss: 1.6727057144206057

Epoch: 374| Step: 0
Training loss: 0.12119543552398682
Validation loss: 1.646698373620228

Epoch: 6| Step: 1
Training loss: 0.3212926387786865
Validation loss: 1.655022213535924

Epoch: 6| Step: 2
Training loss: 0.16062873601913452
Validation loss: 1.6625200779207292

Epoch: 6| Step: 3
Training loss: 0.12740376591682434
Validation loss: 1.6836119390303088

Epoch: 6| Step: 4
Training loss: 0.1649213433265686
Validation loss: 1.6511098787348757

Epoch: 6| Step: 5
Training loss: 0.1278124451637268
Validation loss: 1.6619720202620312

Epoch: 6| Step: 6
Training loss: 0.17280152440071106
Validation loss: 1.6719957756739792

Epoch: 6| Step: 7
Training loss: 0.14303144812583923
Validation loss: 1.6795444719253048

Epoch: 6| Step: 8
Training loss: 0.13020113110542297
Validation loss: 1.6736693177171933

Epoch: 6| Step: 9
Training loss: 0.1210230365395546
Validation loss: 1.7035476725588563

Epoch: 6| Step: 10
Training loss: 0.12641958892345428
Validation loss: 1.6957677474585913

Epoch: 6| Step: 11
Training loss: 0.20601704716682434
Validation loss: 1.7210332328273403

Epoch: 6| Step: 12
Training loss: 0.1029842421412468
Validation loss: 1.7176405217057915

Epoch: 6| Step: 13
Training loss: 0.08956846594810486
Validation loss: 1.7362267099401003

Epoch: 375| Step: 0
Training loss: 0.13857346773147583
Validation loss: 1.7266647943886377

Epoch: 6| Step: 1
Training loss: 0.07593333721160889
Validation loss: 1.7207266156391432

Epoch: 6| Step: 2
Training loss: 0.14152011275291443
Validation loss: 1.6977086977292133

Epoch: 6| Step: 3
Training loss: 0.0841776579618454
Validation loss: 1.7071838917270783

Epoch: 6| Step: 4
Training loss: 0.19483119249343872
Validation loss: 1.6749277153322775

Epoch: 6| Step: 5
Training loss: 0.1444999873638153
Validation loss: 1.6774490033426592

Epoch: 6| Step: 6
Training loss: 0.13475537300109863
Validation loss: 1.6765546439796366

Epoch: 6| Step: 7
Training loss: 0.1382921189069748
Validation loss: 1.6398969824596117

Epoch: 6| Step: 8
Training loss: 0.1029592901468277
Validation loss: 1.6257315886917936

Epoch: 6| Step: 9
Training loss: 0.37259340286254883
Validation loss: 1.5945579287826375

Epoch: 6| Step: 10
Training loss: 0.09954160451889038
Validation loss: 1.604145981932199

Epoch: 6| Step: 11
Training loss: 0.10170653462409973
Validation loss: 1.6102134207243561

Epoch: 6| Step: 12
Training loss: 0.1408301144838333
Validation loss: 1.632245611119014

Epoch: 6| Step: 13
Training loss: 0.21662099659442902
Validation loss: 1.6134053250794769

Epoch: 376| Step: 0
Training loss: 0.12424121052026749
Validation loss: 1.631134348530923

Epoch: 6| Step: 1
Training loss: 0.10532137751579285
Validation loss: 1.614234742297921

Epoch: 6| Step: 2
Training loss: 0.13577859103679657
Validation loss: 1.642733561095371

Epoch: 6| Step: 3
Training loss: 0.19722944498062134
Validation loss: 1.6597273824035481

Epoch: 6| Step: 4
Training loss: 0.3122025728225708
Validation loss: 1.6645811424460462

Epoch: 6| Step: 5
Training loss: 0.1728380024433136
Validation loss: 1.6669093581937975

Epoch: 6| Step: 6
Training loss: 0.13806259632110596
Validation loss: 1.6394510320437852

Epoch: 6| Step: 7
Training loss: 0.10539153218269348
Validation loss: 1.6701528173620983

Epoch: 6| Step: 8
Training loss: 0.1451866775751114
Validation loss: 1.6421052076483285

Epoch: 6| Step: 9
Training loss: 0.1870308518409729
Validation loss: 1.6406524694094093

Epoch: 6| Step: 10
Training loss: 0.14047649502754211
Validation loss: 1.6088176017166467

Epoch: 6| Step: 11
Training loss: 0.11763426661491394
Validation loss: 1.5748927054866668

Epoch: 6| Step: 12
Training loss: 0.11542603373527527
Validation loss: 1.582068044652221

Epoch: 6| Step: 13
Training loss: 0.12680046260356903
Validation loss: 1.5769036252011535

Epoch: 377| Step: 0
Training loss: 0.14582371711730957
Validation loss: 1.593062654618294

Epoch: 6| Step: 1
Training loss: 0.19046588242053986
Validation loss: 1.5927744116834415

Epoch: 6| Step: 2
Training loss: 0.18893271684646606
Validation loss: 1.6194043338939708

Epoch: 6| Step: 3
Training loss: 0.16048482060432434
Validation loss: 1.624044538826071

Epoch: 6| Step: 4
Training loss: 0.3015548586845398
Validation loss: 1.6260233361233947

Epoch: 6| Step: 5
Training loss: 0.07463698834180832
Validation loss: 1.6675367739892775

Epoch: 6| Step: 6
Training loss: 0.11493679136037827
Validation loss: 1.6565201705501926

Epoch: 6| Step: 7
Training loss: 0.1317923367023468
Validation loss: 1.6679319867523767

Epoch: 6| Step: 8
Training loss: 0.17043228447437286
Validation loss: 1.6760842338685067

Epoch: 6| Step: 9
Training loss: 0.14550724625587463
Validation loss: 1.6684436003367107

Epoch: 6| Step: 10
Training loss: 0.10034749656915665
Validation loss: 1.6701775853351881

Epoch: 6| Step: 11
Training loss: 0.08826819062232971
Validation loss: 1.6891760903020059

Epoch: 6| Step: 12
Training loss: 0.12573525309562683
Validation loss: 1.6776629468446136

Epoch: 6| Step: 13
Training loss: 0.10960817337036133
Validation loss: 1.6461877938239806

Epoch: 378| Step: 0
Training loss: 0.07207442820072174
Validation loss: 1.6570796569188435

Epoch: 6| Step: 1
Training loss: 0.11888584494590759
Validation loss: 1.6357064234313143

Epoch: 6| Step: 2
Training loss: 0.2882530391216278
Validation loss: 1.6169317473647415

Epoch: 6| Step: 3
Training loss: 0.13905812799930573
Validation loss: 1.6577090524858045

Epoch: 6| Step: 4
Training loss: 0.18239928781986237
Validation loss: 1.6212418066558016

Epoch: 6| Step: 5
Training loss: 0.12484385818243027
Validation loss: 1.6029004473840036

Epoch: 6| Step: 6
Training loss: 0.07692085206508636
Validation loss: 1.6099424682637697

Epoch: 6| Step: 7
Training loss: 0.10579223185777664
Validation loss: 1.5929129790234309

Epoch: 6| Step: 8
Training loss: 0.10180962085723877
Validation loss: 1.6184976152194444

Epoch: 6| Step: 9
Training loss: 0.09570472687482834
Validation loss: 1.6155985356659017

Epoch: 6| Step: 10
Training loss: 0.11466047912836075
Validation loss: 1.6336115611496793

Epoch: 6| Step: 11
Training loss: 0.1432109773159027
Validation loss: 1.6270739199012838

Epoch: 6| Step: 12
Training loss: 0.15811485052108765
Validation loss: 1.6561132707903463

Epoch: 6| Step: 13
Training loss: 0.10619649291038513
Validation loss: 1.6274973359159244

Epoch: 379| Step: 0
Training loss: 0.06574010848999023
Validation loss: 1.63537504852459

Epoch: 6| Step: 1
Training loss: 0.3363756239414215
Validation loss: 1.6214691131345687

Epoch: 6| Step: 2
Training loss: 0.12282491475343704
Validation loss: 1.6584909885160384

Epoch: 6| Step: 3
Training loss: 0.12127387523651123
Validation loss: 1.6510467580569688

Epoch: 6| Step: 4
Training loss: 0.16113650798797607
Validation loss: 1.6181238005238194

Epoch: 6| Step: 5
Training loss: 0.06488902121782303
Validation loss: 1.658148366917846

Epoch: 6| Step: 6
Training loss: 0.06603551656007767
Validation loss: 1.6485844286539222

Epoch: 6| Step: 7
Training loss: 0.11451767385005951
Validation loss: 1.670413762010554

Epoch: 6| Step: 8
Training loss: 0.10971442610025406
Validation loss: 1.665429340895786

Epoch: 6| Step: 9
Training loss: 0.10621348023414612
Validation loss: 1.6618798522539036

Epoch: 6| Step: 10
Training loss: 0.13524234294891357
Validation loss: 1.6476962451011903

Epoch: 6| Step: 11
Training loss: 0.17074088752269745
Validation loss: 1.636041170807295

Epoch: 6| Step: 12
Training loss: 0.11189636588096619
Validation loss: 1.6578598791553127

Epoch: 6| Step: 13
Training loss: 0.23777365684509277
Validation loss: 1.6289882147183983

Epoch: 380| Step: 0
Training loss: 0.11259987950325012
Validation loss: 1.6631554890704412

Epoch: 6| Step: 1
Training loss: 0.2700832188129425
Validation loss: 1.6268491411721835

Epoch: 6| Step: 2
Training loss: 0.08455289900302887
Validation loss: 1.6543649793953024

Epoch: 6| Step: 3
Training loss: 0.13502822816371918
Validation loss: 1.6501081707657024

Epoch: 6| Step: 4
Training loss: 0.07869232445955276
Validation loss: 1.6534030322105653

Epoch: 6| Step: 5
Training loss: 0.12225905060768127
Validation loss: 1.659172281142204

Epoch: 6| Step: 6
Training loss: 0.17137104272842407
Validation loss: 1.6721337046674503

Epoch: 6| Step: 7
Training loss: 0.15895701944828033
Validation loss: 1.6663317911086544

Epoch: 6| Step: 8
Training loss: 0.1033509373664856
Validation loss: 1.6846163824040403

Epoch: 6| Step: 9
Training loss: 0.16533854603767395
Validation loss: 1.6770812132025277

Epoch: 6| Step: 10
Training loss: 0.14167797565460205
Validation loss: 1.6540447614526237

Epoch: 6| Step: 11
Training loss: 0.13906073570251465
Validation loss: 1.642586459395706

Epoch: 6| Step: 12
Training loss: 0.0821654200553894
Validation loss: 1.6470674622443415

Epoch: 6| Step: 13
Training loss: 0.08206801861524582
Validation loss: 1.6326808775624921

Epoch: 381| Step: 0
Training loss: 0.10116152465343475
Validation loss: 1.6455541887590963

Epoch: 6| Step: 1
Training loss: 0.11272133886814117
Validation loss: 1.6396984387469549

Epoch: 6| Step: 2
Training loss: 0.3723410665988922
Validation loss: 1.632702608262339

Epoch: 6| Step: 3
Training loss: 0.08913721889257431
Validation loss: 1.630070447921753

Epoch: 6| Step: 4
Training loss: 0.10314831137657166
Validation loss: 1.627915277275988

Epoch: 6| Step: 5
Training loss: 0.11232244223356247
Validation loss: 1.605985628661289

Epoch: 6| Step: 6
Training loss: 0.09562161564826965
Validation loss: 1.6071799967878608

Epoch: 6| Step: 7
Training loss: 0.07660230994224548
Validation loss: 1.6171971341615081

Epoch: 6| Step: 8
Training loss: 0.10314877331256866
Validation loss: 1.6079748651032806

Epoch: 6| Step: 9
Training loss: 0.1350601762533188
Validation loss: 1.6026486222461989

Epoch: 6| Step: 10
Training loss: 0.18099793791770935
Validation loss: 1.6278016772321475

Epoch: 6| Step: 11
Training loss: 0.12053282558917999
Validation loss: 1.6510198782849055

Epoch: 6| Step: 12
Training loss: 0.11800264567136765
Validation loss: 1.633778118318127

Epoch: 6| Step: 13
Training loss: 0.1333085149526596
Validation loss: 1.6721800168355305

Epoch: 382| Step: 0
Training loss: 0.16451391577720642
Validation loss: 1.7087828907915341

Epoch: 6| Step: 1
Training loss: 0.360034704208374
Validation loss: 1.6904317396943287

Epoch: 6| Step: 2
Training loss: 0.147426038980484
Validation loss: 1.6463086117980301

Epoch: 6| Step: 3
Training loss: 0.10797470062971115
Validation loss: 1.6609060456675868

Epoch: 6| Step: 4
Training loss: 0.05348765105009079
Validation loss: 1.6450313598878923

Epoch: 6| Step: 5
Training loss: 0.0685839131474495
Validation loss: 1.6491535902023315

Epoch: 6| Step: 6
Training loss: 0.0829688087105751
Validation loss: 1.6424820153943953

Epoch: 6| Step: 7
Training loss: 0.12683410942554474
Validation loss: 1.6373670562621085

Epoch: 6| Step: 8
Training loss: 0.2345733493566513
Validation loss: 1.6135466758922865

Epoch: 6| Step: 9
Training loss: 0.09402962028980255
Validation loss: 1.6134297386292489

Epoch: 6| Step: 10
Training loss: 0.08579759299755096
Validation loss: 1.6222653158249394

Epoch: 6| Step: 11
Training loss: 0.14356859028339386
Validation loss: 1.6286939023643412

Epoch: 6| Step: 12
Training loss: 0.130523219704628
Validation loss: 1.6235165032007361

Epoch: 6| Step: 13
Training loss: 0.10325465351343155
Validation loss: 1.6450139296952115

Epoch: 383| Step: 0
Training loss: 0.1300705373287201
Validation loss: 1.6225561070185837

Epoch: 6| Step: 1
Training loss: 0.09484246373176575
Validation loss: 1.6554164078927809

Epoch: 6| Step: 2
Training loss: 0.2128172516822815
Validation loss: 1.669864546868109

Epoch: 6| Step: 3
Training loss: 0.09411773085594177
Validation loss: 1.7067158004289031

Epoch: 6| Step: 4
Training loss: 0.2329132854938507
Validation loss: 1.6947063534490523

Epoch: 6| Step: 5
Training loss: 0.28073689341545105
Validation loss: 1.7303945172217585

Epoch: 6| Step: 6
Training loss: 0.13163705170154572
Validation loss: 1.6726190082488521

Epoch: 6| Step: 7
Training loss: 0.2566470205783844
Validation loss: 1.6556036574866182

Epoch: 6| Step: 8
Training loss: 0.12206430733203888
Validation loss: 1.6386912522777435

Epoch: 6| Step: 9
Training loss: 0.10263004899024963
Validation loss: 1.6262919454164402

Epoch: 6| Step: 10
Training loss: 0.14177417755126953
Validation loss: 1.6080103048714258

Epoch: 6| Step: 11
Training loss: 0.11955878883600235
Validation loss: 1.6040222952442784

Epoch: 6| Step: 12
Training loss: 0.14120075106620789
Validation loss: 1.6145680719806301

Epoch: 6| Step: 13
Training loss: 0.2777654230594635
Validation loss: 1.6288000140138852

Epoch: 384| Step: 0
Training loss: 0.12160711735486984
Validation loss: 1.6227177381515503

Epoch: 6| Step: 1
Training loss: 0.1979282945394516
Validation loss: 1.6181570035155102

Epoch: 6| Step: 2
Training loss: 0.07379607856273651
Validation loss: 1.6112522796917987

Epoch: 6| Step: 3
Training loss: 0.06639730930328369
Validation loss: 1.642718804779873

Epoch: 6| Step: 4
Training loss: 0.07397087663412094
Validation loss: 1.6181319900738296

Epoch: 6| Step: 5
Training loss: 0.08778038620948792
Validation loss: 1.6556768481449415

Epoch: 6| Step: 6
Training loss: 0.286944180727005
Validation loss: 1.6204635891863095

Epoch: 6| Step: 7
Training loss: 0.13736838102340698
Validation loss: 1.6148973921293854

Epoch: 6| Step: 8
Training loss: 0.1592937409877777
Validation loss: 1.6349819155149563

Epoch: 6| Step: 9
Training loss: 0.12249062210321426
Validation loss: 1.6502731461678781

Epoch: 6| Step: 10
Training loss: 0.10050094127655029
Validation loss: 1.6042063736146497

Epoch: 6| Step: 11
Training loss: 0.11239791661500931
Validation loss: 1.6245907545089722

Epoch: 6| Step: 12
Training loss: 0.11222989112138748
Validation loss: 1.6159083509957919

Epoch: 6| Step: 13
Training loss: 0.1132076159119606
Validation loss: 1.6148278854226554

Epoch: 385| Step: 0
Training loss: 0.1649026870727539
Validation loss: 1.5959210767540881

Epoch: 6| Step: 1
Training loss: 0.1319517344236374
Validation loss: 1.579276786055616

Epoch: 6| Step: 2
Training loss: 0.12214069068431854
Validation loss: 1.5814414049989434

Epoch: 6| Step: 3
Training loss: 0.11481645703315735
Validation loss: 1.5741631869346864

Epoch: 6| Step: 4
Training loss: 0.10598189383745193
Validation loss: 1.564800807224807

Epoch: 6| Step: 5
Training loss: 0.10393524169921875
Validation loss: 1.56947720948086

Epoch: 6| Step: 6
Training loss: 0.17245763540267944
Validation loss: 1.5622871953953978

Epoch: 6| Step: 7
Training loss: 0.1775696575641632
Validation loss: 1.5796209772427876

Epoch: 6| Step: 8
Training loss: 0.10329702496528625
Validation loss: 1.5771407824690624

Epoch: 6| Step: 9
Training loss: 0.3119463324546814
Validation loss: 1.5932547046292214

Epoch: 6| Step: 10
Training loss: 0.12387262284755707
Validation loss: 1.596729297791758

Epoch: 6| Step: 11
Training loss: 0.16962304711341858
Validation loss: 1.593770077151637

Epoch: 6| Step: 12
Training loss: 0.09960196167230606
Validation loss: 1.6378680403514574

Epoch: 6| Step: 13
Training loss: 0.05231308937072754
Validation loss: 1.593405012161501

Epoch: 386| Step: 0
Training loss: 0.09574049711227417
Validation loss: 1.6052576341936666

Epoch: 6| Step: 1
Training loss: 0.09008260071277618
Validation loss: 1.6263483339740383

Epoch: 6| Step: 2
Training loss: 0.11245618760585785
Validation loss: 1.615271404225339

Epoch: 6| Step: 3
Training loss: 0.11027909070253372
Validation loss: 1.6021731335629699

Epoch: 6| Step: 4
Training loss: 0.3265495300292969
Validation loss: 1.5900481695769935

Epoch: 6| Step: 5
Training loss: 0.10064788162708282
Validation loss: 1.6111703521461898

Epoch: 6| Step: 6
Training loss: 0.16339200735092163
Validation loss: 1.619901721195508

Epoch: 6| Step: 7
Training loss: 0.09627144038677216
Validation loss: 1.604100150446738

Epoch: 6| Step: 8
Training loss: 0.09315086156129837
Validation loss: 1.6053831295300556

Epoch: 6| Step: 9
Training loss: 0.09106814861297607
Validation loss: 1.6045647718573128

Epoch: 6| Step: 10
Training loss: 0.09825584292411804
Validation loss: 1.6148422994921285

Epoch: 6| Step: 11
Training loss: 0.13592097163200378
Validation loss: 1.6188175921799035

Epoch: 6| Step: 12
Training loss: 0.12488071620464325
Validation loss: 1.6136096062198761

Epoch: 6| Step: 13
Training loss: 0.15676496922969818
Validation loss: 1.635933353054908

Epoch: 387| Step: 0
Training loss: 0.10712830722332001
Validation loss: 1.6406559149424236

Epoch: 6| Step: 1
Training loss: 0.10715984553098679
Validation loss: 1.645090695991311

Epoch: 6| Step: 2
Training loss: 0.07671327888965607
Validation loss: 1.652032909854766

Epoch: 6| Step: 3
Training loss: 0.15344488620758057
Validation loss: 1.6288835040984615

Epoch: 6| Step: 4
Training loss: 0.27367112040519714
Validation loss: 1.6560737138153405

Epoch: 6| Step: 5
Training loss: 0.07490652799606323
Validation loss: 1.6428543457420923

Epoch: 6| Step: 6
Training loss: 0.07476026564836502
Validation loss: 1.669789106615128

Epoch: 6| Step: 7
Training loss: 0.11058355867862701
Validation loss: 1.67115952122596

Epoch: 6| Step: 8
Training loss: 0.09904994070529938
Validation loss: 1.6525070987721926

Epoch: 6| Step: 9
Training loss: 0.053822290152311325
Validation loss: 1.6468466430582025

Epoch: 6| Step: 10
Training loss: 0.10472561419010162
Validation loss: 1.624049038015386

Epoch: 6| Step: 11
Training loss: 0.10281107574701309
Validation loss: 1.6173715463248632

Epoch: 6| Step: 12
Training loss: 0.1371549665927887
Validation loss: 1.6430878587948379

Epoch: 6| Step: 13
Training loss: 0.11135142296552658
Validation loss: 1.6382741633281912

Epoch: 388| Step: 0
Training loss: 0.31100502610206604
Validation loss: 1.5989633529416976

Epoch: 6| Step: 1
Training loss: 0.07572071999311447
Validation loss: 1.6235248478510047

Epoch: 6| Step: 2
Training loss: 0.137764573097229
Validation loss: 1.663088470376948

Epoch: 6| Step: 3
Training loss: 0.10376196354627609
Validation loss: 1.6342494257034794

Epoch: 6| Step: 4
Training loss: 0.057919733226299286
Validation loss: 1.6316322998334003

Epoch: 6| Step: 5
Training loss: 0.09941177815198898
Validation loss: 1.6446479097489388

Epoch: 6| Step: 6
Training loss: 0.11785323172807693
Validation loss: 1.6259201995788082

Epoch: 6| Step: 7
Training loss: 0.13202153146266937
Validation loss: 1.642955075028122

Epoch: 6| Step: 8
Training loss: 0.17937850952148438
Validation loss: 1.6580054913797686

Epoch: 6| Step: 9
Training loss: 0.11180520057678223
Validation loss: 1.6502181829944733

Epoch: 6| Step: 10
Training loss: 0.09190316498279572
Validation loss: 1.6114936208212247

Epoch: 6| Step: 11
Training loss: 0.14668184518814087
Validation loss: 1.5949118983361028

Epoch: 6| Step: 12
Training loss: 0.10721684992313385
Validation loss: 1.577500541363993

Epoch: 6| Step: 13
Training loss: 0.0663226842880249
Validation loss: 1.5714764530940721

Epoch: 389| Step: 0
Training loss: 0.0695018321275711
Validation loss: 1.5947520720061434

Epoch: 6| Step: 1
Training loss: 0.11350367218255997
Validation loss: 1.5825359552137312

Epoch: 6| Step: 2
Training loss: 0.16083203256130219
Validation loss: 1.5826135707157913

Epoch: 6| Step: 3
Training loss: 0.06049298495054245
Validation loss: 1.580033907326319

Epoch: 6| Step: 4
Training loss: 0.06397588551044464
Validation loss: 1.593855183611634

Epoch: 6| Step: 5
Training loss: 0.08883709460496902
Validation loss: 1.6228307370216615

Epoch: 6| Step: 6
Training loss: 0.11207680404186249
Validation loss: 1.62804760215103

Epoch: 6| Step: 7
Training loss: 0.27023255825042725
Validation loss: 1.6404055062160696

Epoch: 6| Step: 8
Training loss: 0.08973541855812073
Validation loss: 1.6198556782096944

Epoch: 6| Step: 9
Training loss: 0.11896277219057083
Validation loss: 1.656034315786054

Epoch: 6| Step: 10
Training loss: 0.06187145411968231
Validation loss: 1.6686492017520371

Epoch: 6| Step: 11
Training loss: 0.15047124028205872
Validation loss: 1.6527401580605456

Epoch: 6| Step: 12
Training loss: 0.08205897361040115
Validation loss: 1.6611467561414164

Epoch: 6| Step: 13
Training loss: 0.07250607758760452
Validation loss: 1.6714934508005779

Epoch: 390| Step: 0
Training loss: 0.1464952975511551
Validation loss: 1.6557739011702999

Epoch: 6| Step: 1
Training loss: 0.14460645616054535
Validation loss: 1.6532559100017752

Epoch: 6| Step: 2
Training loss: 0.07883650809526443
Validation loss: 1.6547497600637457

Epoch: 6| Step: 3
Training loss: 0.10898924618959427
Validation loss: 1.6330027887898106

Epoch: 6| Step: 4
Training loss: 0.12553660571575165
Validation loss: 1.6232996858576292

Epoch: 6| Step: 5
Training loss: 0.28526437282562256
Validation loss: 1.6210142297129477

Epoch: 6| Step: 6
Training loss: 0.10800935328006744
Validation loss: 1.6281984749660696

Epoch: 6| Step: 7
Training loss: 0.06633938103914261
Validation loss: 1.656287673980959

Epoch: 6| Step: 8
Training loss: 0.1128900870680809
Validation loss: 1.633642327400946

Epoch: 6| Step: 9
Training loss: 0.08651207387447357
Validation loss: 1.6418067934692546

Epoch: 6| Step: 10
Training loss: 0.1356847584247589
Validation loss: 1.6797931386578469

Epoch: 6| Step: 11
Training loss: 0.10438446700572968
Validation loss: 1.6708811495893745

Epoch: 6| Step: 12
Training loss: 0.10986697673797607
Validation loss: 1.6665210928968204

Epoch: 6| Step: 13
Training loss: 0.07025650888681412
Validation loss: 1.6458191064096266

Epoch: 391| Step: 0
Training loss: 0.08470238000154495
Validation loss: 1.651106111464962

Epoch: 6| Step: 1
Training loss: 0.10123291611671448
Validation loss: 1.6360571166520477

Epoch: 6| Step: 2
Training loss: 0.11625362932682037
Validation loss: 1.6214804431443572

Epoch: 6| Step: 3
Training loss: 0.07026542723178864
Validation loss: 1.616442971332099

Epoch: 6| Step: 4
Training loss: 0.10983163118362427
Validation loss: 1.6174067560062613

Epoch: 6| Step: 5
Training loss: 0.1725216954946518
Validation loss: 1.5967409636384697

Epoch: 6| Step: 6
Training loss: 0.10304683446884155
Validation loss: 1.5816145955875356

Epoch: 6| Step: 7
Training loss: 0.09656912833452225
Validation loss: 1.6082533521036948

Epoch: 6| Step: 8
Training loss: 0.1131291463971138
Validation loss: 1.5882965339127408

Epoch: 6| Step: 9
Training loss: 0.09012199938297272
Validation loss: 1.5952660165807253

Epoch: 6| Step: 10
Training loss: 0.09877409785985947
Validation loss: 1.5982975677777362

Epoch: 6| Step: 11
Training loss: 0.07255519926548004
Validation loss: 1.6103029135734803

Epoch: 6| Step: 12
Training loss: 0.3015516400337219
Validation loss: 1.6147524361969323

Epoch: 6| Step: 13
Training loss: 0.1232014000415802
Validation loss: 1.6298550610901208

Epoch: 392| Step: 0
Training loss: 0.11967181414365768
Validation loss: 1.6383427804516209

Epoch: 6| Step: 1
Training loss: 0.0754539966583252
Validation loss: 1.6472244237058906

Epoch: 6| Step: 2
Training loss: 0.11166545748710632
Validation loss: 1.6407825844262236

Epoch: 6| Step: 3
Training loss: 0.12199776619672775
Validation loss: 1.6511287522572342

Epoch: 6| Step: 4
Training loss: 0.08576639741659164
Validation loss: 1.6709261299461446

Epoch: 6| Step: 5
Training loss: 0.12213894724845886
Validation loss: 1.621907034227925

Epoch: 6| Step: 6
Training loss: 0.10197663307189941
Validation loss: 1.6712613515956427

Epoch: 6| Step: 7
Training loss: 0.13352042436599731
Validation loss: 1.639731627638622

Epoch: 6| Step: 8
Training loss: 0.10603928565979004
Validation loss: 1.5981364455274356

Epoch: 6| Step: 9
Training loss: 0.08315669745206833
Validation loss: 1.6121067898247832

Epoch: 6| Step: 10
Training loss: 0.16554829478263855
Validation loss: 1.6233886787968297

Epoch: 6| Step: 11
Training loss: 0.2893160581588745
Validation loss: 1.6126338403712037

Epoch: 6| Step: 12
Training loss: 0.1110026091337204
Validation loss: 1.6476100106393137

Epoch: 6| Step: 13
Training loss: 0.1433715522289276
Validation loss: 1.6528800674664077

Epoch: 393| Step: 0
Training loss: 0.2907094955444336
Validation loss: 1.6391188854812293

Epoch: 6| Step: 1
Training loss: 0.09786474704742432
Validation loss: 1.6460143032894339

Epoch: 6| Step: 2
Training loss: 0.05951453745365143
Validation loss: 1.6630979558472991

Epoch: 6| Step: 3
Training loss: 0.09208901226520538
Validation loss: 1.660782152606595

Epoch: 6| Step: 4
Training loss: 0.13413575291633606
Validation loss: 1.6459379285894415

Epoch: 6| Step: 5
Training loss: 0.08422781527042389
Validation loss: 1.6679075110343196

Epoch: 6| Step: 6
Training loss: 0.06087362766265869
Validation loss: 1.6671770708535307

Epoch: 6| Step: 7
Training loss: 0.058494627475738525
Validation loss: 1.6262661116097563

Epoch: 6| Step: 8
Training loss: 0.06993579864501953
Validation loss: 1.634237665002064

Epoch: 6| Step: 9
Training loss: 0.1507788896560669
Validation loss: 1.6058914007679108

Epoch: 6| Step: 10
Training loss: 0.13622653484344482
Validation loss: 1.623139250663019

Epoch: 6| Step: 11
Training loss: 0.13049671053886414
Validation loss: 1.5986161321722052

Epoch: 6| Step: 12
Training loss: 0.10668741166591644
Validation loss: 1.6141662828383907

Epoch: 6| Step: 13
Training loss: 0.10462453961372375
Validation loss: 1.613755520953927

Epoch: 394| Step: 0
Training loss: 0.07619825005531311
Validation loss: 1.6305484002636326

Epoch: 6| Step: 1
Training loss: 0.14320820569992065
Validation loss: 1.6348906755447388

Epoch: 6| Step: 2
Training loss: 0.16753500699996948
Validation loss: 1.6454915949093398

Epoch: 6| Step: 3
Training loss: 0.26767006516456604
Validation loss: 1.6720873104628695

Epoch: 6| Step: 4
Training loss: 0.09004539251327515
Validation loss: 1.640574033542346

Epoch: 6| Step: 5
Training loss: 0.08209474384784698
Validation loss: 1.6396991078571608

Epoch: 6| Step: 6
Training loss: 0.09366019070148468
Validation loss: 1.637274266571127

Epoch: 6| Step: 7
Training loss: 0.10222424566745758
Validation loss: 1.6343413591384888

Epoch: 6| Step: 8
Training loss: 0.06863854825496674
Validation loss: 1.6470603250688123

Epoch: 6| Step: 9
Training loss: 0.1398501992225647
Validation loss: 1.619769723184647

Epoch: 6| Step: 10
Training loss: 0.08822928369045258
Validation loss: 1.6484872423192507

Epoch: 6| Step: 11
Training loss: 0.11909268796443939
Validation loss: 1.6432910830743852

Epoch: 6| Step: 12
Training loss: 0.10215674340724945
Validation loss: 1.631069980641847

Epoch: 6| Step: 13
Training loss: 0.07934499531984329
Validation loss: 1.6676415064001595

Epoch: 395| Step: 0
Training loss: 0.07799320667982101
Validation loss: 1.6211088459978822

Epoch: 6| Step: 1
Training loss: 0.09585126489400864
Validation loss: 1.6443579812203684

Epoch: 6| Step: 2
Training loss: 0.26398131251335144
Validation loss: 1.636716377350592

Epoch: 6| Step: 3
Training loss: 0.07685351371765137
Validation loss: 1.6167663387072984

Epoch: 6| Step: 4
Training loss: 0.1000768169760704
Validation loss: 1.6222769368079402

Epoch: 6| Step: 5
Training loss: 0.10554655641317368
Validation loss: 1.6142021635527253

Epoch: 6| Step: 6
Training loss: 0.17214033007621765
Validation loss: 1.6067833644087597

Epoch: 6| Step: 7
Training loss: 0.06949345022439957
Validation loss: 1.5897678623917282

Epoch: 6| Step: 8
Training loss: 0.0755137950181961
Validation loss: 1.5827144570248102

Epoch: 6| Step: 9
Training loss: 0.12543287873268127
Validation loss: 1.59089994430542

Epoch: 6| Step: 10
Training loss: 0.09120316803455353
Validation loss: 1.5991265427681707

Epoch: 6| Step: 11
Training loss: 0.10725264251232147
Validation loss: 1.5969084334629837

Epoch: 6| Step: 12
Training loss: 0.1686432957649231
Validation loss: 1.626723244626035

Epoch: 6| Step: 13
Training loss: 0.12346541881561279
Validation loss: 1.6489078793474423

Epoch: 396| Step: 0
Training loss: 0.10721788555383682
Validation loss: 1.637156573675012

Epoch: 6| Step: 1
Training loss: 0.24715834856033325
Validation loss: 1.6361340040801673

Epoch: 6| Step: 2
Training loss: 0.10070188343524933
Validation loss: 1.6511192808869064

Epoch: 6| Step: 3
Training loss: 0.08816272020339966
Validation loss: 1.6447037394328783

Epoch: 6| Step: 4
Training loss: 0.06372129917144775
Validation loss: 1.6312823577593731

Epoch: 6| Step: 5
Training loss: 0.11133230477571487
Validation loss: 1.6281293361417708

Epoch: 6| Step: 6
Training loss: 0.08952338248491287
Validation loss: 1.599871197054463

Epoch: 6| Step: 7
Training loss: 0.10644662380218506
Validation loss: 1.6212524547371814

Epoch: 6| Step: 8
Training loss: 0.10945260524749756
Validation loss: 1.613460571535172

Epoch: 6| Step: 9
Training loss: 0.131631001830101
Validation loss: 1.6230013678150792

Epoch: 6| Step: 10
Training loss: 0.10592173039913177
Validation loss: 1.6281469124619679

Epoch: 6| Step: 11
Training loss: 0.16299790143966675
Validation loss: 1.59908974939777

Epoch: 6| Step: 12
Training loss: 0.11935413628816605
Validation loss: 1.6225837513964663

Epoch: 6| Step: 13
Training loss: 0.12743091583251953
Validation loss: 1.6065203066795104

Epoch: 397| Step: 0
Training loss: 0.12999708950519562
Validation loss: 1.6017672143956667

Epoch: 6| Step: 1
Training loss: 0.1012636125087738
Validation loss: 1.5875292721615042

Epoch: 6| Step: 2
Training loss: 0.1252039074897766
Validation loss: 1.6067993346080984

Epoch: 6| Step: 3
Training loss: 0.13020607829093933
Validation loss: 1.586343983168243

Epoch: 6| Step: 4
Training loss: 0.09736116975545883
Validation loss: 1.627492521398811

Epoch: 6| Step: 5
Training loss: 0.11962403357028961
Validation loss: 1.6098070888109104

Epoch: 6| Step: 6
Training loss: 0.08323559910058975
Validation loss: 1.6355627377827961

Epoch: 6| Step: 7
Training loss: 0.11816217750310898
Validation loss: 1.637297805919442

Epoch: 6| Step: 8
Training loss: 0.11707889288663864
Validation loss: 1.647898970111724

Epoch: 6| Step: 9
Training loss: 0.1093057245016098
Validation loss: 1.6597888418423232

Epoch: 6| Step: 10
Training loss: 0.06723138689994812
Validation loss: 1.638537008275268

Epoch: 6| Step: 11
Training loss: 0.26193368434906006
Validation loss: 1.6496046909721949

Epoch: 6| Step: 12
Training loss: 0.0608108788728714
Validation loss: 1.6429209119530135

Epoch: 6| Step: 13
Training loss: 0.0882071927189827
Validation loss: 1.665184292742001

Epoch: 398| Step: 0
Training loss: 0.10114680230617523
Validation loss: 1.6326216754092966

Epoch: 6| Step: 1
Training loss: 0.10699223726987839
Validation loss: 1.6648730270324215

Epoch: 6| Step: 2
Training loss: 0.10788162797689438
Validation loss: 1.662003428705277

Epoch: 6| Step: 3
Training loss: 0.08155263960361481
Validation loss: 1.6449832736804921

Epoch: 6| Step: 4
Training loss: 0.24307048320770264
Validation loss: 1.6353516937584005

Epoch: 6| Step: 5
Training loss: 0.0935111790895462
Validation loss: 1.644480856516028

Epoch: 6| Step: 6
Training loss: 0.13717208802700043
Validation loss: 1.6262538086983465

Epoch: 6| Step: 7
Training loss: 0.0906452089548111
Validation loss: 1.6254654462619493

Epoch: 6| Step: 8
Training loss: 0.08850749582052231
Validation loss: 1.6428808730135682

Epoch: 6| Step: 9
Training loss: 0.0778733342885971
Validation loss: 1.6221837023253083

Epoch: 6| Step: 10
Training loss: 0.0746079757809639
Validation loss: 1.6466569182693318

Epoch: 6| Step: 11
Training loss: 0.1075223982334137
Validation loss: 1.6431465764199533

Epoch: 6| Step: 12
Training loss: 0.08284734189510345
Validation loss: 1.6491550066137826

Epoch: 6| Step: 13
Training loss: 0.0948386862874031
Validation loss: 1.650967078824197

Epoch: 399| Step: 0
Training loss: 0.17363913357257843
Validation loss: 1.661175820135301

Epoch: 6| Step: 1
Training loss: 0.07554609328508377
Validation loss: 1.6342372727650467

Epoch: 6| Step: 2
Training loss: 0.10100245475769043
Validation loss: 1.6111768945570915

Epoch: 6| Step: 3
Training loss: 0.07846154272556305
Validation loss: 1.6329804005161408

Epoch: 6| Step: 4
Training loss: 0.05039540305733681
Validation loss: 1.6190899238791516

Epoch: 6| Step: 5
Training loss: 0.12590305507183075
Validation loss: 1.6218969334838211

Epoch: 6| Step: 6
Training loss: 0.1064685732126236
Validation loss: 1.6373819356323571

Epoch: 6| Step: 7
Training loss: 0.11178264021873474
Validation loss: 1.6157944317786925

Epoch: 6| Step: 8
Training loss: 0.05382546782493591
Validation loss: 1.6168254267784856

Epoch: 6| Step: 9
Training loss: 0.27512073516845703
Validation loss: 1.6018579198468117

Epoch: 6| Step: 10
Training loss: 0.07953852415084839
Validation loss: 1.6436000677847094

Epoch: 6| Step: 11
Training loss: 0.09125231206417084
Validation loss: 1.6407980829156854

Epoch: 6| Step: 12
Training loss: 0.10686423629522324
Validation loss: 1.6409893458889377

Epoch: 6| Step: 13
Training loss: 0.09673210978507996
Validation loss: 1.635326999489979

Epoch: 400| Step: 0
Training loss: 0.10677264630794525
Validation loss: 1.634799789356929

Epoch: 6| Step: 1
Training loss: 0.10325072705745697
Validation loss: 1.6351095732822214

Epoch: 6| Step: 2
Training loss: 0.19249257445335388
Validation loss: 1.5718037941122567

Epoch: 6| Step: 3
Training loss: 0.12371150404214859
Validation loss: 1.5914475853725145

Epoch: 6| Step: 4
Training loss: 0.12397181987762451
Validation loss: 1.5900140462383148

Epoch: 6| Step: 5
Training loss: 0.08777544647455215
Validation loss: 1.6145692153643536

Epoch: 6| Step: 6
Training loss: 0.07333894819021225
Validation loss: 1.5943259744233982

Epoch: 6| Step: 7
Training loss: 0.294639527797699
Validation loss: 1.5804552365374822

Epoch: 6| Step: 8
Training loss: 0.0842743068933487
Validation loss: 1.6073033258479128

Epoch: 6| Step: 9
Training loss: 0.07207223027944565
Validation loss: 1.6193937678490915

Epoch: 6| Step: 10
Training loss: 0.11206378042697906
Validation loss: 1.6222150915412492

Epoch: 6| Step: 11
Training loss: 0.15099585056304932
Validation loss: 1.6209544661224529

Epoch: 6| Step: 12
Training loss: 0.08971434831619263
Validation loss: 1.6182929444056686

Epoch: 6| Step: 13
Training loss: 0.08167052268981934
Validation loss: 1.6367635496201054

Epoch: 401| Step: 0
Training loss: 0.06601870805025101
Validation loss: 1.65232704916308

Epoch: 6| Step: 1
Training loss: 0.09582223743200302
Validation loss: 1.6184568097514491

Epoch: 6| Step: 2
Training loss: 0.09778786450624466
Validation loss: 1.6677166749072332

Epoch: 6| Step: 3
Training loss: 0.09090690314769745
Validation loss: 1.6669059491926623

Epoch: 6| Step: 4
Training loss: 0.34463945031166077
Validation loss: 1.6509885339326755

Epoch: 6| Step: 5
Training loss: 0.11210626363754272
Validation loss: 1.676346887824356

Epoch: 6| Step: 6
Training loss: 0.08047619462013245
Validation loss: 1.6532592036390816

Epoch: 6| Step: 7
Training loss: 0.11600156873464584
Validation loss: 1.6543042864850772

Epoch: 6| Step: 8
Training loss: 0.10846567153930664
Validation loss: 1.6227602240859822

Epoch: 6| Step: 9
Training loss: 0.14313003420829773
Validation loss: 1.60995618502299

Epoch: 6| Step: 10
Training loss: 0.14350327849388123
Validation loss: 1.598083024383873

Epoch: 6| Step: 11
Training loss: 0.12961071729660034
Validation loss: 1.5593862674569572

Epoch: 6| Step: 12
Training loss: 0.09007769823074341
Validation loss: 1.5742059651241507

Epoch: 6| Step: 13
Training loss: 0.08867152780294418
Validation loss: 1.5678736317542292

Epoch: 402| Step: 0
Training loss: 0.0984138622879982
Validation loss: 1.599524926113826

Epoch: 6| Step: 1
Training loss: 0.1030406728386879
Validation loss: 1.5721502778350667

Epoch: 6| Step: 2
Training loss: 0.1589382141828537
Validation loss: 1.6178936022584156

Epoch: 6| Step: 3
Training loss: 0.15387502312660217
Validation loss: 1.5872092144463652

Epoch: 6| Step: 4
Training loss: 0.08884567767381668
Validation loss: 1.5921202475024807

Epoch: 6| Step: 5
Training loss: 0.09096396714448929
Validation loss: 1.6224886486607213

Epoch: 6| Step: 6
Training loss: 0.11569821834564209
Validation loss: 1.5963949317573218

Epoch: 6| Step: 7
Training loss: 0.0818597599864006
Validation loss: 1.5859935668206984

Epoch: 6| Step: 8
Training loss: 0.08516618609428406
Validation loss: 1.59685044903909

Epoch: 6| Step: 9
Training loss: 0.09905374050140381
Validation loss: 1.6113270046890422

Epoch: 6| Step: 10
Training loss: 0.14046552777290344
Validation loss: 1.6301751732826233

Epoch: 6| Step: 11
Training loss: 0.1004725992679596
Validation loss: 1.6416619388006066

Epoch: 6| Step: 12
Training loss: 0.31103938817977905
Validation loss: 1.6267025714279504

Epoch: 6| Step: 13
Training loss: 0.04228351265192032
Validation loss: 1.644115327506937

Epoch: 403| Step: 0
Training loss: 0.11497946083545685
Validation loss: 1.6623876428091398

Epoch: 6| Step: 1
Training loss: 0.24959862232208252
Validation loss: 1.6141160457364974

Epoch: 6| Step: 2
Training loss: 0.2075711190700531
Validation loss: 1.6475801737077775

Epoch: 6| Step: 3
Training loss: 0.15764187276363373
Validation loss: 1.6509587816012803

Epoch: 6| Step: 4
Training loss: 0.11515361815690994
Validation loss: 1.6404938210723221

Epoch: 6| Step: 5
Training loss: 0.0642763152718544
Validation loss: 1.600047508875529

Epoch: 6| Step: 6
Training loss: 0.10006508976221085
Validation loss: 1.624294195123898

Epoch: 6| Step: 7
Training loss: 0.06451912224292755
Validation loss: 1.6042281055963168

Epoch: 6| Step: 8
Training loss: 0.0757378563284874
Validation loss: 1.5754937061699488

Epoch: 6| Step: 9
Training loss: 0.16110898554325104
Validation loss: 1.5679886546186221

Epoch: 6| Step: 10
Training loss: 0.11197780072689056
Validation loss: 1.5587472274739256

Epoch: 6| Step: 11
Training loss: 0.12936359643936157
Validation loss: 1.6086551040731452

Epoch: 6| Step: 12
Training loss: 0.15915590524673462
Validation loss: 1.6030451225978073

Epoch: 6| Step: 13
Training loss: 0.17950564622879028
Validation loss: 1.6058682844203005

Epoch: 404| Step: 0
Training loss: 0.15737223625183105
Validation loss: 1.6042504438789942

Epoch: 6| Step: 1
Training loss: 0.11519532650709152
Validation loss: 1.606130838394165

Epoch: 6| Step: 2
Training loss: 0.12850475311279297
Validation loss: 1.6033282626059748

Epoch: 6| Step: 3
Training loss: 0.23569230735301971
Validation loss: 1.6095707416534424

Epoch: 6| Step: 4
Training loss: 0.09923258423805237
Validation loss: 1.6239362121910177

Epoch: 6| Step: 5
Training loss: 0.20110681653022766
Validation loss: 1.6441843522492277

Epoch: 6| Step: 6
Training loss: 0.13661520183086395
Validation loss: 1.6486062054993005

Epoch: 6| Step: 7
Training loss: 0.08546208590269089
Validation loss: 1.6112949860993253

Epoch: 6| Step: 8
Training loss: 0.1351262629032135
Validation loss: 1.6178352422611688

Epoch: 6| Step: 9
Training loss: 0.08348482847213745
Validation loss: 1.6117233986495643

Epoch: 6| Step: 10
Training loss: 0.16189852356910706
Validation loss: 1.5922620360569288

Epoch: 6| Step: 11
Training loss: 0.05059655010700226
Validation loss: 1.5839734461999708

Epoch: 6| Step: 12
Training loss: 0.13450480997562408
Validation loss: 1.5853349085777038

Epoch: 6| Step: 13
Training loss: 0.15529796481132507
Validation loss: 1.626367538206039

Epoch: 405| Step: 0
Training loss: 0.081009142100811
Validation loss: 1.6290562896318332

Epoch: 6| Step: 1
Training loss: 0.1094040647149086
Validation loss: 1.6543666508889967

Epoch: 6| Step: 2
Training loss: 0.12124129384756088
Validation loss: 1.6599897056497552

Epoch: 6| Step: 3
Training loss: 0.23163676261901855
Validation loss: 1.6733546744110763

Epoch: 6| Step: 4
Training loss: 0.09469421952962875
Validation loss: 1.6923941258461244

Epoch: 6| Step: 5
Training loss: 0.09268389642238617
Validation loss: 1.6867900715079358

Epoch: 6| Step: 6
Training loss: 0.3299719989299774
Validation loss: 1.6682750499376686

Epoch: 6| Step: 7
Training loss: 0.07809823751449585
Validation loss: 1.641550140996133

Epoch: 6| Step: 8
Training loss: 0.11555536091327667
Validation loss: 1.6252870367419334

Epoch: 6| Step: 9
Training loss: 0.11686290055513382
Validation loss: 1.5808149492868813

Epoch: 6| Step: 10
Training loss: 0.20278331637382507
Validation loss: 1.6077651169992262

Epoch: 6| Step: 11
Training loss: 0.1687082052230835
Validation loss: 1.591086826016826

Epoch: 6| Step: 12
Training loss: 0.14940932393074036
Validation loss: 1.5786874627554288

Epoch: 6| Step: 13
Training loss: 0.1307152807712555
Validation loss: 1.5646373610342703

Epoch: 406| Step: 0
Training loss: 0.09734486043453217
Validation loss: 1.5849891811288812

Epoch: 6| Step: 1
Training loss: 0.1219959408044815
Validation loss: 1.5827932421879103

Epoch: 6| Step: 2
Training loss: 0.13107983767986298
Validation loss: 1.5721542463507703

Epoch: 6| Step: 3
Training loss: 0.09261920303106308
Validation loss: 1.6189393958737772

Epoch: 6| Step: 4
Training loss: 0.15297852456569672
Validation loss: 1.602889395529224

Epoch: 6| Step: 5
Training loss: 0.08179374039173126
Validation loss: 1.5983415495964788

Epoch: 6| Step: 6
Training loss: 0.10527624189853668
Validation loss: 1.580404657189564

Epoch: 6| Step: 7
Training loss: 0.11973775923252106
Validation loss: 1.596601611824446

Epoch: 6| Step: 8
Training loss: 0.07977992296218872
Validation loss: 1.6127427444663098

Epoch: 6| Step: 9
Training loss: 0.08688781410455704
Validation loss: 1.6085919077678392

Epoch: 6| Step: 10
Training loss: 0.2161102592945099
Validation loss: 1.5932997606133903

Epoch: 6| Step: 11
Training loss: 0.1649520993232727
Validation loss: 1.6025103740794684

Epoch: 6| Step: 12
Training loss: 0.15000560879707336
Validation loss: 1.6067601147518362

Epoch: 6| Step: 13
Training loss: 0.17192284762859344
Validation loss: 1.588701714751541

Epoch: 407| Step: 0
Training loss: 0.16173124313354492
Validation loss: 1.6145806671470724

Epoch: 6| Step: 1
Training loss: 0.13294970989227295
Validation loss: 1.5980183129669518

Epoch: 6| Step: 2
Training loss: 0.22799314558506012
Validation loss: 1.6241921686357068

Epoch: 6| Step: 3
Training loss: 0.15472915768623352
Validation loss: 1.6467931578236241

Epoch: 6| Step: 4
Training loss: 0.18231824040412903
Validation loss: 1.6411487979273642

Epoch: 6| Step: 5
Training loss: 0.11094412207603455
Validation loss: 1.6223494134923464

Epoch: 6| Step: 6
Training loss: 0.08670095354318619
Validation loss: 1.6320039456890476

Epoch: 6| Step: 7
Training loss: 0.10460387170314789
Validation loss: 1.6252935099345382

Epoch: 6| Step: 8
Training loss: 0.08402563631534576
Validation loss: 1.617589496797131

Epoch: 6| Step: 9
Training loss: 0.09976496547460556
Validation loss: 1.6165772112466956

Epoch: 6| Step: 10
Training loss: 0.15432149171829224
Validation loss: 1.618109953018927

Epoch: 6| Step: 11
Training loss: 0.2925749719142914
Validation loss: 1.6238242387771606

Epoch: 6| Step: 12
Training loss: 0.14004488289356232
Validation loss: 1.5921542426591277

Epoch: 6| Step: 13
Training loss: 0.08917054533958435
Validation loss: 1.6024113931963522

Epoch: 408| Step: 0
Training loss: 0.1035822182893753
Validation loss: 1.604852654600656

Epoch: 6| Step: 1
Training loss: 0.053823668509721756
Validation loss: 1.6322733920107606

Epoch: 6| Step: 2
Training loss: 0.115780308842659
Validation loss: 1.6294430257171713

Epoch: 6| Step: 3
Training loss: 0.1347215175628662
Validation loss: 1.6182492086964269

Epoch: 6| Step: 4
Training loss: 0.13154533505439758
Validation loss: 1.6245747381641018

Epoch: 6| Step: 5
Training loss: 0.10134304314851761
Validation loss: 1.6425756100685365

Epoch: 6| Step: 6
Training loss: 0.1143413633108139
Validation loss: 1.6131356595664896

Epoch: 6| Step: 7
Training loss: 0.10776849836111069
Validation loss: 1.6172039521637784

Epoch: 6| Step: 8
Training loss: 0.2700254023075104
Validation loss: 1.5884429908567859

Epoch: 6| Step: 9
Training loss: 0.07105900347232819
Validation loss: 1.6036423470384331

Epoch: 6| Step: 10
Training loss: 0.10882625728845596
Validation loss: 1.6260865478105442

Epoch: 6| Step: 11
Training loss: 0.12825126945972443
Validation loss: 1.613752693258306

Epoch: 6| Step: 12
Training loss: 0.15826945006847382
Validation loss: 1.6231649947422806

Epoch: 6| Step: 13
Training loss: 0.08764693140983582
Validation loss: 1.6396784609363926

Epoch: 409| Step: 0
Training loss: 0.07421424239873886
Validation loss: 1.6361445021885697

Epoch: 6| Step: 1
Training loss: 0.2767627239227295
Validation loss: 1.631776350800709

Epoch: 6| Step: 2
Training loss: 0.1251344084739685
Validation loss: 1.6394623210353236

Epoch: 6| Step: 3
Training loss: 0.07342766225337982
Validation loss: 1.649381132536037

Epoch: 6| Step: 4
Training loss: 0.10483132302761078
Validation loss: 1.6418375686932636

Epoch: 6| Step: 5
Training loss: 0.08140966296195984
Validation loss: 1.6625450913624098

Epoch: 6| Step: 6
Training loss: 0.133101224899292
Validation loss: 1.6208339211761311

Epoch: 6| Step: 7
Training loss: 0.10414011031389236
Validation loss: 1.628634616892825

Epoch: 6| Step: 8
Training loss: 0.13975650072097778
Validation loss: 1.6409474239554456

Epoch: 6| Step: 9
Training loss: 0.11697356402873993
Validation loss: 1.6354382807208645

Epoch: 6| Step: 10
Training loss: 0.0640435665845871
Validation loss: 1.6271192418631686

Epoch: 6| Step: 11
Training loss: 0.12086998671293259
Validation loss: 1.654002130672496

Epoch: 6| Step: 12
Training loss: 0.1898488700389862
Validation loss: 1.6483435720525763

Epoch: 6| Step: 13
Training loss: 0.15629179775714874
Validation loss: 1.628204995586026

Epoch: 410| Step: 0
Training loss: 0.27085933089256287
Validation loss: 1.6451420322541268

Epoch: 6| Step: 1
Training loss: 0.08929508924484253
Validation loss: 1.6235100146262877

Epoch: 6| Step: 2
Training loss: 0.1493731588125229
Validation loss: 1.6379285499613772

Epoch: 6| Step: 3
Training loss: 0.1063077449798584
Validation loss: 1.6249275822793283

Epoch: 6| Step: 4
Training loss: 0.09016675502061844
Validation loss: 1.6332339753386795

Epoch: 6| Step: 5
Training loss: 0.14247523248195648
Validation loss: 1.617834496241744

Epoch: 6| Step: 6
Training loss: 0.09727999567985535
Validation loss: 1.6243188124831005

Epoch: 6| Step: 7
Training loss: 0.10555002093315125
Validation loss: 1.6325556308992448

Epoch: 6| Step: 8
Training loss: 0.07072389125823975
Validation loss: 1.6480620971290014

Epoch: 6| Step: 9
Training loss: 0.11561595648527145
Validation loss: 1.667308916327774

Epoch: 6| Step: 10
Training loss: 0.09982994198799133
Validation loss: 1.6795160796052666

Epoch: 6| Step: 11
Training loss: 0.17812594771385193
Validation loss: 1.691032136640241

Epoch: 6| Step: 12
Training loss: 0.12435412406921387
Validation loss: 1.7365383922412831

Epoch: 6| Step: 13
Training loss: 0.161834254860878
Validation loss: 1.7348505912288543

Epoch: 411| Step: 0
Training loss: 0.11260252445936203
Validation loss: 1.7385684597876765

Epoch: 6| Step: 1
Training loss: 0.10630936920642853
Validation loss: 1.69926102699772

Epoch: 6| Step: 2
Training loss: 0.1536499559879303
Validation loss: 1.6686846210110573

Epoch: 6| Step: 3
Training loss: 0.11683228611946106
Validation loss: 1.671763934755838

Epoch: 6| Step: 4
Training loss: 0.13838253915309906
Validation loss: 1.6303409222633607

Epoch: 6| Step: 5
Training loss: 0.12826819717884064
Validation loss: 1.6322150153498496

Epoch: 6| Step: 6
Training loss: 0.08967464417219162
Validation loss: 1.630728457563667

Epoch: 6| Step: 7
Training loss: 0.16351914405822754
Validation loss: 1.6229785168042747

Epoch: 6| Step: 8
Training loss: 0.31054335832595825
Validation loss: 1.626879184476791

Epoch: 6| Step: 9
Training loss: 0.07177013158798218
Validation loss: 1.6013852742410475

Epoch: 6| Step: 10
Training loss: 0.12410593032836914
Validation loss: 1.6157545562713378

Epoch: 6| Step: 11
Training loss: 0.1367335319519043
Validation loss: 1.6360701630192418

Epoch: 6| Step: 12
Training loss: 0.10481356084346771
Validation loss: 1.62852454826396

Epoch: 6| Step: 13
Training loss: 0.1897343546152115
Validation loss: 1.613557916815563

Epoch: 412| Step: 0
Training loss: 0.08863058686256409
Validation loss: 1.6378564937140352

Epoch: 6| Step: 1
Training loss: 0.08549946546554565
Validation loss: 1.6243241730556692

Epoch: 6| Step: 2
Training loss: 0.11280233412981033
Validation loss: 1.6370072185352285

Epoch: 6| Step: 3
Training loss: 0.11611084640026093
Validation loss: 1.6357277426668393

Epoch: 6| Step: 4
Training loss: 0.23745204508304596
Validation loss: 1.6426142825875232

Epoch: 6| Step: 5
Training loss: 0.07328736037015915
Validation loss: 1.6205888819950882

Epoch: 6| Step: 6
Training loss: 0.11694911867380142
Validation loss: 1.6264519845285723

Epoch: 6| Step: 7
Training loss: 0.0737767219543457
Validation loss: 1.6436629602985997

Epoch: 6| Step: 8
Training loss: 0.047404512763023376
Validation loss: 1.6328814465512511

Epoch: 6| Step: 9
Training loss: 0.0710461437702179
Validation loss: 1.6358716128974833

Epoch: 6| Step: 10
Training loss: 0.11216379702091217
Validation loss: 1.639919480969829

Epoch: 6| Step: 11
Training loss: 0.12748858332633972
Validation loss: 1.6307741736852994

Epoch: 6| Step: 12
Training loss: 0.13393835723400116
Validation loss: 1.6568612257639568

Epoch: 6| Step: 13
Training loss: 0.1310138702392578
Validation loss: 1.6323259376710462

Epoch: 413| Step: 0
Training loss: 0.08764514327049255
Validation loss: 1.6448204055909188

Epoch: 6| Step: 1
Training loss: 0.13215306401252747
Validation loss: 1.6600072550517257

Epoch: 6| Step: 2
Training loss: 0.08854983747005463
Validation loss: 1.6433949162883144

Epoch: 6| Step: 3
Training loss: 0.07634162902832031
Validation loss: 1.64497209108004

Epoch: 6| Step: 4
Training loss: 0.29303985834121704
Validation loss: 1.622586582296638

Epoch: 6| Step: 5
Training loss: 0.08649725466966629
Validation loss: 1.6251403452247701

Epoch: 6| Step: 6
Training loss: 0.11109858751296997
Validation loss: 1.6512896219889324

Epoch: 6| Step: 7
Training loss: 0.08873582631349564
Validation loss: 1.624040549801242

Epoch: 6| Step: 8
Training loss: 0.08521698415279388
Validation loss: 1.6341741879781086

Epoch: 6| Step: 9
Training loss: 0.09165991097688675
Validation loss: 1.6245456459701701

Epoch: 6| Step: 10
Training loss: 0.09030817449092865
Validation loss: 1.6075323422749836

Epoch: 6| Step: 11
Training loss: 0.13246610760688782
Validation loss: 1.5843454996744792

Epoch: 6| Step: 12
Training loss: 0.13203537464141846
Validation loss: 1.5968712837465349

Epoch: 6| Step: 13
Training loss: 0.0779331624507904
Validation loss: 1.6075401242061327

Epoch: 414| Step: 0
Training loss: 0.24942126870155334
Validation loss: 1.622797825003183

Epoch: 6| Step: 1
Training loss: 0.10042703151702881
Validation loss: 1.6190269147196124

Epoch: 6| Step: 2
Training loss: 0.09731396287679672
Validation loss: 1.6085435882691415

Epoch: 6| Step: 3
Training loss: 0.06701894849538803
Validation loss: 1.6113578773313952

Epoch: 6| Step: 4
Training loss: 0.061961352825164795
Validation loss: 1.6379631809009019

Epoch: 6| Step: 5
Training loss: 0.11361397802829742
Validation loss: 1.6165933262917302

Epoch: 6| Step: 6
Training loss: 0.10126622766256332
Validation loss: 1.6054846343173776

Epoch: 6| Step: 7
Training loss: 0.1133102998137474
Validation loss: 1.6325548592434134

Epoch: 6| Step: 8
Training loss: 0.13311165571212769
Validation loss: 1.649181301875781

Epoch: 6| Step: 9
Training loss: 0.08191307634115219
Validation loss: 1.6175309073540471

Epoch: 6| Step: 10
Training loss: 0.09934693574905396
Validation loss: 1.6474023890751663

Epoch: 6| Step: 11
Training loss: 0.12071286886930466
Validation loss: 1.61394924758583

Epoch: 6| Step: 12
Training loss: 0.08486308157444
Validation loss: 1.6082616544538928

Epoch: 6| Step: 13
Training loss: 0.1530899703502655
Validation loss: 1.558203403667737

Epoch: 415| Step: 0
Training loss: 0.09087517857551575
Validation loss: 1.5904099979708273

Epoch: 6| Step: 1
Training loss: 0.055974751710891724
Validation loss: 1.595012677613125

Epoch: 6| Step: 2
Training loss: 0.13670843839645386
Validation loss: 1.5910005531003397

Epoch: 6| Step: 3
Training loss: 0.14996764063835144
Validation loss: 1.5885841333737938

Epoch: 6| Step: 4
Training loss: 0.08149977028369904
Validation loss: 1.592828284027756

Epoch: 6| Step: 5
Training loss: 0.10584007203578949
Validation loss: 1.567624076720207

Epoch: 6| Step: 6
Training loss: 0.10322295874357224
Validation loss: 1.5766207864207606

Epoch: 6| Step: 7
Training loss: 0.060328807681798935
Validation loss: 1.5484917413803838

Epoch: 6| Step: 8
Training loss: 0.08028782904148102
Validation loss: 1.5559751775956923

Epoch: 6| Step: 9
Training loss: 0.13505014777183533
Validation loss: 1.564742676673397

Epoch: 6| Step: 10
Training loss: 0.10198026895523071
Validation loss: 1.5620437488760999

Epoch: 6| Step: 11
Training loss: 0.11344105005264282
Validation loss: 1.5249493070828017

Epoch: 6| Step: 12
Training loss: 0.2403974086046219
Validation loss: 1.5630676861732238

Epoch: 6| Step: 13
Training loss: 0.07960952073335648
Validation loss: 1.5553941854866602

Epoch: 416| Step: 0
Training loss: 0.0788772851228714
Validation loss: 1.5699243865987307

Epoch: 6| Step: 1
Training loss: 0.09351246058940887
Validation loss: 1.5781546164584417

Epoch: 6| Step: 2
Training loss: 0.06548804044723511
Validation loss: 1.5664050027888308

Epoch: 6| Step: 3
Training loss: 0.11489304900169373
Validation loss: 1.5680133924689343

Epoch: 6| Step: 4
Training loss: 0.09214422106742859
Validation loss: 1.5587623952537455

Epoch: 6| Step: 5
Training loss: 0.06393574178218842
Validation loss: 1.5723760269021476

Epoch: 6| Step: 6
Training loss: 0.1257762908935547
Validation loss: 1.5729093859272618

Epoch: 6| Step: 7
Training loss: 0.10312170535326004
Validation loss: 1.585348198490758

Epoch: 6| Step: 8
Training loss: 0.08510727435350418
Validation loss: 1.608265826779027

Epoch: 6| Step: 9
Training loss: 0.2823581099510193
Validation loss: 1.5864468454032816

Epoch: 6| Step: 10
Training loss: 0.1221243217587471
Validation loss: 1.5961481371233541

Epoch: 6| Step: 11
Training loss: 0.125298410654068
Validation loss: 1.5966024719258791

Epoch: 6| Step: 12
Training loss: 0.11935031414031982
Validation loss: 1.6100563233898533

Epoch: 6| Step: 13
Training loss: 0.10944480448961258
Validation loss: 1.5715081608423622

Epoch: 417| Step: 0
Training loss: 0.21808695793151855
Validation loss: 1.6202038923899333

Epoch: 6| Step: 1
Training loss: 0.12613563239574432
Validation loss: 1.5829433933381112

Epoch: 6| Step: 2
Training loss: 0.07336261868476868
Validation loss: 1.5840694801781767

Epoch: 6| Step: 3
Training loss: 0.08363428711891174
Validation loss: 1.6008734421063495

Epoch: 6| Step: 4
Training loss: 0.0762529969215393
Validation loss: 1.587670954324866

Epoch: 6| Step: 5
Training loss: 0.05623967945575714
Validation loss: 1.6023061454937022

Epoch: 6| Step: 6
Training loss: 0.0667424350976944
Validation loss: 1.6042039702015538

Epoch: 6| Step: 7
Training loss: 0.052616186439991
Validation loss: 1.6087359452760348

Epoch: 6| Step: 8
Training loss: 0.1366313099861145
Validation loss: 1.6085060488793157

Epoch: 6| Step: 9
Training loss: 0.07302982360124588
Validation loss: 1.6162748785429104

Epoch: 6| Step: 10
Training loss: 0.0801011472940445
Validation loss: 1.5968743319152503

Epoch: 6| Step: 11
Training loss: 0.07700179517269135
Validation loss: 1.5947870093007241

Epoch: 6| Step: 12
Training loss: 0.10972195863723755
Validation loss: 1.6062082808504823

Epoch: 6| Step: 13
Training loss: 0.07105822116136551
Validation loss: 1.625178083296745

Epoch: 418| Step: 0
Training loss: 0.11657733470201492
Validation loss: 1.6182092953753728

Epoch: 6| Step: 1
Training loss: 0.09644594043493271
Validation loss: 1.6140822390074372

Epoch: 6| Step: 2
Training loss: 0.08893997222185135
Validation loss: 1.6273648495315223

Epoch: 6| Step: 3
Training loss: 0.09507548809051514
Validation loss: 1.610064515503504

Epoch: 6| Step: 4
Training loss: 0.12229487299919128
Validation loss: 1.592149983170212

Epoch: 6| Step: 5
Training loss: 0.09765829890966415
Validation loss: 1.5922018122929398

Epoch: 6| Step: 6
Training loss: 0.2609275281429291
Validation loss: 1.6065095233660873

Epoch: 6| Step: 7
Training loss: 0.11285674571990967
Validation loss: 1.5749465714218795

Epoch: 6| Step: 8
Training loss: 0.06935825198888779
Validation loss: 1.5663193304051635

Epoch: 6| Step: 9
Training loss: 0.09722335636615753
Validation loss: 1.5596711699680617

Epoch: 6| Step: 10
Training loss: 0.10517936944961548
Validation loss: 1.5866613670061993

Epoch: 6| Step: 11
Training loss: 0.11283236742019653
Validation loss: 1.5917791102522163

Epoch: 6| Step: 12
Training loss: 0.06867074221372604
Validation loss: 1.5833573123460174

Epoch: 6| Step: 13
Training loss: 0.09315536916255951
Validation loss: 1.5807434749859635

Epoch: 419| Step: 0
Training loss: 0.10932452976703644
Validation loss: 1.6027684006639706

Epoch: 6| Step: 1
Training loss: 0.1187184602022171
Validation loss: 1.638435850861252

Epoch: 6| Step: 2
Training loss: 0.08027053624391556
Validation loss: 1.6231243341199812

Epoch: 6| Step: 3
Training loss: 0.09847253561019897
Validation loss: 1.621548706485379

Epoch: 6| Step: 4
Training loss: 0.07386788725852966
Validation loss: 1.6288535312939716

Epoch: 6| Step: 5
Training loss: 0.1045769453048706
Validation loss: 1.6354055994300432

Epoch: 6| Step: 6
Training loss: 0.09649953991174698
Validation loss: 1.6396890019857755

Epoch: 6| Step: 7
Training loss: 0.12072484940290451
Validation loss: 1.6303743521372478

Epoch: 6| Step: 8
Training loss: 0.13287276029586792
Validation loss: 1.6428776197536017

Epoch: 6| Step: 9
Training loss: 0.11813415586948395
Validation loss: 1.6254253195178123

Epoch: 6| Step: 10
Training loss: 0.09381867200136185
Validation loss: 1.6307359780034711

Epoch: 6| Step: 11
Training loss: 0.26578325033187866
Validation loss: 1.6169020206697526

Epoch: 6| Step: 12
Training loss: 0.08462763577699661
Validation loss: 1.63386308762335

Epoch: 6| Step: 13
Training loss: 0.1012246236205101
Validation loss: 1.6227274287131526

Epoch: 420| Step: 0
Training loss: 0.06970049440860748
Validation loss: 1.592690121742987

Epoch: 6| Step: 1
Training loss: 0.10849621891975403
Validation loss: 1.6208217733649797

Epoch: 6| Step: 2
Training loss: 0.08673904091119766
Validation loss: 1.5770536712420884

Epoch: 6| Step: 3
Training loss: 0.07777131348848343
Validation loss: 1.563473646358777

Epoch: 6| Step: 4
Training loss: 0.06170110031962395
Validation loss: 1.5552811289346347

Epoch: 6| Step: 5
Training loss: 0.07037205249071121
Validation loss: 1.5540284610563708

Epoch: 6| Step: 6
Training loss: 0.16643817722797394
Validation loss: 1.5786075579222811

Epoch: 6| Step: 7
Training loss: 0.2920383810997009
Validation loss: 1.5901571384040258

Epoch: 6| Step: 8
Training loss: 0.12474603950977325
Validation loss: 1.5911862619461552

Epoch: 6| Step: 9
Training loss: 0.07303294539451599
Validation loss: 1.6212129464713476

Epoch: 6| Step: 10
Training loss: 0.16363775730133057
Validation loss: 1.640986245165589

Epoch: 6| Step: 11
Training loss: 0.0895916074514389
Validation loss: 1.613691117173882

Epoch: 6| Step: 12
Training loss: 0.10435424000024796
Validation loss: 1.6607549985249836

Epoch: 6| Step: 13
Training loss: 0.114715576171875
Validation loss: 1.66923176985915

Epoch: 421| Step: 0
Training loss: 0.2912588119506836
Validation loss: 1.6608276008277811

Epoch: 6| Step: 1
Training loss: 0.15204963088035583
Validation loss: 1.6686823521890948

Epoch: 6| Step: 2
Training loss: 0.06989963352680206
Validation loss: 1.71417099173351

Epoch: 6| Step: 3
Training loss: 0.09081649780273438
Validation loss: 1.6820179954651864

Epoch: 6| Step: 4
Training loss: 0.11205661296844482
Validation loss: 1.6538696673608595

Epoch: 6| Step: 5
Training loss: 0.11162173748016357
Validation loss: 1.6720533729881368

Epoch: 6| Step: 6
Training loss: 0.06073392182588577
Validation loss: 1.6270921537953038

Epoch: 6| Step: 7
Training loss: 0.16823819279670715
Validation loss: 1.6223268842184415

Epoch: 6| Step: 8
Training loss: 0.13258829712867737
Validation loss: 1.623177328417378

Epoch: 6| Step: 9
Training loss: 0.0873902291059494
Validation loss: 1.6348615077234083

Epoch: 6| Step: 10
Training loss: 0.0830712616443634
Validation loss: 1.6024209325031569

Epoch: 6| Step: 11
Training loss: 0.10151442140340805
Validation loss: 1.6176520560377388

Epoch: 6| Step: 12
Training loss: 0.05983143672347069
Validation loss: 1.6254415691539805

Epoch: 6| Step: 13
Training loss: 0.15679559111595154
Validation loss: 1.6337418786941036

Epoch: 422| Step: 0
Training loss: 0.13769112527370453
Validation loss: 1.6461652081499818

Epoch: 6| Step: 1
Training loss: 0.12558408081531525
Validation loss: 1.6448208952462802

Epoch: 6| Step: 2
Training loss: 0.12473580241203308
Validation loss: 1.6784419372517576

Epoch: 6| Step: 3
Training loss: 0.09283868223428726
Validation loss: 1.6749841602899695

Epoch: 6| Step: 4
Training loss: 0.1471235454082489
Validation loss: 1.672704501818585

Epoch: 6| Step: 5
Training loss: 0.07259881496429443
Validation loss: 1.6808083993132397

Epoch: 6| Step: 6
Training loss: 0.07459626346826553
Validation loss: 1.6847869298791374

Epoch: 6| Step: 7
Training loss: 0.09755649417638779
Validation loss: 1.658983483109423

Epoch: 6| Step: 8
Training loss: 0.1436557024717331
Validation loss: 1.6766019764766897

Epoch: 6| Step: 9
Training loss: 0.10442057251930237
Validation loss: 1.6737848776642994

Epoch: 6| Step: 10
Training loss: 0.1564362347126007
Validation loss: 1.6607248808747979

Epoch: 6| Step: 11
Training loss: 0.07865902036428452
Validation loss: 1.6169215767614302

Epoch: 6| Step: 12
Training loss: 0.25360846519470215
Validation loss: 1.6204081248211604

Epoch: 6| Step: 13
Training loss: 0.1691010445356369
Validation loss: 1.6227509629341863

Epoch: 423| Step: 0
Training loss: 0.12741144001483917
Validation loss: 1.6129163567737868

Epoch: 6| Step: 1
Training loss: 0.08986197412014008
Validation loss: 1.6268081716311875

Epoch: 6| Step: 2
Training loss: 0.16646626591682434
Validation loss: 1.6373219682324318

Epoch: 6| Step: 3
Training loss: 0.09243306517601013
Validation loss: 1.6102123298952657

Epoch: 6| Step: 4
Training loss: 0.07869523018598557
Validation loss: 1.6125254438769432

Epoch: 6| Step: 5
Training loss: 0.1056215912103653
Validation loss: 1.6156819494821693

Epoch: 6| Step: 6
Training loss: 0.33019503951072693
Validation loss: 1.63990770616839

Epoch: 6| Step: 7
Training loss: 0.0821601003408432
Validation loss: 1.6472959146704724

Epoch: 6| Step: 8
Training loss: 0.07737018167972565
Validation loss: 1.619830805768249

Epoch: 6| Step: 9
Training loss: 0.11620800942182541
Validation loss: 1.6327113105404762

Epoch: 6| Step: 10
Training loss: 0.09626814723014832
Validation loss: 1.6100921682132188

Epoch: 6| Step: 11
Training loss: 0.13194265961647034
Validation loss: 1.6411118199748378

Epoch: 6| Step: 12
Training loss: 0.09771829843521118
Validation loss: 1.6151461242347636

Epoch: 6| Step: 13
Training loss: 0.0842379480600357
Validation loss: 1.6277117959914669

Epoch: 424| Step: 0
Training loss: 0.10844689607620239
Validation loss: 1.624179333768865

Epoch: 6| Step: 1
Training loss: 0.09921135008335114
Validation loss: 1.622564987469745

Epoch: 6| Step: 2
Training loss: 0.12590903043746948
Validation loss: 1.6382513200083086

Epoch: 6| Step: 3
Training loss: 0.06671001762151718
Validation loss: 1.5898681417588265

Epoch: 6| Step: 4
Training loss: 0.1118645966053009
Validation loss: 1.5922172569459485

Epoch: 6| Step: 5
Training loss: 0.09007172286510468
Validation loss: 1.567656099155385

Epoch: 6| Step: 6
Training loss: 0.10171887278556824
Validation loss: 1.5672630033185404

Epoch: 6| Step: 7
Training loss: 0.0894443690776825
Validation loss: 1.561010222281179

Epoch: 6| Step: 8
Training loss: 0.24508430063724518
Validation loss: 1.5486687947345037

Epoch: 6| Step: 9
Training loss: 0.09896507859230042
Validation loss: 1.529497592679916

Epoch: 6| Step: 10
Training loss: 0.15701620280742645
Validation loss: 1.569251045103996

Epoch: 6| Step: 11
Training loss: 0.10724878311157227
Validation loss: 1.5645461890005297

Epoch: 6| Step: 12
Training loss: 0.0947306752204895
Validation loss: 1.5911971779279812

Epoch: 6| Step: 13
Training loss: 0.0936189740896225
Validation loss: 1.588412884742983

Epoch: 425| Step: 0
Training loss: 0.12703381478786469
Validation loss: 1.6133208056931854

Epoch: 6| Step: 1
Training loss: 0.10495483875274658
Validation loss: 1.6074361262782928

Epoch: 6| Step: 2
Training loss: 0.24951589107513428
Validation loss: 1.6343827760347756

Epoch: 6| Step: 3
Training loss: 0.11919829994440079
Validation loss: 1.6590434684548327

Epoch: 6| Step: 4
Training loss: 0.10876313596963882
Validation loss: 1.660970026446927

Epoch: 6| Step: 5
Training loss: 0.1059638261795044
Validation loss: 1.6386946529470465

Epoch: 6| Step: 6
Training loss: 0.112504743039608
Validation loss: 1.6533891821420321

Epoch: 6| Step: 7
Training loss: 0.16726332902908325
Validation loss: 1.6497995661151024

Epoch: 6| Step: 8
Training loss: 0.06369525194168091
Validation loss: 1.612390043914959

Epoch: 6| Step: 9
Training loss: 0.13832344114780426
Validation loss: 1.6266667464727997

Epoch: 6| Step: 10
Training loss: 0.09104137867689133
Validation loss: 1.6072754475378221

Epoch: 6| Step: 11
Training loss: 0.15460151433944702
Validation loss: 1.6133436515767088

Epoch: 6| Step: 12
Training loss: 0.094432033598423
Validation loss: 1.5987822650581278

Epoch: 6| Step: 13
Training loss: 0.09051207453012466
Validation loss: 1.6135857951256536

Epoch: 426| Step: 0
Training loss: 0.13933716714382172
Validation loss: 1.594789017913162

Epoch: 6| Step: 1
Training loss: 0.0725409984588623
Validation loss: 1.5927691562201387

Epoch: 6| Step: 2
Training loss: 0.12835893034934998
Validation loss: 1.5758738158851542

Epoch: 6| Step: 3
Training loss: 0.10013537108898163
Validation loss: 1.5873251397122619

Epoch: 6| Step: 4
Training loss: 0.3738313913345337
Validation loss: 1.6190844517882153

Epoch: 6| Step: 5
Training loss: 0.09760262072086334
Validation loss: 1.5972568578617548

Epoch: 6| Step: 6
Training loss: 0.1481868475675583
Validation loss: 1.6102869254286571

Epoch: 6| Step: 7
Training loss: 0.11669052392244339
Validation loss: 1.5972453278879966

Epoch: 6| Step: 8
Training loss: 0.1055072546005249
Validation loss: 1.6169876161442007

Epoch: 6| Step: 9
Training loss: 0.0823742002248764
Validation loss: 1.6448535509006952

Epoch: 6| Step: 10
Training loss: 0.07851679623126984
Validation loss: 1.6739434292239528

Epoch: 6| Step: 11
Training loss: 0.16544987261295319
Validation loss: 1.6692324453784573

Epoch: 6| Step: 12
Training loss: 0.2319539487361908
Validation loss: 1.6542617390232701

Epoch: 6| Step: 13
Training loss: 0.09100912511348724
Validation loss: 1.6530011738500288

Epoch: 427| Step: 0
Training loss: 0.08283417671918869
Validation loss: 1.6084254275086105

Epoch: 6| Step: 1
Training loss: 0.10398506373167038
Validation loss: 1.6030219216500559

Epoch: 6| Step: 2
Training loss: 0.09014534950256348
Validation loss: 1.5855827895543908

Epoch: 6| Step: 3
Training loss: 0.12029106914997101
Validation loss: 1.5996705780747116

Epoch: 6| Step: 4
Training loss: 0.047102540731430054
Validation loss: 1.5897587319856048

Epoch: 6| Step: 5
Training loss: 0.08182075619697571
Validation loss: 1.5843509909927205

Epoch: 6| Step: 6
Training loss: 0.13409794867038727
Validation loss: 1.604232926522532

Epoch: 6| Step: 7
Training loss: 0.13814184069633484
Validation loss: 1.5808413733718216

Epoch: 6| Step: 8
Training loss: 0.1544904261827469
Validation loss: 1.6038144647434194

Epoch: 6| Step: 9
Training loss: 0.29511505365371704
Validation loss: 1.5863072461979364

Epoch: 6| Step: 10
Training loss: 0.07236696779727936
Validation loss: 1.6163558921506327

Epoch: 6| Step: 11
Training loss: 0.09345981478691101
Validation loss: 1.6273909089385823

Epoch: 6| Step: 12
Training loss: 0.1127806082367897
Validation loss: 1.6311102900453793

Epoch: 6| Step: 13
Training loss: 0.1743454486131668
Validation loss: 1.634309995558954

Epoch: 428| Step: 0
Training loss: 0.11717589199542999
Validation loss: 1.6314717121021722

Epoch: 6| Step: 1
Training loss: 0.11419162154197693
Validation loss: 1.647238342992721

Epoch: 6| Step: 2
Training loss: 0.20772767066955566
Validation loss: 1.6677664684992966

Epoch: 6| Step: 3
Training loss: 0.10675497353076935
Validation loss: 1.6540777952440324

Epoch: 6| Step: 4
Training loss: 0.101045623421669
Validation loss: 1.631515161965483

Epoch: 6| Step: 5
Training loss: 0.07241985201835632
Validation loss: 1.5759532323447607

Epoch: 6| Step: 6
Training loss: 0.08829372376203537
Validation loss: 1.5815705407050349

Epoch: 6| Step: 7
Training loss: 0.08513636887073517
Validation loss: 1.5648987472698253

Epoch: 6| Step: 8
Training loss: 0.1462632417678833
Validation loss: 1.5370096263065134

Epoch: 6| Step: 9
Training loss: 0.11671924591064453
Validation loss: 1.520349815327634

Epoch: 6| Step: 10
Training loss: 0.09677913784980774
Validation loss: 1.566721946962418

Epoch: 6| Step: 11
Training loss: 0.2857210040092468
Validation loss: 1.5504645339904293

Epoch: 6| Step: 12
Training loss: 0.15092161297798157
Validation loss: 1.5828595353711037

Epoch: 6| Step: 13
Training loss: 0.10829421132802963
Validation loss: 1.6047942792215655

Epoch: 429| Step: 0
Training loss: 0.07927082479000092
Validation loss: 1.61812852274987

Epoch: 6| Step: 1
Training loss: 0.06099625304341316
Validation loss: 1.622330795052231

Epoch: 6| Step: 2
Training loss: 0.06927088648080826
Validation loss: 1.5928437068898191

Epoch: 6| Step: 3
Training loss: 0.12946639955043793
Validation loss: 1.6143244210109915

Epoch: 6| Step: 4
Training loss: 0.10413096845149994
Validation loss: 1.621018240528722

Epoch: 6| Step: 5
Training loss: 0.08966241031885147
Validation loss: 1.604554727513303

Epoch: 6| Step: 6
Training loss: 0.08589582145214081
Validation loss: 1.5912658392742116

Epoch: 6| Step: 7
Training loss: 0.08694799244403839
Validation loss: 1.5831718406369608

Epoch: 6| Step: 8
Training loss: 0.1931285858154297
Validation loss: 1.5995057590546147

Epoch: 6| Step: 9
Training loss: 0.05274759232997894
Validation loss: 1.5983337151106967

Epoch: 6| Step: 10
Training loss: 0.0743502676486969
Validation loss: 1.6123861856358026

Epoch: 6| Step: 11
Training loss: 0.23762913048267365
Validation loss: 1.5641252084444928

Epoch: 6| Step: 12
Training loss: 0.07251410186290741
Validation loss: 1.5698312033889115

Epoch: 6| Step: 13
Training loss: 0.14873673021793365
Validation loss: 1.546985968466728

Epoch: 430| Step: 0
Training loss: 0.09416892379522324
Validation loss: 1.5572217074773644

Epoch: 6| Step: 1
Training loss: 0.07775399088859558
Validation loss: 1.5735128746237805

Epoch: 6| Step: 2
Training loss: 0.12463465332984924
Validation loss: 1.566952887401786

Epoch: 6| Step: 3
Training loss: 0.128118097782135
Validation loss: 1.6022017489197433

Epoch: 6| Step: 4
Training loss: 0.1521981656551361
Validation loss: 1.5978069882239065

Epoch: 6| Step: 5
Training loss: 0.10978448390960693
Validation loss: 1.5906231941715363

Epoch: 6| Step: 6
Training loss: 0.07423070818185806
Validation loss: 1.6150888601938884

Epoch: 6| Step: 7
Training loss: 0.08687515556812286
Validation loss: 1.6247583819973854

Epoch: 6| Step: 8
Training loss: 0.0810556560754776
Validation loss: 1.6020320000187043

Epoch: 6| Step: 9
Training loss: 0.07639309018850327
Validation loss: 1.5955821570529733

Epoch: 6| Step: 10
Training loss: 0.07610312849283218
Validation loss: 1.6084602250847766

Epoch: 6| Step: 11
Training loss: 0.2847154140472412
Validation loss: 1.5899374497834073

Epoch: 6| Step: 12
Training loss: 0.1113477349281311
Validation loss: 1.6110263197652754

Epoch: 6| Step: 13
Training loss: 0.11036872863769531
Validation loss: 1.6097619994994132

Epoch: 431| Step: 0
Training loss: 0.06359564512968063
Validation loss: 1.6287389724485335

Epoch: 6| Step: 1
Training loss: 0.13545778393745422
Validation loss: 1.6227868051939114

Epoch: 6| Step: 2
Training loss: 0.11156977713108063
Validation loss: 1.645626296279251

Epoch: 6| Step: 3
Training loss: 0.16480043530464172
Validation loss: 1.634125719788254

Epoch: 6| Step: 4
Training loss: 0.21128667891025543
Validation loss: 1.6368903652314217

Epoch: 6| Step: 5
Training loss: 0.1328948438167572
Validation loss: 1.610911379578293

Epoch: 6| Step: 6
Training loss: 0.1419145166873932
Validation loss: 1.5830900733188917

Epoch: 6| Step: 7
Training loss: 0.10471035540103912
Validation loss: 1.5821532946760937

Epoch: 6| Step: 8
Training loss: 0.10822564363479614
Validation loss: 1.5839095372025684

Epoch: 6| Step: 9
Training loss: 0.14256426692008972
Validation loss: 1.555337381619279

Epoch: 6| Step: 10
Training loss: 0.12748375535011292
Validation loss: 1.5579742718768377

Epoch: 6| Step: 11
Training loss: 0.1620851457118988
Validation loss: 1.5744504274860505

Epoch: 6| Step: 12
Training loss: 0.17522546648979187
Validation loss: 1.5976960101435262

Epoch: 6| Step: 13
Training loss: 0.3440922498703003
Validation loss: 1.6057043895926526

Epoch: 432| Step: 0
Training loss: 0.2400880753993988
Validation loss: 1.618362042211717

Epoch: 6| Step: 1
Training loss: 0.14219486713409424
Validation loss: 1.6145925547486992

Epoch: 6| Step: 2
Training loss: 0.14313381910324097
Validation loss: 1.6617109506360945

Epoch: 6| Step: 3
Training loss: 0.08028538525104523
Validation loss: 1.678619336056453

Epoch: 6| Step: 4
Training loss: 0.09817907214164734
Validation loss: 1.6587016992671515

Epoch: 6| Step: 5
Training loss: 0.06203629821538925
Validation loss: 1.6685694571464293

Epoch: 6| Step: 6
Training loss: 0.10184808820486069
Validation loss: 1.6679325654942503

Epoch: 6| Step: 7
Training loss: 0.10586720705032349
Validation loss: 1.6530020403605636

Epoch: 6| Step: 8
Training loss: 0.10142810642719269
Validation loss: 1.6631915441123388

Epoch: 6| Step: 9
Training loss: 0.10019748657941818
Validation loss: 1.6471369522874073

Epoch: 6| Step: 10
Training loss: 0.13563477993011475
Validation loss: 1.6298548957352996

Epoch: 6| Step: 11
Training loss: 0.09650665521621704
Validation loss: 1.6080096895976732

Epoch: 6| Step: 12
Training loss: 0.04161883518099785
Validation loss: 1.6177237559390325

Epoch: 6| Step: 13
Training loss: 0.07697481662034988
Validation loss: 1.5949081925935642

Epoch: 433| Step: 0
Training loss: 0.11993408203125
Validation loss: 1.598762854453056

Epoch: 6| Step: 1
Training loss: 0.07287447154521942
Validation loss: 1.5952372615055372

Epoch: 6| Step: 2
Training loss: 0.09582427144050598
Validation loss: 1.6103912668843423

Epoch: 6| Step: 3
Training loss: 0.06586926430463791
Validation loss: 1.6124969169657717

Epoch: 6| Step: 4
Training loss: 0.11315873265266418
Validation loss: 1.64146472689926

Epoch: 6| Step: 5
Training loss: 0.11725493520498276
Validation loss: 1.6529458786851616

Epoch: 6| Step: 6
Training loss: 0.0724324882030487
Validation loss: 1.6266161677657918

Epoch: 6| Step: 7
Training loss: 0.10231228917837143
Validation loss: 1.610185984642275

Epoch: 6| Step: 8
Training loss: 0.09253230690956116
Validation loss: 1.6116469752403997

Epoch: 6| Step: 9
Training loss: 0.07544512301683426
Validation loss: 1.6134163884706394

Epoch: 6| Step: 10
Training loss: 0.0807252749800682
Validation loss: 1.6098339160283406

Epoch: 6| Step: 11
Training loss: 0.14182844758033752
Validation loss: 1.6047029995149182

Epoch: 6| Step: 12
Training loss: 0.11934143304824829
Validation loss: 1.6132613548668482

Epoch: 6| Step: 13
Training loss: 0.30949464440345764
Validation loss: 1.603349406232116

Epoch: 434| Step: 0
Training loss: 0.1229517012834549
Validation loss: 1.6287389160484396

Epoch: 6| Step: 1
Training loss: 0.09987112879753113
Validation loss: 1.6335159796540455

Epoch: 6| Step: 2
Training loss: 0.05118514224886894
Validation loss: 1.6691386956040577

Epoch: 6| Step: 3
Training loss: 0.10645367205142975
Validation loss: 1.6761833326790923

Epoch: 6| Step: 4
Training loss: 0.09809532761573792
Validation loss: 1.666403333346049

Epoch: 6| Step: 5
Training loss: 0.10139219462871552
Validation loss: 1.6673622605621174

Epoch: 6| Step: 6
Training loss: 0.09161149710416794
Validation loss: 1.6594972866837696

Epoch: 6| Step: 7
Training loss: 0.11790496110916138
Validation loss: 1.661340650691781

Epoch: 6| Step: 8
Training loss: 0.23032204806804657
Validation loss: 1.6617049504351873

Epoch: 6| Step: 9
Training loss: 0.10582302510738373
Validation loss: 1.656187495877666

Epoch: 6| Step: 10
Training loss: 0.1473129838705063
Validation loss: 1.6648716183118923

Epoch: 6| Step: 11
Training loss: 0.08169081807136536
Validation loss: 1.6552617857533116

Epoch: 6| Step: 12
Training loss: 0.08596795797348022
Validation loss: 1.6471425282057894

Epoch: 6| Step: 13
Training loss: 0.08006090670824051
Validation loss: 1.6442182128147413

Epoch: 435| Step: 0
Training loss: 0.07606141269207001
Validation loss: 1.6450920643345002

Epoch: 6| Step: 1
Training loss: 0.10200117528438568
Validation loss: 1.6367062830155896

Epoch: 6| Step: 2
Training loss: 0.07766769826412201
Validation loss: 1.6828137277275004

Epoch: 6| Step: 3
Training loss: 0.06910787522792816
Validation loss: 1.6480990359860082

Epoch: 6| Step: 4
Training loss: 0.06927691400051117
Validation loss: 1.6437214061778078

Epoch: 6| Step: 5
Training loss: 0.20852458477020264
Validation loss: 1.652395764986674

Epoch: 6| Step: 6
Training loss: 0.10824552178382874
Validation loss: 1.65201005371668

Epoch: 6| Step: 7
Training loss: 0.13836681842803955
Validation loss: 1.6653442741722189

Epoch: 6| Step: 8
Training loss: 0.10677607357501984
Validation loss: 1.6540955369190504

Epoch: 6| Step: 9
Training loss: 0.13908959925174713
Validation loss: 1.6493898540414789

Epoch: 6| Step: 10
Training loss: 0.06583011150360107
Validation loss: 1.618319470395324

Epoch: 6| Step: 11
Training loss: 0.10177003592252731
Validation loss: 1.6125554717997068

Epoch: 6| Step: 12
Training loss: 0.09746690839529037
Validation loss: 1.597412387530009

Epoch: 6| Step: 13
Training loss: 0.10059858858585358
Validation loss: 1.5985674563274588

Epoch: 436| Step: 0
Training loss: 0.11900332570075989
Validation loss: 1.5999410254980928

Epoch: 6| Step: 1
Training loss: 0.11040019243955612
Validation loss: 1.5833475948661886

Epoch: 6| Step: 2
Training loss: 0.08932867646217346
Validation loss: 1.5832246849613805

Epoch: 6| Step: 3
Training loss: 0.10443925857543945
Validation loss: 1.5796082340260988

Epoch: 6| Step: 4
Training loss: 0.10467079281806946
Validation loss: 1.5798694318340671

Epoch: 6| Step: 5
Training loss: 0.1003546416759491
Validation loss: 1.6060835687063073

Epoch: 6| Step: 6
Training loss: 0.0541861355304718
Validation loss: 1.5754681735910394

Epoch: 6| Step: 7
Training loss: 0.23990210890769958
Validation loss: 1.6263751778551327

Epoch: 6| Step: 8
Training loss: 0.07140345126390457
Validation loss: 1.616152572375472

Epoch: 6| Step: 9
Training loss: 0.07587650418281555
Validation loss: 1.6375620442052041

Epoch: 6| Step: 10
Training loss: 0.0898372083902359
Validation loss: 1.6276448048571104

Epoch: 6| Step: 11
Training loss: 0.06315208971500397
Validation loss: 1.612958522253139

Epoch: 6| Step: 12
Training loss: 0.059501685202121735
Validation loss: 1.629575132041849

Epoch: 6| Step: 13
Training loss: 0.13432112336158752
Validation loss: 1.604891405310682

Epoch: 437| Step: 0
Training loss: 0.10202163457870483
Validation loss: 1.6137055171433317

Epoch: 6| Step: 1
Training loss: 0.06970880925655365
Validation loss: 1.6318705037075987

Epoch: 6| Step: 2
Training loss: 0.0850066989660263
Validation loss: 1.6175290987055788

Epoch: 6| Step: 3
Training loss: 0.11959738284349442
Validation loss: 1.6305650536732008

Epoch: 6| Step: 4
Training loss: 0.05582181364297867
Validation loss: 1.6139578742365683

Epoch: 6| Step: 5
Training loss: 0.10574670135974884
Validation loss: 1.608875842504604

Epoch: 6| Step: 6
Training loss: 0.07218752801418304
Validation loss: 1.5831901822038876

Epoch: 6| Step: 7
Training loss: 0.0667506754398346
Validation loss: 1.5762844136966172

Epoch: 6| Step: 8
Training loss: 0.0974559336900711
Validation loss: 1.5669448612838663

Epoch: 6| Step: 9
Training loss: 0.23797762393951416
Validation loss: 1.574436782508768

Epoch: 6| Step: 10
Training loss: 0.08961409330368042
Validation loss: 1.5565898008244012

Epoch: 6| Step: 11
Training loss: 0.10930217802524567
Validation loss: 1.584596674929383

Epoch: 6| Step: 12
Training loss: 0.11712487787008286
Validation loss: 1.5611539707388928

Epoch: 6| Step: 13
Training loss: 0.07327406853437424
Validation loss: 1.577773263377528

Epoch: 438| Step: 0
Training loss: 0.12388557940721512
Validation loss: 1.602946545488091

Epoch: 6| Step: 1
Training loss: 0.0835881382226944
Validation loss: 1.6003989558066092

Epoch: 6| Step: 2
Training loss: 0.07039596140384674
Validation loss: 1.603730123530152

Epoch: 6| Step: 3
Training loss: 0.0793275535106659
Validation loss: 1.6181246349888463

Epoch: 6| Step: 4
Training loss: 0.07809904217720032
Validation loss: 1.6095375899345643

Epoch: 6| Step: 5
Training loss: 0.13203030824661255
Validation loss: 1.631794370630736

Epoch: 6| Step: 6
Training loss: 0.09411195665597916
Validation loss: 1.6195845693670294

Epoch: 6| Step: 7
Training loss: 0.08002837747335434
Validation loss: 1.629412514548148

Epoch: 6| Step: 8
Training loss: 0.08162236213684082
Validation loss: 1.637470196652156

Epoch: 6| Step: 9
Training loss: 0.07330954819917679
Validation loss: 1.6104583701779764

Epoch: 6| Step: 10
Training loss: 0.12104770541191101
Validation loss: 1.6185137097553541

Epoch: 6| Step: 11
Training loss: 0.13763776421546936
Validation loss: 1.5926161248196837

Epoch: 6| Step: 12
Training loss: 0.2190912663936615
Validation loss: 1.5866207115111812

Epoch: 6| Step: 13
Training loss: 0.09695858508348465
Validation loss: 1.5784699904021395

Epoch: 439| Step: 0
Training loss: 0.08206947147846222
Validation loss: 1.5631472000511744

Epoch: 6| Step: 1
Training loss: 0.09978610277175903
Validation loss: 1.5466796582744968

Epoch: 6| Step: 2
Training loss: 0.11745114624500275
Validation loss: 1.5598668770123554

Epoch: 6| Step: 3
Training loss: 0.0797356590628624
Validation loss: 1.569713210546842

Epoch: 6| Step: 4
Training loss: 0.09652872383594513
Validation loss: 1.5402212899218324

Epoch: 6| Step: 5
Training loss: 0.1259811371564865
Validation loss: 1.5825170445185837

Epoch: 6| Step: 6
Training loss: 0.07015809416770935
Validation loss: 1.5846608236271849

Epoch: 6| Step: 7
Training loss: 0.11596597731113434
Validation loss: 1.5727550701428485

Epoch: 6| Step: 8
Training loss: 0.11846933513879776
Validation loss: 1.5979366943400393

Epoch: 6| Step: 9
Training loss: 0.2492295205593109
Validation loss: 1.5935793166519494

Epoch: 6| Step: 10
Training loss: 0.06214828044176102
Validation loss: 1.620409756578425

Epoch: 6| Step: 11
Training loss: 0.1216532438993454
Validation loss: 1.633650400305307

Epoch: 6| Step: 12
Training loss: 0.11527779698371887
Validation loss: 1.6420960041784471

Epoch: 6| Step: 13
Training loss: 0.07673469930887222
Validation loss: 1.6299416313889206

Epoch: 440| Step: 0
Training loss: 0.11741520464420319
Validation loss: 1.6525290653269777

Epoch: 6| Step: 1
Training loss: 0.0893101915717125
Validation loss: 1.6513941416176416

Epoch: 6| Step: 2
Training loss: 0.11023316532373428
Validation loss: 1.6238629664144208

Epoch: 6| Step: 3
Training loss: 0.0903775691986084
Validation loss: 1.6069221637582267

Epoch: 6| Step: 4
Training loss: 0.06862448155879974
Validation loss: 1.5979518441743747

Epoch: 6| Step: 5
Training loss: 0.11532192677259445
Validation loss: 1.6177726291841077

Epoch: 6| Step: 6
Training loss: 0.09488718211650848
Validation loss: 1.5818856711028724

Epoch: 6| Step: 7
Training loss: 0.08347585052251816
Validation loss: 1.5808368062460294

Epoch: 6| Step: 8
Training loss: 0.22624576091766357
Validation loss: 1.601875409003227

Epoch: 6| Step: 9
Training loss: 0.11459696292877197
Validation loss: 1.5942188514176237

Epoch: 6| Step: 10
Training loss: 0.1298363208770752
Validation loss: 1.6055277451392143

Epoch: 6| Step: 11
Training loss: 0.08327476680278778
Validation loss: 1.610958791548206

Epoch: 6| Step: 12
Training loss: 0.05348190665245056
Validation loss: 1.5995265770983953

Epoch: 6| Step: 13
Training loss: 0.08567755669355392
Validation loss: 1.6082346497043487

Epoch: 441| Step: 0
Training loss: 0.061995744705200195
Validation loss: 1.6045027663630824

Epoch: 6| Step: 1
Training loss: 0.08206263184547424
Validation loss: 1.58821556773237

Epoch: 6| Step: 2
Training loss: 0.09735267609357834
Validation loss: 1.5583380601739372

Epoch: 6| Step: 3
Training loss: 0.08333152532577515
Validation loss: 1.5679711923804334

Epoch: 6| Step: 4
Training loss: 0.06785406172275543
Validation loss: 1.5793488769121067

Epoch: 6| Step: 5
Training loss: 0.06869950890541077
Validation loss: 1.588561773300171

Epoch: 6| Step: 6
Training loss: 0.10546000301837921
Validation loss: 1.590190690050843

Epoch: 6| Step: 7
Training loss: 0.11790536344051361
Validation loss: 1.5891341573448592

Epoch: 6| Step: 8
Training loss: 0.0500209778547287
Validation loss: 1.5667380312437653

Epoch: 6| Step: 9
Training loss: 0.08548307418823242
Validation loss: 1.590890920290383

Epoch: 6| Step: 10
Training loss: 0.047519221901893616
Validation loss: 1.5847684862793132

Epoch: 6| Step: 11
Training loss: 0.11481583118438721
Validation loss: 1.584338991872726

Epoch: 6| Step: 12
Training loss: 0.11144242435693741
Validation loss: 1.6048426756294825

Epoch: 6| Step: 13
Training loss: 0.3571091294288635
Validation loss: 1.5866031313455233

Epoch: 442| Step: 0
Training loss: 0.07411643862724304
Validation loss: 1.5850195961613809

Epoch: 6| Step: 1
Training loss: 0.05811616778373718
Validation loss: 1.5978975860021447

Epoch: 6| Step: 2
Training loss: 0.08308082818984985
Validation loss: 1.6054321553117485

Epoch: 6| Step: 3
Training loss: 0.2075159251689911
Validation loss: 1.6231173007718978

Epoch: 6| Step: 4
Training loss: 0.11244785785675049
Validation loss: 1.638776352328639

Epoch: 6| Step: 5
Training loss: 0.09880319237709045
Validation loss: 1.5936741367463143

Epoch: 6| Step: 6
Training loss: 0.08463557064533234
Validation loss: 1.6117170824799487

Epoch: 6| Step: 7
Training loss: 0.12231434136629105
Validation loss: 1.616590828023931

Epoch: 6| Step: 8
Training loss: 0.08859443664550781
Validation loss: 1.5917860641274402

Epoch: 6| Step: 9
Training loss: 0.11773203313350677
Validation loss: 1.6165255500424294

Epoch: 6| Step: 10
Training loss: 0.1680275797843933
Validation loss: 1.6064017024091495

Epoch: 6| Step: 11
Training loss: 0.1255393773317337
Validation loss: 1.5838152772636824

Epoch: 6| Step: 12
Training loss: 0.13577285408973694
Validation loss: 1.5966974484023226

Epoch: 6| Step: 13
Training loss: 0.11234605312347412
Validation loss: 1.591431599791332

Epoch: 443| Step: 0
Training loss: 0.12577781081199646
Validation loss: 1.5674388985480032

Epoch: 6| Step: 1
Training loss: 0.10010108351707458
Validation loss: 1.586727362807079

Epoch: 6| Step: 2
Training loss: 0.2139701247215271
Validation loss: 1.6105865483642907

Epoch: 6| Step: 3
Training loss: 0.09718649089336395
Validation loss: 1.6079856836667625

Epoch: 6| Step: 4
Training loss: 0.11904746294021606
Validation loss: 1.6172460561157556

Epoch: 6| Step: 5
Training loss: 0.09847741574048996
Validation loss: 1.630712483518867

Epoch: 6| Step: 6
Training loss: 0.12535922229290009
Validation loss: 1.631674417885401

Epoch: 6| Step: 7
Training loss: 0.1004994809627533
Validation loss: 1.6240750948588054

Epoch: 6| Step: 8
Training loss: 0.10297942161560059
Validation loss: 1.6117683892608972

Epoch: 6| Step: 9
Training loss: 0.0655902773141861
Validation loss: 1.617821922866247

Epoch: 6| Step: 10
Training loss: 0.12536445260047913
Validation loss: 1.6215431356942782

Epoch: 6| Step: 11
Training loss: 0.0905352383852005
Validation loss: 1.6296288838950537

Epoch: 6| Step: 12
Training loss: 0.1075749546289444
Validation loss: 1.6041924402277956

Epoch: 6| Step: 13
Training loss: 0.16132251918315887
Validation loss: 1.616182734889369

Epoch: 444| Step: 0
Training loss: 0.10457074642181396
Validation loss: 1.5793499831230409

Epoch: 6| Step: 1
Training loss: 0.10552096366882324
Validation loss: 1.571702448270654

Epoch: 6| Step: 2
Training loss: 0.08142565190792084
Validation loss: 1.5732601945118239

Epoch: 6| Step: 3
Training loss: 0.05207304283976555
Validation loss: 1.5789398865033222

Epoch: 6| Step: 4
Training loss: 0.07526198029518127
Validation loss: 1.545762800401257

Epoch: 6| Step: 5
Training loss: 0.079777792096138
Validation loss: 1.5518616014911282

Epoch: 6| Step: 6
Training loss: 0.10084483027458191
Validation loss: 1.6022792086806348

Epoch: 6| Step: 7
Training loss: 0.0934586226940155
Validation loss: 1.586054059766954

Epoch: 6| Step: 8
Training loss: 0.08672648668289185
Validation loss: 1.5929076594691123

Epoch: 6| Step: 9
Training loss: 0.07518270611763
Validation loss: 1.586273354868735

Epoch: 6| Step: 10
Training loss: 0.07461823523044586
Validation loss: 1.6081409941437423

Epoch: 6| Step: 11
Training loss: 0.08518942445516586
Validation loss: 1.618160573385095

Epoch: 6| Step: 12
Training loss: 0.0988660529255867
Validation loss: 1.622016232500794

Epoch: 6| Step: 13
Training loss: 0.4204920530319214
Validation loss: 1.61890830404015

Epoch: 445| Step: 0
Training loss: 0.09728069603443146
Validation loss: 1.6210370371418614

Epoch: 6| Step: 1
Training loss: 0.13310782611370087
Validation loss: 1.6173734870008243

Epoch: 6| Step: 2
Training loss: 0.08149860799312592
Validation loss: 1.5950685470334944

Epoch: 6| Step: 3
Training loss: 0.07108044624328613
Validation loss: 1.6101652691441197

Epoch: 6| Step: 4
Training loss: 0.07180830091238022
Validation loss: 1.6045640591652162

Epoch: 6| Step: 5
Training loss: 0.09223870933055878
Validation loss: 1.6215281015442264

Epoch: 6| Step: 6
Training loss: 0.0662614107131958
Validation loss: 1.6050026647506221

Epoch: 6| Step: 7
Training loss: 0.11391128599643707
Validation loss: 1.633024513721466

Epoch: 6| Step: 8
Training loss: 0.21933074295520782
Validation loss: 1.606264127198086

Epoch: 6| Step: 9
Training loss: 0.08367147296667099
Validation loss: 1.6048035852370723

Epoch: 6| Step: 10
Training loss: 0.04660592973232269
Validation loss: 1.5690349122529388

Epoch: 6| Step: 11
Training loss: 0.08100667595863342
Validation loss: 1.5744730003418461

Epoch: 6| Step: 12
Training loss: 0.04647710174322128
Validation loss: 1.5941553436299807

Epoch: 6| Step: 13
Training loss: 0.06282988935709
Validation loss: 1.6003892139721942

Epoch: 446| Step: 0
Training loss: 0.06041111797094345
Validation loss: 1.5881147333370742

Epoch: 6| Step: 1
Training loss: 0.21438831090927124
Validation loss: 1.6041174434846448

Epoch: 6| Step: 2
Training loss: 0.08353210985660553
Validation loss: 1.597104577608006

Epoch: 6| Step: 3
Training loss: 0.0538351871073246
Validation loss: 1.6011469389802666

Epoch: 6| Step: 4
Training loss: 0.1273532509803772
Validation loss: 1.6000394705803163

Epoch: 6| Step: 5
Training loss: 0.08918371796607971
Validation loss: 1.6202514351055186

Epoch: 6| Step: 6
Training loss: 0.09126351773738861
Validation loss: 1.63071197079074

Epoch: 6| Step: 7
Training loss: 0.0871967002749443
Validation loss: 1.6143326656792754

Epoch: 6| Step: 8
Training loss: 0.11106757819652557
Validation loss: 1.6303853604101366

Epoch: 6| Step: 9
Training loss: 0.07951615750789642
Validation loss: 1.6145942429060578

Epoch: 6| Step: 10
Training loss: 0.09655178338289261
Validation loss: 1.5889845163591447

Epoch: 6| Step: 11
Training loss: 0.061941713094711304
Validation loss: 1.625447678309615

Epoch: 6| Step: 12
Training loss: 0.06316424161195755
Validation loss: 1.59802447852268

Epoch: 6| Step: 13
Training loss: 0.130568265914917
Validation loss: 1.6136578988003474

Epoch: 447| Step: 0
Training loss: 0.08145991712808609
Validation loss: 1.606625239054362

Epoch: 6| Step: 1
Training loss: 0.06134895607829094
Validation loss: 1.6252931510248492

Epoch: 6| Step: 2
Training loss: 0.09843041747808456
Validation loss: 1.6142108491671983

Epoch: 6| Step: 3
Training loss: 0.08385763317346573
Validation loss: 1.649341384569804

Epoch: 6| Step: 4
Training loss: 0.09753533452749252
Validation loss: 1.645275136475922

Epoch: 6| Step: 5
Training loss: 0.1277000904083252
Validation loss: 1.649899664745536

Epoch: 6| Step: 6
Training loss: 0.10656215995550156
Validation loss: 1.6379331363144742

Epoch: 6| Step: 7
Training loss: 0.061237603425979614
Validation loss: 1.6425265548049763

Epoch: 6| Step: 8
Training loss: 0.06299710273742676
Validation loss: 1.646806078572427

Epoch: 6| Step: 9
Training loss: 0.08519434183835983
Validation loss: 1.664358474875009

Epoch: 6| Step: 10
Training loss: 0.1077621579170227
Validation loss: 1.6532806209338609

Epoch: 6| Step: 11
Training loss: 0.2322101593017578
Validation loss: 1.6462602974266134

Epoch: 6| Step: 12
Training loss: 0.10048016160726547
Validation loss: 1.6278347956236972

Epoch: 6| Step: 13
Training loss: 0.14738744497299194
Validation loss: 1.6543669008439588

Epoch: 448| Step: 0
Training loss: 0.0377148762345314
Validation loss: 1.6563694618081535

Epoch: 6| Step: 1
Training loss: 0.12221461534500122
Validation loss: 1.6708211052802302

Epoch: 6| Step: 2
Training loss: 0.05975377559661865
Validation loss: 1.6543449022436654

Epoch: 6| Step: 3
Training loss: 0.11081578582525253
Validation loss: 1.6389044504011832

Epoch: 6| Step: 4
Training loss: 0.06800376623868942
Validation loss: 1.659369780171302

Epoch: 6| Step: 5
Training loss: 0.06749803572893143
Validation loss: 1.643309667546262

Epoch: 6| Step: 6
Training loss: 0.0956045389175415
Validation loss: 1.6546073459809827

Epoch: 6| Step: 7
Training loss: 0.08333148807287216
Validation loss: 1.6534143083839006

Epoch: 6| Step: 8
Training loss: 0.08131532371044159
Validation loss: 1.6540164409145233

Epoch: 6| Step: 9
Training loss: 0.2140292227268219
Validation loss: 1.6377475671870734

Epoch: 6| Step: 10
Training loss: 0.06252673268318176
Validation loss: 1.645888884862264

Epoch: 6| Step: 11
Training loss: 0.08474696427583694
Validation loss: 1.629055735885456

Epoch: 6| Step: 12
Training loss: 0.09699428081512451
Validation loss: 1.617645707181705

Epoch: 6| Step: 13
Training loss: 0.0668850764632225
Validation loss: 1.628088729355925

Epoch: 449| Step: 0
Training loss: 0.23224839568138123
Validation loss: 1.590739341192348

Epoch: 6| Step: 1
Training loss: 0.05868007615208626
Validation loss: 1.6175529072361607

Epoch: 6| Step: 2
Training loss: 0.07028314471244812
Validation loss: 1.6111779392406504

Epoch: 6| Step: 3
Training loss: 0.06476977467536926
Validation loss: 1.6000229363800378

Epoch: 6| Step: 4
Training loss: 0.11671862006187439
Validation loss: 1.6012706538682342

Epoch: 6| Step: 5
Training loss: 0.037942465394735336
Validation loss: 1.5890103950295398

Epoch: 6| Step: 6
Training loss: 0.04986106976866722
Validation loss: 1.6349056254151046

Epoch: 6| Step: 7
Training loss: 0.07766605168581009
Validation loss: 1.6247986805054448

Epoch: 6| Step: 8
Training loss: 0.06200091540813446
Validation loss: 1.6237729646826302

Epoch: 6| Step: 9
Training loss: 0.05694924294948578
Validation loss: 1.638429545587109

Epoch: 6| Step: 10
Training loss: 0.07522201538085938
Validation loss: 1.625612155083687

Epoch: 6| Step: 11
Training loss: 0.06618459522724152
Validation loss: 1.6345099967013124

Epoch: 6| Step: 12
Training loss: 0.07736818492412567
Validation loss: 1.6273137843737038

Epoch: 6| Step: 13
Training loss: 0.0516977459192276
Validation loss: 1.61615034585358

Epoch: 450| Step: 0
Training loss: 0.039022281765937805
Validation loss: 1.6571335459268222

Epoch: 6| Step: 1
Training loss: 0.11194826662540436
Validation loss: 1.6506535532653972

Epoch: 6| Step: 2
Training loss: 0.07888014614582062
Validation loss: 1.607642581385951

Epoch: 6| Step: 3
Training loss: 0.11022162437438965
Validation loss: 1.6044077309229041

Epoch: 6| Step: 4
Training loss: 0.1103254035115242
Validation loss: 1.6076757395139305

Epoch: 6| Step: 5
Training loss: 0.123216912150383
Validation loss: 1.5569405735179942

Epoch: 6| Step: 6
Training loss: 0.1227237731218338
Validation loss: 1.5619871654818136

Epoch: 6| Step: 7
Training loss: 0.10689738392829895
Validation loss: 1.5809666995079286

Epoch: 6| Step: 8
Training loss: 0.06342373788356781
Validation loss: 1.6001364723328622

Epoch: 6| Step: 9
Training loss: 0.06877574324607849
Validation loss: 1.5985591373135966

Epoch: 6| Step: 10
Training loss: 0.06666693836450577
Validation loss: 1.6054627356990692

Epoch: 6| Step: 11
Training loss: 0.09795796871185303
Validation loss: 1.6178393069133963

Epoch: 6| Step: 12
Training loss: 0.21017441153526306
Validation loss: 1.6376139476735105

Epoch: 6| Step: 13
Training loss: 0.11216999590396881
Validation loss: 1.6413537738143757

Epoch: 451| Step: 0
Training loss: 0.07698085159063339
Validation loss: 1.634398801352388

Epoch: 6| Step: 1
Training loss: 0.23511317372322083
Validation loss: 1.6207084412215857

Epoch: 6| Step: 2
Training loss: 0.04591429978609085
Validation loss: 1.6241606461104525

Epoch: 6| Step: 3
Training loss: 0.057838838547468185
Validation loss: 1.632078334849368

Epoch: 6| Step: 4
Training loss: 0.0966603010892868
Validation loss: 1.6000925661415182

Epoch: 6| Step: 5
Training loss: 0.10865191370248795
Validation loss: 1.5883945739397438

Epoch: 6| Step: 6
Training loss: 0.09783274680376053
Validation loss: 1.572680466918535

Epoch: 6| Step: 7
Training loss: 0.10549239069223404
Validation loss: 1.6011143807441957

Epoch: 6| Step: 8
Training loss: 0.07435838133096695
Validation loss: 1.591166067507959

Epoch: 6| Step: 9
Training loss: 0.06775154173374176
Validation loss: 1.5902275975032518

Epoch: 6| Step: 10
Training loss: 0.10496988892555237
Validation loss: 1.5757697679663216

Epoch: 6| Step: 11
Training loss: 0.05749212205410004
Validation loss: 1.612083806786486

Epoch: 6| Step: 12
Training loss: 0.11351229250431061
Validation loss: 1.621357503757682

Epoch: 6| Step: 13
Training loss: 0.08772221952676773
Validation loss: 1.632885088202774

Epoch: 452| Step: 0
Training loss: 0.1032886803150177
Validation loss: 1.6184850585076116

Epoch: 6| Step: 1
Training loss: 0.06580955535173416
Validation loss: 1.6365377723529775

Epoch: 6| Step: 2
Training loss: 0.06949935108423233
Validation loss: 1.6169700596922187

Epoch: 6| Step: 3
Training loss: 0.054954931139945984
Validation loss: 1.635775314864292

Epoch: 6| Step: 4
Training loss: 0.06646005809307098
Validation loss: 1.60504017337676

Epoch: 6| Step: 5
Training loss: 0.08921549469232559
Validation loss: 1.6076165527425788

Epoch: 6| Step: 6
Training loss: 0.0707685798406601
Validation loss: 1.620341016400245

Epoch: 6| Step: 7
Training loss: 0.046982862055301666
Validation loss: 1.611017393809493

Epoch: 6| Step: 8
Training loss: 0.216851145029068
Validation loss: 1.580012688713689

Epoch: 6| Step: 9
Training loss: 0.10488253831863403
Validation loss: 1.5767744946223434

Epoch: 6| Step: 10
Training loss: 0.05291670188307762
Validation loss: 1.5872392410873084

Epoch: 6| Step: 11
Training loss: 0.08868047595024109
Validation loss: 1.5871776380846578

Epoch: 6| Step: 12
Training loss: 0.07397948205471039
Validation loss: 1.5852762934982136

Epoch: 6| Step: 13
Training loss: 0.09065359085798264
Validation loss: 1.575853963052073

Epoch: 453| Step: 0
Training loss: 0.05733700096607208
Validation loss: 1.5997529170846427

Epoch: 6| Step: 1
Training loss: 0.11487695574760437
Validation loss: 1.6063932180404663

Epoch: 6| Step: 2
Training loss: 0.062446229159832
Validation loss: 1.5955459610108407

Epoch: 6| Step: 3
Training loss: 0.07898180186748505
Validation loss: 1.6131503223091044

Epoch: 6| Step: 4
Training loss: 0.04204230383038521
Validation loss: 1.6192746188050957

Epoch: 6| Step: 5
Training loss: 0.23899082839488983
Validation loss: 1.595971284374114

Epoch: 6| Step: 6
Training loss: 0.06189584732055664
Validation loss: 1.6233196745636642

Epoch: 6| Step: 7
Training loss: 0.07124374806880951
Validation loss: 1.5987112573398057

Epoch: 6| Step: 8
Training loss: 0.10510087758302689
Validation loss: 1.5826296396152948

Epoch: 6| Step: 9
Training loss: 0.118846595287323
Validation loss: 1.58263393755882

Epoch: 6| Step: 10
Training loss: 0.08744563907384872
Validation loss: 1.5968814998544671

Epoch: 6| Step: 11
Training loss: 0.11249177902936935
Validation loss: 1.5881812085387528

Epoch: 6| Step: 12
Training loss: 0.06321009993553162
Validation loss: 1.5812391850256151

Epoch: 6| Step: 13
Training loss: 0.08111508935689926
Validation loss: 1.595387880520154

Epoch: 454| Step: 0
Training loss: 0.08118029683828354
Validation loss: 1.5740139445950907

Epoch: 6| Step: 1
Training loss: 0.08752734959125519
Validation loss: 1.588523764764109

Epoch: 6| Step: 2
Training loss: 0.06383109837770462
Validation loss: 1.6054818860946163

Epoch: 6| Step: 3
Training loss: 0.058191508054733276
Validation loss: 1.6019667387008667

Epoch: 6| Step: 4
Training loss: 0.21716436743736267
Validation loss: 1.610797211688052

Epoch: 6| Step: 5
Training loss: 0.09711191058158875
Validation loss: 1.6075578043537755

Epoch: 6| Step: 6
Training loss: 0.07896435260772705
Validation loss: 1.6147711200098838

Epoch: 6| Step: 7
Training loss: 0.04033008590340614
Validation loss: 1.615353302289081

Epoch: 6| Step: 8
Training loss: 0.14035485684871674
Validation loss: 1.5939512727081135

Epoch: 6| Step: 9
Training loss: 0.06418150663375854
Validation loss: 1.6076704737960652

Epoch: 6| Step: 10
Training loss: 0.11665690690279007
Validation loss: 1.5924736376731627

Epoch: 6| Step: 11
Training loss: 0.05608849972486496
Validation loss: 1.599537093152282

Epoch: 6| Step: 12
Training loss: 0.05322520434856415
Validation loss: 1.5955977503971388

Epoch: 6| Step: 13
Training loss: 0.02789124846458435
Validation loss: 1.5922446199642715

Epoch: 455| Step: 0
Training loss: 0.07530447840690613
Validation loss: 1.6086550348548478

Epoch: 6| Step: 1
Training loss: 0.04789448529481888
Validation loss: 1.5994137064103158

Epoch: 6| Step: 2
Training loss: 0.07663371413946152
Validation loss: 1.5769052031219646

Epoch: 6| Step: 3
Training loss: 0.09096066653728485
Validation loss: 1.591809521439255

Epoch: 6| Step: 4
Training loss: 0.046945229172706604
Validation loss: 1.5866866906483967

Epoch: 6| Step: 5
Training loss: 0.08303604274988174
Validation loss: 1.5886539477174

Epoch: 6| Step: 6
Training loss: 0.06357478350400925
Validation loss: 1.5965167232739028

Epoch: 6| Step: 7
Training loss: 0.24653993546962738
Validation loss: 1.5791401023505836

Epoch: 6| Step: 8
Training loss: 0.0876510888338089
Validation loss: 1.5852239849746868

Epoch: 6| Step: 9
Training loss: 0.05362989753484726
Validation loss: 1.621750617540011

Epoch: 6| Step: 10
Training loss: 0.07884493470191956
Validation loss: 1.606509062551683

Epoch: 6| Step: 11
Training loss: 0.09808427095413208
Validation loss: 1.6303367576291483

Epoch: 6| Step: 12
Training loss: 0.0837244987487793
Validation loss: 1.6176032763655468

Epoch: 6| Step: 13
Training loss: 0.0749782845377922
Validation loss: 1.6233254812097038

Epoch: 456| Step: 0
Training loss: 0.06135886162519455
Validation loss: 1.6253345269028858

Epoch: 6| Step: 1
Training loss: 0.09786134958267212
Validation loss: 1.6489968428047754

Epoch: 6| Step: 2
Training loss: 0.08727823197841644
Validation loss: 1.636553265715158

Epoch: 6| Step: 3
Training loss: 0.08791529387235641
Validation loss: 1.6297787043356127

Epoch: 6| Step: 4
Training loss: 0.08575625717639923
Validation loss: 1.6554243859424387

Epoch: 6| Step: 5
Training loss: 0.08135674148797989
Validation loss: 1.6490713511743853

Epoch: 6| Step: 6
Training loss: 0.09967109560966492
Validation loss: 1.6593369758257301

Epoch: 6| Step: 7
Training loss: 0.06657729297876358
Validation loss: 1.6583075010648338

Epoch: 6| Step: 8
Training loss: 0.06439925730228424
Validation loss: 1.649066420011623

Epoch: 6| Step: 9
Training loss: 0.10141786932945251
Validation loss: 1.6348631023078837

Epoch: 6| Step: 10
Training loss: 0.24840964376926422
Validation loss: 1.6032399862043318

Epoch: 6| Step: 11
Training loss: 0.09816168993711472
Validation loss: 1.6151325984667706

Epoch: 6| Step: 12
Training loss: 0.05235502868890762
Validation loss: 1.6014242402968868

Epoch: 6| Step: 13
Training loss: 0.06584778428077698
Validation loss: 1.6172471853994554

Epoch: 457| Step: 0
Training loss: 0.07386380434036255
Validation loss: 1.59209817840207

Epoch: 6| Step: 1
Training loss: 0.08441315591335297
Validation loss: 1.6155910876489454

Epoch: 6| Step: 2
Training loss: 0.12103921920061111
Validation loss: 1.6182077059181788

Epoch: 6| Step: 3
Training loss: 0.14957614243030548
Validation loss: 1.6544571230488438

Epoch: 6| Step: 4
Training loss: 0.21404686570167542
Validation loss: 1.6424210122836533

Epoch: 6| Step: 5
Training loss: 0.10893786698579788
Validation loss: 1.6524118441407398

Epoch: 6| Step: 6
Training loss: 0.12584716081619263
Validation loss: 1.6527470837357223

Epoch: 6| Step: 7
Training loss: 0.14135867357254028
Validation loss: 1.655643609262282

Epoch: 6| Step: 8
Training loss: 0.1017841175198555
Validation loss: 1.6450611250374907

Epoch: 6| Step: 9
Training loss: 0.07963798195123672
Validation loss: 1.6223585080075007

Epoch: 6| Step: 10
Training loss: 0.06173276901245117
Validation loss: 1.5856746627438454

Epoch: 6| Step: 11
Training loss: 0.0868491530418396
Validation loss: 1.5752375920613606

Epoch: 6| Step: 12
Training loss: 0.08617611229419708
Validation loss: 1.572101386644507

Epoch: 6| Step: 13
Training loss: 0.1492236703634262
Validation loss: 1.537138847894566

Epoch: 458| Step: 0
Training loss: 0.06531831622123718
Validation loss: 1.5602169036865234

Epoch: 6| Step: 1
Training loss: 0.08974473178386688
Validation loss: 1.5693912294603163

Epoch: 6| Step: 2
Training loss: 0.18767526745796204
Validation loss: 1.577489532450194

Epoch: 6| Step: 3
Training loss: 0.09698247164487839
Validation loss: 1.6091184475088631

Epoch: 6| Step: 4
Training loss: 0.20900912582874298
Validation loss: 1.6270015688352688

Epoch: 6| Step: 5
Training loss: 0.09374594688415527
Validation loss: 1.630345904698936

Epoch: 6| Step: 6
Training loss: 0.11693750321865082
Validation loss: 1.6210684276396228

Epoch: 6| Step: 7
Training loss: 0.08492539823055267
Validation loss: 1.6217178888218378

Epoch: 6| Step: 8
Training loss: 0.04000221937894821
Validation loss: 1.6139219563494447

Epoch: 6| Step: 9
Training loss: 0.07574373483657837
Validation loss: 1.6364000535780383

Epoch: 6| Step: 10
Training loss: 0.16172786056995392
Validation loss: 1.6035192422969367

Epoch: 6| Step: 11
Training loss: 0.0703953206539154
Validation loss: 1.6090203536454069

Epoch: 6| Step: 12
Training loss: 0.06093265116214752
Validation loss: 1.5780867107452885

Epoch: 6| Step: 13
Training loss: 0.12049777060747147
Validation loss: 1.571960283863929

Epoch: 459| Step: 0
Training loss: 0.08712561428546906
Validation loss: 1.5518943430275045

Epoch: 6| Step: 1
Training loss: 0.07967990636825562
Validation loss: 1.5581077901265954

Epoch: 6| Step: 2
Training loss: 0.09873104840517044
Validation loss: 1.5375525348929948

Epoch: 6| Step: 3
Training loss: 0.07979230582714081
Validation loss: 1.546956330217341

Epoch: 6| Step: 4
Training loss: 0.07888312637805939
Validation loss: 1.565673009041817

Epoch: 6| Step: 5
Training loss: 0.08789384365081787
Validation loss: 1.5386076383693243

Epoch: 6| Step: 6
Training loss: 0.06985296308994293
Validation loss: 1.5617302053718156

Epoch: 6| Step: 7
Training loss: 0.08038334548473358
Validation loss: 1.5726326716843473

Epoch: 6| Step: 8
Training loss: 0.24536040425300598
Validation loss: 1.5776521954485165

Epoch: 6| Step: 9
Training loss: 0.09116116166114807
Validation loss: 1.5699022021344913

Epoch: 6| Step: 10
Training loss: 0.07044491171836853
Validation loss: 1.5899031726262902

Epoch: 6| Step: 11
Training loss: 0.0865192711353302
Validation loss: 1.589390448344651

Epoch: 6| Step: 12
Training loss: 0.11042861640453339
Validation loss: 1.5974314674254386

Epoch: 6| Step: 13
Training loss: 0.04079961031675339
Validation loss: 1.5970265660234677

Epoch: 460| Step: 0
Training loss: 0.03189105540513992
Validation loss: 1.5859913800352363

Epoch: 6| Step: 1
Training loss: 0.05706649273633957
Validation loss: 1.5772269669399466

Epoch: 6| Step: 2
Training loss: 0.06266852468252182
Validation loss: 1.5808537820334077

Epoch: 6| Step: 3
Training loss: 0.08989045768976212
Validation loss: 1.5818307797114055

Epoch: 6| Step: 4
Training loss: 0.07713232189416885
Validation loss: 1.5984099212513174

Epoch: 6| Step: 5
Training loss: 0.08552485704421997
Validation loss: 1.571493003958015

Epoch: 6| Step: 6
Training loss: 0.08231133967638016
Validation loss: 1.5816205855338805

Epoch: 6| Step: 7
Training loss: 0.10320968925952911
Validation loss: 1.6003472394840692

Epoch: 6| Step: 8
Training loss: 0.0848788246512413
Validation loss: 1.562420723258808

Epoch: 6| Step: 9
Training loss: 0.13239911198616028
Validation loss: 1.565511380472491

Epoch: 6| Step: 10
Training loss: 0.0861993134021759
Validation loss: 1.5374944197234286

Epoch: 6| Step: 11
Training loss: 0.04806263744831085
Validation loss: 1.5814213034927205

Epoch: 6| Step: 12
Training loss: 0.20403972268104553
Validation loss: 1.567908606221599

Epoch: 6| Step: 13
Training loss: 0.06987109780311584
Validation loss: 1.5537140266869658

Epoch: 461| Step: 0
Training loss: 0.08635015040636063
Validation loss: 1.5652452194562523

Epoch: 6| Step: 1
Training loss: 0.13609877228736877
Validation loss: 1.5653704789377028

Epoch: 6| Step: 2
Training loss: 0.05328621715307236
Validation loss: 1.5686296416867165

Epoch: 6| Step: 3
Training loss: 0.08703383803367615
Validation loss: 1.56076475369033

Epoch: 6| Step: 4
Training loss: 0.23713397979736328
Validation loss: 1.5999734658066944

Epoch: 6| Step: 5
Training loss: 0.08342060446739197
Validation loss: 1.6207292669562883

Epoch: 6| Step: 6
Training loss: 0.08193623274564743
Validation loss: 1.610064205302987

Epoch: 6| Step: 7
Training loss: 0.08353286981582642
Validation loss: 1.6261044804767897

Epoch: 6| Step: 8
Training loss: 0.13316267728805542
Validation loss: 1.6362458980211647

Epoch: 6| Step: 9
Training loss: 0.12213566154241562
Validation loss: 1.6183267536983694

Epoch: 6| Step: 10
Training loss: 0.0768561139702797
Validation loss: 1.6345805839825702

Epoch: 6| Step: 11
Training loss: 0.10501670092344284
Validation loss: 1.6268315443428614

Epoch: 6| Step: 12
Training loss: 0.060887668281793594
Validation loss: 1.61038464115512

Epoch: 6| Step: 13
Training loss: 0.08354813605546951
Validation loss: 1.6052803993225098

Epoch: 462| Step: 0
Training loss: 0.12062966823577881
Validation loss: 1.6054691364688258

Epoch: 6| Step: 1
Training loss: 0.041389308869838715
Validation loss: 1.6056285981209046

Epoch: 6| Step: 2
Training loss: 0.051382385194301605
Validation loss: 1.5838580964713969

Epoch: 6| Step: 3
Training loss: 0.07190755009651184
Validation loss: 1.609907095150281

Epoch: 6| Step: 4
Training loss: 0.03994622826576233
Validation loss: 1.6180343499747656

Epoch: 6| Step: 5
Training loss: 0.1697358936071396
Validation loss: 1.604063509612955

Epoch: 6| Step: 6
Training loss: 0.05754828825592995
Validation loss: 1.6102939344221545

Epoch: 6| Step: 7
Training loss: 0.04577673226594925
Validation loss: 1.599323977706253

Epoch: 6| Step: 8
Training loss: 0.06744961440563202
Validation loss: 1.6028222935174101

Epoch: 6| Step: 9
Training loss: 0.10263462364673615
Validation loss: 1.6017216572197535

Epoch: 6| Step: 10
Training loss: 0.08357415348291397
Validation loss: 1.620174902741627

Epoch: 6| Step: 11
Training loss: 0.0970003679394722
Validation loss: 1.6222135315659225

Epoch: 6| Step: 12
Training loss: 0.09764265269041061
Validation loss: 1.6289591609790761

Epoch: 6| Step: 13
Training loss: 0.07272715121507645
Validation loss: 1.634746290022327

Epoch: 463| Step: 0
Training loss: 0.04901092126965523
Validation loss: 1.6333681562895417

Epoch: 6| Step: 1
Training loss: 0.05960837006568909
Validation loss: 1.6418623167981383

Epoch: 6| Step: 2
Training loss: 0.07077016681432724
Validation loss: 1.633283197238881

Epoch: 6| Step: 3
Training loss: 0.0877685621380806
Validation loss: 1.632330806024613

Epoch: 6| Step: 4
Training loss: 0.08240129053592682
Validation loss: 1.639902469932392

Epoch: 6| Step: 5
Training loss: 0.05142073333263397
Validation loss: 1.6243676190735192

Epoch: 6| Step: 6
Training loss: 0.059347331523895264
Validation loss: 1.5997352036096717

Epoch: 6| Step: 7
Training loss: 0.045960433781147
Validation loss: 1.5942382453590311

Epoch: 6| Step: 8
Training loss: 0.07765308767557144
Validation loss: 1.5942956286091958

Epoch: 6| Step: 9
Training loss: 0.0870007872581482
Validation loss: 1.6029276873475762

Epoch: 6| Step: 10
Training loss: 0.11151450872421265
Validation loss: 1.6009622235451975

Epoch: 6| Step: 11
Training loss: 0.11075477302074432
Validation loss: 1.6280908738413165

Epoch: 6| Step: 12
Training loss: 0.08034957200288773
Validation loss: 1.6257832973234114

Epoch: 6| Step: 13
Training loss: 0.3665446639060974
Validation loss: 1.627523382504781

Epoch: 464| Step: 0
Training loss: 0.25305309891700745
Validation loss: 1.6049770501352125

Epoch: 6| Step: 1
Training loss: 0.08090832829475403
Validation loss: 1.6121363255285448

Epoch: 6| Step: 2
Training loss: 0.07796607911586761
Validation loss: 1.6121566167441748

Epoch: 6| Step: 3
Training loss: 0.07246974855661392
Validation loss: 1.6117993003578597

Epoch: 6| Step: 4
Training loss: 0.11742548644542694
Validation loss: 1.6211400487089669

Epoch: 6| Step: 5
Training loss: 0.07649800181388855
Validation loss: 1.5820693751817108

Epoch: 6| Step: 6
Training loss: 0.10622285306453705
Validation loss: 1.5972336453776206

Epoch: 6| Step: 7
Training loss: 0.08191811293363571
Validation loss: 1.6117283746760378

Epoch: 6| Step: 8
Training loss: 0.08006782829761505
Validation loss: 1.597598841113429

Epoch: 6| Step: 9
Training loss: 0.09957621246576309
Validation loss: 1.5875583105189826

Epoch: 6| Step: 10
Training loss: 0.06291353702545166
Validation loss: 1.5897061914526007

Epoch: 6| Step: 11
Training loss: 0.07860533893108368
Validation loss: 1.5955257146589217

Epoch: 6| Step: 12
Training loss: 0.13672250509262085
Validation loss: 1.5712189482104393

Epoch: 6| Step: 13
Training loss: 0.060711972415447235
Validation loss: 1.5638341499913124

Epoch: 465| Step: 0
Training loss: 0.22347179055213928
Validation loss: 1.5754490078136485

Epoch: 6| Step: 1
Training loss: 0.04562690481543541
Validation loss: 1.6214394505305956

Epoch: 6| Step: 2
Training loss: 0.081117644906044
Validation loss: 1.6290455108047814

Epoch: 6| Step: 3
Training loss: 0.0755172073841095
Validation loss: 1.6364840422907183

Epoch: 6| Step: 4
Training loss: 0.1362440586090088
Validation loss: 1.6314402203406058

Epoch: 6| Step: 5
Training loss: 0.07162407040596008
Validation loss: 1.6551303120069607

Epoch: 6| Step: 6
Training loss: 0.10447853803634644
Validation loss: 1.6227937488145725

Epoch: 6| Step: 7
Training loss: 0.07739260047674179
Validation loss: 1.6700452425146615

Epoch: 6| Step: 8
Training loss: 0.09125417470932007
Validation loss: 1.653454085832001

Epoch: 6| Step: 9
Training loss: 0.08642765879631042
Validation loss: 1.6416342412271807

Epoch: 6| Step: 10
Training loss: 0.13399216532707214
Validation loss: 1.6278772315671366

Epoch: 6| Step: 11
Training loss: 0.08005218207836151
Validation loss: 1.6183139649770593

Epoch: 6| Step: 12
Training loss: 0.07180455327033997
Validation loss: 1.6024420107564619

Epoch: 6| Step: 13
Training loss: 0.03940805047750473
Validation loss: 1.5971951202679706

Epoch: 466| Step: 0
Training loss: 0.0552871935069561
Validation loss: 1.5809200623983979

Epoch: 6| Step: 1
Training loss: 0.07725544273853302
Validation loss: 1.5560909753204675

Epoch: 6| Step: 2
Training loss: 0.09443175792694092
Validation loss: 1.5490895368719613

Epoch: 6| Step: 3
Training loss: 0.10195980221033096
Validation loss: 1.523109398862367

Epoch: 6| Step: 4
Training loss: 0.10055451095104218
Validation loss: 1.5768162162714108

Epoch: 6| Step: 5
Training loss: 0.1105027049779892
Validation loss: 1.5489742332889187

Epoch: 6| Step: 6
Training loss: 0.12399056553840637
Validation loss: 1.5604294064224407

Epoch: 6| Step: 7
Training loss: 0.07611043751239777
Validation loss: 1.588397716963163

Epoch: 6| Step: 8
Training loss: 0.12821471691131592
Validation loss: 1.5914379114745765

Epoch: 6| Step: 9
Training loss: 0.09411799162626266
Validation loss: 1.6011071141048143

Epoch: 6| Step: 10
Training loss: 0.07252994179725647
Validation loss: 1.6194773809884184

Epoch: 6| Step: 11
Training loss: 0.21701647341251373
Validation loss: 1.5993217499025407

Epoch: 6| Step: 12
Training loss: 0.08650204539299011
Validation loss: 1.6077560295340836

Epoch: 6| Step: 13
Training loss: 0.07552070170640945
Validation loss: 1.6144576790512248

Epoch: 467| Step: 0
Training loss: 0.09946584701538086
Validation loss: 1.6098073362022318

Epoch: 6| Step: 1
Training loss: 0.09519843012094498
Validation loss: 1.6187256177266438

Epoch: 6| Step: 2
Training loss: 0.13367824256420135
Validation loss: 1.6135332263926023

Epoch: 6| Step: 3
Training loss: 0.13187752664089203
Validation loss: 1.6388820512320406

Epoch: 6| Step: 4
Training loss: 0.24488112330436707
Validation loss: 1.6265262352522982

Epoch: 6| Step: 5
Training loss: 0.11217697709798813
Validation loss: 1.5713204491523005

Epoch: 6| Step: 6
Training loss: 0.07229042053222656
Validation loss: 1.5745859274300196

Epoch: 6| Step: 7
Training loss: 0.08203745633363724
Validation loss: 1.545092011010775

Epoch: 6| Step: 8
Training loss: 0.07830579578876495
Validation loss: 1.546478142020523

Epoch: 6| Step: 9
Training loss: 0.10530093312263489
Validation loss: 1.5161251021969704

Epoch: 6| Step: 10
Training loss: 0.10000243037939072
Validation loss: 1.5364591280619304

Epoch: 6| Step: 11
Training loss: 0.10351131111383438
Validation loss: 1.5285151453428372

Epoch: 6| Step: 12
Training loss: 0.0808049887418747
Validation loss: 1.5363012065169632

Epoch: 6| Step: 13
Training loss: 0.04915755242109299
Validation loss: 1.5588299766663583

Epoch: 468| Step: 0
Training loss: 0.07724611461162567
Validation loss: 1.543726695481167

Epoch: 6| Step: 1
Training loss: 0.06943444907665253
Validation loss: 1.5826288013048069

Epoch: 6| Step: 2
Training loss: 0.04976902902126312
Validation loss: 1.597972535317944

Epoch: 6| Step: 3
Training loss: 0.08324078470468521
Validation loss: 1.6102477324906217

Epoch: 6| Step: 4
Training loss: 0.08724907785654068
Validation loss: 1.6316869220426005

Epoch: 6| Step: 5
Training loss: 0.14034265279769897
Validation loss: 1.646233218972401

Epoch: 6| Step: 6
Training loss: 0.08881266415119171
Validation loss: 1.6433082280620452

Epoch: 6| Step: 7
Training loss: 0.08456157147884369
Validation loss: 1.6607213430507208

Epoch: 6| Step: 8
Training loss: 0.10194051265716553
Validation loss: 1.6260655118573097

Epoch: 6| Step: 9
Training loss: 0.13324815034866333
Validation loss: 1.6104288690833635

Epoch: 6| Step: 10
Training loss: 0.12552796304225922
Validation loss: 1.6016997316832184

Epoch: 6| Step: 11
Training loss: 0.09889375418424606
Validation loss: 1.5726008620313419

Epoch: 6| Step: 12
Training loss: 0.0859077125787735
Validation loss: 1.5733949061362975

Epoch: 6| Step: 13
Training loss: 0.32208821177482605
Validation loss: 1.5704172016471944

Epoch: 469| Step: 0
Training loss: 0.06259304285049438
Validation loss: 1.5648385119694534

Epoch: 6| Step: 1
Training loss: 0.0638551265001297
Validation loss: 1.6062523729057723

Epoch: 6| Step: 2
Training loss: 0.08159792423248291
Validation loss: 1.5886329681642595

Epoch: 6| Step: 3
Training loss: 0.08844266831874847
Validation loss: 1.6360925730838571

Epoch: 6| Step: 4
Training loss: 0.087349072098732
Validation loss: 1.660865681145781

Epoch: 6| Step: 5
Training loss: 0.10351230204105377
Validation loss: 1.6499065058205717

Epoch: 6| Step: 6
Training loss: 0.24552291631698608
Validation loss: 1.6430992977593535

Epoch: 6| Step: 7
Training loss: 0.09174928814172745
Validation loss: 1.6384591902455976

Epoch: 6| Step: 8
Training loss: 0.07843820005655289
Validation loss: 1.617512543996175

Epoch: 6| Step: 9
Training loss: 0.1032075509428978
Validation loss: 1.5988770915615944

Epoch: 6| Step: 10
Training loss: 0.122731052339077
Validation loss: 1.5903289151448075

Epoch: 6| Step: 11
Training loss: 0.07801458239555359
Validation loss: 1.5962747591798023

Epoch: 6| Step: 12
Training loss: 0.04584749788045883
Validation loss: 1.5643756222981278

Epoch: 6| Step: 13
Training loss: 0.086570605635643
Validation loss: 1.5953999847494147

Epoch: 470| Step: 0
Training loss: 0.12249978631734848
Validation loss: 1.5786522755058863

Epoch: 6| Step: 1
Training loss: 0.10059194266796112
Validation loss: 1.5642198913840837

Epoch: 6| Step: 2
Training loss: 0.11074095964431763
Validation loss: 1.5772321698486165

Epoch: 6| Step: 3
Training loss: 0.09207393229007721
Validation loss: 1.5755585649962067

Epoch: 6| Step: 4
Training loss: 0.12074688076972961
Validation loss: 1.610788010781811

Epoch: 6| Step: 5
Training loss: 0.1493743658065796
Validation loss: 1.6350570045491701

Epoch: 6| Step: 6
Training loss: 0.1397974193096161
Validation loss: 1.624321242814423

Epoch: 6| Step: 7
Training loss: 0.08720763027667999
Validation loss: 1.6151711556219286

Epoch: 6| Step: 8
Training loss: 0.0740279108285904
Validation loss: 1.6268511741392073

Epoch: 6| Step: 9
Training loss: 0.05586725473403931
Validation loss: 1.6127002085408857

Epoch: 6| Step: 10
Training loss: 0.08377187699079514
Validation loss: 1.6021191112456783

Epoch: 6| Step: 11
Training loss: 0.08928631246089935
Validation loss: 1.5891453399453113

Epoch: 6| Step: 12
Training loss: 0.2348557710647583
Validation loss: 1.603251116250151

Epoch: 6| Step: 13
Training loss: 0.15047048032283783
Validation loss: 1.5926298402970838

Epoch: 471| Step: 0
Training loss: 0.12587043642997742
Validation loss: 1.5765699904452088

Epoch: 6| Step: 1
Training loss: 0.052242543548345566
Validation loss: 1.5753783743868592

Epoch: 6| Step: 2
Training loss: 0.12692102789878845
Validation loss: 1.544200361415904

Epoch: 6| Step: 3
Training loss: 0.1312648057937622
Validation loss: 1.5496798048737228

Epoch: 6| Step: 4
Training loss: 0.15987174212932587
Validation loss: 1.547615904961863

Epoch: 6| Step: 5
Training loss: 0.1921822726726532
Validation loss: 1.5334864060084026

Epoch: 6| Step: 6
Training loss: 0.10824122279882431
Validation loss: 1.5271775850685694

Epoch: 6| Step: 7
Training loss: 0.13593438267707825
Validation loss: 1.5473100613522273

Epoch: 6| Step: 8
Training loss: 0.11425147950649261
Validation loss: 1.5836522771466164

Epoch: 6| Step: 9
Training loss: 0.0612432137131691
Validation loss: 1.5955906183488908

Epoch: 6| Step: 10
Training loss: 0.08599423617124557
Validation loss: 1.627438206826487

Epoch: 6| Step: 11
Training loss: 0.08359504491090775
Validation loss: 1.634799321492513

Epoch: 6| Step: 12
Training loss: 0.08274269104003906
Validation loss: 1.6181431560106174

Epoch: 6| Step: 13
Training loss: 0.06773653626441956
Validation loss: 1.6386238849291237

Epoch: 472| Step: 0
Training loss: 0.07466641068458557
Validation loss: 1.6281557788131058

Epoch: 6| Step: 1
Training loss: 0.07499033957719803
Validation loss: 1.5974033494149484

Epoch: 6| Step: 2
Training loss: 0.06544014811515808
Validation loss: 1.6140835772278488

Epoch: 6| Step: 3
Training loss: 0.07303480058908463
Validation loss: 1.5818627329282864

Epoch: 6| Step: 4
Training loss: 0.09630250930786133
Validation loss: 1.5905872993571784

Epoch: 6| Step: 5
Training loss: 0.12712052464485168
Validation loss: 1.5861852451037335

Epoch: 6| Step: 6
Training loss: 0.06218339130282402
Validation loss: 1.5740298160942652

Epoch: 6| Step: 7
Training loss: 0.09015723317861557
Validation loss: 1.5922290727656374

Epoch: 6| Step: 8
Training loss: 0.09981603175401688
Validation loss: 1.603229981596752

Epoch: 6| Step: 9
Training loss: 0.07456793636083603
Validation loss: 1.5783640838438464

Epoch: 6| Step: 10
Training loss: 0.2510779798030853
Validation loss: 1.6016453017470658

Epoch: 6| Step: 11
Training loss: 0.11229228973388672
Validation loss: 1.5916938807374688

Epoch: 6| Step: 12
Training loss: 0.09039823710918427
Validation loss: 1.6110920290793143

Epoch: 6| Step: 13
Training loss: 0.04066816344857216
Validation loss: 1.599724253018697

Epoch: 473| Step: 0
Training loss: 0.08167513459920883
Validation loss: 1.5984615741237518

Epoch: 6| Step: 1
Training loss: 0.06229405105113983
Validation loss: 1.607774522996718

Epoch: 6| Step: 2
Training loss: 0.08360189944505692
Validation loss: 1.5965565507129957

Epoch: 6| Step: 3
Training loss: 0.05722443759441376
Validation loss: 1.626835705131613

Epoch: 6| Step: 4
Training loss: 0.09953047335147858
Validation loss: 1.6234828413173716

Epoch: 6| Step: 5
Training loss: 0.0991227775812149
Validation loss: 1.6056721338661768

Epoch: 6| Step: 6
Training loss: 0.10380212962627411
Validation loss: 1.5995143716053297

Epoch: 6| Step: 7
Training loss: 0.07507994771003723
Validation loss: 1.6202985753295243

Epoch: 6| Step: 8
Training loss: 0.07821698486804962
Validation loss: 1.6261694431304932

Epoch: 6| Step: 9
Training loss: 0.061458997428417206
Validation loss: 1.5907565727028796

Epoch: 6| Step: 10
Training loss: 0.06776636838912964
Validation loss: 1.5996081764980028

Epoch: 6| Step: 11
Training loss: 0.08391085267066956
Validation loss: 1.5902182491876746

Epoch: 6| Step: 12
Training loss: 0.2025465965270996
Validation loss: 1.591662637649044

Epoch: 6| Step: 13
Training loss: 0.08435344696044922
Validation loss: 1.5712157782687937

Epoch: 474| Step: 0
Training loss: 0.09861281514167786
Validation loss: 1.567878988481337

Epoch: 6| Step: 1
Training loss: 0.09057128429412842
Validation loss: 1.5836597527227094

Epoch: 6| Step: 2
Training loss: 0.08070243149995804
Validation loss: 1.6033614303476067

Epoch: 6| Step: 3
Training loss: 0.0507364496588707
Validation loss: 1.5890984535217285

Epoch: 6| Step: 4
Training loss: 0.07723444700241089
Validation loss: 1.585143066221668

Epoch: 6| Step: 5
Training loss: 0.09370415657758713
Validation loss: 1.580941956530335

Epoch: 6| Step: 6
Training loss: 0.11041616648435593
Validation loss: 1.579366168027283

Epoch: 6| Step: 7
Training loss: 0.08752410113811493
Validation loss: 1.5907190999677103

Epoch: 6| Step: 8
Training loss: 0.10318520665168762
Validation loss: 1.5916530214330202

Epoch: 6| Step: 9
Training loss: 0.07862111181020737
Validation loss: 1.5858038984319216

Epoch: 6| Step: 10
Training loss: 0.07533590495586395
Validation loss: 1.6217099722995554

Epoch: 6| Step: 11
Training loss: 0.19919094443321228
Validation loss: 1.5891699560226933

Epoch: 6| Step: 12
Training loss: 0.0890171080827713
Validation loss: 1.6115110740866712

Epoch: 6| Step: 13
Training loss: 0.06740370392799377
Validation loss: 1.610168772359048

Epoch: 475| Step: 0
Training loss: 0.10385727137327194
Validation loss: 1.571219341729277

Epoch: 6| Step: 1
Training loss: 0.1092706024646759
Validation loss: 1.5869867647847822

Epoch: 6| Step: 2
Training loss: 0.05737434700131416
Validation loss: 1.5690204212742467

Epoch: 6| Step: 3
Training loss: 0.08566554635763168
Validation loss: 1.5691519885934808

Epoch: 6| Step: 4
Training loss: 0.07109353691339493
Validation loss: 1.5637258983427478

Epoch: 6| Step: 5
Training loss: 0.06652922928333282
Validation loss: 1.5557093697209512

Epoch: 6| Step: 6
Training loss: 0.10375604778528214
Validation loss: 1.567492849083357

Epoch: 6| Step: 7
Training loss: 0.04991087317466736
Validation loss: 1.5878082449718187

Epoch: 6| Step: 8
Training loss: 0.06916354596614838
Validation loss: 1.6074465077410462

Epoch: 6| Step: 9
Training loss: 0.04887721687555313
Validation loss: 1.6058033397120814

Epoch: 6| Step: 10
Training loss: 0.055849745869636536
Validation loss: 1.6051369187652424

Epoch: 6| Step: 11
Training loss: 0.08165496587753296
Validation loss: 1.611197297291089

Epoch: 6| Step: 12
Training loss: 0.17621535062789917
Validation loss: 1.6114797694708711

Epoch: 6| Step: 13
Training loss: 0.046903952956199646
Validation loss: 1.6031955621575797

Epoch: 476| Step: 0
Training loss: 0.09818555414676666
Validation loss: 1.5876778761545818

Epoch: 6| Step: 1
Training loss: 0.07544948160648346
Validation loss: 1.5958008586719472

Epoch: 6| Step: 2
Training loss: 0.06558267772197723
Validation loss: 1.604037123341714

Epoch: 6| Step: 3
Training loss: 0.09660046547651291
Validation loss: 1.5606498115806169

Epoch: 6| Step: 4
Training loss: 0.07186692953109741
Validation loss: 1.551993344419746

Epoch: 6| Step: 5
Training loss: 0.07726944237947464
Validation loss: 1.5223923216583908

Epoch: 6| Step: 6
Training loss: 0.0709831714630127
Validation loss: 1.5320716032417871

Epoch: 6| Step: 7
Training loss: 0.15041515231132507
Validation loss: 1.5313751492449033

Epoch: 6| Step: 8
Training loss: 0.0923665463924408
Validation loss: 1.5382937853054335

Epoch: 6| Step: 9
Training loss: 0.09105198085308075
Validation loss: 1.5408805442112747

Epoch: 6| Step: 10
Training loss: 0.09780566394329071
Validation loss: 1.5337136163506457

Epoch: 6| Step: 11
Training loss: 0.06209281086921692
Validation loss: 1.5454055686150827

Epoch: 6| Step: 12
Training loss: 0.19240200519561768
Validation loss: 1.6072545692484865

Epoch: 6| Step: 13
Training loss: 0.059150680899620056
Validation loss: 1.6036161966221307

Epoch: 477| Step: 0
Training loss: 0.062088802456855774
Validation loss: 1.6042995299062421

Epoch: 6| Step: 1
Training loss: 0.09984302520751953
Validation loss: 1.6221229337876844

Epoch: 6| Step: 2
Training loss: 0.06496594846248627
Validation loss: 1.6306832836520286

Epoch: 6| Step: 3
Training loss: 0.08321421593427658
Validation loss: 1.6163529029456518

Epoch: 6| Step: 4
Training loss: 0.07920876145362854
Validation loss: 1.614857001971173

Epoch: 6| Step: 5
Training loss: 0.07161329686641693
Validation loss: 1.6102299997883458

Epoch: 6| Step: 6
Training loss: 0.09375277906656265
Validation loss: 1.597839513132649

Epoch: 6| Step: 7
Training loss: 0.09428916126489639
Validation loss: 1.5912688483474076

Epoch: 6| Step: 8
Training loss: 0.06747846305370331
Validation loss: 1.5820109728843934

Epoch: 6| Step: 9
Training loss: 0.05499020218849182
Validation loss: 1.5475776016071279

Epoch: 6| Step: 10
Training loss: 0.0877353772521019
Validation loss: 1.545129850346555

Epoch: 6| Step: 11
Training loss: 0.20036177337169647
Validation loss: 1.5436234692091584

Epoch: 6| Step: 12
Training loss: 0.08343660086393356
Validation loss: 1.5283003968577231

Epoch: 6| Step: 13
Training loss: 0.06708353012800217
Validation loss: 1.5199298845824374

Epoch: 478| Step: 0
Training loss: 0.042478859424591064
Validation loss: 1.5378008081066994

Epoch: 6| Step: 1
Training loss: 0.09718997776508331
Validation loss: 1.547760404566283

Epoch: 6| Step: 2
Training loss: 0.08846361190080643
Validation loss: 1.542018787835234

Epoch: 6| Step: 3
Training loss: 0.09998728334903717
Validation loss: 1.5587817263859574

Epoch: 6| Step: 4
Training loss: 0.07843092828989029
Validation loss: 1.5851700434120752

Epoch: 6| Step: 5
Training loss: 0.10282178968191147
Validation loss: 1.6014710434021489

Epoch: 6| Step: 6
Training loss: 0.1252601146697998
Validation loss: 1.6389081119209208

Epoch: 6| Step: 7
Training loss: 0.09635163098573685
Validation loss: 1.6421508955699142

Epoch: 6| Step: 8
Training loss: 0.10441736876964569
Validation loss: 1.6452663739522297

Epoch: 6| Step: 9
Training loss: 0.06510916352272034
Validation loss: 1.6479138392274097

Epoch: 6| Step: 10
Training loss: 0.09673421084880829
Validation loss: 1.6373048636221117

Epoch: 6| Step: 11
Training loss: 0.07960879057645798
Validation loss: 1.624180337434174

Epoch: 6| Step: 12
Training loss: 0.20201894640922546
Validation loss: 1.6337786246371526

Epoch: 6| Step: 13
Training loss: 0.03483264520764351
Validation loss: 1.6312346637889903

Epoch: 479| Step: 0
Training loss: 0.06304009258747101
Validation loss: 1.6140358326255635

Epoch: 6| Step: 1
Training loss: 0.0917268842458725
Validation loss: 1.5986508246391051

Epoch: 6| Step: 2
Training loss: 0.07192902266979218
Validation loss: 1.5906110181603381

Epoch: 6| Step: 3
Training loss: 0.06913504749536514
Validation loss: 1.5642336030160227

Epoch: 6| Step: 4
Training loss: 0.08763470500707626
Validation loss: 1.5732539610196186

Epoch: 6| Step: 5
Training loss: 0.07281941920518875
Validation loss: 1.560391044103971

Epoch: 6| Step: 6
Training loss: 0.0792011246085167
Validation loss: 1.5888288213360695

Epoch: 6| Step: 7
Training loss: 0.07821837067604065
Validation loss: 1.6317089078246907

Epoch: 6| Step: 8
Training loss: 0.06417812407016754
Validation loss: 1.6404812925605363

Epoch: 6| Step: 9
Training loss: 0.0752740353345871
Validation loss: 1.6478765754289524

Epoch: 6| Step: 10
Training loss: 0.05118352174758911
Validation loss: 1.663889273520439

Epoch: 6| Step: 11
Training loss: 0.18092268705368042
Validation loss: 1.6580372882145706

Epoch: 6| Step: 12
Training loss: 0.0914808064699173
Validation loss: 1.675151204550138

Epoch: 6| Step: 13
Training loss: 0.06284824758768082
Validation loss: 1.6439118436587754

Epoch: 480| Step: 0
Training loss: 0.08894222974777222
Validation loss: 1.6520542842085644

Epoch: 6| Step: 1
Training loss: 0.09200654923915863
Validation loss: 1.654044617888748

Epoch: 6| Step: 2
Training loss: 0.08724518865346909
Validation loss: 1.6573007414417882

Epoch: 6| Step: 3
Training loss: 0.05368907004594803
Validation loss: 1.6404404588924941

Epoch: 6| Step: 4
Training loss: 0.09344729036092758
Validation loss: 1.6475274319289832

Epoch: 6| Step: 5
Training loss: 0.0536019429564476
Validation loss: 1.6080509904892213

Epoch: 6| Step: 6
Training loss: 0.09643295407295227
Validation loss: 1.6152399688638666

Epoch: 6| Step: 7
Training loss: 0.08469057083129883
Validation loss: 1.606541960470138

Epoch: 6| Step: 8
Training loss: 0.06799051910638809
Validation loss: 1.5952801473679081

Epoch: 6| Step: 9
Training loss: 0.08017264306545258
Validation loss: 1.5681830356197972

Epoch: 6| Step: 10
Training loss: 0.19797278940677643
Validation loss: 1.587452761588558

Epoch: 6| Step: 11
Training loss: 0.10333049297332764
Validation loss: 1.573960800324717

Epoch: 6| Step: 12
Training loss: 0.03332680091261864
Validation loss: 1.586553160862256

Epoch: 6| Step: 13
Training loss: 0.1430238038301468
Validation loss: 1.598713667162003

Epoch: 481| Step: 0
Training loss: 0.06051221489906311
Validation loss: 1.5617287158966064

Epoch: 6| Step: 1
Training loss: 0.07738752663135529
Validation loss: 1.5899934666131132

Epoch: 6| Step: 2
Training loss: 0.11713755130767822
Validation loss: 1.593651661308863

Epoch: 6| Step: 3
Training loss: 0.08520524203777313
Validation loss: 1.596221020144801

Epoch: 6| Step: 4
Training loss: 0.07254811376333237
Validation loss: 1.6082838094362648

Epoch: 6| Step: 5
Training loss: 0.09186533093452454
Validation loss: 1.5921654855051348

Epoch: 6| Step: 6
Training loss: 0.09165622293949127
Validation loss: 1.5858412686214651

Epoch: 6| Step: 7
Training loss: 0.0592813715338707
Validation loss: 1.5994584944940382

Epoch: 6| Step: 8
Training loss: 0.09143716096878052
Validation loss: 1.6237958765798999

Epoch: 6| Step: 9
Training loss: 0.07051359862089157
Validation loss: 1.5818135443554129

Epoch: 6| Step: 10
Training loss: 0.09728650748729706
Validation loss: 1.5981915625192786

Epoch: 6| Step: 11
Training loss: 0.10040013492107391
Validation loss: 1.584407010386067

Epoch: 6| Step: 12
Training loss: 0.1766006499528885
Validation loss: 1.6038383745378064

Epoch: 6| Step: 13
Training loss: 0.08407651633024216
Validation loss: 1.6010494680814846

Epoch: 482| Step: 0
Training loss: 0.1114048957824707
Validation loss: 1.6276293441813479

Epoch: 6| Step: 1
Training loss: 0.07997690141201019
Validation loss: 1.598713126233829

Epoch: 6| Step: 2
Training loss: 0.0963578075170517
Validation loss: 1.6028295293931039

Epoch: 6| Step: 3
Training loss: 0.0855167880654335
Validation loss: 1.5797309849851875

Epoch: 6| Step: 4
Training loss: 0.08753717690706253
Validation loss: 1.6019531200009007

Epoch: 6| Step: 5
Training loss: 0.0975361168384552
Validation loss: 1.6006006348517634

Epoch: 6| Step: 6
Training loss: 0.0927828922867775
Validation loss: 1.60171284919144

Epoch: 6| Step: 7
Training loss: 0.040260229259729385
Validation loss: 1.617333181442753

Epoch: 6| Step: 8
Training loss: 0.08027803897857666
Validation loss: 1.632539664545367

Epoch: 6| Step: 9
Training loss: 0.07173209637403488
Validation loss: 1.61441514056216

Epoch: 6| Step: 10
Training loss: 0.04968082159757614
Validation loss: 1.615193259331488

Epoch: 6| Step: 11
Training loss: 0.20087754726409912
Validation loss: 1.6250883251108148

Epoch: 6| Step: 12
Training loss: 0.03772816061973572
Validation loss: 1.6042762135946622

Epoch: 6| Step: 13
Training loss: 0.09842430055141449
Validation loss: 1.602989040395265

Epoch: 483| Step: 0
Training loss: 0.07319580763578415
Validation loss: 1.5815543090143511

Epoch: 6| Step: 1
Training loss: 0.052603282034397125
Validation loss: 1.604845618688932

Epoch: 6| Step: 2
Training loss: 0.06966681778430939
Validation loss: 1.6190864091278405

Epoch: 6| Step: 3
Training loss: 0.06716139614582062
Validation loss: 1.6067784793915287

Epoch: 6| Step: 4
Training loss: 0.0975114032626152
Validation loss: 1.593925351737648

Epoch: 6| Step: 5
Training loss: 0.19465170800685883
Validation loss: 1.6023461703331239

Epoch: 6| Step: 6
Training loss: 0.047814611345529556
Validation loss: 1.6055915240318543

Epoch: 6| Step: 7
Training loss: 0.06685364246368408
Validation loss: 1.5806073860455585

Epoch: 6| Step: 8
Training loss: 0.07457628846168518
Validation loss: 1.607178795722223

Epoch: 6| Step: 9
Training loss: 0.09679444134235382
Validation loss: 1.5652358064087488

Epoch: 6| Step: 10
Training loss: 0.058739468455314636
Validation loss: 1.5915465188282791

Epoch: 6| Step: 11
Training loss: 0.14284104108810425
Validation loss: 1.5946257665593138

Epoch: 6| Step: 12
Training loss: 0.05962032452225685
Validation loss: 1.5807490438543341

Epoch: 6| Step: 13
Training loss: 0.04000695422291756
Validation loss: 1.5969538688659668

Epoch: 484| Step: 0
Training loss: 0.08645548671483994
Validation loss: 1.6196522789616739

Epoch: 6| Step: 1
Training loss: 0.08653409779071808
Validation loss: 1.5919801112144225

Epoch: 6| Step: 2
Training loss: 0.060665398836135864
Validation loss: 1.616453334849368

Epoch: 6| Step: 3
Training loss: 0.07780414819717407
Validation loss: 1.6174756365437661

Epoch: 6| Step: 4
Training loss: 0.05147312209010124
Validation loss: 1.6350929890909502

Epoch: 6| Step: 5
Training loss: 0.09744762629270554
Validation loss: 1.65525302579326

Epoch: 6| Step: 6
Training loss: 0.10096730291843414
Validation loss: 1.6394354169086744

Epoch: 6| Step: 7
Training loss: 0.20581528544425964
Validation loss: 1.626879367136186

Epoch: 6| Step: 8
Training loss: 0.08584274351596832
Validation loss: 1.6333871169756817

Epoch: 6| Step: 9
Training loss: 0.10423669219017029
Validation loss: 1.6057693112281062

Epoch: 6| Step: 10
Training loss: 0.06518875807523727
Validation loss: 1.600187640036306

Epoch: 6| Step: 11
Training loss: 0.0882202535867691
Validation loss: 1.6159618695576985

Epoch: 6| Step: 12
Training loss: 0.06282037496566772
Validation loss: 1.6044610905390915

Epoch: 6| Step: 13
Training loss: 0.05555202066898346
Validation loss: 1.5963930250495992

Epoch: 485| Step: 0
Training loss: 0.16606034338474274
Validation loss: 1.6176246443102438

Epoch: 6| Step: 1
Training loss: 0.05323399230837822
Validation loss: 1.626366763986567

Epoch: 6| Step: 2
Training loss: 0.07743868231773376
Validation loss: 1.6181640407090545

Epoch: 6| Step: 3
Training loss: 0.08529652655124664
Validation loss: 1.6167850481566561

Epoch: 6| Step: 4
Training loss: 0.0970141813158989
Validation loss: 1.6410771467352425

Epoch: 6| Step: 5
Training loss: 0.06165355443954468
Validation loss: 1.6372781543321506

Epoch: 6| Step: 6
Training loss: 0.0678538829088211
Validation loss: 1.650937993039367

Epoch: 6| Step: 7
Training loss: 0.06768641620874405
Validation loss: 1.6472611991308068

Epoch: 6| Step: 8
Training loss: 0.11873030662536621
Validation loss: 1.629533536972538

Epoch: 6| Step: 9
Training loss: 0.09129337966442108
Validation loss: 1.6354850889534078

Epoch: 6| Step: 10
Training loss: 0.1118929386138916
Validation loss: 1.6350766766455866

Epoch: 6| Step: 11
Training loss: 0.04700463265180588
Validation loss: 1.6080524947053643

Epoch: 6| Step: 12
Training loss: 0.06997509300708771
Validation loss: 1.6076138327198644

Epoch: 6| Step: 13
Training loss: 0.05102964863181114
Validation loss: 1.5706844669516369

Epoch: 486| Step: 0
Training loss: 0.08780337870121002
Validation loss: 1.5245526618854974

Epoch: 6| Step: 1
Training loss: 0.0746147483587265
Validation loss: 1.5303840637207031

Epoch: 6| Step: 2
Training loss: 0.22815272212028503
Validation loss: 1.5274913900641984

Epoch: 6| Step: 3
Training loss: 0.05954018235206604
Validation loss: 1.5523089317865268

Epoch: 6| Step: 4
Training loss: 0.05062691867351532
Validation loss: 1.5744297440334032

Epoch: 6| Step: 5
Training loss: 0.051703065633773804
Validation loss: 1.580410756090636

Epoch: 6| Step: 6
Training loss: 0.04229762405157089
Validation loss: 1.5875405675621443

Epoch: 6| Step: 7
Training loss: 0.06015752628445625
Validation loss: 1.591452807508489

Epoch: 6| Step: 8
Training loss: 0.09900546818971634
Validation loss: 1.6050664455659929

Epoch: 6| Step: 9
Training loss: 0.07130519300699234
Validation loss: 1.6363717381672194

Epoch: 6| Step: 10
Training loss: 0.09213164448738098
Validation loss: 1.6105280537759104

Epoch: 6| Step: 11
Training loss: 0.08246921002864838
Validation loss: 1.6081894366971907

Epoch: 6| Step: 12
Training loss: 0.09891365468502045
Validation loss: 1.6249316687225013

Epoch: 6| Step: 13
Training loss: 0.15781858563423157
Validation loss: 1.5694213644150765

Epoch: 487| Step: 0
Training loss: 0.21954116225242615
Validation loss: 1.527765945721698

Epoch: 6| Step: 1
Training loss: 0.09874734282493591
Validation loss: 1.551718094015634

Epoch: 6| Step: 2
Training loss: 0.09347674250602722
Validation loss: 1.5039007849590753

Epoch: 6| Step: 3
Training loss: 0.07072223722934723
Validation loss: 1.523822812623875

Epoch: 6| Step: 4
Training loss: 0.10607657581567764
Validation loss: 1.5348808355228876

Epoch: 6| Step: 5
Training loss: 0.09913571178913116
Validation loss: 1.5372309345071034

Epoch: 6| Step: 6
Training loss: 0.09341172873973846
Validation loss: 1.544828442476129

Epoch: 6| Step: 7
Training loss: 0.06593262404203415
Validation loss: 1.5641753827371905

Epoch: 6| Step: 8
Training loss: 0.0949908047914505
Validation loss: 1.6175840285516554

Epoch: 6| Step: 9
Training loss: 0.08232348412275314
Validation loss: 1.6058212864783503

Epoch: 6| Step: 10
Training loss: 0.03587513417005539
Validation loss: 1.58874007450637

Epoch: 6| Step: 11
Training loss: 0.047203823924064636
Validation loss: 1.6039792030088362

Epoch: 6| Step: 12
Training loss: 0.11029550433158875
Validation loss: 1.62409286345205

Epoch: 6| Step: 13
Training loss: 0.13393817842006683
Validation loss: 1.6127835678797897

Epoch: 488| Step: 0
Training loss: 0.06973616778850555
Validation loss: 1.582834380929188

Epoch: 6| Step: 1
Training loss: 0.10449680685997009
Validation loss: 1.5635550252852901

Epoch: 6| Step: 2
Training loss: 0.07269418239593506
Validation loss: 1.5379266713255195

Epoch: 6| Step: 3
Training loss: 0.07911548018455505
Validation loss: 1.5439594458508235

Epoch: 6| Step: 4
Training loss: 0.07655619084835052
Validation loss: 1.5301433045377013

Epoch: 6| Step: 5
Training loss: 0.06520311534404755
Validation loss: 1.5277945521057292

Epoch: 6| Step: 6
Training loss: 0.06621972471475601
Validation loss: 1.5157981687976467

Epoch: 6| Step: 7
Training loss: 0.10910831391811371
Validation loss: 1.524186429157052

Epoch: 6| Step: 8
Training loss: 0.21497873961925507
Validation loss: 1.530313144447983

Epoch: 6| Step: 9
Training loss: 0.10494981706142426
Validation loss: 1.5581602050412087

Epoch: 6| Step: 10
Training loss: 0.07628904283046722
Validation loss: 1.5671283993669736

Epoch: 6| Step: 11
Training loss: 0.09232950955629349
Validation loss: 1.5556377262197516

Epoch: 6| Step: 12
Training loss: 0.06428054720163345
Validation loss: 1.5671539332277031

Epoch: 6| Step: 13
Training loss: 0.07545929402112961
Validation loss: 1.5998908858145438

Epoch: 489| Step: 0
Training loss: 0.06582063436508179
Validation loss: 1.6056799145155056

Epoch: 6| Step: 1
Training loss: 0.05621306598186493
Validation loss: 1.6301192186212028

Epoch: 6| Step: 2
Training loss: 0.08018616586923599
Validation loss: 1.604422177037885

Epoch: 6| Step: 3
Training loss: 0.06695514917373657
Validation loss: 1.5917451932866087

Epoch: 6| Step: 4
Training loss: 0.08345898985862732
Validation loss: 1.595212201918325

Epoch: 6| Step: 5
Training loss: 0.07905001193284988
Validation loss: 1.5807033085053968

Epoch: 6| Step: 6
Training loss: 0.06081333011388779
Validation loss: 1.5759569182190845

Epoch: 6| Step: 7
Training loss: 0.07283371686935425
Validation loss: 1.5559372978825723

Epoch: 6| Step: 8
Training loss: 0.08416929841041565
Validation loss: 1.5645516495550833

Epoch: 6| Step: 9
Training loss: 0.09104549139738083
Validation loss: 1.549760764644992

Epoch: 6| Step: 10
Training loss: 0.10946644097566605
Validation loss: 1.5390758668222735

Epoch: 6| Step: 11
Training loss: 0.07706214487552643
Validation loss: 1.5705201818097023

Epoch: 6| Step: 12
Training loss: 0.18504591286182404
Validation loss: 1.5627244108466691

Epoch: 6| Step: 13
Training loss: 0.06923508644104004
Validation loss: 1.6030581433285949

Epoch: 490| Step: 0
Training loss: 0.17678070068359375
Validation loss: 1.6007978082985006

Epoch: 6| Step: 1
Training loss: 0.07917370647192001
Validation loss: 1.615859354695966

Epoch: 6| Step: 2
Training loss: 0.05848761647939682
Validation loss: 1.6421054294032436

Epoch: 6| Step: 3
Training loss: 0.11704173684120178
Validation loss: 1.6202670374224264

Epoch: 6| Step: 4
Training loss: 0.09527942538261414
Validation loss: 1.6173073655815535

Epoch: 6| Step: 5
Training loss: 0.0772569552063942
Validation loss: 1.6315914084834438

Epoch: 6| Step: 6
Training loss: 0.06733329594135284
Validation loss: 1.617277269722313

Epoch: 6| Step: 7
Training loss: 0.06958983838558197
Validation loss: 1.585053369563113

Epoch: 6| Step: 8
Training loss: 0.10319061577320099
Validation loss: 1.5777435546280236

Epoch: 6| Step: 9
Training loss: 0.07760240137577057
Validation loss: 1.5683160725460257

Epoch: 6| Step: 10
Training loss: 0.0668429583311081
Validation loss: 1.5398898765604982

Epoch: 6| Step: 11
Training loss: 0.13988664746284485
Validation loss: 1.543644025761594

Epoch: 6| Step: 12
Training loss: 0.0677035003900528
Validation loss: 1.55520704484755

Epoch: 6| Step: 13
Training loss: 0.08247154206037521
Validation loss: 1.57155958555078

Epoch: 491| Step: 0
Training loss: 0.054320793598890305
Validation loss: 1.5323352262537966

Epoch: 6| Step: 1
Training loss: 0.08253905922174454
Validation loss: 1.5689729464951383

Epoch: 6| Step: 2
Training loss: 0.051682885736227036
Validation loss: 1.5575117321424587

Epoch: 6| Step: 3
Training loss: 0.04589610546827316
Validation loss: 1.5753731676327285

Epoch: 6| Step: 4
Training loss: 0.04418930038809776
Validation loss: 1.5682090969495877

Epoch: 6| Step: 5
Training loss: 0.061678528785705566
Validation loss: 1.5803350043553177

Epoch: 6| Step: 6
Training loss: 0.07317706942558289
Validation loss: 1.5768113854110881

Epoch: 6| Step: 7
Training loss: 0.20939619839191437
Validation loss: 1.5962488036001883

Epoch: 6| Step: 8
Training loss: 0.08578557521104813
Validation loss: 1.586170418288118

Epoch: 6| Step: 9
Training loss: 0.08267431706190109
Validation loss: 1.6027677751356555

Epoch: 6| Step: 10
Training loss: 0.050316229462623596
Validation loss: 1.5790422167829288

Epoch: 6| Step: 11
Training loss: 0.0811149999499321
Validation loss: 1.5864156997332008

Epoch: 6| Step: 12
Training loss: 0.07310432940721512
Validation loss: 1.5798048652628416

Epoch: 6| Step: 13
Training loss: 0.03800200670957565
Validation loss: 1.5837257831327376

Epoch: 492| Step: 0
Training loss: 0.0716959685087204
Validation loss: 1.5574626961062032

Epoch: 6| Step: 1
Training loss: 0.1992071270942688
Validation loss: 1.5574108413470689

Epoch: 6| Step: 2
Training loss: 0.07242227345705032
Validation loss: 1.5339049293148903

Epoch: 6| Step: 3
Training loss: 0.13340294361114502
Validation loss: 1.554371141618298

Epoch: 6| Step: 4
Training loss: 0.06799767166376114
Validation loss: 1.5543684767138573

Epoch: 6| Step: 5
Training loss: 0.06778942048549652
Validation loss: 1.5857310987287951

Epoch: 6| Step: 6
Training loss: 0.05324961245059967
Validation loss: 1.5709768879798152

Epoch: 6| Step: 7
Training loss: 0.08153931796550751
Validation loss: 1.5942391131513862

Epoch: 6| Step: 8
Training loss: 0.14691463112831116
Validation loss: 1.6073952323646956

Epoch: 6| Step: 9
Training loss: 0.11975091695785522
Validation loss: 1.6634326775868733

Epoch: 6| Step: 10
Training loss: 0.09164388477802277
Validation loss: 1.639091528872008

Epoch: 6| Step: 11
Training loss: 0.0953582227230072
Validation loss: 1.6370709455141457

Epoch: 6| Step: 12
Training loss: 0.09853048622608185
Validation loss: 1.6097157668041926

Epoch: 6| Step: 13
Training loss: 0.0814669132232666
Validation loss: 1.6386819013985254

Epoch: 493| Step: 0
Training loss: 0.08120368421077728
Validation loss: 1.6338933578101538

Epoch: 6| Step: 1
Training loss: 0.057248543947935104
Validation loss: 1.6237436904702136

Epoch: 6| Step: 2
Training loss: 0.11500164866447449
Validation loss: 1.6162272563544653

Epoch: 6| Step: 3
Training loss: 0.08283404260873795
Validation loss: 1.5952795526032806

Epoch: 6| Step: 4
Training loss: 0.09052842855453491
Validation loss: 1.599626793656298

Epoch: 6| Step: 5
Training loss: 0.10717331618070602
Validation loss: 1.596810281917613

Epoch: 6| Step: 6
Training loss: 0.054750099778175354
Validation loss: 1.6092067623651156

Epoch: 6| Step: 7
Training loss: 0.05122137814760208
Validation loss: 1.5997797404566119

Epoch: 6| Step: 8
Training loss: 0.0923202708363533
Validation loss: 1.6022179536922003

Epoch: 6| Step: 9
Training loss: 0.05284716933965683
Validation loss: 1.6038442478385022

Epoch: 6| Step: 10
Training loss: 0.0762176439166069
Validation loss: 1.5980427290803643

Epoch: 6| Step: 11
Training loss: 0.06896322965621948
Validation loss: 1.5945903896003641

Epoch: 6| Step: 12
Training loss: 0.1879524290561676
Validation loss: 1.6314897883322932

Epoch: 6| Step: 13
Training loss: 0.050514619797468185
Validation loss: 1.6311291571586364

Epoch: 494| Step: 0
Training loss: 0.0778656005859375
Validation loss: 1.646977768149427

Epoch: 6| Step: 1
Training loss: 0.10525719821453094
Validation loss: 1.6556042317421205

Epoch: 6| Step: 2
Training loss: 0.10054655373096466
Validation loss: 1.6378282167578255

Epoch: 6| Step: 3
Training loss: 0.06413935869932175
Validation loss: 1.6530987447307957

Epoch: 6| Step: 4
Training loss: 0.06357797980308533
Validation loss: 1.6409430144935526

Epoch: 6| Step: 5
Training loss: 0.06414651870727539
Validation loss: 1.6472004793023551

Epoch: 6| Step: 6
Training loss: 0.08442655950784683
Validation loss: 1.655994019200725

Epoch: 6| Step: 7
Training loss: 0.20335185527801514
Validation loss: 1.630423225382323

Epoch: 6| Step: 8
Training loss: 0.05708657577633858
Validation loss: 1.644671368342574

Epoch: 6| Step: 9
Training loss: 0.09705784916877747
Validation loss: 1.6201753795787852

Epoch: 6| Step: 10
Training loss: 0.050741977989673615
Validation loss: 1.6205493057927778

Epoch: 6| Step: 11
Training loss: 0.07532332837581635
Validation loss: 1.6140935856808898

Epoch: 6| Step: 12
Training loss: 0.058712370693683624
Validation loss: 1.6155557593991678

Epoch: 6| Step: 13
Training loss: 0.06801477819681168
Validation loss: 1.6173300614920996

Epoch: 495| Step: 0
Training loss: 0.07982299476861954
Validation loss: 1.6306310879286898

Epoch: 6| Step: 1
Training loss: 0.07589149475097656
Validation loss: 1.632871348370788

Epoch: 6| Step: 2
Training loss: 0.18132102489471436
Validation loss: 1.6498598719155917

Epoch: 6| Step: 3
Training loss: 0.08770260214805603
Validation loss: 1.6570440723050026

Epoch: 6| Step: 4
Training loss: 0.0366211012005806
Validation loss: 1.63105825390867

Epoch: 6| Step: 5
Training loss: 0.06824219226837158
Validation loss: 1.6361418859933012

Epoch: 6| Step: 6
Training loss: 0.08695302903652191
Validation loss: 1.6327314774195354

Epoch: 6| Step: 7
Training loss: 0.042222023010253906
Validation loss: 1.616317827214477

Epoch: 6| Step: 8
Training loss: 0.08738550543785095
Validation loss: 1.622960348283091

Epoch: 6| Step: 9
Training loss: 0.10178624093532562
Validation loss: 1.6310926464296156

Epoch: 6| Step: 10
Training loss: 0.07399764657020569
Validation loss: 1.6257818360482492

Epoch: 6| Step: 11
Training loss: 0.10398194193840027
Validation loss: 1.635772858255653

Epoch: 6| Step: 12
Training loss: 0.09775435924530029
Validation loss: 1.6156535840803576

Epoch: 6| Step: 13
Training loss: 0.04686954244971275
Validation loss: 1.6115865527942617

Epoch: 496| Step: 0
Training loss: 0.03820343688130379
Validation loss: 1.599443704851212

Epoch: 6| Step: 1
Training loss: 0.06978131830692291
Validation loss: 1.611509596147845

Epoch: 6| Step: 2
Training loss: 0.09714806824922562
Validation loss: 1.5989297359220442

Epoch: 6| Step: 3
Training loss: 0.17714788019657135
Validation loss: 1.6231362537671161

Epoch: 6| Step: 4
Training loss: 0.07932207733392715
Validation loss: 1.634994327381093

Epoch: 6| Step: 5
Training loss: 0.046558886766433716
Validation loss: 1.6256341908567695

Epoch: 6| Step: 6
Training loss: 0.0739501416683197
Validation loss: 1.6126551525567168

Epoch: 6| Step: 7
Training loss: 0.06284014135599136
Validation loss: 1.631907775837888

Epoch: 6| Step: 8
Training loss: 0.08654889464378357
Validation loss: 1.6278383616478211

Epoch: 6| Step: 9
Training loss: 0.04707033559679985
Validation loss: 1.6410895188649495

Epoch: 6| Step: 10
Training loss: 0.04944893717765808
Validation loss: 1.6221683999543548

Epoch: 6| Step: 11
Training loss: 0.04935996234416962
Validation loss: 1.631851488544095

Epoch: 6| Step: 12
Training loss: 0.08469577133655548
Validation loss: 1.6001626958129227

Epoch: 6| Step: 13
Training loss: 0.06567757576704025
Validation loss: 1.6444610498284782

Epoch: 497| Step: 0
Training loss: 0.06191695109009743
Validation loss: 1.5969464368717645

Epoch: 6| Step: 1
Training loss: 0.07257304340600967
Validation loss: 1.6317869424819946

Epoch: 6| Step: 2
Training loss: 0.09293152391910553
Validation loss: 1.627510097719008

Epoch: 6| Step: 3
Training loss: 0.06385808438062668
Validation loss: 1.6198455620837469

Epoch: 6| Step: 4
Training loss: 0.07309072464704514
Validation loss: 1.5993104698837444

Epoch: 6| Step: 5
Training loss: 0.06632134318351746
Validation loss: 1.590367159535808

Epoch: 6| Step: 6
Training loss: 0.05204980820417404
Validation loss: 1.601807617372082

Epoch: 6| Step: 7
Training loss: 0.09006461501121521
Validation loss: 1.5999226313765331

Epoch: 6| Step: 8
Training loss: 0.07041845470666885
Validation loss: 1.548400225177888

Epoch: 6| Step: 9
Training loss: 0.18845289945602417
Validation loss: 1.5440466045051493

Epoch: 6| Step: 10
Training loss: 0.04608984291553497
Validation loss: 1.5951145259282922

Epoch: 6| Step: 11
Training loss: 0.08382001519203186
Validation loss: 1.5843507679559852

Epoch: 6| Step: 12
Training loss: 0.09846839308738708
Validation loss: 1.603908747755071

Epoch: 6| Step: 13
Training loss: 0.05058082565665245
Validation loss: 1.5950420082256358

Epoch: 498| Step: 0
Training loss: 0.06272083520889282
Validation loss: 1.6032334937844226

Epoch: 6| Step: 1
Training loss: 0.10202521830797195
Validation loss: 1.5891793415110598

Epoch: 6| Step: 2
Training loss: 0.1006031483411789
Validation loss: 1.615048223926175

Epoch: 6| Step: 3
Training loss: 0.0923469290137291
Validation loss: 1.5930306757650068

Epoch: 6| Step: 4
Training loss: 0.07920964062213898
Validation loss: 1.5961894976195468

Epoch: 6| Step: 5
Training loss: 0.07921446859836578
Validation loss: 1.6040625585022794

Epoch: 6| Step: 6
Training loss: 0.06003980338573456
Validation loss: 1.5925284111371605

Epoch: 6| Step: 7
Training loss: 0.1489262729883194
Validation loss: 1.6039839277985275

Epoch: 6| Step: 8
Training loss: 0.051151033490896225
Validation loss: 1.6085012805077337

Epoch: 6| Step: 9
Training loss: 0.06310627609491348
Validation loss: 1.6030585637656591

Epoch: 6| Step: 10
Training loss: 0.07392141222953796
Validation loss: 1.5979202473035423

Epoch: 6| Step: 11
Training loss: 0.04309927672147751
Validation loss: 1.5827197233835857

Epoch: 6| Step: 12
Training loss: 0.05440413951873779
Validation loss: 1.5786746817250406

Epoch: 6| Step: 13
Training loss: 0.04356557875871658
Validation loss: 1.5894936130892845

Epoch: 499| Step: 0
Training loss: 0.042996034026145935
Validation loss: 1.600477026354882

Epoch: 6| Step: 1
Training loss: 0.07170835882425308
Validation loss: 1.6118366256836922

Epoch: 6| Step: 2
Training loss: 0.08876644819974899
Validation loss: 1.5710901541094626

Epoch: 6| Step: 3
Training loss: 0.06692097336053848
Validation loss: 1.5958251235305623

Epoch: 6| Step: 4
Training loss: 0.06251572072505951
Validation loss: 1.5735344681688535

Epoch: 6| Step: 5
Training loss: 0.19980008900165558
Validation loss: 1.588662814068538

Epoch: 6| Step: 6
Training loss: 0.06604818999767303
Validation loss: 1.585533599699697

Epoch: 6| Step: 7
Training loss: 0.06537486612796783
Validation loss: 1.594066305827069

Epoch: 6| Step: 8
Training loss: 0.1023210734128952
Validation loss: 1.5923596236013597

Epoch: 6| Step: 9
Training loss: 0.06633888930082321
Validation loss: 1.595850331808931

Epoch: 6| Step: 10
Training loss: 0.046877190470695496
Validation loss: 1.60751627209366

Epoch: 6| Step: 11
Training loss: 0.0524037703871727
Validation loss: 1.5799277392766808

Epoch: 6| Step: 12
Training loss: 0.042346179485321045
Validation loss: 1.602064742836901

Epoch: 6| Step: 13
Training loss: 0.05850796401500702
Validation loss: 1.6066353974803802

Epoch: 500| Step: 0
Training loss: 0.03269949182868004
Validation loss: 1.6073043641223703

Epoch: 6| Step: 1
Training loss: 0.0802609771490097
Validation loss: 1.595691047688966

Epoch: 6| Step: 2
Training loss: 0.05200675129890442
Validation loss: 1.6052022787832445

Epoch: 6| Step: 3
Training loss: 0.07621673494577408
Validation loss: 1.6219685385304112

Epoch: 6| Step: 4
Training loss: 0.04958771914243698
Validation loss: 1.5835306746985323

Epoch: 6| Step: 5
Training loss: 0.18979354202747345
Validation loss: 1.6031234841192923

Epoch: 6| Step: 6
Training loss: 0.08005467057228088
Validation loss: 1.605737243929217

Epoch: 6| Step: 7
Training loss: 0.08149175345897675
Validation loss: 1.6233720933237383

Epoch: 6| Step: 8
Training loss: 0.11006706953048706
Validation loss: 1.6250683312774987

Epoch: 6| Step: 9
Training loss: 0.05792833864688873
Validation loss: 1.615664553898637

Epoch: 6| Step: 10
Training loss: 0.0534362718462944
Validation loss: 1.5900377054368295

Epoch: 6| Step: 11
Training loss: 0.12207324802875519
Validation loss: 1.5576907101497854

Epoch: 6| Step: 12
Training loss: 0.08900192379951477
Validation loss: 1.5596168310411516

Epoch: 6| Step: 13
Training loss: 0.04949111491441727
Validation loss: 1.5374899397614181

Testing loss: 2.106823518541124
