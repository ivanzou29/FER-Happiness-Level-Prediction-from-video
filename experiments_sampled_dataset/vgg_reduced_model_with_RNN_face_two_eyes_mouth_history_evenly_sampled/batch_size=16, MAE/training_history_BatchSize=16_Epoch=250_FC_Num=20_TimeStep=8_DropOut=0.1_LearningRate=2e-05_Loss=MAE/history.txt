Epoch: 1| Step: 0
Training loss: 4.453126907348633
Validation loss: 5.176620303943593

Epoch: 6| Step: 1
Training loss: 5.018888473510742
Validation loss: 5.147087917532972

Epoch: 6| Step: 2
Training loss: 3.7682714462280273
Validation loss: 5.1186114229181765

Epoch: 6| Step: 3
Training loss: 4.343132972717285
Validation loss: 5.088626979499735

Epoch: 6| Step: 4
Training loss: 5.546914100646973
Validation loss: 5.0556032990896576

Epoch: 6| Step: 5
Training loss: 3.584965705871582
Validation loss: 5.02007996138706

Epoch: 6| Step: 6
Training loss: 5.66556453704834
Validation loss: 4.9782395773036505

Epoch: 6| Step: 7
Training loss: 5.277761459350586
Validation loss: 4.931978784581666

Epoch: 6| Step: 8
Training loss: 6.9219183921813965
Validation loss: 4.87892726672593

Epoch: 6| Step: 9
Training loss: 3.9783949851989746
Validation loss: 4.8196721435875025

Epoch: 6| Step: 10
Training loss: 3.4277453422546387
Validation loss: 4.755132598261679

Epoch: 6| Step: 11
Training loss: 4.337797164916992
Validation loss: 4.685886752220892

Epoch: 6| Step: 12
Training loss: 5.506205081939697
Validation loss: 4.611812806898548

Epoch: 6| Step: 13
Training loss: 3.7326114177703857
Validation loss: 4.534477269777688

Epoch: 2| Step: 0
Training loss: 4.267080307006836
Validation loss: 4.455346658665647

Epoch: 6| Step: 1
Training loss: 4.560216903686523
Validation loss: 4.375447365545457

Epoch: 6| Step: 2
Training loss: 2.4480085372924805
Validation loss: 4.298746924246511

Epoch: 6| Step: 3
Training loss: 3.827509880065918
Validation loss: 4.2275306281223095

Epoch: 6| Step: 4
Training loss: 3.4432308673858643
Validation loss: 4.159323266757432

Epoch: 6| Step: 5
Training loss: 4.896069526672363
Validation loss: 4.092226484770416

Epoch: 6| Step: 6
Training loss: 3.993086814880371
Validation loss: 4.029059117840182

Epoch: 6| Step: 7
Training loss: 4.5200958251953125
Validation loss: 3.971414484003539

Epoch: 6| Step: 8
Training loss: 4.371447563171387
Validation loss: 3.9206437654392694

Epoch: 6| Step: 9
Training loss: 4.257570266723633
Validation loss: 3.8725672127098165

Epoch: 6| Step: 10
Training loss: 3.460841178894043
Validation loss: 3.8305163947484826

Epoch: 6| Step: 11
Training loss: 3.6100378036499023
Validation loss: 3.790715156062957

Epoch: 6| Step: 12
Training loss: 3.7782161235809326
Validation loss: 3.7580279893772577

Epoch: 6| Step: 13
Training loss: 2.3354880809783936
Validation loss: 3.7281245570028982

Epoch: 3| Step: 0
Training loss: 3.496361494064331
Validation loss: 3.7021278976112284

Epoch: 6| Step: 1
Training loss: 3.389256715774536
Validation loss: 3.6763501603116273

Epoch: 6| Step: 2
Training loss: 3.346139430999756
Validation loss: 3.6543960571289062

Epoch: 6| Step: 3
Training loss: 2.7855308055877686
Validation loss: 3.6436354062890493

Epoch: 6| Step: 4
Training loss: 3.474250316619873
Validation loss: 3.629294708210935

Epoch: 6| Step: 5
Training loss: 4.9022369384765625
Validation loss: 3.611734195422101

Epoch: 6| Step: 6
Training loss: 2.5688843727111816
Validation loss: 3.590437299461775

Epoch: 6| Step: 7
Training loss: 2.7696471214294434
Validation loss: 3.566155674637005

Epoch: 6| Step: 8
Training loss: 5.121272563934326
Validation loss: 3.5448331268884803

Epoch: 6| Step: 9
Training loss: 3.871828317642212
Validation loss: 3.5220174763792302

Epoch: 6| Step: 10
Training loss: 3.89284348487854
Validation loss: 3.5006195037595687

Epoch: 6| Step: 11
Training loss: 3.013089656829834
Validation loss: 3.4832305959475938

Epoch: 6| Step: 12
Training loss: 2.2693777084350586
Validation loss: 3.465177115573678

Epoch: 6| Step: 13
Training loss: 4.357738494873047
Validation loss: 3.4473006212583153

Epoch: 4| Step: 0
Training loss: 3.724496364593506
Validation loss: 3.4275123098845124

Epoch: 6| Step: 1
Training loss: 3.976696491241455
Validation loss: 3.4090484624267905

Epoch: 6| Step: 2
Training loss: 3.44923996925354
Validation loss: 3.3869835997140534

Epoch: 6| Step: 3
Training loss: 2.3620572090148926
Validation loss: 3.3623166391926427

Epoch: 6| Step: 4
Training loss: 2.5672476291656494
Validation loss: 3.325913926606537

Epoch: 6| Step: 5
Training loss: 3.169144630432129
Validation loss: 3.3033366972400295

Epoch: 6| Step: 6
Training loss: 2.382340431213379
Validation loss: 3.28476898131832

Epoch: 6| Step: 7
Training loss: 3.0821139812469482
Validation loss: 3.275956687106881

Epoch: 6| Step: 8
Training loss: 3.9446017742156982
Validation loss: 3.2654088338216147

Epoch: 6| Step: 9
Training loss: 3.652768611907959
Validation loss: 3.25165799356276

Epoch: 6| Step: 10
Training loss: 3.5121097564697266
Validation loss: 3.23508027292067

Epoch: 6| Step: 11
Training loss: 3.387247085571289
Validation loss: 3.2202479480415263

Epoch: 6| Step: 12
Training loss: 3.145111083984375
Validation loss: 3.205941548911474

Epoch: 6| Step: 13
Training loss: 3.557050943374634
Validation loss: 3.19218917815916

Epoch: 5| Step: 0
Training loss: 2.8331480026245117
Validation loss: 3.1764888250699608

Epoch: 6| Step: 1
Training loss: 3.149901866912842
Validation loss: 3.1632367282785396

Epoch: 6| Step: 2
Training loss: 2.7555694580078125
Validation loss: 3.1503789758169525

Epoch: 6| Step: 3
Training loss: 3.233707904815674
Validation loss: 3.1376346977808143

Epoch: 6| Step: 4
Training loss: 4.609020709991455
Validation loss: 3.123928439232611

Epoch: 6| Step: 5
Training loss: 3.2205417156219482
Validation loss: 3.114985845422232

Epoch: 6| Step: 6
Training loss: 2.84211802482605
Validation loss: 3.105043908601166

Epoch: 6| Step: 7
Training loss: 2.4548139572143555
Validation loss: 3.095984440977855

Epoch: 6| Step: 8
Training loss: 3.4792816638946533
Validation loss: 3.093485393831807

Epoch: 6| Step: 9
Training loss: 2.9188387393951416
Validation loss: 3.074047609042096

Epoch: 6| Step: 10
Training loss: 2.8592886924743652
Validation loss: 3.083600987670242

Epoch: 6| Step: 11
Training loss: 4.048149108886719
Validation loss: 3.0790584241190264

Epoch: 6| Step: 12
Training loss: 2.3763833045959473
Validation loss: 3.069197459887433

Epoch: 6| Step: 13
Training loss: 3.3352253437042236
Validation loss: 3.047673668912662

Epoch: 6| Step: 0
Training loss: 2.848670244216919
Validation loss: 3.0420792230995755

Epoch: 6| Step: 1
Training loss: 3.404749631881714
Validation loss: 3.045155394461847

Epoch: 6| Step: 2
Training loss: 2.6854395866394043
Validation loss: 3.028886887335008

Epoch: 6| Step: 3
Training loss: 3.477442741394043
Validation loss: 3.020617097936651

Epoch: 6| Step: 4
Training loss: 3.0317788124084473
Validation loss: 3.009983916436472

Epoch: 6| Step: 5
Training loss: 3.854804039001465
Validation loss: 3.004681897419755

Epoch: 6| Step: 6
Training loss: 3.04860782623291
Validation loss: 2.998421581842566

Epoch: 6| Step: 7
Training loss: 2.463867664337158
Validation loss: 2.999307527337023

Epoch: 6| Step: 8
Training loss: 3.9847044944763184
Validation loss: 3.020704210445445

Epoch: 6| Step: 9
Training loss: 3.1485912799835205
Validation loss: 2.9817418462486676

Epoch: 6| Step: 10
Training loss: 1.591729760169983
Validation loss: 2.97103028656334

Epoch: 6| Step: 11
Training loss: 3.203514575958252
Validation loss: 2.9733938017199115

Epoch: 6| Step: 12
Training loss: 3.5104575157165527
Validation loss: 2.9885447845664075

Epoch: 6| Step: 13
Training loss: 2.4928905963897705
Validation loss: 2.9830695634247153

Epoch: 7| Step: 0
Training loss: 3.5174849033355713
Validation loss: 2.9986457927252657

Epoch: 6| Step: 1
Training loss: 2.75993013381958
Validation loss: 2.952487971193047

Epoch: 6| Step: 2
Training loss: 2.2627530097961426
Validation loss: 2.94807295901801

Epoch: 6| Step: 3
Training loss: 3.260982036590576
Validation loss: 2.956578803318803

Epoch: 6| Step: 4
Training loss: 2.073171615600586
Validation loss: 2.9635019738187074

Epoch: 6| Step: 5
Training loss: 3.4786386489868164
Validation loss: 2.962896075299991

Epoch: 6| Step: 6
Training loss: 3.7218868732452393
Validation loss: 2.9515446386029645

Epoch: 6| Step: 7
Training loss: 3.191286563873291
Validation loss: 2.936708281117101

Epoch: 6| Step: 8
Training loss: 2.8638405799865723
Validation loss: 2.9327647198912916

Epoch: 6| Step: 9
Training loss: 3.8421106338500977
Validation loss: 2.933771264168524

Epoch: 6| Step: 10
Training loss: 3.0750107765197754
Validation loss: 2.930382192775767

Epoch: 6| Step: 11
Training loss: 2.411698579788208
Validation loss: 2.932732420582925

Epoch: 6| Step: 12
Training loss: 3.356140375137329
Validation loss: 2.930617683677263

Epoch: 6| Step: 13
Training loss: 2.4364664554595947
Validation loss: 2.921350743180962

Epoch: 8| Step: 0
Training loss: 2.9964141845703125
Validation loss: 2.9082932959320726

Epoch: 6| Step: 1
Training loss: 2.500260829925537
Validation loss: 2.900436039893858

Epoch: 6| Step: 2
Training loss: 2.5385072231292725
Validation loss: 2.8934939087078138

Epoch: 6| Step: 3
Training loss: 2.875378131866455
Validation loss: 2.8897329248407835

Epoch: 6| Step: 4
Training loss: 2.819814682006836
Validation loss: 2.8870954539186213

Epoch: 6| Step: 5
Training loss: 3.3807592391967773
Validation loss: 2.882264662814397

Epoch: 6| Step: 6
Training loss: 2.4245219230651855
Validation loss: 2.8773803967301563

Epoch: 6| Step: 7
Training loss: 3.437037706375122
Validation loss: 2.871161109657698

Epoch: 6| Step: 8
Training loss: 2.1637723445892334
Validation loss: 2.8638638245162142

Epoch: 6| Step: 9
Training loss: 4.049969673156738
Validation loss: 2.858242950131816

Epoch: 6| Step: 10
Training loss: 3.098071336746216
Validation loss: 2.8533022506262666

Epoch: 6| Step: 11
Training loss: 3.0403449535369873
Validation loss: 2.8478595851570048

Epoch: 6| Step: 12
Training loss: 3.3526062965393066
Validation loss: 2.841265527150964

Epoch: 6| Step: 13
Training loss: 2.997384548187256
Validation loss: 2.838359840454594

Epoch: 9| Step: 0
Training loss: 3.104973316192627
Validation loss: 2.8278769318775465

Epoch: 6| Step: 1
Training loss: 3.5560860633850098
Validation loss: 2.8230025306824715

Epoch: 6| Step: 2
Training loss: 3.8106632232666016
Validation loss: 2.81821866702008

Epoch: 6| Step: 3
Training loss: 3.06412410736084
Validation loss: 2.811285739303917

Epoch: 6| Step: 4
Training loss: 1.8251855373382568
Validation loss: 2.8017899554262877

Epoch: 6| Step: 5
Training loss: 2.69293212890625
Validation loss: 2.7978275360599643

Epoch: 6| Step: 6
Training loss: 3.361504554748535
Validation loss: 2.7929929917858494

Epoch: 6| Step: 7
Training loss: 2.592083215713501
Validation loss: 2.788310743147327

Epoch: 6| Step: 8
Training loss: 3.2540335655212402
Validation loss: 2.7819106348099245

Epoch: 6| Step: 9
Training loss: 2.4533586502075195
Validation loss: 2.7771947588971866

Epoch: 6| Step: 10
Training loss: 2.929547071456909
Validation loss: 2.7750000953674316

Epoch: 6| Step: 11
Training loss: 2.39862060546875
Validation loss: 2.768985420145014

Epoch: 6| Step: 12
Training loss: 3.285949468612671
Validation loss: 2.7700488182806198

Epoch: 6| Step: 13
Training loss: 2.5200448036193848
Validation loss: 2.7609620453209005

Epoch: 10| Step: 0
Training loss: 2.9839653968811035
Validation loss: 2.760694960112213

Epoch: 6| Step: 1
Training loss: 2.5555176734924316
Validation loss: 2.763676466480378

Epoch: 6| Step: 2
Training loss: 2.706164836883545
Validation loss: 2.764036842571792

Epoch: 6| Step: 3
Training loss: 2.6379969120025635
Validation loss: 2.763593545524023

Epoch: 6| Step: 4
Training loss: 3.7185168266296387
Validation loss: 2.7614082059552594

Epoch: 6| Step: 5
Training loss: 3.0278427600860596
Validation loss: 2.7534428693914927

Epoch: 6| Step: 6
Training loss: 2.812019109725952
Validation loss: 2.745528692840248

Epoch: 6| Step: 7
Training loss: 2.793879508972168
Validation loss: 2.744101929408248

Epoch: 6| Step: 8
Training loss: 2.3150970935821533
Validation loss: 2.739323644227879

Epoch: 6| Step: 9
Training loss: 2.4694619178771973
Validation loss: 2.7347967547755085

Epoch: 6| Step: 10
Training loss: 3.420585870742798
Validation loss: 2.727233358608779

Epoch: 6| Step: 11
Training loss: 3.7300686836242676
Validation loss: 2.7210511084525817

Epoch: 6| Step: 12
Training loss: 2.955141544342041
Validation loss: 2.7154108144903697

Epoch: 6| Step: 13
Training loss: 2.129918098449707
Validation loss: 2.714490923830258

Epoch: 11| Step: 0
Training loss: 2.4320054054260254
Validation loss: 2.714568461141279

Epoch: 6| Step: 1
Training loss: 3.414165496826172
Validation loss: 2.712830969082412

Epoch: 6| Step: 2
Training loss: 3.6060686111450195
Validation loss: 2.7117744825219594

Epoch: 6| Step: 3
Training loss: 1.6954951286315918
Validation loss: 2.7065642341490714

Epoch: 6| Step: 4
Training loss: 3.092317819595337
Validation loss: 2.700081081800563

Epoch: 6| Step: 5
Training loss: 2.7071523666381836
Validation loss: 2.6966484490261284

Epoch: 6| Step: 6
Training loss: 2.3030877113342285
Validation loss: 2.692860495659613

Epoch: 6| Step: 7
Training loss: 3.7894158363342285
Validation loss: 2.6884915828704834

Epoch: 6| Step: 8
Training loss: 3.408855438232422
Validation loss: 2.683292373534172

Epoch: 6| Step: 9
Training loss: 2.9422101974487305
Validation loss: 2.678479351023192

Epoch: 6| Step: 10
Training loss: 2.5298688411712646
Validation loss: 2.6754841573776735

Epoch: 6| Step: 11
Training loss: 2.2878365516662598
Validation loss: 2.673868848431495

Epoch: 6| Step: 12
Training loss: 2.571572780609131
Validation loss: 2.6711262938796834

Epoch: 6| Step: 13
Training loss: 3.661863088607788
Validation loss: 2.6709825300401255

Epoch: 12| Step: 0
Training loss: 2.1828720569610596
Validation loss: 2.6680709828612623

Epoch: 6| Step: 1
Training loss: 2.6158764362335205
Validation loss: 2.6684856466067735

Epoch: 6| Step: 2
Training loss: 4.460747241973877
Validation loss: 2.6615759224020024

Epoch: 6| Step: 3
Training loss: 2.8336048126220703
Validation loss: 2.659189998462636

Epoch: 6| Step: 4
Training loss: 2.6431431770324707
Validation loss: 2.6581564846859185

Epoch: 6| Step: 5
Training loss: 3.212127685546875
Validation loss: 2.6563438548836658

Epoch: 6| Step: 6
Training loss: 2.7879223823547363
Validation loss: 2.652790697672034

Epoch: 6| Step: 7
Training loss: 2.7813565731048584
Validation loss: 2.6524517433617705

Epoch: 6| Step: 8
Training loss: 3.0733938217163086
Validation loss: 2.648970337324245

Epoch: 6| Step: 9
Training loss: 1.874925136566162
Validation loss: 2.6471643806785665

Epoch: 6| Step: 10
Training loss: 2.2016406059265137
Validation loss: 2.6459501840734996

Epoch: 6| Step: 11
Training loss: 3.116748094558716
Validation loss: 2.6442137200345277

Epoch: 6| Step: 12
Training loss: 2.9099912643432617
Validation loss: 2.6420147547157864

Epoch: 6| Step: 13
Training loss: 3.1894824504852295
Validation loss: 2.6390291080679944

Epoch: 13| Step: 0
Training loss: 3.1025390625
Validation loss: 2.6371274942992837

Epoch: 6| Step: 1
Training loss: 3.0547146797180176
Validation loss: 2.638274146664527

Epoch: 6| Step: 2
Training loss: 2.6111068725585938
Validation loss: 2.6353218170904342

Epoch: 6| Step: 3
Training loss: 2.8211112022399902
Validation loss: 2.629561093545729

Epoch: 6| Step: 4
Training loss: 2.7583792209625244
Validation loss: 2.6247346990851947

Epoch: 6| Step: 5
Training loss: 2.6644182205200195
Validation loss: 2.628288120351812

Epoch: 6| Step: 6
Training loss: 3.234884262084961
Validation loss: 2.6267736393918275

Epoch: 6| Step: 7
Training loss: 3.1812949180603027
Validation loss: 2.6240003570433585

Epoch: 6| Step: 8
Training loss: 2.331514358520508
Validation loss: 2.6240013004631124

Epoch: 6| Step: 9
Training loss: 2.425434112548828
Validation loss: 2.6248024022707375

Epoch: 6| Step: 10
Training loss: 3.034024238586426
Validation loss: 2.6207429875609694

Epoch: 6| Step: 11
Training loss: 3.448345184326172
Validation loss: 2.6236103811571674

Epoch: 6| Step: 12
Training loss: 2.2803077697753906
Validation loss: 2.6183141431500836

Epoch: 6| Step: 13
Training loss: 2.353278160095215
Validation loss: 2.6223870221004693

Epoch: 14| Step: 0
Training loss: 2.384103775024414
Validation loss: 2.6145551358499834

Epoch: 6| Step: 1
Training loss: 3.5197696685791016
Validation loss: 2.6064666804446968

Epoch: 6| Step: 2
Training loss: 2.4581477642059326
Validation loss: 2.5967936797808577

Epoch: 6| Step: 3
Training loss: 3.0213708877563477
Validation loss: 2.5966811897934123

Epoch: 6| Step: 4
Training loss: 3.0687074661254883
Validation loss: 2.5964679102743826

Epoch: 6| Step: 5
Training loss: 3.082475423812866
Validation loss: 2.661993121588102

Epoch: 6| Step: 6
Training loss: 2.7751717567443848
Validation loss: 2.6726637809507308

Epoch: 6| Step: 7
Training loss: 3.4736523628234863
Validation loss: 2.6562270964345625

Epoch: 6| Step: 8
Training loss: 2.5287258625030518
Validation loss: 2.6522264096044723

Epoch: 6| Step: 9
Training loss: 2.434555768966675
Validation loss: 2.643944404458487

Epoch: 6| Step: 10
Training loss: 1.8994826078414917
Validation loss: 2.6419308877760366

Epoch: 6| Step: 11
Training loss: 2.6428165435791016
Validation loss: 2.645703267025691

Epoch: 6| Step: 12
Training loss: 3.5601754188537598
Validation loss: 2.638749594329506

Epoch: 6| Step: 13
Training loss: 2.7063326835632324
Validation loss: 2.6099428438371226

Epoch: 15| Step: 0
Training loss: 3.314124345779419
Validation loss: 2.6254696538371425

Epoch: 6| Step: 1
Training loss: 3.3079581260681152
Validation loss: 2.5989669907477593

Epoch: 6| Step: 2
Training loss: 1.9406297206878662
Validation loss: 2.577252188036519

Epoch: 6| Step: 3
Training loss: 3.1341614723205566
Validation loss: 2.581043104971609

Epoch: 6| Step: 4
Training loss: 2.8931469917297363
Validation loss: 2.590870923893426

Epoch: 6| Step: 5
Training loss: 2.6445906162261963
Validation loss: 2.591340828967351

Epoch: 6| Step: 6
Training loss: 2.7020463943481445
Validation loss: 2.597313411774174

Epoch: 6| Step: 7
Training loss: 2.8498740196228027
Validation loss: 2.59576851578169

Epoch: 6| Step: 8
Training loss: 3.2385430335998535
Validation loss: 2.5983548395095335

Epoch: 6| Step: 9
Training loss: 2.437858819961548
Validation loss: 2.5906513044911046

Epoch: 6| Step: 10
Training loss: 2.70510196685791
Validation loss: 2.5871381785279963

Epoch: 6| Step: 11
Training loss: 2.3947763442993164
Validation loss: 2.59166685740153

Epoch: 6| Step: 12
Training loss: 2.43064022064209
Validation loss: 2.568539511772894

Epoch: 6| Step: 13
Training loss: 3.470977306365967
Validation loss: 2.570736087778563

Epoch: 16| Step: 0
Training loss: 3.248598575592041
Validation loss: 2.560120318525581

Epoch: 6| Step: 1
Training loss: 3.5301854610443115
Validation loss: 2.560935648538733

Epoch: 6| Step: 2
Training loss: 2.36311674118042
Validation loss: 2.557331895315519

Epoch: 6| Step: 3
Training loss: 2.33052921295166
Validation loss: 2.5589943291038595

Epoch: 6| Step: 4
Training loss: 3.2919671535491943
Validation loss: 2.5665096903360016

Epoch: 6| Step: 5
Training loss: 3.7507810592651367
Validation loss: 2.5701956031143025

Epoch: 6| Step: 6
Training loss: 2.2782509326934814
Validation loss: 2.5635001838848157

Epoch: 6| Step: 7
Training loss: 2.672043561935425
Validation loss: 2.5637213465987996

Epoch: 6| Step: 8
Training loss: 3.092771053314209
Validation loss: 2.564274887884817

Epoch: 6| Step: 9
Training loss: 2.3046345710754395
Validation loss: 2.5582186739931823

Epoch: 6| Step: 10
Training loss: 2.982192277908325
Validation loss: 2.5450454270967873

Epoch: 6| Step: 11
Training loss: 1.9105719327926636
Validation loss: 2.5374138944892475

Epoch: 6| Step: 12
Training loss: 2.6138930320739746
Validation loss: 2.539753488315049

Epoch: 6| Step: 13
Training loss: 2.3561737537384033
Validation loss: 2.536089410064041

Epoch: 17| Step: 0
Training loss: 2.302741289138794
Validation loss: 2.5340128611492854

Epoch: 6| Step: 1
Training loss: 2.7767367362976074
Validation loss: 2.5352686810237106

Epoch: 6| Step: 2
Training loss: 2.474240303039551
Validation loss: 2.549728920382838

Epoch: 6| Step: 3
Training loss: 2.0721189975738525
Validation loss: 2.547503286792386

Epoch: 6| Step: 4
Training loss: 2.7524361610412598
Validation loss: 2.539630369473529

Epoch: 6| Step: 5
Training loss: 2.7160825729370117
Validation loss: 2.532184644411969

Epoch: 6| Step: 6
Training loss: 2.4168550968170166
Validation loss: 2.5356053357483237

Epoch: 6| Step: 7
Training loss: 4.157497882843018
Validation loss: 2.5301012557039977

Epoch: 6| Step: 8
Training loss: 2.645569324493408
Validation loss: 2.5224758040520454

Epoch: 6| Step: 9
Training loss: 2.7647671699523926
Validation loss: 2.513124950470463

Epoch: 6| Step: 10
Training loss: 3.112092971801758
Validation loss: 2.5035247520733903

Epoch: 6| Step: 11
Training loss: 2.4407732486724854
Validation loss: 2.50760345689712

Epoch: 6| Step: 12
Training loss: 2.901986837387085
Validation loss: 2.5079665748021935

Epoch: 6| Step: 13
Training loss: 3.4442262649536133
Validation loss: 2.5150064627329507

Epoch: 18| Step: 0
Training loss: 2.904855728149414
Validation loss: 2.5056269297035794

Epoch: 6| Step: 1
Training loss: 2.241478443145752
Validation loss: 2.5019950379607496

Epoch: 6| Step: 2
Training loss: 2.820021629333496
Validation loss: 2.5149016944311

Epoch: 6| Step: 3
Training loss: 2.2041707038879395
Validation loss: 2.546811052547988

Epoch: 6| Step: 4
Training loss: 2.768937110900879
Validation loss: 2.604383114845522

Epoch: 6| Step: 5
Training loss: 2.208047866821289
Validation loss: 2.6513400872548423

Epoch: 6| Step: 6
Training loss: 3.087143898010254
Validation loss: 2.681211071629678

Epoch: 6| Step: 7
Training loss: 2.1809396743774414
Validation loss: 2.613818642913654

Epoch: 6| Step: 8
Training loss: 3.411282539367676
Validation loss: 2.5355407114951842

Epoch: 6| Step: 9
Training loss: 2.592423915863037
Validation loss: 2.4931930290755404

Epoch: 6| Step: 10
Training loss: 3.5440075397491455
Validation loss: 2.550572705525224

Epoch: 6| Step: 11
Training loss: 3.582857370376587
Validation loss: 2.6822435163682505

Epoch: 6| Step: 12
Training loss: 2.5653886795043945
Validation loss: 2.6307068409458285

Epoch: 6| Step: 13
Training loss: 3.4057459831237793
Validation loss: 2.6213556925455728

Epoch: 19| Step: 0
Training loss: 3.099813461303711
Validation loss: 2.5669370005207677

Epoch: 6| Step: 1
Training loss: 2.0670483112335205
Validation loss: 2.5393270754045054

Epoch: 6| Step: 2
Training loss: 2.602576971054077
Validation loss: 2.5255240522405153

Epoch: 6| Step: 3
Training loss: 2.156085729598999
Validation loss: 2.5364744368419854

Epoch: 6| Step: 4
Training loss: 3.588120222091675
Validation loss: 2.567959636770269

Epoch: 6| Step: 5
Training loss: 2.1564724445343018
Validation loss: 2.569137991115611

Epoch: 6| Step: 6
Training loss: 3.6621813774108887
Validation loss: 2.540604965661162

Epoch: 6| Step: 7
Training loss: 2.0069656372070312
Validation loss: 2.533647075776131

Epoch: 6| Step: 8
Training loss: 3.1312994956970215
Validation loss: 2.5214249677555536

Epoch: 6| Step: 9
Training loss: 2.8492202758789062
Validation loss: 2.5091866523988786

Epoch: 6| Step: 10
Training loss: 2.756704330444336
Validation loss: 2.5023314029939714

Epoch: 6| Step: 11
Training loss: 3.1148717403411865
Validation loss: 2.490366737047831

Epoch: 6| Step: 12
Training loss: 3.0282278060913086
Validation loss: 2.4983499921778196

Epoch: 6| Step: 13
Training loss: 2.2492270469665527
Validation loss: 2.507253372541038

Epoch: 20| Step: 0
Training loss: 2.7865262031555176
Validation loss: 2.4881681088478333

Epoch: 6| Step: 1
Training loss: 2.002854347229004
Validation loss: 2.4880293210347495

Epoch: 6| Step: 2
Training loss: 3.768101930618286
Validation loss: 2.487159470076202

Epoch: 6| Step: 3
Training loss: 2.4000062942504883
Validation loss: 2.4862073826533493

Epoch: 6| Step: 4
Training loss: 2.3972299098968506
Validation loss: 2.486722884639617

Epoch: 6| Step: 5
Training loss: 2.924713134765625
Validation loss: 2.4831097433643956

Epoch: 6| Step: 6
Training loss: 2.3504106998443604
Validation loss: 2.479293789914859

Epoch: 6| Step: 7
Training loss: 2.7449140548706055
Validation loss: 2.482559216919766

Epoch: 6| Step: 8
Training loss: 3.0444507598876953
Validation loss: 2.4833238945212415

Epoch: 6| Step: 9
Training loss: 2.6959614753723145
Validation loss: 2.4792447115785334

Epoch: 6| Step: 10
Training loss: 2.7202353477478027
Validation loss: 2.4812354990231094

Epoch: 6| Step: 11
Training loss: 3.2718591690063477
Validation loss: 2.483927575490808

Epoch: 6| Step: 12
Training loss: 2.623203754425049
Validation loss: 2.4891590251717517

Epoch: 6| Step: 13
Training loss: 2.44869065284729
Validation loss: 2.4937767392845562

Epoch: 21| Step: 0
Training loss: 2.563326358795166
Validation loss: 2.5056994089516262

Epoch: 6| Step: 1
Training loss: 2.485711097717285
Validation loss: 2.5372007764795774

Epoch: 6| Step: 2
Training loss: 2.919313907623291
Validation loss: 2.537862580309632

Epoch: 6| Step: 3
Training loss: 3.4356908798217773
Validation loss: 2.5052269633098314

Epoch: 6| Step: 4
Training loss: 2.919252395629883
Validation loss: 2.4801411654359553

Epoch: 6| Step: 5
Training loss: 2.4153852462768555
Validation loss: 2.455324549828806

Epoch: 6| Step: 6
Training loss: 2.95717191696167
Validation loss: 2.4439205097895798

Epoch: 6| Step: 7
Training loss: 2.4730632305145264
Validation loss: 2.451746491975682

Epoch: 6| Step: 8
Training loss: 2.910778284072876
Validation loss: 2.466973068893597

Epoch: 6| Step: 9
Training loss: 2.8125171661376953
Validation loss: 2.4686178135615524

Epoch: 6| Step: 10
Training loss: 2.8477845191955566
Validation loss: 2.4580425600851736

Epoch: 6| Step: 11
Training loss: 1.7818028926849365
Validation loss: 2.4538652179061726

Epoch: 6| Step: 12
Training loss: 2.641441822052002
Validation loss: 2.444483526291386

Epoch: 6| Step: 13
Training loss: 3.2817392349243164
Validation loss: 2.4371427823138494

Epoch: 22| Step: 0
Training loss: 2.172578811645508
Validation loss: 2.441059676549768

Epoch: 6| Step: 1
Training loss: 2.502544641494751
Validation loss: 2.4450436125519457

Epoch: 6| Step: 2
Training loss: 3.269529104232788
Validation loss: 2.469953231914069

Epoch: 6| Step: 3
Training loss: 2.6856026649475098
Validation loss: 2.5182501193015807

Epoch: 6| Step: 4
Training loss: 3.5363354682922363
Validation loss: 2.563823865305993

Epoch: 6| Step: 5
Training loss: 2.4908242225646973
Validation loss: 2.5834150083603395

Epoch: 6| Step: 6
Training loss: 2.2810912132263184
Validation loss: 2.5377991071311374

Epoch: 6| Step: 7
Training loss: 2.7777140140533447
Validation loss: 2.4957274083168275

Epoch: 6| Step: 8
Training loss: 2.7498624324798584
Validation loss: 2.4710452018245572

Epoch: 6| Step: 9
Training loss: 2.35640549659729
Validation loss: 2.45088368333796

Epoch: 6| Step: 10
Training loss: 2.646731376647949
Validation loss: 2.4347593220331336

Epoch: 6| Step: 11
Training loss: 3.3523595333099365
Validation loss: 2.434083023378926

Epoch: 6| Step: 12
Training loss: 3.073070526123047
Validation loss: 2.4322579573559504

Epoch: 6| Step: 13
Training loss: 1.6274001598358154
Validation loss: 2.4308582505872174

Epoch: 23| Step: 0
Training loss: 2.0303573608398438
Validation loss: 2.4312307603897585

Epoch: 6| Step: 1
Training loss: 3.2105724811553955
Validation loss: 2.435177162129392

Epoch: 6| Step: 2
Training loss: 2.6239757537841797
Validation loss: 2.4322097506574405

Epoch: 6| Step: 3
Training loss: 3.0082554817199707
Validation loss: 2.434050626652215

Epoch: 6| Step: 4
Training loss: 2.7185347080230713
Validation loss: 2.434981164111886

Epoch: 6| Step: 5
Training loss: 3.2623987197875977
Validation loss: 2.4363441903104066

Epoch: 6| Step: 6
Training loss: 2.485105037689209
Validation loss: 2.4347537794420795

Epoch: 6| Step: 7
Training loss: 2.8445489406585693
Validation loss: 2.431533593003468

Epoch: 6| Step: 8
Training loss: 2.069031238555908
Validation loss: 2.4304005228063112

Epoch: 6| Step: 9
Training loss: 2.7694296836853027
Validation loss: 2.431265449011198

Epoch: 6| Step: 10
Training loss: 2.6314194202423096
Validation loss: 2.429506399298227

Epoch: 6| Step: 11
Training loss: 2.4995198249816895
Validation loss: 2.416986673108993

Epoch: 6| Step: 12
Training loss: 3.000570774078369
Validation loss: 2.4210529353028987

Epoch: 6| Step: 13
Training loss: 2.127203941345215
Validation loss: 2.4200231567505868

Epoch: 24| Step: 0
Training loss: 2.737057685852051
Validation loss: 2.4291313591823784

Epoch: 6| Step: 1
Training loss: 2.7957379817962646
Validation loss: 2.4381899167132635

Epoch: 6| Step: 2
Training loss: 3.019413948059082
Validation loss: 2.4373890712697017

Epoch: 6| Step: 3
Training loss: 1.8235468864440918
Validation loss: 2.4455383798127532

Epoch: 6| Step: 4
Training loss: 2.6909375190734863
Validation loss: 2.4405874770174742

Epoch: 6| Step: 5
Training loss: 2.4112162590026855
Validation loss: 2.4434124961976083

Epoch: 6| Step: 6
Training loss: 2.4703667163848877
Validation loss: 2.43582736292193

Epoch: 6| Step: 7
Training loss: 2.4233179092407227
Validation loss: 2.4267307455821703

Epoch: 6| Step: 8
Training loss: 2.948647975921631
Validation loss: 2.4318556990674747

Epoch: 6| Step: 9
Training loss: 2.8247134685516357
Validation loss: 2.4245027213968258

Epoch: 6| Step: 10
Training loss: 2.8074545860290527
Validation loss: 2.4345923931367937

Epoch: 6| Step: 11
Training loss: 2.9520983695983887
Validation loss: 2.4153157844338367

Epoch: 6| Step: 12
Training loss: 2.588806629180908
Validation loss: 2.4113120725077968

Epoch: 6| Step: 13
Training loss: 3.0152008533477783
Validation loss: 2.4116714359611593

Epoch: 25| Step: 0
Training loss: 2.643801212310791
Validation loss: 2.4111794758868474

Epoch: 6| Step: 1
Training loss: 2.028029680252075
Validation loss: 2.4071401473014586

Epoch: 6| Step: 2
Training loss: 2.6455888748168945
Validation loss: 2.402634753975817

Epoch: 6| Step: 3
Training loss: 2.458785057067871
Validation loss: 2.3974389542815504

Epoch: 6| Step: 4
Training loss: 3.539468288421631
Validation loss: 2.3943230387985066

Epoch: 6| Step: 5
Training loss: 2.773827075958252
Validation loss: 2.393173121636914

Epoch: 6| Step: 6
Training loss: 2.8925485610961914
Validation loss: 2.396890917131978

Epoch: 6| Step: 7
Training loss: 2.9629364013671875
Validation loss: 2.397127861617714

Epoch: 6| Step: 8
Training loss: 2.3392109870910645
Validation loss: 2.3961032590558453

Epoch: 6| Step: 9
Training loss: 2.8605034351348877
Validation loss: 2.396021484046854

Epoch: 6| Step: 10
Training loss: 2.2451491355895996
Validation loss: 2.394707956621724

Epoch: 6| Step: 11
Training loss: 2.183105230331421
Validation loss: 2.3947949973485803

Epoch: 6| Step: 12
Training loss: 3.0138251781463623
Validation loss: 2.391248481248015

Epoch: 6| Step: 13
Training loss: 2.8408823013305664
Validation loss: 2.3953818313537107

Epoch: 26| Step: 0
Training loss: 3.078197956085205
Validation loss: 2.4147870976437806

Epoch: 6| Step: 1
Training loss: 2.914785861968994
Validation loss: 2.4375199630696285

Epoch: 6| Step: 2
Training loss: 2.404995918273926
Validation loss: 2.4522907451916764

Epoch: 6| Step: 3
Training loss: 2.988405227661133
Validation loss: 2.4841251091290544

Epoch: 6| Step: 4
Training loss: 2.394010066986084
Validation loss: 2.4812210580354095

Epoch: 6| Step: 5
Training loss: 2.2708892822265625
Validation loss: 2.4652113632489274

Epoch: 6| Step: 6
Training loss: 2.765392780303955
Validation loss: 2.44894044117261

Epoch: 6| Step: 7
Training loss: 2.0762414932250977
Validation loss: 2.428459467426423

Epoch: 6| Step: 8
Training loss: 3.4027764797210693
Validation loss: 2.4183000236429195

Epoch: 6| Step: 9
Training loss: 2.7155251502990723
Validation loss: 2.4179101246659473

Epoch: 6| Step: 10
Training loss: 2.679033041000366
Validation loss: 2.4051211418644076

Epoch: 6| Step: 11
Training loss: 2.4704649448394775
Validation loss: 2.404900799515427

Epoch: 6| Step: 12
Training loss: 2.664630651473999
Validation loss: 2.4088624036440285

Epoch: 6| Step: 13
Training loss: 2.1944751739501953
Validation loss: 2.4032362943054526

Epoch: 27| Step: 0
Training loss: 2.2427234649658203
Validation loss: 2.4013117910713278

Epoch: 6| Step: 1
Training loss: 2.9494502544403076
Validation loss: 2.39664384113845

Epoch: 6| Step: 2
Training loss: 2.566211700439453
Validation loss: 2.3875470712620723

Epoch: 6| Step: 3
Training loss: 2.3679234981536865
Validation loss: 2.391596091690884

Epoch: 6| Step: 4
Training loss: 2.949371814727783
Validation loss: 2.3785028432005193

Epoch: 6| Step: 5
Training loss: 1.8751788139343262
Validation loss: 2.381619302175378

Epoch: 6| Step: 6
Training loss: 2.8101937770843506
Validation loss: 2.412332066925623

Epoch: 6| Step: 7
Training loss: 2.146775722503662
Validation loss: 2.4258916685658116

Epoch: 6| Step: 8
Training loss: 3.1780385971069336
Validation loss: 2.4354715526744886

Epoch: 6| Step: 9
Training loss: 2.62137770652771
Validation loss: 2.4242985684384584

Epoch: 6| Step: 10
Training loss: 2.529775857925415
Validation loss: 2.408213351362495

Epoch: 6| Step: 11
Training loss: 2.5046792030334473
Validation loss: 2.403733463697536

Epoch: 6| Step: 12
Training loss: 3.4659199714660645
Validation loss: 2.396490937920027

Epoch: 6| Step: 13
Training loss: 3.147608757019043
Validation loss: 2.3834201802489576

Epoch: 28| Step: 0
Training loss: 2.9848227500915527
Validation loss: 2.3677890736569642

Epoch: 6| Step: 1
Training loss: 2.308096408843994
Validation loss: 2.3606406334907777

Epoch: 6| Step: 2
Training loss: 2.932194471359253
Validation loss: 2.3594507530171382

Epoch: 6| Step: 3
Training loss: 2.543856143951416
Validation loss: 2.3527227627333773

Epoch: 6| Step: 4
Training loss: 2.896306037902832
Validation loss: 2.3536753475025134

Epoch: 6| Step: 5
Training loss: 2.722500801086426
Validation loss: 2.365984765432214

Epoch: 6| Step: 6
Training loss: 1.909453272819519
Validation loss: 2.3568101954716507

Epoch: 6| Step: 7
Training loss: 2.9140796661376953
Validation loss: 2.3503021040270404

Epoch: 6| Step: 8
Training loss: 2.25758695602417
Validation loss: 2.348761720042075

Epoch: 6| Step: 9
Training loss: 2.6391940116882324
Validation loss: 2.35184843309464

Epoch: 6| Step: 10
Training loss: 2.9561891555786133
Validation loss: 2.351468804062054

Epoch: 6| Step: 11
Training loss: 2.9202232360839844
Validation loss: 2.356706311625819

Epoch: 6| Step: 12
Training loss: 2.2290658950805664
Validation loss: 2.3740368773860316

Epoch: 6| Step: 13
Training loss: 2.451685905456543
Validation loss: 2.393076224993634

Epoch: 29| Step: 0
Training loss: 2.4830288887023926
Validation loss: 2.42233879335465

Epoch: 6| Step: 1
Training loss: 1.9906784296035767
Validation loss: 2.434444918427416

Epoch: 6| Step: 2
Training loss: 2.217116594314575
Validation loss: 2.4418753834180933

Epoch: 6| Step: 3
Training loss: 2.619169235229492
Validation loss: 2.4427374844909995

Epoch: 6| Step: 4
Training loss: 2.6445159912109375
Validation loss: 2.4279643899650982

Epoch: 6| Step: 5
Training loss: 2.8841114044189453
Validation loss: 2.399807578773909

Epoch: 6| Step: 6
Training loss: 2.8011584281921387
Validation loss: 2.373915462083714

Epoch: 6| Step: 7
Training loss: 2.1524925231933594
Validation loss: 2.3484251140266337

Epoch: 6| Step: 8
Training loss: 2.6763370037078857
Validation loss: 2.3477666685658116

Epoch: 6| Step: 9
Training loss: 2.9513332843780518
Validation loss: 2.342035306397305

Epoch: 6| Step: 10
Training loss: 3.258667469024658
Validation loss: 2.343182002344439

Epoch: 6| Step: 11
Training loss: 2.7566065788269043
Validation loss: 2.343309014074264

Epoch: 6| Step: 12
Training loss: 2.8201701641082764
Validation loss: 2.3447708173464705

Epoch: 6| Step: 13
Training loss: 2.379058361053467
Validation loss: 2.3456161765642065

Epoch: 30| Step: 0
Training loss: 2.7913103103637695
Validation loss: 2.3522468664312877

Epoch: 6| Step: 1
Training loss: 3.1967711448669434
Validation loss: 2.3625703703972603

Epoch: 6| Step: 2
Training loss: 2.7696595191955566
Validation loss: 2.378065824508667

Epoch: 6| Step: 3
Training loss: 2.2770626544952393
Validation loss: 2.4073600948497815

Epoch: 6| Step: 4
Training loss: 3.0429863929748535
Validation loss: 2.4001574259932323

Epoch: 6| Step: 5
Training loss: 2.4788460731506348
Validation loss: 2.3644052064546974

Epoch: 6| Step: 6
Training loss: 2.430662155151367
Validation loss: 2.3455213244243334

Epoch: 6| Step: 7
Training loss: 2.959139347076416
Validation loss: 2.357532432002406

Epoch: 6| Step: 8
Training loss: 2.6150519847869873
Validation loss: 2.3730727959704656

Epoch: 6| Step: 9
Training loss: 2.2067651748657227
Validation loss: 2.3619607225541146

Epoch: 6| Step: 10
Training loss: 2.21097469329834
Validation loss: 2.3339559852436023

Epoch: 6| Step: 11
Training loss: 2.741689682006836
Validation loss: 2.3392494288823937

Epoch: 6| Step: 12
Training loss: 2.571883201599121
Validation loss: 2.3567505908268753

Epoch: 6| Step: 13
Training loss: 2.680164337158203
Validation loss: 2.3491116121251094

Epoch: 31| Step: 0
Training loss: 2.850489854812622
Validation loss: 2.348215297986102

Epoch: 6| Step: 1
Training loss: 2.431867837905884
Validation loss: 2.3704101731700282

Epoch: 6| Step: 2
Training loss: 2.1675519943237305
Validation loss: 2.381050568754955

Epoch: 6| Step: 3
Training loss: 2.2130508422851562
Validation loss: 2.4134014857712613

Epoch: 6| Step: 4
Training loss: 3.414567232131958
Validation loss: 2.4139550065481536

Epoch: 6| Step: 5
Training loss: 2.1971161365509033
Validation loss: 2.3930588306919223

Epoch: 6| Step: 6
Training loss: 2.4587979316711426
Validation loss: 2.370423842501897

Epoch: 6| Step: 7
Training loss: 3.2193779945373535
Validation loss: 2.3529241431143975

Epoch: 6| Step: 8
Training loss: 2.4198126792907715
Validation loss: 2.339638763858426

Epoch: 6| Step: 9
Training loss: 2.97409725189209
Validation loss: 2.332664453855125

Epoch: 6| Step: 10
Training loss: 2.8273234367370605
Validation loss: 2.3334542218075005

Epoch: 6| Step: 11
Training loss: 2.8047971725463867
Validation loss: 2.337557872136434

Epoch: 6| Step: 12
Training loss: 1.9404098987579346
Validation loss: 2.3417183942692255

Epoch: 6| Step: 13
Training loss: 2.54721736907959
Validation loss: 2.3439854037377144

Epoch: 32| Step: 0
Training loss: 2.168048620223999
Validation loss: 2.3461304608211724

Epoch: 6| Step: 1
Training loss: 2.63769268989563
Validation loss: 2.3415168844243532

Epoch: 6| Step: 2
Training loss: 2.808645248413086
Validation loss: 2.340100560137021

Epoch: 6| Step: 3
Training loss: 2.73087739944458
Validation loss: 2.3431251830952142

Epoch: 6| Step: 4
Training loss: 2.5085902214050293
Validation loss: 2.3392884936383975

Epoch: 6| Step: 5
Training loss: 2.8112995624542236
Validation loss: 2.3358606933265604

Epoch: 6| Step: 6
Training loss: 1.9252119064331055
Validation loss: 2.3391010069078013

Epoch: 6| Step: 7
Training loss: 2.1895511150360107
Validation loss: 2.35490426453211

Epoch: 6| Step: 8
Training loss: 3.1267521381378174
Validation loss: 2.383790323811193

Epoch: 6| Step: 9
Training loss: 2.3804380893707275
Validation loss: 2.402567614791214

Epoch: 6| Step: 10
Training loss: 2.717895984649658
Validation loss: 2.429533173961024

Epoch: 6| Step: 11
Training loss: 3.2076807022094727
Validation loss: 2.448194175638178

Epoch: 6| Step: 12
Training loss: 2.974893093109131
Validation loss: 2.453080754126272

Epoch: 6| Step: 13
Training loss: 3.0386171340942383
Validation loss: 2.4246297933722056

Epoch: 33| Step: 0
Training loss: 3.0661611557006836
Validation loss: 2.4258301360632784

Epoch: 6| Step: 1
Training loss: 2.2340409755706787
Validation loss: 2.4293555367377495

Epoch: 6| Step: 2
Training loss: 2.8336281776428223
Validation loss: 2.4131276530604207

Epoch: 6| Step: 3
Training loss: 2.5155117511749268
Validation loss: 2.3818302872360393

Epoch: 6| Step: 4
Training loss: 2.2887463569641113
Validation loss: 2.3833014644602293

Epoch: 6| Step: 5
Training loss: 3.173656463623047
Validation loss: 2.3635342428761144

Epoch: 6| Step: 6
Training loss: 2.5179104804992676
Validation loss: 2.329867591140091

Epoch: 6| Step: 7
Training loss: 2.418013572692871
Validation loss: 2.319764011649675

Epoch: 6| Step: 8
Training loss: 2.9153730869293213
Validation loss: 2.3084369449205298

Epoch: 6| Step: 9
Training loss: 2.6516129970550537
Validation loss: 2.301853810587237

Epoch: 6| Step: 10
Training loss: 2.0262742042541504
Validation loss: 2.3078692215745167

Epoch: 6| Step: 11
Training loss: 2.2543747425079346
Validation loss: 2.312255851684078

Epoch: 6| Step: 12
Training loss: 2.487492799758911
Validation loss: 2.3291096764226116

Epoch: 6| Step: 13
Training loss: 3.652787446975708
Validation loss: 2.3387531849645797

Epoch: 34| Step: 0
Training loss: 3.2158286571502686
Validation loss: 2.3186641098350607

Epoch: 6| Step: 1
Training loss: 3.2541298866271973
Validation loss: 2.3037658199187248

Epoch: 6| Step: 2
Training loss: 2.3235349655151367
Validation loss: 2.297387141053395

Epoch: 6| Step: 3
Training loss: 2.782151937484741
Validation loss: 2.2833270975338515

Epoch: 6| Step: 4
Training loss: 2.1578598022460938
Validation loss: 2.282136312095068

Epoch: 6| Step: 5
Training loss: 2.7336912155151367
Validation loss: 2.281945164485644

Epoch: 6| Step: 6
Training loss: 2.167625904083252
Validation loss: 2.2867906349961475

Epoch: 6| Step: 7
Training loss: 2.450956106185913
Validation loss: 2.2898332508661414

Epoch: 6| Step: 8
Training loss: 2.8159384727478027
Validation loss: 2.304585410702613

Epoch: 6| Step: 9
Training loss: 2.774366855621338
Validation loss: 2.308984024550325

Epoch: 6| Step: 10
Training loss: 2.0964550971984863
Validation loss: 2.321627181063416

Epoch: 6| Step: 11
Training loss: 1.9318733215332031
Validation loss: 2.3225711827637046

Epoch: 6| Step: 12
Training loss: 2.76495099067688
Validation loss: 2.3153502223312215

Epoch: 6| Step: 13
Training loss: 2.883906841278076
Validation loss: 2.3085455086923417

Epoch: 35| Step: 0
Training loss: 2.4505391120910645
Validation loss: 2.303309074012182

Epoch: 6| Step: 1
Training loss: 2.610757350921631
Validation loss: 2.299605959205217

Epoch: 6| Step: 2
Training loss: 3.1862411499023438
Validation loss: 2.2962853293265066

Epoch: 6| Step: 3
Training loss: 2.405790090560913
Validation loss: 2.2955856951334144

Epoch: 6| Step: 4
Training loss: 2.802184581756592
Validation loss: 2.297102633342948

Epoch: 6| Step: 5
Training loss: 2.657647132873535
Validation loss: 2.2931704239178727

Epoch: 6| Step: 6
Training loss: 1.9701590538024902
Validation loss: 2.2897967805144606

Epoch: 6| Step: 7
Training loss: 2.3277106285095215
Validation loss: 2.2876196343411683

Epoch: 6| Step: 8
Training loss: 3.2268338203430176
Validation loss: 2.2863349965823594

Epoch: 6| Step: 9
Training loss: 2.665525436401367
Validation loss: 2.2799900552277923

Epoch: 6| Step: 10
Training loss: 2.2217392921447754
Validation loss: 2.2933547317340808

Epoch: 6| Step: 11
Training loss: 1.8766318559646606
Validation loss: 2.310943535579148

Epoch: 6| Step: 12
Training loss: 2.9872069358825684
Validation loss: 2.326898564574539

Epoch: 6| Step: 13
Training loss: 2.6580400466918945
Validation loss: 2.3280200573705856

Epoch: 36| Step: 0
Training loss: 2.052175998687744
Validation loss: 2.401246009334441

Epoch: 6| Step: 1
Training loss: 2.130141258239746
Validation loss: 2.4725321364659134

Epoch: 6| Step: 2
Training loss: 2.83377742767334
Validation loss: 2.5958072280371063

Epoch: 6| Step: 3
Training loss: 3.2141366004943848
Validation loss: 2.5876938553266626

Epoch: 6| Step: 4
Training loss: 2.335171937942505
Validation loss: 2.496078875757033

Epoch: 6| Step: 5
Training loss: 3.3498730659484863
Validation loss: 2.4830285297927035

Epoch: 6| Step: 6
Training loss: 3.4995079040527344
Validation loss: 2.389837521378712

Epoch: 6| Step: 7
Training loss: 3.0260322093963623
Validation loss: 2.326335594218264

Epoch: 6| Step: 8
Training loss: 2.697758197784424
Validation loss: 2.2942341604540424

Epoch: 6| Step: 9
Training loss: 2.388974666595459
Validation loss: 2.310979357329748

Epoch: 6| Step: 10
Training loss: 2.0408968925476074
Validation loss: 2.340686516095233

Epoch: 6| Step: 11
Training loss: 3.0963311195373535
Validation loss: 2.3802533957266037

Epoch: 6| Step: 12
Training loss: 2.3147928714752197
Validation loss: 2.3535359136519896

Epoch: 6| Step: 13
Training loss: 1.607096552848816
Validation loss: 2.3065556941493863

Epoch: 37| Step: 0
Training loss: 2.704596996307373
Validation loss: 2.309642581529515

Epoch: 6| Step: 1
Training loss: 2.900057554244995
Validation loss: 2.320001881609681

Epoch: 6| Step: 2
Training loss: 2.1377921104431152
Validation loss: 2.3609501802793114

Epoch: 6| Step: 3
Training loss: 2.8995683193206787
Validation loss: 2.402751115060622

Epoch: 6| Step: 4
Training loss: 2.4783990383148193
Validation loss: 2.4590285542190715

Epoch: 6| Step: 5
Training loss: 3.103191375732422
Validation loss: 2.4935532385303127

Epoch: 6| Step: 6
Training loss: 2.7592806816101074
Validation loss: 2.5007543486933552

Epoch: 6| Step: 7
Training loss: 3.0525035858154297
Validation loss: 2.4878852213582685

Epoch: 6| Step: 8
Training loss: 2.0358591079711914
Validation loss: 2.4405787350029073

Epoch: 6| Step: 9
Training loss: 2.6634457111358643
Validation loss: 2.4057147887445267

Epoch: 6| Step: 10
Training loss: 2.9401397705078125
Validation loss: 2.3282333676533034

Epoch: 6| Step: 11
Training loss: 2.273685932159424
Validation loss: 2.2887351077090026

Epoch: 6| Step: 12
Training loss: 1.9025001525878906
Validation loss: 2.2626145732018257

Epoch: 6| Step: 13
Training loss: 2.666358470916748
Validation loss: 2.2657570736382597

Epoch: 38| Step: 0
Training loss: 2.700092077255249
Validation loss: 2.2783935813493628

Epoch: 6| Step: 1
Training loss: 1.8684509992599487
Validation loss: 2.3086845746604343

Epoch: 6| Step: 2
Training loss: 2.279252529144287
Validation loss: 2.311316736282841

Epoch: 6| Step: 3
Training loss: 2.2169711589813232
Validation loss: 2.3193713336862545

Epoch: 6| Step: 4
Training loss: 2.923997402191162
Validation loss: 2.331727712385116

Epoch: 6| Step: 5
Training loss: 2.740293264389038
Validation loss: 2.337239226987285

Epoch: 6| Step: 6
Training loss: 3.3193342685699463
Validation loss: 2.297602484303136

Epoch: 6| Step: 7
Training loss: 2.42543363571167
Validation loss: 2.2702215204956713

Epoch: 6| Step: 8
Training loss: 2.482351541519165
Validation loss: 2.2537508344137542

Epoch: 6| Step: 9
Training loss: 2.4394373893737793
Validation loss: 2.2492681651987056

Epoch: 6| Step: 10
Training loss: 2.6356191635131836
Validation loss: 2.2480670969973326

Epoch: 6| Step: 11
Training loss: 2.904229164123535
Validation loss: 2.264820656468791

Epoch: 6| Step: 12
Training loss: 2.6873531341552734
Validation loss: 2.281730223727483

Epoch: 6| Step: 13
Training loss: 2.7448501586914062
Validation loss: 2.2999356536455053

Epoch: 39| Step: 0
Training loss: 2.3850903511047363
Validation loss: 2.3053223368942097

Epoch: 6| Step: 1
Training loss: 2.3802828788757324
Validation loss: 2.3059251398168583

Epoch: 6| Step: 2
Training loss: 2.27268385887146
Validation loss: 2.323018035581035

Epoch: 6| Step: 3
Training loss: 2.8401944637298584
Validation loss: 2.322246507931781

Epoch: 6| Step: 4
Training loss: 2.934504985809326
Validation loss: 2.3230519961285334

Epoch: 6| Step: 5
Training loss: 2.0542964935302734
Validation loss: 2.3233607404975483

Epoch: 6| Step: 6
Training loss: 2.6507515907287598
Validation loss: 2.314322598518864

Epoch: 6| Step: 7
Training loss: 2.6343002319335938
Validation loss: 2.3168555485304965

Epoch: 6| Step: 8
Training loss: 2.756483316421509
Validation loss: 2.288917362049062

Epoch: 6| Step: 9
Training loss: 2.5002360343933105
Validation loss: 2.2697995029469973

Epoch: 6| Step: 10
Training loss: 2.5877084732055664
Validation loss: 2.249467924077024

Epoch: 6| Step: 11
Training loss: 3.017005443572998
Validation loss: 2.2403133594861595

Epoch: 6| Step: 12
Training loss: 2.5493319034576416
Validation loss: 2.2344440003877044

Epoch: 6| Step: 13
Training loss: 2.0171618461608887
Validation loss: 2.2291185073955084

Epoch: 40| Step: 0
Training loss: 2.5590453147888184
Validation loss: 2.232837917984173

Epoch: 6| Step: 1
Training loss: 3.39298152923584
Validation loss: 2.230700636422762

Epoch: 6| Step: 2
Training loss: 1.932520866394043
Validation loss: 2.227655922212908

Epoch: 6| Step: 3
Training loss: 2.6112489700317383
Validation loss: 2.231003697200488

Epoch: 6| Step: 4
Training loss: 2.7625441551208496
Validation loss: 2.2354134334030973

Epoch: 6| Step: 5
Training loss: 2.527162551879883
Validation loss: 2.232500409567228

Epoch: 6| Step: 6
Training loss: 3.1279568672180176
Validation loss: 2.2393303391753987

Epoch: 6| Step: 7
Training loss: 2.5010616779327393
Validation loss: 2.238738825244288

Epoch: 6| Step: 8
Training loss: 2.1713171005249023
Validation loss: 2.236246306409118

Epoch: 6| Step: 9
Training loss: 2.625025749206543
Validation loss: 2.2365968317113896

Epoch: 6| Step: 10
Training loss: 3.4508957862854004
Validation loss: 2.2405252789938324

Epoch: 6| Step: 11
Training loss: 1.3687667846679688
Validation loss: 2.2418193227501324

Epoch: 6| Step: 12
Training loss: 2.6524300575256348
Validation loss: 2.2461643321539766

Epoch: 6| Step: 13
Training loss: 1.6501227617263794
Validation loss: 2.2447708511865265

Epoch: 41| Step: 0
Training loss: 2.422415256500244
Validation loss: 2.255324625199841

Epoch: 6| Step: 1
Training loss: 2.60467791557312
Validation loss: 2.2741832656245076

Epoch: 6| Step: 2
Training loss: 2.533411741256714
Validation loss: 2.272963793047013

Epoch: 6| Step: 3
Training loss: 2.2362799644470215
Validation loss: 2.2490448772266345

Epoch: 6| Step: 4
Training loss: 2.4278883934020996
Validation loss: 2.237841083157447

Epoch: 6| Step: 5
Training loss: 3.215507745742798
Validation loss: 2.229586209020307

Epoch: 6| Step: 6
Training loss: 2.6918587684631348
Validation loss: 2.2209269795366513

Epoch: 6| Step: 7
Training loss: 2.215184450149536
Validation loss: 2.2170307072260047

Epoch: 6| Step: 8
Training loss: 2.4191951751708984
Validation loss: 2.2202747432134484

Epoch: 6| Step: 9
Training loss: 2.086653470993042
Validation loss: 2.2216133789349626

Epoch: 6| Step: 10
Training loss: 2.8127825260162354
Validation loss: 2.217767584708429

Epoch: 6| Step: 11
Training loss: 3.0368571281433105
Validation loss: 2.2274269493677283

Epoch: 6| Step: 12
Training loss: 2.8517143726348877
Validation loss: 2.2323385130974556

Epoch: 6| Step: 13
Training loss: 1.9346883296966553
Validation loss: 2.247953153425647

Epoch: 42| Step: 0
Training loss: 1.9861011505126953
Validation loss: 2.2535261159302085

Epoch: 6| Step: 1
Training loss: 3.3077919483184814
Validation loss: 2.2576539401085145

Epoch: 6| Step: 2
Training loss: 2.758791923522949
Validation loss: 2.264216721698802

Epoch: 6| Step: 3
Training loss: 2.8776893615722656
Validation loss: 2.249950196153374

Epoch: 6| Step: 4
Training loss: 2.3240416049957275
Validation loss: 2.245434599538003

Epoch: 6| Step: 5
Training loss: 2.0220582485198975
Validation loss: 2.2218807576805033

Epoch: 6| Step: 6
Training loss: 2.1401233673095703
Validation loss: 2.218731003422891

Epoch: 6| Step: 7
Training loss: 2.7875571250915527
Validation loss: 2.211685872847034

Epoch: 6| Step: 8
Training loss: 2.7092204093933105
Validation loss: 2.215970552095803

Epoch: 6| Step: 9
Training loss: 2.364102840423584
Validation loss: 2.2088842622695433

Epoch: 6| Step: 10
Training loss: 2.5151805877685547
Validation loss: 2.2164058403302263

Epoch: 6| Step: 11
Training loss: 2.6781535148620605
Validation loss: 2.2111637156496764

Epoch: 6| Step: 12
Training loss: 2.4405574798583984
Validation loss: 2.2060192528591362

Epoch: 6| Step: 13
Training loss: 2.9441919326782227
Validation loss: 2.2097103493188017

Epoch: 43| Step: 0
Training loss: 2.180144786834717
Validation loss: 2.210195226054038

Epoch: 6| Step: 1
Training loss: 2.460022211074829
Validation loss: 2.2164181893871677

Epoch: 6| Step: 2
Training loss: 1.5448349714279175
Validation loss: 2.2229834500179497

Epoch: 6| Step: 3
Training loss: 2.301037073135376
Validation loss: 2.225259188682802

Epoch: 6| Step: 4
Training loss: 2.75938081741333
Validation loss: 2.2352276950754146

Epoch: 6| Step: 5
Training loss: 2.743837833404541
Validation loss: 2.2360345086743756

Epoch: 6| Step: 6
Training loss: 2.859607219696045
Validation loss: 2.236855645333567

Epoch: 6| Step: 7
Training loss: 3.031466484069824
Validation loss: 2.2355367945086573

Epoch: 6| Step: 8
Training loss: 2.3270814418792725
Validation loss: 2.246593908597064

Epoch: 6| Step: 9
Training loss: 2.836275815963745
Validation loss: 2.2637429442456973

Epoch: 6| Step: 10
Training loss: 2.621828079223633
Validation loss: 2.268297682526291

Epoch: 6| Step: 11
Training loss: 3.4135985374450684
Validation loss: 2.301952385133313

Epoch: 6| Step: 12
Training loss: 2.0439226627349854
Validation loss: 2.307344321281679

Epoch: 6| Step: 13
Training loss: 2.2409141063690186
Validation loss: 2.296301593062698

Epoch: 44| Step: 0
Training loss: 2.3517959117889404
Validation loss: 2.2770753534891273

Epoch: 6| Step: 1
Training loss: 1.818037748336792
Validation loss: 2.279900550842285

Epoch: 6| Step: 2
Training loss: 2.050088405609131
Validation loss: 2.2627899262212936

Epoch: 6| Step: 3
Training loss: 2.8290762901306152
Validation loss: 2.228890839443412

Epoch: 6| Step: 4
Training loss: 3.4186248779296875
Validation loss: 2.211246330250976

Epoch: 6| Step: 5
Training loss: 3.1456708908081055
Validation loss: 2.2058646896834015

Epoch: 6| Step: 6
Training loss: 2.791604518890381
Validation loss: 2.20087049212507

Epoch: 6| Step: 7
Training loss: 2.4983110427856445
Validation loss: 2.201905753022881

Epoch: 6| Step: 8
Training loss: 2.719940185546875
Validation loss: 2.2014124239644697

Epoch: 6| Step: 9
Training loss: 2.337076187133789
Validation loss: 2.1987515393123833

Epoch: 6| Step: 10
Training loss: 2.1511924266815186
Validation loss: 2.196226586577713

Epoch: 6| Step: 11
Training loss: 2.3229269981384277
Validation loss: 2.1990249080042683

Epoch: 6| Step: 12
Training loss: 2.3425121307373047
Validation loss: 2.1980607612158662

Epoch: 6| Step: 13
Training loss: 2.4829463958740234
Validation loss: 2.205999723044775

Epoch: 45| Step: 0
Training loss: 2.3335928916931152
Validation loss: 2.2069647196800477

Epoch: 6| Step: 1
Training loss: 2.1051321029663086
Validation loss: 2.2123786531468874

Epoch: 6| Step: 2
Training loss: 2.975287437438965
Validation loss: 2.2132941522905902

Epoch: 6| Step: 3
Training loss: 2.459754228591919
Validation loss: 2.218189718902752

Epoch: 6| Step: 4
Training loss: 2.5104739665985107
Validation loss: 2.2381487777156215

Epoch: 6| Step: 5
Training loss: 2.8051905632019043
Validation loss: 2.245737111696633

Epoch: 6| Step: 6
Training loss: 2.2386293411254883
Validation loss: 2.2735142297642206

Epoch: 6| Step: 7
Training loss: 2.6933035850524902
Validation loss: 2.2917861195020777

Epoch: 6| Step: 8
Training loss: 2.643773078918457
Validation loss: 2.2851567755463305

Epoch: 6| Step: 9
Training loss: 2.218679189682007
Validation loss: 2.3022442325468986

Epoch: 6| Step: 10
Training loss: 3.270083427429199
Validation loss: 2.2991024755662486

Epoch: 6| Step: 11
Training loss: 2.320010185241699
Validation loss: 2.262314716974894

Epoch: 6| Step: 12
Training loss: 2.3499176502227783
Validation loss: 2.2293902622756137

Epoch: 6| Step: 13
Training loss: 2.4034860134124756
Validation loss: 2.204475297722765

Epoch: 46| Step: 0
Training loss: 2.249485492706299
Validation loss: 2.2108269199248283

Epoch: 6| Step: 1
Training loss: 1.5617331266403198
Validation loss: 2.204580419807024

Epoch: 6| Step: 2
Training loss: 2.5358588695526123
Validation loss: 2.2237655475575435

Epoch: 6| Step: 3
Training loss: 2.483006477355957
Validation loss: 2.236342796715357

Epoch: 6| Step: 4
Training loss: 2.4812843799591064
Validation loss: 2.2591562322390977

Epoch: 6| Step: 5
Training loss: 3.2167465686798096
Validation loss: 2.2810787616237516

Epoch: 6| Step: 6
Training loss: 2.25850248336792
Validation loss: 2.300895085898779

Epoch: 6| Step: 7
Training loss: 2.8731141090393066
Validation loss: 2.2971498658580165

Epoch: 6| Step: 8
Training loss: 2.55502986907959
Validation loss: 2.2956901058073966

Epoch: 6| Step: 9
Training loss: 3.0149283409118652
Validation loss: 2.2881820624874485

Epoch: 6| Step: 10
Training loss: 2.81327748298645
Validation loss: 2.2740828452571744

Epoch: 6| Step: 11
Training loss: 3.1614456176757812
Validation loss: 2.2512293989940355

Epoch: 6| Step: 12
Training loss: 2.1245028972625732
Validation loss: 2.239035442311277

Epoch: 6| Step: 13
Training loss: 1.586190938949585
Validation loss: 2.2242928935635473

Epoch: 47| Step: 0
Training loss: 1.984999656677246
Validation loss: 2.2183767262325493

Epoch: 6| Step: 1
Training loss: 2.345930337905884
Validation loss: 2.23017551565683

Epoch: 6| Step: 2
Training loss: 2.5738797187805176
Validation loss: 2.244062997961557

Epoch: 6| Step: 3
Training loss: 3.1832833290100098
Validation loss: 2.275721452569449

Epoch: 6| Step: 4
Training loss: 2.7433180809020996
Validation loss: 2.2761722764661236

Epoch: 6| Step: 5
Training loss: 2.7851758003234863
Validation loss: 2.2737537019996235

Epoch: 6| Step: 6
Training loss: 1.6989995241165161
Validation loss: 2.260210496123119

Epoch: 6| Step: 7
Training loss: 3.2872226238250732
Validation loss: 2.240997483653407

Epoch: 6| Step: 8
Training loss: 2.3920814990997314
Validation loss: 2.2314352668741697

Epoch: 6| Step: 9
Training loss: 3.2219276428222656
Validation loss: 2.233110022801225

Epoch: 6| Step: 10
Training loss: 2.5003769397735596
Validation loss: 2.2261746442446144

Epoch: 6| Step: 11
Training loss: 2.3070240020751953
Validation loss: 2.227688422767065

Epoch: 6| Step: 12
Training loss: 2.0234694480895996
Validation loss: 2.239075094140986

Epoch: 6| Step: 13
Training loss: 1.7110813856124878
Validation loss: 2.2449803531810804

Epoch: 48| Step: 0
Training loss: 2.541029453277588
Validation loss: 2.2533172407457904

Epoch: 6| Step: 1
Training loss: 2.2417383193969727
Validation loss: 2.240968890087579

Epoch: 6| Step: 2
Training loss: 2.1754446029663086
Validation loss: 2.2135502599900767

Epoch: 6| Step: 3
Training loss: 2.802064895629883
Validation loss: 2.206077793593048

Epoch: 6| Step: 4
Training loss: 2.2248482704162598
Validation loss: 2.202028512954712

Epoch: 6| Step: 5
Training loss: 2.7914674282073975
Validation loss: 2.2020107494887484

Epoch: 6| Step: 6
Training loss: 2.126405715942383
Validation loss: 2.1958009940321728

Epoch: 6| Step: 7
Training loss: 2.6066322326660156
Validation loss: 2.1990385029905584

Epoch: 6| Step: 8
Training loss: 2.699974536895752
Validation loss: 2.202656904856364

Epoch: 6| Step: 9
Training loss: 2.7153663635253906
Validation loss: 2.220023488485685

Epoch: 6| Step: 10
Training loss: 3.1135168075561523
Validation loss: 2.220070490273096

Epoch: 6| Step: 11
Training loss: 1.9311048984527588
Validation loss: 2.226959838662096

Epoch: 6| Step: 12
Training loss: 2.671320915222168
Validation loss: 2.2525758704831524

Epoch: 6| Step: 13
Training loss: 2.406667947769165
Validation loss: 2.260018853731053

Epoch: 49| Step: 0
Training loss: 2.9198172092437744
Validation loss: 2.2739036672858783

Epoch: 6| Step: 1
Training loss: 3.3911032676696777
Validation loss: 2.29392566732181

Epoch: 6| Step: 2
Training loss: 1.837609052658081
Validation loss: 2.314824181218301

Epoch: 6| Step: 3
Training loss: 2.560453414916992
Validation loss: 2.3117064711868123

Epoch: 6| Step: 4
Training loss: 1.8479454517364502
Validation loss: 2.281996424480151

Epoch: 6| Step: 5
Training loss: 3.099968194961548
Validation loss: 2.251848061879476

Epoch: 6| Step: 6
Training loss: 1.9184367656707764
Validation loss: 2.235341109255309

Epoch: 6| Step: 7
Training loss: 2.3545286655426025
Validation loss: 2.2234460781979304

Epoch: 6| Step: 8
Training loss: 2.1770002841949463
Validation loss: 2.214963536108694

Epoch: 6| Step: 9
Training loss: 3.3225395679473877
Validation loss: 2.2093732280115925

Epoch: 6| Step: 10
Training loss: 2.7889325618743896
Validation loss: 2.198726628416328

Epoch: 6| Step: 11
Training loss: 2.233063220977783
Validation loss: 2.1907996234073432

Epoch: 6| Step: 12
Training loss: 2.3820247650146484
Validation loss: 2.190241531659198

Epoch: 6| Step: 13
Training loss: 2.4535973072052
Validation loss: 2.192253592193768

Epoch: 50| Step: 0
Training loss: 2.204958200454712
Validation loss: 2.203367187130836

Epoch: 6| Step: 1
Training loss: 2.3893344402313232
Validation loss: 2.2195845150178477

Epoch: 6| Step: 2
Training loss: 2.6546471118927
Validation loss: 2.1921209032817552

Epoch: 6| Step: 3
Training loss: 2.203646183013916
Validation loss: 2.1786211895686325

Epoch: 6| Step: 4
Training loss: 3.104767322540283
Validation loss: 2.18173296477205

Epoch: 6| Step: 5
Training loss: 2.521413803100586
Validation loss: 2.1723627710855133

Epoch: 6| Step: 6
Training loss: 2.5189321041107178
Validation loss: 2.172166439794725

Epoch: 6| Step: 7
Training loss: 2.6869516372680664
Validation loss: 2.1611857696246077

Epoch: 6| Step: 8
Training loss: 2.917156219482422
Validation loss: 2.165621289642908

Epoch: 6| Step: 9
Training loss: 2.5280885696411133
Validation loss: 2.1550887887195875

Epoch: 6| Step: 10
Training loss: 2.392958641052246
Validation loss: 2.155273796409689

Epoch: 6| Step: 11
Training loss: 2.753370523452759
Validation loss: 2.164493355699765

Epoch: 6| Step: 12
Training loss: 1.8235061168670654
Validation loss: 2.1625472525114655

Epoch: 6| Step: 13
Training loss: 2.0888476371765137
Validation loss: 2.1708632182049494

Epoch: 51| Step: 0
Training loss: 2.965583324432373
Validation loss: 2.16558474750929

Epoch: 6| Step: 1
Training loss: 2.684602737426758
Validation loss: 2.1759991543267363

Epoch: 6| Step: 2
Training loss: 2.5762429237365723
Validation loss: 2.1843494984411422

Epoch: 6| Step: 3
Training loss: 2.753502368927002
Validation loss: 2.2038997680910173

Epoch: 6| Step: 4
Training loss: 2.583653688430786
Validation loss: 2.244493960052408

Epoch: 6| Step: 5
Training loss: 2.015760898590088
Validation loss: 2.284902577759117

Epoch: 6| Step: 6
Training loss: 2.3677334785461426
Validation loss: 2.3179113685443835

Epoch: 6| Step: 7
Training loss: 2.4200568199157715
Validation loss: 2.286821872957291

Epoch: 6| Step: 8
Training loss: 2.403141975402832
Validation loss: 2.245603824174532

Epoch: 6| Step: 9
Training loss: 2.7497706413269043
Validation loss: 2.2025520852817

Epoch: 6| Step: 10
Training loss: 2.3728582859039307
Validation loss: 2.1705631056139545

Epoch: 6| Step: 11
Training loss: 2.9112186431884766
Validation loss: 2.156876230752596

Epoch: 6| Step: 12
Training loss: 1.609323501586914
Validation loss: 2.1553885065099245

Epoch: 6| Step: 13
Training loss: 2.771233558654785
Validation loss: 2.160759920715004

Epoch: 52| Step: 0
Training loss: 2.57271146774292
Validation loss: 2.1660658274927447

Epoch: 6| Step: 1
Training loss: 2.6594326496124268
Validation loss: 2.1596460573134886

Epoch: 6| Step: 2
Training loss: 2.209956645965576
Validation loss: 2.1531806479218187

Epoch: 6| Step: 3
Training loss: 1.9955427646636963
Validation loss: 2.1606076430248957

Epoch: 6| Step: 4
Training loss: 3.448469638824463
Validation loss: 2.1596839299765964

Epoch: 6| Step: 5
Training loss: 1.9410288333892822
Validation loss: 2.161685869257937

Epoch: 6| Step: 6
Training loss: 2.3396759033203125
Validation loss: 2.1695718803713397

Epoch: 6| Step: 7
Training loss: 2.162508726119995
Validation loss: 2.1810576479922057

Epoch: 6| Step: 8
Training loss: 2.0708842277526855
Validation loss: 2.193916554092079

Epoch: 6| Step: 9
Training loss: 2.5705859661102295
Validation loss: 2.215966684843904

Epoch: 6| Step: 10
Training loss: 2.7580013275146484
Validation loss: 2.209587812423706

Epoch: 6| Step: 11
Training loss: 2.396648406982422
Validation loss: 2.219794851477428

Epoch: 6| Step: 12
Training loss: 2.657139301300049
Validation loss: 2.2464224394931587

Epoch: 6| Step: 13
Training loss: 3.552715301513672
Validation loss: 2.336090341691048

Epoch: 53| Step: 0
Training loss: 2.1806647777557373
Validation loss: 2.3460497240866385

Epoch: 6| Step: 1
Training loss: 2.6239590644836426
Validation loss: 2.2855839370399393

Epoch: 6| Step: 2
Training loss: 2.2137675285339355
Validation loss: 2.2268301453641666

Epoch: 6| Step: 3
Training loss: 2.5770113468170166
Validation loss: 2.200417895470896

Epoch: 6| Step: 4
Training loss: 2.5017483234405518
Validation loss: 2.169226465686675

Epoch: 6| Step: 5
Training loss: 2.259641647338867
Validation loss: 2.154447582460219

Epoch: 6| Step: 6
Training loss: 2.397939682006836
Validation loss: 2.1550537693885063

Epoch: 6| Step: 7
Training loss: 2.8289456367492676
Validation loss: 2.1495352201564337

Epoch: 6| Step: 8
Training loss: 1.7920252084732056
Validation loss: 2.1559434167800413

Epoch: 6| Step: 9
Training loss: 2.393016815185547
Validation loss: 2.164948190412214

Epoch: 6| Step: 10
Training loss: 2.843651294708252
Validation loss: 2.1783659791433685

Epoch: 6| Step: 11
Training loss: 2.831602096557617
Validation loss: 2.2075720602466213

Epoch: 6| Step: 12
Training loss: 3.085545063018799
Validation loss: 2.2060608453648065

Epoch: 6| Step: 13
Training loss: 2.2017900943756104
Validation loss: 2.186655362447103

Epoch: 54| Step: 0
Training loss: 2.11761474609375
Validation loss: 2.157520314698578

Epoch: 6| Step: 1
Training loss: 2.666496992111206
Validation loss: 2.150493198825467

Epoch: 6| Step: 2
Training loss: 2.1451363563537598
Validation loss: 2.137095961519467

Epoch: 6| Step: 3
Training loss: 2.7745213508605957
Validation loss: 2.13540611087635

Epoch: 6| Step: 4
Training loss: 2.0706329345703125
Validation loss: 2.135351796304026

Epoch: 6| Step: 5
Training loss: 3.076106548309326
Validation loss: 2.1287162162924327

Epoch: 6| Step: 6
Training loss: 2.068502426147461
Validation loss: 2.1376522715373705

Epoch: 6| Step: 7
Training loss: 2.201519012451172
Validation loss: 2.1307026570843113

Epoch: 6| Step: 8
Training loss: 2.2714169025421143
Validation loss: 2.1352803784032024

Epoch: 6| Step: 9
Training loss: 2.83123779296875
Validation loss: 2.143656938306747

Epoch: 6| Step: 10
Training loss: 2.491121530532837
Validation loss: 2.1649831982069117

Epoch: 6| Step: 11
Training loss: 2.545309543609619
Validation loss: 2.2082576995254843

Epoch: 6| Step: 12
Training loss: 3.3650670051574707
Validation loss: 2.201060502759872

Epoch: 6| Step: 13
Training loss: 1.5967689752578735
Validation loss: 2.1986219062600085

Epoch: 55| Step: 0
Training loss: 2.4673545360565186
Validation loss: 2.1956393795628704

Epoch: 6| Step: 1
Training loss: 2.0577664375305176
Validation loss: 2.19216263422402

Epoch: 6| Step: 2
Training loss: 2.066650390625
Validation loss: 2.182310183842977

Epoch: 6| Step: 3
Training loss: 2.695739269256592
Validation loss: 2.163270950317383

Epoch: 6| Step: 4
Training loss: 1.8508683443069458
Validation loss: 2.1393663216662664

Epoch: 6| Step: 5
Training loss: 2.109286308288574
Validation loss: 2.1399173095662105

Epoch: 6| Step: 6
Training loss: 1.7409780025482178
Validation loss: 2.1317199366067046

Epoch: 6| Step: 7
Training loss: 2.4877262115478516
Validation loss: 2.134461715657224

Epoch: 6| Step: 8
Training loss: 2.524442672729492
Validation loss: 2.138415587845669

Epoch: 6| Step: 9
Training loss: 2.7976675033569336
Validation loss: 2.171082692761575

Epoch: 6| Step: 10
Training loss: 2.6615848541259766
Validation loss: 2.1444021437757756

Epoch: 6| Step: 11
Training loss: 3.041889190673828
Validation loss: 2.137818133959206

Epoch: 6| Step: 12
Training loss: 3.0620639324188232
Validation loss: 2.13326330595119

Epoch: 6| Step: 13
Training loss: 3.239179849624634
Validation loss: 2.135615106551878

Epoch: 56| Step: 0
Training loss: 2.2709412574768066
Validation loss: 2.133836514206343

Epoch: 6| Step: 1
Training loss: 2.09881854057312
Validation loss: 2.1459799761413247

Epoch: 6| Step: 2
Training loss: 2.278923273086548
Validation loss: 2.146205855954078

Epoch: 6| Step: 3
Training loss: 3.3610775470733643
Validation loss: 2.1467821726235012

Epoch: 6| Step: 4
Training loss: 2.7268552780151367
Validation loss: 2.139362137804749

Epoch: 6| Step: 5
Training loss: 2.9780993461608887
Validation loss: 2.1355798834113666

Epoch: 6| Step: 6
Training loss: 2.1151280403137207
Validation loss: 2.135190817617601

Epoch: 6| Step: 7
Training loss: 2.4400761127471924
Validation loss: 2.1324115542955298

Epoch: 6| Step: 8
Training loss: 2.4419844150543213
Validation loss: 2.1343210538228354

Epoch: 6| Step: 9
Training loss: 2.4007067680358887
Validation loss: 2.1393089755888908

Epoch: 6| Step: 10
Training loss: 2.2796175479888916
Validation loss: 2.1404447811906055

Epoch: 6| Step: 11
Training loss: 2.1761972904205322
Validation loss: 2.154270993765964

Epoch: 6| Step: 12
Training loss: 2.458768367767334
Validation loss: 2.1639728494869765

Epoch: 6| Step: 13
Training loss: 2.036604881286621
Validation loss: 2.1662287430096696

Epoch: 57| Step: 0
Training loss: 2.2642383575439453
Validation loss: 2.1830062174027964

Epoch: 6| Step: 1
Training loss: 2.8174941539764404
Validation loss: 2.183018135768111

Epoch: 6| Step: 2
Training loss: 2.463879108428955
Validation loss: 2.1788850856083695

Epoch: 6| Step: 3
Training loss: 2.648794651031494
Validation loss: 2.2094213783100085

Epoch: 6| Step: 4
Training loss: 2.3421406745910645
Validation loss: 2.2071014681170062

Epoch: 6| Step: 5
Training loss: 2.129333972930908
Validation loss: 2.2022312559107298

Epoch: 6| Step: 6
Training loss: 2.341083288192749
Validation loss: 2.135629056602396

Epoch: 6| Step: 7
Training loss: 2.2059438228607178
Validation loss: 2.1225432785608436

Epoch: 6| Step: 8
Training loss: 2.548795700073242
Validation loss: 2.1209184738897506

Epoch: 6| Step: 9
Training loss: 2.5670084953308105
Validation loss: 2.1474681605574903

Epoch: 6| Step: 10
Training loss: 2.572657585144043
Validation loss: 2.1635045569430114

Epoch: 6| Step: 11
Training loss: 2.169166326522827
Validation loss: 2.1767630987269904

Epoch: 6| Step: 12
Training loss: 2.9220681190490723
Validation loss: 2.1880432072506157

Epoch: 6| Step: 13
Training loss: 2.4508676528930664
Validation loss: 2.162839292198099

Epoch: 58| Step: 0
Training loss: 3.1114158630371094
Validation loss: 2.157127344480125

Epoch: 6| Step: 1
Training loss: 2.1594841480255127
Validation loss: 2.136275783661873

Epoch: 6| Step: 2
Training loss: 2.685779333114624
Validation loss: 2.1267514331366426

Epoch: 6| Step: 3
Training loss: 2.787879228591919
Validation loss: 2.1351636468723254

Epoch: 6| Step: 4
Training loss: 2.920708656311035
Validation loss: 2.132496549237159

Epoch: 6| Step: 5
Training loss: 2.2708685398101807
Validation loss: 2.138921235197334

Epoch: 6| Step: 6
Training loss: 2.14963436126709
Validation loss: 2.1471614068554294

Epoch: 6| Step: 7
Training loss: 2.8501405715942383
Validation loss: 2.1550166965812765

Epoch: 6| Step: 8
Training loss: 2.2668700218200684
Validation loss: 2.1464252664196874

Epoch: 6| Step: 9
Training loss: 2.256016254425049
Validation loss: 2.141777379538423

Epoch: 6| Step: 10
Training loss: 2.158968687057495
Validation loss: 2.1374828853914813

Epoch: 6| Step: 11
Training loss: 2.187605857849121
Validation loss: 2.1387747974805933

Epoch: 6| Step: 12
Training loss: 2.064697504043579
Validation loss: 2.13072290215441

Epoch: 6| Step: 13
Training loss: 1.976204752922058
Validation loss: 2.119797832222395

Epoch: 59| Step: 0
Training loss: 2.421248435974121
Validation loss: 2.1155759724237586

Epoch: 6| Step: 1
Training loss: 2.941169023513794
Validation loss: 2.1090385631848405

Epoch: 6| Step: 2
Training loss: 2.3922650814056396
Validation loss: 2.1075481061012513

Epoch: 6| Step: 3
Training loss: 1.9492852687835693
Validation loss: 2.110200507666475

Epoch: 6| Step: 4
Training loss: 2.5815210342407227
Validation loss: 2.1112070929619575

Epoch: 6| Step: 5
Training loss: 1.9379221200942993
Validation loss: 2.1127066458425214

Epoch: 6| Step: 6
Training loss: 2.775249481201172
Validation loss: 2.117785084632135

Epoch: 6| Step: 7
Training loss: 2.2047839164733887
Validation loss: 2.1149471511123

Epoch: 6| Step: 8
Training loss: 2.1389365196228027
Validation loss: 2.138208871246666

Epoch: 6| Step: 9
Training loss: 2.488640785217285
Validation loss: 2.148224130753548

Epoch: 6| Step: 10
Training loss: 2.87843656539917
Validation loss: 2.1645139314795054

Epoch: 6| Step: 11
Training loss: 2.506359100341797
Validation loss: 2.1750628256028697

Epoch: 6| Step: 12
Training loss: 2.466610908508301
Validation loss: 2.174446345657431

Epoch: 6| Step: 13
Training loss: 1.9339945316314697
Validation loss: 2.157535219705233

Epoch: 60| Step: 0
Training loss: 2.9755210876464844
Validation loss: 2.140829699013823

Epoch: 6| Step: 1
Training loss: 2.3866589069366455
Validation loss: 2.1272822298029417

Epoch: 6| Step: 2
Training loss: 2.7650163173675537
Validation loss: 2.1140055246250604

Epoch: 6| Step: 3
Training loss: 2.7785751819610596
Validation loss: 2.103882543502315

Epoch: 6| Step: 4
Training loss: 2.8295185565948486
Validation loss: 2.099331901919457

Epoch: 6| Step: 5
Training loss: 1.870203971862793
Validation loss: 2.094343980153402

Epoch: 6| Step: 6
Training loss: 2.224358558654785
Validation loss: 2.0947150427808046

Epoch: 6| Step: 7
Training loss: 2.610915184020996
Validation loss: 2.0954345592888455

Epoch: 6| Step: 8
Training loss: 2.20377254486084
Validation loss: 2.094361671837427

Epoch: 6| Step: 9
Training loss: 2.5721137523651123
Validation loss: 2.1013795252769225

Epoch: 6| Step: 10
Training loss: 1.9636554718017578
Validation loss: 2.1072483370381017

Epoch: 6| Step: 11
Training loss: 2.1579904556274414
Validation loss: 2.1078057878760883

Epoch: 6| Step: 12
Training loss: 2.4803504943847656
Validation loss: 2.1067328247972714

Epoch: 6| Step: 13
Training loss: 1.5801013708114624
Validation loss: 2.1231927076975503

Epoch: 61| Step: 0
Training loss: 1.8163936138153076
Validation loss: 2.1433441126218407

Epoch: 6| Step: 1
Training loss: 2.5172014236450195
Validation loss: 2.1512260744648595

Epoch: 6| Step: 2
Training loss: 2.126251697540283
Validation loss: 2.179839477744154

Epoch: 6| Step: 3
Training loss: 2.459926128387451
Validation loss: 2.2244142665657947

Epoch: 6| Step: 4
Training loss: 3.12326717376709
Validation loss: 2.2664884264751146

Epoch: 6| Step: 5
Training loss: 1.435009241104126
Validation loss: 2.2278831799825034

Epoch: 6| Step: 6
Training loss: 3.3226349353790283
Validation loss: 2.2092505616526448

Epoch: 6| Step: 7
Training loss: 2.762604236602783
Validation loss: 2.1625386232970865

Epoch: 6| Step: 8
Training loss: 2.960340976715088
Validation loss: 2.1325394056176625

Epoch: 6| Step: 9
Training loss: 2.2339296340942383
Validation loss: 2.112096696771601

Epoch: 6| Step: 10
Training loss: 2.792166233062744
Validation loss: 2.0923223187846522

Epoch: 6| Step: 11
Training loss: 1.8539224863052368
Validation loss: 2.0855508696648384

Epoch: 6| Step: 12
Training loss: 2.30885648727417
Validation loss: 2.0830835014261226

Epoch: 6| Step: 13
Training loss: 2.5528628826141357
Validation loss: 2.1016699242335495

Epoch: 62| Step: 0
Training loss: 3.187000274658203
Validation loss: 2.1027546236591954

Epoch: 6| Step: 1
Training loss: 2.0520262718200684
Validation loss: 2.1101241957756782

Epoch: 6| Step: 2
Training loss: 3.3696036338806152
Validation loss: 2.113864685899468

Epoch: 6| Step: 3
Training loss: 2.3885035514831543
Validation loss: 2.11943450538061

Epoch: 6| Step: 4
Training loss: 2.325151205062866
Validation loss: 2.116477935544906

Epoch: 6| Step: 5
Training loss: 3.2338624000549316
Validation loss: 2.120536963144938

Epoch: 6| Step: 6
Training loss: 2.221473455429077
Validation loss: 2.1163763384665213

Epoch: 6| Step: 7
Training loss: 2.032099723815918
Validation loss: 2.1086075357211533

Epoch: 6| Step: 8
Training loss: 2.452129364013672
Validation loss: 2.106300510385985

Epoch: 6| Step: 9
Training loss: 2.1605052947998047
Validation loss: 2.101377369255148

Epoch: 6| Step: 10
Training loss: 2.0972142219543457
Validation loss: 2.0873903395027242

Epoch: 6| Step: 11
Training loss: 2.3285186290740967
Validation loss: 2.092639469331311

Epoch: 6| Step: 12
Training loss: 2.3019895553588867
Validation loss: 2.1017278381573257

Epoch: 6| Step: 13
Training loss: 2.7286345958709717
Validation loss: 2.1099403212147374

Epoch: 63| Step: 0
Training loss: 2.378859758377075
Validation loss: 2.1300517038632463

Epoch: 6| Step: 1
Training loss: 2.6972274780273438
Validation loss: 2.1484772133570846

Epoch: 6| Step: 2
Training loss: 1.887376070022583
Validation loss: 2.1532240631759807

Epoch: 6| Step: 3
Training loss: 2.591761350631714
Validation loss: 2.1589517952293478

Epoch: 6| Step: 4
Training loss: 1.3351917266845703
Validation loss: 2.174526963182675

Epoch: 6| Step: 5
Training loss: 2.6186277866363525
Validation loss: 2.175781293581891

Epoch: 6| Step: 6
Training loss: 2.046252727508545
Validation loss: 2.1797106394203762

Epoch: 6| Step: 7
Training loss: 2.4561710357666016
Validation loss: 2.1723292079023135

Epoch: 6| Step: 8
Training loss: 2.499101161956787
Validation loss: 2.1573142441370154

Epoch: 6| Step: 9
Training loss: 2.544912815093994
Validation loss: 2.1261566877365112

Epoch: 6| Step: 10
Training loss: 2.9491469860076904
Validation loss: 2.1050918025355183

Epoch: 6| Step: 11
Training loss: 2.8661017417907715
Validation loss: 2.089282448573779

Epoch: 6| Step: 12
Training loss: 2.5367727279663086
Validation loss: 2.0727134878917406

Epoch: 6| Step: 13
Training loss: 2.608882188796997
Validation loss: 2.0821631031651653

Epoch: 64| Step: 0
Training loss: 2.246812343597412
Validation loss: 2.084990652658606

Epoch: 6| Step: 1
Training loss: 2.4113528728485107
Validation loss: 2.08715852614372

Epoch: 6| Step: 2
Training loss: 2.120988368988037
Validation loss: 2.082654727402554

Epoch: 6| Step: 3
Training loss: 2.6633992195129395
Validation loss: 2.093585770617249

Epoch: 6| Step: 4
Training loss: 2.02192759513855
Validation loss: 2.0870361379397813

Epoch: 6| Step: 5
Training loss: 2.4358272552490234
Validation loss: 2.0871541782092025

Epoch: 6| Step: 6
Training loss: 2.1839656829833984
Validation loss: 2.088068587805635

Epoch: 6| Step: 7
Training loss: 2.5865490436553955
Validation loss: 2.094265111031071

Epoch: 6| Step: 8
Training loss: 2.3080062866210938
Validation loss: 2.115891513004098

Epoch: 6| Step: 9
Training loss: 2.646313190460205
Validation loss: 2.126917228903822

Epoch: 6| Step: 10
Training loss: 3.1664938926696777
Validation loss: 2.138965704107797

Epoch: 6| Step: 11
Training loss: 2.4187521934509277
Validation loss: 2.1486086973579983

Epoch: 6| Step: 12
Training loss: 2.0297017097473145
Validation loss: 2.2011679116115777

Epoch: 6| Step: 13
Training loss: 2.4088544845581055
Validation loss: 2.2301803147920998

Epoch: 65| Step: 0
Training loss: 3.2342286109924316
Validation loss: 2.244520100214148

Epoch: 6| Step: 1
Training loss: 2.5740790367126465
Validation loss: 2.212007499510242

Epoch: 6| Step: 2
Training loss: 1.8544206619262695
Validation loss: 2.1627451271139164

Epoch: 6| Step: 3
Training loss: 2.287052631378174
Validation loss: 2.133062417789172

Epoch: 6| Step: 4
Training loss: 3.0133185386657715
Validation loss: 2.096914724637103

Epoch: 6| Step: 5
Training loss: 2.395540714263916
Validation loss: 2.0866086226637646

Epoch: 6| Step: 6
Training loss: 1.9706428050994873
Validation loss: 2.0761993495366906

Epoch: 6| Step: 7
Training loss: 2.8316245079040527
Validation loss: 2.077540247671066

Epoch: 6| Step: 8
Training loss: 2.349161148071289
Validation loss: 2.075854807771662

Epoch: 6| Step: 9
Training loss: 1.5056960582733154
Validation loss: 2.0796631689994567

Epoch: 6| Step: 10
Training loss: 2.5781149864196777
Validation loss: 2.0866466799089984

Epoch: 6| Step: 11
Training loss: 2.862363338470459
Validation loss: 2.0821918723403767

Epoch: 6| Step: 12
Training loss: 1.910215139389038
Validation loss: 2.0843277823540474

Epoch: 6| Step: 13
Training loss: 2.10866117477417
Validation loss: 2.0902647767015683

Epoch: 66| Step: 0
Training loss: 1.8754197359085083
Validation loss: 2.108488735332284

Epoch: 6| Step: 1
Training loss: 2.9236507415771484
Validation loss: 2.139615830554757

Epoch: 6| Step: 2
Training loss: 2.809299945831299
Validation loss: 2.1626680602309523

Epoch: 6| Step: 3
Training loss: 2.135084629058838
Validation loss: 2.218314209292012

Epoch: 6| Step: 4
Training loss: 2.410341501235962
Validation loss: 2.2788132339395504

Epoch: 6| Step: 5
Training loss: 2.700881004333496
Validation loss: 2.3144542376200357

Epoch: 6| Step: 6
Training loss: 2.5167226791381836
Validation loss: 2.319486956442556

Epoch: 6| Step: 7
Training loss: 2.382707357406616
Validation loss: 2.2934785735222603

Epoch: 6| Step: 8
Training loss: 2.568549633026123
Validation loss: 2.2709125113743607

Epoch: 6| Step: 9
Training loss: 2.0789859294891357
Validation loss: 2.2184101586700766

Epoch: 6| Step: 10
Training loss: 2.4186670780181885
Validation loss: 2.16704354106739

Epoch: 6| Step: 11
Training loss: 3.0245108604431152
Validation loss: 2.115612212047782

Epoch: 6| Step: 12
Training loss: 2.273061990737915
Validation loss: 2.0921745723293674

Epoch: 6| Step: 13
Training loss: 1.6818307638168335
Validation loss: 2.0773951879111667

Epoch: 67| Step: 0
Training loss: 2.333958148956299
Validation loss: 2.071122832195733

Epoch: 6| Step: 1
Training loss: 1.9203078746795654
Validation loss: 2.0627121527989707

Epoch: 6| Step: 2
Training loss: 2.232668876647949
Validation loss: 2.0589514240141837

Epoch: 6| Step: 3
Training loss: 2.7810397148132324
Validation loss: 2.0591488166521956

Epoch: 6| Step: 4
Training loss: 3.2541165351867676
Validation loss: 2.0560826165701753

Epoch: 6| Step: 5
Training loss: 2.7931249141693115
Validation loss: 2.0642683634193997

Epoch: 6| Step: 6
Training loss: 2.125150680541992
Validation loss: 2.0665298841332875

Epoch: 6| Step: 7
Training loss: 2.233407974243164
Validation loss: 2.0681341078973587

Epoch: 6| Step: 8
Training loss: 2.171811580657959
Validation loss: 2.06987787062122

Epoch: 6| Step: 9
Training loss: 2.2804839611053467
Validation loss: 2.0659725153318016

Epoch: 6| Step: 10
Training loss: 2.4565930366516113
Validation loss: 2.069780103621944

Epoch: 6| Step: 11
Training loss: 2.976184368133545
Validation loss: 2.0697166406980125

Epoch: 6| Step: 12
Training loss: 1.7430591583251953
Validation loss: 2.0718804713218444

Epoch: 6| Step: 13
Training loss: 2.0462770462036133
Validation loss: 2.063806412040546

Epoch: 68| Step: 0
Training loss: 3.063288450241089
Validation loss: 2.066952690001457

Epoch: 6| Step: 1
Training loss: 2.3764443397521973
Validation loss: 2.069207945177632

Epoch: 6| Step: 2
Training loss: 2.0752859115600586
Validation loss: 2.068015408772294

Epoch: 6| Step: 3
Training loss: 2.0991010665893555
Validation loss: 2.0722246144407537

Epoch: 6| Step: 4
Training loss: 2.0651426315307617
Validation loss: 2.0737536132976575

Epoch: 6| Step: 5
Training loss: 1.989736795425415
Validation loss: 2.078496084418348

Epoch: 6| Step: 6
Training loss: 2.2452921867370605
Validation loss: 2.079142458977238

Epoch: 6| Step: 7
Training loss: 3.0910143852233887
Validation loss: 2.084278727090487

Epoch: 6| Step: 8
Training loss: 2.2882838249206543
Validation loss: 2.075820892087875

Epoch: 6| Step: 9
Training loss: 1.9899426698684692
Validation loss: 2.0766338968789704

Epoch: 6| Step: 10
Training loss: 2.4267172813415527
Validation loss: 2.075977575394415

Epoch: 6| Step: 11
Training loss: 3.1218762397766113
Validation loss: 2.078288168035528

Epoch: 6| Step: 12
Training loss: 2.104708671569824
Validation loss: 2.076396506319764

Epoch: 6| Step: 13
Training loss: 2.189183235168457
Validation loss: 2.084508862546695

Epoch: 69| Step: 0
Training loss: 1.9482159614562988
Validation loss: 2.0822060031275593

Epoch: 6| Step: 1
Training loss: 2.711489677429199
Validation loss: 2.086561305548555

Epoch: 6| Step: 2
Training loss: 2.916266918182373
Validation loss: 2.0851437430227957

Epoch: 6| Step: 3
Training loss: 2.324188709259033
Validation loss: 2.0938435472467893

Epoch: 6| Step: 4
Training loss: 2.5381007194519043
Validation loss: 2.1103275591327297

Epoch: 6| Step: 5
Training loss: 2.2609102725982666
Validation loss: 2.120286933837398

Epoch: 6| Step: 6
Training loss: 2.9815902709960938
Validation loss: 2.1062802947977537

Epoch: 6| Step: 7
Training loss: 2.5916571617126465
Validation loss: 2.097858641737251

Epoch: 6| Step: 8
Training loss: 1.8115737438201904
Validation loss: 2.081920576351945

Epoch: 6| Step: 9
Training loss: 2.1072278022766113
Validation loss: 2.06791486150475

Epoch: 6| Step: 10
Training loss: 2.4217782020568848
Validation loss: 2.060800311385944

Epoch: 6| Step: 11
Training loss: 2.07059645652771
Validation loss: 2.0600440361166514

Epoch: 6| Step: 12
Training loss: 2.1763110160827637
Validation loss: 2.056518699533196

Epoch: 6| Step: 13
Training loss: 2.3043107986450195
Validation loss: 2.052006677914691

Epoch: 70| Step: 0
Training loss: 1.9925086498260498
Validation loss: 2.0461706089717087

Epoch: 6| Step: 1
Training loss: 1.7901774644851685
Validation loss: 2.048923874414095

Epoch: 6| Step: 2
Training loss: 2.597355365753174
Validation loss: 2.0489036793349893

Epoch: 6| Step: 3
Training loss: 2.5004448890686035
Validation loss: 2.052258465879707

Epoch: 6| Step: 4
Training loss: 2.50846529006958
Validation loss: 2.059074545419344

Epoch: 6| Step: 5
Training loss: 2.5709686279296875
Validation loss: 2.057634065228124

Epoch: 6| Step: 6
Training loss: 2.577505350112915
Validation loss: 2.048393428966563

Epoch: 6| Step: 7
Training loss: 2.036811351776123
Validation loss: 2.0423578523820445

Epoch: 6| Step: 8
Training loss: 2.240036964416504
Validation loss: 2.045492023550054

Epoch: 6| Step: 9
Training loss: 1.9608516693115234
Validation loss: 2.0414571095538396

Epoch: 6| Step: 10
Training loss: 2.5138344764709473
Validation loss: 2.0433543753880326

Epoch: 6| Step: 11
Training loss: 2.6917896270751953
Validation loss: 2.048550413500878

Epoch: 6| Step: 12
Training loss: 2.380849838256836
Validation loss: 2.042949782904758

Epoch: 6| Step: 13
Training loss: 2.8090476989746094
Validation loss: 2.0426015212971675

Epoch: 71| Step: 0
Training loss: 2.366605758666992
Validation loss: 2.047406881086288

Epoch: 6| Step: 1
Training loss: 2.6494312286376953
Validation loss: 2.0762740860703173

Epoch: 6| Step: 2
Training loss: 2.576930046081543
Validation loss: 2.0881268157753894

Epoch: 6| Step: 3
Training loss: 2.0314035415649414
Validation loss: 2.085492209721637

Epoch: 6| Step: 4
Training loss: 2.5012047290802
Validation loss: 2.0613713161919707

Epoch: 6| Step: 5
Training loss: 1.438416838645935
Validation loss: 2.05114387055879

Epoch: 6| Step: 6
Training loss: 2.196214199066162
Validation loss: 2.040272387125159

Epoch: 6| Step: 7
Training loss: 2.2240800857543945
Validation loss: 2.036479932005687

Epoch: 6| Step: 8
Training loss: 2.4196548461914062
Validation loss: 2.0440462917409916

Epoch: 6| Step: 9
Training loss: 1.9438172578811646
Validation loss: 2.0416032960337978

Epoch: 6| Step: 10
Training loss: 2.8289856910705566
Validation loss: 2.0361497773919055

Epoch: 6| Step: 11
Training loss: 1.9629688262939453
Validation loss: 2.029003168946953

Epoch: 6| Step: 12
Training loss: 3.103775978088379
Validation loss: 2.0329363666554934

Epoch: 6| Step: 13
Training loss: 2.965320110321045
Validation loss: 2.0398871873014714

Epoch: 72| Step: 0
Training loss: 1.75174081325531
Validation loss: 2.0355039745248775

Epoch: 6| Step: 1
Training loss: 1.7155542373657227
Validation loss: 2.033947585731424

Epoch: 6| Step: 2
Training loss: 2.5662174224853516
Validation loss: 2.035786956869146

Epoch: 6| Step: 3
Training loss: 1.7489802837371826
Validation loss: 2.0405226702331216

Epoch: 6| Step: 4
Training loss: 2.5604004859924316
Validation loss: 2.0598686818153626

Epoch: 6| Step: 5
Training loss: 2.382941722869873
Validation loss: 2.071838076396655

Epoch: 6| Step: 6
Training loss: 2.8071718215942383
Validation loss: 2.100527499311714

Epoch: 6| Step: 7
Training loss: 2.175767660140991
Validation loss: 2.137641670883343

Epoch: 6| Step: 8
Training loss: 2.8572964668273926
Validation loss: 2.1602973104805074

Epoch: 6| Step: 9
Training loss: 2.397865056991577
Validation loss: 2.154816278847315

Epoch: 6| Step: 10
Training loss: 2.2573068141937256
Validation loss: 2.128342543878863

Epoch: 6| Step: 11
Training loss: 2.5967507362365723
Validation loss: 2.10355043923983

Epoch: 6| Step: 12
Training loss: 2.959076404571533
Validation loss: 2.0691991929085023

Epoch: 6| Step: 13
Training loss: 2.3616960048675537
Validation loss: 2.0539298595920688

Epoch: 73| Step: 0
Training loss: 2.1505684852600098
Validation loss: 2.040695071220398

Epoch: 6| Step: 1
Training loss: 2.1040964126586914
Validation loss: 2.0422629156420307

Epoch: 6| Step: 2
Training loss: 2.2854244709014893
Validation loss: 2.041318997260063

Epoch: 6| Step: 3
Training loss: 2.652489423751831
Validation loss: 2.0394664913095455

Epoch: 6| Step: 4
Training loss: 2.6643285751342773
Validation loss: 2.0299394938253585

Epoch: 6| Step: 5
Training loss: 2.4639852046966553
Validation loss: 2.0287634224020024

Epoch: 6| Step: 6
Training loss: 1.9079337120056152
Validation loss: 2.0212596693346576

Epoch: 6| Step: 7
Training loss: 1.6510204076766968
Validation loss: 2.0366258467397382

Epoch: 6| Step: 8
Training loss: 2.3234825134277344
Validation loss: 2.0662862588000555

Epoch: 6| Step: 9
Training loss: 2.027254581451416
Validation loss: 2.091195103942707

Epoch: 6| Step: 10
Training loss: 2.3756251335144043
Validation loss: 2.1028471967225433

Epoch: 6| Step: 11
Training loss: 2.9642298221588135
Validation loss: 2.1073622742006854

Epoch: 6| Step: 12
Training loss: 2.74042010307312
Validation loss: 2.0967114740802395

Epoch: 6| Step: 13
Training loss: 2.781453847885132
Validation loss: 2.103926558648386

Epoch: 74| Step: 0
Training loss: 2.4402012825012207
Validation loss: 2.0888603310431204

Epoch: 6| Step: 1
Training loss: 2.4683523178100586
Validation loss: 2.0639303397106867

Epoch: 6| Step: 2
Training loss: 2.7173547744750977
Validation loss: 2.0426414166727374

Epoch: 6| Step: 3
Training loss: 2.4975321292877197
Validation loss: 2.0375392488254014

Epoch: 6| Step: 4
Training loss: 2.269089698791504
Validation loss: 2.033195444332656

Epoch: 6| Step: 5
Training loss: 1.8140588998794556
Validation loss: 2.0283634867719424

Epoch: 6| Step: 6
Training loss: 2.6030783653259277
Validation loss: 2.02188426961181

Epoch: 6| Step: 7
Training loss: 2.192826747894287
Validation loss: 2.0258610504929737

Epoch: 6| Step: 8
Training loss: 1.9521428346633911
Validation loss: 2.0333415974852858

Epoch: 6| Step: 9
Training loss: 2.3551998138427734
Validation loss: 2.0238324314035396

Epoch: 6| Step: 10
Training loss: 2.037170171737671
Validation loss: 2.0301293596144645

Epoch: 6| Step: 11
Training loss: 2.355586051940918
Validation loss: 2.0278556731439408

Epoch: 6| Step: 12
Training loss: 2.3772623538970947
Validation loss: 2.039919243063978

Epoch: 6| Step: 13
Training loss: 3.006527900695801
Validation loss: 2.0632522952172065

Epoch: 75| Step: 0
Training loss: 2.5712008476257324
Validation loss: 2.0902035313267864

Epoch: 6| Step: 1
Training loss: 1.8364567756652832
Validation loss: 2.109288243837254

Epoch: 6| Step: 2
Training loss: 2.3333358764648438
Validation loss: 2.131845271715554

Epoch: 6| Step: 3
Training loss: 2.5851616859436035
Validation loss: 2.130075000947522

Epoch: 6| Step: 4
Training loss: 2.550638198852539
Validation loss: 2.104399593927527

Epoch: 6| Step: 5
Training loss: 1.8090367317199707
Validation loss: 2.0800709032243296

Epoch: 6| Step: 6
Training loss: 2.0943686962127686
Validation loss: 2.070601091589979

Epoch: 6| Step: 7
Training loss: 2.9761855602264404
Validation loss: 2.0645326747689197

Epoch: 6| Step: 8
Training loss: 2.2168643474578857
Validation loss: 2.0594245285116215

Epoch: 6| Step: 9
Training loss: 2.075774669647217
Validation loss: 2.045630902372381

Epoch: 6| Step: 10
Training loss: 2.4096357822418213
Validation loss: 2.036095501274191

Epoch: 6| Step: 11
Training loss: 2.4208741188049316
Validation loss: 2.0233567325017785

Epoch: 6| Step: 12
Training loss: 2.4991068840026855
Validation loss: 2.0253964329278595

Epoch: 6| Step: 13
Training loss: 2.3464038372039795
Validation loss: 2.0217183072079896

Epoch: 76| Step: 0
Training loss: 2.237104892730713
Validation loss: 2.0279121809108283

Epoch: 6| Step: 1
Training loss: 2.7723898887634277
Validation loss: 2.0193411022104244

Epoch: 6| Step: 2
Training loss: 2.284727096557617
Validation loss: 2.0327141079851376

Epoch: 6| Step: 3
Training loss: 2.4283344745635986
Validation loss: 2.041601604030978

Epoch: 6| Step: 4
Training loss: 2.2425551414489746
Validation loss: 2.03686454731931

Epoch: 6| Step: 5
Training loss: 2.3500235080718994
Validation loss: 2.036344207743163

Epoch: 6| Step: 6
Training loss: 2.678687334060669
Validation loss: 2.0519314363438594

Epoch: 6| Step: 7
Training loss: 2.6414794921875
Validation loss: 2.0528824995922785

Epoch: 6| Step: 8
Training loss: 2.219940662384033
Validation loss: 2.0690351865624868

Epoch: 6| Step: 9
Training loss: 1.6038774251937866
Validation loss: 2.095447023709615

Epoch: 6| Step: 10
Training loss: 2.824824333190918
Validation loss: 2.096059391575475

Epoch: 6| Step: 11
Training loss: 1.6954963207244873
Validation loss: 2.0960161121942664

Epoch: 6| Step: 12
Training loss: 2.067631483078003
Validation loss: 2.087803389436455

Epoch: 6| Step: 13
Training loss: 2.578789234161377
Validation loss: 2.0793844064076743

Epoch: 77| Step: 0
Training loss: 2.644124746322632
Validation loss: 2.072720294357628

Epoch: 6| Step: 1
Training loss: 2.9937801361083984
Validation loss: 2.064731519709351

Epoch: 6| Step: 2
Training loss: 2.3056535720825195
Validation loss: 2.056207033895677

Epoch: 6| Step: 3
Training loss: 1.8645600080490112
Validation loss: 2.035821271199052

Epoch: 6| Step: 4
Training loss: 3.062507390975952
Validation loss: 2.027325343060237

Epoch: 6| Step: 5
Training loss: 2.0915169715881348
Validation loss: 2.0353878403222687

Epoch: 6| Step: 6
Training loss: 2.4453587532043457
Validation loss: 2.0389271346471642

Epoch: 6| Step: 7
Training loss: 2.6886773109436035
Validation loss: 2.0428868506544378

Epoch: 6| Step: 8
Training loss: 1.66145658493042
Validation loss: 2.0489729091685307

Epoch: 6| Step: 9
Training loss: 2.1086032390594482
Validation loss: 2.058758649774777

Epoch: 6| Step: 10
Training loss: 2.6105587482452393
Validation loss: 2.057324610730653

Epoch: 6| Step: 11
Training loss: 1.5897419452667236
Validation loss: 2.0558033835503364

Epoch: 6| Step: 12
Training loss: 2.4447741508483887
Validation loss: 2.0652270304259432

Epoch: 6| Step: 13
Training loss: 1.6619367599487305
Validation loss: 2.0587508832254717

Epoch: 78| Step: 0
Training loss: 2.9472808837890625
Validation loss: 2.0461814659898

Epoch: 6| Step: 1
Training loss: 2.1116857528686523
Validation loss: 2.04462202518217

Epoch: 6| Step: 2
Training loss: 2.617145538330078
Validation loss: 2.0318556908638246

Epoch: 6| Step: 3
Training loss: 2.077881336212158
Validation loss: 2.029535598652337

Epoch: 6| Step: 4
Training loss: 2.4524378776550293
Validation loss: 2.0161857143525155

Epoch: 6| Step: 5
Training loss: 2.113847255706787
Validation loss: 2.023495848460864

Epoch: 6| Step: 6
Training loss: 2.508582592010498
Validation loss: 2.024224619711599

Epoch: 6| Step: 7
Training loss: 2.4271974563598633
Validation loss: 2.028201941520937

Epoch: 6| Step: 8
Training loss: 1.5444375276565552
Validation loss: 2.0231460576416342

Epoch: 6| Step: 9
Training loss: 2.2510504722595215
Validation loss: 2.0172327923518356

Epoch: 6| Step: 10
Training loss: 2.5493197441101074
Validation loss: 2.020563917775308

Epoch: 6| Step: 11
Training loss: 2.351980209350586
Validation loss: 2.025137782096863

Epoch: 6| Step: 12
Training loss: 2.256709575653076
Validation loss: 2.0224573894213607

Epoch: 6| Step: 13
Training loss: 1.8649622201919556
Validation loss: 2.0237096304534585

Epoch: 79| Step: 0
Training loss: 2.2310614585876465
Validation loss: 2.019895750989196

Epoch: 6| Step: 1
Training loss: 1.9699840545654297
Validation loss: 2.0145093497409614

Epoch: 6| Step: 2
Training loss: 2.3738393783569336
Validation loss: 2.0167438701916764

Epoch: 6| Step: 3
Training loss: 2.0789637565612793
Validation loss: 2.021603251016268

Epoch: 6| Step: 4
Training loss: 2.1718077659606934
Validation loss: 2.0164273746552004

Epoch: 6| Step: 5
Training loss: 2.3875844478607178
Validation loss: 2.0241877212319324

Epoch: 6| Step: 6
Training loss: 2.578644275665283
Validation loss: 2.0290105406956007

Epoch: 6| Step: 7
Training loss: 2.4123291969299316
Validation loss: 2.022440520665979

Epoch: 6| Step: 8
Training loss: 2.6189942359924316
Validation loss: 2.0102560007443993

Epoch: 6| Step: 9
Training loss: 1.572299599647522
Validation loss: 2.0011136942012335

Epoch: 6| Step: 10
Training loss: 2.7871408462524414
Validation loss: 2.0056846859634563

Epoch: 6| Step: 11
Training loss: 2.0570690631866455
Validation loss: 2.004810008951413

Epoch: 6| Step: 12
Training loss: 2.5634875297546387
Validation loss: 2.005008948746548

Epoch: 6| Step: 13
Training loss: 2.6138229370117188
Validation loss: 2.0133933380085933

Epoch: 80| Step: 0
Training loss: 2.400434732437134
Validation loss: 2.018660887595146

Epoch: 6| Step: 1
Training loss: 2.7764296531677246
Validation loss: 2.029982605288106

Epoch: 6| Step: 2
Training loss: 2.4522290229797363
Validation loss: 2.0351869162692817

Epoch: 6| Step: 3
Training loss: 3.0810952186584473
Validation loss: 2.0774301021329817

Epoch: 6| Step: 4
Training loss: 1.9254586696624756
Validation loss: 2.106960114612374

Epoch: 6| Step: 5
Training loss: 2.338653326034546
Validation loss: 2.097022118106965

Epoch: 6| Step: 6
Training loss: 2.2689619064331055
Validation loss: 2.101813949564452

Epoch: 6| Step: 7
Training loss: 2.693675994873047
Validation loss: 2.0992028585044284

Epoch: 6| Step: 8
Training loss: 1.7069334983825684
Validation loss: 2.0870659799985987

Epoch: 6| Step: 9
Training loss: 2.658273696899414
Validation loss: 2.0611773126868793

Epoch: 6| Step: 10
Training loss: 2.039111614227295
Validation loss: 2.043916766361524

Epoch: 6| Step: 11
Training loss: 1.7633495330810547
Validation loss: 2.0332259362743748

Epoch: 6| Step: 12
Training loss: 1.7857341766357422
Validation loss: 2.0301521516615346

Epoch: 6| Step: 13
Training loss: 2.9716796875
Validation loss: 2.028848304543444

Epoch: 81| Step: 0
Training loss: 2.076808452606201
Validation loss: 2.0374909216357815

Epoch: 6| Step: 1
Training loss: 2.8243460655212402
Validation loss: 2.0328755378723145

Epoch: 6| Step: 2
Training loss: 2.216601848602295
Validation loss: 2.0342723707998953

Epoch: 6| Step: 3
Training loss: 2.5454084873199463
Validation loss: 2.0311841785266833

Epoch: 6| Step: 4
Training loss: 2.243638515472412
Validation loss: 2.0359503505050496

Epoch: 6| Step: 5
Training loss: 2.7421889305114746
Validation loss: 2.0231002966562905

Epoch: 6| Step: 6
Training loss: 1.694102168083191
Validation loss: 2.0183493501396588

Epoch: 6| Step: 7
Training loss: 2.1303768157958984
Validation loss: 2.0053837235255907

Epoch: 6| Step: 8
Training loss: 3.3785781860351562
Validation loss: 2.011489006780809

Epoch: 6| Step: 9
Training loss: 2.4496822357177734
Validation loss: 2.036304135476389

Epoch: 6| Step: 10
Training loss: 1.9216375350952148
Validation loss: 2.05362158308747

Epoch: 6| Step: 11
Training loss: 1.8243346214294434
Validation loss: 2.051312420957832

Epoch: 6| Step: 12
Training loss: 2.3706953525543213
Validation loss: 2.0590581073555896

Epoch: 6| Step: 13
Training loss: 2.0556061267852783
Validation loss: 2.0681207026204755

Epoch: 82| Step: 0
Training loss: 2.1522696018218994
Validation loss: 2.072537596507739

Epoch: 6| Step: 1
Training loss: 2.5546770095825195
Validation loss: 2.0670415739859305

Epoch: 6| Step: 2
Training loss: 2.1261472702026367
Validation loss: 2.0581701071031633

Epoch: 6| Step: 3
Training loss: 2.390733242034912
Validation loss: 2.0505058688502156

Epoch: 6| Step: 4
Training loss: 1.8650627136230469
Validation loss: 2.016947089984853

Epoch: 6| Step: 5
Training loss: 2.177469491958618
Validation loss: 2.0078558306540213

Epoch: 6| Step: 6
Training loss: 2.3682472705841064
Validation loss: 1.9999182762638215

Epoch: 6| Step: 7
Training loss: 2.771838426589966
Validation loss: 1.9971470986643145

Epoch: 6| Step: 8
Training loss: 1.9444599151611328
Validation loss: 1.9919752472190446

Epoch: 6| Step: 9
Training loss: 2.8267323970794678
Validation loss: 1.9896620576099684

Epoch: 6| Step: 10
Training loss: 2.019007682800293
Validation loss: 1.9895091723370295

Epoch: 6| Step: 11
Training loss: 2.389866828918457
Validation loss: 1.9946710332747428

Epoch: 6| Step: 12
Training loss: 2.127399206161499
Validation loss: 1.9923866051499561

Epoch: 6| Step: 13
Training loss: 2.2913899421691895
Validation loss: 1.988750675673126

Epoch: 83| Step: 0
Training loss: 2.819551944732666
Validation loss: 1.9864280185391825

Epoch: 6| Step: 1
Training loss: 2.055421829223633
Validation loss: 1.9821644316437423

Epoch: 6| Step: 2
Training loss: 1.629257082939148
Validation loss: 1.9877338614515079

Epoch: 6| Step: 3
Training loss: 1.6660257577896118
Validation loss: 1.9975702211421023

Epoch: 6| Step: 4
Training loss: 2.6991257667541504
Validation loss: 2.0100512568668654

Epoch: 6| Step: 5
Training loss: 3.112819194793701
Validation loss: 2.022420734487554

Epoch: 6| Step: 6
Training loss: 2.3159823417663574
Validation loss: 2.022262893697267

Epoch: 6| Step: 7
Training loss: 2.348693370819092
Validation loss: 2.0227389861178655

Epoch: 6| Step: 8
Training loss: 2.6217164993286133
Validation loss: 2.0091024650040494

Epoch: 6| Step: 9
Training loss: 1.9513533115386963
Validation loss: 2.008422105543075

Epoch: 6| Step: 10
Training loss: 2.519361972808838
Validation loss: 1.9920319741772068

Epoch: 6| Step: 11
Training loss: 1.8921254873275757
Validation loss: 1.9904905288450179

Epoch: 6| Step: 12
Training loss: 2.0110902786254883
Validation loss: 1.9918826164737824

Epoch: 6| Step: 13
Training loss: 2.4253249168395996
Validation loss: 1.9870837221863449

Epoch: 84| Step: 0
Training loss: 2.485543966293335
Validation loss: 1.9784640266049294

Epoch: 6| Step: 1
Training loss: 2.686433792114258
Validation loss: 1.9771364824746245

Epoch: 6| Step: 2
Training loss: 2.87040376663208
Validation loss: 1.9787711097348122

Epoch: 6| Step: 3
Training loss: 2.3616018295288086
Validation loss: 1.9769294364477998

Epoch: 6| Step: 4
Training loss: 2.0129551887512207
Validation loss: 1.9823718763166858

Epoch: 6| Step: 5
Training loss: 2.1183228492736816
Validation loss: 1.9836364612784436

Epoch: 6| Step: 6
Training loss: 2.178607940673828
Validation loss: 1.9874441623687744

Epoch: 6| Step: 7
Training loss: 2.273376941680908
Validation loss: 1.98944059495003

Epoch: 6| Step: 8
Training loss: 2.0220041275024414
Validation loss: 2.0032237101626653

Epoch: 6| Step: 9
Training loss: 2.2233693599700928
Validation loss: 2.0110509369962957

Epoch: 6| Step: 10
Training loss: 2.6942954063415527
Validation loss: 2.027763194935296

Epoch: 6| Step: 11
Training loss: 1.9299910068511963
Validation loss: 2.058993471566067

Epoch: 6| Step: 12
Training loss: 1.6173689365386963
Validation loss: 2.0767794732124574

Epoch: 6| Step: 13
Training loss: 2.7008683681488037
Validation loss: 2.062525792788434

Epoch: 85| Step: 0
Training loss: 2.488633632659912
Validation loss: 2.0332710358404342

Epoch: 6| Step: 1
Training loss: 2.67746901512146
Validation loss: 2.010455414813052

Epoch: 6| Step: 2
Training loss: 3.3666224479675293
Validation loss: 2.0083536935108963

Epoch: 6| Step: 3
Training loss: 1.9678452014923096
Validation loss: 2.0055551977567774

Epoch: 6| Step: 4
Training loss: 2.8414878845214844
Validation loss: 1.980849668543826

Epoch: 6| Step: 5
Training loss: 2.4444026947021484
Validation loss: 1.9791607574750019

Epoch: 6| Step: 6
Training loss: 1.1928868293762207
Validation loss: 1.9750359160925752

Epoch: 6| Step: 7
Training loss: 2.173740863800049
Validation loss: 1.9781193720397128

Epoch: 6| Step: 8
Training loss: 2.236389398574829
Validation loss: 1.988910444321171

Epoch: 6| Step: 9
Training loss: 2.1214613914489746
Validation loss: 1.9886284310330626

Epoch: 6| Step: 10
Training loss: 2.7070844173431396
Validation loss: 1.9981131528013496

Epoch: 6| Step: 11
Training loss: 1.690403938293457
Validation loss: 1.9915934993374733

Epoch: 6| Step: 12
Training loss: 1.6517311334609985
Validation loss: 1.9977781362431024

Epoch: 6| Step: 13
Training loss: 1.9363373517990112
Validation loss: 2.010002164430516

Epoch: 86| Step: 0
Training loss: 3.0508229732513428
Validation loss: 2.0077668210511566

Epoch: 6| Step: 1
Training loss: 2.4915645122528076
Validation loss: 2.006313234247187

Epoch: 6| Step: 2
Training loss: 1.6124564409255981
Validation loss: 2.0049614778129

Epoch: 6| Step: 3
Training loss: 2.6802401542663574
Validation loss: 1.9963203527594124

Epoch: 6| Step: 4
Training loss: 1.6663758754730225
Validation loss: 1.9941728179172804

Epoch: 6| Step: 5
Training loss: 2.684784412384033
Validation loss: 1.9969764063435216

Epoch: 6| Step: 6
Training loss: 2.566659450531006
Validation loss: 2.0020357754922684

Epoch: 6| Step: 7
Training loss: 2.1698412895202637
Validation loss: 2.0031919069187616

Epoch: 6| Step: 8
Training loss: 2.168595790863037
Validation loss: 2.0127758172250565

Epoch: 6| Step: 9
Training loss: 2.8842861652374268
Validation loss: 2.0168124514241375

Epoch: 6| Step: 10
Training loss: 1.9388657808303833
Validation loss: 2.0264206406890706

Epoch: 6| Step: 11
Training loss: 1.6939254999160767
Validation loss: 2.0160202774950253

Epoch: 6| Step: 12
Training loss: 2.3654367923736572
Validation loss: 2.011134566799287

Epoch: 6| Step: 13
Training loss: 1.3679563999176025
Validation loss: 2.0040982166926065

Epoch: 87| Step: 0
Training loss: 2.40024471282959
Validation loss: 2.0009462653949694

Epoch: 6| Step: 1
Training loss: 1.7336766719818115
Validation loss: 1.9897870863637617

Epoch: 6| Step: 2
Training loss: 2.4391136169433594
Validation loss: 2.0005777817900463

Epoch: 6| Step: 3
Training loss: 2.325897693634033
Validation loss: 1.9935384847784554

Epoch: 6| Step: 4
Training loss: 2.1346282958984375
Validation loss: 1.9981366024222424

Epoch: 6| Step: 5
Training loss: 2.103322744369507
Validation loss: 1.9832673880361742

Epoch: 6| Step: 6
Training loss: 2.3960275650024414
Validation loss: 1.9841733645367365

Epoch: 6| Step: 7
Training loss: 2.6649227142333984
Validation loss: 1.9804640072648243

Epoch: 6| Step: 8
Training loss: 2.2283332347869873
Validation loss: 1.987113054080676

Epoch: 6| Step: 9
Training loss: 2.465589761734009
Validation loss: 1.977983458067781

Epoch: 6| Step: 10
Training loss: 1.8285435438156128
Validation loss: 1.9860393372915124

Epoch: 6| Step: 11
Training loss: 2.387545347213745
Validation loss: 1.9924471506508448

Epoch: 6| Step: 12
Training loss: 2.1937193870544434
Validation loss: 2.033665680116223

Epoch: 6| Step: 13
Training loss: 2.4912548065185547
Validation loss: 2.0451499608255204

Epoch: 88| Step: 0
Training loss: 1.9216269254684448
Validation loss: 2.0852680872845393

Epoch: 6| Step: 1
Training loss: 2.348330020904541
Validation loss: 2.122916397228036

Epoch: 6| Step: 2
Training loss: 2.7053921222686768
Validation loss: 2.1427425543467202

Epoch: 6| Step: 3
Training loss: 2.697070837020874
Validation loss: 2.0774659136290192

Epoch: 6| Step: 4
Training loss: 2.7682838439941406
Validation loss: 2.057037700888931

Epoch: 6| Step: 5
Training loss: 2.066679000854492
Validation loss: 2.0326390381782287

Epoch: 6| Step: 6
Training loss: 2.258474111557007
Validation loss: 1.9998263748743201

Epoch: 6| Step: 7
Training loss: 2.2778334617614746
Validation loss: 1.976342708833756

Epoch: 6| Step: 8
Training loss: 2.416027545928955
Validation loss: 1.961047895493046

Epoch: 6| Step: 9
Training loss: 1.6918492317199707
Validation loss: 1.963050284693318

Epoch: 6| Step: 10
Training loss: 2.122955799102783
Validation loss: 1.964157747965987

Epoch: 6| Step: 11
Training loss: 2.1428005695343018
Validation loss: 1.968062077799151

Epoch: 6| Step: 12
Training loss: 1.839829921722412
Validation loss: 1.9732548331701627

Epoch: 6| Step: 13
Training loss: 3.0499560832977295
Validation loss: 1.988937436893422

Epoch: 89| Step: 0
Training loss: 2.207590103149414
Validation loss: 2.0175108960879746

Epoch: 6| Step: 1
Training loss: 2.525867462158203
Validation loss: 2.0382745265960693

Epoch: 6| Step: 2
Training loss: 3.072542667388916
Validation loss: 2.057913677666777

Epoch: 6| Step: 3
Training loss: 1.7147736549377441
Validation loss: 2.0672760932676253

Epoch: 6| Step: 4
Training loss: 2.58134126663208
Validation loss: 2.042950343060237

Epoch: 6| Step: 5
Training loss: 2.081596851348877
Validation loss: 2.037259296704364

Epoch: 6| Step: 6
Training loss: 1.8153715133666992
Validation loss: 2.0118632906226703

Epoch: 6| Step: 7
Training loss: 1.5164068937301636
Validation loss: 2.0128368741722515

Epoch: 6| Step: 8
Training loss: 2.9218668937683105
Validation loss: 1.9917207020585255

Epoch: 6| Step: 9
Training loss: 2.342134475708008
Validation loss: 1.9910064538319905

Epoch: 6| Step: 10
Training loss: 2.380300998687744
Validation loss: 1.997555257171713

Epoch: 6| Step: 11
Training loss: 1.6699373722076416
Validation loss: 2.003730832889516

Epoch: 6| Step: 12
Training loss: 2.6823177337646484
Validation loss: 1.9997220552095802

Epoch: 6| Step: 13
Training loss: 2.1581790447235107
Validation loss: 2.0007425251827446

Epoch: 90| Step: 0
Training loss: 1.8667564392089844
Validation loss: 2.0122746805990896

Epoch: 6| Step: 1
Training loss: 1.8591169118881226
Validation loss: 2.0240351512867916

Epoch: 6| Step: 2
Training loss: 2.1426515579223633
Validation loss: 2.05259039837827

Epoch: 6| Step: 3
Training loss: 2.298865795135498
Validation loss: 2.0677380638737834

Epoch: 6| Step: 4
Training loss: 2.006533145904541
Validation loss: 2.0721242145825456

Epoch: 6| Step: 5
Training loss: 2.198080539703369
Validation loss: 2.0537771012193415

Epoch: 6| Step: 6
Training loss: 2.368359327316284
Validation loss: 2.0582338225456978

Epoch: 6| Step: 7
Training loss: 2.520664691925049
Validation loss: 2.046708640231881

Epoch: 6| Step: 8
Training loss: 2.952909469604492
Validation loss: 2.0358244513952606

Epoch: 6| Step: 9
Training loss: 2.423748731613159
Validation loss: 2.0173569994588054

Epoch: 6| Step: 10
Training loss: 2.3262977600097656
Validation loss: 2.003510573858856

Epoch: 6| Step: 11
Training loss: 2.625518560409546
Validation loss: 1.9974019706890147

Epoch: 6| Step: 12
Training loss: 1.8751709461212158
Validation loss: 1.9836556873013895

Epoch: 6| Step: 13
Training loss: 1.7449641227722168
Validation loss: 1.9823898987103534

Epoch: 91| Step: 0
Training loss: 1.6685762405395508
Validation loss: 1.9757270377169374

Epoch: 6| Step: 1
Training loss: 1.8586148023605347
Validation loss: 1.979152858898204

Epoch: 6| Step: 2
Training loss: 1.686477541923523
Validation loss: 1.9729194282203593

Epoch: 6| Step: 3
Training loss: 2.3495969772338867
Validation loss: 1.9678895934935539

Epoch: 6| Step: 4
Training loss: 2.7424306869506836
Validation loss: 1.9683256636383712

Epoch: 6| Step: 5
Training loss: 2.2029504776000977
Validation loss: 1.9732118524530882

Epoch: 6| Step: 6
Training loss: 3.101745128631592
Validation loss: 1.9654755476982362

Epoch: 6| Step: 7
Training loss: 2.524421215057373
Validation loss: 1.965282097939522

Epoch: 6| Step: 8
Training loss: 2.7841639518737793
Validation loss: 1.9673114271574124

Epoch: 6| Step: 9
Training loss: 2.446597099304199
Validation loss: 1.9653550783793132

Epoch: 6| Step: 10
Training loss: 1.8556463718414307
Validation loss: 1.9833604110184537

Epoch: 6| Step: 11
Training loss: 2.4970788955688477
Validation loss: 1.9978161165791173

Epoch: 6| Step: 12
Training loss: 2.231243371963501
Validation loss: 2.025864557553363

Epoch: 6| Step: 13
Training loss: 1.0315824747085571
Validation loss: 2.069926984848515

Epoch: 92| Step: 0
Training loss: 2.207460880279541
Validation loss: 2.092133747634067

Epoch: 6| Step: 1
Training loss: 2.194715976715088
Validation loss: 2.08035651458207

Epoch: 6| Step: 2
Training loss: 1.7234950065612793
Validation loss: 2.03944061135733

Epoch: 6| Step: 3
Training loss: 1.7542788982391357
Validation loss: 2.0154878888078915

Epoch: 6| Step: 4
Training loss: 2.5919203758239746
Validation loss: 2.0128859396903747

Epoch: 6| Step: 5
Training loss: 2.3111634254455566
Validation loss: 2.006286051965529

Epoch: 6| Step: 6
Training loss: 2.6263809204101562
Validation loss: 1.9960832749643633

Epoch: 6| Step: 7
Training loss: 2.2218499183654785
Validation loss: 1.9991015208664762

Epoch: 6| Step: 8
Training loss: 2.2492432594299316
Validation loss: 1.9922318125283847

Epoch: 6| Step: 9
Training loss: 2.2049179077148438
Validation loss: 1.9922067478138914

Epoch: 6| Step: 10
Training loss: 2.7644710540771484
Validation loss: 1.9950036182198474

Epoch: 6| Step: 11
Training loss: 2.073063373565674
Validation loss: 1.9896415536121657

Epoch: 6| Step: 12
Training loss: 2.3631794452667236
Validation loss: 1.9958600177559802

Epoch: 6| Step: 13
Training loss: 1.8444781303405762
Validation loss: 1.9869882573363602

Epoch: 93| Step: 0
Training loss: 2.4551162719726562
Validation loss: 1.9896224878167594

Epoch: 6| Step: 1
Training loss: 1.7016892433166504
Validation loss: 2.0028053483655377

Epoch: 6| Step: 2
Training loss: 2.7147698402404785
Validation loss: 2.0106136773222234

Epoch: 6| Step: 3
Training loss: 2.426891326904297
Validation loss: 2.0155466987240698

Epoch: 6| Step: 4
Training loss: 2.483687400817871
Validation loss: 2.0362270583388624

Epoch: 6| Step: 5
Training loss: 1.7786073684692383
Validation loss: 2.0370994819107877

Epoch: 6| Step: 6
Training loss: 2.45821475982666
Validation loss: 2.0080837344610565

Epoch: 6| Step: 7
Training loss: 1.6228866577148438
Validation loss: 2.0051552916085846

Epoch: 6| Step: 8
Training loss: 2.547255754470825
Validation loss: 2.0037178121587282

Epoch: 6| Step: 9
Training loss: 2.0132479667663574
Validation loss: 2.0082089567697174

Epoch: 6| Step: 10
Training loss: 2.0786681175231934
Validation loss: 2.013028952383226

Epoch: 6| Step: 11
Training loss: 2.4257264137268066
Validation loss: 2.0131352563058176

Epoch: 6| Step: 12
Training loss: 2.0906102657318115
Validation loss: 2.0366451022445515

Epoch: 6| Step: 13
Training loss: 2.509486198425293
Validation loss: 2.0287290452629008

Epoch: 94| Step: 0
Training loss: 1.448976993560791
Validation loss: 1.987679084142049

Epoch: 6| Step: 1
Training loss: 2.6693062782287598
Validation loss: 1.9835957916834022

Epoch: 6| Step: 2
Training loss: 2.2368369102478027
Validation loss: 1.9709822183014245

Epoch: 6| Step: 3
Training loss: 2.855825901031494
Validation loss: 1.9647397020811677

Epoch: 6| Step: 4
Training loss: 2.214390754699707
Validation loss: 1.96549851663651

Epoch: 6| Step: 5
Training loss: 2.3757870197296143
Validation loss: 1.970968274660008

Epoch: 6| Step: 6
Training loss: 2.348825454711914
Validation loss: 1.9662550828790153

Epoch: 6| Step: 7
Training loss: 1.8574446439743042
Validation loss: 1.9601862379299697

Epoch: 6| Step: 8
Training loss: 1.9902894496917725
Validation loss: 1.9786125921433972

Epoch: 6| Step: 9
Training loss: 1.5434991121292114
Validation loss: 2.005594990586722

Epoch: 6| Step: 10
Training loss: 2.264451265335083
Validation loss: 2.0460350116093955

Epoch: 6| Step: 11
Training loss: 2.184480667114258
Validation loss: 2.0780869658275316

Epoch: 6| Step: 12
Training loss: 3.0763442516326904
Validation loss: 2.079775014231282

Epoch: 6| Step: 13
Training loss: 1.9517712593078613
Validation loss: 2.083863565998693

Epoch: 95| Step: 0
Training loss: 2.782538414001465
Validation loss: 2.0981966885187293

Epoch: 6| Step: 1
Training loss: 3.3919777870178223
Validation loss: 2.1124369508476666

Epoch: 6| Step: 2
Training loss: 2.1882097721099854
Validation loss: 2.1056589567533104

Epoch: 6| Step: 3
Training loss: 1.6856120824813843
Validation loss: 2.081113253870318

Epoch: 6| Step: 4
Training loss: 2.0103249549865723
Validation loss: 2.0296632346286567

Epoch: 6| Step: 5
Training loss: 1.9190809726715088
Validation loss: 1.9971723876973635

Epoch: 6| Step: 6
Training loss: 1.8530452251434326
Validation loss: 1.9662743883748208

Epoch: 6| Step: 7
Training loss: 1.8836116790771484
Validation loss: 1.9467432652750323

Epoch: 6| Step: 8
Training loss: 2.0104119777679443
Validation loss: 1.9400152057729743

Epoch: 6| Step: 9
Training loss: 2.5859405994415283
Validation loss: 1.939505600160168

Epoch: 6| Step: 10
Training loss: 2.6141529083251953
Validation loss: 1.938398681661134

Epoch: 6| Step: 11
Training loss: 2.144965171813965
Validation loss: 1.943225650377171

Epoch: 6| Step: 12
Training loss: 2.2229180335998535
Validation loss: 1.941303721038244

Epoch: 6| Step: 13
Training loss: 2.3615124225616455
Validation loss: 1.9375740789598035

Epoch: 96| Step: 0
Training loss: 1.5825107097625732
Validation loss: 1.964937469010712

Epoch: 6| Step: 1
Training loss: 2.645918130874634
Validation loss: 1.9799691195129066

Epoch: 6| Step: 2
Training loss: 2.159977912902832
Validation loss: 2.00052414401885

Epoch: 6| Step: 3
Training loss: 2.0492117404937744
Validation loss: 2.029943484132008

Epoch: 6| Step: 4
Training loss: 2.5516741275787354
Validation loss: 2.0285055124631493

Epoch: 6| Step: 5
Training loss: 1.8177974224090576
Validation loss: 2.02351773554279

Epoch: 6| Step: 6
Training loss: 3.3186416625976562
Validation loss: 2.0036648268340738

Epoch: 6| Step: 7
Training loss: 2.512441635131836
Validation loss: 1.9989180975062872

Epoch: 6| Step: 8
Training loss: 1.7994725704193115
Validation loss: 1.9768635637016707

Epoch: 6| Step: 9
Training loss: 1.2881579399108887
Validation loss: 1.9503639936447144

Epoch: 6| Step: 10
Training loss: 2.4766321182250977
Validation loss: 1.9549584927097443

Epoch: 6| Step: 11
Training loss: 2.189420223236084
Validation loss: 1.955275866293138

Epoch: 6| Step: 12
Training loss: 2.196909189224243
Validation loss: 1.9496642671605593

Epoch: 6| Step: 13
Training loss: 2.8416473865509033
Validation loss: 1.9608507399917932

Epoch: 97| Step: 0
Training loss: 2.227187395095825
Validation loss: 1.9676344292138213

Epoch: 6| Step: 1
Training loss: 1.9870895147323608
Validation loss: 2.011039544177312

Epoch: 6| Step: 2
Training loss: 2.6137571334838867
Validation loss: 2.044669456379388

Epoch: 6| Step: 3
Training loss: 2.5917510986328125
Validation loss: 2.0788065528356903

Epoch: 6| Step: 4
Training loss: 2.6297035217285156
Validation loss: 2.1135205350896364

Epoch: 6| Step: 5
Training loss: 1.4743289947509766
Validation loss: 2.1163607412768948

Epoch: 6| Step: 6
Training loss: 2.0123677253723145
Validation loss: 2.080516169148107

Epoch: 6| Step: 7
Training loss: 2.2328500747680664
Validation loss: 2.0490602344594975

Epoch: 6| Step: 8
Training loss: 2.3102381229400635
Validation loss: 2.033031445677562

Epoch: 6| Step: 9
Training loss: 2.197087049484253
Validation loss: 1.9956762803498136

Epoch: 6| Step: 10
Training loss: 1.639517068862915
Validation loss: 1.9608050648884108

Epoch: 6| Step: 11
Training loss: 2.941438674926758
Validation loss: 1.9514850570309548

Epoch: 6| Step: 12
Training loss: 1.8566899299621582
Validation loss: 1.9636853664152083

Epoch: 6| Step: 13
Training loss: 2.2209479808807373
Validation loss: 1.9658486663654287

Epoch: 98| Step: 0
Training loss: 2.389984607696533
Validation loss: 1.962032328369797

Epoch: 6| Step: 1
Training loss: 2.0464816093444824
Validation loss: 1.9656555908982472

Epoch: 6| Step: 2
Training loss: 2.6695022583007812
Validation loss: 1.9688477464901504

Epoch: 6| Step: 3
Training loss: 2.1387381553649902
Validation loss: 1.9774559441433157

Epoch: 6| Step: 4
Training loss: 2.0591280460357666
Validation loss: 1.9730467719416465

Epoch: 6| Step: 5
Training loss: 2.274531841278076
Validation loss: 1.976826734440301

Epoch: 6| Step: 6
Training loss: 2.872804880142212
Validation loss: 1.9865393228428339

Epoch: 6| Step: 7
Training loss: 2.4793567657470703
Validation loss: 1.9796945164280553

Epoch: 6| Step: 8
Training loss: 2.2864198684692383
Validation loss: 2.001108254155805

Epoch: 6| Step: 9
Training loss: 2.1323018074035645
Validation loss: 2.0093077857007264

Epoch: 6| Step: 10
Training loss: 1.7597790956497192
Validation loss: 2.0183411067531956

Epoch: 6| Step: 11
Training loss: 2.002535343170166
Validation loss: 2.0215064300003873

Epoch: 6| Step: 12
Training loss: 1.9724640846252441
Validation loss: 1.9975366207861132

Epoch: 6| Step: 13
Training loss: 1.645402431488037
Validation loss: 1.9885668536668182

Epoch: 99| Step: 0
Training loss: 2.7099106311798096
Validation loss: 1.9946397273771224

Epoch: 6| Step: 1
Training loss: 2.1271610260009766
Validation loss: 1.9938716952518751

Epoch: 6| Step: 2
Training loss: 2.564769744873047
Validation loss: 1.9862239950446672

Epoch: 6| Step: 3
Training loss: 2.1296427249908447
Validation loss: 1.9775553082907071

Epoch: 6| Step: 4
Training loss: 2.258787155151367
Validation loss: 1.9757522024134153

Epoch: 6| Step: 5
Training loss: 1.6324260234832764
Validation loss: 1.9785241901233632

Epoch: 6| Step: 6
Training loss: 1.7592443227767944
Validation loss: 1.9953373811578239

Epoch: 6| Step: 7
Training loss: 1.8017644882202148
Validation loss: 1.9944489284228253

Epoch: 6| Step: 8
Training loss: 2.3859620094299316
Validation loss: 1.9883174293784684

Epoch: 6| Step: 9
Training loss: 2.775909662246704
Validation loss: 1.9848445935915875

Epoch: 6| Step: 10
Training loss: 1.5669455528259277
Validation loss: 1.99112259188006

Epoch: 6| Step: 11
Training loss: 2.2363054752349854
Validation loss: 1.9847271468049736

Epoch: 6| Step: 12
Training loss: 1.9987092018127441
Validation loss: 1.9861118485850673

Epoch: 6| Step: 13
Training loss: 3.1701443195343018
Validation loss: 1.974739533598705

Epoch: 100| Step: 0
Training loss: 2.141796588897705
Validation loss: 1.976299108997468

Epoch: 6| Step: 1
Training loss: 2.846363067626953
Validation loss: 1.9768556446157477

Epoch: 6| Step: 2
Training loss: 1.9574445486068726
Validation loss: 1.976019791377488

Epoch: 6| Step: 3
Training loss: 2.6628479957580566
Validation loss: 1.972275205837783

Epoch: 6| Step: 4
Training loss: 1.9669935703277588
Validation loss: 1.9675572585034113

Epoch: 6| Step: 5
Training loss: 1.9473916292190552
Validation loss: 1.979402231913741

Epoch: 6| Step: 6
Training loss: 2.0438876152038574
Validation loss: 1.9756109868326495

Epoch: 6| Step: 7
Training loss: 2.503124713897705
Validation loss: 1.9682568375782301

Epoch: 6| Step: 8
Training loss: 1.7514677047729492
Validation loss: 1.9761396223498928

Epoch: 6| Step: 9
Training loss: 2.094447135925293
Validation loss: 1.9827964754514797

Epoch: 6| Step: 10
Training loss: 2.7637414932250977
Validation loss: 1.9725887083238172

Epoch: 6| Step: 11
Training loss: 1.8827180862426758
Validation loss: 1.9828582937999437

Epoch: 6| Step: 12
Training loss: 1.588346242904663
Validation loss: 1.9989515273801741

Epoch: 6| Step: 13
Training loss: 2.395859718322754
Validation loss: 1.9925418194904123

Epoch: 101| Step: 0
Training loss: 2.68436336517334
Validation loss: 2.0081298569197297

Epoch: 6| Step: 1
Training loss: 2.3624792098999023
Validation loss: 2.0051864962424

Epoch: 6| Step: 2
Training loss: 2.453547954559326
Validation loss: 1.995477525136804

Epoch: 6| Step: 3
Training loss: 1.556775450706482
Validation loss: 1.995672356697821

Epoch: 6| Step: 4
Training loss: 1.646355152130127
Validation loss: 1.9800167237558672

Epoch: 6| Step: 5
Training loss: 2.3587584495544434
Validation loss: 1.9506292637958322

Epoch: 6| Step: 6
Training loss: 1.9320592880249023
Validation loss: 1.9416624230723227

Epoch: 6| Step: 7
Training loss: 2.602393627166748
Validation loss: 1.944042746738721

Epoch: 6| Step: 8
Training loss: 2.395169258117676
Validation loss: 1.9310312912028322

Epoch: 6| Step: 9
Training loss: 2.1978487968444824
Validation loss: 1.945947693240258

Epoch: 6| Step: 10
Training loss: 1.7177226543426514
Validation loss: 1.958251755724671

Epoch: 6| Step: 11
Training loss: 1.91846764087677
Validation loss: 1.9625014053877963

Epoch: 6| Step: 12
Training loss: 2.377613067626953
Validation loss: 1.9600491933925177

Epoch: 6| Step: 13
Training loss: 2.317789316177368
Validation loss: 1.9670277667301956

Epoch: 102| Step: 0
Training loss: 1.4872283935546875
Validation loss: 1.9673780548957087

Epoch: 6| Step: 1
Training loss: 1.8721299171447754
Validation loss: 1.9690974886699388

Epoch: 6| Step: 2
Training loss: 2.1863455772399902
Validation loss: 1.9754275532178982

Epoch: 6| Step: 3
Training loss: 2.1811277866363525
Validation loss: 1.9764691091352893

Epoch: 6| Step: 4
Training loss: 1.6148254871368408
Validation loss: 1.9923833570172709

Epoch: 6| Step: 5
Training loss: 2.815608024597168
Validation loss: 1.9881603474258094

Epoch: 6| Step: 6
Training loss: 1.7320513725280762
Validation loss: 1.972429238339906

Epoch: 6| Step: 7
Training loss: 1.9147826433181763
Validation loss: 1.9650846860742057

Epoch: 6| Step: 8
Training loss: 2.4941489696502686
Validation loss: 1.9639569713223366

Epoch: 6| Step: 9
Training loss: 2.039828300476074
Validation loss: 1.9600382607470277

Epoch: 6| Step: 10
Training loss: 2.307152271270752
Validation loss: 1.9619040591742403

Epoch: 6| Step: 11
Training loss: 2.7872118949890137
Validation loss: 1.9724969504981913

Epoch: 6| Step: 12
Training loss: 1.9998605251312256
Validation loss: 1.9829093871578094

Epoch: 6| Step: 13
Training loss: 3.0407958030700684
Validation loss: 1.9941733383363294

Epoch: 103| Step: 0
Training loss: 1.7216403484344482
Validation loss: 2.0093333785251906

Epoch: 6| Step: 1
Training loss: 2.3377668857574463
Validation loss: 1.9987214560149817

Epoch: 6| Step: 2
Training loss: 2.1087870597839355
Validation loss: 1.9922449281138759

Epoch: 6| Step: 3
Training loss: 2.030735731124878
Validation loss: 2.0061137599329792

Epoch: 6| Step: 4
Training loss: 2.622939109802246
Validation loss: 2.0009873349179506

Epoch: 6| Step: 5
Training loss: 1.8906019926071167
Validation loss: 2.0011602345333306

Epoch: 6| Step: 6
Training loss: 2.3398284912109375
Validation loss: 1.9947847089459818

Epoch: 6| Step: 7
Training loss: 2.4521472454071045
Validation loss: 1.9784539720063568

Epoch: 6| Step: 8
Training loss: 1.784104347229004
Validation loss: 1.9750343074080765

Epoch: 6| Step: 9
Training loss: 1.8667521476745605
Validation loss: 1.9845104089347265

Epoch: 6| Step: 10
Training loss: 2.064180850982666
Validation loss: 1.979348474933255

Epoch: 6| Step: 11
Training loss: 1.9102321863174438
Validation loss: 1.985406844846664

Epoch: 6| Step: 12
Training loss: 2.573577404022217
Validation loss: 1.9683666947067424

Epoch: 6| Step: 13
Training loss: 2.2719125747680664
Validation loss: 1.9785909588618944

Epoch: 104| Step: 0
Training loss: 1.7893792390823364
Validation loss: 2.0338460783804617

Epoch: 6| Step: 1
Training loss: 2.4573516845703125
Validation loss: 2.0673698763693533

Epoch: 6| Step: 2
Training loss: 2.123868703842163
Validation loss: 2.1061522294116277

Epoch: 6| Step: 3
Training loss: 2.7909979820251465
Validation loss: 2.102943161482452

Epoch: 6| Step: 4
Training loss: 1.9035717248916626
Validation loss: 2.0859801410346903

Epoch: 6| Step: 5
Training loss: 2.2899575233459473
Validation loss: 2.055214002568235

Epoch: 6| Step: 6
Training loss: 2.028423309326172
Validation loss: 2.0316919767728416

Epoch: 6| Step: 7
Training loss: 2.0090370178222656
Validation loss: 2.004717875552434

Epoch: 6| Step: 8
Training loss: 2.049738883972168
Validation loss: 2.0007262358101467

Epoch: 6| Step: 9
Training loss: 2.0544004440307617
Validation loss: 1.991140857819588

Epoch: 6| Step: 10
Training loss: 1.8289984464645386
Validation loss: 1.9926464480738486

Epoch: 6| Step: 11
Training loss: 2.0523366928100586
Validation loss: 1.9718836225489134

Epoch: 6| Step: 12
Training loss: 2.3357720375061035
Validation loss: 1.9520978760975662

Epoch: 6| Step: 13
Training loss: 3.1330180168151855
Validation loss: 1.9412582023169405

Epoch: 105| Step: 0
Training loss: 1.8518531322479248
Validation loss: 1.9643494672672723

Epoch: 6| Step: 1
Training loss: 2.128065347671509
Validation loss: 1.970030547470175

Epoch: 6| Step: 2
Training loss: 2.4195449352264404
Validation loss: 1.9880680012446579

Epoch: 6| Step: 3
Training loss: 2.9393606185913086
Validation loss: 2.0276263900982436

Epoch: 6| Step: 4
Training loss: 1.983680009841919
Validation loss: 2.0392318438458186

Epoch: 6| Step: 5
Training loss: 2.053887367248535
Validation loss: 2.0513549697014595

Epoch: 6| Step: 6
Training loss: 2.276271104812622
Validation loss: 2.0547553595676216

Epoch: 6| Step: 7
Training loss: 1.883286476135254
Validation loss: 2.045721066895352

Epoch: 6| Step: 8
Training loss: 1.9800024032592773
Validation loss: 2.01588080006261

Epoch: 6| Step: 9
Training loss: 2.377573013305664
Validation loss: 1.9875292572923886

Epoch: 6| Step: 10
Training loss: 2.152968406677246
Validation loss: 1.9608225873721543

Epoch: 6| Step: 11
Training loss: 1.979126214981079
Validation loss: 1.9417128716745684

Epoch: 6| Step: 12
Training loss: 2.052990436553955
Validation loss: 1.9443063210415583

Epoch: 6| Step: 13
Training loss: 1.860735535621643
Validation loss: 1.949285173928866

Epoch: 106| Step: 0
Training loss: 1.9803351163864136
Validation loss: 1.9522996166700959

Epoch: 6| Step: 1
Training loss: 2.479820728302002
Validation loss: 1.9597872123923352

Epoch: 6| Step: 2
Training loss: 2.425246238708496
Validation loss: 1.9659565212906047

Epoch: 6| Step: 3
Training loss: 2.746936321258545
Validation loss: 1.9660118741373862

Epoch: 6| Step: 4
Training loss: 1.9667041301727295
Validation loss: 1.9765120757523404

Epoch: 6| Step: 5
Training loss: 1.9495168924331665
Validation loss: 1.9749779880687754

Epoch: 6| Step: 6
Training loss: 1.9733043909072876
Validation loss: 1.9632997794817852

Epoch: 6| Step: 7
Training loss: 2.6037464141845703
Validation loss: 1.9656301044648694

Epoch: 6| Step: 8
Training loss: 2.0094940662384033
Validation loss: 1.9473480114372828

Epoch: 6| Step: 9
Training loss: 1.7378212213516235
Validation loss: 1.9491495599028885

Epoch: 6| Step: 10
Training loss: 2.095479726791382
Validation loss: 1.9288814503659484

Epoch: 6| Step: 11
Training loss: 1.6705514192581177
Validation loss: 1.9411028662035543

Epoch: 6| Step: 12
Training loss: 2.138544797897339
Validation loss: 1.9205680290857952

Epoch: 6| Step: 13
Training loss: 1.958403468132019
Validation loss: 1.9324242197057253

Epoch: 107| Step: 0
Training loss: 1.7763751745224
Validation loss: 1.944884277159168

Epoch: 6| Step: 1
Training loss: 1.7178936004638672
Validation loss: 1.9425256854744368

Epoch: 6| Step: 2
Training loss: 2.466944932937622
Validation loss: 1.943350007457118

Epoch: 6| Step: 3
Training loss: 1.7832008600234985
Validation loss: 1.934847234397806

Epoch: 6| Step: 4
Training loss: 2.4514455795288086
Validation loss: 1.931665846096572

Epoch: 6| Step: 5
Training loss: 1.646372675895691
Validation loss: 1.9302791690313688

Epoch: 6| Step: 6
Training loss: 2.132249593734741
Validation loss: 1.9294829830046623

Epoch: 6| Step: 7
Training loss: 2.3122739791870117
Validation loss: 1.936703262790557

Epoch: 6| Step: 8
Training loss: 2.842918634414673
Validation loss: 1.9498179548530168

Epoch: 6| Step: 9
Training loss: 1.649186611175537
Validation loss: 1.9657432879171064

Epoch: 6| Step: 10
Training loss: 1.8264334201812744
Validation loss: 1.9849596664469729

Epoch: 6| Step: 11
Training loss: 2.1173224449157715
Validation loss: 1.989890375444966

Epoch: 6| Step: 12
Training loss: 2.2829322814941406
Validation loss: 1.980094664840288

Epoch: 6| Step: 13
Training loss: 2.5313892364501953
Validation loss: 1.9818261720800912

Epoch: 108| Step: 0
Training loss: 2.5997533798217773
Validation loss: 1.994768540064494

Epoch: 6| Step: 1
Training loss: 1.530268907546997
Validation loss: 1.987313247496082

Epoch: 6| Step: 2
Training loss: 2.667613983154297
Validation loss: 1.9762655137687601

Epoch: 6| Step: 3
Training loss: 1.808180809020996
Validation loss: 1.976946815367668

Epoch: 6| Step: 4
Training loss: 2.365633964538574
Validation loss: 1.9922496272671608

Epoch: 6| Step: 5
Training loss: 2.1416335105895996
Validation loss: 1.9729930841794578

Epoch: 6| Step: 6
Training loss: 1.7554287910461426
Validation loss: 1.9703543801461496

Epoch: 6| Step: 7
Training loss: 1.6258823871612549
Validation loss: 1.9597689643982918

Epoch: 6| Step: 8
Training loss: 2.21199893951416
Validation loss: 1.9673311761630479

Epoch: 6| Step: 9
Training loss: 1.968254566192627
Validation loss: 1.9584806683242961

Epoch: 6| Step: 10
Training loss: 2.3092041015625
Validation loss: 1.957017014103551

Epoch: 6| Step: 11
Training loss: 2.527935028076172
Validation loss: 1.9635967157220329

Epoch: 6| Step: 12
Training loss: 1.7310075759887695
Validation loss: 1.9619657608770555

Epoch: 6| Step: 13
Training loss: 1.8860514163970947
Validation loss: 1.96350997237749

Epoch: 109| Step: 0
Training loss: 2.0621519088745117
Validation loss: 1.961385097554935

Epoch: 6| Step: 1
Training loss: 2.442532777786255
Validation loss: 1.9859023222359278

Epoch: 6| Step: 2
Training loss: 2.237074851989746
Validation loss: 1.9825108076936455

Epoch: 6| Step: 3
Training loss: 2.7128467559814453
Validation loss: 1.9629123774907922

Epoch: 6| Step: 4
Training loss: 1.6301252841949463
Validation loss: 1.9484720563375821

Epoch: 6| Step: 5
Training loss: 2.3204452991485596
Validation loss: 1.9494025630335654

Epoch: 6| Step: 6
Training loss: 1.8921855688095093
Validation loss: 1.9392290371720509

Epoch: 6| Step: 7
Training loss: 2.7563962936401367
Validation loss: 1.9551134199224494

Epoch: 6| Step: 8
Training loss: 1.6292436122894287
Validation loss: 1.9724355577140726

Epoch: 6| Step: 9
Training loss: 2.6546742916107178
Validation loss: 1.972911678334718

Epoch: 6| Step: 10
Training loss: 1.6538677215576172
Validation loss: 1.9735023411371375

Epoch: 6| Step: 11
Training loss: 1.7161823511123657
Validation loss: 1.9608146657225907

Epoch: 6| Step: 12
Training loss: 2.01279354095459
Validation loss: 1.9481932681093934

Epoch: 6| Step: 13
Training loss: 1.1123937368392944
Validation loss: 1.9721140476965136

Epoch: 110| Step: 0
Training loss: 2.4254062175750732
Validation loss: 1.986393561927221

Epoch: 6| Step: 1
Training loss: 1.7435338497161865
Validation loss: 1.9934560368137975

Epoch: 6| Step: 2
Training loss: 2.0948476791381836
Validation loss: 1.9666478351880146

Epoch: 6| Step: 3
Training loss: 2.637542247772217
Validation loss: 1.9815593816900765

Epoch: 6| Step: 4
Training loss: 1.8813824653625488
Validation loss: 2.010326544443766

Epoch: 6| Step: 5
Training loss: 2.3733887672424316
Validation loss: 2.0369528762755857

Epoch: 6| Step: 6
Training loss: 2.1044559478759766
Validation loss: 2.0545266648774505

Epoch: 6| Step: 7
Training loss: 2.275371551513672
Validation loss: 2.089402175718738

Epoch: 6| Step: 8
Training loss: 1.846348524093628
Validation loss: 2.1113567890659457

Epoch: 6| Step: 9
Training loss: 1.7028685808181763
Validation loss: 2.0907760409898657

Epoch: 6| Step: 10
Training loss: 2.514688014984131
Validation loss: 2.0017299190644295

Epoch: 6| Step: 11
Training loss: 1.5713067054748535
Validation loss: 1.9700566773773522

Epoch: 6| Step: 12
Training loss: 2.1766180992126465
Validation loss: 1.9596362319043887

Epoch: 6| Step: 13
Training loss: 2.7319517135620117
Validation loss: 1.9539139283600675

Epoch: 111| Step: 0
Training loss: 2.3738832473754883
Validation loss: 1.958638665496662

Epoch: 6| Step: 1
Training loss: 2.12849760055542
Validation loss: 1.9492989329881565

Epoch: 6| Step: 2
Training loss: 2.0102357864379883
Validation loss: 1.9836924499081028

Epoch: 6| Step: 3
Training loss: 1.8380846977233887
Validation loss: 2.0355910101244525

Epoch: 6| Step: 4
Training loss: 2.1049439907073975
Validation loss: 2.1125268026064803

Epoch: 6| Step: 5
Training loss: 2.4552693367004395
Validation loss: 2.1520945538756666

Epoch: 6| Step: 6
Training loss: 2.5202910900115967
Validation loss: 2.1147013659118326

Epoch: 6| Step: 7
Training loss: 1.6486586332321167
Validation loss: 2.0618702186051237

Epoch: 6| Step: 8
Training loss: 2.2527053356170654
Validation loss: 2.036918233799678

Epoch: 6| Step: 9
Training loss: 2.7261581420898438
Validation loss: 2.0021941520834483

Epoch: 6| Step: 10
Training loss: 2.0268607139587402
Validation loss: 1.9814524112209198

Epoch: 6| Step: 11
Training loss: 2.12404465675354
Validation loss: 1.9517635581313924

Epoch: 6| Step: 12
Training loss: 1.7129932641983032
Validation loss: 1.9426791744847451

Epoch: 6| Step: 13
Training loss: 1.4598166942596436
Validation loss: 1.9673424228545158

Epoch: 112| Step: 0
Training loss: 2.398118495941162
Validation loss: 1.9903721963205645

Epoch: 6| Step: 1
Training loss: 2.5578525066375732
Validation loss: 1.9897970935349822

Epoch: 6| Step: 2
Training loss: 2.3252620697021484
Validation loss: 2.01084065693681

Epoch: 6| Step: 3
Training loss: 2.1044650077819824
Validation loss: 2.0095421806458504

Epoch: 6| Step: 4
Training loss: 1.7146046161651611
Validation loss: 1.9935524040652859

Epoch: 6| Step: 5
Training loss: 2.820143222808838
Validation loss: 1.9545385978555168

Epoch: 6| Step: 6
Training loss: 2.436838150024414
Validation loss: 1.9578192259675713

Epoch: 6| Step: 7
Training loss: 1.1261403560638428
Validation loss: 1.962059478605947

Epoch: 6| Step: 8
Training loss: 2.1938390731811523
Validation loss: 1.9548884463566605

Epoch: 6| Step: 9
Training loss: 1.9009946584701538
Validation loss: 1.9740285834958475

Epoch: 6| Step: 10
Training loss: 2.091313600540161
Validation loss: 2.0166525943304903

Epoch: 6| Step: 11
Training loss: 1.7833964824676514
Validation loss: 2.026198879364998

Epoch: 6| Step: 12
Training loss: 1.8686532974243164
Validation loss: 2.0336537540599866

Epoch: 6| Step: 13
Training loss: 2.2008886337280273
Validation loss: 2.003108633461819

Epoch: 113| Step: 0
Training loss: 1.735025405883789
Validation loss: 1.9782239057684456

Epoch: 6| Step: 1
Training loss: 2.1596593856811523
Validation loss: 1.9781667365822742

Epoch: 6| Step: 2
Training loss: 1.7563109397888184
Validation loss: 1.9807670180515577

Epoch: 6| Step: 3
Training loss: 2.190535545349121
Validation loss: 1.968839386458038

Epoch: 6| Step: 4
Training loss: 1.7540571689605713
Validation loss: 1.9694084659699471

Epoch: 6| Step: 5
Training loss: 2.4706063270568848
Validation loss: 1.9755012886498564

Epoch: 6| Step: 6
Training loss: 2.6716396808624268
Validation loss: 1.9969436763435282

Epoch: 6| Step: 7
Training loss: 1.8570947647094727
Validation loss: 1.9863667782916818

Epoch: 6| Step: 8
Training loss: 2.5490944385528564
Validation loss: 1.9719640721556961

Epoch: 6| Step: 9
Training loss: 2.8001112937927246
Validation loss: 1.9384403164668749

Epoch: 6| Step: 10
Training loss: 1.4841258525848389
Validation loss: 1.9497842839969102

Epoch: 6| Step: 11
Training loss: 1.5599346160888672
Validation loss: 1.9509050000098445

Epoch: 6| Step: 12
Training loss: 1.68844735622406
Validation loss: 1.9428545633951824

Epoch: 6| Step: 13
Training loss: 2.9090750217437744
Validation loss: 1.9438112910075853

Epoch: 114| Step: 0
Training loss: 2.2451868057250977
Validation loss: 1.9325142291284376

Epoch: 6| Step: 1
Training loss: 2.217133045196533
Validation loss: 1.9274740808753557

Epoch: 6| Step: 2
Training loss: 1.889609456062317
Validation loss: 1.9050972295063797

Epoch: 6| Step: 3
Training loss: 2.3900890350341797
Validation loss: 1.9090875271827943

Epoch: 6| Step: 4
Training loss: 2.196169853210449
Validation loss: 1.9130579797170495

Epoch: 6| Step: 5
Training loss: 1.7490901947021484
Validation loss: 1.9296011488924745

Epoch: 6| Step: 6
Training loss: 1.7853604555130005
Validation loss: 1.9495100641763339

Epoch: 6| Step: 7
Training loss: 1.63169264793396
Validation loss: 1.9626751920228362

Epoch: 6| Step: 8
Training loss: 2.137697219848633
Validation loss: 1.9783140946460027

Epoch: 6| Step: 9
Training loss: 1.9486606121063232
Validation loss: 1.9931938391859814

Epoch: 6| Step: 10
Training loss: 2.512967348098755
Validation loss: 2.0129775603612265

Epoch: 6| Step: 11
Training loss: 1.7531044483184814
Validation loss: 2.0239370381960304

Epoch: 6| Step: 12
Training loss: 2.3746323585510254
Validation loss: 1.9865669986253143

Epoch: 6| Step: 13
Training loss: 2.0804009437561035
Validation loss: 1.9479627263161443

Epoch: 115| Step: 0
Training loss: 1.4528934955596924
Validation loss: 1.9390325520628242

Epoch: 6| Step: 1
Training loss: 1.585365891456604
Validation loss: 1.9386473471118557

Epoch: 6| Step: 2
Training loss: 2.1763713359832764
Validation loss: 1.947316514548435

Epoch: 6| Step: 3
Training loss: 2.059065103530884
Validation loss: 1.9772038229050175

Epoch: 6| Step: 4
Training loss: 2.2013964653015137
Validation loss: 1.9661777827047533

Epoch: 6| Step: 5
Training loss: 2.200141429901123
Validation loss: 1.9548792723686463

Epoch: 6| Step: 6
Training loss: 2.660562753677368
Validation loss: 1.9917588644130255

Epoch: 6| Step: 7
Training loss: 2.205920934677124
Validation loss: 1.992861920787442

Epoch: 6| Step: 8
Training loss: 2.498302459716797
Validation loss: 2.0075317044411936

Epoch: 6| Step: 9
Training loss: 2.5577921867370605
Validation loss: 2.0176215171813965

Epoch: 6| Step: 10
Training loss: 1.5618935823440552
Validation loss: 2.018543371590235

Epoch: 6| Step: 11
Training loss: 2.08650803565979
Validation loss: 2.011547730815026

Epoch: 6| Step: 12
Training loss: 1.8289939165115356
Validation loss: 1.997558839859501

Epoch: 6| Step: 13
Training loss: 2.1444969177246094
Validation loss: 1.9845891203931583

Epoch: 116| Step: 0
Training loss: 2.205139636993408
Validation loss: 1.9740348528790217

Epoch: 6| Step: 1
Training loss: 1.6619446277618408
Validation loss: 1.9806224864016297

Epoch: 6| Step: 2
Training loss: 2.2517988681793213
Validation loss: 1.9854322415526195

Epoch: 6| Step: 3
Training loss: 2.458087205886841
Validation loss: 1.986551687281619

Epoch: 6| Step: 4
Training loss: 1.464958906173706
Validation loss: 1.9897569200044036

Epoch: 6| Step: 5
Training loss: 2.58453631401062
Validation loss: 1.9689686682916456

Epoch: 6| Step: 6
Training loss: 2.092484951019287
Validation loss: 1.9537963559550624

Epoch: 6| Step: 7
Training loss: 1.7884535789489746
Validation loss: 2.0103064557557464

Epoch: 6| Step: 8
Training loss: 1.5751816034317017
Validation loss: 2.0978788483527397

Epoch: 6| Step: 9
Training loss: 1.8414545059204102
Validation loss: 2.151462047330795

Epoch: 6| Step: 10
Training loss: 2.1261024475097656
Validation loss: 2.139237857634021

Epoch: 6| Step: 11
Training loss: 2.715810537338257
Validation loss: 2.104106701830382

Epoch: 6| Step: 12
Training loss: 2.0329525470733643
Validation loss: 2.0796907665908977

Epoch: 6| Step: 13
Training loss: 2.027859687805176
Validation loss: 2.0472565056175314

Epoch: 117| Step: 0
Training loss: 2.929931163787842
Validation loss: 1.997301955376902

Epoch: 6| Step: 1
Training loss: 2.0745887756347656
Validation loss: 1.9533657796921269

Epoch: 6| Step: 2
Training loss: 1.7042427062988281
Validation loss: 1.933679275615241

Epoch: 6| Step: 3
Training loss: 2.1468665599823
Validation loss: 1.9381930302548152

Epoch: 6| Step: 4
Training loss: 1.9064635038375854
Validation loss: 1.9502196927224436

Epoch: 6| Step: 5
Training loss: 2.3202152252197266
Validation loss: 1.961803340142773

Epoch: 6| Step: 6
Training loss: 1.8865742683410645
Validation loss: 1.9701286515881937

Epoch: 6| Step: 7
Training loss: 2.0586724281311035
Validation loss: 1.9616540042302941

Epoch: 6| Step: 8
Training loss: 1.8660264015197754
Validation loss: 1.9476705007655646

Epoch: 6| Step: 9
Training loss: 2.164565086364746
Validation loss: 1.9329125663285613

Epoch: 6| Step: 10
Training loss: 2.1789257526397705
Validation loss: 1.9452498266773839

Epoch: 6| Step: 11
Training loss: 1.5828495025634766
Validation loss: 1.98802532944628

Epoch: 6| Step: 12
Training loss: 1.9704985618591309
Validation loss: 2.0413786339503464

Epoch: 6| Step: 13
Training loss: 1.98862624168396
Validation loss: 2.1122538043606665

Epoch: 118| Step: 0
Training loss: 1.8223795890808105
Validation loss: 2.1601347372096074

Epoch: 6| Step: 1
Training loss: 2.1109092235565186
Validation loss: 2.175597829203452

Epoch: 6| Step: 2
Training loss: 2.9784202575683594
Validation loss: 2.183514266885737

Epoch: 6| Step: 3
Training loss: 2.0462183952331543
Validation loss: 2.1643558586797407

Epoch: 6| Step: 4
Training loss: 2.2153983116149902
Validation loss: 2.1514986509917886

Epoch: 6| Step: 5
Training loss: 2.324517250061035
Validation loss: 2.0587557720881637

Epoch: 6| Step: 6
Training loss: 1.6724048852920532
Validation loss: 1.9982371573807092

Epoch: 6| Step: 7
Training loss: 2.1642508506774902
Validation loss: 1.93244678999788

Epoch: 6| Step: 8
Training loss: 2.1028435230255127
Validation loss: 1.947403379665908

Epoch: 6| Step: 9
Training loss: 0.8308327198028564
Validation loss: 1.9616654226856847

Epoch: 6| Step: 10
Training loss: 1.6525166034698486
Validation loss: 1.9819932394130255

Epoch: 6| Step: 11
Training loss: 2.705490827560425
Validation loss: 1.9938980071775374

Epoch: 6| Step: 12
Training loss: 2.067796468734741
Validation loss: 2.008334928943265

Epoch: 6| Step: 13
Training loss: 3.0167248249053955
Validation loss: 1.98908346122311

Epoch: 119| Step: 0
Training loss: 1.7981289625167847
Validation loss: 1.986165697856616

Epoch: 6| Step: 1
Training loss: 1.8782269954681396
Validation loss: 1.9942317572973107

Epoch: 6| Step: 2
Training loss: 1.6644747257232666
Validation loss: 1.9899535307320215

Epoch: 6| Step: 3
Training loss: 2.9753661155700684
Validation loss: 2.0132035234923005

Epoch: 6| Step: 4
Training loss: 1.458616018295288
Validation loss: 2.0364959868051673

Epoch: 6| Step: 5
Training loss: 2.489097833633423
Validation loss: 2.064567214699202

Epoch: 6| Step: 6
Training loss: 1.7629222869873047
Validation loss: 2.0704104118449713

Epoch: 6| Step: 7
Training loss: 2.482396364212036
Validation loss: 2.0782751934502715

Epoch: 6| Step: 8
Training loss: 2.5325143337249756
Validation loss: 2.0685601157526814

Epoch: 6| Step: 9
Training loss: 1.50925612449646
Validation loss: 2.075873524911942

Epoch: 6| Step: 10
Training loss: 2.2653932571411133
Validation loss: 2.061597711296492

Epoch: 6| Step: 11
Training loss: 1.6061115264892578
Validation loss: 2.040617213454298

Epoch: 6| Step: 12
Training loss: 2.476217746734619
Validation loss: 2.0229596117491364

Epoch: 6| Step: 13
Training loss: 1.2816160917282104
Validation loss: 2.0202586548302763

Epoch: 120| Step: 0
Training loss: 2.174191951751709
Validation loss: 2.0101538999106294

Epoch: 6| Step: 1
Training loss: 2.810746431350708
Validation loss: 2.005778690820099

Epoch: 6| Step: 2
Training loss: 1.2069251537322998
Validation loss: 1.9827812281988

Epoch: 6| Step: 3
Training loss: 1.8180418014526367
Validation loss: 1.9701193430090462

Epoch: 6| Step: 4
Training loss: 2.1436827182769775
Validation loss: 1.955590537799302

Epoch: 6| Step: 5
Training loss: 1.874330759048462
Validation loss: 1.9711673926281672

Epoch: 6| Step: 6
Training loss: 1.7617313861846924
Validation loss: 1.9882655733375139

Epoch: 6| Step: 7
Training loss: 2.5654048919677734
Validation loss: 1.9878497431355138

Epoch: 6| Step: 8
Training loss: 1.7479207515716553
Validation loss: 2.003927174434867

Epoch: 6| Step: 9
Training loss: 2.0202488899230957
Validation loss: 1.9973418379342684

Epoch: 6| Step: 10
Training loss: 2.57902193069458
Validation loss: 1.9791553046113701

Epoch: 6| Step: 11
Training loss: 1.8078134059906006
Validation loss: 1.9837714010669338

Epoch: 6| Step: 12
Training loss: 1.396287202835083
Validation loss: 1.979774441770328

Epoch: 6| Step: 13
Training loss: 1.791521668434143
Validation loss: 1.9691598761466242

Epoch: 121| Step: 0
Training loss: 1.6655328273773193
Validation loss: 1.976115131890902

Epoch: 6| Step: 1
Training loss: 2.350548028945923
Validation loss: 1.9553226655529392

Epoch: 6| Step: 2
Training loss: 2.3258349895477295
Validation loss: 1.9756766365420433

Epoch: 6| Step: 3
Training loss: 2.2036097049713135
Validation loss: 1.965316831424672

Epoch: 6| Step: 4
Training loss: 1.8271703720092773
Validation loss: 1.9544881646351149

Epoch: 6| Step: 5
Training loss: 2.22090744972229
Validation loss: 1.9637316144922727

Epoch: 6| Step: 6
Training loss: 2.2387852668762207
Validation loss: 1.9651599981451546

Epoch: 6| Step: 7
Training loss: 2.080770492553711
Validation loss: 1.965594591632966

Epoch: 6| Step: 8
Training loss: 1.9544367790222168
Validation loss: 1.9734017182421941

Epoch: 6| Step: 9
Training loss: 1.810618281364441
Validation loss: 1.9873002754744662

Epoch: 6| Step: 10
Training loss: 0.7656181454658508
Validation loss: 2.0213310949264036

Epoch: 6| Step: 11
Training loss: 2.2119903564453125
Validation loss: 2.0195641530457364

Epoch: 6| Step: 12
Training loss: 2.0722155570983887
Validation loss: 2.011158102302141

Epoch: 6| Step: 13
Training loss: 2.0560100078582764
Validation loss: 1.9994156052989345

Epoch: 122| Step: 0
Training loss: 2.379460096359253
Validation loss: 1.9633265836264497

Epoch: 6| Step: 1
Training loss: 2.1369986534118652
Validation loss: 1.954945751415786

Epoch: 6| Step: 2
Training loss: 1.4989886283874512
Validation loss: 1.954490771857641

Epoch: 6| Step: 3
Training loss: 1.8272076845169067
Validation loss: 1.9546134305256668

Epoch: 6| Step: 4
Training loss: 2.096752405166626
Validation loss: 1.9499788386847383

Epoch: 6| Step: 5
Training loss: 1.1890568733215332
Validation loss: 1.9432126142645394

Epoch: 6| Step: 6
Training loss: 2.609600067138672
Validation loss: 1.926407419225221

Epoch: 6| Step: 7
Training loss: 1.4899708032608032
Validation loss: 1.9417817413166005

Epoch: 6| Step: 8
Training loss: 2.1492319107055664
Validation loss: 1.9263523112061203

Epoch: 6| Step: 9
Training loss: 1.3234364986419678
Validation loss: 1.9503048107188234

Epoch: 6| Step: 10
Training loss: 2.378413200378418
Validation loss: 1.9652224484310354

Epoch: 6| Step: 11
Training loss: 2.3742940425872803
Validation loss: 1.9843627714341687

Epoch: 6| Step: 12
Training loss: 2.1761128902435303
Validation loss: 1.97994694658505

Epoch: 6| Step: 13
Training loss: 2.2734768390655518
Validation loss: 1.975838848339614

Epoch: 123| Step: 0
Training loss: 2.006267547607422
Validation loss: 1.9648475570063437

Epoch: 6| Step: 1
Training loss: 2.4062106609344482
Validation loss: 1.9496468626042849

Epoch: 6| Step: 2
Training loss: 1.7906529903411865
Validation loss: 1.9460510720488846

Epoch: 6| Step: 3
Training loss: 1.74196457862854
Validation loss: 1.9588305386163856

Epoch: 6| Step: 4
Training loss: 1.8922483921051025
Validation loss: 1.9648070386660996

Epoch: 6| Step: 5
Training loss: 1.1737926006317139
Validation loss: 1.9694520952881023

Epoch: 6| Step: 6
Training loss: 1.830712914466858
Validation loss: 1.9603337267393708

Epoch: 6| Step: 7
Training loss: 2.33219838142395
Validation loss: 1.9570777082955966

Epoch: 6| Step: 8
Training loss: 2.0637879371643066
Validation loss: 1.9591622532054942

Epoch: 6| Step: 9
Training loss: 2.1252942085266113
Validation loss: 1.9667608276490243

Epoch: 6| Step: 10
Training loss: 1.9630669355392456
Validation loss: 1.9609752931902487

Epoch: 6| Step: 11
Training loss: 1.6982823610305786
Validation loss: 1.9581549193269463

Epoch: 6| Step: 12
Training loss: 2.409201145172119
Validation loss: 1.9674259590846237

Epoch: 6| Step: 13
Training loss: 1.554587721824646
Validation loss: 1.9747978371958579

Epoch: 124| Step: 0
Training loss: 1.7311115264892578
Validation loss: 1.969274018400459

Epoch: 6| Step: 1
Training loss: 3.0853490829467773
Validation loss: 1.9694779919039818

Epoch: 6| Step: 2
Training loss: 2.627713203430176
Validation loss: 1.9914895078187347

Epoch: 6| Step: 3
Training loss: 2.322324275970459
Validation loss: 1.9840073021509315

Epoch: 6| Step: 4
Training loss: 2.269082546234131
Validation loss: 2.014076869974854

Epoch: 6| Step: 5
Training loss: 1.357252836227417
Validation loss: 2.0111685029921995

Epoch: 6| Step: 6
Training loss: 2.024761199951172
Validation loss: 2.0138511580805623

Epoch: 6| Step: 7
Training loss: 1.6132724285125732
Validation loss: 2.0160950204377532

Epoch: 6| Step: 8
Training loss: 1.4130759239196777
Validation loss: 1.9957691648954987

Epoch: 6| Step: 9
Training loss: 2.029428482055664
Validation loss: 1.9891798778246808

Epoch: 6| Step: 10
Training loss: 2.231011390686035
Validation loss: 1.9676518004427674

Epoch: 6| Step: 11
Training loss: 0.8276113271713257
Validation loss: 1.9559901606652044

Epoch: 6| Step: 12
Training loss: 1.5788371562957764
Validation loss: 1.9540583023460962

Epoch: 6| Step: 13
Training loss: 1.3745522499084473
Validation loss: 1.9521979619097967

Epoch: 125| Step: 0
Training loss: 2.286879062652588
Validation loss: 1.960405558668157

Epoch: 6| Step: 1
Training loss: 1.8933507204055786
Validation loss: 1.9633362523971065

Epoch: 6| Step: 2
Training loss: 1.504158854484558
Validation loss: 1.9762046990856048

Epoch: 6| Step: 3
Training loss: 1.7930641174316406
Validation loss: 1.988607753989517

Epoch: 6| Step: 4
Training loss: 1.5065113306045532
Validation loss: 2.013502723427229

Epoch: 6| Step: 5
Training loss: 2.1382362842559814
Validation loss: 2.030438409056715

Epoch: 6| Step: 6
Training loss: 1.9649202823638916
Validation loss: 2.0436196455391507

Epoch: 6| Step: 7
Training loss: 2.3509602546691895
Validation loss: 2.05177882922593

Epoch: 6| Step: 8
Training loss: 1.0837570428848267
Validation loss: 2.029708085521575

Epoch: 6| Step: 9
Training loss: 1.8744401931762695
Validation loss: 1.992282941777219

Epoch: 6| Step: 10
Training loss: 2.490196704864502
Validation loss: 1.9824087286508212

Epoch: 6| Step: 11
Training loss: 2.019798755645752
Validation loss: 1.966545925345472

Epoch: 6| Step: 12
Training loss: 1.62921142578125
Validation loss: 1.9578057565996725

Epoch: 6| Step: 13
Training loss: 2.712233066558838
Validation loss: 1.981406129816527

Epoch: 126| Step: 0
Training loss: 1.580033779144287
Validation loss: 1.9850704772498018

Epoch: 6| Step: 1
Training loss: 1.7780430316925049
Validation loss: 2.0020446905525784

Epoch: 6| Step: 2
Training loss: 2.210886001586914
Validation loss: 2.0137745013801

Epoch: 6| Step: 3
Training loss: 2.0619609355926514
Validation loss: 2.0072581511671825

Epoch: 6| Step: 4
Training loss: 2.094546318054199
Validation loss: 1.9843940145225936

Epoch: 6| Step: 5
Training loss: 1.8028486967086792
Validation loss: 1.9799044850052043

Epoch: 6| Step: 6
Training loss: 1.7798712253570557
Validation loss: 1.9562596300596833

Epoch: 6| Step: 7
Training loss: 2.013160228729248
Validation loss: 1.9558050555567588

Epoch: 6| Step: 8
Training loss: 1.682948112487793
Validation loss: 1.9422905675826534

Epoch: 6| Step: 9
Training loss: 1.5742926597595215
Validation loss: 1.9571361067474529

Epoch: 6| Step: 10
Training loss: 2.113473415374756
Validation loss: 1.963698947301475

Epoch: 6| Step: 11
Training loss: 1.828827142715454
Validation loss: 1.9901276762767504

Epoch: 6| Step: 12
Training loss: 2.309223175048828
Validation loss: 2.0269496748524327

Epoch: 6| Step: 13
Training loss: 2.1129281520843506
Validation loss: 2.028062016733231

Epoch: 127| Step: 0
Training loss: 1.9787079095840454
Validation loss: 2.0205687194742183

Epoch: 6| Step: 1
Training loss: 2.302894115447998
Validation loss: 2.0407932778840423

Epoch: 6| Step: 2
Training loss: 1.9251196384429932
Validation loss: 2.013019266948905

Epoch: 6| Step: 3
Training loss: 2.249114751815796
Validation loss: 1.9931161775383899

Epoch: 6| Step: 4
Training loss: 1.7464972734451294
Validation loss: 1.976630639004451

Epoch: 6| Step: 5
Training loss: 1.7340621948242188
Validation loss: 1.9628443307774042

Epoch: 6| Step: 6
Training loss: 1.3921974897384644
Validation loss: 1.9842376837166407

Epoch: 6| Step: 7
Training loss: 1.6574766635894775
Validation loss: 1.997674495943131

Epoch: 6| Step: 8
Training loss: 1.3685637712478638
Validation loss: 2.026220134509507

Epoch: 6| Step: 9
Training loss: 2.082958698272705
Validation loss: 2.0404709846742692

Epoch: 6| Step: 10
Training loss: 2.4629926681518555
Validation loss: 2.022050457616006

Epoch: 6| Step: 11
Training loss: 2.004530906677246
Validation loss: 2.0170564100306523

Epoch: 6| Step: 12
Training loss: 2.2922208309173584
Validation loss: 1.9928040530091973

Epoch: 6| Step: 13
Training loss: 1.4786550998687744
Validation loss: 1.9901904085631013

Epoch: 128| Step: 0
Training loss: 2.49104642868042
Validation loss: 1.9800821940104167

Epoch: 6| Step: 1
Training loss: 1.6290462017059326
Validation loss: 1.9829748933033278

Epoch: 6| Step: 2
Training loss: 2.349980354309082
Validation loss: 1.9823334627254035

Epoch: 6| Step: 3
Training loss: 1.948257565498352
Validation loss: 1.9739872576088033

Epoch: 6| Step: 4
Training loss: 1.9950876235961914
Validation loss: 1.9786663465602423

Epoch: 6| Step: 5
Training loss: 2.156221628189087
Validation loss: 1.978374840110861

Epoch: 6| Step: 6
Training loss: 1.3865044116973877
Validation loss: 1.9844160438865743

Epoch: 6| Step: 7
Training loss: 2.1354174613952637
Validation loss: 1.9734992391319686

Epoch: 6| Step: 8
Training loss: 1.4846007823944092
Validation loss: 1.988937754784861

Epoch: 6| Step: 9
Training loss: 1.4260218143463135
Validation loss: 1.994864398433316

Epoch: 6| Step: 10
Training loss: 1.7412045001983643
Validation loss: 2.0150736403721634

Epoch: 6| Step: 11
Training loss: 1.7825692892074585
Validation loss: 2.02170790010883

Epoch: 6| Step: 12
Training loss: 2.190330982208252
Validation loss: 2.0333411360299714

Epoch: 6| Step: 13
Training loss: 1.444749355316162
Validation loss: 2.0074212281934676

Epoch: 129| Step: 0
Training loss: 2.632673740386963
Validation loss: 1.9858416741894138

Epoch: 6| Step: 1
Training loss: 2.1717615127563477
Validation loss: 1.9845729540753108

Epoch: 6| Step: 2
Training loss: 1.8203203678131104
Validation loss: 1.9895244529170375

Epoch: 6| Step: 3
Training loss: 1.6617892980575562
Validation loss: 1.964721482287171

Epoch: 6| Step: 4
Training loss: 2.271573543548584
Validation loss: 1.9841936544705463

Epoch: 6| Step: 5
Training loss: 2.3979403972625732
Validation loss: 1.958204819310096

Epoch: 6| Step: 6
Training loss: 1.2056231498718262
Validation loss: 1.950037552464393

Epoch: 6| Step: 7
Training loss: 1.5119975805282593
Validation loss: 1.9556293231184765

Epoch: 6| Step: 8
Training loss: 1.3900573253631592
Validation loss: 1.9535495927256923

Epoch: 6| Step: 9
Training loss: 1.4182782173156738
Validation loss: 1.948286138555055

Epoch: 6| Step: 10
Training loss: 1.3930197954177856
Validation loss: 1.9694832960764568

Epoch: 6| Step: 11
Training loss: 1.7960577011108398
Validation loss: 1.9765629499189314

Epoch: 6| Step: 12
Training loss: 1.6266834735870361
Validation loss: 1.9636637190336823

Epoch: 6| Step: 13
Training loss: 2.8241899013519287
Validation loss: 1.9647873011968469

Epoch: 130| Step: 0
Training loss: 2.008118152618408
Validation loss: 1.9596188478572394

Epoch: 6| Step: 1
Training loss: 1.5257030725479126
Validation loss: 1.9532488443518197

Epoch: 6| Step: 2
Training loss: 1.6837435960769653
Validation loss: 1.9401293185449415

Epoch: 6| Step: 3
Training loss: 1.6113029718399048
Validation loss: 1.9595926192498976

Epoch: 6| Step: 4
Training loss: 1.7943514585494995
Validation loss: 1.9634956211172125

Epoch: 6| Step: 5
Training loss: 1.7018378973007202
Validation loss: 1.9860789109301824

Epoch: 6| Step: 6
Training loss: 1.2652064561843872
Validation loss: 2.0225543117010467

Epoch: 6| Step: 7
Training loss: 1.233830451965332
Validation loss: 2.063348711177867

Epoch: 6| Step: 8
Training loss: 1.244466781616211
Validation loss: 2.0656085219434512

Epoch: 6| Step: 9
Training loss: 2.0868499279022217
Validation loss: 2.0816034809235604

Epoch: 6| Step: 10
Training loss: 2.2820987701416016
Validation loss: 2.062048490329455

Epoch: 6| Step: 11
Training loss: 2.3555099964141846
Validation loss: 2.056864335972776

Epoch: 6| Step: 12
Training loss: 2.6925814151763916
Validation loss: 2.0424858780317408

Epoch: 6| Step: 13
Training loss: 2.755063533782959
Validation loss: 2.0040404412054245

Epoch: 131| Step: 0
Training loss: 1.4749835729599
Validation loss: 1.9652851063718078

Epoch: 6| Step: 1
Training loss: 1.7073471546173096
Validation loss: 1.951328177605906

Epoch: 6| Step: 2
Training loss: 2.3086624145507812
Validation loss: 1.9676059779300485

Epoch: 6| Step: 3
Training loss: 1.2919974327087402
Validation loss: 1.989904757468931

Epoch: 6| Step: 4
Training loss: 2.1640682220458984
Validation loss: 1.9975235167370047

Epoch: 6| Step: 5
Training loss: 1.798977017402649
Validation loss: 2.025446630293323

Epoch: 6| Step: 6
Training loss: 1.996323585510254
Validation loss: 2.062316316430287

Epoch: 6| Step: 7
Training loss: 2.3657689094543457
Validation loss: 2.073297664683352

Epoch: 6| Step: 8
Training loss: 2.405855894088745
Validation loss: 2.058152914047241

Epoch: 6| Step: 9
Training loss: 1.6577558517456055
Validation loss: 2.0521620101826166

Epoch: 6| Step: 10
Training loss: 2.061328172683716
Validation loss: 2.034150820906444

Epoch: 6| Step: 11
Training loss: 1.3976857662200928
Validation loss: 2.019502150115146

Epoch: 6| Step: 12
Training loss: 2.0877633094787598
Validation loss: 1.9950760128677532

Epoch: 6| Step: 13
Training loss: 0.6818335652351379
Validation loss: 1.9613806855294011

Epoch: 132| Step: 0
Training loss: 1.812706470489502
Validation loss: 1.9364595592662852

Epoch: 6| Step: 1
Training loss: 2.056457996368408
Validation loss: 1.935326632633004

Epoch: 6| Step: 2
Training loss: 1.8734714984893799
Validation loss: 1.921790656223092

Epoch: 6| Step: 3
Training loss: 1.616183876991272
Validation loss: 1.9241508437741188

Epoch: 6| Step: 4
Training loss: 1.4770854711532593
Validation loss: 1.9156598070616364

Epoch: 6| Step: 5
Training loss: 2.169734001159668
Validation loss: 1.9250185553745558

Epoch: 6| Step: 6
Training loss: 2.0486602783203125
Validation loss: 1.9058917466030325

Epoch: 6| Step: 7
Training loss: 1.7078146934509277
Validation loss: 1.914412562565137

Epoch: 6| Step: 8
Training loss: 2.183065891265869
Validation loss: 1.9266719766842422

Epoch: 6| Step: 9
Training loss: 1.9594106674194336
Validation loss: 1.924165118125177

Epoch: 6| Step: 10
Training loss: 1.5862774848937988
Validation loss: 1.9262275259981874

Epoch: 6| Step: 11
Training loss: 1.229872226715088
Validation loss: 1.937811133682087

Epoch: 6| Step: 12
Training loss: 1.6847047805786133
Validation loss: 1.934092778031544

Epoch: 6| Step: 13
Training loss: 1.676068663597107
Validation loss: 1.9363310272975633

Epoch: 133| Step: 0
Training loss: 1.5865211486816406
Validation loss: 1.9366775123021935

Epoch: 6| Step: 1
Training loss: 1.9885286092758179
Validation loss: 1.934375286102295

Epoch: 6| Step: 2
Training loss: 2.672085762023926
Validation loss: 1.950758772511636

Epoch: 6| Step: 3
Training loss: 1.5434744358062744
Validation loss: 1.9621030258876022

Epoch: 6| Step: 4
Training loss: 1.2923245429992676
Validation loss: 1.9734547381759973

Epoch: 6| Step: 5
Training loss: 1.5783402919769287
Validation loss: 1.9742730176577004

Epoch: 6| Step: 6
Training loss: 1.8114310503005981
Validation loss: 1.9420580287133493

Epoch: 6| Step: 7
Training loss: 1.1514244079589844
Validation loss: 1.9295352966554704

Epoch: 6| Step: 8
Training loss: 1.876283049583435
Validation loss: 1.9188947639157694

Epoch: 6| Step: 9
Training loss: 1.843827247619629
Validation loss: 1.9049345600989558

Epoch: 6| Step: 10
Training loss: 1.9742944240570068
Validation loss: 1.9060674046957364

Epoch: 6| Step: 11
Training loss: 2.164602041244507
Validation loss: 1.9020076567126858

Epoch: 6| Step: 12
Training loss: 1.3589102029800415
Validation loss: 1.8900742684641192

Epoch: 6| Step: 13
Training loss: 2.263209342956543
Validation loss: 1.8968095010326755

Epoch: 134| Step: 0
Training loss: 1.7157150506973267
Validation loss: 1.9167958472364692

Epoch: 6| Step: 1
Training loss: 1.5253734588623047
Validation loss: 1.9296095191791494

Epoch: 6| Step: 2
Training loss: 2.027195453643799
Validation loss: 1.9385638262635918

Epoch: 6| Step: 3
Training loss: 1.7268353700637817
Validation loss: 1.965025177565954

Epoch: 6| Step: 4
Training loss: 1.7760045528411865
Validation loss: 1.9885477301894978

Epoch: 6| Step: 5
Training loss: 2.75144100189209
Validation loss: 1.9735933990888699

Epoch: 6| Step: 6
Training loss: 1.1734778881072998
Validation loss: 1.9736130955398723

Epoch: 6| Step: 7
Training loss: 1.956923007965088
Validation loss: 1.9789937439785208

Epoch: 6| Step: 8
Training loss: 1.1823443174362183
Validation loss: 1.9838400117812618

Epoch: 6| Step: 9
Training loss: 1.8156925439834595
Validation loss: 1.9833785077576995

Epoch: 6| Step: 10
Training loss: 1.8485140800476074
Validation loss: 1.9797484669634091

Epoch: 6| Step: 11
Training loss: 1.8689031600952148
Validation loss: 1.9714422174679336

Epoch: 6| Step: 12
Training loss: 2.00465726852417
Validation loss: 1.938573504006991

Epoch: 6| Step: 13
Training loss: 1.8918691873550415
Validation loss: 1.9249178389067292

Epoch: 135| Step: 0
Training loss: 2.028475284576416
Validation loss: 1.9220196816229052

Epoch: 6| Step: 1
Training loss: 1.440236210823059
Validation loss: 1.9333695186081754

Epoch: 6| Step: 2
Training loss: 1.7710109949111938
Validation loss: 1.9458278199677825

Epoch: 6| Step: 3
Training loss: 1.067179560661316
Validation loss: 1.9392441844427457

Epoch: 6| Step: 4
Training loss: 1.7063007354736328
Validation loss: 1.9527658954743417

Epoch: 6| Step: 5
Training loss: 2.04544734954834
Validation loss: 1.9439669437305902

Epoch: 6| Step: 6
Training loss: 1.2734088897705078
Validation loss: 1.9530785673408098

Epoch: 6| Step: 7
Training loss: 2.0639684200286865
Validation loss: 1.938066396661984

Epoch: 6| Step: 8
Training loss: 2.021859645843506
Validation loss: 1.9367889473515172

Epoch: 6| Step: 9
Training loss: 1.699873685836792
Validation loss: 1.941140183838465

Epoch: 6| Step: 10
Training loss: 1.9284255504608154
Validation loss: 1.9757469943774644

Epoch: 6| Step: 11
Training loss: 2.3642537593841553
Validation loss: 1.996130238297165

Epoch: 6| Step: 12
Training loss: 1.526961088180542
Validation loss: 2.0188418331966607

Epoch: 6| Step: 13
Training loss: 2.114145517349243
Validation loss: 2.0126329493779007

Epoch: 136| Step: 0
Training loss: 1.5458961725234985
Validation loss: 2.0087853862393286

Epoch: 6| Step: 1
Training loss: 1.7317156791687012
Validation loss: 1.9906117352106238

Epoch: 6| Step: 2
Training loss: 2.0256385803222656
Validation loss: 1.9557049530808643

Epoch: 6| Step: 3
Training loss: 1.790082573890686
Validation loss: 1.9534772237141926

Epoch: 6| Step: 4
Training loss: 1.7595608234405518
Validation loss: 1.9323122988465011

Epoch: 6| Step: 5
Training loss: 1.173412799835205
Validation loss: 1.9257464178146855

Epoch: 6| Step: 6
Training loss: 1.7920384407043457
Validation loss: 1.9092973278414818

Epoch: 6| Step: 7
Training loss: 2.0346603393554688
Validation loss: 1.904725133731801

Epoch: 6| Step: 8
Training loss: 2.4703731536865234
Validation loss: 1.9136538736281856

Epoch: 6| Step: 9
Training loss: 1.8163501024246216
Validation loss: 1.9308067675559752

Epoch: 6| Step: 10
Training loss: 1.8107682466506958
Validation loss: 1.9348773610207342

Epoch: 6| Step: 11
Training loss: 1.7354273796081543
Validation loss: 1.9279068080327844

Epoch: 6| Step: 12
Training loss: 1.761374831199646
Validation loss: 1.9258369809837752

Epoch: 6| Step: 13
Training loss: 1.1400675773620605
Validation loss: 1.9255446208420621

Epoch: 137| Step: 0
Training loss: 1.7934316396713257
Validation loss: 1.9481241805579073

Epoch: 6| Step: 1
Training loss: 1.658856987953186
Validation loss: 1.9303990794766335

Epoch: 6| Step: 2
Training loss: 1.5138652324676514
Validation loss: 1.930575882234881

Epoch: 6| Step: 3
Training loss: 1.7717584371566772
Validation loss: 1.9436473692617109

Epoch: 6| Step: 4
Training loss: 1.0428600311279297
Validation loss: 1.942958370331795

Epoch: 6| Step: 5
Training loss: 0.8359495997428894
Validation loss: 1.9562897400189472

Epoch: 6| Step: 6
Training loss: 2.679539203643799
Validation loss: 1.9601317144209338

Epoch: 6| Step: 7
Training loss: 2.5766913890838623
Validation loss: 1.9777222435961488

Epoch: 6| Step: 8
Training loss: 2.2287449836730957
Validation loss: 1.9885134158595916

Epoch: 6| Step: 9
Training loss: 1.7481175661087036
Validation loss: 2.0090482645137335

Epoch: 6| Step: 10
Training loss: 1.3603496551513672
Validation loss: 2.0262268640661754

Epoch: 6| Step: 11
Training loss: 2.2190723419189453
Validation loss: 2.0286411393073296

Epoch: 6| Step: 12
Training loss: 1.5844041109085083
Validation loss: 2.0325371949903426

Epoch: 6| Step: 13
Training loss: 1.1611415147781372
Validation loss: 2.044413197425104

Epoch: 138| Step: 0
Training loss: 2.0821683406829834
Validation loss: 2.0221516932210615

Epoch: 6| Step: 1
Training loss: 1.8249788284301758
Validation loss: 1.9944108609230287

Epoch: 6| Step: 2
Training loss: 1.3297213315963745
Validation loss: 1.949418710124108

Epoch: 6| Step: 3
Training loss: 1.7371160984039307
Validation loss: 1.9482483210102204

Epoch: 6| Step: 4
Training loss: 1.2763670682907104
Validation loss: 1.9465572757105674

Epoch: 6| Step: 5
Training loss: 2.108447551727295
Validation loss: 1.9312305245348202

Epoch: 6| Step: 6
Training loss: 1.538108229637146
Validation loss: 1.9585325846108057

Epoch: 6| Step: 7
Training loss: 1.9806056022644043
Validation loss: 1.9962267875671387

Epoch: 6| Step: 8
Training loss: 2.5689480304718018
Validation loss: 2.0096531055306874

Epoch: 6| Step: 9
Training loss: 1.7541778087615967
Validation loss: 1.9791937361481369

Epoch: 6| Step: 10
Training loss: 2.0178399085998535
Validation loss: 1.9614549054894397

Epoch: 6| Step: 11
Training loss: 1.767488718032837
Validation loss: 1.9432860369323401

Epoch: 6| Step: 12
Training loss: 1.6195638179779053
Validation loss: 1.9360377365542996

Epoch: 6| Step: 13
Training loss: 1.51405930519104
Validation loss: 1.9909902362413303

Epoch: 139| Step: 0
Training loss: 2.3707239627838135
Validation loss: 2.0648402116631948

Epoch: 6| Step: 1
Training loss: 2.2913107872009277
Validation loss: 2.124384467319776

Epoch: 6| Step: 2
Training loss: 1.7440770864486694
Validation loss: 2.1024300565001783

Epoch: 6| Step: 3
Training loss: 1.9674476385116577
Validation loss: 2.0716726805574153

Epoch: 6| Step: 4
Training loss: 1.359049916267395
Validation loss: 2.0238437434678436

Epoch: 6| Step: 5
Training loss: 1.688446283340454
Validation loss: 1.9978827225264681

Epoch: 6| Step: 6
Training loss: 1.4631621837615967
Validation loss: 1.9677860377937235

Epoch: 6| Step: 7
Training loss: 1.8334283828735352
Validation loss: 1.9392697183034753

Epoch: 6| Step: 8
Training loss: 1.4430570602416992
Validation loss: 1.946734841151904

Epoch: 6| Step: 9
Training loss: 1.9969844818115234
Validation loss: 1.9579209781462146

Epoch: 6| Step: 10
Training loss: 1.8440347909927368
Validation loss: 1.9661128905511671

Epoch: 6| Step: 11
Training loss: 1.6870923042297363
Validation loss: 1.9730439442460255

Epoch: 6| Step: 12
Training loss: 1.822317361831665
Validation loss: 1.964824027912591

Epoch: 6| Step: 13
Training loss: 2.066765546798706
Validation loss: 1.964930836872388

Epoch: 140| Step: 0
Training loss: 1.9745737314224243
Validation loss: 1.960460643614492

Epoch: 6| Step: 1
Training loss: 1.7625563144683838
Validation loss: 1.947097304046795

Epoch: 6| Step: 2
Training loss: 1.8903040885925293
Validation loss: 1.9422103999763407

Epoch: 6| Step: 3
Training loss: 1.7326269149780273
Validation loss: 1.9618304980698453

Epoch: 6| Step: 4
Training loss: 1.4615459442138672
Validation loss: 2.0260026839471634

Epoch: 6| Step: 5
Training loss: 2.1636765003204346
Validation loss: 2.0339594297511603

Epoch: 6| Step: 6
Training loss: 1.6332710981369019
Validation loss: 2.0552708371993034

Epoch: 6| Step: 7
Training loss: 1.9013421535491943
Validation loss: 2.034861123690041

Epoch: 6| Step: 8
Training loss: 1.0920742750167847
Validation loss: 2.0061248502423688

Epoch: 6| Step: 9
Training loss: 1.1270923614501953
Validation loss: 1.9746026480069725

Epoch: 6| Step: 10
Training loss: 1.6262497901916504
Validation loss: 1.9505435600075671

Epoch: 6| Step: 11
Training loss: 2.2101526260375977
Validation loss: 1.9350208415780017

Epoch: 6| Step: 12
Training loss: 2.0652081966400146
Validation loss: 1.9142559048950032

Epoch: 6| Step: 13
Training loss: 2.109870433807373
Validation loss: 1.912682189736315

Epoch: 141| Step: 0
Training loss: 1.6386663913726807
Validation loss: 1.9013873684790827

Epoch: 6| Step: 1
Training loss: 1.7525010108947754
Validation loss: 1.9174961197760798

Epoch: 6| Step: 2
Training loss: 1.310290813446045
Validation loss: 1.9068397270735873

Epoch: 6| Step: 3
Training loss: 1.2625776529312134
Validation loss: 1.908731045261506

Epoch: 6| Step: 4
Training loss: 1.7564287185668945
Validation loss: 1.8979055009862429

Epoch: 6| Step: 5
Training loss: 1.6372870206832886
Validation loss: 1.9176307801277406

Epoch: 6| Step: 6
Training loss: 1.7403364181518555
Validation loss: 1.9289270767601587

Epoch: 6| Step: 7
Training loss: 1.6923227310180664
Validation loss: 1.9803013481119627

Epoch: 6| Step: 8
Training loss: 1.889596939086914
Validation loss: 1.9943067360949773

Epoch: 6| Step: 9
Training loss: 2.0246267318725586
Validation loss: 2.013335459975786

Epoch: 6| Step: 10
Training loss: 2.0555925369262695
Validation loss: 2.0144882073966404

Epoch: 6| Step: 11
Training loss: 2.2939186096191406
Validation loss: 1.990415096282959

Epoch: 6| Step: 12
Training loss: 1.4656310081481934
Validation loss: 1.962196942298643

Epoch: 6| Step: 13
Training loss: 1.9722115993499756
Validation loss: 1.9712267216815744

Epoch: 142| Step: 0
Training loss: 1.6654047966003418
Validation loss: 1.9442786209044918

Epoch: 6| Step: 1
Training loss: 1.7238237857818604
Validation loss: 1.9530507326126099

Epoch: 6| Step: 2
Training loss: 1.7586830854415894
Validation loss: 1.9617583379950574

Epoch: 6| Step: 3
Training loss: 0.9683465361595154
Validation loss: 1.9671588764395764

Epoch: 6| Step: 4
Training loss: 1.2446691989898682
Validation loss: 1.954794717091386

Epoch: 6| Step: 5
Training loss: 2.4309463500976562
Validation loss: 1.979793462702023

Epoch: 6| Step: 6
Training loss: 1.8545464277267456
Validation loss: 1.972282484013547

Epoch: 6| Step: 7
Training loss: 1.3360475301742554
Validation loss: 1.9908462186013498

Epoch: 6| Step: 8
Training loss: 1.5207328796386719
Validation loss: 2.0047229233608452

Epoch: 6| Step: 9
Training loss: 2.5451247692108154
Validation loss: 1.9830641208156463

Epoch: 6| Step: 10
Training loss: 1.873259425163269
Validation loss: 1.960012032139686

Epoch: 6| Step: 11
Training loss: 1.3782284259796143
Validation loss: 1.9583037937841108

Epoch: 6| Step: 12
Training loss: 1.3894743919372559
Validation loss: 1.9384654593724076

Epoch: 6| Step: 13
Training loss: 2.425969123840332
Validation loss: 1.9375877072734218

Epoch: 143| Step: 0
Training loss: 2.2358322143554688
Validation loss: 1.9008709692185926

Epoch: 6| Step: 1
Training loss: 1.6289880275726318
Validation loss: 1.9029099710526005

Epoch: 6| Step: 2
Training loss: 1.6304066181182861
Validation loss: 1.8941113384821082

Epoch: 6| Step: 3
Training loss: 1.4681599140167236
Validation loss: 1.9024071642147597

Epoch: 6| Step: 4
Training loss: 1.7583043575286865
Validation loss: 1.9204470713933308

Epoch: 6| Step: 5
Training loss: 1.8791208267211914
Validation loss: 1.90486006839301

Epoch: 6| Step: 6
Training loss: 2.130221366882324
Validation loss: 1.9193375059353408

Epoch: 6| Step: 7
Training loss: 1.1476867198944092
Validation loss: 1.919911858856037

Epoch: 6| Step: 8
Training loss: 1.3825907707214355
Validation loss: 1.920582030409126

Epoch: 6| Step: 9
Training loss: 1.811518669128418
Validation loss: 1.919422443195056

Epoch: 6| Step: 10
Training loss: 1.4522638320922852
Validation loss: 1.934841767434151

Epoch: 6| Step: 11
Training loss: 2.177328109741211
Validation loss: 1.9520089472493818

Epoch: 6| Step: 12
Training loss: 1.207629919052124
Validation loss: 1.965512385932348

Epoch: 6| Step: 13
Training loss: 2.038376569747925
Validation loss: 1.9711527055309666

Epoch: 144| Step: 0
Training loss: 1.9473474025726318
Validation loss: 1.966646355967368

Epoch: 6| Step: 1
Training loss: 1.6514348983764648
Validation loss: 1.9931783624874648

Epoch: 6| Step: 2
Training loss: 1.781507968902588
Validation loss: 1.98981491468286

Epoch: 6| Step: 3
Training loss: 2.5788440704345703
Validation loss: 1.989893663314081

Epoch: 6| Step: 4
Training loss: 1.6068637371063232
Validation loss: 2.009399590953704

Epoch: 6| Step: 5
Training loss: 1.1566545963287354
Validation loss: 1.9885054121735275

Epoch: 6| Step: 6
Training loss: 2.6138405799865723
Validation loss: 1.9493332191180157

Epoch: 6| Step: 7
Training loss: 1.0349409580230713
Validation loss: 1.927328981379027

Epoch: 6| Step: 8
Training loss: 1.52290678024292
Validation loss: 1.9421805848357498

Epoch: 6| Step: 9
Training loss: 1.5713169574737549
Validation loss: 1.9791132788504324

Epoch: 6| Step: 10
Training loss: 1.3199512958526611
Validation loss: 2.0093399273451937

Epoch: 6| Step: 11
Training loss: 1.77409029006958
Validation loss: 2.024100221613402

Epoch: 6| Step: 12
Training loss: 1.6726748943328857
Validation loss: 1.9987727724095827

Epoch: 6| Step: 13
Training loss: 1.9638571739196777
Validation loss: 1.9529435788431475

Epoch: 145| Step: 0
Training loss: 1.9409127235412598
Validation loss: 1.9142807452909407

Epoch: 6| Step: 1
Training loss: 2.343998908996582
Validation loss: 1.941940199944281

Epoch: 6| Step: 2
Training loss: 2.0395960807800293
Validation loss: 1.9560117644648398

Epoch: 6| Step: 3
Training loss: 1.4054160118103027
Validation loss: 1.9628174484417003

Epoch: 6| Step: 4
Training loss: 1.8698028326034546
Validation loss: 1.951871310510943

Epoch: 6| Step: 5
Training loss: 1.4826762676239014
Validation loss: 1.917850540530297

Epoch: 6| Step: 6
Training loss: 1.5395923852920532
Validation loss: 1.907436058085452

Epoch: 6| Step: 7
Training loss: 1.276970386505127
Validation loss: 1.9169766018467564

Epoch: 6| Step: 8
Training loss: 1.372039556503296
Validation loss: 1.93296738337445

Epoch: 6| Step: 9
Training loss: 1.6744177341461182
Validation loss: 1.941999646925157

Epoch: 6| Step: 10
Training loss: 1.6799293756484985
Validation loss: 1.9560602313728743

Epoch: 6| Step: 11
Training loss: 1.3324344158172607
Validation loss: 1.9688480951452767

Epoch: 6| Step: 12
Training loss: 2.253699541091919
Validation loss: 1.9437248296635126

Epoch: 6| Step: 13
Training loss: 1.053702712059021
Validation loss: 1.9407482275398829

Epoch: 146| Step: 0
Training loss: 0.8145158886909485
Validation loss: 1.9355221333042267

Epoch: 6| Step: 1
Training loss: 1.3951599597930908
Validation loss: 1.9333913223717802

Epoch: 6| Step: 2
Training loss: 2.515453338623047
Validation loss: 1.9196818951637513

Epoch: 6| Step: 3
Training loss: 0.9700194597244263
Validation loss: 1.9198360622570079

Epoch: 6| Step: 4
Training loss: 1.8895127773284912
Validation loss: 1.9135076333117742

Epoch: 6| Step: 5
Training loss: 1.6383435726165771
Validation loss: 1.9158494036684754

Epoch: 6| Step: 6
Training loss: 1.2996221780776978
Validation loss: 1.9294600512391777

Epoch: 6| Step: 7
Training loss: 1.364139437675476
Validation loss: 1.9616916756476126

Epoch: 6| Step: 8
Training loss: 2.008579969406128
Validation loss: 1.960669755935669

Epoch: 6| Step: 9
Training loss: 1.7388701438903809
Validation loss: 1.9592969122753348

Epoch: 6| Step: 10
Training loss: 1.7209141254425049
Validation loss: 1.9487327401356032

Epoch: 6| Step: 11
Training loss: 1.7359726428985596
Validation loss: 1.9638056165428572

Epoch: 6| Step: 12
Training loss: 1.9483803510665894
Validation loss: 1.9628679585713211

Epoch: 6| Step: 13
Training loss: 1.7624952793121338
Validation loss: 1.954201864939864

Epoch: 147| Step: 0
Training loss: 1.8841612339019775
Validation loss: 1.9695756512303506

Epoch: 6| Step: 1
Training loss: 1.1538304090499878
Validation loss: 1.9731840792522635

Epoch: 6| Step: 2
Training loss: 1.0419986248016357
Validation loss: 1.960873430775058

Epoch: 6| Step: 3
Training loss: 1.6165225505828857
Validation loss: 1.9634675671977382

Epoch: 6| Step: 4
Training loss: 2.2528836727142334
Validation loss: 1.963192550084924

Epoch: 6| Step: 5
Training loss: 1.5235357284545898
Validation loss: 1.9440139057815715

Epoch: 6| Step: 6
Training loss: 1.4196546077728271
Validation loss: 1.9439716774930236

Epoch: 6| Step: 7
Training loss: 1.236799716949463
Validation loss: 1.9502061554180679

Epoch: 6| Step: 8
Training loss: 1.5925942659378052
Validation loss: 1.9570818114024338

Epoch: 6| Step: 9
Training loss: 1.1294316053390503
Validation loss: 1.976445767187303

Epoch: 6| Step: 10
Training loss: 1.5222784280776978
Validation loss: 1.977535334966516

Epoch: 6| Step: 11
Training loss: 1.406446099281311
Validation loss: 2.0104449256773917

Epoch: 6| Step: 12
Training loss: 2.1741414070129395
Validation loss: 1.9956864374940113

Epoch: 6| Step: 13
Training loss: 3.1442883014678955
Validation loss: 1.9858390541486843

Epoch: 148| Step: 0
Training loss: 1.8509316444396973
Validation loss: 1.9629552005439677

Epoch: 6| Step: 1
Training loss: 1.4535372257232666
Validation loss: 1.9440427031568301

Epoch: 6| Step: 2
Training loss: 1.5749781131744385
Validation loss: 1.9285264733017131

Epoch: 6| Step: 3
Training loss: 1.5307722091674805
Validation loss: 1.9234462989273893

Epoch: 6| Step: 4
Training loss: 1.5353020429611206
Validation loss: 1.897519439779302

Epoch: 6| Step: 5
Training loss: 1.8127901554107666
Validation loss: 1.895043102643823

Epoch: 6| Step: 6
Training loss: 1.900292158126831
Validation loss: 1.8943078838368899

Epoch: 6| Step: 7
Training loss: 1.6198872327804565
Validation loss: 1.8671787195308234

Epoch: 6| Step: 8
Training loss: 1.5133594274520874
Validation loss: 1.8707363015861922

Epoch: 6| Step: 9
Training loss: 1.4326789379119873
Validation loss: 1.8712218769135014

Epoch: 6| Step: 10
Training loss: 1.4580333232879639
Validation loss: 1.8762754137798021

Epoch: 6| Step: 11
Training loss: 1.9634400606155396
Validation loss: 1.8811068945033576

Epoch: 6| Step: 12
Training loss: 1.4411048889160156
Validation loss: 1.9070031412186161

Epoch: 6| Step: 13
Training loss: 1.6337189674377441
Validation loss: 1.9379938058955695

Epoch: 149| Step: 0
Training loss: 1.698330044746399
Validation loss: 1.9591837954777542

Epoch: 6| Step: 1
Training loss: 1.1025676727294922
Validation loss: 1.9764461184060702

Epoch: 6| Step: 2
Training loss: 1.571327567100525
Validation loss: 1.98902391874662

Epoch: 6| Step: 3
Training loss: 1.4603633880615234
Validation loss: 1.9863926031256234

Epoch: 6| Step: 4
Training loss: 1.6242599487304688
Validation loss: 1.9738803063669512

Epoch: 6| Step: 5
Training loss: 1.8931078910827637
Validation loss: 1.9565562330266482

Epoch: 6| Step: 6
Training loss: 1.3526618480682373
Validation loss: 1.9499281478184525

Epoch: 6| Step: 7
Training loss: 0.8407157063484192
Validation loss: 1.9333070785768571

Epoch: 6| Step: 8
Training loss: 1.4863426685333252
Validation loss: 1.9340084573274017

Epoch: 6| Step: 9
Training loss: 2.0438859462738037
Validation loss: 1.9243841491719729

Epoch: 6| Step: 10
Training loss: 2.0983316898345947
Validation loss: 1.931181602580573

Epoch: 6| Step: 11
Training loss: 1.2788678407669067
Validation loss: 1.9119355909286007

Epoch: 6| Step: 12
Training loss: 2.287186622619629
Validation loss: 1.9221236487870574

Epoch: 6| Step: 13
Training loss: 1.3695274591445923
Validation loss: 1.9312739256889588

Epoch: 150| Step: 0
Training loss: 1.4341192245483398
Validation loss: 1.9341081906390447

Epoch: 6| Step: 1
Training loss: 1.7745978832244873
Validation loss: 1.926508931703465

Epoch: 6| Step: 2
Training loss: 1.8662405014038086
Validation loss: 1.9416275165414298

Epoch: 6| Step: 3
Training loss: 1.529463291168213
Validation loss: 1.9672181657565537

Epoch: 6| Step: 4
Training loss: 1.0634950399398804
Validation loss: 1.9743132181065057

Epoch: 6| Step: 5
Training loss: 1.7659283876419067
Validation loss: 1.9736559685840402

Epoch: 6| Step: 6
Training loss: 1.6212882995605469
Validation loss: 1.980759504020855

Epoch: 6| Step: 7
Training loss: 2.4048686027526855
Validation loss: 1.981536703725015

Epoch: 6| Step: 8
Training loss: 2.001532554626465
Validation loss: 1.9884281696811799

Epoch: 6| Step: 9
Training loss: 1.450545310974121
Validation loss: 1.9760402607661423

Epoch: 6| Step: 10
Training loss: 0.9312077760696411
Validation loss: 1.9618143099610523

Epoch: 6| Step: 11
Training loss: 0.9505100250244141
Validation loss: 1.9521615325763662

Epoch: 6| Step: 12
Training loss: 1.3470139503479004
Validation loss: 1.9271566291009226

Epoch: 6| Step: 13
Training loss: 1.4941986799240112
Validation loss: 1.9224643835457422

Epoch: 151| Step: 0
Training loss: 1.33461332321167
Validation loss: 1.9305207114065848

Epoch: 6| Step: 1
Training loss: 1.7687575817108154
Validation loss: 1.938388519389655

Epoch: 6| Step: 2
Training loss: 2.2780466079711914
Validation loss: 1.9279559427692043

Epoch: 6| Step: 3
Training loss: 1.4945924282073975
Validation loss: 1.924615308802615

Epoch: 6| Step: 4
Training loss: 1.3512468338012695
Validation loss: 1.9181020721312492

Epoch: 6| Step: 5
Training loss: 2.2877049446105957
Validation loss: 1.9569197623960433

Epoch: 6| Step: 6
Training loss: 1.2572542428970337
Validation loss: 1.9540976632025935

Epoch: 6| Step: 7
Training loss: 1.5667227506637573
Validation loss: 1.972501052323208

Epoch: 6| Step: 8
Training loss: 1.685300350189209
Validation loss: 1.9735922646778885

Epoch: 6| Step: 9
Training loss: 1.390683889389038
Validation loss: 1.9761237457234373

Epoch: 6| Step: 10
Training loss: 1.3692240715026855
Validation loss: 1.967133827106927

Epoch: 6| Step: 11
Training loss: 1.147659420967102
Validation loss: 1.9534810102114113

Epoch: 6| Step: 12
Training loss: 1.4740076065063477
Validation loss: 1.9424587911175144

Epoch: 6| Step: 13
Training loss: 1.4073439836502075
Validation loss: 1.9012784957885742

Epoch: 152| Step: 0
Training loss: 1.9344501495361328
Validation loss: 1.8972252453527143

Epoch: 6| Step: 1
Training loss: 1.250565528869629
Validation loss: 1.9158711997411584

Epoch: 6| Step: 2
Training loss: 1.4275380373001099
Validation loss: 1.931994866299373

Epoch: 6| Step: 3
Training loss: 2.110400438308716
Validation loss: 1.9289157672594952

Epoch: 6| Step: 4
Training loss: 1.3963987827301025
Validation loss: 1.9450178005362069

Epoch: 6| Step: 5
Training loss: 0.886637806892395
Validation loss: 1.9565104271775933

Epoch: 6| Step: 6
Training loss: 1.0853445529937744
Validation loss: 1.9643827651136665

Epoch: 6| Step: 7
Training loss: 1.8331935405731201
Validation loss: 1.971465414570224

Epoch: 6| Step: 8
Training loss: 1.4483726024627686
Validation loss: 1.9727497985286098

Epoch: 6| Step: 9
Training loss: 1.1762326955795288
Validation loss: 1.9553950268735167

Epoch: 6| Step: 10
Training loss: 2.096092700958252
Validation loss: 1.934534683022448

Epoch: 6| Step: 11
Training loss: 2.113675832748413
Validation loss: 1.9222576079830047

Epoch: 6| Step: 12
Training loss: 1.2361242771148682
Validation loss: 1.912696744806023

Epoch: 6| Step: 13
Training loss: 1.1503214836120605
Validation loss: 1.9227239803601337

Epoch: 153| Step: 0
Training loss: 1.207871675491333
Validation loss: 1.9099338631476126

Epoch: 6| Step: 1
Training loss: 1.0992827415466309
Validation loss: 1.9072930325743973

Epoch: 6| Step: 2
Training loss: 1.327284336090088
Validation loss: 1.9059165549534622

Epoch: 6| Step: 3
Training loss: 1.4364769458770752
Validation loss: 1.9178853932247366

Epoch: 6| Step: 4
Training loss: 1.5074183940887451
Validation loss: 1.9271437403976277

Epoch: 6| Step: 5
Training loss: 1.6664907932281494
Validation loss: 1.9461092948913574

Epoch: 6| Step: 6
Training loss: 1.7186630964279175
Validation loss: 1.9280507218453191

Epoch: 6| Step: 7
Training loss: 1.3589608669281006
Validation loss: 1.9070694792655207

Epoch: 6| Step: 8
Training loss: 1.1905536651611328
Validation loss: 1.9309088337805964

Epoch: 6| Step: 9
Training loss: 2.328965187072754
Validation loss: 1.9307760666775446

Epoch: 6| Step: 10
Training loss: 1.537390947341919
Validation loss: 1.9329246628669001

Epoch: 6| Step: 11
Training loss: 1.5500853061676025
Validation loss: 1.9233164556564823

Epoch: 6| Step: 12
Training loss: 1.4608055353164673
Validation loss: 1.9162684243212464

Epoch: 6| Step: 13
Training loss: 1.4646408557891846
Validation loss: 1.930826146115539

Epoch: 154| Step: 0
Training loss: 1.4786200523376465
Validation loss: 1.9270461246531496

Epoch: 6| Step: 1
Training loss: 1.5824095010757446
Validation loss: 1.9065576009852911

Epoch: 6| Step: 2
Training loss: 1.9986774921417236
Validation loss: 1.9227532340634255

Epoch: 6| Step: 3
Training loss: 1.6423956155776978
Validation loss: 1.927223377330329

Epoch: 6| Step: 4
Training loss: 1.5418838262557983
Validation loss: 1.9429784000560801

Epoch: 6| Step: 5
Training loss: 1.153275728225708
Validation loss: 1.927921095202046

Epoch: 6| Step: 6
Training loss: 1.063083529472351
Validation loss: 1.940743464295582

Epoch: 6| Step: 7
Training loss: 1.552790641784668
Validation loss: 1.9344893937469811

Epoch: 6| Step: 8
Training loss: 1.5975370407104492
Validation loss: 1.9346130355711906

Epoch: 6| Step: 9
Training loss: 1.4434531927108765
Validation loss: 1.9556569527554255

Epoch: 6| Step: 10
Training loss: 0.9636256694793701
Validation loss: 1.95451856172213

Epoch: 6| Step: 11
Training loss: 1.7125341892242432
Validation loss: 1.9642749678704046

Epoch: 6| Step: 12
Training loss: 1.551274061203003
Validation loss: 1.9797652408640871

Epoch: 6| Step: 13
Training loss: 1.0381040573120117
Validation loss: 1.9575553478733185

Epoch: 155| Step: 0
Training loss: 1.4835636615753174
Validation loss: 1.9417359495675692

Epoch: 6| Step: 1
Training loss: 1.223522663116455
Validation loss: 1.9286977129597818

Epoch: 6| Step: 2
Training loss: 0.9407227039337158
Validation loss: 1.9262398712096676

Epoch: 6| Step: 3
Training loss: 1.5391535758972168
Validation loss: 1.929537707759488

Epoch: 6| Step: 4
Training loss: 1.8823224306106567
Validation loss: 1.939493727940385

Epoch: 6| Step: 5
Training loss: 1.6324849128723145
Validation loss: 1.9337635450465704

Epoch: 6| Step: 6
Training loss: 1.4386570453643799
Validation loss: 1.942719687697708

Epoch: 6| Step: 7
Training loss: 1.0513839721679688
Validation loss: 1.9442319203448553

Epoch: 6| Step: 8
Training loss: 1.6337422132492065
Validation loss: 1.9422477676022438

Epoch: 6| Step: 9
Training loss: 1.3361966609954834
Validation loss: 1.9133150910818448

Epoch: 6| Step: 10
Training loss: 1.4530067443847656
Validation loss: 1.918095439992925

Epoch: 6| Step: 11
Training loss: 1.4828927516937256
Validation loss: 1.9111663705559188

Epoch: 6| Step: 12
Training loss: 1.9058926105499268
Validation loss: 1.895431008390201

Epoch: 6| Step: 13
Training loss: 1.4841426610946655
Validation loss: 1.8971305983040923

Epoch: 156| Step: 0
Training loss: 1.41304612159729
Validation loss: 1.9005330480555052

Epoch: 6| Step: 1
Training loss: 1.1561239957809448
Validation loss: 1.9531555996146253

Epoch: 6| Step: 2
Training loss: 1.092739462852478
Validation loss: 1.9689575869549987

Epoch: 6| Step: 3
Training loss: 1.830155372619629
Validation loss: 1.9530103591180616

Epoch: 6| Step: 4
Training loss: 1.0884325504302979
Validation loss: 1.9302791549313454

Epoch: 6| Step: 5
Training loss: 1.4231740236282349
Validation loss: 1.924261469994822

Epoch: 6| Step: 6
Training loss: 1.5635621547698975
Validation loss: 1.9021775286684754

Epoch: 6| Step: 7
Training loss: 1.9739205837249756
Validation loss: 1.8914145423519997

Epoch: 6| Step: 8
Training loss: 1.7352261543273926
Validation loss: 1.9006098778017106

Epoch: 6| Step: 9
Training loss: 1.607285737991333
Validation loss: 1.895920830388223

Epoch: 6| Step: 10
Training loss: 1.3353618383407593
Validation loss: 1.9135835965474446

Epoch: 6| Step: 11
Training loss: 1.2346606254577637
Validation loss: 1.9303182248146302

Epoch: 6| Step: 12
Training loss: 1.6115347146987915
Validation loss: 1.943436554683152

Epoch: 6| Step: 13
Training loss: 2.15181303024292
Validation loss: 1.959628661473592

Epoch: 157| Step: 0
Training loss: 1.463008165359497
Validation loss: 1.9543729623158772

Epoch: 6| Step: 1
Training loss: 1.5165057182312012
Validation loss: 1.9589407290181806

Epoch: 6| Step: 2
Training loss: 1.8741148710250854
Validation loss: 1.957730544510708

Epoch: 6| Step: 3
Training loss: 1.479602336883545
Validation loss: 1.942842593757055

Epoch: 6| Step: 4
Training loss: 1.5802868604660034
Validation loss: 1.9339770501659763

Epoch: 6| Step: 5
Training loss: 1.515660285949707
Validation loss: 1.9447087382757535

Epoch: 6| Step: 6
Training loss: 1.1013375520706177
Validation loss: 1.9392101405769266

Epoch: 6| Step: 7
Training loss: 1.5834418535232544
Validation loss: 1.9321480976637972

Epoch: 6| Step: 8
Training loss: 1.4837517738342285
Validation loss: 1.945227474294683

Epoch: 6| Step: 9
Training loss: 1.4805355072021484
Validation loss: 1.9359949801557808

Epoch: 6| Step: 10
Training loss: 1.2687451839447021
Validation loss: 1.9244670124464138

Epoch: 6| Step: 11
Training loss: 1.3454535007476807
Validation loss: 1.9409595868920768

Epoch: 6| Step: 12
Training loss: 1.136357307434082
Validation loss: 1.9444232807364514

Epoch: 6| Step: 13
Training loss: 0.9540343880653381
Validation loss: 1.9899757959509408

Epoch: 158| Step: 0
Training loss: 1.7254565954208374
Validation loss: 1.9860336934366534

Epoch: 6| Step: 1
Training loss: 1.6374144554138184
Validation loss: 2.0046931389839417

Epoch: 6| Step: 2
Training loss: 1.5867528915405273
Validation loss: 2.0098884105682373

Epoch: 6| Step: 3
Training loss: 0.996216356754303
Validation loss: 1.9795916439384542

Epoch: 6| Step: 4
Training loss: 1.2492389678955078
Validation loss: 1.9564730057152369

Epoch: 6| Step: 5
Training loss: 1.5958077907562256
Validation loss: 1.938714074832137

Epoch: 6| Step: 6
Training loss: 0.8208711743354797
Validation loss: 1.9120940264835153

Epoch: 6| Step: 7
Training loss: 1.4179348945617676
Validation loss: 1.9401679885002874

Epoch: 6| Step: 8
Training loss: 1.5827089548110962
Validation loss: 1.9286880134254374

Epoch: 6| Step: 9
Training loss: 1.5647525787353516
Validation loss: 1.927716439770114

Epoch: 6| Step: 10
Training loss: 1.3870261907577515
Validation loss: 1.903759874323363

Epoch: 6| Step: 11
Training loss: 1.371059536933899
Validation loss: 1.8958804235663465

Epoch: 6| Step: 12
Training loss: 1.5846567153930664
Validation loss: 1.8703025540997904

Epoch: 6| Step: 13
Training loss: 1.2519056797027588
Validation loss: 1.8685243411730694

Epoch: 159| Step: 0
Training loss: 1.3150241374969482
Validation loss: 1.902786704801744

Epoch: 6| Step: 1
Training loss: 1.5615999698638916
Validation loss: 1.9010474912581905

Epoch: 6| Step: 2
Training loss: 1.270900011062622
Validation loss: 1.946403677745532

Epoch: 6| Step: 3
Training loss: 1.6274808645248413
Validation loss: 1.947701108071112

Epoch: 6| Step: 4
Training loss: 1.2027442455291748
Validation loss: 1.9378477860522527

Epoch: 6| Step: 5
Training loss: 1.3277230262756348
Validation loss: 1.920836966524842

Epoch: 6| Step: 6
Training loss: 1.7081661224365234
Validation loss: 1.9074324369430542

Epoch: 6| Step: 7
Training loss: 1.2792320251464844
Validation loss: 1.882103681564331

Epoch: 6| Step: 8
Training loss: 2.0014443397521973
Validation loss: 1.8921356560081564

Epoch: 6| Step: 9
Training loss: 1.051000952720642
Validation loss: 1.9035104064531223

Epoch: 6| Step: 10
Training loss: 1.0479456186294556
Validation loss: 1.9170985811500139

Epoch: 6| Step: 11
Training loss: 1.4619419574737549
Validation loss: 1.9332519474849905

Epoch: 6| Step: 12
Training loss: 1.3272703886032104
Validation loss: 1.9481408262765536

Epoch: 6| Step: 13
Training loss: 1.921547532081604
Validation loss: 1.9544886273722495

Epoch: 160| Step: 0
Training loss: 1.083772897720337
Validation loss: 1.9600535361997542

Epoch: 6| Step: 1
Training loss: 1.4266719818115234
Validation loss: 1.9816742686815159

Epoch: 6| Step: 2
Training loss: 1.333204984664917
Validation loss: 1.984001313486407

Epoch: 6| Step: 3
Training loss: 1.2610840797424316
Validation loss: 2.0184361524479364

Epoch: 6| Step: 4
Training loss: 1.2925745248794556
Validation loss: 1.9932641444667694

Epoch: 6| Step: 5
Training loss: 1.8230981826782227
Validation loss: 1.9827340161928566

Epoch: 6| Step: 6
Training loss: 1.1588959693908691
Validation loss: 1.9636904860055575

Epoch: 6| Step: 7
Training loss: 1.8356188535690308
Validation loss: 1.9435453466189805

Epoch: 6| Step: 8
Training loss: 1.3276007175445557
Validation loss: 1.9225331762785554

Epoch: 6| Step: 9
Training loss: 1.6059093475341797
Validation loss: 1.8897980182401595

Epoch: 6| Step: 10
Training loss: 0.9738406538963318
Validation loss: 1.863303017872636

Epoch: 6| Step: 11
Training loss: 1.4453376531600952
Validation loss: 1.853332442622031

Epoch: 6| Step: 12
Training loss: 1.4049043655395508
Validation loss: 1.862192105221492

Epoch: 6| Step: 13
Training loss: 0.8512544631958008
Validation loss: 1.8601065451099026

Epoch: 161| Step: 0
Training loss: 0.9230116009712219
Validation loss: 1.8503042523578932

Epoch: 6| Step: 1
Training loss: 1.970442533493042
Validation loss: 1.88419045043248

Epoch: 6| Step: 2
Training loss: 1.0943288803100586
Validation loss: 1.8777628893493323

Epoch: 6| Step: 3
Training loss: 1.3006095886230469
Validation loss: 1.870606457033465

Epoch: 6| Step: 4
Training loss: 1.6896042823791504
Validation loss: 1.8768713884456183

Epoch: 6| Step: 5
Training loss: 1.8174498081207275
Validation loss: 1.8591454375174739

Epoch: 6| Step: 6
Training loss: 1.0009136199951172
Validation loss: 1.8646509801187823

Epoch: 6| Step: 7
Training loss: 1.4352612495422363
Validation loss: 1.8801693070319392

Epoch: 6| Step: 8
Training loss: 0.9797754287719727
Validation loss: 1.893083151950631

Epoch: 6| Step: 9
Training loss: 1.08933424949646
Validation loss: 1.9173010754328903

Epoch: 6| Step: 10
Training loss: 1.6187328100204468
Validation loss: 1.9280117737349642

Epoch: 6| Step: 11
Training loss: 1.5761816501617432
Validation loss: 1.933143243994764

Epoch: 6| Step: 12
Training loss: 1.8748741149902344
Validation loss: 1.9555108265210224

Epoch: 6| Step: 13
Training loss: 1.0492603778839111
Validation loss: 1.9516166346047514

Epoch: 162| Step: 0
Training loss: 1.147429347038269
Validation loss: 1.9564328706392677

Epoch: 6| Step: 1
Training loss: 1.7940994501113892
Validation loss: 1.9426213925884617

Epoch: 6| Step: 2
Training loss: 1.6203265190124512
Validation loss: 1.9358608953414425

Epoch: 6| Step: 3
Training loss: 1.1890037059783936
Validation loss: 1.9070803247472292

Epoch: 6| Step: 4
Training loss: 1.8219072818756104
Validation loss: 1.882161214787473

Epoch: 6| Step: 5
Training loss: 1.8050264120101929
Validation loss: 1.8663711188941874

Epoch: 6| Step: 6
Training loss: 1.5542397499084473
Validation loss: 1.8565481349986086

Epoch: 6| Step: 7
Training loss: 0.9619389176368713
Validation loss: 1.8398607687283588

Epoch: 6| Step: 8
Training loss: 1.6442291736602783
Validation loss: 1.8633445962782829

Epoch: 6| Step: 9
Training loss: 1.2637238502502441
Validation loss: 1.8597014847622122

Epoch: 6| Step: 10
Training loss: 1.335803508758545
Validation loss: 1.891276131394089

Epoch: 6| Step: 11
Training loss: 1.4171056747436523
Validation loss: 1.9173998332792712

Epoch: 6| Step: 12
Training loss: 0.9914913177490234
Validation loss: 1.9384833548658638

Epoch: 6| Step: 13
Training loss: 1.3704338073730469
Validation loss: 1.9557061964465725

Epoch: 163| Step: 0
Training loss: 1.7393760681152344
Validation loss: 1.9939770134546424

Epoch: 6| Step: 1
Training loss: 1.395049810409546
Validation loss: 1.9872236098012617

Epoch: 6| Step: 2
Training loss: 1.7510888576507568
Validation loss: 1.9931372211825462

Epoch: 6| Step: 3
Training loss: 1.2262392044067383
Validation loss: 2.0093687888114684

Epoch: 6| Step: 4
Training loss: 0.8054119348526001
Validation loss: 1.9852679647425169

Epoch: 6| Step: 5
Training loss: 1.8254148960113525
Validation loss: 1.9787174629908737

Epoch: 6| Step: 6
Training loss: 1.8359419107437134
Validation loss: 1.9574504898440452

Epoch: 6| Step: 7
Training loss: 1.2878326177597046
Validation loss: 1.9714549446618685

Epoch: 6| Step: 8
Training loss: 1.2248311042785645
Validation loss: 1.9364059355951124

Epoch: 6| Step: 9
Training loss: 1.472822666168213
Validation loss: 1.8973242428994948

Epoch: 6| Step: 10
Training loss: 1.2638967037200928
Validation loss: 1.8724054828766854

Epoch: 6| Step: 11
Training loss: 1.2990095615386963
Validation loss: 1.8524975174216813

Epoch: 6| Step: 12
Training loss: 1.5173163414001465
Validation loss: 1.827820650992855

Epoch: 6| Step: 13
Training loss: 1.5910165309906006
Validation loss: 1.8148311902117986

Epoch: 164| Step: 0
Training loss: 1.489159107208252
Validation loss: 1.8125496577191096

Epoch: 6| Step: 1
Training loss: 1.6240663528442383
Validation loss: 1.8509206566759335

Epoch: 6| Step: 2
Training loss: 1.8290514945983887
Validation loss: 1.893929253342331

Epoch: 6| Step: 3
Training loss: 1.066711187362671
Validation loss: 1.8910868731878137

Epoch: 6| Step: 4
Training loss: 1.2172904014587402
Validation loss: 1.8987825006567023

Epoch: 6| Step: 5
Training loss: 1.369787335395813
Validation loss: 1.8778826254670338

Epoch: 6| Step: 6
Training loss: 1.5939327478408813
Validation loss: 1.859392563501994

Epoch: 6| Step: 7
Training loss: 0.7475970983505249
Validation loss: 1.840760075917808

Epoch: 6| Step: 8
Training loss: 1.270066261291504
Validation loss: 1.876872803575249

Epoch: 6| Step: 9
Training loss: 1.7085118293762207
Validation loss: 1.8774010109645065

Epoch: 6| Step: 10
Training loss: 1.7355371713638306
Validation loss: 1.9021355259803034

Epoch: 6| Step: 11
Training loss: 1.1479370594024658
Validation loss: 1.9006140347450011

Epoch: 6| Step: 12
Training loss: 1.2098236083984375
Validation loss: 1.9039172177673669

Epoch: 6| Step: 13
Training loss: 1.9047170877456665
Validation loss: 1.8982498261236376

Epoch: 165| Step: 0
Training loss: 1.299207329750061
Validation loss: 1.8969263440819197

Epoch: 6| Step: 1
Training loss: 1.4103291034698486
Validation loss: 1.9080703053423154

Epoch: 6| Step: 2
Training loss: 1.2566413879394531
Validation loss: 1.8908262380989649

Epoch: 6| Step: 3
Training loss: 1.3506109714508057
Validation loss: 1.897573189068866

Epoch: 6| Step: 4
Training loss: 1.303331732749939
Validation loss: 1.9028621283910607

Epoch: 6| Step: 5
Training loss: 1.4697391986846924
Validation loss: 1.9259501259814027

Epoch: 6| Step: 6
Training loss: 1.1183298826217651
Validation loss: 1.9308774432828348

Epoch: 6| Step: 7
Training loss: 0.8880304098129272
Validation loss: 1.9103351639163109

Epoch: 6| Step: 8
Training loss: 1.1780657768249512
Validation loss: 1.8770437317509805

Epoch: 6| Step: 9
Training loss: 1.1220381259918213
Validation loss: 1.8522427005152549

Epoch: 6| Step: 10
Training loss: 1.7489370107650757
Validation loss: 1.865836557521615

Epoch: 6| Step: 11
Training loss: 1.0194075107574463
Validation loss: 1.871661921983124

Epoch: 6| Step: 12
Training loss: 1.5745692253112793
Validation loss: 1.865217040943843

Epoch: 6| Step: 13
Training loss: 2.401005268096924
Validation loss: 1.8653725398484098

Epoch: 166| Step: 0
Training loss: 1.2469727993011475
Validation loss: 1.83929197249874

Epoch: 6| Step: 1
Training loss: 1.4958646297454834
Validation loss: 1.8501394461559992

Epoch: 6| Step: 2
Training loss: 1.365455150604248
Validation loss: 1.857258157063556

Epoch: 6| Step: 3
Training loss: 0.8561305403709412
Validation loss: 1.8812089991825882

Epoch: 6| Step: 4
Training loss: 1.8554373979568481
Validation loss: 1.8828753194501322

Epoch: 6| Step: 5
Training loss: 0.7753587365150452
Validation loss: 1.8979761754312823

Epoch: 6| Step: 6
Training loss: 0.9539223909378052
Validation loss: 1.8944418763601651

Epoch: 6| Step: 7
Training loss: 1.3866444826126099
Validation loss: 1.8817405136682654

Epoch: 6| Step: 8
Training loss: 1.1296398639678955
Validation loss: 1.8821066515420073

Epoch: 6| Step: 9
Training loss: 1.444946050643921
Validation loss: 1.8756792558136808

Epoch: 6| Step: 10
Training loss: 1.1556575298309326
Validation loss: 1.90137239169049

Epoch: 6| Step: 11
Training loss: 2.084404945373535
Validation loss: 1.9053546049261605

Epoch: 6| Step: 12
Training loss: 0.6556499004364014
Validation loss: 1.9114022075489003

Epoch: 6| Step: 13
Training loss: 2.0030717849731445
Validation loss: 1.9062353769938152

Epoch: 167| Step: 0
Training loss: 1.4954028129577637
Validation loss: 1.888305123134326

Epoch: 6| Step: 1
Training loss: 0.8045758008956909
Validation loss: 1.898257447827247

Epoch: 6| Step: 2
Training loss: 1.0066142082214355
Validation loss: 1.88635806627171

Epoch: 6| Step: 3
Training loss: 1.3320460319519043
Validation loss: 1.8801275107168383

Epoch: 6| Step: 4
Training loss: 1.4588565826416016
Validation loss: 1.887073564273055

Epoch: 6| Step: 5
Training loss: 1.9870989322662354
Validation loss: 1.8707024166660924

Epoch: 6| Step: 6
Training loss: 1.1456843614578247
Validation loss: 1.8608782624685636

Epoch: 6| Step: 7
Training loss: 1.284981369972229
Validation loss: 1.856047216282096

Epoch: 6| Step: 8
Training loss: 0.9608006477355957
Validation loss: 1.8496814620110296

Epoch: 6| Step: 9
Training loss: 1.4249722957611084
Validation loss: 1.863124260338404

Epoch: 6| Step: 10
Training loss: 0.9106236696243286
Validation loss: 1.8554367096193376

Epoch: 6| Step: 11
Training loss: 1.6574902534484863
Validation loss: 1.871384875107837

Epoch: 6| Step: 12
Training loss: 1.1412932872772217
Validation loss: 1.8993578290426603

Epoch: 6| Step: 13
Training loss: 1.0046098232269287
Validation loss: 1.8803150346202235

Epoch: 168| Step: 0
Training loss: 1.1614898443222046
Validation loss: 1.8872488301287416

Epoch: 6| Step: 1
Training loss: 1.6438134908676147
Validation loss: 1.888953362741778

Epoch: 6| Step: 2
Training loss: 1.3886539936065674
Validation loss: 1.914990596873786

Epoch: 6| Step: 3
Training loss: 1.2236273288726807
Validation loss: 1.9250313466595066

Epoch: 6| Step: 4
Training loss: 1.1261861324310303
Validation loss: 1.9432241224473523

Epoch: 6| Step: 5
Training loss: 1.4019955396652222
Validation loss: 1.9529978690608856

Epoch: 6| Step: 6
Training loss: 1.2922409772872925
Validation loss: 1.9469891825029928

Epoch: 6| Step: 7
Training loss: 1.476304292678833
Validation loss: 1.9528850099091888

Epoch: 6| Step: 8
Training loss: 0.7657109498977661
Validation loss: 1.9675253142592728

Epoch: 6| Step: 9
Training loss: 1.4004721641540527
Validation loss: 1.963993246837329

Epoch: 6| Step: 10
Training loss: 1.581162929534912
Validation loss: 1.946155148167764

Epoch: 6| Step: 11
Training loss: 1.0821094512939453
Validation loss: 1.948613469318677

Epoch: 6| Step: 12
Training loss: 0.8605762720108032
Validation loss: 1.9282029956899664

Epoch: 6| Step: 13
Training loss: 1.058719277381897
Validation loss: 1.9221416698989047

Epoch: 169| Step: 0
Training loss: 1.4477771520614624
Validation loss: 1.9068352278842722

Epoch: 6| Step: 1
Training loss: 0.7076388001441956
Validation loss: 1.8994694473922893

Epoch: 6| Step: 2
Training loss: 0.8039043545722961
Validation loss: 1.9284247288139917

Epoch: 6| Step: 3
Training loss: 1.1149859428405762
Validation loss: 1.9154200335984588

Epoch: 6| Step: 4
Training loss: 0.9180560111999512
Validation loss: 1.9017350981312413

Epoch: 6| Step: 5
Training loss: 1.0992766618728638
Validation loss: 1.8974812338429112

Epoch: 6| Step: 6
Training loss: 1.8176199197769165
Validation loss: 1.892272154490153

Epoch: 6| Step: 7
Training loss: 1.951303243637085
Validation loss: 1.8711012512124994

Epoch: 6| Step: 8
Training loss: 1.3156665563583374
Validation loss: 1.8601656139537852

Epoch: 6| Step: 9
Training loss: 1.2940113544464111
Validation loss: 1.845607929332282

Epoch: 6| Step: 10
Training loss: 1.0072112083435059
Validation loss: 1.846340892135456

Epoch: 6| Step: 11
Training loss: 1.4256396293640137
Validation loss: 1.8603129092083182

Epoch: 6| Step: 12
Training loss: 1.0129649639129639
Validation loss: 1.884200624240342

Epoch: 6| Step: 13
Training loss: 1.6475355625152588
Validation loss: 1.890217201684111

Epoch: 170| Step: 0
Training loss: 1.556208610534668
Validation loss: 1.882508203547488

Epoch: 6| Step: 1
Training loss: 1.62926185131073
Validation loss: 1.898840896544918

Epoch: 6| Step: 2
Training loss: 1.7754430770874023
Validation loss: 1.9042441101484402

Epoch: 6| Step: 3
Training loss: 1.7913994789123535
Validation loss: 1.893122729434762

Epoch: 6| Step: 4
Training loss: 0.6268486976623535
Validation loss: 1.8938992664378176

Epoch: 6| Step: 5
Training loss: 1.2036561965942383
Validation loss: 1.8931039161579584

Epoch: 6| Step: 6
Training loss: 1.086674451828003
Validation loss: 1.910120560276893

Epoch: 6| Step: 7
Training loss: 1.251383900642395
Validation loss: 1.909147798374135

Epoch: 6| Step: 8
Training loss: 1.5992071628570557
Validation loss: 1.917351786808301

Epoch: 6| Step: 9
Training loss: 0.9910410046577454
Validation loss: 1.9207087280929729

Epoch: 6| Step: 10
Training loss: 0.5159523487091064
Validation loss: 1.935788328929614

Epoch: 6| Step: 11
Training loss: 0.848400890827179
Validation loss: 1.9044543837988248

Epoch: 6| Step: 12
Training loss: 0.8645466566085815
Validation loss: 1.9061292755988337

Epoch: 6| Step: 13
Training loss: 0.9685678482055664
Validation loss: 1.9019327138059883

Epoch: 171| Step: 0
Training loss: 1.0856609344482422
Validation loss: 1.8825975887237056

Epoch: 6| Step: 1
Training loss: 1.7318205833435059
Validation loss: 1.884827753548981

Epoch: 6| Step: 2
Training loss: 1.1330291032791138
Validation loss: 1.878176510974925

Epoch: 6| Step: 3
Training loss: 1.2751586437225342
Validation loss: 1.880019877546577

Epoch: 6| Step: 4
Training loss: 0.5665830373764038
Validation loss: 1.8478443802043956

Epoch: 6| Step: 5
Training loss: 1.602281093597412
Validation loss: 1.8462877606832853

Epoch: 6| Step: 6
Training loss: 1.2135674953460693
Validation loss: 1.8724891985616376

Epoch: 6| Step: 7
Training loss: 1.2599022388458252
Validation loss: 1.8507443538276098

Epoch: 6| Step: 8
Training loss: 1.3883517980575562
Validation loss: 1.8522053149438673

Epoch: 6| Step: 9
Training loss: 1.1706148386001587
Validation loss: 1.8721712584136634

Epoch: 6| Step: 10
Training loss: 1.16486394405365
Validation loss: 1.8551297674896896

Epoch: 6| Step: 11
Training loss: 0.6333783864974976
Validation loss: 1.86557718887124

Epoch: 6| Step: 12
Training loss: 1.4062162637710571
Validation loss: 1.8713186133292414

Epoch: 6| Step: 13
Training loss: 1.1011971235275269
Validation loss: 1.9049363290109942

Epoch: 172| Step: 0
Training loss: 1.2235498428344727
Validation loss: 1.8878743238346551

Epoch: 6| Step: 1
Training loss: 1.0809588432312012
Validation loss: 1.907962086380169

Epoch: 6| Step: 2
Training loss: 0.866554319858551
Validation loss: 1.9081097918172036

Epoch: 6| Step: 3
Training loss: 0.8445316553115845
Validation loss: 1.9230966849993634

Epoch: 6| Step: 4
Training loss: 0.7958800792694092
Validation loss: 1.9067461746995167

Epoch: 6| Step: 5
Training loss: 1.0463240146636963
Validation loss: 1.9118075434879591

Epoch: 6| Step: 6
Training loss: 1.8256890773773193
Validation loss: 1.8915014754059494

Epoch: 6| Step: 7
Training loss: 0.7675228118896484
Validation loss: 1.883572465629988

Epoch: 6| Step: 8
Training loss: 1.5301897525787354
Validation loss: 1.8819857694769417

Epoch: 6| Step: 9
Training loss: 2.032017230987549
Validation loss: 1.8755115360342047

Epoch: 6| Step: 10
Training loss: 1.4093505144119263
Validation loss: 1.8923925738180838

Epoch: 6| Step: 11
Training loss: 0.9900988936424255
Validation loss: 1.903101885190574

Epoch: 6| Step: 12
Training loss: 1.022141456604004
Validation loss: 1.8969576384431572

Epoch: 6| Step: 13
Training loss: 1.0788140296936035
Validation loss: 1.8871188227848341

Epoch: 173| Step: 0
Training loss: 0.9258183240890503
Validation loss: 1.8950628298585133

Epoch: 6| Step: 1
Training loss: 0.6499777436256409
Validation loss: 1.8824224215681835

Epoch: 6| Step: 2
Training loss: 1.2277714014053345
Validation loss: 1.907579900116049

Epoch: 6| Step: 3
Training loss: 1.0823856592178345
Validation loss: 1.9349281300780594

Epoch: 6| Step: 4
Training loss: 1.0428138971328735
Validation loss: 1.9477639505940099

Epoch: 6| Step: 5
Training loss: 0.5505344867706299
Validation loss: 1.9416679874543221

Epoch: 6| Step: 6
Training loss: 0.8071538805961609
Validation loss: 1.9209795972352386

Epoch: 6| Step: 7
Training loss: 1.3490564823150635
Validation loss: 1.9157101979819677

Epoch: 6| Step: 8
Training loss: 1.5721004009246826
Validation loss: 1.8937076855731267

Epoch: 6| Step: 9
Training loss: 0.8654342293739319
Validation loss: 1.8847003277911936

Epoch: 6| Step: 10
Training loss: 1.5693821907043457
Validation loss: 1.8707516513844973

Epoch: 6| Step: 11
Training loss: 1.5965549945831299
Validation loss: 1.87215672257126

Epoch: 6| Step: 12
Training loss: 1.6355726718902588
Validation loss: 1.8602444535942488

Epoch: 6| Step: 13
Training loss: 1.6522424221038818
Validation loss: 1.878828925471152

Epoch: 174| Step: 0
Training loss: 1.3488857746124268
Validation loss: 1.8581821508305048

Epoch: 6| Step: 1
Training loss: 0.9096022844314575
Validation loss: 1.866894281038674

Epoch: 6| Step: 2
Training loss: 0.9278631806373596
Validation loss: 1.856967592752108

Epoch: 6| Step: 3
Training loss: 1.3003605604171753
Validation loss: 1.8469322419935656

Epoch: 6| Step: 4
Training loss: 1.418656826019287
Validation loss: 1.8423326323109288

Epoch: 6| Step: 5
Training loss: 1.1878011226654053
Validation loss: 1.8384892120156238

Epoch: 6| Step: 6
Training loss: 1.0900168418884277
Validation loss: 1.8163370150391773

Epoch: 6| Step: 7
Training loss: 0.7343140840530396
Validation loss: 1.828484248089534

Epoch: 6| Step: 8
Training loss: 0.7743417024612427
Validation loss: 1.8335922277101906

Epoch: 6| Step: 9
Training loss: 1.1071828603744507
Validation loss: 1.8626438597197175

Epoch: 6| Step: 10
Training loss: 1.2962963581085205
Validation loss: 1.8903695614107194

Epoch: 6| Step: 11
Training loss: 1.3517498970031738
Validation loss: 1.9190487579632831

Epoch: 6| Step: 12
Training loss: 0.9539559483528137
Validation loss: 1.9059907364588913

Epoch: 6| Step: 13
Training loss: 1.8883094787597656
Validation loss: 1.9419133278631395

Epoch: 175| Step: 0
Training loss: 1.435509443283081
Validation loss: 1.9233461144149944

Epoch: 6| Step: 1
Training loss: 0.9493595361709595
Validation loss: 1.9074082272027129

Epoch: 6| Step: 2
Training loss: 1.7897056341171265
Validation loss: 1.8971244237756217

Epoch: 6| Step: 3
Training loss: 0.9559635519981384
Validation loss: 1.8545597676307923

Epoch: 6| Step: 4
Training loss: 0.9071217179298401
Validation loss: 1.8516580148409771

Epoch: 6| Step: 5
Training loss: 0.9487590789794922
Validation loss: 1.8591728389904063

Epoch: 6| Step: 6
Training loss: 1.0224474668502808
Validation loss: 1.8509888930987286

Epoch: 6| Step: 7
Training loss: 1.1287152767181396
Validation loss: 1.8855257803393948

Epoch: 6| Step: 8
Training loss: 1.432542324066162
Validation loss: 1.8928409878925612

Epoch: 6| Step: 9
Training loss: 1.0647391080856323
Validation loss: 1.888233712924424

Epoch: 6| Step: 10
Training loss: 1.3061578273773193
Validation loss: 1.8673181354358632

Epoch: 6| Step: 11
Training loss: 0.9015641212463379
Validation loss: 1.8777995301831154

Epoch: 6| Step: 12
Training loss: 0.9735698103904724
Validation loss: 1.8611705277555732

Epoch: 6| Step: 13
Training loss: 0.7595880031585693
Validation loss: 1.8907725811004639

Epoch: 176| Step: 0
Training loss: 1.557619571685791
Validation loss: 1.8861654676416868

Epoch: 6| Step: 1
Training loss: 0.855852484703064
Validation loss: 1.9022685891838484

Epoch: 6| Step: 2
Training loss: 1.3082523345947266
Validation loss: 1.9181358545057234

Epoch: 6| Step: 3
Training loss: 1.408359408378601
Validation loss: 1.9086940006543232

Epoch: 6| Step: 4
Training loss: 0.8042829036712646
Validation loss: 1.9011294418765652

Epoch: 6| Step: 5
Training loss: 0.826532244682312
Validation loss: 1.897209963490886

Epoch: 6| Step: 6
Training loss: 1.4109686613082886
Validation loss: 1.8774075508117676

Epoch: 6| Step: 7
Training loss: 1.0724122524261475
Validation loss: 1.8589620628664572

Epoch: 6| Step: 8
Training loss: 0.9414762258529663
Validation loss: 1.872891833705287

Epoch: 6| Step: 9
Training loss: 0.7575190663337708
Validation loss: 1.8496552052036408

Epoch: 6| Step: 10
Training loss: 0.639022946357727
Validation loss: 1.858762530870335

Epoch: 6| Step: 11
Training loss: 1.263548493385315
Validation loss: 1.8549507330822688

Epoch: 6| Step: 12
Training loss: 1.184150218963623
Validation loss: 1.8583978260717084

Epoch: 6| Step: 13
Training loss: 1.1659260988235474
Validation loss: 1.8417515165062361

Epoch: 177| Step: 0
Training loss: 1.1624808311462402
Validation loss: 1.8401023764764108

Epoch: 6| Step: 1
Training loss: 1.1824710369110107
Validation loss: 1.8450585347349926

Epoch: 6| Step: 2
Training loss: 0.6349291205406189
Validation loss: 1.851285142283286

Epoch: 6| Step: 3
Training loss: 1.0129661560058594
Validation loss: 1.8569999715333343

Epoch: 6| Step: 4
Training loss: 1.2694326639175415
Validation loss: 1.8792268486433132

Epoch: 6| Step: 5
Training loss: 1.1769787073135376
Validation loss: 1.8825249979572911

Epoch: 6| Step: 6
Training loss: 0.9858813881874084
Validation loss: 1.8847875313092304

Epoch: 6| Step: 7
Training loss: 1.40086829662323
Validation loss: 1.8873038740568264

Epoch: 6| Step: 8
Training loss: 0.891211748123169
Validation loss: 1.8825667724814465

Epoch: 6| Step: 9
Training loss: 0.9609866142272949
Validation loss: 1.873302064916139

Epoch: 6| Step: 10
Training loss: 0.912916898727417
Validation loss: 1.8630865812301636

Epoch: 6| Step: 11
Training loss: 0.8794748187065125
Validation loss: 1.8490793038440008

Epoch: 6| Step: 12
Training loss: 1.482492208480835
Validation loss: 1.8597766840329735

Epoch: 6| Step: 13
Training loss: 1.2765300273895264
Validation loss: 1.8547193183693835

Epoch: 178| Step: 0
Training loss: 0.856799840927124
Validation loss: 1.852670177336662

Epoch: 6| Step: 1
Training loss: 1.4474254846572876
Validation loss: 1.8620942497766146

Epoch: 6| Step: 2
Training loss: 1.2589855194091797
Validation loss: 1.8709723590522684

Epoch: 6| Step: 3
Training loss: 0.857351541519165
Validation loss: 1.8830299736351095

Epoch: 6| Step: 4
Training loss: 0.6012001633644104
Validation loss: 1.8871878705998903

Epoch: 6| Step: 5
Training loss: 1.204263687133789
Validation loss: 1.8997347034433836

Epoch: 6| Step: 6
Training loss: 0.7730661034584045
Validation loss: 1.89298048070682

Epoch: 6| Step: 7
Training loss: 1.09287428855896
Validation loss: 1.9116373164679414

Epoch: 6| Step: 8
Training loss: 1.0363078117370605
Validation loss: 1.9057464125335857

Epoch: 6| Step: 9
Training loss: 1.0234463214874268
Validation loss: 1.9062005601903445

Epoch: 6| Step: 10
Training loss: 1.9056320190429688
Validation loss: 1.8776268882136191

Epoch: 6| Step: 11
Training loss: 0.8777579069137573
Validation loss: 1.897579716097924

Epoch: 6| Step: 12
Training loss: 0.9105262756347656
Validation loss: 1.8879905067464358

Epoch: 6| Step: 13
Training loss: 1.3129991292953491
Validation loss: 1.8775657492299234

Epoch: 179| Step: 0
Training loss: 0.8026523590087891
Validation loss: 1.8822503730814943

Epoch: 6| Step: 1
Training loss: 1.1264452934265137
Validation loss: 1.8564346105821672

Epoch: 6| Step: 2
Training loss: 1.1975491046905518
Validation loss: 1.8458658418347758

Epoch: 6| Step: 3
Training loss: 1.2055563926696777
Validation loss: 1.8563883830142278

Epoch: 6| Step: 4
Training loss: 1.0590901374816895
Validation loss: 1.8381356475173787

Epoch: 6| Step: 5
Training loss: 1.4977262020111084
Validation loss: 1.8664969449402184

Epoch: 6| Step: 6
Training loss: 0.9888002276420593
Validation loss: 1.840294494423815

Epoch: 6| Step: 7
Training loss: 1.0596294403076172
Validation loss: 1.8671439642547278

Epoch: 6| Step: 8
Training loss: 0.8918412923812866
Validation loss: 1.8976663440786383

Epoch: 6| Step: 9
Training loss: 0.9315420985221863
Validation loss: 1.93810825322264

Epoch: 6| Step: 10
Training loss: 1.950859785079956
Validation loss: 1.9671754913945352

Epoch: 6| Step: 11
Training loss: 0.8971977829933167
Validation loss: 1.9541124489999586

Epoch: 6| Step: 12
Training loss: 0.9007115364074707
Validation loss: 1.934043675340632

Epoch: 6| Step: 13
Training loss: 1.145241379737854
Validation loss: 1.906626909009872

Epoch: 180| Step: 0
Training loss: 0.936019241809845
Validation loss: 1.8730229780238161

Epoch: 6| Step: 1
Training loss: 1.2044957876205444
Validation loss: 1.8485734385828818

Epoch: 6| Step: 2
Training loss: 1.0435597896575928
Validation loss: 1.8459368713440434

Epoch: 6| Step: 3
Training loss: 1.0845565795898438
Validation loss: 1.8515680707911009

Epoch: 6| Step: 4
Training loss: 0.5490617752075195
Validation loss: 1.861824079226422

Epoch: 6| Step: 5
Training loss: 1.341911792755127
Validation loss: 1.8873361028650755

Epoch: 6| Step: 6
Training loss: 0.7174046039581299
Validation loss: 1.8859847258496028

Epoch: 6| Step: 7
Training loss: 0.9974021911621094
Validation loss: 1.8819488479245094

Epoch: 6| Step: 8
Training loss: 0.7855942249298096
Validation loss: 1.885878166844768

Epoch: 6| Step: 9
Training loss: 1.4113924503326416
Validation loss: 1.8682247515647643

Epoch: 6| Step: 10
Training loss: 1.2950520515441895
Validation loss: 1.8658931306613389

Epoch: 6| Step: 11
Training loss: 1.1533253192901611
Validation loss: 1.8782130979722547

Epoch: 6| Step: 12
Training loss: 1.2030112743377686
Validation loss: 1.8933791524620467

Epoch: 6| Step: 13
Training loss: 0.698002815246582
Validation loss: 1.8828339422902753

Epoch: 181| Step: 0
Training loss: 0.5588876008987427
Validation loss: 1.8675106699748705

Epoch: 6| Step: 1
Training loss: 1.1038227081298828
Validation loss: 1.8809343614885885

Epoch: 6| Step: 2
Training loss: 0.5472792387008667
Validation loss: 1.9158533286022883

Epoch: 6| Step: 3
Training loss: 1.031426191329956
Validation loss: 1.890812015020719

Epoch: 6| Step: 4
Training loss: 1.439502477645874
Validation loss: 1.8874429195157942

Epoch: 6| Step: 5
Training loss: 0.7204787731170654
Validation loss: 1.85882689363213

Epoch: 6| Step: 6
Training loss: 1.1508033275604248
Validation loss: 1.8736845062625023

Epoch: 6| Step: 7
Training loss: 0.98732990026474
Validation loss: 1.8738733581317368

Epoch: 6| Step: 8
Training loss: 1.0587458610534668
Validation loss: 1.8765621826212893

Epoch: 6| Step: 9
Training loss: 1.79087495803833
Validation loss: 1.8684387155758437

Epoch: 6| Step: 10
Training loss: 1.5181527137756348
Validation loss: 1.8804519381574405

Epoch: 6| Step: 11
Training loss: 1.3000900745391846
Validation loss: 1.8988420681286884

Epoch: 6| Step: 12
Training loss: 0.657056987285614
Validation loss: 1.9137805956666187

Epoch: 6| Step: 13
Training loss: 1.0498425960540771
Validation loss: 1.9472621320396342

Epoch: 182| Step: 0
Training loss: 1.220466136932373
Validation loss: 1.9482741266168573

Epoch: 6| Step: 1
Training loss: 1.0730879306793213
Validation loss: 1.9627251625061035

Epoch: 6| Step: 2
Training loss: 0.7553654909133911
Validation loss: 1.9101004113433182

Epoch: 6| Step: 3
Training loss: 1.354238510131836
Validation loss: 1.8750799279059134

Epoch: 6| Step: 4
Training loss: 1.067771315574646
Validation loss: 1.9046925178138159

Epoch: 6| Step: 5
Training loss: 1.6803220510482788
Validation loss: 1.899876784252864

Epoch: 6| Step: 6
Training loss: 1.2009772062301636
Validation loss: 1.8946895407092186

Epoch: 6| Step: 7
Training loss: 1.2977393865585327
Validation loss: 1.872445951225937

Epoch: 6| Step: 8
Training loss: 1.008256435394287
Validation loss: 1.8772385953575053

Epoch: 6| Step: 9
Training loss: 0.9317963123321533
Validation loss: 1.8888109140498663

Epoch: 6| Step: 10
Training loss: 0.6429554224014282
Validation loss: 1.8619600213984007

Epoch: 6| Step: 11
Training loss: 0.691329300403595
Validation loss: 1.86449340081984

Epoch: 6| Step: 12
Training loss: 1.2870395183563232
Validation loss: 1.845200264325706

Epoch: 6| Step: 13
Training loss: 0.7613626718521118
Validation loss: 1.8483796145326348

Epoch: 183| Step: 0
Training loss: 0.7818870544433594
Validation loss: 1.8347649010278846

Epoch: 6| Step: 1
Training loss: 1.4329025745391846
Validation loss: 1.8415586999667588

Epoch: 6| Step: 2
Training loss: 0.8137282729148865
Validation loss: 1.837912586427504

Epoch: 6| Step: 3
Training loss: 1.3568310737609863
Validation loss: 1.8608823335298927

Epoch: 6| Step: 4
Training loss: 1.0453846454620361
Validation loss: 1.888767901287284

Epoch: 6| Step: 5
Training loss: 1.2952561378479004
Validation loss: 1.8898483181512484

Epoch: 6| Step: 6
Training loss: 1.0611793994903564
Validation loss: 1.872110753931025

Epoch: 6| Step: 7
Training loss: 1.1412585973739624
Validation loss: 1.850678769491052

Epoch: 6| Step: 8
Training loss: 1.0581786632537842
Validation loss: 1.848118466715659

Epoch: 6| Step: 9
Training loss: 1.1338005065917969
Validation loss: 1.8422640292875228

Epoch: 6| Step: 10
Training loss: 0.7152343392372131
Validation loss: 1.8377865232447141

Epoch: 6| Step: 11
Training loss: 0.9958047270774841
Validation loss: 1.847746117140657

Epoch: 6| Step: 12
Training loss: 0.8139732480049133
Validation loss: 1.8391306528481104

Epoch: 6| Step: 13
Training loss: 1.3869138956069946
Validation loss: 1.8444780790677635

Epoch: 184| Step: 0
Training loss: 0.8322750926017761
Validation loss: 1.8423784868691557

Epoch: 6| Step: 1
Training loss: 1.167837142944336
Validation loss: 1.8525205171236427

Epoch: 6| Step: 2
Training loss: 1.3478670120239258
Validation loss: 1.869983220613131

Epoch: 6| Step: 3
Training loss: 1.620031714439392
Validation loss: 1.8924224197223622

Epoch: 6| Step: 4
Training loss: 0.8966782093048096
Validation loss: 1.899969905935308

Epoch: 6| Step: 5
Training loss: 1.2160561084747314
Validation loss: 1.8565028546958842

Epoch: 6| Step: 6
Training loss: 1.259070873260498
Validation loss: 1.8665905896053518

Epoch: 6| Step: 7
Training loss: 0.7303785085678101
Validation loss: 1.8766327391388595

Epoch: 6| Step: 8
Training loss: 1.1509294509887695
Validation loss: 1.8627464732816141

Epoch: 6| Step: 9
Training loss: 1.1386656761169434
Validation loss: 1.8282056982799242

Epoch: 6| Step: 10
Training loss: 0.9606173634529114
Validation loss: 1.8099432017213555

Epoch: 6| Step: 11
Training loss: 0.5587981343269348
Validation loss: 1.7875377029500983

Epoch: 6| Step: 12
Training loss: 0.9196443557739258
Validation loss: 1.767851137345837

Epoch: 6| Step: 13
Training loss: 0.5632040500640869
Validation loss: 1.799802807069594

Epoch: 185| Step: 0
Training loss: 0.8379094004631042
Validation loss: 1.7990599575863089

Epoch: 6| Step: 1
Training loss: 0.7193036079406738
Validation loss: 1.749860473858413

Epoch: 6| Step: 2
Training loss: 1.2261086702346802
Validation loss: 1.739538308112852

Epoch: 6| Step: 3
Training loss: 1.2038028240203857
Validation loss: 1.762080797585108

Epoch: 6| Step: 4
Training loss: 0.9983665943145752
Validation loss: 1.7746111590375182

Epoch: 6| Step: 5
Training loss: 0.6535839438438416
Validation loss: 1.8178417028919343

Epoch: 6| Step: 6
Training loss: 0.977806806564331
Validation loss: 1.867813842270964

Epoch: 6| Step: 7
Training loss: 1.1532493829727173
Validation loss: 1.8914770887744041

Epoch: 6| Step: 8
Training loss: 1.4443193674087524
Validation loss: 1.9213052372778616

Epoch: 6| Step: 9
Training loss: 1.122253656387329
Validation loss: 1.9020743446965371

Epoch: 6| Step: 10
Training loss: 1.0629323720932007
Validation loss: 1.8960589490911013

Epoch: 6| Step: 11
Training loss: 1.3471697568893433
Validation loss: 1.8733695117376183

Epoch: 6| Step: 12
Training loss: 0.7364648580551147
Validation loss: 1.8563150039283178

Epoch: 6| Step: 13
Training loss: 1.3035022020339966
Validation loss: 1.8554872056489349

Epoch: 186| Step: 0
Training loss: 0.6595968008041382
Validation loss: 1.859030637689816

Epoch: 6| Step: 1
Training loss: 0.8842833638191223
Validation loss: 1.870101426237373

Epoch: 6| Step: 2
Training loss: 1.3070448637008667
Validation loss: 1.8608989125938826

Epoch: 6| Step: 3
Training loss: 0.40952226519584656
Validation loss: 1.8632513310319634

Epoch: 6| Step: 4
Training loss: 0.8254148960113525
Validation loss: 1.8957147290629726

Epoch: 6| Step: 5
Training loss: 1.1623246669769287
Validation loss: 1.8961388270060222

Epoch: 6| Step: 6
Training loss: 0.8413679003715515
Validation loss: 1.9004126851276686

Epoch: 6| Step: 7
Training loss: 1.2017898559570312
Validation loss: 1.89185465792174

Epoch: 6| Step: 8
Training loss: 0.9514797925949097
Validation loss: 1.8722099155508063

Epoch: 6| Step: 9
Training loss: 0.9200210571289062
Validation loss: 1.883422415743592

Epoch: 6| Step: 10
Training loss: 1.2046558856964111
Validation loss: 1.8707315639782978

Epoch: 6| Step: 11
Training loss: 1.3213800191879272
Validation loss: 1.860121230925283

Epoch: 6| Step: 12
Training loss: 1.0605814456939697
Validation loss: 1.8647428789446432

Epoch: 6| Step: 13
Training loss: 1.816657543182373
Validation loss: 1.8804575973941433

Epoch: 187| Step: 0
Training loss: 1.0183815956115723
Validation loss: 1.8830791378533969

Epoch: 6| Step: 1
Training loss: 1.121614694595337
Validation loss: 1.8540327664344542

Epoch: 6| Step: 2
Training loss: 0.9926559925079346
Validation loss: 1.8597131493271037

Epoch: 6| Step: 3
Training loss: 1.0159292221069336
Validation loss: 1.8521014054616292

Epoch: 6| Step: 4
Training loss: 1.2702553272247314
Validation loss: 1.853484720312139

Epoch: 6| Step: 5
Training loss: 0.49144497513771057
Validation loss: 1.8790269705557054

Epoch: 6| Step: 6
Training loss: 0.7480432987213135
Validation loss: 1.9075906943249445

Epoch: 6| Step: 7
Training loss: 0.9287175536155701
Validation loss: 1.913949199902114

Epoch: 6| Step: 8
Training loss: 0.8972355127334595
Validation loss: 1.924714780622913

Epoch: 6| Step: 9
Training loss: 1.1316108703613281
Validation loss: 1.9354945587855514

Epoch: 6| Step: 10
Training loss: 1.1475803852081299
Validation loss: 1.9244027124938143

Epoch: 6| Step: 11
Training loss: 1.1027803421020508
Validation loss: 1.954553158052506

Epoch: 6| Step: 12
Training loss: 1.279456615447998
Validation loss: 1.9501726883713917

Epoch: 6| Step: 13
Training loss: 0.7222599983215332
Validation loss: 1.9779138898336759

Epoch: 188| Step: 0
Training loss: 1.3528859615325928
Validation loss: 1.9533125328761276

Epoch: 6| Step: 1
Training loss: 0.8766489028930664
Validation loss: 1.944387625622493

Epoch: 6| Step: 2
Training loss: 1.1622378826141357
Validation loss: 1.9135373907704507

Epoch: 6| Step: 3
Training loss: 1.3472492694854736
Validation loss: 1.9032467654956284

Epoch: 6| Step: 4
Training loss: 1.4717413187026978
Validation loss: 1.8833370260013047

Epoch: 6| Step: 5
Training loss: 0.6958665251731873
Validation loss: 1.8436329582686066

Epoch: 6| Step: 6
Training loss: 1.2179428339004517
Validation loss: 1.8164733071481027

Epoch: 6| Step: 7
Training loss: 0.7007375955581665
Validation loss: 1.8357405611263808

Epoch: 6| Step: 8
Training loss: 0.6991956233978271
Validation loss: 1.81878529056426

Epoch: 6| Step: 9
Training loss: 0.8592804670333862
Validation loss: 1.822389369369835

Epoch: 6| Step: 10
Training loss: 1.269661784172058
Validation loss: 1.8302569158615605

Epoch: 6| Step: 11
Training loss: 0.5653966665267944
Validation loss: 1.8296755706110308

Epoch: 6| Step: 12
Training loss: 0.5297249555587769
Validation loss: 1.863723124227216

Epoch: 6| Step: 13
Training loss: 0.6340948939323425
Validation loss: 1.8571270435087142

Epoch: 189| Step: 0
Training loss: 1.0651533603668213
Validation loss: 1.8607052910712458

Epoch: 6| Step: 1
Training loss: 0.6529364585876465
Validation loss: 1.8756201728697746

Epoch: 6| Step: 2
Training loss: 0.8224751949310303
Validation loss: 1.8798363747135285

Epoch: 6| Step: 3
Training loss: 0.6335912942886353
Validation loss: 1.8647459835134528

Epoch: 6| Step: 4
Training loss: 1.1231669187545776
Validation loss: 1.8561964214489024

Epoch: 6| Step: 5
Training loss: 1.1655595302581787
Validation loss: 1.8459367136801443

Epoch: 6| Step: 6
Training loss: 0.7258992195129395
Validation loss: 1.8533430445578791

Epoch: 6| Step: 7
Training loss: 1.1050031185150146
Validation loss: 1.863014926192581

Epoch: 6| Step: 8
Training loss: 0.6473900079727173
Validation loss: 1.8410926121537403

Epoch: 6| Step: 9
Training loss: 0.8627530336380005
Validation loss: 1.8415007078519432

Epoch: 6| Step: 10
Training loss: 0.7616925239562988
Validation loss: 1.850131711652202

Epoch: 6| Step: 11
Training loss: 1.0490130186080933
Validation loss: 1.8480326411544636

Epoch: 6| Step: 12
Training loss: 1.4129441976547241
Validation loss: 1.8088223870082567

Epoch: 6| Step: 13
Training loss: 1.417184829711914
Validation loss: 1.8146646317615305

Epoch: 190| Step: 0
Training loss: 0.8437600135803223
Validation loss: 1.789510726928711

Epoch: 6| Step: 1
Training loss: 0.6852243542671204
Validation loss: 1.7756099649654922

Epoch: 6| Step: 2
Training loss: 0.8145240545272827
Validation loss: 1.7965274190389982

Epoch: 6| Step: 3
Training loss: 1.5522112846374512
Validation loss: 1.7883692659357542

Epoch: 6| Step: 4
Training loss: 1.3299007415771484
Validation loss: 1.7726610117061163

Epoch: 6| Step: 5
Training loss: 1.2024762630462646
Validation loss: 1.8066284976979738

Epoch: 6| Step: 6
Training loss: 0.8550422191619873
Validation loss: 1.8220487999659714

Epoch: 6| Step: 7
Training loss: 1.1071369647979736
Validation loss: 1.8220763180845527

Epoch: 6| Step: 8
Training loss: 1.0187761783599854
Validation loss: 1.8146434291716544

Epoch: 6| Step: 9
Training loss: 0.3934679627418518
Validation loss: 1.8363128567254672

Epoch: 6| Step: 10
Training loss: 1.0639431476593018
Validation loss: 1.853391792184563

Epoch: 6| Step: 11
Training loss: 0.765516996383667
Validation loss: 1.863330013008528

Epoch: 6| Step: 12
Training loss: 0.6048334240913391
Validation loss: 1.8617161653375114

Epoch: 6| Step: 13
Training loss: 0.560696005821228
Validation loss: 1.8605621335326985

Epoch: 191| Step: 0
Training loss: 0.8281893730163574
Validation loss: 1.8988310842103855

Epoch: 6| Step: 1
Training loss: 0.8814181089401245
Validation loss: 1.9245352386146464

Epoch: 6| Step: 2
Training loss: 0.9185099601745605
Validation loss: 1.9140380121046496

Epoch: 6| Step: 3
Training loss: 1.0250341892242432
Validation loss: 1.9055720452339417

Epoch: 6| Step: 4
Training loss: 1.1170434951782227
Validation loss: 1.8647914009709512

Epoch: 6| Step: 5
Training loss: 0.46870681643486023
Validation loss: 1.8428258511327928

Epoch: 6| Step: 6
Training loss: 1.1934174299240112
Validation loss: 1.8400959840384863

Epoch: 6| Step: 7
Training loss: 1.0108745098114014
Validation loss: 1.8429284813583537

Epoch: 6| Step: 8
Training loss: 0.9790983200073242
Validation loss: 1.8123429629110521

Epoch: 6| Step: 9
Training loss: 0.9749310612678528
Validation loss: 1.8306403557459514

Epoch: 6| Step: 10
Training loss: 1.3419568538665771
Validation loss: 1.8429880808758479

Epoch: 6| Step: 11
Training loss: 0.7365671396255493
Validation loss: 1.8240131921665643

Epoch: 6| Step: 12
Training loss: 0.8048432469367981
Validation loss: 1.8469063197412798

Epoch: 6| Step: 13
Training loss: 0.749643087387085
Validation loss: 1.8366553962871592

Epoch: 192| Step: 0
Training loss: 0.6940163373947144
Validation loss: 1.8444744130616546

Epoch: 6| Step: 1
Training loss: 0.6369320750236511
Validation loss: 1.8361702619060394

Epoch: 6| Step: 2
Training loss: 0.9109306931495667
Validation loss: 1.8212839929006432

Epoch: 6| Step: 3
Training loss: 1.0095336437225342
Validation loss: 1.8540855748679048

Epoch: 6| Step: 4
Training loss: 1.2336554527282715
Validation loss: 1.8417502910860124

Epoch: 6| Step: 5
Training loss: 1.2522364854812622
Validation loss: 1.840195845532161

Epoch: 6| Step: 6
Training loss: 1.3999395370483398
Validation loss: 1.8374690394247732

Epoch: 6| Step: 7
Training loss: 1.0751826763153076
Validation loss: 1.8424272691049883

Epoch: 6| Step: 8
Training loss: 0.8594046831130981
Validation loss: 1.8238890491506106

Epoch: 6| Step: 9
Training loss: 0.656613290309906
Validation loss: 1.8538163169737785

Epoch: 6| Step: 10
Training loss: 1.107088565826416
Validation loss: 1.8708744895073675

Epoch: 6| Step: 11
Training loss: 0.6314604878425598
Validation loss: 1.8746940910175283

Epoch: 6| Step: 12
Training loss: 0.7910865545272827
Validation loss: 1.8855299231826619

Epoch: 6| Step: 13
Training loss: 0.36558079719543457
Validation loss: 1.8909214312030422

Epoch: 193| Step: 0
Training loss: 0.9343408346176147
Validation loss: 1.8967932590874292

Epoch: 6| Step: 1
Training loss: 1.2969523668289185
Validation loss: 1.9083398644642164

Epoch: 6| Step: 2
Training loss: 1.2181898355484009
Validation loss: 1.9065477745507353

Epoch: 6| Step: 3
Training loss: 1.0171183347702026
Validation loss: 1.92753081680626

Epoch: 6| Step: 4
Training loss: 0.7492842674255371
Validation loss: 1.8910322253422072

Epoch: 6| Step: 5
Training loss: 0.38923850655555725
Validation loss: 1.866429877537553

Epoch: 6| Step: 6
Training loss: 1.1906561851501465
Validation loss: 1.8433671292438303

Epoch: 6| Step: 7
Training loss: 0.7460798025131226
Validation loss: 1.8405426253554642

Epoch: 6| Step: 8
Training loss: 0.8134156465530396
Validation loss: 1.8430861029573666

Epoch: 6| Step: 9
Training loss: 1.0057555437088013
Validation loss: 1.864928134026066

Epoch: 6| Step: 10
Training loss: 0.9690905213356018
Validation loss: 1.8956182054294053

Epoch: 6| Step: 11
Training loss: 1.1143490076065063
Validation loss: 1.862128823034225

Epoch: 6| Step: 12
Training loss: 0.7928863763809204
Validation loss: 1.840209549473178

Epoch: 6| Step: 13
Training loss: 0.9672259092330933
Validation loss: 1.8154926966595393

Epoch: 194| Step: 0
Training loss: 0.4093337059020996
Validation loss: 1.8066600855960642

Epoch: 6| Step: 1
Training loss: 1.2517162561416626
Validation loss: 1.7927883735267065

Epoch: 6| Step: 2
Training loss: 0.6154468059539795
Validation loss: 1.8046149822973436

Epoch: 6| Step: 3
Training loss: 0.8058079481124878
Validation loss: 1.8055524710685975

Epoch: 6| Step: 4
Training loss: 1.2867891788482666
Validation loss: 1.8244067302314184

Epoch: 6| Step: 5
Training loss: 1.2331181764602661
Validation loss: 1.835496756338304

Epoch: 6| Step: 6
Training loss: 0.7135346531867981
Validation loss: 1.844802430880967

Epoch: 6| Step: 7
Training loss: 0.9835137724876404
Validation loss: 1.8719866352696573

Epoch: 6| Step: 8
Training loss: 0.7030472755432129
Validation loss: 1.8571359931781728

Epoch: 6| Step: 9
Training loss: 0.9865269660949707
Validation loss: 1.8633268546032649

Epoch: 6| Step: 10
Training loss: 0.9578747749328613
Validation loss: 1.8631822191258913

Epoch: 6| Step: 11
Training loss: 0.9061810970306396
Validation loss: 1.8511870945653608

Epoch: 6| Step: 12
Training loss: 0.9333366751670837
Validation loss: 1.806024794937462

Epoch: 6| Step: 13
Training loss: 0.5362851023674011
Validation loss: 1.8245817192139164

Epoch: 195| Step: 0
Training loss: 0.8278323411941528
Validation loss: 1.8066022472996865

Epoch: 6| Step: 1
Training loss: 1.0230658054351807
Validation loss: 1.812771003733399

Epoch: 6| Step: 2
Training loss: 0.5745075345039368
Validation loss: 1.8269780733252083

Epoch: 6| Step: 3
Training loss: 1.049912452697754
Validation loss: 1.8278219558859383

Epoch: 6| Step: 4
Training loss: 1.3592426776885986
Validation loss: 1.833783665011006

Epoch: 6| Step: 5
Training loss: 0.9332235455513
Validation loss: 1.850053350130717

Epoch: 6| Step: 6
Training loss: 0.6728264093399048
Validation loss: 1.840203369817426

Epoch: 6| Step: 7
Training loss: 1.1136727333068848
Validation loss: 1.8254247224459084

Epoch: 6| Step: 8
Training loss: 1.0249947309494019
Validation loss: 1.7944601569124448

Epoch: 6| Step: 9
Training loss: 0.5962911248207092
Validation loss: 1.8323367257272043

Epoch: 6| Step: 10
Training loss: 0.8487489819526672
Validation loss: 1.8166178618707964

Epoch: 6| Step: 11
Training loss: 0.8601161241531372
Validation loss: 1.8412445565705657

Epoch: 6| Step: 12
Training loss: 0.9200210571289062
Validation loss: 1.863704223786631

Epoch: 6| Step: 13
Training loss: 0.5232481956481934
Validation loss: 1.8785969929028583

Epoch: 196| Step: 0
Training loss: 1.1373960971832275
Validation loss: 1.8933415207811581

Epoch: 6| Step: 1
Training loss: 1.7134666442871094
Validation loss: 1.8964415827105123

Epoch: 6| Step: 2
Training loss: 0.775193989276886
Validation loss: 1.8932294768671836

Epoch: 6| Step: 3
Training loss: 0.5767405033111572
Validation loss: 1.9196399565665954

Epoch: 6| Step: 4
Training loss: 0.6039193868637085
Validation loss: 1.9309656978935323

Epoch: 6| Step: 5
Training loss: 0.9262619614601135
Validation loss: 1.946072442557222

Epoch: 6| Step: 6
Training loss: 0.9867323637008667
Validation loss: 1.9047057859359249

Epoch: 6| Step: 7
Training loss: 0.7417364716529846
Validation loss: 1.891248030047263

Epoch: 6| Step: 8
Training loss: 0.9737657308578491
Validation loss: 1.8445890001071397

Epoch: 6| Step: 9
Training loss: 0.6524717807769775
Validation loss: 1.808496549565305

Epoch: 6| Step: 10
Training loss: 0.7921738624572754
Validation loss: 1.8107859255165182

Epoch: 6| Step: 11
Training loss: 1.0716389417648315
Validation loss: 1.7859402292518205

Epoch: 6| Step: 12
Training loss: 0.8172568082809448
Validation loss: 1.7934608010835544

Epoch: 6| Step: 13
Training loss: 0.7395387887954712
Validation loss: 1.7761158315084313

Epoch: 197| Step: 0
Training loss: 1.04781973361969
Validation loss: 1.7893489060863372

Epoch: 6| Step: 1
Training loss: 0.5469975471496582
Validation loss: 1.7790642669123988

Epoch: 6| Step: 2
Training loss: 0.7564265131950378
Validation loss: 1.812607842106973

Epoch: 6| Step: 3
Training loss: 0.9730458855628967
Validation loss: 1.85485924572073

Epoch: 6| Step: 4
Training loss: 0.9191513061523438
Validation loss: 1.8581215899477723

Epoch: 6| Step: 5
Training loss: 0.8487467765808105
Validation loss: 1.861056638020341

Epoch: 6| Step: 6
Training loss: 1.0436761379241943
Validation loss: 1.8464592297871907

Epoch: 6| Step: 7
Training loss: 0.8273086547851562
Validation loss: 1.8376054879157775

Epoch: 6| Step: 8
Training loss: 0.9998948574066162
Validation loss: 1.8120171536681473

Epoch: 6| Step: 9
Training loss: 0.971473217010498
Validation loss: 1.8226817333570091

Epoch: 6| Step: 10
Training loss: 0.8144519329071045
Validation loss: 1.8082064761910388

Epoch: 6| Step: 11
Training loss: 0.9478729963302612
Validation loss: 1.8214823674130183

Epoch: 6| Step: 12
Training loss: 0.9761199355125427
Validation loss: 1.8076204151235602

Epoch: 6| Step: 13
Training loss: 0.8318952918052673
Validation loss: 1.8080658451203377

Epoch: 198| Step: 0
Training loss: 0.4107823967933655
Validation loss: 1.8363167983229443

Epoch: 6| Step: 1
Training loss: 1.037402868270874
Validation loss: 1.9148652656103975

Epoch: 6| Step: 2
Training loss: 1.2518701553344727
Validation loss: 1.94484539698529

Epoch: 6| Step: 3
Training loss: 0.7999438047409058
Validation loss: 1.9209522995897519

Epoch: 6| Step: 4
Training loss: 1.0996540784835815
Validation loss: 1.9143406050179594

Epoch: 6| Step: 5
Training loss: 1.0452888011932373
Validation loss: 1.8987100790905695

Epoch: 6| Step: 6
Training loss: 0.8970772624015808
Validation loss: 1.8699366328536824

Epoch: 6| Step: 7
Training loss: 1.3753981590270996
Validation loss: 1.8396779324418755

Epoch: 6| Step: 8
Training loss: 0.9433743953704834
Validation loss: 1.830612406935743

Epoch: 6| Step: 9
Training loss: 0.9139260053634644
Validation loss: 1.8689322971528577

Epoch: 6| Step: 10
Training loss: 0.8174207806587219
Validation loss: 1.823176573681575

Epoch: 6| Step: 11
Training loss: 1.0127923488616943
Validation loss: 1.7898171781211771

Epoch: 6| Step: 12
Training loss: 0.5652649402618408
Validation loss: 1.7738483336664015

Epoch: 6| Step: 13
Training loss: 1.100429654121399
Validation loss: 1.755584386087233

Epoch: 199| Step: 0
Training loss: 0.7450529336929321
Validation loss: 1.7758414206966278

Epoch: 6| Step: 1
Training loss: 0.8025960326194763
Validation loss: 1.8055373801979968

Epoch: 6| Step: 2
Training loss: 0.6233713626861572
Validation loss: 1.8402706743568502

Epoch: 6| Step: 3
Training loss: 0.9943655729293823
Validation loss: 1.888305656371578

Epoch: 6| Step: 4
Training loss: 0.872259259223938
Validation loss: 1.8993310684798865

Epoch: 6| Step: 5
Training loss: 0.8565946817398071
Validation loss: 1.8553812567905714

Epoch: 6| Step: 6
Training loss: 0.8346495628356934
Validation loss: 1.8469104536118046

Epoch: 6| Step: 7
Training loss: 0.9420957565307617
Validation loss: 1.8496527556450135

Epoch: 6| Step: 8
Training loss: 0.8784865736961365
Validation loss: 1.8230735986463484

Epoch: 6| Step: 9
Training loss: 0.7208473086357117
Validation loss: 1.8304162243361115

Epoch: 6| Step: 10
Training loss: 0.9949307441711426
Validation loss: 1.8266427311846005

Epoch: 6| Step: 11
Training loss: 1.1176843643188477
Validation loss: 1.7932114549862441

Epoch: 6| Step: 12
Training loss: 1.0364569425582886
Validation loss: 1.8003076750745055

Epoch: 6| Step: 13
Training loss: 0.5529094934463501
Validation loss: 1.7740641486260198

Epoch: 200| Step: 0
Training loss: 1.3727362155914307
Validation loss: 1.785589987231839

Epoch: 6| Step: 1
Training loss: 0.6834501624107361
Validation loss: 1.8252982144714684

Epoch: 6| Step: 2
Training loss: 0.8267638087272644
Validation loss: 1.8366420986831828

Epoch: 6| Step: 3
Training loss: 0.5006469488143921
Validation loss: 1.8346121157369306

Epoch: 6| Step: 4
Training loss: 0.5647034645080566
Validation loss: 1.8836004067492742

Epoch: 6| Step: 5
Training loss: 0.6507677435874939
Validation loss: 1.8752753144951277

Epoch: 6| Step: 6
Training loss: 1.0240721702575684
Validation loss: 1.8602896787786996

Epoch: 6| Step: 7
Training loss: 0.8301772475242615
Validation loss: 1.8755440660702285

Epoch: 6| Step: 8
Training loss: 0.9379923343658447
Validation loss: 1.8613968113417267

Epoch: 6| Step: 9
Training loss: 0.9654139280319214
Validation loss: 1.8678645241645075

Epoch: 6| Step: 10
Training loss: 0.8167617917060852
Validation loss: 1.843963662783305

Epoch: 6| Step: 11
Training loss: 0.6029273867607117
Validation loss: 1.862334998705054

Epoch: 6| Step: 12
Training loss: 0.8535797595977783
Validation loss: 1.8696611876128821

Epoch: 6| Step: 13
Training loss: 0.9852777123451233
Validation loss: 1.8488541021141955

Epoch: 201| Step: 0
Training loss: 0.6629599332809448
Validation loss: 1.8431051982346403

Epoch: 6| Step: 1
Training loss: 0.792746901512146
Validation loss: 1.8455273053979362

Epoch: 6| Step: 2
Training loss: 1.0712766647338867
Validation loss: 1.8360875088681456

Epoch: 6| Step: 3
Training loss: 0.5549545288085938
Validation loss: 1.8285818945976995

Epoch: 6| Step: 4
Training loss: 0.6318830847740173
Validation loss: 1.8249347338112452

Epoch: 6| Step: 5
Training loss: 0.776687502861023
Validation loss: 1.802789706055836

Epoch: 6| Step: 6
Training loss: 0.8177518844604492
Validation loss: 1.812347686418923

Epoch: 6| Step: 7
Training loss: 0.7874071002006531
Validation loss: 1.7895119382489113

Epoch: 6| Step: 8
Training loss: 0.9927201271057129
Validation loss: 1.8002336755875619

Epoch: 6| Step: 9
Training loss: 1.2365379333496094
Validation loss: 1.8289120735660676

Epoch: 6| Step: 10
Training loss: 0.5106518268585205
Validation loss: 1.8060592374493998

Epoch: 6| Step: 11
Training loss: 0.6736323833465576
Validation loss: 1.8257468746554466

Epoch: 6| Step: 12
Training loss: 0.7357949018478394
Validation loss: 1.8460546180766115

Epoch: 6| Step: 13
Training loss: 0.6747702360153198
Validation loss: 1.825189257180819

Epoch: 202| Step: 0
Training loss: 0.5322229266166687
Validation loss: 1.8320152323733094

Epoch: 6| Step: 1
Training loss: 0.5812956094741821
Validation loss: 1.8231558287015526

Epoch: 6| Step: 2
Training loss: 1.1073232889175415
Validation loss: 1.818092853792252

Epoch: 6| Step: 3
Training loss: 1.0033310651779175
Validation loss: 1.8082806179600377

Epoch: 6| Step: 4
Training loss: 0.7923451662063599
Validation loss: 1.7959129169423094

Epoch: 6| Step: 5
Training loss: 0.886366605758667
Validation loss: 1.815216213144282

Epoch: 6| Step: 6
Training loss: 0.8163312673568726
Validation loss: 1.7873940237106816

Epoch: 6| Step: 7
Training loss: 0.7626386880874634
Validation loss: 1.8176008475724088

Epoch: 6| Step: 8
Training loss: 0.41504621505737305
Validation loss: 1.7900508578105638

Epoch: 6| Step: 9
Training loss: 0.7015351057052612
Validation loss: 1.7771626236618205

Epoch: 6| Step: 10
Training loss: 0.44853702187538147
Validation loss: 1.7933697892773537

Epoch: 6| Step: 11
Training loss: 0.7567490339279175
Validation loss: 1.8093710817316526

Epoch: 6| Step: 12
Training loss: 1.1418722867965698
Validation loss: 1.8040791044953048

Epoch: 6| Step: 13
Training loss: 0.8007004857063293
Validation loss: 1.8155581951141357

Epoch: 203| Step: 0
Training loss: 0.7596026659011841
Validation loss: 1.8030215386421449

Epoch: 6| Step: 1
Training loss: 0.862930178642273
Validation loss: 1.8032384226399083

Epoch: 6| Step: 2
Training loss: 0.8712385296821594
Validation loss: 1.8035832887054772

Epoch: 6| Step: 3
Training loss: 0.5448158979415894
Validation loss: 1.826899193948315

Epoch: 6| Step: 4
Training loss: 0.7963885068893433
Validation loss: 1.855206533144879

Epoch: 6| Step: 5
Training loss: 1.0070152282714844
Validation loss: 1.8233210835405576

Epoch: 6| Step: 6
Training loss: 0.7379621267318726
Validation loss: 1.8287965777099773

Epoch: 6| Step: 7
Training loss: 0.6020256280899048
Validation loss: 1.8472182122609948

Epoch: 6| Step: 8
Training loss: 0.6798920035362244
Validation loss: 1.83487045380377

Epoch: 6| Step: 9
Training loss: 0.9949062466621399
Validation loss: 1.8207806464164489

Epoch: 6| Step: 10
Training loss: 0.7659786939620972
Validation loss: 1.800358881232559

Epoch: 6| Step: 11
Training loss: 0.4205710291862488
Validation loss: 1.8206280226348548

Epoch: 6| Step: 12
Training loss: 1.0038259029388428
Validation loss: 1.8143769707731021

Epoch: 6| Step: 13
Training loss: 0.34487608075141907
Validation loss: 1.799210040800033

Epoch: 204| Step: 0
Training loss: 0.5609868764877319
Validation loss: 1.7946842178221671

Epoch: 6| Step: 1
Training loss: 1.1029760837554932
Validation loss: 1.8060343291169854

Epoch: 6| Step: 2
Training loss: 0.6731102466583252
Validation loss: 1.8232944691053001

Epoch: 6| Step: 3
Training loss: 0.865015983581543
Validation loss: 1.8184358817274853

Epoch: 6| Step: 4
Training loss: 0.692535400390625
Validation loss: 1.8222199652784614

Epoch: 6| Step: 5
Training loss: 0.9542436599731445
Validation loss: 1.8163009599972797

Epoch: 6| Step: 6
Training loss: 0.8641598224639893
Validation loss: 1.8180393672758532

Epoch: 6| Step: 7
Training loss: 0.6550766229629517
Validation loss: 1.829949672504138

Epoch: 6| Step: 8
Training loss: 0.6843641996383667
Validation loss: 1.8265147644986388

Epoch: 6| Step: 9
Training loss: 0.41661280393600464
Validation loss: 1.8583546735907113

Epoch: 6| Step: 10
Training loss: 1.0490344762802124
Validation loss: 1.8423629076250139

Epoch: 6| Step: 11
Training loss: 0.5588480234146118
Validation loss: 1.8320971278734104

Epoch: 6| Step: 12
Training loss: 0.6489212512969971
Validation loss: 1.8350123167037964

Epoch: 6| Step: 13
Training loss: 1.0354945659637451
Validation loss: 1.8290638462189706

Epoch: 205| Step: 0
Training loss: 0.9936500787734985
Validation loss: 1.7976883483189408

Epoch: 6| Step: 1
Training loss: 0.4582093358039856
Validation loss: 1.7895539934917162

Epoch: 6| Step: 2
Training loss: 0.500458836555481
Validation loss: 1.7794431050618489

Epoch: 6| Step: 3
Training loss: 0.7292205095291138
Validation loss: 1.7725433790555565

Epoch: 6| Step: 4
Training loss: 0.5075675845146179
Validation loss: 1.7839356301933207

Epoch: 6| Step: 5
Training loss: 0.5124268531799316
Validation loss: 1.7583941849329139

Epoch: 6| Step: 6
Training loss: 0.7182444930076599
Validation loss: 1.7733062787722516

Epoch: 6| Step: 7
Training loss: 0.8432204127311707
Validation loss: 1.7762810978838193

Epoch: 6| Step: 8
Training loss: 0.8051543235778809
Validation loss: 1.80186745812816

Epoch: 6| Step: 9
Training loss: 0.8905972242355347
Validation loss: 1.8162386443025322

Epoch: 6| Step: 10
Training loss: 0.9740535020828247
Validation loss: 1.8051789858007943

Epoch: 6| Step: 11
Training loss: 0.7626320719718933
Validation loss: 1.8501949143666092

Epoch: 6| Step: 12
Training loss: 0.661522626876831
Validation loss: 1.8252738816763765

Epoch: 6| Step: 13
Training loss: 0.8285546898841858
Validation loss: 1.8184284651151268

Epoch: 206| Step: 0
Training loss: 0.5791895389556885
Validation loss: 1.8063766059055124

Epoch: 6| Step: 1
Training loss: 0.6221387982368469
Validation loss: 1.8216351001493392

Epoch: 6| Step: 2
Training loss: 0.9803546071052551
Validation loss: 1.8193946217977872

Epoch: 6| Step: 3
Training loss: 0.578609049320221
Validation loss: 1.8442114937689997

Epoch: 6| Step: 4
Training loss: 0.8912776708602905
Validation loss: 1.828421829849161

Epoch: 6| Step: 5
Training loss: 0.44603630900382996
Validation loss: 1.8282036255764704

Epoch: 6| Step: 6
Training loss: 0.7214422225952148
Validation loss: 1.8303262085042975

Epoch: 6| Step: 7
Training loss: 0.9440748691558838
Validation loss: 1.8260472577105287

Epoch: 6| Step: 8
Training loss: 0.8549937605857849
Validation loss: 1.8259750412356468

Epoch: 6| Step: 9
Training loss: 0.8172135353088379
Validation loss: 1.8282397011274933

Epoch: 6| Step: 10
Training loss: 0.7176124453544617
Validation loss: 1.8124562207088675

Epoch: 6| Step: 11
Training loss: 0.8269391059875488
Validation loss: 1.835519177939302

Epoch: 6| Step: 12
Training loss: 0.655096173286438
Validation loss: 1.8388400564911545

Epoch: 6| Step: 13
Training loss: 0.9181864261627197
Validation loss: 1.851899016288019

Epoch: 207| Step: 0
Training loss: 0.8901108503341675
Validation loss: 1.8313564292846187

Epoch: 6| Step: 1
Training loss: 0.5536741614341736
Validation loss: 1.8158921195614723

Epoch: 6| Step: 2
Training loss: 0.5388538837432861
Validation loss: 1.7932056368038218

Epoch: 6| Step: 3
Training loss: 0.5938142538070679
Validation loss: 1.7980054552837084

Epoch: 6| Step: 4
Training loss: 0.7151021361351013
Validation loss: 1.7750559032604258

Epoch: 6| Step: 5
Training loss: 1.1654179096221924
Validation loss: 1.7797984717994608

Epoch: 6| Step: 6
Training loss: 0.48094895482063293
Validation loss: 1.771693968003796

Epoch: 6| Step: 7
Training loss: 0.4593973755836487
Validation loss: 1.79590323791709

Epoch: 6| Step: 8
Training loss: 0.7220544815063477
Validation loss: 1.8151412138374903

Epoch: 6| Step: 9
Training loss: 0.8035041093826294
Validation loss: 1.7976963327777

Epoch: 6| Step: 10
Training loss: 0.6694246530532837
Validation loss: 1.8116690471608152

Epoch: 6| Step: 11
Training loss: 0.824261486530304
Validation loss: 1.785095137934531

Epoch: 6| Step: 12
Training loss: 1.005277395248413
Validation loss: 1.7933735975655176

Epoch: 6| Step: 13
Training loss: 1.0902411937713623
Validation loss: 1.769696722748459

Epoch: 208| Step: 0
Training loss: 1.1870704889297485
Validation loss: 1.7856469320994552

Epoch: 6| Step: 1
Training loss: 0.8202789425849915
Validation loss: 1.7755110584279543

Epoch: 6| Step: 2
Training loss: 0.9074424505233765
Validation loss: 1.7733142568219094

Epoch: 6| Step: 3
Training loss: 0.5777172446250916
Validation loss: 1.781334251485845

Epoch: 6| Step: 4
Training loss: 0.488614559173584
Validation loss: 1.7673137021321121

Epoch: 6| Step: 5
Training loss: 0.8585095405578613
Validation loss: 1.7631613028946744

Epoch: 6| Step: 6
Training loss: 0.8341190814971924
Validation loss: 1.7624639541872087

Epoch: 6| Step: 7
Training loss: 0.7893847227096558
Validation loss: 1.741912644396546

Epoch: 6| Step: 8
Training loss: 0.3200382590293884
Validation loss: 1.7453224633329658

Epoch: 6| Step: 9
Training loss: 0.6443074345588684
Validation loss: 1.7513962663630003

Epoch: 6| Step: 10
Training loss: 0.5113430023193359
Validation loss: 1.735645906899565

Epoch: 6| Step: 11
Training loss: 0.4537432789802551
Validation loss: 1.7524596850077312

Epoch: 6| Step: 12
Training loss: 0.6018686294555664
Validation loss: 1.7573996731030044

Epoch: 6| Step: 13
Training loss: 0.7008655071258545
Validation loss: 1.747297038314163

Epoch: 209| Step: 0
Training loss: 0.8706412315368652
Validation loss: 1.752212211649905

Epoch: 6| Step: 1
Training loss: 0.40020668506622314
Validation loss: 1.7514525575022544

Epoch: 6| Step: 2
Training loss: 0.9012887477874756
Validation loss: 1.7599706149870349

Epoch: 6| Step: 3
Training loss: 0.9217244982719421
Validation loss: 1.7523266205223658

Epoch: 6| Step: 4
Training loss: 0.6815296411514282
Validation loss: 1.7544900217363912

Epoch: 6| Step: 5
Training loss: 0.9713720679283142
Validation loss: 1.7522164801115632

Epoch: 6| Step: 6
Training loss: 0.40916213393211365
Validation loss: 1.7551242472023092

Epoch: 6| Step: 7
Training loss: 0.5819078683853149
Validation loss: 1.763154032409832

Epoch: 6| Step: 8
Training loss: 0.6664158701896667
Validation loss: 1.748393533050373

Epoch: 6| Step: 9
Training loss: 0.9853024482727051
Validation loss: 1.7531646797733922

Epoch: 6| Step: 10
Training loss: 0.7889007925987244
Validation loss: 1.7521001100540161

Epoch: 6| Step: 11
Training loss: 0.5598422288894653
Validation loss: 1.764494865171371

Epoch: 6| Step: 12
Training loss: 0.33771318197250366
Validation loss: 1.7728311528441727

Epoch: 6| Step: 13
Training loss: 0.38389673829078674
Validation loss: 1.785299736966369

Epoch: 210| Step: 0
Training loss: 0.4459436535835266
Validation loss: 1.7930729325099657

Epoch: 6| Step: 1
Training loss: 0.5270248651504517
Validation loss: 1.8115555368443972

Epoch: 6| Step: 2
Training loss: 0.6942656636238098
Validation loss: 1.7886552285122614

Epoch: 6| Step: 3
Training loss: 0.9326655864715576
Validation loss: 1.7889420524720223

Epoch: 6| Step: 4
Training loss: 0.9776368141174316
Validation loss: 1.802107435400768

Epoch: 6| Step: 5
Training loss: 0.7660046815872192
Validation loss: 1.7790446640342794

Epoch: 6| Step: 6
Training loss: 0.8132262229919434
Validation loss: 1.795323114241323

Epoch: 6| Step: 7
Training loss: 0.3817753493785858
Validation loss: 1.7858128868123537

Epoch: 6| Step: 8
Training loss: 0.46758031845092773
Validation loss: 1.7679515423313263

Epoch: 6| Step: 9
Training loss: 0.988455057144165
Validation loss: 1.754030018724421

Epoch: 6| Step: 10
Training loss: 0.633263349533081
Validation loss: 1.743726566273679

Epoch: 6| Step: 11
Training loss: 0.5646959543228149
Validation loss: 1.7460556491728751

Epoch: 6| Step: 12
Training loss: 0.4562922716140747
Validation loss: 1.753980376387155

Epoch: 6| Step: 13
Training loss: 0.547514021396637
Validation loss: 1.7543203023172194

Epoch: 211| Step: 0
Training loss: 0.5642635822296143
Validation loss: 1.7636109154711488

Epoch: 6| Step: 1
Training loss: 0.539223849773407
Validation loss: 1.776548393311039

Epoch: 6| Step: 2
Training loss: 0.8589386343955994
Validation loss: 1.7591662817103888

Epoch: 6| Step: 3
Training loss: 0.6570154428482056
Validation loss: 1.8074447275489889

Epoch: 6| Step: 4
Training loss: 0.8143341541290283
Validation loss: 1.810965512388496

Epoch: 6| Step: 5
Training loss: 0.9520242214202881
Validation loss: 1.8051686376653693

Epoch: 6| Step: 6
Training loss: 1.0138874053955078
Validation loss: 1.803776494918331

Epoch: 6| Step: 7
Training loss: 0.5149272680282593
Validation loss: 1.8019836243762766

Epoch: 6| Step: 8
Training loss: 0.45201024413108826
Validation loss: 1.7839432019059376

Epoch: 6| Step: 9
Training loss: 0.4336163103580475
Validation loss: 1.7603276916729507

Epoch: 6| Step: 10
Training loss: 0.6675041913986206
Validation loss: 1.7577329912493307

Epoch: 6| Step: 11
Training loss: 0.5605637431144714
Validation loss: 1.7928157032177012

Epoch: 6| Step: 12
Training loss: 0.6204549074172974
Validation loss: 1.7706961144683182

Epoch: 6| Step: 13
Training loss: 0.7970271706581116
Validation loss: 1.7764922482993013

Epoch: 212| Step: 0
Training loss: 0.5704144239425659
Validation loss: 1.7747300709447553

Epoch: 6| Step: 1
Training loss: 1.0861715078353882
Validation loss: 1.7802701406581427

Epoch: 6| Step: 2
Training loss: 0.4642322361469269
Validation loss: 1.7827016768916961

Epoch: 6| Step: 3
Training loss: 0.8133120536804199
Validation loss: 1.7868123003231582

Epoch: 6| Step: 4
Training loss: 0.7023528814315796
Validation loss: 1.786700992174046

Epoch: 6| Step: 5
Training loss: 0.5955742597579956
Validation loss: 1.8227536755223428

Epoch: 6| Step: 6
Training loss: 0.35570716857910156
Validation loss: 1.7976298870578888

Epoch: 6| Step: 7
Training loss: 0.6968183517456055
Validation loss: 1.7919128748678392

Epoch: 6| Step: 8
Training loss: 0.7030890583992004
Validation loss: 1.7823547701681814

Epoch: 6| Step: 9
Training loss: 0.44390326738357544
Validation loss: 1.788645193140994

Epoch: 6| Step: 10
Training loss: 0.8606096506118774
Validation loss: 1.783002576520366

Epoch: 6| Step: 11
Training loss: 0.6342499852180481
Validation loss: 1.801128372069328

Epoch: 6| Step: 12
Training loss: 0.6227003335952759
Validation loss: 1.8051451354898431

Epoch: 6| Step: 13
Training loss: 0.7025583386421204
Validation loss: 1.787297171931113

Epoch: 213| Step: 0
Training loss: 0.6609885096549988
Validation loss: 1.7715920748249177

Epoch: 6| Step: 1
Training loss: 0.5223507285118103
Validation loss: 1.7618229517372705

Epoch: 6| Step: 2
Training loss: 0.44777771830558777
Validation loss: 1.753121570874286

Epoch: 6| Step: 3
Training loss: 0.6806082129478455
Validation loss: 1.7548730629746632

Epoch: 6| Step: 4
Training loss: 0.5746974945068359
Validation loss: 1.760073410567417

Epoch: 6| Step: 5
Training loss: 0.5603554248809814
Validation loss: 1.7647184838530838

Epoch: 6| Step: 6
Training loss: 0.9473977088928223
Validation loss: 1.7532706593954435

Epoch: 6| Step: 7
Training loss: 0.5785632729530334
Validation loss: 1.753226641685732

Epoch: 6| Step: 8
Training loss: 0.5061310529708862
Validation loss: 1.7365058058051652

Epoch: 6| Step: 9
Training loss: 0.8240684270858765
Validation loss: 1.7467042246172506

Epoch: 6| Step: 10
Training loss: 0.7266068458557129
Validation loss: 1.725970470777122

Epoch: 6| Step: 11
Training loss: 0.777824878692627
Validation loss: 1.7542495246856444

Epoch: 6| Step: 12
Training loss: 0.47202616930007935
Validation loss: 1.740669677334447

Epoch: 6| Step: 13
Training loss: 0.6602808833122253
Validation loss: 1.7500349642128072

Epoch: 214| Step: 0
Training loss: 0.545474648475647
Validation loss: 1.7746983433282504

Epoch: 6| Step: 1
Training loss: 0.4166991412639618
Validation loss: 1.7896302874370287

Epoch: 6| Step: 2
Training loss: 0.6135762333869934
Validation loss: 1.7732063544693815

Epoch: 6| Step: 3
Training loss: 0.8209015727043152
Validation loss: 1.7992659127840431

Epoch: 6| Step: 4
Training loss: 0.551621675491333
Validation loss: 1.7736367666593162

Epoch: 6| Step: 5
Training loss: 0.5323162078857422
Validation loss: 1.7730573172210364

Epoch: 6| Step: 6
Training loss: 0.6573216319084167
Validation loss: 1.7810426514635804

Epoch: 6| Step: 7
Training loss: 0.5652030110359192
Validation loss: 1.7766345342000325

Epoch: 6| Step: 8
Training loss: 0.6995399594306946
Validation loss: 1.7840715236561273

Epoch: 6| Step: 9
Training loss: 0.4752383828163147
Validation loss: 1.7567243870868479

Epoch: 6| Step: 10
Training loss: 0.6661087274551392
Validation loss: 1.7650514059169318

Epoch: 6| Step: 11
Training loss: 0.6308407783508301
Validation loss: 1.7811633156191917

Epoch: 6| Step: 12
Training loss: 0.9740105867385864
Validation loss: 1.7759199603911369

Epoch: 6| Step: 13
Training loss: 0.882758378982544
Validation loss: 1.7921892942920807

Epoch: 215| Step: 0
Training loss: 0.672888994216919
Validation loss: 1.7797900707490983

Epoch: 6| Step: 1
Training loss: 0.38340574502944946
Validation loss: 1.7425669880323513

Epoch: 6| Step: 2
Training loss: 0.6423779726028442
Validation loss: 1.749444297564927

Epoch: 6| Step: 3
Training loss: 0.6181647777557373
Validation loss: 1.7679164230182607

Epoch: 6| Step: 4
Training loss: 0.5009171962738037
Validation loss: 1.7578548628796813

Epoch: 6| Step: 5
Training loss: 0.5265916585922241
Validation loss: 1.7726252220010246

Epoch: 6| Step: 6
Training loss: 0.6276528835296631
Validation loss: 1.776231796510758

Epoch: 6| Step: 7
Training loss: 0.6721112132072449
Validation loss: 1.798289034956245

Epoch: 6| Step: 8
Training loss: 0.5856668949127197
Validation loss: 1.8278159736305155

Epoch: 6| Step: 9
Training loss: 0.6286203861236572
Validation loss: 1.8399730677245765

Epoch: 6| Step: 10
Training loss: 0.67815101146698
Validation loss: 1.8585124297808575

Epoch: 6| Step: 11
Training loss: 0.8858582377433777
Validation loss: 1.836431610968805

Epoch: 6| Step: 12
Training loss: 1.2171083688735962
Validation loss: 1.838975873044742

Epoch: 6| Step: 13
Training loss: 0.33004119992256165
Validation loss: 1.832563377195789

Epoch: 216| Step: 0
Training loss: 0.5445096492767334
Validation loss: 1.8033518880926154

Epoch: 6| Step: 1
Training loss: 0.6335420608520508
Validation loss: 1.7919807075172343

Epoch: 6| Step: 2
Training loss: 0.6324896812438965
Validation loss: 1.7811229382791827

Epoch: 6| Step: 3
Training loss: 0.7163077592849731
Validation loss: 1.758027934258984

Epoch: 6| Step: 4
Training loss: 0.2850019931793213
Validation loss: 1.737713066480493

Epoch: 6| Step: 5
Training loss: 0.5592165589332581
Validation loss: 1.7395898372896257

Epoch: 6| Step: 6
Training loss: 0.7976442575454712
Validation loss: 1.7488572084775535

Epoch: 6| Step: 7
Training loss: 0.3446442484855652
Validation loss: 1.7517551773337907

Epoch: 6| Step: 8
Training loss: 0.4863312542438507
Validation loss: 1.7237999682785363

Epoch: 6| Step: 9
Training loss: 0.6855194568634033
Validation loss: 1.7370455008681103

Epoch: 6| Step: 10
Training loss: 0.7647644281387329
Validation loss: 1.7505131780460317

Epoch: 6| Step: 11
Training loss: 0.6964466571807861
Validation loss: 1.7478205414228543

Epoch: 6| Step: 12
Training loss: 0.6918789148330688
Validation loss: 1.7302035054852885

Epoch: 6| Step: 13
Training loss: 1.0600825548171997
Validation loss: 1.7372428114696215

Epoch: 217| Step: 0
Training loss: 0.6911100149154663
Validation loss: 1.7362867324582991

Epoch: 6| Step: 1
Training loss: 0.9305999875068665
Validation loss: 1.7418108710678675

Epoch: 6| Step: 2
Training loss: 0.4652939438819885
Validation loss: 1.7301896797713412

Epoch: 6| Step: 3
Training loss: 0.439873605966568
Validation loss: 1.7258573411613383

Epoch: 6| Step: 4
Training loss: 0.5227192640304565
Validation loss: 1.7199930978077713

Epoch: 6| Step: 5
Training loss: 0.7363438010215759
Validation loss: 1.7230440173097836

Epoch: 6| Step: 6
Training loss: 0.5408183932304382
Validation loss: 1.6986945649628997

Epoch: 6| Step: 7
Training loss: 0.3619115650653839
Validation loss: 1.707240209784559

Epoch: 6| Step: 8
Training loss: 0.7340137362480164
Validation loss: 1.7089733000724547

Epoch: 6| Step: 9
Training loss: 0.2716332674026489
Validation loss: 1.692481743392124

Epoch: 6| Step: 10
Training loss: 0.7295923829078674
Validation loss: 1.7356747722113004

Epoch: 6| Step: 11
Training loss: 0.9173328876495361
Validation loss: 1.7098110721957298

Epoch: 6| Step: 12
Training loss: 0.6402357816696167
Validation loss: 1.7450822220053723

Epoch: 6| Step: 13
Training loss: 0.5636485815048218
Validation loss: 1.7469970154505905

Epoch: 218| Step: 0
Training loss: 0.5905748009681702
Validation loss: 1.7336395017562374

Epoch: 6| Step: 1
Training loss: 0.6326556205749512
Validation loss: 1.730429708316762

Epoch: 6| Step: 2
Training loss: 0.8624212741851807
Validation loss: 1.7337072895419212

Epoch: 6| Step: 3
Training loss: 0.46121445298194885
Validation loss: 1.7310641286193684

Epoch: 6| Step: 4
Training loss: 0.30471718311309814
Validation loss: 1.7357094608327395

Epoch: 6| Step: 5
Training loss: 0.47594720125198364
Validation loss: 1.7243838399969122

Epoch: 6| Step: 6
Training loss: 0.4459265172481537
Validation loss: 1.7736456214740712

Epoch: 6| Step: 7
Training loss: 0.5807739496231079
Validation loss: 1.774226423232786

Epoch: 6| Step: 8
Training loss: 0.5456594824790955
Validation loss: 1.7569836531915972

Epoch: 6| Step: 9
Training loss: 0.6161954998970032
Validation loss: 1.7771935847497755

Epoch: 6| Step: 10
Training loss: 0.7569431066513062
Validation loss: 1.757228797481906

Epoch: 6| Step: 11
Training loss: 0.8718822598457336
Validation loss: 1.746500817678308

Epoch: 6| Step: 12
Training loss: 0.9227823615074158
Validation loss: 1.7574713717224777

Epoch: 6| Step: 13
Training loss: 0.4613291323184967
Validation loss: 1.717468072009343

Epoch: 219| Step: 0
Training loss: 0.24791184067726135
Validation loss: 1.723841913284794

Epoch: 6| Step: 1
Training loss: 0.4923171103000641
Validation loss: 1.718291962018577

Epoch: 6| Step: 2
Training loss: 0.8074156045913696
Validation loss: 1.7205331312712802

Epoch: 6| Step: 3
Training loss: 0.5253866314888
Validation loss: 1.7090771249545518

Epoch: 6| Step: 4
Training loss: 0.4283290505409241
Validation loss: 1.7240846105801162

Epoch: 6| Step: 5
Training loss: 0.8339227437973022
Validation loss: 1.7268239041810394

Epoch: 6| Step: 6
Training loss: 0.2989206314086914
Validation loss: 1.7137429534748037

Epoch: 6| Step: 7
Training loss: 0.4720956087112427
Validation loss: 1.7159131996093258

Epoch: 6| Step: 8
Training loss: 0.9284124374389648
Validation loss: 1.6922934414238058

Epoch: 6| Step: 9
Training loss: 0.5858410000801086
Validation loss: 1.7301077765803183

Epoch: 6| Step: 10
Training loss: 0.6849251985549927
Validation loss: 1.7449010982308337

Epoch: 6| Step: 11
Training loss: 0.5295883417129517
Validation loss: 1.7591591214620939

Epoch: 6| Step: 12
Training loss: 0.755615234375
Validation loss: 1.771259464243407

Epoch: 6| Step: 13
Training loss: 0.395145982503891
Validation loss: 1.7599118986437399

Epoch: 220| Step: 0
Training loss: 0.6735352277755737
Validation loss: 1.7625546583565332

Epoch: 6| Step: 1
Training loss: 0.7838394641876221
Validation loss: 1.7600499506919616

Epoch: 6| Step: 2
Training loss: 0.4916941225528717
Validation loss: 1.733044873001755

Epoch: 6| Step: 3
Training loss: 0.3502258062362671
Validation loss: 1.7504831270505024

Epoch: 6| Step: 4
Training loss: 0.7698447704315186
Validation loss: 1.7142905804418749

Epoch: 6| Step: 5
Training loss: 0.5111674070358276
Validation loss: 1.7060217421541932

Epoch: 6| Step: 6
Training loss: 0.36200469732284546
Validation loss: 1.7122208931112801

Epoch: 6| Step: 7
Training loss: 0.6662307381629944
Validation loss: 1.6962689981665662

Epoch: 6| Step: 8
Training loss: 0.5729740858078003
Validation loss: 1.6866410842505835

Epoch: 6| Step: 9
Training loss: 0.35938990116119385
Validation loss: 1.690615479664136

Epoch: 6| Step: 10
Training loss: 0.8692027926445007
Validation loss: 1.6793472574603172

Epoch: 6| Step: 11
Training loss: 0.4820706844329834
Validation loss: 1.6922788748177149

Epoch: 6| Step: 12
Training loss: 0.6261577010154724
Validation loss: 1.6824186207145773

Epoch: 6| Step: 13
Training loss: 0.4757005274295807
Validation loss: 1.6586363546309932

Epoch: 221| Step: 0
Training loss: 0.2317453920841217
Validation loss: 1.6830958627885388

Epoch: 6| Step: 1
Training loss: 0.5423639416694641
Validation loss: 1.723763205671823

Epoch: 6| Step: 2
Training loss: 0.5603736639022827
Validation loss: 1.7128496990408948

Epoch: 6| Step: 3
Training loss: 0.803558349609375
Validation loss: 1.7308314359316261

Epoch: 6| Step: 4
Training loss: 0.8846813440322876
Validation loss: 1.6921795183612454

Epoch: 6| Step: 5
Training loss: 0.4020909070968628
Validation loss: 1.678786877662905

Epoch: 6| Step: 6
Training loss: 0.6355907917022705
Validation loss: 1.6597561579878612

Epoch: 6| Step: 7
Training loss: 0.6578963994979858
Validation loss: 1.6430868564113494

Epoch: 6| Step: 8
Training loss: 0.4305162727832794
Validation loss: 1.6645726170591129

Epoch: 6| Step: 9
Training loss: 0.4129130244255066
Validation loss: 1.6689871203514837

Epoch: 6| Step: 10
Training loss: 0.5702164173126221
Validation loss: 1.6816082398096721

Epoch: 6| Step: 11
Training loss: 0.5639247894287109
Validation loss: 1.6773050626118977

Epoch: 6| Step: 12
Training loss: 0.8226330876350403
Validation loss: 1.680213535985639

Epoch: 6| Step: 13
Training loss: 0.884912371635437
Validation loss: 1.6693319851352322

Epoch: 222| Step: 0
Training loss: 0.6137079000473022
Validation loss: 1.6769136664687947

Epoch: 6| Step: 1
Training loss: 0.7575601935386658
Validation loss: 1.6951178760938748

Epoch: 6| Step: 2
Training loss: 0.6556941270828247
Validation loss: 1.7023248557121522

Epoch: 6| Step: 3
Training loss: 0.3908156454563141
Validation loss: 1.768821043352927

Epoch: 6| Step: 4
Training loss: 0.7954663634300232
Validation loss: 1.7552234562494422

Epoch: 6| Step: 5
Training loss: 0.5141767859458923
Validation loss: 1.740967478803409

Epoch: 6| Step: 6
Training loss: 0.39456117153167725
Validation loss: 1.7235843032918952

Epoch: 6| Step: 7
Training loss: 0.2803910970687866
Validation loss: 1.698673653346236

Epoch: 6| Step: 8
Training loss: 0.5134109854698181
Validation loss: 1.685741521978891

Epoch: 6| Step: 9
Training loss: 0.980631411075592
Validation loss: 1.711117552172753

Epoch: 6| Step: 10
Training loss: 0.631690263748169
Validation loss: 1.7459687276553082

Epoch: 6| Step: 11
Training loss: 0.4353940784931183
Validation loss: 1.7027790495144424

Epoch: 6| Step: 12
Training loss: 0.5576938390731812
Validation loss: 1.6733958951888546

Epoch: 6| Step: 13
Training loss: 0.847241997718811
Validation loss: 1.703513865829796

Epoch: 223| Step: 0
Training loss: 0.5436114072799683
Validation loss: 1.713537880169448

Epoch: 6| Step: 1
Training loss: 0.5108559727668762
Validation loss: 1.7275535252786451

Epoch: 6| Step: 2
Training loss: 0.37673136591911316
Validation loss: 1.746516977587054

Epoch: 6| Step: 3
Training loss: 0.33893686532974243
Validation loss: 1.7689651571294314

Epoch: 6| Step: 4
Training loss: 0.7455602884292603
Validation loss: 1.8006481252690798

Epoch: 6| Step: 5
Training loss: 0.30037689208984375
Validation loss: 1.7714250562011555

Epoch: 6| Step: 6
Training loss: 0.6420039534568787
Validation loss: 1.7754713027707991

Epoch: 6| Step: 7
Training loss: 0.5410927534103394
Validation loss: 1.7739117888994114

Epoch: 6| Step: 8
Training loss: 0.5278266668319702
Validation loss: 1.7615519159583635

Epoch: 6| Step: 9
Training loss: 0.6869863271713257
Validation loss: 1.7709049114616968

Epoch: 6| Step: 10
Training loss: 0.8300352096557617
Validation loss: 1.7287660003990255

Epoch: 6| Step: 11
Training loss: 0.43855875730514526
Validation loss: 1.727718028970944

Epoch: 6| Step: 12
Training loss: 0.763228178024292
Validation loss: 1.7264928689566992

Epoch: 6| Step: 13
Training loss: 0.46951887011528015
Validation loss: 1.7093688570043093

Epoch: 224| Step: 0
Training loss: 0.6071224808692932
Validation loss: 1.7217530037767144

Epoch: 6| Step: 1
Training loss: 0.767745852470398
Validation loss: 1.6889289386810795

Epoch: 6| Step: 2
Training loss: 0.37295234203338623
Validation loss: 1.7114152216142224

Epoch: 6| Step: 3
Training loss: 0.7288492321968079
Validation loss: 1.6858993384145922

Epoch: 6| Step: 4
Training loss: 0.31847625970840454
Validation loss: 1.6943691469007922

Epoch: 6| Step: 5
Training loss: 0.7241930365562439
Validation loss: 1.7126279428441038

Epoch: 6| Step: 6
Training loss: 0.4240252375602722
Validation loss: 1.702480931435862

Epoch: 6| Step: 7
Training loss: 0.48692986369132996
Validation loss: 1.688431228360822

Epoch: 6| Step: 8
Training loss: 0.40806880593299866
Validation loss: 1.686873366755824

Epoch: 6| Step: 9
Training loss: 0.4053136706352234
Validation loss: 1.7086615370165916

Epoch: 6| Step: 10
Training loss: 0.6453773975372314
Validation loss: 1.7387278208168604

Epoch: 6| Step: 11
Training loss: 0.5138158798217773
Validation loss: 1.7351834645835302

Epoch: 6| Step: 12
Training loss: 0.5438039302825928
Validation loss: 1.7163547379996187

Epoch: 6| Step: 13
Training loss: 0.7300167083740234
Validation loss: 1.7495780170604747

Epoch: 225| Step: 0
Training loss: 0.58390212059021
Validation loss: 1.7416684678805772

Epoch: 6| Step: 1
Training loss: 0.9049102067947388
Validation loss: 1.7775837541908346

Epoch: 6| Step: 2
Training loss: 0.9930717945098877
Validation loss: 1.7878366093481741

Epoch: 6| Step: 3
Training loss: 0.40950626134872437
Validation loss: 1.767387761864611

Epoch: 6| Step: 4
Training loss: 0.5031976103782654
Validation loss: 1.713185469309489

Epoch: 6| Step: 5
Training loss: 0.30208611488342285
Validation loss: 1.69945647639613

Epoch: 6| Step: 6
Training loss: 0.5156604647636414
Validation loss: 1.6551940825677687

Epoch: 6| Step: 7
Training loss: 0.5279310941696167
Validation loss: 1.7058494296125186

Epoch: 6| Step: 8
Training loss: 0.5587689280509949
Validation loss: 1.6754578018701205

Epoch: 6| Step: 9
Training loss: 0.43476244807243347
Validation loss: 1.6859930663980462

Epoch: 6| Step: 10
Training loss: 0.6525391936302185
Validation loss: 1.6744928218985116

Epoch: 6| Step: 11
Training loss: 0.4959523677825928
Validation loss: 1.6616601341514177

Epoch: 6| Step: 12
Training loss: 0.2617400586605072
Validation loss: 1.6385856905291158

Epoch: 6| Step: 13
Training loss: 0.783385157585144
Validation loss: 1.6590045113717355

Epoch: 226| Step: 0
Training loss: 0.8451802134513855
Validation loss: 1.6540014859168761

Epoch: 6| Step: 1
Training loss: 0.526932954788208
Validation loss: 1.6455835911535448

Epoch: 6| Step: 2
Training loss: 0.6529446840286255
Validation loss: 1.6283418555413522

Epoch: 6| Step: 3
Training loss: 0.45495522022247314
Validation loss: 1.6669307895886

Epoch: 6| Step: 4
Training loss: 0.5590980648994446
Validation loss: 1.6703771032312864

Epoch: 6| Step: 5
Training loss: 0.668544352054596
Validation loss: 1.654956836854258

Epoch: 6| Step: 6
Training loss: 0.46777766942977905
Validation loss: 1.6726782129656883

Epoch: 6| Step: 7
Training loss: 0.33846089243888855
Validation loss: 1.6545971862731441

Epoch: 6| Step: 8
Training loss: 0.4064418077468872
Validation loss: 1.671502596588545

Epoch: 6| Step: 9
Training loss: 0.2601271867752075
Validation loss: 1.662494808114985

Epoch: 6| Step: 10
Training loss: 0.4570648670196533
Validation loss: 1.6922440439142206

Epoch: 6| Step: 11
Training loss: 0.30776888132095337
Validation loss: 1.6897544655748593

Epoch: 6| Step: 12
Training loss: 0.5177381038665771
Validation loss: 1.705625480221164

Epoch: 6| Step: 13
Training loss: 0.5761970281600952
Validation loss: 1.7174615090893162

Epoch: 227| Step: 0
Training loss: 0.5708808898925781
Validation loss: 1.700747339956222

Epoch: 6| Step: 1
Training loss: 0.35556313395500183
Validation loss: 1.7083681757732103

Epoch: 6| Step: 2
Training loss: 0.36954137682914734
Validation loss: 1.7308893742099885

Epoch: 6| Step: 3
Training loss: 0.47730565071105957
Validation loss: 1.7462317071935183

Epoch: 6| Step: 4
Training loss: 0.4917100965976715
Validation loss: 1.75453322164474

Epoch: 6| Step: 5
Training loss: 0.6595537662506104
Validation loss: 1.7162840609909387

Epoch: 6| Step: 6
Training loss: 0.5047982931137085
Validation loss: 1.7129587409316853

Epoch: 6| Step: 7
Training loss: 0.6083223819732666
Validation loss: 1.697248133279944

Epoch: 6| Step: 8
Training loss: 0.2628541588783264
Validation loss: 1.7063729583576162

Epoch: 6| Step: 9
Training loss: 0.5655987858772278
Validation loss: 1.6954932046192948

Epoch: 6| Step: 10
Training loss: 0.7313012480735779
Validation loss: 1.715142019333378

Epoch: 6| Step: 11
Training loss: 0.5527651309967041
Validation loss: 1.709053829152097

Epoch: 6| Step: 12
Training loss: 0.46617329120635986
Validation loss: 1.6808490727537422

Epoch: 6| Step: 13
Training loss: 0.4365237355232239
Validation loss: 1.673880857806052

Epoch: 228| Step: 0
Training loss: 0.5525550842285156
Validation loss: 1.6975981984087216

Epoch: 6| Step: 1
Training loss: 0.8235569000244141
Validation loss: 1.6965839529550204

Epoch: 6| Step: 2
Training loss: 0.5350767374038696
Validation loss: 1.6908742984135945

Epoch: 6| Step: 3
Training loss: 0.37314102053642273
Validation loss: 1.7101328783137824

Epoch: 6| Step: 4
Training loss: 0.5812257528305054
Validation loss: 1.7172824426363873

Epoch: 6| Step: 5
Training loss: 0.4556999206542969
Validation loss: 1.731733157429644

Epoch: 6| Step: 6
Training loss: 0.6230645179748535
Validation loss: 1.7362252102103284

Epoch: 6| Step: 7
Training loss: 0.5889139771461487
Validation loss: 1.7273811524914158

Epoch: 6| Step: 8
Training loss: 0.5124831795692444
Validation loss: 1.7232104603962233

Epoch: 6| Step: 9
Training loss: 0.5532277226448059
Validation loss: 1.6935038412770917

Epoch: 6| Step: 10
Training loss: 0.32719504833221436
Validation loss: 1.7019150090473953

Epoch: 6| Step: 11
Training loss: 0.44206327199935913
Validation loss: 1.7124506568395963

Epoch: 6| Step: 12
Training loss: 0.6175506114959717
Validation loss: 1.6889988555703113

Epoch: 6| Step: 13
Training loss: 0.30924519896507263
Validation loss: 1.6856566180465042

Epoch: 229| Step: 0
Training loss: 0.4484218955039978
Validation loss: 1.6957349866949103

Epoch: 6| Step: 1
Training loss: 0.5264976024627686
Validation loss: 1.6902680781579786

Epoch: 6| Step: 2
Training loss: 0.6055449843406677
Validation loss: 1.7322549755855272

Epoch: 6| Step: 3
Training loss: 0.46662983298301697
Validation loss: 1.7206378585548812

Epoch: 6| Step: 4
Training loss: 0.5424671173095703
Validation loss: 1.7117811749058385

Epoch: 6| Step: 5
Training loss: 0.2859705090522766
Validation loss: 1.713197305638303

Epoch: 6| Step: 6
Training loss: 0.7611546516418457
Validation loss: 1.7094729472232122

Epoch: 6| Step: 7
Training loss: 0.6019026041030884
Validation loss: 1.7197274072195894

Epoch: 6| Step: 8
Training loss: 0.5793755054473877
Validation loss: 1.7040183313431279

Epoch: 6| Step: 9
Training loss: 0.36231744289398193
Validation loss: 1.7263303546495334

Epoch: 6| Step: 10
Training loss: 0.5066254734992981
Validation loss: 1.7032063904628958

Epoch: 6| Step: 11
Training loss: 0.4180232882499695
Validation loss: 1.7154419563149894

Epoch: 6| Step: 12
Training loss: 0.5804191827774048
Validation loss: 1.6963551044464111

Epoch: 6| Step: 13
Training loss: 0.5905030965805054
Validation loss: 1.6736594925644577

Epoch: 230| Step: 0
Training loss: 0.2663084864616394
Validation loss: 1.6583539465422272

Epoch: 6| Step: 1
Training loss: 0.38357987999916077
Validation loss: 1.6739141120705554

Epoch: 6| Step: 2
Training loss: 0.7381324768066406
Validation loss: 1.687486977987392

Epoch: 6| Step: 3
Training loss: 0.2993568480014801
Validation loss: 1.6762367115225842

Epoch: 6| Step: 4
Training loss: 0.3993765115737915
Validation loss: 1.6807618359083771

Epoch: 6| Step: 5
Training loss: 0.31748345494270325
Validation loss: 1.6661455682528916

Epoch: 6| Step: 6
Training loss: 0.791630744934082
Validation loss: 1.6620275423090944

Epoch: 6| Step: 7
Training loss: 0.5297092795372009
Validation loss: 1.674741296358006

Epoch: 6| Step: 8
Training loss: 0.6340528726577759
Validation loss: 1.6818630926070675

Epoch: 6| Step: 9
Training loss: 0.4539697766304016
Validation loss: 1.6810929672692412

Epoch: 6| Step: 10
Training loss: 0.38572341203689575
Validation loss: 1.7029444325354792

Epoch: 6| Step: 11
Training loss: 0.9025665521621704
Validation loss: 1.6964838607336885

Epoch: 6| Step: 12
Training loss: 0.5468942523002625
Validation loss: 1.6886264060133247

Epoch: 6| Step: 13
Training loss: 0.6343963146209717
Validation loss: 1.6755290544161232

Epoch: 231| Step: 0
Training loss: 0.5948491096496582
Validation loss: 1.6567143445373864

Epoch: 6| Step: 1
Training loss: 0.6968443989753723
Validation loss: 1.6458165812236007

Epoch: 6| Step: 2
Training loss: 0.5588490962982178
Validation loss: 1.6359065540375248

Epoch: 6| Step: 3
Training loss: 0.48264986276626587
Validation loss: 1.6458212842223465

Epoch: 6| Step: 4
Training loss: 0.3476186692714691
Validation loss: 1.6453965684419036

Epoch: 6| Step: 5
Training loss: 0.4442155957221985
Validation loss: 1.6335354210228048

Epoch: 6| Step: 6
Training loss: 0.45385050773620605
Validation loss: 1.6821659700844878

Epoch: 6| Step: 7
Training loss: 0.22473718225955963
Validation loss: 1.6834322021853538

Epoch: 6| Step: 8
Training loss: 0.4323897659778595
Validation loss: 1.6891511447968022

Epoch: 6| Step: 9
Training loss: 0.42748743295669556
Validation loss: 1.6840863407299083

Epoch: 6| Step: 10
Training loss: 0.2886110544204712
Validation loss: 1.6657538683183732

Epoch: 6| Step: 11
Training loss: 0.6507758498191833
Validation loss: 1.6763988259018108

Epoch: 6| Step: 12
Training loss: 0.4194445013999939
Validation loss: 1.686264016294992

Epoch: 6| Step: 13
Training loss: 0.3477472960948944
Validation loss: 1.7158590965373541

Epoch: 232| Step: 0
Training loss: 0.20374079048633575
Validation loss: 1.6869042035072082

Epoch: 6| Step: 1
Training loss: 0.5678472518920898
Validation loss: 1.6770823822226575

Epoch: 6| Step: 2
Training loss: 0.4113079905509949
Validation loss: 1.6551026400699411

Epoch: 6| Step: 3
Training loss: 0.3282569348812103
Validation loss: 1.6358653242870043

Epoch: 6| Step: 4
Training loss: 0.5529083013534546
Validation loss: 1.6399713729017524

Epoch: 6| Step: 5
Training loss: 0.48148947954177856
Validation loss: 1.6384185001414309

Epoch: 6| Step: 6
Training loss: 0.8870352506637573
Validation loss: 1.6333063046137493

Epoch: 6| Step: 7
Training loss: 0.28724122047424316
Validation loss: 1.5914961714898386

Epoch: 6| Step: 8
Training loss: 0.6126317977905273
Validation loss: 1.5883359857784805

Epoch: 6| Step: 9
Training loss: 0.3940751552581787
Validation loss: 1.6073834511541552

Epoch: 6| Step: 10
Training loss: 0.6460212469100952
Validation loss: 1.6538544342082033

Epoch: 6| Step: 11
Training loss: 0.5665783882141113
Validation loss: 1.6420318977807158

Epoch: 6| Step: 12
Training loss: 0.44391825795173645
Validation loss: 1.6657133717690744

Epoch: 6| Step: 13
Training loss: 0.21872003376483917
Validation loss: 1.6761811958846224

Epoch: 233| Step: 0
Training loss: 0.5971016883850098
Validation loss: 1.6846967512561428

Epoch: 6| Step: 1
Training loss: 0.46130359172821045
Validation loss: 1.7022586971200921

Epoch: 6| Step: 2
Training loss: 0.40359294414520264
Validation loss: 1.7070572914615754

Epoch: 6| Step: 3
Training loss: 0.7806622982025146
Validation loss: 1.7290347942741968

Epoch: 6| Step: 4
Training loss: 0.5495827198028564
Validation loss: 1.7179041139541134

Epoch: 6| Step: 5
Training loss: 0.43173250555992126
Validation loss: 1.7266716880183066

Epoch: 6| Step: 6
Training loss: 0.1714577078819275
Validation loss: 1.6937389207142655

Epoch: 6| Step: 7
Training loss: 0.35960787534713745
Validation loss: 1.690671237566138

Epoch: 6| Step: 8
Training loss: 0.42138034105300903
Validation loss: 1.661464996235345

Epoch: 6| Step: 9
Training loss: 0.5944716930389404
Validation loss: 1.6430432565750615

Epoch: 6| Step: 10
Training loss: 0.7195900678634644
Validation loss: 1.6707462033917826

Epoch: 6| Step: 11
Training loss: 0.5924729108810425
Validation loss: 1.6583129705921296

Epoch: 6| Step: 12
Training loss: 0.46739593148231506
Validation loss: 1.6390310038802445

Epoch: 6| Step: 13
Training loss: 0.48591697216033936
Validation loss: 1.6519412917475547

Epoch: 234| Step: 0
Training loss: 0.38461390137672424
Validation loss: 1.660881676981526

Epoch: 6| Step: 1
Training loss: 0.5278935432434082
Validation loss: 1.6450037469146073

Epoch: 6| Step: 2
Training loss: 0.32103201746940613
Validation loss: 1.6585413461090417

Epoch: 6| Step: 3
Training loss: 0.5895001292228699
Validation loss: 1.6682509081338042

Epoch: 6| Step: 4
Training loss: 0.5940393805503845
Validation loss: 1.6971339000168668

Epoch: 6| Step: 5
Training loss: 0.34607136249542236
Validation loss: 1.6945061235017673

Epoch: 6| Step: 6
Training loss: 0.8393988609313965
Validation loss: 1.695733638219936

Epoch: 6| Step: 7
Training loss: 0.5562075972557068
Validation loss: 1.71419156494961

Epoch: 6| Step: 8
Training loss: 0.35557007789611816
Validation loss: 1.7316946291154431

Epoch: 6| Step: 9
Training loss: 0.27731186151504517
Validation loss: 1.720600196110305

Epoch: 6| Step: 10
Training loss: 0.2666732966899872
Validation loss: 1.7494546034002816

Epoch: 6| Step: 11
Training loss: 0.5278353691101074
Validation loss: 1.7158327346206994

Epoch: 6| Step: 12
Training loss: 0.47655633091926575
Validation loss: 1.7241717589798795

Epoch: 6| Step: 13
Training loss: 0.48245859146118164
Validation loss: 1.7115514509139522

Epoch: 235| Step: 0
Training loss: 0.5540510416030884
Validation loss: 1.7298919167569888

Epoch: 6| Step: 1
Training loss: 0.4428495466709137
Validation loss: 1.7353724843712264

Epoch: 6| Step: 2
Training loss: 0.3218066096305847
Validation loss: 1.7251360429230558

Epoch: 6| Step: 3
Training loss: 0.5398640632629395
Validation loss: 1.7347382012233938

Epoch: 6| Step: 4
Training loss: 0.6955571174621582
Validation loss: 1.7122701419297086

Epoch: 6| Step: 5
Training loss: 0.506127119064331
Validation loss: 1.6969933945645568

Epoch: 6| Step: 6
Training loss: 0.45985186100006104
Validation loss: 1.6805478718972975

Epoch: 6| Step: 7
Training loss: 0.3698713779449463
Validation loss: 1.7003186607873568

Epoch: 6| Step: 8
Training loss: 0.40786221623420715
Validation loss: 1.683546830249089

Epoch: 6| Step: 9
Training loss: 0.3877846598625183
Validation loss: 1.6617749224426925

Epoch: 6| Step: 10
Training loss: 0.3697342872619629
Validation loss: 1.656544400799659

Epoch: 6| Step: 11
Training loss: 0.4929373264312744
Validation loss: 1.6718194484710693

Epoch: 6| Step: 12
Training loss: 0.46881020069122314
Validation loss: 1.6189070029925274

Epoch: 6| Step: 13
Training loss: 0.49132055044174194
Validation loss: 1.651240700034685

Epoch: 236| Step: 0
Training loss: 0.5524407029151917
Validation loss: 1.6358236689721384

Epoch: 6| Step: 1
Training loss: 0.3662817180156708
Validation loss: 1.6332269342996741

Epoch: 6| Step: 2
Training loss: 0.44181185960769653
Validation loss: 1.6036161632948025

Epoch: 6| Step: 3
Training loss: 0.5920102596282959
Validation loss: 1.6310379082156765

Epoch: 6| Step: 4
Training loss: 0.5457713603973389
Validation loss: 1.6185451156349593

Epoch: 6| Step: 5
Training loss: 0.6988478302955627
Validation loss: 1.6081670907235914

Epoch: 6| Step: 6
Training loss: 0.441745787858963
Validation loss: 1.5924243657819686

Epoch: 6| Step: 7
Training loss: 0.2879130244255066
Validation loss: 1.559234134612545

Epoch: 6| Step: 8
Training loss: 0.5979511737823486
Validation loss: 1.5856784043773529

Epoch: 6| Step: 9
Training loss: 0.3680116534233093
Validation loss: 1.577176103027918

Epoch: 6| Step: 10
Training loss: 0.48746243119239807
Validation loss: 1.5854222415595927

Epoch: 6| Step: 11
Training loss: 0.3000112473964691
Validation loss: 1.5915759648046186

Epoch: 6| Step: 12
Training loss: 0.2687511444091797
Validation loss: 1.5730375166862243

Epoch: 6| Step: 13
Training loss: 0.348941832780838
Validation loss: 1.6007659499363234

Epoch: 237| Step: 0
Training loss: 0.29041388630867004
Validation loss: 1.6395825339901833

Epoch: 6| Step: 1
Training loss: 0.33555155992507935
Validation loss: 1.662184969071419

Epoch: 6| Step: 2
Training loss: 0.5430130958557129
Validation loss: 1.6667403508258123

Epoch: 6| Step: 3
Training loss: 0.34879070520401
Validation loss: 1.6863865249900407

Epoch: 6| Step: 4
Training loss: 0.5780812501907349
Validation loss: 1.6957460244496663

Epoch: 6| Step: 5
Training loss: 0.44678765535354614
Validation loss: 1.6906946192505539

Epoch: 6| Step: 6
Training loss: 0.38610804080963135
Validation loss: 1.6841336040086643

Epoch: 6| Step: 7
Training loss: 0.45057278871536255
Validation loss: 1.6491449622697727

Epoch: 6| Step: 8
Training loss: 0.5925486087799072
Validation loss: 1.6596097471893474

Epoch: 6| Step: 9
Training loss: 0.37841492891311646
Validation loss: 1.6503392816871725

Epoch: 6| Step: 10
Training loss: 0.348161518573761
Validation loss: 1.6683220863342285

Epoch: 6| Step: 11
Training loss: 0.2076214998960495
Validation loss: 1.612949179064843

Epoch: 6| Step: 12
Training loss: 0.7372136116027832
Validation loss: 1.6193415298256824

Epoch: 6| Step: 13
Training loss: 0.4905923306941986
Validation loss: 1.6336964663638864

Epoch: 238| Step: 0
Training loss: 0.49352866411209106
Validation loss: 1.6443033679839103

Epoch: 6| Step: 1
Training loss: 0.24645499885082245
Validation loss: 1.5931965663868894

Epoch: 6| Step: 2
Training loss: 0.6756311655044556
Validation loss: 1.6267405607367074

Epoch: 6| Step: 3
Training loss: 0.3316619396209717
Validation loss: 1.6122457776018368

Epoch: 6| Step: 4
Training loss: 0.6265583038330078
Validation loss: 1.6360500922767065

Epoch: 6| Step: 5
Training loss: 0.5190340280532837
Validation loss: 1.642130890200215

Epoch: 6| Step: 6
Training loss: 0.33999085426330566
Validation loss: 1.6821721664039038

Epoch: 6| Step: 7
Training loss: 0.2518599331378937
Validation loss: 1.6722104908317648

Epoch: 6| Step: 8
Training loss: 0.423948734998703
Validation loss: 1.7037324443940194

Epoch: 6| Step: 9
Training loss: 0.20618581771850586
Validation loss: 1.6608842829222321

Epoch: 6| Step: 10
Training loss: 0.39340776205062866
Validation loss: 1.647937592639718

Epoch: 6| Step: 11
Training loss: 0.6846556067466736
Validation loss: 1.6666219695921867

Epoch: 6| Step: 12
Training loss: 0.6669716835021973
Validation loss: 1.6788208177012782

Epoch: 6| Step: 13
Training loss: 0.2624017000198364
Validation loss: 1.6615396725234164

Epoch: 239| Step: 0
Training loss: 0.40891599655151367
Validation loss: 1.666452117504612

Epoch: 6| Step: 1
Training loss: 0.56819087266922
Validation loss: 1.6817796358498194

Epoch: 6| Step: 2
Training loss: 0.4390203356742859
Validation loss: 1.6765129232919345

Epoch: 6| Step: 3
Training loss: 0.742583155632019
Validation loss: 1.6486685365758917

Epoch: 6| Step: 4
Training loss: 0.3723948001861572
Validation loss: 1.676487845759238

Epoch: 6| Step: 5
Training loss: 0.3539264500141144
Validation loss: 1.6680527515308832

Epoch: 6| Step: 6
Training loss: 0.3226485252380371
Validation loss: 1.6884203405790432

Epoch: 6| Step: 7
Training loss: 0.5892208218574524
Validation loss: 1.682413217841938

Epoch: 6| Step: 8
Training loss: 0.4389536380767822
Validation loss: 1.7355274679840251

Epoch: 6| Step: 9
Training loss: 0.6349027156829834
Validation loss: 1.723329981168111

Epoch: 6| Step: 10
Training loss: 0.5819746851921082
Validation loss: 1.7244758875139299

Epoch: 6| Step: 11
Training loss: 0.2544938325881958
Validation loss: 1.6748257811351488

Epoch: 6| Step: 12
Training loss: 0.6100045442581177
Validation loss: 1.6971843165736045

Epoch: 6| Step: 13
Training loss: 0.4288608431816101
Validation loss: 1.686895037210116

Epoch: 240| Step: 0
Training loss: 0.7066340446472168
Validation loss: 1.6719733361274964

Epoch: 6| Step: 1
Training loss: 0.6531645655632019
Validation loss: 1.7164756764647782

Epoch: 6| Step: 2
Training loss: 0.5876728296279907
Validation loss: 1.7228034926999

Epoch: 6| Step: 3
Training loss: 0.6122952103614807
Validation loss: 1.6841182426739765

Epoch: 6| Step: 4
Training loss: 0.558456301689148
Validation loss: 1.6247043250709452

Epoch: 6| Step: 5
Training loss: 0.32052838802337646
Validation loss: 1.6225392030131431

Epoch: 6| Step: 6
Training loss: 0.40889737010002136
Validation loss: 1.654056070953287

Epoch: 6| Step: 7
Training loss: 0.569697916507721
Validation loss: 1.6450139822498444

Epoch: 6| Step: 8
Training loss: 0.5337463021278381
Validation loss: 1.6751046770362443

Epoch: 6| Step: 9
Training loss: 0.4503442049026489
Validation loss: 1.6782641859464749

Epoch: 6| Step: 10
Training loss: 0.5091100931167603
Validation loss: 1.6669547416830575

Epoch: 6| Step: 11
Training loss: 0.32515522837638855
Validation loss: 1.6810745334112516

Epoch: 6| Step: 12
Training loss: 0.5032132267951965
Validation loss: 1.6478396666947233

Epoch: 6| Step: 13
Training loss: 0.34292781352996826
Validation loss: 1.6708158818624352

Epoch: 241| Step: 0
Training loss: 0.3706236481666565
Validation loss: 1.6937928443313928

Epoch: 6| Step: 1
Training loss: 0.5744460821151733
Validation loss: 1.6616050492050827

Epoch: 6| Step: 2
Training loss: 0.5081112384796143
Validation loss: 1.64143172899882

Epoch: 6| Step: 3
Training loss: 0.4553697109222412
Validation loss: 1.6429161769087597

Epoch: 6| Step: 4
Training loss: 0.37694257497787476
Validation loss: 1.6416887942180838

Epoch: 6| Step: 5
Training loss: 0.32246702909469604
Validation loss: 1.6282877960512716

Epoch: 6| Step: 6
Training loss: 0.5023722052574158
Validation loss: 1.6504255892128072

Epoch: 6| Step: 7
Training loss: 0.3653229773044586
Validation loss: 1.6325342373181415

Epoch: 6| Step: 8
Training loss: 0.5393269658088684
Validation loss: 1.6439649033290085

Epoch: 6| Step: 9
Training loss: 0.3950607478618622
Validation loss: 1.634339964517983

Epoch: 6| Step: 10
Training loss: 0.766183614730835
Validation loss: 1.6300390381966867

Epoch: 6| Step: 11
Training loss: 0.5925561189651489
Validation loss: 1.6160206897284395

Epoch: 6| Step: 12
Training loss: 0.4634523391723633
Validation loss: 1.579279407378166

Epoch: 6| Step: 13
Training loss: 0.2981501817703247
Validation loss: 1.5966999376973798

Epoch: 242| Step: 0
Training loss: 0.48368269205093384
Validation loss: 1.5989634324145574

Epoch: 6| Step: 1
Training loss: 0.5042120814323425
Validation loss: 1.589383250923567

Epoch: 6| Step: 2
Training loss: 0.3300294876098633
Validation loss: 1.6056791390142133

Epoch: 6| Step: 3
Training loss: 0.5220107436180115
Validation loss: 1.5956713884107527

Epoch: 6| Step: 4
Training loss: 0.36568260192871094
Validation loss: 1.5907508724479265

Epoch: 6| Step: 5
Training loss: 0.5097643136978149
Validation loss: 1.6351291864149031

Epoch: 6| Step: 6
Training loss: 0.4161040186882019
Validation loss: 1.6398694092227566

Epoch: 6| Step: 7
Training loss: 0.7143495678901672
Validation loss: 1.6516565110093804

Epoch: 6| Step: 8
Training loss: 0.28917038440704346
Validation loss: 1.6589969511955016

Epoch: 6| Step: 9
Training loss: 0.34166061878204346
Validation loss: 1.6555826253788446

Epoch: 6| Step: 10
Training loss: 0.368476539850235
Validation loss: 1.6601735930288992

Epoch: 6| Step: 11
Training loss: 0.4190827012062073
Validation loss: 1.6629424120790215

Epoch: 6| Step: 12
Training loss: 0.3356935381889343
Validation loss: 1.6785540824295373

Epoch: 6| Step: 13
Training loss: 0.3434543013572693
Validation loss: 1.661303594548215

Epoch: 243| Step: 0
Training loss: 0.49509358406066895
Validation loss: 1.6316424877412858

Epoch: 6| Step: 1
Training loss: 0.46300235390663147
Validation loss: 1.6288878520329793

Epoch: 6| Step: 2
Training loss: 0.367397665977478
Validation loss: 1.637189842039539

Epoch: 6| Step: 3
Training loss: 0.4176939129829407
Validation loss: 1.6306746018830167

Epoch: 6| Step: 4
Training loss: 0.45601946115493774
Validation loss: 1.618583477953429

Epoch: 6| Step: 5
Training loss: 0.36810097098350525
Validation loss: 1.6242396485420965

Epoch: 6| Step: 6
Training loss: 0.3235023021697998
Validation loss: 1.6548397476955126

Epoch: 6| Step: 7
Training loss: 0.4547434151172638
Validation loss: 1.663448659322595

Epoch: 6| Step: 8
Training loss: 0.36094456911087036
Validation loss: 1.6505304818512292

Epoch: 6| Step: 9
Training loss: 0.49241381883621216
Validation loss: 1.6807958156831804

Epoch: 6| Step: 10
Training loss: 0.5832770466804504
Validation loss: 1.636168614510567

Epoch: 6| Step: 11
Training loss: 0.1702328622341156
Validation loss: 1.6465983672808575

Epoch: 6| Step: 12
Training loss: 0.4585554003715515
Validation loss: 1.6448739818347398

Epoch: 6| Step: 13
Training loss: 0.24938923120498657
Validation loss: 1.624558065527229

Epoch: 244| Step: 0
Training loss: 0.5296914577484131
Validation loss: 1.645825377074621

Epoch: 6| Step: 1
Training loss: 0.24021212756633759
Validation loss: 1.6180384479543215

Epoch: 6| Step: 2
Training loss: 0.29838964343070984
Validation loss: 1.6155393226172334

Epoch: 6| Step: 3
Training loss: 0.3225994110107422
Validation loss: 1.6031312993777695

Epoch: 6| Step: 4
Training loss: 0.17083275318145752
Validation loss: 1.6300426670300063

Epoch: 6| Step: 5
Training loss: 0.49704039096832275
Validation loss: 1.6167546997788131

Epoch: 6| Step: 6
Training loss: 0.45151233673095703
Validation loss: 1.6138903158967213

Epoch: 6| Step: 7
Training loss: 0.5825660228729248
Validation loss: 1.6470128092714535

Epoch: 6| Step: 8
Training loss: 0.43585413694381714
Validation loss: 1.633442404449627

Epoch: 6| Step: 9
Training loss: 0.2725249230861664
Validation loss: 1.6148734477258497

Epoch: 6| Step: 10
Training loss: 0.28582462668418884
Validation loss: 1.633873148631024

Epoch: 6| Step: 11
Training loss: 0.44346752762794495
Validation loss: 1.64931668004682

Epoch: 6| Step: 12
Training loss: 0.39279428124427795
Validation loss: 1.6479463449088476

Epoch: 6| Step: 13
Training loss: 0.11898969113826752
Validation loss: 1.6139059246227305

Epoch: 245| Step: 0
Training loss: 0.34071433544158936
Validation loss: 1.6086845551767657

Epoch: 6| Step: 1
Training loss: 0.3082302212715149
Validation loss: 1.5871918316810363

Epoch: 6| Step: 2
Training loss: 0.25559717416763306
Validation loss: 1.5926227108124764

Epoch: 6| Step: 3
Training loss: 0.38758254051208496
Validation loss: 1.6010488348622476

Epoch: 6| Step: 4
Training loss: 0.4490838050842285
Validation loss: 1.6075788505615727

Epoch: 6| Step: 5
Training loss: 0.43478885293006897
Validation loss: 1.615626391544137

Epoch: 6| Step: 6
Training loss: 0.38001325726509094
Validation loss: 1.6225115099260885

Epoch: 6| Step: 7
Training loss: 0.4002610146999359
Validation loss: 1.6076299054648286

Epoch: 6| Step: 8
Training loss: 0.41713595390319824
Validation loss: 1.6245496375586397

Epoch: 6| Step: 9
Training loss: 0.4257448613643646
Validation loss: 1.6183495470272597

Epoch: 6| Step: 10
Training loss: 0.42329758405685425
Validation loss: 1.6275282418856056

Epoch: 6| Step: 11
Training loss: 0.26722168922424316
Validation loss: 1.6234082906476912

Epoch: 6| Step: 12
Training loss: 0.4036126136779785
Validation loss: 1.603190436158129

Epoch: 6| Step: 13
Training loss: 0.39096367359161377
Validation loss: 1.633501047729164

Epoch: 246| Step: 0
Training loss: 0.20896413922309875
Validation loss: 1.640417964227738

Epoch: 6| Step: 1
Training loss: 0.4291204810142517
Validation loss: 1.6151280415955411

Epoch: 6| Step: 2
Training loss: 0.44160476326942444
Validation loss: 1.6203915367844284

Epoch: 6| Step: 3
Training loss: 0.19162873923778534
Validation loss: 1.6358761043958767

Epoch: 6| Step: 4
Training loss: 0.4277205169200897
Validation loss: 1.647153369842037

Epoch: 6| Step: 5
Training loss: 0.3714107871055603
Validation loss: 1.6512090070273286

Epoch: 6| Step: 6
Training loss: 0.5071902871131897
Validation loss: 1.643538623727778

Epoch: 6| Step: 7
Training loss: 0.41780853271484375
Validation loss: 1.6501670345183341

Epoch: 6| Step: 8
Training loss: 0.5054339170455933
Validation loss: 1.6656694540413477

Epoch: 6| Step: 9
Training loss: 0.5083807706832886
Validation loss: 1.6380191951669671

Epoch: 6| Step: 10
Training loss: 0.4518207013607025
Validation loss: 1.6517024758041545

Epoch: 6| Step: 11
Training loss: 0.29616472125053406
Validation loss: 1.6583166455709806

Epoch: 6| Step: 12
Training loss: 0.5270897746086121
Validation loss: 1.6400233084155666

Epoch: 6| Step: 13
Training loss: 0.19208380579948425
Validation loss: 1.6309948108529533

Epoch: 247| Step: 0
Training loss: 0.4071139097213745
Validation loss: 1.635683810839089

Epoch: 6| Step: 1
Training loss: 0.3117419183254242
Validation loss: 1.6317747664707962

Epoch: 6| Step: 2
Training loss: 0.2768000364303589
Validation loss: 1.6038616165038078

Epoch: 6| Step: 3
Training loss: 0.1606583595275879
Validation loss: 1.6267812405863116

Epoch: 6| Step: 4
Training loss: 0.5062387585639954
Validation loss: 1.6566961067979054

Epoch: 6| Step: 5
Training loss: 0.3001113831996918
Validation loss: 1.6307612529364965

Epoch: 6| Step: 6
Training loss: 0.1800001859664917
Validation loss: 1.6290107593741467

Epoch: 6| Step: 7
Training loss: 0.4033429026603699
Validation loss: 1.6063769120042042

Epoch: 6| Step: 8
Training loss: 0.6276942491531372
Validation loss: 1.6085491782875472

Epoch: 6| Step: 9
Training loss: 0.42547115683555603
Validation loss: 1.5799766099581154

Epoch: 6| Step: 10
Training loss: 0.4322357773780823
Validation loss: 1.5845055721139396

Epoch: 6| Step: 11
Training loss: 0.29021960496902466
Validation loss: 1.6061670972454933

Epoch: 6| Step: 12
Training loss: 0.3796253502368927
Validation loss: 1.5892464025046236

Epoch: 6| Step: 13
Training loss: 0.32007932662963867
Validation loss: 1.5885556872173021

Epoch: 248| Step: 0
Training loss: 0.6890596151351929
Validation loss: 1.6109922098857101

Epoch: 6| Step: 1
Training loss: 0.3958178162574768
Validation loss: 1.6112531833751227

Epoch: 6| Step: 2
Training loss: 0.2933383285999298
Validation loss: 1.6037526117858065

Epoch: 6| Step: 3
Training loss: 0.3589751720428467
Validation loss: 1.6002831382136191

Epoch: 6| Step: 4
Training loss: 0.354185551404953
Validation loss: 1.6052647380418674

Epoch: 6| Step: 5
Training loss: 0.27036774158477783
Validation loss: 1.5887578943724274

Epoch: 6| Step: 6
Training loss: 0.20957036316394806
Validation loss: 1.6027615583071144

Epoch: 6| Step: 7
Training loss: 0.1774449348449707
Validation loss: 1.6149651594059442

Epoch: 6| Step: 8
Training loss: 0.33156439661979675
Validation loss: 1.5713347952852967

Epoch: 6| Step: 9
Training loss: 0.37470191717147827
Validation loss: 1.607808704017311

Epoch: 6| Step: 10
Training loss: 0.6072507500648499
Validation loss: 1.5830086136376986

Epoch: 6| Step: 11
Training loss: 0.3103891611099243
Validation loss: 1.5727048830319477

Epoch: 6| Step: 12
Training loss: 0.39216500520706177
Validation loss: 1.5880934640925417

Epoch: 6| Step: 13
Training loss: 0.44044622778892517
Validation loss: 1.5737928305902789

Epoch: 249| Step: 0
Training loss: 0.17180149257183075
Validation loss: 1.5829245672431043

Epoch: 6| Step: 1
Training loss: 0.1904887557029724
Validation loss: 1.5731603214817662

Epoch: 6| Step: 2
Training loss: 0.31203368306159973
Validation loss: 1.5722339627563313

Epoch: 6| Step: 3
Training loss: 0.39340701699256897
Validation loss: 1.586152466394568

Epoch: 6| Step: 4
Training loss: 0.42219823598861694
Validation loss: 1.600479466940767

Epoch: 6| Step: 5
Training loss: 0.5655224323272705
Validation loss: 1.6166178962235809

Epoch: 6| Step: 6
Training loss: 0.42841988801956177
Validation loss: 1.6032304084429176

Epoch: 6| Step: 7
Training loss: 0.5658172965049744
Validation loss: 1.5894683266198764

Epoch: 6| Step: 8
Training loss: 0.4083246886730194
Validation loss: 1.6243609715533514

Epoch: 6| Step: 9
Training loss: 0.18810072541236877
Validation loss: 1.618805000858922

Epoch: 6| Step: 10
Training loss: 0.47195112705230713
Validation loss: 1.6147155210536013

Epoch: 6| Step: 11
Training loss: 0.19745773077011108
Validation loss: 1.622449419831717

Epoch: 6| Step: 12
Training loss: 0.306893914937973
Validation loss: 1.6119614519098753

Epoch: 6| Step: 13
Training loss: 0.42340534925460815
Validation loss: 1.6094345136355328

Epoch: 250| Step: 0
Training loss: 0.3236815929412842
Validation loss: 1.621366125281139

Epoch: 6| Step: 1
Training loss: 0.3172317147254944
Validation loss: 1.6206478764933925

Epoch: 6| Step: 2
Training loss: 0.24019187688827515
Validation loss: 1.6105762938017487

Epoch: 6| Step: 3
Training loss: 0.4317217767238617
Validation loss: 1.607687460478916

Epoch: 6| Step: 4
Training loss: 0.2962195873260498
Validation loss: 1.5952767954077771

Epoch: 6| Step: 5
Training loss: 0.3167651891708374
Validation loss: 1.5941070971950408

Epoch: 6| Step: 6
Training loss: 0.5158394575119019
Validation loss: 1.5940107799345447

Epoch: 6| Step: 7
Training loss: 0.2259727418422699
Validation loss: 1.6304656126165902

Epoch: 6| Step: 8
Training loss: 0.2179383933544159
Validation loss: 1.609126990841281

Epoch: 6| Step: 9
Training loss: 0.2834554612636566
Validation loss: 1.6167429583047026

Epoch: 6| Step: 10
Training loss: 0.44636258482933044
Validation loss: 1.6642205894634288

Epoch: 6| Step: 11
Training loss: 0.38738298416137695
Validation loss: 1.6880379915237427

Epoch: 6| Step: 12
Training loss: 0.47853028774261475
Validation loss: 1.638648795825179

Epoch: 6| Step: 13
Training loss: 0.3666084110736847
Validation loss: 1.6661336909058273

Testing loss: 2.0380338244967993
