Epoch: 1| Step: 0
Training loss: 6.286049295142919
Validation loss: 5.800147239929275

Epoch: 5| Step: 1
Training loss: 5.421537273343235
Validation loss: 5.7786997075869495

Epoch: 5| Step: 2
Training loss: 5.421553632463009
Validation loss: 5.7602181633984895

Epoch: 5| Step: 3
Training loss: 4.61691050981494
Validation loss: 5.742111058884716

Epoch: 5| Step: 4
Training loss: 6.003394755985267
Validation loss: 5.723081952197175

Epoch: 5| Step: 5
Training loss: 5.551052014420049
Validation loss: 5.701602368313807

Epoch: 5| Step: 6
Training loss: 6.4297696707424
Validation loss: 5.677396064115763

Epoch: 5| Step: 7
Training loss: 4.5830649326226816
Validation loss: 5.649564477859833

Epoch: 5| Step: 8
Training loss: 6.761941589879449
Validation loss: 5.617776224231566

Epoch: 5| Step: 9
Training loss: 5.974018428093373
Validation loss: 5.58284678181171

Epoch: 5| Step: 10
Training loss: 5.455248749793096
Validation loss: 5.54330148514613

Epoch: 2| Step: 0
Training loss: 4.668698663186735
Validation loss: 5.499712202833678

Epoch: 5| Step: 1
Training loss: 5.455198052409796
Validation loss: 5.453861887150109

Epoch: 5| Step: 2
Training loss: 5.841408000158558
Validation loss: 5.405111494222051

Epoch: 5| Step: 3
Training loss: 6.002680497639224
Validation loss: 5.353562891223911

Epoch: 5| Step: 4
Training loss: 5.073310142260233
Validation loss: 5.301212034753611

Epoch: 5| Step: 5
Training loss: 5.97751058401258
Validation loss: 5.247984355181623

Epoch: 5| Step: 6
Training loss: 4.933662951687074
Validation loss: 5.195821218837238

Epoch: 5| Step: 7
Training loss: 5.636051426627843
Validation loss: 5.144509570890325

Epoch: 5| Step: 8
Training loss: 4.806216807554638
Validation loss: 5.094782715726867

Epoch: 5| Step: 9
Training loss: 4.264258756276232
Validation loss: 5.043520196275201

Epoch: 5| Step: 10
Training loss: 5.406500661694885
Validation loss: 4.988183205075664

Epoch: 3| Step: 0
Training loss: 4.533385937516425
Validation loss: 4.929537068505183

Epoch: 5| Step: 1
Training loss: 4.1442449904086684
Validation loss: 4.880963935193803

Epoch: 5| Step: 2
Training loss: 4.142647418459238
Validation loss: 4.839642370634292

Epoch: 5| Step: 3
Training loss: 5.251133387704863
Validation loss: 4.805952303811536

Epoch: 5| Step: 4
Training loss: 5.258551037005257
Validation loss: 4.775563202251923

Epoch: 5| Step: 5
Training loss: 5.127696374697314
Validation loss: 4.744771617660055

Epoch: 5| Step: 6
Training loss: 5.1518678481526585
Validation loss: 4.708492082901014

Epoch: 5| Step: 7
Training loss: 4.504705512003857
Validation loss: 4.67672378112113

Epoch: 5| Step: 8
Training loss: 4.802859868988745
Validation loss: 4.644956231789634

Epoch: 5| Step: 9
Training loss: 5.278521312517749
Validation loss: 4.612123885861828

Epoch: 5| Step: 10
Training loss: 4.778128808209016
Validation loss: 4.5814760414450735

Epoch: 4| Step: 0
Training loss: 4.269698772302465
Validation loss: 4.558589739137427

Epoch: 5| Step: 1
Training loss: 4.079671865993598
Validation loss: 4.528458754169753

Epoch: 5| Step: 2
Training loss: 4.558736424636397
Validation loss: 4.500777914517979

Epoch: 5| Step: 3
Training loss: 3.7088147968819904
Validation loss: 4.480499489765127

Epoch: 5| Step: 4
Training loss: 4.5797557855654185
Validation loss: 4.459988552549513

Epoch: 5| Step: 5
Training loss: 3.732733329741346
Validation loss: 4.438380499371872

Epoch: 5| Step: 6
Training loss: 5.598286754932628
Validation loss: 4.4195385432462375

Epoch: 5| Step: 7
Training loss: 4.797880483610421
Validation loss: 4.40038596890727

Epoch: 5| Step: 8
Training loss: 4.6798283168895765
Validation loss: 4.3861082425793345

Epoch: 5| Step: 9
Training loss: 5.132791690406827
Validation loss: 4.369454705616617

Epoch: 5| Step: 10
Training loss: 4.58171237834405
Validation loss: 4.353632963364542

Epoch: 5| Step: 0
Training loss: 4.732126841556561
Validation loss: 4.337272187781716

Epoch: 5| Step: 1
Training loss: 3.2810401486094483
Validation loss: 4.319745640142651

Epoch: 5| Step: 2
Training loss: 3.6886266506646024
Validation loss: 4.303026963442299

Epoch: 5| Step: 3
Training loss: 5.354314700602304
Validation loss: 4.289661775861945

Epoch: 5| Step: 4
Training loss: 4.37051772343946
Validation loss: 4.272482614432337

Epoch: 5| Step: 5
Training loss: 4.207357211577185
Validation loss: 4.257451643323265

Epoch: 5| Step: 6
Training loss: 5.043683912182232
Validation loss: 4.244866824722496

Epoch: 5| Step: 7
Training loss: 4.269431403581477
Validation loss: 4.227914047693392

Epoch: 5| Step: 8
Training loss: 4.250887161110507
Validation loss: 4.206679423775562

Epoch: 5| Step: 9
Training loss: 3.596342926044654
Validation loss: 4.200576975422935

Epoch: 5| Step: 10
Training loss: 5.085673663771583
Validation loss: 4.194704821256161

Epoch: 6| Step: 0
Training loss: 4.504008944582146
Validation loss: 4.169689663509334

Epoch: 5| Step: 1
Training loss: 4.404348409482313
Validation loss: 4.167794924332215

Epoch: 5| Step: 2
Training loss: 4.069192157399645
Validation loss: 4.155162443543916

Epoch: 5| Step: 3
Training loss: 3.6400168242432516
Validation loss: 4.13767505832197

Epoch: 5| Step: 4
Training loss: 4.510575054579854
Validation loss: 4.1166095899737165

Epoch: 5| Step: 5
Training loss: 4.48388541602841
Validation loss: 4.102411998901186

Epoch: 5| Step: 6
Training loss: 5.069324367732655
Validation loss: 4.084092205083141

Epoch: 5| Step: 7
Training loss: 4.212917110269668
Validation loss: 4.08008703724088

Epoch: 5| Step: 8
Training loss: 3.6904230978291923
Validation loss: 4.066957495396842

Epoch: 5| Step: 9
Training loss: 4.22929950875045
Validation loss: 4.045885449138847

Epoch: 5| Step: 10
Training loss: 3.6004052940683184
Validation loss: 4.025864202416732

Epoch: 7| Step: 0
Training loss: 3.524523514812992
Validation loss: 4.0110327262511465

Epoch: 5| Step: 1
Training loss: 5.004324378144312
Validation loss: 3.9998754833181036

Epoch: 5| Step: 2
Training loss: 4.696612643023003
Validation loss: 3.9847303019352873

Epoch: 5| Step: 3
Training loss: 3.8343941561368857
Validation loss: 3.9668894450216863

Epoch: 5| Step: 4
Training loss: 3.8613955501984996
Validation loss: 3.9542783168364988

Epoch: 5| Step: 5
Training loss: 3.344818087251413
Validation loss: 3.930666951814289

Epoch: 5| Step: 6
Training loss: 3.944846067144983
Validation loss: 3.9243492391676806

Epoch: 5| Step: 7
Training loss: 4.255518528041546
Validation loss: 3.9153526386697117

Epoch: 5| Step: 8
Training loss: 4.358350407777872
Validation loss: 3.8931100427973204

Epoch: 5| Step: 9
Training loss: 3.617182886108356
Validation loss: 3.891217027863936

Epoch: 5| Step: 10
Training loss: 4.414692467490746
Validation loss: 3.877910686552174

Epoch: 8| Step: 0
Training loss: 3.823530156579959
Validation loss: 3.8589459684334706

Epoch: 5| Step: 1
Training loss: 3.6247908433228138
Validation loss: 3.854768243927286

Epoch: 5| Step: 2
Training loss: 3.9438050666749067
Validation loss: 3.842419291019939

Epoch: 5| Step: 3
Training loss: 5.731367023899838
Validation loss: 3.824001082786228

Epoch: 5| Step: 4
Training loss: 3.8341716734210856
Validation loss: 3.817457143855136

Epoch: 5| Step: 5
Training loss: 3.1806082927064914
Validation loss: 3.8123001726763834

Epoch: 5| Step: 6
Training loss: 3.41774552842518
Validation loss: 3.7807145891807745

Epoch: 5| Step: 7
Training loss: 4.479964476512668
Validation loss: 3.7846416224843344

Epoch: 5| Step: 8
Training loss: 3.7899869754537265
Validation loss: 3.7819985842225754

Epoch: 5| Step: 9
Training loss: 4.118079188455775
Validation loss: 3.770123302669088

Epoch: 5| Step: 10
Training loss: 3.1018186218438664
Validation loss: 3.74957753061141

Epoch: 9| Step: 0
Training loss: 4.260950454563526
Validation loss: 3.7353939479133826

Epoch: 5| Step: 1
Training loss: 3.483663306661493
Validation loss: 3.7168070059551215

Epoch: 5| Step: 2
Training loss: 3.20183987772657
Validation loss: 3.703334887034176

Epoch: 5| Step: 3
Training loss: 4.13993075326698
Validation loss: 3.703615286898583

Epoch: 5| Step: 4
Training loss: 4.1888826279687565
Validation loss: 3.680277605500421

Epoch: 5| Step: 5
Training loss: 3.967399908196195
Validation loss: 3.667727559302175

Epoch: 5| Step: 6
Training loss: 3.336210503228264
Validation loss: 3.6554291502004816

Epoch: 5| Step: 7
Training loss: 3.2893399735429982
Validation loss: 3.644604583738569

Epoch: 5| Step: 8
Training loss: 3.6610271838506683
Validation loss: 3.628787247967773

Epoch: 5| Step: 9
Training loss: 4.791010051464348
Validation loss: 3.613569657894597

Epoch: 5| Step: 10
Training loss: 3.759653382050215
Validation loss: 3.611887074286544

Epoch: 10| Step: 0
Training loss: 4.277629574496993
Validation loss: 3.582376833692256

Epoch: 5| Step: 1
Training loss: 3.9439986354601126
Validation loss: 3.574418463759792

Epoch: 5| Step: 2
Training loss: 3.9801747641220606
Validation loss: 3.5623849541841723

Epoch: 5| Step: 3
Training loss: 3.43028431350764
Validation loss: 3.5456872479760877

Epoch: 5| Step: 4
Training loss: 3.189409618933603
Validation loss: 3.5368766145243473

Epoch: 5| Step: 5
Training loss: 3.0738425891112704
Validation loss: 3.524609492074985

Epoch: 5| Step: 6
Training loss: 3.5237063962925386
Validation loss: 3.51395626593393

Epoch: 5| Step: 7
Training loss: 4.168782091374675
Validation loss: 3.509647851296285

Epoch: 5| Step: 8
Training loss: 3.5387399286458976
Validation loss: 3.494649073805714

Epoch: 5| Step: 9
Training loss: 3.539646395248197
Validation loss: 3.48445564499322

Epoch: 5| Step: 10
Training loss: 4.269530133162594
Validation loss: 3.475288620633415

Epoch: 11| Step: 0
Training loss: 2.7067815492080363
Validation loss: 3.4701551499375265

Epoch: 5| Step: 1
Training loss: 3.144871512064138
Validation loss: 3.461729753767322

Epoch: 5| Step: 2
Training loss: 3.7184644316972246
Validation loss: 3.4539882234463013

Epoch: 5| Step: 3
Training loss: 4.1724759358420105
Validation loss: 3.444211842299869

Epoch: 5| Step: 4
Training loss: 3.7122917193932223
Validation loss: 3.43441176869699

Epoch: 5| Step: 5
Training loss: 3.9784838638198967
Validation loss: 3.428688194691624

Epoch: 5| Step: 6
Training loss: 4.053374384705648
Validation loss: 3.42756163010458

Epoch: 5| Step: 7
Training loss: 3.7992706903997595
Validation loss: 3.4173697601823347

Epoch: 5| Step: 8
Training loss: 3.681853545732986
Validation loss: 3.4133678095664934

Epoch: 5| Step: 9
Training loss: 2.9037346568299576
Validation loss: 3.4064114274496875

Epoch: 5| Step: 10
Training loss: 4.0086390663548945
Validation loss: 3.3971908491172322

Epoch: 12| Step: 0
Training loss: 3.645639134639111
Validation loss: 3.3860727365787295

Epoch: 5| Step: 1
Training loss: 3.161159210047721
Validation loss: 3.3776755838401287

Epoch: 5| Step: 2
Training loss: 3.178947643836466
Validation loss: 3.3723044787831573

Epoch: 5| Step: 3
Training loss: 3.082153936731498
Validation loss: 3.3701970993749

Epoch: 5| Step: 4
Training loss: 4.393421300799453
Validation loss: 3.362132251551839

Epoch: 5| Step: 5
Training loss: 3.785962407702837
Validation loss: 3.347319606584744

Epoch: 5| Step: 6
Training loss: 3.7556390960576107
Validation loss: 3.3410979180467395

Epoch: 5| Step: 7
Training loss: 3.304196585046331
Validation loss: 3.348245851554463

Epoch: 5| Step: 8
Training loss: 3.611394936256642
Validation loss: 3.328667188987084

Epoch: 5| Step: 9
Training loss: 3.2014870526279706
Validation loss: 3.3330225835561875

Epoch: 5| Step: 10
Training loss: 4.193384164240306
Validation loss: 3.332120189074357

Epoch: 13| Step: 0
Training loss: 3.344173939292434
Validation loss: 3.326317543200173

Epoch: 5| Step: 1
Training loss: 3.0854343438699243
Validation loss: 3.313964317323899

Epoch: 5| Step: 2
Training loss: 3.903285374030524
Validation loss: 3.304082014383153

Epoch: 5| Step: 3
Training loss: 2.8426974518035215
Validation loss: 3.295837926627422

Epoch: 5| Step: 4
Training loss: 4.1452854631550915
Validation loss: 3.2909077296050735

Epoch: 5| Step: 5
Training loss: 3.799362560815995
Validation loss: 3.288500574069651

Epoch: 5| Step: 6
Training loss: 3.2463198145842025
Validation loss: 3.2785839885666426

Epoch: 5| Step: 7
Training loss: 3.214696609633977
Validation loss: 3.277978692855999

Epoch: 5| Step: 8
Training loss: 3.9443558845667326
Validation loss: 3.2801290070954807

Epoch: 5| Step: 9
Training loss: 3.2752984704444272
Validation loss: 3.270186339429689

Epoch: 5| Step: 10
Training loss: 3.8563472593336705
Validation loss: 3.263511658838985

Epoch: 14| Step: 0
Training loss: 2.732771746777054
Validation loss: 3.257121675487328

Epoch: 5| Step: 1
Training loss: 3.160059980475085
Validation loss: 3.2504289452863535

Epoch: 5| Step: 2
Training loss: 3.3196032675429508
Validation loss: 3.243479729717041

Epoch: 5| Step: 3
Training loss: 2.9701197626390328
Validation loss: 3.238863462459962

Epoch: 5| Step: 4
Training loss: 3.664464607216714
Validation loss: 3.2368702314489997

Epoch: 5| Step: 5
Training loss: 4.213738976359199
Validation loss: 3.2317028289203207

Epoch: 5| Step: 6
Training loss: 2.9798559356275476
Validation loss: 3.2273089624917164

Epoch: 5| Step: 7
Training loss: 3.6098259978482634
Validation loss: 3.2203553598177295

Epoch: 5| Step: 8
Training loss: 3.684496416027797
Validation loss: 3.2160477605564006

Epoch: 5| Step: 9
Training loss: 4.075928312006267
Validation loss: 3.210862001579835

Epoch: 5| Step: 10
Training loss: 3.613839695020878
Validation loss: 3.2135514466790434

Epoch: 15| Step: 0
Training loss: 3.6406082349399393
Validation loss: 3.206794592444158

Epoch: 5| Step: 1
Training loss: 2.833607118131721
Validation loss: 3.2006434246227795

Epoch: 5| Step: 2
Training loss: 3.586979068589748
Validation loss: 3.1970768863668373

Epoch: 5| Step: 3
Training loss: 2.9324453165690865
Validation loss: 3.196056633640259

Epoch: 5| Step: 4
Training loss: 3.7632618687221497
Validation loss: 3.1881003267913113

Epoch: 5| Step: 5
Training loss: 3.3483151084615317
Validation loss: 3.1854226140874085

Epoch: 5| Step: 6
Training loss: 3.7898080623206973
Validation loss: 3.181550295538021

Epoch: 5| Step: 7
Training loss: 2.9769333335579975
Validation loss: 3.175996053646733

Epoch: 5| Step: 8
Training loss: 3.847084893729982
Validation loss: 3.175093925688104

Epoch: 5| Step: 9
Training loss: 3.391313895985017
Validation loss: 3.1704248847304144

Epoch: 5| Step: 10
Training loss: 3.6622522107561064
Validation loss: 3.1672178678160923

Epoch: 16| Step: 0
Training loss: 2.1652118371309768
Validation loss: 3.1660706785537425

Epoch: 5| Step: 1
Training loss: 3.156766490411952
Validation loss: 3.161400975378753

Epoch: 5| Step: 2
Training loss: 4.09905243135056
Validation loss: 3.158096564434463

Epoch: 5| Step: 3
Training loss: 3.477534811804128
Validation loss: 3.155768058059298

Epoch: 5| Step: 4
Training loss: 3.958818519705147
Validation loss: 3.1531715532644875

Epoch: 5| Step: 5
Training loss: 3.5537969458797085
Validation loss: 3.148379737631318

Epoch: 5| Step: 6
Training loss: 3.194093653634545
Validation loss: 3.145067284817021

Epoch: 5| Step: 7
Training loss: 3.347663799264023
Validation loss: 3.143728193350443

Epoch: 5| Step: 8
Training loss: 3.64523325023357
Validation loss: 3.1388207382623663

Epoch: 5| Step: 9
Training loss: 3.3832232289806505
Validation loss: 3.1382121134750847

Epoch: 5| Step: 10
Training loss: 3.2365410227669327
Validation loss: 3.1347667437629902

Epoch: 17| Step: 0
Training loss: 2.7185982848181722
Validation loss: 3.1314999061530715

Epoch: 5| Step: 1
Training loss: 4.076743641020319
Validation loss: 3.127286092043714

Epoch: 5| Step: 2
Training loss: 4.09183183532201
Validation loss: 3.126576388236189

Epoch: 5| Step: 3
Training loss: 3.353182456741029
Validation loss: 3.121784702177513

Epoch: 5| Step: 4
Training loss: 2.987633648680103
Validation loss: 3.1225189351938

Epoch: 5| Step: 5
Training loss: 3.1475427458922995
Validation loss: 3.119305499111102

Epoch: 5| Step: 6
Training loss: 3.9593136560615143
Validation loss: 3.1162146132266546

Epoch: 5| Step: 7
Training loss: 3.4865778643919274
Validation loss: 3.116473388952269

Epoch: 5| Step: 8
Training loss: 3.5601164222282584
Validation loss: 3.114529465616174

Epoch: 5| Step: 9
Training loss: 2.72043084112319
Validation loss: 3.1119883184941575

Epoch: 5| Step: 10
Training loss: 2.736217727993621
Validation loss: 3.110900377780029

Epoch: 18| Step: 0
Training loss: 3.7461698681493707
Validation loss: 3.114541504588957

Epoch: 5| Step: 1
Training loss: 3.518179681610183
Validation loss: 3.1059442834145825

Epoch: 5| Step: 2
Training loss: 3.1481524544314516
Validation loss: 3.107745552413247

Epoch: 5| Step: 3
Training loss: 3.52001882006209
Validation loss: 3.106547508337302

Epoch: 5| Step: 4
Training loss: 3.40028643243048
Validation loss: 3.105229128957882

Epoch: 5| Step: 5
Training loss: 2.920807179230952
Validation loss: 3.100397710134153

Epoch: 5| Step: 6
Training loss: 2.967233370827634
Validation loss: 3.100662656775904

Epoch: 5| Step: 7
Training loss: 3.9627730651534616
Validation loss: 3.1072016921636667

Epoch: 5| Step: 8
Training loss: 2.8035401784250316
Validation loss: 3.0982058346260475

Epoch: 5| Step: 9
Training loss: 3.3094183064365765
Validation loss: 3.097101634435148

Epoch: 5| Step: 10
Training loss: 3.7789437062455886
Validation loss: 3.102333517513213

Epoch: 19| Step: 0
Training loss: 2.47654882962759
Validation loss: 3.099241655978643

Epoch: 5| Step: 1
Training loss: 3.9350031853436347
Validation loss: 3.101998614223047

Epoch: 5| Step: 2
Training loss: 3.122636282568056
Validation loss: 3.091783730890157

Epoch: 5| Step: 3
Training loss: 3.1805202883820076
Validation loss: 3.0867129386791734

Epoch: 5| Step: 4
Training loss: 3.3090603802251155
Validation loss: 3.0856324237822244

Epoch: 5| Step: 5
Training loss: 3.183098839982456
Validation loss: 3.085352136690015

Epoch: 5| Step: 6
Training loss: 3.4900257494394635
Validation loss: 3.0888564494403226

Epoch: 5| Step: 7
Training loss: 3.681306195437352
Validation loss: 3.0795779507627783

Epoch: 5| Step: 8
Training loss: 4.050857057662159
Validation loss: 3.085954723047887

Epoch: 5| Step: 9
Training loss: 2.9577005452824268
Validation loss: 3.06978198152293

Epoch: 5| Step: 10
Training loss: 3.361568426822219
Validation loss: 3.0720451463670693

Epoch: 20| Step: 0
Training loss: 3.418110906641998
Validation loss: 3.071122343529433

Epoch: 5| Step: 1
Training loss: 4.450356141315647
Validation loss: 3.070592184551261

Epoch: 5| Step: 2
Training loss: 3.17737572163577
Validation loss: 3.0722126639067375

Epoch: 5| Step: 3
Training loss: 3.046574191381012
Validation loss: 3.0664464632972472

Epoch: 5| Step: 4
Training loss: 3.256525384603413
Validation loss: 3.066009022974618

Epoch: 5| Step: 5
Training loss: 2.8501382693830926
Validation loss: 3.064101728875427

Epoch: 5| Step: 6
Training loss: 3.4567159217947396
Validation loss: 3.0615014814706347

Epoch: 5| Step: 7
Training loss: 2.309938197444508
Validation loss: 3.058797943034392

Epoch: 5| Step: 8
Training loss: 3.2487946255750053
Validation loss: 3.0581933940577413

Epoch: 5| Step: 9
Training loss: 3.743537675189275
Validation loss: 3.057527155739928

Epoch: 5| Step: 10
Training loss: 3.432049956467202
Validation loss: 3.0557298428475868

Epoch: 21| Step: 0
Training loss: 3.5041814077266085
Validation loss: 3.054712903933907

Epoch: 5| Step: 1
Training loss: 3.361565447979165
Validation loss: 3.0508046881897855

Epoch: 5| Step: 2
Training loss: 3.6446903435264995
Validation loss: 3.056639967449859

Epoch: 5| Step: 3
Training loss: 2.624500317925819
Validation loss: 3.0606085984938622

Epoch: 5| Step: 4
Training loss: 3.7368813248252395
Validation loss: 3.0458390604856977

Epoch: 5| Step: 5
Training loss: 2.7226192958956457
Validation loss: 3.0441181273651274

Epoch: 5| Step: 6
Training loss: 3.7691413638232514
Validation loss: 3.0423927491247253

Epoch: 5| Step: 7
Training loss: 3.39477369630093
Validation loss: 3.0432583252785115

Epoch: 5| Step: 8
Training loss: 3.4613918583139007
Validation loss: 3.041033969085942

Epoch: 5| Step: 9
Training loss: 2.452492990901781
Validation loss: 3.037947172557233

Epoch: 5| Step: 10
Training loss: 3.672662009449922
Validation loss: 3.0405755706591493

Epoch: 22| Step: 0
Training loss: 3.2866785103647063
Validation loss: 3.0391126612153996

Epoch: 5| Step: 1
Training loss: 2.55828529420497
Validation loss: 3.035092554376788

Epoch: 5| Step: 2
Training loss: 3.1611198399100515
Validation loss: 3.039249824258957

Epoch: 5| Step: 3
Training loss: 3.516094396832099
Validation loss: 3.051538059124203

Epoch: 5| Step: 4
Training loss: 3.492090006241869
Validation loss: 3.032751435691624

Epoch: 5| Step: 5
Training loss: 3.6235984197351843
Validation loss: 3.0315291023885527

Epoch: 5| Step: 6
Training loss: 2.707938082292824
Validation loss: 3.0325576115105655

Epoch: 5| Step: 7
Training loss: 3.475209450755959
Validation loss: 3.034425640649946

Epoch: 5| Step: 8
Training loss: 3.881139260399988
Validation loss: 3.034141682737645

Epoch: 5| Step: 9
Training loss: 2.8222737348499396
Validation loss: 3.031879566453587

Epoch: 5| Step: 10
Training loss: 3.7903872975968684
Validation loss: 3.024655247928975

Epoch: 23| Step: 0
Training loss: 3.591259566127359
Validation loss: 3.0202470617158785

Epoch: 5| Step: 1
Training loss: 2.898181667501925
Validation loss: 3.019870095010143

Epoch: 5| Step: 2
Training loss: 2.6861424233120346
Validation loss: 3.0227920535602535

Epoch: 5| Step: 3
Training loss: 3.7937126648022588
Validation loss: 3.026493825699863

Epoch: 5| Step: 4
Training loss: 3.579901108681218
Validation loss: 3.0197560848922413

Epoch: 5| Step: 5
Training loss: 3.6281285432967465
Validation loss: 3.015946003217563

Epoch: 5| Step: 6
Training loss: 3.2901115284947533
Validation loss: 3.0128378221400527

Epoch: 5| Step: 7
Training loss: 3.27821616745137
Validation loss: 3.013665864158891

Epoch: 5| Step: 8
Training loss: 3.1672972168476825
Validation loss: 3.0140836111965106

Epoch: 5| Step: 9
Training loss: 3.0401312902609856
Validation loss: 3.014464071423862

Epoch: 5| Step: 10
Training loss: 3.193356985855375
Validation loss: 3.017997313976129

Epoch: 24| Step: 0
Training loss: 4.020805134781437
Validation loss: 3.015921534192381

Epoch: 5| Step: 1
Training loss: 2.9395352070142597
Validation loss: 3.0134624378413584

Epoch: 5| Step: 2
Training loss: 3.59055285667672
Validation loss: 3.009274322441214

Epoch: 5| Step: 3
Training loss: 3.1650122453353253
Validation loss: 3.0069162977725905

Epoch: 5| Step: 4
Training loss: 3.3219320498687677
Validation loss: 3.006879782345956

Epoch: 5| Step: 5
Training loss: 3.5111846687428927
Validation loss: 3.0071122878922707

Epoch: 5| Step: 6
Training loss: 2.6248513134217757
Validation loss: 3.007570790728382

Epoch: 5| Step: 7
Training loss: 2.497637299819855
Validation loss: 3.011588843942904

Epoch: 5| Step: 8
Training loss: 3.8997860336296992
Validation loss: 3.0336162920507412

Epoch: 5| Step: 9
Training loss: 2.796749090845
Validation loss: 3.0070134137412823

Epoch: 5| Step: 10
Training loss: 3.5257525567329018
Validation loss: 2.9994635290302027

Epoch: 25| Step: 0
Training loss: 2.9703167445249297
Validation loss: 2.9975273186376996

Epoch: 5| Step: 1
Training loss: 3.9042262824252236
Validation loss: 3.0005175356037594

Epoch: 5| Step: 2
Training loss: 3.0740893868707984
Validation loss: 2.9975322825150386

Epoch: 5| Step: 3
Training loss: 3.7877111797819687
Validation loss: 2.9980450707308894

Epoch: 5| Step: 4
Training loss: 3.4586643995053583
Validation loss: 2.999755208477693

Epoch: 5| Step: 5
Training loss: 2.975448119449513
Validation loss: 2.9971633150542334

Epoch: 5| Step: 6
Training loss: 3.6005646156898523
Validation loss: 2.997423844212684

Epoch: 5| Step: 7
Training loss: 3.2849311161802643
Validation loss: 2.9948858710511486

Epoch: 5| Step: 8
Training loss: 2.6654475127293793
Validation loss: 2.997059074895113

Epoch: 5| Step: 9
Training loss: 3.0063937717882805
Validation loss: 2.9925456332209137

Epoch: 5| Step: 10
Training loss: 3.167117003158288
Validation loss: 2.9914828421526867

Epoch: 26| Step: 0
Training loss: 3.419033037426041
Validation loss: 2.9888304318683296

Epoch: 5| Step: 1
Training loss: 2.8064496553419143
Validation loss: 2.98683339361797

Epoch: 5| Step: 2
Training loss: 3.5271152832122366
Validation loss: 2.988381225191833

Epoch: 5| Step: 3
Training loss: 3.6348755587721002
Validation loss: 2.9871078835252014

Epoch: 5| Step: 4
Training loss: 2.978491611071228
Validation loss: 2.9867276097057256

Epoch: 5| Step: 5
Training loss: 3.1585100599246188
Validation loss: 2.9852390997985307

Epoch: 5| Step: 6
Training loss: 3.2253273731232865
Validation loss: 2.9839295197218316

Epoch: 5| Step: 7
Training loss: 3.6696847429957895
Validation loss: 2.988163480583411

Epoch: 5| Step: 8
Training loss: 4.0128223420435285
Validation loss: 2.9960630350345703

Epoch: 5| Step: 9
Training loss: 2.837463808879193
Validation loss: 2.9876997993595893

Epoch: 5| Step: 10
Training loss: 2.1091717657446845
Validation loss: 2.9807007784678143

Epoch: 27| Step: 0
Training loss: 3.404352762154212
Validation loss: 2.9849361456284695

Epoch: 5| Step: 1
Training loss: 3.2896739545390896
Validation loss: 2.982821472037931

Epoch: 5| Step: 2
Training loss: 2.5934364405077233
Validation loss: 2.9843881232341376

Epoch: 5| Step: 3
Training loss: 3.5690404182554607
Validation loss: 2.985159696656047

Epoch: 5| Step: 4
Training loss: 3.466922175332468
Validation loss: 2.976012825364817

Epoch: 5| Step: 5
Training loss: 3.525895371588147
Validation loss: 2.9760546227430753

Epoch: 5| Step: 6
Training loss: 3.1611730875272617
Validation loss: 2.9709530698315016

Epoch: 5| Step: 7
Training loss: 3.0539890281015496
Validation loss: 2.9682222969201635

Epoch: 5| Step: 8
Training loss: 3.2785716433484944
Validation loss: 2.964382395301599

Epoch: 5| Step: 9
Training loss: 3.17816440554095
Validation loss: 2.9655768871127117

Epoch: 5| Step: 10
Training loss: 3.1706127041533736
Validation loss: 2.9617952238754297

Epoch: 28| Step: 0
Training loss: 3.591659335831834
Validation loss: 2.9629519671175704

Epoch: 5| Step: 1
Training loss: 3.6058419510770934
Validation loss: 2.961034887629353

Epoch: 5| Step: 2
Training loss: 3.088534341753057
Validation loss: 2.963226248516952

Epoch: 5| Step: 3
Training loss: 3.79429972403512
Validation loss: 2.9613879366034586

Epoch: 5| Step: 4
Training loss: 3.9655148995148064
Validation loss: 2.962714570845765

Epoch: 5| Step: 5
Training loss: 3.1107723604186672
Validation loss: 2.958487712177611

Epoch: 5| Step: 6
Training loss: 3.145606194858136
Validation loss: 2.9581330067044513

Epoch: 5| Step: 7
Training loss: 2.643204010842169
Validation loss: 2.960281071162672

Epoch: 5| Step: 8
Training loss: 3.0550065520320877
Validation loss: 2.9562125940329644

Epoch: 5| Step: 9
Training loss: 2.7073415162821464
Validation loss: 2.960453930886026

Epoch: 5| Step: 10
Training loss: 2.5048909029170026
Validation loss: 2.95983603541621

Epoch: 29| Step: 0
Training loss: 3.2721533247972117
Validation loss: 2.956826174612543

Epoch: 5| Step: 1
Training loss: 3.0569833386646934
Validation loss: 2.9529851926042556

Epoch: 5| Step: 2
Training loss: 3.15656920981159
Validation loss: 2.9520954143614406

Epoch: 5| Step: 3
Training loss: 3.625243080144657
Validation loss: 2.9493565646235376

Epoch: 5| Step: 4
Training loss: 3.265989146395027
Validation loss: 2.9494818287795983

Epoch: 5| Step: 5
Training loss: 3.4338907887994714
Validation loss: 2.945173991277378

Epoch: 5| Step: 6
Training loss: 3.4765873254468267
Validation loss: 2.948440516228857

Epoch: 5| Step: 7
Training loss: 2.6970179372946994
Validation loss: 2.9480956857462024

Epoch: 5| Step: 8
Training loss: 3.2496515233942445
Validation loss: 2.949585902963403

Epoch: 5| Step: 9
Training loss: 3.5673019437607163
Validation loss: 2.942249249145085

Epoch: 5| Step: 10
Training loss: 2.5355261017109005
Validation loss: 2.945533778728117

Epoch: 30| Step: 0
Training loss: 3.078274021317365
Validation loss: 2.9440682731291847

Epoch: 5| Step: 1
Training loss: 3.0751539114293927
Validation loss: 2.945155073623944

Epoch: 5| Step: 2
Training loss: 3.541635281292844
Validation loss: 2.9438299392517226

Epoch: 5| Step: 3
Training loss: 3.722137703260218
Validation loss: 2.9424525698714485

Epoch: 5| Step: 4
Training loss: 3.067437842748964
Validation loss: 2.946019853447928

Epoch: 5| Step: 5
Training loss: 3.5389075508470667
Validation loss: 2.9445025904646376

Epoch: 5| Step: 6
Training loss: 3.7073611724646067
Validation loss: 2.943076780475486

Epoch: 5| Step: 7
Training loss: 2.487312068261772
Validation loss: 2.948474916545178

Epoch: 5| Step: 8
Training loss: 2.983874533666926
Validation loss: 3.0437059133665088

Epoch: 5| Step: 9
Training loss: 2.750829831544561
Validation loss: 3.0360633228573612

Epoch: 5| Step: 10
Training loss: 3.568401467962939
Validation loss: 3.027175077409569

Epoch: 31| Step: 0
Training loss: 2.912404752164384
Validation loss: 3.0216596486680407

Epoch: 5| Step: 1
Training loss: 3.8912266032504763
Validation loss: 3.0237116709353686

Epoch: 5| Step: 2
Training loss: 3.6462944974332117
Validation loss: 3.026893585746242

Epoch: 5| Step: 3
Training loss: 3.144079936557106
Validation loss: 3.0342755388376754

Epoch: 5| Step: 4
Training loss: 2.7815610733088567
Validation loss: 3.0289442864617064

Epoch: 5| Step: 5
Training loss: 3.2411825437988777
Validation loss: 3.0317739497547698

Epoch: 5| Step: 6
Training loss: 3.654783036123717
Validation loss: 3.023118840721095

Epoch: 5| Step: 7
Training loss: 3.2528081646187723
Validation loss: 3.0231023332771314

Epoch: 5| Step: 8
Training loss: 3.221278114418202
Validation loss: 3.0351283148065726

Epoch: 5| Step: 9
Training loss: 3.323328708146785
Validation loss: 3.0224146849937172

Epoch: 5| Step: 10
Training loss: 2.9208811329310205
Validation loss: 3.019078723555855

Epoch: 32| Step: 0
Training loss: 3.093167028505792
Validation loss: 3.0138966306798642

Epoch: 5| Step: 1
Training loss: 2.847665962024762
Validation loss: 3.0108769442441177

Epoch: 5| Step: 2
Training loss: 3.7270504933860265
Validation loss: 3.0109741180783494

Epoch: 5| Step: 3
Training loss: 3.0991572126583016
Validation loss: 3.0089084034576614

Epoch: 5| Step: 4
Training loss: 3.627261541561837
Validation loss: 3.010104777257773

Epoch: 5| Step: 5
Training loss: 3.1747929723330452
Validation loss: 3.005563279332684

Epoch: 5| Step: 6
Training loss: 2.972537385466431
Validation loss: 3.005157856433688

Epoch: 5| Step: 7
Training loss: 3.3810666977701738
Validation loss: 3.0007354474057713

Epoch: 5| Step: 8
Training loss: 3.2933625950716676
Validation loss: 2.99866518965952

Epoch: 5| Step: 9
Training loss: 3.5991072819421084
Validation loss: 3.0003169364048823

Epoch: 5| Step: 10
Training loss: 3.0667651312680153
Validation loss: 2.9873471498700583

Epoch: 33| Step: 0
Training loss: 3.1627283368211914
Validation loss: 2.957170859173227

Epoch: 5| Step: 1
Training loss: 2.637217834710444
Validation loss: 2.983473919362938

Epoch: 5| Step: 2
Training loss: 3.5486855612101373
Validation loss: 3.078758215841626

Epoch: 5| Step: 3
Training loss: 3.5284480228322908
Validation loss: 2.951265034852621

Epoch: 5| Step: 4
Training loss: 2.665453952967604
Validation loss: 2.9304593219854143

Epoch: 5| Step: 5
Training loss: 4.013303568107595
Validation loss: 2.937614350546657

Epoch: 5| Step: 6
Training loss: 2.9613669695443194
Validation loss: 2.9517892852010394

Epoch: 5| Step: 7
Training loss: 3.2925276455192884
Validation loss: 2.9911373358997078

Epoch: 5| Step: 8
Training loss: 3.336308264396893
Validation loss: 2.9756796683928113

Epoch: 5| Step: 9
Training loss: 3.236290111330006
Validation loss: 2.942753215813779

Epoch: 5| Step: 10
Training loss: 3.1147930538203403
Validation loss: 2.9229903720889134

Epoch: 34| Step: 0
Training loss: 2.94630670336739
Validation loss: 2.92251474622935

Epoch: 5| Step: 1
Training loss: 2.7707478980944695
Validation loss: 2.924994257930157

Epoch: 5| Step: 2
Training loss: 2.781662385349472
Validation loss: 2.929030892026591

Epoch: 5| Step: 3
Training loss: 3.10344832811319
Validation loss: 2.927772134094388

Epoch: 5| Step: 4
Training loss: 3.2572205369333993
Validation loss: 2.9285733803677587

Epoch: 5| Step: 5
Training loss: 2.930817978505715
Validation loss: 2.9333834205357006

Epoch: 5| Step: 6
Training loss: 3.4376826844656136
Validation loss: 2.9427577676776218

Epoch: 5| Step: 7
Training loss: 4.1022820704365035
Validation loss: 2.9199518193214327

Epoch: 5| Step: 8
Training loss: 3.0978689806170525
Validation loss: 2.9157808573065758

Epoch: 5| Step: 9
Training loss: 3.426629791086089
Validation loss: 2.9253879504401707

Epoch: 5| Step: 10
Training loss: 3.319243566446059
Validation loss: 2.9249816053254016

Epoch: 35| Step: 0
Training loss: 3.3314995648943304
Validation loss: 2.9254496644292978

Epoch: 5| Step: 1
Training loss: 2.53211093907836
Validation loss: 2.919138038612932

Epoch: 5| Step: 2
Training loss: 3.853894871931372
Validation loss: 2.9128421466113426

Epoch: 5| Step: 3
Training loss: 3.6261601400303625
Validation loss: 2.904712416253785

Epoch: 5| Step: 4
Training loss: 3.6028657156562565
Validation loss: 2.8902912314145195

Epoch: 5| Step: 5
Training loss: 3.266074993760579
Validation loss: 2.8872736728104442

Epoch: 5| Step: 6
Training loss: 2.6426512037774983
Validation loss: 2.8863623214744405

Epoch: 5| Step: 7
Training loss: 3.7065150199944994
Validation loss: 2.8934153854494156

Epoch: 5| Step: 8
Training loss: 2.7267581027896757
Validation loss: 2.8960995277716215

Epoch: 5| Step: 9
Training loss: 2.792346719686131
Validation loss: 2.908047577431769

Epoch: 5| Step: 10
Training loss: 2.6928643206652128
Validation loss: 2.9249961353069978

Epoch: 36| Step: 0
Training loss: 3.173006804787462
Validation loss: 2.9193426492953596

Epoch: 5| Step: 1
Training loss: 3.3992628476494233
Validation loss: 2.89582892755678

Epoch: 5| Step: 2
Training loss: 3.244548921194804
Validation loss: 2.886450171095603

Epoch: 5| Step: 3
Training loss: 3.8033190387008085
Validation loss: 2.8797767836708883

Epoch: 5| Step: 4
Training loss: 3.4154385165919936
Validation loss: 2.8816562035169353

Epoch: 5| Step: 5
Training loss: 2.8546841191781773
Validation loss: 2.876203475032306

Epoch: 5| Step: 6
Training loss: 3.1169705805438053
Validation loss: 2.8891389387629687

Epoch: 5| Step: 7
Training loss: 2.6751091551569246
Validation loss: 2.8736927989523835

Epoch: 5| Step: 8
Training loss: 3.265620035414139
Validation loss: 2.8763087335928197

Epoch: 5| Step: 9
Training loss: 2.634999168004985
Validation loss: 2.882606941660397

Epoch: 5| Step: 10
Training loss: 3.22508076411407
Validation loss: 2.876441959555617

Epoch: 37| Step: 0
Training loss: 3.113965197477106
Validation loss: 2.878527740539898

Epoch: 5| Step: 1
Training loss: 3.217680373749056
Validation loss: 2.874314854730959

Epoch: 5| Step: 2
Training loss: 3.1237871486718682
Validation loss: 2.881185699607406

Epoch: 5| Step: 3
Training loss: 3.3234528175793723
Validation loss: 2.8829403104789053

Epoch: 5| Step: 4
Training loss: 3.524146843871982
Validation loss: 2.887754143362925

Epoch: 5| Step: 5
Training loss: 3.177990209671218
Validation loss: 2.890030528110017

Epoch: 5| Step: 6
Training loss: 2.6008214496543545
Validation loss: 2.883342610698197

Epoch: 5| Step: 7
Training loss: 3.0380314742687347
Validation loss: 2.8860461570625158

Epoch: 5| Step: 8
Training loss: 3.647303141457874
Validation loss: 2.885635974179288

Epoch: 5| Step: 9
Training loss: 2.5235521981358557
Validation loss: 2.878196346607413

Epoch: 5| Step: 10
Training loss: 3.4414875830609635
Validation loss: 2.8717533155644297

Epoch: 38| Step: 0
Training loss: 3.088931097188986
Validation loss: 2.8686822740838793

Epoch: 5| Step: 1
Training loss: 3.442374085760215
Validation loss: 2.8678136629517677

Epoch: 5| Step: 2
Training loss: 3.376752469051241
Validation loss: 2.8659292722018384

Epoch: 5| Step: 3
Training loss: 3.732746359685076
Validation loss: 2.8659435138726086

Epoch: 5| Step: 4
Training loss: 2.7683021820477567
Validation loss: 2.866521518745267

Epoch: 5| Step: 5
Training loss: 2.6605159835579055
Validation loss: 2.8650258750314754

Epoch: 5| Step: 6
Training loss: 3.285942718313067
Validation loss: 2.864310247356816

Epoch: 5| Step: 7
Training loss: 3.217092735521516
Validation loss: 2.8645649738040384

Epoch: 5| Step: 8
Training loss: 2.9593596670524946
Validation loss: 2.8627752247442855

Epoch: 5| Step: 9
Training loss: 3.4181841449987878
Validation loss: 2.862059396194412

Epoch: 5| Step: 10
Training loss: 2.4748088030705264
Validation loss: 2.8613665408952893

Epoch: 39| Step: 0
Training loss: 2.8936405433073524
Validation loss: 2.8603810477618965

Epoch: 5| Step: 1
Training loss: 2.659946875938033
Validation loss: 2.8601841365914416

Epoch: 5| Step: 2
Training loss: 2.314024036404624
Validation loss: 2.8631190410013803

Epoch: 5| Step: 3
Training loss: 3.334944494606243
Validation loss: 2.8621685911123245

Epoch: 5| Step: 4
Training loss: 3.304452441357694
Validation loss: 2.861623253924804

Epoch: 5| Step: 5
Training loss: 3.3768237802369017
Validation loss: 2.8625536198082546

Epoch: 5| Step: 6
Training loss: 2.9886230273300285
Validation loss: 2.859506674965231

Epoch: 5| Step: 7
Training loss: 3.5644710508967057
Validation loss: 2.856782475463095

Epoch: 5| Step: 8
Training loss: 3.1942357718455434
Validation loss: 2.857642138383056

Epoch: 5| Step: 9
Training loss: 3.365668217373554
Validation loss: 2.854926746809979

Epoch: 5| Step: 10
Training loss: 3.459248632312903
Validation loss: 2.8559952667075086

Epoch: 40| Step: 0
Training loss: 3.0949746222372294
Validation loss: 2.85371217431662

Epoch: 5| Step: 1
Training loss: 3.297405760649758
Validation loss: 2.8521893140374015

Epoch: 5| Step: 2
Training loss: 3.4804070977809736
Validation loss: 2.854595686217936

Epoch: 5| Step: 3
Training loss: 2.2630158231538564
Validation loss: 2.8557592526189044

Epoch: 5| Step: 4
Training loss: 4.105723800504046
Validation loss: 2.858446969960062

Epoch: 5| Step: 5
Training loss: 2.752650977211559
Validation loss: 2.8554678180831603

Epoch: 5| Step: 6
Training loss: 2.167201110753098
Validation loss: 2.8551961693146573

Epoch: 5| Step: 7
Training loss: 3.230724836575459
Validation loss: 2.8541747777895594

Epoch: 5| Step: 8
Training loss: 3.2322728794021933
Validation loss: 2.8443018069024064

Epoch: 5| Step: 9
Training loss: 3.334712569677225
Validation loss: 2.844815045417178

Epoch: 5| Step: 10
Training loss: 3.068779094115281
Validation loss: 2.8457365835335446

Epoch: 41| Step: 0
Training loss: 3.0174667189689846
Validation loss: 2.8416171138668536

Epoch: 5| Step: 1
Training loss: 3.245925696988625
Validation loss: 2.8442179031131456

Epoch: 5| Step: 2
Training loss: 2.859412854887315
Validation loss: 2.8406519303706483

Epoch: 5| Step: 3
Training loss: 2.6113250207418908
Validation loss: 2.839195779555518

Epoch: 5| Step: 4
Training loss: 3.489381213051965
Validation loss: 2.843407808774996

Epoch: 5| Step: 5
Training loss: 3.244534224599076
Validation loss: 2.85315607471798

Epoch: 5| Step: 6
Training loss: 2.7396011545353454
Validation loss: 2.851663655279195

Epoch: 5| Step: 7
Training loss: 2.9491990246649955
Validation loss: 2.8521906299279722

Epoch: 5| Step: 8
Training loss: 3.6524453215321686
Validation loss: 2.85801627646113

Epoch: 5| Step: 9
Training loss: 3.431653408662871
Validation loss: 2.8580082895618597

Epoch: 5| Step: 10
Training loss: 3.067010477392051
Validation loss: 2.849627752916106

Epoch: 42| Step: 0
Training loss: 2.6949810321826875
Validation loss: 2.8335746617723774

Epoch: 5| Step: 1
Training loss: 3.606733139704134
Validation loss: 2.831095585130789

Epoch: 5| Step: 2
Training loss: 2.949115594739836
Validation loss: 2.8297921121711527

Epoch: 5| Step: 3
Training loss: 2.9359227267914307
Validation loss: 2.8293513094354075

Epoch: 5| Step: 4
Training loss: 3.63955738310942
Validation loss: 2.829150933713631

Epoch: 5| Step: 5
Training loss: 2.432198456660263
Validation loss: 2.8261169826936503

Epoch: 5| Step: 6
Training loss: 2.3096380308518323
Validation loss: 2.824712322875843

Epoch: 5| Step: 7
Training loss: 3.4051658935018225
Validation loss: 2.823399718611045

Epoch: 5| Step: 8
Training loss: 3.530580440273137
Validation loss: 2.82969458352358

Epoch: 5| Step: 9
Training loss: 3.644134794302737
Validation loss: 2.8325802479612867

Epoch: 5| Step: 10
Training loss: 2.8212408931181248
Validation loss: 2.8298019398631595

Epoch: 43| Step: 0
Training loss: 3.161803543541126
Validation loss: 2.8246592409894227

Epoch: 5| Step: 1
Training loss: 3.2152384148411173
Validation loss: 2.820832887912666

Epoch: 5| Step: 2
Training loss: 2.444027596631618
Validation loss: 2.81864467247893

Epoch: 5| Step: 3
Training loss: 2.5167629914028495
Validation loss: 2.8205445887535374

Epoch: 5| Step: 4
Training loss: 3.3165202666005182
Validation loss: 2.8170135759401327

Epoch: 5| Step: 5
Training loss: 3.0832843432959227
Validation loss: 2.816586741812049

Epoch: 5| Step: 6
Training loss: 3.565897074824537
Validation loss: 2.8144859202804953

Epoch: 5| Step: 7
Training loss: 3.4338730144094374
Validation loss: 2.8143669686184367

Epoch: 5| Step: 8
Training loss: 3.2201438774520152
Validation loss: 2.813547713585491

Epoch: 5| Step: 9
Training loss: 2.8833331539911056
Validation loss: 2.811015540608811

Epoch: 5| Step: 10
Training loss: 3.285727361688599
Validation loss: 2.809713786997345

Epoch: 44| Step: 0
Training loss: 2.849337276569661
Validation loss: 2.8114878566284687

Epoch: 5| Step: 1
Training loss: 3.1519403022205554
Validation loss: 2.8087100125971842

Epoch: 5| Step: 2
Training loss: 3.6668353619927427
Validation loss: 2.809951287331518

Epoch: 5| Step: 3
Training loss: 3.1368294170234865
Validation loss: 2.808041404516441

Epoch: 5| Step: 4
Training loss: 3.1230213767818538
Validation loss: 2.8096698171063648

Epoch: 5| Step: 5
Training loss: 3.1027946426933513
Validation loss: 2.8094028214234803

Epoch: 5| Step: 6
Training loss: 2.4329696026340546
Validation loss: 2.807372761391674

Epoch: 5| Step: 7
Training loss: 3.0216840050507257
Validation loss: 2.8079271474896648

Epoch: 5| Step: 8
Training loss: 2.89517760685664
Validation loss: 2.8078720400271964

Epoch: 5| Step: 9
Training loss: 2.780394519009029
Validation loss: 2.820205818717188

Epoch: 5| Step: 10
Training loss: 3.9408253751144566
Validation loss: 2.83539027142942

Epoch: 45| Step: 0
Training loss: 3.2921316727809864
Validation loss: 2.824186746733132

Epoch: 5| Step: 1
Training loss: 2.252068204826007
Validation loss: 2.809137112694284

Epoch: 5| Step: 2
Training loss: 3.0218621617609593
Validation loss: 2.811793141200585

Epoch: 5| Step: 3
Training loss: 3.4207452450622817
Validation loss: 2.812035169211051

Epoch: 5| Step: 4
Training loss: 2.6271247439003402
Validation loss: 2.80135586669403

Epoch: 5| Step: 5
Training loss: 3.626850313651204
Validation loss: 2.804683770650207

Epoch: 5| Step: 6
Training loss: 2.7639704350934284
Validation loss: 2.804209963953935

Epoch: 5| Step: 7
Training loss: 3.3539916441056423
Validation loss: 2.8099597191969785

Epoch: 5| Step: 8
Training loss: 3.3556361484182533
Validation loss: 2.810598554213539

Epoch: 5| Step: 9
Training loss: 2.972637321822951
Validation loss: 2.808392978627697

Epoch: 5| Step: 10
Training loss: 3.2713273924556026
Validation loss: 2.8043571005855394

Epoch: 46| Step: 0
Training loss: 3.291206875006765
Validation loss: 2.799252820414428

Epoch: 5| Step: 1
Training loss: 3.2160938747806114
Validation loss: 2.7972641247569547

Epoch: 5| Step: 2
Training loss: 3.560746681688034
Validation loss: 2.799989074987495

Epoch: 5| Step: 3
Training loss: 3.1472248932199647
Validation loss: 2.7981204345904533

Epoch: 5| Step: 4
Training loss: 2.920828728846804
Validation loss: 2.8073704145144522

Epoch: 5| Step: 5
Training loss: 3.1604015882245946
Validation loss: 2.8117901005266406

Epoch: 5| Step: 6
Training loss: 2.9092221393029694
Validation loss: 2.8088235541591473

Epoch: 5| Step: 7
Training loss: 3.280845980520937
Validation loss: 2.808797762688704

Epoch: 5| Step: 8
Training loss: 2.803602768616106
Validation loss: 2.8066651456427985

Epoch: 5| Step: 9
Training loss: 2.669943574316311
Validation loss: 2.814096939486459

Epoch: 5| Step: 10
Training loss: 3.079665364999252
Validation loss: 2.8105088709209567

Epoch: 47| Step: 0
Training loss: 3.1617537752685303
Validation loss: 2.8015879061817466

Epoch: 5| Step: 1
Training loss: 3.2027584703592633
Validation loss: 2.803768312058313

Epoch: 5| Step: 2
Training loss: 3.1375383230353737
Validation loss: 2.8017844812984296

Epoch: 5| Step: 3
Training loss: 3.0328247070066836
Validation loss: 2.796785911524818

Epoch: 5| Step: 4
Training loss: 3.133005797399374
Validation loss: 2.796643420162688

Epoch: 5| Step: 5
Training loss: 3.0438716856270425
Validation loss: 2.788607845611832

Epoch: 5| Step: 6
Training loss: 2.709925833809803
Validation loss: 2.7874677950062177

Epoch: 5| Step: 7
Training loss: 3.2676883001729835
Validation loss: 2.7859748498317805

Epoch: 5| Step: 8
Training loss: 3.1862126162862454
Validation loss: 2.7905148030898244

Epoch: 5| Step: 9
Training loss: 3.395090142740181
Validation loss: 2.7830891608995127

Epoch: 5| Step: 10
Training loss: 2.542252822158662
Validation loss: 2.7822298059489334

Epoch: 48| Step: 0
Training loss: 3.0689807750687685
Validation loss: 2.788422238479428

Epoch: 5| Step: 1
Training loss: 3.0539167363495934
Validation loss: 2.7907994095145443

Epoch: 5| Step: 2
Training loss: 2.7339504239290275
Validation loss: 2.8073874535290426

Epoch: 5| Step: 3
Training loss: 3.5180894140143737
Validation loss: 2.8137895733656006

Epoch: 5| Step: 4
Training loss: 3.691581148717102
Validation loss: 2.7913276452427715

Epoch: 5| Step: 5
Training loss: 2.99421547474528
Validation loss: 2.783582195552843

Epoch: 5| Step: 6
Training loss: 2.686514296632259
Validation loss: 2.7766672483955053

Epoch: 5| Step: 7
Training loss: 3.1156926215666654
Validation loss: 2.7768116705206434

Epoch: 5| Step: 8
Training loss: 2.849089587510567
Validation loss: 2.775675865051767

Epoch: 5| Step: 9
Training loss: 3.115996092464558
Validation loss: 2.777522285224121

Epoch: 5| Step: 10
Training loss: 2.9428548500697587
Validation loss: 2.777573593148379

Epoch: 49| Step: 0
Training loss: 3.1561697770300614
Validation loss: 2.775532070103583

Epoch: 5| Step: 1
Training loss: 2.9667735698455124
Validation loss: 2.7811821817183726

Epoch: 5| Step: 2
Training loss: 3.659468579093428
Validation loss: 2.7787984726963684

Epoch: 5| Step: 3
Training loss: 2.9575056252381717
Validation loss: 2.7720495055100542

Epoch: 5| Step: 4
Training loss: 2.9298185192057473
Validation loss: 2.771243595563983

Epoch: 5| Step: 5
Training loss: 3.15727594905118
Validation loss: 2.770478880906208

Epoch: 5| Step: 6
Training loss: 3.391148680577025
Validation loss: 2.766571370586537

Epoch: 5| Step: 7
Training loss: 3.049431300690244
Validation loss: 2.7650880101665885

Epoch: 5| Step: 8
Training loss: 2.6025632474251505
Validation loss: 2.7677176879733123

Epoch: 5| Step: 9
Training loss: 2.9793646330960164
Validation loss: 2.767087251007413

Epoch: 5| Step: 10
Training loss: 2.853658496327069
Validation loss: 2.7663859094695913

Epoch: 50| Step: 0
Training loss: 2.9170623147642516
Validation loss: 2.763509258218472

Epoch: 5| Step: 1
Training loss: 2.6193093879144365
Validation loss: 2.767863038326461

Epoch: 5| Step: 2
Training loss: 3.239315811019813
Validation loss: 2.7673925692368115

Epoch: 5| Step: 3
Training loss: 3.086032218928086
Validation loss: 2.7856260445760666

Epoch: 5| Step: 4
Training loss: 3.166824303434474
Validation loss: 2.7813150292970534

Epoch: 5| Step: 5
Training loss: 3.4535159066688466
Validation loss: 2.7773705839980902

Epoch: 5| Step: 6
Training loss: 3.597422307430086
Validation loss: 2.765909151497032

Epoch: 5| Step: 7
Training loss: 2.4146579637642707
Validation loss: 2.7627341431852503

Epoch: 5| Step: 8
Training loss: 3.087088454768259
Validation loss: 2.759938466371621

Epoch: 5| Step: 9
Training loss: 2.6408700321432637
Validation loss: 2.759758502852403

Epoch: 5| Step: 10
Training loss: 3.3764907935214854
Validation loss: 2.758148677637825

Epoch: 51| Step: 0
Training loss: 3.2975654059944777
Validation loss: 2.7567132000264793

Epoch: 5| Step: 1
Training loss: 3.112582904983105
Validation loss: 2.755248135170803

Epoch: 5| Step: 2
Training loss: 3.33047989466013
Validation loss: 2.755679514423703

Epoch: 5| Step: 3
Training loss: 2.731237562487324
Validation loss: 2.762748002803477

Epoch: 5| Step: 4
Training loss: 3.3375167503365217
Validation loss: 2.776959415979616

Epoch: 5| Step: 5
Training loss: 3.532326053297141
Validation loss: 2.7917206323874963

Epoch: 5| Step: 6
Training loss: 2.817538601222468
Validation loss: 2.7821406815996106

Epoch: 5| Step: 7
Training loss: 2.877141072335882
Validation loss: 2.770707393957363

Epoch: 5| Step: 8
Training loss: 2.8063939250919443
Validation loss: 2.759805624616192

Epoch: 5| Step: 9
Training loss: 2.76368041559524
Validation loss: 2.7559280061955542

Epoch: 5| Step: 10
Training loss: 3.047767860463525
Validation loss: 2.7529894781019655

Epoch: 52| Step: 0
Training loss: 3.073619197561509
Validation loss: 2.7509805212169636

Epoch: 5| Step: 1
Training loss: 2.661202335674408
Validation loss: 2.753954195204351

Epoch: 5| Step: 2
Training loss: 3.132258111697677
Validation loss: 2.7523504375757137

Epoch: 5| Step: 3
Training loss: 2.843899733405619
Validation loss: 2.7500538032988655

Epoch: 5| Step: 4
Training loss: 2.9757163780073714
Validation loss: 2.75335229779925

Epoch: 5| Step: 5
Training loss: 3.107746560464999
Validation loss: 2.7558650271986096

Epoch: 5| Step: 6
Training loss: 3.4893803931291445
Validation loss: 2.7730155460923944

Epoch: 5| Step: 7
Training loss: 3.0398795395123956
Validation loss: 2.7927468034196665

Epoch: 5| Step: 8
Training loss: 3.0358356515682003
Validation loss: 2.7956485429803952

Epoch: 5| Step: 9
Training loss: 3.3355542572508043
Validation loss: 2.7891605615374546

Epoch: 5| Step: 10
Training loss: 3.0021329291061445
Validation loss: 2.7443936160070184

Epoch: 53| Step: 0
Training loss: 2.867790969413651
Validation loss: 2.7593577063542365

Epoch: 5| Step: 1
Training loss: 3.00162636859227
Validation loss: 2.7990975334113504

Epoch: 5| Step: 2
Training loss: 2.706276968806199
Validation loss: 2.8051375632042923

Epoch: 5| Step: 3
Training loss: 3.7410632138921303
Validation loss: 2.7811178166999215

Epoch: 5| Step: 4
Training loss: 3.2008116765586108
Validation loss: 2.766648888323886

Epoch: 5| Step: 5
Training loss: 2.3948361076710407
Validation loss: 2.7580179991220857

Epoch: 5| Step: 6
Training loss: 3.151609427424697
Validation loss: 2.7537172872749074

Epoch: 5| Step: 7
Training loss: 3.4197446558255433
Validation loss: 2.756182171758981

Epoch: 5| Step: 8
Training loss: 3.2591229554375003
Validation loss: 2.7564199578697495

Epoch: 5| Step: 9
Training loss: 2.748717442450238
Validation loss: 2.754361093545399

Epoch: 5| Step: 10
Training loss: 3.233605039788367
Validation loss: 2.7494694775095283

Epoch: 54| Step: 0
Training loss: 2.4650865244816766
Validation loss: 2.744856135702125

Epoch: 5| Step: 1
Training loss: 3.3607902916698804
Validation loss: 2.7455965175801054

Epoch: 5| Step: 2
Training loss: 2.919826176838974
Validation loss: 2.7496798935897817

Epoch: 5| Step: 3
Training loss: 3.5062694256630302
Validation loss: 2.7704130216783014

Epoch: 5| Step: 4
Training loss: 3.155682805529765
Validation loss: 2.769733750797138

Epoch: 5| Step: 5
Training loss: 3.102077796850821
Validation loss: 2.7502122071874915

Epoch: 5| Step: 6
Training loss: 3.0482037116833123
Validation loss: 2.734908652082178

Epoch: 5| Step: 7
Training loss: 3.2649342659705107
Validation loss: 2.7406868675821006

Epoch: 5| Step: 8
Training loss: 2.5274221416974507
Validation loss: 2.7419161818209186

Epoch: 5| Step: 9
Training loss: 3.1170017885038392
Validation loss: 2.7434405323095894

Epoch: 5| Step: 10
Training loss: 3.172261933276543
Validation loss: 2.74101177662146

Epoch: 55| Step: 0
Training loss: 2.3816493462942048
Validation loss: 2.7426355257300306

Epoch: 5| Step: 1
Training loss: 2.953639394373841
Validation loss: 2.744180704763533

Epoch: 5| Step: 2
Training loss: 3.6021902732941036
Validation loss: 2.743928493883279

Epoch: 5| Step: 3
Training loss: 2.8265232165692415
Validation loss: 2.7420601558270614

Epoch: 5| Step: 4
Training loss: 2.8234622517246555
Validation loss: 2.741424529195637

Epoch: 5| Step: 5
Training loss: 3.060688806686252
Validation loss: 2.7393340358365723

Epoch: 5| Step: 6
Training loss: 3.2538933541911326
Validation loss: 2.7405321011531134

Epoch: 5| Step: 7
Training loss: 3.528704780940207
Validation loss: 2.738414279310887

Epoch: 5| Step: 8
Training loss: 2.824591014592951
Validation loss: 2.737494886161945

Epoch: 5| Step: 9
Training loss: 2.9270937411484135
Validation loss: 2.735441392193672

Epoch: 5| Step: 10
Training loss: 3.36942707115643
Validation loss: 2.7363197791640608

Epoch: 56| Step: 0
Training loss: 2.866841557808545
Validation loss: 2.7327543006887964

Epoch: 5| Step: 1
Training loss: 3.1306488861129282
Validation loss: 2.7287955771959216

Epoch: 5| Step: 2
Training loss: 3.1488073240652428
Validation loss: 2.729555252793348

Epoch: 5| Step: 3
Training loss: 3.682330111995791
Validation loss: 2.7309453472794862

Epoch: 5| Step: 4
Training loss: 1.8310379556527203
Validation loss: 2.7283055790453776

Epoch: 5| Step: 5
Training loss: 2.8982283935794464
Validation loss: 2.7266854842790984

Epoch: 5| Step: 6
Training loss: 2.904736853021756
Validation loss: 2.7244825246815556

Epoch: 5| Step: 7
Training loss: 2.802344658635856
Validation loss: 2.730545284405049

Epoch: 5| Step: 8
Training loss: 3.1498416013098636
Validation loss: 2.7286424832480987

Epoch: 5| Step: 9
Training loss: 3.1640386886642613
Validation loss: 2.7292054730997086

Epoch: 5| Step: 10
Training loss: 3.670351791983502
Validation loss: 2.7295110172626993

Epoch: 57| Step: 0
Training loss: 3.559699044954421
Validation loss: 2.7272084442361213

Epoch: 5| Step: 1
Training loss: 3.2663674126656246
Validation loss: 2.722988413300559

Epoch: 5| Step: 2
Training loss: 2.6637271435104726
Validation loss: 2.7216592521810887

Epoch: 5| Step: 3
Training loss: 3.6536073181921007
Validation loss: 2.726592119481909

Epoch: 5| Step: 4
Training loss: 2.6813916718016824
Validation loss: 2.7312902335947786

Epoch: 5| Step: 5
Training loss: 2.649448978068862
Validation loss: 2.7184651694378315

Epoch: 5| Step: 6
Training loss: 2.828348899113613
Validation loss: 2.718560172226552

Epoch: 5| Step: 7
Training loss: 2.980434512520423
Validation loss: 2.718035213476298

Epoch: 5| Step: 8
Training loss: 2.7386317661380635
Validation loss: 2.716462745678178

Epoch: 5| Step: 9
Training loss: 3.237678499345559
Validation loss: 2.716463103356463

Epoch: 5| Step: 10
Training loss: 2.947359623304301
Validation loss: 2.7118474351632087

Epoch: 58| Step: 0
Training loss: 3.51045993736758
Validation loss: 2.7098179826886932

Epoch: 5| Step: 1
Training loss: 2.5738500119713184
Validation loss: 2.7132604404182223

Epoch: 5| Step: 2
Training loss: 2.577353529667288
Validation loss: 2.714954883929773

Epoch: 5| Step: 3
Training loss: 3.20560489582043
Validation loss: 2.712784533252451

Epoch: 5| Step: 4
Training loss: 2.6787523244900213
Validation loss: 2.710756915335351

Epoch: 5| Step: 5
Training loss: 3.446126482731786
Validation loss: 2.7126640213904194

Epoch: 5| Step: 6
Training loss: 2.9874590372126337
Validation loss: 2.712816830126656

Epoch: 5| Step: 7
Training loss: 3.2058513668681203
Validation loss: 2.7166051601989323

Epoch: 5| Step: 8
Training loss: 2.637851048108679
Validation loss: 2.7150150660808374

Epoch: 5| Step: 9
Training loss: 3.250364136470454
Validation loss: 2.7138618918158595

Epoch: 5| Step: 10
Training loss: 3.177221593297748
Validation loss: 2.706834911185835

Epoch: 59| Step: 0
Training loss: 3.020122593545087
Validation loss: 2.710069402541538

Epoch: 5| Step: 1
Training loss: 3.1622598669987045
Validation loss: 2.7116898428964844

Epoch: 5| Step: 2
Training loss: 3.0961285319890517
Validation loss: 2.715547052839852

Epoch: 5| Step: 3
Training loss: 2.939510874640355
Validation loss: 2.723251909660484

Epoch: 5| Step: 4
Training loss: 3.2943648052256855
Validation loss: 2.7335876254701676

Epoch: 5| Step: 5
Training loss: 2.870248267836522
Validation loss: 2.7360546404049138

Epoch: 5| Step: 6
Training loss: 2.6547554748346505
Validation loss: 2.7135658942517167

Epoch: 5| Step: 7
Training loss: 2.9540518461725562
Validation loss: 2.7082779414063323

Epoch: 5| Step: 8
Training loss: 2.8774677134938815
Validation loss: 2.705422695685977

Epoch: 5| Step: 9
Training loss: 3.330073972458921
Validation loss: 2.7027321275759992

Epoch: 5| Step: 10
Training loss: 3.0249839593131007
Validation loss: 2.703187271151086

Epoch: 60| Step: 0
Training loss: 2.7467880565089784
Validation loss: 2.7023952299726566

Epoch: 5| Step: 1
Training loss: 2.587006777134804
Validation loss: 2.701158050598303

Epoch: 5| Step: 2
Training loss: 3.125321943865562
Validation loss: 2.7027749033974264

Epoch: 5| Step: 3
Training loss: 2.8217055665917576
Validation loss: 2.7016696581743265

Epoch: 5| Step: 4
Training loss: 3.3245282863928782
Validation loss: 2.701669077441507

Epoch: 5| Step: 5
Training loss: 3.1946108917511102
Validation loss: 2.701108958499875

Epoch: 5| Step: 6
Training loss: 3.1117523153239284
Validation loss: 2.698990123705284

Epoch: 5| Step: 7
Training loss: 3.3686650479562767
Validation loss: 2.698638150266678

Epoch: 5| Step: 8
Training loss: 3.128814505423833
Validation loss: 2.697624150458835

Epoch: 5| Step: 9
Training loss: 2.877859435115567
Validation loss: 2.696649465138585

Epoch: 5| Step: 10
Training loss: 2.9180733331325075
Validation loss: 2.699587912276423

Epoch: 61| Step: 0
Training loss: 3.2129971843081453
Validation loss: 2.705024517969422

Epoch: 5| Step: 1
Training loss: 3.2278605290928972
Validation loss: 2.736719053172041

Epoch: 5| Step: 2
Training loss: 3.4318051415459205
Validation loss: 2.770140758791242

Epoch: 5| Step: 3
Training loss: 3.013359523366807
Validation loss: 2.7574275597342917

Epoch: 5| Step: 4
Training loss: 2.5831169119799884
Validation loss: 2.7452162379434952

Epoch: 5| Step: 5
Training loss: 2.3974228492710226
Validation loss: 2.7292321003241176

Epoch: 5| Step: 6
Training loss: 3.122669266326934
Validation loss: 2.7141600361608162

Epoch: 5| Step: 7
Training loss: 3.315912468301376
Validation loss: 2.696173773229103

Epoch: 5| Step: 8
Training loss: 3.2681924318880897
Validation loss: 2.691685144410606

Epoch: 5| Step: 9
Training loss: 2.495302842132854
Validation loss: 2.696505232284193

Epoch: 5| Step: 10
Training loss: 2.9710859243935364
Validation loss: 2.697804131779731

Epoch: 62| Step: 0
Training loss: 3.1812570807897163
Validation loss: 2.69721625200015

Epoch: 5| Step: 1
Training loss: 2.85879560760293
Validation loss: 2.701403201619295

Epoch: 5| Step: 2
Training loss: 2.836995245449854
Validation loss: 2.7085105863234484

Epoch: 5| Step: 3
Training loss: 3.5966456150385153
Validation loss: 2.7144601698024258

Epoch: 5| Step: 4
Training loss: 2.7349715099908125
Validation loss: 2.6956343910550506

Epoch: 5| Step: 5
Training loss: 2.6032626808273083
Validation loss: 2.700342367274491

Epoch: 5| Step: 6
Training loss: 2.638597692072274
Validation loss: 2.7089663782494995

Epoch: 5| Step: 7
Training loss: 2.9568406400133522
Validation loss: 2.7276367624918345

Epoch: 5| Step: 8
Training loss: 3.125746675932727
Validation loss: 2.739094305979566

Epoch: 5| Step: 9
Training loss: 2.949303793786254
Validation loss: 2.728397166654844

Epoch: 5| Step: 10
Training loss: 3.843465282781132
Validation loss: 2.7145213073389

Epoch: 63| Step: 0
Training loss: 3.2831168540680697
Validation loss: 2.7062404020534703

Epoch: 5| Step: 1
Training loss: 3.15433360925785
Validation loss: 2.7199902636313342

Epoch: 5| Step: 2
Training loss: 2.768966466566316
Validation loss: 2.729509018578966

Epoch: 5| Step: 3
Training loss: 3.484986255897774
Validation loss: 2.729289991355189

Epoch: 5| Step: 4
Training loss: 2.9132399638189765
Validation loss: 2.7181428517312396

Epoch: 5| Step: 5
Training loss: 3.053112199457797
Validation loss: 2.708050751122963

Epoch: 5| Step: 6
Training loss: 2.7255006487741853
Validation loss: 2.694764097022859

Epoch: 5| Step: 7
Training loss: 3.3470102263272454
Validation loss: 2.6917598557621676

Epoch: 5| Step: 8
Training loss: 3.089671365243015
Validation loss: 2.696182279466043

Epoch: 5| Step: 9
Training loss: 2.7137253028592747
Validation loss: 2.696149965892104

Epoch: 5| Step: 10
Training loss: 2.638146043814184
Validation loss: 2.6917217393647914

Epoch: 64| Step: 0
Training loss: 3.0572017069399435
Validation loss: 2.688443348627206

Epoch: 5| Step: 1
Training loss: 3.230487348325393
Validation loss: 2.6900340527377686

Epoch: 5| Step: 2
Training loss: 2.9596495230132005
Validation loss: 2.683841772971772

Epoch: 5| Step: 3
Training loss: 3.1087176524259776
Validation loss: 2.6833211968145627

Epoch: 5| Step: 4
Training loss: 2.982521959785139
Validation loss: 2.6810208120047636

Epoch: 5| Step: 5
Training loss: 2.784495742183587
Validation loss: 2.6813328556233884

Epoch: 5| Step: 6
Training loss: 3.256665949696124
Validation loss: 2.6804225342494536

Epoch: 5| Step: 7
Training loss: 2.7129319299748835
Validation loss: 2.6787966613103387

Epoch: 5| Step: 8
Training loss: 2.9383469030362988
Validation loss: 2.679361771857801

Epoch: 5| Step: 9
Training loss: 3.182870232681631
Validation loss: 2.6779075050734984

Epoch: 5| Step: 10
Training loss: 2.9097344624078043
Validation loss: 2.6780587790118973

Epoch: 65| Step: 0
Training loss: 3.1051429049767014
Validation loss: 2.6778978187931424

Epoch: 5| Step: 1
Training loss: 2.98198152600098
Validation loss: 2.676261237123949

Epoch: 5| Step: 2
Training loss: 3.8989339447413753
Validation loss: 2.677348298116951

Epoch: 5| Step: 3
Training loss: 3.0604532369909045
Validation loss: 2.674837849329179

Epoch: 5| Step: 4
Training loss: 3.107753465033266
Validation loss: 2.672570026458374

Epoch: 5| Step: 5
Training loss: 2.6822501071315163
Validation loss: 2.6784385004963354

Epoch: 5| Step: 6
Training loss: 2.4919679359651026
Validation loss: 2.675663597730591

Epoch: 5| Step: 7
Training loss: 2.916539180330906
Validation loss: 2.678001659675329

Epoch: 5| Step: 8
Training loss: 2.5058496702486472
Validation loss: 2.6762392949486817

Epoch: 5| Step: 9
Training loss: 3.066883919801834
Validation loss: 2.671492924381997

Epoch: 5| Step: 10
Training loss: 2.9946040263340548
Validation loss: 2.6688920440148114

Epoch: 66| Step: 0
Training loss: 2.5035598205769958
Validation loss: 2.677012348794079

Epoch: 5| Step: 1
Training loss: 2.733755771820994
Validation loss: 2.673353636035486

Epoch: 5| Step: 2
Training loss: 2.9667706767790785
Validation loss: 2.6750955611939484

Epoch: 5| Step: 3
Training loss: 2.9998087822055197
Validation loss: 2.6759121899849685

Epoch: 5| Step: 4
Training loss: 3.0925911939122464
Validation loss: 2.6828591488452744

Epoch: 5| Step: 5
Training loss: 2.845485953878652
Validation loss: 2.6833545051380985

Epoch: 5| Step: 6
Training loss: 3.1914207430152097
Validation loss: 2.690206215913821

Epoch: 5| Step: 7
Training loss: 3.2933953168444106
Validation loss: 2.6881274039243555

Epoch: 5| Step: 8
Training loss: 2.899090058521714
Validation loss: 2.696151025141457

Epoch: 5| Step: 9
Training loss: 3.1992378280871936
Validation loss: 2.686034602201577

Epoch: 5| Step: 10
Training loss: 3.184608344605772
Validation loss: 2.6682257062133523

Epoch: 67| Step: 0
Training loss: 2.5180673057402165
Validation loss: 2.6656955314531703

Epoch: 5| Step: 1
Training loss: 3.104387894156865
Validation loss: 2.6645701233330334

Epoch: 5| Step: 2
Training loss: 3.5246454101127407
Validation loss: 2.6649264193450386

Epoch: 5| Step: 3
Training loss: 2.853820742692312
Validation loss: 2.663626586366788

Epoch: 5| Step: 4
Training loss: 2.809090815715558
Validation loss: 2.6674873399250028

Epoch: 5| Step: 5
Training loss: 2.84445818791778
Validation loss: 2.6716472857561735

Epoch: 5| Step: 6
Training loss: 3.186955723388217
Validation loss: 2.689880489177463

Epoch: 5| Step: 7
Training loss: 2.625323048649771
Validation loss: 2.7001474210355814

Epoch: 5| Step: 8
Training loss: 2.7978865855955837
Validation loss: 2.724098516458677

Epoch: 5| Step: 9
Training loss: 3.02685448415303
Validation loss: 2.7162220967912583

Epoch: 5| Step: 10
Training loss: 3.7149973936829084
Validation loss: 2.7630189362096167

Epoch: 68| Step: 0
Training loss: 3.5315708250969258
Validation loss: 2.6935896698684747

Epoch: 5| Step: 1
Training loss: 3.119781714897438
Validation loss: 2.657774286284253

Epoch: 5| Step: 2
Training loss: 2.7262392918211584
Validation loss: 2.704548153068669

Epoch: 5| Step: 3
Training loss: 2.945557601808406
Validation loss: 2.7594336782731137

Epoch: 5| Step: 4
Training loss: 3.244466913339973
Validation loss: 2.7290183838558266

Epoch: 5| Step: 5
Training loss: 2.4124119124859567
Validation loss: 2.716785545800556

Epoch: 5| Step: 6
Training loss: 3.08177534039346
Validation loss: 2.7175890469146586

Epoch: 5| Step: 7
Training loss: 2.9426310751346567
Validation loss: 2.723886819781216

Epoch: 5| Step: 8
Training loss: 2.8706104105274055
Validation loss: 2.7571018710246515

Epoch: 5| Step: 9
Training loss: 3.243622170577428
Validation loss: 2.789151873773344

Epoch: 5| Step: 10
Training loss: 3.286500054934426
Validation loss: 2.7407228222814655

Epoch: 69| Step: 0
Training loss: 2.6163740573564422
Validation loss: 2.7249569363675543

Epoch: 5| Step: 1
Training loss: 3.5862598149672897
Validation loss: 2.7222864754366762

Epoch: 5| Step: 2
Training loss: 3.1196837409217593
Validation loss: 2.745480584384577

Epoch: 5| Step: 3
Training loss: 2.941939550031584
Validation loss: 2.7838128580277233

Epoch: 5| Step: 4
Training loss: 2.453218300375422
Validation loss: 2.724325587086112

Epoch: 5| Step: 5
Training loss: 3.258646540373081
Validation loss: 2.7189542254974586

Epoch: 5| Step: 6
Training loss: 3.1920655408837337
Validation loss: 2.723881703576137

Epoch: 5| Step: 7
Training loss: 2.615520436009645
Validation loss: 2.733796079793713

Epoch: 5| Step: 8
Training loss: 3.4725626019958624
Validation loss: 2.7371217999927744

Epoch: 5| Step: 9
Training loss: 2.663969155743032
Validation loss: 2.7331737030000895

Epoch: 5| Step: 10
Training loss: 3.3746599096679963
Validation loss: 2.723869784550433

Epoch: 70| Step: 0
Training loss: 3.3577953794388162
Validation loss: 2.7136342101339648

Epoch: 5| Step: 1
Training loss: 3.237812813629144
Validation loss: 2.711938695671533

Epoch: 5| Step: 2
Training loss: 3.2699665613827054
Validation loss: 2.7054839597470894

Epoch: 5| Step: 3
Training loss: 2.6932527052107003
Validation loss: 2.6906275064092426

Epoch: 5| Step: 4
Training loss: 2.7816477287597117
Validation loss: 2.6588793698313826

Epoch: 5| Step: 5
Training loss: 3.41008549602645
Validation loss: 2.661358557740239

Epoch: 5| Step: 6
Training loss: 3.417263320060778
Validation loss: 2.665182503052924

Epoch: 5| Step: 7
Training loss: 2.6101835905376953
Validation loss: 2.665971216980364

Epoch: 5| Step: 8
Training loss: 2.3938874566275623
Validation loss: 2.6652122785195163

Epoch: 5| Step: 9
Training loss: 2.548602588949989
Validation loss: 2.667278973848663

Epoch: 5| Step: 10
Training loss: 3.1764705046069897
Validation loss: 2.666233811767089

Epoch: 71| Step: 0
Training loss: 2.698193942124325
Validation loss: 2.665033746745916

Epoch: 5| Step: 1
Training loss: 2.9801201172756633
Validation loss: 2.6697433537661883

Epoch: 5| Step: 2
Training loss: 2.8238652642557445
Validation loss: 2.680998432582872

Epoch: 5| Step: 3
Training loss: 2.5507395625541633
Validation loss: 2.6734531637378636

Epoch: 5| Step: 4
Training loss: 3.33130304176229
Validation loss: 2.672885433378972

Epoch: 5| Step: 5
Training loss: 3.0094889935128846
Validation loss: 2.6713462488226893

Epoch: 5| Step: 6
Training loss: 3.0729053216929523
Validation loss: 2.6659482842628464

Epoch: 5| Step: 7
Training loss: 3.366875653972318
Validation loss: 2.6568450367416956

Epoch: 5| Step: 8
Training loss: 2.9597125174127945
Validation loss: 2.6563271112607705

Epoch: 5| Step: 9
Training loss: 2.7851701177008366
Validation loss: 2.646951815113594

Epoch: 5| Step: 10
Training loss: 3.170897384845452
Validation loss: 2.648037822859979

Epoch: 72| Step: 0
Training loss: 2.7959997416593025
Validation loss: 2.647771001941871

Epoch: 5| Step: 1
Training loss: 3.262261077200203
Validation loss: 2.650321711025614

Epoch: 5| Step: 2
Training loss: 3.219801055259349
Validation loss: 2.65057365982521

Epoch: 5| Step: 3
Training loss: 2.497511578934933
Validation loss: 2.652725114260093

Epoch: 5| Step: 4
Training loss: 2.4451663427579122
Validation loss: 2.653742928960505

Epoch: 5| Step: 5
Training loss: 3.1700619180691234
Validation loss: 2.6631476450798384

Epoch: 5| Step: 6
Training loss: 3.4263930780262917
Validation loss: 2.6674325833911965

Epoch: 5| Step: 7
Training loss: 3.464452332210418
Validation loss: 2.678201637114916

Epoch: 5| Step: 8
Training loss: 3.166834542358782
Validation loss: 2.6786327871276763

Epoch: 5| Step: 9
Training loss: 2.5964236899007886
Validation loss: 2.652072599586309

Epoch: 5| Step: 10
Training loss: 2.328572479869662
Validation loss: 2.6410783287679096

Epoch: 73| Step: 0
Training loss: 2.9333450476094627
Validation loss: 2.6382698079507017

Epoch: 5| Step: 1
Training loss: 2.911618268710373
Validation loss: 2.6375700488710336

Epoch: 5| Step: 2
Training loss: 2.9704564059181964
Validation loss: 2.642766660828945

Epoch: 5| Step: 3
Training loss: 2.6077982998707623
Validation loss: 2.6396620459940245

Epoch: 5| Step: 4
Training loss: 2.6800970092695264
Validation loss: 2.6383984343300386

Epoch: 5| Step: 5
Training loss: 3.1621253594600627
Validation loss: 2.6436024986794906

Epoch: 5| Step: 6
Training loss: 3.2819685376302177
Validation loss: 2.642373206490418

Epoch: 5| Step: 7
Training loss: 2.129454263970304
Validation loss: 2.6472997951159964

Epoch: 5| Step: 8
Training loss: 3.507532189262961
Validation loss: 2.6543948794630947

Epoch: 5| Step: 9
Training loss: 2.7459494497226506
Validation loss: 2.6594295236947922

Epoch: 5| Step: 10
Training loss: 3.6322198199747873
Validation loss: 2.6584528687821334

Epoch: 74| Step: 0
Training loss: 3.215691159293443
Validation loss: 2.668196584099908

Epoch: 5| Step: 1
Training loss: 2.267245324920266
Validation loss: 2.6680794631067286

Epoch: 5| Step: 2
Training loss: 2.632443274804275
Validation loss: 2.6769896485643616

Epoch: 5| Step: 3
Training loss: 2.6068799545105645
Validation loss: 2.6926727689268137

Epoch: 5| Step: 4
Training loss: 3.6906635485904213
Validation loss: 2.72012616949177

Epoch: 5| Step: 5
Training loss: 2.7874363023810145
Validation loss: 2.7298651800739746

Epoch: 5| Step: 6
Training loss: 3.595531519618391
Validation loss: 2.700397570085128

Epoch: 5| Step: 7
Training loss: 2.7778026346578004
Validation loss: 2.6626599485003757

Epoch: 5| Step: 8
Training loss: 3.1014954682224345
Validation loss: 2.653906012985262

Epoch: 5| Step: 9
Training loss: 3.309013691343248
Validation loss: 2.6571720055266

Epoch: 5| Step: 10
Training loss: 2.5032545839597455
Validation loss: 2.6581459512734544

Epoch: 75| Step: 0
Training loss: 2.7273419421978664
Validation loss: 2.662518384431798

Epoch: 5| Step: 1
Training loss: 3.03227704139746
Validation loss: 2.6620143693796363

Epoch: 5| Step: 2
Training loss: 3.1498721808280092
Validation loss: 2.665385493862304

Epoch: 5| Step: 3
Training loss: 3.255559128233852
Validation loss: 2.656868745664168

Epoch: 5| Step: 4
Training loss: 3.132127035212568
Validation loss: 2.6654615156109944

Epoch: 5| Step: 5
Training loss: 2.9778665404430784
Validation loss: 2.668723113948174

Epoch: 5| Step: 6
Training loss: 2.8297234333353996
Validation loss: 2.6630780321418404

Epoch: 5| Step: 7
Training loss: 3.0418518915781965
Validation loss: 2.652826643199528

Epoch: 5| Step: 8
Training loss: 3.1180189357571635
Validation loss: 2.654599187701506

Epoch: 5| Step: 9
Training loss: 2.293556566943367
Validation loss: 2.6460803211115707

Epoch: 5| Step: 10
Training loss: 3.1878488387164565
Validation loss: 2.654274520412263

Epoch: 76| Step: 0
Training loss: 2.7432385465424045
Validation loss: 2.6360466971802654

Epoch: 5| Step: 1
Training loss: 3.3607868864893717
Validation loss: 2.6303247745015836

Epoch: 5| Step: 2
Training loss: 3.1857796308571436
Validation loss: 2.6309844533893805

Epoch: 5| Step: 3
Training loss: 2.8601318358333008
Validation loss: 2.6365667639483297

Epoch: 5| Step: 4
Training loss: 2.56093195879129
Validation loss: 2.639341581907851

Epoch: 5| Step: 5
Training loss: 2.719666512886221
Validation loss: 2.6358295149565727

Epoch: 5| Step: 6
Training loss: 2.9386933520271445
Validation loss: 2.637292147340246

Epoch: 5| Step: 7
Training loss: 2.951839429587322
Validation loss: 2.624467836807283

Epoch: 5| Step: 8
Training loss: 3.2074692458405107
Validation loss: 2.629891174421796

Epoch: 5| Step: 9
Training loss: 3.0474444517435266
Validation loss: 2.6283048656125514

Epoch: 5| Step: 10
Training loss: 2.9596914120216202
Validation loss: 2.6416727264009756

Epoch: 77| Step: 0
Training loss: 3.5605459375427317
Validation loss: 2.6547128600602634

Epoch: 5| Step: 1
Training loss: 3.322735070953687
Validation loss: 2.684009563313472

Epoch: 5| Step: 2
Training loss: 2.846529932810514
Validation loss: 2.67574704020139

Epoch: 5| Step: 3
Training loss: 3.172657536532459
Validation loss: 2.671803319286502

Epoch: 5| Step: 4
Training loss: 2.2131700869570032
Validation loss: 2.6689864369337024

Epoch: 5| Step: 5
Training loss: 3.352297971186641
Validation loss: 2.680914681169279

Epoch: 5| Step: 6
Training loss: 2.788579220400763
Validation loss: 2.667681611121263

Epoch: 5| Step: 7
Training loss: 2.9251804524373
Validation loss: 2.667616448794818

Epoch: 5| Step: 8
Training loss: 2.2881009422523375
Validation loss: 2.635264987188803

Epoch: 5| Step: 9
Training loss: 2.797934304922885
Validation loss: 2.622250139630578

Epoch: 5| Step: 10
Training loss: 3.0648033666466263
Validation loss: 2.62108493943622

Epoch: 78| Step: 0
Training loss: 2.862668168237959
Validation loss: 2.6195278977217225

Epoch: 5| Step: 1
Training loss: 2.9348603421050776
Validation loss: 2.62135807074707

Epoch: 5| Step: 2
Training loss: 2.7977566315155884
Validation loss: 2.6215728541472556

Epoch: 5| Step: 3
Training loss: 3.419659737954739
Validation loss: 2.620171882006209

Epoch: 5| Step: 4
Training loss: 2.9775718919865297
Validation loss: 2.619339738676316

Epoch: 5| Step: 5
Training loss: 2.4821512118254803
Validation loss: 2.615731085490656

Epoch: 5| Step: 6
Training loss: 2.939460262657447
Validation loss: 2.6120651188934425

Epoch: 5| Step: 7
Training loss: 3.2540315418461434
Validation loss: 2.619320233385079

Epoch: 5| Step: 8
Training loss: 2.5193876950079694
Validation loss: 2.631815293565361

Epoch: 5| Step: 9
Training loss: 3.2283510880448962
Validation loss: 2.631269227882425

Epoch: 5| Step: 10
Training loss: 3.089842824055645
Validation loss: 2.624571814629075

Epoch: 79| Step: 0
Training loss: 3.163538157026002
Validation loss: 2.616271018762865

Epoch: 5| Step: 1
Training loss: 2.6878649441645774
Validation loss: 2.6180310763949706

Epoch: 5| Step: 2
Training loss: 3.0557328798878247
Validation loss: 2.62386360611197

Epoch: 5| Step: 3
Training loss: 3.207952220789253
Validation loss: 2.620479091278848

Epoch: 5| Step: 4
Training loss: 3.0478274690652953
Validation loss: 2.624409370366976

Epoch: 5| Step: 5
Training loss: 2.6896471716772763
Validation loss: 2.6179990917839624

Epoch: 5| Step: 6
Training loss: 3.623164666001319
Validation loss: 2.6182616863796837

Epoch: 5| Step: 7
Training loss: 2.5118187963040466
Validation loss: 2.6189589232040915

Epoch: 5| Step: 8
Training loss: 2.6708858510615228
Validation loss: 2.6233575783647005

Epoch: 5| Step: 9
Training loss: 2.749419150998479
Validation loss: 2.6219302484684013

Epoch: 5| Step: 10
Training loss: 2.8365188717321064
Validation loss: 2.621003658436682

Epoch: 80| Step: 0
Training loss: 2.9988777922750516
Validation loss: 2.6216553339713804

Epoch: 5| Step: 1
Training loss: 3.125246267151867
Validation loss: 2.612094225926865

Epoch: 5| Step: 2
Training loss: 3.0011665937026453
Validation loss: 2.6101781601212797

Epoch: 5| Step: 3
Training loss: 2.324147147991094
Validation loss: 2.6074370085088994

Epoch: 5| Step: 4
Training loss: 2.6966048086527383
Validation loss: 2.6065488870410136

Epoch: 5| Step: 5
Training loss: 3.359023532668025
Validation loss: 2.607379101125132

Epoch: 5| Step: 6
Training loss: 3.093223449903863
Validation loss: 2.607787821337804

Epoch: 5| Step: 7
Training loss: 3.2865517064456213
Validation loss: 2.6113463636690306

Epoch: 5| Step: 8
Training loss: 2.4221065287515935
Validation loss: 2.6084331964192358

Epoch: 5| Step: 9
Training loss: 2.800242096788894
Validation loss: 2.612058192712384

Epoch: 5| Step: 10
Training loss: 3.137110627470644
Validation loss: 2.606705338699204

Epoch: 81| Step: 0
Training loss: 3.152177808664823
Validation loss: 2.609664479454076

Epoch: 5| Step: 1
Training loss: 3.3718917096760723
Validation loss: 2.6162807832830834

Epoch: 5| Step: 2
Training loss: 2.6315043564314085
Validation loss: 2.6117370291701425

Epoch: 5| Step: 3
Training loss: 3.327243025420223
Validation loss: 2.6046454014608553

Epoch: 5| Step: 4
Training loss: 3.0861073121296316
Validation loss: 2.6091814785442837

Epoch: 5| Step: 5
Training loss: 2.7847323101703405
Validation loss: 2.6078658750256705

Epoch: 5| Step: 6
Training loss: 2.4399025642764594
Validation loss: 2.608013862824036

Epoch: 5| Step: 7
Training loss: 3.517286526859011
Validation loss: 2.613818849908814

Epoch: 5| Step: 8
Training loss: 3.059951188689232
Validation loss: 2.6112253614928638

Epoch: 5| Step: 9
Training loss: 2.3404487248088715
Validation loss: 2.614972621475038

Epoch: 5| Step: 10
Training loss: 2.1182926010589687
Validation loss: 2.6110942232465395

Epoch: 82| Step: 0
Training loss: 3.0026802170257447
Validation loss: 2.6077307495082507

Epoch: 5| Step: 1
Training loss: 2.8408030236991104
Validation loss: 2.6080313451681816

Epoch: 5| Step: 2
Training loss: 2.430493383672075
Validation loss: 2.6053294824924906

Epoch: 5| Step: 3
Training loss: 2.9796373400094374
Validation loss: 2.608128332942128

Epoch: 5| Step: 4
Training loss: 2.892095078568726
Validation loss: 2.6041261481957894

Epoch: 5| Step: 5
Training loss: 2.8177904174656914
Validation loss: 2.6049344518792905

Epoch: 5| Step: 6
Training loss: 2.9101487127628904
Validation loss: 2.60970798406693

Epoch: 5| Step: 7
Training loss: 2.882184381467788
Validation loss: 2.6071971135690486

Epoch: 5| Step: 8
Training loss: 2.9643132837165767
Validation loss: 2.6019392168534483

Epoch: 5| Step: 9
Training loss: 3.3737516567004255
Validation loss: 2.6026202572367305

Epoch: 5| Step: 10
Training loss: 3.090533501453818
Validation loss: 2.60607451089596

Epoch: 83| Step: 0
Training loss: 2.8359026946146715
Validation loss: 2.598617525118132

Epoch: 5| Step: 1
Training loss: 2.747191382058145
Validation loss: 2.5989364909822337

Epoch: 5| Step: 2
Training loss: 3.4291163079668867
Validation loss: 2.601718604125096

Epoch: 5| Step: 3
Training loss: 2.71590160370292
Validation loss: 2.6022840304466017

Epoch: 5| Step: 4
Training loss: 2.9656997269279124
Validation loss: 2.5950356578698632

Epoch: 5| Step: 5
Training loss: 2.73043775199791
Validation loss: 2.599028457648109

Epoch: 5| Step: 6
Training loss: 2.9576120347950066
Validation loss: 2.5923690851074803

Epoch: 5| Step: 7
Training loss: 3.1624281441588162
Validation loss: 2.590864885055006

Epoch: 5| Step: 8
Training loss: 3.1535040363886537
Validation loss: 2.5931336231057815

Epoch: 5| Step: 9
Training loss: 2.99008479326638
Validation loss: 2.5938224055906507

Epoch: 5| Step: 10
Training loss: 2.250798083861088
Validation loss: 2.5926354478782923

Epoch: 84| Step: 0
Training loss: 2.561709398332275
Validation loss: 2.5997898909452193

Epoch: 5| Step: 1
Training loss: 3.3052787522393454
Validation loss: 2.6102571942048134

Epoch: 5| Step: 2
Training loss: 2.63271379144293
Validation loss: 2.6082077033723436

Epoch: 5| Step: 3
Training loss: 3.2646125063457925
Validation loss: 2.6307157956348917

Epoch: 5| Step: 4
Training loss: 2.867590935619628
Validation loss: 2.6311510467648804

Epoch: 5| Step: 5
Training loss: 3.2546274546827036
Validation loss: 2.626775086708468

Epoch: 5| Step: 6
Training loss: 2.684723773010125
Validation loss: 2.6313905008449776

Epoch: 5| Step: 7
Training loss: 2.5926021196049027
Validation loss: 2.6052581455513324

Epoch: 5| Step: 8
Training loss: 3.14815290882856
Validation loss: 2.592361954503921

Epoch: 5| Step: 9
Training loss: 2.8425164534093432
Validation loss: 2.591326070572728

Epoch: 5| Step: 10
Training loss: 2.8314903847748214
Validation loss: 2.588866508184462

Epoch: 85| Step: 0
Training loss: 2.6133128165717743
Validation loss: 2.5889458066717794

Epoch: 5| Step: 1
Training loss: 3.0834227540392436
Validation loss: 2.5903141488703847

Epoch: 5| Step: 2
Training loss: 3.081488925421858
Validation loss: 2.591941641949886

Epoch: 5| Step: 3
Training loss: 3.5863219077984314
Validation loss: 2.5991586423077875

Epoch: 5| Step: 4
Training loss: 2.6394259648028653
Validation loss: 2.616302976486067

Epoch: 5| Step: 5
Training loss: 2.9314205486078406
Validation loss: 2.633562915542999

Epoch: 5| Step: 6
Training loss: 3.013614755362369
Validation loss: 2.6477100620665293

Epoch: 5| Step: 7
Training loss: 2.6886684627752393
Validation loss: 2.644960302202364

Epoch: 5| Step: 8
Training loss: 3.0950750730712135
Validation loss: 2.5986171936406057

Epoch: 5| Step: 9
Training loss: 2.636279893310421
Validation loss: 2.5899161638314556

Epoch: 5| Step: 10
Training loss: 2.7794768435341703
Validation loss: 2.5919310142510765

Epoch: 86| Step: 0
Training loss: 3.0629387366096035
Validation loss: 2.599536580300587

Epoch: 5| Step: 1
Training loss: 2.8711676555645202
Validation loss: 2.6047843630403014

Epoch: 5| Step: 2
Training loss: 3.1312621887335284
Validation loss: 2.6070026462106823

Epoch: 5| Step: 3
Training loss: 3.1384716337999605
Validation loss: 2.6081948763292684

Epoch: 5| Step: 4
Training loss: 2.8677530588435167
Validation loss: 2.6013320682347825

Epoch: 5| Step: 5
Training loss: 2.66047144519528
Validation loss: 2.600965755703465

Epoch: 5| Step: 6
Training loss: 2.692345797090946
Validation loss: 2.5989830934423286

Epoch: 5| Step: 7
Training loss: 3.070652600736394
Validation loss: 2.593903364185879

Epoch: 5| Step: 8
Training loss: 3.1179469051183677
Validation loss: 2.5968967489204475

Epoch: 5| Step: 9
Training loss: 3.119604870400147
Validation loss: 2.5978269188034426

Epoch: 5| Step: 10
Training loss: 2.596565832286739
Validation loss: 2.601217117695823

Epoch: 87| Step: 0
Training loss: 3.072958235809716
Validation loss: 2.6203608432283203

Epoch: 5| Step: 1
Training loss: 2.600071110119768
Validation loss: 2.6206025667320323

Epoch: 5| Step: 2
Training loss: 3.375697734905886
Validation loss: 2.6344955321588013

Epoch: 5| Step: 3
Training loss: 3.036479882261435
Validation loss: 2.649766748200461

Epoch: 5| Step: 4
Training loss: 2.7655772404399332
Validation loss: 2.6267949914399105

Epoch: 5| Step: 5
Training loss: 2.7028302158741466
Validation loss: 2.5946414115997936

Epoch: 5| Step: 6
Training loss: 2.8539971814104903
Validation loss: 2.5914442921407863

Epoch: 5| Step: 7
Training loss: 2.931433073723952
Validation loss: 2.584388020102184

Epoch: 5| Step: 8
Training loss: 2.8930063696961574
Validation loss: 2.583578688223322

Epoch: 5| Step: 9
Training loss: 2.8098650138986727
Validation loss: 2.5808693904713387

Epoch: 5| Step: 10
Training loss: 3.01689397963581
Validation loss: 2.583346235525546

Epoch: 88| Step: 0
Training loss: 3.1352017013179196
Validation loss: 2.5884667248261164

Epoch: 5| Step: 1
Training loss: 3.258800622029618
Validation loss: 2.597829656297355

Epoch: 5| Step: 2
Training loss: 2.489728330169888
Validation loss: 2.6127047776098165

Epoch: 5| Step: 3
Training loss: 2.9693487266320813
Validation loss: 2.640665229616641

Epoch: 5| Step: 4
Training loss: 2.5855704332273457
Validation loss: 2.62502148175569

Epoch: 5| Step: 5
Training loss: 3.192697812302115
Validation loss: 2.615237290326853

Epoch: 5| Step: 6
Training loss: 2.5225074400475442
Validation loss: 2.5863290506481107

Epoch: 5| Step: 7
Training loss: 3.0758627696882224
Validation loss: 2.57756028937353

Epoch: 5| Step: 8
Training loss: 2.6622972652994257
Validation loss: 2.5734124969862306

Epoch: 5| Step: 9
Training loss: 3.1752451764457486
Validation loss: 2.573637845119664

Epoch: 5| Step: 10
Training loss: 3.0486238595690662
Validation loss: 2.5745302139147896

Epoch: 89| Step: 0
Training loss: 3.26197355268786
Validation loss: 2.5721989394862286

Epoch: 5| Step: 1
Training loss: 3.044889615067242
Validation loss: 2.5746975855067737

Epoch: 5| Step: 2
Training loss: 2.890452446813481
Validation loss: 2.573634227225503

Epoch: 5| Step: 3
Training loss: 2.776176024734833
Validation loss: 2.58158224169958

Epoch: 5| Step: 4
Training loss: 2.585801319789203
Validation loss: 2.582324906596941

Epoch: 5| Step: 5
Training loss: 3.1937783435974745
Validation loss: 2.589627716983221

Epoch: 5| Step: 6
Training loss: 2.864351205379464
Validation loss: 2.5940602958683443

Epoch: 5| Step: 7
Training loss: 3.123927733519604
Validation loss: 2.5900419168663116

Epoch: 5| Step: 8
Training loss: 2.1494708541168346
Validation loss: 2.5870817903342482

Epoch: 5| Step: 9
Training loss: 2.9398557266855097
Validation loss: 2.5793935419889436

Epoch: 5| Step: 10
Training loss: 2.980230039383954
Validation loss: 2.578140061857465

Epoch: 90| Step: 0
Training loss: 2.759039414110814
Validation loss: 2.57729381438838

Epoch: 5| Step: 1
Training loss: 3.156912252613798
Validation loss: 2.570238900485957

Epoch: 5| Step: 2
Training loss: 3.3328836296635673
Validation loss: 2.568395114966461

Epoch: 5| Step: 3
Training loss: 3.093334131514786
Validation loss: 2.5675964487511096

Epoch: 5| Step: 4
Training loss: 3.0825216582466326
Validation loss: 2.5698580818474768

Epoch: 5| Step: 5
Training loss: 2.5892592010643956
Validation loss: 2.5715655536995934

Epoch: 5| Step: 6
Training loss: 3.0270627389738047
Validation loss: 2.5690290324399614

Epoch: 5| Step: 7
Training loss: 2.9177281945689892
Validation loss: 2.5773804057663607

Epoch: 5| Step: 8
Training loss: 2.7549456427277774
Validation loss: 2.5723364796408967

Epoch: 5| Step: 9
Training loss: 2.929668945253743
Validation loss: 2.5796168649999687

Epoch: 5| Step: 10
Training loss: 1.9524978241071898
Validation loss: 2.583877238938292

Epoch: 91| Step: 0
Training loss: 3.2166203240200617
Validation loss: 2.6051044253977502

Epoch: 5| Step: 1
Training loss: 2.4654996697466816
Validation loss: 2.601601248531448

Epoch: 5| Step: 2
Training loss: 2.753075700333643
Validation loss: 2.6104390646695577

Epoch: 5| Step: 3
Training loss: 2.9658449113546057
Validation loss: 2.5952555525506837

Epoch: 5| Step: 4
Training loss: 2.6477248771915622
Validation loss: 2.5891648640423988

Epoch: 5| Step: 5
Training loss: 3.12800423220375
Validation loss: 2.5823574730400347

Epoch: 5| Step: 6
Training loss: 3.7771854466085313
Validation loss: 2.569841082518585

Epoch: 5| Step: 7
Training loss: 2.6967210710253497
Validation loss: 2.566014588599925

Epoch: 5| Step: 8
Training loss: 2.9004399459190346
Validation loss: 2.568263866018548

Epoch: 5| Step: 9
Training loss: 2.3918235616582924
Validation loss: 2.564667061770895

Epoch: 5| Step: 10
Training loss: 2.6644519510058253
Validation loss: 2.567928326167591

Epoch: 92| Step: 0
Training loss: 2.829555423714832
Validation loss: 2.5761003366857214

Epoch: 5| Step: 1
Training loss: 2.877470364919293
Validation loss: 2.581974221467403

Epoch: 5| Step: 2
Training loss: 2.264028052152857
Validation loss: 2.585406618293026

Epoch: 5| Step: 3
Training loss: 2.8961631715129297
Validation loss: 2.5952327802781037

Epoch: 5| Step: 4
Training loss: 3.3109657045164895
Validation loss: 2.6012439719399327

Epoch: 5| Step: 5
Training loss: 2.886719245549264
Validation loss: 2.612909530772314

Epoch: 5| Step: 6
Training loss: 3.427761223408029
Validation loss: 2.6010679882189485

Epoch: 5| Step: 7
Training loss: 2.9913151916209966
Validation loss: 2.5892543841950424

Epoch: 5| Step: 8
Training loss: 2.1153778562904626
Validation loss: 2.5737398104663756

Epoch: 5| Step: 9
Training loss: 3.2128737057875183
Validation loss: 2.5686034541190668

Epoch: 5| Step: 10
Training loss: 2.783592180866717
Validation loss: 2.5673629953507366

Epoch: 93| Step: 0
Training loss: 3.0226270589949653
Validation loss: 2.5704432104942407

Epoch: 5| Step: 1
Training loss: 2.3827207453837675
Validation loss: 2.5631889299557766

Epoch: 5| Step: 2
Training loss: 2.383250311981632
Validation loss: 2.56202182465129

Epoch: 5| Step: 3
Training loss: 3.2683263675577208
Validation loss: 2.562262016068207

Epoch: 5| Step: 4
Training loss: 3.028004905122238
Validation loss: 2.568741425315103

Epoch: 5| Step: 5
Training loss: 2.884740665356223
Validation loss: 2.5730265390937035

Epoch: 5| Step: 6
Training loss: 3.0200633854561483
Validation loss: 2.583798337547816

Epoch: 5| Step: 7
Training loss: 3.221388392882083
Validation loss: 2.586468304459214

Epoch: 5| Step: 8
Training loss: 2.9207466108986044
Validation loss: 2.6138269768275113

Epoch: 5| Step: 9
Training loss: 2.8200690251553464
Validation loss: 2.6130175966488225

Epoch: 5| Step: 10
Training loss: 2.6877568144408075
Validation loss: 2.593886710719149

Epoch: 94| Step: 0
Training loss: 2.8295228991352865
Validation loss: 2.583527134649564

Epoch: 5| Step: 1
Training loss: 3.200164021818339
Validation loss: 2.5817790547511956

Epoch: 5| Step: 2
Training loss: 2.3948692593498007
Validation loss: 2.576082497325779

Epoch: 5| Step: 3
Training loss: 2.8216293515304613
Validation loss: 2.5717327952548734

Epoch: 5| Step: 4
Training loss: 3.1798899443193624
Validation loss: 2.577896891645608

Epoch: 5| Step: 5
Training loss: 2.712842640133134
Validation loss: 2.5808772883818567

Epoch: 5| Step: 6
Training loss: 3.35000310869215
Validation loss: 2.5821182067296684

Epoch: 5| Step: 7
Training loss: 2.671416483123916
Validation loss: 2.5857908225085584

Epoch: 5| Step: 8
Training loss: 2.968548737781063
Validation loss: 2.5854549068556576

Epoch: 5| Step: 9
Training loss: 2.6524773228401317
Validation loss: 2.5789201660568097

Epoch: 5| Step: 10
Training loss: 2.7687437931447607
Validation loss: 2.5658513036032

Epoch: 95| Step: 0
Training loss: 2.8542370938338992
Validation loss: 2.562906425613885

Epoch: 5| Step: 1
Training loss: 2.8693460348101043
Validation loss: 2.5602987565677453

Epoch: 5| Step: 2
Training loss: 3.1003057206053506
Validation loss: 2.5640755518590033

Epoch: 5| Step: 3
Training loss: 2.5476789083353513
Validation loss: 2.5575587465228375

Epoch: 5| Step: 4
Training loss: 2.746671830129245
Validation loss: 2.5652134153043415

Epoch: 5| Step: 5
Training loss: 2.780337751989265
Validation loss: 2.5838607619497043

Epoch: 5| Step: 6
Training loss: 3.1711343736811886
Validation loss: 2.5759114318335072

Epoch: 5| Step: 7
Training loss: 2.8500450799957204
Validation loss: 2.5793170319813936

Epoch: 5| Step: 8
Training loss: 2.7488870969742685
Validation loss: 2.5762769930212857

Epoch: 5| Step: 9
Training loss: 3.3937460602514395
Validation loss: 2.575691595647797

Epoch: 5| Step: 10
Training loss: 2.4049219206826815
Validation loss: 2.578072073484244

Epoch: 96| Step: 0
Training loss: 2.4222240565620656
Validation loss: 2.575445594229024

Epoch: 5| Step: 1
Training loss: 3.126248224830657
Validation loss: 2.572011658851985

Epoch: 5| Step: 2
Training loss: 2.882688607549081
Validation loss: 2.553386518407007

Epoch: 5| Step: 3
Training loss: 2.5074745972583643
Validation loss: 2.5533666598995133

Epoch: 5| Step: 4
Training loss: 2.767540909241663
Validation loss: 2.552046604825578

Epoch: 5| Step: 5
Training loss: 3.0049285141349094
Validation loss: 2.5532550009866872

Epoch: 5| Step: 6
Training loss: 2.917961886600864
Validation loss: 2.5492820978236077

Epoch: 5| Step: 7
Training loss: 3.0726613773833713
Validation loss: 2.5512178583766216

Epoch: 5| Step: 8
Training loss: 2.3686419258525535
Validation loss: 2.5601199892996407

Epoch: 5| Step: 9
Training loss: 3.5054892681992977
Validation loss: 2.5855284985999765

Epoch: 5| Step: 10
Training loss: 3.0276540289582927
Validation loss: 2.5907447287237684

Epoch: 97| Step: 0
Training loss: 3.063503490228721
Validation loss: 2.5936382233540027

Epoch: 5| Step: 1
Training loss: 2.798479866461126
Validation loss: 2.6275900852953713

Epoch: 5| Step: 2
Training loss: 2.7958896542223632
Validation loss: 2.612937691417044

Epoch: 5| Step: 3
Training loss: 3.2942158610264274
Validation loss: 2.5771203254679382

Epoch: 5| Step: 4
Training loss: 2.7431562402545113
Validation loss: 2.571292059556757

Epoch: 5| Step: 5
Training loss: 2.9922555462542557
Validation loss: 2.5465975535492316

Epoch: 5| Step: 6
Training loss: 3.1843298312681427
Validation loss: 2.54760940666225

Epoch: 5| Step: 7
Training loss: 2.591629816347325
Validation loss: 2.5510596433229478

Epoch: 5| Step: 8
Training loss: 2.425495124687748
Validation loss: 2.551039918447812

Epoch: 5| Step: 9
Training loss: 2.9126213539611174
Validation loss: 2.554776782250358

Epoch: 5| Step: 10
Training loss: 2.7956510455024595
Validation loss: 2.5559527554913632

Epoch: 98| Step: 0
Training loss: 2.275251785430191
Validation loss: 2.559221655223818

Epoch: 5| Step: 1
Training loss: 3.097675029991149
Validation loss: 2.5680614949839167

Epoch: 5| Step: 2
Training loss: 2.553519819121106
Validation loss: 2.5759312727885364

Epoch: 5| Step: 3
Training loss: 3.4276684355302898
Validation loss: 2.5853865396870392

Epoch: 5| Step: 4
Training loss: 2.888734436389391
Validation loss: 2.5715480018969585

Epoch: 5| Step: 5
Training loss: 2.4995793942446247
Validation loss: 2.561452561987305

Epoch: 5| Step: 6
Training loss: 2.612001479190799
Validation loss: 2.5606281708175027

Epoch: 5| Step: 7
Training loss: 2.928026547400189
Validation loss: 2.554441830263729

Epoch: 5| Step: 8
Training loss: 3.0742167335901107
Validation loss: 2.541665546901812

Epoch: 5| Step: 9
Training loss: 3.3231509294515273
Validation loss: 2.545878544750993

Epoch: 5| Step: 10
Training loss: 2.7706815539404643
Validation loss: 2.543859303286266

Epoch: 99| Step: 0
Training loss: 2.9043508908162017
Validation loss: 2.5566218215884016

Epoch: 5| Step: 1
Training loss: 2.7735803701647415
Validation loss: 2.5701008411039563

Epoch: 5| Step: 2
Training loss: 3.046243768497021
Validation loss: 2.5777908680442847

Epoch: 5| Step: 3
Training loss: 2.8822674326445994
Validation loss: 2.5778207986649573

Epoch: 5| Step: 4
Training loss: 2.592761299406616
Validation loss: 2.5720057650900365

Epoch: 5| Step: 5
Training loss: 2.735535903814971
Validation loss: 2.562034119385318

Epoch: 5| Step: 6
Training loss: 2.7180808986893803
Validation loss: 2.5649544880790076

Epoch: 5| Step: 7
Training loss: 2.260822335917292
Validation loss: 2.564453939741656

Epoch: 5| Step: 8
Training loss: 3.084281380420074
Validation loss: 2.5680758152493985

Epoch: 5| Step: 9
Training loss: 3.0022785752444063
Validation loss: 2.5609493751337897

Epoch: 5| Step: 10
Training loss: 3.4530779114701575
Validation loss: 2.5531448393409732

Epoch: 100| Step: 0
Training loss: 3.1129053671496507
Validation loss: 2.5581730492726265

Epoch: 5| Step: 1
Training loss: 3.1830841592729917
Validation loss: 2.5554949607757305

Epoch: 5| Step: 2
Training loss: 3.233754268919166
Validation loss: 2.5581006919319025

Epoch: 5| Step: 3
Training loss: 2.4188334408741667
Validation loss: 2.5543139773161627

Epoch: 5| Step: 4
Training loss: 3.0797344202254022
Validation loss: 2.554368963770056

Epoch: 5| Step: 5
Training loss: 2.82488912854328
Validation loss: 2.5542082344372643

Epoch: 5| Step: 6
Training loss: 2.7047578146888873
Validation loss: 2.545884158640475

Epoch: 5| Step: 7
Training loss: 2.8404065273693933
Validation loss: 2.5520451241287185

Epoch: 5| Step: 8
Training loss: 2.9545517154440533
Validation loss: 2.5474462290696787

Epoch: 5| Step: 9
Training loss: 2.6348501408215617
Validation loss: 2.5625797022228007

Epoch: 5| Step: 10
Training loss: 2.2831113354691457
Validation loss: 2.55643780367412

Epoch: 101| Step: 0
Training loss: 3.078780206182864
Validation loss: 2.561218723741209

Epoch: 5| Step: 1
Training loss: 2.7098169126986975
Validation loss: 2.577300300835309

Epoch: 5| Step: 2
Training loss: 2.5568810241374624
Validation loss: 2.5830381550954784

Epoch: 5| Step: 3
Training loss: 3.1457368612760073
Validation loss: 2.6147849131031577

Epoch: 5| Step: 4
Training loss: 3.008215305059503
Validation loss: 2.591140898606405

Epoch: 5| Step: 5
Training loss: 3.03122262844037
Validation loss: 2.567401753781211

Epoch: 5| Step: 6
Training loss: 2.416337506031432
Validation loss: 2.5518310559470523

Epoch: 5| Step: 7
Training loss: 2.877792992013639
Validation loss: 2.5504554571007394

Epoch: 5| Step: 8
Training loss: 2.573899105990482
Validation loss: 2.5483127790747626

Epoch: 5| Step: 9
Training loss: 3.065340865380501
Validation loss: 2.546321057493108

Epoch: 5| Step: 10
Training loss: 2.940674871980538
Validation loss: 2.544775846595341

Epoch: 102| Step: 0
Training loss: 2.8792133141661593
Validation loss: 2.5371051411804686

Epoch: 5| Step: 1
Training loss: 2.8872796573210704
Validation loss: 2.5401048513256783

Epoch: 5| Step: 2
Training loss: 2.790354282622995
Validation loss: 2.544017487976432

Epoch: 5| Step: 3
Training loss: 3.1811548544814534
Validation loss: 2.5437974543066915

Epoch: 5| Step: 4
Training loss: 2.750663243855455
Validation loss: 2.564735749849488

Epoch: 5| Step: 5
Training loss: 2.974417326470318
Validation loss: 2.5830991359648174

Epoch: 5| Step: 6
Training loss: 3.002380380399592
Validation loss: 2.5857326048555858

Epoch: 5| Step: 7
Training loss: 2.9824172384029937
Validation loss: 2.5754228418971667

Epoch: 5| Step: 8
Training loss: 2.515153260159035
Validation loss: 2.548683027532311

Epoch: 5| Step: 9
Training loss: 2.4785819018485435
Validation loss: 2.546739475115403

Epoch: 5| Step: 10
Training loss: 3.0264259571475858
Validation loss: 2.532488179931552

Epoch: 103| Step: 0
Training loss: 2.713357861835231
Validation loss: 2.535211009847001

Epoch: 5| Step: 1
Training loss: 3.067438930907775
Validation loss: 2.539857893204685

Epoch: 5| Step: 2
Training loss: 2.933998780919233
Validation loss: 2.5446100411386126

Epoch: 5| Step: 3
Training loss: 3.2152124612946884
Validation loss: 2.5386711077673683

Epoch: 5| Step: 4
Training loss: 2.8157810993511
Validation loss: 2.5310837906190113

Epoch: 5| Step: 5
Training loss: 2.8255596855527743
Validation loss: 2.5306693104398272

Epoch: 5| Step: 6
Training loss: 2.8124367600854567
Validation loss: 2.5355843002934284

Epoch: 5| Step: 7
Training loss: 3.0506369816740766
Validation loss: 2.5422313045523457

Epoch: 5| Step: 8
Training loss: 2.3401186467926993
Validation loss: 2.559200664956694

Epoch: 5| Step: 9
Training loss: 2.7715500117480922
Validation loss: 2.572280285634545

Epoch: 5| Step: 10
Training loss: 3.003061639631425
Validation loss: 2.5861655246502773

Epoch: 104| Step: 0
Training loss: 2.853533338090985
Validation loss: 2.5836913981731704

Epoch: 5| Step: 1
Training loss: 2.687112469788522
Validation loss: 2.5862227531850346

Epoch: 5| Step: 2
Training loss: 3.1032247629100578
Validation loss: 2.583852662816959

Epoch: 5| Step: 3
Training loss: 2.71978529587614
Validation loss: 2.582848838549182

Epoch: 5| Step: 4
Training loss: 2.5044011476473576
Validation loss: 2.577636131456237

Epoch: 5| Step: 5
Training loss: 2.594681078620214
Validation loss: 2.5520194117008113

Epoch: 5| Step: 6
Training loss: 2.260974188284849
Validation loss: 2.5345374033565693

Epoch: 5| Step: 7
Training loss: 2.8311383964318977
Validation loss: 2.525313978777888

Epoch: 5| Step: 8
Training loss: 3.571062071932416
Validation loss: 2.5271418575896805

Epoch: 5| Step: 9
Training loss: 2.911570774880156
Validation loss: 2.536166126744857

Epoch: 5| Step: 10
Training loss: 3.230213381211709
Validation loss: 2.5396304925366855

Epoch: 105| Step: 0
Training loss: 2.8462900408716494
Validation loss: 2.533742180406326

Epoch: 5| Step: 1
Training loss: 3.414284426112596
Validation loss: 2.5314778243519336

Epoch: 5| Step: 2
Training loss: 2.436371664392451
Validation loss: 2.5244904156517203

Epoch: 5| Step: 3
Training loss: 2.668068835055376
Validation loss: 2.5335531002869573

Epoch: 5| Step: 4
Training loss: 3.335711505033373
Validation loss: 2.5341806657416095

Epoch: 5| Step: 5
Training loss: 2.076343202743962
Validation loss: 2.5365796410230206

Epoch: 5| Step: 6
Training loss: 2.9644085108523535
Validation loss: 2.5590685206902464

Epoch: 5| Step: 7
Training loss: 2.758569975399135
Validation loss: 2.5895259267880375

Epoch: 5| Step: 8
Training loss: 3.0007514012606857
Validation loss: 2.595125513894448

Epoch: 5| Step: 9
Training loss: 2.2707714690667977
Validation loss: 2.56012007041103

Epoch: 5| Step: 10
Training loss: 3.372372487501641
Validation loss: 2.5553304467727154

Epoch: 106| Step: 0
Training loss: 2.9541185110567523
Validation loss: 2.5610245539527496

Epoch: 5| Step: 1
Training loss: 2.718948357021857
Validation loss: 2.5423032957503593

Epoch: 5| Step: 2
Training loss: 3.052822314342382
Validation loss: 2.538996700320893

Epoch: 5| Step: 3
Training loss: 2.6155078565464587
Validation loss: 2.5304736839980606

Epoch: 5| Step: 4
Training loss: 2.92303737428297
Validation loss: 2.5324832449587555

Epoch: 5| Step: 5
Training loss: 2.839296815615713
Validation loss: 2.5308543060179396

Epoch: 5| Step: 6
Training loss: 2.704881218860098
Validation loss: 2.5305001533065523

Epoch: 5| Step: 7
Training loss: 2.437504988445166
Validation loss: 2.5383846466687965

Epoch: 5| Step: 8
Training loss: 3.1152218235444638
Validation loss: 2.5418156859717826

Epoch: 5| Step: 9
Training loss: 3.0214446052246937
Validation loss: 2.554194234890518

Epoch: 5| Step: 10
Training loss: 2.8654493837613737
Validation loss: 2.581957602263888

Epoch: 107| Step: 0
Training loss: 2.4323284356049335
Validation loss: 2.6081564331558904

Epoch: 5| Step: 1
Training loss: 2.857220113935918
Validation loss: 2.6584885682448602

Epoch: 5| Step: 2
Training loss: 2.9770762082853985
Validation loss: 2.7637737964281643

Epoch: 5| Step: 3
Training loss: 2.937057461782707
Validation loss: 2.7936046970627713

Epoch: 5| Step: 4
Training loss: 3.9172260344914807
Validation loss: 2.7465468659076495

Epoch: 5| Step: 5
Training loss: 3.1366801372350985
Validation loss: 2.56199621134982

Epoch: 5| Step: 6
Training loss: 2.8055580084593807
Validation loss: 2.5254125419108324

Epoch: 5| Step: 7
Training loss: 2.151404755792896
Validation loss: 2.533178366933673

Epoch: 5| Step: 8
Training loss: 2.4362977804447468
Validation loss: 2.5548032757152965

Epoch: 5| Step: 9
Training loss: 3.1348681471747577
Validation loss: 2.5620727282890203

Epoch: 5| Step: 10
Training loss: 3.079931668105673
Validation loss: 2.5517130305383895

Epoch: 108| Step: 0
Training loss: 3.3354644797379063
Validation loss: 2.5462310820533856

Epoch: 5| Step: 1
Training loss: 2.45157530606817
Validation loss: 2.525361417045323

Epoch: 5| Step: 2
Training loss: 2.969556839372775
Validation loss: 2.5285955497813255

Epoch: 5| Step: 3
Training loss: 3.0111693043108074
Validation loss: 2.526514005927772

Epoch: 5| Step: 4
Training loss: 2.480936417834681
Validation loss: 2.5386769425911564

Epoch: 5| Step: 5
Training loss: 2.448694102967132
Validation loss: 2.546958267196552

Epoch: 5| Step: 6
Training loss: 2.749404842824369
Validation loss: 2.5985278806106957

Epoch: 5| Step: 7
Training loss: 2.767966362340868
Validation loss: 2.5702694367103565

Epoch: 5| Step: 8
Training loss: 3.1058452258041434
Validation loss: 2.593738695740977

Epoch: 5| Step: 9
Training loss: 3.04909368087966
Validation loss: 2.6159088562151

Epoch: 5| Step: 10
Training loss: 2.9611611797623816
Validation loss: 2.6075254402456896

Epoch: 109| Step: 0
Training loss: 3.0223713259130918
Validation loss: 2.5635929793073893

Epoch: 5| Step: 1
Training loss: 2.96483184852272
Validation loss: 2.525756698754039

Epoch: 5| Step: 2
Training loss: 3.1683549563255156
Validation loss: 2.5256816049634265

Epoch: 5| Step: 3
Training loss: 2.6297721173730517
Validation loss: 2.544207073128192

Epoch: 5| Step: 4
Training loss: 3.0352853872745063
Validation loss: 2.5725382881652084

Epoch: 5| Step: 5
Training loss: 2.8841827361562915
Validation loss: 2.6221471168493524

Epoch: 5| Step: 6
Training loss: 3.0801737981534507
Validation loss: 2.532017262254595

Epoch: 5| Step: 7
Training loss: 2.8693044887047745
Validation loss: 2.5232467515777404

Epoch: 5| Step: 8
Training loss: 2.240640884406954
Validation loss: 2.523828266233304

Epoch: 5| Step: 9
Training loss: 2.8512678438303096
Validation loss: 2.552440864543505

Epoch: 5| Step: 10
Training loss: 2.958428036602193
Validation loss: 2.599176835189615

Epoch: 110| Step: 0
Training loss: 2.7715991307615506
Validation loss: 2.7470328749040083

Epoch: 5| Step: 1
Training loss: 3.48304606870007
Validation loss: 2.9324986504202295

Epoch: 5| Step: 2
Training loss: 2.828418105306228
Validation loss: 2.9106027850101377

Epoch: 5| Step: 3
Training loss: 3.2950813512643653
Validation loss: 2.8393031342003376

Epoch: 5| Step: 4
Training loss: 2.849946868133524
Validation loss: 2.622653040911958

Epoch: 5| Step: 5
Training loss: 3.2324549186377514
Validation loss: 2.534867849384105

Epoch: 5| Step: 6
Training loss: 2.583991202808912
Validation loss: 2.523158786043744

Epoch: 5| Step: 7
Training loss: 3.0135937110124367
Validation loss: 2.529316864713868

Epoch: 5| Step: 8
Training loss: 3.019778380946479
Validation loss: 2.565019414982134

Epoch: 5| Step: 9
Training loss: 2.842023388201954
Validation loss: 2.633929235149462

Epoch: 5| Step: 10
Training loss: 2.821908853017324
Validation loss: 2.6621840130849486

Epoch: 111| Step: 0
Training loss: 3.1760061637184425
Validation loss: 2.623204244508003

Epoch: 5| Step: 1
Training loss: 3.039703850626195
Validation loss: 2.5869348893436506

Epoch: 5| Step: 2
Training loss: 2.942082827545095
Validation loss: 2.580059890848449

Epoch: 5| Step: 3
Training loss: 2.4804962396975747
Validation loss: 2.6146399039153496

Epoch: 5| Step: 4
Training loss: 2.4119888831557748
Validation loss: 2.665770975040907

Epoch: 5| Step: 5
Training loss: 2.9644960141720533
Validation loss: 2.713127317323589

Epoch: 5| Step: 6
Training loss: 2.7757985555515727
Validation loss: 2.6851025968194038

Epoch: 5| Step: 7
Training loss: 3.3778287547709724
Validation loss: 2.63928009528971

Epoch: 5| Step: 8
Training loss: 3.4025520059505694
Validation loss: 2.66573160130962

Epoch: 5| Step: 9
Training loss: 2.77691793061289
Validation loss: 2.6557880846887896

Epoch: 5| Step: 10
Training loss: 2.9865839108287076
Validation loss: 2.644170982223624

Epoch: 112| Step: 0
Training loss: 3.2537786085502916
Validation loss: 2.6314229354828647

Epoch: 5| Step: 1
Training loss: 2.6048422178783697
Validation loss: 2.6373264160950605

Epoch: 5| Step: 2
Training loss: 3.042725069721967
Validation loss: 2.61661295907864

Epoch: 5| Step: 3
Training loss: 3.2591112507421953
Validation loss: 2.6128063113984936

Epoch: 5| Step: 4
Training loss: 2.803902773936007
Validation loss: 2.5974992977137714

Epoch: 5| Step: 5
Training loss: 2.5110210677781915
Validation loss: 2.5881217414059314

Epoch: 5| Step: 6
Training loss: 3.412878324336523
Validation loss: 2.580639295481609

Epoch: 5| Step: 7
Training loss: 2.2884498791930876
Validation loss: 2.5727627313631567

Epoch: 5| Step: 8
Training loss: 2.8783006380481315
Validation loss: 2.574146509063291

Epoch: 5| Step: 9
Training loss: 2.827413395669223
Validation loss: 2.5746931894630865

Epoch: 5| Step: 10
Training loss: 2.7827919104112673
Validation loss: 2.57767347432109

Epoch: 113| Step: 0
Training loss: 2.37375457634668
Validation loss: 2.5664562355890395

Epoch: 5| Step: 1
Training loss: 2.472103689926367
Validation loss: 2.5660542255893164

Epoch: 5| Step: 2
Training loss: 2.984777133871036
Validation loss: 2.574974081074451

Epoch: 5| Step: 3
Training loss: 3.423620606143381
Validation loss: 2.5778518686206753

Epoch: 5| Step: 4
Training loss: 2.481974467635718
Validation loss: 2.5736216163542225

Epoch: 5| Step: 5
Training loss: 3.0413009911467164
Validation loss: 2.5855930437138688

Epoch: 5| Step: 6
Training loss: 2.894933510446695
Validation loss: 2.5739483215806893

Epoch: 5| Step: 7
Training loss: 3.2167664869826815
Validation loss: 2.552288953388767

Epoch: 5| Step: 8
Training loss: 2.6942369167027564
Validation loss: 2.5244055035237905

Epoch: 5| Step: 9
Training loss: 2.790571899592346
Validation loss: 2.5161573238783186

Epoch: 5| Step: 10
Training loss: 2.875560374173204
Validation loss: 2.5155161224693297

Epoch: 114| Step: 0
Training loss: 2.7519718383412717
Validation loss: 2.5124756264293855

Epoch: 5| Step: 1
Training loss: 2.951876098710146
Validation loss: 2.510395681233688

Epoch: 5| Step: 2
Training loss: 2.971299371818702
Validation loss: 2.5039417796154386

Epoch: 5| Step: 3
Training loss: 2.9782274450752766
Validation loss: 2.5080614901409897

Epoch: 5| Step: 4
Training loss: 2.933195653487538
Validation loss: 2.5088736805894394

Epoch: 5| Step: 5
Training loss: 2.6311809793512597
Validation loss: 2.504693582423375

Epoch: 5| Step: 6
Training loss: 2.6343409236274247
Validation loss: 2.505717973077506

Epoch: 5| Step: 7
Training loss: 2.5690536430938438
Validation loss: 2.508633281685634

Epoch: 5| Step: 8
Training loss: 2.502808900226353
Validation loss: 2.520397054624801

Epoch: 5| Step: 9
Training loss: 2.926634639863094
Validation loss: 2.542767288602608

Epoch: 5| Step: 10
Training loss: 3.183520656752938
Validation loss: 2.561631176212767

Epoch: 115| Step: 0
Training loss: 2.151624611350727
Validation loss: 2.5811174300407123

Epoch: 5| Step: 1
Training loss: 2.618473021943187
Validation loss: 2.5727751162645616

Epoch: 5| Step: 2
Training loss: 3.071717074458919
Validation loss: 2.545992132221277

Epoch: 5| Step: 3
Training loss: 2.5352021435079424
Validation loss: 2.531503710988678

Epoch: 5| Step: 4
Training loss: 2.9581748131918832
Validation loss: 2.5176370521023057

Epoch: 5| Step: 5
Training loss: 2.8321962505812763
Validation loss: 2.522465370706659

Epoch: 5| Step: 6
Training loss: 2.502479372806502
Validation loss: 2.518059509129564

Epoch: 5| Step: 7
Training loss: 3.1818345527723184
Validation loss: 2.5157208117123844

Epoch: 5| Step: 8
Training loss: 3.0440075023222817
Validation loss: 2.510695857094581

Epoch: 5| Step: 9
Training loss: 3.2355262071317137
Validation loss: 2.506661479964658

Epoch: 5| Step: 10
Training loss: 2.712894755525788
Validation loss: 2.4990488211761863

Epoch: 116| Step: 0
Training loss: 2.521919006190603
Validation loss: 2.5019459319063517

Epoch: 5| Step: 1
Training loss: 3.137826916202116
Validation loss: 2.4995516913441804

Epoch: 5| Step: 2
Training loss: 3.249903457381435
Validation loss: 2.499912268627182

Epoch: 5| Step: 3
Training loss: 2.9715739421602123
Validation loss: 2.511553480437955

Epoch: 5| Step: 4
Training loss: 2.459539300842273
Validation loss: 2.49725023217953

Epoch: 5| Step: 5
Training loss: 2.462801756983631
Validation loss: 2.5135647650472297

Epoch: 5| Step: 6
Training loss: 3.008650388063188
Validation loss: 2.5211735052393016

Epoch: 5| Step: 7
Training loss: 2.527776996440091
Validation loss: 2.5214365948627564

Epoch: 5| Step: 8
Training loss: 2.9239334770390064
Validation loss: 2.5353542937976674

Epoch: 5| Step: 9
Training loss: 2.8164303761373457
Validation loss: 2.524192607424331

Epoch: 5| Step: 10
Training loss: 2.741054202913643
Validation loss: 2.5283505347055146

Epoch: 117| Step: 0
Training loss: 3.0854113166414114
Validation loss: 2.514869858379549

Epoch: 5| Step: 1
Training loss: 3.2915228478283236
Validation loss: 2.507183217957289

Epoch: 5| Step: 2
Training loss: 2.6662509912130425
Validation loss: 2.5081949388043387

Epoch: 5| Step: 3
Training loss: 2.150621448570452
Validation loss: 2.497974051695805

Epoch: 5| Step: 4
Training loss: 3.0403663956543494
Validation loss: 2.4953498990763507

Epoch: 5| Step: 5
Training loss: 3.4339867411442477
Validation loss: 2.496795452445865

Epoch: 5| Step: 6
Training loss: 1.9883361089366758
Validation loss: 2.4987201337108718

Epoch: 5| Step: 7
Training loss: 3.0099573191915017
Validation loss: 2.4965695897812457

Epoch: 5| Step: 8
Training loss: 2.459083464234149
Validation loss: 2.5015021743546715

Epoch: 5| Step: 9
Training loss: 2.69363156299481
Validation loss: 2.5061386329150803

Epoch: 5| Step: 10
Training loss: 2.7707948801532205
Validation loss: 2.5201567875319424

Epoch: 118| Step: 0
Training loss: 2.989320980527448
Validation loss: 2.526287698556944

Epoch: 5| Step: 1
Training loss: 2.866301272266828
Validation loss: 2.5216546671112265

Epoch: 5| Step: 2
Training loss: 2.489546473614644
Validation loss: 2.5198334757084218

Epoch: 5| Step: 3
Training loss: 3.0124274977194245
Validation loss: 2.516305226030175

Epoch: 5| Step: 4
Training loss: 2.349077299253354
Validation loss: 2.5038063953820044

Epoch: 5| Step: 5
Training loss: 2.485687676805663
Validation loss: 2.5024047514649266

Epoch: 5| Step: 6
Training loss: 3.1109947701302603
Validation loss: 2.502307481192902

Epoch: 5| Step: 7
Training loss: 3.131695859920853
Validation loss: 2.4985337818456546

Epoch: 5| Step: 8
Training loss: 2.742572377031391
Validation loss: 2.501317260680426

Epoch: 5| Step: 9
Training loss: 2.960899171606312
Validation loss: 2.495630704854036

Epoch: 5| Step: 10
Training loss: 2.602847128665342
Validation loss: 2.502161272081723

Epoch: 119| Step: 0
Training loss: 2.4256526894526003
Validation loss: 2.505299132108317

Epoch: 5| Step: 1
Training loss: 2.890309579496984
Validation loss: 2.509264983106527

Epoch: 5| Step: 2
Training loss: 3.244781265527864
Validation loss: 2.515872181665678

Epoch: 5| Step: 3
Training loss: 2.612171159700685
Validation loss: 2.518607299735097

Epoch: 5| Step: 4
Training loss: 2.7177439615047274
Validation loss: 2.526388225287628

Epoch: 5| Step: 5
Training loss: 2.6881294400520614
Validation loss: 2.532712243885918

Epoch: 5| Step: 6
Training loss: 2.406184505215348
Validation loss: 2.53517989662653

Epoch: 5| Step: 7
Training loss: 2.5109056073141325
Validation loss: 2.533525498193208

Epoch: 5| Step: 8
Training loss: 2.6298930567766035
Validation loss: 2.535896518175895

Epoch: 5| Step: 9
Training loss: 3.2697279858390966
Validation loss: 2.5255358192139434

Epoch: 5| Step: 10
Training loss: 3.203617560499066
Validation loss: 2.517703109629148

Epoch: 120| Step: 0
Training loss: 3.4846716784430307
Validation loss: 2.5142941147652005

Epoch: 5| Step: 1
Training loss: 2.3731470408708337
Validation loss: 2.4937675693602492

Epoch: 5| Step: 2
Training loss: 2.2682118347650344
Validation loss: 2.4912033984917885

Epoch: 5| Step: 3
Training loss: 2.6566530707221614
Validation loss: 2.4937474334692897

Epoch: 5| Step: 4
Training loss: 2.963368245946491
Validation loss: 2.491949986070057

Epoch: 5| Step: 5
Training loss: 3.1512632349894685
Validation loss: 2.4950343160940687

Epoch: 5| Step: 6
Training loss: 2.912646729534726
Validation loss: 2.4986201508391583

Epoch: 5| Step: 7
Training loss: 3.080182467418574
Validation loss: 2.5109409572311727

Epoch: 5| Step: 8
Training loss: 2.500126454016232
Validation loss: 2.5287720489574768

Epoch: 5| Step: 9
Training loss: 2.4901916739598744
Validation loss: 2.538160560263191

Epoch: 5| Step: 10
Training loss: 2.675070652964525
Validation loss: 2.557032271473282

Epoch: 121| Step: 0
Training loss: 2.6310197743071813
Validation loss: 2.5543111811420105

Epoch: 5| Step: 1
Training loss: 3.066677125277169
Validation loss: 2.547531427850948

Epoch: 5| Step: 2
Training loss: 2.5079689808924375
Validation loss: 2.5801323646537084

Epoch: 5| Step: 3
Training loss: 2.4562434887981746
Validation loss: 2.5515356189739107

Epoch: 5| Step: 4
Training loss: 3.103768666672544
Validation loss: 2.5593123098835675

Epoch: 5| Step: 5
Training loss: 2.688022119238081
Validation loss: 2.5676540262598393

Epoch: 5| Step: 6
Training loss: 2.7818310591399076
Validation loss: 2.5239250351922755

Epoch: 5| Step: 7
Training loss: 2.767856968822562
Validation loss: 2.5004500650528585

Epoch: 5| Step: 8
Training loss: 2.446553460792822
Validation loss: 2.4901738214178066

Epoch: 5| Step: 9
Training loss: 3.258168006728751
Validation loss: 2.4914846016365035

Epoch: 5| Step: 10
Training loss: 2.8681545861373072
Validation loss: 2.4911495586486776

Epoch: 122| Step: 0
Training loss: 2.780914886516411
Validation loss: 2.4895363695682935

Epoch: 5| Step: 1
Training loss: 3.2994124785410275
Validation loss: 2.48803029786483

Epoch: 5| Step: 2
Training loss: 2.535571706436046
Validation loss: 2.4980359237766825

Epoch: 5| Step: 3
Training loss: 2.988239123477576
Validation loss: 2.4901328293719986

Epoch: 5| Step: 4
Training loss: 3.2233229068980647
Validation loss: 2.4857630928829875

Epoch: 5| Step: 5
Training loss: 2.735065482016467
Validation loss: 2.4906962942978703

Epoch: 5| Step: 6
Training loss: 2.846427746677091
Validation loss: 2.489269667438021

Epoch: 5| Step: 7
Training loss: 2.7029290100665744
Validation loss: 2.496325214176389

Epoch: 5| Step: 8
Training loss: 2.574041658599386
Validation loss: 2.5268714535630514

Epoch: 5| Step: 9
Training loss: 2.82336176404934
Validation loss: 2.5580261347320756

Epoch: 5| Step: 10
Training loss: 2.038781976221028
Validation loss: 2.584300158653834

Epoch: 123| Step: 0
Training loss: 2.9213027801773097
Validation loss: 2.5922621942106656

Epoch: 5| Step: 1
Training loss: 2.5344033085644924
Validation loss: 2.5921465170689624

Epoch: 5| Step: 2
Training loss: 2.8424119421371192
Validation loss: 2.5812072625625104

Epoch: 5| Step: 3
Training loss: 2.8146735375719705
Validation loss: 2.530456734660969

Epoch: 5| Step: 4
Training loss: 2.7785908706410725
Validation loss: 2.515873597037996

Epoch: 5| Step: 5
Training loss: 2.9390712350556334
Validation loss: 2.5033761899815143

Epoch: 5| Step: 6
Training loss: 3.002482817360073
Validation loss: 2.494420423024401

Epoch: 5| Step: 7
Training loss: 2.7485626972910664
Validation loss: 2.499834816100342

Epoch: 5| Step: 8
Training loss: 2.614973082248884
Validation loss: 2.4977255349989673

Epoch: 5| Step: 9
Training loss: 2.607628334815324
Validation loss: 2.4961962896677736

Epoch: 5| Step: 10
Training loss: 2.9966803303521274
Validation loss: 2.49573717823838

Epoch: 124| Step: 0
Training loss: 2.6472527208558336
Validation loss: 2.5000293965816076

Epoch: 5| Step: 1
Training loss: 2.598146504195478
Validation loss: 2.494441074547782

Epoch: 5| Step: 2
Training loss: 2.4549692595629726
Validation loss: 2.4978605663030384

Epoch: 5| Step: 3
Training loss: 2.5243718451801107
Validation loss: 2.4999178185850313

Epoch: 5| Step: 4
Training loss: 3.029260041180804
Validation loss: 2.500624509969137

Epoch: 5| Step: 5
Training loss: 2.7533486525484263
Validation loss: 2.5011655438804867

Epoch: 5| Step: 6
Training loss: 2.782052427970238
Validation loss: 2.509021997793708

Epoch: 5| Step: 7
Training loss: 2.968457980600833
Validation loss: 2.5117105662397354

Epoch: 5| Step: 8
Training loss: 3.249676908425709
Validation loss: 2.5152157757850713

Epoch: 5| Step: 9
Training loss: 2.6941502815815777
Validation loss: 2.5096501006482117

Epoch: 5| Step: 10
Training loss: 2.8301055885809436
Validation loss: 2.506227775824821

Epoch: 125| Step: 0
Training loss: 3.111019294004532
Validation loss: 2.5057732289276555

Epoch: 5| Step: 1
Training loss: 2.7790480051249236
Validation loss: 2.5066917894400893

Epoch: 5| Step: 2
Training loss: 3.282270581609389
Validation loss: 2.5268758166370096

Epoch: 5| Step: 3
Training loss: 2.3986383906923066
Validation loss: 2.5163548060020915

Epoch: 5| Step: 4
Training loss: 2.3708145002299807
Validation loss: 2.512872049572228

Epoch: 5| Step: 5
Training loss: 2.8271975181944335
Validation loss: 2.501369929545621

Epoch: 5| Step: 6
Training loss: 2.986116709938025
Validation loss: 2.501293927328896

Epoch: 5| Step: 7
Training loss: 3.017859545180331
Validation loss: 2.4962942047512784

Epoch: 5| Step: 8
Training loss: 2.4101602068950503
Validation loss: 2.5010464139548727

Epoch: 5| Step: 9
Training loss: 2.527052707806271
Validation loss: 2.5053709556101866

Epoch: 5| Step: 10
Training loss: 2.7510734543750712
Validation loss: 2.50616842394958

Epoch: 126| Step: 0
Training loss: 2.6706709798027983
Validation loss: 2.4985651349039806

Epoch: 5| Step: 1
Training loss: 2.2950381245490337
Validation loss: 2.4991815129576027

Epoch: 5| Step: 2
Training loss: 3.124586459453881
Validation loss: 2.5088920622093696

Epoch: 5| Step: 3
Training loss: 2.8694959281577432
Validation loss: 2.5104375494645517

Epoch: 5| Step: 4
Training loss: 2.1794185130635713
Validation loss: 2.5171863426689143

Epoch: 5| Step: 5
Training loss: 3.1101738751737784
Validation loss: 2.5080055998428126

Epoch: 5| Step: 6
Training loss: 3.156062054467623
Validation loss: 2.5202255896128354

Epoch: 5| Step: 7
Training loss: 2.078494619898914
Validation loss: 2.516574136119137

Epoch: 5| Step: 8
Training loss: 3.3166148700854863
Validation loss: 2.513479886704257

Epoch: 5| Step: 9
Training loss: 2.6705342994748507
Validation loss: 2.5064715874035812

Epoch: 5| Step: 10
Training loss: 2.72785023007983
Validation loss: 2.5160451059409006

Epoch: 127| Step: 0
Training loss: 2.384277293751919
Validation loss: 2.514341824670655

Epoch: 5| Step: 1
Training loss: 2.580566452445009
Validation loss: 2.503091162388

Epoch: 5| Step: 2
Training loss: 3.000922220261316
Validation loss: 2.5029331945499305

Epoch: 5| Step: 3
Training loss: 2.9100680958753933
Validation loss: 2.495352414069986

Epoch: 5| Step: 4
Training loss: 2.8614826043516888
Validation loss: 2.506815097649558

Epoch: 5| Step: 5
Training loss: 2.6541285401804284
Validation loss: 2.513586964576933

Epoch: 5| Step: 6
Training loss: 2.9158946150795644
Validation loss: 2.5172657167330037

Epoch: 5| Step: 7
Training loss: 2.8556193717755805
Validation loss: 2.509113177771396

Epoch: 5| Step: 8
Training loss: 3.025720330848146
Validation loss: 2.517480573373824

Epoch: 5| Step: 9
Training loss: 2.2706918818196944
Validation loss: 2.5207375149138453

Epoch: 5| Step: 10
Training loss: 2.93389411536541
Validation loss: 2.5122944797125393

Epoch: 128| Step: 0
Training loss: 2.1393087753847007
Validation loss: 2.5034227843695427

Epoch: 5| Step: 1
Training loss: 2.4446321461118576
Validation loss: 2.500874878993621

Epoch: 5| Step: 2
Training loss: 2.6209496630478175
Validation loss: 2.4932182629414097

Epoch: 5| Step: 3
Training loss: 3.0401466612824675
Validation loss: 2.491523878828474

Epoch: 5| Step: 4
Training loss: 2.647914418465425
Validation loss: 2.4876467954100105

Epoch: 5| Step: 5
Training loss: 3.07158605355595
Validation loss: 2.4876915671860353

Epoch: 5| Step: 6
Training loss: 3.3543621187938286
Validation loss: 2.489189817248145

Epoch: 5| Step: 7
Training loss: 2.5643738199073702
Validation loss: 2.4956807561591083

Epoch: 5| Step: 8
Training loss: 2.5019558884950097
Validation loss: 2.494303696668215

Epoch: 5| Step: 9
Training loss: 3.031835597782304
Validation loss: 2.506911704205713

Epoch: 5| Step: 10
Training loss: 2.88874070896056
Validation loss: 2.5089200364691857

Epoch: 129| Step: 0
Training loss: 1.8360737202207338
Validation loss: 2.505112595249204

Epoch: 5| Step: 1
Training loss: 2.6934589591644738
Validation loss: 2.5019047997191985

Epoch: 5| Step: 2
Training loss: 3.2253066752502875
Validation loss: 2.5006365119585503

Epoch: 5| Step: 3
Training loss: 2.803176515375901
Validation loss: 2.503256096588984

Epoch: 5| Step: 4
Training loss: 3.111653935291117
Validation loss: 2.494479386401562

Epoch: 5| Step: 5
Training loss: 2.52237511347415
Validation loss: 2.47964266017004

Epoch: 5| Step: 6
Training loss: 2.7410936048488406
Validation loss: 2.4751195953897835

Epoch: 5| Step: 7
Training loss: 2.6752477406373787
Validation loss: 2.4870174793929616

Epoch: 5| Step: 8
Training loss: 3.219326819427951
Validation loss: 2.4835040613611024

Epoch: 5| Step: 9
Training loss: 2.46346528551168
Validation loss: 2.483271099650609

Epoch: 5| Step: 10
Training loss: 2.8070558202375824
Validation loss: 2.47919920495564

Epoch: 130| Step: 0
Training loss: 2.764249987844857
Validation loss: 2.4826345014046938

Epoch: 5| Step: 1
Training loss: 2.5877483746281484
Validation loss: 2.492192551797427

Epoch: 5| Step: 2
Training loss: 2.720880484841804
Validation loss: 2.5037583894963658

Epoch: 5| Step: 3
Training loss: 2.2392597289977627
Validation loss: 2.502143349205707

Epoch: 5| Step: 4
Training loss: 2.88370737799145
Validation loss: 2.503857492455922

Epoch: 5| Step: 5
Training loss: 2.6980372712464358
Validation loss: 2.499107179879709

Epoch: 5| Step: 6
Training loss: 2.805554014358685
Validation loss: 2.492679950147016

Epoch: 5| Step: 7
Training loss: 2.936871075770648
Validation loss: 2.4849964411220165

Epoch: 5| Step: 8
Training loss: 3.036860357054152
Validation loss: 2.4842029567944044

Epoch: 5| Step: 9
Training loss: 3.168207613480641
Validation loss: 2.486599919174057

Epoch: 5| Step: 10
Training loss: 2.468361159980661
Validation loss: 2.493986532436856

Epoch: 131| Step: 0
Training loss: 3.173722804742912
Validation loss: 2.5168823720674

Epoch: 5| Step: 1
Training loss: 2.4473365475058415
Validation loss: 2.5059781236971967

Epoch: 5| Step: 2
Training loss: 2.658231288023569
Validation loss: 2.508237986465597

Epoch: 5| Step: 3
Training loss: 3.0899940579551672
Validation loss: 2.5087793670378686

Epoch: 5| Step: 4
Training loss: 2.377856694849939
Validation loss: 2.4875728369986034

Epoch: 5| Step: 5
Training loss: 2.6192027062576284
Validation loss: 2.487452638681976

Epoch: 5| Step: 6
Training loss: 2.8340257658719294
Validation loss: 2.483274172997474

Epoch: 5| Step: 7
Training loss: 2.370555533797586
Validation loss: 2.480585609598499

Epoch: 5| Step: 8
Training loss: 3.1988872500717926
Validation loss: 2.475209434923164

Epoch: 5| Step: 9
Training loss: 3.0286520610470866
Validation loss: 2.480530869585653

Epoch: 5| Step: 10
Training loss: 2.312835050487639
Validation loss: 2.4919704337967374

Epoch: 132| Step: 0
Training loss: 2.7207251203514615
Validation loss: 2.5152478810230323

Epoch: 5| Step: 1
Training loss: 2.8233598218153424
Validation loss: 2.5556493667331175

Epoch: 5| Step: 2
Training loss: 2.285346337913864
Validation loss: 2.575219112121397

Epoch: 5| Step: 3
Training loss: 2.869737369602941
Validation loss: 2.5789998946275325

Epoch: 5| Step: 4
Training loss: 2.9173364324407953
Validation loss: 2.5680060889299323

Epoch: 5| Step: 5
Training loss: 2.588967475689767
Validation loss: 2.5406765198528856

Epoch: 5| Step: 6
Training loss: 2.251846403585688
Validation loss: 2.5049590742608587

Epoch: 5| Step: 7
Training loss: 2.4835205528126147
Validation loss: 2.481450195039084

Epoch: 5| Step: 8
Training loss: 3.3432628241038955
Validation loss: 2.4788910411049385

Epoch: 5| Step: 9
Training loss: 3.0061896367664747
Validation loss: 2.4748772229513367

Epoch: 5| Step: 10
Training loss: 3.081377044596587
Validation loss: 2.47635409264119

Epoch: 133| Step: 0
Training loss: 2.3716309392958554
Validation loss: 2.517789793438969

Epoch: 5| Step: 1
Training loss: 2.7409347759281566
Validation loss: 2.5409252488059795

Epoch: 5| Step: 2
Training loss: 3.012300863055181
Validation loss: 2.538967129893784

Epoch: 5| Step: 3
Training loss: 2.512247222786491
Validation loss: 2.5428675146914697

Epoch: 5| Step: 4
Training loss: 2.702647525314325
Validation loss: 2.5281804862434076

Epoch: 5| Step: 5
Training loss: 3.1253529158630786
Validation loss: 2.5402403431427114

Epoch: 5| Step: 6
Training loss: 1.9638140124420813
Validation loss: 2.514211734740572

Epoch: 5| Step: 7
Training loss: 2.448070786406379
Validation loss: 2.5129290752352196

Epoch: 5| Step: 8
Training loss: 3.204555285184773
Validation loss: 2.5500172810508817

Epoch: 5| Step: 9
Training loss: 3.0788152085467724
Validation loss: 2.584353297375906

Epoch: 5| Step: 10
Training loss: 3.383677876284766
Validation loss: 2.6058045324161543

Epoch: 134| Step: 0
Training loss: 2.636441500180596
Validation loss: 2.6012090666905383

Epoch: 5| Step: 1
Training loss: 2.828444489194474
Validation loss: 2.5945171413238177

Epoch: 5| Step: 2
Training loss: 2.963917382709221
Validation loss: 2.5572454681711294

Epoch: 5| Step: 3
Training loss: 2.5350677521810328
Validation loss: 2.511161614697346

Epoch: 5| Step: 4
Training loss: 2.776354649824399
Validation loss: 2.4877959612851592

Epoch: 5| Step: 5
Training loss: 2.5314911150594623
Validation loss: 2.469000165421065

Epoch: 5| Step: 6
Training loss: 2.6593043101650666
Validation loss: 2.4671151430989653

Epoch: 5| Step: 7
Training loss: 3.183662947388313
Validation loss: 2.470944103671526

Epoch: 5| Step: 8
Training loss: 2.1807643185711463
Validation loss: 2.4739050522114683

Epoch: 5| Step: 9
Training loss: 3.3889648310867395
Validation loss: 2.474443544604315

Epoch: 5| Step: 10
Training loss: 2.7830876483719496
Validation loss: 2.470439083321358

Epoch: 135| Step: 0
Training loss: 2.9345707999687614
Validation loss: 2.487198831299657

Epoch: 5| Step: 1
Training loss: 2.988654139571691
Validation loss: 2.4770485452247497

Epoch: 5| Step: 2
Training loss: 2.608038462911051
Validation loss: 2.4837719750477945

Epoch: 5| Step: 3
Training loss: 2.5811984151715044
Validation loss: 2.505239057775675

Epoch: 5| Step: 4
Training loss: 2.327738889896926
Validation loss: 2.506958799919784

Epoch: 5| Step: 5
Training loss: 2.767224727403896
Validation loss: 2.5223454223809156

Epoch: 5| Step: 6
Training loss: 2.4080017451156426
Validation loss: 2.5241931609415187

Epoch: 5| Step: 7
Training loss: 2.891460895820752
Validation loss: 2.5186145740058206

Epoch: 5| Step: 8
Training loss: 2.4208746043729024
Validation loss: 2.5360683227144953

Epoch: 5| Step: 9
Training loss: 3.2068245713129926
Validation loss: 2.526411385728718

Epoch: 5| Step: 10
Training loss: 3.0863209932797933
Validation loss: 2.5018244023850755

Epoch: 136| Step: 0
Training loss: 2.9561393733223804
Validation loss: 2.4898262133711264

Epoch: 5| Step: 1
Training loss: 3.1453398429034594
Validation loss: 2.4849159094047977

Epoch: 5| Step: 2
Training loss: 2.8003312391810544
Validation loss: 2.475342555374705

Epoch: 5| Step: 3
Training loss: 2.5861511142239557
Validation loss: 2.472550981839731

Epoch: 5| Step: 4
Training loss: 2.680619236305535
Validation loss: 2.4700204849373493

Epoch: 5| Step: 5
Training loss: 3.031678159697902
Validation loss: 2.4697193575503196

Epoch: 5| Step: 6
Training loss: 2.6046463384734113
Validation loss: 2.4659164011340264

Epoch: 5| Step: 7
Training loss: 2.7348736989429554
Validation loss: 2.46486581836985

Epoch: 5| Step: 8
Training loss: 2.2287915232026854
Validation loss: 2.476910656033212

Epoch: 5| Step: 9
Training loss: 2.743150851583532
Validation loss: 2.477999570609995

Epoch: 5| Step: 10
Training loss: 2.676063778851361
Validation loss: 2.495762745308958

Epoch: 137| Step: 0
Training loss: 2.9699643512474463
Validation loss: 2.5165112793458326

Epoch: 5| Step: 1
Training loss: 2.762179539937991
Validation loss: 2.5064942251235687

Epoch: 5| Step: 2
Training loss: 3.4742299001869505
Validation loss: 2.5113403318994996

Epoch: 5| Step: 3
Training loss: 2.71108691768413
Validation loss: 2.492777028401446

Epoch: 5| Step: 4
Training loss: 2.2244631859066812
Validation loss: 2.4868728299701237

Epoch: 5| Step: 5
Training loss: 2.788543225414898
Validation loss: 2.473383849474754

Epoch: 5| Step: 6
Training loss: 2.705142023867363
Validation loss: 2.47242442705153

Epoch: 5| Step: 7
Training loss: 2.6915774796141148
Validation loss: 2.4656570070866795

Epoch: 5| Step: 8
Training loss: 2.7723976442449487
Validation loss: 2.469278889778643

Epoch: 5| Step: 9
Training loss: 2.6395472748141877
Validation loss: 2.4712729749583047

Epoch: 5| Step: 10
Training loss: 2.2811633576962107
Validation loss: 2.465053396736782

Epoch: 138| Step: 0
Training loss: 2.772731121532424
Validation loss: 2.471934337460444

Epoch: 5| Step: 1
Training loss: 2.435437430191832
Validation loss: 2.4837395630674224

Epoch: 5| Step: 2
Training loss: 2.5222223621691398
Validation loss: 2.4910986887144784

Epoch: 5| Step: 3
Training loss: 2.934574374737205
Validation loss: 2.4965504309687363

Epoch: 5| Step: 4
Training loss: 2.9943059289618055
Validation loss: 2.488974324557063

Epoch: 5| Step: 5
Training loss: 2.8107194138426643
Validation loss: 2.4792876568669073

Epoch: 5| Step: 6
Training loss: 2.579000798213816
Validation loss: 2.480521198028596

Epoch: 5| Step: 7
Training loss: 3.0352539675188415
Validation loss: 2.476676233620644

Epoch: 5| Step: 8
Training loss: 2.6408231762439636
Validation loss: 2.4736830010991246

Epoch: 5| Step: 9
Training loss: 2.769793456326744
Validation loss: 2.482547144608902

Epoch: 5| Step: 10
Training loss: 2.6554616319157502
Validation loss: 2.4948013675067875

Epoch: 139| Step: 0
Training loss: 2.4739652185176944
Validation loss: 2.4901741457111313

Epoch: 5| Step: 1
Training loss: 2.919553109552397
Validation loss: 2.4797277331854604

Epoch: 5| Step: 2
Training loss: 2.9977472112046333
Validation loss: 2.4755862844156695

Epoch: 5| Step: 3
Training loss: 2.836042754266642
Validation loss: 2.474605786369936

Epoch: 5| Step: 4
Training loss: 2.4051684636616475
Validation loss: 2.4688444855484213

Epoch: 5| Step: 5
Training loss: 2.458503900418961
Validation loss: 2.4736410662714796

Epoch: 5| Step: 6
Training loss: 2.598204682472396
Validation loss: 2.4769831464149723

Epoch: 5| Step: 7
Training loss: 2.4866295906691462
Validation loss: 2.4832627178700415

Epoch: 5| Step: 8
Training loss: 2.889034679190175
Validation loss: 2.483408569616187

Epoch: 5| Step: 9
Training loss: 2.946212347774877
Validation loss: 2.483250636039502

Epoch: 5| Step: 10
Training loss: 3.179816615976883
Validation loss: 2.507203654946568

Epoch: 140| Step: 0
Training loss: 3.159495130117134
Validation loss: 2.506608623641761

Epoch: 5| Step: 1
Training loss: 2.6568669219826364
Validation loss: 2.5097290092572146

Epoch: 5| Step: 2
Training loss: 2.2238621448974882
Validation loss: 2.4855849037105946

Epoch: 5| Step: 3
Training loss: 2.742228363689028
Validation loss: 2.487966265537644

Epoch: 5| Step: 4
Training loss: 2.7289303878734485
Validation loss: 2.4785321806733043

Epoch: 5| Step: 5
Training loss: 2.610598796834444
Validation loss: 2.475592812116821

Epoch: 5| Step: 6
Training loss: 2.8724275773416386
Validation loss: 2.461721698688418

Epoch: 5| Step: 7
Training loss: 2.8261568587088113
Validation loss: 2.4698773519485346

Epoch: 5| Step: 8
Training loss: 2.9440955929059873
Validation loss: 2.460274696454947

Epoch: 5| Step: 9
Training loss: 2.6636489144401505
Validation loss: 2.45902293068001

Epoch: 5| Step: 10
Training loss: 2.5054322352185494
Validation loss: 2.466633594746314

Epoch: 141| Step: 0
Training loss: 2.6604573755776704
Validation loss: 2.4753828996118736

Epoch: 5| Step: 1
Training loss: 2.5881622977978855
Validation loss: 2.489147963942522

Epoch: 5| Step: 2
Training loss: 2.0449365653573337
Validation loss: 2.499329855530202

Epoch: 5| Step: 3
Training loss: 2.9833404185745525
Validation loss: 2.5202438131623963

Epoch: 5| Step: 4
Training loss: 3.3556509268248083
Validation loss: 2.509196335141736

Epoch: 5| Step: 5
Training loss: 2.1224092510399934
Validation loss: 2.502444014000903

Epoch: 5| Step: 6
Training loss: 2.9263154422004374
Validation loss: 2.5044328438739734

Epoch: 5| Step: 7
Training loss: 2.9799071416532388
Validation loss: 2.4924791255251297

Epoch: 5| Step: 8
Training loss: 2.893961862013572
Validation loss: 2.4740424115455872

Epoch: 5| Step: 9
Training loss: 2.707217519717646
Validation loss: 2.4840286745112543

Epoch: 5| Step: 10
Training loss: 2.5239163821254422
Validation loss: 2.4738207188896273

Epoch: 142| Step: 0
Training loss: 2.494301882603884
Validation loss: 2.462516286315248

Epoch: 5| Step: 1
Training loss: 2.3761447356224883
Validation loss: 2.4699812716286815

Epoch: 5| Step: 2
Training loss: 2.2054774933823103
Validation loss: 2.469252055946237

Epoch: 5| Step: 3
Training loss: 3.2437728498826397
Validation loss: 2.4675410903628068

Epoch: 5| Step: 4
Training loss: 2.8078471373224407
Validation loss: 2.4702472936023994

Epoch: 5| Step: 5
Training loss: 2.758855519802421
Validation loss: 2.4796129433219174

Epoch: 5| Step: 6
Training loss: 3.2733997716072354
Validation loss: 2.488408375767963

Epoch: 5| Step: 7
Training loss: 2.600426136454563
Validation loss: 2.499996150434258

Epoch: 5| Step: 8
Training loss: 2.1380075755542687
Validation loss: 2.4931808036738685

Epoch: 5| Step: 9
Training loss: 2.690601245097391
Validation loss: 2.491628025419415

Epoch: 5| Step: 10
Training loss: 3.1952762368529837
Validation loss: 2.4890971190181985

Epoch: 143| Step: 0
Training loss: 2.8351235811186157
Validation loss: 2.4819298989898333

Epoch: 5| Step: 1
Training loss: 3.037028360052903
Validation loss: 2.4743002913731047

Epoch: 5| Step: 2
Training loss: 2.368571566099051
Validation loss: 2.4692502920003547

Epoch: 5| Step: 3
Training loss: 2.5942042309224305
Validation loss: 2.4688227860715575

Epoch: 5| Step: 4
Training loss: 2.34348570287147
Validation loss: 2.4724929066926253

Epoch: 5| Step: 5
Training loss: 2.8120722975302157
Validation loss: 2.472838740135188

Epoch: 5| Step: 6
Training loss: 2.6871950730617336
Validation loss: 2.471708480166741

Epoch: 5| Step: 7
Training loss: 3.37808016342347
Validation loss: 2.4718680337949004

Epoch: 5| Step: 8
Training loss: 2.61814903701745
Validation loss: 2.4788702031530407

Epoch: 5| Step: 9
Training loss: 2.75624926301077
Validation loss: 2.4789477822424053

Epoch: 5| Step: 10
Training loss: 2.125817982932127
Validation loss: 2.4915038143233295

Epoch: 144| Step: 0
Training loss: 2.584146484456929
Validation loss: 2.504743123056917

Epoch: 5| Step: 1
Training loss: 2.7350938996370022
Validation loss: 2.5091664472349575

Epoch: 5| Step: 2
Training loss: 2.7382475542071316
Validation loss: 2.515122073113664

Epoch: 5| Step: 3
Training loss: 2.958820965475489
Validation loss: 2.4972306664116894

Epoch: 5| Step: 4
Training loss: 2.524124193796579
Validation loss: 2.5085836860454687

Epoch: 5| Step: 5
Training loss: 3.0352726623126496
Validation loss: 2.483969661217919

Epoch: 5| Step: 6
Training loss: 2.887346707853516
Validation loss: 2.47667136547777

Epoch: 5| Step: 7
Training loss: 2.4957608521837034
Validation loss: 2.4756220392514328

Epoch: 5| Step: 8
Training loss: 2.7002603864502714
Validation loss: 2.466014562083257

Epoch: 5| Step: 9
Training loss: 2.1169318576201572
Validation loss: 2.4678605641143436

Epoch: 5| Step: 10
Training loss: 2.9888779786142026
Validation loss: 2.468054735178105

Epoch: 145| Step: 0
Training loss: 2.214402142992802
Validation loss: 2.4590059663386876

Epoch: 5| Step: 1
Training loss: 3.125793051226629
Validation loss: 2.4703837013012375

Epoch: 5| Step: 2
Training loss: 2.6813982515764287
Validation loss: 2.4737114035791006

Epoch: 5| Step: 3
Training loss: 2.5085293229632097
Validation loss: 2.4745444949972133

Epoch: 5| Step: 4
Training loss: 2.103011188573455
Validation loss: 2.4865025585114853

Epoch: 5| Step: 5
Training loss: 2.6712793054253976
Validation loss: 2.5032084068511455

Epoch: 5| Step: 6
Training loss: 3.4083697521499343
Validation loss: 2.520850179913077

Epoch: 5| Step: 7
Training loss: 2.8394892706140182
Validation loss: 2.5002828068898735

Epoch: 5| Step: 8
Training loss: 2.3374710407605144
Validation loss: 2.4738533002041074

Epoch: 5| Step: 9
Training loss: 2.9131502661666118
Validation loss: 2.467420838845146

Epoch: 5| Step: 10
Training loss: 2.8427595153278977
Validation loss: 2.4697705484643557

Epoch: 146| Step: 0
Training loss: 2.155847041859767
Validation loss: 2.457216516647357

Epoch: 5| Step: 1
Training loss: 2.512420508802083
Validation loss: 2.460913042063163

Epoch: 5| Step: 2
Training loss: 2.7398543036491207
Validation loss: 2.452937405134826

Epoch: 5| Step: 3
Training loss: 2.5817325205702035
Validation loss: 2.4605670155908013

Epoch: 5| Step: 4
Training loss: 2.331145816551097
Validation loss: 2.4620453101128126

Epoch: 5| Step: 5
Training loss: 2.77581461728819
Validation loss: 2.4721583209924476

Epoch: 5| Step: 6
Training loss: 2.90875218462237
Validation loss: 2.4804753831912465

Epoch: 5| Step: 7
Training loss: 2.582692025681309
Validation loss: 2.4784656542473322

Epoch: 5| Step: 8
Training loss: 3.149546236325318
Validation loss: 2.5087420154511526

Epoch: 5| Step: 9
Training loss: 3.228050055284742
Validation loss: 2.527060074938385

Epoch: 5| Step: 10
Training loss: 2.506416383771194
Validation loss: 2.528711727300945

Epoch: 147| Step: 0
Training loss: 2.6068019401429514
Validation loss: 2.559197551562715

Epoch: 5| Step: 1
Training loss: 2.976920679524017
Validation loss: 2.497761344464707

Epoch: 5| Step: 2
Training loss: 3.1612044624738296
Validation loss: 2.48034174649462

Epoch: 5| Step: 3
Training loss: 2.656013927067011
Validation loss: 2.4540476367989377

Epoch: 5| Step: 4
Training loss: 2.3092719564819864
Validation loss: 2.464329574272945

Epoch: 5| Step: 5
Training loss: 2.790696635079745
Validation loss: 2.4643482860676365

Epoch: 5| Step: 6
Training loss: 3.2165825221729105
Validation loss: 2.462322203244997

Epoch: 5| Step: 7
Training loss: 2.6622142477222126
Validation loss: 2.4597799828803377

Epoch: 5| Step: 8
Training loss: 2.15122344670596
Validation loss: 2.472658962257405

Epoch: 5| Step: 9
Training loss: 2.877956860132156
Validation loss: 2.4715380706164174

Epoch: 5| Step: 10
Training loss: 2.4576438540385497
Validation loss: 2.4867522565841083

Epoch: 148| Step: 0
Training loss: 2.308935149843772
Validation loss: 2.4921043336600763

Epoch: 5| Step: 1
Training loss: 2.409009070012368
Validation loss: 2.4827930214330256

Epoch: 5| Step: 2
Training loss: 3.053053943506077
Validation loss: 2.4662816906985476

Epoch: 5| Step: 3
Training loss: 2.2348646147684192
Validation loss: 2.465849723563355

Epoch: 5| Step: 4
Training loss: 2.522866482685762
Validation loss: 2.4631913601260553

Epoch: 5| Step: 5
Training loss: 3.0067114461988407
Validation loss: 2.4578805339255716

Epoch: 5| Step: 6
Training loss: 2.3339537295320745
Validation loss: 2.452438995334153

Epoch: 5| Step: 7
Training loss: 2.880043747092821
Validation loss: 2.4504899581221786

Epoch: 5| Step: 8
Training loss: 2.7539784523447173
Validation loss: 2.4622353273228708

Epoch: 5| Step: 9
Training loss: 2.850330661531381
Validation loss: 2.4685876620818212

Epoch: 5| Step: 10
Training loss: 3.2357972192496867
Validation loss: 2.4793330438601244

Epoch: 149| Step: 0
Training loss: 2.6954285527551667
Validation loss: 2.4825441096033236

Epoch: 5| Step: 1
Training loss: 3.304605974494914
Validation loss: 2.4720156229066887

Epoch: 5| Step: 2
Training loss: 2.505023201322946
Validation loss: 2.4649751733901963

Epoch: 5| Step: 3
Training loss: 2.3115576808828155
Validation loss: 2.463401680322789

Epoch: 5| Step: 4
Training loss: 2.728562722588105
Validation loss: 2.464846801599911

Epoch: 5| Step: 5
Training loss: 2.120563813216969
Validation loss: 2.470597889838171

Epoch: 5| Step: 6
Training loss: 2.765567326348459
Validation loss: 2.4772432866079375

Epoch: 5| Step: 7
Training loss: 3.0881528218260423
Validation loss: 2.493320878709386

Epoch: 5| Step: 8
Training loss: 2.637593622941467
Validation loss: 2.512087814158903

Epoch: 5| Step: 9
Training loss: 2.8088923734564166
Validation loss: 2.5052889795433897

Epoch: 5| Step: 10
Training loss: 2.754326538047393
Validation loss: 2.523795027838127

Epoch: 150| Step: 0
Training loss: 2.8403319892798047
Validation loss: 2.507384404669271

Epoch: 5| Step: 1
Training loss: 2.4448426011485624
Validation loss: 2.479161905098163

Epoch: 5| Step: 2
Training loss: 2.746773213832245
Validation loss: 2.471875905574937

Epoch: 5| Step: 3
Training loss: 2.94644216228835
Validation loss: 2.4709104755187963

Epoch: 5| Step: 4
Training loss: 2.831452998616439
Validation loss: 2.4598138715879707

Epoch: 5| Step: 5
Training loss: 2.649801617520288
Validation loss: 2.455992200399813

Epoch: 5| Step: 6
Training loss: 2.532658408841438
Validation loss: 2.4481215074266043

Epoch: 5| Step: 7
Training loss: 2.4702205865253712
Validation loss: 2.450618069329059

Epoch: 5| Step: 8
Training loss: 2.918518423169015
Validation loss: 2.4517882382029446

Epoch: 5| Step: 9
Training loss: 2.7702045348634505
Validation loss: 2.45573685981665

Epoch: 5| Step: 10
Training loss: 2.597940392119469
Validation loss: 2.469675917725266

Epoch: 151| Step: 0
Training loss: 2.9608051199999914
Validation loss: 2.482211963184921

Epoch: 5| Step: 1
Training loss: 2.3641654386126136
Validation loss: 2.499230796652786

Epoch: 5| Step: 2
Training loss: 2.6809636850142136
Validation loss: 2.5453941453437587

Epoch: 5| Step: 3
Training loss: 2.725703500353327
Validation loss: 2.566616411666659

Epoch: 5| Step: 4
Training loss: 3.091716984616132
Validation loss: 2.6200533118730576

Epoch: 5| Step: 5
Training loss: 3.0823737704751326
Validation loss: 2.6153794286646592

Epoch: 5| Step: 6
Training loss: 2.5164934637665826
Validation loss: 2.668665308707339

Epoch: 5| Step: 7
Training loss: 3.546084009103786
Validation loss: 2.6566740195828698

Epoch: 5| Step: 8
Training loss: 2.635960720030081
Validation loss: 2.592809186999151

Epoch: 5| Step: 9
Training loss: 2.965318161875292
Validation loss: 2.541648878468669

Epoch: 5| Step: 10
Training loss: 1.9162540268031423
Validation loss: 2.5091047637962043

Epoch: 152| Step: 0
Training loss: 3.154649385294763
Validation loss: 2.5251205877707092

Epoch: 5| Step: 1
Training loss: 2.394353215878496
Validation loss: 2.519715463922059

Epoch: 5| Step: 2
Training loss: 2.8052411821276233
Validation loss: 2.534072323441237

Epoch: 5| Step: 3
Training loss: 2.445349549814171
Validation loss: 2.565033198531999

Epoch: 5| Step: 4
Training loss: 2.7628590173583927
Validation loss: 2.530101181708697

Epoch: 5| Step: 5
Training loss: 2.62635096345476
Validation loss: 2.4987772289291432

Epoch: 5| Step: 6
Training loss: 2.6138393564516256
Validation loss: 2.4737060228234324

Epoch: 5| Step: 7
Training loss: 2.6831028474026093
Validation loss: 2.460467815747089

Epoch: 5| Step: 8
Training loss: 2.603541082900195
Validation loss: 2.442708363069378

Epoch: 5| Step: 9
Training loss: 3.181207466965331
Validation loss: 2.43581721019835

Epoch: 5| Step: 10
Training loss: 2.807076799217963
Validation loss: 2.4374415482926692

Epoch: 153| Step: 0
Training loss: 2.867832869987061
Validation loss: 2.430572589125084

Epoch: 5| Step: 1
Training loss: 3.086553970762331
Validation loss: 2.43809747275495

Epoch: 5| Step: 2
Training loss: 2.8063816914743063
Validation loss: 2.439716840294453

Epoch: 5| Step: 3
Training loss: 3.0068862083224572
Validation loss: 2.4457938008821363

Epoch: 5| Step: 4
Training loss: 2.6119725438671386
Validation loss: 2.4547156538046266

Epoch: 5| Step: 5
Training loss: 2.330245211063175
Validation loss: 2.476320198907161

Epoch: 5| Step: 6
Training loss: 2.7923912038074676
Validation loss: 2.4912428972490943

Epoch: 5| Step: 7
Training loss: 2.4310426520650905
Validation loss: 2.4923991132979575

Epoch: 5| Step: 8
Training loss: 2.7938807992377055
Validation loss: 2.484029168862932

Epoch: 5| Step: 9
Training loss: 2.7970509393858975
Validation loss: 2.482054741548104

Epoch: 5| Step: 10
Training loss: 2.318732857448004
Validation loss: 2.4757529049817

Epoch: 154| Step: 0
Training loss: 2.6711724679465427
Validation loss: 2.4466530985340182

Epoch: 5| Step: 1
Training loss: 3.2573686841726874
Validation loss: 2.4528161199230736

Epoch: 5| Step: 2
Training loss: 2.5438106332811774
Validation loss: 2.4528073173797442

Epoch: 5| Step: 3
Training loss: 3.0470361911488513
Validation loss: 2.4605688842201476

Epoch: 5| Step: 4
Training loss: 2.491940955520327
Validation loss: 2.467973409648045

Epoch: 5| Step: 5
Training loss: 2.8710987324574115
Validation loss: 2.459036552527675

Epoch: 5| Step: 6
Training loss: 2.478110037490296
Validation loss: 2.4556386534231165

Epoch: 5| Step: 7
Training loss: 2.1439675179056406
Validation loss: 2.4465516689549722

Epoch: 5| Step: 8
Training loss: 2.9408368576546104
Validation loss: 2.444042732802695

Epoch: 5| Step: 9
Training loss: 2.1872920346177254
Validation loss: 2.440474686813849

Epoch: 5| Step: 10
Training loss: 2.8990084761791395
Validation loss: 2.4313393530203578

Epoch: 155| Step: 0
Training loss: 2.3361911189464752
Validation loss: 2.442928764384653

Epoch: 5| Step: 1
Training loss: 2.52801665084522
Validation loss: 2.4419556998906167

Epoch: 5| Step: 2
Training loss: 3.0022444276563416
Validation loss: 2.4397038356290994

Epoch: 5| Step: 3
Training loss: 3.0506615218383693
Validation loss: 2.4407922930137302

Epoch: 5| Step: 4
Training loss: 2.7030782530165776
Validation loss: 2.4702570167997107

Epoch: 5| Step: 5
Training loss: 2.7665147804790653
Validation loss: 2.5017982373423853

Epoch: 5| Step: 6
Training loss: 2.404043796337128
Validation loss: 2.527172698488772

Epoch: 5| Step: 7
Training loss: 2.6457251779472712
Validation loss: 2.531837580522926

Epoch: 5| Step: 8
Training loss: 2.488077152331613
Validation loss: 2.5104112771010896

Epoch: 5| Step: 9
Training loss: 2.605955064217803
Validation loss: 2.476606664745469

Epoch: 5| Step: 10
Training loss: 3.2071344356687246
Validation loss: 2.4703857653850845

Epoch: 156| Step: 0
Training loss: 2.8579723482389294
Validation loss: 2.454964841270056

Epoch: 5| Step: 1
Training loss: 3.196483145793635
Validation loss: 2.4521510846213923

Epoch: 5| Step: 2
Training loss: 2.8011557782186367
Validation loss: 2.4546159871926574

Epoch: 5| Step: 3
Training loss: 1.9406381849249537
Validation loss: 2.457758233648433

Epoch: 5| Step: 4
Training loss: 2.79777043676015
Validation loss: 2.4482246793364237

Epoch: 5| Step: 5
Training loss: 2.5525720452762313
Validation loss: 2.4610162329462013

Epoch: 5| Step: 6
Training loss: 2.7749415657833163
Validation loss: 2.4593368926975443

Epoch: 5| Step: 7
Training loss: 2.240230756522252
Validation loss: 2.4748533948159928

Epoch: 5| Step: 8
Training loss: 2.7772856329351434
Validation loss: 2.5003224154705737

Epoch: 5| Step: 9
Training loss: 2.6082624245004635
Validation loss: 2.50880225677023

Epoch: 5| Step: 10
Training loss: 2.8901645602989303
Validation loss: 2.511933366687888

Epoch: 157| Step: 0
Training loss: 2.694603160452718
Validation loss: 2.5065857864936008

Epoch: 5| Step: 1
Training loss: 2.6420646219313375
Validation loss: 2.488670171009495

Epoch: 5| Step: 2
Training loss: 2.2572263597008217
Validation loss: 2.5065597018364048

Epoch: 5| Step: 3
Training loss: 2.3905220757562007
Validation loss: 2.5305853512546883

Epoch: 5| Step: 4
Training loss: 3.180943046705149
Validation loss: 2.5625484561015353

Epoch: 5| Step: 5
Training loss: 2.88522477780027
Validation loss: 2.5201433485479448

Epoch: 5| Step: 6
Training loss: 3.2215765236684293
Validation loss: 2.5096414821267787

Epoch: 5| Step: 7
Training loss: 2.605820662082679
Validation loss: 2.503670913719927

Epoch: 5| Step: 8
Training loss: 2.673848365946717
Validation loss: 2.498402871881321

Epoch: 5| Step: 9
Training loss: 3.009043414425498
Validation loss: 2.5072253637609236

Epoch: 5| Step: 10
Training loss: 2.6500208799871134
Validation loss: 2.4971429978989095

Epoch: 158| Step: 0
Training loss: 2.9577677727897953
Validation loss: 2.4884068551434666

Epoch: 5| Step: 1
Training loss: 2.9824116425004554
Validation loss: 2.472072070741791

Epoch: 5| Step: 2
Training loss: 2.300918549098638
Validation loss: 2.4580330408921887

Epoch: 5| Step: 3
Training loss: 2.639516021986278
Validation loss: 2.460382487314142

Epoch: 5| Step: 4
Training loss: 2.8346818818802157
Validation loss: 2.492275162816788

Epoch: 5| Step: 5
Training loss: 2.6934592247173232
Validation loss: 2.5029359047259208

Epoch: 5| Step: 6
Training loss: 2.7426852999795877
Validation loss: 2.518931746998865

Epoch: 5| Step: 7
Training loss: 2.686531957115717
Validation loss: 2.556685403877472

Epoch: 5| Step: 8
Training loss: 2.8225602679242217
Validation loss: 2.5171051206027975

Epoch: 5| Step: 9
Training loss: 2.6301613882174735
Validation loss: 2.505670597234279

Epoch: 5| Step: 10
Training loss: 2.5351649021183253
Validation loss: 2.4999365275539396

Epoch: 159| Step: 0
Training loss: 2.764347449451509
Validation loss: 2.4591719912484353

Epoch: 5| Step: 1
Training loss: 2.193832387219427
Validation loss: 2.436111700610801

Epoch: 5| Step: 2
Training loss: 2.8534232143553764
Validation loss: 2.4325351514606552

Epoch: 5| Step: 3
Training loss: 3.090573462200235
Validation loss: 2.43029467255435

Epoch: 5| Step: 4
Training loss: 2.407430483090697
Validation loss: 2.4296112391496685

Epoch: 5| Step: 5
Training loss: 2.653755542607388
Validation loss: 2.4304307045539817

Epoch: 5| Step: 6
Training loss: 2.8970430623739483
Validation loss: 2.4391365941155545

Epoch: 5| Step: 7
Training loss: 2.342904307060153
Validation loss: 2.4509595027813953

Epoch: 5| Step: 8
Training loss: 2.849538089731229
Validation loss: 2.4508212655352595

Epoch: 5| Step: 9
Training loss: 2.3752735381964123
Validation loss: 2.44122536869837

Epoch: 5| Step: 10
Training loss: 2.860171347867144
Validation loss: 2.4409779971337944

Epoch: 160| Step: 0
Training loss: 2.8807880353984774
Validation loss: 2.4431236262674605

Epoch: 5| Step: 1
Training loss: 2.47409772513695
Validation loss: 2.4515019786313124

Epoch: 5| Step: 2
Training loss: 2.1504909620168284
Validation loss: 2.456440975385488

Epoch: 5| Step: 3
Training loss: 2.682849941981054
Validation loss: 2.454757698888052

Epoch: 5| Step: 4
Training loss: 2.47145280282752
Validation loss: 2.4311428189954283

Epoch: 5| Step: 5
Training loss: 3.1313696984961177
Validation loss: 2.434816619354874

Epoch: 5| Step: 6
Training loss: 2.893979657083863
Validation loss: 2.433022426572757

Epoch: 5| Step: 7
Training loss: 2.7007710344928566
Validation loss: 2.4204622750977327

Epoch: 5| Step: 8
Training loss: 2.8833381152986184
Validation loss: 2.426522682188177

Epoch: 5| Step: 9
Training loss: 1.6681269764951028
Validation loss: 2.4270421907994826

Epoch: 5| Step: 10
Training loss: 3.2758503399619925
Validation loss: 2.431596397369652

Epoch: 161| Step: 0
Training loss: 2.313552926036283
Validation loss: 2.426106499616443

Epoch: 5| Step: 1
Training loss: 3.051922026831834
Validation loss: 2.445571610483798

Epoch: 5| Step: 2
Training loss: 2.4857183699112335
Validation loss: 2.4617705123370146

Epoch: 5| Step: 3
Training loss: 3.2062571029138245
Validation loss: 2.4835148175656077

Epoch: 5| Step: 4
Training loss: 2.2520075425043724
Validation loss: 2.484334381797187

Epoch: 5| Step: 5
Training loss: 2.333042455889448
Validation loss: 2.4770586417346863

Epoch: 5| Step: 6
Training loss: 2.901662014850333
Validation loss: 2.468336175285453

Epoch: 5| Step: 7
Training loss: 2.5039931831206133
Validation loss: 2.4452174018589843

Epoch: 5| Step: 8
Training loss: 2.633769871546694
Validation loss: 2.4316616199277443

Epoch: 5| Step: 9
Training loss: 2.6322598655560006
Validation loss: 2.438368772632537

Epoch: 5| Step: 10
Training loss: 2.849669112689901
Validation loss: 2.438601800929743

Epoch: 162| Step: 0
Training loss: 2.8941702881481106
Validation loss: 2.4305696358299747

Epoch: 5| Step: 1
Training loss: 2.890279883325329
Validation loss: 2.4251428475153474

Epoch: 5| Step: 2
Training loss: 3.022305219888138
Validation loss: 2.4337175721904916

Epoch: 5| Step: 3
Training loss: 2.831044244763424
Validation loss: 2.4283628967731246

Epoch: 5| Step: 4
Training loss: 2.578672593656643
Validation loss: 2.4307265357386814

Epoch: 5| Step: 5
Training loss: 2.984969314596388
Validation loss: 2.4372985668265317

Epoch: 5| Step: 6
Training loss: 2.4472959231900915
Validation loss: 2.446032145141848

Epoch: 5| Step: 7
Training loss: 2.124791527788093
Validation loss: 2.4636756374743296

Epoch: 5| Step: 8
Training loss: 2.2753592951504578
Validation loss: 2.4773322729971663

Epoch: 5| Step: 9
Training loss: 2.600446582001308
Validation loss: 2.47556599546292

Epoch: 5| Step: 10
Training loss: 2.377611631706917
Validation loss: 2.454225738266851

Epoch: 163| Step: 0
Training loss: 2.124495502498586
Validation loss: 2.4462305933886235

Epoch: 5| Step: 1
Training loss: 3.0884982144074407
Validation loss: 2.4492547044893516

Epoch: 5| Step: 2
Training loss: 2.6988012761116544
Validation loss: 2.4448767000506426

Epoch: 5| Step: 3
Training loss: 2.550474653760091
Validation loss: 2.4448131009520693

Epoch: 5| Step: 4
Training loss: 2.798442806066342
Validation loss: 2.445514627486204

Epoch: 5| Step: 5
Training loss: 2.946347163673473
Validation loss: 2.4467748432644045

Epoch: 5| Step: 6
Training loss: 2.554664168411711
Validation loss: 2.456678271015017

Epoch: 5| Step: 7
Training loss: 2.7147757761836635
Validation loss: 2.4475736637370344

Epoch: 5| Step: 8
Training loss: 2.481844302861531
Validation loss: 2.447776498929196

Epoch: 5| Step: 9
Training loss: 2.6677952901323763
Validation loss: 2.455653164719188

Epoch: 5| Step: 10
Training loss: 2.312611139049655
Validation loss: 2.4558243497811856

Epoch: 164| Step: 0
Training loss: 2.414133607872637
Validation loss: 2.4577643961625806

Epoch: 5| Step: 1
Training loss: 2.9777272266000385
Validation loss: 2.4660872355329384

Epoch: 5| Step: 2
Training loss: 2.379978182716707
Validation loss: 2.446972823731879

Epoch: 5| Step: 3
Training loss: 2.308435631515389
Validation loss: 2.4422630584474403

Epoch: 5| Step: 4
Training loss: 3.0679748799316466
Validation loss: 2.444996692024357

Epoch: 5| Step: 5
Training loss: 2.40479561585606
Validation loss: 2.436465886719282

Epoch: 5| Step: 6
Training loss: 2.912233161981728
Validation loss: 2.4358959520680115

Epoch: 5| Step: 7
Training loss: 2.889202860944848
Validation loss: 2.432098530320841

Epoch: 5| Step: 8
Training loss: 2.7426293172053415
Validation loss: 2.4444786940161225

Epoch: 5| Step: 9
Training loss: 1.9854917612781458
Validation loss: 2.4485961417880495

Epoch: 5| Step: 10
Training loss: 2.752286394026769
Validation loss: 2.4595963289385265

Epoch: 165| Step: 0
Training loss: 3.116727943294019
Validation loss: 2.4661179464829814

Epoch: 5| Step: 1
Training loss: 2.792689852361109
Validation loss: 2.485933707074834

Epoch: 5| Step: 2
Training loss: 2.6406238262467343
Validation loss: 2.4827614144731722

Epoch: 5| Step: 3
Training loss: 1.7756705320509671
Validation loss: 2.471978870090475

Epoch: 5| Step: 4
Training loss: 2.6173764288734556
Validation loss: 2.460410516102611

Epoch: 5| Step: 5
Training loss: 2.3938063851431264
Validation loss: 2.4536401152833385

Epoch: 5| Step: 6
Training loss: 2.780644383018881
Validation loss: 2.4411963987012

Epoch: 5| Step: 7
Training loss: 2.4968164200768115
Validation loss: 2.45145642042127

Epoch: 5| Step: 8
Training loss: 2.877557860587313
Validation loss: 2.4411133665887004

Epoch: 5| Step: 9
Training loss: 2.914865991512152
Validation loss: 2.4601074266842216

Epoch: 5| Step: 10
Training loss: 2.3163872085998047
Validation loss: 2.4773695724617752

Epoch: 166| Step: 0
Training loss: 2.9670016310391314
Validation loss: 2.5227709352437135

Epoch: 5| Step: 1
Training loss: 3.044716407836761
Validation loss: 2.600959946278736

Epoch: 5| Step: 2
Training loss: 3.13258402840328
Validation loss: 2.6093514195575906

Epoch: 5| Step: 3
Training loss: 2.12205402141555
Validation loss: 2.5792924143971705

Epoch: 5| Step: 4
Training loss: 2.5121971137589716
Validation loss: 2.5477524159542924

Epoch: 5| Step: 5
Training loss: 2.5190733974132584
Validation loss: 2.5461779315601136

Epoch: 5| Step: 6
Training loss: 2.322729938568665
Validation loss: 2.5463650835486096

Epoch: 5| Step: 7
Training loss: 2.479306118246073
Validation loss: 2.5627139832767183

Epoch: 5| Step: 8
Training loss: 2.6559112332803863
Validation loss: 2.5524749562532008

Epoch: 5| Step: 9
Training loss: 2.973559850038787
Validation loss: 2.5491328173816417

Epoch: 5| Step: 10
Training loss: 2.603615806809871
Validation loss: 2.5392571194684734

Epoch: 167| Step: 0
Training loss: 2.6891122462067245
Validation loss: 2.5235474508974325

Epoch: 5| Step: 1
Training loss: 2.5938889799455955
Validation loss: 2.4963919003372466

Epoch: 5| Step: 2
Training loss: 2.3078241243373143
Validation loss: 2.503494828618548

Epoch: 5| Step: 3
Training loss: 2.900453755626073
Validation loss: 2.4974181225253465

Epoch: 5| Step: 4
Training loss: 2.9528076970221515
Validation loss: 2.5008822063799574

Epoch: 5| Step: 5
Training loss: 1.804908771904065
Validation loss: 2.505580733628505

Epoch: 5| Step: 6
Training loss: 2.687644511041353
Validation loss: 2.532015009464681

Epoch: 5| Step: 7
Training loss: 3.023897042454365
Validation loss: 2.5399902526788587

Epoch: 5| Step: 8
Training loss: 2.8627509527687045
Validation loss: 2.535715891037689

Epoch: 5| Step: 9
Training loss: 2.422466476570655
Validation loss: 2.5543969247413214

Epoch: 5| Step: 10
Training loss: 2.6435847201436355
Validation loss: 2.5901861494506315

Epoch: 168| Step: 0
Training loss: 2.425076835437566
Validation loss: 2.5959602029332602

Epoch: 5| Step: 1
Training loss: 2.59022503055687
Validation loss: 2.5366182553328747

Epoch: 5| Step: 2
Training loss: 2.3231466433235544
Validation loss: 2.533354728470218

Epoch: 5| Step: 3
Training loss: 3.056010162366577
Validation loss: 2.5120566451855892

Epoch: 5| Step: 4
Training loss: 2.6008352918616486
Validation loss: 2.50492127475403

Epoch: 5| Step: 5
Training loss: 2.7921108822378344
Validation loss: 2.504682875204656

Epoch: 5| Step: 6
Training loss: 1.7564464092728422
Validation loss: 2.502281131665057

Epoch: 5| Step: 7
Training loss: 3.0290264350792944
Validation loss: 2.5205983786607162

Epoch: 5| Step: 8
Training loss: 2.9994037353512715
Validation loss: 2.527955306681532

Epoch: 5| Step: 9
Training loss: 2.831355489150881
Validation loss: 2.5475184955553662

Epoch: 5| Step: 10
Training loss: 3.0261412367249045
Validation loss: 2.5604879111653025

Epoch: 169| Step: 0
Training loss: 2.6375531268079926
Validation loss: 2.5707623507966715

Epoch: 5| Step: 1
Training loss: 2.6112664956557436
Validation loss: 2.5494276257716413

Epoch: 5| Step: 2
Training loss: 2.217846861228164
Validation loss: 2.540363179924317

Epoch: 5| Step: 3
Training loss: 2.889168862282493
Validation loss: 2.5398817191256255

Epoch: 5| Step: 4
Training loss: 3.0639311891204475
Validation loss: 2.526836822632784

Epoch: 5| Step: 5
Training loss: 2.873296149854816
Validation loss: 2.5117099946615693

Epoch: 5| Step: 6
Training loss: 2.8797511772115603
Validation loss: 2.5265187141072785

Epoch: 5| Step: 7
Training loss: 2.119783506135596
Validation loss: 2.533697309203299

Epoch: 5| Step: 8
Training loss: 2.6164496904869243
Validation loss: 2.5387170750708425

Epoch: 5| Step: 9
Training loss: 2.4588802397404863
Validation loss: 2.548795267944002

Epoch: 5| Step: 10
Training loss: 2.6204106311927746
Validation loss: 2.541634548501422

Epoch: 170| Step: 0
Training loss: 2.5679566506384224
Validation loss: 2.53807513176427

Epoch: 5| Step: 1
Training loss: 2.775830249477366
Validation loss: 2.5642984478552986

Epoch: 5| Step: 2
Training loss: 1.7854788924790685
Validation loss: 2.5754965650139106

Epoch: 5| Step: 3
Training loss: 2.7270988221065013
Validation loss: 2.570960532593495

Epoch: 5| Step: 4
Training loss: 2.202573666677488
Validation loss: 2.601919918087734

Epoch: 5| Step: 5
Training loss: 2.4234040386514177
Validation loss: 2.610262269904615

Epoch: 5| Step: 6
Training loss: 2.8379581703291694
Validation loss: 2.6066938555700805

Epoch: 5| Step: 7
Training loss: 2.6161340215923774
Validation loss: 2.609717079608433

Epoch: 5| Step: 8
Training loss: 2.9523383813563417
Validation loss: 2.6008067862772872

Epoch: 5| Step: 9
Training loss: 3.1469406469594943
Validation loss: 2.584067182544352

Epoch: 5| Step: 10
Training loss: 2.6519870433922397
Validation loss: 2.5820981809880124

Epoch: 171| Step: 0
Training loss: 2.3832726206304695
Validation loss: 2.5443382773585084

Epoch: 5| Step: 1
Training loss: 2.025056522663728
Validation loss: 2.5385661281298684

Epoch: 5| Step: 2
Training loss: 2.3397860766707965
Validation loss: 2.524868115814954

Epoch: 5| Step: 3
Training loss: 2.635278107590488
Validation loss: 2.51844494565556

Epoch: 5| Step: 4
Training loss: 2.7353229732306388
Validation loss: 2.522783561501112

Epoch: 5| Step: 5
Training loss: 2.433470109030602
Validation loss: 2.513397122995622

Epoch: 5| Step: 6
Training loss: 2.737084838879162
Validation loss: 2.5459052677611167

Epoch: 5| Step: 7
Training loss: 2.8524614981109853
Validation loss: 2.5603150167123774

Epoch: 5| Step: 8
Training loss: 2.831415948783296
Validation loss: 2.560018234540489

Epoch: 5| Step: 9
Training loss: 2.683115643107984
Validation loss: 2.5490199381049905

Epoch: 5| Step: 10
Training loss: 2.902324034673953
Validation loss: 2.5264914207498643

Epoch: 172| Step: 0
Training loss: 2.4839844786609016
Validation loss: 2.4918047278985047

Epoch: 5| Step: 1
Training loss: 2.1632445404255405
Validation loss: 2.4791725643257054

Epoch: 5| Step: 2
Training loss: 2.671677253053299
Validation loss: 2.4793192574445757

Epoch: 5| Step: 3
Training loss: 2.205712064266145
Validation loss: 2.468170015851203

Epoch: 5| Step: 4
Training loss: 3.1256264630859465
Validation loss: 2.4649648146999117

Epoch: 5| Step: 5
Training loss: 2.0087273439412736
Validation loss: 2.471487084352805

Epoch: 5| Step: 6
Training loss: 2.705956712296189
Validation loss: 2.472601156109065

Epoch: 5| Step: 7
Training loss: 2.912128532853231
Validation loss: 2.505003837497526

Epoch: 5| Step: 8
Training loss: 2.7349927803795073
Validation loss: 2.5370718241087102

Epoch: 5| Step: 9
Training loss: 2.9957782922462646
Validation loss: 2.5500019123344484

Epoch: 5| Step: 10
Training loss: 2.266686657742624
Validation loss: 2.5531228190933493

Epoch: 173| Step: 0
Training loss: 2.9817023168074117
Validation loss: 2.5252085093306897

Epoch: 5| Step: 1
Training loss: 2.495845489811998
Validation loss: 2.5443205306774215

Epoch: 5| Step: 2
Training loss: 2.6311705588628533
Validation loss: 2.556232170176986

Epoch: 5| Step: 3
Training loss: 2.5020657587717916
Validation loss: 2.528295218648962

Epoch: 5| Step: 4
Training loss: 2.479036268977623
Validation loss: 2.517080173641152

Epoch: 5| Step: 5
Training loss: 2.8686981794875384
Validation loss: 2.511851970681541

Epoch: 5| Step: 6
Training loss: 2.690688083099687
Validation loss: 2.5105020798477065

Epoch: 5| Step: 7
Training loss: 2.282824560782383
Validation loss: 2.516922692657916

Epoch: 5| Step: 8
Training loss: 2.1873494777663036
Validation loss: 2.5510575410050214

Epoch: 5| Step: 9
Training loss: 2.457574296140612
Validation loss: 2.5651147249507447

Epoch: 5| Step: 10
Training loss: 2.218309922967744
Validation loss: 2.578520795235574

Epoch: 174| Step: 0
Training loss: 2.5624020255362763
Validation loss: 2.5712574615841652

Epoch: 5| Step: 1
Training loss: 2.7429693688696433
Validation loss: 2.5980724380348637

Epoch: 5| Step: 2
Training loss: 2.1683561511626523
Validation loss: 2.5698199131316737

Epoch: 5| Step: 3
Training loss: 2.4768202012820306
Validation loss: 2.5226308816764127

Epoch: 5| Step: 4
Training loss: 2.5111729813533463
Validation loss: 2.5006551837696485

Epoch: 5| Step: 5
Training loss: 2.2595140849630666
Validation loss: 2.4878817926479737

Epoch: 5| Step: 6
Training loss: 2.5878453894926206
Validation loss: 2.4968788763089047

Epoch: 5| Step: 7
Training loss: 3.1450854458747264
Validation loss: 2.508074968309177

Epoch: 5| Step: 8
Training loss: 2.6520819780616463
Validation loss: 2.5343393918220536

Epoch: 5| Step: 9
Training loss: 2.8288392908936366
Validation loss: 2.561407927503108

Epoch: 5| Step: 10
Training loss: 2.215814179386345
Validation loss: 2.529186750858891

Epoch: 175| Step: 0
Training loss: 2.512200720123875
Validation loss: 2.490833446580479

Epoch: 5| Step: 1
Training loss: 2.9630645922168024
Validation loss: 2.4609145828015992

Epoch: 5| Step: 2
Training loss: 2.453742077232159
Validation loss: 2.4627057269144297

Epoch: 5| Step: 3
Training loss: 1.9808154282371155
Validation loss: 2.4554635579584345

Epoch: 5| Step: 4
Training loss: 2.911314294808573
Validation loss: 2.464706511465306

Epoch: 5| Step: 5
Training loss: 2.5254594479274894
Validation loss: 2.4792811518192375

Epoch: 5| Step: 6
Training loss: 2.384656249091379
Validation loss: 2.503839763973016

Epoch: 5| Step: 7
Training loss: 2.4399244526596062
Validation loss: 2.511912925314763

Epoch: 5| Step: 8
Training loss: 2.6266791105056306
Validation loss: 2.521934835757925

Epoch: 5| Step: 9
Training loss: 2.6363280960605273
Validation loss: 2.550031338715692

Epoch: 5| Step: 10
Training loss: 2.186912893799366
Validation loss: 2.5998190999105075

Epoch: 176| Step: 0
Training loss: 2.3091094446359897
Validation loss: 2.6183394131510536

Epoch: 5| Step: 1
Training loss: 2.6229629787227733
Validation loss: 2.6307482824433532

Epoch: 5| Step: 2
Training loss: 2.076456418280683
Validation loss: 2.592499863751372

Epoch: 5| Step: 3
Training loss: 2.010624678792267
Validation loss: 2.562309646239271

Epoch: 5| Step: 4
Training loss: 2.6692315125089103
Validation loss: 2.5238662213814296

Epoch: 5| Step: 5
Training loss: 2.5541579137987154
Validation loss: 2.4817186961363715

Epoch: 5| Step: 6
Training loss: 2.814766881582958
Validation loss: 2.493829483096636

Epoch: 5| Step: 7
Training loss: 2.182067446847217
Validation loss: 2.4553288825691006

Epoch: 5| Step: 8
Training loss: 2.5926954584554296
Validation loss: 2.468147199046128

Epoch: 5| Step: 9
Training loss: 2.8838373445628
Validation loss: 2.512042708726912

Epoch: 5| Step: 10
Training loss: 2.912557341047997
Validation loss: 2.5214899435628655

Epoch: 177| Step: 0
Training loss: 1.9556788722926834
Validation loss: 2.544843406853591

Epoch: 5| Step: 1
Training loss: 2.8277363378373317
Validation loss: 2.5697621990932062

Epoch: 5| Step: 2
Training loss: 2.319728482406116
Validation loss: 2.5489351069006614

Epoch: 5| Step: 3
Training loss: 2.8705032675637625
Validation loss: 2.5429124816634374

Epoch: 5| Step: 4
Training loss: 2.3658597640706205
Validation loss: 2.520511227962304

Epoch: 5| Step: 5
Training loss: 2.290175027613499
Validation loss: 2.517495309668296

Epoch: 5| Step: 6
Training loss: 2.6629537921009345
Validation loss: 2.5241003755469276

Epoch: 5| Step: 7
Training loss: 2.7219853060211525
Validation loss: 2.543033162580876

Epoch: 5| Step: 8
Training loss: 2.4255270709601344
Validation loss: 2.5650401397521487

Epoch: 5| Step: 9
Training loss: 2.0852992763754563
Validation loss: 2.5486044951307365

Epoch: 5| Step: 10
Training loss: 2.9626905742141885
Validation loss: 2.5589082899199966

Epoch: 178| Step: 0
Training loss: 2.9024009236882096
Validation loss: 2.5240271409688484

Epoch: 5| Step: 1
Training loss: 2.3539252593459534
Validation loss: 2.4837239886105005

Epoch: 5| Step: 2
Training loss: 2.7339197270260187
Validation loss: 2.466266034061286

Epoch: 5| Step: 3
Training loss: 1.6905326437270698
Validation loss: 2.4347090981126325

Epoch: 5| Step: 4
Training loss: 2.924008493204998
Validation loss: 2.4268985575673834

Epoch: 5| Step: 5
Training loss: 2.0809066626731063
Validation loss: 2.430716997714048

Epoch: 5| Step: 6
Training loss: 2.9668376987604383
Validation loss: 2.4169896355171443

Epoch: 5| Step: 7
Training loss: 2.9233185980964445
Validation loss: 2.4320864162090925

Epoch: 5| Step: 8
Training loss: 2.545756650311931
Validation loss: 2.470442383290109

Epoch: 5| Step: 9
Training loss: 2.092745183984503
Validation loss: 2.5020821371028927

Epoch: 5| Step: 10
Training loss: 2.127851928578691
Validation loss: 2.4934963847710994

Epoch: 179| Step: 0
Training loss: 2.4225647959197474
Validation loss: 2.479184838718965

Epoch: 5| Step: 1
Training loss: 2.8285495165461945
Validation loss: 2.442029860921405

Epoch: 5| Step: 2
Training loss: 2.094102858231484
Validation loss: 2.4298519557235165

Epoch: 5| Step: 3
Training loss: 2.8124636329842794
Validation loss: 2.44528131544713

Epoch: 5| Step: 4
Training loss: 2.5811261828562686
Validation loss: 2.4633330197590593

Epoch: 5| Step: 5
Training loss: 2.8611128065316156
Validation loss: 2.5072377012285676

Epoch: 5| Step: 6
Training loss: 2.4768042220794317
Validation loss: 2.4972135509871043

Epoch: 5| Step: 7
Training loss: 2.6394181964364667
Validation loss: 2.5332394419251916

Epoch: 5| Step: 8
Training loss: 2.1255037047345584
Validation loss: 2.5763319704443637

Epoch: 5| Step: 9
Training loss: 2.1746165584324277
Validation loss: 2.6033302230467648

Epoch: 5| Step: 10
Training loss: 2.40204788495056
Validation loss: 2.6115145283466354

Epoch: 180| Step: 0
Training loss: 2.203032363134409
Validation loss: 2.606436647168932

Epoch: 5| Step: 1
Training loss: 1.9061667627390884
Validation loss: 2.5701477893675384

Epoch: 5| Step: 2
Training loss: 2.6115428576632835
Validation loss: 2.550776545397094

Epoch: 5| Step: 3
Training loss: 2.5879650637879017
Validation loss: 2.5043840587066244

Epoch: 5| Step: 4
Training loss: 2.208504568214865
Validation loss: 2.4845550599814668

Epoch: 5| Step: 5
Training loss: 2.8571448462343105
Validation loss: 2.4930529196840823

Epoch: 5| Step: 6
Training loss: 2.130285757534055
Validation loss: 2.482361477844825

Epoch: 5| Step: 7
Training loss: 2.2409011394001612
Validation loss: 2.449855553071184

Epoch: 5| Step: 8
Training loss: 2.6251714741240595
Validation loss: 2.4550799737900606

Epoch: 5| Step: 9
Training loss: 2.7408250863993198
Validation loss: 2.4319564512101532

Epoch: 5| Step: 10
Training loss: 2.582055996359289
Validation loss: 2.41831230028857

Epoch: 181| Step: 0
Training loss: 2.4394284957974066
Validation loss: 2.427538235558207

Epoch: 5| Step: 1
Training loss: 2.476463628774866
Validation loss: 2.4330022183800266

Epoch: 5| Step: 2
Training loss: 2.8184969228064856
Validation loss: 2.441502328208613

Epoch: 5| Step: 3
Training loss: 2.329480589409744
Validation loss: 2.46149684098621

Epoch: 5| Step: 4
Training loss: 2.4443410095332916
Validation loss: 2.4568996228873954

Epoch: 5| Step: 5
Training loss: 2.474739920312285
Validation loss: 2.483752643719156

Epoch: 5| Step: 6
Training loss: 2.3794752420803498
Validation loss: 2.531208530715784

Epoch: 5| Step: 7
Training loss: 2.251378802523283
Validation loss: 2.560602822906546

Epoch: 5| Step: 8
Training loss: 2.484548502687567
Validation loss: 2.6035248239033124

Epoch: 5| Step: 9
Training loss: 2.4102120416202575
Validation loss: 2.5762450234023557

Epoch: 5| Step: 10
Training loss: 2.5429790631391294
Validation loss: 2.5337740994635767

Epoch: 182| Step: 0
Training loss: 1.8340642584647509
Validation loss: 2.519553863991165

Epoch: 5| Step: 1
Training loss: 1.9754441305151773
Validation loss: 2.469210682310456

Epoch: 5| Step: 2
Training loss: 2.7533571385731523
Validation loss: 2.446571357094283

Epoch: 5| Step: 3
Training loss: 2.721306136344737
Validation loss: 2.4334627819845878

Epoch: 5| Step: 4
Training loss: 2.28081633743943
Validation loss: 2.4086197529449342

Epoch: 5| Step: 5
Training loss: 2.566340847720678
Validation loss: 2.417663845501891

Epoch: 5| Step: 6
Training loss: 2.2492279211548327
Validation loss: 2.4297744159856136

Epoch: 5| Step: 7
Training loss: 2.9120065426595776
Validation loss: 2.437741156449963

Epoch: 5| Step: 8
Training loss: 2.633772044114465
Validation loss: 2.4557281877961623

Epoch: 5| Step: 9
Training loss: 2.6580947752991535
Validation loss: 2.4680067682728373

Epoch: 5| Step: 10
Training loss: 2.0093853797466528
Validation loss: 2.4870372053960437

Epoch: 183| Step: 0
Training loss: 2.5391816566090757
Validation loss: 2.4908074738247263

Epoch: 5| Step: 1
Training loss: 2.26199017676557
Validation loss: 2.465694144217421

Epoch: 5| Step: 2
Training loss: 2.8302056683324333
Validation loss: 2.488609081804231

Epoch: 5| Step: 3
Training loss: 2.6306882716260214
Validation loss: 2.46589305093397

Epoch: 5| Step: 4
Training loss: 2.3284543207728556
Validation loss: 2.431111448466011

Epoch: 5| Step: 5
Training loss: 2.25552769984608
Validation loss: 2.4242796562629785

Epoch: 5| Step: 6
Training loss: 2.684746329544731
Validation loss: 2.4398355519471435

Epoch: 5| Step: 7
Training loss: 2.0206160149933505
Validation loss: 2.4543497677841897

Epoch: 5| Step: 8
Training loss: 2.523177567549306
Validation loss: 2.426193236402303

Epoch: 5| Step: 9
Training loss: 2.158564224068844
Validation loss: 2.423902536053699

Epoch: 5| Step: 10
Training loss: 2.2481399901301002
Validation loss: 2.4136865003576484

Epoch: 184| Step: 0
Training loss: 2.2942395303750645
Validation loss: 2.422324044168902

Epoch: 5| Step: 1
Training loss: 2.3382731214816013
Validation loss: 2.4293109100894945

Epoch: 5| Step: 2
Training loss: 1.9549850761839096
Validation loss: 2.4264446197821443

Epoch: 5| Step: 3
Training loss: 1.8893748161676729
Validation loss: 2.4310446831153465

Epoch: 5| Step: 4
Training loss: 2.375907925179994
Validation loss: 2.4482775730849586

Epoch: 5| Step: 5
Training loss: 2.0967462082266053
Validation loss: 2.4481534788793766

Epoch: 5| Step: 6
Training loss: 2.366601449667819
Validation loss: 2.4557490060223435

Epoch: 5| Step: 7
Training loss: 2.954466177136862
Validation loss: 2.4539499749972147

Epoch: 5| Step: 8
Training loss: 2.3439027863611623
Validation loss: 2.436559933901127

Epoch: 5| Step: 9
Training loss: 2.7893841555319283
Validation loss: 2.417549545578347

Epoch: 5| Step: 10
Training loss: 2.863993599037391
Validation loss: 2.429629304561712

Epoch: 185| Step: 0
Training loss: 2.280657965771268
Validation loss: 2.4786525054241193

Epoch: 5| Step: 1
Training loss: 2.8281325872330028
Validation loss: 2.5007132835504122

Epoch: 5| Step: 2
Training loss: 2.0730837142830922
Validation loss: 2.512514827502692

Epoch: 5| Step: 3
Training loss: 2.0829449736697754
Validation loss: 2.4808354846986997

Epoch: 5| Step: 4
Training loss: 2.7751823846490535
Validation loss: 2.4550903329406952

Epoch: 5| Step: 5
Training loss: 2.068665392663932
Validation loss: 2.4190755796429744

Epoch: 5| Step: 6
Training loss: 1.631361394126157
Validation loss: 2.4199929272331278

Epoch: 5| Step: 7
Training loss: 2.8933099597508316
Validation loss: 2.4170494303342145

Epoch: 5| Step: 8
Training loss: 2.758215510069471
Validation loss: 2.4115761678252072

Epoch: 5| Step: 9
Training loss: 2.6252119796175024
Validation loss: 2.434265708668368

Epoch: 5| Step: 10
Training loss: 1.9412740435956632
Validation loss: 2.4676018949361618

Epoch: 186| Step: 0
Training loss: 2.1536961787534463
Validation loss: 2.4974829071874747

Epoch: 5| Step: 1
Training loss: 2.345390051182852
Validation loss: 2.5331950440439477

Epoch: 5| Step: 2
Training loss: 2.7164371342805436
Validation loss: 2.534317604712748

Epoch: 5| Step: 3
Training loss: 2.331795889832208
Validation loss: 2.5203718798522403

Epoch: 5| Step: 4
Training loss: 2.5834562723583585
Validation loss: 2.4978347199859896

Epoch: 5| Step: 5
Training loss: 2.082589194596113
Validation loss: 2.4892003423876514

Epoch: 5| Step: 6
Training loss: 2.159844760614432
Validation loss: 2.483661693934982

Epoch: 5| Step: 7
Training loss: 2.5623624811256067
Validation loss: 2.471055892305706

Epoch: 5| Step: 8
Training loss: 1.3505771109843538
Validation loss: 2.4601826494698904

Epoch: 5| Step: 9
Training loss: 2.669227850343076
Validation loss: 2.4350466986093484

Epoch: 5| Step: 10
Training loss: 2.829151114944015
Validation loss: 2.435551095895991

Epoch: 187| Step: 0
Training loss: 2.2459353714541797
Validation loss: 2.428735932939731

Epoch: 5| Step: 1
Training loss: 2.4847578797311884
Validation loss: 2.4291511447202114

Epoch: 5| Step: 2
Training loss: 2.4608053504945206
Validation loss: 2.442138314303104

Epoch: 5| Step: 3
Training loss: 2.3924779754230805
Validation loss: 2.4303747146374155

Epoch: 5| Step: 4
Training loss: 2.6207402498325325
Validation loss: 2.4363109632351456

Epoch: 5| Step: 5
Training loss: 2.1193384034291247
Validation loss: 2.4337325597005735

Epoch: 5| Step: 6
Training loss: 1.8689663127110414
Validation loss: 2.4527586916949344

Epoch: 5| Step: 7
Training loss: 2.039230865893821
Validation loss: 2.4749528876467615

Epoch: 5| Step: 8
Training loss: 1.6361793230032322
Validation loss: 2.504786865633058

Epoch: 5| Step: 9
Training loss: 2.8342444880844884
Validation loss: 2.5322200709462552

Epoch: 5| Step: 10
Training loss: 2.9053323589088142
Validation loss: 2.523243620237004

Epoch: 188| Step: 0
Training loss: 2.1222144550605204
Validation loss: 2.5597255242330017

Epoch: 5| Step: 1
Training loss: 2.3092044338890125
Validation loss: 2.5590264613346387

Epoch: 5| Step: 2
Training loss: 2.0270946548109166
Validation loss: 2.5110583762759107

Epoch: 5| Step: 3
Training loss: 2.4419603863314134
Validation loss: 2.508218557514339

Epoch: 5| Step: 4
Training loss: 2.3391328218804586
Validation loss: 2.4983753072883284

Epoch: 5| Step: 5
Training loss: 2.2759737634604775
Validation loss: 2.527940553274817

Epoch: 5| Step: 6
Training loss: 2.61741049656326
Validation loss: 2.5391632812288534

Epoch: 5| Step: 7
Training loss: 2.5146313713013115
Validation loss: 2.510256317971953

Epoch: 5| Step: 8
Training loss: 1.9615633144501554
Validation loss: 2.4738923412560534

Epoch: 5| Step: 9
Training loss: 2.2494057824354314
Validation loss: 2.454622767533088

Epoch: 5| Step: 10
Training loss: 2.7290045614850933
Validation loss: 2.417222356575104

Epoch: 189| Step: 0
Training loss: 2.8180902660578755
Validation loss: 2.4307381577661005

Epoch: 5| Step: 1
Training loss: 2.5348535953658082
Validation loss: 2.4227014270186644

Epoch: 5| Step: 2
Training loss: 1.9597829634333053
Validation loss: 2.425241960041681

Epoch: 5| Step: 3
Training loss: 2.1223770109562867
Validation loss: 2.4188882438325097

Epoch: 5| Step: 4
Training loss: 1.8633625004805214
Validation loss: 2.4378625207340234

Epoch: 5| Step: 5
Training loss: 2.5865840967836107
Validation loss: 2.460806805873715

Epoch: 5| Step: 6
Training loss: 2.5257132929619366
Validation loss: 2.4953095376021674

Epoch: 5| Step: 7
Training loss: 2.112921326284274
Validation loss: 2.5046255451049353

Epoch: 5| Step: 8
Training loss: 2.035609804306961
Validation loss: 2.475544120861115

Epoch: 5| Step: 9
Training loss: 2.082181484964297
Validation loss: 2.4573923781330858

Epoch: 5| Step: 10
Training loss: 2.405035034210019
Validation loss: 2.4692422945300865

Epoch: 190| Step: 0
Training loss: 2.0337347238971604
Validation loss: 2.4878049661768373

Epoch: 5| Step: 1
Training loss: 1.598954696733976
Validation loss: 2.4953704925668716

Epoch: 5| Step: 2
Training loss: 2.7291290532983017
Validation loss: 2.522884544897729

Epoch: 5| Step: 3
Training loss: 2.528877842189407
Validation loss: 2.5479394180837875

Epoch: 5| Step: 4
Training loss: 2.461724630752556
Validation loss: 2.5142746173937445

Epoch: 5| Step: 5
Training loss: 2.45341256758339
Validation loss: 2.4999863613946167

Epoch: 5| Step: 6
Training loss: 2.374196970853238
Validation loss: 2.5000621982753737

Epoch: 5| Step: 7
Training loss: 2.1551825050906994
Validation loss: 2.4612778128346355

Epoch: 5| Step: 8
Training loss: 1.7286480351827018
Validation loss: 2.460779130602223

Epoch: 5| Step: 9
Training loss: 2.6928673309272213
Validation loss: 2.4865010521868327

Epoch: 5| Step: 10
Training loss: 2.311915349512821
Validation loss: 2.4629547554998403

Epoch: 191| Step: 0
Training loss: 1.664211499344594
Validation loss: 2.4945252102152873

Epoch: 5| Step: 1
Training loss: 2.3403740538261206
Validation loss: 2.5137280136012286

Epoch: 5| Step: 2
Training loss: 2.6058201131148833
Validation loss: 2.4997231012222167

Epoch: 5| Step: 3
Training loss: 2.5663192943316666
Validation loss: 2.4940451519587805

Epoch: 5| Step: 4
Training loss: 1.7837875093874973
Validation loss: 2.4064300846876154

Epoch: 5| Step: 5
Training loss: 2.024813504520448
Validation loss: 2.378171911867464

Epoch: 5| Step: 6
Training loss: 2.5819117623756718
Validation loss: 2.3861128167454826

Epoch: 5| Step: 7
Training loss: 1.9107751136336248
Validation loss: 2.3950040922152005

Epoch: 5| Step: 8
Training loss: 2.752411045504564
Validation loss: 2.408603263809768

Epoch: 5| Step: 9
Training loss: 2.758774111546877
Validation loss: 2.4138472967203324

Epoch: 5| Step: 10
Training loss: 2.61585395202904
Validation loss: 2.414490297577056

Epoch: 192| Step: 0
Training loss: 1.8217758387281038
Validation loss: 2.429200042445793

Epoch: 5| Step: 1
Training loss: 1.8502408876043914
Validation loss: 2.4588630325286793

Epoch: 5| Step: 2
Training loss: 2.3814969793280922
Validation loss: 2.515206447566463

Epoch: 5| Step: 3
Training loss: 2.1949579896143514
Validation loss: 2.6053497094897637

Epoch: 5| Step: 4
Training loss: 2.6320486347261833
Validation loss: 2.6333788541372143

Epoch: 5| Step: 5
Training loss: 2.1916287287146945
Validation loss: 2.6022592744894486

Epoch: 5| Step: 6
Training loss: 2.075702143989827
Validation loss: 2.560298315993389

Epoch: 5| Step: 7
Training loss: 2.1396291602209536
Validation loss: 2.5073741577925253

Epoch: 5| Step: 8
Training loss: 2.3792301452327758
Validation loss: 2.4320389126028945

Epoch: 5| Step: 9
Training loss: 2.7560685562997023
Validation loss: 2.4314609103214764

Epoch: 5| Step: 10
Training loss: 2.7236592485383406
Validation loss: 2.4272679880066272

Epoch: 193| Step: 0
Training loss: 2.3764991044537
Validation loss: 2.409891906187722

Epoch: 5| Step: 1
Training loss: 2.221164195861992
Validation loss: 2.4306376134456102

Epoch: 5| Step: 2
Training loss: 2.583487834207053
Validation loss: 2.452513380834208

Epoch: 5| Step: 3
Training loss: 2.2934614493750023
Validation loss: 2.4558911888906403

Epoch: 5| Step: 4
Training loss: 2.694240367890947
Validation loss: 2.4395550840585134

Epoch: 5| Step: 5
Training loss: 2.315203452511199
Validation loss: 2.456637854400544

Epoch: 5| Step: 6
Training loss: 2.151412845634431
Validation loss: 2.4715806064251042

Epoch: 5| Step: 7
Training loss: 2.406597161949283
Validation loss: 2.4713912392795785

Epoch: 5| Step: 8
Training loss: 2.331306383202787
Validation loss: 2.3986922271761255

Epoch: 5| Step: 9
Training loss: 2.240613431381942
Validation loss: 2.384138115461246

Epoch: 5| Step: 10
Training loss: 1.9247486990842375
Validation loss: 2.375946237461865

Epoch: 194| Step: 0
Training loss: 2.669282692983689
Validation loss: 2.401823690611499

Epoch: 5| Step: 1
Training loss: 2.1767099477058607
Validation loss: 2.421200669825794

Epoch: 5| Step: 2
Training loss: 2.037905309886352
Validation loss: 2.437808272622767

Epoch: 5| Step: 3
Training loss: 2.0458715177599487
Validation loss: 2.4702827448448477

Epoch: 5| Step: 4
Training loss: 1.6603623206204374
Validation loss: 2.505911030735394

Epoch: 5| Step: 5
Training loss: 2.4982326936545136
Validation loss: 2.5395949741379957

Epoch: 5| Step: 6
Training loss: 1.8881005702226634
Validation loss: 2.564029616240347

Epoch: 5| Step: 7
Training loss: 2.166357923175705
Validation loss: 2.615892410462935

Epoch: 5| Step: 8
Training loss: 2.696641411947938
Validation loss: 2.6536561610565226

Epoch: 5| Step: 9
Training loss: 2.342673906610744
Validation loss: 2.599693610760079

Epoch: 5| Step: 10
Training loss: 2.6943449633434358
Validation loss: 2.5833306016487447

Epoch: 195| Step: 0
Training loss: 2.4842491837797986
Validation loss: 2.5288530073098308

Epoch: 5| Step: 1
Training loss: 2.2659825536152245
Validation loss: 2.4814397584193153

Epoch: 5| Step: 2
Training loss: 2.264386173802982
Validation loss: 2.4575728816166618

Epoch: 5| Step: 3
Training loss: 2.3973826719977085
Validation loss: 2.451438994822602

Epoch: 5| Step: 4
Training loss: 2.059167423698423
Validation loss: 2.4506767805429783

Epoch: 5| Step: 5
Training loss: 2.4133467616274937
Validation loss: 2.456395038087397

Epoch: 5| Step: 6
Training loss: 2.2165086197499395
Validation loss: 2.432000950582515

Epoch: 5| Step: 7
Training loss: 2.400129187603763
Validation loss: 2.4306373444921494

Epoch: 5| Step: 8
Training loss: 2.435486083813049
Validation loss: 2.424152722952823

Epoch: 5| Step: 9
Training loss: 1.4953644969673057
Validation loss: 2.4194092910887255

Epoch: 5| Step: 10
Training loss: 2.1673345514530893
Validation loss: 2.4467969457292456

Epoch: 196| Step: 0
Training loss: 1.8953981913215916
Validation loss: 2.488397371308943

Epoch: 5| Step: 1
Training loss: 2.497245033545639
Validation loss: 2.5161400763648167

Epoch: 5| Step: 2
Training loss: 1.9533797441291771
Validation loss: 2.536448017264551

Epoch: 5| Step: 3
Training loss: 2.3439643253241575
Validation loss: 2.557324487071088

Epoch: 5| Step: 4
Training loss: 2.1410372817362773
Validation loss: 2.5731893080031565

Epoch: 5| Step: 5
Training loss: 2.31995396782162
Validation loss: 2.560855054382577

Epoch: 5| Step: 6
Training loss: 2.48613997809086
Validation loss: 2.5330665164385167

Epoch: 5| Step: 7
Training loss: 2.3337389956655685
Validation loss: 2.5250969159803307

Epoch: 5| Step: 8
Training loss: 1.9802759441597275
Validation loss: 2.48009232453819

Epoch: 5| Step: 9
Training loss: 2.393734275029178
Validation loss: 2.454966094391048

Epoch: 5| Step: 10
Training loss: 2.0836950242468415
Validation loss: 2.4265327707621345

Epoch: 197| Step: 0
Training loss: 1.7628204216768113
Validation loss: 2.4478381526367166

Epoch: 5| Step: 1
Training loss: 2.3522759556067574
Validation loss: 2.486997859923022

Epoch: 5| Step: 2
Training loss: 2.248837594599927
Validation loss: 2.518618630243647

Epoch: 5| Step: 3
Training loss: 2.910427905210961
Validation loss: 2.4798979190481236

Epoch: 5| Step: 4
Training loss: 2.2409228436840958
Validation loss: 2.434208663217142

Epoch: 5| Step: 5
Training loss: 2.417673022006721
Validation loss: 2.4219905956678445

Epoch: 5| Step: 6
Training loss: 2.324423593421925
Validation loss: 2.4248655762546782

Epoch: 5| Step: 7
Training loss: 2.310814629951482
Validation loss: 2.430735244222543

Epoch: 5| Step: 8
Training loss: 2.071304371591527
Validation loss: 2.439497372551678

Epoch: 5| Step: 9
Training loss: 1.8376842873471952
Validation loss: 2.4538693364418096

Epoch: 5| Step: 10
Training loss: 1.7766358024082494
Validation loss: 2.456995780760935

Epoch: 198| Step: 0
Training loss: 1.65820564117061
Validation loss: 2.4798796677960757

Epoch: 5| Step: 1
Training loss: 2.0280151431479507
Validation loss: 2.5014936363942404

Epoch: 5| Step: 2
Training loss: 2.428754228636339
Validation loss: 2.495655114287191

Epoch: 5| Step: 3
Training loss: 2.528851726935316
Validation loss: 2.506225409837321

Epoch: 5| Step: 4
Training loss: 2.4209152781218912
Validation loss: 2.4815775757046614

Epoch: 5| Step: 5
Training loss: 2.2317026870513765
Validation loss: 2.531062782744328

Epoch: 5| Step: 6
Training loss: 1.8609502835158964
Validation loss: 2.55892066172785

Epoch: 5| Step: 7
Training loss: 2.101998663243995
Validation loss: 2.5736859231829388

Epoch: 5| Step: 8
Training loss: 2.3681423162661344
Validation loss: 2.5738642143727004

Epoch: 5| Step: 9
Training loss: 2.489897150880022
Validation loss: 2.5016647128701828

Epoch: 5| Step: 10
Training loss: 1.9736824614533823
Validation loss: 2.4390172703406705

Epoch: 199| Step: 0
Training loss: 1.697890330229349
Validation loss: 2.409321172665271

Epoch: 5| Step: 1
Training loss: 2.6436906884576707
Validation loss: 2.3891787201342125

Epoch: 5| Step: 2
Training loss: 1.9442923448505018
Validation loss: 2.4372140229153505

Epoch: 5| Step: 3
Training loss: 2.1021491724395958
Validation loss: 2.471785176344483

Epoch: 5| Step: 4
Training loss: 1.1207245009289402
Validation loss: 2.4589475910959013

Epoch: 5| Step: 5
Training loss: 2.3101805318330957
Validation loss: 2.4647182275780968

Epoch: 5| Step: 6
Training loss: 2.5823606895546236
Validation loss: 2.459484837687357

Epoch: 5| Step: 7
Training loss: 2.2408768814222864
Validation loss: 2.4212524481915527

Epoch: 5| Step: 8
Training loss: 1.9348380352713102
Validation loss: 2.4291583539065287

Epoch: 5| Step: 9
Training loss: 2.610230813763995
Validation loss: 2.4463932962169244

Epoch: 5| Step: 10
Training loss: 2.4454355422194025
Validation loss: 2.473759648495038

Epoch: 200| Step: 0
Training loss: 2.1703372698497074
Validation loss: 2.516669835297333

Epoch: 5| Step: 1
Training loss: 1.7953853237166293
Validation loss: 2.533320910736912

Epoch: 5| Step: 2
Training loss: 2.16722168293833
Validation loss: 2.549266122297486

Epoch: 5| Step: 3
Training loss: 1.8487804130234677
Validation loss: 2.532688399105729

Epoch: 5| Step: 4
Training loss: 2.2710118938085877
Validation loss: 2.5168985984695347

Epoch: 5| Step: 5
Training loss: 1.788989469545183
Validation loss: 2.506284365529495

Epoch: 5| Step: 6
Training loss: 1.8231568605125719
Validation loss: 2.4973987048658257

Epoch: 5| Step: 7
Training loss: 2.354864697791269
Validation loss: 2.451456060679022

Epoch: 5| Step: 8
Training loss: 2.0425133279578014
Validation loss: 2.4382262240575763

Epoch: 5| Step: 9
Training loss: 2.700139596650541
Validation loss: 2.404700295996889

Epoch: 5| Step: 10
Training loss: 2.0204396077329543
Validation loss: 2.385293402207165

Epoch: 201| Step: 0
Training loss: 1.7399492469050413
Validation loss: 2.3863480359933784

Epoch: 5| Step: 1
Training loss: 1.5741570320999092
Validation loss: 2.409660773065967

Epoch: 5| Step: 2
Training loss: 2.6374642681576
Validation loss: 2.4369928396635676

Epoch: 5| Step: 3
Training loss: 2.282544121707509
Validation loss: 2.5104338302777855

Epoch: 5| Step: 4
Training loss: 2.1085065396094183
Validation loss: 2.5519920153642586

Epoch: 5| Step: 5
Training loss: 2.6884691132297815
Validation loss: 2.5452672011867614

Epoch: 5| Step: 6
Training loss: 1.7325132532975216
Validation loss: 2.5155638708545807

Epoch: 5| Step: 7
Training loss: 2.0720124948485696
Validation loss: 2.486032995705986

Epoch: 5| Step: 8
Training loss: 2.019439872282934
Validation loss: 2.459434677275386

Epoch: 5| Step: 9
Training loss: 1.7028548700133688
Validation loss: 2.4368817208130324

Epoch: 5| Step: 10
Training loss: 2.3207176188780583
Validation loss: 2.3807409202301395

Epoch: 202| Step: 0
Training loss: 1.9916030325626501
Validation loss: 2.3931665001364046

Epoch: 5| Step: 1
Training loss: 1.822617082955757
Validation loss: 2.3948888167945257

Epoch: 5| Step: 2
Training loss: 2.11970826030982
Validation loss: 2.4054486288428585

Epoch: 5| Step: 3
Training loss: 2.358115460022395
Validation loss: 2.42853935712914

Epoch: 5| Step: 4
Training loss: 2.0941801625656975
Validation loss: 2.4718049331565908

Epoch: 5| Step: 5
Training loss: 2.0131674281768195
Validation loss: 2.4815369416726383

Epoch: 5| Step: 6
Training loss: 1.655821978845752
Validation loss: 2.493381035071348

Epoch: 5| Step: 7
Training loss: 2.456694029453364
Validation loss: 2.4611559011620554

Epoch: 5| Step: 8
Training loss: 2.0062009526136872
Validation loss: 2.453775682612751

Epoch: 5| Step: 9
Training loss: 2.1550806164100496
Validation loss: 2.4402616919747797

Epoch: 5| Step: 10
Training loss: 2.146842780836236
Validation loss: 2.448611231919898

Epoch: 203| Step: 0
Training loss: 1.8459432455825573
Validation loss: 2.469419393550747

Epoch: 5| Step: 1
Training loss: 2.239603075043955
Validation loss: 2.4574596033529597

Epoch: 5| Step: 2
Training loss: 1.8641410459355927
Validation loss: 2.479808021933789

Epoch: 5| Step: 3
Training loss: 2.4162756395237706
Validation loss: 2.5126757068158576

Epoch: 5| Step: 4
Training loss: 2.1155630263206437
Validation loss: 2.5380331639028455

Epoch: 5| Step: 5
Training loss: 2.043804515613167
Validation loss: 2.565427042344573

Epoch: 5| Step: 6
Training loss: 2.0659287591488766
Validation loss: 2.5220557936710346

Epoch: 5| Step: 7
Training loss: 1.9310530182460925
Validation loss: 2.496972311833354

Epoch: 5| Step: 8
Training loss: 2.2509531545352854
Validation loss: 2.460630965458696

Epoch: 5| Step: 9
Training loss: 1.9126927048080993
Validation loss: 2.443228509703034

Epoch: 5| Step: 10
Training loss: 1.9375467602409282
Validation loss: 2.4112327199227517

Epoch: 204| Step: 0
Training loss: 2.3775652032328742
Validation loss: 2.393367794160791

Epoch: 5| Step: 1
Training loss: 2.1011025304746305
Validation loss: 2.37215591801916

Epoch: 5| Step: 2
Training loss: 2.2016880408420745
Validation loss: 2.3431548064942365

Epoch: 5| Step: 3
Training loss: 2.018796569476039
Validation loss: 2.332206852617477

Epoch: 5| Step: 4
Training loss: 1.5589915750213497
Validation loss: 2.3610346367539825

Epoch: 5| Step: 5
Training loss: 1.9748418503227063
Validation loss: 2.3772961047720576

Epoch: 5| Step: 6
Training loss: 2.120858363795137
Validation loss: 2.4104773500534398

Epoch: 5| Step: 7
Training loss: 2.3190904475343808
Validation loss: 2.4264950606857116

Epoch: 5| Step: 8
Training loss: 1.8174680826147243
Validation loss: 2.4493741653777943

Epoch: 5| Step: 9
Training loss: 1.7789168889025369
Validation loss: 2.4881190818645784

Epoch: 5| Step: 10
Training loss: 2.0663350603211597
Validation loss: 2.5098235761916152

Epoch: 205| Step: 0
Training loss: 1.9256988569666802
Validation loss: 2.4896966743044064

Epoch: 5| Step: 1
Training loss: 1.9173186340502504
Validation loss: 2.488085251028465

Epoch: 5| Step: 2
Training loss: 2.2045297675749964
Validation loss: 2.4833594695017522

Epoch: 5| Step: 3
Training loss: 1.7165303549611857
Validation loss: 2.478989183651866

Epoch: 5| Step: 4
Training loss: 2.251495500106432
Validation loss: 2.489832644534331

Epoch: 5| Step: 5
Training loss: 1.752639823048283
Validation loss: 2.5173354573558053

Epoch: 5| Step: 6
Training loss: 2.1148761364895274
Validation loss: 2.4951467042829893

Epoch: 5| Step: 7
Training loss: 2.077857208206992
Validation loss: 2.448544474683513

Epoch: 5| Step: 8
Training loss: 1.6453224870137748
Validation loss: 2.4382677018327836

Epoch: 5| Step: 9
Training loss: 2.1340688281985587
Validation loss: 2.401774674229894

Epoch: 5| Step: 10
Training loss: 2.1714860307111086
Validation loss: 2.4098316359008747

Epoch: 206| Step: 0
Training loss: 2.003482647418205
Validation loss: 2.3723447223320853

Epoch: 5| Step: 1
Training loss: 2.171370413367074
Validation loss: 2.385324563333586

Epoch: 5| Step: 2
Training loss: 2.0053738876631684
Validation loss: 2.4075539290429635

Epoch: 5| Step: 3
Training loss: 1.6177208799459837
Validation loss: 2.4270090021965753

Epoch: 5| Step: 4
Training loss: 1.4968905008106759
Validation loss: 2.443766824390413

Epoch: 5| Step: 5
Training loss: 2.4325498543283186
Validation loss: 2.450836659958863

Epoch: 5| Step: 6
Training loss: 2.1598199234179263
Validation loss: 2.4613678565825805

Epoch: 5| Step: 7
Training loss: 2.131080119502438
Validation loss: 2.4973800518218146

Epoch: 5| Step: 8
Training loss: 1.9047739536608217
Validation loss: 2.5123608103651347

Epoch: 5| Step: 9
Training loss: 1.8782473100642716
Validation loss: 2.5297653095777055

Epoch: 5| Step: 10
Training loss: 2.0563255133865344
Validation loss: 2.553840687775705

Epoch: 207| Step: 0
Training loss: 2.0914384978369256
Validation loss: 2.4955042212955196

Epoch: 5| Step: 1
Training loss: 2.0914679089627914
Validation loss: 2.484499894594668

Epoch: 5| Step: 2
Training loss: 1.816980874014984
Validation loss: 2.5004627947936164

Epoch: 5| Step: 3
Training loss: 1.8373604312752285
Validation loss: 2.5089462968595413

Epoch: 5| Step: 4
Training loss: 2.3243752819531918
Validation loss: 2.529729902472289

Epoch: 5| Step: 5
Training loss: 1.9673033349169409
Validation loss: 2.4880644519557054

Epoch: 5| Step: 6
Training loss: 1.7258984423625885
Validation loss: 2.4426659531545036

Epoch: 5| Step: 7
Training loss: 2.210357374234374
Validation loss: 2.4221230804906693

Epoch: 5| Step: 8
Training loss: 1.6042674970108108
Validation loss: 2.4095656137489665

Epoch: 5| Step: 9
Training loss: 2.0712828467463313
Validation loss: 2.3964551791883553

Epoch: 5| Step: 10
Training loss: 1.6679640329906222
Validation loss: 2.40783940637376

Epoch: 208| Step: 0
Training loss: 2.0763677754032184
Validation loss: 2.42508134201225

Epoch: 5| Step: 1
Training loss: 1.5666856778120886
Validation loss: 2.4486557291023128

Epoch: 5| Step: 2
Training loss: 2.260623963397703
Validation loss: 2.4940430272789422

Epoch: 5| Step: 3
Training loss: 1.4370979078436221
Validation loss: 2.4899198687624575

Epoch: 5| Step: 4
Training loss: 1.9650286669011128
Validation loss: 2.467385561558284

Epoch: 5| Step: 5
Training loss: 1.943878625864039
Validation loss: 2.4429609664525977

Epoch: 5| Step: 6
Training loss: 2.254349636847898
Validation loss: 2.449368537004003

Epoch: 5| Step: 7
Training loss: 1.8056890177510923
Validation loss: 2.4477660978287465

Epoch: 5| Step: 8
Training loss: 2.1198895655964503
Validation loss: 2.4898897592480282

Epoch: 5| Step: 9
Training loss: 1.9979687747252763
Validation loss: 2.486093094333226

Epoch: 5| Step: 10
Training loss: 2.003820703773747
Validation loss: 2.461707433008825

Epoch: 209| Step: 0
Training loss: 2.185144409540398
Validation loss: 2.4300627160040347

Epoch: 5| Step: 1
Training loss: 1.6270342345243787
Validation loss: 2.396094977674442

Epoch: 5| Step: 2
Training loss: 1.8551216523619836
Validation loss: 2.4043157064015723

Epoch: 5| Step: 3
Training loss: 1.618158021592149
Validation loss: 2.3811494976109726

Epoch: 5| Step: 4
Training loss: 1.6556522082306842
Validation loss: 2.41138942523221

Epoch: 5| Step: 5
Training loss: 2.1007021592964468
Validation loss: 2.4465634562899403

Epoch: 5| Step: 6
Training loss: 2.4045517117815014
Validation loss: 2.4819048117637013

Epoch: 5| Step: 7
Training loss: 2.0937243787421984
Validation loss: 2.495553959761451

Epoch: 5| Step: 8
Training loss: 1.6224768931149733
Validation loss: 2.460866072517134

Epoch: 5| Step: 9
Training loss: 1.7174565389984076
Validation loss: 2.4349309194336906

Epoch: 5| Step: 10
Training loss: 2.15978459891314
Validation loss: 2.419441489373618

Epoch: 210| Step: 0
Training loss: 2.088638899546246
Validation loss: 2.4015407166857576

Epoch: 5| Step: 1
Training loss: 1.6514686810454133
Validation loss: 2.38703764042228

Epoch: 5| Step: 2
Training loss: 1.9652661576693236
Validation loss: 2.3989229936437573

Epoch: 5| Step: 3
Training loss: 1.701382997290689
Validation loss: 2.3829850393760528

Epoch: 5| Step: 4
Training loss: 1.6589181389642673
Validation loss: 2.3930248879551987

Epoch: 5| Step: 5
Training loss: 1.4414620737570434
Validation loss: 2.4016934612277003

Epoch: 5| Step: 6
Training loss: 1.7594377252431497
Validation loss: 2.434247017336308

Epoch: 5| Step: 7
Training loss: 1.9012945207327774
Validation loss: 2.456228449730927

Epoch: 5| Step: 8
Training loss: 2.1930884773994297
Validation loss: 2.4931502888131067

Epoch: 5| Step: 9
Training loss: 2.0662694067254237
Validation loss: 2.5122902867294923

Epoch: 5| Step: 10
Training loss: 2.3736911982142876
Validation loss: 2.5296870837267984

Epoch: 211| Step: 0
Training loss: 2.054485818806081
Validation loss: 2.5222318331654123

Epoch: 5| Step: 1
Training loss: 1.4629798525806863
Validation loss: 2.500718373483307

Epoch: 5| Step: 2
Training loss: 2.008970053108281
Validation loss: 2.4765351985162676

Epoch: 5| Step: 3
Training loss: 2.0810967328797534
Validation loss: 2.4791416392032954

Epoch: 5| Step: 4
Training loss: 1.871060237703868
Validation loss: 2.4671680246345993

Epoch: 5| Step: 5
Training loss: 2.303478169375245
Validation loss: 2.4674589115246026

Epoch: 5| Step: 6
Training loss: 1.7829845081368776
Validation loss: 2.440843965617612

Epoch: 5| Step: 7
Training loss: 2.0340697450636256
Validation loss: 2.4481352281537805

Epoch: 5| Step: 8
Training loss: 1.7760937665380734
Validation loss: 2.461004137737658

Epoch: 5| Step: 9
Training loss: 1.6530052646476971
Validation loss: 2.5081653200471115

Epoch: 5| Step: 10
Training loss: 1.522795086907291
Validation loss: 2.5518582269681644

Epoch: 212| Step: 0
Training loss: 1.9867440447470248
Validation loss: 2.53291303440901

Epoch: 5| Step: 1
Training loss: 1.998832719628721
Validation loss: 2.4912860217306014

Epoch: 5| Step: 2
Training loss: 1.9918445965230314
Validation loss: 2.44178154195067

Epoch: 5| Step: 3
Training loss: 1.6169401707618511
Validation loss: 2.4314586982684356

Epoch: 5| Step: 4
Training loss: 1.5292452709704223
Validation loss: 2.4020011838358624

Epoch: 5| Step: 5
Training loss: 1.9086052149812025
Validation loss: 2.3886122005152

Epoch: 5| Step: 6
Training loss: 1.6060398691675095
Validation loss: 2.3807354144190644

Epoch: 5| Step: 7
Training loss: 2.272410996711659
Validation loss: 2.3723928306694493

Epoch: 5| Step: 8
Training loss: 1.8626279185357808
Validation loss: 2.373829415509262

Epoch: 5| Step: 9
Training loss: 2.147670983645237
Validation loss: 2.400607263141615

Epoch: 5| Step: 10
Training loss: 1.5161014869710328
Validation loss: 2.4289223245201303

Epoch: 213| Step: 0
Training loss: 1.916466709432023
Validation loss: 2.4750623749626897

Epoch: 5| Step: 1
Training loss: 1.7511675209809872
Validation loss: 2.4813402302027967

Epoch: 5| Step: 2
Training loss: 2.014192767254939
Validation loss: 2.4692860274915875

Epoch: 5| Step: 3
Training loss: 1.2768405308041118
Validation loss: 2.482187644642027

Epoch: 5| Step: 4
Training loss: 2.044377791082984
Validation loss: 2.487980438871498

Epoch: 5| Step: 5
Training loss: 2.2162337743312577
Validation loss: 2.4979687416763765

Epoch: 5| Step: 6
Training loss: 1.8930090383161746
Validation loss: 2.4871967852916375

Epoch: 5| Step: 7
Training loss: 1.4530009555170287
Validation loss: 2.468367264865661

Epoch: 5| Step: 8
Training loss: 1.9676165269713235
Validation loss: 2.4711984881246285

Epoch: 5| Step: 9
Training loss: 1.6953072262167757
Validation loss: 2.441754160778493

Epoch: 5| Step: 10
Training loss: 1.6613358200329151
Validation loss: 2.447201267730498

Epoch: 214| Step: 0
Training loss: 1.848019779888002
Validation loss: 2.4275631744290953

Epoch: 5| Step: 1
Training loss: 1.6677876358508954
Validation loss: 2.41681647941382

Epoch: 5| Step: 2
Training loss: 2.0657360237513935
Validation loss: 2.4153094598368323

Epoch: 5| Step: 3
Training loss: 2.060282468780864
Validation loss: 2.4177317798664477

Epoch: 5| Step: 4
Training loss: 1.7811112600804933
Validation loss: 2.411247766387896

Epoch: 5| Step: 5
Training loss: 1.7617753859253087
Validation loss: 2.4375670260544875

Epoch: 5| Step: 6
Training loss: 1.9333393584628875
Validation loss: 2.485843609530291

Epoch: 5| Step: 7
Training loss: 1.7148031521034324
Validation loss: 2.506822869917502

Epoch: 5| Step: 8
Training loss: 1.641202915675497
Validation loss: 2.4761466233557146

Epoch: 5| Step: 9
Training loss: 1.839023415304926
Validation loss: 2.457735058368047

Epoch: 5| Step: 10
Training loss: 1.8253383427354517
Validation loss: 2.4339529164280473

Epoch: 215| Step: 0
Training loss: 1.696673080204881
Validation loss: 2.4183604869540867

Epoch: 5| Step: 1
Training loss: 1.9783973470206546
Validation loss: 2.417685756019565

Epoch: 5| Step: 2
Training loss: 1.7706198470137966
Validation loss: 2.4158952388414248

Epoch: 5| Step: 3
Training loss: 1.2651979644332079
Validation loss: 2.4300253149581152

Epoch: 5| Step: 4
Training loss: 2.0430513733591162
Validation loss: 2.457587267266412

Epoch: 5| Step: 5
Training loss: 1.9323994965469125
Validation loss: 2.459797579719879

Epoch: 5| Step: 6
Training loss: 1.659794307971741
Validation loss: 2.4356755258865856

Epoch: 5| Step: 7
Training loss: 1.5961411434088832
Validation loss: 2.433903351596737

Epoch: 5| Step: 8
Training loss: 1.8166403998946232
Validation loss: 2.428009689459981

Epoch: 5| Step: 9
Training loss: 2.0451405871876642
Validation loss: 2.4219539622845794

Epoch: 5| Step: 10
Training loss: 1.5314150351513778
Validation loss: 2.4271145555907796

Epoch: 216| Step: 0
Training loss: 2.036279408691555
Validation loss: 2.417501293968076

Epoch: 5| Step: 1
Training loss: 1.9799678853831033
Validation loss: 2.4091197143806378

Epoch: 5| Step: 2
Training loss: 1.5647231498787897
Validation loss: 2.4170755826107815

Epoch: 5| Step: 3
Training loss: 2.0949135579049543
Validation loss: 2.409354719300051

Epoch: 5| Step: 4
Training loss: 1.4635120900198526
Validation loss: 2.441743850566026

Epoch: 5| Step: 5
Training loss: 1.727596266916971
Validation loss: 2.438286625195906

Epoch: 5| Step: 6
Training loss: 1.7793110785142476
Validation loss: 2.454185469290875

Epoch: 5| Step: 7
Training loss: 1.466550194204819
Validation loss: 2.4561922341018123

Epoch: 5| Step: 8
Training loss: 1.3404585870637005
Validation loss: 2.43245243076037

Epoch: 5| Step: 9
Training loss: 1.6097356892065309
Validation loss: 2.430815128894391

Epoch: 5| Step: 10
Training loss: 1.9876814201613924
Validation loss: 2.4048917719538174

Epoch: 217| Step: 0
Training loss: 1.7072102258640556
Validation loss: 2.4083515222612473

Epoch: 5| Step: 1
Training loss: 1.7785651066241508
Validation loss: 2.3841318212410534

Epoch: 5| Step: 2
Training loss: 1.6085009377203792
Validation loss: 2.3623915920938967

Epoch: 5| Step: 3
Training loss: 1.843151318610243
Validation loss: 2.3761040831149325

Epoch: 5| Step: 4
Training loss: 1.1351125058949547
Validation loss: 2.4054974989562283

Epoch: 5| Step: 5
Training loss: 1.7940676444451165
Validation loss: 2.41806463882777

Epoch: 5| Step: 6
Training loss: 1.5568022027869484
Validation loss: 2.4265482981460313

Epoch: 5| Step: 7
Training loss: 1.8612654876576995
Validation loss: 2.456092300702749

Epoch: 5| Step: 8
Training loss: 1.7415159154137887
Validation loss: 2.4703077399481237

Epoch: 5| Step: 9
Training loss: 1.8864098843005763
Validation loss: 2.4755123007010202

Epoch: 5| Step: 10
Training loss: 2.0337818505736194
Validation loss: 2.4830752524043316

Epoch: 218| Step: 0
Training loss: 1.760063527217847
Validation loss: 2.467734591564093

Epoch: 5| Step: 1
Training loss: 1.8425121354592418
Validation loss: 2.4544299748462626

Epoch: 5| Step: 2
Training loss: 2.0059128617655806
Validation loss: 2.437130410167162

Epoch: 5| Step: 3
Training loss: 1.7212116992376416
Validation loss: 2.41551367766085

Epoch: 5| Step: 4
Training loss: 1.187931484333822
Validation loss: 2.3889266164779426

Epoch: 5| Step: 5
Training loss: 1.6962558213810834
Validation loss: 2.390329342545341

Epoch: 5| Step: 6
Training loss: 1.874918745187617
Validation loss: 2.4043262154985334

Epoch: 5| Step: 7
Training loss: 1.487086099052191
Validation loss: 2.4233095248004717

Epoch: 5| Step: 8
Training loss: 2.11187810377721
Validation loss: 2.4141047794897994

Epoch: 5| Step: 9
Training loss: 1.798060813715525
Validation loss: 2.4037254646584922

Epoch: 5| Step: 10
Training loss: 0.8666572324227091
Validation loss: 2.4128741193218626

Epoch: 219| Step: 0
Training loss: 1.777846246467132
Validation loss: 2.422547153505991

Epoch: 5| Step: 1
Training loss: 1.722948668004751
Validation loss: 2.393821700712369

Epoch: 5| Step: 2
Training loss: 1.9649675152061497
Validation loss: 2.3785988257637447

Epoch: 5| Step: 3
Training loss: 1.6478145199580103
Validation loss: 2.373456043460257

Epoch: 5| Step: 4
Training loss: 1.504817854799393
Validation loss: 2.3549591488928034

Epoch: 5| Step: 5
Training loss: 1.5181311896909795
Validation loss: 2.3535944032306975

Epoch: 5| Step: 6
Training loss: 1.9219303898466609
Validation loss: 2.374483256316745

Epoch: 5| Step: 7
Training loss: 1.4271392625675894
Validation loss: 2.4127004085890027

Epoch: 5| Step: 8
Training loss: 1.9118992628669844
Validation loss: 2.4241209330651348

Epoch: 5| Step: 9
Training loss: 1.6600053067869365
Validation loss: 2.4488880365767427

Epoch: 5| Step: 10
Training loss: 1.70709989571197
Validation loss: 2.4641699653263363

Epoch: 220| Step: 0
Training loss: 1.8592987044893752
Validation loss: 2.429946351201194

Epoch: 5| Step: 1
Training loss: 1.661059468223916
Validation loss: 2.4153043427597862

Epoch: 5| Step: 2
Training loss: 1.3736590869592313
Validation loss: 2.367394008541117

Epoch: 5| Step: 3
Training loss: 1.9209410716505033
Validation loss: 2.387185145442384

Epoch: 5| Step: 4
Training loss: 1.630326491228772
Validation loss: 2.3788189281536827

Epoch: 5| Step: 5
Training loss: 1.674717420968085
Validation loss: 2.3838197663361456

Epoch: 5| Step: 6
Training loss: 1.7633552478277041
Validation loss: 2.396069932751691

Epoch: 5| Step: 7
Training loss: 1.250104279936777
Validation loss: 2.4034267462521752

Epoch: 5| Step: 8
Training loss: 1.4310994498019307
Validation loss: 2.4342856562518014

Epoch: 5| Step: 9
Training loss: 1.890077306690259
Validation loss: 2.440166366526309

Epoch: 5| Step: 10
Training loss: 1.9123940182909662
Validation loss: 2.3945985163089074

Epoch: 221| Step: 0
Training loss: 1.7209092188891293
Validation loss: 2.3614949301875416

Epoch: 5| Step: 1
Training loss: 1.8168218321840237
Validation loss: 2.376468673892392

Epoch: 5| Step: 2
Training loss: 1.7714400280634715
Validation loss: 2.3592667756185794

Epoch: 5| Step: 3
Training loss: 1.6692897738028378
Validation loss: 2.3598940155587695

Epoch: 5| Step: 4
Training loss: 1.0296879700354282
Validation loss: 2.3887415391387483

Epoch: 5| Step: 5
Training loss: 1.989524887052017
Validation loss: 2.3714360599575377

Epoch: 5| Step: 6
Training loss: 1.2825580990516305
Validation loss: 2.390811545332067

Epoch: 5| Step: 7
Training loss: 1.70055931090617
Validation loss: 2.4116980154205954

Epoch: 5| Step: 8
Training loss: 1.8368828470192937
Validation loss: 2.40716229028723

Epoch: 5| Step: 9
Training loss: 1.5565151800634076
Validation loss: 2.4177011960129566

Epoch: 5| Step: 10
Training loss: 1.6275695146050833
Validation loss: 2.4086713323851785

Epoch: 222| Step: 0
Training loss: 1.9620988909718289
Validation loss: 2.3982438315272048

Epoch: 5| Step: 1
Training loss: 1.2649780786446851
Validation loss: 2.382408265150108

Epoch: 5| Step: 2
Training loss: 2.2384310101376803
Validation loss: 2.3776332492817787

Epoch: 5| Step: 3
Training loss: 1.4324460125614502
Validation loss: 2.3505685504691693

Epoch: 5| Step: 4
Training loss: 1.3645132886463869
Validation loss: 2.3641013677501848

Epoch: 5| Step: 5
Training loss: 1.6745089166904443
Validation loss: 2.372084523921717

Epoch: 5| Step: 6
Training loss: 1.7409569196109254
Validation loss: 2.391397690058782

Epoch: 5| Step: 7
Training loss: 1.6242979440469523
Validation loss: 2.381567415788231

Epoch: 5| Step: 8
Training loss: 1.6914410664628958
Validation loss: 2.4300487239109856

Epoch: 5| Step: 9
Training loss: 1.618214451633222
Validation loss: 2.440091676074096

Epoch: 5| Step: 10
Training loss: 1.094904807669167
Validation loss: 2.42346205459024

Epoch: 223| Step: 0
Training loss: 1.4604471781214847
Validation loss: 2.4215979940016825

Epoch: 5| Step: 1
Training loss: 1.6745988991874412
Validation loss: 2.410356622404456

Epoch: 5| Step: 2
Training loss: 1.342234488787153
Validation loss: 2.3685658425869334

Epoch: 5| Step: 3
Training loss: 1.7190357317536766
Validation loss: 2.380307239653095

Epoch: 5| Step: 4
Training loss: 1.4246897242537713
Validation loss: 2.369581310334586

Epoch: 5| Step: 5
Training loss: 1.646988797101644
Validation loss: 2.352125298981394

Epoch: 5| Step: 6
Training loss: 1.1621516372304779
Validation loss: 2.3458278248162947

Epoch: 5| Step: 7
Training loss: 1.9352431535361947
Validation loss: 2.3492458036541524

Epoch: 5| Step: 8
Training loss: 1.6765265952440322
Validation loss: 2.3736215519217088

Epoch: 5| Step: 9
Training loss: 1.7616307813922674
Validation loss: 2.3494406533438883

Epoch: 5| Step: 10
Training loss: 1.8691435587669636
Validation loss: 2.371868683678255

Epoch: 224| Step: 0
Training loss: 1.5732094532209033
Validation loss: 2.3854222211402774

Epoch: 5| Step: 1
Training loss: 1.504081418623632
Validation loss: 2.3720458028796965

Epoch: 5| Step: 2
Training loss: 1.3737529821944907
Validation loss: 2.3890860586205926

Epoch: 5| Step: 3
Training loss: 1.7801068971446183
Validation loss: 2.384531222096946

Epoch: 5| Step: 4
Training loss: 1.5678884290831592
Validation loss: 2.3888831691414323

Epoch: 5| Step: 5
Training loss: 0.8949805717916912
Validation loss: 2.3761087516234425

Epoch: 5| Step: 6
Training loss: 1.8005938980716072
Validation loss: 2.3479410967545973

Epoch: 5| Step: 7
Training loss: 1.8330766180230231
Validation loss: 2.331778048253717

Epoch: 5| Step: 8
Training loss: 1.584748146312404
Validation loss: 2.326343987960679

Epoch: 5| Step: 9
Training loss: 1.8301965437024303
Validation loss: 2.346360174170954

Epoch: 5| Step: 10
Training loss: 1.7243610691504716
Validation loss: 2.3327086494354727

Epoch: 225| Step: 0
Training loss: 1.4146359792958954
Validation loss: 2.3515806907740884

Epoch: 5| Step: 1
Training loss: 1.6970246981350396
Validation loss: 2.367183371638126

Epoch: 5| Step: 2
Training loss: 1.2495309903506027
Validation loss: 2.374005768574112

Epoch: 5| Step: 3
Training loss: 1.9607593105863104
Validation loss: 2.4078419222723038

Epoch: 5| Step: 4
Training loss: 1.4106580522997727
Validation loss: 2.386301667916803

Epoch: 5| Step: 5
Training loss: 1.4130320298168078
Validation loss: 2.4141987383399797

Epoch: 5| Step: 6
Training loss: 1.8798470471435427
Validation loss: 2.4044266243198336

Epoch: 5| Step: 7
Training loss: 2.028723216182636
Validation loss: 2.4014796042991873

Epoch: 5| Step: 8
Training loss: 1.2818302143369635
Validation loss: 2.3703450848253795

Epoch: 5| Step: 9
Training loss: 1.566850023835205
Validation loss: 2.34375705184696

Epoch: 5| Step: 10
Training loss: 1.19293609954181
Validation loss: 2.3347383706163143

Epoch: 226| Step: 0
Training loss: 1.52810860529493
Validation loss: 2.3198847272270666

Epoch: 5| Step: 1
Training loss: 1.8480651274017397
Validation loss: 2.308864152010198

Epoch: 5| Step: 2
Training loss: 1.440181387497437
Validation loss: 2.3142090789519445

Epoch: 5| Step: 3
Training loss: 1.9809995161977347
Validation loss: 2.3151066796214077

Epoch: 5| Step: 4
Training loss: 1.3715544793256667
Validation loss: 2.345150668636751

Epoch: 5| Step: 5
Training loss: 1.4234181508529862
Validation loss: 2.3592835834897823

Epoch: 5| Step: 6
Training loss: 1.6538736101406608
Validation loss: 2.376828651675359

Epoch: 5| Step: 7
Training loss: 1.452594291003297
Validation loss: 2.3434029183390734

Epoch: 5| Step: 8
Training loss: 1.4299031913106515
Validation loss: 2.357234834690273

Epoch: 5| Step: 9
Training loss: 1.6083111997013635
Validation loss: 2.367101427796713

Epoch: 5| Step: 10
Training loss: 1.4952865295387108
Validation loss: 2.3865474290818294

Epoch: 227| Step: 0
Training loss: 1.7114529464677148
Validation loss: 2.381593353272153

Epoch: 5| Step: 1
Training loss: 1.490049658210254
Validation loss: 2.3863998524159022

Epoch: 5| Step: 2
Training loss: 1.7723114875440533
Validation loss: 2.383983318093274

Epoch: 5| Step: 3
Training loss: 1.186562268284998
Validation loss: 2.3605535256189856

Epoch: 5| Step: 4
Training loss: 1.4132125998082437
Validation loss: 2.3729040874919995

Epoch: 5| Step: 5
Training loss: 1.7321170164492627
Validation loss: 2.3805086512716382

Epoch: 5| Step: 6
Training loss: 1.3970953185153971
Validation loss: 2.3537939144809332

Epoch: 5| Step: 7
Training loss: 1.427982167920669
Validation loss: 2.3206482607703487

Epoch: 5| Step: 8
Training loss: 1.3712307679488986
Validation loss: 2.316022878448731

Epoch: 5| Step: 9
Training loss: 1.581320746727675
Validation loss: 2.3157190656798416

Epoch: 5| Step: 10
Training loss: 1.8635942688013145
Validation loss: 2.324478804669322

Epoch: 228| Step: 0
Training loss: 1.724319727455281
Validation loss: 2.306550882963878

Epoch: 5| Step: 1
Training loss: 1.0172709698862938
Validation loss: 2.3075914911503754

Epoch: 5| Step: 2
Training loss: 1.7888399343854247
Validation loss: 2.3282937225959257

Epoch: 5| Step: 3
Training loss: 1.7773339575193834
Validation loss: 2.315817663906103

Epoch: 5| Step: 4
Training loss: 1.4891997779419779
Validation loss: 2.3117590894932216

Epoch: 5| Step: 5
Training loss: 1.0930391453942798
Validation loss: 2.3293429575789952

Epoch: 5| Step: 6
Training loss: 1.7213336599016262
Validation loss: 2.314529416441789

Epoch: 5| Step: 7
Training loss: 1.496070562835371
Validation loss: 2.3513803937217705

Epoch: 5| Step: 8
Training loss: 1.6535485747163683
Validation loss: 2.3712913894515886

Epoch: 5| Step: 9
Training loss: 1.7901825043540291
Validation loss: 2.40283287998838

Epoch: 5| Step: 10
Training loss: 1.0441170418270604
Validation loss: 2.387190287355305

Epoch: 229| Step: 0
Training loss: 1.456303064255417
Validation loss: 2.3927608297175977

Epoch: 5| Step: 1
Training loss: 1.613598217433915
Validation loss: 2.3826385192456043

Epoch: 5| Step: 2
Training loss: 1.6851531770171477
Validation loss: 2.3823011829103957

Epoch: 5| Step: 3
Training loss: 1.7097737434792333
Validation loss: 2.3684209177421

Epoch: 5| Step: 4
Training loss: 1.3534244655280068
Validation loss: 2.3376241771946993

Epoch: 5| Step: 5
Training loss: 1.4455973576443983
Validation loss: 2.355599700014646

Epoch: 5| Step: 6
Training loss: 1.2697696403280798
Validation loss: 2.329463528531594

Epoch: 5| Step: 7
Training loss: 1.8449992457442563
Validation loss: 2.313193664234752

Epoch: 5| Step: 8
Training loss: 1.0583236180758169
Validation loss: 2.306831853116366

Epoch: 5| Step: 9
Training loss: 1.6487609401337027
Validation loss: 2.327192522940007

Epoch: 5| Step: 10
Training loss: 1.501316128941055
Validation loss: 2.2998719309479743

Epoch: 230| Step: 0
Training loss: 1.7313630352921932
Validation loss: 2.319813532948887

Epoch: 5| Step: 1
Training loss: 1.135764544095577
Validation loss: 2.3000226764711376

Epoch: 5| Step: 2
Training loss: 1.340395043842689
Validation loss: 2.3082146841513587

Epoch: 5| Step: 3
Training loss: 1.496449878825765
Validation loss: 2.329842931743561

Epoch: 5| Step: 4
Training loss: 1.2493262859577938
Validation loss: 2.3272474134828656

Epoch: 5| Step: 5
Training loss: 1.4065703133190408
Validation loss: 2.342843256736793

Epoch: 5| Step: 6
Training loss: 1.7484645238020309
Validation loss: 2.3453677964747497

Epoch: 5| Step: 7
Training loss: 1.6213325048907783
Validation loss: 2.336390408420583

Epoch: 5| Step: 8
Training loss: 1.430372313869214
Validation loss: 2.317321052193436

Epoch: 5| Step: 9
Training loss: 1.8083134015767686
Validation loss: 2.2823925104446214

Epoch: 5| Step: 10
Training loss: 1.4415799168118206
Validation loss: 2.297767433975739

Epoch: 231| Step: 0
Training loss: 1.9432384664217055
Validation loss: 2.323533318488232

Epoch: 5| Step: 1
Training loss: 1.238091391078855
Validation loss: 2.351402951309844

Epoch: 5| Step: 2
Training loss: 1.342231069441627
Validation loss: 2.349444175640038

Epoch: 5| Step: 3
Training loss: 1.8303783907304998
Validation loss: 2.3769652865935753

Epoch: 5| Step: 4
Training loss: 1.2820444202850798
Validation loss: 2.372053348817648

Epoch: 5| Step: 5
Training loss: 1.6054775859654584
Validation loss: 2.4163385478952257

Epoch: 5| Step: 6
Training loss: 1.477855056082199
Validation loss: 2.3694272920183987

Epoch: 5| Step: 7
Training loss: 1.6507268980640581
Validation loss: 2.321148857507122

Epoch: 5| Step: 8
Training loss: 1.3851198246486272
Validation loss: 2.297206329340359

Epoch: 5| Step: 9
Training loss: 1.158626794118765
Validation loss: 2.2881242390865717

Epoch: 5| Step: 10
Training loss: 1.3771376898690668
Validation loss: 2.2487174677750463

Epoch: 232| Step: 0
Training loss: 1.6405321367412795
Validation loss: 2.278626664650916

Epoch: 5| Step: 1
Training loss: 1.347908947238112
Validation loss: 2.262125909100852

Epoch: 5| Step: 2
Training loss: 1.254104075765713
Validation loss: 2.2615843166596785

Epoch: 5| Step: 3
Training loss: 1.9028959941416304
Validation loss: 2.280915863339242

Epoch: 5| Step: 4
Training loss: 1.7462497445217593
Validation loss: 2.3177130413019125

Epoch: 5| Step: 5
Training loss: 1.5112878150720834
Validation loss: 2.317007282377117

Epoch: 5| Step: 6
Training loss: 1.2659420511111656
Validation loss: 2.3372801750982406

Epoch: 5| Step: 7
Training loss: 1.3574298666300273
Validation loss: 2.331048898265996

Epoch: 5| Step: 8
Training loss: 1.6603649053159766
Validation loss: 2.341459654566893

Epoch: 5| Step: 9
Training loss: 1.2307719508012647
Validation loss: 2.3922852658347145

Epoch: 5| Step: 10
Training loss: 1.58508413121621
Validation loss: 2.3425055850172725

Epoch: 233| Step: 0
Training loss: 1.6370477095440328
Validation loss: 2.3040411508441907

Epoch: 5| Step: 1
Training loss: 1.4205610471160237
Validation loss: 2.2856395091595574

Epoch: 5| Step: 2
Training loss: 1.4957154595022635
Validation loss: 2.2568185665680587

Epoch: 5| Step: 3
Training loss: 1.1485750284694334
Validation loss: 2.258506087301063

Epoch: 5| Step: 4
Training loss: 1.6647222223056777
Validation loss: 2.2753603649490675

Epoch: 5| Step: 5
Training loss: 1.6398547589721724
Validation loss: 2.2989759905832914

Epoch: 5| Step: 6
Training loss: 1.2391872521191114
Validation loss: 2.351107462465013

Epoch: 5| Step: 7
Training loss: 1.6704262847255567
Validation loss: 2.344232869602887

Epoch: 5| Step: 8
Training loss: 1.4089187729477695
Validation loss: 2.294249335758594

Epoch: 5| Step: 9
Training loss: 1.6819220295273571
Validation loss: 2.2821816612385617

Epoch: 5| Step: 10
Training loss: 1.7110243823144045
Validation loss: 2.2490874893195008

Epoch: 234| Step: 0
Training loss: 1.1017400720199642
Validation loss: 2.213544188370737

Epoch: 5| Step: 1
Training loss: 1.2524712453042688
Validation loss: 2.230710954573526

Epoch: 5| Step: 2
Training loss: 1.4900886994401026
Validation loss: 2.2517225583284315

Epoch: 5| Step: 3
Training loss: 1.516915862951953
Validation loss: 2.272095715354883

Epoch: 5| Step: 4
Training loss: 1.5053516922454337
Validation loss: 2.3097466560076922

Epoch: 5| Step: 5
Training loss: 1.3916955748808737
Validation loss: 2.3300835381649665

Epoch: 5| Step: 6
Training loss: 1.3879699649996573
Validation loss: 2.3428982451021585

Epoch: 5| Step: 7
Training loss: 1.502796268799866
Validation loss: 2.322664627299547

Epoch: 5| Step: 8
Training loss: 1.7901992851012978
Validation loss: 2.340106433933142

Epoch: 5| Step: 9
Training loss: 1.5072844376178671
Validation loss: 2.368028579386811

Epoch: 5| Step: 10
Training loss: 1.4823211917184078
Validation loss: 2.336266388888178

Epoch: 235| Step: 0
Training loss: 1.4327766938139899
Validation loss: 2.3456725845451936

Epoch: 5| Step: 1
Training loss: 1.0153376246073813
Validation loss: 2.322083142158986

Epoch: 5| Step: 2
Training loss: 1.8126155553352954
Validation loss: 2.2911009290632647

Epoch: 5| Step: 3
Training loss: 1.4241216328247197
Validation loss: 2.29083716033616

Epoch: 5| Step: 4
Training loss: 1.7482886120604288
Validation loss: 2.284162392077939

Epoch: 5| Step: 5
Training loss: 1.7853791412837507
Validation loss: 2.276966098625315

Epoch: 5| Step: 6
Training loss: 1.3236584223408294
Validation loss: 2.2729618843749377

Epoch: 5| Step: 7
Training loss: 0.9135880828572045
Validation loss: 2.2776873115227545

Epoch: 5| Step: 8
Training loss: 1.1273256211862042
Validation loss: 2.2993897954999185

Epoch: 5| Step: 9
Training loss: 1.5132173114083847
Validation loss: 2.3258199017284737

Epoch: 5| Step: 10
Training loss: 1.2515661918214218
Validation loss: 2.319359122867984

Epoch: 236| Step: 0
Training loss: 1.2935560108646316
Validation loss: 2.3126068179252064

Epoch: 5| Step: 1
Training loss: 1.2977772067823925
Validation loss: 2.3134829985298007

Epoch: 5| Step: 2
Training loss: 1.5822193175252286
Validation loss: 2.297574729499908

Epoch: 5| Step: 3
Training loss: 1.6159218520965455
Validation loss: 2.2984172974498325

Epoch: 5| Step: 4
Training loss: 1.6408241514404636
Validation loss: 2.2874182720748855

Epoch: 5| Step: 5
Training loss: 1.353587623431729
Validation loss: 2.2649752943087837

Epoch: 5| Step: 6
Training loss: 1.597637223034814
Validation loss: 2.2812144475760516

Epoch: 5| Step: 7
Training loss: 1.3595241596338228
Validation loss: 2.2792504920608687

Epoch: 5| Step: 8
Training loss: 1.23715857024646
Validation loss: 2.291155154137805

Epoch: 5| Step: 9
Training loss: 0.9846355154055418
Validation loss: 2.276429178799082

Epoch: 5| Step: 10
Training loss: 1.455382941148601
Validation loss: 2.3018649986102626

Epoch: 237| Step: 0
Training loss: 1.2348368299855828
Validation loss: 2.288403483484724

Epoch: 5| Step: 1
Training loss: 1.4718545608559217
Validation loss: 2.287112201929817

Epoch: 5| Step: 2
Training loss: 1.1364558594301164
Validation loss: 2.3074983192083716

Epoch: 5| Step: 3
Training loss: 1.4278237123105497
Validation loss: 2.3000198414451867

Epoch: 5| Step: 4
Training loss: 1.412732336465489
Validation loss: 2.2855611967698617

Epoch: 5| Step: 5
Training loss: 1.677681083854233
Validation loss: 2.2621656645021258

Epoch: 5| Step: 6
Training loss: 1.0801687909610458
Validation loss: 2.2432105538922573

Epoch: 5| Step: 7
Training loss: 1.627490409436073
Validation loss: 2.2527476076150745

Epoch: 5| Step: 8
Training loss: 1.0970431207129523
Validation loss: 2.2221065011281573

Epoch: 5| Step: 9
Training loss: 1.6109326426361588
Validation loss: 2.240706046523328

Epoch: 5| Step: 10
Training loss: 1.4306957254388728
Validation loss: 2.270067566968369

Epoch: 238| Step: 0
Training loss: 1.2550200272288177
Validation loss: 2.280350486846856

Epoch: 5| Step: 1
Training loss: 1.359546387490274
Validation loss: 2.2907598302836583

Epoch: 5| Step: 2
Training loss: 1.4960467378485849
Validation loss: 2.2845762722991476

Epoch: 5| Step: 3
Training loss: 1.257910825309993
Validation loss: 2.278751579022531

Epoch: 5| Step: 4
Training loss: 1.4168141606162243
Validation loss: 2.297366430891501

Epoch: 5| Step: 5
Training loss: 1.6433650795357224
Validation loss: 2.306526003893621

Epoch: 5| Step: 6
Training loss: 1.6690445229298392
Validation loss: 2.2842641660666456

Epoch: 5| Step: 7
Training loss: 0.9995686971863139
Validation loss: 2.2738887225047764

Epoch: 5| Step: 8
Training loss: 0.9194454895319638
Validation loss: 2.3072297321665243

Epoch: 5| Step: 9
Training loss: 1.6466792705120454
Validation loss: 2.2940905012654076

Epoch: 5| Step: 10
Training loss: 1.1792798885450109
Validation loss: 2.300203052062723

Epoch: 239| Step: 0
Training loss: 1.5729801426220396
Validation loss: 2.2426332951924928

Epoch: 5| Step: 1
Training loss: 1.3513919524266662
Validation loss: 2.247983631737522

Epoch: 5| Step: 2
Training loss: 1.2298600886406654
Validation loss: 2.21566459603834

Epoch: 5| Step: 3
Training loss: 1.6073934707820359
Validation loss: 2.244513155456279

Epoch: 5| Step: 4
Training loss: 1.0192168470824292
Validation loss: 2.2317738570990477

Epoch: 5| Step: 5
Training loss: 1.1903774634931334
Validation loss: 2.2504147417392844

Epoch: 5| Step: 6
Training loss: 1.624673223651046
Validation loss: 2.2487856334932537

Epoch: 5| Step: 7
Training loss: 1.0005950349494315
Validation loss: 2.244200861973021

Epoch: 5| Step: 8
Training loss: 1.0245168105273337
Validation loss: 2.281296440053007

Epoch: 5| Step: 9
Training loss: 1.772337517763117
Validation loss: 2.293086707347618

Epoch: 5| Step: 10
Training loss: 1.3003342235522697
Validation loss: 2.2888481792692312

Epoch: 240| Step: 0
Training loss: 1.515382255699826
Validation loss: 2.323067695000748

Epoch: 5| Step: 1
Training loss: 1.272735729978998
Validation loss: 2.3240614353435785

Epoch: 5| Step: 2
Training loss: 1.473543016492514
Validation loss: 2.346267285217508

Epoch: 5| Step: 3
Training loss: 0.813533712259465
Validation loss: 2.353762815702836

Epoch: 5| Step: 4
Training loss: 1.4850062584022656
Validation loss: 2.3453512288223695

Epoch: 5| Step: 5
Training loss: 1.7360619254032499
Validation loss: 2.3003055930374305

Epoch: 5| Step: 6
Training loss: 1.001392229815051
Validation loss: 2.257181255852252

Epoch: 5| Step: 7
Training loss: 1.1220245750408253
Validation loss: 2.2470939788183166

Epoch: 5| Step: 8
Training loss: 1.3994313549775537
Validation loss: 2.2527703044644274

Epoch: 5| Step: 9
Training loss: 1.4147630505267454
Validation loss: 2.219893334094313

Epoch: 5| Step: 10
Training loss: 1.4466457506651311
Validation loss: 2.2498286169448614

Epoch: 241| Step: 0
Training loss: 1.1095822637660027
Validation loss: 2.260372767828577

Epoch: 5| Step: 1
Training loss: 1.4250000368084819
Validation loss: 2.2742168062160157

Epoch: 5| Step: 2
Training loss: 1.3612434875360522
Validation loss: 2.281724807070533

Epoch: 5| Step: 3
Training loss: 1.0732837839023093
Validation loss: 2.2848322420319023

Epoch: 5| Step: 4
Training loss: 1.6189002950408042
Validation loss: 2.2579775082617815

Epoch: 5| Step: 5
Training loss: 1.2766886673285767
Validation loss: 2.2260395696023605

Epoch: 5| Step: 6
Training loss: 1.3568441135681266
Validation loss: 2.230508941776183

Epoch: 5| Step: 7
Training loss: 1.0539463971566718
Validation loss: 2.238751330201991

Epoch: 5| Step: 8
Training loss: 1.656722595158574
Validation loss: 2.2762719372942164

Epoch: 5| Step: 9
Training loss: 1.4287738486341257
Validation loss: 2.3007996528444266

Epoch: 5| Step: 10
Training loss: 1.2040003279973848
Validation loss: 2.3649322229246548

Epoch: 242| Step: 0
Training loss: 1.4018976888806138
Validation loss: 2.39628722254944

Epoch: 5| Step: 1
Training loss: 1.1784312652042601
Validation loss: 2.3893754634403037

Epoch: 5| Step: 2
Training loss: 1.3723815347794064
Validation loss: 2.38855456596099

Epoch: 5| Step: 3
Training loss: 1.2428589451671868
Validation loss: 2.3929640310780083

Epoch: 5| Step: 4
Training loss: 1.3220449965086587
Validation loss: 2.351699660483363

Epoch: 5| Step: 5
Training loss: 1.5640284120120493
Validation loss: 2.3085361399469764

Epoch: 5| Step: 6
Training loss: 1.3641070294185298
Validation loss: 2.2661047654174937

Epoch: 5| Step: 7
Training loss: 1.0479199332963045
Validation loss: 2.241823724077827

Epoch: 5| Step: 8
Training loss: 1.3885817786926518
Validation loss: 2.240896304757159

Epoch: 5| Step: 9
Training loss: 1.3129759788291486
Validation loss: 2.2338368996782254

Epoch: 5| Step: 10
Training loss: 1.258353833585235
Validation loss: 2.252492266100817

Epoch: 243| Step: 0
Training loss: 1.514593737049218
Validation loss: 2.281897687366074

Epoch: 5| Step: 1
Training loss: 1.0751975299420822
Validation loss: 2.3134415463278803

Epoch: 5| Step: 2
Training loss: 1.185024844122451
Validation loss: 2.3386292858542914

Epoch: 5| Step: 3
Training loss: 1.5205760982127572
Validation loss: 2.299568362861198

Epoch: 5| Step: 4
Training loss: 1.3872249485296828
Validation loss: 2.280664036916021

Epoch: 5| Step: 5
Training loss: 1.520551246017824
Validation loss: 2.274512546436886

Epoch: 5| Step: 6
Training loss: 1.3774038023685566
Validation loss: 2.251262889188207

Epoch: 5| Step: 7
Training loss: 1.0171189104854046
Validation loss: 2.2658117809255054

Epoch: 5| Step: 8
Training loss: 1.273843805754116
Validation loss: 2.254879853073055

Epoch: 5| Step: 9
Training loss: 1.3210228357846392
Validation loss: 2.272064265601471

Epoch: 5| Step: 10
Training loss: 1.0279602405748471
Validation loss: 2.2516023434719767

Epoch: 244| Step: 0
Training loss: 1.4108764415553463
Validation loss: 2.2817458342834875

Epoch: 5| Step: 1
Training loss: 1.5009257321012561
Validation loss: 2.264525331999926

Epoch: 5| Step: 2
Training loss: 1.398426716512522
Validation loss: 2.282789767903865

Epoch: 5| Step: 3
Training loss: 1.3730599414968818
Validation loss: 2.3185037481104613

Epoch: 5| Step: 4
Training loss: 1.3657079920221844
Validation loss: 2.3382152367275704

Epoch: 5| Step: 5
Training loss: 1.2715777525475687
Validation loss: 2.3352798950381555

Epoch: 5| Step: 6
Training loss: 0.9925534031719369
Validation loss: 2.2708089314828315

Epoch: 5| Step: 7
Training loss: 1.1976106280392291
Validation loss: 2.2494836836385663

Epoch: 5| Step: 8
Training loss: 1.3177961940900897
Validation loss: 2.2226975461274234

Epoch: 5| Step: 9
Training loss: 1.0038899817428828
Validation loss: 2.2309202021772805

Epoch: 5| Step: 10
Training loss: 1.4706912907786653
Validation loss: 2.2159281858835826

Epoch: 245| Step: 0
Training loss: 1.4505284398790916
Validation loss: 2.252458522986053

Epoch: 5| Step: 1
Training loss: 1.2060841915830687
Validation loss: 2.2181065244599307

Epoch: 5| Step: 2
Training loss: 1.2323087951725191
Validation loss: 2.2340741478830624

Epoch: 5| Step: 3
Training loss: 1.436823561362851
Validation loss: 2.250555691069144

Epoch: 5| Step: 4
Training loss: 1.171272529865761
Validation loss: 2.242567133928235

Epoch: 5| Step: 5
Training loss: 1.4667216966159928
Validation loss: 2.2849190492719655

Epoch: 5| Step: 6
Training loss: 1.2473198768675506
Validation loss: 2.3069955966447884

Epoch: 5| Step: 7
Training loss: 1.3231511496445154
Validation loss: 2.2970703557580188

Epoch: 5| Step: 8
Training loss: 1.0622969040582892
Validation loss: 2.276760287671542

Epoch: 5| Step: 9
Training loss: 1.5083057604775776
Validation loss: 2.2531195177249894

Epoch: 5| Step: 10
Training loss: 1.3163017435218944
Validation loss: 2.2281179427097118

Epoch: 246| Step: 0
Training loss: 1.4621911203625335
Validation loss: 2.238304117020772

Epoch: 5| Step: 1
Training loss: 1.6279564153334143
Validation loss: 2.2175143745813726

Epoch: 5| Step: 2
Training loss: 1.3370447310908964
Validation loss: 2.2145630967810384

Epoch: 5| Step: 3
Training loss: 1.2745751757743662
Validation loss: 2.2182033945278965

Epoch: 5| Step: 4
Training loss: 1.4832407583144565
Validation loss: 2.243982152017266

Epoch: 5| Step: 5
Training loss: 1.0816196801942992
Validation loss: 2.2588211045309614

Epoch: 5| Step: 6
Training loss: 1.411013947334811
Validation loss: 2.296320988134794

Epoch: 5| Step: 7
Training loss: 1.0095233442111797
Validation loss: 2.3447941216085653

Epoch: 5| Step: 8
Training loss: 1.0794955401767978
Validation loss: 2.3778146511489475

Epoch: 5| Step: 9
Training loss: 1.028697641090113
Validation loss: 2.3790414293799635

Epoch: 5| Step: 10
Training loss: 1.1434301085336158
Validation loss: 2.3602840989538962

Epoch: 247| Step: 0
Training loss: 0.8314633647741296
Validation loss: 2.2969341168620403

Epoch: 5| Step: 1
Training loss: 1.4716531995428581
Validation loss: 2.262097181195454

Epoch: 5| Step: 2
Training loss: 1.2153608687317965
Validation loss: 2.2122917588979716

Epoch: 5| Step: 3
Training loss: 1.1855361158709177
Validation loss: 2.1860336756711587

Epoch: 5| Step: 4
Training loss: 0.8780371204536638
Validation loss: 2.184672912265164

Epoch: 5| Step: 5
Training loss: 1.3846758341227876
Validation loss: 2.17068819895293

Epoch: 5| Step: 6
Training loss: 1.539017187700474
Validation loss: 2.1862446149204855

Epoch: 5| Step: 7
Training loss: 1.088504967078466
Validation loss: 2.2079405718787064

Epoch: 5| Step: 8
Training loss: 1.4472286410117179
Validation loss: 2.227983323568221

Epoch: 5| Step: 9
Training loss: 0.9482320673016534
Validation loss: 2.2499069117131762

Epoch: 5| Step: 10
Training loss: 1.6189055968217845
Validation loss: 2.247839968711766

Epoch: 248| Step: 0
Training loss: 1.0605550804312522
Validation loss: 2.2422783831668185

Epoch: 5| Step: 1
Training loss: 1.1225736732349507
Validation loss: 2.2297685975098536

Epoch: 5| Step: 2
Training loss: 1.0688199405204841
Validation loss: 2.2348975177211887

Epoch: 5| Step: 3
Training loss: 0.8653767556868754
Validation loss: 2.227843532408982

Epoch: 5| Step: 4
Training loss: 1.094620712294528
Validation loss: 2.237367833873777

Epoch: 5| Step: 5
Training loss: 1.0461779878870887
Validation loss: 2.2028855654993267

Epoch: 5| Step: 6
Training loss: 1.6221665107546426
Validation loss: 2.2334901248048546

Epoch: 5| Step: 7
Training loss: 1.2336878735206287
Validation loss: 2.2064919118655864

Epoch: 5| Step: 8
Training loss: 1.403649277644511
Validation loss: 2.2201655642905087

Epoch: 5| Step: 9
Training loss: 1.60166804268282
Validation loss: 2.240730559198815

Epoch: 5| Step: 10
Training loss: 1.2444733993580979
Validation loss: 2.2759117848197135

Epoch: 249| Step: 0
Training loss: 1.1787905282974926
Validation loss: 2.300102325506646

Epoch: 5| Step: 1
Training loss: 1.2951823299146277
Validation loss: 2.307821331665035

Epoch: 5| Step: 2
Training loss: 1.2204263358071195
Validation loss: 2.30201470348812

Epoch: 5| Step: 3
Training loss: 1.0989783527786607
Validation loss: 2.286320560933424

Epoch: 5| Step: 4
Training loss: 1.1784401166103369
Validation loss: 2.266294871003812

Epoch: 5| Step: 5
Training loss: 1.4961102437437344
Validation loss: 2.2422179030354132

Epoch: 5| Step: 6
Training loss: 0.9054327601339479
Validation loss: 2.1954547834657663

Epoch: 5| Step: 7
Training loss: 1.0754072792878124
Validation loss: 2.1819686276594146

Epoch: 5| Step: 8
Training loss: 1.4478551819551666
Validation loss: 2.173294461664727

Epoch: 5| Step: 9
Training loss: 1.3759199446217332
Validation loss: 2.1803086353970835

Epoch: 5| Step: 10
Training loss: 1.011553305276842
Validation loss: 2.2027448827929863

Epoch: 250| Step: 0
Training loss: 1.0958499912016026
Validation loss: 2.2255922959496357

Epoch: 5| Step: 1
Training loss: 1.2672492072230297
Validation loss: 2.276868064511104

Epoch: 5| Step: 2
Training loss: 1.1417288468591684
Validation loss: 2.2822550982461043

Epoch: 5| Step: 3
Training loss: 1.1211188443130062
Validation loss: 2.3017121684283244

Epoch: 5| Step: 4
Training loss: 1.0155920170049941
Validation loss: 2.308047205056895

Epoch: 5| Step: 5
Training loss: 1.3841050136614539
Validation loss: 2.3162496216695887

Epoch: 5| Step: 6
Training loss: 1.4336799782746465
Validation loss: 2.281965821355324

Epoch: 5| Step: 7
Training loss: 1.3234208215160224
Validation loss: 2.2733097596600675

Epoch: 5| Step: 8
Training loss: 1.083337484253976
Validation loss: 2.2568791319486903

Epoch: 5| Step: 9
Training loss: 1.1407325902910748
Validation loss: 2.21416042985888

Epoch: 5| Step: 10
Training loss: 1.3631593491233132
Validation loss: 2.1787854787588996

Epoch: 251| Step: 0
Training loss: 1.367257514250797
Validation loss: 2.196057983615689

Epoch: 5| Step: 1
Training loss: 1.1286226332104479
Validation loss: 2.20672047095189

Epoch: 5| Step: 2
Training loss: 0.6605827037584829
Validation loss: 2.2421259300465457

Epoch: 5| Step: 3
Training loss: 0.972762075282089
Validation loss: 2.2647676276321986

Epoch: 5| Step: 4
Training loss: 1.563395129340096
Validation loss: 2.2887520853140195

Epoch: 5| Step: 5
Training loss: 1.0301695857203914
Validation loss: 2.310328519717104

Epoch: 5| Step: 6
Training loss: 1.2255384701963266
Validation loss: 2.3310332516453878

Epoch: 5| Step: 7
Training loss: 1.5550324330520016
Validation loss: 2.2854735928277132

Epoch: 5| Step: 8
Training loss: 0.9930964234011621
Validation loss: 2.218501443212269

Epoch: 5| Step: 9
Training loss: 1.3435432363721698
Validation loss: 2.2228530913986155

Epoch: 5| Step: 10
Training loss: 1.0922380078251788
Validation loss: 2.214777307251125

Epoch: 252| Step: 0
Training loss: 1.053017770984959
Validation loss: 2.228549654141998

Epoch: 5| Step: 1
Training loss: 1.313270615098364
Validation loss: 2.2177246557701724

Epoch: 5| Step: 2
Training loss: 0.71292548943535
Validation loss: 2.1833770454813513

Epoch: 5| Step: 3
Training loss: 0.8946569429403094
Validation loss: 2.2323262001601076

Epoch: 5| Step: 4
Training loss: 1.3030056649507233
Validation loss: 2.231493405978783

Epoch: 5| Step: 5
Training loss: 1.3780164143867797
Validation loss: 2.247122984093342

Epoch: 5| Step: 6
Training loss: 1.3281442977400861
Validation loss: 2.239397797240807

Epoch: 5| Step: 7
Training loss: 1.0948369211316296
Validation loss: 2.23530801227023

Epoch: 5| Step: 8
Training loss: 1.4674082369602965
Validation loss: 2.2341529568921286

Epoch: 5| Step: 9
Training loss: 1.3909543965294071
Validation loss: 2.222839240668555

Epoch: 5| Step: 10
Training loss: 0.557886249144193
Validation loss: 2.218785186446977

Epoch: 253| Step: 0
Training loss: 0.9495417041589125
Validation loss: 2.218376905912723

Epoch: 5| Step: 1
Training loss: 1.1317756906689849
Validation loss: 2.209169409099681

Epoch: 5| Step: 2
Training loss: 0.8416417945988955
Validation loss: 2.207447327787324

Epoch: 5| Step: 3
Training loss: 1.1854001100497953
Validation loss: 2.2208176937736575

Epoch: 5| Step: 4
Training loss: 1.3632154913402643
Validation loss: 2.2357977162575526

Epoch: 5| Step: 5
Training loss: 1.3599201293239849
Validation loss: 2.2488232045259813

Epoch: 5| Step: 6
Training loss: 1.3883149752065236
Validation loss: 2.259401797795775

Epoch: 5| Step: 7
Training loss: 1.2371611237129185
Validation loss: 2.256282002234549

Epoch: 5| Step: 8
Training loss: 1.0886957829111752
Validation loss: 2.228094419436262

Epoch: 5| Step: 9
Training loss: 0.934000030603347
Validation loss: 2.251786713253446

Epoch: 5| Step: 10
Training loss: 1.1640440152127935
Validation loss: 2.189485490904463

Epoch: 254| Step: 0
Training loss: 0.8781262815201392
Validation loss: 2.2136330650227203

Epoch: 5| Step: 1
Training loss: 1.0147951697394353
Validation loss: 2.2196663907085514

Epoch: 5| Step: 2
Training loss: 0.8384060285976658
Validation loss: 2.2454472698340315

Epoch: 5| Step: 3
Training loss: 1.0819479018517815
Validation loss: 2.2583168358690804

Epoch: 5| Step: 4
Training loss: 1.099862159415604
Validation loss: 2.2587493327920956

Epoch: 5| Step: 5
Training loss: 1.0681309987675947
Validation loss: 2.2476848557659936

Epoch: 5| Step: 6
Training loss: 1.42396961236527
Validation loss: 2.269919866978239

Epoch: 5| Step: 7
Training loss: 1.1683835725054552
Validation loss: 2.267068972918032

Epoch: 5| Step: 8
Training loss: 1.4926357694434929
Validation loss: 2.2450674948832963

Epoch: 5| Step: 9
Training loss: 1.3664413595950746
Validation loss: 2.214922581188694

Epoch: 5| Step: 10
Training loss: 1.0708531594327384
Validation loss: 2.236073069078049

Epoch: 255| Step: 0
Training loss: 1.0765478235581436
Validation loss: 2.2243881474990346

Epoch: 5| Step: 1
Training loss: 1.3382340707384965
Validation loss: 2.2073109114088543

Epoch: 5| Step: 2
Training loss: 1.0866515741489835
Validation loss: 2.2171164540268022

Epoch: 5| Step: 3
Training loss: 1.145899816954039
Validation loss: 2.2068517439333695

Epoch: 5| Step: 4
Training loss: 1.5737843257199622
Validation loss: 2.220039754247576

Epoch: 5| Step: 5
Training loss: 1.2623134664082396
Validation loss: 2.2348141412582994

Epoch: 5| Step: 6
Training loss: 0.7743660333466817
Validation loss: 2.2702101644258277

Epoch: 5| Step: 7
Training loss: 1.2393136519168397
Validation loss: 2.2749791879207937

Epoch: 5| Step: 8
Training loss: 0.9039324361821125
Validation loss: 2.2588985184584116

Epoch: 5| Step: 9
Training loss: 0.9834776224267838
Validation loss: 2.279232391570868

Epoch: 5| Step: 10
Training loss: 0.9971062992786462
Validation loss: 2.271682714374706

Epoch: 256| Step: 0
Training loss: 1.3210324463249055
Validation loss: 2.2566852221513205

Epoch: 5| Step: 1
Training loss: 1.2833150643538722
Validation loss: 2.236443023015585

Epoch: 5| Step: 2
Training loss: 1.2431593637909533
Validation loss: 2.2140100258452

Epoch: 5| Step: 3
Training loss: 1.2147188766427217
Validation loss: 2.2321087563952577

Epoch: 5| Step: 4
Training loss: 1.18703903486926
Validation loss: 2.22839561868984

Epoch: 5| Step: 5
Training loss: 1.1727778707789651
Validation loss: 2.217561854008401

Epoch: 5| Step: 6
Training loss: 0.6440860944976565
Validation loss: 2.24627429380997

Epoch: 5| Step: 7
Training loss: 1.1297527162502765
Validation loss: 2.243674191097364

Epoch: 5| Step: 8
Training loss: 0.8669120076042177
Validation loss: 2.2429314533537554

Epoch: 5| Step: 9
Training loss: 1.192006694637291
Validation loss: 2.2636127773704433

Epoch: 5| Step: 10
Training loss: 0.9961113124121951
Validation loss: 2.273042741044608

Epoch: 257| Step: 0
Training loss: 0.9459864838301953
Validation loss: 2.2341506378385487

Epoch: 5| Step: 1
Training loss: 1.2571055635116288
Validation loss: 2.236819805040579

Epoch: 5| Step: 2
Training loss: 1.1273711435819016
Validation loss: 2.206901191743748

Epoch: 5| Step: 3
Training loss: 1.1477664881581122
Validation loss: 2.212747560303836

Epoch: 5| Step: 4
Training loss: 0.8545281800455403
Validation loss: 2.2161492208308875

Epoch: 5| Step: 5
Training loss: 1.3538403142247937
Validation loss: 2.2004576318942046

Epoch: 5| Step: 6
Training loss: 1.2605281917108313
Validation loss: 2.2205047566443934

Epoch: 5| Step: 7
Training loss: 0.7803270992308134
Validation loss: 2.241010804972199

Epoch: 5| Step: 8
Training loss: 1.2160873671316015
Validation loss: 2.245269416962463

Epoch: 5| Step: 9
Training loss: 0.9722923302728221
Validation loss: 2.209903228291793

Epoch: 5| Step: 10
Training loss: 1.220150509680465
Validation loss: 2.203038206000259

Epoch: 258| Step: 0
Training loss: 0.8390198680766772
Validation loss: 2.2379910596398638

Epoch: 5| Step: 1
Training loss: 0.8616637529684223
Validation loss: 2.2226507435994693

Epoch: 5| Step: 2
Training loss: 1.5056886885471537
Validation loss: 2.2055861207842637

Epoch: 5| Step: 3
Training loss: 1.0978492214230176
Validation loss: 2.226118433879227

Epoch: 5| Step: 4
Training loss: 1.1307293383953867
Validation loss: 2.2554011718708544

Epoch: 5| Step: 5
Training loss: 1.1160007923116573
Validation loss: 2.2434918422641297

Epoch: 5| Step: 6
Training loss: 1.1050477321378653
Validation loss: 2.2618307739469015

Epoch: 5| Step: 7
Training loss: 1.0934971653396153
Validation loss: 2.2386370637006165

Epoch: 5| Step: 8
Training loss: 1.0329352970964207
Validation loss: 2.2328834176084693

Epoch: 5| Step: 9
Training loss: 1.0957070416875185
Validation loss: 2.220869474073269

Epoch: 5| Step: 10
Training loss: 1.1538522448134436
Validation loss: 2.235316444150893

Epoch: 259| Step: 0
Training loss: 0.7340214872697196
Validation loss: 2.2089430868258337

Epoch: 5| Step: 1
Training loss: 0.9359878106199786
Validation loss: 2.2584261699832813

Epoch: 5| Step: 2
Training loss: 1.4514996041754993
Validation loss: 2.2670101278186037

Epoch: 5| Step: 3
Training loss: 1.4178386029503194
Validation loss: 2.2590296293700014

Epoch: 5| Step: 4
Training loss: 0.6501085282468598
Validation loss: 2.2415430881498852

Epoch: 5| Step: 5
Training loss: 1.0690866955001461
Validation loss: 2.20597390429045

Epoch: 5| Step: 6
Training loss: 1.0117751293601076
Validation loss: 2.2290664671799574

Epoch: 5| Step: 7
Training loss: 1.080790831250535
Validation loss: 2.195222208946106

Epoch: 5| Step: 8
Training loss: 1.2098811310318078
Validation loss: 2.214254008747074

Epoch: 5| Step: 9
Training loss: 1.0620039735708955
Validation loss: 2.2418655302115074

Epoch: 5| Step: 10
Training loss: 1.2976203523065184
Validation loss: 2.2058672048855703

Epoch: 260| Step: 0
Training loss: 1.1965167891507689
Validation loss: 2.214212731999321

Epoch: 5| Step: 1
Training loss: 1.0097085431195703
Validation loss: 2.2227134943039384

Epoch: 5| Step: 2
Training loss: 1.078851537953872
Validation loss: 2.243147757141649

Epoch: 5| Step: 3
Training loss: 1.1582381193332656
Validation loss: 2.2651910091090435

Epoch: 5| Step: 4
Training loss: 0.6294689859487252
Validation loss: 2.261054287660613

Epoch: 5| Step: 5
Training loss: 0.86278965274193
Validation loss: 2.253196950050427

Epoch: 5| Step: 6
Training loss: 1.2213856002352308
Validation loss: 2.2290041633036766

Epoch: 5| Step: 7
Training loss: 1.1945529593970543
Validation loss: 2.231894313516777

Epoch: 5| Step: 8
Training loss: 1.1875082818796574
Validation loss: 2.212815156504568

Epoch: 5| Step: 9
Training loss: 1.0250396418465348
Validation loss: 2.236080532730697

Epoch: 5| Step: 10
Training loss: 1.3165169960776442
Validation loss: 2.2295517020126625

Epoch: 261| Step: 0
Training loss: 1.0438392235544405
Validation loss: 2.219021854618368

Epoch: 5| Step: 1
Training loss: 1.2112673402535128
Validation loss: 2.2471419935030243

Epoch: 5| Step: 2
Training loss: 0.964457631554471
Validation loss: 2.261498950641806

Epoch: 5| Step: 3
Training loss: 1.0617509333186743
Validation loss: 2.278347817523366

Epoch: 5| Step: 4
Training loss: 1.0286588772618712
Validation loss: 2.259903648579302

Epoch: 5| Step: 5
Training loss: 1.3019871892401378
Validation loss: 2.2637922144633316

Epoch: 5| Step: 6
Training loss: 1.216100502666893
Validation loss: 2.225973856066917

Epoch: 5| Step: 7
Training loss: 1.1124949573016802
Validation loss: 2.2144245848429183

Epoch: 5| Step: 8
Training loss: 1.1835167988856892
Validation loss: 2.197788660726723

Epoch: 5| Step: 9
Training loss: 0.9064623485263795
Validation loss: 2.1657760432728947

Epoch: 5| Step: 10
Training loss: 0.8100820288507513
Validation loss: 2.19804205568637

Epoch: 262| Step: 0
Training loss: 0.9345502223423517
Validation loss: 2.204201803953368

Epoch: 5| Step: 1
Training loss: 1.3047078296653623
Validation loss: 2.2074670719773573

Epoch: 5| Step: 2
Training loss: 0.9215373374528081
Validation loss: 2.1931768177075104

Epoch: 5| Step: 3
Training loss: 1.0922571075480616
Validation loss: 2.2296550776515884

Epoch: 5| Step: 4
Training loss: 0.7636184088290914
Validation loss: 2.209843265822297

Epoch: 5| Step: 5
Training loss: 0.6750347225653878
Validation loss: 2.2180951030238067

Epoch: 5| Step: 6
Training loss: 1.3428965231228691
Validation loss: 2.214788215657028

Epoch: 5| Step: 7
Training loss: 1.3717446371717203
Validation loss: 2.22868818227752

Epoch: 5| Step: 8
Training loss: 0.8129242742962295
Validation loss: 2.2359275337640865

Epoch: 5| Step: 9
Training loss: 1.1539105641898448
Validation loss: 2.257340281450263

Epoch: 5| Step: 10
Training loss: 1.1764222485765052
Validation loss: 2.2650571530882315

Epoch: 263| Step: 0
Training loss: 1.0585844032466174
Validation loss: 2.250295256767943

Epoch: 5| Step: 1
Training loss: 1.094778122653294
Validation loss: 2.2646578706519938

Epoch: 5| Step: 2
Training loss: 1.3037163323565812
Validation loss: 2.239960221565117

Epoch: 5| Step: 3
Training loss: 1.180474984779278
Validation loss: 2.2243814646309517

Epoch: 5| Step: 4
Training loss: 1.077474757383421
Validation loss: 2.2286844846630562

Epoch: 5| Step: 5
Training loss: 0.782418331113456
Validation loss: 2.2042189812648774

Epoch: 5| Step: 6
Training loss: 1.1379301557343178
Validation loss: 2.2444312190242512

Epoch: 5| Step: 7
Training loss: 0.9583278669671325
Validation loss: 2.2391767330673016

Epoch: 5| Step: 8
Training loss: 1.0514286698632314
Validation loss: 2.222067614230832

Epoch: 5| Step: 9
Training loss: 1.2505104453235167
Validation loss: 2.194651697257892

Epoch: 5| Step: 10
Training loss: 0.6771923393143492
Validation loss: 2.1855055851041714

Epoch: 264| Step: 0
Training loss: 0.952501124083489
Validation loss: 2.1990878263397433

Epoch: 5| Step: 1
Training loss: 1.2547962678388667
Validation loss: 2.2093060530357986

Epoch: 5| Step: 2
Training loss: 0.8328348496750066
Validation loss: 2.2080860994043183

Epoch: 5| Step: 3
Training loss: 0.8832282378698008
Validation loss: 2.2244190225845033

Epoch: 5| Step: 4
Training loss: 0.6169305097346055
Validation loss: 2.218651056574946

Epoch: 5| Step: 5
Training loss: 0.8754485887762177
Validation loss: 2.1925164136949102

Epoch: 5| Step: 6
Training loss: 1.0700003175645874
Validation loss: 2.181992815622782

Epoch: 5| Step: 7
Training loss: 1.3461518667541874
Validation loss: 2.1636243511170345

Epoch: 5| Step: 8
Training loss: 1.1432380531098898
Validation loss: 2.175325484645251

Epoch: 5| Step: 9
Training loss: 1.3301984421679194
Validation loss: 2.1921229744601733

Epoch: 5| Step: 10
Training loss: 1.0710279203812882
Validation loss: 2.1882020898883887

Epoch: 265| Step: 0
Training loss: 1.2557626452651338
Validation loss: 2.211838655726444

Epoch: 5| Step: 1
Training loss: 1.1046331907570637
Validation loss: 2.2230112606273

Epoch: 5| Step: 2
Training loss: 0.9344127366728862
Validation loss: 2.24274087795614

Epoch: 5| Step: 3
Training loss: 1.251389398879327
Validation loss: 2.2736917876533047

Epoch: 5| Step: 4
Training loss: 1.1577441381949818
Validation loss: 2.263142590349834

Epoch: 5| Step: 5
Training loss: 1.2146664210974245
Validation loss: 2.2356630796540906

Epoch: 5| Step: 6
Training loss: 0.9417764402788782
Validation loss: 2.218270387045925

Epoch: 5| Step: 7
Training loss: 0.8119811455435595
Validation loss: 2.2362947919960146

Epoch: 5| Step: 8
Training loss: 0.5424273419396574
Validation loss: 2.232493171403556

Epoch: 5| Step: 9
Training loss: 0.8151432470798539
Validation loss: 2.203758789165585

Epoch: 5| Step: 10
Training loss: 1.2903374118298663
Validation loss: 2.192769441100703

Epoch: 266| Step: 0
Training loss: 0.8039324653288122
Validation loss: 2.2065581277506485

Epoch: 5| Step: 1
Training loss: 0.9280655119355933
Validation loss: 2.2083502171157927

Epoch: 5| Step: 2
Training loss: 0.7054636316124322
Validation loss: 2.2056006127898735

Epoch: 5| Step: 3
Training loss: 0.8123762329909263
Validation loss: 2.2279811724172536

Epoch: 5| Step: 4
Training loss: 1.1107640770864347
Validation loss: 2.2228879447565575

Epoch: 5| Step: 5
Training loss: 1.0415013309237675
Validation loss: 2.236544016879335

Epoch: 5| Step: 6
Training loss: 1.246353935414904
Validation loss: 2.245049492771222

Epoch: 5| Step: 7
Training loss: 0.8344561205230624
Validation loss: 2.2443639725018

Epoch: 5| Step: 8
Training loss: 1.3715457008360354
Validation loss: 2.230648057054562

Epoch: 5| Step: 9
Training loss: 1.109652363664833
Validation loss: 2.2290834298826954

Epoch: 5| Step: 10
Training loss: 1.202093202141636
Validation loss: 2.228105423726869

Epoch: 267| Step: 0
Training loss: 0.6206603547443525
Validation loss: 2.222979426671235

Epoch: 5| Step: 1
Training loss: 0.9608198264419673
Validation loss: 2.2011427067909213

Epoch: 5| Step: 2
Training loss: 1.0166509288341024
Validation loss: 2.1950853598341373

Epoch: 5| Step: 3
Training loss: 1.2704034714072432
Validation loss: 2.182761356730804

Epoch: 5| Step: 4
Training loss: 0.8258545178090214
Validation loss: 2.1902924956452474

Epoch: 5| Step: 5
Training loss: 1.0106457060684422
Validation loss: 2.2074430324938437

Epoch: 5| Step: 6
Training loss: 1.2911685270177293
Validation loss: 2.2163108695884706

Epoch: 5| Step: 7
Training loss: 1.2470913902419258
Validation loss: 2.221058987420297

Epoch: 5| Step: 8
Training loss: 0.9887062335063517
Validation loss: 2.1888701347978237

Epoch: 5| Step: 9
Training loss: 1.1156440156229661
Validation loss: 2.2148069469916356

Epoch: 5| Step: 10
Training loss: 0.7439127896171084
Validation loss: 2.219927618973812

Epoch: 268| Step: 0
Training loss: 1.1703490940377481
Validation loss: 2.211374560609029

Epoch: 5| Step: 1
Training loss: 1.1464847909124032
Validation loss: 2.2182180132881166

Epoch: 5| Step: 2
Training loss: 0.8964489034312917
Validation loss: 2.212446227247828

Epoch: 5| Step: 3
Training loss: 1.2563945762984787
Validation loss: 2.1894813319090174

Epoch: 5| Step: 4
Training loss: 0.959490982152437
Validation loss: 2.201618264364676

Epoch: 5| Step: 5
Training loss: 1.0997974512712019
Validation loss: 2.1976533012801536

Epoch: 5| Step: 6
Training loss: 0.8970972762653631
Validation loss: 2.1853804848607896

Epoch: 5| Step: 7
Training loss: 1.1091522208022317
Validation loss: 2.187451874515617

Epoch: 5| Step: 8
Training loss: 0.8083053664321329
Validation loss: 2.242013318596442

Epoch: 5| Step: 9
Training loss: 0.9507246904938966
Validation loss: 2.238476910384553

Epoch: 5| Step: 10
Training loss: 0.8570456059382788
Validation loss: 2.2510390921654473

Epoch: 269| Step: 0
Training loss: 1.1143358021087943
Validation loss: 2.2743199715565394

Epoch: 5| Step: 1
Training loss: 0.6963526842495744
Validation loss: 2.2458636753401557

Epoch: 5| Step: 2
Training loss: 0.8324442809878639
Validation loss: 2.2494082156868433

Epoch: 5| Step: 3
Training loss: 1.0624401412258713
Validation loss: 2.2424114581796317

Epoch: 5| Step: 4
Training loss: 1.1050877537987136
Validation loss: 2.1891817744726763

Epoch: 5| Step: 5
Training loss: 0.8717176999627487
Validation loss: 2.19494570839675

Epoch: 5| Step: 6
Training loss: 0.8974153094061063
Validation loss: 2.1903081691632766

Epoch: 5| Step: 7
Training loss: 1.2401035510172058
Validation loss: 2.2018075705966695

Epoch: 5| Step: 8
Training loss: 1.2317585800023823
Validation loss: 2.1928103656591786

Epoch: 5| Step: 9
Training loss: 0.9326405147810684
Validation loss: 2.1717885931896506

Epoch: 5| Step: 10
Training loss: 1.0072516721710163
Validation loss: 2.2366044521425255

Epoch: 270| Step: 0
Training loss: 1.3704631692139695
Validation loss: 2.244656507748913

Epoch: 5| Step: 1
Training loss: 0.9109509972542423
Validation loss: 2.2503261597519724

Epoch: 5| Step: 2
Training loss: 0.8439505303470308
Validation loss: 2.22905588109533

Epoch: 5| Step: 3
Training loss: 1.0048091405437591
Validation loss: 2.2633140356371517

Epoch: 5| Step: 4
Training loss: 1.250936538806463
Validation loss: 2.282763234489208

Epoch: 5| Step: 5
Training loss: 0.9289263646905231
Validation loss: 2.23684357064284

Epoch: 5| Step: 6
Training loss: 0.8105654427113688
Validation loss: 2.2300528226558005

Epoch: 5| Step: 7
Training loss: 1.1158050306366445
Validation loss: 2.2094616171733823

Epoch: 5| Step: 8
Training loss: 1.0949808007564648
Validation loss: 2.2290893493743815

Epoch: 5| Step: 9
Training loss: 0.6794854664065816
Validation loss: 2.2072503741506897

Epoch: 5| Step: 10
Training loss: 0.6847428391490596
Validation loss: 2.212247971416806

Epoch: 271| Step: 0
Training loss: 0.5544033934795537
Validation loss: 2.2057402672329536

Epoch: 5| Step: 1
Training loss: 1.363218551986565
Validation loss: 2.204687058874984

Epoch: 5| Step: 2
Training loss: 1.2162893348127777
Validation loss: 2.2134000713849162

Epoch: 5| Step: 3
Training loss: 1.0709079283523844
Validation loss: 2.196329643090444

Epoch: 5| Step: 4
Training loss: 0.9305770529134861
Validation loss: 2.1729396023622964

Epoch: 5| Step: 5
Training loss: 0.8911002714696725
Validation loss: 2.1911924755578953

Epoch: 5| Step: 6
Training loss: 1.2034108701665436
Validation loss: 2.1938434856586198

Epoch: 5| Step: 7
Training loss: 0.6910584000393994
Validation loss: 2.181474986356864

Epoch: 5| Step: 8
Training loss: 0.8561426234615417
Validation loss: 2.189567994456171

Epoch: 5| Step: 9
Training loss: 0.8209299579298597
Validation loss: 2.193458502657287

Epoch: 5| Step: 10
Training loss: 1.0233374393848793
Validation loss: 2.196265078675353

Epoch: 272| Step: 0
Training loss: 1.2001694877459625
Validation loss: 2.197200737472495

Epoch: 5| Step: 1
Training loss: 0.5824729216507231
Validation loss: 2.1775852968477376

Epoch: 5| Step: 2
Training loss: 0.9722204189435191
Validation loss: 2.1738819974737353

Epoch: 5| Step: 3
Training loss: 0.9178380345554965
Validation loss: 2.1601355375387166

Epoch: 5| Step: 4
Training loss: 1.1077017186653544
Validation loss: 2.18338514366884

Epoch: 5| Step: 5
Training loss: 0.9935158375695353
Validation loss: 2.1898848476357244

Epoch: 5| Step: 6
Training loss: 1.1379765109837643
Validation loss: 2.184829169006365

Epoch: 5| Step: 7
Training loss: 1.0871005519518497
Validation loss: 2.2161179881771442

Epoch: 5| Step: 8
Training loss: 0.9472303246281776
Validation loss: 2.215849152137356

Epoch: 5| Step: 9
Training loss: 0.853428991185238
Validation loss: 2.2295102703842393

Epoch: 5| Step: 10
Training loss: 0.8124580372464641
Validation loss: 2.2182178301063664

Epoch: 273| Step: 0
Training loss: 0.9482715417500439
Validation loss: 2.2099645985797083

Epoch: 5| Step: 1
Training loss: 1.1937289251094934
Validation loss: 2.2167512521173016

Epoch: 5| Step: 2
Training loss: 1.1381356234528628
Validation loss: 2.199851577400251

Epoch: 5| Step: 3
Training loss: 1.1986439473612571
Validation loss: 2.180121119157682

Epoch: 5| Step: 4
Training loss: 1.0401929857856245
Validation loss: 2.176511793620218

Epoch: 5| Step: 5
Training loss: 0.9285435410388575
Validation loss: 2.163977426773121

Epoch: 5| Step: 6
Training loss: 1.0458200177767298
Validation loss: 2.183951377548579

Epoch: 5| Step: 7
Training loss: 0.8187498558568463
Validation loss: 2.1780932341525983

Epoch: 5| Step: 8
Training loss: 0.8267692768789909
Validation loss: 2.194766179868852

Epoch: 5| Step: 9
Training loss: 0.7112976671010877
Validation loss: 2.2058918955108116

Epoch: 5| Step: 10
Training loss: 0.8454340270960861
Validation loss: 2.2350854183855113

Epoch: 274| Step: 0
Training loss: 1.0290130281763576
Validation loss: 2.256768721520089

Epoch: 5| Step: 1
Training loss: 0.9664540925823393
Validation loss: 2.2692390615134705

Epoch: 5| Step: 2
Training loss: 0.8670425637586844
Validation loss: 2.2875380392244233

Epoch: 5| Step: 3
Training loss: 0.9059589839518274
Validation loss: 2.269133784639702

Epoch: 5| Step: 4
Training loss: 1.0312487284334608
Validation loss: 2.2375109983178376

Epoch: 5| Step: 5
Training loss: 0.6482308989320912
Validation loss: 2.2231017226676335

Epoch: 5| Step: 6
Training loss: 0.8362180649001055
Validation loss: 2.2180660417800713

Epoch: 5| Step: 7
Training loss: 1.1242231229759352
Validation loss: 2.203056716646219

Epoch: 5| Step: 8
Training loss: 1.0357572718095018
Validation loss: 2.1821985405253472

Epoch: 5| Step: 9
Training loss: 1.0641865527735275
Validation loss: 2.1742338118139184

Epoch: 5| Step: 10
Training loss: 1.1764077580027212
Validation loss: 2.1924456086597695

Epoch: 275| Step: 0
Training loss: 0.7088185686585436
Validation loss: 2.2136828772848003

Epoch: 5| Step: 1
Training loss: 1.117742120683031
Validation loss: 2.2268779514627237

Epoch: 5| Step: 2
Training loss: 1.0272447081425142
Validation loss: 2.196266657994974

Epoch: 5| Step: 3
Training loss: 1.0775653658199795
Validation loss: 2.2086473564038323

Epoch: 5| Step: 4
Training loss: 0.9103634970798702
Validation loss: 2.212901707212846

Epoch: 5| Step: 5
Training loss: 0.6908161640986378
Validation loss: 2.241738179083967

Epoch: 5| Step: 6
Training loss: 1.0943284821005301
Validation loss: 2.249656549057155

Epoch: 5| Step: 7
Training loss: 1.0071105878427749
Validation loss: 2.2465500240561407

Epoch: 5| Step: 8
Training loss: 0.5896179070012726
Validation loss: 2.2243639664510484

Epoch: 5| Step: 9
Training loss: 0.931170394874521
Validation loss: 2.230750459057306

Epoch: 5| Step: 10
Training loss: 1.2245001979997505
Validation loss: 2.235036731190659

Epoch: 276| Step: 0
Training loss: 0.8655191129516687
Validation loss: 2.224744533627087

Epoch: 5| Step: 1
Training loss: 0.42120831404991055
Validation loss: 2.224843849610365

Epoch: 5| Step: 2
Training loss: 0.6439140601495603
Validation loss: 2.2123660911052423

Epoch: 5| Step: 3
Training loss: 0.6751067483345734
Validation loss: 2.207098452116375

Epoch: 5| Step: 4
Training loss: 0.8095156808786974
Validation loss: 2.226194050212092

Epoch: 5| Step: 5
Training loss: 1.2792475800080376
Validation loss: 2.202219879619161

Epoch: 5| Step: 6
Training loss: 1.3087592632326581
Validation loss: 2.2093045938540072

Epoch: 5| Step: 7
Training loss: 0.9206754023991268
Validation loss: 2.230463837574241

Epoch: 5| Step: 8
Training loss: 1.0269459001207912
Validation loss: 2.2212174598365246

Epoch: 5| Step: 9
Training loss: 1.0152587230150762
Validation loss: 2.2058082972486925

Epoch: 5| Step: 10
Training loss: 1.1650486295807678
Validation loss: 2.205386450237738

Epoch: 277| Step: 0
Training loss: 0.7466598679738238
Validation loss: 2.2054764321135054

Epoch: 5| Step: 1
Training loss: 1.0988564225562811
Validation loss: 2.2156109416993592

Epoch: 5| Step: 2
Training loss: 0.6860123491399078
Validation loss: 2.224038673473853

Epoch: 5| Step: 3
Training loss: 0.474912287745068
Validation loss: 2.201990425820672

Epoch: 5| Step: 4
Training loss: 1.1262707421089477
Validation loss: 2.195897047559141

Epoch: 5| Step: 5
Training loss: 0.8301495330613479
Validation loss: 2.2107963498113015

Epoch: 5| Step: 6
Training loss: 1.0194160717911738
Validation loss: 2.2167085045323405

Epoch: 5| Step: 7
Training loss: 0.9120398419360903
Validation loss: 2.216873740205789

Epoch: 5| Step: 8
Training loss: 1.1082973350090155
Validation loss: 2.214288356919165

Epoch: 5| Step: 9
Training loss: 0.8429219456531091
Validation loss: 2.228096000357139

Epoch: 5| Step: 10
Training loss: 1.3086738220313314
Validation loss: 2.2222721106644516

Epoch: 278| Step: 0
Training loss: 0.8153092164002367
Validation loss: 2.2100790228241665

Epoch: 5| Step: 1
Training loss: 0.898138444304799
Validation loss: 2.1982389346100435

Epoch: 5| Step: 2
Training loss: 1.1408230857769697
Validation loss: 2.193469552731545

Epoch: 5| Step: 3
Training loss: 0.7857574893789898
Validation loss: 2.1875500323174375

Epoch: 5| Step: 4
Training loss: 1.115168260528637
Validation loss: 2.161679297928239

Epoch: 5| Step: 5
Training loss: 1.165328086693546
Validation loss: 2.1622911875117996

Epoch: 5| Step: 6
Training loss: 0.41206979787535664
Validation loss: 2.1749480780077177

Epoch: 5| Step: 7
Training loss: 0.9010520045104533
Validation loss: 2.188296397804307

Epoch: 5| Step: 8
Training loss: 1.1367365255637387
Validation loss: 2.176215298502329

Epoch: 5| Step: 9
Training loss: 0.8529296190153932
Validation loss: 2.1834391014646157

Epoch: 5| Step: 10
Training loss: 0.8642709504761482
Validation loss: 2.2178097017437275

Epoch: 279| Step: 0
Training loss: 0.7399724733542603
Validation loss: 2.237531305024109

Epoch: 5| Step: 1
Training loss: 0.9715326092460302
Validation loss: 2.2273979457546824

Epoch: 5| Step: 2
Training loss: 0.8834120815791316
Validation loss: 2.2356341900158245

Epoch: 5| Step: 3
Training loss: 0.9623085103966522
Validation loss: 2.2503477520573636

Epoch: 5| Step: 4
Training loss: 1.1547130989674985
Validation loss: 2.2208619506432172

Epoch: 5| Step: 5
Training loss: 0.6906239669239723
Validation loss: 2.244991058279547

Epoch: 5| Step: 6
Training loss: 0.7062053176788787
Validation loss: 2.1938323311281995

Epoch: 5| Step: 7
Training loss: 1.0685363846056601
Validation loss: 2.199649523293948

Epoch: 5| Step: 8
Training loss: 1.2162473365307584
Validation loss: 2.2062926364439024

Epoch: 5| Step: 9
Training loss: 0.412457540523205
Validation loss: 2.183781681518096

Epoch: 5| Step: 10
Training loss: 1.1300230211259132
Validation loss: 2.168101548097631

Epoch: 280| Step: 0
Training loss: 1.0524711208957322
Validation loss: 2.1900000588003166

Epoch: 5| Step: 1
Training loss: 1.2291456587122276
Validation loss: 2.195320418405643

Epoch: 5| Step: 2
Training loss: 0.9811167304538221
Validation loss: 2.1951092584458785

Epoch: 5| Step: 3
Training loss: 0.968807495625981
Validation loss: 2.1913788782995387

Epoch: 5| Step: 4
Training loss: 0.9168154675191684
Validation loss: 2.1866003597837547

Epoch: 5| Step: 5
Training loss: 0.8641043489058684
Validation loss: 2.201599622851135

Epoch: 5| Step: 6
Training loss: 0.7662542832147513
Validation loss: 2.173346991437892

Epoch: 5| Step: 7
Training loss: 0.7789318788342912
Validation loss: 2.211996207291644

Epoch: 5| Step: 8
Training loss: 0.7832514113003471
Validation loss: 2.213945972404249

Epoch: 5| Step: 9
Training loss: 0.8185270588316438
Validation loss: 2.225309277242655

Epoch: 5| Step: 10
Training loss: 0.8103460591667903
Validation loss: 2.2441483851111683

Epoch: 281| Step: 0
Training loss: 0.992833385349913
Validation loss: 2.210671381927401

Epoch: 5| Step: 1
Training loss: 0.870390946364474
Validation loss: 2.232795380128063

Epoch: 5| Step: 2
Training loss: 0.7160860117578048
Validation loss: 2.22160195578081

Epoch: 5| Step: 3
Training loss: 0.9738962626270248
Validation loss: 2.2407349823209413

Epoch: 5| Step: 4
Training loss: 0.7034773473583263
Validation loss: 2.212594061932435

Epoch: 5| Step: 5
Training loss: 0.9755152160243832
Validation loss: 2.217271683506912

Epoch: 5| Step: 6
Training loss: 0.8335705340083293
Validation loss: 2.2070053721965444

Epoch: 5| Step: 7
Training loss: 1.2564873675141328
Validation loss: 2.1976881710832656

Epoch: 5| Step: 8
Training loss: 0.6856309888051342
Validation loss: 2.184608038549398

Epoch: 5| Step: 9
Training loss: 0.8434608458503059
Validation loss: 2.1857236983665502

Epoch: 5| Step: 10
Training loss: 1.146193927321075
Validation loss: 2.203217729548482

Epoch: 282| Step: 0
Training loss: 0.9001060913392632
Validation loss: 2.19363987368151

Epoch: 5| Step: 1
Training loss: 0.904838976260362
Validation loss: 2.203401963416103

Epoch: 5| Step: 2
Training loss: 1.2245492631435027
Validation loss: 2.1879587328248666

Epoch: 5| Step: 3
Training loss: 0.9417484025731525
Validation loss: 2.223345607258713

Epoch: 5| Step: 4
Training loss: 0.8149229016725884
Validation loss: 2.244363664092367

Epoch: 5| Step: 5
Training loss: 0.9891750832070791
Validation loss: 2.2309634301237597

Epoch: 5| Step: 6
Training loss: 0.8536066840370422
Validation loss: 2.2132834709670073

Epoch: 5| Step: 7
Training loss: 0.7042895950897461
Validation loss: 2.1832993884791554

Epoch: 5| Step: 8
Training loss: 0.9731499518182732
Validation loss: 2.1526519350479645

Epoch: 5| Step: 9
Training loss: 0.9672208838794711
Validation loss: 2.158770005472682

Epoch: 5| Step: 10
Training loss: 0.9134182412006023
Validation loss: 2.1702918125757953

Epoch: 283| Step: 0
Training loss: 0.868457654435674
Validation loss: 2.1505080104397476

Epoch: 5| Step: 1
Training loss: 1.2872127323590177
Validation loss: 2.191247798302081

Epoch: 5| Step: 2
Training loss: 1.0299270119778032
Validation loss: 2.2050531718114184

Epoch: 5| Step: 3
Training loss: 1.0156180748336616
Validation loss: 2.1996357065222925

Epoch: 5| Step: 4
Training loss: 0.8615777655166797
Validation loss: 2.2017901090021246

Epoch: 5| Step: 5
Training loss: 0.8037886182249244
Validation loss: 2.229430327886539

Epoch: 5| Step: 6
Training loss: 0.7651325121035446
Validation loss: 2.2051161605429264

Epoch: 5| Step: 7
Training loss: 0.9664029021887433
Validation loss: 2.1994863842816823

Epoch: 5| Step: 8
Training loss: 0.5441495830294185
Validation loss: 2.1943816116768056

Epoch: 5| Step: 9
Training loss: 0.8382598845789045
Validation loss: 2.1723105512576137

Epoch: 5| Step: 10
Training loss: 0.8803845328914787
Validation loss: 2.1943728671228553

Epoch: 284| Step: 0
Training loss: 1.196876549782011
Validation loss: 2.1561798338718856

Epoch: 5| Step: 1
Training loss: 0.7034853965284672
Validation loss: 2.162702918242969

Epoch: 5| Step: 2
Training loss: 0.907334665154772
Validation loss: 2.1677229765902495

Epoch: 5| Step: 3
Training loss: 0.7113336989191195
Validation loss: 2.1493935679625253

Epoch: 5| Step: 4
Training loss: 0.5027559739625288
Validation loss: 2.1489864157510263

Epoch: 5| Step: 5
Training loss: 0.9628977127278598
Validation loss: 2.1879731388816963

Epoch: 5| Step: 6
Training loss: 1.0476739596037088
Validation loss: 2.1804799849564866

Epoch: 5| Step: 7
Training loss: 1.0054968912236866
Validation loss: 2.1885803057202766

Epoch: 5| Step: 8
Training loss: 0.8779288727923082
Validation loss: 2.207544104102628

Epoch: 5| Step: 9
Training loss: 0.7520155843580847
Validation loss: 2.1931463759875083

Epoch: 5| Step: 10
Training loss: 1.014040312208361
Validation loss: 2.2107562901780935

Epoch: 285| Step: 0
Training loss: 0.9838030834005435
Validation loss: 2.200993369148608

Epoch: 5| Step: 1
Training loss: 0.9831716660508641
Validation loss: 2.202037293754629

Epoch: 5| Step: 2
Training loss: 0.8428304040780088
Validation loss: 2.1919275119776604

Epoch: 5| Step: 3
Training loss: 0.9983842134061329
Validation loss: 2.1807863747937586

Epoch: 5| Step: 4
Training loss: 0.9961325245210556
Validation loss: 2.1915455988229913

Epoch: 5| Step: 5
Training loss: 0.761103063349009
Validation loss: 2.2061336747069507

Epoch: 5| Step: 6
Training loss: 0.7875336291686427
Validation loss: 2.2121831322301007

Epoch: 5| Step: 7
Training loss: 0.5383641238702719
Validation loss: 2.2067341794690924

Epoch: 5| Step: 8
Training loss: 0.8321168524177213
Validation loss: 2.2175102704669722

Epoch: 5| Step: 9
Training loss: 0.9297594635623618
Validation loss: 2.195631205894385

Epoch: 5| Step: 10
Training loss: 0.9667173102420378
Validation loss: 2.200341088971415

Epoch: 286| Step: 0
Training loss: 0.5181684186847932
Validation loss: 2.17870663556198

Epoch: 5| Step: 1
Training loss: 1.0465287732043163
Validation loss: 2.1976344791489435

Epoch: 5| Step: 2
Training loss: 0.990151155424684
Validation loss: 2.197856781441186

Epoch: 5| Step: 3
Training loss: 0.8098042958691839
Validation loss: 2.1777794979921725

Epoch: 5| Step: 4
Training loss: 1.0213666158744503
Validation loss: 2.183920156323571

Epoch: 5| Step: 5
Training loss: 1.049671026193145
Validation loss: 2.1630392504867837

Epoch: 5| Step: 6
Training loss: 0.8452486574669471
Validation loss: 2.1764445257947176

Epoch: 5| Step: 7
Training loss: 0.6824254761345914
Validation loss: 2.1917197865752387

Epoch: 5| Step: 8
Training loss: 0.7739076822854122
Validation loss: 2.203268554544063

Epoch: 5| Step: 9
Training loss: 0.7538475053264594
Validation loss: 2.203967793510688

Epoch: 5| Step: 10
Training loss: 1.0002358277720071
Validation loss: 2.1865983443719013

Epoch: 287| Step: 0
Training loss: 0.9627073782909428
Validation loss: 2.202210881852841

Epoch: 5| Step: 1
Training loss: 0.7806849916127859
Validation loss: 2.1854194204323907

Epoch: 5| Step: 2
Training loss: 1.0119726974325027
Validation loss: 2.182180092607656

Epoch: 5| Step: 3
Training loss: 0.7052759120309331
Validation loss: 2.1976979785531485

Epoch: 5| Step: 4
Training loss: 0.9872405411495847
Validation loss: 2.2141082115861006

Epoch: 5| Step: 5
Training loss: 1.1153107999412981
Validation loss: 2.186349970209815

Epoch: 5| Step: 6
Training loss: 0.5389987520865183
Validation loss: 2.209463765469733

Epoch: 5| Step: 7
Training loss: 0.8868912852474307
Validation loss: 2.2219678337950937

Epoch: 5| Step: 8
Training loss: 0.8110615394705945
Validation loss: 2.2131115787396607

Epoch: 5| Step: 9
Training loss: 0.6807052183912599
Validation loss: 2.209450184987631

Epoch: 5| Step: 10
Training loss: 0.8853450671398896
Validation loss: 2.176331769282755

Epoch: 288| Step: 0
Training loss: 0.8024575157447248
Validation loss: 2.198959456825056

Epoch: 5| Step: 1
Training loss: 0.7407871487327724
Validation loss: 2.218459619160078

Epoch: 5| Step: 2
Training loss: 0.8544530194706157
Validation loss: 2.1928461495434384

Epoch: 5| Step: 3
Training loss: 0.8448450964523092
Validation loss: 2.164719979832294

Epoch: 5| Step: 4
Training loss: 0.8037197627050024
Validation loss: 2.1720843594521835

Epoch: 5| Step: 5
Training loss: 1.0000162719356358
Validation loss: 2.1505306663579753

Epoch: 5| Step: 6
Training loss: 0.8974790685438999
Validation loss: 2.18506649857122

Epoch: 5| Step: 7
Training loss: 0.8123299714226148
Validation loss: 2.163190297559023

Epoch: 5| Step: 8
Training loss: 0.9268350840312317
Validation loss: 2.1670410347129367

Epoch: 5| Step: 9
Training loss: 0.798329913809613
Validation loss: 2.178380604899425

Epoch: 5| Step: 10
Training loss: 0.9119708591143073
Validation loss: 2.2072795397570686

Epoch: 289| Step: 0
Training loss: 1.0386852067003574
Validation loss: 2.196636316819827

Epoch: 5| Step: 1
Training loss: 1.0103731965352483
Validation loss: 2.2222486345283627

Epoch: 5| Step: 2
Training loss: 0.8951381307170753
Validation loss: 2.1944553449308173

Epoch: 5| Step: 3
Training loss: 0.89201905085016
Validation loss: 2.2087394525117903

Epoch: 5| Step: 4
Training loss: 0.9559246594357552
Validation loss: 2.190364482178064

Epoch: 5| Step: 5
Training loss: 0.7643227693643163
Validation loss: 2.1923727210736867

Epoch: 5| Step: 6
Training loss: 0.62176177848792
Validation loss: 2.204520669051575

Epoch: 5| Step: 7
Training loss: 0.880271461675884
Validation loss: 2.207975614771166

Epoch: 5| Step: 8
Training loss: 0.6930927892411942
Validation loss: 2.2077753736254695

Epoch: 5| Step: 9
Training loss: 0.7993715112295365
Validation loss: 2.1888530982175287

Epoch: 5| Step: 10
Training loss: 0.6857936664881794
Validation loss: 2.1724413085276355

Epoch: 290| Step: 0
Training loss: 0.7892436584396719
Validation loss: 2.1988180932816146

Epoch: 5| Step: 1
Training loss: 0.9446196105367147
Validation loss: 2.1923493562616714

Epoch: 5| Step: 2
Training loss: 0.7742136134218797
Validation loss: 2.1866533425246812

Epoch: 5| Step: 3
Training loss: 0.9075435417280505
Validation loss: 2.211487779905299

Epoch: 5| Step: 4
Training loss: 0.8660827679516783
Validation loss: 2.229705808218149

Epoch: 5| Step: 5
Training loss: 0.6459652755663797
Validation loss: 2.231003738527122

Epoch: 5| Step: 6
Training loss: 1.0336066973993312
Validation loss: 2.2165319947567346

Epoch: 5| Step: 7
Training loss: 0.7752420585764382
Validation loss: 2.22142071891065

Epoch: 5| Step: 8
Training loss: 1.0300672858213666
Validation loss: 2.2086441260931693

Epoch: 5| Step: 9
Training loss: 0.717716884331407
Validation loss: 2.199804477309409

Epoch: 5| Step: 10
Training loss: 0.6446685413599945
Validation loss: 2.1874449141403356

Epoch: 291| Step: 0
Training loss: 0.7847722950903969
Validation loss: 2.1923347848467505

Epoch: 5| Step: 1
Training loss: 0.6433571264787025
Validation loss: 2.1982771482555896

Epoch: 5| Step: 2
Training loss: 0.9186548469211704
Validation loss: 2.210248523750113

Epoch: 5| Step: 3
Training loss: 0.9985282617904557
Validation loss: 2.2033315198282497

Epoch: 5| Step: 4
Training loss: 0.5755442676404869
Validation loss: 2.2151165400124717

Epoch: 5| Step: 5
Training loss: 1.0816770448955828
Validation loss: 2.2259893301731206

Epoch: 5| Step: 6
Training loss: 0.6794699397423842
Validation loss: 2.215670823287056

Epoch: 5| Step: 7
Training loss: 0.9027338216954066
Validation loss: 2.2070480193585396

Epoch: 5| Step: 8
Training loss: 0.7105272807334089
Validation loss: 2.209020126667246

Epoch: 5| Step: 9
Training loss: 0.8963785877850192
Validation loss: 2.2232418137081464

Epoch: 5| Step: 10
Training loss: 0.8467685604420818
Validation loss: 2.1519343903252164

Epoch: 292| Step: 0
Training loss: 0.8821503510661541
Validation loss: 2.170125277590708

Epoch: 5| Step: 1
Training loss: 0.8807829762418707
Validation loss: 2.162437502623992

Epoch: 5| Step: 2
Training loss: 0.8898693024112251
Validation loss: 2.1745162868346357

Epoch: 5| Step: 3
Training loss: 0.6047189315000002
Validation loss: 2.1257051435601824

Epoch: 5| Step: 4
Training loss: 0.8301731548889281
Validation loss: 2.167014946723517

Epoch: 5| Step: 5
Training loss: 0.9377293624051127
Validation loss: 2.1598858004141883

Epoch: 5| Step: 6
Training loss: 0.7970149347444812
Validation loss: 2.1525761761865465

Epoch: 5| Step: 7
Training loss: 0.5506899061279239
Validation loss: 2.1813504329771813

Epoch: 5| Step: 8
Training loss: 0.7161996624685609
Validation loss: 2.1989829478452796

Epoch: 5| Step: 9
Training loss: 1.048156523256075
Validation loss: 2.2074263233336535

Epoch: 5| Step: 10
Training loss: 0.8850168709305293
Validation loss: 2.1952152370054816

Epoch: 293| Step: 0
Training loss: 0.7781733394452998
Validation loss: 2.2019812970126376

Epoch: 5| Step: 1
Training loss: 0.8470151032268858
Validation loss: 2.2006805794935635

Epoch: 5| Step: 2
Training loss: 0.39663407830333136
Validation loss: 2.186633223690231

Epoch: 5| Step: 3
Training loss: 0.9096066039063737
Validation loss: 2.180057157469187

Epoch: 5| Step: 4
Training loss: 0.5910449649161641
Validation loss: 2.158797034167889

Epoch: 5| Step: 5
Training loss: 0.8539137271927177
Validation loss: 2.183030664565396

Epoch: 5| Step: 6
Training loss: 0.7594929183644881
Validation loss: 2.1774467647320646

Epoch: 5| Step: 7
Training loss: 1.0431022987158272
Validation loss: 2.181847682645376

Epoch: 5| Step: 8
Training loss: 1.163132468829396
Validation loss: 2.2064345063878177

Epoch: 5| Step: 9
Training loss: 0.9666883003072224
Validation loss: 2.174764417262061

Epoch: 5| Step: 10
Training loss: 0.40761631671719284
Validation loss: 2.17862997233117

Epoch: 294| Step: 0
Training loss: 0.9854804598353151
Validation loss: 2.193838578279875

Epoch: 5| Step: 1
Training loss: 1.036204947676017
Validation loss: 2.1829547668092464

Epoch: 5| Step: 2
Training loss: 0.533465394294718
Validation loss: 2.2083116858457057

Epoch: 5| Step: 3
Training loss: 0.7607555461685137
Validation loss: 2.2003471941422728

Epoch: 5| Step: 4
Training loss: 0.8389533357271669
Validation loss: 2.1889598469656586

Epoch: 5| Step: 5
Training loss: 1.1382632430202917
Validation loss: 2.1823253597174745

Epoch: 5| Step: 6
Training loss: 0.9004450717442715
Validation loss: 2.218450855688798

Epoch: 5| Step: 7
Training loss: 0.640884393419681
Validation loss: 2.195001225026985

Epoch: 5| Step: 8
Training loss: 0.7046062549522408
Validation loss: 2.2088898611269134

Epoch: 5| Step: 9
Training loss: 0.7123087559409407
Validation loss: 2.21651489320496

Epoch: 5| Step: 10
Training loss: 0.4391855569712081
Validation loss: 2.2016319199388015

Epoch: 295| Step: 0
Training loss: 0.6743470336234485
Validation loss: 2.1853802866091394

Epoch: 5| Step: 1
Training loss: 0.9487626035453758
Validation loss: 2.178309540457856

Epoch: 5| Step: 2
Training loss: 0.6415449608116196
Validation loss: 2.144267714039099

Epoch: 5| Step: 3
Training loss: 0.9955546397451416
Validation loss: 2.1486989329287463

Epoch: 5| Step: 4
Training loss: 0.810607613735175
Validation loss: 2.1660568615230082

Epoch: 5| Step: 5
Training loss: 0.8483912713539312
Validation loss: 2.1442838740166295

Epoch: 5| Step: 6
Training loss: 0.9542934572249993
Validation loss: 2.1649591159548183

Epoch: 5| Step: 7
Training loss: 0.6197047025646467
Validation loss: 2.202877377817001

Epoch: 5| Step: 8
Training loss: 0.5582888911717508
Validation loss: 2.17908980184734

Epoch: 5| Step: 9
Training loss: 0.8563855279741119
Validation loss: 2.194379004086007

Epoch: 5| Step: 10
Training loss: 0.9028924371988836
Validation loss: 2.1737081831482676

Epoch: 296| Step: 0
Training loss: 1.0611170576060998
Validation loss: 2.202777108680186

Epoch: 5| Step: 1
Training loss: 1.1031758283192512
Validation loss: 2.1926587008837704

Epoch: 5| Step: 2
Training loss: 0.6166452850896462
Validation loss: 2.1892106184075395

Epoch: 5| Step: 3
Training loss: 0.8134144258981871
Validation loss: 2.183247453369974

Epoch: 5| Step: 4
Training loss: 0.6619079193343442
Validation loss: 2.1721615033184984

Epoch: 5| Step: 5
Training loss: 0.6478587405773438
Validation loss: 2.192143412170748

Epoch: 5| Step: 6
Training loss: 0.47394769957074984
Validation loss: 2.2037927189818456

Epoch: 5| Step: 7
Training loss: 0.9047432903685041
Validation loss: 2.2270912266580667

Epoch: 5| Step: 8
Training loss: 0.8867355210655009
Validation loss: 2.2739813544250436

Epoch: 5| Step: 9
Training loss: 0.8301915349341747
Validation loss: 2.259348752070685

Epoch: 5| Step: 10
Training loss: 0.8470106347057075
Validation loss: 2.220517233621273

Epoch: 297| Step: 0
Training loss: 0.6294736494316715
Validation loss: 2.2392664687830197

Epoch: 5| Step: 1
Training loss: 0.9363368766417047
Validation loss: 2.2023888810321073

Epoch: 5| Step: 2
Training loss: 0.9781257629391555
Validation loss: 2.1819817397377306

Epoch: 5| Step: 3
Training loss: 0.7717884092371513
Validation loss: 2.1567225925898184

Epoch: 5| Step: 4
Training loss: 0.7180504919431484
Validation loss: 2.159996375861749

Epoch: 5| Step: 5
Training loss: 0.8034548902020571
Validation loss: 2.174004403014682

Epoch: 5| Step: 6
Training loss: 0.8676229191414254
Validation loss: 2.1688986180476744

Epoch: 5| Step: 7
Training loss: 0.6463601952537286
Validation loss: 2.172255335128983

Epoch: 5| Step: 8
Training loss: 1.0254703745029177
Validation loss: 2.1937819524466224

Epoch: 5| Step: 9
Training loss: 0.7881305213994977
Validation loss: 2.1719823394523408

Epoch: 5| Step: 10
Training loss: 0.6699224533212017
Validation loss: 2.1678011247684412

Epoch: 298| Step: 0
Training loss: 0.9651474880014083
Validation loss: 2.1909454202179215

Epoch: 5| Step: 1
Training loss: 0.9068218597364468
Validation loss: 2.1981307485674044

Epoch: 5| Step: 2
Training loss: 0.8802702767209797
Validation loss: 2.1972978250748803

Epoch: 5| Step: 3
Training loss: 0.7915699088212613
Validation loss: 2.1853348753630883

Epoch: 5| Step: 4
Training loss: 0.828068785288916
Validation loss: 2.1459599198842767

Epoch: 5| Step: 5
Training loss: 0.513863009439822
Validation loss: 2.1674781960475995

Epoch: 5| Step: 6
Training loss: 0.8287498348115092
Validation loss: 2.181332312837065

Epoch: 5| Step: 7
Training loss: 0.7400687643913094
Validation loss: 2.2006940611966663

Epoch: 5| Step: 8
Training loss: 0.6266624038082917
Validation loss: 2.1761515121112045

Epoch: 5| Step: 9
Training loss: 0.8544524614091389
Validation loss: 2.208247405005854

Epoch: 5| Step: 10
Training loss: 0.8549216624394504
Validation loss: 2.195030276297869

Epoch: 299| Step: 0
Training loss: 0.8771383858722528
Validation loss: 2.2077810344061017

Epoch: 5| Step: 1
Training loss: 0.7703550934380599
Validation loss: 2.1817035582062427

Epoch: 5| Step: 2
Training loss: 0.9847329109686668
Validation loss: 2.2094181286620196

Epoch: 5| Step: 3
Training loss: 0.4737777959978127
Validation loss: 2.180683550729136

Epoch: 5| Step: 4
Training loss: 0.5103500640648597
Validation loss: 2.1464021995771185

Epoch: 5| Step: 5
Training loss: 0.9762865210624343
Validation loss: 2.148904699872375

Epoch: 5| Step: 6
Training loss: 0.7785064589539354
Validation loss: 2.1585965792508794

Epoch: 5| Step: 7
Training loss: 0.7288164024134054
Validation loss: 2.1649753216061614

Epoch: 5| Step: 8
Training loss: 0.728271934516811
Validation loss: 2.145498750154741

Epoch: 5| Step: 9
Training loss: 1.0408676070858636
Validation loss: 2.142036265596967

Epoch: 5| Step: 10
Training loss: 0.5776131916172353
Validation loss: 2.1539826982586168

Epoch: 300| Step: 0
Training loss: 0.8792435401525182
Validation loss: 2.156683069997159

Epoch: 5| Step: 1
Training loss: 0.6709698190709441
Validation loss: 2.1955652279405715

Epoch: 5| Step: 2
Training loss: 0.7069112559969669
Validation loss: 2.157577728870219

Epoch: 5| Step: 3
Training loss: 0.5670100446800314
Validation loss: 2.2043163412582443

Epoch: 5| Step: 4
Training loss: 1.203258457460844
Validation loss: 2.1914239347168856

Epoch: 5| Step: 5
Training loss: 0.733315291688528
Validation loss: 2.1952385970067803

Epoch: 5| Step: 6
Training loss: 0.8265479203724904
Validation loss: 2.1635464182139685

Epoch: 5| Step: 7
Training loss: 0.9080917454174979
Validation loss: 2.167050845428712

Epoch: 5| Step: 8
Training loss: 0.7024142593787263
Validation loss: 2.168872240349871

Epoch: 5| Step: 9
Training loss: 0.7155082824009067
Validation loss: 2.1464282174070157

Epoch: 5| Step: 10
Training loss: 0.5152527303368839
Validation loss: 2.1202009215717377

Epoch: 301| Step: 0
Training loss: 0.8529995333456751
Validation loss: 2.154653422089522

Epoch: 5| Step: 1
Training loss: 1.0848178168252949
Validation loss: 2.167252364006641

Epoch: 5| Step: 2
Training loss: 0.7372248928520293
Validation loss: 2.1619748570405397

Epoch: 5| Step: 3
Training loss: 0.9651036703921979
Validation loss: 2.1341246659407713

Epoch: 5| Step: 4
Training loss: 0.6913249081107748
Validation loss: 2.1463853060630087

Epoch: 5| Step: 5
Training loss: 0.8100783499159029
Validation loss: 2.142611432308074

Epoch: 5| Step: 6
Training loss: 0.453136443947285
Validation loss: 2.1553289185877573

Epoch: 5| Step: 7
Training loss: 0.635604679454265
Validation loss: 2.1450926588300887

Epoch: 5| Step: 8
Training loss: 0.7722432327690261
Validation loss: 2.1546886415384923

Epoch: 5| Step: 9
Training loss: 0.7255914823954307
Validation loss: 2.1561703939962955

Epoch: 5| Step: 10
Training loss: 0.7040693722798839
Validation loss: 2.1495210166501586

Epoch: 302| Step: 0
Training loss: 0.9415095735570665
Validation loss: 2.158399969176074

Epoch: 5| Step: 1
Training loss: 0.5128936674517351
Validation loss: 2.147388165153264

Epoch: 5| Step: 2
Training loss: 0.6381837104966539
Validation loss: 2.145051369467265

Epoch: 5| Step: 3
Training loss: 0.964315231063232
Validation loss: 2.163049685581535

Epoch: 5| Step: 4
Training loss: 0.799112246102054
Validation loss: 2.135980302292226

Epoch: 5| Step: 5
Training loss: 0.7906872479808739
Validation loss: 2.15554737962667

Epoch: 5| Step: 6
Training loss: 0.6229691651292446
Validation loss: 2.156565157041376

Epoch: 5| Step: 7
Training loss: 0.7056875791413653
Validation loss: 2.1590428870979474

Epoch: 5| Step: 8
Training loss: 0.8494462481462174
Validation loss: 2.167305403365498

Epoch: 5| Step: 9
Training loss: 0.917505122853875
Validation loss: 2.191633934061353

Epoch: 5| Step: 10
Training loss: 0.5408018495460348
Validation loss: 2.17835683345213

Epoch: 303| Step: 0
Training loss: 0.7789181431940359
Validation loss: 2.162349023906592

Epoch: 5| Step: 1
Training loss: 0.891453274181108
Validation loss: 2.1574387854266437

Epoch: 5| Step: 2
Training loss: 0.5416340512457674
Validation loss: 2.161648007632711

Epoch: 5| Step: 3
Training loss: 0.622565152002834
Validation loss: 2.151684723597965

Epoch: 5| Step: 4
Training loss: 0.7197434981073324
Validation loss: 2.146584580507449

Epoch: 5| Step: 5
Training loss: 1.1603911704658814
Validation loss: 2.143995337952143

Epoch: 5| Step: 6
Training loss: 0.8354527146195488
Validation loss: 2.1532241922983695

Epoch: 5| Step: 7
Training loss: 0.9409013082536734
Validation loss: 2.145600810974497

Epoch: 5| Step: 8
Training loss: 0.5858717309279868
Validation loss: 2.1336542159135674

Epoch: 5| Step: 9
Training loss: 0.4184163807160971
Validation loss: 2.124659003610146

Epoch: 5| Step: 10
Training loss: 0.5849194392544236
Validation loss: 2.149783332640751

Epoch: 304| Step: 0
Training loss: 0.5670137239019752
Validation loss: 2.1479556572349328

Epoch: 5| Step: 1
Training loss: 0.7109024961468785
Validation loss: 2.1704227481610903

Epoch: 5| Step: 2
Training loss: 0.5594099257663641
Validation loss: 2.152877996504461

Epoch: 5| Step: 3
Training loss: 0.7605491853668122
Validation loss: 2.2031491988892427

Epoch: 5| Step: 4
Training loss: 0.7706504467353968
Validation loss: 2.1773313102521494

Epoch: 5| Step: 5
Training loss: 0.8195382597035292
Validation loss: 2.177126406583881

Epoch: 5| Step: 6
Training loss: 0.9423318009084631
Validation loss: 2.1601553634715613

Epoch: 5| Step: 7
Training loss: 0.8008727602890894
Validation loss: 2.1636583243938614

Epoch: 5| Step: 8
Training loss: 0.37586896273195397
Validation loss: 2.1473539344663375

Epoch: 5| Step: 9
Training loss: 0.9589256377402343
Validation loss: 2.165927935748698

Epoch: 5| Step: 10
Training loss: 0.890777307169428
Validation loss: 2.1774592329480695

Epoch: 305| Step: 0
Training loss: 0.6277487866516419
Validation loss: 2.153234174907314

Epoch: 5| Step: 1
Training loss: 0.6266601686149217
Validation loss: 2.1384937100723334

Epoch: 5| Step: 2
Training loss: 0.6770584737664512
Validation loss: 2.1739046332672354

Epoch: 5| Step: 3
Training loss: 0.83343430543165
Validation loss: 2.1530593871360257

Epoch: 5| Step: 4
Training loss: 0.5247816789905069
Validation loss: 2.1928104276221068

Epoch: 5| Step: 5
Training loss: 0.6088742374954978
Validation loss: 2.1583903388735624

Epoch: 5| Step: 6
Training loss: 0.990331490774847
Validation loss: 2.1635057411274374

Epoch: 5| Step: 7
Training loss: 0.9206799665669432
Validation loss: 2.1501200499599653

Epoch: 5| Step: 8
Training loss: 0.8966470209318863
Validation loss: 2.1648368061778953

Epoch: 5| Step: 9
Training loss: 0.7429954548076779
Validation loss: 2.1024252029662924

Epoch: 5| Step: 10
Training loss: 0.6711205305056169
Validation loss: 2.1488822349918597

Epoch: 306| Step: 0
Training loss: 0.795139104981002
Validation loss: 2.1591072875719206

Epoch: 5| Step: 1
Training loss: 0.5928897900587419
Validation loss: 2.1832339455418825

Epoch: 5| Step: 2
Training loss: 0.5705256129239851
Validation loss: 2.163276181815217

Epoch: 5| Step: 3
Training loss: 0.4823043618340527
Validation loss: 2.1786775560738105

Epoch: 5| Step: 4
Training loss: 0.7498283984645152
Validation loss: 2.183224458836285

Epoch: 5| Step: 5
Training loss: 0.46085206549319113
Validation loss: 2.173046046299942

Epoch: 5| Step: 6
Training loss: 0.6862517425640058
Validation loss: 2.1639105287106504

Epoch: 5| Step: 7
Training loss: 1.1255645395125204
Validation loss: 2.191212873978815

Epoch: 5| Step: 8
Training loss: 0.8562348997914712
Validation loss: 2.1837309870289694

Epoch: 5| Step: 9
Training loss: 0.7765978584452575
Validation loss: 2.163602697280945

Epoch: 5| Step: 10
Training loss: 0.8064259758458245
Validation loss: 2.170933435324844

Epoch: 307| Step: 0
Training loss: 0.5438810957801768
Validation loss: 2.167604362021155

Epoch: 5| Step: 1
Training loss: 0.9837185017779242
Validation loss: 2.166717544870164

Epoch: 5| Step: 2
Training loss: 0.848182971634462
Validation loss: 2.179069474649507

Epoch: 5| Step: 3
Training loss: 0.7822461453199887
Validation loss: 2.1504108179550387

Epoch: 5| Step: 4
Training loss: 0.8261498703066549
Validation loss: 2.151844845341362

Epoch: 5| Step: 5
Training loss: 0.5693308599386306
Validation loss: 2.1682186220322595

Epoch: 5| Step: 6
Training loss: 0.6833499800778849
Validation loss: 2.1746973647537393

Epoch: 5| Step: 7
Training loss: 0.5644490858943261
Validation loss: 2.170199507448463

Epoch: 5| Step: 8
Training loss: 0.48421007855785275
Validation loss: 2.1759546149385423

Epoch: 5| Step: 9
Training loss: 0.6850219847290663
Validation loss: 2.173512034620958

Epoch: 5| Step: 10
Training loss: 0.9907589939122149
Validation loss: 2.1479369939898882

Epoch: 308| Step: 0
Training loss: 0.6459404769334262
Validation loss: 2.1644748821845767

Epoch: 5| Step: 1
Training loss: 0.6471795438667014
Validation loss: 2.1713874271379243

Epoch: 5| Step: 2
Training loss: 0.675461754216665
Validation loss: 2.1747530758723124

Epoch: 5| Step: 3
Training loss: 0.6957571986419194
Validation loss: 2.166461811446538

Epoch: 5| Step: 4
Training loss: 0.47590872211078494
Validation loss: 2.1820179708437526

Epoch: 5| Step: 5
Training loss: 0.9261319425767773
Validation loss: 2.1825149251201093

Epoch: 5| Step: 6
Training loss: 0.7740985472951942
Validation loss: 2.151201664468118

Epoch: 5| Step: 7
Training loss: 1.030322900823151
Validation loss: 2.174368298829537

Epoch: 5| Step: 8
Training loss: 0.6029226111765105
Validation loss: 2.1874634430580353

Epoch: 5| Step: 9
Training loss: 0.6338536915794312
Validation loss: 2.220821547627515

Epoch: 5| Step: 10
Training loss: 0.8072654760890902
Validation loss: 2.1560220959081513

Epoch: 309| Step: 0
Training loss: 0.7652125902176068
Validation loss: 2.1373919233656413

Epoch: 5| Step: 1
Training loss: 0.6852773587618559
Validation loss: 2.151964465562498

Epoch: 5| Step: 2
Training loss: 0.5694193966972835
Validation loss: 2.170291852738035

Epoch: 5| Step: 3
Training loss: 0.9620581194675608
Validation loss: 2.1686649841211483

Epoch: 5| Step: 4
Training loss: 0.5246988159195408
Validation loss: 2.16779645645169

Epoch: 5| Step: 5
Training loss: 0.6117942666008032
Validation loss: 2.18132999462823

Epoch: 5| Step: 6
Training loss: 0.9341653008044078
Validation loss: 2.203407896054005

Epoch: 5| Step: 7
Training loss: 0.582361294149733
Validation loss: 2.203565446016381

Epoch: 5| Step: 8
Training loss: 0.6612071639249814
Validation loss: 2.1811117082154174

Epoch: 5| Step: 9
Training loss: 0.7632819543716164
Validation loss: 2.2012857139694817

Epoch: 5| Step: 10
Training loss: 0.7855377788576653
Validation loss: 2.2104744960681604

Epoch: 310| Step: 0
Training loss: 0.32932181303503105
Validation loss: 2.2250808066055257

Epoch: 5| Step: 1
Training loss: 0.4790324786858109
Validation loss: 2.2173371947824427

Epoch: 5| Step: 2
Training loss: 0.8895445510724816
Validation loss: 2.17804210947256

Epoch: 5| Step: 3
Training loss: 0.7329033654982913
Validation loss: 2.1738878278832603

Epoch: 5| Step: 4
Training loss: 0.4896415073922321
Validation loss: 2.160772396582339

Epoch: 5| Step: 5
Training loss: 0.9970865126890023
Validation loss: 2.143611109332041

Epoch: 5| Step: 6
Training loss: 0.5082580079359269
Validation loss: 2.145414871533624

Epoch: 5| Step: 7
Training loss: 0.8492209763484573
Validation loss: 2.1520612424184358

Epoch: 5| Step: 8
Training loss: 0.704312148856843
Validation loss: 2.162205164831925

Epoch: 5| Step: 9
Training loss: 0.7757723850999945
Validation loss: 2.163554835313633

Epoch: 5| Step: 10
Training loss: 0.9139756381504752
Validation loss: 2.182442861894499

Epoch: 311| Step: 0
Training loss: 0.7183379775278496
Validation loss: 2.172106180718747

Epoch: 5| Step: 1
Training loss: 0.8220366025372287
Validation loss: 2.138988014163026

Epoch: 5| Step: 2
Training loss: 0.7306693714461883
Validation loss: 2.1631514365242617

Epoch: 5| Step: 3
Training loss: 0.7772237023671311
Validation loss: 2.1562263793032006

Epoch: 5| Step: 4
Training loss: 0.8071447833577162
Validation loss: 2.1693355267664627

Epoch: 5| Step: 5
Training loss: 0.6041698921599831
Validation loss: 2.1741408489368474

Epoch: 5| Step: 6
Training loss: 0.5375531392111281
Validation loss: 2.161076829147714

Epoch: 5| Step: 7
Training loss: 0.6498080557072873
Validation loss: 2.1588120828182706

Epoch: 5| Step: 8
Training loss: 0.7791129447314047
Validation loss: 2.1566763039286574

Epoch: 5| Step: 9
Training loss: 0.440577987435477
Validation loss: 2.144746801204345

Epoch: 5| Step: 10
Training loss: 0.9750233843028786
Validation loss: 2.1306659212933283

Epoch: 312| Step: 0
Training loss: 0.7075538179397147
Validation loss: 2.1443837011575733

Epoch: 5| Step: 1
Training loss: 0.8477178806102617
Validation loss: 2.1486669870906243

Epoch: 5| Step: 2
Training loss: 0.6145191940416974
Validation loss: 2.1372571235707594

Epoch: 5| Step: 3
Training loss: 0.8743060289165686
Validation loss: 2.1361586963509502

Epoch: 5| Step: 4
Training loss: 0.8149476231085894
Validation loss: 2.165494387134095

Epoch: 5| Step: 5
Training loss: 0.5030122263315473
Validation loss: 2.1670845727526027

Epoch: 5| Step: 6
Training loss: 0.44609778581119786
Validation loss: 2.1753183069244177

Epoch: 5| Step: 7
Training loss: 0.562642768119941
Validation loss: 2.198567828825199

Epoch: 5| Step: 8
Training loss: 0.8707334175162784
Validation loss: 2.1740802126028003

Epoch: 5| Step: 9
Training loss: 0.790455598738742
Validation loss: 2.150566243595386

Epoch: 5| Step: 10
Training loss: 0.6039580911392651
Validation loss: 2.176159515847319

Epoch: 313| Step: 0
Training loss: 0.8930441142908787
Validation loss: 2.1831311366475856

Epoch: 5| Step: 1
Training loss: 0.7749308032246344
Validation loss: 2.1438167320189483

Epoch: 5| Step: 2
Training loss: 0.8002051537439059
Validation loss: 2.1453666008183903

Epoch: 5| Step: 3
Training loss: 0.5372522892253062
Validation loss: 2.168577222309342

Epoch: 5| Step: 4
Training loss: 0.6344414455398986
Validation loss: 2.182162770008419

Epoch: 5| Step: 5
Training loss: 0.3299837372486168
Validation loss: 2.1452777902850424

Epoch: 5| Step: 6
Training loss: 0.8878118692387102
Validation loss: 2.139449316849384

Epoch: 5| Step: 7
Training loss: 0.6717057791231994
Validation loss: 2.1440645050634384

Epoch: 5| Step: 8
Training loss: 0.7115070451078029
Validation loss: 2.1627975088978624

Epoch: 5| Step: 9
Training loss: 0.5940341771340796
Validation loss: 2.1782274175616254

Epoch: 5| Step: 10
Training loss: 0.7686421636605918
Validation loss: 2.177071111823075

Epoch: 314| Step: 0
Training loss: 0.9987450712461924
Validation loss: 2.17214825111481

Epoch: 5| Step: 1
Training loss: 0.5423416523190845
Validation loss: 2.1574333015090237

Epoch: 5| Step: 2
Training loss: 0.6557915312238538
Validation loss: 2.172941576171799

Epoch: 5| Step: 3
Training loss: 0.7094160715052332
Validation loss: 2.164568690115905

Epoch: 5| Step: 4
Training loss: 0.9335742772836821
Validation loss: 2.203700570865597

Epoch: 5| Step: 5
Training loss: 0.7376561823842657
Validation loss: 2.192870952875916

Epoch: 5| Step: 6
Training loss: 0.4791876297663608
Validation loss: 2.194951731633027

Epoch: 5| Step: 7
Training loss: 0.822661062373244
Validation loss: 2.2223084779973967

Epoch: 5| Step: 8
Training loss: 0.39123963637839865
Validation loss: 2.17086513906091

Epoch: 5| Step: 9
Training loss: 0.645065225142119
Validation loss: 2.1591132890817377

Epoch: 5| Step: 10
Training loss: 0.5163812582227292
Validation loss: 2.178157226147081

Epoch: 315| Step: 0
Training loss: 0.450430951128689
Validation loss: 2.1649612130869684

Epoch: 5| Step: 1
Training loss: 0.7844378472793123
Validation loss: 2.142195437288961

Epoch: 5| Step: 2
Training loss: 0.7995951358214985
Validation loss: 2.13711914659098

Epoch: 5| Step: 3
Training loss: 0.5885378294513034
Validation loss: 2.1359212639846885

Epoch: 5| Step: 4
Training loss: 0.6101892850678409
Validation loss: 2.136693477209324

Epoch: 5| Step: 5
Training loss: 0.6691085950285999
Validation loss: 2.144035805873554

Epoch: 5| Step: 6
Training loss: 0.8774638568466362
Validation loss: 2.167386520709282

Epoch: 5| Step: 7
Training loss: 0.7616135744696297
Validation loss: 2.1389991466770555

Epoch: 5| Step: 8
Training loss: 0.5706773923154886
Validation loss: 2.15885759774903

Epoch: 5| Step: 9
Training loss: 0.6972635733950909
Validation loss: 2.1582150142462653

Epoch: 5| Step: 10
Training loss: 0.7901356641559402
Validation loss: 2.196390693487248

Epoch: 316| Step: 0
Training loss: 0.8930770848356921
Validation loss: 2.1661453166078624

Epoch: 5| Step: 1
Training loss: 0.435471857564218
Validation loss: 2.1685312499404925

Epoch: 5| Step: 2
Training loss: 0.48292550736608153
Validation loss: 2.161651046074987

Epoch: 5| Step: 3
Training loss: 0.5530804740096539
Validation loss: 2.1931210859815384

Epoch: 5| Step: 4
Training loss: 0.8333385745519484
Validation loss: 2.1822766778221534

Epoch: 5| Step: 5
Training loss: 0.6221920355454752
Validation loss: 2.1679356028616845

Epoch: 5| Step: 6
Training loss: 0.7237724962180715
Validation loss: 2.1607826557600225

Epoch: 5| Step: 7
Training loss: 0.7026729826221082
Validation loss: 2.165710482761166

Epoch: 5| Step: 8
Training loss: 0.8332302069431975
Validation loss: 2.179933973698088

Epoch: 5| Step: 9
Training loss: 0.8158115246760433
Validation loss: 2.1607223054210842

Epoch: 5| Step: 10
Training loss: 0.4170924296262087
Validation loss: 2.164033851005948

Epoch: 317| Step: 0
Training loss: 0.6264008558483051
Validation loss: 2.1596420522569018

Epoch: 5| Step: 1
Training loss: 0.6417787211492268
Validation loss: 2.141522158374378

Epoch: 5| Step: 2
Training loss: 0.7792190857116453
Validation loss: 2.1782278418480665

Epoch: 5| Step: 3
Training loss: 0.43191857688099167
Validation loss: 2.188487544308149

Epoch: 5| Step: 4
Training loss: 0.9886695792459024
Validation loss: 2.1783362169633698

Epoch: 5| Step: 5
Training loss: 0.49315490714158006
Validation loss: 2.165605361627592

Epoch: 5| Step: 6
Training loss: 0.9267881687928764
Validation loss: 2.161139907440849

Epoch: 5| Step: 7
Training loss: 0.6325183231730348
Validation loss: 2.157530289338258

Epoch: 5| Step: 8
Training loss: 0.6787394346113891
Validation loss: 2.1790837712376465

Epoch: 5| Step: 9
Training loss: 0.40429755685352564
Validation loss: 2.1483292675629797

Epoch: 5| Step: 10
Training loss: 0.6894132478328657
Validation loss: 2.1684680077466036

Epoch: 318| Step: 0
Training loss: 0.4656075205498278
Validation loss: 2.1758727790113412

Epoch: 5| Step: 1
Training loss: 0.8194012621548862
Validation loss: 2.1708710454762667

Epoch: 5| Step: 2
Training loss: 0.7562446105386672
Validation loss: 2.1793622265872674

Epoch: 5| Step: 3
Training loss: 0.8777408927264649
Validation loss: 2.171890729114054

Epoch: 5| Step: 4
Training loss: 0.4040817757395087
Validation loss: 2.165903137535635

Epoch: 5| Step: 5
Training loss: 0.5100440657034945
Validation loss: 2.1956950449108787

Epoch: 5| Step: 6
Training loss: 0.9181969541603443
Validation loss: 2.154982112182826

Epoch: 5| Step: 7
Training loss: 0.8477127126707324
Validation loss: 2.1758737910956945

Epoch: 5| Step: 8
Training loss: 0.5994179385878109
Validation loss: 2.164953748779291

Epoch: 5| Step: 9
Training loss: 0.5548166742489021
Validation loss: 2.164678245304169

Epoch: 5| Step: 10
Training loss: 0.3823485774712522
Validation loss: 2.1446515751929165

Epoch: 319| Step: 0
Training loss: 0.542370913041562
Validation loss: 2.1449645800966812

Epoch: 5| Step: 1
Training loss: 0.651949872099645
Validation loss: 2.15169400711595

Epoch: 5| Step: 2
Training loss: 0.4461879156505884
Validation loss: 2.1615030119264333

Epoch: 5| Step: 3
Training loss: 0.8756633696225986
Validation loss: 2.166296849171151

Epoch: 5| Step: 4
Training loss: 0.5646152725429
Validation loss: 2.1570315413736627

Epoch: 5| Step: 5
Training loss: 0.8315132928773235
Validation loss: 2.1731484994462367

Epoch: 5| Step: 6
Training loss: 0.8034462475532305
Validation loss: 2.1635297006324365

Epoch: 5| Step: 7
Training loss: 0.4849933707138118
Validation loss: 2.1414304612676407

Epoch: 5| Step: 8
Training loss: 0.6429774889809817
Validation loss: 2.167826066832071

Epoch: 5| Step: 9
Training loss: 0.7362872448812301
Validation loss: 2.1825809645791594

Epoch: 5| Step: 10
Training loss: 0.6740022517245908
Validation loss: 2.1722194551635727

Epoch: 320| Step: 0
Training loss: 0.7885339307384573
Validation loss: 2.1877447351766968

Epoch: 5| Step: 1
Training loss: 0.5547783468292226
Validation loss: 2.1721813074139567

Epoch: 5| Step: 2
Training loss: 0.37391198791105645
Validation loss: 2.1815023119232797

Epoch: 5| Step: 3
Training loss: 0.7221374298922382
Validation loss: 2.181384147813309

Epoch: 5| Step: 4
Training loss: 0.5798006517968489
Validation loss: 2.1618732084378283

Epoch: 5| Step: 5
Training loss: 0.8731175336470748
Validation loss: 2.153644398140489

Epoch: 5| Step: 6
Training loss: 0.4183204098461899
Validation loss: 2.130729953414808

Epoch: 5| Step: 7
Training loss: 0.6762357958149798
Validation loss: 2.1651205287996333

Epoch: 5| Step: 8
Training loss: 0.755272097471719
Validation loss: 2.146096226491477

Epoch: 5| Step: 9
Training loss: 0.7646837482118721
Validation loss: 2.1531760222409364

Epoch: 5| Step: 10
Training loss: 0.6361163981975442
Validation loss: 2.139793911913209

Epoch: 321| Step: 0
Training loss: 0.7354397866466482
Validation loss: 2.143600230990215

Epoch: 5| Step: 1
Training loss: 0.9111505079442055
Validation loss: 2.143176275896089

Epoch: 5| Step: 2
Training loss: 0.8862153359374322
Validation loss: 2.137478715571991

Epoch: 5| Step: 3
Training loss: 0.8268671379378761
Validation loss: 2.1501104773620723

Epoch: 5| Step: 4
Training loss: 0.62165802088837
Validation loss: 2.1385581470607695

Epoch: 5| Step: 5
Training loss: 0.38725594095015925
Validation loss: 2.1572041563548137

Epoch: 5| Step: 6
Training loss: 0.4990895147303341
Validation loss: 2.1613149764172057

Epoch: 5| Step: 7
Training loss: 0.39485912107400845
Validation loss: 2.1864614057407676

Epoch: 5| Step: 8
Training loss: 0.6188973029919389
Validation loss: 2.184765401769181

Epoch: 5| Step: 9
Training loss: 0.6673085926952981
Validation loss: 2.2064486111418598

Epoch: 5| Step: 10
Training loss: 0.47549005125370136
Validation loss: 2.1874272417898

Epoch: 322| Step: 0
Training loss: 0.7472477322005123
Validation loss: 2.1690140291142095

Epoch: 5| Step: 1
Training loss: 0.5481795418896366
Validation loss: 2.16774633246492

Epoch: 5| Step: 2
Training loss: 0.4157164845849716
Validation loss: 2.1728362656806457

Epoch: 5| Step: 3
Training loss: 0.3938281715845566
Validation loss: 2.1773735593228345

Epoch: 5| Step: 4
Training loss: 0.7715716348866697
Validation loss: 2.167624739373907

Epoch: 5| Step: 5
Training loss: 0.7858416474213682
Validation loss: 2.161410237170215

Epoch: 5| Step: 6
Training loss: 0.39743493672273333
Validation loss: 2.159635718056066

Epoch: 5| Step: 7
Training loss: 0.6659791102985168
Validation loss: 2.1605766157513373

Epoch: 5| Step: 8
Training loss: 0.6427132368802347
Validation loss: 2.1172973982081422

Epoch: 5| Step: 9
Training loss: 0.7462579836010995
Validation loss: 2.1453088084857583

Epoch: 5| Step: 10
Training loss: 0.9748615557852295
Validation loss: 2.1368000974649686

Epoch: 323| Step: 0
Training loss: 0.7770520146853821
Validation loss: 2.15637284794315

Epoch: 5| Step: 1
Training loss: 0.9568667211990467
Validation loss: 2.1387043237483816

Epoch: 5| Step: 2
Training loss: 0.539905331490242
Validation loss: 2.153373475067619

Epoch: 5| Step: 3
Training loss: 0.4801578135888573
Validation loss: 2.1460511206277086

Epoch: 5| Step: 4
Training loss: 0.6792739837983696
Validation loss: 2.1542682193036597

Epoch: 5| Step: 5
Training loss: 0.7650947291495667
Validation loss: 2.1773183485490746

Epoch: 5| Step: 6
Training loss: 0.34078536633257783
Validation loss: 2.2111589631091966

Epoch: 5| Step: 7
Training loss: 0.8077510183169133
Validation loss: 2.245211172028601

Epoch: 5| Step: 8
Training loss: 0.6953368450574746
Validation loss: 2.197470597891717

Epoch: 5| Step: 9
Training loss: 0.2985839594219506
Validation loss: 2.239889672160042

Epoch: 5| Step: 10
Training loss: 0.6702537715411618
Validation loss: 2.1817039712410913

Epoch: 324| Step: 0
Training loss: 0.5831667173944701
Validation loss: 2.166162052466673

Epoch: 5| Step: 1
Training loss: 0.7101471248833601
Validation loss: 2.160266887554664

Epoch: 5| Step: 2
Training loss: 0.43202737596095914
Validation loss: 2.167536904692099

Epoch: 5| Step: 3
Training loss: 0.5724993544162625
Validation loss: 2.150962663867412

Epoch: 5| Step: 4
Training loss: 0.36238913567254716
Validation loss: 2.1505860427117534

Epoch: 5| Step: 5
Training loss: 0.7555886900249714
Validation loss: 2.149969629396114

Epoch: 5| Step: 6
Training loss: 0.6440612466458449
Validation loss: 2.15155330660195

Epoch: 5| Step: 7
Training loss: 0.7153435715925975
Validation loss: 2.161097967354582

Epoch: 5| Step: 8
Training loss: 0.5107229604803681
Validation loss: 2.1581178540573283

Epoch: 5| Step: 9
Training loss: 0.9770552955839613
Validation loss: 2.155215228044092

Epoch: 5| Step: 10
Training loss: 0.6876261335320935
Validation loss: 2.1481213578861125

Epoch: 325| Step: 0
Training loss: 0.7966748528545424
Validation loss: 2.1426343649567783

Epoch: 5| Step: 1
Training loss: 0.7015799182522214
Validation loss: 2.141122328930803

Epoch: 5| Step: 2
Training loss: 0.5968510058708116
Validation loss: 2.174821640809014

Epoch: 5| Step: 3
Training loss: 0.6918346780262911
Validation loss: 2.135247028454816

Epoch: 5| Step: 4
Training loss: 0.7602556310694146
Validation loss: 2.1747646565610936

Epoch: 5| Step: 5
Training loss: 0.6689356893696518
Validation loss: 2.1799397838051067

Epoch: 5| Step: 6
Training loss: 0.37835232072957564
Validation loss: 2.162336219886696

Epoch: 5| Step: 7
Training loss: 0.45899086805580147
Validation loss: 2.191946780768985

Epoch: 5| Step: 8
Training loss: 0.5216466529752709
Validation loss: 2.168996321243135

Epoch: 5| Step: 9
Training loss: 0.6919625840407864
Validation loss: 2.1615056224107123

Epoch: 5| Step: 10
Training loss: 0.688559799032531
Validation loss: 2.1689011120686423

Epoch: 326| Step: 0
Training loss: 0.5631504007383605
Validation loss: 2.1752137785704524

Epoch: 5| Step: 1
Training loss: 0.7020300286505489
Validation loss: 2.1763228591442663

Epoch: 5| Step: 2
Training loss: 0.6755337565138605
Validation loss: 2.127556908699508

Epoch: 5| Step: 3
Training loss: 0.6888613227700583
Validation loss: 2.125535511435819

Epoch: 5| Step: 4
Training loss: 0.38336873029290486
Validation loss: 2.134543941708952

Epoch: 5| Step: 5
Training loss: 0.46833240663644915
Validation loss: 2.147712632072207

Epoch: 5| Step: 6
Training loss: 0.9126677345894733
Validation loss: 2.1323745484037286

Epoch: 5| Step: 7
Training loss: 0.6761251026815717
Validation loss: 2.1262707804259384

Epoch: 5| Step: 8
Training loss: 0.750714835604484
Validation loss: 2.1296015049438246

Epoch: 5| Step: 9
Training loss: 0.4970518157455362
Validation loss: 2.1431427566664087

Epoch: 5| Step: 10
Training loss: 0.5554363407600662
Validation loss: 2.1496263685903854

Epoch: 327| Step: 0
Training loss: 0.584291791856804
Validation loss: 2.136036230488691

Epoch: 5| Step: 1
Training loss: 0.7584854755859236
Validation loss: 2.159028767716319

Epoch: 5| Step: 2
Training loss: 0.7549759781407486
Validation loss: 2.1513421010909313

Epoch: 5| Step: 3
Training loss: 0.31957949528302226
Validation loss: 2.133609850312866

Epoch: 5| Step: 4
Training loss: 0.5523374500481916
Validation loss: 2.1742036708430494

Epoch: 5| Step: 5
Training loss: 0.7716289915880427
Validation loss: 2.149322618593949

Epoch: 5| Step: 6
Training loss: 0.7333268335083254
Validation loss: 2.134358353660171

Epoch: 5| Step: 7
Training loss: 0.5823651578472328
Validation loss: 2.140032178448824

Epoch: 5| Step: 8
Training loss: 0.8216797832527948
Validation loss: 2.1650549519904234

Epoch: 5| Step: 9
Training loss: 0.41277276109914557
Validation loss: 2.175680403742567

Epoch: 5| Step: 10
Training loss: 0.4814739257480825
Validation loss: 2.1804849653137497

Epoch: 328| Step: 0
Training loss: 0.549918344244913
Validation loss: 2.157450757311044

Epoch: 5| Step: 1
Training loss: 0.5837626466871928
Validation loss: 2.160353346977451

Epoch: 5| Step: 2
Training loss: 0.6151034745727401
Validation loss: 2.186680760187496

Epoch: 5| Step: 3
Training loss: 0.48816587992498717
Validation loss: 2.155331921334215

Epoch: 5| Step: 4
Training loss: 0.6659128327905174
Validation loss: 2.158052846717238

Epoch: 5| Step: 5
Training loss: 0.6837378867643743
Validation loss: 2.134727885174225

Epoch: 5| Step: 6
Training loss: 0.5731156841590069
Validation loss: 2.111285716939795

Epoch: 5| Step: 7
Training loss: 0.8059059103742757
Validation loss: 2.143221771207938

Epoch: 5| Step: 8
Training loss: 0.6316617935021205
Validation loss: 2.1499999616527052

Epoch: 5| Step: 9
Training loss: 0.6098054441540556
Validation loss: 2.132876472485853

Epoch: 5| Step: 10
Training loss: 0.6976481651871467
Validation loss: 2.121986433522892

Epoch: 329| Step: 0
Training loss: 0.4754002422027629
Validation loss: 2.1281340486428895

Epoch: 5| Step: 1
Training loss: 0.44279592058995665
Validation loss: 2.1633133972377276

Epoch: 5| Step: 2
Training loss: 0.6959651926780556
Validation loss: 2.1599142545815906

Epoch: 5| Step: 3
Training loss: 0.33829164687251095
Validation loss: 2.1760390620435293

Epoch: 5| Step: 4
Training loss: 0.637091966083619
Validation loss: 2.174670600582194

Epoch: 5| Step: 5
Training loss: 0.5221594109733764
Validation loss: 2.2051309593610755

Epoch: 5| Step: 6
Training loss: 0.7777002945028137
Validation loss: 2.1910038651143657

Epoch: 5| Step: 7
Training loss: 0.4664245940519551
Validation loss: 2.1478749793388903

Epoch: 5| Step: 8
Training loss: 0.8051926591999988
Validation loss: 2.1618923668206715

Epoch: 5| Step: 9
Training loss: 0.8748634095528574
Validation loss: 2.131677484743768

Epoch: 5| Step: 10
Training loss: 0.5902840947455189
Validation loss: 2.105017744466025

Epoch: 330| Step: 0
Training loss: 0.753487070194173
Validation loss: 2.112073718343592

Epoch: 5| Step: 1
Training loss: 0.7223813745600584
Validation loss: 2.102063798506216

Epoch: 5| Step: 2
Training loss: 0.5442853101298674
Validation loss: 2.114938549024759

Epoch: 5| Step: 3
Training loss: 0.39935871291045066
Validation loss: 2.1166382382768645

Epoch: 5| Step: 4
Training loss: 0.7410243506915755
Validation loss: 2.1025063299482976

Epoch: 5| Step: 5
Training loss: 0.3140789791547421
Validation loss: 2.1106302407309774

Epoch: 5| Step: 6
Training loss: 0.688751879895478
Validation loss: 2.1374362662360027

Epoch: 5| Step: 7
Training loss: 0.6141339345445532
Validation loss: 2.1558390982762647

Epoch: 5| Step: 8
Training loss: 0.8017806724792772
Validation loss: 2.1668853864320874

Epoch: 5| Step: 9
Training loss: 0.7007177258196393
Validation loss: 2.186098315636832

Epoch: 5| Step: 10
Training loss: 0.45657950678384207
Validation loss: 2.1483035579629677

Epoch: 331| Step: 0
Training loss: 0.582192136302758
Validation loss: 2.1634146013436686

Epoch: 5| Step: 1
Training loss: 0.9284476018180815
Validation loss: 2.132569131598009

Epoch: 5| Step: 2
Training loss: 0.5770075024062506
Validation loss: 2.150348498509146

Epoch: 5| Step: 3
Training loss: 0.43571380016648265
Validation loss: 2.1540835784649963

Epoch: 5| Step: 4
Training loss: 0.7280139985834639
Validation loss: 2.151372779827491

Epoch: 5| Step: 5
Training loss: 0.8689058822633802
Validation loss: 2.1564417892415637

Epoch: 5| Step: 6
Training loss: 0.43778578756391934
Validation loss: 2.171653825415639

Epoch: 5| Step: 7
Training loss: 0.5893058597952404
Validation loss: 2.1627192694139725

Epoch: 5| Step: 8
Training loss: 0.5161838970398068
Validation loss: 2.1902857707809145

Epoch: 5| Step: 9
Training loss: 0.23353567836875708
Validation loss: 2.1750992015072845

Epoch: 5| Step: 10
Training loss: 0.7376953706748884
Validation loss: 2.1848233490206797

Epoch: 332| Step: 0
Training loss: 0.7437306073008657
Validation loss: 2.1753618590210517

Epoch: 5| Step: 1
Training loss: 0.41663634865449417
Validation loss: 2.188438685250103

Epoch: 5| Step: 2
Training loss: 0.8423382993878051
Validation loss: 2.1475945888935644

Epoch: 5| Step: 3
Training loss: 0.81662926069217
Validation loss: 2.131993154373896

Epoch: 5| Step: 4
Training loss: 0.377424765315011
Validation loss: 2.142263526848207

Epoch: 5| Step: 5
Training loss: 0.6978613181490603
Validation loss: 2.1556623293223294

Epoch: 5| Step: 6
Training loss: 0.544046553499117
Validation loss: 2.169013031558101

Epoch: 5| Step: 7
Training loss: 0.35248049516350655
Validation loss: 2.155032957742586

Epoch: 5| Step: 8
Training loss: 0.3290258711075322
Validation loss: 2.1902312986773596

Epoch: 5| Step: 9
Training loss: 0.7500236030679278
Validation loss: 2.180951993738018

Epoch: 5| Step: 10
Training loss: 0.5281906956097638
Validation loss: 2.1837973706561122

Epoch: 333| Step: 0
Training loss: 0.4043994165386609
Validation loss: 2.1651434166300794

Epoch: 5| Step: 1
Training loss: 0.44214335649221376
Validation loss: 2.167624889576266

Epoch: 5| Step: 2
Training loss: 0.5620735989465988
Validation loss: 2.1701180968461005

Epoch: 5| Step: 3
Training loss: 0.6081812977778887
Validation loss: 2.1546327239548506

Epoch: 5| Step: 4
Training loss: 0.802780298557599
Validation loss: 2.168439584245825

Epoch: 5| Step: 5
Training loss: 0.46521503783043033
Validation loss: 2.146012943738361

Epoch: 5| Step: 6
Training loss: 0.6401865784805013
Validation loss: 2.15312906319616

Epoch: 5| Step: 7
Training loss: 0.7026962032415317
Validation loss: 2.144676390819054

Epoch: 5| Step: 8
Training loss: 0.5250428477467932
Validation loss: 2.172909425741834

Epoch: 5| Step: 9
Training loss: 0.6603676045682612
Validation loss: 2.1625223501362694

Epoch: 5| Step: 10
Training loss: 0.7601278662405628
Validation loss: 2.176092158199851

Epoch: 334| Step: 0
Training loss: 0.6497459080043632
Validation loss: 2.1694780687097523

Epoch: 5| Step: 1
Training loss: 0.8245317488526611
Validation loss: 2.1932005407401842

Epoch: 5| Step: 2
Training loss: 0.5428073011818081
Validation loss: 2.1692720214342565

Epoch: 5| Step: 3
Training loss: 0.6425854296979256
Validation loss: 2.181215266362447

Epoch: 5| Step: 4
Training loss: 0.3200666251524754
Validation loss: 2.1644713774921245

Epoch: 5| Step: 5
Training loss: 0.46479441276752437
Validation loss: 2.160750184263549

Epoch: 5| Step: 6
Training loss: 0.6780199663941332
Validation loss: 2.1881393799066458

Epoch: 5| Step: 7
Training loss: 0.687993934234505
Validation loss: 2.1517722307884637

Epoch: 5| Step: 8
Training loss: 0.6857789779698458
Validation loss: 2.176268390358869

Epoch: 5| Step: 9
Training loss: 0.35501258001737956
Validation loss: 2.1598958887312145

Epoch: 5| Step: 10
Training loss: 0.5263168509058539
Validation loss: 2.1931165224106905

Epoch: 335| Step: 0
Training loss: 0.5585540543970204
Validation loss: 2.1649795969506807

Epoch: 5| Step: 1
Training loss: 0.5623321812683285
Validation loss: 2.163885991123091

Epoch: 5| Step: 2
Training loss: 0.37913038565775065
Validation loss: 2.1785670433006064

Epoch: 5| Step: 3
Training loss: 0.27005773070612626
Validation loss: 2.174179020082095

Epoch: 5| Step: 4
Training loss: 0.62639440912106
Validation loss: 2.181593369113813

Epoch: 5| Step: 5
Training loss: 0.6351782294079836
Validation loss: 2.161540441415111

Epoch: 5| Step: 6
Training loss: 0.5877698349666417
Validation loss: 2.1466742959508274

Epoch: 5| Step: 7
Training loss: 0.8435358906104804
Validation loss: 2.1611055179350673

Epoch: 5| Step: 8
Training loss: 0.6470677259159177
Validation loss: 2.158218542164667

Epoch: 5| Step: 9
Training loss: 0.7298864808065681
Validation loss: 2.134239142138592

Epoch: 5| Step: 10
Training loss: 0.4825008497576569
Validation loss: 2.1274400294974534

Epoch: 336| Step: 0
Training loss: 0.5727118877533255
Validation loss: 2.1669174251164707

Epoch: 5| Step: 1
Training loss: 0.8406033651411183
Validation loss: 2.155435003576891

Epoch: 5| Step: 2
Training loss: 0.551269342035577
Validation loss: 2.1666293716849396

Epoch: 5| Step: 3
Training loss: 0.6852689435052937
Validation loss: 2.1303210789890397

Epoch: 5| Step: 4
Training loss: 0.21156697481232223
Validation loss: 2.155768647041848

Epoch: 5| Step: 5
Training loss: 0.42160270875258765
Validation loss: 2.1466710529943076

Epoch: 5| Step: 6
Training loss: 0.5841244430718929
Validation loss: 2.1332610314256573

Epoch: 5| Step: 7
Training loss: 0.23190191755320375
Validation loss: 2.152703887353024

Epoch: 5| Step: 8
Training loss: 0.6883861725903022
Validation loss: 2.1838017306539506

Epoch: 5| Step: 9
Training loss: 0.6018446471185176
Validation loss: 2.1734521161776743

Epoch: 5| Step: 10
Training loss: 0.8009021946823984
Validation loss: 2.179692710340676

Epoch: 337| Step: 0
Training loss: 0.5449199334660333
Validation loss: 2.1952111612711422

Epoch: 5| Step: 1
Training loss: 0.48120368016255516
Validation loss: 2.194428511565578

Epoch: 5| Step: 2
Training loss: 0.6479631550374623
Validation loss: 2.165855625870868

Epoch: 5| Step: 3
Training loss: 0.4076428378359948
Validation loss: 2.174972399445844

Epoch: 5| Step: 4
Training loss: 0.40389832833820866
Validation loss: 2.1863209466522613

Epoch: 5| Step: 5
Training loss: 0.5039241107466328
Validation loss: 2.1537285511221334

Epoch: 5| Step: 6
Training loss: 0.3164403449632666
Validation loss: 2.1832945941956674

Epoch: 5| Step: 7
Training loss: 0.6593594228341813
Validation loss: 2.15999032042897

Epoch: 5| Step: 8
Training loss: 0.7931317692701498
Validation loss: 2.159086138187214

Epoch: 5| Step: 9
Training loss: 0.7394393234456149
Validation loss: 2.160818131234237

Epoch: 5| Step: 10
Training loss: 0.762251564890055
Validation loss: 2.1296231830866534

Epoch: 338| Step: 0
Training loss: 0.6917355502156252
Validation loss: 2.1446357640466798

Epoch: 5| Step: 1
Training loss: 0.39828709026019044
Validation loss: 2.159016317743458

Epoch: 5| Step: 2
Training loss: 0.38449065554118994
Validation loss: 2.148622187845364

Epoch: 5| Step: 3
Training loss: 0.6359555872189091
Validation loss: 2.1507245199718654

Epoch: 5| Step: 4
Training loss: 0.8214398221909933
Validation loss: 2.144752111967012

Epoch: 5| Step: 5
Training loss: 0.7125152435679829
Validation loss: 2.153220785973247

Epoch: 5| Step: 6
Training loss: 0.5299622692317205
Validation loss: 2.1877430559595643

Epoch: 5| Step: 7
Training loss: 0.2908271588915229
Validation loss: 2.182388953913782

Epoch: 5| Step: 8
Training loss: 0.5994727013109777
Validation loss: 2.205301298329058

Epoch: 5| Step: 9
Training loss: 0.4143762119845104
Validation loss: 2.1687853001843003

Epoch: 5| Step: 10
Training loss: 0.6959667984850874
Validation loss: 2.1749278252582696

Epoch: 339| Step: 0
Training loss: 0.5403718940209685
Validation loss: 2.1660890876252044

Epoch: 5| Step: 1
Training loss: 0.5424159137761434
Validation loss: 2.163226884874662

Epoch: 5| Step: 2
Training loss: 0.5061255384439028
Validation loss: 2.1407509923805703

Epoch: 5| Step: 3
Training loss: 0.7195397474882709
Validation loss: 2.167942063288283

Epoch: 5| Step: 4
Training loss: 0.6961917675465248
Validation loss: 2.1417075254496893

Epoch: 5| Step: 5
Training loss: 0.5180010525166191
Validation loss: 2.1643107566417026

Epoch: 5| Step: 6
Training loss: 0.5294920220228814
Validation loss: 2.187247213357252

Epoch: 5| Step: 7
Training loss: 0.6924987824976716
Validation loss: 2.1756958525984658

Epoch: 5| Step: 8
Training loss: 0.7165766489434575
Validation loss: 2.174981821366342

Epoch: 5| Step: 9
Training loss: 0.2467394486841083
Validation loss: 2.180844995845203

Epoch: 5| Step: 10
Training loss: 0.4823231460920827
Validation loss: 2.1999334559253727

Epoch: 340| Step: 0
Training loss: 0.3513509643778955
Validation loss: 2.1478223678885864

Epoch: 5| Step: 1
Training loss: 0.5593644274346473
Validation loss: 2.1561941645215885

Epoch: 5| Step: 2
Training loss: 0.5812309702967815
Validation loss: 2.1516892225363144

Epoch: 5| Step: 3
Training loss: 0.4245109331691047
Validation loss: 2.1523839224973202

Epoch: 5| Step: 4
Training loss: 0.6711931095132205
Validation loss: 2.1603723438053226

Epoch: 5| Step: 5
Training loss: 0.6609222437403183
Validation loss: 2.132795494036132

Epoch: 5| Step: 6
Training loss: 0.5398391160338236
Validation loss: 2.134014759145232

Epoch: 5| Step: 7
Training loss: 0.5602064793836115
Validation loss: 2.1613739485465118

Epoch: 5| Step: 8
Training loss: 0.7197593567621948
Validation loss: 2.1436521636322055

Epoch: 5| Step: 9
Training loss: 0.4848999439834213
Validation loss: 2.137276275906793

Epoch: 5| Step: 10
Training loss: 0.6172222658819821
Validation loss: 2.157341824380319

Epoch: 341| Step: 0
Training loss: 0.5468845911547339
Validation loss: 2.1778762459947396

Epoch: 5| Step: 1
Training loss: 0.9861681515728312
Validation loss: 2.175805281701551

Epoch: 5| Step: 2
Training loss: 0.45336187682446716
Validation loss: 2.1477802554796828

Epoch: 5| Step: 3
Training loss: 0.5667184166792906
Validation loss: 2.149432834575828

Epoch: 5| Step: 4
Training loss: 0.539737499949254
Validation loss: 2.1460571281876346

Epoch: 5| Step: 5
Training loss: 0.4537501462300383
Validation loss: 2.1539404581336883

Epoch: 5| Step: 6
Training loss: 0.4836980488454091
Validation loss: 2.148058769427168

Epoch: 5| Step: 7
Training loss: 0.510645840895391
Validation loss: 2.1424976179363093

Epoch: 5| Step: 8
Training loss: 0.4715329844425007
Validation loss: 2.154849465065604

Epoch: 5| Step: 9
Training loss: 0.41289582623658616
Validation loss: 2.175279693196558

Epoch: 5| Step: 10
Training loss: 0.622811299814311
Validation loss: 2.1578101853219716

Epoch: 342| Step: 0
Training loss: 0.9018879189098009
Validation loss: 2.1700203898136214

Epoch: 5| Step: 1
Training loss: 0.748307464070342
Validation loss: 2.154198581278807

Epoch: 5| Step: 2
Training loss: 0.5748933734715606
Validation loss: 2.1571675696879167

Epoch: 5| Step: 3
Training loss: 0.40454976378002444
Validation loss: 2.1690487574321655

Epoch: 5| Step: 4
Training loss: 0.44287333125145395
Validation loss: 2.1758794088033118

Epoch: 5| Step: 5
Training loss: 0.5714000626673145
Validation loss: 2.162453206727499

Epoch: 5| Step: 6
Training loss: 0.4950611150467201
Validation loss: 2.183620902004974

Epoch: 5| Step: 7
Training loss: 0.48846014179021974
Validation loss: 2.189954914263491

Epoch: 5| Step: 8
Training loss: 0.41792418340361437
Validation loss: 2.175336022847096

Epoch: 5| Step: 9
Training loss: 0.6192175639870562
Validation loss: 2.160487342336862

Epoch: 5| Step: 10
Training loss: 0.2699865835000033
Validation loss: 2.174541664416645

Epoch: 343| Step: 0
Training loss: 0.49416759854604636
Validation loss: 2.1545651216717507

Epoch: 5| Step: 1
Training loss: 0.6963306002646181
Validation loss: 2.170376045334302

Epoch: 5| Step: 2
Training loss: 0.4803157190526485
Validation loss: 2.1557832723716337

Epoch: 5| Step: 3
Training loss: 0.6672817735378298
Validation loss: 2.144720392425901

Epoch: 5| Step: 4
Training loss: 0.44390543109478553
Validation loss: 2.1535257420394722

Epoch: 5| Step: 5
Training loss: 0.6011753322608491
Validation loss: 2.126501273295297

Epoch: 5| Step: 6
Training loss: 0.4300202208577256
Validation loss: 2.156869328841368

Epoch: 5| Step: 7
Training loss: 0.7141295236731033
Validation loss: 2.162292668786588

Epoch: 5| Step: 8
Training loss: 0.5635416399896396
Validation loss: 2.177140523405956

Epoch: 5| Step: 9
Training loss: 0.672568030337548
Validation loss: 2.175803884592221

Epoch: 5| Step: 10
Training loss: 0.42257519295525603
Validation loss: 2.1588143563313063

Epoch: 344| Step: 0
Training loss: 0.6162269457205272
Validation loss: 2.1613118544719554

Epoch: 5| Step: 1
Training loss: 0.6087862006748308
Validation loss: 2.1653903056438413

Epoch: 5| Step: 2
Training loss: 0.6245747311487273
Validation loss: 2.1495882808390947

Epoch: 5| Step: 3
Training loss: 0.5253435985975006
Validation loss: 2.178728175760517

Epoch: 5| Step: 4
Training loss: 0.6931509000034208
Validation loss: 2.1729149962518615

Epoch: 5| Step: 5
Training loss: 0.36984278992631825
Validation loss: 2.1588542038750185

Epoch: 5| Step: 6
Training loss: 0.45690769579537127
Validation loss: 2.1790035911309884

Epoch: 5| Step: 7
Training loss: 0.48654260463623644
Validation loss: 2.1440276881969855

Epoch: 5| Step: 8
Training loss: 0.7787542916144451
Validation loss: 2.199099757427076

Epoch: 5| Step: 9
Training loss: 0.5258539702189146
Validation loss: 2.1768647851735192

Epoch: 5| Step: 10
Training loss: 0.19056673253789838
Validation loss: 2.136499154749893

Epoch: 345| Step: 0
Training loss: 0.6243417372831257
Validation loss: 2.1709502618075245

Epoch: 5| Step: 1
Training loss: 0.6709378160139244
Validation loss: 2.1475421191967183

Epoch: 5| Step: 2
Training loss: 0.406057220348332
Validation loss: 2.1656409315244676

Epoch: 5| Step: 3
Training loss: 0.6136057050107137
Validation loss: 2.1770051978561504

Epoch: 5| Step: 4
Training loss: 0.3624875411819429
Validation loss: 2.1348083946350096

Epoch: 5| Step: 5
Training loss: 0.7336090232551071
Validation loss: 2.144235984343331

Epoch: 5| Step: 6
Training loss: 0.642921750099455
Validation loss: 2.122511286451216

Epoch: 5| Step: 7
Training loss: 0.23874244458291966
Validation loss: 2.152971689349785

Epoch: 5| Step: 8
Training loss: 0.3465426536841993
Validation loss: 2.163658000629777

Epoch: 5| Step: 9
Training loss: 0.5152164921755338
Validation loss: 2.144498387330805

Epoch: 5| Step: 10
Training loss: 0.6787910688561275
Validation loss: 2.1524329746812083

Epoch: 346| Step: 0
Training loss: 0.5983116445843096
Validation loss: 2.1531586246534116

Epoch: 5| Step: 1
Training loss: 0.6565361534399282
Validation loss: 2.143720699327591

Epoch: 5| Step: 2
Training loss: 0.6011240463614163
Validation loss: 2.1108275838215054

Epoch: 5| Step: 3
Training loss: 0.6147130543720943
Validation loss: 2.1486827995941575

Epoch: 5| Step: 4
Training loss: 0.5367085018595501
Validation loss: 2.141291771465556

Epoch: 5| Step: 5
Training loss: 0.613884768596859
Validation loss: 2.1400787216959194

Epoch: 5| Step: 6
Training loss: 0.48728952021110444
Validation loss: 2.162895006470667

Epoch: 5| Step: 7
Training loss: 0.41246458537348013
Validation loss: 2.1568845398116885

Epoch: 5| Step: 8
Training loss: 0.6519526377059551
Validation loss: 2.153821485660963

Epoch: 5| Step: 9
Training loss: 0.3256733104906793
Validation loss: 2.165903284306477

Epoch: 5| Step: 10
Training loss: 0.4558150746345905
Validation loss: 2.1662184257131254

Epoch: 347| Step: 0
Training loss: 0.50318345269369
Validation loss: 2.1378833131535147

Epoch: 5| Step: 1
Training loss: 0.39920654128903743
Validation loss: 2.1571626959348205

Epoch: 5| Step: 2
Training loss: 0.5048651332453054
Validation loss: 2.1401671035213807

Epoch: 5| Step: 3
Training loss: 0.36718575497476386
Validation loss: 2.136841552262604

Epoch: 5| Step: 4
Training loss: 0.4592676952142661
Validation loss: 2.1198869268423195

Epoch: 5| Step: 5
Training loss: 0.312649345474223
Validation loss: 2.135104764724477

Epoch: 5| Step: 6
Training loss: 0.6197822687627971
Validation loss: 2.147935946064817

Epoch: 5| Step: 7
Training loss: 0.5432375235812346
Validation loss: 2.1602819707644807

Epoch: 5| Step: 8
Training loss: 0.7204529449509658
Validation loss: 2.161406963245487

Epoch: 5| Step: 9
Training loss: 0.7580783810162517
Validation loss: 2.1595143793861866

Epoch: 5| Step: 10
Training loss: 0.6474241358451822
Validation loss: 2.166140499151374

Epoch: 348| Step: 0
Training loss: 0.4507674844844888
Validation loss: 2.1836388728375926

Epoch: 5| Step: 1
Training loss: 0.4743895787045697
Validation loss: 2.173859040673874

Epoch: 5| Step: 2
Training loss: 0.3858247885811787
Validation loss: 2.179367650326014

Epoch: 5| Step: 3
Training loss: 0.5246096908557023
Validation loss: 2.155884742564157

Epoch: 5| Step: 4
Training loss: 0.5336226046399639
Validation loss: 2.1544089882365074

Epoch: 5| Step: 5
Training loss: 0.31259296941654974
Validation loss: 2.1474726247782585

Epoch: 5| Step: 6
Training loss: 0.6606084414800585
Validation loss: 2.1494871330063416

Epoch: 5| Step: 7
Training loss: 0.8097936968577178
Validation loss: 2.179904239361284

Epoch: 5| Step: 8
Training loss: 0.41759470664950094
Validation loss: 2.163082911739901

Epoch: 5| Step: 9
Training loss: 0.6576370159226784
Validation loss: 2.1395746763162693

Epoch: 5| Step: 10
Training loss: 0.49483656595867415
Validation loss: 2.1440238762622537

Epoch: 349| Step: 0
Training loss: 0.6953119427968053
Validation loss: 2.1499960696849114

Epoch: 5| Step: 1
Training loss: 0.7621332068067908
Validation loss: 2.1350790453714685

Epoch: 5| Step: 2
Training loss: 0.3632235532494062
Validation loss: 2.159986319466325

Epoch: 5| Step: 3
Training loss: 0.1512449139831508
Validation loss: 2.1472727408793184

Epoch: 5| Step: 4
Training loss: 0.6811363519138094
Validation loss: 2.137201373666582

Epoch: 5| Step: 5
Training loss: 0.48077497570566813
Validation loss: 2.1411497165957027

Epoch: 5| Step: 6
Training loss: 0.6274613076701531
Validation loss: 2.1280505068555007

Epoch: 5| Step: 7
Training loss: 0.45988709976814673
Validation loss: 2.120652538100557

Epoch: 5| Step: 8
Training loss: 0.3509401004215955
Validation loss: 2.1354463596715667

Epoch: 5| Step: 9
Training loss: 0.3102001317688326
Validation loss: 2.155318537105302

Epoch: 5| Step: 10
Training loss: 0.6609510569162804
Validation loss: 2.1369890568187024

Epoch: 350| Step: 0
Training loss: 0.5203848688242216
Validation loss: 2.163256045253887

Epoch: 5| Step: 1
Training loss: 0.548964296871948
Validation loss: 2.162963236155925

Epoch: 5| Step: 2
Training loss: 0.5381499319913474
Validation loss: 2.179881667925506

Epoch: 5| Step: 3
Training loss: 0.41254593564515213
Validation loss: 2.1657973821195946

Epoch: 5| Step: 4
Training loss: 0.5561301852426315
Validation loss: 2.159757307488832

Epoch: 5| Step: 5
Training loss: 0.5005762534631809
Validation loss: 2.1497656762478736

Epoch: 5| Step: 6
Training loss: 0.6318558420055947
Validation loss: 2.181639207831849

Epoch: 5| Step: 7
Training loss: 0.516514848379351
Validation loss: 2.1699634664425114

Epoch: 5| Step: 8
Training loss: 0.46730428913612543
Validation loss: 2.1913752683529952

Epoch: 5| Step: 9
Training loss: 0.6629488863768712
Validation loss: 2.168582951128211

Epoch: 5| Step: 10
Training loss: 0.36562071985201117
Validation loss: 2.180061888315372

Epoch: 351| Step: 0
Training loss: 0.4711848757592708
Validation loss: 2.1523378052488042

Epoch: 5| Step: 1
Training loss: 0.5954813059571865
Validation loss: 2.1588499692437706

Epoch: 5| Step: 2
Training loss: 0.5379684513832436
Validation loss: 2.1537016971839833

Epoch: 5| Step: 3
Training loss: 0.5620342551716565
Validation loss: 2.146157553726606

Epoch: 5| Step: 4
Training loss: 0.5949719553837611
Validation loss: 2.14753986657854

Epoch: 5| Step: 5
Training loss: 0.5531147433262112
Validation loss: 2.148580395373643

Epoch: 5| Step: 6
Training loss: 0.7503866152877156
Validation loss: 2.147331283235194

Epoch: 5| Step: 7
Training loss: 0.38289536338354035
Validation loss: 2.135283837037673

Epoch: 5| Step: 8
Training loss: 0.35688065372404604
Validation loss: 2.166214979464409

Epoch: 5| Step: 9
Training loss: 0.5074353211157955
Validation loss: 2.1502101353364407

Epoch: 5| Step: 10
Training loss: 0.37202994060005556
Validation loss: 2.1285422080204612

Epoch: 352| Step: 0
Training loss: 0.5547243025485012
Validation loss: 2.154371526773119

Epoch: 5| Step: 1
Training loss: 0.5269089212957918
Validation loss: 2.1460368267724106

Epoch: 5| Step: 2
Training loss: 0.49978057695843303
Validation loss: 2.157515083514737

Epoch: 5| Step: 3
Training loss: 0.3783395599841524
Validation loss: 2.157672428364647

Epoch: 5| Step: 4
Training loss: 0.3807976501527078
Validation loss: 2.150291525008449

Epoch: 5| Step: 5
Training loss: 0.5769786552715727
Validation loss: 2.133026877946864

Epoch: 5| Step: 6
Training loss: 0.618950558920353
Validation loss: 2.14174106893688

Epoch: 5| Step: 7
Training loss: 0.5747933140678436
Validation loss: 2.1415778065729056

Epoch: 5| Step: 8
Training loss: 0.593053760893124
Validation loss: 2.1427654412151838

Epoch: 5| Step: 9
Training loss: 0.5716183487776094
Validation loss: 2.1503387063706545

Epoch: 5| Step: 10
Training loss: 0.3427223645712977
Validation loss: 2.139627442043703

Epoch: 353| Step: 0
Training loss: 0.4043594348806749
Validation loss: 2.1374643296083526

Epoch: 5| Step: 1
Training loss: 0.5501375427359103
Validation loss: 2.1645603681552132

Epoch: 5| Step: 2
Training loss: 0.28848356833761235
Validation loss: 2.176700353067637

Epoch: 5| Step: 3
Training loss: 0.48421874140800675
Validation loss: 2.171824718125535

Epoch: 5| Step: 4
Training loss: 0.6660646661059378
Validation loss: 2.1714931780077737

Epoch: 5| Step: 5
Training loss: 0.6332980988974372
Validation loss: 2.1594506879231754

Epoch: 5| Step: 6
Training loss: 0.5004356393809274
Validation loss: 2.1543603469622252

Epoch: 5| Step: 7
Training loss: 0.5837956764762874
Validation loss: 2.1485359880800408

Epoch: 5| Step: 8
Training loss: 0.5583358382648055
Validation loss: 2.1445729570109817

Epoch: 5| Step: 9
Training loss: 0.60476569919465
Validation loss: 2.136313526851144

Epoch: 5| Step: 10
Training loss: 0.22559855372171594
Validation loss: 2.1420489225728905

Epoch: 354| Step: 0
Training loss: 0.4956053033837855
Validation loss: 2.1303231350067713

Epoch: 5| Step: 1
Training loss: 0.4231182429169963
Validation loss: 2.158933712106507

Epoch: 5| Step: 2
Training loss: 0.5599552980530843
Validation loss: 2.174892861652179

Epoch: 5| Step: 3
Training loss: 0.6441847361028553
Validation loss: 2.156903248058634

Epoch: 5| Step: 4
Training loss: 0.5362305543392671
Validation loss: 2.1951124423968307

Epoch: 5| Step: 5
Training loss: 0.4973813116407029
Validation loss: 2.174801094541443

Epoch: 5| Step: 6
Training loss: 0.6646853723388824
Validation loss: 2.179399922218816

Epoch: 5| Step: 7
Training loss: 0.47281918200141215
Validation loss: 2.1624252755966618

Epoch: 5| Step: 8
Training loss: 0.4190663694107777
Validation loss: 2.1339344059540797

Epoch: 5| Step: 9
Training loss: 0.5848773266068727
Validation loss: 2.1218271618630506

Epoch: 5| Step: 10
Training loss: 0.2889220824578968
Validation loss: 2.1205324587479697

Epoch: 355| Step: 0
Training loss: 0.6983416719856811
Validation loss: 2.1273954559745567

Epoch: 5| Step: 1
Training loss: 0.23415629196064797
Validation loss: 2.11200614244249

Epoch: 5| Step: 2
Training loss: 0.5660358401651397
Validation loss: 2.1549017714094765

Epoch: 5| Step: 3
Training loss: 0.19752954070467107
Validation loss: 2.120675982020361

Epoch: 5| Step: 4
Training loss: 0.5773876230297423
Validation loss: 2.137510118602672

Epoch: 5| Step: 5
Training loss: 0.7416241565765775
Validation loss: 2.142972440640424

Epoch: 5| Step: 6
Training loss: 0.5610442397375794
Validation loss: 2.153911739969634

Epoch: 5| Step: 7
Training loss: 0.45652176914871506
Validation loss: 2.1456034181046024

Epoch: 5| Step: 8
Training loss: 0.5242551992737952
Validation loss: 2.16474500239892

Epoch: 5| Step: 9
Training loss: 0.37767976683698323
Validation loss: 2.150563894606302

Epoch: 5| Step: 10
Training loss: 0.5913852481312887
Validation loss: 2.190846793771996

Epoch: 356| Step: 0
Training loss: 0.238723797308972
Validation loss: 2.1995604231138293

Epoch: 5| Step: 1
Training loss: 0.4015419572555558
Validation loss: 2.204205137309004

Epoch: 5| Step: 2
Training loss: 0.6986465243731459
Validation loss: 2.2148958082755286

Epoch: 5| Step: 3
Training loss: 0.19746059753509446
Validation loss: 2.1809163476546076

Epoch: 5| Step: 4
Training loss: 0.5260828556012497
Validation loss: 2.1904784029606343

Epoch: 5| Step: 5
Training loss: 0.5288958279415379
Validation loss: 2.16318110989474

Epoch: 5| Step: 6
Training loss: 0.6543920191580131
Validation loss: 2.1862704077830033

Epoch: 5| Step: 7
Training loss: 0.3046592430314408
Validation loss: 2.1553942477478407

Epoch: 5| Step: 8
Training loss: 0.5286202698588638
Validation loss: 2.185707993733054

Epoch: 5| Step: 9
Training loss: 0.49220563461561495
Validation loss: 2.171772724634545

Epoch: 5| Step: 10
Training loss: 0.828470014281598
Validation loss: 2.1502335607194274

Epoch: 357| Step: 0
Training loss: 0.46305335681202314
Validation loss: 2.1590672511556095

Epoch: 5| Step: 1
Training loss: 0.49780897554729225
Validation loss: 2.1770934618736706

Epoch: 5| Step: 2
Training loss: 0.5581219955226772
Validation loss: 2.165642679669659

Epoch: 5| Step: 3
Training loss: 0.4944974945022243
Validation loss: 2.1850646512801237

Epoch: 5| Step: 4
Training loss: 0.5205497796351042
Validation loss: 2.1811902505645926

Epoch: 5| Step: 5
Training loss: 0.3259016733787348
Validation loss: 2.1860351814638093

Epoch: 5| Step: 6
Training loss: 0.4650260503711633
Validation loss: 2.1664015134031387

Epoch: 5| Step: 7
Training loss: 0.531934689625185
Validation loss: 2.212220010757354

Epoch: 5| Step: 8
Training loss: 0.41884368161721264
Validation loss: 2.160951668315588

Epoch: 5| Step: 9
Training loss: 0.31403380922437607
Validation loss: 2.1697287511550383

Epoch: 5| Step: 10
Training loss: 0.8639498231896577
Validation loss: 2.175915422229738

Epoch: 358| Step: 0
Training loss: 0.6417698051701562
Validation loss: 2.1885389951567498

Epoch: 5| Step: 1
Training loss: 0.24916253786323575
Validation loss: 2.168124764506752

Epoch: 5| Step: 2
Training loss: 0.34788346098816464
Validation loss: 2.187195584727996

Epoch: 5| Step: 3
Training loss: 0.4315511688468519
Validation loss: 2.1719295152261506

Epoch: 5| Step: 4
Training loss: 0.502246666955593
Validation loss: 2.1888268602658916

Epoch: 5| Step: 5
Training loss: 0.22778169850203087
Validation loss: 2.1701477411123777

Epoch: 5| Step: 6
Training loss: 0.5541936798491106
Validation loss: 2.1491643039842576

Epoch: 5| Step: 7
Training loss: 0.652471975185101
Validation loss: 2.1255734820146075

Epoch: 5| Step: 8
Training loss: 0.5909562892337403
Validation loss: 2.177843977126612

Epoch: 5| Step: 9
Training loss: 0.472162540566329
Validation loss: 2.149150865241744

Epoch: 5| Step: 10
Training loss: 0.7004290287788472
Validation loss: 2.1502642627235327

Epoch: 359| Step: 0
Training loss: 0.5502957036814385
Validation loss: 2.155277086801603

Epoch: 5| Step: 1
Training loss: 0.6579372650128671
Validation loss: 2.1174348446714606

Epoch: 5| Step: 2
Training loss: 0.4959410935664128
Validation loss: 2.1750348897023133

Epoch: 5| Step: 3
Training loss: 0.29250496075572396
Validation loss: 2.1623656036051644

Epoch: 5| Step: 4
Training loss: 0.3603691572323683
Validation loss: 2.1818527174548796

Epoch: 5| Step: 5
Training loss: 0.578798571828571
Validation loss: 2.167825570737211

Epoch: 5| Step: 6
Training loss: 0.1569317725597549
Validation loss: 2.162652981743491

Epoch: 5| Step: 7
Training loss: 0.47615944124031034
Validation loss: 2.1817337377458106

Epoch: 5| Step: 8
Training loss: 0.53347047803294
Validation loss: 2.162331549552736

Epoch: 5| Step: 9
Training loss: 0.6076262887526301
Validation loss: 2.1637075756633757

Epoch: 5| Step: 10
Training loss: 0.6882157284815329
Validation loss: 2.1652022596223888

Epoch: 360| Step: 0
Training loss: 0.5007006385421262
Validation loss: 2.1234107507892817

Epoch: 5| Step: 1
Training loss: 0.7582731911281897
Validation loss: 2.1608027747356977

Epoch: 5| Step: 2
Training loss: 0.5420597893422704
Validation loss: 2.181958226059522

Epoch: 5| Step: 3
Training loss: 0.5611392091518618
Validation loss: 2.1630813425622177

Epoch: 5| Step: 4
Training loss: 0.5410989084419234
Validation loss: 2.182475548336253

Epoch: 5| Step: 5
Training loss: 0.43026157523836844
Validation loss: 2.1646341235482236

Epoch: 5| Step: 6
Training loss: 0.38659735421500396
Validation loss: 2.162439506766299

Epoch: 5| Step: 7
Training loss: 0.4345694552638139
Validation loss: 2.177658282646092

Epoch: 5| Step: 8
Training loss: 0.3628757223265972
Validation loss: 2.15187871479395

Epoch: 5| Step: 9
Training loss: 0.3421476144929916
Validation loss: 2.186642722865491

Epoch: 5| Step: 10
Training loss: 0.4849344529760352
Validation loss: 2.1600744386263466

Epoch: 361| Step: 0
Training loss: 0.45701525733549786
Validation loss: 2.1295700424732087

Epoch: 5| Step: 1
Training loss: 0.5736454547635846
Validation loss: 2.1628152844120923

Epoch: 5| Step: 2
Training loss: 0.46680418511576394
Validation loss: 2.132613122152144

Epoch: 5| Step: 3
Training loss: 0.412232059820574
Validation loss: 2.154529626530304

Epoch: 5| Step: 4
Training loss: 0.2893533403393642
Validation loss: 2.1689955837075234

Epoch: 5| Step: 5
Training loss: 0.5648282662323184
Validation loss: 2.1753979747037913

Epoch: 5| Step: 6
Training loss: 0.3277049668659142
Validation loss: 2.1779750913685745

Epoch: 5| Step: 7
Training loss: 0.4977758231005201
Validation loss: 2.176628924594446

Epoch: 5| Step: 8
Training loss: 0.827241065953818
Validation loss: 2.145412389045704

Epoch: 5| Step: 9
Training loss: 0.43404670631671544
Validation loss: 2.1706881576169965

Epoch: 5| Step: 10
Training loss: 0.3994793640328541
Validation loss: 2.1412378027879684

Epoch: 362| Step: 0
Training loss: 0.5566767898322477
Validation loss: 2.160930657990814

Epoch: 5| Step: 1
Training loss: 0.5600805170213252
Validation loss: 2.1846754199617915

Epoch: 5| Step: 2
Training loss: 0.45343344154881493
Validation loss: 2.158462859648638

Epoch: 5| Step: 3
Training loss: 0.6744476124416582
Validation loss: 2.1401587196171876

Epoch: 5| Step: 4
Training loss: 0.37874232020004284
Validation loss: 2.1394865707786086

Epoch: 5| Step: 5
Training loss: 0.5135816197461388
Validation loss: 2.151390704253308

Epoch: 5| Step: 6
Training loss: 0.29156080805623874
Validation loss: 2.1510230139089708

Epoch: 5| Step: 7
Training loss: 0.4686442255842017
Validation loss: 2.142008878495903

Epoch: 5| Step: 8
Training loss: 0.2647992088200168
Validation loss: 2.1438701425083404

Epoch: 5| Step: 9
Training loss: 0.4157800320761933
Validation loss: 2.1463831268807807

Epoch: 5| Step: 10
Training loss: 0.6429364211343276
Validation loss: 2.164408997991654

Epoch: 363| Step: 0
Training loss: 0.4117177395021029
Validation loss: 2.1424268135400544

Epoch: 5| Step: 1
Training loss: 0.40075133288227865
Validation loss: 2.129052321138126

Epoch: 5| Step: 2
Training loss: 0.7126229397634057
Validation loss: 2.164061791583607

Epoch: 5| Step: 3
Training loss: 0.4636936063743608
Validation loss: 2.1534182308263006

Epoch: 5| Step: 4
Training loss: 0.3805054218078895
Validation loss: 2.149153868866438

Epoch: 5| Step: 5
Training loss: 0.5933510544314698
Validation loss: 2.145743125535107

Epoch: 5| Step: 6
Training loss: 0.1464881705746055
Validation loss: 2.1512478409297913

Epoch: 5| Step: 7
Training loss: 0.540806698998036
Validation loss: 2.148838102667307

Epoch: 5| Step: 8
Training loss: 0.3684450286600774
Validation loss: 2.143623900521866

Epoch: 5| Step: 9
Training loss: 0.5485759984085781
Validation loss: 2.1552773145853807

Epoch: 5| Step: 10
Training loss: 0.45734688056940426
Validation loss: 2.1298737682293383

Epoch: 364| Step: 0
Training loss: 0.5436048281013107
Validation loss: 2.1767674062960927

Epoch: 5| Step: 1
Training loss: 0.364508698408054
Validation loss: 2.159027644431299

Epoch: 5| Step: 2
Training loss: 0.4539943609549154
Validation loss: 2.15095581186866

Epoch: 5| Step: 3
Training loss: 0.457877655079918
Validation loss: 2.1623128847144413

Epoch: 5| Step: 4
Training loss: 0.5953020840832476
Validation loss: 2.1318221177434427

Epoch: 5| Step: 5
Training loss: 0.13602620880649907
Validation loss: 2.168297209316958

Epoch: 5| Step: 6
Training loss: 0.5638640606816285
Validation loss: 2.1731053182497684

Epoch: 5| Step: 7
Training loss: 0.41792134880734205
Validation loss: 2.169261170140847

Epoch: 5| Step: 8
Training loss: 0.566622357412589
Validation loss: 2.174519128391097

Epoch: 5| Step: 9
Training loss: 0.44459893125374716
Validation loss: 2.143244859404259

Epoch: 5| Step: 10
Training loss: 0.5553957755740335
Validation loss: 2.164916719346156

Epoch: 365| Step: 0
Training loss: 0.47876286250333006
Validation loss: 2.1559722136500783

Epoch: 5| Step: 1
Training loss: 0.3277639718951254
Validation loss: 2.1623899936525497

Epoch: 5| Step: 2
Training loss: 0.606359822855733
Validation loss: 2.167330855030766

Epoch: 5| Step: 3
Training loss: 0.601876709362229
Validation loss: 2.192190444728315

Epoch: 5| Step: 4
Training loss: 0.5911342070748419
Validation loss: 2.148768947238385

Epoch: 5| Step: 5
Training loss: 0.300061876651122
Validation loss: 2.18417357568341

Epoch: 5| Step: 6
Training loss: 0.5043743532027738
Validation loss: 2.1453618149733074

Epoch: 5| Step: 7
Training loss: 0.4868867721897303
Validation loss: 2.142889817697278

Epoch: 5| Step: 8
Training loss: 0.4047188514731142
Validation loss: 2.167611406803357

Epoch: 5| Step: 9
Training loss: 0.15078945038786443
Validation loss: 2.15204970990672

Epoch: 5| Step: 10
Training loss: 0.5709184014728281
Validation loss: 2.1755281598934104

Epoch: 366| Step: 0
Training loss: 0.3160817165601599
Validation loss: 2.164934200069518

Epoch: 5| Step: 1
Training loss: 0.39668776082736057
Validation loss: 2.176634191724236

Epoch: 5| Step: 2
Training loss: 0.5459427926429851
Validation loss: 2.169370709931598

Epoch: 5| Step: 3
Training loss: 0.3740130988303174
Validation loss: 2.1577258962790222

Epoch: 5| Step: 4
Training loss: 0.4538782042146253
Validation loss: 2.1632374713489333

Epoch: 5| Step: 5
Training loss: 0.32712746168616275
Validation loss: 2.1436746782392295

Epoch: 5| Step: 6
Training loss: 0.5450320388843354
Validation loss: 2.1916621819168793

Epoch: 5| Step: 7
Training loss: 0.6373556964836664
Validation loss: 2.167569910086721

Epoch: 5| Step: 8
Training loss: 0.5943496587186706
Validation loss: 2.1543800505218393

Epoch: 5| Step: 9
Training loss: 0.37611232139590517
Validation loss: 2.179101224636357

Epoch: 5| Step: 10
Training loss: 0.49930988309744834
Validation loss: 2.1600916060506585

Epoch: 367| Step: 0
Training loss: 0.3464725359041229
Validation loss: 2.167660998157923

Epoch: 5| Step: 1
Training loss: 0.530958628691543
Validation loss: 2.1744673549504947

Epoch: 5| Step: 2
Training loss: 0.33026058187792934
Validation loss: 2.2007354831632333

Epoch: 5| Step: 3
Training loss: 0.6170487308223621
Validation loss: 2.1905850643144285

Epoch: 5| Step: 4
Training loss: 0.31965569868421545
Validation loss: 2.1655781175148134

Epoch: 5| Step: 5
Training loss: 0.5324075653548935
Validation loss: 2.1508440529140906

Epoch: 5| Step: 6
Training loss: 0.5275282360492698
Validation loss: 2.1511864830307688

Epoch: 5| Step: 7
Training loss: 0.45893159928152627
Validation loss: 2.178452353107415

Epoch: 5| Step: 8
Training loss: 0.38777853507331117
Validation loss: 2.2111778538813938

Epoch: 5| Step: 9
Training loss: 0.5211639276972766
Validation loss: 2.1678889930907346

Epoch: 5| Step: 10
Training loss: 0.4450988759069276
Validation loss: 2.185987419537639

Epoch: 368| Step: 0
Training loss: 0.4384456360239472
Validation loss: 2.1633796821515476

Epoch: 5| Step: 1
Training loss: 0.31785905759557687
Validation loss: 2.1553681662771145

Epoch: 5| Step: 2
Training loss: 0.47350112814804113
Validation loss: 2.1507614164924647

Epoch: 5| Step: 3
Training loss: 0.3377805651868573
Validation loss: 2.1626638012927466

Epoch: 5| Step: 4
Training loss: 0.6249021930458923
Validation loss: 2.181579512018897

Epoch: 5| Step: 5
Training loss: 0.7165266977808014
Validation loss: 2.1561054111706124

Epoch: 5| Step: 6
Training loss: 0.423598002880646
Validation loss: 2.1645838221097473

Epoch: 5| Step: 7
Training loss: 0.2511888192781199
Validation loss: 2.1919890171330825

Epoch: 5| Step: 8
Training loss: 0.42702559530545986
Validation loss: 2.146214940966592

Epoch: 5| Step: 9
Training loss: 0.5098073364965316
Validation loss: 2.1652567563715395

Epoch: 5| Step: 10
Training loss: 0.3471777655698676
Validation loss: 2.1477244194414418

Epoch: 369| Step: 0
Training loss: 0.33796625999700936
Validation loss: 2.1543210095123295

Epoch: 5| Step: 1
Training loss: 0.4266421861939575
Validation loss: 2.188854510715065

Epoch: 5| Step: 2
Training loss: 0.2336880311829824
Validation loss: 2.1716218831706744

Epoch: 5| Step: 3
Training loss: 0.39480003794280527
Validation loss: 2.1656250836227744

Epoch: 5| Step: 4
Training loss: 0.688380414593392
Validation loss: 2.1609316438553416

Epoch: 5| Step: 5
Training loss: 0.4467255442457232
Validation loss: 2.1451643713345248

Epoch: 5| Step: 6
Training loss: 0.5291935724892406
Validation loss: 2.1659686348114

Epoch: 5| Step: 7
Training loss: 0.6025381969278756
Validation loss: 2.173690283978061

Epoch: 5| Step: 8
Training loss: 0.35856682670101253
Validation loss: 2.164836694861317

Epoch: 5| Step: 9
Training loss: 0.5109296932265665
Validation loss: 2.15315831865845

Epoch: 5| Step: 10
Training loss: 0.2605588890176837
Validation loss: 2.1609692677161276

Epoch: 370| Step: 0
Training loss: 0.27351660265471334
Validation loss: 2.1882410484769856

Epoch: 5| Step: 1
Training loss: 0.23237053921302928
Validation loss: 2.1860966847017007

Epoch: 5| Step: 2
Training loss: 0.48292191262587075
Validation loss: 2.170155029849388

Epoch: 5| Step: 3
Training loss: 0.3942551732785197
Validation loss: 2.1618243144222395

Epoch: 5| Step: 4
Training loss: 0.5240476383019526
Validation loss: 2.1724507036632854

Epoch: 5| Step: 5
Training loss: 0.4282168797937434
Validation loss: 2.141094548184647

Epoch: 5| Step: 6
Training loss: 0.26907629509362263
Validation loss: 2.155123142877946

Epoch: 5| Step: 7
Training loss: 0.544404471264261
Validation loss: 2.1523152219529416

Epoch: 5| Step: 8
Training loss: 0.712268338270962
Validation loss: 2.1573867583507838

Epoch: 5| Step: 9
Training loss: 0.5276836006592481
Validation loss: 2.17554607502263

Epoch: 5| Step: 10
Training loss: 0.4600216284881313
Validation loss: 2.189821521466704

Epoch: 371| Step: 0
Training loss: 0.638135655769056
Validation loss: 2.1834446609615337

Epoch: 5| Step: 1
Training loss: 0.5829172751001105
Validation loss: 2.1890138570731557

Epoch: 5| Step: 2
Training loss: 0.4266011629293984
Validation loss: 2.1885425696614895

Epoch: 5| Step: 3
Training loss: 0.37224272490412635
Validation loss: 2.1818398677990243

Epoch: 5| Step: 4
Training loss: 0.47427348429056776
Validation loss: 2.174112035008936

Epoch: 5| Step: 5
Training loss: 0.20895365908203695
Validation loss: 2.177676359191384

Epoch: 5| Step: 6
Training loss: 0.3650246492319255
Validation loss: 2.197765480638356

Epoch: 5| Step: 7
Training loss: 0.5021021580893417
Validation loss: 2.179223780372871

Epoch: 5| Step: 8
Training loss: 0.6013068361839331
Validation loss: 2.1602096371518806

Epoch: 5| Step: 9
Training loss: 0.41059809908721834
Validation loss: 2.159068525217633

Epoch: 5| Step: 10
Training loss: 0.35963842854307854
Validation loss: 2.1448687452155344

Epoch: 372| Step: 0
Training loss: 0.4838581711925388
Validation loss: 2.1679009226386294

Epoch: 5| Step: 1
Training loss: 0.49274410080342074
Validation loss: 2.15079624554057

Epoch: 5| Step: 2
Training loss: 0.3296964684843946
Validation loss: 2.1608357068077546

Epoch: 5| Step: 3
Training loss: 0.49253937087048233
Validation loss: 2.167325823154854

Epoch: 5| Step: 4
Training loss: 0.3353015624659546
Validation loss: 2.1544518792875937

Epoch: 5| Step: 5
Training loss: 0.46815876231656706
Validation loss: 2.1605332076135197

Epoch: 5| Step: 6
Training loss: 0.2645853959901763
Validation loss: 2.134671210533996

Epoch: 5| Step: 7
Training loss: 0.4429839473048327
Validation loss: 2.1662105035933656

Epoch: 5| Step: 8
Training loss: 0.5457252132066023
Validation loss: 2.173579685116319

Epoch: 5| Step: 9
Training loss: 0.563045369783128
Validation loss: 2.15153307909103

Epoch: 5| Step: 10
Training loss: 0.5249233791660765
Validation loss: 2.18972564544199

Epoch: 373| Step: 0
Training loss: 0.4915195049536933
Validation loss: 2.1488159287908144

Epoch: 5| Step: 1
Training loss: 0.40462863597114185
Validation loss: 2.1544527574536008

Epoch: 5| Step: 2
Training loss: 0.3841209626610978
Validation loss: 2.134421243870644

Epoch: 5| Step: 3
Training loss: 0.5784898843647417
Validation loss: 2.1155659394873836

Epoch: 5| Step: 4
Training loss: 0.3343797429363384
Validation loss: 2.1453965918711613

Epoch: 5| Step: 5
Training loss: 0.3143978544198115
Validation loss: 2.1326424691197503

Epoch: 5| Step: 6
Training loss: 0.5156106657867889
Validation loss: 2.129514655333226

Epoch: 5| Step: 7
Training loss: 0.489237010155706
Validation loss: 2.1404773459736086

Epoch: 5| Step: 8
Training loss: 0.4864767376061453
Validation loss: 2.17135834231068

Epoch: 5| Step: 9
Training loss: 0.39499210597250406
Validation loss: 2.1820014335553397

Epoch: 5| Step: 10
Training loss: 0.5757244635934495
Validation loss: 2.195207972500074

Epoch: 374| Step: 0
Training loss: 0.3265971763123775
Validation loss: 2.204269462176678

Epoch: 5| Step: 1
Training loss: 0.4605789406366053
Validation loss: 2.1989827018551025

Epoch: 5| Step: 2
Training loss: 0.4158734539829936
Validation loss: 2.1451968706609588

Epoch: 5| Step: 3
Training loss: 0.37733106493113594
Validation loss: 2.165250817177521

Epoch: 5| Step: 4
Training loss: 0.2818397986979622
Validation loss: 2.134776065601498

Epoch: 5| Step: 5
Training loss: 0.5775644058792179
Validation loss: 2.15203749712267

Epoch: 5| Step: 6
Training loss: 0.3602577232020068
Validation loss: 2.140545930323516

Epoch: 5| Step: 7
Training loss: 0.6405332080859338
Validation loss: 2.161537074287995

Epoch: 5| Step: 8
Training loss: 0.36627154039568155
Validation loss: 2.17678826994785

Epoch: 5| Step: 9
Training loss: 0.6584916204181487
Validation loss: 2.1609208005071663

Epoch: 5| Step: 10
Training loss: 0.4693896379994729
Validation loss: 2.174275181937465

Epoch: 375| Step: 0
Training loss: 0.6033892452912634
Validation loss: 2.182038252363608

Epoch: 5| Step: 1
Training loss: 0.40255394787314835
Validation loss: 2.1890954166377057

Epoch: 5| Step: 2
Training loss: 0.4713629375786834
Validation loss: 2.2102570593490767

Epoch: 5| Step: 3
Training loss: 0.37620806812059165
Validation loss: 2.200876170841171

Epoch: 5| Step: 4
Training loss: 0.20409865126290325
Validation loss: 2.2000040531820284

Epoch: 5| Step: 5
Training loss: 0.4079677140256716
Validation loss: 2.1847371198921066

Epoch: 5| Step: 6
Training loss: 0.4964010683485072
Validation loss: 2.1553905427423867

Epoch: 5| Step: 7
Training loss: 0.4001601509520762
Validation loss: 2.1604499426616433

Epoch: 5| Step: 8
Training loss: 0.48348811695265936
Validation loss: 2.1528613931580223

Epoch: 5| Step: 9
Training loss: 0.44228623032729003
Validation loss: 2.177071361466635

Epoch: 5| Step: 10
Training loss: 0.5826590307838901
Validation loss: 2.15530254312524

Epoch: 376| Step: 0
Training loss: 0.6202354018105204
Validation loss: 2.167465409021315

Epoch: 5| Step: 1
Training loss: 0.530067923889729
Validation loss: 2.1849634374038036

Epoch: 5| Step: 2
Training loss: 0.3944792004989772
Validation loss: 2.1790432368367987

Epoch: 5| Step: 3
Training loss: 0.5329654429346269
Validation loss: 2.1850126431472634

Epoch: 5| Step: 4
Training loss: 0.4078346122213177
Validation loss: 2.205439788385376

Epoch: 5| Step: 5
Training loss: 0.36852566393016145
Validation loss: 2.1886645385965706

Epoch: 5| Step: 6
Training loss: 0.48282444331140445
Validation loss: 2.1927365759217228

Epoch: 5| Step: 7
Training loss: 0.3868208856282353
Validation loss: 2.2005003328503716

Epoch: 5| Step: 8
Training loss: 0.4409932930819109
Validation loss: 2.2017427889799235

Epoch: 5| Step: 9
Training loss: 0.27549745638394874
Validation loss: 2.212567111664215

Epoch: 5| Step: 10
Training loss: 0.3416564980114077
Validation loss: 2.203447034309609

Epoch: 377| Step: 0
Training loss: 0.3292598739778532
Validation loss: 2.1929990849298946

Epoch: 5| Step: 1
Training loss: 0.3697177875845794
Validation loss: 2.1598209465854974

Epoch: 5| Step: 2
Training loss: 0.18428353328043945
Validation loss: 2.191996539665424

Epoch: 5| Step: 3
Training loss: 0.5083750616467047
Validation loss: 2.1687487315782126

Epoch: 5| Step: 4
Training loss: 0.49618226110285224
Validation loss: 2.1607433343822797

Epoch: 5| Step: 5
Training loss: 0.4030037253955425
Validation loss: 2.1464807286648115

Epoch: 5| Step: 6
Training loss: 0.6995514019791552
Validation loss: 2.1610781743879834

Epoch: 5| Step: 7
Training loss: 0.33558624223160877
Validation loss: 2.1281313809604896

Epoch: 5| Step: 8
Training loss: 0.1518318182384272
Validation loss: 2.162033017604658

Epoch: 5| Step: 9
Training loss: 0.6443087106937972
Validation loss: 2.1356855547810776

Epoch: 5| Step: 10
Training loss: 0.324699883633297
Validation loss: 2.1494397370503817

Epoch: 378| Step: 0
Training loss: 0.5897106500477366
Validation loss: 2.127719401935046

Epoch: 5| Step: 1
Training loss: 0.40285594522412677
Validation loss: 2.1606957650232608

Epoch: 5| Step: 2
Training loss: 0.3871801686920598
Validation loss: 2.1581723972490816

Epoch: 5| Step: 3
Training loss: 0.3872247333496878
Validation loss: 2.185250830306907

Epoch: 5| Step: 4
Training loss: 0.34322094302052936
Validation loss: 2.1682556666078314

Epoch: 5| Step: 5
Training loss: 0.5502391338670685
Validation loss: 2.1937172195588635

Epoch: 5| Step: 6
Training loss: 0.27846476503795137
Validation loss: 2.155644789465914

Epoch: 5| Step: 7
Training loss: 0.411642976769712
Validation loss: 2.17382374263964

Epoch: 5| Step: 8
Training loss: 0.42761929152669675
Validation loss: 2.1613400894085077

Epoch: 5| Step: 9
Training loss: 0.5883480586279504
Validation loss: 2.153217085859872

Epoch: 5| Step: 10
Training loss: 0.3248664636638964
Validation loss: 2.1574368907138872

Epoch: 379| Step: 0
Training loss: 0.16441573988878375
Validation loss: 2.165839317316762

Epoch: 5| Step: 1
Training loss: 0.5053103497989653
Validation loss: 2.174367959269509

Epoch: 5| Step: 2
Training loss: 0.6372279138176
Validation loss: 2.1335327754442774

Epoch: 5| Step: 3
Training loss: 0.5053955956752844
Validation loss: 2.1446370108208175

Epoch: 5| Step: 4
Training loss: 0.522619661838118
Validation loss: 2.1559210929628425

Epoch: 5| Step: 5
Training loss: 0.3518081866196622
Validation loss: 2.1765511887802984

Epoch: 5| Step: 6
Training loss: 0.5957948207635233
Validation loss: 2.1543580776736757

Epoch: 5| Step: 7
Training loss: 0.2624737397183
Validation loss: 2.17083260005129

Epoch: 5| Step: 8
Training loss: 0.33354075008570583
Validation loss: 2.178089671336081

Epoch: 5| Step: 9
Training loss: 0.36437417797434296
Validation loss: 2.180820605007618

Epoch: 5| Step: 10
Training loss: 0.10949179254951245
Validation loss: 2.1682040155525697

Epoch: 380| Step: 0
Training loss: 0.3306489782165587
Validation loss: 2.1514626423540695

Epoch: 5| Step: 1
Training loss: 0.4467514614258501
Validation loss: 2.162818822902874

Epoch: 5| Step: 2
Training loss: 0.5053476226811111
Validation loss: 2.1283772779557526

Epoch: 5| Step: 3
Training loss: 0.41192995477571825
Validation loss: 2.170009644453236

Epoch: 5| Step: 4
Training loss: 0.436451165619158
Validation loss: 2.1427528156902906

Epoch: 5| Step: 5
Training loss: 0.5921564048715754
Validation loss: 2.1592936602395993

Epoch: 5| Step: 6
Training loss: 0.4152078262985714
Validation loss: 2.1669929186192234

Epoch: 5| Step: 7
Training loss: 0.2728264247534795
Validation loss: 2.1519258962029566

Epoch: 5| Step: 8
Training loss: 0.38331769189159404
Validation loss: 2.144442819703147

Epoch: 5| Step: 9
Training loss: 0.5840585208632773
Validation loss: 2.170514703927142

Epoch: 5| Step: 10
Training loss: 0.13426431072448203
Validation loss: 2.1629972725591613

Epoch: 381| Step: 0
Training loss: 0.35636809048197987
Validation loss: 2.1592373501898314

Epoch: 5| Step: 1
Training loss: 0.48215747645834856
Validation loss: 2.142065266842343

Epoch: 5| Step: 2
Training loss: 0.3977127214965338
Validation loss: 2.1428265263967576

Epoch: 5| Step: 3
Training loss: 0.5029225172994641
Validation loss: 2.1515795451274053

Epoch: 5| Step: 4
Training loss: 0.42794352256177304
Validation loss: 2.146771867778443

Epoch: 5| Step: 5
Training loss: 0.47048113958337023
Validation loss: 2.1581025205152704

Epoch: 5| Step: 6
Training loss: 0.3865251152692238
Validation loss: 2.1520226426290683

Epoch: 5| Step: 7
Training loss: 0.3937124120845709
Validation loss: 2.165468524389727

Epoch: 5| Step: 8
Training loss: 0.4198200545955199
Validation loss: 2.166855164540655

Epoch: 5| Step: 9
Training loss: 0.2350703890622003
Validation loss: 2.1636934120763898

Epoch: 5| Step: 10
Training loss: 0.5565783549497023
Validation loss: 2.1867008138106834

Epoch: 382| Step: 0
Training loss: 0.46661266379166116
Validation loss: 2.200322783260725

Epoch: 5| Step: 1
Training loss: 0.3566776720173247
Validation loss: 2.177598688434558

Epoch: 5| Step: 2
Training loss: 0.3913576122528584
Validation loss: 2.1538476066903924

Epoch: 5| Step: 3
Training loss: 0.4995318545760528
Validation loss: 2.1879355399872087

Epoch: 5| Step: 4
Training loss: 0.4817451023413077
Validation loss: 2.1745937278672085

Epoch: 5| Step: 5
Training loss: 0.208985765399051
Validation loss: 2.1594955088618364

Epoch: 5| Step: 6
Training loss: 0.42176969414831395
Validation loss: 2.1666498936870813

Epoch: 5| Step: 7
Training loss: 0.2823469967594731
Validation loss: 2.1580598620946363

Epoch: 5| Step: 8
Training loss: 0.2893976897207446
Validation loss: 2.1673857341300002

Epoch: 5| Step: 9
Training loss: 0.5878442384789708
Validation loss: 2.175149758321883

Epoch: 5| Step: 10
Training loss: 0.4755919689132834
Validation loss: 2.1793980736535636

Epoch: 383| Step: 0
Training loss: 0.4553182238688324
Validation loss: 2.16222227561958

Epoch: 5| Step: 1
Training loss: 0.48612953635522227
Validation loss: 2.1554769872457693

Epoch: 5| Step: 2
Training loss: 0.48628862825739394
Validation loss: 2.1487768978696575

Epoch: 5| Step: 3
Training loss: 0.5753667346063156
Validation loss: 2.1627042482471435

Epoch: 5| Step: 4
Training loss: 0.45372206714919616
Validation loss: 2.179111726196485

Epoch: 5| Step: 5
Training loss: 0.28330789140933
Validation loss: 2.176642025849541

Epoch: 5| Step: 6
Training loss: 0.34344358225357735
Validation loss: 2.1689523771572023

Epoch: 5| Step: 7
Training loss: 0.3506710193645521
Validation loss: 2.1528780721200684

Epoch: 5| Step: 8
Training loss: 0.42535473520646033
Validation loss: 2.161022741847135

Epoch: 5| Step: 9
Training loss: 0.2029947266610176
Validation loss: 2.178957232820659

Epoch: 5| Step: 10
Training loss: 0.4308989353642178
Validation loss: 2.200388749632861

Epoch: 384| Step: 0
Training loss: 0.41041436928946806
Validation loss: 2.1994184425468526

Epoch: 5| Step: 1
Training loss: 0.33058353531830253
Validation loss: 2.2043668571559087

Epoch: 5| Step: 2
Training loss: 0.31538058864300167
Validation loss: 2.1880667003679655

Epoch: 5| Step: 3
Training loss: 0.6384588697146126
Validation loss: 2.1932876392993474

Epoch: 5| Step: 4
Training loss: 0.6162642321384322
Validation loss: 2.1861457769873476

Epoch: 5| Step: 5
Training loss: 0.43259076797724055
Validation loss: 2.196611963610167

Epoch: 5| Step: 6
Training loss: 0.33100864911736166
Validation loss: 2.183532545510317

Epoch: 5| Step: 7
Training loss: 0.3865690615936675
Validation loss: 2.1380708020710775

Epoch: 5| Step: 8
Training loss: 0.3745538322315318
Validation loss: 2.1558546583970006

Epoch: 5| Step: 9
Training loss: 0.32904715611837854
Validation loss: 2.1713041799391344

Epoch: 5| Step: 10
Training loss: 0.2573470480127938
Validation loss: 2.1666494215790917

Epoch: 385| Step: 0
Training loss: 0.5675887818986729
Validation loss: 2.1352319148768086

Epoch: 5| Step: 1
Training loss: 0.5534346495026685
Validation loss: 2.1687514160866552

Epoch: 5| Step: 2
Training loss: 0.19249717101891778
Validation loss: 2.1445361446895053

Epoch: 5| Step: 3
Training loss: 0.5047992806904077
Validation loss: 2.125926208600685

Epoch: 5| Step: 4
Training loss: 0.43709828462414657
Validation loss: 2.15240100982226

Epoch: 5| Step: 5
Training loss: 0.410361883296025
Validation loss: 2.1609500465772977

Epoch: 5| Step: 6
Training loss: 0.13830051261014886
Validation loss: 2.1833168347444625

Epoch: 5| Step: 7
Training loss: 0.5019011118023573
Validation loss: 2.1710269984329154

Epoch: 5| Step: 8
Training loss: 0.4569105168169387
Validation loss: 2.1727141161542978

Epoch: 5| Step: 9
Training loss: 0.3705850025099665
Validation loss: 2.2064856244366635

Epoch: 5| Step: 10
Training loss: 0.3316898048878588
Validation loss: 2.2018150624946107

Epoch: 386| Step: 0
Training loss: 0.4184942952215026
Validation loss: 2.175296368796596

Epoch: 5| Step: 1
Training loss: 0.40959050352056064
Validation loss: 2.156870915910113

Epoch: 5| Step: 2
Training loss: 0.5794186680786308
Validation loss: 2.166404758775307

Epoch: 5| Step: 3
Training loss: 0.4626855355643206
Validation loss: 2.1673037331523535

Epoch: 5| Step: 4
Training loss: 0.4353112922208069
Validation loss: 2.1781747088910812

Epoch: 5| Step: 5
Training loss: 0.5723511042891761
Validation loss: 2.163204160458777

Epoch: 5| Step: 6
Training loss: 0.24810600326950175
Validation loss: 2.1914889505907245

Epoch: 5| Step: 7
Training loss: 0.2621701461450347
Validation loss: 2.162199865517111

Epoch: 5| Step: 8
Training loss: 0.45559950664349536
Validation loss: 2.1844382262940587

Epoch: 5| Step: 9
Training loss: 0.4558930365809857
Validation loss: 2.1877569847513048

Epoch: 5| Step: 10
Training loss: 0.4092887969657029
Validation loss: 2.188109657192636

Epoch: 387| Step: 0
Training loss: 0.40259457149479544
Validation loss: 2.164379628689127

Epoch: 5| Step: 1
Training loss: 0.39271865530977423
Validation loss: 2.1323048987003275

Epoch: 5| Step: 2
Training loss: 0.2850373033111433
Validation loss: 2.134773787503594

Epoch: 5| Step: 3
Training loss: 0.42859201367645733
Validation loss: 2.1426577077516824

Epoch: 5| Step: 4
Training loss: 0.5305360877735548
Validation loss: 2.1321342465899034

Epoch: 5| Step: 5
Training loss: 0.3845337299637418
Validation loss: 2.134521815110713

Epoch: 5| Step: 6
Training loss: 0.47425375279765153
Validation loss: 2.1373532409697855

Epoch: 5| Step: 7
Training loss: 0.3722037128789586
Validation loss: 2.1494450269745147

Epoch: 5| Step: 8
Training loss: 0.4439980700017033
Validation loss: 2.159404087335241

Epoch: 5| Step: 9
Training loss: 0.5114704432351955
Validation loss: 2.1781894209339634

Epoch: 5| Step: 10
Training loss: 0.36374863942209734
Validation loss: 2.178647865484168

Epoch: 388| Step: 0
Training loss: 0.5150767503879464
Validation loss: 2.1674736660117673

Epoch: 5| Step: 1
Training loss: 0.4913598322209805
Validation loss: 2.1994108393293628

Epoch: 5| Step: 2
Training loss: 0.4859729067055741
Validation loss: 2.235567682857273

Epoch: 5| Step: 3
Training loss: 0.3267494843602216
Validation loss: 2.1892687278693845

Epoch: 5| Step: 4
Training loss: 0.2528782501351257
Validation loss: 2.1448892817927128

Epoch: 5| Step: 5
Training loss: 0.4169607574982269
Validation loss: 2.160728596689817

Epoch: 5| Step: 6
Training loss: 0.5849529386810952
Validation loss: 2.0955803403624484

Epoch: 5| Step: 7
Training loss: 0.44852689456785144
Validation loss: 2.118252366881472

Epoch: 5| Step: 8
Training loss: 0.49618622526194156
Validation loss: 2.1099577226083768

Epoch: 5| Step: 9
Training loss: 0.3775306388913818
Validation loss: 2.1302733173853827

Epoch: 5| Step: 10
Training loss: 0.270755723079099
Validation loss: 2.1260031408033737

Epoch: 389| Step: 0
Training loss: 0.26291318459378826
Validation loss: 2.194250333389059

Epoch: 5| Step: 1
Training loss: 0.4812745880682404
Validation loss: 2.2035163485847917

Epoch: 5| Step: 2
Training loss: 0.4703943814956199
Validation loss: 2.203679191002665

Epoch: 5| Step: 3
Training loss: 0.58488838369959
Validation loss: 2.218009854743014

Epoch: 5| Step: 4
Training loss: 0.4617010193855859
Validation loss: 2.2225449382436087

Epoch: 5| Step: 5
Training loss: 0.4523335648412869
Validation loss: 2.2093691212588853

Epoch: 5| Step: 6
Training loss: 0.5561066056920223
Validation loss: 2.138141070880906

Epoch: 5| Step: 7
Training loss: 0.6571277470436026
Validation loss: 2.161405552974417

Epoch: 5| Step: 8
Training loss: 0.5132137910359076
Validation loss: 2.1658995747887486

Epoch: 5| Step: 9
Training loss: 0.4274366553262396
Validation loss: 2.1628496096915906

Epoch: 5| Step: 10
Training loss: 0.4772257176641783
Validation loss: 2.1961062012551817

Epoch: 390| Step: 0
Training loss: 0.4094272674798238
Validation loss: 2.207340303562573

Epoch: 5| Step: 1
Training loss: 0.5054366359502832
Validation loss: 2.21895959566945

Epoch: 5| Step: 2
Training loss: 0.39669429690168306
Validation loss: 2.2124859553065654

Epoch: 5| Step: 3
Training loss: 0.6896109035739053
Validation loss: 2.175983043952643

Epoch: 5| Step: 4
Training loss: 0.533932253701407
Validation loss: 2.14203606512892

Epoch: 5| Step: 5
Training loss: 0.48762969223694597
Validation loss: 2.1585234239953084

Epoch: 5| Step: 6
Training loss: 0.6019007487349917
Validation loss: 2.146418186722039

Epoch: 5| Step: 7
Training loss: 0.4662108953097979
Validation loss: 2.106073073504411

Epoch: 5| Step: 8
Training loss: 0.4480572653565903
Validation loss: 2.1252988669079764

Epoch: 5| Step: 9
Training loss: 0.4158722715583551
Validation loss: 2.165817058274045

Epoch: 5| Step: 10
Training loss: 0.6935250527601723
Validation loss: 2.2109872134153545

Epoch: 391| Step: 0
Training loss: 0.6054371241031511
Validation loss: 2.167236231570153

Epoch: 5| Step: 1
Training loss: 0.46376968162085963
Validation loss: 2.182743138487409

Epoch: 5| Step: 2
Training loss: 0.30137093443404706
Validation loss: 2.2060818989010733

Epoch: 5| Step: 3
Training loss: 0.5426278450624812
Validation loss: 2.2292009473098195

Epoch: 5| Step: 4
Training loss: 0.8319877648966991
Validation loss: 2.202235668184468

Epoch: 5| Step: 5
Training loss: 0.5311270459324913
Validation loss: 2.226552560320294

Epoch: 5| Step: 6
Training loss: 0.3352838966740892
Validation loss: 2.135279175068486

Epoch: 5| Step: 7
Training loss: 0.49041218971384776
Validation loss: 2.097553342081315

Epoch: 5| Step: 8
Training loss: 0.4075996647401017
Validation loss: 2.0631694956288738

Epoch: 5| Step: 9
Training loss: 0.5939472774233518
Validation loss: 2.0787762116489605

Epoch: 5| Step: 10
Training loss: 0.4451863628899371
Validation loss: 2.07700157964472

Epoch: 392| Step: 0
Training loss: 0.5255805030521953
Validation loss: 2.0785642504020037

Epoch: 5| Step: 1
Training loss: 0.4911603048329169
Validation loss: 2.116900025494142

Epoch: 5| Step: 2
Training loss: 0.5147301393691354
Validation loss: 2.129199416224561

Epoch: 5| Step: 3
Training loss: 0.38589015006132565
Validation loss: 2.1684440756140693

Epoch: 5| Step: 4
Training loss: 0.6871438621206897
Validation loss: 2.209297823586002

Epoch: 5| Step: 5
Training loss: 0.5802798963846614
Validation loss: 2.1965152112988084

Epoch: 5| Step: 6
Training loss: 0.40606955041881204
Validation loss: 2.2410957108237564

Epoch: 5| Step: 7
Training loss: 0.40923771412630394
Validation loss: 2.200529058714948

Epoch: 5| Step: 8
Training loss: 0.6264182212410747
Validation loss: 2.1797520367771543

Epoch: 5| Step: 9
Training loss: 0.3979649640110287
Validation loss: 2.156432006345152

Epoch: 5| Step: 10
Training loss: 0.5148339995646136
Validation loss: 2.162991828809229

Epoch: 393| Step: 0
Training loss: 0.41789248474814095
Validation loss: 2.1664590903760295

Epoch: 5| Step: 1
Training loss: 0.4164092838541842
Validation loss: 2.164634585732867

Epoch: 5| Step: 2
Training loss: 0.41562551914268714
Validation loss: 2.1637459723329893

Epoch: 5| Step: 3
Training loss: 0.5479392459215432
Validation loss: 2.1603142017237653

Epoch: 5| Step: 4
Training loss: 0.5572680233607362
Validation loss: 2.161429376824571

Epoch: 5| Step: 5
Training loss: 0.3612765301133034
Validation loss: 2.1461354716084897

Epoch: 5| Step: 6
Training loss: 0.3888746719751351
Validation loss: 2.1893964782466737

Epoch: 5| Step: 7
Training loss: 0.4690525032518305
Validation loss: 2.1766660427475846

Epoch: 5| Step: 8
Training loss: 0.6465250791891041
Validation loss: 2.2045304170527693

Epoch: 5| Step: 9
Training loss: 0.36967026593755287
Validation loss: 2.1758739966936806

Epoch: 5| Step: 10
Training loss: 0.3694141928378199
Validation loss: 2.180797160216865

Epoch: 394| Step: 0
Training loss: 0.4365298720873366
Validation loss: 2.1947588350321046

Epoch: 5| Step: 1
Training loss: 0.5324577179540587
Validation loss: 2.193845289332273

Epoch: 5| Step: 2
Training loss: 0.3508370225573464
Validation loss: 2.1969158291051247

Epoch: 5| Step: 3
Training loss: 0.2868505076422679
Validation loss: 2.179283321910411

Epoch: 5| Step: 4
Training loss: 0.3640770143881856
Validation loss: 2.170247624211519

Epoch: 5| Step: 5
Training loss: 0.4249247764885311
Validation loss: 2.1780954975444047

Epoch: 5| Step: 6
Training loss: 0.2883671051204686
Validation loss: 2.1681486173951585

Epoch: 5| Step: 7
Training loss: 0.5752913131003644
Validation loss: 2.1806542036962817

Epoch: 5| Step: 8
Training loss: 0.5781567539051858
Validation loss: 2.1980587866150887

Epoch: 5| Step: 9
Training loss: 0.630196946937117
Validation loss: 2.180413234608578

Epoch: 5| Step: 10
Training loss: 0.3080967147720096
Validation loss: 2.1554836571729012

Epoch: 395| Step: 0
Training loss: 0.32052620295102563
Validation loss: 2.1810831720912613

Epoch: 5| Step: 1
Training loss: 0.43658354684589423
Validation loss: 2.167747305177418

Epoch: 5| Step: 2
Training loss: 0.5153762043752206
Validation loss: 2.18079098033083

Epoch: 5| Step: 3
Training loss: 0.5168726882052587
Validation loss: 2.2122052445867926

Epoch: 5| Step: 4
Training loss: 0.43155415562125066
Validation loss: 2.2081699910723938

Epoch: 5| Step: 5
Training loss: 0.3994230721723653
Validation loss: 2.2281778080298644

Epoch: 5| Step: 6
Training loss: 0.4828566318082604
Validation loss: 2.2177749205864954

Epoch: 5| Step: 7
Training loss: 0.3680985086296833
Validation loss: 2.2182883788091448

Epoch: 5| Step: 8
Training loss: 0.41482656985698363
Validation loss: 2.229687491790601

Epoch: 5| Step: 9
Training loss: 0.5044921307890502
Validation loss: 2.2172298891553064

Epoch: 5| Step: 10
Training loss: 0.2559261380516029
Validation loss: 2.2393488947042006

Epoch: 396| Step: 0
Training loss: 0.287467512596462
Validation loss: 2.2328043284147867

Epoch: 5| Step: 1
Training loss: 0.43566969777665127
Validation loss: 2.1908472103488115

Epoch: 5| Step: 2
Training loss: 0.16397428411556353
Validation loss: 2.191309283928427

Epoch: 5| Step: 3
Training loss: 0.2957581669162701
Validation loss: 2.1558815033546583

Epoch: 5| Step: 4
Training loss: 0.44608651203757277
Validation loss: 2.138416044867615

Epoch: 5| Step: 5
Training loss: 0.5470036219157898
Validation loss: 2.1628459494606873

Epoch: 5| Step: 6
Training loss: 0.42379857325036946
Validation loss: 2.1331540035318186

Epoch: 5| Step: 7
Training loss: 0.37001700542652033
Validation loss: 2.1415168156594384

Epoch: 5| Step: 8
Training loss: 0.599394595170943
Validation loss: 2.184438297883209

Epoch: 5| Step: 9
Training loss: 0.3057716594628658
Validation loss: 2.186258933186273

Epoch: 5| Step: 10
Training loss: 0.49746197032783807
Validation loss: 2.195973113235634

Epoch: 397| Step: 0
Training loss: 0.2871344678643877
Validation loss: 2.181088704682279

Epoch: 5| Step: 1
Training loss: 0.23544026519573316
Validation loss: 2.211532506332147

Epoch: 5| Step: 2
Training loss: 0.4716645548349737
Validation loss: 2.1936072558653605

Epoch: 5| Step: 3
Training loss: 0.32999963222107476
Validation loss: 2.2299497097541066

Epoch: 5| Step: 4
Training loss: 0.49531593321564055
Validation loss: 2.223409612442109

Epoch: 5| Step: 5
Training loss: 0.38909800570459
Validation loss: 2.2384208720551606

Epoch: 5| Step: 6
Training loss: 0.49659583448582645
Validation loss: 2.207555285737141

Epoch: 5| Step: 7
Training loss: 0.4284755608078064
Validation loss: 2.233327652114795

Epoch: 5| Step: 8
Training loss: 0.3673099962804422
Validation loss: 2.2603910658409103

Epoch: 5| Step: 9
Training loss: 0.35147788830986815
Validation loss: 2.2267681240605466

Epoch: 5| Step: 10
Training loss: 0.4446835174971979
Validation loss: 2.2354839638418187

Epoch: 398| Step: 0
Training loss: 0.28695846016751203
Validation loss: 2.2385469259750974

Epoch: 5| Step: 1
Training loss: 0.3739420550778416
Validation loss: 2.243235999178666

Epoch: 5| Step: 2
Training loss: 0.5452636412672375
Validation loss: 2.274076588966476

Epoch: 5| Step: 3
Training loss: 0.3486926671212977
Validation loss: 2.2459480781273933

Epoch: 5| Step: 4
Training loss: 0.34463145211053137
Validation loss: 2.2307781202264234

Epoch: 5| Step: 5
Training loss: 0.33281910491263667
Validation loss: 2.2341396736511014

Epoch: 5| Step: 6
Training loss: 0.2838240032910033
Validation loss: 2.243594929248416

Epoch: 5| Step: 7
Training loss: 0.42350584513200895
Validation loss: 2.2232459971844634

Epoch: 5| Step: 8
Training loss: 0.42380882254387386
Validation loss: 2.2248608133957375

Epoch: 5| Step: 9
Training loss: 0.45112119117517824
Validation loss: 2.2433731793278615

Epoch: 5| Step: 10
Training loss: 0.49026072761863226
Validation loss: 2.2202101441920004

Epoch: 399| Step: 0
Training loss: 0.22156422502736625
Validation loss: 2.2074889296268485

Epoch: 5| Step: 1
Training loss: 0.3921173010080332
Validation loss: 2.259341793059945

Epoch: 5| Step: 2
Training loss: 0.2915220015387073
Validation loss: 2.2138099275258827

Epoch: 5| Step: 3
Training loss: 0.5115174050283102
Validation loss: 2.1979045831623893

Epoch: 5| Step: 4
Training loss: 0.3292696831858185
Validation loss: 2.188488514537516

Epoch: 5| Step: 5
Training loss: 0.4909591636272991
Validation loss: 2.19207380318617

Epoch: 5| Step: 6
Training loss: 0.3826424746605935
Validation loss: 2.1896582338670294

Epoch: 5| Step: 7
Training loss: 0.4074512657617262
Validation loss: 2.191607164410939

Epoch: 5| Step: 8
Training loss: 0.4454213728743824
Validation loss: 2.185702430023324

Epoch: 5| Step: 9
Training loss: 0.19878427962615278
Validation loss: 2.2054178941530767

Epoch: 5| Step: 10
Training loss: 0.4303418811970539
Validation loss: 2.170389043181906

Epoch: 400| Step: 0
Training loss: 0.3931781680992094
Validation loss: 2.175126650485242

Epoch: 5| Step: 1
Training loss: 0.35683545225848534
Validation loss: 2.1934096459237833

Epoch: 5| Step: 2
Training loss: 0.41159300069094157
Validation loss: 2.182013636066658

Epoch: 5| Step: 3
Training loss: 0.24103321833519648
Validation loss: 2.173246820809253

Epoch: 5| Step: 4
Training loss: 0.23189919467613881
Validation loss: 2.2088339287167478

Epoch: 5| Step: 5
Training loss: 0.39146184926114597
Validation loss: 2.194349224525098

Epoch: 5| Step: 6
Training loss: 0.33997198951917657
Validation loss: 2.18695935601444

Epoch: 5| Step: 7
Training loss: 0.5031935805025732
Validation loss: 2.1848211911631763

Epoch: 5| Step: 8
Training loss: 0.41632301543613826
Validation loss: 2.2152445241142167

Epoch: 5| Step: 9
Training loss: 0.5247355635294199
Validation loss: 2.2165985797899177

Epoch: 5| Step: 10
Training loss: 0.25686610519713476
Validation loss: 2.1951209133481138

Epoch: 401| Step: 0
Training loss: 0.23276025518714924
Validation loss: 2.1800920611826644

Epoch: 5| Step: 1
Training loss: 0.38149927619925417
Validation loss: 2.179874880954747

Epoch: 5| Step: 2
Training loss: 0.29533918805101117
Validation loss: 2.1951427520355904

Epoch: 5| Step: 3
Training loss: 0.528411885503052
Validation loss: 2.175156829935573

Epoch: 5| Step: 4
Training loss: 0.2605864670624725
Validation loss: 2.2004567208258146

Epoch: 5| Step: 5
Training loss: 0.446472430799489
Validation loss: 2.1820501785729425

Epoch: 5| Step: 6
Training loss: 0.5101177417189215
Validation loss: 2.189598279567737

Epoch: 5| Step: 7
Training loss: 0.5325923677487067
Validation loss: 2.1922954786122433

Epoch: 5| Step: 8
Training loss: 0.23287552550108626
Validation loss: 2.1975241445048193

Epoch: 5| Step: 9
Training loss: 0.2970293421837041
Validation loss: 2.1943574527901992

Epoch: 5| Step: 10
Training loss: 0.33912884946396626
Validation loss: 2.228173798342836

Epoch: 402| Step: 0
Training loss: 0.29019058328436953
Validation loss: 2.169115770336066

Epoch: 5| Step: 1
Training loss: 0.4135259174483652
Validation loss: 2.1678038157720483

Epoch: 5| Step: 2
Training loss: 0.3524025311887357
Validation loss: 2.161339227681424

Epoch: 5| Step: 3
Training loss: 0.40818958168743086
Validation loss: 2.1650386527985037

Epoch: 5| Step: 4
Training loss: 0.3200529256281414
Validation loss: 2.161765895942679

Epoch: 5| Step: 5
Training loss: 0.33471092035322786
Validation loss: 2.158121967771064

Epoch: 5| Step: 6
Training loss: 0.4147936106409068
Validation loss: 2.177043443602772

Epoch: 5| Step: 7
Training loss: 0.4070604017365559
Validation loss: 2.1851623361671497

Epoch: 5| Step: 8
Training loss: 0.5087103901845288
Validation loss: 2.206569109319946

Epoch: 5| Step: 9
Training loss: 0.22304380718733613
Validation loss: 2.217271844220657

Epoch: 5| Step: 10
Training loss: 0.40990084007272026
Validation loss: 2.202711554262285

Epoch: 403| Step: 0
Training loss: 0.31894342406742254
Validation loss: 2.213654301267149

Epoch: 5| Step: 1
Training loss: 0.42760974339865065
Validation loss: 2.2320122893977157

Epoch: 5| Step: 2
Training loss: 0.27934514142176503
Validation loss: 2.1993417436088256

Epoch: 5| Step: 3
Training loss: 0.3057830505824887
Validation loss: 2.2035832850257195

Epoch: 5| Step: 4
Training loss: 0.3613187221643949
Validation loss: 2.1886274394455727

Epoch: 5| Step: 5
Training loss: 0.37238156573656006
Validation loss: 2.177499239074123

Epoch: 5| Step: 6
Training loss: 0.4708771285081619
Validation loss: 2.1936963278862893

Epoch: 5| Step: 7
Training loss: 0.523967929648563
Validation loss: 2.154080562672117

Epoch: 5| Step: 8
Training loss: 0.4366509850734099
Validation loss: 2.1613758611580236

Epoch: 5| Step: 9
Training loss: 0.370737125296654
Validation loss: 2.1746126138522612

Epoch: 5| Step: 10
Training loss: 0.173668193108865
Validation loss: 2.2030196416688446

Epoch: 404| Step: 0
Training loss: 0.3334512079955182
Validation loss: 2.1937811192388748

Epoch: 5| Step: 1
Training loss: 0.30734056417795097
Validation loss: 2.2105495173768457

Epoch: 5| Step: 2
Training loss: 0.310550521733207
Validation loss: 2.2184781681141694

Epoch: 5| Step: 3
Training loss: 0.4599085492471063
Validation loss: 2.2043719591553406

Epoch: 5| Step: 4
Training loss: 0.3090722201509221
Validation loss: 2.2362164177288064

Epoch: 5| Step: 5
Training loss: 0.3609486623582046
Validation loss: 2.2442826720239313

Epoch: 5| Step: 6
Training loss: 0.43022527853758186
Validation loss: 2.2297752294527924

Epoch: 5| Step: 7
Training loss: 0.384009998976146
Validation loss: 2.2243448638020173

Epoch: 5| Step: 8
Training loss: 0.34363131208093317
Validation loss: 2.2347221354406215

Epoch: 5| Step: 9
Training loss: 0.3766756370553731
Validation loss: 2.227738298202654

Epoch: 5| Step: 10
Training loss: 0.369897621270065
Validation loss: 2.230237023784398

Epoch: 405| Step: 0
Training loss: 0.3270803238290882
Validation loss: 2.2122193872936613

Epoch: 5| Step: 1
Training loss: 0.29259116954779885
Validation loss: 2.216185045469586

Epoch: 5| Step: 2
Training loss: 0.4214503482238783
Validation loss: 2.2326169798473865

Epoch: 5| Step: 3
Training loss: 0.31892210717706976
Validation loss: 2.226084518436681

Epoch: 5| Step: 4
Training loss: 0.28952260386881384
Validation loss: 2.1980866848201863

Epoch: 5| Step: 5
Training loss: 0.20251451967130663
Validation loss: 2.22286043307517

Epoch: 5| Step: 6
Training loss: 0.43891989676206367
Validation loss: 2.2072241101117935

Epoch: 5| Step: 7
Training loss: 0.5068198846468834
Validation loss: 2.1765989116049442

Epoch: 5| Step: 8
Training loss: 0.48078315806389904
Validation loss: 2.201504288295675

Epoch: 5| Step: 9
Training loss: 0.35029668750176846
Validation loss: 2.1838330650942335

Epoch: 5| Step: 10
Training loss: 0.281593669093354
Validation loss: 2.180480394108079

Epoch: 406| Step: 0
Training loss: 0.5040927807864406
Validation loss: 2.182832021381749

Epoch: 5| Step: 1
Training loss: 0.19505275620945853
Validation loss: 2.184794984582255

Epoch: 5| Step: 2
Training loss: 0.37073025217278754
Validation loss: 2.156109254062109

Epoch: 5| Step: 3
Training loss: 0.3337939539372949
Validation loss: 2.1635667478798197

Epoch: 5| Step: 4
Training loss: 0.41185128686395195
Validation loss: 2.1481574079367762

Epoch: 5| Step: 5
Training loss: 0.3386758819483836
Validation loss: 2.184958978232538

Epoch: 5| Step: 6
Training loss: 0.4128113684108105
Validation loss: 2.1779514941183815

Epoch: 5| Step: 7
Training loss: 0.4527063408796221
Validation loss: 2.1823819151320687

Epoch: 5| Step: 8
Training loss: 0.22333295784006532
Validation loss: 2.1778089849992806

Epoch: 5| Step: 9
Training loss: 0.22638674199822717
Validation loss: 2.1983570323933805

Epoch: 5| Step: 10
Training loss: 0.3402721401588811
Validation loss: 2.1966419073965797

Epoch: 407| Step: 0
Training loss: 0.4143709257624633
Validation loss: 2.18349045259609

Epoch: 5| Step: 1
Training loss: 0.4865011037802255
Validation loss: 2.2081661203625282

Epoch: 5| Step: 2
Training loss: 0.4254212563715784
Validation loss: 2.18452021897899

Epoch: 5| Step: 3
Training loss: 0.2982403578386723
Validation loss: 2.1953618661497925

Epoch: 5| Step: 4
Training loss: 0.3261667925044639
Validation loss: 2.1832173229371152

Epoch: 5| Step: 5
Training loss: 0.2998318986006658
Validation loss: 2.145649651422411

Epoch: 5| Step: 6
Training loss: 0.43780379306431805
Validation loss: 2.1458390088777386

Epoch: 5| Step: 7
Training loss: 0.2786438115958671
Validation loss: 2.160073668373693

Epoch: 5| Step: 8
Training loss: 0.23364210776478012
Validation loss: 2.166595310695841

Epoch: 5| Step: 9
Training loss: 0.34194705388634716
Validation loss: 2.177359668307869

Epoch: 5| Step: 10
Training loss: 0.30071402702678
Validation loss: 2.1742521343722285

Epoch: 408| Step: 0
Training loss: 0.5129408475483783
Validation loss: 2.1711983106446064

Epoch: 5| Step: 1
Training loss: 0.5109831203427443
Validation loss: 2.1917181571914304

Epoch: 5| Step: 2
Training loss: 0.15105027894974832
Validation loss: 2.183924139851328

Epoch: 5| Step: 3
Training loss: 0.39215347704787423
Validation loss: 2.2040544508732856

Epoch: 5| Step: 4
Training loss: 0.408688398233918
Validation loss: 2.1925306249396286

Epoch: 5| Step: 5
Training loss: 0.2670492528446061
Validation loss: 2.1925979663257196

Epoch: 5| Step: 6
Training loss: 0.27831166571854665
Validation loss: 2.1831818955590387

Epoch: 5| Step: 7
Training loss: 0.21223673886848407
Validation loss: 2.179842429686958

Epoch: 5| Step: 8
Training loss: 0.4052838427575199
Validation loss: 2.166883188823979

Epoch: 5| Step: 9
Training loss: 0.2755588937273812
Validation loss: 2.177474443133038

Epoch: 5| Step: 10
Training loss: 0.2563208720428909
Validation loss: 2.1778727875878716

Epoch: 409| Step: 0
Training loss: 0.45525585845956823
Validation loss: 2.1948275114499207

Epoch: 5| Step: 1
Training loss: 0.23814842555696758
Validation loss: 2.1742655618165196

Epoch: 5| Step: 2
Training loss: 0.44967333142384613
Validation loss: 2.1744847423906166

Epoch: 5| Step: 3
Training loss: 0.38518249855588726
Validation loss: 2.200345791352605

Epoch: 5| Step: 4
Training loss: 0.3823182554985735
Validation loss: 2.195798304939353

Epoch: 5| Step: 5
Training loss: 0.2918969193504764
Validation loss: 2.1785893226975683

Epoch: 5| Step: 6
Training loss: 0.3110305091115505
Validation loss: 2.201301398888914

Epoch: 5| Step: 7
Training loss: 0.2776389230270984
Validation loss: 2.168044487139203

Epoch: 5| Step: 8
Training loss: 0.19443771917391484
Validation loss: 2.170044054109962

Epoch: 5| Step: 9
Training loss: 0.29657184029392625
Validation loss: 2.19215246207688

Epoch: 5| Step: 10
Training loss: 0.4504652558666556
Validation loss: 2.178199506276192

Epoch: 410| Step: 0
Training loss: 0.19986751049781928
Validation loss: 2.1959923389405107

Epoch: 5| Step: 1
Training loss: 0.3763731809019118
Validation loss: 2.164260177317618

Epoch: 5| Step: 2
Training loss: 0.4335750541436668
Validation loss: 2.1828838236818364

Epoch: 5| Step: 3
Training loss: 0.42446633379987925
Validation loss: 2.1624708176179683

Epoch: 5| Step: 4
Training loss: 0.2730574828176136
Validation loss: 2.1913347966518564

Epoch: 5| Step: 5
Training loss: 0.425593886141451
Validation loss: 2.1784422065641573

Epoch: 5| Step: 6
Training loss: 0.17206453038696742
Validation loss: 2.167879296145783

Epoch: 5| Step: 7
Training loss: 0.2677167129813139
Validation loss: 2.1849869287145434

Epoch: 5| Step: 8
Training loss: 0.4042647344372788
Validation loss: 2.165482397566001

Epoch: 5| Step: 9
Training loss: 0.21620750217758286
Validation loss: 2.1781950103072476

Epoch: 5| Step: 10
Training loss: 0.48435075760749924
Validation loss: 2.168391171694683

Epoch: 411| Step: 0
Training loss: 0.31524104568627476
Validation loss: 2.19257166912569

Epoch: 5| Step: 1
Training loss: 0.5283303251040444
Validation loss: 2.1850009278739217

Epoch: 5| Step: 2
Training loss: 0.24960455315220387
Validation loss: 2.187313503161627

Epoch: 5| Step: 3
Training loss: 0.18165602669996642
Validation loss: 2.181011459003339

Epoch: 5| Step: 4
Training loss: 0.4572022273102855
Validation loss: 2.170405237228821

Epoch: 5| Step: 5
Training loss: 0.4803104605100935
Validation loss: 2.169157200251273

Epoch: 5| Step: 6
Training loss: 0.28642091795742863
Validation loss: 2.181843411566829

Epoch: 5| Step: 7
Training loss: 0.3426669463450748
Validation loss: 2.193127321716362

Epoch: 5| Step: 8
Training loss: 0.27591363468845026
Validation loss: 2.202060655021567

Epoch: 5| Step: 9
Training loss: 0.15357835885601692
Validation loss: 2.1900123361459314

Epoch: 5| Step: 10
Training loss: 0.31102256809314427
Validation loss: 2.190921772227251

Epoch: 412| Step: 0
Training loss: 0.10156272924837502
Validation loss: 2.1677872084835643

Epoch: 5| Step: 1
Training loss: 0.5099512105866624
Validation loss: 2.186084530781158

Epoch: 5| Step: 2
Training loss: 0.3310226379904894
Validation loss: 2.207695844800047

Epoch: 5| Step: 3
Training loss: 0.47728802219877114
Validation loss: 2.189937306067362

Epoch: 5| Step: 4
Training loss: 0.2526710837827555
Validation loss: 2.1852819011288886

Epoch: 5| Step: 5
Training loss: 0.18479153328481832
Validation loss: 2.189067575412626

Epoch: 5| Step: 6
Training loss: 0.3404896178378229
Validation loss: 2.180588722521061

Epoch: 5| Step: 7
Training loss: 0.16391838647004525
Validation loss: 2.1771080293200167

Epoch: 5| Step: 8
Training loss: 0.3501416102953047
Validation loss: 2.183458856106978

Epoch: 5| Step: 9
Training loss: 0.3568195834115757
Validation loss: 2.192268828132973

Epoch: 5| Step: 10
Training loss: 0.4010321153601536
Validation loss: 2.18840550199598

Epoch: 413| Step: 0
Training loss: 0.38859469160173715
Validation loss: 2.1868969169463557

Epoch: 5| Step: 1
Training loss: 0.5853116062236913
Validation loss: 2.2128932038263844

Epoch: 5| Step: 2
Training loss: 0.30016149108218976
Validation loss: 2.199454954642408

Epoch: 5| Step: 3
Training loss: 0.2219894614279669
Validation loss: 2.189556985868714

Epoch: 5| Step: 4
Training loss: 0.3581374254784013
Validation loss: 2.175070472172487

Epoch: 5| Step: 5
Training loss: 0.33637065463482596
Validation loss: 2.1788812031741727

Epoch: 5| Step: 6
Training loss: 0.272744881944688
Validation loss: 2.158618070719199

Epoch: 5| Step: 7
Training loss: 0.4535264505939217
Validation loss: 2.1595848669028346

Epoch: 5| Step: 8
Training loss: 0.10081586206450321
Validation loss: 2.1609126210987357

Epoch: 5| Step: 9
Training loss: 0.21726375002911014
Validation loss: 2.165258162358269

Epoch: 5| Step: 10
Training loss: 0.23442890024289767
Validation loss: 2.175037388473736

Epoch: 414| Step: 0
Training loss: 0.25750585584093005
Validation loss: 2.1784142674329554

Epoch: 5| Step: 1
Training loss: 0.28432278782597686
Validation loss: 2.1936619427306825

Epoch: 5| Step: 2
Training loss: 0.23921826094085913
Validation loss: 2.183130828395047

Epoch: 5| Step: 3
Training loss: 0.1222945099978817
Validation loss: 2.16351619707857

Epoch: 5| Step: 4
Training loss: 0.5264337104843033
Validation loss: 2.1705310299116434

Epoch: 5| Step: 5
Training loss: 0.4964838371604089
Validation loss: 2.1705731095779246

Epoch: 5| Step: 6
Training loss: 0.19427653224212219
Validation loss: 2.1991960093062484

Epoch: 5| Step: 7
Training loss: 0.38194538703956277
Validation loss: 2.205713299181371

Epoch: 5| Step: 8
Training loss: 0.2449144991991543
Validation loss: 2.20468109363189

Epoch: 5| Step: 9
Training loss: 0.38072550450488907
Validation loss: 2.18809252916205

Epoch: 5| Step: 10
Training loss: 0.3238433479992003
Validation loss: 2.1933345672557696

Epoch: 415| Step: 0
Training loss: 0.1896833809934855
Validation loss: 2.1851509290773663

Epoch: 5| Step: 1
Training loss: 0.3936807132492666
Validation loss: 2.2018779412704026

Epoch: 5| Step: 2
Training loss: 0.30127991792898534
Validation loss: 2.201636339227634

Epoch: 5| Step: 3
Training loss: 0.4467071311269606
Validation loss: 2.2074584736197362

Epoch: 5| Step: 4
Training loss: 0.22092336451622352
Validation loss: 2.209864594170041

Epoch: 5| Step: 5
Training loss: 0.2563205087001684
Validation loss: 2.19689225355026

Epoch: 5| Step: 6
Training loss: 0.45379566020689366
Validation loss: 2.1894764247057505

Epoch: 5| Step: 7
Training loss: 0.31387978168280156
Validation loss: 2.180735575700548

Epoch: 5| Step: 8
Training loss: 0.2126638009064241
Validation loss: 2.1884675449824478

Epoch: 5| Step: 9
Training loss: 0.37310155497748115
Validation loss: 2.175615575324771

Epoch: 5| Step: 10
Training loss: 0.3573071863827934
Validation loss: 2.1888108107111917

Epoch: 416| Step: 0
Training loss: 0.30840834347432516
Validation loss: 2.1848446822432774

Epoch: 5| Step: 1
Training loss: 0.46238342697619644
Validation loss: 2.2035276239536667

Epoch: 5| Step: 2
Training loss: 0.30263790931725976
Validation loss: 2.1955654661401267

Epoch: 5| Step: 3
Training loss: 0.29209188845118705
Validation loss: 2.2118499448844497

Epoch: 5| Step: 4
Training loss: 0.3055966824009451
Validation loss: 2.1982412586031708

Epoch: 5| Step: 5
Training loss: 0.3001349056425208
Validation loss: 2.2009118969691537

Epoch: 5| Step: 6
Training loss: 0.265328353839504
Validation loss: 2.197215026345797

Epoch: 5| Step: 7
Training loss: 0.2739675697369986
Validation loss: 2.184138146209733

Epoch: 5| Step: 8
Training loss: 0.3237900024724408
Validation loss: 2.2215834138680584

Epoch: 5| Step: 9
Training loss: 0.5405281707840048
Validation loss: 2.2228454835704343

Epoch: 5| Step: 10
Training loss: 0.15332246888217538
Validation loss: 2.200433881080152

Epoch: 417| Step: 0
Training loss: 0.4520755816233093
Validation loss: 2.202038951884494

Epoch: 5| Step: 1
Training loss: 0.2522890084712271
Validation loss: 2.1851645432555795

Epoch: 5| Step: 2
Training loss: 0.1622606226830041
Validation loss: 2.2001213661120955

Epoch: 5| Step: 3
Training loss: 0.24583952503300366
Validation loss: 2.182873313697279

Epoch: 5| Step: 4
Training loss: 0.37727322600593904
Validation loss: 2.206554057864016

Epoch: 5| Step: 5
Training loss: 0.42099245795881324
Validation loss: 2.1851049211680054

Epoch: 5| Step: 6
Training loss: 0.41269280955994947
Validation loss: 2.212688102440792

Epoch: 5| Step: 7
Training loss: 0.33326486415794965
Validation loss: 2.1874306182874634

Epoch: 5| Step: 8
Training loss: 0.2853067732379343
Validation loss: 2.205988427450265

Epoch: 5| Step: 9
Training loss: 0.11732277215351908
Validation loss: 2.2158301837576366

Epoch: 5| Step: 10
Training loss: 0.4211461694536638
Validation loss: 2.2049026549509017

Epoch: 418| Step: 0
Training loss: 0.5567268171001636
Validation loss: 2.1938222043009534

Epoch: 5| Step: 1
Training loss: 0.12816884349031424
Validation loss: 2.2186076655728195

Epoch: 5| Step: 2
Training loss: 0.23659611317022855
Validation loss: 2.21805468486062

Epoch: 5| Step: 3
Training loss: 0.32514501875801843
Validation loss: 2.200546367215819

Epoch: 5| Step: 4
Training loss: 0.3271178273925878
Validation loss: 2.1862391164845034

Epoch: 5| Step: 5
Training loss: 0.156119685667467
Validation loss: 2.195004885363463

Epoch: 5| Step: 6
Training loss: 0.4881867279116955
Validation loss: 2.213092245168994

Epoch: 5| Step: 7
Training loss: 0.3189486450282844
Validation loss: 2.166298576668898

Epoch: 5| Step: 8
Training loss: 0.22544921100361645
Validation loss: 2.1865880336763532

Epoch: 5| Step: 9
Training loss: 0.32448349909494967
Validation loss: 2.2113178525629427

Epoch: 5| Step: 10
Training loss: 0.19029779023447538
Validation loss: 2.2010112866598237

Epoch: 419| Step: 0
Training loss: 0.3297357193997567
Validation loss: 2.1768611161219615

Epoch: 5| Step: 1
Training loss: 0.16717346569231148
Validation loss: 2.2028481609089123

Epoch: 5| Step: 2
Training loss: 0.29812625662820713
Validation loss: 2.199698330592711

Epoch: 5| Step: 3
Training loss: 0.32154166080876406
Validation loss: 2.1836694570771975

Epoch: 5| Step: 4
Training loss: 0.36772791681561195
Validation loss: 2.1972855388509194

Epoch: 5| Step: 5
Training loss: 0.379005851632492
Validation loss: 2.2014847963105924

Epoch: 5| Step: 6
Training loss: 0.28558415483960076
Validation loss: 2.1823283223817103

Epoch: 5| Step: 7
Training loss: 0.3198555617953738
Validation loss: 2.1967039422659678

Epoch: 5| Step: 8
Training loss: 0.1778471976384918
Validation loss: 2.195346812592907

Epoch: 5| Step: 9
Training loss: 0.4071670232558644
Validation loss: 2.178355709541942

Epoch: 5| Step: 10
Training loss: 0.3680305137552414
Validation loss: 2.2123913447843417

Epoch: 420| Step: 0
Training loss: 0.3234512828341213
Validation loss: 2.2006975617895557

Epoch: 5| Step: 1
Training loss: 0.26005357543366486
Validation loss: 2.1899774974765047

Epoch: 5| Step: 2
Training loss: 0.2640882101465332
Validation loss: 2.1825135684256733

Epoch: 5| Step: 3
Training loss: 0.35424291500525584
Validation loss: 2.2084270657850285

Epoch: 5| Step: 4
Training loss: 0.12467011866567658
Validation loss: 2.200282003091444

Epoch: 5| Step: 5
Training loss: 0.09666280406378469
Validation loss: 2.1996524160056308

Epoch: 5| Step: 6
Training loss: 0.3903976160094881
Validation loss: 2.200604933410537

Epoch: 5| Step: 7
Training loss: 0.3043531882364587
Validation loss: 2.2209704673775925

Epoch: 5| Step: 8
Training loss: 0.5169894343390401
Validation loss: 2.216860997559766

Epoch: 5| Step: 9
Training loss: 0.3196818376973782
Validation loss: 2.1974031246647194

Epoch: 5| Step: 10
Training loss: 0.3770523731244522
Validation loss: 2.1931360046071164

Epoch: 421| Step: 0
Training loss: 0.28808610560525416
Validation loss: 2.2080290099623237

Epoch: 5| Step: 1
Training loss: 0.21297391084783668
Validation loss: 2.201818429153944

Epoch: 5| Step: 2
Training loss: 0.2075084997498727
Validation loss: 2.195283911407236

Epoch: 5| Step: 3
Training loss: 0.3722705252325885
Validation loss: 2.174281006576352

Epoch: 5| Step: 4
Training loss: 0.1643450721811574
Validation loss: 2.1898769420618405

Epoch: 5| Step: 5
Training loss: 0.37897720852290195
Validation loss: 2.1548130002212633

Epoch: 5| Step: 6
Training loss: 0.3504844880025016
Validation loss: 2.158509349911037

Epoch: 5| Step: 7
Training loss: 0.34377490300225777
Validation loss: 2.181039632566735

Epoch: 5| Step: 8
Training loss: 0.3961341325688803
Validation loss: 2.1943706403811727

Epoch: 5| Step: 9
Training loss: 0.3101913888661749
Validation loss: 2.1696825792771106

Epoch: 5| Step: 10
Training loss: 0.3889319350150838
Validation loss: 2.1790063712452485

Epoch: 422| Step: 0
Training loss: 0.2188639854729334
Validation loss: 2.176697277333193

Epoch: 5| Step: 1
Training loss: 0.2898456429473674
Validation loss: 2.17674745077585

Epoch: 5| Step: 2
Training loss: 0.17180738961628905
Validation loss: 2.170938485408945

Epoch: 5| Step: 3
Training loss: 0.4416564299938613
Validation loss: 2.178365291593236

Epoch: 5| Step: 4
Training loss: 0.11089704104864803
Validation loss: 2.1393587184339893

Epoch: 5| Step: 5
Training loss: 0.40941789562497183
Validation loss: 2.158621364016034

Epoch: 5| Step: 6
Training loss: 0.11201710991494454
Validation loss: 2.1747131712981784

Epoch: 5| Step: 7
Training loss: 0.29288361901964866
Validation loss: 2.166957493361483

Epoch: 5| Step: 8
Training loss: 0.5468724931931943
Validation loss: 2.1713602974863404

Epoch: 5| Step: 9
Training loss: 0.224733384769987
Validation loss: 2.1592685596594823

Epoch: 5| Step: 10
Training loss: 0.3758239039840353
Validation loss: 2.1979545594272087

Epoch: 423| Step: 0
Training loss: 0.5682745801457152
Validation loss: 2.1861832237286154

Epoch: 5| Step: 1
Training loss: 0.24872264273125844
Validation loss: 2.220141279515559

Epoch: 5| Step: 2
Training loss: 0.29339464384512914
Validation loss: 2.2084702464603385

Epoch: 5| Step: 3
Training loss: 0.23766444843554704
Validation loss: 2.168420549915478

Epoch: 5| Step: 4
Training loss: 0.27082851142747894
Validation loss: 2.1880254205299847

Epoch: 5| Step: 5
Training loss: 0.49411927429633845
Validation loss: 2.180241957409328

Epoch: 5| Step: 6
Training loss: 0.2533891106493415
Validation loss: 2.212194131072118

Epoch: 5| Step: 7
Training loss: 0.26130555401821853
Validation loss: 2.1970679537914606

Epoch: 5| Step: 8
Training loss: 0.2188062169862656
Validation loss: 2.1925026764995246

Epoch: 5| Step: 9
Training loss: 0.162621218603653
Validation loss: 2.191387457857776

Epoch: 5| Step: 10
Training loss: 0.1835294062903271
Validation loss: 2.1731221970757013

Epoch: 424| Step: 0
Training loss: 0.3445737894659277
Validation loss: 2.1879974631674073

Epoch: 5| Step: 1
Training loss: 0.2208859437601759
Validation loss: 2.1979084672781233

Epoch: 5| Step: 2
Training loss: 0.18208933341537759
Validation loss: 2.1985075706020547

Epoch: 5| Step: 3
Training loss: 0.367748197640593
Validation loss: 2.197275306598294

Epoch: 5| Step: 4
Training loss: 0.368497237360781
Validation loss: 2.169633377975747

Epoch: 5| Step: 5
Training loss: 0.2865133131613908
Validation loss: 2.212971767965266

Epoch: 5| Step: 6
Training loss: 0.3557257718677794
Validation loss: 2.1890945353878744

Epoch: 5| Step: 7
Training loss: 0.4167410923132284
Validation loss: 2.1850257522114083

Epoch: 5| Step: 8
Training loss: 0.2689555557505472
Validation loss: 2.191323173088389

Epoch: 5| Step: 9
Training loss: 0.20043289229589628
Validation loss: 2.1987843711893156

Epoch: 5| Step: 10
Training loss: 0.39488881969873185
Validation loss: 2.202831750612923

Epoch: 425| Step: 0
Training loss: 0.18836761448677175
Validation loss: 2.1948601502605234

Epoch: 5| Step: 1
Training loss: 0.2605945011745193
Validation loss: 2.194475306480004

Epoch: 5| Step: 2
Training loss: 0.24949218912454618
Validation loss: 2.177617588385397

Epoch: 5| Step: 3
Training loss: 0.4134407773972848
Validation loss: 2.1925106187919847

Epoch: 5| Step: 4
Training loss: 0.3777812893126164
Validation loss: 2.20292852836664

Epoch: 5| Step: 5
Training loss: 0.22929245393770287
Validation loss: 2.210165829151428

Epoch: 5| Step: 6
Training loss: 0.3143818697548504
Validation loss: 2.1756443410599355

Epoch: 5| Step: 7
Training loss: 0.3085039466855855
Validation loss: 2.178972321954495

Epoch: 5| Step: 8
Training loss: 0.3372704763021592
Validation loss: 2.1616440749665

Epoch: 5| Step: 9
Training loss: 0.24872193129003092
Validation loss: 2.175535890178405

Epoch: 5| Step: 10
Training loss: 0.38390119627691416
Validation loss: 2.1889016461486883

Epoch: 426| Step: 0
Training loss: 0.37497514403937027
Validation loss: 2.1769514491878144

Epoch: 5| Step: 1
Training loss: 0.24620448754498808
Validation loss: 2.1809075347106313

Epoch: 5| Step: 2
Training loss: 0.149644798188752
Validation loss: 2.180912611657196

Epoch: 5| Step: 3
Training loss: 0.3791161575141455
Validation loss: 2.1999638654914677

Epoch: 5| Step: 4
Training loss: 0.1890566501815855
Validation loss: 2.1675717728788952

Epoch: 5| Step: 5
Training loss: 0.2947476864190904
Validation loss: 2.196391884037157

Epoch: 5| Step: 6
Training loss: 0.21217026582935425
Validation loss: 2.16558523222233

Epoch: 5| Step: 7
Training loss: 0.1745726841261644
Validation loss: 2.191655888790806

Epoch: 5| Step: 8
Training loss: 0.32251299987141535
Validation loss: 2.1876936901497865

Epoch: 5| Step: 9
Training loss: 0.5498831711578446
Validation loss: 2.188211628237173

Epoch: 5| Step: 10
Training loss: 0.34044252460064023
Validation loss: 2.1896688067046113

Epoch: 427| Step: 0
Training loss: 0.2933918377506407
Validation loss: 2.2128818759673394

Epoch: 5| Step: 1
Training loss: 0.35955420462662097
Validation loss: 2.1849302846762626

Epoch: 5| Step: 2
Training loss: 0.33091878211279396
Validation loss: 2.19629408288004

Epoch: 5| Step: 3
Training loss: 0.3434153900631105
Validation loss: 2.190439959923363

Epoch: 5| Step: 4
Training loss: 0.23646671393047114
Validation loss: 2.1998313371641145

Epoch: 5| Step: 5
Training loss: 0.35245798293419217
Validation loss: 2.2166773179241157

Epoch: 5| Step: 6
Training loss: 0.3387909509392202
Validation loss: 2.2180133037347725

Epoch: 5| Step: 7
Training loss: 0.34898118636991193
Validation loss: 2.216905391238515

Epoch: 5| Step: 8
Training loss: 0.2414957288074113
Validation loss: 2.200042414163144

Epoch: 5| Step: 9
Training loss: 0.30214782004610774
Validation loss: 2.189359594659174

Epoch: 5| Step: 10
Training loss: 0.11291744332717997
Validation loss: 2.1815192234655107

Epoch: 428| Step: 0
Training loss: 0.36606753784198875
Validation loss: 2.217921188732185

Epoch: 5| Step: 1
Training loss: 0.2767749649149132
Validation loss: 2.1844300701033488

Epoch: 5| Step: 2
Training loss: 0.3331893470840333
Validation loss: 2.193360298367004

Epoch: 5| Step: 3
Training loss: 0.09727425728451627
Validation loss: 2.2037284095722853

Epoch: 5| Step: 4
Training loss: 0.3125417323857245
Validation loss: 2.1944395281333917

Epoch: 5| Step: 5
Training loss: 0.24201025937683784
Validation loss: 2.196324190912393

Epoch: 5| Step: 6
Training loss: 0.27278817600386207
Validation loss: 2.185369558118027

Epoch: 5| Step: 7
Training loss: 0.4024893858203137
Validation loss: 2.2074989369257363

Epoch: 5| Step: 8
Training loss: 0.25402318755889425
Validation loss: 2.1883160898540663

Epoch: 5| Step: 9
Training loss: 0.2777763270631631
Validation loss: 2.199870782028362

Epoch: 5| Step: 10
Training loss: 0.37216613817127614
Validation loss: 2.182958990499433

Epoch: 429| Step: 0
Training loss: 0.2996997338901582
Validation loss: 2.199467102283288

Epoch: 5| Step: 1
Training loss: 0.22867517525624598
Validation loss: 2.1886384134686323

Epoch: 5| Step: 2
Training loss: 0.1726423495293966
Validation loss: 2.1827338422681324

Epoch: 5| Step: 3
Training loss: 0.38686718644739343
Validation loss: 2.2076547502619457

Epoch: 5| Step: 4
Training loss: 0.26678702083502254
Validation loss: 2.178781068717195

Epoch: 5| Step: 5
Training loss: 0.24048748483729665
Validation loss: 2.1726258276201933

Epoch: 5| Step: 6
Training loss: 0.23811692684735922
Validation loss: 2.1811773264852112

Epoch: 5| Step: 7
Training loss: 0.3367465169304519
Validation loss: 2.170910625661485

Epoch: 5| Step: 8
Training loss: 0.3194071022554535
Validation loss: 2.196684660351978

Epoch: 5| Step: 9
Training loss: 0.3326148122096747
Validation loss: 2.196896103280729

Epoch: 5| Step: 10
Training loss: 0.523726483183517
Validation loss: 2.1873175127407585

Epoch: 430| Step: 0
Training loss: 0.23511758625879553
Validation loss: 2.1778702508700163

Epoch: 5| Step: 1
Training loss: 0.294518997686312
Validation loss: 2.157171473673859

Epoch: 5| Step: 2
Training loss: 0.39062999722145353
Validation loss: 2.1649834791527574

Epoch: 5| Step: 3
Training loss: 0.15962591988306699
Validation loss: 2.1672130925872186

Epoch: 5| Step: 4
Training loss: 0.31257366265904263
Validation loss: 2.180829455919995

Epoch: 5| Step: 5
Training loss: 0.3550243953932581
Validation loss: 2.1958002132516

Epoch: 5| Step: 6
Training loss: 0.34481735762838617
Validation loss: 2.18282420536164

Epoch: 5| Step: 7
Training loss: 0.3357032802156192
Validation loss: 2.2370903782740137

Epoch: 5| Step: 8
Training loss: 0.13045925202889425
Validation loss: 2.2304890466860687

Epoch: 5| Step: 9
Training loss: 0.4920153392449414
Validation loss: 2.2323994357870816

Epoch: 5| Step: 10
Training loss: 0.21282986114983515
Validation loss: 2.215575836750221

Epoch: 431| Step: 0
Training loss: 0.4058136063323751
Validation loss: 2.225503497173561

Epoch: 5| Step: 1
Training loss: 0.19444991368500042
Validation loss: 2.22411653442499

Epoch: 5| Step: 2
Training loss: 0.4289406962363869
Validation loss: 2.2477684610869026

Epoch: 5| Step: 3
Training loss: 0.31045946054523194
Validation loss: 2.2431171152731757

Epoch: 5| Step: 4
Training loss: 0.20241552022707718
Validation loss: 2.2194621329672826

Epoch: 5| Step: 5
Training loss: 0.27226824766015123
Validation loss: 2.2105410954013984

Epoch: 5| Step: 6
Training loss: 0.3223177087483875
Validation loss: 2.202872037274102

Epoch: 5| Step: 7
Training loss: 0.17398869673967376
Validation loss: 2.2177008043504123

Epoch: 5| Step: 8
Training loss: 0.4457650478452499
Validation loss: 2.1981625353573238

Epoch: 5| Step: 9
Training loss: 0.3520594475429458
Validation loss: 2.201772720041159

Epoch: 5| Step: 10
Training loss: 0.13982887215563364
Validation loss: 2.1636893243583715

Epoch: 432| Step: 0
Training loss: 0.2881499138609059
Validation loss: 2.2156717790096687

Epoch: 5| Step: 1
Training loss: 0.3775040548624701
Validation loss: 2.1909838941693196

Epoch: 5| Step: 2
Training loss: 0.28626914568345
Validation loss: 2.170602934239571

Epoch: 5| Step: 3
Training loss: 0.2033577649070729
Validation loss: 2.194153366819073

Epoch: 5| Step: 4
Training loss: 0.4272560336455347
Validation loss: 2.2051912781153433

Epoch: 5| Step: 5
Training loss: 0.1580621067312227
Validation loss: 2.1864620811045192

Epoch: 5| Step: 6
Training loss: 0.24826739113492963
Validation loss: 2.173566584274252

Epoch: 5| Step: 7
Training loss: 0.45025642625648504
Validation loss: 2.2029927718116045

Epoch: 5| Step: 8
Training loss: 0.29218950270920097
Validation loss: 2.217071996351511

Epoch: 5| Step: 9
Training loss: 0.30110505249632863
Validation loss: 2.2305711677050297

Epoch: 5| Step: 10
Training loss: 0.13393837887185922
Validation loss: 2.22992906326369

Epoch: 433| Step: 0
Training loss: 0.24165702220290697
Validation loss: 2.196181281183953

Epoch: 5| Step: 1
Training loss: 0.23111120485643044
Validation loss: 2.2279660228245284

Epoch: 5| Step: 2
Training loss: 0.294705203971732
Validation loss: 2.2244436017942695

Epoch: 5| Step: 3
Training loss: 0.2799055629303142
Validation loss: 2.2389914188068603

Epoch: 5| Step: 4
Training loss: 0.21662567871238364
Validation loss: 2.259734641225126

Epoch: 5| Step: 5
Training loss: 0.448883196686597
Validation loss: 2.233582932013615

Epoch: 5| Step: 6
Training loss: 0.35123803742832377
Validation loss: 2.2339137655631736

Epoch: 5| Step: 7
Training loss: 0.2617741568830398
Validation loss: 2.244696608523275

Epoch: 5| Step: 8
Training loss: 0.3108588636825049
Validation loss: 2.2174563370736142

Epoch: 5| Step: 9
Training loss: 0.36203111874936506
Validation loss: 2.214269956085914

Epoch: 5| Step: 10
Training loss: 0.36592676963026416
Validation loss: 2.2398944689170133

Epoch: 434| Step: 0
Training loss: 0.22030376491409592
Validation loss: 2.213890979477118

Epoch: 5| Step: 1
Training loss: 0.2709166539234341
Validation loss: 2.223161700578171

Epoch: 5| Step: 2
Training loss: 0.30186402510206756
Validation loss: 2.215528066848459

Epoch: 5| Step: 3
Training loss: 0.247332505436231
Validation loss: 2.219859052149896

Epoch: 5| Step: 4
Training loss: 0.32610866368128316
Validation loss: 2.215887484081922

Epoch: 5| Step: 5
Training loss: 0.265365979181923
Validation loss: 2.212563909960152

Epoch: 5| Step: 6
Training loss: 0.24411061674709433
Validation loss: 2.197000464406283

Epoch: 5| Step: 7
Training loss: 0.41479515538200645
Validation loss: 2.172455046901045

Epoch: 5| Step: 8
Training loss: 0.3054507062417073
Validation loss: 2.2130625210674384

Epoch: 5| Step: 9
Training loss: 0.4498158011676416
Validation loss: 2.1815458360440716

Epoch: 5| Step: 10
Training loss: 0.33998231145833074
Validation loss: 2.222584309312902

Epoch: 435| Step: 0
Training loss: 0.22525830442434214
Validation loss: 2.1954216986680404

Epoch: 5| Step: 1
Training loss: 0.21893427954583083
Validation loss: 2.1762389372551

Epoch: 5| Step: 2
Training loss: 0.21595037002412537
Validation loss: 2.221288612957533

Epoch: 5| Step: 3
Training loss: 0.31356388432602245
Validation loss: 2.189078929009417

Epoch: 5| Step: 4
Training loss: 0.33118161719216416
Validation loss: 2.164179949388485

Epoch: 5| Step: 5
Training loss: 0.40577960290526793
Validation loss: 2.1836328841418533

Epoch: 5| Step: 6
Training loss: 0.4394556003076988
Validation loss: 2.183067571704692

Epoch: 5| Step: 7
Training loss: 0.26248055227082334
Validation loss: 2.200739440330951

Epoch: 5| Step: 8
Training loss: 0.13019939789312357
Validation loss: 2.1721021973522086

Epoch: 5| Step: 9
Training loss: 0.314598168513829
Validation loss: 2.2136593505923376

Epoch: 5| Step: 10
Training loss: 0.3044526344238589
Validation loss: 2.1878285813138514

Epoch: 436| Step: 0
Training loss: 0.20017783856309404
Validation loss: 2.208353754909988

Epoch: 5| Step: 1
Training loss: 0.20180286594998456
Validation loss: 2.1851835440683263

Epoch: 5| Step: 2
Training loss: 0.3591179135476829
Validation loss: 2.209580814585787

Epoch: 5| Step: 3
Training loss: 0.4622171065189291
Validation loss: 2.1783476220789653

Epoch: 5| Step: 4
Training loss: 0.37300241415096513
Validation loss: 2.1826282730806557

Epoch: 5| Step: 5
Training loss: 0.32859955258762713
Validation loss: 2.2203170185727683

Epoch: 5| Step: 6
Training loss: 0.34052126862358184
Validation loss: 2.1936363343622163

Epoch: 5| Step: 7
Training loss: 0.17380176301430722
Validation loss: 2.1723733175232187

Epoch: 5| Step: 8
Training loss: 0.18031059948400588
Validation loss: 2.177363497382409

Epoch: 5| Step: 9
Training loss: 0.28207903111180804
Validation loss: 2.2073229054803636

Epoch: 5| Step: 10
Training loss: 0.2936465116580753
Validation loss: 2.208684614323909

Epoch: 437| Step: 0
Training loss: 0.28073243361620454
Validation loss: 2.192100899273308

Epoch: 5| Step: 1
Training loss: 0.25302680371431874
Validation loss: 2.202685435998878

Epoch: 5| Step: 2
Training loss: 0.35971229729570303
Validation loss: 2.194064752687258

Epoch: 5| Step: 3
Training loss: 0.19154757517786164
Validation loss: 2.1823405958979203

Epoch: 5| Step: 4
Training loss: 0.36086069751405486
Validation loss: 2.196431685383279

Epoch: 5| Step: 5
Training loss: 0.299662404048788
Validation loss: 2.1998346981190298

Epoch: 5| Step: 6
Training loss: 0.38877700457352654
Validation loss: 2.1828639041117968

Epoch: 5| Step: 7
Training loss: 0.2532193796789557
Validation loss: 2.1966119070063725

Epoch: 5| Step: 8
Training loss: 0.39314166941878703
Validation loss: 2.192341564817366

Epoch: 5| Step: 9
Training loss: 0.2598178925669216
Validation loss: 2.1631960163492505

Epoch: 5| Step: 10
Training loss: 0.13139771284069934
Validation loss: 2.1730845292475096

Epoch: 438| Step: 0
Training loss: 0.25927760237341446
Validation loss: 2.1803179889891298

Epoch: 5| Step: 1
Training loss: 0.18143790222738362
Validation loss: 2.199386574247836

Epoch: 5| Step: 2
Training loss: 0.26776401995703
Validation loss: 2.177757424559477

Epoch: 5| Step: 3
Training loss: 0.27963604373805917
Validation loss: 2.19448727315886

Epoch: 5| Step: 4
Training loss: 0.3609373711920174
Validation loss: 2.193976091742186

Epoch: 5| Step: 5
Training loss: 0.2450681462565345
Validation loss: 2.1790924777338683

Epoch: 5| Step: 6
Training loss: 0.3122201739597465
Validation loss: 2.1648087471137205

Epoch: 5| Step: 7
Training loss: 0.22307902069403612
Validation loss: 2.1707068874383633

Epoch: 5| Step: 8
Training loss: 0.4169963148569432
Validation loss: 2.176500172167978

Epoch: 5| Step: 9
Training loss: 0.31751124204421943
Validation loss: 2.143977899347488

Epoch: 5| Step: 10
Training loss: 0.27339806953598356
Validation loss: 2.158321059529383

Epoch: 439| Step: 0
Training loss: 0.2656627936684185
Validation loss: 2.1725645943988257

Epoch: 5| Step: 1
Training loss: 0.2794058260456329
Validation loss: 2.148480961901642

Epoch: 5| Step: 2
Training loss: 0.33175587173733273
Validation loss: 2.162729158410389

Epoch: 5| Step: 3
Training loss: 0.15578844325485497
Validation loss: 2.1617910220770145

Epoch: 5| Step: 4
Training loss: 0.2862344893163693
Validation loss: 2.1741341542960084

Epoch: 5| Step: 5
Training loss: 0.2179881606807876
Validation loss: 2.1937496440877697

Epoch: 5| Step: 6
Training loss: 0.24255046256759863
Validation loss: 2.1791699723116076

Epoch: 5| Step: 7
Training loss: 0.49054524265436306
Validation loss: 2.1443844698729073

Epoch: 5| Step: 8
Training loss: 0.42897770951677716
Validation loss: 2.178528967868626

Epoch: 5| Step: 9
Training loss: 0.25933574299001316
Validation loss: 2.168738878895454

Epoch: 5| Step: 10
Training loss: 0.1172398609167694
Validation loss: 2.1686542834677716

Epoch: 440| Step: 0
Training loss: 0.4231433522401465
Validation loss: 2.1868005879641053

Epoch: 5| Step: 1
Training loss: 0.3191130557344579
Validation loss: 2.1693775344919715

Epoch: 5| Step: 2
Training loss: 0.23056877519553068
Validation loss: 2.182420218188037

Epoch: 5| Step: 3
Training loss: 0.25684298661570265
Validation loss: 2.1876546099003114

Epoch: 5| Step: 4
Training loss: 0.29554810889014493
Validation loss: 2.2202555279966716

Epoch: 5| Step: 5
Training loss: 0.3866394616735982
Validation loss: 2.2142039615609646

Epoch: 5| Step: 6
Training loss: 0.26846153724527266
Validation loss: 2.2066011986115037

Epoch: 5| Step: 7
Training loss: 0.24501732391542982
Validation loss: 2.216540149927474

Epoch: 5| Step: 8
Training loss: 0.1756254247239431
Validation loss: 2.2238814770609903

Epoch: 5| Step: 9
Training loss: 0.32315156709372794
Validation loss: 2.209737855401991

Epoch: 5| Step: 10
Training loss: 0.2760756339761187
Validation loss: 2.168484921929057

Epoch: 441| Step: 0
Training loss: 0.31708688878502633
Validation loss: 2.176991217347798

Epoch: 5| Step: 1
Training loss: 0.1465812489935367
Validation loss: 2.18800304447488

Epoch: 5| Step: 2
Training loss: 0.5004712804372452
Validation loss: 2.1972507711658174

Epoch: 5| Step: 3
Training loss: 0.28026570166568543
Validation loss: 2.1967694063805925

Epoch: 5| Step: 4
Training loss: 0.25078715142172264
Validation loss: 2.1932510999261194

Epoch: 5| Step: 5
Training loss: 0.4097116331125801
Validation loss: 2.1865959602275575

Epoch: 5| Step: 6
Training loss: 0.3167511743585484
Validation loss: 2.1938435043556006

Epoch: 5| Step: 7
Training loss: 0.1899552720213618
Validation loss: 2.191677750892766

Epoch: 5| Step: 8
Training loss: 0.23938970239273638
Validation loss: 2.2096629411188484

Epoch: 5| Step: 9
Training loss: 0.2011048103320111
Validation loss: 2.1856717018104814

Epoch: 5| Step: 10
Training loss: 0.13907662277087515
Validation loss: 2.1837740009662827

Epoch: 442| Step: 0
Training loss: 0.31770534852715554
Validation loss: 2.1884814924451717

Epoch: 5| Step: 1
Training loss: 0.23995595786187393
Validation loss: 2.184934634786772

Epoch: 5| Step: 2
Training loss: 0.3474629754301007
Validation loss: 2.1712274076518

Epoch: 5| Step: 3
Training loss: 0.23720019202268813
Validation loss: 2.167034127081153

Epoch: 5| Step: 4
Training loss: 0.18672686363691662
Validation loss: 2.1522223313636584

Epoch: 5| Step: 5
Training loss: 0.38862774469014355
Validation loss: 2.149792684889253

Epoch: 5| Step: 6
Training loss: 0.2808456030216041
Validation loss: 2.1498804640587212

Epoch: 5| Step: 7
Training loss: 0.39932813396290406
Validation loss: 2.1552545735572375

Epoch: 5| Step: 8
Training loss: 0.13296483223474426
Validation loss: 2.1810870344454245

Epoch: 5| Step: 9
Training loss: 0.3278355684336725
Validation loss: 2.1642730576102474

Epoch: 5| Step: 10
Training loss: 0.23606360425430753
Validation loss: 2.1770279654494082

Epoch: 443| Step: 0
Training loss: 0.31430327357512033
Validation loss: 2.164330435354633

Epoch: 5| Step: 1
Training loss: 0.15976596589739928
Validation loss: 2.164987742639804

Epoch: 5| Step: 2
Training loss: 0.20478073537381453
Validation loss: 2.191175237076964

Epoch: 5| Step: 3
Training loss: 0.33486312016271597
Validation loss: 2.199062018854066

Epoch: 5| Step: 4
Training loss: 0.3394562057162172
Validation loss: 2.1748607176711308

Epoch: 5| Step: 5
Training loss: 0.22969372604651078
Validation loss: 2.1735263715970428

Epoch: 5| Step: 6
Training loss: 0.3843836946201869
Validation loss: 2.2249530299668403

Epoch: 5| Step: 7
Training loss: 0.3101112140849506
Validation loss: 2.2174103514351455

Epoch: 5| Step: 8
Training loss: 0.3011146654348483
Validation loss: 2.2003837304395684

Epoch: 5| Step: 9
Training loss: 0.3129290734526596
Validation loss: 2.1907194608987375

Epoch: 5| Step: 10
Training loss: 0.2035195022623696
Validation loss: 2.196530863465013

Epoch: 444| Step: 0
Training loss: 0.25809786637794047
Validation loss: 2.191112809335136

Epoch: 5| Step: 1
Training loss: 0.23386120905959507
Validation loss: 2.1706821804327223

Epoch: 5| Step: 2
Training loss: 0.2764044962256447
Validation loss: 2.1956051586992227

Epoch: 5| Step: 3
Training loss: 0.3901830461899554
Validation loss: 2.2213125663660573

Epoch: 5| Step: 4
Training loss: 0.31341222893187376
Validation loss: 2.1733917726213807

Epoch: 5| Step: 5
Training loss: 0.34242485123423827
Validation loss: 2.197658457361101

Epoch: 5| Step: 6
Training loss: 0.218765547744806
Validation loss: 2.1742758952797057

Epoch: 5| Step: 7
Training loss: 0.21846804158375957
Validation loss: 2.1740442613432798

Epoch: 5| Step: 8
Training loss: 0.3491562618869147
Validation loss: 2.147263585992785

Epoch: 5| Step: 9
Training loss: 0.1611247840962025
Validation loss: 2.179037522577126

Epoch: 5| Step: 10
Training loss: 0.24902532240210357
Validation loss: 2.215770551760135

Epoch: 445| Step: 0
Training loss: 0.2298164835925153
Validation loss: 2.192833133410167

Epoch: 5| Step: 1
Training loss: 0.25151186012796006
Validation loss: 2.1958743425143417

Epoch: 5| Step: 2
Training loss: 0.4272871945911411
Validation loss: 2.184645095062954

Epoch: 5| Step: 3
Training loss: 0.36529377337019736
Validation loss: 2.1869650958787243

Epoch: 5| Step: 4
Training loss: 0.17674338034201284
Validation loss: 2.200606609802975

Epoch: 5| Step: 5
Training loss: 0.24692540197491308
Validation loss: 2.192477258047086

Epoch: 5| Step: 6
Training loss: 0.1468486960171339
Validation loss: 2.198344894361738

Epoch: 5| Step: 7
Training loss: 0.3013572874192222
Validation loss: 2.2032490525687156

Epoch: 5| Step: 8
Training loss: 0.18377142283386133
Validation loss: 2.181909824423745

Epoch: 5| Step: 9
Training loss: 0.39439506824294196
Validation loss: 2.2304823286516973

Epoch: 5| Step: 10
Training loss: 0.1722131458887267
Validation loss: 2.188004280011683

Epoch: 446| Step: 0
Training loss: 0.2374538768980564
Validation loss: 2.2051642167390155

Epoch: 5| Step: 1
Training loss: 0.2584344269363376
Validation loss: 2.189089284478286

Epoch: 5| Step: 2
Training loss: 0.2951408735221008
Validation loss: 2.184175214216641

Epoch: 5| Step: 3
Training loss: 0.1628049325465662
Validation loss: 2.198570593528678

Epoch: 5| Step: 4
Training loss: 0.18904114200605276
Validation loss: 2.201313998684958

Epoch: 5| Step: 5
Training loss: 0.23982911702104429
Validation loss: 2.201909418988354

Epoch: 5| Step: 6
Training loss: 0.2510166210459927
Validation loss: 2.198748059578935

Epoch: 5| Step: 7
Training loss: 0.15497566557029155
Validation loss: 2.194205318944694

Epoch: 5| Step: 8
Training loss: 0.37221001833193357
Validation loss: 2.1897974720743556

Epoch: 5| Step: 9
Training loss: 0.33995610057147313
Validation loss: 2.1980553832897494

Epoch: 5| Step: 10
Training loss: 0.46746113332554806
Validation loss: 2.194949183118163

Epoch: 447| Step: 0
Training loss: 0.1833677016270495
Validation loss: 2.200705473924416

Epoch: 5| Step: 1
Training loss: 0.20123698282792035
Validation loss: 2.2048157382045566

Epoch: 5| Step: 2
Training loss: 0.2282628919646853
Validation loss: 2.19643469029727

Epoch: 5| Step: 3
Training loss: 0.3615361207852703
Validation loss: 2.239017190272912

Epoch: 5| Step: 4
Training loss: 0.27693998469721215
Validation loss: 2.1928565643818763

Epoch: 5| Step: 5
Training loss: 0.33960092573095885
Validation loss: 2.2132055237039223

Epoch: 5| Step: 6
Training loss: 0.2864482559974677
Validation loss: 2.194145868038922

Epoch: 5| Step: 7
Training loss: 0.27147029593207467
Validation loss: 2.1915861099125813

Epoch: 5| Step: 8
Training loss: 0.30545232831127206
Validation loss: 2.1786243887807015

Epoch: 5| Step: 9
Training loss: 0.18331308420116146
Validation loss: 2.15948005125003

Epoch: 5| Step: 10
Training loss: 0.34928061302176805
Validation loss: 2.1764956485422884

Epoch: 448| Step: 0
Training loss: 0.2603914995748195
Validation loss: 2.179136520271649

Epoch: 5| Step: 1
Training loss: 0.33373653965141775
Validation loss: 2.1732451557521095

Epoch: 5| Step: 2
Training loss: 0.3474929404570792
Validation loss: 2.173329474577028

Epoch: 5| Step: 3
Training loss: 0.3878487924566597
Validation loss: 2.1820048296106203

Epoch: 5| Step: 4
Training loss: 0.3359895155802189
Validation loss: 2.1593761963079166

Epoch: 5| Step: 5
Training loss: 0.3122764383772004
Validation loss: 2.1788606645960322

Epoch: 5| Step: 6
Training loss: 0.1522725562489512
Validation loss: 2.190565797881384

Epoch: 5| Step: 7
Training loss: 0.2429808267124941
Validation loss: 2.1939891612716167

Epoch: 5| Step: 8
Training loss: 0.307543318825738
Validation loss: 2.1938597385335097

Epoch: 5| Step: 9
Training loss: 0.20444293881945452
Validation loss: 2.204372625542815

Epoch: 5| Step: 10
Training loss: 0.11769876611772016
Validation loss: 2.189620289832602

Epoch: 449| Step: 0
Training loss: 0.2593234177509428
Validation loss: 2.1914811549175695

Epoch: 5| Step: 1
Training loss: 0.1709092218538594
Validation loss: 2.1744269316801845

Epoch: 5| Step: 2
Training loss: 0.251882010781189
Validation loss: 2.1631717888642696

Epoch: 5| Step: 3
Training loss: 0.18910259578290936
Validation loss: 2.1771836151501125

Epoch: 5| Step: 4
Training loss: 0.2994977019282332
Validation loss: 2.1997609225794474

Epoch: 5| Step: 5
Training loss: 0.31266591912626224
Validation loss: 2.1853110159123976

Epoch: 5| Step: 6
Training loss: 0.3691284540985573
Validation loss: 2.19797802328053

Epoch: 5| Step: 7
Training loss: 0.25556559112500465
Validation loss: 2.172926339271579

Epoch: 5| Step: 8
Training loss: 0.4119663984857635
Validation loss: 2.186386536388956

Epoch: 5| Step: 9
Training loss: 0.24437145764742058
Validation loss: 2.183206430576741

Epoch: 5| Step: 10
Training loss: 0.2518076957486726
Validation loss: 2.1774093620104416

Epoch: 450| Step: 0
Training loss: 0.4391090741688771
Validation loss: 2.181989295595821

Epoch: 5| Step: 1
Training loss: 0.20222717631384848
Validation loss: 2.168091970938661

Epoch: 5| Step: 2
Training loss: 0.3720000593687851
Validation loss: 2.193289069395993

Epoch: 5| Step: 3
Training loss: 0.14228746102062845
Validation loss: 2.1580494607841896

Epoch: 5| Step: 4
Training loss: 0.12625914676268815
Validation loss: 2.1681653082306616

Epoch: 5| Step: 5
Training loss: 0.2222971613924961
Validation loss: 2.1939214068649124

Epoch: 5| Step: 6
Training loss: 0.24963922844442601
Validation loss: 2.1609051155196166

Epoch: 5| Step: 7
Training loss: 0.18163426705995095
Validation loss: 2.1866099948102153

Epoch: 5| Step: 8
Training loss: 0.3052266681206877
Validation loss: 2.220690729877927

Epoch: 5| Step: 9
Training loss: 0.22935338794225965
Validation loss: 2.212001135233113

Epoch: 5| Step: 10
Training loss: 0.3981096938767633
Validation loss: 2.2129462243405125

Epoch: 451| Step: 0
Training loss: 0.40851872851326754
Validation loss: 2.205944438147485

Epoch: 5| Step: 1
Training loss: 0.2651479869717199
Validation loss: 2.1931178006556857

Epoch: 5| Step: 2
Training loss: 0.19588833799028973
Validation loss: 2.189362190663929

Epoch: 5| Step: 3
Training loss: 0.26645190890851234
Validation loss: 2.1851335569964774

Epoch: 5| Step: 4
Training loss: 0.24928987498603628
Validation loss: 2.16259305256934

Epoch: 5| Step: 5
Training loss: 0.3477565642086307
Validation loss: 2.172101158725066

Epoch: 5| Step: 6
Training loss: 0.391916086881191
Validation loss: 2.1401112269769835

Epoch: 5| Step: 7
Training loss: 0.2943013971486112
Validation loss: 2.143890607935499

Epoch: 5| Step: 8
Training loss: 0.27124181381301365
Validation loss: 2.1449750284239215

Epoch: 5| Step: 9
Training loss: 0.3369062561015341
Validation loss: 2.123885161477256

Epoch: 5| Step: 10
Training loss: 0.31034829130183256
Validation loss: 2.138681217700815

Epoch: 452| Step: 0
Training loss: 0.2891827281733816
Validation loss: 2.147299412561503

Epoch: 5| Step: 1
Training loss: 0.2338197887118702
Validation loss: 2.157458078249009

Epoch: 5| Step: 2
Training loss: 0.33592348291296265
Validation loss: 2.146381239727488

Epoch: 5| Step: 3
Training loss: 0.31867719361060565
Validation loss: 2.140007365272244

Epoch: 5| Step: 4
Training loss: 0.2043204434368563
Validation loss: 2.1798597786635336

Epoch: 5| Step: 5
Training loss: 0.3087679576477765
Validation loss: 2.1778410648651096

Epoch: 5| Step: 6
Training loss: 0.2724160051383498
Validation loss: 2.17693399312672

Epoch: 5| Step: 7
Training loss: 0.2517156886809092
Validation loss: 2.1465573338435253

Epoch: 5| Step: 8
Training loss: 0.2534035621620008
Validation loss: 2.1679834958260202

Epoch: 5| Step: 9
Training loss: 0.357359854731843
Validation loss: 2.1760351294669857

Epoch: 5| Step: 10
Training loss: 0.23602599543264688
Validation loss: 2.152376190352597

Epoch: 453| Step: 0
Training loss: 0.20239318553064956
Validation loss: 2.1721074424116917

Epoch: 5| Step: 1
Training loss: 0.2909793575140847
Validation loss: 2.1755529079033726

Epoch: 5| Step: 2
Training loss: 0.2126511618168744
Validation loss: 2.1604630785436645

Epoch: 5| Step: 3
Training loss: 0.23593369190351265
Validation loss: 2.1743154364762876

Epoch: 5| Step: 4
Training loss: 0.13997646965317165
Validation loss: 2.185389993293811

Epoch: 5| Step: 5
Training loss: 0.41431523653013724
Validation loss: 2.189893465533339

Epoch: 5| Step: 6
Training loss: 0.2130537195788338
Validation loss: 2.193589970914154

Epoch: 5| Step: 7
Training loss: 0.26769965259168227
Validation loss: 2.1869931402885023

Epoch: 5| Step: 8
Training loss: 0.2858122895425822
Validation loss: 2.2108578054664156

Epoch: 5| Step: 9
Training loss: 0.39809623764078933
Validation loss: 2.190719999788535

Epoch: 5| Step: 10
Training loss: 0.36364707165633536
Validation loss: 2.204109221649896

Epoch: 454| Step: 0
Training loss: 0.3601429653406967
Validation loss: 2.2076784251337527

Epoch: 5| Step: 1
Training loss: 0.22378466585341253
Validation loss: 2.216420595196664

Epoch: 5| Step: 2
Training loss: 0.23947823161047307
Validation loss: 2.2078825253855263

Epoch: 5| Step: 3
Training loss: 0.3763551663595663
Validation loss: 2.2288430273882587

Epoch: 5| Step: 4
Training loss: 0.31072075492367807
Validation loss: 2.2148613922625486

Epoch: 5| Step: 5
Training loss: 0.3856555696609242
Validation loss: 2.2137372847710055

Epoch: 5| Step: 6
Training loss: 0.1857056590843383
Validation loss: 2.194360283549265

Epoch: 5| Step: 7
Training loss: 0.17707049917013049
Validation loss: 2.215067571592521

Epoch: 5| Step: 8
Training loss: 0.29168703087604886
Validation loss: 2.1920648506093405

Epoch: 5| Step: 9
Training loss: 0.27716289587393894
Validation loss: 2.228309920593228

Epoch: 5| Step: 10
Training loss: 0.37183092080463126
Validation loss: 2.2316922697007593

Epoch: 455| Step: 0
Training loss: 0.34506513702844216
Validation loss: 2.224071085898424

Epoch: 5| Step: 1
Training loss: 0.27569449683914093
Validation loss: 2.2025882495028792

Epoch: 5| Step: 2
Training loss: 0.357849761322089
Validation loss: 2.186022307137719

Epoch: 5| Step: 3
Training loss: 0.24529228187876134
Validation loss: 2.1778376989557575

Epoch: 5| Step: 4
Training loss: 0.19329904327890932
Validation loss: 2.1667082644919096

Epoch: 5| Step: 5
Training loss: 0.3153633780210957
Validation loss: 2.2109673089064805

Epoch: 5| Step: 6
Training loss: 0.27693367581749995
Validation loss: 2.2111602233879113

Epoch: 5| Step: 7
Training loss: 0.2715219979322806
Validation loss: 2.185573730608731

Epoch: 5| Step: 8
Training loss: 0.41816245252004447
Validation loss: 2.2010502567139847

Epoch: 5| Step: 9
Training loss: 0.17440189541266024
Validation loss: 2.1877250954037284

Epoch: 5| Step: 10
Training loss: 0.20541952870782212
Validation loss: 2.183019327367361

Epoch: 456| Step: 0
Training loss: 0.15844657204216095
Validation loss: 2.2041511528430195

Epoch: 5| Step: 1
Training loss: 0.2763755311818498
Validation loss: 2.198362861446869

Epoch: 5| Step: 2
Training loss: 0.31452212554006864
Validation loss: 2.2160022590229653

Epoch: 5| Step: 3
Training loss: 0.287440297416948
Validation loss: 2.2250624699641284

Epoch: 5| Step: 4
Training loss: 0.29467420726014776
Validation loss: 2.216595400968365

Epoch: 5| Step: 5
Training loss: 0.11288330869495004
Validation loss: 2.18800339597902

Epoch: 5| Step: 6
Training loss: 0.36221637317811334
Validation loss: 2.1795393423377862

Epoch: 5| Step: 7
Training loss: 0.2202187514539913
Validation loss: 2.192205110072711

Epoch: 5| Step: 8
Training loss: 0.37823347947373986
Validation loss: 2.19218222894094

Epoch: 5| Step: 9
Training loss: 0.16250383115800487
Validation loss: 2.1839939563492106

Epoch: 5| Step: 10
Training loss: 0.2194064882019341
Validation loss: 2.1882383726480152

Epoch: 457| Step: 0
Training loss: 0.18137752798436377
Validation loss: 2.2034177507829744

Epoch: 5| Step: 1
Training loss: 0.1940498066711495
Validation loss: 2.1806268084260654

Epoch: 5| Step: 2
Training loss: 0.26196889168299664
Validation loss: 2.2004087027936223

Epoch: 5| Step: 3
Training loss: 0.1652815972254397
Validation loss: 2.200330421775838

Epoch: 5| Step: 4
Training loss: 0.20806090702605579
Validation loss: 2.1860084042345878

Epoch: 5| Step: 5
Training loss: 0.3078457543278138
Validation loss: 2.223236233517347

Epoch: 5| Step: 6
Training loss: 0.3182449369170135
Validation loss: 2.176743406415942

Epoch: 5| Step: 7
Training loss: 0.19556497467989137
Validation loss: 2.210323814854362

Epoch: 5| Step: 8
Training loss: 0.32988166605612984
Validation loss: 2.144819801224647

Epoch: 5| Step: 9
Training loss: 0.34893279432908764
Validation loss: 2.1759886224992604

Epoch: 5| Step: 10
Training loss: 0.41789569394525966
Validation loss: 2.1534236737774215

Epoch: 458| Step: 0
Training loss: 0.4196756395040248
Validation loss: 2.1611977497348867

Epoch: 5| Step: 1
Training loss: 0.21720007613017836
Validation loss: 2.1359086727193595

Epoch: 5| Step: 2
Training loss: 0.23068585111214268
Validation loss: 2.1875582152558812

Epoch: 5| Step: 3
Training loss: 0.19166885578591575
Validation loss: 2.2050378391152825

Epoch: 5| Step: 4
Training loss: 0.48486918189385375
Validation loss: 2.2271638620525462

Epoch: 5| Step: 5
Training loss: 0.40630153182452405
Validation loss: 2.1977376483453206

Epoch: 5| Step: 6
Training loss: 0.209602386921157
Validation loss: 2.151272193168001

Epoch: 5| Step: 7
Training loss: 0.2555478215702991
Validation loss: 2.1755283354748833

Epoch: 5| Step: 8
Training loss: 0.33136332031065574
Validation loss: 2.1600038578940137

Epoch: 5| Step: 9
Training loss: 0.3096297655266319
Validation loss: 2.1652218449842597

Epoch: 5| Step: 10
Training loss: 0.38363611410802423
Validation loss: 2.1378256932676196

Epoch: 459| Step: 0
Training loss: 0.29098057375788206
Validation loss: 2.1312806998822134

Epoch: 5| Step: 1
Training loss: 0.42601762562318213
Validation loss: 2.1715779379106874

Epoch: 5| Step: 2
Training loss: 0.18163619497496
Validation loss: 2.189288628977923

Epoch: 5| Step: 3
Training loss: 0.2392541145506037
Validation loss: 2.1749649824615136

Epoch: 5| Step: 4
Training loss: 0.36271701597849476
Validation loss: 2.225517002446257

Epoch: 5| Step: 5
Training loss: 0.3177459048375701
Validation loss: 2.2382325521455013

Epoch: 5| Step: 6
Training loss: 0.3650822246051129
Validation loss: 2.224989761360322

Epoch: 5| Step: 7
Training loss: 0.2852985340640316
Validation loss: 2.2471974937844914

Epoch: 5| Step: 8
Training loss: 0.34434027276904555
Validation loss: 2.263965199834315

Epoch: 5| Step: 9
Training loss: 0.17757990695648362
Validation loss: 2.2398633304446878

Epoch: 5| Step: 10
Training loss: 0.31588505569064196
Validation loss: 2.2758454853798504

Epoch: 460| Step: 0
Training loss: 0.2728571181936581
Validation loss: 2.2217912641469897

Epoch: 5| Step: 1
Training loss: 0.22120893800489602
Validation loss: 2.255050986383661

Epoch: 5| Step: 2
Training loss: 0.32321478044657187
Validation loss: 2.2938190115083197

Epoch: 5| Step: 3
Training loss: 0.14649567878342337
Validation loss: 2.2707264237094593

Epoch: 5| Step: 4
Training loss: 0.2852344536343677
Validation loss: 2.2308691625205337

Epoch: 5| Step: 5
Training loss: 0.3462404181431907
Validation loss: 2.2520904031003415

Epoch: 5| Step: 6
Training loss: 0.33589734347551564
Validation loss: 2.2488064272000017

Epoch: 5| Step: 7
Training loss: 0.23133808984135565
Validation loss: 2.204675382448841

Epoch: 5| Step: 8
Training loss: 0.35185820541143403
Validation loss: 2.2090001416192457

Epoch: 5| Step: 9
Training loss: 0.2802481955615644
Validation loss: 2.196485766203215

Epoch: 5| Step: 10
Training loss: 0.36078799317849625
Validation loss: 2.19014471709921

Epoch: 461| Step: 0
Training loss: 0.19766994624877576
Validation loss: 2.2171544449293155

Epoch: 5| Step: 1
Training loss: 0.4034205351438316
Validation loss: 2.2271339199950217

Epoch: 5| Step: 2
Training loss: 0.3391931598487041
Validation loss: 2.18163153325102

Epoch: 5| Step: 3
Training loss: 0.2965904804893979
Validation loss: 2.249767641263412

Epoch: 5| Step: 4
Training loss: 0.28776690388037146
Validation loss: 2.215069173095108

Epoch: 5| Step: 5
Training loss: 0.20000814667143307
Validation loss: 2.208741838869445

Epoch: 5| Step: 6
Training loss: 0.18646758676367162
Validation loss: 2.216858136554483

Epoch: 5| Step: 7
Training loss: 0.22611896904135242
Validation loss: 2.2056493064168183

Epoch: 5| Step: 8
Training loss: 0.254141434540091
Validation loss: 2.211939268605342

Epoch: 5| Step: 9
Training loss: 0.3644443474108158
Validation loss: 2.2258230446964897

Epoch: 5| Step: 10
Training loss: 0.2301442965959815
Validation loss: 2.1913606372311123

Epoch: 462| Step: 0
Training loss: 0.3683260250265526
Validation loss: 2.203084994333751

Epoch: 5| Step: 1
Training loss: 0.13781945063996895
Validation loss: 2.1763656867269994

Epoch: 5| Step: 2
Training loss: 0.23815318089784984
Validation loss: 2.1819540585910944

Epoch: 5| Step: 3
Training loss: 0.23266783290285423
Validation loss: 2.1790861583069594

Epoch: 5| Step: 4
Training loss: 0.2561662013573558
Validation loss: 2.176417455647529

Epoch: 5| Step: 5
Training loss: 0.2847519058878803
Validation loss: 2.176413447484397

Epoch: 5| Step: 6
Training loss: 0.22330847796392864
Validation loss: 2.1733608066564516

Epoch: 5| Step: 7
Training loss: 0.38244338632621094
Validation loss: 2.157594429594839

Epoch: 5| Step: 8
Training loss: 0.27107595006017576
Validation loss: 2.191374092918255

Epoch: 5| Step: 9
Training loss: 0.2920085940647686
Validation loss: 2.165785176723925

Epoch: 5| Step: 10
Training loss: 0.20759857467518553
Validation loss: 2.1609160580081888

Epoch: 463| Step: 0
Training loss: 0.28601432404043814
Validation loss: 2.200077294458247

Epoch: 5| Step: 1
Training loss: 0.1293180707632247
Validation loss: 2.168292714688669

Epoch: 5| Step: 2
Training loss: 0.1574995088475002
Validation loss: 2.2143103692357045

Epoch: 5| Step: 3
Training loss: 0.20206943755861
Validation loss: 2.2126257776607643

Epoch: 5| Step: 4
Training loss: 0.1899411414764834
Validation loss: 2.1851547994932967

Epoch: 5| Step: 5
Training loss: 0.32449534693748416
Validation loss: 2.1903595149211155

Epoch: 5| Step: 6
Training loss: 0.2587038007670817
Validation loss: 2.1736323017609895

Epoch: 5| Step: 7
Training loss: 0.3284319735968582
Validation loss: 2.16169053001868

Epoch: 5| Step: 8
Training loss: 0.2911243875529037
Validation loss: 2.1797161084980505

Epoch: 5| Step: 9
Training loss: 0.3118179149214856
Validation loss: 2.1792780435377708

Epoch: 5| Step: 10
Training loss: 0.2300924931364536
Validation loss: 2.195137661285808

Epoch: 464| Step: 0
Training loss: 0.1827709855927971
Validation loss: 2.2146971084459754

Epoch: 5| Step: 1
Training loss: 0.2800012922044296
Validation loss: 2.193928537161234

Epoch: 5| Step: 2
Training loss: 0.25448802906541435
Validation loss: 2.212801085380622

Epoch: 5| Step: 3
Training loss: 0.2486750315910182
Validation loss: 2.2116932163149845

Epoch: 5| Step: 4
Training loss: 0.1956176376937853
Validation loss: 2.2232374734008027

Epoch: 5| Step: 5
Training loss: 0.26722802975757415
Validation loss: 2.202681239077798

Epoch: 5| Step: 6
Training loss: 0.25591171253507833
Validation loss: 2.2160569699230193

Epoch: 5| Step: 7
Training loss: 0.17582276701723534
Validation loss: 2.212690995485896

Epoch: 5| Step: 8
Training loss: 0.27537688092504087
Validation loss: 2.2133395706563426

Epoch: 5| Step: 9
Training loss: 0.4706655463575929
Validation loss: 2.205735208496516

Epoch: 5| Step: 10
Training loss: 0.4169858087770961
Validation loss: 2.171052187425504

Epoch: 465| Step: 0
Training loss: 0.27146034683267356
Validation loss: 2.162270734997268

Epoch: 5| Step: 1
Training loss: 0.33983115468855507
Validation loss: 2.176821917946879

Epoch: 5| Step: 2
Training loss: 0.2119804489290663
Validation loss: 2.1573350675078955

Epoch: 5| Step: 3
Training loss: 0.20465686765441563
Validation loss: 2.193379064840522

Epoch: 5| Step: 4
Training loss: 0.368684779881248
Validation loss: 2.196243677790338

Epoch: 5| Step: 5
Training loss: 0.20675664359792362
Validation loss: 2.2353673925855175

Epoch: 5| Step: 6
Training loss: 0.31675339716765843
Validation loss: 2.215384411614274

Epoch: 5| Step: 7
Training loss: 0.3731739167396093
Validation loss: 2.2396513218634344

Epoch: 5| Step: 8
Training loss: 0.23559614586665006
Validation loss: 2.2336547870310013

Epoch: 5| Step: 9
Training loss: 0.24489093688543873
Validation loss: 2.249628853352343

Epoch: 5| Step: 10
Training loss: 0.18013049541246642
Validation loss: 2.256920297986257

Epoch: 466| Step: 0
Training loss: 0.36795888186948694
Validation loss: 2.2603022481821045

Epoch: 5| Step: 1
Training loss: 0.21148297635289884
Validation loss: 2.2248368057182666

Epoch: 5| Step: 2
Training loss: 0.37641783741193313
Validation loss: 2.2541606830058574

Epoch: 5| Step: 3
Training loss: 0.1512717592236612
Validation loss: 2.262544903615243

Epoch: 5| Step: 4
Training loss: 0.21688360764684175
Validation loss: 2.2275858253319045

Epoch: 5| Step: 5
Training loss: 0.2751890621734437
Validation loss: 2.207963996954595

Epoch: 5| Step: 6
Training loss: 0.29459278111547865
Validation loss: 2.209357514251079

Epoch: 5| Step: 7
Training loss: 0.2001547888703212
Validation loss: 2.185165641079599

Epoch: 5| Step: 8
Training loss: 0.31290678727867594
Validation loss: 2.2110329142178684

Epoch: 5| Step: 9
Training loss: 0.17403432317525
Validation loss: 2.196284109809725

Epoch: 5| Step: 10
Training loss: 0.3422031059364414
Validation loss: 2.1795775177403445

Epoch: 467| Step: 0
Training loss: 0.2676528492192077
Validation loss: 2.179216579611574

Epoch: 5| Step: 1
Training loss: 0.1155038890423843
Validation loss: 2.1740316090423453

Epoch: 5| Step: 2
Training loss: 0.3673296105548978
Validation loss: 2.1792645499264185

Epoch: 5| Step: 3
Training loss: 0.3961630773724081
Validation loss: 2.193981866415572

Epoch: 5| Step: 4
Training loss: 0.19883612745927282
Validation loss: 2.2066018933708738

Epoch: 5| Step: 5
Training loss: 0.19661044859591154
Validation loss: 2.178935753126039

Epoch: 5| Step: 6
Training loss: 0.2773226340408661
Validation loss: 2.1916731059454206

Epoch: 5| Step: 7
Training loss: 0.21974796614774394
Validation loss: 2.205273035691855

Epoch: 5| Step: 8
Training loss: 0.1665324972445668
Validation loss: 2.205945947781177

Epoch: 5| Step: 9
Training loss: 0.3034849644790594
Validation loss: 2.200918627804123

Epoch: 5| Step: 10
Training loss: 0.318661470367267
Validation loss: 2.178412471577465

Epoch: 468| Step: 0
Training loss: 0.2894039199746839
Validation loss: 2.204057836793336

Epoch: 5| Step: 1
Training loss: 0.21429341662846577
Validation loss: 2.2009074194411617

Epoch: 5| Step: 2
Training loss: 0.25344264915400133
Validation loss: 2.1851598653986666

Epoch: 5| Step: 3
Training loss: 0.3291371493243176
Validation loss: 2.1948113159675

Epoch: 5| Step: 4
Training loss: 0.20748874211507476
Validation loss: 2.1822808111940235

Epoch: 5| Step: 5
Training loss: 0.21187033839428623
Validation loss: 2.1903252178346437

Epoch: 5| Step: 6
Training loss: 0.33931258774575496
Validation loss: 2.199754629314078

Epoch: 5| Step: 7
Training loss: 0.25101850582194796
Validation loss: 2.2075759260599987

Epoch: 5| Step: 8
Training loss: 0.12356223310982993
Validation loss: 2.220353988305217

Epoch: 5| Step: 9
Training loss: 0.2983297667854026
Validation loss: 2.225188670006246

Epoch: 5| Step: 10
Training loss: 0.2015904821149635
Validation loss: 2.2141156844407033

Epoch: 469| Step: 0
Training loss: 0.29963252936743145
Validation loss: 2.194738256976747

Epoch: 5| Step: 1
Training loss: 0.2502238046710372
Validation loss: 2.1841584150846565

Epoch: 5| Step: 2
Training loss: 0.23513988615365178
Validation loss: 2.2161405827018914

Epoch: 5| Step: 3
Training loss: 0.2415283215464059
Validation loss: 2.2219869689941794

Epoch: 5| Step: 4
Training loss: 0.2874332340087315
Validation loss: 2.2267560326763634

Epoch: 5| Step: 5
Training loss: 0.20373152997253693
Validation loss: 2.2123747923503725

Epoch: 5| Step: 6
Training loss: 0.38831322382907524
Validation loss: 2.177270560837767

Epoch: 5| Step: 7
Training loss: 0.30890371955448753
Validation loss: 2.2220658628853767

Epoch: 5| Step: 8
Training loss: 0.1861350424633961
Validation loss: 2.219956708391926

Epoch: 5| Step: 9
Training loss: 0.20059190869381405
Validation loss: 2.213672002807276

Epoch: 5| Step: 10
Training loss: 0.18292466455895184
Validation loss: 2.2241313073879065

Epoch: 470| Step: 0
Training loss: 0.25701094781994943
Validation loss: 2.1827858072148993

Epoch: 5| Step: 1
Training loss: 0.28685383226176286
Validation loss: 2.1734645489230893

Epoch: 5| Step: 2
Training loss: 0.11936549165690646
Validation loss: 2.189143175163599

Epoch: 5| Step: 3
Training loss: 0.3226779265430854
Validation loss: 2.1903821039110944

Epoch: 5| Step: 4
Training loss: 0.2774512660131892
Validation loss: 2.2068048257754427

Epoch: 5| Step: 5
Training loss: 0.30614711142514717
Validation loss: 2.1954863544432333

Epoch: 5| Step: 6
Training loss: 0.18021661145889625
Validation loss: 2.191587472103452

Epoch: 5| Step: 7
Training loss: 0.18308206027129054
Validation loss: 2.172908585710278

Epoch: 5| Step: 8
Training loss: 0.19666291689092977
Validation loss: 2.192809996804351

Epoch: 5| Step: 9
Training loss: 0.305265721609824
Validation loss: 2.1723173530105497

Epoch: 5| Step: 10
Training loss: 0.12329146885552524
Validation loss: 2.1939059321024326

Epoch: 471| Step: 0
Training loss: 0.2952348425347411
Validation loss: 2.1853715119027104

Epoch: 5| Step: 1
Training loss: 0.18456207741425135
Validation loss: 2.2119658833179847

Epoch: 5| Step: 2
Training loss: 0.1917033517152001
Validation loss: 2.2035971730252593

Epoch: 5| Step: 3
Training loss: 0.20666975273980165
Validation loss: 2.191642860324789

Epoch: 5| Step: 4
Training loss: 0.195485782048965
Validation loss: 2.1909308921208863

Epoch: 5| Step: 5
Training loss: 0.2110944711346736
Validation loss: 2.211080470793266

Epoch: 5| Step: 6
Training loss: 0.24691741343624662
Validation loss: 2.1905494237231036

Epoch: 5| Step: 7
Training loss: 0.23368544867860697
Validation loss: 2.222901808445931

Epoch: 5| Step: 8
Training loss: 0.26384002127808814
Validation loss: 2.1743040125683515

Epoch: 5| Step: 9
Training loss: 0.4002723146886146
Validation loss: 2.221339946319931

Epoch: 5| Step: 10
Training loss: 0.16435101095626467
Validation loss: 2.2218290435772174

Epoch: 472| Step: 0
Training loss: 0.25121165742149637
Validation loss: 2.1967241728054248

Epoch: 5| Step: 1
Training loss: 0.15799272344943782
Validation loss: 2.2204094238537513

Epoch: 5| Step: 2
Training loss: 0.22004897305399124
Validation loss: 2.201968097080479

Epoch: 5| Step: 3
Training loss: 0.30379596513516666
Validation loss: 2.175759720687967

Epoch: 5| Step: 4
Training loss: 0.29983599868941174
Validation loss: 2.2172486793531774

Epoch: 5| Step: 5
Training loss: 0.10627434062538967
Validation loss: 2.1978931278970038

Epoch: 5| Step: 6
Training loss: 0.3131554167739934
Validation loss: 2.1971600965455576

Epoch: 5| Step: 7
Training loss: 0.1679276593536833
Validation loss: 2.2066679293666662

Epoch: 5| Step: 8
Training loss: 0.258932944552131
Validation loss: 2.1770911126562775

Epoch: 5| Step: 9
Training loss: 0.11777107448326568
Validation loss: 2.1918010150278047

Epoch: 5| Step: 10
Training loss: 0.2749975253123863
Validation loss: 2.2055080142316985

Epoch: 473| Step: 0
Training loss: 0.22692029751699055
Validation loss: 2.1885194058534236

Epoch: 5| Step: 1
Training loss: 0.22059785813725347
Validation loss: 2.189695141108192

Epoch: 5| Step: 2
Training loss: 0.2709250279628172
Validation loss: 2.2038389119926682

Epoch: 5| Step: 3
Training loss: 0.37182899719487367
Validation loss: 2.1729707359603063

Epoch: 5| Step: 4
Training loss: 0.2272817441928903
Validation loss: 2.1643876279859264

Epoch: 5| Step: 5
Training loss: 0.25617155293185273
Validation loss: 2.180269311069682

Epoch: 5| Step: 6
Training loss: 0.1362427463263008
Validation loss: 2.1732027922113035

Epoch: 5| Step: 7
Training loss: 0.2375869171562919
Validation loss: 2.1706908598043664

Epoch: 5| Step: 8
Training loss: 0.3294022881244559
Validation loss: 2.150617089252213

Epoch: 5| Step: 9
Training loss: 0.10769094234838336
Validation loss: 2.1732321661392495

Epoch: 5| Step: 10
Training loss: 0.27467926622794225
Validation loss: 2.182290539300817

Epoch: 474| Step: 0
Training loss: 0.25905209974849047
Validation loss: 2.183778948571307

Epoch: 5| Step: 1
Training loss: 0.19585073694719118
Validation loss: 2.1760714268903354

Epoch: 5| Step: 2
Training loss: 0.16528473575844987
Validation loss: 2.1572884048794796

Epoch: 5| Step: 3
Training loss: 0.36200747162
Validation loss: 2.187608606598655

Epoch: 5| Step: 4
Training loss: 0.18302030490183077
Validation loss: 2.1686498138133388

Epoch: 5| Step: 5
Training loss: 0.21800211374216136
Validation loss: 2.1529095946660712

Epoch: 5| Step: 6
Training loss: 0.15798576163391845
Validation loss: 2.154704135010583

Epoch: 5| Step: 7
Training loss: 0.3213729401065803
Validation loss: 2.181017490747774

Epoch: 5| Step: 8
Training loss: 0.31881060538358086
Validation loss: 2.1701338056169814

Epoch: 5| Step: 9
Training loss: 0.14382873379621486
Validation loss: 2.1543468138990396

Epoch: 5| Step: 10
Training loss: 0.11115643161461777
Validation loss: 2.1574677305368146

Epoch: 475| Step: 0
Training loss: 0.1254607515529084
Validation loss: 2.154960704607275

Epoch: 5| Step: 1
Training loss: 0.1738521420035417
Validation loss: 2.1799678268647553

Epoch: 5| Step: 2
Training loss: 0.35172420597462645
Validation loss: 2.1782850679750263

Epoch: 5| Step: 3
Training loss: 0.2860573678917947
Validation loss: 2.193864734090448

Epoch: 5| Step: 4
Training loss: 0.17360545480308925
Validation loss: 2.1705088520549447

Epoch: 5| Step: 5
Training loss: 0.130888729219254
Validation loss: 2.1685931875417452

Epoch: 5| Step: 6
Training loss: 0.20155852853573658
Validation loss: 2.1963344486063114

Epoch: 5| Step: 7
Training loss: 0.22577072600814785
Validation loss: 2.207894127375049

Epoch: 5| Step: 8
Training loss: 0.16891589487436154
Validation loss: 2.1778894721726587

Epoch: 5| Step: 9
Training loss: 0.32548111736884505
Validation loss: 2.2037179748608513

Epoch: 5| Step: 10
Training loss: 0.29228090282522756
Validation loss: 2.1883378541134

Epoch: 476| Step: 0
Training loss: 0.21254932097665516
Validation loss: 2.1661935562664807

Epoch: 5| Step: 1
Training loss: 0.16739309161393268
Validation loss: 2.197658561765783

Epoch: 5| Step: 2
Training loss: 0.24001832101103776
Validation loss: 2.206973867262994

Epoch: 5| Step: 3
Training loss: 0.35277194628856
Validation loss: 2.215069663817259

Epoch: 5| Step: 4
Training loss: 0.2736932239922641
Validation loss: 2.209800928123122

Epoch: 5| Step: 5
Training loss: 0.18737459956387822
Validation loss: 2.2117498031735168

Epoch: 5| Step: 6
Training loss: 0.28855828823777746
Validation loss: 2.1923718072301805

Epoch: 5| Step: 7
Training loss: 0.16430313764128388
Validation loss: 2.2206593048106864

Epoch: 5| Step: 8
Training loss: 0.1977153033973109
Validation loss: 2.196440546628805

Epoch: 5| Step: 9
Training loss: 0.11174014460172373
Validation loss: 2.2164895286288004

Epoch: 5| Step: 10
Training loss: 0.2949033819804746
Validation loss: 2.2276436731614755

Epoch: 477| Step: 0
Training loss: 0.17902913974484436
Validation loss: 2.1973379104373243

Epoch: 5| Step: 1
Training loss: 0.26852558325070314
Validation loss: 2.229704552098094

Epoch: 5| Step: 2
Training loss: 0.2546914065242796
Validation loss: 2.2112986311264997

Epoch: 5| Step: 3
Training loss: 0.3233796602399215
Validation loss: 2.198081669117572

Epoch: 5| Step: 4
Training loss: 0.2794830528701883
Validation loss: 2.194750176082786

Epoch: 5| Step: 5
Training loss: 0.21617202236279426
Validation loss: 2.1975537646744687

Epoch: 5| Step: 6
Training loss: 0.1673845400103489
Validation loss: 2.179672644579951

Epoch: 5| Step: 7
Training loss: 0.16108705853607233
Validation loss: 2.198114803683284

Epoch: 5| Step: 8
Training loss: 0.1898273527654203
Validation loss: 2.1750828426285804

Epoch: 5| Step: 9
Training loss: 0.18543657738867841
Validation loss: 2.1988164446735605

Epoch: 5| Step: 10
Training loss: 0.31770438702534853
Validation loss: 2.18640273799496

Epoch: 478| Step: 0
Training loss: 0.20172622374289767
Validation loss: 2.1953254681515366

Epoch: 5| Step: 1
Training loss: 0.202518603359278
Validation loss: 2.1915567217104805

Epoch: 5| Step: 2
Training loss: 0.1782358974606794
Validation loss: 2.199865141097764

Epoch: 5| Step: 3
Training loss: 0.1663416354227544
Validation loss: 2.20679462023538

Epoch: 5| Step: 4
Training loss: 0.26300560872548273
Validation loss: 2.2151136466632244

Epoch: 5| Step: 5
Training loss: 0.4147450202081887
Validation loss: 2.2046795970859145

Epoch: 5| Step: 6
Training loss: 0.20750963972864206
Validation loss: 2.208967640941237

Epoch: 5| Step: 7
Training loss: 0.2816081151307064
Validation loss: 2.1855094026927504

Epoch: 5| Step: 8
Training loss: 0.2527620798576738
Validation loss: 2.19684043965269

Epoch: 5| Step: 9
Training loss: 0.1252120424896531
Validation loss: 2.203118259614821

Epoch: 5| Step: 10
Training loss: 0.26359239015980324
Validation loss: 2.187676773897918

Epoch: 479| Step: 0
Training loss: 0.33242992700670937
Validation loss: 2.1739760975946947

Epoch: 5| Step: 1
Training loss: 0.22771526439695625
Validation loss: 2.1710144796965865

Epoch: 5| Step: 2
Training loss: 0.1871591987454002
Validation loss: 2.164110385685866

Epoch: 5| Step: 3
Training loss: 0.32921048407911646
Validation loss: 2.1727949772991044

Epoch: 5| Step: 4
Training loss: 0.2623463550004339
Validation loss: 2.193086979372045

Epoch: 5| Step: 5
Training loss: 0.25159390294984
Validation loss: 2.2057030293147486

Epoch: 5| Step: 6
Training loss: 0.2278768626946233
Validation loss: 2.1634470341826146

Epoch: 5| Step: 7
Training loss: 0.29221452904187006
Validation loss: 2.165403307372381

Epoch: 5| Step: 8
Training loss: 0.158756571374636
Validation loss: 2.1794454830046126

Epoch: 5| Step: 9
Training loss: 0.19194125317699168
Validation loss: 2.156386462805674

Epoch: 5| Step: 10
Training loss: 0.1799538752613159
Validation loss: 2.1928418262340177

Epoch: 480| Step: 0
Training loss: 0.21302123831420555
Validation loss: 2.1612844465170045

Epoch: 5| Step: 1
Training loss: 0.233541006174665
Validation loss: 2.1746004570497304

Epoch: 5| Step: 2
Training loss: 0.33860308994707305
Validation loss: 2.19703696242659

Epoch: 5| Step: 3
Training loss: 0.14290167402385753
Validation loss: 2.183175381297597

Epoch: 5| Step: 4
Training loss: 0.20989525233267997
Validation loss: 2.2140949354546535

Epoch: 5| Step: 5
Training loss: 0.1671706300317059
Validation loss: 2.2226792858452624

Epoch: 5| Step: 6
Training loss: 0.23250325965903598
Validation loss: 2.2404532843200786

Epoch: 5| Step: 7
Training loss: 0.34581350730268057
Validation loss: 2.2050235212943514

Epoch: 5| Step: 8
Training loss: 0.12519401156840115
Validation loss: 2.201345345299708

Epoch: 5| Step: 9
Training loss: 0.23419848788963935
Validation loss: 2.2195306537236377

Epoch: 5| Step: 10
Training loss: 0.32476966655346323
Validation loss: 2.1990905618280387

Epoch: 481| Step: 0
Training loss: 0.16373057507731406
Validation loss: 2.185682075181724

Epoch: 5| Step: 1
Training loss: 0.3772740159451431
Validation loss: 2.1987245753769185

Epoch: 5| Step: 2
Training loss: 0.2595172641299763
Validation loss: 2.18341786282322

Epoch: 5| Step: 3
Training loss: 0.09203144802888248
Validation loss: 2.1744752517045014

Epoch: 5| Step: 4
Training loss: 0.29055652632124657
Validation loss: 2.17437851832359

Epoch: 5| Step: 5
Training loss: 0.2005743578695027
Validation loss: 2.164969951510445

Epoch: 5| Step: 6
Training loss: 0.35082971709570626
Validation loss: 2.1553075287303143

Epoch: 5| Step: 7
Training loss: 0.1602547970409381
Validation loss: 2.161973505836381

Epoch: 5| Step: 8
Training loss: 0.17758242431148702
Validation loss: 2.164354437847473

Epoch: 5| Step: 9
Training loss: 0.18165135095573282
Validation loss: 2.1593245738657867

Epoch: 5| Step: 10
Training loss: 0.21034586906697528
Validation loss: 2.2010696552926867

Epoch: 482| Step: 0
Training loss: 0.12790338959374234
Validation loss: 2.1828433061151284

Epoch: 5| Step: 1
Training loss: 0.22523019657764615
Validation loss: 2.209420020569311

Epoch: 5| Step: 2
Training loss: 0.21942176871869998
Validation loss: 2.187361992673808

Epoch: 5| Step: 3
Training loss: 0.3059432001332957
Validation loss: 2.1792222939899317

Epoch: 5| Step: 4
Training loss: 0.1967852948193954
Validation loss: 2.1832746830702523

Epoch: 5| Step: 5
Training loss: 0.1977776689734127
Validation loss: 2.1634860922394084

Epoch: 5| Step: 6
Training loss: 0.13885771025604837
Validation loss: 2.19986312094071

Epoch: 5| Step: 7
Training loss: 0.16552294947550056
Validation loss: 2.175901660344128

Epoch: 5| Step: 8
Training loss: 0.27430319667692543
Validation loss: 2.1894317804768377

Epoch: 5| Step: 9
Training loss: 0.3491354025729513
Validation loss: 2.1708741436365293

Epoch: 5| Step: 10
Training loss: 0.35580552046413444
Validation loss: 2.197933380276467

Epoch: 483| Step: 0
Training loss: 0.28748319255378973
Validation loss: 2.200392507029817

Epoch: 5| Step: 1
Training loss: 0.18956252017022643
Validation loss: 2.2028163061500314

Epoch: 5| Step: 2
Training loss: 0.2998756299904697
Validation loss: 2.2000413578467843

Epoch: 5| Step: 3
Training loss: 0.145321124600246
Validation loss: 2.2155133490505

Epoch: 5| Step: 4
Training loss: 0.13984391729248952
Validation loss: 2.218801053846478

Epoch: 5| Step: 5
Training loss: 0.25463782335032104
Validation loss: 2.2246718958741596

Epoch: 5| Step: 6
Training loss: 0.2528637833325623
Validation loss: 2.222382388658041

Epoch: 5| Step: 7
Training loss: 0.2725325459546907
Validation loss: 2.236811957614433

Epoch: 5| Step: 8
Training loss: 0.20006330836680067
Validation loss: 2.239919293200573

Epoch: 5| Step: 9
Training loss: 0.28309268771240814
Validation loss: 2.215075928616675

Epoch: 5| Step: 10
Training loss: 0.14052547800868087
Validation loss: 2.226205544102809

Epoch: 484| Step: 0
Training loss: 0.2106795499835632
Validation loss: 2.2166242338464324

Epoch: 5| Step: 1
Training loss: 0.2139571710392163
Validation loss: 2.214913679297532

Epoch: 5| Step: 2
Training loss: 0.15545000078254054
Validation loss: 2.2018861379084376

Epoch: 5| Step: 3
Training loss: 0.24132768994628973
Validation loss: 2.1921913434446787

Epoch: 5| Step: 4
Training loss: 0.09377492136322707
Validation loss: 2.1781834278481695

Epoch: 5| Step: 5
Training loss: 0.38877556725966506
Validation loss: 2.1855970482116214

Epoch: 5| Step: 6
Training loss: 0.324622890498608
Validation loss: 2.1716739906489297

Epoch: 5| Step: 7
Training loss: 0.15752252716602075
Validation loss: 2.170269101891241

Epoch: 5| Step: 8
Training loss: 0.2638325237148086
Validation loss: 2.1768963543067326

Epoch: 5| Step: 9
Training loss: 0.1909691919943717
Validation loss: 2.1914659717584546

Epoch: 5| Step: 10
Training loss: 0.17939485685913903
Validation loss: 2.1853369183351425

Epoch: 485| Step: 0
Training loss: 0.22335031315559756
Validation loss: 2.18145149894679

Epoch: 5| Step: 1
Training loss: 0.18794397599924473
Validation loss: 2.1937664100901015

Epoch: 5| Step: 2
Training loss: 0.1487164824553984
Validation loss: 2.171689884715606

Epoch: 5| Step: 3
Training loss: 0.22303638299960446
Validation loss: 2.162466906601905

Epoch: 5| Step: 4
Training loss: 0.2831261628908103
Validation loss: 2.167864555523821

Epoch: 5| Step: 5
Training loss: 0.25496789089637434
Validation loss: 2.2088950391439304

Epoch: 5| Step: 6
Training loss: 0.2572851278012123
Validation loss: 2.1746072086104964

Epoch: 5| Step: 7
Training loss: 0.2152416359564586
Validation loss: 2.186168875064049

Epoch: 5| Step: 8
Training loss: 0.26078223160272695
Validation loss: 2.1809174887591247

Epoch: 5| Step: 9
Training loss: 0.18332455561677788
Validation loss: 2.1837603103230228

Epoch: 5| Step: 10
Training loss: 0.19466794469907284
Validation loss: 2.2000984876365552

Epoch: 486| Step: 0
Training loss: 0.14756393624915087
Validation loss: 2.1788437756591224

Epoch: 5| Step: 1
Training loss: 0.14098298019891153
Validation loss: 2.199296816471556

Epoch: 5| Step: 2
Training loss: 0.14474374383417155
Validation loss: 2.1593280501073067

Epoch: 5| Step: 3
Training loss: 0.38433461326001106
Validation loss: 2.1651369297959264

Epoch: 5| Step: 4
Training loss: 0.11998338147166973
Validation loss: 2.1640888628759343

Epoch: 5| Step: 5
Training loss: 0.2438407429489306
Validation loss: 2.174490058335709

Epoch: 5| Step: 6
Training loss: 0.34474976329159096
Validation loss: 2.169853663863758

Epoch: 5| Step: 7
Training loss: 0.21020815289914643
Validation loss: 2.1977909682822743

Epoch: 5| Step: 8
Training loss: 0.17805121550012537
Validation loss: 2.215144381361793

Epoch: 5| Step: 9
Training loss: 0.20606386245621913
Validation loss: 2.175277528228896

Epoch: 5| Step: 10
Training loss: 0.19461205768918396
Validation loss: 2.1863555973489945

Epoch: 487| Step: 0
Training loss: 0.27047205940042224
Validation loss: 2.197319312530149

Epoch: 5| Step: 1
Training loss: 0.19745293779327316
Validation loss: 2.195091679333035

Epoch: 5| Step: 2
Training loss: 0.19164310125593156
Validation loss: 2.191273873893605

Epoch: 5| Step: 3
Training loss: 0.21926671546790463
Validation loss: 2.1918109576173217

Epoch: 5| Step: 4
Training loss: 0.30091011705131265
Validation loss: 2.1747877517408343

Epoch: 5| Step: 5
Training loss: 0.15839659669796596
Validation loss: 2.1818552918419014

Epoch: 5| Step: 6
Training loss: 0.22621804393685
Validation loss: 2.178001765496638

Epoch: 5| Step: 7
Training loss: 0.11613732097919048
Validation loss: 2.2133065696145366

Epoch: 5| Step: 8
Training loss: 0.26795484656919183
Validation loss: 2.1737933477319356

Epoch: 5| Step: 9
Training loss: 0.1292320166584691
Validation loss: 2.1861461569343312

Epoch: 5| Step: 10
Training loss: 0.22370924330706463
Validation loss: 2.206348965591808

Epoch: 488| Step: 0
Training loss: 0.2267649338135469
Validation loss: 2.202862542620375

Epoch: 5| Step: 1
Training loss: 0.24582115849692304
Validation loss: 2.1992619168039784

Epoch: 5| Step: 2
Training loss: 0.13310774075646423
Validation loss: 2.2023665775753734

Epoch: 5| Step: 3
Training loss: 0.21214446274628915
Validation loss: 2.2043976829612184

Epoch: 5| Step: 4
Training loss: 0.23636975197637303
Validation loss: 2.1859346428996242

Epoch: 5| Step: 5
Training loss: 0.19529462732556338
Validation loss: 2.1928073668851717

Epoch: 5| Step: 6
Training loss: 0.26995768882221954
Validation loss: 2.178232683180012

Epoch: 5| Step: 7
Training loss: 0.28339885656429675
Validation loss: 2.2004255299040025

Epoch: 5| Step: 8
Training loss: 0.11339716899765488
Validation loss: 2.1868257605642127

Epoch: 5| Step: 9
Training loss: 0.1328345588989909
Validation loss: 2.200215249937333

Epoch: 5| Step: 10
Training loss: 0.26586839800153833
Validation loss: 2.1938220535550763

Epoch: 489| Step: 0
Training loss: 0.166492864516724
Validation loss: 2.1958025548576243

Epoch: 5| Step: 1
Training loss: 0.1396300763950789
Validation loss: 2.199987349574037

Epoch: 5| Step: 2
Training loss: 0.23900589428600355
Validation loss: 2.183974264065233

Epoch: 5| Step: 3
Training loss: 0.34202997161222026
Validation loss: 2.1848679894396947

Epoch: 5| Step: 4
Training loss: 0.09570443386039226
Validation loss: 2.1798409446079123

Epoch: 5| Step: 5
Training loss: 0.22888076171622915
Validation loss: 2.172653346785016

Epoch: 5| Step: 6
Training loss: 0.33402606636969506
Validation loss: 2.206949560171088

Epoch: 5| Step: 7
Training loss: 0.32401431199020364
Validation loss: 2.1928400866198183

Epoch: 5| Step: 8
Training loss: 0.14183324736174358
Validation loss: 2.2046087884857206

Epoch: 5| Step: 9
Training loss: 0.13477989480584182
Validation loss: 2.2078817137548743

Epoch: 5| Step: 10
Training loss: 0.11594688244536802
Validation loss: 2.201312525471009

Epoch: 490| Step: 0
Training loss: 0.3405761171839954
Validation loss: 2.221174151575169

Epoch: 5| Step: 1
Training loss: 0.12181790386879979
Validation loss: 2.2070805596293486

Epoch: 5| Step: 2
Training loss: 0.1607122771198157
Validation loss: 2.19294535885204

Epoch: 5| Step: 3
Training loss: 0.2653936893621985
Validation loss: 2.2400672242940565

Epoch: 5| Step: 4
Training loss: 0.2238108746470407
Validation loss: 2.2215154151445278

Epoch: 5| Step: 5
Training loss: 0.19894695440843568
Validation loss: 2.191706012512395

Epoch: 5| Step: 6
Training loss: 0.1987407784751862
Validation loss: 2.2242032539397862

Epoch: 5| Step: 7
Training loss: 0.17475732769153426
Validation loss: 2.201064139148645

Epoch: 5| Step: 8
Training loss: 0.2237366847386525
Validation loss: 2.207257716039315

Epoch: 5| Step: 9
Training loss: 0.16522068548647167
Validation loss: 2.2097070449242535

Epoch: 5| Step: 10
Training loss: 0.20407232960427396
Validation loss: 2.214295451443999

Epoch: 491| Step: 0
Training loss: 0.2631104036663677
Validation loss: 2.2031213100998523

Epoch: 5| Step: 1
Training loss: 0.18643080323430586
Validation loss: 2.214023231853261

Epoch: 5| Step: 2
Training loss: 0.32494949810419566
Validation loss: 2.1825552021159

Epoch: 5| Step: 3
Training loss: 0.1946995175940254
Validation loss: 2.188965335053974

Epoch: 5| Step: 4
Training loss: 0.1610839943193454
Validation loss: 2.19715687589074

Epoch: 5| Step: 5
Training loss: 0.25173025106135294
Validation loss: 2.187730745664951

Epoch: 5| Step: 6
Training loss: 0.11560726851389842
Validation loss: 2.199208941734948

Epoch: 5| Step: 7
Training loss: 0.14512473121432534
Validation loss: 2.185459334802543

Epoch: 5| Step: 8
Training loss: 0.2228958697659652
Validation loss: 2.185183409737797

Epoch: 5| Step: 9
Training loss: 0.1301351405103428
Validation loss: 2.195682717901734

Epoch: 5| Step: 10
Training loss: 0.2757010097319827
Validation loss: 2.185959403858677

Epoch: 492| Step: 0
Training loss: 0.3036507181894662
Validation loss: 2.188577029391688

Epoch: 5| Step: 1
Training loss: 0.2501456611198298
Validation loss: 2.2035944012493056

Epoch: 5| Step: 2
Training loss: 0.10707506201980757
Validation loss: 2.1702143264183094

Epoch: 5| Step: 3
Training loss: 0.1517970595307144
Validation loss: 2.1864913566328865

Epoch: 5| Step: 4
Training loss: 0.1563394231016429
Validation loss: 2.19348565994564

Epoch: 5| Step: 5
Training loss: 0.26881554159232157
Validation loss: 2.1596849856831923

Epoch: 5| Step: 6
Training loss: 0.18550532026257438
Validation loss: 2.194741479720643

Epoch: 5| Step: 7
Training loss: 0.21977230867378902
Validation loss: 2.1882457686594297

Epoch: 5| Step: 8
Training loss: 0.13611832655205833
Validation loss: 2.192445610413729

Epoch: 5| Step: 9
Training loss: 0.30884306530141736
Validation loss: 2.1638669410246933

Epoch: 5| Step: 10
Training loss: 0.1510036039624957
Validation loss: 2.1922610410800845

Epoch: 493| Step: 0
Training loss: 0.16748134179068472
Validation loss: 2.166288751895412

Epoch: 5| Step: 1
Training loss: 0.2742468572269589
Validation loss: 2.184251557234491

Epoch: 5| Step: 2
Training loss: 0.1782788540798678
Validation loss: 2.2172609700017993

Epoch: 5| Step: 3
Training loss: 0.17054601571237493
Validation loss: 2.190427687315346

Epoch: 5| Step: 4
Training loss: 0.17008176493922292
Validation loss: 2.1848412254798064

Epoch: 5| Step: 5
Training loss: 0.12740622871694418
Validation loss: 2.1986379702949566

Epoch: 5| Step: 6
Training loss: 0.23429619735919968
Validation loss: 2.202091890305787

Epoch: 5| Step: 7
Training loss: 0.21278439067271263
Validation loss: 2.199048524813813

Epoch: 5| Step: 8
Training loss: 0.25132990800001564
Validation loss: 2.188790956793581

Epoch: 5| Step: 9
Training loss: 0.2537754308707238
Validation loss: 2.2134278190815624

Epoch: 5| Step: 10
Training loss: 0.19809507915726712
Validation loss: 2.1973747021070276

Epoch: 494| Step: 0
Training loss: 0.23686594494092023
Validation loss: 2.1744376938237076

Epoch: 5| Step: 1
Training loss: 0.3146692800692827
Validation loss: 2.1719711794700327

Epoch: 5| Step: 2
Training loss: 0.2652304046513474
Validation loss: 2.174519021696481

Epoch: 5| Step: 3
Training loss: 0.18143301553601413
Validation loss: 2.1817359726848897

Epoch: 5| Step: 4
Training loss: 0.27312240156338713
Validation loss: 2.186340100695681

Epoch: 5| Step: 5
Training loss: 0.14340469413207585
Validation loss: 2.1706876686718943

Epoch: 5| Step: 6
Training loss: 0.14320526284819207
Validation loss: 2.172684434927396

Epoch: 5| Step: 7
Training loss: 0.19724505855501318
Validation loss: 2.177587331196957

Epoch: 5| Step: 8
Training loss: 0.09484811240192154
Validation loss: 2.1765018547588086

Epoch: 5| Step: 9
Training loss: 0.17664110957217996
Validation loss: 2.1536372261298444

Epoch: 5| Step: 10
Training loss: 0.12810350214476215
Validation loss: 2.178735408729275

Epoch: 495| Step: 0
Training loss: 0.25507363670337746
Validation loss: 2.188434893271839

Epoch: 5| Step: 1
Training loss: 0.16842442072476696
Validation loss: 2.174195062092367

Epoch: 5| Step: 2
Training loss: 0.13846214310826577
Validation loss: 2.168751075647195

Epoch: 5| Step: 3
Training loss: 0.32523936755095995
Validation loss: 2.1888609372159804

Epoch: 5| Step: 4
Training loss: 0.13152300818440926
Validation loss: 2.1883210866439664

Epoch: 5| Step: 5
Training loss: 0.16273032037314372
Validation loss: 2.2168874061757005

Epoch: 5| Step: 6
Training loss: 0.2617495646769156
Validation loss: 2.1662979222376477

Epoch: 5| Step: 7
Training loss: 0.17790168181691723
Validation loss: 2.1862595792971984

Epoch: 5| Step: 8
Training loss: 0.1292521719279689
Validation loss: 2.195441694052317

Epoch: 5| Step: 9
Training loss: 0.3213006571153035
Validation loss: 2.1968153963948245

Epoch: 5| Step: 10
Training loss: 0.13788886028597827
Validation loss: 2.1959495316458826

Epoch: 496| Step: 0
Training loss: 0.20386309587268872
Validation loss: 2.176300164277186

Epoch: 5| Step: 1
Training loss: 0.1823089262193914
Validation loss: 2.1971318003601836

Epoch: 5| Step: 2
Training loss: 0.12103884359704477
Validation loss: 2.183047817044574

Epoch: 5| Step: 3
Training loss: 0.12721860710244715
Validation loss: 2.1741956905641566

Epoch: 5| Step: 4
Training loss: 0.23082710143799504
Validation loss: 2.1785208201504616

Epoch: 5| Step: 5
Training loss: 0.22013001594969786
Validation loss: 2.1794231335482013

Epoch: 5| Step: 6
Training loss: 0.2650974869901448
Validation loss: 2.1822145447282932

Epoch: 5| Step: 7
Training loss: 0.2992472234181252
Validation loss: 2.186393391673339

Epoch: 5| Step: 8
Training loss: 0.15422137139362152
Validation loss: 2.2038002573513444

Epoch: 5| Step: 9
Training loss: 0.15623294021934972
Validation loss: 2.1710098985874176

Epoch: 5| Step: 10
Training loss: 0.24558565124281456
Validation loss: 2.2039008803802624

Epoch: 497| Step: 0
Training loss: 0.1496074273005065
Validation loss: 2.2001000155557073

Epoch: 5| Step: 1
Training loss: 0.12793439026553438
Validation loss: 2.1971152175597344

Epoch: 5| Step: 2
Training loss: 0.277290473441507
Validation loss: 2.190719221002042

Epoch: 5| Step: 3
Training loss: 0.11165225794590389
Validation loss: 2.1941910542858727

Epoch: 5| Step: 4
Training loss: 0.2886273743394257
Validation loss: 2.2263805638181404

Epoch: 5| Step: 5
Training loss: 0.21983337349387586
Validation loss: 2.1969951880505647

Epoch: 5| Step: 6
Training loss: 0.2505318527547507
Validation loss: 2.1995446983895146

Epoch: 5| Step: 7
Training loss: 0.10747669728403693
Validation loss: 2.179296670124896

Epoch: 5| Step: 8
Training loss: 0.14701901461966607
Validation loss: 2.1753550720906887

Epoch: 5| Step: 9
Training loss: 0.26948783358976997
Validation loss: 2.214650093144852

Epoch: 5| Step: 10
Training loss: 0.1978698202372152
Validation loss: 2.2183702251594255

Epoch: 498| Step: 0
Training loss: 0.13015931319333537
Validation loss: 2.203607036796527

Epoch: 5| Step: 1
Training loss: 0.14000604099200012
Validation loss: 2.210550005043265

Epoch: 5| Step: 2
Training loss: 0.18034914768214305
Validation loss: 2.210720710093482

Epoch: 5| Step: 3
Training loss: 0.23698081375779323
Validation loss: 2.2084079291788727

Epoch: 5| Step: 4
Training loss: 0.14250540511855922
Validation loss: 2.2240328177701154

Epoch: 5| Step: 5
Training loss: 0.28262042905138784
Validation loss: 2.2168609374254973

Epoch: 5| Step: 6
Training loss: 0.26842058474854974
Validation loss: 2.188582419752003

Epoch: 5| Step: 7
Training loss: 0.25276896256288234
Validation loss: 2.188135681138459

Epoch: 5| Step: 8
Training loss: 0.17164556405032855
Validation loss: 2.1753856219491463

Epoch: 5| Step: 9
Training loss: 0.1391431162256131
Validation loss: 2.1962559418279795

Epoch: 5| Step: 10
Training loss: 0.21069568442678505
Validation loss: 2.205009039447646

Epoch: 499| Step: 0
Training loss: 0.20843585392589384
Validation loss: 2.16807007320493

Epoch: 5| Step: 1
Training loss: 0.124819338152033
Validation loss: 2.2103345068913747

Epoch: 5| Step: 2
Training loss: 0.2579538651347785
Validation loss: 2.171214537620016

Epoch: 5| Step: 3
Training loss: 0.20922561340811877
Validation loss: 2.1818596345709516

Epoch: 5| Step: 4
Training loss: 0.09930162948162682
Validation loss: 2.194019081261956

Epoch: 5| Step: 5
Training loss: 0.13051667104306677
Validation loss: 2.175191211793715

Epoch: 5| Step: 6
Training loss: 0.10054471736095676
Validation loss: 2.201977645944525

Epoch: 5| Step: 7
Training loss: 0.4095350738777678
Validation loss: 2.2003826888506675

Epoch: 5| Step: 8
Training loss: 0.19960267341248183
Validation loss: 2.195606541165257

Epoch: 5| Step: 9
Training loss: 0.1105337917012996
Validation loss: 2.1882169149353348

Epoch: 5| Step: 10
Training loss: 0.20781825387489425
Validation loss: 2.1826038607674803

Epoch: 500| Step: 0
Training loss: 0.21508893847345587
Validation loss: 2.1558381106774975

Epoch: 5| Step: 1
Training loss: 0.30384286548015343
Validation loss: 2.17741550439899

Epoch: 5| Step: 2
Training loss: 0.18369357459143737
Validation loss: 2.155739537898655

Epoch: 5| Step: 3
Training loss: 0.2570703401378599
Validation loss: 2.18464429826886

Epoch: 5| Step: 4
Training loss: 0.12552516113302056
Validation loss: 2.1443592324338936

Epoch: 5| Step: 5
Training loss: 0.13885719381391873
Validation loss: 2.1800269070929414

Epoch: 5| Step: 6
Training loss: 0.10839485042238678
Validation loss: 2.1566002685959575

Epoch: 5| Step: 7
Training loss: 0.12201664317015574
Validation loss: 2.178710982397609

Epoch: 5| Step: 8
Training loss: 0.1762336578215881
Validation loss: 2.194059764888521

Epoch: 5| Step: 9
Training loss: 0.28423772789424145
Validation loss: 2.1710265001173843

Epoch: 5| Step: 10
Training loss: 0.22763258522368768
Validation loss: 2.1680149548296352

Epoch: 501| Step: 0
Training loss: 0.28416373349006235
Validation loss: 2.1743539847956184

Epoch: 5| Step: 1
Training loss: 0.14727699731684304
Validation loss: 2.1908514972238775

Epoch: 5| Step: 2
Training loss: 0.1666516853592944
Validation loss: 2.1903374699490317

Epoch: 5| Step: 3
Training loss: 0.22999736294582232
Validation loss: 2.178483014869005

Epoch: 5| Step: 4
Training loss: 0.3524128590240019
Validation loss: 2.158533348248002

Epoch: 5| Step: 5
Training loss: 0.19035437635271246
Validation loss: 2.164244085061803

Epoch: 5| Step: 6
Training loss: 0.1783468780283366
Validation loss: 2.1630906592417336

Epoch: 5| Step: 7
Training loss: 0.25111002657441844
Validation loss: 2.1556968550159343

Epoch: 5| Step: 8
Training loss: 0.16390301127547746
Validation loss: 2.1399169450263624

Epoch: 5| Step: 9
Training loss: 0.1607911620499969
Validation loss: 2.1969515379513567

Epoch: 5| Step: 10
Training loss: 0.07690831733972392
Validation loss: 2.1838477237573377

Epoch: 502| Step: 0
Training loss: 0.24443338007809012
Validation loss: 2.2005427504645376

Epoch: 5| Step: 1
Training loss: 0.19396183293139319
Validation loss: 2.2257093826309773

Epoch: 5| Step: 2
Training loss: 0.15878479190540526
Validation loss: 2.2403262192376627

Epoch: 5| Step: 3
Training loss: 0.283958138955363
Validation loss: 2.1988821874996365

Epoch: 5| Step: 4
Training loss: 0.11456701630312831
Validation loss: 2.226188195571465

Epoch: 5| Step: 5
Training loss: 0.19697502183983057
Validation loss: 2.1853766746720833

Epoch: 5| Step: 6
Training loss: 0.22659030283319584
Validation loss: 2.1858998318921254

Epoch: 5| Step: 7
Training loss: 0.2030283899908737
Validation loss: 2.1916712735805834

Epoch: 5| Step: 8
Training loss: 0.13143083002305525
Validation loss: 2.1800653844076336

Epoch: 5| Step: 9
Training loss: 0.2566024966781134
Validation loss: 2.1705395203199402

Epoch: 5| Step: 10
Training loss: 0.17428926315340526
Validation loss: 2.19347054442463

Epoch: 503| Step: 0
Training loss: 0.35045506576918445
Validation loss: 2.201988044370828

Epoch: 5| Step: 1
Training loss: 0.2820889754672555
Validation loss: 2.1681848945393836

Epoch: 5| Step: 2
Training loss: 0.1814545940082502
Validation loss: 2.2030717768684314

Epoch: 5| Step: 3
Training loss: 0.10090216214419614
Validation loss: 2.1810246015200665

Epoch: 5| Step: 4
Training loss: 0.2555207202557079
Validation loss: 2.195434956935417

Epoch: 5| Step: 5
Training loss: 0.13049679671709763
Validation loss: 2.1932622129954766

Epoch: 5| Step: 6
Training loss: 0.16511138482565912
Validation loss: 2.1849564479817247

Epoch: 5| Step: 7
Training loss: 0.09949456872924906
Validation loss: 2.1771626602026353

Epoch: 5| Step: 8
Training loss: 0.2281230831718911
Validation loss: 2.2077211077749572

Epoch: 5| Step: 9
Training loss: 0.14543530878785976
Validation loss: 2.1779515809286223

Epoch: 5| Step: 10
Training loss: 0.16538769955901617
Validation loss: 2.212740329606745

Epoch: 504| Step: 0
Training loss: 0.29673443779395586
Validation loss: 2.2035086198948646

Epoch: 5| Step: 1
Training loss: 0.164213689894894
Validation loss: 2.1821134917776175

Epoch: 5| Step: 2
Training loss: 0.10917674983649753
Validation loss: 2.18661779378083

Epoch: 5| Step: 3
Training loss: 0.152180804628202
Validation loss: 2.2093981274884507

Epoch: 5| Step: 4
Training loss: 0.16358322004916576
Validation loss: 2.1815559587510234

Epoch: 5| Step: 5
Training loss: 0.18346328360812628
Validation loss: 2.1824497191412178

Epoch: 5| Step: 6
Training loss: 0.3225120064991817
Validation loss: 2.20185451984942

Epoch: 5| Step: 7
Training loss: 0.10774149163041974
Validation loss: 2.21621425862308

Epoch: 5| Step: 8
Training loss: 0.1348022880992843
Validation loss: 2.1849489141176446

Epoch: 5| Step: 9
Training loss: 0.23757391833388586
Validation loss: 2.176596060690984

Epoch: 5| Step: 10
Training loss: 0.34993056775159276
Validation loss: 2.184197279716867

Epoch: 505| Step: 0
Training loss: 0.31857514821479954
Validation loss: 2.178109034296747

Epoch: 5| Step: 1
Training loss: 0.1559003255104205
Validation loss: 2.2177881064880602

Epoch: 5| Step: 2
Training loss: 0.18262491872813083
Validation loss: 2.1916596950814866

Epoch: 5| Step: 3
Training loss: 0.343825245337897
Validation loss: 2.21898796472742

Epoch: 5| Step: 4
Training loss: 0.2690845879627591
Validation loss: 2.188604938938992

Epoch: 5| Step: 5
Training loss: 0.13771247080499374
Validation loss: 2.174515919592445

Epoch: 5| Step: 6
Training loss: 0.16421430807702986
Validation loss: 2.2086953566617824

Epoch: 5| Step: 7
Training loss: 0.23468833482545573
Validation loss: 2.2020713493435604

Epoch: 5| Step: 8
Training loss: 0.1932187387749306
Validation loss: 2.1885791232204097

Epoch: 5| Step: 9
Training loss: 0.17718053819210022
Validation loss: 2.188678900768554

Epoch: 5| Step: 10
Training loss: 0.27932948475648806
Validation loss: 2.2138192831659818

Epoch: 506| Step: 0
Training loss: 0.20593310561288958
Validation loss: 2.1959743752250067

Epoch: 5| Step: 1
Training loss: 0.24527641079518006
Validation loss: 2.1816508659514398

Epoch: 5| Step: 2
Training loss: 0.3119537347395451
Validation loss: 2.182088396988068

Epoch: 5| Step: 3
Training loss: 0.2904505780524072
Validation loss: 2.1913272288538996

Epoch: 5| Step: 4
Training loss: 0.19167284013992314
Validation loss: 2.183044569991727

Epoch: 5| Step: 5
Training loss: 0.30665504518849707
Validation loss: 2.1639728846700512

Epoch: 5| Step: 6
Training loss: 0.22995921561165267
Validation loss: 2.1796519223318853

Epoch: 5| Step: 7
Training loss: 0.11324062934532508
Validation loss: 2.195585263468732

Epoch: 5| Step: 8
Training loss: 0.1403938420138881
Validation loss: 2.1731224653108487

Epoch: 5| Step: 9
Training loss: 0.2803903794307489
Validation loss: 2.194251936065246

Epoch: 5| Step: 10
Training loss: 0.17706432427497634
Validation loss: 2.1800145723356907

Epoch: 507| Step: 0
Training loss: 0.2858208658156462
Validation loss: 2.1803818815918166

Epoch: 5| Step: 1
Training loss: 0.16752508253213055
Validation loss: 2.197735212711287

Epoch: 5| Step: 2
Training loss: 0.2955843073236726
Validation loss: 2.1755555038857226

Epoch: 5| Step: 3
Training loss: 0.1462197520284281
Validation loss: 2.1802284380155315

Epoch: 5| Step: 4
Training loss: 0.17660384031774654
Validation loss: 2.212324703232049

Epoch: 5| Step: 5
Training loss: 0.25037793560278254
Validation loss: 2.2313568201804044

Epoch: 5| Step: 6
Training loss: 0.22768808977415617
Validation loss: 2.219317365842972

Epoch: 5| Step: 7
Training loss: 0.2440609611238034
Validation loss: 2.2234916559523517

Epoch: 5| Step: 8
Training loss: 0.23342171556914326
Validation loss: 2.2285559351140725

Epoch: 5| Step: 9
Training loss: 0.1418470162677223
Validation loss: 2.2183387839768702

Epoch: 5| Step: 10
Training loss: 0.21577750942349758
Validation loss: 2.22188664841407

Epoch: 508| Step: 0
Training loss: 0.19330003579265678
Validation loss: 2.1963952992777256

Epoch: 5| Step: 1
Training loss: 0.21569085877610164
Validation loss: 2.242550941977278

Epoch: 5| Step: 2
Training loss: 0.26093376636689297
Validation loss: 2.2232027506370065

Epoch: 5| Step: 3
Training loss: 0.12565434818825624
Validation loss: 2.177397703551552

Epoch: 5| Step: 4
Training loss: 0.21210580053531666
Validation loss: 2.1933515403906485

Epoch: 5| Step: 5
Training loss: 0.1917545302936387
Validation loss: 2.202664169654145

Epoch: 5| Step: 6
Training loss: 0.27940570604949555
Validation loss: 2.2068762632344257

Epoch: 5| Step: 7
Training loss: 0.19965453262295033
Validation loss: 2.2137406778842523

Epoch: 5| Step: 8
Training loss: 0.14073908999102505
Validation loss: 2.2093109185153157

Epoch: 5| Step: 9
Training loss: 0.2277360072003823
Validation loss: 2.203802111330865

Epoch: 5| Step: 10
Training loss: 0.3038341971251896
Validation loss: 2.1998113193314706

Epoch: 509| Step: 0
Training loss: 0.2946456727392908
Validation loss: 2.1798056270072674

Epoch: 5| Step: 1
Training loss: 0.15690335526613866
Validation loss: 2.209675707291336

Epoch: 5| Step: 2
Training loss: 0.3416530851634333
Validation loss: 2.200116445353324

Epoch: 5| Step: 3
Training loss: 0.14651880495441144
Validation loss: 2.2064424630162005

Epoch: 5| Step: 4
Training loss: 0.16046517513939904
Validation loss: 2.205075941621805

Epoch: 5| Step: 5
Training loss: 0.1474403152193004
Validation loss: 2.176134286425619

Epoch: 5| Step: 6
Training loss: 0.17243352544717647
Validation loss: 2.1937476621221004

Epoch: 5| Step: 7
Training loss: 0.15387447702108242
Validation loss: 2.1990193418470407

Epoch: 5| Step: 8
Training loss: 0.14859156393374526
Validation loss: 2.201168422330669

Epoch: 5| Step: 9
Training loss: 0.23432282025912585
Validation loss: 2.195795736975409

Epoch: 5| Step: 10
Training loss: 0.2144874566118659
Validation loss: 2.1593798072148473

Epoch: 510| Step: 0
Training loss: 0.21988352785114398
Validation loss: 2.1683241863495573

Epoch: 5| Step: 1
Training loss: 0.22340208753314425
Validation loss: 2.1684192127770463

Epoch: 5| Step: 2
Training loss: 0.2347331330828267
Validation loss: 2.1917469250535793

Epoch: 5| Step: 3
Training loss: 0.1774825838268782
Validation loss: 2.196795861055113

Epoch: 5| Step: 4
Training loss: 0.17488708365624406
Validation loss: 2.1779867390858394

Epoch: 5| Step: 5
Training loss: 0.35276695134833186
Validation loss: 2.190494570205653

Epoch: 5| Step: 6
Training loss: 0.1702311704403152
Validation loss: 2.1901463988644556

Epoch: 5| Step: 7
Training loss: 0.22342160508499473
Validation loss: 2.2168654185804737

Epoch: 5| Step: 8
Training loss: 0.22368480461129553
Validation loss: 2.215786701648657

Epoch: 5| Step: 9
Training loss: 0.2228572172739661
Validation loss: 2.170576169778097

Epoch: 5| Step: 10
Training loss: 0.1292545929430261
Validation loss: 2.2201289603553986

Epoch: 511| Step: 0
Training loss: 0.20666988792972532
Validation loss: 2.2157785408123685

Epoch: 5| Step: 1
Training loss: 0.16205709257751655
Validation loss: 2.220069059868123

Epoch: 5| Step: 2
Training loss: 0.20023630234307585
Validation loss: 2.21569220430008

Epoch: 5| Step: 3
Training loss: 0.2051451528094402
Validation loss: 2.2037574723054636

Epoch: 5| Step: 4
Training loss: 0.27640875513851054
Validation loss: 2.1972682688342817

Epoch: 5| Step: 5
Training loss: 0.2261676636404254
Validation loss: 2.189659072741396

Epoch: 5| Step: 6
Training loss: 0.14682670012145294
Validation loss: 2.189716739168766

Epoch: 5| Step: 7
Training loss: 0.12653079577699147
Validation loss: 2.181147197427325

Epoch: 5| Step: 8
Training loss: 0.2479282756432854
Validation loss: 2.14880449936018

Epoch: 5| Step: 9
Training loss: 0.3049673360390558
Validation loss: 2.1830869650829694

Epoch: 5| Step: 10
Training loss: 0.095541866838731
Validation loss: 2.162500320132007

Epoch: 512| Step: 0
Training loss: 0.2608227837402496
Validation loss: 2.164298099558136

Epoch: 5| Step: 1
Training loss: 0.20263942119221115
Validation loss: 2.1689389440056246

Epoch: 5| Step: 2
Training loss: 0.16912692567352117
Validation loss: 2.164677293122232

Epoch: 5| Step: 3
Training loss: 0.3356392223747414
Validation loss: 2.1439148841068216

Epoch: 5| Step: 4
Training loss: 0.1571468660701323
Validation loss: 2.174977314620571

Epoch: 5| Step: 5
Training loss: 0.2657149527210113
Validation loss: 2.1981787988664303

Epoch: 5| Step: 6
Training loss: 0.13919926144120348
Validation loss: 2.195483059228354

Epoch: 5| Step: 7
Training loss: 0.18418839718238036
Validation loss: 2.1901814499293852

Epoch: 5| Step: 8
Training loss: 0.1900377397010926
Validation loss: 2.229488628054505

Epoch: 5| Step: 9
Training loss: 0.14714155915753596
Validation loss: 2.1840824520515385

Epoch: 5| Step: 10
Training loss: 0.2167145856417319
Validation loss: 2.2123424565476943

Epoch: 513| Step: 0
Training loss: 0.13943992733947883
Validation loss: 2.197679607665207

Epoch: 5| Step: 1
Training loss: 0.1340458625971328
Validation loss: 2.2185945336519857

Epoch: 5| Step: 2
Training loss: 0.20284168953231801
Validation loss: 2.176928267736658

Epoch: 5| Step: 3
Training loss: 0.12871467197077158
Validation loss: 2.1892328172986892

Epoch: 5| Step: 4
Training loss: 0.22323077515595052
Validation loss: 2.2070081356231

Epoch: 5| Step: 5
Training loss: 0.17655848228474533
Validation loss: 2.193097698165044

Epoch: 5| Step: 6
Training loss: 0.2845266393741472
Validation loss: 2.179103032424179

Epoch: 5| Step: 7
Training loss: 0.16243984823889007
Validation loss: 2.2202215818826945

Epoch: 5| Step: 8
Training loss: 0.1178171013634233
Validation loss: 2.174962667484984

Epoch: 5| Step: 9
Training loss: 0.23958814743982673
Validation loss: 2.1893637925273035

Epoch: 5| Step: 10
Training loss: 0.303579897071221
Validation loss: 2.2092254020615645

Epoch: 514| Step: 0
Training loss: 0.23906630812211133
Validation loss: 2.1958215822659355

Epoch: 5| Step: 1
Training loss: 0.15264753472976741
Validation loss: 2.211949152546915

Epoch: 5| Step: 2
Training loss: 0.27817936055281534
Validation loss: 2.2079959272259324

Epoch: 5| Step: 3
Training loss: 0.282431781959096
Validation loss: 2.1849084037530524

Epoch: 5| Step: 4
Training loss: 0.16308648571904488
Validation loss: 2.2100322613402787

Epoch: 5| Step: 5
Training loss: 0.24034788194923
Validation loss: 2.2195435080962356

Epoch: 5| Step: 6
Training loss: 0.14665000452642502
Validation loss: 2.233925042431381

Epoch: 5| Step: 7
Training loss: 0.2252306596950376
Validation loss: 2.196072221555618

Epoch: 5| Step: 8
Training loss: 0.1876431752969535
Validation loss: 2.1913513699649716

Epoch: 5| Step: 9
Training loss: 0.21213902780774904
Validation loss: 2.2082215629319526

Epoch: 5| Step: 10
Training loss: 0.1712626853389891
Validation loss: 2.235282226712026

Epoch: 515| Step: 0
Training loss: 0.14920953702196996
Validation loss: 2.2164982761440113

Epoch: 5| Step: 1
Training loss: 0.17282960504412515
Validation loss: 2.2144412559580022

Epoch: 5| Step: 2
Training loss: 0.1495882216058168
Validation loss: 2.2438310291646113

Epoch: 5| Step: 3
Training loss: 0.2364138140479974
Validation loss: 2.229701434502789

Epoch: 5| Step: 4
Training loss: 0.2920448230264972
Validation loss: 2.2064657814188884

Epoch: 5| Step: 5
Training loss: 0.25995297953564955
Validation loss: 2.2428054532563277

Epoch: 5| Step: 6
Training loss: 0.19925876290401864
Validation loss: 2.21761519583582

Epoch: 5| Step: 7
Training loss: 0.2794117724563314
Validation loss: 2.1986492240414144

Epoch: 5| Step: 8
Training loss: 0.22323541439057665
Validation loss: 2.174411225038863

Epoch: 5| Step: 9
Training loss: 0.23418119682990068
Validation loss: 2.2284374564331073

Epoch: 5| Step: 10
Training loss: 0.13144322998755165
Validation loss: 2.200268563139199

Epoch: 516| Step: 0
Training loss: 0.307868443164089
Validation loss: 2.21312128600504

Epoch: 5| Step: 1
Training loss: 0.15593689303002883
Validation loss: 2.1817825733457514

Epoch: 5| Step: 2
Training loss: 0.23298424715912655
Validation loss: 2.2017312337535113

Epoch: 5| Step: 3
Training loss: 0.17489141837991246
Validation loss: 2.1785259464941147

Epoch: 5| Step: 4
Training loss: 0.1953596153651381
Validation loss: 2.156496902057464

Epoch: 5| Step: 5
Training loss: 0.22229563639515543
Validation loss: 2.1768618262614554

Epoch: 5| Step: 6
Training loss: 0.14012551345952312
Validation loss: 2.1739454105924976

Epoch: 5| Step: 7
Training loss: 0.30133112891324154
Validation loss: 2.1839751749664056

Epoch: 5| Step: 8
Training loss: 0.22208990045885088
Validation loss: 2.1732244152734674

Epoch: 5| Step: 9
Training loss: 0.24140066337911087
Validation loss: 2.1755260847314357

Epoch: 5| Step: 10
Training loss: 0.13762857970901482
Validation loss: 2.2069696965020547

Epoch: 517| Step: 0
Training loss: 0.22588779021330976
Validation loss: 2.2314265915843863

Epoch: 5| Step: 1
Training loss: 0.16037829637410345
Validation loss: 2.2095476071513676

Epoch: 5| Step: 2
Training loss: 0.21414269594891083
Validation loss: 2.2234772084938856

Epoch: 5| Step: 3
Training loss: 0.1192160586457049
Validation loss: 2.2135110739826365

Epoch: 5| Step: 4
Training loss: 0.16492912761728182
Validation loss: 2.209224575258517

Epoch: 5| Step: 5
Training loss: 0.21464479077116308
Validation loss: 2.2191374973464733

Epoch: 5| Step: 6
Training loss: 0.13490107543313745
Validation loss: 2.2032621211976884

Epoch: 5| Step: 7
Training loss: 0.20078423568346235
Validation loss: 2.215898278271178

Epoch: 5| Step: 8
Training loss: 0.24078694040405427
Validation loss: 2.237817094618518

Epoch: 5| Step: 9
Training loss: 0.20018628728108015
Validation loss: 2.223761495619188

Epoch: 5| Step: 10
Training loss: 0.35002604753776034
Validation loss: 2.2209020054723845

Epoch: 518| Step: 0
Training loss: 0.2720606471506232
Validation loss: 2.225949144032538

Epoch: 5| Step: 1
Training loss: 0.14243428931063687
Validation loss: 2.208423501989228

Epoch: 5| Step: 2
Training loss: 0.16394047513437102
Validation loss: 2.2282514003254543

Epoch: 5| Step: 3
Training loss: 0.1813565873929042
Validation loss: 2.226523151492581

Epoch: 5| Step: 4
Training loss: 0.21948034266419478
Validation loss: 2.214424784256835

Epoch: 5| Step: 5
Training loss: 0.1316169261824488
Validation loss: 2.2043254080609156

Epoch: 5| Step: 6
Training loss: 0.14490253854160814
Validation loss: 2.201982102668434

Epoch: 5| Step: 7
Training loss: 0.15300162415094312
Validation loss: 2.181486688835753

Epoch: 5| Step: 8
Training loss: 0.18832170716588037
Validation loss: 2.1988939372429575

Epoch: 5| Step: 9
Training loss: 0.2423921381949191
Validation loss: 2.1785143646177336

Epoch: 5| Step: 10
Training loss: 0.29233872381280307
Validation loss: 2.192779797847068

Epoch: 519| Step: 0
Training loss: 0.22833085537497505
Validation loss: 2.1689728594505335

Epoch: 5| Step: 1
Training loss: 0.1161932410863016
Validation loss: 2.143769703689624

Epoch: 5| Step: 2
Training loss: 0.2725122738401343
Validation loss: 2.19502680520862

Epoch: 5| Step: 3
Training loss: 0.0938797192377832
Validation loss: 2.177325582963287

Epoch: 5| Step: 4
Training loss: 0.28884348433549517
Validation loss: 2.2065898489078095

Epoch: 5| Step: 5
Training loss: 0.24318004080735428
Validation loss: 2.1882537691638277

Epoch: 5| Step: 6
Training loss: 0.15473957774589098
Validation loss: 2.1676484026219445

Epoch: 5| Step: 7
Training loss: 0.13014077261711302
Validation loss: 2.180678348633977

Epoch: 5| Step: 8
Training loss: 0.1388153220752475
Validation loss: 2.1768538569049594

Epoch: 5| Step: 9
Training loss: 0.19706576203157758
Validation loss: 2.187106491181413

Epoch: 5| Step: 10
Training loss: 0.20893498309425554
Validation loss: 2.207485008946497

Epoch: 520| Step: 0
Training loss: 0.2386706172703945
Validation loss: 2.1767239906749514

Epoch: 5| Step: 1
Training loss: 0.1615187790739747
Validation loss: 2.17575990803349

Epoch: 5| Step: 2
Training loss: 0.15075269067910912
Validation loss: 2.1845131424694952

Epoch: 5| Step: 3
Training loss: 0.16633657398149582
Validation loss: 2.1435513232159864

Epoch: 5| Step: 4
Training loss: 0.14319733497164974
Validation loss: 2.1671537671329264

Epoch: 5| Step: 5
Training loss: 0.1510862512118245
Validation loss: 2.146896761462581

Epoch: 5| Step: 6
Training loss: 0.1960000714866352
Validation loss: 2.144746254349239

Epoch: 5| Step: 7
Training loss: 0.2944304179815839
Validation loss: 2.182532784073696

Epoch: 5| Step: 8
Training loss: 0.32617620362476146
Validation loss: 2.1568332523529667

Epoch: 5| Step: 9
Training loss: 0.13294369865021227
Validation loss: 2.1643331668005703

Epoch: 5| Step: 10
Training loss: 0.16365610606631728
Validation loss: 2.175714849792237

Epoch: 521| Step: 0
Training loss: 0.10261174759315365
Validation loss: 2.153513456675844

Epoch: 5| Step: 1
Training loss: 0.20319978547716175
Validation loss: 2.169584389433201

Epoch: 5| Step: 2
Training loss: 0.3102385832040761
Validation loss: 2.1890394357819445

Epoch: 5| Step: 3
Training loss: 0.21085803866448805
Validation loss: 2.196602116278592

Epoch: 5| Step: 4
Training loss: 0.1528189229980534
Validation loss: 2.206205612066563

Epoch: 5| Step: 5
Training loss: 0.1522368581832241
Validation loss: 2.20757311224728

Epoch: 5| Step: 6
Training loss: 0.2738587812603467
Validation loss: 2.221745974599705

Epoch: 5| Step: 7
Training loss: 0.19505378754656033
Validation loss: 2.2144261526583793

Epoch: 5| Step: 8
Training loss: 0.3127683679277748
Validation loss: 2.2305609870029293

Epoch: 5| Step: 9
Training loss: 0.21021661494160243
Validation loss: 2.1814759993676613

Epoch: 5| Step: 10
Training loss: 0.3763281825253453
Validation loss: 2.198614885446772

Epoch: 522| Step: 0
Training loss: 0.15099829977464616
Validation loss: 2.171222224816524

Epoch: 5| Step: 1
Training loss: 0.34069539926259235
Validation loss: 2.168521059045104

Epoch: 5| Step: 2
Training loss: 0.14665808867865232
Validation loss: 2.1773496267608086

Epoch: 5| Step: 3
Training loss: 0.30480165054976993
Validation loss: 2.1814017369082523

Epoch: 5| Step: 4
Training loss: 0.19374535308925822
Validation loss: 2.1773924888964835

Epoch: 5| Step: 5
Training loss: 0.23315672548636973
Validation loss: 2.221671730630359

Epoch: 5| Step: 6
Training loss: 0.18329797416411428
Validation loss: 2.189414007071199

Epoch: 5| Step: 7
Training loss: 0.36510150961060994
Validation loss: 2.235046175765819

Epoch: 5| Step: 8
Training loss: 0.3711361107992343
Validation loss: 2.2093304464673222

Epoch: 5| Step: 9
Training loss: 0.20992755180891762
Validation loss: 2.213170914023609

Epoch: 5| Step: 10
Training loss: 0.21175442673031733
Validation loss: 2.2163250959839704

Epoch: 523| Step: 0
Training loss: 0.22091391295874416
Validation loss: 2.1916549705543575

Epoch: 5| Step: 1
Training loss: 0.24130119148735657
Validation loss: 2.21031482427087

Epoch: 5| Step: 2
Training loss: 0.26818937944790694
Validation loss: 2.187623146212171

Epoch: 5| Step: 3
Training loss: 0.2123420892949458
Validation loss: 2.2008175239175793

Epoch: 5| Step: 4
Training loss: 0.2715842248635311
Validation loss: 2.1851626799158197

Epoch: 5| Step: 5
Training loss: 0.23833761173995327
Validation loss: 2.1975549373871015

Epoch: 5| Step: 6
Training loss: 0.3560518575399977
Validation loss: 2.1748307068025934

Epoch: 5| Step: 7
Training loss: 0.2767340311346911
Validation loss: 2.200639635871565

Epoch: 5| Step: 8
Training loss: 0.3247314214509239
Validation loss: 2.207722322986959

Epoch: 5| Step: 9
Training loss: 0.2614052588836797
Validation loss: 2.1966698702786767

Epoch: 5| Step: 10
Training loss: 0.1372610304926016
Validation loss: 2.181373130537947

Epoch: 524| Step: 0
Training loss: 0.3833002564250487
Validation loss: 2.233325083109286

Epoch: 5| Step: 1
Training loss: 0.2651564588978652
Validation loss: 2.215746561290406

Epoch: 5| Step: 2
Training loss: 0.20116082874081018
Validation loss: 2.2255362349926977

Epoch: 5| Step: 3
Training loss: 0.2046245190498838
Validation loss: 2.218784851373602

Epoch: 5| Step: 4
Training loss: 0.20584701631281754
Validation loss: 2.2228493344852773

Epoch: 5| Step: 5
Training loss: 0.2258150827738949
Validation loss: 2.213762469537946

Epoch: 5| Step: 6
Training loss: 0.3173704174262305
Validation loss: 2.228526310857663

Epoch: 5| Step: 7
Training loss: 0.20018216531894376
Validation loss: 2.215180554976449

Epoch: 5| Step: 8
Training loss: 0.338981389307086
Validation loss: 2.199690445719788

Epoch: 5| Step: 9
Training loss: 0.2392656831030662
Validation loss: 2.17658369559613

Epoch: 5| Step: 10
Training loss: 0.3854094603440454
Validation loss: 2.2373121837114165

Epoch: 525| Step: 0
Training loss: 0.2692191486942397
Validation loss: 2.202626396711847

Epoch: 5| Step: 1
Training loss: 0.26247379649030167
Validation loss: 2.2230646769674984

Epoch: 5| Step: 2
Training loss: 0.19974684376723606
Validation loss: 2.220640252836885

Epoch: 5| Step: 3
Training loss: 0.2137023255515313
Validation loss: 2.238363946991457

Epoch: 5| Step: 4
Training loss: 0.20568505349409638
Validation loss: 2.263207867220265

Epoch: 5| Step: 5
Training loss: 0.2993449933338558
Validation loss: 2.225097840017514

Epoch: 5| Step: 6
Training loss: 0.29855149373830947
Validation loss: 2.2094060049846025

Epoch: 5| Step: 7
Training loss: 0.21118154360377558
Validation loss: 2.192699809315172

Epoch: 5| Step: 8
Training loss: 0.2641625959526967
Validation loss: 2.1926194811317234

Epoch: 5| Step: 9
Training loss: 0.2876209838939924
Validation loss: 2.2062727542166174

Epoch: 5| Step: 10
Training loss: 0.17822323106646923
Validation loss: 2.230165102330185

Epoch: 526| Step: 0
Training loss: 0.3680855948207636
Validation loss: 2.2193170117899963

Epoch: 5| Step: 1
Training loss: 0.13782766758239906
Validation loss: 2.1933204266750987

Epoch: 5| Step: 2
Training loss: 0.21170993061629326
Validation loss: 2.189286045766873

Epoch: 5| Step: 3
Training loss: 0.2639812914557318
Validation loss: 2.193222352378243

Epoch: 5| Step: 4
Training loss: 0.22609016905969326
Validation loss: 2.2077745747284903

Epoch: 5| Step: 5
Training loss: 0.3468309529149645
Validation loss: 2.212246996832457

Epoch: 5| Step: 6
Training loss: 0.23781613779481267
Validation loss: 2.1948026998590766

Epoch: 5| Step: 7
Training loss: 0.2077914800984114
Validation loss: 2.2044108418877753

Epoch: 5| Step: 8
Training loss: 0.20222451441646758
Validation loss: 2.216961365741107

Epoch: 5| Step: 9
Training loss: 0.2772183067422298
Validation loss: 2.218271427169818

Epoch: 5| Step: 10
Training loss: 0.13992077608172193
Validation loss: 2.2313808875343693

Epoch: 527| Step: 0
Training loss: 0.3235049145235333
Validation loss: 2.2201941783220063

Epoch: 5| Step: 1
Training loss: 0.21699469364892474
Validation loss: 2.198156732013651

Epoch: 5| Step: 2
Training loss: 0.24457068902208937
Validation loss: 2.1708331958395246

Epoch: 5| Step: 3
Training loss: 0.17223932385509208
Validation loss: 2.2013786828689867

Epoch: 5| Step: 4
Training loss: 0.1990632871764951
Validation loss: 2.214624030595786

Epoch: 5| Step: 5
Training loss: 0.1522663971561839
Validation loss: 2.233596418276469

Epoch: 5| Step: 6
Training loss: 0.25413743278311524
Validation loss: 2.2240860055525116

Epoch: 5| Step: 7
Training loss: 0.1701794677846436
Validation loss: 2.2225208451363616

Epoch: 5| Step: 8
Training loss: 0.23174758680253835
Validation loss: 2.196163553938456

Epoch: 5| Step: 9
Training loss: 0.2502586100047009
Validation loss: 2.1907210243224107

Epoch: 5| Step: 10
Training loss: 0.12299709978454546
Validation loss: 2.1626440937821605

Epoch: 528| Step: 0
Training loss: 0.14531509386844435
Validation loss: 2.1585546633837422

Epoch: 5| Step: 1
Training loss: 0.18911201207051798
Validation loss: 2.1573736714715572

Epoch: 5| Step: 2
Training loss: 0.17769241885791268
Validation loss: 2.151837943135622

Epoch: 5| Step: 3
Training loss: 0.20566226780933436
Validation loss: 2.168386655388975

Epoch: 5| Step: 4
Training loss: 0.31185466174469634
Validation loss: 2.134908978858501

Epoch: 5| Step: 5
Training loss: 0.2193477841419463
Validation loss: 2.1549483108383836

Epoch: 5| Step: 6
Training loss: 0.14811401505520774
Validation loss: 2.1504699830084255

Epoch: 5| Step: 7
Training loss: 0.12850316198842965
Validation loss: 2.1846985065946636

Epoch: 5| Step: 8
Training loss: 0.23928471628074502
Validation loss: 2.179440936085091

Epoch: 5| Step: 9
Training loss: 0.1809586262928577
Validation loss: 2.1758254691390166

Epoch: 5| Step: 10
Training loss: 0.2483560407594133
Validation loss: 2.1698796202528974

Epoch: 529| Step: 0
Training loss: 0.14821290291085323
Validation loss: 2.1907578279412867

Epoch: 5| Step: 1
Training loss: 0.25853369727187375
Validation loss: 2.186342320372875

Epoch: 5| Step: 2
Training loss: 0.1642997819622483
Validation loss: 2.1964418643741968

Epoch: 5| Step: 3
Training loss: 0.24337898469297164
Validation loss: 2.186172208797503

Epoch: 5| Step: 4
Training loss: 0.15493774113515146
Validation loss: 2.1853384891288945

Epoch: 5| Step: 5
Training loss: 0.20114512404565857
Validation loss: 2.180008466669707

Epoch: 5| Step: 6
Training loss: 0.22619131528488398
Validation loss: 2.159713831841519

Epoch: 5| Step: 7
Training loss: 0.1560561348343097
Validation loss: 2.213741108681876

Epoch: 5| Step: 8
Training loss: 0.15070890212863525
Validation loss: 2.2013459217662543

Epoch: 5| Step: 9
Training loss: 0.24220487316946004
Validation loss: 2.1730274675931627

Epoch: 5| Step: 10
Training loss: 0.16827175068409428
Validation loss: 2.1770841827445873

Epoch: 530| Step: 0
Training loss: 0.16010300984168424
Validation loss: 2.2082435512653285

Epoch: 5| Step: 1
Training loss: 0.17043062759339483
Validation loss: 2.2091884456939033

Epoch: 5| Step: 2
Training loss: 0.16618420512550947
Validation loss: 2.2334087355500705

Epoch: 5| Step: 3
Training loss: 0.11974907114299828
Validation loss: 2.195547442300761

Epoch: 5| Step: 4
Training loss: 0.1469083943347439
Validation loss: 2.2234410332279753

Epoch: 5| Step: 5
Training loss: 0.21814771742965394
Validation loss: 2.229338087226881

Epoch: 5| Step: 6
Training loss: 0.3167880780260404
Validation loss: 2.224677190422495

Epoch: 5| Step: 7
Training loss: 0.16757183529981207
Validation loss: 2.194846469199183

Epoch: 5| Step: 8
Training loss: 0.11558068093004188
Validation loss: 2.2129907944406164

Epoch: 5| Step: 9
Training loss: 0.14478204206912418
Validation loss: 2.234695894567424

Epoch: 5| Step: 10
Training loss: 0.2732870914408541
Validation loss: 2.20404033254255

Epoch: 531| Step: 0
Training loss: 0.23327260635674038
Validation loss: 2.2053831767899545

Epoch: 5| Step: 1
Training loss: 0.1453566502083326
Validation loss: 2.2082260018298796

Epoch: 5| Step: 2
Training loss: 0.20210639774472708
Validation loss: 2.183367956853401

Epoch: 5| Step: 3
Training loss: 0.11650355147941657
Validation loss: 2.1887782529911233

Epoch: 5| Step: 4
Training loss: 0.19904096936095828
Validation loss: 2.194233763862686

Epoch: 5| Step: 5
Training loss: 0.13671017347410402
Validation loss: 2.176086644124929

Epoch: 5| Step: 6
Training loss: 0.1965877859957013
Validation loss: 2.194254349570114

Epoch: 5| Step: 7
Training loss: 0.2742910007379097
Validation loss: 2.1626236617939045

Epoch: 5| Step: 8
Training loss: 0.27899101155425193
Validation loss: 2.183939489600635

Epoch: 5| Step: 9
Training loss: 0.16140195736526886
Validation loss: 2.1869184761164124

Epoch: 5| Step: 10
Training loss: 0.15903908423236088
Validation loss: 2.199849243163264

Epoch: 532| Step: 0
Training loss: 0.17292897597606655
Validation loss: 2.191337858275697

Epoch: 5| Step: 1
Training loss: 0.17460396500128128
Validation loss: 2.2032582395384837

Epoch: 5| Step: 2
Training loss: 0.08926982631842403
Validation loss: 2.196261239511537

Epoch: 5| Step: 3
Training loss: 0.12370897963058348
Validation loss: 2.1959393708031256

Epoch: 5| Step: 4
Training loss: 0.13665113139341925
Validation loss: 2.2226797887280663

Epoch: 5| Step: 5
Training loss: 0.21854239217009244
Validation loss: 2.2112834530325443

Epoch: 5| Step: 6
Training loss: 0.23322205682327193
Validation loss: 2.221063800029106

Epoch: 5| Step: 7
Training loss: 0.28505876259506363
Validation loss: 2.2234441717078273

Epoch: 5| Step: 8
Training loss: 0.15154067526329493
Validation loss: 2.212948913157003

Epoch: 5| Step: 9
Training loss: 0.1872129726909786
Validation loss: 2.239286156808011

Epoch: 5| Step: 10
Training loss: 0.20027436347153618
Validation loss: 2.218349416581462

Epoch: 533| Step: 0
Training loss: 0.2533498095395547
Validation loss: 2.2116259834170515

Epoch: 5| Step: 1
Training loss: 0.1703642097332212
Validation loss: 2.2104531956411027

Epoch: 5| Step: 2
Training loss: 0.2557231890076236
Validation loss: 2.198664407150619

Epoch: 5| Step: 3
Training loss: 0.178799560335358
Validation loss: 2.2148629455897852

Epoch: 5| Step: 4
Training loss: 0.15919103172459814
Validation loss: 2.16658529912911

Epoch: 5| Step: 5
Training loss: 0.1564902663681199
Validation loss: 2.1824428368594373

Epoch: 5| Step: 6
Training loss: 0.1292554071432574
Validation loss: 2.1609039433822486

Epoch: 5| Step: 7
Training loss: 0.22568191204162513
Validation loss: 2.2027021689017334

Epoch: 5| Step: 8
Training loss: 0.10182568945934603
Validation loss: 2.193197185399012

Epoch: 5| Step: 9
Training loss: 0.13961334054242866
Validation loss: 2.156965465481211

Epoch: 5| Step: 10
Training loss: 0.12571055398045325
Validation loss: 2.137494643825385

Epoch: 534| Step: 0
Training loss: 0.08177717063070977
Validation loss: 2.1747909881348786

Epoch: 5| Step: 1
Training loss: 0.1326793816958328
Validation loss: 2.184262001903007

Epoch: 5| Step: 2
Training loss: 0.25181562530839113
Validation loss: 2.155373555537928

Epoch: 5| Step: 3
Training loss: 0.1083794053011727
Validation loss: 2.1783755538269265

Epoch: 5| Step: 4
Training loss: 0.12837460006764861
Validation loss: 2.1603529352006525

Epoch: 5| Step: 5
Training loss: 0.2580720721839512
Validation loss: 2.1660280163966967

Epoch: 5| Step: 6
Training loss: 0.23585101115006152
Validation loss: 2.1838564024565676

Epoch: 5| Step: 7
Training loss: 0.18598795214339817
Validation loss: 2.174365914539295

Epoch: 5| Step: 8
Training loss: 0.13374471973754123
Validation loss: 2.1650026846124955

Epoch: 5| Step: 9
Training loss: 0.16308964936378062
Validation loss: 2.1770253005675597

Epoch: 5| Step: 10
Training loss: 0.10892452131188723
Validation loss: 2.181231526947331

Epoch: 535| Step: 0
Training loss: 0.15724100319077156
Validation loss: 2.1690270445791158

Epoch: 5| Step: 1
Training loss: 0.24436592387640382
Validation loss: 2.1654814871729795

Epoch: 5| Step: 2
Training loss: 0.1251236557278558
Validation loss: 2.1901491229878123

Epoch: 5| Step: 3
Training loss: 0.25250197667113006
Validation loss: 2.190008732433724

Epoch: 5| Step: 4
Training loss: 0.16900261695411467
Validation loss: 2.1697497377252377

Epoch: 5| Step: 5
Training loss: 0.12903446987658856
Validation loss: 2.1924723587186095

Epoch: 5| Step: 6
Training loss: 0.19842853150413434
Validation loss: 2.1852193020922432

Epoch: 5| Step: 7
Training loss: 0.2069207292332189
Validation loss: 2.1987403403622894

Epoch: 5| Step: 8
Training loss: 0.10492658784895083
Validation loss: 2.1921799413554974

Epoch: 5| Step: 9
Training loss: 0.13987686574951214
Validation loss: 2.2022535005039816

Epoch: 5| Step: 10
Training loss: 0.14591221010294855
Validation loss: 2.207974316100622

Epoch: 536| Step: 0
Training loss: 0.2253518066166881
Validation loss: 2.2205021398993012

Epoch: 5| Step: 1
Training loss: 0.20115438403783753
Validation loss: 2.2313785925990532

Epoch: 5| Step: 2
Training loss: 0.23626563136548112
Validation loss: 2.2109163107110823

Epoch: 5| Step: 3
Training loss: 0.10764171473150431
Validation loss: 2.1809128949502314

Epoch: 5| Step: 4
Training loss: 0.14743167384725211
Validation loss: 2.1791614220025775

Epoch: 5| Step: 5
Training loss: 0.14990915289209902
Validation loss: 2.1975092154216815

Epoch: 5| Step: 6
Training loss: 0.18011584228264782
Validation loss: 2.190270942765429

Epoch: 5| Step: 7
Training loss: 0.15461133348478426
Validation loss: 2.1888208728810095

Epoch: 5| Step: 8
Training loss: 0.24439631233794906
Validation loss: 2.1755621623365036

Epoch: 5| Step: 9
Training loss: 0.22197845256737697
Validation loss: 2.183504260873215

Epoch: 5| Step: 10
Training loss: 0.24176583190970258
Validation loss: 2.193441006154239

Epoch: 537| Step: 0
Training loss: 0.23711011311449173
Validation loss: 2.187059422555417

Epoch: 5| Step: 1
Training loss: 0.15267403574152288
Validation loss: 2.1921002946467643

Epoch: 5| Step: 2
Training loss: 0.136344738688481
Validation loss: 2.2033521962274873

Epoch: 5| Step: 3
Training loss: 0.16121903626767212
Validation loss: 2.205647032944035

Epoch: 5| Step: 4
Training loss: 0.17181604631426795
Validation loss: 2.1965853094805237

Epoch: 5| Step: 5
Training loss: 0.2011475316846343
Validation loss: 2.205806552751621

Epoch: 5| Step: 6
Training loss: 0.12317448009081611
Validation loss: 2.174894642732748

Epoch: 5| Step: 7
Training loss: 0.12580725655712832
Validation loss: 2.2015208339600565

Epoch: 5| Step: 8
Training loss: 0.1443215279103366
Validation loss: 2.2121864384940175

Epoch: 5| Step: 9
Training loss: 0.22294368093716835
Validation loss: 2.2020627529102943

Epoch: 5| Step: 10
Training loss: 0.2597468089696146
Validation loss: 2.1928198611652583

Epoch: 538| Step: 0
Training loss: 0.15080141342815157
Validation loss: 2.1944677019070196

Epoch: 5| Step: 1
Training loss: 0.1844069146159041
Validation loss: 2.140925485197652

Epoch: 5| Step: 2
Training loss: 0.23932220215356959
Validation loss: 2.15622740239255

Epoch: 5| Step: 3
Training loss: 0.0946455687900129
Validation loss: 2.137820736146093

Epoch: 5| Step: 4
Training loss: 0.17018112049901313
Validation loss: 2.1564071661008875

Epoch: 5| Step: 5
Training loss: 0.19027872214891234
Validation loss: 2.14491868549738

Epoch: 5| Step: 6
Training loss: 0.2672597982512434
Validation loss: 2.156875260508543

Epoch: 5| Step: 7
Training loss: 0.13234627458941012
Validation loss: 2.140014944744091

Epoch: 5| Step: 8
Training loss: 0.2279210138836182
Validation loss: 2.1353612532930453

Epoch: 5| Step: 9
Training loss: 0.15490406414919272
Validation loss: 2.146771935846931

Epoch: 5| Step: 10
Training loss: 0.1455092078020415
Validation loss: 2.1772391872923236

Epoch: 539| Step: 0
Training loss: 0.1343794763728784
Validation loss: 2.1642846647626515

Epoch: 5| Step: 1
Training loss: 0.1338112944905457
Validation loss: 2.1486379568304423

Epoch: 5| Step: 2
Training loss: 0.15846863001602798
Validation loss: 2.1868741583161295

Epoch: 5| Step: 3
Training loss: 0.07157668461939826
Validation loss: 2.17122130325174

Epoch: 5| Step: 4
Training loss: 0.1531370245824877
Validation loss: 2.181548192803408

Epoch: 5| Step: 5
Training loss: 0.14494169439018054
Validation loss: 2.1779237131923135

Epoch: 5| Step: 6
Training loss: 0.1582814364229782
Validation loss: 2.175881979653764

Epoch: 5| Step: 7
Training loss: 0.19275374886903204
Validation loss: 2.2122759317228673

Epoch: 5| Step: 8
Training loss: 0.24769398976327595
Validation loss: 2.1656739794274316

Epoch: 5| Step: 9
Training loss: 0.24562340399779312
Validation loss: 2.1802355196132135

Epoch: 5| Step: 10
Training loss: 0.14889699939201625
Validation loss: 2.1710623230446093

Epoch: 540| Step: 0
Training loss: 0.12646806926369705
Validation loss: 2.191535653859799

Epoch: 5| Step: 1
Training loss: 0.14081643240737746
Validation loss: 2.172902140934906

Epoch: 5| Step: 2
Training loss: 0.2357657811858753
Validation loss: 2.1837689917175545

Epoch: 5| Step: 3
Training loss: 0.24916412269022936
Validation loss: 2.1768718800688682

Epoch: 5| Step: 4
Training loss: 0.16266370125046106
Validation loss: 2.1750969772810036

Epoch: 5| Step: 5
Training loss: 0.15533246411896737
Validation loss: 2.2040197347151604

Epoch: 5| Step: 6
Training loss: 0.21221068054797093
Validation loss: 2.1960926435254917

Epoch: 5| Step: 7
Training loss: 0.13084947491674565
Validation loss: 2.1879973624026197

Epoch: 5| Step: 8
Training loss: 0.11977250180840966
Validation loss: 2.200250188663324

Epoch: 5| Step: 9
Training loss: 0.2029182225238859
Validation loss: 2.1799122084444162

Epoch: 5| Step: 10
Training loss: 0.1008478476912657
Validation loss: 2.180944425470161

Epoch: 541| Step: 0
Training loss: 0.22787636408551892
Validation loss: 2.1994100397253216

Epoch: 5| Step: 1
Training loss: 0.14316068153500439
Validation loss: 2.1807133899423494

Epoch: 5| Step: 2
Training loss: 0.10925431064180485
Validation loss: 2.1889817113996104

Epoch: 5| Step: 3
Training loss: 0.23012670091614804
Validation loss: 2.141099015494715

Epoch: 5| Step: 4
Training loss: 0.15690563453716194
Validation loss: 2.166251784336225

Epoch: 5| Step: 5
Training loss: 0.10313088967381899
Validation loss: 2.160880177804066

Epoch: 5| Step: 6
Training loss: 0.24416219234571182
Validation loss: 2.178011781084485

Epoch: 5| Step: 7
Training loss: 0.20620196173171337
Validation loss: 2.198829758255903

Epoch: 5| Step: 8
Training loss: 0.1397823145514788
Validation loss: 2.1698465377500753

Epoch: 5| Step: 9
Training loss: 0.1299711085043841
Validation loss: 2.178753661072724

Epoch: 5| Step: 10
Training loss: 0.12381714838396878
Validation loss: 2.188442855598593

Epoch: 542| Step: 0
Training loss: 0.16842687585691177
Validation loss: 2.2057577736839202

Epoch: 5| Step: 1
Training loss: 0.19894988485610038
Validation loss: 2.2229905254765536

Epoch: 5| Step: 2
Training loss: 0.13569813981065562
Validation loss: 2.2080311045025187

Epoch: 5| Step: 3
Training loss: 0.1411763218705508
Validation loss: 2.1849888083370153

Epoch: 5| Step: 4
Training loss: 0.13319099712255847
Validation loss: 2.195338689923524

Epoch: 5| Step: 5
Training loss: 0.11156802096316476
Validation loss: 2.177492001999183

Epoch: 5| Step: 6
Training loss: 0.16157334535710063
Validation loss: 2.17965997760951

Epoch: 5| Step: 7
Training loss: 0.2077944919843372
Validation loss: 2.215391468491863

Epoch: 5| Step: 8
Training loss: 0.15104220790327594
Validation loss: 2.192724841119561

Epoch: 5| Step: 9
Training loss: 0.1419266684698172
Validation loss: 2.184093782557327

Epoch: 5| Step: 10
Training loss: 0.24105381964399195
Validation loss: 2.194688178269223

Epoch: 543| Step: 0
Training loss: 0.1303704936838806
Validation loss: 2.1610961618544446

Epoch: 5| Step: 1
Training loss: 0.17413323125292984
Validation loss: 2.2031153033806854

Epoch: 5| Step: 2
Training loss: 0.26046216408333095
Validation loss: 2.2029750915227857

Epoch: 5| Step: 3
Training loss: 0.2149104794996746
Validation loss: 2.186786686492042

Epoch: 5| Step: 4
Training loss: 0.11524589529480368
Validation loss: 2.181497380601815

Epoch: 5| Step: 5
Training loss: 0.12814899749019545
Validation loss: 2.164312068186371

Epoch: 5| Step: 6
Training loss: 0.15395569805742737
Validation loss: 2.153638404602943

Epoch: 5| Step: 7
Training loss: 0.18080329684753021
Validation loss: 2.1879571562961755

Epoch: 5| Step: 8
Training loss: 0.12005307649862222
Validation loss: 2.187675535246509

Epoch: 5| Step: 9
Training loss: 0.08638204933689136
Validation loss: 2.1633429652884977

Epoch: 5| Step: 10
Training loss: 0.18554701554142497
Validation loss: 2.1960645985811817

Epoch: 544| Step: 0
Training loss: 0.1452732948513823
Validation loss: 2.2046652153086987

Epoch: 5| Step: 1
Training loss: 0.27727834172025784
Validation loss: 2.17222133993277

Epoch: 5| Step: 2
Training loss: 0.13209722552161735
Validation loss: 2.18238676428185

Epoch: 5| Step: 3
Training loss: 0.19085203432261147
Validation loss: 2.1902701199267245

Epoch: 5| Step: 4
Training loss: 0.0935036631592681
Validation loss: 2.1930137083353114

Epoch: 5| Step: 5
Training loss: 0.19622348999662817
Validation loss: 2.187218773690987

Epoch: 5| Step: 6
Training loss: 0.14307907360879313
Validation loss: 2.194762598563165

Epoch: 5| Step: 7
Training loss: 0.08106254631458804
Validation loss: 2.190090575683332

Epoch: 5| Step: 8
Training loss: 0.16495559771361876
Validation loss: 2.175789975013529

Epoch: 5| Step: 9
Training loss: 0.24515291538730175
Validation loss: 2.2018541417398034

Epoch: 5| Step: 10
Training loss: 0.08710348190593342
Validation loss: 2.2011955689354803

Epoch: 545| Step: 0
Training loss: 0.14954752975940702
Validation loss: 2.212996052062669

Epoch: 5| Step: 1
Training loss: 0.16221039852939637
Validation loss: 2.2166943106668917

Epoch: 5| Step: 2
Training loss: 0.13495452054083829
Validation loss: 2.1867300972803876

Epoch: 5| Step: 3
Training loss: 0.14800790057326935
Validation loss: 2.231866322159827

Epoch: 5| Step: 4
Training loss: 0.16834459284169023
Validation loss: 2.2164858123990774

Epoch: 5| Step: 5
Training loss: 0.19047400130120118
Validation loss: 2.2245470891936083

Epoch: 5| Step: 6
Training loss: 0.23286142379237246
Validation loss: 2.2143161383477596

Epoch: 5| Step: 7
Training loss: 0.2893981917503073
Validation loss: 2.246959234686198

Epoch: 5| Step: 8
Training loss: 0.1719295079323105
Validation loss: 2.23223151177115

Epoch: 5| Step: 9
Training loss: 0.24471482464162184
Validation loss: 2.2306049741296476

Epoch: 5| Step: 10
Training loss: 0.2216419994565765
Validation loss: 2.191857387936618

Epoch: 546| Step: 0
Training loss: 0.16454040087097654
Validation loss: 2.188888135148915

Epoch: 5| Step: 1
Training loss: 0.2080160327415393
Validation loss: 2.2197760754691576

Epoch: 5| Step: 2
Training loss: 0.2079131578163369
Validation loss: 2.2181794765999387

Epoch: 5| Step: 3
Training loss: 0.21769545317761146
Validation loss: 2.177910397761959

Epoch: 5| Step: 4
Training loss: 0.26771895329429946
Validation loss: 2.192800502132393

Epoch: 5| Step: 5
Training loss: 0.1771070076507001
Validation loss: 2.1858766582575946

Epoch: 5| Step: 6
Training loss: 0.15164981421133195
Validation loss: 2.172932996635326

Epoch: 5| Step: 7
Training loss: 0.199311496612473
Validation loss: 2.184955387305344

Epoch: 5| Step: 8
Training loss: 0.15919143539794253
Validation loss: 2.1654344220553

Epoch: 5| Step: 9
Training loss: 0.14719614671712
Validation loss: 2.170766483074549

Epoch: 5| Step: 10
Training loss: 0.16270257239841823
Validation loss: 2.1485505606248227

Epoch: 547| Step: 0
Training loss: 0.2940483419636238
Validation loss: 2.1588214588917336

Epoch: 5| Step: 1
Training loss: 0.27046142621099356
Validation loss: 2.1581753206093004

Epoch: 5| Step: 2
Training loss: 0.10791974435042093
Validation loss: 2.139819015100414

Epoch: 5| Step: 3
Training loss: 0.1389264603963829
Validation loss: 2.172047501154989

Epoch: 5| Step: 4
Training loss: 0.2346653570251288
Validation loss: 2.1846440436232637

Epoch: 5| Step: 5
Training loss: 0.17880426898520133
Validation loss: 2.175960608272164

Epoch: 5| Step: 6
Training loss: 0.2310938520605392
Validation loss: 2.1491900861900346

Epoch: 5| Step: 7
Training loss: 0.1685972045194514
Validation loss: 2.174970680900117

Epoch: 5| Step: 8
Training loss: 0.11850287202229805
Validation loss: 2.178974845035722

Epoch: 5| Step: 9
Training loss: 0.20882393569825777
Validation loss: 2.1703148844790507

Epoch: 5| Step: 10
Training loss: 0.2548221208946973
Validation loss: 2.1558787112568085

Epoch: 548| Step: 0
Training loss: 0.28703469323681996
Validation loss: 2.176170419918505

Epoch: 5| Step: 1
Training loss: 0.2013334810331284
Validation loss: 2.169574184873884

Epoch: 5| Step: 2
Training loss: 0.18860244500217754
Validation loss: 2.2168766115987153

Epoch: 5| Step: 3
Training loss: 0.20372190253938438
Validation loss: 2.200763363745328

Epoch: 5| Step: 4
Training loss: 0.24084780459556648
Validation loss: 2.227381575624316

Epoch: 5| Step: 5
Training loss: 0.1720731795610115
Validation loss: 2.253851922130217

Epoch: 5| Step: 6
Training loss: 0.1473991441411012
Validation loss: 2.22810818083163

Epoch: 5| Step: 7
Training loss: 0.12292306590057976
Validation loss: 2.227018464569945

Epoch: 5| Step: 8
Training loss: 0.1706642180739183
Validation loss: 2.2191396102829164

Epoch: 5| Step: 9
Training loss: 0.1878882798585841
Validation loss: 2.2366592149955906

Epoch: 5| Step: 10
Training loss: 0.17813559718147318
Validation loss: 2.243043952990706

Epoch: 549| Step: 0
Training loss: 0.23356739616366093
Validation loss: 2.2496347085263753

Epoch: 5| Step: 1
Training loss: 0.1964048641856974
Validation loss: 2.22632851931914

Epoch: 5| Step: 2
Training loss: 0.18419542538665756
Validation loss: 2.246275801447818

Epoch: 5| Step: 3
Training loss: 0.2905790395183339
Validation loss: 2.2321524233107666

Epoch: 5| Step: 4
Training loss: 0.17558694803118977
Validation loss: 2.225017556940089

Epoch: 5| Step: 5
Training loss: 0.15327790153610166
Validation loss: 2.209947994908192

Epoch: 5| Step: 6
Training loss: 0.1299782452583009
Validation loss: 2.195490309395171

Epoch: 5| Step: 7
Training loss: 0.13911024838340183
Validation loss: 2.2178024517166692

Epoch: 5| Step: 8
Training loss: 0.14720993911687227
Validation loss: 2.180580448472899

Epoch: 5| Step: 9
Training loss: 0.16231745842956696
Validation loss: 2.188068605464304

Epoch: 5| Step: 10
Training loss: 0.291869364138804
Validation loss: 2.1702081358878407

Epoch: 550| Step: 0
Training loss: 0.3279891300457346
Validation loss: 2.1690241843038396

Epoch: 5| Step: 1
Training loss: 0.12003510857502658
Validation loss: 2.166847008124807

Epoch: 5| Step: 2
Training loss: 0.14674886984406202
Validation loss: 2.165855997540651

Epoch: 5| Step: 3
Training loss: 0.16648784123665067
Validation loss: 2.182633930957028

Epoch: 5| Step: 4
Training loss: 0.18745366159680096
Validation loss: 2.144040678975723

Epoch: 5| Step: 5
Training loss: 0.19965357169854986
Validation loss: 2.1628700324336103

Epoch: 5| Step: 6
Training loss: 0.14479159414051718
Validation loss: 2.1800453338366825

Epoch: 5| Step: 7
Training loss: 0.12031180811967943
Validation loss: 2.170071125200353

Epoch: 5| Step: 8
Training loss: 0.15448579208312083
Validation loss: 2.11836880239641

Epoch: 5| Step: 9
Training loss: 0.20602885983847008
Validation loss: 2.148609364068797

Epoch: 5| Step: 10
Training loss: 0.2137485593195098
Validation loss: 2.1670918848050413

Epoch: 551| Step: 0
Training loss: 0.1883380558855139
Validation loss: 2.161104680432861

Epoch: 5| Step: 1
Training loss: 0.1973111883741543
Validation loss: 2.1583046186171972

Epoch: 5| Step: 2
Training loss: 0.12692708702097832
Validation loss: 2.1581199780317872

Epoch: 5| Step: 3
Training loss: 0.15684660023776567
Validation loss: 2.15551644869887

Epoch: 5| Step: 4
Training loss: 0.22629619436353296
Validation loss: 2.1380552168423765

Epoch: 5| Step: 5
Training loss: 0.2440908991718363
Validation loss: 2.159146565129524

Epoch: 5| Step: 6
Training loss: 0.13658570219081942
Validation loss: 2.154465515808784

Epoch: 5| Step: 7
Training loss: 0.2723452688274392
Validation loss: 2.135149055437828

Epoch: 5| Step: 8
Training loss: 0.17075844616826266
Validation loss: 2.131485428312442

Epoch: 5| Step: 9
Training loss: 0.12333256616211506
Validation loss: 2.1508957573192165

Epoch: 5| Step: 10
Training loss: 0.19691511683984872
Validation loss: 2.1839679528948044

Epoch: 552| Step: 0
Training loss: 0.1121839205694185
Validation loss: 2.1719142213556855

Epoch: 5| Step: 1
Training loss: 0.11215421298364878
Validation loss: 2.1844441728798962

Epoch: 5| Step: 2
Training loss: 0.0683689825935864
Validation loss: 2.190576128474266

Epoch: 5| Step: 3
Training loss: 0.22695982557112812
Validation loss: 2.1635113263700867

Epoch: 5| Step: 4
Training loss: 0.20303267434788835
Validation loss: 2.188951895888845

Epoch: 5| Step: 5
Training loss: 0.2130059621014542
Validation loss: 2.172903272385183

Epoch: 5| Step: 6
Training loss: 0.10918479798286694
Validation loss: 2.1773074544581874

Epoch: 5| Step: 7
Training loss: 0.14737935367249286
Validation loss: 2.187277828014965

Epoch: 5| Step: 8
Training loss: 0.2589560923373254
Validation loss: 2.1803038004384865

Epoch: 5| Step: 9
Training loss: 0.12943873819903742
Validation loss: 2.1508121198662096

Epoch: 5| Step: 10
Training loss: 0.25285335257851416
Validation loss: 2.1967043472286947

Epoch: 553| Step: 0
Training loss: 0.22064317885007448
Validation loss: 2.1925380976741913

Epoch: 5| Step: 1
Training loss: 0.11202530317071824
Validation loss: 2.1989516007805854

Epoch: 5| Step: 2
Training loss: 0.19700503369256595
Validation loss: 2.211646166715402

Epoch: 5| Step: 3
Training loss: 0.2029138531349479
Validation loss: 2.190774063921248

Epoch: 5| Step: 4
Training loss: 0.1129872024471443
Validation loss: 2.213891436879021

Epoch: 5| Step: 5
Training loss: 0.17833827200925897
Validation loss: 2.1860130764642816

Epoch: 5| Step: 6
Training loss: 0.09963804655132152
Validation loss: 2.1884625311018584

Epoch: 5| Step: 7
Training loss: 0.13478416508839608
Validation loss: 2.1756330360724

Epoch: 5| Step: 8
Training loss: 0.21820456761457951
Validation loss: 2.152731077508264

Epoch: 5| Step: 9
Training loss: 0.11245506419022679
Validation loss: 2.1746037933395805

Epoch: 5| Step: 10
Training loss: 0.20653286812255622
Validation loss: 2.1785955764914613

Epoch: 554| Step: 0
Training loss: 0.13250449171865
Validation loss: 2.1780162597758643

Epoch: 5| Step: 1
Training loss: 0.2157769914879473
Validation loss: 2.1668499913605355

Epoch: 5| Step: 2
Training loss: 0.22853097293533897
Validation loss: 2.1678877384031052

Epoch: 5| Step: 3
Training loss: 0.10412675470416949
Validation loss: 2.173689203651474

Epoch: 5| Step: 4
Training loss: 0.13343154166942575
Validation loss: 2.1673768629153325

Epoch: 5| Step: 5
Training loss: 0.19301248510402783
Validation loss: 2.1922718884523893

Epoch: 5| Step: 6
Training loss: 0.17819169703143192
Validation loss: 2.176877966268247

Epoch: 5| Step: 7
Training loss: 0.08733269244439959
Validation loss: 2.1840657009184596

Epoch: 5| Step: 8
Training loss: 0.18485212257106617
Validation loss: 2.1798880797176663

Epoch: 5| Step: 9
Training loss: 0.1379855931176116
Validation loss: 2.1771249305443567

Epoch: 5| Step: 10
Training loss: 0.16238828014375487
Validation loss: 2.157271089477136

Epoch: 555| Step: 0
Training loss: 0.15551366157330965
Validation loss: 2.1799025414621096

Epoch: 5| Step: 1
Training loss: 0.1339365223102603
Validation loss: 2.1712090424474253

Epoch: 5| Step: 2
Training loss: 0.2770734598198041
Validation loss: 2.1972915655904157

Epoch: 5| Step: 3
Training loss: 0.2059526868988742
Validation loss: 2.1724135317776647

Epoch: 5| Step: 4
Training loss: 0.09471909995031699
Validation loss: 2.1776406921575413

Epoch: 5| Step: 5
Training loss: 0.1297983884703647
Validation loss: 2.1552145744106523

Epoch: 5| Step: 6
Training loss: 0.17798260761261217
Validation loss: 2.1784950888121344

Epoch: 5| Step: 7
Training loss: 0.18197972423866185
Validation loss: 2.18158895887258

Epoch: 5| Step: 8
Training loss: 0.1432868899001872
Validation loss: 2.174147047725493

Epoch: 5| Step: 9
Training loss: 0.17971144392286054
Validation loss: 2.1551340005270943

Epoch: 5| Step: 10
Training loss: 0.13044313162137583
Validation loss: 2.1702770331162995

Epoch: 556| Step: 0
Training loss: 0.1318214832435464
Validation loss: 2.1768243498936135

Epoch: 5| Step: 1
Training loss: 0.17318000408568213
Validation loss: 2.145346717683178

Epoch: 5| Step: 2
Training loss: 0.17049593255953993
Validation loss: 2.155534534907218

Epoch: 5| Step: 3
Training loss: 0.1970082010284319
Validation loss: 2.1747381425396815

Epoch: 5| Step: 4
Training loss: 0.12569330588446243
Validation loss: 2.154327671118481

Epoch: 5| Step: 5
Training loss: 0.2269001122440348
Validation loss: 2.2170596780598157

Epoch: 5| Step: 6
Training loss: 0.20194053094136524
Validation loss: 2.1910742475544693

Epoch: 5| Step: 7
Training loss: 0.11791918341679886
Validation loss: 2.2028735781075945

Epoch: 5| Step: 8
Training loss: 0.11590424306154821
Validation loss: 2.1794652703162654

Epoch: 5| Step: 9
Training loss: 0.11831954310996018
Validation loss: 2.2141451680449067

Epoch: 5| Step: 10
Training loss: 0.18715950726324182
Validation loss: 2.171210776958712

Epoch: 557| Step: 0
Training loss: 0.19962029100643397
Validation loss: 2.198065851589095

Epoch: 5| Step: 1
Training loss: 0.12507113280519672
Validation loss: 2.199813517258075

Epoch: 5| Step: 2
Training loss: 0.16206826987258496
Validation loss: 2.2106019568470203

Epoch: 5| Step: 3
Training loss: 0.20701912178646728
Validation loss: 2.1907096941564315

Epoch: 5| Step: 4
Training loss: 0.19565098995101599
Validation loss: 2.1960566965756154

Epoch: 5| Step: 5
Training loss: 0.09933621688155451
Validation loss: 2.158697762816881

Epoch: 5| Step: 6
Training loss: 0.10034777862465337
Validation loss: 2.189943773875165

Epoch: 5| Step: 7
Training loss: 0.22284615098031327
Validation loss: 2.1813006034049427

Epoch: 5| Step: 8
Training loss: 0.11728572702388063
Validation loss: 2.1740121219139064

Epoch: 5| Step: 9
Training loss: 0.15417305287674463
Validation loss: 2.156588381146353

Epoch: 5| Step: 10
Training loss: 0.26181678928459634
Validation loss: 2.17577995037649

Epoch: 558| Step: 0
Training loss: 0.16001681328887202
Validation loss: 2.164348935917808

Epoch: 5| Step: 1
Training loss: 0.22860802306687442
Validation loss: 2.153351274973294

Epoch: 5| Step: 2
Training loss: 0.15830262316621185
Validation loss: 2.169381518134519

Epoch: 5| Step: 3
Training loss: 0.1622564728478754
Validation loss: 2.137973236345166

Epoch: 5| Step: 4
Training loss: 0.10617967146794131
Validation loss: 2.1708640372525676

Epoch: 5| Step: 5
Training loss: 0.22199817918554854
Validation loss: 2.1712761914640497

Epoch: 5| Step: 6
Training loss: 0.1224613373733149
Validation loss: 2.17080786081904

Epoch: 5| Step: 7
Training loss: 0.20097597083179808
Validation loss: 2.171953924466485

Epoch: 5| Step: 8
Training loss: 0.26085756013918115
Validation loss: 2.181487446827049

Epoch: 5| Step: 9
Training loss: 0.21743106015288738
Validation loss: 2.2009808641931476

Epoch: 5| Step: 10
Training loss: 0.17432296163590483
Validation loss: 2.1863423746042625

Epoch: 559| Step: 0
Training loss: 0.26916926028170307
Validation loss: 2.197293081752362

Epoch: 5| Step: 1
Training loss: 0.2293960207472213
Validation loss: 2.1941360931804486

Epoch: 5| Step: 2
Training loss: 0.170191260809012
Validation loss: 2.178210634347896

Epoch: 5| Step: 3
Training loss: 0.1880661047821053
Validation loss: 2.221927951057002

Epoch: 5| Step: 4
Training loss: 0.12793420827317972
Validation loss: 2.220016018928781

Epoch: 5| Step: 5
Training loss: 0.16251069111684002
Validation loss: 2.222614949356634

Epoch: 5| Step: 6
Training loss: 0.17611470912639227
Validation loss: 2.205333938771445

Epoch: 5| Step: 7
Training loss: 0.1835424574767478
Validation loss: 2.228856892568327

Epoch: 5| Step: 8
Training loss: 0.13510979366667752
Validation loss: 2.2490332564960402

Epoch: 5| Step: 9
Training loss: 0.2605718563520071
Validation loss: 2.226727909376745

Epoch: 5| Step: 10
Training loss: 0.18144483165862035
Validation loss: 2.2224662534184914

Epoch: 560| Step: 0
Training loss: 0.12775583320287673
Validation loss: 2.2478551793851005

Epoch: 5| Step: 1
Training loss: 0.2611639062805174
Validation loss: 2.25462473086794

Epoch: 5| Step: 2
Training loss: 0.13414933084753963
Validation loss: 2.231977404508314

Epoch: 5| Step: 3
Training loss: 0.1990721106791788
Validation loss: 2.2483718409258815

Epoch: 5| Step: 4
Training loss: 0.1665857622853863
Validation loss: 2.2473968934385895

Epoch: 5| Step: 5
Training loss: 0.2008314307473577
Validation loss: 2.2427264270449148

Epoch: 5| Step: 6
Training loss: 0.1548070861973245
Validation loss: 2.2446221088990876

Epoch: 5| Step: 7
Training loss: 0.26058126334171416
Validation loss: 2.1983551128897396

Epoch: 5| Step: 8
Training loss: 0.12776307183217867
Validation loss: 2.200944837503817

Epoch: 5| Step: 9
Training loss: 0.22630003821030892
Validation loss: 2.172096613545217

Epoch: 5| Step: 10
Training loss: 0.12671140988183835
Validation loss: 2.1964345788313167

Epoch: 561| Step: 0
Training loss: 0.1824926369795144
Validation loss: 2.1798798873914684

Epoch: 5| Step: 1
Training loss: 0.11793956237621132
Validation loss: 2.187758293665299

Epoch: 5| Step: 2
Training loss: 0.12257293222149064
Validation loss: 2.1959078652956294

Epoch: 5| Step: 3
Training loss: 0.11263793760764379
Validation loss: 2.1594409429950994

Epoch: 5| Step: 4
Training loss: 0.18288205567905313
Validation loss: 2.1702741656290345

Epoch: 5| Step: 5
Training loss: 0.24555458315269713
Validation loss: 2.1868311127450815

Epoch: 5| Step: 6
Training loss: 0.12288542403645547
Validation loss: 2.1799061683495475

Epoch: 5| Step: 7
Training loss: 0.11827703072847187
Validation loss: 2.206050209951257

Epoch: 5| Step: 8
Training loss: 0.20011214412817455
Validation loss: 2.1764530773540285

Epoch: 5| Step: 9
Training loss: 0.23359348813810948
Validation loss: 2.214688248767744

Epoch: 5| Step: 10
Training loss: 0.16646879278984114
Validation loss: 2.207173905847281

Epoch: 562| Step: 0
Training loss: 0.18125579430098748
Validation loss: 2.2281755776783

Epoch: 5| Step: 1
Training loss: 0.07692491164248874
Validation loss: 2.225876815674077

Epoch: 5| Step: 2
Training loss: 0.25230572298826404
Validation loss: 2.2267512116467465

Epoch: 5| Step: 3
Training loss: 0.1837432942172411
Validation loss: 2.2150443139408806

Epoch: 5| Step: 4
Training loss: 0.2249044470413321
Validation loss: 2.2288849148179333

Epoch: 5| Step: 5
Training loss: 0.2002171109124841
Validation loss: 2.2266783331011597

Epoch: 5| Step: 6
Training loss: 0.12495957406323624
Validation loss: 2.25737596287029

Epoch: 5| Step: 7
Training loss: 0.1599611047131383
Validation loss: 2.2383064815936895

Epoch: 5| Step: 8
Training loss: 0.14591860548801353
Validation loss: 2.229410608020372

Epoch: 5| Step: 9
Training loss: 0.2536665151468627
Validation loss: 2.2272683021439734

Epoch: 5| Step: 10
Training loss: 0.13101412035829305
Validation loss: 2.232200077477842

Epoch: 563| Step: 0
Training loss: 0.1499152721583052
Validation loss: 2.2066669465090136

Epoch: 5| Step: 1
Training loss: 0.13658118138757358
Validation loss: 2.203064998501139

Epoch: 5| Step: 2
Training loss: 0.1733407356346718
Validation loss: 2.195266974817227

Epoch: 5| Step: 3
Training loss: 0.13096016233656624
Validation loss: 2.1802662926948266

Epoch: 5| Step: 4
Training loss: 0.3256978113368234
Validation loss: 2.2105915569003827

Epoch: 5| Step: 5
Training loss: 0.15359479182987268
Validation loss: 2.216601989919595

Epoch: 5| Step: 6
Training loss: 0.1802251691248864
Validation loss: 2.204347565513591

Epoch: 5| Step: 7
Training loss: 0.1764663748999299
Validation loss: 2.1914040483205532

Epoch: 5| Step: 8
Training loss: 0.18546823541687152
Validation loss: 2.188345687928555

Epoch: 5| Step: 9
Training loss: 0.11279989196535654
Validation loss: 2.2166708488973867

Epoch: 5| Step: 10
Training loss: 0.16973912068604677
Validation loss: 2.179811628569972

Epoch: 564| Step: 0
Training loss: 0.2161379845278046
Validation loss: 2.180985497275088

Epoch: 5| Step: 1
Training loss: 0.12526078141516903
Validation loss: 2.226046353445002

Epoch: 5| Step: 2
Training loss: 0.1303633926917385
Validation loss: 2.1768837580342844

Epoch: 5| Step: 3
Training loss: 0.20085711993891944
Validation loss: 2.2053361471779693

Epoch: 5| Step: 4
Training loss: 0.2291188144936298
Validation loss: 2.2014279486509283

Epoch: 5| Step: 5
Training loss: 0.1442222191113363
Validation loss: 2.1703108883749294

Epoch: 5| Step: 6
Training loss: 0.1653170417168971
Validation loss: 2.225352893546277

Epoch: 5| Step: 7
Training loss: 0.15613524872399265
Validation loss: 2.206910202042021

Epoch: 5| Step: 8
Training loss: 0.1320182528672757
Validation loss: 2.2138851999932903

Epoch: 5| Step: 9
Training loss: 0.1637408987275135
Validation loss: 2.1930297911338323

Epoch: 5| Step: 10
Training loss: 0.23216603727990212
Validation loss: 2.1995923923328364

Epoch: 565| Step: 0
Training loss: 0.1837522958430415
Validation loss: 2.179832567461231

Epoch: 5| Step: 1
Training loss: 0.13895461312203533
Validation loss: 2.1793938742344685

Epoch: 5| Step: 2
Training loss: 0.17779794541242988
Validation loss: 2.1992576346659707

Epoch: 5| Step: 3
Training loss: 0.08660917974292094
Validation loss: 2.153197273729629

Epoch: 5| Step: 4
Training loss: 0.13643231359201183
Validation loss: 2.1522310768408475

Epoch: 5| Step: 5
Training loss: 0.12179081772673586
Validation loss: 2.1375936684710752

Epoch: 5| Step: 6
Training loss: 0.15519736483772575
Validation loss: 2.1381381525021097

Epoch: 5| Step: 7
Training loss: 0.2672923573871309
Validation loss: 2.1700549345669815

Epoch: 5| Step: 8
Training loss: 0.2825762420498752
Validation loss: 2.1706621037167464

Epoch: 5| Step: 9
Training loss: 0.20882811007230273
Validation loss: 2.1607857585970156

Epoch: 5| Step: 10
Training loss: 0.22861752316704115
Validation loss: 2.152479652348725

Epoch: 566| Step: 0
Training loss: 0.22961922234091786
Validation loss: 2.203398542746863

Epoch: 5| Step: 1
Training loss: 0.16480004761812936
Validation loss: 2.197331235719575

Epoch: 5| Step: 2
Training loss: 0.24759589521794845
Validation loss: 2.2014912761906014

Epoch: 5| Step: 3
Training loss: 0.19539161986929388
Validation loss: 2.2007891984576076

Epoch: 5| Step: 4
Training loss: 0.21024737669094046
Validation loss: 2.227004880914381

Epoch: 5| Step: 5
Training loss: 0.16949605202824355
Validation loss: 2.2227281237696315

Epoch: 5| Step: 6
Training loss: 0.2656337091476733
Validation loss: 2.213189505565327

Epoch: 5| Step: 7
Training loss: 0.15619182695849934
Validation loss: 2.2264320955658863

Epoch: 5| Step: 8
Training loss: 0.24954046542899305
Validation loss: 2.2233992121575707

Epoch: 5| Step: 9
Training loss: 0.11191313528505659
Validation loss: 2.1893672269277955

Epoch: 5| Step: 10
Training loss: 0.16836334055680055
Validation loss: 2.2093927087201894

Epoch: 567| Step: 0
Training loss: 0.27724875582887953
Validation loss: 2.1852851601081404

Epoch: 5| Step: 1
Training loss: 0.18495213408098757
Validation loss: 2.16347866135363

Epoch: 5| Step: 2
Training loss: 0.19818307906783522
Validation loss: 2.1873344241528034

Epoch: 5| Step: 3
Training loss: 0.2645932664408376
Validation loss: 2.2124754109750553

Epoch: 5| Step: 4
Training loss: 0.17238003592607343
Validation loss: 2.207204951461063

Epoch: 5| Step: 5
Training loss: 0.260899242863081
Validation loss: 2.203084679563852

Epoch: 5| Step: 6
Training loss: 0.21268034532918403
Validation loss: 2.18932435888875

Epoch: 5| Step: 7
Training loss: 0.29270495936574886
Validation loss: 2.20077761492676

Epoch: 5| Step: 8
Training loss: 0.24405135239164097
Validation loss: 2.210475998548881

Epoch: 5| Step: 9
Training loss: 0.247118360951205
Validation loss: 2.20303341045267

Epoch: 5| Step: 10
Training loss: 0.1900698073355071
Validation loss: 2.1697385000931724

Epoch: 568| Step: 0
Training loss: 0.19048819010089066
Validation loss: 2.2121140043396417

Epoch: 5| Step: 1
Training loss: 0.22542798511137968
Validation loss: 2.192389452001735

Epoch: 5| Step: 2
Training loss: 0.13411029481666825
Validation loss: 2.196021580227911

Epoch: 5| Step: 3
Training loss: 0.20171186509265018
Validation loss: 2.191682590587568

Epoch: 5| Step: 4
Training loss: 0.12095147665714345
Validation loss: 2.1774260042287277

Epoch: 5| Step: 5
Training loss: 0.26469153584687816
Validation loss: 2.19578224387796

Epoch: 5| Step: 6
Training loss: 0.20116547694726197
Validation loss: 2.204227342492927

Epoch: 5| Step: 7
Training loss: 0.1587547645266873
Validation loss: 2.197919583626076

Epoch: 5| Step: 8
Training loss: 0.1905554527300819
Validation loss: 2.192620911079556

Epoch: 5| Step: 9
Training loss: 0.19064620986573086
Validation loss: 2.1944222065124337

Epoch: 5| Step: 10
Training loss: 0.2734168726088905
Validation loss: 2.1708039128609586

Epoch: 569| Step: 0
Training loss: 0.19903166719291998
Validation loss: 2.1750708599473683

Epoch: 5| Step: 1
Training loss: 0.14553083327301106
Validation loss: 2.2040617786909578

Epoch: 5| Step: 2
Training loss: 0.2245682803168376
Validation loss: 2.164487076906652

Epoch: 5| Step: 3
Training loss: 0.18054242549944832
Validation loss: 2.1986942005567807

Epoch: 5| Step: 4
Training loss: 0.1739241409866978
Validation loss: 2.181889239156972

Epoch: 5| Step: 5
Training loss: 0.21995873794444984
Validation loss: 2.168259583439677

Epoch: 5| Step: 6
Training loss: 0.2361389695746035
Validation loss: 2.172027471582821

Epoch: 5| Step: 7
Training loss: 0.17668234547132367
Validation loss: 2.16776533073234

Epoch: 5| Step: 8
Training loss: 0.2550486467278061
Validation loss: 2.175476234291536

Epoch: 5| Step: 9
Training loss: 0.2074978805916336
Validation loss: 2.1691956588242056

Epoch: 5| Step: 10
Training loss: 0.32535936038239777
Validation loss: 2.180981052304246

Epoch: 570| Step: 0
Training loss: 0.23791922755931388
Validation loss: 2.2047471493685413

Epoch: 5| Step: 1
Training loss: 0.23082746456245168
Validation loss: 2.18221110024558

Epoch: 5| Step: 2
Training loss: 0.1687354840993616
Validation loss: 2.20042135255644

Epoch: 5| Step: 3
Training loss: 0.19282755299919102
Validation loss: 2.2025964725955447

Epoch: 5| Step: 4
Training loss: 0.16965078235879236
Validation loss: 2.2073635631208846

Epoch: 5| Step: 5
Training loss: 0.17696084433048714
Validation loss: 2.208721124131232

Epoch: 5| Step: 6
Training loss: 0.19989808510855014
Validation loss: 2.20233389344521

Epoch: 5| Step: 7
Training loss: 0.18378000753962506
Validation loss: 2.190641944813516

Epoch: 5| Step: 8
Training loss: 0.22321325199705272
Validation loss: 2.1718367216677

Epoch: 5| Step: 9
Training loss: 0.18680920105921914
Validation loss: 2.1672092421778104

Epoch: 5| Step: 10
Training loss: 0.26308801787530195
Validation loss: 2.197622051321207

Epoch: 571| Step: 0
Training loss: 0.17639631641250908
Validation loss: 2.163960255820073

Epoch: 5| Step: 1
Training loss: 0.13049196505018026
Validation loss: 2.1828265977362067

Epoch: 5| Step: 2
Training loss: 0.1403974506690978
Validation loss: 2.181148456828869

Epoch: 5| Step: 3
Training loss: 0.17112413489295128
Validation loss: 2.1665540329485693

Epoch: 5| Step: 4
Training loss: 0.229229626712813
Validation loss: 2.205026255813497

Epoch: 5| Step: 5
Training loss: 0.27569372663209635
Validation loss: 2.2157384752229397

Epoch: 5| Step: 6
Training loss: 0.21502412680053995
Validation loss: 2.1853017857538655

Epoch: 5| Step: 7
Training loss: 0.13386759576214843
Validation loss: 2.1790799394506353

Epoch: 5| Step: 8
Training loss: 0.23793879116881392
Validation loss: 2.1626816534751327

Epoch: 5| Step: 9
Training loss: 0.12116178016743934
Validation loss: 2.166175834806739

Epoch: 5| Step: 10
Training loss: 0.18404939599986042
Validation loss: 2.184101460223944

Epoch: 572| Step: 0
Training loss: 0.16821378754707472
Validation loss: 2.211272605593512

Epoch: 5| Step: 1
Training loss: 0.19119784628890102
Validation loss: 2.1954278922529715

Epoch: 5| Step: 2
Training loss: 0.10210874271270025
Validation loss: 2.177413340377553

Epoch: 5| Step: 3
Training loss: 0.11798149775792127
Validation loss: 2.1754219328612083

Epoch: 5| Step: 4
Training loss: 0.1491481309323814
Validation loss: 2.1768821034137984

Epoch: 5| Step: 5
Training loss: 0.20977443129596854
Validation loss: 2.180021604061374

Epoch: 5| Step: 6
Training loss: 0.1564107663877303
Validation loss: 2.1810971093276317

Epoch: 5| Step: 7
Training loss: 0.16018873559807897
Validation loss: 2.1848046968008044

Epoch: 5| Step: 8
Training loss: 0.1623962174095602
Validation loss: 2.158875123674635

Epoch: 5| Step: 9
Training loss: 0.2408294982272058
Validation loss: 2.190073665654128

Epoch: 5| Step: 10
Training loss: 0.18712927009715166
Validation loss: 2.1904206123350765

Epoch: 573| Step: 0
Training loss: 0.12589440882880223
Validation loss: 2.181491988893406

Epoch: 5| Step: 1
Training loss: 0.16207055121032096
Validation loss: 2.1907393698924382

Epoch: 5| Step: 2
Training loss: 0.16801258557547846
Validation loss: 2.1832743854059458

Epoch: 5| Step: 3
Training loss: 0.18070268991288493
Validation loss: 2.176330451140558

Epoch: 5| Step: 4
Training loss: 0.21794554405693742
Validation loss: 2.1866640102006176

Epoch: 5| Step: 5
Training loss: 0.1857163608858868
Validation loss: 2.1738749317370263

Epoch: 5| Step: 6
Training loss: 0.1167241273417526
Validation loss: 2.2095228610750755

Epoch: 5| Step: 7
Training loss: 0.1637507610448959
Validation loss: 2.205649899193079

Epoch: 5| Step: 8
Training loss: 0.16320538857525987
Validation loss: 2.220412523899278

Epoch: 5| Step: 9
Training loss: 0.18866980731218103
Validation loss: 2.1907773395970933

Epoch: 5| Step: 10
Training loss: 0.1539312327871321
Validation loss: 2.222423133005772

Epoch: 574| Step: 0
Training loss: 0.23508952420285553
Validation loss: 2.209742186260102

Epoch: 5| Step: 1
Training loss: 0.1442084315773689
Validation loss: 2.2181993344503503

Epoch: 5| Step: 2
Training loss: 0.13785765256371002
Validation loss: 2.201931960511568

Epoch: 5| Step: 3
Training loss: 0.22966168414248017
Validation loss: 2.204644243653481

Epoch: 5| Step: 4
Training loss: 0.1699822143321289
Validation loss: 2.2272079847599535

Epoch: 5| Step: 5
Training loss: 0.20282665680848438
Validation loss: 2.2122264800519322

Epoch: 5| Step: 6
Training loss: 0.10149144474744685
Validation loss: 2.203679234046454

Epoch: 5| Step: 7
Training loss: 0.13580590406192347
Validation loss: 2.172930418756432

Epoch: 5| Step: 8
Training loss: 0.21525415755398203
Validation loss: 2.199419180371097

Epoch: 5| Step: 9
Training loss: 0.18408283061453493
Validation loss: 2.1875901796940402

Epoch: 5| Step: 10
Training loss: 0.19101402422462396
Validation loss: 2.1992747485970323

Epoch: 575| Step: 0
Training loss: 0.22228532982016613
Validation loss: 2.163025957208949

Epoch: 5| Step: 1
Training loss: 0.13702589003890336
Validation loss: 2.1790394740979036

Epoch: 5| Step: 2
Training loss: 0.1200509625366697
Validation loss: 2.1963831019655946

Epoch: 5| Step: 3
Training loss: 0.1403354869993085
Validation loss: 2.2152606807307906

Epoch: 5| Step: 4
Training loss: 0.24303385300853017
Validation loss: 2.1647415034730098

Epoch: 5| Step: 5
Training loss: 0.20348885848911585
Validation loss: 2.183483052805326

Epoch: 5| Step: 6
Training loss: 0.20873830694011453
Validation loss: 2.164619530187595

Epoch: 5| Step: 7
Training loss: 0.18178739053323803
Validation loss: 2.166725166972992

Epoch: 5| Step: 8
Training loss: 0.2621540889889653
Validation loss: 2.168907523816967

Epoch: 5| Step: 9
Training loss: 0.10471507837233174
Validation loss: 2.174052336513956

Epoch: 5| Step: 10
Training loss: 0.14319985841229302
Validation loss: 2.1964685044878216

Epoch: 576| Step: 0
Training loss: 0.13538828347542678
Validation loss: 2.1860800217110508

Epoch: 5| Step: 1
Training loss: 0.20328460438428883
Validation loss: 2.1955519132449135

Epoch: 5| Step: 2
Training loss: 0.16977868678985772
Validation loss: 2.2014690055625707

Epoch: 5| Step: 3
Training loss: 0.18237474228812633
Validation loss: 2.186247748166794

Epoch: 5| Step: 4
Training loss: 0.2267478480683808
Validation loss: 2.2014113462447416

Epoch: 5| Step: 5
Training loss: 0.08372929003851094
Validation loss: 2.219957693449413

Epoch: 5| Step: 6
Training loss: 0.22492006623791988
Validation loss: 2.194406340409168

Epoch: 5| Step: 7
Training loss: 0.1834941553294638
Validation loss: 2.1798948595911

Epoch: 5| Step: 8
Training loss: 0.09539107617045813
Validation loss: 2.204972633274026

Epoch: 5| Step: 9
Training loss: 0.18276479946464333
Validation loss: 2.189177249532003

Epoch: 5| Step: 10
Training loss: 0.16536064531237923
Validation loss: 2.1974217422790727

Epoch: 577| Step: 0
Training loss: 0.28236195837522243
Validation loss: 2.2116183694250715

Epoch: 5| Step: 1
Training loss: 0.0968257446202688
Validation loss: 2.184763568891221

Epoch: 5| Step: 2
Training loss: 0.10476705460565076
Validation loss: 2.230675372415023

Epoch: 5| Step: 3
Training loss: 0.09065593692931932
Validation loss: 2.221568114480978

Epoch: 5| Step: 4
Training loss: 0.2647866595465383
Validation loss: 2.1928376046275457

Epoch: 5| Step: 5
Training loss: 0.20623578795683045
Validation loss: 2.1945048074644187

Epoch: 5| Step: 6
Training loss: 0.1785606106393456
Validation loss: 2.2122777070420403

Epoch: 5| Step: 7
Training loss: 0.1825510302978995
Validation loss: 2.1919206775101308

Epoch: 5| Step: 8
Training loss: 0.1400944915311931
Validation loss: 2.2070494205018347

Epoch: 5| Step: 9
Training loss: 0.15946145657832456
Validation loss: 2.1971080042591766

Epoch: 5| Step: 10
Training loss: 0.23103719856326338
Validation loss: 2.228751509515265

Epoch: 578| Step: 0
Training loss: 0.2544387808186306
Validation loss: 2.246425184395947

Epoch: 5| Step: 1
Training loss: 0.2380351531119534
Validation loss: 2.2113310560994663

Epoch: 5| Step: 2
Training loss: 0.2064568901605012
Validation loss: 2.2433383693978937

Epoch: 5| Step: 3
Training loss: 0.12139915592867985
Validation loss: 2.204639656259003

Epoch: 5| Step: 4
Training loss: 0.14600113314603652
Validation loss: 2.1811253578902283

Epoch: 5| Step: 5
Training loss: 0.12282391435660488
Validation loss: 2.185678734689439

Epoch: 5| Step: 6
Training loss: 0.2768169961668821
Validation loss: 2.188983656104476

Epoch: 5| Step: 7
Training loss: 0.2746708845813693
Validation loss: 2.1449892952923415

Epoch: 5| Step: 8
Training loss: 0.25249355227670084
Validation loss: 2.178576090766076

Epoch: 5| Step: 9
Training loss: 0.253150475362105
Validation loss: 2.2058645800739733

Epoch: 5| Step: 10
Training loss: 0.11374112621870539
Validation loss: 2.2083078357000794

Epoch: 579| Step: 0
Training loss: 0.1721106290403611
Validation loss: 2.199238394958396

Epoch: 5| Step: 1
Training loss: 0.16150854404150747
Validation loss: 2.2356238643751114

Epoch: 5| Step: 2
Training loss: 0.2482392023538845
Validation loss: 2.213341026019741

Epoch: 5| Step: 3
Training loss: 0.27720808015134546
Validation loss: 2.222230930935124

Epoch: 5| Step: 4
Training loss: 0.17278484091232882
Validation loss: 2.2431148752037116

Epoch: 5| Step: 5
Training loss: 0.10796842684745733
Validation loss: 2.2501517783579033

Epoch: 5| Step: 6
Training loss: 0.15053939273177766
Validation loss: 2.230681948508647

Epoch: 5| Step: 7
Training loss: 0.24859245254398604
Validation loss: 2.2347658072153775

Epoch: 5| Step: 8
Training loss: 0.38194685005624923
Validation loss: 2.2317186820154444

Epoch: 5| Step: 9
Training loss: 0.1862423961482537
Validation loss: 2.238808564896443

Epoch: 5| Step: 10
Training loss: 0.20246405541508516
Validation loss: 2.2182762123112902

Epoch: 580| Step: 0
Training loss: 0.19046927798591518
Validation loss: 2.2283339224900103

Epoch: 5| Step: 1
Training loss: 0.21087768377677737
Validation loss: 2.22586849200343

Epoch: 5| Step: 2
Training loss: 0.11698864913964613
Validation loss: 2.204498973270927

Epoch: 5| Step: 3
Training loss: 0.19400835462835544
Validation loss: 2.210362946054675

Epoch: 5| Step: 4
Training loss: 0.23778482223436398
Validation loss: 2.22892274998941

Epoch: 5| Step: 5
Training loss: 0.37535916453625046
Validation loss: 2.222584348530213

Epoch: 5| Step: 6
Training loss: 0.3101722809230329
Validation loss: 2.2260053350952242

Epoch: 5| Step: 7
Training loss: 0.33727076348266655
Validation loss: 2.2304189632019873

Epoch: 5| Step: 8
Training loss: 0.42930565253214525
Validation loss: 2.22881522516781

Epoch: 5| Step: 9
Training loss: 0.18420779235256785
Validation loss: 2.230438698290193

Epoch: 5| Step: 10
Training loss: 0.2513113646036915
Validation loss: 2.2207820194790364

Epoch: 581| Step: 0
Training loss: 0.28856052166081125
Validation loss: 2.183631613845919

Epoch: 5| Step: 1
Training loss: 0.3438805418965018
Validation loss: 2.176442751872008

Epoch: 5| Step: 2
Training loss: 0.2217343048838586
Validation loss: 2.1790972806742976

Epoch: 5| Step: 3
Training loss: 0.25305458431625133
Validation loss: 2.234264989213235

Epoch: 5| Step: 4
Training loss: 0.18364808110595945
Validation loss: 2.275344132010858

Epoch: 5| Step: 5
Training loss: 0.16991665711557993
Validation loss: 2.2601063827592265

Epoch: 5| Step: 6
Training loss: 0.38586559011826105
Validation loss: 2.222712900311457

Epoch: 5| Step: 7
Training loss: 0.39709061750366903
Validation loss: 2.191916262901782

Epoch: 5| Step: 8
Training loss: 0.27746292025472447
Validation loss: 2.1944560896808216

Epoch: 5| Step: 9
Training loss: 0.2418937131754687
Validation loss: 2.2151955883238568

Epoch: 5| Step: 10
Training loss: 0.2096887909526853
Validation loss: 2.179419813164011

Epoch: 582| Step: 0
Training loss: 0.2808997436925942
Validation loss: 2.1943234471790927

Epoch: 5| Step: 1
Training loss: 0.36225526786248924
Validation loss: 2.1941340776800695

Epoch: 5| Step: 2
Training loss: 0.25511230718745664
Validation loss: 2.1951902300956005

Epoch: 5| Step: 3
Training loss: 0.2704783124021158
Validation loss: 2.178248461127957

Epoch: 5| Step: 4
Training loss: 0.18823828978737286
Validation loss: 2.166901275989298

Epoch: 5| Step: 5
Training loss: 0.1265572611583996
Validation loss: 2.164019763596072

Epoch: 5| Step: 6
Training loss: 0.2245891396073336
Validation loss: 2.1357327365141447

Epoch: 5| Step: 7
Training loss: 0.22071251807015346
Validation loss: 2.168867964700039

Epoch: 5| Step: 8
Training loss: 0.16084356066283353
Validation loss: 2.1693218773599376

Epoch: 5| Step: 9
Training loss: 0.18403781795003982
Validation loss: 2.205851511609466

Epoch: 5| Step: 10
Training loss: 0.16872610081872993
Validation loss: 2.1737774065397484

Epoch: 583| Step: 0
Training loss: 0.2442209721913831
Validation loss: 2.174520263126329

Epoch: 5| Step: 1
Training loss: 0.2977890449325965
Validation loss: 2.1616895409424224

Epoch: 5| Step: 2
Training loss: 0.18016688006984213
Validation loss: 2.175076925256117

Epoch: 5| Step: 3
Training loss: 0.13814914934574324
Validation loss: 2.1739979912633625

Epoch: 5| Step: 4
Training loss: 0.16782188093614703
Validation loss: 2.1895527157782

Epoch: 5| Step: 5
Training loss: 0.13484508825369607
Validation loss: 2.1702434236240746

Epoch: 5| Step: 6
Training loss: 0.28823138945567656
Validation loss: 2.1680350900551466

Epoch: 5| Step: 7
Training loss: 0.20986239760165346
Validation loss: 2.174364838380239

Epoch: 5| Step: 8
Training loss: 0.194214106954622
Validation loss: 2.1650226234626264

Epoch: 5| Step: 9
Training loss: 0.2492079705564861
Validation loss: 2.166408065085654

Epoch: 5| Step: 10
Training loss: 0.18369905008720414
Validation loss: 2.1863154390275685

Epoch: 584| Step: 0
Training loss: 0.2301436086576895
Validation loss: 2.199737637407649

Epoch: 5| Step: 1
Training loss: 0.20675015710481073
Validation loss: 2.207137751135438

Epoch: 5| Step: 2
Training loss: 0.13961103245157425
Validation loss: 2.207453059090605

Epoch: 5| Step: 3
Training loss: 0.17727314135779856
Validation loss: 2.1621990669728532

Epoch: 5| Step: 4
Training loss: 0.22808486735698344
Validation loss: 2.174614093954833

Epoch: 5| Step: 5
Training loss: 0.24080742355221507
Validation loss: 2.1782407663620114

Epoch: 5| Step: 6
Training loss: 0.24998283327291165
Validation loss: 2.1703005525704624

Epoch: 5| Step: 7
Training loss: 0.2132244380280009
Validation loss: 2.161207735251953

Epoch: 5| Step: 8
Training loss: 0.16746019846862353
Validation loss: 2.148720507286305

Epoch: 5| Step: 9
Training loss: 0.12141707540236886
Validation loss: 2.169608238090492

Epoch: 5| Step: 10
Training loss: 0.1671640337313646
Validation loss: 2.1793575953865503

Epoch: 585| Step: 0
Training loss: 0.14959800218826586
Validation loss: 2.185558207297766

Epoch: 5| Step: 1
Training loss: 0.11408756891834505
Validation loss: 2.1884509022401155

Epoch: 5| Step: 2
Training loss: 0.19932617769114705
Validation loss: 2.1816933979943816

Epoch: 5| Step: 3
Training loss: 0.11985952763354395
Validation loss: 2.198908097943648

Epoch: 5| Step: 4
Training loss: 0.19650156465421909
Validation loss: 2.1976383987383636

Epoch: 5| Step: 5
Training loss: 0.18858445000019383
Validation loss: 2.1968975094400705

Epoch: 5| Step: 6
Training loss: 0.18259079890401936
Validation loss: 2.187272292325859

Epoch: 5| Step: 7
Training loss: 0.22220918042603058
Validation loss: 2.208382250924509

Epoch: 5| Step: 8
Training loss: 0.14640280041656115
Validation loss: 2.193322272857093

Epoch: 5| Step: 9
Training loss: 0.15871779002428643
Validation loss: 2.2067901923987363

Epoch: 5| Step: 10
Training loss: 0.12047752358318112
Validation loss: 2.186785075706888

Epoch: 586| Step: 0
Training loss: 0.12233475842082177
Validation loss: 2.218172681411198

Epoch: 5| Step: 1
Training loss: 0.11463110011216646
Validation loss: 2.2138478263670134

Epoch: 5| Step: 2
Training loss: 0.272794321291303
Validation loss: 2.2326149141139093

Epoch: 5| Step: 3
Training loss: 0.10649780851306644
Validation loss: 2.226556964112506

Epoch: 5| Step: 4
Training loss: 0.11051318056155686
Validation loss: 2.2207804171900887

Epoch: 5| Step: 5
Training loss: 0.16494481934109767
Validation loss: 2.227372902502552

Epoch: 5| Step: 6
Training loss: 0.10960108092121552
Validation loss: 2.2152733909208693

Epoch: 5| Step: 7
Training loss: 0.15475606795433106
Validation loss: 2.2397128007406875

Epoch: 5| Step: 8
Training loss: 0.14750151675866885
Validation loss: 2.2181671544901653

Epoch: 5| Step: 9
Training loss: 0.11125075847656493
Validation loss: 2.207821689415868

Epoch: 5| Step: 10
Training loss: 0.24714095722790433
Validation loss: 2.1851886204657647

Epoch: 587| Step: 0
Training loss: 0.1964781310831779
Validation loss: 2.189995060280813

Epoch: 5| Step: 1
Training loss: 0.13302469132439027
Validation loss: 2.18417625707902

Epoch: 5| Step: 2
Training loss: 0.1467306736741388
Validation loss: 2.1884280985621927

Epoch: 5| Step: 3
Training loss: 0.13932782161551704
Validation loss: 2.1899570682331544

Epoch: 5| Step: 4
Training loss: 0.15096787110611565
Validation loss: 2.170070586498989

Epoch: 5| Step: 5
Training loss: 0.10949636861008569
Validation loss: 2.180254540453192

Epoch: 5| Step: 6
Training loss: 0.19895406979757668
Validation loss: 2.1796332658476203

Epoch: 5| Step: 7
Training loss: 0.11444696842729658
Validation loss: 2.174098983952108

Epoch: 5| Step: 8
Training loss: 0.10078282207179598
Validation loss: 2.1582919661028783

Epoch: 5| Step: 9
Training loss: 0.13544199015959885
Validation loss: 2.1794586720170814

Epoch: 5| Step: 10
Training loss: 0.20910938481337477
Validation loss: 2.164920132136321

Epoch: 588| Step: 0
Training loss: 0.18809926113579784
Validation loss: 2.1903602651602223

Epoch: 5| Step: 1
Training loss: 0.11246278249850974
Validation loss: 2.159853489471006

Epoch: 5| Step: 2
Training loss: 0.18335531863328325
Validation loss: 2.1706496820839707

Epoch: 5| Step: 3
Training loss: 0.10507917421377269
Validation loss: 2.184191206723522

Epoch: 5| Step: 4
Training loss: 0.18046964546080538
Validation loss: 2.137334170886508

Epoch: 5| Step: 5
Training loss: 0.14993392040174466
Validation loss: 2.1656265337623903

Epoch: 5| Step: 6
Training loss: 0.0897523996090805
Validation loss: 2.1468063068733847

Epoch: 5| Step: 7
Training loss: 0.13309268988030143
Validation loss: 2.1704183790047757

Epoch: 5| Step: 8
Training loss: 0.0801671481159976
Validation loss: 2.150820880612963

Epoch: 5| Step: 9
Training loss: 0.09971443881055254
Validation loss: 2.1681512222428534

Epoch: 5| Step: 10
Training loss: 0.08970146210914415
Validation loss: 2.1587220048869633

Epoch: 589| Step: 0
Training loss: 0.08820289134525947
Validation loss: 2.1722565802128604

Epoch: 5| Step: 1
Training loss: 0.11044731880530341
Validation loss: 2.1593252600915025

Epoch: 5| Step: 2
Training loss: 0.13596560253497425
Validation loss: 2.146189515416273

Epoch: 5| Step: 3
Training loss: 0.13138642855595592
Validation loss: 2.1719657098184206

Epoch: 5| Step: 4
Training loss: 0.2654170737171096
Validation loss: 2.1700644079628186

Epoch: 5| Step: 5
Training loss: 0.1621731379936031
Validation loss: 2.1611401684146547

Epoch: 5| Step: 6
Training loss: 0.09284206161228553
Validation loss: 2.167686853666403

Epoch: 5| Step: 7
Training loss: 0.10072327006894369
Validation loss: 2.187390743990299

Epoch: 5| Step: 8
Training loss: 0.10376768194180958
Validation loss: 2.1719333224471327

Epoch: 5| Step: 9
Training loss: 0.10134614770207277
Validation loss: 2.1327014876024606

Epoch: 5| Step: 10
Training loss: 0.14964252035042613
Validation loss: 2.198094713652728

Epoch: 590| Step: 0
Training loss: 0.19368828628949136
Validation loss: 2.1863639196021554

Epoch: 5| Step: 1
Training loss: 0.13856893398969017
Validation loss: 2.180378336624366

Epoch: 5| Step: 2
Training loss: 0.20491557263926072
Validation loss: 2.1531999585769954

Epoch: 5| Step: 3
Training loss: 0.11040864582064454
Validation loss: 2.180573716876256

Epoch: 5| Step: 4
Training loss: 0.10889043929924021
Validation loss: 2.16785746130509

Epoch: 5| Step: 5
Training loss: 0.10540016027966334
Validation loss: 2.157854001682263

Epoch: 5| Step: 6
Training loss: 0.13973304213082582
Validation loss: 2.181260809798281

Epoch: 5| Step: 7
Training loss: 0.10349993316906232
Validation loss: 2.2011393711269864

Epoch: 5| Step: 8
Training loss: 0.10482721009241137
Validation loss: 2.1823547970500523

Epoch: 5| Step: 9
Training loss: 0.1946030319631912
Validation loss: 2.191273561521835

Epoch: 5| Step: 10
Training loss: 0.0673411800476093
Validation loss: 2.1890608350741556

Epoch: 591| Step: 0
Training loss: 0.1655363288623799
Validation loss: 2.1900765031207268

Epoch: 5| Step: 1
Training loss: 0.10730659628282373
Validation loss: 2.201571781970861

Epoch: 5| Step: 2
Training loss: 0.13682268823963503
Validation loss: 2.1984892729464214

Epoch: 5| Step: 3
Training loss: 0.09826578175457476
Validation loss: 2.210183182816238

Epoch: 5| Step: 4
Training loss: 0.09965102409585676
Validation loss: 2.2087646321692986

Epoch: 5| Step: 5
Training loss: 0.1209840392911486
Validation loss: 2.201096862515849

Epoch: 5| Step: 6
Training loss: 0.11943203822921918
Validation loss: 2.2000725507193315

Epoch: 5| Step: 7
Training loss: 0.17516586881321877
Validation loss: 2.194395153107686

Epoch: 5| Step: 8
Training loss: 0.11574821350910615
Validation loss: 2.2136472565127847

Epoch: 5| Step: 9
Training loss: 0.17140085754327455
Validation loss: 2.2120292643896713

Epoch: 5| Step: 10
Training loss: 0.14253188389321655
Validation loss: 2.1774248715964695

Epoch: 592| Step: 0
Training loss: 0.18723880933903156
Validation loss: 2.1969981344331053

Epoch: 5| Step: 1
Training loss: 0.15738859179753328
Validation loss: 2.202077466016027

Epoch: 5| Step: 2
Training loss: 0.08194068325593197
Validation loss: 2.199352780443152

Epoch: 5| Step: 3
Training loss: 0.15262085825496824
Validation loss: 2.2234566500615793

Epoch: 5| Step: 4
Training loss: 0.06420186587134372
Validation loss: 2.1919239061510365

Epoch: 5| Step: 5
Training loss: 0.2492052424366781
Validation loss: 2.2135206868421884

Epoch: 5| Step: 6
Training loss: 0.1250575648320135
Validation loss: 2.2186611168710533

Epoch: 5| Step: 7
Training loss: 0.08743532719887988
Validation loss: 2.20466176055183

Epoch: 5| Step: 8
Training loss: 0.11829604509863917
Validation loss: 2.2086108610471773

Epoch: 5| Step: 9
Training loss: 0.13506354007779445
Validation loss: 2.206744681529746

Epoch: 5| Step: 10
Training loss: 0.12608569984548365
Validation loss: 2.2002416264780043

Epoch: 593| Step: 0
Training loss: 0.15570661712191003
Validation loss: 2.182503178232665

Epoch: 5| Step: 1
Training loss: 0.07610383418312791
Validation loss: 2.195185677833377

Epoch: 5| Step: 2
Training loss: 0.13914565295217107
Validation loss: 2.193465143578017

Epoch: 5| Step: 3
Training loss: 0.19752385451116616
Validation loss: 2.188138658196271

Epoch: 5| Step: 4
Training loss: 0.12280566551396147
Validation loss: 2.1881131357399624

Epoch: 5| Step: 5
Training loss: 0.07669337275864371
Validation loss: 2.2019420209351064

Epoch: 5| Step: 6
Training loss: 0.2011588194230986
Validation loss: 2.171187855675777

Epoch: 5| Step: 7
Training loss: 0.10082314123348136
Validation loss: 2.17452601519327

Epoch: 5| Step: 8
Training loss: 0.1807961161739878
Validation loss: 2.191697627787422

Epoch: 5| Step: 9
Training loss: 0.10296007645158163
Validation loss: 2.1610099777182135

Epoch: 5| Step: 10
Training loss: 0.11317120748420736
Validation loss: 2.1719058903589405

Epoch: 594| Step: 0
Training loss: 0.11281362980120986
Validation loss: 2.1944359784213714

Epoch: 5| Step: 1
Training loss: 0.10117269869141367
Validation loss: 2.1836248784474597

Epoch: 5| Step: 2
Training loss: 0.2432178989240138
Validation loss: 2.1801622685012054

Epoch: 5| Step: 3
Training loss: 0.09167637423658741
Validation loss: 2.1789907817351835

Epoch: 5| Step: 4
Training loss: 0.10380284929575098
Validation loss: 2.190606741079921

Epoch: 5| Step: 5
Training loss: 0.1238918357152015
Validation loss: 2.188610871860913

Epoch: 5| Step: 6
Training loss: 0.19439322619219043
Validation loss: 2.187751521169439

Epoch: 5| Step: 7
Training loss: 0.10779591809478531
Validation loss: 2.1869891998619866

Epoch: 5| Step: 8
Training loss: 0.12314854690211965
Validation loss: 2.1533874205111774

Epoch: 5| Step: 9
Training loss: 0.12140128093600273
Validation loss: 2.204987258366474

Epoch: 5| Step: 10
Training loss: 0.10566427068636934
Validation loss: 2.1537986959332907

Epoch: 595| Step: 0
Training loss: 0.16243757782112656
Validation loss: 2.1756040168407824

Epoch: 5| Step: 1
Training loss: 0.0713600889182332
Validation loss: 2.1935987279385722

Epoch: 5| Step: 2
Training loss: 0.12796956088842043
Validation loss: 2.184235991076386

Epoch: 5| Step: 3
Training loss: 0.16357163384516002
Validation loss: 2.1905307231230955

Epoch: 5| Step: 4
Training loss: 0.21080312157304384
Validation loss: 2.226504212447501

Epoch: 5| Step: 5
Training loss: 0.09175284323912318
Validation loss: 2.212857615525146

Epoch: 5| Step: 6
Training loss: 0.13065961279940388
Validation loss: 2.185914165903528

Epoch: 5| Step: 7
Training loss: 0.08973938643968399
Validation loss: 2.202195573604296

Epoch: 5| Step: 8
Training loss: 0.16958862819145934
Validation loss: 2.1876921784676084

Epoch: 5| Step: 9
Training loss: 0.10121394372683962
Validation loss: 2.223964601143674

Epoch: 5| Step: 10
Training loss: 0.12146453082051553
Validation loss: 2.198486238773083

Epoch: 596| Step: 0
Training loss: 0.12550673738714285
Validation loss: 2.227808623668535

Epoch: 5| Step: 1
Training loss: 0.18453826827964448
Validation loss: 2.193516616460013

Epoch: 5| Step: 2
Training loss: 0.13157974357818958
Validation loss: 2.202369957360079

Epoch: 5| Step: 3
Training loss: 0.119510420686069
Validation loss: 2.171790975292578

Epoch: 5| Step: 4
Training loss: 0.077695821062306
Validation loss: 2.1979836498093057

Epoch: 5| Step: 5
Training loss: 0.15844336271254855
Validation loss: 2.2034491052820973

Epoch: 5| Step: 6
Training loss: 0.07425112708256608
Validation loss: 2.21119635609633

Epoch: 5| Step: 7
Training loss: 0.19153992208689463
Validation loss: 2.2061519525370654

Epoch: 5| Step: 8
Training loss: 0.2258369238563334
Validation loss: 2.210804512804215

Epoch: 5| Step: 9
Training loss: 0.13074340236203108
Validation loss: 2.2061121522487412

Epoch: 5| Step: 10
Training loss: 0.10775560643547277
Validation loss: 2.1948842919339135

Epoch: 597| Step: 0
Training loss: 0.1421877730021109
Validation loss: 2.1958428652612656

Epoch: 5| Step: 1
Training loss: 0.14783920629514447
Validation loss: 2.209647259282961

Epoch: 5| Step: 2
Training loss: 0.11622376731767399
Validation loss: 2.188619778827417

Epoch: 5| Step: 3
Training loss: 0.15254051999068619
Validation loss: 2.177554244531384

Epoch: 5| Step: 4
Training loss: 0.11970365874621232
Validation loss: 2.1951832452070814

Epoch: 5| Step: 5
Training loss: 0.1364092866705955
Validation loss: 2.2187278107488697

Epoch: 5| Step: 6
Training loss: 0.1277300171881607
Validation loss: 2.215959395760706

Epoch: 5| Step: 7
Training loss: 0.08302778116028868
Validation loss: 2.1910631356732178

Epoch: 5| Step: 8
Training loss: 0.18085270904384554
Validation loss: 2.207752966081213

Epoch: 5| Step: 9
Training loss: 0.2507436391369752
Validation loss: 2.199500973589277

Epoch: 5| Step: 10
Training loss: 0.06755008184558088
Validation loss: 2.2162564208857862

Epoch: 598| Step: 0
Training loss: 0.1836757071163034
Validation loss: 2.211850181330264

Epoch: 5| Step: 1
Training loss: 0.11535335314607742
Validation loss: 2.2074238124483987

Epoch: 5| Step: 2
Training loss: 0.11907872952962385
Validation loss: 2.2145268135227414

Epoch: 5| Step: 3
Training loss: 0.09374098933150667
Validation loss: 2.2233624475689022

Epoch: 5| Step: 4
Training loss: 0.2161241265776257
Validation loss: 2.2472525021561114

Epoch: 5| Step: 5
Training loss: 0.12039361331159414
Validation loss: 2.219124110940495

Epoch: 5| Step: 6
Training loss: 0.11737041106384015
Validation loss: 2.2333044207591186

Epoch: 5| Step: 7
Training loss: 0.13682319874753168
Validation loss: 2.2262969058136792

Epoch: 5| Step: 8
Training loss: 0.15878764242215254
Validation loss: 2.215666097892196

Epoch: 5| Step: 9
Training loss: 0.11617106466902186
Validation loss: 2.201001239453465

Epoch: 5| Step: 10
Training loss: 0.22294820918131567
Validation loss: 2.201106335668346

Epoch: 599| Step: 0
Training loss: 0.13207434537789609
Validation loss: 2.2335029499147945

Epoch: 5| Step: 1
Training loss: 0.23289288150854834
Validation loss: 2.187023084484714

Epoch: 5| Step: 2
Training loss: 0.091291900373559
Validation loss: 2.206497750217896

Epoch: 5| Step: 3
Training loss: 0.10211072192657243
Validation loss: 2.2066277364051503

Epoch: 5| Step: 4
Training loss: 0.1486195276366204
Validation loss: 2.2335420543664966

Epoch: 5| Step: 5
Training loss: 0.12450188616655748
Validation loss: 2.2141010050163406

Epoch: 5| Step: 6
Training loss: 0.15422354537094218
Validation loss: 2.2131573090861774

Epoch: 5| Step: 7
Training loss: 0.08918273886307251
Validation loss: 2.2012081600200863

Epoch: 5| Step: 8
Training loss: 0.1754156018422655
Validation loss: 2.1876587817434894

Epoch: 5| Step: 9
Training loss: 0.08491357491683413
Validation loss: 2.222165843118546

Epoch: 5| Step: 10
Training loss: 0.08797539490677937
Validation loss: 2.197644157372461

Epoch: 600| Step: 0
Training loss: 0.23423907789153564
Validation loss: 2.1780645643194614

Epoch: 5| Step: 1
Training loss: 0.12637280093523853
Validation loss: 2.1796847607436654

Epoch: 5| Step: 2
Training loss: 0.0958750358277469
Validation loss: 2.1841317245927856

Epoch: 5| Step: 3
Training loss: 0.1654045865090383
Validation loss: 2.1781751938015983

Epoch: 5| Step: 4
Training loss: 0.11971551523690269
Validation loss: 2.192790955977947

Epoch: 5| Step: 5
Training loss: 0.16948728782462721
Validation loss: 2.2120493234782423

Epoch: 5| Step: 6
Training loss: 0.10285090755945198
Validation loss: 2.2098678441582886

Epoch: 5| Step: 7
Training loss: 0.08039526245747002
Validation loss: 2.2373365066934134

Epoch: 5| Step: 8
Training loss: 0.1148084187169
Validation loss: 2.228921256492841

Epoch: 5| Step: 9
Training loss: 0.15202465629196896
Validation loss: 2.19844408292078

Epoch: 5| Step: 10
Training loss: 0.09970884405537474
Validation loss: 2.194014794149432

Epoch: 601| Step: 0
Training loss: 0.10614981450890314
Validation loss: 2.205325816268679

Epoch: 5| Step: 1
Training loss: 0.1579957827785381
Validation loss: 2.190045617379961

Epoch: 5| Step: 2
Training loss: 0.09088506236275999
Validation loss: 2.1993220896655403

Epoch: 5| Step: 3
Training loss: 0.08955723230719183
Validation loss: 2.180034676695895

Epoch: 5| Step: 4
Training loss: 0.08805739686845754
Validation loss: 2.1961794773859915

Epoch: 5| Step: 5
Training loss: 0.1283526744126812
Validation loss: 2.187449454384275

Epoch: 5| Step: 6
Training loss: 0.13829932067815276
Validation loss: 2.1772463940046745

Epoch: 5| Step: 7
Training loss: 0.18323728775633027
Validation loss: 2.189421683645153

Epoch: 5| Step: 8
Training loss: 0.07382920582298046
Validation loss: 2.2066961994067054

Epoch: 5| Step: 9
Training loss: 0.12436661586585772
Validation loss: 2.19066654256219

Epoch: 5| Step: 10
Training loss: 0.19203103527184345
Validation loss: 2.184708324852393

Epoch: 602| Step: 0
Training loss: 0.17221632574247892
Validation loss: 2.2031688338187974

Epoch: 5| Step: 1
Training loss: 0.09779998691640174
Validation loss: 2.166880770565159

Epoch: 5| Step: 2
Training loss: 0.08251918420210774
Validation loss: 2.18946220183329

Epoch: 5| Step: 3
Training loss: 0.1638933115471756
Validation loss: 2.180333870602787

Epoch: 5| Step: 4
Training loss: 0.12483017904382494
Validation loss: 2.1876001554844575

Epoch: 5| Step: 5
Training loss: 0.08526635357680215
Validation loss: 2.1982293636743027

Epoch: 5| Step: 6
Training loss: 0.1301807485607141
Validation loss: 2.220706222326676

Epoch: 5| Step: 7
Training loss: 0.11459302635448114
Validation loss: 2.2297788608736844

Epoch: 5| Step: 8
Training loss: 0.11241926070905499
Validation loss: 2.2001031209133837

Epoch: 5| Step: 9
Training loss: 0.07664467418348783
Validation loss: 2.2011813734523153

Epoch: 5| Step: 10
Training loss: 0.1993344662757985
Validation loss: 2.2021448286186245

Epoch: 603| Step: 0
Training loss: 0.167228631726557
Validation loss: 2.199951284182429

Epoch: 5| Step: 1
Training loss: 0.07156088687190536
Validation loss: 2.2110108249213223

Epoch: 5| Step: 2
Training loss: 0.11122115751818931
Validation loss: 2.21092955143151

Epoch: 5| Step: 3
Training loss: 0.10990170124924394
Validation loss: 2.194794407268095

Epoch: 5| Step: 4
Training loss: 0.09043490763483368
Validation loss: 2.222532088542014

Epoch: 5| Step: 5
Training loss: 0.08311897575985405
Validation loss: 2.2167382982855934

Epoch: 5| Step: 6
Training loss: 0.20387483625212455
Validation loss: 2.1847555004549792

Epoch: 5| Step: 7
Training loss: 0.08541684218520453
Validation loss: 2.20669972794466

Epoch: 5| Step: 8
Training loss: 0.19372246108151914
Validation loss: 2.188336922769671

Epoch: 5| Step: 9
Training loss: 0.11938260082318222
Validation loss: 2.2173434630027624

Epoch: 5| Step: 10
Training loss: 0.10391600570198287
Validation loss: 2.189143775337064

Epoch: 604| Step: 0
Training loss: 0.05268090018144262
Validation loss: 2.207368862600487

Epoch: 5| Step: 1
Training loss: 0.10357770767536416
Validation loss: 2.2112046005086925

Epoch: 5| Step: 2
Training loss: 0.080004140357448
Validation loss: 2.2116315624737766

Epoch: 5| Step: 3
Training loss: 0.08710050944044923
Validation loss: 2.18718984722676

Epoch: 5| Step: 4
Training loss: 0.09847488128758335
Validation loss: 2.1928418677368935

Epoch: 5| Step: 5
Training loss: 0.1802562750915825
Validation loss: 2.2130067989577684

Epoch: 5| Step: 6
Training loss: 0.17000865912473148
Validation loss: 2.1832778064881464

Epoch: 5| Step: 7
Training loss: 0.1690496111732204
Validation loss: 2.2187655603052967

Epoch: 5| Step: 8
Training loss: 0.15980017435381536
Validation loss: 2.2093142682403055

Epoch: 5| Step: 9
Training loss: 0.10928235217251211
Validation loss: 2.209344865757316

Epoch: 5| Step: 10
Training loss: 0.0896293528402927
Validation loss: 2.1898925927993433

Epoch: 605| Step: 0
Training loss: 0.08851510822990384
Validation loss: 2.1958724044957356

Epoch: 5| Step: 1
Training loss: 0.1362271120485069
Validation loss: 2.2034918582127094

Epoch: 5| Step: 2
Training loss: 0.07322918458592904
Validation loss: 2.190541532250875

Epoch: 5| Step: 3
Training loss: 0.08257288308500045
Validation loss: 2.221504157793986

Epoch: 5| Step: 4
Training loss: 0.12311441974517134
Validation loss: 2.2076827225820312

Epoch: 5| Step: 5
Training loss: 0.2177449964759788
Validation loss: 2.2060096257229156

Epoch: 5| Step: 6
Training loss: 0.09036000308412685
Validation loss: 2.17339531836843

Epoch: 5| Step: 7
Training loss: 0.07276376875012228
Validation loss: 2.1812580302067994

Epoch: 5| Step: 8
Training loss: 0.10617200955290475
Validation loss: 2.1925978856491843

Epoch: 5| Step: 9
Training loss: 0.08274551631324606
Validation loss: 2.1986030852388203

Epoch: 5| Step: 10
Training loss: 0.20221235582372837
Validation loss: 2.1972895570679962

Epoch: 606| Step: 0
Training loss: 0.07681061927787536
Validation loss: 2.2095233460674177

Epoch: 5| Step: 1
Training loss: 0.08585237220672531
Validation loss: 2.1748135885341644

Epoch: 5| Step: 2
Training loss: 0.1888189220592716
Validation loss: 2.1990680774471913

Epoch: 5| Step: 3
Training loss: 0.19714840153738608
Validation loss: 2.2002889438304756

Epoch: 5| Step: 4
Training loss: 0.06593653099649743
Validation loss: 2.1916470807234107

Epoch: 5| Step: 5
Training loss: 0.09597725435969415
Validation loss: 2.1936443824048997

Epoch: 5| Step: 6
Training loss: 0.0911523379547987
Validation loss: 2.206983291376427

Epoch: 5| Step: 7
Training loss: 0.170142600420175
Validation loss: 2.2008493464523524

Epoch: 5| Step: 8
Training loss: 0.0874378968498067
Validation loss: 2.2228808589143734

Epoch: 5| Step: 9
Training loss: 0.0991405317668311
Validation loss: 2.206448450801656

Epoch: 5| Step: 10
Training loss: 0.07307368923620823
Validation loss: 2.1780443111230072

Epoch: 607| Step: 0
Training loss: 0.09059345460917913
Validation loss: 2.1853177508064707

Epoch: 5| Step: 1
Training loss: 0.16156287167430752
Validation loss: 2.194414991369173

Epoch: 5| Step: 2
Training loss: 0.1182579109215174
Validation loss: 2.16224511054116

Epoch: 5| Step: 3
Training loss: 0.06696003122665532
Validation loss: 2.195364390830554

Epoch: 5| Step: 4
Training loss: 0.13563696810658754
Validation loss: 2.20777270057078

Epoch: 5| Step: 5
Training loss: 0.1445079926516832
Validation loss: 2.2083832515926347

Epoch: 5| Step: 6
Training loss: 0.10583593330684593
Validation loss: 2.190776213867481

Epoch: 5| Step: 7
Training loss: 0.10158851180393563
Validation loss: 2.1913708684392748

Epoch: 5| Step: 8
Training loss: 0.0897301806101134
Validation loss: 2.1821681427309607

Epoch: 5| Step: 9
Training loss: 0.19046341035037873
Validation loss: 2.189968306886699

Epoch: 5| Step: 10
Training loss: 0.06926829772923931
Validation loss: 2.194182544109125

Epoch: 608| Step: 0
Training loss: 0.10398456680228574
Validation loss: 2.191623262502524

Epoch: 5| Step: 1
Training loss: 0.0630494567337764
Validation loss: 2.211589496062249

Epoch: 5| Step: 2
Training loss: 0.08086627870840835
Validation loss: 2.204090359273353

Epoch: 5| Step: 3
Training loss: 0.0973954150586998
Validation loss: 2.2146538940643876

Epoch: 5| Step: 4
Training loss: 0.16456172125697646
Validation loss: 2.189331851056625

Epoch: 5| Step: 5
Training loss: 0.16308021535371597
Validation loss: 2.1927304331926263

Epoch: 5| Step: 6
Training loss: 0.15010030392934334
Validation loss: 2.179471973577291

Epoch: 5| Step: 7
Training loss: 0.11406121498194036
Validation loss: 2.2017576299747827

Epoch: 5| Step: 8
Training loss: 0.11820474822700391
Validation loss: 2.186961905048238

Epoch: 5| Step: 9
Training loss: 0.12262983265447464
Validation loss: 2.202612666120546

Epoch: 5| Step: 10
Training loss: 0.09916799591312915
Validation loss: 2.1943307362263753

Epoch: 609| Step: 0
Training loss: 0.11309403125346391
Validation loss: 2.194908096959374

Epoch: 5| Step: 1
Training loss: 0.13584142940426727
Validation loss: 2.185666885753231

Epoch: 5| Step: 2
Training loss: 0.2288400840825085
Validation loss: 2.1825863439070847

Epoch: 5| Step: 3
Training loss: 0.09253898912058957
Validation loss: 2.1871925794278977

Epoch: 5| Step: 4
Training loss: 0.0785015390106304
Validation loss: 2.1748167476793663

Epoch: 5| Step: 5
Training loss: 0.0897821443229717
Validation loss: 2.170698586352816

Epoch: 5| Step: 6
Training loss: 0.1523353256439453
Validation loss: 2.1897823855335807

Epoch: 5| Step: 7
Training loss: 0.11298853363958473
Validation loss: 2.175605467399131

Epoch: 5| Step: 8
Training loss: 0.09542887668991258
Validation loss: 2.185149813354496

Epoch: 5| Step: 9
Training loss: 0.10599008826792394
Validation loss: 2.1783042891480253

Epoch: 5| Step: 10
Training loss: 0.10156426519913993
Validation loss: 2.1880553787187917

Epoch: 610| Step: 0
Training loss: 0.09841083816463467
Validation loss: 2.194097423876127

Epoch: 5| Step: 1
Training loss: 0.10254733642620785
Validation loss: 2.202753152436232

Epoch: 5| Step: 2
Training loss: 0.09170605854367232
Validation loss: 2.2170831443869687

Epoch: 5| Step: 3
Training loss: 0.17660748955075317
Validation loss: 2.2142837984774197

Epoch: 5| Step: 4
Training loss: 0.19793233474819177
Validation loss: 2.207353485596301

Epoch: 5| Step: 5
Training loss: 0.13002610727338196
Validation loss: 2.2046003734685247

Epoch: 5| Step: 6
Training loss: 0.10610689385167042
Validation loss: 2.185449015507393

Epoch: 5| Step: 7
Training loss: 0.10052599092784666
Validation loss: 2.2290798450575697

Epoch: 5| Step: 8
Training loss: 0.07835128913608812
Validation loss: 2.201905925561348

Epoch: 5| Step: 9
Training loss: 0.16537037160960608
Validation loss: 2.2049995836433287

Epoch: 5| Step: 10
Training loss: 0.09318035131285023
Validation loss: 2.2120590643786238

Epoch: 611| Step: 0
Training loss: 0.15578760631529798
Validation loss: 2.2085836686168037

Epoch: 5| Step: 1
Training loss: 0.09301045908681117
Validation loss: 2.191267834113193

Epoch: 5| Step: 2
Training loss: 0.1593924779284103
Validation loss: 2.207543878808688

Epoch: 5| Step: 3
Training loss: 0.11215166364312586
Validation loss: 2.1956059807061585

Epoch: 5| Step: 4
Training loss: 0.14454481989074108
Validation loss: 2.184164689318814

Epoch: 5| Step: 5
Training loss: 0.19135920277258614
Validation loss: 2.200347513381657

Epoch: 5| Step: 6
Training loss: 0.11805543556705934
Validation loss: 2.1840805293928014

Epoch: 5| Step: 7
Training loss: 0.08110975784633218
Validation loss: 2.203174757775567

Epoch: 5| Step: 8
Training loss: 0.10664868830843544
Validation loss: 2.2028409841289043

Epoch: 5| Step: 9
Training loss: 0.1657774619371694
Validation loss: 2.1638475264448225

Epoch: 5| Step: 10
Training loss: 0.12962801039942123
Validation loss: 2.2021890212921598

Epoch: 612| Step: 0
Training loss: 0.09833779924799821
Validation loss: 2.196160357795275

Epoch: 5| Step: 1
Training loss: 0.23374241655971487
Validation loss: 2.2026307462082526

Epoch: 5| Step: 2
Training loss: 0.07560555526306674
Validation loss: 2.20527568038884

Epoch: 5| Step: 3
Training loss: 0.1227139897417718
Validation loss: 2.22604328024765

Epoch: 5| Step: 4
Training loss: 0.11231731260902017
Validation loss: 2.201397506758936

Epoch: 5| Step: 5
Training loss: 0.1257600105905445
Validation loss: 2.2103533032243994

Epoch: 5| Step: 6
Training loss: 0.06884524158545038
Validation loss: 2.1933245602738443

Epoch: 5| Step: 7
Training loss: 0.13324270974680094
Validation loss: 2.203660985731142

Epoch: 5| Step: 8
Training loss: 0.14581164059628937
Validation loss: 2.16858729561035

Epoch: 5| Step: 9
Training loss: 0.18548777793582216
Validation loss: 2.1888999367822692

Epoch: 5| Step: 10
Training loss: 0.0817775094390714
Validation loss: 2.191739881819384

Epoch: 613| Step: 0
Training loss: 0.09752699404184845
Validation loss: 2.1853278044243942

Epoch: 5| Step: 1
Training loss: 0.10568167685957705
Validation loss: 2.1765143330992145

Epoch: 5| Step: 2
Training loss: 0.19210252821776252
Validation loss: 2.1850313299635302

Epoch: 5| Step: 3
Training loss: 0.11370648941833002
Validation loss: 2.1833287918372672

Epoch: 5| Step: 4
Training loss: 0.1109966269941273
Validation loss: 2.164203472616802

Epoch: 5| Step: 5
Training loss: 0.1754209322327699
Validation loss: 2.1790630157421105

Epoch: 5| Step: 6
Training loss: 0.07548772631560902
Validation loss: 2.176983758959519

Epoch: 5| Step: 7
Training loss: 0.07088530198098929
Validation loss: 2.197803408277472

Epoch: 5| Step: 8
Training loss: 0.13948222585983622
Validation loss: 2.166852532697904

Epoch: 5| Step: 9
Training loss: 0.10164732783395518
Validation loss: 2.179165846568167

Epoch: 5| Step: 10
Training loss: 0.16727900830588852
Validation loss: 2.1685723334136693

Epoch: 614| Step: 0
Training loss: 0.16964788929119246
Validation loss: 2.1644479768029963

Epoch: 5| Step: 1
Training loss: 0.22514756450009288
Validation loss: 2.1827773673775313

Epoch: 5| Step: 2
Training loss: 0.1024286902274891
Validation loss: 2.172931492086471

Epoch: 5| Step: 3
Training loss: 0.12044676481753151
Validation loss: 2.168482990317651

Epoch: 5| Step: 4
Training loss: 0.07875791122987347
Validation loss: 2.169634299624211

Epoch: 5| Step: 5
Training loss: 0.08232095911036875
Validation loss: 2.1658770822985107

Epoch: 5| Step: 6
Training loss: 0.2083893889274472
Validation loss: 2.1834845538993792

Epoch: 5| Step: 7
Training loss: 0.12695149640725978
Validation loss: 2.1526540870430164

Epoch: 5| Step: 8
Training loss: 0.10201427956802703
Validation loss: 2.196706222660292

Epoch: 5| Step: 9
Training loss: 0.14182471088806614
Validation loss: 2.2199132476362586

Epoch: 5| Step: 10
Training loss: 0.08348129096627435
Validation loss: 2.1953894506403375

Epoch: 615| Step: 0
Training loss: 0.13601191226946885
Validation loss: 2.189562590130342

Epoch: 5| Step: 1
Training loss: 0.14027449185456634
Validation loss: 2.2138511376718046

Epoch: 5| Step: 2
Training loss: 0.11571888977874711
Validation loss: 2.1831904841382883

Epoch: 5| Step: 3
Training loss: 0.12166887268941635
Validation loss: 2.2057246760596145

Epoch: 5| Step: 4
Training loss: 0.16535464705003775
Validation loss: 2.1922886552316667

Epoch: 5| Step: 5
Training loss: 0.1457174825881138
Validation loss: 2.195440883077125

Epoch: 5| Step: 6
Training loss: 0.12033957542097042
Validation loss: 2.2161988365691254

Epoch: 5| Step: 7
Training loss: 0.2462356854407603
Validation loss: 2.219260104404075

Epoch: 5| Step: 8
Training loss: 0.12203693314993763
Validation loss: 2.2319489564720763

Epoch: 5| Step: 9
Training loss: 0.08957351595660415
Validation loss: 2.1974228389377384

Epoch: 5| Step: 10
Training loss: 0.19832311585064008
Validation loss: 2.206477497168997

Epoch: 616| Step: 0
Training loss: 0.10578596571577421
Validation loss: 2.1946508998623377

Epoch: 5| Step: 1
Training loss: 0.0928600258554869
Validation loss: 2.1824960622932967

Epoch: 5| Step: 2
Training loss: 0.09129001305982608
Validation loss: 2.1978749715114847

Epoch: 5| Step: 3
Training loss: 0.16629526484730633
Validation loss: 2.1865508345150073

Epoch: 5| Step: 4
Training loss: 0.1436701848447703
Validation loss: 2.187840542164203

Epoch: 5| Step: 5
Training loss: 0.09133269252075168
Validation loss: 2.1982772508815804

Epoch: 5| Step: 6
Training loss: 0.2122093463882013
Validation loss: 2.171773521429298

Epoch: 5| Step: 7
Training loss: 0.10352245344276231
Validation loss: 2.1888686227569076

Epoch: 5| Step: 8
Training loss: 0.1515519030297642
Validation loss: 2.182903945069927

Epoch: 5| Step: 9
Training loss: 0.12313634405063065
Validation loss: 2.1860158863646797

Epoch: 5| Step: 10
Training loss: 0.1308060651341062
Validation loss: 2.1700452851046874

Epoch: 617| Step: 0
Training loss: 0.10385248417274215
Validation loss: 2.181413169479488

Epoch: 5| Step: 1
Training loss: 0.18134193062153106
Validation loss: 2.20131271646481

Epoch: 5| Step: 2
Training loss: 0.1434443042944701
Validation loss: 2.1865277697850334

Epoch: 5| Step: 3
Training loss: 0.060923628955359334
Validation loss: 2.190396804185661

Epoch: 5| Step: 4
Training loss: 0.07677399632141946
Validation loss: 2.1884067127048095

Epoch: 5| Step: 5
Training loss: 0.08326867850090204
Validation loss: 2.165278176406374

Epoch: 5| Step: 6
Training loss: 0.10897908761929462
Validation loss: 2.1984152645092645

Epoch: 5| Step: 7
Training loss: 0.09444863555625917
Validation loss: 2.172711407043824

Epoch: 5| Step: 8
Training loss: 0.14815994715588485
Validation loss: 2.2055093114485254

Epoch: 5| Step: 9
Training loss: 0.19536183687776443
Validation loss: 2.1781048930081295

Epoch: 5| Step: 10
Training loss: 0.10517025581516684
Validation loss: 2.1819447111313743

Epoch: 618| Step: 0
Training loss: 0.13637089072198133
Validation loss: 2.1733959211212617

Epoch: 5| Step: 1
Training loss: 0.09838184683250167
Validation loss: 2.1714214548700137

Epoch: 5| Step: 2
Training loss: 0.15029007163425104
Validation loss: 2.167842951137133

Epoch: 5| Step: 3
Training loss: 0.07725855055340856
Validation loss: 2.179231000520924

Epoch: 5| Step: 4
Training loss: 0.08765572044991181
Validation loss: 2.1927732647491136

Epoch: 5| Step: 5
Training loss: 0.15241339509878385
Validation loss: 2.1711716999371533

Epoch: 5| Step: 6
Training loss: 0.1262961702502937
Validation loss: 2.1613645930348064

Epoch: 5| Step: 7
Training loss: 0.09901690057098732
Validation loss: 2.1651540742485955

Epoch: 5| Step: 8
Training loss: 0.0824411234142492
Validation loss: 2.170849682988822

Epoch: 5| Step: 9
Training loss: 0.18212538810379683
Validation loss: 2.1857056743006043

Epoch: 5| Step: 10
Training loss: 0.19312884334641037
Validation loss: 2.191224215582499

Epoch: 619| Step: 0
Training loss: 0.159601413492765
Validation loss: 2.2025637569587793

Epoch: 5| Step: 1
Training loss: 0.16563941739868032
Validation loss: 2.169946184250418

Epoch: 5| Step: 2
Training loss: 0.10714027167149753
Validation loss: 2.191492600416164

Epoch: 5| Step: 3
Training loss: 0.10232756009792729
Validation loss: 2.178363629860022

Epoch: 5| Step: 4
Training loss: 0.17868811039455107
Validation loss: 2.2118498162300986

Epoch: 5| Step: 5
Training loss: 0.12490396983241689
Validation loss: 2.1724357385731032

Epoch: 5| Step: 6
Training loss: 0.1726120134792368
Validation loss: 2.1808701208117163

Epoch: 5| Step: 7
Training loss: 0.07479030356298443
Validation loss: 2.195233721066431

Epoch: 5| Step: 8
Training loss: 0.10449580159577307
Validation loss: 2.1840591928144795

Epoch: 5| Step: 9
Training loss: 0.12941512897580532
Validation loss: 2.190255242060065

Epoch: 5| Step: 10
Training loss: 0.10990686188029365
Validation loss: 2.1848167475423446

Epoch: 620| Step: 0
Training loss: 0.11621965648095536
Validation loss: 2.1807030693497853

Epoch: 5| Step: 1
Training loss: 0.15726997534338927
Validation loss: 2.177893086521385

Epoch: 5| Step: 2
Training loss: 0.11163911548819279
Validation loss: 2.179054636193009

Epoch: 5| Step: 3
Training loss: 0.11979761100270296
Validation loss: 2.192043539703906

Epoch: 5| Step: 4
Training loss: 0.07989855730050206
Validation loss: 2.1975867529207784

Epoch: 5| Step: 5
Training loss: 0.10955221856327652
Validation loss: 2.1858962219863667

Epoch: 5| Step: 6
Training loss: 0.11300508362672551
Validation loss: 2.171855176585984

Epoch: 5| Step: 7
Training loss: 0.19438901013605883
Validation loss: 2.1759757373309077

Epoch: 5| Step: 8
Training loss: 0.1024881281824863
Validation loss: 2.174138896851278

Epoch: 5| Step: 9
Training loss: 0.1860057377019995
Validation loss: 2.1530427441090416

Epoch: 5| Step: 10
Training loss: 0.09616479166597242
Validation loss: 2.182808069977508

Epoch: 621| Step: 0
Training loss: 0.10289919598825316
Validation loss: 2.1706810058981336

Epoch: 5| Step: 1
Training loss: 0.10539164196963088
Validation loss: 2.172527138305349

Epoch: 5| Step: 2
Training loss: 0.16280124279430644
Validation loss: 2.16324022372895

Epoch: 5| Step: 3
Training loss: 0.1323404759629214
Validation loss: 2.180691101680437

Epoch: 5| Step: 4
Training loss: 0.170336234556234
Validation loss: 2.1757434981540538

Epoch: 5| Step: 5
Training loss: 0.1395207067694775
Validation loss: 2.2017470872431977

Epoch: 5| Step: 6
Training loss: 0.06205961487833355
Validation loss: 2.194780176515581

Epoch: 5| Step: 7
Training loss: 0.11314390340690451
Validation loss: 2.18859762379397

Epoch: 5| Step: 8
Training loss: 0.10432910671175023
Validation loss: 2.1881057603694956

Epoch: 5| Step: 9
Training loss: 0.11994165294716888
Validation loss: 2.1790447154005195

Epoch: 5| Step: 10
Training loss: 0.18682846373409054
Validation loss: 2.195918617601234

Epoch: 622| Step: 0
Training loss: 0.06369790221014246
Validation loss: 2.1802931404456842

Epoch: 5| Step: 1
Training loss: 0.12197343415255826
Validation loss: 2.179019179372899

Epoch: 5| Step: 2
Training loss: 0.16123147313748415
Validation loss: 2.2072487347444207

Epoch: 5| Step: 3
Training loss: 0.09717420337553867
Validation loss: 2.2074462128816137

Epoch: 5| Step: 4
Training loss: 0.13479669185195745
Validation loss: 2.219367032042631

Epoch: 5| Step: 5
Training loss: 0.1409718025357347
Validation loss: 2.179648707857615

Epoch: 5| Step: 6
Training loss: 0.11928904387771028
Validation loss: 2.205791792461348

Epoch: 5| Step: 7
Training loss: 0.059838827188416974
Validation loss: 2.196576965847507

Epoch: 5| Step: 8
Training loss: 0.09160666848045645
Validation loss: 2.1718132917399586

Epoch: 5| Step: 9
Training loss: 0.1768569457541707
Validation loss: 2.1810359111794413

Epoch: 5| Step: 10
Training loss: 0.08033606228127342
Validation loss: 2.1855824511327806

Epoch: 623| Step: 0
Training loss: 0.10137063481784579
Validation loss: 2.1752182388621875

Epoch: 5| Step: 1
Training loss: 0.1042554392639213
Validation loss: 2.178399726374403

Epoch: 5| Step: 2
Training loss: 0.10506487713228756
Validation loss: 2.167812731656306

Epoch: 5| Step: 3
Training loss: 0.13436951681527154
Validation loss: 2.1740405999132815

Epoch: 5| Step: 4
Training loss: 0.0969984262344294
Validation loss: 2.173640681573707

Epoch: 5| Step: 5
Training loss: 0.17609958434234577
Validation loss: 2.1529827412226936

Epoch: 5| Step: 6
Training loss: 0.11553561309214423
Validation loss: 2.157885306599414

Epoch: 5| Step: 7
Training loss: 0.10970897858915042
Validation loss: 2.1681544703168245

Epoch: 5| Step: 8
Training loss: 0.06460782472441114
Validation loss: 2.1553201155030277

Epoch: 5| Step: 9
Training loss: 0.08186818559513066
Validation loss: 2.178338651927022

Epoch: 5| Step: 10
Training loss: 0.19050221162548495
Validation loss: 2.177073117213697

Epoch: 624| Step: 0
Training loss: 0.0965691039996775
Validation loss: 2.1699643031838476

Epoch: 5| Step: 1
Training loss: 0.08070150953985855
Validation loss: 2.176809503788067

Epoch: 5| Step: 2
Training loss: 0.07029639496737954
Validation loss: 2.1887744162145286

Epoch: 5| Step: 3
Training loss: 0.12172379329624451
Validation loss: 2.189536092553819

Epoch: 5| Step: 4
Training loss: 0.1066050643108102
Validation loss: 2.1831252795483405

Epoch: 5| Step: 5
Training loss: 0.08435631054941561
Validation loss: 2.20175454558043

Epoch: 5| Step: 6
Training loss: 0.1612048652694016
Validation loss: 2.173103515647528

Epoch: 5| Step: 7
Training loss: 0.09805264133047524
Validation loss: 2.194885864071029

Epoch: 5| Step: 8
Training loss: 0.0981707656490457
Validation loss: 2.1896245656454005

Epoch: 5| Step: 9
Training loss: 0.15936443513559606
Validation loss: 2.2101789746143328

Epoch: 5| Step: 10
Training loss: 0.1765597165993921
Validation loss: 2.183720015052241

Epoch: 625| Step: 0
Training loss: 0.17475996031296762
Validation loss: 2.2066274134271793

Epoch: 5| Step: 1
Training loss: 0.11156956942783437
Validation loss: 2.1833185696175113

Epoch: 5| Step: 2
Training loss: 0.1057449274655809
Validation loss: 2.1912958158516442

Epoch: 5| Step: 3
Training loss: 0.09862417239880196
Validation loss: 2.190708564881358

Epoch: 5| Step: 4
Training loss: 0.1659199326675695
Validation loss: 2.197343472103277

Epoch: 5| Step: 5
Training loss: 0.08850166583614937
Validation loss: 2.179101616546884

Epoch: 5| Step: 6
Training loss: 0.08064652995937685
Validation loss: 2.205552717789954

Epoch: 5| Step: 7
Training loss: 0.07821019415101574
Validation loss: 2.1710088854164598

Epoch: 5| Step: 8
Training loss: 0.08815111658477229
Validation loss: 2.18388833949101

Epoch: 5| Step: 9
Training loss: 0.18156538194480001
Validation loss: 2.1783235842953

Epoch: 5| Step: 10
Training loss: 0.0922225911627653
Validation loss: 2.1887052951061285

Epoch: 626| Step: 0
Training loss: 0.17513069994170855
Validation loss: 2.17030436678335

Epoch: 5| Step: 1
Training loss: 0.15726739933587747
Validation loss: 2.1825011919270643

Epoch: 5| Step: 2
Training loss: 0.11856180433628259
Validation loss: 2.1712089054811927

Epoch: 5| Step: 3
Training loss: 0.15344434325696402
Validation loss: 2.1974079103330006

Epoch: 5| Step: 4
Training loss: 0.11756224319058832
Validation loss: 2.1728244133737555

Epoch: 5| Step: 5
Training loss: 0.07238041292712324
Validation loss: 2.178245723592744

Epoch: 5| Step: 6
Training loss: 0.05729148424003919
Validation loss: 2.1874891667603182

Epoch: 5| Step: 7
Training loss: 0.0816763227162855
Validation loss: 2.1626238076018844

Epoch: 5| Step: 8
Training loss: 0.09532383769251145
Validation loss: 2.14455383397674

Epoch: 5| Step: 9
Training loss: 0.09398396424531164
Validation loss: 2.168239776925968

Epoch: 5| Step: 10
Training loss: 0.06223270883396149
Validation loss: 2.1607709633546106

Epoch: 627| Step: 0
Training loss: 0.11947353939561273
Validation loss: 2.1979114590923197

Epoch: 5| Step: 1
Training loss: 0.1738546383386396
Validation loss: 2.1844622284789654

Epoch: 5| Step: 2
Training loss: 0.16233916828750508
Validation loss: 2.174490911609119

Epoch: 5| Step: 3
Training loss: 0.19102289774960704
Validation loss: 2.1916600483386146

Epoch: 5| Step: 4
Training loss: 0.06696244433119246
Validation loss: 2.184275594920515

Epoch: 5| Step: 5
Training loss: 0.1059789063686256
Validation loss: 2.1854759755457582

Epoch: 5| Step: 6
Training loss: 0.09240391068953255
Validation loss: 2.1724503856348023

Epoch: 5| Step: 7
Training loss: 0.07132478694166103
Validation loss: 2.1565109268640943

Epoch: 5| Step: 8
Training loss: 0.10778173512188974
Validation loss: 2.2074399653344554

Epoch: 5| Step: 9
Training loss: 0.07964627775151754
Validation loss: 2.160087792793568

Epoch: 5| Step: 10
Training loss: 0.11132642677751914
Validation loss: 2.189225803156121

Epoch: 628| Step: 0
Training loss: 0.06755392145552126
Validation loss: 2.177533864147826

Epoch: 5| Step: 1
Training loss: 0.18944712757174115
Validation loss: 2.1800319837384183

Epoch: 5| Step: 2
Training loss: 0.0977675280764517
Validation loss: 2.1677853198591355

Epoch: 5| Step: 3
Training loss: 0.09030325147600984
Validation loss: 2.1786459792143478

Epoch: 5| Step: 4
Training loss: 0.09897726174909317
Validation loss: 2.185191960534097

Epoch: 5| Step: 5
Training loss: 0.13646786695281565
Validation loss: 2.1670307519278325

Epoch: 5| Step: 6
Training loss: 0.18732740485224503
Validation loss: 2.18497604810912

Epoch: 5| Step: 7
Training loss: 0.10128361209544283
Validation loss: 2.1750440561719206

Epoch: 5| Step: 8
Training loss: 0.06013269621295249
Validation loss: 2.1750823646898225

Epoch: 5| Step: 9
Training loss: 0.09333385553685768
Validation loss: 2.165144245465753

Epoch: 5| Step: 10
Training loss: 0.0975266072910885
Validation loss: 2.1631614142079174

Epoch: 629| Step: 0
Training loss: 0.186116618745911
Validation loss: 2.177678611244119

Epoch: 5| Step: 1
Training loss: 0.0974385409718587
Validation loss: 2.211678294780215

Epoch: 5| Step: 2
Training loss: 0.06748387111472168
Validation loss: 2.1657610628383432

Epoch: 5| Step: 3
Training loss: 0.06391073442618077
Validation loss: 2.1781417358996498

Epoch: 5| Step: 4
Training loss: 0.15001223385115514
Validation loss: 2.169942076412633

Epoch: 5| Step: 5
Training loss: 0.09500718580537565
Validation loss: 2.1693407891510788

Epoch: 5| Step: 6
Training loss: 0.05712822563222412
Validation loss: 2.1760919861981525

Epoch: 5| Step: 7
Training loss: 0.13227609695465659
Validation loss: 2.1632236768060147

Epoch: 5| Step: 8
Training loss: 0.09708422497805794
Validation loss: 2.171595931078783

Epoch: 5| Step: 9
Training loss: 0.10395703580418626
Validation loss: 2.1908565078312425

Epoch: 5| Step: 10
Training loss: 0.17416555892745686
Validation loss: 2.195547562569161

Epoch: 630| Step: 0
Training loss: 0.08295513052068972
Validation loss: 2.188436185380092

Epoch: 5| Step: 1
Training loss: 0.15120746430192594
Validation loss: 2.166687655485295

Epoch: 5| Step: 2
Training loss: 0.14007228606182276
Validation loss: 2.164792807854324

Epoch: 5| Step: 3
Training loss: 0.10831243092902876
Validation loss: 2.1760360507602705

Epoch: 5| Step: 4
Training loss: 0.10347284476664001
Validation loss: 2.196550354476669

Epoch: 5| Step: 5
Training loss: 0.13561573588026585
Validation loss: 2.1822240182025037

Epoch: 5| Step: 6
Training loss: 0.08127162237578035
Validation loss: 2.1921553524021484

Epoch: 5| Step: 7
Training loss: 0.14253734632542492
Validation loss: 2.1866211639076756

Epoch: 5| Step: 8
Training loss: 0.05110777132103843
Validation loss: 2.2056593260576727

Epoch: 5| Step: 9
Training loss: 0.11803781843252555
Validation loss: 2.1900729305342943

Epoch: 5| Step: 10
Training loss: 0.10076243461506915
Validation loss: 2.1630517869353176

Epoch: 631| Step: 0
Training loss: 0.09385886924198422
Validation loss: 2.1714163114587097

Epoch: 5| Step: 1
Training loss: 0.1539047062017014
Validation loss: 2.199375566723644

Epoch: 5| Step: 2
Training loss: 0.13393251010234875
Validation loss: 2.178799571594471

Epoch: 5| Step: 3
Training loss: 0.13024900913685342
Validation loss: 2.1930047064056124

Epoch: 5| Step: 4
Training loss: 0.15420893686219056
Validation loss: 2.2065623928164806

Epoch: 5| Step: 5
Training loss: 0.07965208907687887
Validation loss: 2.1957743805524212

Epoch: 5| Step: 6
Training loss: 0.07465560239923758
Validation loss: 2.2079178072273136

Epoch: 5| Step: 7
Training loss: 0.09063766428000457
Validation loss: 2.1900551049733603

Epoch: 5| Step: 8
Training loss: 0.06544113770687528
Validation loss: 2.2046886682087576

Epoch: 5| Step: 9
Training loss: 0.08799712298611737
Validation loss: 2.1454617992757066

Epoch: 5| Step: 10
Training loss: 0.11361502933452547
Validation loss: 2.188261017508862

Epoch: 632| Step: 0
Training loss: 0.1642766928056123
Validation loss: 2.1636971846185724

Epoch: 5| Step: 1
Training loss: 0.07801021547871398
Validation loss: 2.1714555446411667

Epoch: 5| Step: 2
Training loss: 0.16861333368274728
Validation loss: 2.1601893657896403

Epoch: 5| Step: 3
Training loss: 0.1057524221742602
Validation loss: 2.161863141799351

Epoch: 5| Step: 4
Training loss: 0.13293995071325856
Validation loss: 2.1581417385523785

Epoch: 5| Step: 5
Training loss: 0.07068848748196138
Validation loss: 2.127978235085412

Epoch: 5| Step: 6
Training loss: 0.09009602621089571
Validation loss: 2.159149084069425

Epoch: 5| Step: 7
Training loss: 0.11953579139808748
Validation loss: 2.149304403775152

Epoch: 5| Step: 8
Training loss: 0.08915517068150107
Validation loss: 2.1584531880564812

Epoch: 5| Step: 9
Training loss: 0.13559710344272166
Validation loss: 2.1544533607463

Epoch: 5| Step: 10
Training loss: 0.14641566890516988
Validation loss: 2.154215691399099

Epoch: 633| Step: 0
Training loss: 0.08447267003141963
Validation loss: 2.161438763487005

Epoch: 5| Step: 1
Training loss: 0.07355490364897861
Validation loss: 2.156584932584961

Epoch: 5| Step: 2
Training loss: 0.1106540281928634
Validation loss: 2.150889134547716

Epoch: 5| Step: 3
Training loss: 0.07590741011238342
Validation loss: 2.1518814099237247

Epoch: 5| Step: 4
Training loss: 0.13869242448732472
Validation loss: 2.1575579713379196

Epoch: 5| Step: 5
Training loss: 0.0861333003646632
Validation loss: 2.174829401895951

Epoch: 5| Step: 6
Training loss: 0.10194745833627562
Validation loss: 2.1709897195101013

Epoch: 5| Step: 7
Training loss: 0.07073892982940133
Validation loss: 2.159439073782634

Epoch: 5| Step: 8
Training loss: 0.17021859231083294
Validation loss: 2.165295166416799

Epoch: 5| Step: 9
Training loss: 0.08914605600560736
Validation loss: 2.1832805359524934

Epoch: 5| Step: 10
Training loss: 0.16717303672513087
Validation loss: 2.176797236772486

Epoch: 634| Step: 0
Training loss: 0.08445769657126842
Validation loss: 2.165546917293058

Epoch: 5| Step: 1
Training loss: 0.08392453834371491
Validation loss: 2.17632981268355

Epoch: 5| Step: 2
Training loss: 0.13781036818622272
Validation loss: 2.1729397757933286

Epoch: 5| Step: 3
Training loss: 0.06427574313363636
Validation loss: 2.1755527234859886

Epoch: 5| Step: 4
Training loss: 0.07852477369100519
Validation loss: 2.170346992430202

Epoch: 5| Step: 5
Training loss: 0.07932108277035438
Validation loss: 2.2006000963005627

Epoch: 5| Step: 6
Training loss: 0.10488605245633095
Validation loss: 2.194635912831277

Epoch: 5| Step: 7
Training loss: 0.15979407810267468
Validation loss: 2.1824269408588766

Epoch: 5| Step: 8
Training loss: 0.09986407776725134
Validation loss: 2.1897808167568362

Epoch: 5| Step: 9
Training loss: 0.10515124602407148
Validation loss: 2.185394669485054

Epoch: 5| Step: 10
Training loss: 0.1781821636028405
Validation loss: 2.183010409293889

Epoch: 635| Step: 0
Training loss: 0.09025673692396369
Validation loss: 2.1903731151595687

Epoch: 5| Step: 1
Training loss: 0.10340194037614085
Validation loss: 2.188938997726235

Epoch: 5| Step: 2
Training loss: 0.10625974421136776
Validation loss: 2.1816629223627806

Epoch: 5| Step: 3
Training loss: 0.17020008725728333
Validation loss: 2.170306653654137

Epoch: 5| Step: 4
Training loss: 0.06937470158413979
Validation loss: 2.170568812180318

Epoch: 5| Step: 5
Training loss: 0.07776188806799082
Validation loss: 2.2125794824860954

Epoch: 5| Step: 6
Training loss: 0.07812765832193026
Validation loss: 2.1520919448535234

Epoch: 5| Step: 7
Training loss: 0.1962333524227646
Validation loss: 2.1821002242359335

Epoch: 5| Step: 8
Training loss: 0.10668792112459537
Validation loss: 2.172669881479601

Epoch: 5| Step: 9
Training loss: 0.08708195329567764
Validation loss: 2.1516989817211467

Epoch: 5| Step: 10
Training loss: 0.16196286808412824
Validation loss: 2.164775317107315

Epoch: 636| Step: 0
Training loss: 0.08874785092431525
Validation loss: 2.1594395041349648

Epoch: 5| Step: 1
Training loss: 0.09920119821188694
Validation loss: 2.163450724502236

Epoch: 5| Step: 2
Training loss: 0.11026863763344344
Validation loss: 2.1751881804793762

Epoch: 5| Step: 3
Training loss: 0.10172621205202662
Validation loss: 2.1690712344664003

Epoch: 5| Step: 4
Training loss: 0.10174378391733735
Validation loss: 2.1637822664941146

Epoch: 5| Step: 5
Training loss: 0.08501192185473579
Validation loss: 2.1696674243553993

Epoch: 5| Step: 6
Training loss: 0.0837567899704009
Validation loss: 2.184981141414851

Epoch: 5| Step: 7
Training loss: 0.11477922813396202
Validation loss: 2.165734170475942

Epoch: 5| Step: 8
Training loss: 0.17047503747367643
Validation loss: 2.1471035419911177

Epoch: 5| Step: 9
Training loss: 0.17785104129412427
Validation loss: 2.1413095923121017

Epoch: 5| Step: 10
Training loss: 0.17844141246027126
Validation loss: 2.1632463322816915

Epoch: 637| Step: 0
Training loss: 0.08085134288958169
Validation loss: 2.155514549323015

Epoch: 5| Step: 1
Training loss: 0.07823590512890702
Validation loss: 2.123658904356102

Epoch: 5| Step: 2
Training loss: 0.17700702528427667
Validation loss: 2.1430681366232034

Epoch: 5| Step: 3
Training loss: 0.1259426914191045
Validation loss: 2.1367144595017225

Epoch: 5| Step: 4
Training loss: 0.10729817724458401
Validation loss: 2.1509999221969784

Epoch: 5| Step: 5
Training loss: 0.07364374390769382
Validation loss: 2.167606492666588

Epoch: 5| Step: 6
Training loss: 0.0842763405626337
Validation loss: 2.151898885743538

Epoch: 5| Step: 7
Training loss: 0.0754414129156958
Validation loss: 2.149472424881787

Epoch: 5| Step: 8
Training loss: 0.09899475238961368
Validation loss: 2.1523181115798624

Epoch: 5| Step: 9
Training loss: 0.17507764081705016
Validation loss: 2.1643798057672394

Epoch: 5| Step: 10
Training loss: 0.10720236197693385
Validation loss: 2.14059005995019

Epoch: 638| Step: 0
Training loss: 0.10641390660896755
Validation loss: 2.1613909366288975

Epoch: 5| Step: 1
Training loss: 0.14368648058615544
Validation loss: 2.1503022568340295

Epoch: 5| Step: 2
Training loss: 0.0870697256267856
Validation loss: 2.1677725228183284

Epoch: 5| Step: 3
Training loss: 0.1582986402043228
Validation loss: 2.169039097879523

Epoch: 5| Step: 4
Training loss: 0.14383709953609064
Validation loss: 2.1778311614988572

Epoch: 5| Step: 5
Training loss: 0.1720212509235982
Validation loss: 2.191248053350199

Epoch: 5| Step: 6
Training loss: 0.10095701932399663
Validation loss: 2.1532776346433353

Epoch: 5| Step: 7
Training loss: 0.11190051035022135
Validation loss: 2.1644051363754597

Epoch: 5| Step: 8
Training loss: 0.11426228734570337
Validation loss: 2.1648668886812965

Epoch: 5| Step: 9
Training loss: 0.10022462375212945
Validation loss: 2.171417834471705

Epoch: 5| Step: 10
Training loss: 0.0675223846925036
Validation loss: 2.1467221509340866

Epoch: 639| Step: 0
Training loss: 0.053348178882752444
Validation loss: 2.169201043868201

Epoch: 5| Step: 1
Training loss: 0.1455766655763927
Validation loss: 2.1704152819656946

Epoch: 5| Step: 2
Training loss: 0.1525441709827949
Validation loss: 2.1663396483430994

Epoch: 5| Step: 3
Training loss: 0.18098774344151727
Validation loss: 2.1503819841026472

Epoch: 5| Step: 4
Training loss: 0.1300039873405743
Validation loss: 2.187616147123587

Epoch: 5| Step: 5
Training loss: 0.10684670876944179
Validation loss: 2.173918565227706

Epoch: 5| Step: 6
Training loss: 0.14502817507071028
Validation loss: 2.1729712302906194

Epoch: 5| Step: 7
Training loss: 0.09571323535998393
Validation loss: 2.182114878091849

Epoch: 5| Step: 8
Training loss: 0.11352708876785632
Validation loss: 2.160725738777225

Epoch: 5| Step: 9
Training loss: 0.1057330546188835
Validation loss: 2.1763031693051014

Epoch: 5| Step: 10
Training loss: 0.1069579989309858
Validation loss: 2.214417691882912

Epoch: 640| Step: 0
Training loss: 0.0906081901366914
Validation loss: 2.1643121134937253

Epoch: 5| Step: 1
Training loss: 0.09386771480937646
Validation loss: 2.203057612093464

Epoch: 5| Step: 2
Training loss: 0.08727069081874371
Validation loss: 2.1818055613381304

Epoch: 5| Step: 3
Training loss: 0.1230526574607783
Validation loss: 2.208610284155347

Epoch: 5| Step: 4
Training loss: 0.07602042339368532
Validation loss: 2.1987170980168456

Epoch: 5| Step: 5
Training loss: 0.1204588342301539
Validation loss: 2.1788775828167264

Epoch: 5| Step: 6
Training loss: 0.19259833835271736
Validation loss: 2.1849886294092276

Epoch: 5| Step: 7
Training loss: 0.18955503259496984
Validation loss: 2.1875412663143328

Epoch: 5| Step: 8
Training loss: 0.09114496083069042
Validation loss: 2.19646287232705

Epoch: 5| Step: 9
Training loss: 0.0997025390718978
Validation loss: 2.1651766349313473

Epoch: 5| Step: 10
Training loss: 0.14333846228131747
Validation loss: 2.167812675187479

Epoch: 641| Step: 0
Training loss: 0.1232035789529762
Validation loss: 2.180337342742935

Epoch: 5| Step: 1
Training loss: 0.142884428401964
Validation loss: 2.1718942708196067

Epoch: 5| Step: 2
Training loss: 0.17545677012534028
Validation loss: 2.14788611204232

Epoch: 5| Step: 3
Training loss: 0.10826717625845968
Validation loss: 2.164967370662571

Epoch: 5| Step: 4
Training loss: 0.099864171026225
Validation loss: 2.1702017362511468

Epoch: 5| Step: 5
Training loss: 0.19710877291798726
Validation loss: 2.131980268151517

Epoch: 5| Step: 6
Training loss: 0.09901271024606288
Validation loss: 2.1272365194033984

Epoch: 5| Step: 7
Training loss: 0.10838527427687206
Validation loss: 2.1470345184549102

Epoch: 5| Step: 8
Training loss: 0.16862186163045373
Validation loss: 2.1420952729998692

Epoch: 5| Step: 9
Training loss: 0.1489001830567278
Validation loss: 2.1385632777927874

Epoch: 5| Step: 10
Training loss: 0.1061914286035483
Validation loss: 2.172974641048736

Epoch: 642| Step: 0
Training loss: 0.14099122414857215
Validation loss: 2.167168081997586

Epoch: 5| Step: 1
Training loss: 0.15738052624982596
Validation loss: 2.165750135359483

Epoch: 5| Step: 2
Training loss: 0.09512167064276723
Validation loss: 2.16167620852981

Epoch: 5| Step: 3
Training loss: 0.12617124994317996
Validation loss: 2.161895854349072

Epoch: 5| Step: 4
Training loss: 0.08384460640049415
Validation loss: 2.1587329908028017

Epoch: 5| Step: 5
Training loss: 0.18316269044042888
Validation loss: 2.1723557172834194

Epoch: 5| Step: 6
Training loss: 0.11302160646976947
Validation loss: 2.1796300636957415

Epoch: 5| Step: 7
Training loss: 0.17146441336956994
Validation loss: 2.1748982850438625

Epoch: 5| Step: 8
Training loss: 0.11568601647924595
Validation loss: 2.1699893721945025

Epoch: 5| Step: 9
Training loss: 0.11743041531563957
Validation loss: 2.2013374494396976

Epoch: 5| Step: 10
Training loss: 0.09272324057357681
Validation loss: 2.1876857040030515

Epoch: 643| Step: 0
Training loss: 0.15674358727336302
Validation loss: 2.197814255123624

Epoch: 5| Step: 1
Training loss: 0.11783169275124855
Validation loss: 2.184679917262641

Epoch: 5| Step: 2
Training loss: 0.2084320559641432
Validation loss: 2.189225543188303

Epoch: 5| Step: 3
Training loss: 0.09940753851657773
Validation loss: 2.2053630216138647

Epoch: 5| Step: 4
Training loss: 0.0891609524025943
Validation loss: 2.1890114995680343

Epoch: 5| Step: 5
Training loss: 0.08532845000882885
Validation loss: 2.1976728047925937

Epoch: 5| Step: 6
Training loss: 0.09642801376085645
Validation loss: 2.1933119756534474

Epoch: 5| Step: 7
Training loss: 0.10061150290763729
Validation loss: 2.1570021432295285

Epoch: 5| Step: 8
Training loss: 0.09899614473383804
Validation loss: 2.1511315124367414

Epoch: 5| Step: 9
Training loss: 0.0816791932708149
Validation loss: 2.1651921892212864

Epoch: 5| Step: 10
Training loss: 0.1629344670782014
Validation loss: 2.1641813110608283

Epoch: 644| Step: 0
Training loss: 0.08990019600751914
Validation loss: 2.1308307794858186

Epoch: 5| Step: 1
Training loss: 0.14375446976056555
Validation loss: 2.132873337761561

Epoch: 5| Step: 2
Training loss: 0.10634459534050428
Validation loss: 2.1582269794491613

Epoch: 5| Step: 3
Training loss: 0.09854938737011369
Validation loss: 2.171956461307325

Epoch: 5| Step: 4
Training loss: 0.12145129992405586
Validation loss: 2.1641620290135575

Epoch: 5| Step: 5
Training loss: 0.0712192892878118
Validation loss: 2.172813178075166

Epoch: 5| Step: 6
Training loss: 0.09919112883595756
Validation loss: 2.1808798987048603

Epoch: 5| Step: 7
Training loss: 0.16498072569429575
Validation loss: 2.1813691317744452

Epoch: 5| Step: 8
Training loss: 0.14352992875819728
Validation loss: 2.158268564338615

Epoch: 5| Step: 9
Training loss: 0.06944742440578543
Validation loss: 2.169195644051215

Epoch: 5| Step: 10
Training loss: 0.1730768545888802
Validation loss: 2.153362201678254

Epoch: 645| Step: 0
Training loss: 0.1963787158794185
Validation loss: 2.1840279126793427

Epoch: 5| Step: 1
Training loss: 0.07050483279919464
Validation loss: 2.16667682497027

Epoch: 5| Step: 2
Training loss: 0.16436361880843117
Validation loss: 2.217348832858499

Epoch: 5| Step: 3
Training loss: 0.1125789692997295
Validation loss: 2.1806138616090314

Epoch: 5| Step: 4
Training loss: 0.1616369337634859
Validation loss: 2.187316740654147

Epoch: 5| Step: 5
Training loss: 0.16885676847528588
Validation loss: 2.210938077444125

Epoch: 5| Step: 6
Training loss: 0.1107741678069771
Validation loss: 2.187915073515688

Epoch: 5| Step: 7
Training loss: 0.08408149659255967
Validation loss: 2.16203303035152

Epoch: 5| Step: 8
Training loss: 0.10652457357289707
Validation loss: 2.1615098405718536

Epoch: 5| Step: 9
Training loss: 0.16408195266748996
Validation loss: 2.179890677593604

Epoch: 5| Step: 10
Training loss: 0.10053191076606406
Validation loss: 2.167951566906515

Epoch: 646| Step: 0
Training loss: 0.1675707515348166
Validation loss: 2.1571370815132607

Epoch: 5| Step: 1
Training loss: 0.20760530382168088
Validation loss: 2.1618099689162436

Epoch: 5| Step: 2
Training loss: 0.15526943081658642
Validation loss: 2.157646736228716

Epoch: 5| Step: 3
Training loss: 0.13265721976753608
Validation loss: 2.143100171900998

Epoch: 5| Step: 4
Training loss: 0.16160350023840972
Validation loss: 2.1617355319167033

Epoch: 5| Step: 5
Training loss: 0.08883815857174979
Validation loss: 2.162691868034059

Epoch: 5| Step: 6
Training loss: 0.1347149601666302
Validation loss: 2.1583667475390107

Epoch: 5| Step: 7
Training loss: 0.16020608336026618
Validation loss: 2.1513327478322934

Epoch: 5| Step: 8
Training loss: 0.15115040668567858
Validation loss: 2.1637014121329012

Epoch: 5| Step: 9
Training loss: 0.11460553752452823
Validation loss: 2.1553564825607956

Epoch: 5| Step: 10
Training loss: 0.1342101327707782
Validation loss: 2.15576349304176

Epoch: 647| Step: 0
Training loss: 0.13390472035107434
Validation loss: 2.168642398847919

Epoch: 5| Step: 1
Training loss: 0.1509026875935491
Validation loss: 2.1578897201403895

Epoch: 5| Step: 2
Training loss: 0.20688236028998472
Validation loss: 2.1918402880228642

Epoch: 5| Step: 3
Training loss: 0.2044102921038856
Validation loss: 2.175258316845523

Epoch: 5| Step: 4
Training loss: 0.08678972533708865
Validation loss: 2.1435215160180143

Epoch: 5| Step: 5
Training loss: 0.1537193584437852
Validation loss: 2.1875989173756145

Epoch: 5| Step: 6
Training loss: 0.11441137313938006
Validation loss: 2.1615677886026567

Epoch: 5| Step: 7
Training loss: 0.14471222527205965
Validation loss: 2.1698351033103527

Epoch: 5| Step: 8
Training loss: 0.2549211173670292
Validation loss: 2.1806552335471694

Epoch: 5| Step: 9
Training loss: 0.09797607977763191
Validation loss: 2.1674711833588702

Epoch: 5| Step: 10
Training loss: 0.19643900254500554
Validation loss: 2.1845801501101403

Epoch: 648| Step: 0
Training loss: 0.19014293893632894
Validation loss: 2.179738210316902

Epoch: 5| Step: 1
Training loss: 0.14808262265096922
Validation loss: 2.1652865923980613

Epoch: 5| Step: 2
Training loss: 0.1731135758614092
Validation loss: 2.1743927694134824

Epoch: 5| Step: 3
Training loss: 0.1491446091173215
Validation loss: 2.174202608458321

Epoch: 5| Step: 4
Training loss: 0.14827366621603907
Validation loss: 2.165736230753913

Epoch: 5| Step: 5
Training loss: 0.13219914736736094
Validation loss: 2.1685115596960203

Epoch: 5| Step: 6
Training loss: 0.10113273069541219
Validation loss: 2.190752164423556

Epoch: 5| Step: 7
Training loss: 0.1185632810981672
Validation loss: 2.1575253617458583

Epoch: 5| Step: 8
Training loss: 0.23209717453022022
Validation loss: 2.1690930242912416

Epoch: 5| Step: 9
Training loss: 0.14065050847442692
Validation loss: 2.1729833224716923

Epoch: 5| Step: 10
Training loss: 0.21818389187738568
Validation loss: 2.1422458515585334

Epoch: 649| Step: 0
Training loss: 0.15204663525210527
Validation loss: 2.168915672779546

Epoch: 5| Step: 1
Training loss: 0.17192192412440446
Validation loss: 2.1537209538484623

Epoch: 5| Step: 2
Training loss: 0.1614181881392083
Validation loss: 2.1489198180959406

Epoch: 5| Step: 3
Training loss: 0.15683965880467232
Validation loss: 2.159154297666079

Epoch: 5| Step: 4
Training loss: 0.26114480583821614
Validation loss: 2.172862765154385

Epoch: 5| Step: 5
Training loss: 0.14000407863321193
Validation loss: 2.18288049065165

Epoch: 5| Step: 6
Training loss: 0.1542304173532669
Validation loss: 2.1761173074114866

Epoch: 5| Step: 7
Training loss: 0.13344845957942503
Validation loss: 2.1820170973096116

Epoch: 5| Step: 8
Training loss: 0.1384061362558269
Validation loss: 2.170884825081407

Epoch: 5| Step: 9
Training loss: 0.22177240558536984
Validation loss: 2.19592290391555

Epoch: 5| Step: 10
Training loss: 0.08729641638369558
Validation loss: 2.2021220576049116

Epoch: 650| Step: 0
Training loss: 0.16598691131009957
Validation loss: 2.195869580355921

Epoch: 5| Step: 1
Training loss: 0.14347648436775023
Validation loss: 2.1705949950519865

Epoch: 5| Step: 2
Training loss: 0.1897300682034584
Validation loss: 2.170447766402071

Epoch: 5| Step: 3
Training loss: 0.18746103438168005
Validation loss: 2.2027961335975643

Epoch: 5| Step: 4
Training loss: 0.14873011508230838
Validation loss: 2.1822257891878185

Epoch: 5| Step: 5
Training loss: 0.18379719601672612
Validation loss: 2.1692911144735

Epoch: 5| Step: 6
Training loss: 0.11542207173172815
Validation loss: 2.149017643465096

Epoch: 5| Step: 7
Training loss: 0.14793703765579325
Validation loss: 2.186594065865624

Epoch: 5| Step: 8
Training loss: 0.11508762989168408
Validation loss: 2.157682167022273

Epoch: 5| Step: 9
Training loss: 0.13021301658473336
Validation loss: 2.196944810715623

Epoch: 5| Step: 10
Training loss: 0.19268376391386668
Validation loss: 2.203964451653719

Epoch: 651| Step: 0
Training loss: 0.17396112775747238
Validation loss: 2.167175192076814

Epoch: 5| Step: 1
Training loss: 0.16350428666319514
Validation loss: 2.180718082039773

Epoch: 5| Step: 2
Training loss: 0.1461454029874477
Validation loss: 2.1940753410964438

Epoch: 5| Step: 3
Training loss: 0.1266137354953279
Validation loss: 2.172059707949659

Epoch: 5| Step: 4
Training loss: 0.11937079708704505
Validation loss: 2.1621160624095226

Epoch: 5| Step: 5
Training loss: 0.1434825599241558
Validation loss: 2.1788118423385727

Epoch: 5| Step: 6
Training loss: 0.16820626321922316
Validation loss: 2.1801611167123216

Epoch: 5| Step: 7
Training loss: 0.07707036872954524
Validation loss: 2.2010581675810137

Epoch: 5| Step: 8
Training loss: 0.0996764088383049
Validation loss: 2.183423750839326

Epoch: 5| Step: 9
Training loss: 0.12129984514402677
Validation loss: 2.1600759815044883

Epoch: 5| Step: 10
Training loss: 0.12012550278701316
Validation loss: 2.174412431749642

Epoch: 652| Step: 0
Training loss: 0.0863487201824448
Validation loss: 2.1662851596053283

Epoch: 5| Step: 1
Training loss: 0.1290606960650862
Validation loss: 2.1665593405457075

Epoch: 5| Step: 2
Training loss: 0.14378477329032258
Validation loss: 2.1659263739584915

Epoch: 5| Step: 3
Training loss: 0.15569229133266901
Validation loss: 2.157985274356245

Epoch: 5| Step: 4
Training loss: 0.16388118465873713
Validation loss: 2.1527052436312037

Epoch: 5| Step: 5
Training loss: 0.18444987813248076
Validation loss: 2.1520902372218775

Epoch: 5| Step: 6
Training loss: 0.18719547098730277
Validation loss: 2.148115930440691

Epoch: 5| Step: 7
Training loss: 0.1161199702525072
Validation loss: 2.1562151877084035

Epoch: 5| Step: 8
Training loss: 0.1378964922686022
Validation loss: 2.1748437852952036

Epoch: 5| Step: 9
Training loss: 0.18928317676563017
Validation loss: 2.1849642739740602

Epoch: 5| Step: 10
Training loss: 0.12288086910046161
Validation loss: 2.176991740205353

Epoch: 653| Step: 0
Training loss: 0.1114931347659526
Validation loss: 2.1778738105140967

Epoch: 5| Step: 1
Training loss: 0.08787333000408645
Validation loss: 2.196733447164662

Epoch: 5| Step: 2
Training loss: 0.14832935032448433
Validation loss: 2.1826311719072518

Epoch: 5| Step: 3
Training loss: 0.11731910865264099
Validation loss: 2.217986809122071

Epoch: 5| Step: 4
Training loss: 0.12830177823575242
Validation loss: 2.2085421082927605

Epoch: 5| Step: 5
Training loss: 0.13717822115199316
Validation loss: 2.218926700740964

Epoch: 5| Step: 6
Training loss: 0.1755806095727954
Validation loss: 2.2198062804798524

Epoch: 5| Step: 7
Training loss: 0.18772810729855416
Validation loss: 2.214150638863719

Epoch: 5| Step: 8
Training loss: 0.09504405623556152
Validation loss: 2.189639861091393

Epoch: 5| Step: 9
Training loss: 0.1170969851927282
Validation loss: 2.1984033763525797

Epoch: 5| Step: 10
Training loss: 0.18430498013981111
Validation loss: 2.1971992924201986

Epoch: 654| Step: 0
Training loss: 0.09421353188104364
Validation loss: 2.2001346391718646

Epoch: 5| Step: 1
Training loss: 0.12669492287054568
Validation loss: 2.1681497844335276

Epoch: 5| Step: 2
Training loss: 0.20292815427228475
Validation loss: 2.1988388546776654

Epoch: 5| Step: 3
Training loss: 0.16344849038962925
Validation loss: 2.200607035016976

Epoch: 5| Step: 4
Training loss: 0.11938168808416477
Validation loss: 2.1710238951769862

Epoch: 5| Step: 5
Training loss: 0.09639543592462321
Validation loss: 2.1832272420889725

Epoch: 5| Step: 6
Training loss: 0.07123143009010899
Validation loss: 2.186132645322315

Epoch: 5| Step: 7
Training loss: 0.14364674270052502
Validation loss: 2.1901760228290263

Epoch: 5| Step: 8
Training loss: 0.10710683489207565
Validation loss: 2.1791792496177718

Epoch: 5| Step: 9
Training loss: 0.0848118938132376
Validation loss: 2.1845584613657314

Epoch: 5| Step: 10
Training loss: 0.10703602331196009
Validation loss: 2.171527307382655

Epoch: 655| Step: 0
Training loss: 0.09995447944419933
Validation loss: 2.191602488900329

Epoch: 5| Step: 1
Training loss: 0.10716011493423283
Validation loss: 2.181520363373305

Epoch: 5| Step: 2
Training loss: 0.08153163808347923
Validation loss: 2.18372524864271

Epoch: 5| Step: 3
Training loss: 0.11665325376845904
Validation loss: 2.177502316619118

Epoch: 5| Step: 4
Training loss: 0.1791349602430401
Validation loss: 2.1609647940297187

Epoch: 5| Step: 5
Training loss: 0.12114329247531204
Validation loss: 2.178664340563685

Epoch: 5| Step: 6
Training loss: 0.11153048812037364
Validation loss: 2.1705308049097614

Epoch: 5| Step: 7
Training loss: 0.12981087262653837
Validation loss: 2.1594350617076095

Epoch: 5| Step: 8
Training loss: 0.16703922323175752
Validation loss: 2.192121941810436

Epoch: 5| Step: 9
Training loss: 0.15436017874562422
Validation loss: 2.19320721809347

Epoch: 5| Step: 10
Training loss: 0.1431287297758178
Validation loss: 2.1920485195180515

Epoch: 656| Step: 0
Training loss: 0.12983716435033268
Validation loss: 2.158218829624431

Epoch: 5| Step: 1
Training loss: 0.11793437813865713
Validation loss: 2.1547282732897273

Epoch: 5| Step: 2
Training loss: 0.1896262213819142
Validation loss: 2.176212532492899

Epoch: 5| Step: 3
Training loss: 0.1312050523883264
Validation loss: 2.1812367042168956

Epoch: 5| Step: 4
Training loss: 0.06308852580166951
Validation loss: 2.2064026325300166

Epoch: 5| Step: 5
Training loss: 0.1219217846400889
Validation loss: 2.1912426388360813

Epoch: 5| Step: 6
Training loss: 0.0796837749732531
Validation loss: 2.1792796434024577

Epoch: 5| Step: 7
Training loss: 0.16756950658586367
Validation loss: 2.18042096168349

Epoch: 5| Step: 8
Training loss: 0.07255897393518503
Validation loss: 2.1878670227796744

Epoch: 5| Step: 9
Training loss: 0.13603006341058693
Validation loss: 2.1784558435450285

Epoch: 5| Step: 10
Training loss: 0.09954093938342004
Validation loss: 2.154087743025235

Epoch: 657| Step: 0
Training loss: 0.11667057308258909
Validation loss: 2.1752192323940194

Epoch: 5| Step: 1
Training loss: 0.13036061362672918
Validation loss: 2.1681676014960156

Epoch: 5| Step: 2
Training loss: 0.12561001050066822
Validation loss: 2.184417730575958

Epoch: 5| Step: 3
Training loss: 0.16063970773058592
Validation loss: 2.1999366652320638

Epoch: 5| Step: 4
Training loss: 0.10280719848489574
Validation loss: 2.1916625620772625

Epoch: 5| Step: 5
Training loss: 0.10188660808554736
Validation loss: 2.1677793559579177

Epoch: 5| Step: 6
Training loss: 0.08379901068880603
Validation loss: 2.1679727445087256

Epoch: 5| Step: 7
Training loss: 0.18530735819278493
Validation loss: 2.1551800838138786

Epoch: 5| Step: 8
Training loss: 0.1929257858570797
Validation loss: 2.1979519595743904

Epoch: 5| Step: 9
Training loss: 0.14844465238505603
Validation loss: 2.184552601638927

Epoch: 5| Step: 10
Training loss: 0.1144992364426936
Validation loss: 2.177708094319784

Epoch: 658| Step: 0
Training loss: 0.1196815336037595
Validation loss: 2.1693048154810093

Epoch: 5| Step: 1
Training loss: 0.17208593602863903
Validation loss: 2.167751478079515

Epoch: 5| Step: 2
Training loss: 0.11495810462787305
Validation loss: 2.1835658034049095

Epoch: 5| Step: 3
Training loss: 0.09913840401117897
Validation loss: 2.163639544812016

Epoch: 5| Step: 4
Training loss: 0.15047800943716666
Validation loss: 2.1840041997647095

Epoch: 5| Step: 5
Training loss: 0.11761592197275819
Validation loss: 2.1893185774925907

Epoch: 5| Step: 6
Training loss: 0.10849415788545821
Validation loss: 2.1801313963506495

Epoch: 5| Step: 7
Training loss: 0.18822357513181273
Validation loss: 2.1818127576673803

Epoch: 5| Step: 8
Training loss: 0.13661355331149916
Validation loss: 2.207476820322985

Epoch: 5| Step: 9
Training loss: 0.08023656603914701
Validation loss: 2.202245327060184

Epoch: 5| Step: 10
Training loss: 0.17216839998551497
Validation loss: 2.221494057865175

Epoch: 659| Step: 0
Training loss: 0.14512594409671684
Validation loss: 2.1916839082693893

Epoch: 5| Step: 1
Training loss: 0.18606177712755922
Validation loss: 2.1850925135905697

Epoch: 5| Step: 2
Training loss: 0.14512444243130948
Validation loss: 2.2036141020147624

Epoch: 5| Step: 3
Training loss: 0.11521307699941184
Validation loss: 2.195845409820176

Epoch: 5| Step: 4
Training loss: 0.18639902889081628
Validation loss: 2.189095232190096

Epoch: 5| Step: 5
Training loss: 0.1130300770955273
Validation loss: 2.201594561004949

Epoch: 5| Step: 6
Training loss: 0.09596369750667152
Validation loss: 2.1741740854156597

Epoch: 5| Step: 7
Training loss: 0.11548496736403727
Validation loss: 2.1860167882059036

Epoch: 5| Step: 8
Training loss: 0.14502975479206776
Validation loss: 2.2011535540695433

Epoch: 5| Step: 9
Training loss: 0.1522216490965004
Validation loss: 2.174983870526984

Epoch: 5| Step: 10
Training loss: 0.18039488457383523
Validation loss: 2.158796168159978

Epoch: 660| Step: 0
Training loss: 0.1133071072434532
Validation loss: 2.1664385742581986

Epoch: 5| Step: 1
Training loss: 0.16010942588731633
Validation loss: 2.1976811918009096

Epoch: 5| Step: 2
Training loss: 0.13599166996598197
Validation loss: 2.201154149803542

Epoch: 5| Step: 3
Training loss: 0.15582730219023339
Validation loss: 2.1723785530772934

Epoch: 5| Step: 4
Training loss: 0.1255179270002906
Validation loss: 2.193998243876839

Epoch: 5| Step: 5
Training loss: 0.12833710942296717
Validation loss: 2.1715402959782044

Epoch: 5| Step: 6
Training loss: 0.1796032459263604
Validation loss: 2.190967127935977

Epoch: 5| Step: 7
Training loss: 0.17695522349210133
Validation loss: 2.1516235789238194

Epoch: 5| Step: 8
Training loss: 0.15131570494281713
Validation loss: 2.185736931011701

Epoch: 5| Step: 9
Training loss: 0.16960911632607728
Validation loss: 2.2116036201027343

Epoch: 5| Step: 10
Training loss: 0.09883654204248457
Validation loss: 2.203078184006393

Epoch: 661| Step: 0
Training loss: 0.1121524857494947
Validation loss: 2.220998945800506

Epoch: 5| Step: 1
Training loss: 0.1780472610891256
Validation loss: 2.216791817209078

Epoch: 5| Step: 2
Training loss: 0.22649935138264263
Validation loss: 2.2198311215302606

Epoch: 5| Step: 3
Training loss: 0.16816578442160493
Validation loss: 2.215430833612462

Epoch: 5| Step: 4
Training loss: 0.1167227669424253
Validation loss: 2.2167611250118573

Epoch: 5| Step: 5
Training loss: 0.11895569926670403
Validation loss: 2.1984959435652813

Epoch: 5| Step: 6
Training loss: 0.16252345319374778
Validation loss: 2.1871883457454024

Epoch: 5| Step: 7
Training loss: 0.26807254860655516
Validation loss: 2.1799512416835563

Epoch: 5| Step: 8
Training loss: 0.15737937822190431
Validation loss: 2.226134208702555

Epoch: 5| Step: 9
Training loss: 0.10048229006895561
Validation loss: 2.2321740653673445

Epoch: 5| Step: 10
Training loss: 0.08661126851952825
Validation loss: 2.227657641900213

Epoch: 662| Step: 0
Training loss: 0.17403893599762668
Validation loss: 2.215964725586797

Epoch: 5| Step: 1
Training loss: 0.08735011047754523
Validation loss: 2.2143403625497613

Epoch: 5| Step: 2
Training loss: 0.11520130685168081
Validation loss: 2.21670443477772

Epoch: 5| Step: 3
Training loss: 0.10386925250178092
Validation loss: 2.193633441313593

Epoch: 5| Step: 4
Training loss: 0.17758707083554037
Validation loss: 2.225732479022493

Epoch: 5| Step: 5
Training loss: 0.21432481863785527
Validation loss: 2.2020375932484253

Epoch: 5| Step: 6
Training loss: 0.15837582239782008
Validation loss: 2.1765443107416735

Epoch: 5| Step: 7
Training loss: 0.07917878420012939
Validation loss: 2.193478029735284

Epoch: 5| Step: 8
Training loss: 0.15859828857918182
Validation loss: 2.1849882856331755

Epoch: 5| Step: 9
Training loss: 0.12336851649027215
Validation loss: 2.160963321780323

Epoch: 5| Step: 10
Training loss: 0.11364924330087088
Validation loss: 2.177819134492742

Epoch: 663| Step: 0
Training loss: 0.16548010340491956
Validation loss: 2.1404738283382794

Epoch: 5| Step: 1
Training loss: 0.08513743057005911
Validation loss: 2.168398765451374

Epoch: 5| Step: 2
Training loss: 0.1324499665905596
Validation loss: 2.1441474898583586

Epoch: 5| Step: 3
Training loss: 0.09454385105984305
Validation loss: 2.1811145003348713

Epoch: 5| Step: 4
Training loss: 0.11367515611665105
Validation loss: 2.1612047703244923

Epoch: 5| Step: 5
Training loss: 0.1752552746381684
Validation loss: 2.1504263803970995

Epoch: 5| Step: 6
Training loss: 0.08747360584978817
Validation loss: 2.1940160374012416

Epoch: 5| Step: 7
Training loss: 0.09048781493849212
Validation loss: 2.1643008476280525

Epoch: 5| Step: 8
Training loss: 0.15410341133584765
Validation loss: 2.1804498250995543

Epoch: 5| Step: 9
Training loss: 0.07826872955824005
Validation loss: 2.196127419914725

Epoch: 5| Step: 10
Training loss: 0.1332044497896692
Validation loss: 2.1719870141164144

Epoch: 664| Step: 0
Training loss: 0.15291025518164927
Validation loss: 2.1742612899928244

Epoch: 5| Step: 1
Training loss: 0.0967782029191728
Validation loss: 2.1904393314308024

Epoch: 5| Step: 2
Training loss: 0.09491736574019499
Validation loss: 2.1726313793878402

Epoch: 5| Step: 3
Training loss: 0.07937496526034038
Validation loss: 2.181546659823117

Epoch: 5| Step: 4
Training loss: 0.13140231275159786
Validation loss: 2.1737914106657352

Epoch: 5| Step: 5
Training loss: 0.167446728079707
Validation loss: 2.196934673730173

Epoch: 5| Step: 6
Training loss: 0.10635039270836942
Validation loss: 2.195692833229101

Epoch: 5| Step: 7
Training loss: 0.13603664953284414
Validation loss: 2.1748033710845247

Epoch: 5| Step: 8
Training loss: 0.04568838438102422
Validation loss: 2.16683014977838

Epoch: 5| Step: 9
Training loss: 0.1092929191500621
Validation loss: 2.1842041013791063

Epoch: 5| Step: 10
Training loss: 0.10457166430055931
Validation loss: 2.2040585823696737

Epoch: 665| Step: 0
Training loss: 0.10236490082037294
Validation loss: 2.185695342093482

Epoch: 5| Step: 1
Training loss: 0.08612861569013161
Validation loss: 2.2057934916431017

Epoch: 5| Step: 2
Training loss: 0.0866326480285641
Validation loss: 2.1904137368836385

Epoch: 5| Step: 3
Training loss: 0.07730592877016476
Validation loss: 2.177604746702516

Epoch: 5| Step: 4
Training loss: 0.08754362377010037
Validation loss: 2.2011786993780453

Epoch: 5| Step: 5
Training loss: 0.16639468730460055
Validation loss: 2.1960403064483036

Epoch: 5| Step: 6
Training loss: 0.14452804097917532
Validation loss: 2.1882164949288674

Epoch: 5| Step: 7
Training loss: 0.07537956391363089
Validation loss: 2.1520721101549123

Epoch: 5| Step: 8
Training loss: 0.15010168135935179
Validation loss: 2.154884430286245

Epoch: 5| Step: 9
Training loss: 0.07722311087918377
Validation loss: 2.136751321991754

Epoch: 5| Step: 10
Training loss: 0.08740048965959629
Validation loss: 2.16069757975663

Epoch: 666| Step: 0
Training loss: 0.10355227199573457
Validation loss: 2.135485679857867

Epoch: 5| Step: 1
Training loss: 0.15613417504818153
Validation loss: 2.131898263585178

Epoch: 5| Step: 2
Training loss: 0.09212432450431161
Validation loss: 2.1458444707549393

Epoch: 5| Step: 3
Training loss: 0.08548560049199717
Validation loss: 2.1568996431085496

Epoch: 5| Step: 4
Training loss: 0.07708543909371239
Validation loss: 2.138033727313945

Epoch: 5| Step: 5
Training loss: 0.07511083080574373
Validation loss: 2.1631620707732053

Epoch: 5| Step: 6
Training loss: 0.12934629152883445
Validation loss: 2.1464614207808146

Epoch: 5| Step: 7
Training loss: 0.13951225576520365
Validation loss: 2.129017459086769

Epoch: 5| Step: 8
Training loss: 0.09199699441940978
Validation loss: 2.1471816654520564

Epoch: 5| Step: 9
Training loss: 0.1281681168509928
Validation loss: 2.1496517809198887

Epoch: 5| Step: 10
Training loss: 0.07839046615936537
Validation loss: 2.1666721548227073

Epoch: 667| Step: 0
Training loss: 0.09878204405995539
Validation loss: 2.1571688579446375

Epoch: 5| Step: 1
Training loss: 0.133732581920706
Validation loss: 2.1515719623086382

Epoch: 5| Step: 2
Training loss: 0.06446006766409597
Validation loss: 2.1421724203576513

Epoch: 5| Step: 3
Training loss: 0.07414393041777363
Validation loss: 2.179510365118844

Epoch: 5| Step: 4
Training loss: 0.08864099935495938
Validation loss: 2.1940474538134724

Epoch: 5| Step: 5
Training loss: 0.1023846417190519
Validation loss: 2.174436383081007

Epoch: 5| Step: 6
Training loss: 0.10005082221066282
Validation loss: 2.1603395488519155

Epoch: 5| Step: 7
Training loss: 0.10262879124159716
Validation loss: 2.184580769726712

Epoch: 5| Step: 8
Training loss: 0.08512582344722606
Validation loss: 2.1462055086248557

Epoch: 5| Step: 9
Training loss: 0.10599905490341459
Validation loss: 2.1973695733607217

Epoch: 5| Step: 10
Training loss: 0.18856343061187789
Validation loss: 2.170948800462965

Epoch: 668| Step: 0
Training loss: 0.12517611197173328
Validation loss: 2.181482147052156

Epoch: 5| Step: 1
Training loss: 0.11270014754159184
Validation loss: 2.1805367434249945

Epoch: 5| Step: 2
Training loss: 0.1215452077169898
Validation loss: 2.1791978170521773

Epoch: 5| Step: 3
Training loss: 0.10771043341315267
Validation loss: 2.1987492307801193

Epoch: 5| Step: 4
Training loss: 0.07313568000563127
Validation loss: 2.1872951780842285

Epoch: 5| Step: 5
Training loss: 0.08013973250406248
Validation loss: 2.175979304492268

Epoch: 5| Step: 6
Training loss: 0.06473099171385395
Validation loss: 2.16065256276604

Epoch: 5| Step: 7
Training loss: 0.08871873571033638
Validation loss: 2.1763343902512395

Epoch: 5| Step: 8
Training loss: 0.14584168271164263
Validation loss: 2.1964634489078443

Epoch: 5| Step: 9
Training loss: 0.1523254579174998
Validation loss: 2.1665672365412

Epoch: 5| Step: 10
Training loss: 0.0904440108422488
Validation loss: 2.1653476735861705

Epoch: 669| Step: 0
Training loss: 0.14991532806923066
Validation loss: 2.17391408575955

Epoch: 5| Step: 1
Training loss: 0.0847780297691066
Validation loss: 2.163950608798058

Epoch: 5| Step: 2
Training loss: 0.06622886457218843
Validation loss: 2.153883739138089

Epoch: 5| Step: 3
Training loss: 0.14715405292697595
Validation loss: 2.178478333550245

Epoch: 5| Step: 4
Training loss: 0.08677612567418486
Validation loss: 2.15738895553175

Epoch: 5| Step: 5
Training loss: 0.15132901110214897
Validation loss: 2.1648458524070806

Epoch: 5| Step: 6
Training loss: 0.07662304204563648
Validation loss: 2.14703528025097

Epoch: 5| Step: 7
Training loss: 0.08148241364412662
Validation loss: 2.172044249165267

Epoch: 5| Step: 8
Training loss: 0.07441177176907053
Validation loss: 2.1810349179464463

Epoch: 5| Step: 9
Training loss: 0.09502476523902766
Validation loss: 2.1715110083679834

Epoch: 5| Step: 10
Training loss: 0.09472904988592022
Validation loss: 2.1930606979721343

Epoch: 670| Step: 0
Training loss: 0.11846101507294919
Validation loss: 2.167640989553035

Epoch: 5| Step: 1
Training loss: 0.14587600898189432
Validation loss: 2.1885716592243347

Epoch: 5| Step: 2
Training loss: 0.12225173819535852
Validation loss: 2.1814006862557105

Epoch: 5| Step: 3
Training loss: 0.11744780637379251
Validation loss: 2.178771490847743

Epoch: 5| Step: 4
Training loss: 0.16522033600201985
Validation loss: 2.188890986449976

Epoch: 5| Step: 5
Training loss: 0.17508752413793308
Validation loss: 2.2255567010687045

Epoch: 5| Step: 6
Training loss: 0.06293454206556162
Validation loss: 2.175434455695694

Epoch: 5| Step: 7
Training loss: 0.06905776961878285
Validation loss: 2.1772200803520425

Epoch: 5| Step: 8
Training loss: 0.16138554029370322
Validation loss: 2.186090421289682

Epoch: 5| Step: 9
Training loss: 0.10162370011599788
Validation loss: 2.152277895866877

Epoch: 5| Step: 10
Training loss: 0.07663353074921683
Validation loss: 2.1545953446140023

Epoch: 671| Step: 0
Training loss: 0.08705681960278114
Validation loss: 2.1661189885241394

Epoch: 5| Step: 1
Training loss: 0.11846242233550354
Validation loss: 2.154964385369219

Epoch: 5| Step: 2
Training loss: 0.09864541719174987
Validation loss: 2.124323210532666

Epoch: 5| Step: 3
Training loss: 0.0935644160649758
Validation loss: 2.177426129618853

Epoch: 5| Step: 4
Training loss: 0.14038947037533558
Validation loss: 2.178328249176019

Epoch: 5| Step: 5
Training loss: 0.1148003105154702
Validation loss: 2.1779466218513

Epoch: 5| Step: 6
Training loss: 0.0701866381077231
Validation loss: 2.1514798689624057

Epoch: 5| Step: 7
Training loss: 0.16074907095760788
Validation loss: 2.168956511099779

Epoch: 5| Step: 8
Training loss: 0.08155259343983483
Validation loss: 2.1956004044222444

Epoch: 5| Step: 9
Training loss: 0.092016252176457
Validation loss: 2.1985751819259773

Epoch: 5| Step: 10
Training loss: 0.16024968282933025
Validation loss: 2.1555800054646244

Epoch: 672| Step: 0
Training loss: 0.15792146381571107
Validation loss: 2.201318051473976

Epoch: 5| Step: 1
Training loss: 0.13928448661020373
Validation loss: 2.1890156922480126

Epoch: 5| Step: 2
Training loss: 0.14251459352320556
Validation loss: 2.197392953918341

Epoch: 5| Step: 3
Training loss: 0.16375602184208565
Validation loss: 2.1751316808155803

Epoch: 5| Step: 4
Training loss: 0.07875750621811402
Validation loss: 2.160425194300536

Epoch: 5| Step: 5
Training loss: 0.10087300511370623
Validation loss: 2.1717491275729683

Epoch: 5| Step: 6
Training loss: 0.05502262210390725
Validation loss: 2.1767756880659332

Epoch: 5| Step: 7
Training loss: 0.0953821424200914
Validation loss: 2.200324963782196

Epoch: 5| Step: 8
Training loss: 0.10470037576862798
Validation loss: 2.211646188739346

Epoch: 5| Step: 9
Training loss: 0.11342883361993164
Validation loss: 2.17769559515489

Epoch: 5| Step: 10
Training loss: 0.13582631118469085
Validation loss: 2.1583027068474707

Epoch: 673| Step: 0
Training loss: 0.13235165075883848
Validation loss: 2.1847133782984307

Epoch: 5| Step: 1
Training loss: 0.14303581379407676
Validation loss: 2.202319159935383

Epoch: 5| Step: 2
Training loss: 0.1253717452836241
Validation loss: 2.1892728240346653

Epoch: 5| Step: 3
Training loss: 0.16247018623120787
Validation loss: 2.176932102427764

Epoch: 5| Step: 4
Training loss: 0.08080082515081882
Validation loss: 2.1856593895261045

Epoch: 5| Step: 5
Training loss: 0.14386210967856242
Validation loss: 2.1716497219884885

Epoch: 5| Step: 6
Training loss: 0.11535407573546981
Validation loss: 2.192439606601911

Epoch: 5| Step: 7
Training loss: 0.21220496642314635
Validation loss: 2.188423322250284

Epoch: 5| Step: 8
Training loss: 0.10541779558829992
Validation loss: 2.1549447359282747

Epoch: 5| Step: 9
Training loss: 0.13603046735034072
Validation loss: 2.149230296461776

Epoch: 5| Step: 10
Training loss: 0.08345670775001082
Validation loss: 2.1542281613809844

Epoch: 674| Step: 0
Training loss: 0.11982081454290565
Validation loss: 2.1331210106542797

Epoch: 5| Step: 1
Training loss: 0.08893021769174134
Validation loss: 2.124589199916099

Epoch: 5| Step: 2
Training loss: 0.13782788381111086
Validation loss: 2.1410686158103966

Epoch: 5| Step: 3
Training loss: 0.1684546705439916
Validation loss: 2.12948402827535

Epoch: 5| Step: 4
Training loss: 0.12234062402149297
Validation loss: 2.128823715165009

Epoch: 5| Step: 5
Training loss: 0.12547044590175607
Validation loss: 2.1613905007345795

Epoch: 5| Step: 6
Training loss: 0.16720304505995356
Validation loss: 2.155645073106454

Epoch: 5| Step: 7
Training loss: 0.14812076808018712
Validation loss: 2.1780448478522096

Epoch: 5| Step: 8
Training loss: 0.08099948772920403
Validation loss: 2.159828581156988

Epoch: 5| Step: 9
Training loss: 0.15147772413883875
Validation loss: 2.191015528399057

Epoch: 5| Step: 10
Training loss: 0.09475655425044069
Validation loss: 2.1650622688253214

Epoch: 675| Step: 0
Training loss: 0.16267165942860692
Validation loss: 2.198111331050276

Epoch: 5| Step: 1
Training loss: 0.17392755193735351
Validation loss: 2.1595349399173145

Epoch: 5| Step: 2
Training loss: 0.11358499090486515
Validation loss: 2.14426763393533

Epoch: 5| Step: 3
Training loss: 0.12507739502302428
Validation loss: 2.15522383112635

Epoch: 5| Step: 4
Training loss: 0.07768103096698067
Validation loss: 2.160899278553953

Epoch: 5| Step: 5
Training loss: 0.09323208023381092
Validation loss: 2.1467664849872743

Epoch: 5| Step: 6
Training loss: 0.14485396621789354
Validation loss: 2.1710220861231573

Epoch: 5| Step: 7
Training loss: 0.1520713118533308
Validation loss: 2.1521250739496645

Epoch: 5| Step: 8
Training loss: 0.12916223078719694
Validation loss: 2.128361898782975

Epoch: 5| Step: 9
Training loss: 0.1373125125614138
Validation loss: 2.142075466014993

Epoch: 5| Step: 10
Training loss: 0.08099632862444274
Validation loss: 2.1397490649766153

Epoch: 676| Step: 0
Training loss: 0.0941426973391802
Validation loss: 2.161197632299807

Epoch: 5| Step: 1
Training loss: 0.13989524106458703
Validation loss: 2.158061136751395

Epoch: 5| Step: 2
Training loss: 0.12214797410550737
Validation loss: 2.1650568151702934

Epoch: 5| Step: 3
Training loss: 0.13343685317496912
Validation loss: 2.177313997939703

Epoch: 5| Step: 4
Training loss: 0.10215732269593278
Validation loss: 2.1842663328049583

Epoch: 5| Step: 5
Training loss: 0.14235267058474507
Validation loss: 2.1723987458061247

Epoch: 5| Step: 6
Training loss: 0.1635578944472874
Validation loss: 2.152446018351177

Epoch: 5| Step: 7
Training loss: 0.09112240683269805
Validation loss: 2.155375362858196

Epoch: 5| Step: 8
Training loss: 0.14596244653931278
Validation loss: 2.148964829150967

Epoch: 5| Step: 9
Training loss: 0.13405430389683773
Validation loss: 2.1447104027621324

Epoch: 5| Step: 10
Training loss: 0.1697239161154486
Validation loss: 2.166974289198579

Epoch: 677| Step: 0
Training loss: 0.09967562398454485
Validation loss: 2.1499757822117487

Epoch: 5| Step: 1
Training loss: 0.1852833432391214
Validation loss: 2.1702951755702053

Epoch: 5| Step: 2
Training loss: 0.14695687066658003
Validation loss: 2.1649129548500006

Epoch: 5| Step: 3
Training loss: 0.20984705120679786
Validation loss: 2.149465606298496

Epoch: 5| Step: 4
Training loss: 0.1364247567118551
Validation loss: 2.199406133200815

Epoch: 5| Step: 5
Training loss: 0.07808740724666022
Validation loss: 2.1617125890292916

Epoch: 5| Step: 6
Training loss: 0.08462559080551572
Validation loss: 2.171494996113843

Epoch: 5| Step: 7
Training loss: 0.12306026734026376
Validation loss: 2.1614579672330647

Epoch: 5| Step: 8
Training loss: 0.08580310564824158
Validation loss: 2.187885207731082

Epoch: 5| Step: 9
Training loss: 0.12092155857885209
Validation loss: 2.188437101452752

Epoch: 5| Step: 10
Training loss: 0.059295243965178074
Validation loss: 2.1794828948935745

Epoch: 678| Step: 0
Training loss: 0.14117391399057364
Validation loss: 2.1841377377433426

Epoch: 5| Step: 1
Training loss: 0.12091843157768864
Validation loss: 2.1952706148579733

Epoch: 5| Step: 2
Training loss: 0.10132342406333729
Validation loss: 2.175965084116405

Epoch: 5| Step: 3
Training loss: 0.17211557479303022
Validation loss: 2.184857230272184

Epoch: 5| Step: 4
Training loss: 0.1370407400031272
Validation loss: 2.1596419845940598

Epoch: 5| Step: 5
Training loss: 0.10683234311600573
Validation loss: 2.174378450235055

Epoch: 5| Step: 6
Training loss: 0.11173416011407156
Validation loss: 2.192344671809657

Epoch: 5| Step: 7
Training loss: 0.1135914395069812
Validation loss: 2.1825505894365027

Epoch: 5| Step: 8
Training loss: 0.1326442803193652
Validation loss: 2.14751699705805

Epoch: 5| Step: 9
Training loss: 0.1211379608848853
Validation loss: 2.1596058119727495

Epoch: 5| Step: 10
Training loss: 0.19625445198366945
Validation loss: 2.190665655507973

Epoch: 679| Step: 0
Training loss: 0.18564075303584995
Validation loss: 2.1826237733142415

Epoch: 5| Step: 1
Training loss: 0.09590593083428915
Validation loss: 2.17831812353293

Epoch: 5| Step: 2
Training loss: 0.10804014015308534
Validation loss: 2.1810534907408905

Epoch: 5| Step: 3
Training loss: 0.21430057005107767
Validation loss: 2.1704732940181986

Epoch: 5| Step: 4
Training loss: 0.13720313504480433
Validation loss: 2.14775514388512

Epoch: 5| Step: 5
Training loss: 0.18077234683125498
Validation loss: 2.1652481218170148

Epoch: 5| Step: 6
Training loss: 0.15841917896996022
Validation loss: 2.1468495802846133

Epoch: 5| Step: 7
Training loss: 0.12283943492420943
Validation loss: 2.153255905033793

Epoch: 5| Step: 8
Training loss: 0.18863092534900042
Validation loss: 2.1502560171450997

Epoch: 5| Step: 9
Training loss: 0.1269851864164199
Validation loss: 2.1479897894164535

Epoch: 5| Step: 10
Training loss: 0.16692050153657695
Validation loss: 2.117464726473124

Epoch: 680| Step: 0
Training loss: 0.26282322261858465
Validation loss: 2.10421372706923

Epoch: 5| Step: 1
Training loss: 0.15126779430911666
Validation loss: 2.1130908560870947

Epoch: 5| Step: 2
Training loss: 0.14335713449749043
Validation loss: 2.0965328153934513

Epoch: 5| Step: 3
Training loss: 0.1319701606454686
Validation loss: 2.086028924142712

Epoch: 5| Step: 4
Training loss: 0.24681482185204792
Validation loss: 2.097804506868286

Epoch: 5| Step: 5
Training loss: 0.14522117826682068
Validation loss: 2.10801463315851

Epoch: 5| Step: 6
Training loss: 0.1858362751797037
Validation loss: 2.110384703011881

Epoch: 5| Step: 7
Training loss: 0.13937038804236998
Validation loss: 2.1401100482424167

Epoch: 5| Step: 8
Training loss: 0.25840294301321254
Validation loss: 2.146183244239891

Epoch: 5| Step: 9
Training loss: 0.10041242744950588
Validation loss: 2.148062321186707

Epoch: 5| Step: 10
Training loss: 0.14783671794633543
Validation loss: 2.1476788177794837

Epoch: 681| Step: 0
Training loss: 0.21198207449422157
Validation loss: 2.139960553921531

Epoch: 5| Step: 1
Training loss: 0.10230109894886813
Validation loss: 2.1449380054756624

Epoch: 5| Step: 2
Training loss: 0.17242581797258233
Validation loss: 2.1419700059960864

Epoch: 5| Step: 3
Training loss: 0.16634433404861876
Validation loss: 2.166891801187126

Epoch: 5| Step: 4
Training loss: 0.0915662933481706
Validation loss: 2.139903544051148

Epoch: 5| Step: 5
Training loss: 0.1718520940342427
Validation loss: 2.1650791702434558

Epoch: 5| Step: 6
Training loss: 0.15811489140763924
Validation loss: 2.1333556206593927

Epoch: 5| Step: 7
Training loss: 0.15191552302471856
Validation loss: 2.1913384379598213

Epoch: 5| Step: 8
Training loss: 0.18962007225991634
Validation loss: 2.190203765102365

Epoch: 5| Step: 9
Training loss: 0.08405997787914438
Validation loss: 2.1657807698031006

Epoch: 5| Step: 10
Training loss: 0.15633570585500098
Validation loss: 2.1484645271279295

Epoch: 682| Step: 0
Training loss: 0.13701311166480776
Validation loss: 2.198781543794042

Epoch: 5| Step: 1
Training loss: 0.1501035427311732
Validation loss: 2.20251395860877

Epoch: 5| Step: 2
Training loss: 0.16059588359522226
Validation loss: 2.212975899611193

Epoch: 5| Step: 3
Training loss: 0.17401921559359781
Validation loss: 2.2104474773356766

Epoch: 5| Step: 4
Training loss: 0.13299710402885223
Validation loss: 2.218493880551092

Epoch: 5| Step: 5
Training loss: 0.15173226906194234
Validation loss: 2.206898462451916

Epoch: 5| Step: 6
Training loss: 0.11295249111653595
Validation loss: 2.1779964016236852

Epoch: 5| Step: 7
Training loss: 0.12220644417417961
Validation loss: 2.181574679876906

Epoch: 5| Step: 8
Training loss: 0.12802136754244453
Validation loss: 2.198245747975987

Epoch: 5| Step: 9
Training loss: 0.19478383996270698
Validation loss: 2.1843614784416197

Epoch: 5| Step: 10
Training loss: 0.16868191511160222
Validation loss: 2.1671681890541055

Epoch: 683| Step: 0
Training loss: 0.1102821123114318
Validation loss: 2.1797466095844094

Epoch: 5| Step: 1
Training loss: 0.11713181205657608
Validation loss: 2.155992444697978

Epoch: 5| Step: 2
Training loss: 0.15387282468449678
Validation loss: 2.1478979059192578

Epoch: 5| Step: 3
Training loss: 0.10857511847683027
Validation loss: 2.157925701745874

Epoch: 5| Step: 4
Training loss: 0.0899502082021826
Validation loss: 2.147980801693937

Epoch: 5| Step: 5
Training loss: 0.08446213761478155
Validation loss: 2.1439395474300627

Epoch: 5| Step: 6
Training loss: 0.10596131610556622
Validation loss: 2.160551421505231

Epoch: 5| Step: 7
Training loss: 0.22543631376510145
Validation loss: 2.1526317678796585

Epoch: 5| Step: 8
Training loss: 0.17107105256987717
Validation loss: 2.1264215391885726

Epoch: 5| Step: 9
Training loss: 0.14747264638734053
Validation loss: 2.1378749102502823

Epoch: 5| Step: 10
Training loss: 0.12134096844029763
Validation loss: 2.149406067113135

Epoch: 684| Step: 0
Training loss: 0.10117685939043093
Validation loss: 2.1594694784089525

Epoch: 5| Step: 1
Training loss: 0.10133279904340496
Validation loss: 2.1990813714365505

Epoch: 5| Step: 2
Training loss: 0.1072240959467457
Validation loss: 2.168328015862108

Epoch: 5| Step: 3
Training loss: 0.18473887945563935
Validation loss: 2.166554278479211

Epoch: 5| Step: 4
Training loss: 0.16522371807857938
Validation loss: 2.194219792647394

Epoch: 5| Step: 5
Training loss: 0.09812983122856203
Validation loss: 2.161510524917761

Epoch: 5| Step: 6
Training loss: 0.1540297477487934
Validation loss: 2.160372362198647

Epoch: 5| Step: 7
Training loss: 0.0884856427819437
Validation loss: 2.1444358859021673

Epoch: 5| Step: 8
Training loss: 0.14856973831122772
Validation loss: 2.1356785511349745

Epoch: 5| Step: 9
Training loss: 0.11651803560104965
Validation loss: 2.151034977404001

Epoch: 5| Step: 10
Training loss: 0.13209164863153156
Validation loss: 2.18434681794482

Epoch: 685| Step: 0
Training loss: 0.16165189651196202
Validation loss: 2.171003498362004

Epoch: 5| Step: 1
Training loss: 0.17956840673451488
Validation loss: 2.1610995403449307

Epoch: 5| Step: 2
Training loss: 0.1333000406656897
Validation loss: 2.1591682896280053

Epoch: 5| Step: 3
Training loss: 0.10425938314581845
Validation loss: 2.1518590755979656

Epoch: 5| Step: 4
Training loss: 0.1646267407150753
Validation loss: 2.169570326838434

Epoch: 5| Step: 5
Training loss: 0.15155193990119015
Validation loss: 2.1854749866767116

Epoch: 5| Step: 6
Training loss: 0.17608792256424885
Validation loss: 2.1685174636552813

Epoch: 5| Step: 7
Training loss: 0.19943524732904477
Validation loss: 2.182729870662192

Epoch: 5| Step: 8
Training loss: 0.2030476092581776
Validation loss: 2.1740952943140495

Epoch: 5| Step: 9
Training loss: 0.0881376345265273
Validation loss: 2.1456719323960214

Epoch: 5| Step: 10
Training loss: 0.11482864413531425
Validation loss: 2.1455053357953413

Epoch: 686| Step: 0
Training loss: 0.09981095262634634
Validation loss: 2.1659035488490592

Epoch: 5| Step: 1
Training loss: 0.18017081897384102
Validation loss: 2.148410945068202

Epoch: 5| Step: 2
Training loss: 0.22318457780418935
Validation loss: 2.1592276310130716

Epoch: 5| Step: 3
Training loss: 0.13658501351099667
Validation loss: 2.1781760665225605

Epoch: 5| Step: 4
Training loss: 0.16143544993721592
Validation loss: 2.1658201713578573

Epoch: 5| Step: 5
Training loss: 0.14794388689058413
Validation loss: 2.172266361472562

Epoch: 5| Step: 6
Training loss: 0.12350894061778701
Validation loss: 2.171428996117286

Epoch: 5| Step: 7
Training loss: 0.2365303356698803
Validation loss: 2.154385858146754

Epoch: 5| Step: 8
Training loss: 0.2293325558898629
Validation loss: 2.1968338071848588

Epoch: 5| Step: 9
Training loss: 0.16885010015374846
Validation loss: 2.1649175382031345

Epoch: 5| Step: 10
Training loss: 0.17748944729679014
Validation loss: 2.169588138734103

Epoch: 687| Step: 0
Training loss: 0.23426635926332
Validation loss: 2.16048048316767

Epoch: 5| Step: 1
Training loss: 0.2526428923794432
Validation loss: 2.172555877672329

Epoch: 5| Step: 2
Training loss: 0.21601318785687754
Validation loss: 2.1767166114584326

Epoch: 5| Step: 3
Training loss: 0.18058846412721352
Validation loss: 2.1596612322129456

Epoch: 5| Step: 4
Training loss: 0.15915970003982755
Validation loss: 2.1553276137685233

Epoch: 5| Step: 5
Training loss: 0.12322175374942351
Validation loss: 2.140896601730005

Epoch: 5| Step: 6
Training loss: 0.20998163343051035
Validation loss: 2.1399527664058953

Epoch: 5| Step: 7
Training loss: 0.2514041568154491
Validation loss: 2.1184712532644574

Epoch: 5| Step: 8
Training loss: 0.2029634530225678
Validation loss: 2.1225089492917424

Epoch: 5| Step: 9
Training loss: 0.1382122818785122
Validation loss: 2.1298981894172706

Epoch: 5| Step: 10
Training loss: 0.15377553554282583
Validation loss: 2.1580170246365733

Epoch: 688| Step: 0
Training loss: 0.06779427949962025
Validation loss: 2.170765779207929

Epoch: 5| Step: 1
Training loss: 0.10299146850214592
Validation loss: 2.156501532423288

Epoch: 5| Step: 2
Training loss: 0.2456427634952739
Validation loss: 2.15167016036517

Epoch: 5| Step: 3
Training loss: 0.23069952063194443
Validation loss: 2.1658612932362993

Epoch: 5| Step: 4
Training loss: 0.14526433864408425
Validation loss: 2.1839934856427776

Epoch: 5| Step: 5
Training loss: 0.1630069004346871
Validation loss: 2.1863535975411366

Epoch: 5| Step: 6
Training loss: 0.10611257255509927
Validation loss: 2.143779350641178

Epoch: 5| Step: 7
Training loss: 0.22142619288832663
Validation loss: 2.16855910065285

Epoch: 5| Step: 8
Training loss: 0.26246669989492727
Validation loss: 2.1697014879242618

Epoch: 5| Step: 9
Training loss: 0.1052117350904916
Validation loss: 2.160493548261333

Epoch: 5| Step: 10
Training loss: 0.09587467155499754
Validation loss: 2.1504856201259956

Epoch: 689| Step: 0
Training loss: 0.19576478089692478
Validation loss: 2.1586765927935265

Epoch: 5| Step: 1
Training loss: 0.11317354047361654
Validation loss: 2.1863783379260435

Epoch: 5| Step: 2
Training loss: 0.1668863128192155
Validation loss: 2.1969186659030933

Epoch: 5| Step: 3
Training loss: 0.15367532436298761
Validation loss: 2.1742045422103806

Epoch: 5| Step: 4
Training loss: 0.18991541745981713
Validation loss: 2.1814622813752385

Epoch: 5| Step: 5
Training loss: 0.13471947446445598
Validation loss: 2.1759316322891644

Epoch: 5| Step: 6
Training loss: 0.13252753653132665
Validation loss: 2.1902377076779844

Epoch: 5| Step: 7
Training loss: 0.1414540673648748
Validation loss: 2.1991231379504415

Epoch: 5| Step: 8
Training loss: 0.10683179390523953
Validation loss: 2.1850007859057774

Epoch: 5| Step: 9
Training loss: 0.13282608916379798
Validation loss: 2.1886816885054046

Epoch: 5| Step: 10
Training loss: 0.1829322096956034
Validation loss: 2.1709719752052377

Epoch: 690| Step: 0
Training loss: 0.24421763922011017
Validation loss: 2.1860625183392117

Epoch: 5| Step: 1
Training loss: 0.12283835453784506
Validation loss: 2.18863829077072

Epoch: 5| Step: 2
Training loss: 0.19428210255627704
Validation loss: 2.1884431109736076

Epoch: 5| Step: 3
Training loss: 0.2594969801580057
Validation loss: 2.204811960730319

Epoch: 5| Step: 4
Training loss: 0.14601735371708793
Validation loss: 2.1870140567249043

Epoch: 5| Step: 5
Training loss: 0.14372146416506887
Validation loss: 2.1818735545102754

Epoch: 5| Step: 6
Training loss: 0.16412571983259444
Validation loss: 2.197436026798659

Epoch: 5| Step: 7
Training loss: 0.1069845052261195
Validation loss: 2.150962239566158

Epoch: 5| Step: 8
Training loss: 0.13106663503067806
Validation loss: 2.156327177131621

Epoch: 5| Step: 9
Training loss: 0.11752616900349717
Validation loss: 2.088692350620968

Epoch: 5| Step: 10
Training loss: 0.17842134870262305
Validation loss: 2.1530536360634445

Epoch: 691| Step: 0
Training loss: 0.11995742997681445
Validation loss: 2.1442477077309223

Epoch: 5| Step: 1
Training loss: 0.1282349431701731
Validation loss: 2.1574925140109156

Epoch: 5| Step: 2
Training loss: 0.16663811049104518
Validation loss: 2.1988218323760638

Epoch: 5| Step: 3
Training loss: 0.08445497007939377
Validation loss: 2.190573660886286

Epoch: 5| Step: 4
Training loss: 0.146061585960499
Validation loss: 2.1922564868282692

Epoch: 5| Step: 5
Training loss: 0.17978460341849795
Validation loss: 2.195681176692342

Epoch: 5| Step: 6
Training loss: 0.10530980814201701
Validation loss: 2.1939066110171286

Epoch: 5| Step: 7
Training loss: 0.11183810544086198
Validation loss: 2.1906728806594433

Epoch: 5| Step: 8
Training loss: 0.1436697699728127
Validation loss: 2.1963633024906897

Epoch: 5| Step: 9
Training loss: 0.12176106381595848
Validation loss: 2.168221705064633

Epoch: 5| Step: 10
Training loss: 0.1706476824219414
Validation loss: 2.1819625591843104

Epoch: 692| Step: 0
Training loss: 0.11976143638666889
Validation loss: 2.1709102607616066

Epoch: 5| Step: 1
Training loss: 0.17421553869666292
Validation loss: 2.1747253651933263

Epoch: 5| Step: 2
Training loss: 0.15673401491057057
Validation loss: 2.1549156129787237

Epoch: 5| Step: 3
Training loss: 0.10463174075171122
Validation loss: 2.1372905185986815

Epoch: 5| Step: 4
Training loss: 0.13142883174789752
Validation loss: 2.1377995077839604

Epoch: 5| Step: 5
Training loss: 0.16834506861359883
Validation loss: 2.1076920456182617

Epoch: 5| Step: 6
Training loss: 0.13667859441424224
Validation loss: 2.1070700451388293

Epoch: 5| Step: 7
Training loss: 0.19431207021479838
Validation loss: 2.113280721084383

Epoch: 5| Step: 8
Training loss: 0.13812698849372973
Validation loss: 2.141381989996376

Epoch: 5| Step: 9
Training loss: 0.10145172625461214
Validation loss: 2.167881859927642

Epoch: 5| Step: 10
Training loss: 0.07270658797623564
Validation loss: 2.1451055433675337

Epoch: 693| Step: 0
Training loss: 0.11174284085040931
Validation loss: 2.1435913546242227

Epoch: 5| Step: 1
Training loss: 0.08685412108000061
Validation loss: 2.165916400134906

Epoch: 5| Step: 2
Training loss: 0.10305088461275738
Validation loss: 2.159304669663397

Epoch: 5| Step: 3
Training loss: 0.08519421811561857
Validation loss: 2.161414232828355

Epoch: 5| Step: 4
Training loss: 0.11610570518732165
Validation loss: 2.1622993451069568

Epoch: 5| Step: 5
Training loss: 0.11059853674351144
Validation loss: 2.1529685052948517

Epoch: 5| Step: 6
Training loss: 0.1156290254987591
Validation loss: 2.1800693990858786

Epoch: 5| Step: 7
Training loss: 0.09280867660238107
Validation loss: 2.1755912516499367

Epoch: 5| Step: 8
Training loss: 0.1821397057161795
Validation loss: 2.1734089085758743

Epoch: 5| Step: 9
Training loss: 0.15088610338742364
Validation loss: 2.1658805051159966

Epoch: 5| Step: 10
Training loss: 0.11810057092916433
Validation loss: 2.1673770013065603

Epoch: 694| Step: 0
Training loss: 0.09453300974918262
Validation loss: 2.1688608220499512

Epoch: 5| Step: 1
Training loss: 0.1539791433180097
Validation loss: 2.1632531998647675

Epoch: 5| Step: 2
Training loss: 0.09800425986384653
Validation loss: 2.1503190921545454

Epoch: 5| Step: 3
Training loss: 0.14670191823674492
Validation loss: 2.1680074070280737

Epoch: 5| Step: 4
Training loss: 0.11163813109712306
Validation loss: 2.1965087193650743

Epoch: 5| Step: 5
Training loss: 0.06011613748549305
Validation loss: 2.179162814900557

Epoch: 5| Step: 6
Training loss: 0.16409094314157865
Validation loss: 2.174460185597334

Epoch: 5| Step: 7
Training loss: 0.14569149328852551
Validation loss: 2.1901615785882753

Epoch: 5| Step: 8
Training loss: 0.10703526632054727
Validation loss: 2.177140552844118

Epoch: 5| Step: 9
Training loss: 0.07404382696637973
Validation loss: 2.1585524044430153

Epoch: 5| Step: 10
Training loss: 0.07968215620598422
Validation loss: 2.1754636003355183

Epoch: 695| Step: 0
Training loss: 0.17104426565433717
Validation loss: 2.1766892072637445

Epoch: 5| Step: 1
Training loss: 0.06759121015686863
Validation loss: 2.171293691830202

Epoch: 5| Step: 2
Training loss: 0.10353095462940017
Validation loss: 2.1535997021378845

Epoch: 5| Step: 3
Training loss: 0.09568090570165988
Validation loss: 2.1508683888655904

Epoch: 5| Step: 4
Training loss: 0.09588276294093723
Validation loss: 2.1447641982958245

Epoch: 5| Step: 5
Training loss: 0.13845074847486769
Validation loss: 2.1666908838639887

Epoch: 5| Step: 6
Training loss: 0.12956911221610404
Validation loss: 2.1592657238567514

Epoch: 5| Step: 7
Training loss: 0.07906757613611742
Validation loss: 2.16561092073877

Epoch: 5| Step: 8
Training loss: 0.13455015039759835
Validation loss: 2.1505155982021638

Epoch: 5| Step: 9
Training loss: 0.10477112589937056
Validation loss: 2.1602668489861325

Epoch: 5| Step: 10
Training loss: 0.08347845169985653
Validation loss: 2.1804768193198063

Epoch: 696| Step: 0
Training loss: 0.08673848140326679
Validation loss: 2.1649753121330164

Epoch: 5| Step: 1
Training loss: 0.10267901633370605
Validation loss: 2.1588450054758717

Epoch: 5| Step: 2
Training loss: 0.10727211743632255
Validation loss: 2.1829376024421303

Epoch: 5| Step: 3
Training loss: 0.17105551449196188
Validation loss: 2.170754011846949

Epoch: 5| Step: 4
Training loss: 0.13094742502912193
Validation loss: 2.1685652214132456

Epoch: 5| Step: 5
Training loss: 0.08702989157279153
Validation loss: 2.1749085235595205

Epoch: 5| Step: 6
Training loss: 0.0812938849060395
Validation loss: 2.1355519533759564

Epoch: 5| Step: 7
Training loss: 0.08077499667964304
Validation loss: 2.1510683834847364

Epoch: 5| Step: 8
Training loss: 0.14634964150823743
Validation loss: 2.154366715713126

Epoch: 5| Step: 9
Training loss: 0.07019516970344501
Validation loss: 2.171764288625944

Epoch: 5| Step: 10
Training loss: 0.07514082804926303
Validation loss: 2.169302315424378

Epoch: 697| Step: 0
Training loss: 0.09391158305399236
Validation loss: 2.1592339616618803

Epoch: 5| Step: 1
Training loss: 0.09304192492228118
Validation loss: 2.153967661392783

Epoch: 5| Step: 2
Training loss: 0.14024410718762453
Validation loss: 2.1499423290453543

Epoch: 5| Step: 3
Training loss: 0.13274873577250498
Validation loss: 2.170003896363561

Epoch: 5| Step: 4
Training loss: 0.1083514223295198
Validation loss: 2.1555773586662115

Epoch: 5| Step: 5
Training loss: 0.07302030651366855
Validation loss: 2.17835295860749

Epoch: 5| Step: 6
Training loss: 0.13784353246349534
Validation loss: 2.1736312343792883

Epoch: 5| Step: 7
Training loss: 0.13331854006787539
Validation loss: 2.171128980078163

Epoch: 5| Step: 8
Training loss: 0.07902225003220065
Validation loss: 2.2002387514358612

Epoch: 5| Step: 9
Training loss: 0.15134878969672652
Validation loss: 2.188850874059112

Epoch: 5| Step: 10
Training loss: 0.10361396419001659
Validation loss: 2.1798740036216873

Epoch: 698| Step: 0
Training loss: 0.0736738770921817
Validation loss: 2.1843365227350735

Epoch: 5| Step: 1
Training loss: 0.08453248501684582
Validation loss: 2.16170105760447

Epoch: 5| Step: 2
Training loss: 0.07191785371910121
Validation loss: 2.183230947705096

Epoch: 5| Step: 3
Training loss: 0.1295828833935072
Validation loss: 2.2073066152691987

Epoch: 5| Step: 4
Training loss: 0.15024272036570752
Validation loss: 2.1860425802383285

Epoch: 5| Step: 5
Training loss: 0.0965870500114961
Validation loss: 2.174570696646235

Epoch: 5| Step: 6
Training loss: 0.0808758284695494
Validation loss: 2.1848822498457854

Epoch: 5| Step: 7
Training loss: 0.0648506792801286
Validation loss: 2.1465080366148275

Epoch: 5| Step: 8
Training loss: 0.08073277202625785
Validation loss: 2.135266329387745

Epoch: 5| Step: 9
Training loss: 0.12445321297986692
Validation loss: 2.166251287289114

Epoch: 5| Step: 10
Training loss: 0.08074230585795504
Validation loss: 2.140111046093977

Epoch: 699| Step: 0
Training loss: 0.08429807472082357
Validation loss: 2.15467123474789

Epoch: 5| Step: 1
Training loss: 0.08284424204951833
Validation loss: 2.1381321574633265

Epoch: 5| Step: 2
Training loss: 0.11574205807315878
Validation loss: 2.1305738477947602

Epoch: 5| Step: 3
Training loss: 0.11036574854857491
Validation loss: 2.1436817134635358

Epoch: 5| Step: 4
Training loss: 0.08406538161582197
Validation loss: 2.1572885115350107

Epoch: 5| Step: 5
Training loss: 0.117395113778074
Validation loss: 2.1669551225080355

Epoch: 5| Step: 6
Training loss: 0.12673819027099542
Validation loss: 2.1178090347502123

Epoch: 5| Step: 7
Training loss: 0.07201638607794954
Validation loss: 2.1642594970986306

Epoch: 5| Step: 8
Training loss: 0.0992873587276434
Validation loss: 2.145512121260283

Epoch: 5| Step: 9
Training loss: 0.13664248246576596
Validation loss: 2.159649423932758

Epoch: 5| Step: 10
Training loss: 0.10273398990341359
Validation loss: 2.153878302110551

Epoch: 700| Step: 0
Training loss: 0.08504752701375018
Validation loss: 2.1500753945621724

Epoch: 5| Step: 1
Training loss: 0.0975233604341004
Validation loss: 2.164272217780191

Epoch: 5| Step: 2
Training loss: 0.14454458149434818
Validation loss: 2.1386749113223065

Epoch: 5| Step: 3
Training loss: 0.065213772381359
Validation loss: 2.1608664963432873

Epoch: 5| Step: 4
Training loss: 0.15606965147230661
Validation loss: 2.136525792638461

Epoch: 5| Step: 5
Training loss: 0.08473584073744152
Validation loss: 2.1341648196625123

Epoch: 5| Step: 6
Training loss: 0.09542807642091664
Validation loss: 2.146784867626205

Epoch: 5| Step: 7
Training loss: 0.05122917948826488
Validation loss: 2.099426831043676

Epoch: 5| Step: 8
Training loss: 0.09625050138212875
Validation loss: 2.158287505871971

Epoch: 5| Step: 9
Training loss: 0.13063441340736986
Validation loss: 2.1420328654169873

Epoch: 5| Step: 10
Training loss: 0.07283246516157033
Validation loss: 2.148585548110228

Epoch: 701| Step: 0
Training loss: 0.09295340699925611
Validation loss: 2.156618131743266

Epoch: 5| Step: 1
Training loss: 0.14217817045352302
Validation loss: 2.171780143667711

Epoch: 5| Step: 2
Training loss: 0.12069647363280372
Validation loss: 2.154858109463181

Epoch: 5| Step: 3
Training loss: 0.09340847910687225
Validation loss: 2.17376485823788

Epoch: 5| Step: 4
Training loss: 0.10137140195460953
Validation loss: 2.140966656555104

Epoch: 5| Step: 5
Training loss: 0.12206665033569171
Validation loss: 2.143795188433043

Epoch: 5| Step: 6
Training loss: 0.1206888497500355
Validation loss: 2.1157311715193607

Epoch: 5| Step: 7
Training loss: 0.08788339002288764
Validation loss: 2.1384926053716535

Epoch: 5| Step: 8
Training loss: 0.10204385432776972
Validation loss: 2.1280886837336155

Epoch: 5| Step: 9
Training loss: 0.1367881939136167
Validation loss: 2.1278016413488183

Epoch: 5| Step: 10
Training loss: 0.1551301522986201
Validation loss: 2.1350167617088003

Epoch: 702| Step: 0
Training loss: 0.07907417788789757
Validation loss: 2.1230180160686745

Epoch: 5| Step: 1
Training loss: 0.08740167777377811
Validation loss: 2.1410758658432316

Epoch: 5| Step: 2
Training loss: 0.09821443772536441
Validation loss: 2.1604688502374825

Epoch: 5| Step: 3
Training loss: 0.08467546823588651
Validation loss: 2.146886518920694

Epoch: 5| Step: 4
Training loss: 0.1720960506886685
Validation loss: 2.1689224393767996

Epoch: 5| Step: 5
Training loss: 0.15407356568729938
Validation loss: 2.1686901118895516

Epoch: 5| Step: 6
Training loss: 0.1489472420660249
Validation loss: 2.1558984794220173

Epoch: 5| Step: 7
Training loss: 0.08103364361049753
Validation loss: 2.177274879742681

Epoch: 5| Step: 8
Training loss: 0.11887009972180561
Validation loss: 2.1610609034381665

Epoch: 5| Step: 9
Training loss: 0.10081422233144959
Validation loss: 2.1854900102824653

Epoch: 5| Step: 10
Training loss: 0.09784983045221463
Validation loss: 2.12939190487644

Epoch: 703| Step: 0
Training loss: 0.13863276883896103
Validation loss: 2.1479308186245247

Epoch: 5| Step: 1
Training loss: 0.1534390081187793
Validation loss: 2.179172656922905

Epoch: 5| Step: 2
Training loss: 0.15933874877334997
Validation loss: 2.1717453147170462

Epoch: 5| Step: 3
Training loss: 0.10931341958136274
Validation loss: 2.1852923068519607

Epoch: 5| Step: 4
Training loss: 0.07009663825306969
Validation loss: 2.17538838076067

Epoch: 5| Step: 5
Training loss: 0.06863660794827153
Validation loss: 2.1805325509016065

Epoch: 5| Step: 6
Training loss: 0.07520270001671597
Validation loss: 2.153741787514552

Epoch: 5| Step: 7
Training loss: 0.101152076772399
Validation loss: 2.1865788730997635

Epoch: 5| Step: 8
Training loss: 0.10430550610979161
Validation loss: 2.1730634144393215

Epoch: 5| Step: 9
Training loss: 0.10401147268647766
Validation loss: 2.1810115433409116

Epoch: 5| Step: 10
Training loss: 0.08107147272799281
Validation loss: 2.1698128450873324

Epoch: 704| Step: 0
Training loss: 0.14017875386530812
Validation loss: 2.159744575646041

Epoch: 5| Step: 1
Training loss: 0.10388690115820658
Validation loss: 2.1665472060023103

Epoch: 5| Step: 2
Training loss: 0.08082489105335111
Validation loss: 2.1889170245304337

Epoch: 5| Step: 3
Training loss: 0.08971912094931082
Validation loss: 2.169893865150815

Epoch: 5| Step: 4
Training loss: 0.08426102549882401
Validation loss: 2.1709950257098565

Epoch: 5| Step: 5
Training loss: 0.05484018129437389
Validation loss: 2.1941351374245577

Epoch: 5| Step: 6
Training loss: 0.1358439318043835
Validation loss: 2.1871440908483466

Epoch: 5| Step: 7
Training loss: 0.10988474742136431
Validation loss: 2.184441155579336

Epoch: 5| Step: 8
Training loss: 0.12682310929437168
Validation loss: 2.1729036511082414

Epoch: 5| Step: 9
Training loss: 0.14329300599245517
Validation loss: 2.166160438771472

Epoch: 5| Step: 10
Training loss: 0.10621350973086362
Validation loss: 2.1679750202402013

Epoch: 705| Step: 0
Training loss: 0.13154820019033764
Validation loss: 2.1668894095576032

Epoch: 5| Step: 1
Training loss: 0.09452880292672881
Validation loss: 2.155081103840368

Epoch: 5| Step: 2
Training loss: 0.07661301384281433
Validation loss: 2.1820951829483923

Epoch: 5| Step: 3
Training loss: 0.0696573564474487
Validation loss: 2.1487136212927167

Epoch: 5| Step: 4
Training loss: 0.07837023986806044
Validation loss: 2.1668944522074662

Epoch: 5| Step: 5
Training loss: 0.10706882113225617
Validation loss: 2.142300120935847

Epoch: 5| Step: 6
Training loss: 0.1315293101786024
Validation loss: 2.1545402997646184

Epoch: 5| Step: 7
Training loss: 0.07282491713151495
Validation loss: 2.134916171756039

Epoch: 5| Step: 8
Training loss: 0.06469956879744782
Validation loss: 2.1452189528803105

Epoch: 5| Step: 9
Training loss: 0.13412787701790976
Validation loss: 2.147193401112927

Epoch: 5| Step: 10
Training loss: 0.06237197220454193
Validation loss: 2.142222057899198

Epoch: 706| Step: 0
Training loss: 0.05632228222158297
Validation loss: 2.144668695136809

Epoch: 5| Step: 1
Training loss: 0.09017938655845029
Validation loss: 2.1533937192207016

Epoch: 5| Step: 2
Training loss: 0.05779652245860827
Validation loss: 2.148357328259612

Epoch: 5| Step: 3
Training loss: 0.1607478658755475
Validation loss: 2.1506806650460617

Epoch: 5| Step: 4
Training loss: 0.12389928505937944
Validation loss: 2.1282613333819405

Epoch: 5| Step: 5
Training loss: 0.07111500367339373
Validation loss: 2.15719758325513

Epoch: 5| Step: 6
Training loss: 0.06740413894959794
Validation loss: 2.1501430879289316

Epoch: 5| Step: 7
Training loss: 0.07620948999830071
Validation loss: 2.148051010673959

Epoch: 5| Step: 8
Training loss: 0.08200756366812274
Validation loss: 2.1373006601914875

Epoch: 5| Step: 9
Training loss: 0.0950169928545888
Validation loss: 2.1715343488827674

Epoch: 5| Step: 10
Training loss: 0.08703170540397703
Validation loss: 2.1646251344665983

Epoch: 707| Step: 0
Training loss: 0.10813187997626873
Validation loss: 2.1457197750862087

Epoch: 5| Step: 1
Training loss: 0.1089550966839092
Validation loss: 2.147600157919036

Epoch: 5| Step: 2
Training loss: 0.13809570644846156
Validation loss: 2.1624092912045447

Epoch: 5| Step: 3
Training loss: 0.07756770563408427
Validation loss: 2.134724552614433

Epoch: 5| Step: 4
Training loss: 0.053615474395503744
Validation loss: 2.1490679886540525

Epoch: 5| Step: 5
Training loss: 0.08324447441629346
Validation loss: 2.117137698717808

Epoch: 5| Step: 6
Training loss: 0.15225327690752546
Validation loss: 2.1287335400548986

Epoch: 5| Step: 7
Training loss: 0.12803337758014138
Validation loss: 2.1159617335689473

Epoch: 5| Step: 8
Training loss: 0.11040845602775483
Validation loss: 2.1388542360885707

Epoch: 5| Step: 9
Training loss: 0.12235972238709814
Validation loss: 2.1371119839000694

Epoch: 5| Step: 10
Training loss: 0.08987988906144616
Validation loss: 2.1244778326348968

Epoch: 708| Step: 0
Training loss: 0.09636501195374692
Validation loss: 2.11501846148522

Epoch: 5| Step: 1
Training loss: 0.16420004392407256
Validation loss: 2.146498484933096

Epoch: 5| Step: 2
Training loss: 0.05049722590431078
Validation loss: 2.144651032497306

Epoch: 5| Step: 3
Training loss: 0.13590130981936197
Validation loss: 2.1386139736783782

Epoch: 5| Step: 4
Training loss: 0.07179037611586993
Validation loss: 2.148492207804804

Epoch: 5| Step: 5
Training loss: 0.0744515332174913
Validation loss: 2.1334911494114928

Epoch: 5| Step: 6
Training loss: 0.08004747071510826
Validation loss: 2.15024049817969

Epoch: 5| Step: 7
Training loss: 0.0701629087149162
Validation loss: 2.1473817082529942

Epoch: 5| Step: 8
Training loss: 0.08192554259271154
Validation loss: 2.131049673136888

Epoch: 5| Step: 9
Training loss: 0.06885474418786523
Validation loss: 2.1543448813623503

Epoch: 5| Step: 10
Training loss: 0.05354234070359805
Validation loss: 2.1512745515130085

Epoch: 709| Step: 0
Training loss: 0.06332311790530239
Validation loss: 2.151010084964458

Epoch: 5| Step: 1
Training loss: 0.1313243831167251
Validation loss: 2.144336962030213

Epoch: 5| Step: 2
Training loss: 0.0827246661248506
Validation loss: 2.168593282115152

Epoch: 5| Step: 3
Training loss: 0.1363093855146552
Validation loss: 2.1633355984958067

Epoch: 5| Step: 4
Training loss: 0.12579617411766825
Validation loss: 2.1482917302145044

Epoch: 5| Step: 5
Training loss: 0.07456000826877796
Validation loss: 2.156571146605551

Epoch: 5| Step: 6
Training loss: 0.05700564944811241
Validation loss: 2.176344202069053

Epoch: 5| Step: 7
Training loss: 0.04915894496639425
Validation loss: 2.1674980642234836

Epoch: 5| Step: 8
Training loss: 0.08844176317527681
Validation loss: 2.1633211759104336

Epoch: 5| Step: 9
Training loss: 0.09155337015567004
Validation loss: 2.1714050635614446

Epoch: 5| Step: 10
Training loss: 0.08368575712476667
Validation loss: 2.1675131124890936

Epoch: 710| Step: 0
Training loss: 0.1402226626464747
Validation loss: 2.154007392696906

Epoch: 5| Step: 1
Training loss: 0.06766109086926153
Validation loss: 2.152506382780895

Epoch: 5| Step: 2
Training loss: 0.1026938042832833
Validation loss: 2.1665973944116907

Epoch: 5| Step: 3
Training loss: 0.13704922788690235
Validation loss: 2.1424850647215594

Epoch: 5| Step: 4
Training loss: 0.043116590180469816
Validation loss: 2.139177297971158

Epoch: 5| Step: 5
Training loss: 0.07690429081992474
Validation loss: 2.1412943096133223

Epoch: 5| Step: 6
Training loss: 0.0813118864002577
Validation loss: 2.130447675919148

Epoch: 5| Step: 7
Training loss: 0.1125726819360542
Validation loss: 2.1397052235277716

Epoch: 5| Step: 8
Training loss: 0.06513243379467928
Validation loss: 2.1480630611358715

Epoch: 5| Step: 9
Training loss: 0.07296244285657069
Validation loss: 2.168172240044921

Epoch: 5| Step: 10
Training loss: 0.10256757793838894
Validation loss: 2.163291531125166

Epoch: 711| Step: 0
Training loss: 0.06366410793134768
Validation loss: 2.1718881328826356

Epoch: 5| Step: 1
Training loss: 0.1579365132074207
Validation loss: 2.1517505887365465

Epoch: 5| Step: 2
Training loss: 0.1269372930191659
Validation loss: 2.158977028316843

Epoch: 5| Step: 3
Training loss: 0.0789788377313163
Validation loss: 2.173352668168066

Epoch: 5| Step: 4
Training loss: 0.13799338847628326
Validation loss: 2.1964910207313864

Epoch: 5| Step: 5
Training loss: 0.17239405543706146
Validation loss: 2.2249863358571536

Epoch: 5| Step: 6
Training loss: 0.16037475985005833
Validation loss: 2.164937906504716

Epoch: 5| Step: 7
Training loss: 0.09208990564273441
Validation loss: 2.1324381403039188

Epoch: 5| Step: 8
Training loss: 0.1377298704028477
Validation loss: 2.1393630725325745

Epoch: 5| Step: 9
Training loss: 0.15036150415049374
Validation loss: 2.1508912510596954

Epoch: 5| Step: 10
Training loss: 0.11497165343529289
Validation loss: 2.127301720673889

Epoch: 712| Step: 0
Training loss: 0.18944540696301226
Validation loss: 2.147660374155039

Epoch: 5| Step: 1
Training loss: 0.18140977115154472
Validation loss: 2.1654665467282697

Epoch: 5| Step: 2
Training loss: 0.1396904595379436
Validation loss: 2.1605201214011562

Epoch: 5| Step: 3
Training loss: 0.13580006799355576
Validation loss: 2.161497276796447

Epoch: 5| Step: 4
Training loss: 0.18409042946354842
Validation loss: 2.1865045934258243

Epoch: 5| Step: 5
Training loss: 0.16761453006356244
Validation loss: 2.2135425495722614

Epoch: 5| Step: 6
Training loss: 0.10482871153834131
Validation loss: 2.1931311289601183

Epoch: 5| Step: 7
Training loss: 0.0975094120437561
Validation loss: 2.181531978059648

Epoch: 5| Step: 8
Training loss: 0.11649482176824044
Validation loss: 2.2132575828672443

Epoch: 5| Step: 9
Training loss: 0.10821809458554787
Validation loss: 2.198327772608694

Epoch: 5| Step: 10
Training loss: 0.1281565627322396
Validation loss: 2.1889999708278354

Epoch: 713| Step: 0
Training loss: 0.10197644058450542
Validation loss: 2.1767088641669288

Epoch: 5| Step: 1
Training loss: 0.11058865876321045
Validation loss: 2.1934735399544665

Epoch: 5| Step: 2
Training loss: 0.14184999705658521
Validation loss: 2.198088840151732

Epoch: 5| Step: 3
Training loss: 0.1577597692887113
Validation loss: 2.2023704253029974

Epoch: 5| Step: 4
Training loss: 0.12800837419169553
Validation loss: 2.1917306114780466

Epoch: 5| Step: 5
Training loss: 0.14763974092420482
Validation loss: 2.170567451857618

Epoch: 5| Step: 6
Training loss: 0.11679495790751776
Validation loss: 2.154357183999343

Epoch: 5| Step: 7
Training loss: 0.08995176125228667
Validation loss: 2.1645768231390106

Epoch: 5| Step: 8
Training loss: 0.10070341619948138
Validation loss: 2.129573089967067

Epoch: 5| Step: 9
Training loss: 0.10512276254426278
Validation loss: 2.129455349883865

Epoch: 5| Step: 10
Training loss: 0.12668039664588454
Validation loss: 2.1626654899068796

Epoch: 714| Step: 0
Training loss: 0.06368850025822492
Validation loss: 2.132981075040702

Epoch: 5| Step: 1
Training loss: 0.1464709021412424
Validation loss: 2.1470190382944607

Epoch: 5| Step: 2
Training loss: 0.098734119057267
Validation loss: 2.152814899415181

Epoch: 5| Step: 3
Training loss: 0.10881841338942926
Validation loss: 2.119552783174733

Epoch: 5| Step: 4
Training loss: 0.11542770364673449
Validation loss: 2.1657817303776628

Epoch: 5| Step: 5
Training loss: 0.07732647861917918
Validation loss: 2.181667319528581

Epoch: 5| Step: 6
Training loss: 0.09441835858471023
Validation loss: 2.1629410844123322

Epoch: 5| Step: 7
Training loss: 0.09308961396795062
Validation loss: 2.13798308017227

Epoch: 5| Step: 8
Training loss: 0.13238656239898383
Validation loss: 2.1324308957679956

Epoch: 5| Step: 9
Training loss: 0.1224123207276098
Validation loss: 2.1425023829575083

Epoch: 5| Step: 10
Training loss: 0.07245825533774027
Validation loss: 2.1377074848981032

Epoch: 715| Step: 0
Training loss: 0.07634328543720377
Validation loss: 2.141019901658324

Epoch: 5| Step: 1
Training loss: 0.10245900434792948
Validation loss: 2.1065113702816918

Epoch: 5| Step: 2
Training loss: 0.07750356099288451
Validation loss: 2.1299293271767556

Epoch: 5| Step: 3
Training loss: 0.09618093462648222
Validation loss: 2.114610027357108

Epoch: 5| Step: 4
Training loss: 0.08432048254915747
Validation loss: 2.1182794414827026

Epoch: 5| Step: 5
Training loss: 0.09224483073167697
Validation loss: 2.1555034456120112

Epoch: 5| Step: 6
Training loss: 0.13681820249501533
Validation loss: 2.125064974327772

Epoch: 5| Step: 7
Training loss: 0.06716415961851913
Validation loss: 2.14936478845004

Epoch: 5| Step: 8
Training loss: 0.07883526576433328
Validation loss: 2.1301141731068522

Epoch: 5| Step: 9
Training loss: 0.14694494955794918
Validation loss: 2.140431544400133

Epoch: 5| Step: 10
Training loss: 0.13412241233887454
Validation loss: 2.120852742983792

Epoch: 716| Step: 0
Training loss: 0.07791254839855107
Validation loss: 2.1577634263361447

Epoch: 5| Step: 1
Training loss: 0.17889626071144848
Validation loss: 2.1410159825899058

Epoch: 5| Step: 2
Training loss: 0.0665301681401926
Validation loss: 2.1537546929188376

Epoch: 5| Step: 3
Training loss: 0.07051284050911659
Validation loss: 2.128033842316924

Epoch: 5| Step: 4
Training loss: 0.0772798752492773
Validation loss: 2.1371877301503366

Epoch: 5| Step: 5
Training loss: 0.1378129294447144
Validation loss: 2.1238073081895856

Epoch: 5| Step: 6
Training loss: 0.1283379076734893
Validation loss: 2.1350131915490578

Epoch: 5| Step: 7
Training loss: 0.10110339144552913
Validation loss: 2.1263353560326186

Epoch: 5| Step: 8
Training loss: 0.09377009454584598
Validation loss: 2.116948665259479

Epoch: 5| Step: 9
Training loss: 0.12445539808861522
Validation loss: 2.1453167605880026

Epoch: 5| Step: 10
Training loss: 0.08579526314292057
Validation loss: 2.118857943297421

Epoch: 717| Step: 0
Training loss: 0.08574470112272589
Validation loss: 2.124401712251742

Epoch: 5| Step: 1
Training loss: 0.07071746001160636
Validation loss: 2.1431042976941628

Epoch: 5| Step: 2
Training loss: 0.14893381691187402
Validation loss: 2.1367524293923523

Epoch: 5| Step: 3
Training loss: 0.07393872929995748
Validation loss: 2.134800189032028

Epoch: 5| Step: 4
Training loss: 0.07133623417596369
Validation loss: 2.139239392192225

Epoch: 5| Step: 5
Training loss: 0.08692783610900046
Validation loss: 2.1340199674739773

Epoch: 5| Step: 6
Training loss: 0.08902848978841904
Validation loss: 2.1590808858362567

Epoch: 5| Step: 7
Training loss: 0.12043834025392271
Validation loss: 2.1423359545215512

Epoch: 5| Step: 8
Training loss: 0.1371829598920336
Validation loss: 2.1464057487031174

Epoch: 5| Step: 9
Training loss: 0.1327834658582618
Validation loss: 2.154191551541589

Epoch: 5| Step: 10
Training loss: 0.10948642521617147
Validation loss: 2.1536127970705428

Epoch: 718| Step: 0
Training loss: 0.13069432083593724
Validation loss: 2.1491801259501067

Epoch: 5| Step: 1
Training loss: 0.07051148339011902
Validation loss: 2.1483384202948654

Epoch: 5| Step: 2
Training loss: 0.10818202952686415
Validation loss: 2.1555103259709534

Epoch: 5| Step: 3
Training loss: 0.1334759326548197
Validation loss: 2.12645250150637

Epoch: 5| Step: 4
Training loss: 0.06788878244658637
Validation loss: 2.1533809941000874

Epoch: 5| Step: 5
Training loss: 0.16339835206826842
Validation loss: 2.150444753804831

Epoch: 5| Step: 6
Training loss: 0.12037206760491011
Validation loss: 2.1612297031084817

Epoch: 5| Step: 7
Training loss: 0.09412740202988594
Validation loss: 2.1577265527160785

Epoch: 5| Step: 8
Training loss: 0.09411269798599983
Validation loss: 2.1297651202340875

Epoch: 5| Step: 9
Training loss: 0.09571121629259138
Validation loss: 2.139322547377556

Epoch: 5| Step: 10
Training loss: 0.08667765300816281
Validation loss: 2.13210417629768

Epoch: 719| Step: 0
Training loss: 0.07588121393492099
Validation loss: 2.157237277056816

Epoch: 5| Step: 1
Training loss: 0.12613390182823342
Validation loss: 2.1217422329519646

Epoch: 5| Step: 2
Training loss: 0.1592217430773055
Validation loss: 2.118659890111439

Epoch: 5| Step: 3
Training loss: 0.11395644522270319
Validation loss: 2.1160443363506167

Epoch: 5| Step: 4
Training loss: 0.09241493626309746
Validation loss: 2.1292118855242363

Epoch: 5| Step: 5
Training loss: 0.10232279996257859
Validation loss: 2.149711048553506

Epoch: 5| Step: 6
Training loss: 0.07304717487130857
Validation loss: 2.1280379611794515

Epoch: 5| Step: 7
Training loss: 0.13740589622563065
Validation loss: 2.1494139432283923

Epoch: 5| Step: 8
Training loss: 0.13355268354717156
Validation loss: 2.134746267600633

Epoch: 5| Step: 9
Training loss: 0.13025087535796478
Validation loss: 2.129444594258827

Epoch: 5| Step: 10
Training loss: 0.07747543123859327
Validation loss: 2.149778223916832

Epoch: 720| Step: 0
Training loss: 0.08464338986425028
Validation loss: 2.1546066177979526

Epoch: 5| Step: 1
Training loss: 0.07130259555236057
Validation loss: 2.1633870511641495

Epoch: 5| Step: 2
Training loss: 0.06955941545968644
Validation loss: 2.1606841534225443

Epoch: 5| Step: 3
Training loss: 0.15194398440643075
Validation loss: 2.1608221721813736

Epoch: 5| Step: 4
Training loss: 0.14548804001590365
Validation loss: 2.168722123912599

Epoch: 5| Step: 5
Training loss: 0.0804590145258726
Validation loss: 2.1685110188339105

Epoch: 5| Step: 6
Training loss: 0.11679104260965639
Validation loss: 2.175301566673849

Epoch: 5| Step: 7
Training loss: 0.06652254552013583
Validation loss: 2.168526063025736

Epoch: 5| Step: 8
Training loss: 0.1560942887248231
Validation loss: 2.1472262664127006

Epoch: 5| Step: 9
Training loss: 0.09565113076017977
Validation loss: 2.164444342963719

Epoch: 5| Step: 10
Training loss: 0.14185287273625655
Validation loss: 2.1615514216051026

Epoch: 721| Step: 0
Training loss: 0.1466810241617997
Validation loss: 2.1572933255858766

Epoch: 5| Step: 1
Training loss: 0.1415302886483831
Validation loss: 2.127094810650686

Epoch: 5| Step: 2
Training loss: 0.07668272524474913
Validation loss: 2.1330160477859077

Epoch: 5| Step: 3
Training loss: 0.08548478067720515
Validation loss: 2.1403584384303116

Epoch: 5| Step: 4
Training loss: 0.08866035054640148
Validation loss: 2.1229392971398586

Epoch: 5| Step: 5
Training loss: 0.12894301901565702
Validation loss: 2.145816613154188

Epoch: 5| Step: 6
Training loss: 0.12432832113914269
Validation loss: 2.173990209519819

Epoch: 5| Step: 7
Training loss: 0.09313500869013677
Validation loss: 2.1730583321316908

Epoch: 5| Step: 8
Training loss: 0.09153085065606738
Validation loss: 2.152795367897337

Epoch: 5| Step: 9
Training loss: 0.10777834354667049
Validation loss: 2.161177338473247

Epoch: 5| Step: 10
Training loss: 0.09289795399877578
Validation loss: 2.152836221154585

Epoch: 722| Step: 0
Training loss: 0.07663001239279855
Validation loss: 2.136621186426984

Epoch: 5| Step: 1
Training loss: 0.07563693546460538
Validation loss: 2.146145207072101

Epoch: 5| Step: 2
Training loss: 0.0644382293423559
Validation loss: 2.149571003889065

Epoch: 5| Step: 3
Training loss: 0.10722572017123426
Validation loss: 2.131855236396006

Epoch: 5| Step: 4
Training loss: 0.10039696951681902
Validation loss: 2.135488760326721

Epoch: 5| Step: 5
Training loss: 0.07858223331605771
Validation loss: 2.1552582835543572

Epoch: 5| Step: 6
Training loss: 0.07394791426718855
Validation loss: 2.1430084920720116

Epoch: 5| Step: 7
Training loss: 0.14244054662501832
Validation loss: 2.1191637559912477

Epoch: 5| Step: 8
Training loss: 0.1520831924322425
Validation loss: 2.1238694926725348

Epoch: 5| Step: 9
Training loss: 0.06308310785827022
Validation loss: 2.135763279966621

Epoch: 5| Step: 10
Training loss: 0.07717349756025378
Validation loss: 2.143293644990509

Epoch: 723| Step: 0
Training loss: 0.07877760647830043
Validation loss: 2.127402950233786

Epoch: 5| Step: 1
Training loss: 0.07495971096738968
Validation loss: 2.1147849950968705

Epoch: 5| Step: 2
Training loss: 0.0816756214532717
Validation loss: 2.141795430103784

Epoch: 5| Step: 3
Training loss: 0.05004997252109604
Validation loss: 2.126656905147448

Epoch: 5| Step: 4
Training loss: 0.060886205120028625
Validation loss: 2.1196737900399154

Epoch: 5| Step: 5
Training loss: 0.13051931834603822
Validation loss: 2.1091380768274046

Epoch: 5| Step: 6
Training loss: 0.05274352020862168
Validation loss: 2.147799403499899

Epoch: 5| Step: 7
Training loss: 0.08147756729142862
Validation loss: 2.141456274333825

Epoch: 5| Step: 8
Training loss: 0.10590979406516972
Validation loss: 2.1190641302157385

Epoch: 5| Step: 9
Training loss: 0.13189245354829082
Validation loss: 2.133131424452546

Epoch: 5| Step: 10
Training loss: 0.08949883742250016
Validation loss: 2.1102463405675898

Epoch: 724| Step: 0
Training loss: 0.09798302813343227
Validation loss: 2.12424787086927

Epoch: 5| Step: 1
Training loss: 0.07866683166745142
Validation loss: 2.133113948712067

Epoch: 5| Step: 2
Training loss: 0.06317963108684295
Validation loss: 2.109050347469474

Epoch: 5| Step: 3
Training loss: 0.06298568631526857
Validation loss: 2.135303996365424

Epoch: 5| Step: 4
Training loss: 0.12721936112690233
Validation loss: 2.1294594094139154

Epoch: 5| Step: 5
Training loss: 0.1117161547085946
Validation loss: 2.149989459046997

Epoch: 5| Step: 6
Training loss: 0.07766665475324068
Validation loss: 2.1444600196169827

Epoch: 5| Step: 7
Training loss: 0.05893375572573737
Validation loss: 2.1631022994051485

Epoch: 5| Step: 8
Training loss: 0.08256716735809567
Validation loss: 2.1530005182880285

Epoch: 5| Step: 9
Training loss: 0.08178817406715758
Validation loss: 2.159947649738857

Epoch: 5| Step: 10
Training loss: 0.06857071971631142
Validation loss: 2.156509405211164

Epoch: 725| Step: 0
Training loss: 0.061261238993813194
Validation loss: 2.1492964163298254

Epoch: 5| Step: 1
Training loss: 0.14112529241533284
Validation loss: 2.1647503316033516

Epoch: 5| Step: 2
Training loss: 0.07307623818738744
Validation loss: 2.146724075405323

Epoch: 5| Step: 3
Training loss: 0.08872098214121872
Validation loss: 2.134621477874146

Epoch: 5| Step: 4
Training loss: 0.09371225272651422
Validation loss: 2.1607221701630546

Epoch: 5| Step: 5
Training loss: 0.08531529421998786
Validation loss: 2.1614955949789985

Epoch: 5| Step: 6
Training loss: 0.12348795354639953
Validation loss: 2.1365891529952403

Epoch: 5| Step: 7
Training loss: 0.07600715139115052
Validation loss: 2.1739934653792354

Epoch: 5| Step: 8
Training loss: 0.08614191485120318
Validation loss: 2.150471005856063

Epoch: 5| Step: 9
Training loss: 0.08981856739558373
Validation loss: 2.0967771453615778

Epoch: 5| Step: 10
Training loss: 0.059696439203463764
Validation loss: 2.131471833002826

Epoch: 726| Step: 0
Training loss: 0.08793405943093081
Validation loss: 2.120826822993707

Epoch: 5| Step: 1
Training loss: 0.11609946843307131
Validation loss: 2.1269340183194583

Epoch: 5| Step: 2
Training loss: 0.12045929038538912
Validation loss: 2.1354054096284374

Epoch: 5| Step: 3
Training loss: 0.12553120038708407
Validation loss: 2.1359915963077074

Epoch: 5| Step: 4
Training loss: 0.0636824642924296
Validation loss: 2.1218192830254514

Epoch: 5| Step: 5
Training loss: 0.08970306618613312
Validation loss: 2.166558650694892

Epoch: 5| Step: 6
Training loss: 0.06923914923614806
Validation loss: 2.1431231534487334

Epoch: 5| Step: 7
Training loss: 0.056780242258706995
Validation loss: 2.1460792965235798

Epoch: 5| Step: 8
Training loss: 0.04852849100963507
Validation loss: 2.1323946925560806

Epoch: 5| Step: 9
Training loss: 0.07264596497126574
Validation loss: 2.1343527810129

Epoch: 5| Step: 10
Training loss: 0.08548949790927236
Validation loss: 2.137100032433201

Epoch: 727| Step: 0
Training loss: 0.09723669525779047
Validation loss: 2.1571438951597304

Epoch: 5| Step: 1
Training loss: 0.07728318325895568
Validation loss: 2.178616644743182

Epoch: 5| Step: 2
Training loss: 0.05277085587718724
Validation loss: 2.143706013825489

Epoch: 5| Step: 3
Training loss: 0.15189250727400475
Validation loss: 2.1576206261417923

Epoch: 5| Step: 4
Training loss: 0.09470895229915773
Validation loss: 2.1551256626544237

Epoch: 5| Step: 5
Training loss: 0.08056357118646858
Validation loss: 2.153895971209635

Epoch: 5| Step: 6
Training loss: 0.10017141555403487
Validation loss: 2.1494369315157504

Epoch: 5| Step: 7
Training loss: 0.07064752763801152
Validation loss: 2.141420057898659

Epoch: 5| Step: 8
Training loss: 0.07447865428726085
Validation loss: 2.1600906209895587

Epoch: 5| Step: 9
Training loss: 0.07047466280759436
Validation loss: 2.1400159282645483

Epoch: 5| Step: 10
Training loss: 0.11696164698949656
Validation loss: 2.121719738442513

Epoch: 728| Step: 0
Training loss: 0.059125118071390814
Validation loss: 2.1451270460074316

Epoch: 5| Step: 1
Training loss: 0.078182181651247
Validation loss: 2.1425898508778976

Epoch: 5| Step: 2
Training loss: 0.08346828756165021
Validation loss: 2.137759661427059

Epoch: 5| Step: 3
Training loss: 0.03296115656158535
Validation loss: 2.1346665075953246

Epoch: 5| Step: 4
Training loss: 0.06055419631500908
Validation loss: 2.1424228252487683

Epoch: 5| Step: 5
Training loss: 0.07198459197600189
Validation loss: 2.1464595050317707

Epoch: 5| Step: 6
Training loss: 0.09114207418954998
Validation loss: 2.1412055352096706

Epoch: 5| Step: 7
Training loss: 0.13973661453225183
Validation loss: 2.1576935252190363

Epoch: 5| Step: 8
Training loss: 0.05615234996961476
Validation loss: 2.156881628370738

Epoch: 5| Step: 9
Training loss: 0.1147480944195287
Validation loss: 2.1493810991539557

Epoch: 5| Step: 10
Training loss: 0.05683256381794317
Validation loss: 2.1680427388613284

Epoch: 729| Step: 0
Training loss: 0.08326570615408349
Validation loss: 2.1686077269724966

Epoch: 5| Step: 1
Training loss: 0.0913323968062858
Validation loss: 2.1662905613517416

Epoch: 5| Step: 2
Training loss: 0.08920429553575081
Validation loss: 2.1616041786358156

Epoch: 5| Step: 3
Training loss: 0.0536966933522862
Validation loss: 2.1552549393235085

Epoch: 5| Step: 4
Training loss: 0.14307630068574204
Validation loss: 2.168615686439074

Epoch: 5| Step: 5
Training loss: 0.12860787423020245
Validation loss: 2.1592349815452394

Epoch: 5| Step: 6
Training loss: 0.08556002652962284
Validation loss: 2.157070023601717

Epoch: 5| Step: 7
Training loss: 0.08589538983849206
Validation loss: 2.1560310346516656

Epoch: 5| Step: 8
Training loss: 0.08321301397021906
Validation loss: 2.146103353821679

Epoch: 5| Step: 9
Training loss: 0.043932428060631565
Validation loss: 2.1574411144535284

Epoch: 5| Step: 10
Training loss: 0.13024831555360955
Validation loss: 2.1473096871596313

Epoch: 730| Step: 0
Training loss: 0.08521795858617902
Validation loss: 2.1757517967823516

Epoch: 5| Step: 1
Training loss: 0.09171510666429725
Validation loss: 2.147003831461007

Epoch: 5| Step: 2
Training loss: 0.06374286397796379
Validation loss: 2.150310060518036

Epoch: 5| Step: 3
Training loss: 0.05857101237675351
Validation loss: 2.1561867085055737

Epoch: 5| Step: 4
Training loss: 0.09424226880902123
Validation loss: 2.1620786683790705

Epoch: 5| Step: 5
Training loss: 0.043081679739033873
Validation loss: 2.1623114202001292

Epoch: 5| Step: 6
Training loss: 0.05747305493335458
Validation loss: 2.157244585052813

Epoch: 5| Step: 7
Training loss: 0.16721559382079795
Validation loss: 2.150643546315765

Epoch: 5| Step: 8
Training loss: 0.08084109613425879
Validation loss: 2.1226783027460363

Epoch: 5| Step: 9
Training loss: 0.07947235855961787
Validation loss: 2.145612621296338

Epoch: 5| Step: 10
Training loss: 0.09969287999801693
Validation loss: 2.1431014814733476

Epoch: 731| Step: 0
Training loss: 0.06914365662108392
Validation loss: 2.1582047131666693

Epoch: 5| Step: 1
Training loss: 0.05180769666697403
Validation loss: 2.146177833095829

Epoch: 5| Step: 2
Training loss: 0.06531295754532505
Validation loss: 2.14489756413793

Epoch: 5| Step: 3
Training loss: 0.08447672993974911
Validation loss: 2.145976746264142

Epoch: 5| Step: 4
Training loss: 0.049357279278991986
Validation loss: 2.1408968624771676

Epoch: 5| Step: 5
Training loss: 0.11130779900629412
Validation loss: 2.1660627271981028

Epoch: 5| Step: 6
Training loss: 0.10373579309324198
Validation loss: 2.1700115063324765

Epoch: 5| Step: 7
Training loss: 0.07514846568628082
Validation loss: 2.1435560951636603

Epoch: 5| Step: 8
Training loss: 0.07294890494323807
Validation loss: 2.1460899998386207

Epoch: 5| Step: 9
Training loss: 0.1095759810207081
Validation loss: 2.1523586052551917

Epoch: 5| Step: 10
Training loss: 0.06639730870133115
Validation loss: 2.15362601750903

Epoch: 732| Step: 0
Training loss: 0.05906992780436298
Validation loss: 2.1455816815682573

Epoch: 5| Step: 1
Training loss: 0.0701556476161473
Validation loss: 2.1629596341943897

Epoch: 5| Step: 2
Training loss: 0.052811336871323576
Validation loss: 2.158835474534508

Epoch: 5| Step: 3
Training loss: 0.06765664478257301
Validation loss: 2.1568528887491873

Epoch: 5| Step: 4
Training loss: 0.05643159838328198
Validation loss: 2.1581195218763747

Epoch: 5| Step: 5
Training loss: 0.13097663863464565
Validation loss: 2.1516670613613273

Epoch: 5| Step: 6
Training loss: 0.05722826891688695
Validation loss: 2.178513002489941

Epoch: 5| Step: 7
Training loss: 0.05031598129430619
Validation loss: 2.1467888755782734

Epoch: 5| Step: 8
Training loss: 0.12449879298716607
Validation loss: 2.176783752515031

Epoch: 5| Step: 9
Training loss: 0.07949500488987118
Validation loss: 2.131121918938672

Epoch: 5| Step: 10
Training loss: 0.09531702281039141
Validation loss: 2.145472353918087

Epoch: 733| Step: 0
Training loss: 0.06179777168848314
Validation loss: 2.13385928368774

Epoch: 5| Step: 1
Training loss: 0.07369720264309088
Validation loss: 2.148984066228035

Epoch: 5| Step: 2
Training loss: 0.05674521269291223
Validation loss: 2.121839106323204

Epoch: 5| Step: 3
Training loss: 0.11608096074758534
Validation loss: 2.135684373003686

Epoch: 5| Step: 4
Training loss: 0.05936765397894201
Validation loss: 2.1345335696318606

Epoch: 5| Step: 5
Training loss: 0.09518244265410854
Validation loss: 2.1186775492060805

Epoch: 5| Step: 6
Training loss: 0.10171689164387578
Validation loss: 2.135997014053345

Epoch: 5| Step: 7
Training loss: 0.1566501857094405
Validation loss: 2.1525616797244775

Epoch: 5| Step: 8
Training loss: 0.07472904354748573
Validation loss: 2.1406382503508112

Epoch: 5| Step: 9
Training loss: 0.08219217229116035
Validation loss: 2.1343705895306146

Epoch: 5| Step: 10
Training loss: 0.07921356348782392
Validation loss: 2.1357158792413538

Epoch: 734| Step: 0
Training loss: 0.12484301081666555
Validation loss: 2.166376925926973

Epoch: 5| Step: 1
Training loss: 0.056010560700597505
Validation loss: 2.1546455675063543

Epoch: 5| Step: 2
Training loss: 0.08359074386646129
Validation loss: 2.1533767510867743

Epoch: 5| Step: 3
Training loss: 0.11897852297773373
Validation loss: 2.1335593821790257

Epoch: 5| Step: 4
Training loss: 0.055333791089441545
Validation loss: 2.1318479665799477

Epoch: 5| Step: 5
Training loss: 0.06446506649714606
Validation loss: 2.107969111335636

Epoch: 5| Step: 6
Training loss: 0.10128654072274441
Validation loss: 2.1412548075519036

Epoch: 5| Step: 7
Training loss: 0.09382526039178374
Validation loss: 2.135943570524365

Epoch: 5| Step: 8
Training loss: 0.08985837008896551
Validation loss: 2.1402771513474663

Epoch: 5| Step: 9
Training loss: 0.0420556517565231
Validation loss: 2.1315883925125516

Epoch: 5| Step: 10
Training loss: 0.08071525002577473
Validation loss: 2.1670914033294464

Epoch: 735| Step: 0
Training loss: 0.0673253740610496
Validation loss: 2.1314078382039234

Epoch: 5| Step: 1
Training loss: 0.10970180088130271
Validation loss: 2.14884492085569

Epoch: 5| Step: 2
Training loss: 0.0710095353500385
Validation loss: 2.1487449209772955

Epoch: 5| Step: 3
Training loss: 0.08208081190063793
Validation loss: 2.12307343805641

Epoch: 5| Step: 4
Training loss: 0.0819536307367479
Validation loss: 2.1475748738125726

Epoch: 5| Step: 5
Training loss: 0.08619055823421759
Validation loss: 2.1527888766040255

Epoch: 5| Step: 6
Training loss: 0.06195036413551985
Validation loss: 2.161466895950225

Epoch: 5| Step: 7
Training loss: 0.11375599481825331
Validation loss: 2.1367573407010925

Epoch: 5| Step: 8
Training loss: 0.06960136690218262
Validation loss: 2.1510243964242495

Epoch: 5| Step: 9
Training loss: 0.06468813849792862
Validation loss: 2.1698036228451696

Epoch: 5| Step: 10
Training loss: 0.1251450531483647
Validation loss: 2.1413777327852834

Epoch: 736| Step: 0
Training loss: 0.06544650274530697
Validation loss: 2.154374049511141

Epoch: 5| Step: 1
Training loss: 0.11437319366534773
Validation loss: 2.1479736077889475

Epoch: 5| Step: 2
Training loss: 0.11534650648787374
Validation loss: 2.1421128579782485

Epoch: 5| Step: 3
Training loss: 0.06279783511845645
Validation loss: 2.1356573275882704

Epoch: 5| Step: 4
Training loss: 0.0936696731636304
Validation loss: 2.128991061106791

Epoch: 5| Step: 5
Training loss: 0.08775398971821942
Validation loss: 2.150257226681393

Epoch: 5| Step: 6
Training loss: 0.06856514071244872
Validation loss: 2.1425802560036016

Epoch: 5| Step: 7
Training loss: 0.0639178015719501
Validation loss: 2.149412930612177

Epoch: 5| Step: 8
Training loss: 0.07772366735139376
Validation loss: 2.1332745300092384

Epoch: 5| Step: 9
Training loss: 0.06743139091517282
Validation loss: 2.1465518728844666

Epoch: 5| Step: 10
Training loss: 0.09449057334413784
Validation loss: 2.1607329539981595

Epoch: 737| Step: 0
Training loss: 0.12046380545590718
Validation loss: 2.16982437770859

Epoch: 5| Step: 1
Training loss: 0.08519323698468939
Validation loss: 2.15616507033767

Epoch: 5| Step: 2
Training loss: 0.06856552782779876
Validation loss: 2.161698819740744

Epoch: 5| Step: 3
Training loss: 0.11061209752924264
Validation loss: 2.1478650261297894

Epoch: 5| Step: 4
Training loss: 0.06537399840020726
Validation loss: 2.150655496723316

Epoch: 5| Step: 5
Training loss: 0.04799746147256691
Validation loss: 2.1559286652413228

Epoch: 5| Step: 6
Training loss: 0.06393151106361097
Validation loss: 2.1374103734362353

Epoch: 5| Step: 7
Training loss: 0.07172988113858975
Validation loss: 2.1690346349276983

Epoch: 5| Step: 8
Training loss: 0.09276205294174542
Validation loss: 2.1583303949755206

Epoch: 5| Step: 9
Training loss: 0.06883614694154123
Validation loss: 2.1325464663832303

Epoch: 5| Step: 10
Training loss: 0.05624528325358793
Validation loss: 2.143370490861652

Epoch: 738| Step: 0
Training loss: 0.06643264260056678
Validation loss: 2.1607559523726345

Epoch: 5| Step: 1
Training loss: 0.06715171687233147
Validation loss: 2.157661166446082

Epoch: 5| Step: 2
Training loss: 0.05755189048546346
Validation loss: 2.1535901295316258

Epoch: 5| Step: 3
Training loss: 0.061090739690051576
Validation loss: 2.1592269477245667

Epoch: 5| Step: 4
Training loss: 0.11727835788764163
Validation loss: 2.130037227204964

Epoch: 5| Step: 5
Training loss: 0.06728013480817445
Validation loss: 2.155229945152181

Epoch: 5| Step: 6
Training loss: 0.07324289957336147
Validation loss: 2.1455369460511475

Epoch: 5| Step: 7
Training loss: 0.11746172212364656
Validation loss: 2.159870835505812

Epoch: 5| Step: 8
Training loss: 0.11261770743158406
Validation loss: 2.1452840031626588

Epoch: 5| Step: 9
Training loss: 0.06670394953291607
Validation loss: 2.131843811786939

Epoch: 5| Step: 10
Training loss: 0.0474781678166746
Validation loss: 2.157180930560291

Epoch: 739| Step: 0
Training loss: 0.05127387936637254
Validation loss: 2.1519006379043644

Epoch: 5| Step: 1
Training loss: 0.04956491338351783
Validation loss: 2.136691936044145

Epoch: 5| Step: 2
Training loss: 0.0668321060663186
Validation loss: 2.1520290260414447

Epoch: 5| Step: 3
Training loss: 0.056041575104403475
Validation loss: 2.1487441723147795

Epoch: 5| Step: 4
Training loss: 0.06675973244367663
Validation loss: 2.1189490698092173

Epoch: 5| Step: 5
Training loss: 0.05742617237463086
Validation loss: 2.143567743933664

Epoch: 5| Step: 6
Training loss: 0.13349891441953948
Validation loss: 2.169643334121634

Epoch: 5| Step: 7
Training loss: 0.12028290396960786
Validation loss: 2.120722604343812

Epoch: 5| Step: 8
Training loss: 0.08695187978204204
Validation loss: 2.1291111441369828

Epoch: 5| Step: 9
Training loss: 0.0721701268091534
Validation loss: 2.153475056129507

Epoch: 5| Step: 10
Training loss: 0.1000921852663604
Validation loss: 2.1616146093914606

Epoch: 740| Step: 0
Training loss: 0.044186144120053554
Validation loss: 2.1611822799806273

Epoch: 5| Step: 1
Training loss: 0.14710773078133305
Validation loss: 2.13881981308459

Epoch: 5| Step: 2
Training loss: 0.06730242785724934
Validation loss: 2.140919866778081

Epoch: 5| Step: 3
Training loss: 0.06261284148566168
Validation loss: 2.16150953872424

Epoch: 5| Step: 4
Training loss: 0.05259489891156743
Validation loss: 2.1454441754284557

Epoch: 5| Step: 5
Training loss: 0.056154373381049325
Validation loss: 2.1590245702370674

Epoch: 5| Step: 6
Training loss: 0.08202202211429234
Validation loss: 2.1580926263551934

Epoch: 5| Step: 7
Training loss: 0.06272276651596428
Validation loss: 2.152773386615249

Epoch: 5| Step: 8
Training loss: 0.04639815641235518
Validation loss: 2.1542261823258353

Epoch: 5| Step: 9
Training loss: 0.104318019066681
Validation loss: 2.1481466128853755

Epoch: 5| Step: 10
Training loss: 0.065692158094469
Validation loss: 2.150401708616757

Epoch: 741| Step: 0
Training loss: 0.10993449975713147
Validation loss: 2.1443221444561194

Epoch: 5| Step: 1
Training loss: 0.07610367815452401
Validation loss: 2.155829545721592

Epoch: 5| Step: 2
Training loss: 0.10191566703618195
Validation loss: 2.1579897655052127

Epoch: 5| Step: 3
Training loss: 0.07578092592209411
Validation loss: 2.136693490407308

Epoch: 5| Step: 4
Training loss: 0.05717972589896224
Validation loss: 2.1403297632099996

Epoch: 5| Step: 5
Training loss: 0.06535879963797804
Validation loss: 2.122551104730922

Epoch: 5| Step: 6
Training loss: 0.14517855033558477
Validation loss: 2.1258873085316736

Epoch: 5| Step: 7
Training loss: 0.08175105538583782
Validation loss: 2.1534130938202245

Epoch: 5| Step: 8
Training loss: 0.08150279317443616
Validation loss: 2.1346873554898957

Epoch: 5| Step: 9
Training loss: 0.062386062450227917
Validation loss: 2.1290882575814827

Epoch: 5| Step: 10
Training loss: 0.18389673798301379
Validation loss: 2.13918674512382

Epoch: 742| Step: 0
Training loss: 0.04917075583575591
Validation loss: 2.119178396233992

Epoch: 5| Step: 1
Training loss: 0.11726442832005793
Validation loss: 2.13934883075667

Epoch: 5| Step: 2
Training loss: 0.05936032556218046
Validation loss: 2.116494767331579

Epoch: 5| Step: 3
Training loss: 0.1041091869632512
Validation loss: 2.1030611451831125

Epoch: 5| Step: 4
Training loss: 0.11152107683880039
Validation loss: 2.0933433239391896

Epoch: 5| Step: 5
Training loss: 0.0520437055076211
Validation loss: 2.118558991227092

Epoch: 5| Step: 6
Training loss: 0.08181916078568996
Validation loss: 2.107841897127924

Epoch: 5| Step: 7
Training loss: 0.05977342132442995
Validation loss: 2.116698203200332

Epoch: 5| Step: 8
Training loss: 0.09210592354025939
Validation loss: 2.105287142883051

Epoch: 5| Step: 9
Training loss: 0.0583550997269855
Validation loss: 2.1004182092953596

Epoch: 5| Step: 10
Training loss: 0.07768700128964515
Validation loss: 2.1257844082793045

Epoch: 743| Step: 0
Training loss: 0.12675872003027638
Validation loss: 2.115165117789061

Epoch: 5| Step: 1
Training loss: 0.056873578293553585
Validation loss: 2.102812947351365

Epoch: 5| Step: 2
Training loss: 0.08623336666158389
Validation loss: 2.1180311865850157

Epoch: 5| Step: 3
Training loss: 0.1029413687141711
Validation loss: 2.120957802550731

Epoch: 5| Step: 4
Training loss: 0.0856710687538863
Validation loss: 2.1459128274199935

Epoch: 5| Step: 5
Training loss: 0.07295865811068344
Validation loss: 2.144669161325242

Epoch: 5| Step: 6
Training loss: 0.07475115526424544
Validation loss: 2.1184929285240406

Epoch: 5| Step: 7
Training loss: 0.11542584788847791
Validation loss: 2.122003903045982

Epoch: 5| Step: 8
Training loss: 0.06520692067715941
Validation loss: 2.1378886115868023

Epoch: 5| Step: 9
Training loss: 0.06872969525317424
Validation loss: 2.127100090761205

Epoch: 5| Step: 10
Training loss: 0.07802262453076039
Validation loss: 2.1485634196531174

Epoch: 744| Step: 0
Training loss: 0.06616618435968757
Validation loss: 2.1668537134486097

Epoch: 5| Step: 1
Training loss: 0.07784272997470004
Validation loss: 2.143560783382608

Epoch: 5| Step: 2
Training loss: 0.09465114304678049
Validation loss: 2.153074237453639

Epoch: 5| Step: 3
Training loss: 0.11795838638913304
Validation loss: 2.139299694269252

Epoch: 5| Step: 4
Training loss: 0.07026213590574779
Validation loss: 2.1450519765992326

Epoch: 5| Step: 5
Training loss: 0.06980614328173877
Validation loss: 2.1348703529444792

Epoch: 5| Step: 6
Training loss: 0.12128047620938805
Validation loss: 2.153997921282323

Epoch: 5| Step: 7
Training loss: 0.05298878530648544
Validation loss: 2.138142566038919

Epoch: 5| Step: 8
Training loss: 0.09265755392736365
Validation loss: 2.130318843059983

Epoch: 5| Step: 9
Training loss: 0.06361808040202618
Validation loss: 2.1282819898574417

Epoch: 5| Step: 10
Training loss: 0.06903435708691079
Validation loss: 2.128820691285595

Epoch: 745| Step: 0
Training loss: 0.15662252007589084
Validation loss: 2.1122555260146223

Epoch: 5| Step: 1
Training loss: 0.05559957055946689
Validation loss: 2.115765581219295

Epoch: 5| Step: 2
Training loss: 0.1158411127939723
Validation loss: 2.146562109857347

Epoch: 5| Step: 3
Training loss: 0.0604460341796402
Validation loss: 2.141826282090089

Epoch: 5| Step: 4
Training loss: 0.07797011280588853
Validation loss: 2.1523504117704

Epoch: 5| Step: 5
Training loss: 0.08066739197849426
Validation loss: 2.1220566514344603

Epoch: 5| Step: 6
Training loss: 0.06337704560262725
Validation loss: 2.123004147364478

Epoch: 5| Step: 7
Training loss: 0.07406386728272081
Validation loss: 2.1201147612436078

Epoch: 5| Step: 8
Training loss: 0.09774530165203142
Validation loss: 2.104571654890736

Epoch: 5| Step: 9
Training loss: 0.06767339523314814
Validation loss: 2.134671447121802

Epoch: 5| Step: 10
Training loss: 0.0652868647893044
Validation loss: 2.148973924001507

Epoch: 746| Step: 0
Training loss: 0.039074456352042326
Validation loss: 2.126512260808299

Epoch: 5| Step: 1
Training loss: 0.05396439398523948
Validation loss: 2.127689972906675

Epoch: 5| Step: 2
Training loss: 0.07895211241937378
Validation loss: 2.121061144244129

Epoch: 5| Step: 3
Training loss: 0.12979004350563703
Validation loss: 2.133965341558049

Epoch: 5| Step: 4
Training loss: 0.08561958495562846
Validation loss: 2.141717042837643

Epoch: 5| Step: 5
Training loss: 0.09576287156278067
Validation loss: 2.1376354148968884

Epoch: 5| Step: 6
Training loss: 0.053773665645070495
Validation loss: 2.1351917411504653

Epoch: 5| Step: 7
Training loss: 0.05834416240343084
Validation loss: 2.1359227162873395

Epoch: 5| Step: 8
Training loss: 0.1092025981878907
Validation loss: 2.14094051667266

Epoch: 5| Step: 9
Training loss: 0.0678587223002265
Validation loss: 2.1313867952512244

Epoch: 5| Step: 10
Training loss: 0.07599964906566778
Validation loss: 2.129775596784379

Epoch: 747| Step: 0
Training loss: 0.06471172746933508
Validation loss: 2.1288285159109783

Epoch: 5| Step: 1
Training loss: 0.0791734527698317
Validation loss: 2.122998201363768

Epoch: 5| Step: 2
Training loss: 0.04834247591578164
Validation loss: 2.1155879880548247

Epoch: 5| Step: 3
Training loss: 0.07782434786943966
Validation loss: 2.1420518027111437

Epoch: 5| Step: 4
Training loss: 0.06554105163322228
Validation loss: 2.1491608124958583

Epoch: 5| Step: 5
Training loss: 0.06332486071598588
Validation loss: 2.1150908439778577

Epoch: 5| Step: 6
Training loss: 0.07981433101538761
Validation loss: 2.1351353141584597

Epoch: 5| Step: 7
Training loss: 0.1622610646370617
Validation loss: 2.117435595928925

Epoch: 5| Step: 8
Training loss: 0.09652193280555871
Validation loss: 2.1044077811739936

Epoch: 5| Step: 9
Training loss: 0.05941189549737205
Validation loss: 2.0982227380500467

Epoch: 5| Step: 10
Training loss: 0.09254581233568471
Validation loss: 2.117745533787285

Epoch: 748| Step: 0
Training loss: 0.038570942618883004
Validation loss: 2.1140857890943536

Epoch: 5| Step: 1
Training loss: 0.07038725415688851
Validation loss: 2.1257758778054003

Epoch: 5| Step: 2
Training loss: 0.05361103824446914
Validation loss: 2.1347194324714414

Epoch: 5| Step: 3
Training loss: 0.0622203014777646
Validation loss: 2.1224520099774082

Epoch: 5| Step: 4
Training loss: 0.11582933410065945
Validation loss: 2.150358704740814

Epoch: 5| Step: 5
Training loss: 0.06201835281449979
Validation loss: 2.146177705282769

Epoch: 5| Step: 6
Training loss: 0.05645098674197272
Validation loss: 2.1429605433913466

Epoch: 5| Step: 7
Training loss: 0.08915825222359741
Validation loss: 2.142019553079974

Epoch: 5| Step: 8
Training loss: 0.11001343532626695
Validation loss: 2.1439968947926995

Epoch: 5| Step: 9
Training loss: 0.07437608067444658
Validation loss: 2.1710372292269806

Epoch: 5| Step: 10
Training loss: 0.06564758088264479
Validation loss: 2.1385848171428012

Epoch: 749| Step: 0
Training loss: 0.07296214927453762
Validation loss: 2.121856734126081

Epoch: 5| Step: 1
Training loss: 0.07801708278100049
Validation loss: 2.1492415184644496

Epoch: 5| Step: 2
Training loss: 0.06067979358724233
Validation loss: 2.1434691675076505

Epoch: 5| Step: 3
Training loss: 0.05541165117903488
Validation loss: 2.134447040812548

Epoch: 5| Step: 4
Training loss: 0.07448098947666403
Validation loss: 2.1336327138998774

Epoch: 5| Step: 5
Training loss: 0.03836708954658968
Validation loss: 2.152522795924747

Epoch: 5| Step: 6
Training loss: 0.11024761790207441
Validation loss: 2.142630195783245

Epoch: 5| Step: 7
Training loss: 0.12165780368158723
Validation loss: 2.1652751022066212

Epoch: 5| Step: 8
Training loss: 0.07345875194129706
Validation loss: 2.142160080653118

Epoch: 5| Step: 9
Training loss: 0.10145493459916287
Validation loss: 2.1542015290727403

Epoch: 5| Step: 10
Training loss: 0.06805572165937383
Validation loss: 2.1576724277705717

Epoch: 750| Step: 0
Training loss: 0.10880179578957089
Validation loss: 2.149840171741722

Epoch: 5| Step: 1
Training loss: 0.06399762427495244
Validation loss: 2.167847349135543

Epoch: 5| Step: 2
Training loss: 0.05610612750302434
Validation loss: 2.164849423993376

Epoch: 5| Step: 3
Training loss: 0.07476063594096757
Validation loss: 2.1522372327206685

Epoch: 5| Step: 4
Training loss: 0.07543134491441415
Validation loss: 2.163373310900913

Epoch: 5| Step: 5
Training loss: 0.05566134780822724
Validation loss: 2.1477216967141013

Epoch: 5| Step: 6
Training loss: 0.04856290791406495
Validation loss: 2.153371449689424

Epoch: 5| Step: 7
Training loss: 0.07900873966308619
Validation loss: 2.1451546499433434

Epoch: 5| Step: 8
Training loss: 0.11609439856731853
Validation loss: 2.160140748161124

Epoch: 5| Step: 9
Training loss: 0.08573978340323865
Validation loss: 2.150254743822766

Epoch: 5| Step: 10
Training loss: 0.09912620023906342
Validation loss: 2.1438249168626298

Testing loss: 2.8358355487191194
