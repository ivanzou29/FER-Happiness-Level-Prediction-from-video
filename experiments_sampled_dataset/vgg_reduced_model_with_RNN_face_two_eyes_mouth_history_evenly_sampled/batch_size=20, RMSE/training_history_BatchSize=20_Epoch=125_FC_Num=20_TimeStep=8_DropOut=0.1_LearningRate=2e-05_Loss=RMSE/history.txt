Epoch: 1| Step: 0
Training loss: 6.888496606520676
Validation loss: 5.825868776816321

Epoch: 5| Step: 1
Training loss: 5.286203623180585
Validation loss: 5.79861292266015

Epoch: 5| Step: 2
Training loss: 5.0768838627507895
Validation loss: 5.775772169958203

Epoch: 5| Step: 3
Training loss: 6.165322990773996
Validation loss: 5.752853226021311

Epoch: 5| Step: 4
Training loss: 6.51748359938571
Validation loss: 5.728237778284422

Epoch: 5| Step: 5
Training loss: 5.799352070363995
Validation loss: 5.700389465486216

Epoch: 5| Step: 6
Training loss: 6.020854945512501
Validation loss: 5.667768396024478

Epoch: 5| Step: 7
Training loss: 4.236897410530305
Validation loss: 5.631247576890737

Epoch: 5| Step: 8
Training loss: 5.890617552734848
Validation loss: 5.590983589604975

Epoch: 5| Step: 9
Training loss: 4.512667733665187
Validation loss: 5.546430615203354

Epoch: 5| Step: 10
Training loss: 6.035472597392598
Validation loss: 5.499978237910766

Epoch: 2| Step: 0
Training loss: 4.755991720437815
Validation loss: 5.449747201746968

Epoch: 5| Step: 1
Training loss: 5.123960808323418
Validation loss: 5.397417109793015

Epoch: 5| Step: 2
Training loss: 5.566202024762374
Validation loss: 5.344236144417978

Epoch: 5| Step: 3
Training loss: 5.7990695470121745
Validation loss: 5.292467441225697

Epoch: 5| Step: 4
Training loss: 5.749635104335562
Validation loss: 5.239792322287489

Epoch: 5| Step: 5
Training loss: 5.861727392370012
Validation loss: 5.187246263794485

Epoch: 5| Step: 6
Training loss: 5.157098133963526
Validation loss: 5.134060783418825

Epoch: 5| Step: 7
Training loss: 5.13582119950749
Validation loss: 5.081364078575879

Epoch: 5| Step: 8
Training loss: 4.058154555083423
Validation loss: 5.023297935474513

Epoch: 5| Step: 9
Training loss: 5.059383987503598
Validation loss: 4.963951715847444

Epoch: 5| Step: 10
Training loss: 5.172525324660376
Validation loss: 4.908967174322592

Epoch: 3| Step: 0
Training loss: 5.370568511250294
Validation loss: 4.859955840685579

Epoch: 5| Step: 1
Training loss: 4.6670995693141775
Validation loss: 4.814983160376464

Epoch: 5| Step: 2
Training loss: 5.5495528513543855
Validation loss: 4.773244385125719

Epoch: 5| Step: 3
Training loss: 4.693565614941662
Validation loss: 4.7327495600300855

Epoch: 5| Step: 4
Training loss: 5.2144540248215385
Validation loss: 4.693907475454588

Epoch: 5| Step: 5
Training loss: 4.274052716870361
Validation loss: 4.652193740499996

Epoch: 5| Step: 6
Training loss: 4.857934278235983
Validation loss: 4.612790777635923

Epoch: 5| Step: 7
Training loss: 3.8495466981040494
Validation loss: 4.576373261178612

Epoch: 5| Step: 8
Training loss: 4.36140509476416
Validation loss: 4.537615414305929

Epoch: 5| Step: 9
Training loss: 4.719390825627249
Validation loss: 4.502447152235485

Epoch: 5| Step: 10
Training loss: 4.46179875011725
Validation loss: 4.458886648226531

Epoch: 4| Step: 0
Training loss: 4.07518653676715
Validation loss: 4.413150736092855

Epoch: 5| Step: 1
Training loss: 4.075150029515664
Validation loss: 4.376179480177526

Epoch: 5| Step: 2
Training loss: 4.7646479371092685
Validation loss: 4.341898877462309

Epoch: 5| Step: 3
Training loss: 4.991909729777186
Validation loss: 4.308125918709686

Epoch: 5| Step: 4
Training loss: 4.075333264536903
Validation loss: 4.275128052165799

Epoch: 5| Step: 5
Training loss: 4.42177492709199
Validation loss: 4.245013865620443

Epoch: 5| Step: 6
Training loss: 4.1536834364318
Validation loss: 4.2145855097372

Epoch: 5| Step: 7
Training loss: 5.126096096523738
Validation loss: 4.180982689706764

Epoch: 5| Step: 8
Training loss: 4.092053010703457
Validation loss: 4.154485158347841

Epoch: 5| Step: 9
Training loss: 5.033002086291079
Validation loss: 4.150187450553557

Epoch: 5| Step: 10
Training loss: 2.6360484535730677
Validation loss: 4.106986241280291

Epoch: 5| Step: 0
Training loss: 3.4336161086533834
Validation loss: 4.10940506954258

Epoch: 5| Step: 1
Training loss: 4.672234869017679
Validation loss: 4.1066633348753765

Epoch: 5| Step: 2
Training loss: 4.356570637312737
Validation loss: 4.059067762222567

Epoch: 5| Step: 3
Training loss: 4.020362048950153
Validation loss: 4.043627495561651

Epoch: 5| Step: 4
Training loss: 3.7944703827457484
Validation loss: 4.038244778943423

Epoch: 5| Step: 5
Training loss: 3.86372359070257
Validation loss: 4.037847105539308

Epoch: 5| Step: 6
Training loss: 3.8151609796279993
Validation loss: 4.020270103109019

Epoch: 5| Step: 7
Training loss: 4.272403236217503
Validation loss: 3.994142886880061

Epoch: 5| Step: 8
Training loss: 4.725958364670557
Validation loss: 3.9843469723723657

Epoch: 5| Step: 9
Training loss: 3.9242429841508573
Validation loss: 3.98135419617053

Epoch: 5| Step: 10
Training loss: 4.90624066977616
Validation loss: 3.947979476255478

Epoch: 6| Step: 0
Training loss: 4.428509052558081
Validation loss: 3.9332933666506187

Epoch: 5| Step: 1
Training loss: 4.219903180787992
Validation loss: 3.9194565334062754

Epoch: 5| Step: 2
Training loss: 2.9974316093017714
Validation loss: 3.9064942432462466

Epoch: 5| Step: 3
Training loss: 4.946147637261242
Validation loss: 3.893866148889506

Epoch: 5| Step: 4
Training loss: 4.096694935348561
Validation loss: 3.8755236935694253

Epoch: 5| Step: 5
Training loss: 3.6947639171044755
Validation loss: 3.8635876950224657

Epoch: 5| Step: 6
Training loss: 4.193282959538954
Validation loss: 3.8474169271774676

Epoch: 5| Step: 7
Training loss: 4.3799345253705795
Validation loss: 3.835493879766504

Epoch: 5| Step: 8
Training loss: 3.2284094302048563
Validation loss: 3.823010563552986

Epoch: 5| Step: 9
Training loss: 3.659629238297809
Validation loss: 3.809516921820911

Epoch: 5| Step: 10
Training loss: 4.124344051110275
Validation loss: 3.795843915738962

Epoch: 7| Step: 0
Training loss: 3.728249733717597
Validation loss: 3.7846309036076455

Epoch: 5| Step: 1
Training loss: 3.924868956887013
Validation loss: 3.7725166969340544

Epoch: 5| Step: 2
Training loss: 3.545001774667745
Validation loss: 3.7629934197575636

Epoch: 5| Step: 3
Training loss: 4.436802339110668
Validation loss: 3.7517980346306037

Epoch: 5| Step: 4
Training loss: 4.077421748885701
Validation loss: 3.737945426002427

Epoch: 5| Step: 5
Training loss: 2.9745112682853043
Validation loss: 3.7184962090132223

Epoch: 5| Step: 6
Training loss: 4.860824712157827
Validation loss: 3.7000675063888493

Epoch: 5| Step: 7
Training loss: 4.226022287421032
Validation loss: 3.685920720586741

Epoch: 5| Step: 8
Training loss: 3.358712632284079
Validation loss: 3.6734308169258387

Epoch: 5| Step: 9
Training loss: 3.63615018044712
Validation loss: 3.6577965980186193

Epoch: 5| Step: 10
Training loss: 3.7717803412240016
Validation loss: 3.64557411409113

Epoch: 8| Step: 0
Training loss: 3.1631578447271926
Validation loss: 3.635773077339289

Epoch: 5| Step: 1
Training loss: 3.335605435070107
Validation loss: 3.6279737844014646

Epoch: 5| Step: 2
Training loss: 4.085408572212123
Validation loss: 3.618047092192102

Epoch: 5| Step: 3
Training loss: 3.6509599808041044
Validation loss: 3.6098110697498966

Epoch: 5| Step: 4
Training loss: 3.347856370960172
Validation loss: 3.603223350133272

Epoch: 5| Step: 5
Training loss: 4.08659984697868
Validation loss: 3.596146375336614

Epoch: 5| Step: 6
Training loss: 4.17868754466606
Validation loss: 3.580423489079411

Epoch: 5| Step: 7
Training loss: 4.2967706841030715
Validation loss: 3.570617480372239

Epoch: 5| Step: 8
Training loss: 3.2276067267869384
Validation loss: 3.5642343677118444

Epoch: 5| Step: 9
Training loss: 4.452206165485852
Validation loss: 3.560866111647376

Epoch: 5| Step: 10
Training loss: 3.5288499085744767
Validation loss: 3.5500967025006904

Epoch: 9| Step: 0
Training loss: 3.4694894913116925
Validation loss: 3.5408896277255733

Epoch: 5| Step: 1
Training loss: 4.205369087921941
Validation loss: 3.528481475098513

Epoch: 5| Step: 2
Training loss: 4.2298731221679295
Validation loss: 3.5198092212977365

Epoch: 5| Step: 3
Training loss: 3.8875379456265793
Validation loss: 3.507970161475067

Epoch: 5| Step: 4
Training loss: 2.6083763175891925
Validation loss: 3.493568030261147

Epoch: 5| Step: 5
Training loss: 3.415963418429683
Validation loss: 3.4838338275598573

Epoch: 5| Step: 6
Training loss: 3.461585817257642
Validation loss: 3.478080208991213

Epoch: 5| Step: 7
Training loss: 3.477317059529533
Validation loss: 3.4684409717362437

Epoch: 5| Step: 8
Training loss: 3.338896178627061
Validation loss: 3.452133301349591

Epoch: 5| Step: 9
Training loss: 4.2213612704851675
Validation loss: 3.4456665744083077

Epoch: 5| Step: 10
Training loss: 4.087014751037157
Validation loss: 3.432697787800397

Epoch: 10| Step: 0
Training loss: 3.7943809072655563
Validation loss: 3.422464121198253

Epoch: 5| Step: 1
Training loss: 3.9441791379532476
Validation loss: 3.41203029897424

Epoch: 5| Step: 2
Training loss: 3.3051921919027705
Validation loss: 3.4048806951378796

Epoch: 5| Step: 3
Training loss: 3.6449980441952916
Validation loss: 3.4037536613554296

Epoch: 5| Step: 4
Training loss: 3.720507551044337
Validation loss: 3.3973910781860703

Epoch: 5| Step: 5
Training loss: 3.4138536891324476
Validation loss: 3.3805309734322035

Epoch: 5| Step: 6
Training loss: 3.1246232377860843
Validation loss: 3.3759248788718645

Epoch: 5| Step: 7
Training loss: 3.539026121243077
Validation loss: 3.3753236579736985

Epoch: 5| Step: 8
Training loss: 3.704845946039689
Validation loss: 3.373454588961482

Epoch: 5| Step: 9
Training loss: 3.7932517263375485
Validation loss: 3.3615818140428235

Epoch: 5| Step: 10
Training loss: 3.718542910667968
Validation loss: 3.3431675376519583

Epoch: 11| Step: 0
Training loss: 3.0138126916428662
Validation loss: 3.3394871732770204

Epoch: 5| Step: 1
Training loss: 3.0929095735451035
Validation loss: 3.3486409046529153

Epoch: 5| Step: 2
Training loss: 4.105369094815116
Validation loss: 3.335902385887575

Epoch: 5| Step: 3
Training loss: 3.657035286845534
Validation loss: 3.316996566517872

Epoch: 5| Step: 4
Training loss: 3.8923479424619774
Validation loss: 3.311389550450724

Epoch: 5| Step: 5
Training loss: 3.6195540462231355
Validation loss: 3.313165650031572

Epoch: 5| Step: 6
Training loss: 3.799534874608562
Validation loss: 3.3070476576004566

Epoch: 5| Step: 7
Training loss: 2.723944076199295
Validation loss: 3.301411453067964

Epoch: 5| Step: 8
Training loss: 3.902967004197198
Validation loss: 3.289565209316316

Epoch: 5| Step: 9
Training loss: 3.2249809619430345
Validation loss: 3.278381242106782

Epoch: 5| Step: 10
Training loss: 3.7839066181717467
Validation loss: 3.275694965983439

Epoch: 12| Step: 0
Training loss: 3.033540312723478
Validation loss: 3.2662530785606028

Epoch: 5| Step: 1
Training loss: 3.472550518198465
Validation loss: 3.2640878300083624

Epoch: 5| Step: 2
Training loss: 3.4764032563160594
Validation loss: 3.2581065653513352

Epoch: 5| Step: 3
Training loss: 2.8205467401590125
Validation loss: 3.251897507226142

Epoch: 5| Step: 4
Training loss: 3.5213750990480692
Validation loss: 3.2476163860075853

Epoch: 5| Step: 5
Training loss: 3.968259045128375
Validation loss: 3.2435756431240454

Epoch: 5| Step: 6
Training loss: 3.9173868342390983
Validation loss: 3.2445086175973237

Epoch: 5| Step: 7
Training loss: 2.905538164147122
Validation loss: 3.237459430130768

Epoch: 5| Step: 8
Training loss: 3.5741002797989028
Validation loss: 3.230990722648009

Epoch: 5| Step: 9
Training loss: 4.065361541022953
Validation loss: 3.227255037801871

Epoch: 5| Step: 10
Training loss: 3.44763935429876
Validation loss: 3.2221793147546998

Epoch: 13| Step: 0
Training loss: 3.6991936140002
Validation loss: 3.220995519465097

Epoch: 5| Step: 1
Training loss: 3.105096221268346
Validation loss: 3.219665744339003

Epoch: 5| Step: 2
Training loss: 4.492316998812781
Validation loss: 3.2160170992134094

Epoch: 5| Step: 3
Training loss: 3.5160805640163892
Validation loss: 3.209709679840349

Epoch: 5| Step: 4
Training loss: 2.856725079782358
Validation loss: 3.205389249099173

Epoch: 5| Step: 5
Training loss: 3.2944145965367673
Validation loss: 3.2013135060077262

Epoch: 5| Step: 6
Training loss: 3.868894258191466
Validation loss: 3.197738955704851

Epoch: 5| Step: 7
Training loss: 3.250920092114308
Validation loss: 3.1968032123965506

Epoch: 5| Step: 8
Training loss: 3.899465543854691
Validation loss: 3.1935803511074297

Epoch: 5| Step: 9
Training loss: 2.614882635688511
Validation loss: 3.194239651531387

Epoch: 5| Step: 10
Training loss: 3.0315328249782976
Validation loss: 3.189893046615931

Epoch: 14| Step: 0
Training loss: 3.7571420686131467
Validation loss: 3.1865001705260365

Epoch: 5| Step: 1
Training loss: 3.0791495694798634
Validation loss: 3.1837651624143417

Epoch: 5| Step: 2
Training loss: 3.432193613846644
Validation loss: 3.1819164667929423

Epoch: 5| Step: 3
Training loss: 3.3073503303831817
Validation loss: 3.178887951965011

Epoch: 5| Step: 4
Training loss: 3.288265321946307
Validation loss: 3.1769886720226683

Epoch: 5| Step: 5
Training loss: 3.5424101703590845
Validation loss: 3.1746401697478706

Epoch: 5| Step: 6
Training loss: 3.09198579674897
Validation loss: 3.172587101959053

Epoch: 5| Step: 7
Training loss: 3.595818629111368
Validation loss: 3.1720882408549267

Epoch: 5| Step: 8
Training loss: 4.014240189387738
Validation loss: 3.16540561549087

Epoch: 5| Step: 9
Training loss: 3.0884853999055406
Validation loss: 3.1652663788209274

Epoch: 5| Step: 10
Training loss: 3.5346046649709324
Validation loss: 3.1631972348849056

Epoch: 15| Step: 0
Training loss: 3.6566700490300112
Validation loss: 3.1609399342162714

Epoch: 5| Step: 1
Training loss: 3.5237954374471205
Validation loss: 3.159063669984891

Epoch: 5| Step: 2
Training loss: 3.128099659027289
Validation loss: 3.1570028525834384

Epoch: 5| Step: 3
Training loss: 2.973759650671341
Validation loss: 3.1559093449487947

Epoch: 5| Step: 4
Training loss: 3.9995854878226886
Validation loss: 3.1519058548988763

Epoch: 5| Step: 5
Training loss: 2.665761366796242
Validation loss: 3.144471646707504

Epoch: 5| Step: 6
Training loss: 3.1995399323189293
Validation loss: 3.141290820919743

Epoch: 5| Step: 7
Training loss: 4.203432206622801
Validation loss: 3.151960408246783

Epoch: 5| Step: 8
Training loss: 3.126960139650939
Validation loss: 3.1385430528953466

Epoch: 5| Step: 9
Training loss: 3.2450140340586806
Validation loss: 3.1464520059090058

Epoch: 5| Step: 10
Training loss: 3.653387399978783
Validation loss: 3.1511961881859434

Epoch: 16| Step: 0
Training loss: 2.8472610429634555
Validation loss: 3.144420108857774

Epoch: 5| Step: 1
Training loss: 4.554472249148272
Validation loss: 3.1379737787501916

Epoch: 5| Step: 2
Training loss: 3.434424949609042
Validation loss: 3.131142513506676

Epoch: 5| Step: 3
Training loss: 3.447537004633225
Validation loss: 3.1347595372212935

Epoch: 5| Step: 4
Training loss: 3.3284707046555915
Validation loss: 3.139994187792176

Epoch: 5| Step: 5
Training loss: 3.120970607806174
Validation loss: 3.1251329069690073

Epoch: 5| Step: 6
Training loss: 3.7537606773770835
Validation loss: 3.1222174646027496

Epoch: 5| Step: 7
Training loss: 3.2477817301016145
Validation loss: 3.1206902037182007

Epoch: 5| Step: 8
Training loss: 3.1087839149432
Validation loss: 3.121763555949876

Epoch: 5| Step: 9
Training loss: 2.8579913684562466
Validation loss: 3.12310462980396

Epoch: 5| Step: 10
Training loss: 3.430747318099153
Validation loss: 3.122664072820109

Epoch: 17| Step: 0
Training loss: 3.391206471732935
Validation loss: 3.116669900877242

Epoch: 5| Step: 1
Training loss: 3.7712297319038917
Validation loss: 3.117723484936535

Epoch: 5| Step: 2
Training loss: 2.2416308838589405
Validation loss: 3.1110863785034075

Epoch: 5| Step: 3
Training loss: 3.856460273734906
Validation loss: 3.1150420438229913

Epoch: 5| Step: 4
Training loss: 3.7329530442782337
Validation loss: 3.111012429646572

Epoch: 5| Step: 5
Training loss: 3.410196520380781
Validation loss: 3.1075529326354565

Epoch: 5| Step: 6
Training loss: 3.3004194975583454
Validation loss: 3.105735698300572

Epoch: 5| Step: 7
Training loss: 3.7209197053926726
Validation loss: 3.1018678078829187

Epoch: 5| Step: 8
Training loss: 3.367489121949794
Validation loss: 3.103744982525964

Epoch: 5| Step: 9
Training loss: 2.8015791050535337
Validation loss: 3.0988500377455925

Epoch: 5| Step: 10
Training loss: 3.2992878983640552
Validation loss: 3.0955503654372674

Epoch: 18| Step: 0
Training loss: 3.734542779066369
Validation loss: 3.092850339792206

Epoch: 5| Step: 1
Training loss: 2.5782658393999918
Validation loss: 3.088054594020371

Epoch: 5| Step: 2
Training loss: 3.6340454634413817
Validation loss: 3.088693078263494

Epoch: 5| Step: 3
Training loss: 3.3478438370447883
Validation loss: 3.088849164834916

Epoch: 5| Step: 4
Training loss: 3.3099363951319876
Validation loss: 3.090521631086476

Epoch: 5| Step: 5
Training loss: 3.715527845545032
Validation loss: 3.089919877275105

Epoch: 5| Step: 6
Training loss: 2.887823613515604
Validation loss: 3.0843846297901045

Epoch: 5| Step: 7
Training loss: 3.7773061314537073
Validation loss: 3.0926143832087845

Epoch: 5| Step: 8
Training loss: 2.610458605876677
Validation loss: 3.0941194885637175

Epoch: 5| Step: 9
Training loss: 3.02634749232257
Validation loss: 3.0950950515244333

Epoch: 5| Step: 10
Training loss: 4.190009432761562
Validation loss: 3.0947607814462508

Epoch: 19| Step: 0
Training loss: 3.808355110712759
Validation loss: 3.0869366931757587

Epoch: 5| Step: 1
Training loss: 2.7754494689673708
Validation loss: 3.091208602298803

Epoch: 5| Step: 2
Training loss: 2.9300907925544397
Validation loss: 3.089958548356247

Epoch: 5| Step: 3
Training loss: 3.5622416620113433
Validation loss: 3.093449189017824

Epoch: 5| Step: 4
Training loss: 2.852271590185992
Validation loss: 3.086378163632514

Epoch: 5| Step: 5
Training loss: 3.9054948000450227
Validation loss: 3.1063371645889224

Epoch: 5| Step: 6
Training loss: 4.019597207761803
Validation loss: 3.153786132002554

Epoch: 5| Step: 7
Training loss: 3.0245638383159217
Validation loss: 3.0853203950490795

Epoch: 5| Step: 8
Training loss: 3.205012960660679
Validation loss: 3.085391679299944

Epoch: 5| Step: 9
Training loss: 3.5432668474287117
Validation loss: 3.1336165149213895

Epoch: 5| Step: 10
Training loss: 3.242652069267034
Validation loss: 3.1425164761831983

Epoch: 20| Step: 0
Training loss: 3.368820042492435
Validation loss: 3.083020907545307

Epoch: 5| Step: 1
Training loss: 3.738956338640276
Validation loss: 3.0777766241553177

Epoch: 5| Step: 2
Training loss: 3.528959763792346
Validation loss: 3.0844130215142034

Epoch: 5| Step: 3
Training loss: 3.190921069539905
Validation loss: 3.0960632373555894

Epoch: 5| Step: 4
Training loss: 3.213086228373262
Validation loss: 3.095152899684001

Epoch: 5| Step: 5
Training loss: 2.977151166722819
Validation loss: 3.092969749407069

Epoch: 5| Step: 6
Training loss: 2.9150223774648123
Validation loss: 3.076376522957282

Epoch: 5| Step: 7
Training loss: 3.6871410130475963
Validation loss: 3.069132442229809

Epoch: 5| Step: 8
Training loss: 2.9618478950633524
Validation loss: 3.0825365650627847

Epoch: 5| Step: 9
Training loss: 3.64610382529878
Validation loss: 3.06514740412786

Epoch: 5| Step: 10
Training loss: 3.6104770315633883
Validation loss: 3.0622468734512713

Epoch: 21| Step: 0
Training loss: 3.1933250308741856
Validation loss: 3.0575870922447113

Epoch: 5| Step: 1
Training loss: 3.2268423924266156
Validation loss: 3.05647141523811

Epoch: 5| Step: 2
Training loss: 3.560254242422993
Validation loss: 3.0529685350369027

Epoch: 5| Step: 3
Training loss: 3.027001933827836
Validation loss: 3.052809900972386

Epoch: 5| Step: 4
Training loss: 3.4189280182903072
Validation loss: 3.0525698197265325

Epoch: 5| Step: 5
Training loss: 2.974361056146644
Validation loss: 3.0511082675680403

Epoch: 5| Step: 6
Training loss: 3.2531620195757776
Validation loss: 3.0484216156065487

Epoch: 5| Step: 7
Training loss: 3.680949972520044
Validation loss: 3.048760651885823

Epoch: 5| Step: 8
Training loss: 3.307839912369439
Validation loss: 3.0511267207006205

Epoch: 5| Step: 9
Training loss: 3.7741786947554945
Validation loss: 3.05185299582746

Epoch: 5| Step: 10
Training loss: 3.145668648625955
Validation loss: 3.05071719825331

Epoch: 22| Step: 0
Training loss: 2.915759535912495
Validation loss: 3.0523481930617087

Epoch: 5| Step: 1
Training loss: 2.9095700896153502
Validation loss: 3.0505677266220426

Epoch: 5| Step: 2
Training loss: 3.4534047561486387
Validation loss: 3.0559853916742505

Epoch: 5| Step: 3
Training loss: 3.50429870380902
Validation loss: 3.0420628462577692

Epoch: 5| Step: 4
Training loss: 4.114617198692056
Validation loss: 3.039541546970281

Epoch: 5| Step: 5
Training loss: 3.6396307508541956
Validation loss: 3.0392339864552973

Epoch: 5| Step: 6
Training loss: 2.7146212040642386
Validation loss: 3.04039014853976

Epoch: 5| Step: 7
Training loss: 3.733563450692145
Validation loss: 3.03585477851845

Epoch: 5| Step: 8
Training loss: 3.3299574128139815
Validation loss: 3.037342225651294

Epoch: 5| Step: 9
Training loss: 3.022025318213893
Validation loss: 3.0352749039233684

Epoch: 5| Step: 10
Training loss: 2.902308755204151
Validation loss: 3.0332677595651996

Epoch: 23| Step: 0
Training loss: 2.922309231238364
Validation loss: 3.0349211295622087

Epoch: 5| Step: 1
Training loss: 3.4082683218155245
Validation loss: 3.030395957527804

Epoch: 5| Step: 2
Training loss: 3.3843636777623254
Validation loss: 3.0302196121946414

Epoch: 5| Step: 3
Training loss: 3.024077433992428
Validation loss: 3.0285298869458694

Epoch: 5| Step: 4
Training loss: 4.056832218558728
Validation loss: 3.0289070860993066

Epoch: 5| Step: 5
Training loss: 3.282537008107407
Validation loss: 3.0266260862681555

Epoch: 5| Step: 6
Training loss: 3.358769419890447
Validation loss: 3.026582048900312

Epoch: 5| Step: 7
Training loss: 2.4281027185308823
Validation loss: 3.025694176811255

Epoch: 5| Step: 8
Training loss: 3.5461801528909684
Validation loss: 3.031836852613509

Epoch: 5| Step: 9
Training loss: 3.3009657227020117
Validation loss: 3.0287965487628457

Epoch: 5| Step: 10
Training loss: 3.526257927637881
Validation loss: 3.0206719247527065

Epoch: 24| Step: 0
Training loss: 3.2399596131715764
Validation loss: 3.0222750291738985

Epoch: 5| Step: 1
Training loss: 3.4931732083766907
Validation loss: 3.019582576183092

Epoch: 5| Step: 2
Training loss: 3.6312591184938223
Validation loss: 3.0158724697391244

Epoch: 5| Step: 3
Training loss: 2.7986003306528033
Validation loss: 3.0125258503732653

Epoch: 5| Step: 4
Training loss: 3.357478968482708
Validation loss: 3.022962519261039

Epoch: 5| Step: 5
Training loss: 3.4436216465453438
Validation loss: 3.0135786230979753

Epoch: 5| Step: 6
Training loss: 3.0507495209317548
Validation loss: 3.0077633049719603

Epoch: 5| Step: 7
Training loss: 3.319249312776341
Validation loss: 3.0064128626355457

Epoch: 5| Step: 8
Training loss: 3.1038033872353723
Validation loss: 3.0045559301626454

Epoch: 5| Step: 9
Training loss: 3.3467170172268816
Validation loss: 3.0036974360593667

Epoch: 5| Step: 10
Training loss: 3.438455067518372
Validation loss: 3.005764357426928

Epoch: 25| Step: 0
Training loss: 3.4441529136941225
Validation loss: 3.012024513776217

Epoch: 5| Step: 1
Training loss: 3.5213763177576816
Validation loss: 3.009600248500268

Epoch: 5| Step: 2
Training loss: 3.6956487587330056
Validation loss: 3.008830349182369

Epoch: 5| Step: 3
Training loss: 3.209034153743169
Validation loss: 3.002777621966605

Epoch: 5| Step: 4
Training loss: 3.03049829345212
Validation loss: 3.0044724631279798

Epoch: 5| Step: 5
Training loss: 2.85714584759147
Validation loss: 2.997448846547367

Epoch: 5| Step: 6
Training loss: 3.7955642761167017
Validation loss: 2.9963935226869998

Epoch: 5| Step: 7
Training loss: 3.0419122431309007
Validation loss: 2.9949267750242794

Epoch: 5| Step: 8
Training loss: 3.025786992625828
Validation loss: 2.992851400222489

Epoch: 5| Step: 9
Training loss: 3.4521137672852373
Validation loss: 2.992998529302764

Epoch: 5| Step: 10
Training loss: 2.829164766995481
Validation loss: 2.99031601815378

Epoch: 26| Step: 0
Training loss: 3.4636773486797
Validation loss: 2.9895456863462013

Epoch: 5| Step: 1
Training loss: 3.15418682083551
Validation loss: 2.9887388829747055

Epoch: 5| Step: 2
Training loss: 2.5281315184557496
Validation loss: 2.9887440261393063

Epoch: 5| Step: 3
Training loss: 3.3168736500267384
Validation loss: 2.989413881139095

Epoch: 5| Step: 4
Training loss: 2.4069357551270625
Validation loss: 2.986880183375732

Epoch: 5| Step: 5
Training loss: 3.246778505450002
Validation loss: 2.9856276621043722

Epoch: 5| Step: 6
Training loss: 3.319409056775928
Validation loss: 2.9982093197580464

Epoch: 5| Step: 7
Training loss: 3.9071919030423508
Validation loss: 2.9933759150543677

Epoch: 5| Step: 8
Training loss: 3.2504198830141244
Validation loss: 2.988006744334104

Epoch: 5| Step: 9
Training loss: 3.159664309090853
Validation loss: 2.991753428171093

Epoch: 5| Step: 10
Training loss: 4.070264702514463
Validation loss: 2.997052302373398

Epoch: 27| Step: 0
Training loss: 2.5784931266830644
Validation loss: 2.985416479957769

Epoch: 5| Step: 1
Training loss: 3.414563873279009
Validation loss: 2.983410960942975

Epoch: 5| Step: 2
Training loss: 2.8836076668419253
Validation loss: 2.9883910606476545

Epoch: 5| Step: 3
Training loss: 4.065225479235006
Validation loss: 2.9898794478531827

Epoch: 5| Step: 4
Training loss: 3.491683343257243
Validation loss: 2.9831071757145864

Epoch: 5| Step: 5
Training loss: 3.024691851345069
Validation loss: 2.978799900776121

Epoch: 5| Step: 6
Training loss: 2.530090254730554
Validation loss: 2.980039419813806

Epoch: 5| Step: 7
Training loss: 3.716825484117101
Validation loss: 2.9785113042285336

Epoch: 5| Step: 8
Training loss: 3.4646891975553507
Validation loss: 2.97734197637507

Epoch: 5| Step: 9
Training loss: 3.167854053006145
Validation loss: 2.9803918570457513

Epoch: 5| Step: 10
Training loss: 3.3355998598709196
Validation loss: 2.9887917209352652

Epoch: 28| Step: 0
Training loss: 4.114315645548014
Validation loss: 3.0088415500654873

Epoch: 5| Step: 1
Training loss: 2.912038309725607
Validation loss: 2.990634788335749

Epoch: 5| Step: 2
Training loss: 2.9103523751550773
Validation loss: 2.977234634211285

Epoch: 5| Step: 3
Training loss: 3.217319652183123
Validation loss: 2.970744516413966

Epoch: 5| Step: 4
Training loss: 3.487746177379763
Validation loss: 2.9687107336170913

Epoch: 5| Step: 5
Training loss: 3.1403040176263377
Validation loss: 2.967082988962955

Epoch: 5| Step: 6
Training loss: 3.821848305135653
Validation loss: 2.970731504639328

Epoch: 5| Step: 7
Training loss: 2.999040132188554
Validation loss: 2.967352148036188

Epoch: 5| Step: 8
Training loss: 2.8788607010156033
Validation loss: 2.966193889191288

Epoch: 5| Step: 9
Training loss: 2.3148578273874283
Validation loss: 2.96639299850669

Epoch: 5| Step: 10
Training loss: 3.802438059245275
Validation loss: 2.967018588854996

Epoch: 29| Step: 0
Training loss: 3.1145050821500164
Validation loss: 2.968578754660883

Epoch: 5| Step: 1
Training loss: 3.3646634370856234
Validation loss: 2.966117608033323

Epoch: 5| Step: 2
Training loss: 3.5730683022992307
Validation loss: 2.964848794537927

Epoch: 5| Step: 3
Training loss: 2.868065972318249
Validation loss: 2.9660771053965678

Epoch: 5| Step: 4
Training loss: 3.3456398445197717
Validation loss: 2.9641906009332697

Epoch: 5| Step: 5
Training loss: 2.8626590068248556
Validation loss: 2.9602958513624054

Epoch: 5| Step: 6
Training loss: 3.269355942414078
Validation loss: 2.960292647996148

Epoch: 5| Step: 7
Training loss: 3.2826208248403126
Validation loss: 2.959971250209024

Epoch: 5| Step: 8
Training loss: 3.5563136143684906
Validation loss: 2.960155943557173

Epoch: 5| Step: 9
Training loss: 2.837504644852252
Validation loss: 2.958561553251753

Epoch: 5| Step: 10
Training loss: 3.661207050294276
Validation loss: 2.955594223011721

Epoch: 30| Step: 0
Training loss: 3.4710116874478274
Validation loss: 2.955178292634505

Epoch: 5| Step: 1
Training loss: 3.2894923275870998
Validation loss: 2.9548673839886583

Epoch: 5| Step: 2
Training loss: 2.913535881014005
Validation loss: 2.955019929154214

Epoch: 5| Step: 3
Training loss: 3.2409018299897423
Validation loss: 2.9549790332228656

Epoch: 5| Step: 4
Training loss: 3.0328122861725517
Validation loss: 2.9537522322168437

Epoch: 5| Step: 5
Training loss: 2.9996956035044757
Validation loss: 2.953760727471856

Epoch: 5| Step: 6
Training loss: 3.3096832679344725
Validation loss: 2.955507290587644

Epoch: 5| Step: 7
Training loss: 3.0821735847203118
Validation loss: 2.9566895075896595

Epoch: 5| Step: 8
Training loss: 3.6141645351969776
Validation loss: 2.9601020626829517

Epoch: 5| Step: 9
Training loss: 3.2826978123279926
Validation loss: 2.954983509862297

Epoch: 5| Step: 10
Training loss: 3.434769673184027
Validation loss: 2.950229436010902

Epoch: 31| Step: 0
Training loss: 2.451434385065406
Validation loss: 2.9457985694591815

Epoch: 5| Step: 1
Training loss: 3.7012892410068767
Validation loss: 2.9463790547042423

Epoch: 5| Step: 2
Training loss: 3.104218774823278
Validation loss: 2.946848298120405

Epoch: 5| Step: 3
Training loss: 2.837980517061766
Validation loss: 2.9445309144186735

Epoch: 5| Step: 4
Training loss: 2.870994431211571
Validation loss: 2.946667417410983

Epoch: 5| Step: 5
Training loss: 3.511340433859419
Validation loss: 2.9462322305884503

Epoch: 5| Step: 6
Training loss: 2.820684603926263
Validation loss: 2.9458630200929927

Epoch: 5| Step: 7
Training loss: 3.932813368120124
Validation loss: 2.941943129788797

Epoch: 5| Step: 8
Training loss: 3.3937121984578944
Validation loss: 2.941618549750873

Epoch: 5| Step: 9
Training loss: 3.3170879907906365
Validation loss: 2.943668011161774

Epoch: 5| Step: 10
Training loss: 3.3766339903063507
Validation loss: 2.942234739888558

Epoch: 32| Step: 0
Training loss: 3.137369014847815
Validation loss: 2.942687614179947

Epoch: 5| Step: 1
Training loss: 3.4476701969130006
Validation loss: 2.9416696405231604

Epoch: 5| Step: 2
Training loss: 3.6119070708274674
Validation loss: 2.9378853280965904

Epoch: 5| Step: 3
Training loss: 2.7344503337836814
Validation loss: 2.9380163621676023

Epoch: 5| Step: 4
Training loss: 3.147982808261252
Validation loss: 2.9389711883716703

Epoch: 5| Step: 5
Training loss: 3.5798975123221712
Validation loss: 2.9383909069661227

Epoch: 5| Step: 6
Training loss: 3.0653477099085515
Validation loss: 2.9375992380527145

Epoch: 5| Step: 7
Training loss: 3.5667719073827016
Validation loss: 2.936017227952395

Epoch: 5| Step: 8
Training loss: 3.0274648728289777
Validation loss: 2.9350750491531272

Epoch: 5| Step: 9
Training loss: 2.8718456710961595
Validation loss: 2.932061127169598

Epoch: 5| Step: 10
Training loss: 3.188901406181246
Validation loss: 2.932026654938127

Epoch: 33| Step: 0
Training loss: 2.986577205112838
Validation loss: 2.934355939827476

Epoch: 5| Step: 1
Training loss: 3.337486461369061
Validation loss: 2.9305334555129514

Epoch: 5| Step: 2
Training loss: 3.672935819584932
Validation loss: 2.9303099583410175

Epoch: 5| Step: 3
Training loss: 2.993304569499832
Validation loss: 2.926572542651995

Epoch: 5| Step: 4
Training loss: 3.3214861781314933
Validation loss: 2.9277068832849125

Epoch: 5| Step: 5
Training loss: 3.704628940796805
Validation loss: 2.9278139450553033

Epoch: 5| Step: 6
Training loss: 2.3282935574337276
Validation loss: 2.927773035991574

Epoch: 5| Step: 7
Training loss: 2.8300491447360225
Validation loss: 2.925399932641238

Epoch: 5| Step: 8
Training loss: 3.4133699530882247
Validation loss: 2.930200735769497

Epoch: 5| Step: 9
Training loss: 3.4137525614194923
Validation loss: 2.9379996173990497

Epoch: 5| Step: 10
Training loss: 3.198210877709339
Validation loss: 2.9490498069070292

Epoch: 34| Step: 0
Training loss: 3.5414909468797253
Validation loss: 2.957449804630791

Epoch: 5| Step: 1
Training loss: 3.26265965213601
Validation loss: 2.9251747487927586

Epoch: 5| Step: 2
Training loss: 2.547099191358455
Validation loss: 2.925013923874816

Epoch: 5| Step: 3
Training loss: 2.9856283541846804
Validation loss: 2.927915164511299

Epoch: 5| Step: 4
Training loss: 3.142287084973244
Validation loss: 2.9393865191105575

Epoch: 5| Step: 5
Training loss: 3.3825752580366544
Validation loss: 2.935467764330082

Epoch: 5| Step: 6
Training loss: 4.090036119893825
Validation loss: 2.9289154658727306

Epoch: 5| Step: 7
Training loss: 2.7769747675407683
Validation loss: 2.921739172475039

Epoch: 5| Step: 8
Training loss: 2.9484521134686044
Validation loss: 2.9212685162274514

Epoch: 5| Step: 9
Training loss: 3.4835182128710476
Validation loss: 2.9197898295752944

Epoch: 5| Step: 10
Training loss: 2.997326136136945
Validation loss: 2.919863859088586

Epoch: 35| Step: 0
Training loss: 3.3329919322339974
Validation loss: 2.9179126281476515

Epoch: 5| Step: 1
Training loss: 3.5781317964847434
Validation loss: 2.918051907249668

Epoch: 5| Step: 2
Training loss: 3.2000209748057555
Validation loss: 2.9182026239444774

Epoch: 5| Step: 3
Training loss: 2.9242976135985117
Validation loss: 2.9186660336085017

Epoch: 5| Step: 4
Training loss: 3.2802077318330087
Validation loss: 2.919673774668898

Epoch: 5| Step: 5
Training loss: 3.1008155365285996
Validation loss: 2.928332656033932

Epoch: 5| Step: 6
Training loss: 3.455875733790546
Validation loss: 2.924561971662183

Epoch: 5| Step: 7
Training loss: 3.3035061214870103
Validation loss: 2.9191355725747212

Epoch: 5| Step: 8
Training loss: 3.340293595207622
Validation loss: 2.919687786672379

Epoch: 5| Step: 9
Training loss: 2.8107021095398528
Validation loss: 2.9139728382241716

Epoch: 5| Step: 10
Training loss: 2.861245299302519
Validation loss: 2.9146067949977823

Epoch: 36| Step: 0
Training loss: 3.082819268615067
Validation loss: 2.912359001756636

Epoch: 5| Step: 1
Training loss: 3.372468776233144
Validation loss: 2.9099402796326648

Epoch: 5| Step: 2
Training loss: 3.34854409764192
Validation loss: 2.9092797646912514

Epoch: 5| Step: 3
Training loss: 3.256487899553967
Validation loss: 2.9070960604145077

Epoch: 5| Step: 4
Training loss: 2.5611254098878757
Validation loss: 2.907012366648709

Epoch: 5| Step: 5
Training loss: 3.478243783463101
Validation loss: 2.9125962255000757

Epoch: 5| Step: 6
Training loss: 3.5186422328131943
Validation loss: 2.913523490137191

Epoch: 5| Step: 7
Training loss: 3.1479955320411395
Validation loss: 2.9077150284595485

Epoch: 5| Step: 8
Training loss: 3.0194371296375726
Validation loss: 2.9071985311788606

Epoch: 5| Step: 9
Training loss: 3.562357180225531
Validation loss: 2.9049784754148646

Epoch: 5| Step: 10
Training loss: 2.6400284855201677
Validation loss: 2.90275370657253

Epoch: 37| Step: 0
Training loss: 3.477489562138923
Validation loss: 2.9032306986714005

Epoch: 5| Step: 1
Training loss: 2.7674635471055633
Validation loss: 2.9013920907035304

Epoch: 5| Step: 2
Training loss: 3.6394048782791386
Validation loss: 2.8986262954392368

Epoch: 5| Step: 3
Training loss: 3.320865360681522
Validation loss: 2.897477355592213

Epoch: 5| Step: 4
Training loss: 3.704281010845696
Validation loss: 2.9102804371775797

Epoch: 5| Step: 5
Training loss: 2.8621642469704183
Validation loss: 2.900068125067826

Epoch: 5| Step: 6
Training loss: 2.478560643429807
Validation loss: 2.898996728896756

Epoch: 5| Step: 7
Training loss: 3.1302120231991735
Validation loss: 2.9032148023166644

Epoch: 5| Step: 8
Training loss: 3.048892091987912
Validation loss: 2.8995397123964652

Epoch: 5| Step: 9
Training loss: 3.150172964524472
Validation loss: 2.8962539307799635

Epoch: 5| Step: 10
Training loss: 3.413109408449341
Validation loss: 2.8994032983185627

Epoch: 38| Step: 0
Training loss: 2.949362643944139
Validation loss: 2.89583284937696

Epoch: 5| Step: 1
Training loss: 2.545235322516341
Validation loss: 2.8928228012265764

Epoch: 5| Step: 2
Training loss: 3.263063585265665
Validation loss: 2.893340946807681

Epoch: 5| Step: 3
Training loss: 3.1080620068583835
Validation loss: 2.8927527448063413

Epoch: 5| Step: 4
Training loss: 3.040692125385172
Validation loss: 2.8915484291787106

Epoch: 5| Step: 5
Training loss: 3.5706514493956547
Validation loss: 2.890034786011747

Epoch: 5| Step: 6
Training loss: 2.799147040012605
Validation loss: 2.8857133664760073

Epoch: 5| Step: 7
Training loss: 3.656257042511246
Validation loss: 2.8842697482183346

Epoch: 5| Step: 8
Training loss: 2.7540300490236653
Validation loss: 2.8816329446385236

Epoch: 5| Step: 9
Training loss: 3.1703254409909456
Validation loss: 2.8831948349913255

Epoch: 5| Step: 10
Training loss: 4.042775319950103
Validation loss: 2.8822518102545183

Epoch: 39| Step: 0
Training loss: 3.5123051545209054
Validation loss: 2.883048437102234

Epoch: 5| Step: 1
Training loss: 3.8167938066875653
Validation loss: 2.8815996787070897

Epoch: 5| Step: 2
Training loss: 3.294516492688003
Validation loss: 2.8834607262333547

Epoch: 5| Step: 3
Training loss: 2.924589640205722
Validation loss: 2.8848251501149487

Epoch: 5| Step: 4
Training loss: 3.0208959814130605
Validation loss: 2.8796494737700984

Epoch: 5| Step: 5
Training loss: 3.250113998761251
Validation loss: 2.8836306430829

Epoch: 5| Step: 6
Training loss: 3.2746651106974647
Validation loss: 2.8821949217670753

Epoch: 5| Step: 7
Training loss: 3.0663204108208273
Validation loss: 2.8819206871031673

Epoch: 5| Step: 8
Training loss: 3.1583014138520324
Validation loss: 2.880028824755966

Epoch: 5| Step: 9
Training loss: 2.8588411426901956
Validation loss: 2.888729143564075

Epoch: 5| Step: 10
Training loss: 2.424217617023583
Validation loss: 2.902099436564869

Epoch: 40| Step: 0
Training loss: 3.2405236812338982
Validation loss: 2.909758633213075

Epoch: 5| Step: 1
Training loss: 3.271987776101556
Validation loss: 2.888966248010001

Epoch: 5| Step: 2
Training loss: 3.6700051599201235
Validation loss: 2.8814350337380144

Epoch: 5| Step: 3
Training loss: 2.729021684906416
Validation loss: 2.873961365833715

Epoch: 5| Step: 4
Training loss: 2.5445225622668888
Validation loss: 2.8739340189438702

Epoch: 5| Step: 5
Training loss: 2.8562262870088038
Validation loss: 2.8739012606721115

Epoch: 5| Step: 6
Training loss: 3.348802830876349
Validation loss: 2.8732764047400625

Epoch: 5| Step: 7
Training loss: 3.317616955004275
Validation loss: 2.8713085110701795

Epoch: 5| Step: 8
Training loss: 2.729662774885115
Validation loss: 2.8732216530487285

Epoch: 5| Step: 9
Training loss: 3.1710862555536288
Validation loss: 2.867958249809312

Epoch: 5| Step: 10
Training loss: 3.9304391434095995
Validation loss: 2.870654311462988

Epoch: 41| Step: 0
Training loss: 3.0551279828473876
Validation loss: 2.8682926740786323

Epoch: 5| Step: 1
Training loss: 3.0570263896448235
Validation loss: 2.8669916893994087

Epoch: 5| Step: 2
Training loss: 3.811772511598217
Validation loss: 2.86671981714555

Epoch: 5| Step: 3
Training loss: 3.0490914914675558
Validation loss: 2.8696388061135805

Epoch: 5| Step: 4
Training loss: 3.4606973465723283
Validation loss: 2.8646464139345142

Epoch: 5| Step: 5
Training loss: 3.2102543087815927
Validation loss: 2.866329213413097

Epoch: 5| Step: 6
Training loss: 2.990320165837409
Validation loss: 2.8640888095263564

Epoch: 5| Step: 7
Training loss: 2.795925725176827
Validation loss: 2.864193313015784

Epoch: 5| Step: 8
Training loss: 2.8059793116594673
Validation loss: 2.8633711023967527

Epoch: 5| Step: 9
Training loss: 3.4309801172732715
Validation loss: 2.8737690115103276

Epoch: 5| Step: 10
Training loss: 3.0631467175292717
Validation loss: 2.881469436826457

Epoch: 42| Step: 0
Training loss: 3.624124618593935
Validation loss: 2.880200460785504

Epoch: 5| Step: 1
Training loss: 3.516941078531985
Validation loss: 2.8583851385311525

Epoch: 5| Step: 2
Training loss: 3.5406559268580473
Validation loss: 2.8580212386608914

Epoch: 5| Step: 3
Training loss: 2.8736658732614444
Validation loss: 2.856876536268467

Epoch: 5| Step: 4
Training loss: 2.387977280769069
Validation loss: 2.8571040128156344

Epoch: 5| Step: 5
Training loss: 3.5221835525053296
Validation loss: 2.8570539922489155

Epoch: 5| Step: 6
Training loss: 2.7126992077785412
Validation loss: 2.8586084898606674

Epoch: 5| Step: 7
Training loss: 3.288481817384588
Validation loss: 2.866539084394475

Epoch: 5| Step: 8
Training loss: 3.35203737393759
Validation loss: 2.889868625613125

Epoch: 5| Step: 9
Training loss: 2.7863517004032072
Validation loss: 2.8549412337349005

Epoch: 5| Step: 10
Training loss: 3.018256427860106
Validation loss: 2.8560066558746775

Epoch: 43| Step: 0
Training loss: 2.990330371275073
Validation loss: 2.8637724956965025

Epoch: 5| Step: 1
Training loss: 3.3079438455098336
Validation loss: 2.9038357586160792

Epoch: 5| Step: 2
Training loss: 3.38919670152327
Validation loss: 2.9188022289928903

Epoch: 5| Step: 3
Training loss: 3.309575067079426
Validation loss: 2.867061857564495

Epoch: 5| Step: 4
Training loss: 2.9203141067035108
Validation loss: 2.8667201140453873

Epoch: 5| Step: 5
Training loss: 3.094752602002709
Validation loss: 2.875699224418043

Epoch: 5| Step: 6
Training loss: 3.1895253347899732
Validation loss: 2.91682689302825

Epoch: 5| Step: 7
Training loss: 3.2487730497898015
Validation loss: 2.8959171486357187

Epoch: 5| Step: 8
Training loss: 3.067043592951038
Validation loss: 2.867245435513585

Epoch: 5| Step: 9
Training loss: 2.9347568446332284
Validation loss: 2.856674742072759

Epoch: 5| Step: 10
Training loss: 3.4962731001046152
Validation loss: 2.8528474280304623

Epoch: 44| Step: 0
Training loss: 3.4115480988706874
Validation loss: 2.860196274532974

Epoch: 5| Step: 1
Training loss: 3.225614320663043
Validation loss: 2.8644729509462645

Epoch: 5| Step: 2
Training loss: 3.0172427883050945
Validation loss: 2.861408273930282

Epoch: 5| Step: 3
Training loss: 2.9200541488643332
Validation loss: 2.8494585417011566

Epoch: 5| Step: 4
Training loss: 2.887570473607747
Validation loss: 2.845591440557762

Epoch: 5| Step: 5
Training loss: 3.0595056336424746
Validation loss: 2.8461596613109883

Epoch: 5| Step: 6
Training loss: 3.0959213805652612
Validation loss: 2.8434139370013334

Epoch: 5| Step: 7
Training loss: 3.227383340607974
Validation loss: 2.8433913083900504

Epoch: 5| Step: 8
Training loss: 3.546309505873704
Validation loss: 2.8469179959506814

Epoch: 5| Step: 9
Training loss: 3.5664702928857577
Validation loss: 2.8566116293283206

Epoch: 5| Step: 10
Training loss: 2.5525416890325743
Validation loss: 2.8534532653481675

Epoch: 45| Step: 0
Training loss: 2.974500848264408
Validation loss: 2.848316806459722

Epoch: 5| Step: 1
Training loss: 3.3059322096283528
Validation loss: 2.841447722443704

Epoch: 5| Step: 2
Training loss: 3.8793062462912937
Validation loss: 2.837440023311943

Epoch: 5| Step: 3
Training loss: 2.48312077562005
Validation loss: 2.835763081872741

Epoch: 5| Step: 4
Training loss: 3.5245964360372195
Validation loss: 2.8343163759839656

Epoch: 5| Step: 5
Training loss: 3.4555630599659684
Validation loss: 2.8331219837423163

Epoch: 5| Step: 6
Training loss: 2.829124821918539
Validation loss: 2.8345091139689997

Epoch: 5| Step: 7
Training loss: 2.800431191077015
Validation loss: 2.840709549728469

Epoch: 5| Step: 8
Training loss: 3.465420198709745
Validation loss: 2.844874471957481

Epoch: 5| Step: 9
Training loss: 2.9067110085677768
Validation loss: 2.841283140017782

Epoch: 5| Step: 10
Training loss: 2.5584451180886663
Validation loss: 2.832894219447174

Epoch: 46| Step: 0
Training loss: 2.7542377245379206
Validation loss: 2.8343040996240734

Epoch: 5| Step: 1
Training loss: 3.085765051550286
Validation loss: 2.831668743600256

Epoch: 5| Step: 2
Training loss: 3.0257769067773985
Validation loss: 2.8310888407388664

Epoch: 5| Step: 3
Training loss: 3.288346817548366
Validation loss: 2.8361681555633766

Epoch: 5| Step: 4
Training loss: 3.0651316332281904
Validation loss: 2.830537334527344

Epoch: 5| Step: 5
Training loss: 3.3081025498718675
Validation loss: 2.8282728467581455

Epoch: 5| Step: 6
Training loss: 3.242315744828094
Validation loss: 2.825998961486282

Epoch: 5| Step: 7
Training loss: 3.1974894748779965
Validation loss: 2.8273938941088823

Epoch: 5| Step: 8
Training loss: 2.777176692353981
Validation loss: 2.82395195787661

Epoch: 5| Step: 9
Training loss: 3.49903829168456
Validation loss: 2.8232231020735914

Epoch: 5| Step: 10
Training loss: 3.16379122100949
Validation loss: 2.823740596714456

Epoch: 47| Step: 0
Training loss: 3.287059327966827
Validation loss: 2.8246949917545945

Epoch: 5| Step: 1
Training loss: 3.2021030191293325
Validation loss: 2.8235441719122187

Epoch: 5| Step: 2
Training loss: 3.4538233814596517
Validation loss: 2.82163428050467

Epoch: 5| Step: 3
Training loss: 2.4446164441525373
Validation loss: 2.8201212616618134

Epoch: 5| Step: 4
Training loss: 2.9695963406071644
Validation loss: 2.8181435844776828

Epoch: 5| Step: 5
Training loss: 3.5869934256041156
Validation loss: 2.8200260767170677

Epoch: 5| Step: 6
Training loss: 2.934428130655016
Validation loss: 2.821847897154166

Epoch: 5| Step: 7
Training loss: 2.870294285749146
Validation loss: 2.8235708437639873

Epoch: 5| Step: 8
Training loss: 3.150049293980079
Validation loss: 2.8230718687990564

Epoch: 5| Step: 9
Training loss: 3.356056170842584
Validation loss: 2.8257616141903648

Epoch: 5| Step: 10
Training loss: 3.0654320207959422
Validation loss: 2.8263195917201998

Epoch: 48| Step: 0
Training loss: 2.486703225583806
Validation loss: 2.820365819130746

Epoch: 5| Step: 1
Training loss: 3.3033458971489704
Validation loss: 2.8182523286942245

Epoch: 5| Step: 2
Training loss: 3.031613672208174
Validation loss: 2.819727092224924

Epoch: 5| Step: 3
Training loss: 3.259658254017344
Validation loss: 2.8267989756618106

Epoch: 5| Step: 4
Training loss: 3.4942750430492806
Validation loss: 2.8343972625022738

Epoch: 5| Step: 5
Training loss: 3.455516142652757
Validation loss: 2.836845651875244

Epoch: 5| Step: 6
Training loss: 3.2403841817577343
Validation loss: 2.8373674799854935

Epoch: 5| Step: 7
Training loss: 3.098588954592313
Validation loss: 2.837223950047308

Epoch: 5| Step: 8
Training loss: 2.5669048875843252
Validation loss: 2.8381293670324204

Epoch: 5| Step: 9
Training loss: 3.3722300995663668
Validation loss: 2.8321248429348973

Epoch: 5| Step: 10
Training loss: 2.9897176643700796
Validation loss: 2.8218829876365326

Epoch: 49| Step: 0
Training loss: 2.817572871893065
Validation loss: 2.817042082395921

Epoch: 5| Step: 1
Training loss: 2.7265308454802013
Validation loss: 2.8098190272638353

Epoch: 5| Step: 2
Training loss: 2.983260341014184
Validation loss: 2.8104787675748213

Epoch: 5| Step: 3
Training loss: 3.1315338493416855
Validation loss: 2.8106379690428858

Epoch: 5| Step: 4
Training loss: 3.3202485919860654
Validation loss: 2.810680100487195

Epoch: 5| Step: 5
Training loss: 3.5757395692929355
Validation loss: 2.810257108283561

Epoch: 5| Step: 6
Training loss: 2.9473228979897415
Validation loss: 2.815275223585493

Epoch: 5| Step: 7
Training loss: 3.098588646815329
Validation loss: 2.814943637072721

Epoch: 5| Step: 8
Training loss: 3.309630392592395
Validation loss: 2.819141382832105

Epoch: 5| Step: 9
Training loss: 3.248512954899804
Validation loss: 2.806865121778185

Epoch: 5| Step: 10
Training loss: 3.1504407241347394
Validation loss: 2.81059195400897

Epoch: 50| Step: 0
Training loss: 3.465005864390245
Validation loss: 2.8134401926168904

Epoch: 5| Step: 1
Training loss: 2.20857247071461
Validation loss: 2.8187131355752126

Epoch: 5| Step: 2
Training loss: 3.5592437050092465
Validation loss: 2.8374146392314907

Epoch: 5| Step: 3
Training loss: 3.227388511759153
Validation loss: 2.8315061559503496

Epoch: 5| Step: 4
Training loss: 3.4172342960901876
Validation loss: 2.814691976005538

Epoch: 5| Step: 5
Training loss: 3.178094788354282
Validation loss: 2.8099120234447335

Epoch: 5| Step: 6
Training loss: 3.1093728530339635
Validation loss: 2.804447222850863

Epoch: 5| Step: 7
Training loss: 2.9401403694638253
Validation loss: 2.808901173574399

Epoch: 5| Step: 8
Training loss: 3.3271309527717854
Validation loss: 2.8086029453752603

Epoch: 5| Step: 9
Training loss: 2.8188718883610058
Validation loss: 2.815171977630923

Epoch: 5| Step: 10
Training loss: 2.962188536934259
Validation loss: 2.8174038747311307

Epoch: 51| Step: 0
Training loss: 2.753137619214792
Validation loss: 2.822922852393645

Epoch: 5| Step: 1
Training loss: 3.207048646087487
Validation loss: 2.8308921542366536

Epoch: 5| Step: 2
Training loss: 3.3516057507407457
Validation loss: 2.82731035268226

Epoch: 5| Step: 3
Training loss: 3.1229966417844843
Validation loss: 2.819162501036339

Epoch: 5| Step: 4
Training loss: 2.6278708971266704
Validation loss: 2.817328303111505

Epoch: 5| Step: 5
Training loss: 3.114050335819663
Validation loss: 2.8197897758807726

Epoch: 5| Step: 6
Training loss: 3.5223802557817065
Validation loss: 2.826209274779173

Epoch: 5| Step: 7
Training loss: 3.250570687293359
Validation loss: 2.802825132083019

Epoch: 5| Step: 8
Training loss: 2.724772655557725
Validation loss: 2.799677403788982

Epoch: 5| Step: 9
Training loss: 3.1822482957813674
Validation loss: 2.800143440955513

Epoch: 5| Step: 10
Training loss: 3.369518491038474
Validation loss: 2.799437240588072

Epoch: 52| Step: 0
Training loss: 2.7593096162646633
Validation loss: 2.798553467288899

Epoch: 5| Step: 1
Training loss: 3.171121141268895
Validation loss: 2.7988712173599004

Epoch: 5| Step: 2
Training loss: 2.901540241967503
Validation loss: 2.7962021757717577

Epoch: 5| Step: 3
Training loss: 3.3351864114390746
Validation loss: 2.795630312741071

Epoch: 5| Step: 4
Training loss: 3.2999110412166943
Validation loss: 2.7920514390894473

Epoch: 5| Step: 5
Training loss: 3.4714077227334754
Validation loss: 2.7912058118506198

Epoch: 5| Step: 6
Training loss: 3.324983788931199
Validation loss: 2.7895231495311434

Epoch: 5| Step: 7
Training loss: 2.9985958628060403
Validation loss: 2.793053993228237

Epoch: 5| Step: 8
Training loss: 2.781480243882191
Validation loss: 2.7893815821333963

Epoch: 5| Step: 9
Training loss: 2.8339209414743483
Validation loss: 2.792580679148869

Epoch: 5| Step: 10
Training loss: 3.3437869346218743
Validation loss: 2.791052017049861

Epoch: 53| Step: 0
Training loss: 2.9283424646810183
Validation loss: 2.788775248074457

Epoch: 5| Step: 1
Training loss: 3.2452907188687403
Validation loss: 2.7873321172159815

Epoch: 5| Step: 2
Training loss: 3.0970084245349776
Validation loss: 2.7939388674802954

Epoch: 5| Step: 3
Training loss: 2.6265960564134896
Validation loss: 2.8037510188017127

Epoch: 5| Step: 4
Training loss: 3.6249586958011877
Validation loss: 2.807586773736626

Epoch: 5| Step: 5
Training loss: 3.7255431886472707
Validation loss: 2.8057401155013117

Epoch: 5| Step: 6
Training loss: 3.1509617987144827
Validation loss: 2.793686398928358

Epoch: 5| Step: 7
Training loss: 2.246454836804263
Validation loss: 2.786937824097109

Epoch: 5| Step: 8
Training loss: 2.903549744708211
Validation loss: 2.7819389042201266

Epoch: 5| Step: 9
Training loss: 3.3197859761756185
Validation loss: 2.78297551270521

Epoch: 5| Step: 10
Training loss: 2.967197695007005
Validation loss: 2.7805479969690396

Epoch: 54| Step: 0
Training loss: 2.991176344733451
Validation loss: 2.7814137372696393

Epoch: 5| Step: 1
Training loss: 2.564031190001077
Validation loss: 2.7805800203031246

Epoch: 5| Step: 2
Training loss: 2.892625271286104
Validation loss: 2.7824689261779887

Epoch: 5| Step: 3
Training loss: 3.272490808344348
Validation loss: 2.7818663097336933

Epoch: 5| Step: 4
Training loss: 3.459929515363245
Validation loss: 2.8003914028098196

Epoch: 5| Step: 5
Training loss: 2.862999125446875
Validation loss: 2.8134949814421972

Epoch: 5| Step: 6
Training loss: 3.3585211090019693
Validation loss: 2.8025994339996823

Epoch: 5| Step: 7
Training loss: 2.9115507944855827
Validation loss: 2.7896506759956528

Epoch: 5| Step: 8
Training loss: 3.0969988785650227
Validation loss: 2.7859096946499933

Epoch: 5| Step: 9
Training loss: 3.2908004554567385
Validation loss: 2.7727857800056155

Epoch: 5| Step: 10
Training loss: 3.3115037103603657
Validation loss: 2.7725086607758427

Epoch: 55| Step: 0
Training loss: 3.446971813789401
Validation loss: 2.7759397970121933

Epoch: 5| Step: 1
Training loss: 3.0120662582728945
Validation loss: 2.773948246885691

Epoch: 5| Step: 2
Training loss: 2.0498842439301748
Validation loss: 2.7750403286288003

Epoch: 5| Step: 3
Training loss: 2.6525695435003147
Validation loss: 2.772423404463429

Epoch: 5| Step: 4
Training loss: 3.35024009527435
Validation loss: 2.7741913005204952

Epoch: 5| Step: 5
Training loss: 3.49677904967257
Validation loss: 2.771846339646664

Epoch: 5| Step: 6
Training loss: 2.610333660619497
Validation loss: 2.7720073908386347

Epoch: 5| Step: 7
Training loss: 3.3627556402317795
Validation loss: 2.7712907570085226

Epoch: 5| Step: 8
Training loss: 3.566165042671506
Validation loss: 2.772775083609258

Epoch: 5| Step: 9
Training loss: 3.013319804602892
Validation loss: 2.7699220022045843

Epoch: 5| Step: 10
Training loss: 3.180285948126839
Validation loss: 2.7675895816022424

Epoch: 56| Step: 0
Training loss: 2.5867216183373745
Validation loss: 2.766776187649924

Epoch: 5| Step: 1
Training loss: 2.8666569273435765
Validation loss: 2.769347345135856

Epoch: 5| Step: 2
Training loss: 3.395416951931798
Validation loss: 2.7675212710949895

Epoch: 5| Step: 3
Training loss: 3.324078315969075
Validation loss: 2.7663165869010187

Epoch: 5| Step: 4
Training loss: 3.0916432615424156
Validation loss: 2.766446962379108

Epoch: 5| Step: 5
Training loss: 3.0658302106233957
Validation loss: 2.7651614428732385

Epoch: 5| Step: 6
Training loss: 3.393449722972018
Validation loss: 2.7670811344044126

Epoch: 5| Step: 7
Training loss: 3.2296636055485535
Validation loss: 2.770561273988765

Epoch: 5| Step: 8
Training loss: 2.8035640751166917
Validation loss: 2.7841614558280257

Epoch: 5| Step: 9
Training loss: 3.370873082653138
Validation loss: 2.7803998465628346

Epoch: 5| Step: 10
Training loss: 2.619362818135083
Validation loss: 2.7714389262905383

Epoch: 57| Step: 0
Training loss: 3.4435459028020214
Validation loss: 2.7679634550540273

Epoch: 5| Step: 1
Training loss: 3.059971914224823
Validation loss: 2.766292185877666

Epoch: 5| Step: 2
Training loss: 2.4878815669791634
Validation loss: 2.762866343072755

Epoch: 5| Step: 3
Training loss: 3.333305517716382
Validation loss: 2.762871121710668

Epoch: 5| Step: 4
Training loss: 3.355372968201494
Validation loss: 2.764020308375425

Epoch: 5| Step: 5
Training loss: 3.0005497428738703
Validation loss: 2.7684034385036993

Epoch: 5| Step: 6
Training loss: 2.8114269328804866
Validation loss: 2.7716441060429644

Epoch: 5| Step: 7
Training loss: 3.1859556458589267
Validation loss: 2.775830580111162

Epoch: 5| Step: 8
Training loss: 2.8390930946729673
Validation loss: 2.7759420808804136

Epoch: 5| Step: 9
Training loss: 3.046192581831534
Validation loss: 2.7659572714336673

Epoch: 5| Step: 10
Training loss: 3.2148477547343677
Validation loss: 2.762653918236328

Epoch: 58| Step: 0
Training loss: 3.2012734621045427
Validation loss: 2.7620838600014275

Epoch: 5| Step: 1
Training loss: 2.8972010687200798
Validation loss: 2.7587195862052893

Epoch: 5| Step: 2
Training loss: 3.411913441981096
Validation loss: 2.761052047654477

Epoch: 5| Step: 3
Training loss: 2.9776769439111095
Validation loss: 2.7547242965540732

Epoch: 5| Step: 4
Training loss: 2.9163083174229896
Validation loss: 2.756693826044074

Epoch: 5| Step: 5
Training loss: 2.933869086092809
Validation loss: 2.7583483428987865

Epoch: 5| Step: 6
Training loss: 2.9234317977254314
Validation loss: 2.752970262296908

Epoch: 5| Step: 7
Training loss: 2.9532943757747736
Validation loss: 2.75689548437145

Epoch: 5| Step: 8
Training loss: 2.9947779027650197
Validation loss: 2.7564171621028577

Epoch: 5| Step: 9
Training loss: 3.300231960120468
Validation loss: 2.7576451478983444

Epoch: 5| Step: 10
Training loss: 3.3302668453672806
Validation loss: 2.766027388033642

Epoch: 59| Step: 0
Training loss: 3.1425505092206443
Validation loss: 2.7894507423125314

Epoch: 5| Step: 1
Training loss: 3.0592593739122735
Validation loss: 2.804539214305862

Epoch: 5| Step: 2
Training loss: 2.9784999359217945
Validation loss: 2.8202329393798315

Epoch: 5| Step: 3
Training loss: 2.908163609694185
Validation loss: 2.7987151772946337

Epoch: 5| Step: 4
Training loss: 3.2708047918220458
Validation loss: 2.7801966878511952

Epoch: 5| Step: 5
Training loss: 3.3679597681501376
Validation loss: 2.760290995032049

Epoch: 5| Step: 6
Training loss: 3.070951516626119
Validation loss: 2.756214202870884

Epoch: 5| Step: 7
Training loss: 3.04632610365295
Validation loss: 2.7536951337160676

Epoch: 5| Step: 8
Training loss: 3.124411260459689
Validation loss: 2.752055020248914

Epoch: 5| Step: 9
Training loss: 3.045222533664989
Validation loss: 2.750055999595868

Epoch: 5| Step: 10
Training loss: 2.874754522043877
Validation loss: 2.7513057744686518

Epoch: 60| Step: 0
Training loss: 3.36836353130542
Validation loss: 2.747897939790712

Epoch: 5| Step: 1
Training loss: 3.04207636194737
Validation loss: 2.7487292947688697

Epoch: 5| Step: 2
Training loss: 2.7640024371653964
Validation loss: 2.747523289748727

Epoch: 5| Step: 3
Training loss: 2.9920878978914534
Validation loss: 2.7517750372673375

Epoch: 5| Step: 4
Training loss: 2.8546527160964086
Validation loss: 2.761581148037979

Epoch: 5| Step: 5
Training loss: 2.9801042766376127
Validation loss: 2.7742779181868156

Epoch: 5| Step: 6
Training loss: 3.1901912921244517
Validation loss: 2.7948041252039038

Epoch: 5| Step: 7
Training loss: 2.799501602910941
Validation loss: 2.775739268273511

Epoch: 5| Step: 8
Training loss: 3.6487344298336
Validation loss: 2.7701442255435293

Epoch: 5| Step: 9
Training loss: 3.147162621848349
Validation loss: 2.748362365888502

Epoch: 5| Step: 10
Training loss: 2.953940949920989
Validation loss: 2.7433733576939465

Epoch: 61| Step: 0
Training loss: 3.8047119390497817
Validation loss: 2.7450113699903356

Epoch: 5| Step: 1
Training loss: 3.1347361150285455
Validation loss: 2.7489633004446525

Epoch: 5| Step: 2
Training loss: 3.364704677098261
Validation loss: 2.7590919930444917

Epoch: 5| Step: 3
Training loss: 3.258157469417342
Validation loss: 2.7645210188676206

Epoch: 5| Step: 4
Training loss: 3.3286215541580666
Validation loss: 2.7682431629997697

Epoch: 5| Step: 5
Training loss: 2.543424457085877
Validation loss: 2.757370448189415

Epoch: 5| Step: 6
Training loss: 3.0594133664960554
Validation loss: 2.7507328108621025

Epoch: 5| Step: 7
Training loss: 2.7257306160656123
Validation loss: 2.7497704616147765

Epoch: 5| Step: 8
Training loss: 2.66255212294014
Validation loss: 2.745609531851599

Epoch: 5| Step: 9
Training loss: 2.8423039039736664
Validation loss: 2.74375304435602

Epoch: 5| Step: 10
Training loss: 2.9948368146506277
Validation loss: 2.7432386091559606

Epoch: 62| Step: 0
Training loss: 2.629644281822102
Validation loss: 2.743863272727137

Epoch: 5| Step: 1
Training loss: 3.000862633342195
Validation loss: 2.7662725268183963

Epoch: 5| Step: 2
Training loss: 3.2722621801585214
Validation loss: 2.7818197008170378

Epoch: 5| Step: 3
Training loss: 3.4987176180721273
Validation loss: 2.780328490794502

Epoch: 5| Step: 4
Training loss: 3.3511818978697447
Validation loss: 2.7441752882094956

Epoch: 5| Step: 5
Training loss: 2.917018996256954
Validation loss: 2.745315858180997

Epoch: 5| Step: 6
Training loss: 3.1855576524955636
Validation loss: 2.7455900048188435

Epoch: 5| Step: 7
Training loss: 3.4736890941110987
Validation loss: 2.749614442438556

Epoch: 5| Step: 8
Training loss: 2.6358346318657717
Validation loss: 2.7602729436445657

Epoch: 5| Step: 9
Training loss: 2.579646083746551
Validation loss: 2.768654310602103

Epoch: 5| Step: 10
Training loss: 3.011083790779123
Validation loss: 2.790994553767847

Epoch: 63| Step: 0
Training loss: 3.0097627732587076
Validation loss: 2.773358166103175

Epoch: 5| Step: 1
Training loss: 3.641870637560134
Validation loss: 2.7560932971238787

Epoch: 5| Step: 2
Training loss: 2.8937713819995
Validation loss: 2.7420041995573707

Epoch: 5| Step: 3
Training loss: 3.377705655108762
Validation loss: 2.7373346889881236

Epoch: 5| Step: 4
Training loss: 2.639997238388929
Validation loss: 2.732696323564564

Epoch: 5| Step: 5
Training loss: 2.92359212918033
Validation loss: 2.735302104674824

Epoch: 5| Step: 6
Training loss: 3.087439989750022
Validation loss: 2.7329453038201663

Epoch: 5| Step: 7
Training loss: 2.882249399823548
Validation loss: 2.730944967090798

Epoch: 5| Step: 8
Training loss: 2.662878047269327
Validation loss: 2.7276333263026045

Epoch: 5| Step: 9
Training loss: 3.33142442085589
Validation loss: 2.7277076037939727

Epoch: 5| Step: 10
Training loss: 3.0273606035317164
Validation loss: 2.727707571839015

Epoch: 64| Step: 0
Training loss: 3.0927210165868484
Validation loss: 2.7281279125667224

Epoch: 5| Step: 1
Training loss: 2.8462298971948043
Validation loss: 2.7292007660835353

Epoch: 5| Step: 2
Training loss: 3.0824206436226316
Validation loss: 2.726788896297735

Epoch: 5| Step: 3
Training loss: 3.1545722959284443
Validation loss: 2.7247880132383298

Epoch: 5| Step: 4
Training loss: 3.456990835524713
Validation loss: 2.723643508932662

Epoch: 5| Step: 5
Training loss: 2.813688408589751
Validation loss: 2.728767055465145

Epoch: 5| Step: 6
Training loss: 2.993072139952684
Validation loss: 2.7290392647653787

Epoch: 5| Step: 7
Training loss: 2.950954063148476
Validation loss: 2.7285032996486236

Epoch: 5| Step: 8
Training loss: 3.1102523716032238
Validation loss: 2.7271784009124493

Epoch: 5| Step: 9
Training loss: 2.983786639790451
Validation loss: 2.733065068666229

Epoch: 5| Step: 10
Training loss: 3.027087470251111
Validation loss: 2.749161666139799

Epoch: 65| Step: 0
Training loss: 3.1426501980062636
Validation loss: 2.7564905393485986

Epoch: 5| Step: 1
Training loss: 3.6392625870819457
Validation loss: 2.7591654914869834

Epoch: 5| Step: 2
Training loss: 2.6842522625291427
Validation loss: 2.7536025934801294

Epoch: 5| Step: 3
Training loss: 2.58531462667556
Validation loss: 2.7578510536320997

Epoch: 5| Step: 4
Training loss: 3.620553018469126
Validation loss: 2.7455836283670796

Epoch: 5| Step: 5
Training loss: 2.473951630164987
Validation loss: 2.7340744317451415

Epoch: 5| Step: 6
Training loss: 2.7338531868171545
Validation loss: 2.7265365716413785

Epoch: 5| Step: 7
Training loss: 3.596600803294249
Validation loss: 2.7267404019826786

Epoch: 5| Step: 8
Training loss: 2.7398561310413605
Validation loss: 2.7184191257173502

Epoch: 5| Step: 9
Training loss: 2.783579504430026
Validation loss: 2.7164423352880833

Epoch: 5| Step: 10
Training loss: 3.2970191960191038
Validation loss: 2.715503259409498

Epoch: 66| Step: 0
Training loss: 2.8343180086069335
Validation loss: 2.7192447972589666

Epoch: 5| Step: 1
Training loss: 2.4984258464185984
Validation loss: 2.714374796887969

Epoch: 5| Step: 2
Training loss: 2.583681442022944
Validation loss: 2.7126712955369263

Epoch: 5| Step: 3
Training loss: 3.2981415977732675
Validation loss: 2.7176912834978357

Epoch: 5| Step: 4
Training loss: 3.13209643468586
Validation loss: 2.7222256111786356

Epoch: 5| Step: 5
Training loss: 2.8911043336739817
Validation loss: 2.7231849327425723

Epoch: 5| Step: 6
Training loss: 3.4171622932526535
Validation loss: 2.7391250515884504

Epoch: 5| Step: 7
Training loss: 3.46206777470811
Validation loss: 2.7320920108910833

Epoch: 5| Step: 8
Training loss: 3.096167958496709
Validation loss: 2.7195024515809894

Epoch: 5| Step: 9
Training loss: 2.8986493878918473
Validation loss: 2.71696096286157

Epoch: 5| Step: 10
Training loss: 3.203644649873574
Validation loss: 2.713139110625373

Epoch: 67| Step: 0
Training loss: 2.8661008017596257
Validation loss: 2.7101983359445057

Epoch: 5| Step: 1
Training loss: 3.248218194660653
Validation loss: 2.716864030157428

Epoch: 5| Step: 2
Training loss: 3.2174730453014226
Validation loss: 2.7094450594387847

Epoch: 5| Step: 3
Training loss: 3.1596499722409948
Validation loss: 2.7158523571072313

Epoch: 5| Step: 4
Training loss: 3.277326145056634
Validation loss: 2.7129931784912595

Epoch: 5| Step: 5
Training loss: 2.980699282788605
Validation loss: 2.7140100744955493

Epoch: 5| Step: 6
Training loss: 3.0318101188466144
Validation loss: 2.717376880855366

Epoch: 5| Step: 7
Training loss: 2.691723011793152
Validation loss: 2.709676290009864

Epoch: 5| Step: 8
Training loss: 3.2912458480768207
Validation loss: 2.710895141410593

Epoch: 5| Step: 9
Training loss: 2.4463515344131426
Validation loss: 2.7122718841760944

Epoch: 5| Step: 10
Training loss: 3.061139174200226
Validation loss: 2.7104434628584877

Epoch: 68| Step: 0
Training loss: 3.294747628950746
Validation loss: 2.7078392758239196

Epoch: 5| Step: 1
Training loss: 2.816573351004613
Validation loss: 2.709835246270823

Epoch: 5| Step: 2
Training loss: 2.6810961877058257
Validation loss: 2.710074051973358

Epoch: 5| Step: 3
Training loss: 2.707150763533543
Validation loss: 2.708415727963315

Epoch: 5| Step: 4
Training loss: 3.2029484397794703
Validation loss: 2.70545356904972

Epoch: 5| Step: 5
Training loss: 3.207843115540169
Validation loss: 2.7098653342897308

Epoch: 5| Step: 6
Training loss: 2.642359147229149
Validation loss: 2.7103186490836

Epoch: 5| Step: 7
Training loss: 3.25778834930909
Validation loss: 2.7060914358131405

Epoch: 5| Step: 8
Training loss: 3.5096907652788016
Validation loss: 2.710428839216514

Epoch: 5| Step: 9
Training loss: 2.7724976572451654
Validation loss: 2.70715699186973

Epoch: 5| Step: 10
Training loss: 3.133690156977707
Validation loss: 2.705112131610696

Epoch: 69| Step: 0
Training loss: 2.965053143853247
Validation loss: 2.705689378908336

Epoch: 5| Step: 1
Training loss: 2.695703096697942
Validation loss: 2.704867641833493

Epoch: 5| Step: 2
Training loss: 3.025047799985929
Validation loss: 2.7011996659523696

Epoch: 5| Step: 3
Training loss: 4.010059344073746
Validation loss: 2.7020439837745354

Epoch: 5| Step: 4
Training loss: 2.815031650019728
Validation loss: 2.7191511826351538

Epoch: 5| Step: 5
Training loss: 3.2288081964851894
Validation loss: 2.7240760843809024

Epoch: 5| Step: 6
Training loss: 2.435936059272345
Validation loss: 2.74381981632207

Epoch: 5| Step: 7
Training loss: 3.325554083068207
Validation loss: 2.7720660153076775

Epoch: 5| Step: 8
Training loss: 2.7014482181662025
Validation loss: 2.7280716846246564

Epoch: 5| Step: 9
Training loss: 3.1382011815503144
Validation loss: 2.702552506696218

Epoch: 5| Step: 10
Training loss: 2.6903338905075205
Validation loss: 2.700211399557603

Epoch: 70| Step: 0
Training loss: 3.1665339860391852
Validation loss: 2.7018498558167203

Epoch: 5| Step: 1
Training loss: 2.3733733780657915
Validation loss: 2.705594572294223

Epoch: 5| Step: 2
Training loss: 3.5178363542170734
Validation loss: 2.714482939174232

Epoch: 5| Step: 3
Training loss: 3.1141515494178664
Validation loss: 2.7295510075359304

Epoch: 5| Step: 4
Training loss: 3.344580003632115
Validation loss: 2.722095361049644

Epoch: 5| Step: 5
Training loss: 2.7750563504108023
Validation loss: 2.709220370542269

Epoch: 5| Step: 6
Training loss: 3.5927900276101745
Validation loss: 2.703225929566322

Epoch: 5| Step: 7
Training loss: 2.7507958561022776
Validation loss: 2.6995294289226006

Epoch: 5| Step: 8
Training loss: 2.979037159770249
Validation loss: 2.7006455107467815

Epoch: 5| Step: 9
Training loss: 2.6590182969524356
Validation loss: 2.70838867175138

Epoch: 5| Step: 10
Training loss: 3.0056139552690246
Validation loss: 2.7198760789110223

Epoch: 71| Step: 0
Training loss: 3.0154524837817958
Validation loss: 2.7420201123838406

Epoch: 5| Step: 1
Training loss: 3.130251629742077
Validation loss: 2.7746948858230533

Epoch: 5| Step: 2
Training loss: 3.160811951539219
Validation loss: 2.73602980926749

Epoch: 5| Step: 3
Training loss: 3.2621776143828773
Validation loss: 2.7026738014244587

Epoch: 5| Step: 4
Training loss: 3.1230471803666204
Validation loss: 2.6976231279005787

Epoch: 5| Step: 5
Training loss: 2.760357166344786
Validation loss: 2.708330286622207

Epoch: 5| Step: 6
Training loss: 2.6633620250176566
Validation loss: 2.710134587509807

Epoch: 5| Step: 7
Training loss: 3.1550233175682574
Validation loss: 2.708225864016699

Epoch: 5| Step: 8
Training loss: 2.8743267100226633
Validation loss: 2.7079325364414184

Epoch: 5| Step: 9
Training loss: 2.52904753763177
Validation loss: 2.7090467991483465

Epoch: 5| Step: 10
Training loss: 3.6451678440711337
Validation loss: 2.72060477553368

Epoch: 72| Step: 0
Training loss: 2.8057898265191112
Validation loss: 2.697665117092887

Epoch: 5| Step: 1
Training loss: 2.9069145837392196
Validation loss: 2.696340162941063

Epoch: 5| Step: 2
Training loss: 2.9009321227471236
Validation loss: 2.6919210880290567

Epoch: 5| Step: 3
Training loss: 3.3899344167301297
Validation loss: 2.6921101973290495

Epoch: 5| Step: 4
Training loss: 3.1843844876882703
Validation loss: 2.6974364294466135

Epoch: 5| Step: 5
Training loss: 2.9948243954846565
Validation loss: 2.7131606126467416

Epoch: 5| Step: 6
Training loss: 3.2636011596542973
Validation loss: 2.708332785581876

Epoch: 5| Step: 7
Training loss: 3.057389023295941
Validation loss: 2.7105981549909957

Epoch: 5| Step: 8
Training loss: 3.174434737702236
Validation loss: 2.700913688870963

Epoch: 5| Step: 9
Training loss: 3.1380917785138114
Validation loss: 2.6873814088526684

Epoch: 5| Step: 10
Training loss: 2.1264915841279373
Validation loss: 2.687979934585689

Epoch: 73| Step: 0
Training loss: 3.028890418915779
Validation loss: 2.6916382444630997

Epoch: 5| Step: 1
Training loss: 2.6683666552484953
Validation loss: 2.6943897010514686

Epoch: 5| Step: 2
Training loss: 2.906599782588339
Validation loss: 2.704636528114114

Epoch: 5| Step: 3
Training loss: 3.2032631448868862
Validation loss: 2.6918158802959633

Epoch: 5| Step: 4
Training loss: 3.131904451425504
Validation loss: 2.679977335784295

Epoch: 5| Step: 5
Training loss: 2.4905188065197703
Validation loss: 2.679080470205365

Epoch: 5| Step: 6
Training loss: 3.1073937933304516
Validation loss: 2.681026011913766

Epoch: 5| Step: 7
Training loss: 3.0318450343708143
Validation loss: 2.682554891836042

Epoch: 5| Step: 8
Training loss: 3.340399516304574
Validation loss: 2.680538743900259

Epoch: 5| Step: 9
Training loss: 2.7867852325251867
Validation loss: 2.682983672999794

Epoch: 5| Step: 10
Training loss: 3.4776935923350076
Validation loss: 2.6812913315825777

Epoch: 74| Step: 0
Training loss: 3.4721193188147947
Validation loss: 2.6825602655702006

Epoch: 5| Step: 1
Training loss: 3.120748145074407
Validation loss: 2.6883464795603476

Epoch: 5| Step: 2
Training loss: 2.519797424923795
Validation loss: 2.687275983321983

Epoch: 5| Step: 3
Training loss: 2.8589268734503888
Validation loss: 2.688200481346406

Epoch: 5| Step: 4
Training loss: 3.202978810021429
Validation loss: 2.702393259615589

Epoch: 5| Step: 5
Training loss: 3.1720477277958086
Validation loss: 2.6930923104041335

Epoch: 5| Step: 6
Training loss: 3.238889041273209
Validation loss: 2.6861362082852414

Epoch: 5| Step: 7
Training loss: 3.090457590041437
Validation loss: 2.6830565455869317

Epoch: 5| Step: 8
Training loss: 2.8090414186535995
Validation loss: 2.6783250147876303

Epoch: 5| Step: 9
Training loss: 3.004075778498103
Validation loss: 2.6764880818122108

Epoch: 5| Step: 10
Training loss: 2.464716646571809
Validation loss: 2.6774452835907576

Epoch: 75| Step: 0
Training loss: 2.55346127633573
Validation loss: 2.6823899627525107

Epoch: 5| Step: 1
Training loss: 3.0404316384914565
Validation loss: 2.683760628308504

Epoch: 5| Step: 2
Training loss: 3.196333220841467
Validation loss: 2.691263504132755

Epoch: 5| Step: 3
Training loss: 2.7711719124425587
Validation loss: 2.7146047830924553

Epoch: 5| Step: 4
Training loss: 3.28952740715729
Validation loss: 2.7168610870585517

Epoch: 5| Step: 5
Training loss: 2.5158340651553304
Validation loss: 2.6906503678911604

Epoch: 5| Step: 6
Training loss: 3.1211145278563706
Validation loss: 2.6838102832342465

Epoch: 5| Step: 7
Training loss: 3.344850305648925
Validation loss: 2.6795143749094863

Epoch: 5| Step: 8
Training loss: 3.005113376503397
Validation loss: 2.6778201578360497

Epoch: 5| Step: 9
Training loss: 2.948127837868142
Validation loss: 2.6747819153405037

Epoch: 5| Step: 10
Training loss: 3.265805326164706
Validation loss: 2.6760266996161737

Epoch: 76| Step: 0
Training loss: 2.685366204860209
Validation loss: 2.675691782011986

Epoch: 5| Step: 1
Training loss: 2.8608404687899345
Validation loss: 2.67551507825824

Epoch: 5| Step: 2
Training loss: 2.6782219885909604
Validation loss: 2.675717388672751

Epoch: 5| Step: 3
Training loss: 3.0807372496437884
Validation loss: 2.67391244257134

Epoch: 5| Step: 4
Training loss: 3.4716397182562053
Validation loss: 2.676144778500134

Epoch: 5| Step: 5
Training loss: 3.0245952114683554
Validation loss: 2.6714361310469124

Epoch: 5| Step: 6
Training loss: 2.972536904223841
Validation loss: 2.672445159048295

Epoch: 5| Step: 7
Training loss: 3.200187564359708
Validation loss: 2.680412256416487

Epoch: 5| Step: 8
Training loss: 3.285374837128112
Validation loss: 2.6877350738960466

Epoch: 5| Step: 9
Training loss: 3.0395565464930265
Validation loss: 2.699562477909095

Epoch: 5| Step: 10
Training loss: 2.6889728679713896
Validation loss: 2.6733537856333256

Epoch: 77| Step: 0
Training loss: 2.9953192116309455
Validation loss: 2.6708383334341512

Epoch: 5| Step: 1
Training loss: 2.2406276899717987
Validation loss: 2.667058272474266

Epoch: 5| Step: 2
Training loss: 2.903319819784267
Validation loss: 2.6645199722694453

Epoch: 5| Step: 3
Training loss: 2.7487026969305504
Validation loss: 2.664202471282047

Epoch: 5| Step: 4
Training loss: 3.1882667367310877
Validation loss: 2.6657078942768915

Epoch: 5| Step: 5
Training loss: 3.154853436289517
Validation loss: 2.6687043202255385

Epoch: 5| Step: 6
Training loss: 2.9925579907400115
Validation loss: 2.667860341426839

Epoch: 5| Step: 7
Training loss: 3.067426183880337
Validation loss: 2.668903113527152

Epoch: 5| Step: 8
Training loss: 2.9799554665329366
Validation loss: 2.6670431081600623

Epoch: 5| Step: 9
Training loss: 3.104424143786794
Validation loss: 2.670175428841146

Epoch: 5| Step: 10
Training loss: 3.5857293893434115
Validation loss: 2.678552906911854

Epoch: 78| Step: 0
Training loss: 2.7698808242280073
Validation loss: 2.6710284794944106

Epoch: 5| Step: 1
Training loss: 2.916188954786629
Validation loss: 2.6692353926896257

Epoch: 5| Step: 2
Training loss: 2.5642033939832722
Validation loss: 2.6652382840465942

Epoch: 5| Step: 3
Training loss: 3.0084652675394494
Validation loss: 2.66163077136058

Epoch: 5| Step: 4
Training loss: 3.51301036670088
Validation loss: 2.6671403434071816

Epoch: 5| Step: 5
Training loss: 3.0876151244904895
Validation loss: 2.6647574062404016

Epoch: 5| Step: 6
Training loss: 2.9840138801067804
Validation loss: 2.6625460454184946

Epoch: 5| Step: 7
Training loss: 2.778726096932053
Validation loss: 2.6751393750031034

Epoch: 5| Step: 8
Training loss: 3.205537957140038
Validation loss: 2.674919902962084

Epoch: 5| Step: 9
Training loss: 3.177727472430272
Validation loss: 2.689846455835478

Epoch: 5| Step: 10
Training loss: 2.8193298487767646
Validation loss: 2.6921705349696827

Epoch: 79| Step: 0
Training loss: 2.630214326052244
Validation loss: 2.6775519014155007

Epoch: 5| Step: 1
Training loss: 2.627488364675731
Validation loss: 2.6676363726482637

Epoch: 5| Step: 2
Training loss: 3.0425069162232177
Validation loss: 2.6692746801621245

Epoch: 5| Step: 3
Training loss: 3.1402806335223277
Validation loss: 2.68022789240884

Epoch: 5| Step: 4
Training loss: 2.7054141720700997
Validation loss: 2.681714730958525

Epoch: 5| Step: 5
Training loss: 2.562425379713353
Validation loss: 2.6983100885212172

Epoch: 5| Step: 6
Training loss: 3.3963130931869525
Validation loss: 2.689165223790923

Epoch: 5| Step: 7
Training loss: 3.0565361029453584
Validation loss: 2.6552735581862796

Epoch: 5| Step: 8
Training loss: 3.6075672725503765
Validation loss: 2.662242777572579

Epoch: 5| Step: 9
Training loss: 3.46432295092429
Validation loss: 2.7095065684397417

Epoch: 5| Step: 10
Training loss: 2.4070591742639404
Validation loss: 2.713914481676472

Epoch: 80| Step: 0
Training loss: 3.1243969144623036
Validation loss: 2.673143418826073

Epoch: 5| Step: 1
Training loss: 3.105330247009674
Validation loss: 2.667042297843432

Epoch: 5| Step: 2
Training loss: 2.922193866812956
Validation loss: 2.6598972506897964

Epoch: 5| Step: 3
Training loss: 3.166119544967066
Validation loss: 2.6569324232067495

Epoch: 5| Step: 4
Training loss: 3.101567419706426
Validation loss: 2.6599210384250482

Epoch: 5| Step: 5
Training loss: 2.7651189998521772
Validation loss: 2.6589778330516727

Epoch: 5| Step: 6
Training loss: 2.2802257590036836
Validation loss: 2.658609985260719

Epoch: 5| Step: 7
Training loss: 3.468281757265162
Validation loss: 2.654323823883738

Epoch: 5| Step: 8
Training loss: 2.6692322270772677
Validation loss: 2.6549781519539715

Epoch: 5| Step: 9
Training loss: 3.6138737373187553
Validation loss: 2.6520158311662776

Epoch: 5| Step: 10
Training loss: 2.5121850608702805
Validation loss: 2.652141583094143

Epoch: 81| Step: 0
Training loss: 2.86799381570402
Validation loss: 2.6572231336675376

Epoch: 5| Step: 1
Training loss: 2.504444082405465
Validation loss: 2.6588987864349343

Epoch: 5| Step: 2
Training loss: 3.141115368570055
Validation loss: 2.6618476446318016

Epoch: 5| Step: 3
Training loss: 2.9758503379823766
Validation loss: 2.6732116293876818

Epoch: 5| Step: 4
Training loss: 2.707628148534223
Validation loss: 2.682756244215504

Epoch: 5| Step: 5
Training loss: 3.3590906776937772
Validation loss: 2.687931679552027

Epoch: 5| Step: 6
Training loss: 3.10967157377639
Validation loss: 2.6800163686936895

Epoch: 5| Step: 7
Training loss: 3.173839693488532
Validation loss: 2.689093613094667

Epoch: 5| Step: 8
Training loss: 3.098375350013344
Validation loss: 2.6776765498324164

Epoch: 5| Step: 9
Training loss: 2.635903917787246
Validation loss: 2.6669126776561294

Epoch: 5| Step: 10
Training loss: 3.250818442948057
Validation loss: 2.655746562813997

Epoch: 82| Step: 0
Training loss: 3.2818541924204396
Validation loss: 2.6562852320304002

Epoch: 5| Step: 1
Training loss: 2.9049847217361586
Validation loss: 2.6571860597369783

Epoch: 5| Step: 2
Training loss: 2.756260767632383
Validation loss: 2.6523089749948996

Epoch: 5| Step: 3
Training loss: 2.9711414542971313
Validation loss: 2.653000535785741

Epoch: 5| Step: 4
Training loss: 3.1779447461288943
Validation loss: 2.654631026843791

Epoch: 5| Step: 5
Training loss: 3.1799205347844692
Validation loss: 2.6473841025300144

Epoch: 5| Step: 6
Training loss: 3.0517754686989242
Validation loss: 2.652227951079234

Epoch: 5| Step: 7
Training loss: 2.444991508110293
Validation loss: 2.646949769586704

Epoch: 5| Step: 8
Training loss: 2.804751594682412
Validation loss: 2.6476952594458965

Epoch: 5| Step: 9
Training loss: 3.2662595287582556
Validation loss: 2.6442331021298107

Epoch: 5| Step: 10
Training loss: 2.9268917324215926
Validation loss: 2.642220418252993

Epoch: 83| Step: 0
Training loss: 3.0715872954864794
Validation loss: 2.644802382608694

Epoch: 5| Step: 1
Training loss: 2.4940226623313126
Validation loss: 2.6542515870850014

Epoch: 5| Step: 2
Training loss: 2.740038951123563
Validation loss: 2.665826787957851

Epoch: 5| Step: 3
Training loss: 2.9427030220096335
Validation loss: 2.6850957721540922

Epoch: 5| Step: 4
Training loss: 2.790630850620267
Validation loss: 2.6846243547017963

Epoch: 5| Step: 5
Training loss: 2.7758031078179126
Validation loss: 2.6938101922677222

Epoch: 5| Step: 6
Training loss: 2.8134630885491747
Validation loss: 2.668216352774746

Epoch: 5| Step: 7
Training loss: 3.248662526683908
Validation loss: 2.6576735280205743

Epoch: 5| Step: 8
Training loss: 3.5956183842625156
Validation loss: 2.6450820164890674

Epoch: 5| Step: 9
Training loss: 3.194622832767608
Validation loss: 2.6485470655866923

Epoch: 5| Step: 10
Training loss: 2.954188564059763
Validation loss: 2.641157266158586

Epoch: 84| Step: 0
Training loss: 2.8403972941536284
Validation loss: 2.6389955338965643

Epoch: 5| Step: 1
Training loss: 3.0050681537129025
Validation loss: 2.642417698693804

Epoch: 5| Step: 2
Training loss: 3.185782175360967
Validation loss: 2.643796472163537

Epoch: 5| Step: 3
Training loss: 3.2553615361083823
Validation loss: 2.646349352674553

Epoch: 5| Step: 4
Training loss: 3.160085934303467
Validation loss: 2.645506585677013

Epoch: 5| Step: 5
Training loss: 2.8096819004549936
Validation loss: 2.6473237580236098

Epoch: 5| Step: 6
Training loss: 3.3718368400839713
Validation loss: 2.651169489024064

Epoch: 5| Step: 7
Training loss: 2.8858053081083193
Validation loss: 2.6527120985139088

Epoch: 5| Step: 8
Training loss: 2.954481025473478
Validation loss: 2.6741391480919874

Epoch: 5| Step: 9
Training loss: 2.4646305530073636
Validation loss: 2.6522491707401277

Epoch: 5| Step: 10
Training loss: 2.6669097630640173
Validation loss: 2.642836967858769

Epoch: 85| Step: 0
Training loss: 2.585682006384557
Validation loss: 2.640499539424833

Epoch: 5| Step: 1
Training loss: 2.841320131563294
Validation loss: 2.6405820465040897

Epoch: 5| Step: 2
Training loss: 3.223632368742396
Validation loss: 2.6398524254706888

Epoch: 5| Step: 3
Training loss: 2.971481833137798
Validation loss: 2.63877710113907

Epoch: 5| Step: 4
Training loss: 2.5790592234905123
Validation loss: 2.638250129720685

Epoch: 5| Step: 5
Training loss: 2.8914293974202643
Validation loss: 2.6357011765903535

Epoch: 5| Step: 6
Training loss: 2.8057674783248765
Validation loss: 2.638298973750242

Epoch: 5| Step: 7
Training loss: 2.922596725024933
Validation loss: 2.633961124621734

Epoch: 5| Step: 8
Training loss: 3.2618079258954795
Validation loss: 2.633910002391333

Epoch: 5| Step: 9
Training loss: 3.700362837244248
Validation loss: 2.6359894075957806

Epoch: 5| Step: 10
Training loss: 2.677306961238712
Validation loss: 2.6497558493275055

Epoch: 86| Step: 0
Training loss: 2.69000641804323
Validation loss: 2.660236987146894

Epoch: 5| Step: 1
Training loss: 3.0365692345251167
Validation loss: 2.663686102456373

Epoch: 5| Step: 2
Training loss: 2.871250195036148
Validation loss: 2.6867348014918533

Epoch: 5| Step: 3
Training loss: 2.568771688921989
Validation loss: 2.6647277950144987

Epoch: 5| Step: 4
Training loss: 3.0584005828310055
Validation loss: 2.6515889812307374

Epoch: 5| Step: 5
Training loss: 3.3213586931744645
Validation loss: 2.6407478276284024

Epoch: 5| Step: 6
Training loss: 2.8855665330951816
Validation loss: 2.633856337776272

Epoch: 5| Step: 7
Training loss: 2.9593330807320157
Validation loss: 2.633865798634811

Epoch: 5| Step: 8
Training loss: 2.975170220385885
Validation loss: 2.6318837949979157

Epoch: 5| Step: 9
Training loss: 2.904358935639045
Validation loss: 2.633265623819018

Epoch: 5| Step: 10
Training loss: 3.3310827445864715
Validation loss: 2.6318315428968946

Epoch: 87| Step: 0
Training loss: 3.1450325323463035
Validation loss: 2.6264549330998097

Epoch: 5| Step: 1
Training loss: 3.0785230969765625
Validation loss: 2.6320635204727925

Epoch: 5| Step: 2
Training loss: 3.07386415174195
Validation loss: 2.6260413068970503

Epoch: 5| Step: 3
Training loss: 3.1371717304069366
Validation loss: 2.6321507995322615

Epoch: 5| Step: 4
Training loss: 3.171451483954261
Validation loss: 2.6313519659257048

Epoch: 5| Step: 5
Training loss: 2.7589173089660375
Validation loss: 2.6317401263774602

Epoch: 5| Step: 6
Training loss: 2.5997872008758036
Validation loss: 2.6351764930574166

Epoch: 5| Step: 7
Training loss: 3.2445414259393006
Validation loss: 2.644380058103241

Epoch: 5| Step: 8
Training loss: 2.783128168535603
Validation loss: 2.656013521674126

Epoch: 5| Step: 9
Training loss: 2.700400859604231
Validation loss: 2.6709657945264698

Epoch: 5| Step: 10
Training loss: 2.9742640634887065
Validation loss: 2.6566043219323277

Epoch: 88| Step: 0
Training loss: 2.550911168386987
Validation loss: 2.6471561467612195

Epoch: 5| Step: 1
Training loss: 3.340462325072242
Validation loss: 2.6308886346442173

Epoch: 5| Step: 2
Training loss: 2.868019253611613
Validation loss: 2.627742988596467

Epoch: 5| Step: 3
Training loss: 2.4906390411096035
Validation loss: 2.6206341762014294

Epoch: 5| Step: 4
Training loss: 2.898594443295595
Validation loss: 2.6236435119383525

Epoch: 5| Step: 5
Training loss: 3.040553180908872
Validation loss: 2.620151461226727

Epoch: 5| Step: 6
Training loss: 3.2129615659911237
Validation loss: 2.621814105094654

Epoch: 5| Step: 7
Training loss: 3.105474738349179
Validation loss: 2.6233864965862113

Epoch: 5| Step: 8
Training loss: 2.733362849781729
Validation loss: 2.6192464371011734

Epoch: 5| Step: 9
Training loss: 3.2123338767712255
Validation loss: 2.6214371403657273

Epoch: 5| Step: 10
Training loss: 3.16930838034755
Validation loss: 2.617314561904137

Epoch: 89| Step: 0
Training loss: 2.9622585600639866
Validation loss: 2.6197853816520165

Epoch: 5| Step: 1
Training loss: 3.0708187549785046
Validation loss: 2.6200157980860204

Epoch: 5| Step: 2
Training loss: 2.79729641771035
Validation loss: 2.618984106671057

Epoch: 5| Step: 3
Training loss: 2.9675938011198273
Validation loss: 2.6177781901799215

Epoch: 5| Step: 4
Training loss: 2.5919081801293022
Validation loss: 2.631421574467558

Epoch: 5| Step: 5
Training loss: 3.0783457410638393
Validation loss: 2.635791196664859

Epoch: 5| Step: 6
Training loss: 2.948825026750674
Validation loss: 2.6370657763190124

Epoch: 5| Step: 7
Training loss: 2.5584548097115536
Validation loss: 2.6337313140108622

Epoch: 5| Step: 8
Training loss: 3.139209789050488
Validation loss: 2.6370973381630685

Epoch: 5| Step: 9
Training loss: 3.3731811708753283
Validation loss: 2.635491674846472

Epoch: 5| Step: 10
Training loss: 2.970539718036213
Validation loss: 2.630390347997939

Epoch: 90| Step: 0
Training loss: 3.1010017560740457
Validation loss: 2.6179261670156784

Epoch: 5| Step: 1
Training loss: 3.0080247680273375
Validation loss: 2.615993138459744

Epoch: 5| Step: 2
Training loss: 2.9251530664285132
Validation loss: 2.615670017597918

Epoch: 5| Step: 3
Training loss: 3.1142993061773994
Validation loss: 2.60801068679493

Epoch: 5| Step: 4
Training loss: 2.867665097739443
Validation loss: 2.6100983869941143

Epoch: 5| Step: 5
Training loss: 2.919969232998059
Validation loss: 2.6123770027628193

Epoch: 5| Step: 6
Training loss: 2.4298720703672507
Validation loss: 2.614052596130865

Epoch: 5| Step: 7
Training loss: 3.2609284865543104
Validation loss: 2.6111564909014815

Epoch: 5| Step: 8
Training loss: 2.843170274603367
Validation loss: 2.611580136822467

Epoch: 5| Step: 9
Training loss: 2.8451256411519736
Validation loss: 2.6101110406559127

Epoch: 5| Step: 10
Training loss: 3.1409322863508864
Validation loss: 2.611719364515401

Epoch: 91| Step: 0
Training loss: 3.172474470945169
Validation loss: 2.6124306292301864

Epoch: 5| Step: 1
Training loss: 2.9748366751837914
Validation loss: 2.6126953559093713

Epoch: 5| Step: 2
Training loss: 2.7033300597629255
Validation loss: 2.610993485938455

Epoch: 5| Step: 3
Training loss: 2.5053262240031695
Validation loss: 2.6104049727792877

Epoch: 5| Step: 4
Training loss: 3.3951220245230314
Validation loss: 2.6108502437543417

Epoch: 5| Step: 5
Training loss: 3.070297124693134
Validation loss: 2.612823112137713

Epoch: 5| Step: 6
Training loss: 3.4070402855984003
Validation loss: 2.613307217059794

Epoch: 5| Step: 7
Training loss: 2.971861644117186
Validation loss: 2.614256882854981

Epoch: 5| Step: 8
Training loss: 2.8537385345643047
Validation loss: 2.6134838146710644

Epoch: 5| Step: 9
Training loss: 2.838136267220705
Validation loss: 2.655705950599201

Epoch: 5| Step: 10
Training loss: 2.598624738690013
Validation loss: 2.7673586850460987

Epoch: 92| Step: 0
Training loss: 3.1706315031911734
Validation loss: 2.683304473947489

Epoch: 5| Step: 1
Training loss: 3.1452008215705103
Validation loss: 2.64966374069259

Epoch: 5| Step: 2
Training loss: 2.8075316732900983
Validation loss: 2.6320902392173897

Epoch: 5| Step: 3
Training loss: 2.8616512389554964
Validation loss: 2.6479718489279307

Epoch: 5| Step: 4
Training loss: 3.209662636827823
Validation loss: 2.6952719579699846

Epoch: 5| Step: 5
Training loss: 2.9300549899724913
Validation loss: 2.733918382340753

Epoch: 5| Step: 6
Training loss: 2.4938314630114364
Validation loss: 2.6193936850395914

Epoch: 5| Step: 7
Training loss: 2.7794487081352637
Validation loss: 2.610091147182226

Epoch: 5| Step: 8
Training loss: 2.3655279908137814
Validation loss: 2.6313499404228446

Epoch: 5| Step: 9
Training loss: 3.605676514827368
Validation loss: 2.9460346738687035

Epoch: 5| Step: 10
Training loss: 3.6808520375603404
Validation loss: 3.1339373036793305

Epoch: 93| Step: 0
Training loss: 2.5235974523911473
Validation loss: 2.8878803396352035

Epoch: 5| Step: 1
Training loss: 2.9566561462261047
Validation loss: 2.708447839353044

Epoch: 5| Step: 2
Training loss: 3.1875001495959676
Validation loss: 2.669769535054026

Epoch: 5| Step: 3
Training loss: 3.1477489239079834
Validation loss: 2.664169688996372

Epoch: 5| Step: 4
Training loss: 2.8732196436942727
Validation loss: 2.692633558167195

Epoch: 5| Step: 5
Training loss: 3.180211429404934
Validation loss: 2.706525604129058

Epoch: 5| Step: 6
Training loss: 3.3473579692267017
Validation loss: 2.6534495116793195

Epoch: 5| Step: 7
Training loss: 2.3813129647007867
Validation loss: 2.6407460753320136

Epoch: 5| Step: 8
Training loss: 3.042864228437989
Validation loss: 2.655728396427639

Epoch: 5| Step: 9
Training loss: 3.449826697820503
Validation loss: 2.701693380813514

Epoch: 5| Step: 10
Training loss: 3.1817103144704295
Validation loss: 2.7283822436618066

Epoch: 94| Step: 0
Training loss: 3.2217966123826094
Validation loss: 2.745903484076968

Epoch: 5| Step: 1
Training loss: 2.896809658066674
Validation loss: 2.7479299713750343

Epoch: 5| Step: 2
Training loss: 3.142906005900633
Validation loss: 2.71682145163249

Epoch: 5| Step: 3
Training loss: 2.812165473540583
Validation loss: 2.6720793791675095

Epoch: 5| Step: 4
Training loss: 3.1765071325547796
Validation loss: 2.6465983435855542

Epoch: 5| Step: 5
Training loss: 2.7804499986471267
Validation loss: 2.6418556219037836

Epoch: 5| Step: 6
Training loss: 2.8162859548414567
Validation loss: 2.6420718954187428

Epoch: 5| Step: 7
Training loss: 2.860217027766049
Validation loss: 2.6310358594961474

Epoch: 5| Step: 8
Training loss: 3.155961882782904
Validation loss: 2.636131485075302

Epoch: 5| Step: 9
Training loss: 2.5436742597921613
Validation loss: 2.6491903680348488

Epoch: 5| Step: 10
Training loss: 3.2904978902381354
Validation loss: 2.6494420673695243

Epoch: 95| Step: 0
Training loss: 2.938583823389246
Validation loss: 2.639134926832032

Epoch: 5| Step: 1
Training loss: 2.7188315543735198
Validation loss: 2.6392679928403378

Epoch: 5| Step: 2
Training loss: 2.5587620337668717
Validation loss: 2.641503710340194

Epoch: 5| Step: 3
Training loss: 2.844494062063799
Validation loss: 2.636080268782508

Epoch: 5| Step: 4
Training loss: 2.9751976268105453
Validation loss: 2.626020688186878

Epoch: 5| Step: 5
Training loss: 3.440117688938144
Validation loss: 2.622045439281767

Epoch: 5| Step: 6
Training loss: 3.07413033693941
Validation loss: 2.618586615825613

Epoch: 5| Step: 7
Training loss: 3.090850241758727
Validation loss: 2.6176627160975117

Epoch: 5| Step: 8
Training loss: 3.098960419127887
Validation loss: 2.6041292777710168

Epoch: 5| Step: 9
Training loss: 2.9912036045045602
Validation loss: 2.5903241240636348

Epoch: 5| Step: 10
Training loss: 2.672457715120152
Validation loss: 2.594552942879641

Epoch: 96| Step: 0
Training loss: 2.8060206058259487
Validation loss: 2.5941914512492024

Epoch: 5| Step: 1
Training loss: 2.3664816631845516
Validation loss: 2.59868941725371

Epoch: 5| Step: 2
Training loss: 2.8788312180160425
Validation loss: 2.6161224534370904

Epoch: 5| Step: 3
Training loss: 3.056890995387016
Validation loss: 2.6549498240649063

Epoch: 5| Step: 4
Training loss: 3.099667371316667
Validation loss: 2.643162287402424

Epoch: 5| Step: 5
Training loss: 2.1386239381756647
Validation loss: 2.612259533238593

Epoch: 5| Step: 6
Training loss: 3.3386596722311217
Validation loss: 2.6233734173651957

Epoch: 5| Step: 7
Training loss: 2.8043758463576665
Validation loss: 2.6493921911703042

Epoch: 5| Step: 8
Training loss: 3.2377749646635046
Validation loss: 2.6491073016482662

Epoch: 5| Step: 9
Training loss: 3.031279573591239
Validation loss: 2.663383710400345

Epoch: 5| Step: 10
Training loss: 3.6272899366532445
Validation loss: 2.66433823999847

Epoch: 97| Step: 0
Training loss: 2.8636552636649912
Validation loss: 2.591274274409977

Epoch: 5| Step: 1
Training loss: 2.817576256628037
Validation loss: 2.5948490414319654

Epoch: 5| Step: 2
Training loss: 3.0638880795289167
Validation loss: 2.603672213630661

Epoch: 5| Step: 3
Training loss: 2.957215236649436
Validation loss: 2.6289041338718886

Epoch: 5| Step: 4
Training loss: 2.8987615769168684
Validation loss: 2.6628606515894933

Epoch: 5| Step: 5
Training loss: 3.021547816177056
Validation loss: 2.6608367445141705

Epoch: 5| Step: 6
Training loss: 2.8798202243961875
Validation loss: 2.621893896252638

Epoch: 5| Step: 7
Training loss: 3.3306578548254766
Validation loss: 2.6058542571175876

Epoch: 5| Step: 8
Training loss: 2.632336944283259
Validation loss: 2.60375339961556

Epoch: 5| Step: 9
Training loss: 2.7299785037469455
Validation loss: 2.5986252536625134

Epoch: 5| Step: 10
Training loss: 3.6155722783233464
Validation loss: 2.5936257305044847

Epoch: 98| Step: 0
Training loss: 3.350841809306081
Validation loss: 2.5941140257569066

Epoch: 5| Step: 1
Training loss: 3.1360227351824244
Validation loss: 2.592252069230198

Epoch: 5| Step: 2
Training loss: 2.3352508045910225
Validation loss: 2.594162351860449

Epoch: 5| Step: 3
Training loss: 3.0033871285224643
Validation loss: 2.6001390497668972

Epoch: 5| Step: 4
Training loss: 3.0533314692673414
Validation loss: 2.6277655786458047

Epoch: 5| Step: 5
Training loss: 2.8965587850775885
Validation loss: 2.636426037242035

Epoch: 5| Step: 6
Training loss: 2.8571852340280377
Validation loss: 2.663508992030787

Epoch: 5| Step: 7
Training loss: 2.9871193615384914
Validation loss: 2.672522017898199

Epoch: 5| Step: 8
Training loss: 2.9238341591975976
Validation loss: 2.68053279706021

Epoch: 5| Step: 9
Training loss: 2.6925692101157637
Validation loss: 2.6568171320984635

Epoch: 5| Step: 10
Training loss: 3.345582976580619
Validation loss: 2.6384108157481454

Epoch: 99| Step: 0
Training loss: 2.6517333281949496
Validation loss: 2.6369287871606204

Epoch: 5| Step: 1
Training loss: 2.5672803809741764
Validation loss: 2.615036866290853

Epoch: 5| Step: 2
Training loss: 3.0628210405507583
Validation loss: 2.619010052426864

Epoch: 5| Step: 3
Training loss: 2.91338645313408
Validation loss: 2.590589542730865

Epoch: 5| Step: 4
Training loss: 3.013788167869231
Validation loss: 2.584250330716293

Epoch: 5| Step: 5
Training loss: 3.2890306049893545
Validation loss: 2.586733564257967

Epoch: 5| Step: 6
Training loss: 2.9754905873199284
Validation loss: 2.5833712451652397

Epoch: 5| Step: 7
Training loss: 2.499772156823308
Validation loss: 2.5807034900249253

Epoch: 5| Step: 8
Training loss: 3.237502792533937
Validation loss: 2.5815340644150035

Epoch: 5| Step: 9
Training loss: 2.9343954684810116
Validation loss: 2.5791772141402376

Epoch: 5| Step: 10
Training loss: 3.1172939655220953
Validation loss: 2.5810031301950778

Epoch: 100| Step: 0
Training loss: 3.2078535208329892
Validation loss: 2.579642693907918

Epoch: 5| Step: 1
Training loss: 3.068561705116968
Validation loss: 2.579199574530763

Epoch: 5| Step: 2
Training loss: 2.814085365215225
Validation loss: 2.5827024591251817

Epoch: 5| Step: 3
Training loss: 2.9669765596302757
Validation loss: 2.583694859598313

Epoch: 5| Step: 4
Training loss: 2.4412183521444124
Validation loss: 2.589594852413739

Epoch: 5| Step: 5
Training loss: 3.1125283665111274
Validation loss: 2.5874222843483072

Epoch: 5| Step: 6
Training loss: 3.171069414036485
Validation loss: 2.5873219015851285

Epoch: 5| Step: 7
Training loss: 2.136212332512299
Validation loss: 2.5933058074565696

Epoch: 5| Step: 8
Training loss: 2.7674437324021097
Validation loss: 2.595327747226567

Epoch: 5| Step: 9
Training loss: 2.8255306589450897
Validation loss: 2.5967391129625175

Epoch: 5| Step: 10
Training loss: 3.6401171677983517
Validation loss: 2.594885323496548

Epoch: 101| Step: 0
Training loss: 2.503936148478379
Validation loss: 2.5895148377311776

Epoch: 5| Step: 1
Training loss: 1.9411044893671636
Validation loss: 2.58775001321879

Epoch: 5| Step: 2
Training loss: 3.089047798426621
Validation loss: 2.5820251179815106

Epoch: 5| Step: 3
Training loss: 2.9531395321443035
Validation loss: 2.5791876031580254

Epoch: 5| Step: 4
Training loss: 2.6841398125005593
Validation loss: 2.5784089748369228

Epoch: 5| Step: 5
Training loss: 3.3631550657767715
Validation loss: 2.5771505414136326

Epoch: 5| Step: 6
Training loss: 3.038827450642809
Validation loss: 2.588542606867514

Epoch: 5| Step: 7
Training loss: 2.796817459281748
Validation loss: 2.5853073006024947

Epoch: 5| Step: 8
Training loss: 3.4513321446939944
Validation loss: 2.5910155462014233

Epoch: 5| Step: 9
Training loss: 2.813766025004431
Validation loss: 2.5885716307789113

Epoch: 5| Step: 10
Training loss: 3.3633105977868083
Validation loss: 2.583384003937839

Epoch: 102| Step: 0
Training loss: 3.1214868252653534
Validation loss: 2.5873483540973328

Epoch: 5| Step: 1
Training loss: 3.028231976551432
Validation loss: 2.5865957445150536

Epoch: 5| Step: 2
Training loss: 2.501688005871864
Validation loss: 2.596550213829207

Epoch: 5| Step: 3
Training loss: 3.2719039784544526
Validation loss: 2.614046455866934

Epoch: 5| Step: 4
Training loss: 3.083659661697394
Validation loss: 2.607100996799529

Epoch: 5| Step: 5
Training loss: 2.313762217220982
Validation loss: 2.5857380876025866

Epoch: 5| Step: 6
Training loss: 2.9200920336080523
Validation loss: 2.5671009953819652

Epoch: 5| Step: 7
Training loss: 3.110765922409373
Validation loss: 2.5689142037214387

Epoch: 5| Step: 8
Training loss: 3.332182510717113
Validation loss: 2.5761166901531096

Epoch: 5| Step: 9
Training loss: 2.6476994839332613
Validation loss: 2.5812577580590106

Epoch: 5| Step: 10
Training loss: 2.8227830036420856
Validation loss: 2.5810701345263847

Epoch: 103| Step: 0
Training loss: 2.892244122660374
Validation loss: 2.5857489801901434

Epoch: 5| Step: 1
Training loss: 2.4348245266895607
Validation loss: 2.5861651816638327

Epoch: 5| Step: 2
Training loss: 3.363783529703508
Validation loss: 2.5930565239214896

Epoch: 5| Step: 3
Training loss: 3.135961305749359
Validation loss: 2.5916944439449314

Epoch: 5| Step: 4
Training loss: 2.8904016356902003
Validation loss: 2.5895327201855407

Epoch: 5| Step: 5
Training loss: 2.680227508851915
Validation loss: 2.5899377336649656

Epoch: 5| Step: 6
Training loss: 3.2131847675955405
Validation loss: 2.58850560105706

Epoch: 5| Step: 7
Training loss: 3.058654550700759
Validation loss: 2.587935981561979

Epoch: 5| Step: 8
Training loss: 2.8080739268436976
Validation loss: 2.5851012537318665

Epoch: 5| Step: 9
Training loss: 2.9158349259045018
Validation loss: 2.5836456614812966

Epoch: 5| Step: 10
Training loss: 3.143336857065253
Validation loss: 2.5835184807642895

Epoch: 104| Step: 0
Training loss: 3.0725089799518512
Validation loss: 2.5794088926173564

Epoch: 5| Step: 1
Training loss: 2.8388178046530457
Validation loss: 2.5726027296974268

Epoch: 5| Step: 2
Training loss: 3.131414620037246
Validation loss: 2.5642436543293763

Epoch: 5| Step: 3
Training loss: 2.932951957301362
Validation loss: 2.5709599871508257

Epoch: 5| Step: 4
Training loss: 2.949177035611448
Validation loss: 2.5837174205149926

Epoch: 5| Step: 5
Training loss: 2.613514249760964
Validation loss: 2.5941086516322236

Epoch: 5| Step: 6
Training loss: 3.121577715919217
Validation loss: 2.6066446445370826

Epoch: 5| Step: 7
Training loss: 2.747102251080776
Validation loss: 2.6316304913331976

Epoch: 5| Step: 8
Training loss: 2.7624622083469603
Validation loss: 2.6528875070945404

Epoch: 5| Step: 9
Training loss: 3.258662929271588
Validation loss: 2.621434863691647

Epoch: 5| Step: 10
Training loss: 2.7568964747161337
Validation loss: 2.609400931265042

Epoch: 105| Step: 0
Training loss: 3.2168231122279276
Validation loss: 2.576554626513707

Epoch: 5| Step: 1
Training loss: 2.574971437758764
Validation loss: 2.5679630219041663

Epoch: 5| Step: 2
Training loss: 2.619667631718075
Validation loss: 2.5622496543908064

Epoch: 5| Step: 3
Training loss: 2.7069974294424095
Validation loss: 2.569011370002972

Epoch: 5| Step: 4
Training loss: 2.74869393631963
Validation loss: 2.5712976797765275

Epoch: 5| Step: 5
Training loss: 2.594170593722768
Validation loss: 2.5647553793891564

Epoch: 5| Step: 6
Training loss: 3.2870271233860375
Validation loss: 2.56627542579304

Epoch: 5| Step: 7
Training loss: 2.9394651292321328
Validation loss: 2.5655694991192144

Epoch: 5| Step: 8
Training loss: 3.181829607311394
Validation loss: 2.5693949936225984

Epoch: 5| Step: 9
Training loss: 3.1232794030363586
Validation loss: 2.5651797907123397

Epoch: 5| Step: 10
Training loss: 3.070694683642274
Validation loss: 2.5702057894927774

Epoch: 106| Step: 0
Training loss: 2.875082595302189
Validation loss: 2.5721417956150257

Epoch: 5| Step: 1
Training loss: 1.863342284156624
Validation loss: 2.568526915144331

Epoch: 5| Step: 2
Training loss: 3.0978976103951834
Validation loss: 2.5736619390494107

Epoch: 5| Step: 3
Training loss: 2.534954797766854
Validation loss: 2.5808146904948734

Epoch: 5| Step: 4
Training loss: 2.9386484052133373
Validation loss: 2.589991054163918

Epoch: 5| Step: 5
Training loss: 3.1024974115377812
Validation loss: 2.5894410880084155

Epoch: 5| Step: 6
Training loss: 3.108858918727303
Validation loss: 2.6110087126417247

Epoch: 5| Step: 7
Training loss: 2.905500089635866
Validation loss: 2.6223087881475804

Epoch: 5| Step: 8
Training loss: 3.026720733523771
Validation loss: 2.632164422440487

Epoch: 5| Step: 9
Training loss: 3.3653953367628415
Validation loss: 2.64833502208668

Epoch: 5| Step: 10
Training loss: 3.1573605236137063
Validation loss: 2.6159383222833386

Epoch: 107| Step: 0
Training loss: 3.0134978228659746
Validation loss: 2.583873884415684

Epoch: 5| Step: 1
Training loss: 2.9428571185192682
Validation loss: 2.5603355692913126

Epoch: 5| Step: 2
Training loss: 3.251391479746084
Validation loss: 2.559959288572697

Epoch: 5| Step: 3
Training loss: 2.8223214642237715
Validation loss: 2.5548961692541

Epoch: 5| Step: 4
Training loss: 3.3154201951263227
Validation loss: 2.5596818822128133

Epoch: 5| Step: 5
Training loss: 2.871909097130795
Validation loss: 2.5552472106066366

Epoch: 5| Step: 6
Training loss: 3.0204920258033945
Validation loss: 2.560346098844474

Epoch: 5| Step: 7
Training loss: 2.6385419405577997
Validation loss: 2.5637157226507123

Epoch: 5| Step: 8
Training loss: 2.271774365322678
Validation loss: 2.560767776062684

Epoch: 5| Step: 9
Training loss: 2.76810598353531
Validation loss: 2.56560184158098

Epoch: 5| Step: 10
Training loss: 3.1887264510137165
Validation loss: 2.5630181101668503

Epoch: 108| Step: 0
Training loss: 2.902156284690582
Validation loss: 2.5633099094174434

Epoch: 5| Step: 1
Training loss: 2.859400181060143
Validation loss: 2.5537825458591326

Epoch: 5| Step: 2
Training loss: 3.1075598244344333
Validation loss: 2.5578282396940257

Epoch: 5| Step: 3
Training loss: 3.033320398268176
Validation loss: 2.5637604334512796

Epoch: 5| Step: 4
Training loss: 2.4938117686487833
Validation loss: 2.572573802658714

Epoch: 5| Step: 5
Training loss: 2.738530864575773
Validation loss: 2.5781854696382207

Epoch: 5| Step: 6
Training loss: 2.9658436251450406
Validation loss: 2.6006980513462663

Epoch: 5| Step: 7
Training loss: 2.883398973309491
Validation loss: 2.6015576773332763

Epoch: 5| Step: 8
Training loss: 3.247220097579094
Validation loss: 2.597223990978286

Epoch: 5| Step: 9
Training loss: 2.492221652666899
Validation loss: 2.5907205660695865

Epoch: 5| Step: 10
Training loss: 3.411802892780738
Validation loss: 2.583199941847848

Epoch: 109| Step: 0
Training loss: 2.810506325986591
Validation loss: 2.571226377748824

Epoch: 5| Step: 1
Training loss: 2.3567176658295548
Validation loss: 2.5666868029927086

Epoch: 5| Step: 2
Training loss: 2.5785533202440853
Validation loss: 2.559373237025986

Epoch: 5| Step: 3
Training loss: 3.008124793548228
Validation loss: 2.558691544657198

Epoch: 5| Step: 4
Training loss: 2.937431659309335
Validation loss: 2.551215012082595

Epoch: 5| Step: 5
Training loss: 3.0801700827466427
Validation loss: 2.5608070788047357

Epoch: 5| Step: 6
Training loss: 3.037610646183144
Validation loss: 2.555835890370985

Epoch: 5| Step: 7
Training loss: 2.6533218400632794
Validation loss: 2.559254167058729

Epoch: 5| Step: 8
Training loss: 3.7153222450772185
Validation loss: 2.5587649433020587

Epoch: 5| Step: 9
Training loss: 2.8679685438338423
Validation loss: 2.566572099719315

Epoch: 5| Step: 10
Training loss: 2.749524855747452
Validation loss: 2.563750248406991

Epoch: 110| Step: 0
Training loss: 2.9584620452246244
Validation loss: 2.573871472915977

Epoch: 5| Step: 1
Training loss: 2.6666024816259037
Validation loss: 2.5917634587895146

Epoch: 5| Step: 2
Training loss: 2.6213085922219723
Validation loss: 2.5800683138878795

Epoch: 5| Step: 3
Training loss: 2.8050688162945216
Validation loss: 2.5748529965104563

Epoch: 5| Step: 4
Training loss: 2.6608098105292752
Validation loss: 2.5775554128466927

Epoch: 5| Step: 5
Training loss: 3.4035042711670775
Validation loss: 2.567366218668511

Epoch: 5| Step: 6
Training loss: 2.806147458384363
Validation loss: 2.565901059215311

Epoch: 5| Step: 7
Training loss: 3.17140878342257
Validation loss: 2.5582776852989824

Epoch: 5| Step: 8
Training loss: 3.5349524339122262
Validation loss: 2.563212820053824

Epoch: 5| Step: 9
Training loss: 2.618412471314266
Validation loss: 2.5555398299497427

Epoch: 5| Step: 10
Training loss: 2.537878329631983
Validation loss: 2.551173533204461

Epoch: 111| Step: 0
Training loss: 2.6129883743185176
Validation loss: 2.549528823823622

Epoch: 5| Step: 1
Training loss: 2.6776102539499855
Validation loss: 2.553032495934504

Epoch: 5| Step: 2
Training loss: 3.0363616317260638
Validation loss: 2.5447133559907673

Epoch: 5| Step: 3
Training loss: 3.137449262596323
Validation loss: 2.55327606121786

Epoch: 5| Step: 4
Training loss: 2.6660537213967643
Validation loss: 2.551050580833023

Epoch: 5| Step: 5
Training loss: 3.290740466288292
Validation loss: 2.556660344768907

Epoch: 5| Step: 6
Training loss: 2.9139006623437465
Validation loss: 2.5583640585304885

Epoch: 5| Step: 7
Training loss: 3.0861258533795977
Validation loss: 2.5677437671992984

Epoch: 5| Step: 8
Training loss: 3.225316137151568
Validation loss: 2.5770305171095873

Epoch: 5| Step: 9
Training loss: 2.623563282480561
Validation loss: 2.583297411350996

Epoch: 5| Step: 10
Training loss: 2.5236855021865408
Validation loss: 2.572520284587186

Epoch: 112| Step: 0
Training loss: 3.0589657066495546
Validation loss: 2.563812080017625

Epoch: 5| Step: 1
Training loss: 2.405718658043312
Validation loss: 2.5743251238723763

Epoch: 5| Step: 2
Training loss: 2.901117530438062
Validation loss: 2.5650589664054557

Epoch: 5| Step: 3
Training loss: 2.4074117655048974
Validation loss: 2.556601418647415

Epoch: 5| Step: 4
Training loss: 2.696053135051133
Validation loss: 2.558111358960811

Epoch: 5| Step: 5
Training loss: 3.202370457050441
Validation loss: 2.556165593918972

Epoch: 5| Step: 6
Training loss: 3.4399509362115155
Validation loss: 2.5582287875420957

Epoch: 5| Step: 7
Training loss: 2.5945825734241263
Validation loss: 2.569343878346571

Epoch: 5| Step: 8
Training loss: 2.9643358039235115
Validation loss: 2.5589785306183703

Epoch: 5| Step: 9
Training loss: 3.3407239679819436
Validation loss: 2.5654541153365065

Epoch: 5| Step: 10
Training loss: 2.6319949185226688
Validation loss: 2.559807622296024

Epoch: 113| Step: 0
Training loss: 2.867718307047298
Validation loss: 2.5618249647857763

Epoch: 5| Step: 1
Training loss: 3.1492797633671894
Validation loss: 2.573879151760164

Epoch: 5| Step: 2
Training loss: 3.448246197737331
Validation loss: 2.5702758521140314

Epoch: 5| Step: 3
Training loss: 3.337328011299591
Validation loss: 2.571966487950008

Epoch: 5| Step: 4
Training loss: 2.8933656639132748
Validation loss: 2.5692970316368027

Epoch: 5| Step: 5
Training loss: 2.6938732782818344
Validation loss: 2.5688288808161057

Epoch: 5| Step: 6
Training loss: 2.2898137549079243
Validation loss: 2.5664770886017427

Epoch: 5| Step: 7
Training loss: 3.0490112640683256
Validation loss: 2.570554827889626

Epoch: 5| Step: 8
Training loss: 2.672454325015343
Validation loss: 2.559539892020553

Epoch: 5| Step: 9
Training loss: 2.9654109447474606
Validation loss: 2.555874448467253

Epoch: 5| Step: 10
Training loss: 2.251571000855472
Validation loss: 2.5546767976011164

Epoch: 114| Step: 0
Training loss: 3.16476892191224
Validation loss: 2.5599382673003017

Epoch: 5| Step: 1
Training loss: 2.5750886550011676
Validation loss: 2.5564552300762955

Epoch: 5| Step: 2
Training loss: 2.880583607034217
Validation loss: 2.558403446297224

Epoch: 5| Step: 3
Training loss: 2.572547103554394
Validation loss: 2.563482638881687

Epoch: 5| Step: 4
Training loss: 2.907224594284688
Validation loss: 2.573884423699982

Epoch: 5| Step: 5
Training loss: 2.771486009485732
Validation loss: 2.5654407672439916

Epoch: 5| Step: 6
Training loss: 3.0363613176414845
Validation loss: 2.550422893414127

Epoch: 5| Step: 7
Training loss: 3.0803255067705315
Validation loss: 2.5517327662850393

Epoch: 5| Step: 8
Training loss: 2.978450466756559
Validation loss: 2.5458041774210143

Epoch: 5| Step: 9
Training loss: 2.9071808011493347
Validation loss: 2.543769503810916

Epoch: 5| Step: 10
Training loss: 3.0595265180495557
Validation loss: 2.5418523861473727

Epoch: 115| Step: 0
Training loss: 2.2866971550883943
Validation loss: 2.547775218170123

Epoch: 5| Step: 1
Training loss: 2.9459146951521324
Validation loss: 2.5427213783872396

Epoch: 5| Step: 2
Training loss: 2.7973171289584955
Validation loss: 2.541586158670276

Epoch: 5| Step: 3
Training loss: 3.125054473402177
Validation loss: 2.539959014304813

Epoch: 5| Step: 4
Training loss: 3.0731210069550907
Validation loss: 2.541890299087148

Epoch: 5| Step: 5
Training loss: 2.9843972090448987
Validation loss: 2.549383861767277

Epoch: 5| Step: 6
Training loss: 3.25848015912138
Validation loss: 2.573097464443405

Epoch: 5| Step: 7
Training loss: 3.043946879009863
Validation loss: 2.5758974795776353

Epoch: 5| Step: 8
Training loss: 2.940311304076555
Validation loss: 2.5714989866125304

Epoch: 5| Step: 9
Training loss: 2.17543089972005
Validation loss: 2.568414260388234

Epoch: 5| Step: 10
Training loss: 3.0671183737195737
Validation loss: 2.5711426630913627

Epoch: 116| Step: 0
Training loss: 2.88760317002976
Validation loss: 2.564373093115125

Epoch: 5| Step: 1
Training loss: 3.03593444667001
Validation loss: 2.5624028149175406

Epoch: 5| Step: 2
Training loss: 2.8626946528854904
Validation loss: 2.5527983664342213

Epoch: 5| Step: 3
Training loss: 2.9537399701219793
Validation loss: 2.5549245709737987

Epoch: 5| Step: 4
Training loss: 2.9888436779241054
Validation loss: 2.547649099566837

Epoch: 5| Step: 5
Training loss: 2.5162222017135125
Validation loss: 2.5555983461863994

Epoch: 5| Step: 6
Training loss: 2.708063454508594
Validation loss: 2.5581801443948797

Epoch: 5| Step: 7
Training loss: 3.39512764242731
Validation loss: 2.5572694438679426

Epoch: 5| Step: 8
Training loss: 3.1908781812386513
Validation loss: 2.5501615999085767

Epoch: 5| Step: 9
Training loss: 2.6543886731619484
Validation loss: 2.5492676136592225

Epoch: 5| Step: 10
Training loss: 2.405868698228404
Validation loss: 2.5518992381260723

Epoch: 117| Step: 0
Training loss: 2.7170809303167376
Validation loss: 2.546693375784622

Epoch: 5| Step: 1
Training loss: 3.0387306326370966
Validation loss: 2.5509141381311955

Epoch: 5| Step: 2
Training loss: 3.2613974041741836
Validation loss: 2.5465734179823794

Epoch: 5| Step: 3
Training loss: 2.2636864096411076
Validation loss: 2.5402136660014105

Epoch: 5| Step: 4
Training loss: 3.109335127531726
Validation loss: 2.548178401618052

Epoch: 5| Step: 5
Training loss: 2.928330252017414
Validation loss: 2.5528517978520675

Epoch: 5| Step: 6
Training loss: 2.833958295075123
Validation loss: 2.554734258872017

Epoch: 5| Step: 7
Training loss: 3.060937288137276
Validation loss: 2.558097252497089

Epoch: 5| Step: 8
Training loss: 2.215369644837864
Validation loss: 2.5531900349779555

Epoch: 5| Step: 9
Training loss: 2.973167104849947
Validation loss: 2.5688827472363953

Epoch: 5| Step: 10
Training loss: 3.195330407575126
Validation loss: 2.5605128837545643

Epoch: 118| Step: 0
Training loss: 2.653459856269129
Validation loss: 2.568996167306994

Epoch: 5| Step: 1
Training loss: 2.663302315908134
Validation loss: 2.572553323936318

Epoch: 5| Step: 2
Training loss: 2.503663811573806
Validation loss: 2.5689003352123123

Epoch: 5| Step: 3
Training loss: 3.1242899278725336
Validation loss: 2.593492529007934

Epoch: 5| Step: 4
Training loss: 3.040258490966604
Validation loss: 2.558694259897513

Epoch: 5| Step: 5
Training loss: 2.527588444793266
Validation loss: 2.5649990378603915

Epoch: 5| Step: 6
Training loss: 2.727505059171997
Validation loss: 2.56182440438882

Epoch: 5| Step: 7
Training loss: 3.2523167495651393
Validation loss: 2.5504140266832747

Epoch: 5| Step: 8
Training loss: 2.6610826400086802
Validation loss: 2.544887486678491

Epoch: 5| Step: 9
Training loss: 3.1539367659186013
Validation loss: 2.5394049179616

Epoch: 5| Step: 10
Training loss: 3.337828339274046
Validation loss: 2.542671357731684

Epoch: 119| Step: 0
Training loss: 2.8550662736833314
Validation loss: 2.545785995858831

Epoch: 5| Step: 1
Training loss: 2.764684398636879
Validation loss: 2.552568439706548

Epoch: 5| Step: 2
Training loss: 2.9533717138180338
Validation loss: 2.560905783000991

Epoch: 5| Step: 3
Training loss: 2.843488408727281
Validation loss: 2.5750004324438263

Epoch: 5| Step: 4
Training loss: 3.106617994404716
Validation loss: 2.5707577535635227

Epoch: 5| Step: 5
Training loss: 2.851723360723938
Validation loss: 2.5846893804984763

Epoch: 5| Step: 6
Training loss: 2.808779311118425
Validation loss: 2.600837618110148

Epoch: 5| Step: 7
Training loss: 2.483526504820612
Validation loss: 2.6018653059531487

Epoch: 5| Step: 8
Training loss: 3.058405727877431
Validation loss: 2.589910920565908

Epoch: 5| Step: 9
Training loss: 3.0776735545972045
Validation loss: 2.5814120550994284

Epoch: 5| Step: 10
Training loss: 2.8886329178830152
Validation loss: 2.5796390019501914

Epoch: 120| Step: 0
Training loss: 2.73342591299495
Validation loss: 2.5668090817824947

Epoch: 5| Step: 1
Training loss: 2.8059098069370525
Validation loss: 2.5573300758342654

Epoch: 5| Step: 2
Training loss: 3.0018238245779365
Validation loss: 2.542935036933421

Epoch: 5| Step: 3
Training loss: 2.9315589725679327
Validation loss: 2.5352443473279633

Epoch: 5| Step: 4
Training loss: 2.77798467395419
Validation loss: 2.529832096716814

Epoch: 5| Step: 5
Training loss: 2.9337751431519377
Validation loss: 2.530448764482161

Epoch: 5| Step: 6
Training loss: 3.0526297191953446
Validation loss: 2.5280427514019688

Epoch: 5| Step: 7
Training loss: 3.298470495249613
Validation loss: 2.5262150936557886

Epoch: 5| Step: 8
Training loss: 2.92369390165568
Validation loss: 2.5256085015008742

Epoch: 5| Step: 9
Training loss: 2.3502978602814277
Validation loss: 2.5250643785819014

Epoch: 5| Step: 10
Training loss: 2.826111471905477
Validation loss: 2.5275786520604595

Epoch: 121| Step: 0
Training loss: 2.9812439476607526
Validation loss: 2.526612270105828

Epoch: 5| Step: 1
Training loss: 2.6344762237396844
Validation loss: 2.5294982954119085

Epoch: 5| Step: 2
Training loss: 2.8742948579575054
Validation loss: 2.5324177430396806

Epoch: 5| Step: 3
Training loss: 3.007815512123086
Validation loss: 2.526680156738744

Epoch: 5| Step: 4
Training loss: 2.5961882379758974
Validation loss: 2.5317768109299656

Epoch: 5| Step: 5
Training loss: 3.026492130719915
Validation loss: 2.5354768051187664

Epoch: 5| Step: 6
Training loss: 3.343197928514133
Validation loss: 2.541168731646883

Epoch: 5| Step: 7
Training loss: 3.013647508306386
Validation loss: 2.537802187338986

Epoch: 5| Step: 8
Training loss: 2.4756718426909634
Validation loss: 2.543901247589982

Epoch: 5| Step: 9
Training loss: 2.3919852382434064
Validation loss: 2.5492717518566392

Epoch: 5| Step: 10
Training loss: 3.237200106719513
Validation loss: 2.5568746162335834

Epoch: 122| Step: 0
Training loss: 2.7936279372617543
Validation loss: 2.575633451308762

Epoch: 5| Step: 1
Training loss: 3.1987669536086143
Validation loss: 2.6066481684229363

Epoch: 5| Step: 2
Training loss: 3.056299121048491
Validation loss: 2.6419910369049315

Epoch: 5| Step: 3
Training loss: 3.0035851037796437
Validation loss: 2.6448817972089333

Epoch: 5| Step: 4
Training loss: 2.538795058030421
Validation loss: 2.5776571078554964

Epoch: 5| Step: 5
Training loss: 1.8013031507349835
Validation loss: 2.539123749479334

Epoch: 5| Step: 6
Training loss: 3.2788574215114306
Validation loss: 2.527753527010851

Epoch: 5| Step: 7
Training loss: 2.8996377192492626
Validation loss: 2.5242967020676303

Epoch: 5| Step: 8
Training loss: 3.0647761391663053
Validation loss: 2.530565391822391

Epoch: 5| Step: 9
Training loss: 2.733943447390427
Validation loss: 2.533235691447021

Epoch: 5| Step: 10
Training loss: 3.283216631859858
Validation loss: 2.54042748802523

Epoch: 123| Step: 0
Training loss: 2.615926683681749
Validation loss: 2.5267629632379403

Epoch: 5| Step: 1
Training loss: 3.1770494469675103
Validation loss: 2.5361680715869706

Epoch: 5| Step: 2
Training loss: 3.4832071990275604
Validation loss: 2.530816133547068

Epoch: 5| Step: 3
Training loss: 2.3250372975957143
Validation loss: 2.5273822761770757

Epoch: 5| Step: 4
Training loss: 3.103408533148771
Validation loss: 2.524959859708673

Epoch: 5| Step: 5
Training loss: 2.9723960572108914
Validation loss: 2.5216430259316316

Epoch: 5| Step: 6
Training loss: 2.494707800318941
Validation loss: 2.530770413749387

Epoch: 5| Step: 7
Training loss: 2.8422243825774856
Validation loss: 2.539454530500269

Epoch: 5| Step: 8
Training loss: 2.5538439743370325
Validation loss: 2.5496518621476354

Epoch: 5| Step: 9
Training loss: 3.1672528042339363
Validation loss: 2.561646481163566

Epoch: 5| Step: 10
Training loss: 2.803144705372488
Validation loss: 2.5634065950673013

Epoch: 124| Step: 0
Training loss: 2.998692068452332
Validation loss: 2.551939375640482

Epoch: 5| Step: 1
Training loss: 2.8979783015732123
Validation loss: 2.5519884150024774

Epoch: 5| Step: 2
Training loss: 2.370885899591766
Validation loss: 2.5548350380092413

Epoch: 5| Step: 3
Training loss: 3.131964133445803
Validation loss: 2.547340266518986

Epoch: 5| Step: 4
Training loss: 3.0544486574424767
Validation loss: 2.549305637557789

Epoch: 5| Step: 5
Training loss: 3.228228196805395
Validation loss: 2.5390589206818626

Epoch: 5| Step: 6
Training loss: 2.212439791619869
Validation loss: 2.53553161112476

Epoch: 5| Step: 7
Training loss: 3.0144235065503424
Validation loss: 2.532009586560829

Epoch: 5| Step: 8
Training loss: 2.68864718061039
Validation loss: 2.5271284516937054

Epoch: 5| Step: 9
Training loss: 3.1022086059061382
Validation loss: 2.5202836451207915

Epoch: 5| Step: 10
Training loss: 2.7758913172408346
Validation loss: 2.5247643006110425

Epoch: 125| Step: 0
Training loss: 2.3342823301251756
Validation loss: 2.52655890780326

Epoch: 5| Step: 1
Training loss: 3.115580591556789
Validation loss: 2.525527407167214

Epoch: 5| Step: 2
Training loss: 2.8657785222686503
Validation loss: 2.5390845553542194

Epoch: 5| Step: 3
Training loss: 2.7792263598420197
Validation loss: 2.5362063575826386

Epoch: 5| Step: 4
Training loss: 2.642504773528119
Validation loss: 2.548602107123601

Epoch: 5| Step: 5
Training loss: 2.5538308110010464
Validation loss: 2.544611283359653

Epoch: 5| Step: 6
Training loss: 3.3307066740937334
Validation loss: 2.54371659919406

Epoch: 5| Step: 7
Training loss: 3.1522670580529253
Validation loss: 2.545351927010803

Epoch: 5| Step: 8
Training loss: 2.82929201443002
Validation loss: 2.546814403999586

Epoch: 5| Step: 9
Training loss: 3.0422548918467256
Validation loss: 2.55526893764946

Epoch: 5| Step: 10
Training loss: 2.7901273345602533
Validation loss: 2.5421443801606163

Testing loss: 2.6879666635443034
