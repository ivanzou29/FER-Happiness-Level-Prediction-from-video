Epoch: 1| Step: 0
Training loss: 6.081163759786431
Validation loss: 5.833983090100082

Epoch: 5| Step: 1
Training loss: 5.972697126249921
Validation loss: 5.8050865966146645

Epoch: 5| Step: 2
Training loss: 6.631813432376959
Validation loss: 5.78265085761341

Epoch: 5| Step: 3
Training loss: 5.390508943497068
Validation loss: 5.762041625939991

Epoch: 5| Step: 4
Training loss: 5.989685411550902
Validation loss: 5.7382079145962885

Epoch: 5| Step: 5
Training loss: 5.824921492018892
Validation loss: 5.710926550417321

Epoch: 5| Step: 6
Training loss: 4.976220039789179
Validation loss: 5.6787345779577665

Epoch: 5| Step: 7
Training loss: 6.02846957141986
Validation loss: 5.641203241788778

Epoch: 5| Step: 8
Training loss: 5.992177950815403
Validation loss: 5.5984576712623

Epoch: 5| Step: 9
Training loss: 5.323014031382587
Validation loss: 5.549668876469004

Epoch: 5| Step: 10
Training loss: 4.399167042697477
Validation loss: 5.49380014145081

Epoch: 2| Step: 0
Training loss: 5.135643304720482
Validation loss: 5.433852014345515

Epoch: 5| Step: 1
Training loss: 5.345041933100391
Validation loss: 5.365845795020764

Epoch: 5| Step: 2
Training loss: 5.284304486057478
Validation loss: 5.292420970177832

Epoch: 5| Step: 3
Training loss: 5.286607722033576
Validation loss: 5.213905965497832

Epoch: 5| Step: 4
Training loss: 4.938682897329609
Validation loss: 5.132792761255847

Epoch: 5| Step: 5
Training loss: 5.754596034371033
Validation loss: 5.046997920166523

Epoch: 5| Step: 6
Training loss: 4.299268465137662
Validation loss: 4.957023200719446

Epoch: 5| Step: 7
Training loss: 5.061944436566035
Validation loss: 4.8683547992055205

Epoch: 5| Step: 8
Training loss: 3.999526353449983
Validation loss: 4.772574201385296

Epoch: 5| Step: 9
Training loss: 5.13805680053723
Validation loss: 4.68023201757075

Epoch: 5| Step: 10
Training loss: 5.659183984710404
Validation loss: 4.59030120126941

Epoch: 3| Step: 0
Training loss: 4.824793187586232
Validation loss: 4.505574591598016

Epoch: 5| Step: 1
Training loss: 4.609468931113898
Validation loss: 4.4269694273722004

Epoch: 5| Step: 2
Training loss: 3.9620427201734576
Validation loss: 4.354247077395268

Epoch: 5| Step: 3
Training loss: 3.6598756208287355
Validation loss: 4.287658760553786

Epoch: 5| Step: 4
Training loss: 3.6170183640684352
Validation loss: 4.229967674407832

Epoch: 5| Step: 5
Training loss: 4.857137772212853
Validation loss: 4.18123114372686

Epoch: 5| Step: 6
Training loss: 3.905644484318897
Validation loss: 4.135199259679917

Epoch: 5| Step: 7
Training loss: 4.398088837757224
Validation loss: 4.098947048764585

Epoch: 5| Step: 8
Training loss: 4.589712847202469
Validation loss: 4.067618397646029

Epoch: 5| Step: 9
Training loss: 4.548810304481517
Validation loss: 4.036434395117406

Epoch: 5| Step: 10
Training loss: 4.583051198887699
Validation loss: 4.010167277327058

Epoch: 4| Step: 0
Training loss: 4.838329013494459
Validation loss: 3.981906574869045

Epoch: 5| Step: 1
Training loss: 3.8976119090341492
Validation loss: 3.941487853114268

Epoch: 5| Step: 2
Training loss: 2.972535781324161
Validation loss: 3.904473819658777

Epoch: 5| Step: 3
Training loss: 4.861730660815194
Validation loss: 3.8902209324506236

Epoch: 5| Step: 4
Training loss: 4.127639619532615
Validation loss: 3.870916875595612

Epoch: 5| Step: 5
Training loss: 3.776084461188895
Validation loss: 3.845415043018114

Epoch: 5| Step: 6
Training loss: 3.2438009269112333
Validation loss: 3.8214821392996834

Epoch: 5| Step: 7
Training loss: 3.830821803995812
Validation loss: 3.807244829035901

Epoch: 5| Step: 8
Training loss: 4.195469347190239
Validation loss: 3.7798755072742054

Epoch: 5| Step: 9
Training loss: 3.521191475313825
Validation loss: 3.7581131652192843

Epoch: 5| Step: 10
Training loss: 4.58359073725293
Validation loss: 3.7339557212045644

Epoch: 5| Step: 0
Training loss: 3.244577432400674
Validation loss: 3.7135926108688784

Epoch: 5| Step: 1
Training loss: 3.350991936337278
Validation loss: 3.691875066902453

Epoch: 5| Step: 2
Training loss: 3.708704740520059
Validation loss: 3.670634420885842

Epoch: 5| Step: 3
Training loss: 4.234283784116118
Validation loss: 3.655207700401456

Epoch: 5| Step: 4
Training loss: 3.9773899259267718
Validation loss: 3.632433331148509

Epoch: 5| Step: 5
Training loss: 4.045333509806874
Validation loss: 3.6187281086849477

Epoch: 5| Step: 6
Training loss: 3.63760840395344
Validation loss: 3.6039007713447466

Epoch: 5| Step: 7
Training loss: 3.8810822528948483
Validation loss: 3.591256672155723

Epoch: 5| Step: 8
Training loss: 3.43549885155108
Validation loss: 3.575769053185932

Epoch: 5| Step: 9
Training loss: 4.355814693380149
Validation loss: 3.564584222760397

Epoch: 5| Step: 10
Training loss: 3.992752184561949
Validation loss: 3.550438439648189

Epoch: 6| Step: 0
Training loss: 4.15236625772945
Validation loss: 3.533281966230925

Epoch: 5| Step: 1
Training loss: 4.068401334622195
Validation loss: 3.5218362435020016

Epoch: 5| Step: 2
Training loss: 3.9460107770831603
Validation loss: 3.5090776612955734

Epoch: 5| Step: 3
Training loss: 3.240310750823423
Validation loss: 3.495734840311999

Epoch: 5| Step: 4
Training loss: 3.596802319174321
Validation loss: 3.485422837767451

Epoch: 5| Step: 5
Training loss: 3.8408085182487994
Validation loss: 3.4775628474286857

Epoch: 5| Step: 6
Training loss: 2.9034196751307797
Validation loss: 3.4655676140386418

Epoch: 5| Step: 7
Training loss: 3.5964606635558236
Validation loss: 3.4575892237348507

Epoch: 5| Step: 8
Training loss: 3.6031596517095945
Validation loss: 3.4465314338278796

Epoch: 5| Step: 9
Training loss: 4.281604167461791
Validation loss: 3.441556410207903

Epoch: 5| Step: 10
Training loss: 3.1297088241422033
Validation loss: 3.42757145065836

Epoch: 7| Step: 0
Training loss: 2.863473924760909
Validation loss: 3.4184909355335704

Epoch: 5| Step: 1
Training loss: 3.4731878811284003
Validation loss: 3.4110360729730664

Epoch: 5| Step: 2
Training loss: 3.9529683078274216
Validation loss: 3.403603187643673

Epoch: 5| Step: 3
Training loss: 3.123965588076059
Validation loss: 3.390117385162408

Epoch: 5| Step: 4
Training loss: 3.305000164130087
Validation loss: 3.379892676017769

Epoch: 5| Step: 5
Training loss: 3.8812854611655
Validation loss: 3.3712523620833963

Epoch: 5| Step: 6
Training loss: 4.154612512618341
Validation loss: 3.360888239477981

Epoch: 5| Step: 7
Training loss: 3.8689908841622977
Validation loss: 3.351425855383729

Epoch: 5| Step: 8
Training loss: 3.37354713533886
Validation loss: 3.3455193597250212

Epoch: 5| Step: 9
Training loss: 3.6395617066068175
Validation loss: 3.342612016830152

Epoch: 5| Step: 10
Training loss: 3.805707289616894
Validation loss: 3.327438119537719

Epoch: 8| Step: 0
Training loss: 2.4863133576127634
Validation loss: 3.3198415315315133

Epoch: 5| Step: 1
Training loss: 3.674684399398221
Validation loss: 3.3115163353716732

Epoch: 5| Step: 2
Training loss: 3.7208167992395724
Validation loss: 3.3036735315540398

Epoch: 5| Step: 3
Training loss: 4.220097531461664
Validation loss: 3.2956847877910533

Epoch: 5| Step: 4
Training loss: 4.008854602273319
Validation loss: 3.289206930953857

Epoch: 5| Step: 5
Training loss: 3.757072391709131
Validation loss: 3.2785511783962478

Epoch: 5| Step: 6
Training loss: 3.039051359886796
Validation loss: 3.274146276583649

Epoch: 5| Step: 7
Training loss: 3.670702288421409
Validation loss: 3.2658885227930345

Epoch: 5| Step: 8
Training loss: 2.6601698730836927
Validation loss: 3.254428707882766

Epoch: 5| Step: 9
Training loss: 3.064274799125507
Validation loss: 3.24776600934366

Epoch: 5| Step: 10
Training loss: 4.136969338122466
Validation loss: 3.241615018921642

Epoch: 9| Step: 0
Training loss: 3.2367592100302764
Validation loss: 3.2340483149500248

Epoch: 5| Step: 1
Training loss: 3.340617200737066
Validation loss: 3.2308774805784677

Epoch: 5| Step: 2
Training loss: 3.769904020387921
Validation loss: 3.22732383999968

Epoch: 5| Step: 3
Training loss: 3.4218716556062425
Validation loss: 3.2144820401911818

Epoch: 5| Step: 4
Training loss: 3.4324650737544213
Validation loss: 3.21650860604412

Epoch: 5| Step: 5
Training loss: 2.4191645067472294
Validation loss: 3.209651267743417

Epoch: 5| Step: 6
Training loss: 3.9907172494858916
Validation loss: 3.2034057382111003

Epoch: 5| Step: 7
Training loss: 3.2198025362112475
Validation loss: 3.1943040821994066

Epoch: 5| Step: 8
Training loss: 3.7884932572162704
Validation loss: 3.1889323451218656

Epoch: 5| Step: 9
Training loss: 3.5900097830381426
Validation loss: 3.1888063356953404

Epoch: 5| Step: 10
Training loss: 3.699005926469323
Validation loss: 3.1800459055348496

Epoch: 10| Step: 0
Training loss: 3.703648011177391
Validation loss: 3.1711660364983483

Epoch: 5| Step: 1
Training loss: 3.576496403301302
Validation loss: 3.166275897847573

Epoch: 5| Step: 2
Training loss: 3.201160256328061
Validation loss: 3.165154052651839

Epoch: 5| Step: 3
Training loss: 3.1783657466660564
Validation loss: 3.158071380054385

Epoch: 5| Step: 4
Training loss: 3.6395007841243285
Validation loss: 3.152127955104554

Epoch: 5| Step: 5
Training loss: 2.8084155624380083
Validation loss: 3.1501203024725664

Epoch: 5| Step: 6
Training loss: 3.588319606397436
Validation loss: 3.156526296586608

Epoch: 5| Step: 7
Training loss: 3.7122147781290837
Validation loss: 3.139822064495818

Epoch: 5| Step: 8
Training loss: 2.8361227852480098
Validation loss: 3.138195993324897

Epoch: 5| Step: 9
Training loss: 3.6987612480670657
Validation loss: 3.137308171520769

Epoch: 5| Step: 10
Training loss: 3.5490412209858646
Validation loss: 3.1346071720695634

Epoch: 11| Step: 0
Training loss: 3.1972272960343817
Validation loss: 3.127010884721601

Epoch: 5| Step: 1
Training loss: 3.515432666179845
Validation loss: 3.1221235626387807

Epoch: 5| Step: 2
Training loss: 3.8492441996063493
Validation loss: 3.1189149255349657

Epoch: 5| Step: 3
Training loss: 2.741756220536677
Validation loss: 3.1196448647160486

Epoch: 5| Step: 4
Training loss: 4.185840790397862
Validation loss: 3.1193503618041207

Epoch: 5| Step: 5
Training loss: 3.30386421644128
Validation loss: 3.1104632747864267

Epoch: 5| Step: 6
Training loss: 3.5224927494145017
Validation loss: 3.106686597415382

Epoch: 5| Step: 7
Training loss: 3.58203763971622
Validation loss: 3.1068438478487734

Epoch: 5| Step: 8
Training loss: 3.7790446510230953
Validation loss: 3.104678047795367

Epoch: 5| Step: 9
Training loss: 2.7323566944345568
Validation loss: 3.1019811827322776

Epoch: 5| Step: 10
Training loss: 2.271833555323647
Validation loss: 3.0938993210574255

Epoch: 12| Step: 0
Training loss: 3.4192773722547116
Validation loss: 3.08794631425742

Epoch: 5| Step: 1
Training loss: 3.5352379889548886
Validation loss: 3.0839563292998524

Epoch: 5| Step: 2
Training loss: 3.4581382573885557
Validation loss: 3.0807406015488765

Epoch: 5| Step: 3
Training loss: 3.379546035437252
Validation loss: 3.07974413957673

Epoch: 5| Step: 4
Training loss: 3.6493624509245137
Validation loss: 3.072702967222877

Epoch: 5| Step: 5
Training loss: 3.675242855844832
Validation loss: 3.071586750472673

Epoch: 5| Step: 6
Training loss: 3.3990174949579584
Validation loss: 3.0687258481253474

Epoch: 5| Step: 7
Training loss: 2.6792385959807903
Validation loss: 3.064369320091973

Epoch: 5| Step: 8
Training loss: 3.258512938509616
Validation loss: 3.0602050211715914

Epoch: 5| Step: 9
Training loss: 2.942335004953051
Validation loss: 3.0591184871369133

Epoch: 5| Step: 10
Training loss: 3.417507920943194
Validation loss: 3.0574427157510926

Epoch: 13| Step: 0
Training loss: 3.8021128753489855
Validation loss: 3.0562106358487564

Epoch: 5| Step: 1
Training loss: 3.6559119435062812
Validation loss: 3.0529764838219577

Epoch: 5| Step: 2
Training loss: 3.37762278618113
Validation loss: 3.049167428845074

Epoch: 5| Step: 3
Training loss: 3.347831445514132
Validation loss: 3.045314761866277

Epoch: 5| Step: 4
Training loss: 2.92820909963564
Validation loss: 3.043236301494746

Epoch: 5| Step: 5
Training loss: 2.9575314218459376
Validation loss: 3.039316502227975

Epoch: 5| Step: 6
Training loss: 3.066565170543491
Validation loss: 3.0380402789792376

Epoch: 5| Step: 7
Training loss: 3.6633648889470884
Validation loss: 3.0358826420048133

Epoch: 5| Step: 8
Training loss: 2.8299894983750535
Validation loss: 3.0332363746920494

Epoch: 5| Step: 9
Training loss: 3.275006994574845
Validation loss: 3.0304048571766495

Epoch: 5| Step: 10
Training loss: 3.6531332702804162
Validation loss: 3.027937694429646

Epoch: 14| Step: 0
Training loss: 2.8177382114445733
Validation loss: 3.026943002587274

Epoch: 5| Step: 1
Training loss: 3.706652285275816
Validation loss: 3.024845783245437

Epoch: 5| Step: 2
Training loss: 3.8256632460471165
Validation loss: 3.0225387687004726

Epoch: 5| Step: 3
Training loss: 3.259041314311789
Validation loss: 3.0203814894558287

Epoch: 5| Step: 4
Training loss: 3.2646246295030026
Validation loss: 3.021108839366266

Epoch: 5| Step: 5
Training loss: 3.3084174855737443
Validation loss: 3.0123423143667742

Epoch: 5| Step: 6
Training loss: 3.312020465041249
Validation loss: 3.012606755814546

Epoch: 5| Step: 7
Training loss: 2.5069919087386294
Validation loss: 3.006346084218656

Epoch: 5| Step: 8
Training loss: 3.595146637580048
Validation loss: 3.0019517031048233

Epoch: 5| Step: 9
Training loss: 3.4179432197707236
Validation loss: 2.9986962028406867

Epoch: 5| Step: 10
Training loss: 3.1823272619842484
Validation loss: 2.993454274672447

Epoch: 15| Step: 0
Training loss: 3.526769039949316
Validation loss: 2.9933363173853365

Epoch: 5| Step: 1
Training loss: 3.2502852094656394
Validation loss: 2.9951007705256147

Epoch: 5| Step: 2
Training loss: 2.9458478446146206
Validation loss: 2.993591029970371

Epoch: 5| Step: 3
Training loss: 3.0331858323114593
Validation loss: 2.9872691106405367

Epoch: 5| Step: 4
Training loss: 3.452013898545241
Validation loss: 2.9826618868433306

Epoch: 5| Step: 5
Training loss: 3.6027659228177313
Validation loss: 2.9890957277799184

Epoch: 5| Step: 6
Training loss: 3.4387702675613507
Validation loss: 3.0241603539945543

Epoch: 5| Step: 7
Training loss: 3.0860808906559587
Validation loss: 2.9812414126062787

Epoch: 5| Step: 8
Training loss: 3.5665051884209005
Validation loss: 2.975612332081713

Epoch: 5| Step: 9
Training loss: 2.975948400552581
Validation loss: 2.9749175137750394

Epoch: 5| Step: 10
Training loss: 3.235005487735109
Validation loss: 2.979432395708621

Epoch: 16| Step: 0
Training loss: 3.214191059959236
Validation loss: 2.9897752148374415

Epoch: 5| Step: 1
Training loss: 2.2102196272726498
Validation loss: 2.976573402006505

Epoch: 5| Step: 2
Training loss: 3.5669526499478814
Validation loss: 2.969801849741298

Epoch: 5| Step: 3
Training loss: 3.0241944304434196
Validation loss: 2.966469417769747

Epoch: 5| Step: 4
Training loss: 3.1520823544040395
Validation loss: 2.9628562397718827

Epoch: 5| Step: 5
Training loss: 3.1572973949582197
Validation loss: 2.9604917039079104

Epoch: 5| Step: 6
Training loss: 3.817719435664848
Validation loss: 2.9628656044647683

Epoch: 5| Step: 7
Training loss: 2.987418495247539
Validation loss: 2.951989384332936

Epoch: 5| Step: 8
Training loss: 4.007052879401558
Validation loss: 2.944778853181657

Epoch: 5| Step: 9
Training loss: 2.963365188644824
Validation loss: 2.9386411242568227

Epoch: 5| Step: 10
Training loss: 3.5487448179201113
Validation loss: 2.9350233561934482

Epoch: 17| Step: 0
Training loss: 3.318604656133131
Validation loss: 2.928682127911962

Epoch: 5| Step: 1
Training loss: 3.523513826951826
Validation loss: 2.9244692340239062

Epoch: 5| Step: 2
Training loss: 2.515541406984084
Validation loss: 2.921449956840398

Epoch: 5| Step: 3
Training loss: 2.8175342856269903
Validation loss: 2.9206066861037128

Epoch: 5| Step: 4
Training loss: 3.2712097599293495
Validation loss: 2.9175407529686637

Epoch: 5| Step: 5
Training loss: 3.1438571373219455
Validation loss: 2.918345639340904

Epoch: 5| Step: 6
Training loss: 3.3620092664927914
Validation loss: 2.9201621812442755

Epoch: 5| Step: 7
Training loss: 3.2867269673209614
Validation loss: 2.914392838964138

Epoch: 5| Step: 8
Training loss: 3.1840363177332076
Validation loss: 2.913409386356415

Epoch: 5| Step: 9
Training loss: 3.4411853801675245
Validation loss: 2.9077791479731103

Epoch: 5| Step: 10
Training loss: 3.661196110082323
Validation loss: 2.9097561979919537

Epoch: 18| Step: 0
Training loss: 3.594919296441132
Validation loss: 2.909267841227257

Epoch: 5| Step: 1
Training loss: 3.70456278127266
Validation loss: 2.9105741150335613

Epoch: 5| Step: 2
Training loss: 3.045071738264029
Validation loss: 2.9055046107454823

Epoch: 5| Step: 3
Training loss: 3.220989892336771
Validation loss: 2.9046537823525447

Epoch: 5| Step: 4
Training loss: 3.3393454375146345
Validation loss: 2.9024851311097914

Epoch: 5| Step: 5
Training loss: 2.843928069523564
Validation loss: 2.9002526483676094

Epoch: 5| Step: 6
Training loss: 2.663923064131877
Validation loss: 2.9027385812714024

Epoch: 5| Step: 7
Training loss: 3.3538396608791885
Validation loss: 2.9052479639933204

Epoch: 5| Step: 8
Training loss: 2.7682573969571735
Validation loss: 2.904494161944838

Epoch: 5| Step: 9
Training loss: 3.006157119807161
Validation loss: 2.8985672660135395

Epoch: 5| Step: 10
Training loss: 3.7829381784000486
Validation loss: 2.894361016488143

Epoch: 19| Step: 0
Training loss: 2.9987881120022526
Validation loss: 2.8960804108299

Epoch: 5| Step: 1
Training loss: 2.742473185294271
Validation loss: 2.907993405477385

Epoch: 5| Step: 2
Training loss: 2.521631119858468
Validation loss: 2.89575498387446

Epoch: 5| Step: 3
Training loss: 3.276790822323225
Validation loss: 2.898221564811546

Epoch: 5| Step: 4
Training loss: 3.0667741494071064
Validation loss: 2.898570325327837

Epoch: 5| Step: 5
Training loss: 3.6925717406125385
Validation loss: 2.9007456037748858

Epoch: 5| Step: 6
Training loss: 3.5878407864750965
Validation loss: 2.8983094317810547

Epoch: 5| Step: 7
Training loss: 3.4854001303442215
Validation loss: 2.891276726480173

Epoch: 5| Step: 8
Training loss: 3.7407270858971455
Validation loss: 2.8895274057594955

Epoch: 5| Step: 9
Training loss: 2.696570415248697
Validation loss: 2.8868621466850395

Epoch: 5| Step: 10
Training loss: 3.3000894938962806
Validation loss: 2.889955531239207

Epoch: 20| Step: 0
Training loss: 2.9905882064804152
Validation loss: 2.8925633736806944

Epoch: 5| Step: 1
Training loss: 3.1406444340194737
Validation loss: 2.898381543932959

Epoch: 5| Step: 2
Training loss: 3.7604353350372324
Validation loss: 2.8894553734092123

Epoch: 5| Step: 3
Training loss: 3.7955588740181194
Validation loss: 2.8878075329227495

Epoch: 5| Step: 4
Training loss: 3.675387257004714
Validation loss: 2.8833496703107633

Epoch: 5| Step: 5
Training loss: 2.673458321789578
Validation loss: 2.881240108658884

Epoch: 5| Step: 6
Training loss: 2.6447391400123714
Validation loss: 2.881411543527351

Epoch: 5| Step: 7
Training loss: 3.1605569894242436
Validation loss: 2.8796275821602264

Epoch: 5| Step: 8
Training loss: 2.994174865009293
Validation loss: 2.880108970434332

Epoch: 5| Step: 9
Training loss: 2.6412066659834292
Validation loss: 2.8803574739064803

Epoch: 5| Step: 10
Training loss: 3.5077627471589987
Validation loss: 2.8811478246989752

Epoch: 21| Step: 0
Training loss: 3.5314378266471182
Validation loss: 2.8782362466128584

Epoch: 5| Step: 1
Training loss: 3.4004239996028724
Validation loss: 2.875403585904215

Epoch: 5| Step: 2
Training loss: 3.017252112496364
Validation loss: 2.8735932381185996

Epoch: 5| Step: 3
Training loss: 3.4843424295177554
Validation loss: 2.875047505874815

Epoch: 5| Step: 4
Training loss: 2.994042521223853
Validation loss: 2.873425869118913

Epoch: 5| Step: 5
Training loss: 3.7844333332331965
Validation loss: 2.873104669161078

Epoch: 5| Step: 6
Training loss: 2.8306189231613605
Validation loss: 2.8730682206953997

Epoch: 5| Step: 7
Training loss: 3.096579750683607
Validation loss: 2.8703635104053267

Epoch: 5| Step: 8
Training loss: 2.959879260822553
Validation loss: 2.86939542564569

Epoch: 5| Step: 9
Training loss: 2.9008895496275247
Validation loss: 2.8699631961404863

Epoch: 5| Step: 10
Training loss: 2.888668738641384
Validation loss: 2.866041748254491

Epoch: 22| Step: 0
Training loss: 3.972834610287501
Validation loss: 2.9072079472920294

Epoch: 5| Step: 1
Training loss: 3.171543348290073
Validation loss: 2.8923402476995603

Epoch: 5| Step: 2
Training loss: 3.171048512386355
Validation loss: 2.867178388792734

Epoch: 5| Step: 3
Training loss: 3.2623160357878263
Validation loss: 2.891103885873255

Epoch: 5| Step: 4
Training loss: 3.289164272011413
Validation loss: 2.900624197210954

Epoch: 5| Step: 5
Training loss: 3.0448457660669352
Validation loss: 2.9036915429757832

Epoch: 5| Step: 6
Training loss: 3.04436714448583
Validation loss: 2.8845120123133303

Epoch: 5| Step: 7
Training loss: 3.0361544858907994
Validation loss: 2.8647053431744576

Epoch: 5| Step: 8
Training loss: 3.3192523295957566
Validation loss: 2.8609263421539555

Epoch: 5| Step: 9
Training loss: 2.7567746205931196
Validation loss: 2.894758238421163

Epoch: 5| Step: 10
Training loss: 2.905456926978751
Validation loss: 2.9239119073431175

Epoch: 23| Step: 0
Training loss: 3.2937297552597715
Validation loss: 3.0170661636134697

Epoch: 5| Step: 1
Training loss: 3.0889676825752224
Validation loss: 2.902171379459077

Epoch: 5| Step: 2
Training loss: 2.8822649510704155
Validation loss: 2.8562556093164946

Epoch: 5| Step: 3
Training loss: 3.042150659245022
Validation loss: 2.915242946936578

Epoch: 5| Step: 4
Training loss: 3.084064156464876
Validation loss: 2.944657345006186

Epoch: 5| Step: 5
Training loss: 3.321365584378325
Validation loss: 2.9032890760997496

Epoch: 5| Step: 6
Training loss: 3.8566083991930737
Validation loss: 2.8568746168193444

Epoch: 5| Step: 7
Training loss: 3.20423207573834
Validation loss: 2.8402448830901594

Epoch: 5| Step: 8
Training loss: 2.965924012170858
Validation loss: 2.8492466918864032

Epoch: 5| Step: 9
Training loss: 3.08325263940192
Validation loss: 2.8735525813353155

Epoch: 5| Step: 10
Training loss: 3.3865911862329794
Validation loss: 2.9174590275291044

Epoch: 24| Step: 0
Training loss: 3.8204646480039504
Validation loss: 3.0125956140321524

Epoch: 5| Step: 1
Training loss: 3.1878748654608313
Validation loss: 2.8798456343974252

Epoch: 5| Step: 2
Training loss: 3.064366141860237
Validation loss: 2.8395378978455956

Epoch: 5| Step: 3
Training loss: 3.784450469142588
Validation loss: 2.832930430068834

Epoch: 5| Step: 4
Training loss: 2.9784711190322426
Validation loss: 2.8383136231300448

Epoch: 5| Step: 5
Training loss: 2.6419084127464245
Validation loss: 2.8599830069332186

Epoch: 5| Step: 6
Training loss: 2.9034029233222607
Validation loss: 2.8784221445231264

Epoch: 5| Step: 7
Training loss: 3.7058479181037987
Validation loss: 2.9505174406550725

Epoch: 5| Step: 8
Training loss: 3.1954967939957335
Validation loss: 2.836340642551495

Epoch: 5| Step: 9
Training loss: 2.9844929137577973
Validation loss: 2.8265398634948316

Epoch: 5| Step: 10
Training loss: 2.481344425893372
Validation loss: 2.8626008244507046

Epoch: 25| Step: 0
Training loss: 3.2440985872690273
Validation loss: 2.946012424500131

Epoch: 5| Step: 1
Training loss: 3.025423408069638
Validation loss: 2.9428758013645955

Epoch: 5| Step: 2
Training loss: 3.024761058103295
Validation loss: 2.9620349311474143

Epoch: 5| Step: 3
Training loss: 2.8738004421006806
Validation loss: 2.8444148109970686

Epoch: 5| Step: 4
Training loss: 3.132445049854258
Validation loss: 2.8175606922727754

Epoch: 5| Step: 5
Training loss: 3.747391874599774
Validation loss: 2.822160707165671

Epoch: 5| Step: 6
Training loss: 3.6375003880241685
Validation loss: 2.8398387867309713

Epoch: 5| Step: 7
Training loss: 2.9007287852635826
Validation loss: 2.8510560781024497

Epoch: 5| Step: 8
Training loss: 2.8723268105775666
Validation loss: 2.877582125267762

Epoch: 5| Step: 9
Training loss: 3.4752286602506937
Validation loss: 2.89155791753339

Epoch: 5| Step: 10
Training loss: 2.9605577371279495
Validation loss: 2.8494744644403496

Epoch: 26| Step: 0
Training loss: 2.891900353420527
Validation loss: 2.8309036960162457

Epoch: 5| Step: 1
Training loss: 3.1379762933928466
Validation loss: 2.8207660576568077

Epoch: 5| Step: 2
Training loss: 2.932593448122364
Validation loss: 2.815700326309185

Epoch: 5| Step: 3
Training loss: 3.0938552684406724
Validation loss: 2.8118564603229026

Epoch: 5| Step: 4
Training loss: 3.6853033732324927
Validation loss: 2.809285964220177

Epoch: 5| Step: 5
Training loss: 3.356245135369496
Validation loss: 2.8091176083711864

Epoch: 5| Step: 6
Training loss: 2.8014715346946844
Validation loss: 2.818307345982026

Epoch: 5| Step: 7
Training loss: 3.3245186765676573
Validation loss: 2.8357538226894112

Epoch: 5| Step: 8
Training loss: 3.561711408101736
Validation loss: 2.929174397482185

Epoch: 5| Step: 9
Training loss: 2.330866179177422
Validation loss: 2.9626551301103974

Epoch: 5| Step: 10
Training loss: 3.4980275181799723
Validation loss: 2.9530752394516715

Epoch: 27| Step: 0
Training loss: 3.8151979749514613
Validation loss: 2.910788263686843

Epoch: 5| Step: 1
Training loss: 3.1274803998959606
Validation loss: 2.8681724733936877

Epoch: 5| Step: 2
Training loss: 3.172136718776456
Validation loss: 2.8653947222890435

Epoch: 5| Step: 3
Training loss: 2.7021482610340564
Validation loss: 2.858480011167327

Epoch: 5| Step: 4
Training loss: 3.3720174255554363
Validation loss: 2.8405407693402926

Epoch: 5| Step: 5
Training loss: 3.078525730131477
Validation loss: 2.831368207022456

Epoch: 5| Step: 6
Training loss: 3.1965534067094517
Validation loss: 2.8304422679956565

Epoch: 5| Step: 7
Training loss: 2.502612275035371
Validation loss: 2.8302669405685625

Epoch: 5| Step: 8
Training loss: 3.2310070249008276
Validation loss: 2.861146514055747

Epoch: 5| Step: 9
Training loss: 3.7191588874226684
Validation loss: 2.872951466137082

Epoch: 5| Step: 10
Training loss: 2.728170713061357
Validation loss: 2.827757969356078

Epoch: 28| Step: 0
Training loss: 3.462609982723445
Validation loss: 2.814104449755526

Epoch: 5| Step: 1
Training loss: 2.667904139528102
Validation loss: 2.8122643120204214

Epoch: 5| Step: 2
Training loss: 3.408393955080214
Validation loss: 2.815166364369369

Epoch: 5| Step: 3
Training loss: 3.192043581653116
Validation loss: 2.814992699243256

Epoch: 5| Step: 4
Training loss: 3.4843172487681824
Validation loss: 2.807750783002297

Epoch: 5| Step: 5
Training loss: 3.205034979809387
Validation loss: 2.7998651325542085

Epoch: 5| Step: 6
Training loss: 3.5362462170696283
Validation loss: 2.80716553461635

Epoch: 5| Step: 7
Training loss: 2.409596085949742
Validation loss: 2.799678843255557

Epoch: 5| Step: 8
Training loss: 2.8936893201361005
Validation loss: 2.8061820956486643

Epoch: 5| Step: 9
Training loss: 2.9531065925145557
Validation loss: 2.8292937659338553

Epoch: 5| Step: 10
Training loss: 3.106184966790065
Validation loss: 2.828694607722407

Epoch: 29| Step: 0
Training loss: 2.9775488313118696
Validation loss: 2.810243994743163

Epoch: 5| Step: 1
Training loss: 2.992299687844618
Validation loss: 2.791968662351215

Epoch: 5| Step: 2
Training loss: 3.545501712005163
Validation loss: 2.793193139613415

Epoch: 5| Step: 3
Training loss: 2.812203455232321
Validation loss: 2.7905448811033757

Epoch: 5| Step: 4
Training loss: 2.8895228578766092
Validation loss: 2.786082973428178

Epoch: 5| Step: 5
Training loss: 3.179900740987709
Validation loss: 2.7862241204753806

Epoch: 5| Step: 6
Training loss: 3.2365818327116136
Validation loss: 2.7863449222339147

Epoch: 5| Step: 7
Training loss: 2.9990935545674215
Validation loss: 2.7870888638448235

Epoch: 5| Step: 8
Training loss: 3.3768242038632077
Validation loss: 2.7858996661103084

Epoch: 5| Step: 9
Training loss: 3.3422430332558357
Validation loss: 2.787924089125617

Epoch: 5| Step: 10
Training loss: 2.922255873718024
Validation loss: 2.789869523135032

Epoch: 30| Step: 0
Training loss: 2.9926878508307153
Validation loss: 2.805157494576188

Epoch: 5| Step: 1
Training loss: 3.055976459142879
Validation loss: 2.841791169989978

Epoch: 5| Step: 2
Training loss: 3.4277112824186515
Validation loss: 2.8482345402815303

Epoch: 5| Step: 3
Training loss: 3.304125726806182
Validation loss: 2.847667974105839

Epoch: 5| Step: 4
Training loss: 3.133195125967691
Validation loss: 2.8472137577769105

Epoch: 5| Step: 5
Training loss: 3.5751202222976834
Validation loss: 2.845601574049912

Epoch: 5| Step: 6
Training loss: 3.215285723909611
Validation loss: 2.842604543367525

Epoch: 5| Step: 7
Training loss: 3.015646978901042
Validation loss: 2.8346067464794

Epoch: 5| Step: 8
Training loss: 2.6826245641450726
Validation loss: 2.8303282114782427

Epoch: 5| Step: 9
Training loss: 3.2071716054853145
Validation loss: 2.832535110703639

Epoch: 5| Step: 10
Training loss: 2.985048867086032
Validation loss: 2.8295093992139377

Epoch: 31| Step: 0
Training loss: 3.528650593021275
Validation loss: 2.8272491650797456

Epoch: 5| Step: 1
Training loss: 2.7721697421596865
Validation loss: 2.827969571460336

Epoch: 5| Step: 2
Training loss: 3.126777143607477
Validation loss: 2.827588428573821

Epoch: 5| Step: 3
Training loss: 2.0723407526806366
Validation loss: 2.8270875674050306

Epoch: 5| Step: 4
Training loss: 3.2724835227976965
Validation loss: 2.823679960029427

Epoch: 5| Step: 5
Training loss: 3.2749353591713057
Validation loss: 2.826965511325906

Epoch: 5| Step: 6
Training loss: 2.8251413023052003
Validation loss: 2.829603989723522

Epoch: 5| Step: 7
Training loss: 3.5588121566998736
Validation loss: 2.8302219113470213

Epoch: 5| Step: 8
Training loss: 2.8675975870091164
Validation loss: 2.838424753967099

Epoch: 5| Step: 9
Training loss: 3.889520450050348
Validation loss: 2.8429306853139975

Epoch: 5| Step: 10
Training loss: 3.059985315624233
Validation loss: 2.8222867361770065

Epoch: 32| Step: 0
Training loss: 3.8296636486516933
Validation loss: 2.827553279244134

Epoch: 5| Step: 1
Training loss: 2.853380266617622
Validation loss: 2.817065676175083

Epoch: 5| Step: 2
Training loss: 3.2772320079281942
Validation loss: 2.817277232360901

Epoch: 5| Step: 3
Training loss: 2.7179115142453734
Validation loss: 2.816796415422637

Epoch: 5| Step: 4
Training loss: 2.8628538887455757
Validation loss: 2.8171628303014846

Epoch: 5| Step: 5
Training loss: 2.8487138288744975
Validation loss: 2.817528098381798

Epoch: 5| Step: 6
Training loss: 3.1974320598479884
Validation loss: 2.818790909214015

Epoch: 5| Step: 7
Training loss: 3.495629715625591
Validation loss: 2.81927947445367

Epoch: 5| Step: 8
Training loss: 3.5361183838337915
Validation loss: 2.8186264290760703

Epoch: 5| Step: 9
Training loss: 3.3029463128702417
Validation loss: 2.820564203111975

Epoch: 5| Step: 10
Training loss: 2.1926235686988482
Validation loss: 2.817284897946341

Epoch: 33| Step: 0
Training loss: 3.0277650601492265
Validation loss: 2.8132177751854797

Epoch: 5| Step: 1
Training loss: 2.2330353462165333
Validation loss: 2.8104803428957905

Epoch: 5| Step: 2
Training loss: 3.5479088171474307
Validation loss: 2.812654058505216

Epoch: 5| Step: 3
Training loss: 3.110756878516669
Validation loss: 2.8121892504459653

Epoch: 5| Step: 4
Training loss: 3.011886888849843
Validation loss: 2.8096321278199987

Epoch: 5| Step: 5
Training loss: 3.061142289621567
Validation loss: 2.8060884359176046

Epoch: 5| Step: 6
Training loss: 2.9508716523954632
Validation loss: 2.7995827709733723

Epoch: 5| Step: 7
Training loss: 2.835600861885326
Validation loss: 2.7916750236634704

Epoch: 5| Step: 8
Training loss: 3.2865696972308163
Validation loss: 2.7964506145268824

Epoch: 5| Step: 9
Training loss: 3.7788437682596183
Validation loss: 2.804229648684083

Epoch: 5| Step: 10
Training loss: 3.324150470252054
Validation loss: 2.784960764311444

Epoch: 34| Step: 0
Training loss: 3.409960484429562
Validation loss: 2.780148164278968

Epoch: 5| Step: 1
Training loss: 3.275092459967793
Validation loss: 2.7780912832182456

Epoch: 5| Step: 2
Training loss: 3.1436774000881824
Validation loss: 2.7771465378665563

Epoch: 5| Step: 3
Training loss: 2.7882561038810763
Validation loss: 2.7780211877994048

Epoch: 5| Step: 4
Training loss: 3.4129284823748747
Validation loss: 2.7792555121539313

Epoch: 5| Step: 5
Training loss: 2.566200840363489
Validation loss: 2.7759399299993146

Epoch: 5| Step: 6
Training loss: 3.3014315534513243
Validation loss: 2.776598107730805

Epoch: 5| Step: 7
Training loss: 3.0675592478010154
Validation loss: 2.7789289858398827

Epoch: 5| Step: 8
Training loss: 2.5606858879896737
Validation loss: 2.7777494380558077

Epoch: 5| Step: 9
Training loss: 3.0409645071370024
Validation loss: 2.778690817572678

Epoch: 5| Step: 10
Training loss: 3.4936158674829736
Validation loss: 2.77773121493975

Epoch: 35| Step: 0
Training loss: 2.8871927865817426
Validation loss: 2.773862750162145

Epoch: 5| Step: 1
Training loss: 3.1086067515808624
Validation loss: 2.7748512566695247

Epoch: 5| Step: 2
Training loss: 3.2410610218323894
Validation loss: 2.77525529900074

Epoch: 5| Step: 3
Training loss: 2.6332534737690367
Validation loss: 2.753497683972078

Epoch: 5| Step: 4
Training loss: 3.1885393729456606
Validation loss: 2.750645837615667

Epoch: 5| Step: 5
Training loss: 3.1307714953258445
Validation loss: 2.7499629621351454

Epoch: 5| Step: 6
Training loss: 2.1079706108679406
Validation loss: 2.7529972426087483

Epoch: 5| Step: 7
Training loss: 3.6583478077201703
Validation loss: 2.7553852206811755

Epoch: 5| Step: 8
Training loss: 3.373854124731575
Validation loss: 2.7585217990872897

Epoch: 5| Step: 9
Training loss: 3.065890867815502
Validation loss: 2.759072441569761

Epoch: 5| Step: 10
Training loss: 3.3830072994395866
Validation loss: 2.7589732372106877

Epoch: 36| Step: 0
Training loss: 3.637966380420633
Validation loss: 2.7505832363139398

Epoch: 5| Step: 1
Training loss: 2.7582398858812853
Validation loss: 2.7496546316812003

Epoch: 5| Step: 2
Training loss: 3.2118574991693984
Validation loss: 2.748130545125988

Epoch: 5| Step: 3
Training loss: 3.3576374617192997
Validation loss: 2.7443169428088874

Epoch: 5| Step: 4
Training loss: 3.1598873519133917
Validation loss: 2.747570166951651

Epoch: 5| Step: 5
Training loss: 2.675800050544125
Validation loss: 2.7415797679644553

Epoch: 5| Step: 6
Training loss: 3.0571605301156453
Validation loss: 2.745395562600346

Epoch: 5| Step: 7
Training loss: 3.2789414777265344
Validation loss: 2.736002535140832

Epoch: 5| Step: 8
Training loss: 2.600996259405782
Validation loss: 2.735443033220754

Epoch: 5| Step: 9
Training loss: 3.4361786123265694
Validation loss: 2.7362570224968046

Epoch: 5| Step: 10
Training loss: 2.416515499078704
Validation loss: 2.7387894612059043

Epoch: 37| Step: 0
Training loss: 2.680111153703072
Validation loss: 2.7511569634983695

Epoch: 5| Step: 1
Training loss: 2.4475763828410564
Validation loss: 2.7534511413816913

Epoch: 5| Step: 2
Training loss: 3.2942008070105837
Validation loss: 2.7514347312543057

Epoch: 5| Step: 3
Training loss: 2.8153215454376292
Validation loss: 2.757798414784959

Epoch: 5| Step: 4
Training loss: 2.963654331061326
Validation loss: 2.744233119040631

Epoch: 5| Step: 5
Training loss: 3.6011949463343282
Validation loss: 2.7431442059152373

Epoch: 5| Step: 6
Training loss: 2.996367957984505
Validation loss: 2.7410265438739407

Epoch: 5| Step: 7
Training loss: 3.159414687695055
Validation loss: 2.7377978037930015

Epoch: 5| Step: 8
Training loss: 3.297346759327129
Validation loss: 2.7346553563837115

Epoch: 5| Step: 9
Training loss: 2.9927437765693914
Validation loss: 2.7311658815934554

Epoch: 5| Step: 10
Training loss: 3.4206868377677657
Validation loss: 2.730717380397926

Epoch: 38| Step: 0
Training loss: 3.3969900271426816
Validation loss: 2.731043516798704

Epoch: 5| Step: 1
Training loss: 3.175919383142881
Validation loss: 2.7286661874793

Epoch: 5| Step: 2
Training loss: 3.4094854265296783
Validation loss: 2.7288301675797157

Epoch: 5| Step: 3
Training loss: 2.8089661331443816
Validation loss: 2.7238790240587156

Epoch: 5| Step: 4
Training loss: 2.997340772152332
Validation loss: 2.725110319210727

Epoch: 5| Step: 5
Training loss: 3.1695830986176983
Validation loss: 2.7221759299429427

Epoch: 5| Step: 6
Training loss: 2.871768130035569
Validation loss: 2.724629664932689

Epoch: 5| Step: 7
Training loss: 2.601899271294461
Validation loss: 2.7214461948342406

Epoch: 5| Step: 8
Training loss: 2.7798762840076945
Validation loss: 2.720563408482241

Epoch: 5| Step: 9
Training loss: 3.3830896136316437
Validation loss: 2.7262892431748043

Epoch: 5| Step: 10
Training loss: 3.0820954561495775
Validation loss: 2.7406377763740695

Epoch: 39| Step: 0
Training loss: 2.557278127433742
Validation loss: 2.7293350016263727

Epoch: 5| Step: 1
Training loss: 3.5613867375482777
Validation loss: 2.72152175556073

Epoch: 5| Step: 2
Training loss: 3.3376621907003945
Validation loss: 2.7171930030349487

Epoch: 5| Step: 3
Training loss: 3.4279633448275733
Validation loss: 2.7115722113706764

Epoch: 5| Step: 4
Training loss: 2.4547456866773363
Validation loss: 2.714110727739068

Epoch: 5| Step: 5
Training loss: 3.5361817616485745
Validation loss: 2.7113109649474425

Epoch: 5| Step: 6
Training loss: 3.528900580225341
Validation loss: 2.7103015919464

Epoch: 5| Step: 7
Training loss: 3.152081446742678
Validation loss: 2.711787016328525

Epoch: 5| Step: 8
Training loss: 2.421715712692765
Validation loss: 2.7151009438467537

Epoch: 5| Step: 9
Training loss: 2.7739345051487754
Validation loss: 2.7120780412098715

Epoch: 5| Step: 10
Training loss: 2.4357101520300293
Validation loss: 2.7102106887329787

Epoch: 40| Step: 0
Training loss: 2.9773496052692687
Validation loss: 2.7080132105140926

Epoch: 5| Step: 1
Training loss: 3.2516834593990533
Validation loss: 2.703723308967076

Epoch: 5| Step: 2
Training loss: 2.4997177918414866
Validation loss: 2.701849720131675

Epoch: 5| Step: 3
Training loss: 3.461041382205769
Validation loss: 2.7018611821730154

Epoch: 5| Step: 4
Training loss: 2.8413541993058673
Validation loss: 2.7017340675014436

Epoch: 5| Step: 5
Training loss: 3.030356049218339
Validation loss: 2.6983353902809983

Epoch: 5| Step: 6
Training loss: 3.580103431358322
Validation loss: 2.6982354397741495

Epoch: 5| Step: 7
Training loss: 2.4340708159376776
Validation loss: 2.6982217637485957

Epoch: 5| Step: 8
Training loss: 3.195980683021272
Validation loss: 2.695677430717543

Epoch: 5| Step: 9
Training loss: 3.118739762222519
Validation loss: 2.696607071298764

Epoch: 5| Step: 10
Training loss: 2.8646769745288903
Validation loss: 2.695233329096458

Epoch: 41| Step: 0
Training loss: 2.759516635253663
Validation loss: 2.6965711235231824

Epoch: 5| Step: 1
Training loss: 2.8748306556252925
Validation loss: 2.6951139500888903

Epoch: 5| Step: 2
Training loss: 3.555652261120899
Validation loss: 2.7022820777321988

Epoch: 5| Step: 3
Training loss: 3.213695965508876
Validation loss: 2.6952625832996584

Epoch: 5| Step: 4
Training loss: 2.823853781769986
Validation loss: 2.69694059307842

Epoch: 5| Step: 5
Training loss: 2.9523920027501145
Validation loss: 2.69343612628051

Epoch: 5| Step: 6
Training loss: 3.276462950351622
Validation loss: 2.690881136595232

Epoch: 5| Step: 7
Training loss: 2.448174407592865
Validation loss: 2.6886953427096345

Epoch: 5| Step: 8
Training loss: 3.3958715112954474
Validation loss: 2.686201953988793

Epoch: 5| Step: 9
Training loss: 2.7138065689636024
Validation loss: 2.6876768686903696

Epoch: 5| Step: 10
Training loss: 3.2074353501307793
Validation loss: 2.685971708134237

Epoch: 42| Step: 0
Training loss: 2.859882413941144
Validation loss: 2.684661629359493

Epoch: 5| Step: 1
Training loss: 2.910189348071011
Validation loss: 2.6849126034194764

Epoch: 5| Step: 2
Training loss: 2.701924934146388
Validation loss: 2.685669406455957

Epoch: 5| Step: 3
Training loss: 3.2639206814852066
Validation loss: 2.682730822280466

Epoch: 5| Step: 4
Training loss: 3.475628879643048
Validation loss: 2.683599617454256

Epoch: 5| Step: 5
Training loss: 2.871378400536471
Validation loss: 2.6804949542668615

Epoch: 5| Step: 6
Training loss: 3.181107337615727
Validation loss: 2.685338638600097

Epoch: 5| Step: 7
Training loss: 3.0637956330890366
Validation loss: 2.6810658571487567

Epoch: 5| Step: 8
Training loss: 3.390196883074176
Validation loss: 2.690957905209382

Epoch: 5| Step: 9
Training loss: 2.592581520233529
Validation loss: 2.685621921299919

Epoch: 5| Step: 10
Training loss: 2.884987938126814
Validation loss: 2.6903405055865908

Epoch: 43| Step: 0
Training loss: 3.3993115232937186
Validation loss: 2.683548421525133

Epoch: 5| Step: 1
Training loss: 3.41293029866884
Validation loss: 2.675684870106976

Epoch: 5| Step: 2
Training loss: 2.8418556023785775
Validation loss: 2.675141237977312

Epoch: 5| Step: 3
Training loss: 3.050992247725109
Validation loss: 2.676342411837782

Epoch: 5| Step: 4
Training loss: 2.713165335207096
Validation loss: 2.6746148616606935

Epoch: 5| Step: 5
Training loss: 2.869829088764392
Validation loss: 2.676530771809922

Epoch: 5| Step: 6
Training loss: 2.8154181706103327
Validation loss: 2.6766527366753317

Epoch: 5| Step: 7
Training loss: 3.0295162945397465
Validation loss: 2.6752587023979304

Epoch: 5| Step: 8
Training loss: 3.501009114432
Validation loss: 2.6758808426136924

Epoch: 5| Step: 9
Training loss: 2.839983615290699
Validation loss: 2.6745154423699895

Epoch: 5| Step: 10
Training loss: 2.60915643381967
Validation loss: 2.674608616013096

Epoch: 44| Step: 0
Training loss: 3.123804855689328
Validation loss: 2.6788228746986444

Epoch: 5| Step: 1
Training loss: 2.656101177758803
Validation loss: 2.6822066321764133

Epoch: 5| Step: 2
Training loss: 3.673045649493308
Validation loss: 2.6883352002087912

Epoch: 5| Step: 3
Training loss: 2.7314188645316353
Validation loss: 2.6836620703697034

Epoch: 5| Step: 4
Training loss: 3.020254110293879
Validation loss: 2.66990806354633

Epoch: 5| Step: 5
Training loss: 3.343964756994384
Validation loss: 2.6686132162499376

Epoch: 5| Step: 6
Training loss: 2.478042304834762
Validation loss: 2.6716695515955826

Epoch: 5| Step: 7
Training loss: 2.787531755890881
Validation loss: 2.6730241149688263

Epoch: 5| Step: 8
Training loss: 3.099593683502342
Validation loss: 2.670037351089466

Epoch: 5| Step: 9
Training loss: 3.2207925482203716
Validation loss: 2.6672217188147562

Epoch: 5| Step: 10
Training loss: 2.919596880429534
Validation loss: 2.664917570918478

Epoch: 45| Step: 0
Training loss: 3.5160290295180405
Validation loss: 2.664838669706299

Epoch: 5| Step: 1
Training loss: 3.2393801381127254
Validation loss: 2.6660493154048654

Epoch: 5| Step: 2
Training loss: 3.0591141025478645
Validation loss: 2.665854216514865

Epoch: 5| Step: 3
Training loss: 2.910919867568125
Validation loss: 2.6719508658946367

Epoch: 5| Step: 4
Training loss: 2.9783624128115
Validation loss: 2.6658557859406273

Epoch: 5| Step: 5
Training loss: 2.6557349210503354
Validation loss: 2.668435550900427

Epoch: 5| Step: 6
Training loss: 3.1014295112290653
Validation loss: 2.6646693239267623

Epoch: 5| Step: 7
Training loss: 3.4853671590082533
Validation loss: 2.6640157739091666

Epoch: 5| Step: 8
Training loss: 3.0077643056203827
Validation loss: 2.6612994230853735

Epoch: 5| Step: 9
Training loss: 2.3766156774386284
Validation loss: 2.6633847432165543

Epoch: 5| Step: 10
Training loss: 2.483157837403612
Validation loss: 2.6605579002588273

Epoch: 46| Step: 0
Training loss: 2.822255234220708
Validation loss: 2.675559502738148

Epoch: 5| Step: 1
Training loss: 3.874464674858145
Validation loss: 2.691070179889127

Epoch: 5| Step: 2
Training loss: 2.9538155207589165
Validation loss: 2.6744265685311346

Epoch: 5| Step: 3
Training loss: 2.5819179492740365
Validation loss: 2.6595966602884062

Epoch: 5| Step: 4
Training loss: 2.6340121923293367
Validation loss: 2.656746235868673

Epoch: 5| Step: 5
Training loss: 2.892875661235655
Validation loss: 2.654651413197098

Epoch: 5| Step: 6
Training loss: 2.9831108891193145
Validation loss: 2.6551407256165924

Epoch: 5| Step: 7
Training loss: 3.2546851793153633
Validation loss: 2.6557411010376986

Epoch: 5| Step: 8
Training loss: 3.047493896227913
Validation loss: 2.6571763326529076

Epoch: 5| Step: 9
Training loss: 2.8560009002577273
Validation loss: 2.6562490213526275

Epoch: 5| Step: 10
Training loss: 2.9899978793337647
Validation loss: 2.6553910277476556

Epoch: 47| Step: 0
Training loss: 2.9462220586099983
Validation loss: 2.6560387678806037

Epoch: 5| Step: 1
Training loss: 2.9749055991702678
Validation loss: 2.6551674573813746

Epoch: 5| Step: 2
Training loss: 3.055742866862948
Validation loss: 2.655889227228147

Epoch: 5| Step: 3
Training loss: 3.253462194433854
Validation loss: 2.6562142414965155

Epoch: 5| Step: 4
Training loss: 3.11023397418032
Validation loss: 2.656474216560094

Epoch: 5| Step: 5
Training loss: 2.619003986432806
Validation loss: 2.654336842350842

Epoch: 5| Step: 6
Training loss: 2.97095239159064
Validation loss: 2.6549784744635634

Epoch: 5| Step: 7
Training loss: 2.7342764700439917
Validation loss: 2.659870501883508

Epoch: 5| Step: 8
Training loss: 3.2335696484703695
Validation loss: 2.6976155356785054

Epoch: 5| Step: 9
Training loss: 3.0125625160663483
Validation loss: 2.6720926555586453

Epoch: 5| Step: 10
Training loss: 3.205069942336066
Validation loss: 2.6688737298457648

Epoch: 48| Step: 0
Training loss: 3.0757371964714104
Validation loss: 2.6564053156478633

Epoch: 5| Step: 1
Training loss: 3.039790127687394
Validation loss: 2.6487229638928373

Epoch: 5| Step: 2
Training loss: 1.5496340719629669
Validation loss: 2.650782866106475

Epoch: 5| Step: 3
Training loss: 2.553040886640843
Validation loss: 2.6514071622708664

Epoch: 5| Step: 4
Training loss: 3.1322874927820665
Validation loss: 2.6538682020243245

Epoch: 5| Step: 5
Training loss: 2.844141335861228
Validation loss: 2.651448263825036

Epoch: 5| Step: 6
Training loss: 2.7721103985423348
Validation loss: 2.6514246466321594

Epoch: 5| Step: 7
Training loss: 2.9864074816242456
Validation loss: 2.6514256425304823

Epoch: 5| Step: 8
Training loss: 3.409703594984739
Validation loss: 2.646079164310863

Epoch: 5| Step: 9
Training loss: 3.539339101057969
Validation loss: 2.644277684711772

Epoch: 5| Step: 10
Training loss: 3.667133142680399
Validation loss: 2.6547044420911536

Epoch: 49| Step: 0
Training loss: 3.2989123950807606
Validation loss: 2.661943622162989

Epoch: 5| Step: 1
Training loss: 3.4805660212803335
Validation loss: 2.6706127127524444

Epoch: 5| Step: 2
Training loss: 2.9023445714690124
Validation loss: 2.6875657066178884

Epoch: 5| Step: 3
Training loss: 2.720838862399393
Validation loss: 2.680646341361921

Epoch: 5| Step: 4
Training loss: 3.336638258648904
Validation loss: 2.667511186835089

Epoch: 5| Step: 5
Training loss: 3.162658982936066
Validation loss: 2.6589525029091097

Epoch: 5| Step: 6
Training loss: 2.9775257704586062
Validation loss: 2.6492240546765657

Epoch: 5| Step: 7
Training loss: 2.8060912123447252
Validation loss: 2.6414267476997164

Epoch: 5| Step: 8
Training loss: 2.794112220853373
Validation loss: 2.642621215821142

Epoch: 5| Step: 9
Training loss: 2.8252059456354517
Validation loss: 2.6475376559794044

Epoch: 5| Step: 10
Training loss: 2.581765396351515
Validation loss: 2.648532604489831

Epoch: 50| Step: 0
Training loss: 3.2710772542854163
Validation loss: 2.6536352559976697

Epoch: 5| Step: 1
Training loss: 3.0880516825783375
Validation loss: 2.6557689503805855

Epoch: 5| Step: 2
Training loss: 2.89491242693017
Validation loss: 2.6518683490081663

Epoch: 5| Step: 3
Training loss: 2.657325706328711
Validation loss: 2.6486583659607645

Epoch: 5| Step: 4
Training loss: 2.8710233303438875
Validation loss: 2.643741911498997

Epoch: 5| Step: 5
Training loss: 2.492844450173093
Validation loss: 2.6414405712282543

Epoch: 5| Step: 6
Training loss: 2.611297447463781
Validation loss: 2.640840359846281

Epoch: 5| Step: 7
Training loss: 3.587727019141701
Validation loss: 2.6433463794359566

Epoch: 5| Step: 8
Training loss: 2.865414604026145
Validation loss: 2.6501159702185655

Epoch: 5| Step: 9
Training loss: 2.837981861220522
Validation loss: 2.6633147860984243

Epoch: 5| Step: 10
Training loss: 3.772733192188512
Validation loss: 2.6903408543500316

Epoch: 51| Step: 0
Training loss: 3.5009878671801444
Validation loss: 2.6943101414613473

Epoch: 5| Step: 1
Training loss: 3.200616365915343
Validation loss: 2.6865860686409726

Epoch: 5| Step: 2
Training loss: 3.0553695814776556
Validation loss: 2.693661301893714

Epoch: 5| Step: 3
Training loss: 3.446080543909603
Validation loss: 2.6884736312356106

Epoch: 5| Step: 4
Training loss: 2.6911827404301096
Validation loss: 2.677232210439006

Epoch: 5| Step: 5
Training loss: 2.528157735454684
Validation loss: 2.665537412084647

Epoch: 5| Step: 6
Training loss: 2.4706396283219187
Validation loss: 2.643825096037974

Epoch: 5| Step: 7
Training loss: 2.565875272822109
Validation loss: 2.6343853841071967

Epoch: 5| Step: 8
Training loss: 2.859544926164549
Validation loss: 2.633629515198761

Epoch: 5| Step: 9
Training loss: 3.3279560744706287
Validation loss: 2.633610843868927

Epoch: 5| Step: 10
Training loss: 3.19266868844655
Validation loss: 2.6327801574588094

Epoch: 52| Step: 0
Training loss: 2.919433879581124
Validation loss: 2.631785484112083

Epoch: 5| Step: 1
Training loss: 3.0793618752455547
Validation loss: 2.6313793758240847

Epoch: 5| Step: 2
Training loss: 3.6318561566726775
Validation loss: 2.628482158517825

Epoch: 5| Step: 3
Training loss: 2.175925012081787
Validation loss: 2.630547631958289

Epoch: 5| Step: 4
Training loss: 3.2782477313141256
Validation loss: 2.6322178712452833

Epoch: 5| Step: 5
Training loss: 2.707669093521848
Validation loss: 2.6355203003995826

Epoch: 5| Step: 6
Training loss: 3.504334898791173
Validation loss: 2.637751336547624

Epoch: 5| Step: 7
Training loss: 2.683646522236309
Validation loss: 2.6345836249037284

Epoch: 5| Step: 8
Training loss: 3.228563921060044
Validation loss: 2.638097060904448

Epoch: 5| Step: 9
Training loss: 2.7156091722525386
Validation loss: 2.623346294191194

Epoch: 5| Step: 10
Training loss: 2.6102576675967373
Validation loss: 2.6254563743042136

Epoch: 53| Step: 0
Training loss: 2.7390254991450957
Validation loss: 2.6251587309458797

Epoch: 5| Step: 1
Training loss: 3.4250693543923254
Validation loss: 2.6319720998351817

Epoch: 5| Step: 2
Training loss: 2.345954265379589
Validation loss: 2.6360683417709323

Epoch: 5| Step: 3
Training loss: 3.3629643626575043
Validation loss: 2.6342141963891934

Epoch: 5| Step: 4
Training loss: 2.9791885766421893
Validation loss: 2.6311164671446265

Epoch: 5| Step: 5
Training loss: 3.293457863753138
Validation loss: 2.630994242229402

Epoch: 5| Step: 6
Training loss: 2.80166505624822
Validation loss: 2.6276729001592614

Epoch: 5| Step: 7
Training loss: 2.8394172274694665
Validation loss: 2.625862429156381

Epoch: 5| Step: 8
Training loss: 2.433575233646201
Validation loss: 2.6283116709484893

Epoch: 5| Step: 9
Training loss: 3.035490550283327
Validation loss: 2.6264366558633254

Epoch: 5| Step: 10
Training loss: 3.4644490289185392
Validation loss: 2.626658169351258

Epoch: 54| Step: 0
Training loss: 2.8673228717829815
Validation loss: 2.6271745939653797

Epoch: 5| Step: 1
Training loss: 2.9847849619228684
Validation loss: 2.625430662158915

Epoch: 5| Step: 2
Training loss: 2.7897018426436917
Validation loss: 2.6377731100193382

Epoch: 5| Step: 3
Training loss: 2.7927554175792433
Validation loss: 2.634242938010111

Epoch: 5| Step: 4
Training loss: 2.483911243075437
Validation loss: 2.652071562364726

Epoch: 5| Step: 5
Training loss: 2.8441834171881233
Validation loss: 2.6555903639351124

Epoch: 5| Step: 6
Training loss: 3.155448131866983
Validation loss: 2.6709171082823264

Epoch: 5| Step: 7
Training loss: 2.813608332642947
Validation loss: 2.653792012393205

Epoch: 5| Step: 8
Training loss: 3.2477112560555566
Validation loss: 2.6293724158836795

Epoch: 5| Step: 9
Training loss: 3.6610174153259396
Validation loss: 2.617878930815177

Epoch: 5| Step: 10
Training loss: 2.998506810200756
Validation loss: 2.617668465928286

Epoch: 55| Step: 0
Training loss: 2.3828513220454255
Validation loss: 2.6167089145615643

Epoch: 5| Step: 1
Training loss: 3.006519545052098
Validation loss: 2.6193040840802526

Epoch: 5| Step: 2
Training loss: 3.3753594101163418
Validation loss: 2.6214527816890945

Epoch: 5| Step: 3
Training loss: 3.372218504653493
Validation loss: 2.6203235803927853

Epoch: 5| Step: 4
Training loss: 2.9805940174261085
Validation loss: 2.617633661189727

Epoch: 5| Step: 5
Training loss: 2.9960277007978005
Validation loss: 2.6201214799348227

Epoch: 5| Step: 6
Training loss: 3.1564512283083754
Validation loss: 2.623094919239482

Epoch: 5| Step: 7
Training loss: 2.617882388656179
Validation loss: 2.620401374166318

Epoch: 5| Step: 8
Training loss: 3.341887195822452
Validation loss: 2.6152817432672943

Epoch: 5| Step: 9
Training loss: 2.821954053952188
Validation loss: 2.6149735116508213

Epoch: 5| Step: 10
Training loss: 2.4210453704402113
Validation loss: 2.6092007368646604

Epoch: 56| Step: 0
Training loss: 3.585719149721393
Validation loss: 2.6114647823301738

Epoch: 5| Step: 1
Training loss: 2.528952038208724
Validation loss: 2.607782592377802

Epoch: 5| Step: 2
Training loss: 2.9905537659583055
Validation loss: 2.612425197106044

Epoch: 5| Step: 3
Training loss: 2.866642455804593
Validation loss: 2.6118657814194974

Epoch: 5| Step: 4
Training loss: 2.817116318500042
Validation loss: 2.614261369271721

Epoch: 5| Step: 5
Training loss: 3.1493784821149076
Validation loss: 2.6148830190263332

Epoch: 5| Step: 6
Training loss: 3.2414732364583516
Validation loss: 2.6139811794877867

Epoch: 5| Step: 7
Training loss: 2.9735237690392697
Validation loss: 2.6141183890215807

Epoch: 5| Step: 8
Training loss: 3.132794539478597
Validation loss: 2.6140591070897523

Epoch: 5| Step: 9
Training loss: 2.344460951740472
Validation loss: 2.6128092627947157

Epoch: 5| Step: 10
Training loss: 2.895288942244285
Validation loss: 2.612838158436013

Epoch: 57| Step: 0
Training loss: 2.703371951779475
Validation loss: 2.612180026827842

Epoch: 5| Step: 1
Training loss: 2.901441636698383
Validation loss: 2.6183402630178425

Epoch: 5| Step: 2
Training loss: 3.0311540411478584
Validation loss: 2.631933032832256

Epoch: 5| Step: 3
Training loss: 3.0422199390564737
Validation loss: 2.6339166832600758

Epoch: 5| Step: 4
Training loss: 3.029486861134187
Validation loss: 2.634995804622013

Epoch: 5| Step: 5
Training loss: 2.9734091087344967
Validation loss: 2.6214283182426517

Epoch: 5| Step: 6
Training loss: 2.8736715149916177
Validation loss: 2.614282506810282

Epoch: 5| Step: 7
Training loss: 3.4591463504477398
Validation loss: 2.6127265841729646

Epoch: 5| Step: 8
Training loss: 2.709470148406773
Validation loss: 2.6125842828624006

Epoch: 5| Step: 9
Training loss: 3.11188685494406
Validation loss: 2.6100016973597855

Epoch: 5| Step: 10
Training loss: 2.72120958640807
Validation loss: 2.6089177985298466

Epoch: 58| Step: 0
Training loss: 2.793858014435931
Validation loss: 2.607260237313976

Epoch: 5| Step: 1
Training loss: 2.967442917439478
Validation loss: 2.604566451036692

Epoch: 5| Step: 2
Training loss: 3.1677599742877787
Validation loss: 2.606109937267043

Epoch: 5| Step: 3
Training loss: 3.3755475765644882
Validation loss: 2.6083516931685407

Epoch: 5| Step: 4
Training loss: 2.479963308185976
Validation loss: 2.6095226556281026

Epoch: 5| Step: 5
Training loss: 2.79034214957163
Validation loss: 2.610895814167217

Epoch: 5| Step: 6
Training loss: 2.9220058799439057
Validation loss: 2.612641792278531

Epoch: 5| Step: 7
Training loss: 3.2001915874348934
Validation loss: 2.6206484175554126

Epoch: 5| Step: 8
Training loss: 2.695362212234037
Validation loss: 2.6324146664322545

Epoch: 5| Step: 9
Training loss: 3.317040839886009
Validation loss: 2.6438934152678537

Epoch: 5| Step: 10
Training loss: 2.632592257108476
Validation loss: 2.6370105222533105

Epoch: 59| Step: 0
Training loss: 3.004498129524287
Validation loss: 2.6443774085471206

Epoch: 5| Step: 1
Training loss: 3.4373934642582014
Validation loss: 2.6562999877472704

Epoch: 5| Step: 2
Training loss: 3.2906109207301335
Validation loss: 2.643837133506885

Epoch: 5| Step: 3
Training loss: 2.7285240134982005
Validation loss: 2.620067544642761

Epoch: 5| Step: 4
Training loss: 2.837322474904663
Validation loss: 2.6069937408230017

Epoch: 5| Step: 5
Training loss: 2.762529181416901
Validation loss: 2.602770836291341

Epoch: 5| Step: 6
Training loss: 2.736268004057142
Validation loss: 2.592743459984422

Epoch: 5| Step: 7
Training loss: 3.4425501399935525
Validation loss: 2.5949879585644453

Epoch: 5| Step: 8
Training loss: 3.1055547354448207
Validation loss: 2.5974587824886384

Epoch: 5| Step: 9
Training loss: 2.5835972825433684
Validation loss: 2.599335984680671

Epoch: 5| Step: 10
Training loss: 2.4120677620082085
Validation loss: 2.599208525711922

Epoch: 60| Step: 0
Training loss: 2.7279110609418136
Validation loss: 2.5973717787185033

Epoch: 5| Step: 1
Training loss: 3.426159549647908
Validation loss: 2.5953710881576177

Epoch: 5| Step: 2
Training loss: 2.882649404155884
Validation loss: 2.5948034258264085

Epoch: 5| Step: 3
Training loss: 3.0941750590851593
Validation loss: 2.596567909606587

Epoch: 5| Step: 4
Training loss: 2.572142995635417
Validation loss: 2.5930621167418932

Epoch: 5| Step: 5
Training loss: 2.9161820871986444
Validation loss: 2.5925842958976135

Epoch: 5| Step: 6
Training loss: 2.948986564742743
Validation loss: 2.5962832400829225

Epoch: 5| Step: 7
Training loss: 3.1900811310020765
Validation loss: 2.5962760871505846

Epoch: 5| Step: 8
Training loss: 2.9460226563762753
Validation loss: 2.59373485878534

Epoch: 5| Step: 9
Training loss: 2.745225663350557
Validation loss: 2.597659927206423

Epoch: 5| Step: 10
Training loss: 2.9585415046053782
Validation loss: 2.6020014474270172

Epoch: 61| Step: 0
Training loss: 2.4274271665542884
Validation loss: 2.602680361656971

Epoch: 5| Step: 1
Training loss: 2.8830862354688427
Validation loss: 2.6054941966879896

Epoch: 5| Step: 2
Training loss: 3.147066106363167
Validation loss: 2.6048875804321856

Epoch: 5| Step: 3
Training loss: 2.9077382532774085
Validation loss: 2.5947505613844926

Epoch: 5| Step: 4
Training loss: 2.8131104548548
Validation loss: 2.5993540515593097

Epoch: 5| Step: 5
Training loss: 2.937406984845086
Validation loss: 2.5945357036913315

Epoch: 5| Step: 6
Training loss: 2.8087483285271664
Validation loss: 2.5859877058508336

Epoch: 5| Step: 7
Training loss: 3.0657821506113776
Validation loss: 2.5937394518637134

Epoch: 5| Step: 8
Training loss: 3.455916437260265
Validation loss: 2.59233648373489

Epoch: 5| Step: 9
Training loss: 3.1000225558537085
Validation loss: 2.5898920538287933

Epoch: 5| Step: 10
Training loss: 2.7559005550387146
Validation loss: 2.586737061255104

Epoch: 62| Step: 0
Training loss: 3.07568293485318
Validation loss: 2.5900557147338423

Epoch: 5| Step: 1
Training loss: 2.7244038165905713
Validation loss: 2.591649705129477

Epoch: 5| Step: 2
Training loss: 2.6604427681889415
Validation loss: 2.601824079323391

Epoch: 5| Step: 3
Training loss: 3.4991125616614918
Validation loss: 2.6144603191585074

Epoch: 5| Step: 4
Training loss: 2.7582304640504867
Validation loss: 2.6167690461117368

Epoch: 5| Step: 5
Training loss: 3.082337261523212
Validation loss: 2.6224988134328626

Epoch: 5| Step: 6
Training loss: 2.3121484025231873
Validation loss: 2.6209170626086182

Epoch: 5| Step: 7
Training loss: 3.4589683838210257
Validation loss: 2.633808011920461

Epoch: 5| Step: 8
Training loss: 2.9574591907771617
Validation loss: 2.617830575402353

Epoch: 5| Step: 9
Training loss: 2.8666900286350945
Validation loss: 2.6035570847970773

Epoch: 5| Step: 10
Training loss: 2.9439020397017885
Validation loss: 2.5958675878496615

Epoch: 63| Step: 0
Training loss: 3.0879253696752587
Validation loss: 2.5816915960522384

Epoch: 5| Step: 1
Training loss: 2.564563013818
Validation loss: 2.5815506088862605

Epoch: 5| Step: 2
Training loss: 2.904982095423558
Validation loss: 2.5848395193882494

Epoch: 5| Step: 3
Training loss: 2.3849427753357055
Validation loss: 2.595960503148459

Epoch: 5| Step: 4
Training loss: 3.027753406002714
Validation loss: 2.5847832322120525

Epoch: 5| Step: 5
Training loss: 3.099681677933494
Validation loss: 2.5814334899214364

Epoch: 5| Step: 6
Training loss: 3.5087833547824436
Validation loss: 2.5827171230503505

Epoch: 5| Step: 7
Training loss: 2.7822035108677814
Validation loss: 2.5917820220852295

Epoch: 5| Step: 8
Training loss: 2.843256981000797
Validation loss: 2.6063379646219844

Epoch: 5| Step: 9
Training loss: 2.6444167502562155
Validation loss: 2.621721960363072

Epoch: 5| Step: 10
Training loss: 3.481551185057431
Validation loss: 2.6597108573938155

Epoch: 64| Step: 0
Training loss: 2.8648292759596528
Validation loss: 2.6362992040783766

Epoch: 5| Step: 1
Training loss: 3.205597607009714
Validation loss: 2.633608733467864

Epoch: 5| Step: 2
Training loss: 3.1399029713114524
Validation loss: 2.615081332441531

Epoch: 5| Step: 3
Training loss: 2.960417769823578
Validation loss: 2.618417468544252

Epoch: 5| Step: 4
Training loss: 2.4309976363427532
Validation loss: 2.6131481449022353

Epoch: 5| Step: 5
Training loss: 3.51230216775823
Validation loss: 2.631773086623225

Epoch: 5| Step: 6
Training loss: 2.190257378177257
Validation loss: 2.574525294804977

Epoch: 5| Step: 7
Training loss: 2.881493408778084
Validation loss: 2.583138276581599

Epoch: 5| Step: 8
Training loss: 2.780044980405643
Validation loss: 2.5970902494857144

Epoch: 5| Step: 9
Training loss: 2.9243669134502293
Validation loss: 2.6354322905204817

Epoch: 5| Step: 10
Training loss: 3.452280899376979
Validation loss: 2.672533983667418

Epoch: 65| Step: 0
Training loss: 3.088114837092415
Validation loss: 2.6785611207239253

Epoch: 5| Step: 1
Training loss: 2.6632719684863204
Validation loss: 2.657507171486899

Epoch: 5| Step: 2
Training loss: 3.37340352481697
Validation loss: 2.645990987287054

Epoch: 5| Step: 3
Training loss: 3.0902829249954693
Validation loss: 2.6088165919690787

Epoch: 5| Step: 4
Training loss: 2.5485038931107566
Validation loss: 2.5933894838296916

Epoch: 5| Step: 5
Training loss: 2.629730050189817
Validation loss: 2.584361796196501

Epoch: 5| Step: 6
Training loss: 2.794141232535671
Validation loss: 2.582166621321858

Epoch: 5| Step: 7
Training loss: 2.956894018498685
Validation loss: 2.586578503831978

Epoch: 5| Step: 8
Training loss: 3.261048537056012
Validation loss: 2.613080502284023

Epoch: 5| Step: 9
Training loss: 2.9667343524826557
Validation loss: 2.6317448956831577

Epoch: 5| Step: 10
Training loss: 3.4110886390462176
Validation loss: 2.6553806665448456

Epoch: 66| Step: 0
Training loss: 2.857985528929308
Validation loss: 2.667488918961669

Epoch: 5| Step: 1
Training loss: 2.9880463551470906
Validation loss: 2.664186630602497

Epoch: 5| Step: 2
Training loss: 3.2470020258327095
Validation loss: 2.664977730597178

Epoch: 5| Step: 3
Training loss: 3.1962772768935634
Validation loss: 2.6199475881341994

Epoch: 5| Step: 4
Training loss: 2.3806339498298086
Validation loss: 2.5980550870146213

Epoch: 5| Step: 5
Training loss: 3.191959477896409
Validation loss: 2.590237855532586

Epoch: 5| Step: 6
Training loss: 2.8495805933690432
Validation loss: 2.5821202758157895

Epoch: 5| Step: 7
Training loss: 3.0708099039979175
Validation loss: 2.583379416264786

Epoch: 5| Step: 8
Training loss: 3.245213137828781
Validation loss: 2.5878002839621654

Epoch: 5| Step: 9
Training loss: 2.1053071535055894
Validation loss: 2.5977706969088894

Epoch: 5| Step: 10
Training loss: 3.231165376067898
Validation loss: 2.599356489594511

Epoch: 67| Step: 0
Training loss: 2.842640922495419
Validation loss: 2.59600978241021

Epoch: 5| Step: 1
Training loss: 2.958181744484006
Validation loss: 2.5923438957584506

Epoch: 5| Step: 2
Training loss: 2.9668663072026775
Validation loss: 2.5897611103327107

Epoch: 5| Step: 3
Training loss: 2.6842073186121023
Validation loss: 2.587348275821204

Epoch: 5| Step: 4
Training loss: 2.953918350465331
Validation loss: 2.5838408975486433

Epoch: 5| Step: 5
Training loss: 3.5443704643886433
Validation loss: 2.5847613337175646

Epoch: 5| Step: 6
Training loss: 2.6978366697570464
Validation loss: 2.5892847625004873

Epoch: 5| Step: 7
Training loss: 2.5338902773085823
Validation loss: 2.608286298841273

Epoch: 5| Step: 8
Training loss: 3.2524737700241064
Validation loss: 2.5915170213334164

Epoch: 5| Step: 9
Training loss: 2.9180272516516763
Validation loss: 2.5878099369743843

Epoch: 5| Step: 10
Training loss: 3.13293578554565
Validation loss: 2.582660002458074

Epoch: 68| Step: 0
Training loss: 2.6449136612471227
Validation loss: 2.5821714980756685

Epoch: 5| Step: 1
Training loss: 2.3027138745509212
Validation loss: 2.5827629198594204

Epoch: 5| Step: 2
Training loss: 2.5453488510655284
Validation loss: 2.5921639689568368

Epoch: 5| Step: 3
Training loss: 3.4781866158976813
Validation loss: 2.5976215195845707

Epoch: 5| Step: 4
Training loss: 3.413372188237692
Validation loss: 2.6022086727537417

Epoch: 5| Step: 5
Training loss: 2.9722035448036133
Validation loss: 2.5909690725324768

Epoch: 5| Step: 6
Training loss: 3.1685912323853356
Validation loss: 2.586406344427068

Epoch: 5| Step: 7
Training loss: 2.963112065307734
Validation loss: 2.587131086610048

Epoch: 5| Step: 8
Training loss: 2.9202840625078417
Validation loss: 2.576449584496597

Epoch: 5| Step: 9
Training loss: 2.7633994247883185
Validation loss: 2.574296701172141

Epoch: 5| Step: 10
Training loss: 3.019800329618122
Validation loss: 2.5741710463911835

Epoch: 69| Step: 0
Training loss: 2.4356927285041494
Validation loss: 2.566402399151342

Epoch: 5| Step: 1
Training loss: 2.562610437758105
Validation loss: 2.5641555440405135

Epoch: 5| Step: 2
Training loss: 3.7529078335787074
Validation loss: 2.5678112952306624

Epoch: 5| Step: 3
Training loss: 2.9217769177952038
Validation loss: 2.563712554741541

Epoch: 5| Step: 4
Training loss: 3.0501056465237486
Validation loss: 2.561866597933945

Epoch: 5| Step: 5
Training loss: 3.1999343984555284
Validation loss: 2.568945908307089

Epoch: 5| Step: 6
Training loss: 2.7472548221119184
Validation loss: 2.5759256507356865

Epoch: 5| Step: 7
Training loss: 3.2669232721814576
Validation loss: 2.575648770598726

Epoch: 5| Step: 8
Training loss: 2.543632924527915
Validation loss: 2.5653227359058746

Epoch: 5| Step: 9
Training loss: 2.841648708820001
Validation loss: 2.5635125895525857

Epoch: 5| Step: 10
Training loss: 2.549636093053425
Validation loss: 2.557442654481689

Epoch: 70| Step: 0
Training loss: 2.9362619916038493
Validation loss: 2.557862148348929

Epoch: 5| Step: 1
Training loss: 2.5617210320697845
Validation loss: 2.555521659468747

Epoch: 5| Step: 2
Training loss: 3.587146563515303
Validation loss: 2.5521907516752873

Epoch: 5| Step: 3
Training loss: 3.330297772723166
Validation loss: 2.5547450463261527

Epoch: 5| Step: 4
Training loss: 2.536683549745429
Validation loss: 2.554567230154212

Epoch: 5| Step: 5
Training loss: 2.450867020696392
Validation loss: 2.5509130165632308

Epoch: 5| Step: 6
Training loss: 2.7983337519427454
Validation loss: 2.5514706353099763

Epoch: 5| Step: 7
Training loss: 2.973250982515485
Validation loss: 2.5637400108242754

Epoch: 5| Step: 8
Training loss: 2.772039958599799
Validation loss: 2.598945840739005

Epoch: 5| Step: 9
Training loss: 3.21653434270418
Validation loss: 2.660096998026004

Epoch: 5| Step: 10
Training loss: 2.7161669683076077
Validation loss: 2.611962601293613

Epoch: 71| Step: 0
Training loss: 2.742472229002395
Validation loss: 2.5900574330284107

Epoch: 5| Step: 1
Training loss: 3.0253455476992044
Validation loss: 2.5562355449271923

Epoch: 5| Step: 2
Training loss: 3.6153944939386293
Validation loss: 2.549498834569421

Epoch: 5| Step: 3
Training loss: 3.0463749401844944
Validation loss: 2.5453876767962718

Epoch: 5| Step: 4
Training loss: 3.1619450018079074
Validation loss: 2.5487416680005226

Epoch: 5| Step: 5
Training loss: 3.038735654068181
Validation loss: 2.547490654317113

Epoch: 5| Step: 6
Training loss: 2.461387181447614
Validation loss: 2.543434434747609

Epoch: 5| Step: 7
Training loss: 2.5870852041173746
Validation loss: 2.54109803698953

Epoch: 5| Step: 8
Training loss: 2.9897903920065643
Validation loss: 2.538761102727011

Epoch: 5| Step: 9
Training loss: 2.6444507400676396
Validation loss: 2.5432971792476824

Epoch: 5| Step: 10
Training loss: 2.5469053301731215
Validation loss: 2.5513576564925162

Epoch: 72| Step: 0
Training loss: 3.0851184385740034
Validation loss: 2.5998781794902532

Epoch: 5| Step: 1
Training loss: 3.1411770008134616
Validation loss: 2.6434543298926454

Epoch: 5| Step: 2
Training loss: 2.886747822079589
Validation loss: 2.6831204347934787

Epoch: 5| Step: 3
Training loss: 2.8189482625521527
Validation loss: 2.693835847488478

Epoch: 5| Step: 4
Training loss: 2.74574696506783
Validation loss: 2.6584165246551215

Epoch: 5| Step: 5
Training loss: 3.0893440083580104
Validation loss: 2.6180562619325234

Epoch: 5| Step: 6
Training loss: 3.1648734854772864
Validation loss: 2.5900429660611164

Epoch: 5| Step: 7
Training loss: 2.715788093822958
Validation loss: 2.5729655127945175

Epoch: 5| Step: 8
Training loss: 2.727707412064219
Validation loss: 2.5660542475686237

Epoch: 5| Step: 9
Training loss: 2.9149839360888854
Validation loss: 2.5692130475629433

Epoch: 5| Step: 10
Training loss: 2.963933309857562
Validation loss: 2.5677851566210164

Epoch: 73| Step: 0
Training loss: 2.7379582060806973
Validation loss: 2.547995822919104

Epoch: 5| Step: 1
Training loss: 2.8331338774842645
Validation loss: 2.535695646441207

Epoch: 5| Step: 2
Training loss: 2.75784898252914
Validation loss: 2.534772064562529

Epoch: 5| Step: 3
Training loss: 3.0311159713845366
Validation loss: 2.534256102510211

Epoch: 5| Step: 4
Training loss: 2.8913983934239553
Validation loss: 2.5378852653200914

Epoch: 5| Step: 5
Training loss: 3.272200685339192
Validation loss: 2.546847676162612

Epoch: 5| Step: 6
Training loss: 3.0555326653596078
Validation loss: 2.576753510945813

Epoch: 5| Step: 7
Training loss: 2.790236282187767
Validation loss: 2.6084331738141966

Epoch: 5| Step: 8
Training loss: 2.8838120461855015
Validation loss: 2.6423482420574453

Epoch: 5| Step: 9
Training loss: 3.059738471130948
Validation loss: 2.588543379363741

Epoch: 5| Step: 10
Training loss: 2.778496740334126
Validation loss: 2.5461486751075335

Epoch: 74| Step: 0
Training loss: 3.207216506049257
Validation loss: 2.52895452384058

Epoch: 5| Step: 1
Training loss: 2.7838576875574574
Validation loss: 2.5302611748657178

Epoch: 5| Step: 2
Training loss: 3.0940842881363597
Validation loss: 2.5257065095976405

Epoch: 5| Step: 3
Training loss: 2.8582833295921035
Validation loss: 2.5284317139021297

Epoch: 5| Step: 4
Training loss: 2.799260150710795
Validation loss: 2.5324311310590457

Epoch: 5| Step: 5
Training loss: 2.9189799444875946
Validation loss: 2.535769250203106

Epoch: 5| Step: 6
Training loss: 2.734494103153837
Validation loss: 2.5350557534215916

Epoch: 5| Step: 7
Training loss: 3.094810227105513
Validation loss: 2.530398733231245

Epoch: 5| Step: 8
Training loss: 2.7589785782527505
Validation loss: 2.529989644063896

Epoch: 5| Step: 9
Training loss: 2.868887498672875
Validation loss: 2.5297782809453984

Epoch: 5| Step: 10
Training loss: 2.8423678214577537
Validation loss: 2.5226155920474276

Epoch: 75| Step: 0
Training loss: 2.173402317840135
Validation loss: 2.5368772663875694

Epoch: 5| Step: 1
Training loss: 2.97042028722187
Validation loss: 2.5582848472713047

Epoch: 5| Step: 2
Training loss: 2.9036867056166717
Validation loss: 2.5759459434124747

Epoch: 5| Step: 3
Training loss: 2.766234422339057
Validation loss: 2.576594763017339

Epoch: 5| Step: 4
Training loss: 2.7832499824728827
Validation loss: 2.564530593277663

Epoch: 5| Step: 5
Training loss: 3.1792815228101046
Validation loss: 2.5500407265345104

Epoch: 5| Step: 6
Training loss: 2.632527231218684
Validation loss: 2.5528857103452665

Epoch: 5| Step: 7
Training loss: 3.5229873538844676
Validation loss: 2.54826036365019

Epoch: 5| Step: 8
Training loss: 3.183094046288851
Validation loss: 2.5409370019186337

Epoch: 5| Step: 9
Training loss: 2.793032942881185
Validation loss: 2.52534731037151

Epoch: 5| Step: 10
Training loss: 2.812433793030414
Validation loss: 2.5215592633632467

Epoch: 76| Step: 0
Training loss: 2.704384041989936
Validation loss: 2.518460312010587

Epoch: 5| Step: 1
Training loss: 3.0894602309688004
Validation loss: 2.5226225605525032

Epoch: 5| Step: 2
Training loss: 3.112479495551656
Validation loss: 2.5178123568881

Epoch: 5| Step: 3
Training loss: 2.654480647784129
Validation loss: 2.514958176015659

Epoch: 5| Step: 4
Training loss: 3.04420675183615
Validation loss: 2.5182267359418042

Epoch: 5| Step: 5
Training loss: 2.788493891864754
Validation loss: 2.522100485223631

Epoch: 5| Step: 6
Training loss: 3.08959728468465
Validation loss: 2.523093609020095

Epoch: 5| Step: 7
Training loss: 2.923812468645457
Validation loss: 2.5278707360819634

Epoch: 5| Step: 8
Training loss: 2.5383670734843995
Validation loss: 2.5389709582364306

Epoch: 5| Step: 9
Training loss: 3.0253948805146798
Validation loss: 2.538703599022086

Epoch: 5| Step: 10
Training loss: 2.811113990896138
Validation loss: 2.5492198383624047

Epoch: 77| Step: 0
Training loss: 3.3464216450617945
Validation loss: 2.546662041453705

Epoch: 5| Step: 1
Training loss: 3.2374431413643228
Validation loss: 2.533202148404927

Epoch: 5| Step: 2
Training loss: 2.9310833263389804
Validation loss: 2.525617684719354

Epoch: 5| Step: 3
Training loss: 2.7146011793048173
Validation loss: 2.527438094018344

Epoch: 5| Step: 4
Training loss: 3.2657331968936862
Validation loss: 2.5212163963793186

Epoch: 5| Step: 5
Training loss: 2.4383611869481387
Validation loss: 2.5130616645656203

Epoch: 5| Step: 6
Training loss: 1.7747863479763233
Validation loss: 2.5178514687633724

Epoch: 5| Step: 7
Training loss: 3.020960697689943
Validation loss: 2.5177009153084766

Epoch: 5| Step: 8
Training loss: 2.6313620174240455
Validation loss: 2.5172222938683366

Epoch: 5| Step: 9
Training loss: 2.7075227453627226
Validation loss: 2.5220893446828057

Epoch: 5| Step: 10
Training loss: 3.3880986940945643
Validation loss: 2.529243722391125

Epoch: 78| Step: 0
Training loss: 2.849645853626178
Validation loss: 2.5288426963736135

Epoch: 5| Step: 1
Training loss: 3.132085777715822
Validation loss: 2.518634916201775

Epoch: 5| Step: 2
Training loss: 2.912597287890274
Validation loss: 2.5159870270128004

Epoch: 5| Step: 3
Training loss: 2.634049031825905
Validation loss: 2.514485573938986

Epoch: 5| Step: 4
Training loss: 2.7181117744676646
Validation loss: 2.5147386845691195

Epoch: 5| Step: 5
Training loss: 2.8681545861373072
Validation loss: 2.513477825370933

Epoch: 5| Step: 6
Training loss: 2.9323592960199454
Validation loss: 2.5138613919316644

Epoch: 5| Step: 7
Training loss: 2.9169516469604986
Validation loss: 2.511979166027112

Epoch: 5| Step: 8
Training loss: 2.849029837669338
Validation loss: 2.516289224526292

Epoch: 5| Step: 9
Training loss: 2.6440753853766514
Validation loss: 2.5269470750538536

Epoch: 5| Step: 10
Training loss: 3.268596994236209
Validation loss: 2.55510298434922

Epoch: 79| Step: 0
Training loss: 3.2324560987614235
Validation loss: 2.626312953940245

Epoch: 5| Step: 1
Training loss: 2.902693674754194
Validation loss: 2.657529134236725

Epoch: 5| Step: 2
Training loss: 2.5702820750003994
Validation loss: 2.7070631524219637

Epoch: 5| Step: 3
Training loss: 3.2652132057574335
Validation loss: 2.708800500061633

Epoch: 5| Step: 4
Training loss: 2.3027984636106495
Validation loss: 2.5707040111984876

Epoch: 5| Step: 5
Training loss: 3.2690139051289258
Validation loss: 2.5271087601650772

Epoch: 5| Step: 6
Training loss: 2.8850538849715535
Validation loss: 2.512687725722387

Epoch: 5| Step: 7
Training loss: 2.6079384509938808
Validation loss: 2.517196544510459

Epoch: 5| Step: 8
Training loss: 2.7883151038699405
Validation loss: 2.5146101760223374

Epoch: 5| Step: 9
Training loss: 2.9688219563648053
Validation loss: 2.517376751896509

Epoch: 5| Step: 10
Training loss: 2.871782575745162
Validation loss: 2.5147105313870313

Epoch: 80| Step: 0
Training loss: 2.835050586067473
Validation loss: 2.5211024054740174

Epoch: 5| Step: 1
Training loss: 3.2508034813305704
Validation loss: 2.511774348442598

Epoch: 5| Step: 2
Training loss: 2.9145754447068586
Validation loss: 2.5148061862890714

Epoch: 5| Step: 3
Training loss: 2.2783872853690497
Validation loss: 2.5150792289011314

Epoch: 5| Step: 4
Training loss: 2.8355638662486857
Validation loss: 2.517918093888505

Epoch: 5| Step: 5
Training loss: 3.025494174157962
Validation loss: 2.5344984690669627

Epoch: 5| Step: 6
Training loss: 2.811158941345341
Validation loss: 2.574018893857826

Epoch: 5| Step: 7
Training loss: 2.964292693663373
Validation loss: 2.6144900064873386

Epoch: 5| Step: 8
Training loss: 2.8570612316733364
Validation loss: 2.633389472272161

Epoch: 5| Step: 9
Training loss: 3.383386294572102
Validation loss: 2.635088257660496

Epoch: 5| Step: 10
Training loss: 2.272529761661915
Validation loss: 2.612431711139571

Epoch: 81| Step: 0
Training loss: 3.3281550876170787
Validation loss: 2.575939522225711

Epoch: 5| Step: 1
Training loss: 2.590869637087014
Validation loss: 2.5489153283709705

Epoch: 5| Step: 2
Training loss: 2.8343237286591543
Validation loss: 2.524865719573054

Epoch: 5| Step: 3
Training loss: 3.2778097373855473
Validation loss: 2.513110801535338

Epoch: 5| Step: 4
Training loss: 3.140014285401328
Validation loss: 2.506068380196538

Epoch: 5| Step: 5
Training loss: 2.537767379278839
Validation loss: 2.5087466333358526

Epoch: 5| Step: 6
Training loss: 2.6282957368563373
Validation loss: 2.508541311659597

Epoch: 5| Step: 7
Training loss: 2.77725696025721
Validation loss: 2.51094305433969

Epoch: 5| Step: 8
Training loss: 2.84167639617895
Validation loss: 2.508730646977824

Epoch: 5| Step: 9
Training loss: 2.813309447050011
Validation loss: 2.5124900471977862

Epoch: 5| Step: 10
Training loss: 2.94633534932153
Validation loss: 2.507150328441553

Epoch: 82| Step: 0
Training loss: 2.8416438425290393
Validation loss: 2.5089694803663836

Epoch: 5| Step: 1
Training loss: 2.956453576851021
Validation loss: 2.5054314432361773

Epoch: 5| Step: 2
Training loss: 3.1061442858017316
Validation loss: 2.5129556915972264

Epoch: 5| Step: 3
Training loss: 3.537262920078076
Validation loss: 2.513058654170709

Epoch: 5| Step: 4
Training loss: 2.974451312588914
Validation loss: 2.509944862415753

Epoch: 5| Step: 5
Training loss: 2.291092008730392
Validation loss: 2.527942836062859

Epoch: 5| Step: 6
Training loss: 2.4653193140485774
Validation loss: 2.527809094266542

Epoch: 5| Step: 7
Training loss: 2.205883598701275
Validation loss: 2.5372847540083274

Epoch: 5| Step: 8
Training loss: 3.132969421870642
Validation loss: 2.5418496236677126

Epoch: 5| Step: 9
Training loss: 3.008955463387894
Validation loss: 2.5838738903687006

Epoch: 5| Step: 10
Training loss: 2.88059387018057
Validation loss: 2.5681893413320225

Epoch: 83| Step: 0
Training loss: 2.813699000475548
Validation loss: 2.547354876371023

Epoch: 5| Step: 1
Training loss: 2.758317074530896
Validation loss: 2.54481930602726

Epoch: 5| Step: 2
Training loss: 2.418125424832415
Validation loss: 2.520143840901662

Epoch: 5| Step: 3
Training loss: 2.947557479129701
Validation loss: 2.5210956941041505

Epoch: 5| Step: 4
Training loss: 2.7685735469761084
Validation loss: 2.5150305213014845

Epoch: 5| Step: 5
Training loss: 3.193973624505701
Validation loss: 2.5088247866028555

Epoch: 5| Step: 6
Training loss: 3.0161987707575304
Validation loss: 2.503992182847363

Epoch: 5| Step: 7
Training loss: 2.9943914439037074
Validation loss: 2.504058302404268

Epoch: 5| Step: 8
Training loss: 2.513863556970176
Validation loss: 2.5030060620284926

Epoch: 5| Step: 9
Training loss: 3.101962969314832
Validation loss: 2.499498212867695

Epoch: 5| Step: 10
Training loss: 2.916470838966338
Validation loss: 2.504602889471411

Epoch: 84| Step: 0
Training loss: 2.7240684491882794
Validation loss: 2.5047315373589583

Epoch: 5| Step: 1
Training loss: 2.685378812212867
Validation loss: 2.503778189923911

Epoch: 5| Step: 2
Training loss: 2.7187722742330194
Validation loss: 2.5036806934732296

Epoch: 5| Step: 3
Training loss: 3.0899661265371456
Validation loss: 2.5077866335791508

Epoch: 5| Step: 4
Training loss: 2.8381744053851414
Validation loss: 2.5125294776231724

Epoch: 5| Step: 5
Training loss: 3.1315837933461936
Validation loss: 2.5322233977177673

Epoch: 5| Step: 6
Training loss: 3.138641186358215
Validation loss: 2.5715590886766058

Epoch: 5| Step: 7
Training loss: 2.2891822757566036
Validation loss: 2.660567561019957

Epoch: 5| Step: 8
Training loss: 2.5950067072434373
Validation loss: 2.7912122622625897

Epoch: 5| Step: 9
Training loss: 3.3731806054302202
Validation loss: 2.919105573334101

Epoch: 5| Step: 10
Training loss: 3.4789371224401413
Validation loss: 2.7268948549735077

Epoch: 85| Step: 0
Training loss: 2.7353806744367466
Validation loss: 2.531067233296533

Epoch: 5| Step: 1
Training loss: 3.0528426196919995
Validation loss: 2.498106265898026

Epoch: 5| Step: 2
Training loss: 2.691290200974584
Validation loss: 2.5069597335623577

Epoch: 5| Step: 3
Training loss: 2.6597630326405066
Validation loss: 2.525179777443355

Epoch: 5| Step: 4
Training loss: 2.4459017205195366
Validation loss: 2.551288448969548

Epoch: 5| Step: 5
Training loss: 3.218742740956241
Validation loss: 2.5739936539111934

Epoch: 5| Step: 6
Training loss: 3.052800446891752
Validation loss: 2.6131327109079323

Epoch: 5| Step: 7
Training loss: 2.7410180187391573
Validation loss: 2.5969939383158525

Epoch: 5| Step: 8
Training loss: 3.2624940601747894
Validation loss: 2.5834393997197407

Epoch: 5| Step: 9
Training loss: 3.1812899064294657
Validation loss: 2.5734669916888917

Epoch: 5| Step: 10
Training loss: 3.353557002101681
Validation loss: 2.5665090210722714

Epoch: 86| Step: 0
Training loss: 2.9773926866283835
Validation loss: 2.5557036333161913

Epoch: 5| Step: 1
Training loss: 3.2122859304625813
Validation loss: 2.5522892456830157

Epoch: 5| Step: 2
Training loss: 2.9614787148118573
Validation loss: 2.540250298493418

Epoch: 5| Step: 3
Training loss: 2.5458744634707426
Validation loss: 2.522336465080763

Epoch: 5| Step: 4
Training loss: 3.0950307025526667
Validation loss: 2.5723244683549242

Epoch: 5| Step: 5
Training loss: 2.8631929849756665
Validation loss: 2.7436087209504003

Epoch: 5| Step: 6
Training loss: 3.4553717989239345
Validation loss: 2.725233496959689

Epoch: 5| Step: 7
Training loss: 2.2304430958463373
Validation loss: 2.6049586440893573

Epoch: 5| Step: 8
Training loss: 2.6906444872284467
Validation loss: 2.5218629543699236

Epoch: 5| Step: 9
Training loss: 3.108329252047753
Validation loss: 2.5032462332467404

Epoch: 5| Step: 10
Training loss: 2.8754220735633322
Validation loss: 2.50475379828928

Epoch: 87| Step: 0
Training loss: 3.2063802413811335
Validation loss: 2.514865025432869

Epoch: 5| Step: 1
Training loss: 2.946296345439706
Validation loss: 2.52308406302099

Epoch: 5| Step: 2
Training loss: 2.5099391773347173
Validation loss: 2.5368701682763386

Epoch: 5| Step: 3
Training loss: 2.839499010572548
Validation loss: 2.5493971757738065

Epoch: 5| Step: 4
Training loss: 3.375772175934489
Validation loss: 2.551681575999909

Epoch: 5| Step: 5
Training loss: 2.7785064366753303
Validation loss: 2.5434645569892798

Epoch: 5| Step: 6
Training loss: 2.585126490348171
Validation loss: 2.540140215748726

Epoch: 5| Step: 7
Training loss: 3.068392786806868
Validation loss: 2.5471567007829417

Epoch: 5| Step: 8
Training loss: 2.8784348245504137
Validation loss: 2.540344219193735

Epoch: 5| Step: 9
Training loss: 3.2699066274768445
Validation loss: 2.5267350252002876

Epoch: 5| Step: 10
Training loss: 2.74438883789021
Validation loss: 2.525234758706736

Epoch: 88| Step: 0
Training loss: 2.8821135710046946
Validation loss: 2.5220008655936725

Epoch: 5| Step: 1
Training loss: 2.903633334328246
Validation loss: 2.51308959343195

Epoch: 5| Step: 2
Training loss: 2.6840606683051296
Validation loss: 2.514784024027303

Epoch: 5| Step: 3
Training loss: 2.757616938500414
Validation loss: 2.51132514911366

Epoch: 5| Step: 4
Training loss: 2.935195018521415
Validation loss: 2.5064220175185805

Epoch: 5| Step: 5
Training loss: 2.8304607377556175
Validation loss: 2.5012805602111245

Epoch: 5| Step: 6
Training loss: 2.8023380225245083
Validation loss: 2.5078127105858985

Epoch: 5| Step: 7
Training loss: 2.8985472295919714
Validation loss: 2.516474420476221

Epoch: 5| Step: 8
Training loss: 2.797835882918543
Validation loss: 2.520270409237756

Epoch: 5| Step: 9
Training loss: 3.0431567857499964
Validation loss: 2.5390183150088834

Epoch: 5| Step: 10
Training loss: 3.235392829592689
Validation loss: 2.542178128923546

Epoch: 89| Step: 0
Training loss: 3.01757622876154
Validation loss: 2.551544369276217

Epoch: 5| Step: 1
Training loss: 2.9593392036633563
Validation loss: 2.5803170101917594

Epoch: 5| Step: 2
Training loss: 2.189314498392105
Validation loss: 2.5848604670850226

Epoch: 5| Step: 3
Training loss: 2.8071244472508723
Validation loss: 2.576339916096998

Epoch: 5| Step: 4
Training loss: 2.9643393427976177
Validation loss: 2.5760580996166573

Epoch: 5| Step: 5
Training loss: 3.0299701938485057
Validation loss: 2.566147971616238

Epoch: 5| Step: 6
Training loss: 2.795173425770404
Validation loss: 2.5142108190859043

Epoch: 5| Step: 7
Training loss: 2.9033707333012493
Validation loss: 2.4948089274976644

Epoch: 5| Step: 8
Training loss: 2.833755873045958
Validation loss: 2.4859867822971227

Epoch: 5| Step: 9
Training loss: 3.0031913630906515
Validation loss: 2.4912422530568934

Epoch: 5| Step: 10
Training loss: 3.0891008991176054
Validation loss: 2.4918852417160644

Epoch: 90| Step: 0
Training loss: 2.7507089221289456
Validation loss: 2.496718015151638

Epoch: 5| Step: 1
Training loss: 2.3843688884771774
Validation loss: 2.495779302646553

Epoch: 5| Step: 2
Training loss: 2.5529356383157347
Validation loss: 2.496330208306108

Epoch: 5| Step: 3
Training loss: 3.5150740128127826
Validation loss: 2.495435212244882

Epoch: 5| Step: 4
Training loss: 2.9074132088641336
Validation loss: 2.499397085152387

Epoch: 5| Step: 5
Training loss: 3.0575505958793725
Validation loss: 2.4948989119286877

Epoch: 5| Step: 6
Training loss: 2.5474383895356967
Validation loss: 2.49431889056146

Epoch: 5| Step: 7
Training loss: 3.075986787586583
Validation loss: 2.49676879318519

Epoch: 5| Step: 8
Training loss: 3.032119468972338
Validation loss: 2.5048624404993203

Epoch: 5| Step: 9
Training loss: 3.189034784356383
Validation loss: 2.5168643783160682

Epoch: 5| Step: 10
Training loss: 2.554618624537427
Validation loss: 2.514200562303316

Epoch: 91| Step: 0
Training loss: 2.704192904289714
Validation loss: 2.521026691033889

Epoch: 5| Step: 1
Training loss: 2.85946004772341
Validation loss: 2.5257026129358726

Epoch: 5| Step: 2
Training loss: 2.5457309891711013
Validation loss: 2.5271458737651793

Epoch: 5| Step: 3
Training loss: 2.7164309026846345
Validation loss: 2.5222748292930497

Epoch: 5| Step: 4
Training loss: 2.513025777281541
Validation loss: 2.5114451950462575

Epoch: 5| Step: 5
Training loss: 2.8050062588164595
Validation loss: 2.4869419147725487

Epoch: 5| Step: 6
Training loss: 2.7015305596091177
Validation loss: 2.4779686567129255

Epoch: 5| Step: 7
Training loss: 3.335493071564764
Validation loss: 2.48297997131486

Epoch: 5| Step: 8
Training loss: 3.3845268292946553
Validation loss: 2.4870932767348757

Epoch: 5| Step: 9
Training loss: 3.2302257810874084
Validation loss: 2.487541321689353

Epoch: 5| Step: 10
Training loss: 2.476495784017331
Validation loss: 2.4942697410707955

Epoch: 92| Step: 0
Training loss: 3.0718622154986543
Validation loss: 2.5014979581574717

Epoch: 5| Step: 1
Training loss: 2.750580986379837
Validation loss: 2.5079337802383868

Epoch: 5| Step: 2
Training loss: 2.962872921935412
Validation loss: 2.5060360069795085

Epoch: 5| Step: 3
Training loss: 3.3318384792292024
Validation loss: 2.5078522544196256

Epoch: 5| Step: 4
Training loss: 2.8320625671759823
Validation loss: 2.5214390411334215

Epoch: 5| Step: 5
Training loss: 2.8494560927331487
Validation loss: 2.523919802116783

Epoch: 5| Step: 6
Training loss: 3.0899502317500818
Validation loss: 2.5194309319896138

Epoch: 5| Step: 7
Training loss: 2.852018972989142
Validation loss: 2.5188108670500604

Epoch: 5| Step: 8
Training loss: 2.8078584305323986
Validation loss: 2.523292268356672

Epoch: 5| Step: 9
Training loss: 2.665685522861467
Validation loss: 2.5448437634683514

Epoch: 5| Step: 10
Training loss: 2.3637390197789365
Validation loss: 2.5642454064166524

Epoch: 93| Step: 0
Training loss: 3.0360641790750886
Validation loss: 2.59116984196658

Epoch: 5| Step: 1
Training loss: 2.920701877685052
Validation loss: 2.6330609522499873

Epoch: 5| Step: 2
Training loss: 2.8267355187445693
Validation loss: 2.6390715008215837

Epoch: 5| Step: 3
Training loss: 2.7262961358631537
Validation loss: 2.63337618475063

Epoch: 5| Step: 4
Training loss: 3.04354316274971
Validation loss: 2.6020831170696086

Epoch: 5| Step: 5
Training loss: 2.1701446885773197
Validation loss: 2.5517693589935657

Epoch: 5| Step: 6
Training loss: 2.4006191607351877
Validation loss: 2.526708255692541

Epoch: 5| Step: 7
Training loss: 2.7771514525552417
Validation loss: 2.516031888517415

Epoch: 5| Step: 8
Training loss: 3.2379801095937126
Validation loss: 2.5066227570209136

Epoch: 5| Step: 9
Training loss: 3.2018310910813876
Validation loss: 2.513143460032371

Epoch: 5| Step: 10
Training loss: 3.272782799702467
Validation loss: 2.537983203374629

Epoch: 94| Step: 0
Training loss: 2.693145234445164
Validation loss: 2.5695837569742026

Epoch: 5| Step: 1
Training loss: 3.1059596027662875
Validation loss: 2.6152180475411204

Epoch: 5| Step: 2
Training loss: 3.025369977788244
Validation loss: 2.592470123370114

Epoch: 5| Step: 3
Training loss: 3.205048072204472
Validation loss: 2.5369855182071777

Epoch: 5| Step: 4
Training loss: 3.3482316545308426
Validation loss: 2.52370084120399

Epoch: 5| Step: 5
Training loss: 2.999039337205492
Validation loss: 2.522943602093398

Epoch: 5| Step: 6
Training loss: 3.3369296383068585
Validation loss: 2.520292597510418

Epoch: 5| Step: 7
Training loss: 2.5055893405385508
Validation loss: 2.512918612244698

Epoch: 5| Step: 8
Training loss: 2.5389936701908664
Validation loss: 2.5056628725490575

Epoch: 5| Step: 9
Training loss: 2.2111914391146277
Validation loss: 2.504152035161562

Epoch: 5| Step: 10
Training loss: 2.6777980360036033
Validation loss: 2.5034594995158126

Epoch: 95| Step: 0
Training loss: 2.4011340561397647
Validation loss: 2.5174878188227328

Epoch: 5| Step: 1
Training loss: 2.902990009959525
Validation loss: 2.555222171505702

Epoch: 5| Step: 2
Training loss: 2.3016445955861364
Validation loss: 2.5654184723020617

Epoch: 5| Step: 3
Training loss: 3.1999433393230463
Validation loss: 2.5993044983927716

Epoch: 5| Step: 4
Training loss: 2.8410319658929546
Validation loss: 2.5788738735464083

Epoch: 5| Step: 5
Training loss: 3.1948129874406166
Validation loss: 2.566147032534523

Epoch: 5| Step: 6
Training loss: 2.7809631542630426
Validation loss: 2.53850204352895

Epoch: 5| Step: 7
Training loss: 2.8875344740886284
Validation loss: 2.527896520719526

Epoch: 5| Step: 8
Training loss: 2.988647757599806
Validation loss: 2.5159765257919107

Epoch: 5| Step: 9
Training loss: 3.1507319190422067
Validation loss: 2.496162270463669

Epoch: 5| Step: 10
Training loss: 2.7806532144519114
Validation loss: 2.4959896726541215

Epoch: 96| Step: 0
Training loss: 3.028899864680044
Validation loss: 2.4916603718251915

Epoch: 5| Step: 1
Training loss: 2.4760874584448094
Validation loss: 2.492182955328038

Epoch: 5| Step: 2
Training loss: 3.2076833157324494
Validation loss: 2.4909179058250093

Epoch: 5| Step: 3
Training loss: 2.926013321069835
Validation loss: 2.492434039635008

Epoch: 5| Step: 4
Training loss: 2.567976611954852
Validation loss: 2.493401769231661

Epoch: 5| Step: 5
Training loss: 3.2230092728043784
Validation loss: 2.4930009533063355

Epoch: 5| Step: 6
Training loss: 3.4172044346323927
Validation loss: 2.4968290728546654

Epoch: 5| Step: 7
Training loss: 2.7485947052723723
Validation loss: 2.4871263572680924

Epoch: 5| Step: 8
Training loss: 2.6400591904333695
Validation loss: 2.4847423776893116

Epoch: 5| Step: 9
Training loss: 1.9893303222624938
Validation loss: 2.4865742424259873

Epoch: 5| Step: 10
Training loss: 3.2342651643393863
Validation loss: 2.5101021265081895

Epoch: 97| Step: 0
Training loss: 3.1760648668809104
Validation loss: 2.5298747442856775

Epoch: 5| Step: 1
Training loss: 2.6152093955934568
Validation loss: 2.544264766823464

Epoch: 5| Step: 2
Training loss: 2.810169101799176
Validation loss: 2.536712955785935

Epoch: 5| Step: 3
Training loss: 2.6845518398100348
Validation loss: 2.5377366711768405

Epoch: 5| Step: 4
Training loss: 2.634642103960364
Validation loss: 2.5165507027939467

Epoch: 5| Step: 5
Training loss: 2.787887796018645
Validation loss: 2.5145600906337653

Epoch: 5| Step: 6
Training loss: 3.02936046737733
Validation loss: 2.491155174438035

Epoch: 5| Step: 7
Training loss: 2.745353935506526
Validation loss: 2.4964922774373894

Epoch: 5| Step: 8
Training loss: 3.023387662097315
Validation loss: 2.485358916054052

Epoch: 5| Step: 9
Training loss: 3.0613209537306747
Validation loss: 2.4859000620337417

Epoch: 5| Step: 10
Training loss: 2.80478831670518
Validation loss: 2.5166581155422127

Epoch: 98| Step: 0
Training loss: 2.313184791416791
Validation loss: 2.56084925807792

Epoch: 5| Step: 1
Training loss: 2.8354750747513426
Validation loss: 2.6482160676948836

Epoch: 5| Step: 2
Training loss: 3.2459065995049765
Validation loss: 2.637031505635386

Epoch: 5| Step: 3
Training loss: 3.2584709398590257
Validation loss: 2.649676641763956

Epoch: 5| Step: 4
Training loss: 2.9013213337318193
Validation loss: 2.58491498722976

Epoch: 5| Step: 5
Training loss: 2.86264068391069
Validation loss: 2.5440800379966366

Epoch: 5| Step: 6
Training loss: 2.667741846849482
Validation loss: 2.5135499593022543

Epoch: 5| Step: 7
Training loss: 2.8242118276086496
Validation loss: 2.499982624608848

Epoch: 5| Step: 8
Training loss: 2.7219815396503457
Validation loss: 2.4889136053855627

Epoch: 5| Step: 9
Training loss: 3.0751284812819777
Validation loss: 2.497531527428289

Epoch: 5| Step: 10
Training loss: 2.9956570024728872
Validation loss: 2.494905974289838

Epoch: 99| Step: 0
Training loss: 2.9922928355826732
Validation loss: 2.4987238426312484

Epoch: 5| Step: 1
Training loss: 3.009471723006333
Validation loss: 2.5044412464186476

Epoch: 5| Step: 2
Training loss: 3.0146610913445153
Validation loss: 2.510816194500523

Epoch: 5| Step: 3
Training loss: 2.622204154521673
Validation loss: 2.509184035912228

Epoch: 5| Step: 4
Training loss: 2.877103119233583
Validation loss: 2.501086232870043

Epoch: 5| Step: 5
Training loss: 2.8850019870797494
Validation loss: 2.5004623703332665

Epoch: 5| Step: 6
Training loss: 2.535551678070141
Validation loss: 2.498444264887913

Epoch: 5| Step: 7
Training loss: 3.1012537728117167
Validation loss: 2.49834684349729

Epoch: 5| Step: 8
Training loss: 2.533742172311925
Validation loss: 2.4976380480845224

Epoch: 5| Step: 9
Training loss: 3.243473248445084
Validation loss: 2.505818442096661

Epoch: 5| Step: 10
Training loss: 2.7872320414163143
Validation loss: 2.531557889580534

Epoch: 100| Step: 0
Training loss: 2.745689742212682
Validation loss: 2.5867171069503483

Epoch: 5| Step: 1
Training loss: 3.069732533586402
Validation loss: 2.607377975332124

Epoch: 5| Step: 2
Training loss: 2.6857694332496007
Validation loss: 2.6138886389754163

Epoch: 5| Step: 3
Training loss: 3.4656971737335063
Validation loss: 2.6544629295505806

Epoch: 5| Step: 4
Training loss: 2.3427715039135935
Validation loss: 2.5904021200608454

Epoch: 5| Step: 5
Training loss: 3.0703932579232878
Validation loss: 2.56726723160935

Epoch: 5| Step: 6
Training loss: 2.5090103853633376
Validation loss: 2.5374091367255946

Epoch: 5| Step: 7
Training loss: 2.5299402309791157
Validation loss: 2.5229244642138124

Epoch: 5| Step: 8
Training loss: 2.737760878024986
Validation loss: 2.510502977452904

Epoch: 5| Step: 9
Training loss: 2.991741256704916
Validation loss: 2.495583464187572

Epoch: 5| Step: 10
Training loss: 3.276001865810287
Validation loss: 2.492278635485009

Epoch: 101| Step: 0
Training loss: 3.1714556938347007
Validation loss: 2.491492488610542

Epoch: 5| Step: 1
Training loss: 3.281734612418441
Validation loss: 2.4890688189757255

Epoch: 5| Step: 2
Training loss: 2.5450637086939563
Validation loss: 2.4805177977821162

Epoch: 5| Step: 3
Training loss: 2.735279740109379
Validation loss: 2.485108470368791

Epoch: 5| Step: 4
Training loss: 2.716350329495227
Validation loss: 2.482698045488518

Epoch: 5| Step: 5
Training loss: 2.459427821599114
Validation loss: 2.4870988635444933

Epoch: 5| Step: 6
Training loss: 2.977691196097064
Validation loss: 2.4802882538304054

Epoch: 5| Step: 7
Training loss: 2.637795190427848
Validation loss: 2.482551103845036

Epoch: 5| Step: 8
Training loss: 3.3244509767132713
Validation loss: 2.4900065308776913

Epoch: 5| Step: 9
Training loss: 2.7538870303518155
Validation loss: 2.484107984187735

Epoch: 5| Step: 10
Training loss: 2.5252405108734393
Validation loss: 2.48856364559373

Epoch: 102| Step: 0
Training loss: 3.0843518782872743
Validation loss: 2.5044837940726747

Epoch: 5| Step: 1
Training loss: 2.5883522399323176
Validation loss: 2.501081541390781

Epoch: 5| Step: 2
Training loss: 3.047365745735364
Validation loss: 2.5241918528126304

Epoch: 5| Step: 3
Training loss: 2.446819292118834
Validation loss: 2.5247715881120114

Epoch: 5| Step: 4
Training loss: 2.7269754616249196
Validation loss: 2.5286016309033315

Epoch: 5| Step: 5
Training loss: 2.843159373225078
Validation loss: 2.521674979191407

Epoch: 5| Step: 6
Training loss: 2.5259012294677343
Validation loss: 2.5012636098405174

Epoch: 5| Step: 7
Training loss: 2.9456864582516498
Validation loss: 2.4906407538814985

Epoch: 5| Step: 8
Training loss: 2.755021971737848
Validation loss: 2.4917331090630044

Epoch: 5| Step: 9
Training loss: 2.7848339349076863
Validation loss: 2.482723940963276

Epoch: 5| Step: 10
Training loss: 3.4569378683980356
Validation loss: 2.4803292855790295

Epoch: 103| Step: 0
Training loss: 2.9243819146136727
Validation loss: 2.4845372721852406

Epoch: 5| Step: 1
Training loss: 2.9419661314549375
Validation loss: 2.4791845078178376

Epoch: 5| Step: 2
Training loss: 2.6220987726865603
Validation loss: 2.4734956542918236

Epoch: 5| Step: 3
Training loss: 2.3677439019993956
Validation loss: 2.4762148737522467

Epoch: 5| Step: 4
Training loss: 2.562657607279208
Validation loss: 2.479515603495191

Epoch: 5| Step: 5
Training loss: 3.419361602360914
Validation loss: 2.4788332437719998

Epoch: 5| Step: 6
Training loss: 2.7231370454862818
Validation loss: 2.478102735876571

Epoch: 5| Step: 7
Training loss: 3.0120119578008895
Validation loss: 2.4771747809819717

Epoch: 5| Step: 8
Training loss: 3.088110050365191
Validation loss: 2.472339381663812

Epoch: 5| Step: 9
Training loss: 2.6526826127998215
Validation loss: 2.475326963297867

Epoch: 5| Step: 10
Training loss: 2.8028420670185694
Validation loss: 2.477575752495307

Epoch: 104| Step: 0
Training loss: 2.727474289728347
Validation loss: 2.482910249692557

Epoch: 5| Step: 1
Training loss: 3.400389783619224
Validation loss: 2.4827125411225097

Epoch: 5| Step: 2
Training loss: 2.7273752482247295
Validation loss: 2.485641140342931

Epoch: 5| Step: 3
Training loss: 3.1151725356323063
Validation loss: 2.4921002548407025

Epoch: 5| Step: 4
Training loss: 2.6076095913526447
Validation loss: 2.5417579518155713

Epoch: 5| Step: 5
Training loss: 2.8574617582550665
Validation loss: 2.6128052536832116

Epoch: 5| Step: 6
Training loss: 2.6380170776300287
Validation loss: 2.632606351974525

Epoch: 5| Step: 7
Training loss: 2.748121660485146
Validation loss: 2.6468373639043103

Epoch: 5| Step: 8
Training loss: 2.4152219882766532
Validation loss: 2.738707735436426

Epoch: 5| Step: 9
Training loss: 3.077315790534083
Validation loss: 2.7046423859370803

Epoch: 5| Step: 10
Training loss: 3.2413821771389326
Validation loss: 2.620417494207026

Epoch: 105| Step: 0
Training loss: 3.1937341499308562
Validation loss: 2.5474770536015936

Epoch: 5| Step: 1
Training loss: 2.312489689984407
Validation loss: 2.513044450383144

Epoch: 5| Step: 2
Training loss: 2.867995977103632
Validation loss: 2.4987326152576586

Epoch: 5| Step: 3
Training loss: 3.154069203761112
Validation loss: 2.4909828904176887

Epoch: 5| Step: 4
Training loss: 2.824184306714244
Validation loss: 2.481415227747587

Epoch: 5| Step: 5
Training loss: 2.735095207189124
Validation loss: 2.4713856117746893

Epoch: 5| Step: 6
Training loss: 2.455529947516551
Validation loss: 2.4655654563364835

Epoch: 5| Step: 7
Training loss: 2.9742049044303585
Validation loss: 2.4623918029725216

Epoch: 5| Step: 8
Training loss: 3.2229856010681126
Validation loss: 2.4606648716182136

Epoch: 5| Step: 9
Training loss: 2.755170902413781
Validation loss: 2.465092141407152

Epoch: 5| Step: 10
Training loss: 2.3546250383766196
Validation loss: 2.4579575583230793

Epoch: 106| Step: 0
Training loss: 2.9598025761311937
Validation loss: 2.462937398762722

Epoch: 5| Step: 1
Training loss: 2.894725468718166
Validation loss: 2.461574632263882

Epoch: 5| Step: 2
Training loss: 3.5244270508384945
Validation loss: 2.461177632820103

Epoch: 5| Step: 3
Training loss: 3.065708114943873
Validation loss: 2.461996889791316

Epoch: 5| Step: 4
Training loss: 2.5287579172098145
Validation loss: 2.458776508788991

Epoch: 5| Step: 5
Training loss: 2.9881969963612676
Validation loss: 2.4638740183379313

Epoch: 5| Step: 6
Training loss: 2.3709300454453537
Validation loss: 2.461791145129064

Epoch: 5| Step: 7
Training loss: 2.4008719052578678
Validation loss: 2.4661195910426583

Epoch: 5| Step: 8
Training loss: 2.46140364818766
Validation loss: 2.469550526721988

Epoch: 5| Step: 9
Training loss: 3.0181178724402664
Validation loss: 2.478674799402507

Epoch: 5| Step: 10
Training loss: 2.73235590911706
Validation loss: 2.504622057825273

Epoch: 107| Step: 0
Training loss: 3.225773971301806
Validation loss: 2.5347638631956935

Epoch: 5| Step: 1
Training loss: 3.05762373741713
Validation loss: 2.59766227208896

Epoch: 5| Step: 2
Training loss: 3.1001016169474815
Validation loss: 2.6981584145515107

Epoch: 5| Step: 3
Training loss: 2.7286146251109527
Validation loss: 2.737497650683396

Epoch: 5| Step: 4
Training loss: 2.5175341830920805
Validation loss: 2.669079528884361

Epoch: 5| Step: 5
Training loss: 3.2051818198585944
Validation loss: 2.6034393295675207

Epoch: 5| Step: 6
Training loss: 2.388362337332514
Validation loss: 2.5251574168829314

Epoch: 5| Step: 7
Training loss: 2.990095477924083
Validation loss: 2.4683552004849587

Epoch: 5| Step: 8
Training loss: 2.3655659878625515
Validation loss: 2.4636404085371537

Epoch: 5| Step: 9
Training loss: 3.0343462674541595
Validation loss: 2.475160237413384

Epoch: 5| Step: 10
Training loss: 3.2635650708605035
Validation loss: 2.4938802572374184

Epoch: 108| Step: 0
Training loss: 3.192141575419927
Validation loss: 2.48633439714331

Epoch: 5| Step: 1
Training loss: 3.14094093973087
Validation loss: 2.493976008993351

Epoch: 5| Step: 2
Training loss: 2.9448575343855175
Validation loss: 2.494572777173128

Epoch: 5| Step: 3
Training loss: 2.748186380387556
Validation loss: 2.4922175997559926

Epoch: 5| Step: 4
Training loss: 2.7396135993320336
Validation loss: 2.491131031702423

Epoch: 5| Step: 5
Training loss: 2.504105249075946
Validation loss: 2.4886841240095627

Epoch: 5| Step: 6
Training loss: 3.48555212280193
Validation loss: 2.490927292067121

Epoch: 5| Step: 7
Training loss: 2.7804871273692866
Validation loss: 2.483436120711173

Epoch: 5| Step: 8
Training loss: 2.4771969340599402
Validation loss: 2.4830552362967753

Epoch: 5| Step: 9
Training loss: 2.785436158740923
Validation loss: 2.4809594962510544

Epoch: 5| Step: 10
Training loss: 2.966535364595705
Validation loss: 2.4787487874960914

Epoch: 109| Step: 0
Training loss: 3.0075919726888034
Validation loss: 2.472178654503626

Epoch: 5| Step: 1
Training loss: 2.675577197682638
Validation loss: 2.4768848457200874

Epoch: 5| Step: 2
Training loss: 2.978928954415345
Validation loss: 2.4792019545195543

Epoch: 5| Step: 3
Training loss: 2.8091156836671667
Validation loss: 2.479415093833101

Epoch: 5| Step: 4
Training loss: 2.330762866467408
Validation loss: 2.4872588677438805

Epoch: 5| Step: 5
Training loss: 2.99237458363817
Validation loss: 2.4890814302856255

Epoch: 5| Step: 6
Training loss: 2.7893250926803512
Validation loss: 2.4907219702375634

Epoch: 5| Step: 7
Training loss: 2.505893151047457
Validation loss: 2.510947866247597

Epoch: 5| Step: 8
Training loss: 3.1288106953749497
Validation loss: 2.529174327364023

Epoch: 5| Step: 9
Training loss: 3.347886850967685
Validation loss: 2.574566919736666

Epoch: 5| Step: 10
Training loss: 2.413059063109153
Validation loss: 2.587721267393474

Epoch: 110| Step: 0
Training loss: 3.6419604557578205
Validation loss: 2.5813387680849917

Epoch: 5| Step: 1
Training loss: 2.929476229361412
Validation loss: 2.524476240133413

Epoch: 5| Step: 2
Training loss: 2.9645516675132293
Validation loss: 2.490080353173875

Epoch: 5| Step: 3
Training loss: 2.9991534946156286
Validation loss: 2.4784927131145063

Epoch: 5| Step: 4
Training loss: 2.3817682698464933
Validation loss: 2.4580059768633595

Epoch: 5| Step: 5
Training loss: 2.740202095347339
Validation loss: 2.454648482942364

Epoch: 5| Step: 6
Training loss: 3.0535016892451763
Validation loss: 2.4578415952591097

Epoch: 5| Step: 7
Training loss: 2.3935546875
Validation loss: 2.459806031556806

Epoch: 5| Step: 8
Training loss: 2.536068415714724
Validation loss: 2.4617051127517744

Epoch: 5| Step: 9
Training loss: 2.7806908549053415
Validation loss: 2.4549119610697065

Epoch: 5| Step: 10
Training loss: 2.853201951392023
Validation loss: 2.449774518120787

Epoch: 111| Step: 0
Training loss: 2.798426192626601
Validation loss: 2.4473638018001984

Epoch: 5| Step: 1
Training loss: 3.071801831449942
Validation loss: 2.4452027961293137

Epoch: 5| Step: 2
Training loss: 2.462178332237531
Validation loss: 2.451901543753662

Epoch: 5| Step: 3
Training loss: 3.092796718267682
Validation loss: 2.467450846948111

Epoch: 5| Step: 4
Training loss: 3.230030329889618
Validation loss: 2.4797307075400985

Epoch: 5| Step: 5
Training loss: 2.4184447576441284
Validation loss: 2.5349006088476385

Epoch: 5| Step: 6
Training loss: 3.2313521998049937
Validation loss: 2.582779288711329

Epoch: 5| Step: 7
Training loss: 2.349245977164666
Validation loss: 2.5707293981263977

Epoch: 5| Step: 8
Training loss: 3.158117214112505
Validation loss: 2.529702781585434

Epoch: 5| Step: 9
Training loss: 2.521214501013277
Validation loss: 2.485029872469535

Epoch: 5| Step: 10
Training loss: 2.7523103892253316
Validation loss: 2.4791055504440562

Epoch: 112| Step: 0
Training loss: 2.764325542451699
Validation loss: 2.455412669113985

Epoch: 5| Step: 1
Training loss: 3.038870131182696
Validation loss: 2.451579265128936

Epoch: 5| Step: 2
Training loss: 3.268918799277824
Validation loss: 2.4673027333315236

Epoch: 5| Step: 3
Training loss: 3.41471915837042
Validation loss: 2.476534529794872

Epoch: 5| Step: 4
Training loss: 2.551423673946969
Validation loss: 2.4893419750553183

Epoch: 5| Step: 5
Training loss: 2.4085616860372867
Validation loss: 2.4855040713144683

Epoch: 5| Step: 6
Training loss: 2.7310149556507892
Validation loss: 2.4694743757154507

Epoch: 5| Step: 7
Training loss: 2.4953350412476905
Validation loss: 2.4686182739039704

Epoch: 5| Step: 8
Training loss: 2.9089851224695225
Validation loss: 2.4642779894458275

Epoch: 5| Step: 9
Training loss: 2.605730080831549
Validation loss: 2.4579100170490253

Epoch: 5| Step: 10
Training loss: 3.2483630826425185
Validation loss: 2.451039604798821

Epoch: 113| Step: 0
Training loss: 2.5453854751195277
Validation loss: 2.4607348786913565

Epoch: 5| Step: 1
Training loss: 2.9794300914333887
Validation loss: 2.459293029722544

Epoch: 5| Step: 2
Training loss: 2.438824807119063
Validation loss: 2.477234660380615

Epoch: 5| Step: 3
Training loss: 2.3990523454203525
Validation loss: 2.5011380876336204

Epoch: 5| Step: 4
Training loss: 3.241986151268554
Validation loss: 2.570262626310949

Epoch: 5| Step: 5
Training loss: 3.0282581154427897
Validation loss: 2.522530738765804

Epoch: 5| Step: 6
Training loss: 3.189393920722708
Validation loss: 2.4954605779722354

Epoch: 5| Step: 7
Training loss: 2.697160435641228
Validation loss: 2.4870958351241588

Epoch: 5| Step: 8
Training loss: 2.829798250858878
Validation loss: 2.481642820379971

Epoch: 5| Step: 9
Training loss: 2.7024821139863286
Validation loss: 2.4752433164206034

Epoch: 5| Step: 10
Training loss: 3.000311994223785
Validation loss: 2.4689150000029163

Epoch: 114| Step: 0
Training loss: 2.912336313780644
Validation loss: 2.4607960097941044

Epoch: 5| Step: 1
Training loss: 2.8488602885799184
Validation loss: 2.4570339523773486

Epoch: 5| Step: 2
Training loss: 2.8968292463160497
Validation loss: 2.459248091200556

Epoch: 5| Step: 3
Training loss: 2.589656495103989
Validation loss: 2.464068874971724

Epoch: 5| Step: 4
Training loss: 2.90361412042426
Validation loss: 2.459564126826745

Epoch: 5| Step: 5
Training loss: 2.688828250982433
Validation loss: 2.4704581462875708

Epoch: 5| Step: 6
Training loss: 2.544127029108507
Validation loss: 2.4894503290482666

Epoch: 5| Step: 7
Training loss: 2.871552099893426
Validation loss: 2.483554243508444

Epoch: 5| Step: 8
Training loss: 3.1863947429382797
Validation loss: 2.481255967745273

Epoch: 5| Step: 9
Training loss: 2.7974357682150304
Validation loss: 2.4815950386400334

Epoch: 5| Step: 10
Training loss: 2.869852516558451
Validation loss: 2.475053221684608

Epoch: 115| Step: 0
Training loss: 2.8751243896112224
Validation loss: 2.470865295916712

Epoch: 5| Step: 1
Training loss: 2.756308775121586
Validation loss: 2.470653169519197

Epoch: 5| Step: 2
Training loss: 2.5017642471763217
Validation loss: 2.4677604321320037

Epoch: 5| Step: 3
Training loss: 3.134683787385805
Validation loss: 2.462087078005593

Epoch: 5| Step: 4
Training loss: 2.493203461302483
Validation loss: 2.4646595975696752

Epoch: 5| Step: 5
Training loss: 3.332016796156737
Validation loss: 2.4643933921751953

Epoch: 5| Step: 6
Training loss: 2.664047464904421
Validation loss: 2.469196775006691

Epoch: 5| Step: 7
Training loss: 2.7039786517863647
Validation loss: 2.4753546436977407

Epoch: 5| Step: 8
Training loss: 3.0613410469494093
Validation loss: 2.49088711005727

Epoch: 5| Step: 9
Training loss: 2.5601302563788555
Validation loss: 2.5175009267695136

Epoch: 5| Step: 10
Training loss: 2.8508149303684927
Validation loss: 2.534933578243336

Epoch: 116| Step: 0
Training loss: 2.4573504751514488
Validation loss: 2.5442760964270104

Epoch: 5| Step: 1
Training loss: 2.8904121939192056
Validation loss: 2.5753404382905933

Epoch: 5| Step: 2
Training loss: 2.916051763475413
Validation loss: 2.57093563655762

Epoch: 5| Step: 3
Training loss: 3.215547171819561
Validation loss: 2.557556823459911

Epoch: 5| Step: 4
Training loss: 2.88651622841266
Validation loss: 2.524156499560179

Epoch: 5| Step: 5
Training loss: 2.792059647718153
Validation loss: 2.4969009818820176

Epoch: 5| Step: 6
Training loss: 1.9435684168348613
Validation loss: 2.480601198592359

Epoch: 5| Step: 7
Training loss: 2.7956499368368597
Validation loss: 2.4665774423491946

Epoch: 5| Step: 8
Training loss: 3.020814215939418
Validation loss: 2.45147512799117

Epoch: 5| Step: 9
Training loss: 3.405512038618895
Validation loss: 2.4476094245316764

Epoch: 5| Step: 10
Training loss: 2.539468679951111
Validation loss: 2.4467848462392126

Epoch: 117| Step: 0
Training loss: 2.609869995679506
Validation loss: 2.4446628985049736

Epoch: 5| Step: 1
Training loss: 3.312225618334737
Validation loss: 2.4456623184542994

Epoch: 5| Step: 2
Training loss: 2.6999912509070034
Validation loss: 2.4474552106215133

Epoch: 5| Step: 3
Training loss: 2.5862246812011622
Validation loss: 2.4474677430673446

Epoch: 5| Step: 4
Training loss: 2.9739796403343193
Validation loss: 2.4523229333496186

Epoch: 5| Step: 5
Training loss: 2.7451709482851587
Validation loss: 2.472175926164304

Epoch: 5| Step: 6
Training loss: 2.644986495216089
Validation loss: 2.471005125377994

Epoch: 5| Step: 7
Training loss: 2.9664808736622104
Validation loss: 2.475965202249369

Epoch: 5| Step: 8
Training loss: 2.6189616552504855
Validation loss: 2.4842149854906994

Epoch: 5| Step: 9
Training loss: 3.011348083089508
Validation loss: 2.4716512959011565

Epoch: 5| Step: 10
Training loss: 2.742133506830221
Validation loss: 2.465342337443611

Epoch: 118| Step: 0
Training loss: 2.986035269629233
Validation loss: 2.4704793893359076

Epoch: 5| Step: 1
Training loss: 3.204006464557579
Validation loss: 2.470599704704865

Epoch: 5| Step: 2
Training loss: 3.008108307795892
Validation loss: 2.463815505588523

Epoch: 5| Step: 3
Training loss: 2.537600991630601
Validation loss: 2.4678133216555103

Epoch: 5| Step: 4
Training loss: 2.6876712123537976
Validation loss: 2.4819027489962444

Epoch: 5| Step: 5
Training loss: 2.769549672397738
Validation loss: 2.503608688363981

Epoch: 5| Step: 6
Training loss: 2.7714370605215137
Validation loss: 2.5050919196406833

Epoch: 5| Step: 7
Training loss: 2.499546486727691
Validation loss: 2.507151921545403

Epoch: 5| Step: 8
Training loss: 2.2884660275692053
Validation loss: 2.4824785292382776

Epoch: 5| Step: 9
Training loss: 2.8507376536043676
Validation loss: 2.467289758212508

Epoch: 5| Step: 10
Training loss: 3.118598178998183
Validation loss: 2.457833528331912

Epoch: 119| Step: 0
Training loss: 2.8715824878979617
Validation loss: 2.456882647015365

Epoch: 5| Step: 1
Training loss: 2.480422805000176
Validation loss: 2.451163336390849

Epoch: 5| Step: 2
Training loss: 2.8418946973605883
Validation loss: 2.4522037692700502

Epoch: 5| Step: 3
Training loss: 2.938089839073309
Validation loss: 2.449102771978754

Epoch: 5| Step: 4
Training loss: 2.9698988448362296
Validation loss: 2.451004614714546

Epoch: 5| Step: 5
Training loss: 2.8325312732071097
Validation loss: 2.4600936304844407

Epoch: 5| Step: 6
Training loss: 2.513010028295397
Validation loss: 2.465310448000582

Epoch: 5| Step: 7
Training loss: 2.8075672549907664
Validation loss: 2.4709155490291326

Epoch: 5| Step: 8
Training loss: 3.002896182485849
Validation loss: 2.469028322734017

Epoch: 5| Step: 9
Training loss: 2.891421811366781
Validation loss: 2.4813689634639777

Epoch: 5| Step: 10
Training loss: 2.7221793108648242
Validation loss: 2.510519906288099

Epoch: 120| Step: 0
Training loss: 3.1651079122698924
Validation loss: 2.514831942282175

Epoch: 5| Step: 1
Training loss: 2.8016779912492424
Validation loss: 2.5248652403244014

Epoch: 5| Step: 2
Training loss: 2.5224293682088583
Validation loss: 2.5167442842637944

Epoch: 5| Step: 3
Training loss: 2.5438092274062165
Validation loss: 2.5017464239300033

Epoch: 5| Step: 4
Training loss: 3.2366902638553077
Validation loss: 2.49566878169863

Epoch: 5| Step: 5
Training loss: 2.429792886392616
Validation loss: 2.4902980010534073

Epoch: 5| Step: 6
Training loss: 2.612333436611664
Validation loss: 2.5217286197015105

Epoch: 5| Step: 7
Training loss: 3.2532512834499956
Validation loss: 2.5217399992157383

Epoch: 5| Step: 8
Training loss: 3.028780058720673
Validation loss: 2.5254533298008104

Epoch: 5| Step: 9
Training loss: 2.2771600089698167
Validation loss: 2.4796966361302646

Epoch: 5| Step: 10
Training loss: 2.531172668782814
Validation loss: 2.4642327548245575

Epoch: 121| Step: 0
Training loss: 1.9700247255700372
Validation loss: 2.452193841195196

Epoch: 5| Step: 1
Training loss: 2.295551152089169
Validation loss: 2.4470631539461403

Epoch: 5| Step: 2
Training loss: 3.3126905854297535
Validation loss: 2.4409797521033054

Epoch: 5| Step: 3
Training loss: 3.364204519262216
Validation loss: 2.443959731307628

Epoch: 5| Step: 4
Training loss: 3.0688289717634265
Validation loss: 2.446495286168157

Epoch: 5| Step: 5
Training loss: 2.992386694271273
Validation loss: 2.4451408736184237

Epoch: 5| Step: 6
Training loss: 2.956926593415064
Validation loss: 2.443734384312759

Epoch: 5| Step: 7
Training loss: 2.931372724944965
Validation loss: 2.4454269290671884

Epoch: 5| Step: 8
Training loss: 2.7389874601992807
Validation loss: 2.4466098254736455

Epoch: 5| Step: 9
Training loss: 2.219780051530523
Validation loss: 2.452245255255868

Epoch: 5| Step: 10
Training loss: 2.5659351119640212
Validation loss: 2.4605375533645653

Epoch: 122| Step: 0
Training loss: 2.6754028943839154
Validation loss: 2.465387056216396

Epoch: 5| Step: 1
Training loss: 3.3953854942287403
Validation loss: 2.4827699073988474

Epoch: 5| Step: 2
Training loss: 2.7542810928959454
Validation loss: 2.4870362699438884

Epoch: 5| Step: 3
Training loss: 2.511216939629729
Validation loss: 2.516500992208929

Epoch: 5| Step: 4
Training loss: 2.704829477939455
Validation loss: 2.540250457948259

Epoch: 5| Step: 5
Training loss: 2.8782174724091725
Validation loss: 2.554368062510399

Epoch: 5| Step: 6
Training loss: 2.6320341414234454
Validation loss: 2.5736810602331537

Epoch: 5| Step: 7
Training loss: 2.2890396898194236
Validation loss: 2.5308998956572166

Epoch: 5| Step: 8
Training loss: 2.983178343201048
Validation loss: 2.5291146777234723

Epoch: 5| Step: 9
Training loss: 3.2418818685952697
Validation loss: 2.5078576452253785

Epoch: 5| Step: 10
Training loss: 2.3972267300634726
Validation loss: 2.4725516464543085

Epoch: 123| Step: 0
Training loss: 2.5935715763355995
Validation loss: 2.45667099231673

Epoch: 5| Step: 1
Training loss: 2.5311601410916444
Validation loss: 2.451058558206285

Epoch: 5| Step: 2
Training loss: 2.889316572010741
Validation loss: 2.4535156413419945

Epoch: 5| Step: 3
Training loss: 2.947578186085305
Validation loss: 2.4488104123172483

Epoch: 5| Step: 4
Training loss: 3.051901715357196
Validation loss: 2.4604540715810983

Epoch: 5| Step: 5
Training loss: 2.6905781173609022
Validation loss: 2.465605646546645

Epoch: 5| Step: 6
Training loss: 2.680970532629214
Validation loss: 2.4684904540226733

Epoch: 5| Step: 7
Training loss: 2.4817151880313775
Validation loss: 2.464504541223175

Epoch: 5| Step: 8
Training loss: 2.986717383374164
Validation loss: 2.471461402038426

Epoch: 5| Step: 9
Training loss: 2.9303179660163177
Validation loss: 2.4675614671161563

Epoch: 5| Step: 10
Training loss: 2.6891170338803625
Validation loss: 2.5053639570279698

Epoch: 124| Step: 0
Training loss: 2.460245864801117
Validation loss: 2.5209203379813725

Epoch: 5| Step: 1
Training loss: 2.5788105371112313
Validation loss: 2.5372922935081688

Epoch: 5| Step: 2
Training loss: 2.903104330755101
Validation loss: 2.514503484288173

Epoch: 5| Step: 3
Training loss: 3.11122237490953
Validation loss: 2.476387653083623

Epoch: 5| Step: 4
Training loss: 3.015507354813381
Validation loss: 2.4596891034765123

Epoch: 5| Step: 5
Training loss: 2.7108336327082876
Validation loss: 2.459911880030382

Epoch: 5| Step: 6
Training loss: 2.5068999439445077
Validation loss: 2.46208370852819

Epoch: 5| Step: 7
Training loss: 2.5368139081705423
Validation loss: 2.4634195208287135

Epoch: 5| Step: 8
Training loss: 2.481732768793926
Validation loss: 2.464896837314839

Epoch: 5| Step: 9
Training loss: 2.7523125548466782
Validation loss: 2.475215353058766

Epoch: 5| Step: 10
Training loss: 3.5101377261276054
Validation loss: 2.477216042301792

Epoch: 125| Step: 0
Training loss: 2.4669616595854307
Validation loss: 2.4873482698544684

Epoch: 5| Step: 1
Training loss: 3.1187530639878016
Validation loss: 2.517468701586882

Epoch: 5| Step: 2
Training loss: 2.4495065815033787
Validation loss: 2.5541939367920796

Epoch: 5| Step: 3
Training loss: 2.876402968707812
Validation loss: 2.5657444235396247

Epoch: 5| Step: 4
Training loss: 2.6858637952206457
Validation loss: 2.545704842375713

Epoch: 5| Step: 5
Training loss: 3.202797775301703
Validation loss: 2.5175758317955577

Epoch: 5| Step: 6
Training loss: 2.852813864181214
Validation loss: 2.4975650219390557

Epoch: 5| Step: 7
Training loss: 2.9964881050565038
Validation loss: 2.4748282021893426

Epoch: 5| Step: 8
Training loss: 2.7349876371449455
Validation loss: 2.4694804788865627

Epoch: 5| Step: 9
Training loss: 2.3272977037539038
Validation loss: 2.4592001047214747

Epoch: 5| Step: 10
Training loss: 2.596317353492987
Validation loss: 2.4571398915743865

Epoch: 126| Step: 0
Training loss: 2.783954548371557
Validation loss: 2.4585501528468563

Epoch: 5| Step: 1
Training loss: 2.396540783355844
Validation loss: 2.4622104147813593

Epoch: 5| Step: 2
Training loss: 2.8786750193349993
Validation loss: 2.4768618395690485

Epoch: 5| Step: 3
Training loss: 2.699758384631518
Validation loss: 2.5002433084201994

Epoch: 5| Step: 4
Training loss: 3.3708248451104033
Validation loss: 2.5145469877473348

Epoch: 5| Step: 5
Training loss: 2.3953662804067295
Validation loss: 2.545213232831251

Epoch: 5| Step: 6
Training loss: 2.7272896657764507
Validation loss: 2.6072896152879426

Epoch: 5| Step: 7
Training loss: 2.784056629684687
Validation loss: 2.5872832681647613

Epoch: 5| Step: 8
Training loss: 3.1401755547498356
Validation loss: 2.518854958690837

Epoch: 5| Step: 9
Training loss: 3.002190426026633
Validation loss: 2.480144307625006

Epoch: 5| Step: 10
Training loss: 2.0479062809362265
Validation loss: 2.457037309998809

Epoch: 127| Step: 0
Training loss: 2.636161869722978
Validation loss: 2.450820962185586

Epoch: 5| Step: 1
Training loss: 3.106206151395664
Validation loss: 2.4443169644781775

Epoch: 5| Step: 2
Training loss: 2.967397924015774
Validation loss: 2.4470895354681645

Epoch: 5| Step: 3
Training loss: 2.8160786219913705
Validation loss: 2.453734916243757

Epoch: 5| Step: 4
Training loss: 2.348686411160756
Validation loss: 2.4446596256088275

Epoch: 5| Step: 5
Training loss: 2.8006495573826835
Validation loss: 2.455495337763137

Epoch: 5| Step: 6
Training loss: 3.1658442249062206
Validation loss: 2.458635419747034

Epoch: 5| Step: 7
Training loss: 1.8500588021083397
Validation loss: 2.4898452494012835

Epoch: 5| Step: 8
Training loss: 2.6719523636175033
Validation loss: 2.5213442906389174

Epoch: 5| Step: 9
Training loss: 3.1409728203987832
Validation loss: 2.5423060592496456

Epoch: 5| Step: 10
Training loss: 2.938986381911962
Validation loss: 2.592342236337272

Epoch: 128| Step: 0
Training loss: 2.795784764405704
Validation loss: 2.62742840331818

Epoch: 5| Step: 1
Training loss: 2.1748261743999175
Validation loss: 2.6575644216586527

Epoch: 5| Step: 2
Training loss: 2.630186950798114
Validation loss: 2.735163845767999

Epoch: 5| Step: 3
Training loss: 3.272063993662943
Validation loss: 2.7284251839262734

Epoch: 5| Step: 4
Training loss: 2.9653869854969828
Validation loss: 2.6941238300385013

Epoch: 5| Step: 5
Training loss: 2.596950349047413
Validation loss: 2.5839613138973805

Epoch: 5| Step: 6
Training loss: 2.055885574837805
Validation loss: 2.491472310666331

Epoch: 5| Step: 7
Training loss: 2.828881936968325
Validation loss: 2.4542594926654475

Epoch: 5| Step: 8
Training loss: 2.56248883500807
Validation loss: 2.4381557399768505

Epoch: 5| Step: 9
Training loss: 3.4406751360518917
Validation loss: 2.4476937863887827

Epoch: 5| Step: 10
Training loss: 2.968951891007283
Validation loss: 2.4472618077136103

Epoch: 129| Step: 0
Training loss: 2.4883247503433683
Validation loss: 2.4580763725467656

Epoch: 5| Step: 1
Training loss: 2.9889987458181446
Validation loss: 2.4619485393262908

Epoch: 5| Step: 2
Training loss: 2.3081513834648018
Validation loss: 2.454597856060931

Epoch: 5| Step: 3
Training loss: 3.1528313884761037
Validation loss: 2.4494090871725396

Epoch: 5| Step: 4
Training loss: 2.2934442966067836
Validation loss: 2.4472216808014355

Epoch: 5| Step: 5
Training loss: 2.8128778839564417
Validation loss: 2.4415940094971265

Epoch: 5| Step: 6
Training loss: 3.051335439521119
Validation loss: 2.4448031842845537

Epoch: 5| Step: 7
Training loss: 2.87674776109572
Validation loss: 2.459759514566803

Epoch: 5| Step: 8
Training loss: 2.721888167024248
Validation loss: 2.491646279099921

Epoch: 5| Step: 9
Training loss: 3.281860585396269
Validation loss: 2.515432107977529

Epoch: 5| Step: 10
Training loss: 2.3134352365122255
Validation loss: 2.5557195545587383

Epoch: 130| Step: 0
Training loss: 2.78246238086698
Validation loss: 2.586909789289803

Epoch: 5| Step: 1
Training loss: 2.6634116174733107
Validation loss: 2.5751936241092506

Epoch: 5| Step: 2
Training loss: 2.7392766125691757
Validation loss: 2.5773982212229476

Epoch: 5| Step: 3
Training loss: 2.5838758657772423
Validation loss: 2.5510504702901438

Epoch: 5| Step: 4
Training loss: 2.871295034398337
Validation loss: 2.5225922737874287

Epoch: 5| Step: 5
Training loss: 2.804194925136557
Validation loss: 2.519842108713562

Epoch: 5| Step: 6
Training loss: 2.7183975342030426
Validation loss: 2.5052857541268603

Epoch: 5| Step: 7
Training loss: 2.5513460197116706
Validation loss: 2.4966128486736268

Epoch: 5| Step: 8
Training loss: 2.9550676364548663
Validation loss: 2.479369063132753

Epoch: 5| Step: 9
Training loss: 2.6172580083202917
Validation loss: 2.473328487786308

Epoch: 5| Step: 10
Training loss: 3.1036234813503487
Validation loss: 2.470180237888016

Epoch: 131| Step: 0
Training loss: 2.821654784944968
Validation loss: 2.456997644280797

Epoch: 5| Step: 1
Training loss: 2.871337880245754
Validation loss: 2.4545594000721436

Epoch: 5| Step: 2
Training loss: 3.2379580199528606
Validation loss: 2.451536736785342

Epoch: 5| Step: 3
Training loss: 3.0743597403045038
Validation loss: 2.4482412314653526

Epoch: 5| Step: 4
Training loss: 2.23533033741698
Validation loss: 2.4517957760712825

Epoch: 5| Step: 5
Training loss: 3.0143488422154987
Validation loss: 2.453286629572122

Epoch: 5| Step: 6
Training loss: 2.7483374164829337
Validation loss: 2.4619972271676596

Epoch: 5| Step: 7
Training loss: 2.3737832014143363
Validation loss: 2.4757598221079964

Epoch: 5| Step: 8
Training loss: 2.7634141781633934
Validation loss: 2.481383424503002

Epoch: 5| Step: 9
Training loss: 2.2493189734720564
Validation loss: 2.51515030323153

Epoch: 5| Step: 10
Training loss: 2.7380665301758893
Validation loss: 2.561491813187818

Epoch: 132| Step: 0
Training loss: 2.3648238766921814
Validation loss: 2.540283255981578

Epoch: 5| Step: 1
Training loss: 3.012056759718696
Validation loss: 2.5259095641492015

Epoch: 5| Step: 2
Training loss: 2.9402435152578965
Validation loss: 2.5022522256505595

Epoch: 5| Step: 3
Training loss: 2.7515985004554606
Validation loss: 2.4770926195441816

Epoch: 5| Step: 4
Training loss: 2.428191383662111
Validation loss: 2.4535147469206398

Epoch: 5| Step: 5
Training loss: 2.9109216694752047
Validation loss: 2.44962974167288

Epoch: 5| Step: 6
Training loss: 2.8423226935144754
Validation loss: 2.440630135374478

Epoch: 5| Step: 7
Training loss: 2.5318173373174093
Validation loss: 2.4403019112715936

Epoch: 5| Step: 8
Training loss: 2.8560366294178827
Validation loss: 2.438254800889302

Epoch: 5| Step: 9
Training loss: 2.824639717691359
Validation loss: 2.449347565114086

Epoch: 5| Step: 10
Training loss: 2.6225939123104705
Validation loss: 2.446601493084543

Epoch: 133| Step: 0
Training loss: 2.702876437892266
Validation loss: 2.4518406828415684

Epoch: 5| Step: 1
Training loss: 2.8575403550069356
Validation loss: 2.4630343981952443

Epoch: 5| Step: 2
Training loss: 2.791847697599093
Validation loss: 2.4731316313532536

Epoch: 5| Step: 3
Training loss: 3.177102727778705
Validation loss: 2.4999850467521814

Epoch: 5| Step: 4
Training loss: 2.7461961100399557
Validation loss: 2.506086152245852

Epoch: 5| Step: 5
Training loss: 2.3042307255574004
Validation loss: 2.5330422468835936

Epoch: 5| Step: 6
Training loss: 2.8737244471558423
Validation loss: 2.5619327758748742

Epoch: 5| Step: 7
Training loss: 2.732594286242128
Validation loss: 2.5722992695869946

Epoch: 5| Step: 8
Training loss: 2.821172186945053
Validation loss: 2.5339682519980005

Epoch: 5| Step: 9
Training loss: 2.4857366896780073
Validation loss: 2.4858246934266126

Epoch: 5| Step: 10
Training loss: 2.4640599378380186
Validation loss: 2.4613741610838975

Epoch: 134| Step: 0
Training loss: 2.6764816815344274
Validation loss: 2.4488886934807166

Epoch: 5| Step: 1
Training loss: 2.9968112847294437
Validation loss: 2.446775415343044

Epoch: 5| Step: 2
Training loss: 2.8640543686272153
Validation loss: 2.4496835521831657

Epoch: 5| Step: 3
Training loss: 2.3522385547419096
Validation loss: 2.4506641128232864

Epoch: 5| Step: 4
Training loss: 2.870064188807626
Validation loss: 2.4523545949556995

Epoch: 5| Step: 5
Training loss: 2.630845600140256
Validation loss: 2.45289413528951

Epoch: 5| Step: 6
Training loss: 2.6417847744344343
Validation loss: 2.4574351431416708

Epoch: 5| Step: 7
Training loss: 2.184078810971106
Validation loss: 2.4668575919154194

Epoch: 5| Step: 8
Training loss: 3.530974385806305
Validation loss: 2.486524150095579

Epoch: 5| Step: 9
Training loss: 2.463255453655215
Validation loss: 2.4912968503273754

Epoch: 5| Step: 10
Training loss: 2.4318142625944046
Validation loss: 2.507787352236426

Epoch: 135| Step: 0
Training loss: 2.6174539458878727
Validation loss: 2.5032976582032225

Epoch: 5| Step: 1
Training loss: 2.5301026934864526
Validation loss: 2.527561321213927

Epoch: 5| Step: 2
Training loss: 2.7179669535061612
Validation loss: 2.5786993466503385

Epoch: 5| Step: 3
Training loss: 2.8647703537434723
Validation loss: 2.599926735679523

Epoch: 5| Step: 4
Training loss: 3.004018158930157
Validation loss: 2.624326971238054

Epoch: 5| Step: 5
Training loss: 2.3538655001217834
Validation loss: 2.6288876494681355

Epoch: 5| Step: 6
Training loss: 3.184857488584884
Validation loss: 2.5765949679816424

Epoch: 5| Step: 7
Training loss: 2.77726065166648
Validation loss: 2.5395828357573462

Epoch: 5| Step: 8
Training loss: 2.9639162565439774
Validation loss: 2.47776083322478

Epoch: 5| Step: 9
Training loss: 1.9076176099404736
Validation loss: 2.4616924731443284

Epoch: 5| Step: 10
Training loss: 2.758320531978655
Validation loss: 2.4556639259904243

Epoch: 136| Step: 0
Training loss: 2.0469250854887258
Validation loss: 2.4431872525562617

Epoch: 5| Step: 1
Training loss: 2.7282867663337385
Validation loss: 2.4510740159869053

Epoch: 5| Step: 2
Training loss: 3.2196051193164377
Validation loss: 2.4641101414280877

Epoch: 5| Step: 3
Training loss: 2.327693822475148
Validation loss: 2.464876515498483

Epoch: 5| Step: 4
Training loss: 2.692763563483746
Validation loss: 2.4599770344481655

Epoch: 5| Step: 5
Training loss: 2.9226109195019427
Validation loss: 2.48169377154199

Epoch: 5| Step: 6
Training loss: 2.788283893886434
Validation loss: 2.5008077567574634

Epoch: 5| Step: 7
Training loss: 2.6468569560150903
Validation loss: 2.5192153746647263

Epoch: 5| Step: 8
Training loss: 2.802288081028556
Validation loss: 2.5599045674099687

Epoch: 5| Step: 9
Training loss: 2.533140912611889
Validation loss: 2.546957879674804

Epoch: 5| Step: 10
Training loss: 2.660560252338451
Validation loss: 2.5559385548670095

Epoch: 137| Step: 0
Training loss: 2.724147743850977
Validation loss: 2.5664180092872995

Epoch: 5| Step: 1
Training loss: 2.789747907262927
Validation loss: 2.588865512976974

Epoch: 5| Step: 2
Training loss: 3.1629294544883266
Validation loss: 2.594939906676208

Epoch: 5| Step: 3
Training loss: 2.2967033062555844
Validation loss: 2.618694068561423

Epoch: 5| Step: 4
Training loss: 2.487373509857147
Validation loss: 2.591194289326317

Epoch: 5| Step: 5
Training loss: 2.3002325935513643
Validation loss: 2.5077255714931512

Epoch: 5| Step: 6
Training loss: 3.0182262527061177
Validation loss: 2.4628820843414454

Epoch: 5| Step: 7
Training loss: 2.7417803948495845
Validation loss: 2.4603302216274896

Epoch: 5| Step: 8
Training loss: 2.475440026672647
Validation loss: 2.450760077054036

Epoch: 5| Step: 9
Training loss: 3.0839840657655007
Validation loss: 2.451472191511361

Epoch: 5| Step: 10
Training loss: 2.3031364782246624
Validation loss: 2.462028542571793

Epoch: 138| Step: 0
Training loss: 2.494972227779082
Validation loss: 2.457717777423309

Epoch: 5| Step: 1
Training loss: 3.0612824803004273
Validation loss: 2.4834159103420905

Epoch: 5| Step: 2
Training loss: 2.4663640334945147
Validation loss: 2.460213853027153

Epoch: 5| Step: 3
Training loss: 3.0845690819802996
Validation loss: 2.48029241512437

Epoch: 5| Step: 4
Training loss: 2.7231659377940893
Validation loss: 2.4550082876457653

Epoch: 5| Step: 5
Training loss: 2.2664077984956794
Validation loss: 2.4821471280116643

Epoch: 5| Step: 6
Training loss: 2.4644108556876434
Validation loss: 2.4845454794132684

Epoch: 5| Step: 7
Training loss: 2.482230070254082
Validation loss: 2.4648434514963293

Epoch: 5| Step: 8
Training loss: 2.2702287924995996
Validation loss: 2.4643205954322633

Epoch: 5| Step: 9
Training loss: 2.8860602550494967
Validation loss: 2.4714674712584137

Epoch: 5| Step: 10
Training loss: 2.72554403701334
Validation loss: 2.515562185752779

Epoch: 139| Step: 0
Training loss: 2.5390739558034836
Validation loss: 2.5667623091628826

Epoch: 5| Step: 1
Training loss: 2.4889700758082736
Validation loss: 2.6145028781478534

Epoch: 5| Step: 2
Training loss: 1.9372176302988013
Validation loss: 2.587982055510115

Epoch: 5| Step: 3
Training loss: 3.0109300186705674
Validation loss: 2.496260303958716

Epoch: 5| Step: 4
Training loss: 2.900746374436861
Validation loss: 2.525198832240948

Epoch: 5| Step: 5
Training loss: 2.5152888103008872
Validation loss: 2.4970154754542393

Epoch: 5| Step: 6
Training loss: 2.939826693195187
Validation loss: 2.461380969677211

Epoch: 5| Step: 7
Training loss: 2.420049754805645
Validation loss: 2.4475467700015896

Epoch: 5| Step: 8
Training loss: 2.2830748901381863
Validation loss: 2.4479243225801794

Epoch: 5| Step: 9
Training loss: 2.8341882949119004
Validation loss: 2.4397193432852755

Epoch: 5| Step: 10
Training loss: 3.169520363848926
Validation loss: 2.456268715481217

Epoch: 140| Step: 0
Training loss: 3.0566456170087033
Validation loss: 2.476675234218502

Epoch: 5| Step: 1
Training loss: 2.4320370025517715
Validation loss: 2.5071484306220375

Epoch: 5| Step: 2
Training loss: 2.568636826298389
Validation loss: 2.562056662412886

Epoch: 5| Step: 3
Training loss: 2.6875965189790163
Validation loss: 2.6333322709085176

Epoch: 5| Step: 4
Training loss: 2.849899183129801
Validation loss: 2.650542301977677

Epoch: 5| Step: 5
Training loss: 2.7284930807832963
Validation loss: 2.579668085291008

Epoch: 5| Step: 6
Training loss: 2.387425594268891
Validation loss: 2.530482236633011

Epoch: 5| Step: 7
Training loss: 2.193804783150658
Validation loss: 2.4543290640784567

Epoch: 5| Step: 8
Training loss: 2.48980369284288
Validation loss: 2.438678378789358

Epoch: 5| Step: 9
Training loss: 2.848292987315272
Validation loss: 2.435673983918175

Epoch: 5| Step: 10
Training loss: 2.712220166094581
Validation loss: 2.435453847121332

Epoch: 141| Step: 0
Training loss: 2.1824681856298893
Validation loss: 2.432226379140872

Epoch: 5| Step: 1
Training loss: 2.738184253754178
Validation loss: 2.4432796260886938

Epoch: 5| Step: 2
Training loss: 2.8511611446999754
Validation loss: 2.422399851823853

Epoch: 5| Step: 3
Training loss: 2.2341407706460092
Validation loss: 2.4429697037325027

Epoch: 5| Step: 4
Training loss: 2.412362793494487
Validation loss: 2.4581507918667316

Epoch: 5| Step: 5
Training loss: 2.9921036750864465
Validation loss: 2.502117040982127

Epoch: 5| Step: 6
Training loss: 2.350480245663406
Validation loss: 2.5536574497690583

Epoch: 5| Step: 7
Training loss: 2.880820312235166
Validation loss: 2.6274435269711924

Epoch: 5| Step: 8
Training loss: 2.2954739819587076
Validation loss: 2.5829119151685433

Epoch: 5| Step: 9
Training loss: 2.6498813350667803
Validation loss: 2.5350437181992556

Epoch: 5| Step: 10
Training loss: 3.065901132760053
Validation loss: 2.510859600524785

Epoch: 142| Step: 0
Training loss: 3.5764024077883185
Validation loss: 2.4783633150643083

Epoch: 5| Step: 1
Training loss: 1.9990661348181937
Validation loss: 2.4444552911062223

Epoch: 5| Step: 2
Training loss: 2.2090435205665
Validation loss: 2.428952783971412

Epoch: 5| Step: 3
Training loss: 2.611653321245669
Validation loss: 2.4162624736817633

Epoch: 5| Step: 4
Training loss: 2.407593389266458
Validation loss: 2.4177145008797525

Epoch: 5| Step: 5
Training loss: 2.4143404013662684
Validation loss: 2.4286208462273833

Epoch: 5| Step: 6
Training loss: 2.6638127990222706
Validation loss: 2.425763246818434

Epoch: 5| Step: 7
Training loss: 2.9211188169119535
Validation loss: 2.463613320778719

Epoch: 5| Step: 8
Training loss: 2.603713603980894
Validation loss: 2.501163314551492

Epoch: 5| Step: 9
Training loss: 2.535583366069162
Validation loss: 2.6067728113875

Epoch: 5| Step: 10
Training loss: 2.263159416588093
Validation loss: 2.6321617596140374

Epoch: 143| Step: 0
Training loss: 2.736775156845143
Validation loss: 2.635801712682703

Epoch: 5| Step: 1
Training loss: 2.621621728242355
Validation loss: 2.5920568000888435

Epoch: 5| Step: 2
Training loss: 3.0387293772780293
Validation loss: 2.5320518334691045

Epoch: 5| Step: 3
Training loss: 2.8322312698761825
Validation loss: 2.486275813904261

Epoch: 5| Step: 4
Training loss: 2.7641583880520093
Validation loss: 2.4797887920321453

Epoch: 5| Step: 5
Training loss: 2.2663642466511282
Validation loss: 2.4765334097378884

Epoch: 5| Step: 6
Training loss: 2.37039561418275
Validation loss: 2.4799951327431957

Epoch: 5| Step: 7
Training loss: 2.3758506255477787
Validation loss: 2.4489536051929326

Epoch: 5| Step: 8
Training loss: 2.266852421255022
Validation loss: 2.434714407109096

Epoch: 5| Step: 9
Training loss: 2.5194557356052747
Validation loss: 2.4153214781852794

Epoch: 5| Step: 10
Training loss: 2.4191385868802473
Validation loss: 2.4196712183289293

Epoch: 144| Step: 0
Training loss: 2.1132683885785846
Validation loss: 2.4202439843483035

Epoch: 5| Step: 1
Training loss: 2.5149458448218076
Validation loss: 2.414741466030983

Epoch: 5| Step: 2
Training loss: 2.9823436914175057
Validation loss: 2.4247154322594384

Epoch: 5| Step: 3
Training loss: 2.7501918552404856
Validation loss: 2.4372893222142453

Epoch: 5| Step: 4
Training loss: 2.474695217748208
Validation loss: 2.459839470197025

Epoch: 5| Step: 5
Training loss: 2.662697003020625
Validation loss: 2.5041679278990543

Epoch: 5| Step: 6
Training loss: 2.71644354139946
Validation loss: 2.5352938956737683

Epoch: 5| Step: 7
Training loss: 1.7839009151226943
Validation loss: 2.5370180381224734

Epoch: 5| Step: 8
Training loss: 2.2608830780882156
Validation loss: 2.5217900096074213

Epoch: 5| Step: 9
Training loss: 3.086633067871643
Validation loss: 2.518519015906642

Epoch: 5| Step: 10
Training loss: 2.361566902248413
Validation loss: 2.546402434975798

Epoch: 145| Step: 0
Training loss: 3.050531159723715
Validation loss: 2.5649542442039808

Epoch: 5| Step: 1
Training loss: 2.7888771658047733
Validation loss: 2.5855615680462143

Epoch: 5| Step: 2
Training loss: 2.2419074013173566
Validation loss: 2.575041946155505

Epoch: 5| Step: 3
Training loss: 2.4571951370285525
Validation loss: 2.538463321535721

Epoch: 5| Step: 4
Training loss: 2.686962517508498
Validation loss: 2.522931539576142

Epoch: 5| Step: 5
Training loss: 2.583935380328451
Validation loss: 2.4894717725205138

Epoch: 5| Step: 6
Training loss: 1.6229549156973617
Validation loss: 2.4573654186758582

Epoch: 5| Step: 7
Training loss: 3.1264205755519163
Validation loss: 2.4207207497809495

Epoch: 5| Step: 8
Training loss: 2.3182165267372343
Validation loss: 2.4325660272747194

Epoch: 5| Step: 9
Training loss: 2.3143807057828774
Validation loss: 2.4843911100590024

Epoch: 5| Step: 10
Training loss: 2.4539905163209403
Validation loss: 2.5108253879166216

Epoch: 146| Step: 0
Training loss: 2.3012554929917406
Validation loss: 2.533659716848925

Epoch: 5| Step: 1
Training loss: 2.362723292541194
Validation loss: 2.580742587505211

Epoch: 5| Step: 2
Training loss: 2.5679939735318116
Validation loss: 2.6086298616917136

Epoch: 5| Step: 3
Training loss: 2.807493373628645
Validation loss: 2.598671500144638

Epoch: 5| Step: 4
Training loss: 2.299104296382248
Validation loss: 2.559260262480939

Epoch: 5| Step: 5
Training loss: 2.910246367627333
Validation loss: 2.533184404669509

Epoch: 5| Step: 6
Training loss: 2.172903791507115
Validation loss: 2.4655728252319173

Epoch: 5| Step: 7
Training loss: 2.4552740900434658
Validation loss: 2.4377690007209902

Epoch: 5| Step: 8
Training loss: 2.476343572428611
Validation loss: 2.4344569053384095

Epoch: 5| Step: 9
Training loss: 2.873109776620654
Validation loss: 2.4489398623565535

Epoch: 5| Step: 10
Training loss: 2.141523409355448
Validation loss: 2.4530072617334437

Epoch: 147| Step: 0
Training loss: 2.3987271509876344
Validation loss: 2.476047896007472

Epoch: 5| Step: 1
Training loss: 2.405088664619285
Validation loss: 2.5168504246796624

Epoch: 5| Step: 2
Training loss: 2.624746673712679
Validation loss: 2.6382034323270926

Epoch: 5| Step: 3
Training loss: 2.544953633693578
Validation loss: 2.6582632804011426

Epoch: 5| Step: 4
Training loss: 2.6587668668268436
Validation loss: 2.6549713927618934

Epoch: 5| Step: 5
Training loss: 2.8822346756933315
Validation loss: 2.592708466991191

Epoch: 5| Step: 6
Training loss: 1.9643495821787575
Validation loss: 2.498822458906779

Epoch: 5| Step: 7
Training loss: 2.4963668172414817
Validation loss: 2.449942508020442

Epoch: 5| Step: 8
Training loss: 2.5147374642917986
Validation loss: 2.3968129873472734

Epoch: 5| Step: 9
Training loss: 2.410269414634606
Validation loss: 2.388069848968282

Epoch: 5| Step: 10
Training loss: 2.5376961655733865
Validation loss: 2.3865087810296277

Epoch: 148| Step: 0
Training loss: 2.3418473722662276
Validation loss: 2.3784355752571473

Epoch: 5| Step: 1
Training loss: 3.0218948253150892
Validation loss: 2.3801405852988164

Epoch: 5| Step: 2
Training loss: 2.7017640673498042
Validation loss: 2.3968255091679915

Epoch: 5| Step: 3
Training loss: 2.350133112931805
Validation loss: 2.403964530497519

Epoch: 5| Step: 4
Training loss: 2.5783141095711217
Validation loss: 2.448197227812697

Epoch: 5| Step: 5
Training loss: 2.237152720518176
Validation loss: 2.4674299393952275

Epoch: 5| Step: 6
Training loss: 2.449161705314056
Validation loss: 2.533145052865286

Epoch: 5| Step: 7
Training loss: 2.52797383350399
Validation loss: 2.5644605826256224

Epoch: 5| Step: 8
Training loss: 2.507578425906706
Validation loss: 2.546703661760689

Epoch: 5| Step: 9
Training loss: 2.5479731152432117
Validation loss: 2.539821597232159

Epoch: 5| Step: 10
Training loss: 2.4095759999388275
Validation loss: 2.481705439998047

Epoch: 149| Step: 0
Training loss: 2.5744679725419557
Validation loss: 2.461698268605581

Epoch: 5| Step: 1
Training loss: 2.273763626670165
Validation loss: 2.4847298949931513

Epoch: 5| Step: 2
Training loss: 2.6010064341264965
Validation loss: 2.5075258956257596

Epoch: 5| Step: 3
Training loss: 2.0539779308140087
Validation loss: 2.4762835902131517

Epoch: 5| Step: 4
Training loss: 2.777029371106961
Validation loss: 2.485534069444489

Epoch: 5| Step: 5
Training loss: 2.203673706984373
Validation loss: 2.5148641467142934

Epoch: 5| Step: 6
Training loss: 3.082232373230138
Validation loss: 2.5281052423696844

Epoch: 5| Step: 7
Training loss: 2.9149737940243363
Validation loss: 2.5908514788850385

Epoch: 5| Step: 8
Training loss: 2.5482765507115293
Validation loss: 2.5562951724682477

Epoch: 5| Step: 9
Training loss: 2.3405300146573036
Validation loss: 2.5136606971035858

Epoch: 5| Step: 10
Training loss: 2.4591275780196535
Validation loss: 2.4840903903067106

Epoch: 150| Step: 0
Training loss: 2.5932921039896355
Validation loss: 2.458338901380682

Epoch: 5| Step: 1
Training loss: 2.658031449670783
Validation loss: 2.454576716830418

Epoch: 5| Step: 2
Training loss: 2.6926353538161467
Validation loss: 2.45932845019371

Epoch: 5| Step: 3
Training loss: 2.6952051998286417
Validation loss: 2.45444626578579

Epoch: 5| Step: 4
Training loss: 2.513197396883238
Validation loss: 2.4535934516171967

Epoch: 5| Step: 5
Training loss: 2.3152908804871775
Validation loss: 2.4489431912956614

Epoch: 5| Step: 6
Training loss: 2.352878747139911
Validation loss: 2.457911537766572

Epoch: 5| Step: 7
Training loss: 2.1361955912331405
Validation loss: 2.487386739395677

Epoch: 5| Step: 8
Training loss: 2.622197244367155
Validation loss: 2.5254540180527347

Epoch: 5| Step: 9
Training loss: 2.6484477625285128
Validation loss: 2.5373794043274813

Epoch: 5| Step: 10
Training loss: 2.1553968870399767
Validation loss: 2.4936117024048277

Epoch: 151| Step: 0
Training loss: 2.287840637525884
Validation loss: 2.4322806953579215

Epoch: 5| Step: 1
Training loss: 2.5439063246772493
Validation loss: 2.4008448172643857

Epoch: 5| Step: 2
Training loss: 2.3274791256862803
Validation loss: 2.4093036450211955

Epoch: 5| Step: 3
Training loss: 2.1866819759546297
Validation loss: 2.4013971061153714

Epoch: 5| Step: 4
Training loss: 2.405761470992097
Validation loss: 2.405226526153511

Epoch: 5| Step: 5
Training loss: 2.3293235816940685
Validation loss: 2.4286388989502963

Epoch: 5| Step: 6
Training loss: 2.884156283499798
Validation loss: 2.4588214809529467

Epoch: 5| Step: 7
Training loss: 2.6239619246081323
Validation loss: 2.558777648433991

Epoch: 5| Step: 8
Training loss: 2.8800084813310987
Validation loss: 2.6480115017381367

Epoch: 5| Step: 9
Training loss: 2.5431196926808752
Validation loss: 2.582587074961842

Epoch: 5| Step: 10
Training loss: 2.37345544884872
Validation loss: 2.546026496560447

Epoch: 152| Step: 0
Training loss: 2.453982258092888
Validation loss: 2.502919475647304

Epoch: 5| Step: 1
Training loss: 2.570698346798857
Validation loss: 2.5425112823991993

Epoch: 5| Step: 2
Training loss: 2.704037727216912
Validation loss: 2.5290161123952206

Epoch: 5| Step: 3
Training loss: 2.7894596276596766
Validation loss: 2.4773907014010588

Epoch: 5| Step: 4
Training loss: 2.245709885676465
Validation loss: 2.441209806024811

Epoch: 5| Step: 5
Training loss: 2.0870798247735536
Validation loss: 2.416712242463326

Epoch: 5| Step: 6
Training loss: 2.7974832395540705
Validation loss: 2.38306890702109

Epoch: 5| Step: 7
Training loss: 2.4741658548688044
Validation loss: 2.387890651367629

Epoch: 5| Step: 8
Training loss: 1.8633769588561244
Validation loss: 2.4254948815879493

Epoch: 5| Step: 9
Training loss: 2.118497886399166
Validation loss: 2.446441500890061

Epoch: 5| Step: 10
Training loss: 2.673090786415043
Validation loss: 2.484448052687474

Epoch: 153| Step: 0
Training loss: 2.553112232638575
Validation loss: 2.5168527348424896

Epoch: 5| Step: 1
Training loss: 2.1439638481579517
Validation loss: 2.5520708282613023

Epoch: 5| Step: 2
Training loss: 2.953118864184267
Validation loss: 2.5219286511378747

Epoch: 5| Step: 3
Training loss: 2.202351319299027
Validation loss: 2.4655985096166924

Epoch: 5| Step: 4
Training loss: 2.3917106207908003
Validation loss: 2.4345952319877786

Epoch: 5| Step: 5
Training loss: 2.4359000408040274
Validation loss: 2.409532291885566

Epoch: 5| Step: 6
Training loss: 2.19289735053377
Validation loss: 2.3944838359129084

Epoch: 5| Step: 7
Training loss: 2.35985019774138
Validation loss: 2.403373569432583

Epoch: 5| Step: 8
Training loss: 2.4222243518508897
Validation loss: 2.395265103261411

Epoch: 5| Step: 9
Training loss: 2.6610059459437787
Validation loss: 2.4240514835066507

Epoch: 5| Step: 10
Training loss: 2.3440420350286386
Validation loss: 2.4907099359121423

Epoch: 154| Step: 0
Training loss: 1.970622973140082
Validation loss: 2.5443538213463612

Epoch: 5| Step: 1
Training loss: 2.4723995611852314
Validation loss: 2.6503924096106664

Epoch: 5| Step: 2
Training loss: 2.7964903497718687
Validation loss: 2.6818748359713487

Epoch: 5| Step: 3
Training loss: 2.431518845783413
Validation loss: 2.514027169542355

Epoch: 5| Step: 4
Training loss: 2.6739994994500433
Validation loss: 2.4046827767825008

Epoch: 5| Step: 5
Training loss: 2.3991637481675236
Validation loss: 2.3853608199340073

Epoch: 5| Step: 6
Training loss: 2.1094597693470365
Validation loss: 2.374373380836036

Epoch: 5| Step: 7
Training loss: 2.515494775659379
Validation loss: 2.3838539492959203

Epoch: 5| Step: 8
Training loss: 2.590055845387617
Validation loss: 2.3857978628706453

Epoch: 5| Step: 9
Training loss: 2.2109176580933854
Validation loss: 2.4104334743483586

Epoch: 5| Step: 10
Training loss: 2.863177663222588
Validation loss: 2.4251240192716184

Epoch: 155| Step: 0
Training loss: 2.4972096129445496
Validation loss: 2.453311286846048

Epoch: 5| Step: 1
Training loss: 2.784534101296912
Validation loss: 2.5195798772068696

Epoch: 5| Step: 2
Training loss: 2.205123319745552
Validation loss: 2.5794629614842703

Epoch: 5| Step: 3
Training loss: 2.3115592280116277
Validation loss: 2.6168106789818446

Epoch: 5| Step: 4
Training loss: 2.5499428836185327
Validation loss: 2.6011198273794958

Epoch: 5| Step: 5
Training loss: 2.692331185605177
Validation loss: 2.588237090303731

Epoch: 5| Step: 6
Training loss: 2.252780362039012
Validation loss: 2.545064540722959

Epoch: 5| Step: 7
Training loss: 2.6392892924147544
Validation loss: 2.5327366795675395

Epoch: 5| Step: 8
Training loss: 2.116676972832207
Validation loss: 2.5297911747229858

Epoch: 5| Step: 9
Training loss: 2.060898592612747
Validation loss: 2.5043003791525584

Epoch: 5| Step: 10
Training loss: 2.294761879396179
Validation loss: 2.430688965081113

Epoch: 156| Step: 0
Training loss: 2.1960263432241147
Validation loss: 2.3791254737574707

Epoch: 5| Step: 1
Training loss: 2.160057686459273
Validation loss: 2.3771822876691924

Epoch: 5| Step: 2
Training loss: 1.856255808092272
Validation loss: 2.382638074871154

Epoch: 5| Step: 3
Training loss: 2.461081945630647
Validation loss: 2.3833893861496147

Epoch: 5| Step: 4
Training loss: 2.8848571969428454
Validation loss: 2.412114342620505

Epoch: 5| Step: 5
Training loss: 2.4042372769763567
Validation loss: 2.4741170448641125

Epoch: 5| Step: 6
Training loss: 2.8445941384814644
Validation loss: 2.5934073128769106

Epoch: 5| Step: 7
Training loss: 2.4889221803202166
Validation loss: 2.6357088994980207

Epoch: 5| Step: 8
Training loss: 2.8629143494143374
Validation loss: 2.6678003654300153

Epoch: 5| Step: 9
Training loss: 2.4524028711402024
Validation loss: 2.664774358540766

Epoch: 5| Step: 10
Training loss: 2.262242811559393
Validation loss: 2.583343379477167

Epoch: 157| Step: 0
Training loss: 2.615782312108483
Validation loss: 2.508413526028324

Epoch: 5| Step: 1
Training loss: 2.1365547186952654
Validation loss: 2.4539664331400246

Epoch: 5| Step: 2
Training loss: 2.404282099587774
Validation loss: 2.397170497196021

Epoch: 5| Step: 3
Training loss: 2.681574654653307
Validation loss: 2.395487536656698

Epoch: 5| Step: 4
Training loss: 2.4846211437432046
Validation loss: 2.3760906838943145

Epoch: 5| Step: 5
Training loss: 2.47660793900547
Validation loss: 2.3998087668371255

Epoch: 5| Step: 6
Training loss: 2.3801480764918455
Validation loss: 2.425705007962302

Epoch: 5| Step: 7
Training loss: 2.4237269058425754
Validation loss: 2.4761281808692024

Epoch: 5| Step: 8
Training loss: 2.3635483772067127
Validation loss: 2.494099560414807

Epoch: 5| Step: 9
Training loss: 2.047235005875243
Validation loss: 2.5244607402976373

Epoch: 5| Step: 10
Training loss: 2.386471399953884
Validation loss: 2.556687075411848

Epoch: 158| Step: 0
Training loss: 2.017706808766774
Validation loss: 2.5737790565603826

Epoch: 5| Step: 1
Training loss: 2.3804528731945616
Validation loss: 2.5569170248085005

Epoch: 5| Step: 2
Training loss: 2.766258296549026
Validation loss: 2.5302807101472022

Epoch: 5| Step: 3
Training loss: 2.425668415879208
Validation loss: 2.4836188375692623

Epoch: 5| Step: 4
Training loss: 2.316355815679349
Validation loss: 2.473067279615737

Epoch: 5| Step: 5
Training loss: 2.6340989951355884
Validation loss: 2.4400872623612195

Epoch: 5| Step: 6
Training loss: 1.6694820784172109
Validation loss: 2.429396850244035

Epoch: 5| Step: 7
Training loss: 2.430850422245184
Validation loss: 2.4192786901036842

Epoch: 5| Step: 8
Training loss: 2.3697351022753694
Validation loss: 2.424632133391179

Epoch: 5| Step: 9
Training loss: 2.671212632913527
Validation loss: 2.4339579258356796

Epoch: 5| Step: 10
Training loss: 2.401453960599272
Validation loss: 2.457403741035279

Epoch: 159| Step: 0
Training loss: 2.382948674547684
Validation loss: 2.499722471522252

Epoch: 5| Step: 1
Training loss: 2.248749597452922
Validation loss: 2.534215244873054

Epoch: 5| Step: 2
Training loss: 2.6571962354135783
Validation loss: 2.548460265142849

Epoch: 5| Step: 3
Training loss: 2.2911178162817154
Validation loss: 2.4934731818054146

Epoch: 5| Step: 4
Training loss: 2.395665060574724
Validation loss: 2.511200409554156

Epoch: 5| Step: 5
Training loss: 2.5144371877286407
Validation loss: 2.4875328636049456

Epoch: 5| Step: 6
Training loss: 1.9834802968474825
Validation loss: 2.475470953506357

Epoch: 5| Step: 7
Training loss: 2.131049353140377
Validation loss: 2.503002949407691

Epoch: 5| Step: 8
Training loss: 2.4389118116262707
Validation loss: 2.4970411244035033

Epoch: 5| Step: 9
Training loss: 2.362912185477246
Validation loss: 2.4950270331836784

Epoch: 5| Step: 10
Training loss: 2.42349317082127
Validation loss: 2.481236018585243

Epoch: 160| Step: 0
Training loss: 2.4587986931296717
Validation loss: 2.4498845760687926

Epoch: 5| Step: 1
Training loss: 2.975436260388757
Validation loss: 2.4408041092126833

Epoch: 5| Step: 2
Training loss: 1.8809504501776648
Validation loss: 2.493856566467767

Epoch: 5| Step: 3
Training loss: 2.446353775965401
Validation loss: 2.521661117239954

Epoch: 5| Step: 4
Training loss: 2.450993383223568
Validation loss: 2.5379911620139417

Epoch: 5| Step: 5
Training loss: 2.426224083032403
Validation loss: 2.5599450460811446

Epoch: 5| Step: 6
Training loss: 2.500202647579028
Validation loss: 2.5308658242990436

Epoch: 5| Step: 7
Training loss: 2.182628001755927
Validation loss: 2.4666056605773856

Epoch: 5| Step: 8
Training loss: 2.1617152295016733
Validation loss: 2.4204324491566998

Epoch: 5| Step: 9
Training loss: 2.1587037209308604
Validation loss: 2.4023768535673935

Epoch: 5| Step: 10
Training loss: 2.096892205294249
Validation loss: 2.4235900310864205

Epoch: 161| Step: 0
Training loss: 1.837875187775564
Validation loss: 2.426311315386712

Epoch: 5| Step: 1
Training loss: 2.6682063565212166
Validation loss: 2.4626902432493423

Epoch: 5| Step: 2
Training loss: 1.9427508911162186
Validation loss: 2.500223637904434

Epoch: 5| Step: 3
Training loss: 2.4405391038146744
Validation loss: 2.5455440443546005

Epoch: 5| Step: 4
Training loss: 2.6278121054380614
Validation loss: 2.610120261495716

Epoch: 5| Step: 5
Training loss: 2.3676679771957123
Validation loss: 2.631648035974852

Epoch: 5| Step: 6
Training loss: 2.3977658204181305
Validation loss: 2.651634976889437

Epoch: 5| Step: 7
Training loss: 2.6976576181204446
Validation loss: 2.65307516246425

Epoch: 5| Step: 8
Training loss: 2.5272958270427495
Validation loss: 2.526841349618526

Epoch: 5| Step: 9
Training loss: 1.9379484826593432
Validation loss: 2.4047979052047297

Epoch: 5| Step: 10
Training loss: 2.697423931672028
Validation loss: 2.3800032601748238

Epoch: 162| Step: 0
Training loss: 2.633514220225956
Validation loss: 2.3853897829032493

Epoch: 5| Step: 1
Training loss: 2.6985298746154163
Validation loss: 2.3701193367404088

Epoch: 5| Step: 2
Training loss: 2.535091264123985
Validation loss: 2.3504798050254063

Epoch: 5| Step: 3
Training loss: 2.7403990736153956
Validation loss: 2.350840116801656

Epoch: 5| Step: 4
Training loss: 2.412299342532132
Validation loss: 2.3663775805042877

Epoch: 5| Step: 5
Training loss: 2.373938072110316
Validation loss: 2.4107781356782656

Epoch: 5| Step: 6
Training loss: 2.2477347308881166
Validation loss: 2.46157669331969

Epoch: 5| Step: 7
Training loss: 2.4758770592816197
Validation loss: 2.5379871104746963

Epoch: 5| Step: 8
Training loss: 2.319335320723602
Validation loss: 2.555523592590158

Epoch: 5| Step: 9
Training loss: 2.363492190192167
Validation loss: 2.5187884092373127

Epoch: 5| Step: 10
Training loss: 1.7865763218418265
Validation loss: 2.4614828963484903

Epoch: 163| Step: 0
Training loss: 1.9934108194496378
Validation loss: 2.4259790056528776

Epoch: 5| Step: 1
Training loss: 2.439647022418231
Validation loss: 2.4014503064177988

Epoch: 5| Step: 2
Training loss: 2.286329597434869
Validation loss: 2.400039190951684

Epoch: 5| Step: 3
Training loss: 2.0971198221881604
Validation loss: 2.4023255188859873

Epoch: 5| Step: 4
Training loss: 2.6453100773394103
Validation loss: 2.3999120587213736

Epoch: 5| Step: 5
Training loss: 1.8584494972130414
Validation loss: 2.4352461431219874

Epoch: 5| Step: 6
Training loss: 2.3626203637519363
Validation loss: 2.46796187103639

Epoch: 5| Step: 7
Training loss: 1.9878693699239178
Validation loss: 2.4994768005407346

Epoch: 5| Step: 8
Training loss: 2.5374924720690077
Validation loss: 2.5448522506834204

Epoch: 5| Step: 9
Training loss: 2.5758110991100143
Validation loss: 2.580255503552037

Epoch: 5| Step: 10
Training loss: 2.6988835216318954
Validation loss: 2.548991454501936

Epoch: 164| Step: 0
Training loss: 2.1796798432465203
Validation loss: 2.463031636828037

Epoch: 5| Step: 1
Training loss: 2.373429632519157
Validation loss: 2.4306512076858895

Epoch: 5| Step: 2
Training loss: 1.7252435954491487
Validation loss: 2.381465033409021

Epoch: 5| Step: 3
Training loss: 2.343399021571913
Validation loss: 2.396775691037007

Epoch: 5| Step: 4
Training loss: 2.5501324002169916
Validation loss: 2.400886467811112

Epoch: 5| Step: 5
Training loss: 2.5957876267754094
Validation loss: 2.444093944393128

Epoch: 5| Step: 6
Training loss: 2.335601680436063
Validation loss: 2.485698955740923

Epoch: 5| Step: 7
Training loss: 2.813668072057249
Validation loss: 2.5467481804920387

Epoch: 5| Step: 8
Training loss: 2.2916729204497117
Validation loss: 2.6143622493449388

Epoch: 5| Step: 9
Training loss: 2.2756506775347902
Validation loss: 2.6493485263488514

Epoch: 5| Step: 10
Training loss: 2.00534499722413
Validation loss: 2.5728624426256133

Epoch: 165| Step: 0
Training loss: 2.734389212435162
Validation loss: 2.4476316859961624

Epoch: 5| Step: 1
Training loss: 2.4218238086827735
Validation loss: 2.3971244732131707

Epoch: 5| Step: 2
Training loss: 1.5685247616720992
Validation loss: 2.3852975900429074

Epoch: 5| Step: 3
Training loss: 2.694171520275586
Validation loss: 2.3683949442440113

Epoch: 5| Step: 4
Training loss: 2.264707392640335
Validation loss: 2.3869749522171904

Epoch: 5| Step: 5
Training loss: 2.204664409470573
Validation loss: 2.3926292005808465

Epoch: 5| Step: 6
Training loss: 1.7877227564376104
Validation loss: 2.3936985201073737

Epoch: 5| Step: 7
Training loss: 1.9908707998440665
Validation loss: 2.434246360167187

Epoch: 5| Step: 8
Training loss: 2.306727964086592
Validation loss: 2.475739143156491

Epoch: 5| Step: 9
Training loss: 2.51645869307304
Validation loss: 2.511985403719017

Epoch: 5| Step: 10
Training loss: 2.471185955168978
Validation loss: 2.5514365070707608

Epoch: 166| Step: 0
Training loss: 2.507554465830979
Validation loss: 2.505139668694316

Epoch: 5| Step: 1
Training loss: 1.79561511113026
Validation loss: 2.5034229502663186

Epoch: 5| Step: 2
Training loss: 2.3750411582191293
Validation loss: 2.437341958920869

Epoch: 5| Step: 3
Training loss: 2.4614604091648986
Validation loss: 2.408014340768073

Epoch: 5| Step: 4
Training loss: 2.500413574342278
Validation loss: 2.4226873902945494

Epoch: 5| Step: 5
Training loss: 2.0523526810479686
Validation loss: 2.41217829370969

Epoch: 5| Step: 6
Training loss: 2.6555722437839204
Validation loss: 2.4392734509597425

Epoch: 5| Step: 7
Training loss: 2.327935742359879
Validation loss: 2.466027688933619

Epoch: 5| Step: 8
Training loss: 2.0345592831355437
Validation loss: 2.5133964788716776

Epoch: 5| Step: 9
Training loss: 1.894092438207409
Validation loss: 2.5743669004198146

Epoch: 5| Step: 10
Training loss: 2.3382765882390153
Validation loss: 2.5731595646144254

Epoch: 167| Step: 0
Training loss: 1.9866027342133565
Validation loss: 2.5250153940211377

Epoch: 5| Step: 1
Training loss: 2.14297534525792
Validation loss: 2.4863895393562854

Epoch: 5| Step: 2
Training loss: 1.9586180689625348
Validation loss: 2.4441783132610175

Epoch: 5| Step: 3
Training loss: 2.5175923301941174
Validation loss: 2.3991405764204146

Epoch: 5| Step: 4
Training loss: 2.5201895866528257
Validation loss: 2.412961413569857

Epoch: 5| Step: 5
Training loss: 1.9319932266732658
Validation loss: 2.4414889844432404

Epoch: 5| Step: 6
Training loss: 2.2891340537491325
Validation loss: 2.4390242317377484

Epoch: 5| Step: 7
Training loss: 1.9604978030444684
Validation loss: 2.4478808143589235

Epoch: 5| Step: 8
Training loss: 2.383329541752429
Validation loss: 2.468885952544816

Epoch: 5| Step: 9
Training loss: 2.5226160371705384
Validation loss: 2.4860928324103084

Epoch: 5| Step: 10
Training loss: 2.388041977007053
Validation loss: 2.569304363449466

Epoch: 168| Step: 0
Training loss: 2.309992074663843
Validation loss: 2.558265079898409

Epoch: 5| Step: 1
Training loss: 1.8818051504438658
Validation loss: 2.5610675764943465

Epoch: 5| Step: 2
Training loss: 2.361421720481471
Validation loss: 2.5366028236265663

Epoch: 5| Step: 3
Training loss: 2.270670987080115
Validation loss: 2.5239387425076467

Epoch: 5| Step: 4
Training loss: 2.241122215359905
Validation loss: 2.479821178115193

Epoch: 5| Step: 5
Training loss: 2.029471455059631
Validation loss: 2.4422581049137144

Epoch: 5| Step: 6
Training loss: 2.4366769623788946
Validation loss: 2.3961622043651523

Epoch: 5| Step: 7
Training loss: 1.9927580371752518
Validation loss: 2.4241754113289686

Epoch: 5| Step: 8
Training loss: 2.4662333348402865
Validation loss: 2.3964268709354974

Epoch: 5| Step: 9
Training loss: 2.2292951980565796
Validation loss: 2.4701176182541853

Epoch: 5| Step: 10
Training loss: 2.1873475157861115
Validation loss: 2.5410865146453885

Epoch: 169| Step: 0
Training loss: 2.173473291493187
Validation loss: 2.6171414367119104

Epoch: 5| Step: 1
Training loss: 2.445328489988655
Validation loss: 2.6916914637736578

Epoch: 5| Step: 2
Training loss: 2.111227733614347
Validation loss: 2.6388837754553185

Epoch: 5| Step: 3
Training loss: 2.1027750254044295
Validation loss: 2.4909686343375537

Epoch: 5| Step: 4
Training loss: 2.3030156682848424
Validation loss: 2.385325486010983

Epoch: 5| Step: 5
Training loss: 2.210325122583095
Validation loss: 2.3425104824569734

Epoch: 5| Step: 6
Training loss: 2.321251265074057
Validation loss: 2.3418509081725802

Epoch: 5| Step: 7
Training loss: 2.1303774168876766
Validation loss: 2.364739946306451

Epoch: 5| Step: 8
Training loss: 2.7035471856620736
Validation loss: 2.3695526756190874

Epoch: 5| Step: 9
Training loss: 2.4965864719028326
Validation loss: 2.372360846444053

Epoch: 5| Step: 10
Training loss: 2.179638605697406
Validation loss: 2.402225811965727

Epoch: 170| Step: 0
Training loss: 2.5823106484730465
Validation loss: 2.474150873969909

Epoch: 5| Step: 1
Training loss: 2.4255646195793017
Validation loss: 2.5435067285362254

Epoch: 5| Step: 2
Training loss: 2.253683148586423
Validation loss: 2.568270650774045

Epoch: 5| Step: 3
Training loss: 2.1377296636687246
Validation loss: 2.571611459381503

Epoch: 5| Step: 4
Training loss: 2.2011246494212995
Validation loss: 2.5753110482507817

Epoch: 5| Step: 5
Training loss: 1.9699036987119691
Validation loss: 2.5377093529984043

Epoch: 5| Step: 6
Training loss: 1.868151364081418
Validation loss: 2.491810096321751

Epoch: 5| Step: 7
Training loss: 2.196037200015086
Validation loss: 2.466270196146114

Epoch: 5| Step: 8
Training loss: 1.6520627912452484
Validation loss: 2.429313769938353

Epoch: 5| Step: 9
Training loss: 2.3186784635546807
Validation loss: 2.421435694392805

Epoch: 5| Step: 10
Training loss: 2.683039667712818
Validation loss: 2.4118371360913042

Epoch: 171| Step: 0
Training loss: 2.0635780060399265
Validation loss: 2.4144293223683713

Epoch: 5| Step: 1
Training loss: 2.105908293130237
Validation loss: 2.4250393627808737

Epoch: 5| Step: 2
Training loss: 2.880142257144032
Validation loss: 2.439891213382939

Epoch: 5| Step: 3
Training loss: 2.2383580485911154
Validation loss: 2.457471094258259

Epoch: 5| Step: 4
Training loss: 2.4288838029365927
Validation loss: 2.4741911070833913

Epoch: 5| Step: 5
Training loss: 2.080711877120035
Validation loss: 2.465008958434455

Epoch: 5| Step: 6
Training loss: 2.180767598408373
Validation loss: 2.4245501015598445

Epoch: 5| Step: 7
Training loss: 1.9643930938402006
Validation loss: 2.4514370988413927

Epoch: 5| Step: 8
Training loss: 1.816598599001554
Validation loss: 2.462964666740378

Epoch: 5| Step: 9
Training loss: 1.8121338836269025
Validation loss: 2.4646197747175633

Epoch: 5| Step: 10
Training loss: 2.2120162435007638
Validation loss: 2.476037544296306

Epoch: 172| Step: 0
Training loss: 1.9295326201643865
Validation loss: 2.456531646219302

Epoch: 5| Step: 1
Training loss: 2.13336208095652
Validation loss: 2.4405689760531906

Epoch: 5| Step: 2
Training loss: 2.3334231927008293
Validation loss: 2.407130794678975

Epoch: 5| Step: 3
Training loss: 2.1544033380453524
Validation loss: 2.4166515588199737

Epoch: 5| Step: 4
Training loss: 2.4124064768318894
Validation loss: 2.416087695079661

Epoch: 5| Step: 5
Training loss: 1.9780246920109972
Validation loss: 2.431776199024079

Epoch: 5| Step: 6
Training loss: 2.222691647963403
Validation loss: 2.491751372262214

Epoch: 5| Step: 7
Training loss: 2.630028585706494
Validation loss: 2.5033185406492184

Epoch: 5| Step: 8
Training loss: 1.9347590470428444
Validation loss: 2.511719879883489

Epoch: 5| Step: 9
Training loss: 1.8375703084560566
Validation loss: 2.518874337150787

Epoch: 5| Step: 10
Training loss: 1.8658656465095724
Validation loss: 2.5191298980171823

Epoch: 173| Step: 0
Training loss: 2.211588841122815
Validation loss: 2.5234307684263

Epoch: 5| Step: 1
Training loss: 2.3625450816217906
Validation loss: 2.4940853951294724

Epoch: 5| Step: 2
Training loss: 2.2579940142150954
Validation loss: 2.49327334133527

Epoch: 5| Step: 3
Training loss: 2.091022935979595
Validation loss: 2.478595942668832

Epoch: 5| Step: 4
Training loss: 1.8172415176720527
Validation loss: 2.4338200685682527

Epoch: 5| Step: 5
Training loss: 1.867443561952282
Validation loss: 2.4052439849170613

Epoch: 5| Step: 6
Training loss: 2.841547857431618
Validation loss: 2.397731400094571

Epoch: 5| Step: 7
Training loss: 2.222259110568431
Validation loss: 2.3869280995785638

Epoch: 5| Step: 8
Training loss: 1.864711636297084
Validation loss: 2.415907729671087

Epoch: 5| Step: 9
Training loss: 1.8213582452719836
Validation loss: 2.4700056812884803

Epoch: 5| Step: 10
Training loss: 2.3625088525031006
Validation loss: 2.574677731061864

Epoch: 174| Step: 0
Training loss: 2.515040359324916
Validation loss: 2.5548777553790454

Epoch: 5| Step: 1
Training loss: 2.228182554638568
Validation loss: 2.513811318139633

Epoch: 5| Step: 2
Training loss: 2.2164559123109715
Validation loss: 2.4742612505414097

Epoch: 5| Step: 3
Training loss: 2.295209215721544
Validation loss: 2.424713581991665

Epoch: 5| Step: 4
Training loss: 1.9237841296127416
Validation loss: 2.388623565409888

Epoch: 5| Step: 5
Training loss: 1.9696010990308643
Validation loss: 2.381347092675829

Epoch: 5| Step: 6
Training loss: 2.5456100786363245
Validation loss: 2.3517472999878257

Epoch: 5| Step: 7
Training loss: 1.854989979863416
Validation loss: 2.3668865699058204

Epoch: 5| Step: 8
Training loss: 1.8490089158853615
Validation loss: 2.389551584324475

Epoch: 5| Step: 9
Training loss: 2.1263623078213962
Validation loss: 2.386970969775985

Epoch: 5| Step: 10
Training loss: 1.7853035563454078
Validation loss: 2.421520928928786

Epoch: 175| Step: 0
Training loss: 1.7759260287259224
Validation loss: 2.4437904646828144

Epoch: 5| Step: 1
Training loss: 2.3714592289050915
Validation loss: 2.524412279213093

Epoch: 5| Step: 2
Training loss: 2.704429532182981
Validation loss: 2.5877539596025723

Epoch: 5| Step: 3
Training loss: 1.780095579602953
Validation loss: 2.4892669547415216

Epoch: 5| Step: 4
Training loss: 2.2687644516665886
Validation loss: 2.425452808044524

Epoch: 5| Step: 5
Training loss: 2.074848316577431
Validation loss: 2.3633519315917084

Epoch: 5| Step: 6
Training loss: 2.2842794708859158
Validation loss: 2.3496632776133097

Epoch: 5| Step: 7
Training loss: 2.2153278877971223
Validation loss: 2.39308683812233

Epoch: 5| Step: 8
Training loss: 1.7958744082728353
Validation loss: 2.4170745940965714

Epoch: 5| Step: 9
Training loss: 1.689009732843411
Validation loss: 2.424079964105026

Epoch: 5| Step: 10
Training loss: 1.9901862770385645
Validation loss: 2.47940573535366

Epoch: 176| Step: 0
Training loss: 2.0569471110961213
Validation loss: 2.4637770602856963

Epoch: 5| Step: 1
Training loss: 2.0985405618975297
Validation loss: 2.4937525550964277

Epoch: 5| Step: 2
Training loss: 2.2959890927776754
Validation loss: 2.4700775979802576

Epoch: 5| Step: 3
Training loss: 2.3359978199190916
Validation loss: 2.4748853710581824

Epoch: 5| Step: 4
Training loss: 1.9078830540363392
Validation loss: 2.455353194618327

Epoch: 5| Step: 5
Training loss: 2.37751817216958
Validation loss: 2.4797715644940257

Epoch: 5| Step: 6
Training loss: 1.9942591050059593
Validation loss: 2.43160261669815

Epoch: 5| Step: 7
Training loss: 1.5634783924099223
Validation loss: 2.414801518227648

Epoch: 5| Step: 8
Training loss: 2.511770577140743
Validation loss: 2.46470781580093

Epoch: 5| Step: 9
Training loss: 1.7445257259406144
Validation loss: 2.4461098958199567

Epoch: 5| Step: 10
Training loss: 1.7209752329895618
Validation loss: 2.446525016521849

Epoch: 177| Step: 0
Training loss: 1.2815915094537267
Validation loss: 2.453777767980444

Epoch: 5| Step: 1
Training loss: 1.9039790274602992
Validation loss: 2.403899808475765

Epoch: 5| Step: 2
Training loss: 2.4439283847336917
Validation loss: 2.4053015254612884

Epoch: 5| Step: 3
Training loss: 2.2311652544100298
Validation loss: 2.4028667759322886

Epoch: 5| Step: 4
Training loss: 2.073502181538395
Validation loss: 2.4129147929993033

Epoch: 5| Step: 5
Training loss: 2.0818647421839236
Validation loss: 2.4617423449070026

Epoch: 5| Step: 6
Training loss: 2.172207484421596
Validation loss: 2.458299519462927

Epoch: 5| Step: 7
Training loss: 1.6449366996204007
Validation loss: 2.4961040062104454

Epoch: 5| Step: 8
Training loss: 1.8044241841096986
Validation loss: 2.496689966809563

Epoch: 5| Step: 9
Training loss: 2.1106940772195917
Validation loss: 2.4771236696000765

Epoch: 5| Step: 10
Training loss: 2.503597532096996
Validation loss: 2.463484822867745

Epoch: 178| Step: 0
Training loss: 2.1705412577284644
Validation loss: 2.41372178182118

Epoch: 5| Step: 1
Training loss: 1.0419965920895953
Validation loss: 2.4261074464098185

Epoch: 5| Step: 2
Training loss: 2.395449886873541
Validation loss: 2.4455155112055817

Epoch: 5| Step: 3
Training loss: 1.547845940323977
Validation loss: 2.4497967656665143

Epoch: 5| Step: 4
Training loss: 1.8435951426501025
Validation loss: 2.4528638748946165

Epoch: 5| Step: 5
Training loss: 2.049344036942184
Validation loss: 2.469521042946148

Epoch: 5| Step: 6
Training loss: 2.230800837765913
Validation loss: 2.4669482841412105

Epoch: 5| Step: 7
Training loss: 2.0538035765036966
Validation loss: 2.4397553600091095

Epoch: 5| Step: 8
Training loss: 2.459927596910823
Validation loss: 2.4227948979932385

Epoch: 5| Step: 9
Training loss: 2.0163509037620537
Validation loss: 2.390545347129252

Epoch: 5| Step: 10
Training loss: 1.920724912329398
Validation loss: 2.3668232548236134

Epoch: 179| Step: 0
Training loss: 2.052330144249724
Validation loss: 2.4243350509516306

Epoch: 5| Step: 1
Training loss: 2.177374374672502
Validation loss: 2.439378057491515

Epoch: 5| Step: 2
Training loss: 2.118403687207969
Validation loss: 2.479687230122127

Epoch: 5| Step: 3
Training loss: 1.9567500538687688
Validation loss: 2.459226983603263

Epoch: 5| Step: 4
Training loss: 1.6972741937805131
Validation loss: 2.4920323572053884

Epoch: 5| Step: 5
Training loss: 1.8683367269021804
Validation loss: 2.470326958556188

Epoch: 5| Step: 6
Training loss: 2.30336524403941
Validation loss: 2.4442327220631275

Epoch: 5| Step: 7
Training loss: 1.8699469187541473
Validation loss: 2.421475326474888

Epoch: 5| Step: 8
Training loss: 1.937554512487606
Validation loss: 2.4608609720373886

Epoch: 5| Step: 9
Training loss: 1.9092027277422077
Validation loss: 2.485575332268932

Epoch: 5| Step: 10
Training loss: 1.9100384198064495
Validation loss: 2.543372779045931

Epoch: 180| Step: 0
Training loss: 1.875285126941306
Validation loss: 2.5064262070218617

Epoch: 5| Step: 1
Training loss: 2.414503532541376
Validation loss: 2.4930016299508058

Epoch: 5| Step: 2
Training loss: 1.8796556528743684
Validation loss: 2.4473521230715924

Epoch: 5| Step: 3
Training loss: 1.7229465231409224
Validation loss: 2.4125114917136066

Epoch: 5| Step: 4
Training loss: 1.886811753660126
Validation loss: 2.400964258197309

Epoch: 5| Step: 5
Training loss: 1.6848045296868044
Validation loss: 2.399584839788532

Epoch: 5| Step: 6
Training loss: 1.9575561306872555
Validation loss: 2.418990821696267

Epoch: 5| Step: 7
Training loss: 2.265984026644669
Validation loss: 2.4101675101149294

Epoch: 5| Step: 8
Training loss: 2.1517895990776448
Validation loss: 2.4396740484214585

Epoch: 5| Step: 9
Training loss: 2.0335637926085326
Validation loss: 2.5044876858743095

Epoch: 5| Step: 10
Training loss: 1.5356749611949267
Validation loss: 2.528933906808805

Epoch: 181| Step: 0
Training loss: 2.0228092588071345
Validation loss: 2.6012357899399903

Epoch: 5| Step: 1
Training loss: 2.3705258639923525
Validation loss: 2.573204323033404

Epoch: 5| Step: 2
Training loss: 2.382968384693496
Validation loss: 2.4737689734086263

Epoch: 5| Step: 3
Training loss: 1.67635877923369
Validation loss: 2.4038869737073174

Epoch: 5| Step: 4
Training loss: 1.9933232678868404
Validation loss: 2.3470768965353446

Epoch: 5| Step: 5
Training loss: 1.9446463306010158
Validation loss: 2.3565114493780612

Epoch: 5| Step: 6
Training loss: 1.9599118533068123
Validation loss: 2.3874309557944398

Epoch: 5| Step: 7
Training loss: 1.9288564274635203
Validation loss: 2.4344379932759677

Epoch: 5| Step: 8
Training loss: 1.8728793549631195
Validation loss: 2.490081690547702

Epoch: 5| Step: 9
Training loss: 1.9575231851347166
Validation loss: 2.4713814634914524

Epoch: 5| Step: 10
Training loss: 1.4028650446564637
Validation loss: 2.498439926555388

Epoch: 182| Step: 0
Training loss: 1.817159713834446
Validation loss: 2.4769053246632278

Epoch: 5| Step: 1
Training loss: 2.187106941877219
Validation loss: 2.465339204827015

Epoch: 5| Step: 2
Training loss: 1.839613266294902
Validation loss: 2.46007087580824

Epoch: 5| Step: 3
Training loss: 1.8091088502777604
Validation loss: 2.4550688523126656

Epoch: 5| Step: 4
Training loss: 2.0508779739095124
Validation loss: 2.46021366806509

Epoch: 5| Step: 5
Training loss: 2.208728131205959
Validation loss: 2.454396721023315

Epoch: 5| Step: 6
Training loss: 1.8586152391766846
Validation loss: 2.507447327160891

Epoch: 5| Step: 7
Training loss: 1.6927153914866868
Validation loss: 2.5455008641846266

Epoch: 5| Step: 8
Training loss: 2.022128709207592
Validation loss: 2.5437957601932957

Epoch: 5| Step: 9
Training loss: 1.9122294465221061
Validation loss: 2.50286829899081

Epoch: 5| Step: 10
Training loss: 1.8963920342920766
Validation loss: 2.459727879488602

Epoch: 183| Step: 0
Training loss: 2.36535382146395
Validation loss: 2.3867925715044356

Epoch: 5| Step: 1
Training loss: 2.1223361203895474
Validation loss: 2.367024684166529

Epoch: 5| Step: 2
Training loss: 1.4872144344846188
Validation loss: 2.370132490114148

Epoch: 5| Step: 3
Training loss: 2.200763491882894
Validation loss: 2.4030544517986807

Epoch: 5| Step: 4
Training loss: 1.769000043145541
Validation loss: 2.4511785958392474

Epoch: 5| Step: 5
Training loss: 1.8433003281345468
Validation loss: 2.429061479271105

Epoch: 5| Step: 6
Training loss: 2.1721987037111825
Validation loss: 2.450365386932467

Epoch: 5| Step: 7
Training loss: 1.6532328492951764
Validation loss: 2.4009696749102933

Epoch: 5| Step: 8
Training loss: 1.7054580667172479
Validation loss: 2.39637756229968

Epoch: 5| Step: 9
Training loss: 1.638979495322329
Validation loss: 2.362550532164156

Epoch: 5| Step: 10
Training loss: 1.984860398406578
Validation loss: 2.368743833228154

Epoch: 184| Step: 0
Training loss: 1.9489020508863382
Validation loss: 2.354539027936291

Epoch: 5| Step: 1
Training loss: 2.4003442398195745
Validation loss: 2.3956353593080104

Epoch: 5| Step: 2
Training loss: 1.7856062107079007
Validation loss: 2.4727987182840416

Epoch: 5| Step: 3
Training loss: 1.759577157854858
Validation loss: 2.526146799751335

Epoch: 5| Step: 4
Training loss: 1.7390806267437136
Validation loss: 2.5690412492329435

Epoch: 5| Step: 5
Training loss: 2.128712832562637
Validation loss: 2.5691866068988736

Epoch: 5| Step: 6
Training loss: 1.461325853922654
Validation loss: 2.433606910567929

Epoch: 5| Step: 7
Training loss: 1.4541206640419742
Validation loss: 2.3273487854880224

Epoch: 5| Step: 8
Training loss: 1.7835660901391592
Validation loss: 2.281166733680111

Epoch: 5| Step: 9
Training loss: 2.1803399753575334
Validation loss: 2.2721438600638497

Epoch: 5| Step: 10
Training loss: 2.5396134468360705
Validation loss: 2.2719371657098058

Epoch: 185| Step: 0
Training loss: 1.9390057895922188
Validation loss: 2.335970606294752

Epoch: 5| Step: 1
Training loss: 1.7873517648547377
Validation loss: 2.462723108185837

Epoch: 5| Step: 2
Training loss: 2.0129743787003846
Validation loss: 2.605794595822882

Epoch: 5| Step: 3
Training loss: 2.187593512579917
Validation loss: 2.7229756439698862

Epoch: 5| Step: 4
Training loss: 2.0582307499124712
Validation loss: 2.6734131609301413

Epoch: 5| Step: 5
Training loss: 1.6784941226468837
Validation loss: 2.5118766991065975

Epoch: 5| Step: 6
Training loss: 2.2184657599829105
Validation loss: 2.3474227808020474

Epoch: 5| Step: 7
Training loss: 2.081216906951733
Validation loss: 2.2949698301745056

Epoch: 5| Step: 8
Training loss: 2.215716477672613
Validation loss: 2.336370228523263

Epoch: 5| Step: 9
Training loss: 2.1056225212718926
Validation loss: 2.3245244274047234

Epoch: 5| Step: 10
Training loss: 1.9176763556399365
Validation loss: 2.3701273723079437

Epoch: 186| Step: 0
Training loss: 1.664584082586178
Validation loss: 2.467934188743867

Epoch: 5| Step: 1
Training loss: 2.090471348155362
Validation loss: 2.5760326985256654

Epoch: 5| Step: 2
Training loss: 2.39808219738249
Validation loss: 2.5773007305456774

Epoch: 5| Step: 3
Training loss: 2.0276653644750526
Validation loss: 2.4960101622649904

Epoch: 5| Step: 4
Training loss: 2.040608839172583
Validation loss: 2.3978779265515375

Epoch: 5| Step: 5
Training loss: 1.7679871818198643
Validation loss: 2.3770305888434153

Epoch: 5| Step: 6
Training loss: 1.9819598180930103
Validation loss: 2.354582628299553

Epoch: 5| Step: 7
Training loss: 1.880032842024592
Validation loss: 2.3300154127871413

Epoch: 5| Step: 8
Training loss: 1.3961842034255436
Validation loss: 2.391997179793966

Epoch: 5| Step: 9
Training loss: 1.4475431806748333
Validation loss: 2.4769803405687925

Epoch: 5| Step: 10
Training loss: 2.4090216391143
Validation loss: 2.51793852519961

Epoch: 187| Step: 0
Training loss: 2.1571101808734707
Validation loss: 2.5469213819077114

Epoch: 5| Step: 1
Training loss: 1.8165168974615755
Validation loss: 2.5752290153750215

Epoch: 5| Step: 2
Training loss: 2.019349080766239
Validation loss: 2.4484428397065314

Epoch: 5| Step: 3
Training loss: 1.6696757174202341
Validation loss: 2.3817279684259094

Epoch: 5| Step: 4
Training loss: 2.0801153761702573
Validation loss: 2.3327391156411945

Epoch: 5| Step: 5
Training loss: 2.0351512125432496
Validation loss: 2.349415164550903

Epoch: 5| Step: 6
Training loss: 2.1524812131764106
Validation loss: 2.3500618663141966

Epoch: 5| Step: 7
Training loss: 1.5087314631754267
Validation loss: 2.3715461439534757

Epoch: 5| Step: 8
Training loss: 1.8562952389326064
Validation loss: 2.3979227194274864

Epoch: 5| Step: 9
Training loss: 1.5947700676762477
Validation loss: 2.4017206954927626

Epoch: 5| Step: 10
Training loss: 2.0428790041757012
Validation loss: 2.424986626068371

Epoch: 188| Step: 0
Training loss: 1.9834112996182534
Validation loss: 2.412201108529559

Epoch: 5| Step: 1
Training loss: 1.8102495758009784
Validation loss: 2.3906200638640405

Epoch: 5| Step: 2
Training loss: 1.1967708193703481
Validation loss: 2.362894351008382

Epoch: 5| Step: 3
Training loss: 1.768549766933899
Validation loss: 2.3283757913439165

Epoch: 5| Step: 4
Training loss: 1.7462987587415002
Validation loss: 2.308957566953742

Epoch: 5| Step: 5
Training loss: 2.3098514958326417
Validation loss: 2.387965327704648

Epoch: 5| Step: 6
Training loss: 2.0812649059048263
Validation loss: 2.445361228671487

Epoch: 5| Step: 7
Training loss: 2.113355145246578
Validation loss: 2.5441800884298824

Epoch: 5| Step: 8
Training loss: 1.6907708293754777
Validation loss: 2.575047910622718

Epoch: 5| Step: 9
Training loss: 1.8122283468890752
Validation loss: 2.492167613655775

Epoch: 5| Step: 10
Training loss: 1.4902269355718223
Validation loss: 2.429427498438517

Epoch: 189| Step: 0
Training loss: 1.7972190859199109
Validation loss: 2.3331396473718344

Epoch: 5| Step: 1
Training loss: 1.7951053031699824
Validation loss: 2.296857103695635

Epoch: 5| Step: 2
Training loss: 1.8056813595625694
Validation loss: 2.284498054758007

Epoch: 5| Step: 3
Training loss: 1.7988249440118453
Validation loss: 2.3206911385429336

Epoch: 5| Step: 4
Training loss: 1.6440836462659647
Validation loss: 2.403849646377235

Epoch: 5| Step: 5
Training loss: 1.8020430176328455
Validation loss: 2.4535911999613242

Epoch: 5| Step: 6
Training loss: 2.0937197099458937
Validation loss: 2.498886936319897

Epoch: 5| Step: 7
Training loss: 1.8093634465034847
Validation loss: 2.6009463846614134

Epoch: 5| Step: 8
Training loss: 1.598127524113219
Validation loss: 2.6127198903310123

Epoch: 5| Step: 9
Training loss: 2.3964032918803975
Validation loss: 2.5024368551009295

Epoch: 5| Step: 10
Training loss: 1.4257338424534967
Validation loss: 2.422720219065001

Epoch: 190| Step: 0
Training loss: 1.394500689345306
Validation loss: 2.3269494097475074

Epoch: 5| Step: 1
Training loss: 1.8893628281615469
Validation loss: 2.303554287875773

Epoch: 5| Step: 2
Training loss: 1.481306820194111
Validation loss: 2.2923971865079156

Epoch: 5| Step: 3
Training loss: 2.045329434970952
Validation loss: 2.2862572831180312

Epoch: 5| Step: 4
Training loss: 2.211815326162729
Validation loss: 2.305095885454373

Epoch: 5| Step: 5
Training loss: 1.6314271589520724
Validation loss: 2.3732378045391207

Epoch: 5| Step: 6
Training loss: 1.680390818414664
Validation loss: 2.4605652167667307

Epoch: 5| Step: 7
Training loss: 1.6508477836231914
Validation loss: 2.5497306508557527

Epoch: 5| Step: 8
Training loss: 2.059254028286733
Validation loss: 2.547099703663966

Epoch: 5| Step: 9
Training loss: 1.8240949764370122
Validation loss: 2.5002622179725837

Epoch: 5| Step: 10
Training loss: 1.90320894904933
Validation loss: 2.453151999788011

Epoch: 191| Step: 0
Training loss: 1.4275026563896944
Validation loss: 2.435327903618934

Epoch: 5| Step: 1
Training loss: 1.8879250407855828
Validation loss: 2.371943655839864

Epoch: 5| Step: 2
Training loss: 1.9173225510713636
Validation loss: 2.414856889350548

Epoch: 5| Step: 3
Training loss: 1.8793230447035336
Validation loss: 2.413023183376019

Epoch: 5| Step: 4
Training loss: 1.42582171657043
Validation loss: 2.469869198737844

Epoch: 5| Step: 5
Training loss: 1.8967636327086432
Validation loss: 2.4401784715182235

Epoch: 5| Step: 6
Training loss: 2.061029314449936
Validation loss: 2.4535712108087786

Epoch: 5| Step: 7
Training loss: 1.885873798852663
Validation loss: 2.4608601813370696

Epoch: 5| Step: 8
Training loss: 1.379273319826501
Validation loss: 2.46154703852837

Epoch: 5| Step: 9
Training loss: 1.8715566807081727
Validation loss: 2.4352813417277055

Epoch: 5| Step: 10
Training loss: 1.818288898024144
Validation loss: 2.3706682356591564

Epoch: 192| Step: 0
Training loss: 1.4513249887680089
Validation loss: 2.3631554555435783

Epoch: 5| Step: 1
Training loss: 1.838164581733914
Validation loss: 2.3526133266661136

Epoch: 5| Step: 2
Training loss: 2.039598533358124
Validation loss: 2.336788203532027

Epoch: 5| Step: 3
Training loss: 2.0140629119517497
Validation loss: 2.3467153077990135

Epoch: 5| Step: 4
Training loss: 1.8642865234210384
Validation loss: 2.347468073385572

Epoch: 5| Step: 5
Training loss: 1.5573950725743475
Validation loss: 2.3637090149570286

Epoch: 5| Step: 6
Training loss: 2.08964877065757
Validation loss: 2.3936685491782574

Epoch: 5| Step: 7
Training loss: 1.7432589123135775
Validation loss: 2.4714189274543354

Epoch: 5| Step: 8
Training loss: 1.902274692543086
Validation loss: 2.551708631065609

Epoch: 5| Step: 9
Training loss: 1.5358404522774116
Validation loss: 2.61704348402234

Epoch: 5| Step: 10
Training loss: 1.3283876047251613
Validation loss: 2.652308754617072

Epoch: 193| Step: 0
Training loss: 1.8106181142015711
Validation loss: 2.567854936860798

Epoch: 5| Step: 1
Training loss: 1.7396843551571686
Validation loss: 2.4962827580219695

Epoch: 5| Step: 2
Training loss: 1.959023928789681
Validation loss: 2.4350468796925995

Epoch: 5| Step: 3
Training loss: 1.2852649584769553
Validation loss: 2.417333634630077

Epoch: 5| Step: 4
Training loss: 1.742787826497496
Validation loss: 2.4101164615700297

Epoch: 5| Step: 5
Training loss: 1.7121012313896276
Validation loss: 2.3322240456702

Epoch: 5| Step: 6
Training loss: 1.9346009992912596
Validation loss: 2.35757648079886

Epoch: 5| Step: 7
Training loss: 1.5177477885371387
Validation loss: 2.3559320444147214

Epoch: 5| Step: 8
Training loss: 2.037481637883673
Validation loss: 2.375059991671469

Epoch: 5| Step: 9
Training loss: 1.6683512121888227
Validation loss: 2.3792267564662217

Epoch: 5| Step: 10
Training loss: 1.5178755735031686
Validation loss: 2.34453615847295

Epoch: 194| Step: 0
Training loss: 1.553960582306876
Validation loss: 2.3129353533337103

Epoch: 5| Step: 1
Training loss: 2.156274878316908
Validation loss: 2.2730908047929432

Epoch: 5| Step: 2
Training loss: 1.9762008999655212
Validation loss: 2.291246894433448

Epoch: 5| Step: 3
Training loss: 1.6410317779523313
Validation loss: 2.3330565028697428

Epoch: 5| Step: 4
Training loss: 1.3877836195292799
Validation loss: 2.387388851441448

Epoch: 5| Step: 5
Training loss: 1.5368303872203537
Validation loss: 2.4721072396705104

Epoch: 5| Step: 6
Training loss: 1.5159072613142914
Validation loss: 2.4394812891699598

Epoch: 5| Step: 7
Training loss: 1.8003280632089287
Validation loss: 2.4424737627490583

Epoch: 5| Step: 8
Training loss: 1.480313496765484
Validation loss: 2.4221261964979592

Epoch: 5| Step: 9
Training loss: 1.5921326452806805
Validation loss: 2.44100368509839

Epoch: 5| Step: 10
Training loss: 1.832945638180362
Validation loss: 2.4317393641038896

Epoch: 195| Step: 0
Training loss: 2.089336925619543
Validation loss: 2.4780810419497366

Epoch: 5| Step: 1
Training loss: 1.6112747830896141
Validation loss: 2.5024360299001387

Epoch: 5| Step: 2
Training loss: 1.852384167652186
Validation loss: 2.498624324695433

Epoch: 5| Step: 3
Training loss: 1.2166790116785555
Validation loss: 2.4494469180753016

Epoch: 5| Step: 4
Training loss: 1.132526966809686
Validation loss: 2.399684825236395

Epoch: 5| Step: 5
Training loss: 1.6975183858423528
Validation loss: 2.4248035784376265

Epoch: 5| Step: 6
Training loss: 2.005736706631288
Validation loss: 2.3456889701431827

Epoch: 5| Step: 7
Training loss: 1.2605448360798992
Validation loss: 2.3572978673491445

Epoch: 5| Step: 8
Training loss: 1.7193201679900614
Validation loss: 2.3614662451850625

Epoch: 5| Step: 9
Training loss: 1.599882258612977
Validation loss: 2.3808431878446012

Epoch: 5| Step: 10
Training loss: 2.0785837455875225
Validation loss: 2.4741646824493966

Epoch: 196| Step: 0
Training loss: 2.002103771961482
Validation loss: 2.4377983421831586

Epoch: 5| Step: 1
Training loss: 1.4185176238940762
Validation loss: 2.4856081339000466

Epoch: 5| Step: 2
Training loss: 1.5977654827802068
Validation loss: 2.4191296713313295

Epoch: 5| Step: 3
Training loss: 1.9208399769081306
Validation loss: 2.4325835922837378

Epoch: 5| Step: 4
Training loss: 1.4819659309692612
Validation loss: 2.4286747559341912

Epoch: 5| Step: 5
Training loss: 1.6721569073166451
Validation loss: 2.388869310384492

Epoch: 5| Step: 6
Training loss: 1.3166229794091178
Validation loss: 2.431596906598198

Epoch: 5| Step: 7
Training loss: 1.233707199049949
Validation loss: 2.399774979396253

Epoch: 5| Step: 8
Training loss: 1.9112857529344265
Validation loss: 2.4190402236563218

Epoch: 5| Step: 9
Training loss: 1.797986358612046
Validation loss: 2.42594481549154

Epoch: 5| Step: 10
Training loss: 1.5080150408918036
Validation loss: 2.452290092116214

Epoch: 197| Step: 0
Training loss: 2.0029058803741147
Validation loss: 2.4255264943983845

Epoch: 5| Step: 1
Training loss: 1.9167934320518805
Validation loss: 2.3822679370441695

Epoch: 5| Step: 2
Training loss: 1.55914128755717
Validation loss: 2.356833874413343

Epoch: 5| Step: 3
Training loss: 1.6036651207099673
Validation loss: 2.353332455216097

Epoch: 5| Step: 4
Training loss: 1.5489383384099862
Validation loss: 2.382427806520783

Epoch: 5| Step: 5
Training loss: 1.1557771385978914
Validation loss: 2.4147037331867045

Epoch: 5| Step: 6
Training loss: 1.2835387280234514
Validation loss: 2.4352959964344514

Epoch: 5| Step: 7
Training loss: 1.6959034816970504
Validation loss: 2.4159885593025394

Epoch: 5| Step: 8
Training loss: 1.5371300042790563
Validation loss: 2.3914414272499034

Epoch: 5| Step: 9
Training loss: 1.6784463244490115
Validation loss: 2.4093446151911264

Epoch: 5| Step: 10
Training loss: 1.6634167775008724
Validation loss: 2.450264158107163

Epoch: 198| Step: 0
Training loss: 1.6137456710367328
Validation loss: 2.435834891741192

Epoch: 5| Step: 1
Training loss: 1.6765371187391749
Validation loss: 2.396574859217364

Epoch: 5| Step: 2
Training loss: 1.494360734272395
Validation loss: 2.390061248402615

Epoch: 5| Step: 3
Training loss: 1.3456569270604466
Validation loss: 2.4350464396181635

Epoch: 5| Step: 4
Training loss: 1.2651050582805123
Validation loss: 2.454886513672903

Epoch: 5| Step: 5
Training loss: 1.7685356792100395
Validation loss: 2.432852185067823

Epoch: 5| Step: 6
Training loss: 1.8224973214421518
Validation loss: 2.459679406251177

Epoch: 5| Step: 7
Training loss: 2.0803029973078226
Validation loss: 2.499159578349017

Epoch: 5| Step: 8
Training loss: 1.8258264551536625
Validation loss: 2.553477263766618

Epoch: 5| Step: 9
Training loss: 1.3779534352051999
Validation loss: 2.446515941949168

Epoch: 5| Step: 10
Training loss: 1.172149473472008
Validation loss: 2.3537971383702625

Epoch: 199| Step: 0
Training loss: 2.201243794577071
Validation loss: 2.2939012295935908

Epoch: 5| Step: 1
Training loss: 1.5274498163648655
Validation loss: 2.2453319665548763

Epoch: 5| Step: 2
Training loss: 1.1772682697322887
Validation loss: 2.2541160364302937

Epoch: 5| Step: 3
Training loss: 1.3939074234946298
Validation loss: 2.306224254890534

Epoch: 5| Step: 4
Training loss: 1.7813116364104717
Validation loss: 2.372771539940521

Epoch: 5| Step: 5
Training loss: 1.774504487626116
Validation loss: 2.4380250222841395

Epoch: 5| Step: 6
Training loss: 1.3355731578828125
Validation loss: 2.4748999611367126

Epoch: 5| Step: 7
Training loss: 1.6715775697620399
Validation loss: 2.4005564352658286

Epoch: 5| Step: 8
Training loss: 1.5603665855258455
Validation loss: 2.310553604895765

Epoch: 5| Step: 9
Training loss: 1.6599321999549457
Validation loss: 2.231017357588152

Epoch: 5| Step: 10
Training loss: 1.6006581800448472
Validation loss: 2.236317419103609

Epoch: 200| Step: 0
Training loss: 0.9902547499386981
Validation loss: 2.2908867967967814

Epoch: 5| Step: 1
Training loss: 1.6019172833741533
Validation loss: 2.349429215665514

Epoch: 5| Step: 2
Training loss: 1.1265400306270361
Validation loss: 2.462827994898015

Epoch: 5| Step: 3
Training loss: 1.4255028021660128
Validation loss: 2.5615089775173563

Epoch: 5| Step: 4
Training loss: 1.7669576831061742
Validation loss: 2.606533879187039

Epoch: 5| Step: 5
Training loss: 1.5496491496561502
Validation loss: 2.519442446530763

Epoch: 5| Step: 6
Training loss: 2.0385383721586363
Validation loss: 2.4777247481512443

Epoch: 5| Step: 7
Training loss: 1.3017192585895714
Validation loss: 2.4277015886899567

Epoch: 5| Step: 8
Training loss: 1.7779053188641567
Validation loss: 2.3708524547245333

Epoch: 5| Step: 9
Training loss: 1.7563200315583642
Validation loss: 2.2960499541607478

Epoch: 5| Step: 10
Training loss: 1.871133186705192
Validation loss: 2.2683395717346673

Epoch: 201| Step: 0
Training loss: 1.8728084472123547
Validation loss: 2.2667199125255064

Epoch: 5| Step: 1
Training loss: 1.2837479130208882
Validation loss: 2.2481727803251945

Epoch: 5| Step: 2
Training loss: 1.386918948054388
Validation loss: 2.2633953253098293

Epoch: 5| Step: 3
Training loss: 1.8899617568693259
Validation loss: 2.247095015868312

Epoch: 5| Step: 4
Training loss: 1.6769700890764219
Validation loss: 2.27759569646949

Epoch: 5| Step: 5
Training loss: 1.3284589908488431
Validation loss: 2.3179928995618426

Epoch: 5| Step: 6
Training loss: 1.5837423984071175
Validation loss: 2.3515225596046503

Epoch: 5| Step: 7
Training loss: 1.4687288161028416
Validation loss: 2.445642819019379

Epoch: 5| Step: 8
Training loss: 1.742814366074757
Validation loss: 2.4923456572395395

Epoch: 5| Step: 9
Training loss: 1.3440828133001288
Validation loss: 2.523677180476608

Epoch: 5| Step: 10
Training loss: 1.5602248603202529
Validation loss: 2.4788795967484547

Epoch: 202| Step: 0
Training loss: 1.3151333594780321
Validation loss: 2.394124289751732

Epoch: 5| Step: 1
Training loss: 1.63200672472709
Validation loss: 2.3310782149134237

Epoch: 5| Step: 2
Training loss: 1.8442996224202621
Validation loss: 2.2982905327834398

Epoch: 5| Step: 3
Training loss: 1.303519725707374
Validation loss: 2.254869269366499

Epoch: 5| Step: 4
Training loss: 1.3651148316705268
Validation loss: 2.294197677956909

Epoch: 5| Step: 5
Training loss: 1.5312147331069104
Validation loss: 2.288962397601483

Epoch: 5| Step: 6
Training loss: 1.5393799585099148
Validation loss: 2.3543170612663613

Epoch: 5| Step: 7
Training loss: 1.5020263019092566
Validation loss: 2.364108408502826

Epoch: 5| Step: 8
Training loss: 1.8451729149154288
Validation loss: 2.378772213939002

Epoch: 5| Step: 9
Training loss: 1.2768254993196566
Validation loss: 2.345958513059211

Epoch: 5| Step: 10
Training loss: 1.9357122356401928
Validation loss: 2.338258668928995

Epoch: 203| Step: 0
Training loss: 1.8524759992725572
Validation loss: 2.4212875220000147

Epoch: 5| Step: 1
Training loss: 1.2105175643774782
Validation loss: 2.4458053465958174

Epoch: 5| Step: 2
Training loss: 1.6602925323198914
Validation loss: 2.3938648774315694

Epoch: 5| Step: 3
Training loss: 1.5360888882884964
Validation loss: 2.3401785708258287

Epoch: 5| Step: 4
Training loss: 1.5053053651925303
Validation loss: 2.3163929636457206

Epoch: 5| Step: 5
Training loss: 1.6998708591776817
Validation loss: 2.2919997956649647

Epoch: 5| Step: 6
Training loss: 1.1909570566341865
Validation loss: 2.296784576138431

Epoch: 5| Step: 7
Training loss: 1.722116537167049
Validation loss: 2.4199296975218973

Epoch: 5| Step: 8
Training loss: 1.794175417226574
Validation loss: 2.4475809569202442

Epoch: 5| Step: 9
Training loss: 1.5132960880558444
Validation loss: 2.464611303502072

Epoch: 5| Step: 10
Training loss: 1.3478172316668262
Validation loss: 2.39709653327819

Epoch: 204| Step: 0
Training loss: 1.6700085355346377
Validation loss: 2.319451274013979

Epoch: 5| Step: 1
Training loss: 1.3248564498442035
Validation loss: 2.2625632344824558

Epoch: 5| Step: 2
Training loss: 1.879901138810834
Validation loss: 2.25393572380151

Epoch: 5| Step: 3
Training loss: 1.6180816979358825
Validation loss: 2.2603112542997277

Epoch: 5| Step: 4
Training loss: 1.5822957889117282
Validation loss: 2.2904052469591623

Epoch: 5| Step: 5
Training loss: 1.595304591115389
Validation loss: 2.350596184030829

Epoch: 5| Step: 6
Training loss: 1.3241647354857708
Validation loss: 2.4119803737703145

Epoch: 5| Step: 7
Training loss: 1.1041351469807292
Validation loss: 2.444572368435113

Epoch: 5| Step: 8
Training loss: 1.9005247345167622
Validation loss: 2.477709564244465

Epoch: 5| Step: 9
Training loss: 1.2827834280532173
Validation loss: 2.38315607852149

Epoch: 5| Step: 10
Training loss: 1.2775843215854625
Validation loss: 2.3596326978880193

Epoch: 205| Step: 0
Training loss: 1.469160144435854
Validation loss: 2.353313742555248

Epoch: 5| Step: 1
Training loss: 1.5070955617737434
Validation loss: 2.35417321179092

Epoch: 5| Step: 2
Training loss: 0.9908427038356564
Validation loss: 2.296179691783285

Epoch: 5| Step: 3
Training loss: 1.6508899542803568
Validation loss: 2.3085763398734067

Epoch: 5| Step: 4
Training loss: 1.7256591643171029
Validation loss: 2.286941339018988

Epoch: 5| Step: 5
Training loss: 0.917369988140466
Validation loss: 2.3128564455121836

Epoch: 5| Step: 6
Training loss: 1.6568471443888193
Validation loss: 2.3351598137792267

Epoch: 5| Step: 7
Training loss: 1.628788859210482
Validation loss: 2.3635226142797396

Epoch: 5| Step: 8
Training loss: 1.466430130582722
Validation loss: 2.3770409780644837

Epoch: 5| Step: 9
Training loss: 1.3373890625766711
Validation loss: 2.350042388531975

Epoch: 5| Step: 10
Training loss: 1.7762810181306037
Validation loss: 2.3124474516986875

Epoch: 206| Step: 0
Training loss: 1.3806263944274297
Validation loss: 2.370684744254111

Epoch: 5| Step: 1
Training loss: 1.9902803754497482
Validation loss: 2.380369066311688

Epoch: 5| Step: 2
Training loss: 1.5689207523626596
Validation loss: 2.3608600647869227

Epoch: 5| Step: 3
Training loss: 1.7526107115337568
Validation loss: 2.3632397090630843

Epoch: 5| Step: 4
Training loss: 1.5043516614155126
Validation loss: 2.33384136596435

Epoch: 5| Step: 5
Training loss: 1.5735095677165216
Validation loss: 2.3171173693587765

Epoch: 5| Step: 6
Training loss: 1.04839590248783
Validation loss: 2.2639162102548855

Epoch: 5| Step: 7
Training loss: 1.3292115647357305
Validation loss: 2.2509139789913064

Epoch: 5| Step: 8
Training loss: 1.3109106704458058
Validation loss: 2.2671708527371757

Epoch: 5| Step: 9
Training loss: 1.3438360053639131
Validation loss: 2.2641662699336473

Epoch: 5| Step: 10
Training loss: 1.0128425042387583
Validation loss: 2.3821768114630992

Epoch: 207| Step: 0
Training loss: 1.85706410136231
Validation loss: 2.4174442924870228

Epoch: 5| Step: 1
Training loss: 1.1044335792432622
Validation loss: 2.3989460061259438

Epoch: 5| Step: 2
Training loss: 1.3037880178231858
Validation loss: 2.379885876091718

Epoch: 5| Step: 3
Training loss: 1.3394982251094665
Validation loss: 2.3139421222802907

Epoch: 5| Step: 4
Training loss: 1.310326001902659
Validation loss: 2.2657818313874722

Epoch: 5| Step: 5
Training loss: 1.652484211463932
Validation loss: 2.234565725002146

Epoch: 5| Step: 6
Training loss: 1.519697165563377
Validation loss: 2.2052701119901776

Epoch: 5| Step: 7
Training loss: 1.3338668570410699
Validation loss: 2.2344288944623285

Epoch: 5| Step: 8
Training loss: 1.356382386386887
Validation loss: 2.3594149090616603

Epoch: 5| Step: 9
Training loss: 1.8134506626364695
Validation loss: 2.4589385821770486

Epoch: 5| Step: 10
Training loss: 1.392375016347822
Validation loss: 2.497500558643048

Epoch: 208| Step: 0
Training loss: 1.4103677860431527
Validation loss: 2.4451309813465363

Epoch: 5| Step: 1
Training loss: 1.369078717757182
Validation loss: 2.4423226596188337

Epoch: 5| Step: 2
Training loss: 1.7679500293962669
Validation loss: 2.2700063528570396

Epoch: 5| Step: 3
Training loss: 1.3791135032449138
Validation loss: 2.2443143397406597

Epoch: 5| Step: 4
Training loss: 1.1763502499448661
Validation loss: 2.2575872159629546

Epoch: 5| Step: 5
Training loss: 1.4677742496775033
Validation loss: 2.270043729647573

Epoch: 5| Step: 6
Training loss: 1.1416706361260751
Validation loss: 2.2573647645401915

Epoch: 5| Step: 7
Training loss: 1.4076600952299165
Validation loss: 2.3521758698770814

Epoch: 5| Step: 8
Training loss: 1.491477118157713
Validation loss: 2.371283584863639

Epoch: 5| Step: 9
Training loss: 1.8797521768733134
Validation loss: 2.423250305512202

Epoch: 5| Step: 10
Training loss: 1.4362191838211291
Validation loss: 2.4417381662815942

Epoch: 209| Step: 0
Training loss: 1.621239933638546
Validation loss: 2.3446747954959575

Epoch: 5| Step: 1
Training loss: 1.2603425826481829
Validation loss: 2.3078111323839274

Epoch: 5| Step: 2
Training loss: 1.8428081757829662
Validation loss: 2.2583321757707724

Epoch: 5| Step: 3
Training loss: 1.2175850313325494
Validation loss: 2.3007071646940243

Epoch: 5| Step: 4
Training loss: 1.5888670374442921
Validation loss: 2.2802719669557323

Epoch: 5| Step: 5
Training loss: 1.0853407063815643
Validation loss: 2.2781886890976675

Epoch: 5| Step: 6
Training loss: 1.1199671171674537
Validation loss: 2.3222524836676115

Epoch: 5| Step: 7
Training loss: 1.5795542222123347
Validation loss: 2.342024193883133

Epoch: 5| Step: 8
Training loss: 1.6600455931641356
Validation loss: 2.350736999231552

Epoch: 5| Step: 9
Training loss: 1.2146548403350197
Validation loss: 2.333398454024034

Epoch: 5| Step: 10
Training loss: 1.2697518494486084
Validation loss: 2.3389188309448716

Epoch: 210| Step: 0
Training loss: 1.3656637801680733
Validation loss: 2.3199808886362843

Epoch: 5| Step: 1
Training loss: 1.5961311354625651
Validation loss: 2.3034053227444145

Epoch: 5| Step: 2
Training loss: 1.4013756941161675
Validation loss: 2.344143916016097

Epoch: 5| Step: 3
Training loss: 1.784074718642644
Validation loss: 2.2918328844872136

Epoch: 5| Step: 4
Training loss: 1.080129225558516
Validation loss: 2.340551846569952

Epoch: 5| Step: 5
Training loss: 0.8975019476718011
Validation loss: 2.3357563410178503

Epoch: 5| Step: 6
Training loss: 1.8829602701915602
Validation loss: 2.3676380833423565

Epoch: 5| Step: 7
Training loss: 1.2546797888721928
Validation loss: 2.4162404515843727

Epoch: 5| Step: 8
Training loss: 1.049388998368794
Validation loss: 2.414303102923804

Epoch: 5| Step: 9
Training loss: 1.4364026068744251
Validation loss: 2.490512377128418

Epoch: 5| Step: 10
Training loss: 1.4018827652939363
Validation loss: 2.5084411193067466

Epoch: 211| Step: 0
Training loss: 0.9091956181262416
Validation loss: 2.404304945085599

Epoch: 5| Step: 1
Training loss: 1.1863243406936936
Validation loss: 2.340928638422145

Epoch: 5| Step: 2
Training loss: 1.3692984714478074
Validation loss: 2.3074571277994953

Epoch: 5| Step: 3
Training loss: 1.4323170145277164
Validation loss: 2.2629786214312912

Epoch: 5| Step: 4
Training loss: 1.5313550951956856
Validation loss: 2.2278837741340674

Epoch: 5| Step: 5
Training loss: 1.2735246499787092
Validation loss: 2.2771609839176934

Epoch: 5| Step: 6
Training loss: 1.356027405574417
Validation loss: 2.312411461520681

Epoch: 5| Step: 7
Training loss: 1.3213819427437754
Validation loss: 2.3629253686630856

Epoch: 5| Step: 8
Training loss: 1.4995360451665656
Validation loss: 2.381364987032628

Epoch: 5| Step: 9
Training loss: 1.4585838738440666
Validation loss: 2.3607497257403307

Epoch: 5| Step: 10
Training loss: 1.8128980002307693
Validation loss: 2.3275723618692674

Epoch: 212| Step: 0
Training loss: 0.973471977394835
Validation loss: 2.272870570626601

Epoch: 5| Step: 1
Training loss: 1.479321279190988
Validation loss: 2.2497156298467775

Epoch: 5| Step: 2
Training loss: 1.5407244234328221
Validation loss: 2.2643542388255633

Epoch: 5| Step: 3
Training loss: 1.326771259394148
Validation loss: 2.2952221835083115

Epoch: 5| Step: 4
Training loss: 1.7085060714600402
Validation loss: 2.3034397168626786

Epoch: 5| Step: 5
Training loss: 1.4611351980988663
Validation loss: 2.367963945065063

Epoch: 5| Step: 6
Training loss: 1.4237743728601215
Validation loss: 2.4377745649098523

Epoch: 5| Step: 7
Training loss: 1.0971221710547598
Validation loss: 2.4947221306008194

Epoch: 5| Step: 8
Training loss: 1.2972161637100523
Validation loss: 2.4855932632208164

Epoch: 5| Step: 9
Training loss: 1.449716569889047
Validation loss: 2.437515213516335

Epoch: 5| Step: 10
Training loss: 1.162642105194902
Validation loss: 2.38905820602651

Epoch: 213| Step: 0
Training loss: 1.4090714019812296
Validation loss: 2.3235294496332854

Epoch: 5| Step: 1
Training loss: 0.8141874616486311
Validation loss: 2.2513716605978322

Epoch: 5| Step: 2
Training loss: 1.218174138103173
Validation loss: 2.253959772991486

Epoch: 5| Step: 3
Training loss: 1.3124458665129224
Validation loss: 2.248917828147583

Epoch: 5| Step: 4
Training loss: 1.249517490720964
Validation loss: 2.291118785290077

Epoch: 5| Step: 5
Training loss: 1.9351594385113897
Validation loss: 2.3630328157744267

Epoch: 5| Step: 6
Training loss: 1.0516331845881732
Validation loss: 2.417086497074767

Epoch: 5| Step: 7
Training loss: 1.3391241693706886
Validation loss: 2.467418006540144

Epoch: 5| Step: 8
Training loss: 1.434107051912944
Validation loss: 2.4820291272652675

Epoch: 5| Step: 9
Training loss: 1.5368023848162153
Validation loss: 2.501310771927411

Epoch: 5| Step: 10
Training loss: 1.2846028258141586
Validation loss: 2.4503381618387827

Epoch: 214| Step: 0
Training loss: 1.1748869273382585
Validation loss: 2.412763945694585

Epoch: 5| Step: 1
Training loss: 1.1584726055497139
Validation loss: 2.3927370934646306

Epoch: 5| Step: 2
Training loss: 0.99058767182211
Validation loss: 2.3199199920301825

Epoch: 5| Step: 3
Training loss: 1.5562196016215286
Validation loss: 2.2421964868376367

Epoch: 5| Step: 4
Training loss: 1.5743368781283633
Validation loss: 2.2405939209256385

Epoch: 5| Step: 5
Training loss: 1.145226953910372
Validation loss: 2.25128339582496

Epoch: 5| Step: 6
Training loss: 1.3917197729397974
Validation loss: 2.280724092155504

Epoch: 5| Step: 7
Training loss: 1.2769674044207726
Validation loss: 2.2990763137659904

Epoch: 5| Step: 8
Training loss: 0.9642424466502647
Validation loss: 2.308172699728647

Epoch: 5| Step: 9
Training loss: 1.7652949472001418
Validation loss: 2.3617737915246257

Epoch: 5| Step: 10
Training loss: 1.3645648760918396
Validation loss: 2.4252149275441286

Epoch: 215| Step: 0
Training loss: 1.6586735106528367
Validation loss: 2.4851623750681253

Epoch: 5| Step: 1
Training loss: 1.694244259159651
Validation loss: 2.439179911471052

Epoch: 5| Step: 2
Training loss: 1.4520739784468442
Validation loss: 2.460888379178568

Epoch: 5| Step: 3
Training loss: 0.8749031626385309
Validation loss: 2.431076209522086

Epoch: 5| Step: 4
Training loss: 1.1582197474401352
Validation loss: 2.387038126937059

Epoch: 5| Step: 5
Training loss: 1.2549546751827336
Validation loss: 2.330008413973964

Epoch: 5| Step: 6
Training loss: 1.0985791002495018
Validation loss: 2.2827091031882203

Epoch: 5| Step: 7
Training loss: 1.1039173036576695
Validation loss: 2.296226408215924

Epoch: 5| Step: 8
Training loss: 1.3408191122451156
Validation loss: 2.316050620341619

Epoch: 5| Step: 9
Training loss: 1.2251359941938729
Validation loss: 2.3711581571034053

Epoch: 5| Step: 10
Training loss: 1.441991671639993
Validation loss: 2.385560918296443

Epoch: 216| Step: 0
Training loss: 1.4039303615666925
Validation loss: 2.3550882233626624

Epoch: 5| Step: 1
Training loss: 1.0996854223918449
Validation loss: 2.386906494760808

Epoch: 5| Step: 2
Training loss: 1.2050418693739546
Validation loss: 2.3923485826917883

Epoch: 5| Step: 3
Training loss: 1.6407196017647228
Validation loss: 2.399984969156977

Epoch: 5| Step: 4
Training loss: 1.0648758075279832
Validation loss: 2.381421607112726

Epoch: 5| Step: 5
Training loss: 1.0429554341927065
Validation loss: 2.3559123529151607

Epoch: 5| Step: 6
Training loss: 1.6706204564938625
Validation loss: 2.3028636558856017

Epoch: 5| Step: 7
Training loss: 1.4723845618290752
Validation loss: 2.35618953458065

Epoch: 5| Step: 8
Training loss: 0.9742377725195578
Validation loss: 2.3916539205759104

Epoch: 5| Step: 9
Training loss: 1.1434907317092446
Validation loss: 2.4467075466042276

Epoch: 5| Step: 10
Training loss: 1.1408984757841114
Validation loss: 2.492150857446253

Epoch: 217| Step: 0
Training loss: 1.4196307737893576
Validation loss: 2.4355165138059083

Epoch: 5| Step: 1
Training loss: 0.9620330272247369
Validation loss: 2.4537086155740506

Epoch: 5| Step: 2
Training loss: 1.0255722611633646
Validation loss: 2.43824162755718

Epoch: 5| Step: 3
Training loss: 1.515902149776744
Validation loss: 2.3877130325867406

Epoch: 5| Step: 4
Training loss: 1.6279310055952223
Validation loss: 2.325544487652448

Epoch: 5| Step: 5
Training loss: 1.753444211461234
Validation loss: 2.364821863568611

Epoch: 5| Step: 6
Training loss: 0.979263050665334
Validation loss: 2.3407570918617826

Epoch: 5| Step: 7
Training loss: 1.3112465004378786
Validation loss: 2.3042344682729183

Epoch: 5| Step: 8
Training loss: 0.8298558195540423
Validation loss: 2.279834567235203

Epoch: 5| Step: 9
Training loss: 1.0599140787389711
Validation loss: 2.347135126341358

Epoch: 5| Step: 10
Training loss: 1.198594020683846
Validation loss: 2.3758032443776065

Epoch: 218| Step: 0
Training loss: 1.430672311596312
Validation loss: 2.493522933025386

Epoch: 5| Step: 1
Training loss: 0.8528649055926852
Validation loss: 2.4818203050679863

Epoch: 5| Step: 2
Training loss: 1.3104305755815087
Validation loss: 2.5148339918017912

Epoch: 5| Step: 3
Training loss: 1.320671077994987
Validation loss: 2.405464647222962

Epoch: 5| Step: 4
Training loss: 1.0673287562078166
Validation loss: 2.3507619284135806

Epoch: 5| Step: 5
Training loss: 1.2847208601569209
Validation loss: 2.2703355057411363

Epoch: 5| Step: 6
Training loss: 1.7037153008468644
Validation loss: 2.3105586560493983

Epoch: 5| Step: 7
Training loss: 1.509576585785985
Validation loss: 2.3257796812918348

Epoch: 5| Step: 8
Training loss: 1.4033217990896572
Validation loss: 2.3842034029696446

Epoch: 5| Step: 9
Training loss: 1.1081589494680228
Validation loss: 2.3891379996863304

Epoch: 5| Step: 10
Training loss: 0.814314466789834
Validation loss: 2.46799580944197

Epoch: 219| Step: 0
Training loss: 1.3189038318023911
Validation loss: 2.4606690421352497

Epoch: 5| Step: 1
Training loss: 1.390074803240065
Validation loss: 2.5240218268493178

Epoch: 5| Step: 2
Training loss: 0.9652552480073313
Validation loss: 2.4361646710932545

Epoch: 5| Step: 3
Training loss: 1.1296630223578363
Validation loss: 2.3746491055857537

Epoch: 5| Step: 4
Training loss: 1.3500431760312104
Validation loss: 2.2555861830200032

Epoch: 5| Step: 5
Training loss: 1.0438971227330507
Validation loss: 2.2486111081181384

Epoch: 5| Step: 6
Training loss: 1.1380668590092835
Validation loss: 2.266446634967872

Epoch: 5| Step: 7
Training loss: 1.2342642722383486
Validation loss: 2.3452545652718646

Epoch: 5| Step: 8
Training loss: 1.2970170552228686
Validation loss: 2.4329351492848286

Epoch: 5| Step: 9
Training loss: 1.6837519241695837
Validation loss: 2.5219021254110188

Epoch: 5| Step: 10
Training loss: 1.346310947494352
Validation loss: 2.563136265135452

Epoch: 220| Step: 0
Training loss: 1.662243417429358
Validation loss: 2.508862442485634

Epoch: 5| Step: 1
Training loss: 0.8788707810768471
Validation loss: 2.4636501687357715

Epoch: 5| Step: 2
Training loss: 1.739902246294359
Validation loss: 2.354115184388353

Epoch: 5| Step: 3
Training loss: 1.007124673491784
Validation loss: 2.291785876025256

Epoch: 5| Step: 4
Training loss: 1.1384743573162026
Validation loss: 2.2529832462079495

Epoch: 5| Step: 5
Training loss: 1.0414013461135596
Validation loss: 2.2453742542643673

Epoch: 5| Step: 6
Training loss: 1.3318109861588443
Validation loss: 2.2610535007856933

Epoch: 5| Step: 7
Training loss: 1.3857742746736534
Validation loss: 2.277664288373806

Epoch: 5| Step: 8
Training loss: 1.2779265774364428
Validation loss: 2.392832233126918

Epoch: 5| Step: 9
Training loss: 0.8635271507549386
Validation loss: 2.4896949382296216

Epoch: 5| Step: 10
Training loss: 1.19743761628823
Validation loss: 2.560137078711561

Epoch: 221| Step: 0
Training loss: 1.3461806912941818
Validation loss: 2.4960116371735945

Epoch: 5| Step: 1
Training loss: 1.3993542186562111
Validation loss: 2.466584392481991

Epoch: 5| Step: 2
Training loss: 1.1612196136703816
Validation loss: 2.33742912118776

Epoch: 5| Step: 3
Training loss: 1.028138234247525
Validation loss: 2.2545796392177517

Epoch: 5| Step: 4
Training loss: 1.0248393584185083
Validation loss: 2.2645595943664283

Epoch: 5| Step: 5
Training loss: 1.00052235788722
Validation loss: 2.256013063123838

Epoch: 5| Step: 6
Training loss: 1.4258098442659228
Validation loss: 2.2655098993005254

Epoch: 5| Step: 7
Training loss: 1.4559665092923773
Validation loss: 2.317813496947775

Epoch: 5| Step: 8
Training loss: 1.1298479422659127
Validation loss: 2.3885543727666043

Epoch: 5| Step: 9
Training loss: 1.2348120676132475
Validation loss: 2.483543117928751

Epoch: 5| Step: 10
Training loss: 1.3339005495601775
Validation loss: 2.519721661096356

Epoch: 222| Step: 0
Training loss: 1.4765004947298528
Validation loss: 2.516935845308622

Epoch: 5| Step: 1
Training loss: 0.9391012504313401
Validation loss: 2.445487401854096

Epoch: 5| Step: 2
Training loss: 0.7235867669697956
Validation loss: 2.3615134102965705

Epoch: 5| Step: 3
Training loss: 1.5235297541928778
Validation loss: 2.319488996877297

Epoch: 5| Step: 4
Training loss: 0.8696583438198207
Validation loss: 2.3059739360337628

Epoch: 5| Step: 5
Training loss: 1.2624597410827065
Validation loss: 2.3155649477945253

Epoch: 5| Step: 6
Training loss: 1.273782086702907
Validation loss: 2.3311155659678824

Epoch: 5| Step: 7
Training loss: 1.0943369788989221
Validation loss: 2.3450028678403703

Epoch: 5| Step: 8
Training loss: 1.429324578253659
Validation loss: 2.4563802274672106

Epoch: 5| Step: 9
Training loss: 1.3181563157421876
Validation loss: 2.4701122909039914

Epoch: 5| Step: 10
Training loss: 1.2175566871182777
Validation loss: 2.4198486340348078

Epoch: 223| Step: 0
Training loss: 1.8081609813750712
Validation loss: 2.381733115662048

Epoch: 5| Step: 1
Training loss: 1.3031923326985673
Validation loss: 2.396225055025085

Epoch: 5| Step: 2
Training loss: 1.254860108166446
Validation loss: 2.307302315831681

Epoch: 5| Step: 3
Training loss: 0.8831591305410895
Validation loss: 2.3275209061442483

Epoch: 5| Step: 4
Training loss: 0.8643098459905748
Validation loss: 2.3050931339633145

Epoch: 5| Step: 5
Training loss: 1.2991905223099065
Validation loss: 2.3017396083301973

Epoch: 5| Step: 6
Training loss: 1.1857305695503866
Validation loss: 2.3669878239421003

Epoch: 5| Step: 7
Training loss: 1.1921698452703473
Validation loss: 2.4271630280203835

Epoch: 5| Step: 8
Training loss: 1.185074588021701
Validation loss: 2.4337861655228847

Epoch: 5| Step: 9
Training loss: 0.9469663166794989
Validation loss: 2.4531444765374193

Epoch: 5| Step: 10
Training loss: 1.0304192751676493
Validation loss: 2.4414089906738647

Epoch: 224| Step: 0
Training loss: 0.798317370550472
Validation loss: 2.4113736248179127

Epoch: 5| Step: 1
Training loss: 1.0416829044348015
Validation loss: 2.4528551158970524

Epoch: 5| Step: 2
Training loss: 1.2003498024520873
Validation loss: 2.4167982588242283

Epoch: 5| Step: 3
Training loss: 1.2323969673747162
Validation loss: 2.3364133192123

Epoch: 5| Step: 4
Training loss: 1.3624408394104879
Validation loss: 2.322949820948256

Epoch: 5| Step: 5
Training loss: 0.9053583362525262
Validation loss: 2.313244863475537

Epoch: 5| Step: 6
Training loss: 1.1536880669135963
Validation loss: 2.318016367112279

Epoch: 5| Step: 7
Training loss: 1.268575596214933
Validation loss: 2.350401768805243

Epoch: 5| Step: 8
Training loss: 0.9563593783186564
Validation loss: 2.378672890645876

Epoch: 5| Step: 9
Training loss: 1.270627015464524
Validation loss: 2.404448003475741

Epoch: 5| Step: 10
Training loss: 1.605672855814818
Validation loss: 2.3521079037108876

Epoch: 225| Step: 0
Training loss: 1.050849657065539
Validation loss: 2.3477211772384456

Epoch: 5| Step: 1
Training loss: 1.4254499494689956
Validation loss: 2.34488894008343

Epoch: 5| Step: 2
Training loss: 1.2430653858802474
Validation loss: 2.3349841137427956

Epoch: 5| Step: 3
Training loss: 1.0855036905051128
Validation loss: 2.3446463705008496

Epoch: 5| Step: 4
Training loss: 1.317820120833074
Validation loss: 2.313310548187789

Epoch: 5| Step: 5
Training loss: 0.99722638529266
Validation loss: 2.381557924700818

Epoch: 5| Step: 6
Training loss: 1.4248470224283722
Validation loss: 2.38200419524712

Epoch: 5| Step: 7
Training loss: 0.8392656687687727
Validation loss: 2.393327290664482

Epoch: 5| Step: 8
Training loss: 1.0077789064471359
Validation loss: 2.401352214707754

Epoch: 5| Step: 9
Training loss: 0.9727413033062589
Validation loss: 2.349042547475443

Epoch: 5| Step: 10
Training loss: 1.307751649377505
Validation loss: 2.3986134727936945

Epoch: 226| Step: 0
Training loss: 0.9867897992744543
Validation loss: 2.3448743850854847

Epoch: 5| Step: 1
Training loss: 0.9866739101294383
Validation loss: 2.410307191902225

Epoch: 5| Step: 2
Training loss: 1.375134678227058
Validation loss: 2.378579905006757

Epoch: 5| Step: 3
Training loss: 1.0962949300364648
Validation loss: 2.3762457364906373

Epoch: 5| Step: 4
Training loss: 1.1827713025677689
Validation loss: 2.341757826942387

Epoch: 5| Step: 5
Training loss: 0.7678098838305123
Validation loss: 2.302980288231934

Epoch: 5| Step: 6
Training loss: 1.3864865390689551
Validation loss: 2.3186163264482

Epoch: 5| Step: 7
Training loss: 1.161922253842575
Validation loss: 2.3570822240423883

Epoch: 5| Step: 8
Training loss: 1.5726145102528037
Validation loss: 2.4235886707726957

Epoch: 5| Step: 9
Training loss: 1.1923901606902727
Validation loss: 2.4054214016149764

Epoch: 5| Step: 10
Training loss: 0.5123191688925401
Validation loss: 2.393751953624561

Epoch: 227| Step: 0
Training loss: 1.3287988187590603
Validation loss: 2.3963481619225253

Epoch: 5| Step: 1
Training loss: 0.8520340969780361
Validation loss: 2.3540452066796718

Epoch: 5| Step: 2
Training loss: 0.7993260256608483
Validation loss: 2.342526865549556

Epoch: 5| Step: 3
Training loss: 1.423219736570514
Validation loss: 2.380226337853664

Epoch: 5| Step: 4
Training loss: 1.3339646255572744
Validation loss: 2.3774893543065496

Epoch: 5| Step: 5
Training loss: 1.2297049437549536
Validation loss: 2.349357537406885

Epoch: 5| Step: 6
Training loss: 0.87926262306261
Validation loss: 2.338074549492997

Epoch: 5| Step: 7
Training loss: 1.1505582781193124
Validation loss: 2.384190964319404

Epoch: 5| Step: 8
Training loss: 1.2383789120257422
Validation loss: 2.3551823149996873

Epoch: 5| Step: 9
Training loss: 1.1410510691381375
Validation loss: 2.4059342197243443

Epoch: 5| Step: 10
Training loss: 1.0727142896182487
Validation loss: 2.392246190732234

Epoch: 228| Step: 0
Training loss: 1.0154391779000267
Validation loss: 2.3823647516664597

Epoch: 5| Step: 1
Training loss: 1.5049524408727806
Validation loss: 2.3655301485587743

Epoch: 5| Step: 2
Training loss: 1.0188447241245968
Validation loss: 2.3290789881471077

Epoch: 5| Step: 3
Training loss: 0.8409385465107235
Validation loss: 2.2840037596755516

Epoch: 5| Step: 4
Training loss: 1.2850820409805677
Validation loss: 2.2703561732155517

Epoch: 5| Step: 5
Training loss: 1.0199140509689189
Validation loss: 2.2501126247507517

Epoch: 5| Step: 6
Training loss: 1.32730090435316
Validation loss: 2.242116848023749

Epoch: 5| Step: 7
Training loss: 0.9726761046072206
Validation loss: 2.306077539977902

Epoch: 5| Step: 8
Training loss: 1.2864387397458048
Validation loss: 2.3671328787639587

Epoch: 5| Step: 9
Training loss: 0.9647830218149748
Validation loss: 2.4283388719213956

Epoch: 5| Step: 10
Training loss: 1.0942664970494809
Validation loss: 2.4535495120864184

Epoch: 229| Step: 0
Training loss: 1.2566384943646698
Validation loss: 2.4661442681422474

Epoch: 5| Step: 1
Training loss: 1.568428845606867
Validation loss: 2.4214908587624673

Epoch: 5| Step: 2
Training loss: 0.6331868183123657
Validation loss: 2.3861984116180786

Epoch: 5| Step: 3
Training loss: 1.123768132013637
Validation loss: 2.339621884297559

Epoch: 5| Step: 4
Training loss: 1.2379451259413394
Validation loss: 2.339095685430558

Epoch: 5| Step: 5
Training loss: 1.5462484921299235
Validation loss: 2.3251376573183253

Epoch: 5| Step: 6
Training loss: 1.0645282123924913
Validation loss: 2.346169309388359

Epoch: 5| Step: 7
Training loss: 0.9601011591006071
Validation loss: 2.380140646693305

Epoch: 5| Step: 8
Training loss: 1.029256859712718
Validation loss: 2.3780595774812925

Epoch: 5| Step: 9
Training loss: 0.7199290597591285
Validation loss: 2.4517997630076707

Epoch: 5| Step: 10
Training loss: 0.7874579781719322
Validation loss: 2.466332946727664

Epoch: 230| Step: 0
Training loss: 0.826551381777314
Validation loss: 2.488395487518705

Epoch: 5| Step: 1
Training loss: 0.9791608499124241
Validation loss: 2.4686998097665924

Epoch: 5| Step: 2
Training loss: 1.2801137398313118
Validation loss: 2.434159504860103

Epoch: 5| Step: 3
Training loss: 1.1238139576262571
Validation loss: 2.3429885010015936

Epoch: 5| Step: 4
Training loss: 1.1585165439226233
Validation loss: 2.2957445680197535

Epoch: 5| Step: 5
Training loss: 1.189744284186247
Validation loss: 2.271784990454436

Epoch: 5| Step: 6
Training loss: 0.8797456251221542
Validation loss: 2.314023736171504

Epoch: 5| Step: 7
Training loss: 0.6055730668310505
Validation loss: 2.3379817628284547

Epoch: 5| Step: 8
Training loss: 1.5318502689825892
Validation loss: 2.3441395234221996

Epoch: 5| Step: 9
Training loss: 1.3491904992976642
Validation loss: 2.3617128360266055

Epoch: 5| Step: 10
Training loss: 1.0189096009846201
Validation loss: 2.382368540578923

Epoch: 231| Step: 0
Training loss: 1.1868704080517944
Validation loss: 2.404924109174451

Epoch: 5| Step: 1
Training loss: 0.7025177770788554
Validation loss: 2.4403128311101767

Epoch: 5| Step: 2
Training loss: 0.6875348082313758
Validation loss: 2.4096650180274324

Epoch: 5| Step: 3
Training loss: 1.1962042579953949
Validation loss: 2.3599190500665452

Epoch: 5| Step: 4
Training loss: 1.0268000335168777
Validation loss: 2.3722234135395226

Epoch: 5| Step: 5
Training loss: 0.6906282821853458
Validation loss: 2.373497253835359

Epoch: 5| Step: 6
Training loss: 1.0119853018383123
Validation loss: 2.416976724945788

Epoch: 5| Step: 7
Training loss: 1.4003323977826783
Validation loss: 2.4379192640645484

Epoch: 5| Step: 8
Training loss: 1.1785122404470323
Validation loss: 2.495596145816412

Epoch: 5| Step: 9
Training loss: 1.413474535021475
Validation loss: 2.5436014638023696

Epoch: 5| Step: 10
Training loss: 1.3164963054699315
Validation loss: 2.4808494889968675

Epoch: 232| Step: 0
Training loss: 1.0570208699124828
Validation loss: 2.477932108066361

Epoch: 5| Step: 1
Training loss: 1.0507321257612767
Validation loss: 2.345350243963185

Epoch: 5| Step: 2
Training loss: 0.8651141907725357
Validation loss: 2.247485286890749

Epoch: 5| Step: 3
Training loss: 0.9004784332289584
Validation loss: 2.2448253615263316

Epoch: 5| Step: 4
Training loss: 1.4477187462794205
Validation loss: 2.2319783888549902

Epoch: 5| Step: 5
Training loss: 0.9209013824577613
Validation loss: 2.2808361905888166

Epoch: 5| Step: 6
Training loss: 1.3873523393019882
Validation loss: 2.3438083053501093

Epoch: 5| Step: 7
Training loss: 0.8342565945395244
Validation loss: 2.4526076473114116

Epoch: 5| Step: 8
Training loss: 1.0505419604034087
Validation loss: 2.5097987223280245

Epoch: 5| Step: 9
Training loss: 1.0745626003301056
Validation loss: 2.5135190160182845

Epoch: 5| Step: 10
Training loss: 1.5088172687745751
Validation loss: 2.476394306523447

Epoch: 233| Step: 0
Training loss: 0.7515306747582158
Validation loss: 2.400443317887602

Epoch: 5| Step: 1
Training loss: 0.559808650363106
Validation loss: 2.3321860731584887

Epoch: 5| Step: 2
Training loss: 0.8964044206988584
Validation loss: 2.3688247332503725

Epoch: 5| Step: 3
Training loss: 1.2262727917683072
Validation loss: 2.28168755871008

Epoch: 5| Step: 4
Training loss: 1.574818234324485
Validation loss: 2.304948689416818

Epoch: 5| Step: 5
Training loss: 1.118311283464601
Validation loss: 2.2985628361305506

Epoch: 5| Step: 6
Training loss: 0.9809065369540549
Validation loss: 2.36159380354716

Epoch: 5| Step: 7
Training loss: 1.2912397089176046
Validation loss: 2.4358883081655147

Epoch: 5| Step: 8
Training loss: 0.8870253515996559
Validation loss: 2.4713910473740928

Epoch: 5| Step: 9
Training loss: 1.149497911478728
Validation loss: 2.512217486489217

Epoch: 5| Step: 10
Training loss: 1.2319124501969514
Validation loss: 2.456422635427184

Epoch: 234| Step: 0
Training loss: 0.7749728367259826
Validation loss: 2.4206726010975417

Epoch: 5| Step: 1
Training loss: 0.9505239547608565
Validation loss: 2.4140911579140147

Epoch: 5| Step: 2
Training loss: 0.8627018775197871
Validation loss: 2.400110854217314

Epoch: 5| Step: 3
Training loss: 1.0109235665305976
Validation loss: 2.338869317228235

Epoch: 5| Step: 4
Training loss: 1.0647387759998006
Validation loss: 2.3672062930526665

Epoch: 5| Step: 5
Training loss: 1.1702629700226987
Validation loss: 2.3754410747022043

Epoch: 5| Step: 6
Training loss: 1.3786262033311831
Validation loss: 2.3832888482960013

Epoch: 5| Step: 7
Training loss: 1.4246544134469616
Validation loss: 2.411338187797007

Epoch: 5| Step: 8
Training loss: 0.9817195983523623
Validation loss: 2.4154483969131335

Epoch: 5| Step: 9
Training loss: 0.9942838494454828
Validation loss: 2.4149010976472254

Epoch: 5| Step: 10
Training loss: 1.0313187778541442
Validation loss: 2.456026120495647

Epoch: 235| Step: 0
Training loss: 0.8975771889925331
Validation loss: 2.479136579425253

Epoch: 5| Step: 1
Training loss: 1.29384129520004
Validation loss: 2.377472497762383

Epoch: 5| Step: 2
Training loss: 0.6851768473157491
Validation loss: 2.392316671839679

Epoch: 5| Step: 3
Training loss: 1.3077314126092652
Validation loss: 2.3627310038818834

Epoch: 5| Step: 4
Training loss: 0.9634561483562448
Validation loss: 2.319880493690753

Epoch: 5| Step: 5
Training loss: 0.928311491703027
Validation loss: 2.339394444855304

Epoch: 5| Step: 6
Training loss: 1.3026832673486723
Validation loss: 2.3456571458573596

Epoch: 5| Step: 7
Training loss: 0.837156031559319
Validation loss: 2.320595673824586

Epoch: 5| Step: 8
Training loss: 0.8903834366715337
Validation loss: 2.293849679066848

Epoch: 5| Step: 9
Training loss: 1.2324145236755788
Validation loss: 2.3542889383506287

Epoch: 5| Step: 10
Training loss: 1.0096412449274035
Validation loss: 2.3494659923715924

Epoch: 236| Step: 0
Training loss: 1.4283536932409266
Validation loss: 2.3353258424740253

Epoch: 5| Step: 1
Training loss: 0.8061716041597757
Validation loss: 2.3714353021414607

Epoch: 5| Step: 2
Training loss: 0.5803639128573088
Validation loss: 2.371654641410037

Epoch: 5| Step: 3
Training loss: 1.3644941558041774
Validation loss: 2.370111372534801

Epoch: 5| Step: 4
Training loss: 1.303718115397492
Validation loss: 2.416975883825823

Epoch: 5| Step: 5
Training loss: 0.7618590396902349
Validation loss: 2.3765434340583362

Epoch: 5| Step: 6
Training loss: 1.3028058857428486
Validation loss: 2.4019156056384023

Epoch: 5| Step: 7
Training loss: 0.6599963519327895
Validation loss: 2.3078347540124646

Epoch: 5| Step: 8
Training loss: 1.1027807979291488
Validation loss: 2.3289600016541296

Epoch: 5| Step: 9
Training loss: 0.9290667793798962
Validation loss: 2.313855568482087

Epoch: 5| Step: 10
Training loss: 0.7681977001577849
Validation loss: 2.3233859504497865

Epoch: 237| Step: 0
Training loss: 1.1207551876937678
Validation loss: 2.31362684156186

Epoch: 5| Step: 1
Training loss: 0.7603551151673762
Validation loss: 2.3224185641509694

Epoch: 5| Step: 2
Training loss: 1.0245859821890873
Validation loss: 2.357379761013065

Epoch: 5| Step: 3
Training loss: 1.423034027904454
Validation loss: 2.3719356156172546

Epoch: 5| Step: 4
Training loss: 0.8395304960626951
Validation loss: 2.4144489634616724

Epoch: 5| Step: 5
Training loss: 0.9112552016833207
Validation loss: 2.3692757951135284

Epoch: 5| Step: 6
Training loss: 1.1054133748449915
Validation loss: 2.3633712535816076

Epoch: 5| Step: 7
Training loss: 1.139675633646152
Validation loss: 2.372141684870232

Epoch: 5| Step: 8
Training loss: 1.0481683513522477
Validation loss: 2.40168793833641

Epoch: 5| Step: 9
Training loss: 0.8179915154467092
Validation loss: 2.455773072765916

Epoch: 5| Step: 10
Training loss: 1.026789758804601
Validation loss: 2.4469253938222035

Epoch: 238| Step: 0
Training loss: 0.9045120872988894
Validation loss: 2.470819143288331

Epoch: 5| Step: 1
Training loss: 0.7470089157905268
Validation loss: 2.425947933987313

Epoch: 5| Step: 2
Training loss: 1.106613159916085
Validation loss: 2.390407385329281

Epoch: 5| Step: 3
Training loss: 1.0580062080302122
Validation loss: 2.348334234964371

Epoch: 5| Step: 4
Training loss: 1.0994157908702715
Validation loss: 2.295238361305987

Epoch: 5| Step: 5
Training loss: 1.0714800515749963
Validation loss: 2.3378979258944548

Epoch: 5| Step: 6
Training loss: 1.1328046074954046
Validation loss: 2.334132056348722

Epoch: 5| Step: 7
Training loss: 0.828874428845679
Validation loss: 2.380548850566692

Epoch: 5| Step: 8
Training loss: 1.455637165180899
Validation loss: 2.4649086908503004

Epoch: 5| Step: 9
Training loss: 0.9088318320137839
Validation loss: 2.3706445582878657

Epoch: 5| Step: 10
Training loss: 0.8652884851762346
Validation loss: 2.353129524793454

Epoch: 239| Step: 0
Training loss: 0.5302955524476757
Validation loss: 2.368813735485849

Epoch: 5| Step: 1
Training loss: 1.2432552522954525
Validation loss: 2.312645834127172

Epoch: 5| Step: 2
Training loss: 1.0867794806968414
Validation loss: 2.337404021290435

Epoch: 5| Step: 3
Training loss: 1.0717378578646108
Validation loss: 2.338203254589215

Epoch: 5| Step: 4
Training loss: 0.8313677654166665
Validation loss: 2.3500725776620097

Epoch: 5| Step: 5
Training loss: 1.35245268508028
Validation loss: 2.3321584759347855

Epoch: 5| Step: 6
Training loss: 0.9457046704159525
Validation loss: 2.322351148926137

Epoch: 5| Step: 7
Training loss: 1.0941097757715648
Validation loss: 2.34610411410195

Epoch: 5| Step: 8
Training loss: 1.0004874471918803
Validation loss: 2.3422346941435497

Epoch: 5| Step: 9
Training loss: 0.9307052427069405
Validation loss: 2.346632320928737

Epoch: 5| Step: 10
Training loss: 0.875424622637694
Validation loss: 2.33396980362446

Epoch: 240| Step: 0
Training loss: 0.6847180738983292
Validation loss: 2.359313903204424

Epoch: 5| Step: 1
Training loss: 1.1580580416250827
Validation loss: 2.3919176915869875

Epoch: 5| Step: 2
Training loss: 0.969920958120256
Validation loss: 2.3635589309012905

Epoch: 5| Step: 3
Training loss: 0.9955522748460481
Validation loss: 2.4214766255119593

Epoch: 5| Step: 4
Training loss: 0.8214244027950114
Validation loss: 2.396322352582975

Epoch: 5| Step: 5
Training loss: 0.7641748201468431
Validation loss: 2.3727674304780475

Epoch: 5| Step: 6
Training loss: 1.2033404863273511
Validation loss: 2.356580271427497

Epoch: 5| Step: 7
Training loss: 0.957970792500352
Validation loss: 2.3380580507732476

Epoch: 5| Step: 8
Training loss: 0.9447452009411773
Validation loss: 2.363754373987797

Epoch: 5| Step: 9
Training loss: 1.3683320404554633
Validation loss: 2.2676816528414268

Epoch: 5| Step: 10
Training loss: 0.9650590169974824
Validation loss: 2.242273918499664

Epoch: 241| Step: 0
Training loss: 0.9296982708475339
Validation loss: 2.277566210866285

Epoch: 5| Step: 1
Training loss: 1.1747661276662322
Validation loss: 2.2239297208544615

Epoch: 5| Step: 2
Training loss: 0.8238449333722725
Validation loss: 2.237785839600293

Epoch: 5| Step: 3
Training loss: 0.47823482760457414
Validation loss: 2.2698850327199978

Epoch: 5| Step: 4
Training loss: 1.5012219538042135
Validation loss: 2.376609938780596

Epoch: 5| Step: 5
Training loss: 0.9000502996164157
Validation loss: 2.384414514644194

Epoch: 5| Step: 6
Training loss: 1.0083151458382054
Validation loss: 2.422276708424671

Epoch: 5| Step: 7
Training loss: 1.0349864316594577
Validation loss: 2.42579090201761

Epoch: 5| Step: 8
Training loss: 0.9197973665181064
Validation loss: 2.4804651068015615

Epoch: 5| Step: 9
Training loss: 0.6684080542043742
Validation loss: 2.4263046508728

Epoch: 5| Step: 10
Training loss: 1.0679151319258833
Validation loss: 2.3470555949978342

Epoch: 242| Step: 0
Training loss: 1.2910189491494648
Validation loss: 2.3557536810405546

Epoch: 5| Step: 1
Training loss: 0.8281544734100462
Validation loss: 2.3318422731196726

Epoch: 5| Step: 2
Training loss: 0.8600730141983279
Validation loss: 2.335985077393242

Epoch: 5| Step: 3
Training loss: 0.8561068380364579
Validation loss: 2.360503635962562

Epoch: 5| Step: 4
Training loss: 1.2049367565162827
Validation loss: 2.3734154048482785

Epoch: 5| Step: 5
Training loss: 0.9877802366679763
Validation loss: 2.425106426661151

Epoch: 5| Step: 6
Training loss: 0.8384913000930457
Validation loss: 2.480826884912669

Epoch: 5| Step: 7
Training loss: 1.1169239080017355
Validation loss: 2.4784612757721347

Epoch: 5| Step: 8
Training loss: 0.6745096491893335
Validation loss: 2.4697532001821645

Epoch: 5| Step: 9
Training loss: 0.8186655860074684
Validation loss: 2.365433188978625

Epoch: 5| Step: 10
Training loss: 1.1805287071366448
Validation loss: 2.3761796477373323

Epoch: 243| Step: 0
Training loss: 0.8534465561075133
Validation loss: 2.30200140673696

Epoch: 5| Step: 1
Training loss: 0.9780603137579643
Validation loss: 2.271757576937686

Epoch: 5| Step: 2
Training loss: 1.2078687114391993
Validation loss: 2.3106660563291777

Epoch: 5| Step: 3
Training loss: 1.1881681369614188
Validation loss: 2.479298705378797

Epoch: 5| Step: 4
Training loss: 0.607890938451255
Validation loss: 2.4933857204761196

Epoch: 5| Step: 5
Training loss: 1.3127340834638348
Validation loss: 2.557536151820407

Epoch: 5| Step: 6
Training loss: 1.34313396260931
Validation loss: 2.493427020956417

Epoch: 5| Step: 7
Training loss: 1.266185118508939
Validation loss: 2.439904318968792

Epoch: 5| Step: 8
Training loss: 0.680213395918213
Validation loss: 2.3327851383973472

Epoch: 5| Step: 9
Training loss: 1.0096852253941684
Validation loss: 2.2578622981613012

Epoch: 5| Step: 10
Training loss: 0.9386137704252431
Validation loss: 2.2496574384911985

Epoch: 244| Step: 0
Training loss: 0.9598693803994564
Validation loss: 2.212410815998581

Epoch: 5| Step: 1
Training loss: 1.172933583563889
Validation loss: 2.2452357154457

Epoch: 5| Step: 2
Training loss: 1.107125755696568
Validation loss: 2.3741301652965485

Epoch: 5| Step: 3
Training loss: 0.9558630528162956
Validation loss: 2.570241190590693

Epoch: 5| Step: 4
Training loss: 0.8062619851574437
Validation loss: 2.7110182132581278

Epoch: 5| Step: 5
Training loss: 1.251365440371005
Validation loss: 2.6752569123346723

Epoch: 5| Step: 6
Training loss: 1.3063010557135228
Validation loss: 2.598896690145779

Epoch: 5| Step: 7
Training loss: 0.7128795048094596
Validation loss: 2.534207440280291

Epoch: 5| Step: 8
Training loss: 0.9296857048466124
Validation loss: 2.391371410267632

Epoch: 5| Step: 9
Training loss: 1.0165681421244703
Validation loss: 2.3062460447256865

Epoch: 5| Step: 10
Training loss: 1.1832226967916657
Validation loss: 2.265514749313322

Epoch: 245| Step: 0
Training loss: 0.7995037775051824
Validation loss: 2.2812870386173265

Epoch: 5| Step: 1
Training loss: 0.8998965482064633
Validation loss: 2.3320578357208084

Epoch: 5| Step: 2
Training loss: 1.052709802117837
Validation loss: 2.410928363955664

Epoch: 5| Step: 3
Training loss: 1.1173814191777878
Validation loss: 2.4488729774628184

Epoch: 5| Step: 4
Training loss: 1.2535205854042553
Validation loss: 2.5202900158564976

Epoch: 5| Step: 5
Training loss: 0.9833017583939367
Validation loss: 2.498399525728543

Epoch: 5| Step: 6
Training loss: 1.0798555941643526
Validation loss: 2.476433547686189

Epoch: 5| Step: 7
Training loss: 0.9783111175817837
Validation loss: 2.4302039353149456

Epoch: 5| Step: 8
Training loss: 1.1113030241426078
Validation loss: 2.4033124145821256

Epoch: 5| Step: 9
Training loss: 0.9138337851752886
Validation loss: 2.3401255474464655

Epoch: 5| Step: 10
Training loss: 1.3161345521267032
Validation loss: 2.314264796424492

Epoch: 246| Step: 0
Training loss: 0.8589936190424784
Validation loss: 2.263749154187669

Epoch: 5| Step: 1
Training loss: 0.8606701887646191
Validation loss: 2.29137152918249

Epoch: 5| Step: 2
Training loss: 0.9811364442272323
Validation loss: 2.3131735607033863

Epoch: 5| Step: 3
Training loss: 0.8950556921014445
Validation loss: 2.388318558781845

Epoch: 5| Step: 4
Training loss: 0.9851114454979012
Validation loss: 2.3744364319701488

Epoch: 5| Step: 5
Training loss: 1.1077218431576006
Validation loss: 2.3479597539668133

Epoch: 5| Step: 6
Training loss: 1.1979163238967183
Validation loss: 2.3476037924637128

Epoch: 5| Step: 7
Training loss: 0.7964966193544684
Validation loss: 2.296192553606562

Epoch: 5| Step: 8
Training loss: 0.9669500672704353
Validation loss: 2.2658714038801824

Epoch: 5| Step: 9
Training loss: 0.6784805016439253
Validation loss: 2.2412812234126016

Epoch: 5| Step: 10
Training loss: 1.3425398855837543
Validation loss: 2.2657095706984327

Epoch: 247| Step: 0
Training loss: 0.7498512915366956
Validation loss: 2.249795872533645

Epoch: 5| Step: 1
Training loss: 1.3548695231887544
Validation loss: 2.271110879721076

Epoch: 5| Step: 2
Training loss: 0.9478658760353065
Validation loss: 2.2453571366151994

Epoch: 5| Step: 3
Training loss: 0.869340954956577
Validation loss: 2.3004494777144973

Epoch: 5| Step: 4
Training loss: 0.9316054683425717
Validation loss: 2.2892633725368308

Epoch: 5| Step: 5
Training loss: 0.9303512127464756
Validation loss: 2.3453041704547837

Epoch: 5| Step: 6
Training loss: 0.7974517081775581
Validation loss: 2.3488387214342477

Epoch: 5| Step: 7
Training loss: 1.152145937735676
Validation loss: 2.374449547933165

Epoch: 5| Step: 8
Training loss: 0.9671299832548353
Validation loss: 2.396126876725049

Epoch: 5| Step: 9
Training loss: 1.0332277002999457
Validation loss: 2.378137327606968

Epoch: 5| Step: 10
Training loss: 0.7119272489857079
Validation loss: 2.3769303908715953

Epoch: 248| Step: 0
Training loss: 0.9009673284540793
Validation loss: 2.3061667546156275

Epoch: 5| Step: 1
Training loss: 0.8464950835462044
Validation loss: 2.286666843417648

Epoch: 5| Step: 2
Training loss: 0.8539594809927809
Validation loss: 2.329651167109706

Epoch: 5| Step: 3
Training loss: 1.1706415424308452
Validation loss: 2.348908229415661

Epoch: 5| Step: 4
Training loss: 0.9214083250066724
Validation loss: 2.407354205114849

Epoch: 5| Step: 5
Training loss: 1.0929960649634163
Validation loss: 2.4579897001298607

Epoch: 5| Step: 6
Training loss: 0.7283519325747645
Validation loss: 2.439210841908599

Epoch: 5| Step: 7
Training loss: 0.6064795885212902
Validation loss: 2.4832031371409373

Epoch: 5| Step: 8
Training loss: 1.414641878080454
Validation loss: 2.4630017913823434

Epoch: 5| Step: 9
Training loss: 0.7608846156485808
Validation loss: 2.4345696891146567

Epoch: 5| Step: 10
Training loss: 0.5997424148932226
Validation loss: 2.3651366261174127

Epoch: 249| Step: 0
Training loss: 0.9116577729506748
Validation loss: 2.3504355248479447

Epoch: 5| Step: 1
Training loss: 1.2627006465743145
Validation loss: 2.2995188664157338

Epoch: 5| Step: 2
Training loss: 0.9831025209664043
Validation loss: 2.283474507229231

Epoch: 5| Step: 3
Training loss: 1.0532025656731545
Validation loss: 2.3075872561689637

Epoch: 5| Step: 4
Training loss: 0.7652462392201774
Validation loss: 2.3493739753252587

Epoch: 5| Step: 5
Training loss: 0.619892422049133
Validation loss: 2.4525324869648326

Epoch: 5| Step: 6
Training loss: 0.8568544008880018
Validation loss: 2.5131973877025957

Epoch: 5| Step: 7
Training loss: 0.9074021940359084
Validation loss: 2.525059819982548

Epoch: 5| Step: 8
Training loss: 1.0583900171153675
Validation loss: 2.494664063933514

Epoch: 5| Step: 9
Training loss: 0.7050211030087777
Validation loss: 2.3952995483227233

Epoch: 5| Step: 10
Training loss: 1.0001476894036734
Validation loss: 2.3414251006801146

Epoch: 250| Step: 0
Training loss: 0.6577123062775848
Validation loss: 2.3203586421723625

Epoch: 5| Step: 1
Training loss: 1.0400565419049062
Validation loss: 2.313179940500051

Epoch: 5| Step: 2
Training loss: 1.0136778726565703
Validation loss: 2.3248949632968103

Epoch: 5| Step: 3
Training loss: 0.7120032653599773
Validation loss: 2.343993824954062

Epoch: 5| Step: 4
Training loss: 0.853496525112111
Validation loss: 2.3531650746961676

Epoch: 5| Step: 5
Training loss: 0.8580772311035115
Validation loss: 2.41054946022119

Epoch: 5| Step: 6
Training loss: 0.8338646545957822
Validation loss: 2.3824353604658306

Epoch: 5| Step: 7
Training loss: 1.2379283703062771
Validation loss: 2.3492002212344425

Epoch: 5| Step: 8
Training loss: 0.9926267237439937
Validation loss: 2.335213184843821

Epoch: 5| Step: 9
Training loss: 0.9647718395045667
Validation loss: 2.320552241910855

Epoch: 5| Step: 10
Training loss: 0.7657262384860929
Validation loss: 2.3053390913876064

Testing loss: 2.660480048236906
