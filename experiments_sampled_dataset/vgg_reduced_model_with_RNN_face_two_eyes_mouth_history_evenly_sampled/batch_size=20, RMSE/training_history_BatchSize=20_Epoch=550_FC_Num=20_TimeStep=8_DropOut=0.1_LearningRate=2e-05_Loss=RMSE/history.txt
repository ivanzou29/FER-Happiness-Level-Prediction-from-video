Epoch: 1| Step: 0
Training loss: 4.920996015262212
Validation loss: 5.812771589162108

Epoch: 5| Step: 1
Training loss: 5.609843880016118
Validation loss: 5.788860528591306

Epoch: 5| Step: 2
Training loss: 4.535827008832318
Validation loss: 5.7683117456834525

Epoch: 5| Step: 3
Training loss: 5.457743702653372
Validation loss: 5.748532222474044

Epoch: 5| Step: 4
Training loss: 5.697415940659319
Validation loss: 5.727140811786062

Epoch: 5| Step: 5
Training loss: 5.499437129955927
Validation loss: 5.702946029059795

Epoch: 5| Step: 6
Training loss: 5.714431883441107
Validation loss: 5.676249786113262

Epoch: 5| Step: 7
Training loss: 6.244935081517124
Validation loss: 5.645686779731807

Epoch: 5| Step: 8
Training loss: 6.258415659817181
Validation loss: 5.613085661528053

Epoch: 5| Step: 9
Training loss: 6.51110038727509
Validation loss: 5.575954225474535

Epoch: 5| Step: 10
Training loss: 6.187222561251611
Validation loss: 5.535534094561061

Epoch: 2| Step: 0
Training loss: 5.45083053979927
Validation loss: 5.4911151168644246

Epoch: 5| Step: 1
Training loss: 6.441005307981154
Validation loss: 5.4414396779161125

Epoch: 5| Step: 2
Training loss: 4.8030709377167495
Validation loss: 5.387613781787531

Epoch: 5| Step: 3
Training loss: 4.641222571742193
Validation loss: 5.328939344179177

Epoch: 5| Step: 4
Training loss: 5.987588761533819
Validation loss: 5.267401095957

Epoch: 5| Step: 5
Training loss: 5.016678078639504
Validation loss: 5.204543300069154

Epoch: 5| Step: 6
Training loss: 5.213856121365152
Validation loss: 5.136416455503994

Epoch: 5| Step: 7
Training loss: 5.278141709657534
Validation loss: 5.070097907187453

Epoch: 5| Step: 8
Training loss: 5.2781870610782065
Validation loss: 5.001718283293966

Epoch: 5| Step: 9
Training loss: 4.907759318872761
Validation loss: 4.932917457873483

Epoch: 5| Step: 10
Training loss: 4.421863569372925
Validation loss: 4.8547571949644155

Epoch: 3| Step: 0
Training loss: 5.008361310240708
Validation loss: 4.775382209423313

Epoch: 5| Step: 1
Training loss: 4.127257220812394
Validation loss: 4.7045789373699165

Epoch: 5| Step: 2
Training loss: 4.442293828281411
Validation loss: 4.6426393218241815

Epoch: 5| Step: 3
Training loss: 4.2834213208217005
Validation loss: 4.582956659196433

Epoch: 5| Step: 4
Training loss: 4.567197915429772
Validation loss: 4.521413486970144

Epoch: 5| Step: 5
Training loss: 3.9562827303287316
Validation loss: 4.465146674465957

Epoch: 5| Step: 6
Training loss: 5.017176688155004
Validation loss: 4.4153992213255435

Epoch: 5| Step: 7
Training loss: 4.531300932499312
Validation loss: 4.368587330820553

Epoch: 5| Step: 8
Training loss: 5.270495779614993
Validation loss: 4.322578060895967

Epoch: 5| Step: 9
Training loss: 4.427671481688299
Validation loss: 4.269222242372287

Epoch: 5| Step: 10
Training loss: 4.564186725016345
Validation loss: 4.228213400978042

Epoch: 4| Step: 0
Training loss: 4.544533247780849
Validation loss: 4.198509289084985

Epoch: 5| Step: 1
Training loss: 4.758554284911153
Validation loss: 4.169642958477634

Epoch: 5| Step: 2
Training loss: 3.012819240005815
Validation loss: 4.137361776944545

Epoch: 5| Step: 3
Training loss: 3.6895618170281907
Validation loss: 4.108104661523394

Epoch: 5| Step: 4
Training loss: 5.022919766100646
Validation loss: 4.083640390687388

Epoch: 5| Step: 5
Training loss: 4.422731997203968
Validation loss: 4.056725410594712

Epoch: 5| Step: 6
Training loss: 4.224337120648246
Validation loss: 4.031255881186059

Epoch: 5| Step: 7
Training loss: 4.166200128503453
Validation loss: 4.008690777051237

Epoch: 5| Step: 8
Training loss: 4.694693170663531
Validation loss: 3.985412827956974

Epoch: 5| Step: 9
Training loss: 3.9390461625906985
Validation loss: 3.96489986871171

Epoch: 5| Step: 10
Training loss: 3.2616380510226617
Validation loss: 3.951526559117011

Epoch: 5| Step: 0
Training loss: 3.6698291029885306
Validation loss: 3.941210923814105

Epoch: 5| Step: 1
Training loss: 3.781911366530098
Validation loss: 3.9241546449431883

Epoch: 5| Step: 2
Training loss: 4.160375168462383
Validation loss: 3.9147428938426234

Epoch: 5| Step: 3
Training loss: 3.8435078366297595
Validation loss: 3.895929956655488

Epoch: 5| Step: 4
Training loss: 4.607085302591169
Validation loss: 3.8821781531861337

Epoch: 5| Step: 5
Training loss: 4.136653737538
Validation loss: 3.8597265598793222

Epoch: 5| Step: 6
Training loss: 3.917927126601559
Validation loss: 3.8364900380221307

Epoch: 5| Step: 7
Training loss: 3.7720115605295477
Validation loss: 3.8302281274559347

Epoch: 5| Step: 8
Training loss: 3.9565817454308165
Validation loss: 3.8022819657077296

Epoch: 5| Step: 9
Training loss: 4.144800693335638
Validation loss: 3.7968348133805234

Epoch: 5| Step: 10
Training loss: 4.263254254412766
Validation loss: 3.780977299483444

Epoch: 6| Step: 0
Training loss: 3.428912168555498
Validation loss: 3.7571250688068782

Epoch: 5| Step: 1
Training loss: 3.5124877495059947
Validation loss: 3.741221661546068

Epoch: 5| Step: 2
Training loss: 5.0379054434073955
Validation loss: 3.721951763716705

Epoch: 5| Step: 3
Training loss: 4.470605425019182
Validation loss: 3.703778221538355

Epoch: 5| Step: 4
Training loss: 3.812845808511651
Validation loss: 3.686616704541019

Epoch: 5| Step: 5
Training loss: 4.061181191812241
Validation loss: 3.6828219184603825

Epoch: 5| Step: 6
Training loss: 4.063357453455906
Validation loss: 3.6596669106267568

Epoch: 5| Step: 7
Training loss: 3.77821379526451
Validation loss: 3.6496059511251935

Epoch: 5| Step: 8
Training loss: 3.806113725800319
Validation loss: 3.6332303448505194

Epoch: 5| Step: 9
Training loss: 3.381277815445245
Validation loss: 3.6262256698730195

Epoch: 5| Step: 10
Training loss: 2.490795643703069
Validation loss: 3.61656275244983

Epoch: 7| Step: 0
Training loss: 3.519037650294736
Validation loss: 3.6109450076205634

Epoch: 5| Step: 1
Training loss: 3.703642346262436
Validation loss: 3.6008622452334285

Epoch: 5| Step: 2
Training loss: 3.538925336659725
Validation loss: 3.5897975578863623

Epoch: 5| Step: 3
Training loss: 4.334306289799319
Validation loss: 3.577914146368446

Epoch: 5| Step: 4
Training loss: 3.791029838209124
Validation loss: 3.567197860199586

Epoch: 5| Step: 5
Training loss: 3.92886847574398
Validation loss: 3.55218399237704

Epoch: 5| Step: 6
Training loss: 3.6843561251272514
Validation loss: 3.5418018949824397

Epoch: 5| Step: 7
Training loss: 3.362942952189736
Validation loss: 3.5287362328872156

Epoch: 5| Step: 8
Training loss: 4.081870043916137
Validation loss: 3.515459350912851

Epoch: 5| Step: 9
Training loss: 3.460871642026472
Validation loss: 3.506088122776636

Epoch: 5| Step: 10
Training loss: 3.837859936462864
Validation loss: 3.4989236621088766

Epoch: 8| Step: 0
Training loss: 3.670567835812967
Validation loss: 3.4885979402439364

Epoch: 5| Step: 1
Training loss: 4.740620839790425
Validation loss: 3.482735379271042

Epoch: 5| Step: 2
Training loss: 3.297017315870868
Validation loss: 3.467586596797477

Epoch: 5| Step: 3
Training loss: 3.8648365002948353
Validation loss: 3.4615071827201267

Epoch: 5| Step: 4
Training loss: 2.5855342861802137
Validation loss: 3.457645542579249

Epoch: 5| Step: 5
Training loss: 3.6026621565104655
Validation loss: 3.4477129632753867

Epoch: 5| Step: 6
Training loss: 4.232789816220018
Validation loss: 3.4371818253529995

Epoch: 5| Step: 7
Training loss: 3.3991511856129333
Validation loss: 3.424807621069726

Epoch: 5| Step: 8
Training loss: 3.3059339404697727
Validation loss: 3.4170242550634784

Epoch: 5| Step: 9
Training loss: 3.6229523762103315
Validation loss: 3.414231233460209

Epoch: 5| Step: 10
Training loss: 3.642142442107875
Validation loss: 3.4026720399035244

Epoch: 9| Step: 0
Training loss: 3.2807561593591275
Validation loss: 3.39516792796533

Epoch: 5| Step: 1
Training loss: 3.218967023032938
Validation loss: 3.3911046701588003

Epoch: 5| Step: 2
Training loss: 3.3898123193511474
Validation loss: 3.3839968542675263

Epoch: 5| Step: 3
Training loss: 3.7177684354034515
Validation loss: 3.3708098503083845

Epoch: 5| Step: 4
Training loss: 4.425408020173906
Validation loss: 3.3636578978338267

Epoch: 5| Step: 5
Training loss: 3.7217260681641573
Validation loss: 3.3628905635864976

Epoch: 5| Step: 6
Training loss: 3.377349883159334
Validation loss: 3.366441440988292

Epoch: 5| Step: 7
Training loss: 3.9808708788915443
Validation loss: 3.368323336179268

Epoch: 5| Step: 8
Training loss: 3.363046458485757
Validation loss: 3.344789601195938

Epoch: 5| Step: 9
Training loss: 3.066874901985523
Validation loss: 3.3756991474644025

Epoch: 5| Step: 10
Training loss: 3.933121441667209
Validation loss: 3.398080290909835

Epoch: 10| Step: 0
Training loss: 3.740684382605482
Validation loss: 3.3598464058905706

Epoch: 5| Step: 1
Training loss: 3.2747829103226387
Validation loss: 3.3732183935231146

Epoch: 5| Step: 2
Training loss: 2.4909004547308626
Validation loss: 3.374230864226013

Epoch: 5| Step: 3
Training loss: 3.6475950653049485
Validation loss: 3.3800137968194983

Epoch: 5| Step: 4
Training loss: 3.6914769080125827
Validation loss: 3.367383794109574

Epoch: 5| Step: 5
Training loss: 3.0872131029031373
Validation loss: 3.3593676235750434

Epoch: 5| Step: 6
Training loss: 3.6945415442636507
Validation loss: 3.356456971067042

Epoch: 5| Step: 7
Training loss: 3.4384590891703146
Validation loss: 3.343598003611037

Epoch: 5| Step: 8
Training loss: 3.5987687601526015
Validation loss: 3.3319763872299957

Epoch: 5| Step: 9
Training loss: 4.70953277343855
Validation loss: 3.323928063942977

Epoch: 5| Step: 10
Training loss: 3.6660922351894674
Validation loss: 3.3140052475740145

Epoch: 11| Step: 0
Training loss: 4.022268062374832
Validation loss: 3.310896033359491

Epoch: 5| Step: 1
Training loss: 2.8585097040715963
Validation loss: 3.305832388485302

Epoch: 5| Step: 2
Training loss: 3.1127642844879357
Validation loss: 3.3005690938794765

Epoch: 5| Step: 3
Training loss: 3.6632170199903356
Validation loss: 3.2924428818758673

Epoch: 5| Step: 4
Training loss: 3.4154904519652547
Validation loss: 3.2872810374758066

Epoch: 5| Step: 5
Training loss: 3.552770210743881
Validation loss: 3.276857097206521

Epoch: 5| Step: 6
Training loss: 4.287971510692867
Validation loss: 3.269937554186821

Epoch: 5| Step: 7
Training loss: 3.015273948357359
Validation loss: 3.2664006057897184

Epoch: 5| Step: 8
Training loss: 3.7169767367312603
Validation loss: 3.263412354020048

Epoch: 5| Step: 9
Training loss: 3.18229339815999
Validation loss: 3.261389122278823

Epoch: 5| Step: 10
Training loss: 3.722059812529465
Validation loss: 3.253327511286792

Epoch: 12| Step: 0
Training loss: 3.1724332872475243
Validation loss: 3.251609156192252

Epoch: 5| Step: 1
Training loss: 2.89193563905172
Validation loss: 3.249514266601771

Epoch: 5| Step: 2
Training loss: 2.9038499335615655
Validation loss: 3.247954666046012

Epoch: 5| Step: 3
Training loss: 4.117745464815995
Validation loss: 3.2476432938827586

Epoch: 5| Step: 4
Training loss: 3.714818463003775
Validation loss: 3.2400820246428617

Epoch: 5| Step: 5
Training loss: 3.758244670039183
Validation loss: 3.2330656607068295

Epoch: 5| Step: 6
Training loss: 4.131462583396216
Validation loss: 3.2271287508565227

Epoch: 5| Step: 7
Training loss: 2.899160454343094
Validation loss: 3.2271693048728736

Epoch: 5| Step: 8
Training loss: 3.1214417608505585
Validation loss: 3.2250946018327835

Epoch: 5| Step: 9
Training loss: 3.8616232559031736
Validation loss: 3.220641758526157

Epoch: 5| Step: 10
Training loss: 3.4472534525280842
Validation loss: 3.2153882316791607

Epoch: 13| Step: 0
Training loss: 3.123754482014201
Validation loss: 3.2103415986327613

Epoch: 5| Step: 1
Training loss: 3.3454525614909745
Validation loss: 3.206818511606905

Epoch: 5| Step: 2
Training loss: 3.5875285822032135
Validation loss: 3.202734424820239

Epoch: 5| Step: 3
Training loss: 3.540913011733702
Validation loss: 3.201658378245673

Epoch: 5| Step: 4
Training loss: 3.7883415873468795
Validation loss: 3.196482050235314

Epoch: 5| Step: 5
Training loss: 3.2376472763674293
Validation loss: 3.192671808814998

Epoch: 5| Step: 6
Training loss: 4.047361366767628
Validation loss: 3.1886408471512127

Epoch: 5| Step: 7
Training loss: 3.153274644489684
Validation loss: 3.184107664879847

Epoch: 5| Step: 8
Training loss: 2.832114424963947
Validation loss: 3.1795635067692403

Epoch: 5| Step: 9
Training loss: 3.4346797124139066
Validation loss: 3.1765041480352654

Epoch: 5| Step: 10
Training loss: 3.7861966650938217
Validation loss: 3.1728305109905346

Epoch: 14| Step: 0
Training loss: 3.442748623072129
Validation loss: 3.168505156537373

Epoch: 5| Step: 1
Training loss: 3.528634512157039
Validation loss: 3.1668998406274107

Epoch: 5| Step: 2
Training loss: 2.8723713011168126
Validation loss: 3.1620090705876547

Epoch: 5| Step: 3
Training loss: 3.073934112904985
Validation loss: 3.1606913430874846

Epoch: 5| Step: 4
Training loss: 3.6692639746329987
Validation loss: 3.1591211055414834

Epoch: 5| Step: 5
Training loss: 3.0568022371413215
Validation loss: 3.1551110970289336

Epoch: 5| Step: 6
Training loss: 3.415271675842496
Validation loss: 3.154525956884994

Epoch: 5| Step: 7
Training loss: 3.1617501557272374
Validation loss: 3.1514291691653584

Epoch: 5| Step: 8
Training loss: 4.260756848222829
Validation loss: 3.151835029788498

Epoch: 5| Step: 9
Training loss: 3.6099059139682073
Validation loss: 3.1480037042574347

Epoch: 5| Step: 10
Training loss: 3.38671213257175
Validation loss: 3.1459853139596765

Epoch: 15| Step: 0
Training loss: 4.202219585478617
Validation loss: 3.145593066956241

Epoch: 5| Step: 1
Training loss: 2.021279498789156
Validation loss: 3.1421059590174427

Epoch: 5| Step: 2
Training loss: 2.906219482261646
Validation loss: 3.143195755408157

Epoch: 5| Step: 3
Training loss: 3.2489543112856003
Validation loss: 3.140742294495764

Epoch: 5| Step: 4
Training loss: 3.6015294005223875
Validation loss: 3.140931452190568

Epoch: 5| Step: 5
Training loss: 3.670845309413696
Validation loss: 3.13797503035296

Epoch: 5| Step: 6
Training loss: 3.4073469163144625
Validation loss: 3.1360216708213033

Epoch: 5| Step: 7
Training loss: 3.8687272522585725
Validation loss: 3.135558395826422

Epoch: 5| Step: 8
Training loss: 3.7394733182544586
Validation loss: 3.13411097549753

Epoch: 5| Step: 9
Training loss: 2.8017102433930154
Validation loss: 3.132808171906733

Epoch: 5| Step: 10
Training loss: 3.5533145474861163
Validation loss: 3.1315400039714247

Epoch: 16| Step: 0
Training loss: 3.2027816960653697
Validation loss: 3.1313343584542874

Epoch: 5| Step: 1
Training loss: 3.4364673797466763
Validation loss: 3.1296048091952096

Epoch: 5| Step: 2
Training loss: 3.314497723164153
Validation loss: 3.129134844295132

Epoch: 5| Step: 3
Training loss: 3.3783875877667247
Validation loss: 3.1255605773194075

Epoch: 5| Step: 4
Training loss: 3.009143564548795
Validation loss: 3.1263719824336733

Epoch: 5| Step: 5
Training loss: 3.102788188131003
Validation loss: 3.127182791711589

Epoch: 5| Step: 6
Training loss: 3.3404303498471832
Validation loss: 3.127476584123226

Epoch: 5| Step: 7
Training loss: 3.4011039007703734
Validation loss: 3.1256031430560833

Epoch: 5| Step: 8
Training loss: 3.949941204937225
Validation loss: 3.124911847255584

Epoch: 5| Step: 9
Training loss: 3.434560455230026
Validation loss: 3.1205953504792374

Epoch: 5| Step: 10
Training loss: 3.7747332952402495
Validation loss: 3.121527118231013

Epoch: 17| Step: 0
Training loss: 2.8078749032534476
Validation loss: 3.1190902959972227

Epoch: 5| Step: 1
Training loss: 3.462365400541964
Validation loss: 3.119867386396279

Epoch: 5| Step: 2
Training loss: 3.510485609756661
Validation loss: 3.1172335832008145

Epoch: 5| Step: 3
Training loss: 2.7769628335995273
Validation loss: 3.113279591565313

Epoch: 5| Step: 4
Training loss: 3.01366776115646
Validation loss: 3.117296335657727

Epoch: 5| Step: 5
Training loss: 3.104869088870092
Validation loss: 3.1141194534409733

Epoch: 5| Step: 6
Training loss: 3.652686705781549
Validation loss: 3.114518935386663

Epoch: 5| Step: 7
Training loss: 4.0027813778103
Validation loss: 3.1151617006140464

Epoch: 5| Step: 8
Training loss: 3.2638615131357382
Validation loss: 3.1119206380503974

Epoch: 5| Step: 9
Training loss: 3.601846348630189
Validation loss: 3.1066950804692484

Epoch: 5| Step: 10
Training loss: 3.9249015164016727
Validation loss: 3.1080202723640804

Epoch: 18| Step: 0
Training loss: 2.988597499094965
Validation loss: 3.104051709377855

Epoch: 5| Step: 1
Training loss: 3.8508500684121225
Validation loss: 3.1037658401789514

Epoch: 5| Step: 2
Training loss: 4.054955857644605
Validation loss: 3.1002321290016766

Epoch: 5| Step: 3
Training loss: 2.980430192810479
Validation loss: 3.103980458046786

Epoch: 5| Step: 4
Training loss: 3.2414610267142683
Validation loss: 3.104850408539761

Epoch: 5| Step: 5
Training loss: 2.6169561938656085
Validation loss: 3.1003896348646576

Epoch: 5| Step: 6
Training loss: 3.57059789806559
Validation loss: 3.0996423043900427

Epoch: 5| Step: 7
Training loss: 2.7392673866254253
Validation loss: 3.0963234637504766

Epoch: 5| Step: 8
Training loss: 3.463565698220005
Validation loss: 3.0978940188604693

Epoch: 5| Step: 9
Training loss: 3.4681391822578584
Validation loss: 3.1033921661299564

Epoch: 5| Step: 10
Training loss: 3.9250417136144273
Validation loss: 3.1058296252425643

Epoch: 19| Step: 0
Training loss: 2.8970297301942542
Validation loss: 3.095256216270431

Epoch: 5| Step: 1
Training loss: 3.178319838411367
Validation loss: 3.095726993233667

Epoch: 5| Step: 2
Training loss: 4.029416399175486
Validation loss: 3.095313396346989

Epoch: 5| Step: 3
Training loss: 3.5373803324054465
Validation loss: 3.09350622432119

Epoch: 5| Step: 4
Training loss: 3.620916368405222
Validation loss: 3.088515934489981

Epoch: 5| Step: 5
Training loss: 3.4164696768441263
Validation loss: 3.089774701667856

Epoch: 5| Step: 6
Training loss: 2.8303294994900496
Validation loss: 3.089428236952771

Epoch: 5| Step: 7
Training loss: 3.849428154227974
Validation loss: 3.0845867681189056

Epoch: 5| Step: 8
Training loss: 2.7779990065746576
Validation loss: 3.0879878559729192

Epoch: 5| Step: 9
Training loss: 3.472086908035028
Validation loss: 3.082414444145427

Epoch: 5| Step: 10
Training loss: 3.1239132326607395
Validation loss: 3.0835122491953113

Epoch: 20| Step: 0
Training loss: 3.2327393159838023
Validation loss: 3.085077808862984

Epoch: 5| Step: 1
Training loss: 3.2500375598791162
Validation loss: 3.0871813745832966

Epoch: 5| Step: 2
Training loss: 3.569865726756102
Validation loss: 3.094031352515104

Epoch: 5| Step: 3
Training loss: 3.9084714142592296
Validation loss: 3.088210081127548

Epoch: 5| Step: 4
Training loss: 3.530743047733184
Validation loss: 3.0900800326369855

Epoch: 5| Step: 5
Training loss: 2.8699443981885517
Validation loss: 3.085043389443427

Epoch: 5| Step: 6
Training loss: 2.7798333149619183
Validation loss: 3.0840462478769193

Epoch: 5| Step: 7
Training loss: 3.1043350549550626
Validation loss: 3.0810227859270682

Epoch: 5| Step: 8
Training loss: 3.594599880399889
Validation loss: 3.0798740018515405

Epoch: 5| Step: 9
Training loss: 3.800783884610148
Validation loss: 3.0804764822186104

Epoch: 5| Step: 10
Training loss: 3.056385241677566
Validation loss: 3.080144689019638

Epoch: 21| Step: 0
Training loss: 3.1095262040222424
Validation loss: 3.0747381308082087

Epoch: 5| Step: 1
Training loss: 4.065940456481661
Validation loss: 3.0766321175280518

Epoch: 5| Step: 2
Training loss: 3.6017421586578924
Validation loss: 3.076960581041341

Epoch: 5| Step: 3
Training loss: 2.6681606061770764
Validation loss: 3.0786727685229374

Epoch: 5| Step: 4
Training loss: 2.87890724378799
Validation loss: 3.0757840290628122

Epoch: 5| Step: 5
Training loss: 3.3736021184576743
Validation loss: 3.0753254877332195

Epoch: 5| Step: 6
Training loss: 3.3166889119640266
Validation loss: 3.0746590762228467

Epoch: 5| Step: 7
Training loss: 3.7064078543435093
Validation loss: 3.0756897430300887

Epoch: 5| Step: 8
Training loss: 3.473796026660009
Validation loss: 3.0843509407200997

Epoch: 5| Step: 9
Training loss: 3.1359284617964236
Validation loss: 3.0930592476465093

Epoch: 5| Step: 10
Training loss: 3.254615587309012
Validation loss: 3.0845508887554063

Epoch: 22| Step: 0
Training loss: 3.4595926741818093
Validation loss: 3.080109600220755

Epoch: 5| Step: 1
Training loss: 3.4902869734512456
Validation loss: 3.084510652174973

Epoch: 5| Step: 2
Training loss: 3.2925899192679378
Validation loss: 3.0722824657487555

Epoch: 5| Step: 3
Training loss: 3.6529797658122325
Validation loss: 3.076281480062216

Epoch: 5| Step: 4
Training loss: 3.481457913283648
Validation loss: 3.0761172993563983

Epoch: 5| Step: 5
Training loss: 3.6425197402324945
Validation loss: 3.0680531357910334

Epoch: 5| Step: 6
Training loss: 2.7665627823901358
Validation loss: 3.0683835294584565

Epoch: 5| Step: 7
Training loss: 3.8203015161524103
Validation loss: 3.064343234065602

Epoch: 5| Step: 8
Training loss: 3.0910204010570648
Validation loss: 3.0655238224552708

Epoch: 5| Step: 9
Training loss: 3.0407898218190805
Validation loss: 3.065691948880576

Epoch: 5| Step: 10
Training loss: 2.745488801526581
Validation loss: 3.0690867878348382

Epoch: 23| Step: 0
Training loss: 3.3940977252115374
Validation loss: 3.0665441635278388

Epoch: 5| Step: 1
Training loss: 3.287215269109078
Validation loss: 3.067779908439563

Epoch: 5| Step: 2
Training loss: 2.5544170271456808
Validation loss: 3.064724823700535

Epoch: 5| Step: 3
Training loss: 2.471646794371953
Validation loss: 3.06632346078141

Epoch: 5| Step: 4
Training loss: 3.682046510699995
Validation loss: 3.0648036242818444

Epoch: 5| Step: 5
Training loss: 2.49648419163667
Validation loss: 3.072116025165635

Epoch: 5| Step: 6
Training loss: 3.404266059635345
Validation loss: 3.0744627408447047

Epoch: 5| Step: 7
Training loss: 3.0094653851809046
Validation loss: 3.080001471470776

Epoch: 5| Step: 8
Training loss: 3.887221230082173
Validation loss: 3.068981785829306

Epoch: 5| Step: 9
Training loss: 3.871800855614807
Validation loss: 3.06462583159314

Epoch: 5| Step: 10
Training loss: 4.189849422179989
Validation loss: 3.0601263987385448

Epoch: 24| Step: 0
Training loss: 3.1627283368211914
Validation loss: 3.0595398845315405

Epoch: 5| Step: 1
Training loss: 3.9708657219691
Validation loss: 3.054649200673532

Epoch: 5| Step: 2
Training loss: 3.217929772615365
Validation loss: 3.0541474649393447

Epoch: 5| Step: 3
Training loss: 3.493372227643946
Validation loss: 3.0553398433424945

Epoch: 5| Step: 4
Training loss: 3.5209650470241427
Validation loss: 3.0586934008272118

Epoch: 5| Step: 5
Training loss: 3.6878747264744427
Validation loss: 3.0624539420184704

Epoch: 5| Step: 6
Training loss: 3.2060703041330747
Validation loss: 3.068866466763769

Epoch: 5| Step: 7
Training loss: 2.3023572617811654
Validation loss: 3.06637085684588

Epoch: 5| Step: 8
Training loss: 3.261967851640589
Validation loss: 3.0657366612338808

Epoch: 5| Step: 9
Training loss: 3.191144019644643
Validation loss: 3.0616598276408498

Epoch: 5| Step: 10
Training loss: 3.2932220035788595
Validation loss: 3.054771549539432

Epoch: 25| Step: 0
Training loss: 3.4539715173780583
Validation loss: 3.050803457966605

Epoch: 5| Step: 1
Training loss: 3.9046256388282004
Validation loss: 3.047351678077842

Epoch: 5| Step: 2
Training loss: 2.8648098018019432
Validation loss: 3.0479557145346377

Epoch: 5| Step: 3
Training loss: 3.4903030943763027
Validation loss: 3.0478765271483383

Epoch: 5| Step: 4
Training loss: 3.3707303484512394
Validation loss: 3.046947645610265

Epoch: 5| Step: 5
Training loss: 3.273509168181742
Validation loss: 3.0451279445577537

Epoch: 5| Step: 6
Training loss: 2.866435355087824
Validation loss: 3.0423054318701865

Epoch: 5| Step: 7
Training loss: 3.6523917944700974
Validation loss: 3.0470764497432152

Epoch: 5| Step: 8
Training loss: 2.7992872352750315
Validation loss: 3.049421639411813

Epoch: 5| Step: 9
Training loss: 3.201972716949714
Validation loss: 3.0556677942801795

Epoch: 5| Step: 10
Training loss: 3.5040126686563924
Validation loss: 3.063518064476554

Epoch: 26| Step: 0
Training loss: 2.9140425366901646
Validation loss: 3.0612896739022353

Epoch: 5| Step: 1
Training loss: 3.605320225856399
Validation loss: 3.0535434057132607

Epoch: 5| Step: 2
Training loss: 3.193445532333526
Validation loss: 3.0451883995566846

Epoch: 5| Step: 3
Training loss: 3.4950851264158866
Validation loss: 3.0364084502285267

Epoch: 5| Step: 4
Training loss: 3.002035086511237
Validation loss: 3.041117466999578

Epoch: 5| Step: 5
Training loss: 3.5286458633629305
Validation loss: 3.0475499661572316

Epoch: 5| Step: 6
Training loss: 3.316612425956459
Validation loss: 3.041351836988984

Epoch: 5| Step: 7
Training loss: 2.936542760838069
Validation loss: 3.0422408275218644

Epoch: 5| Step: 8
Training loss: 3.782171594213913
Validation loss: 3.0605866509789754

Epoch: 5| Step: 9
Training loss: 3.468391743622892
Validation loss: 3.067694911213261

Epoch: 5| Step: 10
Training loss: 3.0451548880535335
Validation loss: 3.0528071465443833

Epoch: 27| Step: 0
Training loss: 3.09052671270424
Validation loss: 3.0477752020425237

Epoch: 5| Step: 1
Training loss: 3.1128949508416737
Validation loss: 3.0437768254468036

Epoch: 5| Step: 2
Training loss: 2.8474517874450007
Validation loss: 3.038000025531444

Epoch: 5| Step: 3
Training loss: 3.531921457914302
Validation loss: 3.0328408504647735

Epoch: 5| Step: 4
Training loss: 3.736179953078367
Validation loss: 3.0303600219688467

Epoch: 5| Step: 5
Training loss: 3.3995195442016053
Validation loss: 3.0325572285568247

Epoch: 5| Step: 6
Training loss: 2.899607789713547
Validation loss: 3.0322397018390217

Epoch: 5| Step: 7
Training loss: 3.4389592627940835
Validation loss: 3.0299798190024454

Epoch: 5| Step: 8
Training loss: 2.9130170240444953
Validation loss: 3.0272934276514745

Epoch: 5| Step: 9
Training loss: 3.6834101868863858
Validation loss: 3.0216917120385496

Epoch: 5| Step: 10
Training loss: 3.591930293581399
Validation loss: 3.023084728403498

Epoch: 28| Step: 0
Training loss: 2.5926474560377137
Validation loss: 3.03937110522364

Epoch: 5| Step: 1
Training loss: 3.2736676483458385
Validation loss: 3.084276650083167

Epoch: 5| Step: 2
Training loss: 3.241635636391156
Validation loss: 3.068579990633376

Epoch: 5| Step: 3
Training loss: 3.2142581151352627
Validation loss: 3.0300203025254375

Epoch: 5| Step: 4
Training loss: 3.1176996025543544
Validation loss: 3.0221491820843798

Epoch: 5| Step: 5
Training loss: 3.471511016911735
Validation loss: 3.0217552642442618

Epoch: 5| Step: 6
Training loss: 3.1320557857626667
Validation loss: 3.023579177744215

Epoch: 5| Step: 7
Training loss: 3.4901299954663445
Validation loss: 3.022685886094933

Epoch: 5| Step: 8
Training loss: 4.051305282672265
Validation loss: 3.021386493847108

Epoch: 5| Step: 9
Training loss: 3.7028279245702267
Validation loss: 3.017683768747005

Epoch: 5| Step: 10
Training loss: 2.743090793259884
Validation loss: 3.015953896573665

Epoch: 29| Step: 0
Training loss: 2.8848400067636373
Validation loss: 3.0151990228022845

Epoch: 5| Step: 1
Training loss: 3.3145057795427166
Validation loss: 3.0160224317289477

Epoch: 5| Step: 2
Training loss: 3.0593583477685375
Validation loss: 3.020081931506836

Epoch: 5| Step: 3
Training loss: 3.6977193143952607
Validation loss: 3.020237854570969

Epoch: 5| Step: 4
Training loss: 3.720375154713444
Validation loss: 3.014116776663107

Epoch: 5| Step: 5
Training loss: 3.335579274439349
Validation loss: 3.014960730427932

Epoch: 5| Step: 6
Training loss: 2.8459107291186756
Validation loss: 3.0104338306974223

Epoch: 5| Step: 7
Training loss: 3.4083337971905405
Validation loss: 3.01176296213543

Epoch: 5| Step: 8
Training loss: 3.226094283521775
Validation loss: 3.012419436832779

Epoch: 5| Step: 9
Training loss: 3.4576354797255218
Validation loss: 3.0126583863285927

Epoch: 5| Step: 10
Training loss: 3.0389718088773656
Validation loss: 3.014262624516044

Epoch: 30| Step: 0
Training loss: 3.1327392873984996
Validation loss: 3.017789864132773

Epoch: 5| Step: 1
Training loss: 3.2041665965569286
Validation loss: 3.0182937628889595

Epoch: 5| Step: 2
Training loss: 3.3617244577680747
Validation loss: 3.0395325526190726

Epoch: 5| Step: 3
Training loss: 3.458755252945816
Validation loss: 3.017854358191693

Epoch: 5| Step: 4
Training loss: 2.9442491306647964
Validation loss: 3.0090703998750907

Epoch: 5| Step: 5
Training loss: 2.229166642899082
Validation loss: 3.002727850116817

Epoch: 5| Step: 6
Training loss: 3.6815688715653687
Validation loss: 2.9953845113135777

Epoch: 5| Step: 7
Training loss: 3.536141038161863
Validation loss: 2.996333156099844

Epoch: 5| Step: 8
Training loss: 3.7684972422092304
Validation loss: 2.9911292382074954

Epoch: 5| Step: 9
Training loss: 3.6438319934760557
Validation loss: 2.9880076168964402

Epoch: 5| Step: 10
Training loss: 2.63621423486331
Validation loss: 2.986068702836052

Epoch: 31| Step: 0
Training loss: 2.473748759712267
Validation loss: 2.9795890461069923

Epoch: 5| Step: 1
Training loss: 3.640669793766143
Validation loss: 2.979538703634106

Epoch: 5| Step: 2
Training loss: 3.2735747169741374
Validation loss: 2.9740272184843093

Epoch: 5| Step: 3
Training loss: 2.8943243326008155
Validation loss: 2.9786158427608243

Epoch: 5| Step: 4
Training loss: 3.8011184652565175
Validation loss: 2.9761544788955305

Epoch: 5| Step: 5
Training loss: 2.71759359386319
Validation loss: 2.9772312139949753

Epoch: 5| Step: 6
Training loss: 3.161838531675934
Validation loss: 2.975103558455959

Epoch: 5| Step: 7
Training loss: 2.8654959779603653
Validation loss: 2.972265284683812

Epoch: 5| Step: 8
Training loss: 3.672296378123876
Validation loss: 2.9737802820747055

Epoch: 5| Step: 9
Training loss: 3.533403668213405
Validation loss: 2.9696872684559183

Epoch: 5| Step: 10
Training loss: 3.5211616829496974
Validation loss: 2.967547460584731

Epoch: 32| Step: 0
Training loss: 2.887470895859987
Validation loss: 2.968316237016537

Epoch: 5| Step: 1
Training loss: 3.4307937402103046
Validation loss: 2.9665425010415256

Epoch: 5| Step: 2
Training loss: 3.587911756325565
Validation loss: 2.967625061264461

Epoch: 5| Step: 3
Training loss: 3.2347497400474903
Validation loss: 2.968760721719462

Epoch: 5| Step: 4
Training loss: 3.543641755134527
Validation loss: 2.9667826205972556

Epoch: 5| Step: 5
Training loss: 3.8273978652134057
Validation loss: 2.964259109983427

Epoch: 5| Step: 6
Training loss: 3.085350888667474
Validation loss: 2.962782182983717

Epoch: 5| Step: 7
Training loss: 3.2437331594276237
Validation loss: 2.9619749046661754

Epoch: 5| Step: 8
Training loss: 3.5221289934909468
Validation loss: 2.962010765428968

Epoch: 5| Step: 9
Training loss: 2.5159927004661258
Validation loss: 2.960215881348241

Epoch: 5| Step: 10
Training loss: 2.4869838428286917
Validation loss: 2.959613681281365

Epoch: 33| Step: 0
Training loss: 2.8987674987975427
Validation loss: 2.962876452173744

Epoch: 5| Step: 1
Training loss: 3.2692560333035257
Validation loss: 2.9698792896563417

Epoch: 5| Step: 2
Training loss: 2.4049607823717403
Validation loss: 2.9709647483209802

Epoch: 5| Step: 3
Training loss: 3.488799156025813
Validation loss: 2.9696531026398203

Epoch: 5| Step: 4
Training loss: 3.5781865676846953
Validation loss: 2.9692762011086535

Epoch: 5| Step: 5
Training loss: 3.1180538034941563
Validation loss: 2.965035144164825

Epoch: 5| Step: 6
Training loss: 3.4974843930270474
Validation loss: 2.9621045883486294

Epoch: 5| Step: 7
Training loss: 3.2177949247670283
Validation loss: 2.959232227265011

Epoch: 5| Step: 8
Training loss: 3.3287725400716637
Validation loss: 2.9540825744468844

Epoch: 5| Step: 9
Training loss: 3.2746093400520397
Validation loss: 2.955984737696142

Epoch: 5| Step: 10
Training loss: 3.4437513901834054
Validation loss: 2.952365826927435

Epoch: 34| Step: 0
Training loss: 2.614969799968737
Validation loss: 2.954049110743578

Epoch: 5| Step: 1
Training loss: 2.927846752450504
Validation loss: 2.9564561834538825

Epoch: 5| Step: 2
Training loss: 2.8166769588064224
Validation loss: 2.953480463163287

Epoch: 5| Step: 3
Training loss: 3.0951265297509982
Validation loss: 2.9513597240289826

Epoch: 5| Step: 4
Training loss: 3.7073104962246526
Validation loss: 2.953264384103631

Epoch: 5| Step: 5
Training loss: 3.590089874630211
Validation loss: 2.947135001295329

Epoch: 5| Step: 6
Training loss: 3.539818689261392
Validation loss: 2.9527334750315624

Epoch: 5| Step: 7
Training loss: 3.24743286862193
Validation loss: 2.952322266613853

Epoch: 5| Step: 8
Training loss: 3.5012432342649147
Validation loss: 2.949630653559614

Epoch: 5| Step: 9
Training loss: 3.2266844202241542
Validation loss: 2.951395295964782

Epoch: 5| Step: 10
Training loss: 3.088331158536532
Validation loss: 2.948395048487849

Epoch: 35| Step: 0
Training loss: 3.7487493336808293
Validation loss: 2.9491708481181353

Epoch: 5| Step: 1
Training loss: 3.396109368898478
Validation loss: 2.949816538398528

Epoch: 5| Step: 2
Training loss: 2.9203384357441635
Validation loss: 2.948228071209999

Epoch: 5| Step: 3
Training loss: 3.1599703475912952
Validation loss: 2.9490006269811206

Epoch: 5| Step: 4
Training loss: 2.6476260041968476
Validation loss: 2.946224709070727

Epoch: 5| Step: 5
Training loss: 3.70400668565052
Validation loss: 2.942873415761804

Epoch: 5| Step: 6
Training loss: 2.9643073319190183
Validation loss: 2.9452677899855697

Epoch: 5| Step: 7
Training loss: 3.4873260181194463
Validation loss: 2.9460072572064298

Epoch: 5| Step: 8
Training loss: 3.25388353575693
Validation loss: 2.9432333137184417

Epoch: 5| Step: 9
Training loss: 3.3689201128017907
Validation loss: 2.9396815964413485

Epoch: 5| Step: 10
Training loss: 2.523364370130838
Validation loss: 2.943633876036165

Epoch: 36| Step: 0
Training loss: 3.1222012002885093
Validation loss: 2.9483048839148687

Epoch: 5| Step: 1
Training loss: 3.2974962851363885
Validation loss: 2.96199416322986

Epoch: 5| Step: 2
Training loss: 2.83861102564822
Validation loss: 2.9724753631763345

Epoch: 5| Step: 3
Training loss: 3.9516209089337457
Validation loss: 2.9663180611926605

Epoch: 5| Step: 4
Training loss: 2.6019365654615862
Validation loss: 2.9386539553384536

Epoch: 5| Step: 5
Training loss: 3.0580293370917278
Validation loss: 2.9374313285374334

Epoch: 5| Step: 6
Training loss: 3.8885357620735346
Validation loss: 2.936460649305181

Epoch: 5| Step: 7
Training loss: 3.495900068832026
Validation loss: 2.938947662566128

Epoch: 5| Step: 8
Training loss: 2.6473716008765074
Validation loss: 2.9428255430083827

Epoch: 5| Step: 9
Training loss: 3.4375868352846113
Validation loss: 2.9413815461239836

Epoch: 5| Step: 10
Training loss: 2.7832674574527645
Validation loss: 2.942757101232925

Epoch: 37| Step: 0
Training loss: 3.7694587661020065
Validation loss: 2.936187808006193

Epoch: 5| Step: 1
Training loss: 2.444233226561331
Validation loss: 2.9363027404899653

Epoch: 5| Step: 2
Training loss: 3.185965374295668
Validation loss: 2.934791875304808

Epoch: 5| Step: 3
Training loss: 2.5764989175348214
Validation loss: 2.9358628335581436

Epoch: 5| Step: 4
Training loss: 2.946769536094151
Validation loss: 2.9355371323443356

Epoch: 5| Step: 5
Training loss: 4.027433022546574
Validation loss: 2.9322200949937547

Epoch: 5| Step: 6
Training loss: 3.272401777852304
Validation loss: 2.933074460837492

Epoch: 5| Step: 7
Training loss: 3.035653445491677
Validation loss: 2.937055805966394

Epoch: 5| Step: 8
Training loss: 3.185604354554998
Validation loss: 2.9422892686008275

Epoch: 5| Step: 9
Training loss: 3.386124678694015
Validation loss: 2.946439872236687

Epoch: 5| Step: 10
Training loss: 3.3043997709219957
Validation loss: 2.9365738678801727

Epoch: 38| Step: 0
Training loss: 3.18635164406278
Validation loss: 2.9278081449694

Epoch: 5| Step: 1
Training loss: 2.9050155807313653
Validation loss: 2.925836926514888

Epoch: 5| Step: 2
Training loss: 3.517332755791783
Validation loss: 2.926603837134088

Epoch: 5| Step: 3
Training loss: 2.8094589747013186
Validation loss: 2.925366666642032

Epoch: 5| Step: 4
Training loss: 2.854072532122427
Validation loss: 2.9251264926051856

Epoch: 5| Step: 5
Training loss: 3.6187823674627193
Validation loss: 2.925551626410735

Epoch: 5| Step: 6
Training loss: 3.986581827003067
Validation loss: 2.925505778397711

Epoch: 5| Step: 7
Training loss: 3.2730661695990397
Validation loss: 2.92469130258663

Epoch: 5| Step: 8
Training loss: 3.07304869976986
Validation loss: 2.926153519127086

Epoch: 5| Step: 9
Training loss: 3.0395916867854944
Validation loss: 2.927463710994312

Epoch: 5| Step: 10
Training loss: 2.8064244239481604
Validation loss: 2.923536265226967

Epoch: 39| Step: 0
Training loss: 3.77593595510254
Validation loss: 2.925512981630819

Epoch: 5| Step: 1
Training loss: 2.948215824399769
Validation loss: 2.923746001857407

Epoch: 5| Step: 2
Training loss: 2.717746330123303
Validation loss: 2.9233227417410768

Epoch: 5| Step: 3
Training loss: 2.8054799100122207
Validation loss: 2.919637103256898

Epoch: 5| Step: 4
Training loss: 3.1910598921790285
Validation loss: 2.9240042391840397

Epoch: 5| Step: 5
Training loss: 3.6192395710890723
Validation loss: 2.9250144900641515

Epoch: 5| Step: 6
Training loss: 3.3267687689249654
Validation loss: 2.932282549089616

Epoch: 5| Step: 7
Training loss: 3.2913133616710453
Validation loss: 2.9272278366238624

Epoch: 5| Step: 8
Training loss: 3.3268395748828703
Validation loss: 2.935139205084684

Epoch: 5| Step: 9
Training loss: 2.9421034109585484
Validation loss: 2.927147676101335

Epoch: 5| Step: 10
Training loss: 3.0848827249502984
Validation loss: 2.9240233559270807

Epoch: 40| Step: 0
Training loss: 3.5620842406620934
Validation loss: 2.9145171402908465

Epoch: 5| Step: 1
Training loss: 2.26207934520869
Validation loss: 2.912219695111825

Epoch: 5| Step: 2
Training loss: 3.330712973302032
Validation loss: 2.9108443097644416

Epoch: 5| Step: 3
Training loss: 3.1093863482244233
Validation loss: 2.910846194505981

Epoch: 5| Step: 4
Training loss: 3.2806801437362605
Validation loss: 2.909510309460883

Epoch: 5| Step: 5
Training loss: 3.8611296707426894
Validation loss: 2.909582484992855

Epoch: 5| Step: 6
Training loss: 3.0252799795172303
Validation loss: 2.9057560224253907

Epoch: 5| Step: 7
Training loss: 2.8795710175293676
Validation loss: 2.90686920552426

Epoch: 5| Step: 8
Training loss: 3.2174963129907215
Validation loss: 2.905520882799581

Epoch: 5| Step: 9
Training loss: 3.404207509674006
Validation loss: 2.904065328422943

Epoch: 5| Step: 10
Training loss: 2.836547954001328
Validation loss: 2.904632541679563

Epoch: 41| Step: 0
Training loss: 3.6321326491293764
Validation loss: 2.9096307575594866

Epoch: 5| Step: 1
Training loss: 3.875418978774729
Validation loss: 2.9241143305876656

Epoch: 5| Step: 2
Training loss: 3.136431423153319
Validation loss: 2.917514785535257

Epoch: 5| Step: 3
Training loss: 3.232123139282876
Validation loss: 2.921763751123298

Epoch: 5| Step: 4
Training loss: 3.046102729152097
Validation loss: 2.9168829267872556

Epoch: 5| Step: 5
Training loss: 3.0320950932650597
Validation loss: 2.9108324473140996

Epoch: 5| Step: 6
Training loss: 3.0822073108972785
Validation loss: 2.911439053371115

Epoch: 5| Step: 7
Training loss: 2.6445761469716365
Validation loss: 2.9045656995355884

Epoch: 5| Step: 8
Training loss: 3.267967442624649
Validation loss: 2.906638740565521

Epoch: 5| Step: 9
Training loss: 2.7703005821113678
Validation loss: 2.9065317561394837

Epoch: 5| Step: 10
Training loss: 3.1899482450203176
Validation loss: 2.9052948182014617

Epoch: 42| Step: 0
Training loss: 3.8893273575660254
Validation loss: 2.9010594194877597

Epoch: 5| Step: 1
Training loss: 3.4698840512738562
Validation loss: 2.8983087798826275

Epoch: 5| Step: 2
Training loss: 2.8639160118787883
Validation loss: 2.8945428896385397

Epoch: 5| Step: 3
Training loss: 2.968460872022818
Validation loss: 2.8922067223069527

Epoch: 5| Step: 4
Training loss: 2.779752349525911
Validation loss: 2.893858434416948

Epoch: 5| Step: 5
Training loss: 3.247128612023623
Validation loss: 2.9054896991746118

Epoch: 5| Step: 6
Training loss: 2.854215709701158
Validation loss: 2.9060243988068084

Epoch: 5| Step: 7
Training loss: 3.437606948575993
Validation loss: 2.896571264456664

Epoch: 5| Step: 8
Training loss: 2.865413771969892
Validation loss: 2.8940317748914803

Epoch: 5| Step: 9
Training loss: 3.3170629778942105
Validation loss: 2.8962768766246745

Epoch: 5| Step: 10
Training loss: 3.1488002066491996
Validation loss: 2.896806501314174

Epoch: 43| Step: 0
Training loss: 3.269829484652619
Validation loss: 2.8891074514286434

Epoch: 5| Step: 1
Training loss: 3.3313611554178792
Validation loss: 2.8901992559709138

Epoch: 5| Step: 2
Training loss: 2.565836618224574
Validation loss: 2.892118823279025

Epoch: 5| Step: 3
Training loss: 2.959385930880024
Validation loss: 2.898204397288738

Epoch: 5| Step: 4
Training loss: 3.5587719601542163
Validation loss: 2.890241956400054

Epoch: 5| Step: 5
Training loss: 3.1296436141046717
Validation loss: 2.8853889648510345

Epoch: 5| Step: 6
Training loss: 3.423875197997141
Validation loss: 2.8855424501652256

Epoch: 5| Step: 7
Training loss: 3.51141091292749
Validation loss: 2.8878559115872044

Epoch: 5| Step: 8
Training loss: 3.4424188273825247
Validation loss: 2.896455473225252

Epoch: 5| Step: 9
Training loss: 2.985044394311539
Validation loss: 2.893731649244894

Epoch: 5| Step: 10
Training loss: 2.4772368755402905
Validation loss: 2.8919988212761756

Epoch: 44| Step: 0
Training loss: 3.2177734375
Validation loss: 2.889570245648763

Epoch: 5| Step: 1
Training loss: 3.350420848545108
Validation loss: 2.8898049816363294

Epoch: 5| Step: 2
Training loss: 3.3330394297412624
Validation loss: 2.883815967457406

Epoch: 5| Step: 3
Training loss: 3.619356827266222
Validation loss: 2.880830070856859

Epoch: 5| Step: 4
Training loss: 2.8913505674585487
Validation loss: 2.8803283871699397

Epoch: 5| Step: 5
Training loss: 2.717434268777619
Validation loss: 2.8790513314014916

Epoch: 5| Step: 6
Training loss: 2.9298421183157353
Validation loss: 2.875423252218896

Epoch: 5| Step: 7
Training loss: 3.0913224377380146
Validation loss: 2.879230636772401

Epoch: 5| Step: 8
Training loss: 3.4758061304142935
Validation loss: 2.877832833472156

Epoch: 5| Step: 9
Training loss: 3.1305776030215315
Validation loss: 2.8775376012576674

Epoch: 5| Step: 10
Training loss: 3.0270783338792073
Validation loss: 2.875234230526236

Epoch: 45| Step: 0
Training loss: 3.1253462027468135
Validation loss: 2.886211824267811

Epoch: 5| Step: 1
Training loss: 3.1797240908905056
Validation loss: 2.8833347650832986

Epoch: 5| Step: 2
Training loss: 3.558624568935565
Validation loss: 2.892961547828773

Epoch: 5| Step: 3
Training loss: 3.5929149155006237
Validation loss: 2.8776580236819544

Epoch: 5| Step: 4
Training loss: 3.1842585518970643
Validation loss: 2.877867169161858

Epoch: 5| Step: 5
Training loss: 2.784764330496175
Validation loss: 2.879222573381505

Epoch: 5| Step: 6
Training loss: 2.9711679349550537
Validation loss: 2.8771990889857078

Epoch: 5| Step: 7
Training loss: 2.4901518445270097
Validation loss: 2.898365632481247

Epoch: 5| Step: 8
Training loss: 3.3760920982905867
Validation loss: 2.910778769320157

Epoch: 5| Step: 9
Training loss: 3.2533377600728337
Validation loss: 2.9073355247713777

Epoch: 5| Step: 10
Training loss: 3.118895557500474
Validation loss: 2.9102493124798388

Epoch: 46| Step: 0
Training loss: 2.6411375191708815
Validation loss: 2.918823206698162

Epoch: 5| Step: 1
Training loss: 3.0272256151345505
Validation loss: 2.929855097307703

Epoch: 5| Step: 2
Training loss: 3.3827903693975148
Validation loss: 2.9098246389114726

Epoch: 5| Step: 3
Training loss: 3.3231166352917754
Validation loss: 2.8731680138667803

Epoch: 5| Step: 4
Training loss: 3.9349456252106276
Validation loss: 2.866725635750761

Epoch: 5| Step: 5
Training loss: 2.813088080064969
Validation loss: 2.8663288055673384

Epoch: 5| Step: 6
Training loss: 3.3423918345489025
Validation loss: 2.862987835731634

Epoch: 5| Step: 7
Training loss: 2.8225404176614153
Validation loss: 2.866248475367872

Epoch: 5| Step: 8
Training loss: 3.0611507012433505
Validation loss: 2.8712232500105106

Epoch: 5| Step: 9
Training loss: 3.2337926073072767
Validation loss: 2.8660055632933443

Epoch: 5| Step: 10
Training loss: 2.9930458530899138
Validation loss: 2.8629307605609977

Epoch: 47| Step: 0
Training loss: 2.9061238251235415
Validation loss: 2.863204112714548

Epoch: 5| Step: 1
Training loss: 3.5911003628130334
Validation loss: 2.86173680580275

Epoch: 5| Step: 2
Training loss: 3.3846678546359694
Validation loss: 2.8602878945210786

Epoch: 5| Step: 3
Training loss: 2.7355496744405476
Validation loss: 2.8599660015975337

Epoch: 5| Step: 4
Training loss: 3.4763559344356185
Validation loss: 2.860250094237128

Epoch: 5| Step: 5
Training loss: 3.2848273258899146
Validation loss: 2.8615436315305316

Epoch: 5| Step: 6
Training loss: 2.85646217276007
Validation loss: 2.871075218397032

Epoch: 5| Step: 7
Training loss: 2.861413614603861
Validation loss: 2.8890742520397494

Epoch: 5| Step: 8
Training loss: 3.3328570184537685
Validation loss: 2.886441834777868

Epoch: 5| Step: 9
Training loss: 3.3217882175539537
Validation loss: 2.8573768367745953

Epoch: 5| Step: 10
Training loss: 2.748207201479835
Validation loss: 2.856937563130492

Epoch: 48| Step: 0
Training loss: 3.5321178888884583
Validation loss: 2.8584914146494342

Epoch: 5| Step: 1
Training loss: 3.2321808232438833
Validation loss: 2.8695008776531346

Epoch: 5| Step: 2
Training loss: 3.967337770083812
Validation loss: 2.886084913703069

Epoch: 5| Step: 3
Training loss: 2.238871604730714
Validation loss: 2.8670082444197345

Epoch: 5| Step: 4
Training loss: 3.2852134382098717
Validation loss: 2.859376332308318

Epoch: 5| Step: 5
Training loss: 2.7615322713739636
Validation loss: 2.860294691958327

Epoch: 5| Step: 6
Training loss: 3.4747441369137673
Validation loss: 2.8605478975355583

Epoch: 5| Step: 7
Training loss: 2.9526785053811966
Validation loss: 2.8593638932225147

Epoch: 5| Step: 8
Training loss: 3.389363418944795
Validation loss: 2.8659295396643056

Epoch: 5| Step: 9
Training loss: 2.9802684391649055
Validation loss: 2.8783385076695485

Epoch: 5| Step: 10
Training loss: 2.5915204312525426
Validation loss: 2.882008310964337

Epoch: 49| Step: 0
Training loss: 3.4970881747397073
Validation loss: 2.8742084902770926

Epoch: 5| Step: 1
Training loss: 2.515156957077986
Validation loss: 2.86433010171553

Epoch: 5| Step: 2
Training loss: 3.53895659635627
Validation loss: 2.856740717926803

Epoch: 5| Step: 3
Training loss: 3.6735054454417826
Validation loss: 2.8527019890210337

Epoch: 5| Step: 4
Training loss: 3.0058133702416776
Validation loss: 2.8538746826292316

Epoch: 5| Step: 5
Training loss: 2.893734800492446
Validation loss: 2.850889351743175

Epoch: 5| Step: 6
Training loss: 3.4484746352816145
Validation loss: 2.849887671503121

Epoch: 5| Step: 7
Training loss: 2.3920979668066047
Validation loss: 2.8497514058247946

Epoch: 5| Step: 8
Training loss: 3.0797570254114675
Validation loss: 2.8504909127483535

Epoch: 5| Step: 9
Training loss: 2.8677470729182093
Validation loss: 2.846633419325804

Epoch: 5| Step: 10
Training loss: 3.4392604134860827
Validation loss: 2.8637067982232147

Epoch: 50| Step: 0
Training loss: 3.3967342624795283
Validation loss: 2.8497969414896507

Epoch: 5| Step: 1
Training loss: 3.117408993149023
Validation loss: 2.8456013605334243

Epoch: 5| Step: 2
Training loss: 2.8044571210766476
Validation loss: 2.844229180352554

Epoch: 5| Step: 3
Training loss: 2.6692288328758664
Validation loss: 2.8478387914547874

Epoch: 5| Step: 4
Training loss: 3.0640737421509403
Validation loss: 2.841774027827388

Epoch: 5| Step: 5
Training loss: 3.02211446671276
Validation loss: 2.8509302750726793

Epoch: 5| Step: 6
Training loss: 3.105718868907485
Validation loss: 2.8553283916374497

Epoch: 5| Step: 7
Training loss: 3.0330867904686842
Validation loss: 2.858247997153678

Epoch: 5| Step: 8
Training loss: 3.665593394787955
Validation loss: 2.8418147477371405

Epoch: 5| Step: 9
Training loss: 3.054678290077628
Validation loss: 2.8407629336350517

Epoch: 5| Step: 10
Training loss: 3.49728260818017
Validation loss: 2.8369709363529982

Epoch: 51| Step: 0
Training loss: 3.252569649937992
Validation loss: 2.8361036599507075

Epoch: 5| Step: 1
Training loss: 2.981165093386456
Validation loss: 2.8379711458727455

Epoch: 5| Step: 2
Training loss: 3.222207591874974
Validation loss: 2.83854401245803

Epoch: 5| Step: 3
Training loss: 2.855449879971422
Validation loss: 2.837385700470301

Epoch: 5| Step: 4
Training loss: 2.8182027856544596
Validation loss: 2.8377738053292076

Epoch: 5| Step: 5
Training loss: 3.5692404174547803
Validation loss: 2.838839635293368

Epoch: 5| Step: 6
Training loss: 3.03408020661869
Validation loss: 2.8355367755892695

Epoch: 5| Step: 7
Training loss: 2.909890960275969
Validation loss: 2.8351668886018047

Epoch: 5| Step: 8
Training loss: 3.3583104065774307
Validation loss: 2.8340976493691

Epoch: 5| Step: 9
Training loss: 3.4880971144446886
Validation loss: 2.834299581168554

Epoch: 5| Step: 10
Training loss: 2.9052982207451343
Validation loss: 2.8293737114608946

Epoch: 52| Step: 0
Training loss: 2.943731313593491
Validation loss: 2.830452424929373

Epoch: 5| Step: 1
Training loss: 3.503006189051722
Validation loss: 2.834128610833108

Epoch: 5| Step: 2
Training loss: 3.0857920938349865
Validation loss: 2.8333712622934666

Epoch: 5| Step: 3
Training loss: 3.670128199861412
Validation loss: 2.839025489657592

Epoch: 5| Step: 4
Training loss: 2.7038798959456796
Validation loss: 2.838969309846187

Epoch: 5| Step: 5
Training loss: 2.539558995927999
Validation loss: 2.8349837057448353

Epoch: 5| Step: 6
Training loss: 3.0368039876105737
Validation loss: 2.8403034439877537

Epoch: 5| Step: 7
Training loss: 3.461618464107829
Validation loss: 2.841407475463098

Epoch: 5| Step: 8
Training loss: 3.1586841224047455
Validation loss: 2.840611024122733

Epoch: 5| Step: 9
Training loss: 3.3524295423416053
Validation loss: 2.8408986856339

Epoch: 5| Step: 10
Training loss: 2.553379855748874
Validation loss: 2.8453653240240717

Epoch: 53| Step: 0
Training loss: 2.7777937083317332
Validation loss: 2.8584719609900806

Epoch: 5| Step: 1
Training loss: 2.485835192077876
Validation loss: 2.9076510009909393

Epoch: 5| Step: 2
Training loss: 2.595993358726999
Validation loss: 2.869278862945746

Epoch: 5| Step: 3
Training loss: 3.525084658208109
Validation loss: 2.8494045613517196

Epoch: 5| Step: 4
Training loss: 3.103244892120767
Validation loss: 2.832151019400062

Epoch: 5| Step: 5
Training loss: 3.033778129356064
Validation loss: 2.826104680241138

Epoch: 5| Step: 6
Training loss: 3.0156582054721395
Validation loss: 2.8238174139020065

Epoch: 5| Step: 7
Training loss: 3.4133537482108127
Validation loss: 2.823194654396748

Epoch: 5| Step: 8
Training loss: 3.1347595404925372
Validation loss: 2.8228841966752682

Epoch: 5| Step: 9
Training loss: 3.310848904225889
Validation loss: 2.820646607376728

Epoch: 5| Step: 10
Training loss: 3.88183090113667
Validation loss: 2.8219556346772356

Epoch: 54| Step: 0
Training loss: 3.0527228161769333
Validation loss: 2.8183161230694536

Epoch: 5| Step: 1
Training loss: 3.4656212245139772
Validation loss: 2.8251381303538134

Epoch: 5| Step: 2
Training loss: 2.3587176689354
Validation loss: 2.813089284837837

Epoch: 5| Step: 3
Training loss: 3.0380859375
Validation loss: 2.810089907199934

Epoch: 5| Step: 4
Training loss: 3.4279004700677103
Validation loss: 2.806584489321959

Epoch: 5| Step: 5
Training loss: 3.000580095790626
Validation loss: 2.797715087086458

Epoch: 5| Step: 6
Training loss: 3.5436101330801835
Validation loss: 2.7998450051022283

Epoch: 5| Step: 7
Training loss: 3.7161001814364045
Validation loss: 2.798599176437308

Epoch: 5| Step: 8
Training loss: 2.750837458626991
Validation loss: 2.795045113005836

Epoch: 5| Step: 9
Training loss: 3.0846471478985364
Validation loss: 2.792878483148949

Epoch: 5| Step: 10
Training loss: 2.4323775434887986
Validation loss: 2.793972169647279

Epoch: 55| Step: 0
Training loss: 3.1517510406427065
Validation loss: 2.796910565117447

Epoch: 5| Step: 1
Training loss: 3.1856866802361132
Validation loss: 2.7977477193721043

Epoch: 5| Step: 2
Training loss: 2.7733870380807626
Validation loss: 2.796049293024108

Epoch: 5| Step: 3
Training loss: 2.719327317251384
Validation loss: 2.799966468991146

Epoch: 5| Step: 4
Training loss: 2.464430785006082
Validation loss: 2.8106937674633414

Epoch: 5| Step: 5
Training loss: 3.4503654397006223
Validation loss: 2.821176660543971

Epoch: 5| Step: 6
Training loss: 3.091975926837257
Validation loss: 2.8280508144622054

Epoch: 5| Step: 7
Training loss: 2.945900612961638
Validation loss: 2.801498809266724

Epoch: 5| Step: 8
Training loss: 2.8795994994056966
Validation loss: 2.791975196854083

Epoch: 5| Step: 9
Training loss: 3.8720623078810705
Validation loss: 2.790905545805272

Epoch: 5| Step: 10
Training loss: 3.4010619805018028
Validation loss: 2.7974053363178624

Epoch: 56| Step: 0
Training loss: 2.8978929033728877
Validation loss: 2.803237769330306

Epoch: 5| Step: 1
Training loss: 2.8715750154676454
Validation loss: 2.789749219524138

Epoch: 5| Step: 2
Training loss: 2.943393557729097
Validation loss: 2.786557248582997

Epoch: 5| Step: 3
Training loss: 3.0406339451186835
Validation loss: 2.7887852037632648

Epoch: 5| Step: 4
Training loss: 3.0478010286482764
Validation loss: 2.7833961096081286

Epoch: 5| Step: 5
Training loss: 3.223491694502843
Validation loss: 2.8028260677831818

Epoch: 5| Step: 6
Training loss: 3.6244556412899733
Validation loss: 2.7792395284156686

Epoch: 5| Step: 7
Training loss: 3.06820925048484
Validation loss: 2.7899407083920607

Epoch: 5| Step: 8
Training loss: 2.8846403287151423
Validation loss: 2.79884410037495

Epoch: 5| Step: 9
Training loss: 3.5958844024697587
Validation loss: 2.8385664051547512

Epoch: 5| Step: 10
Training loss: 2.8703858209921083
Validation loss: 2.796195478324258

Epoch: 57| Step: 0
Training loss: 3.4197870442528364
Validation loss: 2.7948439902614948

Epoch: 5| Step: 1
Training loss: 3.2288331546627513
Validation loss: 2.7936294688597854

Epoch: 5| Step: 2
Training loss: 3.284232682212557
Validation loss: 2.800084292846726

Epoch: 5| Step: 3
Training loss: 2.9688341630750945
Validation loss: 2.808079858295665

Epoch: 5| Step: 4
Training loss: 3.054102380621573
Validation loss: 2.8192244688622576

Epoch: 5| Step: 5
Training loss: 3.0695591747385618
Validation loss: 2.817645805662439

Epoch: 5| Step: 6
Training loss: 3.0224793958947673
Validation loss: 2.8045131946706197

Epoch: 5| Step: 7
Training loss: 3.382133997296882
Validation loss: 2.800223512855026

Epoch: 5| Step: 8
Training loss: 2.790196292493948
Validation loss: 2.7835360427125297

Epoch: 5| Step: 9
Training loss: 3.0467407196972838
Validation loss: 2.776901396116148

Epoch: 5| Step: 10
Training loss: 2.7398038323341423
Validation loss: 2.78206954740649

Epoch: 58| Step: 0
Training loss: 3.526008158777657
Validation loss: 2.7764528130104216

Epoch: 5| Step: 1
Training loss: 2.2495447334001515
Validation loss: 2.784559347830894

Epoch: 5| Step: 2
Training loss: 2.7683046796564788
Validation loss: 2.7938042160205576

Epoch: 5| Step: 3
Training loss: 3.325913961897662
Validation loss: 2.8152590937605004

Epoch: 5| Step: 4
Training loss: 3.1043567129924785
Validation loss: 2.8236065547418296

Epoch: 5| Step: 5
Training loss: 3.5469384544847045
Validation loss: 2.8300250105950426

Epoch: 5| Step: 6
Training loss: 3.0537994733028118
Validation loss: 2.7844407943005343

Epoch: 5| Step: 7
Training loss: 3.028958585187128
Validation loss: 2.7706103540879625

Epoch: 5| Step: 8
Training loss: 2.5429318098675453
Validation loss: 2.771919666378089

Epoch: 5| Step: 9
Training loss: 3.0830122978170573
Validation loss: 2.7705335245920075

Epoch: 5| Step: 10
Training loss: 3.5745485247457083
Validation loss: 2.7688110679640503

Epoch: 59| Step: 0
Training loss: 3.3480910883445287
Validation loss: 2.7708880887638

Epoch: 5| Step: 1
Training loss: 3.119298081792006
Validation loss: 2.771479989541443

Epoch: 5| Step: 2
Training loss: 2.8270597190311104
Validation loss: 2.775695524934248

Epoch: 5| Step: 3
Training loss: 3.44413353087586
Validation loss: 2.7748733540386814

Epoch: 5| Step: 4
Training loss: 2.734936029916977
Validation loss: 2.7730248936515216

Epoch: 5| Step: 5
Training loss: 2.7343814522803336
Validation loss: 2.7727604715754155

Epoch: 5| Step: 6
Training loss: 3.3484264720712007
Validation loss: 2.765109226897127

Epoch: 5| Step: 7
Training loss: 3.1529278787143267
Validation loss: 2.774270551451801

Epoch: 5| Step: 8
Training loss: 3.369109488080757
Validation loss: 2.7711493711049027

Epoch: 5| Step: 9
Training loss: 2.553331861205046
Validation loss: 2.7670032276000867

Epoch: 5| Step: 10
Training loss: 3.0324534750543397
Validation loss: 2.7675778924956957

Epoch: 60| Step: 0
Training loss: 2.556871419795478
Validation loss: 2.769279923191003

Epoch: 5| Step: 1
Training loss: 2.40441061288525
Validation loss: 2.762335527845434

Epoch: 5| Step: 2
Training loss: 2.8428274481729363
Validation loss: 2.7618125833098888

Epoch: 5| Step: 3
Training loss: 3.5813127335784176
Validation loss: 2.762203733197995

Epoch: 5| Step: 4
Training loss: 3.7695296055291103
Validation loss: 2.7606399814193514

Epoch: 5| Step: 5
Training loss: 2.639376734652391
Validation loss: 2.761917969673963

Epoch: 5| Step: 6
Training loss: 3.1639624309021364
Validation loss: 2.759871167555176

Epoch: 5| Step: 7
Training loss: 2.9512549236536056
Validation loss: 2.75757186273444

Epoch: 5| Step: 8
Training loss: 2.9384515722599702
Validation loss: 2.760703592524576

Epoch: 5| Step: 9
Training loss: 3.4451033686616954
Validation loss: 2.7621096894929567

Epoch: 5| Step: 10
Training loss: 3.2246376188856205
Validation loss: 2.756737781622704

Epoch: 61| Step: 0
Training loss: 3.1729451896869905
Validation loss: 2.7578115257873366

Epoch: 5| Step: 1
Training loss: 2.06494573600353
Validation loss: 2.7565254397293897

Epoch: 5| Step: 2
Training loss: 3.1364777924943223
Validation loss: 2.7706599181653435

Epoch: 5| Step: 3
Training loss: 3.5254402643233105
Validation loss: 2.771673478695993

Epoch: 5| Step: 4
Training loss: 2.21807915660341
Validation loss: 2.7729577830064938

Epoch: 5| Step: 5
Training loss: 3.2057912754928957
Validation loss: 2.780401495170355

Epoch: 5| Step: 6
Training loss: 3.2041441249839924
Validation loss: 2.7753697547434744

Epoch: 5| Step: 7
Training loss: 3.2639862767473335
Validation loss: 2.757246221752855

Epoch: 5| Step: 8
Training loss: 3.4162537550111716
Validation loss: 2.7500742867766177

Epoch: 5| Step: 9
Training loss: 3.1898911427068066
Validation loss: 2.7536695585904556

Epoch: 5| Step: 10
Training loss: 3.0403577696936943
Validation loss: 2.7518971798466265

Epoch: 62| Step: 0
Training loss: 2.1462394428826674
Validation loss: 2.7549629287454405

Epoch: 5| Step: 1
Training loss: 3.4978470311249197
Validation loss: 2.7531277767246216

Epoch: 5| Step: 2
Training loss: 3.458192722878431
Validation loss: 2.7528408866634426

Epoch: 5| Step: 3
Training loss: 3.054729958944049
Validation loss: 2.7532791665341207

Epoch: 5| Step: 4
Training loss: 3.0074586338106184
Validation loss: 2.7543300656581002

Epoch: 5| Step: 5
Training loss: 2.9556951086740075
Validation loss: 2.7693866925912385

Epoch: 5| Step: 6
Training loss: 3.0205215468589297
Validation loss: 2.8011436965296155

Epoch: 5| Step: 7
Training loss: 3.071607476787208
Validation loss: 2.8000258063666763

Epoch: 5| Step: 8
Training loss: 2.5147704574461263
Validation loss: 2.771704783223019

Epoch: 5| Step: 9
Training loss: 3.4742714866099482
Validation loss: 2.7629330242742904

Epoch: 5| Step: 10
Training loss: 3.2646744362186424
Validation loss: 2.752848841568056

Epoch: 63| Step: 0
Training loss: 3.2337600197063585
Validation loss: 2.7470035346186763

Epoch: 5| Step: 1
Training loss: 3.0542336831713546
Validation loss: 2.746821004482054

Epoch: 5| Step: 2
Training loss: 2.4611728131855197
Validation loss: 2.738370485533904

Epoch: 5| Step: 3
Training loss: 2.6129661107747126
Validation loss: 2.7382748771257335

Epoch: 5| Step: 4
Training loss: 3.215689083309762
Validation loss: 2.7431549430866755

Epoch: 5| Step: 5
Training loss: 2.6944169920301717
Validation loss: 2.7397711845521013

Epoch: 5| Step: 6
Training loss: 3.2695846279804974
Validation loss: 2.7411584205436097

Epoch: 5| Step: 7
Training loss: 3.454307664325709
Validation loss: 2.744335799767888

Epoch: 5| Step: 8
Training loss: 3.6566408388610263
Validation loss: 2.7402860583264252

Epoch: 5| Step: 9
Training loss: 2.633720264094954
Validation loss: 2.740650940473436

Epoch: 5| Step: 10
Training loss: 3.2332550911104887
Validation loss: 2.740183156614021

Epoch: 64| Step: 0
Training loss: 3.0287951724800375
Validation loss: 2.741629976556392

Epoch: 5| Step: 1
Training loss: 3.3530595899247637
Validation loss: 2.7398924737180432

Epoch: 5| Step: 2
Training loss: 3.3449046200324246
Validation loss: 2.742696135690619

Epoch: 5| Step: 3
Training loss: 2.7074618967180637
Validation loss: 2.741356777742495

Epoch: 5| Step: 4
Training loss: 3.1094590372202027
Validation loss: 2.7420003475549417

Epoch: 5| Step: 5
Training loss: 3.5880297704969184
Validation loss: 2.748986492791386

Epoch: 5| Step: 6
Training loss: 2.889392156861511
Validation loss: 2.742466459461147

Epoch: 5| Step: 7
Training loss: 2.7753660562006313
Validation loss: 2.7413244785749424

Epoch: 5| Step: 8
Training loss: 2.7230977339448765
Validation loss: 2.7386409848620987

Epoch: 5| Step: 9
Training loss: 3.3109353166746724
Validation loss: 2.7383919579502165

Epoch: 5| Step: 10
Training loss: 2.4963321482398806
Validation loss: 2.7344888849171705

Epoch: 65| Step: 0
Training loss: 3.385796972579184
Validation loss: 2.734380242830515

Epoch: 5| Step: 1
Training loss: 2.5308908278342965
Validation loss: 2.733972211431938

Epoch: 5| Step: 2
Training loss: 3.4036253169909747
Validation loss: 2.74236393964398

Epoch: 5| Step: 3
Training loss: 3.056925624443039
Validation loss: 2.7439203617613206

Epoch: 5| Step: 4
Training loss: 3.1979274356093277
Validation loss: 2.748068236358735

Epoch: 5| Step: 5
Training loss: 2.965811952058516
Validation loss: 2.756447496859156

Epoch: 5| Step: 6
Training loss: 3.370686069913539
Validation loss: 2.7515210105913113

Epoch: 5| Step: 7
Training loss: 2.977963255645969
Validation loss: 2.749516103350507

Epoch: 5| Step: 8
Training loss: 2.7803338074100816
Validation loss: 2.7494743903883765

Epoch: 5| Step: 9
Training loss: 2.6879083190167052
Validation loss: 2.7367148630549267

Epoch: 5| Step: 10
Training loss: 3.0679806306170363
Validation loss: 2.7351510723554613

Epoch: 66| Step: 0
Training loss: 2.9521996395555625
Validation loss: 2.730857187146327

Epoch: 5| Step: 1
Training loss: 3.002338451705415
Validation loss: 2.72600823891695

Epoch: 5| Step: 2
Training loss: 3.3439398025405804
Validation loss: 2.727767326956444

Epoch: 5| Step: 3
Training loss: 3.015457702107301
Validation loss: 2.727024766815524

Epoch: 5| Step: 4
Training loss: 3.0741681842450346
Validation loss: 2.7250467582778537

Epoch: 5| Step: 5
Training loss: 2.6087664962561377
Validation loss: 2.72481215650767

Epoch: 5| Step: 6
Training loss: 3.170507577879542
Validation loss: 2.7258106053750244

Epoch: 5| Step: 7
Training loss: 2.948442248253165
Validation loss: 2.7247288325804715

Epoch: 5| Step: 8
Training loss: 3.4505023922217513
Validation loss: 2.724336421950975

Epoch: 5| Step: 9
Training loss: 2.95802441627273
Validation loss: 2.7254004820233737

Epoch: 5| Step: 10
Training loss: 2.8286810059673586
Validation loss: 2.727549551872956

Epoch: 67| Step: 0
Training loss: 2.843625244086955
Validation loss: 2.732048514572691

Epoch: 5| Step: 1
Training loss: 3.31811192012529
Validation loss: 2.7510628972085804

Epoch: 5| Step: 2
Training loss: 2.9182117366094356
Validation loss: 2.780016920841328

Epoch: 5| Step: 3
Training loss: 3.321030483033584
Validation loss: 2.754269289599382

Epoch: 5| Step: 4
Training loss: 3.1120187839343223
Validation loss: 2.726661987539361

Epoch: 5| Step: 5
Training loss: 2.988427890346083
Validation loss: 2.7212308155162694

Epoch: 5| Step: 6
Training loss: 3.040886731071392
Validation loss: 2.727452820654766

Epoch: 5| Step: 7
Training loss: 3.183375214173068
Validation loss: 2.7325796432303755

Epoch: 5| Step: 8
Training loss: 3.03920025746183
Validation loss: 2.7446398267590686

Epoch: 5| Step: 9
Training loss: 2.7245330690479674
Validation loss: 2.7429528736691737

Epoch: 5| Step: 10
Training loss: 3.255638073847168
Validation loss: 2.7328846253516974

Epoch: 68| Step: 0
Training loss: 2.705280921578116
Validation loss: 2.7244597908906045

Epoch: 5| Step: 1
Training loss: 3.3071205074846293
Validation loss: 2.7210890689362652

Epoch: 5| Step: 2
Training loss: 2.7041685702920177
Validation loss: 2.725345510040105

Epoch: 5| Step: 3
Training loss: 2.443863021695577
Validation loss: 2.720931723620247

Epoch: 5| Step: 4
Training loss: 3.0681870264593547
Validation loss: 2.7235011885347378

Epoch: 5| Step: 5
Training loss: 3.3919590729457605
Validation loss: 2.722935671049225

Epoch: 5| Step: 6
Training loss: 3.1558526421631052
Validation loss: 2.726201875664207

Epoch: 5| Step: 7
Training loss: 3.199829490410418
Validation loss: 2.730067116700662

Epoch: 5| Step: 8
Training loss: 3.494214043824107
Validation loss: 2.737698859517891

Epoch: 5| Step: 9
Training loss: 2.748992301805249
Validation loss: 2.755101939708121

Epoch: 5| Step: 10
Training loss: 3.179601869671985
Validation loss: 2.733992768510799

Epoch: 69| Step: 0
Training loss: 2.9538655639203277
Validation loss: 2.7269161281934555

Epoch: 5| Step: 1
Training loss: 3.7826584643988905
Validation loss: 2.7249431460800753

Epoch: 5| Step: 2
Training loss: 3.0955879069647003
Validation loss: 2.7208639593715

Epoch: 5| Step: 3
Training loss: 2.6031082647364965
Validation loss: 2.720447443670923

Epoch: 5| Step: 4
Training loss: 2.878272640322457
Validation loss: 2.720062576445162

Epoch: 5| Step: 5
Training loss: 3.031135950204247
Validation loss: 2.737062429872172

Epoch: 5| Step: 6
Training loss: 2.888523637064423
Validation loss: 2.729420009922801

Epoch: 5| Step: 7
Training loss: 3.414171719058911
Validation loss: 2.727898052453819

Epoch: 5| Step: 8
Training loss: 2.7411495320095067
Validation loss: 2.728730057284557

Epoch: 5| Step: 9
Training loss: 2.7768780925560934
Validation loss: 2.7176687721206685

Epoch: 5| Step: 10
Training loss: 3.035877431765104
Validation loss: 2.7138087426390616

Epoch: 70| Step: 0
Training loss: 3.2881056601168224
Validation loss: 2.7106474053047727

Epoch: 5| Step: 1
Training loss: 3.079290024312911
Validation loss: 2.715228425065858

Epoch: 5| Step: 2
Training loss: 3.4058763491573667
Validation loss: 2.7138655853818783

Epoch: 5| Step: 3
Training loss: 2.2117273651893097
Validation loss: 2.709624531847985

Epoch: 5| Step: 4
Training loss: 3.1677059342085587
Validation loss: 2.7145487075770824

Epoch: 5| Step: 5
Training loss: 2.91485339520734
Validation loss: 2.7142017808585153

Epoch: 5| Step: 6
Training loss: 2.906196183557507
Validation loss: 2.7125618420004485

Epoch: 5| Step: 7
Training loss: 3.2934567054878454
Validation loss: 2.7092285737018442

Epoch: 5| Step: 8
Training loss: 3.3028479973340663
Validation loss: 2.7105238002084002

Epoch: 5| Step: 9
Training loss: 2.698672734859992
Validation loss: 2.7170634665097215

Epoch: 5| Step: 10
Training loss: 2.8975384492602347
Validation loss: 2.7206093843456034

Epoch: 71| Step: 0
Training loss: 2.8514805612157366
Validation loss: 2.7225237482941176

Epoch: 5| Step: 1
Training loss: 3.522394876095946
Validation loss: 2.7199933183314724

Epoch: 5| Step: 2
Training loss: 3.1352289255570183
Validation loss: 2.7161362138877365

Epoch: 5| Step: 3
Training loss: 3.1840195447139776
Validation loss: 2.7161518610823876

Epoch: 5| Step: 4
Training loss: 3.1750403334090755
Validation loss: 2.718345286649856

Epoch: 5| Step: 5
Training loss: 2.9957079384088985
Validation loss: 2.723489158652093

Epoch: 5| Step: 6
Training loss: 2.3802032693242823
Validation loss: 2.7215742115368626

Epoch: 5| Step: 7
Training loss: 2.8004098217636506
Validation loss: 2.721527594937622

Epoch: 5| Step: 8
Training loss: 2.9393470314117955
Validation loss: 2.722724785984293

Epoch: 5| Step: 9
Training loss: 3.2092934365016026
Validation loss: 2.726005980925346

Epoch: 5| Step: 10
Training loss: 2.889126776005517
Validation loss: 2.7276365209436633

Epoch: 72| Step: 0
Training loss: 3.252249012909032
Validation loss: 2.713585060794097

Epoch: 5| Step: 1
Training loss: 3.3065004538733764
Validation loss: 2.713838016710561

Epoch: 5| Step: 2
Training loss: 3.431236803484556
Validation loss: 2.7055275287532434

Epoch: 5| Step: 3
Training loss: 2.929970201204075
Validation loss: 2.703937473618102

Epoch: 5| Step: 4
Training loss: 3.655422932255537
Validation loss: 2.704697991969378

Epoch: 5| Step: 5
Training loss: 3.115527329975335
Validation loss: 2.701232347146717

Epoch: 5| Step: 6
Training loss: 2.8536434575768554
Validation loss: 2.698393245871177

Epoch: 5| Step: 7
Training loss: 2.4916714220628897
Validation loss: 2.704875599448417

Epoch: 5| Step: 8
Training loss: 2.702574304481995
Validation loss: 2.7002899441134796

Epoch: 5| Step: 9
Training loss: 1.7688996996394803
Validation loss: 2.701627824215924

Epoch: 5| Step: 10
Training loss: 3.2782529676859293
Validation loss: 2.709376930307757

Epoch: 73| Step: 0
Training loss: 3.125102689963154
Validation loss: 2.7122452407346342

Epoch: 5| Step: 1
Training loss: 3.4235590444392394
Validation loss: 2.721269947712791

Epoch: 5| Step: 2
Training loss: 2.8620164687711163
Validation loss: 2.715469999418964

Epoch: 5| Step: 3
Training loss: 3.5250745129657117
Validation loss: 2.707769387899521

Epoch: 5| Step: 4
Training loss: 3.073622765748577
Validation loss: 2.7127570613284138

Epoch: 5| Step: 5
Training loss: 2.9594975898270124
Validation loss: 2.7179921666015185

Epoch: 5| Step: 6
Training loss: 2.5873180749304514
Validation loss: 2.7143310402687804

Epoch: 5| Step: 7
Training loss: 2.975442029667461
Validation loss: 2.706029672972202

Epoch: 5| Step: 8
Training loss: 2.7368387512329337
Validation loss: 2.70016156012891

Epoch: 5| Step: 9
Training loss: 3.015122920325208
Validation loss: 2.7026535003274788

Epoch: 5| Step: 10
Training loss: 2.708208717022389
Validation loss: 2.700507282166873

Epoch: 74| Step: 0
Training loss: 2.8679417753600696
Validation loss: 2.6950952381409863

Epoch: 5| Step: 1
Training loss: 2.739066410007504
Validation loss: 2.690680197859803

Epoch: 5| Step: 2
Training loss: 3.187514361180883
Validation loss: 2.699992679903536

Epoch: 5| Step: 3
Training loss: 3.0743325974591307
Validation loss: 2.7008745037816624

Epoch: 5| Step: 4
Training loss: 3.093789919200712
Validation loss: 2.7075409581226544

Epoch: 5| Step: 5
Training loss: 2.798165902526207
Validation loss: 2.723255239352957

Epoch: 5| Step: 6
Training loss: 2.9292463860622564
Validation loss: 2.709227652988551

Epoch: 5| Step: 7
Training loss: 2.3089285412515386
Validation loss: 2.7008120644518296

Epoch: 5| Step: 8
Training loss: 3.3240644013447014
Validation loss: 2.70171978576378

Epoch: 5| Step: 9
Training loss: 3.4740713731179413
Validation loss: 2.6894124755771

Epoch: 5| Step: 10
Training loss: 3.2095033733245004
Validation loss: 2.6870498299275805

Epoch: 75| Step: 0
Training loss: 3.3017611341394857
Validation loss: 2.6880661810877915

Epoch: 5| Step: 1
Training loss: 2.8951998413368387
Validation loss: 2.686510417551206

Epoch: 5| Step: 2
Training loss: 2.732494208773857
Validation loss: 2.6880394636705724

Epoch: 5| Step: 3
Training loss: 3.0525844193016005
Validation loss: 2.690391171102279

Epoch: 5| Step: 4
Training loss: 2.6922198700467086
Validation loss: 2.684992242870918

Epoch: 5| Step: 5
Training loss: 3.3293046606792545
Validation loss: 2.6994349833801854

Epoch: 5| Step: 6
Training loss: 3.229274985844981
Validation loss: 2.7250655185664994

Epoch: 5| Step: 7
Training loss: 3.133010972126469
Validation loss: 2.741566910362496

Epoch: 5| Step: 8
Training loss: 2.991741575473882
Validation loss: 2.7175367206116983

Epoch: 5| Step: 9
Training loss: 3.0294936292688046
Validation loss: 2.700660059213211

Epoch: 5| Step: 10
Training loss: 2.7375442884511823
Validation loss: 2.69117328387968

Epoch: 76| Step: 0
Training loss: 2.7728864095418997
Validation loss: 2.682399583113726

Epoch: 5| Step: 1
Training loss: 2.9050576009637044
Validation loss: 2.681845145130507

Epoch: 5| Step: 2
Training loss: 3.207290099984943
Validation loss: 2.6858728819872972

Epoch: 5| Step: 3
Training loss: 3.4495430574639667
Validation loss: 2.683315122862698

Epoch: 5| Step: 4
Training loss: 2.70541893089486
Validation loss: 2.6831065651575257

Epoch: 5| Step: 5
Training loss: 3.1748969053816922
Validation loss: 2.686175532975927

Epoch: 5| Step: 6
Training loss: 3.4575462518054656
Validation loss: 2.6846844089110156

Epoch: 5| Step: 7
Training loss: 3.309440351350655
Validation loss: 2.6837437863854974

Epoch: 5| Step: 8
Training loss: 3.0493937718493256
Validation loss: 2.681130855150579

Epoch: 5| Step: 9
Training loss: 2.1057981328987294
Validation loss: 2.6877545138220067

Epoch: 5| Step: 10
Training loss: 2.6165422697525558
Validation loss: 2.6941818959637898

Epoch: 77| Step: 0
Training loss: 2.845161506882191
Validation loss: 2.7151655538622954

Epoch: 5| Step: 1
Training loss: 2.7765877039360607
Validation loss: 2.7755226524771226

Epoch: 5| Step: 2
Training loss: 2.737700527284441
Validation loss: 2.9730947845682714

Epoch: 5| Step: 3
Training loss: 3.328705786233399
Validation loss: 3.233238016805599

Epoch: 5| Step: 4
Training loss: 3.9380308731907023
Validation loss: 3.1055347120116434

Epoch: 5| Step: 5
Training loss: 2.9114598983369193
Validation loss: 2.862362022350603

Epoch: 5| Step: 6
Training loss: 3.5819234218196616
Validation loss: 2.809534002459791

Epoch: 5| Step: 7
Training loss: 3.905254145519991
Validation loss: 2.8394214944565164

Epoch: 5| Step: 8
Training loss: 2.7904133236903825
Validation loss: 2.8064892654594678

Epoch: 5| Step: 9
Training loss: 2.877578242718823
Validation loss: 2.774626012003207

Epoch: 5| Step: 10
Training loss: 2.7866666531752933
Validation loss: 2.7437457031153567

Epoch: 78| Step: 0
Training loss: 3.010202543218029
Validation loss: 2.7439759071126155

Epoch: 5| Step: 1
Training loss: 2.9322069245058606
Validation loss: 2.7427953450686036

Epoch: 5| Step: 2
Training loss: 3.60967302949766
Validation loss: 2.763775948429159

Epoch: 5| Step: 3
Training loss: 3.074084578304226
Validation loss: 2.7661306823751377

Epoch: 5| Step: 4
Training loss: 3.193027565425851
Validation loss: 2.746973513673471

Epoch: 5| Step: 5
Training loss: 2.8470242273809236
Validation loss: 2.738049876228968

Epoch: 5| Step: 6
Training loss: 2.6723021227214034
Validation loss: 2.7308227088058117

Epoch: 5| Step: 7
Training loss: 3.2219978908482187
Validation loss: 2.7276591182934222

Epoch: 5| Step: 8
Training loss: 2.9290998759642908
Validation loss: 2.7278716603134767

Epoch: 5| Step: 9
Training loss: 2.99971356613958
Validation loss: 2.7314668215233935

Epoch: 5| Step: 10
Training loss: 3.0910349019602994
Validation loss: 2.7452101080963502

Epoch: 79| Step: 0
Training loss: 3.138354643271432
Validation loss: 2.752122233537253

Epoch: 5| Step: 1
Training loss: 2.8011055602965618
Validation loss: 2.7747954248747697

Epoch: 5| Step: 2
Training loss: 3.325522538047519
Validation loss: 2.778191647683578

Epoch: 5| Step: 3
Training loss: 2.8560177631413475
Validation loss: 2.761024212899814

Epoch: 5| Step: 4
Training loss: 3.0847524178202774
Validation loss: 2.7471280646559424

Epoch: 5| Step: 5
Training loss: 3.037632152053063
Validation loss: 2.748369654687683

Epoch: 5| Step: 6
Training loss: 2.8181768134847376
Validation loss: 2.7424880886347363

Epoch: 5| Step: 7
Training loss: 2.7635937143872438
Validation loss: 2.7363350748471

Epoch: 5| Step: 8
Training loss: 3.4587307131015494
Validation loss: 2.7328189258003523

Epoch: 5| Step: 9
Training loss: 2.857490293631501
Validation loss: 2.7314002309446

Epoch: 5| Step: 10
Training loss: 3.4380054449068265
Validation loss: 2.7287227207227813

Epoch: 80| Step: 0
Training loss: 3.5708773977854027
Validation loss: 2.724580896953317

Epoch: 5| Step: 1
Training loss: 2.962244233627302
Validation loss: 2.7230471892971018

Epoch: 5| Step: 2
Training loss: 3.1518714673901664
Validation loss: 2.728079107512385

Epoch: 5| Step: 3
Training loss: 2.99554716891364
Validation loss: 2.726032050692888

Epoch: 5| Step: 4
Training loss: 2.4583324389267496
Validation loss: 2.731637260255557

Epoch: 5| Step: 5
Training loss: 3.2139278697078084
Validation loss: 2.7454513498349673

Epoch: 5| Step: 6
Training loss: 2.8611953027512538
Validation loss: 2.7515942715049855

Epoch: 5| Step: 7
Training loss: 2.6523226258190924
Validation loss: 2.7691774165833927

Epoch: 5| Step: 8
Training loss: 3.7359361776990156
Validation loss: 2.775303001937591

Epoch: 5| Step: 9
Training loss: 2.8429472073092326
Validation loss: 2.739908722549591

Epoch: 5| Step: 10
Training loss: 2.7641198324292247
Validation loss: 2.726952475984385

Epoch: 81| Step: 0
Training loss: 3.5935886512692643
Validation loss: 2.715201768147902

Epoch: 5| Step: 1
Training loss: 2.748522014522122
Validation loss: 2.7193678909410086

Epoch: 5| Step: 2
Training loss: 2.9318127057465913
Validation loss: 2.708845646365371

Epoch: 5| Step: 3
Training loss: 2.385547706525154
Validation loss: 2.7065175045478673

Epoch: 5| Step: 4
Training loss: 2.7411662316558463
Validation loss: 2.707474509125932

Epoch: 5| Step: 5
Training loss: 3.036783889060099
Validation loss: 2.705231380241671

Epoch: 5| Step: 6
Training loss: 2.9670035596002684
Validation loss: 2.712326191070102

Epoch: 5| Step: 7
Training loss: 3.21543951064906
Validation loss: 2.6994640419996543

Epoch: 5| Step: 8
Training loss: 3.0493327864977378
Validation loss: 2.7088006798798605

Epoch: 5| Step: 9
Training loss: 3.2102956014222026
Validation loss: 2.70293719722664

Epoch: 5| Step: 10
Training loss: 3.2169952053500355
Validation loss: 2.703301949310581

Epoch: 82| Step: 0
Training loss: 3.2790879165390017
Validation loss: 2.712359391313543

Epoch: 5| Step: 1
Training loss: 3.0244823296601946
Validation loss: 2.7009028122489833

Epoch: 5| Step: 2
Training loss: 2.6465139239586537
Validation loss: 2.693661219093127

Epoch: 5| Step: 3
Training loss: 2.7536624448816456
Validation loss: 2.694927445951595

Epoch: 5| Step: 4
Training loss: 2.9793419063931603
Validation loss: 2.6892265693682775

Epoch: 5| Step: 5
Training loss: 3.2542377133658773
Validation loss: 2.6908260691517363

Epoch: 5| Step: 6
Training loss: 3.2542611577719756
Validation loss: 2.6906210511544373

Epoch: 5| Step: 7
Training loss: 2.6695793953545954
Validation loss: 2.6907258644734116

Epoch: 5| Step: 8
Training loss: 3.474017431089146
Validation loss: 2.687220526222507

Epoch: 5| Step: 9
Training loss: 2.777442125598185
Validation loss: 2.6852741644281437

Epoch: 5| Step: 10
Training loss: 2.830804051189858
Validation loss: 2.6895585404923437

Epoch: 83| Step: 0
Training loss: 3.2184474765864826
Validation loss: 2.688897147694656

Epoch: 5| Step: 1
Training loss: 2.964573542528925
Validation loss: 2.686620482034542

Epoch: 5| Step: 2
Training loss: 2.3287800117069937
Validation loss: 2.700683912225435

Epoch: 5| Step: 3
Training loss: 3.306014856294736
Validation loss: 2.7058595597129846

Epoch: 5| Step: 4
Training loss: 2.6017683251326535
Validation loss: 2.711032346720188

Epoch: 5| Step: 5
Training loss: 3.2339848822132407
Validation loss: 2.7095711264098212

Epoch: 5| Step: 6
Training loss: 3.1887805834671457
Validation loss: 2.6967790125825246

Epoch: 5| Step: 7
Training loss: 3.246583169520123
Validation loss: 2.687091853635075

Epoch: 5| Step: 8
Training loss: 2.6571802642052598
Validation loss: 2.6818671676214674

Epoch: 5| Step: 9
Training loss: 2.7865819505502736
Validation loss: 2.680924027598716

Epoch: 5| Step: 10
Training loss: 3.3388696153380324
Validation loss: 2.684694890972976

Epoch: 84| Step: 0
Training loss: 2.9393569271530526
Validation loss: 2.6829356176311396

Epoch: 5| Step: 1
Training loss: 3.371623292707785
Validation loss: 2.6776012827589915

Epoch: 5| Step: 2
Training loss: 2.9320174654223163
Validation loss: 2.6801847309105877

Epoch: 5| Step: 3
Training loss: 3.060601716563532
Validation loss: 2.6787998184911705

Epoch: 5| Step: 4
Training loss: 2.7368931973086053
Validation loss: 2.6812925640230745

Epoch: 5| Step: 5
Training loss: 3.407553327203314
Validation loss: 2.680959801726939

Epoch: 5| Step: 6
Training loss: 2.532330788535474
Validation loss: 2.6832212846500494

Epoch: 5| Step: 7
Training loss: 2.7751001666437207
Validation loss: 2.6867147062916636

Epoch: 5| Step: 8
Training loss: 2.7540729878047463
Validation loss: 2.689880198491524

Epoch: 5| Step: 9
Training loss: 3.501133735140012
Validation loss: 2.68709115908099

Epoch: 5| Step: 10
Training loss: 2.766328366596406
Validation loss: 2.680897400612177

Epoch: 85| Step: 0
Training loss: 2.5801860547069655
Validation loss: 2.6814946785126312

Epoch: 5| Step: 1
Training loss: 3.26877438479604
Validation loss: 2.687938562826225

Epoch: 5| Step: 2
Training loss: 2.9550471433438696
Validation loss: 2.6803787388917377

Epoch: 5| Step: 3
Training loss: 3.05842537252053
Validation loss: 2.674023058191861

Epoch: 5| Step: 4
Training loss: 2.7963755071011276
Validation loss: 2.6702302328182324

Epoch: 5| Step: 5
Training loss: 2.2477571116740025
Validation loss: 2.6729809014081356

Epoch: 5| Step: 6
Training loss: 3.1074458132720313
Validation loss: 2.6827278331351114

Epoch: 5| Step: 7
Training loss: 3.2177578776653384
Validation loss: 2.693799600067703

Epoch: 5| Step: 8
Training loss: 3.0058546159197217
Validation loss: 2.672817767924029

Epoch: 5| Step: 9
Training loss: 3.365375075274349
Validation loss: 2.6754258533805575

Epoch: 5| Step: 10
Training loss: 3.301837530925385
Validation loss: 2.6847613728584987

Epoch: 86| Step: 0
Training loss: 3.0427907321163454
Validation loss: 2.716895933182394

Epoch: 5| Step: 1
Training loss: 3.2834991013043693
Validation loss: 2.749859831473557

Epoch: 5| Step: 2
Training loss: 3.473959644933145
Validation loss: 2.715723716682111

Epoch: 5| Step: 3
Training loss: 2.9935476533363237
Validation loss: 2.6769234850686887

Epoch: 5| Step: 4
Training loss: 3.0935001465060745
Validation loss: 2.6761377317343933

Epoch: 5| Step: 5
Training loss: 2.860666119023898
Validation loss: 2.671190292244899

Epoch: 5| Step: 6
Training loss: 2.7408918052955284
Validation loss: 2.671014831170084

Epoch: 5| Step: 7
Training loss: 2.9611099716321108
Validation loss: 2.6735265923987583

Epoch: 5| Step: 8
Training loss: 2.992082638807968
Validation loss: 2.682069082051764

Epoch: 5| Step: 9
Training loss: 2.9186697121794967
Validation loss: 2.6863497871867867

Epoch: 5| Step: 10
Training loss: 2.538488610774622
Validation loss: 2.694637410570768

Epoch: 87| Step: 0
Training loss: 3.4320506511498494
Validation loss: 2.6845378744331647

Epoch: 5| Step: 1
Training loss: 2.7072491358583823
Validation loss: 2.6659624710683016

Epoch: 5| Step: 2
Training loss: 3.28594692662402
Validation loss: 2.675162641004597

Epoch: 5| Step: 3
Training loss: 3.3965604662803566
Validation loss: 2.676932131005119

Epoch: 5| Step: 4
Training loss: 3.2548759270385466
Validation loss: 2.6743497979677358

Epoch: 5| Step: 5
Training loss: 2.81611180981914
Validation loss: 2.699765310870146

Epoch: 5| Step: 6
Training loss: 3.0085056843791893
Validation loss: 2.7126102533413623

Epoch: 5| Step: 7
Training loss: 2.473633969107507
Validation loss: 2.702350887578776

Epoch: 5| Step: 8
Training loss: 2.5261491785405727
Validation loss: 2.679214879288246

Epoch: 5| Step: 9
Training loss: 2.556386027179482
Validation loss: 2.6527657846729014

Epoch: 5| Step: 10
Training loss: 3.294467571349628
Validation loss: 2.648076485753736

Epoch: 88| Step: 0
Training loss: 2.912421124745068
Validation loss: 2.644198601484959

Epoch: 5| Step: 1
Training loss: 2.7345552221578933
Validation loss: 2.6458496795399986

Epoch: 5| Step: 2
Training loss: 3.210914630297966
Validation loss: 2.650163082615851

Epoch: 5| Step: 3
Training loss: 3.2403456270458006
Validation loss: 2.6497539327079283

Epoch: 5| Step: 4
Training loss: 3.0892199092695147
Validation loss: 2.6591318363206424

Epoch: 5| Step: 5
Training loss: 3.001864330837487
Validation loss: 2.6660885469390037

Epoch: 5| Step: 6
Training loss: 2.289411394526163
Validation loss: 2.681775802449555

Epoch: 5| Step: 7
Training loss: 2.918247684490586
Validation loss: 2.686044845159288

Epoch: 5| Step: 8
Training loss: 3.4642085683376296
Validation loss: 2.695936171567893

Epoch: 5| Step: 9
Training loss: 3.187462002396834
Validation loss: 2.700468666475516

Epoch: 5| Step: 10
Training loss: 2.6943494762538154
Validation loss: 2.709486743369237

Epoch: 89| Step: 0
Training loss: 3.0429877107981964
Validation loss: 2.720003498441291

Epoch: 5| Step: 1
Training loss: 2.4357711333891183
Validation loss: 2.7217832642787307

Epoch: 5| Step: 2
Training loss: 3.1055699361954603
Validation loss: 2.7065349549427347

Epoch: 5| Step: 3
Training loss: 2.8786380803377836
Validation loss: 2.6995394411909643

Epoch: 5| Step: 4
Training loss: 3.3497164250386673
Validation loss: 2.6810608409081746

Epoch: 5| Step: 5
Training loss: 2.0050943581692993
Validation loss: 2.683735793814356

Epoch: 5| Step: 6
Training loss: 3.2126653250222916
Validation loss: 2.673656240003454

Epoch: 5| Step: 7
Training loss: 3.2047134554596304
Validation loss: 2.669856243072664

Epoch: 5| Step: 8
Training loss: 3.296492423327878
Validation loss: 2.6655368465623446

Epoch: 5| Step: 9
Training loss: 2.8310361600376845
Validation loss: 2.662805596772723

Epoch: 5| Step: 10
Training loss: 3.2419307009558063
Validation loss: 2.6598822325303

Epoch: 90| Step: 0
Training loss: 2.848316759656883
Validation loss: 2.655083422218393

Epoch: 5| Step: 1
Training loss: 2.619084550341195
Validation loss: 2.662681833124512

Epoch: 5| Step: 2
Training loss: 2.840633151438215
Validation loss: 2.659504876090507

Epoch: 5| Step: 3
Training loss: 3.3732912895035216
Validation loss: 2.6583156229311875

Epoch: 5| Step: 4
Training loss: 2.7831606356405834
Validation loss: 2.655632427888288

Epoch: 5| Step: 5
Training loss: 3.5314382317261432
Validation loss: 2.6604320094137806

Epoch: 5| Step: 6
Training loss: 3.030776311299351
Validation loss: 2.659319337372432

Epoch: 5| Step: 7
Training loss: 2.9170047745690098
Validation loss: 2.653134018549934

Epoch: 5| Step: 8
Training loss: 2.5103019171061587
Validation loss: 2.6570123262611904

Epoch: 5| Step: 9
Training loss: 3.07492596296795
Validation loss: 2.6591430910756855

Epoch: 5| Step: 10
Training loss: 3.1820800178100637
Validation loss: 2.665246653355365

Epoch: 91| Step: 0
Training loss: 2.903423452486013
Validation loss: 2.673642721114915

Epoch: 5| Step: 1
Training loss: 3.065172236272
Validation loss: 2.7047370524737455

Epoch: 5| Step: 2
Training loss: 3.2857173481328683
Validation loss: 2.7328628751439648

Epoch: 5| Step: 3
Training loss: 2.5872459213161285
Validation loss: 2.737984000060826

Epoch: 5| Step: 4
Training loss: 3.1441815483926705
Validation loss: 2.7481924840063536

Epoch: 5| Step: 5
Training loss: 2.6798889262397467
Validation loss: 2.765289613523554

Epoch: 5| Step: 6
Training loss: 2.831461082151971
Validation loss: 2.7384177010359125

Epoch: 5| Step: 7
Training loss: 3.1759725327733337
Validation loss: 2.7303932105905893

Epoch: 5| Step: 8
Training loss: 3.1069214308190536
Validation loss: 2.6604146025581366

Epoch: 5| Step: 9
Training loss: 2.6787145867011692
Validation loss: 2.6477537364801575

Epoch: 5| Step: 10
Training loss: 3.4017640418158646
Validation loss: 2.649858269874546

Epoch: 92| Step: 0
Training loss: 3.273028145552242
Validation loss: 2.6452543471212646

Epoch: 5| Step: 1
Training loss: 3.205604449567189
Validation loss: 2.6493840233633508

Epoch: 5| Step: 2
Training loss: 2.8034388916093813
Validation loss: 2.6470517214880145

Epoch: 5| Step: 3
Training loss: 2.512652803395765
Validation loss: 2.647263729780639

Epoch: 5| Step: 4
Training loss: 3.5200297926595647
Validation loss: 2.6442593876639373

Epoch: 5| Step: 5
Training loss: 3.2282630558534238
Validation loss: 2.6390300763336225

Epoch: 5| Step: 6
Training loss: 2.4590768713366944
Validation loss: 2.638323610170088

Epoch: 5| Step: 7
Training loss: 3.078748610786995
Validation loss: 2.6374487898310264

Epoch: 5| Step: 8
Training loss: 3.113166988865442
Validation loss: 2.6301738118225475

Epoch: 5| Step: 9
Training loss: 2.812670045586463
Validation loss: 2.626203422278015

Epoch: 5| Step: 10
Training loss: 2.637554663502978
Validation loss: 2.620333534289503

Epoch: 93| Step: 0
Training loss: 2.560332614480244
Validation loss: 2.622387313906328

Epoch: 5| Step: 1
Training loss: 2.6655611090924465
Validation loss: 2.620066393969353

Epoch: 5| Step: 2
Training loss: 2.306942421778737
Validation loss: 2.622919993045908

Epoch: 5| Step: 3
Training loss: 3.226609051901999
Validation loss: 2.6183949672269686

Epoch: 5| Step: 4
Training loss: 3.325413992212773
Validation loss: 2.6289257017208714

Epoch: 5| Step: 5
Training loss: 3.137795611433814
Validation loss: 2.6324622134612174

Epoch: 5| Step: 6
Training loss: 2.9689973426979126
Validation loss: 2.6365727438356

Epoch: 5| Step: 7
Training loss: 2.8355827004512903
Validation loss: 2.6336492308735657

Epoch: 5| Step: 8
Training loss: 3.159537387979842
Validation loss: 2.6288284738588965

Epoch: 5| Step: 9
Training loss: 3.3561272113864797
Validation loss: 2.6254905880964574

Epoch: 5| Step: 10
Training loss: 2.6954716289925695
Validation loss: 2.6263827516722724

Epoch: 94| Step: 0
Training loss: 2.856577854830925
Validation loss: 2.616447535869505

Epoch: 5| Step: 1
Training loss: 2.9463215928246407
Validation loss: 2.6178442620588522

Epoch: 5| Step: 2
Training loss: 3.1077576077668625
Validation loss: 2.6148828170631906

Epoch: 5| Step: 3
Training loss: 2.6934086806865216
Validation loss: 2.616565259252977

Epoch: 5| Step: 4
Training loss: 3.248660178210582
Validation loss: 2.6133116599811976

Epoch: 5| Step: 5
Training loss: 2.709454661323488
Validation loss: 2.614227675358301

Epoch: 5| Step: 6
Training loss: 2.512544060316017
Validation loss: 2.615595525344516

Epoch: 5| Step: 7
Training loss: 2.66594649564106
Validation loss: 2.6104149998520563

Epoch: 5| Step: 8
Training loss: 3.2544818199682584
Validation loss: 2.61416332926018

Epoch: 5| Step: 9
Training loss: 2.9054671022636662
Validation loss: 2.6149196554705245

Epoch: 5| Step: 10
Training loss: 3.5070287427852893
Validation loss: 2.6113337837329915

Epoch: 95| Step: 0
Training loss: 2.8349989501843535
Validation loss: 2.611775353874913

Epoch: 5| Step: 1
Training loss: 2.7850969262780474
Validation loss: 2.6166250502119026

Epoch: 5| Step: 2
Training loss: 3.1511365807900895
Validation loss: 2.6216996810225064

Epoch: 5| Step: 3
Training loss: 2.7163903530775855
Validation loss: 2.629062682735152

Epoch: 5| Step: 4
Training loss: 2.9669146837723006
Validation loss: 2.631227800400667

Epoch: 5| Step: 5
Training loss: 3.149522920841544
Validation loss: 2.6290985414000776

Epoch: 5| Step: 6
Training loss: 3.4761961326005655
Validation loss: 2.62580697253707

Epoch: 5| Step: 7
Training loss: 2.914559738649014
Validation loss: 2.6230798487012907

Epoch: 5| Step: 8
Training loss: 2.794596847092754
Validation loss: 2.620996748051453

Epoch: 5| Step: 9
Training loss: 2.598299655251531
Validation loss: 2.6114980171269924

Epoch: 5| Step: 10
Training loss: 2.913599545109989
Validation loss: 2.6175683831835723

Epoch: 96| Step: 0
Training loss: 2.936731278498565
Validation loss: 2.610548807009811

Epoch: 5| Step: 1
Training loss: 3.1957814961340385
Validation loss: 2.607953844951453

Epoch: 5| Step: 2
Training loss: 3.2772800225664995
Validation loss: 2.6120913659791545

Epoch: 5| Step: 3
Training loss: 2.5801932621806913
Validation loss: 2.617056530225466

Epoch: 5| Step: 4
Training loss: 2.9238212753552033
Validation loss: 2.6162473142952773

Epoch: 5| Step: 5
Training loss: 3.058532636282803
Validation loss: 2.6101711670561873

Epoch: 5| Step: 6
Training loss: 2.533954917627117
Validation loss: 2.6089950067712144

Epoch: 5| Step: 7
Training loss: 2.7534458938971174
Validation loss: 2.611345222896933

Epoch: 5| Step: 8
Training loss: 2.822078416152546
Validation loss: 2.61791705054236

Epoch: 5| Step: 9
Training loss: 3.073861049214478
Validation loss: 2.625111151244948

Epoch: 5| Step: 10
Training loss: 3.117046764131901
Validation loss: 2.6376272574702204

Epoch: 97| Step: 0
Training loss: 3.144850587919387
Validation loss: 2.642596613646316

Epoch: 5| Step: 1
Training loss: 2.8676712501161417
Validation loss: 2.6485518423774432

Epoch: 5| Step: 2
Training loss: 3.1458760104958183
Validation loss: 2.6390461768133635

Epoch: 5| Step: 3
Training loss: 2.154163180064977
Validation loss: 2.631141193227082

Epoch: 5| Step: 4
Training loss: 2.9423286845751497
Validation loss: 2.623967844313347

Epoch: 5| Step: 5
Training loss: 3.2713967747133608
Validation loss: 2.6268803131507377

Epoch: 5| Step: 6
Training loss: 3.330900798766842
Validation loss: 2.6219297933171553

Epoch: 5| Step: 7
Training loss: 2.7272708704971005
Validation loss: 2.619565293228446

Epoch: 5| Step: 8
Training loss: 3.227521924595196
Validation loss: 2.6193536053633464

Epoch: 5| Step: 9
Training loss: 2.565034125028561
Validation loss: 2.6145000404458614

Epoch: 5| Step: 10
Training loss: 2.7494208853175537
Validation loss: 2.6164351156755665

Epoch: 98| Step: 0
Training loss: 2.959004357399525
Validation loss: 2.605737750894203

Epoch: 5| Step: 1
Training loss: 2.735267972911699
Validation loss: 2.6048534769040743

Epoch: 5| Step: 2
Training loss: 3.2276380468936368
Validation loss: 2.5986100195095023

Epoch: 5| Step: 3
Training loss: 2.84000460288521
Validation loss: 2.602711956331109

Epoch: 5| Step: 4
Training loss: 2.8212968371301668
Validation loss: 2.604970057120957

Epoch: 5| Step: 5
Training loss: 2.8593810034516896
Validation loss: 2.6032970671430498

Epoch: 5| Step: 6
Training loss: 2.4371611530803587
Validation loss: 2.604877382488726

Epoch: 5| Step: 7
Training loss: 3.402501835090316
Validation loss: 2.613386841227875

Epoch: 5| Step: 8
Training loss: 3.2605352573135242
Validation loss: 2.623009310199187

Epoch: 5| Step: 9
Training loss: 2.9069293468958337
Validation loss: 2.6219735754741875

Epoch: 5| Step: 10
Training loss: 2.6476334783318283
Validation loss: 2.6167593911805502

Epoch: 99| Step: 0
Training loss: 2.659799156924406
Validation loss: 2.606090222781644

Epoch: 5| Step: 1
Training loss: 3.0595280765816812
Validation loss: 2.6006588043608763

Epoch: 5| Step: 2
Training loss: 3.0068644825496307
Validation loss: 2.6026829472811697

Epoch: 5| Step: 3
Training loss: 2.950567359030012
Validation loss: 2.5981503889054514

Epoch: 5| Step: 4
Training loss: 2.6616875138617897
Validation loss: 2.595056570680743

Epoch: 5| Step: 5
Training loss: 3.046399201631842
Validation loss: 2.5958120434837295

Epoch: 5| Step: 6
Training loss: 3.057951527253136
Validation loss: 2.5937791109335575

Epoch: 5| Step: 7
Training loss: 3.290674969618888
Validation loss: 2.5948659544856008

Epoch: 5| Step: 8
Training loss: 2.6858779980524736
Validation loss: 2.5950482614915913

Epoch: 5| Step: 9
Training loss: 2.922501603934547
Validation loss: 2.603146317131798

Epoch: 5| Step: 10
Training loss: 2.8193887904478308
Validation loss: 2.6071689990824676

Epoch: 100| Step: 0
Training loss: 2.788220275742358
Validation loss: 2.603225403688707

Epoch: 5| Step: 1
Training loss: 3.074028736335099
Validation loss: 2.6215425380403627

Epoch: 5| Step: 2
Training loss: 3.3429854044685485
Validation loss: 2.6277257583704134

Epoch: 5| Step: 3
Training loss: 2.452152229406417
Validation loss: 2.603170478196137

Epoch: 5| Step: 4
Training loss: 3.3066707639002284
Validation loss: 2.600163934365428

Epoch: 5| Step: 5
Training loss: 2.8408224945741876
Validation loss: 2.5928851288246038

Epoch: 5| Step: 6
Training loss: 2.469357862362377
Validation loss: 2.59171374466533

Epoch: 5| Step: 7
Training loss: 3.0691670618014704
Validation loss: 2.588634163891724

Epoch: 5| Step: 8
Training loss: 3.2247261936554943
Validation loss: 2.597259282422096

Epoch: 5| Step: 9
Training loss: 2.8053296557421685
Validation loss: 2.591926963943971

Epoch: 5| Step: 10
Training loss: 2.767357838329729
Validation loss: 2.5963957381864047

Epoch: 101| Step: 0
Training loss: 2.649867569115502
Validation loss: 2.6052975259570705

Epoch: 5| Step: 1
Training loss: 2.4626401793572317
Validation loss: 2.627219669475872

Epoch: 5| Step: 2
Training loss: 2.669063583639997
Validation loss: 2.6550595621739723

Epoch: 5| Step: 3
Training loss: 3.4463932478850094
Validation loss: 2.6933971036732425

Epoch: 5| Step: 4
Training loss: 3.0816880725249876
Validation loss: 2.6851369719403864

Epoch: 5| Step: 5
Training loss: 2.7823145682762114
Validation loss: 2.6545536074924816

Epoch: 5| Step: 6
Training loss: 2.8382431199914344
Validation loss: 2.6195513924303646

Epoch: 5| Step: 7
Training loss: 3.3569623933423713
Validation loss: 2.598853620097875

Epoch: 5| Step: 8
Training loss: 2.6090102254857976
Validation loss: 2.5963365141949324

Epoch: 5| Step: 9
Training loss: 2.8638277664182263
Validation loss: 2.588385462476236

Epoch: 5| Step: 10
Training loss: 3.4391565666176747
Validation loss: 2.585668209964686

Epoch: 102| Step: 0
Training loss: 2.991550148596032
Validation loss: 2.5897155422131304

Epoch: 5| Step: 1
Training loss: 2.7050503615734556
Validation loss: 2.5884858723317103

Epoch: 5| Step: 2
Training loss: 3.0370991697477256
Validation loss: 2.588901439229783

Epoch: 5| Step: 3
Training loss: 2.942666724706988
Validation loss: 2.582847991892658

Epoch: 5| Step: 4
Training loss: 3.069997368479045
Validation loss: 2.5858924286052245

Epoch: 5| Step: 5
Training loss: 2.618198848437784
Validation loss: 2.586777451055968

Epoch: 5| Step: 6
Training loss: 3.423477424726546
Validation loss: 2.589659762939864

Epoch: 5| Step: 7
Training loss: 2.8064193266693542
Validation loss: 2.5995522794341768

Epoch: 5| Step: 8
Training loss: 2.800520923385822
Validation loss: 2.6010278370829156

Epoch: 5| Step: 9
Training loss: 3.23180401477896
Validation loss: 2.611721546591634

Epoch: 5| Step: 10
Training loss: 2.3861944493681384
Validation loss: 2.620077503426019

Epoch: 103| Step: 0
Training loss: 2.937139448399286
Validation loss: 2.6349131109452664

Epoch: 5| Step: 1
Training loss: 2.7492302771042354
Validation loss: 2.610751435412213

Epoch: 5| Step: 2
Training loss: 3.0762579043029894
Validation loss: 2.606042191646701

Epoch: 5| Step: 3
Training loss: 2.7837419811419344
Validation loss: 2.588713894341214

Epoch: 5| Step: 4
Training loss: 2.487428144634381
Validation loss: 2.5860720472654335

Epoch: 5| Step: 5
Training loss: 3.2479562936012614
Validation loss: 2.585017593697445

Epoch: 5| Step: 6
Training loss: 2.9116616675674796
Validation loss: 2.585340629704209

Epoch: 5| Step: 7
Training loss: 3.152410608123871
Validation loss: 2.582797943378538

Epoch: 5| Step: 8
Training loss: 3.033711485993522
Validation loss: 2.583202343523132

Epoch: 5| Step: 9
Training loss: 2.973209444923339
Validation loss: 2.580791388491153

Epoch: 5| Step: 10
Training loss: 2.779680645115652
Validation loss: 2.5828280998510107

Epoch: 104| Step: 0
Training loss: 2.942086717335051
Validation loss: 2.5828561487665973

Epoch: 5| Step: 1
Training loss: 2.8248975684576303
Validation loss: 2.5830441328583893

Epoch: 5| Step: 2
Training loss: 2.988191251708483
Validation loss: 2.5918173945534306

Epoch: 5| Step: 3
Training loss: 3.501197473853128
Validation loss: 2.600435040673088

Epoch: 5| Step: 4
Training loss: 3.140799142744712
Validation loss: 2.610028525065256

Epoch: 5| Step: 5
Training loss: 3.290666420178685
Validation loss: 2.602447848872636

Epoch: 5| Step: 6
Training loss: 2.7382355385527934
Validation loss: 2.6115138868264207

Epoch: 5| Step: 7
Training loss: 2.3152599875866273
Validation loss: 2.6107082791116953

Epoch: 5| Step: 8
Training loss: 2.5717954676626666
Validation loss: 2.629677955632982

Epoch: 5| Step: 9
Training loss: 2.9869148670959484
Validation loss: 2.6324908330026764

Epoch: 5| Step: 10
Training loss: 2.6128786059100433
Validation loss: 2.625870329398444

Epoch: 105| Step: 0
Training loss: 2.9241992865201847
Validation loss: 2.592526029071514

Epoch: 5| Step: 1
Training loss: 2.9782085523062807
Validation loss: 2.582235591982001

Epoch: 5| Step: 2
Training loss: 2.907676100773062
Validation loss: 2.5779569111779037

Epoch: 5| Step: 3
Training loss: 2.915456484455967
Validation loss: 2.582117598116209

Epoch: 5| Step: 4
Training loss: 2.6987329865732557
Validation loss: 2.5838583926360266

Epoch: 5| Step: 5
Training loss: 2.998275738159947
Validation loss: 2.5848369917878684

Epoch: 5| Step: 6
Training loss: 2.871210337237448
Validation loss: 2.5879276059233223

Epoch: 5| Step: 7
Training loss: 2.9812455471173505
Validation loss: 2.5873266180134533

Epoch: 5| Step: 8
Training loss: 3.1171110139034264
Validation loss: 2.5877843114368577

Epoch: 5| Step: 9
Training loss: 2.9805631410143354
Validation loss: 2.583749861254723

Epoch: 5| Step: 10
Training loss: 2.7076778988146373
Validation loss: 2.5818947346759376

Epoch: 106| Step: 0
Training loss: 3.249810726816538
Validation loss: 2.581999502547962

Epoch: 5| Step: 1
Training loss: 2.9778521289684536
Validation loss: 2.5819181617591287

Epoch: 5| Step: 2
Training loss: 2.697190224976854
Validation loss: 2.5787589428919553

Epoch: 5| Step: 3
Training loss: 3.0921074716660493
Validation loss: 2.579812925681671

Epoch: 5| Step: 4
Training loss: 3.074751191036404
Validation loss: 2.577251259668826

Epoch: 5| Step: 5
Training loss: 2.80625094135498
Validation loss: 2.5791065066776486

Epoch: 5| Step: 6
Training loss: 2.826906226131375
Validation loss: 2.580167611669704

Epoch: 5| Step: 7
Training loss: 2.579403277150418
Validation loss: 2.587482850787427

Epoch: 5| Step: 8
Training loss: 2.778788988643831
Validation loss: 2.619941049733134

Epoch: 5| Step: 9
Training loss: 2.9603567233225947
Validation loss: 2.6338766815001193

Epoch: 5| Step: 10
Training loss: 2.936947385062755
Validation loss: 2.633782975062213

Epoch: 107| Step: 0
Training loss: 2.882001561182302
Validation loss: 2.628418196495385

Epoch: 5| Step: 1
Training loss: 2.8363225165856614
Validation loss: 2.630793771291924

Epoch: 5| Step: 2
Training loss: 3.071462323709871
Validation loss: 2.6264193506926636

Epoch: 5| Step: 3
Training loss: 3.1345999700681224
Validation loss: 2.628650388986759

Epoch: 5| Step: 4
Training loss: 3.1628209068111985
Validation loss: 2.640754258206406

Epoch: 5| Step: 5
Training loss: 2.1232942579178204
Validation loss: 2.623283434387804

Epoch: 5| Step: 6
Training loss: 3.007356842007762
Validation loss: 2.6113447330127206

Epoch: 5| Step: 7
Training loss: 2.60739947248686
Validation loss: 2.605763301209415

Epoch: 5| Step: 8
Training loss: 2.543363057167412
Validation loss: 2.6052198391222667

Epoch: 5| Step: 9
Training loss: 3.017256695562866
Validation loss: 2.5800159051844793

Epoch: 5| Step: 10
Training loss: 3.4528144247971686
Validation loss: 2.5821951102898497

Epoch: 108| Step: 0
Training loss: 2.556190725072998
Validation loss: 2.5750542125735665

Epoch: 5| Step: 1
Training loss: 3.31843510227564
Validation loss: 2.5733036475780846

Epoch: 5| Step: 2
Training loss: 2.525849409095237
Validation loss: 2.5689122706970613

Epoch: 5| Step: 3
Training loss: 2.940342278829933
Validation loss: 2.5705733379009157

Epoch: 5| Step: 4
Training loss: 2.7718238111928057
Validation loss: 2.5763077353061656

Epoch: 5| Step: 5
Training loss: 3.1047085965288836
Validation loss: 2.572820633677868

Epoch: 5| Step: 6
Training loss: 2.714892489867115
Validation loss: 2.5775661137426678

Epoch: 5| Step: 7
Training loss: 2.830879345477716
Validation loss: 2.5899751495899848

Epoch: 5| Step: 8
Training loss: 2.6742924690394165
Validation loss: 2.598441538146164

Epoch: 5| Step: 9
Training loss: 3.1683087525140796
Validation loss: 2.613276377346164

Epoch: 5| Step: 10
Training loss: 3.3482067318785695
Validation loss: 2.573483793234026

Epoch: 109| Step: 0
Training loss: 2.72162441146887
Validation loss: 2.570701861121506

Epoch: 5| Step: 1
Training loss: 2.94049520175687
Validation loss: 2.5755710415047206

Epoch: 5| Step: 2
Training loss: 2.9199599247625367
Validation loss: 2.570833151137838

Epoch: 5| Step: 3
Training loss: 2.8399532249789536
Validation loss: 2.5828863720528092

Epoch: 5| Step: 4
Training loss: 2.359057575624445
Validation loss: 2.5823017095561704

Epoch: 5| Step: 5
Training loss: 2.8055256305857004
Validation loss: 2.588314981802461

Epoch: 5| Step: 6
Training loss: 3.14220089067805
Validation loss: 2.5916841406724913

Epoch: 5| Step: 7
Training loss: 2.6209542113681383
Validation loss: 2.60211547366949

Epoch: 5| Step: 8
Training loss: 3.5553723692063284
Validation loss: 2.5981080494963043

Epoch: 5| Step: 9
Training loss: 2.830637116443108
Validation loss: 2.6017672688420945

Epoch: 5| Step: 10
Training loss: 3.1760906899233334
Validation loss: 2.6002864352115793

Epoch: 110| Step: 0
Training loss: 2.986508710152688
Validation loss: 2.6015366522150924

Epoch: 5| Step: 1
Training loss: 3.3714111461604737
Validation loss: 2.5847920841936065

Epoch: 5| Step: 2
Training loss: 2.907620834765463
Validation loss: 2.595053573408827

Epoch: 5| Step: 3
Training loss: 3.0300419553363667
Validation loss: 2.5936210398633124

Epoch: 5| Step: 4
Training loss: 2.800387345497147
Validation loss: 2.5979130803862787

Epoch: 5| Step: 5
Training loss: 2.8413218097867796
Validation loss: 2.611241542107157

Epoch: 5| Step: 6
Training loss: 2.6476814743826
Validation loss: 2.6194065981772243

Epoch: 5| Step: 7
Training loss: 2.7268996590428993
Validation loss: 2.6439174265023535

Epoch: 5| Step: 8
Training loss: 2.8814389644726894
Validation loss: 2.6400329058067165

Epoch: 5| Step: 9
Training loss: 3.1241365384243007
Validation loss: 2.6324049822097435

Epoch: 5| Step: 10
Training loss: 2.6277271817878542
Validation loss: 2.6143507361083986

Epoch: 111| Step: 0
Training loss: 3.469692755077347
Validation loss: 2.6107077930358504

Epoch: 5| Step: 1
Training loss: 2.7728528763225913
Validation loss: 2.610961336565976

Epoch: 5| Step: 2
Training loss: 2.550237296787885
Validation loss: 2.603978045780047

Epoch: 5| Step: 3
Training loss: 3.0735458161001916
Validation loss: 2.6114543744654526

Epoch: 5| Step: 4
Training loss: 2.743508219221876
Validation loss: 2.6035230711710837

Epoch: 5| Step: 5
Training loss: 3.3189298017111666
Validation loss: 2.6045087140958225

Epoch: 5| Step: 6
Training loss: 3.4166153849653225
Validation loss: 2.6045400336266358

Epoch: 5| Step: 7
Training loss: 3.1264161525106027
Validation loss: 2.6100259722558876

Epoch: 5| Step: 8
Training loss: 2.6232622843536264
Validation loss: 2.5903747813005538

Epoch: 5| Step: 9
Training loss: 1.8342050372900491
Validation loss: 2.5902703937490994

Epoch: 5| Step: 10
Training loss: 2.6881124109196466
Validation loss: 2.594309086692822

Epoch: 112| Step: 0
Training loss: 2.7696643361557634
Validation loss: 2.5975921605682455

Epoch: 5| Step: 1
Training loss: 2.6785666565625506
Validation loss: 2.6011502844311427

Epoch: 5| Step: 2
Training loss: 3.181275966815607
Validation loss: 2.5991621329443224

Epoch: 5| Step: 3
Training loss: 2.311609973262693
Validation loss: 2.598510307691142

Epoch: 5| Step: 4
Training loss: 3.082262076471863
Validation loss: 2.6081084381065445

Epoch: 5| Step: 5
Training loss: 3.199959432821626
Validation loss: 2.5996503808462514

Epoch: 5| Step: 6
Training loss: 2.537291769118594
Validation loss: 2.5976060713039457

Epoch: 5| Step: 7
Training loss: 3.101976650462516
Validation loss: 2.5959161054862117

Epoch: 5| Step: 8
Training loss: 2.9451085027580186
Validation loss: 2.5851195128173146

Epoch: 5| Step: 9
Training loss: 3.036223274323779
Validation loss: 2.5913340345551994

Epoch: 5| Step: 10
Training loss: 2.957285377537856
Validation loss: 2.583866690185254

Epoch: 113| Step: 0
Training loss: 3.243067904513961
Validation loss: 2.5861198019752103

Epoch: 5| Step: 1
Training loss: 2.8645772668022884
Validation loss: 2.595174890015255

Epoch: 5| Step: 2
Training loss: 3.3743932673127106
Validation loss: 2.5848051989560403

Epoch: 5| Step: 3
Training loss: 2.3484868311570675
Validation loss: 2.588534838315717

Epoch: 5| Step: 4
Training loss: 3.125128476362918
Validation loss: 2.5908291864036572

Epoch: 5| Step: 5
Training loss: 2.9598715280025707
Validation loss: 2.581790037025249

Epoch: 5| Step: 6
Training loss: 2.754579545630434
Validation loss: 2.578404608983534

Epoch: 5| Step: 7
Training loss: 2.0611344643178375
Validation loss: 2.573744534850839

Epoch: 5| Step: 8
Training loss: 2.9316679504056298
Validation loss: 2.5741571733386013

Epoch: 5| Step: 9
Training loss: 3.1848904268349365
Validation loss: 2.5682673527282973

Epoch: 5| Step: 10
Training loss: 2.7008452752435974
Validation loss: 2.564791725327262

Epoch: 114| Step: 0
Training loss: 2.7000719590664546
Validation loss: 2.5572986793576464

Epoch: 5| Step: 1
Training loss: 3.109399229942497
Validation loss: 2.5570584277636073

Epoch: 5| Step: 2
Training loss: 2.2535345078376627
Validation loss: 2.5563387228810157

Epoch: 5| Step: 3
Training loss: 3.1986752748276817
Validation loss: 2.5535611369037152

Epoch: 5| Step: 4
Training loss: 2.849397856697438
Validation loss: 2.5529233590116225

Epoch: 5| Step: 5
Training loss: 2.7460131789389233
Validation loss: 2.555681819688645

Epoch: 5| Step: 6
Training loss: 2.78354215999721
Validation loss: 2.5550479595103703

Epoch: 5| Step: 7
Training loss: 3.3362682455513695
Validation loss: 2.5597841400791714

Epoch: 5| Step: 8
Training loss: 3.0178892499903833
Validation loss: 2.57139721954018

Epoch: 5| Step: 9
Training loss: 2.6204028974395652
Validation loss: 2.580445133553056

Epoch: 5| Step: 10
Training loss: 3.104265932548381
Validation loss: 2.587944066925114

Epoch: 115| Step: 0
Training loss: 3.007327667397864
Validation loss: 2.621923769277862

Epoch: 5| Step: 1
Training loss: 3.323683232744724
Validation loss: 2.639469551927026

Epoch: 5| Step: 2
Training loss: 3.171556278244833
Validation loss: 2.5991449963299234

Epoch: 5| Step: 3
Training loss: 3.1270937200005684
Validation loss: 2.563875317008696

Epoch: 5| Step: 4
Training loss: 2.211900049969412
Validation loss: 2.5501678296555914

Epoch: 5| Step: 5
Training loss: 2.6328721761307565
Validation loss: 2.5545720421807365

Epoch: 5| Step: 6
Training loss: 2.296504814782422
Validation loss: 2.5657009628361833

Epoch: 5| Step: 7
Training loss: 2.893628843337653
Validation loss: 2.5760676752175926

Epoch: 5| Step: 8
Training loss: 3.1991582359394326
Validation loss: 2.5666748791331395

Epoch: 5| Step: 9
Training loss: 3.0351122603794196
Validation loss: 2.5630133270008986

Epoch: 5| Step: 10
Training loss: 3.055589781675445
Validation loss: 2.552930014827561

Epoch: 116| Step: 0
Training loss: 3.081480414575137
Validation loss: 2.553948920227773

Epoch: 5| Step: 1
Training loss: 3.2101461730189853
Validation loss: 2.5561546479795267

Epoch: 5| Step: 2
Training loss: 2.431131994526581
Validation loss: 2.569942525161359

Epoch: 5| Step: 3
Training loss: 2.26586376115974
Validation loss: 2.5929654700802676

Epoch: 5| Step: 4
Training loss: 2.9446418464114945
Validation loss: 2.6184404827017254

Epoch: 5| Step: 5
Training loss: 2.7387041970640262
Validation loss: 2.5929811971342485

Epoch: 5| Step: 6
Training loss: 3.4342613916462947
Validation loss: 2.584778701572678

Epoch: 5| Step: 7
Training loss: 2.6130854557515066
Validation loss: 2.55848886236835

Epoch: 5| Step: 8
Training loss: 2.9133882535155964
Validation loss: 2.5522332420964022

Epoch: 5| Step: 9
Training loss: 3.448499386382909
Validation loss: 2.549765098532986

Epoch: 5| Step: 10
Training loss: 2.5552192157980675
Validation loss: 2.548638219708668

Epoch: 117| Step: 0
Training loss: 2.610435407428696
Validation loss: 2.549599826179828

Epoch: 5| Step: 1
Training loss: 2.9860220154080355
Validation loss: 2.548358625276565

Epoch: 5| Step: 2
Training loss: 2.8085813561857105
Validation loss: 2.547551964817297

Epoch: 5| Step: 3
Training loss: 2.7789178564361747
Validation loss: 2.543679896687739

Epoch: 5| Step: 4
Training loss: 2.771245299573189
Validation loss: 2.5528292920397107

Epoch: 5| Step: 5
Training loss: 2.8809752360176364
Validation loss: 2.553357607605808

Epoch: 5| Step: 6
Training loss: 3.0155410359607093
Validation loss: 2.561853364742431

Epoch: 5| Step: 7
Training loss: 3.049528560786765
Validation loss: 2.5702202474270983

Epoch: 5| Step: 8
Training loss: 3.1187172866970903
Validation loss: 2.5789059845407065

Epoch: 5| Step: 9
Training loss: 2.98567211462917
Validation loss: 2.5913516779044703

Epoch: 5| Step: 10
Training loss: 2.708141721158378
Validation loss: 2.5791836044049843

Epoch: 118| Step: 0
Training loss: 2.629438734612775
Validation loss: 2.58361994006588

Epoch: 5| Step: 1
Training loss: 3.123543972320781
Validation loss: 2.574419211018728

Epoch: 5| Step: 2
Training loss: 2.747174111529893
Validation loss: 2.5591078019453035

Epoch: 5| Step: 3
Training loss: 3.2420764582358887
Validation loss: 2.552039546896472

Epoch: 5| Step: 4
Training loss: 2.9652485326138276
Validation loss: 2.54497510914342

Epoch: 5| Step: 5
Training loss: 2.8982780803424735
Validation loss: 2.540851789863437

Epoch: 5| Step: 6
Training loss: 3.2130258270849827
Validation loss: 2.546382482737117

Epoch: 5| Step: 7
Training loss: 2.742487964308139
Validation loss: 2.546692759711924

Epoch: 5| Step: 8
Training loss: 2.6261582317051806
Validation loss: 2.5454440762363206

Epoch: 5| Step: 9
Training loss: 2.4757670861053014
Validation loss: 2.544705564454254

Epoch: 5| Step: 10
Training loss: 3.225986530907284
Validation loss: 2.55839165418032

Epoch: 119| Step: 0
Training loss: 2.9269140518127994
Validation loss: 2.5648597868637535

Epoch: 5| Step: 1
Training loss: 2.790585313196547
Validation loss: 2.584414776425295

Epoch: 5| Step: 2
Training loss: 2.6711821968495277
Validation loss: 2.583931047624109

Epoch: 5| Step: 3
Training loss: 3.2374908623879404
Validation loss: 2.588614665907953

Epoch: 5| Step: 4
Training loss: 2.701582098956525
Validation loss: 2.5721053013720003

Epoch: 5| Step: 5
Training loss: 3.0517923435546384
Validation loss: 2.5667111649296284

Epoch: 5| Step: 6
Training loss: 2.6951024954985803
Validation loss: 2.568243078422303

Epoch: 5| Step: 7
Training loss: 3.092141706330945
Validation loss: 2.5596313747220156

Epoch: 5| Step: 8
Training loss: 2.719986732955441
Validation loss: 2.5626136620517586

Epoch: 5| Step: 9
Training loss: 3.1405401265836628
Validation loss: 2.5630364725600034

Epoch: 5| Step: 10
Training loss: 2.592523951479593
Validation loss: 2.55996340447977

Epoch: 120| Step: 0
Training loss: 3.0259838175318854
Validation loss: 2.554465599441639

Epoch: 5| Step: 1
Training loss: 2.4951148942014902
Validation loss: 2.563343889075846

Epoch: 5| Step: 2
Training loss: 2.4140418585725034
Validation loss: 2.562175138877206

Epoch: 5| Step: 3
Training loss: 2.5704816861111484
Validation loss: 2.5452790596481036

Epoch: 5| Step: 4
Training loss: 2.806880677853883
Validation loss: 2.5516983893770537

Epoch: 5| Step: 5
Training loss: 2.804733488508104
Validation loss: 2.5478239201056683

Epoch: 5| Step: 6
Training loss: 3.2756893451661675
Validation loss: 2.5456643316335845

Epoch: 5| Step: 7
Training loss: 3.1159474289245925
Validation loss: 2.531319853622577

Epoch: 5| Step: 8
Training loss: 3.2353929769742193
Validation loss: 2.547237393357624

Epoch: 5| Step: 9
Training loss: 2.7969045797307595
Validation loss: 2.548422865410854

Epoch: 5| Step: 10
Training loss: 3.0228068953357337
Validation loss: 2.5491090025009853

Epoch: 121| Step: 0
Training loss: 2.902248622315956
Validation loss: 2.5549325651405237

Epoch: 5| Step: 1
Training loss: 2.8475440569677004
Validation loss: 2.568281911412249

Epoch: 5| Step: 2
Training loss: 2.8810037040117282
Validation loss: 2.5761437682335973

Epoch: 5| Step: 3
Training loss: 2.5278023682493944
Validation loss: 2.5852375947751676

Epoch: 5| Step: 4
Training loss: 3.1657949720205516
Validation loss: 2.5917063802981475

Epoch: 5| Step: 5
Training loss: 2.7799441240033165
Validation loss: 2.5740641133990065

Epoch: 5| Step: 6
Training loss: 1.8359494472683078
Validation loss: 2.569793294653399

Epoch: 5| Step: 7
Training loss: 2.496947618557617
Validation loss: 2.5649619612381596

Epoch: 5| Step: 8
Training loss: 3.437649255459965
Validation loss: 2.558495742184478

Epoch: 5| Step: 9
Training loss: 3.3653188242088174
Validation loss: 2.553517716820721

Epoch: 5| Step: 10
Training loss: 3.066254630258317
Validation loss: 2.556519925589402

Epoch: 122| Step: 0
Training loss: 3.027550868670936
Validation loss: 2.561300666844555

Epoch: 5| Step: 1
Training loss: 2.926498752924166
Validation loss: 2.564596269637111

Epoch: 5| Step: 2
Training loss: 2.88525865767135
Validation loss: 2.549257261599618

Epoch: 5| Step: 3
Training loss: 2.911011599602451
Validation loss: 2.553387346719981

Epoch: 5| Step: 4
Training loss: 3.044039145018712
Validation loss: 2.5422943270879386

Epoch: 5| Step: 5
Training loss: 2.642122825764961
Validation loss: 2.5361422780477008

Epoch: 5| Step: 6
Training loss: 2.5105144645245354
Validation loss: 2.539739737357039

Epoch: 5| Step: 7
Training loss: 2.7262912385769615
Validation loss: 2.5375569963805384

Epoch: 5| Step: 8
Training loss: 3.009392023880165
Validation loss: 2.544939354569796

Epoch: 5| Step: 9
Training loss: 2.745991820265554
Validation loss: 2.5507131273875183

Epoch: 5| Step: 10
Training loss: 3.1747946244745933
Validation loss: 2.5526296202111083

Epoch: 123| Step: 0
Training loss: 2.337979855981723
Validation loss: 2.5583146373336465

Epoch: 5| Step: 1
Training loss: 2.1367220974465324
Validation loss: 2.55948409065461

Epoch: 5| Step: 2
Training loss: 3.211066992902851
Validation loss: 2.548051306914006

Epoch: 5| Step: 3
Training loss: 3.2693512751951443
Validation loss: 2.551921446242389

Epoch: 5| Step: 4
Training loss: 3.318056736033915
Validation loss: 2.5638835202446284

Epoch: 5| Step: 5
Training loss: 2.7887378151019138
Validation loss: 2.5484040737949556

Epoch: 5| Step: 6
Training loss: 2.797164987203509
Validation loss: 2.549999495475473

Epoch: 5| Step: 7
Training loss: 2.37615908397146
Validation loss: 2.5595771944172654

Epoch: 5| Step: 8
Training loss: 2.775425416109567
Validation loss: 2.54930608204316

Epoch: 5| Step: 9
Training loss: 3.254472589379418
Validation loss: 2.5592142143871537

Epoch: 5| Step: 10
Training loss: 3.038178695395689
Validation loss: 2.551178889747982

Epoch: 124| Step: 0
Training loss: 2.3816893885573944
Validation loss: 2.550780122343354

Epoch: 5| Step: 1
Training loss: 2.9971032462450045
Validation loss: 2.564942075410386

Epoch: 5| Step: 2
Training loss: 3.155250013211952
Validation loss: 2.569753036954555

Epoch: 5| Step: 3
Training loss: 3.3138114204599955
Validation loss: 2.5900538172839647

Epoch: 5| Step: 4
Training loss: 2.982344490851011
Validation loss: 2.5903556982315044

Epoch: 5| Step: 5
Training loss: 2.5225873997408006
Validation loss: 2.5714688956739624

Epoch: 5| Step: 6
Training loss: 2.449207360638142
Validation loss: 2.5591131188407186

Epoch: 5| Step: 7
Training loss: 2.8805622529512256
Validation loss: 2.546253162908258

Epoch: 5| Step: 8
Training loss: 2.631509792523481
Validation loss: 2.5436850961660773

Epoch: 5| Step: 9
Training loss: 3.2797442659842164
Validation loss: 2.5363946445832273

Epoch: 5| Step: 10
Training loss: 2.77896693101489
Validation loss: 2.5355786828098577

Epoch: 125| Step: 0
Training loss: 2.225276535508534
Validation loss: 2.533789996616884

Epoch: 5| Step: 1
Training loss: 2.315912152193966
Validation loss: 2.537363809531236

Epoch: 5| Step: 2
Training loss: 2.4785470802709946
Validation loss: 2.54288270876366

Epoch: 5| Step: 3
Training loss: 3.3238935479609255
Validation loss: 2.5436351791227128

Epoch: 5| Step: 4
Training loss: 2.7546396131242576
Validation loss: 2.553958759405411

Epoch: 5| Step: 5
Training loss: 2.533177336691693
Validation loss: 2.562510655718883

Epoch: 5| Step: 6
Training loss: 2.646898030402684
Validation loss: 2.566812303798327

Epoch: 5| Step: 7
Training loss: 3.2290717982641275
Validation loss: 2.594232813997102

Epoch: 5| Step: 8
Training loss: 3.404290291740981
Validation loss: 2.587171831444334

Epoch: 5| Step: 9
Training loss: 3.1209091876750987
Validation loss: 2.5749400921089216

Epoch: 5| Step: 10
Training loss: 3.251533439979314
Validation loss: 2.5615314320899145

Epoch: 126| Step: 0
Training loss: 3.0059999231070726
Validation loss: 2.5473257572236294

Epoch: 5| Step: 1
Training loss: 3.1200934992743194
Validation loss: 2.5383221805155585

Epoch: 5| Step: 2
Training loss: 2.9095848392979975
Validation loss: 2.5340188643011214

Epoch: 5| Step: 3
Training loss: 2.8404424526869696
Validation loss: 2.5286947539879723

Epoch: 5| Step: 4
Training loss: 2.8476718227133353
Validation loss: 2.536218125487465

Epoch: 5| Step: 5
Training loss: 2.89888527591133
Validation loss: 2.528730472632469

Epoch: 5| Step: 6
Training loss: 2.9660307627733355
Validation loss: 2.5364570409633314

Epoch: 5| Step: 7
Training loss: 2.4499115519225696
Validation loss: 2.5439414135430645

Epoch: 5| Step: 8
Training loss: 3.1892145071103766
Validation loss: 2.5382587563554835

Epoch: 5| Step: 9
Training loss: 2.953213483504095
Validation loss: 2.5489835080821086

Epoch: 5| Step: 10
Training loss: 1.9897911469209195
Validation loss: 2.554886889584758

Epoch: 127| Step: 0
Training loss: 3.0206432589660452
Validation loss: 2.5689375835211274

Epoch: 5| Step: 1
Training loss: 2.6760583441721844
Validation loss: 2.5487825281394954

Epoch: 5| Step: 2
Training loss: 3.1698901350555913
Validation loss: 2.5514060338227345

Epoch: 5| Step: 3
Training loss: 2.624543922404169
Validation loss: 2.5423110674226894

Epoch: 5| Step: 4
Training loss: 2.9334191728805554
Validation loss: 2.5314655321069517

Epoch: 5| Step: 5
Training loss: 2.966601909687912
Validation loss: 2.532764295318797

Epoch: 5| Step: 6
Training loss: 2.5717576437000607
Validation loss: 2.529208585207241

Epoch: 5| Step: 7
Training loss: 2.6342229036746105
Validation loss: 2.527204239974201

Epoch: 5| Step: 8
Training loss: 2.786055966616804
Validation loss: 2.560397863845099

Epoch: 5| Step: 9
Training loss: 3.2707568279155144
Validation loss: 2.5510819336150057

Epoch: 5| Step: 10
Training loss: 2.731090120223332
Validation loss: 2.547233256887425

Epoch: 128| Step: 0
Training loss: 2.761207371352888
Validation loss: 2.551880821713304

Epoch: 5| Step: 1
Training loss: 2.635168543859599
Validation loss: 2.560749544567332

Epoch: 5| Step: 2
Training loss: 3.0106739255458925
Validation loss: 2.5505181015247853

Epoch: 5| Step: 3
Training loss: 2.662506275438247
Validation loss: 2.5572121398147485

Epoch: 5| Step: 4
Training loss: 3.0400734129624523
Validation loss: 2.5580384045742792

Epoch: 5| Step: 5
Training loss: 2.634063151987755
Validation loss: 2.578383410974953

Epoch: 5| Step: 6
Training loss: 2.886118246964498
Validation loss: 2.5844256254883153

Epoch: 5| Step: 7
Training loss: 2.8589644006979182
Validation loss: 2.609073964679986

Epoch: 5| Step: 8
Training loss: 2.881515252404767
Validation loss: 2.593475166128344

Epoch: 5| Step: 9
Training loss: 2.8105398341044974
Validation loss: 2.5677418332938036

Epoch: 5| Step: 10
Training loss: 3.184322194268988
Validation loss: 2.5702141939562506

Epoch: 129| Step: 0
Training loss: 2.9967439783948677
Validation loss: 2.547502025928811

Epoch: 5| Step: 1
Training loss: 2.8849738891054653
Validation loss: 2.550037129449739

Epoch: 5| Step: 2
Training loss: 2.8559271031006896
Validation loss: 2.5461962764540558

Epoch: 5| Step: 3
Training loss: 3.01427370145208
Validation loss: 2.5503921205693167

Epoch: 5| Step: 4
Training loss: 2.812614438589757
Validation loss: 2.5759880698621465

Epoch: 5| Step: 5
Training loss: 2.8866971109325124
Validation loss: 2.5817057146026277

Epoch: 5| Step: 6
Training loss: 2.6749307213484372
Validation loss: 2.597524075349417

Epoch: 5| Step: 7
Training loss: 2.6284122994928873
Validation loss: 2.5532394238343357

Epoch: 5| Step: 8
Training loss: 2.747909011039645
Validation loss: 2.5218903059517235

Epoch: 5| Step: 9
Training loss: 3.079853637487458
Validation loss: 2.5228861199368056

Epoch: 5| Step: 10
Training loss: 2.854723706613492
Validation loss: 2.524819141661718

Epoch: 130| Step: 0
Training loss: 3.1512583928675486
Validation loss: 2.5299659357530215

Epoch: 5| Step: 1
Training loss: 2.8041020794516136
Validation loss: 2.528116474030506

Epoch: 5| Step: 2
Training loss: 3.140627884744866
Validation loss: 2.51889877578173

Epoch: 5| Step: 3
Training loss: 3.168008787605351
Validation loss: 2.5175356901965444

Epoch: 5| Step: 4
Training loss: 2.622552911826488
Validation loss: 2.516703356246081

Epoch: 5| Step: 5
Training loss: 2.6363984542149934
Validation loss: 2.52840467135846

Epoch: 5| Step: 6
Training loss: 3.064584917646803
Validation loss: 2.544217627110455

Epoch: 5| Step: 7
Training loss: 2.415692911513551
Validation loss: 2.563759277005059

Epoch: 5| Step: 8
Training loss: 2.577159168933701
Validation loss: 2.5590648491396046

Epoch: 5| Step: 9
Training loss: 2.9599279126848708
Validation loss: 2.5504907182112877

Epoch: 5| Step: 10
Training loss: 3.045344667768792
Validation loss: 2.577826664214368

Epoch: 131| Step: 0
Training loss: 3.041500417964868
Validation loss: 2.545799797947207

Epoch: 5| Step: 1
Training loss: 2.7997046280788416
Validation loss: 2.5593531394931515

Epoch: 5| Step: 2
Training loss: 2.5997888516005476
Validation loss: 2.5518408741564804

Epoch: 5| Step: 3
Training loss: 2.7568692331333766
Validation loss: 2.5397328148085667

Epoch: 5| Step: 4
Training loss: 2.826676898958772
Validation loss: 2.531198978859365

Epoch: 5| Step: 5
Training loss: 2.7193993856169145
Validation loss: 2.5415518679448357

Epoch: 5| Step: 6
Training loss: 2.6463347332866576
Validation loss: 2.5248027849175503

Epoch: 5| Step: 7
Training loss: 3.2653918023327155
Validation loss: 2.533591711142976

Epoch: 5| Step: 8
Training loss: 3.0288743610489246
Validation loss: 2.5360268897625002

Epoch: 5| Step: 9
Training loss: 2.4790350187166452
Validation loss: 2.54463936968454

Epoch: 5| Step: 10
Training loss: 3.1494488854663967
Validation loss: 2.5464631525282524

Epoch: 132| Step: 0
Training loss: 3.35874741480692
Validation loss: 2.540407930865267

Epoch: 5| Step: 1
Training loss: 2.94477349567958
Validation loss: 2.567713595312148

Epoch: 5| Step: 2
Training loss: 2.833762940392818
Validation loss: 2.5759903737646708

Epoch: 5| Step: 3
Training loss: 2.6761266777777757
Validation loss: 2.636564090982951

Epoch: 5| Step: 4
Training loss: 2.7399995340221595
Validation loss: 2.636178964093965

Epoch: 5| Step: 5
Training loss: 3.364702834771713
Validation loss: 2.5738552301851274

Epoch: 5| Step: 6
Training loss: 3.177808501651562
Validation loss: 2.5514386633346784

Epoch: 5| Step: 7
Training loss: 3.160371563228535
Validation loss: 2.541396540410608

Epoch: 5| Step: 8
Training loss: 2.5058001944614396
Validation loss: 2.538106081216

Epoch: 5| Step: 9
Training loss: 2.3046148773648043
Validation loss: 2.5346064796005914

Epoch: 5| Step: 10
Training loss: 2.117795174302527
Validation loss: 2.541199201553482

Epoch: 133| Step: 0
Training loss: 2.995925998094674
Validation loss: 2.5323295838219764

Epoch: 5| Step: 1
Training loss: 2.5978227375571725
Validation loss: 2.5325802642539097

Epoch: 5| Step: 2
Training loss: 2.836790518770763
Validation loss: 2.52476256884915

Epoch: 5| Step: 3
Training loss: 2.8337047183907984
Validation loss: 2.5302674683006257

Epoch: 5| Step: 4
Training loss: 2.773032575248822
Validation loss: 2.5259115666203273

Epoch: 5| Step: 5
Training loss: 2.567647091107471
Validation loss: 2.545697923963647

Epoch: 5| Step: 6
Training loss: 2.5901477111760345
Validation loss: 2.559906424115127

Epoch: 5| Step: 7
Training loss: 2.693244915052256
Validation loss: 2.5813828156237255

Epoch: 5| Step: 8
Training loss: 2.8987464431668495
Validation loss: 2.599857270951135

Epoch: 5| Step: 9
Training loss: 3.0251326035368984
Validation loss: 2.584492685911685

Epoch: 5| Step: 10
Training loss: 3.437391106007814
Validation loss: 2.587032134887746

Epoch: 134| Step: 0
Training loss: 2.603288690702803
Validation loss: 2.6146477753151594

Epoch: 5| Step: 1
Training loss: 2.3633388543793075
Validation loss: 2.5999804419514714

Epoch: 5| Step: 2
Training loss: 3.09546559863599
Validation loss: 2.5957215820975788

Epoch: 5| Step: 3
Training loss: 2.236678636559617
Validation loss: 2.564595070083981

Epoch: 5| Step: 4
Training loss: 3.658642890595271
Validation loss: 2.5354543801629714

Epoch: 5| Step: 5
Training loss: 2.792043081688985
Validation loss: 2.554832891635976

Epoch: 5| Step: 6
Training loss: 2.9009419851567384
Validation loss: 2.5475759220540786

Epoch: 5| Step: 7
Training loss: 3.337771195383886
Validation loss: 2.5686242687406247

Epoch: 5| Step: 8
Training loss: 2.573453520288961
Validation loss: 2.5828040169851265

Epoch: 5| Step: 9
Training loss: 2.7312666309819296
Validation loss: 2.6065678790962052

Epoch: 5| Step: 10
Training loss: 2.482537987947573
Validation loss: 2.617174424083837

Epoch: 135| Step: 0
Training loss: 2.322756934269232
Validation loss: 2.6109872334207056

Epoch: 5| Step: 1
Training loss: 3.153976679278497
Validation loss: 2.612311335300179

Epoch: 5| Step: 2
Training loss: 2.8878308787822466
Validation loss: 2.5557218155436834

Epoch: 5| Step: 3
Training loss: 3.0529941245758767
Validation loss: 2.523597028774364

Epoch: 5| Step: 4
Training loss: 2.7435340292356454
Validation loss: 2.522783209897536

Epoch: 5| Step: 5
Training loss: 3.117796568296941
Validation loss: 2.5262269212953807

Epoch: 5| Step: 6
Training loss: 1.960487587673255
Validation loss: 2.50996780688791

Epoch: 5| Step: 7
Training loss: 2.9392508300925435
Validation loss: 2.5274835961748385

Epoch: 5| Step: 8
Training loss: 2.8967869421158152
Validation loss: 2.532777655695592

Epoch: 5| Step: 9
Training loss: 2.77228438355043
Validation loss: 2.5499065200670605

Epoch: 5| Step: 10
Training loss: 3.1660068895430076
Validation loss: 2.5746099061673036

Epoch: 136| Step: 0
Training loss: 2.8695928062776312
Validation loss: 2.5693833906404415

Epoch: 5| Step: 1
Training loss: 3.024138613294204
Validation loss: 2.560518615741427

Epoch: 5| Step: 2
Training loss: 2.6787392409300383
Validation loss: 2.560906475739901

Epoch: 5| Step: 3
Training loss: 3.3516538380801473
Validation loss: 2.5513883523796475

Epoch: 5| Step: 4
Training loss: 2.558562719724764
Validation loss: 2.5237908346618916

Epoch: 5| Step: 5
Training loss: 2.5600240888058288
Validation loss: 2.527537639825286

Epoch: 5| Step: 6
Training loss: 2.865799320954948
Validation loss: 2.519168162084431

Epoch: 5| Step: 7
Training loss: 3.097533869400385
Validation loss: 2.521251519369216

Epoch: 5| Step: 8
Training loss: 2.2043456896051956
Validation loss: 2.526361830609153

Epoch: 5| Step: 9
Training loss: 2.8165963752899326
Validation loss: 2.5227891322772424

Epoch: 5| Step: 10
Training loss: 2.8371984447608902
Validation loss: 2.5445193956502314

Epoch: 137| Step: 0
Training loss: 2.228385313003667
Validation loss: 2.5696875622276227

Epoch: 5| Step: 1
Training loss: 3.1858148047004606
Validation loss: 2.5700444306339967

Epoch: 5| Step: 2
Training loss: 3.1121663355172324
Validation loss: 2.5613482548389217

Epoch: 5| Step: 3
Training loss: 2.723612591383568
Validation loss: 2.5755751563521665

Epoch: 5| Step: 4
Training loss: 3.1274782653590045
Validation loss: 2.5930644825892837

Epoch: 5| Step: 5
Training loss: 2.6667268468106156
Validation loss: 2.5847358049109714

Epoch: 5| Step: 6
Training loss: 2.384712837253599
Validation loss: 2.5753143850585234

Epoch: 5| Step: 7
Training loss: 2.7018712835310597
Validation loss: 2.5693644360301766

Epoch: 5| Step: 8
Training loss: 2.6757696666606035
Validation loss: 2.54630177313832

Epoch: 5| Step: 9
Training loss: 3.1200803560521733
Validation loss: 2.52625249336607

Epoch: 5| Step: 10
Training loss: 2.879077673354184
Validation loss: 2.539779297875698

Epoch: 138| Step: 0
Training loss: 3.205944327791415
Validation loss: 2.5249267966324753

Epoch: 5| Step: 1
Training loss: 2.9192658060503005
Validation loss: 2.5360505767932158

Epoch: 5| Step: 2
Training loss: 2.5138449679683386
Validation loss: 2.544262877543685

Epoch: 5| Step: 3
Training loss: 2.7443662503163173
Validation loss: 2.5540304827734386

Epoch: 5| Step: 4
Training loss: 3.000814645149863
Validation loss: 2.553050161974293

Epoch: 5| Step: 5
Training loss: 2.9161837223401075
Validation loss: 2.542830011529904

Epoch: 5| Step: 6
Training loss: 2.63504431786809
Validation loss: 2.5257675937302833

Epoch: 5| Step: 7
Training loss: 2.772390592461309
Validation loss: 2.5551972144303656

Epoch: 5| Step: 8
Training loss: 2.827510113550476
Validation loss: 2.5603071565038684

Epoch: 5| Step: 9
Training loss: 2.5667911978232
Validation loss: 2.625013366055776

Epoch: 5| Step: 10
Training loss: 2.8224051787512705
Validation loss: 2.566992167965538

Epoch: 139| Step: 0
Training loss: 2.753173384311644
Validation loss: 2.5144547527912393

Epoch: 5| Step: 1
Training loss: 2.6192947330978673
Validation loss: 2.5123641379232393

Epoch: 5| Step: 2
Training loss: 2.5771561160303857
Validation loss: 2.5217317890134647

Epoch: 5| Step: 3
Training loss: 2.870493632806714
Validation loss: 2.514691730480626

Epoch: 5| Step: 4
Training loss: 3.0037049621685314
Validation loss: 2.5108301244935847

Epoch: 5| Step: 5
Training loss: 2.719497490212793
Validation loss: 2.509529068849092

Epoch: 5| Step: 6
Training loss: 3.1200568203765022
Validation loss: 2.51182642551069

Epoch: 5| Step: 7
Training loss: 2.8637441804744315
Validation loss: 2.5288837452274064

Epoch: 5| Step: 8
Training loss: 2.476714794398121
Validation loss: 2.5429649211230374

Epoch: 5| Step: 9
Training loss: 2.919893459832475
Validation loss: 2.559011559470175

Epoch: 5| Step: 10
Training loss: 2.787021092899303
Validation loss: 2.622716801416952

Epoch: 140| Step: 0
Training loss: 3.0663070371091665
Validation loss: 2.6434041118369853

Epoch: 5| Step: 1
Training loss: 3.568693833318341
Validation loss: 2.6089822602433466

Epoch: 5| Step: 2
Training loss: 2.4588852817727096
Validation loss: 2.5455897707266195

Epoch: 5| Step: 3
Training loss: 2.7650626952528943
Validation loss: 2.516441160335802

Epoch: 5| Step: 4
Training loss: 2.2806662243676596
Validation loss: 2.5175435586928323

Epoch: 5| Step: 5
Training loss: 3.2689311982036067
Validation loss: 2.513173704594627

Epoch: 5| Step: 6
Training loss: 2.81374975623897
Validation loss: 2.510125108352987

Epoch: 5| Step: 7
Training loss: 2.722027086110557
Validation loss: 2.5229856878467807

Epoch: 5| Step: 8
Training loss: 2.610625372903298
Validation loss: 2.515854163875916

Epoch: 5| Step: 9
Training loss: 2.6878527032821227
Validation loss: 2.5301582537320897

Epoch: 5| Step: 10
Training loss: 2.661387960818701
Validation loss: 2.529872489587903

Epoch: 141| Step: 0
Training loss: 2.7572963328815017
Validation loss: 2.5362170196584994

Epoch: 5| Step: 1
Training loss: 2.9175866628816367
Validation loss: 2.5525072276047127

Epoch: 5| Step: 2
Training loss: 3.085224465190556
Validation loss: 2.583046248842211

Epoch: 5| Step: 3
Training loss: 2.529811120502857
Validation loss: 2.595162037081514

Epoch: 5| Step: 4
Training loss: 2.8466173744251955
Validation loss: 2.605300987704404

Epoch: 5| Step: 5
Training loss: 2.566799371764879
Validation loss: 2.549346433349247

Epoch: 5| Step: 6
Training loss: 2.985302845785447
Validation loss: 2.5167195160626012

Epoch: 5| Step: 7
Training loss: 2.91553122808159
Validation loss: 2.515659283889915

Epoch: 5| Step: 8
Training loss: 2.454866993519523
Validation loss: 2.5160221394513425

Epoch: 5| Step: 9
Training loss: 3.068904485912252
Validation loss: 2.5162939008963483

Epoch: 5| Step: 10
Training loss: 2.8484627375737586
Validation loss: 2.5394783258821447

Epoch: 142| Step: 0
Training loss: 2.750303511776631
Validation loss: 2.5656985197984215

Epoch: 5| Step: 1
Training loss: 2.2743448760408653
Validation loss: 2.57850079922062

Epoch: 5| Step: 2
Training loss: 2.8720860848874126
Validation loss: 2.613574661290335

Epoch: 5| Step: 3
Training loss: 3.106928644171859
Validation loss: 2.7038507435104435

Epoch: 5| Step: 4
Training loss: 2.405893968276777
Validation loss: 2.6493065648659453

Epoch: 5| Step: 5
Training loss: 2.617346642054054
Validation loss: 2.5678069043701752

Epoch: 5| Step: 6
Training loss: 3.2715416564481474
Validation loss: 2.5214576463370957

Epoch: 5| Step: 7
Training loss: 2.7582424790400775
Validation loss: 2.5204480584517954

Epoch: 5| Step: 8
Training loss: 3.003424120881055
Validation loss: 2.515779542847821

Epoch: 5| Step: 9
Training loss: 2.8462223582041704
Validation loss: 2.505700270035467

Epoch: 5| Step: 10
Training loss: 2.674184503762288
Validation loss: 2.507720950705901

Epoch: 143| Step: 0
Training loss: 2.6051690474004654
Validation loss: 2.501329439730235

Epoch: 5| Step: 1
Training loss: 2.898210295540214
Validation loss: 2.496912486353902

Epoch: 5| Step: 2
Training loss: 3.5396341363240866
Validation loss: 2.520594502580315

Epoch: 5| Step: 3
Training loss: 2.0440746691104925
Validation loss: 2.5522522003847152

Epoch: 5| Step: 4
Training loss: 2.8060341155139183
Validation loss: 2.584447424656551

Epoch: 5| Step: 5
Training loss: 3.0885459209410695
Validation loss: 2.5746004287018356

Epoch: 5| Step: 6
Training loss: 3.2440446429491034
Validation loss: 2.5949111318244458

Epoch: 5| Step: 7
Training loss: 2.882160723025281
Validation loss: 2.5597799607888407

Epoch: 5| Step: 8
Training loss: 2.477772702818702
Validation loss: 2.5380051640676102

Epoch: 5| Step: 9
Training loss: 2.192703379959951
Validation loss: 2.525325166511088

Epoch: 5| Step: 10
Training loss: 2.643368982585383
Validation loss: 2.526292199127523

Epoch: 144| Step: 0
Training loss: 3.0454140314955502
Validation loss: 2.5352633598505796

Epoch: 5| Step: 1
Training loss: 2.7686768842907097
Validation loss: 2.5498138901501117

Epoch: 5| Step: 2
Training loss: 3.103535752324208
Validation loss: 2.5581126362152835

Epoch: 5| Step: 3
Training loss: 2.637574550063204
Validation loss: 2.5580025128902366

Epoch: 5| Step: 4
Training loss: 2.364241778426887
Validation loss: 2.550778519301186

Epoch: 5| Step: 5
Training loss: 2.7047197345507468
Validation loss: 2.5364256610338174

Epoch: 5| Step: 6
Training loss: 2.7421037710073812
Validation loss: 2.530859812433422

Epoch: 5| Step: 7
Training loss: 2.89304724578307
Validation loss: 2.538833892097474

Epoch: 5| Step: 8
Training loss: 2.676614227953061
Validation loss: 2.527596463547568

Epoch: 5| Step: 9
Training loss: 2.4994811473302563
Validation loss: 2.5357624487500545

Epoch: 5| Step: 10
Training loss: 2.961948353071783
Validation loss: 2.569647905460361

Epoch: 145| Step: 0
Training loss: 3.372663183428274
Validation loss: 2.597222032631622

Epoch: 5| Step: 1
Training loss: 2.9144070909906534
Validation loss: 2.643139544756419

Epoch: 5| Step: 2
Training loss: 2.8644019791965816
Validation loss: 2.638156370670719

Epoch: 5| Step: 3
Training loss: 2.575203737513475
Validation loss: 2.5955757478931507

Epoch: 5| Step: 4
Training loss: 2.5586657797888246
Validation loss: 2.524013408741046

Epoch: 5| Step: 5
Training loss: 3.02402240309919
Validation loss: 2.4889953683741424

Epoch: 5| Step: 6
Training loss: 2.765410334127844
Validation loss: 2.498415811117449

Epoch: 5| Step: 7
Training loss: 2.6632116306971123
Validation loss: 2.50289102973324

Epoch: 5| Step: 8
Training loss: 2.6856572242953702
Validation loss: 2.5166328850314983

Epoch: 5| Step: 9
Training loss: 2.701943111580359
Validation loss: 2.5177281502055178

Epoch: 5| Step: 10
Training loss: 2.767393505800808
Validation loss: 2.5014009693121246

Epoch: 146| Step: 0
Training loss: 2.4408668349408793
Validation loss: 2.4906082665975244

Epoch: 5| Step: 1
Training loss: 2.862564892428938
Validation loss: 2.5033003915390277

Epoch: 5| Step: 2
Training loss: 2.883301566799745
Validation loss: 2.544655895114941

Epoch: 5| Step: 3
Training loss: 3.3602149090838656
Validation loss: 2.62666803873042

Epoch: 5| Step: 4
Training loss: 3.1385345333983476
Validation loss: 2.5518018000107205

Epoch: 5| Step: 5
Training loss: 2.7042791295189117
Validation loss: 2.5210401314104147

Epoch: 5| Step: 6
Training loss: 2.3636061768171395
Validation loss: 2.4876288390684067

Epoch: 5| Step: 7
Training loss: 2.8746860166840906
Validation loss: 2.5053029873400297

Epoch: 5| Step: 8
Training loss: 2.41962362672909
Validation loss: 2.5022047995564116

Epoch: 5| Step: 9
Training loss: 2.669001858192846
Validation loss: 2.4979470581246446

Epoch: 5| Step: 10
Training loss: 2.9340008936947615
Validation loss: 2.511035578576025

Epoch: 147| Step: 0
Training loss: 2.4906711090682694
Validation loss: 2.515283795717891

Epoch: 5| Step: 1
Training loss: 2.8424126131687806
Validation loss: 2.5500996604970796

Epoch: 5| Step: 2
Training loss: 2.9843497549856663
Validation loss: 2.6280353866765425

Epoch: 5| Step: 3
Training loss: 2.8845756948626065
Validation loss: 2.6933580852597876

Epoch: 5| Step: 4
Training loss: 2.8564529914426697
Validation loss: 2.711567691197456

Epoch: 5| Step: 5
Training loss: 2.8052208693477194
Validation loss: 2.7181241073265316

Epoch: 5| Step: 6
Training loss: 2.5411121722446515
Validation loss: 2.6118931141131396

Epoch: 5| Step: 7
Training loss: 2.8670133698933062
Validation loss: 2.5336132474841073

Epoch: 5| Step: 8
Training loss: 2.439956894009155
Validation loss: 2.51360253962383

Epoch: 5| Step: 9
Training loss: 2.887093691292301
Validation loss: 2.5133949412354664

Epoch: 5| Step: 10
Training loss: 3.141348077083156
Validation loss: 2.519428231417113

Epoch: 148| Step: 0
Training loss: 2.467667740798889
Validation loss: 2.5359557596114306

Epoch: 5| Step: 1
Training loss: 2.9623800905321467
Validation loss: 2.537093484499068

Epoch: 5| Step: 2
Training loss: 2.6066191048279013
Validation loss: 2.519362046135063

Epoch: 5| Step: 3
Training loss: 2.8229316532727236
Validation loss: 2.522068246640539

Epoch: 5| Step: 4
Training loss: 2.5275849547102442
Validation loss: 2.5079866658760213

Epoch: 5| Step: 5
Training loss: 2.952868415140815
Validation loss: 2.527173791030002

Epoch: 5| Step: 6
Training loss: 3.1505162497232906
Validation loss: 2.5417703768428153

Epoch: 5| Step: 7
Training loss: 2.785758832079298
Validation loss: 2.5904128559677413

Epoch: 5| Step: 8
Training loss: 3.0124347790507713
Validation loss: 2.592303000309512

Epoch: 5| Step: 9
Training loss: 2.9214191591175815
Validation loss: 2.613827863470262

Epoch: 5| Step: 10
Training loss: 2.4819193285573964
Validation loss: 2.5971244776582894

Epoch: 149| Step: 0
Training loss: 2.7104867346051447
Validation loss: 2.5356096324013997

Epoch: 5| Step: 1
Training loss: 2.7567970200162204
Validation loss: 2.4971677847182314

Epoch: 5| Step: 2
Training loss: 3.2723842920373745
Validation loss: 2.4979931836822553

Epoch: 5| Step: 3
Training loss: 2.3978335337696333
Validation loss: 2.5055945709715823

Epoch: 5| Step: 4
Training loss: 2.544773662522708
Validation loss: 2.5022554396093386

Epoch: 5| Step: 5
Training loss: 1.7886699928928593
Validation loss: 2.4996637230996233

Epoch: 5| Step: 6
Training loss: 2.940132422546538
Validation loss: 2.5051364441089

Epoch: 5| Step: 7
Training loss: 2.876669689131203
Validation loss: 2.5126480692344284

Epoch: 5| Step: 8
Training loss: 3.3169038397047546
Validation loss: 2.4954946262608315

Epoch: 5| Step: 9
Training loss: 2.8539139758740895
Validation loss: 2.5353830034090308

Epoch: 5| Step: 10
Training loss: 2.4243207825835373
Validation loss: 2.5070885135944425

Epoch: 150| Step: 0
Training loss: 2.3922286296076924
Validation loss: 2.4952862282092743

Epoch: 5| Step: 1
Training loss: 2.814699965591585
Validation loss: 2.497783524337209

Epoch: 5| Step: 2
Training loss: 2.7004831446951703
Validation loss: 2.5225570312506544

Epoch: 5| Step: 3
Training loss: 2.566382932048987
Validation loss: 2.545700860514646

Epoch: 5| Step: 4
Training loss: 2.824793671356562
Validation loss: 2.5521542493867333

Epoch: 5| Step: 5
Training loss: 2.1534815167833323
Validation loss: 2.5335545270311917

Epoch: 5| Step: 6
Training loss: 2.9633114439846335
Validation loss: 2.5198864631025706

Epoch: 5| Step: 7
Training loss: 2.63659215552578
Validation loss: 2.500786652419348

Epoch: 5| Step: 8
Training loss: 3.188738414065952
Validation loss: 2.497800549642051

Epoch: 5| Step: 9
Training loss: 2.8635287106358374
Validation loss: 2.496055237995194

Epoch: 5| Step: 10
Training loss: 2.97237857118207
Validation loss: 2.5023467227161964

Epoch: 151| Step: 0
Training loss: 2.888373080282968
Validation loss: 2.5230449418286254

Epoch: 5| Step: 1
Training loss: 2.621273210865704
Validation loss: 2.5358034573683086

Epoch: 5| Step: 2
Training loss: 2.3537426344421504
Validation loss: 2.5389503836666836

Epoch: 5| Step: 3
Training loss: 2.6778699755680044
Validation loss: 2.53850425521539

Epoch: 5| Step: 4
Training loss: 2.740686946155765
Validation loss: 2.5600877137725084

Epoch: 5| Step: 5
Training loss: 2.612931163927886
Validation loss: 2.5492867549029277

Epoch: 5| Step: 6
Training loss: 3.188069909701716
Validation loss: 2.5182200881704944

Epoch: 5| Step: 7
Training loss: 3.063693845398479
Validation loss: 2.5120873365546075

Epoch: 5| Step: 8
Training loss: 2.2484785870157427
Validation loss: 2.50350277401388

Epoch: 5| Step: 9
Training loss: 2.771459599519282
Validation loss: 2.4992189622947594

Epoch: 5| Step: 10
Training loss: 2.7955407737633586
Validation loss: 2.488022027943859

Epoch: 152| Step: 0
Training loss: 3.0357913576488245
Validation loss: 2.5046859847142446

Epoch: 5| Step: 1
Training loss: 2.4176754873779207
Validation loss: 2.4996892223183487

Epoch: 5| Step: 2
Training loss: 2.6552558384852594
Validation loss: 2.516190469583098

Epoch: 5| Step: 3
Training loss: 2.5964887935485477
Validation loss: 2.5509831884829874

Epoch: 5| Step: 4
Training loss: 2.4122078199799577
Validation loss: 2.577837677249553

Epoch: 5| Step: 5
Training loss: 3.147793763187405
Validation loss: 2.6174183968502747

Epoch: 5| Step: 6
Training loss: 2.21158571479863
Validation loss: 2.5937544714796097

Epoch: 5| Step: 7
Training loss: 3.404514675647144
Validation loss: 2.571533783712505

Epoch: 5| Step: 8
Training loss: 2.297999619214165
Validation loss: 2.523491589666128

Epoch: 5| Step: 9
Training loss: 2.291746681434856
Validation loss: 2.5080716411933976

Epoch: 5| Step: 10
Training loss: 3.0318105906807027
Validation loss: 2.497841635490267

Epoch: 153| Step: 0
Training loss: 2.221800305791661
Validation loss: 2.4963891152788267

Epoch: 5| Step: 1
Training loss: 2.58413393679151
Validation loss: 2.497006173185402

Epoch: 5| Step: 2
Training loss: 2.755080471905902
Validation loss: 2.5108203838190306

Epoch: 5| Step: 3
Training loss: 2.685830240732137
Validation loss: 2.50319215366629

Epoch: 5| Step: 4
Training loss: 3.008743102537648
Validation loss: 2.510186331646949

Epoch: 5| Step: 5
Training loss: 2.8037522650755036
Validation loss: 2.548255896848226

Epoch: 5| Step: 6
Training loss: 2.998421571658448
Validation loss: 2.5989410349179187

Epoch: 5| Step: 7
Training loss: 3.0634746946718883
Validation loss: 2.745677601331514

Epoch: 5| Step: 8
Training loss: 2.720704965255345
Validation loss: 2.69123207551596

Epoch: 5| Step: 9
Training loss: 3.064870423009571
Validation loss: 2.6384658757961867

Epoch: 5| Step: 10
Training loss: 1.798648854288837
Validation loss: 2.5143777339547135

Epoch: 154| Step: 0
Training loss: 2.824493437054573
Validation loss: 2.5018188525578897

Epoch: 5| Step: 1
Training loss: 2.5943441055285295
Validation loss: 2.50038949742016

Epoch: 5| Step: 2
Training loss: 2.9839418106848568
Validation loss: 2.5057350068811197

Epoch: 5| Step: 3
Training loss: 2.905903949439262
Validation loss: 2.51361487944742

Epoch: 5| Step: 4
Training loss: 2.232226746208924
Validation loss: 2.487521770248257

Epoch: 5| Step: 5
Training loss: 2.5831829047756463
Validation loss: 2.4943141729923917

Epoch: 5| Step: 6
Training loss: 2.9205954294730194
Validation loss: 2.523840383379362

Epoch: 5| Step: 7
Training loss: 3.0034060216724057
Validation loss: 2.5513870853237557

Epoch: 5| Step: 8
Training loss: 2.6695065178756754
Validation loss: 2.6007531010124985

Epoch: 5| Step: 9
Training loss: 2.3542600855113553
Validation loss: 2.6699192651938035

Epoch: 5| Step: 10
Training loss: 3.1859028124452697
Validation loss: 2.6677287198607216

Epoch: 155| Step: 0
Training loss: 2.422289019236227
Validation loss: 2.552586147122563

Epoch: 5| Step: 1
Training loss: 2.852073310145248
Validation loss: 2.507071309015722

Epoch: 5| Step: 2
Training loss: 2.767979196415159
Validation loss: 2.494898726969157

Epoch: 5| Step: 3
Training loss: 2.2732885777308613
Validation loss: 2.5098163586680617

Epoch: 5| Step: 4
Training loss: 3.191810983793089
Validation loss: 2.5131348657321935

Epoch: 5| Step: 5
Training loss: 2.942049926199335
Validation loss: 2.513830785450584

Epoch: 5| Step: 6
Training loss: 2.9286881433549445
Validation loss: 2.5236459870259877

Epoch: 5| Step: 7
Training loss: 2.8049570448199224
Validation loss: 2.520209713706494

Epoch: 5| Step: 8
Training loss: 2.9628070977947036
Validation loss: 2.505468058345489

Epoch: 5| Step: 9
Training loss: 3.0402892316456582
Validation loss: 2.5074807204011615

Epoch: 5| Step: 10
Training loss: 3.1222282324386557
Validation loss: 2.5097019664220754

Epoch: 156| Step: 0
Training loss: 2.8602693753662787
Validation loss: 2.52778311502779

Epoch: 5| Step: 1
Training loss: 2.729760772647488
Validation loss: 2.5397450589650257

Epoch: 5| Step: 2
Training loss: 2.8153758286992043
Validation loss: 2.5653614312243986

Epoch: 5| Step: 3
Training loss: 2.3039539268840836
Validation loss: 2.6120564947794076

Epoch: 5| Step: 4
Training loss: 2.43005574370445
Validation loss: 2.715000486891874

Epoch: 5| Step: 5
Training loss: 2.977913617440817
Validation loss: 2.805993257347968

Epoch: 5| Step: 6
Training loss: 2.702393625796645
Validation loss: 2.7127929231433874

Epoch: 5| Step: 7
Training loss: 2.6312379741620413
Validation loss: 2.608621639961345

Epoch: 5| Step: 8
Training loss: 3.0065100289740077
Validation loss: 2.577020566064531

Epoch: 5| Step: 9
Training loss: 2.921596901454724
Validation loss: 2.534624195174654

Epoch: 5| Step: 10
Training loss: 2.9682787069370127
Validation loss: 2.495699609885642

Epoch: 157| Step: 0
Training loss: 2.8957253488582975
Validation loss: 2.506721981960512

Epoch: 5| Step: 1
Training loss: 3.3589136560942854
Validation loss: 2.506152788380568

Epoch: 5| Step: 2
Training loss: 2.7805339448664688
Validation loss: 2.518941877653497

Epoch: 5| Step: 3
Training loss: 2.177385105469855
Validation loss: 2.517063894938072

Epoch: 5| Step: 4
Training loss: 2.49331974151633
Validation loss: 2.5232410903709495

Epoch: 5| Step: 5
Training loss: 2.1882319724361152
Validation loss: 2.5447042426913615

Epoch: 5| Step: 6
Training loss: 2.5701992392587165
Validation loss: 2.5427687363901903

Epoch: 5| Step: 7
Training loss: 2.579382942100593
Validation loss: 2.5509965871008875

Epoch: 5| Step: 8
Training loss: 3.0371153411316
Validation loss: 2.526377440551317

Epoch: 5| Step: 9
Training loss: 2.924248532004199
Validation loss: 2.536298686964083

Epoch: 5| Step: 10
Training loss: 2.748918494055961
Validation loss: 2.5549666175823176

Epoch: 158| Step: 0
Training loss: 2.404987548986233
Validation loss: 2.5955081599411307

Epoch: 5| Step: 1
Training loss: 2.7103900631520905
Validation loss: 2.591008799237562

Epoch: 5| Step: 2
Training loss: 2.684602550591945
Validation loss: 2.564503820431953

Epoch: 5| Step: 3
Training loss: 2.521830232924859
Validation loss: 2.5406826305831958

Epoch: 5| Step: 4
Training loss: 3.180567963940118
Validation loss: 2.5330529587124815

Epoch: 5| Step: 5
Training loss: 2.4069684429944838
Validation loss: 2.5367010507111085

Epoch: 5| Step: 6
Training loss: 3.3185809478520016
Validation loss: 2.5812249373897944

Epoch: 5| Step: 7
Training loss: 2.628482053182054
Validation loss: 2.621182205128047

Epoch: 5| Step: 8
Training loss: 2.7235861548923577
Validation loss: 2.6772856270615857

Epoch: 5| Step: 9
Training loss: 2.9532835579747014
Validation loss: 2.600027926415718

Epoch: 5| Step: 10
Training loss: 1.9455982289492866
Validation loss: 2.541778053318861

Epoch: 159| Step: 0
Training loss: 2.442929407674595
Validation loss: 2.517117751855711

Epoch: 5| Step: 1
Training loss: 2.5563683069734764
Validation loss: 2.498894295183131

Epoch: 5| Step: 2
Training loss: 2.7733524793031243
Validation loss: 2.4916896301549185

Epoch: 5| Step: 3
Training loss: 2.7038643768427764
Validation loss: 2.495237348461488

Epoch: 5| Step: 4
Training loss: 3.384778163070041
Validation loss: 2.487110763819453

Epoch: 5| Step: 5
Training loss: 3.194588651488902
Validation loss: 2.490380735654503

Epoch: 5| Step: 6
Training loss: 2.706457476338401
Validation loss: 2.489636907740342

Epoch: 5| Step: 7
Training loss: 2.3685371403937925
Validation loss: 2.4999164526320254

Epoch: 5| Step: 8
Training loss: 2.581392748859566
Validation loss: 2.509908422927141

Epoch: 5| Step: 9
Training loss: 2.3545918263601884
Validation loss: 2.5489666204748054

Epoch: 5| Step: 10
Training loss: 2.715862450792296
Validation loss: 2.58981552186593

Epoch: 160| Step: 0
Training loss: 2.744250268883843
Validation loss: 2.7270602670912685

Epoch: 5| Step: 1
Training loss: 3.2591339285511722
Validation loss: 2.838251016184365

Epoch: 5| Step: 2
Training loss: 2.6441394059196295
Validation loss: 2.8058144176417428

Epoch: 5| Step: 3
Training loss: 2.5622243035105736
Validation loss: 2.6512280528455134

Epoch: 5| Step: 4
Training loss: 3.189455666573161
Validation loss: 2.574966814189887

Epoch: 5| Step: 5
Training loss: 2.8704006059027196
Validation loss: 2.499251851557399

Epoch: 5| Step: 6
Training loss: 2.654272891982572
Validation loss: 2.5018188161806583

Epoch: 5| Step: 7
Training loss: 2.813722980357674
Validation loss: 2.494317054924534

Epoch: 5| Step: 8
Training loss: 2.661753529242208
Validation loss: 2.49693391297064

Epoch: 5| Step: 9
Training loss: 2.377382990287287
Validation loss: 2.4947252463600686

Epoch: 5| Step: 10
Training loss: 2.421776947989932
Validation loss: 2.485578352227781

Epoch: 161| Step: 0
Training loss: 3.1644708817278935
Validation loss: 2.4873701127938306

Epoch: 5| Step: 1
Training loss: 2.962909615442602
Validation loss: 2.488122799374954

Epoch: 5| Step: 2
Training loss: 2.395653814694356
Validation loss: 2.5024002627420243

Epoch: 5| Step: 3
Training loss: 2.5509405159409617
Validation loss: 2.5027802942863744

Epoch: 5| Step: 4
Training loss: 2.7467340669726235
Validation loss: 2.5319142910014305

Epoch: 5| Step: 5
Training loss: 2.6867263035114815
Validation loss: 2.5695388905924155

Epoch: 5| Step: 6
Training loss: 2.7332361083843497
Validation loss: 2.5602944719789136

Epoch: 5| Step: 7
Training loss: 2.222187227397457
Validation loss: 2.5824891344150047

Epoch: 5| Step: 8
Training loss: 2.7343331470011227
Validation loss: 2.5954395103754773

Epoch: 5| Step: 9
Training loss: 2.094338177864138
Validation loss: 2.5761856242558876

Epoch: 5| Step: 10
Training loss: 2.9583314886669445
Validation loss: 2.5694091218713435

Epoch: 162| Step: 0
Training loss: 2.9609544094277225
Validation loss: 2.5396756409833627

Epoch: 5| Step: 1
Training loss: 2.3113780006132165
Validation loss: 2.53639616979247

Epoch: 5| Step: 2
Training loss: 2.995658275881843
Validation loss: 2.497395881922209

Epoch: 5| Step: 3
Training loss: 2.9890952603528493
Validation loss: 2.4984077715602995

Epoch: 5| Step: 4
Training loss: 2.4195113923068106
Validation loss: 2.5015456528332782

Epoch: 5| Step: 5
Training loss: 2.29439925066405
Validation loss: 2.496434000347775

Epoch: 5| Step: 6
Training loss: 2.2602496341805867
Validation loss: 2.5003152894584653

Epoch: 5| Step: 7
Training loss: 2.7683827933850567
Validation loss: 2.5199665079952918

Epoch: 5| Step: 8
Training loss: 2.7563904291826296
Validation loss: 2.5322365154409927

Epoch: 5| Step: 9
Training loss: 2.7457309011090163
Validation loss: 2.527930275125425

Epoch: 5| Step: 10
Training loss: 2.632700297967324
Validation loss: 2.535054651130687

Epoch: 163| Step: 0
Training loss: 2.401793080306951
Validation loss: 2.520620848825176

Epoch: 5| Step: 1
Training loss: 1.894966248586626
Validation loss: 2.498207875327181

Epoch: 5| Step: 2
Training loss: 2.9101074214653613
Validation loss: 2.5003219868850954

Epoch: 5| Step: 3
Training loss: 2.7198144867688576
Validation loss: 2.510067393925261

Epoch: 5| Step: 4
Training loss: 2.2854881110857495
Validation loss: 2.4919539632874343

Epoch: 5| Step: 5
Training loss: 2.492293017793403
Validation loss: 2.492179955716563

Epoch: 5| Step: 6
Training loss: 2.7293969753630734
Validation loss: 2.4910831458596396

Epoch: 5| Step: 7
Training loss: 2.573209388132995
Validation loss: 2.500660008297744

Epoch: 5| Step: 8
Training loss: 2.835592117505681
Validation loss: 2.5360979350280357

Epoch: 5| Step: 9
Training loss: 3.095072762122408
Validation loss: 2.5788657935453108

Epoch: 5| Step: 10
Training loss: 2.8844923795247963
Validation loss: 2.585911018184682

Epoch: 164| Step: 0
Training loss: 3.370654805803355
Validation loss: 2.6695359666168366

Epoch: 5| Step: 1
Training loss: 2.867998138501615
Validation loss: 2.7132393360306453

Epoch: 5| Step: 2
Training loss: 2.2099006297352926
Validation loss: 2.592764563329297

Epoch: 5| Step: 3
Training loss: 2.4619099951002696
Validation loss: 2.518030925762457

Epoch: 5| Step: 4
Training loss: 2.629805299202328
Validation loss: 2.5198369465147623

Epoch: 5| Step: 5
Training loss: 2.7254693318336694
Validation loss: 2.5176576445433425

Epoch: 5| Step: 6
Training loss: 1.8486215920568754
Validation loss: 2.507174061800761

Epoch: 5| Step: 7
Training loss: 2.6480573983439855
Validation loss: 2.5220762859953414

Epoch: 5| Step: 8
Training loss: 3.333696885946316
Validation loss: 2.524843722778442

Epoch: 5| Step: 9
Training loss: 2.110287391290658
Validation loss: 2.5197919197690966

Epoch: 5| Step: 10
Training loss: 2.2949755853089826
Validation loss: 2.506662373831474

Epoch: 165| Step: 0
Training loss: 2.4782894623530574
Validation loss: 2.5149565674695387

Epoch: 5| Step: 1
Training loss: 2.894359753427895
Validation loss: 2.5416344425923043

Epoch: 5| Step: 2
Training loss: 2.483440967335146
Validation loss: 2.546872798602408

Epoch: 5| Step: 3
Training loss: 2.4783746966373696
Validation loss: 2.5360816045278463

Epoch: 5| Step: 4
Training loss: 2.3587542595190616
Validation loss: 2.550126111070753

Epoch: 5| Step: 5
Training loss: 3.008900155923328
Validation loss: 2.525732778158289

Epoch: 5| Step: 6
Training loss: 3.1794424501511647
Validation loss: 2.5226790309531046

Epoch: 5| Step: 7
Training loss: 2.5915105872875452
Validation loss: 2.4863564603617525

Epoch: 5| Step: 8
Training loss: 2.3591772337631602
Validation loss: 2.4972132460867424

Epoch: 5| Step: 9
Training loss: 2.62761158685358
Validation loss: 2.4678157234312903

Epoch: 5| Step: 10
Training loss: 2.294556673900741
Validation loss: 2.503382853105364

Epoch: 166| Step: 0
Training loss: 2.4819655340354534
Validation loss: 2.5653647489952602

Epoch: 5| Step: 1
Training loss: 2.7223115590632485
Validation loss: 2.6042879892616626

Epoch: 5| Step: 2
Training loss: 2.810062114802855
Validation loss: 2.6697592978313534

Epoch: 5| Step: 3
Training loss: 3.187245527095111
Validation loss: 2.673644385689887

Epoch: 5| Step: 4
Training loss: 2.7840319660861828
Validation loss: 2.5819370142803892

Epoch: 5| Step: 5
Training loss: 2.0966579683100153
Validation loss: 2.5155434329954693

Epoch: 5| Step: 6
Training loss: 2.1851403725094642
Validation loss: 2.4979677307804056

Epoch: 5| Step: 7
Training loss: 2.446971976159886
Validation loss: 2.5085335140569187

Epoch: 5| Step: 8
Training loss: 2.8992093027752976
Validation loss: 2.4925391798078858

Epoch: 5| Step: 9
Training loss: 2.408724218764063
Validation loss: 2.484505235464151

Epoch: 5| Step: 10
Training loss: 2.66004188504621
Validation loss: 2.4828198483118413

Epoch: 167| Step: 0
Training loss: 2.2005163670481362
Validation loss: 2.5100272854515424

Epoch: 5| Step: 1
Training loss: 2.6349301297444785
Validation loss: 2.515705938660691

Epoch: 5| Step: 2
Training loss: 2.3948615936870925
Validation loss: 2.564633427516687

Epoch: 5| Step: 3
Training loss: 2.767586567394057
Validation loss: 2.609038882178731

Epoch: 5| Step: 4
Training loss: 2.594635685832137
Validation loss: 2.619884624278242

Epoch: 5| Step: 5
Training loss: 2.8908262440504817
Validation loss: 2.6025812943630235

Epoch: 5| Step: 6
Training loss: 2.5925772899852224
Validation loss: 2.562736387276961

Epoch: 5| Step: 7
Training loss: 2.2344397688861584
Validation loss: 2.538915193511123

Epoch: 5| Step: 8
Training loss: 2.5066286899686157
Validation loss: 2.5333630072594198

Epoch: 5| Step: 9
Training loss: 2.6079805040040345
Validation loss: 2.4997272117027793

Epoch: 5| Step: 10
Training loss: 3.089830169454985
Validation loss: 2.487223838844541

Epoch: 168| Step: 0
Training loss: 2.403693885088717
Validation loss: 2.493067919651855

Epoch: 5| Step: 1
Training loss: 2.4109185248349507
Validation loss: 2.502145563317446

Epoch: 5| Step: 2
Training loss: 2.7296581456702818
Validation loss: 2.513849806955333

Epoch: 5| Step: 3
Training loss: 2.8817072044273235
Validation loss: 2.538477087695134

Epoch: 5| Step: 4
Training loss: 2.9631405487972167
Validation loss: 2.5474149442539695

Epoch: 5| Step: 5
Training loss: 2.043687508003876
Validation loss: 2.572098436030891

Epoch: 5| Step: 6
Training loss: 2.4718129918245704
Validation loss: 2.5821510974570767

Epoch: 5| Step: 7
Training loss: 2.8783680634059046
Validation loss: 2.562504337926395

Epoch: 5| Step: 8
Training loss: 2.5337477240531046
Validation loss: 2.541611306891945

Epoch: 5| Step: 9
Training loss: 2.608422842307911
Validation loss: 2.5141974329515353

Epoch: 5| Step: 10
Training loss: 2.2894114986658445
Validation loss: 2.5049366007450944

Epoch: 169| Step: 0
Training loss: 2.435387894520572
Validation loss: 2.4774949888793323

Epoch: 5| Step: 1
Training loss: 2.5643854415573126
Validation loss: 2.472384692457697

Epoch: 5| Step: 2
Training loss: 2.730264593304225
Validation loss: 2.4769619115347696

Epoch: 5| Step: 3
Training loss: 2.1265082896860563
Validation loss: 2.480105346383305

Epoch: 5| Step: 4
Training loss: 2.984687509202243
Validation loss: 2.5144173366540343

Epoch: 5| Step: 5
Training loss: 2.0121974930957207
Validation loss: 2.5194879302853845

Epoch: 5| Step: 6
Training loss: 2.6241725344050697
Validation loss: 2.5369742085919906

Epoch: 5| Step: 7
Training loss: 2.7800596454451596
Validation loss: 2.529010812813609

Epoch: 5| Step: 8
Training loss: 2.507030900032112
Validation loss: 2.4792971181599492

Epoch: 5| Step: 9
Training loss: 2.8618623514722743
Validation loss: 2.469412253108816

Epoch: 5| Step: 10
Training loss: 2.3826781188093333
Validation loss: 2.48922906834064

Epoch: 170| Step: 0
Training loss: 2.0986311084000175
Validation loss: 2.495398398555749

Epoch: 5| Step: 1
Training loss: 2.1817522011880532
Validation loss: 2.5417664160504825

Epoch: 5| Step: 2
Training loss: 2.064995614109508
Validation loss: 2.5811864923007537

Epoch: 5| Step: 3
Training loss: 2.4827427330321745
Validation loss: 2.547942287657108

Epoch: 5| Step: 4
Training loss: 3.237453746097027
Validation loss: 2.526268709815525

Epoch: 5| Step: 5
Training loss: 2.02891523721296
Validation loss: 2.48239031495107

Epoch: 5| Step: 6
Training loss: 2.4464531818699378
Validation loss: 2.4992686894039924

Epoch: 5| Step: 7
Training loss: 3.235047348831564
Validation loss: 2.4906821925151528

Epoch: 5| Step: 8
Training loss: 2.9079563505000507
Validation loss: 2.5062626045799403

Epoch: 5| Step: 9
Training loss: 2.484736578198403
Validation loss: 2.5287489734997317

Epoch: 5| Step: 10
Training loss: 2.509482614910363
Validation loss: 2.5593038335585416

Epoch: 171| Step: 0
Training loss: 2.959249453112162
Validation loss: 2.5676989125971263

Epoch: 5| Step: 1
Training loss: 2.9174235497193464
Validation loss: 2.559625359307491

Epoch: 5| Step: 2
Training loss: 2.2620183189587957
Validation loss: 2.5645891442832878

Epoch: 5| Step: 3
Training loss: 2.1071615403019033
Validation loss: 2.509156429347687

Epoch: 5| Step: 4
Training loss: 2.0991017282377533
Validation loss: 2.4949438423026287

Epoch: 5| Step: 5
Training loss: 2.263303738298971
Validation loss: 2.4792047743963392

Epoch: 5| Step: 6
Training loss: 1.9221946636544618
Validation loss: 2.4928622136588663

Epoch: 5| Step: 7
Training loss: 2.9365533155488657
Validation loss: 2.4997586523481172

Epoch: 5| Step: 8
Training loss: 2.3473776653617353
Validation loss: 2.528687055029214

Epoch: 5| Step: 9
Training loss: 3.0185646395116597
Validation loss: 2.5330645924927113

Epoch: 5| Step: 10
Training loss: 2.6914175888730667
Validation loss: 2.5869070897906696

Epoch: 172| Step: 0
Training loss: 2.8454561250689463
Validation loss: 2.622043954116342

Epoch: 5| Step: 1
Training loss: 2.300319035835242
Validation loss: 2.5358235757438568

Epoch: 5| Step: 2
Training loss: 2.544263565745495
Validation loss: 2.520173897693232

Epoch: 5| Step: 3
Training loss: 2.286669108090149
Validation loss: 2.510105907466097

Epoch: 5| Step: 4
Training loss: 2.4110699224787204
Validation loss: 2.5159885666311586

Epoch: 5| Step: 5
Training loss: 2.5960446054890824
Validation loss: 2.564761983508991

Epoch: 5| Step: 6
Training loss: 2.4290701029599773
Validation loss: 2.5561570931183155

Epoch: 5| Step: 7
Training loss: 2.6890192395221013
Validation loss: 2.5330131716911244

Epoch: 5| Step: 8
Training loss: 2.5437446500454817
Validation loss: 2.4879690703288393

Epoch: 5| Step: 9
Training loss: 1.9644202805536581
Validation loss: 2.4812182049284495

Epoch: 5| Step: 10
Training loss: 2.9350861716414625
Validation loss: 2.481699425256955

Epoch: 173| Step: 0
Training loss: 2.244273315437758
Validation loss: 2.51137119943591

Epoch: 5| Step: 1
Training loss: 2.4722626238699394
Validation loss: 2.5032428433859524

Epoch: 5| Step: 2
Training loss: 2.4765427645790448
Validation loss: 2.559684793707066

Epoch: 5| Step: 3
Training loss: 2.371563181528317
Validation loss: 2.5279654681062507

Epoch: 5| Step: 4
Training loss: 2.5023619937856942
Validation loss: 2.497573374710897

Epoch: 5| Step: 5
Training loss: 2.0777144636048885
Validation loss: 2.4968487310967604

Epoch: 5| Step: 6
Training loss: 2.273625736374662
Validation loss: 2.509939401020327

Epoch: 5| Step: 7
Training loss: 2.628309252944518
Validation loss: 2.537397756253893

Epoch: 5| Step: 8
Training loss: 2.5696853753848536
Validation loss: 2.6141019982023006

Epoch: 5| Step: 9
Training loss: 2.6506040820281527
Validation loss: 2.6563513536799377

Epoch: 5| Step: 10
Training loss: 3.3068207332907513
Validation loss: 2.719376826159412

Epoch: 174| Step: 0
Training loss: 2.54582061473044
Validation loss: 2.4779536760437746

Epoch: 5| Step: 1
Training loss: 2.8779553689577764
Validation loss: 2.4455376145691763

Epoch: 5| Step: 2
Training loss: 2.1507074744571923
Validation loss: 2.436778810351641

Epoch: 5| Step: 3
Training loss: 2.78515051457268
Validation loss: 2.4312673227572628

Epoch: 5| Step: 4
Training loss: 2.2242399181863375
Validation loss: 2.455524795235748

Epoch: 5| Step: 5
Training loss: 2.8704798450808924
Validation loss: 2.4589672529649165

Epoch: 5| Step: 6
Training loss: 2.68784223639639
Validation loss: 2.507969969357616

Epoch: 5| Step: 7
Training loss: 1.7430575127187466
Validation loss: 2.5291847697329097

Epoch: 5| Step: 8
Training loss: 2.795087019055363
Validation loss: 2.5617817458121044

Epoch: 5| Step: 9
Training loss: 2.400362118582004
Validation loss: 2.622629547596586

Epoch: 5| Step: 10
Training loss: 2.801038573293986
Validation loss: 2.609589189002825

Epoch: 175| Step: 0
Training loss: 2.104493886854012
Validation loss: 2.6277934727717516

Epoch: 5| Step: 1
Training loss: 2.49786867843826
Validation loss: 2.5795167012489157

Epoch: 5| Step: 2
Training loss: 2.4316415074358337
Validation loss: 2.5403605177508157

Epoch: 5| Step: 3
Training loss: 2.366588554526024
Validation loss: 2.4805257010226116

Epoch: 5| Step: 4
Training loss: 2.4770319641108403
Validation loss: 2.453264021802522

Epoch: 5| Step: 5
Training loss: 1.8849676310545205
Validation loss: 2.4511793593321136

Epoch: 5| Step: 6
Training loss: 2.853354531087598
Validation loss: 2.501865099375344

Epoch: 5| Step: 7
Training loss: 2.7249612123021176
Validation loss: 2.4781576267669467

Epoch: 5| Step: 8
Training loss: 2.1945788695077115
Validation loss: 2.491095171178253

Epoch: 5| Step: 9
Training loss: 2.9114343486382555
Validation loss: 2.489055798190829

Epoch: 5| Step: 10
Training loss: 2.7394293583483957
Validation loss: 2.486300234753421

Epoch: 176| Step: 0
Training loss: 2.5556233876205288
Validation loss: 2.504043711245287

Epoch: 5| Step: 1
Training loss: 2.4542273699037778
Validation loss: 2.5102321465205133

Epoch: 5| Step: 2
Training loss: 2.074112309312846
Validation loss: 2.511620453294255

Epoch: 5| Step: 3
Training loss: 2.586397988614953
Validation loss: 2.5050925797154613

Epoch: 5| Step: 4
Training loss: 2.5999245742714603
Validation loss: 2.501920458761698

Epoch: 5| Step: 5
Training loss: 2.307921232581823
Validation loss: 2.466208619650402

Epoch: 5| Step: 6
Training loss: 2.4903829612533834
Validation loss: 2.4604225819288508

Epoch: 5| Step: 7
Training loss: 2.48034369686617
Validation loss: 2.4949057677522792

Epoch: 5| Step: 8
Training loss: 2.710188352648176
Validation loss: 2.513444787709439

Epoch: 5| Step: 9
Training loss: 2.0715059115624515
Validation loss: 2.551836827527722

Epoch: 5| Step: 10
Training loss: 2.675333116414283
Validation loss: 2.5641779414441452

Epoch: 177| Step: 0
Training loss: 1.7977140375072547
Validation loss: 2.5597410318688714

Epoch: 5| Step: 1
Training loss: 2.9042110058443216
Validation loss: 2.5068876743540556

Epoch: 5| Step: 2
Training loss: 2.8100014502633583
Validation loss: 2.458235034433833

Epoch: 5| Step: 3
Training loss: 2.4218231195615063
Validation loss: 2.4491922364969576

Epoch: 5| Step: 4
Training loss: 2.2813453131843677
Validation loss: 2.4326206483774047

Epoch: 5| Step: 5
Training loss: 2.4197482707981757
Validation loss: 2.429629732955461

Epoch: 5| Step: 6
Training loss: 2.3498453860451907
Validation loss: 2.435067603107808

Epoch: 5| Step: 7
Training loss: 2.2761805395246535
Validation loss: 2.4964720125681206

Epoch: 5| Step: 8
Training loss: 2.7726341266023544
Validation loss: 2.661386687372747

Epoch: 5| Step: 9
Training loss: 2.6102675322006066
Validation loss: 2.5953860766002546

Epoch: 5| Step: 10
Training loss: 2.5399691327539826
Validation loss: 2.5464259379043295

Epoch: 178| Step: 0
Training loss: 1.98416947629629
Validation loss: 2.508902186399465

Epoch: 5| Step: 1
Training loss: 2.159972584868339
Validation loss: 2.4860967664071243

Epoch: 5| Step: 2
Training loss: 2.3988172994598282
Validation loss: 2.5167488171798422

Epoch: 5| Step: 3
Training loss: 2.633616519943838
Validation loss: 2.5105879278479994

Epoch: 5| Step: 4
Training loss: 2.570375389558792
Validation loss: 2.5479688662723863

Epoch: 5| Step: 5
Training loss: 1.9433282744252929
Validation loss: 2.516691549042726

Epoch: 5| Step: 6
Training loss: 2.4088062728382074
Validation loss: 2.5032740309561663

Epoch: 5| Step: 7
Training loss: 2.7021701427231797
Validation loss: 2.504541306034802

Epoch: 5| Step: 8
Training loss: 3.149665384836616
Validation loss: 2.491822634600598

Epoch: 5| Step: 9
Training loss: 2.4429231615634626
Validation loss: 2.463563242345214

Epoch: 5| Step: 10
Training loss: 1.8380323430392154
Validation loss: 2.4214434537944514

Epoch: 179| Step: 0
Training loss: 2.210230630086233
Validation loss: 2.4070530651239976

Epoch: 5| Step: 1
Training loss: 2.9165004319547574
Validation loss: 2.437940969932083

Epoch: 5| Step: 2
Training loss: 2.2468663752659572
Validation loss: 2.4191110039963104

Epoch: 5| Step: 3
Training loss: 2.5533764009188475
Validation loss: 2.434500580805144

Epoch: 5| Step: 4
Training loss: 2.957107039051051
Validation loss: 2.6096434626724014

Epoch: 5| Step: 5
Training loss: 2.5060845717630635
Validation loss: 2.66519918235705

Epoch: 5| Step: 6
Training loss: 1.952152773159111
Validation loss: 2.5863140929809703

Epoch: 5| Step: 7
Training loss: 2.6133088023468143
Validation loss: 2.5462468269276783

Epoch: 5| Step: 8
Training loss: 1.89831190910452
Validation loss: 2.45827895643671

Epoch: 5| Step: 9
Training loss: 2.027965413590548
Validation loss: 2.4347591856434607

Epoch: 5| Step: 10
Training loss: 2.7128342031457295
Validation loss: 2.454374016415797

Epoch: 180| Step: 0
Training loss: 2.246556932540874
Validation loss: 2.457868740368558

Epoch: 5| Step: 1
Training loss: 2.4600694851249765
Validation loss: 2.445654697738914

Epoch: 5| Step: 2
Training loss: 2.530090254730554
Validation loss: 2.4618110732657597

Epoch: 5| Step: 3
Training loss: 2.6624204883433586
Validation loss: 2.51370249922388

Epoch: 5| Step: 4
Training loss: 1.8869901663276847
Validation loss: 2.465880583541596

Epoch: 5| Step: 5
Training loss: 2.2996783114494783
Validation loss: 2.458426745061565

Epoch: 5| Step: 6
Training loss: 2.305011584238331
Validation loss: 2.456681701126719

Epoch: 5| Step: 7
Training loss: 1.9336748202504426
Validation loss: 2.4522577679262123

Epoch: 5| Step: 8
Training loss: 2.545994144070372
Validation loss: 2.47372840387122

Epoch: 5| Step: 9
Training loss: 2.5842404977469324
Validation loss: 2.531173452710979

Epoch: 5| Step: 10
Training loss: 2.7399837844257426
Validation loss: 2.6031119106052123

Epoch: 181| Step: 0
Training loss: 2.464431365469252
Validation loss: 2.5934879058375158

Epoch: 5| Step: 1
Training loss: 2.274507356059451
Validation loss: 2.555870410230806

Epoch: 5| Step: 2
Training loss: 2.0075308160566285
Validation loss: 2.5817089835653064

Epoch: 5| Step: 3
Training loss: 2.648377274360172
Validation loss: 2.573020534072027

Epoch: 5| Step: 4
Training loss: 2.2442142484455503
Validation loss: 2.5442657643626214

Epoch: 5| Step: 5
Training loss: 2.175281624812593
Validation loss: 2.545091157449114

Epoch: 5| Step: 6
Training loss: 2.5438842063198503
Validation loss: 2.6202447892796483

Epoch: 5| Step: 7
Training loss: 2.420108667881562
Validation loss: 2.4979649515840943

Epoch: 5| Step: 8
Training loss: 2.7070791617332923
Validation loss: 2.4116771677285813

Epoch: 5| Step: 9
Training loss: 2.533433514002893
Validation loss: 2.4433146229250995

Epoch: 5| Step: 10
Training loss: 2.5344771546873006
Validation loss: 2.422639547363864

Epoch: 182| Step: 0
Training loss: 2.6674070423235476
Validation loss: 2.4294448455451803

Epoch: 5| Step: 1
Training loss: 2.169387820334264
Validation loss: 2.422133950512288

Epoch: 5| Step: 2
Training loss: 2.432159049906681
Validation loss: 2.4401061978790635

Epoch: 5| Step: 3
Training loss: 2.369853014029661
Validation loss: 2.544122156011431

Epoch: 5| Step: 4
Training loss: 2.1872028693988903
Validation loss: 2.5549021004783854

Epoch: 5| Step: 5
Training loss: 2.6077819347018876
Validation loss: 2.5625938100223338

Epoch: 5| Step: 6
Training loss: 2.1557906394046764
Validation loss: 2.534455097676114

Epoch: 5| Step: 7
Training loss: 2.8207109756265387
Validation loss: 2.4958416430828563

Epoch: 5| Step: 8
Training loss: 2.6694915134418644
Validation loss: 2.456363261573403

Epoch: 5| Step: 9
Training loss: 2.3577857317457265
Validation loss: 2.4875499394862413

Epoch: 5| Step: 10
Training loss: 1.6937560922435695
Validation loss: 2.4790742160114396

Epoch: 183| Step: 0
Training loss: 2.8261150151394028
Validation loss: 2.458520806701967

Epoch: 5| Step: 1
Training loss: 2.2292307075024174
Validation loss: 2.4398636160860896

Epoch: 5| Step: 2
Training loss: 2.1894702213106494
Validation loss: 2.4461913948685776

Epoch: 5| Step: 3
Training loss: 2.2730575191538995
Validation loss: 2.510788348577248

Epoch: 5| Step: 4
Training loss: 2.539679161894535
Validation loss: 2.583470738005459

Epoch: 5| Step: 5
Training loss: 2.0195873260091304
Validation loss: 2.502834280848658

Epoch: 5| Step: 6
Training loss: 2.256361656913255
Validation loss: 2.5053310333965753

Epoch: 5| Step: 7
Training loss: 2.6763870778583847
Validation loss: 2.4741570039433762

Epoch: 5| Step: 8
Training loss: 2.534717116212855
Validation loss: 2.491564189474323

Epoch: 5| Step: 9
Training loss: 2.2063032451828986
Validation loss: 2.5154732482790076

Epoch: 5| Step: 10
Training loss: 2.0018966741278823
Validation loss: 2.5669930238464738

Epoch: 184| Step: 0
Training loss: 2.6386137757586448
Validation loss: 2.653063668416947

Epoch: 5| Step: 1
Training loss: 2.0802231142616994
Validation loss: 2.7008877686667407

Epoch: 5| Step: 2
Training loss: 1.974207141934178
Validation loss: 2.6252131133873307

Epoch: 5| Step: 3
Training loss: 2.240077391547732
Validation loss: 2.546266576851034

Epoch: 5| Step: 4
Training loss: 1.941643621719977
Validation loss: 2.4659177204241267

Epoch: 5| Step: 5
Training loss: 2.874272295864455
Validation loss: 2.4244480988660335

Epoch: 5| Step: 6
Training loss: 2.429256192406628
Validation loss: 2.4272684516711824

Epoch: 5| Step: 7
Training loss: 2.2783475204654864
Validation loss: 2.437530461645034

Epoch: 5| Step: 8
Training loss: 2.430369388777303
Validation loss: 2.466513673161127

Epoch: 5| Step: 9
Training loss: 2.641986022161432
Validation loss: 2.581921611164207

Epoch: 5| Step: 10
Training loss: 2.278152871713611
Validation loss: 2.5415055327945004

Epoch: 185| Step: 0
Training loss: 2.0728843980383025
Validation loss: 2.511682227033476

Epoch: 5| Step: 1
Training loss: 2.044878969225146
Validation loss: 2.4440746653057466

Epoch: 5| Step: 2
Training loss: 2.094185968814317
Validation loss: 2.428660865624873

Epoch: 5| Step: 3
Training loss: 2.9839184796342924
Validation loss: 2.4146914898715717

Epoch: 5| Step: 4
Training loss: 2.8653497029128765
Validation loss: 2.4015685792972885

Epoch: 5| Step: 5
Training loss: 2.703775052092558
Validation loss: 2.409658779314568

Epoch: 5| Step: 6
Training loss: 2.3511952465117054
Validation loss: 2.5100357126760184

Epoch: 5| Step: 7
Training loss: 1.9467771600474895
Validation loss: 2.6038173787487207

Epoch: 5| Step: 8
Training loss: 2.224635417943204
Validation loss: 2.6722493048934752

Epoch: 5| Step: 9
Training loss: 2.2408796476961865
Validation loss: 2.7421837155671507

Epoch: 5| Step: 10
Training loss: 1.9443180345892248
Validation loss: 2.657273695473385

Epoch: 186| Step: 0
Training loss: 2.090536583825547
Validation loss: 2.521451137225766

Epoch: 5| Step: 1
Training loss: 2.2913800378204763
Validation loss: 2.530128251715747

Epoch: 5| Step: 2
Training loss: 2.7526052445500095
Validation loss: 2.512482760807003

Epoch: 5| Step: 3
Training loss: 1.9180026857438839
Validation loss: 2.426041620142918

Epoch: 5| Step: 4
Training loss: 2.205595430525625
Validation loss: 2.458145845319185

Epoch: 5| Step: 5
Training loss: 2.12476459770067
Validation loss: 2.5243301450962727

Epoch: 5| Step: 6
Training loss: 2.250489711450647
Validation loss: 2.5818490416207145

Epoch: 5| Step: 7
Training loss: 2.1958893259088956
Validation loss: 2.6897297352330978

Epoch: 5| Step: 8
Training loss: 2.5046928229605596
Validation loss: 2.814076549423922

Epoch: 5| Step: 9
Training loss: 2.381043624946104
Validation loss: 2.6503860904391443

Epoch: 5| Step: 10
Training loss: 2.6087263751639562
Validation loss: 2.5162862740277716

Epoch: 187| Step: 0
Training loss: 2.9553551704752485
Validation loss: 2.4133535973646483

Epoch: 5| Step: 1
Training loss: 1.8896341801383978
Validation loss: 2.401763272296747

Epoch: 5| Step: 2
Training loss: 2.4609717957059676
Validation loss: 2.3955537027369513

Epoch: 5| Step: 3
Training loss: 2.7660130805025545
Validation loss: 2.427308597926232

Epoch: 5| Step: 4
Training loss: 2.5445993940805263
Validation loss: 2.4874065237939567

Epoch: 5| Step: 5
Training loss: 2.2871680639019423
Validation loss: 2.583933764122437

Epoch: 5| Step: 6
Training loss: 2.0600328428002133
Validation loss: 2.6142822812656554

Epoch: 5| Step: 7
Training loss: 1.9442266168138593
Validation loss: 2.502111339139984

Epoch: 5| Step: 8
Training loss: 2.1270510928568536
Validation loss: 2.4879839020780588

Epoch: 5| Step: 9
Training loss: 2.309905994368564
Validation loss: 2.402318345495893

Epoch: 5| Step: 10
Training loss: 1.5853686134518332
Validation loss: 2.3814287261084264

Epoch: 188| Step: 0
Training loss: 2.280795326385473
Validation loss: 2.3713455084108666

Epoch: 5| Step: 1
Training loss: 2.7422466217362413
Validation loss: 2.3892305368637015

Epoch: 5| Step: 2
Training loss: 2.0646399753575047
Validation loss: 2.4738887818970383

Epoch: 5| Step: 3
Training loss: 2.506485917933575
Validation loss: 2.677197532728614

Epoch: 5| Step: 4
Training loss: 2.5755948685103363
Validation loss: 2.6234566672916677

Epoch: 5| Step: 5
Training loss: 2.165809559629836
Validation loss: 2.449774134062507

Epoch: 5| Step: 6
Training loss: 2.287580511625322
Validation loss: 2.368441694278896

Epoch: 5| Step: 7
Training loss: 2.363650256896369
Validation loss: 2.3904656690830604

Epoch: 5| Step: 8
Training loss: 2.179439298109559
Validation loss: 2.371541288097918

Epoch: 5| Step: 9
Training loss: 2.1480390699445624
Validation loss: 2.4152511079573937

Epoch: 5| Step: 10
Training loss: 2.2353448430231575
Validation loss: 2.558363933272675

Epoch: 189| Step: 0
Training loss: 2.0909954569624483
Validation loss: 2.8119981124243307

Epoch: 5| Step: 1
Training loss: 2.425381195939656
Validation loss: 2.9017572872189765

Epoch: 5| Step: 2
Training loss: 2.395733529928431
Validation loss: 2.8084524218569977

Epoch: 5| Step: 3
Training loss: 2.051371520334851
Validation loss: 2.6234372189944337

Epoch: 5| Step: 4
Training loss: 2.344375933670106
Validation loss: 2.489809808990396

Epoch: 5| Step: 5
Training loss: 2.5798674272882343
Validation loss: 2.4309428849142107

Epoch: 5| Step: 6
Training loss: 2.1355713827018836
Validation loss: 2.4281624677338765

Epoch: 5| Step: 7
Training loss: 2.1250815656378967
Validation loss: 2.404893964737062

Epoch: 5| Step: 8
Training loss: 2.3960153482929467
Validation loss: 2.4012343966598952

Epoch: 5| Step: 9
Training loss: 2.5705981805999
Validation loss: 2.4567589238098817

Epoch: 5| Step: 10
Training loss: 2.6333087940118913
Validation loss: 2.53492945001304

Epoch: 190| Step: 0
Training loss: 2.4923134894498333
Validation loss: 2.6557542004010415

Epoch: 5| Step: 1
Training loss: 2.2019701155974234
Validation loss: 2.6252436468648583

Epoch: 5| Step: 2
Training loss: 2.263048588121989
Validation loss: 2.6231950745464276

Epoch: 5| Step: 3
Training loss: 2.1237093427963876
Validation loss: 2.6355718850441225

Epoch: 5| Step: 4
Training loss: 2.2885437465467855
Validation loss: 2.573141820438054

Epoch: 5| Step: 5
Training loss: 2.2645564223032557
Validation loss: 2.5077507602565947

Epoch: 5| Step: 6
Training loss: 2.37282402342238
Validation loss: 2.456917129752119

Epoch: 5| Step: 7
Training loss: 2.5716857024712256
Validation loss: 2.421974770207402

Epoch: 5| Step: 8
Training loss: 2.125665672606296
Validation loss: 2.4079064414486138

Epoch: 5| Step: 9
Training loss: 2.1036901658378246
Validation loss: 2.4467147208256503

Epoch: 5| Step: 10
Training loss: 2.2564344589618224
Validation loss: 2.4461302718847153

Epoch: 191| Step: 0
Training loss: 2.4638442538506093
Validation loss: 2.5090680484952204

Epoch: 5| Step: 1
Training loss: 2.659076219353637
Validation loss: 2.683264359087245

Epoch: 5| Step: 2
Training loss: 1.9005948591116006
Validation loss: 2.819931924949988

Epoch: 5| Step: 3
Training loss: 2.673010958294111
Validation loss: 2.775033595812911

Epoch: 5| Step: 4
Training loss: 2.3813845498827284
Validation loss: 2.580214397628583

Epoch: 5| Step: 5
Training loss: 2.19571147293434
Validation loss: 2.4075173794695366

Epoch: 5| Step: 6
Training loss: 1.7124429289503664
Validation loss: 2.4062785304210226

Epoch: 5| Step: 7
Training loss: 2.177994374718946
Validation loss: 2.382912258599721

Epoch: 5| Step: 8
Training loss: 2.3922040125241453
Validation loss: 2.3930061733928873

Epoch: 5| Step: 9
Training loss: 2.2625147023434593
Validation loss: 2.4141431546034675

Epoch: 5| Step: 10
Training loss: 1.9413527053418413
Validation loss: 2.40931226388169

Epoch: 192| Step: 0
Training loss: 2.5795882263120755
Validation loss: 2.416192645987498

Epoch: 5| Step: 1
Training loss: 2.372871147525202
Validation loss: 2.479608598923161

Epoch: 5| Step: 2
Training loss: 1.698061213357122
Validation loss: 2.578937394316929

Epoch: 5| Step: 3
Training loss: 1.8928682244688502
Validation loss: 2.635182237750985

Epoch: 5| Step: 4
Training loss: 2.333447612507069
Validation loss: 2.636738194644986

Epoch: 5| Step: 5
Training loss: 2.561284218778782
Validation loss: 2.539598407842116

Epoch: 5| Step: 6
Training loss: 2.1913317227397804
Validation loss: 2.4201738462292486

Epoch: 5| Step: 7
Training loss: 2.1691783383094885
Validation loss: 2.3796744316088647

Epoch: 5| Step: 8
Training loss: 2.0281457509065186
Validation loss: 2.370477280844546

Epoch: 5| Step: 9
Training loss: 2.373216662200194
Validation loss: 2.3923434020361922

Epoch: 5| Step: 10
Training loss: 2.301922086243949
Validation loss: 2.415515833207248

Epoch: 193| Step: 0
Training loss: 2.0788488059724934
Validation loss: 2.5162645190884816

Epoch: 5| Step: 1
Training loss: 1.7797144243918195
Validation loss: 2.605349826584689

Epoch: 5| Step: 2
Training loss: 2.1106488937638543
Validation loss: 2.704918262707871

Epoch: 5| Step: 3
Training loss: 2.403804180072248
Validation loss: 2.8331072431787843

Epoch: 5| Step: 4
Training loss: 2.340099492688538
Validation loss: 2.695730797575258

Epoch: 5| Step: 5
Training loss: 2.094394641534815
Validation loss: 2.5679382894845757

Epoch: 5| Step: 6
Training loss: 2.5572625577452164
Validation loss: 2.4489519108963176

Epoch: 5| Step: 7
Training loss: 2.7104204987585105
Validation loss: 2.3729047146531226

Epoch: 5| Step: 8
Training loss: 2.0753460423200596
Validation loss: 2.3846663804040316

Epoch: 5| Step: 9
Training loss: 2.385579987866582
Validation loss: 2.414336924903099

Epoch: 5| Step: 10
Training loss: 2.3853445139360465
Validation loss: 2.391142240478578

Epoch: 194| Step: 0
Training loss: 2.149754678791419
Validation loss: 2.436818598984427

Epoch: 5| Step: 1
Training loss: 2.617198158356329
Validation loss: 2.502181444769058

Epoch: 5| Step: 2
Training loss: 2.2467351113863163
Validation loss: 2.5787116205247638

Epoch: 5| Step: 3
Training loss: 1.8939805951116353
Validation loss: 2.6001886619607006

Epoch: 5| Step: 4
Training loss: 2.2597620377969583
Validation loss: 2.573504053364727

Epoch: 5| Step: 5
Training loss: 2.533223642517623
Validation loss: 2.5662584911417525

Epoch: 5| Step: 6
Training loss: 1.9806534720505313
Validation loss: 2.53673281732843

Epoch: 5| Step: 7
Training loss: 2.2641188251868383
Validation loss: 2.5041618560334764

Epoch: 5| Step: 8
Training loss: 2.383623429185207
Validation loss: 2.4877901591230627

Epoch: 5| Step: 9
Training loss: 1.9425905480017318
Validation loss: 2.4525833571742757

Epoch: 5| Step: 10
Training loss: 1.5770511561764216
Validation loss: 2.4481687319562324

Epoch: 195| Step: 0
Training loss: 2.3039910767501652
Validation loss: 2.4477272140161577

Epoch: 5| Step: 1
Training loss: 2.0107265358788604
Validation loss: 2.487212140102679

Epoch: 5| Step: 2
Training loss: 1.9067801066755503
Validation loss: 2.5070398619106316

Epoch: 5| Step: 3
Training loss: 1.8080711186355323
Validation loss: 2.586078198436373

Epoch: 5| Step: 4
Training loss: 2.700783040269827
Validation loss: 2.660751743764998

Epoch: 5| Step: 5
Training loss: 2.593989533543703
Validation loss: 2.596023518932751

Epoch: 5| Step: 6
Training loss: 1.6353591698260375
Validation loss: 2.5530734460557682

Epoch: 5| Step: 7
Training loss: 1.8187121121894296
Validation loss: 2.449598059499236

Epoch: 5| Step: 8
Training loss: 2.178021631839263
Validation loss: 2.4253988034690477

Epoch: 5| Step: 9
Training loss: 2.3333597408798514
Validation loss: 2.383129675574204

Epoch: 5| Step: 10
Training loss: 2.242250129276935
Validation loss: 2.372730309397755

Epoch: 196| Step: 0
Training loss: 2.024730372433497
Validation loss: 2.412362021967333

Epoch: 5| Step: 1
Training loss: 2.300239123477601
Validation loss: 2.4926448308155273

Epoch: 5| Step: 2
Training loss: 2.043993486838219
Validation loss: 2.5728686652343864

Epoch: 5| Step: 3
Training loss: 2.047298591405119
Validation loss: 2.636601079565808

Epoch: 5| Step: 4
Training loss: 1.8041059209216124
Validation loss: 2.7222700234807045

Epoch: 5| Step: 5
Training loss: 2.5698271411992932
Validation loss: 2.6180971644135114

Epoch: 5| Step: 6
Training loss: 1.9375707551895922
Validation loss: 2.582558248341263

Epoch: 5| Step: 7
Training loss: 1.8248116226170663
Validation loss: 2.4873278325720745

Epoch: 5| Step: 8
Training loss: 2.629728327596851
Validation loss: 2.4820183584249844

Epoch: 5| Step: 9
Training loss: 1.9672111067442468
Validation loss: 2.482267452072638

Epoch: 5| Step: 10
Training loss: 2.1468377833354206
Validation loss: 2.468359098358209

Epoch: 197| Step: 0
Training loss: 2.1279430205166854
Validation loss: 2.389765123208295

Epoch: 5| Step: 1
Training loss: 2.123283927478431
Validation loss: 2.4076111204941872

Epoch: 5| Step: 2
Training loss: 2.097025799623044
Validation loss: 2.365330546107418

Epoch: 5| Step: 3
Training loss: 2.6274978923698415
Validation loss: 2.4196169019436544

Epoch: 5| Step: 4
Training loss: 1.7937284700915894
Validation loss: 2.506801889340781

Epoch: 5| Step: 5
Training loss: 1.8161685911181638
Validation loss: 2.598164464393445

Epoch: 5| Step: 6
Training loss: 2.2396312856345935
Validation loss: 2.667069806177069

Epoch: 5| Step: 7
Training loss: 2.12434175057357
Validation loss: 2.720687281603212

Epoch: 5| Step: 8
Training loss: 2.3700430488700652
Validation loss: 2.6535150450901592

Epoch: 5| Step: 9
Training loss: 2.1597926573666606
Validation loss: 2.547943414054307

Epoch: 5| Step: 10
Training loss: 1.816931207743396
Validation loss: 2.41996038669222

Epoch: 198| Step: 0
Training loss: 2.3544025696795194
Validation loss: 2.4595186741756248

Epoch: 5| Step: 1
Training loss: 2.4266821621131123
Validation loss: 2.464652508868228

Epoch: 5| Step: 2
Training loss: 2.0935979759480565
Validation loss: 2.4733152473157056

Epoch: 5| Step: 3
Training loss: 2.3296505838765915
Validation loss: 2.479846232146305

Epoch: 5| Step: 4
Training loss: 1.7629677686119711
Validation loss: 2.5143966412066194

Epoch: 5| Step: 5
Training loss: 1.962403558681821
Validation loss: 2.486486716796901

Epoch: 5| Step: 6
Training loss: 2.08636310250239
Validation loss: 2.54862904801957

Epoch: 5| Step: 7
Training loss: 1.612865773196844
Validation loss: 2.5320518354940558

Epoch: 5| Step: 8
Training loss: 2.5523274103861264
Validation loss: 2.541072944221057

Epoch: 5| Step: 9
Training loss: 1.9868997447155046
Validation loss: 2.5509842381653627

Epoch: 5| Step: 10
Training loss: 1.4831611086842031
Validation loss: 2.521303690473703

Epoch: 199| Step: 0
Training loss: 1.4870156341018181
Validation loss: 2.466675351462115

Epoch: 5| Step: 1
Training loss: 1.6134912386509477
Validation loss: 2.5457380122246787

Epoch: 5| Step: 2
Training loss: 2.288622192114401
Validation loss: 2.544839091206599

Epoch: 5| Step: 3
Training loss: 1.9578708819599508
Validation loss: 2.5890228015152545

Epoch: 5| Step: 4
Training loss: 2.683067036875008
Validation loss: 2.5459832399903464

Epoch: 5| Step: 5
Training loss: 2.082358500973045
Validation loss: 2.461985764676354

Epoch: 5| Step: 6
Training loss: 1.7422300598693765
Validation loss: 2.4868980088231716

Epoch: 5| Step: 7
Training loss: 2.402979027093428
Validation loss: 2.534470031647075

Epoch: 5| Step: 8
Training loss: 1.3975131426962644
Validation loss: 2.5550070972246526

Epoch: 5| Step: 9
Training loss: 2.450813419226979
Validation loss: 2.584954566476168

Epoch: 5| Step: 10
Training loss: 2.3104140694147572
Validation loss: 2.5701295077057322

Epoch: 200| Step: 0
Training loss: 2.326151376116648
Validation loss: 2.4285432576813433

Epoch: 5| Step: 1
Training loss: 1.4732855709383554
Validation loss: 2.396623180750279

Epoch: 5| Step: 2
Training loss: 2.058894386995544
Validation loss: 2.357260730503018

Epoch: 5| Step: 3
Training loss: 2.1444980083731155
Validation loss: 2.3725243928427435

Epoch: 5| Step: 4
Training loss: 2.240921035001797
Validation loss: 2.331687884516082

Epoch: 5| Step: 5
Training loss: 2.0035726109620935
Validation loss: 2.428101401922357

Epoch: 5| Step: 6
Training loss: 1.9664933122860155
Validation loss: 2.4885410415271654

Epoch: 5| Step: 7
Training loss: 2.1723236059783027
Validation loss: 2.6501110762931317

Epoch: 5| Step: 8
Training loss: 1.896607258485869
Validation loss: 2.7977461652878333

Epoch: 5| Step: 9
Training loss: 2.389112405399194
Validation loss: 2.9981788342466915

Epoch: 5| Step: 10
Training loss: 2.1234216999647875
Validation loss: 2.8172065922449834

Epoch: 201| Step: 0
Training loss: 1.9973600965450335
Validation loss: 2.587912985391074

Epoch: 5| Step: 1
Training loss: 2.424139723625312
Validation loss: 2.4404386308080865

Epoch: 5| Step: 2
Training loss: 2.280440722584385
Validation loss: 2.4041648122002934

Epoch: 5| Step: 3
Training loss: 1.7302356158208287
Validation loss: 2.401581584976734

Epoch: 5| Step: 4
Training loss: 1.882755389475197
Validation loss: 2.4027191581105978

Epoch: 5| Step: 5
Training loss: 2.385197180988105
Validation loss: 2.466042674478041

Epoch: 5| Step: 6
Training loss: 1.4090433986686375
Validation loss: 2.606569800423548

Epoch: 5| Step: 7
Training loss: 2.2655930089336227
Validation loss: 2.61700493670642

Epoch: 5| Step: 8
Training loss: 2.0088333325290177
Validation loss: 2.5152468301866246

Epoch: 5| Step: 9
Training loss: 2.0310475175145704
Validation loss: 2.461424362169482

Epoch: 5| Step: 10
Training loss: 1.9451747370584551
Validation loss: 2.4045923449880537

Epoch: 202| Step: 0
Training loss: 1.8432575149993455
Validation loss: 2.3461060886505867

Epoch: 5| Step: 1
Training loss: 2.2833039952456153
Validation loss: 2.3587068207714332

Epoch: 5| Step: 2
Training loss: 1.818339445043841
Validation loss: 2.34476758271475

Epoch: 5| Step: 3
Training loss: 2.1671118890159224
Validation loss: 2.3943553594244946

Epoch: 5| Step: 4
Training loss: 2.130255651220502
Validation loss: 2.4961292917076805

Epoch: 5| Step: 5
Training loss: 1.802291733115567
Validation loss: 2.6315390030452908

Epoch: 5| Step: 6
Training loss: 2.489975476737845
Validation loss: 2.7886967283428774

Epoch: 5| Step: 7
Training loss: 2.03786600020164
Validation loss: 2.7245547446119147

Epoch: 5| Step: 8
Training loss: 1.9393677476605342
Validation loss: 2.6049390616237327

Epoch: 5| Step: 9
Training loss: 1.8526128051430577
Validation loss: 2.5119982811563526

Epoch: 5| Step: 10
Training loss: 2.2708363547582096
Validation loss: 2.4321921745586206

Epoch: 203| Step: 0
Training loss: 1.8247101017877898
Validation loss: 2.3862493916939007

Epoch: 5| Step: 1
Training loss: 2.003107279730391
Validation loss: 2.4390583026705848

Epoch: 5| Step: 2
Training loss: 2.467666098309859
Validation loss: 2.5142981106778537

Epoch: 5| Step: 3
Training loss: 1.5980006362092587
Validation loss: 2.6267635917671517

Epoch: 5| Step: 4
Training loss: 2.451459574438253
Validation loss: 2.6675287674637427

Epoch: 5| Step: 5
Training loss: 1.8257253172259953
Validation loss: 2.5059387671711266

Epoch: 5| Step: 6
Training loss: 2.1910890835890036
Validation loss: 2.4197967154482543

Epoch: 5| Step: 7
Training loss: 1.843538304476482
Validation loss: 2.395856463591289

Epoch: 5| Step: 8
Training loss: 2.4291851346168345
Validation loss: 2.3880255519035614

Epoch: 5| Step: 9
Training loss: 1.9804151779844452
Validation loss: 2.439154983117462

Epoch: 5| Step: 10
Training loss: 2.0846214000096452
Validation loss: 2.52522984813683

Epoch: 204| Step: 0
Training loss: 1.9798476469784163
Validation loss: 2.533325848125783

Epoch: 5| Step: 1
Training loss: 2.13592492234518
Validation loss: 2.533300033743393

Epoch: 5| Step: 2
Training loss: 2.3037447795508643
Validation loss: 2.5562932048297227

Epoch: 5| Step: 3
Training loss: 2.3135688991967727
Validation loss: 2.654242828634314

Epoch: 5| Step: 4
Training loss: 1.3378891993605544
Validation loss: 2.5954693125422628

Epoch: 5| Step: 5
Training loss: 1.97552565568945
Validation loss: 2.4476934145724636

Epoch: 5| Step: 6
Training loss: 1.955994352266236
Validation loss: 2.443130901255051

Epoch: 5| Step: 7
Training loss: 2.152303982625193
Validation loss: 2.4421112914264835

Epoch: 5| Step: 8
Training loss: 1.9492477384257898
Validation loss: 2.39731792947971

Epoch: 5| Step: 9
Training loss: 1.9098242098615366
Validation loss: 2.361555466851087

Epoch: 5| Step: 10
Training loss: 2.003498712633032
Validation loss: 2.3540812491484835

Epoch: 205| Step: 0
Training loss: 2.4169874526468775
Validation loss: 2.3422353442928836

Epoch: 5| Step: 1
Training loss: 1.881604958945182
Validation loss: 2.3868959905954212

Epoch: 5| Step: 2
Training loss: 1.7480816544637174
Validation loss: 2.432045752987525

Epoch: 5| Step: 3
Training loss: 1.983395913149243
Validation loss: 2.5599208731209004

Epoch: 5| Step: 4
Training loss: 2.4531541567485036
Validation loss: 2.6895646456205227

Epoch: 5| Step: 5
Training loss: 1.6774926327857709
Validation loss: 2.720966066309056

Epoch: 5| Step: 6
Training loss: 1.9584984675915869
Validation loss: 2.719432348673262

Epoch: 5| Step: 7
Training loss: 2.333387124486052
Validation loss: 2.5246805725493675

Epoch: 5| Step: 8
Training loss: 1.8407641010151021
Validation loss: 2.4046590782518473

Epoch: 5| Step: 9
Training loss: 2.0222358817849044
Validation loss: 2.38049490260802

Epoch: 5| Step: 10
Training loss: 1.817199665005901
Validation loss: 2.3673922607469193

Epoch: 206| Step: 0
Training loss: 1.9639718337515768
Validation loss: 2.398174719754496

Epoch: 5| Step: 1
Training loss: 1.7987344160326075
Validation loss: 2.4321445544356384

Epoch: 5| Step: 2
Training loss: 2.1725127018073245
Validation loss: 2.6038208552632853

Epoch: 5| Step: 3
Training loss: 1.9877668813344358
Validation loss: 2.612802047174527

Epoch: 5| Step: 4
Training loss: 1.7847078457198462
Validation loss: 2.678111085960757

Epoch: 5| Step: 5
Training loss: 1.9014259333222208
Validation loss: 2.689148413809813

Epoch: 5| Step: 6
Training loss: 2.17916524776415
Validation loss: 2.6392641356252198

Epoch: 5| Step: 7
Training loss: 2.1145401622956763
Validation loss: 2.5124445194083203

Epoch: 5| Step: 8
Training loss: 1.9140374629660337
Validation loss: 2.4394473124213105

Epoch: 5| Step: 9
Training loss: 1.9482972560356329
Validation loss: 2.4079870126646763

Epoch: 5| Step: 10
Training loss: 1.9980789137254422
Validation loss: 2.3780529653207534

Epoch: 207| Step: 0
Training loss: 1.7897736581026549
Validation loss: 2.391582569886075

Epoch: 5| Step: 1
Training loss: 2.0815374135841016
Validation loss: 2.4267185455847455

Epoch: 5| Step: 2
Training loss: 1.7012537204048683
Validation loss: 2.4784586743356525

Epoch: 5| Step: 3
Training loss: 1.8548990439116215
Validation loss: 2.545773521953168

Epoch: 5| Step: 4
Training loss: 2.3428542396314755
Validation loss: 2.556878888505502

Epoch: 5| Step: 5
Training loss: 1.6287963244627157
Validation loss: 2.513982906550141

Epoch: 5| Step: 6
Training loss: 1.4278032570646417
Validation loss: 2.433604461336112

Epoch: 5| Step: 7
Training loss: 1.895121814667487
Validation loss: 2.3917047865093126

Epoch: 5| Step: 8
Training loss: 2.4582630944859067
Validation loss: 2.411854687309634

Epoch: 5| Step: 9
Training loss: 1.9995879702531845
Validation loss: 2.4336984057820428

Epoch: 5| Step: 10
Training loss: 2.086540335080003
Validation loss: 2.5522588177725303

Epoch: 208| Step: 0
Training loss: 2.0653249871881805
Validation loss: 2.6337356197861026

Epoch: 5| Step: 1
Training loss: 1.2909348732398225
Validation loss: 2.622472832786344

Epoch: 5| Step: 2
Training loss: 2.524036348223238
Validation loss: 2.6107640319015952

Epoch: 5| Step: 3
Training loss: 2.390901636810234
Validation loss: 2.4988355047192607

Epoch: 5| Step: 4
Training loss: 1.8404534174115865
Validation loss: 2.39198579877525

Epoch: 5| Step: 5
Training loss: 1.4691949535610358
Validation loss: 2.353556648066727

Epoch: 5| Step: 6
Training loss: 2.3145376970637463
Validation loss: 2.3570705395710836

Epoch: 5| Step: 7
Training loss: 1.7742502643939226
Validation loss: 2.453776820371196

Epoch: 5| Step: 8
Training loss: 1.6060299971309908
Validation loss: 2.597642324729355

Epoch: 5| Step: 9
Training loss: 2.144543812754927
Validation loss: 2.7112401717840253

Epoch: 5| Step: 10
Training loss: 1.7978261006141045
Validation loss: 2.6804265541281755

Epoch: 209| Step: 0
Training loss: 1.9868805453789176
Validation loss: 2.569568715799057

Epoch: 5| Step: 1
Training loss: 1.886975320307951
Validation loss: 2.454414539245806

Epoch: 5| Step: 2
Training loss: 2.1848200048686657
Validation loss: 2.422320687114444

Epoch: 5| Step: 3
Training loss: 2.0713917348433264
Validation loss: 2.372449374197812

Epoch: 5| Step: 4
Training loss: 1.7937949942551392
Validation loss: 2.404783544902679

Epoch: 5| Step: 5
Training loss: 1.715890412915088
Validation loss: 2.3773840848078827

Epoch: 5| Step: 6
Training loss: 1.7682218106715626
Validation loss: 2.4091439798426886

Epoch: 5| Step: 7
Training loss: 2.0026983892914227
Validation loss: 2.4688521177543605

Epoch: 5| Step: 8
Training loss: 1.9851833108966408
Validation loss: 2.5732147391547966

Epoch: 5| Step: 9
Training loss: 2.2189551245203245
Validation loss: 2.7493206669205823

Epoch: 5| Step: 10
Training loss: 1.6902856087727431
Validation loss: 2.688420147972512

Epoch: 210| Step: 0
Training loss: 2.4933570341863915
Validation loss: 2.6089660960785928

Epoch: 5| Step: 1
Training loss: 2.409841458182812
Validation loss: 2.551446978900179

Epoch: 5| Step: 2
Training loss: 2.201292750535369
Validation loss: 2.4294017914849304

Epoch: 5| Step: 3
Training loss: 1.9432549683401712
Validation loss: 2.4326233810338254

Epoch: 5| Step: 4
Training loss: 1.5586297740931998
Validation loss: 2.3830439145370788

Epoch: 5| Step: 5
Training loss: 1.8606059383585833
Validation loss: 2.4065365087379447

Epoch: 5| Step: 6
Training loss: 1.3751583441679467
Validation loss: 2.429197527560773

Epoch: 5| Step: 7
Training loss: 1.743488732457161
Validation loss: 2.500053489276911

Epoch: 5| Step: 8
Training loss: 1.6369540607575521
Validation loss: 2.5215561207767303

Epoch: 5| Step: 9
Training loss: 1.7199000585707176
Validation loss: 2.638192135856992

Epoch: 5| Step: 10
Training loss: 1.8842402066784434
Validation loss: 2.7206772637684615

Epoch: 211| Step: 0
Training loss: 1.8071132062442836
Validation loss: 2.750241978385234

Epoch: 5| Step: 1
Training loss: 2.571800844553367
Validation loss: 2.714941362945728

Epoch: 5| Step: 2
Training loss: 1.8617273404927304
Validation loss: 2.622981090553166

Epoch: 5| Step: 3
Training loss: 1.7092093880886339
Validation loss: 2.6003025833324247

Epoch: 5| Step: 4
Training loss: 1.9003297143252755
Validation loss: 2.4969768868028694

Epoch: 5| Step: 5
Training loss: 2.0771700163430133
Validation loss: 2.4801400385811023

Epoch: 5| Step: 6
Training loss: 1.7575415508410432
Validation loss: 2.406629092768232

Epoch: 5| Step: 7
Training loss: 1.6578504638927096
Validation loss: 2.3896449562264404

Epoch: 5| Step: 8
Training loss: 1.8471555132122022
Validation loss: 2.3968473588237122

Epoch: 5| Step: 9
Training loss: 1.769026795960092
Validation loss: 2.462589742798081

Epoch: 5| Step: 10
Training loss: 1.6319769222553884
Validation loss: 2.499864288461251

Epoch: 212| Step: 0
Training loss: 1.8847732148487077
Validation loss: 2.4810344298742604

Epoch: 5| Step: 1
Training loss: 1.873832529908538
Validation loss: 2.417410666693506

Epoch: 5| Step: 2
Training loss: 1.7620314766695202
Validation loss: 2.3679036141907153

Epoch: 5| Step: 3
Training loss: 1.7869196556571663
Validation loss: 2.3879825186702184

Epoch: 5| Step: 4
Training loss: 1.606828619496448
Validation loss: 2.45309423507441

Epoch: 5| Step: 5
Training loss: 1.8551574445881447
Validation loss: 2.5430852658765857

Epoch: 5| Step: 6
Training loss: 1.6316252412041115
Validation loss: 2.562951010995144

Epoch: 5| Step: 7
Training loss: 2.079849101608438
Validation loss: 2.5464966175396455

Epoch: 5| Step: 8
Training loss: 1.9363162208300484
Validation loss: 2.4860079555574752

Epoch: 5| Step: 9
Training loss: 1.796455865158066
Validation loss: 2.4589811878896706

Epoch: 5| Step: 10
Training loss: 2.4282902566845728
Validation loss: 2.476394123287519

Epoch: 213| Step: 0
Training loss: 1.9510017756185658
Validation loss: 2.413188640896075

Epoch: 5| Step: 1
Training loss: 1.725579858152845
Validation loss: 2.4041140723346204

Epoch: 5| Step: 2
Training loss: 1.739027775968751
Validation loss: 2.369986797323854

Epoch: 5| Step: 3
Training loss: 1.9153115692858396
Validation loss: 2.361265006128021

Epoch: 5| Step: 4
Training loss: 2.110594333451876
Validation loss: 2.4162439486508234

Epoch: 5| Step: 5
Training loss: 1.6527787305613673
Validation loss: 2.5667200133164485

Epoch: 5| Step: 6
Training loss: 1.816143582948633
Validation loss: 2.7064421633574587

Epoch: 5| Step: 7
Training loss: 2.101288504625005
Validation loss: 2.76615978178313

Epoch: 5| Step: 8
Training loss: 2.164021295368667
Validation loss: 2.7606536491086278

Epoch: 5| Step: 9
Training loss: 1.8047803054000473
Validation loss: 2.5545396654472

Epoch: 5| Step: 10
Training loss: 1.8967260487629167
Validation loss: 2.4338579084691765

Epoch: 214| Step: 0
Training loss: 1.930912879728856
Validation loss: 2.358727118242256

Epoch: 5| Step: 1
Training loss: 1.8204593844766697
Validation loss: 2.4113239615981645

Epoch: 5| Step: 2
Training loss: 1.5192195307827607
Validation loss: 2.4872057964755485

Epoch: 5| Step: 3
Training loss: 1.8538079789934383
Validation loss: 2.5764777585731022

Epoch: 5| Step: 4
Training loss: 1.5537605781225778
Validation loss: 2.6557317547906947

Epoch: 5| Step: 5
Training loss: 1.7546917827822288
Validation loss: 2.673655136364573

Epoch: 5| Step: 6
Training loss: 1.6890805224957777
Validation loss: 2.6324373673411614

Epoch: 5| Step: 7
Training loss: 2.14229067853755
Validation loss: 2.5765622555720116

Epoch: 5| Step: 8
Training loss: 1.5692871693865404
Validation loss: 2.4638348091746267

Epoch: 5| Step: 9
Training loss: 2.3185393368837297
Validation loss: 2.3987619086367764

Epoch: 5| Step: 10
Training loss: 2.267313676473909
Validation loss: 2.3356500999538587

Epoch: 215| Step: 0
Training loss: 1.5723847338181611
Validation loss: 2.3620857313951937

Epoch: 5| Step: 1
Training loss: 1.8567300143755308
Validation loss: 2.4116329354131953

Epoch: 5| Step: 2
Training loss: 1.4705520288834804
Validation loss: 2.454467465152905

Epoch: 5| Step: 3
Training loss: 1.913861197960446
Validation loss: 2.5109218197588024

Epoch: 5| Step: 4
Training loss: 2.1484788925344973
Validation loss: 2.535342526939135

Epoch: 5| Step: 5
Training loss: 1.9497415762615518
Validation loss: 2.584983983734339

Epoch: 5| Step: 6
Training loss: 1.5140298530830267
Validation loss: 2.4978166285339127

Epoch: 5| Step: 7
Training loss: 1.8100973844938062
Validation loss: 2.4703998569400922

Epoch: 5| Step: 8
Training loss: 1.7825762847156608
Validation loss: 2.415625235008561

Epoch: 5| Step: 9
Training loss: 2.2019758541713204
Validation loss: 2.4218911267344705

Epoch: 5| Step: 10
Training loss: 1.815027841927177
Validation loss: 2.4401149180647965

Epoch: 216| Step: 0
Training loss: 2.0074206018007734
Validation loss: 2.5389457621530283

Epoch: 5| Step: 1
Training loss: 2.2725796998403522
Validation loss: 2.5816903021623756

Epoch: 5| Step: 2
Training loss: 1.6458119821571913
Validation loss: 2.5829883395357207

Epoch: 5| Step: 3
Training loss: 1.9400991418419269
Validation loss: 2.610443609697516

Epoch: 5| Step: 4
Training loss: 1.615355407534629
Validation loss: 2.572022701769901

Epoch: 5| Step: 5
Training loss: 1.3262616269018148
Validation loss: 2.4627077953514935

Epoch: 5| Step: 6
Training loss: 1.9894130760429662
Validation loss: 2.3683388110513417

Epoch: 5| Step: 7
Training loss: 1.9566304601647837
Validation loss: 2.3572111844335795

Epoch: 5| Step: 8
Training loss: 1.6761176920880922
Validation loss: 2.398563980380947

Epoch: 5| Step: 9
Training loss: 1.7812300563833487
Validation loss: 2.4629121696034226

Epoch: 5| Step: 10
Training loss: 1.6677424614595404
Validation loss: 2.5583204954973677

Epoch: 217| Step: 0
Training loss: 1.580520850778079
Validation loss: 2.601849987313018

Epoch: 5| Step: 1
Training loss: 2.2122930138961014
Validation loss: 2.5939998790506182

Epoch: 5| Step: 2
Training loss: 1.967814510853906
Validation loss: 2.6060428369731867

Epoch: 5| Step: 3
Training loss: 1.8612413416162163
Validation loss: 2.624527433080768

Epoch: 5| Step: 4
Training loss: 1.902170098934733
Validation loss: 2.5832062799831847

Epoch: 5| Step: 5
Training loss: 1.811104269963913
Validation loss: 2.4452263659237907

Epoch: 5| Step: 6
Training loss: 1.5503318000796265
Validation loss: 2.3729658655778256

Epoch: 5| Step: 7
Training loss: 1.7721627649294016
Validation loss: 2.32922291914944

Epoch: 5| Step: 8
Training loss: 1.9144808565040954
Validation loss: 2.3008489339920537

Epoch: 5| Step: 9
Training loss: 1.6705886312822442
Validation loss: 2.3524492580273435

Epoch: 5| Step: 10
Training loss: 1.6577725879348184
Validation loss: 2.371151869512745

Epoch: 218| Step: 0
Training loss: 1.893012627798805
Validation loss: 2.4307902349883537

Epoch: 5| Step: 1
Training loss: 1.7667263950591725
Validation loss: 2.5033379994378633

Epoch: 5| Step: 2
Training loss: 1.2946099413365864
Validation loss: 2.5935924871134275

Epoch: 5| Step: 3
Training loss: 1.919954844877613
Validation loss: 2.6868177140724514

Epoch: 5| Step: 4
Training loss: 1.8494429548695603
Validation loss: 2.7269118449829133

Epoch: 5| Step: 5
Training loss: 1.7942159466222016
Validation loss: 2.6791335715218403

Epoch: 5| Step: 6
Training loss: 2.161925544952963
Validation loss: 2.642426800007119

Epoch: 5| Step: 7
Training loss: 1.818400938745232
Validation loss: 2.5350239566872323

Epoch: 5| Step: 8
Training loss: 1.7818819230131482
Validation loss: 2.4154611097521923

Epoch: 5| Step: 9
Training loss: 1.876750256295604
Validation loss: 2.3755017529373

Epoch: 5| Step: 10
Training loss: 1.508562603100025
Validation loss: 2.3263977563238343

Epoch: 219| Step: 0
Training loss: 1.8647750528608582
Validation loss: 2.4085465589283

Epoch: 5| Step: 1
Training loss: 1.2196275534963272
Validation loss: 2.5429903097561786

Epoch: 5| Step: 2
Training loss: 2.135587905592895
Validation loss: 2.679066842806133

Epoch: 5| Step: 3
Training loss: 1.9695689602139057
Validation loss: 2.7520136215088553

Epoch: 5| Step: 4
Training loss: 0.951062675959883
Validation loss: 2.728274401422548

Epoch: 5| Step: 5
Training loss: 1.8421578726032126
Validation loss: 2.678336299922649

Epoch: 5| Step: 6
Training loss: 2.13206664517643
Validation loss: 2.4906782117230186

Epoch: 5| Step: 7
Training loss: 1.9134737938929713
Validation loss: 2.4047946180298347

Epoch: 5| Step: 8
Training loss: 1.5792113993137633
Validation loss: 2.3487540299158467

Epoch: 5| Step: 9
Training loss: 2.1056539988367944
Validation loss: 2.361255164178586

Epoch: 5| Step: 10
Training loss: 2.361676337958836
Validation loss: 2.398886626760647

Epoch: 220| Step: 0
Training loss: 1.543308655203038
Validation loss: 2.5667457063259316

Epoch: 5| Step: 1
Training loss: 2.2042218447186444
Validation loss: 2.740692560425339

Epoch: 5| Step: 2
Training loss: 1.977640935840493
Validation loss: 2.818719514853346

Epoch: 5| Step: 3
Training loss: 1.7555731857329324
Validation loss: 2.735385323020714

Epoch: 5| Step: 4
Training loss: 1.7186633695097775
Validation loss: 2.5698769574999814

Epoch: 5| Step: 5
Training loss: 1.6971598461625568
Validation loss: 2.432086856292085

Epoch: 5| Step: 6
Training loss: 2.210132897295105
Validation loss: 2.333614060731926

Epoch: 5| Step: 7
Training loss: 1.392666208014832
Validation loss: 2.336880240042563

Epoch: 5| Step: 8
Training loss: 1.5383868598235964
Validation loss: 2.355238249623583

Epoch: 5| Step: 9
Training loss: 1.982539612228819
Validation loss: 2.490702580658619

Epoch: 5| Step: 10
Training loss: 1.6579539333059286
Validation loss: 2.635433440321439

Epoch: 221| Step: 0
Training loss: 1.9065114451739396
Validation loss: 2.772516272604451

Epoch: 5| Step: 1
Training loss: 1.8999413079683185
Validation loss: 2.7589197695390144

Epoch: 5| Step: 2
Training loss: 2.043478790860103
Validation loss: 2.7498863165020855

Epoch: 5| Step: 3
Training loss: 1.8528140702983285
Validation loss: 2.569182560649008

Epoch: 5| Step: 4
Training loss: 1.2098818700047331
Validation loss: 2.419667267981527

Epoch: 5| Step: 5
Training loss: 1.6162210423824972
Validation loss: 2.3213890862039572

Epoch: 5| Step: 6
Training loss: 2.0576354950686495
Validation loss: 2.2656979637858172

Epoch: 5| Step: 7
Training loss: 1.919404900335647
Validation loss: 2.3274214477719535

Epoch: 5| Step: 8
Training loss: 2.015046502421566
Validation loss: 2.4065374104992037

Epoch: 5| Step: 9
Training loss: 1.7030909123640399
Validation loss: 2.564778791102177

Epoch: 5| Step: 10
Training loss: 1.6259273670532577
Validation loss: 2.62118504635442

Epoch: 222| Step: 0
Training loss: 2.1662365290800203
Validation loss: 2.5893116127762594

Epoch: 5| Step: 1
Training loss: 1.7394146256862593
Validation loss: 2.593777979237664

Epoch: 5| Step: 2
Training loss: 1.3254735622208478
Validation loss: 2.5495460968464827

Epoch: 5| Step: 3
Training loss: 1.6672360957462955
Validation loss: 2.506449729889005

Epoch: 5| Step: 4
Training loss: 1.4342166056888657
Validation loss: 2.5005952854427433

Epoch: 5| Step: 5
Training loss: 2.138564294347577
Validation loss: 2.450271327146419

Epoch: 5| Step: 6
Training loss: 1.0737845913307784
Validation loss: 2.435885113990148

Epoch: 5| Step: 7
Training loss: 1.8450451197702558
Validation loss: 2.492478981528057

Epoch: 5| Step: 8
Training loss: 1.9834320351005625
Validation loss: 2.539040006249231

Epoch: 5| Step: 9
Training loss: 2.0153691329014163
Validation loss: 2.541634742163797

Epoch: 5| Step: 10
Training loss: 1.4538914289749094
Validation loss: 2.616844991116718

Epoch: 223| Step: 0
Training loss: 1.5365104623345873
Validation loss: 2.60283265694468

Epoch: 5| Step: 1
Training loss: 1.6401215280304642
Validation loss: 2.554785866142053

Epoch: 5| Step: 2
Training loss: 1.7817817028271283
Validation loss: 2.519086716929858

Epoch: 5| Step: 3
Training loss: 1.927111740590261
Validation loss: 2.5198598426273326

Epoch: 5| Step: 4
Training loss: 1.4479529104110473
Validation loss: 2.4548431309341416

Epoch: 5| Step: 5
Training loss: 1.8486473860773278
Validation loss: 2.4378134013535075

Epoch: 5| Step: 6
Training loss: 1.256424274028281
Validation loss: 2.480415173256291

Epoch: 5| Step: 7
Training loss: 1.8875396395935602
Validation loss: 2.5467875747678783

Epoch: 5| Step: 8
Training loss: 1.7875655128904693
Validation loss: 2.6035733485158064

Epoch: 5| Step: 9
Training loss: 1.6532502269366882
Validation loss: 2.649937900582566

Epoch: 5| Step: 10
Training loss: 2.1574713523615987
Validation loss: 2.6245165221925597

Epoch: 224| Step: 0
Training loss: 2.1622597798013725
Validation loss: 2.5132298941058724

Epoch: 5| Step: 1
Training loss: 1.7097137115594485
Validation loss: 2.501318676089327

Epoch: 5| Step: 2
Training loss: 1.7172720363312088
Validation loss: 2.4865687400102634

Epoch: 5| Step: 3
Training loss: 1.7378806349059277
Validation loss: 2.4709243202635336

Epoch: 5| Step: 4
Training loss: 1.6937287839567219
Validation loss: 2.447158944059647

Epoch: 5| Step: 5
Training loss: 1.7437922865686408
Validation loss: 2.4567914759988394

Epoch: 5| Step: 6
Training loss: 1.3045262219917757
Validation loss: 2.5324201432712705

Epoch: 5| Step: 7
Training loss: 1.7331322006147538
Validation loss: 2.5147342244883184

Epoch: 5| Step: 8
Training loss: 1.697242938593527
Validation loss: 2.494987123217645

Epoch: 5| Step: 9
Training loss: 1.7911934634308768
Validation loss: 2.466794934702849

Epoch: 5| Step: 10
Training loss: 1.3889052654996281
Validation loss: 2.485467242555358

Epoch: 225| Step: 0
Training loss: 1.6849898990588696
Validation loss: 2.4997441930026834

Epoch: 5| Step: 1
Training loss: 1.5767681218356844
Validation loss: 2.4998761525805437

Epoch: 5| Step: 2
Training loss: 1.7945750900845654
Validation loss: 2.534071447336339

Epoch: 5| Step: 3
Training loss: 1.6863679974375023
Validation loss: 2.470244978253263

Epoch: 5| Step: 4
Training loss: 1.6550578739384962
Validation loss: 2.4438079469174796

Epoch: 5| Step: 5
Training loss: 1.9745915050811083
Validation loss: 2.399198454612899

Epoch: 5| Step: 6
Training loss: 1.5119713860483617
Validation loss: 2.3802419260558576

Epoch: 5| Step: 7
Training loss: 1.8258630828082003
Validation loss: 2.437488346582095

Epoch: 5| Step: 8
Training loss: 1.6885270419498393
Validation loss: 2.4861273461884554

Epoch: 5| Step: 9
Training loss: 1.756040434365295
Validation loss: 2.5740591361311926

Epoch: 5| Step: 10
Training loss: 1.4032194755709828
Validation loss: 2.6665662024272687

Epoch: 226| Step: 0
Training loss: 1.4873352248024352
Validation loss: 2.681673088552703

Epoch: 5| Step: 1
Training loss: 1.4004681298423618
Validation loss: 2.6491827763608624

Epoch: 5| Step: 2
Training loss: 1.722303497112626
Validation loss: 2.640909884291848

Epoch: 5| Step: 3
Training loss: 2.117683605894727
Validation loss: 2.614741759155268

Epoch: 5| Step: 4
Training loss: 1.764054266451736
Validation loss: 2.5504377117725077

Epoch: 5| Step: 5
Training loss: 1.7674636719462666
Validation loss: 2.481253400234964

Epoch: 5| Step: 6
Training loss: 1.9271175553316047
Validation loss: 2.45154833283583

Epoch: 5| Step: 7
Training loss: 1.770053542237894
Validation loss: 2.425502847849963

Epoch: 5| Step: 8
Training loss: 1.6470607413953946
Validation loss: 2.44604926653861

Epoch: 5| Step: 9
Training loss: 1.1387207125468328
Validation loss: 2.4529078246170934

Epoch: 5| Step: 10
Training loss: 1.5471591881072635
Validation loss: 2.420502760364928

Epoch: 227| Step: 0
Training loss: 1.435836991039598
Validation loss: 2.3896555985013146

Epoch: 5| Step: 1
Training loss: 1.606909112735125
Validation loss: 2.3767312469628803

Epoch: 5| Step: 2
Training loss: 1.3899661442866813
Validation loss: 2.3965411267376844

Epoch: 5| Step: 3
Training loss: 1.8743035612519332
Validation loss: 2.4317820478604757

Epoch: 5| Step: 4
Training loss: 1.4733666444410285
Validation loss: 2.5113200970118754

Epoch: 5| Step: 5
Training loss: 1.947209670201271
Validation loss: 2.5975501910472403

Epoch: 5| Step: 6
Training loss: 2.040349327733099
Validation loss: 2.613090400379915

Epoch: 5| Step: 7
Training loss: 1.2865247773632151
Validation loss: 2.5771021370386573

Epoch: 5| Step: 8
Training loss: 1.706553377002416
Validation loss: 2.489596541689723

Epoch: 5| Step: 9
Training loss: 1.789704719781671
Validation loss: 2.4332303720178965

Epoch: 5| Step: 10
Training loss: 1.6807890362908073
Validation loss: 2.348519537316214

Epoch: 228| Step: 0
Training loss: 1.626891429230501
Validation loss: 2.31606630674757

Epoch: 5| Step: 1
Training loss: 1.4695322104678548
Validation loss: 2.374829753047916

Epoch: 5| Step: 2
Training loss: 1.7413950944135028
Validation loss: 2.4144106664733447

Epoch: 5| Step: 3
Training loss: 1.674731087805198
Validation loss: 2.549979118971049

Epoch: 5| Step: 4
Training loss: 1.272446416389947
Validation loss: 2.5926668663424883

Epoch: 5| Step: 5
Training loss: 1.5893309419910524
Validation loss: 2.6326219629682255

Epoch: 5| Step: 6
Training loss: 1.8620538087480107
Validation loss: 2.642620688564789

Epoch: 5| Step: 7
Training loss: 1.262620727507664
Validation loss: 2.6108650333601333

Epoch: 5| Step: 8
Training loss: 2.0570783158425847
Validation loss: 2.5913771049311873

Epoch: 5| Step: 9
Training loss: 1.9737875536582752
Validation loss: 2.5335539057398297

Epoch: 5| Step: 10
Training loss: 1.36352375136288
Validation loss: 2.471808371317379

Epoch: 229| Step: 0
Training loss: 1.8576344269157212
Validation loss: 2.38651978963301

Epoch: 5| Step: 1
Training loss: 2.050038811851238
Validation loss: 2.3680267584437518

Epoch: 5| Step: 2
Training loss: 1.6905860938709376
Validation loss: 2.379713839183583

Epoch: 5| Step: 3
Training loss: 1.5722130049909726
Validation loss: 2.385518188795204

Epoch: 5| Step: 4
Training loss: 1.9599183614427689
Validation loss: 2.462598212639395

Epoch: 5| Step: 5
Training loss: 1.2070248304276598
Validation loss: 2.525171977412007

Epoch: 5| Step: 6
Training loss: 1.6870323522164377
Validation loss: 2.5995895490875514

Epoch: 5| Step: 7
Training loss: 1.6888108989766857
Validation loss: 2.6488431290257144

Epoch: 5| Step: 8
Training loss: 1.411476975021098
Validation loss: 2.5805107923232655

Epoch: 5| Step: 9
Training loss: 1.2999625622420423
Validation loss: 2.5018876978260933

Epoch: 5| Step: 10
Training loss: 1.5421719968687102
Validation loss: 2.417616498043261

Epoch: 230| Step: 0
Training loss: 1.216259980273489
Validation loss: 2.4008609144118327

Epoch: 5| Step: 1
Training loss: 1.0357494453982987
Validation loss: 2.4013801275470623

Epoch: 5| Step: 2
Training loss: 1.801307187678188
Validation loss: 2.442431312023701

Epoch: 5| Step: 3
Training loss: 1.8797082279930157
Validation loss: 2.467974562675233

Epoch: 5| Step: 4
Training loss: 1.3371224752949535
Validation loss: 2.535568091858008

Epoch: 5| Step: 5
Training loss: 1.3606370789215594
Validation loss: 2.543644660090232

Epoch: 5| Step: 6
Training loss: 1.6877582493725798
Validation loss: 2.472226801782711

Epoch: 5| Step: 7
Training loss: 1.666998337486825
Validation loss: 2.4588409644994837

Epoch: 5| Step: 8
Training loss: 1.7517755901154661
Validation loss: 2.417198563564538

Epoch: 5| Step: 9
Training loss: 2.0404610350369716
Validation loss: 2.4100502410868105

Epoch: 5| Step: 10
Training loss: 1.9507513041674636
Validation loss: 2.425162748570094

Epoch: 231| Step: 0
Training loss: 1.5351148604620442
Validation loss: 2.517191829079205

Epoch: 5| Step: 1
Training loss: 1.9509241750696869
Validation loss: 2.5441466090700935

Epoch: 5| Step: 2
Training loss: 1.4843132407742212
Validation loss: 2.5793257884217153

Epoch: 5| Step: 3
Training loss: 1.3076582568145607
Validation loss: 2.61693505049321

Epoch: 5| Step: 4
Training loss: 1.3082282167877695
Validation loss: 2.5982716881982526

Epoch: 5| Step: 5
Training loss: 1.4680450858123062
Validation loss: 2.5448363833459258

Epoch: 5| Step: 6
Training loss: 1.597032495185972
Validation loss: 2.4714568337761884

Epoch: 5| Step: 7
Training loss: 1.4492725454869746
Validation loss: 2.43748910805262

Epoch: 5| Step: 8
Training loss: 2.0206986084169873
Validation loss: 2.4553290235243423

Epoch: 5| Step: 9
Training loss: 1.5806882078927802
Validation loss: 2.4199747713454163

Epoch: 5| Step: 10
Training loss: 2.038299066853905
Validation loss: 2.4503532904156176

Epoch: 232| Step: 0
Training loss: 1.61026095105898
Validation loss: 2.4551022359115846

Epoch: 5| Step: 1
Training loss: 1.7169549758553309
Validation loss: 2.5536978658364617

Epoch: 5| Step: 2
Training loss: 1.5079793096585092
Validation loss: 2.585331396343572

Epoch: 5| Step: 3
Training loss: 1.5575605519680045
Validation loss: 2.6572945342829866

Epoch: 5| Step: 4
Training loss: 1.8451738193995728
Validation loss: 2.6695263555975486

Epoch: 5| Step: 5
Training loss: 1.4743135471320061
Validation loss: 2.5770997077933075

Epoch: 5| Step: 6
Training loss: 1.6172842835292163
Validation loss: 2.474818374716479

Epoch: 5| Step: 7
Training loss: 1.7027313057367957
Validation loss: 2.391064564775989

Epoch: 5| Step: 8
Training loss: 1.4112102764475591
Validation loss: 2.3406827987215126

Epoch: 5| Step: 9
Training loss: 1.6465165937174278
Validation loss: 2.364051239837259

Epoch: 5| Step: 10
Training loss: 1.4823942119042777
Validation loss: 2.365191599657398

Epoch: 233| Step: 0
Training loss: 1.7898288734513796
Validation loss: 2.4096448325837545

Epoch: 5| Step: 1
Training loss: 1.2894027723242043
Validation loss: 2.4545417782129757

Epoch: 5| Step: 2
Training loss: 1.790726866163011
Validation loss: 2.523413349151477

Epoch: 5| Step: 3
Training loss: 1.862497096731496
Validation loss: 2.5735013029452873

Epoch: 5| Step: 4
Training loss: 1.6299492220780174
Validation loss: 2.580110272674747

Epoch: 5| Step: 5
Training loss: 1.2938380704379697
Validation loss: 2.5611467167037647

Epoch: 5| Step: 6
Training loss: 1.4347884270081388
Validation loss: 2.511252269851344

Epoch: 5| Step: 7
Training loss: 1.451650712501867
Validation loss: 2.4648886437084423

Epoch: 5| Step: 8
Training loss: 1.5495506804389392
Validation loss: 2.47812779486716

Epoch: 5| Step: 9
Training loss: 1.7299947326227163
Validation loss: 2.430718914075847

Epoch: 5| Step: 10
Training loss: 1.6179603535919191
Validation loss: 2.425642343828556

Epoch: 234| Step: 0
Training loss: 1.9151581411577219
Validation loss: 2.3604572369949888

Epoch: 5| Step: 1
Training loss: 1.6459348945024885
Validation loss: 2.389309525411067

Epoch: 5| Step: 2
Training loss: 1.4266698289253863
Validation loss: 2.3742494859920065

Epoch: 5| Step: 3
Training loss: 1.625353994692462
Validation loss: 2.4563735657378163

Epoch: 5| Step: 4
Training loss: 1.510810756791705
Validation loss: 2.5538959981121154

Epoch: 5| Step: 5
Training loss: 1.5865239905206472
Validation loss: 2.7094165033764153

Epoch: 5| Step: 6
Training loss: 1.6634249473268712
Validation loss: 2.736888650575838

Epoch: 5| Step: 7
Training loss: 1.6243438863324704
Validation loss: 2.724119610122649

Epoch: 5| Step: 8
Training loss: 1.4002419450007522
Validation loss: 2.5865246203814447

Epoch: 5| Step: 9
Training loss: 1.5609707787739908
Validation loss: 2.444128379947192

Epoch: 5| Step: 10
Training loss: 1.7611106618178016
Validation loss: 2.3654553752071683

Epoch: 235| Step: 0
Training loss: 1.610033363565244
Validation loss: 2.333288463331037

Epoch: 5| Step: 1
Training loss: 1.501968125763232
Validation loss: 2.3545914420195957

Epoch: 5| Step: 2
Training loss: 1.8703288703017196
Validation loss: 2.3544857546863147

Epoch: 5| Step: 3
Training loss: 1.6627330932124722
Validation loss: 2.385327843485042

Epoch: 5| Step: 4
Training loss: 1.6142361011187394
Validation loss: 2.450395562051792

Epoch: 5| Step: 5
Training loss: 1.6110092309915818
Validation loss: 2.565505830232579

Epoch: 5| Step: 6
Training loss: 1.625780578349175
Validation loss: 2.6912227058248748

Epoch: 5| Step: 7
Training loss: 1.650469860454642
Validation loss: 2.7187611192233767

Epoch: 5| Step: 8
Training loss: 1.2862860632494253
Validation loss: 2.739552910411746

Epoch: 5| Step: 9
Training loss: 1.2471121330687167
Validation loss: 2.6739698074507348

Epoch: 5| Step: 10
Training loss: 1.8419006900917987
Validation loss: 2.554745333321985

Epoch: 236| Step: 0
Training loss: 1.325847782765184
Validation loss: 2.438235551860784

Epoch: 5| Step: 1
Training loss: 1.9793538523713587
Validation loss: 2.377030916709074

Epoch: 5| Step: 2
Training loss: 1.5584877379653739
Validation loss: 2.3505180900515206

Epoch: 5| Step: 3
Training loss: 1.6764337296464302
Validation loss: 2.40323759321648

Epoch: 5| Step: 4
Training loss: 1.428448499771992
Validation loss: 2.4714961735606362

Epoch: 5| Step: 5
Training loss: 1.5859018707031516
Validation loss: 2.5797994387263543

Epoch: 5| Step: 6
Training loss: 1.8421981228820627
Validation loss: 2.6531539989810327

Epoch: 5| Step: 7
Training loss: 1.405572897766809
Validation loss: 2.6474279227319344

Epoch: 5| Step: 8
Training loss: 1.2974703697540493
Validation loss: 2.4743121993258406

Epoch: 5| Step: 9
Training loss: 1.4735448771860247
Validation loss: 2.377159407445931

Epoch: 5| Step: 10
Training loss: 1.9572024089714988
Validation loss: 2.32050768452278

Epoch: 237| Step: 0
Training loss: 1.5240952856758452
Validation loss: 2.3399332017666215

Epoch: 5| Step: 1
Training loss: 1.85359775373317
Validation loss: 2.352661573688947

Epoch: 5| Step: 2
Training loss: 1.5246583399532063
Validation loss: 2.3751310043602434

Epoch: 5| Step: 3
Training loss: 2.1470589948987624
Validation loss: 2.4704119160054336

Epoch: 5| Step: 4
Training loss: 1.4816475958324515
Validation loss: 2.5716551868020945

Epoch: 5| Step: 5
Training loss: 1.7318171291807776
Validation loss: 2.6979209544165608

Epoch: 5| Step: 6
Training loss: 1.5694096185351778
Validation loss: 2.7303325646048853

Epoch: 5| Step: 7
Training loss: 1.3842268784892895
Validation loss: 2.649021876141042

Epoch: 5| Step: 8
Training loss: 1.1650384997280965
Validation loss: 2.4850906535222976

Epoch: 5| Step: 9
Training loss: 1.2615034551554267
Validation loss: 2.3825650607639726

Epoch: 5| Step: 10
Training loss: 1.3668223738165657
Validation loss: 2.3528173100401504

Epoch: 238| Step: 0
Training loss: 1.543128669273986
Validation loss: 2.3693253880708274

Epoch: 5| Step: 1
Training loss: 1.4656498433104002
Validation loss: 2.413892075765668

Epoch: 5| Step: 2
Training loss: 1.300485388298624
Validation loss: 2.4190146320514674

Epoch: 5| Step: 3
Training loss: 1.6275627029223696
Validation loss: 2.498736806880631

Epoch: 5| Step: 4
Training loss: 1.3935295803104635
Validation loss: 2.631144954198103

Epoch: 5| Step: 5
Training loss: 1.7023396212285722
Validation loss: 2.6402364067371056

Epoch: 5| Step: 6
Training loss: 1.4597315579370005
Validation loss: 2.56954534673043

Epoch: 5| Step: 7
Training loss: 1.3990063922018916
Validation loss: 2.543400513158711

Epoch: 5| Step: 8
Training loss: 1.8560344275454943
Validation loss: 2.4771774810477174

Epoch: 5| Step: 9
Training loss: 1.583531174931321
Validation loss: 2.3711126380518546

Epoch: 5| Step: 10
Training loss: 1.7534320419626332
Validation loss: 2.3279729114734344

Epoch: 239| Step: 0
Training loss: 1.5519859573574488
Validation loss: 2.2812068877260123

Epoch: 5| Step: 1
Training loss: 1.5963189607091242
Validation loss: 2.3201027013626696

Epoch: 5| Step: 2
Training loss: 1.432121497940479
Validation loss: 2.4082731763659626

Epoch: 5| Step: 3
Training loss: 1.560316009059133
Validation loss: 2.47280148636889

Epoch: 5| Step: 4
Training loss: 1.5286704932784776
Validation loss: 2.588267491444417

Epoch: 5| Step: 5
Training loss: 1.7461763571500375
Validation loss: 2.6407849032291795

Epoch: 5| Step: 6
Training loss: 1.4385373891904503
Validation loss: 2.616581345120672

Epoch: 5| Step: 7
Training loss: 1.4805091711479776
Validation loss: 2.5606091974522047

Epoch: 5| Step: 8
Training loss: 1.1852261708102427
Validation loss: 2.520655851964796

Epoch: 5| Step: 9
Training loss: 1.5616611517798973
Validation loss: 2.460568170525806

Epoch: 5| Step: 10
Training loss: 1.8309057882166733
Validation loss: 2.421935994163842

Epoch: 240| Step: 0
Training loss: 1.629845218213451
Validation loss: 2.4287924366743128

Epoch: 5| Step: 1
Training loss: 1.7884507111883452
Validation loss: 2.432458336990847

Epoch: 5| Step: 2
Training loss: 1.5131451484003653
Validation loss: 2.4478928445474213

Epoch: 5| Step: 3
Training loss: 1.459520601446709
Validation loss: 2.472560774777482

Epoch: 5| Step: 4
Training loss: 1.544911612417518
Validation loss: 2.5223343937069265

Epoch: 5| Step: 5
Training loss: 1.479572840339811
Validation loss: 2.511630517492446

Epoch: 5| Step: 6
Training loss: 1.4060336476365467
Validation loss: 2.4855907404153883

Epoch: 5| Step: 7
Training loss: 1.3805552016747522
Validation loss: 2.5244649415008147

Epoch: 5| Step: 8
Training loss: 1.7482646785137872
Validation loss: 2.547331032791647

Epoch: 5| Step: 9
Training loss: 1.5331359459804672
Validation loss: 2.508339450182652

Epoch: 5| Step: 10
Training loss: 1.0803257691062542
Validation loss: 2.488196707438861

Epoch: 241| Step: 0
Training loss: 1.2864711261478705
Validation loss: 2.477122156537245

Epoch: 5| Step: 1
Training loss: 1.319002393100005
Validation loss: 2.4661073321856897

Epoch: 5| Step: 2
Training loss: 1.1582004489192312
Validation loss: 2.4495767771748116

Epoch: 5| Step: 3
Training loss: 1.337277236997708
Validation loss: 2.436946950244895

Epoch: 5| Step: 4
Training loss: 1.7145538432604586
Validation loss: 2.4919663599020088

Epoch: 5| Step: 5
Training loss: 1.6301112120666628
Validation loss: 2.5247430431643054

Epoch: 5| Step: 6
Training loss: 1.8385939838289003
Validation loss: 2.4868118625867064

Epoch: 5| Step: 7
Training loss: 1.3271932138239608
Validation loss: 2.505148970438481

Epoch: 5| Step: 8
Training loss: 1.7162362182463924
Validation loss: 2.5427219399696797

Epoch: 5| Step: 9
Training loss: 1.6483983762898324
Validation loss: 2.565072525867842

Epoch: 5| Step: 10
Training loss: 1.2066423104306223
Validation loss: 2.5381068306807624

Epoch: 242| Step: 0
Training loss: 1.419869486224053
Validation loss: 2.5033537857183426

Epoch: 5| Step: 1
Training loss: 1.537661306711896
Validation loss: 2.5182131553305727

Epoch: 5| Step: 2
Training loss: 1.3126231544480929
Validation loss: 2.50231276971123

Epoch: 5| Step: 3
Training loss: 1.3598350097347311
Validation loss: 2.4677498441182446

Epoch: 5| Step: 4
Training loss: 1.308962323109186
Validation loss: 2.4923435259678786

Epoch: 5| Step: 5
Training loss: 1.5401064048271786
Validation loss: 2.574917348253444

Epoch: 5| Step: 6
Training loss: 1.6785703980810833
Validation loss: 2.585994159585967

Epoch: 5| Step: 7
Training loss: 1.188421744945092
Validation loss: 2.58886530848902

Epoch: 5| Step: 8
Training loss: 1.67866371359097
Validation loss: 2.5636154551266737

Epoch: 5| Step: 9
Training loss: 1.7929962754474174
Validation loss: 2.4680350319637436

Epoch: 5| Step: 10
Training loss: 1.395251945386254
Validation loss: 2.4476334927542993

Epoch: 243| Step: 0
Training loss: 1.1558604744161138
Validation loss: 2.453732358593579

Epoch: 5| Step: 1
Training loss: 1.0594872226745735
Validation loss: 2.4627377651128035

Epoch: 5| Step: 2
Training loss: 1.5505178693905983
Validation loss: 2.516747566299555

Epoch: 5| Step: 3
Training loss: 1.4431011707160795
Validation loss: 2.5432971973916616

Epoch: 5| Step: 4
Training loss: 0.7276014877266378
Validation loss: 2.550309754590997

Epoch: 5| Step: 5
Training loss: 1.7709250781658739
Validation loss: 2.5707786125703853

Epoch: 5| Step: 6
Training loss: 1.8107234535404395
Validation loss: 2.5637116337672117

Epoch: 5| Step: 7
Training loss: 1.5149097918101881
Validation loss: 2.564649471253409

Epoch: 5| Step: 8
Training loss: 1.8970527150898986
Validation loss: 2.5552540229012117

Epoch: 5| Step: 9
Training loss: 1.3109562287112417
Validation loss: 2.4609508622772442

Epoch: 5| Step: 10
Training loss: 1.5163284714182619
Validation loss: 2.4435682484453722

Epoch: 244| Step: 0
Training loss: 1.486823942920143
Validation loss: 2.4655414851787243

Epoch: 5| Step: 1
Training loss: 1.4857370652558937
Validation loss: 2.5414646625852977

Epoch: 5| Step: 2
Training loss: 1.6776639592733555
Validation loss: 2.5662470767720986

Epoch: 5| Step: 3
Training loss: 1.7397500679683768
Validation loss: 2.5885894018960443

Epoch: 5| Step: 4
Training loss: 1.6352977911959958
Validation loss: 2.5517258802909977

Epoch: 5| Step: 5
Training loss: 1.45736682289945
Validation loss: 2.499178167847348

Epoch: 5| Step: 6
Training loss: 1.1612668357096818
Validation loss: 2.432090626245285

Epoch: 5| Step: 7
Training loss: 0.8857051080346905
Validation loss: 2.3987622698691546

Epoch: 5| Step: 8
Training loss: 1.6335559229436865
Validation loss: 2.4358592218079407

Epoch: 5| Step: 9
Training loss: 1.3391774914930503
Validation loss: 2.4374656832592927

Epoch: 5| Step: 10
Training loss: 1.4379629965147585
Validation loss: 2.4847182438354904

Epoch: 245| Step: 0
Training loss: 1.1007671325514725
Validation loss: 2.4573272417757357

Epoch: 5| Step: 1
Training loss: 1.2900592533815696
Validation loss: 2.497545284138383

Epoch: 5| Step: 2
Training loss: 1.4911987863781293
Validation loss: 2.573835743752998

Epoch: 5| Step: 3
Training loss: 1.5592846402761893
Validation loss: 2.498943310630188

Epoch: 5| Step: 4
Training loss: 1.5655712461095144
Validation loss: 2.4777132497777834

Epoch: 5| Step: 5
Training loss: 1.6076147582529712
Validation loss: 2.4962455624646984

Epoch: 5| Step: 6
Training loss: 1.3991761201619055
Validation loss: 2.483506850030304

Epoch: 5| Step: 7
Training loss: 1.4752941032350257
Validation loss: 2.4935752164884213

Epoch: 5| Step: 8
Training loss: 1.7410158742348585
Validation loss: 2.4732218063852693

Epoch: 5| Step: 9
Training loss: 1.3457392672486892
Validation loss: 2.4540457407438323

Epoch: 5| Step: 10
Training loss: 1.0852302608421618
Validation loss: 2.495626860875587

Epoch: 246| Step: 0
Training loss: 1.3382139831490851
Validation loss: 2.5062270597890643

Epoch: 5| Step: 1
Training loss: 1.5914262024083279
Validation loss: 2.5429914096153943

Epoch: 5| Step: 2
Training loss: 1.741369012406266
Validation loss: 2.579032362898337

Epoch: 5| Step: 3
Training loss: 1.3029482550106473
Validation loss: 2.557101660399887

Epoch: 5| Step: 4
Training loss: 1.1397337370839948
Validation loss: 2.548384183503232

Epoch: 5| Step: 5
Training loss: 1.1883452067823066
Validation loss: 2.5424908720976234

Epoch: 5| Step: 6
Training loss: 1.2685476395409003
Validation loss: 2.500577613798701

Epoch: 5| Step: 7
Training loss: 1.956915267583641
Validation loss: 2.474153359740223

Epoch: 5| Step: 8
Training loss: 1.122117376046013
Validation loss: 2.4128143910331366

Epoch: 5| Step: 9
Training loss: 1.3655615156768055
Validation loss: 2.3565870770996193

Epoch: 5| Step: 10
Training loss: 1.5211950768968119
Validation loss: 2.337772199947914

Epoch: 247| Step: 0
Training loss: 1.3482081071176126
Validation loss: 2.3144266261587165

Epoch: 5| Step: 1
Training loss: 1.6793600783485518
Validation loss: 2.3408400751019136

Epoch: 5| Step: 2
Training loss: 1.510295266720661
Validation loss: 2.3644899891320845

Epoch: 5| Step: 3
Training loss: 1.6413217427479485
Validation loss: 2.4241451319124074

Epoch: 5| Step: 4
Training loss: 1.187061831296416
Validation loss: 2.4780215776846086

Epoch: 5| Step: 5
Training loss: 1.4808799152564782
Validation loss: 2.5274095061544215

Epoch: 5| Step: 6
Training loss: 1.6387643344697411
Validation loss: 2.5117461554001292

Epoch: 5| Step: 7
Training loss: 1.5166981623946003
Validation loss: 2.5173655181457697

Epoch: 5| Step: 8
Training loss: 1.443634378666842
Validation loss: 2.5209223983137545

Epoch: 5| Step: 9
Training loss: 1.0277953805074749
Validation loss: 2.530509040172707

Epoch: 5| Step: 10
Training loss: 1.0523911519975229
Validation loss: 2.492021321427409

Epoch: 248| Step: 0
Training loss: 1.41249081431415
Validation loss: 2.450028907922598

Epoch: 5| Step: 1
Training loss: 1.3591106201550698
Validation loss: 2.435931912450193

Epoch: 5| Step: 2
Training loss: 1.4454891612366678
Validation loss: 2.385268859181616

Epoch: 5| Step: 3
Training loss: 1.682956513004512
Validation loss: 2.3607182847540384

Epoch: 5| Step: 4
Training loss: 1.5190974305167888
Validation loss: 2.3683674496185487

Epoch: 5| Step: 5
Training loss: 1.1282343465377207
Validation loss: 2.390007359090095

Epoch: 5| Step: 6
Training loss: 1.0798826954855867
Validation loss: 2.473854873298699

Epoch: 5| Step: 7
Training loss: 1.2906764244198081
Validation loss: 2.4921345064290357

Epoch: 5| Step: 8
Training loss: 1.5018593073043718
Validation loss: 2.5197235413064605

Epoch: 5| Step: 9
Training loss: 1.7450999049359315
Validation loss: 2.450648313518468

Epoch: 5| Step: 10
Training loss: 1.2647968455542522
Validation loss: 2.4705825791172553

Epoch: 249| Step: 0
Training loss: 1.266952477802112
Validation loss: 2.4760852231026726

Epoch: 5| Step: 1
Training loss: 1.314314677640506
Validation loss: 2.4304337518958126

Epoch: 5| Step: 2
Training loss: 1.8890549627237325
Validation loss: 2.445649421925755

Epoch: 5| Step: 3
Training loss: 1.2511512223467671
Validation loss: 2.424491137533655

Epoch: 5| Step: 4
Training loss: 1.598903700633511
Validation loss: 2.474064484387644

Epoch: 5| Step: 5
Training loss: 1.2341473526423243
Validation loss: 2.5178130380648955

Epoch: 5| Step: 6
Training loss: 1.4913192539809548
Validation loss: 2.4941490606763628

Epoch: 5| Step: 7
Training loss: 1.7065180305983656
Validation loss: 2.5072158432353167

Epoch: 5| Step: 8
Training loss: 1.1726337773802042
Validation loss: 2.5237826575418763

Epoch: 5| Step: 9
Training loss: 1.070806124943917
Validation loss: 2.502384607214209

Epoch: 5| Step: 10
Training loss: 0.9768489875185653
Validation loss: 2.4988453936787955

Epoch: 250| Step: 0
Training loss: 1.3460135800780453
Validation loss: 2.4932290769766237

Epoch: 5| Step: 1
Training loss: 0.9891213325732352
Validation loss: 2.4873327746808203

Epoch: 5| Step: 2
Training loss: 1.519916946375691
Validation loss: 2.521824052114604

Epoch: 5| Step: 3
Training loss: 0.9176384189457536
Validation loss: 2.4817838198581317

Epoch: 5| Step: 4
Training loss: 1.4112563979998056
Validation loss: 2.505414150535403

Epoch: 5| Step: 5
Training loss: 1.8892109524663203
Validation loss: 2.49212166059553

Epoch: 5| Step: 6
Training loss: 1.1497101252559658
Validation loss: 2.4720458044222346

Epoch: 5| Step: 7
Training loss: 1.4826997639737758
Validation loss: 2.4784868700378073

Epoch: 5| Step: 8
Training loss: 1.326529857651752
Validation loss: 2.4977135395496544

Epoch: 5| Step: 9
Training loss: 1.472235662570918
Validation loss: 2.491922509558909

Epoch: 5| Step: 10
Training loss: 1.40765615731924
Validation loss: 2.4775296876213337

Epoch: 251| Step: 0
Training loss: 0.956494893398901
Validation loss: 2.4901794249946168

Epoch: 5| Step: 1
Training loss: 1.2543566598962734
Validation loss: 2.493937622590008

Epoch: 5| Step: 2
Training loss: 1.161971242693265
Validation loss: 2.4314820512473676

Epoch: 5| Step: 3
Training loss: 1.321788932938319
Validation loss: 2.4280820201375044

Epoch: 5| Step: 4
Training loss: 1.558838942130861
Validation loss: 2.459098942461416

Epoch: 5| Step: 5
Training loss: 1.2848272395241622
Validation loss: 2.485809604373842

Epoch: 5| Step: 6
Training loss: 1.2996655510793826
Validation loss: 2.468818332343787

Epoch: 5| Step: 7
Training loss: 1.3188778458225532
Validation loss: 2.461258128540923

Epoch: 5| Step: 8
Training loss: 1.581859890169697
Validation loss: 2.4823370327053214

Epoch: 5| Step: 9
Training loss: 1.8524846223303606
Validation loss: 2.509682335310859

Epoch: 5| Step: 10
Training loss: 1.1559582419492636
Validation loss: 2.53630642043203

Epoch: 252| Step: 0
Training loss: 1.5716075965538523
Validation loss: 2.551740233960813

Epoch: 5| Step: 1
Training loss: 1.5180646001265792
Validation loss: 2.5800880115903335

Epoch: 5| Step: 2
Training loss: 1.661495754414454
Validation loss: 2.5148702824469855

Epoch: 5| Step: 3
Training loss: 1.2246670990743966
Validation loss: 2.475530007327164

Epoch: 5| Step: 4
Training loss: 1.123388301530791
Validation loss: 2.437142489214037

Epoch: 5| Step: 5
Training loss: 1.2498611373063921
Validation loss: 2.373414985750698

Epoch: 5| Step: 6
Training loss: 1.420290388852143
Validation loss: 2.3833042502771145

Epoch: 5| Step: 7
Training loss: 1.66278628989104
Validation loss: 2.3426715412315864

Epoch: 5| Step: 8
Training loss: 1.1580733794284401
Validation loss: 2.4800730828860718

Epoch: 5| Step: 9
Training loss: 1.1181264279624559
Validation loss: 2.545848964635588

Epoch: 5| Step: 10
Training loss: 1.0008805689489433
Validation loss: 2.5570742854294934

Epoch: 253| Step: 0
Training loss: 1.0799181304029986
Validation loss: 2.53155696399713

Epoch: 5| Step: 1
Training loss: 1.0468241551136614
Validation loss: 2.4439734077412676

Epoch: 5| Step: 2
Training loss: 1.9003782673793677
Validation loss: 2.3755331803719133

Epoch: 5| Step: 3
Training loss: 1.5132864775244876
Validation loss: 2.409952823868359

Epoch: 5| Step: 4
Training loss: 1.0259324159243495
Validation loss: 2.3823733948115606

Epoch: 5| Step: 5
Training loss: 1.5398899700441357
Validation loss: 2.403465952109727

Epoch: 5| Step: 6
Training loss: 1.4137942655127862
Validation loss: 2.421785215472701

Epoch: 5| Step: 7
Training loss: 1.0015659588115795
Validation loss: 2.477365193084197

Epoch: 5| Step: 8
Training loss: 1.352426462272007
Validation loss: 2.5309025130835274

Epoch: 5| Step: 9
Training loss: 1.2634006309366395
Validation loss: 2.614705457009964

Epoch: 5| Step: 10
Training loss: 1.2136855415333545
Validation loss: 2.6041815112931657

Epoch: 254| Step: 0
Training loss: 1.0961502985053884
Validation loss: 2.5965023429036367

Epoch: 5| Step: 1
Training loss: 1.5285993717374489
Validation loss: 2.58297353323558

Epoch: 5| Step: 2
Training loss: 1.347964044334765
Validation loss: 2.5710165854344766

Epoch: 5| Step: 3
Training loss: 1.607174897252974
Validation loss: 2.5298862538531646

Epoch: 5| Step: 4
Training loss: 1.6116368223475803
Validation loss: 2.5328194955529533

Epoch: 5| Step: 5
Training loss: 1.210583592042974
Validation loss: 2.5305381562939377

Epoch: 5| Step: 6
Training loss: 1.44241049913657
Validation loss: 2.5084274857162465

Epoch: 5| Step: 7
Training loss: 1.1480587704598086
Validation loss: 2.4470828421607957

Epoch: 5| Step: 8
Training loss: 1.098143228586933
Validation loss: 2.440632281868229

Epoch: 5| Step: 9
Training loss: 1.053325932744341
Validation loss: 2.4156456453469266

Epoch: 5| Step: 10
Training loss: 1.3244231299835458
Validation loss: 2.430602089182037

Epoch: 255| Step: 0
Training loss: 1.3842871610101617
Validation loss: 2.4943465195090435

Epoch: 5| Step: 1
Training loss: 0.7771757318075859
Validation loss: 2.4961511538354126

Epoch: 5| Step: 2
Training loss: 1.5726885682834502
Validation loss: 2.5413682043891446

Epoch: 5| Step: 3
Training loss: 1.7133491972301413
Validation loss: 2.622863314015109

Epoch: 5| Step: 4
Training loss: 1.0601456306392307
Validation loss: 2.5873088600215466

Epoch: 5| Step: 5
Training loss: 1.1091947812119596
Validation loss: 2.542992193932675

Epoch: 5| Step: 6
Training loss: 1.5408598962574143
Validation loss: 2.4640543804643174

Epoch: 5| Step: 7
Training loss: 1.1593596938117674
Validation loss: 2.4377681836012766

Epoch: 5| Step: 8
Training loss: 1.386424159606385
Validation loss: 2.392522329349963

Epoch: 5| Step: 9
Training loss: 1.321063127394016
Validation loss: 2.3882558634083986

Epoch: 5| Step: 10
Training loss: 1.1280237992562647
Validation loss: 2.449904965735474

Epoch: 256| Step: 0
Training loss: 1.2334523192994897
Validation loss: 2.538619347102667

Epoch: 5| Step: 1
Training loss: 1.482230072278713
Validation loss: 2.579126816075145

Epoch: 5| Step: 2
Training loss: 1.2390891727689013
Validation loss: 2.6379093837860217

Epoch: 5| Step: 3
Training loss: 1.374635908299486
Validation loss: 2.633490990267359

Epoch: 5| Step: 4
Training loss: 1.425236846247532
Validation loss: 2.5728324373834615

Epoch: 5| Step: 5
Training loss: 1.092695654452175
Validation loss: 2.483547552476417

Epoch: 5| Step: 6
Training loss: 1.1553069728134053
Validation loss: 2.424079191019306

Epoch: 5| Step: 7
Training loss: 0.9428745074138748
Validation loss: 2.393880861412504

Epoch: 5| Step: 8
Training loss: 1.5551016557834914
Validation loss: 2.3680691442654167

Epoch: 5| Step: 9
Training loss: 1.6865437235272078
Validation loss: 2.397918451540769

Epoch: 5| Step: 10
Training loss: 1.2673637314628559
Validation loss: 2.4235997891465497

Epoch: 257| Step: 0
Training loss: 1.0237887413137636
Validation loss: 2.4947036486837133

Epoch: 5| Step: 1
Training loss: 1.1218818791850642
Validation loss: 2.576222978692529

Epoch: 5| Step: 2
Training loss: 0.9360831043935115
Validation loss: 2.615713690381745

Epoch: 5| Step: 3
Training loss: 1.6731995656522936
Validation loss: 2.558509809376909

Epoch: 5| Step: 4
Training loss: 1.3721229190176416
Validation loss: 2.5545365704580654

Epoch: 5| Step: 5
Training loss: 1.5863189990080084
Validation loss: 2.5114189597645766

Epoch: 5| Step: 6
Training loss: 1.2187712740875356
Validation loss: 2.418959649668997

Epoch: 5| Step: 7
Training loss: 1.4099045631900329
Validation loss: 2.3888842079547272

Epoch: 5| Step: 8
Training loss: 1.2328506425147219
Validation loss: 2.3974023960732826

Epoch: 5| Step: 9
Training loss: 1.3198289606515121
Validation loss: 2.423476135487978

Epoch: 5| Step: 10
Training loss: 1.3725968080437103
Validation loss: 2.505671751330901

Epoch: 258| Step: 0
Training loss: 1.2392682014192198
Validation loss: 2.579560368455558

Epoch: 5| Step: 1
Training loss: 1.1279136227210949
Validation loss: 2.612401030861451

Epoch: 5| Step: 2
Training loss: 1.494399583104584
Validation loss: 2.474330076170867

Epoch: 5| Step: 3
Training loss: 0.9785689836218943
Validation loss: 2.4322240381381426

Epoch: 5| Step: 4
Training loss: 1.2703632152235595
Validation loss: 2.347426093711185

Epoch: 5| Step: 5
Training loss: 1.6326084283218867
Validation loss: 2.2975309862608833

Epoch: 5| Step: 6
Training loss: 1.565976129016199
Validation loss: 2.3496798748695995

Epoch: 5| Step: 7
Training loss: 1.4233261919103017
Validation loss: 2.3594340655409067

Epoch: 5| Step: 8
Training loss: 1.2126020742493961
Validation loss: 2.483280524087174

Epoch: 5| Step: 9
Training loss: 1.0300475537331566
Validation loss: 2.546266035180016

Epoch: 5| Step: 10
Training loss: 1.3363311812146477
Validation loss: 2.6243855772504294

Epoch: 259| Step: 0
Training loss: 1.638390536249105
Validation loss: 2.584175473418383

Epoch: 5| Step: 1
Training loss: 0.984829903501782
Validation loss: 2.543007618117957

Epoch: 5| Step: 2
Training loss: 0.9695738089147895
Validation loss: 2.4839412336075375

Epoch: 5| Step: 3
Training loss: 1.2033573273109668
Validation loss: 2.4428888874234356

Epoch: 5| Step: 4
Training loss: 1.3311817223317701
Validation loss: 2.3919825309692113

Epoch: 5| Step: 5
Training loss: 1.693512413562817
Validation loss: 2.3757201356738618

Epoch: 5| Step: 6
Training loss: 1.311371817953198
Validation loss: 2.382767077167198

Epoch: 5| Step: 7
Training loss: 1.2318612106534657
Validation loss: 2.386688386366053

Epoch: 5| Step: 8
Training loss: 1.2144651651015677
Validation loss: 2.40214988846038

Epoch: 5| Step: 9
Training loss: 1.2919722574993433
Validation loss: 2.4629795709977094

Epoch: 5| Step: 10
Training loss: 0.959306557913484
Validation loss: 2.511197771081863

Epoch: 260| Step: 0
Training loss: 1.3146414770617347
Validation loss: 2.5411840216274717

Epoch: 5| Step: 1
Training loss: 1.2975485557775959
Validation loss: 2.556199893199074

Epoch: 5| Step: 2
Training loss: 1.1737398695178487
Validation loss: 2.572921167709906

Epoch: 5| Step: 3
Training loss: 1.5792502744311212
Validation loss: 2.551116208289851

Epoch: 5| Step: 4
Training loss: 1.4506485047874755
Validation loss: 2.477222723528355

Epoch: 5| Step: 5
Training loss: 1.1729104617255661
Validation loss: 2.4080673352611646

Epoch: 5| Step: 6
Training loss: 1.6836375078148347
Validation loss: 2.4090092408146755

Epoch: 5| Step: 7
Training loss: 0.9846465629317355
Validation loss: 2.413535066093589

Epoch: 5| Step: 8
Training loss: 0.6661303468941681
Validation loss: 2.4813500690395163

Epoch: 5| Step: 9
Training loss: 1.2654139024798303
Validation loss: 2.5995672911057586

Epoch: 5| Step: 10
Training loss: 1.1822852528043806
Validation loss: 2.6105813140074723

Epoch: 261| Step: 0
Training loss: 1.0935077398939372
Validation loss: 2.6127208695836615

Epoch: 5| Step: 1
Training loss: 1.2151613464287836
Validation loss: 2.5384369261730466

Epoch: 5| Step: 2
Training loss: 1.5651170557626466
Validation loss: 2.49586724503372

Epoch: 5| Step: 3
Training loss: 1.2418209470783865
Validation loss: 2.410787211848035

Epoch: 5| Step: 4
Training loss: 1.1697502710905043
Validation loss: 2.4051467098514117

Epoch: 5| Step: 5
Training loss: 1.0134227645042706
Validation loss: 2.436881763945723

Epoch: 5| Step: 6
Training loss: 0.8350381023599363
Validation loss: 2.46415582462014

Epoch: 5| Step: 7
Training loss: 1.3584968097973635
Validation loss: 2.473682353370371

Epoch: 5| Step: 8
Training loss: 1.0319031467677002
Validation loss: 2.559435103261127

Epoch: 5| Step: 9
Training loss: 1.4273003833114632
Validation loss: 2.5835365277686897

Epoch: 5| Step: 10
Training loss: 1.765922588824799
Validation loss: 2.5884545348439403

Epoch: 262| Step: 0
Training loss: 1.2752091890650155
Validation loss: 2.5314233452920565

Epoch: 5| Step: 1
Training loss: 1.3974089862755663
Validation loss: 2.472686061858587

Epoch: 5| Step: 2
Training loss: 1.6199768631071751
Validation loss: 2.428519330677074

Epoch: 5| Step: 3
Training loss: 0.7214333574549053
Validation loss: 2.388460155368981

Epoch: 5| Step: 4
Training loss: 1.059051864989353
Validation loss: 2.373321551066362

Epoch: 5| Step: 5
Training loss: 1.0273153206840548
Validation loss: 2.3985409599581318

Epoch: 5| Step: 6
Training loss: 1.378039036013796
Validation loss: 2.4207453532783103

Epoch: 5| Step: 7
Training loss: 1.4748978692596664
Validation loss: 2.4558265910383557

Epoch: 5| Step: 8
Training loss: 1.333517101657342
Validation loss: 2.4672859002120076

Epoch: 5| Step: 9
Training loss: 1.265911211217789
Validation loss: 2.5267210022912012

Epoch: 5| Step: 10
Training loss: 0.9797333166673597
Validation loss: 2.5293088919567563

Epoch: 263| Step: 0
Training loss: 1.3582363841011367
Validation loss: 2.540775469294682

Epoch: 5| Step: 1
Training loss: 1.4843705026658844
Validation loss: 2.539749885952611

Epoch: 5| Step: 2
Training loss: 1.1641871238409298
Validation loss: 2.47569429657547

Epoch: 5| Step: 3
Training loss: 1.1919853429021188
Validation loss: 2.458553790981124

Epoch: 5| Step: 4
Training loss: 1.5127580406821302
Validation loss: 2.406426879109419

Epoch: 5| Step: 5
Training loss: 1.0162566348301514
Validation loss: 2.4221379232972087

Epoch: 5| Step: 6
Training loss: 0.8354853895908579
Validation loss: 2.4765629792794446

Epoch: 5| Step: 7
Training loss: 1.032652277212283
Validation loss: 2.4837099323960725

Epoch: 5| Step: 8
Training loss: 1.1967684785537116
Validation loss: 2.518977769194843

Epoch: 5| Step: 9
Training loss: 1.4313167606425437
Validation loss: 2.5164025939965176

Epoch: 5| Step: 10
Training loss: 1.4041120595907086
Validation loss: 2.525352923204748

Epoch: 264| Step: 0
Training loss: 1.2263599884604406
Validation loss: 2.5041617935846054

Epoch: 5| Step: 1
Training loss: 1.0874972770919913
Validation loss: 2.4759355851872

Epoch: 5| Step: 2
Training loss: 1.1452206563098632
Validation loss: 2.4850653366892

Epoch: 5| Step: 3
Training loss: 1.5083021248527118
Validation loss: 2.528734198364609

Epoch: 5| Step: 4
Training loss: 1.079961677330526
Validation loss: 2.5289139627269885

Epoch: 5| Step: 5
Training loss: 1.2403511052504286
Validation loss: 2.485118212790497

Epoch: 5| Step: 6
Training loss: 0.9028136776038043
Validation loss: 2.4820755124830076

Epoch: 5| Step: 7
Training loss: 1.489143422220556
Validation loss: 2.5213789217683162

Epoch: 5| Step: 8
Training loss: 1.505992759803704
Validation loss: 2.568622620943359

Epoch: 5| Step: 9
Training loss: 1.2667139807865777
Validation loss: 2.5748879653320214

Epoch: 5| Step: 10
Training loss: 0.9413425534808115
Validation loss: 2.572180605625332

Epoch: 265| Step: 0
Training loss: 1.2789088934869308
Validation loss: 2.5245698616675973

Epoch: 5| Step: 1
Training loss: 1.2784465264127833
Validation loss: 2.496659255587755

Epoch: 5| Step: 2
Training loss: 1.5072328708502332
Validation loss: 2.485317266944704

Epoch: 5| Step: 3
Training loss: 1.4080347391687227
Validation loss: 2.439799094563034

Epoch: 5| Step: 4
Training loss: 1.2719016144988267
Validation loss: 2.3906390694864994

Epoch: 5| Step: 5
Training loss: 0.8868112725877074
Validation loss: 2.3769227779072133

Epoch: 5| Step: 6
Training loss: 1.0768290484560183
Validation loss: 2.4174733334363148

Epoch: 5| Step: 7
Training loss: 1.2522178524747432
Validation loss: 2.4392882214629807

Epoch: 5| Step: 8
Training loss: 1.5366424277842583
Validation loss: 2.4435939994052163

Epoch: 5| Step: 9
Training loss: 0.5077579762458229
Validation loss: 2.47185693858727

Epoch: 5| Step: 10
Training loss: 1.0815727832551125
Validation loss: 2.5441825269394016

Epoch: 266| Step: 0
Training loss: 1.258872255072519
Validation loss: 2.5927744697692496

Epoch: 5| Step: 1
Training loss: 1.220733495715943
Validation loss: 2.5487471518649265

Epoch: 5| Step: 2
Training loss: 1.1321909810875306
Validation loss: 2.463237697303367

Epoch: 5| Step: 3
Training loss: 1.1622269258430304
Validation loss: 2.433590283132393

Epoch: 5| Step: 4
Training loss: 1.0556208119103223
Validation loss: 2.3719389942649998

Epoch: 5| Step: 5
Training loss: 1.0484188709224238
Validation loss: 2.3815749681564995

Epoch: 5| Step: 6
Training loss: 1.851118461062059
Validation loss: 2.3470069924274197

Epoch: 5| Step: 7
Training loss: 0.5852627493045286
Validation loss: 2.3709721566251867

Epoch: 5| Step: 8
Training loss: 1.228999250400895
Validation loss: 2.475768566860512

Epoch: 5| Step: 9
Training loss: 1.131863637326868
Validation loss: 2.524639428953304

Epoch: 5| Step: 10
Training loss: 1.5262469868548219
Validation loss: 2.5679790947544023

Epoch: 267| Step: 0
Training loss: 1.1270308707408618
Validation loss: 2.534328577698746

Epoch: 5| Step: 1
Training loss: 1.4624239453485965
Validation loss: 2.4228643930937164

Epoch: 5| Step: 2
Training loss: 1.2182386254700004
Validation loss: 2.378172596389706

Epoch: 5| Step: 3
Training loss: 1.309223900136209
Validation loss: 2.350536528308585

Epoch: 5| Step: 4
Training loss: 1.2136499850457203
Validation loss: 2.385240974911397

Epoch: 5| Step: 5
Training loss: 1.2189397908644817
Validation loss: 2.4434528866894385

Epoch: 5| Step: 6
Training loss: 1.0233879950977205
Validation loss: 2.539218333268477

Epoch: 5| Step: 7
Training loss: 0.9380561768296257
Validation loss: 2.5938113862972343

Epoch: 5| Step: 8
Training loss: 1.5966363836826527
Validation loss: 2.661358997960393

Epoch: 5| Step: 9
Training loss: 1.2825871445047705
Validation loss: 2.6878743212685117

Epoch: 5| Step: 10
Training loss: 1.015972899492278
Validation loss: 2.5758504111809875

Epoch: 268| Step: 0
Training loss: 0.8935946096038285
Validation loss: 2.478928898320509

Epoch: 5| Step: 1
Training loss: 1.224759763399583
Validation loss: 2.3969736781882762

Epoch: 5| Step: 2
Training loss: 1.4965527978129758
Validation loss: 2.388292519904695

Epoch: 5| Step: 3
Training loss: 1.1689204290636819
Validation loss: 2.4335789091172937

Epoch: 5| Step: 4
Training loss: 1.26179371897473
Validation loss: 2.474004562455494

Epoch: 5| Step: 5
Training loss: 1.0144861732243826
Validation loss: 2.540712888370235

Epoch: 5| Step: 6
Training loss: 1.5468615907030068
Validation loss: 2.5638172816644857

Epoch: 5| Step: 7
Training loss: 1.4463595335158754
Validation loss: 2.573359989591615

Epoch: 5| Step: 8
Training loss: 1.186893057060585
Validation loss: 2.530434861439514

Epoch: 5| Step: 9
Training loss: 1.122150468079829
Validation loss: 2.496219378998708

Epoch: 5| Step: 10
Training loss: 0.7374184223898061
Validation loss: 2.4241818537992312

Epoch: 269| Step: 0
Training loss: 0.9991140613489253
Validation loss: 2.3874739635344757

Epoch: 5| Step: 1
Training loss: 0.9520678989876112
Validation loss: 2.3987338124997146

Epoch: 5| Step: 2
Training loss: 1.4132633374683234
Validation loss: 2.474874812490483

Epoch: 5| Step: 3
Training loss: 1.1595385412972101
Validation loss: 2.4860300783900753

Epoch: 5| Step: 4
Training loss: 1.1734764854568522
Validation loss: 2.5499781146187073

Epoch: 5| Step: 5
Training loss: 1.4876710937580002
Validation loss: 2.5583062839658024

Epoch: 5| Step: 6
Training loss: 0.9355247670151718
Validation loss: 2.5650099985292054

Epoch: 5| Step: 7
Training loss: 1.3582210685503584
Validation loss: 2.55526516031159

Epoch: 5| Step: 8
Training loss: 1.2654909604524793
Validation loss: 2.4896308122774764

Epoch: 5| Step: 9
Training loss: 1.1229473036701536
Validation loss: 2.4815693762231947

Epoch: 5| Step: 10
Training loss: 1.0718959594990634
Validation loss: 2.455932271246987

Epoch: 270| Step: 0
Training loss: 1.689702468729572
Validation loss: 2.4227213883383643

Epoch: 5| Step: 1
Training loss: 1.2504484325942893
Validation loss: 2.457537353431702

Epoch: 5| Step: 2
Training loss: 1.1833619246364404
Validation loss: 2.436453367128247

Epoch: 5| Step: 3
Training loss: 0.8752835699800635
Validation loss: 2.448153895654262

Epoch: 5| Step: 4
Training loss: 1.075201133275712
Validation loss: 2.49454708485959

Epoch: 5| Step: 5
Training loss: 0.9865703927305286
Validation loss: 2.4679682366005173

Epoch: 5| Step: 6
Training loss: 1.2893466982969006
Validation loss: 2.4718518659720154

Epoch: 5| Step: 7
Training loss: 1.075160664373471
Validation loss: 2.3999160784401785

Epoch: 5| Step: 8
Training loss: 1.0556184404168236
Validation loss: 2.4003532956323133

Epoch: 5| Step: 9
Training loss: 1.0877656984767974
Validation loss: 2.3896828594591906

Epoch: 5| Step: 10
Training loss: 1.341537206141649
Validation loss: 2.4450988188668465

Epoch: 271| Step: 0
Training loss: 0.9063322753390326
Validation loss: 2.5271786430435164

Epoch: 5| Step: 1
Training loss: 1.308635790704701
Validation loss: 2.544634983168682

Epoch: 5| Step: 2
Training loss: 1.485904106783774
Validation loss: 2.604050779327756

Epoch: 5| Step: 3
Training loss: 1.127861727694262
Validation loss: 2.5799323554971476

Epoch: 5| Step: 4
Training loss: 1.0044571964074291
Validation loss: 2.4985052275137347

Epoch: 5| Step: 5
Training loss: 1.1658038741001084
Validation loss: 2.494237318527184

Epoch: 5| Step: 6
Training loss: 1.0804030083262406
Validation loss: 2.457354598087674

Epoch: 5| Step: 7
Training loss: 0.863646658637547
Validation loss: 2.4739278801607263

Epoch: 5| Step: 8
Training loss: 1.1774015699742566
Validation loss: 2.5096147958831394

Epoch: 5| Step: 9
Training loss: 1.3604331009219253
Validation loss: 2.5619000288501392

Epoch: 5| Step: 10
Training loss: 1.258197701746549
Validation loss: 2.6052374159861733

Epoch: 272| Step: 0
Training loss: 1.0343467570249376
Validation loss: 2.573551274250966

Epoch: 5| Step: 1
Training loss: 1.1835110575679553
Validation loss: 2.5540896493847045

Epoch: 5| Step: 2
Training loss: 1.3426651234723654
Validation loss: 2.472970153824243

Epoch: 5| Step: 3
Training loss: 0.985602506624013
Validation loss: 2.433215532079649

Epoch: 5| Step: 4
Training loss: 1.162616727977757
Validation loss: 2.3240911567143447

Epoch: 5| Step: 5
Training loss: 1.2480562833571678
Validation loss: 2.3424921074292353

Epoch: 5| Step: 6
Training loss: 0.8069108044091848
Validation loss: 2.342411868483977

Epoch: 5| Step: 7
Training loss: 1.33042466274829
Validation loss: 2.4004255892491524

Epoch: 5| Step: 8
Training loss: 1.3076315459530712
Validation loss: 2.520554421769429

Epoch: 5| Step: 9
Training loss: 1.400738320487992
Validation loss: 2.620210461982731

Epoch: 5| Step: 10
Training loss: 0.9445494732861794
Validation loss: 2.6613903882631584

Epoch: 273| Step: 0
Training loss: 1.281454070052165
Validation loss: 2.708345004893507

Epoch: 5| Step: 1
Training loss: 0.953159206589531
Validation loss: 2.5950169331098523

Epoch: 5| Step: 2
Training loss: 1.1113332738237494
Validation loss: 2.479087109287534

Epoch: 5| Step: 3
Training loss: 1.2207124023084963
Validation loss: 2.337919091560845

Epoch: 5| Step: 4
Training loss: 1.4143415144168952
Validation loss: 2.299589360693528

Epoch: 5| Step: 5
Training loss: 1.0033199513029816
Validation loss: 2.323968596632107

Epoch: 5| Step: 6
Training loss: 0.9548328919527598
Validation loss: 2.353983346428089

Epoch: 5| Step: 7
Training loss: 1.3444071648729983
Validation loss: 2.4347943797067733

Epoch: 5| Step: 8
Training loss: 1.2981888883073724
Validation loss: 2.614805968955338

Epoch: 5| Step: 9
Training loss: 1.3975819362716573
Validation loss: 2.7060395541362103

Epoch: 5| Step: 10
Training loss: 0.8571345862489109
Validation loss: 2.7406722547121483

Epoch: 274| Step: 0
Training loss: 1.4742204772259855
Validation loss: 2.722084694321673

Epoch: 5| Step: 1
Training loss: 0.9899872240051333
Validation loss: 2.671023878231681

Epoch: 5| Step: 2
Training loss: 1.0446973327666935
Validation loss: 2.4858367668717416

Epoch: 5| Step: 3
Training loss: 1.0693627480407562
Validation loss: 2.325518572689233

Epoch: 5| Step: 4
Training loss: 1.4004903888147886
Validation loss: 2.275221538180665

Epoch: 5| Step: 5
Training loss: 1.3225091571887446
Validation loss: 2.2950755349030656

Epoch: 5| Step: 6
Training loss: 1.3766199452844212
Validation loss: 2.304113526755038

Epoch: 5| Step: 7
Training loss: 1.3338706999973886
Validation loss: 2.446301789029899

Epoch: 5| Step: 8
Training loss: 1.1565533832808133
Validation loss: 2.6085193732676855

Epoch: 5| Step: 9
Training loss: 0.8257705399063222
Validation loss: 2.63136056966771

Epoch: 5| Step: 10
Training loss: 1.2447693582022832
Validation loss: 2.588211569036561

Epoch: 275| Step: 0
Training loss: 1.2593479617413392
Validation loss: 2.4855672130171103

Epoch: 5| Step: 1
Training loss: 1.3268575117887644
Validation loss: 2.376413379219987

Epoch: 5| Step: 2
Training loss: 1.102824360888273
Validation loss: 2.2928186085059337

Epoch: 5| Step: 3
Training loss: 1.2141167038216125
Validation loss: 2.31004773293109

Epoch: 5| Step: 4
Training loss: 0.9514576758665104
Validation loss: 2.297971439070456

Epoch: 5| Step: 5
Training loss: 1.0996170179192923
Validation loss: 2.2967549250026806

Epoch: 5| Step: 6
Training loss: 0.6342699433703315
Validation loss: 2.3544858995010345

Epoch: 5| Step: 7
Training loss: 1.18672772442436
Validation loss: 2.4499611183247167

Epoch: 5| Step: 8
Training loss: 1.253951217463015
Validation loss: 2.471816217358703

Epoch: 5| Step: 9
Training loss: 1.3243833006400225
Validation loss: 2.587506017231594

Epoch: 5| Step: 10
Training loss: 1.3301191281623819
Validation loss: 2.5962513321649903

Epoch: 276| Step: 0
Training loss: 1.0615621803604376
Validation loss: 2.5766318732300943

Epoch: 5| Step: 1
Training loss: 1.1725370952700136
Validation loss: 2.5506826666038904

Epoch: 5| Step: 2
Training loss: 1.1750012722414311
Validation loss: 2.538205202575326

Epoch: 5| Step: 3
Training loss: 1.0436777855110155
Validation loss: 2.482979771012679

Epoch: 5| Step: 4
Training loss: 0.6786911556736669
Validation loss: 2.4614308175471353

Epoch: 5| Step: 5
Training loss: 1.1296490400212407
Validation loss: 2.4607458281859027

Epoch: 5| Step: 6
Training loss: 1.578132100608639
Validation loss: 2.497495953325033

Epoch: 5| Step: 7
Training loss: 1.016282206420317
Validation loss: 2.543765422170308

Epoch: 5| Step: 8
Training loss: 1.0689389402010354
Validation loss: 2.5381426663528113

Epoch: 5| Step: 9
Training loss: 1.168351381836348
Validation loss: 2.562365674715846

Epoch: 5| Step: 10
Training loss: 1.3066214202245001
Validation loss: 2.5703478457691156

Epoch: 277| Step: 0
Training loss: 1.3245211005713593
Validation loss: 2.550587128926766

Epoch: 5| Step: 1
Training loss: 0.9649287506839478
Validation loss: 2.545343660021753

Epoch: 5| Step: 2
Training loss: 1.454503379830964
Validation loss: 2.518564641539258

Epoch: 5| Step: 3
Training loss: 1.184315175178603
Validation loss: 2.4783664493207618

Epoch: 5| Step: 4
Training loss: 1.1546176522774734
Validation loss: 2.459518344797969

Epoch: 5| Step: 5
Training loss: 1.2435271039431637
Validation loss: 2.433901801132453

Epoch: 5| Step: 6
Training loss: 1.185075694535659
Validation loss: 2.371647419030063

Epoch: 5| Step: 7
Training loss: 0.9153345825719771
Validation loss: 2.4071954713641643

Epoch: 5| Step: 8
Training loss: 1.1616603464659765
Validation loss: 2.3809384808303062

Epoch: 5| Step: 9
Training loss: 0.8766221949196429
Validation loss: 2.414850162968641

Epoch: 5| Step: 10
Training loss: 0.674622639501915
Validation loss: 2.4550712908344265

Epoch: 278| Step: 0
Training loss: 1.1632000076894746
Validation loss: 2.483144506870918

Epoch: 5| Step: 1
Training loss: 1.272461452762151
Validation loss: 2.516955416790105

Epoch: 5| Step: 2
Training loss: 1.1135293784443365
Validation loss: 2.475987185989803

Epoch: 5| Step: 3
Training loss: 1.1094597797504473
Validation loss: 2.482960132028124

Epoch: 5| Step: 4
Training loss: 1.0509111402134026
Validation loss: 2.5098611159680813

Epoch: 5| Step: 5
Training loss: 1.1118286292971065
Validation loss: 2.477809898397209

Epoch: 5| Step: 6
Training loss: 0.9788542445221571
Validation loss: 2.4795864560185636

Epoch: 5| Step: 7
Training loss: 1.2604958480469999
Validation loss: 2.4744142336156103

Epoch: 5| Step: 8
Training loss: 1.0548944340902482
Validation loss: 2.484430520032006

Epoch: 5| Step: 9
Training loss: 1.0736375380785579
Validation loss: 2.517841923253316

Epoch: 5| Step: 10
Training loss: 1.0723969703928902
Validation loss: 2.538435542570172

Epoch: 279| Step: 0
Training loss: 1.2752680814560868
Validation loss: 2.5414345267273424

Epoch: 5| Step: 1
Training loss: 0.6922663495208837
Validation loss: 2.5264829804289315

Epoch: 5| Step: 2
Training loss: 1.288138873651634
Validation loss: 2.4851421199373065

Epoch: 5| Step: 3
Training loss: 1.2908178688749992
Validation loss: 2.540483903230571

Epoch: 5| Step: 4
Training loss: 1.2555353152960802
Validation loss: 2.499323210578161

Epoch: 5| Step: 5
Training loss: 0.7873986330338778
Validation loss: 2.5329623950668916

Epoch: 5| Step: 6
Training loss: 1.192161745765656
Validation loss: 2.425818305379603

Epoch: 5| Step: 7
Training loss: 1.0856078491437402
Validation loss: 2.425803825388696

Epoch: 5| Step: 8
Training loss: 1.093744386931049
Validation loss: 2.3781881538562626

Epoch: 5| Step: 9
Training loss: 0.6783891532536336
Validation loss: 2.4252519122969436

Epoch: 5| Step: 10
Training loss: 1.3149032842221573
Validation loss: 2.4285077682314427

Epoch: 280| Step: 0
Training loss: 1.3280154912343818
Validation loss: 2.454671922352316

Epoch: 5| Step: 1
Training loss: 0.9998082334705567
Validation loss: 2.501955139472378

Epoch: 5| Step: 2
Training loss: 1.3657278934360613
Validation loss: 2.51143676540585

Epoch: 5| Step: 3
Training loss: 0.8609040269385072
Validation loss: 2.4892898333704663

Epoch: 5| Step: 4
Training loss: 0.6158655955140697
Validation loss: 2.479606009029277

Epoch: 5| Step: 5
Training loss: 0.9817866249062408
Validation loss: 2.4405456175863005

Epoch: 5| Step: 6
Training loss: 1.1179586563347792
Validation loss: 2.4702073231692734

Epoch: 5| Step: 7
Training loss: 1.1997640655958541
Validation loss: 2.475261578037408

Epoch: 5| Step: 8
Training loss: 1.1318991300305716
Validation loss: 2.459857056189109

Epoch: 5| Step: 9
Training loss: 1.0625429705738003
Validation loss: 2.4766251471445515

Epoch: 5| Step: 10
Training loss: 1.2496243866200347
Validation loss: 2.5251213715472436

Epoch: 281| Step: 0
Training loss: 1.0835773975593368
Validation loss: 2.5126068541060214

Epoch: 5| Step: 1
Training loss: 0.9139237909953847
Validation loss: 2.5556101582142032

Epoch: 5| Step: 2
Training loss: 1.4053851541167437
Validation loss: 2.5052092935524777

Epoch: 5| Step: 3
Training loss: 0.4611596041130427
Validation loss: 2.5157196041400387

Epoch: 5| Step: 4
Training loss: 1.1677108020512497
Validation loss: 2.4547286833771698

Epoch: 5| Step: 5
Training loss: 0.9470359602488309
Validation loss: 2.3778313295303795

Epoch: 5| Step: 6
Training loss: 1.1089336430688355
Validation loss: 2.36655570864456

Epoch: 5| Step: 7
Training loss: 1.0961555186219012
Validation loss: 2.3984845986431047

Epoch: 5| Step: 8
Training loss: 1.289728027549961
Validation loss: 2.4216058396928415

Epoch: 5| Step: 9
Training loss: 1.4364779612320784
Validation loss: 2.440938684855901

Epoch: 5| Step: 10
Training loss: 0.8580344755431163
Validation loss: 2.4885695175489877

Epoch: 282| Step: 0
Training loss: 1.6065154364681573
Validation loss: 2.5327316286755024

Epoch: 5| Step: 1
Training loss: 1.1201362375437058
Validation loss: 2.5425475430001874

Epoch: 5| Step: 2
Training loss: 1.117739401056987
Validation loss: 2.48921784865645

Epoch: 5| Step: 3
Training loss: 0.9847393875228136
Validation loss: 2.45970626426149

Epoch: 5| Step: 4
Training loss: 0.9260504930645568
Validation loss: 2.437893216820984

Epoch: 5| Step: 5
Training loss: 1.195030129184538
Validation loss: 2.398200829854456

Epoch: 5| Step: 6
Training loss: 0.6277421401278873
Validation loss: 2.417117343254641

Epoch: 5| Step: 7
Training loss: 1.1132084337480441
Validation loss: 2.397202300123512

Epoch: 5| Step: 8
Training loss: 1.1337975790014443
Validation loss: 2.471058307529296

Epoch: 5| Step: 9
Training loss: 0.755923009751693
Validation loss: 2.4906287222515973

Epoch: 5| Step: 10
Training loss: 1.0117794887618
Validation loss: 2.4965968092643207

Epoch: 283| Step: 0
Training loss: 1.1574419424767999
Validation loss: 2.5224194893848613

Epoch: 5| Step: 1
Training loss: 0.8486026806853976
Validation loss: 2.5499619695251234

Epoch: 5| Step: 2
Training loss: 1.12662425936695
Validation loss: 2.519361110983172

Epoch: 5| Step: 3
Training loss: 0.5610858306708321
Validation loss: 2.4707538867194168

Epoch: 5| Step: 4
Training loss: 1.179592356097659
Validation loss: 2.4593427724116093

Epoch: 5| Step: 5
Training loss: 1.154300231412342
Validation loss: 2.4765031783597076

Epoch: 5| Step: 6
Training loss: 1.2293660384735394
Validation loss: 2.476519209193318

Epoch: 5| Step: 7
Training loss: 0.8751639485033355
Validation loss: 2.4423845160770474

Epoch: 5| Step: 8
Training loss: 1.1373774661624247
Validation loss: 2.4448385986723657

Epoch: 5| Step: 9
Training loss: 1.1223379003645044
Validation loss: 2.407635593888745

Epoch: 5| Step: 10
Training loss: 1.2829810288528913
Validation loss: 2.376665899813385

Epoch: 284| Step: 0
Training loss: 0.8217994292584255
Validation loss: 2.42298787482621

Epoch: 5| Step: 1
Training loss: 1.064426302790649
Validation loss: 2.411909210919335

Epoch: 5| Step: 2
Training loss: 0.8972957488115422
Validation loss: 2.384492299461523

Epoch: 5| Step: 3
Training loss: 1.1714117024449862
Validation loss: 2.4300616399355

Epoch: 5| Step: 4
Training loss: 0.7874875355294183
Validation loss: 2.4906790428779457

Epoch: 5| Step: 5
Training loss: 1.3488413147512055
Validation loss: 2.5060030921774423

Epoch: 5| Step: 6
Training loss: 0.9168810629822977
Validation loss: 2.545410756014959

Epoch: 5| Step: 7
Training loss: 1.1902410093247167
Validation loss: 2.5054023479427836

Epoch: 5| Step: 8
Training loss: 1.1215499321973976
Validation loss: 2.493656627699757

Epoch: 5| Step: 9
Training loss: 1.1227722362897694
Validation loss: 2.4488405856597044

Epoch: 5| Step: 10
Training loss: 1.0934768880731138
Validation loss: 2.4592249716586627

Epoch: 285| Step: 0
Training loss: 0.8500534124983186
Validation loss: 2.4332991408065365

Epoch: 5| Step: 1
Training loss: 1.3206481958275789
Validation loss: 2.4202917538811124

Epoch: 5| Step: 2
Training loss: 0.8428973375393111
Validation loss: 2.423359363432639

Epoch: 5| Step: 3
Training loss: 0.9034032835100323
Validation loss: 2.452609266174962

Epoch: 5| Step: 4
Training loss: 1.15099107910199
Validation loss: 2.4887834527906847

Epoch: 5| Step: 5
Training loss: 1.059381733650705
Validation loss: 2.5067074308514976

Epoch: 5| Step: 6
Training loss: 1.1558200964872196
Validation loss: 2.510345972334014

Epoch: 5| Step: 7
Training loss: 1.0380418396677846
Validation loss: 2.5208487520803162

Epoch: 5| Step: 8
Training loss: 0.9550742244835836
Validation loss: 2.5707083093525553

Epoch: 5| Step: 9
Training loss: 1.1857778207988467
Validation loss: 2.5418588036816328

Epoch: 5| Step: 10
Training loss: 1.2051945511082922
Validation loss: 2.500604772737858

Epoch: 286| Step: 0
Training loss: 1.0120697001929788
Validation loss: 2.404072696846

Epoch: 5| Step: 1
Training loss: 0.8710381186473172
Validation loss: 2.357979245158639

Epoch: 5| Step: 2
Training loss: 1.2873921062111915
Validation loss: 2.3081685816021973

Epoch: 5| Step: 3
Training loss: 1.11443780085594
Validation loss: 2.3251620538862303

Epoch: 5| Step: 4
Training loss: 0.9854933425933928
Validation loss: 2.4437422974108967

Epoch: 5| Step: 5
Training loss: 0.9908314546920723
Validation loss: 2.5163900335245355

Epoch: 5| Step: 6
Training loss: 0.8677229388146164
Validation loss: 2.580259738104549

Epoch: 5| Step: 7
Training loss: 1.22601558859593
Validation loss: 2.577297001413263

Epoch: 5| Step: 8
Training loss: 1.1302562943696528
Validation loss: 2.5582593498770416

Epoch: 5| Step: 9
Training loss: 0.8229483626494635
Validation loss: 2.498736792516986

Epoch: 5| Step: 10
Training loss: 1.340789727892255
Validation loss: 2.442869398383063

Epoch: 287| Step: 0
Training loss: 0.9097167497005986
Validation loss: 2.4505752952001854

Epoch: 5| Step: 1
Training loss: 0.6770169421193318
Validation loss: 2.4103067414609227

Epoch: 5| Step: 2
Training loss: 1.325089520003441
Validation loss: 2.382963445607258

Epoch: 5| Step: 3
Training loss: 0.8662326814315695
Validation loss: 2.465962065418756

Epoch: 5| Step: 4
Training loss: 1.2753785674619071
Validation loss: 2.470669568276677

Epoch: 5| Step: 5
Training loss: 0.7919178656196637
Validation loss: 2.5131461887802864

Epoch: 5| Step: 6
Training loss: 1.1089376742750856
Validation loss: 2.56120482757562

Epoch: 5| Step: 7
Training loss: 1.2950463328670758
Validation loss: 2.5517789503898505

Epoch: 5| Step: 8
Training loss: 1.0220466073041048
Validation loss: 2.530865523452864

Epoch: 5| Step: 9
Training loss: 1.2329443354637353
Validation loss: 2.4823829856506214

Epoch: 5| Step: 10
Training loss: 0.5687498082171106
Validation loss: 2.451857504370533

Epoch: 288| Step: 0
Training loss: 0.7268289877185695
Validation loss: 2.4234834070426814

Epoch: 5| Step: 1
Training loss: 1.079352191801139
Validation loss: 2.457230052524953

Epoch: 5| Step: 2
Training loss: 0.8927779026291206
Validation loss: 2.495639871003233

Epoch: 5| Step: 3
Training loss: 0.9842262761224491
Validation loss: 2.524623186806644

Epoch: 5| Step: 4
Training loss: 1.0503587972600446
Validation loss: 2.538607518628755

Epoch: 5| Step: 5
Training loss: 1.0601193179147064
Validation loss: 2.513750454412821

Epoch: 5| Step: 6
Training loss: 0.996609812175945
Validation loss: 2.480013765622048

Epoch: 5| Step: 7
Training loss: 0.7837865848915605
Validation loss: 2.472190901402068

Epoch: 5| Step: 8
Training loss: 1.3338007207090896
Validation loss: 2.4354127477469096

Epoch: 5| Step: 9
Training loss: 1.1247143912697664
Validation loss: 2.3939895861691447

Epoch: 5| Step: 10
Training loss: 1.2132246997867073
Validation loss: 2.3464256048939087

Epoch: 289| Step: 0
Training loss: 0.8054138904911143
Validation loss: 2.2852026835897665

Epoch: 5| Step: 1
Training loss: 1.0364050476076445
Validation loss: 2.3003336075075276

Epoch: 5| Step: 2
Training loss: 0.8743242992674167
Validation loss: 2.3274068936869337

Epoch: 5| Step: 3
Training loss: 1.347843323038276
Validation loss: 2.3677022385079707

Epoch: 5| Step: 4
Training loss: 1.3377181115966659
Validation loss: 2.423143205239854

Epoch: 5| Step: 5
Training loss: 0.7890490917917306
Validation loss: 2.4448073566929707

Epoch: 5| Step: 6
Training loss: 1.1780976451662764
Validation loss: 2.452998857015842

Epoch: 5| Step: 7
Training loss: 0.5265067345495511
Validation loss: 2.4342316180478734

Epoch: 5| Step: 8
Training loss: 0.8125028243382589
Validation loss: 2.4543738492927294

Epoch: 5| Step: 9
Training loss: 1.3354876915447698
Validation loss: 2.4494468840601447

Epoch: 5| Step: 10
Training loss: 0.8936568071555908
Validation loss: 2.4980866134469077

Epoch: 290| Step: 0
Training loss: 1.1968269477939149
Validation loss: 2.460649935629117

Epoch: 5| Step: 1
Training loss: 0.7945546794726434
Validation loss: 2.482613570957198

Epoch: 5| Step: 2
Training loss: 1.2650004129069865
Validation loss: 2.4467616801799363

Epoch: 5| Step: 3
Training loss: 0.6693445949256138
Validation loss: 2.4854983210470514

Epoch: 5| Step: 4
Training loss: 0.8408898514226741
Validation loss: 2.466103738460462

Epoch: 5| Step: 5
Training loss: 1.29351518499532
Validation loss: 2.492315210328575

Epoch: 5| Step: 6
Training loss: 1.058329193727903
Validation loss: 2.4538667643054457

Epoch: 5| Step: 7
Training loss: 0.999250697504315
Validation loss: 2.4175900059238677

Epoch: 5| Step: 8
Training loss: 1.1564691181306488
Validation loss: 2.3695188992577325

Epoch: 5| Step: 9
Training loss: 0.6598460806196399
Validation loss: 2.381985945951787

Epoch: 5| Step: 10
Training loss: 0.9362029321754596
Validation loss: 2.3896219968589145

Epoch: 291| Step: 0
Training loss: 0.8676272128051802
Validation loss: 2.375370110136454

Epoch: 5| Step: 1
Training loss: 1.244903905216367
Validation loss: 2.443683940463624

Epoch: 5| Step: 2
Training loss: 1.0977882495941376
Validation loss: 2.4679416066605797

Epoch: 5| Step: 3
Training loss: 0.9641691621854156
Validation loss: 2.5094252105762096

Epoch: 5| Step: 4
Training loss: 0.5773548976869843
Validation loss: 2.475115874921447

Epoch: 5| Step: 5
Training loss: 0.9609672107600471
Validation loss: 2.4061728988374678

Epoch: 5| Step: 6
Training loss: 0.8932479248449828
Validation loss: 2.4264665751537082

Epoch: 5| Step: 7
Training loss: 1.1373944977681059
Validation loss: 2.3964550010727015

Epoch: 5| Step: 8
Training loss: 1.3761343611694135
Validation loss: 2.3796162433755916

Epoch: 5| Step: 9
Training loss: 0.9335382676497214
Validation loss: 2.451912016184676

Epoch: 5| Step: 10
Training loss: 0.7215858986993945
Validation loss: 2.4571846333828016

Epoch: 292| Step: 0
Training loss: 1.108152226061419
Validation loss: 2.484526105606412

Epoch: 5| Step: 1
Training loss: 1.2380614461671415
Validation loss: 2.411329110777391

Epoch: 5| Step: 2
Training loss: 0.395095459533435
Validation loss: 2.455297873263356

Epoch: 5| Step: 3
Training loss: 1.03372346578768
Validation loss: 2.3962791901875553

Epoch: 5| Step: 4
Training loss: 1.0171829012577855
Validation loss: 2.399161208208748

Epoch: 5| Step: 5
Training loss: 1.1932000336350663
Validation loss: 2.3765293458470884

Epoch: 5| Step: 6
Training loss: 0.5924947671216545
Validation loss: 2.361680405388837

Epoch: 5| Step: 7
Training loss: 0.9992903038812705
Validation loss: 2.4054949624880204

Epoch: 5| Step: 8
Training loss: 1.0060322733303837
Validation loss: 2.467114347129207

Epoch: 5| Step: 9
Training loss: 0.8618493957257154
Validation loss: 2.490497647933468

Epoch: 5| Step: 10
Training loss: 1.23240064309477
Validation loss: 2.570196215991408

Epoch: 293| Step: 0
Training loss: 1.008542173737859
Validation loss: 2.5766787805980758

Epoch: 5| Step: 1
Training loss: 0.7992127105991838
Validation loss: 2.489770541826343

Epoch: 5| Step: 2
Training loss: 0.9434678862341813
Validation loss: 2.4473153968832193

Epoch: 5| Step: 3
Training loss: 1.1581837232743366
Validation loss: 2.4199729137452324

Epoch: 5| Step: 4
Training loss: 1.1663630237988587
Validation loss: 2.410351505182803

Epoch: 5| Step: 5
Training loss: 0.8272357340643489
Validation loss: 2.381548769430947

Epoch: 5| Step: 6
Training loss: 1.2388713405394582
Validation loss: 2.433456064891821

Epoch: 5| Step: 7
Training loss: 0.8694506831515743
Validation loss: 2.5378489623487277

Epoch: 5| Step: 8
Training loss: 1.176758217712586
Validation loss: 2.632985687231664

Epoch: 5| Step: 9
Training loss: 0.8299767286416349
Validation loss: 2.570012782493492

Epoch: 5| Step: 10
Training loss: 1.0612837618252782
Validation loss: 2.4811267308556637

Epoch: 294| Step: 0
Training loss: 0.7886348736468844
Validation loss: 2.3716796285239776

Epoch: 5| Step: 1
Training loss: 1.0068397854898885
Validation loss: 2.3734211447494507

Epoch: 5| Step: 2
Training loss: 1.181776256501201
Validation loss: 2.38415067589438

Epoch: 5| Step: 3
Training loss: 0.9778790868639375
Validation loss: 2.320287402771945

Epoch: 5| Step: 4
Training loss: 1.403693949123015
Validation loss: 2.3765018843823946

Epoch: 5| Step: 5
Training loss: 0.6443912700889324
Validation loss: 2.3274132763247675

Epoch: 5| Step: 6
Training loss: 0.9853571276323271
Validation loss: 2.4073649714361545

Epoch: 5| Step: 7
Training loss: 0.7622467949494278
Validation loss: 2.459133570302669

Epoch: 5| Step: 8
Training loss: 1.0852158158653948
Validation loss: 2.5650038912841024

Epoch: 5| Step: 9
Training loss: 0.7858584096864528
Validation loss: 2.651347941274359

Epoch: 5| Step: 10
Training loss: 1.1848914960285772
Validation loss: 2.6223671450040977

Epoch: 295| Step: 0
Training loss: 1.0346149684838628
Validation loss: 2.6164776459726737

Epoch: 5| Step: 1
Training loss: 0.8769642036944624
Validation loss: 2.5578166764512686

Epoch: 5| Step: 2
Training loss: 1.0908776851309343
Validation loss: 2.461291472980008

Epoch: 5| Step: 3
Training loss: 0.970842132746776
Validation loss: 2.4050989027931435

Epoch: 5| Step: 4
Training loss: 0.7391008943742521
Validation loss: 2.370181856663611

Epoch: 5| Step: 5
Training loss: 1.09323969244225
Validation loss: 2.3921691928124242

Epoch: 5| Step: 6
Training loss: 0.9367704413804951
Validation loss: 2.3785185071645647

Epoch: 5| Step: 7
Training loss: 1.045768209661356
Validation loss: 2.3978473637029207

Epoch: 5| Step: 8
Training loss: 1.2385416328723198
Validation loss: 2.4501796577015726

Epoch: 5| Step: 9
Training loss: 1.0971714999282571
Validation loss: 2.471676451415624

Epoch: 5| Step: 10
Training loss: 0.6208573857284325
Validation loss: 2.5317954343350575

Epoch: 296| Step: 0
Training loss: 1.338233001783463
Validation loss: 2.5941400809130206

Epoch: 5| Step: 1
Training loss: 1.2170538225332308
Validation loss: 2.6419531039377953

Epoch: 5| Step: 2
Training loss: 1.2719067225143843
Validation loss: 2.6445575684385827

Epoch: 5| Step: 3
Training loss: 0.8121200920451056
Validation loss: 2.529167885753095

Epoch: 5| Step: 4
Training loss: 1.0725719799438378
Validation loss: 2.443130156233518

Epoch: 5| Step: 5
Training loss: 0.5460937096155067
Validation loss: 2.377149061880524

Epoch: 5| Step: 6
Training loss: 0.9364772940396858
Validation loss: 2.399551130391743

Epoch: 5| Step: 7
Training loss: 0.5466044710510332
Validation loss: 2.4185034299737342

Epoch: 5| Step: 8
Training loss: 0.8320044929607744
Validation loss: 2.4371637028754933

Epoch: 5| Step: 9
Training loss: 0.7568262111900224
Validation loss: 2.496534200158775

Epoch: 5| Step: 10
Training loss: 1.2154983768365992
Validation loss: 2.5137614391598966

Epoch: 297| Step: 0
Training loss: 0.6984259943686466
Validation loss: 2.49045239441008

Epoch: 5| Step: 1
Training loss: 1.0760900116677319
Validation loss: 2.485984723947954

Epoch: 5| Step: 2
Training loss: 1.100953170314018
Validation loss: 2.495614006823409

Epoch: 5| Step: 3
Training loss: 0.8081521196527904
Validation loss: 2.4850774323926226

Epoch: 5| Step: 4
Training loss: 0.9605422719105946
Validation loss: 2.488307486087507

Epoch: 5| Step: 5
Training loss: 0.9569673166523707
Validation loss: 2.4890109963651543

Epoch: 5| Step: 6
Training loss: 0.851388230996831
Validation loss: 2.4942382010436694

Epoch: 5| Step: 7
Training loss: 1.1622595425560915
Validation loss: 2.4363925817238137

Epoch: 5| Step: 8
Training loss: 0.956910666829455
Validation loss: 2.436090024221853

Epoch: 5| Step: 9
Training loss: 1.016413573254087
Validation loss: 2.4223795460188478

Epoch: 5| Step: 10
Training loss: 0.9407252147429491
Validation loss: 2.455220994097855

Epoch: 298| Step: 0
Training loss: 1.2094013930799568
Validation loss: 2.3988875297945396

Epoch: 5| Step: 1
Training loss: 1.1991610932546484
Validation loss: 2.4225893309527216

Epoch: 5| Step: 2
Training loss: 1.123085618387413
Validation loss: 2.421893892667704

Epoch: 5| Step: 3
Training loss: 0.8684710720363804
Validation loss: 2.4436222532832463

Epoch: 5| Step: 4
Training loss: 0.46564152323444613
Validation loss: 2.458320173044437

Epoch: 5| Step: 5
Training loss: 0.9618111027642929
Validation loss: 2.4591554334633603

Epoch: 5| Step: 6
Training loss: 0.5245064595409276
Validation loss: 2.514622252969425

Epoch: 5| Step: 7
Training loss: 0.842890089322849
Validation loss: 2.516310882465119

Epoch: 5| Step: 8
Training loss: 1.0718046493353979
Validation loss: 2.4492250261113337

Epoch: 5| Step: 9
Training loss: 0.9703444618452712
Validation loss: 2.4406194380659962

Epoch: 5| Step: 10
Training loss: 0.9444533613351234
Validation loss: 2.4258352175275526

Epoch: 299| Step: 0
Training loss: 1.0529234650883892
Validation loss: 2.415570642979672

Epoch: 5| Step: 1
Training loss: 0.7424444456542271
Validation loss: 2.406403890226608

Epoch: 5| Step: 2
Training loss: 0.9683009922144238
Validation loss: 2.43623337546915

Epoch: 5| Step: 3
Training loss: 1.0030411135575428
Validation loss: 2.4555304998070024

Epoch: 5| Step: 4
Training loss: 0.9854546938139143
Validation loss: 2.485703428728051

Epoch: 5| Step: 5
Training loss: 1.378703721169823
Validation loss: 2.494267450076559

Epoch: 5| Step: 6
Training loss: 0.5662560888725136
Validation loss: 2.5219744671832554

Epoch: 5| Step: 7
Training loss: 0.7214805730978732
Validation loss: 2.4977776586473714

Epoch: 5| Step: 8
Training loss: 1.0596595269540945
Validation loss: 2.5156114094195807

Epoch: 5| Step: 9
Training loss: 0.9228067054140311
Validation loss: 2.4764430788904206

Epoch: 5| Step: 10
Training loss: 0.824539447604155
Validation loss: 2.4419781567208867

Epoch: 300| Step: 0
Training loss: 1.0519212969396232
Validation loss: 2.3873316823991195

Epoch: 5| Step: 1
Training loss: 1.1658388447898251
Validation loss: 2.3357175648791686

Epoch: 5| Step: 2
Training loss: 0.9100478930498662
Validation loss: 2.3529718506719464

Epoch: 5| Step: 3
Training loss: 0.9250604583983685
Validation loss: 2.362274064320558

Epoch: 5| Step: 4
Training loss: 0.6394609249247488
Validation loss: 2.3773399595925455

Epoch: 5| Step: 5
Training loss: 0.8194627265902281
Validation loss: 2.379311579774342

Epoch: 5| Step: 6
Training loss: 1.0537232123394462
Validation loss: 2.4409695184392635

Epoch: 5| Step: 7
Training loss: 0.6764596609845265
Validation loss: 2.4796739517512667

Epoch: 5| Step: 8
Training loss: 0.9599720516706247
Validation loss: 2.5197819130946013

Epoch: 5| Step: 9
Training loss: 0.7848564828291322
Validation loss: 2.4810656310558885

Epoch: 5| Step: 10
Training loss: 1.296289242745439
Validation loss: 2.420982511307996

Epoch: 301| Step: 0
Training loss: 0.7402431517712282
Validation loss: 2.3706758692494825

Epoch: 5| Step: 1
Training loss: 0.6602984168107497
Validation loss: 2.3291951651947307

Epoch: 5| Step: 2
Training loss: 0.819802443559927
Validation loss: 2.3315246606739466

Epoch: 5| Step: 3
Training loss: 1.1478904407272341
Validation loss: 2.3903440315313462

Epoch: 5| Step: 4
Training loss: 1.1307441507778992
Validation loss: 2.4143607142596046

Epoch: 5| Step: 5
Training loss: 1.2826839889108794
Validation loss: 2.4616281249036436

Epoch: 5| Step: 6
Training loss: 1.0728676917493758
Validation loss: 2.4705617281597743

Epoch: 5| Step: 7
Training loss: 0.6179575160725925
Validation loss: 2.5029625331244265

Epoch: 5| Step: 8
Training loss: 0.5963541944301105
Validation loss: 2.489742613945532

Epoch: 5| Step: 9
Training loss: 1.0631925906090356
Validation loss: 2.461910927603797

Epoch: 5| Step: 10
Training loss: 0.936229257850425
Validation loss: 2.4462538886636827

Epoch: 302| Step: 0
Training loss: 1.0463706552444685
Validation loss: 2.45368617520562

Epoch: 5| Step: 1
Training loss: 1.1167834958599008
Validation loss: 2.438475927497323

Epoch: 5| Step: 2
Training loss: 1.0028509389536377
Validation loss: 2.427600014634084

Epoch: 5| Step: 3
Training loss: 1.0027139909052172
Validation loss: 2.4086670579996325

Epoch: 5| Step: 4
Training loss: 0.9894972546266133
Validation loss: 2.4348075916953027

Epoch: 5| Step: 5
Training loss: 0.8596779722727851
Validation loss: 2.4479964491794766

Epoch: 5| Step: 6
Training loss: 0.8310566598440718
Validation loss: 2.4834940462812063

Epoch: 5| Step: 7
Training loss: 0.6201250210965596
Validation loss: 2.461321174075659

Epoch: 5| Step: 8
Training loss: 0.6425009915978762
Validation loss: 2.5505753690208826

Epoch: 5| Step: 9
Training loss: 1.2333623861207363
Validation loss: 2.5092652037872267

Epoch: 5| Step: 10
Training loss: 0.6765615555754451
Validation loss: 2.4757596305411362

Epoch: 303| Step: 0
Training loss: 0.9002824168027053
Validation loss: 2.435397735839045

Epoch: 5| Step: 1
Training loss: 0.7810904149142431
Validation loss: 2.3856945420516076

Epoch: 5| Step: 2
Training loss: 1.1013950734701785
Validation loss: 2.41654982636223

Epoch: 5| Step: 3
Training loss: 1.101614714122259
Validation loss: 2.405503346677573

Epoch: 5| Step: 4
Training loss: 0.7436556299428787
Validation loss: 2.4428895842447886

Epoch: 5| Step: 5
Training loss: 1.1261747372763227
Validation loss: 2.410744018119584

Epoch: 5| Step: 6
Training loss: 0.9162070068327104
Validation loss: 2.4720587053184206

Epoch: 5| Step: 7
Training loss: 0.9918324593721938
Validation loss: 2.502526636960738

Epoch: 5| Step: 8
Training loss: 0.9115189595722449
Validation loss: 2.4913715728450856

Epoch: 5| Step: 9
Training loss: 0.8193074199819625
Validation loss: 2.4754287351700066

Epoch: 5| Step: 10
Training loss: 0.5167944967917277
Validation loss: 2.488767021450085

Epoch: 304| Step: 0
Training loss: 0.8932259710642129
Validation loss: 2.4432544919358157

Epoch: 5| Step: 1
Training loss: 1.1301070957577781
Validation loss: 2.39964829682781

Epoch: 5| Step: 2
Training loss: 1.0114181248654162
Validation loss: 2.4274442016187896

Epoch: 5| Step: 3
Training loss: 1.0310526572321481
Validation loss: 2.4429534674363014

Epoch: 5| Step: 4
Training loss: 1.0722407770665185
Validation loss: 2.4086500923606873

Epoch: 5| Step: 5
Training loss: 1.0621255326944825
Validation loss: 2.3996731195829444

Epoch: 5| Step: 6
Training loss: 0.7611859536750761
Validation loss: 2.372217263318727

Epoch: 5| Step: 7
Training loss: 0.8737586957747117
Validation loss: 2.365674738456518

Epoch: 5| Step: 8
Training loss: 0.681025623853353
Validation loss: 2.340250626622136

Epoch: 5| Step: 9
Training loss: 0.6609694759488814
Validation loss: 2.363967810696605

Epoch: 5| Step: 10
Training loss: 0.782446326770262
Validation loss: 2.3769892062259994

Epoch: 305| Step: 0
Training loss: 0.6891802931464382
Validation loss: 2.4308336683819647

Epoch: 5| Step: 1
Training loss: 0.8180115172127992
Validation loss: 2.5162739737941457

Epoch: 5| Step: 2
Training loss: 0.9853642049834709
Validation loss: 2.5731213990410655

Epoch: 5| Step: 3
Training loss: 0.8609131659030188
Validation loss: 2.508681685823356

Epoch: 5| Step: 4
Training loss: 0.8550289887538884
Validation loss: 2.4769612175712172

Epoch: 5| Step: 5
Training loss: 1.2496491416620807
Validation loss: 2.457807475178381

Epoch: 5| Step: 6
Training loss: 0.9011739108257341
Validation loss: 2.390032379585628

Epoch: 5| Step: 7
Training loss: 1.1360329987944784
Validation loss: 2.419520309627844

Epoch: 5| Step: 8
Training loss: 1.0470324725240843
Validation loss: 2.3958613434625957

Epoch: 5| Step: 9
Training loss: 0.7224868988380445
Validation loss: 2.4184192848237513

Epoch: 5| Step: 10
Training loss: 0.5255770157673801
Validation loss: 2.455008795411925

Epoch: 306| Step: 0
Training loss: 0.8732262070912185
Validation loss: 2.5123694705784625

Epoch: 5| Step: 1
Training loss: 0.9861424035195049
Validation loss: 2.560581534592348

Epoch: 5| Step: 2
Training loss: 0.6857841494071546
Validation loss: 2.557868780789978

Epoch: 5| Step: 3
Training loss: 1.0838263319120696
Validation loss: 2.600143427438484

Epoch: 5| Step: 4
Training loss: 0.4849758728161073
Validation loss: 2.54882761253899

Epoch: 5| Step: 5
Training loss: 1.0208267224675165
Validation loss: 2.509319405853034

Epoch: 5| Step: 6
Training loss: 1.1767431234495553
Validation loss: 2.4491405913884035

Epoch: 5| Step: 7
Training loss: 1.1270045329885363
Validation loss: 2.3795791440250764

Epoch: 5| Step: 8
Training loss: 0.7151291907910656
Validation loss: 2.4080055309513266

Epoch: 5| Step: 9
Training loss: 0.8509406172589864
Validation loss: 2.3585711357082735

Epoch: 5| Step: 10
Training loss: 0.7894723035775209
Validation loss: 2.421491252600105

Epoch: 307| Step: 0
Training loss: 0.6450177986069769
Validation loss: 2.469274149287633

Epoch: 5| Step: 1
Training loss: 1.091851575979032
Validation loss: 2.5176084924508375

Epoch: 5| Step: 2
Training loss: 0.9478211966146111
Validation loss: 2.481039071431356

Epoch: 5| Step: 3
Training loss: 0.6761760330292724
Validation loss: 2.428812665643833

Epoch: 5| Step: 4
Training loss: 0.899279026162233
Validation loss: 2.382604700821959

Epoch: 5| Step: 5
Training loss: 0.8028262194882619
Validation loss: 2.3919965260218734

Epoch: 5| Step: 6
Training loss: 0.9421377861609921
Validation loss: 2.3363342683503214

Epoch: 5| Step: 7
Training loss: 0.782446707656645
Validation loss: 2.3254333052627807

Epoch: 5| Step: 8
Training loss: 0.9320914978865723
Validation loss: 2.3737764504438217

Epoch: 5| Step: 9
Training loss: 1.0230504243081986
Validation loss: 2.393819310371955

Epoch: 5| Step: 10
Training loss: 1.0795114972737794
Validation loss: 2.4061107597875155

Epoch: 308| Step: 0
Training loss: 1.127548827236916
Validation loss: 2.4624014988861465

Epoch: 5| Step: 1
Training loss: 1.0721077446666993
Validation loss: 2.4739182428933915

Epoch: 5| Step: 2
Training loss: 0.8984546825590279
Validation loss: 2.5033575676519106

Epoch: 5| Step: 3
Training loss: 0.9181354777112847
Validation loss: 2.490976352102875

Epoch: 5| Step: 4
Training loss: 0.8097309463958676
Validation loss: 2.4771272690714157

Epoch: 5| Step: 5
Training loss: 0.9491580268683223
Validation loss: 2.451020708771943

Epoch: 5| Step: 6
Training loss: 0.9170506207878283
Validation loss: 2.4058660119048922

Epoch: 5| Step: 7
Training loss: 0.8806356750772595
Validation loss: 2.401441374306636

Epoch: 5| Step: 8
Training loss: 0.638921006634714
Validation loss: 2.390973882748746

Epoch: 5| Step: 9
Training loss: 0.8100394993440685
Validation loss: 2.4432881911999496

Epoch: 5| Step: 10
Training loss: 0.7091422837798926
Validation loss: 2.4418153324105116

Epoch: 309| Step: 0
Training loss: 0.9881992230657609
Validation loss: 2.4325724127450616

Epoch: 5| Step: 1
Training loss: 0.6956999695677955
Validation loss: 2.4827122019144894

Epoch: 5| Step: 2
Training loss: 0.8193599074520982
Validation loss: 2.5104380886542677

Epoch: 5| Step: 3
Training loss: 0.5606094484925903
Validation loss: 2.512395278592246

Epoch: 5| Step: 4
Training loss: 0.8314601388782793
Validation loss: 2.4919464265271354

Epoch: 5| Step: 5
Training loss: 1.1552260736605882
Validation loss: 2.439465344926811

Epoch: 5| Step: 6
Training loss: 1.0974678067849286
Validation loss: 2.3908610196929705

Epoch: 5| Step: 7
Training loss: 0.5722424499193638
Validation loss: 2.3637324147378753

Epoch: 5| Step: 8
Training loss: 0.7616923792260126
Validation loss: 2.3424695877004567

Epoch: 5| Step: 9
Training loss: 0.9620935882499827
Validation loss: 2.345093480016306

Epoch: 5| Step: 10
Training loss: 1.0767917959135955
Validation loss: 2.3875585945063493

Epoch: 310| Step: 0
Training loss: 1.2622649719988341
Validation loss: 2.4285638323307714

Epoch: 5| Step: 1
Training loss: 0.9611912834181819
Validation loss: 2.4787440459822303

Epoch: 5| Step: 2
Training loss: 0.8070860364990445
Validation loss: 2.538374457014037

Epoch: 5| Step: 3
Training loss: 0.8517642350928925
Validation loss: 2.5630903636938798

Epoch: 5| Step: 4
Training loss: 0.6313680717784464
Validation loss: 2.5323754910999634

Epoch: 5| Step: 5
Training loss: 0.8251024905033919
Validation loss: 2.491296566312704

Epoch: 5| Step: 6
Training loss: 1.051097099170705
Validation loss: 2.4290251182283766

Epoch: 5| Step: 7
Training loss: 0.45291432053988623
Validation loss: 2.41932983142822

Epoch: 5| Step: 8
Training loss: 0.8693287849346287
Validation loss: 2.418333776656618

Epoch: 5| Step: 9
Training loss: 0.6709699079045088
Validation loss: 2.42595761704437

Epoch: 5| Step: 10
Training loss: 1.0039321361722149
Validation loss: 2.412853791788466

Epoch: 311| Step: 0
Training loss: 0.8174869375322695
Validation loss: 2.4383948660501504

Epoch: 5| Step: 1
Training loss: 0.8204473475474561
Validation loss: 2.5182658088046574

Epoch: 5| Step: 2
Training loss: 1.0018079626509073
Validation loss: 2.505962722234588

Epoch: 5| Step: 3
Training loss: 0.8259701674225749
Validation loss: 2.526904083350234

Epoch: 5| Step: 4
Training loss: 0.7718540127020691
Validation loss: 2.4903247048782142

Epoch: 5| Step: 5
Training loss: 0.9558709721081927
Validation loss: 2.443786919964838

Epoch: 5| Step: 6
Training loss: 0.8715078626859073
Validation loss: 2.4229602564078134

Epoch: 5| Step: 7
Training loss: 0.8424645274360804
Validation loss: 2.4364716474877635

Epoch: 5| Step: 8
Training loss: 0.6709513414338397
Validation loss: 2.4275600896899907

Epoch: 5| Step: 9
Training loss: 0.6312513049272703
Validation loss: 2.456497867730403

Epoch: 5| Step: 10
Training loss: 1.2913971537727182
Validation loss: 2.4565437217050503

Epoch: 312| Step: 0
Training loss: 0.7359721084523929
Validation loss: 2.544567104549197

Epoch: 5| Step: 1
Training loss: 0.928415823175919
Validation loss: 2.5496097852050923

Epoch: 5| Step: 2
Training loss: 0.7670819569260575
Validation loss: 2.5831783296471205

Epoch: 5| Step: 3
Training loss: 0.501433404013061
Validation loss: 2.466081443109138

Epoch: 5| Step: 4
Training loss: 0.7600941082762577
Validation loss: 2.397011166069792

Epoch: 5| Step: 5
Training loss: 1.0840692160456902
Validation loss: 2.410576331217268

Epoch: 5| Step: 6
Training loss: 0.6676327267320905
Validation loss: 2.406960848883053

Epoch: 5| Step: 7
Training loss: 1.1708309354565232
Validation loss: 2.415146753556211

Epoch: 5| Step: 8
Training loss: 0.813300472036028
Validation loss: 2.4148172749802788

Epoch: 5| Step: 9
Training loss: 1.136923545400722
Validation loss: 2.4365059082589644

Epoch: 5| Step: 10
Training loss: 0.8118469474826719
Validation loss: 2.4185978104661814

Epoch: 313| Step: 0
Training loss: 0.6562538600989757
Validation loss: 2.4392400798449776

Epoch: 5| Step: 1
Training loss: 0.8841032871129569
Validation loss: 2.4599714193910676

Epoch: 5| Step: 2
Training loss: 0.7530593463566678
Validation loss: 2.4800261107963015

Epoch: 5| Step: 3
Training loss: 0.7038154179334981
Validation loss: 2.430651553631892

Epoch: 5| Step: 4
Training loss: 0.7698986512527711
Validation loss: 2.437622477417931

Epoch: 5| Step: 5
Training loss: 0.6795293470519633
Validation loss: 2.3951855715189363

Epoch: 5| Step: 6
Training loss: 0.9390666904451175
Validation loss: 2.430199797963761

Epoch: 5| Step: 7
Training loss: 1.1697149077742663
Validation loss: 2.443970257699714

Epoch: 5| Step: 8
Training loss: 0.819442578401614
Validation loss: 2.395473969746468

Epoch: 5| Step: 9
Training loss: 1.0245651555526947
Validation loss: 2.409604367563632

Epoch: 5| Step: 10
Training loss: 0.9365915665493046
Validation loss: 2.4012227636864267

Epoch: 314| Step: 0
Training loss: 0.40641288059667224
Validation loss: 2.401941507504123

Epoch: 5| Step: 1
Training loss: 0.9743369109592362
Validation loss: 2.4198350707479332

Epoch: 5| Step: 2
Training loss: 0.811240099712791
Validation loss: 2.4002994173689896

Epoch: 5| Step: 3
Training loss: 0.6538329800081266
Validation loss: 2.4608374618768947

Epoch: 5| Step: 4
Training loss: 1.0850400440895405
Validation loss: 2.446904282601658

Epoch: 5| Step: 5
Training loss: 0.6206038120106598
Validation loss: 2.461700619069984

Epoch: 5| Step: 6
Training loss: 0.9462168127612266
Validation loss: 2.4570608048735476

Epoch: 5| Step: 7
Training loss: 0.8827427524257245
Validation loss: 2.4315040312470724

Epoch: 5| Step: 8
Training loss: 0.7372189503518639
Validation loss: 2.4251457410855757

Epoch: 5| Step: 9
Training loss: 1.2671561221978043
Validation loss: 2.453458878376007

Epoch: 5| Step: 10
Training loss: 0.6169871717383771
Validation loss: 2.477579484790797

Epoch: 315| Step: 0
Training loss: 0.5876766081420067
Validation loss: 2.457243588327985

Epoch: 5| Step: 1
Training loss: 0.7922907970730302
Validation loss: 2.519443114038781

Epoch: 5| Step: 2
Training loss: 0.8849824214525731
Validation loss: 2.5525818515965386

Epoch: 5| Step: 3
Training loss: 0.7141674991263037
Validation loss: 2.5501175609837348

Epoch: 5| Step: 4
Training loss: 0.8451229510497583
Validation loss: 2.5332078116390946

Epoch: 5| Step: 5
Training loss: 0.6246046246222139
Validation loss: 2.492404830158566

Epoch: 5| Step: 6
Training loss: 0.661582241817922
Validation loss: 2.4381103845200363

Epoch: 5| Step: 7
Training loss: 1.1559587575788886
Validation loss: 2.364736785307631

Epoch: 5| Step: 8
Training loss: 1.034486546797229
Validation loss: 2.3666666441282933

Epoch: 5| Step: 9
Training loss: 1.0524793326552802
Validation loss: 2.3896917507704267

Epoch: 5| Step: 10
Training loss: 0.929734525372773
Validation loss: 2.4230755114652354

Epoch: 316| Step: 0
Training loss: 0.977864427562283
Validation loss: 2.478715657212902

Epoch: 5| Step: 1
Training loss: 0.9405976617838798
Validation loss: 2.509952841526813

Epoch: 5| Step: 2
Training loss: 0.793246892245529
Validation loss: 2.5108840365039042

Epoch: 5| Step: 3
Training loss: 1.0723671231063363
Validation loss: 2.536695237113306

Epoch: 5| Step: 4
Training loss: 0.9395621825302481
Validation loss: 2.49134650506138

Epoch: 5| Step: 5
Training loss: 0.8530295098489599
Validation loss: 2.4332268772390244

Epoch: 5| Step: 6
Training loss: 0.7051774058094126
Validation loss: 2.4282360444115816

Epoch: 5| Step: 7
Training loss: 0.7709831831022022
Validation loss: 2.408356563630512

Epoch: 5| Step: 8
Training loss: 0.9288950515983224
Validation loss: 2.4330417531968207

Epoch: 5| Step: 9
Training loss: 0.42227794689229503
Validation loss: 2.4075878245388327

Epoch: 5| Step: 10
Training loss: 0.7681974673870263
Validation loss: 2.40698726095025

Epoch: 317| Step: 0
Training loss: 0.7796473276801357
Validation loss: 2.3989995429021516

Epoch: 5| Step: 1
Training loss: 0.921153578299512
Validation loss: 2.4176147653489717

Epoch: 5| Step: 2
Training loss: 0.8232894648578116
Validation loss: 2.43514526170579

Epoch: 5| Step: 3
Training loss: 0.8846470498634081
Validation loss: 2.4188899003658166

Epoch: 5| Step: 4
Training loss: 0.8477230485182857
Validation loss: 2.4490624166742787

Epoch: 5| Step: 5
Training loss: 0.7013330300962617
Validation loss: 2.4739109817576015

Epoch: 5| Step: 6
Training loss: 0.7414421756188253
Validation loss: 2.4670443787214196

Epoch: 5| Step: 7
Training loss: 0.8857833028417281
Validation loss: 2.523658192409749

Epoch: 5| Step: 8
Training loss: 0.6246328706121411
Validation loss: 2.4743639655650544

Epoch: 5| Step: 9
Training loss: 1.07274357161755
Validation loss: 2.478204393756674

Epoch: 5| Step: 10
Training loss: 0.8498440823884859
Validation loss: 2.452413944599731

Epoch: 318| Step: 0
Training loss: 0.6877345638671394
Validation loss: 2.452770873552656

Epoch: 5| Step: 1
Training loss: 0.7799408434174042
Validation loss: 2.4365457970949587

Epoch: 5| Step: 2
Training loss: 0.8879635178013948
Validation loss: 2.4353787826600324

Epoch: 5| Step: 3
Training loss: 0.8604290826623648
Validation loss: 2.4646698285634314

Epoch: 5| Step: 4
Training loss: 0.898667181759365
Validation loss: 2.3983819432765308

Epoch: 5| Step: 5
Training loss: 0.6842926158700623
Validation loss: 2.439043837691619

Epoch: 5| Step: 6
Training loss: 1.1822277281468832
Validation loss: 2.462330624031675

Epoch: 5| Step: 7
Training loss: 0.8838650665480295
Validation loss: 2.4602843559056065

Epoch: 5| Step: 8
Training loss: 0.7242410551420132
Validation loss: 2.4728881579960325

Epoch: 5| Step: 9
Training loss: 0.6730621407006923
Validation loss: 2.4522493041869295

Epoch: 5| Step: 10
Training loss: 0.7630413213242441
Validation loss: 2.5286063737222473

Epoch: 319| Step: 0
Training loss: 0.763073542904082
Validation loss: 2.446060884411294

Epoch: 5| Step: 1
Training loss: 0.7492524235927726
Validation loss: 2.454704747907333

Epoch: 5| Step: 2
Training loss: 0.7804704209807172
Validation loss: 2.387064379256364

Epoch: 5| Step: 3
Training loss: 0.9382516390966322
Validation loss: 2.337734581297156

Epoch: 5| Step: 4
Training loss: 1.065869653981177
Validation loss: 2.3551060614290154

Epoch: 5| Step: 5
Training loss: 0.7782341156713115
Validation loss: 2.3810508064429374

Epoch: 5| Step: 6
Training loss: 0.8189986470179857
Validation loss: 2.4424989138574857

Epoch: 5| Step: 7
Training loss: 0.7077408491167614
Validation loss: 2.5044711223881153

Epoch: 5| Step: 8
Training loss: 0.7763423891725449
Validation loss: 2.539844283915997

Epoch: 5| Step: 9
Training loss: 0.8970651843628088
Validation loss: 2.5381174413407463

Epoch: 5| Step: 10
Training loss: 0.8019318664676373
Validation loss: 2.497946827207353

Epoch: 320| Step: 0
Training loss: 0.539290034607045
Validation loss: 2.4567488988352713

Epoch: 5| Step: 1
Training loss: 0.8911378621930792
Validation loss: 2.3767153229270694

Epoch: 5| Step: 2
Training loss: 0.935873114101853
Validation loss: 2.3819884393801565

Epoch: 5| Step: 3
Training loss: 0.752465724861518
Validation loss: 2.3520768044395832

Epoch: 5| Step: 4
Training loss: 0.9628889846014013
Validation loss: 2.4519982222699994

Epoch: 5| Step: 5
Training loss: 0.5354032572936109
Validation loss: 2.4737134275775774

Epoch: 5| Step: 6
Training loss: 0.9001917422872086
Validation loss: 2.5047436491432595

Epoch: 5| Step: 7
Training loss: 0.7225923252184877
Validation loss: 2.509126894482847

Epoch: 5| Step: 8
Training loss: 1.0439855070021644
Validation loss: 2.5326953682384095

Epoch: 5| Step: 9
Training loss: 0.776129037090559
Validation loss: 2.489639946456098

Epoch: 5| Step: 10
Training loss: 0.9211227451254933
Validation loss: 2.4498798430467112

Epoch: 321| Step: 0
Training loss: 0.8465259944892468
Validation loss: 2.4229880832619144

Epoch: 5| Step: 1
Training loss: 0.6967271707885262
Validation loss: 2.4093021521463007

Epoch: 5| Step: 2
Training loss: 1.0199144016139627
Validation loss: 2.383359797587732

Epoch: 5| Step: 3
Training loss: 0.5341200437844781
Validation loss: 2.3989946857109823

Epoch: 5| Step: 4
Training loss: 1.0102929632750426
Validation loss: 2.388741545041448

Epoch: 5| Step: 5
Training loss: 0.6366569161375805
Validation loss: 2.462043678450637

Epoch: 5| Step: 6
Training loss: 1.0075492810864137
Validation loss: 2.4894018774279907

Epoch: 5| Step: 7
Training loss: 0.778471928359275
Validation loss: 2.477783192131834

Epoch: 5| Step: 8
Training loss: 0.771459728764745
Validation loss: 2.4932534585106274

Epoch: 5| Step: 9
Training loss: 0.8134857946561205
Validation loss: 2.446915526051787

Epoch: 5| Step: 10
Training loss: 0.7725143317710993
Validation loss: 2.4719165412960518

Epoch: 322| Step: 0
Training loss: 0.9271526882218034
Validation loss: 2.4300629713064996

Epoch: 5| Step: 1
Training loss: 0.7396744595833853
Validation loss: 2.3851156878213007

Epoch: 5| Step: 2
Training loss: 1.1923764640270442
Validation loss: 2.3752898528894946

Epoch: 5| Step: 3
Training loss: 0.7497322876285861
Validation loss: 2.376921019862812

Epoch: 5| Step: 4
Training loss: 0.4690799505557144
Validation loss: 2.380805127729323

Epoch: 5| Step: 5
Training loss: 0.9123889241481582
Validation loss: 2.43009611820037

Epoch: 5| Step: 6
Training loss: 0.5125775883257114
Validation loss: 2.464514945537341

Epoch: 5| Step: 7
Training loss: 0.9481888195227555
Validation loss: 2.5224462368212

Epoch: 5| Step: 8
Training loss: 0.6718691892150841
Validation loss: 2.535007213739138

Epoch: 5| Step: 9
Training loss: 0.6937677174960587
Validation loss: 2.494704662957611

Epoch: 5| Step: 10
Training loss: 0.9277409924722871
Validation loss: 2.462986619236326

Epoch: 323| Step: 0
Training loss: 1.030332214703709
Validation loss: 2.493922017761695

Epoch: 5| Step: 1
Training loss: 0.7983004592373327
Validation loss: 2.4563851859195833

Epoch: 5| Step: 2
Training loss: 0.5309910704208537
Validation loss: 2.406982853633753

Epoch: 5| Step: 3
Training loss: 0.7285964143766919
Validation loss: 2.416652565541215

Epoch: 5| Step: 4
Training loss: 0.7732227296975411
Validation loss: 2.4243360449651035

Epoch: 5| Step: 5
Training loss: 0.8407969897997587
Validation loss: 2.4349551993101612

Epoch: 5| Step: 6
Training loss: 1.0407922444251798
Validation loss: 2.537994412533646

Epoch: 5| Step: 7
Training loss: 0.8175493843141153
Validation loss: 2.5830712832209253

Epoch: 5| Step: 8
Training loss: 0.6100569112994799
Validation loss: 2.5352446911361484

Epoch: 5| Step: 9
Training loss: 0.8783903515192029
Validation loss: 2.3923603268626774

Epoch: 5| Step: 10
Training loss: 0.8990792677518668
Validation loss: 2.324852857764298

Epoch: 324| Step: 0
Training loss: 0.7354027475727452
Validation loss: 2.31340277404494

Epoch: 5| Step: 1
Training loss: 0.9664773123910715
Validation loss: 2.3237256536385673

Epoch: 5| Step: 2
Training loss: 0.3173184256166604
Validation loss: 2.3418444975594808

Epoch: 5| Step: 3
Training loss: 0.8787133238234955
Validation loss: 2.4286228128005427

Epoch: 5| Step: 4
Training loss: 0.8604650000481314
Validation loss: 2.4648044876162825

Epoch: 5| Step: 5
Training loss: 0.704763199489434
Validation loss: 2.4993731256267115

Epoch: 5| Step: 6
Training loss: 0.5636715080698872
Validation loss: 2.515196714157246

Epoch: 5| Step: 7
Training loss: 1.0909022178397265
Validation loss: 2.4902897983715526

Epoch: 5| Step: 8
Training loss: 1.0114096975893936
Validation loss: 2.4199663218220375

Epoch: 5| Step: 9
Training loss: 0.7770318023599901
Validation loss: 2.4127455914345854

Epoch: 5| Step: 10
Training loss: 0.8314233269359859
Validation loss: 2.406269728365695

Epoch: 325| Step: 0
Training loss: 1.0637445453723597
Validation loss: 2.452241929753913

Epoch: 5| Step: 1
Training loss: 1.1882421784307042
Validation loss: 2.468281850149196

Epoch: 5| Step: 2
Training loss: 0.6815292573471425
Validation loss: 2.4424048345268474

Epoch: 5| Step: 3
Training loss: 0.8940377352450419
Validation loss: 2.493182099282417

Epoch: 5| Step: 4
Training loss: 0.5972894527854201
Validation loss: 2.4404380125984395

Epoch: 5| Step: 5
Training loss: 0.6680773596555029
Validation loss: 2.4203921846124823

Epoch: 5| Step: 6
Training loss: 0.9098050991354032
Validation loss: 2.3640589224467834

Epoch: 5| Step: 7
Training loss: 0.6432324819955574
Validation loss: 2.3798792339958195

Epoch: 5| Step: 8
Training loss: 0.5506847648790804
Validation loss: 2.408634781673648

Epoch: 5| Step: 9
Training loss: 0.752747470363698
Validation loss: 2.449392957929655

Epoch: 5| Step: 10
Training loss: 0.7357352624804756
Validation loss: 2.479348188872528

Epoch: 326| Step: 0
Training loss: 0.6804960418378646
Validation loss: 2.4936794804477773

Epoch: 5| Step: 1
Training loss: 0.8463728369585329
Validation loss: 2.511145348161522

Epoch: 5| Step: 2
Training loss: 0.7318651448538335
Validation loss: 2.4489319367414915

Epoch: 5| Step: 3
Training loss: 0.6380226031428073
Validation loss: 2.438306415819104

Epoch: 5| Step: 4
Training loss: 1.0820708009397815
Validation loss: 2.385178708107717

Epoch: 5| Step: 5
Training loss: 0.7221732510160095
Validation loss: 2.383994505038566

Epoch: 5| Step: 6
Training loss: 1.024559512508488
Validation loss: 2.4013316924893906

Epoch: 5| Step: 7
Training loss: 1.0481897894363643
Validation loss: 2.4137061729863585

Epoch: 5| Step: 8
Training loss: 0.7737084116566851
Validation loss: 2.450355144339909

Epoch: 5| Step: 9
Training loss: 0.306677554877114
Validation loss: 2.4848413022702194

Epoch: 5| Step: 10
Training loss: 0.6086807942853906
Validation loss: 2.5453271007832288

Epoch: 327| Step: 0
Training loss: 0.880079918396905
Validation loss: 2.5533201561104253

Epoch: 5| Step: 1
Training loss: 0.7822362015757738
Validation loss: 2.5298124672743496

Epoch: 5| Step: 2
Training loss: 0.5769740840175837
Validation loss: 2.529478880775984

Epoch: 5| Step: 3
Training loss: 0.6628352099911554
Validation loss: 2.482954701105446

Epoch: 5| Step: 4
Training loss: 0.7697549872291019
Validation loss: 2.426841315439333

Epoch: 5| Step: 5
Training loss: 0.864647487573509
Validation loss: 2.4434107173748143

Epoch: 5| Step: 6
Training loss: 0.4141101989622749
Validation loss: 2.447483622608991

Epoch: 5| Step: 7
Training loss: 0.8610020926557534
Validation loss: 2.442061231865008

Epoch: 5| Step: 8
Training loss: 0.6881236585487921
Validation loss: 2.453789353440328

Epoch: 5| Step: 9
Training loss: 1.0278513999436938
Validation loss: 2.4240572023911207

Epoch: 5| Step: 10
Training loss: 1.0222965315977774
Validation loss: 2.450126954640713

Epoch: 328| Step: 0
Training loss: 0.7740651291027552
Validation loss: 2.448455204281817

Epoch: 5| Step: 1
Training loss: 0.950328696005336
Validation loss: 2.4315821705563647

Epoch: 5| Step: 2
Training loss: 1.1565055564750188
Validation loss: 2.4615288897115066

Epoch: 5| Step: 3
Training loss: 0.622846995851625
Validation loss: 2.4345324447097765

Epoch: 5| Step: 4
Training loss: 0.6246638347652463
Validation loss: 2.4327380497198665

Epoch: 5| Step: 5
Training loss: 0.7643061976686492
Validation loss: 2.4033879210924263

Epoch: 5| Step: 6
Training loss: 0.6346266843883499
Validation loss: 2.400888524372226

Epoch: 5| Step: 7
Training loss: 0.7088199561443118
Validation loss: 2.4131390267160175

Epoch: 5| Step: 8
Training loss: 0.7596258510492556
Validation loss: 2.457060391696236

Epoch: 5| Step: 9
Training loss: 0.7007154504000549
Validation loss: 2.4520914149677635

Epoch: 5| Step: 10
Training loss: 0.6985935207597787
Validation loss: 2.5068892788738393

Epoch: 329| Step: 0
Training loss: 0.6311909421356079
Validation loss: 2.56235624400838

Epoch: 5| Step: 1
Training loss: 0.9575773277133119
Validation loss: 2.618793870403418

Epoch: 5| Step: 2
Training loss: 0.9144693756940887
Validation loss: 2.592641208716655

Epoch: 5| Step: 3
Training loss: 0.48322175775620735
Validation loss: 2.588336944325058

Epoch: 5| Step: 4
Training loss: 0.8095213871840825
Validation loss: 2.6022734666595557

Epoch: 5| Step: 5
Training loss: 0.6364950243357609
Validation loss: 2.5132229365346173

Epoch: 5| Step: 6
Training loss: 0.6528253205438794
Validation loss: 2.4458952325415253

Epoch: 5| Step: 7
Training loss: 0.6251602682619973
Validation loss: 2.4333403006383807

Epoch: 5| Step: 8
Training loss: 0.77046220883788
Validation loss: 2.3655343009389416

Epoch: 5| Step: 9
Training loss: 1.0133661827192235
Validation loss: 2.373357511973381

Epoch: 5| Step: 10
Training loss: 0.9422883139553526
Validation loss: 2.417633759173521

Epoch: 330| Step: 0
Training loss: 0.7605375864395316
Validation loss: 2.446733064397944

Epoch: 5| Step: 1
Training loss: 0.7705543030225418
Validation loss: 2.4672094278486525

Epoch: 5| Step: 2
Training loss: 0.5535125646190261
Validation loss: 2.4792058270667923

Epoch: 5| Step: 3
Training loss: 1.06943370076077
Validation loss: 2.484949189149008

Epoch: 5| Step: 4
Training loss: 1.0059443465702298
Validation loss: 2.537477174493895

Epoch: 5| Step: 5
Training loss: 0.656133686838841
Validation loss: 2.5238299117876113

Epoch: 5| Step: 6
Training loss: 0.4377459447837368
Validation loss: 2.4483859376685597

Epoch: 5| Step: 7
Training loss: 0.7901343440254838
Validation loss: 2.4314760003074043

Epoch: 5| Step: 8
Training loss: 0.8270604470751518
Validation loss: 2.3957513810346645

Epoch: 5| Step: 9
Training loss: 0.8344166191665157
Validation loss: 2.3482920540707766

Epoch: 5| Step: 10
Training loss: 0.3591451324385831
Validation loss: 2.3714922446966655

Epoch: 331| Step: 0
Training loss: 0.6367519580629734
Validation loss: 2.358990405445305

Epoch: 5| Step: 1
Training loss: 0.6212462711797982
Validation loss: 2.398380055056442

Epoch: 5| Step: 2
Training loss: 0.5179002155515638
Validation loss: 2.419574621294472

Epoch: 5| Step: 3
Training loss: 0.7798583032820366
Validation loss: 2.4320785057695997

Epoch: 5| Step: 4
Training loss: 0.7695446497336297
Validation loss: 2.422478386391108

Epoch: 5| Step: 5
Training loss: 0.53151970917053
Validation loss: 2.4210372248519443

Epoch: 5| Step: 6
Training loss: 0.8493969531166071
Validation loss: 2.4038647774478976

Epoch: 5| Step: 7
Training loss: 0.8218240888948931
Validation loss: 2.4197529790597905

Epoch: 5| Step: 8
Training loss: 0.9874899791257371
Validation loss: 2.385709834207165

Epoch: 5| Step: 9
Training loss: 0.8580815378005876
Validation loss: 2.4121227537543626

Epoch: 5| Step: 10
Training loss: 0.9757893362695215
Validation loss: 2.3938131433469203

Epoch: 332| Step: 0
Training loss: 0.6340497014392986
Validation loss: 2.418144114618166

Epoch: 5| Step: 1
Training loss: 0.9827485347242938
Validation loss: 2.3518728380479255

Epoch: 5| Step: 2
Training loss: 0.9730258224212925
Validation loss: 2.3731352691344805

Epoch: 5| Step: 3
Training loss: 0.46739683341433735
Validation loss: 2.402166809294219

Epoch: 5| Step: 4
Training loss: 0.5466601085802522
Validation loss: 2.4188978703630517

Epoch: 5| Step: 5
Training loss: 0.9298200753194357
Validation loss: 2.405213405350976

Epoch: 5| Step: 6
Training loss: 0.7243766719479557
Validation loss: 2.4006759375334794

Epoch: 5| Step: 7
Training loss: 0.9322240829834411
Validation loss: 2.441729707025534

Epoch: 5| Step: 8
Training loss: 0.5214160774454831
Validation loss: 2.430407706440467

Epoch: 5| Step: 9
Training loss: 0.6552905835155475
Validation loss: 2.438958740686603

Epoch: 5| Step: 10
Training loss: 0.6629233743898488
Validation loss: 2.415639723479906

Epoch: 333| Step: 0
Training loss: 0.7876362516213713
Validation loss: 2.405139876370778

Epoch: 5| Step: 1
Training loss: 0.71403578660275
Validation loss: 2.427298862169192

Epoch: 5| Step: 2
Training loss: 0.9532630070064811
Validation loss: 2.4320260682180983

Epoch: 5| Step: 3
Training loss: 0.5539982233776429
Validation loss: 2.421423851437676

Epoch: 5| Step: 4
Training loss: 0.875984523571161
Validation loss: 2.4449607797726567

Epoch: 5| Step: 5
Training loss: 0.5830859925776121
Validation loss: 2.458257177253327

Epoch: 5| Step: 6
Training loss: 0.723716947166457
Validation loss: 2.431662446479391

Epoch: 5| Step: 7
Training loss: 0.8695630365064473
Validation loss: 2.461591432057572

Epoch: 5| Step: 8
Training loss: 0.6703168410936472
Validation loss: 2.455424835716645

Epoch: 5| Step: 9
Training loss: 0.6088984411070251
Validation loss: 2.408386712895466

Epoch: 5| Step: 10
Training loss: 0.8048782492908403
Validation loss: 2.4221116513035943

Epoch: 334| Step: 0
Training loss: 1.0315703270218566
Validation loss: 2.4058672298615407

Epoch: 5| Step: 1
Training loss: 0.5546891118415732
Validation loss: 2.42284357270704

Epoch: 5| Step: 2
Training loss: 1.0109921943219842
Validation loss: 2.433886076293158

Epoch: 5| Step: 3
Training loss: 0.7775886571571967
Validation loss: 2.45645762556536

Epoch: 5| Step: 4
Training loss: 0.6548534929428621
Validation loss: 2.4369217591934667

Epoch: 5| Step: 5
Training loss: 0.4713823317091877
Validation loss: 2.436840335170683

Epoch: 5| Step: 6
Training loss: 0.7187958992939277
Validation loss: 2.4673591627461526

Epoch: 5| Step: 7
Training loss: 0.3278959814747095
Validation loss: 2.424687523727675

Epoch: 5| Step: 8
Training loss: 1.005588650612527
Validation loss: 2.461308662172811

Epoch: 5| Step: 9
Training loss: 0.3703353762099617
Validation loss: 2.4502362559899544

Epoch: 5| Step: 10
Training loss: 0.7677190908422787
Validation loss: 2.4342129275072164

Epoch: 335| Step: 0
Training loss: 0.6105441102534571
Validation loss: 2.4538243121738996

Epoch: 5| Step: 1
Training loss: 0.8581209916967921
Validation loss: 2.486836621456313

Epoch: 5| Step: 2
Training loss: 0.6444513907231758
Validation loss: 2.4616395635450914

Epoch: 5| Step: 3
Training loss: 0.7950831818998463
Validation loss: 2.482229024030147

Epoch: 5| Step: 4
Training loss: 0.7833301317541831
Validation loss: 2.418685342248232

Epoch: 5| Step: 5
Training loss: 0.750563489313718
Validation loss: 2.415792829854747

Epoch: 5| Step: 6
Training loss: 0.9164927852323747
Validation loss: 2.3846636024677483

Epoch: 5| Step: 7
Training loss: 0.7520161391768521
Validation loss: 2.4088600715136916

Epoch: 5| Step: 8
Training loss: 0.5917209790603077
Validation loss: 2.399511741977037

Epoch: 5| Step: 9
Training loss: 0.7981076150672111
Validation loss: 2.4547814296719954

Epoch: 5| Step: 10
Training loss: 0.6161418700769244
Validation loss: 2.4418087758306384

Epoch: 336| Step: 0
Training loss: 0.8428516196965897
Validation loss: 2.442985177540145

Epoch: 5| Step: 1
Training loss: 0.515108774882636
Validation loss: 2.4598537336822806

Epoch: 5| Step: 2
Training loss: 0.7212864445779055
Validation loss: 2.4453066688490877

Epoch: 5| Step: 3
Training loss: 0.7494278553321513
Validation loss: 2.4381201917167363

Epoch: 5| Step: 4
Training loss: 0.8358850195266934
Validation loss: 2.430901026943322

Epoch: 5| Step: 5
Training loss: 0.6410469665862006
Validation loss: 2.4007041700539644

Epoch: 5| Step: 6
Training loss: 0.8616150531645688
Validation loss: 2.462696631808446

Epoch: 5| Step: 7
Training loss: 0.6529529719147723
Validation loss: 2.4518611221134234

Epoch: 5| Step: 8
Training loss: 0.515609220783508
Validation loss: 2.4892806098530755

Epoch: 5| Step: 9
Training loss: 0.7353102633162176
Validation loss: 2.500839930612239

Epoch: 5| Step: 10
Training loss: 0.8728579459700637
Validation loss: 2.4425663983677577

Epoch: 337| Step: 0
Training loss: 0.6426533246315769
Validation loss: 2.484606681428241

Epoch: 5| Step: 1
Training loss: 0.7364625681566983
Validation loss: 2.4507694173006915

Epoch: 5| Step: 2
Training loss: 0.7474913763103801
Validation loss: 2.42876407783474

Epoch: 5| Step: 3
Training loss: 0.8042965652294776
Validation loss: 2.4321495138106353

Epoch: 5| Step: 4
Training loss: 0.7139371114945342
Validation loss: 2.423833697922783

Epoch: 5| Step: 5
Training loss: 0.5373963300398633
Validation loss: 2.416105245130595

Epoch: 5| Step: 6
Training loss: 0.7138134979222367
Validation loss: 2.4274703089696774

Epoch: 5| Step: 7
Training loss: 0.7990159091487572
Validation loss: 2.4253390126076626

Epoch: 5| Step: 8
Training loss: 0.6639410019970472
Validation loss: 2.4904269339234957

Epoch: 5| Step: 9
Training loss: 0.7784208570222652
Validation loss: 2.451320582073413

Epoch: 5| Step: 10
Training loss: 0.8750810926189699
Validation loss: 2.4241252933594954

Epoch: 338| Step: 0
Training loss: 0.41675512646392243
Validation loss: 2.416511916473566

Epoch: 5| Step: 1
Training loss: 0.6577765103822317
Validation loss: 2.374760300997508

Epoch: 5| Step: 2
Training loss: 0.7458456136093867
Validation loss: 2.391058285036353

Epoch: 5| Step: 3
Training loss: 0.666784340685341
Validation loss: 2.417580247996064

Epoch: 5| Step: 4
Training loss: 0.7417728671286337
Validation loss: 2.3821211693045643

Epoch: 5| Step: 5
Training loss: 0.8813488735708352
Validation loss: 2.4343042956837753

Epoch: 5| Step: 6
Training loss: 0.8230223084899122
Validation loss: 2.402690974874673

Epoch: 5| Step: 7
Training loss: 0.6511532776847995
Validation loss: 2.380709429091031

Epoch: 5| Step: 8
Training loss: 0.6830807313945911
Validation loss: 2.418113169156782

Epoch: 5| Step: 9
Training loss: 0.7125155781833126
Validation loss: 2.4141324944388916

Epoch: 5| Step: 10
Training loss: 0.9011204341498122
Validation loss: 2.4297013939363055

Epoch: 339| Step: 0
Training loss: 0.7388603724408144
Validation loss: 2.444055388164147

Epoch: 5| Step: 1
Training loss: 0.665436770012653
Validation loss: 2.486200444314189

Epoch: 5| Step: 2
Training loss: 0.8338121508834997
Validation loss: 2.45948114255871

Epoch: 5| Step: 3
Training loss: 0.6692388183021589
Validation loss: 2.4665545744344213

Epoch: 5| Step: 4
Training loss: 0.5763037062006006
Validation loss: 2.4291477010623965

Epoch: 5| Step: 5
Training loss: 0.47104856865927286
Validation loss: 2.391291747953126

Epoch: 5| Step: 6
Training loss: 0.6577048297394444
Validation loss: 2.4587316755199633

Epoch: 5| Step: 7
Training loss: 0.438365930818585
Validation loss: 2.4422315420869016

Epoch: 5| Step: 8
Training loss: 0.9519286542712765
Validation loss: 2.443279605103452

Epoch: 5| Step: 9
Training loss: 0.49479160476148787
Validation loss: 2.4534931709964236

Epoch: 5| Step: 10
Training loss: 1.1565849746874592
Validation loss: 2.475183686622117

Epoch: 340| Step: 0
Training loss: 0.5633788660465675
Validation loss: 2.4272768625730814

Epoch: 5| Step: 1
Training loss: 0.7840452922272232
Validation loss: 2.3900676348062944

Epoch: 5| Step: 2
Training loss: 0.5945650579837986
Validation loss: 2.3816521799523036

Epoch: 5| Step: 3
Training loss: 0.9926690262293991
Validation loss: 2.3849670830854244

Epoch: 5| Step: 4
Training loss: 0.7182891031383226
Validation loss: 2.387601918308305

Epoch: 5| Step: 5
Training loss: 0.6864554098835942
Validation loss: 2.3932387331389844

Epoch: 5| Step: 6
Training loss: 0.6024280860134472
Validation loss: 2.4271627497039545

Epoch: 5| Step: 7
Training loss: 0.7751603252947362
Validation loss: 2.4816951320296656

Epoch: 5| Step: 8
Training loss: 0.7989914780712539
Validation loss: 2.5275138040421674

Epoch: 5| Step: 9
Training loss: 0.6213096387394548
Validation loss: 2.5155737890851126

Epoch: 5| Step: 10
Training loss: 0.6574635864733895
Validation loss: 2.43116856342747

Epoch: 341| Step: 0
Training loss: 0.7471863899557754
Validation loss: 2.430731181075877

Epoch: 5| Step: 1
Training loss: 0.7050093091525964
Validation loss: 2.3773810670570206

Epoch: 5| Step: 2
Training loss: 0.7275287806661261
Validation loss: 2.321321738267467

Epoch: 5| Step: 3
Training loss: 0.7173912639831511
Validation loss: 2.3434836232842104

Epoch: 5| Step: 4
Training loss: 0.8204529778223713
Validation loss: 2.409298465177611

Epoch: 5| Step: 5
Training loss: 0.8367363152320927
Validation loss: 2.482768457666235

Epoch: 5| Step: 6
Training loss: 0.4756373195581584
Validation loss: 2.529787304113824

Epoch: 5| Step: 7
Training loss: 0.7581260661646807
Validation loss: 2.5010360980597257

Epoch: 5| Step: 8
Training loss: 0.6394544467434654
Validation loss: 2.508016491178805

Epoch: 5| Step: 9
Training loss: 0.8366153499993427
Validation loss: 2.455133246383061

Epoch: 5| Step: 10
Training loss: 0.6089875627964016
Validation loss: 2.412452719351191

Epoch: 342| Step: 0
Training loss: 0.340893122812025
Validation loss: 2.3877910062774745

Epoch: 5| Step: 1
Training loss: 0.866264711450497
Validation loss: 2.299089983419726

Epoch: 5| Step: 2
Training loss: 0.8599445882954667
Validation loss: 2.2891107201550245

Epoch: 5| Step: 3
Training loss: 0.7216292222978378
Validation loss: 2.3458002230588453

Epoch: 5| Step: 4
Training loss: 0.629425639944088
Validation loss: 2.3735101244038574

Epoch: 5| Step: 5
Training loss: 0.6615876249174241
Validation loss: 2.4228836251016608

Epoch: 5| Step: 6
Training loss: 0.6269798867286527
Validation loss: 2.525025466762902

Epoch: 5| Step: 7
Training loss: 0.5670192689699436
Validation loss: 2.5423667964844525

Epoch: 5| Step: 8
Training loss: 0.9019540052380733
Validation loss: 2.5014881667960647

Epoch: 5| Step: 9
Training loss: 0.6006454066165138
Validation loss: 2.451193939908466

Epoch: 5| Step: 10
Training loss: 0.9600868802195626
Validation loss: 2.397080954149868

Epoch: 343| Step: 0
Training loss: 0.47148289336546145
Validation loss: 2.364429878899389

Epoch: 5| Step: 1
Training loss: 0.7606096066474346
Validation loss: 2.3524560048153393

Epoch: 5| Step: 2
Training loss: 0.540498258916078
Validation loss: 2.3611298242061056

Epoch: 5| Step: 3
Training loss: 0.9008428799008381
Validation loss: 2.415560796766091

Epoch: 5| Step: 4
Training loss: 0.5063812627280307
Validation loss: 2.46598482135314

Epoch: 5| Step: 5
Training loss: 1.1557352105707972
Validation loss: 2.4698466986430168

Epoch: 5| Step: 6
Training loss: 0.6965324115715249
Validation loss: 2.4750604318230867

Epoch: 5| Step: 7
Training loss: 0.6693077497777703
Validation loss: 2.425860471922794

Epoch: 5| Step: 8
Training loss: 0.3867997749295413
Validation loss: 2.40147402166827

Epoch: 5| Step: 9
Training loss: 0.48766746090094
Validation loss: 2.336324285716062

Epoch: 5| Step: 10
Training loss: 0.8391432923929019
Validation loss: 2.3785439249748834

Epoch: 344| Step: 0
Training loss: 0.7134749434708867
Validation loss: 2.367399914105091

Epoch: 5| Step: 1
Training loss: 0.9734506694949911
Validation loss: 2.3941778508265448

Epoch: 5| Step: 2
Training loss: 0.435191158901109
Validation loss: 2.4097358226692767

Epoch: 5| Step: 3
Training loss: 0.6826967730536272
Validation loss: 2.4451791369896507

Epoch: 5| Step: 4
Training loss: 0.8036409998855724
Validation loss: 2.4974705745240886

Epoch: 5| Step: 5
Training loss: 0.5544813605874336
Validation loss: 2.5464947822658304

Epoch: 5| Step: 6
Training loss: 0.6883763017089684
Validation loss: 2.540464491818594

Epoch: 5| Step: 7
Training loss: 0.7772825590806737
Validation loss: 2.4908813686145086

Epoch: 5| Step: 8
Training loss: 0.5282881016528111
Validation loss: 2.39412972194013

Epoch: 5| Step: 9
Training loss: 0.7536818017045871
Validation loss: 2.3468649429807757

Epoch: 5| Step: 10
Training loss: 0.727210955272277
Validation loss: 2.3678277865374997

Epoch: 345| Step: 0
Training loss: 0.9797229133788348
Validation loss: 2.3822177773505517

Epoch: 5| Step: 1
Training loss: 0.5246258242393638
Validation loss: 2.424144852720721

Epoch: 5| Step: 2
Training loss: 0.5645458844798499
Validation loss: 2.4280116607515883

Epoch: 5| Step: 3
Training loss: 0.6480723352472307
Validation loss: 2.454558138387996

Epoch: 5| Step: 4
Training loss: 0.5708989824937796
Validation loss: 2.5163013076781966

Epoch: 5| Step: 5
Training loss: 0.6231257947727289
Validation loss: 2.52358529953898

Epoch: 5| Step: 6
Training loss: 0.4166238842298856
Validation loss: 2.481802222899541

Epoch: 5| Step: 7
Training loss: 0.5732235231236684
Validation loss: 2.4250776082052483

Epoch: 5| Step: 8
Training loss: 1.0225233115451198
Validation loss: 2.3985015100625735

Epoch: 5| Step: 9
Training loss: 0.8688702452069477
Validation loss: 2.3671584280351436

Epoch: 5| Step: 10
Training loss: 0.5949596330429162
Validation loss: 2.402545393924834

Epoch: 346| Step: 0
Training loss: 0.9128760764742347
Validation loss: 2.40558639195161

Epoch: 5| Step: 1
Training loss: 0.6465337913043214
Validation loss: 2.445244161854019

Epoch: 5| Step: 2
Training loss: 1.0448347108797076
Validation loss: 2.4451679710040204

Epoch: 5| Step: 3
Training loss: 0.663445758525605
Validation loss: 2.4956663142767126

Epoch: 5| Step: 4
Training loss: 0.6712068295937265
Validation loss: 2.484909393298791

Epoch: 5| Step: 5
Training loss: 0.4851319796869283
Validation loss: 2.4768096602779743

Epoch: 5| Step: 6
Training loss: 0.5827686835378345
Validation loss: 2.4816067215065973

Epoch: 5| Step: 7
Training loss: 0.6822627160916594
Validation loss: 2.448613476114939

Epoch: 5| Step: 8
Training loss: 0.6283009619515277
Validation loss: 2.4169389888128925

Epoch: 5| Step: 9
Training loss: 0.6506363229929767
Validation loss: 2.4549778298380946

Epoch: 5| Step: 10
Training loss: 0.6811366363136282
Validation loss: 2.4172437805839557

Epoch: 347| Step: 0
Training loss: 0.836573741895731
Validation loss: 2.395320131854706

Epoch: 5| Step: 1
Training loss: 0.5738009795019327
Validation loss: 2.438756734991432

Epoch: 5| Step: 2
Training loss: 0.5267053201027576
Validation loss: 2.446882027091943

Epoch: 5| Step: 3
Training loss: 0.5543214906760603
Validation loss: 2.4734698034204694

Epoch: 5| Step: 4
Training loss: 0.8587633904269615
Validation loss: 2.4681482050175103

Epoch: 5| Step: 5
Training loss: 0.8603305705840386
Validation loss: 2.424361734784691

Epoch: 5| Step: 6
Training loss: 0.5712000590057236
Validation loss: 2.44119880461078

Epoch: 5| Step: 7
Training loss: 0.6228193866293491
Validation loss: 2.3991178414972776

Epoch: 5| Step: 8
Training loss: 0.5702412965821956
Validation loss: 2.444130103285505

Epoch: 5| Step: 9
Training loss: 0.9121064016551008
Validation loss: 2.4928147765497934

Epoch: 5| Step: 10
Training loss: 0.5610915139944362
Validation loss: 2.542995426970634

Epoch: 348| Step: 0
Training loss: 0.7957813761928421
Validation loss: 2.597574982014533

Epoch: 5| Step: 1
Training loss: 0.20693519451247708
Validation loss: 2.5707422954314163

Epoch: 5| Step: 2
Training loss: 0.8232990213598474
Validation loss: 2.546059170849159

Epoch: 5| Step: 3
Training loss: 0.6591928438357225
Validation loss: 2.5083075861341375

Epoch: 5| Step: 4
Training loss: 0.7937082685178546
Validation loss: 2.430421843085847

Epoch: 5| Step: 5
Training loss: 0.7055131832759208
Validation loss: 2.3954269735123317

Epoch: 5| Step: 6
Training loss: 0.42837116445778367
Validation loss: 2.3620835547664645

Epoch: 5| Step: 7
Training loss: 0.6699359769977348
Validation loss: 2.3818045135795627

Epoch: 5| Step: 8
Training loss: 0.6881898323513589
Validation loss: 2.39117678995926

Epoch: 5| Step: 9
Training loss: 0.774791726460001
Validation loss: 2.439139024128786

Epoch: 5| Step: 10
Training loss: 0.8327998877853222
Validation loss: 2.472827097745556

Epoch: 349| Step: 0
Training loss: 0.6593756942383786
Validation loss: 2.5065944922284342

Epoch: 5| Step: 1
Training loss: 0.7531442695146925
Validation loss: 2.5359287012642704

Epoch: 5| Step: 2
Training loss: 0.7199468185069446
Validation loss: 2.4820862562867485

Epoch: 5| Step: 3
Training loss: 0.7674582196025066
Validation loss: 2.437542405139563

Epoch: 5| Step: 4
Training loss: 0.552322665706442
Validation loss: 2.3965609604320885

Epoch: 5| Step: 5
Training loss: 0.5962573365693803
Validation loss: 2.359609846316827

Epoch: 5| Step: 6
Training loss: 0.9431624118066098
Validation loss: 2.3933083690530514

Epoch: 5| Step: 7
Training loss: 0.7400408167150008
Validation loss: 2.351427639028202

Epoch: 5| Step: 8
Training loss: 0.6841393609431126
Validation loss: 2.413193080434775

Epoch: 5| Step: 9
Training loss: 0.35775911857505355
Validation loss: 2.4155930081425327

Epoch: 5| Step: 10
Training loss: 0.6798634356219885
Validation loss: 2.4774541678512123

Epoch: 350| Step: 0
Training loss: 0.7069092956237224
Validation loss: 2.4800484456627476

Epoch: 5| Step: 1
Training loss: 0.6450188381933493
Validation loss: 2.4947744608643356

Epoch: 5| Step: 2
Training loss: 0.5958435143310093
Validation loss: 2.4423162692000466

Epoch: 5| Step: 3
Training loss: 0.6608811636287921
Validation loss: 2.4365187174538665

Epoch: 5| Step: 4
Training loss: 0.6748203656684258
Validation loss: 2.425061852575811

Epoch: 5| Step: 5
Training loss: 0.44417005523631997
Validation loss: 2.4266227124171995

Epoch: 5| Step: 6
Training loss: 0.7263868386179101
Validation loss: 2.469974928897172

Epoch: 5| Step: 7
Training loss: 0.6174462657205452
Validation loss: 2.5043936319672895

Epoch: 5| Step: 8
Training loss: 0.8926905721873168
Validation loss: 2.535675670616717

Epoch: 5| Step: 9
Training loss: 0.7348923179998386
Validation loss: 2.489661060073624

Epoch: 5| Step: 10
Training loss: 0.5975378829326958
Validation loss: 2.455356211028863

Epoch: 351| Step: 0
Training loss: 0.6452566515237187
Validation loss: 2.4360012866641054

Epoch: 5| Step: 1
Training loss: 0.7149437172618792
Validation loss: 2.4408503966517765

Epoch: 5| Step: 2
Training loss: 0.5631577037498068
Validation loss: 2.4476241944818913

Epoch: 5| Step: 3
Training loss: 0.7712181694349778
Validation loss: 2.4372358933692517

Epoch: 5| Step: 4
Training loss: 0.5241830839255585
Validation loss: 2.451546529485742

Epoch: 5| Step: 5
Training loss: 0.5760434799671663
Validation loss: 2.461155930328

Epoch: 5| Step: 6
Training loss: 0.7006644322769237
Validation loss: 2.407752724983092

Epoch: 5| Step: 7
Training loss: 0.5976771432054462
Validation loss: 2.419872680673596

Epoch: 5| Step: 8
Training loss: 0.9157631206816987
Validation loss: 2.424065097760907

Epoch: 5| Step: 9
Training loss: 0.600995502539197
Validation loss: 2.414934668150136

Epoch: 5| Step: 10
Training loss: 0.5961784342636299
Validation loss: 2.434684234544549

Epoch: 352| Step: 0
Training loss: 0.762261378362551
Validation loss: 2.4378158500373233

Epoch: 5| Step: 1
Training loss: 0.8772000855024429
Validation loss: 2.432257201957664

Epoch: 5| Step: 2
Training loss: 0.4802691812780425
Validation loss: 2.457412906848874

Epoch: 5| Step: 3
Training loss: 0.8455670535807837
Validation loss: 2.4407876242864663

Epoch: 5| Step: 4
Training loss: 0.7751973100955106
Validation loss: 2.421042688249532

Epoch: 5| Step: 5
Training loss: 0.5675558328681176
Validation loss: 2.462818119540288

Epoch: 5| Step: 6
Training loss: 0.465810491750266
Validation loss: 2.4744569655250728

Epoch: 5| Step: 7
Training loss: 0.49162917788951704
Validation loss: 2.413503492192958

Epoch: 5| Step: 8
Training loss: 0.5422257753433396
Validation loss: 2.433570659578407

Epoch: 5| Step: 9
Training loss: 0.578609830306824
Validation loss: 2.392273959057612

Epoch: 5| Step: 10
Training loss: 0.5933647662803723
Validation loss: 2.3681096272565325

Epoch: 353| Step: 0
Training loss: 0.8439837591113755
Validation loss: 2.362011482314465

Epoch: 5| Step: 1
Training loss: 0.9060564492157742
Validation loss: 2.3291365325573343

Epoch: 5| Step: 2
Training loss: 0.6184060103855347
Validation loss: 2.331572731093115

Epoch: 5| Step: 3
Training loss: 0.467536069656598
Validation loss: 2.3661218691710584

Epoch: 5| Step: 4
Training loss: 0.2129571530745338
Validation loss: 2.350880383401358

Epoch: 5| Step: 5
Training loss: 0.33313871702541803
Validation loss: 2.423268374969865

Epoch: 5| Step: 6
Training loss: 0.9027027555414133
Validation loss: 2.4638814547213808

Epoch: 5| Step: 7
Training loss: 0.7370812083706614
Validation loss: 2.498170216879936

Epoch: 5| Step: 8
Training loss: 0.4861833287893917
Validation loss: 2.4668709065369403

Epoch: 5| Step: 9
Training loss: 0.5223963617364626
Validation loss: 2.4802612931069197

Epoch: 5| Step: 10
Training loss: 0.7366199269361988
Validation loss: 2.3859534783788665

Epoch: 354| Step: 0
Training loss: 0.5331468098283572
Validation loss: 2.366895702821782

Epoch: 5| Step: 1
Training loss: 0.6932863438788602
Validation loss: 2.3857458463989856

Epoch: 5| Step: 2
Training loss: 0.6291317269010908
Validation loss: 2.385749508516052

Epoch: 5| Step: 3
Training loss: 0.9435523489321213
Validation loss: 2.392524385600057

Epoch: 5| Step: 4
Training loss: 0.7285815661657372
Validation loss: 2.4985929036355774

Epoch: 5| Step: 5
Training loss: 0.7274433661895499
Validation loss: 2.5378147324985774

Epoch: 5| Step: 6
Training loss: 0.5266876094714339
Validation loss: 2.5426803099405735

Epoch: 5| Step: 7
Training loss: 0.6951378163564332
Validation loss: 2.5390674040110444

Epoch: 5| Step: 8
Training loss: 0.44078379603600226
Validation loss: 2.4943536759341827

Epoch: 5| Step: 9
Training loss: 0.7082718139935481
Validation loss: 2.4386635047238454

Epoch: 5| Step: 10
Training loss: 0.3566154178598292
Validation loss: 2.351691890622644

Epoch: 355| Step: 0
Training loss: 0.6663663505603953
Validation loss: 2.3454924283179484

Epoch: 5| Step: 1
Training loss: 0.7570823219165194
Validation loss: 2.3261607320608575

Epoch: 5| Step: 2
Training loss: 0.514647684693917
Validation loss: 2.348330063633296

Epoch: 5| Step: 3
Training loss: 0.6563273111853034
Validation loss: 2.431109923111283

Epoch: 5| Step: 4
Training loss: 0.7679952405394658
Validation loss: 2.452637830382708

Epoch: 5| Step: 5
Training loss: 0.5703560799447944
Validation loss: 2.5171402439249855

Epoch: 5| Step: 6
Training loss: 0.625219735619222
Validation loss: 2.5626819752573

Epoch: 5| Step: 7
Training loss: 0.80911812848527
Validation loss: 2.5234277693855707

Epoch: 5| Step: 8
Training loss: 0.6751792298890734
Validation loss: 2.4887721203637385

Epoch: 5| Step: 9
Training loss: 0.6479878532660521
Validation loss: 2.4333855964564783

Epoch: 5| Step: 10
Training loss: 0.27716231791905305
Validation loss: 2.3963357285419202

Epoch: 356| Step: 0
Training loss: 0.7912188233656092
Validation loss: 2.380012505407889

Epoch: 5| Step: 1
Training loss: 0.5505774641788935
Validation loss: 2.3963420629198455

Epoch: 5| Step: 2
Training loss: 0.667924957624519
Validation loss: 2.426412889505532

Epoch: 5| Step: 3
Training loss: 0.7483500371808978
Validation loss: 2.456773252137572

Epoch: 5| Step: 4
Training loss: 0.7574591058450535
Validation loss: 2.494863689735209

Epoch: 5| Step: 5
Training loss: 0.4677250464780131
Validation loss: 2.5662467900635777

Epoch: 5| Step: 6
Training loss: 0.5192751719434793
Validation loss: 2.582293980306732

Epoch: 5| Step: 7
Training loss: 0.7718342434397174
Validation loss: 2.586760860729714

Epoch: 5| Step: 8
Training loss: 0.5565385155969027
Validation loss: 2.5132882356545796

Epoch: 5| Step: 9
Training loss: 0.621981747728967
Validation loss: 2.4788265299131007

Epoch: 5| Step: 10
Training loss: 0.4467634688760848
Validation loss: 2.404462429753835

Epoch: 357| Step: 0
Training loss: 0.648058930159015
Validation loss: 2.3895596698770483

Epoch: 5| Step: 1
Training loss: 0.5818084700069169
Validation loss: 2.3757096667579103

Epoch: 5| Step: 2
Training loss: 0.7126127772839596
Validation loss: 2.3778839972785852

Epoch: 5| Step: 3
Training loss: 0.45197007552187746
Validation loss: 2.4055024823624462

Epoch: 5| Step: 4
Training loss: 0.5307273537776732
Validation loss: 2.466007279754335

Epoch: 5| Step: 5
Training loss: 0.45924527483976807
Validation loss: 2.5264666375008606

Epoch: 5| Step: 6
Training loss: 0.6464901373568954
Validation loss: 2.5147427129073

Epoch: 5| Step: 7
Training loss: 0.6782722866939792
Validation loss: 2.566728047653225

Epoch: 5| Step: 8
Training loss: 0.48282453589884466
Validation loss: 2.5305498234166977

Epoch: 5| Step: 9
Training loss: 0.8634210533759892
Validation loss: 2.495347483734898

Epoch: 5| Step: 10
Training loss: 0.7543535634987583
Validation loss: 2.453148101787737

Epoch: 358| Step: 0
Training loss: 0.5319793967186818
Validation loss: 2.3893945401192256

Epoch: 5| Step: 1
Training loss: 0.6068037021449846
Validation loss: 2.4006511721348223

Epoch: 5| Step: 2
Training loss: 0.8305042564287609
Validation loss: 2.4418842651994686

Epoch: 5| Step: 3
Training loss: 0.7039724752791823
Validation loss: 2.456448511500061

Epoch: 5| Step: 4
Training loss: 0.5417067867484177
Validation loss: 2.4914050421260723

Epoch: 5| Step: 5
Training loss: 0.47873813360463097
Validation loss: 2.518292855369165

Epoch: 5| Step: 6
Training loss: 0.48166761237626915
Validation loss: 2.5628152048659287

Epoch: 5| Step: 7
Training loss: 0.6207991807192995
Validation loss: 2.492945348031074

Epoch: 5| Step: 8
Training loss: 0.7193878494825259
Validation loss: 2.4534501126208927

Epoch: 5| Step: 9
Training loss: 0.6737713997225552
Validation loss: 2.398817818318599

Epoch: 5| Step: 10
Training loss: 0.747267832854978
Validation loss: 2.3800652853819404

Epoch: 359| Step: 0
Training loss: 0.5045250043485394
Validation loss: 2.4424499438726803

Epoch: 5| Step: 1
Training loss: 0.739985441760606
Validation loss: 2.447099919539404

Epoch: 5| Step: 2
Training loss: 0.5647582447130717
Validation loss: 2.4662915033325006

Epoch: 5| Step: 3
Training loss: 0.6986180287653381
Validation loss: 2.518213542185579

Epoch: 5| Step: 4
Training loss: 0.5331716004159565
Validation loss: 2.5445045246901525

Epoch: 5| Step: 5
Training loss: 0.6387811269846325
Validation loss: 2.558502043823302

Epoch: 5| Step: 6
Training loss: 0.548489041637119
Validation loss: 2.5424340093554085

Epoch: 5| Step: 7
Training loss: 0.5235353634575404
Validation loss: 2.5390934323681886

Epoch: 5| Step: 8
Training loss: 0.7586500907113988
Validation loss: 2.4571963107631833

Epoch: 5| Step: 9
Training loss: 0.7035469060929972
Validation loss: 2.4425259455654698

Epoch: 5| Step: 10
Training loss: 0.6345942574043141
Validation loss: 2.446966367928904

Epoch: 360| Step: 0
Training loss: 0.5570627586152718
Validation loss: 2.402594063269767

Epoch: 5| Step: 1
Training loss: 0.7637226839066084
Validation loss: 2.4618080330026224

Epoch: 5| Step: 2
Training loss: 0.5128299790587688
Validation loss: 2.4629114591903565

Epoch: 5| Step: 3
Training loss: 0.6938404831861144
Validation loss: 2.4899966902104844

Epoch: 5| Step: 4
Training loss: 0.6268331822969309
Validation loss: 2.45437879090814

Epoch: 5| Step: 5
Training loss: 0.5474525943682436
Validation loss: 2.4571527538778892

Epoch: 5| Step: 6
Training loss: 0.5007705711142618
Validation loss: 2.4279112484914633

Epoch: 5| Step: 7
Training loss: 0.6338497420830205
Validation loss: 2.407487207870549

Epoch: 5| Step: 8
Training loss: 0.5582411126464165
Validation loss: 2.3932971972572403

Epoch: 5| Step: 9
Training loss: 0.6971677609961804
Validation loss: 2.366650194705533

Epoch: 5| Step: 10
Training loss: 0.6413488717847003
Validation loss: 2.4526932734047393

Epoch: 361| Step: 0
Training loss: 0.6358546144424675
Validation loss: 2.4934130312651734

Epoch: 5| Step: 1
Training loss: 0.5335575644425804
Validation loss: 2.531075274454195

Epoch: 5| Step: 2
Training loss: 0.6198072244524087
Validation loss: 2.495253164672239

Epoch: 5| Step: 3
Training loss: 0.6732825904278659
Validation loss: 2.4169741283979675

Epoch: 5| Step: 4
Training loss: 0.6052040998362225
Validation loss: 2.4100052534347474

Epoch: 5| Step: 5
Training loss: 0.6109307310700134
Validation loss: 2.4216623266484802

Epoch: 5| Step: 6
Training loss: 0.5289445668798344
Validation loss: 2.396479342887821

Epoch: 5| Step: 7
Training loss: 0.5294676501682533
Validation loss: 2.388166873877793

Epoch: 5| Step: 8
Training loss: 0.6735115081409955
Validation loss: 2.440065228873666

Epoch: 5| Step: 9
Training loss: 0.779200574235685
Validation loss: 2.466630763616018

Epoch: 5| Step: 10
Training loss: 0.5152562585771714
Validation loss: 2.424326944439306

Epoch: 362| Step: 0
Training loss: 0.47924644559339113
Validation loss: 2.4133122883966145

Epoch: 5| Step: 1
Training loss: 0.5339875930655678
Validation loss: 2.372356025755619

Epoch: 5| Step: 2
Training loss: 0.7595438106324616
Validation loss: 2.3790567731906433

Epoch: 5| Step: 3
Training loss: 0.8030780511336466
Validation loss: 2.412596407156377

Epoch: 5| Step: 4
Training loss: 0.5156608048925556
Validation loss: 2.417686366792415

Epoch: 5| Step: 5
Training loss: 0.73299908082652
Validation loss: 2.4395326632464225

Epoch: 5| Step: 6
Training loss: 0.5414302077504122
Validation loss: 2.489774062263664

Epoch: 5| Step: 7
Training loss: 0.4817097616578982
Validation loss: 2.5144573506319667

Epoch: 5| Step: 8
Training loss: 0.7249314242849261
Validation loss: 2.458729504684401

Epoch: 5| Step: 9
Training loss: 0.448231316727607
Validation loss: 2.4102414537039634

Epoch: 5| Step: 10
Training loss: 0.4491543101655871
Validation loss: 2.3863838129558337

Epoch: 363| Step: 0
Training loss: 0.6304242076998443
Validation loss: 2.368623240518135

Epoch: 5| Step: 1
Training loss: 0.6228097207198311
Validation loss: 2.3545124069776606

Epoch: 5| Step: 2
Training loss: 0.7335891170985106
Validation loss: 2.4158385894494883

Epoch: 5| Step: 3
Training loss: 0.3894906740443259
Validation loss: 2.4622301276432506

Epoch: 5| Step: 4
Training loss: 0.6847842939131004
Validation loss: 2.4525885835774814

Epoch: 5| Step: 5
Training loss: 0.5811221043561154
Validation loss: 2.4878197638681923

Epoch: 5| Step: 6
Training loss: 0.7070542431880934
Validation loss: 2.4176626250050375

Epoch: 5| Step: 7
Training loss: 0.5730349476410953
Validation loss: 2.409230397295279

Epoch: 5| Step: 8
Training loss: 0.5086720454690724
Validation loss: 2.4025116108240554

Epoch: 5| Step: 9
Training loss: 0.6398137701554252
Validation loss: 2.3867569155990065

Epoch: 5| Step: 10
Training loss: 0.4418750231741504
Validation loss: 2.3683132669367555

Epoch: 364| Step: 0
Training loss: 0.6678522465703428
Validation loss: 2.342116303757269

Epoch: 5| Step: 1
Training loss: 0.4137224564503336
Validation loss: 2.4050566035572025

Epoch: 5| Step: 2
Training loss: 0.7552679937189668
Validation loss: 2.3892487772310314

Epoch: 5| Step: 3
Training loss: 0.7557863106517754
Validation loss: 2.4445648214021225

Epoch: 5| Step: 4
Training loss: 0.69430996917365
Validation loss: 2.4640542680994293

Epoch: 5| Step: 5
Training loss: 0.386074068254017
Validation loss: 2.459488227402745

Epoch: 5| Step: 6
Training loss: 0.6384270808433558
Validation loss: 2.4682871487331743

Epoch: 5| Step: 7
Training loss: 0.5465185911361649
Validation loss: 2.477095502883544

Epoch: 5| Step: 8
Training loss: 0.5985136924824987
Validation loss: 2.4849677869444875

Epoch: 5| Step: 9
Training loss: 0.5053724500849854
Validation loss: 2.473493766925913

Epoch: 5| Step: 10
Training loss: 0.3630024239876892
Validation loss: 2.4082204738276434

Epoch: 365| Step: 0
Training loss: 0.6388349179147796
Validation loss: 2.3458943468154305

Epoch: 5| Step: 1
Training loss: 0.6118671368803841
Validation loss: 2.362289845866889

Epoch: 5| Step: 2
Training loss: 0.6070665258421184
Validation loss: 2.3771334242782896

Epoch: 5| Step: 3
Training loss: 0.4322731423909311
Validation loss: 2.4026058736654825

Epoch: 5| Step: 4
Training loss: 0.4893748282411549
Validation loss: 2.4524966024806547

Epoch: 5| Step: 5
Training loss: 0.6107148332999698
Validation loss: 2.457388984483451

Epoch: 5| Step: 6
Training loss: 0.6801502362648592
Validation loss: 2.4859140388320804

Epoch: 5| Step: 7
Training loss: 0.4339112846019241
Validation loss: 2.5085060495422122

Epoch: 5| Step: 8
Training loss: 0.627370012429571
Validation loss: 2.54512405325898

Epoch: 5| Step: 9
Training loss: 0.35633792043251566
Validation loss: 2.482418074596509

Epoch: 5| Step: 10
Training loss: 0.8016639496551702
Validation loss: 2.473909510253246

Epoch: 366| Step: 0
Training loss: 0.6754924178979164
Validation loss: 2.4478123468300046

Epoch: 5| Step: 1
Training loss: 0.32665561735595
Validation loss: 2.4447149328752844

Epoch: 5| Step: 2
Training loss: 0.5925993310180426
Validation loss: 2.3819744291147984

Epoch: 5| Step: 3
Training loss: 0.6214834945739609
Validation loss: 2.387367879524162

Epoch: 5| Step: 4
Training loss: 0.5346068743633747
Validation loss: 2.438361948146086

Epoch: 5| Step: 5
Training loss: 0.7136181607048125
Validation loss: 2.4975374296225454

Epoch: 5| Step: 6
Training loss: 0.44938077907003054
Validation loss: 2.5079297997407215

Epoch: 5| Step: 7
Training loss: 0.6944614302359254
Validation loss: 2.5198072906274147

Epoch: 5| Step: 8
Training loss: 0.5352551445462095
Validation loss: 2.522121826947073

Epoch: 5| Step: 9
Training loss: 0.4340398401067712
Validation loss: 2.4991144006345887

Epoch: 5| Step: 10
Training loss: 0.7349958838782242
Validation loss: 2.418365699331434

Epoch: 367| Step: 0
Training loss: 0.4907287597276683
Validation loss: 2.420065564782118

Epoch: 5| Step: 1
Training loss: 0.4920782240403987
Validation loss: 2.4158425720563628

Epoch: 5| Step: 2
Training loss: 0.7890204994429865
Validation loss: 2.431397682557373

Epoch: 5| Step: 3
Training loss: 0.43673671828754945
Validation loss: 2.44886760546661

Epoch: 5| Step: 4
Training loss: 0.800723338940668
Validation loss: 2.468276506373182

Epoch: 5| Step: 5
Training loss: 0.42191028447415846
Validation loss: 2.5127988376887718

Epoch: 5| Step: 6
Training loss: 0.43579973484580947
Validation loss: 2.5120054964930025

Epoch: 5| Step: 7
Training loss: 0.48979104654404576
Validation loss: 2.481292596580893

Epoch: 5| Step: 8
Training loss: 0.5220804986270425
Validation loss: 2.4666107554142367

Epoch: 5| Step: 9
Training loss: 0.6598069886633873
Validation loss: 2.4521936744462676

Epoch: 5| Step: 10
Training loss: 0.49285923063189435
Validation loss: 2.4378122046155797

Epoch: 368| Step: 0
Training loss: 0.688836402735166
Validation loss: 2.463295845990807

Epoch: 5| Step: 1
Training loss: 0.5454903102297372
Validation loss: 2.455687620873981

Epoch: 5| Step: 2
Training loss: 0.5355736434334576
Validation loss: 2.5039660942079456

Epoch: 5| Step: 3
Training loss: 0.49131309705871945
Validation loss: 2.472264805635527

Epoch: 5| Step: 4
Training loss: 0.6149672397556406
Validation loss: 2.4680884785863726

Epoch: 5| Step: 5
Training loss: 0.5105249588457269
Validation loss: 2.429172652959813

Epoch: 5| Step: 6
Training loss: 0.6656930539439663
Validation loss: 2.449997738669103

Epoch: 5| Step: 7
Training loss: 0.6077852051791729
Validation loss: 2.4412124056739684

Epoch: 5| Step: 8
Training loss: 0.4042666880077186
Validation loss: 2.452503414813361

Epoch: 5| Step: 9
Training loss: 0.5144879490819185
Validation loss: 2.4193598542793815

Epoch: 5| Step: 10
Training loss: 0.5365969068440914
Validation loss: 2.385890026192254

Epoch: 369| Step: 0
Training loss: 0.4250121213081997
Validation loss: 2.413132796984566

Epoch: 5| Step: 1
Training loss: 0.6657796089171834
Validation loss: 2.4413179020472957

Epoch: 5| Step: 2
Training loss: 0.5094379234064164
Validation loss: 2.45585454655676

Epoch: 5| Step: 3
Training loss: 0.7449473416196569
Validation loss: 2.4604511038793526

Epoch: 5| Step: 4
Training loss: 0.6441871880704229
Validation loss: 2.5002784307337933

Epoch: 5| Step: 5
Training loss: 0.7187052588427939
Validation loss: 2.4533609846697693

Epoch: 5| Step: 6
Training loss: 0.405495144052981
Validation loss: 2.485550085351904

Epoch: 5| Step: 7
Training loss: 0.25997991972647433
Validation loss: 2.4674994584277137

Epoch: 5| Step: 8
Training loss: 0.4327409106654789
Validation loss: 2.494888321945928

Epoch: 5| Step: 9
Training loss: 0.44934831492281135
Validation loss: 2.4300909868966647

Epoch: 5| Step: 10
Training loss: 0.6313890294608497
Validation loss: 2.4563184385292516

Epoch: 370| Step: 0
Training loss: 0.5878474831197177
Validation loss: 2.459941268983154

Epoch: 5| Step: 1
Training loss: 0.5518297806787419
Validation loss: 2.4248252869990976

Epoch: 5| Step: 2
Training loss: 0.7136147779520075
Validation loss: 2.4340662975693284

Epoch: 5| Step: 3
Training loss: 0.7124805682025462
Validation loss: 2.399852212932625

Epoch: 5| Step: 4
Training loss: 0.3273894489773152
Validation loss: 2.4596201339444317

Epoch: 5| Step: 5
Training loss: 0.5203303451456356
Validation loss: 2.533262193627614

Epoch: 5| Step: 6
Training loss: 0.5506733457231069
Validation loss: 2.489504677279174

Epoch: 5| Step: 7
Training loss: 0.3507936653879696
Validation loss: 2.450813648308993

Epoch: 5| Step: 8
Training loss: 0.3351420143856637
Validation loss: 2.397717551316003

Epoch: 5| Step: 9
Training loss: 0.5098070149773751
Validation loss: 2.3829567088105263

Epoch: 5| Step: 10
Training loss: 0.746743124328366
Validation loss: 2.375481780105607

Epoch: 371| Step: 0
Training loss: 0.6043945134986213
Validation loss: 2.3897983237777227

Epoch: 5| Step: 1
Training loss: 0.30869663310128714
Validation loss: 2.3853906136663725

Epoch: 5| Step: 2
Training loss: 0.8787932937940046
Validation loss: 2.4176040457335017

Epoch: 5| Step: 3
Training loss: 0.3797162629837895
Validation loss: 2.424948124425315

Epoch: 5| Step: 4
Training loss: 0.6154680323057888
Validation loss: 2.3873513134047797

Epoch: 5| Step: 5
Training loss: 0.4093221994375862
Validation loss: 2.4423949442938873

Epoch: 5| Step: 6
Training loss: 0.43390707774868054
Validation loss: 2.483851677902658

Epoch: 5| Step: 7
Training loss: 0.46724900890120724
Validation loss: 2.476178375833455

Epoch: 5| Step: 8
Training loss: 0.5518842704141211
Validation loss: 2.4986423035939778

Epoch: 5| Step: 9
Training loss: 0.5151088905953571
Validation loss: 2.488676315695798

Epoch: 5| Step: 10
Training loss: 0.6088957491452068
Validation loss: 2.449429269378514

Epoch: 372| Step: 0
Training loss: 0.46607351718919005
Validation loss: 2.4475078455200636

Epoch: 5| Step: 1
Training loss: 0.4925243194016948
Validation loss: 2.4034653611893164

Epoch: 5| Step: 2
Training loss: 0.43922404782395413
Validation loss: 2.3677552804405693

Epoch: 5| Step: 3
Training loss: 0.5077222597197288
Validation loss: 2.420947047626074

Epoch: 5| Step: 4
Training loss: 0.33217184792478177
Validation loss: 2.415449905093648

Epoch: 5| Step: 5
Training loss: 0.40361278357614716
Validation loss: 2.453501116358595

Epoch: 5| Step: 6
Training loss: 0.7189454766532132
Validation loss: 2.489054336669905

Epoch: 5| Step: 7
Training loss: 0.46808032837475305
Validation loss: 2.474114571491534

Epoch: 5| Step: 8
Training loss: 0.5990527424144513
Validation loss: 2.457327652821651

Epoch: 5| Step: 9
Training loss: 0.6304785225452357
Validation loss: 2.415067481660723

Epoch: 5| Step: 10
Training loss: 0.6728979795083472
Validation loss: 2.4116897314291266

Epoch: 373| Step: 0
Training loss: 0.6429106712762238
Validation loss: 2.4123865045502644

Epoch: 5| Step: 1
Training loss: 0.5081043578455957
Validation loss: 2.435963665282859

Epoch: 5| Step: 2
Training loss: 0.6241779166032428
Validation loss: 2.4120444814618005

Epoch: 5| Step: 3
Training loss: 0.41643152357058477
Validation loss: 2.5143407102399085

Epoch: 5| Step: 4
Training loss: 0.49578627121261437
Validation loss: 2.4400958796527763

Epoch: 5| Step: 5
Training loss: 0.6840374188031499
Validation loss: 2.4647611379897545

Epoch: 5| Step: 6
Training loss: 0.41692959317896
Validation loss: 2.431978832765332

Epoch: 5| Step: 7
Training loss: 0.32715011140765204
Validation loss: 2.4500857226250696

Epoch: 5| Step: 8
Training loss: 0.36620454909792427
Validation loss: 2.413865034049867

Epoch: 5| Step: 9
Training loss: 0.4922911065666552
Validation loss: 2.3586869502749797

Epoch: 5| Step: 10
Training loss: 0.749597361887317
Validation loss: 2.409224767182664

Epoch: 374| Step: 0
Training loss: 0.6937850075558085
Validation loss: 2.3954390830530485

Epoch: 5| Step: 1
Training loss: 0.6101271804351703
Validation loss: 2.450027958340199

Epoch: 5| Step: 2
Training loss: 0.3911667881248805
Validation loss: 2.5036706393005836

Epoch: 5| Step: 3
Training loss: 0.5774850654322341
Validation loss: 2.510377116592351

Epoch: 5| Step: 4
Training loss: 0.35188939473333586
Validation loss: 2.540942603520369

Epoch: 5| Step: 5
Training loss: 0.3612680333662207
Validation loss: 2.466307144216099

Epoch: 5| Step: 6
Training loss: 0.682074138433349
Validation loss: 2.468818002649234

Epoch: 5| Step: 7
Training loss: 0.5660057230228721
Validation loss: 2.4177923653559343

Epoch: 5| Step: 8
Training loss: 0.41157473555373736
Validation loss: 2.4036084679500904

Epoch: 5| Step: 9
Training loss: 0.6054734014517019
Validation loss: 2.3501144800641405

Epoch: 5| Step: 10
Training loss: 0.5750212997140339
Validation loss: 2.3997208969215444

Epoch: 375| Step: 0
Training loss: 0.4339269440400086
Validation loss: 2.4125616246069272

Epoch: 5| Step: 1
Training loss: 0.44765142601303315
Validation loss: 2.4616545997555095

Epoch: 5| Step: 2
Training loss: 0.519801621606124
Validation loss: 2.4534855056410425

Epoch: 5| Step: 3
Training loss: 0.4836666711605255
Validation loss: 2.467854908820923

Epoch: 5| Step: 4
Training loss: 0.522670411515363
Validation loss: 2.487362260159141

Epoch: 5| Step: 5
Training loss: 0.7645877896905763
Validation loss: 2.4549240617532018

Epoch: 5| Step: 6
Training loss: 0.37607949569435245
Validation loss: 2.4028394949095397

Epoch: 5| Step: 7
Training loss: 0.6239247370884473
Validation loss: 2.4044560325383553

Epoch: 5| Step: 8
Training loss: 0.5574412962023685
Validation loss: 2.384635010176982

Epoch: 5| Step: 9
Training loss: 0.5248918399203399
Validation loss: 2.3614422964204733

Epoch: 5| Step: 10
Training loss: 0.4419516004941021
Validation loss: 2.396419349326633

Epoch: 376| Step: 0
Training loss: 0.49370024587344236
Validation loss: 2.3914464935470208

Epoch: 5| Step: 1
Training loss: 0.636457963205616
Validation loss: 2.431502317938171

Epoch: 5| Step: 2
Training loss: 0.7945107561467264
Validation loss: 2.469995070724016

Epoch: 5| Step: 3
Training loss: 0.39309074373897807
Validation loss: 2.4323891528848347

Epoch: 5| Step: 4
Training loss: 0.43158309000716366
Validation loss: 2.475519150150203

Epoch: 5| Step: 5
Training loss: 0.3936592701421099
Validation loss: 2.492417330473979

Epoch: 5| Step: 6
Training loss: 0.467557694093124
Validation loss: 2.506067599667912

Epoch: 5| Step: 7
Training loss: 0.5710926468156213
Validation loss: 2.490135493767382

Epoch: 5| Step: 8
Training loss: 0.48257329626201084
Validation loss: 2.4558030227650214

Epoch: 5| Step: 9
Training loss: 0.5321567314603204
Validation loss: 2.428353097677437

Epoch: 5| Step: 10
Training loss: 0.5667696083287908
Validation loss: 2.3994478400650543

Epoch: 377| Step: 0
Training loss: 0.6552457164011649
Validation loss: 2.393157432661464

Epoch: 5| Step: 1
Training loss: 0.5014598515604721
Validation loss: 2.4289356254439616

Epoch: 5| Step: 2
Training loss: 0.32596500483663443
Validation loss: 2.3961211585830515

Epoch: 5| Step: 3
Training loss: 0.6562150537177925
Validation loss: 2.413434329833063

Epoch: 5| Step: 4
Training loss: 0.5989154689764988
Validation loss: 2.423238283641181

Epoch: 5| Step: 5
Training loss: 0.5434839562449366
Validation loss: 2.4467318233009285

Epoch: 5| Step: 6
Training loss: 0.5306981249545225
Validation loss: 2.448570731357964

Epoch: 5| Step: 7
Training loss: 0.4564256323512527
Validation loss: 2.4290490930209154

Epoch: 5| Step: 8
Training loss: 0.6407145460860029
Validation loss: 2.421264471981469

Epoch: 5| Step: 9
Training loss: 0.37465592334798936
Validation loss: 2.378489502559418

Epoch: 5| Step: 10
Training loss: 0.21909563823381953
Validation loss: 2.3560439267892295

Epoch: 378| Step: 0
Training loss: 0.6187326910507102
Validation loss: 2.400618301069017

Epoch: 5| Step: 1
Training loss: 0.5413075564926976
Validation loss: 2.425923931188726

Epoch: 5| Step: 2
Training loss: 0.4475810508745589
Validation loss: 2.4190351674600112

Epoch: 5| Step: 3
Training loss: 0.146474520033893
Validation loss: 2.420612570111891

Epoch: 5| Step: 4
Training loss: 0.5990856256533547
Validation loss: 2.3569130665544593

Epoch: 5| Step: 5
Training loss: 0.4053538782649682
Validation loss: 2.434572020490782

Epoch: 5| Step: 6
Training loss: 0.45931288954536215
Validation loss: 2.401835992048435

Epoch: 5| Step: 7
Training loss: 0.4236827724151952
Validation loss: 2.430647992917024

Epoch: 5| Step: 8
Training loss: 0.6953253584112136
Validation loss: 2.399254028758903

Epoch: 5| Step: 9
Training loss: 0.21884573816891317
Validation loss: 2.387797321450887

Epoch: 5| Step: 10
Training loss: 0.764698908712557
Validation loss: 2.356568131913354

Epoch: 379| Step: 0
Training loss: 0.47320616077635225
Validation loss: 2.366291966912479

Epoch: 5| Step: 1
Training loss: 0.6065620396026169
Validation loss: 2.379515937190064

Epoch: 5| Step: 2
Training loss: 0.5649280332204067
Validation loss: 2.419146446906046

Epoch: 5| Step: 3
Training loss: 0.4056307217410417
Validation loss: 2.455705757009091

Epoch: 5| Step: 4
Training loss: 0.38455562379449987
Validation loss: 2.4953206435965063

Epoch: 5| Step: 5
Training loss: 0.5668244495164897
Validation loss: 2.45000716056221

Epoch: 5| Step: 6
Training loss: 0.4939397471436051
Validation loss: 2.4481467460702313

Epoch: 5| Step: 7
Training loss: 0.619633788081328
Validation loss: 2.432455191007983

Epoch: 5| Step: 8
Training loss: 0.28982575918539294
Validation loss: 2.444385827768764

Epoch: 5| Step: 9
Training loss: 0.4167127007645039
Validation loss: 2.4111076941151786

Epoch: 5| Step: 10
Training loss: 0.6740276096671393
Validation loss: 2.3900363569257044

Epoch: 380| Step: 0
Training loss: 0.46620803467734195
Validation loss: 2.407692644979942

Epoch: 5| Step: 1
Training loss: 0.42841457472553074
Validation loss: 2.4066274757314376

Epoch: 5| Step: 2
Training loss: 0.3727352778292492
Validation loss: 2.4267371596818923

Epoch: 5| Step: 3
Training loss: 0.5109250560026721
Validation loss: 2.4622578480351436

Epoch: 5| Step: 4
Training loss: 0.5613516636043072
Validation loss: 2.4968032887604523

Epoch: 5| Step: 5
Training loss: 0.4954959391313011
Validation loss: 2.4696603734357367

Epoch: 5| Step: 6
Training loss: 0.3945324963842665
Validation loss: 2.5215809472051354

Epoch: 5| Step: 7
Training loss: 0.632982725630892
Validation loss: 2.516736329740371

Epoch: 5| Step: 8
Training loss: 0.5912009786240269
Validation loss: 2.456230146836192

Epoch: 5| Step: 9
Training loss: 0.6094580129176301
Validation loss: 2.364888173786774

Epoch: 5| Step: 10
Training loss: 0.36405865744990085
Validation loss: 2.355535357798806

Epoch: 381| Step: 0
Training loss: 0.5879857439418167
Validation loss: 2.324741309262296

Epoch: 5| Step: 1
Training loss: 0.6453349795363187
Validation loss: 2.335818385451948

Epoch: 5| Step: 2
Training loss: 0.5596147023647323
Validation loss: 2.3492536639949373

Epoch: 5| Step: 3
Training loss: 0.31949452886389285
Validation loss: 2.372621089646379

Epoch: 5| Step: 4
Training loss: 0.5004532666867618
Validation loss: 2.463514096351364

Epoch: 5| Step: 5
Training loss: 0.3511428341510662
Validation loss: 2.4694845535416485

Epoch: 5| Step: 6
Training loss: 0.5891351042912363
Validation loss: 2.5359176983030296

Epoch: 5| Step: 7
Training loss: 0.542382122364917
Validation loss: 2.5203802740139443

Epoch: 5| Step: 8
Training loss: 0.5813969477642607
Validation loss: 2.4717442651671293

Epoch: 5| Step: 9
Training loss: 0.3821848375316591
Validation loss: 2.4249962315616265

Epoch: 5| Step: 10
Training loss: 0.5327192073821625
Validation loss: 2.385363277861153

Epoch: 382| Step: 0
Training loss: 0.30306558026624497
Validation loss: 2.376608721471373

Epoch: 5| Step: 1
Training loss: 0.38876481598344853
Validation loss: 2.350798143907474

Epoch: 5| Step: 2
Training loss: 0.7059260840841727
Validation loss: 2.3492792080111786

Epoch: 5| Step: 3
Training loss: 0.717409459425895
Validation loss: 2.4707295301061487

Epoch: 5| Step: 4
Training loss: 0.6513163533885163
Validation loss: 2.517908477359635

Epoch: 5| Step: 5
Training loss: 0.5946325970161008
Validation loss: 2.572518212762502

Epoch: 5| Step: 6
Training loss: 0.5296767163374584
Validation loss: 2.58737271073929

Epoch: 5| Step: 7
Training loss: 0.3335415765848382
Validation loss: 2.479834355936498

Epoch: 5| Step: 8
Training loss: 0.354873872097436
Validation loss: 2.407774388170172

Epoch: 5| Step: 9
Training loss: 0.29323549207343597
Validation loss: 2.343312013234719

Epoch: 5| Step: 10
Training loss: 0.6468517262423015
Validation loss: 2.3195872536007616

Epoch: 383| Step: 0
Training loss: 0.5637503608313377
Validation loss: 2.3504640227138727

Epoch: 5| Step: 1
Training loss: 0.6112293736462794
Validation loss: 2.405339578460725

Epoch: 5| Step: 2
Training loss: 0.6480639657220959
Validation loss: 2.4786299381906955

Epoch: 5| Step: 3
Training loss: 0.3389117186911044
Validation loss: 2.4771558452523057

Epoch: 5| Step: 4
Training loss: 0.5097069542105626
Validation loss: 2.481377429127828

Epoch: 5| Step: 5
Training loss: 0.6811693852524923
Validation loss: 2.5040438484345198

Epoch: 5| Step: 6
Training loss: 0.3945574610095462
Validation loss: 2.4301612955751053

Epoch: 5| Step: 7
Training loss: 0.4435543018307473
Validation loss: 2.4096979103738714

Epoch: 5| Step: 8
Training loss: 0.2934051315443942
Validation loss: 2.3750115282591735

Epoch: 5| Step: 9
Training loss: 0.6764096552145604
Validation loss: 2.3929740372265185

Epoch: 5| Step: 10
Training loss: 0.5470743905745868
Validation loss: 2.411560428165965

Epoch: 384| Step: 0
Training loss: 0.6561621879682848
Validation loss: 2.497690072971017

Epoch: 5| Step: 1
Training loss: 0.4443053182594869
Validation loss: 2.5871567666768605

Epoch: 5| Step: 2
Training loss: 0.6236559721687143
Validation loss: 2.5881094279617685

Epoch: 5| Step: 3
Training loss: 0.7511736111514241
Validation loss: 2.554180158985543

Epoch: 5| Step: 4
Training loss: 0.4410835369250656
Validation loss: 2.5261860905877938

Epoch: 5| Step: 5
Training loss: 0.3179848697334787
Validation loss: 2.5168677365890084

Epoch: 5| Step: 6
Training loss: 0.61143034546554
Validation loss: 2.443428615710577

Epoch: 5| Step: 7
Training loss: 0.5135095724274075
Validation loss: 2.4434191592698973

Epoch: 5| Step: 8
Training loss: 0.5301475867326139
Validation loss: 2.4806924455690007

Epoch: 5| Step: 9
Training loss: 0.5635457384828516
Validation loss: 2.4574892469624934

Epoch: 5| Step: 10
Training loss: 0.5159234137088009
Validation loss: 2.4399152017105696

Epoch: 385| Step: 0
Training loss: 0.5947324254540903
Validation loss: 2.454037350029493

Epoch: 5| Step: 1
Training loss: 0.5392462928478305
Validation loss: 2.4475701758218285

Epoch: 5| Step: 2
Training loss: 0.6860976438470484
Validation loss: 2.4290532750760674

Epoch: 5| Step: 3
Training loss: 0.7107135294152348
Validation loss: 2.4177336736498773

Epoch: 5| Step: 4
Training loss: 0.42658603798896333
Validation loss: 2.336681556269199

Epoch: 5| Step: 5
Training loss: 0.3194298678967747
Validation loss: 2.376399676445242

Epoch: 5| Step: 6
Training loss: 0.4432178557133483
Validation loss: 2.3706935905687216

Epoch: 5| Step: 7
Training loss: 0.3754572067994561
Validation loss: 2.4374549599675666

Epoch: 5| Step: 8
Training loss: 0.5877741955004183
Validation loss: 2.4302053035297364

Epoch: 5| Step: 9
Training loss: 0.6166369239834287
Validation loss: 2.4639195836523897

Epoch: 5| Step: 10
Training loss: 0.5550209440111388
Validation loss: 2.4518724366744182

Epoch: 386| Step: 0
Training loss: 0.3878387454893912
Validation loss: 2.435736824918513

Epoch: 5| Step: 1
Training loss: 0.5798843522531606
Validation loss: 2.361347661684422

Epoch: 5| Step: 2
Training loss: 0.45696230311249275
Validation loss: 2.36399959290223

Epoch: 5| Step: 3
Training loss: 0.5016587875017827
Validation loss: 2.3969784482973355

Epoch: 5| Step: 4
Training loss: 0.3978450709072254
Validation loss: 2.4751662861704666

Epoch: 5| Step: 5
Training loss: 0.4632690910557853
Validation loss: 2.5422570393380677

Epoch: 5| Step: 6
Training loss: 0.579056890865031
Validation loss: 2.593458153062526

Epoch: 5| Step: 7
Training loss: 0.591009642475556
Validation loss: 2.599502059427394

Epoch: 5| Step: 8
Training loss: 0.6321382816255328
Validation loss: 2.5327748625683633

Epoch: 5| Step: 9
Training loss: 0.6001096992743087
Validation loss: 2.4144910328547553

Epoch: 5| Step: 10
Training loss: 0.5842600398280393
Validation loss: 2.358696132873691

Epoch: 387| Step: 0
Training loss: 0.6670689238477812
Validation loss: 2.3108905947139458

Epoch: 5| Step: 1
Training loss: 0.8063474404056497
Validation loss: 2.35183166025341

Epoch: 5| Step: 2
Training loss: 0.5097578493891836
Validation loss: 2.4504304849833187

Epoch: 5| Step: 3
Training loss: 0.5157735495005489
Validation loss: 2.580695472872251

Epoch: 5| Step: 4
Training loss: 0.6185801282492429
Validation loss: 2.6513801305619595

Epoch: 5| Step: 5
Training loss: 0.5140453764779614
Validation loss: 2.6481258562169647

Epoch: 5| Step: 6
Training loss: 0.3344127517850963
Validation loss: 2.577499382353401

Epoch: 5| Step: 7
Training loss: 0.27771456201116373
Validation loss: 2.49839930562726

Epoch: 5| Step: 8
Training loss: 0.6573665067461725
Validation loss: 2.463419557252644

Epoch: 5| Step: 9
Training loss: 0.41825990251195344
Validation loss: 2.3840628084649635

Epoch: 5| Step: 10
Training loss: 0.43580217961562395
Validation loss: 2.369423108050769

Epoch: 388| Step: 0
Training loss: 0.617619375435272
Validation loss: 2.3537220151557685

Epoch: 5| Step: 1
Training loss: 0.46259324061819174
Validation loss: 2.389936645758959

Epoch: 5| Step: 2
Training loss: 0.484407146986804
Validation loss: 2.449899526414764

Epoch: 5| Step: 3
Training loss: 0.5472207747384865
Validation loss: 2.50972773138409

Epoch: 5| Step: 4
Training loss: 0.3475536559381992
Validation loss: 2.5260130237561906

Epoch: 5| Step: 5
Training loss: 0.3211290836616561
Validation loss: 2.5835123850219444

Epoch: 5| Step: 6
Training loss: 0.7130179513594846
Validation loss: 2.574595252326079

Epoch: 5| Step: 7
Training loss: 0.4784541343572925
Validation loss: 2.534558426936471

Epoch: 5| Step: 8
Training loss: 0.48735669915356056
Validation loss: 2.5373626764167794

Epoch: 5| Step: 9
Training loss: 0.5021230803251904
Validation loss: 2.507952727381998

Epoch: 5| Step: 10
Training loss: 0.6138988713660634
Validation loss: 2.487867617721677

Epoch: 389| Step: 0
Training loss: 0.6445118294304277
Validation loss: 2.5000501996814664

Epoch: 5| Step: 1
Training loss: 0.5512801271540365
Validation loss: 2.4609182820283495

Epoch: 5| Step: 2
Training loss: 0.39437534537806557
Validation loss: 2.44155554661539

Epoch: 5| Step: 3
Training loss: 0.2865062529046322
Validation loss: 2.465323389341903

Epoch: 5| Step: 4
Training loss: 0.31099033481905547
Validation loss: 2.471695036024539

Epoch: 5| Step: 5
Training loss: 0.3796296833114965
Validation loss: 2.450906880818731

Epoch: 5| Step: 6
Training loss: 0.5677413201737338
Validation loss: 2.5236234442431558

Epoch: 5| Step: 7
Training loss: 0.5523868991772661
Validation loss: 2.563390952591542

Epoch: 5| Step: 8
Training loss: 0.5063770546834971
Validation loss: 2.521775122029168

Epoch: 5| Step: 9
Training loss: 0.5224550335987248
Validation loss: 2.4505222219380167

Epoch: 5| Step: 10
Training loss: 0.546873991829079
Validation loss: 2.4953921296750696

Epoch: 390| Step: 0
Training loss: 0.3851533088803919
Validation loss: 2.433119224633637

Epoch: 5| Step: 1
Training loss: 0.6921080997987947
Validation loss: 2.426881016905679

Epoch: 5| Step: 2
Training loss: 0.3298890401772962
Validation loss: 2.4072804598440647

Epoch: 5| Step: 3
Training loss: 0.3642366623043467
Validation loss: 2.435802151842733

Epoch: 5| Step: 4
Training loss: 0.4238164522172103
Validation loss: 2.438767815749984

Epoch: 5| Step: 5
Training loss: 0.5488182962969723
Validation loss: 2.477562384684984

Epoch: 5| Step: 6
Training loss: 0.5546617904937431
Validation loss: 2.4791424240729065

Epoch: 5| Step: 7
Training loss: 0.4753867482236518
Validation loss: 2.4779720273510035

Epoch: 5| Step: 8
Training loss: 0.5442398889922758
Validation loss: 2.4697079578232306

Epoch: 5| Step: 9
Training loss: 0.44004649474753976
Validation loss: 2.4639362337577455

Epoch: 5| Step: 10
Training loss: 0.37525875383265006
Validation loss: 2.4213672435141995

Epoch: 391| Step: 0
Training loss: 0.35495152414475334
Validation loss: 2.4434560027748247

Epoch: 5| Step: 1
Training loss: 0.4351265765333889
Validation loss: 2.4207343721769705

Epoch: 5| Step: 2
Training loss: 0.6096249092388262
Validation loss: 2.420844516647483

Epoch: 5| Step: 3
Training loss: 0.46746242433383084
Validation loss: 2.4511081965915156

Epoch: 5| Step: 4
Training loss: 0.18596273299111152
Validation loss: 2.492329652085417

Epoch: 5| Step: 5
Training loss: 0.5123693392669606
Validation loss: 2.517082229987383

Epoch: 5| Step: 6
Training loss: 0.5230599365426815
Validation loss: 2.5243131529854184

Epoch: 5| Step: 7
Training loss: 0.6855799131773734
Validation loss: 2.4912503918882902

Epoch: 5| Step: 8
Training loss: 0.4871414614512806
Validation loss: 2.5003941102249216

Epoch: 5| Step: 9
Training loss: 0.424479743941525
Validation loss: 2.4802803715390946

Epoch: 5| Step: 10
Training loss: 0.3672695879792395
Validation loss: 2.4848580572169108

Epoch: 392| Step: 0
Training loss: 0.32464378716208053
Validation loss: 2.465236768930769

Epoch: 5| Step: 1
Training loss: 0.5930204929297448
Validation loss: 2.4428012909887906

Epoch: 5| Step: 2
Training loss: 0.2736776659606285
Validation loss: 2.3993833979483723

Epoch: 5| Step: 3
Training loss: 0.6726791094396948
Validation loss: 2.4136737813581046

Epoch: 5| Step: 4
Training loss: 0.4629079276283503
Validation loss: 2.3895935314856422

Epoch: 5| Step: 5
Training loss: 0.5851515266828807
Validation loss: 2.4097539253777933

Epoch: 5| Step: 6
Training loss: 0.43402888827711666
Validation loss: 2.430002681201175

Epoch: 5| Step: 7
Training loss: 0.5767401269151162
Validation loss: 2.4986965719345933

Epoch: 5| Step: 8
Training loss: 0.22908631003260127
Validation loss: 2.5191599608004425

Epoch: 5| Step: 9
Training loss: 0.5290994874358015
Validation loss: 2.6005298649629194

Epoch: 5| Step: 10
Training loss: 0.19084800355305268
Validation loss: 2.571321254256225

Epoch: 393| Step: 0
Training loss: 0.4012268637882527
Validation loss: 2.5450478456967325

Epoch: 5| Step: 1
Training loss: 0.5271502387011449
Validation loss: 2.522402221676747

Epoch: 5| Step: 2
Training loss: 0.4933908375473427
Validation loss: 2.4627664447606685

Epoch: 5| Step: 3
Training loss: 0.38492524762047486
Validation loss: 2.4097423026800597

Epoch: 5| Step: 4
Training loss: 0.42334973456808184
Validation loss: 2.4575470831022765

Epoch: 5| Step: 5
Training loss: 0.47703533479482907
Validation loss: 2.469515427270256

Epoch: 5| Step: 6
Training loss: 0.5038646710415262
Validation loss: 2.4598065969570313

Epoch: 5| Step: 7
Training loss: 0.6632262630607786
Validation loss: 2.487929926616107

Epoch: 5| Step: 8
Training loss: 0.31012827172911805
Validation loss: 2.494876985908361

Epoch: 5| Step: 9
Training loss: 0.199641004620684
Validation loss: 2.5040655302536727

Epoch: 5| Step: 10
Training loss: 0.6195655591972508
Validation loss: 2.4729851864520356

Epoch: 394| Step: 0
Training loss: 0.4622530026346068
Validation loss: 2.4238848393884824

Epoch: 5| Step: 1
Training loss: 0.5089058769395707
Validation loss: 2.456358743507736

Epoch: 5| Step: 2
Training loss: 0.23675368746783101
Validation loss: 2.425474986429251

Epoch: 5| Step: 3
Training loss: 0.34309213717180836
Validation loss: 2.434510965920769

Epoch: 5| Step: 4
Training loss: 0.3773032820268933
Validation loss: 2.432169690878747

Epoch: 5| Step: 5
Training loss: 0.4514205379476186
Validation loss: 2.439315471093648

Epoch: 5| Step: 6
Training loss: 0.578733484844101
Validation loss: 2.4414806156768796

Epoch: 5| Step: 7
Training loss: 0.6179227192128504
Validation loss: 2.457782223348647

Epoch: 5| Step: 8
Training loss: 0.34803536992264683
Validation loss: 2.430230398583273

Epoch: 5| Step: 9
Training loss: 0.445794363487485
Validation loss: 2.507114427097248

Epoch: 5| Step: 10
Training loss: 0.4620481461811307
Validation loss: 2.446504285370162

Epoch: 395| Step: 0
Training loss: 0.31694286665513044
Validation loss: 2.4676591636904233

Epoch: 5| Step: 1
Training loss: 0.3555997250899163
Validation loss: 2.482135594351485

Epoch: 5| Step: 2
Training loss: 0.6837869425666938
Validation loss: 2.449095938672448

Epoch: 5| Step: 3
Training loss: 0.53336161399406
Validation loss: 2.4533466724643485

Epoch: 5| Step: 4
Training loss: 0.2991980712358632
Validation loss: 2.436698043846735

Epoch: 5| Step: 5
Training loss: 0.3983686050988605
Validation loss: 2.431996322955583

Epoch: 5| Step: 6
Training loss: 0.28239259159127544
Validation loss: 2.4114475930837043

Epoch: 5| Step: 7
Training loss: 0.5758570441329666
Validation loss: 2.4417552826151767

Epoch: 5| Step: 8
Training loss: 0.4455671586140818
Validation loss: 2.475410950405191

Epoch: 5| Step: 9
Training loss: 0.4140457833712365
Validation loss: 2.4765399830780126

Epoch: 5| Step: 10
Training loss: 0.45069794306534317
Validation loss: 2.491055167859059

Epoch: 396| Step: 0
Training loss: 0.3922996862074282
Validation loss: 2.5227367972872368

Epoch: 5| Step: 1
Training loss: 0.3496488410368632
Validation loss: 2.51501038388967

Epoch: 5| Step: 2
Training loss: 0.4749969344291143
Validation loss: 2.463273690703465

Epoch: 5| Step: 3
Training loss: 0.7095094948201177
Validation loss: 2.4867899415497514

Epoch: 5| Step: 4
Training loss: 0.40197896624096596
Validation loss: 2.4645726511315167

Epoch: 5| Step: 5
Training loss: 0.24918091974164538
Validation loss: 2.4492325268597206

Epoch: 5| Step: 6
Training loss: 0.4156084172088545
Validation loss: 2.4400926526371967

Epoch: 5| Step: 7
Training loss: 0.3681187690375921
Validation loss: 2.4424936359509983

Epoch: 5| Step: 8
Training loss: 0.29996570649437576
Validation loss: 2.3920368580666773

Epoch: 5| Step: 9
Training loss: 0.43271083119675
Validation loss: 2.413407877847952

Epoch: 5| Step: 10
Training loss: 0.6724605891581089
Validation loss: 2.439605413620189

Epoch: 397| Step: 0
Training loss: 0.4509848169733603
Validation loss: 2.417302198369584

Epoch: 5| Step: 1
Training loss: 0.4505500471606371
Validation loss: 2.40555148033369

Epoch: 5| Step: 2
Training loss: 0.5589189983019927
Validation loss: 2.4364157285266876

Epoch: 5| Step: 3
Training loss: 0.4299393522663812
Validation loss: 2.4748691079654788

Epoch: 5| Step: 4
Training loss: 0.35458580861570554
Validation loss: 2.4963286668330413

Epoch: 5| Step: 5
Training loss: 0.3731712014301995
Validation loss: 2.4886562194763933

Epoch: 5| Step: 6
Training loss: 0.2121089531348092
Validation loss: 2.475953954558386

Epoch: 5| Step: 7
Training loss: 0.4724753482886957
Validation loss: 2.473898593114371

Epoch: 5| Step: 8
Training loss: 0.559495531447824
Validation loss: 2.4123761835958626

Epoch: 5| Step: 9
Training loss: 0.528428917966847
Validation loss: 2.437124931816319

Epoch: 5| Step: 10
Training loss: 0.38709976230546045
Validation loss: 2.433095707193579

Epoch: 398| Step: 0
Training loss: 0.6204569929359198
Validation loss: 2.429034828068975

Epoch: 5| Step: 1
Training loss: 0.4463515290130821
Validation loss: 2.391585634569675

Epoch: 5| Step: 2
Training loss: 0.4553895138739909
Validation loss: 2.4371937816311875

Epoch: 5| Step: 3
Training loss: 0.3102529322218982
Validation loss: 2.432320560207204

Epoch: 5| Step: 4
Training loss: 0.5505225473579952
Validation loss: 2.4697307581979384

Epoch: 5| Step: 5
Training loss: 0.425962811877319
Validation loss: 2.469051812527827

Epoch: 5| Step: 6
Training loss: 0.25253202778163375
Validation loss: 2.489896261290705

Epoch: 5| Step: 7
Training loss: 0.3872785466116036
Validation loss: 2.511240792279824

Epoch: 5| Step: 8
Training loss: 0.4273546876501404
Validation loss: 2.4809850709445516

Epoch: 5| Step: 9
Training loss: 0.4706186084135982
Validation loss: 2.52096550016246

Epoch: 5| Step: 10
Training loss: 0.31128845201380506
Validation loss: 2.466104104382391

Epoch: 399| Step: 0
Training loss: 0.5087894139499146
Validation loss: 2.425082494290147

Epoch: 5| Step: 1
Training loss: 0.3655932697971541
Validation loss: 2.4391851093128327

Epoch: 5| Step: 2
Training loss: 0.5154369762811628
Validation loss: 2.444524153646272

Epoch: 5| Step: 3
Training loss: 0.5798495577678358
Validation loss: 2.4492877381925005

Epoch: 5| Step: 4
Training loss: 0.5236045513900193
Validation loss: 2.4516591822032017

Epoch: 5| Step: 5
Training loss: 0.3106169831413837
Validation loss: 2.4663944099399826

Epoch: 5| Step: 6
Training loss: 0.41857381501951973
Validation loss: 2.4353017431271478

Epoch: 5| Step: 7
Training loss: 0.28372075360772725
Validation loss: 2.4715273893540886

Epoch: 5| Step: 8
Training loss: 0.40657778500816544
Validation loss: 2.4640086969521238

Epoch: 5| Step: 9
Training loss: 0.33498720560977974
Validation loss: 2.47191134642429

Epoch: 5| Step: 10
Training loss: 0.4193382643345034
Validation loss: 2.4644784896763654

Epoch: 400| Step: 0
Training loss: 0.36604559662688047
Validation loss: 2.4652605350701546

Epoch: 5| Step: 1
Training loss: 0.3515593104747623
Validation loss: 2.4850678868500777

Epoch: 5| Step: 2
Training loss: 0.4874096682805859
Validation loss: 2.4746905093874814

Epoch: 5| Step: 3
Training loss: 0.49968319035163267
Validation loss: 2.49798960811991

Epoch: 5| Step: 4
Training loss: 0.40611396859574583
Validation loss: 2.4647555421524694

Epoch: 5| Step: 5
Training loss: 0.38633543341254845
Validation loss: 2.402234767839901

Epoch: 5| Step: 6
Training loss: 0.5694541219597121
Validation loss: 2.402722759947858

Epoch: 5| Step: 7
Training loss: 0.6085528917027184
Validation loss: 2.3834459011320517

Epoch: 5| Step: 8
Training loss: 0.45602714243008585
Validation loss: 2.3829267394090676

Epoch: 5| Step: 9
Training loss: 0.32760330007021027
Validation loss: 2.3933874784860905

Epoch: 5| Step: 10
Training loss: 0.2803224660277668
Validation loss: 2.443573945258806

Epoch: 401| Step: 0
Training loss: 0.5450786788826077
Validation loss: 2.4786323615484465

Epoch: 5| Step: 1
Training loss: 0.5986367952049407
Validation loss: 2.5018191333286155

Epoch: 5| Step: 2
Training loss: 0.31599083462533367
Validation loss: 2.4488050166286617

Epoch: 5| Step: 3
Training loss: 0.3494775406315929
Validation loss: 2.4332499456368644

Epoch: 5| Step: 4
Training loss: 0.419351838462914
Validation loss: 2.4190619659218706

Epoch: 5| Step: 5
Training loss: 0.36818597864948205
Validation loss: 2.440338106391142

Epoch: 5| Step: 6
Training loss: 0.5803774950629883
Validation loss: 2.4491227745729334

Epoch: 5| Step: 7
Training loss: 0.3837298476180706
Validation loss: 2.4853941837228373

Epoch: 5| Step: 8
Training loss: 0.5231885745158592
Validation loss: 2.4939906744726

Epoch: 5| Step: 9
Training loss: 0.44488392668897797
Validation loss: 2.5203227990029426

Epoch: 5| Step: 10
Training loss: 0.31234217473024534
Validation loss: 2.489812910303901

Epoch: 402| Step: 0
Training loss: 0.2594769673820247
Validation loss: 2.492482106262679

Epoch: 5| Step: 1
Training loss: 0.5749310597265231
Validation loss: 2.493019023146994

Epoch: 5| Step: 2
Training loss: 0.2357239369278508
Validation loss: 2.4896672360374117

Epoch: 5| Step: 3
Training loss: 0.5011836287680413
Validation loss: 2.473815591231461

Epoch: 5| Step: 4
Training loss: 0.5263797001244971
Validation loss: 2.474906272600901

Epoch: 5| Step: 5
Training loss: 0.34879653890181966
Validation loss: 2.431003559817005

Epoch: 5| Step: 6
Training loss: 0.40953669303179047
Validation loss: 2.474832595897194

Epoch: 5| Step: 7
Training loss: 0.5262775521756373
Validation loss: 2.4879675556183365

Epoch: 5| Step: 8
Training loss: 0.2822647068949491
Validation loss: 2.523734906695065

Epoch: 5| Step: 9
Training loss: 0.5824416844806817
Validation loss: 2.564832118872094

Epoch: 5| Step: 10
Training loss: 0.39036179258007675
Validation loss: 2.5140267432932317

Epoch: 403| Step: 0
Training loss: 0.16380557878784585
Validation loss: 2.521544246827453

Epoch: 5| Step: 1
Training loss: 0.2937072220557285
Validation loss: 2.5212457418326757

Epoch: 5| Step: 2
Training loss: 0.4497735619387193
Validation loss: 2.508998167986363

Epoch: 5| Step: 3
Training loss: 0.45482872608235125
Validation loss: 2.4962557471887896

Epoch: 5| Step: 4
Training loss: 0.34535317030421203
Validation loss: 2.4438131249498967

Epoch: 5| Step: 5
Training loss: 0.5699483675744187
Validation loss: 2.5120031436015533

Epoch: 5| Step: 6
Training loss: 0.27158308635947026
Validation loss: 2.497246244405349

Epoch: 5| Step: 7
Training loss: 0.41947837297459056
Validation loss: 2.5098967349277586

Epoch: 5| Step: 8
Training loss: 0.468453981390801
Validation loss: 2.478843775136787

Epoch: 5| Step: 9
Training loss: 0.5995046418513779
Validation loss: 2.49431184195497

Epoch: 5| Step: 10
Training loss: 0.3909417584718657
Validation loss: 2.523145767436914

Epoch: 404| Step: 0
Training loss: 0.36051288084914274
Validation loss: 2.480850559570128

Epoch: 5| Step: 1
Training loss: 0.31615833884093336
Validation loss: 2.492493064402447

Epoch: 5| Step: 2
Training loss: 0.4404368262547666
Validation loss: 2.485234554614928

Epoch: 5| Step: 3
Training loss: 0.5988445063252145
Validation loss: 2.4517930072745084

Epoch: 5| Step: 4
Training loss: 0.4391794327298574
Validation loss: 2.471133896454171

Epoch: 5| Step: 5
Training loss: 0.15774319751131433
Validation loss: 2.421822158919782

Epoch: 5| Step: 6
Training loss: 0.3905562149521308
Validation loss: 2.40874973876716

Epoch: 5| Step: 7
Training loss: 0.35190077507720147
Validation loss: 2.440302413956082

Epoch: 5| Step: 8
Training loss: 0.47562817145153685
Validation loss: 2.4047858081444247

Epoch: 5| Step: 9
Training loss: 0.44654298065643366
Validation loss: 2.4408359811547538

Epoch: 5| Step: 10
Training loss: 0.5606709784851485
Validation loss: 2.505480524182385

Epoch: 405| Step: 0
Training loss: 0.5047991626144633
Validation loss: 2.5034357816318047

Epoch: 5| Step: 1
Training loss: 0.29456346725201454
Validation loss: 2.5457268180280166

Epoch: 5| Step: 2
Training loss: 0.5449084755402008
Validation loss: 2.560671252079142

Epoch: 5| Step: 3
Training loss: 0.36326164274729195
Validation loss: 2.565894021411052

Epoch: 5| Step: 4
Training loss: 0.2417820181773401
Validation loss: 2.5026242902844134

Epoch: 5| Step: 5
Training loss: 0.4330248838370899
Validation loss: 2.3877351411739247

Epoch: 5| Step: 6
Training loss: 0.5942349461232287
Validation loss: 2.3570186096994727

Epoch: 5| Step: 7
Training loss: 0.4327092987579953
Validation loss: 2.3458130565257953

Epoch: 5| Step: 8
Training loss: 0.44367746042321793
Validation loss: 2.4314186078850075

Epoch: 5| Step: 9
Training loss: 0.46513258351328474
Validation loss: 2.4851855302921138

Epoch: 5| Step: 10
Training loss: 0.3772846009709063
Validation loss: 2.5328507086192333

Epoch: 406| Step: 0
Training loss: 0.546456476553311
Validation loss: 2.6142696978059266

Epoch: 5| Step: 1
Training loss: 0.41291062262403966
Validation loss: 2.564221102034925

Epoch: 5| Step: 2
Training loss: 0.43140859106548457
Validation loss: 2.494961095059397

Epoch: 5| Step: 3
Training loss: 0.23787782474901337
Validation loss: 2.4335202547202908

Epoch: 5| Step: 4
Training loss: 0.46320596247238405
Validation loss: 2.398159023091466

Epoch: 5| Step: 5
Training loss: 0.6226432712786554
Validation loss: 2.3063362643688086

Epoch: 5| Step: 6
Training loss: 0.45360615276077715
Validation loss: 2.3013388022251804

Epoch: 5| Step: 7
Training loss: 0.5283916657894393
Validation loss: 2.3729982278694672

Epoch: 5| Step: 8
Training loss: 0.5191044596065111
Validation loss: 2.4501394592952144

Epoch: 5| Step: 9
Training loss: 0.35533521051221156
Validation loss: 2.525096255043215

Epoch: 5| Step: 10
Training loss: 0.37049242791071374
Validation loss: 2.587003097668429

Epoch: 407| Step: 0
Training loss: 0.5444182115785237
Validation loss: 2.5796388101471286

Epoch: 5| Step: 1
Training loss: 0.6492015978662473
Validation loss: 2.550988734358606

Epoch: 5| Step: 2
Training loss: 0.3526456782624487
Validation loss: 2.525563501522024

Epoch: 5| Step: 3
Training loss: 0.20429554532203706
Validation loss: 2.4298657458516613

Epoch: 5| Step: 4
Training loss: 0.3856098575803104
Validation loss: 2.4733923611259803

Epoch: 5| Step: 5
Training loss: 0.3331146516319824
Validation loss: 2.4405503172391474

Epoch: 5| Step: 6
Training loss: 0.3766269359621161
Validation loss: 2.4753899793336918

Epoch: 5| Step: 7
Training loss: 0.3964211925656938
Validation loss: 2.524994015328678

Epoch: 5| Step: 8
Training loss: 0.5016511238685535
Validation loss: 2.5432230801726745

Epoch: 5| Step: 9
Training loss: 0.4735865304888093
Validation loss: 2.5969146861717047

Epoch: 5| Step: 10
Training loss: 0.37719137934070157
Validation loss: 2.5445378844848867

Epoch: 408| Step: 0
Training loss: 0.5659745774743417
Validation loss: 2.546014135601564

Epoch: 5| Step: 1
Training loss: 0.39356462641204104
Validation loss: 2.487966570540807

Epoch: 5| Step: 2
Training loss: 0.3264985076591245
Validation loss: 2.412308545820116

Epoch: 5| Step: 3
Training loss: 0.5290905032827429
Validation loss: 2.415458553498352

Epoch: 5| Step: 4
Training loss: 0.24553087743726276
Validation loss: 2.3660471692367495

Epoch: 5| Step: 5
Training loss: 0.2839544524494122
Validation loss: 2.3799715236436554

Epoch: 5| Step: 6
Training loss: 0.4526698687779108
Validation loss: 2.413692872577772

Epoch: 5| Step: 7
Training loss: 0.6301177776840687
Validation loss: 2.4334964082560426

Epoch: 5| Step: 8
Training loss: 0.3333172074033263
Validation loss: 2.520784281130774

Epoch: 5| Step: 9
Training loss: 0.38884671749879424
Validation loss: 2.53464513813093

Epoch: 5| Step: 10
Training loss: 0.26815660970601723
Validation loss: 2.5802390163520057

Epoch: 409| Step: 0
Training loss: 0.5609802537951639
Validation loss: 2.62927028547441

Epoch: 5| Step: 1
Training loss: 0.2887095668070125
Validation loss: 2.618962391365687

Epoch: 5| Step: 2
Training loss: 0.26945852597763925
Validation loss: 2.554008984594475

Epoch: 5| Step: 3
Training loss: 0.4446090864744643
Validation loss: 2.517056834655715

Epoch: 5| Step: 4
Training loss: 0.4896033583935309
Validation loss: 2.4613944149532507

Epoch: 5| Step: 5
Training loss: 0.4082513078060098
Validation loss: 2.4273849612181393

Epoch: 5| Step: 6
Training loss: 0.38079406960892337
Validation loss: 2.368240138105742

Epoch: 5| Step: 7
Training loss: 0.5762312260463636
Validation loss: 2.3683811571913513

Epoch: 5| Step: 8
Training loss: 0.4240510591553328
Validation loss: 2.379641026229654

Epoch: 5| Step: 9
Training loss: 0.2345917017806513
Validation loss: 2.396271354650365

Epoch: 5| Step: 10
Training loss: 0.3838013120448421
Validation loss: 2.4551187385402096

Epoch: 410| Step: 0
Training loss: 0.42676098994767836
Validation loss: 2.4934981181991627

Epoch: 5| Step: 1
Training loss: 0.37501456311876086
Validation loss: 2.5255113037091457

Epoch: 5| Step: 2
Training loss: 0.4232583501006766
Validation loss: 2.5109404487790874

Epoch: 5| Step: 3
Training loss: 0.2017785526040399
Validation loss: 2.481422492752798

Epoch: 5| Step: 4
Training loss: 0.49296979949404185
Validation loss: 2.4350222722504036

Epoch: 5| Step: 5
Training loss: 0.37288254718514924
Validation loss: 2.444749135275303

Epoch: 5| Step: 6
Training loss: 0.3818943535103894
Validation loss: 2.4331583150260867

Epoch: 5| Step: 7
Training loss: 0.4590673006506562
Validation loss: 2.417067081587489

Epoch: 5| Step: 8
Training loss: 0.39086973153331156
Validation loss: 2.4205424537937916

Epoch: 5| Step: 9
Training loss: 0.5862262777152943
Validation loss: 2.4415973143272534

Epoch: 5| Step: 10
Training loss: 0.34474359313566244
Validation loss: 2.4645890560209747

Epoch: 411| Step: 0
Training loss: 0.4197984203461109
Validation loss: 2.5205800854616958

Epoch: 5| Step: 1
Training loss: 0.4478886858014669
Validation loss: 2.4910827023059134

Epoch: 5| Step: 2
Training loss: 0.23976888761913936
Validation loss: 2.5085437071436782

Epoch: 5| Step: 3
Training loss: 0.39880189874784355
Validation loss: 2.4812666944336486

Epoch: 5| Step: 4
Training loss: 0.29100540962467397
Validation loss: 2.4712643782038732

Epoch: 5| Step: 5
Training loss: 0.5421564626467382
Validation loss: 2.4398154994813535

Epoch: 5| Step: 6
Training loss: 0.37958130234357473
Validation loss: 2.4551283159450317

Epoch: 5| Step: 7
Training loss: 0.4387961159893696
Validation loss: 2.430742264142738

Epoch: 5| Step: 8
Training loss: 0.3291509121532918
Validation loss: 2.43288769755108

Epoch: 5| Step: 9
Training loss: 0.4536537012789487
Validation loss: 2.4672082012083485

Epoch: 5| Step: 10
Training loss: 0.487379370338861
Validation loss: 2.4644457012017607

Epoch: 412| Step: 0
Training loss: 0.3584699845165152
Validation loss: 2.463219451662485

Epoch: 5| Step: 1
Training loss: 0.39231645584117525
Validation loss: 2.481544279670395

Epoch: 5| Step: 2
Training loss: 0.401679258775728
Validation loss: 2.4985081784885943

Epoch: 5| Step: 3
Training loss: 0.4456872032858899
Validation loss: 2.461955569169906

Epoch: 5| Step: 4
Training loss: 0.4812261767497705
Validation loss: 2.449021481823374

Epoch: 5| Step: 5
Training loss: 0.33242950116923053
Validation loss: 2.428574001625079

Epoch: 5| Step: 6
Training loss: 0.4736497227117773
Validation loss: 2.4240707885874775

Epoch: 5| Step: 7
Training loss: 0.4486706914924318
Validation loss: 2.4304730278766975

Epoch: 5| Step: 8
Training loss: 0.17061534868268952
Validation loss: 2.3982727484812045

Epoch: 5| Step: 9
Training loss: 0.5191839103937419
Validation loss: 2.415532608408066

Epoch: 5| Step: 10
Training loss: 0.45784683489370465
Validation loss: 2.4277452822001093

Epoch: 413| Step: 0
Training loss: 0.40099099900186985
Validation loss: 2.503703310350351

Epoch: 5| Step: 1
Training loss: 0.3101204157194094
Validation loss: 2.552039109919007

Epoch: 5| Step: 2
Training loss: 0.3909672572872976
Validation loss: 2.5665552239608127

Epoch: 5| Step: 3
Training loss: 0.34908167476461904
Validation loss: 2.5979736548708385

Epoch: 5| Step: 4
Training loss: 0.31542547122747483
Validation loss: 2.601048937771322

Epoch: 5| Step: 5
Training loss: 0.3852179526219208
Validation loss: 2.609396886951756

Epoch: 5| Step: 6
Training loss: 0.46835930755080246
Validation loss: 2.5447303171584355

Epoch: 5| Step: 7
Training loss: 0.3345830693348801
Validation loss: 2.496749971148583

Epoch: 5| Step: 8
Training loss: 0.5888415531886158
Validation loss: 2.451369909256619

Epoch: 5| Step: 9
Training loss: 0.39355680782229696
Validation loss: 2.4629719070626974

Epoch: 5| Step: 10
Training loss: 0.5087078417713332
Validation loss: 2.4223916636954135

Epoch: 414| Step: 0
Training loss: 0.5257334104996161
Validation loss: 2.43155926346191

Epoch: 5| Step: 1
Training loss: 0.4402870234746433
Validation loss: 2.465593111155954

Epoch: 5| Step: 2
Training loss: 0.43586705503451306
Validation loss: 2.4936573715045385

Epoch: 5| Step: 3
Training loss: 0.42021998979208713
Validation loss: 2.5139452967727323

Epoch: 5| Step: 4
Training loss: 0.41378278101112137
Validation loss: 2.558291327801809

Epoch: 5| Step: 5
Training loss: 0.4659591244055215
Validation loss: 2.5251759490045838

Epoch: 5| Step: 6
Training loss: 0.22431760994401823
Validation loss: 2.500620555769012

Epoch: 5| Step: 7
Training loss: 0.38152224247888716
Validation loss: 2.494531647762663

Epoch: 5| Step: 8
Training loss: 0.33723409076278016
Validation loss: 2.4091076416821697

Epoch: 5| Step: 9
Training loss: 0.3206763410825546
Validation loss: 2.3870813699721087

Epoch: 5| Step: 10
Training loss: 0.5023503197793596
Validation loss: 2.4157105737399522

Epoch: 415| Step: 0
Training loss: 0.46668109495417387
Validation loss: 2.4367005767669045

Epoch: 5| Step: 1
Training loss: 0.4579832643872412
Validation loss: 2.449615254347855

Epoch: 5| Step: 2
Training loss: 0.3686663492333895
Validation loss: 2.5002816215962467

Epoch: 5| Step: 3
Training loss: 0.4629119514027181
Validation loss: 2.487701460253765

Epoch: 5| Step: 4
Training loss: 0.28416052160489313
Validation loss: 2.511438669171869

Epoch: 5| Step: 5
Training loss: 0.38979398069539267
Validation loss: 2.5900677051596066

Epoch: 5| Step: 6
Training loss: 0.5049762750000361
Validation loss: 2.5302299450528656

Epoch: 5| Step: 7
Training loss: 0.4681782096090748
Validation loss: 2.4873028920369746

Epoch: 5| Step: 8
Training loss: 0.4113305492999879
Validation loss: 2.4747509528703673

Epoch: 5| Step: 9
Training loss: 0.14785775734787396
Validation loss: 2.528163296416955

Epoch: 5| Step: 10
Training loss: 0.26833456554978946
Validation loss: 2.528346490024789

Epoch: 416| Step: 0
Training loss: 0.45636098569982214
Validation loss: 2.4931692490780155

Epoch: 5| Step: 1
Training loss: 0.470372760752169
Validation loss: 2.4766812942846466

Epoch: 5| Step: 2
Training loss: 0.1914376213678616
Validation loss: 2.4783398328406085

Epoch: 5| Step: 3
Training loss: 0.1488900438798382
Validation loss: 2.4539239795985868

Epoch: 5| Step: 4
Training loss: 0.47977457840414817
Validation loss: 2.474960487549999

Epoch: 5| Step: 5
Training loss: 0.4786326518300175
Validation loss: 2.4645534154767974

Epoch: 5| Step: 6
Training loss: 0.2383912098548557
Validation loss: 2.514059668275845

Epoch: 5| Step: 7
Training loss: 0.32087568456653287
Validation loss: 2.5373795760869324

Epoch: 5| Step: 8
Training loss: 0.2874254835005436
Validation loss: 2.544677564493403

Epoch: 5| Step: 9
Training loss: 0.46297565113888844
Validation loss: 2.533194382183662

Epoch: 5| Step: 10
Training loss: 0.5281910341501405
Validation loss: 2.4984874025664445

Epoch: 417| Step: 0
Training loss: 0.3249408310434953
Validation loss: 2.507980494903198

Epoch: 5| Step: 1
Training loss: 0.4272837943745759
Validation loss: 2.478184415893817

Epoch: 5| Step: 2
Training loss: 0.2249291672738515
Validation loss: 2.464831095284794

Epoch: 5| Step: 3
Training loss: 0.3821046863955384
Validation loss: 2.4590475700513936

Epoch: 5| Step: 4
Training loss: 0.308278755993816
Validation loss: 2.4577427761841784

Epoch: 5| Step: 5
Training loss: 0.48738222900414396
Validation loss: 2.4190649613497976

Epoch: 5| Step: 6
Training loss: 0.37418328198766204
Validation loss: 2.4501415142754226

Epoch: 5| Step: 7
Training loss: 0.47136488176956143
Validation loss: 2.491093488563352

Epoch: 5| Step: 8
Training loss: 0.2076987177333086
Validation loss: 2.510154630451382

Epoch: 5| Step: 9
Training loss: 0.3093389856203016
Validation loss: 2.5272202722874053

Epoch: 5| Step: 10
Training loss: 0.6401204937145134
Validation loss: 2.5740376309369717

Epoch: 418| Step: 0
Training loss: 0.3624364813698053
Validation loss: 2.5396883002917257

Epoch: 5| Step: 1
Training loss: 0.28164950448058124
Validation loss: 2.4970265682143737

Epoch: 5| Step: 2
Training loss: 0.5666232515514704
Validation loss: 2.471515764125851

Epoch: 5| Step: 3
Training loss: 0.32323606779177383
Validation loss: 2.5069438697722553

Epoch: 5| Step: 4
Training loss: 0.32997493146555623
Validation loss: 2.4872562755088534

Epoch: 5| Step: 5
Training loss: 0.4599769087365322
Validation loss: 2.4815198667713996

Epoch: 5| Step: 6
Training loss: 0.29130331323014924
Validation loss: 2.552384365091892

Epoch: 5| Step: 7
Training loss: 0.36603934782129965
Validation loss: 2.4949286511877435

Epoch: 5| Step: 8
Training loss: 0.37294801930097077
Validation loss: 2.5287716378661083

Epoch: 5| Step: 9
Training loss: 0.3227489430656236
Validation loss: 2.4916270474480338

Epoch: 5| Step: 10
Training loss: 0.532779287606386
Validation loss: 2.5177125334764576

Epoch: 419| Step: 0
Training loss: 0.2201154446469404
Validation loss: 2.5036762700108617

Epoch: 5| Step: 1
Training loss: 0.6034778965882116
Validation loss: 2.4911146935445028

Epoch: 5| Step: 2
Training loss: 0.4472801839133096
Validation loss: 2.4837532547603054

Epoch: 5| Step: 3
Training loss: 0.12816202745156105
Validation loss: 2.4718506208928095

Epoch: 5| Step: 4
Training loss: 0.46273875260041475
Validation loss: 2.516723625777503

Epoch: 5| Step: 5
Training loss: 0.4598379436389468
Validation loss: 2.4913078476386743

Epoch: 5| Step: 6
Training loss: 0.4226116530604909
Validation loss: 2.5048826252073044

Epoch: 5| Step: 7
Training loss: 0.41982323131103527
Validation loss: 2.5079173826225047

Epoch: 5| Step: 8
Training loss: 0.30076542106691656
Validation loss: 2.468955263405549

Epoch: 5| Step: 9
Training loss: 0.1691191556136418
Validation loss: 2.4825219897840447

Epoch: 5| Step: 10
Training loss: 0.29115789891163285
Validation loss: 2.488205110720504

Epoch: 420| Step: 0
Training loss: 0.30117843462458893
Validation loss: 2.456793951159057

Epoch: 5| Step: 1
Training loss: 0.4035225423568927
Validation loss: 2.4893823225775487

Epoch: 5| Step: 2
Training loss: 0.44469145919849484
Validation loss: 2.469979962812402

Epoch: 5| Step: 3
Training loss: 0.4079940479489544
Validation loss: 2.531407322888325

Epoch: 5| Step: 4
Training loss: 0.4589420380241355
Validation loss: 2.5317778589558015

Epoch: 5| Step: 5
Training loss: 0.3698314882606037
Validation loss: 2.492931959286347

Epoch: 5| Step: 6
Training loss: 0.11497677685820726
Validation loss: 2.5077508681078555

Epoch: 5| Step: 7
Training loss: 0.23981291544771136
Validation loss: 2.4905832014244567

Epoch: 5| Step: 8
Training loss: 0.4195662123392141
Validation loss: 2.461593602452163

Epoch: 5| Step: 9
Training loss: 0.40987950025474584
Validation loss: 2.4849247354204405

Epoch: 5| Step: 10
Training loss: 0.5025702812618097
Validation loss: 2.476206942258671

Epoch: 421| Step: 0
Training loss: 0.39080384928482614
Validation loss: 2.498936993192365

Epoch: 5| Step: 1
Training loss: 0.5341453192497487
Validation loss: 2.4948770619479435

Epoch: 5| Step: 2
Training loss: 0.345594539938425
Validation loss: 2.540467738669121

Epoch: 5| Step: 3
Training loss: 0.25049662436706405
Validation loss: 2.539623301174872

Epoch: 5| Step: 4
Training loss: 0.4204508798261372
Validation loss: 2.525109809803431

Epoch: 5| Step: 5
Training loss: 0.3279398781952106
Validation loss: 2.55340205450161

Epoch: 5| Step: 6
Training loss: 0.29319091003002723
Validation loss: 2.5231320149173704

Epoch: 5| Step: 7
Training loss: 0.44161492875398317
Validation loss: 2.556748756973468

Epoch: 5| Step: 8
Training loss: 0.43744567125048983
Validation loss: 2.5175362013898805

Epoch: 5| Step: 9
Training loss: 0.28558847252231073
Validation loss: 2.503407677476292

Epoch: 5| Step: 10
Training loss: 0.44752604803004487
Validation loss: 2.482126087071827

Epoch: 422| Step: 0
Training loss: 0.381058802110756
Validation loss: 2.5301139649162567

Epoch: 5| Step: 1
Training loss: 0.24287632689994582
Validation loss: 2.5679061212092344

Epoch: 5| Step: 2
Training loss: 0.4536583491050369
Validation loss: 2.52138678640509

Epoch: 5| Step: 3
Training loss: 0.4464449453757073
Validation loss: 2.5628604590372634

Epoch: 5| Step: 4
Training loss: 0.466327686817681
Validation loss: 2.5130275737492043

Epoch: 5| Step: 5
Training loss: 0.36680378039017686
Validation loss: 2.486645849013697

Epoch: 5| Step: 6
Training loss: 0.37332003513703876
Validation loss: 2.5050804552909285

Epoch: 5| Step: 7
Training loss: 0.35868649249575946
Validation loss: 2.4875432437430276

Epoch: 5| Step: 8
Training loss: 0.19774224517726174
Validation loss: 2.452846856459265

Epoch: 5| Step: 9
Training loss: 0.29613348309292914
Validation loss: 2.482102782979622

Epoch: 5| Step: 10
Training loss: 0.44118041616433246
Validation loss: 2.4867431432417217

Epoch: 423| Step: 0
Training loss: 0.2825219479618027
Validation loss: 2.4838896845120506

Epoch: 5| Step: 1
Training loss: 0.304169201785893
Validation loss: 2.4719049583453163

Epoch: 5| Step: 2
Training loss: 0.3799538435636022
Validation loss: 2.4896914640170156

Epoch: 5| Step: 3
Training loss: 0.40501673278268574
Validation loss: 2.5292683649065744

Epoch: 5| Step: 4
Training loss: 0.34259813395998
Validation loss: 2.48213535111844

Epoch: 5| Step: 5
Training loss: 0.3558186915033337
Validation loss: 2.4919626957057766

Epoch: 5| Step: 6
Training loss: 0.3450206550344461
Validation loss: 2.4621524877488645

Epoch: 5| Step: 7
Training loss: 0.37202877904206766
Validation loss: 2.4512752291370257

Epoch: 5| Step: 8
Training loss: 0.5038970532428225
Validation loss: 2.4866763014214843

Epoch: 5| Step: 9
Training loss: 0.47168655864378517
Validation loss: 2.469361719202112

Epoch: 5| Step: 10
Training loss: 0.35836101617264743
Validation loss: 2.511666385415642

Epoch: 424| Step: 0
Training loss: 0.4424348510046413
Validation loss: 2.5485056575279623

Epoch: 5| Step: 1
Training loss: 0.3186148688971832
Validation loss: 2.549801681273658

Epoch: 5| Step: 2
Training loss: 0.3296890222595651
Validation loss: 2.5403748110063358

Epoch: 5| Step: 3
Training loss: 0.40964672592793483
Validation loss: 2.5540853757093265

Epoch: 5| Step: 4
Training loss: 0.2738218331260332
Validation loss: 2.543826560429699

Epoch: 5| Step: 5
Training loss: 0.3636613313680997
Validation loss: 2.499824137295973

Epoch: 5| Step: 6
Training loss: 0.2779521313824897
Validation loss: 2.463160770367174

Epoch: 5| Step: 7
Training loss: 0.2832065450527597
Validation loss: 2.507532813029343

Epoch: 5| Step: 8
Training loss: 0.49041307087727615
Validation loss: 2.4592008777123464

Epoch: 5| Step: 9
Training loss: 0.3724090956169233
Validation loss: 2.5188357195187527

Epoch: 5| Step: 10
Training loss: 0.396947336738427
Validation loss: 2.5512705682539565

Epoch: 425| Step: 0
Training loss: 0.1896848735910303
Validation loss: 2.528969303770741

Epoch: 5| Step: 1
Training loss: 0.3436639851546606
Validation loss: 2.5695988678989936

Epoch: 5| Step: 2
Training loss: 0.34583106609926484
Validation loss: 2.5513122404919586

Epoch: 5| Step: 3
Training loss: 0.361851287684219
Validation loss: 2.5936913462042503

Epoch: 5| Step: 4
Training loss: 0.28270132398150255
Validation loss: 2.558131014779254

Epoch: 5| Step: 5
Training loss: 0.5272245201675552
Validation loss: 2.5183025264204173

Epoch: 5| Step: 6
Training loss: 0.12728255884606027
Validation loss: 2.504958661820084

Epoch: 5| Step: 7
Training loss: 0.4060729814879086
Validation loss: 2.5252010576093924

Epoch: 5| Step: 8
Training loss: 0.34552357208037493
Validation loss: 2.527486910923198

Epoch: 5| Step: 9
Training loss: 0.3300285527852612
Validation loss: 2.526139492876187

Epoch: 5| Step: 10
Training loss: 0.5290982200880291
Validation loss: 2.5212934594949803

Epoch: 426| Step: 0
Training loss: 0.17431815865113992
Validation loss: 2.5195333114683

Epoch: 5| Step: 1
Training loss: 0.3074455509011837
Validation loss: 2.539170035710996

Epoch: 5| Step: 2
Training loss: 0.2873303866740554
Validation loss: 2.5032421951129584

Epoch: 5| Step: 3
Training loss: 0.6201956631723801
Validation loss: 2.5124711735552836

Epoch: 5| Step: 4
Training loss: 0.3243944197741867
Validation loss: 2.486666645003147

Epoch: 5| Step: 5
Training loss: 0.2858685259150587
Validation loss: 2.502466577514862

Epoch: 5| Step: 6
Training loss: 0.3530091087095476
Validation loss: 2.4914898133188195

Epoch: 5| Step: 7
Training loss: 0.33382678636264207
Validation loss: 2.4807127783687726

Epoch: 5| Step: 8
Training loss: 0.36658141660539695
Validation loss: 2.5153526403804722

Epoch: 5| Step: 9
Training loss: 0.3376241195233646
Validation loss: 2.4901129811839002

Epoch: 5| Step: 10
Training loss: 0.33742686512413167
Validation loss: 2.523362213244001

Epoch: 427| Step: 0
Training loss: 0.38505127271232104
Validation loss: 2.4909290519835796

Epoch: 5| Step: 1
Training loss: 0.19304691461356607
Validation loss: 2.5289964097151687

Epoch: 5| Step: 2
Training loss: 0.17767191407690774
Validation loss: 2.5271313195368332

Epoch: 5| Step: 3
Training loss: 0.4501228025881186
Validation loss: 2.5346053376675326

Epoch: 5| Step: 4
Training loss: 0.43734694255877915
Validation loss: 2.5054636104118195

Epoch: 5| Step: 5
Training loss: 0.27533848586834003
Validation loss: 2.509036178884133

Epoch: 5| Step: 6
Training loss: 0.36675474353497206
Validation loss: 2.513942887060105

Epoch: 5| Step: 7
Training loss: 0.38455787123224433
Validation loss: 2.504317003909746

Epoch: 5| Step: 8
Training loss: 0.43082141380435623
Validation loss: 2.46482749865872

Epoch: 5| Step: 9
Training loss: 0.25597923325149974
Validation loss: 2.5039414873085444

Epoch: 5| Step: 10
Training loss: 0.43221055460994395
Validation loss: 2.522790208425391

Epoch: 428| Step: 0
Training loss: 0.3694106028030672
Validation loss: 2.51764458119809

Epoch: 5| Step: 1
Training loss: 0.2590413573165412
Validation loss: 2.527933332714441

Epoch: 5| Step: 2
Training loss: 0.3298900226281627
Validation loss: 2.528076021159169

Epoch: 5| Step: 3
Training loss: 0.43402344659127734
Validation loss: 2.584342880020654

Epoch: 5| Step: 4
Training loss: 0.4097969661396484
Validation loss: 2.55373216312492

Epoch: 5| Step: 5
Training loss: 0.1742706505912633
Validation loss: 2.5087741330259803

Epoch: 5| Step: 6
Training loss: 0.33956453757935945
Validation loss: 2.513763747062311

Epoch: 5| Step: 7
Training loss: 0.43673485878048274
Validation loss: 2.4708006081202623

Epoch: 5| Step: 8
Training loss: 0.29791705552767117
Validation loss: 2.4580101341611966

Epoch: 5| Step: 9
Training loss: 0.35392337277655334
Validation loss: 2.4643826950300265

Epoch: 5| Step: 10
Training loss: 0.5068683650644391
Validation loss: 2.48505737567257

Epoch: 429| Step: 0
Training loss: 0.30406710234057205
Validation loss: 2.5427747435404098

Epoch: 5| Step: 1
Training loss: 0.25495029886059506
Validation loss: 2.513357663341893

Epoch: 5| Step: 2
Training loss: 0.17770889644563398
Validation loss: 2.5690041561056765

Epoch: 5| Step: 3
Training loss: 0.3797888161445374
Validation loss: 2.6264515373013806

Epoch: 5| Step: 4
Training loss: 0.24467251630679912
Validation loss: 2.5750776192578804

Epoch: 5| Step: 5
Training loss: 0.2562545607323797
Validation loss: 2.5580651122985816

Epoch: 5| Step: 6
Training loss: 0.46726261032706096
Validation loss: 2.5219151057097786

Epoch: 5| Step: 7
Training loss: 0.4217711426795107
Validation loss: 2.4898444226013963

Epoch: 5| Step: 8
Training loss: 0.4256674238171835
Validation loss: 2.500743871174489

Epoch: 5| Step: 9
Training loss: 0.5296745782586992
Validation loss: 2.4731256304863947

Epoch: 5| Step: 10
Training loss: 0.2756405636335566
Validation loss: 2.4722306748862084

Epoch: 430| Step: 0
Training loss: 0.32835881667233763
Validation loss: 2.4956245331187894

Epoch: 5| Step: 1
Training loss: 0.2920281888781966
Validation loss: 2.471438531598202

Epoch: 5| Step: 2
Training loss: 0.2882381877422627
Validation loss: 2.5269366802512727

Epoch: 5| Step: 3
Training loss: 0.2786281823720552
Validation loss: 2.5104161931696427

Epoch: 5| Step: 4
Training loss: 0.2900872752387456
Validation loss: 2.5695211081933125

Epoch: 5| Step: 5
Training loss: 0.509905185815012
Validation loss: 2.5497015045459372

Epoch: 5| Step: 6
Training loss: 0.3772985032401487
Validation loss: 2.535059768183496

Epoch: 5| Step: 7
Training loss: 0.4119813548470831
Validation loss: 2.497073637847487

Epoch: 5| Step: 8
Training loss: 0.3826946544261919
Validation loss: 2.494099794258005

Epoch: 5| Step: 9
Training loss: 0.33712741896341764
Validation loss: 2.480118846235489

Epoch: 5| Step: 10
Training loss: 0.341319628361139
Validation loss: 2.4573515643083508

Epoch: 431| Step: 0
Training loss: 0.27566474096066884
Validation loss: 2.4621066523290036

Epoch: 5| Step: 1
Training loss: 0.3445073584406028
Validation loss: 2.436066832229481

Epoch: 5| Step: 2
Training loss: 0.40828271482360357
Validation loss: 2.4844682216406597

Epoch: 5| Step: 3
Training loss: 0.41009971592336814
Validation loss: 2.505471592538823

Epoch: 5| Step: 4
Training loss: 0.45261765720760844
Validation loss: 2.5013809389396244

Epoch: 5| Step: 5
Training loss: 0.3266709558272662
Validation loss: 2.5551656753615695

Epoch: 5| Step: 6
Training loss: 0.21888213764787437
Validation loss: 2.5700069669419436

Epoch: 5| Step: 7
Training loss: 0.48602938381306
Validation loss: 2.5986752311594747

Epoch: 5| Step: 8
Training loss: 0.3681379556885759
Validation loss: 2.585320337388662

Epoch: 5| Step: 9
Training loss: 0.34106041176107565
Validation loss: 2.5266898717839306

Epoch: 5| Step: 10
Training loss: 0.24781268621295796
Validation loss: 2.4727330593360426

Epoch: 432| Step: 0
Training loss: 0.4421162423185105
Validation loss: 2.458127753781679

Epoch: 5| Step: 1
Training loss: 0.34309564428399814
Validation loss: 2.425007245165336

Epoch: 5| Step: 2
Training loss: 0.3811726968595726
Validation loss: 2.440199319447195

Epoch: 5| Step: 3
Training loss: 0.334413598408626
Validation loss: 2.4595742351770506

Epoch: 5| Step: 4
Training loss: 0.43715967838307285
Validation loss: 2.516288305552331

Epoch: 5| Step: 5
Training loss: 0.3800929059783966
Validation loss: 2.564910747122866

Epoch: 5| Step: 6
Training loss: 0.2587253276146855
Validation loss: 2.574626292999178

Epoch: 5| Step: 7
Training loss: 0.20297842973235156
Validation loss: 2.59135768397628

Epoch: 5| Step: 8
Training loss: 0.392896475696219
Validation loss: 2.5875441212315797

Epoch: 5| Step: 9
Training loss: 0.4138028392300705
Validation loss: 2.5725484578490163

Epoch: 5| Step: 10
Training loss: 0.31067416143628807
Validation loss: 2.5529892445990954

Epoch: 433| Step: 0
Training loss: 0.27709735079613684
Validation loss: 2.515104246674763

Epoch: 5| Step: 1
Training loss: 0.3074410797286076
Validation loss: 2.4887489954189688

Epoch: 5| Step: 2
Training loss: 0.44947618488665025
Validation loss: 2.4705066529346467

Epoch: 5| Step: 3
Training loss: 0.25841630685021194
Validation loss: 2.5038071141578135

Epoch: 5| Step: 4
Training loss: 0.26871103070747276
Validation loss: 2.486103037071748

Epoch: 5| Step: 5
Training loss: 0.4002994712716508
Validation loss: 2.4738960335124283

Epoch: 5| Step: 6
Training loss: 0.4842995923318827
Validation loss: 2.5280698556190746

Epoch: 5| Step: 7
Training loss: 0.3142218598259791
Validation loss: 2.5335250934385147

Epoch: 5| Step: 8
Training loss: 0.14938479492163273
Validation loss: 2.541152280388592

Epoch: 5| Step: 9
Training loss: 0.42861393415462595
Validation loss: 2.521491581492746

Epoch: 5| Step: 10
Training loss: 0.30929605025730467
Validation loss: 2.5722773575008904

Epoch: 434| Step: 0
Training loss: 0.4804381384053163
Validation loss: 2.6154259954419703

Epoch: 5| Step: 1
Training loss: 0.36095334798525996
Validation loss: 2.548257067875444

Epoch: 5| Step: 2
Training loss: 0.3110441389238987
Validation loss: 2.540092712858411

Epoch: 5| Step: 3
Training loss: 0.5158163062578857
Validation loss: 2.4645890305363216

Epoch: 5| Step: 4
Training loss: 0.33867584894966113
Validation loss: 2.450181093234641

Epoch: 5| Step: 5
Training loss: 0.22789590711098698
Validation loss: 2.4403669253232825

Epoch: 5| Step: 6
Training loss: 0.3064101257935014
Validation loss: 2.3965000981429694

Epoch: 5| Step: 7
Training loss: 0.3327095172389653
Validation loss: 2.3942868362043965

Epoch: 5| Step: 8
Training loss: 0.19801841283024887
Validation loss: 2.4149319515714383

Epoch: 5| Step: 9
Training loss: 0.3925583108485022
Validation loss: 2.4729249667561324

Epoch: 5| Step: 10
Training loss: 0.24829417388917857
Validation loss: 2.481958775712952

Epoch: 435| Step: 0
Training loss: 0.35410699855968314
Validation loss: 2.5115695947931505

Epoch: 5| Step: 1
Training loss: 0.20337321631113042
Validation loss: 2.5062420576267037

Epoch: 5| Step: 2
Training loss: 0.37997817776787635
Validation loss: 2.5147064270475887

Epoch: 5| Step: 3
Training loss: 0.17340850007691877
Validation loss: 2.512374834344729

Epoch: 5| Step: 4
Training loss: 0.2984414060446881
Validation loss: 2.4914596728722014

Epoch: 5| Step: 5
Training loss: 0.47249775585771914
Validation loss: 2.4969122769021435

Epoch: 5| Step: 6
Training loss: 0.44037490808560154
Validation loss: 2.4947700356115097

Epoch: 5| Step: 7
Training loss: 0.22921614582374086
Validation loss: 2.4566629450254154

Epoch: 5| Step: 8
Training loss: 0.16628447249648173
Validation loss: 2.4495617113060453

Epoch: 5| Step: 9
Training loss: 0.3035941190614288
Validation loss: 2.4420053469406775

Epoch: 5| Step: 10
Training loss: 0.4761105254585248
Validation loss: 2.4645677507594237

Epoch: 436| Step: 0
Training loss: 0.5223804162267939
Validation loss: 2.4688730454535173

Epoch: 5| Step: 1
Training loss: 0.24620746074474975
Validation loss: 2.4866039874270935

Epoch: 5| Step: 2
Training loss: 0.1776462273467153
Validation loss: 2.5233504006238063

Epoch: 5| Step: 3
Training loss: 0.3282375823749625
Validation loss: 2.52130717501641

Epoch: 5| Step: 4
Training loss: 0.2893185641250068
Validation loss: 2.5192385084450164

Epoch: 5| Step: 5
Training loss: 0.2914745245715592
Validation loss: 2.5314483073691303

Epoch: 5| Step: 6
Training loss: 0.45986537386065107
Validation loss: 2.5027745632256773

Epoch: 5| Step: 7
Training loss: 0.2817383473625965
Validation loss: 2.4502232485646913

Epoch: 5| Step: 8
Training loss: 0.48250677929202135
Validation loss: 2.480889642928118

Epoch: 5| Step: 9
Training loss: 0.21739682531991095
Validation loss: 2.416781241537188

Epoch: 5| Step: 10
Training loss: 0.25524343359512464
Validation loss: 2.453163593428359

Epoch: 437| Step: 0
Training loss: 0.2048116496734615
Validation loss: 2.468955924834652

Epoch: 5| Step: 1
Training loss: 0.47385273969324576
Validation loss: 2.493880423768978

Epoch: 5| Step: 2
Training loss: 0.29410776610816725
Validation loss: 2.5350755399674507

Epoch: 5| Step: 3
Training loss: 0.3778908879671726
Validation loss: 2.5491560769033543

Epoch: 5| Step: 4
Training loss: 0.2192536669389696
Validation loss: 2.5357057455062697

Epoch: 5| Step: 5
Training loss: 0.3690698545726066
Validation loss: 2.5068696645972284

Epoch: 5| Step: 6
Training loss: 0.4634346963562277
Validation loss: 2.492863092934241

Epoch: 5| Step: 7
Training loss: 0.450145478707293
Validation loss: 2.4808956637658772

Epoch: 5| Step: 8
Training loss: 0.308919095306293
Validation loss: 2.496582425050842

Epoch: 5| Step: 9
Training loss: 0.2506834017519184
Validation loss: 2.4955475145783867

Epoch: 5| Step: 10
Training loss: 0.10254401694544549
Validation loss: 2.483000398955

Epoch: 438| Step: 0
Training loss: 0.3164818991190149
Validation loss: 2.5293000029009547

Epoch: 5| Step: 1
Training loss: 0.36687628766927294
Validation loss: 2.5197619052221687

Epoch: 5| Step: 2
Training loss: 0.28996658704090555
Validation loss: 2.4892355072259673

Epoch: 5| Step: 3
Training loss: 0.2762994851803065
Validation loss: 2.472690144709477

Epoch: 5| Step: 4
Training loss: 0.3459908317318675
Validation loss: 2.443226364965553

Epoch: 5| Step: 5
Training loss: 0.35959539704108473
Validation loss: 2.4431226781984643

Epoch: 5| Step: 6
Training loss: 0.5306790032106979
Validation loss: 2.417491560602885

Epoch: 5| Step: 7
Training loss: 0.22166061319305275
Validation loss: 2.449484835261921

Epoch: 5| Step: 8
Training loss: 0.33240941895077786
Validation loss: 2.4808920532283487

Epoch: 5| Step: 9
Training loss: 0.26404378587669847
Validation loss: 2.4877182691039446

Epoch: 5| Step: 10
Training loss: 0.3167759066414535
Validation loss: 2.5171752526896385

Epoch: 439| Step: 0
Training loss: 0.3004914039050366
Validation loss: 2.5354462573427794

Epoch: 5| Step: 1
Training loss: 0.3966504956336455
Validation loss: 2.5662539952288013

Epoch: 5| Step: 2
Training loss: 0.22868002170325766
Validation loss: 2.551385577114455

Epoch: 5| Step: 3
Training loss: 0.2284977408689762
Validation loss: 2.5681611881300834

Epoch: 5| Step: 4
Training loss: 0.17841293419727855
Validation loss: 2.548372011034899

Epoch: 5| Step: 5
Training loss: 0.25241168380278145
Validation loss: 2.5225101027690937

Epoch: 5| Step: 6
Training loss: 0.5331432602361312
Validation loss: 2.525421601995571

Epoch: 5| Step: 7
Training loss: 0.4124801558720928
Validation loss: 2.484013340271951

Epoch: 5| Step: 8
Training loss: 0.1780700239036001
Validation loss: 2.4993388460480825

Epoch: 5| Step: 9
Training loss: 0.2850769925689577
Validation loss: 2.5361232776737355

Epoch: 5| Step: 10
Training loss: 0.47927708666554497
Validation loss: 2.529342343717549

Epoch: 440| Step: 0
Training loss: 0.3610299607125699
Validation loss: 2.594574975120817

Epoch: 5| Step: 1
Training loss: 0.3170336284332024
Validation loss: 2.52858993704887

Epoch: 5| Step: 2
Training loss: 0.3972288761752396
Validation loss: 2.560311235804902

Epoch: 5| Step: 3
Training loss: 0.3700083670765533
Validation loss: 2.5520065714626496

Epoch: 5| Step: 4
Training loss: 0.20795068269717526
Validation loss: 2.5317757284757723

Epoch: 5| Step: 5
Training loss: 0.3309299267666884
Validation loss: 2.4598020529073046

Epoch: 5| Step: 6
Training loss: 0.3097704291722783
Validation loss: 2.451491910198596

Epoch: 5| Step: 7
Training loss: 0.2969160051637344
Validation loss: 2.4316578097740456

Epoch: 5| Step: 8
Training loss: 0.35785702757320936
Validation loss: 2.4349236789067734

Epoch: 5| Step: 9
Training loss: 0.4315218179409409
Validation loss: 2.427935645553396

Epoch: 5| Step: 10
Training loss: 0.2619262698157033
Validation loss: 2.4602638355192306

Epoch: 441| Step: 0
Training loss: 0.21948968622833048
Validation loss: 2.4707528522374873

Epoch: 5| Step: 1
Training loss: 0.4359306560512366
Validation loss: 2.4472812345386177

Epoch: 5| Step: 2
Training loss: 0.4379076250844567
Validation loss: 2.515397739456974

Epoch: 5| Step: 3
Training loss: 0.41580708967823415
Validation loss: 2.499997023867815

Epoch: 5| Step: 4
Training loss: 0.3110460791473931
Validation loss: 2.4969584641832276

Epoch: 5| Step: 5
Training loss: 0.32043765111986244
Validation loss: 2.480540406749893

Epoch: 5| Step: 6
Training loss: 0.2074371802795052
Validation loss: 2.483014164931782

Epoch: 5| Step: 7
Training loss: 0.13665108368609993
Validation loss: 2.4742459168997755

Epoch: 5| Step: 8
Training loss: 0.3662422675400362
Validation loss: 2.4119888151318283

Epoch: 5| Step: 9
Training loss: 0.2177768843852733
Validation loss: 2.46693216253493

Epoch: 5| Step: 10
Training loss: 0.3844872062784423
Validation loss: 2.4378786195273596

Epoch: 442| Step: 0
Training loss: 0.1476782277821173
Validation loss: 2.432997282343944

Epoch: 5| Step: 1
Training loss: 0.31084618449597645
Validation loss: 2.4464327005599604

Epoch: 5| Step: 2
Training loss: 0.2964361737137364
Validation loss: 2.4663288169718713

Epoch: 5| Step: 3
Training loss: 0.36125217361192263
Validation loss: 2.458018480024891

Epoch: 5| Step: 4
Training loss: 0.33051792166736144
Validation loss: 2.494419109559532

Epoch: 5| Step: 5
Training loss: 0.21608677980403693
Validation loss: 2.4980118773039015

Epoch: 5| Step: 6
Training loss: 0.3513906800758854
Validation loss: 2.481286560691845

Epoch: 5| Step: 7
Training loss: 0.43364746173470736
Validation loss: 2.501575504714022

Epoch: 5| Step: 8
Training loss: 0.35124943887591087
Validation loss: 2.541311897083426

Epoch: 5| Step: 9
Training loss: 0.19394850329706445
Validation loss: 2.4686058192365046

Epoch: 5| Step: 10
Training loss: 0.45674572690417087
Validation loss: 2.5001205948486955

Epoch: 443| Step: 0
Training loss: 0.24499378669654998
Validation loss: 2.551563137764635

Epoch: 5| Step: 1
Training loss: 0.21878795635077938
Validation loss: 2.472713237883925

Epoch: 5| Step: 2
Training loss: 0.3387080321760916
Validation loss: 2.4639437979302903

Epoch: 5| Step: 3
Training loss: 0.4008765644558009
Validation loss: 2.4780893072858388

Epoch: 5| Step: 4
Training loss: 0.31213525705361556
Validation loss: 2.435999767002251

Epoch: 5| Step: 5
Training loss: 0.2434785486804645
Validation loss: 2.4401174364066116

Epoch: 5| Step: 6
Training loss: 0.4063428075859127
Validation loss: 2.4897753627339863

Epoch: 5| Step: 7
Training loss: 0.31711975934002895
Validation loss: 2.4816897820134645

Epoch: 5| Step: 8
Training loss: 0.4064384170233271
Validation loss: 2.511845360131859

Epoch: 5| Step: 9
Training loss: 0.3454022364292181
Validation loss: 2.521371124213468

Epoch: 5| Step: 10
Training loss: 0.2686174770125446
Validation loss: 2.4728354640987678

Epoch: 444| Step: 0
Training loss: 0.2791702410246114
Validation loss: 2.529316863700298

Epoch: 5| Step: 1
Training loss: 0.32259603959216776
Validation loss: 2.4875861067000127

Epoch: 5| Step: 2
Training loss: 0.23269120007016103
Validation loss: 2.4468713717837827

Epoch: 5| Step: 3
Training loss: 0.2856329499855753
Validation loss: 2.4497969053703543

Epoch: 5| Step: 4
Training loss: 0.3043947769961988
Validation loss: 2.4245318893925156

Epoch: 5| Step: 5
Training loss: 0.4097398187967919
Validation loss: 2.4302804375933538

Epoch: 5| Step: 6
Training loss: 0.33318752462486817
Validation loss: 2.4406260913268034

Epoch: 5| Step: 7
Training loss: 0.30723041257974043
Validation loss: 2.4440523703934787

Epoch: 5| Step: 8
Training loss: 0.3569409412718444
Validation loss: 2.456523556205497

Epoch: 5| Step: 9
Training loss: 0.423368477210499
Validation loss: 2.4957515745138346

Epoch: 5| Step: 10
Training loss: 0.23510550461538965
Validation loss: 2.500116633699125

Epoch: 445| Step: 0
Training loss: 0.34858040722968475
Validation loss: 2.529789244739396

Epoch: 5| Step: 1
Training loss: 0.37503739011646137
Validation loss: 2.55862311464023

Epoch: 5| Step: 2
Training loss: 0.38550541045081915
Validation loss: 2.490545346369279

Epoch: 5| Step: 3
Training loss: 0.38106030763580745
Validation loss: 2.4558316727447544

Epoch: 5| Step: 4
Training loss: 0.19165309248070603
Validation loss: 2.4596776693139906

Epoch: 5| Step: 5
Training loss: 0.27203973733894904
Validation loss: 2.4917056126695263

Epoch: 5| Step: 6
Training loss: 0.18099755102682166
Validation loss: 2.518468508447397

Epoch: 5| Step: 7
Training loss: 0.386534251890169
Validation loss: 2.4944852012669356

Epoch: 5| Step: 8
Training loss: 0.36754284566772266
Validation loss: 2.554416596596591

Epoch: 5| Step: 9
Training loss: 0.3522579308517898
Validation loss: 2.59916600725935

Epoch: 5| Step: 10
Training loss: 0.26731347131630695
Validation loss: 2.5719701799569386

Epoch: 446| Step: 0
Training loss: 0.21746694268386813
Validation loss: 2.579966064805713

Epoch: 5| Step: 1
Training loss: 0.39913262709233416
Validation loss: 2.5778949733126284

Epoch: 5| Step: 2
Training loss: 0.2442307344084408
Validation loss: 2.5556711605752955

Epoch: 5| Step: 3
Training loss: 0.458200475192396
Validation loss: 2.525614523836382

Epoch: 5| Step: 4
Training loss: 0.25299371917753827
Validation loss: 2.484034865768692

Epoch: 5| Step: 5
Training loss: 0.5230422734121531
Validation loss: 2.5016566550602466

Epoch: 5| Step: 6
Training loss: 0.3631945680958862
Validation loss: 2.5020649442070146

Epoch: 5| Step: 7
Training loss: 0.23503127404866997
Validation loss: 2.480507565492518

Epoch: 5| Step: 8
Training loss: 0.11409043009307546
Validation loss: 2.4677373663682842

Epoch: 5| Step: 9
Training loss: 0.2536325593539076
Validation loss: 2.4648072969220287

Epoch: 5| Step: 10
Training loss: 0.25588328126067705
Validation loss: 2.509860141526258

Epoch: 447| Step: 0
Training loss: 0.23496253757455196
Validation loss: 2.491580273627897

Epoch: 5| Step: 1
Training loss: 0.3198785167931581
Validation loss: 2.5154169998285996

Epoch: 5| Step: 2
Training loss: 0.155161037188741
Validation loss: 2.514762787218611

Epoch: 5| Step: 3
Training loss: 0.30095733095944244
Validation loss: 2.5518135844037007

Epoch: 5| Step: 4
Training loss: 0.44715916728454974
Validation loss: 2.556073800625499

Epoch: 5| Step: 5
Training loss: 0.3113848578287333
Validation loss: 2.5421512290800004

Epoch: 5| Step: 6
Training loss: 0.34966688908438676
Validation loss: 2.512741434636005

Epoch: 5| Step: 7
Training loss: 0.3533253552871426
Validation loss: 2.517197795167634

Epoch: 5| Step: 8
Training loss: 0.23008413873659553
Validation loss: 2.476482418658999

Epoch: 5| Step: 9
Training loss: 0.39195258563473906
Validation loss: 2.456614088327681

Epoch: 5| Step: 10
Training loss: 0.2647793857603831
Validation loss: 2.458762451756266

Epoch: 448| Step: 0
Training loss: 0.2473948386657529
Validation loss: 2.4901940345914886

Epoch: 5| Step: 1
Training loss: 0.23799245562236357
Validation loss: 2.498303565887314

Epoch: 5| Step: 2
Training loss: 0.2248592810870164
Validation loss: 2.541664124206315

Epoch: 5| Step: 3
Training loss: 0.37204011409089655
Validation loss: 2.4760149946448387

Epoch: 5| Step: 4
Training loss: 0.3197133694806461
Validation loss: 2.490638398819839

Epoch: 5| Step: 5
Training loss: 0.18912881444827204
Validation loss: 2.4946649590161925

Epoch: 5| Step: 6
Training loss: 0.41855419904757796
Validation loss: 2.5012178551556037

Epoch: 5| Step: 7
Training loss: 0.27750045754850317
Validation loss: 2.47787843612549

Epoch: 5| Step: 8
Training loss: 0.36288882153476615
Validation loss: 2.476466185723018

Epoch: 5| Step: 9
Training loss: 0.33968282594597193
Validation loss: 2.514138046925599

Epoch: 5| Step: 10
Training loss: 0.4336829909857007
Validation loss: 2.521001301115953

Epoch: 449| Step: 0
Training loss: 0.1841931804354479
Validation loss: 2.5507489502790577

Epoch: 5| Step: 1
Training loss: 0.11375296967423677
Validation loss: 2.6042517397530967

Epoch: 5| Step: 2
Training loss: 0.406115381237892
Validation loss: 2.57720412149672

Epoch: 5| Step: 3
Training loss: 0.39342013726012953
Validation loss: 2.5774253430323197

Epoch: 5| Step: 4
Training loss: 0.35506384708583455
Validation loss: 2.5470507604087316

Epoch: 5| Step: 5
Training loss: 0.350314351246253
Validation loss: 2.554797690455754

Epoch: 5| Step: 6
Training loss: 0.38017181543358614
Validation loss: 2.5307325591092056

Epoch: 5| Step: 7
Training loss: 0.3538353880618812
Validation loss: 2.4617601578655806

Epoch: 5| Step: 8
Training loss: 0.3195282942954654
Validation loss: 2.4583933122331776

Epoch: 5| Step: 9
Training loss: 0.3138595451939058
Validation loss: 2.4208506709372415

Epoch: 5| Step: 10
Training loss: 0.2200573444678031
Validation loss: 2.4235312650490948

Epoch: 450| Step: 0
Training loss: 0.19026667146472495
Validation loss: 2.4587893479340903

Epoch: 5| Step: 1
Training loss: 0.3358812839578951
Validation loss: 2.457475591501255

Epoch: 5| Step: 2
Training loss: 0.2954380369034245
Validation loss: 2.5241807956433036

Epoch: 5| Step: 3
Training loss: 0.4792797760217917
Validation loss: 2.5357094801988893

Epoch: 5| Step: 4
Training loss: 0.3666649610667585
Validation loss: 2.5519362624289172

Epoch: 5| Step: 5
Training loss: 0.15564320279719007
Validation loss: 2.5219421233027504

Epoch: 5| Step: 6
Training loss: 0.14496862115132683
Validation loss: 2.490195211303228

Epoch: 5| Step: 7
Training loss: 0.48511579225073664
Validation loss: 2.483869866941038

Epoch: 5| Step: 8
Training loss: 0.18909953243345576
Validation loss: 2.4581792184176976

Epoch: 5| Step: 9
Training loss: 0.2609945354830507
Validation loss: 2.4330674016721687

Epoch: 5| Step: 10
Training loss: 0.25136081062059157
Validation loss: 2.4358570261154977

Epoch: 451| Step: 0
Training loss: 0.2680558027105449
Validation loss: 2.4470026142865695

Epoch: 5| Step: 1
Training loss: 0.2847975211993983
Validation loss: 2.467608874389966

Epoch: 5| Step: 2
Training loss: 0.332569695496497
Validation loss: 2.5016093980393284

Epoch: 5| Step: 3
Training loss: 0.10796817669667955
Validation loss: 2.523135496173054

Epoch: 5| Step: 4
Training loss: 0.33871248655126673
Validation loss: 2.5452571853846386

Epoch: 5| Step: 5
Training loss: 0.18446611561445894
Validation loss: 2.5210309732105065

Epoch: 5| Step: 6
Training loss: 0.4076120761026272
Validation loss: 2.493348742861814

Epoch: 5| Step: 7
Training loss: 0.306403183578873
Validation loss: 2.527832823820399

Epoch: 5| Step: 8
Training loss: 0.1792004972407082
Validation loss: 2.494200419319997

Epoch: 5| Step: 9
Training loss: 0.513538560864366
Validation loss: 2.4623523817618427

Epoch: 5| Step: 10
Training loss: 0.20586082414554943
Validation loss: 2.5126127668018254

Epoch: 452| Step: 0
Training loss: 0.17607972976937675
Validation loss: 2.5006555887187094

Epoch: 5| Step: 1
Training loss: 0.27827841460096986
Validation loss: 2.5227584964130125

Epoch: 5| Step: 2
Training loss: 0.24483523167177615
Validation loss: 2.4960275355237576

Epoch: 5| Step: 3
Training loss: 0.3444183095293961
Validation loss: 2.511805729128787

Epoch: 5| Step: 4
Training loss: 0.34094963789888627
Validation loss: 2.46721048771526

Epoch: 5| Step: 5
Training loss: 0.15303669348942536
Validation loss: 2.4858577269015023

Epoch: 5| Step: 6
Training loss: 0.43774887227077086
Validation loss: 2.4821159073738466

Epoch: 5| Step: 7
Training loss: 0.3477931449625337
Validation loss: 2.5014300117350183

Epoch: 5| Step: 8
Training loss: 0.3781746161830072
Validation loss: 2.45701051724124

Epoch: 5| Step: 9
Training loss: 0.23055967864804786
Validation loss: 2.4754921152205602

Epoch: 5| Step: 10
Training loss: 0.1940960481765883
Validation loss: 2.4308761291711702

Epoch: 453| Step: 0
Training loss: 0.28348565314000096
Validation loss: 2.4595843497396523

Epoch: 5| Step: 1
Training loss: 0.3702506275236078
Validation loss: 2.464698964195542

Epoch: 5| Step: 2
Training loss: 0.29736264233450066
Validation loss: 2.486962586132706

Epoch: 5| Step: 3
Training loss: 0.28607661505845566
Validation loss: 2.4848402406383254

Epoch: 5| Step: 4
Training loss: 0.1392249241068889
Validation loss: 2.504828089686578

Epoch: 5| Step: 5
Training loss: 0.27880653607733197
Validation loss: 2.5362885184943265

Epoch: 5| Step: 6
Training loss: 0.1790144172741589
Validation loss: 2.5460074103527996

Epoch: 5| Step: 7
Training loss: 0.31175430257637954
Validation loss: 2.494030458018371

Epoch: 5| Step: 8
Training loss: 0.23796377764170143
Validation loss: 2.493028806637983

Epoch: 5| Step: 9
Training loss: 0.3606988324196418
Validation loss: 2.4224853074789903

Epoch: 5| Step: 10
Training loss: 0.4687158731117571
Validation loss: 2.3815694957597753

Epoch: 454| Step: 0
Training loss: 0.4441325634012522
Validation loss: 2.4508600735861372

Epoch: 5| Step: 1
Training loss: 0.32790660402029287
Validation loss: 2.4916101512727096

Epoch: 5| Step: 2
Training loss: 0.17733058544485217
Validation loss: 2.528139585175606

Epoch: 5| Step: 3
Training loss: 0.24179797996552005
Validation loss: 2.5777627978265634

Epoch: 5| Step: 4
Training loss: 0.40619031761167723
Validation loss: 2.6134650602326785

Epoch: 5| Step: 5
Training loss: 0.17802536377927888
Validation loss: 2.614924963050578

Epoch: 5| Step: 6
Training loss: 0.28291899799281534
Validation loss: 2.5721571735748223

Epoch: 5| Step: 7
Training loss: 0.18398033186242227
Validation loss: 2.589767281448887

Epoch: 5| Step: 8
Training loss: 0.2244964149704983
Validation loss: 2.5144501086854483

Epoch: 5| Step: 9
Training loss: 0.42407261700744653
Validation loss: 2.5099148169333088

Epoch: 5| Step: 10
Training loss: 0.3468092985048396
Validation loss: 2.4573998226551845

Epoch: 455| Step: 0
Training loss: 0.31239755858762924
Validation loss: 2.4738710052327444

Epoch: 5| Step: 1
Training loss: 0.3046114533229467
Validation loss: 2.481881207073419

Epoch: 5| Step: 2
Training loss: 0.25449439667733126
Validation loss: 2.5462530169180995

Epoch: 5| Step: 3
Training loss: 0.14515485775200848
Validation loss: 2.5387102668729105

Epoch: 5| Step: 4
Training loss: 0.28565598163314615
Validation loss: 2.5380685935546636

Epoch: 5| Step: 5
Training loss: 0.42906535798501116
Validation loss: 2.5454239921017305

Epoch: 5| Step: 6
Training loss: 0.2344885233285084
Validation loss: 2.533534376977083

Epoch: 5| Step: 7
Training loss: 0.35934336149846735
Validation loss: 2.5185062125274844

Epoch: 5| Step: 8
Training loss: 0.3421660037669917
Validation loss: 2.4899768780022176

Epoch: 5| Step: 9
Training loss: 0.2371740413259981
Validation loss: 2.5195338019062157

Epoch: 5| Step: 10
Training loss: 0.43338591947351784
Validation loss: 2.4810666679542313

Epoch: 456| Step: 0
Training loss: 0.18017621544266155
Validation loss: 2.505133507082075

Epoch: 5| Step: 1
Training loss: 0.2665214977280475
Validation loss: 2.533849171962587

Epoch: 5| Step: 2
Training loss: 0.3094680930246897
Validation loss: 2.576953925005601

Epoch: 5| Step: 3
Training loss: 0.36411032874149385
Validation loss: 2.5828241791920257

Epoch: 5| Step: 4
Training loss: 0.21067316659147936
Validation loss: 2.5349814933377526

Epoch: 5| Step: 5
Training loss: 0.3171849029885698
Validation loss: 2.523231652119363

Epoch: 5| Step: 6
Training loss: 0.2190509837194008
Validation loss: 2.4796700484022676

Epoch: 5| Step: 7
Training loss: 0.2681279763143246
Validation loss: 2.498112406359343

Epoch: 5| Step: 8
Training loss: 0.4663355315251834
Validation loss: 2.5003559699993674

Epoch: 5| Step: 9
Training loss: 0.36417913737793056
Validation loss: 2.431371514573365

Epoch: 5| Step: 10
Training loss: 0.182504568206102
Validation loss: 2.456180376075734

Epoch: 457| Step: 0
Training loss: 0.36383617225939685
Validation loss: 2.41682218624777

Epoch: 5| Step: 1
Training loss: 0.3641862568870894
Validation loss: 2.464283649826977

Epoch: 5| Step: 2
Training loss: 0.5060228945109965
Validation loss: 2.4599939879243826

Epoch: 5| Step: 3
Training loss: 0.2549980458483898
Validation loss: 2.485272084138729

Epoch: 5| Step: 4
Training loss: 0.11964811054151436
Validation loss: 2.461513602775712

Epoch: 5| Step: 5
Training loss: 0.20388563497697276
Validation loss: 2.4909180416787655

Epoch: 5| Step: 6
Training loss: 0.36916833601991084
Validation loss: 2.46679152385006

Epoch: 5| Step: 7
Training loss: 0.1948054216155728
Validation loss: 2.4822129247260807

Epoch: 5| Step: 8
Training loss: 0.16055924606923916
Validation loss: 2.474537409230412

Epoch: 5| Step: 9
Training loss: 0.2153845223526341
Validation loss: 2.461792174004492

Epoch: 5| Step: 10
Training loss: 0.15336282711642438
Validation loss: 2.458004818117024

Epoch: 458| Step: 0
Training loss: 0.47477678399768475
Validation loss: 2.4464972247507992

Epoch: 5| Step: 1
Training loss: 0.23744484800640292
Validation loss: 2.486343101095027

Epoch: 5| Step: 2
Training loss: 0.2713986268232967
Validation loss: 2.5164666953363906

Epoch: 5| Step: 3
Training loss: 0.18738204504209377
Validation loss: 2.4529935499684328

Epoch: 5| Step: 4
Training loss: 0.22149601019383164
Validation loss: 2.5093565128481976

Epoch: 5| Step: 5
Training loss: 0.16648296325170953
Validation loss: 2.482446238752868

Epoch: 5| Step: 6
Training loss: 0.26292807608442037
Validation loss: 2.45996256611451

Epoch: 5| Step: 7
Training loss: 0.3056575055378859
Validation loss: 2.515816401707892

Epoch: 5| Step: 8
Training loss: 0.3451982464503243
Validation loss: 2.4533329667761654

Epoch: 5| Step: 9
Training loss: 0.34609578349461134
Validation loss: 2.4680243116496885

Epoch: 5| Step: 10
Training loss: 0.20590986794370197
Validation loss: 2.4531330740504274

Epoch: 459| Step: 0
Training loss: 0.21705552729526653
Validation loss: 2.4723005089603314

Epoch: 5| Step: 1
Training loss: 0.2479083507943639
Validation loss: 2.467734150566284

Epoch: 5| Step: 2
Training loss: 0.3076439982038521
Validation loss: 2.483575720340115

Epoch: 5| Step: 3
Training loss: 0.14623742586473587
Validation loss: 2.4914072441720836

Epoch: 5| Step: 4
Training loss: 0.33562268432159303
Validation loss: 2.483273280003228

Epoch: 5| Step: 5
Training loss: 0.35161380393480046
Validation loss: 2.4965510974093297

Epoch: 5| Step: 6
Training loss: 0.2842224980254505
Validation loss: 2.4874231109880585

Epoch: 5| Step: 7
Training loss: 0.34905257186157995
Validation loss: 2.4936089039604195

Epoch: 5| Step: 8
Training loss: 0.3067361112005938
Validation loss: 2.5032740207150157

Epoch: 5| Step: 9
Training loss: 0.365609634109132
Validation loss: 2.4895283682713485

Epoch: 5| Step: 10
Training loss: 0.1642307145744498
Validation loss: 2.488994163285412

Epoch: 460| Step: 0
Training loss: 0.2676670177407138
Validation loss: 2.5091288357618367

Epoch: 5| Step: 1
Training loss: 0.2654592333385048
Validation loss: 2.4973103051815833

Epoch: 5| Step: 2
Training loss: 0.24510987715439586
Validation loss: 2.491877593637649

Epoch: 5| Step: 3
Training loss: 0.45616955505188833
Validation loss: 2.484014344978171

Epoch: 5| Step: 4
Training loss: 0.36820933015622315
Validation loss: 2.4853299978632495

Epoch: 5| Step: 5
Training loss: 0.27119832783850956
Validation loss: 2.4839665990523168

Epoch: 5| Step: 6
Training loss: 0.32599844290575025
Validation loss: 2.50120089616034

Epoch: 5| Step: 7
Training loss: 0.2705042869806361
Validation loss: 2.4534922086487327

Epoch: 5| Step: 8
Training loss: 0.12757039028578618
Validation loss: 2.4775994675314523

Epoch: 5| Step: 9
Training loss: 0.13268883641891094
Validation loss: 2.49168485513501

Epoch: 5| Step: 10
Training loss: 0.2897438962086141
Validation loss: 2.537966281965915

Epoch: 461| Step: 0
Training loss: 0.19286778121228262
Validation loss: 2.5163573295471235

Epoch: 5| Step: 1
Training loss: 0.3233839340819029
Validation loss: 2.5083575025326232

Epoch: 5| Step: 2
Training loss: 0.25955682264512525
Validation loss: 2.552110352330247

Epoch: 5| Step: 3
Training loss: 0.32918386816799244
Validation loss: 2.49350871305802

Epoch: 5| Step: 4
Training loss: 0.16847062539797683
Validation loss: 2.48496773948815

Epoch: 5| Step: 5
Training loss: 0.34730775918654466
Validation loss: 2.47054437920719

Epoch: 5| Step: 6
Training loss: 0.3499816319209845
Validation loss: 2.5178212844641283

Epoch: 5| Step: 7
Training loss: 0.3869482958234482
Validation loss: 2.5316635982955487

Epoch: 5| Step: 8
Training loss: 0.3838039715615587
Validation loss: 2.567760485387165

Epoch: 5| Step: 9
Training loss: 0.17336841401529296
Validation loss: 2.5771056033350286

Epoch: 5| Step: 10
Training loss: 0.18022845565672702
Validation loss: 2.5856580383421592

Epoch: 462| Step: 0
Training loss: 0.3250372562695216
Validation loss: 2.5547674640153866

Epoch: 5| Step: 1
Training loss: 0.23864112318750352
Validation loss: 2.5336768112046983

Epoch: 5| Step: 2
Training loss: 0.25971752094211614
Validation loss: 2.5419817387450734

Epoch: 5| Step: 3
Training loss: 0.33485110514684713
Validation loss: 2.5455140388720365

Epoch: 5| Step: 4
Training loss: 0.2814477913804918
Validation loss: 2.498642881239489

Epoch: 5| Step: 5
Training loss: 0.23329636803944243
Validation loss: 2.5071407790000135

Epoch: 5| Step: 6
Training loss: 0.17149253035076578
Validation loss: 2.5225360570428412

Epoch: 5| Step: 7
Training loss: 0.36797597112677166
Validation loss: 2.555212796703656

Epoch: 5| Step: 8
Training loss: 0.30704943624900344
Validation loss: 2.5527976976054925

Epoch: 5| Step: 9
Training loss: 0.34378465564470584
Validation loss: 2.5314941227761865

Epoch: 5| Step: 10
Training loss: 0.20843154658518634
Validation loss: 2.5248480665107316

Epoch: 463| Step: 0
Training loss: 0.2177307360741622
Validation loss: 2.541829302355491

Epoch: 5| Step: 1
Training loss: 0.23755048259225608
Validation loss: 2.4985761474222934

Epoch: 5| Step: 2
Training loss: 0.2752132927007123
Validation loss: 2.4639912675250804

Epoch: 5| Step: 3
Training loss: 0.4949420867622604
Validation loss: 2.44242494970437

Epoch: 5| Step: 4
Training loss: 0.3151348141144847
Validation loss: 2.4576764057200045

Epoch: 5| Step: 5
Training loss: 0.17153818550551087
Validation loss: 2.453096879607603

Epoch: 5| Step: 6
Training loss: 0.20781672122081266
Validation loss: 2.469970435729944

Epoch: 5| Step: 7
Training loss: 0.2510769268588681
Validation loss: 2.471294733835673

Epoch: 5| Step: 8
Training loss: 0.2876863067729834
Validation loss: 2.489695486030337

Epoch: 5| Step: 9
Training loss: 0.1980276309112023
Validation loss: 2.509112725144183

Epoch: 5| Step: 10
Training loss: 0.3261808862412183
Validation loss: 2.549173728574451

Epoch: 464| Step: 0
Training loss: 0.2897278371420023
Validation loss: 2.5256157583981613

Epoch: 5| Step: 1
Training loss: 0.31202474456485074
Validation loss: 2.5308199423111293

Epoch: 5| Step: 2
Training loss: 0.2838219819794083
Validation loss: 2.5148785074042674

Epoch: 5| Step: 3
Training loss: 0.19258712917734633
Validation loss: 2.5116212224004792

Epoch: 5| Step: 4
Training loss: 0.3149964868448018
Validation loss: 2.4998261273330313

Epoch: 5| Step: 5
Training loss: 0.3269379009498875
Validation loss: 2.4627644461172213

Epoch: 5| Step: 6
Training loss: 0.390656527200626
Validation loss: 2.4568398348248017

Epoch: 5| Step: 7
Training loss: 0.2349410533022356
Validation loss: 2.427077065807033

Epoch: 5| Step: 8
Training loss: 0.28546864890110873
Validation loss: 2.449495350469776

Epoch: 5| Step: 9
Training loss: 0.30444433828531475
Validation loss: 2.46052388095885

Epoch: 5| Step: 10
Training loss: 0.2253909403569017
Validation loss: 2.4430103302044466

Epoch: 465| Step: 0
Training loss: 0.26907212779578377
Validation loss: 2.4806594766263266

Epoch: 5| Step: 1
Training loss: 0.3572748225646686
Validation loss: 2.483831055997983

Epoch: 5| Step: 2
Training loss: 0.17115616030270195
Validation loss: 2.5009280502367286

Epoch: 5| Step: 3
Training loss: 0.23851862793377454
Validation loss: 2.5445780978157213

Epoch: 5| Step: 4
Training loss: 0.401620455467141
Validation loss: 2.515346978733064

Epoch: 5| Step: 5
Training loss: 0.21547421801837124
Validation loss: 2.4955580729999585

Epoch: 5| Step: 6
Training loss: 0.27058095666115534
Validation loss: 2.447508336773785

Epoch: 5| Step: 7
Training loss: 0.2931289489171019
Validation loss: 2.4258405797624287

Epoch: 5| Step: 8
Training loss: 0.37263090099434115
Validation loss: 2.4081721838003243

Epoch: 5| Step: 9
Training loss: 0.29491485183134425
Validation loss: 2.3975103724861793

Epoch: 5| Step: 10
Training loss: 0.249931467616875
Validation loss: 2.40949064130223

Epoch: 466| Step: 0
Training loss: 0.23175022305063256
Validation loss: 2.4435023810917946

Epoch: 5| Step: 1
Training loss: 0.15725096519125484
Validation loss: 2.475918774002404

Epoch: 5| Step: 2
Training loss: 0.25283514192567574
Validation loss: 2.490328058792485

Epoch: 5| Step: 3
Training loss: 0.371139884891783
Validation loss: 2.500971811361661

Epoch: 5| Step: 4
Training loss: 0.3897877494327021
Validation loss: 2.453735141918645

Epoch: 5| Step: 5
Training loss: 0.2550030275006182
Validation loss: 2.4602262965133934

Epoch: 5| Step: 6
Training loss: 0.2678463698105362
Validation loss: 2.4536566486422804

Epoch: 5| Step: 7
Training loss: 0.1800404171966153
Validation loss: 2.426671208669178

Epoch: 5| Step: 8
Training loss: 0.29326453218688875
Validation loss: 2.3735213121071865

Epoch: 5| Step: 9
Training loss: 0.3975537728279937
Validation loss: 2.3920187970426827

Epoch: 5| Step: 10
Training loss: 0.33633555626717454
Validation loss: 2.429968934842354

Epoch: 467| Step: 0
Training loss: 0.21455434901275341
Validation loss: 2.449241503443838

Epoch: 5| Step: 1
Training loss: 0.1951123260869968
Validation loss: 2.4937777251400335

Epoch: 5| Step: 2
Training loss: 0.42000140834186217
Validation loss: 2.523751223633226

Epoch: 5| Step: 3
Training loss: 0.39025225975438066
Validation loss: 2.567175898185165

Epoch: 5| Step: 4
Training loss: 0.2042299441806254
Validation loss: 2.5648785253840787

Epoch: 5| Step: 5
Training loss: 0.16013315662340172
Validation loss: 2.537618671145618

Epoch: 5| Step: 6
Training loss: 0.2831983368567484
Validation loss: 2.462210088887371

Epoch: 5| Step: 7
Training loss: 0.19058192110295957
Validation loss: 2.4290100082671673

Epoch: 5| Step: 8
Training loss: 0.24539465227195592
Validation loss: 2.4070161373008294

Epoch: 5| Step: 9
Training loss: 0.4040049729253617
Validation loss: 2.4185581815806225

Epoch: 5| Step: 10
Training loss: 0.2691504096036753
Validation loss: 2.4059448448220464

Epoch: 468| Step: 0
Training loss: 0.14006518488748632
Validation loss: 2.4137616446448633

Epoch: 5| Step: 1
Training loss: 0.28401307665410963
Validation loss: 2.4617557699850594

Epoch: 5| Step: 2
Training loss: 0.3378545267744925
Validation loss: 2.480157615521127

Epoch: 5| Step: 3
Training loss: 0.45486345262224076
Validation loss: 2.5407937386745787

Epoch: 5| Step: 4
Training loss: 0.3809053246582869
Validation loss: 2.5318700237902

Epoch: 5| Step: 5
Training loss: 0.22180765298452718
Validation loss: 2.53464856893196

Epoch: 5| Step: 6
Training loss: 0.23937264625547477
Validation loss: 2.52289521043345

Epoch: 5| Step: 7
Training loss: 0.24089860192719006
Validation loss: 2.484352648822761

Epoch: 5| Step: 8
Training loss: 0.32819454273606796
Validation loss: 2.4840944275809

Epoch: 5| Step: 9
Training loss: 0.15853635989826417
Validation loss: 2.443844198159103

Epoch: 5| Step: 10
Training loss: 0.3461339604288001
Validation loss: 2.442302444928739

Epoch: 469| Step: 0
Training loss: 0.23515480966221938
Validation loss: 2.4639332470997295

Epoch: 5| Step: 1
Training loss: 0.13413569521857172
Validation loss: 2.4781403806477784

Epoch: 5| Step: 2
Training loss: 0.37461471633364973
Validation loss: 2.539182753069867

Epoch: 5| Step: 3
Training loss: 0.2665157948683681
Validation loss: 2.5935758504312427

Epoch: 5| Step: 4
Training loss: 0.3145342183245444
Validation loss: 2.521989500471202

Epoch: 5| Step: 5
Training loss: 0.2779217325494266
Validation loss: 2.503307674958044

Epoch: 5| Step: 6
Training loss: 0.3705372301487602
Validation loss: 2.4611472862559562

Epoch: 5| Step: 7
Training loss: 0.3468010166244885
Validation loss: 2.4317318378619373

Epoch: 5| Step: 8
Training loss: 0.3715346477839919
Validation loss: 2.3730358427868143

Epoch: 5| Step: 9
Training loss: 0.24165589686078984
Validation loss: 2.366539879173935

Epoch: 5| Step: 10
Training loss: 0.23002683977901084
Validation loss: 2.3849834416471367

Epoch: 470| Step: 0
Training loss: 0.2918841056710338
Validation loss: 2.4071099873079427

Epoch: 5| Step: 1
Training loss: 0.378551395643244
Validation loss: 2.406181205551305

Epoch: 5| Step: 2
Training loss: 0.19253576559508898
Validation loss: 2.46269118118288

Epoch: 5| Step: 3
Training loss: 0.28862803259157177
Validation loss: 2.484285626074707

Epoch: 5| Step: 4
Training loss: 0.30536822545504194
Validation loss: 2.51857885745553

Epoch: 5| Step: 5
Training loss: 0.2538290346551424
Validation loss: 2.523312492579851

Epoch: 5| Step: 6
Training loss: 0.2249911174080465
Validation loss: 2.5473029097214805

Epoch: 5| Step: 7
Training loss: 0.3341443977918925
Validation loss: 2.5242753640057516

Epoch: 5| Step: 8
Training loss: 0.3597997353088419
Validation loss: 2.5260631104093934

Epoch: 5| Step: 9
Training loss: 0.25713435484911806
Validation loss: 2.5282342189078335

Epoch: 5| Step: 10
Training loss: 0.25444454938792915
Validation loss: 2.595335872286326

Epoch: 471| Step: 0
Training loss: 0.40160112454980723
Validation loss: 2.5983529205800586

Epoch: 5| Step: 1
Training loss: 0.3876327925461274
Validation loss: 2.595638972528169

Epoch: 5| Step: 2
Training loss: 0.17705389904847676
Validation loss: 2.5846993496276607

Epoch: 5| Step: 3
Training loss: 0.2099250052999169
Validation loss: 2.55768159702544

Epoch: 5| Step: 4
Training loss: 0.2975704555068959
Validation loss: 2.52845573266215

Epoch: 5| Step: 5
Training loss: 0.35599667259065026
Validation loss: 2.521237025678931

Epoch: 5| Step: 6
Training loss: 0.11098910880811558
Validation loss: 2.4622017582727267

Epoch: 5| Step: 7
Training loss: 0.18902341541117512
Validation loss: 2.4309611692739357

Epoch: 5| Step: 8
Training loss: 0.3158215430146676
Validation loss: 2.35417274570869

Epoch: 5| Step: 9
Training loss: 0.4209706538793557
Validation loss: 2.3373620763859093

Epoch: 5| Step: 10
Training loss: 0.32408671390707217
Validation loss: 2.395795021624675

Epoch: 472| Step: 0
Training loss: 0.28197123187432593
Validation loss: 2.4373247227150574

Epoch: 5| Step: 1
Training loss: 0.26224970692271826
Validation loss: 2.486917305393721

Epoch: 5| Step: 2
Training loss: 0.28706227130245415
Validation loss: 2.5084372346608106

Epoch: 5| Step: 3
Training loss: 0.33165534563048205
Validation loss: 2.534776621877358

Epoch: 5| Step: 4
Training loss: 0.32136606609667684
Validation loss: 2.555366812396051

Epoch: 5| Step: 5
Training loss: 0.24131603499656187
Validation loss: 2.5149461241270243

Epoch: 5| Step: 6
Training loss: 0.2587562540238371
Validation loss: 2.481653159040243

Epoch: 5| Step: 7
Training loss: 0.3752194795465609
Validation loss: 2.4320964569330994

Epoch: 5| Step: 8
Training loss: 0.3832380498589458
Validation loss: 2.426047925568046

Epoch: 5| Step: 9
Training loss: 0.19785132186890078
Validation loss: 2.457738555848748

Epoch: 5| Step: 10
Training loss: 0.22641374374213996
Validation loss: 2.46588499891033

Epoch: 473| Step: 0
Training loss: 0.23510068762969524
Validation loss: 2.5161275685831717

Epoch: 5| Step: 1
Training loss: 0.38575933877020435
Validation loss: 2.5461213313929822

Epoch: 5| Step: 2
Training loss: 0.37363052646637546
Validation loss: 2.5629558893027773

Epoch: 5| Step: 3
Training loss: 0.3449832943658764
Validation loss: 2.581537646411261

Epoch: 5| Step: 4
Training loss: 0.2714725738814646
Validation loss: 2.505104556204826

Epoch: 5| Step: 5
Training loss: 0.17600691932554208
Validation loss: 2.432479662115495

Epoch: 5| Step: 6
Training loss: 0.30166387484682977
Validation loss: 2.4409867000267664

Epoch: 5| Step: 7
Training loss: 0.1867353623473978
Validation loss: 2.4022236861146187

Epoch: 5| Step: 8
Training loss: 0.3607145719176348
Validation loss: 2.4242567023735906

Epoch: 5| Step: 9
Training loss: 0.31501083200237967
Validation loss: 2.4778904629335092

Epoch: 5| Step: 10
Training loss: 0.20236007006015308
Validation loss: 2.4952618439348564

Epoch: 474| Step: 0
Training loss: 0.2451154853184174
Validation loss: 2.5505995468762173

Epoch: 5| Step: 1
Training loss: 0.34778587196535843
Validation loss: 2.58198070956033

Epoch: 5| Step: 2
Training loss: 0.32917557288848864
Validation loss: 2.5423883502533173

Epoch: 5| Step: 3
Training loss: 0.32873045602149886
Validation loss: 2.4745544406258704

Epoch: 5| Step: 4
Training loss: 0.23661958833310823
Validation loss: 2.403391871530559

Epoch: 5| Step: 5
Training loss: 0.353234848727475
Validation loss: 2.4041277221814283

Epoch: 5| Step: 6
Training loss: 0.3081714299564352
Validation loss: 2.375343166271505

Epoch: 5| Step: 7
Training loss: 0.35963364291553596
Validation loss: 2.4183477411229437

Epoch: 5| Step: 8
Training loss: 0.2239496244171461
Validation loss: 2.424139529036736

Epoch: 5| Step: 9
Training loss: 0.38399090688588566
Validation loss: 2.484867947121952

Epoch: 5| Step: 10
Training loss: 0.18965493101716374
Validation loss: 2.564834333841703

Epoch: 475| Step: 0
Training loss: 0.25478909402818495
Validation loss: 2.5887885352417666

Epoch: 5| Step: 1
Training loss: 0.4351181349164828
Validation loss: 2.5794721924955204

Epoch: 5| Step: 2
Training loss: 0.3078765865359392
Validation loss: 2.5692342912988546

Epoch: 5| Step: 3
Training loss: 0.18878722406427909
Validation loss: 2.5088741271288035

Epoch: 5| Step: 4
Training loss: 0.277956500606378
Validation loss: 2.460180798783121

Epoch: 5| Step: 5
Training loss: 0.23488095825671326
Validation loss: 2.433597154709902

Epoch: 5| Step: 6
Training loss: 0.32448624296519085
Validation loss: 2.400775369249118

Epoch: 5| Step: 7
Training loss: 0.24483036266358238
Validation loss: 2.400552248953061

Epoch: 5| Step: 8
Training loss: 0.24367921333233833
Validation loss: 2.4075759278406212

Epoch: 5| Step: 9
Training loss: 0.21953421757005737
Validation loss: 2.4687208441594595

Epoch: 5| Step: 10
Training loss: 0.28450939544925374
Validation loss: 2.473159391263014

Epoch: 476| Step: 0
Training loss: 0.28828517683709354
Validation loss: 2.5237715122369995

Epoch: 5| Step: 1
Training loss: 0.24280328298624196
Validation loss: 2.503730103119081

Epoch: 5| Step: 2
Training loss: 0.18960315623417756
Validation loss: 2.528564849929113

Epoch: 5| Step: 3
Training loss: 0.20016780757367156
Validation loss: 2.528833587212948

Epoch: 5| Step: 4
Training loss: 0.4135209266528859
Validation loss: 2.5363845078312965

Epoch: 5| Step: 5
Training loss: 0.359543221948696
Validation loss: 2.535889653880231

Epoch: 5| Step: 6
Training loss: 0.21751616981021052
Validation loss: 2.510307975141567

Epoch: 5| Step: 7
Training loss: 0.2523693520517168
Validation loss: 2.4977747232313625

Epoch: 5| Step: 8
Training loss: 0.3090758240183443
Validation loss: 2.482031143964529

Epoch: 5| Step: 9
Training loss: 0.2643760320855234
Validation loss: 2.4778950229557832

Epoch: 5| Step: 10
Training loss: 0.2216787212199523
Validation loss: 2.4686801239027254

Epoch: 477| Step: 0
Training loss: 0.38153032721771024
Validation loss: 2.4963096432722773

Epoch: 5| Step: 1
Training loss: 0.12891210195956537
Validation loss: 2.528847465098136

Epoch: 5| Step: 2
Training loss: 0.2974785517125564
Validation loss: 2.5372439279651577

Epoch: 5| Step: 3
Training loss: 0.23690772901153115
Validation loss: 2.535033976261305

Epoch: 5| Step: 4
Training loss: 0.3348573797089166
Validation loss: 2.5358975968492383

Epoch: 5| Step: 5
Training loss: 0.2907676408259038
Validation loss: 2.5570555122763676

Epoch: 5| Step: 6
Training loss: 0.1873295525841595
Validation loss: 2.520114358510103

Epoch: 5| Step: 7
Training loss: 0.24197004923569604
Validation loss: 2.5551503948010943

Epoch: 5| Step: 8
Training loss: 0.20057035532362377
Validation loss: 2.5171485668766715

Epoch: 5| Step: 9
Training loss: 0.16583909578730874
Validation loss: 2.5234402450464812

Epoch: 5| Step: 10
Training loss: 0.39036255603320696
Validation loss: 2.5037432201209064

Epoch: 478| Step: 0
Training loss: 0.21784487865387095
Validation loss: 2.4841379455125097

Epoch: 5| Step: 1
Training loss: 0.2666330004590289
Validation loss: 2.471353744814026

Epoch: 5| Step: 2
Training loss: 0.3493512975230785
Validation loss: 2.4765908001018087

Epoch: 5| Step: 3
Training loss: 0.3817440810291162
Validation loss: 2.492124488484802

Epoch: 5| Step: 4
Training loss: 0.21043025947012955
Validation loss: 2.4834481082170243

Epoch: 5| Step: 5
Training loss: 0.24046661812256798
Validation loss: 2.4826371542274392

Epoch: 5| Step: 6
Training loss: 0.24339442850238793
Validation loss: 2.4893699290573776

Epoch: 5| Step: 7
Training loss: 0.15852168470656994
Validation loss: 2.485248004942877

Epoch: 5| Step: 8
Training loss: 0.3364929552935015
Validation loss: 2.496307044004256

Epoch: 5| Step: 9
Training loss: 0.21302029396647945
Validation loss: 2.4973948433347863

Epoch: 5| Step: 10
Training loss: 0.21545762877778507
Validation loss: 2.5201098926840486

Epoch: 479| Step: 0
Training loss: 0.2264316197246974
Validation loss: 2.5046036714800675

Epoch: 5| Step: 1
Training loss: 0.36576331693090625
Validation loss: 2.510536746168884

Epoch: 5| Step: 2
Training loss: 0.34211216145121354
Validation loss: 2.4983541936900413

Epoch: 5| Step: 3
Training loss: 0.17536875220954432
Validation loss: 2.513950050926037

Epoch: 5| Step: 4
Training loss: 0.19880764748996166
Validation loss: 2.5017886387794235

Epoch: 5| Step: 5
Training loss: 0.23375687947324025
Validation loss: 2.4968262831500865

Epoch: 5| Step: 6
Training loss: 0.1778408507119326
Validation loss: 2.458182496257281

Epoch: 5| Step: 7
Training loss: 0.3837341774092241
Validation loss: 2.424622976351914

Epoch: 5| Step: 8
Training loss: 0.26248527837525515
Validation loss: 2.430838338298289

Epoch: 5| Step: 9
Training loss: 0.2766872614904099
Validation loss: 2.3780580100122735

Epoch: 5| Step: 10
Training loss: 0.2113459394494687
Validation loss: 2.414001346191476

Epoch: 480| Step: 0
Training loss: 0.1538448291057281
Validation loss: 2.4629033542215075

Epoch: 5| Step: 1
Training loss: 0.28489681094953234
Validation loss: 2.462818836746372

Epoch: 5| Step: 2
Training loss: 0.427339310422498
Validation loss: 2.496299544007118

Epoch: 5| Step: 3
Training loss: 0.28887582885940205
Validation loss: 2.483846059534337

Epoch: 5| Step: 4
Training loss: 0.1582500423514956
Validation loss: 2.4656888624153748

Epoch: 5| Step: 5
Training loss: 0.21196382351458892
Validation loss: 2.4984273014313088

Epoch: 5| Step: 6
Training loss: 0.14102574705743612
Validation loss: 2.4863101560415397

Epoch: 5| Step: 7
Training loss: 0.2316086751894739
Validation loss: 2.4610741580769866

Epoch: 5| Step: 8
Training loss: 0.2584418792999344
Validation loss: 2.488889211208691

Epoch: 5| Step: 9
Training loss: 0.31121853104419056
Validation loss: 2.455757796977404

Epoch: 5| Step: 10
Training loss: 0.2346274605664186
Validation loss: 2.5063239150652348

Epoch: 481| Step: 0
Training loss: 0.1932522544451749
Validation loss: 2.4690378025742654

Epoch: 5| Step: 1
Training loss: 0.16749264642245207
Validation loss: 2.4973571972645665

Epoch: 5| Step: 2
Training loss: 0.220038451199501
Validation loss: 2.506774939184372

Epoch: 5| Step: 3
Training loss: 0.36925537102111167
Validation loss: 2.5099401936230556

Epoch: 5| Step: 4
Training loss: 0.2180506904292837
Validation loss: 2.505482183321969

Epoch: 5| Step: 5
Training loss: 0.16475541382969552
Validation loss: 2.5333257469291413

Epoch: 5| Step: 6
Training loss: 0.4355854137117488
Validation loss: 2.4979600233266073

Epoch: 5| Step: 7
Training loss: 0.23819138442620458
Validation loss: 2.5443563513790872

Epoch: 5| Step: 8
Training loss: 0.1567920402480926
Validation loss: 2.5490356919020574

Epoch: 5| Step: 9
Training loss: 0.22208363535832473
Validation loss: 2.527692026356614

Epoch: 5| Step: 10
Training loss: 0.30739166227635034
Validation loss: 2.532028028031485

Epoch: 482| Step: 0
Training loss: 0.18371552628908677
Validation loss: 2.518459648313841

Epoch: 5| Step: 1
Training loss: 0.17056129442664647
Validation loss: 2.5336624968587014

Epoch: 5| Step: 2
Training loss: 0.16204806972560173
Validation loss: 2.530663883639276

Epoch: 5| Step: 3
Training loss: 0.3463613311007465
Validation loss: 2.5649736851687224

Epoch: 5| Step: 4
Training loss: 0.2953083209594844
Validation loss: 2.559298291176739

Epoch: 5| Step: 5
Training loss: 0.312442273530247
Validation loss: 2.555093309109668

Epoch: 5| Step: 6
Training loss: 0.3124185336736302
Validation loss: 2.5293342757657924

Epoch: 5| Step: 7
Training loss: 0.2397571802003846
Validation loss: 2.535368082399343

Epoch: 5| Step: 8
Training loss: 0.2880273274430547
Validation loss: 2.53964044371657

Epoch: 5| Step: 9
Training loss: 0.20283753888545972
Validation loss: 2.5156495073933978

Epoch: 5| Step: 10
Training loss: 0.2260423641955839
Validation loss: 2.549512961458602

Epoch: 483| Step: 0
Training loss: 0.3315536879322155
Validation loss: 2.53352294419001

Epoch: 5| Step: 1
Training loss: 0.33575984781895774
Validation loss: 2.478995349231999

Epoch: 5| Step: 2
Training loss: 0.308236990302189
Validation loss: 2.48328933423575

Epoch: 5| Step: 3
Training loss: 0.14169365749054078
Validation loss: 2.470641560411464

Epoch: 5| Step: 4
Training loss: 0.2745860229591039
Validation loss: 2.549648379139873

Epoch: 5| Step: 5
Training loss: 0.20887841898804052
Validation loss: 2.5070596793694224

Epoch: 5| Step: 6
Training loss: 0.17819493744473816
Validation loss: 2.484880739149174

Epoch: 5| Step: 7
Training loss: 0.3039461433292413
Validation loss: 2.5446137929868464

Epoch: 5| Step: 8
Training loss: 0.28385421624606105
Validation loss: 2.5574330402197583

Epoch: 5| Step: 9
Training loss: 0.15543161888101795
Validation loss: 2.5009912996844172

Epoch: 5| Step: 10
Training loss: 0.11952958168162033
Validation loss: 2.519492020730457

Epoch: 484| Step: 0
Training loss: 0.1473299859759075
Validation loss: 2.5254487607371883

Epoch: 5| Step: 1
Training loss: 0.33169256776324174
Validation loss: 2.5233194947196167

Epoch: 5| Step: 2
Training loss: 0.1663221782662281
Validation loss: 2.5100343879766265

Epoch: 5| Step: 3
Training loss: 0.1259545891102539
Validation loss: 2.5485156424565907

Epoch: 5| Step: 4
Training loss: 0.15241003428483937
Validation loss: 2.4966184244492675

Epoch: 5| Step: 5
Training loss: 0.28919886903528486
Validation loss: 2.5007133706893305

Epoch: 5| Step: 6
Training loss: 0.26144766646482054
Validation loss: 2.4799051740256473

Epoch: 5| Step: 7
Training loss: 0.35869104150119496
Validation loss: 2.445919050358978

Epoch: 5| Step: 8
Training loss: 0.17564070168995666
Validation loss: 2.4504906705670564

Epoch: 5| Step: 9
Training loss: 0.2040806079675777
Validation loss: 2.4506463824039737

Epoch: 5| Step: 10
Training loss: 0.40276982607428036
Validation loss: 2.458339405069697

Epoch: 485| Step: 0
Training loss: 0.33301407704655583
Validation loss: 2.4699677267478317

Epoch: 5| Step: 1
Training loss: 0.24659901173355686
Validation loss: 2.453384823530768

Epoch: 5| Step: 2
Training loss: 0.24710816255525886
Validation loss: 2.4874211548303715

Epoch: 5| Step: 3
Training loss: 0.329660614327595
Validation loss: 2.480488390106383

Epoch: 5| Step: 4
Training loss: 0.2215280224078936
Validation loss: 2.502466250716725

Epoch: 5| Step: 5
Training loss: 0.28550589041637675
Validation loss: 2.5062979606569042

Epoch: 5| Step: 6
Training loss: 0.16990616057068908
Validation loss: 2.5155173138332674

Epoch: 5| Step: 7
Training loss: 0.17171758791050432
Validation loss: 2.537431321628366

Epoch: 5| Step: 8
Training loss: 0.11551796237392437
Validation loss: 2.5430602471534174

Epoch: 5| Step: 9
Training loss: 0.3491080648485329
Validation loss: 2.520863450379869

Epoch: 5| Step: 10
Training loss: 0.19100384354094457
Validation loss: 2.4850910718395083

Epoch: 486| Step: 0
Training loss: 0.12442957468507344
Validation loss: 2.500073774336222

Epoch: 5| Step: 1
Training loss: 0.27819194845166595
Validation loss: 2.4854845507786005

Epoch: 5| Step: 2
Training loss: 0.3524651489547357
Validation loss: 2.452713377370626

Epoch: 5| Step: 3
Training loss: 0.24728590714856083
Validation loss: 2.4710476662107412

Epoch: 5| Step: 4
Training loss: 0.13484230486072218
Validation loss: 2.4675328899525937

Epoch: 5| Step: 5
Training loss: 0.33743216442151075
Validation loss: 2.4709305329430156

Epoch: 5| Step: 6
Training loss: 0.15972241514535207
Validation loss: 2.476115031985082

Epoch: 5| Step: 7
Training loss: 0.28465471187757685
Validation loss: 2.4857312947305967

Epoch: 5| Step: 8
Training loss: 0.3217895690725789
Validation loss: 2.512875634564456

Epoch: 5| Step: 9
Training loss: 0.3154433752343826
Validation loss: 2.565559548586608

Epoch: 5| Step: 10
Training loss: 0.16784576415765934
Validation loss: 2.556794816381995

Epoch: 487| Step: 0
Training loss: 0.3433486372621646
Validation loss: 2.506167858267953

Epoch: 5| Step: 1
Training loss: 0.21224220640905767
Validation loss: 2.51782208985863

Epoch: 5| Step: 2
Training loss: 0.3749280701634358
Validation loss: 2.496931713745169

Epoch: 5| Step: 3
Training loss: 0.11974046137973021
Validation loss: 2.470237010467519

Epoch: 5| Step: 4
Training loss: 0.19923268063775884
Validation loss: 2.4990620122458203

Epoch: 5| Step: 5
Training loss: 0.24161948998686564
Validation loss: 2.46655551557563

Epoch: 5| Step: 6
Training loss: 0.23296674604724518
Validation loss: 2.516855272148513

Epoch: 5| Step: 7
Training loss: 0.15752930253165842
Validation loss: 2.524774332723407

Epoch: 5| Step: 8
Training loss: 0.221487474503939
Validation loss: 2.538964906493928

Epoch: 5| Step: 9
Training loss: 0.29264232252049127
Validation loss: 2.5084887667949207

Epoch: 5| Step: 10
Training loss: 0.2515499526502079
Validation loss: 2.49841368605004

Epoch: 488| Step: 0
Training loss: 0.16708275084877589
Validation loss: 2.5075363054623296

Epoch: 5| Step: 1
Training loss: 0.27552589178699893
Validation loss: 2.4854288134439537

Epoch: 5| Step: 2
Training loss: 0.3034354183703128
Validation loss: 2.4796585280332657

Epoch: 5| Step: 3
Training loss: 0.27196156121297205
Validation loss: 2.485313432802593

Epoch: 5| Step: 4
Training loss: 0.21141012543469265
Validation loss: 2.478299832587846

Epoch: 5| Step: 5
Training loss: 0.2880305091423745
Validation loss: 2.499459715369219

Epoch: 5| Step: 6
Training loss: 0.16475258177331992
Validation loss: 2.4904268428217664

Epoch: 5| Step: 7
Training loss: 0.1577307631072938
Validation loss: 2.455001574157968

Epoch: 5| Step: 8
Training loss: 0.29658183881937417
Validation loss: 2.4887234196462833

Epoch: 5| Step: 9
Training loss: 0.1716389226850739
Validation loss: 2.5218561819968186

Epoch: 5| Step: 10
Training loss: 0.36043977562278773
Validation loss: 2.543327081357827

Epoch: 489| Step: 0
Training loss: 0.14800691266565338
Validation loss: 2.5026028916432734

Epoch: 5| Step: 1
Training loss: 0.3279975234772649
Validation loss: 2.5076923507058178

Epoch: 5| Step: 2
Training loss: 0.194793507538391
Validation loss: 2.5211555141508226

Epoch: 5| Step: 3
Training loss: 0.2953667600929654
Validation loss: 2.526481162072858

Epoch: 5| Step: 4
Training loss: 0.2778719586743481
Validation loss: 2.5137237944533526

Epoch: 5| Step: 5
Training loss: 0.24397032329295862
Validation loss: 2.484490152327998

Epoch: 5| Step: 6
Training loss: 0.1663670130932752
Validation loss: 2.511899659102204

Epoch: 5| Step: 7
Training loss: 0.29004985134211037
Validation loss: 2.467159335643607

Epoch: 5| Step: 8
Training loss: 0.1803931292512456
Validation loss: 2.4709896148687704

Epoch: 5| Step: 9
Training loss: 0.1969777073966658
Validation loss: 2.4779778147403726

Epoch: 5| Step: 10
Training loss: 0.37689726420568753
Validation loss: 2.4978732327789457

Epoch: 490| Step: 0
Training loss: 0.15710972656445882
Validation loss: 2.4995461236502865

Epoch: 5| Step: 1
Training loss: 0.2987688915911421
Validation loss: 2.4694910688233014

Epoch: 5| Step: 2
Training loss: 0.3115100319587914
Validation loss: 2.481821051903644

Epoch: 5| Step: 3
Training loss: 0.1958640892821778
Validation loss: 2.4571083677953367

Epoch: 5| Step: 4
Training loss: 0.22653875555380815
Validation loss: 2.459786514486678

Epoch: 5| Step: 5
Training loss: 0.261706081482321
Validation loss: 2.4875363789643434

Epoch: 5| Step: 6
Training loss: 0.2530490196068839
Validation loss: 2.4965225481260593

Epoch: 5| Step: 7
Training loss: 0.3249015168299011
Validation loss: 2.4782547194228113

Epoch: 5| Step: 8
Training loss: 0.12992587845506987
Validation loss: 2.5443159461232114

Epoch: 5| Step: 9
Training loss: 0.3158019853793447
Validation loss: 2.5301314951119696

Epoch: 5| Step: 10
Training loss: 0.14236824055267425
Validation loss: 2.5425035909956324

Epoch: 491| Step: 0
Training loss: 0.30947048852172765
Validation loss: 2.55200195249715

Epoch: 5| Step: 1
Training loss: 0.15883042335254607
Validation loss: 2.535974963927817

Epoch: 5| Step: 2
Training loss: 0.22390196149915842
Validation loss: 2.5292878318375047

Epoch: 5| Step: 3
Training loss: 0.1413882918572681
Validation loss: 2.4820018311699603

Epoch: 5| Step: 4
Training loss: 0.20999799889224155
Validation loss: 2.478074219237735

Epoch: 5| Step: 5
Training loss: 0.38041843418422405
Validation loss: 2.4700037108178354

Epoch: 5| Step: 6
Training loss: 0.25965507564263046
Validation loss: 2.433453904166853

Epoch: 5| Step: 7
Training loss: 0.22272218597949617
Validation loss: 2.4845093979499095

Epoch: 5| Step: 8
Training loss: 0.1705738418253107
Validation loss: 2.502704751297159

Epoch: 5| Step: 9
Training loss: 0.33571782803224665
Validation loss: 2.5178752392170716

Epoch: 5| Step: 10
Training loss: 0.28738359084859383
Validation loss: 2.5890553267818452

Epoch: 492| Step: 0
Training loss: 0.27021214270473926
Validation loss: 2.544557109667621

Epoch: 5| Step: 1
Training loss: 0.2723737460943931
Validation loss: 2.560051998025653

Epoch: 5| Step: 2
Training loss: 0.16246500991116092
Validation loss: 2.5169351221336087

Epoch: 5| Step: 3
Training loss: 0.2583766890619635
Validation loss: 2.554560417031708

Epoch: 5| Step: 4
Training loss: 0.20799729943012424
Validation loss: 2.5137504717502184

Epoch: 5| Step: 5
Training loss: 0.24708983755047612
Validation loss: 2.5245135244498096

Epoch: 5| Step: 6
Training loss: 0.33172485575939115
Validation loss: 2.5072017239358204

Epoch: 5| Step: 7
Training loss: 0.326233304115393
Validation loss: 2.5102950175456646

Epoch: 5| Step: 8
Training loss: 0.23143430273210228
Validation loss: 2.5131348483905493

Epoch: 5| Step: 9
Training loss: 0.19191594283450147
Validation loss: 2.483122592690694

Epoch: 5| Step: 10
Training loss: 0.1553470628953398
Validation loss: 2.484939225802804

Epoch: 493| Step: 0
Training loss: 0.2198785552864572
Validation loss: 2.5033770578834584

Epoch: 5| Step: 1
Training loss: 0.27474035772181327
Validation loss: 2.4789066117982625

Epoch: 5| Step: 2
Training loss: 0.24896492364106604
Validation loss: 2.490983271209932

Epoch: 5| Step: 3
Training loss: 0.3070957184100881
Validation loss: 2.473811220070655

Epoch: 5| Step: 4
Training loss: 0.12089386717210791
Validation loss: 2.48078622411713

Epoch: 5| Step: 5
Training loss: 0.20563326584223354
Validation loss: 2.5023779624341898

Epoch: 5| Step: 6
Training loss: 0.20402804789263068
Validation loss: 2.4925231306410005

Epoch: 5| Step: 7
Training loss: 0.32130142234519476
Validation loss: 2.488456459629691

Epoch: 5| Step: 8
Training loss: 0.23625499602742117
Validation loss: 2.476870335128192

Epoch: 5| Step: 9
Training loss: 0.14834116017885698
Validation loss: 2.4805500089877675

Epoch: 5| Step: 10
Training loss: 0.3186934304060574
Validation loss: 2.4855164188728893

Epoch: 494| Step: 0
Training loss: 0.2063459714937194
Validation loss: 2.497228487979447

Epoch: 5| Step: 1
Training loss: 0.10895231435083849
Validation loss: 2.510540061337977

Epoch: 5| Step: 2
Training loss: 0.25621894148107477
Validation loss: 2.5309443338000044

Epoch: 5| Step: 3
Training loss: 0.3131114104552331
Validation loss: 2.545137513443437

Epoch: 5| Step: 4
Training loss: 0.2158370809815764
Validation loss: 2.578830892580439

Epoch: 5| Step: 5
Training loss: 0.2807886790724068
Validation loss: 2.6031405869277915

Epoch: 5| Step: 6
Training loss: 0.20407284073676277
Validation loss: 2.5564320820923183

Epoch: 5| Step: 7
Training loss: 0.26909967783692806
Validation loss: 2.5589769797976585

Epoch: 5| Step: 8
Training loss: 0.3299683834232491
Validation loss: 2.5550505080511687

Epoch: 5| Step: 9
Training loss: 0.2168607961224815
Validation loss: 2.5302553733210975

Epoch: 5| Step: 10
Training loss: 0.204085280941691
Validation loss: 2.4768891876510652

Epoch: 495| Step: 0
Training loss: 0.3455560877980048
Validation loss: 2.5130442642087876

Epoch: 5| Step: 1
Training loss: 0.2991468313255287
Validation loss: 2.468711598311678

Epoch: 5| Step: 2
Training loss: 0.2101710842526927
Validation loss: 2.4927383695091163

Epoch: 5| Step: 3
Training loss: 0.17911456860624228
Validation loss: 2.449031687075009

Epoch: 5| Step: 4
Training loss: 0.2776244314764145
Validation loss: 2.4499490742249046

Epoch: 5| Step: 5
Training loss: 0.23883737485653445
Validation loss: 2.4896863608079656

Epoch: 5| Step: 6
Training loss: 0.3259114922180443
Validation loss: 2.4954311522252177

Epoch: 5| Step: 7
Training loss: 0.17177979585199699
Validation loss: 2.5000985218446803

Epoch: 5| Step: 8
Training loss: 0.16112003275736758
Validation loss: 2.523774826781862

Epoch: 5| Step: 9
Training loss: 0.18673292848392092
Validation loss: 2.4494413516194165

Epoch: 5| Step: 10
Training loss: 0.20472706310470856
Validation loss: 2.4853786887442437

Epoch: 496| Step: 0
Training loss: 0.15831398317611378
Validation loss: 2.490742810933169

Epoch: 5| Step: 1
Training loss: 0.1428079712064104
Validation loss: 2.505005579337111

Epoch: 5| Step: 2
Training loss: 0.23165483286419128
Validation loss: 2.5014500688734063

Epoch: 5| Step: 3
Training loss: 0.2143949676478649
Validation loss: 2.4721782677038977

Epoch: 5| Step: 4
Training loss: 0.30406943012428156
Validation loss: 2.463608641187653

Epoch: 5| Step: 5
Training loss: 0.1899250876666137
Validation loss: 2.4707496263527404

Epoch: 5| Step: 6
Training loss: 0.1796031422174504
Validation loss: 2.4786712158826707

Epoch: 5| Step: 7
Training loss: 0.30125960174470023
Validation loss: 2.5108693839299208

Epoch: 5| Step: 8
Training loss: 0.3238561740042896
Validation loss: 2.5133936968459363

Epoch: 5| Step: 9
Training loss: 0.25296040941217035
Validation loss: 2.5220559664740687

Epoch: 5| Step: 10
Training loss: 0.3491652240738547
Validation loss: 2.499066336418965

Epoch: 497| Step: 0
Training loss: 0.22853812082531086
Validation loss: 2.4801800505011307

Epoch: 5| Step: 1
Training loss: 0.1954208169037547
Validation loss: 2.456430881276401

Epoch: 5| Step: 2
Training loss: 0.33143454395395233
Validation loss: 2.4520321942184515

Epoch: 5| Step: 3
Training loss: 0.2543821423345637
Validation loss: 2.4244992538065366

Epoch: 5| Step: 4
Training loss: 0.1858231645757766
Validation loss: 2.4334520863540887

Epoch: 5| Step: 5
Training loss: 0.23624832603073465
Validation loss: 2.4307700672993797

Epoch: 5| Step: 6
Training loss: 0.2456603699860197
Validation loss: 2.4193547966317888

Epoch: 5| Step: 7
Training loss: 0.2181670049538939
Validation loss: 2.4215366049048095

Epoch: 5| Step: 8
Training loss: 0.19807691214643694
Validation loss: 2.449391162412481

Epoch: 5| Step: 9
Training loss: 0.329545205943543
Validation loss: 2.4746009597371708

Epoch: 5| Step: 10
Training loss: 0.16810774042742624
Validation loss: 2.4736442686942337

Epoch: 498| Step: 0
Training loss: 0.2750139568861926
Validation loss: 2.48196570549808

Epoch: 5| Step: 1
Training loss: 0.21265321144999513
Validation loss: 2.497940042334643

Epoch: 5| Step: 2
Training loss: 0.21565599356993845
Validation loss: 2.5022684285916403

Epoch: 5| Step: 3
Training loss: 0.13368100306269506
Validation loss: 2.5059337144403777

Epoch: 5| Step: 4
Training loss: 0.3330398499412116
Validation loss: 2.507663041910079

Epoch: 5| Step: 5
Training loss: 0.14193628147195142
Validation loss: 2.4813725753738836

Epoch: 5| Step: 6
Training loss: 0.2404242904639923
Validation loss: 2.4429649992893747

Epoch: 5| Step: 7
Training loss: 0.353842968367229
Validation loss: 2.429039532050621

Epoch: 5| Step: 8
Training loss: 0.27606000779356765
Validation loss: 2.436220621598299

Epoch: 5| Step: 9
Training loss: 0.1710035600235883
Validation loss: 2.4171349839361707

Epoch: 5| Step: 10
Training loss: 0.17603426314385248
Validation loss: 2.4430812865220557

Epoch: 499| Step: 0
Training loss: 0.18884097827731308
Validation loss: 2.4395615195412157

Epoch: 5| Step: 1
Training loss: 0.2602327635230471
Validation loss: 2.4701420224152164

Epoch: 5| Step: 2
Training loss: 0.3099053191755417
Validation loss: 2.4918890215083254

Epoch: 5| Step: 3
Training loss: 0.2677327982909252
Validation loss: 2.5252690065445194

Epoch: 5| Step: 4
Training loss: 0.19394888744920233
Validation loss: 2.526685581949262

Epoch: 5| Step: 5
Training loss: 0.279454180294494
Validation loss: 2.516798223907364

Epoch: 5| Step: 6
Training loss: 0.21177160511229598
Validation loss: 2.5046342556061574

Epoch: 5| Step: 7
Training loss: 0.19371041308803388
Validation loss: 2.53542532858732

Epoch: 5| Step: 8
Training loss: 0.3070940322362275
Validation loss: 2.525554743425171

Epoch: 5| Step: 9
Training loss: 0.17313681519124857
Validation loss: 2.548744635243365

Epoch: 5| Step: 10
Training loss: 0.22770141572440955
Validation loss: 2.544605985025787

Epoch: 500| Step: 0
Training loss: 0.3026575052435215
Validation loss: 2.536393882483633

Epoch: 5| Step: 1
Training loss: 0.17070095095788587
Validation loss: 2.5543312460826737

Epoch: 5| Step: 2
Training loss: 0.21709167781712319
Validation loss: 2.5390425547028594

Epoch: 5| Step: 3
Training loss: 0.20971775609819557
Validation loss: 2.5253423452015222

Epoch: 5| Step: 4
Training loss: 0.2060970787086087
Validation loss: 2.4764286604323416

Epoch: 5| Step: 5
Training loss: 0.20093071936502557
Validation loss: 2.4860203426355314

Epoch: 5| Step: 6
Training loss: 0.24821940751980992
Validation loss: 2.4718136452289308

Epoch: 5| Step: 7
Training loss: 0.24154210233991796
Validation loss: 2.4469450359992178

Epoch: 5| Step: 8
Training loss: 0.2682744037418922
Validation loss: 2.457892342028333

Epoch: 5| Step: 9
Training loss: 0.20461866590009414
Validation loss: 2.4743088216299385

Epoch: 5| Step: 10
Training loss: 0.3092104146488368
Validation loss: 2.4746961345566802

Epoch: 501| Step: 0
Training loss: 0.3423130388643942
Validation loss: 2.4898512192384006

Epoch: 5| Step: 1
Training loss: 0.3134253391709797
Validation loss: 2.541841449171248

Epoch: 5| Step: 2
Training loss: 0.23966880065161797
Validation loss: 2.5104863298367066

Epoch: 5| Step: 3
Training loss: 0.13772531953493444
Validation loss: 2.5653798927659612

Epoch: 5| Step: 4
Training loss: 0.24628876724648985
Validation loss: 2.5558141531019074

Epoch: 5| Step: 5
Training loss: 0.18936461908070226
Validation loss: 2.541104331329175

Epoch: 5| Step: 6
Training loss: 0.11345905293616924
Validation loss: 2.5841853304443614

Epoch: 5| Step: 7
Training loss: 0.33354202334027316
Validation loss: 2.5597947720508447

Epoch: 5| Step: 8
Training loss: 0.11414932741310803
Validation loss: 2.5545387200909944

Epoch: 5| Step: 9
Training loss: 0.1712363363126342
Validation loss: 2.5864131985517274

Epoch: 5| Step: 10
Training loss: 0.24463019304070324
Validation loss: 2.5752405591678267

Epoch: 502| Step: 0
Training loss: 0.2174550967068512
Validation loss: 2.5648066235945617

Epoch: 5| Step: 1
Training loss: 0.24535152738364724
Validation loss: 2.573451035299587

Epoch: 5| Step: 2
Training loss: 0.1386157782013808
Validation loss: 2.503528940698212

Epoch: 5| Step: 3
Training loss: 0.2313616637678789
Validation loss: 2.4476905625823098

Epoch: 5| Step: 4
Training loss: 0.241691982276554
Validation loss: 2.4726115470904

Epoch: 5| Step: 5
Training loss: 0.12963254378897926
Validation loss: 2.44392775534349

Epoch: 5| Step: 6
Training loss: 0.25388984627187267
Validation loss: 2.433425226708522

Epoch: 5| Step: 7
Training loss: 0.19483540438328206
Validation loss: 2.4809947603262326

Epoch: 5| Step: 8
Training loss: 0.3604101531408553
Validation loss: 2.4773143671091633

Epoch: 5| Step: 9
Training loss: 0.21349826329002855
Validation loss: 2.488159850532912

Epoch: 5| Step: 10
Training loss: 0.344073522652773
Validation loss: 2.479773379883545

Epoch: 503| Step: 0
Training loss: 0.2061948435176103
Validation loss: 2.515942093890649

Epoch: 5| Step: 1
Training loss: 0.2163584029671118
Validation loss: 2.5002682675226438

Epoch: 5| Step: 2
Training loss: 0.18200986515545906
Validation loss: 2.516662655744132

Epoch: 5| Step: 3
Training loss: 0.1833028009757627
Validation loss: 2.5233401627039815

Epoch: 5| Step: 4
Training loss: 0.2831639229838201
Validation loss: 2.5453683329966665

Epoch: 5| Step: 5
Training loss: 0.2894326752351344
Validation loss: 2.484174840934404

Epoch: 5| Step: 6
Training loss: 0.30997618533767046
Validation loss: 2.5153686101323696

Epoch: 5| Step: 7
Training loss: 0.25280288699231646
Validation loss: 2.4710229753117603

Epoch: 5| Step: 8
Training loss: 0.22636817128820969
Validation loss: 2.525127374739498

Epoch: 5| Step: 9
Training loss: 0.2402836198653925
Validation loss: 2.523906327303745

Epoch: 5| Step: 10
Training loss: 0.19474586306990518
Validation loss: 2.539258673751228

Epoch: 504| Step: 0
Training loss: 0.23192112939369458
Validation loss: 2.530651960237848

Epoch: 5| Step: 1
Training loss: 0.30258152702501195
Validation loss: 2.5258892995697044

Epoch: 5| Step: 2
Training loss: 0.11271422391121842
Validation loss: 2.5175588445029304

Epoch: 5| Step: 3
Training loss: 0.1595416779897534
Validation loss: 2.518901975624898

Epoch: 5| Step: 4
Training loss: 0.26481306579093644
Validation loss: 2.5370625317890236

Epoch: 5| Step: 5
Training loss: 0.3340792716324074
Validation loss: 2.5265689612007103

Epoch: 5| Step: 6
Training loss: 0.21203488540062873
Validation loss: 2.4884497145573254

Epoch: 5| Step: 7
Training loss: 0.14046566599132596
Validation loss: 2.460169569065217

Epoch: 5| Step: 8
Training loss: 0.2999452764548694
Validation loss: 2.4811336877627754

Epoch: 5| Step: 9
Training loss: 0.15176321336716644
Validation loss: 2.480642367781894

Epoch: 5| Step: 10
Training loss: 0.15157218710429915
Validation loss: 2.478590742144448

Epoch: 505| Step: 0
Training loss: 0.2805701622344744
Validation loss: 2.533220373732169

Epoch: 5| Step: 1
Training loss: 0.2186505653680444
Validation loss: 2.510395465758414

Epoch: 5| Step: 2
Training loss: 0.1988228341918168
Validation loss: 2.4971393287224264

Epoch: 5| Step: 3
Training loss: 0.1905302515790525
Validation loss: 2.489301770545061

Epoch: 5| Step: 4
Training loss: 0.23754015570528425
Validation loss: 2.4601276524255913

Epoch: 5| Step: 5
Training loss: 0.37263086100527437
Validation loss: 2.423427304222059

Epoch: 5| Step: 6
Training loss: 0.21714337470158315
Validation loss: 2.4537593992360827

Epoch: 5| Step: 7
Training loss: 0.20118350393516485
Validation loss: 2.479440901588084

Epoch: 5| Step: 8
Training loss: 0.23058001208685092
Validation loss: 2.509252233654803

Epoch: 5| Step: 9
Training loss: 0.13092449333030237
Validation loss: 2.5316874942453302

Epoch: 5| Step: 10
Training loss: 0.2581060068194886
Validation loss: 2.531463318321771

Epoch: 506| Step: 0
Training loss: 0.3434485392406008
Validation loss: 2.5345802564801674

Epoch: 5| Step: 1
Training loss: 0.212473933991396
Validation loss: 2.5416929209008985

Epoch: 5| Step: 2
Training loss: 0.18631803977111536
Validation loss: 2.517606611679448

Epoch: 5| Step: 3
Training loss: 0.12656478173353705
Validation loss: 2.521296269917044

Epoch: 5| Step: 4
Training loss: 0.2987349371125417
Validation loss: 2.450834287569111

Epoch: 5| Step: 5
Training loss: 0.24239332159407925
Validation loss: 2.470069623427298

Epoch: 5| Step: 6
Training loss: 0.19804746714245758
Validation loss: 2.433691505522031

Epoch: 5| Step: 7
Training loss: 0.18780951979965482
Validation loss: 2.460945798433776

Epoch: 5| Step: 8
Training loss: 0.28007820852962084
Validation loss: 2.4485498128375336

Epoch: 5| Step: 9
Training loss: 0.15023601932786246
Validation loss: 2.5240909811351937

Epoch: 5| Step: 10
Training loss: 0.30252061495801413
Validation loss: 2.5084148423855503

Epoch: 507| Step: 0
Training loss: 0.3196137063071658
Validation loss: 2.5642440947257485

Epoch: 5| Step: 1
Training loss: 0.20267705860527616
Validation loss: 2.57916246746793

Epoch: 5| Step: 2
Training loss: 0.1595285839676277
Validation loss: 2.586193677139773

Epoch: 5| Step: 3
Training loss: 0.2786362845427655
Validation loss: 2.5629319245397992

Epoch: 5| Step: 4
Training loss: 0.2904385727611585
Validation loss: 2.4828564427180964

Epoch: 5| Step: 5
Training loss: 0.2550097328553854
Validation loss: 2.4811043746979475

Epoch: 5| Step: 6
Training loss: 0.31721532070127767
Validation loss: 2.4666142912372977

Epoch: 5| Step: 7
Training loss: 0.1947560489869573
Validation loss: 2.475582301613746

Epoch: 5| Step: 8
Training loss: 0.2846707299754524
Validation loss: 2.4745413849080475

Epoch: 5| Step: 9
Training loss: 0.22685228100038304
Validation loss: 2.5063080503193165

Epoch: 5| Step: 10
Training loss: 0.1683423080113488
Validation loss: 2.532698343146287

Epoch: 508| Step: 0
Training loss: 0.21480228717556815
Validation loss: 2.576594934152584

Epoch: 5| Step: 1
Training loss: 0.24674015074352101
Validation loss: 2.5636051035041

Epoch: 5| Step: 2
Training loss: 0.18023799452766415
Validation loss: 2.574394614315159

Epoch: 5| Step: 3
Training loss: 0.2768922004351365
Validation loss: 2.5170308992534762

Epoch: 5| Step: 4
Training loss: 0.24736967534092866
Validation loss: 2.508565644009794

Epoch: 5| Step: 5
Training loss: 0.22064925692619233
Validation loss: 2.474518553294355

Epoch: 5| Step: 6
Training loss: 0.27409812958801827
Validation loss: 2.411669844631034

Epoch: 5| Step: 7
Training loss: 0.13091689596372583
Validation loss: 2.4240544743553576

Epoch: 5| Step: 8
Training loss: 0.31936848325855405
Validation loss: 2.4092982922676853

Epoch: 5| Step: 9
Training loss: 0.24208489674956823
Validation loss: 2.4216934755316677

Epoch: 5| Step: 10
Training loss: 0.36653176051145014
Validation loss: 2.467641425520511

Epoch: 509| Step: 0
Training loss: 0.19152056919652188
Validation loss: 2.545681086061247

Epoch: 5| Step: 1
Training loss: 0.34461118372042754
Validation loss: 2.5666799061783596

Epoch: 5| Step: 2
Training loss: 0.3542798670142554
Validation loss: 2.5831631061215297

Epoch: 5| Step: 3
Training loss: 0.2410530082979195
Validation loss: 2.535424799008749

Epoch: 5| Step: 4
Training loss: 0.22861548630059594
Validation loss: 2.473297200919004

Epoch: 5| Step: 5
Training loss: 0.24627184856860518
Validation loss: 2.4693475936918716

Epoch: 5| Step: 6
Training loss: 0.2678760624062123
Validation loss: 2.4137727721731705

Epoch: 5| Step: 7
Training loss: 0.27740667193519175
Validation loss: 2.4534402799747768

Epoch: 5| Step: 8
Training loss: 0.18311100252054652
Validation loss: 2.457461679335288

Epoch: 5| Step: 9
Training loss: 0.16370547138719713
Validation loss: 2.479991244888796

Epoch: 5| Step: 10
Training loss: 0.24679273912829133
Validation loss: 2.5430755187048564

Epoch: 510| Step: 0
Training loss: 0.33188835884047196
Validation loss: 2.602917572381515

Epoch: 5| Step: 1
Training loss: 0.3603945037150137
Validation loss: 2.5735052617154026

Epoch: 5| Step: 2
Training loss: 0.21122779121412621
Validation loss: 2.498870434454535

Epoch: 5| Step: 3
Training loss: 0.33370013718183544
Validation loss: 2.435838966108278

Epoch: 5| Step: 4
Training loss: 0.29278570178748853
Validation loss: 2.4445324097425725

Epoch: 5| Step: 5
Training loss: 0.2201077947499599
Validation loss: 2.3952318864209476

Epoch: 5| Step: 6
Training loss: 0.24247402500619683
Validation loss: 2.4445564353747504

Epoch: 5| Step: 7
Training loss: 0.2627948019530091
Validation loss: 2.4297450820825492

Epoch: 5| Step: 8
Training loss: 0.20805345849318804
Validation loss: 2.448235282157016

Epoch: 5| Step: 9
Training loss: 0.13692846562570657
Validation loss: 2.4722780408438236

Epoch: 5| Step: 10
Training loss: 0.15042445805448668
Validation loss: 2.5086061708319214

Epoch: 511| Step: 0
Training loss: 0.17065311808035738
Validation loss: 2.493716491709307

Epoch: 5| Step: 1
Training loss: 0.3114393951990689
Validation loss: 2.496638609063692

Epoch: 5| Step: 2
Training loss: 0.216783694992146
Validation loss: 2.484484814005741

Epoch: 5| Step: 3
Training loss: 0.1969076439875189
Validation loss: 2.435800577853726

Epoch: 5| Step: 4
Training loss: 0.2477466839319176
Validation loss: 2.4378434920734855

Epoch: 5| Step: 5
Training loss: 0.22781808469543907
Validation loss: 2.4595528781373113

Epoch: 5| Step: 6
Training loss: 0.277927080733298
Validation loss: 2.5128569076675866

Epoch: 5| Step: 7
Training loss: 0.3525461846052248
Validation loss: 2.531247182399124

Epoch: 5| Step: 8
Training loss: 0.22707440653295766
Validation loss: 2.5212336162839497

Epoch: 5| Step: 9
Training loss: 0.2805676394846096
Validation loss: 2.5455838026981534

Epoch: 5| Step: 10
Training loss: 0.2188916514073954
Validation loss: 2.539432514702524

Epoch: 512| Step: 0
Training loss: 0.18490051321814113
Validation loss: 2.489742749348578

Epoch: 5| Step: 1
Training loss: 0.27224594439138383
Validation loss: 2.4891157630673315

Epoch: 5| Step: 2
Training loss: 0.16618331406196796
Validation loss: 2.4711790584371913

Epoch: 5| Step: 3
Training loss: 0.23375303872066158
Validation loss: 2.4546946774678817

Epoch: 5| Step: 4
Training loss: 0.24444215845640027
Validation loss: 2.438621481765971

Epoch: 5| Step: 5
Training loss: 0.31611031951318197
Validation loss: 2.394127838932794

Epoch: 5| Step: 6
Training loss: 0.19370689374022673
Validation loss: 2.486481456479897

Epoch: 5| Step: 7
Training loss: 0.2528842752700676
Validation loss: 2.5192521191455355

Epoch: 5| Step: 8
Training loss: 0.27135313415819035
Validation loss: 2.594602595686638

Epoch: 5| Step: 9
Training loss: 0.24646867469321157
Validation loss: 2.6060890679042163

Epoch: 5| Step: 10
Training loss: 0.24240786771048853
Validation loss: 2.57286262895535

Epoch: 513| Step: 0
Training loss: 0.16935204733981413
Validation loss: 2.5802202328973274

Epoch: 5| Step: 1
Training loss: 0.35316981478541104
Validation loss: 2.566112790783011

Epoch: 5| Step: 2
Training loss: 0.23389051748866171
Validation loss: 2.5035056607287904

Epoch: 5| Step: 3
Training loss: 0.16159860736891885
Validation loss: 2.473646078216714

Epoch: 5| Step: 4
Training loss: 0.17541881920889973
Validation loss: 2.4706120598232415

Epoch: 5| Step: 5
Training loss: 0.23495950928315018
Validation loss: 2.446549460067677

Epoch: 5| Step: 6
Training loss: 0.29036372089115353
Validation loss: 2.440166177418165

Epoch: 5| Step: 7
Training loss: 0.1343597090138386
Validation loss: 2.5189234670870753

Epoch: 5| Step: 8
Training loss: 0.3272167533031782
Validation loss: 2.555593500982134

Epoch: 5| Step: 9
Training loss: 0.11586740752096315
Validation loss: 2.565710603070467

Epoch: 5| Step: 10
Training loss: 0.2569215291060423
Validation loss: 2.5779057652844624

Epoch: 514| Step: 0
Training loss: 0.21035915137922762
Validation loss: 2.5737347115479228

Epoch: 5| Step: 1
Training loss: 0.19357501634378227
Validation loss: 2.5369695076899297

Epoch: 5| Step: 2
Training loss: 0.2594087199617529
Validation loss: 2.4856683500619705

Epoch: 5| Step: 3
Training loss: 0.1593423375151073
Validation loss: 2.484604543260203

Epoch: 5| Step: 4
Training loss: 0.22320016714131685
Validation loss: 2.485274235916027

Epoch: 5| Step: 5
Training loss: 0.3138975127595868
Validation loss: 2.45959219204089

Epoch: 5| Step: 6
Training loss: 0.1628436384425772
Validation loss: 2.4514455936205617

Epoch: 5| Step: 7
Training loss: 0.35011002054553764
Validation loss: 2.473792386061863

Epoch: 5| Step: 8
Training loss: 0.13435857223295766
Validation loss: 2.466762413453403

Epoch: 5| Step: 9
Training loss: 0.11916653554610172
Validation loss: 2.4825482908672742

Epoch: 5| Step: 10
Training loss: 0.30755270630302073
Validation loss: 2.484936279347647

Epoch: 515| Step: 0
Training loss: 0.22973507952781547
Validation loss: 2.542752410420201

Epoch: 5| Step: 1
Training loss: 0.2978655452260277
Validation loss: 2.5508123759407564

Epoch: 5| Step: 2
Training loss: 0.16667813333663348
Validation loss: 2.5103172766280304

Epoch: 5| Step: 3
Training loss: 0.18131596252859172
Validation loss: 2.507966618591969

Epoch: 5| Step: 4
Training loss: 0.190277087372976
Validation loss: 2.4723359639431552

Epoch: 5| Step: 5
Training loss: 0.25141254362641646
Validation loss: 2.4733310692241166

Epoch: 5| Step: 6
Training loss: 0.260186220567734
Validation loss: 2.4823815862960252

Epoch: 5| Step: 7
Training loss: 0.30201036569508966
Validation loss: 2.45238229264551

Epoch: 5| Step: 8
Training loss: 0.2003241705805057
Validation loss: 2.4716205681338335

Epoch: 5| Step: 9
Training loss: 0.1714162230567805
Validation loss: 2.51909982266298

Epoch: 5| Step: 10
Training loss: 0.34826508263311207
Validation loss: 2.535079021760599

Epoch: 516| Step: 0
Training loss: 0.22786760146549143
Validation loss: 2.525192861705793

Epoch: 5| Step: 1
Training loss: 0.32303359109303853
Validation loss: 2.5205540347651536

Epoch: 5| Step: 2
Training loss: 0.20923801431716305
Validation loss: 2.4898640783301293

Epoch: 5| Step: 3
Training loss: 0.2849555158197394
Validation loss: 2.431536071482656

Epoch: 5| Step: 4
Training loss: 0.26445018197567444
Validation loss: 2.397857329694453

Epoch: 5| Step: 5
Training loss: 0.17717970768716348
Validation loss: 2.4107885113273073

Epoch: 5| Step: 6
Training loss: 0.17743538241115459
Validation loss: 2.425566983920066

Epoch: 5| Step: 7
Training loss: 0.23174029677744729
Validation loss: 2.473224483297765

Epoch: 5| Step: 8
Training loss: 0.15454426983485048
Validation loss: 2.5044931192369124

Epoch: 5| Step: 9
Training loss: 0.27846958106165987
Validation loss: 2.4969321346988402

Epoch: 5| Step: 10
Training loss: 0.3095910339159317
Validation loss: 2.5365909958559647

Epoch: 517| Step: 0
Training loss: 0.254700972194898
Validation loss: 2.5209335170626272

Epoch: 5| Step: 1
Training loss: 0.13952742181547917
Validation loss: 2.499475006641676

Epoch: 5| Step: 2
Training loss: 0.19380235502994078
Validation loss: 2.44515460373191

Epoch: 5| Step: 3
Training loss: 0.22586122040339415
Validation loss: 2.4897534039492277

Epoch: 5| Step: 4
Training loss: 0.3143309243211198
Validation loss: 2.4732791004908012

Epoch: 5| Step: 5
Training loss: 0.31638489168394196
Validation loss: 2.439459878125015

Epoch: 5| Step: 6
Training loss: 0.26324370198536595
Validation loss: 2.476875118525041

Epoch: 5| Step: 7
Training loss: 0.19032568414555878
Validation loss: 2.4921538025724606

Epoch: 5| Step: 8
Training loss: 0.10768177496691185
Validation loss: 2.477352737893359

Epoch: 5| Step: 9
Training loss: 0.14864046250054444
Validation loss: 2.5410552776415423

Epoch: 5| Step: 10
Training loss: 0.2205548759087512
Validation loss: 2.5565636225887887

Epoch: 518| Step: 0
Training loss: 0.14837772646594763
Validation loss: 2.547009492019868

Epoch: 5| Step: 1
Training loss: 0.27228435139995105
Validation loss: 2.5504257883382824

Epoch: 5| Step: 2
Training loss: 0.24424678020492782
Validation loss: 2.51993268557413

Epoch: 5| Step: 3
Training loss: 0.14942085649589407
Validation loss: 2.5306111487548573

Epoch: 5| Step: 4
Training loss: 0.22557598769138584
Validation loss: 2.5043034225969634

Epoch: 5| Step: 5
Training loss: 0.1316272779767534
Validation loss: 2.4938641210989143

Epoch: 5| Step: 6
Training loss: 0.24309625407865137
Validation loss: 2.4501205887624637

Epoch: 5| Step: 7
Training loss: 0.17734385124909455
Validation loss: 2.4247075754840934

Epoch: 5| Step: 8
Training loss: 0.16966711875585808
Validation loss: 2.474164405275483

Epoch: 5| Step: 9
Training loss: 0.2433549828538667
Validation loss: 2.445062989373651

Epoch: 5| Step: 10
Training loss: 0.26526128887994593
Validation loss: 2.464718470969764

Epoch: 519| Step: 0
Training loss: 0.13010410587786844
Validation loss: 2.458226890060155

Epoch: 5| Step: 1
Training loss: 0.26936336485567974
Validation loss: 2.4820120696939885

Epoch: 5| Step: 2
Training loss: 0.2935818804888943
Validation loss: 2.4866266147723137

Epoch: 5| Step: 3
Training loss: 0.1785514202999882
Validation loss: 2.4896679640438046

Epoch: 5| Step: 4
Training loss: 0.18200197475601268
Validation loss: 2.4525086445228683

Epoch: 5| Step: 5
Training loss: 0.21052602087862132
Validation loss: 2.4367414287495253

Epoch: 5| Step: 6
Training loss: 0.21032371230371139
Validation loss: 2.4479998453775456

Epoch: 5| Step: 7
Training loss: 0.2264579005326455
Validation loss: 2.426106400815997

Epoch: 5| Step: 8
Training loss: 0.1336256965007062
Validation loss: 2.4438894125866764

Epoch: 5| Step: 9
Training loss: 0.1531937495936914
Validation loss: 2.5072674955638194

Epoch: 5| Step: 10
Training loss: 0.29668028619842696
Validation loss: 2.5614338629594444

Epoch: 520| Step: 0
Training loss: 0.26091966054090776
Validation loss: 2.529160268565013

Epoch: 5| Step: 1
Training loss: 0.28342389676593605
Validation loss: 2.5639191406224158

Epoch: 5| Step: 2
Training loss: 0.2060799425024584
Validation loss: 2.534199136936029

Epoch: 5| Step: 3
Training loss: 0.16785852009018393
Validation loss: 2.5287201632242318

Epoch: 5| Step: 4
Training loss: 0.2664130665866295
Validation loss: 2.478974152271393

Epoch: 5| Step: 5
Training loss: 0.19020418362270794
Validation loss: 2.4666535310498032

Epoch: 5| Step: 6
Training loss: 0.15959657595343277
Validation loss: 2.504816538668349

Epoch: 5| Step: 7
Training loss: 0.09385397728026938
Validation loss: 2.4844488436197825

Epoch: 5| Step: 8
Training loss: 0.20568701859588528
Validation loss: 2.5348670757006224

Epoch: 5| Step: 9
Training loss: 0.23117242491393383
Validation loss: 2.4825403971637576

Epoch: 5| Step: 10
Training loss: 0.3250859623711175
Validation loss: 2.4846785907990427

Epoch: 521| Step: 0
Training loss: 0.2369079019825798
Validation loss: 2.4957264644382837

Epoch: 5| Step: 1
Training loss: 0.21422900768682074
Validation loss: 2.4758632018493576

Epoch: 5| Step: 2
Training loss: 0.1790487088722798
Validation loss: 2.4075323639672863

Epoch: 5| Step: 3
Training loss: 0.21383232982265735
Validation loss: 2.4382306090705628

Epoch: 5| Step: 4
Training loss: 0.19195920519268195
Validation loss: 2.4623851512601

Epoch: 5| Step: 5
Training loss: 0.17257358807548898
Validation loss: 2.46742499794304

Epoch: 5| Step: 6
Training loss: 0.14426774412995277
Validation loss: 2.4897983777543358

Epoch: 5| Step: 7
Training loss: 0.20502102374805248
Validation loss: 2.491035311582813

Epoch: 5| Step: 8
Training loss: 0.17011514721598409
Validation loss: 2.545544116866456

Epoch: 5| Step: 9
Training loss: 0.3290422765380694
Validation loss: 2.547195171859185

Epoch: 5| Step: 10
Training loss: 0.30225663174452294
Validation loss: 2.5197194761642914

Epoch: 522| Step: 0
Training loss: 0.21644097404214455
Validation loss: 2.52997096886046

Epoch: 5| Step: 1
Training loss: 0.1037472795939843
Validation loss: 2.4767105360044357

Epoch: 5| Step: 2
Training loss: 0.18073309533157647
Validation loss: 2.4851203327215456

Epoch: 5| Step: 3
Training loss: 0.1689177363827914
Validation loss: 2.4348215711814523

Epoch: 5| Step: 4
Training loss: 0.2711995366395309
Validation loss: 2.44175165304905

Epoch: 5| Step: 5
Training loss: 0.14251625338519255
Validation loss: 2.430704208570698

Epoch: 5| Step: 6
Training loss: 0.27135553664717676
Validation loss: 2.4648179433400688

Epoch: 5| Step: 7
Training loss: 0.2343384237359432
Validation loss: 2.5089700025011643

Epoch: 5| Step: 8
Training loss: 0.2807567430138237
Validation loss: 2.510890591387028

Epoch: 5| Step: 9
Training loss: 0.2288275651804444
Validation loss: 2.52336871234585

Epoch: 5| Step: 10
Training loss: 0.23777099601854573
Validation loss: 2.5276079185769387

Epoch: 523| Step: 0
Training loss: 0.19659076108465873
Validation loss: 2.5106059936430407

Epoch: 5| Step: 1
Training loss: 0.19755025667860832
Validation loss: 2.5312279057522797

Epoch: 5| Step: 2
Training loss: 0.19315240360016608
Validation loss: 2.4811513299908516

Epoch: 5| Step: 3
Training loss: 0.32030652203447746
Validation loss: 2.472775687594288

Epoch: 5| Step: 4
Training loss: 0.2061494546070698
Validation loss: 2.422171879837575

Epoch: 5| Step: 5
Training loss: 0.26177540920208464
Validation loss: 2.4699673562086684

Epoch: 5| Step: 6
Training loss: 0.1508032723388926
Validation loss: 2.5041615468603617

Epoch: 5| Step: 7
Training loss: 0.29305061468119475
Validation loss: 2.5031920481789864

Epoch: 5| Step: 8
Training loss: 0.12192129576302356
Validation loss: 2.548592297561127

Epoch: 5| Step: 9
Training loss: 0.13257067767903427
Validation loss: 2.562586028833189

Epoch: 5| Step: 10
Training loss: 0.2299383412387491
Validation loss: 2.5488208569957505

Epoch: 524| Step: 0
Training loss: 0.16142478845640645
Validation loss: 2.568576398352151

Epoch: 5| Step: 1
Training loss: 0.2338641639617245
Validation loss: 2.5085968119038413

Epoch: 5| Step: 2
Training loss: 0.1269049920022324
Validation loss: 2.4945774552011004

Epoch: 5| Step: 3
Training loss: 0.1441651295040664
Validation loss: 2.498057829767196

Epoch: 5| Step: 4
Training loss: 0.21017367209219998
Validation loss: 2.4968154559454474

Epoch: 5| Step: 5
Training loss: 0.2769947273633951
Validation loss: 2.5228570669126245

Epoch: 5| Step: 6
Training loss: 0.33998038296696526
Validation loss: 2.502854792271951

Epoch: 5| Step: 7
Training loss: 0.1777371416819777
Validation loss: 2.481500411489035

Epoch: 5| Step: 8
Training loss: 0.2900519962188504
Validation loss: 2.476357983100139

Epoch: 5| Step: 9
Training loss: 0.1980270195211602
Validation loss: 2.4574450787300517

Epoch: 5| Step: 10
Training loss: 0.1645494681738921
Validation loss: 2.457759441535802

Epoch: 525| Step: 0
Training loss: 0.16793499097238188
Validation loss: 2.5015372339010726

Epoch: 5| Step: 1
Training loss: 0.2134459453520464
Validation loss: 2.499892332209396

Epoch: 5| Step: 2
Training loss: 0.11477921190589262
Validation loss: 2.4874677002474663

Epoch: 5| Step: 3
Training loss: 0.15532258293649495
Validation loss: 2.512267172644519

Epoch: 5| Step: 4
Training loss: 0.13606315510872033
Validation loss: 2.489952074167808

Epoch: 5| Step: 5
Training loss: 0.2333476118986882
Validation loss: 2.4827449396633856

Epoch: 5| Step: 6
Training loss: 0.3153629763893286
Validation loss: 2.454949068599142

Epoch: 5| Step: 7
Training loss: 0.31922461526255874
Validation loss: 2.43301448914637

Epoch: 5| Step: 8
Training loss: 0.1820336263935359
Validation loss: 2.4830127019196486

Epoch: 5| Step: 9
Training loss: 0.25549430136101686
Validation loss: 2.4658442897843145

Epoch: 5| Step: 10
Training loss: 0.207189589356119
Validation loss: 2.465505777557859

Epoch: 526| Step: 0
Training loss: 0.2845252253330828
Validation loss: 2.461569182278283

Epoch: 5| Step: 1
Training loss: 0.2932053945378837
Validation loss: 2.514101508629419

Epoch: 5| Step: 2
Training loss: 0.24614305607787715
Validation loss: 2.5089687068710202

Epoch: 5| Step: 3
Training loss: 0.15710002237762324
Validation loss: 2.5360257899154806

Epoch: 5| Step: 4
Training loss: 0.20711272813636047
Validation loss: 2.526005736792054

Epoch: 5| Step: 5
Training loss: 0.1055388614949975
Validation loss: 2.485564589880447

Epoch: 5| Step: 6
Training loss: 0.24849620431413194
Validation loss: 2.4568165068807777

Epoch: 5| Step: 7
Training loss: 0.19249524544132796
Validation loss: 2.4670474572151466

Epoch: 5| Step: 8
Training loss: 0.13659608651612787
Validation loss: 2.488647782178363

Epoch: 5| Step: 9
Training loss: 0.2095205167856057
Validation loss: 2.475750228214317

Epoch: 5| Step: 10
Training loss: 0.27853735776111066
Validation loss: 2.4837076843027033

Epoch: 527| Step: 0
Training loss: 0.22050949481224386
Validation loss: 2.4423359893823933

Epoch: 5| Step: 1
Training loss: 0.2949647682778789
Validation loss: 2.4481139802359966

Epoch: 5| Step: 2
Training loss: 0.1416947814330761
Validation loss: 2.4624945779227163

Epoch: 5| Step: 3
Training loss: 0.2417818795085402
Validation loss: 2.440365386319178

Epoch: 5| Step: 4
Training loss: 0.2741089886478497
Validation loss: 2.4915593020606193

Epoch: 5| Step: 5
Training loss: 0.14781466115537012
Validation loss: 2.4884692617983593

Epoch: 5| Step: 6
Training loss: 0.16166890292939642
Validation loss: 2.497317491609481

Epoch: 5| Step: 7
Training loss: 0.20951119092922985
Validation loss: 2.4890165500308092

Epoch: 5| Step: 8
Training loss: 0.19819508072734543
Validation loss: 2.4865694060331256

Epoch: 5| Step: 9
Training loss: 0.17168721322499847
Validation loss: 2.479265893687825

Epoch: 5| Step: 10
Training loss: 0.11858895653371712
Validation loss: 2.459368506223896

Epoch: 528| Step: 0
Training loss: 0.1590812121066366
Validation loss: 2.511502402138052

Epoch: 5| Step: 1
Training loss: 0.21010476442465403
Validation loss: 2.4999390102453316

Epoch: 5| Step: 2
Training loss: 0.16062031943184846
Validation loss: 2.4863481365411872

Epoch: 5| Step: 3
Training loss: 0.20479245952777403
Validation loss: 2.4931876467415637

Epoch: 5| Step: 4
Training loss: 0.23718995197320425
Validation loss: 2.493740540022179

Epoch: 5| Step: 5
Training loss: 0.17354486724868112
Validation loss: 2.5016352022829174

Epoch: 5| Step: 6
Training loss: 0.14103815527488778
Validation loss: 2.520196753615387

Epoch: 5| Step: 7
Training loss: 0.2859010636716819
Validation loss: 2.501421755368481

Epoch: 5| Step: 8
Training loss: 0.15698292021724214
Validation loss: 2.477103706824668

Epoch: 5| Step: 9
Training loss: 0.21901673845714462
Validation loss: 2.501209636012281

Epoch: 5| Step: 10
Training loss: 0.2580639595430231
Validation loss: 2.4874848466579498

Epoch: 529| Step: 0
Training loss: 0.14634211307883344
Validation loss: 2.4629264038440164

Epoch: 5| Step: 1
Training loss: 0.18055535216095872
Validation loss: 2.473052975201244

Epoch: 5| Step: 2
Training loss: 0.20202162814848604
Validation loss: 2.462541986963994

Epoch: 5| Step: 3
Training loss: 0.30883967583784927
Validation loss: 2.528473551151593

Epoch: 5| Step: 4
Training loss: 0.24619789795902042
Validation loss: 2.561208952491534

Epoch: 5| Step: 5
Training loss: 0.13271052288238347
Validation loss: 2.513899408584458

Epoch: 5| Step: 6
Training loss: 0.1373210311213685
Validation loss: 2.5453287958917876

Epoch: 5| Step: 7
Training loss: 0.3400315390712623
Validation loss: 2.523314909600402

Epoch: 5| Step: 8
Training loss: 0.1725474014495277
Validation loss: 2.4936142715837586

Epoch: 5| Step: 9
Training loss: 0.12320405518271971
Validation loss: 2.4634167453236206

Epoch: 5| Step: 10
Training loss: 0.15356831022673667
Validation loss: 2.4453948758395074

Epoch: 530| Step: 0
Training loss: 0.276716032354105
Validation loss: 2.4676980752242206

Epoch: 5| Step: 1
Training loss: 0.16382129854160846
Validation loss: 2.441955822720833

Epoch: 5| Step: 2
Training loss: 0.11951681062337448
Validation loss: 2.5008460946021667

Epoch: 5| Step: 3
Training loss: 0.22458091223785315
Validation loss: 2.5141587169702535

Epoch: 5| Step: 4
Training loss: 0.255437094800799
Validation loss: 2.5296909666503504

Epoch: 5| Step: 5
Training loss: 0.1913831268667992
Validation loss: 2.4902391764791365

Epoch: 5| Step: 6
Training loss: 0.15276919160783828
Validation loss: 2.456128364370746

Epoch: 5| Step: 7
Training loss: 0.27365702944648146
Validation loss: 2.399560764519864

Epoch: 5| Step: 8
Training loss: 0.2785291055891873
Validation loss: 2.372253342008948

Epoch: 5| Step: 9
Training loss: 0.26992287035260326
Validation loss: 2.3678822921378715

Epoch: 5| Step: 10
Training loss: 0.24670576258293192
Validation loss: 2.3745631370454756

Epoch: 531| Step: 0
Training loss: 0.32555862843127786
Validation loss: 2.418072439792668

Epoch: 5| Step: 1
Training loss: 0.18662541782194406
Validation loss: 2.445969188182027

Epoch: 5| Step: 2
Training loss: 0.3040592857575165
Validation loss: 2.4775444100970194

Epoch: 5| Step: 3
Training loss: 0.22955452904181164
Validation loss: 2.499992079363345

Epoch: 5| Step: 4
Training loss: 0.1617596657450382
Validation loss: 2.468826868042554

Epoch: 5| Step: 5
Training loss: 0.18898881469406537
Validation loss: 2.494252061098194

Epoch: 5| Step: 6
Training loss: 0.14924220879384908
Validation loss: 2.4674034537816096

Epoch: 5| Step: 7
Training loss: 0.1505767549814836
Validation loss: 2.460573967593273

Epoch: 5| Step: 8
Training loss: 0.22163504936727005
Validation loss: 2.473112155693608

Epoch: 5| Step: 9
Training loss: 0.2242308536944436
Validation loss: 2.4658076076937685

Epoch: 5| Step: 10
Training loss: 0.2516779616854897
Validation loss: 2.4593218621226796

Epoch: 532| Step: 0
Training loss: 0.20029527913011386
Validation loss: 2.488169855075233

Epoch: 5| Step: 1
Training loss: 0.17340850007691877
Validation loss: 2.5148007971259565

Epoch: 5| Step: 2
Training loss: 0.1936889594584081
Validation loss: 2.531781882965946

Epoch: 5| Step: 3
Training loss: 0.3594504981969951
Validation loss: 2.5587703816392606

Epoch: 5| Step: 4
Training loss: 0.2718407877957892
Validation loss: 2.532217741393669

Epoch: 5| Step: 5
Training loss: 0.16846414081110966
Validation loss: 2.5359055458589888

Epoch: 5| Step: 6
Training loss: 0.26792773497298694
Validation loss: 2.498461310316367

Epoch: 5| Step: 7
Training loss: 0.18047136907617406
Validation loss: 2.4775237853616447

Epoch: 5| Step: 8
Training loss: 0.19496663942217277
Validation loss: 2.475479913651337

Epoch: 5| Step: 9
Training loss: 0.18636846845350924
Validation loss: 2.480852578260824

Epoch: 5| Step: 10
Training loss: 0.21558683375500426
Validation loss: 2.4464613156636603

Epoch: 533| Step: 0
Training loss: 0.16197014770258022
Validation loss: 2.4293278485769534

Epoch: 5| Step: 1
Training loss: 0.22340125376805026
Validation loss: 2.478740669671325

Epoch: 5| Step: 2
Training loss: 0.2995431610509153
Validation loss: 2.4338510676476774

Epoch: 5| Step: 3
Training loss: 0.2891580320703466
Validation loss: 2.4565137071621455

Epoch: 5| Step: 4
Training loss: 0.21759407286350896
Validation loss: 2.435959164106883

Epoch: 5| Step: 5
Training loss: 0.15371210614042502
Validation loss: 2.5102942362887295

Epoch: 5| Step: 6
Training loss: 0.22875714376895168
Validation loss: 2.4887601270841633

Epoch: 5| Step: 7
Training loss: 0.25207547610361936
Validation loss: 2.4694389585465304

Epoch: 5| Step: 8
Training loss: 0.16358677830091298
Validation loss: 2.4611573719585595

Epoch: 5| Step: 9
Training loss: 0.1652271789985882
Validation loss: 2.445994822680778

Epoch: 5| Step: 10
Training loss: 0.2372229871098848
Validation loss: 2.428898658785832

Epoch: 534| Step: 0
Training loss: 0.24131936945025942
Validation loss: 2.423876346381705

Epoch: 5| Step: 1
Training loss: 0.1563983332357655
Validation loss: 2.403738822351955

Epoch: 5| Step: 2
Training loss: 0.12012528182878887
Validation loss: 2.4401959207972714

Epoch: 5| Step: 3
Training loss: 0.15403083004722998
Validation loss: 2.4765717149850768

Epoch: 5| Step: 4
Training loss: 0.22034568874819246
Validation loss: 2.4365692796569838

Epoch: 5| Step: 5
Training loss: 0.32434171619801233
Validation loss: 2.4482876421710498

Epoch: 5| Step: 6
Training loss: 0.1531790367945741
Validation loss: 2.4715184153984207

Epoch: 5| Step: 7
Training loss: 0.19349974536694178
Validation loss: 2.4816896802607755

Epoch: 5| Step: 8
Training loss: 0.2377781324830212
Validation loss: 2.4917531197648506

Epoch: 5| Step: 9
Training loss: 0.25152163558672347
Validation loss: 2.4704890929410483

Epoch: 5| Step: 10
Training loss: 0.1490220368545725
Validation loss: 2.4495932432455017

Epoch: 535| Step: 0
Training loss: 0.20535015955448105
Validation loss: 2.4835917633275475

Epoch: 5| Step: 1
Training loss: 0.24971894768010233
Validation loss: 2.4593894724052556

Epoch: 5| Step: 2
Training loss: 0.18563623786072356
Validation loss: 2.4547654824600817

Epoch: 5| Step: 3
Training loss: 0.3111755916403191
Validation loss: 2.3967296963753815

Epoch: 5| Step: 4
Training loss: 0.12946204097803074
Validation loss: 2.41160328091735

Epoch: 5| Step: 5
Training loss: 0.2272058593121649
Validation loss: 2.360347878898736

Epoch: 5| Step: 6
Training loss: 0.23122594392507312
Validation loss: 2.3908187119640587

Epoch: 5| Step: 7
Training loss: 0.1733564449473556
Validation loss: 2.388379210939923

Epoch: 5| Step: 8
Training loss: 0.14842358323160443
Validation loss: 2.4325991158226574

Epoch: 5| Step: 9
Training loss: 0.308295347101208
Validation loss: 2.4382819758533794

Epoch: 5| Step: 10
Training loss: 0.1758861070055899
Validation loss: 2.4419888155330858

Epoch: 536| Step: 0
Training loss: 0.13301766200854487
Validation loss: 2.4516141476706266

Epoch: 5| Step: 1
Training loss: 0.18351328892558708
Validation loss: 2.4781923193343753

Epoch: 5| Step: 2
Training loss: 0.1896696917550185
Validation loss: 2.4953618452735413

Epoch: 5| Step: 3
Training loss: 0.2072571745327803
Validation loss: 2.512888290137841

Epoch: 5| Step: 4
Training loss: 0.17405618216111132
Validation loss: 2.5293787991867367

Epoch: 5| Step: 5
Training loss: 0.247668405589519
Validation loss: 2.5105617407918723

Epoch: 5| Step: 6
Training loss: 0.21575430469097323
Validation loss: 2.4563320184940465

Epoch: 5| Step: 7
Training loss: 0.19258202245145908
Validation loss: 2.47567962885361

Epoch: 5| Step: 8
Training loss: 0.19286436238191665
Validation loss: 2.457642969464633

Epoch: 5| Step: 9
Training loss: 0.2302626884740691
Validation loss: 2.459037453280899

Epoch: 5| Step: 10
Training loss: 0.28236876604376565
Validation loss: 2.4267611068987467

Epoch: 537| Step: 0
Training loss: 0.29504047308106957
Validation loss: 2.410828369483057

Epoch: 5| Step: 1
Training loss: 0.2463606189718877
Validation loss: 2.4212776384182226

Epoch: 5| Step: 2
Training loss: 0.3335466360551548
Validation loss: 2.4397662849208643

Epoch: 5| Step: 3
Training loss: 0.17369890231796994
Validation loss: 2.4385127763029

Epoch: 5| Step: 4
Training loss: 0.18342951266560975
Validation loss: 2.515622050760607

Epoch: 5| Step: 5
Training loss: 0.15230501122549112
Validation loss: 2.556731012208504

Epoch: 5| Step: 6
Training loss: 0.1471678682566137
Validation loss: 2.607159291883787

Epoch: 5| Step: 7
Training loss: 0.21649736042649137
Validation loss: 2.5966116844904

Epoch: 5| Step: 8
Training loss: 0.21329762113011858
Validation loss: 2.6137523888908127

Epoch: 5| Step: 9
Training loss: 0.1524682331123355
Validation loss: 2.5842371010385716

Epoch: 5| Step: 10
Training loss: 0.3356346384188238
Validation loss: 2.5347802871419285

Epoch: 538| Step: 0
Training loss: 0.284425504622205
Validation loss: 2.473594698041827

Epoch: 5| Step: 1
Training loss: 0.2097492126352311
Validation loss: 2.437058178678918

Epoch: 5| Step: 2
Training loss: 0.28468644620363265
Validation loss: 2.413243859932732

Epoch: 5| Step: 3
Training loss: 0.1519337173463373
Validation loss: 2.4566814026748416

Epoch: 5| Step: 4
Training loss: 0.17494927186224332
Validation loss: 2.467241552515013

Epoch: 5| Step: 5
Training loss: 0.19992946558171554
Validation loss: 2.4596934038460185

Epoch: 5| Step: 6
Training loss: 0.21393906243433822
Validation loss: 2.521861695860656

Epoch: 5| Step: 7
Training loss: 0.2213699512837576
Validation loss: 2.556657247333326

Epoch: 5| Step: 8
Training loss: 0.2192763229703805
Validation loss: 2.5416575256323144

Epoch: 5| Step: 9
Training loss: 0.20817446412999824
Validation loss: 2.5618654511401076

Epoch: 5| Step: 10
Training loss: 0.27900997177970605
Validation loss: 2.5204165432861543

Epoch: 539| Step: 0
Training loss: 0.1907683076147329
Validation loss: 2.4887699819115268

Epoch: 5| Step: 1
Training loss: 0.14590469740137346
Validation loss: 2.468270974592083

Epoch: 5| Step: 2
Training loss: 0.22017716721959968
Validation loss: 2.4155058291632514

Epoch: 5| Step: 3
Training loss: 0.22170128065973074
Validation loss: 2.462367565103682

Epoch: 5| Step: 4
Training loss: 0.22882571740412566
Validation loss: 2.4585105355206376

Epoch: 5| Step: 5
Training loss: 0.33485954907802457
Validation loss: 2.5196580525991377

Epoch: 5| Step: 6
Training loss: 0.31332515018934054
Validation loss: 2.4680406115361277

Epoch: 5| Step: 7
Training loss: 0.27682320004745053
Validation loss: 2.448937211240647

Epoch: 5| Step: 8
Training loss: 0.18788369972964586
Validation loss: 2.3914036365799247

Epoch: 5| Step: 9
Training loss: 0.2696314777388426
Validation loss: 2.381196917744639

Epoch: 5| Step: 10
Training loss: 0.10424795307092667
Validation loss: 2.3488151110635376

Epoch: 540| Step: 0
Training loss: 0.23184236840549746
Validation loss: 2.314029154764006

Epoch: 5| Step: 1
Training loss: 0.17691939960969194
Validation loss: 2.345603354471804

Epoch: 5| Step: 2
Training loss: 0.27707733199186196
Validation loss: 2.3192299722450898

Epoch: 5| Step: 3
Training loss: 0.2001976571294676
Validation loss: 2.3765675672074598

Epoch: 5| Step: 4
Training loss: 0.1682198001234232
Validation loss: 2.4053608882185125

Epoch: 5| Step: 5
Training loss: 0.26684599629461964
Validation loss: 2.437093095495745

Epoch: 5| Step: 6
Training loss: 0.33480377514031345
Validation loss: 2.470990649251579

Epoch: 5| Step: 7
Training loss: 0.2603684507874976
Validation loss: 2.4652107739985007

Epoch: 5| Step: 8
Training loss: 0.23762888015306216
Validation loss: 2.421099366764502

Epoch: 5| Step: 9
Training loss: 0.25768784196892475
Validation loss: 2.435873437059712

Epoch: 5| Step: 10
Training loss: 0.21684007815594558
Validation loss: 2.438053457417148

Epoch: 541| Step: 0
Training loss: 0.25241590478059434
Validation loss: 2.4651709595302282

Epoch: 5| Step: 1
Training loss: 0.18732766337683462
Validation loss: 2.4472356202770578

Epoch: 5| Step: 2
Training loss: 0.22616689772062323
Validation loss: 2.482668963096528

Epoch: 5| Step: 3
Training loss: 0.15507384733935226
Validation loss: 2.523467562261568

Epoch: 5| Step: 4
Training loss: 0.19817284371899396
Validation loss: 2.519604062256202

Epoch: 5| Step: 5
Training loss: 0.2235158506150292
Validation loss: 2.5199263185131056

Epoch: 5| Step: 6
Training loss: 0.1918957833984523
Validation loss: 2.5044913038522822

Epoch: 5| Step: 7
Training loss: 0.21088523570478732
Validation loss: 2.498736400594634

Epoch: 5| Step: 8
Training loss: 0.2340632192781446
Validation loss: 2.4201274821790117

Epoch: 5| Step: 9
Training loss: 0.27978550243522704
Validation loss: 2.4003982078573785

Epoch: 5| Step: 10
Training loss: 0.17299255181483386
Validation loss: 2.377964846163765

Epoch: 542| Step: 0
Training loss: 0.2877294500728559
Validation loss: 2.354351373675987

Epoch: 5| Step: 1
Training loss: 0.13104523796659162
Validation loss: 2.378390704248729

Epoch: 5| Step: 2
Training loss: 0.2516136543911117
Validation loss: 2.396666920990073

Epoch: 5| Step: 3
Training loss: 0.23969917848328492
Validation loss: 2.431433430322446

Epoch: 5| Step: 4
Training loss: 0.1806592064282176
Validation loss: 2.447112754995137

Epoch: 5| Step: 5
Training loss: 0.14689035107153192
Validation loss: 2.4918849598260473

Epoch: 5| Step: 6
Training loss: 0.2694422809988082
Validation loss: 2.511187040040912

Epoch: 5| Step: 7
Training loss: 0.1814373991917019
Validation loss: 2.454191620928952

Epoch: 5| Step: 8
Training loss: 0.14922279382389136
Validation loss: 2.4527296619430006

Epoch: 5| Step: 9
Training loss: 0.17054348186904242
Validation loss: 2.4513287080830697

Epoch: 5| Step: 10
Training loss: 0.3737446116693752
Validation loss: 2.4293009681311606

Epoch: 543| Step: 0
Training loss: 0.34512208072667033
Validation loss: 2.439348007771277

Epoch: 5| Step: 1
Training loss: 0.1933385568065916
Validation loss: 2.4312061008389794

Epoch: 5| Step: 2
Training loss: 0.24089432605385236
Validation loss: 2.470862697895874

Epoch: 5| Step: 3
Training loss: 0.22909914813838653
Validation loss: 2.467199362729985

Epoch: 5| Step: 4
Training loss: 0.2672550032489008
Validation loss: 2.49322808163903

Epoch: 5| Step: 5
Training loss: 0.25624024093466835
Validation loss: 2.4784405862602505

Epoch: 5| Step: 6
Training loss: 0.1989596589445388
Validation loss: 2.4373795421990794

Epoch: 5| Step: 7
Training loss: 0.1964801124277234
Validation loss: 2.416846855685761

Epoch: 5| Step: 8
Training loss: 0.28770092598073616
Validation loss: 2.3972698144428084

Epoch: 5| Step: 9
Training loss: 0.21513614697754835
Validation loss: 2.3875825038425407

Epoch: 5| Step: 10
Training loss: 0.1717907525706793
Validation loss: 2.393239159209296

Epoch: 544| Step: 0
Training loss: 0.26975579514257764
Validation loss: 2.4394009447613563

Epoch: 5| Step: 1
Training loss: 0.1773782137854521
Validation loss: 2.4402526539927867

Epoch: 5| Step: 2
Training loss: 0.2897215367046263
Validation loss: 2.4656336398736043

Epoch: 5| Step: 3
Training loss: 0.16651494725109026
Validation loss: 2.5152158420365005

Epoch: 5| Step: 4
Training loss: 0.24354714547894402
Validation loss: 2.53369608439727

Epoch: 5| Step: 5
Training loss: 0.20918376715606019
Validation loss: 2.509140908439988

Epoch: 5| Step: 6
Training loss: 0.22306139375963324
Validation loss: 2.5082530816418993

Epoch: 5| Step: 7
Training loss: 0.3060098708982287
Validation loss: 2.4982679376158874

Epoch: 5| Step: 8
Training loss: 0.2725245903889008
Validation loss: 2.4796644386519575

Epoch: 5| Step: 9
Training loss: 0.24945146762621084
Validation loss: 2.5070562281978486

Epoch: 5| Step: 10
Training loss: 0.3534810486634356
Validation loss: 2.5542390024573836

Epoch: 545| Step: 0
Training loss: 0.2170497175945966
Validation loss: 2.601621603054972

Epoch: 5| Step: 1
Training loss: 0.20641019625360255
Validation loss: 2.627353798527549

Epoch: 5| Step: 2
Training loss: 0.23664467474065587
Validation loss: 2.6099725051083555

Epoch: 5| Step: 3
Training loss: 0.20666711201222437
Validation loss: 2.5786643817939123

Epoch: 5| Step: 4
Training loss: 0.1768684251864052
Validation loss: 2.5677449183566017

Epoch: 5| Step: 5
Training loss: 0.2184537942754819
Validation loss: 2.5044896860246113

Epoch: 5| Step: 6
Training loss: 0.2087351480500105
Validation loss: 2.50506310132269

Epoch: 5| Step: 7
Training loss: 0.3093841666973228
Validation loss: 2.41047233811294

Epoch: 5| Step: 8
Training loss: 0.25938618704788147
Validation loss: 2.452243894111004

Epoch: 5| Step: 9
Training loss: 0.3269528159957027
Validation loss: 2.462078369521411

Epoch: 5| Step: 10
Training loss: 0.2508150167103674
Validation loss: 2.4727945495631474

Epoch: 546| Step: 0
Training loss: 0.2204646619908439
Validation loss: 2.4668856832716792

Epoch: 5| Step: 1
Training loss: 0.11685512614721986
Validation loss: 2.489145401482886

Epoch: 5| Step: 2
Training loss: 0.23721551985960515
Validation loss: 2.5166125867553304

Epoch: 5| Step: 3
Training loss: 0.278111563583019
Validation loss: 2.58069209682944

Epoch: 5| Step: 4
Training loss: 0.24556825936122725
Validation loss: 2.557391095311285

Epoch: 5| Step: 5
Training loss: 0.17921681538596104
Validation loss: 2.533965556801532

Epoch: 5| Step: 6
Training loss: 0.14877503066273345
Validation loss: 2.54117559984168

Epoch: 5| Step: 7
Training loss: 0.18620326739183574
Validation loss: 2.521583813732451

Epoch: 5| Step: 8
Training loss: 0.24589413161139928
Validation loss: 2.4899873601760087

Epoch: 5| Step: 9
Training loss: 0.23733399449604162
Validation loss: 2.451470382353602

Epoch: 5| Step: 10
Training loss: 0.2240041124145187
Validation loss: 2.4480306337454265

Epoch: 547| Step: 0
Training loss: 0.1977713212245285
Validation loss: 2.4986047866171446

Epoch: 5| Step: 1
Training loss: 0.150502200661852
Validation loss: 2.5008017474672966

Epoch: 5| Step: 2
Training loss: 0.17781987072730673
Validation loss: 2.503675810257033

Epoch: 5| Step: 3
Training loss: 0.31684722312154673
Validation loss: 2.506737239159637

Epoch: 5| Step: 4
Training loss: 0.17627964360614742
Validation loss: 2.4851413885419213

Epoch: 5| Step: 5
Training loss: 0.2891127310746049
Validation loss: 2.49016857622479

Epoch: 5| Step: 6
Training loss: 0.28023656409806796
Validation loss: 2.4431194515082

Epoch: 5| Step: 7
Training loss: 0.2233306142270211
Validation loss: 2.440514715620307

Epoch: 5| Step: 8
Training loss: 0.2003968317806954
Validation loss: 2.426468454195914

Epoch: 5| Step: 9
Training loss: 0.19905235784195865
Validation loss: 2.4634153716191554

Epoch: 5| Step: 10
Training loss: 0.16373939714611885
Validation loss: 2.498052162788843

Epoch: 548| Step: 0
Training loss: 0.14072745617444202
Validation loss: 2.497974952776451

Epoch: 5| Step: 1
Training loss: 0.1282315950553674
Validation loss: 2.580299570576407

Epoch: 5| Step: 2
Training loss: 0.22957513000252386
Validation loss: 2.5323025950522937

Epoch: 5| Step: 3
Training loss: 0.25359486780020163
Validation loss: 2.5505067021493395

Epoch: 5| Step: 4
Training loss: 0.1474656552703218
Validation loss: 2.5099837251050676

Epoch: 5| Step: 5
Training loss: 0.27834919562130195
Validation loss: 2.449156684610488

Epoch: 5| Step: 6
Training loss: 0.21903935946902145
Validation loss: 2.4518596145033698

Epoch: 5| Step: 7
Training loss: 0.300404225650444
Validation loss: 2.4484234147687864

Epoch: 5| Step: 8
Training loss: 0.14403183457613286
Validation loss: 2.4387628309391136

Epoch: 5| Step: 9
Training loss: 0.22205837187458252
Validation loss: 2.476147218673122

Epoch: 5| Step: 10
Training loss: 0.24703367059572492
Validation loss: 2.4891681438636675

Epoch: 549| Step: 0
Training loss: 0.21202033757666622
Validation loss: 2.539054141855169

Epoch: 5| Step: 1
Training loss: 0.16894272157303053
Validation loss: 2.5800068927357076

Epoch: 5| Step: 2
Training loss: 0.2988753437309889
Validation loss: 2.5834912209850507

Epoch: 5| Step: 3
Training loss: 0.20653591639966662
Validation loss: 2.5677411423989733

Epoch: 5| Step: 4
Training loss: 0.24263613432649783
Validation loss: 2.5123471439632885

Epoch: 5| Step: 5
Training loss: 0.1994686616135105
Validation loss: 2.4990764019345906

Epoch: 5| Step: 6
Training loss: 0.2319010018989976
Validation loss: 2.470282591251569

Epoch: 5| Step: 7
Training loss: 0.20331093641020542
Validation loss: 2.469031315688608

Epoch: 5| Step: 8
Training loss: 0.33194467874520484
Validation loss: 2.4628553817111585

Epoch: 5| Step: 9
Training loss: 0.2047165908233766
Validation loss: 2.4989470817985153

Epoch: 5| Step: 10
Training loss: 0.17907333109920884
Validation loss: 2.517085059370388

Epoch: 550| Step: 0
Training loss: 0.1686678796977908
Validation loss: 2.5763794400062214

Epoch: 5| Step: 1
Training loss: 0.18919494576825616
Validation loss: 2.577190145402124

Epoch: 5| Step: 2
Training loss: 0.18005660749788766
Validation loss: 2.5822335840454604

Epoch: 5| Step: 3
Training loss: 0.3173325131979898
Validation loss: 2.5545094219036875

Epoch: 5| Step: 4
Training loss: 0.1711979992603938
Validation loss: 2.5346523603055857

Epoch: 5| Step: 5
Training loss: 0.22316122514312192
Validation loss: 2.469767985622226

Epoch: 5| Step: 6
Training loss: 0.2562266763679379
Validation loss: 2.4866413870004878

Epoch: 5| Step: 7
Training loss: 0.2357655915760798
Validation loss: 2.4475005154581537

Epoch: 5| Step: 8
Training loss: 0.22387330895705884
Validation loss: 2.4388427906175747

Epoch: 5| Step: 9
Training loss: 0.12662859297679296
Validation loss: 2.47319212019028

Epoch: 5| Step: 10
Training loss: 0.18203196873338778
Validation loss: 2.4501153926700945

Testing loss: 3.135405125390797
