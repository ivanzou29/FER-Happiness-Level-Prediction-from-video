Epoch: 1| Step: 0
Training loss: 5.848248550497699
Validation loss: 5.857238066587865

Epoch: 5| Step: 1
Training loss: 5.518496363029032
Validation loss: 5.832792200165622

Epoch: 5| Step: 2
Training loss: 6.703624929000779
Validation loss: 5.813012220395562

Epoch: 5| Step: 3
Training loss: 5.636732285153535
Validation loss: 5.794323420814244

Epoch: 5| Step: 4
Training loss: 5.579802616142207
Validation loss: 5.773152969535715

Epoch: 5| Step: 5
Training loss: 6.552467743271334
Validation loss: 5.74952511389105

Epoch: 5| Step: 6
Training loss: 5.743369218327109
Validation loss: 5.722048300472727

Epoch: 5| Step: 7
Training loss: 4.916509313274475
Validation loss: 5.690142504803518

Epoch: 5| Step: 8
Training loss: 5.743311101273016
Validation loss: 5.654409107753045

Epoch: 5| Step: 9
Training loss: 5.462787974991963
Validation loss: 5.614299920055252

Epoch: 5| Step: 10
Training loss: 5.508320669985867
Validation loss: 5.56866420105544

Epoch: 2| Step: 0
Training loss: 5.178053193869298
Validation loss: 5.5186406423848435

Epoch: 5| Step: 1
Training loss: 5.7517903070122305
Validation loss: 5.460820530424413

Epoch: 5| Step: 2
Training loss: 5.472164112864763
Validation loss: 5.4008885199907075

Epoch: 5| Step: 3
Training loss: 4.987758910837283
Validation loss: 5.334318025245328

Epoch: 5| Step: 4
Training loss: 5.139881764399056
Validation loss: 5.268137903331219

Epoch: 5| Step: 5
Training loss: 5.813780940844349
Validation loss: 5.202317799721753

Epoch: 5| Step: 6
Training loss: 5.568770057308155
Validation loss: 5.136776768879867

Epoch: 5| Step: 7
Training loss: 4.275533381867447
Validation loss: 5.072306238622669

Epoch: 5| Step: 8
Training loss: 4.388980218014884
Validation loss: 5.011604726791323

Epoch: 5| Step: 9
Training loss: 5.073675935650601
Validation loss: 4.955287784258842

Epoch: 5| Step: 10
Training loss: 6.032417777268245
Validation loss: 4.899363338989149

Epoch: 3| Step: 0
Training loss: 5.383272237204654
Validation loss: 4.845711862854852

Epoch: 5| Step: 1
Training loss: 4.402207271758725
Validation loss: 4.792285199078225

Epoch: 5| Step: 2
Training loss: 3.7741521628492727
Validation loss: 4.741802257164454

Epoch: 5| Step: 3
Training loss: 4.5176076793239925
Validation loss: 4.687824398287222

Epoch: 5| Step: 4
Training loss: 3.978950068518844
Validation loss: 4.637153609588708

Epoch: 5| Step: 5
Training loss: 5.588969313538132
Validation loss: 4.583393485083809

Epoch: 5| Step: 6
Training loss: 5.813759287939729
Validation loss: 4.532934150969783

Epoch: 5| Step: 7
Training loss: 5.7289394634162685
Validation loss: 4.478975036749632

Epoch: 5| Step: 8
Training loss: 4.163838507548457
Validation loss: 4.42430933906377

Epoch: 5| Step: 9
Training loss: 4.1851950607508375
Validation loss: 4.382630561785791

Epoch: 5| Step: 10
Training loss: 2.8961674522651584
Validation loss: 4.363642147497127

Epoch: 4| Step: 0
Training loss: 5.0940400023490415
Validation loss: 4.358063651311819

Epoch: 5| Step: 1
Training loss: 4.954438718229878
Validation loss: 4.30564641566649

Epoch: 5| Step: 2
Training loss: 4.815111516847532
Validation loss: 4.271568506785032

Epoch: 5| Step: 3
Training loss: 3.9355118591416827
Validation loss: 4.243994880369778

Epoch: 5| Step: 4
Training loss: 4.900360265449998
Validation loss: 4.228687490590073

Epoch: 5| Step: 5
Training loss: 4.726602248347846
Validation loss: 4.200533921720346

Epoch: 5| Step: 6
Training loss: 4.23726046174921
Validation loss: 4.165793357307292

Epoch: 5| Step: 7
Training loss: 2.980042993376204
Validation loss: 4.146479876476023

Epoch: 5| Step: 8
Training loss: 3.5932642069332497
Validation loss: 4.128587593965993

Epoch: 5| Step: 9
Training loss: 4.210201616692275
Validation loss: 4.114435796661391

Epoch: 5| Step: 10
Training loss: 3.7627722353365387
Validation loss: 4.090787475520888

Epoch: 5| Step: 0
Training loss: 3.220449498948984
Validation loss: 4.061806694549475

Epoch: 5| Step: 1
Training loss: 4.128552843052982
Validation loss: 4.0396027089797535

Epoch: 5| Step: 2
Training loss: 4.972595262415676
Validation loss: 4.019099410901118

Epoch: 5| Step: 3
Training loss: 4.05537094206969
Validation loss: 4.0011036257905195

Epoch: 5| Step: 4
Training loss: 4.068443528219308
Validation loss: 3.985852117991479

Epoch: 5| Step: 5
Training loss: 4.1256493721970084
Validation loss: 3.9716805847173893

Epoch: 5| Step: 6
Training loss: 4.110641458393433
Validation loss: 3.953769063114095

Epoch: 5| Step: 7
Training loss: 3.6594376973189586
Validation loss: 3.9384300668744427

Epoch: 5| Step: 8
Training loss: 4.8427290301893695
Validation loss: 3.9229442938138295

Epoch: 5| Step: 9
Training loss: 3.7182593783335545
Validation loss: 3.9035056881760735

Epoch: 5| Step: 10
Training loss: 4.193646830214994
Validation loss: 3.8902516099186597

Epoch: 6| Step: 0
Training loss: 4.675015315882436
Validation loss: 3.8768201146466326

Epoch: 5| Step: 1
Training loss: 4.252999985964641
Validation loss: 3.8634996915132738

Epoch: 5| Step: 2
Training loss: 4.55030111636953
Validation loss: 3.852970454931217

Epoch: 5| Step: 3
Training loss: 3.6733235849803845
Validation loss: 3.8408531546598152

Epoch: 5| Step: 4
Training loss: 3.00815665517891
Validation loss: 3.8261966659396953

Epoch: 5| Step: 5
Training loss: 4.028629131155113
Validation loss: 3.8147191999537404

Epoch: 5| Step: 6
Training loss: 3.8411655576382704
Validation loss: 3.8025758908305107

Epoch: 5| Step: 7
Training loss: 4.0751645388470825
Validation loss: 3.788907643046031

Epoch: 5| Step: 8
Training loss: 3.767625206257148
Validation loss: 3.7781278825810283

Epoch: 5| Step: 9
Training loss: 3.819194731592924
Validation loss: 3.7658591514432715

Epoch: 5| Step: 10
Training loss: 3.9606642167959665
Validation loss: 3.757741753512134

Epoch: 7| Step: 0
Training loss: 4.3159274426885075
Validation loss: 3.7438451580084435

Epoch: 5| Step: 1
Training loss: 3.7732009339665358
Validation loss: 3.7324899954963593

Epoch: 5| Step: 2
Training loss: 3.910432087470357
Validation loss: 3.718235748628872

Epoch: 5| Step: 3
Training loss: 3.651899569832069
Validation loss: 3.708852582035878

Epoch: 5| Step: 4
Training loss: 3.8092904260649205
Validation loss: 3.6976548796210005

Epoch: 5| Step: 5
Training loss: 3.1721037984174747
Validation loss: 3.6852618600476226

Epoch: 5| Step: 6
Training loss: 4.531712791224037
Validation loss: 3.6753076919126944

Epoch: 5| Step: 7
Training loss: 4.468916029613482
Validation loss: 3.664638046672093

Epoch: 5| Step: 8
Training loss: 3.498004071747475
Validation loss: 3.6526450745695773

Epoch: 5| Step: 9
Training loss: 3.333840204483893
Validation loss: 3.6417644276887335

Epoch: 5| Step: 10
Training loss: 3.9093818011937493
Validation loss: 3.6330279422793943

Epoch: 8| Step: 0
Training loss: 4.452702231165231
Validation loss: 3.623922508252799

Epoch: 5| Step: 1
Training loss: 3.7006741553947626
Validation loss: 3.6084878228308144

Epoch: 5| Step: 2
Training loss: 3.2117918785193496
Validation loss: 3.600094398732979

Epoch: 5| Step: 3
Training loss: 3.356552996890569
Validation loss: 3.585060161899786

Epoch: 5| Step: 4
Training loss: 3.635872813175184
Validation loss: 3.5813415115920706

Epoch: 5| Step: 5
Training loss: 4.40515772490598
Validation loss: 3.5713825637736996

Epoch: 5| Step: 6
Training loss: 3.695737786045315
Validation loss: 3.556532093333895

Epoch: 5| Step: 7
Training loss: 3.926125946854166
Validation loss: 3.5551813521110294

Epoch: 5| Step: 8
Training loss: 3.906841752053177
Validation loss: 3.5419817316871915

Epoch: 5| Step: 9
Training loss: 3.753187477932169
Validation loss: 3.525659538118325

Epoch: 5| Step: 10
Training loss: 3.1796804517063313
Validation loss: 3.529388073349671

Epoch: 9| Step: 0
Training loss: 3.689384754652039
Validation loss: 3.531676925535646

Epoch: 5| Step: 1
Training loss: 2.774648310739762
Validation loss: 3.50181556378727

Epoch: 5| Step: 2
Training loss: 3.054670328935914
Validation loss: 3.497913465257959

Epoch: 5| Step: 3
Training loss: 4.077704513912601
Validation loss: 3.496410646213371

Epoch: 5| Step: 4
Training loss: 2.6409423456857373
Validation loss: 3.484909422033341

Epoch: 5| Step: 5
Training loss: 4.332130093904463
Validation loss: 3.4728574017333202

Epoch: 5| Step: 6
Training loss: 4.154004630573393
Validation loss: 3.4646066895148913

Epoch: 5| Step: 7
Training loss: 3.730850791342144
Validation loss: 3.4567580304043934

Epoch: 5| Step: 8
Training loss: 3.7388717838656254
Validation loss: 3.4482726009521083

Epoch: 5| Step: 9
Training loss: 4.114051623534688
Validation loss: 3.440184219945558

Epoch: 5| Step: 10
Training loss: 3.8476277461666286
Validation loss: 3.424602018832358

Epoch: 10| Step: 0
Training loss: 3.332243900288624
Validation loss: 3.4171925106822365

Epoch: 5| Step: 1
Training loss: 3.7114942273590077
Validation loss: 3.4162970212141817

Epoch: 5| Step: 2
Training loss: 3.0773707981087903
Validation loss: 3.4056799243072042

Epoch: 5| Step: 3
Training loss: 4.095543388486155
Validation loss: 3.399049350462867

Epoch: 5| Step: 4
Training loss: 3.84568799792289
Validation loss: 3.40822354558672

Epoch: 5| Step: 5
Training loss: 3.50139671794563
Validation loss: 3.382908693154833

Epoch: 5| Step: 6
Training loss: 3.325561395734825
Validation loss: 3.376717581215137

Epoch: 5| Step: 7
Training loss: 3.709012658692843
Validation loss: 3.375193579320522

Epoch: 5| Step: 8
Training loss: 3.982530593323523
Validation loss: 3.3713708474531305

Epoch: 5| Step: 9
Training loss: 4.042179166934902
Validation loss: 3.3636242986683764

Epoch: 5| Step: 10
Training loss: 2.827375281000783
Validation loss: 3.3587023432440564

Epoch: 11| Step: 0
Training loss: 3.9525089311589308
Validation loss: 3.352481075837655

Epoch: 5| Step: 1
Training loss: 2.951794521406672
Validation loss: 3.345504518172298

Epoch: 5| Step: 2
Training loss: 3.556073465641844
Validation loss: 3.339924108342931

Epoch: 5| Step: 3
Training loss: 3.223596720015309
Validation loss: 3.3340715442020956

Epoch: 5| Step: 4
Training loss: 4.2187678583968085
Validation loss: 3.3294988578562807

Epoch: 5| Step: 5
Training loss: 2.979228750440075
Validation loss: 3.3251650007302676

Epoch: 5| Step: 6
Training loss: 3.8369803011510104
Validation loss: 3.3210394653305686

Epoch: 5| Step: 7
Training loss: 4.3764890044257365
Validation loss: 3.3177557431373574

Epoch: 5| Step: 8
Training loss: 3.5588688330578644
Validation loss: 3.311279071094672

Epoch: 5| Step: 9
Training loss: 3.386370543076627
Validation loss: 3.3070030256334464

Epoch: 5| Step: 10
Training loss: 2.6432928569367715
Validation loss: 3.300795787806691

Epoch: 12| Step: 0
Training loss: 3.6114579172778747
Validation loss: 3.299224395878054

Epoch: 5| Step: 1
Training loss: 3.4625323132270696
Validation loss: 3.2973649882113136

Epoch: 5| Step: 2
Training loss: 3.9098417325196233
Validation loss: 3.2936095618499963

Epoch: 5| Step: 3
Training loss: 3.9979990484361534
Validation loss: 3.2902365605303387

Epoch: 5| Step: 4
Training loss: 2.96872124908981
Validation loss: 3.283190923646175

Epoch: 5| Step: 5
Training loss: 3.7605739289401576
Validation loss: 3.280690275816102

Epoch: 5| Step: 6
Training loss: 3.680641131735747
Validation loss: 3.2764294898518087

Epoch: 5| Step: 7
Training loss: 3.787626958047431
Validation loss: 3.275169625985828

Epoch: 5| Step: 8
Training loss: 2.9381765033011176
Validation loss: 3.2708392362983525

Epoch: 5| Step: 9
Training loss: 3.5791316719401998
Validation loss: 3.2707097756696877

Epoch: 5| Step: 10
Training loss: 2.7926031980510833
Validation loss: 3.270082927835331

Epoch: 13| Step: 0
Training loss: 2.7763711377148295
Validation loss: 3.26675539607761

Epoch: 5| Step: 1
Training loss: 3.0373283871495156
Validation loss: 3.2655766240127515

Epoch: 5| Step: 2
Training loss: 3.725014675034668
Validation loss: 3.2597320229908555

Epoch: 5| Step: 3
Training loss: 4.0073296626033
Validation loss: 3.256784419252659

Epoch: 5| Step: 4
Training loss: 3.08665732185262
Validation loss: 3.2541691753229727

Epoch: 5| Step: 5
Training loss: 3.500318240275179
Validation loss: 3.2545320765125356

Epoch: 5| Step: 6
Training loss: 4.141760558836471
Validation loss: 3.2501201402341766

Epoch: 5| Step: 7
Training loss: 3.716772499345319
Validation loss: 3.2474668505091233

Epoch: 5| Step: 8
Training loss: 2.7640385792216318
Validation loss: 3.2432547192482297

Epoch: 5| Step: 9
Training loss: 4.170761359804055
Validation loss: 3.240408137791076

Epoch: 5| Step: 10
Training loss: 3.1739543244140735
Validation loss: 3.2388234316392017

Epoch: 14| Step: 0
Training loss: 3.0750825824348107
Validation loss: 3.235783664983804

Epoch: 5| Step: 1
Training loss: 3.0441461324917296
Validation loss: 3.2340766460403687

Epoch: 5| Step: 2
Training loss: 3.545324314277638
Validation loss: 3.2324682505205766

Epoch: 5| Step: 3
Training loss: 3.1554071792976397
Validation loss: 3.232222587673707

Epoch: 5| Step: 4
Training loss: 3.4611495321177905
Validation loss: 3.235533865892443

Epoch: 5| Step: 5
Training loss: 3.9041716883303748
Validation loss: 3.23055034344495

Epoch: 5| Step: 6
Training loss: 3.8167806888745037
Validation loss: 3.2251608929664015

Epoch: 5| Step: 7
Training loss: 2.7025833028116772
Validation loss: 3.224786099139096

Epoch: 5| Step: 8
Training loss: 3.825523270860921
Validation loss: 3.222558278831651

Epoch: 5| Step: 9
Training loss: 4.076971950708667
Validation loss: 3.2227605613514894

Epoch: 5| Step: 10
Training loss: 3.427982958178185
Validation loss: 3.2172453465997783

Epoch: 15| Step: 0
Training loss: 3.3475498462979916
Validation loss: 3.2166116638258706

Epoch: 5| Step: 1
Training loss: 2.9678606809424823
Validation loss: 3.2147174204779234

Epoch: 5| Step: 2
Training loss: 4.185592672477514
Validation loss: 3.215748780858622

Epoch: 5| Step: 3
Training loss: 3.003107527762405
Validation loss: 3.2123539719019845

Epoch: 5| Step: 4
Training loss: 3.773638417836205
Validation loss: 3.2101112577932978

Epoch: 5| Step: 5
Training loss: 3.306150576966095
Validation loss: 3.2086678612740536

Epoch: 5| Step: 6
Training loss: 2.999810689675127
Validation loss: 3.207250577525707

Epoch: 5| Step: 7
Training loss: 3.731694236904543
Validation loss: 3.2051332146610965

Epoch: 5| Step: 8
Training loss: 3.1021979999719993
Validation loss: 3.2032788855731344

Epoch: 5| Step: 9
Training loss: 3.3680455647917937
Validation loss: 3.201667982099686

Epoch: 5| Step: 10
Training loss: 4.186771158586889
Validation loss: 3.200323389617234

Epoch: 16| Step: 0
Training loss: 3.639037477858505
Validation loss: 3.1979877356738027

Epoch: 5| Step: 1
Training loss: 3.116829528905272
Validation loss: 3.196797900349311

Epoch: 5| Step: 2
Training loss: 2.785790840606125
Validation loss: 3.194337794619233

Epoch: 5| Step: 3
Training loss: 4.24680679637045
Validation loss: 3.1931208539236433

Epoch: 5| Step: 4
Training loss: 3.703923521582938
Validation loss: 3.190943288766587

Epoch: 5| Step: 5
Training loss: 3.7316316240126843
Validation loss: 3.187806544401535

Epoch: 5| Step: 6
Training loss: 2.552684033341841
Validation loss: 3.1860326437318864

Epoch: 5| Step: 7
Training loss: 3.8392235380188438
Validation loss: 3.1871879645278085

Epoch: 5| Step: 8
Training loss: 2.9243866432253287
Validation loss: 3.1849088727501185

Epoch: 5| Step: 9
Training loss: 3.366343664657413
Validation loss: 3.187614930260697

Epoch: 5| Step: 10
Training loss: 3.7264422191346034
Validation loss: 3.1841624217281743

Epoch: 17| Step: 0
Training loss: 2.6708728182329344
Validation loss: 3.1804031518496627

Epoch: 5| Step: 1
Training loss: 3.565679904471564
Validation loss: 3.1768889285838835

Epoch: 5| Step: 2
Training loss: 3.548596203982766
Validation loss: 3.1750449398259017

Epoch: 5| Step: 3
Training loss: 2.901779838807582
Validation loss: 3.1704674521568283

Epoch: 5| Step: 4
Training loss: 3.924867377500702
Validation loss: 3.1696806318045474

Epoch: 5| Step: 5
Training loss: 3.9019149529414134
Validation loss: 3.16794998533412

Epoch: 5| Step: 6
Training loss: 3.606247376650909
Validation loss: 3.16867647742058

Epoch: 5| Step: 7
Training loss: 3.012772866708427
Validation loss: 3.169871032382727

Epoch: 5| Step: 8
Training loss: 3.3441850610932637
Validation loss: 3.1700023370766983

Epoch: 5| Step: 9
Training loss: 3.20326418690542
Validation loss: 3.1673370873020765

Epoch: 5| Step: 10
Training loss: 3.9250965033652334
Validation loss: 3.163468360593822

Epoch: 18| Step: 0
Training loss: 3.7671085458564435
Validation loss: 3.1584994904524377

Epoch: 5| Step: 1
Training loss: 3.9810191663957673
Validation loss: 3.160348009622451

Epoch: 5| Step: 2
Training loss: 2.763433590379016
Validation loss: 3.161660560218729

Epoch: 5| Step: 3
Training loss: 4.013146255120817
Validation loss: 3.1593371449673464

Epoch: 5| Step: 4
Training loss: 3.5529356947151816
Validation loss: 3.1566020063040656

Epoch: 5| Step: 5
Training loss: 2.940037057863613
Validation loss: 3.155309195156919

Epoch: 5| Step: 6
Training loss: 2.888392560659416
Validation loss: 3.156793285857237

Epoch: 5| Step: 7
Training loss: 3.296284120952331
Validation loss: 3.160985804539035

Epoch: 5| Step: 8
Training loss: 2.619562511900348
Validation loss: 3.158772066337772

Epoch: 5| Step: 9
Training loss: 3.6191955661051716
Validation loss: 3.1528478590584705

Epoch: 5| Step: 10
Training loss: 3.906678931528396
Validation loss: 3.1528007514678795

Epoch: 19| Step: 0
Training loss: 3.8585904825972577
Validation loss: 3.149020695783301

Epoch: 5| Step: 1
Training loss: 3.343050446819196
Validation loss: 3.1480099121959033

Epoch: 5| Step: 2
Training loss: 2.812811770643011
Validation loss: 3.1464703887386007

Epoch: 5| Step: 3
Training loss: 3.407364409247597
Validation loss: 3.146051269058004

Epoch: 5| Step: 4
Training loss: 3.258232547017529
Validation loss: 3.146088225082329

Epoch: 5| Step: 5
Training loss: 3.453607309757756
Validation loss: 3.1459821652125006

Epoch: 5| Step: 6
Training loss: 3.6469685703489128
Validation loss: 3.144428123230682

Epoch: 5| Step: 7
Training loss: 3.482501154760428
Validation loss: 3.143086079247259

Epoch: 5| Step: 8
Training loss: 3.295506776497422
Validation loss: 3.1429711316392184

Epoch: 5| Step: 9
Training loss: 3.3995515247092274
Validation loss: 3.139964364453581

Epoch: 5| Step: 10
Training loss: 3.518034249343406
Validation loss: 3.1402320083312834

Epoch: 20| Step: 0
Training loss: 3.7947341471998803
Validation loss: 3.1371940704521037

Epoch: 5| Step: 1
Training loss: 3.165492358728567
Validation loss: 3.135407355646327

Epoch: 5| Step: 2
Training loss: 3.795438769561592
Validation loss: 3.135284809161777

Epoch: 5| Step: 3
Training loss: 3.7352309263608037
Validation loss: 3.1323165912260515

Epoch: 5| Step: 4
Training loss: 3.3651574336913024
Validation loss: 3.130351926402376

Epoch: 5| Step: 5
Training loss: 3.1776396884421914
Validation loss: 3.12758471336803

Epoch: 5| Step: 6
Training loss: 3.0050156309511507
Validation loss: 3.1257131078742066

Epoch: 5| Step: 7
Training loss: 3.0882152022448137
Validation loss: 3.125273167966071

Epoch: 5| Step: 8
Training loss: 3.460770785964219
Validation loss: 3.1349943840980226

Epoch: 5| Step: 9
Training loss: 3.4021668765915583
Validation loss: 3.1388626079987927

Epoch: 5| Step: 10
Training loss: 3.3384818529473086
Validation loss: 3.127142141222235

Epoch: 21| Step: 0
Training loss: 3.403717639557727
Validation loss: 3.121518140831483

Epoch: 5| Step: 1
Training loss: 3.1135295161068344
Validation loss: 3.1206945494393823

Epoch: 5| Step: 2
Training loss: 2.957731660361878
Validation loss: 3.1250326831708235

Epoch: 5| Step: 3
Training loss: 3.209515407503285
Validation loss: 3.1254149573680707

Epoch: 5| Step: 4
Training loss: 2.893097845622948
Validation loss: 3.1298215885601257

Epoch: 5| Step: 5
Training loss: 2.957010770497527
Validation loss: 3.1236449652987845

Epoch: 5| Step: 6
Training loss: 2.8306741764701497
Validation loss: 3.120474548123317

Epoch: 5| Step: 7
Training loss: 4.183632502300679
Validation loss: 3.1164534077033093

Epoch: 5| Step: 8
Training loss: 3.3773151510326263
Validation loss: 3.1154137856658886

Epoch: 5| Step: 9
Training loss: 4.442934389016726
Validation loss: 3.113757834678135

Epoch: 5| Step: 10
Training loss: 3.5570544735799503
Validation loss: 3.1223613165073996

Epoch: 22| Step: 0
Training loss: 3.9041146507312883
Validation loss: 3.121456585283348

Epoch: 5| Step: 1
Training loss: 3.633981430510134
Validation loss: 3.12307863132687

Epoch: 5| Step: 2
Training loss: 3.519168000946286
Validation loss: 3.115540841295731

Epoch: 5| Step: 3
Training loss: 3.309352747164251
Validation loss: 3.1092215393126486

Epoch: 5| Step: 4
Training loss: 2.4514673548871984
Validation loss: 3.1069789969016313

Epoch: 5| Step: 5
Training loss: 3.659972032533946
Validation loss: 3.114645195373842

Epoch: 5| Step: 6
Training loss: 3.6742574551437857
Validation loss: 3.1129295020822476

Epoch: 5| Step: 7
Training loss: 3.712042649994202
Validation loss: 3.1175989827304815

Epoch: 5| Step: 8
Training loss: 2.9071729281561667
Validation loss: 3.1030328522605197

Epoch: 5| Step: 9
Training loss: 3.2041457619913163
Validation loss: 3.114923422731411

Epoch: 5| Step: 10
Training loss: 2.9166447956536756
Validation loss: 3.1482273460070678

Epoch: 23| Step: 0
Training loss: 3.2379216453492043
Validation loss: 3.139254533071705

Epoch: 5| Step: 1
Training loss: 3.2586875124648027
Validation loss: 3.105766835904242

Epoch: 5| Step: 2
Training loss: 3.4342027976796623
Validation loss: 3.1013840148490806

Epoch: 5| Step: 3
Training loss: 2.8791861533919247
Validation loss: 3.100180146788088

Epoch: 5| Step: 4
Training loss: 4.027846207896087
Validation loss: 3.1084950583461546

Epoch: 5| Step: 5
Training loss: 3.602574932264161
Validation loss: 3.101497966152533

Epoch: 5| Step: 6
Training loss: 3.187333944146548
Validation loss: 3.095031531689492

Epoch: 5| Step: 7
Training loss: 3.5543829818912323
Validation loss: 3.0977772751640122

Epoch: 5| Step: 8
Training loss: 3.7001500795186555
Validation loss: 3.0973519671582923

Epoch: 5| Step: 9
Training loss: 3.440131965811734
Validation loss: 3.0952425286091008

Epoch: 5| Step: 10
Training loss: 2.3818243260274574
Validation loss: 3.0973111014557686

Epoch: 24| Step: 0
Training loss: 2.5938105748468328
Validation loss: 3.099474043559495

Epoch: 5| Step: 1
Training loss: 4.043110985949081
Validation loss: 3.1044993041001843

Epoch: 5| Step: 2
Training loss: 3.3725738282037017
Validation loss: 3.0966891880934653

Epoch: 5| Step: 3
Training loss: 3.4981790983001684
Validation loss: 3.0904289361341193

Epoch: 5| Step: 4
Training loss: 3.2029887844988605
Validation loss: 3.0865135526460112

Epoch: 5| Step: 5
Training loss: 3.8690146705426205
Validation loss: 3.0866532654162273

Epoch: 5| Step: 6
Training loss: 3.736711098585165
Validation loss: 3.0863999709354095

Epoch: 5| Step: 7
Training loss: 2.795389132358168
Validation loss: 3.082512568912341

Epoch: 5| Step: 8
Training loss: 2.6864735617075977
Validation loss: 3.0848681485897065

Epoch: 5| Step: 9
Training loss: 3.472052299580251
Validation loss: 3.087666695528636

Epoch: 5| Step: 10
Training loss: 3.4019028107464577
Validation loss: 3.093730141302622

Epoch: 25| Step: 0
Training loss: 4.00942098304265
Validation loss: 3.091874421789047

Epoch: 5| Step: 1
Training loss: 3.126259511805802
Validation loss: 3.0773542209636386

Epoch: 5| Step: 2
Training loss: 3.9308260108330164
Validation loss: 3.0751428837214765

Epoch: 5| Step: 3
Training loss: 3.5830627753262587
Validation loss: 3.0760796277131206

Epoch: 5| Step: 4
Training loss: 2.529663530675607
Validation loss: 3.074575205968838

Epoch: 5| Step: 5
Training loss: 3.7181467801198522
Validation loss: 3.074828519057371

Epoch: 5| Step: 6
Training loss: 3.42823708697869
Validation loss: 3.0731354538395674

Epoch: 5| Step: 7
Training loss: 1.8046543399026698
Validation loss: 3.073103105504252

Epoch: 5| Step: 8
Training loss: 3.6141497583736273
Validation loss: 3.0725869017299843

Epoch: 5| Step: 9
Training loss: 3.333239426879548
Validation loss: 3.07555976492869

Epoch: 5| Step: 10
Training loss: 3.1260499334856293
Validation loss: 3.075720726379412

Epoch: 26| Step: 0
Training loss: 3.4477513822063592
Validation loss: 3.077800505633564

Epoch: 5| Step: 1
Training loss: 3.064248189401041
Validation loss: 3.0759791149576823

Epoch: 5| Step: 2
Training loss: 3.7531915434846863
Validation loss: 3.0828504480802033

Epoch: 5| Step: 3
Training loss: 3.7318493590131285
Validation loss: 3.082283393894146

Epoch: 5| Step: 4
Training loss: 3.043979148933689
Validation loss: 3.0864333136996303

Epoch: 5| Step: 5
Training loss: 3.24877906754022
Validation loss: 3.0659994340019305

Epoch: 5| Step: 6
Training loss: 2.827208312459663
Validation loss: 3.065816237725454

Epoch: 5| Step: 7
Training loss: 3.7217568174571234
Validation loss: 3.063962749890178

Epoch: 5| Step: 8
Training loss: 2.8000295739655656
Validation loss: 3.0702633445044785

Epoch: 5| Step: 9
Training loss: 3.5166163424345753
Validation loss: 3.081205653843887

Epoch: 5| Step: 10
Training loss: 3.459971273666822
Validation loss: 3.061401969780684

Epoch: 27| Step: 0
Training loss: 3.1828628918081465
Validation loss: 3.0608481028124084

Epoch: 5| Step: 1
Training loss: 3.6102275419512115
Validation loss: 3.0681297719891583

Epoch: 5| Step: 2
Training loss: 2.6092834456594556
Validation loss: 3.0799935574724535

Epoch: 5| Step: 3
Training loss: 3.437004747260386
Validation loss: 3.098658155650854

Epoch: 5| Step: 4
Training loss: 3.4243346131810464
Validation loss: 3.0755504824736635

Epoch: 5| Step: 5
Training loss: 3.085687477510045
Validation loss: 3.067481893649847

Epoch: 5| Step: 6
Training loss: 3.8002623216534546
Validation loss: 3.065593393590264

Epoch: 5| Step: 7
Training loss: 3.87178977152054
Validation loss: 3.06061395258475

Epoch: 5| Step: 8
Training loss: 2.686883633926479
Validation loss: 3.0574622827330438

Epoch: 5| Step: 9
Training loss: 3.2850677079142607
Validation loss: 3.0580243641084963

Epoch: 5| Step: 10
Training loss: 3.4813943610402025
Validation loss: 3.0558406895050254

Epoch: 28| Step: 0
Training loss: 3.4463365205095187
Validation loss: 3.0553052516922854

Epoch: 5| Step: 1
Training loss: 3.108296422935244
Validation loss: 3.057595911072272

Epoch: 5| Step: 2
Training loss: 2.7845965193495683
Validation loss: 3.062404996910617

Epoch: 5| Step: 3
Training loss: 3.6204882200861013
Validation loss: 3.066535820204872

Epoch: 5| Step: 4
Training loss: 3.0336597735077224
Validation loss: 3.0612880442472417

Epoch: 5| Step: 5
Training loss: 3.6880572916243737
Validation loss: 3.0619409154212507

Epoch: 5| Step: 6
Training loss: 3.507357901361392
Validation loss: 3.0596202145846014

Epoch: 5| Step: 7
Training loss: 3.070186699772501
Validation loss: 3.0501012792368996

Epoch: 5| Step: 8
Training loss: 3.0478276255167844
Validation loss: 3.0503334932250232

Epoch: 5| Step: 9
Training loss: 3.5581467114242957
Validation loss: 3.048783015837623

Epoch: 5| Step: 10
Training loss: 3.657601652786135
Validation loss: 3.0500715603394273

Epoch: 29| Step: 0
Training loss: 3.267049816264381
Validation loss: 3.051175549291962

Epoch: 5| Step: 1
Training loss: 3.5657129355443766
Validation loss: 3.0523022414239156

Epoch: 5| Step: 2
Training loss: 2.9455835030536672
Validation loss: 3.052090040719827

Epoch: 5| Step: 3
Training loss: 3.3813002379910713
Validation loss: 3.051637932793281

Epoch: 5| Step: 4
Training loss: 3.5119693993384464
Validation loss: 3.051878406555459

Epoch: 5| Step: 5
Training loss: 3.45205575260125
Validation loss: 3.0492226886238556

Epoch: 5| Step: 6
Training loss: 3.389186290205482
Validation loss: 3.0441635549292174

Epoch: 5| Step: 7
Training loss: 3.559418399536158
Validation loss: 3.0410597669556005

Epoch: 5| Step: 8
Training loss: 2.6377763901656603
Validation loss: 3.040775039151813

Epoch: 5| Step: 9
Training loss: 3.2860064228573216
Validation loss: 3.039600088885298

Epoch: 5| Step: 10
Training loss: 3.4012251722164972
Validation loss: 3.0368230721619547

Epoch: 30| Step: 0
Training loss: 2.912810437599011
Validation loss: 3.035790242945651

Epoch: 5| Step: 1
Training loss: 3.5100760516325895
Validation loss: 3.0350482327189736

Epoch: 5| Step: 2
Training loss: 4.048549938812125
Validation loss: 3.034202944692702

Epoch: 5| Step: 3
Training loss: 3.2723931806716395
Validation loss: 3.033070744675761

Epoch: 5| Step: 4
Training loss: 3.03691452726056
Validation loss: 3.034057007631982

Epoch: 5| Step: 5
Training loss: 2.784789672525133
Validation loss: 3.034669921468875

Epoch: 5| Step: 6
Training loss: 2.7869726734279405
Validation loss: 3.0343598513098713

Epoch: 5| Step: 7
Training loss: 3.4022481666216344
Validation loss: 3.033369221069909

Epoch: 5| Step: 8
Training loss: 3.0670361303210667
Validation loss: 3.04213532868675

Epoch: 5| Step: 9
Training loss: 3.6753197926586068
Validation loss: 3.0421380523271964

Epoch: 5| Step: 10
Training loss: 3.7000902835037826
Validation loss: 3.036221635858638

Epoch: 31| Step: 0
Training loss: 2.5772358603789436
Validation loss: 3.032868056959102

Epoch: 5| Step: 1
Training loss: 3.237704125527156
Validation loss: 3.028567721727227

Epoch: 5| Step: 2
Training loss: 3.4570798019189457
Validation loss: 3.0270684615190224

Epoch: 5| Step: 3
Training loss: 3.1860979774098714
Validation loss: 3.0225722052549275

Epoch: 5| Step: 4
Training loss: 3.248430019588399
Validation loss: 3.0228016286340336

Epoch: 5| Step: 5
Training loss: 3.3607542533345325
Validation loss: 3.022265368454877

Epoch: 5| Step: 6
Training loss: 3.456842139292561
Validation loss: 3.018589745306872

Epoch: 5| Step: 7
Training loss: 3.380936946232422
Validation loss: 3.0133187139161737

Epoch: 5| Step: 8
Training loss: 3.557633405423849
Validation loss: 3.012230452559843

Epoch: 5| Step: 9
Training loss: 2.8300184792498277
Validation loss: 3.0096217569031776

Epoch: 5| Step: 10
Training loss: 3.899827728379185
Validation loss: 3.007193186381882

Epoch: 32| Step: 0
Training loss: 3.294582347188673
Validation loss: 3.0065519182513727

Epoch: 5| Step: 1
Training loss: 3.3244925721260956
Validation loss: 3.0038106705158634

Epoch: 5| Step: 2
Training loss: 3.410820790284934
Validation loss: 3.0047167747809045

Epoch: 5| Step: 3
Training loss: 2.687997638848948
Validation loss: 3.002087967133867

Epoch: 5| Step: 4
Training loss: 2.7074739608850997
Validation loss: 3.010809604942531

Epoch: 5| Step: 5
Training loss: 3.8280871331035313
Validation loss: 3.019042043593608

Epoch: 5| Step: 6
Training loss: 3.423923663010329
Validation loss: 3.027575514671568

Epoch: 5| Step: 7
Training loss: 2.7619362924839947
Validation loss: 3.0149612967319923

Epoch: 5| Step: 8
Training loss: 3.367744134267632
Validation loss: 3.007217934436564

Epoch: 5| Step: 9
Training loss: 3.3085629080063375
Validation loss: 3.011978478916148

Epoch: 5| Step: 10
Training loss: 3.824329721401276
Validation loss: 3.0082412752908785

Epoch: 33| Step: 0
Training loss: 3.5472812503957423
Validation loss: 2.997157442176449

Epoch: 5| Step: 1
Training loss: 3.3811248022793934
Validation loss: 2.99584889772783

Epoch: 5| Step: 2
Training loss: 3.6651280527265757
Validation loss: 2.994260509553515

Epoch: 5| Step: 3
Training loss: 2.8905171142240396
Validation loss: 2.996784575558593

Epoch: 5| Step: 4
Training loss: 3.5270174029715613
Validation loss: 2.997336111591607

Epoch: 5| Step: 5
Training loss: 2.879042727005937
Validation loss: 3.006707558160675

Epoch: 5| Step: 6
Training loss: 2.798642074459951
Validation loss: 3.006922161821121

Epoch: 5| Step: 7
Training loss: 3.5346201790546976
Validation loss: 3.008236586450962

Epoch: 5| Step: 8
Training loss: 3.0445788999631107
Validation loss: 2.9871032619259688

Epoch: 5| Step: 9
Training loss: 3.2014075163995557
Validation loss: 2.9867705454959568

Epoch: 5| Step: 10
Training loss: 3.4320726030490816
Validation loss: 2.987172173219752

Epoch: 34| Step: 0
Training loss: 3.658687724426364
Validation loss: 2.986877273735755

Epoch: 5| Step: 1
Training loss: 2.534446205427684
Validation loss: 2.9868881441018904

Epoch: 5| Step: 2
Training loss: 3.0475225298504833
Validation loss: 2.9869206468185405

Epoch: 5| Step: 3
Training loss: 3.3292883330748833
Validation loss: 2.9863856257556742

Epoch: 5| Step: 4
Training loss: 2.9139927914542723
Validation loss: 2.986798926965912

Epoch: 5| Step: 5
Training loss: 3.036098417453536
Validation loss: 2.9857936339959363

Epoch: 5| Step: 6
Training loss: 2.771699516650715
Validation loss: 2.983640793822193

Epoch: 5| Step: 7
Training loss: 4.08966233107059
Validation loss: 2.990156736920134

Epoch: 5| Step: 8
Training loss: 3.14439279950449
Validation loss: 2.9895798837965484

Epoch: 5| Step: 9
Training loss: 3.596515155626129
Validation loss: 2.99924522308533

Epoch: 5| Step: 10
Training loss: 3.53322377364924
Validation loss: 2.992051246908189

Epoch: 35| Step: 0
Training loss: 3.7411887602122635
Validation loss: 2.9822120836893014

Epoch: 5| Step: 1
Training loss: 3.236224102035987
Validation loss: 2.979227901121718

Epoch: 5| Step: 2
Training loss: 3.544334005577186
Validation loss: 2.9788967233719164

Epoch: 5| Step: 3
Training loss: 3.1781102423011127
Validation loss: 2.979909306189646

Epoch: 5| Step: 4
Training loss: 2.4623409084301495
Validation loss: 2.980073251488082

Epoch: 5| Step: 5
Training loss: 2.7533690016455137
Validation loss: 2.979604194284004

Epoch: 5| Step: 6
Training loss: 3.4149621262691245
Validation loss: 2.980974091568229

Epoch: 5| Step: 7
Training loss: 3.775186642712767
Validation loss: 2.979454424765231

Epoch: 5| Step: 8
Training loss: 3.042303480260215
Validation loss: 2.9744349539304755

Epoch: 5| Step: 9
Training loss: 3.1879990130988953
Validation loss: 2.9736202754643064

Epoch: 5| Step: 10
Training loss: 3.2328042164360404
Validation loss: 2.97211890267399

Epoch: 36| Step: 0
Training loss: 3.775561128053026
Validation loss: 2.971867094258754

Epoch: 5| Step: 1
Training loss: 3.4856206608868905
Validation loss: 2.969852043052586

Epoch: 5| Step: 2
Training loss: 3.329894978697201
Validation loss: 2.968865997345305

Epoch: 5| Step: 3
Training loss: 3.0590391261082353
Validation loss: 2.9694818688047335

Epoch: 5| Step: 4
Training loss: 3.479813947636922
Validation loss: 2.9653526949202096

Epoch: 5| Step: 5
Training loss: 2.6981265208593714
Validation loss: 2.966596660730529

Epoch: 5| Step: 6
Training loss: 2.8424211688085763
Validation loss: 2.965632250461753

Epoch: 5| Step: 7
Training loss: 3.6632142864411072
Validation loss: 2.965361570186691

Epoch: 5| Step: 8
Training loss: 3.4969219569376433
Validation loss: 2.966428478321163

Epoch: 5| Step: 9
Training loss: 2.7266321911144042
Validation loss: 2.963880623831942

Epoch: 5| Step: 10
Training loss: 2.841799727500716
Validation loss: 2.9667909826239494

Epoch: 37| Step: 0
Training loss: 2.853961092560072
Validation loss: 2.9825490940830712

Epoch: 5| Step: 1
Training loss: 2.7140464874480417
Validation loss: 3.0169127601583314

Epoch: 5| Step: 2
Training loss: 3.787607444523336
Validation loss: 2.997710884263412

Epoch: 5| Step: 3
Training loss: 3.328816803144764
Validation loss: 2.9622192162867527

Epoch: 5| Step: 4
Training loss: 3.8163336568310204
Validation loss: 2.96310369722489

Epoch: 5| Step: 5
Training loss: 3.4460546684600257
Validation loss: 2.980567355597164

Epoch: 5| Step: 6
Training loss: 3.464323639135403
Validation loss: 3.053264263599004

Epoch: 5| Step: 7
Training loss: 3.2890971492292334
Validation loss: 2.967059683463685

Epoch: 5| Step: 8
Training loss: 2.667717090986048
Validation loss: 2.9590444222931955

Epoch: 5| Step: 9
Training loss: 3.257481107620412
Validation loss: 2.9635365708836074

Epoch: 5| Step: 10
Training loss: 2.908387741264916
Validation loss: 2.9973145184494943

Epoch: 38| Step: 0
Training loss: 2.3553033520780415
Validation loss: 3.0115909942211356

Epoch: 5| Step: 1
Training loss: 4.089152775993463
Validation loss: 3.009597469858946

Epoch: 5| Step: 2
Training loss: 3.647986177878378
Validation loss: 2.962534558487641

Epoch: 5| Step: 3
Training loss: 3.645999199863499
Validation loss: 2.9535029019175454

Epoch: 5| Step: 4
Training loss: 3.230996103844615
Validation loss: 2.950339801823972

Epoch: 5| Step: 5
Training loss: 2.8145967932623277
Validation loss: 2.948497709011715

Epoch: 5| Step: 6
Training loss: 3.558503569581478
Validation loss: 2.9529525064924664

Epoch: 5| Step: 7
Training loss: 2.910892183582786
Validation loss: 2.9595095785897847

Epoch: 5| Step: 8
Training loss: 2.9924897920184246
Validation loss: 2.9510884052909714

Epoch: 5| Step: 9
Training loss: 3.0987242196177456
Validation loss: 2.948956534476047

Epoch: 5| Step: 10
Training loss: 3.029774414830375
Validation loss: 2.9463656673349674

Epoch: 39| Step: 0
Training loss: 3.399062526710246
Validation loss: 2.947008613498928

Epoch: 5| Step: 1
Training loss: 3.5505561715310554
Validation loss: 2.946195285864464

Epoch: 5| Step: 2
Training loss: 3.2458307960771298
Validation loss: 2.9464831706173573

Epoch: 5| Step: 3
Training loss: 2.6751923964287423
Validation loss: 2.9473766593388513

Epoch: 5| Step: 4
Training loss: 3.253060147301376
Validation loss: 2.950987412525836

Epoch: 5| Step: 5
Training loss: 3.4187719480378376
Validation loss: 2.9526543542521706

Epoch: 5| Step: 6
Training loss: 3.219726414401346
Validation loss: 2.9561398676411033

Epoch: 5| Step: 7
Training loss: 3.215459827151385
Validation loss: 2.9555589739749686

Epoch: 5| Step: 8
Training loss: 2.9942568801835234
Validation loss: 2.961126339404516

Epoch: 5| Step: 9
Training loss: 3.281842423500554
Validation loss: 2.962506011192503

Epoch: 5| Step: 10
Training loss: 3.2032402203933907
Validation loss: 2.952804972595487

Epoch: 40| Step: 0
Training loss: 3.207241334899144
Validation loss: 2.9493482513887503

Epoch: 5| Step: 1
Training loss: 3.5983534809330053
Validation loss: 2.946748277102644

Epoch: 5| Step: 2
Training loss: 3.1306932087552415
Validation loss: 2.9418955294672435

Epoch: 5| Step: 3
Training loss: 3.356178927956607
Validation loss: 2.942615818519048

Epoch: 5| Step: 4
Training loss: 3.202302557332953
Validation loss: 2.949482626689849

Epoch: 5| Step: 5
Training loss: 3.2144429546829936
Validation loss: 2.9446765705678426

Epoch: 5| Step: 6
Training loss: 3.7468720424153648
Validation loss: 2.945170128196746

Epoch: 5| Step: 7
Training loss: 2.855946303901998
Validation loss: 2.9427145861051867

Epoch: 5| Step: 8
Training loss: 3.483543536279234
Validation loss: 2.9368877833280878

Epoch: 5| Step: 9
Training loss: 1.859319926496124
Validation loss: 2.9364726116423734

Epoch: 5| Step: 10
Training loss: 3.4115418091478764
Validation loss: 2.935923928311062

Epoch: 41| Step: 0
Training loss: 3.403246894383847
Validation loss: 2.9324934549430584

Epoch: 5| Step: 1
Training loss: 3.6956644999500976
Validation loss: 2.9324957147975446

Epoch: 5| Step: 2
Training loss: 3.676595178176
Validation loss: 2.9309661765608124

Epoch: 5| Step: 3
Training loss: 3.260840163996739
Validation loss: 2.9277885336940805

Epoch: 5| Step: 4
Training loss: 2.958106144164547
Validation loss: 2.9289401926165

Epoch: 5| Step: 5
Training loss: 3.169230293426307
Validation loss: 2.928472530328242

Epoch: 5| Step: 6
Training loss: 2.93814794009272
Validation loss: 2.9244231980984603

Epoch: 5| Step: 7
Training loss: 3.0853890619753814
Validation loss: 2.9264024279650918

Epoch: 5| Step: 8
Training loss: 3.061341825753682
Validation loss: 2.9256177656356597

Epoch: 5| Step: 9
Training loss: 2.712765915313262
Validation loss: 2.925554106319091

Epoch: 5| Step: 10
Training loss: 3.250818442948057
Validation loss: 2.923218822622042

Epoch: 42| Step: 0
Training loss: 2.9217996026577215
Validation loss: 2.921779597450472

Epoch: 5| Step: 1
Training loss: 2.802063971432487
Validation loss: 2.922380927501525

Epoch: 5| Step: 2
Training loss: 2.772595860825122
Validation loss: 2.922955057017488

Epoch: 5| Step: 3
Training loss: 3.130183231974586
Validation loss: 2.92166924872249

Epoch: 5| Step: 4
Training loss: 3.1173554568825903
Validation loss: 2.9206925946059896

Epoch: 5| Step: 5
Training loss: 3.282112516846762
Validation loss: 2.9201294042769876

Epoch: 5| Step: 6
Training loss: 3.720507038386121
Validation loss: 2.9374330644349396

Epoch: 5| Step: 7
Training loss: 3.7116306661416707
Validation loss: 2.930518774525492

Epoch: 5| Step: 8
Training loss: 3.1124793423499497
Validation loss: 2.919226605591477

Epoch: 5| Step: 9
Training loss: 3.4229291572428036
Validation loss: 2.9191585256190606

Epoch: 5| Step: 10
Training loss: 3.1790878892756735
Validation loss: 2.9200732317675717

Epoch: 43| Step: 0
Training loss: 3.693725245049107
Validation loss: 2.9182251723136132

Epoch: 5| Step: 1
Training loss: 3.1143988275047074
Validation loss: 2.917242178559467

Epoch: 5| Step: 2
Training loss: 2.3838789757661467
Validation loss: 2.9154599577969456

Epoch: 5| Step: 3
Training loss: 3.4271627183124127
Validation loss: 2.9151262888880924

Epoch: 5| Step: 4
Training loss: 3.7691671719418265
Validation loss: 2.91343689859346

Epoch: 5| Step: 5
Training loss: 3.179667554788105
Validation loss: 2.9133608358548404

Epoch: 5| Step: 6
Training loss: 3.164518799080885
Validation loss: 2.915269894013838

Epoch: 5| Step: 7
Training loss: 3.0659238399395328
Validation loss: 2.917218721826442

Epoch: 5| Step: 8
Training loss: 3.433756228824239
Validation loss: 2.9187796736634346

Epoch: 5| Step: 9
Training loss: 2.8719439642494877
Validation loss: 2.9253788986885607

Epoch: 5| Step: 10
Training loss: 2.891844785922844
Validation loss: 2.9304079237850114

Epoch: 44| Step: 0
Training loss: 3.835661278003468
Validation loss: 2.925242798296173

Epoch: 5| Step: 1
Training loss: 2.6555933421154196
Validation loss: 2.915364494811588

Epoch: 5| Step: 2
Training loss: 3.3397653670900826
Validation loss: 2.9131247348135245

Epoch: 5| Step: 3
Training loss: 3.1432965052022532
Validation loss: 2.912347743176534

Epoch: 5| Step: 4
Training loss: 2.8963070671771614
Validation loss: 2.9112433193201657

Epoch: 5| Step: 5
Training loss: 2.9411762041203997
Validation loss: 2.9100752210351466

Epoch: 5| Step: 6
Training loss: 3.1335078583127745
Validation loss: 2.9097675657170945

Epoch: 5| Step: 7
Training loss: 3.531732846897606
Validation loss: 2.9099182925762626

Epoch: 5| Step: 8
Training loss: 3.175770439326618
Validation loss: 2.909977148127205

Epoch: 5| Step: 9
Training loss: 3.0282011134735716
Validation loss: 2.909533497039189

Epoch: 5| Step: 10
Training loss: 3.4167835556752797
Validation loss: 2.9106708907064314

Epoch: 45| Step: 0
Training loss: 3.218709704693161
Validation loss: 2.908628131388837

Epoch: 5| Step: 1
Training loss: 3.314516425441498
Validation loss: 2.9053268827818823

Epoch: 5| Step: 2
Training loss: 3.012361964945302
Validation loss: 2.905354333904116

Epoch: 5| Step: 3
Training loss: 3.0033344175934467
Validation loss: 2.902640060871436

Epoch: 5| Step: 4
Training loss: 3.3381868948570146
Validation loss: 2.9034603322122257

Epoch: 5| Step: 5
Training loss: 2.7073167702622936
Validation loss: 2.9003572683804464

Epoch: 5| Step: 6
Training loss: 3.3980419411049505
Validation loss: 2.8999967187502937

Epoch: 5| Step: 7
Training loss: 3.0441165272568913
Validation loss: 2.899863165759084

Epoch: 5| Step: 8
Training loss: 3.1465568131598043
Validation loss: 2.9020198823006

Epoch: 5| Step: 9
Training loss: 3.650231910549446
Validation loss: 2.905164134036814

Epoch: 5| Step: 10
Training loss: 3.1671847538684443
Validation loss: 2.9065129477264415

Epoch: 46| Step: 0
Training loss: 3.721818699639116
Validation loss: 2.9450548062039688

Epoch: 5| Step: 1
Training loss: 3.1633408465227544
Validation loss: 2.951013973261311

Epoch: 5| Step: 2
Training loss: 2.970601999943013
Validation loss: 2.9506304856410073

Epoch: 5| Step: 3
Training loss: 3.562439633577431
Validation loss: 2.927038335529108

Epoch: 5| Step: 4
Training loss: 3.2503861417992757
Validation loss: 2.896022247493408

Epoch: 5| Step: 5
Training loss: 3.1232890213544255
Validation loss: 2.8933730286767774

Epoch: 5| Step: 6
Training loss: 3.0164864846332557
Validation loss: 2.8914792329345533

Epoch: 5| Step: 7
Training loss: 3.5264722522686194
Validation loss: 2.891360865092345

Epoch: 5| Step: 8
Training loss: 2.6383838962313315
Validation loss: 2.8925870507347216

Epoch: 5| Step: 9
Training loss: 2.919268746195219
Validation loss: 2.899117696035861

Epoch: 5| Step: 10
Training loss: 3.0498764513350705
Validation loss: 2.8966773405482242

Epoch: 47| Step: 0
Training loss: 3.415933266678004
Validation loss: 2.8878765765707906

Epoch: 5| Step: 1
Training loss: 2.940600767451297
Validation loss: 2.8867652744227037

Epoch: 5| Step: 2
Training loss: 3.4288102333599686
Validation loss: 2.8849801645211786

Epoch: 5| Step: 3
Training loss: 3.0796457010081197
Validation loss: 2.885206797227682

Epoch: 5| Step: 4
Training loss: 3.0968687732991924
Validation loss: 2.8844912854528397

Epoch: 5| Step: 5
Training loss: 2.883971273451126
Validation loss: 2.8841718715747535

Epoch: 5| Step: 6
Training loss: 2.9964220645469504
Validation loss: 2.8858366315929542

Epoch: 5| Step: 7
Training loss: 3.1939787004557254
Validation loss: 2.8940769052809303

Epoch: 5| Step: 8
Training loss: 3.027963331254988
Validation loss: 2.8886637580898045

Epoch: 5| Step: 9
Training loss: 3.254839301998785
Validation loss: 2.895485839804649

Epoch: 5| Step: 10
Training loss: 3.6295253525313704
Validation loss: 2.899928761952025

Epoch: 48| Step: 0
Training loss: 3.152356758705346
Validation loss: 2.9071742103408713

Epoch: 5| Step: 1
Training loss: 3.7543035608552993
Validation loss: 2.9092892295834245

Epoch: 5| Step: 2
Training loss: 3.4380584263211484
Validation loss: 2.900772354109994

Epoch: 5| Step: 3
Training loss: 3.271949885257374
Validation loss: 2.878570624790278

Epoch: 5| Step: 4
Training loss: 3.1717733733334588
Validation loss: 2.879603898260019

Epoch: 5| Step: 5
Training loss: 3.0044978121087573
Validation loss: 2.877243203025409

Epoch: 5| Step: 6
Training loss: 3.8521689659050944
Validation loss: 2.878142447409438

Epoch: 5| Step: 7
Training loss: 2.3936346718518386
Validation loss: 2.8770891920997768

Epoch: 5| Step: 8
Training loss: 2.6710907973178055
Validation loss: 2.8785380671243637

Epoch: 5| Step: 9
Training loss: 3.113482345538353
Validation loss: 2.876420977575514

Epoch: 5| Step: 10
Training loss: 2.7797393982681067
Validation loss: 2.875886369405147

Epoch: 49| Step: 0
Training loss: 2.952214176254912
Validation loss: 2.8730176544649852

Epoch: 5| Step: 1
Training loss: 2.668824802752947
Validation loss: 2.8727256451604655

Epoch: 5| Step: 2
Training loss: 2.662309086362003
Validation loss: 2.872841404979016

Epoch: 5| Step: 3
Training loss: 2.7552327742090474
Validation loss: 2.8713625921198456

Epoch: 5| Step: 4
Training loss: 3.6411178320781707
Validation loss: 2.8713312866268135

Epoch: 5| Step: 5
Training loss: 2.9991522226907064
Validation loss: 2.869456778599143

Epoch: 5| Step: 6
Training loss: 3.5329469637481434
Validation loss: 2.8720809631108892

Epoch: 5| Step: 7
Training loss: 3.4145010310819597
Validation loss: 2.8709318047113537

Epoch: 5| Step: 8
Training loss: 3.6305559923177735
Validation loss: 2.8705810607012356

Epoch: 5| Step: 9
Training loss: 3.1453211959059186
Validation loss: 2.8703532517642683

Epoch: 5| Step: 10
Training loss: 3.245120126296442
Validation loss: 2.8681973046034077

Epoch: 50| Step: 0
Training loss: 2.845971884829202
Validation loss: 2.869994839021955

Epoch: 5| Step: 1
Training loss: 2.82720856544976
Validation loss: 2.86659241744963

Epoch: 5| Step: 2
Training loss: 3.197678713483124
Validation loss: 2.8649895546499087

Epoch: 5| Step: 3
Training loss: 3.2393374497954763
Validation loss: 2.8673003996725455

Epoch: 5| Step: 4
Training loss: 3.096732041401496
Validation loss: 2.864755933526816

Epoch: 5| Step: 5
Training loss: 3.489367820955107
Validation loss: 2.865888123832627

Epoch: 5| Step: 6
Training loss: 2.9599718919914415
Validation loss: 2.863474281086455

Epoch: 5| Step: 7
Training loss: 3.4667351171875964
Validation loss: 2.8670086628990785

Epoch: 5| Step: 8
Training loss: 3.034757806456333
Validation loss: 2.864492775538147

Epoch: 5| Step: 9
Training loss: 3.5161368442503935
Validation loss: 2.8611025899883713

Epoch: 5| Step: 10
Training loss: 2.974484977700906
Validation loss: 2.8626753522698354

Epoch: 51| Step: 0
Training loss: 3.6068780362095447
Validation loss: 2.860408575310947

Epoch: 5| Step: 1
Training loss: 2.665630516771017
Validation loss: 2.8625612922164634

Epoch: 5| Step: 2
Training loss: 3.443929312411438
Validation loss: 2.8642472545255955

Epoch: 5| Step: 3
Training loss: 2.8094870641505274
Validation loss: 2.860675127301698

Epoch: 5| Step: 4
Training loss: 3.323144902888416
Validation loss: 2.857111815607701

Epoch: 5| Step: 5
Training loss: 3.675656712821236
Validation loss: 2.8569648564539833

Epoch: 5| Step: 6
Training loss: 3.155793109721736
Validation loss: 2.854639926839114

Epoch: 5| Step: 7
Training loss: 3.459828907479496
Validation loss: 2.853890228597059

Epoch: 5| Step: 8
Training loss: 2.56214865159901
Validation loss: 2.854381804370467

Epoch: 5| Step: 9
Training loss: 3.053737795192893
Validation loss: 2.854112465773987

Epoch: 5| Step: 10
Training loss: 2.593855890157788
Validation loss: 2.8513018053038355

Epoch: 52| Step: 0
Training loss: 3.377808426695637
Validation loss: 2.8514819430644347

Epoch: 5| Step: 1
Training loss: 2.973515109534239
Validation loss: 2.851216409931543

Epoch: 5| Step: 2
Training loss: 3.0635476947730735
Validation loss: 2.849914374771637

Epoch: 5| Step: 3
Training loss: 3.4585262535855823
Validation loss: 2.8483256089800797

Epoch: 5| Step: 4
Training loss: 2.829481610918056
Validation loss: 2.8480844334858304

Epoch: 5| Step: 5
Training loss: 3.8465784102639313
Validation loss: 2.847164336912605

Epoch: 5| Step: 6
Training loss: 2.736902953930928
Validation loss: 2.8451180235456954

Epoch: 5| Step: 7
Training loss: 2.9921250299451425
Validation loss: 2.8464277286640525

Epoch: 5| Step: 8
Training loss: 2.8474584858776057
Validation loss: 2.8453383924577653

Epoch: 5| Step: 9
Training loss: 3.2871491219559217
Validation loss: 2.84419876014137

Epoch: 5| Step: 10
Training loss: 3.046600955474309
Validation loss: 2.845112687424679

Epoch: 53| Step: 0
Training loss: 2.788970176386867
Validation loss: 2.8415015219356654

Epoch: 5| Step: 1
Training loss: 2.53884332737942
Validation loss: 2.843594358977175

Epoch: 5| Step: 2
Training loss: 3.2181904130437857
Validation loss: 2.8486384048133377

Epoch: 5| Step: 3
Training loss: 3.2851919564609764
Validation loss: 2.8512088337740056

Epoch: 5| Step: 4
Training loss: 2.878429192156342
Validation loss: 2.8527557892522823

Epoch: 5| Step: 5
Training loss: 3.4648313640386
Validation loss: 2.8693964388096274

Epoch: 5| Step: 6
Training loss: 3.2297913142010546
Validation loss: 2.920233011071129

Epoch: 5| Step: 7
Training loss: 3.325760408801712
Validation loss: 2.858643379306704

Epoch: 5| Step: 8
Training loss: 3.526587454826278
Validation loss: 2.841752340615301

Epoch: 5| Step: 9
Training loss: 3.075215160006609
Validation loss: 2.8406617674204626

Epoch: 5| Step: 10
Training loss: 3.1695546650274338
Validation loss: 2.847861414433695

Epoch: 54| Step: 0
Training loss: 3.058559763440644
Validation loss: 2.8477455808336005

Epoch: 5| Step: 1
Training loss: 3.6234720890554097
Validation loss: 2.8553408806258815

Epoch: 5| Step: 2
Training loss: 2.9348489689350257
Validation loss: 2.851398500498968

Epoch: 5| Step: 3
Training loss: 3.1163676242533755
Validation loss: 2.858030510021884

Epoch: 5| Step: 4
Training loss: 3.487231259947003
Validation loss: 2.8462655004162256

Epoch: 5| Step: 5
Training loss: 3.245873105185386
Validation loss: 2.8375945202308914

Epoch: 5| Step: 6
Training loss: 2.87949964600879
Validation loss: 2.837011371878273

Epoch: 5| Step: 7
Training loss: 2.706051868119246
Validation loss: 2.834413740174602

Epoch: 5| Step: 8
Training loss: 2.7708440125529683
Validation loss: 2.8443558210006534

Epoch: 5| Step: 9
Training loss: 3.3332658919823412
Validation loss: 2.8562898722971344

Epoch: 5| Step: 10
Training loss: 3.440529199525929
Validation loss: 2.85808737179784

Epoch: 55| Step: 0
Training loss: 2.9675428646755084
Validation loss: 2.88449187292776

Epoch: 5| Step: 1
Training loss: 2.657727358002069
Validation loss: 2.9252233091685023

Epoch: 5| Step: 2
Training loss: 2.662676587763326
Validation loss: 2.9479329840582693

Epoch: 5| Step: 3
Training loss: 3.189498574002574
Validation loss: 2.9364728822829225

Epoch: 5| Step: 4
Training loss: 3.805997337135911
Validation loss: 2.85817062805527

Epoch: 5| Step: 5
Training loss: 2.9931807898696543
Validation loss: 2.830470189965515

Epoch: 5| Step: 6
Training loss: 3.32552325498313
Validation loss: 2.8312730452449366

Epoch: 5| Step: 7
Training loss: 2.9159662404768314
Validation loss: 2.8312888085764376

Epoch: 5| Step: 8
Training loss: 3.6300680314932174
Validation loss: 2.832581486981175

Epoch: 5| Step: 9
Training loss: 3.380918611374471
Validation loss: 2.8361626588816016

Epoch: 5| Step: 10
Training loss: 2.865685342301053
Validation loss: 2.8336107551315983

Epoch: 56| Step: 0
Training loss: 3.1003943100232445
Validation loss: 2.828210969319782

Epoch: 5| Step: 1
Training loss: 3.078573900979794
Validation loss: 2.8263673516387566

Epoch: 5| Step: 2
Training loss: 3.485957038855414
Validation loss: 2.8239412038180265

Epoch: 5| Step: 3
Training loss: 3.5093247312374647
Validation loss: 2.8245672340772234

Epoch: 5| Step: 4
Training loss: 3.0547736660641336
Validation loss: 2.8220679729036595

Epoch: 5| Step: 5
Training loss: 3.640570775229896
Validation loss: 2.819872851897709

Epoch: 5| Step: 6
Training loss: 2.6914059842445894
Validation loss: 2.821499315266617

Epoch: 5| Step: 7
Training loss: 3.0292940416451932
Validation loss: 2.8192602130707765

Epoch: 5| Step: 8
Training loss: 3.1430633341045455
Validation loss: 2.8166984650118567

Epoch: 5| Step: 9
Training loss: 2.8677459089868376
Validation loss: 2.816818221965533

Epoch: 5| Step: 10
Training loss: 2.527894421449134
Validation loss: 2.8210768847899765

Epoch: 57| Step: 0
Training loss: 2.486688939813811
Validation loss: 2.8626684404828264

Epoch: 5| Step: 1
Training loss: 3.238371513038231
Validation loss: 2.8554704989144044

Epoch: 5| Step: 2
Training loss: 2.7791911873791375
Validation loss: 2.821481002185904

Epoch: 5| Step: 3
Training loss: 3.35852252878479
Validation loss: 2.82888123916489

Epoch: 5| Step: 4
Training loss: 3.57459147860166
Validation loss: 2.827634150698967

Epoch: 5| Step: 5
Training loss: 3.2048315944853063
Validation loss: 2.832261216243661

Epoch: 5| Step: 6
Training loss: 3.0238115734755637
Validation loss: 2.8246245035656643

Epoch: 5| Step: 7
Training loss: 3.4781040845655107
Validation loss: 2.8208704820758377

Epoch: 5| Step: 8
Training loss: 2.7092827135536166
Validation loss: 2.818061064264106

Epoch: 5| Step: 9
Training loss: 3.14108971341277
Validation loss: 2.818062502527763

Epoch: 5| Step: 10
Training loss: 3.2570272912769775
Validation loss: 2.8148286556442006

Epoch: 58| Step: 0
Training loss: 2.8870727156865343
Validation loss: 2.817685288412794

Epoch: 5| Step: 1
Training loss: 2.3036095118622186
Validation loss: 2.8515621385898604

Epoch: 5| Step: 2
Training loss: 3.030296096938322
Validation loss: 2.9081057294596118

Epoch: 5| Step: 3
Training loss: 3.238525970378411
Validation loss: 2.9237285826162873

Epoch: 5| Step: 4
Training loss: 3.637725199122195
Validation loss: 2.855433301033813

Epoch: 5| Step: 5
Training loss: 3.398151534753772
Validation loss: 2.807201309997986

Epoch: 5| Step: 6
Training loss: 2.6151670941564875
Validation loss: 2.808017692003064

Epoch: 5| Step: 7
Training loss: 3.0655164849132523
Validation loss: 2.8209017323084034

Epoch: 5| Step: 8
Training loss: 3.655257913697666
Validation loss: 2.8943718649660903

Epoch: 5| Step: 9
Training loss: 3.4988425929664864
Validation loss: 3.0068515435248693

Epoch: 5| Step: 10
Training loss: 3.061887095875781
Validation loss: 2.9284203080524143

Epoch: 59| Step: 0
Training loss: 3.0741463135227964
Validation loss: 2.8483024109501196

Epoch: 5| Step: 1
Training loss: 3.436401052807973
Validation loss: 2.8170946207381613

Epoch: 5| Step: 2
Training loss: 3.293338270711351
Validation loss: 2.8121717564537643

Epoch: 5| Step: 3
Training loss: 2.706114951061195
Validation loss: 2.8049055587089478

Epoch: 5| Step: 4
Training loss: 3.0624911249771753
Validation loss: 2.8046678468192345

Epoch: 5| Step: 5
Training loss: 3.4400148382532225
Validation loss: 2.8053331932396683

Epoch: 5| Step: 6
Training loss: 3.164079830922829
Validation loss: 2.806464155000802

Epoch: 5| Step: 7
Training loss: 3.2885562026812556
Validation loss: 2.8450236622934906

Epoch: 5| Step: 8
Training loss: 2.7634915673845235
Validation loss: 2.914462425349182

Epoch: 5| Step: 9
Training loss: 3.326569672841536
Validation loss: 2.9531755132175257

Epoch: 5| Step: 10
Training loss: 2.8480199259800303
Validation loss: 2.8417309906382733

Epoch: 60| Step: 0
Training loss: 3.1195542760506005
Validation loss: 2.806810425485831

Epoch: 5| Step: 1
Training loss: 3.3738252926622794
Validation loss: 2.8065664963645744

Epoch: 5| Step: 2
Training loss: 3.709923406874526
Validation loss: 2.8122488039564906

Epoch: 5| Step: 3
Training loss: 3.069250801694709
Validation loss: 2.8628229245229044

Epoch: 5| Step: 4
Training loss: 2.782814957169439
Validation loss: 2.9007947860926078

Epoch: 5| Step: 5
Training loss: 3.0650227335200353
Validation loss: 2.90409033119421

Epoch: 5| Step: 6
Training loss: 2.8258195616614232
Validation loss: 2.8494062159197733

Epoch: 5| Step: 7
Training loss: 3.453634509303574
Validation loss: 2.820660293319141

Epoch: 5| Step: 8
Training loss: 2.8116078127264172
Validation loss: 2.7987173482286387

Epoch: 5| Step: 9
Training loss: 2.9642260967306564
Validation loss: 2.7985678805271523

Epoch: 5| Step: 10
Training loss: 3.3557222601411802
Validation loss: 2.7998187289546554

Epoch: 61| Step: 0
Training loss: 3.0972907871778705
Validation loss: 2.8176090628700727

Epoch: 5| Step: 1
Training loss: 3.211227663763581
Validation loss: 2.8200989215876424

Epoch: 5| Step: 2
Training loss: 3.1588864032623616
Validation loss: 2.807878967094111

Epoch: 5| Step: 3
Training loss: 2.8764934807101286
Validation loss: 2.7949144581108665

Epoch: 5| Step: 4
Training loss: 2.9077305457830653
Validation loss: 2.7868238885345353

Epoch: 5| Step: 5
Training loss: 2.4922777117721924
Validation loss: 2.7882978131501046

Epoch: 5| Step: 6
Training loss: 3.227710732007911
Validation loss: 2.8069203531286537

Epoch: 5| Step: 7
Training loss: 3.507679688248219
Validation loss: 2.847889469882632

Epoch: 5| Step: 8
Training loss: 2.749815067662106
Validation loss: 2.8350702465566737

Epoch: 5| Step: 9
Training loss: 3.087980497091107
Validation loss: 2.837499560038576

Epoch: 5| Step: 10
Training loss: 3.8665526822707834
Validation loss: 2.8356956370435324

Epoch: 62| Step: 0
Training loss: 2.689136627789202
Validation loss: 2.810520572116407

Epoch: 5| Step: 1
Training loss: 3.229013468071904
Validation loss: 2.796338907463147

Epoch: 5| Step: 2
Training loss: 3.459586196145367
Validation loss: 2.778568228026845

Epoch: 5| Step: 3
Training loss: 2.738026300988057
Validation loss: 2.7797605714175018

Epoch: 5| Step: 4
Training loss: 2.9125915578440975
Validation loss: 2.7824756032270006

Epoch: 5| Step: 5
Training loss: 2.8962278760543305
Validation loss: 2.7847661560358294

Epoch: 5| Step: 6
Training loss: 3.1695445853336675
Validation loss: 2.783252051253899

Epoch: 5| Step: 7
Training loss: 3.438123889140005
Validation loss: 2.7834486419900473

Epoch: 5| Step: 8
Training loss: 2.429562875182557
Validation loss: 2.784224877591215

Epoch: 5| Step: 9
Training loss: 3.52246120824091
Validation loss: 2.783997836882053

Epoch: 5| Step: 10
Training loss: 3.5130438929942227
Validation loss: 2.786545513001815

Epoch: 63| Step: 0
Training loss: 3.181884306678806
Validation loss: 2.7883610617620613

Epoch: 5| Step: 1
Training loss: 3.4154365620195155
Validation loss: 2.784164925379648

Epoch: 5| Step: 2
Training loss: 2.67111105900724
Validation loss: 2.781791136618779

Epoch: 5| Step: 3
Training loss: 3.011482833152153
Validation loss: 2.778500567574186

Epoch: 5| Step: 4
Training loss: 2.8392937926582786
Validation loss: 2.7776307738451815

Epoch: 5| Step: 5
Training loss: 3.1024161060188646
Validation loss: 2.774817553177087

Epoch: 5| Step: 6
Training loss: 3.4081105042035102
Validation loss: 2.771304235259815

Epoch: 5| Step: 7
Training loss: 3.305104619388769
Validation loss: 2.770473471351243

Epoch: 5| Step: 8
Training loss: 2.7374855006282504
Validation loss: 2.7706015063729232

Epoch: 5| Step: 9
Training loss: 3.486032818594354
Validation loss: 2.7734814555018263

Epoch: 5| Step: 10
Training loss: 2.825867906106018
Validation loss: 2.7769929780805094

Epoch: 64| Step: 0
Training loss: 2.9538783167194533
Validation loss: 2.7753917611562255

Epoch: 5| Step: 1
Training loss: 3.014246650318703
Validation loss: 2.794269097798258

Epoch: 5| Step: 2
Training loss: 3.019987597408469
Validation loss: 2.7891792605435213

Epoch: 5| Step: 3
Training loss: 3.571301613322217
Validation loss: 2.7787324785189007

Epoch: 5| Step: 4
Training loss: 2.4990614082817735
Validation loss: 2.7656484261882026

Epoch: 5| Step: 5
Training loss: 3.2858466512661857
Validation loss: 2.7589110227868177

Epoch: 5| Step: 6
Training loss: 2.9831217586005003
Validation loss: 2.757531992481701

Epoch: 5| Step: 7
Training loss: 3.165210807493173
Validation loss: 2.755666724470059

Epoch: 5| Step: 8
Training loss: 2.359514649155126
Validation loss: 2.754500440153651

Epoch: 5| Step: 9
Training loss: 3.4501414117994607
Validation loss: 2.759474449152676

Epoch: 5| Step: 10
Training loss: 3.4235409378449946
Validation loss: 2.7599618795210654

Epoch: 65| Step: 0
Training loss: 2.610736149272727
Validation loss: 2.759703999746966

Epoch: 5| Step: 1
Training loss: 3.3010791170149183
Validation loss: 2.76012852086415

Epoch: 5| Step: 2
Training loss: 3.4339706335572804
Validation loss: 2.7583436372844132

Epoch: 5| Step: 3
Training loss: 2.832759537283272
Validation loss: 2.7569097545995365

Epoch: 5| Step: 4
Training loss: 3.5340542081897017
Validation loss: 2.7545002288825113

Epoch: 5| Step: 5
Training loss: 2.8276257153262208
Validation loss: 2.7542201835823277

Epoch: 5| Step: 6
Training loss: 3.3012169183635667
Validation loss: 2.757112476664275

Epoch: 5| Step: 7
Training loss: 3.043666147569225
Validation loss: 2.7569134983601633

Epoch: 5| Step: 8
Training loss: 3.0949225467487125
Validation loss: 2.7595856269842414

Epoch: 5| Step: 9
Training loss: 2.8612759634217353
Validation loss: 2.7556025282022656

Epoch: 5| Step: 10
Training loss: 2.908742676558904
Validation loss: 2.753524205699649

Epoch: 66| Step: 0
Training loss: 2.7329390760959793
Validation loss: 2.7556467058592893

Epoch: 5| Step: 1
Training loss: 2.5017095442758537
Validation loss: 2.7512663948559166

Epoch: 5| Step: 2
Training loss: 3.775188789952136
Validation loss: 2.749516833417281

Epoch: 5| Step: 3
Training loss: 3.2830318880557225
Validation loss: 2.749944657433554

Epoch: 5| Step: 4
Training loss: 3.0525448985004036
Validation loss: 2.7514366562426185

Epoch: 5| Step: 5
Training loss: 2.6905587997887817
Validation loss: 2.7489144213899386

Epoch: 5| Step: 6
Training loss: 2.7150385285905165
Validation loss: 2.7492814397744234

Epoch: 5| Step: 7
Training loss: 3.243478540957886
Validation loss: 2.749775116638546

Epoch: 5| Step: 8
Training loss: 3.4770170107566085
Validation loss: 2.746677377097305

Epoch: 5| Step: 9
Training loss: 3.3608670491984203
Validation loss: 2.748813871162496

Epoch: 5| Step: 10
Training loss: 2.6983665081464334
Validation loss: 2.7448667979966883

Epoch: 67| Step: 0
Training loss: 3.211346899510637
Validation loss: 2.745322641933887

Epoch: 5| Step: 1
Training loss: 2.9571505765636457
Validation loss: 2.7456238607378003

Epoch: 5| Step: 2
Training loss: 3.3258114505800793
Validation loss: 2.7492770757804275

Epoch: 5| Step: 3
Training loss: 2.5837122629009213
Validation loss: 2.7431116315340938

Epoch: 5| Step: 4
Training loss: 3.7183470948524766
Validation loss: 2.7465362848079478

Epoch: 5| Step: 5
Training loss: 2.9850324136325574
Validation loss: 2.744935586359863

Epoch: 5| Step: 6
Training loss: 3.3660872713086936
Validation loss: 2.7477271232479934

Epoch: 5| Step: 7
Training loss: 3.1371689944800165
Validation loss: 2.7444574439371516

Epoch: 5| Step: 8
Training loss: 2.470094242383003
Validation loss: 2.741323938974175

Epoch: 5| Step: 9
Training loss: 2.740135098628192
Validation loss: 2.744417993147568

Epoch: 5| Step: 10
Training loss: 3.0797381361577947
Validation loss: 2.740903278039605

Epoch: 68| Step: 0
Training loss: 2.908961354156006
Validation loss: 2.743120341749352

Epoch: 5| Step: 1
Training loss: 3.2332432927706787
Validation loss: 2.742545464290527

Epoch: 5| Step: 2
Training loss: 2.9127719670309564
Validation loss: 2.74234551971656

Epoch: 5| Step: 3
Training loss: 3.2114888481268413
Validation loss: 2.7404329094704014

Epoch: 5| Step: 4
Training loss: 3.3322025447342334
Validation loss: 2.7396124623746103

Epoch: 5| Step: 5
Training loss: 2.9650504099274
Validation loss: 2.7403049056020503

Epoch: 5| Step: 6
Training loss: 2.8034905985182514
Validation loss: 2.7378264327658464

Epoch: 5| Step: 7
Training loss: 2.6774026009932044
Validation loss: 2.733686990041065

Epoch: 5| Step: 8
Training loss: 3.249439778094058
Validation loss: 2.7331901568568693

Epoch: 5| Step: 9
Training loss: 3.4744262990168324
Validation loss: 2.7331172646370563

Epoch: 5| Step: 10
Training loss: 2.7935135743463593
Validation loss: 2.733742139390027

Epoch: 69| Step: 0
Training loss: 2.7600713453884707
Validation loss: 2.7301023398419964

Epoch: 5| Step: 1
Training loss: 3.0020395339710952
Validation loss: 2.732665840543433

Epoch: 5| Step: 2
Training loss: 3.7001203105027307
Validation loss: 2.7322017582747473

Epoch: 5| Step: 3
Training loss: 2.524223748417318
Validation loss: 2.732824140659105

Epoch: 5| Step: 4
Training loss: 3.4252386413746723
Validation loss: 2.736925540340681

Epoch: 5| Step: 5
Training loss: 2.7459442401845373
Validation loss: 2.7354851869422085

Epoch: 5| Step: 6
Training loss: 3.3366185370857013
Validation loss: 2.7428547069961255

Epoch: 5| Step: 7
Training loss: 3.5589013914085244
Validation loss: 2.7306818074965586

Epoch: 5| Step: 8
Training loss: 3.239908396285426
Validation loss: 2.727332793379462

Epoch: 5| Step: 9
Training loss: 2.0935107421818056
Validation loss: 2.7319943444827324

Epoch: 5| Step: 10
Training loss: 2.827644096500585
Validation loss: 2.729405481378735

Epoch: 70| Step: 0
Training loss: 3.221000107119445
Validation loss: 2.7295479954654356

Epoch: 5| Step: 1
Training loss: 2.9515987266793164
Validation loss: 2.7295276237507853

Epoch: 5| Step: 2
Training loss: 2.7927088049651423
Validation loss: 2.7292620064443613

Epoch: 5| Step: 3
Training loss: 3.349927668004098
Validation loss: 2.7282745545865446

Epoch: 5| Step: 4
Training loss: 2.660037045041601
Validation loss: 2.72774371735658

Epoch: 5| Step: 5
Training loss: 3.004435756728473
Validation loss: 2.727670332780223

Epoch: 5| Step: 6
Training loss: 2.943358726982344
Validation loss: 2.7277062250311768

Epoch: 5| Step: 7
Training loss: 3.2016161830826717
Validation loss: 2.7255015075534823

Epoch: 5| Step: 8
Training loss: 2.5157412863444675
Validation loss: 2.728997534726358

Epoch: 5| Step: 9
Training loss: 3.593108542871269
Validation loss: 2.732723169130773

Epoch: 5| Step: 10
Training loss: 3.243666860584424
Validation loss: 2.742542081367143

Epoch: 71| Step: 0
Training loss: 3.6274750251357206
Validation loss: 2.7508461005778977

Epoch: 5| Step: 1
Training loss: 3.465217234750051
Validation loss: 2.749672325763533

Epoch: 5| Step: 2
Training loss: 2.74577145157018
Validation loss: 2.727450513572292

Epoch: 5| Step: 3
Training loss: 2.709131700267998
Validation loss: 2.7194470851023014

Epoch: 5| Step: 4
Training loss: 3.072558952243984
Validation loss: 2.7189273401568355

Epoch: 5| Step: 5
Training loss: 2.971642620897238
Validation loss: 2.718777533007405

Epoch: 5| Step: 6
Training loss: 2.7175444637756447
Validation loss: 2.7205438859027398

Epoch: 5| Step: 7
Training loss: 3.0735479880924945
Validation loss: 2.7216473337838982

Epoch: 5| Step: 8
Training loss: 3.4547147241673106
Validation loss: 2.7200117048959345

Epoch: 5| Step: 9
Training loss: 2.808582629525316
Validation loss: 2.7198943663575648

Epoch: 5| Step: 10
Training loss: 2.751748916056002
Validation loss: 2.7186688788351585

Epoch: 72| Step: 0
Training loss: 2.852199033996192
Validation loss: 2.718687400714827

Epoch: 5| Step: 1
Training loss: 3.654526393906237
Validation loss: 2.716337088211365

Epoch: 5| Step: 2
Training loss: 2.849084399198684
Validation loss: 2.7154801455058086

Epoch: 5| Step: 3
Training loss: 3.227933947807968
Validation loss: 2.714192309111304

Epoch: 5| Step: 4
Training loss: 2.8033164240734982
Validation loss: 2.7118016099576576

Epoch: 5| Step: 5
Training loss: 2.8036248789474363
Validation loss: 2.7119806636220547

Epoch: 5| Step: 6
Training loss: 3.3227941954872806
Validation loss: 2.713760304499466

Epoch: 5| Step: 7
Training loss: 2.751855830901867
Validation loss: 2.71253353707011

Epoch: 5| Step: 8
Training loss: 3.414834081548384
Validation loss: 2.71485104380233

Epoch: 5| Step: 9
Training loss: 2.693301127622066
Validation loss: 2.714800951869639

Epoch: 5| Step: 10
Training loss: 2.994961640330437
Validation loss: 2.7212132577536607

Epoch: 73| Step: 0
Training loss: 2.691881732989824
Validation loss: 2.714933950407566

Epoch: 5| Step: 1
Training loss: 2.8498633770235715
Validation loss: 2.7130252527111294

Epoch: 5| Step: 2
Training loss: 3.3962059674657112
Validation loss: 2.7147477691390924

Epoch: 5| Step: 3
Training loss: 3.5919825976232707
Validation loss: 2.7112776894596657

Epoch: 5| Step: 4
Training loss: 3.355880694254464
Validation loss: 2.709120725577292

Epoch: 5| Step: 5
Training loss: 2.786149242525162
Validation loss: 2.7083695654579247

Epoch: 5| Step: 6
Training loss: 2.9601821137156925
Validation loss: 2.7077174266520188

Epoch: 5| Step: 7
Training loss: 2.4874138630277565
Validation loss: 2.7069296047493863

Epoch: 5| Step: 8
Training loss: 3.395116968401233
Validation loss: 2.7116561088046636

Epoch: 5| Step: 9
Training loss: 3.181743585034118
Validation loss: 2.7103526542609404

Epoch: 5| Step: 10
Training loss: 2.4658956323583197
Validation loss: 2.7099013583023113

Epoch: 74| Step: 0
Training loss: 2.777671311775345
Validation loss: 2.7058397126589155

Epoch: 5| Step: 1
Training loss: 2.577365277799699
Validation loss: 2.7049199127751007

Epoch: 5| Step: 2
Training loss: 2.9831644369156427
Validation loss: 2.702572992578802

Epoch: 5| Step: 3
Training loss: 3.4173801111429856
Validation loss: 2.705717667319893

Epoch: 5| Step: 4
Training loss: 2.4624427672575546
Validation loss: 2.7046190503044625

Epoch: 5| Step: 5
Training loss: 3.5414209317993426
Validation loss: 2.7044639811008997

Epoch: 5| Step: 6
Training loss: 2.883394342853812
Validation loss: 2.7055130386779576

Epoch: 5| Step: 7
Training loss: 3.648772851206574
Validation loss: 2.7047399528429814

Epoch: 5| Step: 8
Training loss: 2.8342142044772043
Validation loss: 2.703703235731941

Epoch: 5| Step: 9
Training loss: 3.2252528601588573
Validation loss: 2.7024821424450622

Epoch: 5| Step: 10
Training loss: 2.7853673397500356
Validation loss: 2.7000045134849606

Epoch: 75| Step: 0
Training loss: 3.0565002214159294
Validation loss: 2.7000664720666596

Epoch: 5| Step: 1
Training loss: 2.9494530186860133
Validation loss: 2.699061657996302

Epoch: 5| Step: 2
Training loss: 2.3246891347143777
Validation loss: 2.7007087342087144

Epoch: 5| Step: 3
Training loss: 3.625147717853346
Validation loss: 2.7048928215956005

Epoch: 5| Step: 4
Training loss: 2.5497878566085643
Validation loss: 2.703326308179076

Epoch: 5| Step: 5
Training loss: 3.0866089681858555
Validation loss: 2.7215450960374863

Epoch: 5| Step: 6
Training loss: 3.509218337790505
Validation loss: 2.7186345618208425

Epoch: 5| Step: 7
Training loss: 2.9168739971766477
Validation loss: 2.739661979942287

Epoch: 5| Step: 8
Training loss: 2.9549441915492918
Validation loss: 2.714214977777084

Epoch: 5| Step: 9
Training loss: 2.6645977120288653
Validation loss: 2.6959968305694324

Epoch: 5| Step: 10
Training loss: 3.5492741877067604
Validation loss: 2.6957475750692828

Epoch: 76| Step: 0
Training loss: 3.627621459189461
Validation loss: 2.6935715264791633

Epoch: 5| Step: 1
Training loss: 3.1704690758256264
Validation loss: 2.6956041213669413

Epoch: 5| Step: 2
Training loss: 2.800259380588123
Validation loss: 2.6999513374464468

Epoch: 5| Step: 3
Training loss: 3.123207799070814
Validation loss: 2.701538430260213

Epoch: 5| Step: 4
Training loss: 3.084668480419612
Validation loss: 2.698520106555789

Epoch: 5| Step: 5
Training loss: 2.9300937218372383
Validation loss: 2.7034822837572445

Epoch: 5| Step: 6
Training loss: 2.965059576610001
Validation loss: 2.6997267272976297

Epoch: 5| Step: 7
Training loss: 2.7593120356079837
Validation loss: 2.7010179547173423

Epoch: 5| Step: 8
Training loss: 2.947191524395679
Validation loss: 2.700091165851589

Epoch: 5| Step: 9
Training loss: 2.890193102764009
Validation loss: 2.6969735369078407

Epoch: 5| Step: 10
Training loss: 3.072518136426445
Validation loss: 2.695277215037989

Epoch: 77| Step: 0
Training loss: 3.0544581802809887
Validation loss: 2.6942819863794245

Epoch: 5| Step: 1
Training loss: 3.4641909495048546
Validation loss: 2.6946142185314748

Epoch: 5| Step: 2
Training loss: 2.6419304323935053
Validation loss: 2.6898453798071977

Epoch: 5| Step: 3
Training loss: 3.3635463632263556
Validation loss: 2.6892502063466295

Epoch: 5| Step: 4
Training loss: 3.1530537048082885
Validation loss: 2.7139067848335316

Epoch: 5| Step: 5
Training loss: 2.6112896867204167
Validation loss: 2.76077739628514

Epoch: 5| Step: 6
Training loss: 3.4513735925415214
Validation loss: 2.8621093319697444

Epoch: 5| Step: 7
Training loss: 2.7648411733804483
Validation loss: 2.862074344145269

Epoch: 5| Step: 8
Training loss: 2.842189150867958
Validation loss: 2.8011019817662026

Epoch: 5| Step: 9
Training loss: 3.4621060639634256
Validation loss: 2.7550432939032636

Epoch: 5| Step: 10
Training loss: 2.729728194459111
Validation loss: 2.691601031180115

Epoch: 78| Step: 0
Training loss: 2.9566063115763033
Validation loss: 2.6894109580274193

Epoch: 5| Step: 1
Training loss: 3.448448362968561
Validation loss: 2.6997014908056247

Epoch: 5| Step: 2
Training loss: 3.1829538275569402
Validation loss: 2.7076761396519795

Epoch: 5| Step: 3
Training loss: 3.095600229954024
Validation loss: 2.7006745003349586

Epoch: 5| Step: 4
Training loss: 3.321836018804606
Validation loss: 2.6941478712837266

Epoch: 5| Step: 5
Training loss: 2.8444037052886264
Validation loss: 2.6934670313883236

Epoch: 5| Step: 6
Training loss: 2.6973183949230184
Validation loss: 2.689555915425944

Epoch: 5| Step: 7
Training loss: 3.31734385901291
Validation loss: 2.692705472685725

Epoch: 5| Step: 8
Training loss: 3.13763558752098
Validation loss: 2.689617590464735

Epoch: 5| Step: 9
Training loss: 2.2482244055254132
Validation loss: 2.6912396562161267

Epoch: 5| Step: 10
Training loss: 3.041665656381378
Validation loss: 2.6921920740047534

Epoch: 79| Step: 0
Training loss: 3.1584963217142152
Validation loss: 2.687373986596399

Epoch: 5| Step: 1
Training loss: 2.865200091925948
Validation loss: 2.6945325543633896

Epoch: 5| Step: 2
Training loss: 2.7326736824979836
Validation loss: 2.693919770082274

Epoch: 5| Step: 3
Training loss: 2.529335522448461
Validation loss: 2.6954015554512347

Epoch: 5| Step: 4
Training loss: 3.1347140584251667
Validation loss: 2.6966404375016824

Epoch: 5| Step: 5
Training loss: 3.361717223766139
Validation loss: 2.6926950722670115

Epoch: 5| Step: 6
Training loss: 3.537380602004469
Validation loss: 2.698590591214697

Epoch: 5| Step: 7
Training loss: 3.2107038946633715
Validation loss: 2.6865377895252345

Epoch: 5| Step: 8
Training loss: 2.4814825914653533
Validation loss: 2.689875136738873

Epoch: 5| Step: 9
Training loss: 3.2163844628808795
Validation loss: 2.6857282536653946

Epoch: 5| Step: 10
Training loss: 2.792903189789983
Validation loss: 2.684468840055763

Epoch: 80| Step: 0
Training loss: 3.388428851381062
Validation loss: 2.688884183097095

Epoch: 5| Step: 1
Training loss: 3.402389999057791
Validation loss: 2.688576189260593

Epoch: 5| Step: 2
Training loss: 2.356689440479158
Validation loss: 2.680534300508313

Epoch: 5| Step: 3
Training loss: 3.1652468124987037
Validation loss: 2.686067903124381

Epoch: 5| Step: 4
Training loss: 2.4442754624460634
Validation loss: 2.6761893453192176

Epoch: 5| Step: 5
Training loss: 2.9753558098367656
Validation loss: 2.6742067302620085

Epoch: 5| Step: 6
Training loss: 3.218589704651658
Validation loss: 2.6747096737076

Epoch: 5| Step: 7
Training loss: 3.1861386851594102
Validation loss: 2.6866067211194693

Epoch: 5| Step: 8
Training loss: 3.136169765597044
Validation loss: 2.7080509764313128

Epoch: 5| Step: 9
Training loss: 2.628979073999468
Validation loss: 2.69957842724075

Epoch: 5| Step: 10
Training loss: 3.128459693769762
Validation loss: 2.690908318346426

Epoch: 81| Step: 0
Training loss: 3.074445355023867
Validation loss: 2.6931713224533658

Epoch: 5| Step: 1
Training loss: 3.6324260547145
Validation loss: 2.6966243357958444

Epoch: 5| Step: 2
Training loss: 3.2722841839482064
Validation loss: 2.6938068423581134

Epoch: 5| Step: 3
Training loss: 3.2741340132907366
Validation loss: 2.6907857463018776

Epoch: 5| Step: 4
Training loss: 2.4176710497079514
Validation loss: 2.693163911870296

Epoch: 5| Step: 5
Training loss: 3.472845597999771
Validation loss: 2.6870343281111517

Epoch: 5| Step: 6
Training loss: 2.3468336038202144
Validation loss: 2.6753577500593435

Epoch: 5| Step: 7
Training loss: 3.25199652748814
Validation loss: 2.673233862058322

Epoch: 5| Step: 8
Training loss: 2.753262751723725
Validation loss: 2.6661798314141354

Epoch: 5| Step: 9
Training loss: 2.6246948064772098
Validation loss: 2.6682495782306797

Epoch: 5| Step: 10
Training loss: 2.686599225632644
Validation loss: 2.6670560635804144

Epoch: 82| Step: 0
Training loss: 2.926673742849127
Validation loss: 2.6661740967787546

Epoch: 5| Step: 1
Training loss: 2.628997393044173
Validation loss: 2.6664160042157907

Epoch: 5| Step: 2
Training loss: 2.884087505457444
Validation loss: 2.6657271563171494

Epoch: 5| Step: 3
Training loss: 3.7223426710792626
Validation loss: 2.680361029257598

Epoch: 5| Step: 4
Training loss: 3.146750327011095
Validation loss: 2.683237683667773

Epoch: 5| Step: 5
Training loss: 3.055898909110083
Validation loss: 2.6882589403279145

Epoch: 5| Step: 6
Training loss: 2.8001819006553506
Validation loss: 2.6955198251324854

Epoch: 5| Step: 7
Training loss: 3.2371743292475696
Validation loss: 2.685050196922879

Epoch: 5| Step: 8
Training loss: 2.975176470996189
Validation loss: 2.665898172588312

Epoch: 5| Step: 9
Training loss: 3.04262163682337
Validation loss: 2.66568298873048

Epoch: 5| Step: 10
Training loss: 2.4872426690651066
Validation loss: 2.665587574781997

Epoch: 83| Step: 0
Training loss: 3.093366811121729
Validation loss: 2.6695065889410214

Epoch: 5| Step: 1
Training loss: 2.7581926035251545
Validation loss: 2.668292753122617

Epoch: 5| Step: 2
Training loss: 3.342868439162734
Validation loss: 2.668130207360648

Epoch: 5| Step: 3
Training loss: 2.961985380003997
Validation loss: 2.6745405915697464

Epoch: 5| Step: 4
Training loss: 3.035177459053552
Validation loss: 2.6752661750366467

Epoch: 5| Step: 5
Training loss: 3.7631966132937005
Validation loss: 2.676533122783519

Epoch: 5| Step: 6
Training loss: 2.988681741443164
Validation loss: 2.6689227136748004

Epoch: 5| Step: 7
Training loss: 2.260976297273701
Validation loss: 2.6690763765341057

Epoch: 5| Step: 8
Training loss: 2.6525210965941812
Validation loss: 2.6647170198677004

Epoch: 5| Step: 9
Training loss: 3.342760741878097
Validation loss: 2.664526663943149

Epoch: 5| Step: 10
Training loss: 2.6348993650614942
Validation loss: 2.6633817304337604

Epoch: 84| Step: 0
Training loss: 2.7600770465490565
Validation loss: 2.662413762488996

Epoch: 5| Step: 1
Training loss: 3.1183565858687263
Validation loss: 2.662516547288419

Epoch: 5| Step: 2
Training loss: 2.8093970241680504
Validation loss: 2.671676719536635

Epoch: 5| Step: 3
Training loss: 2.4233233643247605
Validation loss: 2.6915538964103245

Epoch: 5| Step: 4
Training loss: 2.829900531975289
Validation loss: 2.7118828089243006

Epoch: 5| Step: 5
Training loss: 3.029924869927838
Validation loss: 2.71456378028174

Epoch: 5| Step: 6
Training loss: 3.209185416946836
Validation loss: 2.699694583395342

Epoch: 5| Step: 7
Training loss: 3.579320183253122
Validation loss: 2.6845640327164317

Epoch: 5| Step: 8
Training loss: 3.1857938501171628
Validation loss: 2.688163446494683

Epoch: 5| Step: 9
Training loss: 2.848166086529632
Validation loss: 2.6598856569711278

Epoch: 5| Step: 10
Training loss: 3.2049442242367885
Validation loss: 2.659279502747606

Epoch: 85| Step: 0
Training loss: 3.1538211050345
Validation loss: 2.660169790204362

Epoch: 5| Step: 1
Training loss: 2.8427454253493623
Validation loss: 2.6680595761922974

Epoch: 5| Step: 2
Training loss: 3.5346185601969653
Validation loss: 2.6633808092723346

Epoch: 5| Step: 3
Training loss: 2.9557477012198796
Validation loss: 2.684377089742942

Epoch: 5| Step: 4
Training loss: 2.8462174997329583
Validation loss: 2.6620280378475996

Epoch: 5| Step: 5
Training loss: 2.678036550977522
Validation loss: 2.659133218824385

Epoch: 5| Step: 6
Training loss: 2.7911616955193885
Validation loss: 2.6568691432072775

Epoch: 5| Step: 7
Training loss: 3.2310787487581094
Validation loss: 2.65538638201021

Epoch: 5| Step: 8
Training loss: 2.8121342739100337
Validation loss: 2.656144297244124

Epoch: 5| Step: 9
Training loss: 2.9250066773428056
Validation loss: 2.658950693190769

Epoch: 5| Step: 10
Training loss: 3.266173978228148
Validation loss: 2.670081216215155

Epoch: 86| Step: 0
Training loss: 3.2374967538235566
Validation loss: 2.683815815887336

Epoch: 5| Step: 1
Training loss: 3.13154176734675
Validation loss: 2.6995893224936385

Epoch: 5| Step: 2
Training loss: 2.999585599888279
Validation loss: 2.708788500480412

Epoch: 5| Step: 3
Training loss: 3.4770972365704584
Validation loss: 2.692164409087701

Epoch: 5| Step: 4
Training loss: 3.348343448145773
Validation loss: 2.6756410891838596

Epoch: 5| Step: 5
Training loss: 2.733995770995993
Validation loss: 2.6737445862083455

Epoch: 5| Step: 6
Training loss: 2.536216854896007
Validation loss: 2.673632676111693

Epoch: 5| Step: 7
Training loss: 2.8973796384364396
Validation loss: 2.6637072125529526

Epoch: 5| Step: 8
Training loss: 2.857741759745458
Validation loss: 2.6620902100489228

Epoch: 5| Step: 9
Training loss: 2.6989860820828357
Validation loss: 2.6566928655999784

Epoch: 5| Step: 10
Training loss: 3.1361480231675567
Validation loss: 2.6561417926171758

Epoch: 87| Step: 0
Training loss: 2.5605722014384398
Validation loss: 2.6557753831994124

Epoch: 5| Step: 1
Training loss: 3.455506207139991
Validation loss: 2.672109320511818

Epoch: 5| Step: 2
Training loss: 2.7965480677298022
Validation loss: 2.6868251345258694

Epoch: 5| Step: 3
Training loss: 3.447927576760417
Validation loss: 2.6909076709835973

Epoch: 5| Step: 4
Training loss: 3.0323363255093287
Validation loss: 2.6918518601462207

Epoch: 5| Step: 5
Training loss: 3.446594691702532
Validation loss: 2.6831288257164374

Epoch: 5| Step: 6
Training loss: 3.197855862879216
Validation loss: 2.667487024694199

Epoch: 5| Step: 7
Training loss: 2.6785156534836663
Validation loss: 2.65132337632309

Epoch: 5| Step: 8
Training loss: 2.9023616579717544
Validation loss: 2.643654791106377

Epoch: 5| Step: 9
Training loss: 2.691633992739875
Validation loss: 2.6445190402262098

Epoch: 5| Step: 10
Training loss: 2.4908798757445942
Validation loss: 2.645404785489398

Epoch: 88| Step: 0
Training loss: 2.7207374762278667
Validation loss: 2.6473402845079095

Epoch: 5| Step: 1
Training loss: 2.6788849365596903
Validation loss: 2.6462425767775444

Epoch: 5| Step: 2
Training loss: 3.2709480962037722
Validation loss: 2.644341817179535

Epoch: 5| Step: 3
Training loss: 2.190171272861502
Validation loss: 2.6417146858945757

Epoch: 5| Step: 4
Training loss: 3.5671641285114384
Validation loss: 2.6366529245488937

Epoch: 5| Step: 5
Training loss: 3.0422613181007816
Validation loss: 2.6441950180846034

Epoch: 5| Step: 6
Training loss: 2.809275749922963
Validation loss: 2.6421092357672764

Epoch: 5| Step: 7
Training loss: 2.6397819301821155
Validation loss: 2.6404728145085095

Epoch: 5| Step: 8
Training loss: 3.320228342223895
Validation loss: 2.644288624099659

Epoch: 5| Step: 9
Training loss: 3.3865351467677063
Validation loss: 2.648398786232749

Epoch: 5| Step: 10
Training loss: 3.046725538451541
Validation loss: 2.64594489157854

Epoch: 89| Step: 0
Training loss: 2.7078033711256966
Validation loss: 2.6416023330667637

Epoch: 5| Step: 1
Training loss: 3.196951373577955
Validation loss: 2.646826818120415

Epoch: 5| Step: 2
Training loss: 3.428211494126626
Validation loss: 2.651761356909492

Epoch: 5| Step: 3
Training loss: 3.241391739223214
Validation loss: 2.6454306455832337

Epoch: 5| Step: 4
Training loss: 2.734903687728755
Validation loss: 2.6395348360814954

Epoch: 5| Step: 5
Training loss: 2.7044616217038544
Validation loss: 2.6378534884658262

Epoch: 5| Step: 6
Training loss: 2.9625677688508967
Validation loss: 2.633774485330951

Epoch: 5| Step: 7
Training loss: 2.446067620341615
Validation loss: 2.633739136139659

Epoch: 5| Step: 8
Training loss: 3.2781389292520138
Validation loss: 2.6366619047769575

Epoch: 5| Step: 9
Training loss: 2.91681105846667
Validation loss: 2.640550199127484

Epoch: 5| Step: 10
Training loss: 3.1083795688930147
Validation loss: 2.637588948772318

Epoch: 90| Step: 0
Training loss: 3.117267043549651
Validation loss: 2.6422506824278478

Epoch: 5| Step: 1
Training loss: 3.2577000879886486
Validation loss: 2.636934543592007

Epoch: 5| Step: 2
Training loss: 2.8815691988339367
Validation loss: 2.6357611929086673

Epoch: 5| Step: 3
Training loss: 2.929683919268645
Validation loss: 2.6372447364809997

Epoch: 5| Step: 4
Training loss: 3.20462313717135
Validation loss: 2.635943938383966

Epoch: 5| Step: 5
Training loss: 2.6665981899847293
Validation loss: 2.6341493263528637

Epoch: 5| Step: 6
Training loss: 2.3246328289558393
Validation loss: 2.631793736246509

Epoch: 5| Step: 7
Training loss: 2.8099643721307292
Validation loss: 2.632977256270603

Epoch: 5| Step: 8
Training loss: 2.8737767146371724
Validation loss: 2.6332933944559267

Epoch: 5| Step: 9
Training loss: 3.4635868996938646
Validation loss: 2.6505139818113594

Epoch: 5| Step: 10
Training loss: 3.1104596417152335
Validation loss: 2.674103349825545

Epoch: 91| Step: 0
Training loss: 2.659008613208078
Validation loss: 2.687444155456971

Epoch: 5| Step: 1
Training loss: 2.8812847276030453
Validation loss: 2.6796437548152054

Epoch: 5| Step: 2
Training loss: 3.602556137081724
Validation loss: 2.6815423132370833

Epoch: 5| Step: 3
Training loss: 2.7613200502848234
Validation loss: 2.6525976387631833

Epoch: 5| Step: 4
Training loss: 2.620319098485328
Validation loss: 2.6289791081296072

Epoch: 5| Step: 5
Training loss: 2.6557500032060264
Validation loss: 2.624411220510367

Epoch: 5| Step: 6
Training loss: 3.723757922063918
Validation loss: 2.6293781781330523

Epoch: 5| Step: 7
Training loss: 2.6643056450912472
Validation loss: 2.6339363111339402

Epoch: 5| Step: 8
Training loss: 3.247823426525478
Validation loss: 2.64036037582441

Epoch: 5| Step: 9
Training loss: 2.776388140749283
Validation loss: 2.6429159157735262

Epoch: 5| Step: 10
Training loss: 3.060279975748667
Validation loss: 2.645776658100749

Epoch: 92| Step: 0
Training loss: 3.122934803433947
Validation loss: 2.6434852743147577

Epoch: 5| Step: 1
Training loss: 2.967652931289854
Validation loss: 2.634176006422883

Epoch: 5| Step: 2
Training loss: 2.680405145311334
Validation loss: 2.631172145079179

Epoch: 5| Step: 3
Training loss: 3.0360698331458518
Validation loss: 2.6291898386646446

Epoch: 5| Step: 4
Training loss: 2.544892458039404
Validation loss: 2.626466147304939

Epoch: 5| Step: 5
Training loss: 2.7401866079396466
Validation loss: 2.625748729231354

Epoch: 5| Step: 6
Training loss: 2.982558411556214
Validation loss: 2.6261137276072066

Epoch: 5| Step: 7
Training loss: 3.3370058015264803
Validation loss: 2.6284143418898913

Epoch: 5| Step: 8
Training loss: 3.0802508918334275
Validation loss: 2.6327114787535666

Epoch: 5| Step: 9
Training loss: 2.800574216546102
Validation loss: 2.64207332081034

Epoch: 5| Step: 10
Training loss: 3.418527856056861
Validation loss: 2.6450300953857186

Epoch: 93| Step: 0
Training loss: 3.434814513860815
Validation loss: 2.6808204997782226

Epoch: 5| Step: 1
Training loss: 2.731562623173565
Validation loss: 2.6716042418427834

Epoch: 5| Step: 2
Training loss: 3.63039063151476
Validation loss: 2.665866373770432

Epoch: 5| Step: 3
Training loss: 3.038268468530264
Validation loss: 2.624234902040888

Epoch: 5| Step: 4
Training loss: 2.9496507340912417
Validation loss: 2.6200904621161984

Epoch: 5| Step: 5
Training loss: 3.058950118427296
Validation loss: 2.622315960011577

Epoch: 5| Step: 6
Training loss: 2.568224397890956
Validation loss: 2.6222385652166773

Epoch: 5| Step: 7
Training loss: 2.909032494597897
Validation loss: 2.624391607361096

Epoch: 5| Step: 8
Training loss: 2.42320795601527
Validation loss: 2.624349154032405

Epoch: 5| Step: 9
Training loss: 3.0494000266882195
Validation loss: 2.6204788232219216

Epoch: 5| Step: 10
Training loss: 2.7959525009508375
Validation loss: 2.623533762804782

Epoch: 94| Step: 0
Training loss: 3.045490752513463
Validation loss: 2.6244686544080356

Epoch: 5| Step: 1
Training loss: 3.0973500585094884
Validation loss: 2.6187292498129344

Epoch: 5| Step: 2
Training loss: 2.5591927562473975
Validation loss: 2.621134901435113

Epoch: 5| Step: 3
Training loss: 2.643831101203917
Validation loss: 2.6176992323520425

Epoch: 5| Step: 4
Training loss: 3.155904618807846
Validation loss: 2.6142540184087024

Epoch: 5| Step: 5
Training loss: 2.969662977677563
Validation loss: 2.6156663588500173

Epoch: 5| Step: 6
Training loss: 2.734909964409749
Validation loss: 2.6116162414203976

Epoch: 5| Step: 7
Training loss: 3.1314578659290415
Validation loss: 2.6111158154783487

Epoch: 5| Step: 8
Training loss: 3.1281203903484394
Validation loss: 2.6151523082940074

Epoch: 5| Step: 9
Training loss: 2.601951776196918
Validation loss: 2.622487574931031

Epoch: 5| Step: 10
Training loss: 3.577411963701165
Validation loss: 2.632922064404244

Epoch: 95| Step: 0
Training loss: 3.2111370832132815
Validation loss: 2.656026750963343

Epoch: 5| Step: 1
Training loss: 3.386840677321502
Validation loss: 2.6771123648399997

Epoch: 5| Step: 2
Training loss: 3.3322537740302094
Validation loss: 2.6218488250043426

Epoch: 5| Step: 3
Training loss: 3.0609520873364287
Validation loss: 2.6138728229252046

Epoch: 5| Step: 4
Training loss: 2.175798453737248
Validation loss: 2.619025669091153

Epoch: 5| Step: 5
Training loss: 2.8615350954368868
Validation loss: 2.6145254384554937

Epoch: 5| Step: 6
Training loss: 2.817526331374868
Validation loss: 2.6182140528200732

Epoch: 5| Step: 7
Training loss: 3.00242818474941
Validation loss: 2.62138468345429

Epoch: 5| Step: 8
Training loss: 2.984110396074018
Validation loss: 2.615924971599494

Epoch: 5| Step: 9
Training loss: 3.1783568951260666
Validation loss: 2.6147912869381047

Epoch: 5| Step: 10
Training loss: 2.529310166018409
Validation loss: 2.611716565015918

Epoch: 96| Step: 0
Training loss: 3.0609530220202883
Validation loss: 2.616246005158818

Epoch: 5| Step: 1
Training loss: 2.732757089706352
Validation loss: 2.6213908104412647

Epoch: 5| Step: 2
Training loss: 2.8692041108318276
Validation loss: 2.626767862605356

Epoch: 5| Step: 3
Training loss: 2.5121597211440547
Validation loss: 2.6199898084730195

Epoch: 5| Step: 4
Training loss: 3.3339669261223244
Validation loss: 2.6399204231374234

Epoch: 5| Step: 5
Training loss: 3.0735396103994392
Validation loss: 2.650827219094075

Epoch: 5| Step: 6
Training loss: 2.5462530581980762
Validation loss: 2.6346665498024726

Epoch: 5| Step: 7
Training loss: 3.3710391503218897
Validation loss: 2.631108463783137

Epoch: 5| Step: 8
Training loss: 3.3914684178353784
Validation loss: 2.616381547279725

Epoch: 5| Step: 9
Training loss: 3.068682444153223
Validation loss: 2.613474253543943

Epoch: 5| Step: 10
Training loss: 2.3940228020419476
Validation loss: 2.616216309338843

Epoch: 97| Step: 0
Training loss: 3.1690322840530682
Validation loss: 2.6124154692038

Epoch: 5| Step: 1
Training loss: 3.0088683021657547
Validation loss: 2.6093522703868093

Epoch: 5| Step: 2
Training loss: 2.8603832364241524
Validation loss: 2.610563152483608

Epoch: 5| Step: 3
Training loss: 2.346518343912502
Validation loss: 2.609912929114291

Epoch: 5| Step: 4
Training loss: 2.984925543848512
Validation loss: 2.6104204209370616

Epoch: 5| Step: 5
Training loss: 3.270223491859011
Validation loss: 2.6122654775000513

Epoch: 5| Step: 6
Training loss: 2.854186807454646
Validation loss: 2.6212282492426344

Epoch: 5| Step: 7
Training loss: 2.944824178269047
Validation loss: 2.633429655689112

Epoch: 5| Step: 8
Training loss: 2.7333901511854126
Validation loss: 2.6446078954582766

Epoch: 5| Step: 9
Training loss: 3.0676520471423134
Validation loss: 2.6429478549224967

Epoch: 5| Step: 10
Training loss: 3.3484024053132733
Validation loss: 2.6451050070257893

Epoch: 98| Step: 0
Training loss: 2.0079546332610754
Validation loss: 2.6209337526677996

Epoch: 5| Step: 1
Training loss: 3.290770461009212
Validation loss: 2.608212611051143

Epoch: 5| Step: 2
Training loss: 3.443117303069315
Validation loss: 2.608925424828346

Epoch: 5| Step: 3
Training loss: 2.885812578456209
Validation loss: 2.6057390003763605

Epoch: 5| Step: 4
Training loss: 2.609440328728196
Validation loss: 2.6292022122569327

Epoch: 5| Step: 5
Training loss: 2.4958196020836563
Validation loss: 2.62813566000218

Epoch: 5| Step: 6
Training loss: 3.2898518029782258
Validation loss: 2.614979364451011

Epoch: 5| Step: 7
Training loss: 3.259566971272405
Validation loss: 2.6082849778459942

Epoch: 5| Step: 8
Training loss: 3.1462670505138965
Validation loss: 2.6051383111132944

Epoch: 5| Step: 9
Training loss: 2.835674851710616
Validation loss: 2.603100856772502

Epoch: 5| Step: 10
Training loss: 3.1415056350951325
Validation loss: 2.6023578831537475

Epoch: 99| Step: 0
Training loss: 2.6044966730194314
Validation loss: 2.6018207666607975

Epoch: 5| Step: 1
Training loss: 3.063501778068045
Validation loss: 2.612522128722346

Epoch: 5| Step: 2
Training loss: 3.553118483135652
Validation loss: 2.6246153134054135

Epoch: 5| Step: 3
Training loss: 2.6780333459899053
Validation loss: 2.6289253243313557

Epoch: 5| Step: 4
Training loss: 3.014234152929484
Validation loss: 2.6344105709420993

Epoch: 5| Step: 5
Training loss: 2.747457803084558
Validation loss: 2.6240135806448435

Epoch: 5| Step: 6
Training loss: 2.9906008026834243
Validation loss: 2.597667921115471

Epoch: 5| Step: 7
Training loss: 2.605178107618001
Validation loss: 2.5943851585281297

Epoch: 5| Step: 8
Training loss: 3.236547652576347
Validation loss: 2.602819163196761

Epoch: 5| Step: 9
Training loss: 3.0174912128462763
Validation loss: 2.605283637593069

Epoch: 5| Step: 10
Training loss: 2.8597550269895655
Validation loss: 2.6088255039091837

Epoch: 100| Step: 0
Training loss: 2.927714504915061
Validation loss: 2.597008359651807

Epoch: 5| Step: 1
Training loss: 2.577571832671553
Validation loss: 2.596796190415421

Epoch: 5| Step: 2
Training loss: 3.4833636676495714
Validation loss: 2.59815341319304

Epoch: 5| Step: 3
Training loss: 3.140914979519397
Validation loss: 2.5984633479891874

Epoch: 5| Step: 4
Training loss: 2.904748508249759
Validation loss: 2.6013153204117203

Epoch: 5| Step: 5
Training loss: 2.602344842072816
Validation loss: 2.5973941512538854

Epoch: 5| Step: 6
Training loss: 3.0561597939501177
Validation loss: 2.5940778584144364

Epoch: 5| Step: 7
Training loss: 2.246596092772094
Validation loss: 2.601680095803204

Epoch: 5| Step: 8
Training loss: 3.2251158050326785
Validation loss: 2.6136180718809054

Epoch: 5| Step: 9
Training loss: 3.065665963586537
Validation loss: 2.6149638696976534

Epoch: 5| Step: 10
Training loss: 3.010281904079551
Validation loss: 2.5965205830299665

Epoch: 101| Step: 0
Training loss: 3.103023770958309
Validation loss: 2.5884841718115474

Epoch: 5| Step: 1
Training loss: 2.7689160092704226
Validation loss: 2.592744741436866

Epoch: 5| Step: 2
Training loss: 2.991827004332393
Validation loss: 2.587160353770146

Epoch: 5| Step: 3
Training loss: 3.000466310499809
Validation loss: 2.5901422892311623

Epoch: 5| Step: 4
Training loss: 2.7019266107109514
Validation loss: 2.5930554670481154

Epoch: 5| Step: 5
Training loss: 2.7040997109453304
Validation loss: 2.5966195527839964

Epoch: 5| Step: 6
Training loss: 2.6615404289309574
Validation loss: 2.5969837745279265

Epoch: 5| Step: 7
Training loss: 3.1043129359523807
Validation loss: 2.597608511966671

Epoch: 5| Step: 8
Training loss: 3.3079444221062198
Validation loss: 2.5952032174154334

Epoch: 5| Step: 9
Training loss: 3.189531464324198
Validation loss: 2.5957411432382873

Epoch: 5| Step: 10
Training loss: 2.9486592753685184
Validation loss: 2.5915641247103696

Epoch: 102| Step: 0
Training loss: 2.8453735076882953
Validation loss: 2.58868912745002

Epoch: 5| Step: 1
Training loss: 3.027971677569586
Validation loss: 2.5890840513593756

Epoch: 5| Step: 2
Training loss: 2.607045395778177
Validation loss: 2.586596664279223

Epoch: 5| Step: 3
Training loss: 2.828798835525014
Validation loss: 2.586983472438074

Epoch: 5| Step: 4
Training loss: 3.145972562492025
Validation loss: 2.58951104896745

Epoch: 5| Step: 5
Training loss: 2.879106822590338
Validation loss: 2.596008345551928

Epoch: 5| Step: 6
Training loss: 3.0345524367715435
Validation loss: 2.6074020023041067

Epoch: 5| Step: 7
Training loss: 2.8946284433538687
Validation loss: 2.6187343247553625

Epoch: 5| Step: 8
Training loss: 3.338529700834559
Validation loss: 2.6391898731788523

Epoch: 5| Step: 9
Training loss: 3.046794870741219
Validation loss: 2.6587003019146342

Epoch: 5| Step: 10
Training loss: 2.62681426067684
Validation loss: 2.687462792373882

Epoch: 103| Step: 0
Training loss: 2.858792438467297
Validation loss: 2.6642476102550585

Epoch: 5| Step: 1
Training loss: 2.9304564420583477
Validation loss: 2.653211981769183

Epoch: 5| Step: 2
Training loss: 2.9461362784590333
Validation loss: 2.6158671247090344

Epoch: 5| Step: 3
Training loss: 2.9218461142351417
Validation loss: 2.5987470457388566

Epoch: 5| Step: 4
Training loss: 2.364062572612875
Validation loss: 2.590044045939476

Epoch: 5| Step: 5
Training loss: 3.0165435498933744
Validation loss: 2.5916081992660183

Epoch: 5| Step: 6
Training loss: 2.638069857825616
Validation loss: 2.5865026325584246

Epoch: 5| Step: 7
Training loss: 3.4127517383770254
Validation loss: 2.582547145249139

Epoch: 5| Step: 8
Training loss: 2.584483034396672
Validation loss: 2.5848958420345247

Epoch: 5| Step: 9
Training loss: 3.220924013612374
Validation loss: 2.5743136387133614

Epoch: 5| Step: 10
Training loss: 3.3414621101867183
Validation loss: 2.5743115852615133

Epoch: 104| Step: 0
Training loss: 2.4886335425956703
Validation loss: 2.5769180351347303

Epoch: 5| Step: 1
Training loss: 3.3364536145228803
Validation loss: 2.5813271323858142

Epoch: 5| Step: 2
Training loss: 2.9893326249928562
Validation loss: 2.573179735639023

Epoch: 5| Step: 3
Training loss: 3.1091796200197086
Validation loss: 2.5766160752376757

Epoch: 5| Step: 4
Training loss: 2.54208972932813
Validation loss: 2.5769903794342475

Epoch: 5| Step: 5
Training loss: 3.3434463790945372
Validation loss: 2.5853430789711638

Epoch: 5| Step: 6
Training loss: 3.029041862452909
Validation loss: 2.583459260261646

Epoch: 5| Step: 7
Training loss: 2.8112921770391273
Validation loss: 2.5770810566436984

Epoch: 5| Step: 8
Training loss: 2.650660749148026
Validation loss: 2.5792329557203386

Epoch: 5| Step: 9
Training loss: 2.9544306699423655
Validation loss: 2.579903479836912

Epoch: 5| Step: 10
Training loss: 2.98816667723579
Validation loss: 2.5789380573605873

Epoch: 105| Step: 0
Training loss: 3.1293041342971444
Validation loss: 2.575081739871574

Epoch: 5| Step: 1
Training loss: 2.533551523784238
Validation loss: 2.572944217165881

Epoch: 5| Step: 2
Training loss: 2.711250133241797
Validation loss: 2.577024390103586

Epoch: 5| Step: 3
Training loss: 2.889634411137384
Validation loss: 2.5796829026127854

Epoch: 5| Step: 4
Training loss: 2.6019953004001457
Validation loss: 2.573503718652486

Epoch: 5| Step: 5
Training loss: 2.9022420503400825
Validation loss: 2.57307277340549

Epoch: 5| Step: 6
Training loss: 3.092389202430555
Validation loss: 2.571276385290148

Epoch: 5| Step: 7
Training loss: 3.2727676470992275
Validation loss: 2.572383876433299

Epoch: 5| Step: 8
Training loss: 3.013846708159797
Validation loss: 2.574760533241172

Epoch: 5| Step: 9
Training loss: 2.734306378184693
Validation loss: 2.598403736023619

Epoch: 5| Step: 10
Training loss: 3.371309452515681
Validation loss: 2.616189451014242

Epoch: 106| Step: 0
Training loss: 3.2410210039163814
Validation loss: 2.6318511244671114

Epoch: 5| Step: 1
Training loss: 2.477298855743187
Validation loss: 2.6604978304661753

Epoch: 5| Step: 2
Training loss: 2.885091733482301
Validation loss: 2.7131451532435134

Epoch: 5| Step: 3
Training loss: 3.051981241820999
Validation loss: 2.7428537499026047

Epoch: 5| Step: 4
Training loss: 2.4916098950743026
Validation loss: 2.7015226633131357

Epoch: 5| Step: 5
Training loss: 3.328537176693885
Validation loss: 2.636687880760347

Epoch: 5| Step: 6
Training loss: 3.094459221205557
Validation loss: 2.6148082298316018

Epoch: 5| Step: 7
Training loss: 2.9275894180050317
Validation loss: 2.5876875043124454

Epoch: 5| Step: 8
Training loss: 2.658309048708145
Validation loss: 2.5781667308841953

Epoch: 5| Step: 9
Training loss: 3.5672262863877724
Validation loss: 2.63771488795824

Epoch: 5| Step: 10
Training loss: 2.7242089199439077
Validation loss: 2.6770900571258354

Epoch: 107| Step: 0
Training loss: 3.1996874716254182
Validation loss: 2.577815694890183

Epoch: 5| Step: 1
Training loss: 3.2215340434834387
Validation loss: 2.5759539430024834

Epoch: 5| Step: 2
Training loss: 2.316899316298404
Validation loss: 2.593220086938569

Epoch: 5| Step: 3
Training loss: 2.768429557219644
Validation loss: 2.6371592066808156

Epoch: 5| Step: 4
Training loss: 2.80051470862219
Validation loss: 2.7497749367028645

Epoch: 5| Step: 5
Training loss: 3.710550709694434
Validation loss: 2.821583330395768

Epoch: 5| Step: 6
Training loss: 3.2960079553563673
Validation loss: 2.7633153152229695

Epoch: 5| Step: 7
Training loss: 3.1264933260576937
Validation loss: 2.6857347531345575

Epoch: 5| Step: 8
Training loss: 2.9143861483516735
Validation loss: 2.644962746661999

Epoch: 5| Step: 9
Training loss: 2.717694132309512
Validation loss: 2.609000312893042

Epoch: 5| Step: 10
Training loss: 2.674117457895106
Validation loss: 2.5938242424644566

Epoch: 108| Step: 0
Training loss: 2.591512243284273
Validation loss: 2.5891391826043972

Epoch: 5| Step: 1
Training loss: 2.8762527721777946
Validation loss: 2.583214061582394

Epoch: 5| Step: 2
Training loss: 2.91940937966888
Validation loss: 2.5823616396169626

Epoch: 5| Step: 3
Training loss: 3.3093513062865374
Validation loss: 2.584349570980215

Epoch: 5| Step: 4
Training loss: 3.3432548370223647
Validation loss: 2.5874759033897794

Epoch: 5| Step: 5
Training loss: 3.142385264679104
Validation loss: 2.590564732910839

Epoch: 5| Step: 6
Training loss: 2.9550508547052186
Validation loss: 2.594826932479333

Epoch: 5| Step: 7
Training loss: 2.7002883757131793
Validation loss: 2.587396681723576

Epoch: 5| Step: 8
Training loss: 2.8352098608637704
Validation loss: 2.577905659871023

Epoch: 5| Step: 9
Training loss: 2.3255261758968646
Validation loss: 2.577368898413913

Epoch: 5| Step: 10
Training loss: 3.176762015348434
Validation loss: 2.5779711426647482

Epoch: 109| Step: 0
Training loss: 2.7973632386351235
Validation loss: 2.579251911360151

Epoch: 5| Step: 1
Training loss: 2.9488905161923626
Validation loss: 2.5732911406892143

Epoch: 5| Step: 2
Training loss: 3.2056731718344498
Validation loss: 2.574125699258016

Epoch: 5| Step: 3
Training loss: 3.4432739316451673
Validation loss: 2.570876041446583

Epoch: 5| Step: 4
Training loss: 2.8860792553779175
Validation loss: 2.576014126232685

Epoch: 5| Step: 5
Training loss: 3.5025146170398953
Validation loss: 2.574239554073652

Epoch: 5| Step: 6
Training loss: 2.37290370179593
Validation loss: 2.5725769765969617

Epoch: 5| Step: 7
Training loss: 3.0321169527793663
Validation loss: 2.5710852564387374

Epoch: 5| Step: 8
Training loss: 1.9447260819178125
Validation loss: 2.568238370869339

Epoch: 5| Step: 9
Training loss: 2.8504208304253007
Validation loss: 2.5756433489879074

Epoch: 5| Step: 10
Training loss: 2.9975469414707754
Validation loss: 2.5707740353108206

Epoch: 110| Step: 0
Training loss: 3.0627922385777158
Validation loss: 2.5708469234613993

Epoch: 5| Step: 1
Training loss: 3.325006591101976
Validation loss: 2.570429675373713

Epoch: 5| Step: 2
Training loss: 2.8681692162981447
Validation loss: 2.5715945568787304

Epoch: 5| Step: 3
Training loss: 2.594952499895728
Validation loss: 2.569072946263429

Epoch: 5| Step: 4
Training loss: 2.4663409297245424
Validation loss: 2.570798144114059

Epoch: 5| Step: 5
Training loss: 2.995278616859331
Validation loss: 2.569073332445088

Epoch: 5| Step: 6
Training loss: 2.7165616754319752
Validation loss: 2.574564083821819

Epoch: 5| Step: 7
Training loss: 3.3467020568901518
Validation loss: 2.5785783753760727

Epoch: 5| Step: 8
Training loss: 3.0963971151330854
Validation loss: 2.584237949224051

Epoch: 5| Step: 9
Training loss: 2.8772023928843
Validation loss: 2.5836859041372726

Epoch: 5| Step: 10
Training loss: 2.6763648072035684
Validation loss: 2.580888555601877

Epoch: 111| Step: 0
Training loss: 2.8358524194150423
Validation loss: 2.5891459948393236

Epoch: 5| Step: 1
Training loss: 2.372731179168047
Validation loss: 2.583677160489498

Epoch: 5| Step: 2
Training loss: 3.1923793770534434
Validation loss: 2.5792043982506847

Epoch: 5| Step: 3
Training loss: 2.866665410625567
Validation loss: 2.585450162223808

Epoch: 5| Step: 4
Training loss: 3.393951331361196
Validation loss: 2.5755090173958144

Epoch: 5| Step: 5
Training loss: 3.1369408401781875
Validation loss: 2.5746479959064836

Epoch: 5| Step: 6
Training loss: 2.686999163424124
Validation loss: 2.5705328390995517

Epoch: 5| Step: 7
Training loss: 3.175399701047661
Validation loss: 2.5839431944569573

Epoch: 5| Step: 8
Training loss: 2.995257602879088
Validation loss: 2.581040166098455

Epoch: 5| Step: 9
Training loss: 2.966556582033577
Validation loss: 2.5709238720073957

Epoch: 5| Step: 10
Training loss: 2.517046035400173
Validation loss: 2.5707330949017213

Epoch: 112| Step: 0
Training loss: 3.026802969592808
Validation loss: 2.576222391574038

Epoch: 5| Step: 1
Training loss: 3.3805977352634633
Validation loss: 2.5816624431561923

Epoch: 5| Step: 2
Training loss: 2.3541782570162577
Validation loss: 2.5839490480928458

Epoch: 5| Step: 3
Training loss: 2.901905052330151
Validation loss: 2.5862487520393618

Epoch: 5| Step: 4
Training loss: 2.620215733651572
Validation loss: 2.5918266873996947

Epoch: 5| Step: 5
Training loss: 3.149275675254162
Validation loss: 2.60040481530164

Epoch: 5| Step: 6
Training loss: 2.8707246919476637
Validation loss: 2.6063017062473133

Epoch: 5| Step: 7
Training loss: 2.3640055909905584
Validation loss: 2.6309330852550876

Epoch: 5| Step: 8
Training loss: 2.991546482516303
Validation loss: 2.6477904632122624

Epoch: 5| Step: 9
Training loss: 3.2512116741075956
Validation loss: 2.6791172402016903

Epoch: 5| Step: 10
Training loss: 3.253297160317526
Validation loss: 2.6851302103762538

Epoch: 113| Step: 0
Training loss: 3.0026146303222294
Validation loss: 2.6815535877004057

Epoch: 5| Step: 1
Training loss: 3.2755577486060483
Validation loss: 2.6751415561394443

Epoch: 5| Step: 2
Training loss: 2.756609343548159
Validation loss: 2.6379292657284408

Epoch: 5| Step: 3
Training loss: 2.994640331038149
Validation loss: 2.6168929106733403

Epoch: 5| Step: 4
Training loss: 2.527811422811131
Validation loss: 2.6109055722789294

Epoch: 5| Step: 5
Training loss: 2.639204105713499
Validation loss: 2.6014322020806224

Epoch: 5| Step: 6
Training loss: 3.013075309047745
Validation loss: 2.594321536724713

Epoch: 5| Step: 7
Training loss: 3.1908178078795184
Validation loss: 2.595482334831983

Epoch: 5| Step: 8
Training loss: 3.1987044930658977
Validation loss: 2.5909816954410574

Epoch: 5| Step: 9
Training loss: 2.7482194337979875
Validation loss: 2.5976439748432836

Epoch: 5| Step: 10
Training loss: 3.1296430046586603
Validation loss: 2.584774516080034

Epoch: 114| Step: 0
Training loss: 3.360352130103846
Validation loss: 2.5892893060473092

Epoch: 5| Step: 1
Training loss: 2.4547041165805044
Validation loss: 2.5885937139286987

Epoch: 5| Step: 2
Training loss: 2.3827914878043837
Validation loss: 2.580265820666409

Epoch: 5| Step: 3
Training loss: 3.220188004827977
Validation loss: 2.5738647731443063

Epoch: 5| Step: 4
Training loss: 2.8894301135735376
Validation loss: 2.5672636536683062

Epoch: 5| Step: 5
Training loss: 2.9125290177500105
Validation loss: 2.5718497922827726

Epoch: 5| Step: 6
Training loss: 2.76062482133018
Validation loss: 2.5755905068450318

Epoch: 5| Step: 7
Training loss: 2.825503488420025
Validation loss: 2.5913984182501237

Epoch: 5| Step: 8
Training loss: 3.0821601250879436
Validation loss: 2.594342276434047

Epoch: 5| Step: 9
Training loss: 2.8570891034655537
Validation loss: 2.615524867330209

Epoch: 5| Step: 10
Training loss: 3.2585994218307297
Validation loss: 2.641043090925022

Epoch: 115| Step: 0
Training loss: 2.8666214968944748
Validation loss: 2.6514394352003423

Epoch: 5| Step: 1
Training loss: 3.4273171543178984
Validation loss: 2.64957317793151

Epoch: 5| Step: 2
Training loss: 2.864862231924976
Validation loss: 2.6357299321484495

Epoch: 5| Step: 3
Training loss: 2.776676146028174
Validation loss: 2.5990813805677617

Epoch: 5| Step: 4
Training loss: 2.159328198512301
Validation loss: 2.566714600812093

Epoch: 5| Step: 5
Training loss: 2.432385777048923
Validation loss: 2.5507699201436798

Epoch: 5| Step: 6
Training loss: 2.5819502686513576
Validation loss: 2.552087331688775

Epoch: 5| Step: 7
Training loss: 3.0415234640891695
Validation loss: 2.5470496401591083

Epoch: 5| Step: 8
Training loss: 3.0864316134283807
Validation loss: 2.5467349170617433

Epoch: 5| Step: 9
Training loss: 3.295535714994409
Validation loss: 2.548247778113796

Epoch: 5| Step: 10
Training loss: 3.3773786851398397
Validation loss: 2.547948163631662

Epoch: 116| Step: 0
Training loss: 3.1866602071858887
Validation loss: 2.547679924663004

Epoch: 5| Step: 1
Training loss: 2.7333837837897668
Validation loss: 2.547892904787514

Epoch: 5| Step: 2
Training loss: 3.1931482274421574
Validation loss: 2.5471171099121777

Epoch: 5| Step: 3
Training loss: 2.7592239874259694
Validation loss: 2.5415395079189365

Epoch: 5| Step: 4
Training loss: 2.738447459097321
Validation loss: 2.5451581734743307

Epoch: 5| Step: 5
Training loss: 2.6979887570994543
Validation loss: 2.570602009206465

Epoch: 5| Step: 6
Training loss: 2.788222327963211
Validation loss: 2.607745933328263

Epoch: 5| Step: 7
Training loss: 2.854431715490142
Validation loss: 2.645397486278324

Epoch: 5| Step: 8
Training loss: 3.094099699350996
Validation loss: 2.6114145960528075

Epoch: 5| Step: 9
Training loss: 2.636793980408251
Validation loss: 2.6144181105232756

Epoch: 5| Step: 10
Training loss: 3.4206257808662803
Validation loss: 2.606966950723895

Epoch: 117| Step: 0
Training loss: 2.4432395460474434
Validation loss: 2.5950630631115335

Epoch: 5| Step: 1
Training loss: 2.7809697556481683
Validation loss: 2.58640176607974

Epoch: 5| Step: 2
Training loss: 2.929317522211455
Validation loss: 2.5649658092519676

Epoch: 5| Step: 3
Training loss: 2.8302951305690804
Validation loss: 2.559181840285121

Epoch: 5| Step: 4
Training loss: 3.12187985103868
Validation loss: 2.5486474708295024

Epoch: 5| Step: 5
Training loss: 2.956514058810451
Validation loss: 2.5424642805825326

Epoch: 5| Step: 6
Training loss: 3.071480642872192
Validation loss: 2.5422343893117585

Epoch: 5| Step: 7
Training loss: 3.314826292432082
Validation loss: 2.541434137354588

Epoch: 5| Step: 8
Training loss: 2.579086032114354
Validation loss: 2.547605256707958

Epoch: 5| Step: 9
Training loss: 2.654952865728181
Validation loss: 2.547040423495482

Epoch: 5| Step: 10
Training loss: 3.192215068770913
Validation loss: 2.543938852865331

Epoch: 118| Step: 0
Training loss: 3.0579426390293443
Validation loss: 2.5527137622261047

Epoch: 5| Step: 1
Training loss: 2.223837379424249
Validation loss: 2.5819445226828757

Epoch: 5| Step: 2
Training loss: 3.161508843627511
Validation loss: 2.596469453284143

Epoch: 5| Step: 3
Training loss: 2.88583224135079
Validation loss: 2.6116435345160074

Epoch: 5| Step: 4
Training loss: 2.3112270872755665
Validation loss: 2.656029013429671

Epoch: 5| Step: 5
Training loss: 3.2383180623096095
Validation loss: 2.6837112284735865

Epoch: 5| Step: 6
Training loss: 2.946305408628421
Validation loss: 2.6679443412068617

Epoch: 5| Step: 7
Training loss: 2.672842642476895
Validation loss: 2.6306041736844676

Epoch: 5| Step: 8
Training loss: 3.4537391634262677
Validation loss: 2.605422908535086

Epoch: 5| Step: 9
Training loss: 3.387601849478238
Validation loss: 2.561129462861104

Epoch: 5| Step: 10
Training loss: 2.488928215202461
Validation loss: 2.5421004292533076

Epoch: 119| Step: 0
Training loss: 2.5737130995518775
Validation loss: 2.5358479207867823

Epoch: 5| Step: 1
Training loss: 2.6849056407750576
Validation loss: 2.5458212138952003

Epoch: 5| Step: 2
Training loss: 3.297899999875631
Validation loss: 2.552377035900869

Epoch: 5| Step: 3
Training loss: 2.818874594901484
Validation loss: 2.5510591097041733

Epoch: 5| Step: 4
Training loss: 3.2514274103496374
Validation loss: 2.5486860773245654

Epoch: 5| Step: 5
Training loss: 2.3896476393286368
Validation loss: 2.546270953508359

Epoch: 5| Step: 6
Training loss: 3.6328793099115337
Validation loss: 2.5468959257644084

Epoch: 5| Step: 7
Training loss: 3.031601403701161
Validation loss: 2.5411831580627955

Epoch: 5| Step: 8
Training loss: 3.014439166843575
Validation loss: 2.5437125940639644

Epoch: 5| Step: 9
Training loss: 2.562605134621557
Validation loss: 2.5382922558051666

Epoch: 5| Step: 10
Training loss: 2.8160105518555185
Validation loss: 2.5371398067593613

Epoch: 120| Step: 0
Training loss: 3.3128693572635637
Validation loss: 2.533794014396142

Epoch: 5| Step: 1
Training loss: 3.045081133834253
Validation loss: 2.5443561156055345

Epoch: 5| Step: 2
Training loss: 2.5674772539031974
Validation loss: 2.543575373731743

Epoch: 5| Step: 3
Training loss: 3.507794284560862
Validation loss: 2.558664560422301

Epoch: 5| Step: 4
Training loss: 2.88618020285118
Validation loss: 2.577361651212341

Epoch: 5| Step: 5
Training loss: 2.765844045466771
Validation loss: 2.6128374245201145

Epoch: 5| Step: 6
Training loss: 2.4462225929717096
Validation loss: 2.6488987682544094

Epoch: 5| Step: 7
Training loss: 3.4477667338952878
Validation loss: 2.6627649410660768

Epoch: 5| Step: 8
Training loss: 3.414512203112632
Validation loss: 2.6326688421353603

Epoch: 5| Step: 9
Training loss: 2.4269106780324545
Validation loss: 2.6109077029947887

Epoch: 5| Step: 10
Training loss: 1.8625782534142163
Validation loss: 2.569577611214152

Epoch: 121| Step: 0
Training loss: 3.503033685642572
Validation loss: 2.562880015914288

Epoch: 5| Step: 1
Training loss: 3.0601916274362395
Validation loss: 2.551330797665134

Epoch: 5| Step: 2
Training loss: 3.3384118652502206
Validation loss: 2.544731637900354

Epoch: 5| Step: 3
Training loss: 2.8108434248953365
Validation loss: 2.5433863825576832

Epoch: 5| Step: 4
Training loss: 2.496858530384121
Validation loss: 2.5417214429235795

Epoch: 5| Step: 5
Training loss: 2.836647302163263
Validation loss: 2.5399239390573936

Epoch: 5| Step: 6
Training loss: 3.175857974693964
Validation loss: 2.546809527991697

Epoch: 5| Step: 7
Training loss: 2.6338846530901256
Validation loss: 2.544986657197254

Epoch: 5| Step: 8
Training loss: 2.036150142312343
Validation loss: 2.5377350518136903

Epoch: 5| Step: 9
Training loss: 2.683336981381924
Validation loss: 2.5402072856891285

Epoch: 5| Step: 10
Training loss: 3.2742862010899336
Validation loss: 2.539323223349054

Epoch: 122| Step: 0
Training loss: 3.3111750994081284
Validation loss: 2.5333977877956264

Epoch: 5| Step: 1
Training loss: 2.9262018652618975
Validation loss: 2.534657377532794

Epoch: 5| Step: 2
Training loss: 2.9601682604830244
Validation loss: 2.5415007141849135

Epoch: 5| Step: 3
Training loss: 3.117039574194124
Validation loss: 2.547424492669636

Epoch: 5| Step: 4
Training loss: 2.567172094427728
Validation loss: 2.547327093728731

Epoch: 5| Step: 5
Training loss: 2.6819338266627955
Validation loss: 2.5578769165942536

Epoch: 5| Step: 6
Training loss: 3.0432949846183694
Validation loss: 2.56205904288258

Epoch: 5| Step: 7
Training loss: 2.9623224647860296
Validation loss: 2.566916134239428

Epoch: 5| Step: 8
Training loss: 3.19445923695848
Validation loss: 2.5723169179194336

Epoch: 5| Step: 9
Training loss: 3.037304681220259
Validation loss: 2.552747301961391

Epoch: 5| Step: 10
Training loss: 1.4046870977382062
Validation loss: 2.5542405681989457

Epoch: 123| Step: 0
Training loss: 2.612215243795854
Validation loss: 2.5396205069962314

Epoch: 5| Step: 1
Training loss: 3.146615611109363
Validation loss: 2.528586694716893

Epoch: 5| Step: 2
Training loss: 2.9373849075171723
Validation loss: 2.5235830991584187

Epoch: 5| Step: 3
Training loss: 2.9530182672821135
Validation loss: 2.5171664114286187

Epoch: 5| Step: 4
Training loss: 2.8264082445319714
Validation loss: 2.525208674811444

Epoch: 5| Step: 5
Training loss: 3.199771521279467
Validation loss: 2.517037498221295

Epoch: 5| Step: 6
Training loss: 3.11211378160186
Validation loss: 2.518480319535145

Epoch: 5| Step: 7
Training loss: 2.803364476209722
Validation loss: 2.5141290807782024

Epoch: 5| Step: 8
Training loss: 2.891535105355446
Validation loss: 2.516492892256034

Epoch: 5| Step: 9
Training loss: 2.7440587801962923
Validation loss: 2.5138214643304093

Epoch: 5| Step: 10
Training loss: 2.3255998883510127
Validation loss: 2.5187300088265645

Epoch: 124| Step: 0
Training loss: 3.2251461143809355
Validation loss: 2.5150910039207632

Epoch: 5| Step: 1
Training loss: 2.7584915837955886
Validation loss: 2.5395709986478305

Epoch: 5| Step: 2
Training loss: 2.997431291137926
Validation loss: 2.5590295008034314

Epoch: 5| Step: 3
Training loss: 2.7228509950975845
Validation loss: 2.571394043148743

Epoch: 5| Step: 4
Training loss: 3.0302956248684185
Validation loss: 2.558661624722371

Epoch: 5| Step: 5
Training loss: 2.8644644047873844
Validation loss: 2.5486161132464176

Epoch: 5| Step: 6
Training loss: 2.8197797869199666
Validation loss: 2.5374413996408576

Epoch: 5| Step: 7
Training loss: 2.807135573502149
Validation loss: 2.519625534502748

Epoch: 5| Step: 8
Training loss: 2.8447265625
Validation loss: 2.512048704393589

Epoch: 5| Step: 9
Training loss: 3.1726370962354298
Validation loss: 2.5084356804430485

Epoch: 5| Step: 10
Training loss: 2.3553426275443328
Validation loss: 2.5048749902035343

Epoch: 125| Step: 0
Training loss: 2.903476170713541
Validation loss: 2.5082565597849533

Epoch: 5| Step: 1
Training loss: 2.3359097380248275
Validation loss: 2.5151456665257292

Epoch: 5| Step: 2
Training loss: 2.6813158253945906
Validation loss: 2.520695391624769

Epoch: 5| Step: 3
Training loss: 2.8124365057665757
Validation loss: 2.532266603841727

Epoch: 5| Step: 4
Training loss: 2.9344755795337405
Validation loss: 2.562333436480287

Epoch: 5| Step: 5
Training loss: 3.222659801134407
Validation loss: 2.6052120760188227

Epoch: 5| Step: 6
Training loss: 2.6627035394515044
Validation loss: 2.6156500752525504

Epoch: 5| Step: 7
Training loss: 3.5076617440025992
Validation loss: 2.6172809944723716

Epoch: 5| Step: 8
Training loss: 3.08287479668311
Validation loss: 2.5983124383985023

Epoch: 5| Step: 9
Training loss: 2.7706065168738765
Validation loss: 2.5842542115147267

Epoch: 5| Step: 10
Training loss: 3.134844418304924
Validation loss: 2.5668153799906976

Epoch: 126| Step: 0
Training loss: 2.776229441711348
Validation loss: 2.5457222047881714

Epoch: 5| Step: 1
Training loss: 2.727171996452751
Validation loss: 2.5437761352031742

Epoch: 5| Step: 2
Training loss: 3.2896875797799696
Validation loss: 2.5284098758868283

Epoch: 5| Step: 3
Training loss: 2.8291084729269245
Validation loss: 2.526133512386119

Epoch: 5| Step: 4
Training loss: 3.053697508564972
Validation loss: 2.529950056116892

Epoch: 5| Step: 5
Training loss: 2.25629371325978
Validation loss: 2.5274855192974273

Epoch: 5| Step: 6
Training loss: 2.942226584281774
Validation loss: 2.526105298449298

Epoch: 5| Step: 7
Training loss: 2.5500929460228923
Validation loss: 2.5294882465625235

Epoch: 5| Step: 8
Training loss: 3.3246233791360704
Validation loss: 2.521401304653318

Epoch: 5| Step: 9
Training loss: 3.2633705936080237
Validation loss: 2.5200166904107046

Epoch: 5| Step: 10
Training loss: 2.9254751618301857
Validation loss: 2.5096267610067233

Epoch: 127| Step: 0
Training loss: 2.9239652776052445
Validation loss: 2.5095783546665342

Epoch: 5| Step: 1
Training loss: 3.1424705434797926
Validation loss: 2.506113123619206

Epoch: 5| Step: 2
Training loss: 2.4853749691923337
Validation loss: 2.516264883828863

Epoch: 5| Step: 3
Training loss: 2.9891593889485155
Validation loss: 2.5239788528640315

Epoch: 5| Step: 4
Training loss: 2.620193440525238
Validation loss: 2.5307413114432715

Epoch: 5| Step: 5
Training loss: 2.858084131912553
Validation loss: 2.530736313296946

Epoch: 5| Step: 6
Training loss: 3.147820575559466
Validation loss: 2.528619418963021

Epoch: 5| Step: 7
Training loss: 2.4972308080815813
Validation loss: 2.5219425726108646

Epoch: 5| Step: 8
Training loss: 3.092849137897761
Validation loss: 2.5289103132896873

Epoch: 5| Step: 9
Training loss: 3.120233486437785
Validation loss: 2.5343675646700605

Epoch: 5| Step: 10
Training loss: 2.649199519626183
Validation loss: 2.5534414886892405

Epoch: 128| Step: 0
Training loss: 2.7396198652222554
Validation loss: 2.5670889541068016

Epoch: 5| Step: 1
Training loss: 2.658139801952876
Validation loss: 2.5635609735126366

Epoch: 5| Step: 2
Training loss: 3.0825368178892165
Validation loss: 2.544332513957795

Epoch: 5| Step: 3
Training loss: 3.080263276180453
Validation loss: 2.5264437556003982

Epoch: 5| Step: 4
Training loss: 2.976955277767887
Validation loss: 2.524053380285713

Epoch: 5| Step: 5
Training loss: 3.0470593518948275
Validation loss: 2.508098352033412

Epoch: 5| Step: 6
Training loss: 2.636338948340503
Validation loss: 2.501220804979979

Epoch: 5| Step: 7
Training loss: 2.664079414381101
Validation loss: 2.499072850490473

Epoch: 5| Step: 8
Training loss: 2.886304275841634
Validation loss: 2.494379643625838

Epoch: 5| Step: 9
Training loss: 2.906393396264955
Validation loss: 2.496279655503576

Epoch: 5| Step: 10
Training loss: 2.828249849545881
Validation loss: 2.4932318460283973

Epoch: 129| Step: 0
Training loss: 2.517784565939548
Validation loss: 2.4979997652077155

Epoch: 5| Step: 1
Training loss: 2.3803347853801413
Validation loss: 2.492264791071846

Epoch: 5| Step: 2
Training loss: 2.950031416127655
Validation loss: 2.4954251279328545

Epoch: 5| Step: 3
Training loss: 3.0224095058225036
Validation loss: 2.4995067417465013

Epoch: 5| Step: 4
Training loss: 2.861829694200617
Validation loss: 2.515286424298314

Epoch: 5| Step: 5
Training loss: 2.830132209466385
Validation loss: 2.543558763673297

Epoch: 5| Step: 6
Training loss: 2.687407292386042
Validation loss: 2.5572103362916625

Epoch: 5| Step: 7
Training loss: 3.3243238923314147
Validation loss: 2.60557774630962

Epoch: 5| Step: 8
Training loss: 2.8921364621564565
Validation loss: 2.575553168617416

Epoch: 5| Step: 9
Training loss: 3.1002651162761437
Validation loss: 2.5446472934015296

Epoch: 5| Step: 10
Training loss: 3.0017030967974234
Validation loss: 2.5204638148697147

Epoch: 130| Step: 0
Training loss: 2.4647417969331626
Validation loss: 2.50527452858074

Epoch: 5| Step: 1
Training loss: 2.9981106530777253
Validation loss: 2.499038069768191

Epoch: 5| Step: 2
Training loss: 2.889685235751249
Validation loss: 2.5008811274677463

Epoch: 5| Step: 3
Training loss: 3.22357719440433
Validation loss: 2.497077927220942

Epoch: 5| Step: 4
Training loss: 2.668470835322827
Validation loss: 2.4994217808964154

Epoch: 5| Step: 5
Training loss: 2.717481470685323
Validation loss: 2.5038552460700574

Epoch: 5| Step: 6
Training loss: 2.8594667180261117
Validation loss: 2.5031571623620787

Epoch: 5| Step: 7
Training loss: 2.974043774198626
Validation loss: 2.5016446016020963

Epoch: 5| Step: 8
Training loss: 2.9505557231854747
Validation loss: 2.5036855643925415

Epoch: 5| Step: 9
Training loss: 2.7990605004284195
Validation loss: 2.501343991377567

Epoch: 5| Step: 10
Training loss: 3.042396579761975
Validation loss: 2.5036058314632657

Epoch: 131| Step: 0
Training loss: 2.904917421726611
Validation loss: 2.5011142483108926

Epoch: 5| Step: 1
Training loss: 2.5782112800726016
Validation loss: 2.5023874214566098

Epoch: 5| Step: 2
Training loss: 2.596218175715972
Validation loss: 2.5098895176145826

Epoch: 5| Step: 3
Training loss: 2.6170541302305232
Validation loss: 2.5207478152720357

Epoch: 5| Step: 4
Training loss: 3.3552837209789876
Validation loss: 2.5478879905962954

Epoch: 5| Step: 5
Training loss: 2.8933590717606497
Validation loss: 2.546271441816796

Epoch: 5| Step: 6
Training loss: 3.0344059825694423
Validation loss: 2.53810990530208

Epoch: 5| Step: 7
Training loss: 2.7438896960451054
Validation loss: 2.5411446121106924

Epoch: 5| Step: 8
Training loss: 2.957521909373012
Validation loss: 2.5249554085446637

Epoch: 5| Step: 9
Training loss: 2.6983800266774103
Validation loss: 2.5175106894571284

Epoch: 5| Step: 10
Training loss: 3.0417554833670084
Validation loss: 2.5279987398946373

Epoch: 132| Step: 0
Training loss: 3.3515821336291185
Validation loss: 2.5151810699889623

Epoch: 5| Step: 1
Training loss: 2.8591998937802114
Validation loss: 2.5365077794675783

Epoch: 5| Step: 2
Training loss: 2.724681478660625
Validation loss: 2.528492352999517

Epoch: 5| Step: 3
Training loss: 2.764344862019628
Validation loss: 2.5183718352128848

Epoch: 5| Step: 4
Training loss: 3.0221469697590373
Validation loss: 2.5107519795311672

Epoch: 5| Step: 5
Training loss: 2.374987150458661
Validation loss: 2.4984196620920733

Epoch: 5| Step: 6
Training loss: 2.6411414008284226
Validation loss: 2.498297465915889

Epoch: 5| Step: 7
Training loss: 2.853208469201924
Validation loss: 2.5007178439872457

Epoch: 5| Step: 8
Training loss: 2.711855070731491
Validation loss: 2.5031548600428772

Epoch: 5| Step: 9
Training loss: 2.9346910397899535
Validation loss: 2.491614323496068

Epoch: 5| Step: 10
Training loss: 3.136885813139409
Validation loss: 2.4935512226130374

Epoch: 133| Step: 0
Training loss: 2.991362535182677
Validation loss: 2.4913390292337008

Epoch: 5| Step: 1
Training loss: 2.186491161413187
Validation loss: 2.501770966342243

Epoch: 5| Step: 2
Training loss: 2.742387291566565
Validation loss: 2.506708362542271

Epoch: 5| Step: 3
Training loss: 3.117049058789403
Validation loss: 2.510604766251405

Epoch: 5| Step: 4
Training loss: 2.9208948459941144
Validation loss: 2.520711878758663

Epoch: 5| Step: 5
Training loss: 2.938431287817964
Validation loss: 2.5277351902583503

Epoch: 5| Step: 6
Training loss: 3.0944635358305583
Validation loss: 2.51746009761229

Epoch: 5| Step: 7
Training loss: 2.453854106262839
Validation loss: 2.5244240553828234

Epoch: 5| Step: 8
Training loss: 3.1826369644023456
Validation loss: 2.5186539584247654

Epoch: 5| Step: 9
Training loss: 2.592939502979829
Validation loss: 2.502639025704831

Epoch: 5| Step: 10
Training loss: 3.0365134878149527
Validation loss: 2.5120960742496026

Epoch: 134| Step: 0
Training loss: 2.7404868566305414
Validation loss: 2.504063326157895

Epoch: 5| Step: 1
Training loss: 2.861405782329284
Validation loss: 2.4979483481821885

Epoch: 5| Step: 2
Training loss: 3.098800544034182
Validation loss: 2.489937307681577

Epoch: 5| Step: 3
Training loss: 2.694770205579033
Validation loss: 2.4862240121213537

Epoch: 5| Step: 4
Training loss: 2.8814618014190487
Validation loss: 2.4913448313628854

Epoch: 5| Step: 5
Training loss: 3.080528598855115
Validation loss: 2.4909458853673

Epoch: 5| Step: 6
Training loss: 2.711193061677458
Validation loss: 2.4931996341468112

Epoch: 5| Step: 7
Training loss: 3.0335571318289545
Validation loss: 2.503529628833365

Epoch: 5| Step: 8
Training loss: 2.5915635786579814
Validation loss: 2.5048218362179666

Epoch: 5| Step: 9
Training loss: 3.1514962533126316
Validation loss: 2.523441575915462

Epoch: 5| Step: 10
Training loss: 2.3582354692658276
Validation loss: 2.50978974987163

Epoch: 135| Step: 0
Training loss: 2.759940042673763
Validation loss: 2.5152135507553

Epoch: 5| Step: 1
Training loss: 2.679696041349361
Validation loss: 2.495034885327422

Epoch: 5| Step: 2
Training loss: 2.7112453846520643
Validation loss: 2.488258593913907

Epoch: 5| Step: 3
Training loss: 2.786568859914889
Validation loss: 2.502439302529112

Epoch: 5| Step: 4
Training loss: 3.2936650419045588
Validation loss: 2.4877635898807875

Epoch: 5| Step: 5
Training loss: 3.026223646109853
Validation loss: 2.4958824540602853

Epoch: 5| Step: 6
Training loss: 2.8859631035892197
Validation loss: 2.5016024652811826

Epoch: 5| Step: 7
Training loss: 2.6155393962456364
Validation loss: 2.504910873495462

Epoch: 5| Step: 8
Training loss: 2.769104401443938
Validation loss: 2.525512811128733

Epoch: 5| Step: 9
Training loss: 2.6991466727894706
Validation loss: 2.517377975986345

Epoch: 5| Step: 10
Training loss: 3.025309296235779
Validation loss: 2.5089968049333407

Epoch: 136| Step: 0
Training loss: 3.1024894194072896
Validation loss: 2.505583901367738

Epoch: 5| Step: 1
Training loss: 2.5305563835852682
Validation loss: 2.507432890170963

Epoch: 5| Step: 2
Training loss: 2.679079837687351
Validation loss: 2.5044009429165186

Epoch: 5| Step: 3
Training loss: 2.5554755159181775
Validation loss: 2.5032525244475123

Epoch: 5| Step: 4
Training loss: 2.8918357169420497
Validation loss: 2.5005741449665164

Epoch: 5| Step: 5
Training loss: 3.166393937530034
Validation loss: 2.50182750315096

Epoch: 5| Step: 6
Training loss: 2.5384943399777598
Validation loss: 2.4982512756833612

Epoch: 5| Step: 7
Training loss: 2.8326777279372184
Validation loss: 2.501095492288814

Epoch: 5| Step: 8
Training loss: 2.8837452441748006
Validation loss: 2.4969979812464294

Epoch: 5| Step: 9
Training loss: 2.6267026193291514
Validation loss: 2.4983880024511675

Epoch: 5| Step: 10
Training loss: 3.3313781885386113
Validation loss: 2.5172706968152507

Epoch: 137| Step: 0
Training loss: 3.1842176703613103
Validation loss: 2.509737678551953

Epoch: 5| Step: 1
Training loss: 2.8676192039184074
Validation loss: 2.545844100876477

Epoch: 5| Step: 2
Training loss: 2.561953881848482
Validation loss: 2.5211434034209876

Epoch: 5| Step: 3
Training loss: 3.1945344681885692
Validation loss: 2.52175443969301

Epoch: 5| Step: 4
Training loss: 2.905207128970194
Validation loss: 2.5248343722550355

Epoch: 5| Step: 5
Training loss: 2.882831190922216
Validation loss: 2.516809994449718

Epoch: 5| Step: 6
Training loss: 2.851666007057647
Validation loss: 2.5042520275073463

Epoch: 5| Step: 7
Training loss: 2.3030258136649233
Validation loss: 2.4939079568339526

Epoch: 5| Step: 8
Training loss: 2.771948358195096
Validation loss: 2.5174053620402588

Epoch: 5| Step: 9
Training loss: 2.8777452713330427
Validation loss: 2.502300764492141

Epoch: 5| Step: 10
Training loss: 2.870556258149485
Validation loss: 2.522428017495391

Epoch: 138| Step: 0
Training loss: 3.0005793012155673
Validation loss: 2.525447671510181

Epoch: 5| Step: 1
Training loss: 2.6025702097104255
Validation loss: 2.572324577983576

Epoch: 5| Step: 2
Training loss: 2.9319613571638943
Validation loss: 2.6101098256791726

Epoch: 5| Step: 3
Training loss: 2.9997968604929954
Validation loss: 2.667153664568525

Epoch: 5| Step: 4
Training loss: 2.88531881412066
Validation loss: 2.663762002357211

Epoch: 5| Step: 5
Training loss: 3.131130918267638
Validation loss: 2.6348326155559008

Epoch: 5| Step: 6
Training loss: 3.081010424602817
Validation loss: 2.6015397642113345

Epoch: 5| Step: 7
Training loss: 2.786536945885942
Validation loss: 2.527409435150951

Epoch: 5| Step: 8
Training loss: 2.75998487634247
Validation loss: 2.485972939969279

Epoch: 5| Step: 9
Training loss: 2.4569936970811175
Validation loss: 2.480272532634458

Epoch: 5| Step: 10
Training loss: 2.842330242848572
Validation loss: 2.487451361732412

Epoch: 139| Step: 0
Training loss: 3.0551965001619865
Validation loss: 2.4919912229012815

Epoch: 5| Step: 1
Training loss: 2.9004927183736178
Validation loss: 2.4915344141724027

Epoch: 5| Step: 2
Training loss: 1.650929379982072
Validation loss: 2.4966999135541315

Epoch: 5| Step: 3
Training loss: 3.1153496317334746
Validation loss: 2.4982127938600187

Epoch: 5| Step: 4
Training loss: 3.368463332058312
Validation loss: 2.497227328954166

Epoch: 5| Step: 5
Training loss: 3.067707849749714
Validation loss: 2.4950570247051203

Epoch: 5| Step: 6
Training loss: 2.759258463937909
Validation loss: 2.4947435102623947

Epoch: 5| Step: 7
Training loss: 2.6527612551384863
Validation loss: 2.49180358692703

Epoch: 5| Step: 8
Training loss: 2.7539316162672622
Validation loss: 2.481691680191029

Epoch: 5| Step: 9
Training loss: 3.2304271247885064
Validation loss: 2.4829773591253557

Epoch: 5| Step: 10
Training loss: 2.77231861164379
Validation loss: 2.502156240410919

Epoch: 140| Step: 0
Training loss: 2.7695601748313248
Validation loss: 2.517787162381014

Epoch: 5| Step: 1
Training loss: 2.8219932556720604
Validation loss: 2.5469487572951706

Epoch: 5| Step: 2
Training loss: 2.8489081583480624
Validation loss: 2.5996361117352

Epoch: 5| Step: 3
Training loss: 2.653963877917201
Validation loss: 2.5991118807403204

Epoch: 5| Step: 4
Training loss: 2.830272891633116
Validation loss: 2.573757099300654

Epoch: 5| Step: 5
Training loss: 3.10237491450799
Validation loss: 2.5456625622258486

Epoch: 5| Step: 6
Training loss: 2.6810862279995757
Validation loss: 2.525868836404132

Epoch: 5| Step: 7
Training loss: 2.843748993925818
Validation loss: 2.501614061883998

Epoch: 5| Step: 8
Training loss: 3.2076663690534044
Validation loss: 2.492915735768446

Epoch: 5| Step: 9
Training loss: 2.6816714758046496
Validation loss: 2.4875978078054493

Epoch: 5| Step: 10
Training loss: 2.7593782211060263
Validation loss: 2.480133514062033

Epoch: 141| Step: 0
Training loss: 3.146487709010493
Validation loss: 2.48118225796205

Epoch: 5| Step: 1
Training loss: 3.1875994797684997
Validation loss: 2.481473573445301

Epoch: 5| Step: 2
Training loss: 2.870482004608588
Validation loss: 2.47726354216107

Epoch: 5| Step: 3
Training loss: 2.8258456323285324
Validation loss: 2.4849359744883794

Epoch: 5| Step: 4
Training loss: 2.932051455120396
Validation loss: 2.4851785512014737

Epoch: 5| Step: 5
Training loss: 2.821345174567475
Validation loss: 2.500635819951671

Epoch: 5| Step: 6
Training loss: 2.1905799980819753
Validation loss: 2.527296346405721

Epoch: 5| Step: 7
Training loss: 2.419582734193022
Validation loss: 2.5448516472609928

Epoch: 5| Step: 8
Training loss: 2.771734440109304
Validation loss: 2.589883871600914

Epoch: 5| Step: 9
Training loss: 3.250922878987521
Validation loss: 2.5884228701363003

Epoch: 5| Step: 10
Training loss: 2.8521278134526193
Validation loss: 2.515721890884142

Epoch: 142| Step: 0
Training loss: 2.9364039222644323
Validation loss: 2.486988902103796

Epoch: 5| Step: 1
Training loss: 2.6741807592235998
Validation loss: 2.478299717765534

Epoch: 5| Step: 2
Training loss: 3.2857353434865266
Validation loss: 2.48069023607861

Epoch: 5| Step: 3
Training loss: 2.7270148046949862
Validation loss: 2.48526825817919

Epoch: 5| Step: 4
Training loss: 3.049533095345806
Validation loss: 2.496721825619252

Epoch: 5| Step: 5
Training loss: 2.705726914807222
Validation loss: 2.4971953672598604

Epoch: 5| Step: 6
Training loss: 2.7504944790256154
Validation loss: 2.4994498129421494

Epoch: 5| Step: 7
Training loss: 2.4629006926340624
Validation loss: 2.4975285978818214

Epoch: 5| Step: 8
Training loss: 2.8959422102478523
Validation loss: 2.4902970179271753

Epoch: 5| Step: 9
Training loss: 2.819968670204305
Validation loss: 2.4871861666375925

Epoch: 5| Step: 10
Training loss: 3.2407388047308414
Validation loss: 2.488478209137687

Epoch: 143| Step: 0
Training loss: 2.7531184808002234
Validation loss: 2.4906386962906

Epoch: 5| Step: 1
Training loss: 2.6975143505771797
Validation loss: 2.4986928516878177

Epoch: 5| Step: 2
Training loss: 3.2637902175020845
Validation loss: 2.5161440540627296

Epoch: 5| Step: 3
Training loss: 3.3013115270702778
Validation loss: 2.545943743650116

Epoch: 5| Step: 4
Training loss: 2.792506807979799
Validation loss: 2.537364397558334

Epoch: 5| Step: 5
Training loss: 2.7674511413947895
Validation loss: 2.5060796891390646

Epoch: 5| Step: 6
Training loss: 2.8158002352192253
Validation loss: 2.4920023817478527

Epoch: 5| Step: 7
Training loss: 2.9273566574329295
Validation loss: 2.486583201739008

Epoch: 5| Step: 8
Training loss: 2.3535320360553347
Validation loss: 2.479506720486775

Epoch: 5| Step: 9
Training loss: 3.0798924982210245
Validation loss: 2.4783241510061487

Epoch: 5| Step: 10
Training loss: 2.5374988612280482
Validation loss: 2.482234283030892

Epoch: 144| Step: 0
Training loss: 2.842490451766512
Validation loss: 2.479527593412378

Epoch: 5| Step: 1
Training loss: 3.3638582343893946
Validation loss: 2.4876177523230765

Epoch: 5| Step: 2
Training loss: 2.763186656830892
Validation loss: 2.490194413445373

Epoch: 5| Step: 3
Training loss: 2.4285663336211543
Validation loss: 2.507598930217096

Epoch: 5| Step: 4
Training loss: 2.9159497242741734
Validation loss: 2.5697827988215884

Epoch: 5| Step: 5
Training loss: 2.5001200647133284
Validation loss: 2.55946608289458

Epoch: 5| Step: 6
Training loss: 2.975448119449513
Validation loss: 2.550050006748508

Epoch: 5| Step: 7
Training loss: 2.9058952525216615
Validation loss: 2.546966269255831

Epoch: 5| Step: 8
Training loss: 2.4122240294107025
Validation loss: 2.5100788033258694

Epoch: 5| Step: 9
Training loss: 2.727748929700134
Validation loss: 2.4960710364418226

Epoch: 5| Step: 10
Training loss: 3.3241501833593983
Validation loss: 2.4958311372193616

Epoch: 145| Step: 0
Training loss: 3.2122075522930937
Validation loss: 2.481672801136464

Epoch: 5| Step: 1
Training loss: 2.7203504740492828
Validation loss: 2.4767986358550584

Epoch: 5| Step: 2
Training loss: 3.0324217114638303
Validation loss: 2.48205860034856

Epoch: 5| Step: 3
Training loss: 2.844559606648088
Validation loss: 2.4914979492836142

Epoch: 5| Step: 4
Training loss: 2.9201789053887675
Validation loss: 2.498894840967189

Epoch: 5| Step: 5
Training loss: 2.6922994828361015
Validation loss: 2.50243416180026

Epoch: 5| Step: 6
Training loss: 2.78827294893277
Validation loss: 2.499702526155294

Epoch: 5| Step: 7
Training loss: 3.090382911141528
Validation loss: 2.49566621360749

Epoch: 5| Step: 8
Training loss: 2.874805609724103
Validation loss: 2.4890172123087315

Epoch: 5| Step: 9
Training loss: 2.4848155464779094
Validation loss: 2.501111064660691

Epoch: 5| Step: 10
Training loss: 2.1514497482243273
Validation loss: 2.504385283005046

Epoch: 146| Step: 0
Training loss: 3.0182793354980793
Validation loss: 2.4980100597748263

Epoch: 5| Step: 1
Training loss: 2.401099700116066
Validation loss: 2.5064954657788596

Epoch: 5| Step: 2
Training loss: 2.5478399590096066
Validation loss: 2.5003579478220814

Epoch: 5| Step: 3
Training loss: 2.883336130776638
Validation loss: 2.5255737821978

Epoch: 5| Step: 4
Training loss: 3.2248227506913407
Validation loss: 2.512780573408814

Epoch: 5| Step: 5
Training loss: 2.654972442368992
Validation loss: 2.515452385204785

Epoch: 5| Step: 6
Training loss: 3.3094302654604766
Validation loss: 2.4986124464239015

Epoch: 5| Step: 7
Training loss: 3.1576590839097487
Validation loss: 2.4867160854901553

Epoch: 5| Step: 8
Training loss: 2.6309640434531056
Validation loss: 2.4818333452201253

Epoch: 5| Step: 9
Training loss: 2.136628478547587
Validation loss: 2.4915929910657915

Epoch: 5| Step: 10
Training loss: 2.7427268516725727
Validation loss: 2.488469362758729

Epoch: 147| Step: 0
Training loss: 2.9623103922111618
Validation loss: 2.494946657745309

Epoch: 5| Step: 1
Training loss: 2.0725586420650646
Validation loss: 2.493247826882776

Epoch: 5| Step: 2
Training loss: 2.931083000973147
Validation loss: 2.5043838734239516

Epoch: 5| Step: 3
Training loss: 3.032352994042903
Validation loss: 2.487680470414918

Epoch: 5| Step: 4
Training loss: 2.8254190218582393
Validation loss: 2.4836375475155816

Epoch: 5| Step: 5
Training loss: 2.8899396754110023
Validation loss: 2.4835063323486586

Epoch: 5| Step: 6
Training loss: 3.1819010909536933
Validation loss: 2.4758594814629817

Epoch: 5| Step: 7
Training loss: 2.575657073693447
Validation loss: 2.480364795302563

Epoch: 5| Step: 8
Training loss: 2.859117006430048
Validation loss: 2.470178616788501

Epoch: 5| Step: 9
Training loss: 2.45311197654037
Validation loss: 2.4769086067019024

Epoch: 5| Step: 10
Training loss: 3.055690903026094
Validation loss: 2.4793224194448067

Epoch: 148| Step: 0
Training loss: 2.599783991130246
Validation loss: 2.4739488592220087

Epoch: 5| Step: 1
Training loss: 2.7020654972363234
Validation loss: 2.487238959515716

Epoch: 5| Step: 2
Training loss: 2.3896176079373674
Validation loss: 2.504285797593642

Epoch: 5| Step: 3
Training loss: 2.9937233431909513
Validation loss: 2.5196658727520855

Epoch: 5| Step: 4
Training loss: 2.404104093357694
Validation loss: 2.529050429654337

Epoch: 5| Step: 5
Training loss: 2.5699119371696626
Validation loss: 2.5369031908978696

Epoch: 5| Step: 6
Training loss: 3.24789800893446
Validation loss: 2.5694965346921763

Epoch: 5| Step: 7
Training loss: 2.909072325928895
Validation loss: 2.5332724724077473

Epoch: 5| Step: 8
Training loss: 2.7758874522323373
Validation loss: 2.5290075821718565

Epoch: 5| Step: 9
Training loss: 3.170367554496328
Validation loss: 2.5036072773216698

Epoch: 5| Step: 10
Training loss: 3.0926436170259177
Validation loss: 2.4899566579177215

Epoch: 149| Step: 0
Training loss: 3.3355644071042057
Validation loss: 2.468249998164935

Epoch: 5| Step: 1
Training loss: 2.326105765453062
Validation loss: 2.4802511388311475

Epoch: 5| Step: 2
Training loss: 2.3635021768507065
Validation loss: 2.4675277549422043

Epoch: 5| Step: 3
Training loss: 2.6438334458621306
Validation loss: 2.4726497036600468

Epoch: 5| Step: 4
Training loss: 2.7014114152306345
Validation loss: 2.480816873492387

Epoch: 5| Step: 5
Training loss: 2.825259279488856
Validation loss: 2.4789522880945163

Epoch: 5| Step: 6
Training loss: 2.795898522774405
Validation loss: 2.4733660155425854

Epoch: 5| Step: 7
Training loss: 2.8040296372766953
Validation loss: 2.477046108932964

Epoch: 5| Step: 8
Training loss: 3.090714015006661
Validation loss: 2.498463986351881

Epoch: 5| Step: 9
Training loss: 2.8855531478902474
Validation loss: 2.488442625631141

Epoch: 5| Step: 10
Training loss: 2.9615690418383287
Validation loss: 2.4884817664301537

Epoch: 150| Step: 0
Training loss: 2.8299335577076787
Validation loss: 2.4881146534040046

Epoch: 5| Step: 1
Training loss: 2.466689106693093
Validation loss: 2.492232309528086

Epoch: 5| Step: 2
Training loss: 2.6398897671082615
Validation loss: 2.5063420504641547

Epoch: 5| Step: 3
Training loss: 2.7268513960934784
Validation loss: 2.5197200006499028

Epoch: 5| Step: 4
Training loss: 2.506014265356234
Validation loss: 2.5261498057124476

Epoch: 5| Step: 5
Training loss: 3.189936435986963
Validation loss: 2.5421847382475313

Epoch: 5| Step: 6
Training loss: 3.1520207841158876
Validation loss: 2.5755236516049314

Epoch: 5| Step: 7
Training loss: 2.8499388370308747
Validation loss: 2.5664263981852855

Epoch: 5| Step: 8
Training loss: 2.9752417009406336
Validation loss: 2.5441127080613106

Epoch: 5| Step: 9
Training loss: 2.3543163915862912
Validation loss: 2.4918606873298987

Epoch: 5| Step: 10
Training loss: 3.064485801391273
Validation loss: 2.4685759778343894

Epoch: 151| Step: 0
Training loss: 2.5714268457316103
Validation loss: 2.463639616647708

Epoch: 5| Step: 1
Training loss: 2.958705735385166
Validation loss: 2.467997306286098

Epoch: 5| Step: 2
Training loss: 2.8513185161567995
Validation loss: 2.464817087343132

Epoch: 5| Step: 3
Training loss: 2.4817612051735347
Validation loss: 2.466789339322122

Epoch: 5| Step: 4
Training loss: 2.827308579094634
Validation loss: 2.461125271520943

Epoch: 5| Step: 5
Training loss: 2.2187105632017303
Validation loss: 2.4692322257581285

Epoch: 5| Step: 6
Training loss: 2.9067648154786934
Validation loss: 2.4737745105128317

Epoch: 5| Step: 7
Training loss: 3.2823417663786136
Validation loss: 2.477940985339067

Epoch: 5| Step: 8
Training loss: 2.620718507015104
Validation loss: 2.4822338967653095

Epoch: 5| Step: 9
Training loss: 2.871004894724108
Validation loss: 2.4924654303376794

Epoch: 5| Step: 10
Training loss: 3.2363107389582786
Validation loss: 2.50599558743975

Epoch: 152| Step: 0
Training loss: 3.2236212747824426
Validation loss: 2.515760027436633

Epoch: 5| Step: 1
Training loss: 3.1921952018327455
Validation loss: 2.5201433251509684

Epoch: 5| Step: 2
Training loss: 3.1982123686587016
Validation loss: 2.5144366718269904

Epoch: 5| Step: 3
Training loss: 2.086737204426891
Validation loss: 2.5091533958765337

Epoch: 5| Step: 4
Training loss: 2.839961452222523
Validation loss: 2.50228057534986

Epoch: 5| Step: 5
Training loss: 2.045669783239843
Validation loss: 2.485752808444629

Epoch: 5| Step: 6
Training loss: 2.967402584080613
Validation loss: 2.4738297699886735

Epoch: 5| Step: 7
Training loss: 3.0708212394596983
Validation loss: 2.4763711814210554

Epoch: 5| Step: 8
Training loss: 2.8075287010512575
Validation loss: 2.4734211359287355

Epoch: 5| Step: 9
Training loss: 2.7841927037357963
Validation loss: 2.475601729880462

Epoch: 5| Step: 10
Training loss: 1.8598535386739443
Validation loss: 2.472258906360926

Epoch: 153| Step: 0
Training loss: 3.1049234547294406
Validation loss: 2.4845598786270062

Epoch: 5| Step: 1
Training loss: 3.1279331937324244
Validation loss: 2.481720307631703

Epoch: 5| Step: 2
Training loss: 2.34353494293291
Validation loss: 2.4837438610181937

Epoch: 5| Step: 3
Training loss: 2.605359671395484
Validation loss: 2.4966785270288394

Epoch: 5| Step: 4
Training loss: 3.263437661077168
Validation loss: 2.501383371515165

Epoch: 5| Step: 5
Training loss: 3.2124628680862615
Validation loss: 2.5131967634188563

Epoch: 5| Step: 6
Training loss: 2.674568736883427
Validation loss: 2.5449175856773563

Epoch: 5| Step: 7
Training loss: 2.379617017978355
Validation loss: 2.533603028774123

Epoch: 5| Step: 8
Training loss: 2.4307405698083873
Validation loss: 2.5073351626349005

Epoch: 5| Step: 9
Training loss: 2.8600174645911016
Validation loss: 2.4911485573347134

Epoch: 5| Step: 10
Training loss: 2.341635907696294
Validation loss: 2.4862776183579176

Epoch: 154| Step: 0
Training loss: 2.994576479049983
Validation loss: 2.4879508880746184

Epoch: 5| Step: 1
Training loss: 2.978156516517801
Validation loss: 2.4932471174016437

Epoch: 5| Step: 2
Training loss: 2.394363372543489
Validation loss: 2.4846608668261836

Epoch: 5| Step: 3
Training loss: 2.946078820546069
Validation loss: 2.494338922144247

Epoch: 5| Step: 4
Training loss: 2.6290567023429756
Validation loss: 2.497244082925396

Epoch: 5| Step: 5
Training loss: 2.810308153354198
Validation loss: 2.4930204432672083

Epoch: 5| Step: 6
Training loss: 2.883534245482971
Validation loss: 2.4959146076937206

Epoch: 5| Step: 7
Training loss: 2.714146981601777
Validation loss: 2.487872565971335

Epoch: 5| Step: 8
Training loss: 2.4825721773255864
Validation loss: 2.5084198543480474

Epoch: 5| Step: 9
Training loss: 3.0135685525365776
Validation loss: 2.523813681699526

Epoch: 5| Step: 10
Training loss: 2.746090624442567
Validation loss: 2.535540798847029

Epoch: 155| Step: 0
Training loss: 2.567566398943205
Validation loss: 2.5007761304250735

Epoch: 5| Step: 1
Training loss: 3.0430524273435586
Validation loss: 2.492839593036292

Epoch: 5| Step: 2
Training loss: 2.232853618267246
Validation loss: 2.4824049647088895

Epoch: 5| Step: 3
Training loss: 2.614147641379533
Validation loss: 2.4772525601180764

Epoch: 5| Step: 4
Training loss: 2.9308023594909893
Validation loss: 2.468218476063638

Epoch: 5| Step: 5
Training loss: 3.05186718554007
Validation loss: 2.4725496173574486

Epoch: 5| Step: 6
Training loss: 2.773667446866052
Validation loss: 2.4627161513198748

Epoch: 5| Step: 7
Training loss: 2.8062455039211356
Validation loss: 2.462192450982259

Epoch: 5| Step: 8
Training loss: 2.370698144831748
Validation loss: 2.468623361471645

Epoch: 5| Step: 9
Training loss: 3.238389476996879
Validation loss: 2.479085043141449

Epoch: 5| Step: 10
Training loss: 2.82626947894801
Validation loss: 2.4811142124034262

Epoch: 156| Step: 0
Training loss: 2.373143524587895
Validation loss: 2.491953554866801

Epoch: 5| Step: 1
Training loss: 3.276467607440211
Validation loss: 2.5088525030878275

Epoch: 5| Step: 2
Training loss: 3.2777479102144262
Validation loss: 2.51500761129421

Epoch: 5| Step: 3
Training loss: 3.1364653260503474
Validation loss: 2.5193208126281714

Epoch: 5| Step: 4
Training loss: 2.3312544303626948
Validation loss: 2.4965717261735505

Epoch: 5| Step: 5
Training loss: 2.739432404473898
Validation loss: 2.473368053298171

Epoch: 5| Step: 6
Training loss: 2.792800748880811
Validation loss: 2.4669819891657108

Epoch: 5| Step: 7
Training loss: 2.6032396014244092
Validation loss: 2.4657311944930598

Epoch: 5| Step: 8
Training loss: 2.775013134899499
Validation loss: 2.458845258011375

Epoch: 5| Step: 9
Training loss: 2.6787403979821365
Validation loss: 2.4682406357824647

Epoch: 5| Step: 10
Training loss: 2.399259743174145
Validation loss: 2.4596323568639864

Epoch: 157| Step: 0
Training loss: 2.107052916576994
Validation loss: 2.4595289765861077

Epoch: 5| Step: 1
Training loss: 2.9689324573865665
Validation loss: 2.4624226125872295

Epoch: 5| Step: 2
Training loss: 3.174882487127338
Validation loss: 2.467811677185711

Epoch: 5| Step: 3
Training loss: 3.0278400235869563
Validation loss: 2.4935249121554746

Epoch: 5| Step: 4
Training loss: 2.6529494480244424
Validation loss: 2.5019236065432553

Epoch: 5| Step: 5
Training loss: 3.2463355312896827
Validation loss: 2.5585629571951207

Epoch: 5| Step: 6
Training loss: 2.7808232355053537
Validation loss: 2.607155010557162

Epoch: 5| Step: 7
Training loss: 2.409470224044921
Validation loss: 2.5696731222469187

Epoch: 5| Step: 8
Training loss: 2.2676639195655977
Validation loss: 2.552666101641826

Epoch: 5| Step: 9
Training loss: 2.7234347091196525
Validation loss: 2.5205103039164527

Epoch: 5| Step: 10
Training loss: 3.107104215084128
Validation loss: 2.509085581666401

Epoch: 158| Step: 0
Training loss: 2.538150095229655
Validation loss: 2.4927716281223975

Epoch: 5| Step: 1
Training loss: 2.680825395019971
Validation loss: 2.482912445849756

Epoch: 5| Step: 2
Training loss: 3.0609333935992904
Validation loss: 2.4816762783105415

Epoch: 5| Step: 3
Training loss: 2.4963117095395124
Validation loss: 2.4896821863834226

Epoch: 5| Step: 4
Training loss: 3.134789810800391
Validation loss: 2.4916571349399526

Epoch: 5| Step: 5
Training loss: 2.7805059916571144
Validation loss: 2.4945156977425857

Epoch: 5| Step: 6
Training loss: 2.706604939149942
Validation loss: 2.5173451320851568

Epoch: 5| Step: 7
Training loss: 2.181121354558652
Validation loss: 2.5225964384678496

Epoch: 5| Step: 8
Training loss: 2.723037145780837
Validation loss: 2.528495003335043

Epoch: 5| Step: 9
Training loss: 3.1723319790883924
Validation loss: 2.5479330148587387

Epoch: 5| Step: 10
Training loss: 3.1407153368051777
Validation loss: 2.5387485710796756

Epoch: 159| Step: 0
Training loss: 2.4143386238472404
Validation loss: 2.5178343631836704

Epoch: 5| Step: 1
Training loss: 2.8172430099629424
Validation loss: 2.4959930590132613

Epoch: 5| Step: 2
Training loss: 2.8727816440498306
Validation loss: 2.484060998092347

Epoch: 5| Step: 3
Training loss: 2.358540772749369
Validation loss: 2.480517045386521

Epoch: 5| Step: 4
Training loss: 3.048496069411487
Validation loss: 2.4682544581114363

Epoch: 5| Step: 5
Training loss: 3.161975011863151
Validation loss: 2.4760594818381185

Epoch: 5| Step: 6
Training loss: 2.738296312843066
Validation loss: 2.4700639996576417

Epoch: 5| Step: 7
Training loss: 2.818859455157296
Validation loss: 2.4673378071135277

Epoch: 5| Step: 8
Training loss: 2.5989595055179335
Validation loss: 2.471258543970968

Epoch: 5| Step: 9
Training loss: 3.207490356145381
Validation loss: 2.474081027880338

Epoch: 5| Step: 10
Training loss: 2.232543408013504
Validation loss: 2.4816665750612596

Epoch: 160| Step: 0
Training loss: 2.5856902128151296
Validation loss: 2.4953582556671523

Epoch: 5| Step: 1
Training loss: 3.0737142960878145
Validation loss: 2.5263158505850294

Epoch: 5| Step: 2
Training loss: 1.9471960791868859
Validation loss: 2.5522195189961985

Epoch: 5| Step: 3
Training loss: 2.7544803535008677
Validation loss: 2.621909441962435

Epoch: 5| Step: 4
Training loss: 2.890810738859477
Validation loss: 2.682264205803198

Epoch: 5| Step: 5
Training loss: 3.0991418265933444
Validation loss: 2.6394984655396203

Epoch: 5| Step: 6
Training loss: 2.606367742499716
Validation loss: 2.5861952721079096

Epoch: 5| Step: 7
Training loss: 3.325154012684051
Validation loss: 2.539360229100003

Epoch: 5| Step: 8
Training loss: 2.9629323072525366
Validation loss: 2.5030663609951076

Epoch: 5| Step: 9
Training loss: 2.880803429011852
Validation loss: 2.4982379528301144

Epoch: 5| Step: 10
Training loss: 2.5291102277899085
Validation loss: 2.4603478186995584

Epoch: 161| Step: 0
Training loss: 2.9411201084570835
Validation loss: 2.4571577410280705

Epoch: 5| Step: 1
Training loss: 2.957598814421982
Validation loss: 2.4545578020780394

Epoch: 5| Step: 2
Training loss: 2.6635750691021784
Validation loss: 2.4545628535114035

Epoch: 5| Step: 3
Training loss: 2.405316060130372
Validation loss: 2.447120758787518

Epoch: 5| Step: 4
Training loss: 3.0419210214388186
Validation loss: 2.4499340221561123

Epoch: 5| Step: 5
Training loss: 2.291725458489171
Validation loss: 2.4521200215382497

Epoch: 5| Step: 6
Training loss: 3.0397985983941154
Validation loss: 2.4536718946743417

Epoch: 5| Step: 7
Training loss: 3.1672177253564384
Validation loss: 2.4486700179485936

Epoch: 5| Step: 8
Training loss: 2.8342448245671963
Validation loss: 2.454055959575563

Epoch: 5| Step: 9
Training loss: 2.3339550575106918
Validation loss: 2.4573365424552

Epoch: 5| Step: 10
Training loss: 2.727146293859494
Validation loss: 2.4699688425166864

Epoch: 162| Step: 0
Training loss: 3.0614530369696675
Validation loss: 2.4855036236708097

Epoch: 5| Step: 1
Training loss: 3.0085132921941833
Validation loss: 2.4984643372735036

Epoch: 5| Step: 2
Training loss: 2.8912575519362536
Validation loss: 2.5140765864179273

Epoch: 5| Step: 3
Training loss: 2.937456171236359
Validation loss: 2.523592966316279

Epoch: 5| Step: 4
Training loss: 2.1123632668931687
Validation loss: 2.550934630779475

Epoch: 5| Step: 5
Training loss: 2.42010748569347
Validation loss: 2.5707138251402046

Epoch: 5| Step: 6
Training loss: 3.1925024533542414
Validation loss: 2.576130452142925

Epoch: 5| Step: 7
Training loss: 2.7437801246466536
Validation loss: 2.506298992742039

Epoch: 5| Step: 8
Training loss: 2.5775256760777077
Validation loss: 2.4590159320693576

Epoch: 5| Step: 9
Training loss: 2.4197825591077016
Validation loss: 2.452748563617871

Epoch: 5| Step: 10
Training loss: 3.0783669623531282
Validation loss: 2.459518761731703

Epoch: 163| Step: 0
Training loss: 2.649288614623597
Validation loss: 2.4621899906198106

Epoch: 5| Step: 1
Training loss: 3.266323471206532
Validation loss: 2.463543645254447

Epoch: 5| Step: 2
Training loss: 2.4743850714740407
Validation loss: 2.461425570340837

Epoch: 5| Step: 3
Training loss: 3.194209349085262
Validation loss: 2.4554014703153024

Epoch: 5| Step: 4
Training loss: 2.776611832592086
Validation loss: 2.453949410859349

Epoch: 5| Step: 5
Training loss: 2.564065873482651
Validation loss: 2.450546377675106

Epoch: 5| Step: 6
Training loss: 2.4988292813950643
Validation loss: 2.4546578282367713

Epoch: 5| Step: 7
Training loss: 3.0946122326230623
Validation loss: 2.447006137059852

Epoch: 5| Step: 8
Training loss: 2.544706298878613
Validation loss: 2.4587326853436338

Epoch: 5| Step: 9
Training loss: 2.714628932879243
Validation loss: 2.46217777623221

Epoch: 5| Step: 10
Training loss: 2.8309654177025947
Validation loss: 2.4796966412995274

Epoch: 164| Step: 0
Training loss: 2.599130220914958
Validation loss: 2.4981383950135774

Epoch: 5| Step: 1
Training loss: 3.109285899663646
Validation loss: 2.530537155369513

Epoch: 5| Step: 2
Training loss: 3.315114123421116
Validation loss: 2.5847902929715505

Epoch: 5| Step: 3
Training loss: 2.737159314141658
Validation loss: 2.6093412606745927

Epoch: 5| Step: 4
Training loss: 2.4675228110885192
Validation loss: 2.64695010857091

Epoch: 5| Step: 5
Training loss: 2.3247549768770575
Validation loss: 2.649500563905684

Epoch: 5| Step: 6
Training loss: 3.0446359085368084
Validation loss: 2.5784875639050684

Epoch: 5| Step: 7
Training loss: 2.436016511645051
Validation loss: 2.5301128543928604

Epoch: 5| Step: 8
Training loss: 2.952715971539007
Validation loss: 2.4992833802427272

Epoch: 5| Step: 9
Training loss: 2.723391462364802
Validation loss: 2.4618814450139554

Epoch: 5| Step: 10
Training loss: 2.898547723118983
Validation loss: 2.4512816725461577

Epoch: 165| Step: 0
Training loss: 3.112608641907656
Validation loss: 2.44964963949687

Epoch: 5| Step: 1
Training loss: 3.1917742326769245
Validation loss: 2.4476034281253587

Epoch: 5| Step: 2
Training loss: 2.810876250434652
Validation loss: 2.44800010195106

Epoch: 5| Step: 3
Training loss: 2.9329841478181464
Validation loss: 2.4509019562610774

Epoch: 5| Step: 4
Training loss: 2.4377782613919354
Validation loss: 2.4497690125820366

Epoch: 5| Step: 5
Training loss: 2.787769862228325
Validation loss: 2.4447698100039768

Epoch: 5| Step: 6
Training loss: 2.920870195084541
Validation loss: 2.445374939201387

Epoch: 5| Step: 7
Training loss: 2.617516704750133
Validation loss: 2.444882585704331

Epoch: 5| Step: 8
Training loss: 2.330890318913031
Validation loss: 2.448136698395428

Epoch: 5| Step: 9
Training loss: 2.7797570668564773
Validation loss: 2.459904530652986

Epoch: 5| Step: 10
Training loss: 2.422128873255097
Validation loss: 2.4582815093565076

Epoch: 166| Step: 0
Training loss: 2.9431544323039076
Validation loss: 2.4675967273433264

Epoch: 5| Step: 1
Training loss: 2.323621041514272
Validation loss: 2.4674119606074747

Epoch: 5| Step: 2
Training loss: 2.7860774460247515
Validation loss: 2.4710695754291163

Epoch: 5| Step: 3
Training loss: 2.1889827607557777
Validation loss: 2.4657617929118736

Epoch: 5| Step: 4
Training loss: 2.945872933977236
Validation loss: 2.4680797434967423

Epoch: 5| Step: 5
Training loss: 2.657635944294938
Validation loss: 2.4631845783933617

Epoch: 5| Step: 6
Training loss: 3.028886010882375
Validation loss: 2.4612757681939894

Epoch: 5| Step: 7
Training loss: 2.651386610771396
Validation loss: 2.4588555350928027

Epoch: 5| Step: 8
Training loss: 2.879531937287108
Validation loss: 2.4571360145073338

Epoch: 5| Step: 9
Training loss: 2.7530248651902354
Validation loss: 2.449211905503346

Epoch: 5| Step: 10
Training loss: 2.9616791694590447
Validation loss: 2.4545865621572394

Epoch: 167| Step: 0
Training loss: 2.546668108628482
Validation loss: 2.482086317225322

Epoch: 5| Step: 1
Training loss: 2.490908111984678
Validation loss: 2.4975101603419647

Epoch: 5| Step: 2
Training loss: 2.925386980329299
Validation loss: 2.5291785719255926

Epoch: 5| Step: 3
Training loss: 2.894272765691603
Validation loss: 2.541886547253245

Epoch: 5| Step: 4
Training loss: 2.364627473618045
Validation loss: 2.508215289870686

Epoch: 5| Step: 5
Training loss: 3.3066893662422143
Validation loss: 2.4890786808205525

Epoch: 5| Step: 6
Training loss: 2.9162653147348054
Validation loss: 2.461301807810389

Epoch: 5| Step: 7
Training loss: 2.620160955915878
Validation loss: 2.451357131648964

Epoch: 5| Step: 8
Training loss: 3.1236488473061206
Validation loss: 2.442065340722261

Epoch: 5| Step: 9
Training loss: 2.355376132643533
Validation loss: 2.4419271201758317

Epoch: 5| Step: 10
Training loss: 2.6760311706107465
Validation loss: 2.449862511924734

Epoch: 168| Step: 0
Training loss: 2.5568087575719525
Validation loss: 2.440428021426416

Epoch: 5| Step: 1
Training loss: 2.52617201845668
Validation loss: 2.443723524349009

Epoch: 5| Step: 2
Training loss: 2.7170977778919263
Validation loss: 2.447793314349583

Epoch: 5| Step: 3
Training loss: 2.396376727856863
Validation loss: 2.45465400103596

Epoch: 5| Step: 4
Training loss: 2.903098089218654
Validation loss: 2.4628939038555626

Epoch: 5| Step: 5
Training loss: 3.163045385323951
Validation loss: 2.481543648456743

Epoch: 5| Step: 6
Training loss: 2.57820323478597
Validation loss: 2.5003962310459493

Epoch: 5| Step: 7
Training loss: 2.8205573062900897
Validation loss: 2.51973177738343

Epoch: 5| Step: 8
Training loss: 2.966160658926861
Validation loss: 2.490612497111895

Epoch: 5| Step: 9
Training loss: 2.596800515475783
Validation loss: 2.4796332105342387

Epoch: 5| Step: 10
Training loss: 2.7937863307015784
Validation loss: 2.4752577376405243

Epoch: 169| Step: 0
Training loss: 3.584050498581095
Validation loss: 2.467858625692305

Epoch: 5| Step: 1
Training loss: 2.250690142433768
Validation loss: 2.4874197057473415

Epoch: 5| Step: 2
Training loss: 2.5857260810655274
Validation loss: 2.4924842374158422

Epoch: 5| Step: 3
Training loss: 2.5881215809382887
Validation loss: 2.4840788481246747

Epoch: 5| Step: 4
Training loss: 2.325558982840925
Validation loss: 2.494688425277009

Epoch: 5| Step: 5
Training loss: 3.0409057048514905
Validation loss: 2.493521576934823

Epoch: 5| Step: 6
Training loss: 3.1783192382990717
Validation loss: 2.4852932779292374

Epoch: 5| Step: 7
Training loss: 2.387294069366573
Validation loss: 2.4723809165467188

Epoch: 5| Step: 8
Training loss: 2.760529214735855
Validation loss: 2.47188542220202

Epoch: 5| Step: 9
Training loss: 2.5026915366607487
Validation loss: 2.468875605071114

Epoch: 5| Step: 10
Training loss: 2.521739092902622
Validation loss: 2.4673035178110063

Epoch: 170| Step: 0
Training loss: 2.88235097772868
Validation loss: 2.45829011084128

Epoch: 5| Step: 1
Training loss: 2.700840508360151
Validation loss: 2.4639937833131733

Epoch: 5| Step: 2
Training loss: 3.0434120256905204
Validation loss: 2.454656063202891

Epoch: 5| Step: 3
Training loss: 2.9117597629779426
Validation loss: 2.4669468001701227

Epoch: 5| Step: 4
Training loss: 2.3743155647665137
Validation loss: 2.4720233085827172

Epoch: 5| Step: 5
Training loss: 2.64285978295036
Validation loss: 2.4748635826331

Epoch: 5| Step: 6
Training loss: 2.5798396102080052
Validation loss: 2.4647753147474263

Epoch: 5| Step: 7
Training loss: 2.6798720226761508
Validation loss: 2.483726356421433

Epoch: 5| Step: 8
Training loss: 2.965028377609445
Validation loss: 2.4925100003626284

Epoch: 5| Step: 9
Training loss: 3.0983892009008147
Validation loss: 2.4985603012006092

Epoch: 5| Step: 10
Training loss: 1.7219453413038726
Validation loss: 2.505330546318004

Epoch: 171| Step: 0
Training loss: 2.6723863435848236
Validation loss: 2.5059604935926543

Epoch: 5| Step: 1
Training loss: 2.8312409659740494
Validation loss: 2.496793355775763

Epoch: 5| Step: 2
Training loss: 2.557743216515939
Validation loss: 2.4866701651954384

Epoch: 5| Step: 3
Training loss: 2.7938837006598
Validation loss: 2.4774387825707027

Epoch: 5| Step: 4
Training loss: 2.9867914612560793
Validation loss: 2.4708641826277655

Epoch: 5| Step: 5
Training loss: 2.655439185763272
Validation loss: 2.4724400198057057

Epoch: 5| Step: 6
Training loss: 2.6199405594991725
Validation loss: 2.4836039952358546

Epoch: 5| Step: 7
Training loss: 2.5566491111573733
Validation loss: 2.484926113741035

Epoch: 5| Step: 8
Training loss: 2.8750998438208155
Validation loss: 2.484629472962488

Epoch: 5| Step: 9
Training loss: 2.587974460611398
Validation loss: 2.469750083021435

Epoch: 5| Step: 10
Training loss: 2.7279748619688893
Validation loss: 2.462063514474587

Epoch: 172| Step: 0
Training loss: 2.9201537585601227
Validation loss: 2.453351261909153

Epoch: 5| Step: 1
Training loss: 2.3129316391068278
Validation loss: 2.454540021451233

Epoch: 5| Step: 2
Training loss: 2.653546292450535
Validation loss: 2.4717470862917286

Epoch: 5| Step: 3
Training loss: 2.5553434970427005
Validation loss: 2.4725627665391112

Epoch: 5| Step: 4
Training loss: 2.877916266776054
Validation loss: 2.491595385867323

Epoch: 5| Step: 5
Training loss: 2.535689428656647
Validation loss: 2.5004297440856145

Epoch: 5| Step: 6
Training loss: 2.8113175343585257
Validation loss: 2.502567237505645

Epoch: 5| Step: 7
Training loss: 2.8993139047305765
Validation loss: 2.5066680131623666

Epoch: 5| Step: 8
Training loss: 2.8245618092126255
Validation loss: 2.518592426933867

Epoch: 5| Step: 9
Training loss: 2.6397132879681804
Validation loss: 2.522408071774031

Epoch: 5| Step: 10
Training loss: 2.6981866080447947
Validation loss: 2.5007038120444856

Epoch: 173| Step: 0
Training loss: 2.8368291792916382
Validation loss: 2.4840558905404158

Epoch: 5| Step: 1
Training loss: 3.1464201188348935
Validation loss: 2.46833154619273

Epoch: 5| Step: 2
Training loss: 2.9780034459736537
Validation loss: 2.4480847393732112

Epoch: 5| Step: 3
Training loss: 2.6718997173392984
Validation loss: 2.4376148000165765

Epoch: 5| Step: 4
Training loss: 2.7604338639401416
Validation loss: 2.456639166150834

Epoch: 5| Step: 5
Training loss: 2.925127636333631
Validation loss: 2.458132031852548

Epoch: 5| Step: 6
Training loss: 2.327401682480652
Validation loss: 2.488814166946584

Epoch: 5| Step: 7
Training loss: 2.554629823926058
Validation loss: 2.497934703506404

Epoch: 5| Step: 8
Training loss: 2.9047120649869855
Validation loss: 2.50611519510197

Epoch: 5| Step: 9
Training loss: 2.209756704376163
Validation loss: 2.520743897723703

Epoch: 5| Step: 10
Training loss: 2.5405889529665737
Validation loss: 2.509610208198752

Epoch: 174| Step: 0
Training loss: 2.437232173975397
Validation loss: 2.47694643832663

Epoch: 5| Step: 1
Training loss: 2.7560762553911684
Validation loss: 2.457631844981633

Epoch: 5| Step: 2
Training loss: 2.9808570138959167
Validation loss: 2.443738868020193

Epoch: 5| Step: 3
Training loss: 1.9888997193378437
Validation loss: 2.447125018386769

Epoch: 5| Step: 4
Training loss: 2.548732524847465
Validation loss: 2.4503307544517465

Epoch: 5| Step: 5
Training loss: 2.281654844548333
Validation loss: 2.449903916171452

Epoch: 5| Step: 6
Training loss: 3.2032473657076634
Validation loss: 2.448595173327789

Epoch: 5| Step: 7
Training loss: 2.7680313934464293
Validation loss: 2.4517446134718828

Epoch: 5| Step: 8
Training loss: 3.102189699650424
Validation loss: 2.4826233107778957

Epoch: 5| Step: 9
Training loss: 2.596403579981429
Validation loss: 2.496814165302559

Epoch: 5| Step: 10
Training loss: 2.928082893907505
Validation loss: 2.5259697624267865

Epoch: 175| Step: 0
Training loss: 2.875677443591774
Validation loss: 2.585938785320801

Epoch: 5| Step: 1
Training loss: 2.838712821256737
Validation loss: 2.544211129876984

Epoch: 5| Step: 2
Training loss: 2.5687962845765044
Validation loss: 2.510716451327758

Epoch: 5| Step: 3
Training loss: 2.5101065437531593
Validation loss: 2.4804741326221125

Epoch: 5| Step: 4
Training loss: 3.076400816133416
Validation loss: 2.4715642894318997

Epoch: 5| Step: 5
Training loss: 2.720763589881327
Validation loss: 2.4753171678399477

Epoch: 5| Step: 6
Training loss: 2.8127649818206537
Validation loss: 2.4715879843550717

Epoch: 5| Step: 7
Training loss: 3.1953912925798793
Validation loss: 2.5005942920119852

Epoch: 5| Step: 8
Training loss: 2.5779831355973446
Validation loss: 2.4912095045139138

Epoch: 5| Step: 9
Training loss: 2.4270155955891406
Validation loss: 2.4860792371293465

Epoch: 5| Step: 10
Training loss: 2.2677559138084145
Validation loss: 2.4695831820207617

Epoch: 176| Step: 0
Training loss: 2.5567932782742466
Validation loss: 2.4597895911205154

Epoch: 5| Step: 1
Training loss: 2.1788964151985937
Validation loss: 2.460082265417271

Epoch: 5| Step: 2
Training loss: 2.4229255612691984
Validation loss: 2.4748350695880563

Epoch: 5| Step: 3
Training loss: 2.7951136322670598
Validation loss: 2.507267458754399

Epoch: 5| Step: 4
Training loss: 3.0916380175748044
Validation loss: 2.5188957652385495

Epoch: 5| Step: 5
Training loss: 2.592759092474441
Validation loss: 2.498504442570252

Epoch: 5| Step: 6
Training loss: 2.7956517277579946
Validation loss: 2.4697122916759255

Epoch: 5| Step: 7
Training loss: 2.7320258812746614
Validation loss: 2.4588835437532577

Epoch: 5| Step: 8
Training loss: 3.014671372554075
Validation loss: 2.434047783757064

Epoch: 5| Step: 9
Training loss: 2.7514503295840567
Validation loss: 2.4384223164845906

Epoch: 5| Step: 10
Training loss: 2.8418299302738186
Validation loss: 2.430106235192177

Epoch: 177| Step: 0
Training loss: 2.7178710744510393
Validation loss: 2.4273414117236207

Epoch: 5| Step: 1
Training loss: 2.8280428879762254
Validation loss: 2.4224613904858945

Epoch: 5| Step: 2
Training loss: 2.772313967655902
Validation loss: 2.4379974806247295

Epoch: 5| Step: 3
Training loss: 2.238154595804423
Validation loss: 2.441657077168921

Epoch: 5| Step: 4
Training loss: 3.3679347083225837
Validation loss: 2.450741879737014

Epoch: 5| Step: 5
Training loss: 3.2241660170867914
Validation loss: 2.465587527604581

Epoch: 5| Step: 6
Training loss: 2.7036722323890614
Validation loss: 2.460549830073046

Epoch: 5| Step: 7
Training loss: 1.7668541874720725
Validation loss: 2.474917944572031

Epoch: 5| Step: 8
Training loss: 2.6197437158118433
Validation loss: 2.4820704824416238

Epoch: 5| Step: 9
Training loss: 2.6727436282212453
Validation loss: 2.479410647758443

Epoch: 5| Step: 10
Training loss: 2.15331256199002
Validation loss: 2.4803363987271334

Epoch: 178| Step: 0
Training loss: 2.665908039982404
Validation loss: 2.4701728744344753

Epoch: 5| Step: 1
Training loss: 2.94741608556052
Validation loss: 2.4621243054259874

Epoch: 5| Step: 2
Training loss: 2.4890627030673667
Validation loss: 2.451020908025062

Epoch: 5| Step: 3
Training loss: 2.6301751666606
Validation loss: 2.4479055763539734

Epoch: 5| Step: 4
Training loss: 2.673433618860421
Validation loss: 2.4341522715173367

Epoch: 5| Step: 5
Training loss: 2.4529908744931523
Validation loss: 2.4416253996903645

Epoch: 5| Step: 6
Training loss: 2.772269935384181
Validation loss: 2.45252429595343

Epoch: 5| Step: 7
Training loss: 2.7869982520167436
Validation loss: 2.468787963915894

Epoch: 5| Step: 8
Training loss: 2.6573758600331296
Validation loss: 2.4761884888329204

Epoch: 5| Step: 9
Training loss: 2.918039670845803
Validation loss: 2.476101821945283

Epoch: 5| Step: 10
Training loss: 2.322884312790702
Validation loss: 2.4795465099956306

Epoch: 179| Step: 0
Training loss: 2.394386473817152
Validation loss: 2.519610240881211

Epoch: 5| Step: 1
Training loss: 2.4884167309442486
Validation loss: 2.518183747049822

Epoch: 5| Step: 2
Training loss: 2.805804781865265
Validation loss: 2.541975087039565

Epoch: 5| Step: 3
Training loss: 2.663554392040668
Validation loss: 2.504345443863478

Epoch: 5| Step: 4
Training loss: 2.859381336976414
Validation loss: 2.446527560749349

Epoch: 5| Step: 5
Training loss: 2.7013889095913304
Validation loss: 2.428552668595442

Epoch: 5| Step: 6
Training loss: 2.8569070139684984
Validation loss: 2.420575368846302

Epoch: 5| Step: 7
Training loss: 2.7034276892034588
Validation loss: 2.4177052540183444

Epoch: 5| Step: 8
Training loss: 3.020312841013787
Validation loss: 2.416482767428426

Epoch: 5| Step: 9
Training loss: 2.1689039807802093
Validation loss: 2.425958815403213

Epoch: 5| Step: 10
Training loss: 2.6844488167078033
Validation loss: 2.450596797432152

Epoch: 180| Step: 0
Training loss: 2.5890174801952086
Validation loss: 2.462350474402239

Epoch: 5| Step: 1
Training loss: 2.529033113961957
Validation loss: 2.465424270202083

Epoch: 5| Step: 2
Training loss: 2.679041392560133
Validation loss: 2.499627186038948

Epoch: 5| Step: 3
Training loss: 2.8206826598488566
Validation loss: 2.5275381875385117

Epoch: 5| Step: 4
Training loss: 2.5539475048767186
Validation loss: 2.5482334419954125

Epoch: 5| Step: 5
Training loss: 2.8080712098930687
Validation loss: 2.5621022141528305

Epoch: 5| Step: 6
Training loss: 3.063164152413936
Validation loss: 2.549583624895785

Epoch: 5| Step: 7
Training loss: 2.5828466469687688
Validation loss: 2.5017219673560342

Epoch: 5| Step: 8
Training loss: 2.464896949641318
Validation loss: 2.4854783419876125

Epoch: 5| Step: 9
Training loss: 2.82115165082682
Validation loss: 2.4615981327801957

Epoch: 5| Step: 10
Training loss: 2.3986208966744065
Validation loss: 2.4603284075214185

Epoch: 181| Step: 0
Training loss: 2.5894749351477224
Validation loss: 2.4536897463702636

Epoch: 5| Step: 1
Training loss: 2.7390530922832057
Validation loss: 2.4562855181661862

Epoch: 5| Step: 2
Training loss: 2.966578442265394
Validation loss: 2.4521417182734284

Epoch: 5| Step: 3
Training loss: 3.0710384685128007
Validation loss: 2.4609484444261085

Epoch: 5| Step: 4
Training loss: 2.4287502038693503
Validation loss: 2.4654368085309017

Epoch: 5| Step: 5
Training loss: 2.484315019759194
Validation loss: 2.4808283347465054

Epoch: 5| Step: 6
Training loss: 2.847075812651184
Validation loss: 2.490083964802237

Epoch: 5| Step: 7
Training loss: 2.1627135772195643
Validation loss: 2.529900163964026

Epoch: 5| Step: 8
Training loss: 2.526181928273399
Validation loss: 2.582588492981655

Epoch: 5| Step: 9
Training loss: 2.4844803697805116
Validation loss: 2.6047558642572985

Epoch: 5| Step: 10
Training loss: 3.0568908393993897
Validation loss: 2.543195773549617

Epoch: 182| Step: 0
Training loss: 2.6531825586192843
Validation loss: 2.462469635730375

Epoch: 5| Step: 1
Training loss: 2.7954107106304034
Validation loss: 2.429051513072888

Epoch: 5| Step: 2
Training loss: 2.3000742112502155
Validation loss: 2.4216178881942994

Epoch: 5| Step: 3
Training loss: 2.4043974247227067
Validation loss: 2.4285090054463687

Epoch: 5| Step: 4
Training loss: 2.661349528876253
Validation loss: 2.4250276473693284

Epoch: 5| Step: 5
Training loss: 2.8023666087383585
Validation loss: 2.42203785656051

Epoch: 5| Step: 6
Training loss: 2.6664882143233344
Validation loss: 2.4225706775776414

Epoch: 5| Step: 7
Training loss: 2.93687448537708
Validation loss: 2.4243740371235094

Epoch: 5| Step: 8
Training loss: 2.682708549818456
Validation loss: 2.4318926512627153

Epoch: 5| Step: 9
Training loss: 2.750531231981464
Validation loss: 2.440172149026032

Epoch: 5| Step: 10
Training loss: 3.09463395870641
Validation loss: 2.4843732323449674

Epoch: 183| Step: 0
Training loss: 2.515515627171581
Validation loss: 2.54417393168677

Epoch: 5| Step: 1
Training loss: 2.5939766658418746
Validation loss: 2.5764440352169578

Epoch: 5| Step: 2
Training loss: 2.760300332742964
Validation loss: 2.639330669124799

Epoch: 5| Step: 3
Training loss: 2.730156658274969
Validation loss: 2.5712907813713017

Epoch: 5| Step: 4
Training loss: 3.522140636428472
Validation loss: 2.481631854617595

Epoch: 5| Step: 5
Training loss: 2.446513408188337
Validation loss: 2.42734497834512

Epoch: 5| Step: 6
Training loss: 2.8348840695852595
Validation loss: 2.416806871111645

Epoch: 5| Step: 7
Training loss: 2.465958187667665
Validation loss: 2.447939391719051

Epoch: 5| Step: 8
Training loss: 2.730438974460996
Validation loss: 2.458888774489549

Epoch: 5| Step: 9
Training loss: 2.519725892584546
Validation loss: 2.4581940552217687

Epoch: 5| Step: 10
Training loss: 2.739996314498762
Validation loss: 2.4639891845588013

Epoch: 184| Step: 0
Training loss: 2.091927375605068
Validation loss: 2.4501171808553615

Epoch: 5| Step: 1
Training loss: 3.151196049883251
Validation loss: 2.469407286554884

Epoch: 5| Step: 2
Training loss: 2.997957169871313
Validation loss: 2.499546771856237

Epoch: 5| Step: 3
Training loss: 2.3995649936949124
Validation loss: 2.5592608895523097

Epoch: 5| Step: 4
Training loss: 2.0901063557992083
Validation loss: 2.577193489724327

Epoch: 5| Step: 5
Training loss: 3.0709998062814434
Validation loss: 2.5837077680884195

Epoch: 5| Step: 6
Training loss: 2.9359969493943665
Validation loss: 2.580861347014172

Epoch: 5| Step: 7
Training loss: 2.860320221640351
Validation loss: 2.522337238542294

Epoch: 5| Step: 8
Training loss: 2.333114704607023
Validation loss: 2.4969270801699457

Epoch: 5| Step: 9
Training loss: 2.4462773671127613
Validation loss: 2.4712577327376346

Epoch: 5| Step: 10
Training loss: 2.536238664100699
Validation loss: 2.4741787457467526

Epoch: 185| Step: 0
Training loss: 2.7921523815096165
Validation loss: 2.4652997569143764

Epoch: 5| Step: 1
Training loss: 2.150112983041531
Validation loss: 2.4519530862728116

Epoch: 5| Step: 2
Training loss: 3.102501714984134
Validation loss: 2.455988438430241

Epoch: 5| Step: 3
Training loss: 2.9721294242022815
Validation loss: 2.450421973607567

Epoch: 5| Step: 4
Training loss: 2.683735717394295
Validation loss: 2.4599639388812062

Epoch: 5| Step: 5
Training loss: 2.706380658596657
Validation loss: 2.4747586243539477

Epoch: 5| Step: 6
Training loss: 2.590032280091131
Validation loss: 2.502168981962887

Epoch: 5| Step: 7
Training loss: 2.894635197347019
Validation loss: 2.5234046567400403

Epoch: 5| Step: 8
Training loss: 2.5270094967396837
Validation loss: 2.5382910882606295

Epoch: 5| Step: 9
Training loss: 2.372696914299263
Validation loss: 2.472914102288654

Epoch: 5| Step: 10
Training loss: 2.784805425562035
Validation loss: 2.4544976269206353

Epoch: 186| Step: 0
Training loss: 3.0110313729508107
Validation loss: 2.4258293395576116

Epoch: 5| Step: 1
Training loss: 2.6152329163550823
Validation loss: 2.415071185298566

Epoch: 5| Step: 2
Training loss: 2.667861065010869
Validation loss: 2.412431735782171

Epoch: 5| Step: 3
Training loss: 2.5663767076995447
Validation loss: 2.4191440582747776

Epoch: 5| Step: 4
Training loss: 2.9138874072941965
Validation loss: 2.424437855165154

Epoch: 5| Step: 5
Training loss: 2.703888096344768
Validation loss: 2.433245536371059

Epoch: 5| Step: 6
Training loss: 2.8847469466114157
Validation loss: 2.445025867063867

Epoch: 5| Step: 7
Training loss: 2.348629158001315
Validation loss: 2.454038720626226

Epoch: 5| Step: 8
Training loss: 2.4478043117846457
Validation loss: 2.4763414719005934

Epoch: 5| Step: 9
Training loss: 2.605546621277039
Validation loss: 2.471623079267988

Epoch: 5| Step: 10
Training loss: 2.193676973958714
Validation loss: 2.4678205986549564

Epoch: 187| Step: 0
Training loss: 2.871376905945741
Validation loss: 2.485404061179743

Epoch: 5| Step: 1
Training loss: 2.37738198742561
Validation loss: 2.488014965619789

Epoch: 5| Step: 2
Training loss: 2.002370145209245
Validation loss: 2.497686632460354

Epoch: 5| Step: 3
Training loss: 2.6886794584944083
Validation loss: 2.465424772443549

Epoch: 5| Step: 4
Training loss: 2.446125127054426
Validation loss: 2.4313205949055012

Epoch: 5| Step: 5
Training loss: 2.9785538867931804
Validation loss: 2.4313349223645746

Epoch: 5| Step: 6
Training loss: 2.616182595527007
Validation loss: 2.437035061120909

Epoch: 5| Step: 7
Training loss: 2.993906826936821
Validation loss: 2.4730185111637537

Epoch: 5| Step: 8
Training loss: 2.853376088787621
Validation loss: 2.4863507945525387

Epoch: 5| Step: 9
Training loss: 2.4471071135629194
Validation loss: 2.4865840131274424

Epoch: 5| Step: 10
Training loss: 2.37432761462093
Validation loss: 2.4849052417999222

Epoch: 188| Step: 0
Training loss: 2.9219546383699058
Validation loss: 2.456503879995189

Epoch: 5| Step: 1
Training loss: 2.3730565200421276
Validation loss: 2.427479485894772

Epoch: 5| Step: 2
Training loss: 2.833723228405533
Validation loss: 2.414806488803081

Epoch: 5| Step: 3
Training loss: 1.9102109811504944
Validation loss: 2.4064507157676713

Epoch: 5| Step: 4
Training loss: 2.9159281386009606
Validation loss: 2.3970177564153454

Epoch: 5| Step: 5
Training loss: 2.702933949681407
Validation loss: 2.397532376292928

Epoch: 5| Step: 6
Training loss: 2.801348215174678
Validation loss: 2.4071983329923015

Epoch: 5| Step: 7
Training loss: 3.101994789419219
Validation loss: 2.422101559397443

Epoch: 5| Step: 8
Training loss: 2.576140038421552
Validation loss: 2.4622173928588986

Epoch: 5| Step: 9
Training loss: 1.9493033901024845
Validation loss: 2.5180922816096185

Epoch: 5| Step: 10
Training loss: 2.468995383899896
Validation loss: 2.5195998605790457

Epoch: 189| Step: 0
Training loss: 2.2276610759547175
Validation loss: 2.5098271777955214

Epoch: 5| Step: 1
Training loss: 2.7825771979824627
Validation loss: 2.477126046824834

Epoch: 5| Step: 2
Training loss: 2.6199431985419888
Validation loss: 2.4429929005028583

Epoch: 5| Step: 3
Training loss: 2.7976477210866397
Validation loss: 2.4169689437794317

Epoch: 5| Step: 4
Training loss: 2.745713274062282
Validation loss: 2.4106949608540362

Epoch: 5| Step: 5
Training loss: 2.3825695476808506
Validation loss: 2.413694657476151

Epoch: 5| Step: 6
Training loss: 2.1722923262076144
Validation loss: 2.4084096964235155

Epoch: 5| Step: 7
Training loss: 2.8452407785977973
Validation loss: 2.4187172671724837

Epoch: 5| Step: 8
Training loss: 2.389831012194315
Validation loss: 2.4093148665586868

Epoch: 5| Step: 9
Training loss: 2.827756741821681
Validation loss: 2.4215589313763637

Epoch: 5| Step: 10
Training loss: 2.8555455647585295
Validation loss: 2.43052122764742

Epoch: 190| Step: 0
Training loss: 2.4805704411364617
Validation loss: 2.4699022276380185

Epoch: 5| Step: 1
Training loss: 2.551058089698108
Validation loss: 2.4958230410593445

Epoch: 5| Step: 2
Training loss: 2.5287522602306907
Validation loss: 2.5155580359236325

Epoch: 5| Step: 3
Training loss: 3.0246027788131937
Validation loss: 2.557292967220549

Epoch: 5| Step: 4
Training loss: 2.5942399814570702
Validation loss: 2.5610804714042

Epoch: 5| Step: 5
Training loss: 2.72616810391853
Validation loss: 2.5421879571857953

Epoch: 5| Step: 6
Training loss: 2.891786084379773
Validation loss: 2.4703681868903264

Epoch: 5| Step: 7
Training loss: 2.3613362024262177
Validation loss: 2.4182246118856248

Epoch: 5| Step: 8
Training loss: 2.8003663164026382
Validation loss: 2.396441628453911

Epoch: 5| Step: 9
Training loss: 2.3657944612264554
Validation loss: 2.394424800389971

Epoch: 5| Step: 10
Training loss: 2.6153335609458623
Validation loss: 2.390426290758829

Epoch: 191| Step: 0
Training loss: 2.5437921693947834
Validation loss: 2.4005215017571757

Epoch: 5| Step: 1
Training loss: 2.8566387821766925
Validation loss: 2.3931704337033657

Epoch: 5| Step: 2
Training loss: 2.387785977317507
Validation loss: 2.383604067550482

Epoch: 5| Step: 3
Training loss: 3.019051774067804
Validation loss: 2.393154369990715

Epoch: 5| Step: 4
Training loss: 2.5699100817079117
Validation loss: 2.393346595063585

Epoch: 5| Step: 5
Training loss: 2.6778718452586387
Validation loss: 2.438251348009068

Epoch: 5| Step: 6
Training loss: 2.8130240058186513
Validation loss: 2.4882709986359837

Epoch: 5| Step: 7
Training loss: 2.553428689738149
Validation loss: 2.5557125970521453

Epoch: 5| Step: 8
Training loss: 2.429778364144505
Validation loss: 2.570196673820635

Epoch: 5| Step: 9
Training loss: 2.4578951967832885
Validation loss: 2.5914945723398577

Epoch: 5| Step: 10
Training loss: 2.719167830708292
Validation loss: 2.4926002400602116

Epoch: 192| Step: 0
Training loss: 2.486704184357377
Validation loss: 2.433822734570961

Epoch: 5| Step: 1
Training loss: 2.538768011768331
Validation loss: 2.395213654691055

Epoch: 5| Step: 2
Training loss: 3.2211571738294893
Validation loss: 2.3960331887399398

Epoch: 5| Step: 3
Training loss: 2.3203836038400474
Validation loss: 2.4095300660848555

Epoch: 5| Step: 4
Training loss: 2.0811876946365016
Validation loss: 2.41568857738743

Epoch: 5| Step: 5
Training loss: 2.6609113296592732
Validation loss: 2.4254191093643147

Epoch: 5| Step: 6
Training loss: 2.572332637669946
Validation loss: 2.426623177261514

Epoch: 5| Step: 7
Training loss: 2.8016291442875842
Validation loss: 2.4340415706763228

Epoch: 5| Step: 8
Training loss: 2.8711854258322846
Validation loss: 2.4274635684303543

Epoch: 5| Step: 9
Training loss: 3.0475355165960822
Validation loss: 2.431034433992395

Epoch: 5| Step: 10
Training loss: 2.628666360914906
Validation loss: 2.446868416158618

Epoch: 193| Step: 0
Training loss: 2.9479075365408156
Validation loss: 2.51271852977449

Epoch: 5| Step: 1
Training loss: 2.944602172353708
Validation loss: 2.558004214632252

Epoch: 5| Step: 2
Training loss: 2.3747905839648236
Validation loss: 2.5633588042589195

Epoch: 5| Step: 3
Training loss: 2.287133038379666
Validation loss: 2.534722289574563

Epoch: 5| Step: 4
Training loss: 2.582847939286792
Validation loss: 2.520530567243756

Epoch: 5| Step: 5
Training loss: 2.9337818070236827
Validation loss: 2.5076382105931705

Epoch: 5| Step: 6
Training loss: 2.6896769555834634
Validation loss: 2.5058088384716117

Epoch: 5| Step: 7
Training loss: 2.746061105113573
Validation loss: 2.482764473994912

Epoch: 5| Step: 8
Training loss: 2.338357851639004
Validation loss: 2.466931881950396

Epoch: 5| Step: 9
Training loss: 2.3659982243238606
Validation loss: 2.459085725456293

Epoch: 5| Step: 10
Training loss: 2.4078389655855092
Validation loss: 2.4592442977258346

Epoch: 194| Step: 0
Training loss: 2.8355300652677973
Validation loss: 2.4472813508162647

Epoch: 5| Step: 1
Training loss: 2.3924288457894685
Validation loss: 2.445249502494982

Epoch: 5| Step: 2
Training loss: 2.831801748513356
Validation loss: 2.4386380591282553

Epoch: 5| Step: 3
Training loss: 2.207093364550428
Validation loss: 2.44716584772563

Epoch: 5| Step: 4
Training loss: 2.104411976429646
Validation loss: 2.435898702098937

Epoch: 5| Step: 5
Training loss: 3.044008442209094
Validation loss: 2.4366513887222734

Epoch: 5| Step: 6
Training loss: 3.0302410216200437
Validation loss: 2.451655376986073

Epoch: 5| Step: 7
Training loss: 2.2149604349499237
Validation loss: 2.4493249790764304

Epoch: 5| Step: 8
Training loss: 2.302513001909523
Validation loss: 2.455500900413419

Epoch: 5| Step: 9
Training loss: 2.639558204184016
Validation loss: 2.457712522289685

Epoch: 5| Step: 10
Training loss: 2.8020670345546153
Validation loss: 2.477428958209906

Epoch: 195| Step: 0
Training loss: 2.796680464985226
Validation loss: 2.4918711626081587

Epoch: 5| Step: 1
Training loss: 2.741576993532829
Validation loss: 2.4988621450088693

Epoch: 5| Step: 2
Training loss: 2.238307879490914
Validation loss: 2.490378701525387

Epoch: 5| Step: 3
Training loss: 2.257970995768261
Validation loss: 2.4926706959781217

Epoch: 5| Step: 4
Training loss: 2.3884128483138083
Validation loss: 2.5040834753321692

Epoch: 5| Step: 5
Training loss: 2.8103932437434374
Validation loss: 2.471790101819951

Epoch: 5| Step: 6
Training loss: 1.9203231873304107
Validation loss: 2.4475097450688215

Epoch: 5| Step: 7
Training loss: 2.5112648846046075
Validation loss: 2.4366093763042427

Epoch: 5| Step: 8
Training loss: 2.957090268875194
Validation loss: 2.4287210592063135

Epoch: 5| Step: 9
Training loss: 3.0321447880478987
Validation loss: 2.425341092829265

Epoch: 5| Step: 10
Training loss: 2.517860698600817
Validation loss: 2.423854301443301

Epoch: 196| Step: 0
Training loss: 2.8598445652692384
Validation loss: 2.43422786141554

Epoch: 5| Step: 1
Training loss: 2.2892504930602957
Validation loss: 2.4517100287065667

Epoch: 5| Step: 2
Training loss: 3.3883397711902057
Validation loss: 2.455477848950776

Epoch: 5| Step: 3
Training loss: 2.3007035298975205
Validation loss: 2.4783744028666232

Epoch: 5| Step: 4
Training loss: 2.4376686233491096
Validation loss: 2.500094190484404

Epoch: 5| Step: 5
Training loss: 2.408716498212732
Validation loss: 2.4757225977999004

Epoch: 5| Step: 6
Training loss: 2.695059324896109
Validation loss: 2.4686484201077787

Epoch: 5| Step: 7
Training loss: 2.284844271238422
Validation loss: 2.466813401239854

Epoch: 5| Step: 8
Training loss: 2.207697350913662
Validation loss: 2.46016012330772

Epoch: 5| Step: 9
Training loss: 2.981987602428145
Validation loss: 2.4804303188962558

Epoch: 5| Step: 10
Training loss: 1.9916273937849014
Validation loss: 2.4606138184158515

Epoch: 197| Step: 0
Training loss: 2.8851191692102485
Validation loss: 2.455684920146936

Epoch: 5| Step: 1
Training loss: 2.122263548927408
Validation loss: 2.4533905038195787

Epoch: 5| Step: 2
Training loss: 2.8658435800570143
Validation loss: 2.4516388259482205

Epoch: 5| Step: 3
Training loss: 2.6082046533922623
Validation loss: 2.4555116926289746

Epoch: 5| Step: 4
Training loss: 2.4703342810773834
Validation loss: 2.467267364996754

Epoch: 5| Step: 5
Training loss: 2.241841891033373
Validation loss: 2.471780801593039

Epoch: 5| Step: 6
Training loss: 2.1514832148906713
Validation loss: 2.4862730206074173

Epoch: 5| Step: 7
Training loss: 2.875533676372126
Validation loss: 2.4770087093799105

Epoch: 5| Step: 8
Training loss: 2.7835761640080445
Validation loss: 2.4636307820162657

Epoch: 5| Step: 9
Training loss: 2.508005485358316
Validation loss: 2.4596965243711955

Epoch: 5| Step: 10
Training loss: 2.3664659464256066
Validation loss: 2.4557413195220157

Epoch: 198| Step: 0
Training loss: 2.8662947842293014
Validation loss: 2.450987533163228

Epoch: 5| Step: 1
Training loss: 2.578974173598087
Validation loss: 2.4513037762077454

Epoch: 5| Step: 2
Training loss: 2.9242516302022854
Validation loss: 2.4609562823804016

Epoch: 5| Step: 3
Training loss: 2.388271594566167
Validation loss: 2.4630502283781914

Epoch: 5| Step: 4
Training loss: 2.2386097292510505
Validation loss: 2.478151250134146

Epoch: 5| Step: 5
Training loss: 2.56215386262642
Validation loss: 2.494610969849689

Epoch: 5| Step: 6
Training loss: 2.507256371936847
Validation loss: 2.4702805841601454

Epoch: 5| Step: 7
Training loss: 2.3734982410566627
Validation loss: 2.4987222451799105

Epoch: 5| Step: 8
Training loss: 2.2416028047940273
Validation loss: 2.4937006989067654

Epoch: 5| Step: 9
Training loss: 2.475481152244878
Validation loss: 2.4996489062961915

Epoch: 5| Step: 10
Training loss: 2.5455890989968113
Validation loss: 2.519526972397021

Epoch: 199| Step: 0
Training loss: 2.211440281937306
Validation loss: 2.4804283448212234

Epoch: 5| Step: 1
Training loss: 2.7190429705036947
Validation loss: 2.4579114730995895

Epoch: 5| Step: 2
Training loss: 2.463831964423218
Validation loss: 2.4562311091548925

Epoch: 5| Step: 3
Training loss: 2.6349157427756773
Validation loss: 2.447755751145954

Epoch: 5| Step: 4
Training loss: 2.9693991503479142
Validation loss: 2.490666672793669

Epoch: 5| Step: 5
Training loss: 2.6942363857503344
Validation loss: 2.4802570035919937

Epoch: 5| Step: 6
Training loss: 2.20671859822242
Validation loss: 2.4970816960731543

Epoch: 5| Step: 7
Training loss: 2.709162766043011
Validation loss: 2.515926299474514

Epoch: 5| Step: 8
Training loss: 2.224910940038067
Validation loss: 2.5511076032362223

Epoch: 5| Step: 9
Training loss: 2.4093290173685964
Validation loss: 2.5208495483717632

Epoch: 5| Step: 10
Training loss: 2.2766465024301836
Validation loss: 2.498360305323447

Epoch: 200| Step: 0
Training loss: 2.3720637792918984
Validation loss: 2.4908121023162284

Epoch: 5| Step: 1
Training loss: 2.1128144656543024
Validation loss: 2.483254204950018

Epoch: 5| Step: 2
Training loss: 2.5876033522747672
Validation loss: 2.4543325987934184

Epoch: 5| Step: 3
Training loss: 2.6086646843537187
Validation loss: 2.459177347511148

Epoch: 5| Step: 4
Training loss: 2.548480317804479
Validation loss: 2.477466821210473

Epoch: 5| Step: 5
Training loss: 2.787555362168752
Validation loss: 2.461698258191467

Epoch: 5| Step: 6
Training loss: 2.5891565300045563
Validation loss: 2.481418283763463

Epoch: 5| Step: 7
Training loss: 2.875772621164639
Validation loss: 2.486952925156366

Epoch: 5| Step: 8
Training loss: 2.417811177531809
Validation loss: 2.510715469049264

Epoch: 5| Step: 9
Training loss: 2.6101970177315184
Validation loss: 2.516862283085579

Epoch: 5| Step: 10
Training loss: 1.7714237425668005
Validation loss: 2.5123204446220706

Epoch: 201| Step: 0
Training loss: 2.459870315948172
Validation loss: 2.4795856774928957

Epoch: 5| Step: 1
Training loss: 2.305482371699476
Validation loss: 2.4981272194481954

Epoch: 5| Step: 2
Training loss: 2.3597979640149784
Validation loss: 2.4822149681289085

Epoch: 5| Step: 3
Training loss: 2.3635246718966796
Validation loss: 2.502036193486654

Epoch: 5| Step: 4
Training loss: 2.616943803515478
Validation loss: 2.4805232175040866

Epoch: 5| Step: 5
Training loss: 2.149988453856227
Validation loss: 2.4888390315640385

Epoch: 5| Step: 6
Training loss: 2.437816599311996
Validation loss: 2.5035355926634333

Epoch: 5| Step: 7
Training loss: 2.5911693373848923
Validation loss: 2.5050499835566398

Epoch: 5| Step: 8
Training loss: 2.122389817180571
Validation loss: 2.516015193422505

Epoch: 5| Step: 9
Training loss: 2.585473701858228
Validation loss: 2.5130172866336347

Epoch: 5| Step: 10
Training loss: 3.2876676741508923
Validation loss: 2.5222117303795057

Epoch: 202| Step: 0
Training loss: 2.1025206923402084
Validation loss: 2.528680854988171

Epoch: 5| Step: 1
Training loss: 2.5900125808115697
Validation loss: 2.5381484993612764

Epoch: 5| Step: 2
Training loss: 2.100078299742957
Validation loss: 2.5223091498450305

Epoch: 5| Step: 3
Training loss: 2.421225380681273
Validation loss: 2.512576341517636

Epoch: 5| Step: 4
Training loss: 2.4278044932176064
Validation loss: 2.5074449096699474

Epoch: 5| Step: 5
Training loss: 2.072262633642398
Validation loss: 2.5149524834091306

Epoch: 5| Step: 6
Training loss: 2.623039149019476
Validation loss: 2.522524820860939

Epoch: 5| Step: 7
Training loss: 2.8429436850537013
Validation loss: 2.5131769015263106

Epoch: 5| Step: 8
Training loss: 2.5028203314483504
Validation loss: 2.509888392014195

Epoch: 5| Step: 9
Training loss: 2.4325849422980816
Validation loss: 2.531302103782215

Epoch: 5| Step: 10
Training loss: 3.038767508578339
Validation loss: 2.510497234407963

Epoch: 203| Step: 0
Training loss: 2.4227751012912377
Validation loss: 2.512660904504603

Epoch: 5| Step: 1
Training loss: 2.8989073174653077
Validation loss: 2.4860373123785333

Epoch: 5| Step: 2
Training loss: 2.720945852697732
Validation loss: 2.493527177100865

Epoch: 5| Step: 3
Training loss: 2.187795019691574
Validation loss: 2.4720639911404443

Epoch: 5| Step: 4
Training loss: 2.223313273044358
Validation loss: 2.477103827912028

Epoch: 5| Step: 5
Training loss: 2.4330332984762335
Validation loss: 2.474572950784778

Epoch: 5| Step: 6
Training loss: 2.575036343068062
Validation loss: 2.512178268530256

Epoch: 5| Step: 7
Training loss: 2.1481596056071135
Validation loss: 2.530866156546635

Epoch: 5| Step: 8
Training loss: 2.690148490154097
Validation loss: 2.5308922500017017

Epoch: 5| Step: 9
Training loss: 2.5985843692637975
Validation loss: 2.5374101521149877

Epoch: 5| Step: 10
Training loss: 2.2286421851044853
Validation loss: 2.524639302022272

Epoch: 204| Step: 0
Training loss: 2.2295584883921795
Validation loss: 2.517365754410466

Epoch: 5| Step: 1
Training loss: 2.8762080101054965
Validation loss: 2.506170247837211

Epoch: 5| Step: 2
Training loss: 2.3597839203207247
Validation loss: 2.4982586610471005

Epoch: 5| Step: 3
Training loss: 1.47001512299109
Validation loss: 2.51009432558352

Epoch: 5| Step: 4
Training loss: 2.0956441936757337
Validation loss: 2.507524643722939

Epoch: 5| Step: 5
Training loss: 2.7149190988307184
Validation loss: 2.5132214867725406

Epoch: 5| Step: 6
Training loss: 2.2962296805523637
Validation loss: 2.5148380245746327

Epoch: 5| Step: 7
Training loss: 2.401667802198443
Validation loss: 2.5341183291453278

Epoch: 5| Step: 8
Training loss: 2.8427313353009898
Validation loss: 2.5097432200614156

Epoch: 5| Step: 9
Training loss: 2.504797623581857
Validation loss: 2.503509750662556

Epoch: 5| Step: 10
Training loss: 3.0166118370960504
Validation loss: 2.4815829559217

Epoch: 205| Step: 0
Training loss: 2.096031312584853
Validation loss: 2.478361120048023

Epoch: 5| Step: 1
Training loss: 2.5366494317624273
Validation loss: 2.4590439597535916

Epoch: 5| Step: 2
Training loss: 2.5930299793633225
Validation loss: 2.4398026056714035

Epoch: 5| Step: 3
Training loss: 2.170268390775779
Validation loss: 2.450392580337178

Epoch: 5| Step: 4
Training loss: 2.667267155589156
Validation loss: 2.461632030825289

Epoch: 5| Step: 5
Training loss: 2.7633796672211335
Validation loss: 2.477798536991971

Epoch: 5| Step: 6
Training loss: 1.947208813113076
Validation loss: 2.496589647973652

Epoch: 5| Step: 7
Training loss: 2.4183167929667566
Validation loss: 2.511182142836552

Epoch: 5| Step: 8
Training loss: 2.594524038247938
Validation loss: 2.5260954847439407

Epoch: 5| Step: 9
Training loss: 2.6802803473663936
Validation loss: 2.504287157068604

Epoch: 5| Step: 10
Training loss: 2.417940056404113
Validation loss: 2.564331689610179

Epoch: 206| Step: 0
Training loss: 2.488563892834231
Validation loss: 2.5805540413561774

Epoch: 5| Step: 1
Training loss: 2.0300975171048012
Validation loss: 2.5689308653931997

Epoch: 5| Step: 2
Training loss: 2.437275215934887
Validation loss: 2.5298545127346643

Epoch: 5| Step: 3
Training loss: 2.575843309991777
Validation loss: 2.4905660135549574

Epoch: 5| Step: 4
Training loss: 2.435683135723217
Validation loss: 2.4677214966485943

Epoch: 5| Step: 5
Training loss: 2.534799888733158
Validation loss: 2.449328198638342

Epoch: 5| Step: 6
Training loss: 2.336488282454905
Validation loss: 2.4562030994728596

Epoch: 5| Step: 7
Training loss: 2.3715611708824946
Validation loss: 2.44016044218144

Epoch: 5| Step: 8
Training loss: 2.5250377010136953
Validation loss: 2.4499979984341405

Epoch: 5| Step: 9
Training loss: 2.7582823269402796
Validation loss: 2.47783670162983

Epoch: 5| Step: 10
Training loss: 2.583007074078344
Validation loss: 2.4944817892231494

Epoch: 207| Step: 0
Training loss: 2.50997318344685
Validation loss: 2.5383602360688586

Epoch: 5| Step: 1
Training loss: 2.4042233936971282
Validation loss: 2.5758331005672934

Epoch: 5| Step: 2
Training loss: 2.1318583048242545
Validation loss: 2.5649245092677098

Epoch: 5| Step: 3
Training loss: 2.6178953209998
Validation loss: 2.54954913756211

Epoch: 5| Step: 4
Training loss: 2.2123518554745933
Validation loss: 2.563441980053472

Epoch: 5| Step: 5
Training loss: 2.653323727051999
Validation loss: 2.4971166903797237

Epoch: 5| Step: 6
Training loss: 2.470205722844028
Validation loss: 2.4869859508612358

Epoch: 5| Step: 7
Training loss: 2.5756984504162763
Validation loss: 2.485305882093813

Epoch: 5| Step: 8
Training loss: 2.265858184390095
Validation loss: 2.49187542801527

Epoch: 5| Step: 9
Training loss: 2.5359925476229463
Validation loss: 2.4936892495250036

Epoch: 5| Step: 10
Training loss: 2.554074928498959
Validation loss: 2.498426900225491

Epoch: 208| Step: 0
Training loss: 2.44365433605689
Validation loss: 2.499835175033721

Epoch: 5| Step: 1
Training loss: 2.583177459280104
Validation loss: 2.4978025387254363

Epoch: 5| Step: 2
Training loss: 2.5791304043966643
Validation loss: 2.4962327136524585

Epoch: 5| Step: 3
Training loss: 3.267805475783936
Validation loss: 2.493577465966658

Epoch: 5| Step: 4
Training loss: 2.0773302437184333
Validation loss: 2.520644249397291

Epoch: 5| Step: 5
Training loss: 2.4273177485305757
Validation loss: 2.5327872891520826

Epoch: 5| Step: 6
Training loss: 2.1265710745028272
Validation loss: 2.532283432739843

Epoch: 5| Step: 7
Training loss: 2.474315791490012
Validation loss: 2.5126301242332714

Epoch: 5| Step: 8
Training loss: 2.015264316195183
Validation loss: 2.4815279176515603

Epoch: 5| Step: 9
Training loss: 2.5796702060316172
Validation loss: 2.465340700164496

Epoch: 5| Step: 10
Training loss: 2.1159357966758576
Validation loss: 2.4542176610213366

Epoch: 209| Step: 0
Training loss: 2.098395133993286
Validation loss: 2.450047626915586

Epoch: 5| Step: 1
Training loss: 2.9066030636516067
Validation loss: 2.4795373133035543

Epoch: 5| Step: 2
Training loss: 2.0883914072172316
Validation loss: 2.477172968862605

Epoch: 5| Step: 3
Training loss: 2.2263601110730598
Validation loss: 2.4970086485234986

Epoch: 5| Step: 4
Training loss: 2.3199098796441233
Validation loss: 2.5025865904768225

Epoch: 5| Step: 5
Training loss: 2.53689783402284
Validation loss: 2.5078043126927887

Epoch: 5| Step: 6
Training loss: 2.449920018505995
Validation loss: 2.4988825074494785

Epoch: 5| Step: 7
Training loss: 2.865859220328128
Validation loss: 2.5049690935828854

Epoch: 5| Step: 8
Training loss: 2.5518899234482046
Validation loss: 2.4995641072004893

Epoch: 5| Step: 9
Training loss: 2.6757108581639724
Validation loss: 2.4926133117532565

Epoch: 5| Step: 10
Training loss: 1.934045603966948
Validation loss: 2.4825882650061053

Epoch: 210| Step: 0
Training loss: 2.4109765732591013
Validation loss: 2.4887827878753623

Epoch: 5| Step: 1
Training loss: 2.349996254288955
Validation loss: 2.4912012477194976

Epoch: 5| Step: 2
Training loss: 2.677242308966525
Validation loss: 2.5334632674116784

Epoch: 5| Step: 3
Training loss: 2.5729860818948307
Validation loss: 2.5577102564825407

Epoch: 5| Step: 4
Training loss: 2.061473822346757
Validation loss: 2.534789003249247

Epoch: 5| Step: 5
Training loss: 2.1447503650227877
Validation loss: 2.5073152088095623

Epoch: 5| Step: 6
Training loss: 2.1165522787268887
Validation loss: 2.4773212995376093

Epoch: 5| Step: 7
Training loss: 2.2701681953665696
Validation loss: 2.4659914571182986

Epoch: 5| Step: 8
Training loss: 2.6020231555081397
Validation loss: 2.4654977845782082

Epoch: 5| Step: 9
Training loss: 2.8358398084391894
Validation loss: 2.462704671355037

Epoch: 5| Step: 10
Training loss: 2.5923649410429905
Validation loss: 2.4704743969090885

Epoch: 211| Step: 0
Training loss: 1.9497496468663156
Validation loss: 2.4750317402985114

Epoch: 5| Step: 1
Training loss: 2.3243983608055605
Validation loss: 2.5120527702128577

Epoch: 5| Step: 2
Training loss: 1.8848047756417916
Validation loss: 2.535705209667408

Epoch: 5| Step: 3
Training loss: 2.772837915216997
Validation loss: 2.592716110315982

Epoch: 5| Step: 4
Training loss: 2.646625810623315
Validation loss: 2.665453854863733

Epoch: 5| Step: 5
Training loss: 2.637934290127554
Validation loss: 2.655713274570696

Epoch: 5| Step: 6
Training loss: 2.145785605878193
Validation loss: 2.6023769698272154

Epoch: 5| Step: 7
Training loss: 2.718724042395839
Validation loss: 2.539211066027429

Epoch: 5| Step: 8
Training loss: 2.257638469179583
Validation loss: 2.510024059995638

Epoch: 5| Step: 9
Training loss: 2.4592274370724145
Validation loss: 2.4901960348981658

Epoch: 5| Step: 10
Training loss: 2.8700778123893995
Validation loss: 2.4853049650731105

Epoch: 212| Step: 0
Training loss: 2.686168251977096
Validation loss: 2.476567381813934

Epoch: 5| Step: 1
Training loss: 2.3364334855705002
Validation loss: 2.476264925125117

Epoch: 5| Step: 2
Training loss: 2.181761052727528
Validation loss: 2.4565804017639263

Epoch: 5| Step: 3
Training loss: 2.4614895640385823
Validation loss: 2.4697963687687983

Epoch: 5| Step: 4
Training loss: 2.5170877125506252
Validation loss: 2.4888851672917234

Epoch: 5| Step: 5
Training loss: 2.355712574347871
Validation loss: 2.5434380734244892

Epoch: 5| Step: 6
Training loss: 2.2097151649544093
Validation loss: 2.625232716492966

Epoch: 5| Step: 7
Training loss: 2.5208228770477925
Validation loss: 2.6461531917549124

Epoch: 5| Step: 8
Training loss: 2.4421683380878636
Validation loss: 2.648332500878012

Epoch: 5| Step: 9
Training loss: 2.4449436287339568
Validation loss: 2.555008683566464

Epoch: 5| Step: 10
Training loss: 2.8311075743162912
Validation loss: 2.4836044607697403

Epoch: 213| Step: 0
Training loss: 2.6263586796928924
Validation loss: 2.449328622540034

Epoch: 5| Step: 1
Training loss: 2.2948763708919535
Validation loss: 2.4415478558563435

Epoch: 5| Step: 2
Training loss: 2.840787245478314
Validation loss: 2.4449308731148425

Epoch: 5| Step: 3
Training loss: 1.945506442410075
Validation loss: 2.441798657980201

Epoch: 5| Step: 4
Training loss: 2.1610244744506724
Validation loss: 2.431799145716558

Epoch: 5| Step: 5
Training loss: 2.5495215397171944
Validation loss: 2.477692640933501

Epoch: 5| Step: 6
Training loss: 2.180048211990736
Validation loss: 2.541108105504197

Epoch: 5| Step: 7
Training loss: 2.8004337451673047
Validation loss: 2.642601862000149

Epoch: 5| Step: 8
Training loss: 2.466818234795934
Validation loss: 2.7065097099449753

Epoch: 5| Step: 9
Training loss: 2.5384158205926117
Validation loss: 2.6937538313873506

Epoch: 5| Step: 10
Training loss: 2.791784758466125
Validation loss: 2.614287492322188

Epoch: 214| Step: 0
Training loss: 2.6021171642961916
Validation loss: 2.5499572463194426

Epoch: 5| Step: 1
Training loss: 2.0949833212395683
Validation loss: 2.488547268946361

Epoch: 5| Step: 2
Training loss: 2.332749657062329
Validation loss: 2.4600672508596224

Epoch: 5| Step: 3
Training loss: 1.9096288284430183
Validation loss: 2.4534794682164143

Epoch: 5| Step: 4
Training loss: 2.703606446891195
Validation loss: 2.448044933832631

Epoch: 5| Step: 5
Training loss: 2.484866111725274
Validation loss: 2.4467515272788587

Epoch: 5| Step: 6
Training loss: 2.5576277212280694
Validation loss: 2.445187380914209

Epoch: 5| Step: 7
Training loss: 2.6926339371006365
Validation loss: 2.453579870078247

Epoch: 5| Step: 8
Training loss: 2.422407916103213
Validation loss: 2.471639025584527

Epoch: 5| Step: 9
Training loss: 2.590700309956422
Validation loss: 2.480629655177823

Epoch: 5| Step: 10
Training loss: 2.3745257255428185
Validation loss: 2.481423728380123

Epoch: 215| Step: 0
Training loss: 2.5926057060858683
Validation loss: 2.4733372566827314

Epoch: 5| Step: 1
Training loss: 2.403455325119943
Validation loss: 2.4921442440153427

Epoch: 5| Step: 2
Training loss: 2.2095310873661855
Validation loss: 2.4980746443613686

Epoch: 5| Step: 3
Training loss: 2.1072499060975294
Validation loss: 2.4971512920247627

Epoch: 5| Step: 4
Training loss: 2.703139112138018
Validation loss: 2.5009282050231585

Epoch: 5| Step: 5
Training loss: 2.2562496491746287
Validation loss: 2.504524767213807

Epoch: 5| Step: 6
Training loss: 2.3124579348475622
Validation loss: 2.5068480253110934

Epoch: 5| Step: 7
Training loss: 2.5526143566074273
Validation loss: 2.5304422936956725

Epoch: 5| Step: 8
Training loss: 2.7088440829187577
Validation loss: 2.56118854805617

Epoch: 5| Step: 9
Training loss: 2.1740876048948268
Validation loss: 2.559536609768233

Epoch: 5| Step: 10
Training loss: 2.326977133198815
Validation loss: 2.544533880647505

Epoch: 216| Step: 0
Training loss: 2.053868816001228
Validation loss: 2.562798394398247

Epoch: 5| Step: 1
Training loss: 2.6054089952562642
Validation loss: 2.562820518571307

Epoch: 5| Step: 2
Training loss: 2.4045572643445627
Validation loss: 2.580944733030195

Epoch: 5| Step: 3
Training loss: 2.16377283905158
Validation loss: 2.5629821641861295

Epoch: 5| Step: 4
Training loss: 2.53324623041824
Validation loss: 2.5441366029637313

Epoch: 5| Step: 5
Training loss: 2.5040176533451515
Validation loss: 2.544254254349151

Epoch: 5| Step: 6
Training loss: 2.1607329717951806
Validation loss: 2.5402183386970125

Epoch: 5| Step: 7
Training loss: 2.7681978833406737
Validation loss: 2.5405598834148617

Epoch: 5| Step: 8
Training loss: 2.110331678671945
Validation loss: 2.571508305031759

Epoch: 5| Step: 9
Training loss: 2.371152471729613
Validation loss: 2.5556948766908243

Epoch: 5| Step: 10
Training loss: 2.465817315128129
Validation loss: 2.5271139034517454

Epoch: 217| Step: 0
Training loss: 2.7791635638157244
Validation loss: 2.513939801237685

Epoch: 5| Step: 1
Training loss: 2.3758163053164836
Validation loss: 2.4817074466301965

Epoch: 5| Step: 2
Training loss: 2.2464348840808914
Validation loss: 2.4911366742902703

Epoch: 5| Step: 3
Training loss: 2.494249979249148
Validation loss: 2.49625749205164

Epoch: 5| Step: 4
Training loss: 2.128042735387726
Validation loss: 2.527798746618454

Epoch: 5| Step: 5
Training loss: 1.6827403868628896
Validation loss: 2.557050422196626

Epoch: 5| Step: 6
Training loss: 2.8575496996998813
Validation loss: 2.576484137622839

Epoch: 5| Step: 7
Training loss: 2.2027943680940103
Validation loss: 2.5483330054271427

Epoch: 5| Step: 8
Training loss: 2.2591408382652727
Validation loss: 2.4840288736968064

Epoch: 5| Step: 9
Training loss: 2.6212960405358463
Validation loss: 2.461333209138179

Epoch: 5| Step: 10
Training loss: 2.497947804243926
Validation loss: 2.4480803013246883

Epoch: 218| Step: 0
Training loss: 2.7911418782129234
Validation loss: 2.452672624702153

Epoch: 5| Step: 1
Training loss: 2.039061915371983
Validation loss: 2.447305267230016

Epoch: 5| Step: 2
Training loss: 2.1419641246124335
Validation loss: 2.443174499309627

Epoch: 5| Step: 3
Training loss: 2.2151835616540922
Validation loss: 2.46102228521582

Epoch: 5| Step: 4
Training loss: 2.199679229933221
Validation loss: 2.4517098922487035

Epoch: 5| Step: 5
Training loss: 2.5184272654006272
Validation loss: 2.495793235418766

Epoch: 5| Step: 6
Training loss: 2.304174954593186
Validation loss: 2.5412222966175535

Epoch: 5| Step: 7
Training loss: 2.745577463858266
Validation loss: 2.5548290318723157

Epoch: 5| Step: 8
Training loss: 2.177944238241401
Validation loss: 2.5383883016738773

Epoch: 5| Step: 9
Training loss: 2.8192961068638196
Validation loss: 2.5302197785374205

Epoch: 5| Step: 10
Training loss: 1.9773700858554923
Validation loss: 2.4792588953483756

Epoch: 219| Step: 0
Training loss: 2.309486074705854
Validation loss: 2.4670181149870207

Epoch: 5| Step: 1
Training loss: 1.9231555053354439
Validation loss: 2.4648452893214907

Epoch: 5| Step: 2
Training loss: 2.1949621172092897
Validation loss: 2.4445543274586377

Epoch: 5| Step: 3
Training loss: 2.715592139849692
Validation loss: 2.4588544356546227

Epoch: 5| Step: 4
Training loss: 1.6246956760371731
Validation loss: 2.4785268290014266

Epoch: 5| Step: 5
Training loss: 2.7151050908384513
Validation loss: 2.4670771763024417

Epoch: 5| Step: 6
Training loss: 2.4612197956268056
Validation loss: 2.4909249156633337

Epoch: 5| Step: 7
Training loss: 2.27638457368146
Validation loss: 2.49212111898596

Epoch: 5| Step: 8
Training loss: 2.5986916221091083
Validation loss: 2.543155759124986

Epoch: 5| Step: 9
Training loss: 2.7801797071869565
Validation loss: 2.4970880561908615

Epoch: 5| Step: 10
Training loss: 1.9870715105256038
Validation loss: 2.5044537598472223

Epoch: 220| Step: 0
Training loss: 2.360924117468845
Validation loss: 2.5156336051555783

Epoch: 5| Step: 1
Training loss: 2.077982503264768
Validation loss: 2.5112892319098785

Epoch: 5| Step: 2
Training loss: 2.3678777210908875
Validation loss: 2.5125836082509494

Epoch: 5| Step: 3
Training loss: 1.8496261966508358
Validation loss: 2.4922363500712628

Epoch: 5| Step: 4
Training loss: 2.3025869333628557
Validation loss: 2.4896616930906665

Epoch: 5| Step: 5
Training loss: 2.308266243722851
Validation loss: 2.497594587803066

Epoch: 5| Step: 6
Training loss: 2.704333702144114
Validation loss: 2.4748154203552493

Epoch: 5| Step: 7
Training loss: 2.369458811652912
Validation loss: 2.4867869385258308

Epoch: 5| Step: 8
Training loss: 2.7524093996913908
Validation loss: 2.4797860203749758

Epoch: 5| Step: 9
Training loss: 2.4278846258438005
Validation loss: 2.5017926321221977

Epoch: 5| Step: 10
Training loss: 1.8928738924915143
Validation loss: 2.522392056134914

Epoch: 221| Step: 0
Training loss: 1.842426406860601
Validation loss: 2.5038020376712566

Epoch: 5| Step: 1
Training loss: 2.7376110873044097
Validation loss: 2.4843032959682283

Epoch: 5| Step: 2
Training loss: 1.9488139678263465
Validation loss: 2.483769467939127

Epoch: 5| Step: 3
Training loss: 1.8199243745706837
Validation loss: 2.478185253825228

Epoch: 5| Step: 4
Training loss: 2.418980794930517
Validation loss: 2.4842196799274934

Epoch: 5| Step: 5
Training loss: 2.52232898657977
Validation loss: 2.489284052713107

Epoch: 5| Step: 6
Training loss: 2.6269664664798293
Validation loss: 2.4968911673602663

Epoch: 5| Step: 7
Training loss: 2.0633555862919453
Validation loss: 2.5226154761934545

Epoch: 5| Step: 8
Training loss: 2.5607034852111172
Validation loss: 2.520516997011409

Epoch: 5| Step: 9
Training loss: 2.4353591124622325
Validation loss: 2.5161242918519937

Epoch: 5| Step: 10
Training loss: 2.4357113266452672
Validation loss: 2.513001590642123

Epoch: 222| Step: 0
Training loss: 1.5800615269716916
Validation loss: 2.508314981237743

Epoch: 5| Step: 1
Training loss: 2.6437423633798818
Validation loss: 2.487276733993249

Epoch: 5| Step: 2
Training loss: 2.4564118931345593
Validation loss: 2.4911462099568236

Epoch: 5| Step: 3
Training loss: 1.9507743422844634
Validation loss: 2.4830580425055166

Epoch: 5| Step: 4
Training loss: 2.4982116024533076
Validation loss: 2.480792313926713

Epoch: 5| Step: 5
Training loss: 2.2890835393257727
Validation loss: 2.4945919506604533

Epoch: 5| Step: 6
Training loss: 2.414890085724224
Validation loss: 2.485138199903108

Epoch: 5| Step: 7
Training loss: 1.8220056346299511
Validation loss: 2.4759705408207084

Epoch: 5| Step: 8
Training loss: 2.644799718935952
Validation loss: 2.461920207322332

Epoch: 5| Step: 9
Training loss: 2.6414906363898036
Validation loss: 2.474037068813657

Epoch: 5| Step: 10
Training loss: 2.1470804263341456
Validation loss: 2.4627327340908156

Epoch: 223| Step: 0
Training loss: 2.5096199913668435
Validation loss: 2.45582003115366

Epoch: 5| Step: 1
Training loss: 1.8926434421979867
Validation loss: 2.4508250730934833

Epoch: 5| Step: 2
Training loss: 1.8055765183364882
Validation loss: 2.428717431272421

Epoch: 5| Step: 3
Training loss: 2.4116914333011192
Validation loss: 2.4398113773783865

Epoch: 5| Step: 4
Training loss: 2.346144406803572
Validation loss: 2.4491638019375594

Epoch: 5| Step: 5
Training loss: 2.8403674119041242
Validation loss: 2.4867067792298005

Epoch: 5| Step: 6
Training loss: 1.8200337601768803
Validation loss: 2.505675414151764

Epoch: 5| Step: 7
Training loss: 2.488555940949315
Validation loss: 2.5261079786904306

Epoch: 5| Step: 8
Training loss: 2.4574603023019796
Validation loss: 2.543066949953377

Epoch: 5| Step: 9
Training loss: 2.093773571280273
Validation loss: 2.538697452728512

Epoch: 5| Step: 10
Training loss: 2.3156862732146144
Validation loss: 2.497211536796146

Epoch: 224| Step: 0
Training loss: 2.4882539421271845
Validation loss: 2.507199339950948

Epoch: 5| Step: 1
Training loss: 2.4948041327582486
Validation loss: 2.502285038674468

Epoch: 5| Step: 2
Training loss: 2.3287112118843147
Validation loss: 2.5158629312861702

Epoch: 5| Step: 3
Training loss: 2.0984010421983035
Validation loss: 2.5255088126582392

Epoch: 5| Step: 4
Training loss: 1.8349515174676712
Validation loss: 2.5226278705058958

Epoch: 5| Step: 5
Training loss: 2.452991263273335
Validation loss: 2.52672767944183

Epoch: 5| Step: 6
Training loss: 2.1444854453498587
Validation loss: 2.481544411904986

Epoch: 5| Step: 7
Training loss: 2.063914998492476
Validation loss: 2.485021578120507

Epoch: 5| Step: 8
Training loss: 2.608464978910703
Validation loss: 2.4390062847889205

Epoch: 5| Step: 9
Training loss: 1.941901959200497
Validation loss: 2.4328193834269483

Epoch: 5| Step: 10
Training loss: 2.3537720093429932
Validation loss: 2.4403228001673436

Epoch: 225| Step: 0
Training loss: 1.8766699665688773
Validation loss: 2.4304946335884052

Epoch: 5| Step: 1
Training loss: 1.8958754971465142
Validation loss: 2.429294838942645

Epoch: 5| Step: 2
Training loss: 2.23726461866673
Validation loss: 2.427238675566255

Epoch: 5| Step: 3
Training loss: 1.9897655649929193
Validation loss: 2.4394256982506466

Epoch: 5| Step: 4
Training loss: 2.3021562544606726
Validation loss: 2.435504363538192

Epoch: 5| Step: 5
Training loss: 2.0963169134079966
Validation loss: 2.46703779358962

Epoch: 5| Step: 6
Training loss: 2.879617880001904
Validation loss: 2.473810585847535

Epoch: 5| Step: 7
Training loss: 2.152005870073672
Validation loss: 2.4766838365165373

Epoch: 5| Step: 8
Training loss: 2.21268957155668
Validation loss: 2.509119997821658

Epoch: 5| Step: 9
Training loss: 2.3151770895996866
Validation loss: 2.573112513884435

Epoch: 5| Step: 10
Training loss: 2.894434218125228
Validation loss: 2.611800547713552

Epoch: 226| Step: 0
Training loss: 2.012878202358935
Validation loss: 2.5709032824192

Epoch: 5| Step: 1
Training loss: 2.3785829120753177
Validation loss: 2.5045477490569974

Epoch: 5| Step: 2
Training loss: 2.2171493989387265
Validation loss: 2.467390237103164

Epoch: 5| Step: 3
Training loss: 1.9750658483030525
Validation loss: 2.4362621166826783

Epoch: 5| Step: 4
Training loss: 2.7127406035564547
Validation loss: 2.439585136482334

Epoch: 5| Step: 5
Training loss: 2.460188881980807
Validation loss: 2.44326660890879

Epoch: 5| Step: 6
Training loss: 1.5307999552889964
Validation loss: 2.4419804526789477

Epoch: 5| Step: 7
Training loss: 2.4077775738539073
Validation loss: 2.473220225632096

Epoch: 5| Step: 8
Training loss: 2.3979938109113603
Validation loss: 2.495877883247563

Epoch: 5| Step: 9
Training loss: 2.2207963130458603
Validation loss: 2.502637542409517

Epoch: 5| Step: 10
Training loss: 2.6687210831873442
Validation loss: 2.5054347032550344

Epoch: 227| Step: 0
Training loss: 2.257499277108416
Validation loss: 2.5276083263076807

Epoch: 5| Step: 1
Training loss: 1.7337553274764517
Validation loss: 2.510434926018995

Epoch: 5| Step: 2
Training loss: 2.5237463416667723
Validation loss: 2.5026499496150674

Epoch: 5| Step: 3
Training loss: 2.0642385380285693
Validation loss: 2.476255361141197

Epoch: 5| Step: 4
Training loss: 1.8989817777083806
Validation loss: 2.4618844180204786

Epoch: 5| Step: 5
Training loss: 2.764094042126328
Validation loss: 2.458525899523578

Epoch: 5| Step: 6
Training loss: 1.9326435875691788
Validation loss: 2.4694348080313544

Epoch: 5| Step: 7
Training loss: 2.1784126080907784
Validation loss: 2.4827581009335624

Epoch: 5| Step: 8
Training loss: 2.3631390993857417
Validation loss: 2.494622756186455

Epoch: 5| Step: 9
Training loss: 2.647744057044368
Validation loss: 2.510478401948288

Epoch: 5| Step: 10
Training loss: 2.3181579039525047
Validation loss: 2.5344318994732866

Epoch: 228| Step: 0
Training loss: 2.408836955790852
Validation loss: 2.5110533134279707

Epoch: 5| Step: 1
Training loss: 1.7885338947687899
Validation loss: 2.5050870289416793

Epoch: 5| Step: 2
Training loss: 2.4745876007206
Validation loss: 2.5032412406254014

Epoch: 5| Step: 3
Training loss: 2.2410188081455082
Validation loss: 2.472930948412986

Epoch: 5| Step: 4
Training loss: 2.1845256747995987
Validation loss: 2.45471134471468

Epoch: 5| Step: 5
Training loss: 2.2068335520553086
Validation loss: 2.436519000488545

Epoch: 5| Step: 6
Training loss: 2.267860519870093
Validation loss: 2.412388937066963

Epoch: 5| Step: 7
Training loss: 2.452946941935592
Validation loss: 2.423752493702707

Epoch: 5| Step: 8
Training loss: 2.263863240300189
Validation loss: 2.385260413540907

Epoch: 5| Step: 9
Training loss: 2.0284706467744216
Validation loss: 2.3844515000564868

Epoch: 5| Step: 10
Training loss: 2.2252357143744543
Validation loss: 2.4040991454418266

Epoch: 229| Step: 0
Training loss: 2.079395909435009
Validation loss: 2.3935419161467273

Epoch: 5| Step: 1
Training loss: 2.530321209838244
Validation loss: 2.4129029751577855

Epoch: 5| Step: 2
Training loss: 2.1998408303335246
Validation loss: 2.4421393976473738

Epoch: 5| Step: 3
Training loss: 2.2298284837597
Validation loss: 2.4954150528261385

Epoch: 5| Step: 4
Training loss: 1.8160624517129713
Validation loss: 2.5221403417318378

Epoch: 5| Step: 5
Training loss: 2.574444727609738
Validation loss: 2.521263538067015

Epoch: 5| Step: 6
Training loss: 1.95772395561664
Validation loss: 2.482126208947017

Epoch: 5| Step: 7
Training loss: 2.1133610116287307
Validation loss: 2.447326945893761

Epoch: 5| Step: 8
Training loss: 2.2255182327075573
Validation loss: 2.4267072354966213

Epoch: 5| Step: 9
Training loss: 2.5717564385156364
Validation loss: 2.426774695916178

Epoch: 5| Step: 10
Training loss: 2.4008188758034334
Validation loss: 2.4547269481587524

Epoch: 230| Step: 0
Training loss: 1.7656653745643036
Validation loss: 2.4507800263718127

Epoch: 5| Step: 1
Training loss: 2.3164617264844534
Validation loss: 2.49284956234306

Epoch: 5| Step: 2
Training loss: 2.323581845507801
Validation loss: 2.4950320823142764

Epoch: 5| Step: 3
Training loss: 1.7785381621523273
Validation loss: 2.4910366741725993

Epoch: 5| Step: 4
Training loss: 2.4325305459279556
Validation loss: 2.4743952011274555

Epoch: 5| Step: 5
Training loss: 2.4105416210848594
Validation loss: 2.435753240882603

Epoch: 5| Step: 6
Training loss: 2.3067018143873836
Validation loss: 2.414148595904572

Epoch: 5| Step: 7
Training loss: 2.1687592036247096
Validation loss: 2.4512136869807306

Epoch: 5| Step: 8
Training loss: 2.2893351630083405
Validation loss: 2.440294574272417

Epoch: 5| Step: 9
Training loss: 2.2107507202188676
Validation loss: 2.4548777091547156

Epoch: 5| Step: 10
Training loss: 2.1696783799588677
Validation loss: 2.4763838496310755

Epoch: 231| Step: 0
Training loss: 2.6973782349433666
Validation loss: 2.461805235894738

Epoch: 5| Step: 1
Training loss: 2.3307470111412454
Validation loss: 2.484725187591553

Epoch: 5| Step: 2
Training loss: 2.166526961101835
Validation loss: 2.4569433042543074

Epoch: 5| Step: 3
Training loss: 2.2227088104094026
Validation loss: 2.449859520143352

Epoch: 5| Step: 4
Training loss: 1.6528352768385786
Validation loss: 2.438142835286527

Epoch: 5| Step: 5
Training loss: 1.773233948171738
Validation loss: 2.432030172947213

Epoch: 5| Step: 6
Training loss: 2.333893152473323
Validation loss: 2.4374672356636604

Epoch: 5| Step: 7
Training loss: 2.422191771433488
Validation loss: 2.4373876095069376

Epoch: 5| Step: 8
Training loss: 2.0493311232755747
Validation loss: 2.4506797352364194

Epoch: 5| Step: 9
Training loss: 2.107539303595245
Validation loss: 2.4799373807834693

Epoch: 5| Step: 10
Training loss: 2.3598349419756333
Validation loss: 2.4979411620297753

Epoch: 232| Step: 0
Training loss: 2.2248940088979694
Validation loss: 2.5164597760033565

Epoch: 5| Step: 1
Training loss: 1.9555973731552525
Validation loss: 2.4833099854153486

Epoch: 5| Step: 2
Training loss: 1.7429883681372609
Validation loss: 2.446799190016714

Epoch: 5| Step: 3
Training loss: 2.3237979283553494
Validation loss: 2.4449508857235647

Epoch: 5| Step: 4
Training loss: 1.9130570865654088
Validation loss: 2.456646546168051

Epoch: 5| Step: 5
Training loss: 1.9808538239344302
Validation loss: 2.4495552256959963

Epoch: 5| Step: 6
Training loss: 2.377251310930042
Validation loss: 2.4402038600781304

Epoch: 5| Step: 7
Training loss: 2.3125422705833647
Validation loss: 2.4183041926688693

Epoch: 5| Step: 8
Training loss: 2.505921027836653
Validation loss: 2.40662941979728

Epoch: 5| Step: 9
Training loss: 2.6655532380044917
Validation loss: 2.4061291593315444

Epoch: 5| Step: 10
Training loss: 1.9035480924702928
Validation loss: 2.404914210310764

Epoch: 233| Step: 0
Training loss: 1.5774911041734396
Validation loss: 2.4546005256069363

Epoch: 5| Step: 1
Training loss: 2.1755777534367233
Validation loss: 2.4692498746333404

Epoch: 5| Step: 2
Training loss: 2.079658114872697
Validation loss: 2.480386971567799

Epoch: 5| Step: 3
Training loss: 1.9132043277079809
Validation loss: 2.4480128897503786

Epoch: 5| Step: 4
Training loss: 2.1918792486136023
Validation loss: 2.424934915807361

Epoch: 5| Step: 5
Training loss: 2.145507923624542
Validation loss: 2.4094469588324228

Epoch: 5| Step: 6
Training loss: 2.4868781956385857
Validation loss: 2.398463154039277

Epoch: 5| Step: 7
Training loss: 2.6234245113666983
Validation loss: 2.3891029056554327

Epoch: 5| Step: 8
Training loss: 2.3439031932356453
Validation loss: 2.371792339662746

Epoch: 5| Step: 9
Training loss: 2.23625999913291
Validation loss: 2.4271678407242847

Epoch: 5| Step: 10
Training loss: 2.3754692617911517
Validation loss: 2.4877233114276964

Epoch: 234| Step: 0
Training loss: 1.99621730952049
Validation loss: 2.5542086650214766

Epoch: 5| Step: 1
Training loss: 2.906876527256422
Validation loss: 2.567554825639555

Epoch: 5| Step: 2
Training loss: 2.078895827435354
Validation loss: 2.4357513032215095

Epoch: 5| Step: 3
Training loss: 2.1068103033705783
Validation loss: 2.3898881160861074

Epoch: 5| Step: 4
Training loss: 2.013631145017278
Validation loss: 2.3871248388261983

Epoch: 5| Step: 5
Training loss: 2.4181407072336523
Validation loss: 2.3929455228069596

Epoch: 5| Step: 6
Training loss: 2.5884723513333
Validation loss: 2.4015855672080777

Epoch: 5| Step: 7
Training loss: 2.518331173892287
Validation loss: 2.3797277124768024

Epoch: 5| Step: 8
Training loss: 2.270192350396832
Validation loss: 2.370135830770654

Epoch: 5| Step: 9
Training loss: 1.6430290410638069
Validation loss: 2.4689424522053245

Epoch: 5| Step: 10
Training loss: 2.3746817526162314
Validation loss: 2.597780192475662

Epoch: 235| Step: 0
Training loss: 2.277996303444828
Validation loss: 2.6568320344244296

Epoch: 5| Step: 1
Training loss: 2.3657977868778213
Validation loss: 2.6628607228322014

Epoch: 5| Step: 2
Training loss: 3.029278458146386
Validation loss: 2.618970470020655

Epoch: 5| Step: 3
Training loss: 2.2517343830097762
Validation loss: 2.4406271564350748

Epoch: 5| Step: 4
Training loss: 1.9774227758054908
Validation loss: 2.371803203637886

Epoch: 5| Step: 5
Training loss: 3.000864381242
Validation loss: 2.3852563487029173

Epoch: 5| Step: 6
Training loss: 2.5308067027794707
Validation loss: 2.4296658791973282

Epoch: 5| Step: 7
Training loss: 2.333884469292218
Validation loss: 2.4183685525122836

Epoch: 5| Step: 8
Training loss: 2.346960488297656
Validation loss: 2.4046915678555867

Epoch: 5| Step: 9
Training loss: 1.6816505493863654
Validation loss: 2.3948285617971283

Epoch: 5| Step: 10
Training loss: 1.5304314118563054
Validation loss: 2.398938317155919

Epoch: 236| Step: 0
Training loss: 2.1146611417038375
Validation loss: 2.416330663882177

Epoch: 5| Step: 1
Training loss: 2.0249272462938523
Validation loss: 2.435197560504515

Epoch: 5| Step: 2
Training loss: 2.4549038991357075
Validation loss: 2.4612519877944306

Epoch: 5| Step: 3
Training loss: 2.198715125192827
Validation loss: 2.4836574185505054

Epoch: 5| Step: 4
Training loss: 2.0656619254778
Validation loss: 2.4963687571468056

Epoch: 5| Step: 5
Training loss: 2.4047203651646174
Validation loss: 2.468123089887064

Epoch: 5| Step: 6
Training loss: 2.209478429291491
Validation loss: 2.4344263388904777

Epoch: 5| Step: 7
Training loss: 1.8260005768590144
Validation loss: 2.3986951481117553

Epoch: 5| Step: 8
Training loss: 2.3835294051536127
Validation loss: 2.3800464457583903

Epoch: 5| Step: 9
Training loss: 2.749913127567393
Validation loss: 2.3607305240106533

Epoch: 5| Step: 10
Training loss: 1.7156434160644236
Validation loss: 2.3722624434567705

Epoch: 237| Step: 0
Training loss: 2.302704763181636
Validation loss: 2.3857285533506363

Epoch: 5| Step: 1
Training loss: 2.0751433817031693
Validation loss: 2.416660189664122

Epoch: 5| Step: 2
Training loss: 1.987736895376367
Validation loss: 2.4495174995550832

Epoch: 5| Step: 3
Training loss: 2.0662004047402633
Validation loss: 2.4489340335617085

Epoch: 5| Step: 4
Training loss: 2.119430873700191
Validation loss: 2.4259967081767395

Epoch: 5| Step: 5
Training loss: 2.5426294243953493
Validation loss: 2.4076331171720855

Epoch: 5| Step: 6
Training loss: 2.2118540235712065
Validation loss: 2.410759929002001

Epoch: 5| Step: 7
Training loss: 2.3264385490114843
Validation loss: 2.4080041426703156

Epoch: 5| Step: 8
Training loss: 1.998477177229784
Validation loss: 2.3902649473935833

Epoch: 5| Step: 9
Training loss: 2.4009623704064307
Validation loss: 2.388039586785781

Epoch: 5| Step: 10
Training loss: 1.8178962093055855
Validation loss: 2.3635345119883477

Epoch: 238| Step: 0
Training loss: 1.8198481282597236
Validation loss: 2.3714209230490004

Epoch: 5| Step: 1
Training loss: 2.814908246972411
Validation loss: 2.3789809615825637

Epoch: 5| Step: 2
Training loss: 2.3472187059766125
Validation loss: 2.391722235717051

Epoch: 5| Step: 3
Training loss: 2.1502434925326375
Validation loss: 2.375136008305476

Epoch: 5| Step: 4
Training loss: 2.0308573416677524
Validation loss: 2.393244917979965

Epoch: 5| Step: 5
Training loss: 2.470186226191343
Validation loss: 2.4007978909276235

Epoch: 5| Step: 6
Training loss: 1.452604631342038
Validation loss: 2.377827916129279

Epoch: 5| Step: 7
Training loss: 2.098904087574144
Validation loss: 2.3909116183504584

Epoch: 5| Step: 8
Training loss: 2.433511649961941
Validation loss: 2.399987720813581

Epoch: 5| Step: 9
Training loss: 1.702873351377938
Validation loss: 2.4105672909442832

Epoch: 5| Step: 10
Training loss: 2.000719656214041
Validation loss: 2.440130832848735

Epoch: 239| Step: 0
Training loss: 2.1924869911912745
Validation loss: 2.4824315355375193

Epoch: 5| Step: 1
Training loss: 2.2776860655435787
Validation loss: 2.5364834549078368

Epoch: 5| Step: 2
Training loss: 2.391154909930281
Validation loss: 2.5341879716871687

Epoch: 5| Step: 3
Training loss: 1.9649654525165934
Validation loss: 2.5015391667223414

Epoch: 5| Step: 4
Training loss: 2.0200107381554147
Validation loss: 2.430954959904765

Epoch: 5| Step: 5
Training loss: 2.09735969137826
Validation loss: 2.4061085308216743

Epoch: 5| Step: 6
Training loss: 1.8216019021702394
Validation loss: 2.3782378185977566

Epoch: 5| Step: 7
Training loss: 1.7562966825858217
Validation loss: 2.3852122777619473

Epoch: 5| Step: 8
Training loss: 2.5525417824369545
Validation loss: 2.3882942829961733

Epoch: 5| Step: 9
Training loss: 2.0722286929363896
Validation loss: 2.390356863942691

Epoch: 5| Step: 10
Training loss: 2.663695726848683
Validation loss: 2.4092082178102405

Epoch: 240| Step: 0
Training loss: 1.8223226687548002
Validation loss: 2.39575596096375

Epoch: 5| Step: 1
Training loss: 2.1760717228891973
Validation loss: 2.4203809529994627

Epoch: 5| Step: 2
Training loss: 1.7369139362156285
Validation loss: 2.4266229627992617

Epoch: 5| Step: 3
Training loss: 2.1411120006944575
Validation loss: 2.4486758861090396

Epoch: 5| Step: 4
Training loss: 2.460111739869562
Validation loss: 2.484278799763785

Epoch: 5| Step: 5
Training loss: 2.3295131359692043
Validation loss: 2.4914538838726323

Epoch: 5| Step: 6
Training loss: 1.831191726642716
Validation loss: 2.4617540095195833

Epoch: 5| Step: 7
Training loss: 2.736271489365261
Validation loss: 2.4351302255143166

Epoch: 5| Step: 8
Training loss: 1.8702783898578998
Validation loss: 2.4131211470036344

Epoch: 5| Step: 9
Training loss: 2.10605874933677
Validation loss: 2.401706348280463

Epoch: 5| Step: 10
Training loss: 2.1174785793981967
Validation loss: 2.379769365266394

Epoch: 241| Step: 0
Training loss: 1.775110136564203
Validation loss: 2.380809612579035

Epoch: 5| Step: 1
Training loss: 2.3288043778234524
Validation loss: 2.3854991036855706

Epoch: 5| Step: 2
Training loss: 2.2552854129813253
Validation loss: 2.3900314292277693

Epoch: 5| Step: 3
Training loss: 2.317122298884079
Validation loss: 2.403867229252538

Epoch: 5| Step: 4
Training loss: 2.0930534456722385
Validation loss: 2.4178202654716765

Epoch: 5| Step: 5
Training loss: 2.3255801020663016
Validation loss: 2.4132441148898587

Epoch: 5| Step: 6
Training loss: 2.1639218060861682
Validation loss: 2.430660562976605

Epoch: 5| Step: 7
Training loss: 2.1628745223292127
Validation loss: 2.4368872281150273

Epoch: 5| Step: 8
Training loss: 1.826027604386418
Validation loss: 2.4857427632341165

Epoch: 5| Step: 9
Training loss: 1.8870990125134333
Validation loss: 2.455095193753833

Epoch: 5| Step: 10
Training loss: 2.121130056052943
Validation loss: 2.4582757611117887

Epoch: 242| Step: 0
Training loss: 2.6070658808652363
Validation loss: 2.4221267108927993

Epoch: 5| Step: 1
Training loss: 2.344498985142243
Validation loss: 2.404761762024772

Epoch: 5| Step: 2
Training loss: 1.8858798039546394
Validation loss: 2.412614211062671

Epoch: 5| Step: 3
Training loss: 2.0796480262501
Validation loss: 2.410659201199337

Epoch: 5| Step: 4
Training loss: 2.1920089029006036
Validation loss: 2.407899336853973

Epoch: 5| Step: 5
Training loss: 1.9412803071770253
Validation loss: 2.4184858994455722

Epoch: 5| Step: 6
Training loss: 2.2450754527642798
Validation loss: 2.4397994271282064

Epoch: 5| Step: 7
Training loss: 1.8899230915144667
Validation loss: 2.4389220844073716

Epoch: 5| Step: 8
Training loss: 1.917578694445863
Validation loss: 2.4156192674566035

Epoch: 5| Step: 9
Training loss: 1.8245608154054935
Validation loss: 2.4201756247589405

Epoch: 5| Step: 10
Training loss: 1.9640284035332214
Validation loss: 2.4007976987184687

Epoch: 243| Step: 0
Training loss: 1.9622323066223806
Validation loss: 2.4103055406382436

Epoch: 5| Step: 1
Training loss: 1.5980074993048288
Validation loss: 2.4122859041807807

Epoch: 5| Step: 2
Training loss: 2.0096377377465564
Validation loss: 2.3979661371524514

Epoch: 5| Step: 3
Training loss: 1.896350419787196
Validation loss: 2.420839999008667

Epoch: 5| Step: 4
Training loss: 2.391247038851877
Validation loss: 2.428467430140288

Epoch: 5| Step: 5
Training loss: 2.794963076625687
Validation loss: 2.4501193336863896

Epoch: 5| Step: 6
Training loss: 1.9795113380533311
Validation loss: 2.4340801775699767

Epoch: 5| Step: 7
Training loss: 2.4287231101423945
Validation loss: 2.4155121063713847

Epoch: 5| Step: 8
Training loss: 1.6098299587088136
Validation loss: 2.3903562161569245

Epoch: 5| Step: 9
Training loss: 1.9890745487732209
Validation loss: 2.378645049493933

Epoch: 5| Step: 10
Training loss: 2.009011945659541
Validation loss: 2.3832674164810035

Epoch: 244| Step: 0
Training loss: 1.6677422470212204
Validation loss: 2.3629737881126447

Epoch: 5| Step: 1
Training loss: 2.1617002298204895
Validation loss: 2.3522410344735123

Epoch: 5| Step: 2
Training loss: 2.3039523746482296
Validation loss: 2.3511338084908613

Epoch: 5| Step: 3
Training loss: 2.182867649394752
Validation loss: 2.3462154336532826

Epoch: 5| Step: 4
Training loss: 2.0655894404826194
Validation loss: 2.3775258452286288

Epoch: 5| Step: 5
Training loss: 2.5413881889332384
Validation loss: 2.3738349427377186

Epoch: 5| Step: 6
Training loss: 1.5540957450877673
Validation loss: 2.393935635361962

Epoch: 5| Step: 7
Training loss: 1.9236156365639359
Validation loss: 2.3857686184864426

Epoch: 5| Step: 8
Training loss: 2.1977706667844297
Validation loss: 2.383277289080635

Epoch: 5| Step: 9
Training loss: 2.1851704863983645
Validation loss: 2.3944232377454777

Epoch: 5| Step: 10
Training loss: 1.9208891906670866
Validation loss: 2.385402280860214

Epoch: 245| Step: 0
Training loss: 1.567739627901762
Validation loss: 2.4156002493018587

Epoch: 5| Step: 1
Training loss: 2.136378175697067
Validation loss: 2.3838315552136247

Epoch: 5| Step: 2
Training loss: 2.481499405248426
Validation loss: 2.3729405760014064

Epoch: 5| Step: 3
Training loss: 2.1557102357067404
Validation loss: 2.378344395540478

Epoch: 5| Step: 4
Training loss: 1.5992255303444594
Validation loss: 2.3746447402711426

Epoch: 5| Step: 5
Training loss: 1.5077600025268367
Validation loss: 2.3849657496510472

Epoch: 5| Step: 6
Training loss: 2.34489006289068
Validation loss: 2.4010629102892547

Epoch: 5| Step: 7
Training loss: 1.9156877118497877
Validation loss: 2.408585548400885

Epoch: 5| Step: 8
Training loss: 1.6282590316693
Validation loss: 2.444581136660259

Epoch: 5| Step: 9
Training loss: 2.3440688869977704
Validation loss: 2.4803949961518352

Epoch: 5| Step: 10
Training loss: 3.0029001522937784
Validation loss: 2.5187441444191503

Epoch: 246| Step: 0
Training loss: 2.220670057334056
Validation loss: 2.457790386406425

Epoch: 5| Step: 1
Training loss: 2.303272291258822
Validation loss: 2.3938801610346165

Epoch: 5| Step: 2
Training loss: 2.341604242363864
Validation loss: 2.3741163046465568

Epoch: 5| Step: 3
Training loss: 2.186992913463608
Validation loss: 2.3985480944103164

Epoch: 5| Step: 4
Training loss: 2.104543280811037
Validation loss: 2.3815798100128385

Epoch: 5| Step: 5
Training loss: 1.888031686335096
Validation loss: 2.4061173273402545

Epoch: 5| Step: 6
Training loss: 1.7247471997323605
Validation loss: 2.402389223668984

Epoch: 5| Step: 7
Training loss: 2.1092141549280568
Validation loss: 2.4166422426505103

Epoch: 5| Step: 8
Training loss: 1.7438318677709697
Validation loss: 2.433845647748427

Epoch: 5| Step: 9
Training loss: 1.8964696661617424
Validation loss: 2.440578906774058

Epoch: 5| Step: 10
Training loss: 2.095660007456316
Validation loss: 2.4609858713704122

Epoch: 247| Step: 0
Training loss: 2.242639901380604
Validation loss: 2.4668159733870874

Epoch: 5| Step: 1
Training loss: 2.1043458113247775
Validation loss: 2.426485455843105

Epoch: 5| Step: 2
Training loss: 1.8719523775286997
Validation loss: 2.4025591759276885

Epoch: 5| Step: 3
Training loss: 2.1780859966972814
Validation loss: 2.4041228377621224

Epoch: 5| Step: 4
Training loss: 2.1062248160557417
Validation loss: 2.368862328942476

Epoch: 5| Step: 5
Training loss: 1.9306592463663375
Validation loss: 2.367934753527083

Epoch: 5| Step: 6
Training loss: 1.4267178738100166
Validation loss: 2.3757009211337863

Epoch: 5| Step: 7
Training loss: 2.3433914927631045
Validation loss: 2.3828584206317123

Epoch: 5| Step: 8
Training loss: 2.210618713904911
Validation loss: 2.3867960161228257

Epoch: 5| Step: 9
Training loss: 2.3690385788642137
Validation loss: 2.389945025531523

Epoch: 5| Step: 10
Training loss: 1.6453064022693866
Validation loss: 2.407373939074148

Epoch: 248| Step: 0
Training loss: 1.9637337008066333
Validation loss: 2.410387166500967

Epoch: 5| Step: 1
Training loss: 2.0521760974449332
Validation loss: 2.4181229885447486

Epoch: 5| Step: 2
Training loss: 2.239366304985965
Validation loss: 2.4353077235049834

Epoch: 5| Step: 3
Training loss: 1.6453021274685284
Validation loss: 2.4111602920790247

Epoch: 5| Step: 4
Training loss: 2.1227409472256196
Validation loss: 2.3695256358512795

Epoch: 5| Step: 5
Training loss: 1.8758685325642743
Validation loss: 2.332785858216901

Epoch: 5| Step: 6
Training loss: 2.0913061426519315
Validation loss: 2.3325396219144303

Epoch: 5| Step: 7
Training loss: 2.3653568453467773
Validation loss: 2.324102174726145

Epoch: 5| Step: 8
Training loss: 2.0082836266324535
Validation loss: 2.3368991737019473

Epoch: 5| Step: 9
Training loss: 1.851325361944631
Validation loss: 2.3571946282426426

Epoch: 5| Step: 10
Training loss: 2.323385342472376
Validation loss: 2.3735002554620976

Epoch: 249| Step: 0
Training loss: 1.9116891899988149
Validation loss: 2.4115697368590574

Epoch: 5| Step: 1
Training loss: 1.9050197070646828
Validation loss: 2.4760464734004013

Epoch: 5| Step: 2
Training loss: 2.5485621755708148
Validation loss: 2.489386023268958

Epoch: 5| Step: 3
Training loss: 1.9450541251920879
Validation loss: 2.4789396474884304

Epoch: 5| Step: 4
Training loss: 1.4711785225694995
Validation loss: 2.4449218765099223

Epoch: 5| Step: 5
Training loss: 2.2597434686548863
Validation loss: 2.4250086295267477

Epoch: 5| Step: 6
Training loss: 2.4131680408622027
Validation loss: 2.3901736150809416

Epoch: 5| Step: 7
Training loss: 1.808944503354661
Validation loss: 2.3832841701873977

Epoch: 5| Step: 8
Training loss: 2.113819441599341
Validation loss: 2.369597420793748

Epoch: 5| Step: 9
Training loss: 1.8859811292656905
Validation loss: 2.3806164021181497

Epoch: 5| Step: 10
Training loss: 1.9352540565510299
Validation loss: 2.376317491581154

Epoch: 250| Step: 0
Training loss: 1.8229381959642905
Validation loss: 2.3725261260506674

Epoch: 5| Step: 1
Training loss: 2.1399199723939986
Validation loss: 2.388519353879394

Epoch: 5| Step: 2
Training loss: 2.1811620175343736
Validation loss: 2.3753292468637244

Epoch: 5| Step: 3
Training loss: 2.3905568829973376
Validation loss: 2.413235133477679

Epoch: 5| Step: 4
Training loss: 1.8530257354447894
Validation loss: 2.4168411947870774

Epoch: 5| Step: 5
Training loss: 2.036215596151353
Validation loss: 2.405674830886519

Epoch: 5| Step: 6
Training loss: 2.252617267430895
Validation loss: 2.431491628972054

Epoch: 5| Step: 7
Training loss: 1.5973276859055183
Validation loss: 2.4256753389623085

Epoch: 5| Step: 8
Training loss: 2.024848122258282
Validation loss: 2.417849615753302

Epoch: 5| Step: 9
Training loss: 1.8079009407849989
Validation loss: 2.4038397014963593

Epoch: 5| Step: 10
Training loss: 2.1555944358404187
Validation loss: 2.404747435088243

Epoch: 251| Step: 0
Training loss: 1.990076060638657
Validation loss: 2.381750659451716

Epoch: 5| Step: 1
Training loss: 1.3792870187636816
Validation loss: 2.383667796226571

Epoch: 5| Step: 2
Training loss: 2.26079101509771
Validation loss: 2.3851082020195364

Epoch: 5| Step: 3
Training loss: 2.122560110150856
Validation loss: 2.4166725471207218

Epoch: 5| Step: 4
Training loss: 2.0620317794615284
Validation loss: 2.43157598175063

Epoch: 5| Step: 5
Training loss: 1.6571241986699443
Validation loss: 2.4551621895018503

Epoch: 5| Step: 6
Training loss: 2.4076717189500085
Validation loss: 2.4432169381714455

Epoch: 5| Step: 7
Training loss: 1.9072816902315017
Validation loss: 2.446213374748649

Epoch: 5| Step: 8
Training loss: 2.35224392671842
Validation loss: 2.4110980013938352

Epoch: 5| Step: 9
Training loss: 1.8103946428382356
Validation loss: 2.441525795124271

Epoch: 5| Step: 10
Training loss: 1.9770758041490373
Validation loss: 2.446653193885212

Epoch: 252| Step: 0
Training loss: 1.9551473904438446
Validation loss: 2.4396372749515596

Epoch: 5| Step: 1
Training loss: 2.384306992427142
Validation loss: 2.4282666513023834

Epoch: 5| Step: 2
Training loss: 2.402116470130409
Validation loss: 2.4527254643382816

Epoch: 5| Step: 3
Training loss: 1.9031889054416387
Validation loss: 2.4094946913241353

Epoch: 5| Step: 4
Training loss: 1.6336856679355554
Validation loss: 2.409466227713231

Epoch: 5| Step: 5
Training loss: 2.0169564514451888
Validation loss: 2.379230359656952

Epoch: 5| Step: 6
Training loss: 1.8676724622111032
Validation loss: 2.3783825747977176

Epoch: 5| Step: 7
Training loss: 1.823104681582474
Validation loss: 2.3846374226244436

Epoch: 5| Step: 8
Training loss: 1.674918497294706
Validation loss: 2.369088075608906

Epoch: 5| Step: 9
Training loss: 2.110899423838918
Validation loss: 2.3878402925308095

Epoch: 5| Step: 10
Training loss: 2.176271996208919
Validation loss: 2.4006657990323985

Epoch: 253| Step: 0
Training loss: 1.743664991706263
Validation loss: 2.3946712052649892

Epoch: 5| Step: 1
Training loss: 1.580584281134444
Validation loss: 2.382698088342955

Epoch: 5| Step: 2
Training loss: 1.7218389323865433
Validation loss: 2.383733765022822

Epoch: 5| Step: 3
Training loss: 2.3888887570501876
Validation loss: 2.3832408738511255

Epoch: 5| Step: 4
Training loss: 1.9370381204677578
Validation loss: 2.388360124541123

Epoch: 5| Step: 5
Training loss: 2.0396523042835963
Validation loss: 2.3769431312210667

Epoch: 5| Step: 6
Training loss: 1.940256250210921
Validation loss: 2.4028601392145332

Epoch: 5| Step: 7
Training loss: 2.162594293732569
Validation loss: 2.393001448931041

Epoch: 5| Step: 8
Training loss: 1.8548034117551502
Validation loss: 2.398943041680934

Epoch: 5| Step: 9
Training loss: 2.164345622908419
Validation loss: 2.4380446867460464

Epoch: 5| Step: 10
Training loss: 2.2546124335447066
Validation loss: 2.407431069843182

Epoch: 254| Step: 0
Training loss: 2.0913332755774134
Validation loss: 2.391479980579115

Epoch: 5| Step: 1
Training loss: 2.2890296907644987
Validation loss: 2.3695758954387207

Epoch: 5| Step: 2
Training loss: 1.9696576887050827
Validation loss: 2.388192399935267

Epoch: 5| Step: 3
Training loss: 2.0999300263872263
Validation loss: 2.4128201514269594

Epoch: 5| Step: 4
Training loss: 2.179689468875119
Validation loss: 2.4368130978396065

Epoch: 5| Step: 5
Training loss: 1.804993442512922
Validation loss: 2.432099544351213

Epoch: 5| Step: 6
Training loss: 2.0931466215331977
Validation loss: 2.423540384429833

Epoch: 5| Step: 7
Training loss: 2.267930640026271
Validation loss: 2.413615041546477

Epoch: 5| Step: 8
Training loss: 1.6603344630909136
Validation loss: 2.410695395802855

Epoch: 5| Step: 9
Training loss: 1.5906340113536335
Validation loss: 2.406730366320814

Epoch: 5| Step: 10
Training loss: 1.6828078982716215
Validation loss: 2.415299355164819

Epoch: 255| Step: 0
Training loss: 2.1573701243467873
Validation loss: 2.43671042225257

Epoch: 5| Step: 1
Training loss: 1.4915718286439552
Validation loss: 2.3885605174137297

Epoch: 5| Step: 2
Training loss: 1.9029831957172856
Validation loss: 2.367343639280665

Epoch: 5| Step: 3
Training loss: 1.9298327927969037
Validation loss: 2.3604320724339787

Epoch: 5| Step: 4
Training loss: 1.9299591738083837
Validation loss: 2.359385783157204

Epoch: 5| Step: 5
Training loss: 1.545963365513085
Validation loss: 2.3517916426732133

Epoch: 5| Step: 6
Training loss: 1.746942164677267
Validation loss: 2.3810734780817424

Epoch: 5| Step: 7
Training loss: 2.3215729343674307
Validation loss: 2.4106323805784595

Epoch: 5| Step: 8
Training loss: 2.457203578515531
Validation loss: 2.420201786684358

Epoch: 5| Step: 9
Training loss: 1.6519894772487729
Validation loss: 2.454778089851908

Epoch: 5| Step: 10
Training loss: 2.5152274818758436
Validation loss: 2.447409993459234

Epoch: 256| Step: 0
Training loss: 1.7829724065428736
Validation loss: 2.428103484000627

Epoch: 5| Step: 1
Training loss: 1.9985315773468444
Validation loss: 2.4152346906315336

Epoch: 5| Step: 2
Training loss: 1.9888847349550898
Validation loss: 2.3978100722555062

Epoch: 5| Step: 3
Training loss: 1.9169839789845906
Validation loss: 2.408156477250129

Epoch: 5| Step: 4
Training loss: 2.067224582100202
Validation loss: 2.4271137317153553

Epoch: 5| Step: 5
Training loss: 2.3217357034088
Validation loss: 2.4280594786008702

Epoch: 5| Step: 6
Training loss: 2.2126289071499574
Validation loss: 2.4412847809794087

Epoch: 5| Step: 7
Training loss: 1.817130323906199
Validation loss: 2.4154862614051136

Epoch: 5| Step: 8
Training loss: 1.9319463320163062
Validation loss: 2.3896443522330078

Epoch: 5| Step: 9
Training loss: 1.523958400779335
Validation loss: 2.413008755688731

Epoch: 5| Step: 10
Training loss: 1.7662351111171242
Validation loss: 2.4059996254253337

Epoch: 257| Step: 0
Training loss: 2.1415762910686906
Validation loss: 2.423247659616021

Epoch: 5| Step: 1
Training loss: 2.1074188204116533
Validation loss: 2.419608987291193

Epoch: 5| Step: 2
Training loss: 1.3513200134432628
Validation loss: 2.407091996780018

Epoch: 5| Step: 3
Training loss: 2.308059966314885
Validation loss: 2.4090464514847074

Epoch: 5| Step: 4
Training loss: 1.8008367236151226
Validation loss: 2.36644595908138

Epoch: 5| Step: 5
Training loss: 1.7351071298818261
Validation loss: 2.363517728923752

Epoch: 5| Step: 6
Training loss: 1.6519676844689744
Validation loss: 2.378991371381867

Epoch: 5| Step: 7
Training loss: 1.9356408582363553
Validation loss: 2.405473232945528

Epoch: 5| Step: 8
Training loss: 2.0929334955781185
Validation loss: 2.4250227188874613

Epoch: 5| Step: 9
Training loss: 2.2783439625192354
Validation loss: 2.479289548094382

Epoch: 5| Step: 10
Training loss: 1.8594266740045857
Validation loss: 2.5054084633595632

Epoch: 258| Step: 0
Training loss: 1.7663706327522986
Validation loss: 2.5112234252453955

Epoch: 5| Step: 1
Training loss: 2.039303469395692
Validation loss: 2.4765790335345064

Epoch: 5| Step: 2
Training loss: 2.018482755090783
Validation loss: 2.4466045087588255

Epoch: 5| Step: 3
Training loss: 1.8651026494512608
Validation loss: 2.4270984118065098

Epoch: 5| Step: 4
Training loss: 1.3621525505187386
Validation loss: 2.3806203370381698

Epoch: 5| Step: 5
Training loss: 2.3959258904753598
Validation loss: 2.3509017020808254

Epoch: 5| Step: 6
Training loss: 1.7799695415248271
Validation loss: 2.355226600632261

Epoch: 5| Step: 7
Training loss: 2.507830848507886
Validation loss: 2.3454646357070295

Epoch: 5| Step: 8
Training loss: 1.799710234524762
Validation loss: 2.3581686126807244

Epoch: 5| Step: 9
Training loss: 1.3306608338052988
Validation loss: 2.4055345172330447

Epoch: 5| Step: 10
Training loss: 2.1793324171040824
Validation loss: 2.448577072996791

Epoch: 259| Step: 0
Training loss: 1.8310111974001915
Validation loss: 2.4485018140544175

Epoch: 5| Step: 1
Training loss: 1.9396231308844665
Validation loss: 2.4311930654116307

Epoch: 5| Step: 2
Training loss: 2.1244153733217432
Validation loss: 2.4008333778130053

Epoch: 5| Step: 3
Training loss: 1.508876681947154
Validation loss: 2.365293047644423

Epoch: 5| Step: 4
Training loss: 1.8904848913816361
Validation loss: 2.370865591595927

Epoch: 5| Step: 5
Training loss: 1.7214109456619022
Validation loss: 2.371418306890182

Epoch: 5| Step: 6
Training loss: 1.9103960694090505
Validation loss: 2.403630976414991

Epoch: 5| Step: 7
Training loss: 2.013046034194179
Validation loss: 2.4148552316431107

Epoch: 5| Step: 8
Training loss: 2.04744671706851
Validation loss: 2.4178272370043077

Epoch: 5| Step: 9
Training loss: 1.8830478885130217
Validation loss: 2.3936962088977056

Epoch: 5| Step: 10
Training loss: 2.3400000518407573
Validation loss: 2.3705652452113974

Epoch: 260| Step: 0
Training loss: 1.670217244757052
Validation loss: 2.3776448035895372

Epoch: 5| Step: 1
Training loss: 1.6332558208030774
Validation loss: 2.3585541205864238

Epoch: 5| Step: 2
Training loss: 1.953709385230689
Validation loss: 2.369553382105633

Epoch: 5| Step: 3
Training loss: 1.5986565254330944
Validation loss: 2.3737587731995484

Epoch: 5| Step: 4
Training loss: 1.813719109259673
Validation loss: 2.386072613417115

Epoch: 5| Step: 5
Training loss: 1.7275681824760953
Validation loss: 2.3938783174548393

Epoch: 5| Step: 6
Training loss: 2.095712339980032
Validation loss: 2.4191665890990772

Epoch: 5| Step: 7
Training loss: 2.505896100483509
Validation loss: 2.4340775608243814

Epoch: 5| Step: 8
Training loss: 2.104970105065389
Validation loss: 2.44939433897505

Epoch: 5| Step: 9
Training loss: 1.5962294197398803
Validation loss: 2.410475054931635

Epoch: 5| Step: 10
Training loss: 2.186574903787997
Validation loss: 2.397447814831977

Epoch: 261| Step: 0
Training loss: 1.8895321043809572
Validation loss: 2.39101453762008

Epoch: 5| Step: 1
Training loss: 1.6814758716296105
Validation loss: 2.3709658636755804

Epoch: 5| Step: 2
Training loss: 2.1445092372077204
Validation loss: 2.3804959822361056

Epoch: 5| Step: 3
Training loss: 2.2863888277396187
Validation loss: 2.381733221685093

Epoch: 5| Step: 4
Training loss: 2.355584744306573
Validation loss: 2.3923195673396296

Epoch: 5| Step: 5
Training loss: 1.5221162984630159
Validation loss: 2.416870117817307

Epoch: 5| Step: 6
Training loss: 1.9159091060477578
Validation loss: 2.447581075278489

Epoch: 5| Step: 7
Training loss: 1.7965530107014989
Validation loss: 2.450139035533806

Epoch: 5| Step: 8
Training loss: 2.058752180514081
Validation loss: 2.438689023640538

Epoch: 5| Step: 9
Training loss: 1.5908665471766963
Validation loss: 2.464727379712332

Epoch: 5| Step: 10
Training loss: 1.410916828667334
Validation loss: 2.4445272757071796

Epoch: 262| Step: 0
Training loss: 1.8755639817489003
Validation loss: 2.432275969713395

Epoch: 5| Step: 1
Training loss: 1.9904979048418232
Validation loss: 2.379498006302866

Epoch: 5| Step: 2
Training loss: 1.9094233754924106
Validation loss: 2.3846716470785263

Epoch: 5| Step: 3
Training loss: 1.2965778791793974
Validation loss: 2.386735491295056

Epoch: 5| Step: 4
Training loss: 2.588776197241055
Validation loss: 2.3741848577074602

Epoch: 5| Step: 5
Training loss: 2.1502334024467107
Validation loss: 2.360622720154816

Epoch: 5| Step: 6
Training loss: 1.540963020925665
Validation loss: 2.356494658179202

Epoch: 5| Step: 7
Training loss: 2.136669876683403
Validation loss: 2.3852296433404128

Epoch: 5| Step: 8
Training loss: 1.4186057769470606
Validation loss: 2.39896293139106

Epoch: 5| Step: 9
Training loss: 1.614517366435811
Validation loss: 2.3723338435465493

Epoch: 5| Step: 10
Training loss: 1.7747274404452258
Validation loss: 2.3949798697441436

Epoch: 263| Step: 0
Training loss: 1.6206616664612146
Validation loss: 2.3747073912403187

Epoch: 5| Step: 1
Training loss: 1.9672640687859013
Validation loss: 2.3993149333816675

Epoch: 5| Step: 2
Training loss: 1.8974876382296926
Validation loss: 2.4111658304867274

Epoch: 5| Step: 3
Training loss: 1.8430274582099144
Validation loss: 2.4437127293797167

Epoch: 5| Step: 4
Training loss: 1.3735755564595942
Validation loss: 2.4066379225369356

Epoch: 5| Step: 5
Training loss: 1.287394884133171
Validation loss: 2.4260070610076525

Epoch: 5| Step: 6
Training loss: 2.364193171326928
Validation loss: 2.4126102603176065

Epoch: 5| Step: 7
Training loss: 1.9489438889452615
Validation loss: 2.3966647944868864

Epoch: 5| Step: 8
Training loss: 1.9337425714114622
Validation loss: 2.3739208604344726

Epoch: 5| Step: 9
Training loss: 2.1312852918102423
Validation loss: 2.405740349137451

Epoch: 5| Step: 10
Training loss: 2.0385727568295655
Validation loss: 2.3870454149810154

Epoch: 264| Step: 0
Training loss: 1.9443543307298015
Validation loss: 2.406827135342218

Epoch: 5| Step: 1
Training loss: 1.6199286628840333
Validation loss: 2.439726889019987

Epoch: 5| Step: 2
Training loss: 1.5997537959930552
Validation loss: 2.431715707863061

Epoch: 5| Step: 3
Training loss: 2.12781898662258
Validation loss: 2.4132624122426365

Epoch: 5| Step: 4
Training loss: 1.7281315780983528
Validation loss: 2.4037596898332643

Epoch: 5| Step: 5
Training loss: 2.004441455658862
Validation loss: 2.37375431390813

Epoch: 5| Step: 6
Training loss: 2.141816079336949
Validation loss: 2.366361856012161

Epoch: 5| Step: 7
Training loss: 1.8576751119185644
Validation loss: 2.391812352379724

Epoch: 5| Step: 8
Training loss: 2.048537881982771
Validation loss: 2.3644432037914043

Epoch: 5| Step: 9
Training loss: 1.7213405852904988
Validation loss: 2.379820501377167

Epoch: 5| Step: 10
Training loss: 1.449370918613624
Validation loss: 2.400264608287596

Epoch: 265| Step: 0
Training loss: 1.758033975847906
Validation loss: 2.415502574072317

Epoch: 5| Step: 1
Training loss: 1.6124347377847925
Validation loss: 2.422329869261183

Epoch: 5| Step: 2
Training loss: 2.0592026217244612
Validation loss: 2.426750051075365

Epoch: 5| Step: 3
Training loss: 1.5999341176297277
Validation loss: 2.427706233743331

Epoch: 5| Step: 4
Training loss: 1.995498717840744
Validation loss: 2.3823277091071247

Epoch: 5| Step: 5
Training loss: 2.1834768083134355
Validation loss: 2.4201834475199426

Epoch: 5| Step: 6
Training loss: 1.4448042517207669
Validation loss: 2.374331670635678

Epoch: 5| Step: 7
Training loss: 1.2142069334231507
Validation loss: 2.379194041960031

Epoch: 5| Step: 8
Training loss: 1.83016430174552
Validation loss: 2.3964828110240894

Epoch: 5| Step: 9
Training loss: 2.1302684100819125
Validation loss: 2.3718621953107113

Epoch: 5| Step: 10
Training loss: 2.2919474574219647
Validation loss: 2.36584826706913

Epoch: 266| Step: 0
Training loss: 1.8311311181965064
Validation loss: 2.4059958119263585

Epoch: 5| Step: 1
Training loss: 1.5321942746010504
Validation loss: 2.416374832484372

Epoch: 5| Step: 2
Training loss: 1.6879275451450224
Validation loss: 2.4237575469333486

Epoch: 5| Step: 3
Training loss: 1.6542444141991774
Validation loss: 2.419361097232011

Epoch: 5| Step: 4
Training loss: 1.5880501492218315
Validation loss: 2.410366250037343

Epoch: 5| Step: 5
Training loss: 2.194245645985321
Validation loss: 2.412220793272236

Epoch: 5| Step: 6
Training loss: 2.0715528695157
Validation loss: 2.3722134171261544

Epoch: 5| Step: 7
Training loss: 2.2016441833634106
Validation loss: 2.3785554689308754

Epoch: 5| Step: 8
Training loss: 1.9323204703296324
Validation loss: 2.383990566009602

Epoch: 5| Step: 9
Training loss: 1.8721393379456546
Validation loss: 2.3598553133926528

Epoch: 5| Step: 10
Training loss: 1.5136467519336478
Validation loss: 2.3592707233275596

Epoch: 267| Step: 0
Training loss: 1.8598289897198068
Validation loss: 2.3775436691445893

Epoch: 5| Step: 1
Training loss: 2.1024456224882533
Validation loss: 2.3868603265683337

Epoch: 5| Step: 2
Training loss: 1.8538709969108573
Validation loss: 2.3750963628678705

Epoch: 5| Step: 3
Training loss: 1.5339090265157798
Validation loss: 2.3635648530977504

Epoch: 5| Step: 4
Training loss: 1.7750970410966433
Validation loss: 2.359501627274625

Epoch: 5| Step: 5
Training loss: 2.012642598283181
Validation loss: 2.3650969761971297

Epoch: 5| Step: 6
Training loss: 1.814730619926933
Validation loss: 2.349615383637469

Epoch: 5| Step: 7
Training loss: 1.971013780953099
Validation loss: 2.3616253256911626

Epoch: 5| Step: 8
Training loss: 1.7088957845341775
Validation loss: 2.38348539155478

Epoch: 5| Step: 9
Training loss: 1.9774458648949376
Validation loss: 2.3746874894564907

Epoch: 5| Step: 10
Training loss: 1.554879794856386
Validation loss: 2.3679613735348934

Epoch: 268| Step: 0
Training loss: 1.3163282784482206
Validation loss: 2.3978269643763697

Epoch: 5| Step: 1
Training loss: 1.847937016194089
Validation loss: 2.4095993905128594

Epoch: 5| Step: 2
Training loss: 2.067731522462918
Validation loss: 2.417924606273083

Epoch: 5| Step: 3
Training loss: 1.8044162562918953
Validation loss: 2.424405931550292

Epoch: 5| Step: 4
Training loss: 2.0123401459890373
Validation loss: 2.4279778149201743

Epoch: 5| Step: 5
Training loss: 1.674237444938349
Validation loss: 2.400142334063833

Epoch: 5| Step: 6
Training loss: 1.796737665650236
Validation loss: 2.4032612033579097

Epoch: 5| Step: 7
Training loss: 1.6779374342792739
Validation loss: 2.3975737625346185

Epoch: 5| Step: 8
Training loss: 2.1750052967226274
Validation loss: 2.408538242809689

Epoch: 5| Step: 9
Training loss: 1.9715076086142742
Validation loss: 2.3906069733494117

Epoch: 5| Step: 10
Training loss: 1.7522916775031705
Validation loss: 2.3958558108723036

Epoch: 269| Step: 0
Training loss: 1.611950045699029
Validation loss: 2.376963279438795

Epoch: 5| Step: 1
Training loss: 1.7143455250841997
Validation loss: 2.3821988035487114

Epoch: 5| Step: 2
Training loss: 1.890257555351803
Validation loss: 2.4409868822447334

Epoch: 5| Step: 3
Training loss: 1.8131730375662176
Validation loss: 2.423296811876262

Epoch: 5| Step: 4
Training loss: 1.857229004161392
Validation loss: 2.4307314869327086

Epoch: 5| Step: 5
Training loss: 1.6581164226173533
Validation loss: 2.39625839236465

Epoch: 5| Step: 6
Training loss: 2.0604927236664112
Validation loss: 2.3823901149900597

Epoch: 5| Step: 7
Training loss: 1.402689856532143
Validation loss: 2.364356384907544

Epoch: 5| Step: 8
Training loss: 2.201047093291001
Validation loss: 2.359105150763282

Epoch: 5| Step: 9
Training loss: 1.633128450479815
Validation loss: 2.3845408798179184

Epoch: 5| Step: 10
Training loss: 2.1025989344993756
Validation loss: 2.373971270486582

Epoch: 270| Step: 0
Training loss: 1.604787417442536
Validation loss: 2.3522818876821803

Epoch: 5| Step: 1
Training loss: 1.674390736128965
Validation loss: 2.380866351389919

Epoch: 5| Step: 2
Training loss: 2.210271081135912
Validation loss: 2.3816394529528293

Epoch: 5| Step: 3
Training loss: 1.837969884673455
Validation loss: 2.3553899653442696

Epoch: 5| Step: 4
Training loss: 1.3216725404054854
Validation loss: 2.3409255917453806

Epoch: 5| Step: 5
Training loss: 2.182191128717514
Validation loss: 2.344965980687608

Epoch: 5| Step: 6
Training loss: 1.9308194072398441
Validation loss: 2.3528913818313617

Epoch: 5| Step: 7
Training loss: 1.7292928381545947
Validation loss: 2.367637535453589

Epoch: 5| Step: 8
Training loss: 1.6117652993592169
Validation loss: 2.353981229284973

Epoch: 5| Step: 9
Training loss: 1.3342237132161399
Validation loss: 2.386450596150852

Epoch: 5| Step: 10
Training loss: 2.3591473197974664
Validation loss: 2.3702778083758314

Epoch: 271| Step: 0
Training loss: 1.8720597419579634
Validation loss: 2.3873677184488153

Epoch: 5| Step: 1
Training loss: 1.5788077209020983
Validation loss: 2.3807286212450203

Epoch: 5| Step: 2
Training loss: 1.7462425765888037
Validation loss: 2.3677541836344145

Epoch: 5| Step: 3
Training loss: 1.7041273754536748
Validation loss: 2.3566901693146725

Epoch: 5| Step: 4
Training loss: 1.7306603870238733
Validation loss: 2.3504160414364708

Epoch: 5| Step: 5
Training loss: 1.6507999070679824
Validation loss: 2.3307941500349787

Epoch: 5| Step: 6
Training loss: 2.0699712508043424
Validation loss: 2.3312816473556235

Epoch: 5| Step: 7
Training loss: 1.836149033068112
Validation loss: 2.3534236181431227

Epoch: 5| Step: 8
Training loss: 1.7823647474254505
Validation loss: 2.3734959793039656

Epoch: 5| Step: 9
Training loss: 2.3155260649227047
Validation loss: 2.3571009649737524

Epoch: 5| Step: 10
Training loss: 1.4783575862943652
Validation loss: 2.34000129312452

Epoch: 272| Step: 0
Training loss: 1.5855120760079735
Validation loss: 2.3561259625080657

Epoch: 5| Step: 1
Training loss: 1.381745093496883
Validation loss: 2.3802236118195634

Epoch: 5| Step: 2
Training loss: 1.6069923466640836
Validation loss: 2.3872932865160843

Epoch: 5| Step: 3
Training loss: 1.6491055694154781
Validation loss: 2.412180904453609

Epoch: 5| Step: 4
Training loss: 1.9785290008725425
Validation loss: 2.4104603647177263

Epoch: 5| Step: 5
Training loss: 2.2576516698030074
Validation loss: 2.3928494834082015

Epoch: 5| Step: 6
Training loss: 2.1700185622023453
Validation loss: 2.3636707765593403

Epoch: 5| Step: 7
Training loss: 1.5725631906157584
Validation loss: 2.362726982746907

Epoch: 5| Step: 8
Training loss: 1.8757497560017176
Validation loss: 2.3785901796808777

Epoch: 5| Step: 9
Training loss: 2.0263544803818445
Validation loss: 2.4163956338116725

Epoch: 5| Step: 10
Training loss: 0.9884593034257714
Validation loss: 2.4275789835234804

Epoch: 273| Step: 0
Training loss: 1.8752438068824155
Validation loss: 2.3982871787676117

Epoch: 5| Step: 1
Training loss: 1.9637734017534834
Validation loss: 2.413318198446996

Epoch: 5| Step: 2
Training loss: 2.2844888348272128
Validation loss: 2.464831348026105

Epoch: 5| Step: 3
Training loss: 1.7536488367486818
Validation loss: 2.493507940935426

Epoch: 5| Step: 4
Training loss: 1.2056637520343993
Validation loss: 2.44976841817985

Epoch: 5| Step: 5
Training loss: 1.6836810520841217
Validation loss: 2.4151138717296896

Epoch: 5| Step: 6
Training loss: 2.1339449269089217
Validation loss: 2.4165818500451026

Epoch: 5| Step: 7
Training loss: 1.8484967439110505
Validation loss: 2.4065085012392373

Epoch: 5| Step: 8
Training loss: 1.8040557019627474
Validation loss: 2.361456350879036

Epoch: 5| Step: 9
Training loss: 2.0826948586256
Validation loss: 2.337590808079541

Epoch: 5| Step: 10
Training loss: 0.7974418419227101
Validation loss: 2.3466284475501533

Epoch: 274| Step: 0
Training loss: 1.899593425215466
Validation loss: 2.388458189537671

Epoch: 5| Step: 1
Training loss: 1.7148566799501863
Validation loss: 2.421212397401812

Epoch: 5| Step: 2
Training loss: 1.5784034860979457
Validation loss: 2.444490779226728

Epoch: 5| Step: 3
Training loss: 2.104827953203171
Validation loss: 2.4663501610719205

Epoch: 5| Step: 4
Training loss: 1.7498243788743704
Validation loss: 2.3944332410080786

Epoch: 5| Step: 5
Training loss: 1.7382532696132889
Validation loss: 2.312765358441882

Epoch: 5| Step: 6
Training loss: 1.8278931690819062
Validation loss: 2.276693614042391

Epoch: 5| Step: 7
Training loss: 1.7170389154519805
Validation loss: 2.2881169149450895

Epoch: 5| Step: 8
Training loss: 1.8289847023492602
Validation loss: 2.311968253653676

Epoch: 5| Step: 9
Training loss: 1.9607246556976876
Validation loss: 2.3065352102034433

Epoch: 5| Step: 10
Training loss: 1.7893887684592498
Validation loss: 2.365634783282173

Epoch: 275| Step: 0
Training loss: 1.709210434267533
Validation loss: 2.425659496323352

Epoch: 5| Step: 1
Training loss: 2.1098502294891084
Validation loss: 2.4826819719432938

Epoch: 5| Step: 2
Training loss: 2.0644886948508563
Validation loss: 2.443265849238887

Epoch: 5| Step: 3
Training loss: 1.9630855634311528
Validation loss: 2.3861197197582578

Epoch: 5| Step: 4
Training loss: 1.641787888881026
Validation loss: 2.3556133202701575

Epoch: 5| Step: 5
Training loss: 1.8062151103626456
Validation loss: 2.336744476855957

Epoch: 5| Step: 6
Training loss: 1.7858485375755602
Validation loss: 2.3264189219312894

Epoch: 5| Step: 7
Training loss: 1.4219618550695898
Validation loss: 2.3293820115212447

Epoch: 5| Step: 8
Training loss: 2.029439618227648
Validation loss: 2.370758822806607

Epoch: 5| Step: 9
Training loss: 1.341865948671855
Validation loss: 2.4221317638107878

Epoch: 5| Step: 10
Training loss: 1.6432377673456535
Validation loss: 2.405286717850432

Epoch: 276| Step: 0
Training loss: 1.8577403729091417
Validation loss: 2.367081067837902

Epoch: 5| Step: 1
Training loss: 1.5547019152715806
Validation loss: 2.3215918515197402

Epoch: 5| Step: 2
Training loss: 1.7673637808142757
Validation loss: 2.346620231006544

Epoch: 5| Step: 3
Training loss: 2.0331256129782522
Validation loss: 2.3184491094456168

Epoch: 5| Step: 4
Training loss: 1.6776611170023543
Validation loss: 2.3139972246578666

Epoch: 5| Step: 5
Training loss: 1.9097112281559923
Validation loss: 2.3630342858056332

Epoch: 5| Step: 6
Training loss: 2.121660188523696
Validation loss: 2.3848193951877223

Epoch: 5| Step: 7
Training loss: 1.2809484173397194
Validation loss: 2.3601304906264278

Epoch: 5| Step: 8
Training loss: 1.5338110234961606
Validation loss: 2.3456688259783474

Epoch: 5| Step: 9
Training loss: 1.5690543225319749
Validation loss: 2.3501451286041326

Epoch: 5| Step: 10
Training loss: 1.7736699964399698
Validation loss: 2.3621917276940283

Epoch: 277| Step: 0
Training loss: 1.8246350354575072
Validation loss: 2.367122697317171

Epoch: 5| Step: 1
Training loss: 1.7545488365597142
Validation loss: 2.3508571114202903

Epoch: 5| Step: 2
Training loss: 1.6325482606399364
Validation loss: 2.3247569805862973

Epoch: 5| Step: 3
Training loss: 1.8850715981806458
Validation loss: 2.3606660577467373

Epoch: 5| Step: 4
Training loss: 1.6603259190642299
Validation loss: 2.3485756802900637

Epoch: 5| Step: 5
Training loss: 1.4517981922000194
Validation loss: 2.356433210368239

Epoch: 5| Step: 6
Training loss: 1.5749919497571812
Validation loss: 2.3923917425980887

Epoch: 5| Step: 7
Training loss: 2.2356723673523957
Validation loss: 2.4370408941803254

Epoch: 5| Step: 8
Training loss: 1.292909649653586
Validation loss: 2.3938309654008014

Epoch: 5| Step: 9
Training loss: 1.1621753321290436
Validation loss: 2.375437436624505

Epoch: 5| Step: 10
Training loss: 2.1107470535895723
Validation loss: 2.3681775704393884

Epoch: 278| Step: 0
Training loss: 1.5159312459910645
Validation loss: 2.339878591285984

Epoch: 5| Step: 1
Training loss: 1.6153272166202581
Validation loss: 2.3450597755294265

Epoch: 5| Step: 2
Training loss: 1.4544637112514744
Validation loss: 2.3519455579988064

Epoch: 5| Step: 3
Training loss: 1.488541948208561
Validation loss: 2.339558639493206

Epoch: 5| Step: 4
Training loss: 1.6590732767111127
Validation loss: 2.3350655773605706

Epoch: 5| Step: 5
Training loss: 1.8534787076885282
Validation loss: 2.358329415768319

Epoch: 5| Step: 6
Training loss: 2.167690059860421
Validation loss: 2.354361645741341

Epoch: 5| Step: 7
Training loss: 1.48426449012976
Validation loss: 2.381564626702047

Epoch: 5| Step: 8
Training loss: 1.4784949035401886
Validation loss: 2.372175695145826

Epoch: 5| Step: 9
Training loss: 1.9696990253753428
Validation loss: 2.405801504075689

Epoch: 5| Step: 10
Training loss: 1.878459726677132
Validation loss: 2.37352850664313

Epoch: 279| Step: 0
Training loss: 1.8970018774897042
Validation loss: 2.3159783091913555

Epoch: 5| Step: 1
Training loss: 1.7933343252843408
Validation loss: 2.30530119814538

Epoch: 5| Step: 2
Training loss: 1.4459224754065705
Validation loss: 2.31072388509608

Epoch: 5| Step: 3
Training loss: 1.7343926643640502
Validation loss: 2.32577305111937

Epoch: 5| Step: 4
Training loss: 1.7145204695544582
Validation loss: 2.3476925499835097

Epoch: 5| Step: 5
Training loss: 1.7754948315815104
Validation loss: 2.3645009739384846

Epoch: 5| Step: 6
Training loss: 1.6990544382212438
Validation loss: 2.4027664438315828

Epoch: 5| Step: 7
Training loss: 1.9941222725228276
Validation loss: 2.3953355479823433

Epoch: 5| Step: 8
Training loss: 1.61017810819653
Validation loss: 2.3858552626160527

Epoch: 5| Step: 9
Training loss: 1.3591606585012956
Validation loss: 2.3906854488765865

Epoch: 5| Step: 10
Training loss: 1.471534362381385
Validation loss: 2.369766328972108

Epoch: 280| Step: 0
Training loss: 1.6752529778817686
Validation loss: 2.342711266481091

Epoch: 5| Step: 1
Training loss: 1.0373292966382477
Validation loss: 2.3340858712346617

Epoch: 5| Step: 2
Training loss: 1.899614448077774
Validation loss: 2.358219212698279

Epoch: 5| Step: 3
Training loss: 1.520142498489369
Validation loss: 2.3544267283360263

Epoch: 5| Step: 4
Training loss: 1.6197929586750859
Validation loss: 2.3248273210445443

Epoch: 5| Step: 5
Training loss: 2.2093187208979725
Validation loss: 2.3097189954542436

Epoch: 5| Step: 6
Training loss: 1.6426766056471238
Validation loss: 2.349105147887362

Epoch: 5| Step: 7
Training loss: 1.6730186614998306
Validation loss: 2.382813177809677

Epoch: 5| Step: 8
Training loss: 1.2768526678984577
Validation loss: 2.4345051299587914

Epoch: 5| Step: 9
Training loss: 2.0920326819483694
Validation loss: 2.458235983974587

Epoch: 5| Step: 10
Training loss: 1.56028040591054
Validation loss: 2.411750681296516

Epoch: 281| Step: 0
Training loss: 2.1657648655146646
Validation loss: 2.388404973016049

Epoch: 5| Step: 1
Training loss: 1.376618646349161
Validation loss: 2.366638891111121

Epoch: 5| Step: 2
Training loss: 1.3236175342593877
Validation loss: 2.3435187451978656

Epoch: 5| Step: 3
Training loss: 2.2760282351681655
Validation loss: 2.349728628359201

Epoch: 5| Step: 4
Training loss: 1.57767177910013
Validation loss: 2.338464772170471

Epoch: 5| Step: 5
Training loss: 1.4856368473721624
Validation loss: 2.339468083610107

Epoch: 5| Step: 6
Training loss: 1.5669645232595186
Validation loss: 2.3432592719105245

Epoch: 5| Step: 7
Training loss: 1.5068737527153078
Validation loss: 2.3837407206324888

Epoch: 5| Step: 8
Training loss: 1.5423227237369206
Validation loss: 2.4423831861744265

Epoch: 5| Step: 9
Training loss: 1.4402988387337499
Validation loss: 2.5227326739952662

Epoch: 5| Step: 10
Training loss: 1.9053860567049001
Validation loss: 2.5850460889311218

Epoch: 282| Step: 0
Training loss: 1.7792695396157638
Validation loss: 2.4930739280457956

Epoch: 5| Step: 1
Training loss: 1.8178005322643924
Validation loss: 2.417224610291563

Epoch: 5| Step: 2
Training loss: 1.5790814060488843
Validation loss: 2.373416287329283

Epoch: 5| Step: 3
Training loss: 1.6895339858268361
Validation loss: 2.362907765388433

Epoch: 5| Step: 4
Training loss: 1.9147972720733777
Validation loss: 2.363491557821687

Epoch: 5| Step: 5
Training loss: 1.1631981629775598
Validation loss: 2.364446188179604

Epoch: 5| Step: 6
Training loss: 1.464467236768081
Validation loss: 2.4096766772703333

Epoch: 5| Step: 7
Training loss: 1.9608871027940835
Validation loss: 2.4444906601944854

Epoch: 5| Step: 8
Training loss: 1.523044241985854
Validation loss: 2.422598563933993

Epoch: 5| Step: 9
Training loss: 2.1229377164037317
Validation loss: 2.3865221507612744

Epoch: 5| Step: 10
Training loss: 1.8232110648622482
Validation loss: 2.344299729935618

Epoch: 283| Step: 0
Training loss: 1.7866788084889151
Validation loss: 2.341431470835164

Epoch: 5| Step: 1
Training loss: 1.716897278020775
Validation loss: 2.3256087931714458

Epoch: 5| Step: 2
Training loss: 1.542012442225665
Validation loss: 2.3240597145281083

Epoch: 5| Step: 3
Training loss: 1.562283157560816
Validation loss: 2.3256324704799702

Epoch: 5| Step: 4
Training loss: 1.9970692380421926
Validation loss: 2.317738493810354

Epoch: 5| Step: 5
Training loss: 1.273970322800761
Validation loss: 2.343139606143506

Epoch: 5| Step: 6
Training loss: 1.6656069326941731
Validation loss: 2.33330661418518

Epoch: 5| Step: 7
Training loss: 1.6989005656880973
Validation loss: 2.3277330219301273

Epoch: 5| Step: 8
Training loss: 1.957478180979295
Validation loss: 2.365554441748798

Epoch: 5| Step: 9
Training loss: 1.739160619608528
Validation loss: 2.3965793241836906

Epoch: 5| Step: 10
Training loss: 1.7694501374035168
Validation loss: 2.3662510546676003

Epoch: 284| Step: 0
Training loss: 1.8503898416058084
Validation loss: 2.3563722081068215

Epoch: 5| Step: 1
Training loss: 1.3676055269130212
Validation loss: 2.349057189055952

Epoch: 5| Step: 2
Training loss: 1.4687939089441016
Validation loss: 2.4068282345805025

Epoch: 5| Step: 3
Training loss: 1.592180414155985
Validation loss: 2.4375661531258315

Epoch: 5| Step: 4
Training loss: 1.8459261320509017
Validation loss: 2.4660308092402294

Epoch: 5| Step: 5
Training loss: 1.7301897982301768
Validation loss: 2.389696189976903

Epoch: 5| Step: 6
Training loss: 1.6773652813137594
Validation loss: 2.3353741930642715

Epoch: 5| Step: 7
Training loss: 1.725838349668297
Validation loss: 2.307620263710485

Epoch: 5| Step: 8
Training loss: 1.5660609295125394
Validation loss: 2.2651491519054368

Epoch: 5| Step: 9
Training loss: 1.8088884875593643
Validation loss: 2.2703099237927113

Epoch: 5| Step: 10
Training loss: 1.9497045855622652
Validation loss: 2.2913492790287266

Epoch: 285| Step: 0
Training loss: 1.4583024521237415
Validation loss: 2.2976444583148723

Epoch: 5| Step: 1
Training loss: 1.091785628750497
Validation loss: 2.328411748911295

Epoch: 5| Step: 2
Training loss: 1.958567246880479
Validation loss: 2.3915381717311557

Epoch: 5| Step: 3
Training loss: 1.5813782651242005
Validation loss: 2.380420702177268

Epoch: 5| Step: 4
Training loss: 2.1250188490087747
Validation loss: 2.3673449766848496

Epoch: 5| Step: 5
Training loss: 1.3711813874235592
Validation loss: 2.318398869398505

Epoch: 5| Step: 6
Training loss: 1.8944765063369733
Validation loss: 2.34162893047748

Epoch: 5| Step: 7
Training loss: 1.6931697118860505
Validation loss: 2.362080793142136

Epoch: 5| Step: 8
Training loss: 1.4273059791950182
Validation loss: 2.3757988774068943

Epoch: 5| Step: 9
Training loss: 1.7178364493310738
Validation loss: 2.3891261490031965

Epoch: 5| Step: 10
Training loss: 1.492282245284405
Validation loss: 2.3778002157560785

Epoch: 286| Step: 0
Training loss: 1.9337454688149192
Validation loss: 2.3902944687120526

Epoch: 5| Step: 1
Training loss: 0.9305830416882322
Validation loss: 2.3743684260301716

Epoch: 5| Step: 2
Training loss: 1.874719408020951
Validation loss: 2.365150712819261

Epoch: 5| Step: 3
Training loss: 1.6142084814566071
Validation loss: 2.3652112399163316

Epoch: 5| Step: 4
Training loss: 1.6700794167965765
Validation loss: 2.3323294843146916

Epoch: 5| Step: 5
Training loss: 1.649181324702668
Validation loss: 2.2877992978087467

Epoch: 5| Step: 6
Training loss: 1.4576945495317244
Validation loss: 2.3031968680178383

Epoch: 5| Step: 7
Training loss: 1.706433783054862
Validation loss: 2.293500968998841

Epoch: 5| Step: 8
Training loss: 1.980314651302682
Validation loss: 2.3313613907657214

Epoch: 5| Step: 9
Training loss: 1.7408661214766843
Validation loss: 2.3558434183120687

Epoch: 5| Step: 10
Training loss: 1.210437105217473
Validation loss: 2.402552013372198

Epoch: 287| Step: 0
Training loss: 1.302198399863639
Validation loss: 2.4129198535209504

Epoch: 5| Step: 1
Training loss: 1.185052709010806
Validation loss: 2.394950919989322

Epoch: 5| Step: 2
Training loss: 1.6953803545473456
Validation loss: 2.3943227916658145

Epoch: 5| Step: 3
Training loss: 1.2125845751809883
Validation loss: 2.352095487158416

Epoch: 5| Step: 4
Training loss: 1.21148462548539
Validation loss: 2.345616884131813

Epoch: 5| Step: 5
Training loss: 1.9530919186651525
Validation loss: 2.374385557802465

Epoch: 5| Step: 6
Training loss: 1.5237629860628956
Validation loss: 2.3442406324719927

Epoch: 5| Step: 7
Training loss: 1.7540391901350965
Validation loss: 2.3559133687246048

Epoch: 5| Step: 8
Training loss: 1.9406121393290519
Validation loss: 2.36349401734057

Epoch: 5| Step: 9
Training loss: 1.7128615338803153
Validation loss: 2.358695600841516

Epoch: 5| Step: 10
Training loss: 1.8637090227929936
Validation loss: 2.361030296215008

Epoch: 288| Step: 0
Training loss: 1.4898708395052918
Validation loss: 2.3623979990392305

Epoch: 5| Step: 1
Training loss: 1.4472987368112498
Validation loss: 2.36147339828437

Epoch: 5| Step: 2
Training loss: 1.68991932693338
Validation loss: 2.369866675688875

Epoch: 5| Step: 3
Training loss: 1.8925354188051235
Validation loss: 2.394856701609111

Epoch: 5| Step: 4
Training loss: 1.4212284504540875
Validation loss: 2.366790015758365

Epoch: 5| Step: 5
Training loss: 1.2149090519369976
Validation loss: 2.3507322258066825

Epoch: 5| Step: 6
Training loss: 1.9463893866438178
Validation loss: 2.330944696194187

Epoch: 5| Step: 7
Training loss: 1.7395216727226557
Validation loss: 2.327154355412137

Epoch: 5| Step: 8
Training loss: 1.7330540618520474
Validation loss: 2.2978901654219572

Epoch: 5| Step: 9
Training loss: 1.537635257633083
Validation loss: 2.321302836584262

Epoch: 5| Step: 10
Training loss: 1.2436250729336047
Validation loss: 2.3446660680521023

Epoch: 289| Step: 0
Training loss: 1.8377697182268091
Validation loss: 2.403772982812868

Epoch: 5| Step: 1
Training loss: 1.3038788076613406
Validation loss: 2.4475447264594483

Epoch: 5| Step: 2
Training loss: 1.5812818471242107
Validation loss: 2.4429395334347372

Epoch: 5| Step: 3
Training loss: 1.4925175646286706
Validation loss: 2.433855969299156

Epoch: 5| Step: 4
Training loss: 1.4647455207950242
Validation loss: 2.399362961463189

Epoch: 5| Step: 5
Training loss: 1.31708140279662
Validation loss: 2.3866749853412084

Epoch: 5| Step: 6
Training loss: 1.754936340568581
Validation loss: 2.338571600114119

Epoch: 5| Step: 7
Training loss: 2.0047776853831096
Validation loss: 2.3603793280772907

Epoch: 5| Step: 8
Training loss: 1.522064529304184
Validation loss: 2.339125975289133

Epoch: 5| Step: 9
Training loss: 1.829270224221303
Validation loss: 2.3231161980887896

Epoch: 5| Step: 10
Training loss: 1.300268077719538
Validation loss: 2.3525582515390093

Epoch: 290| Step: 0
Training loss: 1.411123435441379
Validation loss: 2.3826772193156254

Epoch: 5| Step: 1
Training loss: 1.8864813550628794
Validation loss: 2.441742650504862

Epoch: 5| Step: 2
Training loss: 1.9912500906140247
Validation loss: 2.357479869402642

Epoch: 5| Step: 3
Training loss: 1.5818322327317633
Validation loss: 2.3070178736945413

Epoch: 5| Step: 4
Training loss: 1.4477757264112407
Validation loss: 2.265329736487368

Epoch: 5| Step: 5
Training loss: 1.4113977097821233
Validation loss: 2.2937983989680792

Epoch: 5| Step: 6
Training loss: 1.8872077892543755
Validation loss: 2.277042182432165

Epoch: 5| Step: 7
Training loss: 1.3705122276910229
Validation loss: 2.3047331324210774

Epoch: 5| Step: 8
Training loss: 1.388521725548854
Validation loss: 2.3624377740175477

Epoch: 5| Step: 9
Training loss: 1.4635352228459493
Validation loss: 2.440321286348229

Epoch: 5| Step: 10
Training loss: 1.8514071371189207
Validation loss: 2.4492986027921804

Epoch: 291| Step: 0
Training loss: 1.6676362396357851
Validation loss: 2.407310965762982

Epoch: 5| Step: 1
Training loss: 1.5538296273559078
Validation loss: 2.3849827795029794

Epoch: 5| Step: 2
Training loss: 1.5287788069000159
Validation loss: 2.360845611511264

Epoch: 5| Step: 3
Training loss: 1.4033390009411482
Validation loss: 2.3296748308448687

Epoch: 5| Step: 4
Training loss: 1.494574908801837
Validation loss: 2.3141504931256285

Epoch: 5| Step: 5
Training loss: 1.2780807188986092
Validation loss: 2.2996907373366122

Epoch: 5| Step: 6
Training loss: 1.5925857180727132
Validation loss: 2.3093393361156096

Epoch: 5| Step: 7
Training loss: 1.5267031367636457
Validation loss: 2.329208158942767

Epoch: 5| Step: 8
Training loss: 1.5484413924490683
Validation loss: 2.3135217162788955

Epoch: 5| Step: 9
Training loss: 1.8843690761390808
Validation loss: 2.321363779741667

Epoch: 5| Step: 10
Training loss: 1.7448305343929535
Validation loss: 2.3480267833166657

Epoch: 292| Step: 0
Training loss: 1.670602902752567
Validation loss: 2.3343575100601077

Epoch: 5| Step: 1
Training loss: 1.7192591519918583
Validation loss: 2.39813191995547

Epoch: 5| Step: 2
Training loss: 1.3244695735358472
Validation loss: 2.414410826806352

Epoch: 5| Step: 3
Training loss: 1.3414790458677763
Validation loss: 2.4178155030815933

Epoch: 5| Step: 4
Training loss: 1.3580792269342201
Validation loss: 2.371908160413206

Epoch: 5| Step: 5
Training loss: 1.3098778644439075
Validation loss: 2.339880248973234

Epoch: 5| Step: 6
Training loss: 1.7738279341391179
Validation loss: 2.359796784204474

Epoch: 5| Step: 7
Training loss: 1.4693507325485937
Validation loss: 2.3519791044059795

Epoch: 5| Step: 8
Training loss: 1.8951554675984785
Validation loss: 2.3818971540383673

Epoch: 5| Step: 9
Training loss: 1.8541406636790014
Validation loss: 2.4144757427487398

Epoch: 5| Step: 10
Training loss: 1.0257406164228682
Validation loss: 2.396485171964076

Epoch: 293| Step: 0
Training loss: 1.7209759949423602
Validation loss: 2.3794521684239927

Epoch: 5| Step: 1
Training loss: 1.4351002108577149
Validation loss: 2.338811380913991

Epoch: 5| Step: 2
Training loss: 1.3313553065525996
Validation loss: 2.2881410261500026

Epoch: 5| Step: 3
Training loss: 1.7000639819278318
Validation loss: 2.29814143729114

Epoch: 5| Step: 4
Training loss: 1.4259527233948885
Validation loss: 2.2970768902094054

Epoch: 5| Step: 5
Training loss: 2.0302182438234837
Validation loss: 2.2841190654044956

Epoch: 5| Step: 6
Training loss: 1.3818509050508951
Validation loss: 2.3169541126691304

Epoch: 5| Step: 7
Training loss: 1.526242066158884
Validation loss: 2.347062410811815

Epoch: 5| Step: 8
Training loss: 1.4408563324721848
Validation loss: 2.383706342461678

Epoch: 5| Step: 9
Training loss: 1.686528102601032
Validation loss: 2.4278812933726805

Epoch: 5| Step: 10
Training loss: 1.2923440028925886
Validation loss: 2.4627793442995687

Epoch: 294| Step: 0
Training loss: 1.0686109619717854
Validation loss: 2.3589532381892475

Epoch: 5| Step: 1
Training loss: 1.2211018879937154
Validation loss: 2.342871114912415

Epoch: 5| Step: 2
Training loss: 1.621348680420966
Validation loss: 2.3152910897602594

Epoch: 5| Step: 3
Training loss: 1.1644717527561237
Validation loss: 2.305961754679847

Epoch: 5| Step: 4
Training loss: 1.587731610320949
Validation loss: 2.2893187738411145

Epoch: 5| Step: 5
Training loss: 1.5338643391589764
Validation loss: 2.3309090944567243

Epoch: 5| Step: 6
Training loss: 1.9133706224221614
Validation loss: 2.36439647065412

Epoch: 5| Step: 7
Training loss: 1.6483578775710872
Validation loss: 2.392630227052981

Epoch: 5| Step: 8
Training loss: 1.125258521999726
Validation loss: 2.389113564831052

Epoch: 5| Step: 9
Training loss: 1.8470209493269987
Validation loss: 2.3842691709315487

Epoch: 5| Step: 10
Training loss: 1.9807642127551104
Validation loss: 2.3804072044795084

Epoch: 295| Step: 0
Training loss: 1.0694470770226867
Validation loss: 2.3467284852936334

Epoch: 5| Step: 1
Training loss: 1.5940395914902117
Validation loss: 2.303047341002673

Epoch: 5| Step: 2
Training loss: 1.6730540031158345
Validation loss: 2.3088837417811305

Epoch: 5| Step: 3
Training loss: 1.6246895860415371
Validation loss: 2.3026974119369576

Epoch: 5| Step: 4
Training loss: 1.6494524393986802
Validation loss: 2.3204061434660392

Epoch: 5| Step: 5
Training loss: 1.2706983161035514
Validation loss: 2.354721148508158

Epoch: 5| Step: 6
Training loss: 1.727891298464603
Validation loss: 2.3741799435405753

Epoch: 5| Step: 7
Training loss: 1.696296792899412
Validation loss: 2.3504944965498202

Epoch: 5| Step: 8
Training loss: 1.7277629010758346
Validation loss: 2.320582455646206

Epoch: 5| Step: 9
Training loss: 1.4002259395706889
Validation loss: 2.3037050584070378

Epoch: 5| Step: 10
Training loss: 1.2549987026982992
Validation loss: 2.3285855965446944

Epoch: 296| Step: 0
Training loss: 1.6800954633792404
Validation loss: 2.3815586050204667

Epoch: 5| Step: 1
Training loss: 1.8588975565869708
Validation loss: 2.389508257784593

Epoch: 5| Step: 2
Training loss: 1.3881181559937144
Validation loss: 2.317537816683573

Epoch: 5| Step: 3
Training loss: 1.5307589930946628
Validation loss: 2.3245207206667153

Epoch: 5| Step: 4
Training loss: 1.62170428073984
Validation loss: 2.3081607754402436

Epoch: 5| Step: 5
Training loss: 1.266469650046471
Validation loss: 2.3282571895334723

Epoch: 5| Step: 6
Training loss: 1.451162510221718
Validation loss: 2.341798390108987

Epoch: 5| Step: 7
Training loss: 1.3412063831870304
Validation loss: 2.355211145111841

Epoch: 5| Step: 8
Training loss: 1.6892853934755196
Validation loss: 2.365899865521271

Epoch: 5| Step: 9
Training loss: 1.1791161170252016
Validation loss: 2.34433723777031

Epoch: 5| Step: 10
Training loss: 1.9099135917571024
Validation loss: 2.3529306997377204

Epoch: 297| Step: 0
Training loss: 1.4819282041448534
Validation loss: 2.3283434826800002

Epoch: 5| Step: 1
Training loss: 1.378491217639552
Validation loss: 2.329318373124951

Epoch: 5| Step: 2
Training loss: 1.3082086708222391
Validation loss: 2.32086926050609

Epoch: 5| Step: 3
Training loss: 1.1683790832102097
Validation loss: 2.3002934318182224

Epoch: 5| Step: 4
Training loss: 1.6479168833633198
Validation loss: 2.3295026943552517

Epoch: 5| Step: 5
Training loss: 1.7682158104940355
Validation loss: 2.335771259051736

Epoch: 5| Step: 6
Training loss: 1.4424373587985084
Validation loss: 2.3469210572644004

Epoch: 5| Step: 7
Training loss: 1.5533003249501869
Validation loss: 2.337490146211056

Epoch: 5| Step: 8
Training loss: 1.2308683200754484
Validation loss: 2.3257753592813053

Epoch: 5| Step: 9
Training loss: 1.6309656531145602
Validation loss: 2.354824082903262

Epoch: 5| Step: 10
Training loss: 1.9367823963855868
Validation loss: 2.2941869135801443

Epoch: 298| Step: 0
Training loss: 1.2037894655850803
Validation loss: 2.2900361126824462

Epoch: 5| Step: 1
Training loss: 1.7471538287053228
Validation loss: 2.2982104573055677

Epoch: 5| Step: 2
Training loss: 1.3858907457312042
Validation loss: 2.2790014209726057

Epoch: 5| Step: 3
Training loss: 1.2865840783485918
Validation loss: 2.323809401726792

Epoch: 5| Step: 4
Training loss: 1.7269415115763236
Validation loss: 2.3769687330501803

Epoch: 5| Step: 5
Training loss: 1.7387353196885296
Validation loss: 2.44537065977983

Epoch: 5| Step: 6
Training loss: 1.3383420307990026
Validation loss: 2.439001018244364

Epoch: 5| Step: 7
Training loss: 1.986332085979642
Validation loss: 2.3856112720554963

Epoch: 5| Step: 8
Training loss: 1.2417956039935794
Validation loss: 2.298196630712288

Epoch: 5| Step: 9
Training loss: 1.3923810094403521
Validation loss: 2.283746696883913

Epoch: 5| Step: 10
Training loss: 1.389959068724834
Validation loss: 2.2620203453735974

Epoch: 299| Step: 0
Training loss: 1.4017399840319396
Validation loss: 2.268038155988339

Epoch: 5| Step: 1
Training loss: 1.6047599322975437
Validation loss: 2.2950657229961644

Epoch: 5| Step: 2
Training loss: 1.1102415649361637
Validation loss: 2.2987220876246015

Epoch: 5| Step: 3
Training loss: 1.5758939779316998
Validation loss: 2.3256485006713747

Epoch: 5| Step: 4
Training loss: 1.223368184548634
Validation loss: 2.366871520880371

Epoch: 5| Step: 5
Training loss: 1.8214422166671185
Validation loss: 2.390351992675222

Epoch: 5| Step: 6
Training loss: 1.8516910685394354
Validation loss: 2.42408300039416

Epoch: 5| Step: 7
Training loss: 1.2469499570262468
Validation loss: 2.3751603565149413

Epoch: 5| Step: 8
Training loss: 1.5466656013326154
Validation loss: 2.337713679348171

Epoch: 5| Step: 9
Training loss: 1.7187361283176017
Validation loss: 2.3304951851731315

Epoch: 5| Step: 10
Training loss: 1.4088493060335467
Validation loss: 2.311131008669662

Epoch: 300| Step: 0
Training loss: 1.7052851984887496
Validation loss: 2.3292937058657897

Epoch: 5| Step: 1
Training loss: 1.8398210722544128
Validation loss: 2.3454665681662563

Epoch: 5| Step: 2
Training loss: 1.280418684552621
Validation loss: 2.3869117951580026

Epoch: 5| Step: 3
Training loss: 1.0951808834040417
Validation loss: 2.4229059539739524

Epoch: 5| Step: 4
Training loss: 1.644145421958953
Validation loss: 2.39613638767308

Epoch: 5| Step: 5
Training loss: 1.4056211124975335
Validation loss: 2.354509743721981

Epoch: 5| Step: 6
Training loss: 1.353259129737094
Validation loss: 2.312863175892411

Epoch: 5| Step: 7
Training loss: 1.6623169246057776
Validation loss: 2.2873200885496305

Epoch: 5| Step: 8
Training loss: 1.5243777772347151
Validation loss: 2.2893799004535014

Epoch: 5| Step: 9
Training loss: 1.51279452585292
Validation loss: 2.311232307220968

Epoch: 5| Step: 10
Training loss: 1.104249639212662
Validation loss: 2.316981381466265

Epoch: 301| Step: 0
Training loss: 1.780227233655436
Validation loss: 2.2955608748122223

Epoch: 5| Step: 1
Training loss: 1.694482978354851
Validation loss: 2.3221200008852825

Epoch: 5| Step: 2
Training loss: 0.8995012702869312
Validation loss: 2.325860715573301

Epoch: 5| Step: 3
Training loss: 1.3763558898436123
Validation loss: 2.33340075024836

Epoch: 5| Step: 4
Training loss: 1.3568608503688924
Validation loss: 2.3762187593994266

Epoch: 5| Step: 5
Training loss: 1.9999696014001458
Validation loss: 2.379665327267461

Epoch: 5| Step: 6
Training loss: 1.383815853960609
Validation loss: 2.374627529398954

Epoch: 5| Step: 7
Training loss: 1.8108095638975625
Validation loss: 2.3573508475843945

Epoch: 5| Step: 8
Training loss: 0.9754744915699299
Validation loss: 2.332444956491973

Epoch: 5| Step: 9
Training loss: 0.76270070483149
Validation loss: 2.314493584356036

Epoch: 5| Step: 10
Training loss: 1.3835660529958895
Validation loss: 2.3115084544741524

Epoch: 302| Step: 0
Training loss: 1.5069114878733076
Validation loss: 2.3087077443291126

Epoch: 5| Step: 1
Training loss: 1.8369411890358163
Validation loss: 2.306900629792186

Epoch: 5| Step: 2
Training loss: 1.268568078514411
Validation loss: 2.32913293442232

Epoch: 5| Step: 3
Training loss: 1.4221029413307522
Validation loss: 2.3442461228395595

Epoch: 5| Step: 4
Training loss: 1.220284010082014
Validation loss: 2.3425996009383554

Epoch: 5| Step: 5
Training loss: 1.4496673136557858
Validation loss: 2.319370144015935

Epoch: 5| Step: 6
Training loss: 1.4590046382043333
Validation loss: 2.287809568935825

Epoch: 5| Step: 7
Training loss: 1.1606067335163204
Validation loss: 2.2863251212371036

Epoch: 5| Step: 8
Training loss: 1.7203043758190106
Validation loss: 2.3028046567334535

Epoch: 5| Step: 9
Training loss: 1.6161819501507377
Validation loss: 2.299128256679749

Epoch: 5| Step: 10
Training loss: 1.1380081467026806
Validation loss: 2.262015852805

Epoch: 303| Step: 0
Training loss: 1.4089086196539349
Validation loss: 2.2697169651311184

Epoch: 5| Step: 1
Training loss: 1.7676347755079274
Validation loss: 2.291477828388532

Epoch: 5| Step: 2
Training loss: 1.1988869372646493
Validation loss: 2.3007539708216274

Epoch: 5| Step: 3
Training loss: 0.9402767068852748
Validation loss: 2.3464903454906305

Epoch: 5| Step: 4
Training loss: 1.279570152854962
Validation loss: 2.341053967076098

Epoch: 5| Step: 5
Training loss: 1.553955519227402
Validation loss: 2.3408319280456165

Epoch: 5| Step: 6
Training loss: 1.4620834181140445
Validation loss: 2.3343784793993057

Epoch: 5| Step: 7
Training loss: 1.5242568722507897
Validation loss: 2.286251371477638

Epoch: 5| Step: 8
Training loss: 1.2731413701708667
Validation loss: 2.2896395252130457

Epoch: 5| Step: 9
Training loss: 1.5224014280383678
Validation loss: 2.313093414705881

Epoch: 5| Step: 10
Training loss: 1.7191826709268025
Validation loss: 2.3011158153716345

Epoch: 304| Step: 0
Training loss: 1.0593324455784061
Validation loss: 2.286834068875383

Epoch: 5| Step: 1
Training loss: 2.0304430018777953
Validation loss: 2.2954611417962605

Epoch: 5| Step: 2
Training loss: 1.6827099243750998
Validation loss: 2.273923959922699

Epoch: 5| Step: 3
Training loss: 1.740195054488788
Validation loss: 2.347751802423842

Epoch: 5| Step: 4
Training loss: 1.2641371941866173
Validation loss: 2.333014706715054

Epoch: 5| Step: 5
Training loss: 1.3172645374363967
Validation loss: 2.341489285386024

Epoch: 5| Step: 6
Training loss: 0.9075152345434744
Validation loss: 2.380777923408273

Epoch: 5| Step: 7
Training loss: 1.0731773183307547
Validation loss: 2.394508840681587

Epoch: 5| Step: 8
Training loss: 1.3177258134770617
Validation loss: 2.35347705105335

Epoch: 5| Step: 9
Training loss: 1.2197677568697893
Validation loss: 2.336252983942578

Epoch: 5| Step: 10
Training loss: 1.6197580004890593
Validation loss: 2.3206528674016167

Epoch: 305| Step: 0
Training loss: 1.507241649979762
Validation loss: 2.302874234983907

Epoch: 5| Step: 1
Training loss: 1.3994246254180904
Validation loss: 2.294010984345396

Epoch: 5| Step: 2
Training loss: 2.035456834733179
Validation loss: 2.304784257657295

Epoch: 5| Step: 3
Training loss: 1.2004152970116977
Validation loss: 2.303794256422238

Epoch: 5| Step: 4
Training loss: 0.9253157076897592
Validation loss: 2.31718569858175

Epoch: 5| Step: 5
Training loss: 1.3249318951072027
Validation loss: 2.3262085895915003

Epoch: 5| Step: 6
Training loss: 1.0269081729817395
Validation loss: 2.3064162689201253

Epoch: 5| Step: 7
Training loss: 1.3107917204450168
Validation loss: 2.3306273057221496

Epoch: 5| Step: 8
Training loss: 1.9731599372426587
Validation loss: 2.32688159034169

Epoch: 5| Step: 9
Training loss: 1.427951363122612
Validation loss: 2.338905057571186

Epoch: 5| Step: 10
Training loss: 0.8864211536743501
Validation loss: 2.336928653912746

Epoch: 306| Step: 0
Training loss: 1.4453812866338145
Validation loss: 2.3556053516412145

Epoch: 5| Step: 1
Training loss: 1.5293765382248439
Validation loss: 2.3583621403324644

Epoch: 5| Step: 2
Training loss: 1.0444014064114588
Validation loss: 2.3573777795948487

Epoch: 5| Step: 3
Training loss: 0.8716865540989802
Validation loss: 2.399052243902824

Epoch: 5| Step: 4
Training loss: 1.5559615852252444
Validation loss: 2.423040689955767

Epoch: 5| Step: 5
Training loss: 1.7759463675279423
Validation loss: 2.4023458821477064

Epoch: 5| Step: 6
Training loss: 1.215916298137556
Validation loss: 2.3805748944539964

Epoch: 5| Step: 7
Training loss: 1.4394492326577717
Validation loss: 2.354539987720237

Epoch: 5| Step: 8
Training loss: 1.097608137603544
Validation loss: 2.3179896004380796

Epoch: 5| Step: 9
Training loss: 1.5058861320681345
Validation loss: 2.3375834173927306

Epoch: 5| Step: 10
Training loss: 1.73617522142506
Validation loss: 2.31300670833757

Epoch: 307| Step: 0
Training loss: 1.3200675240498674
Validation loss: 2.34665106064934

Epoch: 5| Step: 1
Training loss: 1.831763469589772
Validation loss: 2.356831523245508

Epoch: 5| Step: 2
Training loss: 1.4550636239577341
Validation loss: 2.3520932516924367

Epoch: 5| Step: 3
Training loss: 1.107793943951884
Validation loss: 2.3319890270662738

Epoch: 5| Step: 4
Training loss: 1.186327958193338
Validation loss: 2.323956605572658

Epoch: 5| Step: 5
Training loss: 1.6152867005439695
Validation loss: 2.333669615902582

Epoch: 5| Step: 6
Training loss: 1.360458336971341
Validation loss: 2.3099155279286605

Epoch: 5| Step: 7
Training loss: 1.3065925441043984
Validation loss: 2.309972262340939

Epoch: 5| Step: 8
Training loss: 1.3232130885003879
Validation loss: 2.2920477096342666

Epoch: 5| Step: 9
Training loss: 1.1232714619185535
Validation loss: 2.2783566538523568

Epoch: 5| Step: 10
Training loss: 1.5947664796653793
Validation loss: 2.264356445995668

Epoch: 308| Step: 0
Training loss: 1.3555375667109744
Validation loss: 2.2908456351483193

Epoch: 5| Step: 1
Training loss: 0.8741656480740219
Validation loss: 2.324571220465896

Epoch: 5| Step: 2
Training loss: 1.420808748645954
Validation loss: 2.3711364140023696

Epoch: 5| Step: 3
Training loss: 1.5751986423748128
Validation loss: 2.3396306119298798

Epoch: 5| Step: 4
Training loss: 1.5005067922863629
Validation loss: 2.3364273365998085

Epoch: 5| Step: 5
Training loss: 1.2295043556877756
Validation loss: 2.3847617861455728

Epoch: 5| Step: 6
Training loss: 1.3967164600360797
Validation loss: 2.3695690416017343

Epoch: 5| Step: 7
Training loss: 1.2365069749622317
Validation loss: 2.358110888524729

Epoch: 5| Step: 8
Training loss: 1.7795273331131711
Validation loss: 2.3352069580080164

Epoch: 5| Step: 9
Training loss: 1.3928429992362905
Validation loss: 2.3106961252940295

Epoch: 5| Step: 10
Training loss: 1.0431538964000984
Validation loss: 2.3081410423624904

Epoch: 309| Step: 0
Training loss: 1.4417647249393597
Validation loss: 2.3417044635405717

Epoch: 5| Step: 1
Training loss: 1.0151775841792627
Validation loss: 2.3096128697998886

Epoch: 5| Step: 2
Training loss: 1.602764515938519
Validation loss: 2.306408831690611

Epoch: 5| Step: 3
Training loss: 1.5999258471233393
Validation loss: 2.31911457166402

Epoch: 5| Step: 4
Training loss: 1.297599635993516
Validation loss: 2.345988164642992

Epoch: 5| Step: 5
Training loss: 0.9918473629385234
Validation loss: 2.30171224193894

Epoch: 5| Step: 6
Training loss: 1.2623120026315244
Validation loss: 2.3114803353218867

Epoch: 5| Step: 7
Training loss: 1.3062122595048626
Validation loss: 2.307577210833075

Epoch: 5| Step: 8
Training loss: 1.6632753758217005
Validation loss: 2.3080188454658543

Epoch: 5| Step: 9
Training loss: 1.4378063041422517
Validation loss: 2.329104153544889

Epoch: 5| Step: 10
Training loss: 1.2356868484909798
Validation loss: 2.311413651409164

Epoch: 310| Step: 0
Training loss: 0.8710594683688351
Validation loss: 2.350505660738149

Epoch: 5| Step: 1
Training loss: 1.5158163520123253
Validation loss: 2.3752969362980236

Epoch: 5| Step: 2
Training loss: 1.2101295483021688
Validation loss: 2.30796637897053

Epoch: 5| Step: 3
Training loss: 1.0935827399837512
Validation loss: 2.3298653446471196

Epoch: 5| Step: 4
Training loss: 1.2731137946660567
Validation loss: 2.2967527009706847

Epoch: 5| Step: 5
Training loss: 1.2175817025125648
Validation loss: 2.2912361665437486

Epoch: 5| Step: 6
Training loss: 1.5857397999177585
Validation loss: 2.308304008326342

Epoch: 5| Step: 7
Training loss: 1.1793990129816985
Validation loss: 2.2952117969982906

Epoch: 5| Step: 8
Training loss: 1.445774478795492
Validation loss: 2.295996350494119

Epoch: 5| Step: 9
Training loss: 1.6204074371982702
Validation loss: 2.3679128774336284

Epoch: 5| Step: 10
Training loss: 1.826147591332527
Validation loss: 2.369378415847664

Epoch: 311| Step: 0
Training loss: 1.5972925345751545
Validation loss: 2.3902420722770947

Epoch: 5| Step: 1
Training loss: 1.3871438248013468
Validation loss: 2.3529009122837223

Epoch: 5| Step: 2
Training loss: 1.3864834438068712
Validation loss: 2.3056356102176165

Epoch: 5| Step: 3
Training loss: 1.4083296762603288
Validation loss: 2.2846260122439923

Epoch: 5| Step: 4
Training loss: 1.471653280546512
Validation loss: 2.293485209296102

Epoch: 5| Step: 5
Training loss: 1.412031791529035
Validation loss: 2.2749774074413014

Epoch: 5| Step: 6
Training loss: 1.5872280338441918
Validation loss: 2.284854144150291

Epoch: 5| Step: 7
Training loss: 1.1229036720859265
Validation loss: 2.2951133786016786

Epoch: 5| Step: 8
Training loss: 1.0534189578053725
Validation loss: 2.3171838841513006

Epoch: 5| Step: 9
Training loss: 1.1879613883490194
Validation loss: 2.3183076163708773

Epoch: 5| Step: 10
Training loss: 1.1013842499357205
Validation loss: 2.344118157461246

Epoch: 312| Step: 0
Training loss: 1.2572133787612698
Validation loss: 2.375635994025038

Epoch: 5| Step: 1
Training loss: 1.3696840870123015
Validation loss: 2.362268861661423

Epoch: 5| Step: 2
Training loss: 1.064682234159614
Validation loss: 2.3372125874559693

Epoch: 5| Step: 3
Training loss: 1.2816104381927953
Validation loss: 2.293158123231351

Epoch: 5| Step: 4
Training loss: 1.143638705482627
Validation loss: 2.3002893020933923

Epoch: 5| Step: 5
Training loss: 1.632924637297677
Validation loss: 2.2735053090631214

Epoch: 5| Step: 6
Training loss: 1.082356318041102
Validation loss: 2.2945922983548512

Epoch: 5| Step: 7
Training loss: 1.5940126688799574
Validation loss: 2.3049724577194124

Epoch: 5| Step: 8
Training loss: 1.1501944460471245
Validation loss: 2.3396393625402214

Epoch: 5| Step: 9
Training loss: 1.587947079639109
Validation loss: 2.357193483019328

Epoch: 5| Step: 10
Training loss: 1.617693982999206
Validation loss: 2.4324482835325054

Epoch: 313| Step: 0
Training loss: 1.318452190381524
Validation loss: 2.442529223419835

Epoch: 5| Step: 1
Training loss: 0.9234493842223526
Validation loss: 2.373291032233151

Epoch: 5| Step: 2
Training loss: 1.6264814079950587
Validation loss: 2.3112377883727935

Epoch: 5| Step: 3
Training loss: 1.1823380358953517
Validation loss: 2.2755554266289293

Epoch: 5| Step: 4
Training loss: 1.4324742241316295
Validation loss: 2.2735808806217963

Epoch: 5| Step: 5
Training loss: 1.4202645372406537
Validation loss: 2.243103858829544

Epoch: 5| Step: 6
Training loss: 1.33062535706565
Validation loss: 2.26495516404448

Epoch: 5| Step: 7
Training loss: 1.355864936907325
Validation loss: 2.3180559270758483

Epoch: 5| Step: 8
Training loss: 1.6803925210075779
Validation loss: 2.376831604333253

Epoch: 5| Step: 9
Training loss: 1.3011876293409332
Validation loss: 2.4033827908998813

Epoch: 5| Step: 10
Training loss: 1.1618143684938158
Validation loss: 2.391891475386568

Epoch: 314| Step: 0
Training loss: 0.9894425877651201
Validation loss: 2.3455185253645077

Epoch: 5| Step: 1
Training loss: 1.5321337426823085
Validation loss: 2.3192126530176154

Epoch: 5| Step: 2
Training loss: 1.5776296914740195
Validation loss: 2.3586046808125354

Epoch: 5| Step: 3
Training loss: 1.3764554037289365
Validation loss: 2.350632613112757

Epoch: 5| Step: 4
Training loss: 1.3281382840558082
Validation loss: 2.349645766464333

Epoch: 5| Step: 5
Training loss: 1.4039181343131777
Validation loss: 2.361016279395634

Epoch: 5| Step: 6
Training loss: 1.1368015429571527
Validation loss: 2.404682996399804

Epoch: 5| Step: 7
Training loss: 1.479610063244624
Validation loss: 2.431642469996898

Epoch: 5| Step: 8
Training loss: 1.568938607964092
Validation loss: 2.4285815756552975

Epoch: 5| Step: 9
Training loss: 1.1330741317112425
Validation loss: 2.3972488284429287

Epoch: 5| Step: 10
Training loss: 1.0742674105633563
Validation loss: 2.311397335052082

Epoch: 315| Step: 0
Training loss: 1.3074918292284452
Validation loss: 2.2756297883336787

Epoch: 5| Step: 1
Training loss: 1.0840517865088963
Validation loss: 2.230729814806641

Epoch: 5| Step: 2
Training loss: 1.7061788495218742
Validation loss: 2.234976640092733

Epoch: 5| Step: 3
Training loss: 1.464397230122043
Validation loss: 2.263595661171156

Epoch: 5| Step: 4
Training loss: 1.1169186782194545
Validation loss: 2.313487945218222

Epoch: 5| Step: 5
Training loss: 1.2701996437606828
Validation loss: 2.3994590190159104

Epoch: 5| Step: 6
Training loss: 1.4957141045929274
Validation loss: 2.443825712264553

Epoch: 5| Step: 7
Training loss: 1.6607968519344518
Validation loss: 2.454861120316527

Epoch: 5| Step: 8
Training loss: 1.066343312624517
Validation loss: 2.3995758697506115

Epoch: 5| Step: 9
Training loss: 1.3181450111458262
Validation loss: 2.3743918622030913

Epoch: 5| Step: 10
Training loss: 1.6239397551538484
Validation loss: 2.3356928537961785

Epoch: 316| Step: 0
Training loss: 0.9885347063940367
Validation loss: 2.311840084050798

Epoch: 5| Step: 1
Training loss: 1.3836515650417134
Validation loss: 2.277088170149218

Epoch: 5| Step: 2
Training loss: 2.004937514475372
Validation loss: 2.303805382075977

Epoch: 5| Step: 3
Training loss: 1.4535502970168048
Validation loss: 2.283819898350898

Epoch: 5| Step: 4
Training loss: 0.7907291976961537
Validation loss: 2.346641290689795

Epoch: 5| Step: 5
Training loss: 0.9454095018288233
Validation loss: 2.341812308484846

Epoch: 5| Step: 6
Training loss: 1.0591031921439464
Validation loss: 2.303276917060045

Epoch: 5| Step: 7
Training loss: 1.2220284309544913
Validation loss: 2.3082134713108338

Epoch: 5| Step: 8
Training loss: 1.1792540606585897
Validation loss: 2.2955998970706606

Epoch: 5| Step: 9
Training loss: 1.7193269628194996
Validation loss: 2.2784825191541067

Epoch: 5| Step: 10
Training loss: 1.294082991274976
Validation loss: 2.268279042803522

Epoch: 317| Step: 0
Training loss: 1.3620408763241179
Validation loss: 2.2633203277396663

Epoch: 5| Step: 1
Training loss: 1.2427688773606764
Validation loss: 2.259082958915846

Epoch: 5| Step: 2
Training loss: 1.1757783097645442
Validation loss: 2.2509705132164317

Epoch: 5| Step: 3
Training loss: 1.367240425175384
Validation loss: 2.283916247529178

Epoch: 5| Step: 4
Training loss: 1.1188037092220342
Validation loss: 2.307777785979914

Epoch: 5| Step: 5
Training loss: 1.259241039260145
Validation loss: 2.348133752697008

Epoch: 5| Step: 6
Training loss: 1.3653918872610675
Validation loss: 2.368024452491256

Epoch: 5| Step: 7
Training loss: 1.3381840070946418
Validation loss: 2.3653716232991777

Epoch: 5| Step: 8
Training loss: 1.0735082877860387
Validation loss: 2.330629800472741

Epoch: 5| Step: 9
Training loss: 1.6872101994086348
Validation loss: 2.293403536330647

Epoch: 5| Step: 10
Training loss: 1.0704267677512591
Validation loss: 2.284536886687151

Epoch: 318| Step: 0
Training loss: 1.3958125705977753
Validation loss: 2.2850369307550555

Epoch: 5| Step: 1
Training loss: 1.523451741469892
Validation loss: 2.2928483499592978

Epoch: 5| Step: 2
Training loss: 0.9682652891307723
Validation loss: 2.3368393663356053

Epoch: 5| Step: 3
Training loss: 1.5130992963168433
Validation loss: 2.3274410454697385

Epoch: 5| Step: 4
Training loss: 1.3463993126428293
Validation loss: 2.3490106502100434

Epoch: 5| Step: 5
Training loss: 0.7599520025656971
Validation loss: 2.3525126090704647

Epoch: 5| Step: 6
Training loss: 0.9554985072944195
Validation loss: 2.3598558837289625

Epoch: 5| Step: 7
Training loss: 1.2774793920329153
Validation loss: 2.3515107722833215

Epoch: 5| Step: 8
Training loss: 1.9077066578041355
Validation loss: 2.3124704323042105

Epoch: 5| Step: 9
Training loss: 1.1525891058975404
Validation loss: 2.2891531269797705

Epoch: 5| Step: 10
Training loss: 0.8643041910777177
Validation loss: 2.280218877761279

Epoch: 319| Step: 0
Training loss: 1.296872288344892
Validation loss: 2.255699204517788

Epoch: 5| Step: 1
Training loss: 1.5711656976024233
Validation loss: 2.2735315124493822

Epoch: 5| Step: 2
Training loss: 0.6922505068034931
Validation loss: 2.2694690572910714

Epoch: 5| Step: 3
Training loss: 1.4636534063325985
Validation loss: 2.2720336148461944

Epoch: 5| Step: 4
Training loss: 1.028288142469997
Validation loss: 2.3141779976857846

Epoch: 5| Step: 5
Training loss: 1.3026106516867177
Validation loss: 2.3505991058380884

Epoch: 5| Step: 6
Training loss: 1.3859407203404666
Validation loss: 2.3801300372713055

Epoch: 5| Step: 7
Training loss: 1.1713567986747828
Validation loss: 2.4076002818016153

Epoch: 5| Step: 8
Training loss: 1.0648416072742737
Validation loss: 2.3697389384266447

Epoch: 5| Step: 9
Training loss: 1.6190271648415895
Validation loss: 2.305645911965785

Epoch: 5| Step: 10
Training loss: 1.3716553844638375
Validation loss: 2.2789467064767917

Epoch: 320| Step: 0
Training loss: 1.2359363001300374
Validation loss: 2.2863435585855845

Epoch: 5| Step: 1
Training loss: 1.4377186650360672
Validation loss: 2.2517438702621684

Epoch: 5| Step: 2
Training loss: 0.8006193788258152
Validation loss: 2.250779379259485

Epoch: 5| Step: 3
Training loss: 1.2749674213211482
Validation loss: 2.294934683549963

Epoch: 5| Step: 4
Training loss: 1.231259530897092
Validation loss: 2.3069640086929564

Epoch: 5| Step: 5
Training loss: 1.2195089373603198
Validation loss: 2.354340191790183

Epoch: 5| Step: 6
Training loss: 1.7221674842065877
Validation loss: 2.3564629172700235

Epoch: 5| Step: 7
Training loss: 1.554684892968527
Validation loss: 2.3651034896278778

Epoch: 5| Step: 8
Training loss: 0.96602968544297
Validation loss: 2.317757820540346

Epoch: 5| Step: 9
Training loss: 0.9021458264230724
Validation loss: 2.3244202637204694

Epoch: 5| Step: 10
Training loss: 1.0640534096664236
Validation loss: 2.2826044352171575

Epoch: 321| Step: 0
Training loss: 1.0804665610290551
Validation loss: 2.3191889035347892

Epoch: 5| Step: 1
Training loss: 1.1767725013670887
Validation loss: 2.2975908282483095

Epoch: 5| Step: 2
Training loss: 1.4131379872551582
Validation loss: 2.3175894404066604

Epoch: 5| Step: 3
Training loss: 1.2466897047603482
Validation loss: 2.318626703756022

Epoch: 5| Step: 4
Training loss: 0.8669836131112527
Validation loss: 2.3156585186536303

Epoch: 5| Step: 5
Training loss: 1.157610016078628
Validation loss: 2.286204912090288

Epoch: 5| Step: 6
Training loss: 1.304019825664711
Validation loss: 2.2767435250734196

Epoch: 5| Step: 7
Training loss: 1.8691492987324871
Validation loss: 2.3066132239515005

Epoch: 5| Step: 8
Training loss: 0.9712339059190975
Validation loss: 2.2773452218722405

Epoch: 5| Step: 9
Training loss: 1.189319321195601
Validation loss: 2.2561881652654283

Epoch: 5| Step: 10
Training loss: 0.9169217571149716
Validation loss: 2.2882485980187424

Epoch: 322| Step: 0
Training loss: 1.4500515336711741
Validation loss: 2.2859217469862756

Epoch: 5| Step: 1
Training loss: 1.1211610567842756
Validation loss: 2.3253552493021

Epoch: 5| Step: 2
Training loss: 1.3289205076068413
Validation loss: 2.3058540852559313

Epoch: 5| Step: 3
Training loss: 1.082414249433228
Validation loss: 2.2926133308314838

Epoch: 5| Step: 4
Training loss: 1.2221859158315709
Validation loss: 2.3052322336263185

Epoch: 5| Step: 5
Training loss: 1.3420689735880023
Validation loss: 2.3222061097577105

Epoch: 5| Step: 6
Training loss: 0.9823739133014098
Validation loss: 2.300936307967337

Epoch: 5| Step: 7
Training loss: 1.2335036377128337
Validation loss: 2.3034859432711996

Epoch: 5| Step: 8
Training loss: 1.0304198536178928
Validation loss: 2.2735081235905565

Epoch: 5| Step: 9
Training loss: 1.3261552003421742
Validation loss: 2.2378246819066776

Epoch: 5| Step: 10
Training loss: 1.1372910988945961
Validation loss: 2.241199216294358

Epoch: 323| Step: 0
Training loss: 1.0222674954681135
Validation loss: 2.2652775753741228

Epoch: 5| Step: 1
Training loss: 1.5020221748899327
Validation loss: 2.2558553304193394

Epoch: 5| Step: 2
Training loss: 1.4633325538256632
Validation loss: 2.276227416944134

Epoch: 5| Step: 3
Training loss: 1.2774121560727938
Validation loss: 2.289470932536906

Epoch: 5| Step: 4
Training loss: 0.7661756364915401
Validation loss: 2.334844228243267

Epoch: 5| Step: 5
Training loss: 1.535636302640911
Validation loss: 2.3256889482488172

Epoch: 5| Step: 6
Training loss: 0.9058946702141984
Validation loss: 2.329746925404521

Epoch: 5| Step: 7
Training loss: 1.361399009752761
Validation loss: 2.3085485686840705

Epoch: 5| Step: 8
Training loss: 0.8827607131217182
Validation loss: 2.362191236604548

Epoch: 5| Step: 9
Training loss: 1.0876020668627455
Validation loss: 2.2995244864160043

Epoch: 5| Step: 10
Training loss: 1.1725626644477833
Validation loss: 2.2968135510489107

Epoch: 324| Step: 0
Training loss: 0.9542464865624076
Validation loss: 2.298303064890935

Epoch: 5| Step: 1
Training loss: 1.2389306131720053
Validation loss: 2.2985609043898223

Epoch: 5| Step: 2
Training loss: 1.2285245036909636
Validation loss: 2.29490867986226

Epoch: 5| Step: 3
Training loss: 1.534294527200534
Validation loss: 2.2888264948612136

Epoch: 5| Step: 4
Training loss: 1.0002968466766515
Validation loss: 2.2647552008720466

Epoch: 5| Step: 5
Training loss: 1.384325697389065
Validation loss: 2.3050470320975167

Epoch: 5| Step: 6
Training loss: 1.4476493295914845
Validation loss: 2.296516264876616

Epoch: 5| Step: 7
Training loss: 1.0147146399803815
Validation loss: 2.3025787778831908

Epoch: 5| Step: 8
Training loss: 0.9476700696071194
Validation loss: 2.343163213527032

Epoch: 5| Step: 9
Training loss: 1.2446408785651624
Validation loss: 2.3349738349334817

Epoch: 5| Step: 10
Training loss: 1.1247686042171214
Validation loss: 2.3374376859107984

Epoch: 325| Step: 0
Training loss: 1.074314459958553
Validation loss: 2.3686848623828785

Epoch: 5| Step: 1
Training loss: 1.6938060624532458
Validation loss: 2.3031869081632013

Epoch: 5| Step: 2
Training loss: 1.0057244367733558
Validation loss: 2.293603125552262

Epoch: 5| Step: 3
Training loss: 1.0336784898962748
Validation loss: 2.310824062135231

Epoch: 5| Step: 4
Training loss: 1.1084765167295467
Validation loss: 2.2917624139407367

Epoch: 5| Step: 5
Training loss: 1.1800920916844846
Validation loss: 2.316894369147944

Epoch: 5| Step: 6
Training loss: 0.9616666679007686
Validation loss: 2.3189420536898036

Epoch: 5| Step: 7
Training loss: 0.9847182931688624
Validation loss: 2.326598089618875

Epoch: 5| Step: 8
Training loss: 1.5200603123042857
Validation loss: 2.3666970506971095

Epoch: 5| Step: 9
Training loss: 1.072081336355493
Validation loss: 2.3246160958791675

Epoch: 5| Step: 10
Training loss: 1.3257411431454256
Validation loss: 2.263849425884647

Epoch: 326| Step: 0
Training loss: 1.169474419058395
Validation loss: 2.29571496319522

Epoch: 5| Step: 1
Training loss: 1.313483006344556
Validation loss: 2.226259057107853

Epoch: 5| Step: 2
Training loss: 1.0675285498131362
Validation loss: 2.254052974827252

Epoch: 5| Step: 3
Training loss: 0.8623574263450161
Validation loss: 2.2688434500338484

Epoch: 5| Step: 4
Training loss: 1.0082343940955372
Validation loss: 2.2752251860803376

Epoch: 5| Step: 5
Training loss: 1.5369361091493614
Validation loss: 2.2804032587621066

Epoch: 5| Step: 6
Training loss: 1.2083533493664214
Validation loss: 2.356078341357191

Epoch: 5| Step: 7
Training loss: 1.2074267285785354
Validation loss: 2.3072937703556486

Epoch: 5| Step: 8
Training loss: 1.1377059477607785
Validation loss: 2.36934154030435

Epoch: 5| Step: 9
Training loss: 1.1843742592036766
Validation loss: 2.3825439872055965

Epoch: 5| Step: 10
Training loss: 1.145521861426797
Validation loss: 2.3365788276470965

Epoch: 327| Step: 0
Training loss: 0.9760136702412694
Validation loss: 2.366372275280655

Epoch: 5| Step: 1
Training loss: 0.9173478969193701
Validation loss: 2.3597638704041453

Epoch: 5| Step: 2
Training loss: 1.2613029621599703
Validation loss: 2.3298177765263737

Epoch: 5| Step: 3
Training loss: 1.50515766344506
Validation loss: 2.285655743566878

Epoch: 5| Step: 4
Training loss: 0.9545604028088669
Validation loss: 2.259036832765113

Epoch: 5| Step: 5
Training loss: 0.8723763572834267
Validation loss: 2.2531522946185554

Epoch: 5| Step: 6
Training loss: 1.2801996903817068
Validation loss: 2.2612213642567367

Epoch: 5| Step: 7
Training loss: 1.4762044805603707
Validation loss: 2.232702593001233

Epoch: 5| Step: 8
Training loss: 1.2958481641617827
Validation loss: 2.259253785198101

Epoch: 5| Step: 9
Training loss: 0.998993277444072
Validation loss: 2.2396187239815157

Epoch: 5| Step: 10
Training loss: 1.2279910861477725
Validation loss: 2.277643239237942

Epoch: 328| Step: 0
Training loss: 1.175021157175685
Validation loss: 2.2590634751975944

Epoch: 5| Step: 1
Training loss: 0.9441095059008702
Validation loss: 2.3005811435490893

Epoch: 5| Step: 2
Training loss: 0.987119300710865
Validation loss: 2.318345396546391

Epoch: 5| Step: 3
Training loss: 0.68736588730558
Validation loss: 2.3246469923695066

Epoch: 5| Step: 4
Training loss: 1.2743026977054288
Validation loss: 2.2649130919500893

Epoch: 5| Step: 5
Training loss: 1.4040648118761438
Validation loss: 2.2771169014461137

Epoch: 5| Step: 6
Training loss: 1.480849325336638
Validation loss: 2.237044226681981

Epoch: 5| Step: 7
Training loss: 1.2158181554323235
Validation loss: 2.2170465410171647

Epoch: 5| Step: 8
Training loss: 1.2238456620105318
Validation loss: 2.1968110666013163

Epoch: 5| Step: 9
Training loss: 1.272138155020269
Validation loss: 2.2115173907025043

Epoch: 5| Step: 10
Training loss: 0.9725437329027663
Validation loss: 2.231574931145021

Epoch: 329| Step: 0
Training loss: 0.9721684898938363
Validation loss: 2.259454703850884

Epoch: 5| Step: 1
Training loss: 1.3092375580752071
Validation loss: 2.31289643290537

Epoch: 5| Step: 2
Training loss: 1.1930763420945854
Validation loss: 2.2925426829898043

Epoch: 5| Step: 3
Training loss: 1.1087946918688016
Validation loss: 2.3025552064361587

Epoch: 5| Step: 4
Training loss: 1.0731454932378355
Validation loss: 2.3095194408457225

Epoch: 5| Step: 5
Training loss: 1.1519434864136384
Validation loss: 2.290594917185666

Epoch: 5| Step: 6
Training loss: 1.0417219846660082
Validation loss: 2.2817577089835375

Epoch: 5| Step: 7
Training loss: 1.446297469748944
Validation loss: 2.296890303383796

Epoch: 5| Step: 8
Training loss: 1.1584048425204396
Validation loss: 2.257487200990514

Epoch: 5| Step: 9
Training loss: 1.0625743278983615
Validation loss: 2.2659057850548887

Epoch: 5| Step: 10
Training loss: 1.0794796380600267
Validation loss: 2.257510515653054

Epoch: 330| Step: 0
Training loss: 1.0363057214275861
Validation loss: 2.244762526008632

Epoch: 5| Step: 1
Training loss: 1.436066866786912
Validation loss: 2.2539226424539818

Epoch: 5| Step: 2
Training loss: 1.0902237315189718
Validation loss: 2.2905503008439307

Epoch: 5| Step: 3
Training loss: 1.1433201133104605
Validation loss: 2.286358453674795

Epoch: 5| Step: 4
Training loss: 1.0457463229536743
Validation loss: 2.2854273588019964

Epoch: 5| Step: 5
Training loss: 1.6120095771382
Validation loss: 2.2471357547836566

Epoch: 5| Step: 6
Training loss: 1.2303763218633963
Validation loss: 2.2227387042365563

Epoch: 5| Step: 7
Training loss: 0.9232967856871073
Validation loss: 2.2613200293646076

Epoch: 5| Step: 8
Training loss: 0.7925128847873807
Validation loss: 2.2472060173809867

Epoch: 5| Step: 9
Training loss: 1.090243413239167
Validation loss: 2.2674874904501996

Epoch: 5| Step: 10
Training loss: 1.0674270383392648
Validation loss: 2.285837694738253

Epoch: 331| Step: 0
Training loss: 1.2619783589099036
Validation loss: 2.3437615725870766

Epoch: 5| Step: 1
Training loss: 0.8758355306772627
Validation loss: 2.380460018780294

Epoch: 5| Step: 2
Training loss: 1.0753074539008525
Validation loss: 2.371065856885218

Epoch: 5| Step: 3
Training loss: 0.6657796312987053
Validation loss: 2.266620836648155

Epoch: 5| Step: 4
Training loss: 1.0595791442784286
Validation loss: 2.265808322096546

Epoch: 5| Step: 5
Training loss: 1.2588959760224172
Validation loss: 2.2332986042730654

Epoch: 5| Step: 6
Training loss: 1.207916527693601
Validation loss: 2.215621092744992

Epoch: 5| Step: 7
Training loss: 1.332453864839477
Validation loss: 2.214864872778919

Epoch: 5| Step: 8
Training loss: 1.413133431923641
Validation loss: 2.1971837812378383

Epoch: 5| Step: 9
Training loss: 0.9358636562658055
Validation loss: 2.2163763236691745

Epoch: 5| Step: 10
Training loss: 1.5716826122091279
Validation loss: 2.2946985293596653

Epoch: 332| Step: 0
Training loss: 1.307457319405477
Validation loss: 2.3654540063886764

Epoch: 5| Step: 1
Training loss: 0.8086693769830422
Validation loss: 2.3757170688684415

Epoch: 5| Step: 2
Training loss: 1.0869108818672577
Validation loss: 2.384547407868984

Epoch: 5| Step: 3
Training loss: 1.3335807491265455
Validation loss: 2.321298596799072

Epoch: 5| Step: 4
Training loss: 0.9619880144379829
Validation loss: 2.2928470107510295

Epoch: 5| Step: 5
Training loss: 1.034928782680401
Validation loss: 2.215083784763523

Epoch: 5| Step: 6
Training loss: 1.4607806606048757
Validation loss: 2.2353210775429395

Epoch: 5| Step: 7
Training loss: 1.324671215075162
Validation loss: 2.219835932181572

Epoch: 5| Step: 8
Training loss: 0.9035439044437106
Validation loss: 2.2057092992158043

Epoch: 5| Step: 9
Training loss: 1.0794096217873248
Validation loss: 2.219352599896086

Epoch: 5| Step: 10
Training loss: 0.9405807104487882
Validation loss: 2.2282306725186625

Epoch: 333| Step: 0
Training loss: 1.0932348945737806
Validation loss: 2.217462146557708

Epoch: 5| Step: 1
Training loss: 0.7312751439654165
Validation loss: 2.2712907481917886

Epoch: 5| Step: 2
Training loss: 0.9470995885313016
Validation loss: 2.2935519377449594

Epoch: 5| Step: 3
Training loss: 1.166254322661375
Validation loss: 2.2914913296861066

Epoch: 5| Step: 4
Training loss: 1.30810546875
Validation loss: 2.2927054220308953

Epoch: 5| Step: 5
Training loss: 1.0938203516541507
Validation loss: 2.2417933883130847

Epoch: 5| Step: 6
Training loss: 1.0903571775537337
Validation loss: 2.2405933476918585

Epoch: 5| Step: 7
Training loss: 1.1527169350701243
Validation loss: 2.2372494597460637

Epoch: 5| Step: 8
Training loss: 1.4699461104447653
Validation loss: 2.2458548960901585

Epoch: 5| Step: 9
Training loss: 1.1009303775051293
Validation loss: 2.248946923322906

Epoch: 5| Step: 10
Training loss: 1.1029043479455338
Validation loss: 2.2560229863565446

Epoch: 334| Step: 0
Training loss: 0.9996399231178761
Validation loss: 2.2912026231027385

Epoch: 5| Step: 1
Training loss: 1.2109149069370424
Validation loss: 2.3216034484275654

Epoch: 5| Step: 2
Training loss: 1.1423622383851606
Validation loss: 2.367799422947733

Epoch: 5| Step: 3
Training loss: 1.3295832986491951
Validation loss: 2.360455981488506

Epoch: 5| Step: 4
Training loss: 1.0652443840919112
Validation loss: 2.3242434518173063

Epoch: 5| Step: 5
Training loss: 0.8407555177469538
Validation loss: 2.288518461675411

Epoch: 5| Step: 6
Training loss: 1.1141016564035287
Validation loss: 2.24978532074615

Epoch: 5| Step: 7
Training loss: 1.4935452340845636
Validation loss: 2.2477745606170605

Epoch: 5| Step: 8
Training loss: 1.183367666677719
Validation loss: 2.252991490754051

Epoch: 5| Step: 9
Training loss: 1.0858324398018553
Validation loss: 2.274372109020168

Epoch: 5| Step: 10
Training loss: 0.6505699941375919
Validation loss: 2.276898627949611

Epoch: 335| Step: 0
Training loss: 0.6603569086959048
Validation loss: 2.2564281306156535

Epoch: 5| Step: 1
Training loss: 1.1749320274333936
Validation loss: 2.267757144895004

Epoch: 5| Step: 2
Training loss: 0.8480472278286741
Validation loss: 2.318362093053575

Epoch: 5| Step: 3
Training loss: 1.1311977585168724
Validation loss: 2.305701050275765

Epoch: 5| Step: 4
Training loss: 1.4381581334056794
Validation loss: 2.291559751222266

Epoch: 5| Step: 5
Training loss: 1.0764275055114403
Validation loss: 2.2903474849786596

Epoch: 5| Step: 6
Training loss: 0.9685350610337238
Validation loss: 2.2875075067085073

Epoch: 5| Step: 7
Training loss: 1.0668055866099466
Validation loss: 2.2768546192155226

Epoch: 5| Step: 8
Training loss: 0.8658867092648755
Validation loss: 2.2790053035494373

Epoch: 5| Step: 9
Training loss: 1.0965784829541176
Validation loss: 2.28888516997584

Epoch: 5| Step: 10
Training loss: 1.3968984990202191
Validation loss: 2.2624525581117245

Epoch: 336| Step: 0
Training loss: 1.051337509686003
Validation loss: 2.249833958833102

Epoch: 5| Step: 1
Training loss: 1.0163108270700694
Validation loss: 2.239715265125965

Epoch: 5| Step: 2
Training loss: 1.233482086172172
Validation loss: 2.2548704927086294

Epoch: 5| Step: 3
Training loss: 0.8844940577189347
Validation loss: 2.246023283107634

Epoch: 5| Step: 4
Training loss: 1.0618884626750944
Validation loss: 2.2524884931796167

Epoch: 5| Step: 5
Training loss: 1.091907420558678
Validation loss: 2.2947068720466897

Epoch: 5| Step: 6
Training loss: 1.3178039284911995
Validation loss: 2.2981489113151703

Epoch: 5| Step: 7
Training loss: 0.9172439310887318
Validation loss: 2.3062653766124694

Epoch: 5| Step: 8
Training loss: 1.0233493213667901
Validation loss: 2.3497710442178796

Epoch: 5| Step: 9
Training loss: 1.097019540332782
Validation loss: 2.3254118341264514

Epoch: 5| Step: 10
Training loss: 1.0831136419599936
Validation loss: 2.294537833289824

Epoch: 337| Step: 0
Training loss: 1.4358931973568572
Validation loss: 2.2558921518596162

Epoch: 5| Step: 1
Training loss: 0.9103587175050029
Validation loss: 2.2202375129155416

Epoch: 5| Step: 2
Training loss: 1.2730430038781901
Validation loss: 2.2218216012810426

Epoch: 5| Step: 3
Training loss: 1.1026993965225458
Validation loss: 2.2097757515728396

Epoch: 5| Step: 4
Training loss: 0.8441122478356217
Validation loss: 2.2214138511215475

Epoch: 5| Step: 5
Training loss: 0.9761782386086941
Validation loss: 2.2326542672137077

Epoch: 5| Step: 6
Training loss: 1.3324136492750114
Validation loss: 2.2687371016559217

Epoch: 5| Step: 7
Training loss: 0.9976891400943212
Validation loss: 2.2813362513211666

Epoch: 5| Step: 8
Training loss: 0.7963538242004203
Validation loss: 2.250019253998187

Epoch: 5| Step: 9
Training loss: 1.0198069817104478
Validation loss: 2.27111311701089

Epoch: 5| Step: 10
Training loss: 1.0669925182048041
Validation loss: 2.301703679050188

Epoch: 338| Step: 0
Training loss: 0.8224852714843132
Validation loss: 2.252339860664088

Epoch: 5| Step: 1
Training loss: 0.9767373500695122
Validation loss: 2.2694301844292384

Epoch: 5| Step: 2
Training loss: 1.1485778307651577
Validation loss: 2.238691909096924

Epoch: 5| Step: 3
Training loss: 1.061770413049144
Validation loss: 2.2549735739529937

Epoch: 5| Step: 4
Training loss: 1.0349030382929154
Validation loss: 2.243963265501846

Epoch: 5| Step: 5
Training loss: 1.5517104125420695
Validation loss: 2.240503809292104

Epoch: 5| Step: 6
Training loss: 1.2203814517578078
Validation loss: 2.2066313054247604

Epoch: 5| Step: 7
Training loss: 0.8718330769731449
Validation loss: 2.2026228968566164

Epoch: 5| Step: 8
Training loss: 0.6195351099035948
Validation loss: 2.2119640328489187

Epoch: 5| Step: 9
Training loss: 1.0730458462671681
Validation loss: 2.2071931542024963

Epoch: 5| Step: 10
Training loss: 0.8921793040418545
Validation loss: 2.2316441879746174

Epoch: 339| Step: 0
Training loss: 1.0723067034303286
Validation loss: 2.2511226321311004

Epoch: 5| Step: 1
Training loss: 0.9090536093645916
Validation loss: 2.2511745039928526

Epoch: 5| Step: 2
Training loss: 1.4414615775553927
Validation loss: 2.2674352455600344

Epoch: 5| Step: 3
Training loss: 1.0162164579817439
Validation loss: 2.2702741130975177

Epoch: 5| Step: 4
Training loss: 1.1124360205437263
Validation loss: 2.3031072455854855

Epoch: 5| Step: 5
Training loss: 0.9455234197704688
Validation loss: 2.2658208562249325

Epoch: 5| Step: 6
Training loss: 0.6930981640999602
Validation loss: 2.292624612501352

Epoch: 5| Step: 7
Training loss: 0.859424936404266
Validation loss: 2.253503959422119

Epoch: 5| Step: 8
Training loss: 0.9533790187348367
Validation loss: 2.2669382489400225

Epoch: 5| Step: 9
Training loss: 1.3661036527663717
Validation loss: 2.255566911188741

Epoch: 5| Step: 10
Training loss: 0.7790038435085808
Validation loss: 2.2462855217502122

Epoch: 340| Step: 0
Training loss: 0.884086634662812
Validation loss: 2.2299118362486605

Epoch: 5| Step: 1
Training loss: 1.1503649256997857
Validation loss: 2.2273837210240517

Epoch: 5| Step: 2
Training loss: 0.8806368595404962
Validation loss: 2.212560642496601

Epoch: 5| Step: 3
Training loss: 0.7691578225246933
Validation loss: 2.2237946325979254

Epoch: 5| Step: 4
Training loss: 1.010362990746278
Validation loss: 2.254649977977662

Epoch: 5| Step: 5
Training loss: 1.6303000216146366
Validation loss: 2.3166471475484327

Epoch: 5| Step: 6
Training loss: 0.9539627708292417
Validation loss: 2.3077964262997894

Epoch: 5| Step: 7
Training loss: 0.9201094968567897
Validation loss: 2.312707871149059

Epoch: 5| Step: 8
Training loss: 1.1782599394646347
Validation loss: 2.294662619988132

Epoch: 5| Step: 9
Training loss: 0.9798179077283418
Validation loss: 2.224407498717438

Epoch: 5| Step: 10
Training loss: 0.8349822816853388
Validation loss: 2.2097288966591844

Epoch: 341| Step: 0
Training loss: 0.805980162598869
Validation loss: 2.2223518780686113

Epoch: 5| Step: 1
Training loss: 0.7581651398048056
Validation loss: 2.2433360084146323

Epoch: 5| Step: 2
Training loss: 1.0410175717104804
Validation loss: 2.2815059546932113

Epoch: 5| Step: 3
Training loss: 1.0626878011445393
Validation loss: 2.258335864574187

Epoch: 5| Step: 4
Training loss: 1.1005106022665065
Validation loss: 2.27709692467683

Epoch: 5| Step: 5
Training loss: 0.9916499626665517
Validation loss: 2.2762473996549923

Epoch: 5| Step: 6
Training loss: 1.112291130003389
Validation loss: 2.224285888834225

Epoch: 5| Step: 7
Training loss: 0.830262215340385
Validation loss: 2.2183572079756773

Epoch: 5| Step: 8
Training loss: 1.2507334941298718
Validation loss: 2.214041236129635

Epoch: 5| Step: 9
Training loss: 0.8437312795187037
Validation loss: 2.2185496104437554

Epoch: 5| Step: 10
Training loss: 1.4127095109291197
Validation loss: 2.227379112555548

Epoch: 342| Step: 0
Training loss: 0.7150135359783286
Validation loss: 2.25184965161426

Epoch: 5| Step: 1
Training loss: 0.8828385610869162
Validation loss: 2.2427786514118417

Epoch: 5| Step: 2
Training loss: 0.7941265579681509
Validation loss: 2.232916713132789

Epoch: 5| Step: 3
Training loss: 0.7764530926087342
Validation loss: 2.2506214227118377

Epoch: 5| Step: 4
Training loss: 0.84999843765564
Validation loss: 2.258334595998835

Epoch: 5| Step: 5
Training loss: 1.1067047219072028
Validation loss: 2.2343175909226973

Epoch: 5| Step: 6
Training loss: 0.9563030352876085
Validation loss: 2.2154437071442254

Epoch: 5| Step: 7
Training loss: 1.786252342633686
Validation loss: 2.2214558168936884

Epoch: 5| Step: 8
Training loss: 0.9762409138470363
Validation loss: 2.21124556704915

Epoch: 5| Step: 9
Training loss: 1.0773950953208895
Validation loss: 2.222926548590847

Epoch: 5| Step: 10
Training loss: 0.6714819046516536
Validation loss: 2.2211107482440924

Epoch: 343| Step: 0
Training loss: 1.0580867665340714
Validation loss: 2.2341971595897627

Epoch: 5| Step: 1
Training loss: 1.1021396937438361
Validation loss: 2.261743789838301

Epoch: 5| Step: 2
Training loss: 0.9259601210973285
Validation loss: 2.246265534425466

Epoch: 5| Step: 3
Training loss: 0.8718394009011895
Validation loss: 2.2789130293940585

Epoch: 5| Step: 4
Training loss: 1.0391266308260836
Validation loss: 2.292137615180741

Epoch: 5| Step: 5
Training loss: 1.1417505119795348
Validation loss: 2.282039771399882

Epoch: 5| Step: 6
Training loss: 1.3517889814306754
Validation loss: 2.2930398565147962

Epoch: 5| Step: 7
Training loss: 1.2238730813495384
Validation loss: 2.326921440279978

Epoch: 5| Step: 8
Training loss: 0.5289666528737398
Validation loss: 2.296173448972171

Epoch: 5| Step: 9
Training loss: 0.6697518714089785
Validation loss: 2.2533418228014734

Epoch: 5| Step: 10
Training loss: 0.9010701294447857
Validation loss: 2.246580643636313

Epoch: 344| Step: 0
Training loss: 0.7683159385858043
Validation loss: 2.248344596321869

Epoch: 5| Step: 1
Training loss: 1.1648523096272843
Validation loss: 2.2564714118316833

Epoch: 5| Step: 2
Training loss: 1.0503456318880902
Validation loss: 2.2660764556301602

Epoch: 5| Step: 3
Training loss: 0.8419063346485826
Validation loss: 2.3031318654986985

Epoch: 5| Step: 4
Training loss: 1.0752596164637875
Validation loss: 2.2943751873480287

Epoch: 5| Step: 5
Training loss: 1.0888455102242458
Validation loss: 2.323931106439735

Epoch: 5| Step: 6
Training loss: 0.8419146178849067
Validation loss: 2.3043705292106518

Epoch: 5| Step: 7
Training loss: 1.250548909783175
Validation loss: 2.3192409663722917

Epoch: 5| Step: 8
Training loss: 0.8172912911025199
Validation loss: 2.2917320864858817

Epoch: 5| Step: 9
Training loss: 1.0962527931203894
Validation loss: 2.211904127404757

Epoch: 5| Step: 10
Training loss: 0.96284128801642
Validation loss: 2.1715476786178414

Epoch: 345| Step: 0
Training loss: 0.9470622365414073
Validation loss: 2.200497829207551

Epoch: 5| Step: 1
Training loss: 1.1761961550250983
Validation loss: 2.162923090361324

Epoch: 5| Step: 2
Training loss: 0.8554242266212359
Validation loss: 2.1982766415396893

Epoch: 5| Step: 3
Training loss: 0.9870734693958388
Validation loss: 2.2403261201113067

Epoch: 5| Step: 4
Training loss: 1.0269351044964068
Validation loss: 2.3553715046732737

Epoch: 5| Step: 5
Training loss: 1.1453915119889746
Validation loss: 2.391541758516947

Epoch: 5| Step: 6
Training loss: 0.7458429364344498
Validation loss: 2.408553679708438

Epoch: 5| Step: 7
Training loss: 0.8461992601315234
Validation loss: 2.3426462868437574

Epoch: 5| Step: 8
Training loss: 0.80303084567435
Validation loss: 2.2961488610743346

Epoch: 5| Step: 9
Training loss: 1.433289706135458
Validation loss: 2.264012049356738

Epoch: 5| Step: 10
Training loss: 1.1831945369253878
Validation loss: 2.2389603908643037

Epoch: 346| Step: 0
Training loss: 0.8312465925792181
Validation loss: 2.188804973202576

Epoch: 5| Step: 1
Training loss: 0.8993526607599408
Validation loss: 2.190125431868001

Epoch: 5| Step: 2
Training loss: 0.8434802436527457
Validation loss: 2.197011955539969

Epoch: 5| Step: 3
Training loss: 1.05262622737779
Validation loss: 2.2416828209677337

Epoch: 5| Step: 4
Training loss: 1.0010176487375766
Validation loss: 2.2418584265914894

Epoch: 5| Step: 5
Training loss: 1.3886191227975935
Validation loss: 2.3151897960555763

Epoch: 5| Step: 6
Training loss: 1.0410651504731114
Validation loss: 2.3235546354159036

Epoch: 5| Step: 7
Training loss: 0.9879300243504866
Validation loss: 2.2742945482762678

Epoch: 5| Step: 8
Training loss: 1.144503179733239
Validation loss: 2.229005240973577

Epoch: 5| Step: 9
Training loss: 1.09875178392285
Validation loss: 2.2535304511211125

Epoch: 5| Step: 10
Training loss: 0.7225552050081452
Validation loss: 2.2109953920814824

Epoch: 347| Step: 0
Training loss: 1.3241349365357062
Validation loss: 2.1981511898994426

Epoch: 5| Step: 1
Training loss: 0.7087305208250784
Validation loss: 2.22855658736785

Epoch: 5| Step: 2
Training loss: 0.8647071489280562
Validation loss: 2.2040255406501874

Epoch: 5| Step: 3
Training loss: 0.7877598575978884
Validation loss: 2.2387746871083896

Epoch: 5| Step: 4
Training loss: 0.8164379716030926
Validation loss: 2.250996214159999

Epoch: 5| Step: 5
Training loss: 1.187721633305825
Validation loss: 2.3199040703341094

Epoch: 5| Step: 6
Training loss: 1.144628995816133
Validation loss: 2.375661672530163

Epoch: 5| Step: 7
Training loss: 1.044697161603292
Validation loss: 2.2375113076718134

Epoch: 5| Step: 8
Training loss: 1.4481791343004475
Validation loss: 2.215841919991725

Epoch: 5| Step: 9
Training loss: 0.8234429346589291
Validation loss: 2.2071430642243275

Epoch: 5| Step: 10
Training loss: 0.6273309632704851
Validation loss: 2.1957303419063345

Epoch: 348| Step: 0
Training loss: 0.600718761116063
Validation loss: 2.1899681277804386

Epoch: 5| Step: 1
Training loss: 0.5248682197301844
Validation loss: 2.2540346810934344

Epoch: 5| Step: 2
Training loss: 0.963250083450088
Validation loss: 2.2898787873057205

Epoch: 5| Step: 3
Training loss: 0.8675136811884311
Validation loss: 2.3214313406997062

Epoch: 5| Step: 4
Training loss: 1.1266472730340598
Validation loss: 2.3190332629594486

Epoch: 5| Step: 5
Training loss: 1.2356640326316906
Validation loss: 2.2577003144276424

Epoch: 5| Step: 6
Training loss: 1.4344011158944687
Validation loss: 2.2557230212436314

Epoch: 5| Step: 7
Training loss: 0.7147178747530284
Validation loss: 2.2133572764509464

Epoch: 5| Step: 8
Training loss: 0.9231596578756777
Validation loss: 2.2291118886122905

Epoch: 5| Step: 9
Training loss: 1.060147373553049
Validation loss: 2.207204334711193

Epoch: 5| Step: 10
Training loss: 0.9860273752493949
Validation loss: 2.1936409704778272

Epoch: 349| Step: 0
Training loss: 1.0571891785105687
Validation loss: 2.183322374004346

Epoch: 5| Step: 1
Training loss: 1.4301632782613258
Validation loss: 2.1938507576036503

Epoch: 5| Step: 2
Training loss: 1.0524157323198557
Validation loss: 2.21641897356154

Epoch: 5| Step: 3
Training loss: 0.932355977971215
Validation loss: 2.2027882243168224

Epoch: 5| Step: 4
Training loss: 0.8844463117445057
Validation loss: 2.2050106624981396

Epoch: 5| Step: 5
Training loss: 1.0299705891900786
Validation loss: 2.2634750433950193

Epoch: 5| Step: 6
Training loss: 0.9637003003378734
Validation loss: 2.2599505976131433

Epoch: 5| Step: 7
Training loss: 0.6897329351603154
Validation loss: 2.293723254894363

Epoch: 5| Step: 8
Training loss: 0.5279112411477149
Validation loss: 2.2839623931641464

Epoch: 5| Step: 9
Training loss: 0.8878610454151757
Validation loss: 2.32834837302286

Epoch: 5| Step: 10
Training loss: 1.143896245726394
Validation loss: 2.300264456161572

Epoch: 350| Step: 0
Training loss: 0.5135961556559626
Validation loss: 2.2067185668553497

Epoch: 5| Step: 1
Training loss: 0.8478448543709411
Validation loss: 2.1751955725417687

Epoch: 5| Step: 2
Training loss: 1.3038683392662973
Validation loss: 2.159156054921964

Epoch: 5| Step: 3
Training loss: 0.9642576221128217
Validation loss: 2.185362522484441

Epoch: 5| Step: 4
Training loss: 1.1567076215629952
Validation loss: 2.168897139363746

Epoch: 5| Step: 5
Training loss: 0.8207439196405247
Validation loss: 2.1942184951822186

Epoch: 5| Step: 6
Training loss: 0.6522312409922597
Validation loss: 2.2593666992525194

Epoch: 5| Step: 7
Training loss: 1.1526967687881042
Validation loss: 2.2560246329328195

Epoch: 5| Step: 8
Training loss: 0.9509120954566871
Validation loss: 2.2978030471425575

Epoch: 5| Step: 9
Training loss: 1.0500745701422813
Validation loss: 2.351472652780564

Epoch: 5| Step: 10
Training loss: 0.8754186310005452
Validation loss: 2.321065781056465

Epoch: 351| Step: 0
Training loss: 0.965666663249416
Validation loss: 2.278720368509629

Epoch: 5| Step: 1
Training loss: 0.978196143344849
Validation loss: 2.224596324027687

Epoch: 5| Step: 2
Training loss: 0.5678943947417526
Validation loss: 2.1905963565053312

Epoch: 5| Step: 3
Training loss: 0.9848231551885569
Validation loss: 2.208272094558521

Epoch: 5| Step: 4
Training loss: 1.1602384493186493
Validation loss: 2.2259552569956016

Epoch: 5| Step: 5
Training loss: 1.013335126093065
Validation loss: 2.2235692679995664

Epoch: 5| Step: 6
Training loss: 0.7112674995240619
Validation loss: 2.26672313132463

Epoch: 5| Step: 7
Training loss: 1.2964823944361707
Validation loss: 2.3167501502562327

Epoch: 5| Step: 8
Training loss: 0.9898562941625727
Validation loss: 2.3296891143633234

Epoch: 5| Step: 9
Training loss: 0.7081524720885526
Validation loss: 2.2719974493681563

Epoch: 5| Step: 10
Training loss: 0.7518496751840769
Validation loss: 2.264993262554955

Epoch: 352| Step: 0
Training loss: 0.7924537301620735
Validation loss: 2.273032157319412

Epoch: 5| Step: 1
Training loss: 0.8913971749193985
Validation loss: 2.2668584162818317

Epoch: 5| Step: 2
Training loss: 1.1349381596359402
Validation loss: 2.2588660774650005

Epoch: 5| Step: 3
Training loss: 0.7901387570243724
Validation loss: 2.2403663813575716

Epoch: 5| Step: 4
Training loss: 0.5800374848486073
Validation loss: 2.220878593348254

Epoch: 5| Step: 5
Training loss: 1.081681177681648
Validation loss: 2.226923562009063

Epoch: 5| Step: 6
Training loss: 1.4871774019113724
Validation loss: 2.234687986911528

Epoch: 5| Step: 7
Training loss: 0.5261992857320325
Validation loss: 2.2400598345806104

Epoch: 5| Step: 8
Training loss: 0.6417620035868578
Validation loss: 2.2387254216947703

Epoch: 5| Step: 9
Training loss: 0.5088045260665923
Validation loss: 2.247412054352956

Epoch: 5| Step: 10
Training loss: 1.0548217122902492
Validation loss: 2.2626494469396583

Epoch: 353| Step: 0
Training loss: 0.874955244282109
Validation loss: 2.2657380706328634

Epoch: 5| Step: 1
Training loss: 0.9674666733632759
Validation loss: 2.2963866121356897

Epoch: 5| Step: 2
Training loss: 0.9093661173488267
Validation loss: 2.3349120129027225

Epoch: 5| Step: 3
Training loss: 0.66983343046589
Validation loss: 2.304344922371988

Epoch: 5| Step: 4
Training loss: 0.8542239394796967
Validation loss: 2.257835922009017

Epoch: 5| Step: 5
Training loss: 1.050995475174939
Validation loss: 2.247288298114478

Epoch: 5| Step: 6
Training loss: 1.0044973095506076
Validation loss: 2.226981698718299

Epoch: 5| Step: 7
Training loss: 0.7831833758444616
Validation loss: 2.212521688050149

Epoch: 5| Step: 8
Training loss: 0.7470305388590259
Validation loss: 2.2223498108684523

Epoch: 5| Step: 9
Training loss: 0.8736901015241513
Validation loss: 2.222565826347742

Epoch: 5| Step: 10
Training loss: 1.2645726950803908
Validation loss: 2.207240845774342

Epoch: 354| Step: 0
Training loss: 0.49347433772899507
Validation loss: 2.2321886744623907

Epoch: 5| Step: 1
Training loss: 0.9252048098153394
Validation loss: 2.249581104283667

Epoch: 5| Step: 2
Training loss: 1.023577032696618
Validation loss: 2.259565448774809

Epoch: 5| Step: 3
Training loss: 0.6023494972518858
Validation loss: 2.3164053911759046

Epoch: 5| Step: 4
Training loss: 1.167424103681715
Validation loss: 2.270761173934827

Epoch: 5| Step: 5
Training loss: 0.8832162929466048
Validation loss: 2.2736141461956643

Epoch: 5| Step: 6
Training loss: 1.0428626760197894
Validation loss: 2.214216938323965

Epoch: 5| Step: 7
Training loss: 0.7471622584988182
Validation loss: 2.2098809792129064

Epoch: 5| Step: 8
Training loss: 1.1152433004205833
Validation loss: 2.209953604882004

Epoch: 5| Step: 9
Training loss: 0.7860730640144046
Validation loss: 2.2130451905602633

Epoch: 5| Step: 10
Training loss: 0.7544584870619447
Validation loss: 2.1895380350100053

Epoch: 355| Step: 0
Training loss: 0.7361503811523885
Validation loss: 2.1866814636208285

Epoch: 5| Step: 1
Training loss: 0.7397769531259282
Validation loss: 2.261728266780763

Epoch: 5| Step: 2
Training loss: 1.1190099723139748
Validation loss: 2.257861523799103

Epoch: 5| Step: 3
Training loss: 0.9282718426687312
Validation loss: 2.2480517113707896

Epoch: 5| Step: 4
Training loss: 1.0748574317608128
Validation loss: 2.3273304455197272

Epoch: 5| Step: 5
Training loss: 0.9935981454525562
Validation loss: 2.296726280868509

Epoch: 5| Step: 6
Training loss: 0.8553830108178267
Validation loss: 2.2151060047310187

Epoch: 5| Step: 7
Training loss: 0.8782964328660857
Validation loss: 2.2189302303374623

Epoch: 5| Step: 8
Training loss: 0.9060373385611006
Validation loss: 2.163083641810097

Epoch: 5| Step: 9
Training loss: 0.5927602901603292
Validation loss: 2.225374575521071

Epoch: 5| Step: 10
Training loss: 0.7291152163927743
Validation loss: 2.198543607495332

Epoch: 356| Step: 0
Training loss: 0.8481138198554181
Validation loss: 2.1936021919380484

Epoch: 5| Step: 1
Training loss: 0.8629552303251851
Validation loss: 2.2062817673718778

Epoch: 5| Step: 2
Training loss: 0.9336308428047413
Validation loss: 2.195024536500787

Epoch: 5| Step: 3
Training loss: 0.8381887407977052
Validation loss: 2.233827186031934

Epoch: 5| Step: 4
Training loss: 0.5447635215457169
Validation loss: 2.24070949375966

Epoch: 5| Step: 5
Training loss: 1.0154998702213989
Validation loss: 2.2580042767290345

Epoch: 5| Step: 6
Training loss: 0.9342564102495997
Validation loss: 2.2487894582273187

Epoch: 5| Step: 7
Training loss: 0.5738329986510722
Validation loss: 2.214221861323006

Epoch: 5| Step: 8
Training loss: 1.1818219510765255
Validation loss: 2.224164053301893

Epoch: 5| Step: 9
Training loss: 0.8296029559665831
Validation loss: 2.2550118033021063

Epoch: 5| Step: 10
Training loss: 0.8550047988087687
Validation loss: 2.2243594502674653

Epoch: 357| Step: 0
Training loss: 0.9264857834550269
Validation loss: 2.2675489969797455

Epoch: 5| Step: 1
Training loss: 0.8386382921990368
Validation loss: 2.230170399930719

Epoch: 5| Step: 2
Training loss: 0.9712926045699729
Validation loss: 2.2379303301879214

Epoch: 5| Step: 3
Training loss: 0.8391929056282295
Validation loss: 2.2401065969675833

Epoch: 5| Step: 4
Training loss: 0.5964366711400195
Validation loss: 2.2284870850305794

Epoch: 5| Step: 5
Training loss: 0.8160020475595627
Validation loss: 2.2643384302393734

Epoch: 5| Step: 6
Training loss: 1.0770147937583896
Validation loss: 2.2191666843413276

Epoch: 5| Step: 7
Training loss: 0.5764847762487328
Validation loss: 2.262770211824377

Epoch: 5| Step: 8
Training loss: 0.7349679865969174
Validation loss: 2.2408515637940734

Epoch: 5| Step: 9
Training loss: 0.5320952367185484
Validation loss: 2.248838795003582

Epoch: 5| Step: 10
Training loss: 1.2685338254274745
Validation loss: 2.243998134855959

Epoch: 358| Step: 0
Training loss: 0.8891330067544767
Validation loss: 2.213189258837478

Epoch: 5| Step: 1
Training loss: 0.7351465838746463
Validation loss: 2.2206685669455313

Epoch: 5| Step: 2
Training loss: 0.6426172679353599
Validation loss: 2.259444185824581

Epoch: 5| Step: 3
Training loss: 1.1969950682969508
Validation loss: 2.2471434532136865

Epoch: 5| Step: 4
Training loss: 0.786370434596353
Validation loss: 2.2403853742898243

Epoch: 5| Step: 5
Training loss: 1.177261941012816
Validation loss: 2.2562324123511197

Epoch: 5| Step: 6
Training loss: 0.633739475373527
Validation loss: 2.2416354275748556

Epoch: 5| Step: 7
Training loss: 0.5795975566501861
Validation loss: 2.2060968367902762

Epoch: 5| Step: 8
Training loss: 0.4833374447346257
Validation loss: 2.2146933081793856

Epoch: 5| Step: 9
Training loss: 0.8207275430568286
Validation loss: 2.175691006210739

Epoch: 5| Step: 10
Training loss: 1.002805767185318
Validation loss: 2.1899534257989774

Epoch: 359| Step: 0
Training loss: 1.1427791581624354
Validation loss: 2.1801712899444925

Epoch: 5| Step: 1
Training loss: 0.8025700384694564
Validation loss: 2.211101117050273

Epoch: 5| Step: 2
Training loss: 0.8550006160399242
Validation loss: 2.2217070802381196

Epoch: 5| Step: 3
Training loss: 1.1952447809720987
Validation loss: 2.2478299677263505

Epoch: 5| Step: 4
Training loss: 0.6364737665414443
Validation loss: 2.2472385474129704

Epoch: 5| Step: 5
Training loss: 0.8241765883812487
Validation loss: 2.261004030861012

Epoch: 5| Step: 6
Training loss: 0.5546875805921899
Validation loss: 2.262857900523767

Epoch: 5| Step: 7
Training loss: 0.7683553473517817
Validation loss: 2.2425967167459757

Epoch: 5| Step: 8
Training loss: 0.7098820995439952
Validation loss: 2.2398213215491722

Epoch: 5| Step: 9
Training loss: 0.7252144151180739
Validation loss: 2.23298287847691

Epoch: 5| Step: 10
Training loss: 0.7556312867463931
Validation loss: 2.1871006596733373

Epoch: 360| Step: 0
Training loss: 0.7682593819231255
Validation loss: 2.161897803852465

Epoch: 5| Step: 1
Training loss: 1.0677764250589836
Validation loss: 2.1898325167246115

Epoch: 5| Step: 2
Training loss: 0.6388445746100155
Validation loss: 2.197873463332666

Epoch: 5| Step: 3
Training loss: 1.3380507324647808
Validation loss: 2.2125744654565946

Epoch: 5| Step: 4
Training loss: 0.7351565970116991
Validation loss: 2.2582534738079323

Epoch: 5| Step: 5
Training loss: 0.6398665194716062
Validation loss: 2.2732386088872776

Epoch: 5| Step: 6
Training loss: 0.8028861317736672
Validation loss: 2.278940499140634

Epoch: 5| Step: 7
Training loss: 0.5892376849182767
Validation loss: 2.299042282565222

Epoch: 5| Step: 8
Training loss: 0.5558757948444054
Validation loss: 2.2715074551431993

Epoch: 5| Step: 9
Training loss: 0.8558869406623638
Validation loss: 2.2587405724138057

Epoch: 5| Step: 10
Training loss: 0.9120294180546619
Validation loss: 2.24310797440423

Epoch: 361| Step: 0
Training loss: 0.7160381074279933
Validation loss: 2.250811912318454

Epoch: 5| Step: 1
Training loss: 0.6352891377114126
Validation loss: 2.2329220076494654

Epoch: 5| Step: 2
Training loss: 0.9817397553696471
Validation loss: 2.234867856505361

Epoch: 5| Step: 3
Training loss: 0.8570553771859164
Validation loss: 2.2436595079620343

Epoch: 5| Step: 4
Training loss: 0.9507813640961151
Validation loss: 2.2854446592336712

Epoch: 5| Step: 5
Training loss: 1.0691227669944
Validation loss: 2.2522512678849838

Epoch: 5| Step: 6
Training loss: 0.6752137022463124
Validation loss: 2.251683651204641

Epoch: 5| Step: 7
Training loss: 0.9385660785770165
Validation loss: 2.2344218592739393

Epoch: 5| Step: 8
Training loss: 0.7801120863366592
Validation loss: 2.287312746982481

Epoch: 5| Step: 9
Training loss: 0.9513697800182964
Validation loss: 2.2751325924077177

Epoch: 5| Step: 10
Training loss: 0.5925676720840798
Validation loss: 2.241821481000654

Epoch: 362| Step: 0
Training loss: 0.8645040215265781
Validation loss: 2.2593040213588735

Epoch: 5| Step: 1
Training loss: 0.7440865564602978
Validation loss: 2.265133902309105

Epoch: 5| Step: 2
Training loss: 0.7002764539110514
Validation loss: 2.2919203024048613

Epoch: 5| Step: 3
Training loss: 1.172094807673184
Validation loss: 2.2630499497786203

Epoch: 5| Step: 4
Training loss: 0.7914943423861196
Validation loss: 2.2807195088500394

Epoch: 5| Step: 5
Training loss: 0.9443366317983164
Validation loss: 2.2726091243614985

Epoch: 5| Step: 6
Training loss: 0.7021535308186269
Validation loss: 2.243274565979867

Epoch: 5| Step: 7
Training loss: 0.8708399244603561
Validation loss: 2.215280491838432

Epoch: 5| Step: 8
Training loss: 0.9115073853872043
Validation loss: 2.234841969510243

Epoch: 5| Step: 9
Training loss: 0.79799330536704
Validation loss: 2.245853811095301

Epoch: 5| Step: 10
Training loss: 0.4798346265883848
Validation loss: 2.2724245774476244

Epoch: 363| Step: 0
Training loss: 1.224144611657687
Validation loss: 2.272753743887306

Epoch: 5| Step: 1
Training loss: 0.7747287183154675
Validation loss: 2.297985410931536

Epoch: 5| Step: 2
Training loss: 0.7689117028969966
Validation loss: 2.259620593994284

Epoch: 5| Step: 3
Training loss: 0.7595086533465973
Validation loss: 2.257429421198412

Epoch: 5| Step: 4
Training loss: 0.9112020877125965
Validation loss: 2.213444296464486

Epoch: 5| Step: 5
Training loss: 0.842391899089951
Validation loss: 2.194618940868593

Epoch: 5| Step: 6
Training loss: 0.6538637692087345
Validation loss: 2.1781289314397787

Epoch: 5| Step: 7
Training loss: 0.5959014562419697
Validation loss: 2.2036189719181785

Epoch: 5| Step: 8
Training loss: 0.7809923891680869
Validation loss: 2.2017287571266575

Epoch: 5| Step: 9
Training loss: 0.877322622505084
Validation loss: 2.1862590709685645

Epoch: 5| Step: 10
Training loss: 0.8069880663238757
Validation loss: 2.200646387052159

Epoch: 364| Step: 0
Training loss: 1.0373253319104005
Validation loss: 2.2273852149760804

Epoch: 5| Step: 1
Training loss: 0.5982633511607338
Validation loss: 2.2213078910586286

Epoch: 5| Step: 2
Training loss: 0.8371874297150187
Validation loss: 2.244879356833591

Epoch: 5| Step: 3
Training loss: 1.0188777773242097
Validation loss: 2.2333872308626628

Epoch: 5| Step: 4
Training loss: 0.7844639853044926
Validation loss: 2.222324555571976

Epoch: 5| Step: 5
Training loss: 0.680533047604476
Validation loss: 2.191005279735571

Epoch: 5| Step: 6
Training loss: 1.0257772824747446
Validation loss: 2.1894057859880065

Epoch: 5| Step: 7
Training loss: 0.7022160058544478
Validation loss: 2.227117018416745

Epoch: 5| Step: 8
Training loss: 0.6646213872372633
Validation loss: 2.240569407327373

Epoch: 5| Step: 9
Training loss: 0.6383053722515887
Validation loss: 2.262398704591346

Epoch: 5| Step: 10
Training loss: 0.8858778743425441
Validation loss: 2.319632082310985

Epoch: 365| Step: 0
Training loss: 0.3724711504267653
Validation loss: 2.267109999726395

Epoch: 5| Step: 1
Training loss: 0.9507922094335659
Validation loss: 2.2835384975830086

Epoch: 5| Step: 2
Training loss: 0.5660087506052524
Validation loss: 2.264120104674941

Epoch: 5| Step: 3
Training loss: 0.8433486195700487
Validation loss: 2.236110342379715

Epoch: 5| Step: 4
Training loss: 1.0830830994176488
Validation loss: 2.228405628666023

Epoch: 5| Step: 5
Training loss: 0.7648088036133228
Validation loss: 2.2601781539400334

Epoch: 5| Step: 6
Training loss: 0.750006755162653
Validation loss: 2.199877641907222

Epoch: 5| Step: 7
Training loss: 0.9664916202025988
Validation loss: 2.204268098518728

Epoch: 5| Step: 8
Training loss: 0.7675222905553484
Validation loss: 2.2223030526405005

Epoch: 5| Step: 9
Training loss: 0.6599737964832583
Validation loss: 2.2224894775232333

Epoch: 5| Step: 10
Training loss: 0.7316154007196404
Validation loss: 2.2005714268458814

Epoch: 366| Step: 0
Training loss: 0.8455451306773859
Validation loss: 2.2258152149367367

Epoch: 5| Step: 1
Training loss: 1.111304525919252
Validation loss: 2.249268172370866

Epoch: 5| Step: 2
Training loss: 0.6120614233265563
Validation loss: 2.261214895118145

Epoch: 5| Step: 3
Training loss: 0.772346497750184
Validation loss: 2.2421908837887043

Epoch: 5| Step: 4
Training loss: 0.8621284417073612
Validation loss: 2.2672069518845803

Epoch: 5| Step: 5
Training loss: 0.9423879356442674
Validation loss: 2.2590101344107003

Epoch: 5| Step: 6
Training loss: 0.6784601859820396
Validation loss: 2.2801428420512324

Epoch: 5| Step: 7
Training loss: 0.6809807674112052
Validation loss: 2.261257255962173

Epoch: 5| Step: 8
Training loss: 0.7281061816751168
Validation loss: 2.2473650176269158

Epoch: 5| Step: 9
Training loss: 0.5460217768182981
Validation loss: 2.2287187384062532

Epoch: 5| Step: 10
Training loss: 0.7580506648566799
Validation loss: 2.189148235352676

Epoch: 367| Step: 0
Training loss: 0.947278964548472
Validation loss: 2.1747398942763043

Epoch: 5| Step: 1
Training loss: 0.6957469183167866
Validation loss: 2.205122093219308

Epoch: 5| Step: 2
Training loss: 1.1099629523134649
Validation loss: 2.209455263935846

Epoch: 5| Step: 3
Training loss: 0.6390436472828387
Validation loss: 2.248175392230968

Epoch: 5| Step: 4
Training loss: 0.8918147589502338
Validation loss: 2.2661262136018574

Epoch: 5| Step: 5
Training loss: 0.7336992035655441
Validation loss: 2.2814801637045212

Epoch: 5| Step: 6
Training loss: 0.8073871104927799
Validation loss: 2.272598805968478

Epoch: 5| Step: 7
Training loss: 0.39673781163988747
Validation loss: 2.2839642957213337

Epoch: 5| Step: 8
Training loss: 0.8337751210902018
Validation loss: 2.240156060314803

Epoch: 5| Step: 9
Training loss: 0.8901299556406199
Validation loss: 2.2347190844989333

Epoch: 5| Step: 10
Training loss: 0.5764087771874503
Validation loss: 2.2413766932864574

Epoch: 368| Step: 0
Training loss: 0.9361810306870797
Validation loss: 2.227750875061184

Epoch: 5| Step: 1
Training loss: 0.6454405410501399
Validation loss: 2.2412489866710095

Epoch: 5| Step: 2
Training loss: 0.7885318142381669
Validation loss: 2.2621782437452738

Epoch: 5| Step: 3
Training loss: 0.9879983187885112
Validation loss: 2.251720775398821

Epoch: 5| Step: 4
Training loss: 0.5993058371392811
Validation loss: 2.268354488981585

Epoch: 5| Step: 5
Training loss: 0.7391100878244242
Validation loss: 2.256452974669139

Epoch: 5| Step: 6
Training loss: 0.8924756147755832
Validation loss: 2.260285788574372

Epoch: 5| Step: 7
Training loss: 0.751624018001248
Validation loss: 2.293329562023777

Epoch: 5| Step: 8
Training loss: 0.7707190471847042
Validation loss: 2.2276458528336764

Epoch: 5| Step: 9
Training loss: 0.7611515770161172
Validation loss: 2.23639044837141

Epoch: 5| Step: 10
Training loss: 0.6061427149277514
Validation loss: 2.2536920958403455

Epoch: 369| Step: 0
Training loss: 0.8019980884847906
Validation loss: 2.1788706256423542

Epoch: 5| Step: 1
Training loss: 0.5896449733049868
Validation loss: 2.2399758256612716

Epoch: 5| Step: 2
Training loss: 0.6409515386017636
Validation loss: 2.223559168227415

Epoch: 5| Step: 3
Training loss: 0.9404935092205183
Validation loss: 2.2250269887388168

Epoch: 5| Step: 4
Training loss: 0.7358931412661411
Validation loss: 2.2545742448970048

Epoch: 5| Step: 5
Training loss: 0.6786765110423558
Validation loss: 2.285921745304039

Epoch: 5| Step: 6
Training loss: 0.7407504977360733
Validation loss: 2.3107361079126463

Epoch: 5| Step: 7
Training loss: 0.7669847053335791
Validation loss: 2.3596378248753793

Epoch: 5| Step: 8
Training loss: 1.1177782217586925
Validation loss: 2.3355456059269644

Epoch: 5| Step: 9
Training loss: 0.6213443418516392
Validation loss: 2.3238996819449684

Epoch: 5| Step: 10
Training loss: 0.7523855179930695
Validation loss: 2.3279983228372543

Epoch: 370| Step: 0
Training loss: 0.8960046752186123
Validation loss: 2.3002574682471355

Epoch: 5| Step: 1
Training loss: 0.6993144944773063
Validation loss: 2.305435642666303

Epoch: 5| Step: 2
Training loss: 0.7337147605791113
Validation loss: 2.238798074688726

Epoch: 5| Step: 3
Training loss: 0.7253926200613299
Validation loss: 2.235024123067958

Epoch: 5| Step: 4
Training loss: 0.5786564420545349
Validation loss: 2.2195951904930538

Epoch: 5| Step: 5
Training loss: 0.8719454309598957
Validation loss: 2.241069639525999

Epoch: 5| Step: 6
Training loss: 0.6930762559143274
Validation loss: 2.2085265723032856

Epoch: 5| Step: 7
Training loss: 0.7133710522646882
Validation loss: 2.240912926801824

Epoch: 5| Step: 8
Training loss: 0.7026858123742745
Validation loss: 2.2613351703386577

Epoch: 5| Step: 9
Training loss: 1.0773588028728236
Validation loss: 2.297961254641344

Epoch: 5| Step: 10
Training loss: 0.6845954531244751
Validation loss: 2.294798062592726

Epoch: 371| Step: 0
Training loss: 0.9674429536112847
Validation loss: 2.2482839099290692

Epoch: 5| Step: 1
Training loss: 0.6699216525686357
Validation loss: 2.272962733672522

Epoch: 5| Step: 2
Training loss: 0.5262564009958997
Validation loss: 2.246334809666821

Epoch: 5| Step: 3
Training loss: 1.1033601094268923
Validation loss: 2.2729964898928516

Epoch: 5| Step: 4
Training loss: 0.9332852991266323
Validation loss: 2.241001790500339

Epoch: 5| Step: 5
Training loss: 0.7533281313525276
Validation loss: 2.2683322051847012

Epoch: 5| Step: 6
Training loss: 0.6751771111720636
Validation loss: 2.247562381220361

Epoch: 5| Step: 7
Training loss: 0.5226164684352009
Validation loss: 2.2603473345532894

Epoch: 5| Step: 8
Training loss: 0.4978309312798031
Validation loss: 2.271002042279226

Epoch: 5| Step: 9
Training loss: 0.5941679136290803
Validation loss: 2.230972190983559

Epoch: 5| Step: 10
Training loss: 0.7837680672201246
Validation loss: 2.23770267214653

Epoch: 372| Step: 0
Training loss: 0.44306315807003616
Validation loss: 2.2794497808464302

Epoch: 5| Step: 1
Training loss: 0.7809336594040285
Validation loss: 2.272817624375961

Epoch: 5| Step: 2
Training loss: 0.7016432089142665
Validation loss: 2.2809223968646166

Epoch: 5| Step: 3
Training loss: 0.855056942276131
Validation loss: 2.257296414966112

Epoch: 5| Step: 4
Training loss: 0.7190850762209708
Validation loss: 2.2191718331808166

Epoch: 5| Step: 5
Training loss: 0.580967180090008
Validation loss: 2.2216453131110545

Epoch: 5| Step: 6
Training loss: 0.7733008138695003
Validation loss: 2.184873941309315

Epoch: 5| Step: 7
Training loss: 0.826228507335176
Validation loss: 2.1772595415864022

Epoch: 5| Step: 8
Training loss: 0.7541837428637869
Validation loss: 2.1933769376075714

Epoch: 5| Step: 9
Training loss: 0.7163947117998483
Validation loss: 2.208804381761161

Epoch: 5| Step: 10
Training loss: 1.018576105172411
Validation loss: 2.3172535185389163

Epoch: 373| Step: 0
Training loss: 0.9778975859184984
Validation loss: 2.2472409447943824

Epoch: 5| Step: 1
Training loss: 0.7630538586097453
Validation loss: 2.25092759034069

Epoch: 5| Step: 2
Training loss: 0.4749142958470371
Validation loss: 2.256804355746773

Epoch: 5| Step: 3
Training loss: 0.8338729819740989
Validation loss: 2.231761828445171

Epoch: 5| Step: 4
Training loss: 0.6521723859102226
Validation loss: 2.227490310490427

Epoch: 5| Step: 5
Training loss: 0.755083420168036
Validation loss: 2.2537985236903912

Epoch: 5| Step: 6
Training loss: 0.5569031481152639
Validation loss: 2.2170525452600742

Epoch: 5| Step: 7
Training loss: 0.7571342815443056
Validation loss: 2.2672425879884326

Epoch: 5| Step: 8
Training loss: 0.3107340506513929
Validation loss: 2.246987278761325

Epoch: 5| Step: 9
Training loss: 0.560163386683843
Validation loss: 2.2576109934667437

Epoch: 5| Step: 10
Training loss: 1.1827214617949955
Validation loss: 2.277197255397219

Epoch: 374| Step: 0
Training loss: 1.0614876692851276
Validation loss: 2.232393216157744

Epoch: 5| Step: 1
Training loss: 0.32767048646107794
Validation loss: 2.2882014711068073

Epoch: 5| Step: 2
Training loss: 0.8304960029271609
Validation loss: 2.2672185965843963

Epoch: 5| Step: 3
Training loss: 0.5186779788014797
Validation loss: 2.285415836325515

Epoch: 5| Step: 4
Training loss: 0.6575358146442685
Validation loss: 2.2931270115350006

Epoch: 5| Step: 5
Training loss: 0.6755541822387445
Validation loss: 2.272636618414294

Epoch: 5| Step: 6
Training loss: 0.6820422631562004
Validation loss: 2.2837266086004777

Epoch: 5| Step: 7
Training loss: 0.9247748784031471
Validation loss: 2.2657727231192752

Epoch: 5| Step: 8
Training loss: 0.6582350001554821
Validation loss: 2.290177975013313

Epoch: 5| Step: 9
Training loss: 0.7662885476352883
Validation loss: 2.2925168008991936

Epoch: 5| Step: 10
Training loss: 0.6562254310731767
Validation loss: 2.2731378998744325

Epoch: 375| Step: 0
Training loss: 0.5499918265168875
Validation loss: 2.2731324435806104

Epoch: 5| Step: 1
Training loss: 0.30274366549110704
Validation loss: 2.2663191634682613

Epoch: 5| Step: 2
Training loss: 0.5528144374056562
Validation loss: 2.242047986731035

Epoch: 5| Step: 3
Training loss: 0.6469802107459885
Validation loss: 2.264392456133406

Epoch: 5| Step: 4
Training loss: 1.0071543829122163
Validation loss: 2.265113847020929

Epoch: 5| Step: 5
Training loss: 0.8305057276965192
Validation loss: 2.2830096336099217

Epoch: 5| Step: 6
Training loss: 0.6684346052466474
Validation loss: 2.2786630303690543

Epoch: 5| Step: 7
Training loss: 0.7685375090524776
Validation loss: 2.2749075861915173

Epoch: 5| Step: 8
Training loss: 0.5903697920744616
Validation loss: 2.2584314166162733

Epoch: 5| Step: 9
Training loss: 1.1317712141593133
Validation loss: 2.2392200489164886

Epoch: 5| Step: 10
Training loss: 0.49008472787844265
Validation loss: 2.230439653431849

Epoch: 376| Step: 0
Training loss: 0.7355579831200783
Validation loss: 2.229488441199271

Epoch: 5| Step: 1
Training loss: 0.3399569114736833
Validation loss: 2.185836926261374

Epoch: 5| Step: 2
Training loss: 0.9365098492826956
Validation loss: 2.216485134617323

Epoch: 5| Step: 3
Training loss: 0.6502582083040644
Validation loss: 2.2172006052661817

Epoch: 5| Step: 4
Training loss: 0.666685176135446
Validation loss: 2.2181227399780976

Epoch: 5| Step: 5
Training loss: 0.7690525018010332
Validation loss: 2.275826442836927

Epoch: 5| Step: 6
Training loss: 0.8927313675165865
Validation loss: 2.243320280271536

Epoch: 5| Step: 7
Training loss: 0.8641290428655282
Validation loss: 2.245002560991716

Epoch: 5| Step: 8
Training loss: 0.6992867719073657
Validation loss: 2.2503950781663806

Epoch: 5| Step: 9
Training loss: 0.5335414497805027
Validation loss: 2.215773239463327

Epoch: 5| Step: 10
Training loss: 0.6604820440726407
Validation loss: 2.225876312793724

Epoch: 377| Step: 0
Training loss: 0.6665322098643482
Validation loss: 2.2641097538219137

Epoch: 5| Step: 1
Training loss: 0.9410393977537257
Validation loss: 2.251249542920451

Epoch: 5| Step: 2
Training loss: 0.7978580619332504
Validation loss: 2.2141339762705967

Epoch: 5| Step: 3
Training loss: 0.6277137491841042
Validation loss: 2.2590720686399663

Epoch: 5| Step: 4
Training loss: 0.6783635409898426
Validation loss: 2.2267462587834803

Epoch: 5| Step: 5
Training loss: 0.7510807277629029
Validation loss: 2.2439196396312266

Epoch: 5| Step: 6
Training loss: 0.6041733944178481
Validation loss: 2.2640088387343726

Epoch: 5| Step: 7
Training loss: 0.5968815388745742
Validation loss: 2.227521533881543

Epoch: 5| Step: 8
Training loss: 0.5646924630112192
Validation loss: 2.247955218047493

Epoch: 5| Step: 9
Training loss: 0.6392289744631519
Validation loss: 2.246935585203857

Epoch: 5| Step: 10
Training loss: 0.8951343685384894
Validation loss: 2.2361904347113195

Epoch: 378| Step: 0
Training loss: 0.6807340479245014
Validation loss: 2.257816678180385

Epoch: 5| Step: 1
Training loss: 0.41795999749547363
Validation loss: 2.2249136143951533

Epoch: 5| Step: 2
Training loss: 0.4443092757389898
Validation loss: 2.22584088154193

Epoch: 5| Step: 3
Training loss: 0.8548091976132383
Validation loss: 2.209715756059883

Epoch: 5| Step: 4
Training loss: 0.6438397483855006
Validation loss: 2.2336189252331193

Epoch: 5| Step: 5
Training loss: 0.7465292573268532
Validation loss: 2.2214072764428554

Epoch: 5| Step: 6
Training loss: 1.0659235605957311
Validation loss: 2.234778392131574

Epoch: 5| Step: 7
Training loss: 0.5568536451207573
Validation loss: 2.2520058389178654

Epoch: 5| Step: 8
Training loss: 0.7110204543459073
Validation loss: 2.2427903969402534

Epoch: 5| Step: 9
Training loss: 0.7654843103805471
Validation loss: 2.252712972700605

Epoch: 5| Step: 10
Training loss: 0.6560006121932057
Validation loss: 2.2597193125456876

Epoch: 379| Step: 0
Training loss: 0.6096297245229741
Validation loss: 2.2294679387728573

Epoch: 5| Step: 1
Training loss: 0.473907375390955
Validation loss: 2.24737356454332

Epoch: 5| Step: 2
Training loss: 0.7213083016220748
Validation loss: 2.2355856753161976

Epoch: 5| Step: 3
Training loss: 0.761141631770559
Validation loss: 2.2443492830276917

Epoch: 5| Step: 4
Training loss: 0.6031473264366637
Validation loss: 2.2215332669582932

Epoch: 5| Step: 5
Training loss: 0.6281864240608873
Validation loss: 2.2136202087558954

Epoch: 5| Step: 6
Training loss: 0.567442321282913
Validation loss: 2.2138923835269626

Epoch: 5| Step: 7
Training loss: 0.6607386711584077
Validation loss: 2.2092501091146883

Epoch: 5| Step: 8
Training loss: 0.9824309452919852
Validation loss: 2.21913764348457

Epoch: 5| Step: 9
Training loss: 0.4663134829279847
Validation loss: 2.208937330374164

Epoch: 5| Step: 10
Training loss: 0.9645820293596213
Validation loss: 2.2302605072169066

Epoch: 380| Step: 0
Training loss: 0.23427333216156437
Validation loss: 2.2026092453894326

Epoch: 5| Step: 1
Training loss: 0.7189169150881524
Validation loss: 2.224455082832532

Epoch: 5| Step: 2
Training loss: 0.7818190600221916
Validation loss: 2.2470308011493456

Epoch: 5| Step: 3
Training loss: 0.3034610272056232
Validation loss: 2.2136642817799954

Epoch: 5| Step: 4
Training loss: 0.6873474385309335
Validation loss: 2.2289478511635963

Epoch: 5| Step: 5
Training loss: 0.5473170809683128
Validation loss: 2.19385960414995

Epoch: 5| Step: 6
Training loss: 0.6705523268615683
Validation loss: 2.2381819449757354

Epoch: 5| Step: 7
Training loss: 0.6755180507848682
Validation loss: 2.234844830435418

Epoch: 5| Step: 8
Training loss: 0.8091005957435656
Validation loss: 2.238738589552108

Epoch: 5| Step: 9
Training loss: 0.9619966577999245
Validation loss: 2.2165153766673864

Epoch: 5| Step: 10
Training loss: 0.8916935116003808
Validation loss: 2.2275348375982436

Epoch: 381| Step: 0
Training loss: 0.6206620113327626
Validation loss: 2.2193400701662576

Epoch: 5| Step: 1
Training loss: 0.5868689699035836
Validation loss: 2.2249520355987196

Epoch: 5| Step: 2
Training loss: 0.47794625799576074
Validation loss: 2.208880603570554

Epoch: 5| Step: 3
Training loss: 0.8239616607778874
Validation loss: 2.217708215391893

Epoch: 5| Step: 4
Training loss: 0.8407890500095168
Validation loss: 2.2301666329282255

Epoch: 5| Step: 5
Training loss: 0.928889854036202
Validation loss: 2.25888991981616

Epoch: 5| Step: 6
Training loss: 0.6644726103942448
Validation loss: 2.2371423440161258

Epoch: 5| Step: 7
Training loss: 0.5474268717243101
Validation loss: 2.2691801015300492

Epoch: 5| Step: 8
Training loss: 0.8379572772923448
Validation loss: 2.2994178495576088

Epoch: 5| Step: 9
Training loss: 0.7211243347096131
Validation loss: 2.2794797881078988

Epoch: 5| Step: 10
Training loss: 0.3370971513921183
Validation loss: 2.281534380345502

Epoch: 382| Step: 0
Training loss: 0.7268922939194868
Validation loss: 2.253595630728332

Epoch: 5| Step: 1
Training loss: 1.068898289972451
Validation loss: 2.2647072551027674

Epoch: 5| Step: 2
Training loss: 0.5213513150996203
Validation loss: 2.2753491610511554

Epoch: 5| Step: 3
Training loss: 0.448917935037081
Validation loss: 2.285198371217839

Epoch: 5| Step: 4
Training loss: 0.7225954597267157
Validation loss: 2.212944921056893

Epoch: 5| Step: 5
Training loss: 0.6497853071271128
Validation loss: 2.245529350145485

Epoch: 5| Step: 6
Training loss: 0.28456755187110033
Validation loss: 2.2520777111623227

Epoch: 5| Step: 7
Training loss: 0.7178281594520937
Validation loss: 2.231928387629726

Epoch: 5| Step: 8
Training loss: 0.5791326710674404
Validation loss: 2.2822775016486587

Epoch: 5| Step: 9
Training loss: 0.7476199054554006
Validation loss: 2.2803970733780736

Epoch: 5| Step: 10
Training loss: 0.6314767939999645
Validation loss: 2.307762826958775

Epoch: 383| Step: 0
Training loss: 0.6198868691765207
Validation loss: 2.271503158529905

Epoch: 5| Step: 1
Training loss: 0.49717483470808693
Validation loss: 2.3034578436017616

Epoch: 5| Step: 2
Training loss: 0.6678637371837789
Validation loss: 2.285155608292174

Epoch: 5| Step: 3
Training loss: 0.5020914740581787
Validation loss: 2.263512805804014

Epoch: 5| Step: 4
Training loss: 1.0491236549167926
Validation loss: 2.2657172829599945

Epoch: 5| Step: 5
Training loss: 0.6113391180543025
Validation loss: 2.274222118014341

Epoch: 5| Step: 6
Training loss: 0.8325739062498497
Validation loss: 2.239099532057727

Epoch: 5| Step: 7
Training loss: 0.5281330277323751
Validation loss: 2.2753168498227994

Epoch: 5| Step: 8
Training loss: 0.6612515814749658
Validation loss: 2.267349315705742

Epoch: 5| Step: 9
Training loss: 0.6111811988428514
Validation loss: 2.2409254417318265

Epoch: 5| Step: 10
Training loss: 0.5625884728260746
Validation loss: 2.2319761577068538

Epoch: 384| Step: 0
Training loss: 0.6096310688848533
Validation loss: 2.243549986714335

Epoch: 5| Step: 1
Training loss: 0.5818432753997543
Validation loss: 2.2549295244308305

Epoch: 5| Step: 2
Training loss: 0.3986504303675689
Validation loss: 2.2457120672204414

Epoch: 5| Step: 3
Training loss: 0.7335578349038986
Validation loss: 2.2431215674045943

Epoch: 5| Step: 4
Training loss: 0.7035944325280484
Validation loss: 2.2525312127491346

Epoch: 5| Step: 5
Training loss: 0.5052849885131154
Validation loss: 2.2494860646664447

Epoch: 5| Step: 6
Training loss: 0.7427474469500832
Validation loss: 2.24803083712771

Epoch: 5| Step: 7
Training loss: 0.9104175438138343
Validation loss: 2.230328146787859

Epoch: 5| Step: 8
Training loss: 0.7995816806009481
Validation loss: 2.237631335505494

Epoch: 5| Step: 9
Training loss: 0.6719561239547521
Validation loss: 2.2394790838827205

Epoch: 5| Step: 10
Training loss: 0.3987282645720269
Validation loss: 2.2593237480966013

Epoch: 385| Step: 0
Training loss: 0.5866450551732292
Validation loss: 2.2286776432836746

Epoch: 5| Step: 1
Training loss: 0.7468220616177961
Validation loss: 2.237099664630512

Epoch: 5| Step: 2
Training loss: 0.4864355527811141
Validation loss: 2.2304418424402748

Epoch: 5| Step: 3
Training loss: 0.495888494847894
Validation loss: 2.298156726664151

Epoch: 5| Step: 4
Training loss: 0.6590851440446616
Validation loss: 2.317858494900166

Epoch: 5| Step: 5
Training loss: 0.45318203600008405
Validation loss: 2.2963638780559643

Epoch: 5| Step: 6
Training loss: 1.1694876194462103
Validation loss: 2.2679733343634303

Epoch: 5| Step: 7
Training loss: 0.6390983021227876
Validation loss: 2.2530474767449746

Epoch: 5| Step: 8
Training loss: 0.5820580290707964
Validation loss: 2.246810181056287

Epoch: 5| Step: 9
Training loss: 0.6763355870125518
Validation loss: 2.1987905005034096

Epoch: 5| Step: 10
Training loss: 0.5099240053347749
Validation loss: 2.2274801145563474

Epoch: 386| Step: 0
Training loss: 0.7721684766685482
Validation loss: 2.209075775842124

Epoch: 5| Step: 1
Training loss: 0.6800750635944768
Validation loss: 2.219215889522454

Epoch: 5| Step: 2
Training loss: 0.821665420208876
Validation loss: 2.2598427859244037

Epoch: 5| Step: 3
Training loss: 0.6600749851747654
Validation loss: 2.2760001107637624

Epoch: 5| Step: 4
Training loss: 0.4927428004311265
Validation loss: 2.2806758565488097

Epoch: 5| Step: 5
Training loss: 0.6115431239938193
Validation loss: 2.286772642709908

Epoch: 5| Step: 6
Training loss: 0.6384061674774997
Validation loss: 2.26081837222074

Epoch: 5| Step: 7
Training loss: 0.46594233484145514
Validation loss: 2.282492716775301

Epoch: 5| Step: 8
Training loss: 0.4112225794709168
Validation loss: 2.2762604568835108

Epoch: 5| Step: 9
Training loss: 0.579289938022804
Validation loss: 2.270216439108995

Epoch: 5| Step: 10
Training loss: 0.941609182685002
Validation loss: 2.2556207005086093

Epoch: 387| Step: 0
Training loss: 0.695499416473111
Validation loss: 2.2565224188635074

Epoch: 5| Step: 1
Training loss: 0.49905780591769594
Validation loss: 2.276884013261968

Epoch: 5| Step: 2
Training loss: 0.7392395904189971
Validation loss: 2.2232578361030346

Epoch: 5| Step: 3
Training loss: 0.7234092706894654
Validation loss: 2.2209294435859666

Epoch: 5| Step: 4
Training loss: 0.5554798806493063
Validation loss: 2.259512873211854

Epoch: 5| Step: 5
Training loss: 0.3077045377205809
Validation loss: 2.2683194871494505

Epoch: 5| Step: 6
Training loss: 0.31416634697902074
Validation loss: 2.2913531121525335

Epoch: 5| Step: 7
Training loss: 1.0359734530416813
Validation loss: 2.278706936674737

Epoch: 5| Step: 8
Training loss: 0.4837368329791953
Validation loss: 2.2824668897627207

Epoch: 5| Step: 9
Training loss: 0.5798742276330677
Validation loss: 2.256121179973623

Epoch: 5| Step: 10
Training loss: 0.9321113213088846
Validation loss: 2.2622589350934326

Epoch: 388| Step: 0
Training loss: 0.42241037800775466
Validation loss: 2.2161098025323653

Epoch: 5| Step: 1
Training loss: 0.8621016508516046
Validation loss: 2.2058041039449425

Epoch: 5| Step: 2
Training loss: 0.4646441888795355
Validation loss: 2.216467232313634

Epoch: 5| Step: 3
Training loss: 0.8250643835087428
Validation loss: 2.22293209813244

Epoch: 5| Step: 4
Training loss: 0.6641977060340981
Validation loss: 2.248642761620772

Epoch: 5| Step: 5
Training loss: 0.7190466558840342
Validation loss: 2.229249810259254

Epoch: 5| Step: 6
Training loss: 0.6343042663075915
Validation loss: 2.2525729698189405

Epoch: 5| Step: 7
Training loss: 0.5127673579867109
Validation loss: 2.254385452596756

Epoch: 5| Step: 8
Training loss: 0.6674923006249475
Validation loss: 2.251622714942492

Epoch: 5| Step: 9
Training loss: 0.6597645743199639
Validation loss: 2.213629957799233

Epoch: 5| Step: 10
Training loss: 0.6510737957973775
Validation loss: 2.218892184341819

Epoch: 389| Step: 0
Training loss: 0.7559353496998753
Validation loss: 2.2003657227660645

Epoch: 5| Step: 1
Training loss: 0.7321302723550638
Validation loss: 2.2501340801072214

Epoch: 5| Step: 2
Training loss: 0.41795233221876266
Validation loss: 2.285232381408796

Epoch: 5| Step: 3
Training loss: 0.5884933423708515
Validation loss: 2.2965610577842526

Epoch: 5| Step: 4
Training loss: 0.5211870581774491
Validation loss: 2.3019887188045516

Epoch: 5| Step: 5
Training loss: 0.6758314125098023
Validation loss: 2.288446908282761

Epoch: 5| Step: 6
Training loss: 0.5829483589771579
Validation loss: 2.304405929637455

Epoch: 5| Step: 7
Training loss: 0.737890513527631
Validation loss: 2.2711179719899333

Epoch: 5| Step: 8
Training loss: 0.5813562203841328
Validation loss: 2.271787536280761

Epoch: 5| Step: 9
Training loss: 0.6438431737192047
Validation loss: 2.260122948595567

Epoch: 5| Step: 10
Training loss: 0.7674791888667913
Validation loss: 2.2232221796307465

Epoch: 390| Step: 0
Training loss: 0.45954088602401244
Validation loss: 2.2221551832047677

Epoch: 5| Step: 1
Training loss: 0.671811766199337
Validation loss: 2.1908103576212294

Epoch: 5| Step: 2
Training loss: 0.7061199617089633
Validation loss: 2.205558587687271

Epoch: 5| Step: 3
Training loss: 0.5965409437534309
Validation loss: 2.2194057202209168

Epoch: 5| Step: 4
Training loss: 0.66530978928386
Validation loss: 2.2256106247701894

Epoch: 5| Step: 5
Training loss: 0.4091630081018372
Validation loss: 2.2837903656992133

Epoch: 5| Step: 6
Training loss: 0.8355017265973151
Validation loss: 2.302819379666605

Epoch: 5| Step: 7
Training loss: 0.6827120517198353
Validation loss: 2.288990164502853

Epoch: 5| Step: 8
Training loss: 0.8879321698238035
Validation loss: 2.296653639787423

Epoch: 5| Step: 9
Training loss: 0.4632435994022597
Validation loss: 2.2589483760924605

Epoch: 5| Step: 10
Training loss: 0.4697109386359769
Validation loss: 2.217990065124469

Epoch: 391| Step: 0
Training loss: 0.5780536246701585
Validation loss: 2.220874648977834

Epoch: 5| Step: 1
Training loss: 0.44372817173851103
Validation loss: 2.22568940979516

Epoch: 5| Step: 2
Training loss: 0.5800752222264677
Validation loss: 2.2267825127509533

Epoch: 5| Step: 3
Training loss: 0.376849481436722
Validation loss: 2.2467620303432647

Epoch: 5| Step: 4
Training loss: 0.7385982256826972
Validation loss: 2.2673301495120803

Epoch: 5| Step: 5
Training loss: 0.7435136692045045
Validation loss: 2.2833836223069506

Epoch: 5| Step: 6
Training loss: 0.752640843185225
Validation loss: 2.268148832201978

Epoch: 5| Step: 7
Training loss: 0.8438400291166167
Validation loss: 2.2575641649788927

Epoch: 5| Step: 8
Training loss: 0.40531707896379177
Validation loss: 2.2696948065323763

Epoch: 5| Step: 9
Training loss: 0.6608609833851665
Validation loss: 2.2585776806183935

Epoch: 5| Step: 10
Training loss: 0.4887559185742906
Validation loss: 2.24645678425087

Epoch: 392| Step: 0
Training loss: 0.8078405585664045
Validation loss: 2.262008837398754

Epoch: 5| Step: 1
Training loss: 0.8029721689828806
Validation loss: 2.2448762991403326

Epoch: 5| Step: 2
Training loss: 0.7015289842377919
Validation loss: 2.2081663246953123

Epoch: 5| Step: 3
Training loss: 0.43825734527185983
Validation loss: 2.2077857569375263

Epoch: 5| Step: 4
Training loss: 0.5640576571100776
Validation loss: 2.2283505933737113

Epoch: 5| Step: 5
Training loss: 0.44692908873369486
Validation loss: 2.2263415040013936

Epoch: 5| Step: 6
Training loss: 0.5859292347642965
Validation loss: 2.235886720767371

Epoch: 5| Step: 7
Training loss: 0.49198792967973703
Validation loss: 2.2387168721078727

Epoch: 5| Step: 8
Training loss: 0.5874256310163398
Validation loss: 2.2627196062204624

Epoch: 5| Step: 9
Training loss: 0.742608603424404
Validation loss: 2.235791860965747

Epoch: 5| Step: 10
Training loss: 0.3632795067201851
Validation loss: 2.2381013992944268

Epoch: 393| Step: 0
Training loss: 0.5072193496302895
Validation loss: 2.2870638275452055

Epoch: 5| Step: 1
Training loss: 0.6568231577428254
Validation loss: 2.2969296445883463

Epoch: 5| Step: 2
Training loss: 0.8290375054621785
Validation loss: 2.265632099257886

Epoch: 5| Step: 3
Training loss: 0.6492515188455718
Validation loss: 2.269040682107183

Epoch: 5| Step: 4
Training loss: 0.49989389247349264
Validation loss: 2.2309199493663683

Epoch: 5| Step: 5
Training loss: 0.46475303790601147
Validation loss: 2.2732887141853837

Epoch: 5| Step: 6
Training loss: 0.5793684397534883
Validation loss: 2.2101347021744426

Epoch: 5| Step: 7
Training loss: 0.8258458208807382
Validation loss: 2.2242784000113387

Epoch: 5| Step: 8
Training loss: 0.5430332392535226
Validation loss: 2.2276355574888878

Epoch: 5| Step: 9
Training loss: 0.4947132065118873
Validation loss: 2.235546186896708

Epoch: 5| Step: 10
Training loss: 0.4902057715350502
Validation loss: 2.223172898220561

Epoch: 394| Step: 0
Training loss: 0.6716174585745064
Validation loss: 2.2558509017145245

Epoch: 5| Step: 1
Training loss: 0.6142535429352809
Validation loss: 2.2902748721681294

Epoch: 5| Step: 2
Training loss: 0.5805978726393056
Validation loss: 2.2959845974482613

Epoch: 5| Step: 3
Training loss: 0.691620120144549
Validation loss: 2.284504249237837

Epoch: 5| Step: 4
Training loss: 0.653873864833785
Validation loss: 2.2948810381933464

Epoch: 5| Step: 5
Training loss: 0.5123939718497127
Validation loss: 2.30063082997568

Epoch: 5| Step: 6
Training loss: 0.5765712582302909
Validation loss: 2.2803173307861013

Epoch: 5| Step: 7
Training loss: 0.1938014515886379
Validation loss: 2.257220207912648

Epoch: 5| Step: 8
Training loss: 0.7019165250293538
Validation loss: 2.221505819569464

Epoch: 5| Step: 9
Training loss: 0.6153034716360803
Validation loss: 2.203657119898167

Epoch: 5| Step: 10
Training loss: 0.5991378570425053
Validation loss: 2.2216706569036893

Epoch: 395| Step: 0
Training loss: 0.6633649416042909
Validation loss: 2.210169591965527

Epoch: 5| Step: 1
Training loss: 0.37139438698470706
Validation loss: 2.233980519915187

Epoch: 5| Step: 2
Training loss: 0.5497986706799158
Validation loss: 2.224008251311139

Epoch: 5| Step: 3
Training loss: 0.6706968446058719
Validation loss: 2.2821568917017028

Epoch: 5| Step: 4
Training loss: 0.28246640372734116
Validation loss: 2.2767045635972365

Epoch: 5| Step: 5
Training loss: 0.6659394833174073
Validation loss: 2.281052969035916

Epoch: 5| Step: 6
Training loss: 0.6205549482165971
Validation loss: 2.2813437197194637

Epoch: 5| Step: 7
Training loss: 0.7495039252953937
Validation loss: 2.2870977264878567

Epoch: 5| Step: 8
Training loss: 0.6352865575774821
Validation loss: 2.238967882677327

Epoch: 5| Step: 9
Training loss: 0.48827375787709126
Validation loss: 2.2310934065421772

Epoch: 5| Step: 10
Training loss: 0.7284701744812859
Validation loss: 2.1988756305606096

Epoch: 396| Step: 0
Training loss: 0.7477555068567987
Validation loss: 2.1851830055729677

Epoch: 5| Step: 1
Training loss: 0.3331260359427714
Validation loss: 2.2279239748582853

Epoch: 5| Step: 2
Training loss: 0.6517720029736201
Validation loss: 2.2273248984561445

Epoch: 5| Step: 3
Training loss: 0.2586369193194232
Validation loss: 2.250588374305248

Epoch: 5| Step: 4
Training loss: 0.6805291281540626
Validation loss: 2.269288868759377

Epoch: 5| Step: 5
Training loss: 0.5055910672942395
Validation loss: 2.25256069543762

Epoch: 5| Step: 6
Training loss: 0.34336368571104514
Validation loss: 2.239468940242049

Epoch: 5| Step: 7
Training loss: 0.6960232348962182
Validation loss: 2.301183752996768

Epoch: 5| Step: 8
Training loss: 0.5620957617473183
Validation loss: 2.299467140808942

Epoch: 5| Step: 9
Training loss: 0.7574430922103418
Validation loss: 2.286027009388954

Epoch: 5| Step: 10
Training loss: 0.7139321857299021
Validation loss: 2.257509016085916

Epoch: 397| Step: 0
Training loss: 0.6684592158502697
Validation loss: 2.260582508142775

Epoch: 5| Step: 1
Training loss: 0.5447615794473775
Validation loss: 2.2575344069562124

Epoch: 5| Step: 2
Training loss: 0.4850505455705708
Validation loss: 2.2614531707791654

Epoch: 5| Step: 3
Training loss: 0.5745070894798248
Validation loss: 2.268074345038054

Epoch: 5| Step: 4
Training loss: 0.3988642370779676
Validation loss: 2.274123005284555

Epoch: 5| Step: 5
Training loss: 0.65601203782097
Validation loss: 2.26223530333387

Epoch: 5| Step: 6
Training loss: 0.7542424613492447
Validation loss: 2.2848015723739046

Epoch: 5| Step: 7
Training loss: 0.5644820578792585
Validation loss: 2.2651007815615976

Epoch: 5| Step: 8
Training loss: 0.6664104913216575
Validation loss: 2.2785256627238546

Epoch: 5| Step: 9
Training loss: 0.5205932890541184
Validation loss: 2.290666716288554

Epoch: 5| Step: 10
Training loss: 0.4490044953613983
Validation loss: 2.2569712528459265

Epoch: 398| Step: 0
Training loss: 0.6719735760787126
Validation loss: 2.272013317498804

Epoch: 5| Step: 1
Training loss: 0.4132817302621744
Validation loss: 2.276005073587917

Epoch: 5| Step: 2
Training loss: 0.7080697289063413
Validation loss: 2.2477732718246703

Epoch: 5| Step: 3
Training loss: 0.6794604656712911
Validation loss: 2.2133486647797045

Epoch: 5| Step: 4
Training loss: 0.47364770924845684
Validation loss: 2.2350863004275325

Epoch: 5| Step: 5
Training loss: 0.3949966141096898
Validation loss: 2.242477336231758

Epoch: 5| Step: 6
Training loss: 0.49135526808075514
Validation loss: 2.250732400660658

Epoch: 5| Step: 7
Training loss: 0.606845717386606
Validation loss: 2.23521880120786

Epoch: 5| Step: 8
Training loss: 0.24107560905989608
Validation loss: 2.2282573151243916

Epoch: 5| Step: 9
Training loss: 0.7745904517158757
Validation loss: 2.28876987585858

Epoch: 5| Step: 10
Training loss: 0.6048567355197563
Validation loss: 2.2734216271503795

Epoch: 399| Step: 0
Training loss: 0.373229895628376
Validation loss: 2.2788381352767

Epoch: 5| Step: 1
Training loss: 0.6503259666767985
Validation loss: 2.29760424452967

Epoch: 5| Step: 2
Training loss: 0.6784183667479512
Validation loss: 2.29999920812471

Epoch: 5| Step: 3
Training loss: 0.8220599136909306
Validation loss: 2.3025805102987618

Epoch: 5| Step: 4
Training loss: 0.520760222707795
Validation loss: 2.2704839284264513

Epoch: 5| Step: 5
Training loss: 0.3744026234072796
Validation loss: 2.2357525693996205

Epoch: 5| Step: 6
Training loss: 0.7576754337902264
Validation loss: 2.240336378879202

Epoch: 5| Step: 7
Training loss: 0.34178306551692894
Validation loss: 2.230176483218229

Epoch: 5| Step: 8
Training loss: 0.6691456961008153
Validation loss: 2.230898250039342

Epoch: 5| Step: 9
Training loss: 0.3148282343068
Validation loss: 2.2468487173140588

Epoch: 5| Step: 10
Training loss: 0.5966388544823357
Validation loss: 2.245043563975533

Epoch: 400| Step: 0
Training loss: 0.6379882233259244
Validation loss: 2.2750318793409696

Epoch: 5| Step: 1
Training loss: 0.7323127360091644
Validation loss: 2.2565460087713536

Epoch: 5| Step: 2
Training loss: 0.3250267691775133
Validation loss: 2.272983577456202

Epoch: 5| Step: 3
Training loss: 0.7179945832130524
Validation loss: 2.2657164185000576

Epoch: 5| Step: 4
Training loss: 0.3456950213673271
Validation loss: 2.2841509378572598

Epoch: 5| Step: 5
Training loss: 0.762189240525977
Validation loss: 2.2801718069429713

Epoch: 5| Step: 6
Training loss: 0.4693241894188643
Validation loss: 2.2723486639507087

Epoch: 5| Step: 7
Training loss: 0.5878274066176702
Validation loss: 2.2513587101066648

Epoch: 5| Step: 8
Training loss: 0.2558236279158459
Validation loss: 2.230128003255182

Epoch: 5| Step: 9
Training loss: 0.6272536891267739
Validation loss: 2.255779908287268

Epoch: 5| Step: 10
Training loss: 0.6704154462390299
Validation loss: 2.2358071071664694

Epoch: 401| Step: 0
Training loss: 0.3081074274789784
Validation loss: 2.253997711591098

Epoch: 5| Step: 1
Training loss: 0.4926796526421235
Validation loss: 2.274843655640724

Epoch: 5| Step: 2
Training loss: 0.5343734138866777
Validation loss: 2.3035664218638363

Epoch: 5| Step: 3
Training loss: 0.5944367001475686
Validation loss: 2.2835181559896376

Epoch: 5| Step: 4
Training loss: 0.6639970859397576
Validation loss: 2.2689248545821576

Epoch: 5| Step: 5
Training loss: 0.27530537631791613
Validation loss: 2.290171086173943

Epoch: 5| Step: 6
Training loss: 0.721398573700944
Validation loss: 2.2568837466306584

Epoch: 5| Step: 7
Training loss: 0.4289040445573314
Validation loss: 2.240315277120454

Epoch: 5| Step: 8
Training loss: 0.7064116276142086
Validation loss: 2.254825972177908

Epoch: 5| Step: 9
Training loss: 0.7483026848983059
Validation loss: 2.2628755043578646

Epoch: 5| Step: 10
Training loss: 0.5781730941150544
Validation loss: 2.2626324322243536

Epoch: 402| Step: 0
Training loss: 0.3494223302094404
Validation loss: 2.2802270097787063

Epoch: 5| Step: 1
Training loss: 0.5846704898726988
Validation loss: 2.2752800633067856

Epoch: 5| Step: 2
Training loss: 0.47180088926484576
Validation loss: 2.305062564832417

Epoch: 5| Step: 3
Training loss: 0.5203485012487016
Validation loss: 2.2833486105893805

Epoch: 5| Step: 4
Training loss: 0.6004283915488294
Validation loss: 2.242526985357559

Epoch: 5| Step: 5
Training loss: 0.3731015949160989
Validation loss: 2.2460148446239527

Epoch: 5| Step: 6
Training loss: 0.44526186872724394
Validation loss: 2.245905027874286

Epoch: 5| Step: 7
Training loss: 0.693601281317899
Validation loss: 2.2201051284149207

Epoch: 5| Step: 8
Training loss: 0.7049760612522282
Validation loss: 2.2327279169175234

Epoch: 5| Step: 9
Training loss: 0.6712941386808114
Validation loss: 2.2465046699083024

Epoch: 5| Step: 10
Training loss: 0.6300980784123695
Validation loss: 2.2540339833252117

Epoch: 403| Step: 0
Training loss: 0.46338032118296885
Validation loss: 2.2844464233396065

Epoch: 5| Step: 1
Training loss: 0.3688807910178937
Validation loss: 2.2738698312808996

Epoch: 5| Step: 2
Training loss: 0.3675851697581122
Validation loss: 2.2990714230454348

Epoch: 5| Step: 3
Training loss: 0.7028739693010139
Validation loss: 2.281724812688302

Epoch: 5| Step: 4
Training loss: 0.8244213198821577
Validation loss: 2.2760954100771076

Epoch: 5| Step: 5
Training loss: 0.5377282478618581
Validation loss: 2.2897134629657407

Epoch: 5| Step: 6
Training loss: 0.5396630632073254
Validation loss: 2.2460490520750453

Epoch: 5| Step: 7
Training loss: 0.39114949300436413
Validation loss: 2.269196326876923

Epoch: 5| Step: 8
Training loss: 0.7107375985270239
Validation loss: 2.237155761838314

Epoch: 5| Step: 9
Training loss: 0.441822429697036
Validation loss: 2.2279938157931154

Epoch: 5| Step: 10
Training loss: 0.47858883044746675
Validation loss: 2.2469541729101254

Epoch: 404| Step: 0
Training loss: 0.40592494211014996
Validation loss: 2.2727497812594026

Epoch: 5| Step: 1
Training loss: 0.5448401058196582
Validation loss: 2.270037436417598

Epoch: 5| Step: 2
Training loss: 0.6058315051793252
Validation loss: 2.2563788921813575

Epoch: 5| Step: 3
Training loss: 0.658105905297493
Validation loss: 2.2640227086526186

Epoch: 5| Step: 4
Training loss: 0.6608528660184124
Validation loss: 2.277860278783025

Epoch: 5| Step: 5
Training loss: 0.3712123681271368
Validation loss: 2.3067721263867695

Epoch: 5| Step: 6
Training loss: 0.7049999669257623
Validation loss: 2.304900131859087

Epoch: 5| Step: 7
Training loss: 0.5911503650194699
Validation loss: 2.276607914277949

Epoch: 5| Step: 8
Training loss: 0.37686033539843605
Validation loss: 2.2464743363004054

Epoch: 5| Step: 9
Training loss: 0.5105264182395957
Validation loss: 2.227518782092861

Epoch: 5| Step: 10
Training loss: 0.41672139007109676
Validation loss: 2.2502323233504695

Epoch: 405| Step: 0
Training loss: 0.7547518874476797
Validation loss: 2.228654205864287

Epoch: 5| Step: 1
Training loss: 0.5627181371940886
Validation loss: 2.229811715277491

Epoch: 5| Step: 2
Training loss: 0.48933026354114406
Validation loss: 2.2446995950809137

Epoch: 5| Step: 3
Training loss: 0.4729007845016832
Validation loss: 2.2725638187432122

Epoch: 5| Step: 4
Training loss: 0.5762290279684741
Validation loss: 2.2671946993444867

Epoch: 5| Step: 5
Training loss: 0.6454276584832765
Validation loss: 2.272229915484556

Epoch: 5| Step: 6
Training loss: 0.5870242911873931
Validation loss: 2.3228504681536593

Epoch: 5| Step: 7
Training loss: 0.4562878717093927
Validation loss: 2.3107898078809863

Epoch: 5| Step: 8
Training loss: 0.3383117653207855
Validation loss: 2.26004488977108

Epoch: 5| Step: 9
Training loss: 0.4036019106522449
Validation loss: 2.220506200961674

Epoch: 5| Step: 10
Training loss: 0.5311423080346299
Validation loss: 2.233990873233854

Epoch: 406| Step: 0
Training loss: 0.5543302271932369
Validation loss: 2.228015317306826

Epoch: 5| Step: 1
Training loss: 0.6049633747238197
Validation loss: 2.1926283712297194

Epoch: 5| Step: 2
Training loss: 0.6630797126039617
Validation loss: 2.2545631946861695

Epoch: 5| Step: 3
Training loss: 0.3210859497310893
Validation loss: 2.233806628172175

Epoch: 5| Step: 4
Training loss: 0.5510631137657144
Validation loss: 2.237842265574353

Epoch: 5| Step: 5
Training loss: 0.7603928984668106
Validation loss: 2.2192143080515856

Epoch: 5| Step: 6
Training loss: 0.40619897521972986
Validation loss: 2.268315480608868

Epoch: 5| Step: 7
Training loss: 0.49984023402683575
Validation loss: 2.263245022980528

Epoch: 5| Step: 8
Training loss: 0.6001381049557782
Validation loss: 2.253900465068615

Epoch: 5| Step: 9
Training loss: 0.2859766537275769
Validation loss: 2.2387654369002483

Epoch: 5| Step: 10
Training loss: 0.4049505763155652
Validation loss: 2.2696953735458067

Epoch: 407| Step: 0
Training loss: 0.4668991423751984
Validation loss: 2.2427050099876613

Epoch: 5| Step: 1
Training loss: 0.5117571576097318
Validation loss: 2.250443810156939

Epoch: 5| Step: 2
Training loss: 0.483454413978089
Validation loss: 2.2517857842439724

Epoch: 5| Step: 3
Training loss: 0.39007350137309377
Validation loss: 2.2564897431845283

Epoch: 5| Step: 4
Training loss: 0.7321313714246296
Validation loss: 2.2912471965322427

Epoch: 5| Step: 5
Training loss: 0.48647056546512374
Validation loss: 2.320144949452459

Epoch: 5| Step: 6
Training loss: 0.4962736089072664
Validation loss: 2.302554811739571

Epoch: 5| Step: 7
Training loss: 0.7044507138465992
Validation loss: 2.2959036135751156

Epoch: 5| Step: 8
Training loss: 0.4404237835608915
Validation loss: 2.2885276099212106

Epoch: 5| Step: 9
Training loss: 0.673349514588195
Validation loss: 2.2595819380228845

Epoch: 5| Step: 10
Training loss: 0.3058530570555465
Validation loss: 2.2472544831351056

Epoch: 408| Step: 0
Training loss: 0.547739653283737
Validation loss: 2.261742300445506

Epoch: 5| Step: 1
Training loss: 0.7206544110135039
Validation loss: 2.209510997293833

Epoch: 5| Step: 2
Training loss: 0.48779851320340434
Validation loss: 2.203823404501006

Epoch: 5| Step: 3
Training loss: 0.5998048991653531
Validation loss: 2.2462049482229913

Epoch: 5| Step: 4
Training loss: 0.3545353550545098
Validation loss: 2.223558622884531

Epoch: 5| Step: 5
Training loss: 0.5389187939147035
Validation loss: 2.259525698680494

Epoch: 5| Step: 6
Training loss: 0.6848318169172327
Validation loss: 2.264594954305856

Epoch: 5| Step: 7
Training loss: 0.3701088534501382
Validation loss: 2.3056340802400825

Epoch: 5| Step: 8
Training loss: 0.6006734148532736
Validation loss: 2.3182089316258527

Epoch: 5| Step: 9
Training loss: 0.3253866440436753
Validation loss: 2.3145272299804853

Epoch: 5| Step: 10
Training loss: 0.4575156391837271
Validation loss: 2.2839232977885717

Epoch: 409| Step: 0
Training loss: 0.5336164612076861
Validation loss: 2.281860805837436

Epoch: 5| Step: 1
Training loss: 0.7547474254881399
Validation loss: 2.2727204121395683

Epoch: 5| Step: 2
Training loss: 0.5460659855018251
Validation loss: 2.2766963092097123

Epoch: 5| Step: 3
Training loss: 0.5573951827076172
Validation loss: 2.224907811692975

Epoch: 5| Step: 4
Training loss: 0.5794164306575771
Validation loss: 2.2591395162395878

Epoch: 5| Step: 5
Training loss: 0.7165431267323316
Validation loss: 2.229563433858379

Epoch: 5| Step: 6
Training loss: 0.47866088842127097
Validation loss: 2.345737863956083

Epoch: 5| Step: 7
Training loss: 0.3793625001874857
Validation loss: 2.324932750554543

Epoch: 5| Step: 8
Training loss: 0.4277079500022294
Validation loss: 2.3742394138868157

Epoch: 5| Step: 9
Training loss: 0.5854390631042249
Validation loss: 2.3282082837273497

Epoch: 5| Step: 10
Training loss: 0.19381618484505028
Validation loss: 2.293225416244718

Epoch: 410| Step: 0
Training loss: 0.5728786166878289
Validation loss: 2.2917919414619035

Epoch: 5| Step: 1
Training loss: 0.49765825256232193
Validation loss: 2.2732075877072564

Epoch: 5| Step: 2
Training loss: 0.6737347081984496
Validation loss: 2.251339350845238

Epoch: 5| Step: 3
Training loss: 0.3400477860157255
Validation loss: 2.2514359103525723

Epoch: 5| Step: 4
Training loss: 0.5262432058534575
Validation loss: 2.2674562831795684

Epoch: 5| Step: 5
Training loss: 0.4523183614560045
Validation loss: 2.2815665276769153

Epoch: 5| Step: 6
Training loss: 0.3441061753903418
Validation loss: 2.285003276115419

Epoch: 5| Step: 7
Training loss: 0.40016439606084475
Validation loss: 2.2616051270180297

Epoch: 5| Step: 8
Training loss: 0.6627983626998679
Validation loss: 2.3295249619649097

Epoch: 5| Step: 9
Training loss: 0.699383593686293
Validation loss: 2.300575001272349

Epoch: 5| Step: 10
Training loss: 0.3312408576459449
Validation loss: 2.281800756921537

Epoch: 411| Step: 0
Training loss: 0.5182038753095187
Validation loss: 2.2903328542494816

Epoch: 5| Step: 1
Training loss: 0.5281222777889
Validation loss: 2.256142978165576

Epoch: 5| Step: 2
Training loss: 0.5568351807149282
Validation loss: 2.231541123905554

Epoch: 5| Step: 3
Training loss: 0.6018705446310116
Validation loss: 2.270434559533438

Epoch: 5| Step: 4
Training loss: 0.42408690045743574
Validation loss: 2.248196375741936

Epoch: 5| Step: 5
Training loss: 0.3924360824889858
Validation loss: 2.2476024284384377

Epoch: 5| Step: 6
Training loss: 0.41597711805768095
Validation loss: 2.295543861695039

Epoch: 5| Step: 7
Training loss: 0.7411861691966785
Validation loss: 2.2908749067494525

Epoch: 5| Step: 8
Training loss: 0.551676138175184
Validation loss: 2.31449761507801

Epoch: 5| Step: 9
Training loss: 0.4407647121049054
Validation loss: 2.341377323964812

Epoch: 5| Step: 10
Training loss: 0.4094049748519584
Validation loss: 2.3339087623461223

Epoch: 412| Step: 0
Training loss: 0.3191192778564802
Validation loss: 2.311366428377294

Epoch: 5| Step: 1
Training loss: 0.49183816471342395
Validation loss: 2.2709952171886783

Epoch: 5| Step: 2
Training loss: 0.5701778723269684
Validation loss: 2.226938355491482

Epoch: 5| Step: 3
Training loss: 0.5778553565860121
Validation loss: 2.2232614695210353

Epoch: 5| Step: 4
Training loss: 0.541049198802781
Validation loss: 2.2636519480410926

Epoch: 5| Step: 5
Training loss: 0.462894182151293
Validation loss: 2.27208144437661

Epoch: 5| Step: 6
Training loss: 0.5892766285067883
Validation loss: 2.2893707561733256

Epoch: 5| Step: 7
Training loss: 0.413378924994555
Validation loss: 2.2597090481773656

Epoch: 5| Step: 8
Training loss: 0.5628895999811755
Validation loss: 2.2794242292073768

Epoch: 5| Step: 9
Training loss: 0.596934038008607
Validation loss: 2.2919273140608625

Epoch: 5| Step: 10
Training loss: 0.3273946376567922
Validation loss: 2.3201893812152967

Epoch: 413| Step: 0
Training loss: 0.4850351081017833
Validation loss: 2.2617025115319818

Epoch: 5| Step: 1
Training loss: 0.6555494247457858
Validation loss: 2.2772774021897626

Epoch: 5| Step: 2
Training loss: 0.43246429703925104
Validation loss: 2.2757233869071136

Epoch: 5| Step: 3
Training loss: 0.5056347734994392
Validation loss: 2.2736521965803855

Epoch: 5| Step: 4
Training loss: 0.45523126014860194
Validation loss: 2.3000906781498416

Epoch: 5| Step: 5
Training loss: 0.447653173599191
Validation loss: 2.310493536651208

Epoch: 5| Step: 6
Training loss: 0.7730657281258474
Validation loss: 2.2632995155952114

Epoch: 5| Step: 7
Training loss: 0.416026764483252
Validation loss: 2.2599951533146627

Epoch: 5| Step: 8
Training loss: 0.45537727575914105
Validation loss: 2.287494633596209

Epoch: 5| Step: 9
Training loss: 0.4445463248380158
Validation loss: 2.2673990276541396

Epoch: 5| Step: 10
Training loss: 0.16250367068766533
Validation loss: 2.269605816988656

Epoch: 414| Step: 0
Training loss: 0.7159378767075
Validation loss: 2.2917175484953494

Epoch: 5| Step: 1
Training loss: 0.5972706916150089
Validation loss: 2.307143671036594

Epoch: 5| Step: 2
Training loss: 0.5087898532619665
Validation loss: 2.3038752388925556

Epoch: 5| Step: 3
Training loss: 0.5262281414666211
Validation loss: 2.308806418790472

Epoch: 5| Step: 4
Training loss: 0.3130615315291918
Validation loss: 2.3099337281514174

Epoch: 5| Step: 5
Training loss: 0.41720502366541545
Validation loss: 2.2867715373309867

Epoch: 5| Step: 6
Training loss: 0.4331646075723889
Validation loss: 2.295880159513518

Epoch: 5| Step: 7
Training loss: 0.32458554626848196
Validation loss: 2.2910854046181255

Epoch: 5| Step: 8
Training loss: 0.6217424855347584
Validation loss: 2.288594611739421

Epoch: 5| Step: 9
Training loss: 0.37091455650557825
Validation loss: 2.2739259340136906

Epoch: 5| Step: 10
Training loss: 0.4264158192333493
Validation loss: 2.2852913496049747

Epoch: 415| Step: 0
Training loss: 0.4041627302010872
Validation loss: 2.298150707308367

Epoch: 5| Step: 1
Training loss: 0.39753480641906547
Validation loss: 2.2812110930150933

Epoch: 5| Step: 2
Training loss: 0.42543600241457874
Validation loss: 2.2908898048290913

Epoch: 5| Step: 3
Training loss: 0.42853067905407743
Validation loss: 2.268342348594562

Epoch: 5| Step: 4
Training loss: 0.4046262790517121
Validation loss: 2.3132732487648644

Epoch: 5| Step: 5
Training loss: 0.6521666052139348
Validation loss: 2.343946276687416

Epoch: 5| Step: 6
Training loss: 0.41940136964444263
Validation loss: 2.3301501058630087

Epoch: 5| Step: 7
Training loss: 0.5558789044057136
Validation loss: 2.275510923805738

Epoch: 5| Step: 8
Training loss: 0.5014432700028573
Validation loss: 2.2822852264440883

Epoch: 5| Step: 9
Training loss: 0.41002562123003816
Validation loss: 2.3018548715022042

Epoch: 5| Step: 10
Training loss: 0.7888655841732709
Validation loss: 2.2656533895431687

Epoch: 416| Step: 0
Training loss: 0.40499754557631124
Validation loss: 2.274547097930964

Epoch: 5| Step: 1
Training loss: 0.48908349318129885
Validation loss: 2.2339404551494106

Epoch: 5| Step: 2
Training loss: 0.6573053230604033
Validation loss: 2.250546173747318

Epoch: 5| Step: 3
Training loss: 0.3837312261667435
Validation loss: 2.28444862793042

Epoch: 5| Step: 4
Training loss: 0.25371180204577487
Validation loss: 2.2906476366349056

Epoch: 5| Step: 5
Training loss: 0.8125247217965609
Validation loss: 2.3054751927724477

Epoch: 5| Step: 6
Training loss: 0.569162803746636
Validation loss: 2.3207907660439724

Epoch: 5| Step: 7
Training loss: 0.25701146962773913
Validation loss: 2.31719161206625

Epoch: 5| Step: 8
Training loss: 0.4463648658666026
Validation loss: 2.3369653103078165

Epoch: 5| Step: 9
Training loss: 0.4823430417781335
Validation loss: 2.3004455661370566

Epoch: 5| Step: 10
Training loss: 0.5586621436017162
Validation loss: 2.3186029189707007

Epoch: 417| Step: 0
Training loss: 0.47468765617905456
Validation loss: 2.2628262702640307

Epoch: 5| Step: 1
Training loss: 0.5399271899163064
Validation loss: 2.236983759177934

Epoch: 5| Step: 2
Training loss: 0.41173344681800833
Validation loss: 2.2208358270876287

Epoch: 5| Step: 3
Training loss: 0.4751809998789813
Validation loss: 2.207391185778243

Epoch: 5| Step: 4
Training loss: 0.6301699671350731
Validation loss: 2.196702255893003

Epoch: 5| Step: 5
Training loss: 0.6600796807481074
Validation loss: 2.212018911427458

Epoch: 5| Step: 6
Training loss: 0.2667864902201086
Validation loss: 2.233725803065907

Epoch: 5| Step: 7
Training loss: 0.364573078919569
Validation loss: 2.2383722459571516

Epoch: 5| Step: 8
Training loss: 0.524849936064696
Validation loss: 2.276670974961347

Epoch: 5| Step: 9
Training loss: 0.4792183834307114
Validation loss: 2.2579010897341933

Epoch: 5| Step: 10
Training loss: 0.4663138504131475
Validation loss: 2.2781484992962144

Epoch: 418| Step: 0
Training loss: 0.5918033209219908
Validation loss: 2.2601216146671277

Epoch: 5| Step: 1
Training loss: 0.2814361300747489
Validation loss: 2.283468065208236

Epoch: 5| Step: 2
Training loss: 0.4578896799225842
Validation loss: 2.2432139447090504

Epoch: 5| Step: 3
Training loss: 0.4084350255761352
Validation loss: 2.2614261325193774

Epoch: 5| Step: 4
Training loss: 0.31029027258027636
Validation loss: 2.210690374857018

Epoch: 5| Step: 5
Training loss: 0.4840000608794907
Validation loss: 2.2145116911264986

Epoch: 5| Step: 6
Training loss: 0.6081477302310071
Validation loss: 2.2119602394766624

Epoch: 5| Step: 7
Training loss: 0.5574321272721888
Validation loss: 2.2581763959451218

Epoch: 5| Step: 8
Training loss: 0.5035059617967146
Validation loss: 2.210608383329132

Epoch: 5| Step: 9
Training loss: 0.539403724480183
Validation loss: 2.2440075628494904

Epoch: 5| Step: 10
Training loss: 0.5566011381365195
Validation loss: 2.2218573933049983

Epoch: 419| Step: 0
Training loss: 0.4564815051478071
Validation loss: 2.2477651318861036

Epoch: 5| Step: 1
Training loss: 0.5079111443590477
Validation loss: 2.206229580207176

Epoch: 5| Step: 2
Training loss: 0.4975360270016217
Validation loss: 2.258155229866114

Epoch: 5| Step: 3
Training loss: 0.6588227838774477
Validation loss: 2.262452615901078

Epoch: 5| Step: 4
Training loss: 0.1673908160509543
Validation loss: 2.2741607574415097

Epoch: 5| Step: 5
Training loss: 0.5478158486977137
Validation loss: 2.27543408970569

Epoch: 5| Step: 6
Training loss: 0.5113238201149566
Validation loss: 2.234559672020056

Epoch: 5| Step: 7
Training loss: 0.5918573027626644
Validation loss: 2.284244645735872

Epoch: 5| Step: 8
Training loss: 0.31407266904015596
Validation loss: 2.26838392988489

Epoch: 5| Step: 9
Training loss: 0.31133123226362147
Validation loss: 2.275604125643973

Epoch: 5| Step: 10
Training loss: 0.5044896496787576
Validation loss: 2.2609701834683453

Epoch: 420| Step: 0
Training loss: 0.4419536572096265
Validation loss: 2.2901137862125363

Epoch: 5| Step: 1
Training loss: 0.43906918177831805
Validation loss: 2.291641346706748

Epoch: 5| Step: 2
Training loss: 0.7730792207972078
Validation loss: 2.279415317726125

Epoch: 5| Step: 3
Training loss: 0.48703992603983176
Validation loss: 2.2416918395626904

Epoch: 5| Step: 4
Training loss: 0.6068371475939415
Validation loss: 2.291985198972204

Epoch: 5| Step: 5
Training loss: 0.16769805431457074
Validation loss: 2.291819360592456

Epoch: 5| Step: 6
Training loss: 0.3459582384263201
Validation loss: 2.3043912162846425

Epoch: 5| Step: 7
Training loss: 0.29236409414712133
Validation loss: 2.319659756173181

Epoch: 5| Step: 8
Training loss: 0.6359382479426604
Validation loss: 2.3158126125995344

Epoch: 5| Step: 9
Training loss: 0.36535640452722795
Validation loss: 2.3007405513182944

Epoch: 5| Step: 10
Training loss: 0.3002634793820414
Validation loss: 2.2800060937179727

Epoch: 421| Step: 0
Training loss: 0.5799656511691897
Validation loss: 2.289778787769

Epoch: 5| Step: 1
Training loss: 0.3814688085926455
Validation loss: 2.2700488319789613

Epoch: 5| Step: 2
Training loss: 0.617313420451738
Validation loss: 2.2240204262202306

Epoch: 5| Step: 3
Training loss: 0.3706696948462628
Validation loss: 2.2969881584727294

Epoch: 5| Step: 4
Training loss: 0.3331628477700803
Validation loss: 2.2765687117480344

Epoch: 5| Step: 5
Training loss: 0.23160833741649
Validation loss: 2.2709058225256555

Epoch: 5| Step: 6
Training loss: 0.41211969805619864
Validation loss: 2.2767842261040467

Epoch: 5| Step: 7
Training loss: 0.6024714204729122
Validation loss: 2.3088686222633297

Epoch: 5| Step: 8
Training loss: 0.48225767607683034
Validation loss: 2.292435711854435

Epoch: 5| Step: 9
Training loss: 0.48558405751436795
Validation loss: 2.3112502841080453

Epoch: 5| Step: 10
Training loss: 0.543447132825891
Validation loss: 2.3039394882684783

Epoch: 422| Step: 0
Training loss: 0.2906249195016729
Validation loss: 2.2948698759766124

Epoch: 5| Step: 1
Training loss: 0.39940369086568306
Validation loss: 2.313461374373844

Epoch: 5| Step: 2
Training loss: 0.3764281100350187
Validation loss: 2.316454674547092

Epoch: 5| Step: 3
Training loss: 0.48812209014904445
Validation loss: 2.2478426790863395

Epoch: 5| Step: 4
Training loss: 0.5362515344130965
Validation loss: 2.2402979005331405

Epoch: 5| Step: 5
Training loss: 0.27994013782901317
Validation loss: 2.243436010906868

Epoch: 5| Step: 6
Training loss: 0.46793705063894225
Validation loss: 2.221444197160376

Epoch: 5| Step: 7
Training loss: 0.49567802912776954
Validation loss: 2.2438922072978764

Epoch: 5| Step: 8
Training loss: 0.4115334233039699
Validation loss: 2.2495160465407236

Epoch: 5| Step: 9
Training loss: 0.7546357099560727
Validation loss: 2.294015317588455

Epoch: 5| Step: 10
Training loss: 0.541500604067366
Validation loss: 2.3095028940934608

Epoch: 423| Step: 0
Training loss: 0.645821937850174
Validation loss: 2.3290494206862276

Epoch: 5| Step: 1
Training loss: 0.5573704803447809
Validation loss: 2.2525617037945085

Epoch: 5| Step: 2
Training loss: 0.2716341771744841
Validation loss: 2.305995124565702

Epoch: 5| Step: 3
Training loss: 0.35327325595076703
Validation loss: 2.255398489334562

Epoch: 5| Step: 4
Training loss: 0.278793949203562
Validation loss: 2.2412122323537385

Epoch: 5| Step: 5
Training loss: 0.6489846322704433
Validation loss: 2.244407227076056

Epoch: 5| Step: 6
Training loss: 0.2528087665673564
Validation loss: 2.2244193856216494

Epoch: 5| Step: 7
Training loss: 0.40634381604826686
Validation loss: 2.210725687263674

Epoch: 5| Step: 8
Training loss: 0.7876568350461525
Validation loss: 2.2091139131463753

Epoch: 5| Step: 9
Training loss: 0.32085435672511065
Validation loss: 2.2161112300480608

Epoch: 5| Step: 10
Training loss: 0.3108513377249056
Validation loss: 2.2399890771548625

Epoch: 424| Step: 0
Training loss: 0.4310107749346637
Validation loss: 2.257144687710406

Epoch: 5| Step: 1
Training loss: 0.44365893759373237
Validation loss: 2.2724179957985458

Epoch: 5| Step: 2
Training loss: 0.528997949176195
Validation loss: 2.253543787293352

Epoch: 5| Step: 3
Training loss: 0.3311556771779108
Validation loss: 2.270293470117083

Epoch: 5| Step: 4
Training loss: 0.41970967098593376
Validation loss: 2.2660337855146047

Epoch: 5| Step: 5
Training loss: 0.4826391248298392
Validation loss: 2.2273590942659505

Epoch: 5| Step: 6
Training loss: 0.4688561955003872
Validation loss: 2.2340490997164424

Epoch: 5| Step: 7
Training loss: 0.4784675418284651
Validation loss: 2.2152374346541177

Epoch: 5| Step: 8
Training loss: 0.6061081002511545
Validation loss: 2.1932715002404866

Epoch: 5| Step: 9
Training loss: 0.5204070031200657
Validation loss: 2.195512261759428

Epoch: 5| Step: 10
Training loss: 0.23036689447227846
Validation loss: 2.214435807853367

Epoch: 425| Step: 0
Training loss: 0.45203272943554584
Validation loss: 2.236864059332505

Epoch: 5| Step: 1
Training loss: 0.36165836810700874
Validation loss: 2.2646085853103464

Epoch: 5| Step: 2
Training loss: 0.688996852939544
Validation loss: 2.2639900008116705

Epoch: 5| Step: 3
Training loss: 0.33857654122919567
Validation loss: 2.2655029309251864

Epoch: 5| Step: 4
Training loss: 0.4001209746649587
Validation loss: 2.257487195312429

Epoch: 5| Step: 5
Training loss: 0.17414032299859278
Validation loss: 2.244177223976028

Epoch: 5| Step: 6
Training loss: 0.3528792940102148
Validation loss: 2.2638271656887374

Epoch: 5| Step: 7
Training loss: 0.6210347273510466
Validation loss: 2.252114497607899

Epoch: 5| Step: 8
Training loss: 0.6398635851867854
Validation loss: 2.272901036396275

Epoch: 5| Step: 9
Training loss: 0.3598155762562621
Validation loss: 2.2855191091592806

Epoch: 5| Step: 10
Training loss: 0.3367256522300986
Validation loss: 2.253596178472035

Epoch: 426| Step: 0
Training loss: 0.43704172383026574
Validation loss: 2.245242703904855

Epoch: 5| Step: 1
Training loss: 0.5485970224376873
Validation loss: 2.246227567947861

Epoch: 5| Step: 2
Training loss: 0.30371427380854404
Validation loss: 2.2736988498849886

Epoch: 5| Step: 3
Training loss: 0.5262922753866166
Validation loss: 2.236327071493463

Epoch: 5| Step: 4
Training loss: 0.5840015472643095
Validation loss: 2.257425647443683

Epoch: 5| Step: 5
Training loss: 0.3496459643434491
Validation loss: 2.259969634115169

Epoch: 5| Step: 6
Training loss: 0.3610209628620466
Validation loss: 2.2705721219954427

Epoch: 5| Step: 7
Training loss: 0.46289907520162255
Validation loss: 2.28932108908196

Epoch: 5| Step: 8
Training loss: 0.3793743034871729
Validation loss: 2.2749705875158237

Epoch: 5| Step: 9
Training loss: 0.6362060635878258
Validation loss: 2.2713169280281114

Epoch: 5| Step: 10
Training loss: 0.3152704456968669
Validation loss: 2.252839071864725

Epoch: 427| Step: 0
Training loss: 0.5194000422641118
Validation loss: 2.2560486536054163

Epoch: 5| Step: 1
Training loss: 0.4357071312276768
Validation loss: 2.261036150917811

Epoch: 5| Step: 2
Training loss: 0.2162232068999153
Validation loss: 2.230871194246399

Epoch: 5| Step: 3
Training loss: 0.19798816886748893
Validation loss: 2.24535135763084

Epoch: 5| Step: 4
Training loss: 0.5852625201587695
Validation loss: 2.2674456993830137

Epoch: 5| Step: 5
Training loss: 0.4005208245696161
Validation loss: 2.281148343273201

Epoch: 5| Step: 6
Training loss: 0.41748350265025164
Validation loss: 2.273249657409053

Epoch: 5| Step: 7
Training loss: 0.3874603443466186
Validation loss: 2.257268763595013

Epoch: 5| Step: 8
Training loss: 0.726099789854754
Validation loss: 2.2777479472267483

Epoch: 5| Step: 9
Training loss: 0.44844452855786016
Validation loss: 2.278303603294974

Epoch: 5| Step: 10
Training loss: 0.5401388286576265
Validation loss: 2.2527901362105305

Epoch: 428| Step: 0
Training loss: 0.4035401195613973
Validation loss: 2.2773786350861838

Epoch: 5| Step: 1
Training loss: 0.2991254984910879
Validation loss: 2.2627109569516968

Epoch: 5| Step: 2
Training loss: 0.44439416860128816
Validation loss: 2.245045372762318

Epoch: 5| Step: 3
Training loss: 0.21843872743952064
Validation loss: 2.275748473734795

Epoch: 5| Step: 4
Training loss: 0.5482929376121247
Validation loss: 2.2548219018674396

Epoch: 5| Step: 5
Training loss: 0.43061253937962446
Validation loss: 2.2578014769925345

Epoch: 5| Step: 6
Training loss: 0.4896817378987436
Validation loss: 2.2518914930439737

Epoch: 5| Step: 7
Training loss: 0.6288845935196696
Validation loss: 2.2816156658123297

Epoch: 5| Step: 8
Training loss: 0.6193738431948609
Validation loss: 2.2341358387546273

Epoch: 5| Step: 9
Training loss: 0.3508757559520486
Validation loss: 2.256982235041269

Epoch: 5| Step: 10
Training loss: 0.4639069389577126
Validation loss: 2.2651749449254655

Epoch: 429| Step: 0
Training loss: 0.343705467027115
Validation loss: 2.224907321412342

Epoch: 5| Step: 1
Training loss: 0.34023691870595835
Validation loss: 2.22275911591236

Epoch: 5| Step: 2
Training loss: 0.5025713190074201
Validation loss: 2.2241758873338044

Epoch: 5| Step: 3
Training loss: 0.6667268373237133
Validation loss: 2.222563561528004

Epoch: 5| Step: 4
Training loss: 0.6090705306579182
Validation loss: 2.204055796634643

Epoch: 5| Step: 5
Training loss: 0.3461740379119571
Validation loss: 2.2144872332132626

Epoch: 5| Step: 6
Training loss: 0.19942047153676348
Validation loss: 2.195104439152873

Epoch: 5| Step: 7
Training loss: 0.3850026054418018
Validation loss: 2.236368975221689

Epoch: 5| Step: 8
Training loss: 0.5733260137299593
Validation loss: 2.242321689405243

Epoch: 5| Step: 9
Training loss: 0.42523539840011615
Validation loss: 2.224043104433127

Epoch: 5| Step: 10
Training loss: 0.30032195904985615
Validation loss: 2.2610200730884293

Epoch: 430| Step: 0
Training loss: 0.46726704306260536
Validation loss: 2.2465318569450137

Epoch: 5| Step: 1
Training loss: 0.4056298584492792
Validation loss: 2.2524055123542195

Epoch: 5| Step: 2
Training loss: 0.3216519147491272
Validation loss: 2.2761837933757314

Epoch: 5| Step: 3
Training loss: 0.5836307641563984
Validation loss: 2.2908541569303327

Epoch: 5| Step: 4
Training loss: 0.33761094486212145
Validation loss: 2.2540120345089005

Epoch: 5| Step: 5
Training loss: 0.506371139820521
Validation loss: 2.235333532603654

Epoch: 5| Step: 6
Training loss: 0.6076850443673397
Validation loss: 2.2669595535340106

Epoch: 5| Step: 7
Training loss: 0.3839313932327798
Validation loss: 2.26128197156766

Epoch: 5| Step: 8
Training loss: 0.5264679594660632
Validation loss: 2.270179911548222

Epoch: 5| Step: 9
Training loss: 0.2578296222202898
Validation loss: 2.2288938005913166

Epoch: 5| Step: 10
Training loss: 0.33623690902298947
Validation loss: 2.2833123026556645

Epoch: 431| Step: 0
Training loss: 0.17392271125907016
Validation loss: 2.273791668245082

Epoch: 5| Step: 1
Training loss: 0.35334431201407335
Validation loss: 2.2491465616907598

Epoch: 5| Step: 2
Training loss: 0.27643746065591857
Validation loss: 2.2573212222064596

Epoch: 5| Step: 3
Training loss: 0.6078471323458231
Validation loss: 2.259832392223716

Epoch: 5| Step: 4
Training loss: 0.46610497627715985
Validation loss: 2.2684710162133874

Epoch: 5| Step: 5
Training loss: 0.5128504926984305
Validation loss: 2.304439924460106

Epoch: 5| Step: 6
Training loss: 0.5795059207617088
Validation loss: 2.279850934061134

Epoch: 5| Step: 7
Training loss: 0.4100262753859583
Validation loss: 2.28089174150936

Epoch: 5| Step: 8
Training loss: 0.3985920961436164
Validation loss: 2.298981510992282

Epoch: 5| Step: 9
Training loss: 0.44954336296577313
Validation loss: 2.2889429262977776

Epoch: 5| Step: 10
Training loss: 0.3375067873554851
Validation loss: 2.3142553871261873

Epoch: 432| Step: 0
Training loss: 0.3561171811116813
Validation loss: 2.24777032470726

Epoch: 5| Step: 1
Training loss: 0.37912095269402046
Validation loss: 2.296245980759937

Epoch: 5| Step: 2
Training loss: 0.5652306557238365
Validation loss: 2.2884396893578858

Epoch: 5| Step: 3
Training loss: 0.5128115277045759
Validation loss: 2.3024911823134815

Epoch: 5| Step: 4
Training loss: 0.3835176279711566
Validation loss: 2.2926540621057874

Epoch: 5| Step: 5
Training loss: 0.5223030778784339
Validation loss: 2.2623570302923666

Epoch: 5| Step: 6
Training loss: 0.19569609166829743
Validation loss: 2.2939566926700916

Epoch: 5| Step: 7
Training loss: 0.41458508963987645
Validation loss: 2.2973587099380106

Epoch: 5| Step: 8
Training loss: 0.4131232531131163
Validation loss: 2.271244167326464

Epoch: 5| Step: 9
Training loss: 0.47748543529866505
Validation loss: 2.2790214041081964

Epoch: 5| Step: 10
Training loss: 0.5749205109343822
Validation loss: 2.2154349329002447

Epoch: 433| Step: 0
Training loss: 0.5669901239066526
Validation loss: 2.249303062634034

Epoch: 5| Step: 1
Training loss: 0.5015428699680636
Validation loss: 2.227196420072456

Epoch: 5| Step: 2
Training loss: 0.1695873101886613
Validation loss: 2.2431102104804514

Epoch: 5| Step: 3
Training loss: 0.3975460514347491
Validation loss: 2.307556389007769

Epoch: 5| Step: 4
Training loss: 0.5120288695395588
Validation loss: 2.344989220940569

Epoch: 5| Step: 5
Training loss: 0.6771852318796604
Validation loss: 2.3129548742633697

Epoch: 5| Step: 6
Training loss: 0.38020287688359344
Validation loss: 2.3256082342786684

Epoch: 5| Step: 7
Training loss: 0.4901187806040097
Validation loss: 2.3260995175435744

Epoch: 5| Step: 8
Training loss: 0.32984218403685284
Validation loss: 2.2729807696104403

Epoch: 5| Step: 9
Training loss: 0.33295399966566547
Validation loss: 2.275716160853605

Epoch: 5| Step: 10
Training loss: 0.3800919454792534
Validation loss: 2.2604365587292534

Epoch: 434| Step: 0
Training loss: 0.5046889266711404
Validation loss: 2.2524481982146587

Epoch: 5| Step: 1
Training loss: 0.2551432335144546
Validation loss: 2.2226285996346293

Epoch: 5| Step: 2
Training loss: 0.5704099493511278
Validation loss: 2.2360494770075574

Epoch: 5| Step: 3
Training loss: 0.3611351941506233
Validation loss: 2.25831906256223

Epoch: 5| Step: 4
Training loss: 0.28924714454487727
Validation loss: 2.255201008958699

Epoch: 5| Step: 5
Training loss: 0.5921019218027076
Validation loss: 2.2652092891376583

Epoch: 5| Step: 6
Training loss: 0.526665144970462
Validation loss: 2.2752432074639746

Epoch: 5| Step: 7
Training loss: 0.15320760994648688
Validation loss: 2.3173263668284014

Epoch: 5| Step: 8
Training loss: 0.4491611609655241
Validation loss: 2.3201928484746372

Epoch: 5| Step: 9
Training loss: 0.4737028561740539
Validation loss: 2.2997629140649747

Epoch: 5| Step: 10
Training loss: 0.47292488913032904
Validation loss: 2.3243748666971906

Epoch: 435| Step: 0
Training loss: 0.4507636828776241
Validation loss: 2.3122626018975785

Epoch: 5| Step: 1
Training loss: 0.43362933519757973
Validation loss: 2.2845271838165355

Epoch: 5| Step: 2
Training loss: 0.2644713819504214
Validation loss: 2.2975031992811363

Epoch: 5| Step: 3
Training loss: 0.4552004899310189
Validation loss: 2.2904361661735724

Epoch: 5| Step: 4
Training loss: 0.40432956581818685
Validation loss: 2.272804535524804

Epoch: 5| Step: 5
Training loss: 0.19351846719809923
Validation loss: 2.2821481285009484

Epoch: 5| Step: 6
Training loss: 0.42914696419806686
Validation loss: 2.2683268322671064

Epoch: 5| Step: 7
Training loss: 0.5121164305409691
Validation loss: 2.31724724814435

Epoch: 5| Step: 8
Training loss: 0.432706543798271
Validation loss: 2.289394346908405

Epoch: 5| Step: 9
Training loss: 0.4851770682175976
Validation loss: 2.2863128150119585

Epoch: 5| Step: 10
Training loss: 0.575932443299555
Validation loss: 2.2766945880639553

Epoch: 436| Step: 0
Training loss: 0.3753113447579702
Validation loss: 2.3051593779230193

Epoch: 5| Step: 1
Training loss: 0.5232130110161113
Validation loss: 2.3182074552872485

Epoch: 5| Step: 2
Training loss: 0.3455544168061955
Validation loss: 2.275710312515535

Epoch: 5| Step: 3
Training loss: 0.5865088665219654
Validation loss: 2.3317301783206767

Epoch: 5| Step: 4
Training loss: 0.35612025658985685
Validation loss: 2.2735566082401255

Epoch: 5| Step: 5
Training loss: 0.4922171386998502
Validation loss: 2.278608180049944

Epoch: 5| Step: 6
Training loss: 0.2446817352448938
Validation loss: 2.2672411954932365

Epoch: 5| Step: 7
Training loss: 0.32145253112972483
Validation loss: 2.287848800160374

Epoch: 5| Step: 8
Training loss: 0.5541587781225153
Validation loss: 2.2755570095013122

Epoch: 5| Step: 9
Training loss: 0.3911976050677544
Validation loss: 2.2738098689825215

Epoch: 5| Step: 10
Training loss: 0.43140208009157355
Validation loss: 2.254241733560847

Epoch: 437| Step: 0
Training loss: 0.40419078669724007
Validation loss: 2.2853798472819427

Epoch: 5| Step: 1
Training loss: 0.44374047927314075
Validation loss: 2.279568767252269

Epoch: 5| Step: 2
Training loss: 0.42202152250873004
Validation loss: 2.3259489008152006

Epoch: 5| Step: 3
Training loss: 0.6183556716239337
Validation loss: 2.3228295514667074

Epoch: 5| Step: 4
Training loss: 0.43656316998811945
Validation loss: 2.3405535563554354

Epoch: 5| Step: 5
Training loss: 0.4437971432587031
Validation loss: 2.300685658916899

Epoch: 5| Step: 6
Training loss: 0.5056121398742671
Validation loss: 2.2990634011707236

Epoch: 5| Step: 7
Training loss: 0.37786894317502384
Validation loss: 2.288947050173567

Epoch: 5| Step: 8
Training loss: 0.18938379887324436
Validation loss: 2.335003563427462

Epoch: 5| Step: 9
Training loss: 0.3729829184146681
Validation loss: 2.253146176650212

Epoch: 5| Step: 10
Training loss: 0.3360340511943515
Validation loss: 2.2809185338483484

Epoch: 438| Step: 0
Training loss: 0.2576577560260497
Validation loss: 2.282987720814325

Epoch: 5| Step: 1
Training loss: 0.45306598344774823
Validation loss: 2.267134498305769

Epoch: 5| Step: 2
Training loss: 0.5042777355530469
Validation loss: 2.305836915717762

Epoch: 5| Step: 3
Training loss: 0.454905989020859
Validation loss: 2.2858299729758422

Epoch: 5| Step: 4
Training loss: 0.3580320184643957
Validation loss: 2.29222623382989

Epoch: 5| Step: 5
Training loss: 0.5184182887458453
Validation loss: 2.3079862168432026

Epoch: 5| Step: 6
Training loss: 0.44280805212679675
Validation loss: 2.2788956951262382

Epoch: 5| Step: 7
Training loss: 0.2100970869206446
Validation loss: 2.2798482251936956

Epoch: 5| Step: 8
Training loss: 0.3223494565184035
Validation loss: 2.2998228685280315

Epoch: 5| Step: 9
Training loss: 0.5371390317185328
Validation loss: 2.272817442774871

Epoch: 5| Step: 10
Training loss: 0.4766927447332476
Validation loss: 2.2767137305997234

Epoch: 439| Step: 0
Training loss: 0.6007782914940819
Validation loss: 2.284890593358533

Epoch: 5| Step: 1
Training loss: 0.3386747049919607
Validation loss: 2.2672586561790844

Epoch: 5| Step: 2
Training loss: 0.33576470743916953
Validation loss: 2.2640178916784675

Epoch: 5| Step: 3
Training loss: 0.27868180473566895
Validation loss: 2.249692250925519

Epoch: 5| Step: 4
Training loss: 0.3791023415543237
Validation loss: 2.2923448489504286

Epoch: 5| Step: 5
Training loss: 0.34103046048503893
Validation loss: 2.270108605083862

Epoch: 5| Step: 6
Training loss: 0.39724044870065844
Validation loss: 2.3222443586130717

Epoch: 5| Step: 7
Training loss: 0.5531493337849792
Validation loss: 2.304042925554351

Epoch: 5| Step: 8
Training loss: 0.5516379707293099
Validation loss: 2.3159781199052274

Epoch: 5| Step: 9
Training loss: 0.4869223797849432
Validation loss: 2.2968840407393873

Epoch: 5| Step: 10
Training loss: 0.20848759761178828
Validation loss: 2.277195921901311

Epoch: 440| Step: 0
Training loss: 0.14809743299772546
Validation loss: 2.2537820015136125

Epoch: 5| Step: 1
Training loss: 0.17172660707265183
Validation loss: 2.286796750151379

Epoch: 5| Step: 2
Training loss: 0.6339424782269532
Validation loss: 2.2879974509326177

Epoch: 5| Step: 3
Training loss: 0.37773320415832146
Validation loss: 2.2914218700991946

Epoch: 5| Step: 4
Training loss: 0.47643093732036856
Validation loss: 2.3260728849385517

Epoch: 5| Step: 5
Training loss: 0.4485084889543093
Validation loss: 2.259016969609867

Epoch: 5| Step: 6
Training loss: 0.2743156772602481
Validation loss: 2.274041764268999

Epoch: 5| Step: 7
Training loss: 0.42383125409496186
Validation loss: 2.31173364766956

Epoch: 5| Step: 8
Training loss: 0.3830408271749368
Validation loss: 2.3084835413949056

Epoch: 5| Step: 9
Training loss: 0.5799648289868843
Validation loss: 2.316086484236204

Epoch: 5| Step: 10
Training loss: 0.35261910921982265
Validation loss: 2.318011351564061

Epoch: 441| Step: 0
Training loss: 0.2042229214032831
Validation loss: 2.3122090841510956

Epoch: 5| Step: 1
Training loss: 0.3090855747399439
Validation loss: 2.308199792380347

Epoch: 5| Step: 2
Training loss: 0.4724052330127773
Validation loss: 2.262140268950257

Epoch: 5| Step: 3
Training loss: 0.4222038894397367
Validation loss: 2.261237924759052

Epoch: 5| Step: 4
Training loss: 0.4897116499680612
Validation loss: 2.2703001335821322

Epoch: 5| Step: 5
Training loss: 0.24786147750850593
Validation loss: 2.2792858867220644

Epoch: 5| Step: 6
Training loss: 0.4434573699607135
Validation loss: 2.271164633893555

Epoch: 5| Step: 7
Training loss: 0.3210827011100854
Validation loss: 2.287867705380105

Epoch: 5| Step: 8
Training loss: 0.557366630527293
Validation loss: 2.2985775516587665

Epoch: 5| Step: 9
Training loss: 0.622357073312514
Validation loss: 2.3262647436994697

Epoch: 5| Step: 10
Training loss: 0.31624071476992355
Validation loss: 2.3290780459391196

Epoch: 442| Step: 0
Training loss: 0.3522188311994654
Validation loss: 2.348143768646484

Epoch: 5| Step: 1
Training loss: 0.43253112005718675
Validation loss: 2.3185224658431958

Epoch: 5| Step: 2
Training loss: 0.22908377322233014
Validation loss: 2.297323757764175

Epoch: 5| Step: 3
Training loss: 0.39824670075332896
Validation loss: 2.2465041244296358

Epoch: 5| Step: 4
Training loss: 0.4257641185148811
Validation loss: 2.266312716799585

Epoch: 5| Step: 5
Training loss: 0.22633644040007647
Validation loss: 2.2304269974843636

Epoch: 5| Step: 6
Training loss: 0.511093835507056
Validation loss: 2.2513886397141816

Epoch: 5| Step: 7
Training loss: 0.4712362633734372
Validation loss: 2.2566160442597316

Epoch: 5| Step: 8
Training loss: 0.43168353389620795
Validation loss: 2.2545960608879283

Epoch: 5| Step: 9
Training loss: 0.25825472675347955
Validation loss: 2.2736474135379168

Epoch: 5| Step: 10
Training loss: 0.673737649786716
Validation loss: 2.2589605158963093

Epoch: 443| Step: 0
Training loss: 0.3202211552143649
Validation loss: 2.3052062304399374

Epoch: 5| Step: 1
Training loss: 0.5076809052373977
Validation loss: 2.270433743164385

Epoch: 5| Step: 2
Training loss: 0.2833401052750266
Validation loss: 2.3063364955741337

Epoch: 5| Step: 3
Training loss: 0.373199192127813
Validation loss: 2.299251976956534

Epoch: 5| Step: 4
Training loss: 0.45386738635406093
Validation loss: 2.3033584213522955

Epoch: 5| Step: 5
Training loss: 0.29933908199275056
Validation loss: 2.2767633495551967

Epoch: 5| Step: 6
Training loss: 0.5034453479858411
Validation loss: 2.2980711144589376

Epoch: 5| Step: 7
Training loss: 0.42671130033825533
Validation loss: 2.2610266828135788

Epoch: 5| Step: 8
Training loss: 0.39532715238775157
Validation loss: 2.2454626405693903

Epoch: 5| Step: 9
Training loss: 0.44791734680597284
Validation loss: 2.2735146569793514

Epoch: 5| Step: 10
Training loss: 0.4431358815997157
Validation loss: 2.2735632283138036

Epoch: 444| Step: 0
Training loss: 0.443908183688793
Validation loss: 2.3358616092426456

Epoch: 5| Step: 1
Training loss: 0.534021022741782
Validation loss: 2.307140740865953

Epoch: 5| Step: 2
Training loss: 0.2211477645026644
Validation loss: 2.3224878406911706

Epoch: 5| Step: 3
Training loss: 0.5146306304456848
Validation loss: 2.3134479713736256

Epoch: 5| Step: 4
Training loss: 0.28817403707038103
Validation loss: 2.306759776987074

Epoch: 5| Step: 5
Training loss: 0.23907927254823433
Validation loss: 2.2814325711066403

Epoch: 5| Step: 6
Training loss: 0.5089838456848624
Validation loss: 2.2919782462159786

Epoch: 5| Step: 7
Training loss: 0.19232508960076172
Validation loss: 2.3143682906425167

Epoch: 5| Step: 8
Training loss: 0.3881141264554854
Validation loss: 2.3357100464330682

Epoch: 5| Step: 9
Training loss: 0.4546556599273827
Validation loss: 2.3086643119719388

Epoch: 5| Step: 10
Training loss: 0.4569454275556744
Validation loss: 2.3251481306627633

Epoch: 445| Step: 0
Training loss: 0.534901885679697
Validation loss: 2.297271247878914

Epoch: 5| Step: 1
Training loss: 0.2713555915609621
Validation loss: 2.2916645728704856

Epoch: 5| Step: 2
Training loss: 0.49553489746360274
Validation loss: 2.3182324113655697

Epoch: 5| Step: 3
Training loss: 0.4079486656139556
Validation loss: 2.3362601791247255

Epoch: 5| Step: 4
Training loss: 0.25271103587570115
Validation loss: 2.3325977953342893

Epoch: 5| Step: 5
Training loss: 0.34665974304425623
Validation loss: 2.287733433082388

Epoch: 5| Step: 6
Training loss: 0.5276237874526619
Validation loss: 2.287818811902264

Epoch: 5| Step: 7
Training loss: 0.46427969810758996
Validation loss: 2.267201345909765

Epoch: 5| Step: 8
Training loss: 0.4194720853434077
Validation loss: 2.2884947089999486

Epoch: 5| Step: 9
Training loss: 0.3988796660384373
Validation loss: 2.2932544763692055

Epoch: 5| Step: 10
Training loss: 0.2851679812591844
Validation loss: 2.2788886349375748

Epoch: 446| Step: 0
Training loss: 0.45315543434275374
Validation loss: 2.308829835922615

Epoch: 5| Step: 1
Training loss: 0.41250665326966224
Validation loss: 2.3487332975248227

Epoch: 5| Step: 2
Training loss: 0.35968313275825337
Validation loss: 2.3419757988718986

Epoch: 5| Step: 3
Training loss: 0.3297401820030596
Validation loss: 2.344185122772153

Epoch: 5| Step: 4
Training loss: 0.4055543408618805
Validation loss: 2.3457711663570544

Epoch: 5| Step: 5
Training loss: 0.39456395684064993
Validation loss: 2.315098809649313

Epoch: 5| Step: 6
Training loss: 0.4723970317159451
Validation loss: 2.3339792916147344

Epoch: 5| Step: 7
Training loss: 0.5108205760661378
Validation loss: 2.3340319186150724

Epoch: 5| Step: 8
Training loss: 0.43460173761136295
Validation loss: 2.3258484752426662

Epoch: 5| Step: 9
Training loss: 0.22184392751795975
Validation loss: 2.3295017093987376

Epoch: 5| Step: 10
Training loss: 0.3676271849758326
Validation loss: 2.3101594971006123

Epoch: 447| Step: 0
Training loss: 0.5452025589608601
Validation loss: 2.319354648516772

Epoch: 5| Step: 1
Training loss: 0.28206206018695484
Validation loss: 2.3022686132942694

Epoch: 5| Step: 2
Training loss: 0.27457386671765155
Validation loss: 2.3232280982831877

Epoch: 5| Step: 3
Training loss: 0.6833189057556093
Validation loss: 2.3129349166269497

Epoch: 5| Step: 4
Training loss: 0.20125006110030486
Validation loss: 2.3258948360504554

Epoch: 5| Step: 5
Training loss: 0.3066321693761031
Validation loss: 2.3262466414929013

Epoch: 5| Step: 6
Training loss: 0.3690366043385923
Validation loss: 2.3287799357482486

Epoch: 5| Step: 7
Training loss: 0.30772607480796665
Validation loss: 2.319977466366324

Epoch: 5| Step: 8
Training loss: 0.3944666403564671
Validation loss: 2.3300559649998616

Epoch: 5| Step: 9
Training loss: 0.4911504749983555
Validation loss: 2.3275331949546247

Epoch: 5| Step: 10
Training loss: 0.27942203838324625
Validation loss: 2.313911722679986

Epoch: 448| Step: 0
Training loss: 0.31309540770564265
Validation loss: 2.337970361199601

Epoch: 5| Step: 1
Training loss: 0.5090382674077368
Validation loss: 2.2979439926616387

Epoch: 5| Step: 2
Training loss: 0.3107676770721125
Validation loss: 2.3221761743754703

Epoch: 5| Step: 3
Training loss: 0.4935048653711575
Validation loss: 2.2807293751693827

Epoch: 5| Step: 4
Training loss: 0.38923209756685134
Validation loss: 2.317712474974614

Epoch: 5| Step: 5
Training loss: 0.21606276344457603
Validation loss: 2.2985309711236455

Epoch: 5| Step: 6
Training loss: 0.30659655843561845
Validation loss: 2.2781405781717528

Epoch: 5| Step: 7
Training loss: 0.4578149873581323
Validation loss: 2.299279522594486

Epoch: 5| Step: 8
Training loss: 0.2765830851291609
Validation loss: 2.30166674454461

Epoch: 5| Step: 9
Training loss: 0.21138013210360268
Validation loss: 2.3333978102018795

Epoch: 5| Step: 10
Training loss: 0.6489806600519229
Validation loss: 2.314095461975684

Epoch: 449| Step: 0
Training loss: 0.1130283550060986
Validation loss: 2.2914083650359376

Epoch: 5| Step: 1
Training loss: 0.21228280924181314
Validation loss: 2.3069623606913376

Epoch: 5| Step: 2
Training loss: 0.31237063114275543
Validation loss: 2.318968528571046

Epoch: 5| Step: 3
Training loss: 0.5195563460864007
Validation loss: 2.298432545949271

Epoch: 5| Step: 4
Training loss: 0.36214313864058806
Validation loss: 2.3130118112144546

Epoch: 5| Step: 5
Training loss: 0.14418008388277734
Validation loss: 2.2859574263828235

Epoch: 5| Step: 6
Training loss: 0.4456088268079094
Validation loss: 2.3063881582673997

Epoch: 5| Step: 7
Training loss: 0.40901901987382633
Validation loss: 2.2936129437160466

Epoch: 5| Step: 8
Training loss: 0.5437475423647709
Validation loss: 2.288854752874864

Epoch: 5| Step: 9
Training loss: 0.3960864696548394
Validation loss: 2.286326534066002

Epoch: 5| Step: 10
Training loss: 0.5278290387685466
Validation loss: 2.283514424226694

Epoch: 450| Step: 0
Training loss: 0.32078361755627127
Validation loss: 2.306037701708831

Epoch: 5| Step: 1
Training loss: 0.4325491203682792
Validation loss: 2.322442298268712

Epoch: 5| Step: 2
Training loss: 0.31147379464693103
Validation loss: 2.3008436626343554

Epoch: 5| Step: 3
Training loss: 0.5490306874125276
Validation loss: 2.3244922775145818

Epoch: 5| Step: 4
Training loss: 0.3504416825126712
Validation loss: 2.3387249889516117

Epoch: 5| Step: 5
Training loss: 0.2042997666367651
Validation loss: 2.3433151191680732

Epoch: 5| Step: 6
Training loss: 0.3343245352338263
Validation loss: 2.2919730405832084

Epoch: 5| Step: 7
Training loss: 0.4188376868660922
Validation loss: 2.267476230692169

Epoch: 5| Step: 8
Training loss: 0.4981540041129208
Validation loss: 2.276475345005943

Epoch: 5| Step: 9
Training loss: 0.4338749326092078
Validation loss: 2.269582591560592

Epoch: 5| Step: 10
Training loss: 0.3042821388447122
Validation loss: 2.2757951657360667

Epoch: 451| Step: 0
Training loss: 0.343071810416189
Validation loss: 2.26087797094642

Epoch: 5| Step: 1
Training loss: 0.4941440928944362
Validation loss: 2.2877979475207733

Epoch: 5| Step: 2
Training loss: 0.22259144090779998
Validation loss: 2.2939424425827295

Epoch: 5| Step: 3
Training loss: 0.24900672706934976
Validation loss: 2.308021112513187

Epoch: 5| Step: 4
Training loss: 0.20960304452590497
Validation loss: 2.32486956928824

Epoch: 5| Step: 5
Training loss: 0.4714186362617126
Validation loss: 2.3229246076391754

Epoch: 5| Step: 6
Training loss: 0.46159990849956817
Validation loss: 2.3114614829264917

Epoch: 5| Step: 7
Training loss: 0.510750648326341
Validation loss: 2.31589128353927

Epoch: 5| Step: 8
Training loss: 0.33455126875766644
Validation loss: 2.3098494225898967

Epoch: 5| Step: 9
Training loss: 0.38192016375072124
Validation loss: 2.2777830838615922

Epoch: 5| Step: 10
Training loss: 0.5174534773531813
Validation loss: 2.279202438979314

Epoch: 452| Step: 0
Training loss: 0.18446487361874678
Validation loss: 2.2965978572848806

Epoch: 5| Step: 1
Training loss: 0.3690526948380546
Validation loss: 2.298505411878989

Epoch: 5| Step: 2
Training loss: 0.3603776751725601
Validation loss: 2.3134323511565595

Epoch: 5| Step: 3
Training loss: 0.19898254753145295
Validation loss: 2.2977671539326723

Epoch: 5| Step: 4
Training loss: 0.38942054068906884
Validation loss: 2.3342296373822777

Epoch: 5| Step: 5
Training loss: 0.521894943404457
Validation loss: 2.327391244611968

Epoch: 5| Step: 6
Training loss: 0.4030494611775079
Validation loss: 2.315226087413468

Epoch: 5| Step: 7
Training loss: 0.3553483151156114
Validation loss: 2.317357648142241

Epoch: 5| Step: 8
Training loss: 0.34731676907238485
Validation loss: 2.3059985336788067

Epoch: 5| Step: 9
Training loss: 0.3266667021821126
Validation loss: 2.2784758104215777

Epoch: 5| Step: 10
Training loss: 0.5899481270503097
Validation loss: 2.295236540136654

Epoch: 453| Step: 0
Training loss: 0.3780855749400257
Validation loss: 2.272753591608821

Epoch: 5| Step: 1
Training loss: 0.36809280070104655
Validation loss: 2.272277733549546

Epoch: 5| Step: 2
Training loss: 0.4452623874508989
Validation loss: 2.3174667242605316

Epoch: 5| Step: 3
Training loss: 0.22408469741925557
Validation loss: 2.3399955621787187

Epoch: 5| Step: 4
Training loss: 0.21867442528538047
Validation loss: 2.3176087794411977

Epoch: 5| Step: 5
Training loss: 0.4207022225061227
Validation loss: 2.344096185965664

Epoch: 5| Step: 6
Training loss: 0.5103463559153364
Validation loss: 2.3444978211425354

Epoch: 5| Step: 7
Training loss: 0.32072390908324766
Validation loss: 2.3185579006361916

Epoch: 5| Step: 8
Training loss: 0.4438093145782898
Validation loss: 2.3530505485083255

Epoch: 5| Step: 9
Training loss: 0.30337650738951877
Validation loss: 2.2707386213475127

Epoch: 5| Step: 10
Training loss: 0.5159459993342808
Validation loss: 2.3190554354290023

Epoch: 454| Step: 0
Training loss: 0.3538844466071993
Validation loss: 2.278543089816558

Epoch: 5| Step: 1
Training loss: 0.3688101525463909
Validation loss: 2.2966903155771567

Epoch: 5| Step: 2
Training loss: 0.261765091622214
Validation loss: 2.287993447477107

Epoch: 5| Step: 3
Training loss: 0.37325995785715665
Validation loss: 2.273002433750902

Epoch: 5| Step: 4
Training loss: 0.5153659400967059
Validation loss: 2.2846938786017787

Epoch: 5| Step: 5
Training loss: 0.317941215503925
Validation loss: 2.264297375007815

Epoch: 5| Step: 6
Training loss: 0.2608584741175274
Validation loss: 2.2713095203428515

Epoch: 5| Step: 7
Training loss: 0.46813552635795214
Validation loss: 2.2774498371875516

Epoch: 5| Step: 8
Training loss: 0.45900304228786276
Validation loss: 2.2862686667952445

Epoch: 5| Step: 9
Training loss: 0.2747983854502511
Validation loss: 2.297765866403552

Epoch: 5| Step: 10
Training loss: 0.4479819146767609
Validation loss: 2.2796172152160072

Epoch: 455| Step: 0
Training loss: 0.4256096940502418
Validation loss: 2.274828702059491

Epoch: 5| Step: 1
Training loss: 0.4568311954429942
Validation loss: 2.283937912892383

Epoch: 5| Step: 2
Training loss: 0.36206429210122526
Validation loss: 2.3268799366150987

Epoch: 5| Step: 3
Training loss: 0.3312054968575015
Validation loss: 2.294022899486891

Epoch: 5| Step: 4
Training loss: 0.21578685794644867
Validation loss: 2.2938798075321176

Epoch: 5| Step: 5
Training loss: 0.22949379453705115
Validation loss: 2.312781102046776

Epoch: 5| Step: 6
Training loss: 0.21253792830986468
Validation loss: 2.2695905001948504

Epoch: 5| Step: 7
Training loss: 0.4771145452953513
Validation loss: 2.2959235679584866

Epoch: 5| Step: 8
Training loss: 0.4667988222472624
Validation loss: 2.3096290866553977

Epoch: 5| Step: 9
Training loss: 0.46774428880060276
Validation loss: 2.3010159966823323

Epoch: 5| Step: 10
Training loss: 0.36868764948255833
Validation loss: 2.3362933675345516

Epoch: 456| Step: 0
Training loss: 0.2602373157244594
Validation loss: 2.314473003085574

Epoch: 5| Step: 1
Training loss: 0.3187178015808423
Validation loss: 2.294814814800015

Epoch: 5| Step: 2
Training loss: 0.25195248921632024
Validation loss: 2.3128919261004692

Epoch: 5| Step: 3
Training loss: 0.25983896869290773
Validation loss: 2.3057054610612275

Epoch: 5| Step: 4
Training loss: 0.5147871087599499
Validation loss: 2.285888832671091

Epoch: 5| Step: 5
Training loss: 0.6341070426685779
Validation loss: 2.2933409458083185

Epoch: 5| Step: 6
Training loss: 0.31340994676712264
Validation loss: 2.272516195373845

Epoch: 5| Step: 7
Training loss: 0.4403041313843513
Validation loss: 2.290020076691286

Epoch: 5| Step: 8
Training loss: 0.381760045775643
Validation loss: 2.268680484142558

Epoch: 5| Step: 9
Training loss: 0.3201051366468374
Validation loss: 2.2993169422658735

Epoch: 5| Step: 10
Training loss: 0.35006914860684885
Validation loss: 2.289617902044338

Epoch: 457| Step: 0
Training loss: 0.36725329763257625
Validation loss: 2.2929402128597687

Epoch: 5| Step: 1
Training loss: 0.29716973982730427
Validation loss: 2.2824663264836023

Epoch: 5| Step: 2
Training loss: 0.5003605377180897
Validation loss: 2.2856512060425747

Epoch: 5| Step: 3
Training loss: 0.4915139569991139
Validation loss: 2.2835544303386905

Epoch: 5| Step: 4
Training loss: 0.3467569936605353
Validation loss: 2.290002866240683

Epoch: 5| Step: 5
Training loss: 0.31806398507339534
Validation loss: 2.3084926282901934

Epoch: 5| Step: 6
Training loss: 0.49542611921878627
Validation loss: 2.2891005153425903

Epoch: 5| Step: 7
Training loss: 0.22121718132291654
Validation loss: 2.281913329367216

Epoch: 5| Step: 8
Training loss: 0.3565594843035656
Validation loss: 2.2666555225763703

Epoch: 5| Step: 9
Training loss: 0.44367971065082085
Validation loss: 2.236116919686933

Epoch: 5| Step: 10
Training loss: 0.5187546224273271
Validation loss: 2.245323366767169

Epoch: 458| Step: 0
Training loss: 0.49005638934231016
Validation loss: 2.2562883082661664

Epoch: 5| Step: 1
Training loss: 0.4951392475457993
Validation loss: 2.270542106532618

Epoch: 5| Step: 2
Training loss: 0.39545174660484467
Validation loss: 2.28841683207955

Epoch: 5| Step: 3
Training loss: 0.34694678534642853
Validation loss: 2.2984133347307347

Epoch: 5| Step: 4
Training loss: 0.4216320963335033
Validation loss: 2.309239770759098

Epoch: 5| Step: 5
Training loss: 0.3408250890358844
Validation loss: 2.3273435075090148

Epoch: 5| Step: 6
Training loss: 0.2647777255645485
Validation loss: 2.278487445629642

Epoch: 5| Step: 7
Training loss: 0.5599344343733171
Validation loss: 2.2902286981287068

Epoch: 5| Step: 8
Training loss: 0.3507736999616769
Validation loss: 2.295534289667222

Epoch: 5| Step: 9
Training loss: 0.4738141686002925
Validation loss: 2.2851262443570133

Epoch: 5| Step: 10
Training loss: 0.27552390424366685
Validation loss: 2.2587057399691712

Epoch: 459| Step: 0
Training loss: 0.3816373655088266
Validation loss: 2.2728591920325876

Epoch: 5| Step: 1
Training loss: 0.5004260512950828
Validation loss: 2.247376721504222

Epoch: 5| Step: 2
Training loss: 0.3839336637304979
Validation loss: 2.266793484581443

Epoch: 5| Step: 3
Training loss: 0.4689245217007006
Validation loss: 2.285477823917303

Epoch: 5| Step: 4
Training loss: 0.23113231177289478
Validation loss: 2.33734065998796

Epoch: 5| Step: 5
Training loss: 0.46283921225846614
Validation loss: 2.32441141721324

Epoch: 5| Step: 6
Training loss: 0.5436733257561036
Validation loss: 2.3334591724665925

Epoch: 5| Step: 7
Training loss: 0.25019624577392136
Validation loss: 2.3404714074732964

Epoch: 5| Step: 8
Training loss: 0.36785359534683937
Validation loss: 2.288033990964148

Epoch: 5| Step: 9
Training loss: 0.3980444671288494
Validation loss: 2.2978539678800547

Epoch: 5| Step: 10
Training loss: 0.2834596721552694
Validation loss: 2.2821754458512453

Epoch: 460| Step: 0
Training loss: 0.33088047090942596
Validation loss: 2.268364140667226

Epoch: 5| Step: 1
Training loss: 0.22878397973230677
Validation loss: 2.3064210106832914

Epoch: 5| Step: 2
Training loss: 0.2733079876041987
Validation loss: 2.268734760324203

Epoch: 5| Step: 3
Training loss: 0.38403685047238884
Validation loss: 2.3147448225981795

Epoch: 5| Step: 4
Training loss: 0.5133858235985074
Validation loss: 2.3042059059928195

Epoch: 5| Step: 5
Training loss: 0.5646541989697899
Validation loss: 2.296985967591184

Epoch: 5| Step: 6
Training loss: 0.5308750175546132
Validation loss: 2.3266502643314624

Epoch: 5| Step: 7
Training loss: 0.28024859434603905
Validation loss: 2.2991337627850577

Epoch: 5| Step: 8
Training loss: 0.136300749065859
Validation loss: 2.3036462733293743

Epoch: 5| Step: 9
Training loss: 0.36179912901694966
Validation loss: 2.251373398825237

Epoch: 5| Step: 10
Training loss: 0.2321054484479182
Validation loss: 2.2857152896769395

Epoch: 461| Step: 0
Training loss: 0.17312106981016712
Validation loss: 2.2541262278895755

Epoch: 5| Step: 1
Training loss: 0.2728414988317302
Validation loss: 2.290177702997462

Epoch: 5| Step: 2
Training loss: 0.37502014582879484
Validation loss: 2.3157297764634404

Epoch: 5| Step: 3
Training loss: 0.37828914295330474
Validation loss: 2.306270706720083

Epoch: 5| Step: 4
Training loss: 0.371444837229095
Validation loss: 2.312174200129363

Epoch: 5| Step: 5
Training loss: 0.40253157074243767
Validation loss: 2.3313488505235473

Epoch: 5| Step: 6
Training loss: 0.454834230088123
Validation loss: 2.3186190132416393

Epoch: 5| Step: 7
Training loss: 0.2769725894948073
Validation loss: 2.3033734089773925

Epoch: 5| Step: 8
Training loss: 0.3208265831266117
Validation loss: 2.340727381679078

Epoch: 5| Step: 9
Training loss: 0.4936136141864857
Validation loss: 2.316303023232851

Epoch: 5| Step: 10
Training loss: 0.598993314191478
Validation loss: 2.314525450017808

Epoch: 462| Step: 0
Training loss: 0.3714259216979115
Validation loss: 2.2627855430618906

Epoch: 5| Step: 1
Training loss: 0.43137327173860124
Validation loss: 2.287775203172791

Epoch: 5| Step: 2
Training loss: 0.3989165548987571
Validation loss: 2.2636436253885

Epoch: 5| Step: 3
Training loss: 0.5176499226992607
Validation loss: 2.267278616737534

Epoch: 5| Step: 4
Training loss: 0.34501377708804326
Validation loss: 2.2733642777203835

Epoch: 5| Step: 5
Training loss: 0.4144180858300617
Validation loss: 2.279059405835327

Epoch: 5| Step: 6
Training loss: 0.38518458759296825
Validation loss: 2.306041719974012

Epoch: 5| Step: 7
Training loss: 0.29665564916186804
Validation loss: 2.3288740175616636

Epoch: 5| Step: 8
Training loss: 0.38003980045441044
Validation loss: 2.32376456699963

Epoch: 5| Step: 9
Training loss: 0.34155046572691883
Validation loss: 2.327496147689644

Epoch: 5| Step: 10
Training loss: 0.3253351661158715
Validation loss: 2.310348247981664

Epoch: 463| Step: 0
Training loss: 0.33735596797668493
Validation loss: 2.2946852178652013

Epoch: 5| Step: 1
Training loss: 0.3232418763311911
Validation loss: 2.298628576805691

Epoch: 5| Step: 2
Training loss: 0.31835731552487617
Validation loss: 2.298764408590597

Epoch: 5| Step: 3
Training loss: 0.42334241327300143
Validation loss: 2.2866814998450673

Epoch: 5| Step: 4
Training loss: 0.46677430549231985
Validation loss: 2.26424137874822

Epoch: 5| Step: 5
Training loss: 0.3398110713812943
Validation loss: 2.2474972274000113

Epoch: 5| Step: 6
Training loss: 0.4020025417546439
Validation loss: 2.2675772929052496

Epoch: 5| Step: 7
Training loss: 0.36945775452437957
Validation loss: 2.257505248142281

Epoch: 5| Step: 8
Training loss: 0.30740202387659743
Validation loss: 2.28827872852877

Epoch: 5| Step: 9
Training loss: 0.3313026624779551
Validation loss: 2.2704442001184018

Epoch: 5| Step: 10
Training loss: 0.38514659629624187
Validation loss: 2.2939032289608865

Epoch: 464| Step: 0
Training loss: 0.22983514037043143
Validation loss: 2.285456518080646

Epoch: 5| Step: 1
Training loss: 0.3786200789657284
Validation loss: 2.2841148245024865

Epoch: 5| Step: 2
Training loss: 0.38164378841342417
Validation loss: 2.2783589003426052

Epoch: 5| Step: 3
Training loss: 0.34240899995014806
Validation loss: 2.2744106370420383

Epoch: 5| Step: 4
Training loss: 0.3394322370241623
Validation loss: 2.2717491674640833

Epoch: 5| Step: 5
Training loss: 0.30880193086336105
Validation loss: 2.2660892518697944

Epoch: 5| Step: 6
Training loss: 0.5396844896719625
Validation loss: 2.235939807156426

Epoch: 5| Step: 7
Training loss: 0.3478680297792019
Validation loss: 2.2510046020808594

Epoch: 5| Step: 8
Training loss: 0.2756881324321487
Validation loss: 2.2892423925368264

Epoch: 5| Step: 9
Training loss: 0.4315964861780248
Validation loss: 2.2946709164412917

Epoch: 5| Step: 10
Training loss: 0.3205573495245458
Validation loss: 2.3098209119837816

Epoch: 465| Step: 0
Training loss: 0.41702068508425255
Validation loss: 2.27711467230674

Epoch: 5| Step: 1
Training loss: 0.41149464177435807
Validation loss: 2.252207461640646

Epoch: 5| Step: 2
Training loss: 0.33069677895184746
Validation loss: 2.2547367684461945

Epoch: 5| Step: 3
Training loss: 0.3244005405977145
Validation loss: 2.249190848138919

Epoch: 5| Step: 4
Training loss: 0.2749305561556335
Validation loss: 2.2586475498212373

Epoch: 5| Step: 5
Training loss: 0.3810781779593623
Validation loss: 2.254216852627042

Epoch: 5| Step: 6
Training loss: 0.3293007267809278
Validation loss: 2.233716972666934

Epoch: 5| Step: 7
Training loss: 0.160251385647456
Validation loss: 2.2500779640882516

Epoch: 5| Step: 8
Training loss: 0.43639399168811144
Validation loss: 2.2673072529855176

Epoch: 5| Step: 9
Training loss: 0.49554482074848816
Validation loss: 2.2805687256099945

Epoch: 5| Step: 10
Training loss: 0.1968599056330909
Validation loss: 2.2805288245013875

Epoch: 466| Step: 0
Training loss: 0.4094701387058254
Validation loss: 2.258835141503078

Epoch: 5| Step: 1
Training loss: 0.3194482588309917
Validation loss: 2.251614803542357

Epoch: 5| Step: 2
Training loss: 0.2865877928226479
Validation loss: 2.255751205824875

Epoch: 5| Step: 3
Training loss: 0.11266080536276238
Validation loss: 2.2657900220088107

Epoch: 5| Step: 4
Training loss: 0.4229193053922719
Validation loss: 2.23568644761062

Epoch: 5| Step: 5
Training loss: 0.31187596001792645
Validation loss: 2.2593888626963468

Epoch: 5| Step: 6
Training loss: 0.4849039696469373
Validation loss: 2.2685420792000053

Epoch: 5| Step: 7
Training loss: 0.3272879345816853
Validation loss: 2.264034694426522

Epoch: 5| Step: 8
Training loss: 0.2476700902254476
Validation loss: 2.2724650794405106

Epoch: 5| Step: 9
Training loss: 0.4282024731115186
Validation loss: 2.3063975941035837

Epoch: 5| Step: 10
Training loss: 0.4188008626252666
Validation loss: 2.2656692325176606

Epoch: 467| Step: 0
Training loss: 0.29536667180599646
Validation loss: 2.2611225757955076

Epoch: 5| Step: 1
Training loss: 0.4905759373813607
Validation loss: 2.283180757066677

Epoch: 5| Step: 2
Training loss: 0.20386563587201265
Validation loss: 2.2839636042907046

Epoch: 5| Step: 3
Training loss: 0.45070004252363116
Validation loss: 2.281534248878729

Epoch: 5| Step: 4
Training loss: 0.28928346178903563
Validation loss: 2.2955882581389506

Epoch: 5| Step: 5
Training loss: 0.2850244557194381
Validation loss: 2.287389996315204

Epoch: 5| Step: 6
Training loss: 0.35563289080482124
Validation loss: 2.2880933939509793

Epoch: 5| Step: 7
Training loss: 0.4037522411579489
Validation loss: 2.274462228581663

Epoch: 5| Step: 8
Training loss: 0.31359693408712375
Validation loss: 2.3176533745866355

Epoch: 5| Step: 9
Training loss: 0.4443721211550745
Validation loss: 2.32543825739856

Epoch: 5| Step: 10
Training loss: 0.21777318090586237
Validation loss: 2.2898022640206737

Epoch: 468| Step: 0
Training loss: 0.20088969504426046
Validation loss: 2.316791309778771

Epoch: 5| Step: 1
Training loss: 0.4239385434654832
Validation loss: 2.289852781061715

Epoch: 5| Step: 2
Training loss: 0.4421817415219679
Validation loss: 2.2954056201383595

Epoch: 5| Step: 3
Training loss: 0.5629377251429047
Validation loss: 2.26546545290816

Epoch: 5| Step: 4
Training loss: 0.4305143204122627
Validation loss: 2.2566466692628913

Epoch: 5| Step: 5
Training loss: 0.33547036272291164
Validation loss: 2.29389504540205

Epoch: 5| Step: 6
Training loss: 0.27531965166344224
Validation loss: 2.3146103207035797

Epoch: 5| Step: 7
Training loss: 0.26110844123914884
Validation loss: 2.2956396747012406

Epoch: 5| Step: 8
Training loss: 0.19181348336403692
Validation loss: 2.2895640828464145

Epoch: 5| Step: 9
Training loss: 0.2725122054892539
Validation loss: 2.3116711264865066

Epoch: 5| Step: 10
Training loss: 0.336213985042382
Validation loss: 2.2824983753280823

Epoch: 469| Step: 0
Training loss: 0.2768272372052466
Validation loss: 2.280314683182138

Epoch: 5| Step: 1
Training loss: 0.18040843095952838
Validation loss: 2.267503901173225

Epoch: 5| Step: 2
Training loss: 0.5315466781674605
Validation loss: 2.250139367721997

Epoch: 5| Step: 3
Training loss: 0.12222469485676488
Validation loss: 2.2777716234479004

Epoch: 5| Step: 4
Training loss: 0.441856171855663
Validation loss: 2.3062214058115713

Epoch: 5| Step: 5
Training loss: 0.12081959284220589
Validation loss: 2.303443612782502

Epoch: 5| Step: 6
Training loss: 0.43817762281967365
Validation loss: 2.3143359586814154

Epoch: 5| Step: 7
Training loss: 0.3187060194901933
Validation loss: 2.2937254494511685

Epoch: 5| Step: 8
Training loss: 0.294092173340981
Validation loss: 2.3178321566567233

Epoch: 5| Step: 9
Training loss: 0.48025040976602684
Validation loss: 2.287341216473858

Epoch: 5| Step: 10
Training loss: 0.35261249569963843
Validation loss: 2.287060595898985

Epoch: 470| Step: 0
Training loss: 0.29137402425330133
Validation loss: 2.298366755050281

Epoch: 5| Step: 1
Training loss: 0.30921453495246587
Validation loss: 2.317171882321914

Epoch: 5| Step: 2
Training loss: 0.3351685572856527
Validation loss: 2.3012741616339842

Epoch: 5| Step: 3
Training loss: 0.44097680325602495
Validation loss: 2.322119632146354

Epoch: 5| Step: 4
Training loss: 0.3560261391114079
Validation loss: 2.3017439036339975

Epoch: 5| Step: 5
Training loss: 0.3880141362203276
Validation loss: 2.3234042525918515

Epoch: 5| Step: 6
Training loss: 0.38009598347971224
Validation loss: 2.306310475937094

Epoch: 5| Step: 7
Training loss: 0.3430002337106014
Validation loss: 2.293370383419561

Epoch: 5| Step: 8
Training loss: 0.5064106886356395
Validation loss: 2.317576692904701

Epoch: 5| Step: 9
Training loss: 0.23439307937827217
Validation loss: 2.3003042278011248

Epoch: 5| Step: 10
Training loss: 0.15407994267337652
Validation loss: 2.2867104872979067

Epoch: 471| Step: 0
Training loss: 0.29460640006736993
Validation loss: 2.3083887037789554

Epoch: 5| Step: 1
Training loss: 0.3036834360900024
Validation loss: 2.3146626615207992

Epoch: 5| Step: 2
Training loss: 0.467894902715334
Validation loss: 2.282525129153064

Epoch: 5| Step: 3
Training loss: 0.34045576476097417
Validation loss: 2.332031735897881

Epoch: 5| Step: 4
Training loss: 0.4464107155634928
Validation loss: 2.316983410707805

Epoch: 5| Step: 5
Training loss: 0.2560547381298443
Validation loss: 2.3276776609882206

Epoch: 5| Step: 6
Training loss: 0.281625880623942
Validation loss: 2.3519688818849103

Epoch: 5| Step: 7
Training loss: 0.5014954495399447
Validation loss: 2.3426251945293397

Epoch: 5| Step: 8
Training loss: 0.2808003407326489
Validation loss: 2.352291880519851

Epoch: 5| Step: 9
Training loss: 0.2274613309054647
Validation loss: 2.333417312660718

Epoch: 5| Step: 10
Training loss: 0.40143983652170456
Validation loss: 2.2933494387555613

Epoch: 472| Step: 0
Training loss: 0.49276154965316576
Validation loss: 2.3158347018830083

Epoch: 5| Step: 1
Training loss: 0.2987343634818846
Validation loss: 2.3324094562427735

Epoch: 5| Step: 2
Training loss: 0.35431824507188064
Validation loss: 2.300536021056921

Epoch: 5| Step: 3
Training loss: 0.38624958516688124
Validation loss: 2.2830357441931266

Epoch: 5| Step: 4
Training loss: 0.2136618268371915
Validation loss: 2.3115493640772824

Epoch: 5| Step: 5
Training loss: 0.21379493991071144
Validation loss: 2.337752144930986

Epoch: 5| Step: 6
Training loss: 0.40833576000556515
Validation loss: 2.3515484082128824

Epoch: 5| Step: 7
Training loss: 0.32591125218009853
Validation loss: 2.3429339852609865

Epoch: 5| Step: 8
Training loss: 0.3332783671101047
Validation loss: 2.346422789332287

Epoch: 5| Step: 9
Training loss: 0.33532143814674054
Validation loss: 2.292010796252832

Epoch: 5| Step: 10
Training loss: 0.5031534234305098
Validation loss: 2.28979433002955

Epoch: 473| Step: 0
Training loss: 0.19401322219834155
Validation loss: 2.291543995509594

Epoch: 5| Step: 1
Training loss: 0.43887151589527673
Validation loss: 2.249434237066167

Epoch: 5| Step: 2
Training loss: 0.4439406764354382
Validation loss: 2.29210752197548

Epoch: 5| Step: 3
Training loss: 0.29679274674386463
Validation loss: 2.2586881660623543

Epoch: 5| Step: 4
Training loss: 0.3599937337091581
Validation loss: 2.2650050768113625

Epoch: 5| Step: 5
Training loss: 0.46105252463300384
Validation loss: 2.2735606630516356

Epoch: 5| Step: 6
Training loss: 0.46101655120575563
Validation loss: 2.2852525248868707

Epoch: 5| Step: 7
Training loss: 0.227412855977864
Validation loss: 2.302740793181718

Epoch: 5| Step: 8
Training loss: 0.20622234845479434
Validation loss: 2.3187704549040395

Epoch: 5| Step: 9
Training loss: 0.2418228372739001
Validation loss: 2.3133905276397884

Epoch: 5| Step: 10
Training loss: 0.31820159934221587
Validation loss: 2.3114848992243515

Epoch: 474| Step: 0
Training loss: 0.27355684673105923
Validation loss: 2.326515191223479

Epoch: 5| Step: 1
Training loss: 0.3006910089642088
Validation loss: 2.3221031337794207

Epoch: 5| Step: 2
Training loss: 0.2780183459032843
Validation loss: 2.304772357549919

Epoch: 5| Step: 3
Training loss: 0.48367968767843944
Validation loss: 2.2956512374340963

Epoch: 5| Step: 4
Training loss: 0.22200153530509265
Validation loss: 2.288521964035758

Epoch: 5| Step: 5
Training loss: 0.2888072407533996
Validation loss: 2.305529796980132

Epoch: 5| Step: 6
Training loss: 0.4955628174718118
Validation loss: 2.2904327971366603

Epoch: 5| Step: 7
Training loss: 0.1809779147404938
Validation loss: 2.2731889530300298

Epoch: 5| Step: 8
Training loss: 0.35924034083633644
Validation loss: 2.328021991810444

Epoch: 5| Step: 9
Training loss: 0.3108733278696625
Validation loss: 2.3092312158001973

Epoch: 5| Step: 10
Training loss: 0.37292530415652925
Validation loss: 2.2884428675248554

Epoch: 475| Step: 0
Training loss: 0.13063629551011852
Validation loss: 2.3013678746375685

Epoch: 5| Step: 1
Training loss: 0.28036800477157536
Validation loss: 2.292749725841961

Epoch: 5| Step: 2
Training loss: 0.4907764917705911
Validation loss: 2.303242559467707

Epoch: 5| Step: 3
Training loss: 0.49239219465929474
Validation loss: 2.305887153183848

Epoch: 5| Step: 4
Training loss: 0.33778236286489266
Validation loss: 2.285133782265723

Epoch: 5| Step: 5
Training loss: 0.34973858198570273
Validation loss: 2.2730330302755926

Epoch: 5| Step: 6
Training loss: 0.17736587470428705
Validation loss: 2.275258051843364

Epoch: 5| Step: 7
Training loss: 0.24109035829493394
Validation loss: 2.2616674980012546

Epoch: 5| Step: 8
Training loss: 0.3557465065471611
Validation loss: 2.260120616488869

Epoch: 5| Step: 9
Training loss: 0.30549017009123125
Validation loss: 2.273396739616169

Epoch: 5| Step: 10
Training loss: 0.38023991214129177
Validation loss: 2.3263781740809866

Epoch: 476| Step: 0
Training loss: 0.28400011714241136
Validation loss: 2.257620007481469

Epoch: 5| Step: 1
Training loss: 0.41148017471223736
Validation loss: 2.3040474418795567

Epoch: 5| Step: 2
Training loss: 0.1994727142791081
Validation loss: 2.3257059006816307

Epoch: 5| Step: 3
Training loss: 0.6077950855104141
Validation loss: 2.27252322318539

Epoch: 5| Step: 4
Training loss: 0.36923745313388606
Validation loss: 2.277462602168303

Epoch: 5| Step: 5
Training loss: 0.18670743085956235
Validation loss: 2.2881465430089403

Epoch: 5| Step: 6
Training loss: 0.18159496594889923
Validation loss: 2.2859523281586873

Epoch: 5| Step: 7
Training loss: 0.2788850642687581
Validation loss: 2.299455871527211

Epoch: 5| Step: 8
Training loss: 0.3455826177531379
Validation loss: 2.268398337140473

Epoch: 5| Step: 9
Training loss: 0.19800660741623322
Validation loss: 2.300790285418336

Epoch: 5| Step: 10
Training loss: 0.2889365231016603
Validation loss: 2.312007043894869

Epoch: 477| Step: 0
Training loss: 0.6705341488393789
Validation loss: 2.3110745245604107

Epoch: 5| Step: 1
Training loss: 0.12287368772282324
Validation loss: 2.3034065447944996

Epoch: 5| Step: 2
Training loss: 0.3340360701858519
Validation loss: 2.3254889654714495

Epoch: 5| Step: 3
Training loss: 0.40279420617277945
Validation loss: 2.31955346198485

Epoch: 5| Step: 4
Training loss: 0.19513747956508767
Validation loss: 2.325755395919568

Epoch: 5| Step: 5
Training loss: 0.32938075462323313
Validation loss: 2.325493302345546

Epoch: 5| Step: 6
Training loss: 0.24123951514837597
Validation loss: 2.2837811277570643

Epoch: 5| Step: 7
Training loss: 0.34764174098910255
Validation loss: 2.3021868432517865

Epoch: 5| Step: 8
Training loss: 0.22943002386442263
Validation loss: 2.290759782720956

Epoch: 5| Step: 9
Training loss: 0.15633305487992608
Validation loss: 2.3526231404757807

Epoch: 5| Step: 10
Training loss: 0.12236866920098725
Validation loss: 2.302669175724895

Epoch: 478| Step: 0
Training loss: 0.47710620632340583
Validation loss: 2.326258582176447

Epoch: 5| Step: 1
Training loss: 0.3040635248698167
Validation loss: 2.326035792096364

Epoch: 5| Step: 2
Training loss: 0.31773461431189914
Validation loss: 2.3117530024221082

Epoch: 5| Step: 3
Training loss: 0.329353179733664
Validation loss: 2.313228978677139

Epoch: 5| Step: 4
Training loss: 0.3467708628937027
Validation loss: 2.2974383676393955

Epoch: 5| Step: 5
Training loss: 0.3536956918633633
Validation loss: 2.3217253317156565

Epoch: 5| Step: 6
Training loss: 0.3733303929997924
Validation loss: 2.2916863322229917

Epoch: 5| Step: 7
Training loss: 0.19650612401701328
Validation loss: 2.2961409071442436

Epoch: 5| Step: 8
Training loss: 0.36004331891048985
Validation loss: 2.3096902534785153

Epoch: 5| Step: 9
Training loss: 0.22630817015919277
Validation loss: 2.328247495441581

Epoch: 5| Step: 10
Training loss: 0.289613006235619
Validation loss: 2.317279469511125

Epoch: 479| Step: 0
Training loss: 0.20547950158073697
Validation loss: 2.312512871934519

Epoch: 5| Step: 1
Training loss: 0.2648445753911753
Validation loss: 2.34355274094991

Epoch: 5| Step: 2
Training loss: 0.3330998335523542
Validation loss: 2.3212440509792693

Epoch: 5| Step: 3
Training loss: 0.2047593136382015
Validation loss: 2.321441507196383

Epoch: 5| Step: 4
Training loss: 0.3867404045438547
Validation loss: 2.2994843289214666

Epoch: 5| Step: 5
Training loss: 0.24529922990077405
Validation loss: 2.3047195023556375

Epoch: 5| Step: 6
Training loss: 0.3344045973539889
Validation loss: 2.2717033391227255

Epoch: 5| Step: 7
Training loss: 0.37424605793555454
Validation loss: 2.274353734121675

Epoch: 5| Step: 8
Training loss: 0.48053288225600155
Validation loss: 2.2791901786563136

Epoch: 5| Step: 9
Training loss: 0.34487180378806104
Validation loss: 2.2685301296718374

Epoch: 5| Step: 10
Training loss: 0.2807380467262483
Validation loss: 2.2701209822118575

Epoch: 480| Step: 0
Training loss: 0.28903410746345315
Validation loss: 2.265379276606645

Epoch: 5| Step: 1
Training loss: 0.3245589298571287
Validation loss: 2.297576582847842

Epoch: 5| Step: 2
Training loss: 0.25855819192607227
Validation loss: 2.2861515838880844

Epoch: 5| Step: 3
Training loss: 0.4379381642326369
Validation loss: 2.2920206704518615

Epoch: 5| Step: 4
Training loss: 0.4721023687574742
Validation loss: 2.2837733866931025

Epoch: 5| Step: 5
Training loss: 0.23404973825467784
Validation loss: 2.275520782290068

Epoch: 5| Step: 6
Training loss: 0.36410752537836283
Validation loss: 2.2659046332917185

Epoch: 5| Step: 7
Training loss: 0.23824520307447178
Validation loss: 2.255561635160932

Epoch: 5| Step: 8
Training loss: 0.23155208329981236
Validation loss: 2.2538704334608766

Epoch: 5| Step: 9
Training loss: 0.31188600541766104
Validation loss: 2.298979068320269

Epoch: 5| Step: 10
Training loss: 0.3571602118907637
Validation loss: 2.2790797180458657

Epoch: 481| Step: 0
Training loss: 0.1832736247721237
Validation loss: 2.3060352353832423

Epoch: 5| Step: 1
Training loss: 0.33456702467354577
Validation loss: 2.2911432660426025

Epoch: 5| Step: 2
Training loss: 0.21537567526788398
Validation loss: 2.3244598382206787

Epoch: 5| Step: 3
Training loss: 0.20090363034622982
Validation loss: 2.289355255829525

Epoch: 5| Step: 4
Training loss: 0.3989800704565497
Validation loss: 2.316274994521162

Epoch: 5| Step: 5
Training loss: 0.19313010678128723
Validation loss: 2.2996699739776787

Epoch: 5| Step: 6
Training loss: 0.18741802569400226
Validation loss: 2.2709595324456124

Epoch: 5| Step: 7
Training loss: 0.31546517517951395
Validation loss: 2.302872901606073

Epoch: 5| Step: 8
Training loss: 0.3607752513758532
Validation loss: 2.325030310260442

Epoch: 5| Step: 9
Training loss: 0.43133898590956893
Validation loss: 2.293270087859332

Epoch: 5| Step: 10
Training loss: 0.5155214147846455
Validation loss: 2.28075260454861

Epoch: 482| Step: 0
Training loss: 0.19222226681296095
Validation loss: 2.299858038544093

Epoch: 5| Step: 1
Training loss: 0.32602415337412777
Validation loss: 2.3031418511928

Epoch: 5| Step: 2
Training loss: 0.3511544296463247
Validation loss: 2.2712326016784234

Epoch: 5| Step: 3
Training loss: 0.4114074876812298
Validation loss: 2.293521678105252

Epoch: 5| Step: 4
Training loss: 0.21097057577706907
Validation loss: 2.2834359250001435

Epoch: 5| Step: 5
Training loss: 0.16019121230374914
Validation loss: 2.3130000071923984

Epoch: 5| Step: 6
Training loss: 0.34163247650708506
Validation loss: 2.2997431027977613

Epoch: 5| Step: 7
Training loss: 0.3915209413715479
Validation loss: 2.310717120748365

Epoch: 5| Step: 8
Training loss: 0.503018388055622
Validation loss: 2.298220419205707

Epoch: 5| Step: 9
Training loss: 0.16701046246923928
Validation loss: 2.3083514011798845

Epoch: 5| Step: 10
Training loss: 0.14549060694207727
Validation loss: 2.3204361248840244

Epoch: 483| Step: 0
Training loss: 0.4950672703847732
Validation loss: 2.3069890244461906

Epoch: 5| Step: 1
Training loss: 0.14140259806517047
Validation loss: 2.271337687025906

Epoch: 5| Step: 2
Training loss: 0.33560587904893435
Validation loss: 2.2978296930617415

Epoch: 5| Step: 3
Training loss: 0.3358806850383808
Validation loss: 2.313739488775399

Epoch: 5| Step: 4
Training loss: 0.39548577141275054
Validation loss: 2.296150800985025

Epoch: 5| Step: 5
Training loss: 0.2157970433183759
Validation loss: 2.3074812324539398

Epoch: 5| Step: 6
Training loss: 0.22140324366432446
Validation loss: 2.2562700639026416

Epoch: 5| Step: 7
Training loss: 0.1911687058130371
Validation loss: 2.287437813515002

Epoch: 5| Step: 8
Training loss: 0.22761058911065005
Validation loss: 2.302683564412773

Epoch: 5| Step: 9
Training loss: 0.2713051348347576
Validation loss: 2.2934387354829995

Epoch: 5| Step: 10
Training loss: 0.4712123095367425
Validation loss: 2.2721759349086117

Epoch: 484| Step: 0
Training loss: 0.34569169149511286
Validation loss: 2.324183647488381

Epoch: 5| Step: 1
Training loss: 0.2876258408833811
Validation loss: 2.2896042978852202

Epoch: 5| Step: 2
Training loss: 0.39789108132531503
Validation loss: 2.30811808140661

Epoch: 5| Step: 3
Training loss: 0.2946177297463105
Validation loss: 2.316092575414561

Epoch: 5| Step: 4
Training loss: 0.27944808814650124
Validation loss: 2.327521972895305

Epoch: 5| Step: 5
Training loss: 0.42479488317641645
Validation loss: 2.339403547021782

Epoch: 5| Step: 6
Training loss: 0.16264243554624666
Validation loss: 2.2975846299980534

Epoch: 5| Step: 7
Training loss: 0.3214633665949588
Validation loss: 2.289377359632806

Epoch: 5| Step: 8
Training loss: 0.32833276710283926
Validation loss: 2.2831959563039024

Epoch: 5| Step: 9
Training loss: 0.2990553372321573
Validation loss: 2.3118228056606536

Epoch: 5| Step: 10
Training loss: 0.22703103420564985
Validation loss: 2.3099455578308707

Epoch: 485| Step: 0
Training loss: 0.23866474840228644
Validation loss: 2.306533399620966

Epoch: 5| Step: 1
Training loss: 0.4314070194600893
Validation loss: 2.292017895434887

Epoch: 5| Step: 2
Training loss: 0.3083899827200456
Validation loss: 2.2717785756590976

Epoch: 5| Step: 3
Training loss: 0.4689894223708118
Validation loss: 2.3077184464406266

Epoch: 5| Step: 4
Training loss: 0.36272071334479716
Validation loss: 2.27139722926228

Epoch: 5| Step: 5
Training loss: 0.2114381764502872
Validation loss: 2.2941837154341824

Epoch: 5| Step: 6
Training loss: 0.43841212421484116
Validation loss: 2.2913083634450047

Epoch: 5| Step: 7
Training loss: 0.20822315978513642
Validation loss: 2.30500765871475

Epoch: 5| Step: 8
Training loss: 0.245080055980718
Validation loss: 2.30715363492234

Epoch: 5| Step: 9
Training loss: 0.18588520123964586
Validation loss: 2.2878462806105055

Epoch: 5| Step: 10
Training loss: 0.2182166460507491
Validation loss: 2.307194108946116

Epoch: 486| Step: 0
Training loss: 0.5012902361638257
Validation loss: 2.2923221446840407

Epoch: 5| Step: 1
Training loss: 0.28606872361630536
Validation loss: 2.2944945785142385

Epoch: 5| Step: 2
Training loss: 0.29902006978356727
Validation loss: 2.315494125565064

Epoch: 5| Step: 3
Training loss: 0.41571488950041313
Validation loss: 2.3061243582775974

Epoch: 5| Step: 4
Training loss: 0.19134406617228983
Validation loss: 2.3187342264832806

Epoch: 5| Step: 5
Training loss: 0.2958045281682644
Validation loss: 2.3517084277769613

Epoch: 5| Step: 6
Training loss: 0.3571203658991951
Validation loss: 2.330134710656567

Epoch: 5| Step: 7
Training loss: 0.29676888476734387
Validation loss: 2.312550879808099

Epoch: 5| Step: 8
Training loss: 0.24324357597968038
Validation loss: 2.2794692252730093

Epoch: 5| Step: 9
Training loss: 0.34129034383768386
Validation loss: 2.282802515378036

Epoch: 5| Step: 10
Training loss: 0.30715196337975126
Validation loss: 2.2877442267037043

Epoch: 487| Step: 0
Training loss: 0.2739572761911706
Validation loss: 2.2725414058794264

Epoch: 5| Step: 1
Training loss: 0.27803530907752333
Validation loss: 2.2982369467957406

Epoch: 5| Step: 2
Training loss: 0.4291081424116623
Validation loss: 2.335998477291505

Epoch: 5| Step: 3
Training loss: 0.47348509382472764
Validation loss: 2.372084545536804

Epoch: 5| Step: 4
Training loss: 0.3429535395349362
Validation loss: 2.3580607851991924

Epoch: 5| Step: 5
Training loss: 0.31063091892229316
Validation loss: 2.324696267539986

Epoch: 5| Step: 6
Training loss: 0.2698889307876491
Validation loss: 2.298998265054111

Epoch: 5| Step: 7
Training loss: 0.29865500478074786
Validation loss: 2.287061360935313

Epoch: 5| Step: 8
Training loss: 0.41398954648489633
Validation loss: 2.3104791208723165

Epoch: 5| Step: 9
Training loss: 0.3138858939140951
Validation loss: 2.277650182288937

Epoch: 5| Step: 10
Training loss: 0.18328212100421226
Validation loss: 2.281349316507187

Epoch: 488| Step: 0
Training loss: 0.41615536630698086
Validation loss: 2.319805708782828

Epoch: 5| Step: 1
Training loss: 0.29050518560459326
Validation loss: 2.350612592565397

Epoch: 5| Step: 2
Training loss: 0.22768557828918934
Validation loss: 2.3051066500476938

Epoch: 5| Step: 3
Training loss: 0.3621362464259222
Validation loss: 2.3684775652937917

Epoch: 5| Step: 4
Training loss: 0.18161595084664928
Validation loss: 2.3665787065507753

Epoch: 5| Step: 5
Training loss: 0.36513150648348774
Validation loss: 2.3363356355756113

Epoch: 5| Step: 6
Training loss: 0.24138130318339895
Validation loss: 2.307306815777084

Epoch: 5| Step: 7
Training loss: 0.5718061405686756
Validation loss: 2.2813006654047387

Epoch: 5| Step: 8
Training loss: 0.2120036274311735
Validation loss: 2.280919868539754

Epoch: 5| Step: 9
Training loss: 0.39227102613652864
Validation loss: 2.2597405099211865

Epoch: 5| Step: 10
Training loss: 0.34089708966386184
Validation loss: 2.266454518914432

Epoch: 489| Step: 0
Training loss: 0.23359474003304517
Validation loss: 2.296306725925376

Epoch: 5| Step: 1
Training loss: 0.11631297192152402
Validation loss: 2.316637401553842

Epoch: 5| Step: 2
Training loss: 0.4716250464972446
Validation loss: 2.363072433609319

Epoch: 5| Step: 3
Training loss: 0.3675408185295995
Validation loss: 2.3148460936899844

Epoch: 5| Step: 4
Training loss: 0.3475128906932778
Validation loss: 2.3185272038559

Epoch: 5| Step: 5
Training loss: 0.3962112764035325
Validation loss: 2.3067643424495956

Epoch: 5| Step: 6
Training loss: 0.39227539460598304
Validation loss: 2.284341101570752

Epoch: 5| Step: 7
Training loss: 0.3779736278924083
Validation loss: 2.2961305794987865

Epoch: 5| Step: 8
Training loss: 0.34165501511679564
Validation loss: 2.268386961541621

Epoch: 5| Step: 9
Training loss: 0.27491018985372073
Validation loss: 2.2794518063855636

Epoch: 5| Step: 10
Training loss: 0.5399940292593448
Validation loss: 2.2682983558174223

Epoch: 490| Step: 0
Training loss: 0.21887273410711355
Validation loss: 2.2839177639934323

Epoch: 5| Step: 1
Training loss: 0.4159345592621239
Validation loss: 2.304146763746899

Epoch: 5| Step: 2
Training loss: 0.31497162666524847
Validation loss: 2.3143004559220675

Epoch: 5| Step: 3
Training loss: 0.3571589185304788
Validation loss: 2.3131429027448833

Epoch: 5| Step: 4
Training loss: 0.47050579572588214
Validation loss: 2.3200221676433963

Epoch: 5| Step: 5
Training loss: 0.41324141802591285
Validation loss: 2.317588515097897

Epoch: 5| Step: 6
Training loss: 0.5013546474361221
Validation loss: 2.322993426823015

Epoch: 5| Step: 7
Training loss: 0.2759439982365155
Validation loss: 2.302552340569975

Epoch: 5| Step: 8
Training loss: 0.3492024893676593
Validation loss: 2.309988913382284

Epoch: 5| Step: 9
Training loss: 0.44986635051318397
Validation loss: 2.2891369173756613

Epoch: 5| Step: 10
Training loss: 0.2787302578576524
Validation loss: 2.3160093485862636

Epoch: 491| Step: 0
Training loss: 0.45713703854830073
Validation loss: 2.3021678156438874

Epoch: 5| Step: 1
Training loss: 0.23050859074605856
Validation loss: 2.304691661332484

Epoch: 5| Step: 2
Training loss: 0.28126398687551585
Validation loss: 2.3079159407209846

Epoch: 5| Step: 3
Training loss: 0.32434836634772435
Validation loss: 2.3332753588100124

Epoch: 5| Step: 4
Training loss: 0.3896737532649743
Validation loss: 2.3227533488777046

Epoch: 5| Step: 5
Training loss: 0.3716762187753807
Validation loss: 2.2995064044815905

Epoch: 5| Step: 6
Training loss: 0.48092765912056873
Validation loss: 2.305154943849982

Epoch: 5| Step: 7
Training loss: 0.3541278280205177
Validation loss: 2.3023111168236303

Epoch: 5| Step: 8
Training loss: 0.19533204934511347
Validation loss: 2.2612752118046897

Epoch: 5| Step: 9
Training loss: 0.28500354283623713
Validation loss: 2.2758337755541844

Epoch: 5| Step: 10
Training loss: 0.2839538096018369
Validation loss: 2.2816180669604447

Epoch: 492| Step: 0
Training loss: 0.3706348593495661
Validation loss: 2.2662187770621194

Epoch: 5| Step: 1
Training loss: 0.5328946741003703
Validation loss: 2.2876911355362974

Epoch: 5| Step: 2
Training loss: 0.2337659950317163
Validation loss: 2.2989188955849116

Epoch: 5| Step: 3
Training loss: 0.37306672687535714
Validation loss: 2.2788410905895318

Epoch: 5| Step: 4
Training loss: 0.34456855675743336
Validation loss: 2.304573883042545

Epoch: 5| Step: 5
Training loss: 0.34364965448088797
Validation loss: 2.293925439813849

Epoch: 5| Step: 6
Training loss: 0.28897531586468145
Validation loss: 2.2624334308877314

Epoch: 5| Step: 7
Training loss: 0.19292570861927497
Validation loss: 2.242367790113806

Epoch: 5| Step: 8
Training loss: 0.2762738127391843
Validation loss: 2.263838431705767

Epoch: 5| Step: 9
Training loss: 0.45943519690928436
Validation loss: 2.281175444459702

Epoch: 5| Step: 10
Training loss: 0.23862463800513745
Validation loss: 2.292567905026841

Epoch: 493| Step: 0
Training loss: 0.2984654463420516
Validation loss: 2.296311400367294

Epoch: 5| Step: 1
Training loss: 0.42879957877238956
Validation loss: 2.3076101774131152

Epoch: 5| Step: 2
Training loss: 0.46794843486320753
Validation loss: 2.379520865116766

Epoch: 5| Step: 3
Training loss: 0.279075428064133
Validation loss: 2.343716251034597

Epoch: 5| Step: 4
Training loss: 0.4810650079807258
Validation loss: 2.33304511068565

Epoch: 5| Step: 5
Training loss: 0.26596353499819875
Validation loss: 2.3471164450981643

Epoch: 5| Step: 6
Training loss: 0.21435607701521578
Validation loss: 2.309465887282828

Epoch: 5| Step: 7
Training loss: 0.3185009787707658
Validation loss: 2.27462856096152

Epoch: 5| Step: 8
Training loss: 0.23305544530217132
Validation loss: 2.2874247304294797

Epoch: 5| Step: 9
Training loss: 0.2205085740866066
Validation loss: 2.313660552976797

Epoch: 5| Step: 10
Training loss: 0.3450007442452516
Validation loss: 2.2811314406907273

Epoch: 494| Step: 0
Training loss: 0.4218177226708811
Validation loss: 2.3058362997777997

Epoch: 5| Step: 1
Training loss: 0.42603089949317047
Validation loss: 2.3371650295664956

Epoch: 5| Step: 2
Training loss: 0.2722630756537945
Validation loss: 2.321482579124652

Epoch: 5| Step: 3
Training loss: 0.33887410225532966
Validation loss: 2.329612451118413

Epoch: 5| Step: 4
Training loss: 0.35997676224678904
Validation loss: 2.3612220725620414

Epoch: 5| Step: 5
Training loss: 0.29213773487214323
Validation loss: 2.3257284978542554

Epoch: 5| Step: 6
Training loss: 0.17178649140637647
Validation loss: 2.305806472076752

Epoch: 5| Step: 7
Training loss: 0.31371174959104464
Validation loss: 2.29966376293729

Epoch: 5| Step: 8
Training loss: 0.3019440949386411
Validation loss: 2.2805544109778855

Epoch: 5| Step: 9
Training loss: 0.2055587404683818
Validation loss: 2.2917116215753546

Epoch: 5| Step: 10
Training loss: 0.389464428124502
Validation loss: 2.2773952976074185

Epoch: 495| Step: 0
Training loss: 0.4687018528689041
Validation loss: 2.2651465816414955

Epoch: 5| Step: 1
Training loss: 0.24738923699803889
Validation loss: 2.304004372311019

Epoch: 5| Step: 2
Training loss: 0.14293748169712472
Validation loss: 2.2847567766990178

Epoch: 5| Step: 3
Training loss: 0.194459032725323
Validation loss: 2.3040911086909848

Epoch: 5| Step: 4
Training loss: 0.3496168444810534
Validation loss: 2.304185790801265

Epoch: 5| Step: 5
Training loss: 0.25866910925480824
Validation loss: 2.290313205428277

Epoch: 5| Step: 6
Training loss: 0.3139689372553722
Validation loss: 2.2863308790700403

Epoch: 5| Step: 7
Training loss: 0.30412839061902514
Validation loss: 2.273474100952493

Epoch: 5| Step: 8
Training loss: 0.2853680177052471
Validation loss: 2.271624515824234

Epoch: 5| Step: 9
Training loss: 0.41448736885253024
Validation loss: 2.268558766507928

Epoch: 5| Step: 10
Training loss: 0.2926494638742776
Validation loss: 2.2680856979031643

Epoch: 496| Step: 0
Training loss: 0.38915571451942915
Validation loss: 2.245991014553803

Epoch: 5| Step: 1
Training loss: 0.32199560470646654
Validation loss: 2.253003518713816

Epoch: 5| Step: 2
Training loss: 0.2599141262907108
Validation loss: 2.263567574830635

Epoch: 5| Step: 3
Training loss: 0.27778413222250253
Validation loss: 2.2526459204873706

Epoch: 5| Step: 4
Training loss: 0.47800502393787775
Validation loss: 2.3039514449752874

Epoch: 5| Step: 5
Training loss: 0.3198615132492798
Validation loss: 2.2814161650605747

Epoch: 5| Step: 6
Training loss: 0.21656874949037555
Validation loss: 2.296050275725377

Epoch: 5| Step: 7
Training loss: 0.24715163660368053
Validation loss: 2.3031811546245065

Epoch: 5| Step: 8
Training loss: 0.23123167938397535
Validation loss: 2.298085218465071

Epoch: 5| Step: 9
Training loss: 0.1694439436859755
Validation loss: 2.2946451326513877

Epoch: 5| Step: 10
Training loss: 0.32635794260661577
Validation loss: 2.3274219170083277

Epoch: 497| Step: 0
Training loss: 0.297004846987685
Validation loss: 2.349670777597572

Epoch: 5| Step: 1
Training loss: 0.22597005269294046
Validation loss: 2.299173400667388

Epoch: 5| Step: 2
Training loss: 0.12102311904734323
Validation loss: 2.3117519655446697

Epoch: 5| Step: 3
Training loss: 0.3246067322440968
Validation loss: 2.3054249429933305

Epoch: 5| Step: 4
Training loss: 0.4792849215110507
Validation loss: 2.2902714290161224

Epoch: 5| Step: 5
Training loss: 0.22798791091066647
Validation loss: 2.29969473101909

Epoch: 5| Step: 6
Training loss: 0.371226718570755
Validation loss: 2.3061917565062626

Epoch: 5| Step: 7
Training loss: 0.3213608148568261
Validation loss: 2.3141006859752853

Epoch: 5| Step: 8
Training loss: 0.146180161251972
Validation loss: 2.3293426725273827

Epoch: 5| Step: 9
Training loss: 0.3364761270575478
Validation loss: 2.3371131927011013

Epoch: 5| Step: 10
Training loss: 0.31443864777214675
Validation loss: 2.3404768338420805

Epoch: 498| Step: 0
Training loss: 0.42437276696360626
Validation loss: 2.31555279530651

Epoch: 5| Step: 1
Training loss: 0.24555318742358026
Validation loss: 2.338403209072918

Epoch: 5| Step: 2
Training loss: 0.2616622351364306
Validation loss: 2.3132280103417537

Epoch: 5| Step: 3
Training loss: 0.3104922888423312
Validation loss: 2.3300748154815656

Epoch: 5| Step: 4
Training loss: 0.2926047288846927
Validation loss: 2.291248089401782

Epoch: 5| Step: 5
Training loss: 0.40629051079871065
Validation loss: 2.312501972200971

Epoch: 5| Step: 6
Training loss: 0.2735603329104442
Validation loss: 2.3167778120677625

Epoch: 5| Step: 7
Training loss: 0.14150151631803173
Validation loss: 2.3411186240680117

Epoch: 5| Step: 8
Training loss: 0.228779982220071
Validation loss: 2.3187884540584935

Epoch: 5| Step: 9
Training loss: 0.3648090640127304
Validation loss: 2.3607680227301415

Epoch: 5| Step: 10
Training loss: 0.27425193748815563
Validation loss: 2.3380955825329006

Epoch: 499| Step: 0
Training loss: 0.3333388107068331
Validation loss: 2.3200001386726217

Epoch: 5| Step: 1
Training loss: 0.2686882935144243
Validation loss: 2.3077090210042503

Epoch: 5| Step: 2
Training loss: 0.5363528107743107
Validation loss: 2.3299585547986856

Epoch: 5| Step: 3
Training loss: 0.3918501333776522
Validation loss: 2.3362404513023063

Epoch: 5| Step: 4
Training loss: 0.1880222438502217
Validation loss: 2.314476694901124

Epoch: 5| Step: 5
Training loss: 0.25506034602176675
Validation loss: 2.306000348572281

Epoch: 5| Step: 6
Training loss: 0.48177100688484437
Validation loss: 2.2855524867215786

Epoch: 5| Step: 7
Training loss: 0.2481582121397392
Validation loss: 2.3049540014368306

Epoch: 5| Step: 8
Training loss: 0.25090436973252095
Validation loss: 2.2941880287956122

Epoch: 5| Step: 9
Training loss: 0.27537766554620724
Validation loss: 2.32962129548249

Epoch: 5| Step: 10
Training loss: 0.2533895517046473
Validation loss: 2.318462333705151

Epoch: 500| Step: 0
Training loss: 0.2832530799742039
Validation loss: 2.305453476826894

Epoch: 5| Step: 1
Training loss: 0.29667915610390766
Validation loss: 2.2585677697450532

Epoch: 5| Step: 2
Training loss: 0.4852749554910433
Validation loss: 2.237818051766132

Epoch: 5| Step: 3
Training loss: 0.40484232205514903
Validation loss: 2.266753849929175

Epoch: 5| Step: 4
Training loss: 0.39634502950087497
Validation loss: 2.2504326918191704

Epoch: 5| Step: 5
Training loss: 0.3921899537089519
Validation loss: 2.2544177880603278

Epoch: 5| Step: 6
Training loss: 0.27188323929239283
Validation loss: 2.2900909932198674

Epoch: 5| Step: 7
Training loss: 0.28748509741596534
Validation loss: 2.3243447072219876

Epoch: 5| Step: 8
Training loss: 0.25866434222849183
Validation loss: 2.2708760694321004

Epoch: 5| Step: 9
Training loss: 0.34821899816098034
Validation loss: 2.3260409705429548

Epoch: 5| Step: 10
Training loss: 0.38955809805561953
Validation loss: 2.3177561846378354

Epoch: 501| Step: 0
Training loss: 0.38474223264273766
Validation loss: 2.320950446349129

Epoch: 5| Step: 1
Training loss: 0.29007330284559163
Validation loss: 2.3389010415093443

Epoch: 5| Step: 2
Training loss: 0.35103570888719654
Validation loss: 2.321988308787729

Epoch: 5| Step: 3
Training loss: 0.2336205339545766
Validation loss: 2.3197282950837166

Epoch: 5| Step: 4
Training loss: 0.26077411756138547
Validation loss: 2.295947259411155

Epoch: 5| Step: 5
Training loss: 0.4002704346924723
Validation loss: 2.300860751327105

Epoch: 5| Step: 6
Training loss: 0.3380375360830309
Validation loss: 2.27575318589776

Epoch: 5| Step: 7
Training loss: 0.2758413913842483
Validation loss: 2.2635466573646874

Epoch: 5| Step: 8
Training loss: 0.2101416763584562
Validation loss: 2.2913118234998824

Epoch: 5| Step: 9
Training loss: 0.43646405390023013
Validation loss: 2.305545613344496

Epoch: 5| Step: 10
Training loss: 0.3003571728556822
Validation loss: 2.302386924834643

Epoch: 502| Step: 0
Training loss: 0.37777142821302123
Validation loss: 2.343897906049363

Epoch: 5| Step: 1
Training loss: 0.2745489691637675
Validation loss: 2.345258678672343

Epoch: 5| Step: 2
Training loss: 0.3102783865871924
Validation loss: 2.335904514509103

Epoch: 5| Step: 3
Training loss: 0.23323774991264593
Validation loss: 2.3642583432805027

Epoch: 5| Step: 4
Training loss: 0.27593335989916784
Validation loss: 2.3334139254784203

Epoch: 5| Step: 5
Training loss: 0.3162841914658009
Validation loss: 2.3315381005014126

Epoch: 5| Step: 6
Training loss: 0.2615850875927727
Validation loss: 2.343264222477353

Epoch: 5| Step: 7
Training loss: 0.20825587958763186
Validation loss: 2.342937949547741

Epoch: 5| Step: 8
Training loss: 0.20650618024876652
Validation loss: 2.3334961228636018

Epoch: 5| Step: 9
Training loss: 0.41305857538456076
Validation loss: 2.344034122213498

Epoch: 5| Step: 10
Training loss: 0.41596828782385
Validation loss: 2.3364761943557886

Epoch: 503| Step: 0
Training loss: 0.3360428090597381
Validation loss: 2.3405710911685516

Epoch: 5| Step: 1
Training loss: 0.2909737627271378
Validation loss: 2.3476695024746492

Epoch: 5| Step: 2
Training loss: 0.13327120358480918
Validation loss: 2.359521508294489

Epoch: 5| Step: 3
Training loss: 0.3957933313669601
Validation loss: 2.371865214138598

Epoch: 5| Step: 4
Training loss: 0.37747788345526123
Validation loss: 2.3301691723215754

Epoch: 5| Step: 5
Training loss: 0.2758267918879034
Validation loss: 2.352081471045908

Epoch: 5| Step: 6
Training loss: 0.24077997047633898
Validation loss: 2.3463767270510516

Epoch: 5| Step: 7
Training loss: 0.41265308978348664
Validation loss: 2.3301545770880683

Epoch: 5| Step: 8
Training loss: 0.2295162269500769
Validation loss: 2.3337801137115277

Epoch: 5| Step: 9
Training loss: 0.2107214174120187
Validation loss: 2.311400387376433

Epoch: 5| Step: 10
Training loss: 0.26620378267744677
Validation loss: 2.3251383872234253

Epoch: 504| Step: 0
Training loss: 0.2348940743861912
Validation loss: 2.325460440456166

Epoch: 5| Step: 1
Training loss: 0.20642938940450206
Validation loss: 2.3249856755008014

Epoch: 5| Step: 2
Training loss: 0.3936768524406378
Validation loss: 2.3446884792140548

Epoch: 5| Step: 3
Training loss: 0.1972574100105772
Validation loss: 2.3679696513565918

Epoch: 5| Step: 4
Training loss: 0.45050585911144636
Validation loss: 2.35780390386385

Epoch: 5| Step: 5
Training loss: 0.2998566722222305
Validation loss: 2.3380557547369603

Epoch: 5| Step: 6
Training loss: 0.3110276585128857
Validation loss: 2.3316021637504347

Epoch: 5| Step: 7
Training loss: 0.21815849269768253
Validation loss: 2.2549031604447114

Epoch: 5| Step: 8
Training loss: 0.2590096738952832
Validation loss: 2.283296441191156

Epoch: 5| Step: 9
Training loss: 0.38274075361279397
Validation loss: 2.2696829172898543

Epoch: 5| Step: 10
Training loss: 0.21842208193938312
Validation loss: 2.2824810045485635

Epoch: 505| Step: 0
Training loss: 0.3187025829650396
Validation loss: 2.2870544296407878

Epoch: 5| Step: 1
Training loss: 0.37959961521613556
Validation loss: 2.246020200719157

Epoch: 5| Step: 2
Training loss: 0.46023920474013724
Validation loss: 2.336769074240447

Epoch: 5| Step: 3
Training loss: 0.3005024745144254
Validation loss: 2.2977275280524956

Epoch: 5| Step: 4
Training loss: 0.21221810604711716
Validation loss: 2.361865495350475

Epoch: 5| Step: 5
Training loss: 0.20202620123081363
Validation loss: 2.3662421586999534

Epoch: 5| Step: 6
Training loss: 0.32227568177223664
Validation loss: 2.3708792868879773

Epoch: 5| Step: 7
Training loss: 0.43801992040562454
Validation loss: 2.3562810156423715

Epoch: 5| Step: 8
Training loss: 0.23878606883312406
Validation loss: 2.2931398994239176

Epoch: 5| Step: 9
Training loss: 0.36195099215555304
Validation loss: 2.257098931409446

Epoch: 5| Step: 10
Training loss: 0.30506254002501093
Validation loss: 2.260906688263863

Epoch: 506| Step: 0
Training loss: 0.40046064183320573
Validation loss: 2.250052640611326

Epoch: 5| Step: 1
Training loss: 0.3213238682779119
Validation loss: 2.2607587571822467

Epoch: 5| Step: 2
Training loss: 0.3683363008199805
Validation loss: 2.260562013282084

Epoch: 5| Step: 3
Training loss: 0.2442801877706661
Validation loss: 2.290612410261298

Epoch: 5| Step: 4
Training loss: 0.20660531115435304
Validation loss: 2.289192916961089

Epoch: 5| Step: 5
Training loss: 0.3154872924358435
Validation loss: 2.3135133699660164

Epoch: 5| Step: 6
Training loss: 0.24562993316452714
Validation loss: 2.343723360956221

Epoch: 5| Step: 7
Training loss: 0.310702027243866
Validation loss: 2.3287452729824785

Epoch: 5| Step: 8
Training loss: 0.40492143166172045
Validation loss: 2.3147975773482874

Epoch: 5| Step: 9
Training loss: 0.298480610954188
Validation loss: 2.3218963654304328

Epoch: 5| Step: 10
Training loss: 0.24518897992352823
Validation loss: 2.3151056785739588

Epoch: 507| Step: 0
Training loss: 0.26332926213360675
Validation loss: 2.289219057247307

Epoch: 5| Step: 1
Training loss: 0.2699410184704674
Validation loss: 2.294646874967006

Epoch: 5| Step: 2
Training loss: 0.27584991302727413
Validation loss: 2.306075587851496

Epoch: 5| Step: 3
Training loss: 0.315707695391489
Validation loss: 2.2981914374915235

Epoch: 5| Step: 4
Training loss: 0.40238537619355186
Validation loss: 2.3055897793892415

Epoch: 5| Step: 5
Training loss: 0.29442118148831353
Validation loss: 2.303481586108696

Epoch: 5| Step: 6
Training loss: 0.2603297310995928
Validation loss: 2.3157359671077105

Epoch: 5| Step: 7
Training loss: 0.29932564103534126
Validation loss: 2.3006781853337075

Epoch: 5| Step: 8
Training loss: 0.14538536424051224
Validation loss: 2.324891262663037

Epoch: 5| Step: 9
Training loss: 0.38192377275341033
Validation loss: 2.3395970150238123

Epoch: 5| Step: 10
Training loss: 0.18501643604003828
Validation loss: 2.3392033689899328

Epoch: 508| Step: 0
Training loss: 0.4209567956672009
Validation loss: 2.3407253697361625

Epoch: 5| Step: 1
Training loss: 0.2597107506636504
Validation loss: 2.355680069810769

Epoch: 5| Step: 2
Training loss: 0.195046606271307
Validation loss: 2.3611782104453183

Epoch: 5| Step: 3
Training loss: 0.1567643164761931
Validation loss: 2.321952076197402

Epoch: 5| Step: 4
Training loss: 0.18127977767869888
Validation loss: 2.3272060973947575

Epoch: 5| Step: 5
Training loss: 0.2034925839492803
Validation loss: 2.295529905685258

Epoch: 5| Step: 6
Training loss: 0.33330510312979844
Validation loss: 2.288077497283569

Epoch: 5| Step: 7
Training loss: 0.4267794954915101
Validation loss: 2.290127247975894

Epoch: 5| Step: 8
Training loss: 0.32418063525713947
Validation loss: 2.279372597579504

Epoch: 5| Step: 9
Training loss: 0.3048979814703758
Validation loss: 2.255687696116648

Epoch: 5| Step: 10
Training loss: 0.28149525227786243
Validation loss: 2.2894387371887253

Epoch: 509| Step: 0
Training loss: 0.19723079864975424
Validation loss: 2.2869739444909842

Epoch: 5| Step: 1
Training loss: 0.27450053797167123
Validation loss: 2.287114701551606

Epoch: 5| Step: 2
Training loss: 0.199517297503374
Validation loss: 2.2889112152143443

Epoch: 5| Step: 3
Training loss: 0.17385361516700096
Validation loss: 2.3028745350007713

Epoch: 5| Step: 4
Training loss: 0.3854528380079816
Validation loss: 2.2945677504944046

Epoch: 5| Step: 5
Training loss: 0.33540166215132167
Validation loss: 2.3158408557157264

Epoch: 5| Step: 6
Training loss: 0.3853085555271484
Validation loss: 2.2948168306870773

Epoch: 5| Step: 7
Training loss: 0.20057334563226692
Validation loss: 2.292135069028577

Epoch: 5| Step: 8
Training loss: 0.21662291859222804
Validation loss: 2.287239463955885

Epoch: 5| Step: 9
Training loss: 0.39619053442569724
Validation loss: 2.3099072224131754

Epoch: 5| Step: 10
Training loss: 0.2075296556583574
Validation loss: 2.2965688841182437

Epoch: 510| Step: 0
Training loss: 0.24118968545675318
Validation loss: 2.2985792999161463

Epoch: 5| Step: 1
Training loss: 0.25500705949978286
Validation loss: 2.2836061403013623

Epoch: 5| Step: 2
Training loss: 0.1972210899918999
Validation loss: 2.254582591079206

Epoch: 5| Step: 3
Training loss: 0.2679786747020409
Validation loss: 2.29459286703667

Epoch: 5| Step: 4
Training loss: 0.3042561583401165
Validation loss: 2.277430530581055

Epoch: 5| Step: 5
Training loss: 0.31999113662932005
Validation loss: 2.285776568732407

Epoch: 5| Step: 6
Training loss: 0.25504858830301896
Validation loss: 2.2981258923588315

Epoch: 5| Step: 7
Training loss: 0.20351955717538414
Validation loss: 2.314514269976687

Epoch: 5| Step: 8
Training loss: 0.4050093928178026
Validation loss: 2.297910721177036

Epoch: 5| Step: 9
Training loss: 0.2025723642397387
Validation loss: 2.2993344350460565

Epoch: 5| Step: 10
Training loss: 0.29613537005200796
Validation loss: 2.284078088208103

Epoch: 511| Step: 0
Training loss: 0.26744570553220604
Validation loss: 2.28680789740289

Epoch: 5| Step: 1
Training loss: 0.26339771004194074
Validation loss: 2.2918804400869033

Epoch: 5| Step: 2
Training loss: 0.4100501150229909
Validation loss: 2.2934701078692985

Epoch: 5| Step: 3
Training loss: 0.40691638358121474
Validation loss: 2.2919955749373435

Epoch: 5| Step: 4
Training loss: 0.13432147601290484
Validation loss: 2.3143797653449725

Epoch: 5| Step: 5
Training loss: 0.18052897171001295
Validation loss: 2.2793877074900117

Epoch: 5| Step: 6
Training loss: 0.27093094051124905
Validation loss: 2.2964648991982703

Epoch: 5| Step: 7
Training loss: 0.3693952943419547
Validation loss: 2.251403588427139

Epoch: 5| Step: 8
Training loss: 0.1629033694324512
Validation loss: 2.2795052367812256

Epoch: 5| Step: 9
Training loss: 0.15691719657915168
Validation loss: 2.322428461399172

Epoch: 5| Step: 10
Training loss: 0.23576587599071588
Validation loss: 2.31879170339956

Epoch: 512| Step: 0
Training loss: 0.16941494797890133
Validation loss: 2.347208198954813

Epoch: 5| Step: 1
Training loss: 0.23769214380388673
Validation loss: 2.3199179388359235

Epoch: 5| Step: 2
Training loss: 0.23037557819912777
Validation loss: 2.3117024920883704

Epoch: 5| Step: 3
Training loss: 0.2883474682272277
Validation loss: 2.2951547870773448

Epoch: 5| Step: 4
Training loss: 0.13942457141853098
Validation loss: 2.3350859804232895

Epoch: 5| Step: 5
Training loss: 0.47332934853338304
Validation loss: 2.3060498398610347

Epoch: 5| Step: 6
Training loss: 0.2902254090393914
Validation loss: 2.321144772066835

Epoch: 5| Step: 7
Training loss: 0.3269112937355096
Validation loss: 2.2922348209386314

Epoch: 5| Step: 8
Training loss: 0.24147233428852158
Validation loss: 2.3074083411015067

Epoch: 5| Step: 9
Training loss: 0.22463661526234113
Validation loss: 2.2834364161865373

Epoch: 5| Step: 10
Training loss: 0.2660990579986241
Validation loss: 2.2575340810409514

Epoch: 513| Step: 0
Training loss: 0.2700387351189837
Validation loss: 2.2961626988819925

Epoch: 5| Step: 1
Training loss: 0.36611978032125014
Validation loss: 2.2747042828519466

Epoch: 5| Step: 2
Training loss: 0.36732695346012456
Validation loss: 2.316906045999428

Epoch: 5| Step: 3
Training loss: 0.40414348401441585
Validation loss: 2.3382639348785115

Epoch: 5| Step: 4
Training loss: 0.2119979165116531
Validation loss: 2.3025144938782263

Epoch: 5| Step: 5
Training loss: 0.21501542081810024
Validation loss: 2.3246999012143763

Epoch: 5| Step: 6
Training loss: 0.15520936615704808
Validation loss: 2.29891191584712

Epoch: 5| Step: 7
Training loss: 0.19539036152489006
Validation loss: 2.30751986314836

Epoch: 5| Step: 8
Training loss: 0.21278242984074305
Validation loss: 2.3220213258050206

Epoch: 5| Step: 9
Training loss: 0.16066806122310978
Validation loss: 2.308376647614212

Epoch: 5| Step: 10
Training loss: 0.32888154958729926
Validation loss: 2.300876995328342

Epoch: 514| Step: 0
Training loss: 0.25213991678203107
Validation loss: 2.267911515200707

Epoch: 5| Step: 1
Training loss: 0.45139724915253177
Validation loss: 2.323047534558471

Epoch: 5| Step: 2
Training loss: 0.26591055611411996
Validation loss: 2.3139548388413815

Epoch: 5| Step: 3
Training loss: 0.11897082031799339
Validation loss: 2.314586302476787

Epoch: 5| Step: 4
Training loss: 0.14354206211338283
Validation loss: 2.322482796165114

Epoch: 5| Step: 5
Training loss: 0.18925905611084312
Validation loss: 2.3185192393449885

Epoch: 5| Step: 6
Training loss: 0.22380121212414567
Validation loss: 2.3185832482276765

Epoch: 5| Step: 7
Training loss: 0.38459220114858145
Validation loss: 2.3492311425150927

Epoch: 5| Step: 8
Training loss: 0.3210640209014199
Validation loss: 2.3493643399953927

Epoch: 5| Step: 9
Training loss: 0.36052590058094347
Validation loss: 2.3249333267011285

Epoch: 5| Step: 10
Training loss: 0.15686143214228365
Validation loss: 2.3330404079252887

Epoch: 515| Step: 0
Training loss: 0.17540892269803862
Validation loss: 2.307488327369252

Epoch: 5| Step: 1
Training loss: 0.42206043124161474
Validation loss: 2.314649821477706

Epoch: 5| Step: 2
Training loss: 0.08891700563921813
Validation loss: 2.3160329745991133

Epoch: 5| Step: 3
Training loss: 0.20443918512245216
Validation loss: 2.320037384644296

Epoch: 5| Step: 4
Training loss: 0.21601560223598257
Validation loss: 2.32647676023897

Epoch: 5| Step: 5
Training loss: 0.3262609828364609
Validation loss: 2.341369702155492

Epoch: 5| Step: 6
Training loss: 0.21855009686077995
Validation loss: 2.3458772594171764

Epoch: 5| Step: 7
Training loss: 0.4003025051003775
Validation loss: 2.3573793455896253

Epoch: 5| Step: 8
Training loss: 0.29411520119835155
Validation loss: 2.346985207453497

Epoch: 5| Step: 9
Training loss: 0.22896983171740887
Validation loss: 2.2971585843494635

Epoch: 5| Step: 10
Training loss: 0.24889241680013022
Validation loss: 2.29018922838151

Epoch: 516| Step: 0
Training loss: 0.2645770606601506
Validation loss: 2.316537640802195

Epoch: 5| Step: 1
Training loss: 0.25474344294422907
Validation loss: 2.3326619602636023

Epoch: 5| Step: 2
Training loss: 0.2854127905691503
Validation loss: 2.316674919036995

Epoch: 5| Step: 3
Training loss: 0.3126465692122352
Validation loss: 2.326701829661434

Epoch: 5| Step: 4
Training loss: 0.21297521398058683
Validation loss: 2.3245607776076644

Epoch: 5| Step: 5
Training loss: 0.38511862271187824
Validation loss: 2.3290082851657

Epoch: 5| Step: 6
Training loss: 0.21174838361945125
Validation loss: 2.3192885928025353

Epoch: 5| Step: 7
Training loss: 0.15035163076611796
Validation loss: 2.3217722529611953

Epoch: 5| Step: 8
Training loss: 0.3608662307857721
Validation loss: 2.3129751614687573

Epoch: 5| Step: 9
Training loss: 0.2863422967960693
Validation loss: 2.3255706106749297

Epoch: 5| Step: 10
Training loss: 0.180113856728044
Validation loss: 2.280146823312142

Epoch: 517| Step: 0
Training loss: 0.2750598192177509
Validation loss: 2.291047549774732

Epoch: 5| Step: 1
Training loss: 0.18914378365640933
Validation loss: 2.304369849465515

Epoch: 5| Step: 2
Training loss: 0.15524577248233895
Validation loss: 2.2861121329005805

Epoch: 5| Step: 3
Training loss: 0.19383157043592908
Validation loss: 2.2736369532753704

Epoch: 5| Step: 4
Training loss: 0.5033166674303219
Validation loss: 2.2613784987783676

Epoch: 5| Step: 5
Training loss: 0.2330060877260514
Validation loss: 2.2791913709475002

Epoch: 5| Step: 6
Training loss: 0.1567811580491932
Validation loss: 2.3180532451594784

Epoch: 5| Step: 7
Training loss: 0.1803662603584717
Validation loss: 2.2773864052035577

Epoch: 5| Step: 8
Training loss: 0.37319907234328054
Validation loss: 2.3194293871772302

Epoch: 5| Step: 9
Training loss: 0.2898726322970597
Validation loss: 2.3358542284498607

Epoch: 5| Step: 10
Training loss: 0.29746441303709953
Validation loss: 2.323636590205711

Epoch: 518| Step: 0
Training loss: 0.22982912692627638
Validation loss: 2.3119924265953244

Epoch: 5| Step: 1
Training loss: 0.14383034611675172
Validation loss: 2.310336754365592

Epoch: 5| Step: 2
Training loss: 0.20243247896229094
Validation loss: 2.2728145664823742

Epoch: 5| Step: 3
Training loss: 0.42893699646967043
Validation loss: 2.3018510079759067

Epoch: 5| Step: 4
Training loss: 0.3328179967900918
Validation loss: 2.3022993264195546

Epoch: 5| Step: 5
Training loss: 0.2522808132283619
Validation loss: 2.268801412754402

Epoch: 5| Step: 6
Training loss: 0.373342247310867
Validation loss: 2.2808007497354845

Epoch: 5| Step: 7
Training loss: 0.1922207551577784
Validation loss: 2.324878079934373

Epoch: 5| Step: 8
Training loss: 0.2660250876335944
Validation loss: 2.294062257457135

Epoch: 5| Step: 9
Training loss: 0.1336100557203086
Validation loss: 2.304067283452242

Epoch: 5| Step: 10
Training loss: 0.16273280418139657
Validation loss: 2.2611337163993377

Epoch: 519| Step: 0
Training loss: 0.24350970570991817
Validation loss: 2.3020613964459002

Epoch: 5| Step: 1
Training loss: 0.22229481523840788
Validation loss: 2.328427606927109

Epoch: 5| Step: 2
Training loss: 0.32282377516931365
Validation loss: 2.3500714158774856

Epoch: 5| Step: 3
Training loss: 0.17970662429874604
Validation loss: 2.3396965836685206

Epoch: 5| Step: 4
Training loss: 0.2676543245619304
Validation loss: 2.3171737609309493

Epoch: 5| Step: 5
Training loss: 0.1743993588494023
Validation loss: 2.3200519772245642

Epoch: 5| Step: 6
Training loss: 0.3089950824912597
Validation loss: 2.317620743611246

Epoch: 5| Step: 7
Training loss: 0.427860502694519
Validation loss: 2.3017658826220915

Epoch: 5| Step: 8
Training loss: 0.2888943337664537
Validation loss: 2.293476309414707

Epoch: 5| Step: 9
Training loss: 0.1874463779544945
Validation loss: 2.2872931349831105

Epoch: 5| Step: 10
Training loss: 0.1748198710405884
Validation loss: 2.293974332772084

Epoch: 520| Step: 0
Training loss: 0.39961472672713116
Validation loss: 2.285486231109454

Epoch: 5| Step: 1
Training loss: 0.35583234363987054
Validation loss: 2.2864129067117

Epoch: 5| Step: 2
Training loss: 0.2674312048980412
Validation loss: 2.2999502476237317

Epoch: 5| Step: 3
Training loss: 0.15507829747802981
Validation loss: 2.3178058988566286

Epoch: 5| Step: 4
Training loss: 0.19481905593341398
Validation loss: 2.319032818557184

Epoch: 5| Step: 5
Training loss: 0.28590355239047505
Validation loss: 2.3240622229471573

Epoch: 5| Step: 6
Training loss: 0.15013899745727954
Validation loss: 2.3570073599799066

Epoch: 5| Step: 7
Training loss: 0.4028084672913915
Validation loss: 2.3258883836636732

Epoch: 5| Step: 8
Training loss: 0.2242432803515536
Validation loss: 2.332716990810483

Epoch: 5| Step: 9
Training loss: 0.20454545552381362
Validation loss: 2.291408231898061

Epoch: 5| Step: 10
Training loss: 0.3148219392098648
Validation loss: 2.288045730508209

Epoch: 521| Step: 0
Training loss: 0.30393141076045793
Validation loss: 2.2882359537072037

Epoch: 5| Step: 1
Training loss: 0.18314788327114734
Validation loss: 2.2854502566350585

Epoch: 5| Step: 2
Training loss: 0.23476280077411324
Validation loss: 2.2680172684502153

Epoch: 5| Step: 3
Training loss: 0.1628513590737525
Validation loss: 2.2555411333226205

Epoch: 5| Step: 4
Training loss: 0.11082649990876475
Validation loss: 2.284450714125621

Epoch: 5| Step: 5
Training loss: 0.37525152671955764
Validation loss: 2.265587596139012

Epoch: 5| Step: 6
Training loss: 0.3008578066808516
Validation loss: 2.2877998379237128

Epoch: 5| Step: 7
Training loss: 0.16018544489233966
Validation loss: 2.310187380425451

Epoch: 5| Step: 8
Training loss: 0.1725345981323471
Validation loss: 2.307656776871462

Epoch: 5| Step: 9
Training loss: 0.4747589252470622
Validation loss: 2.2833387426760323

Epoch: 5| Step: 10
Training loss: 0.1379979709967605
Validation loss: 2.308902090038518

Epoch: 522| Step: 0
Training loss: 0.1194238657198354
Validation loss: 2.3401349195511987

Epoch: 5| Step: 1
Training loss: 0.24289589767892544
Validation loss: 2.326308950578161

Epoch: 5| Step: 2
Training loss: 0.4425476642843095
Validation loss: 2.3108862656574067

Epoch: 5| Step: 3
Training loss: 0.24292416976205033
Validation loss: 2.3146136656247767

Epoch: 5| Step: 4
Training loss: 0.20007475968181662
Validation loss: 2.2876160446795324

Epoch: 5| Step: 5
Training loss: 0.23474526563010037
Validation loss: 2.299126903009879

Epoch: 5| Step: 6
Training loss: 0.16286049754043105
Validation loss: 2.3325063504183814

Epoch: 5| Step: 7
Training loss: 0.16292135419915083
Validation loss: 2.3103159207923656

Epoch: 5| Step: 8
Training loss: 0.21211272038584278
Validation loss: 2.3073667042148234

Epoch: 5| Step: 9
Training loss: 0.4499044243988222
Validation loss: 2.2994770944776204

Epoch: 5| Step: 10
Training loss: 0.27783597329934884
Validation loss: 2.2872560081268567

Epoch: 523| Step: 0
Training loss: 0.2564721667951199
Validation loss: 2.2911145053135638

Epoch: 5| Step: 1
Training loss: 0.3676855888933039
Validation loss: 2.3178769363590326

Epoch: 5| Step: 2
Training loss: 0.15449186872408419
Validation loss: 2.3236211438449277

Epoch: 5| Step: 3
Training loss: 0.21132294442248764
Validation loss: 2.3171213219416193

Epoch: 5| Step: 4
Training loss: 0.23014397286057084
Validation loss: 2.300367218403281

Epoch: 5| Step: 5
Training loss: 0.23705231232882182
Validation loss: 2.285087773037063

Epoch: 5| Step: 6
Training loss: 0.3151413630239952
Validation loss: 2.301214918975081

Epoch: 5| Step: 7
Training loss: 0.1366301044821973
Validation loss: 2.3066117857597908

Epoch: 5| Step: 8
Training loss: 0.38439896826719744
Validation loss: 2.3133075260891847

Epoch: 5| Step: 9
Training loss: 0.3100620539915187
Validation loss: 2.3174890336780565

Epoch: 5| Step: 10
Training loss: 0.13591154771567854
Validation loss: 2.285195203122559

Epoch: 524| Step: 0
Training loss: 0.27070870496935645
Validation loss: 2.293841809926668

Epoch: 5| Step: 1
Training loss: 0.3190020644463432
Validation loss: 2.295490941986648

Epoch: 5| Step: 2
Training loss: 0.2318136125724549
Validation loss: 2.2834998861227365

Epoch: 5| Step: 3
Training loss: 0.1557611806256317
Validation loss: 2.2997884961201347

Epoch: 5| Step: 4
Training loss: 0.4371297495766392
Validation loss: 2.2975870774999496

Epoch: 5| Step: 5
Training loss: 0.39662844290743327
Validation loss: 2.3087802704245015

Epoch: 5| Step: 6
Training loss: 0.183930088951607
Validation loss: 2.281507240161721

Epoch: 5| Step: 7
Training loss: 0.21884447850410194
Validation loss: 2.293098103517592

Epoch: 5| Step: 8
Training loss: 0.19398486952732086
Validation loss: 2.2692396735477645

Epoch: 5| Step: 9
Training loss: 0.1916372306824824
Validation loss: 2.310846336668998

Epoch: 5| Step: 10
Training loss: 0.15490621652116043
Validation loss: 2.2912871649704725

Epoch: 525| Step: 0
Training loss: 0.1846565771598713
Validation loss: 2.288542560248232

Epoch: 5| Step: 1
Training loss: 0.1710397190845795
Validation loss: 2.2909656891947163

Epoch: 5| Step: 2
Training loss: 0.3074941722193574
Validation loss: 2.3066589088559626

Epoch: 5| Step: 3
Training loss: 0.1981415892674489
Validation loss: 2.3010581400940273

Epoch: 5| Step: 4
Training loss: 0.15882481176107593
Validation loss: 2.3083197579259167

Epoch: 5| Step: 5
Training loss: 0.2599795901559011
Validation loss: 2.300708089549361

Epoch: 5| Step: 6
Training loss: 0.3632908686523271
Validation loss: 2.296347733864749

Epoch: 5| Step: 7
Training loss: 0.2729003534950044
Validation loss: 2.2961176374978223

Epoch: 5| Step: 8
Training loss: 0.30610269390317807
Validation loss: 2.3016218794695598

Epoch: 5| Step: 9
Training loss: 0.21621493686467885
Validation loss: 2.2773566410919344

Epoch: 5| Step: 10
Training loss: 0.26076330320888214
Validation loss: 2.261460765489425

Epoch: 526| Step: 0
Training loss: 0.39815979049518063
Validation loss: 2.272174874329313

Epoch: 5| Step: 1
Training loss: 0.3572500472485863
Validation loss: 2.2960085054429196

Epoch: 5| Step: 2
Training loss: 0.2586134692737987
Validation loss: 2.270397291930522

Epoch: 5| Step: 3
Training loss: 0.22500804681428999
Validation loss: 2.301433342476253

Epoch: 5| Step: 4
Training loss: 0.173836214970273
Validation loss: 2.278642421362413

Epoch: 5| Step: 5
Training loss: 0.18959834245508503
Validation loss: 2.2781986265805383

Epoch: 5| Step: 6
Training loss: 0.2049170179151395
Validation loss: 2.282565442374407

Epoch: 5| Step: 7
Training loss: 0.3001436063654252
Validation loss: 2.285602422741006

Epoch: 5| Step: 8
Training loss: 0.23148311837377003
Validation loss: 2.295931667799712

Epoch: 5| Step: 9
Training loss: 0.16444541319572586
Validation loss: 2.267435382366811

Epoch: 5| Step: 10
Training loss: 0.16687380068773072
Validation loss: 2.2944885154734194

Epoch: 527| Step: 0
Training loss: 0.15234117016686435
Validation loss: 2.26910668481257

Epoch: 5| Step: 1
Training loss: 0.2926820242021519
Validation loss: 2.327995052759205

Epoch: 5| Step: 2
Training loss: 0.3173861576784348
Validation loss: 2.283069645115688

Epoch: 5| Step: 3
Training loss: 0.11798529066878034
Validation loss: 2.269266673218483

Epoch: 5| Step: 4
Training loss: 0.26735566630468405
Validation loss: 2.280004509998921

Epoch: 5| Step: 5
Training loss: 0.15875528077105677
Validation loss: 2.296805514591245

Epoch: 5| Step: 6
Training loss: 0.23824335015734555
Validation loss: 2.2966393478304483

Epoch: 5| Step: 7
Training loss: 0.36642673492104205
Validation loss: 2.3198799632549614

Epoch: 5| Step: 8
Training loss: 0.19268831694668279
Validation loss: 2.3223981215526317

Epoch: 5| Step: 9
Training loss: 0.33958150896311723
Validation loss: 2.3233941597843693

Epoch: 5| Step: 10
Training loss: 0.13585942509119955
Validation loss: 2.3254625692336397

Epoch: 528| Step: 0
Training loss: 0.15508741956285813
Validation loss: 2.3134574925538236

Epoch: 5| Step: 1
Training loss: 0.25442096184843865
Validation loss: 2.3231384110438227

Epoch: 5| Step: 2
Training loss: 0.3870623054719495
Validation loss: 2.3130096648819674

Epoch: 5| Step: 3
Training loss: 0.2204266732533864
Validation loss: 2.3138978087620936

Epoch: 5| Step: 4
Training loss: 0.43034298923827685
Validation loss: 2.344693240888678

Epoch: 5| Step: 5
Training loss: 0.12744586396003038
Validation loss: 2.307377169337832

Epoch: 5| Step: 6
Training loss: 0.32164739783705226
Validation loss: 2.324327156983561

Epoch: 5| Step: 7
Training loss: 0.20975149487120728
Validation loss: 2.3214909012035574

Epoch: 5| Step: 8
Training loss: 0.1784152727596752
Validation loss: 2.3201776302834887

Epoch: 5| Step: 9
Training loss: 0.19822072631726348
Validation loss: 2.311939372201279

Epoch: 5| Step: 10
Training loss: 0.250049124302062
Validation loss: 2.306275320949281

Epoch: 529| Step: 0
Training loss: 0.18571593964575148
Validation loss: 2.315249107429665

Epoch: 5| Step: 1
Training loss: 0.18349291690595848
Validation loss: 2.331752084928991

Epoch: 5| Step: 2
Training loss: 0.2070728116333513
Validation loss: 2.2929998347749048

Epoch: 5| Step: 3
Training loss: 0.2464058501579606
Validation loss: 2.2790899924740033

Epoch: 5| Step: 4
Training loss: 0.2541897877875597
Validation loss: 2.289724952199333

Epoch: 5| Step: 5
Training loss: 0.1598999368242529
Validation loss: 2.3156920200388624

Epoch: 5| Step: 6
Training loss: 0.41879586352944315
Validation loss: 2.3016114355164623

Epoch: 5| Step: 7
Training loss: 0.37711356509014426
Validation loss: 2.321501336889323

Epoch: 5| Step: 8
Training loss: 0.32385230900152023
Validation loss: 2.3226493149279923

Epoch: 5| Step: 9
Training loss: 0.1470492344072031
Validation loss: 2.302956456510577

Epoch: 5| Step: 10
Training loss: 0.17910359713231724
Validation loss: 2.2921031006814925

Epoch: 530| Step: 0
Training loss: 0.18528049823095685
Validation loss: 2.3150819179655735

Epoch: 5| Step: 1
Training loss: 0.19587319954103685
Validation loss: 2.317841884908109

Epoch: 5| Step: 2
Training loss: 0.24122293728157926
Validation loss: 2.2936025278433587

Epoch: 5| Step: 3
Training loss: 0.19781033688005836
Validation loss: 2.316071958543063

Epoch: 5| Step: 4
Training loss: 0.12950574306232152
Validation loss: 2.3084819189097474

Epoch: 5| Step: 5
Training loss: 0.18087163805325152
Validation loss: 2.3141670382190163

Epoch: 5| Step: 6
Training loss: 0.342437633993391
Validation loss: 2.283615506930484

Epoch: 5| Step: 7
Training loss: 0.439854671552723
Validation loss: 2.2698020395805245

Epoch: 5| Step: 8
Training loss: 0.2676177169578525
Validation loss: 2.2843924318032336

Epoch: 5| Step: 9
Training loss: 0.16613022271027375
Validation loss: 2.3121850942011517

Epoch: 5| Step: 10
Training loss: 0.28557585844428346
Validation loss: 2.304142082391917

Epoch: 531| Step: 0
Training loss: 0.22144254528287613
Validation loss: 2.292676458938414

Epoch: 5| Step: 1
Training loss: 0.3630022597886252
Validation loss: 2.2986346952860544

Epoch: 5| Step: 2
Training loss: 0.2685507756728592
Validation loss: 2.2963902018535434

Epoch: 5| Step: 3
Training loss: 0.2286718600644236
Validation loss: 2.2942682413136812

Epoch: 5| Step: 4
Training loss: 0.1312604919849429
Validation loss: 2.2930610010538874

Epoch: 5| Step: 5
Training loss: 0.24912496254973793
Validation loss: 2.311957644091956

Epoch: 5| Step: 6
Training loss: 0.2246489780176088
Validation loss: 2.303750680242287

Epoch: 5| Step: 7
Training loss: 0.2805102474360357
Validation loss: 2.312859587910528

Epoch: 5| Step: 8
Training loss: 0.24514192859060635
Validation loss: 2.3028742027000866

Epoch: 5| Step: 9
Training loss: 0.283004888673452
Validation loss: 2.3123142585780028

Epoch: 5| Step: 10
Training loss: 0.1578096276201264
Validation loss: 2.321821792304916

Epoch: 532| Step: 0
Training loss: 0.12433910372433168
Validation loss: 2.3010560528008708

Epoch: 5| Step: 1
Training loss: 0.22378204397287887
Validation loss: 2.307982913412424

Epoch: 5| Step: 2
Training loss: 0.17397727889315565
Validation loss: 2.3062202208249034

Epoch: 5| Step: 3
Training loss: 0.15024601188538225
Validation loss: 2.295377953181376

Epoch: 5| Step: 4
Training loss: 0.2415450172587301
Validation loss: 2.307245103538485

Epoch: 5| Step: 5
Training loss: 0.3701437183221723
Validation loss: 2.289105835021122

Epoch: 5| Step: 6
Training loss: 0.2149625449767778
Validation loss: 2.2877706480007864

Epoch: 5| Step: 7
Training loss: 0.2705014500059092
Validation loss: 2.313335405270018

Epoch: 5| Step: 8
Training loss: 0.33381561566534235
Validation loss: 2.309488431336774

Epoch: 5| Step: 9
Training loss: 0.2917655779946236
Validation loss: 2.3155008704217375

Epoch: 5| Step: 10
Training loss: 0.2818262237334114
Validation loss: 2.27749477770709

Epoch: 533| Step: 0
Training loss: 0.3238161068700531
Validation loss: 2.2725927414794844

Epoch: 5| Step: 1
Training loss: 0.1604264352866822
Validation loss: 2.2938547088873005

Epoch: 5| Step: 2
Training loss: 0.13222010412178692
Validation loss: 2.292493343499495

Epoch: 5| Step: 3
Training loss: 0.2867384480250549
Validation loss: 2.282448668764029

Epoch: 5| Step: 4
Training loss: 0.1549077796775857
Validation loss: 2.286602835782145

Epoch: 5| Step: 5
Training loss: 0.249231483469006
Validation loss: 2.3144667503572354

Epoch: 5| Step: 6
Training loss: 0.21322331113156529
Validation loss: 2.333714176848652

Epoch: 5| Step: 7
Training loss: 0.3783263064703783
Validation loss: 2.3518844240778995

Epoch: 5| Step: 8
Training loss: 0.412478783090737
Validation loss: 2.346455502956262

Epoch: 5| Step: 9
Training loss: 0.306029993459591
Validation loss: 2.382360631311474

Epoch: 5| Step: 10
Training loss: 0.32865361367198664
Validation loss: 2.331593776605216

Epoch: 534| Step: 0
Training loss: 0.2034670535681698
Validation loss: 2.297522740863288

Epoch: 5| Step: 1
Training loss: 0.3700207506624346
Validation loss: 2.291684542350372

Epoch: 5| Step: 2
Training loss: 0.22494761665172905
Validation loss: 2.270429243531622

Epoch: 5| Step: 3
Training loss: 0.23988532473303575
Validation loss: 2.2361939462302756

Epoch: 5| Step: 4
Training loss: 0.32058384497345277
Validation loss: 2.250440680851648

Epoch: 5| Step: 5
Training loss: 0.19504159259129208
Validation loss: 2.2793649573893737

Epoch: 5| Step: 6
Training loss: 0.3850821727525241
Validation loss: 2.285833135144445

Epoch: 5| Step: 7
Training loss: 0.29976684878260806
Validation loss: 2.3196430054581327

Epoch: 5| Step: 8
Training loss: 0.25608480874280104
Validation loss: 2.311766561631112

Epoch: 5| Step: 9
Training loss: 0.2468751656857671
Validation loss: 2.3096948786354234

Epoch: 5| Step: 10
Training loss: 0.195905633567927
Validation loss: 2.3354913357688636

Epoch: 535| Step: 0
Training loss: 0.2589181254304575
Validation loss: 2.29357656018916

Epoch: 5| Step: 1
Training loss: 0.19612198926475907
Validation loss: 2.277185700845959

Epoch: 5| Step: 2
Training loss: 0.18837872866577193
Validation loss: 2.2475409817293683

Epoch: 5| Step: 3
Training loss: 0.1856755864286786
Validation loss: 2.2292782018905983

Epoch: 5| Step: 4
Training loss: 0.39444115998164775
Validation loss: 2.2560974344936553

Epoch: 5| Step: 5
Training loss: 0.12191722043808066
Validation loss: 2.2425120986519

Epoch: 5| Step: 6
Training loss: 0.29496414942628796
Validation loss: 2.257380267634194

Epoch: 5| Step: 7
Training loss: 0.23389102716798066
Validation loss: 2.263665856811323

Epoch: 5| Step: 8
Training loss: 0.22230837231553113
Validation loss: 2.3297577802204925

Epoch: 5| Step: 9
Training loss: 0.2935493565200331
Validation loss: 2.269419655024121

Epoch: 5| Step: 10
Training loss: 0.33959280812125936
Validation loss: 2.3144164354939942

Epoch: 536| Step: 0
Training loss: 0.2703727770725883
Validation loss: 2.329357166091982

Epoch: 5| Step: 1
Training loss: 0.3401897576351968
Validation loss: 2.3178957409990004

Epoch: 5| Step: 2
Training loss: 0.25924959770638606
Validation loss: 2.2976813230294226

Epoch: 5| Step: 3
Training loss: 0.36595523299358546
Validation loss: 2.342258243882078

Epoch: 5| Step: 4
Training loss: 0.1819594466739723
Validation loss: 2.339149990329724

Epoch: 5| Step: 5
Training loss: 0.21371860655640207
Validation loss: 2.333832512328016

Epoch: 5| Step: 6
Training loss: 0.20629474703572406
Validation loss: 2.294660392811011

Epoch: 5| Step: 7
Training loss: 0.28975515888203107
Validation loss: 2.2955546453948172

Epoch: 5| Step: 8
Training loss: 0.28647622861741034
Validation loss: 2.2982027258016595

Epoch: 5| Step: 9
Training loss: 0.3018160519986328
Validation loss: 2.313052039201657

Epoch: 5| Step: 10
Training loss: 0.1749537913589209
Validation loss: 2.278034309893375

Epoch: 537| Step: 0
Training loss: 0.2591453690507205
Validation loss: 2.2711174837833723

Epoch: 5| Step: 1
Training loss: 0.15879669218044384
Validation loss: 2.2775580845442054

Epoch: 5| Step: 2
Training loss: 0.23282131363999817
Validation loss: 2.290498208173066

Epoch: 5| Step: 3
Training loss: 0.2765376640202774
Validation loss: 2.3049530627139165

Epoch: 5| Step: 4
Training loss: 0.41670365368074574
Validation loss: 2.318432560078906

Epoch: 5| Step: 5
Training loss: 0.2630391759739914
Validation loss: 2.324341789912126

Epoch: 5| Step: 6
Training loss: 0.2871330407178864
Validation loss: 2.307402633642624

Epoch: 5| Step: 7
Training loss: 0.1463241591071416
Validation loss: 2.269324872928722

Epoch: 5| Step: 8
Training loss: 0.34894684397823533
Validation loss: 2.344905600104456

Epoch: 5| Step: 9
Training loss: 0.19184760376495313
Validation loss: 2.2973106104581102

Epoch: 5| Step: 10
Training loss: 0.1413552740325881
Validation loss: 2.3026695164051736

Epoch: 538| Step: 0
Training loss: 0.28832183490181207
Validation loss: 2.2994512358094132

Epoch: 5| Step: 1
Training loss: 0.11371112519448245
Validation loss: 2.3076031250886886

Epoch: 5| Step: 2
Training loss: 0.17469303998368516
Validation loss: 2.301962233508672

Epoch: 5| Step: 3
Training loss: 0.2822356437093251
Validation loss: 2.305037372743386

Epoch: 5| Step: 4
Training loss: 0.18816034938576878
Validation loss: 2.2979904891531917

Epoch: 5| Step: 5
Training loss: 0.19227211570401656
Validation loss: 2.292739450010294

Epoch: 5| Step: 6
Training loss: 0.27708166123127076
Validation loss: 2.295340065818616

Epoch: 5| Step: 7
Training loss: 0.2178393379709146
Validation loss: 2.277150556682159

Epoch: 5| Step: 8
Training loss: 0.34388147354133963
Validation loss: 2.303769258836362

Epoch: 5| Step: 9
Training loss: 0.3663880797153015
Validation loss: 2.3097150440781298

Epoch: 5| Step: 10
Training loss: 0.11633868368738745
Validation loss: 2.294964237001064

Epoch: 539| Step: 0
Training loss: 0.2799607103958156
Validation loss: 2.3085646242212685

Epoch: 5| Step: 1
Training loss: 0.15632133643582197
Validation loss: 2.28315300597287

Epoch: 5| Step: 2
Training loss: 0.2410265028243847
Validation loss: 2.276345788507368

Epoch: 5| Step: 3
Training loss: 0.25669549503512074
Validation loss: 2.298726427042729

Epoch: 5| Step: 4
Training loss: 0.23077096359583532
Validation loss: 2.2989616032233915

Epoch: 5| Step: 5
Training loss: 0.2092603928487177
Validation loss: 2.3128940586870606

Epoch: 5| Step: 6
Training loss: 0.2672474760368143
Validation loss: 2.2908698267428864

Epoch: 5| Step: 7
Training loss: 0.21488142550183256
Validation loss: 2.3170168497854617

Epoch: 5| Step: 8
Training loss: 0.39171691869757286
Validation loss: 2.301336099713135

Epoch: 5| Step: 9
Training loss: 0.1501304369778862
Validation loss: 2.3380526867728237

Epoch: 5| Step: 10
Training loss: 0.20452127696086292
Validation loss: 2.2737425448064816

Epoch: 540| Step: 0
Training loss: 0.18564524803444646
Validation loss: 2.29664312189357

Epoch: 5| Step: 1
Training loss: 0.2345022650743501
Validation loss: 2.2918220955800916

Epoch: 5| Step: 2
Training loss: 0.36190119482182054
Validation loss: 2.279885365296234

Epoch: 5| Step: 3
Training loss: 0.1356573594510842
Validation loss: 2.2934625593542157

Epoch: 5| Step: 4
Training loss: 0.1922271893000175
Validation loss: 2.2942074254124014

Epoch: 5| Step: 5
Training loss: 0.15070861168658062
Validation loss: 2.2779684835649685

Epoch: 5| Step: 6
Training loss: 0.2315526785678916
Validation loss: 2.2824719042324135

Epoch: 5| Step: 7
Training loss: 0.12825925614090058
Validation loss: 2.307777145007953

Epoch: 5| Step: 8
Training loss: 0.1915971038019597
Validation loss: 2.3163526702767374

Epoch: 5| Step: 9
Training loss: 0.20253313473420623
Validation loss: 2.290897845253211

Epoch: 5| Step: 10
Training loss: 0.4291917194843985
Validation loss: 2.307068287685214

Epoch: 541| Step: 0
Training loss: 0.17831211718876847
Validation loss: 2.3150112703241668

Epoch: 5| Step: 1
Training loss: 0.15617498742990946
Validation loss: 2.3156980325457486

Epoch: 5| Step: 2
Training loss: 0.34827713761569407
Validation loss: 2.315263646589863

Epoch: 5| Step: 3
Training loss: 0.1303858802210968
Validation loss: 2.3001710214204114

Epoch: 5| Step: 4
Training loss: 0.3846189151427647
Validation loss: 2.3218208327979544

Epoch: 5| Step: 5
Training loss: 0.26423236473464273
Validation loss: 2.2812346647418313

Epoch: 5| Step: 6
Training loss: 0.2514974776638266
Validation loss: 2.298766894426843

Epoch: 5| Step: 7
Training loss: 0.19315953958151358
Validation loss: 2.2905616810931297

Epoch: 5| Step: 8
Training loss: 0.12359577696930903
Validation loss: 2.3275229790663494

Epoch: 5| Step: 9
Training loss: 0.25748904484990465
Validation loss: 2.3182276760679525

Epoch: 5| Step: 10
Training loss: 0.12321241536063521
Validation loss: 2.3115247084935415

Epoch: 542| Step: 0
Training loss: 0.258533567588117
Validation loss: 2.3271215797721667

Epoch: 5| Step: 1
Training loss: 0.13804895561347194
Validation loss: 2.309287630096079

Epoch: 5| Step: 2
Training loss: 0.1339426759831381
Validation loss: 2.3245726508548006

Epoch: 5| Step: 3
Training loss: 0.20597518725110625
Validation loss: 2.292428736980119

Epoch: 5| Step: 4
Training loss: 0.24216208786080426
Validation loss: 2.2895897542219315

Epoch: 5| Step: 5
Training loss: 0.10169221773733408
Validation loss: 2.2875579040808756

Epoch: 5| Step: 6
Training loss: 0.346673035893633
Validation loss: 2.2632296614398584

Epoch: 5| Step: 7
Training loss: 0.23449426636416978
Validation loss: 2.278095225574775

Epoch: 5| Step: 8
Training loss: 0.321029326201521
Validation loss: 2.2607172046075563

Epoch: 5| Step: 9
Training loss: 0.20462911588529376
Validation loss: 2.293347526657448

Epoch: 5| Step: 10
Training loss: 0.33272137446553907
Validation loss: 2.269652740969628

Epoch: 543| Step: 0
Training loss: 0.2683501834766762
Validation loss: 2.262336711286104

Epoch: 5| Step: 1
Training loss: 0.276146547917828
Validation loss: 2.2690093599105063

Epoch: 5| Step: 2
Training loss: 0.18147964932828545
Validation loss: 2.285325733087938

Epoch: 5| Step: 3
Training loss: 0.12113472030106646
Validation loss: 2.298498163200489

Epoch: 5| Step: 4
Training loss: 0.4080425293333323
Validation loss: 2.306331717511302

Epoch: 5| Step: 5
Training loss: 0.27154104066789964
Validation loss: 2.297674524747457

Epoch: 5| Step: 6
Training loss: 0.14788783093456456
Validation loss: 2.3014693155205834

Epoch: 5| Step: 7
Training loss: 0.1700517005000885
Validation loss: 2.27576038648749

Epoch: 5| Step: 8
Training loss: 0.31565623223282324
Validation loss: 2.322089540534033

Epoch: 5| Step: 9
Training loss: 0.1860004903379253
Validation loss: 2.3055621106620885

Epoch: 5| Step: 10
Training loss: 0.22563299703823272
Validation loss: 2.3194060654543707

Epoch: 544| Step: 0
Training loss: 0.20261612753060415
Validation loss: 2.3258156679730413

Epoch: 5| Step: 1
Training loss: 0.25435197294829964
Validation loss: 2.3365302189072006

Epoch: 5| Step: 2
Training loss: 0.18683812423469573
Validation loss: 2.3502061048762304

Epoch: 5| Step: 3
Training loss: 0.10687139958178558
Validation loss: 2.3450145818306503

Epoch: 5| Step: 4
Training loss: 0.18572886727081261
Validation loss: 2.3390174014760534

Epoch: 5| Step: 5
Training loss: 0.17953559425350207
Validation loss: 2.3392816319262666

Epoch: 5| Step: 6
Training loss: 0.1882347472921727
Validation loss: 2.3094842187046805

Epoch: 5| Step: 7
Training loss: 0.17689349830934897
Validation loss: 2.3086846973985944

Epoch: 5| Step: 8
Training loss: 0.29038369610524817
Validation loss: 2.288203181916732

Epoch: 5| Step: 9
Training loss: 0.39092820797617783
Validation loss: 2.294172198942924

Epoch: 5| Step: 10
Training loss: 0.30971628351723796
Validation loss: 2.3183378250792055

Epoch: 545| Step: 0
Training loss: 0.39664380856510495
Validation loss: 2.324160364647699

Epoch: 5| Step: 1
Training loss: 0.21419473065442896
Validation loss: 2.312554480463278

Epoch: 5| Step: 2
Training loss: 0.27587526032055704
Validation loss: 2.3008532092314375

Epoch: 5| Step: 3
Training loss: 0.20534217728851561
Validation loss: 2.2869865873726645

Epoch: 5| Step: 4
Training loss: 0.2848717432919756
Validation loss: 2.3098101760200676

Epoch: 5| Step: 5
Training loss: 0.1253724881302786
Validation loss: 2.3311313528028412

Epoch: 5| Step: 6
Training loss: 0.11850612563333986
Validation loss: 2.3205834985206835

Epoch: 5| Step: 7
Training loss: 0.22332706956981654
Validation loss: 2.3148385739035775

Epoch: 5| Step: 8
Training loss: 0.29320375553737205
Validation loss: 2.3145129048142183

Epoch: 5| Step: 9
Training loss: 0.15740953780453978
Validation loss: 2.3146818732731886

Epoch: 5| Step: 10
Training loss: 0.21930835343216207
Validation loss: 2.309780297524862

Epoch: 546| Step: 0
Training loss: 0.24481421055706232
Validation loss: 2.283791913116819

Epoch: 5| Step: 1
Training loss: 0.21990236666732033
Validation loss: 2.289459540147359

Epoch: 5| Step: 2
Training loss: 0.11806347403975188
Validation loss: 2.2902064794088686

Epoch: 5| Step: 3
Training loss: 0.3443207554058626
Validation loss: 2.3139426762354445

Epoch: 5| Step: 4
Training loss: 0.212273552093357
Validation loss: 2.2953536594373767

Epoch: 5| Step: 5
Training loss: 0.12520924578422546
Validation loss: 2.3161161795478997

Epoch: 5| Step: 6
Training loss: 0.18449384124421744
Validation loss: 2.31635123204495

Epoch: 5| Step: 7
Training loss: 0.35545912928714396
Validation loss: 2.324284362831977

Epoch: 5| Step: 8
Training loss: 0.2801043169657932
Validation loss: 2.324134492712742

Epoch: 5| Step: 9
Training loss: 0.22185850283582081
Validation loss: 2.3141059409823908

Epoch: 5| Step: 10
Training loss: 0.2993934121572297
Validation loss: 2.269268647971796

Epoch: 547| Step: 0
Training loss: 0.3142115689921985
Validation loss: 2.3080829750546226

Epoch: 5| Step: 1
Training loss: 0.23993620938676624
Validation loss: 2.26846097395984

Epoch: 5| Step: 2
Training loss: 0.27997504110301086
Validation loss: 2.2627920779533115

Epoch: 5| Step: 3
Training loss: 0.2592937370908074
Validation loss: 2.2699583485952455

Epoch: 5| Step: 4
Training loss: 0.35762141343457987
Validation loss: 2.2931355807370797

Epoch: 5| Step: 5
Training loss: 0.3506620319210352
Validation loss: 2.324597807689577

Epoch: 5| Step: 6
Training loss: 0.24652435836898048
Validation loss: 2.3404817519571384

Epoch: 5| Step: 7
Training loss: 0.15469491295439985
Validation loss: 2.3264623886772116

Epoch: 5| Step: 8
Training loss: 0.104539227815581
Validation loss: 2.3407143056620763

Epoch: 5| Step: 9
Training loss: 0.18499405472777794
Validation loss: 2.3330516169014826

Epoch: 5| Step: 10
Training loss: 0.17561595880749
Validation loss: 2.297146211167887

Epoch: 548| Step: 0
Training loss: 0.27540508529899865
Validation loss: 2.3152740865374994

Epoch: 5| Step: 1
Training loss: 0.17075583366542113
Validation loss: 2.300918066658044

Epoch: 5| Step: 2
Training loss: 0.1656807888737479
Validation loss: 2.3131325761995964

Epoch: 5| Step: 3
Training loss: 0.17575079866074542
Validation loss: 2.3027382704432147

Epoch: 5| Step: 4
Training loss: 0.19954563885085533
Validation loss: 2.2981481059065847

Epoch: 5| Step: 5
Training loss: 0.3544264803434461
Validation loss: 2.305777589048471

Epoch: 5| Step: 6
Training loss: 0.28786352591645054
Validation loss: 2.3054187113172215

Epoch: 5| Step: 7
Training loss: 0.2666073892815995
Validation loss: 2.2905222361108724

Epoch: 5| Step: 8
Training loss: 0.17715402318860715
Validation loss: 2.3348852274591994

Epoch: 5| Step: 9
Training loss: 0.11980284288004342
Validation loss: 2.315379952709476

Epoch: 5| Step: 10
Training loss: 0.2810004902450181
Validation loss: 2.2760599061047344

Epoch: 549| Step: 0
Training loss: 0.09707119210226553
Validation loss: 2.3228821066024574

Epoch: 5| Step: 1
Training loss: 0.30521093547523326
Validation loss: 2.2806820186954107

Epoch: 5| Step: 2
Training loss: 0.38483581290073343
Validation loss: 2.3048248567106526

Epoch: 5| Step: 3
Training loss: 0.16605150732577
Validation loss: 2.292652719708984

Epoch: 5| Step: 4
Training loss: 0.16738734979166273
Validation loss: 2.293509760359833

Epoch: 5| Step: 5
Training loss: 0.21142293562526854
Validation loss: 2.310715234671173

Epoch: 5| Step: 6
Training loss: 0.14220420587303048
Validation loss: 2.308317792147198

Epoch: 5| Step: 7
Training loss: 0.21443912377016494
Validation loss: 2.289785736007725

Epoch: 5| Step: 8
Training loss: 0.2665586611704989
Validation loss: 2.290511067202808

Epoch: 5| Step: 9
Training loss: 0.22751622228633764
Validation loss: 2.2827224261210755

Epoch: 5| Step: 10
Training loss: 0.21617897576242534
Validation loss: 2.271168972911979

Epoch: 550| Step: 0
Training loss: 0.19723519949871773
Validation loss: 2.2426057333804477

Epoch: 5| Step: 1
Training loss: 0.33128670633020396
Validation loss: 2.2814743655377434

Epoch: 5| Step: 2
Training loss: 0.13953938260785761
Validation loss: 2.2875711954120166

Epoch: 5| Step: 3
Training loss: 0.18168355578001627
Validation loss: 2.275552365091499

Epoch: 5| Step: 4
Training loss: 0.24387737577347732
Validation loss: 2.3009080646278375

Epoch: 5| Step: 5
Training loss: 0.2037615247842928
Validation loss: 2.2949094305527957

Epoch: 5| Step: 6
Training loss: 0.22152867824413952
Validation loss: 2.2681911443609017

Epoch: 5| Step: 7
Training loss: 0.2001189016268378
Validation loss: 2.3048957131370105

Epoch: 5| Step: 8
Training loss: 0.15896590919948414
Validation loss: 2.303869142119002

Epoch: 5| Step: 9
Training loss: 0.4145766251307255
Validation loss: 2.261380681078166

Epoch: 5| Step: 10
Training loss: 0.17033767251688808
Validation loss: 2.2981719813545434

Epoch: 551| Step: 0
Training loss: 0.13237060634680792
Validation loss: 2.2882599121311538

Epoch: 5| Step: 1
Training loss: 0.20420064756896023
Validation loss: 2.2852452975539035

Epoch: 5| Step: 2
Training loss: 0.3842434898500054
Validation loss: 2.3117640925457734

Epoch: 5| Step: 3
Training loss: 0.3365728557874253
Validation loss: 2.3038987640083537

Epoch: 5| Step: 4
Training loss: 0.14183609711625708
Validation loss: 2.3221470130605346

Epoch: 5| Step: 5
Training loss: 0.19436174729297342
Validation loss: 2.2980594266869314

Epoch: 5| Step: 6
Training loss: 0.21820478955653874
Validation loss: 2.304758699908328

Epoch: 5| Step: 7
Training loss: 0.18337494412260757
Validation loss: 2.3350594511371146

Epoch: 5| Step: 8
Training loss: 0.15783246499478645
Validation loss: 2.3584404338356113

Epoch: 5| Step: 9
Training loss: 0.3129830203752358
Validation loss: 2.3390667169682393

Epoch: 5| Step: 10
Training loss: 0.2423511690422055
Validation loss: 2.3305263513309864

Epoch: 552| Step: 0
Training loss: 0.3768035117396739
Validation loss: 2.344572962726346

Epoch: 5| Step: 1
Training loss: 0.1500205713808912
Validation loss: 2.3038899012942693

Epoch: 5| Step: 2
Training loss: 0.2784036344319055
Validation loss: 2.302004982687723

Epoch: 5| Step: 3
Training loss: 0.17581420695448893
Validation loss: 2.2915658505396137

Epoch: 5| Step: 4
Training loss: 0.13068405904987804
Validation loss: 2.273525118932177

Epoch: 5| Step: 5
Training loss: 0.2620984213028308
Validation loss: 2.2824836560979533

Epoch: 5| Step: 6
Training loss: 0.1998631303321241
Validation loss: 2.2981151251865617

Epoch: 5| Step: 7
Training loss: 0.1602582257959644
Validation loss: 2.299969805197809

Epoch: 5| Step: 8
Training loss: 0.19278160626728977
Validation loss: 2.29529210106724

Epoch: 5| Step: 9
Training loss: 0.34578675804801856
Validation loss: 2.3292120678944173

Epoch: 5| Step: 10
Training loss: 0.19700873048856424
Validation loss: 2.340239348879643

Epoch: 553| Step: 0
Training loss: 0.1682328487786532
Validation loss: 2.3176745915673105

Epoch: 5| Step: 1
Training loss: 0.2532034611074447
Validation loss: 2.340557460050602

Epoch: 5| Step: 2
Training loss: 0.36365768454100666
Validation loss: 2.363939818317195

Epoch: 5| Step: 3
Training loss: 0.26326184356888
Validation loss: 2.360644876660531

Epoch: 5| Step: 4
Training loss: 0.21854944913175509
Validation loss: 2.3319402533934346

Epoch: 5| Step: 5
Training loss: 0.12200695300881899
Validation loss: 2.3502641638910364

Epoch: 5| Step: 6
Training loss: 0.16690142992827328
Validation loss: 2.3150788095899952

Epoch: 5| Step: 7
Training loss: 0.2439003181347135
Validation loss: 2.3390066329254604

Epoch: 5| Step: 8
Training loss: 0.07883702005363799
Validation loss: 2.347991966857476

Epoch: 5| Step: 9
Training loss: 0.18094802397592163
Validation loss: 2.3296013551740744

Epoch: 5| Step: 10
Training loss: 0.3215758947765242
Validation loss: 2.30353643010819

Epoch: 554| Step: 0
Training loss: 0.19104246680328918
Validation loss: 2.3290976539132378

Epoch: 5| Step: 1
Training loss: 0.19548330467796435
Validation loss: 2.2815945722299

Epoch: 5| Step: 2
Training loss: 0.18472808069326005
Validation loss: 2.2817821997252383

Epoch: 5| Step: 3
Training loss: 0.19820599155059737
Validation loss: 2.3161494617973375

Epoch: 5| Step: 4
Training loss: 0.3432459495254048
Validation loss: 2.3014044468943844

Epoch: 5| Step: 5
Training loss: 0.2959377149442156
Validation loss: 2.3199417333451904

Epoch: 5| Step: 6
Training loss: 0.20078453254242895
Validation loss: 2.2999894005030526

Epoch: 5| Step: 7
Training loss: 0.18779055613189466
Validation loss: 2.305693690794168

Epoch: 5| Step: 8
Training loss: 0.13575339099563535
Validation loss: 2.3105500210941785

Epoch: 5| Step: 9
Training loss: 0.13019151499532317
Validation loss: 2.29047617114937

Epoch: 5| Step: 10
Training loss: 0.38937217077632635
Validation loss: 2.303210246634991

Epoch: 555| Step: 0
Training loss: 0.2423398938170433
Validation loss: 2.2917927644852436

Epoch: 5| Step: 1
Training loss: 0.3869976617732616
Validation loss: 2.279583263512788

Epoch: 5| Step: 2
Training loss: 0.2258359753637737
Validation loss: 2.3046486827820454

Epoch: 5| Step: 3
Training loss: 0.13125202001425001
Validation loss: 2.2743459626610205

Epoch: 5| Step: 4
Training loss: 0.24899515477554562
Validation loss: 2.291789582014828

Epoch: 5| Step: 5
Training loss: 0.33977206340065574
Validation loss: 2.297751792792971

Epoch: 5| Step: 6
Training loss: 0.12087558120466503
Validation loss: 2.28527128780036

Epoch: 5| Step: 7
Training loss: 0.1540684759981188
Validation loss: 2.2677526456037667

Epoch: 5| Step: 8
Training loss: 0.1281119569675744
Validation loss: 2.294714948811344

Epoch: 5| Step: 9
Training loss: 0.21146478799699595
Validation loss: 2.2934551231539135

Epoch: 5| Step: 10
Training loss: 0.1389281162026593
Validation loss: 2.2721060958330512

Epoch: 556| Step: 0
Training loss: 0.15788296103811442
Validation loss: 2.2997094838951515

Epoch: 5| Step: 1
Training loss: 0.15848855772218323
Validation loss: 2.32177970557188

Epoch: 5| Step: 2
Training loss: 0.24882488937310315
Validation loss: 2.3058017390562155

Epoch: 5| Step: 3
Training loss: 0.17539997075930452
Validation loss: 2.322040091362134

Epoch: 5| Step: 4
Training loss: 0.18918713843453183
Validation loss: 2.2977117627513404

Epoch: 5| Step: 5
Training loss: 0.34800140520543815
Validation loss: 2.308841471948763

Epoch: 5| Step: 6
Training loss: 0.24205840423284525
Validation loss: 2.2962987792406357

Epoch: 5| Step: 7
Training loss: 0.15854233415687027
Validation loss: 2.31025298672527

Epoch: 5| Step: 8
Training loss: 0.10085302835259555
Validation loss: 2.2781874017566626

Epoch: 5| Step: 9
Training loss: 0.10382509755298322
Validation loss: 2.2602842755366095

Epoch: 5| Step: 10
Training loss: 0.36647616128168264
Validation loss: 2.2627700294169206

Epoch: 557| Step: 0
Training loss: 0.20368821665674944
Validation loss: 2.318174815799341

Epoch: 5| Step: 1
Training loss: 0.13641698777538314
Validation loss: 2.3142357940838134

Epoch: 5| Step: 2
Training loss: 0.13438328118644788
Validation loss: 2.320455443508255

Epoch: 5| Step: 3
Training loss: 0.11552078005927359
Validation loss: 2.3195641854564912

Epoch: 5| Step: 4
Training loss: 0.24693787836341768
Validation loss: 2.2983987550668274

Epoch: 5| Step: 5
Training loss: 0.15525676829754217
Validation loss: 2.3356957382693744

Epoch: 5| Step: 6
Training loss: 0.19717766906546758
Validation loss: 2.313065616841458

Epoch: 5| Step: 7
Training loss: 0.1673297593245955
Validation loss: 2.3061906204162703

Epoch: 5| Step: 8
Training loss: 0.2721324156940973
Validation loss: 2.2858847829052396

Epoch: 5| Step: 9
Training loss: 0.31855774766304656
Validation loss: 2.293428945636749

Epoch: 5| Step: 10
Training loss: 0.36461268261442575
Validation loss: 2.3021124613035586

Epoch: 558| Step: 0
Training loss: 0.3047153753587288
Validation loss: 2.292212693242844

Epoch: 5| Step: 1
Training loss: 0.21785626739297015
Validation loss: 2.288089079184186

Epoch: 5| Step: 2
Training loss: 0.16329425367566103
Validation loss: 2.2756025963167525

Epoch: 5| Step: 3
Training loss: 0.18562040377876607
Validation loss: 2.2862614224906683

Epoch: 5| Step: 4
Training loss: 0.17602458641514018
Validation loss: 2.2965980995170967

Epoch: 5| Step: 5
Training loss: 0.19687362473628156
Validation loss: 2.292415287054337

Epoch: 5| Step: 6
Training loss: 0.17894869763083468
Validation loss: 2.304131202029479

Epoch: 5| Step: 7
Training loss: 0.39529203957543135
Validation loss: 2.3189977801553394

Epoch: 5| Step: 8
Training loss: 0.1287474014774607
Validation loss: 2.314697459307623

Epoch: 5| Step: 9
Training loss: 0.26844506540617646
Validation loss: 2.314774904476744

Epoch: 5| Step: 10
Training loss: 0.20539938876440425
Validation loss: 2.3028349240873682

Epoch: 559| Step: 0
Training loss: 0.21358363196651892
Validation loss: 2.309186829642323

Epoch: 5| Step: 1
Training loss: 0.16972314240726805
Validation loss: 2.2886688712663634

Epoch: 5| Step: 2
Training loss: 0.16132991180169354
Validation loss: 2.257014022734881

Epoch: 5| Step: 3
Training loss: 0.26908429723210403
Validation loss: 2.2651410902531937

Epoch: 5| Step: 4
Training loss: 0.31062094087078485
Validation loss: 2.2673454996662965

Epoch: 5| Step: 5
Training loss: 0.1733391237915561
Validation loss: 2.2379854893052724

Epoch: 5| Step: 6
Training loss: 0.13469638980992002
Validation loss: 2.278078926034973

Epoch: 5| Step: 7
Training loss: 0.3866609857747525
Validation loss: 2.26811953575033

Epoch: 5| Step: 8
Training loss: 0.1077554638272767
Validation loss: 2.273092904795569

Epoch: 5| Step: 9
Training loss: 0.1880484051358864
Validation loss: 2.2800832920821628

Epoch: 5| Step: 10
Training loss: 0.1525992671540238
Validation loss: 2.293156629647036

Epoch: 560| Step: 0
Training loss: 0.1595428746702333
Validation loss: 2.2799297540598475

Epoch: 5| Step: 1
Training loss: 0.1504391492860989
Validation loss: 2.29718256996329

Epoch: 5| Step: 2
Training loss: 0.17027385474458223
Validation loss: 2.3090608449533705

Epoch: 5| Step: 3
Training loss: 0.23704480827093904
Validation loss: 2.314467422706336

Epoch: 5| Step: 4
Training loss: 0.24482464906329823
Validation loss: 2.288656320008972

Epoch: 5| Step: 5
Training loss: 0.17226026985166198
Validation loss: 2.3209572802827383

Epoch: 5| Step: 6
Training loss: 0.22912843161290447
Validation loss: 2.276046353818226

Epoch: 5| Step: 7
Training loss: 0.13650813910650955
Validation loss: 2.3427578877871067

Epoch: 5| Step: 8
Training loss: 0.18523472076795622
Validation loss: 2.309274389376682

Epoch: 5| Step: 9
Training loss: 0.35574024438248814
Validation loss: 2.293298832733604

Epoch: 5| Step: 10
Training loss: 0.3114833507037824
Validation loss: 2.294690653075584

Epoch: 561| Step: 0
Training loss: 0.20711030890082627
Validation loss: 2.2838796062588838

Epoch: 5| Step: 1
Training loss: 0.1563325008502426
Validation loss: 2.2601820365252814

Epoch: 5| Step: 2
Training loss: 0.2928531800248689
Validation loss: 2.2584241153703286

Epoch: 5| Step: 3
Training loss: 0.3751512659481388
Validation loss: 2.271718731104803

Epoch: 5| Step: 4
Training loss: 0.16408305947592675
Validation loss: 2.2936531291207323

Epoch: 5| Step: 5
Training loss: 0.1820094148694931
Validation loss: 2.2992581049278473

Epoch: 5| Step: 6
Training loss: 0.15608516581685544
Validation loss: 2.296887565501966

Epoch: 5| Step: 7
Training loss: 0.27173376635253577
Validation loss: 2.303181903731829

Epoch: 5| Step: 8
Training loss: 0.2777264332340024
Validation loss: 2.3218461320704153

Epoch: 5| Step: 9
Training loss: 0.20798386628480842
Validation loss: 2.3168801151876885

Epoch: 5| Step: 10
Training loss: 0.10748326108183102
Validation loss: 2.262968890132816

Epoch: 562| Step: 0
Training loss: 0.26054898079588784
Validation loss: 2.257917799766666

Epoch: 5| Step: 1
Training loss: 0.4033561487417958
Validation loss: 2.2530914669156497

Epoch: 5| Step: 2
Training loss: 0.24476375403786513
Validation loss: 2.261211360099087

Epoch: 5| Step: 3
Training loss: 0.13957963595783676
Validation loss: 2.241961646427181

Epoch: 5| Step: 4
Training loss: 0.2647784149691674
Validation loss: 2.238278333908329

Epoch: 5| Step: 5
Training loss: 0.2885615157221515
Validation loss: 2.281391043354822

Epoch: 5| Step: 6
Training loss: 0.17107389979414958
Validation loss: 2.285053830252642

Epoch: 5| Step: 7
Training loss: 0.21191768379457357
Validation loss: 2.2990862735869935

Epoch: 5| Step: 8
Training loss: 0.11908436056383205
Validation loss: 2.3013027781249225

Epoch: 5| Step: 9
Training loss: 0.17557221805663994
Validation loss: 2.320653288294809

Epoch: 5| Step: 10
Training loss: 0.12555775778603448
Validation loss: 2.339819568966037

Epoch: 563| Step: 0
Training loss: 0.22555561605018384
Validation loss: 2.337419314875861

Epoch: 5| Step: 1
Training loss: 0.16319625800784401
Validation loss: 2.3542228773330245

Epoch: 5| Step: 2
Training loss: 0.28252639155624504
Validation loss: 2.320436879469014

Epoch: 5| Step: 3
Training loss: 0.14950721928299954
Validation loss: 2.316833971235003

Epoch: 5| Step: 4
Training loss: 0.18516741650545704
Validation loss: 2.3002418178051354

Epoch: 5| Step: 5
Training loss: 0.1455622001745593
Validation loss: 2.287357584505709

Epoch: 5| Step: 6
Training loss: 0.2135190787037788
Validation loss: 2.273186341670647

Epoch: 5| Step: 7
Training loss: 0.21326515954493885
Validation loss: 2.3132424729911594

Epoch: 5| Step: 8
Training loss: 0.14601656920085412
Validation loss: 2.300302507044986

Epoch: 5| Step: 9
Training loss: 0.4152851407444877
Validation loss: 2.31214144054628

Epoch: 5| Step: 10
Training loss: 0.09758972763276323
Validation loss: 2.306414494924649

Epoch: 564| Step: 0
Training loss: 0.27403070952703334
Validation loss: 2.307823116798421

Epoch: 5| Step: 1
Training loss: 0.14463789974380267
Validation loss: 2.3375644969525418

Epoch: 5| Step: 2
Training loss: 0.14065213074168623
Validation loss: 2.294782953606676

Epoch: 5| Step: 3
Training loss: 0.16802133801528932
Validation loss: 2.3044061682676724

Epoch: 5| Step: 4
Training loss: 0.4617338090948453
Validation loss: 2.2954222813558225

Epoch: 5| Step: 5
Training loss: 0.19106752240596225
Validation loss: 2.2907850641165166

Epoch: 5| Step: 6
Training loss: 0.2067486525696941
Validation loss: 2.273842303659142

Epoch: 5| Step: 7
Training loss: 0.15609790432760096
Validation loss: 2.3114632192210127

Epoch: 5| Step: 8
Training loss: 0.17508898690713626
Validation loss: 2.2991723238297195

Epoch: 5| Step: 9
Training loss: 0.09348444282545855
Validation loss: 2.2671723897308915

Epoch: 5| Step: 10
Training loss: 0.14267677003908188
Validation loss: 2.2719407957509263

Epoch: 565| Step: 0
Training loss: 0.25946575438451625
Validation loss: 2.278133947205001

Epoch: 5| Step: 1
Training loss: 0.1571240357378503
Validation loss: 2.2868592664329537

Epoch: 5| Step: 2
Training loss: 0.16431466659736801
Validation loss: 2.2720904100095756

Epoch: 5| Step: 3
Training loss: 0.33535298795402674
Validation loss: 2.2956125008213495

Epoch: 5| Step: 4
Training loss: 0.13734913319615188
Validation loss: 2.280757347961907

Epoch: 5| Step: 5
Training loss: 0.15671079757115944
Validation loss: 2.288890070141179

Epoch: 5| Step: 6
Training loss: 0.19258728392450178
Validation loss: 2.2908735269404343

Epoch: 5| Step: 7
Training loss: 0.20755171582338222
Validation loss: 2.308212556126719

Epoch: 5| Step: 8
Training loss: 0.2390884578549429
Validation loss: 2.297658301620102

Epoch: 5| Step: 9
Training loss: 0.1580618828301016
Validation loss: 2.288466013286093

Epoch: 5| Step: 10
Training loss: 0.22702164821969184
Validation loss: 2.2831523985103988

Epoch: 566| Step: 0
Training loss: 0.2418402597456724
Validation loss: 2.3054087643974523

Epoch: 5| Step: 1
Training loss: 0.16093445330578482
Validation loss: 2.325370262726601

Epoch: 5| Step: 2
Training loss: 0.16427272996511078
Validation loss: 2.307943793945576

Epoch: 5| Step: 3
Training loss: 0.1015603450399807
Validation loss: 2.2984298455969654

Epoch: 5| Step: 4
Training loss: 0.370548470075674
Validation loss: 2.3078021744419552

Epoch: 5| Step: 5
Training loss: 0.22863199254391905
Validation loss: 2.296087239725951

Epoch: 5| Step: 6
Training loss: 0.19818511855536125
Validation loss: 2.2979756694608673

Epoch: 5| Step: 7
Training loss: 0.12135132958884615
Validation loss: 2.2933212288586904

Epoch: 5| Step: 8
Training loss: 0.22283254303205954
Validation loss: 2.2634407963249874

Epoch: 5| Step: 9
Training loss: 0.29258709525807486
Validation loss: 2.2724419743330464

Epoch: 5| Step: 10
Training loss: 0.15395585533887182
Validation loss: 2.2922659056006585

Epoch: 567| Step: 0
Training loss: 0.18912936596643481
Validation loss: 2.2982396942248604

Epoch: 5| Step: 1
Training loss: 0.2991611644421304
Validation loss: 2.2532119595837123

Epoch: 5| Step: 2
Training loss: 0.12747131376734666
Validation loss: 2.298127484227202

Epoch: 5| Step: 3
Training loss: 0.16914690812138222
Validation loss: 2.2953176687292935

Epoch: 5| Step: 4
Training loss: 0.11328331353511406
Validation loss: 2.313708308127106

Epoch: 5| Step: 5
Training loss: 0.3632395320442066
Validation loss: 2.3060829133195875

Epoch: 5| Step: 6
Training loss: 0.22812175225859302
Validation loss: 2.3193517216143724

Epoch: 5| Step: 7
Training loss: 0.15895463679412286
Validation loss: 2.300763319453209

Epoch: 5| Step: 8
Training loss: 0.1428585365080548
Validation loss: 2.2908811802258793

Epoch: 5| Step: 9
Training loss: 0.23459197967855272
Validation loss: 2.293156245071277

Epoch: 5| Step: 10
Training loss: 0.12026117967322514
Validation loss: 2.2943483348207607

Epoch: 568| Step: 0
Training loss: 0.21772907643463374
Validation loss: 2.290415681009469

Epoch: 5| Step: 1
Training loss: 0.16428638690516845
Validation loss: 2.3139682533083885

Epoch: 5| Step: 2
Training loss: 0.3414786465002241
Validation loss: 2.2886040576478117

Epoch: 5| Step: 3
Training loss: 0.13132352500951736
Validation loss: 2.290573529676653

Epoch: 5| Step: 4
Training loss: 0.13463862972987933
Validation loss: 2.3391034867204867

Epoch: 5| Step: 5
Training loss: 0.1443642927819174
Validation loss: 2.3292060792655493

Epoch: 5| Step: 6
Training loss: 0.2238165088455394
Validation loss: 2.3439581392357383

Epoch: 5| Step: 7
Training loss: 0.09835217463928356
Validation loss: 2.3041259882492917

Epoch: 5| Step: 8
Training loss: 0.19291134184978673
Validation loss: 2.2723562668092026

Epoch: 5| Step: 9
Training loss: 0.3402954585429795
Validation loss: 2.317343776487097

Epoch: 5| Step: 10
Training loss: 0.13032621689970506
Validation loss: 2.294721674306386

Epoch: 569| Step: 0
Training loss: 0.1745529066427866
Validation loss: 2.3008655803054983

Epoch: 5| Step: 1
Training loss: 0.24680204490518887
Validation loss: 2.252656384901985

Epoch: 5| Step: 2
Training loss: 0.19369994139803373
Validation loss: 2.2559960568798747

Epoch: 5| Step: 3
Training loss: 0.268227297890582
Validation loss: 2.276608563462469

Epoch: 5| Step: 4
Training loss: 0.16481252505628086
Validation loss: 2.268985542543692

Epoch: 5| Step: 5
Training loss: 0.2028134965210871
Validation loss: 2.2683424627429836

Epoch: 5| Step: 6
Training loss: 0.10433435552405312
Validation loss: 2.3017388325795447

Epoch: 5| Step: 7
Training loss: 0.12652476743144603
Validation loss: 2.3160705671798825

Epoch: 5| Step: 8
Training loss: 0.375415313734495
Validation loss: 2.311474123298243

Epoch: 5| Step: 9
Training loss: 0.24055998530749703
Validation loss: 2.3182649997266487

Epoch: 5| Step: 10
Training loss: 0.22267640173218062
Validation loss: 2.3059073919493316

Epoch: 570| Step: 0
Training loss: 0.18759324814772055
Validation loss: 2.2769471361052323

Epoch: 5| Step: 1
Training loss: 0.16641293834623389
Validation loss: 2.2938594363831926

Epoch: 5| Step: 2
Training loss: 0.12441724671341786
Validation loss: 2.242522196517933

Epoch: 5| Step: 3
Training loss: 0.0877989476282258
Validation loss: 2.2748695579318885

Epoch: 5| Step: 4
Training loss: 0.1655852742506937
Validation loss: 2.248777513179363

Epoch: 5| Step: 5
Training loss: 0.35003821215479997
Validation loss: 2.2798506889250683

Epoch: 5| Step: 6
Training loss: 0.2628063690386676
Validation loss: 2.289841559627192

Epoch: 5| Step: 7
Training loss: 0.17064006347675637
Validation loss: 2.2997085408019315

Epoch: 5| Step: 8
Training loss: 0.2173050689145337
Validation loss: 2.2873696194848088

Epoch: 5| Step: 9
Training loss: 0.26063143774813313
Validation loss: 2.2967553486010024

Epoch: 5| Step: 10
Training loss: 0.2547522170098581
Validation loss: 2.286469749459371

Epoch: 571| Step: 0
Training loss: 0.1349239870159022
Validation loss: 2.280721117925711

Epoch: 5| Step: 1
Training loss: 0.2909740699951166
Validation loss: 2.2996498698332437

Epoch: 5| Step: 2
Training loss: 0.10816312715119775
Validation loss: 2.2893485515231844

Epoch: 5| Step: 3
Training loss: 0.193488973477114
Validation loss: 2.2891389214641342

Epoch: 5| Step: 4
Training loss: 0.20296872986932174
Validation loss: 2.265992943996024

Epoch: 5| Step: 5
Training loss: 0.15689795373645357
Validation loss: 2.268214233148849

Epoch: 5| Step: 6
Training loss: 0.32418433546776243
Validation loss: 2.2592052228167927

Epoch: 5| Step: 7
Training loss: 0.36375998670102294
Validation loss: 2.2652181721914184

Epoch: 5| Step: 8
Training loss: 0.14559760299508476
Validation loss: 2.280886066045129

Epoch: 5| Step: 9
Training loss: 0.17001585718136775
Validation loss: 2.2674771193546905

Epoch: 5| Step: 10
Training loss: 0.1624487920001452
Validation loss: 2.2951602044210806

Epoch: 572| Step: 0
Training loss: 0.23134593198108724
Validation loss: 2.2797312021960168

Epoch: 5| Step: 1
Training loss: 0.1981686986752731
Validation loss: 2.280327516444023

Epoch: 5| Step: 2
Training loss: 0.3399741919974619
Validation loss: 2.283112630701046

Epoch: 5| Step: 3
Training loss: 0.23699032404418333
Validation loss: 2.323048435621468

Epoch: 5| Step: 4
Training loss: 0.13981510433709612
Validation loss: 2.3212643645847546

Epoch: 5| Step: 5
Training loss: 0.16809406706777788
Validation loss: 2.3214459885686796

Epoch: 5| Step: 6
Training loss: 0.28111015922908134
Validation loss: 2.323101639102496

Epoch: 5| Step: 7
Training loss: 0.12361300507139568
Validation loss: 2.307829219233702

Epoch: 5| Step: 8
Training loss: 0.25514811012847205
Validation loss: 2.3136746206767955

Epoch: 5| Step: 9
Training loss: 0.13457332934360028
Validation loss: 2.301236751229259

Epoch: 5| Step: 10
Training loss: 0.1540057659339256
Validation loss: 2.2802835868154077

Epoch: 573| Step: 0
Training loss: 0.18160408431821462
Validation loss: 2.2933329620179785

Epoch: 5| Step: 1
Training loss: 0.1872645926894666
Validation loss: 2.277826401059559

Epoch: 5| Step: 2
Training loss: 0.15963000974993685
Validation loss: 2.2660367665772325

Epoch: 5| Step: 3
Training loss: 0.4551783602759533
Validation loss: 2.2799562288089925

Epoch: 5| Step: 4
Training loss: 0.1996089535912173
Validation loss: 2.277125721161005

Epoch: 5| Step: 5
Training loss: 0.24806638325549277
Validation loss: 2.2638194141472505

Epoch: 5| Step: 6
Training loss: 0.1823714740077652
Validation loss: 2.2855708700133897

Epoch: 5| Step: 7
Training loss: 0.22847986349042068
Validation loss: 2.260755780499716

Epoch: 5| Step: 8
Training loss: 0.14799992161503855
Validation loss: 2.261915679467816

Epoch: 5| Step: 9
Training loss: 0.1501046099072737
Validation loss: 2.3021718094835637

Epoch: 5| Step: 10
Training loss: 0.10717014381449809
Validation loss: 2.252560863307449

Epoch: 574| Step: 0
Training loss: 0.24676801258556
Validation loss: 2.275059433135614

Epoch: 5| Step: 1
Training loss: 0.44684461076817483
Validation loss: 2.272142153522294

Epoch: 5| Step: 2
Training loss: 0.09162391946924393
Validation loss: 2.2920921497493913

Epoch: 5| Step: 3
Training loss: 0.16280308482061623
Validation loss: 2.2578289492519183

Epoch: 5| Step: 4
Training loss: 0.2002607750279693
Validation loss: 2.2607213153334955

Epoch: 5| Step: 5
Training loss: 0.166512346473284
Validation loss: 2.2870878938061416

Epoch: 5| Step: 6
Training loss: 0.12696351228914918
Validation loss: 2.254961604819274

Epoch: 5| Step: 7
Training loss: 0.16734597725548087
Validation loss: 2.283766232696364

Epoch: 5| Step: 8
Training loss: 0.11450334397632331
Validation loss: 2.2828185852247733

Epoch: 5| Step: 9
Training loss: 0.2029847339359446
Validation loss: 2.2436172005020056

Epoch: 5| Step: 10
Training loss: 0.2285678999359161
Validation loss: 2.2600376011107794

Epoch: 575| Step: 0
Training loss: 0.31628366144182746
Validation loss: 2.272525348530755

Epoch: 5| Step: 1
Training loss: 0.29032359953029846
Validation loss: 2.2530679842067003

Epoch: 5| Step: 2
Training loss: 0.12566388678901586
Validation loss: 2.2910076152022723

Epoch: 5| Step: 3
Training loss: 0.2644608737368165
Validation loss: 2.2792643621635262

Epoch: 5| Step: 4
Training loss: 0.21380120396094432
Validation loss: 2.2763337504297834

Epoch: 5| Step: 5
Training loss: 0.1306309129093085
Validation loss: 2.284656502476594

Epoch: 5| Step: 6
Training loss: 0.3532829889139118
Validation loss: 2.290280200312527

Epoch: 5| Step: 7
Training loss: 0.21503793437221824
Validation loss: 2.246885714876999

Epoch: 5| Step: 8
Training loss: 0.19781295459930107
Validation loss: 2.287434761156644

Epoch: 5| Step: 9
Training loss: 0.16502769701946504
Validation loss: 2.3029958137557975

Epoch: 5| Step: 10
Training loss: 0.11431180868153544
Validation loss: 2.2699818203333497

Epoch: 576| Step: 0
Training loss: 0.12393634847283018
Validation loss: 2.233637534232992

Epoch: 5| Step: 1
Training loss: 0.16944511440367005
Validation loss: 2.236781414051154

Epoch: 5| Step: 2
Training loss: 0.18740725210181744
Validation loss: 2.256602815992952

Epoch: 5| Step: 3
Training loss: 0.19347836464917317
Validation loss: 2.254164559464913

Epoch: 5| Step: 4
Training loss: 0.12028741404719503
Validation loss: 2.287074607512774

Epoch: 5| Step: 5
Training loss: 0.21684725064449353
Validation loss: 2.281970034233282

Epoch: 5| Step: 6
Training loss: 0.30796922189181875
Validation loss: 2.3088755019504457

Epoch: 5| Step: 7
Training loss: 0.31349046622842425
Validation loss: 2.3027367385406388

Epoch: 5| Step: 8
Training loss: 0.11021882488220068
Validation loss: 2.3051866194261095

Epoch: 5| Step: 9
Training loss: 0.3478433983951553
Validation loss: 2.3178978479674477

Epoch: 5| Step: 10
Training loss: 0.11535203309678485
Validation loss: 2.3421893206075977

Epoch: 577| Step: 0
Training loss: 0.13815127287931325
Validation loss: 2.2850622300294465

Epoch: 5| Step: 1
Training loss: 0.1907287401360896
Validation loss: 2.291961403367407

Epoch: 5| Step: 2
Training loss: 0.1520829964714587
Validation loss: 2.2906269295245356

Epoch: 5| Step: 3
Training loss: 0.23832087890777784
Validation loss: 2.2885245111271746

Epoch: 5| Step: 4
Training loss: 0.18405953631581412
Validation loss: 2.299612919620676

Epoch: 5| Step: 5
Training loss: 0.2205336350356199
Validation loss: 2.271036052282427

Epoch: 5| Step: 6
Training loss: 0.23162491183837677
Validation loss: 2.266773390821089

Epoch: 5| Step: 7
Training loss: 0.2545781269311129
Validation loss: 2.274206050973563

Epoch: 5| Step: 8
Training loss: 0.39003113426742875
Validation loss: 2.292684834142518

Epoch: 5| Step: 9
Training loss: 0.156934680472067
Validation loss: 2.2552173198172394

Epoch: 5| Step: 10
Training loss: 0.10627944079095543
Validation loss: 2.2542417102471837

Epoch: 578| Step: 0
Training loss: 0.18002687415863944
Validation loss: 2.2739279746199386

Epoch: 5| Step: 1
Training loss: 0.16112976071328772
Validation loss: 2.319682238180195

Epoch: 5| Step: 2
Training loss: 0.25081690300128834
Validation loss: 2.2893286221371807

Epoch: 5| Step: 3
Training loss: 0.3658433824424758
Validation loss: 2.269300441489525

Epoch: 5| Step: 4
Training loss: 0.12013156928826818
Validation loss: 2.2903990219879313

Epoch: 5| Step: 5
Training loss: 0.27568409210603256
Validation loss: 2.280359166455527

Epoch: 5| Step: 6
Training loss: 0.217899568236743
Validation loss: 2.2690135810268552

Epoch: 5| Step: 7
Training loss: 0.12424258147463088
Validation loss: 2.2443207479354377

Epoch: 5| Step: 8
Training loss: 0.2291045628552019
Validation loss: 2.256610054968199

Epoch: 5| Step: 9
Training loss: 0.11856406267480615
Validation loss: 2.243770710853

Epoch: 5| Step: 10
Training loss: 0.109455674936133
Validation loss: 2.243281169136705

Epoch: 579| Step: 0
Training loss: 0.15475486434892988
Validation loss: 2.261944425829036

Epoch: 5| Step: 1
Training loss: 0.3339716814093993
Validation loss: 2.2769036997197105

Epoch: 5| Step: 2
Training loss: 0.2414753040447665
Validation loss: 2.296581320410609

Epoch: 5| Step: 3
Training loss: 0.15677020974737538
Validation loss: 2.276410421838438

Epoch: 5| Step: 4
Training loss: 0.22162714095945327
Validation loss: 2.295141788192673

Epoch: 5| Step: 5
Training loss: 0.1787755463758379
Validation loss: 2.27204401986742

Epoch: 5| Step: 6
Training loss: 0.10139171288950573
Validation loss: 2.27365378641547

Epoch: 5| Step: 7
Training loss: 0.13861783411881048
Validation loss: 2.23934220668386

Epoch: 5| Step: 8
Training loss: 0.14530122415827013
Validation loss: 2.2727329273237435

Epoch: 5| Step: 9
Training loss: 0.11368748567496152
Validation loss: 2.259534951262392

Epoch: 5| Step: 10
Training loss: 0.2823055381228969
Validation loss: 2.2714143453630027

Epoch: 580| Step: 0
Training loss: 0.25718029130309544
Validation loss: 2.283770698193897

Epoch: 5| Step: 1
Training loss: 0.17485276951506834
Validation loss: 2.274752488995327

Epoch: 5| Step: 2
Training loss: 0.40385276248436214
Validation loss: 2.298568390433761

Epoch: 5| Step: 3
Training loss: 0.10007927888715742
Validation loss: 2.2480028191857775

Epoch: 5| Step: 4
Training loss: 0.14424957716712927
Validation loss: 2.2769004649123805

Epoch: 5| Step: 5
Training loss: 0.21533033582231853
Validation loss: 2.311128208900692

Epoch: 5| Step: 6
Training loss: 0.11051891937210521
Validation loss: 2.2781778963412576

Epoch: 5| Step: 7
Training loss: 0.13444508565643837
Validation loss: 2.2857182035718395

Epoch: 5| Step: 8
Training loss: 0.10935766218914962
Validation loss: 2.2720854527387866

Epoch: 5| Step: 9
Training loss: 0.21675086177502814
Validation loss: 2.281920115061579

Epoch: 5| Step: 10
Training loss: 0.1507903644791547
Validation loss: 2.267591076696316

Epoch: 581| Step: 0
Training loss: 0.16311069688901758
Validation loss: 2.2667101888064365

Epoch: 5| Step: 1
Training loss: 0.18561247619612312
Validation loss: 2.2785100796014874

Epoch: 5| Step: 2
Training loss: 0.12077724717873917
Validation loss: 2.2534042956503435

Epoch: 5| Step: 3
Training loss: 0.12462733267893848
Validation loss: 2.2695107275094406

Epoch: 5| Step: 4
Training loss: 0.10314614104546266
Validation loss: 2.2927564766693083

Epoch: 5| Step: 5
Training loss: 0.29487847015098373
Validation loss: 2.2905363306377384

Epoch: 5| Step: 6
Training loss: 0.1778789602885625
Validation loss: 2.3036164217229183

Epoch: 5| Step: 7
Training loss: 0.08689279510382468
Validation loss: 2.28594557237738

Epoch: 5| Step: 8
Training loss: 0.25094250993489936
Validation loss: 2.2785681326607983

Epoch: 5| Step: 9
Training loss: 0.3540408411160413
Validation loss: 2.294344921805384

Epoch: 5| Step: 10
Training loss: 0.14148921455898428
Validation loss: 2.3308027875341795

Epoch: 582| Step: 0
Training loss: 0.35921348176322826
Validation loss: 2.304519004773476

Epoch: 5| Step: 1
Training loss: 0.25516094364631037
Validation loss: 2.3121055392977095

Epoch: 5| Step: 2
Training loss: 0.15497352618199575
Validation loss: 2.3144728435830593

Epoch: 5| Step: 3
Training loss: 0.10619670376202718
Validation loss: 2.314775959935296

Epoch: 5| Step: 4
Training loss: 0.11205271358994802
Validation loss: 2.289351075578686

Epoch: 5| Step: 5
Training loss: 0.14918034169067876
Validation loss: 2.285359262949944

Epoch: 5| Step: 6
Training loss: 0.20098544250385095
Validation loss: 2.2940339250166426

Epoch: 5| Step: 7
Training loss: 0.2410839920516783
Validation loss: 2.2874136982599333

Epoch: 5| Step: 8
Training loss: 0.1748233018053488
Validation loss: 2.3140755479655297

Epoch: 5| Step: 9
Training loss: 0.1063842204406201
Validation loss: 2.304981650214329

Epoch: 5| Step: 10
Training loss: 0.08302347372077058
Validation loss: 2.2834894771674

Epoch: 583| Step: 0
Training loss: 0.10775402909189413
Validation loss: 2.3089832947326743

Epoch: 5| Step: 1
Training loss: 0.18775038094932725
Validation loss: 2.3072630803803014

Epoch: 5| Step: 2
Training loss: 0.12815838675355945
Validation loss: 2.2717845243963826

Epoch: 5| Step: 3
Training loss: 0.13280327147790302
Validation loss: 2.2976328219297066

Epoch: 5| Step: 4
Training loss: 0.08665655328509761
Validation loss: 2.3004447464880062

Epoch: 5| Step: 5
Training loss: 0.23963725305649689
Validation loss: 2.29342347278373

Epoch: 5| Step: 6
Training loss: 0.18073100319038268
Validation loss: 2.2836281684055275

Epoch: 5| Step: 7
Training loss: 0.3347385769469784
Validation loss: 2.2455990505218426

Epoch: 5| Step: 8
Training loss: 0.11543683677001589
Validation loss: 2.2769959911266273

Epoch: 5| Step: 9
Training loss: 0.3412150417140002
Validation loss: 2.259104684839529

Epoch: 5| Step: 10
Training loss: 0.08047219750509832
Validation loss: 2.2933569099520517

Epoch: 584| Step: 0
Training loss: 0.11837705222086038
Validation loss: 2.2613770987044006

Epoch: 5| Step: 1
Training loss: 0.358500349226852
Validation loss: 2.2444823112132606

Epoch: 5| Step: 2
Training loss: 0.21560658362427185
Validation loss: 2.2631599761767407

Epoch: 5| Step: 3
Training loss: 0.11475854765491451
Validation loss: 2.296888437204607

Epoch: 5| Step: 4
Training loss: 0.13334769516824274
Validation loss: 2.27471150028619

Epoch: 5| Step: 5
Training loss: 0.15684542455043415
Validation loss: 2.2787317622751764

Epoch: 5| Step: 6
Training loss: 0.23928982267533325
Validation loss: 2.2790884907950932

Epoch: 5| Step: 7
Training loss: 0.1215654729575216
Validation loss: 2.2585142963625686

Epoch: 5| Step: 8
Training loss: 0.10508264847417431
Validation loss: 2.280719784804069

Epoch: 5| Step: 9
Training loss: 0.1418602651977171
Validation loss: 2.261423119305171

Epoch: 5| Step: 10
Training loss: 0.24445381675273664
Validation loss: 2.2544034114304723

Epoch: 585| Step: 0
Training loss: 0.1266638026598634
Validation loss: 2.277940327970082

Epoch: 5| Step: 1
Training loss: 0.10582475712039985
Validation loss: 2.2569717174193724

Epoch: 5| Step: 2
Training loss: 0.21326537789333197
Validation loss: 2.2584469997935916

Epoch: 5| Step: 3
Training loss: 0.17641915498839006
Validation loss: 2.2538114632903317

Epoch: 5| Step: 4
Training loss: 0.21160325317101755
Validation loss: 2.275583242493399

Epoch: 5| Step: 5
Training loss: 0.27636478813936105
Validation loss: 2.2813980081495915

Epoch: 5| Step: 6
Training loss: 0.3905947482792703
Validation loss: 2.299994112045577

Epoch: 5| Step: 7
Training loss: 0.14210705472657328
Validation loss: 2.2926570353917017

Epoch: 5| Step: 8
Training loss: 0.11190724327122764
Validation loss: 2.3128409407343242

Epoch: 5| Step: 9
Training loss: 0.14611874407379857
Validation loss: 2.301802780732116

Epoch: 5| Step: 10
Training loss: 0.10445159052176065
Validation loss: 2.2867399912056987

Epoch: 586| Step: 0
Training loss: 0.10645938482794833
Validation loss: 2.279825121538459

Epoch: 5| Step: 1
Training loss: 0.2712620710069029
Validation loss: 2.314232159488086

Epoch: 5| Step: 2
Training loss: 0.13749760441427197
Validation loss: 2.290174073317836

Epoch: 5| Step: 3
Training loss: 0.33415637132825643
Validation loss: 2.2920359592699007

Epoch: 5| Step: 4
Training loss: 0.22275852899299364
Validation loss: 2.2396820878398414

Epoch: 5| Step: 5
Training loss: 0.13415637028864477
Validation loss: 2.2504733908194616

Epoch: 5| Step: 6
Training loss: 0.10215543099381685
Validation loss: 2.261747615328998

Epoch: 5| Step: 7
Training loss: 0.16886161649410586
Validation loss: 2.247979874057602

Epoch: 5| Step: 8
Training loss: 0.165560187398154
Validation loss: 2.2817841164590473

Epoch: 5| Step: 9
Training loss: 0.12494104828096733
Validation loss: 2.2640006007629956

Epoch: 5| Step: 10
Training loss: 0.24077806744214317
Validation loss: 2.2536137079065934

Epoch: 587| Step: 0
Training loss: 0.16282339149332486
Validation loss: 2.252694524123702

Epoch: 5| Step: 1
Training loss: 0.23839236623479795
Validation loss: 2.279652310669206

Epoch: 5| Step: 2
Training loss: 0.13430516734993625
Validation loss: 2.2793220321588947

Epoch: 5| Step: 3
Training loss: 0.14588131427501166
Validation loss: 2.2967428367907723

Epoch: 5| Step: 4
Training loss: 0.27399110610129385
Validation loss: 2.343305535507

Epoch: 5| Step: 5
Training loss: 0.1038579902220878
Validation loss: 2.28123701796783

Epoch: 5| Step: 6
Training loss: 0.11870433312007536
Validation loss: 2.302839291379427

Epoch: 5| Step: 7
Training loss: 0.3737648251632872
Validation loss: 2.2748590170777305

Epoch: 5| Step: 8
Training loss: 0.1475392569413645
Validation loss: 2.2465747148874233

Epoch: 5| Step: 9
Training loss: 0.15798388701982188
Validation loss: 2.308944152243754

Epoch: 5| Step: 10
Training loss: 0.20852127637811962
Validation loss: 2.274695242994524

Epoch: 588| Step: 0
Training loss: 0.11574332137233184
Validation loss: 2.3140998578688294

Epoch: 5| Step: 1
Training loss: 0.19459191912109378
Validation loss: 2.3032481158423765

Epoch: 5| Step: 2
Training loss: 0.1427162428970424
Validation loss: 2.308209589550474

Epoch: 5| Step: 3
Training loss: 0.37889820758897
Validation loss: 2.3249881906393624

Epoch: 5| Step: 4
Training loss: 0.2637736936295169
Validation loss: 2.3162825472751383

Epoch: 5| Step: 5
Training loss: 0.13416399246220212
Validation loss: 2.3052365774710477

Epoch: 5| Step: 6
Training loss: 0.1239177110537824
Validation loss: 2.296535156235104

Epoch: 5| Step: 7
Training loss: 0.2339249661257753
Validation loss: 2.2913594469741443

Epoch: 5| Step: 8
Training loss: 0.1289142981820044
Validation loss: 2.2803436391457477

Epoch: 5| Step: 9
Training loss: 0.12143061681172296
Validation loss: 2.2708400509085696

Epoch: 5| Step: 10
Training loss: 0.17486781573416016
Validation loss: 2.2839231830157765

Epoch: 589| Step: 0
Training loss: 0.11823849264899361
Validation loss: 2.2614841094705023

Epoch: 5| Step: 1
Training loss: 0.14106650055547915
Validation loss: 2.253751711821287

Epoch: 5| Step: 2
Training loss: 0.19303913763233846
Validation loss: 2.248306996766642

Epoch: 5| Step: 3
Training loss: 0.3627173446348034
Validation loss: 2.28998925989053

Epoch: 5| Step: 4
Training loss: 0.10644591620037827
Validation loss: 2.287516221920749

Epoch: 5| Step: 5
Training loss: 0.12355819306419127
Validation loss: 2.286750969870575

Epoch: 5| Step: 6
Training loss: 0.24499609794477414
Validation loss: 2.321305833916658

Epoch: 5| Step: 7
Training loss: 0.1356146027605302
Validation loss: 2.2721807774622684

Epoch: 5| Step: 8
Training loss: 0.10958400834516882
Validation loss: 2.296380247643126

Epoch: 5| Step: 9
Training loss: 0.21124305493602658
Validation loss: 2.3164013062234323

Epoch: 5| Step: 10
Training loss: 0.2445879081436864
Validation loss: 2.2749663830869395

Epoch: 590| Step: 0
Training loss: 0.20654155288824236
Validation loss: 2.281377873901373

Epoch: 5| Step: 1
Training loss: 0.14878624805002882
Validation loss: 2.2907174095563683

Epoch: 5| Step: 2
Training loss: 0.16905142918862368
Validation loss: 2.284271195050786

Epoch: 5| Step: 3
Training loss: 0.24138765386910657
Validation loss: 2.2554584387129415

Epoch: 5| Step: 4
Training loss: 0.35129483948127915
Validation loss: 2.2409772739277853

Epoch: 5| Step: 5
Training loss: 0.23323459540695518
Validation loss: 2.2358039550819035

Epoch: 5| Step: 6
Training loss: 0.1558112839908791
Validation loss: 2.2509340548770944

Epoch: 5| Step: 7
Training loss: 0.15350588119684322
Validation loss: 2.2513901165986048

Epoch: 5| Step: 8
Training loss: 0.12644720506827942
Validation loss: 2.2690298123663015

Epoch: 5| Step: 9
Training loss: 0.11646753320526618
Validation loss: 2.2281988912712487

Epoch: 5| Step: 10
Training loss: 0.19162974641250546
Validation loss: 2.19870332668883

Epoch: 591| Step: 0
Training loss: 0.2681194037629256
Validation loss: 2.2464729024022145

Epoch: 5| Step: 1
Training loss: 0.13182433041940217
Validation loss: 2.2956101723824545

Epoch: 5| Step: 2
Training loss: 0.08387303734833869
Validation loss: 2.2742642465878204

Epoch: 5| Step: 3
Training loss: 0.35125069036110473
Validation loss: 2.308068125752289

Epoch: 5| Step: 4
Training loss: 0.1374534620294128
Validation loss: 2.3232956877859796

Epoch: 5| Step: 5
Training loss: 0.23912567849668687
Validation loss: 2.279687009737676

Epoch: 5| Step: 6
Training loss: 0.1437592249481086
Validation loss: 2.30423499174082

Epoch: 5| Step: 7
Training loss: 0.14396304483289898
Validation loss: 2.260133199174147

Epoch: 5| Step: 8
Training loss: 0.19916163355028874
Validation loss: 2.2597485636124666

Epoch: 5| Step: 9
Training loss: 0.24529891097948286
Validation loss: 2.2832221826521346

Epoch: 5| Step: 10
Training loss: 0.24780360630426956
Validation loss: 2.2613927250678447

Epoch: 592| Step: 0
Training loss: 0.1851308173406027
Validation loss: 2.280850893475067

Epoch: 5| Step: 1
Training loss: 0.13789897763725292
Validation loss: 2.254974074181363

Epoch: 5| Step: 2
Training loss: 0.16473060200410322
Validation loss: 2.3076215940674873

Epoch: 5| Step: 3
Training loss: 0.354588477138112
Validation loss: 2.3391762874589004

Epoch: 5| Step: 4
Training loss: 0.26574308911952405
Validation loss: 2.3221340162331714

Epoch: 5| Step: 5
Training loss: 0.2495691043085936
Validation loss: 2.299436491868012

Epoch: 5| Step: 6
Training loss: 0.181001389527783
Validation loss: 2.251961036919178

Epoch: 5| Step: 7
Training loss: 0.23832825681697387
Validation loss: 2.2805549775395573

Epoch: 5| Step: 8
Training loss: 0.14195009287113605
Validation loss: 2.261150415864394

Epoch: 5| Step: 9
Training loss: 0.19548879296529956
Validation loss: 2.2793412645391755

Epoch: 5| Step: 10
Training loss: 0.2847472092020323
Validation loss: 2.2537839602599568

Epoch: 593| Step: 0
Training loss: 0.3659763245872419
Validation loss: 2.2619715125783446

Epoch: 5| Step: 1
Training loss: 0.2276706806052309
Validation loss: 2.2697039916807076

Epoch: 5| Step: 2
Training loss: 0.16880444072366907
Validation loss: 2.2648687167586483

Epoch: 5| Step: 3
Training loss: 0.21018426240474397
Validation loss: 2.271881557764944

Epoch: 5| Step: 4
Training loss: 0.11763588636655792
Validation loss: 2.2518625787898547

Epoch: 5| Step: 5
Training loss: 0.1347917724895897
Validation loss: 2.30322700722395

Epoch: 5| Step: 6
Training loss: 0.17046041212136878
Validation loss: 2.2836755277731915

Epoch: 5| Step: 7
Training loss: 0.31258016988461523
Validation loss: 2.313828461726501

Epoch: 5| Step: 8
Training loss: 0.2303534154508553
Validation loss: 2.2542962777753357

Epoch: 5| Step: 9
Training loss: 0.20756227838388963
Validation loss: 2.2621180576664677

Epoch: 5| Step: 10
Training loss: 0.2353851959129118
Validation loss: 2.2581840374367044

Epoch: 594| Step: 0
Training loss: 0.20969631463638497
Validation loss: 2.285818789552126

Epoch: 5| Step: 1
Training loss: 0.16101730136655756
Validation loss: 2.2776411175426894

Epoch: 5| Step: 2
Training loss: 0.3735583329334512
Validation loss: 2.2921464319027947

Epoch: 5| Step: 3
Training loss: 0.17029939019204046
Validation loss: 2.3109716932037982

Epoch: 5| Step: 4
Training loss: 0.23837168337620557
Validation loss: 2.3062350531235243

Epoch: 5| Step: 5
Training loss: 0.14526264607043268
Validation loss: 2.3430863981216854

Epoch: 5| Step: 6
Training loss: 0.3558287003295198
Validation loss: 2.3290470414700484

Epoch: 5| Step: 7
Training loss: 0.11885048761811406
Validation loss: 2.328759087731255

Epoch: 5| Step: 8
Training loss: 0.1298690731267619
Validation loss: 2.275240191140046

Epoch: 5| Step: 9
Training loss: 0.22598675216081798
Validation loss: 2.214105572228963

Epoch: 5| Step: 10
Training loss: 0.21616904965158046
Validation loss: 2.2652696443261933

Epoch: 595| Step: 0
Training loss: 0.3166847180985324
Validation loss: 2.217046785003087

Epoch: 5| Step: 1
Training loss: 0.14773333570819827
Validation loss: 2.2462263815564274

Epoch: 5| Step: 2
Training loss: 0.11604007212909057
Validation loss: 2.2610963028687787

Epoch: 5| Step: 3
Training loss: 0.1299821215839038
Validation loss: 2.2574771939121385

Epoch: 5| Step: 4
Training loss: 0.20878657668715234
Validation loss: 2.266536149517518

Epoch: 5| Step: 5
Training loss: 0.17486450301405762
Validation loss: 2.2875788911246864

Epoch: 5| Step: 6
Training loss: 0.3748758428398139
Validation loss: 2.2929500103829517

Epoch: 5| Step: 7
Training loss: 0.325873906980583
Validation loss: 2.2917051403436868

Epoch: 5| Step: 8
Training loss: 0.20055671263559408
Validation loss: 2.2571354446386955

Epoch: 5| Step: 9
Training loss: 0.18358254905783664
Validation loss: 2.234625739960098

Epoch: 5| Step: 10
Training loss: 0.20127881550186486
Validation loss: 2.274159252507714

Epoch: 596| Step: 0
Training loss: 0.3436717356104654
Validation loss: 2.2136780411020305

Epoch: 5| Step: 1
Training loss: 0.1707728496677343
Validation loss: 2.246370671033668

Epoch: 5| Step: 2
Training loss: 0.18620964938102938
Validation loss: 2.223096089366987

Epoch: 5| Step: 3
Training loss: 0.22475386408803413
Validation loss: 2.2428468953243517

Epoch: 5| Step: 4
Training loss: 0.1972940443359581
Validation loss: 2.2652821203228637

Epoch: 5| Step: 5
Training loss: 0.2581110295170464
Validation loss: 2.332155727241996

Epoch: 5| Step: 6
Training loss: 0.15587852546808853
Validation loss: 2.328589148184967

Epoch: 5| Step: 7
Training loss: 0.1836750378127479
Validation loss: 2.35454437452129

Epoch: 5| Step: 8
Training loss: 0.25593533735095153
Validation loss: 2.3313523363745547

Epoch: 5| Step: 9
Training loss: 0.2736751068995957
Validation loss: 2.3230001700459084

Epoch: 5| Step: 10
Training loss: 0.21154005032973094
Validation loss: 2.2829900744791973

Epoch: 597| Step: 0
Training loss: 0.16832138903086138
Validation loss: 2.290478963703847

Epoch: 5| Step: 1
Training loss: 0.2161985767694142
Validation loss: 2.297476247737695

Epoch: 5| Step: 2
Training loss: 0.1653003148471842
Validation loss: 2.2811351741043615

Epoch: 5| Step: 3
Training loss: 0.16601662355010474
Validation loss: 2.3002230510656556

Epoch: 5| Step: 4
Training loss: 0.26577122253932106
Validation loss: 2.347050687381056

Epoch: 5| Step: 5
Training loss: 0.24422383988312146
Validation loss: 2.344822872808449

Epoch: 5| Step: 6
Training loss: 0.16953368075337752
Validation loss: 2.359959896101291

Epoch: 5| Step: 7
Training loss: 0.24270418641773045
Validation loss: 2.338375710986941

Epoch: 5| Step: 8
Training loss: 0.38597640640661773
Validation loss: 2.3322415974907

Epoch: 5| Step: 9
Training loss: 0.2469635231317387
Validation loss: 2.29443446917828

Epoch: 5| Step: 10
Training loss: 0.11846104652033972
Validation loss: 2.2726353967391995

Epoch: 598| Step: 0
Training loss: 0.18327602326988554
Validation loss: 2.254019778832725

Epoch: 5| Step: 1
Training loss: 0.4544226710880461
Validation loss: 2.275413157956082

Epoch: 5| Step: 2
Training loss: 0.16761186300127223
Validation loss: 2.2380277351258213

Epoch: 5| Step: 3
Training loss: 0.25393343559860054
Validation loss: 2.2371664832036844

Epoch: 5| Step: 4
Training loss: 0.2731356862463298
Validation loss: 2.249158442088519

Epoch: 5| Step: 5
Training loss: 0.1696526049111533
Validation loss: 2.3165234510474835

Epoch: 5| Step: 6
Training loss: 0.22030147362569855
Validation loss: 2.3386020513288392

Epoch: 5| Step: 7
Training loss: 0.1931064473502873
Validation loss: 2.324917453672642

Epoch: 5| Step: 8
Training loss: 0.14644342485881562
Validation loss: 2.315964082801362

Epoch: 5| Step: 9
Training loss: 0.15119361154386646
Validation loss: 2.2993178729764456

Epoch: 5| Step: 10
Training loss: 0.14436519594675185
Validation loss: 2.3211936709684933

Epoch: 599| Step: 0
Training loss: 0.10744212566579381
Validation loss: 2.2809674060854985

Epoch: 5| Step: 1
Training loss: 0.26288144349251863
Validation loss: 2.3060431474041962

Epoch: 5| Step: 2
Training loss: 0.22666451196458656
Validation loss: 2.2900312451953058

Epoch: 5| Step: 3
Training loss: 0.26217746390320484
Validation loss: 2.2819916635879625

Epoch: 5| Step: 4
Training loss: 0.3493836276092919
Validation loss: 2.2940783707968593

Epoch: 5| Step: 5
Training loss: 0.160941004020544
Validation loss: 2.3014753796645366

Epoch: 5| Step: 6
Training loss: 0.20908379195432764
Validation loss: 2.287196386119066

Epoch: 5| Step: 7
Training loss: 0.15308541934662287
Validation loss: 2.3501773748088435

Epoch: 5| Step: 8
Training loss: 0.2694628670231754
Validation loss: 2.3323415686245292

Epoch: 5| Step: 9
Training loss: 0.3316739347554499
Validation loss: 2.334672209358243

Epoch: 5| Step: 10
Training loss: 0.2775653034773841
Validation loss: 2.2996542086154523

Epoch: 600| Step: 0
Training loss: 0.15079526218472403
Validation loss: 2.263574703192489

Epoch: 5| Step: 1
Training loss: 0.12350862391522209
Validation loss: 2.2677636078060184

Epoch: 5| Step: 2
Training loss: 0.23063367664483714
Validation loss: 2.2106708038337803

Epoch: 5| Step: 3
Training loss: 0.22902659810094436
Validation loss: 2.2443858934503513

Epoch: 5| Step: 4
Training loss: 0.25535204143458834
Validation loss: 2.269230438223627

Epoch: 5| Step: 5
Training loss: 0.2431735224588041
Validation loss: 2.2653379672204785

Epoch: 5| Step: 6
Training loss: 0.2897148375178584
Validation loss: 2.3140226172211547

Epoch: 5| Step: 7
Training loss: 0.23602189171561322
Validation loss: 2.2996001192909117

Epoch: 5| Step: 8
Training loss: 0.25792727660930426
Validation loss: 2.2417682514289123

Epoch: 5| Step: 9
Training loss: 0.44862405970217933
Validation loss: 2.2365474172301028

Epoch: 5| Step: 10
Training loss: 0.2507075786819077
Validation loss: 2.181298464980548

Testing loss: 2.5201071541827
