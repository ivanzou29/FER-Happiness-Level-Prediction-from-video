Epoch: 1| Step: 0
Training loss: 5.577149377982105
Validation loss: 5.759267688598755

Epoch: 5| Step: 1
Training loss: 5.789228552780425
Validation loss: 5.733997478398754

Epoch: 5| Step: 2
Training loss: 4.8269148115437455
Validation loss: 5.711625791222009

Epoch: 5| Step: 3
Training loss: 6.394653542851675
Validation loss: 5.685881110115978

Epoch: 5| Step: 4
Training loss: 6.388724121327943
Validation loss: 5.657070015488627

Epoch: 5| Step: 5
Training loss: 6.030309416011091
Validation loss: 5.62435956839003

Epoch: 5| Step: 6
Training loss: 4.6466272243173945
Validation loss: 5.58682295039369

Epoch: 5| Step: 7
Training loss: 5.317368016077898
Validation loss: 5.544042410034166

Epoch: 5| Step: 8
Training loss: 5.660113790601616
Validation loss: 5.495147421402629

Epoch: 5| Step: 9
Training loss: 5.034193042992711
Validation loss: 5.439637762139324

Epoch: 5| Step: 10
Training loss: 6.146755584658406
Validation loss: 5.377146016558855

Epoch: 2| Step: 0
Training loss: 4.897147901729244
Validation loss: 5.307435690858506

Epoch: 5| Step: 1
Training loss: 5.045971485433853
Validation loss: 5.233155051970507

Epoch: 5| Step: 2
Training loss: 5.678738395381812
Validation loss: 5.150829916236028

Epoch: 5| Step: 3
Training loss: 3.3007046843005914
Validation loss: 5.068319286148612

Epoch: 5| Step: 4
Training loss: 5.164305342188666
Validation loss: 4.9852466235825625

Epoch: 5| Step: 5
Training loss: 4.8619705578796415
Validation loss: 4.903971452098589

Epoch: 5| Step: 6
Training loss: 6.060947494714948
Validation loss: 4.8254427902682355

Epoch: 5| Step: 7
Training loss: 4.555544633516281
Validation loss: 4.745098557901103

Epoch: 5| Step: 8
Training loss: 4.918216956603944
Validation loss: 4.66546463464488

Epoch: 5| Step: 9
Training loss: 4.731554658017967
Validation loss: 4.5838701189267566

Epoch: 5| Step: 10
Training loss: 4.903186205937194
Validation loss: 4.4976451185807464

Epoch: 3| Step: 0
Training loss: 3.196064084180414
Validation loss: 4.409801261378041

Epoch: 5| Step: 1
Training loss: 4.498528981843763
Validation loss: 4.33644313345464

Epoch: 5| Step: 2
Training loss: 5.3244784677345764
Validation loss: 4.2711356911627005

Epoch: 5| Step: 3
Training loss: 5.017715731375052
Validation loss: 4.214580137420404

Epoch: 5| Step: 4
Training loss: 4.3583409987042465
Validation loss: 4.1604952180966075

Epoch: 5| Step: 5
Training loss: 4.5867176854452865
Validation loss: 4.111329544211725

Epoch: 5| Step: 6
Training loss: 3.905601874942478
Validation loss: 4.065767779694927

Epoch: 5| Step: 7
Training loss: 3.4999974114544696
Validation loss: 4.023846962046347

Epoch: 5| Step: 8
Training loss: 3.87592353890256
Validation loss: 3.985472549967736

Epoch: 5| Step: 9
Training loss: 4.45607319998757
Validation loss: 3.9467286747252026

Epoch: 5| Step: 10
Training loss: 3.5731607841233197
Validation loss: 3.9098731910450586

Epoch: 4| Step: 0
Training loss: 4.271339250078108
Validation loss: 3.8787714136871956

Epoch: 5| Step: 1
Training loss: 4.096451894180852
Validation loss: 3.8467379286007217

Epoch: 5| Step: 2
Training loss: 3.320523890329657
Validation loss: 3.8214083290054104

Epoch: 5| Step: 3
Training loss: 4.308268364441662
Validation loss: 3.8010526605579953

Epoch: 5| Step: 4
Training loss: 2.6807988033930634
Validation loss: 3.7720466968153645

Epoch: 5| Step: 5
Training loss: 4.018059493524936
Validation loss: 3.7494085549626632

Epoch: 5| Step: 6
Training loss: 3.3788704048857356
Validation loss: 3.7216219691758594

Epoch: 5| Step: 7
Training loss: 3.8907887374556482
Validation loss: 3.699343910460101

Epoch: 5| Step: 8
Training loss: 4.5310618394392135
Validation loss: 3.6749803177166487

Epoch: 5| Step: 9
Training loss: 4.208455955808784
Validation loss: 3.652106654537158

Epoch: 5| Step: 10
Training loss: 4.162988005203681
Validation loss: 3.639338988388752

Epoch: 5| Step: 0
Training loss: 4.1849888346351065
Validation loss: 3.614161895064289

Epoch: 5| Step: 1
Training loss: 3.497950089828701
Validation loss: 3.5800962003746992

Epoch: 5| Step: 2
Training loss: 3.911496111013924
Validation loss: 3.5637688297712

Epoch: 5| Step: 3
Training loss: 4.0043261498570155
Validation loss: 3.5469469543157945

Epoch: 5| Step: 4
Training loss: 4.015683184844148
Validation loss: 3.5275625072175028

Epoch: 5| Step: 5
Training loss: 3.868184032547542
Validation loss: 3.5124132382934805

Epoch: 5| Step: 6
Training loss: 3.8338622405565683
Validation loss: 3.4958029396849564

Epoch: 5| Step: 7
Training loss: 3.723082254858255
Validation loss: 3.4853935605218536

Epoch: 5| Step: 8
Training loss: 3.6565788968824364
Validation loss: 3.477452568736341

Epoch: 5| Step: 9
Training loss: 3.3101063843194973
Validation loss: 3.4561370636821844

Epoch: 5| Step: 10
Training loss: 2.799407324053932
Validation loss: 3.4432664304390332

Epoch: 6| Step: 0
Training loss: 3.453486635077609
Validation loss: 3.443331081737208

Epoch: 5| Step: 1
Training loss: 4.247281719883512
Validation loss: 3.439163035428292

Epoch: 5| Step: 2
Training loss: 3.363174631730506
Validation loss: 3.410958747319767

Epoch: 5| Step: 3
Training loss: 2.8173720652145535
Validation loss: 3.4006612598541945

Epoch: 5| Step: 4
Training loss: 3.909242262138139
Validation loss: 3.3967783659978017

Epoch: 5| Step: 5
Training loss: 3.315861417950726
Validation loss: 3.3936599010919646

Epoch: 5| Step: 6
Training loss: 3.870890992183099
Validation loss: 3.3894716700655074

Epoch: 5| Step: 7
Training loss: 3.6733163155670963
Validation loss: 3.3748903670710133

Epoch: 5| Step: 8
Training loss: 4.129775086714251
Validation loss: 3.3625079515537504

Epoch: 5| Step: 9
Training loss: 3.3550848957810215
Validation loss: 3.3424566077306848

Epoch: 5| Step: 10
Training loss: 3.393758565143715
Validation loss: 3.3304220119517733

Epoch: 7| Step: 0
Training loss: 2.8738591791745947
Validation loss: 3.3330991467893423

Epoch: 5| Step: 1
Training loss: 3.5303619078212525
Validation loss: 3.3195088341775176

Epoch: 5| Step: 2
Training loss: 4.415193179992285
Validation loss: 3.3255171232514145

Epoch: 5| Step: 3
Training loss: 3.7155755863481246
Validation loss: 3.3103137456770533

Epoch: 5| Step: 4
Training loss: 3.4238829970110953
Validation loss: 3.3040483571768835

Epoch: 5| Step: 5
Training loss: 3.9606878137987627
Validation loss: 3.2947791496002963

Epoch: 5| Step: 6
Training loss: 3.01211517535267
Validation loss: 3.285615188458611

Epoch: 5| Step: 7
Training loss: 3.468900660086821
Validation loss: 3.2725023445434287

Epoch: 5| Step: 8
Training loss: 3.3340860629538502
Validation loss: 3.262429648196264

Epoch: 5| Step: 9
Training loss: 3.6993796163544013
Validation loss: 3.251141364304497

Epoch: 5| Step: 10
Training loss: 3.212775453862806
Validation loss: 3.2389432281772863

Epoch: 8| Step: 0
Training loss: 3.167333348684191
Validation loss: 3.2258343707178794

Epoch: 5| Step: 1
Training loss: 3.2697247774918967
Validation loss: 3.214341869928232

Epoch: 5| Step: 2
Training loss: 3.3159809176789805
Validation loss: 3.2129783602682926

Epoch: 5| Step: 3
Training loss: 3.3319428086701945
Validation loss: 3.192159534513931

Epoch: 5| Step: 4
Training loss: 2.7769532177246696
Validation loss: 3.198278623822859

Epoch: 5| Step: 5
Training loss: 3.6422837043798384
Validation loss: 3.195656640031231

Epoch: 5| Step: 6
Training loss: 4.401708981937575
Validation loss: 3.180364919524894

Epoch: 5| Step: 7
Training loss: 3.2864563826581885
Validation loss: 3.166925876826523

Epoch: 5| Step: 8
Training loss: 3.3713943152961843
Validation loss: 3.164035074977803

Epoch: 5| Step: 9
Training loss: 2.8945777055356086
Validation loss: 3.1611762260091036

Epoch: 5| Step: 10
Training loss: 4.270028660340799
Validation loss: 3.156040189144165

Epoch: 9| Step: 0
Training loss: 3.7844499651463606
Validation loss: 3.148100695891488

Epoch: 5| Step: 1
Training loss: 3.517843673824116
Validation loss: 3.1382560058071185

Epoch: 5| Step: 2
Training loss: 3.365699386128845
Validation loss: 3.127302602893127

Epoch: 5| Step: 3
Training loss: 3.069229828095462
Validation loss: 3.117889248822017

Epoch: 5| Step: 4
Training loss: 2.479232648297361
Validation loss: 3.1162127556195895

Epoch: 5| Step: 5
Training loss: 3.953471775450619
Validation loss: 3.114241121358819

Epoch: 5| Step: 6
Training loss: 3.0163301424207813
Validation loss: 3.1065457637839637

Epoch: 5| Step: 7
Training loss: 3.6336616426111275
Validation loss: 3.0975174771338523

Epoch: 5| Step: 8
Training loss: 3.6182912374326417
Validation loss: 3.090784629915569

Epoch: 5| Step: 9
Training loss: 3.181264425368663
Validation loss: 3.084429510852779

Epoch: 5| Step: 10
Training loss: 3.360847753570617
Validation loss: 3.07870127037815

Epoch: 10| Step: 0
Training loss: 3.2305242494476856
Validation loss: 3.078788689521414

Epoch: 5| Step: 1
Training loss: 3.270643840249308
Validation loss: 3.0716102310487363

Epoch: 5| Step: 2
Training loss: 3.302665939840217
Validation loss: 3.06523573840096

Epoch: 5| Step: 3
Training loss: 3.548361714543596
Validation loss: 3.066059883829232

Epoch: 5| Step: 4
Training loss: 3.8014640547630805
Validation loss: 3.0643883910863514

Epoch: 5| Step: 5
Training loss: 3.3691737430437496
Validation loss: 3.060135824321874

Epoch: 5| Step: 6
Training loss: 3.2309093244102405
Validation loss: 3.050923303239599

Epoch: 5| Step: 7
Training loss: 3.39703859498539
Validation loss: 3.0453451627605697

Epoch: 5| Step: 8
Training loss: 2.749875672737794
Validation loss: 3.041679339031995

Epoch: 5| Step: 9
Training loss: 3.075581385538322
Validation loss: 3.051840905286792

Epoch: 5| Step: 10
Training loss: 3.776366177349878
Validation loss: 3.056024886438044

Epoch: 11| Step: 0
Training loss: 3.285258578454233
Validation loss: 3.0343123768292815

Epoch: 5| Step: 1
Training loss: 2.7879185828439557
Validation loss: 3.029610496947548

Epoch: 5| Step: 2
Training loss: 3.357243345084296
Validation loss: 3.031123578270964

Epoch: 5| Step: 3
Training loss: 3.1420196928479207
Validation loss: 3.028813968081612

Epoch: 5| Step: 4
Training loss: 3.59769866288789
Validation loss: 3.0277070277450386

Epoch: 5| Step: 5
Training loss: 2.5382430881814546
Validation loss: 3.02543648459198

Epoch: 5| Step: 6
Training loss: 3.5027742290218353
Validation loss: 3.027469316803308

Epoch: 5| Step: 7
Training loss: 3.821066565486131
Validation loss: 3.023691381074243

Epoch: 5| Step: 8
Training loss: 3.227584713888568
Validation loss: 3.0233983630365193

Epoch: 5| Step: 9
Training loss: 4.029876001689042
Validation loss: 3.0194991976491763

Epoch: 5| Step: 10
Training loss: 2.8746528415890085
Validation loss: 3.016796980339836

Epoch: 12| Step: 0
Training loss: 3.5142051711915587
Validation loss: 3.0117685988381235

Epoch: 5| Step: 1
Training loss: 3.3002620130617504
Validation loss: 3.0093119205452337

Epoch: 5| Step: 2
Training loss: 3.390639344637715
Validation loss: 3.0040575381388916

Epoch: 5| Step: 3
Training loss: 4.029419949344301
Validation loss: 3.0033637368388235

Epoch: 5| Step: 4
Training loss: 2.6958018867588525
Validation loss: 3.005429691790946

Epoch: 5| Step: 5
Training loss: 3.378931934060621
Validation loss: 3.009570606687806

Epoch: 5| Step: 6
Training loss: 2.7143633300755248
Validation loss: 3.003210745750425

Epoch: 5| Step: 7
Training loss: 3.1154316711132486
Validation loss: 3.0318425027297904

Epoch: 5| Step: 8
Training loss: 3.58714536715071
Validation loss: 2.9895256070922387

Epoch: 5| Step: 9
Training loss: 2.783782149199039
Validation loss: 2.9860456957611152

Epoch: 5| Step: 10
Training loss: 3.5822829695752523
Validation loss: 3.011016978875555

Epoch: 13| Step: 0
Training loss: 3.139143257374506
Validation loss: 3.011588089727769

Epoch: 5| Step: 1
Training loss: 3.3711172304186614
Validation loss: 3.001487843242687

Epoch: 5| Step: 2
Training loss: 3.227360144199313
Validation loss: 3.0011692571429127

Epoch: 5| Step: 3
Training loss: 3.383135703066575
Validation loss: 2.9939605549788957

Epoch: 5| Step: 4
Training loss: 3.4035076336092054
Validation loss: 2.9899165687495226

Epoch: 5| Step: 5
Training loss: 3.5925655901077262
Validation loss: 2.988542966074224

Epoch: 5| Step: 6
Training loss: 3.390427403471493
Validation loss: 2.9818107791812656

Epoch: 5| Step: 7
Training loss: 2.150106995160289
Validation loss: 2.9780970870059047

Epoch: 5| Step: 8
Training loss: 3.207445905412127
Validation loss: 2.9930684843024347

Epoch: 5| Step: 9
Training loss: 3.698387237839048
Validation loss: 2.9741794713796974

Epoch: 5| Step: 10
Training loss: 3.3322808193464692
Validation loss: 2.9580221039875942

Epoch: 14| Step: 0
Training loss: 3.590244607056875
Validation loss: 2.9557715087621728

Epoch: 5| Step: 1
Training loss: 2.768850482297058
Validation loss: 2.952157034630488

Epoch: 5| Step: 2
Training loss: 3.326087435391417
Validation loss: 2.950058873602216

Epoch: 5| Step: 3
Training loss: 2.955005995329634
Validation loss: 2.9535641447613763

Epoch: 5| Step: 4
Training loss: 3.451261958537096
Validation loss: 2.950007410180915

Epoch: 5| Step: 5
Training loss: 3.3348994549603477
Validation loss: 2.949980216414472

Epoch: 5| Step: 6
Training loss: 3.215213499440568
Validation loss: 2.944156872087597

Epoch: 5| Step: 7
Training loss: 2.989722927613682
Validation loss: 2.942474792139975

Epoch: 5| Step: 8
Training loss: 3.4622159710562275
Validation loss: 2.93417070370803

Epoch: 5| Step: 9
Training loss: 3.456558522807655
Validation loss: 2.9345899946420766

Epoch: 5| Step: 10
Training loss: 3.159992529703316
Validation loss: 2.9354407782187972

Epoch: 15| Step: 0
Training loss: 4.182172204287322
Validation loss: 2.9363319555007354

Epoch: 5| Step: 1
Training loss: 3.6864682063329544
Validation loss: 2.935658446886737

Epoch: 5| Step: 2
Training loss: 2.9599275904897375
Validation loss: 2.9270271474255334

Epoch: 5| Step: 3
Training loss: 3.7042030020878
Validation loss: 2.9294208600519553

Epoch: 5| Step: 4
Training loss: 3.699995432670455
Validation loss: 2.9326596007469257

Epoch: 5| Step: 5
Training loss: 3.153862531773338
Validation loss: 2.92009549265592

Epoch: 5| Step: 6
Training loss: 2.3820182101805165
Validation loss: 2.918060012696866

Epoch: 5| Step: 7
Training loss: 2.944002138261433
Validation loss: 2.9149179434383394

Epoch: 5| Step: 8
Training loss: 3.007868461583708
Validation loss: 2.9196700762895484

Epoch: 5| Step: 9
Training loss: 2.871462428497278
Validation loss: 2.973576302311947

Epoch: 5| Step: 10
Training loss: 2.386645226977216
Validation loss: 2.9903484947571224

Epoch: 16| Step: 0
Training loss: 3.873841389368614
Validation loss: 2.929433243195264

Epoch: 5| Step: 1
Training loss: 3.462644685552329
Validation loss: 2.915419947296145

Epoch: 5| Step: 2
Training loss: 3.563759698175556
Validation loss: 2.914432913704756

Epoch: 5| Step: 3
Training loss: 3.813085542333061
Validation loss: 2.9152299028893713

Epoch: 5| Step: 4
Training loss: 2.7060046430549343
Validation loss: 2.912980884883204

Epoch: 5| Step: 5
Training loss: 2.7797351097588465
Validation loss: 2.9169870162571923

Epoch: 5| Step: 6
Training loss: 2.7426511367144286
Validation loss: 2.9175282525675046

Epoch: 5| Step: 7
Training loss: 3.5972176449098927
Validation loss: 2.9121370262863

Epoch: 5| Step: 8
Training loss: 2.950770817284476
Validation loss: 2.9080965190105195

Epoch: 5| Step: 9
Training loss: 2.3488417185547523
Validation loss: 2.9188748633472477

Epoch: 5| Step: 10
Training loss: 3.17127842296092
Validation loss: 2.9052823815880666

Epoch: 17| Step: 0
Training loss: 3.2259142503877087
Validation loss: 2.9042207723772084

Epoch: 5| Step: 1
Training loss: 3.3873348181734495
Validation loss: 2.9018858729217563

Epoch: 5| Step: 2
Training loss: 3.018218353401323
Validation loss: 2.9006692754086316

Epoch: 5| Step: 3
Training loss: 3.3987071664740967
Validation loss: 2.902921259538029

Epoch: 5| Step: 4
Training loss: 3.191192881293018
Validation loss: 2.9028762357400115

Epoch: 5| Step: 5
Training loss: 3.6565838522793377
Validation loss: 2.9018637638803404

Epoch: 5| Step: 6
Training loss: 2.8803962154169147
Validation loss: 2.905671315132976

Epoch: 5| Step: 7
Training loss: 3.3610924877004598
Validation loss: 2.917769615250061

Epoch: 5| Step: 8
Training loss: 3.4442877597105466
Validation loss: 2.926431015583607

Epoch: 5| Step: 9
Training loss: 3.264146095764874
Validation loss: 2.9218504854605905

Epoch: 5| Step: 10
Training loss: 2.1977925800411726
Validation loss: 2.899626467859543

Epoch: 18| Step: 0
Training loss: 3.131876589276625
Validation loss: 2.8950010726603397

Epoch: 5| Step: 1
Training loss: 3.3087901808111564
Validation loss: 2.8928497347129465

Epoch: 5| Step: 2
Training loss: 2.5975161866022405
Validation loss: 2.8946642873398707

Epoch: 5| Step: 3
Training loss: 3.542005649874471
Validation loss: 2.896086550643053

Epoch: 5| Step: 4
Training loss: 3.411149027928106
Validation loss: 2.8959024338007566

Epoch: 5| Step: 5
Training loss: 3.4500746566876996
Validation loss: 2.8929768429924545

Epoch: 5| Step: 6
Training loss: 3.264215484583909
Validation loss: 2.892922336543823

Epoch: 5| Step: 7
Training loss: 3.5769116872412092
Validation loss: 2.887124578131594

Epoch: 5| Step: 8
Training loss: 3.116655423829171
Validation loss: 2.8867906463820163

Epoch: 5| Step: 9
Training loss: 2.711521932173824
Validation loss: 2.8858566087983286

Epoch: 5| Step: 10
Training loss: 2.9776269806530644
Validation loss: 2.88692000172117

Epoch: 19| Step: 0
Training loss: 3.5237266946260757
Validation loss: 2.8974335283866592

Epoch: 5| Step: 1
Training loss: 3.1195417419761577
Validation loss: 2.9002629718495

Epoch: 5| Step: 2
Training loss: 2.4948679700636096
Validation loss: 2.8989645147107184

Epoch: 5| Step: 3
Training loss: 3.597498655232807
Validation loss: 2.9048068216379925

Epoch: 5| Step: 4
Training loss: 2.7956187234556924
Validation loss: 2.915121692999203

Epoch: 5| Step: 5
Training loss: 2.9623638331027626
Validation loss: 2.928598907472272

Epoch: 5| Step: 6
Training loss: 3.253314895291011
Validation loss: 2.8875171080754884

Epoch: 5| Step: 7
Training loss: 3.170164050842311
Validation loss: 2.8792680160283526

Epoch: 5| Step: 8
Training loss: 3.3879413443918347
Validation loss: 2.884058245670178

Epoch: 5| Step: 9
Training loss: 3.5758549181546666
Validation loss: 2.881196145684

Epoch: 5| Step: 10
Training loss: 3.063042106137251
Validation loss: 2.881629676957464

Epoch: 20| Step: 0
Training loss: 3.219055605704062
Validation loss: 2.879983554342217

Epoch: 5| Step: 1
Training loss: 3.640621070695975
Validation loss: 2.8812303362998346

Epoch: 5| Step: 2
Training loss: 3.613969265155323
Validation loss: 2.8791363170143667

Epoch: 5| Step: 3
Training loss: 3.413862069747723
Validation loss: 2.8765596775508686

Epoch: 5| Step: 4
Training loss: 3.3236057599386784
Validation loss: 2.87801166604467

Epoch: 5| Step: 5
Training loss: 2.853423047244809
Validation loss: 2.875692365329858

Epoch: 5| Step: 6
Training loss: 2.7178067730618163
Validation loss: 2.8757359961262785

Epoch: 5| Step: 7
Training loss: 2.9659773879523637
Validation loss: 2.875598057003082

Epoch: 5| Step: 8
Training loss: 3.3571765892166114
Validation loss: 2.8783499705288307

Epoch: 5| Step: 9
Training loss: 3.112250910217461
Validation loss: 2.8792756857454123

Epoch: 5| Step: 10
Training loss: 2.5523763579220144
Validation loss: 2.874291056592596

Epoch: 21| Step: 0
Training loss: 3.75166563554024
Validation loss: 2.869391372986363

Epoch: 5| Step: 1
Training loss: 2.8950125722661553
Validation loss: 2.872259487962567

Epoch: 5| Step: 2
Training loss: 3.1114541008512564
Validation loss: 2.868565918342497

Epoch: 5| Step: 3
Training loss: 3.1902289582840937
Validation loss: 2.870826229344626

Epoch: 5| Step: 4
Training loss: 2.2388037692481464
Validation loss: 2.88014620566499

Epoch: 5| Step: 5
Training loss: 3.7667853755868363
Validation loss: 2.8987412305303573

Epoch: 5| Step: 6
Training loss: 3.6951611348739726
Validation loss: 2.873479785414115

Epoch: 5| Step: 7
Training loss: 2.7586449077381716
Validation loss: 2.8704293127407463

Epoch: 5| Step: 8
Training loss: 3.030450145155896
Validation loss: 2.8710029409665125

Epoch: 5| Step: 9
Training loss: 2.8134887652677056
Validation loss: 2.866637501373891

Epoch: 5| Step: 10
Training loss: 3.2982018860512987
Validation loss: 2.8661600338327613

Epoch: 22| Step: 0
Training loss: 3.41695325316308
Validation loss: 2.8640473214259554

Epoch: 5| Step: 1
Training loss: 3.2899089095656957
Validation loss: 2.869503082588044

Epoch: 5| Step: 2
Training loss: 3.50580170565382
Validation loss: 2.9003962129785106

Epoch: 5| Step: 3
Training loss: 2.6381465860553277
Validation loss: 2.8811205611479527

Epoch: 5| Step: 4
Training loss: 3.2658364259459103
Validation loss: 2.8757148155442467

Epoch: 5| Step: 5
Training loss: 3.1742755093336297
Validation loss: 2.889903178466122

Epoch: 5| Step: 6
Training loss: 3.019639895361076
Validation loss: 2.871135601480626

Epoch: 5| Step: 7
Training loss: 3.2977655301833435
Validation loss: 2.864979802920396

Epoch: 5| Step: 8
Training loss: 2.8373545739638453
Validation loss: 2.8637768221804847

Epoch: 5| Step: 9
Training loss: 3.1524614314503876
Validation loss: 2.8711034452469844

Epoch: 5| Step: 10
Training loss: 3.2957138258482344
Validation loss: 2.8730130929401674

Epoch: 23| Step: 0
Training loss: 3.356328532118859
Validation loss: 2.8560164974860203

Epoch: 5| Step: 1
Training loss: 2.7167290378111826
Validation loss: 2.8561668103305795

Epoch: 5| Step: 2
Training loss: 3.973630412493131
Validation loss: 2.85502355359641

Epoch: 5| Step: 3
Training loss: 3.262803314257434
Validation loss: 2.8599228294087253

Epoch: 5| Step: 4
Training loss: 3.3661810483786914
Validation loss: 2.866826483140216

Epoch: 5| Step: 5
Training loss: 3.220095455105366
Validation loss: 2.8693133626460097

Epoch: 5| Step: 6
Training loss: 3.18779469044092
Validation loss: 2.867267927725126

Epoch: 5| Step: 7
Training loss: 2.614222791720043
Validation loss: 2.8672627875067733

Epoch: 5| Step: 8
Training loss: 2.9613249432157094
Validation loss: 2.87145784128904

Epoch: 5| Step: 9
Training loss: 2.9155207608183304
Validation loss: 2.875989952162783

Epoch: 5| Step: 10
Training loss: 3.02193190669983
Validation loss: 2.85139480077476

Epoch: 24| Step: 0
Training loss: 2.540747919428802
Validation loss: 2.8487324771454583

Epoch: 5| Step: 1
Training loss: 3.405528140791764
Validation loss: 2.8500476381976054

Epoch: 5| Step: 2
Training loss: 3.267923960423253
Validation loss: 2.850193408735366

Epoch: 5| Step: 3
Training loss: 2.970431684724583
Validation loss: 2.8488451759065443

Epoch: 5| Step: 4
Training loss: 2.7834171038906397
Validation loss: 2.8467784623481793

Epoch: 5| Step: 5
Training loss: 3.299584599561449
Validation loss: 2.849628476227004

Epoch: 5| Step: 6
Training loss: 2.871631307297521
Validation loss: 2.846077254413913

Epoch: 5| Step: 7
Training loss: 3.2695179782903425
Validation loss: 2.8467015298947387

Epoch: 5| Step: 8
Training loss: 3.5345380210887494
Validation loss: 2.8446396575674644

Epoch: 5| Step: 9
Training loss: 3.443185854914302
Validation loss: 2.845692463050237

Epoch: 5| Step: 10
Training loss: 3.132669117374223
Validation loss: 2.847833917737104

Epoch: 25| Step: 0
Training loss: 3.2012728662951457
Validation loss: 2.8917856109753886

Epoch: 5| Step: 1
Training loss: 2.9757191021339175
Validation loss: 2.8780541562543824

Epoch: 5| Step: 2
Training loss: 2.922033948195876
Validation loss: 2.859446032864677

Epoch: 5| Step: 3
Training loss: 3.3569640978727695
Validation loss: 2.8427807980611695

Epoch: 5| Step: 4
Training loss: 2.8429259059829857
Validation loss: 2.8448110784970915

Epoch: 5| Step: 5
Training loss: 3.0942670601988356
Validation loss: 2.8407721322719324

Epoch: 5| Step: 6
Training loss: 3.278736423314527
Validation loss: 2.8381279344215176

Epoch: 5| Step: 7
Training loss: 3.800026672671219
Validation loss: 2.839729104215585

Epoch: 5| Step: 8
Training loss: 3.292425108501752
Validation loss: 2.8367813605421364

Epoch: 5| Step: 9
Training loss: 2.8533809350698545
Validation loss: 2.8413172217379667

Epoch: 5| Step: 10
Training loss: 2.8225312949406227
Validation loss: 2.835853073014628

Epoch: 26| Step: 0
Training loss: 3.151935914990505
Validation loss: 2.8368928216032376

Epoch: 5| Step: 1
Training loss: 2.782142238872214
Validation loss: 2.8355883546656946

Epoch: 5| Step: 2
Training loss: 3.2215606861736608
Validation loss: 2.8356537299098576

Epoch: 5| Step: 3
Training loss: 3.116731156142668
Validation loss: 2.8320678400795445

Epoch: 5| Step: 4
Training loss: 3.1781882610795367
Validation loss: 2.833399448552326

Epoch: 5| Step: 5
Training loss: 3.032733043197787
Validation loss: 2.8370031270430993

Epoch: 5| Step: 6
Training loss: 3.133685744197045
Validation loss: 2.830885532521226

Epoch: 5| Step: 7
Training loss: 2.8504522801292334
Validation loss: 2.8305211096256593

Epoch: 5| Step: 8
Training loss: 3.4945633762041886
Validation loss: 2.827409677253948

Epoch: 5| Step: 9
Training loss: 3.001830337385956
Validation loss: 2.8301988457312506

Epoch: 5| Step: 10
Training loss: 3.4727979530284503
Validation loss: 2.8340142992244384

Epoch: 27| Step: 0
Training loss: 2.8848295934321824
Validation loss: 2.831658208519196

Epoch: 5| Step: 1
Training loss: 2.574226159416499
Validation loss: 2.8390159485412583

Epoch: 5| Step: 2
Training loss: 2.5822626376677915
Validation loss: 2.851539443379799

Epoch: 5| Step: 3
Training loss: 3.150694991448424
Validation loss: 2.8668916660355594

Epoch: 5| Step: 4
Training loss: 3.4023782266299993
Validation loss: 2.8292790570736046

Epoch: 5| Step: 5
Training loss: 3.133382769120272
Validation loss: 2.828998757711694

Epoch: 5| Step: 6
Training loss: 3.4346927624248167
Validation loss: 2.8443998044906285

Epoch: 5| Step: 7
Training loss: 3.395801723465723
Validation loss: 2.891696345381569

Epoch: 5| Step: 8
Training loss: 3.071933774492569
Validation loss: 2.845653160785445

Epoch: 5| Step: 9
Training loss: 3.222915028672561
Validation loss: 2.8218861037411207

Epoch: 5| Step: 10
Training loss: 3.676597772081322
Validation loss: 2.8222688042674267

Epoch: 28| Step: 0
Training loss: 2.818087558764114
Validation loss: 2.829171436233363

Epoch: 5| Step: 1
Training loss: 3.0886455001660194
Validation loss: 2.8475387271935295

Epoch: 5| Step: 2
Training loss: 2.525189243438884
Validation loss: 2.839797195314996

Epoch: 5| Step: 3
Training loss: 3.747743690715958
Validation loss: 2.811878289676691

Epoch: 5| Step: 4
Training loss: 3.550243240404809
Validation loss: 2.816454638603546

Epoch: 5| Step: 5
Training loss: 3.277766676702577
Validation loss: 2.8151605871786898

Epoch: 5| Step: 6
Training loss: 3.4130877537101747
Validation loss: 2.8139481784617697

Epoch: 5| Step: 7
Training loss: 2.405818751940283
Validation loss: 2.8161356535426134

Epoch: 5| Step: 8
Training loss: 2.523929795940776
Validation loss: 2.814387254555498

Epoch: 5| Step: 9
Training loss: 3.3823877645002383
Validation loss: 2.8211196963695597

Epoch: 5| Step: 10
Training loss: 3.412592032173163
Validation loss: 2.8239056695608116

Epoch: 29| Step: 0
Training loss: 3.0332873861445044
Validation loss: 2.817636536985001

Epoch: 5| Step: 1
Training loss: 3.707030864108581
Validation loss: 2.8132472167982043

Epoch: 5| Step: 2
Training loss: 3.199591050242819
Validation loss: 2.8134148507841386

Epoch: 5| Step: 3
Training loss: 3.5678250852912337
Validation loss: 2.811440768567694

Epoch: 5| Step: 4
Training loss: 3.011460823859433
Validation loss: 2.8114169041759642

Epoch: 5| Step: 5
Training loss: 3.2935327157839143
Validation loss: 2.810858232050983

Epoch: 5| Step: 6
Training loss: 2.5652193666463172
Validation loss: 2.809888491855279

Epoch: 5| Step: 7
Training loss: 2.8304726988353974
Validation loss: 2.812343253048461

Epoch: 5| Step: 8
Training loss: 2.8722881298099208
Validation loss: 2.8075555451391105

Epoch: 5| Step: 9
Training loss: 3.1609839262030213
Validation loss: 2.8069797206864644

Epoch: 5| Step: 10
Training loss: 3.0098598893719126
Validation loss: 2.8038142662686703

Epoch: 30| Step: 0
Training loss: 3.704543859946338
Validation loss: 2.803595493565736

Epoch: 5| Step: 1
Training loss: 3.4639947962909052
Validation loss: 2.802488385047696

Epoch: 5| Step: 2
Training loss: 2.9416422755569296
Validation loss: 2.798871711975663

Epoch: 5| Step: 3
Training loss: 2.5575653571972405
Validation loss: 2.799461515713922

Epoch: 5| Step: 4
Training loss: 3.041991717245148
Validation loss: 2.7950849030850393

Epoch: 5| Step: 5
Training loss: 3.2449141102196584
Validation loss: 2.79477419026292

Epoch: 5| Step: 6
Training loss: 2.769433626463931
Validation loss: 2.798108793316807

Epoch: 5| Step: 7
Training loss: 3.332745277667561
Validation loss: 2.7959183971413846

Epoch: 5| Step: 8
Training loss: 2.873555193550042
Validation loss: 2.7934109777787732

Epoch: 5| Step: 9
Training loss: 3.038101789726804
Validation loss: 2.7952592226686446

Epoch: 5| Step: 10
Training loss: 3.105968507104743
Validation loss: 2.8013956861042897

Epoch: 31| Step: 0
Training loss: 3.2622050944954775
Validation loss: 2.80488758879911

Epoch: 5| Step: 1
Training loss: 3.211034026168504
Validation loss: 2.803584736405381

Epoch: 5| Step: 2
Training loss: 2.833415273341706
Validation loss: 2.7928653678689153

Epoch: 5| Step: 3
Training loss: 3.6086538676085373
Validation loss: 2.7881920391631847

Epoch: 5| Step: 4
Training loss: 3.0333081366641808
Validation loss: 2.7878655378885355

Epoch: 5| Step: 5
Training loss: 3.082386455687708
Validation loss: 2.7882783883153137

Epoch: 5| Step: 6
Training loss: 2.954411302201866
Validation loss: 2.7886040193729933

Epoch: 5| Step: 7
Training loss: 3.182995324555947
Validation loss: 2.7908747239549925

Epoch: 5| Step: 8
Training loss: 3.097380694415476
Validation loss: 2.7928321681641672

Epoch: 5| Step: 9
Training loss: 3.262832250521615
Validation loss: 2.788360671013761

Epoch: 5| Step: 10
Training loss: 2.5637948091144476
Validation loss: 2.8023111421790743

Epoch: 32| Step: 0
Training loss: 3.191349771436447
Validation loss: 2.8436253991517537

Epoch: 5| Step: 1
Training loss: 2.8597335173762737
Validation loss: 2.841139187993065

Epoch: 5| Step: 2
Training loss: 3.1700367980169015
Validation loss: 2.788747735991707

Epoch: 5| Step: 3
Training loss: 3.337376590118721
Validation loss: 2.7854750994564577

Epoch: 5| Step: 4
Training loss: 2.5820380829736553
Validation loss: 2.7861426110856953

Epoch: 5| Step: 5
Training loss: 2.585951975064519
Validation loss: 2.7859906753035824

Epoch: 5| Step: 6
Training loss: 3.2082796629012473
Validation loss: 2.7876228506676712

Epoch: 5| Step: 7
Training loss: 3.7204107855543374
Validation loss: 2.799099365173028

Epoch: 5| Step: 8
Training loss: 3.545689456111074
Validation loss: 2.7873850877074675

Epoch: 5| Step: 9
Training loss: 2.546482266528934
Validation loss: 2.790279878423188

Epoch: 5| Step: 10
Training loss: 3.3549878238735595
Validation loss: 2.786529638240408

Epoch: 33| Step: 0
Training loss: 3.204377315692277
Validation loss: 2.7888937860299174

Epoch: 5| Step: 1
Training loss: 2.905303472796425
Validation loss: 2.788254866311451

Epoch: 5| Step: 2
Training loss: 3.102999183893173
Validation loss: 2.7928887161088216

Epoch: 5| Step: 3
Training loss: 2.4225645990882
Validation loss: 2.8022618524899965

Epoch: 5| Step: 4
Training loss: 2.972894927179041
Validation loss: 2.839348160254794

Epoch: 5| Step: 5
Training loss: 3.6105434623651784
Validation loss: 2.8743308788068167

Epoch: 5| Step: 6
Training loss: 2.998923744425311
Validation loss: 2.856123568148172

Epoch: 5| Step: 7
Training loss: 2.848541247832052
Validation loss: 2.8233003637474097

Epoch: 5| Step: 8
Training loss: 3.2205367082915117
Validation loss: 2.7763112929275

Epoch: 5| Step: 9
Training loss: 3.3018056149027784
Validation loss: 2.77092569995865

Epoch: 5| Step: 10
Training loss: 3.4767328456335593
Validation loss: 2.7754003645224974

Epoch: 34| Step: 0
Training loss: 3.2251829287671776
Validation loss: 2.7721626398581924

Epoch: 5| Step: 1
Training loss: 3.277408494639456
Validation loss: 2.775080579219497

Epoch: 5| Step: 2
Training loss: 2.6875455985525747
Validation loss: 2.7823954140061766

Epoch: 5| Step: 3
Training loss: 3.130314999168383
Validation loss: 2.7811239982988787

Epoch: 5| Step: 4
Training loss: 3.566816158073354
Validation loss: 2.776649801123305

Epoch: 5| Step: 5
Training loss: 3.032585714941828
Validation loss: 2.7728207702195706

Epoch: 5| Step: 6
Training loss: 2.966384909319223
Validation loss: 2.770844319726032

Epoch: 5| Step: 7
Training loss: 2.731428116985336
Validation loss: 2.7693915164461926

Epoch: 5| Step: 8
Training loss: 3.245944500555053
Validation loss: 2.7694799402641843

Epoch: 5| Step: 9
Training loss: 3.3072805489581016
Validation loss: 2.770600187818535

Epoch: 5| Step: 10
Training loss: 2.6556750404561376
Validation loss: 2.7871279957861534

Epoch: 35| Step: 0
Training loss: 2.976036686148174
Validation loss: 2.793692479304585

Epoch: 5| Step: 1
Training loss: 3.206468725644708
Validation loss: 2.809301252288124

Epoch: 5| Step: 2
Training loss: 3.7782249014672082
Validation loss: 2.787777521588522

Epoch: 5| Step: 3
Training loss: 2.92332920055322
Validation loss: 2.7675006231008688

Epoch: 5| Step: 4
Training loss: 3.6255370432852962
Validation loss: 2.7606526554685984

Epoch: 5| Step: 5
Training loss: 3.3662579662910086
Validation loss: 2.765269075876568

Epoch: 5| Step: 6
Training loss: 3.5329005342200595
Validation loss: 2.7702736676000255

Epoch: 5| Step: 7
Training loss: 2.1693922163825
Validation loss: 2.7680153949081108

Epoch: 5| Step: 8
Training loss: 2.58685369482343
Validation loss: 2.7686135832355125

Epoch: 5| Step: 9
Training loss: 2.302888019020772
Validation loss: 2.7686577681042257

Epoch: 5| Step: 10
Training loss: 3.310483498655906
Validation loss: 2.7663370398527642

Epoch: 36| Step: 0
Training loss: 3.41406808673742
Validation loss: 2.7628334695314787

Epoch: 5| Step: 1
Training loss: 3.0525862937932953
Validation loss: 2.7585781024376126

Epoch: 5| Step: 2
Training loss: 2.6036388828779775
Validation loss: 2.7568677266785495

Epoch: 5| Step: 3
Training loss: 3.0071545166058833
Validation loss: 2.756677537583613

Epoch: 5| Step: 4
Training loss: 3.028624666008271
Validation loss: 2.7576380639677858

Epoch: 5| Step: 5
Training loss: 2.9151504571994824
Validation loss: 2.757297756353021

Epoch: 5| Step: 6
Training loss: 3.603257183948878
Validation loss: 2.764636026575408

Epoch: 5| Step: 7
Training loss: 3.057319775289138
Validation loss: 2.770094133050139

Epoch: 5| Step: 8
Training loss: 2.881851987364236
Validation loss: 2.76759351840885

Epoch: 5| Step: 9
Training loss: 2.9740373608744313
Validation loss: 2.765066550359091

Epoch: 5| Step: 10
Training loss: 3.214361662194493
Validation loss: 2.7592617882733372

Epoch: 37| Step: 0
Training loss: 2.8770681489013867
Validation loss: 2.7584087042614893

Epoch: 5| Step: 1
Training loss: 2.270694506773384
Validation loss: 2.75273886683873

Epoch: 5| Step: 2
Training loss: 3.3416637436496446
Validation loss: 2.752574437161389

Epoch: 5| Step: 3
Training loss: 2.9380666308030823
Validation loss: 2.7540799338306443

Epoch: 5| Step: 4
Training loss: 3.167073039699897
Validation loss: 2.7667528284589875

Epoch: 5| Step: 5
Training loss: 2.991669054659118
Validation loss: 2.7642783094717047

Epoch: 5| Step: 6
Training loss: 2.8912517795977823
Validation loss: 2.760954753851696

Epoch: 5| Step: 7
Training loss: 3.2975545607673866
Validation loss: 2.754475566821149

Epoch: 5| Step: 8
Training loss: 3.63193519417675
Validation loss: 2.7461906591865106

Epoch: 5| Step: 9
Training loss: 2.9937019997334415
Validation loss: 2.746155020663153

Epoch: 5| Step: 10
Training loss: 3.2481342241994136
Validation loss: 2.7448618348419505

Epoch: 38| Step: 0
Training loss: 3.4766557659540305
Validation loss: 2.7456596069959076

Epoch: 5| Step: 1
Training loss: 3.255695194711369
Validation loss: 2.7443057944794034

Epoch: 5| Step: 2
Training loss: 3.0944696995701246
Validation loss: 2.7445914713137056

Epoch: 5| Step: 3
Training loss: 2.773717216033214
Validation loss: 2.744807564578323

Epoch: 5| Step: 4
Training loss: 3.239703667829309
Validation loss: 2.741704117968345

Epoch: 5| Step: 5
Training loss: 2.861951157372372
Validation loss: 2.7445775900639

Epoch: 5| Step: 6
Training loss: 2.534774210729122
Validation loss: 2.744997047246253

Epoch: 5| Step: 7
Training loss: 3.505173946096687
Validation loss: 2.74418838676035

Epoch: 5| Step: 8
Training loss: 3.022299540066751
Validation loss: 2.740186487250914

Epoch: 5| Step: 9
Training loss: 2.724880716355393
Validation loss: 2.7408433949497075

Epoch: 5| Step: 10
Training loss: 3.1796212154293473
Validation loss: 2.7398769789461226

Epoch: 39| Step: 0
Training loss: 2.516079405503448
Validation loss: 2.7400213393868507

Epoch: 5| Step: 1
Training loss: 3.0339106258437987
Validation loss: 2.7430940876560577

Epoch: 5| Step: 2
Training loss: 3.088696909579048
Validation loss: 2.7447533875771537

Epoch: 5| Step: 3
Training loss: 3.165852207717669
Validation loss: 2.7493267782782906

Epoch: 5| Step: 4
Training loss: 3.4505330710523947
Validation loss: 2.7579902629515476

Epoch: 5| Step: 5
Training loss: 3.1371285632818102
Validation loss: 2.745908726369172

Epoch: 5| Step: 6
Training loss: 3.1259472746402115
Validation loss: 2.73788999711697

Epoch: 5| Step: 7
Training loss: 3.104405711824471
Validation loss: 2.735982896439395

Epoch: 5| Step: 8
Training loss: 3.5057338341467608
Validation loss: 2.7379383098683765

Epoch: 5| Step: 9
Training loss: 2.831779689797187
Validation loss: 2.7340641305592075

Epoch: 5| Step: 10
Training loss: 2.543718781150807
Validation loss: 2.7345130672258007

Epoch: 40| Step: 0
Training loss: 2.3701594364281395
Validation loss: 2.7315187401935317

Epoch: 5| Step: 1
Training loss: 3.070910834719459
Validation loss: 2.735256365934501

Epoch: 5| Step: 2
Training loss: 3.4257781878015106
Validation loss: 2.733102732296833

Epoch: 5| Step: 3
Training loss: 3.341312553941921
Validation loss: 2.7329424230656447

Epoch: 5| Step: 4
Training loss: 2.907519483689605
Validation loss: 2.7303245835341787

Epoch: 5| Step: 5
Training loss: 3.107056640030154
Validation loss: 2.731181273723595

Epoch: 5| Step: 6
Training loss: 3.0865735907421508
Validation loss: 2.7289687004015284

Epoch: 5| Step: 7
Training loss: 3.122088792905502
Validation loss: 2.7306952618079827

Epoch: 5| Step: 8
Training loss: 3.6511484403501977
Validation loss: 2.7271680670982437

Epoch: 5| Step: 9
Training loss: 2.986400456173175
Validation loss: 2.728924290022792

Epoch: 5| Step: 10
Training loss: 2.239829494935236
Validation loss: 2.7272008572940987

Epoch: 41| Step: 0
Training loss: 3.097410868177438
Validation loss: 2.732469328393393

Epoch: 5| Step: 1
Training loss: 3.315650305619957
Validation loss: 2.7313781244544737

Epoch: 5| Step: 2
Training loss: 3.2865318294152086
Validation loss: 2.7474501264967865

Epoch: 5| Step: 3
Training loss: 3.2280188868937967
Validation loss: 2.7344633748529468

Epoch: 5| Step: 4
Training loss: 2.8483256323814268
Validation loss: 2.724941189204592

Epoch: 5| Step: 5
Training loss: 3.1108100684912543
Validation loss: 2.7198886987892235

Epoch: 5| Step: 6
Training loss: 2.7709241197288175
Validation loss: 2.7206490060484185

Epoch: 5| Step: 7
Training loss: 2.8676333379632997
Validation loss: 2.7224050301697895

Epoch: 5| Step: 8
Training loss: 2.716601520373499
Validation loss: 2.7234579174199447

Epoch: 5| Step: 9
Training loss: 3.0958790244782017
Validation loss: 2.721645990570763

Epoch: 5| Step: 10
Training loss: 3.223649675243687
Validation loss: 2.7217526835233867

Epoch: 42| Step: 0
Training loss: 2.311699290449896
Validation loss: 2.7182655322435894

Epoch: 5| Step: 1
Training loss: 2.9832584229624275
Validation loss: 2.717695793486068

Epoch: 5| Step: 2
Training loss: 3.638833059282219
Validation loss: 2.7231052127558604

Epoch: 5| Step: 3
Training loss: 3.615227516369777
Validation loss: 2.7178867842879724

Epoch: 5| Step: 4
Training loss: 3.0269334084300277
Validation loss: 2.7156984863020357

Epoch: 5| Step: 5
Training loss: 3.60303829515589
Validation loss: 2.718347262419897

Epoch: 5| Step: 6
Training loss: 2.8107109313545977
Validation loss: 2.714629478730693

Epoch: 5| Step: 7
Training loss: 2.7300824286344674
Validation loss: 2.713868680038437

Epoch: 5| Step: 8
Training loss: 3.05103366408379
Validation loss: 2.717605000821749

Epoch: 5| Step: 9
Training loss: 2.5465047368234575
Validation loss: 2.717307631652085

Epoch: 5| Step: 10
Training loss: 2.8129063630587536
Validation loss: 2.715595966060566

Epoch: 43| Step: 0
Training loss: 3.04069432084513
Validation loss: 2.7161527822800835

Epoch: 5| Step: 1
Training loss: 2.6757226199667006
Validation loss: 2.717425844159359

Epoch: 5| Step: 2
Training loss: 2.990533994368258
Validation loss: 2.7307184882003512

Epoch: 5| Step: 3
Training loss: 3.3992029489979796
Validation loss: 2.7402954464301343

Epoch: 5| Step: 4
Training loss: 3.050760149424869
Validation loss: 2.722663696126342

Epoch: 5| Step: 5
Training loss: 2.9452053222583294
Validation loss: 2.717425793215339

Epoch: 5| Step: 6
Training loss: 2.929570635689993
Validation loss: 2.717802953736495

Epoch: 5| Step: 7
Training loss: 2.7683839129704366
Validation loss: 2.7130341625168293

Epoch: 5| Step: 8
Training loss: 3.1216945714428066
Validation loss: 2.7151843810078327

Epoch: 5| Step: 9
Training loss: 3.056730791900928
Validation loss: 2.7086764529254

Epoch: 5| Step: 10
Training loss: 3.4042685809029303
Validation loss: 2.712220309767787

Epoch: 44| Step: 0
Training loss: 2.4352046233565647
Validation loss: 2.709693825079265

Epoch: 5| Step: 1
Training loss: 3.49594576218736
Validation loss: 2.7090248045569094

Epoch: 5| Step: 2
Training loss: 3.1945992492170507
Validation loss: 2.7081902862963134

Epoch: 5| Step: 3
Training loss: 2.895711351931268
Validation loss: 2.711493594642151

Epoch: 5| Step: 4
Training loss: 2.549026236014861
Validation loss: 2.7206401796026944

Epoch: 5| Step: 5
Training loss: 3.581387294514251
Validation loss: 2.735264204211082

Epoch: 5| Step: 6
Training loss: 3.5040121243236624
Validation loss: 2.7414006332269643

Epoch: 5| Step: 7
Training loss: 2.4713243027796405
Validation loss: 2.724123973010543

Epoch: 5| Step: 8
Training loss: 3.085122302581732
Validation loss: 2.712592231502209

Epoch: 5| Step: 9
Training loss: 3.1975298884756826
Validation loss: 2.7027568425354667

Epoch: 5| Step: 10
Training loss: 2.725046955369038
Validation loss: 2.7029958999175543

Epoch: 45| Step: 0
Training loss: 3.0258038548285824
Validation loss: 2.70277819950831

Epoch: 5| Step: 1
Training loss: 3.2509450272107476
Validation loss: 2.700983068899607

Epoch: 5| Step: 2
Training loss: 3.249617920937795
Validation loss: 2.704319354505021

Epoch: 5| Step: 3
Training loss: 2.66287992748626
Validation loss: 2.705061090733433

Epoch: 5| Step: 4
Training loss: 2.9602349487056068
Validation loss: 2.713344553037648

Epoch: 5| Step: 5
Training loss: 2.012165501440671
Validation loss: 2.719228061035491

Epoch: 5| Step: 6
Training loss: 3.6283714138468914
Validation loss: 2.7380447087752477

Epoch: 5| Step: 7
Training loss: 3.377675161838593
Validation loss: 2.7224821660410936

Epoch: 5| Step: 8
Training loss: 2.970554164986584
Validation loss: 2.7056326439096328

Epoch: 5| Step: 9
Training loss: 3.0029349275868915
Validation loss: 2.6970492271989093

Epoch: 5| Step: 10
Training loss: 2.973255152280329
Validation loss: 2.701455327022335

Epoch: 46| Step: 0
Training loss: 3.062096082559011
Validation loss: 2.70251670820171

Epoch: 5| Step: 1
Training loss: 3.4055793872004236
Validation loss: 2.700959937992003

Epoch: 5| Step: 2
Training loss: 3.263792408989434
Validation loss: 2.6998694340057012

Epoch: 5| Step: 3
Training loss: 2.8449104372753395
Validation loss: 2.6988308022596823

Epoch: 5| Step: 4
Training loss: 3.1801887885620874
Validation loss: 2.6955109297163937

Epoch: 5| Step: 5
Training loss: 2.7091957675384304
Validation loss: 2.697992789763674

Epoch: 5| Step: 6
Training loss: 2.831120880079491
Validation loss: 2.7030499587963583

Epoch: 5| Step: 7
Training loss: 3.0329534718975353
Validation loss: 2.7157915402796395

Epoch: 5| Step: 8
Training loss: 3.0232785205295447
Validation loss: 2.71070980817909

Epoch: 5| Step: 9
Training loss: 3.1042937353014355
Validation loss: 2.721846034424711

Epoch: 5| Step: 10
Training loss: 2.796456161763804
Validation loss: 2.7170853526266314

Epoch: 47| Step: 0
Training loss: 2.6729658253629713
Validation loss: 2.7130439917117406

Epoch: 5| Step: 1
Training loss: 2.807435116379045
Validation loss: 2.7025957198124013

Epoch: 5| Step: 2
Training loss: 2.6448628205059017
Validation loss: 2.702492941564222

Epoch: 5| Step: 3
Training loss: 3.0606369268221196
Validation loss: 2.7024501489474897

Epoch: 5| Step: 4
Training loss: 3.5319622300527285
Validation loss: 2.6921795633116075

Epoch: 5| Step: 5
Training loss: 3.437738028868249
Validation loss: 2.6896268847289955

Epoch: 5| Step: 6
Training loss: 2.8443793973174163
Validation loss: 2.693239041958473

Epoch: 5| Step: 7
Training loss: 2.3080791797113234
Validation loss: 2.6986625350824625

Epoch: 5| Step: 8
Training loss: 3.188361257247031
Validation loss: 2.7080613112483665

Epoch: 5| Step: 9
Training loss: 3.511783518634155
Validation loss: 2.70301332183191

Epoch: 5| Step: 10
Training loss: 2.9972394321887577
Validation loss: 2.6917598452857328

Epoch: 48| Step: 0
Training loss: 2.9624916366265945
Validation loss: 2.6879259093002714

Epoch: 5| Step: 1
Training loss: 2.9711968226763488
Validation loss: 2.680763906921462

Epoch: 5| Step: 2
Training loss: 2.9255234078849903
Validation loss: 2.6782216114472863

Epoch: 5| Step: 3
Training loss: 3.0233278870735054
Validation loss: 2.6816891691368805

Epoch: 5| Step: 4
Training loss: 3.0951605769640422
Validation loss: 2.680409761075886

Epoch: 5| Step: 5
Training loss: 3.043647817662856
Validation loss: 2.67752964523656

Epoch: 5| Step: 6
Training loss: 3.020695983570457
Validation loss: 2.6810917672301704

Epoch: 5| Step: 7
Training loss: 2.5430272530712843
Validation loss: 2.6800736665342995

Epoch: 5| Step: 8
Training loss: 2.762091669482568
Validation loss: 2.675468796524177

Epoch: 5| Step: 9
Training loss: 3.2833861164426636
Validation loss: 2.681942511888682

Epoch: 5| Step: 10
Training loss: 3.544238618942084
Validation loss: 2.676431151177475

Epoch: 49| Step: 0
Training loss: 2.8878217971960876
Validation loss: 2.6758550123720486

Epoch: 5| Step: 1
Training loss: 3.415072014693036
Validation loss: 2.6825484515596347

Epoch: 5| Step: 2
Training loss: 3.1721978986274864
Validation loss: 2.6770591583124417

Epoch: 5| Step: 3
Training loss: 2.8552256009677897
Validation loss: 2.6745748896474533

Epoch: 5| Step: 4
Training loss: 2.8951242434074613
Validation loss: 2.679481078647704

Epoch: 5| Step: 5
Training loss: 2.7435342899416164
Validation loss: 2.6780820263517624

Epoch: 5| Step: 6
Training loss: 2.5726076215914486
Validation loss: 2.68083214449081

Epoch: 5| Step: 7
Training loss: 2.424495141085655
Validation loss: 2.6795221207923894

Epoch: 5| Step: 8
Training loss: 3.5425712926093973
Validation loss: 2.6936444438319227

Epoch: 5| Step: 9
Training loss: 3.4014466742165843
Validation loss: 2.6894447804987593

Epoch: 5| Step: 10
Training loss: 3.0596173791464354
Validation loss: 2.6913469030221195

Epoch: 50| Step: 0
Training loss: 2.1104479286260864
Validation loss: 2.691934072284904

Epoch: 5| Step: 1
Training loss: 3.217604053536873
Validation loss: 2.693321529672433

Epoch: 5| Step: 2
Training loss: 3.246134586742981
Validation loss: 2.696203583925158

Epoch: 5| Step: 3
Training loss: 3.1189995186167225
Validation loss: 2.6812764074385385

Epoch: 5| Step: 4
Training loss: 2.9253843723331663
Validation loss: 2.6820011187441852

Epoch: 5| Step: 5
Training loss: 2.982826030654552
Validation loss: 2.6774039980004045

Epoch: 5| Step: 6
Training loss: 2.947447632768494
Validation loss: 2.6694104722917382

Epoch: 5| Step: 7
Training loss: 2.8690301031193415
Validation loss: 2.6700911151971773

Epoch: 5| Step: 8
Training loss: 2.9665913011500393
Validation loss: 2.6719851809038455

Epoch: 5| Step: 9
Training loss: 3.481237256011374
Validation loss: 2.669970367193154

Epoch: 5| Step: 10
Training loss: 3.047742045352954
Validation loss: 2.6729559207223494

Epoch: 51| Step: 0
Training loss: 3.465968761129419
Validation loss: 2.6694573949431035

Epoch: 5| Step: 1
Training loss: 2.459323899006019
Validation loss: 2.667272330409295

Epoch: 5| Step: 2
Training loss: 2.923960059074506
Validation loss: 2.6689662647740766

Epoch: 5| Step: 3
Training loss: 3.016674274273407
Validation loss: 2.6686000166939916

Epoch: 5| Step: 4
Training loss: 2.5146381977946857
Validation loss: 2.6739893138946647

Epoch: 5| Step: 5
Training loss: 3.0799169601046286
Validation loss: 2.6770950606966966

Epoch: 5| Step: 6
Training loss: 2.68420634156207
Validation loss: 2.6850627255579016

Epoch: 5| Step: 7
Training loss: 3.5522005541002737
Validation loss: 2.684396273212224

Epoch: 5| Step: 8
Training loss: 3.256209090958836
Validation loss: 2.6887087401460237

Epoch: 5| Step: 9
Training loss: 2.9641837892063725
Validation loss: 2.6874689642680245

Epoch: 5| Step: 10
Training loss: 2.899542667238781
Validation loss: 2.675508080617974

Epoch: 52| Step: 0
Training loss: 2.7668900694521827
Validation loss: 2.662950988700634

Epoch: 5| Step: 1
Training loss: 2.3167098619930293
Validation loss: 2.6619891923652497

Epoch: 5| Step: 2
Training loss: 3.198161228698606
Validation loss: 2.657745224241097

Epoch: 5| Step: 3
Training loss: 2.871885188004746
Validation loss: 2.662092420174182

Epoch: 5| Step: 4
Training loss: 2.5369116490985713
Validation loss: 2.6608124013293715

Epoch: 5| Step: 5
Training loss: 3.094414841856369
Validation loss: 2.6597569150106177

Epoch: 5| Step: 6
Training loss: 3.0589102122163325
Validation loss: 2.660601173951395

Epoch: 5| Step: 7
Training loss: 2.999494192080591
Validation loss: 2.6619741590422614

Epoch: 5| Step: 8
Training loss: 2.7204102456434858
Validation loss: 2.661911973536519

Epoch: 5| Step: 9
Training loss: 3.626695959683466
Validation loss: 2.6574541020508744

Epoch: 5| Step: 10
Training loss: 3.599217112503358
Validation loss: 2.657495276971575

Epoch: 53| Step: 0
Training loss: 3.0349334674311064
Validation loss: 2.6611652844259717

Epoch: 5| Step: 1
Training loss: 3.0695688060425192
Validation loss: 2.660730731622146

Epoch: 5| Step: 2
Training loss: 3.3840042376119714
Validation loss: 2.665501386727898

Epoch: 5| Step: 3
Training loss: 3.171808852835521
Validation loss: 2.6714466343830274

Epoch: 5| Step: 4
Training loss: 2.1515412816460664
Validation loss: 2.67406463853396

Epoch: 5| Step: 5
Training loss: 3.1358013402918825
Validation loss: 2.6738549805831684

Epoch: 5| Step: 6
Training loss: 3.119970776103166
Validation loss: 2.6697144796322694

Epoch: 5| Step: 7
Training loss: 2.8329255053646065
Validation loss: 2.717493287543369

Epoch: 5| Step: 8
Training loss: 3.4022418597060433
Validation loss: 2.7180869359804305

Epoch: 5| Step: 9
Training loss: 2.6648344560347588
Validation loss: 2.7191898007668196

Epoch: 5| Step: 10
Training loss: 2.97134575047194
Validation loss: 2.706170452943561

Epoch: 54| Step: 0
Training loss: 2.270834044943415
Validation loss: 2.7028064899338564

Epoch: 5| Step: 1
Training loss: 2.680170221474125
Validation loss: 2.7060539011810665

Epoch: 5| Step: 2
Training loss: 3.0058385936273995
Validation loss: 2.72784602164071

Epoch: 5| Step: 3
Training loss: 3.159592775108305
Validation loss: 2.741791727361972

Epoch: 5| Step: 4
Training loss: 2.8078919702490968
Validation loss: 2.749364141745981

Epoch: 5| Step: 5
Training loss: 3.16285935120623
Validation loss: 2.7634627089106147

Epoch: 5| Step: 6
Training loss: 3.5110192541052454
Validation loss: 2.7802635324754115

Epoch: 5| Step: 7
Training loss: 3.3124023998924823
Validation loss: 2.753680241687538

Epoch: 5| Step: 8
Training loss: 2.8914444045543926
Validation loss: 2.7427920017100993

Epoch: 5| Step: 9
Training loss: 3.1500762385270478
Validation loss: 2.714636203649322

Epoch: 5| Step: 10
Training loss: 3.1326103620884713
Validation loss: 2.7037916488238296

Epoch: 55| Step: 0
Training loss: 2.8322789156253654
Validation loss: 2.697699324534966

Epoch: 5| Step: 1
Training loss: 3.5037704322374332
Validation loss: 2.6878266199254925

Epoch: 5| Step: 2
Training loss: 2.8408849347561427
Validation loss: 2.690552273859667

Epoch: 5| Step: 3
Training loss: 3.5287415363617005
Validation loss: 2.6871755250995446

Epoch: 5| Step: 4
Training loss: 2.926498264110838
Validation loss: 2.684894211381318

Epoch: 5| Step: 5
Training loss: 2.518549480928362
Validation loss: 2.6879356529115714

Epoch: 5| Step: 6
Training loss: 2.7537314501538908
Validation loss: 2.6912785643618924

Epoch: 5| Step: 7
Training loss: 3.0219391651304006
Validation loss: 2.69580134375198

Epoch: 5| Step: 8
Training loss: 2.828112860384857
Validation loss: 2.7090954947390733

Epoch: 5| Step: 9
Training loss: 3.08300239917762
Validation loss: 2.7080380098106116

Epoch: 5| Step: 10
Training loss: 3.190976210794503
Validation loss: 2.7146489224921444

Epoch: 56| Step: 0
Training loss: 3.2583068911625053
Validation loss: 2.7188976871488992

Epoch: 5| Step: 1
Training loss: 2.547352751874084
Validation loss: 2.705758005461655

Epoch: 5| Step: 2
Training loss: 2.219943088454973
Validation loss: 2.686923683302768

Epoch: 5| Step: 3
Training loss: 3.3878373319449278
Validation loss: 2.669560741145089

Epoch: 5| Step: 4
Training loss: 2.491638505791416
Validation loss: 2.659470697914237

Epoch: 5| Step: 5
Training loss: 3.049014079100525
Validation loss: 2.645342671777028

Epoch: 5| Step: 6
Training loss: 2.902991652531569
Validation loss: 2.6437199728800507

Epoch: 5| Step: 7
Training loss: 2.879558266830653
Validation loss: 2.644759659804763

Epoch: 5| Step: 8
Training loss: 3.2780222684838156
Validation loss: 2.647447117324552

Epoch: 5| Step: 9
Training loss: 3.2484025697357644
Validation loss: 2.6420626182256464

Epoch: 5| Step: 10
Training loss: 3.338531271947587
Validation loss: 2.6390659093356668

Epoch: 57| Step: 0
Training loss: 2.938842466677197
Validation loss: 2.6410321783777544

Epoch: 5| Step: 1
Training loss: 3.414146439766521
Validation loss: 2.640064222431577

Epoch: 5| Step: 2
Training loss: 2.959920341089967
Validation loss: 2.636254675712285

Epoch: 5| Step: 3
Training loss: 2.630866806144386
Validation loss: 2.648246581840576

Epoch: 5| Step: 4
Training loss: 2.629818082254351
Validation loss: 2.6511814815426042

Epoch: 5| Step: 5
Training loss: 2.7249430134265413
Validation loss: 2.64858839252705

Epoch: 5| Step: 6
Training loss: 3.3661294854792345
Validation loss: 2.659983012181934

Epoch: 5| Step: 7
Training loss: 3.1263514838816575
Validation loss: 2.6731490195901477

Epoch: 5| Step: 8
Training loss: 3.14862892950919
Validation loss: 2.6630428139289157

Epoch: 5| Step: 9
Training loss: 2.9172453896530794
Validation loss: 2.657509205028878

Epoch: 5| Step: 10
Training loss: 2.725395936811776
Validation loss: 2.6398581697000685

Epoch: 58| Step: 0
Training loss: 3.11235509328299
Validation loss: 2.6431951934766555

Epoch: 5| Step: 1
Training loss: 2.717391716169243
Validation loss: 2.6365491217433417

Epoch: 5| Step: 2
Training loss: 2.430444335814879
Validation loss: 2.6341583083034505

Epoch: 5| Step: 3
Training loss: 2.6747465708819638
Validation loss: 2.6353578928575194

Epoch: 5| Step: 4
Training loss: 3.496994635586855
Validation loss: 2.6363201046308165

Epoch: 5| Step: 5
Training loss: 3.304357056746695
Validation loss: 2.63267621558826

Epoch: 5| Step: 6
Training loss: 3.260486849840962
Validation loss: 2.634877975514237

Epoch: 5| Step: 7
Training loss: 2.305836536592281
Validation loss: 2.6341703646431984

Epoch: 5| Step: 8
Training loss: 2.89493021615736
Validation loss: 2.629721013144542

Epoch: 5| Step: 9
Training loss: 3.4241542802260003
Validation loss: 2.637236379405466

Epoch: 5| Step: 10
Training loss: 2.755516068712291
Validation loss: 2.6414665574802716

Epoch: 59| Step: 0
Training loss: 3.2742726573907257
Validation loss: 2.6467791078026504

Epoch: 5| Step: 1
Training loss: 2.6867996900234865
Validation loss: 2.6515937235366382

Epoch: 5| Step: 2
Training loss: 3.069800880262107
Validation loss: 2.680342257835858

Epoch: 5| Step: 3
Training loss: 3.0485850694876993
Validation loss: 2.691000459496185

Epoch: 5| Step: 4
Training loss: 2.8004352776203603
Validation loss: 2.730308805358216

Epoch: 5| Step: 5
Training loss: 2.823366070737351
Validation loss: 2.679556557935998

Epoch: 5| Step: 6
Training loss: 3.078486697251396
Validation loss: 2.647052276432188

Epoch: 5| Step: 7
Training loss: 3.1404825814062733
Validation loss: 2.6255997735811465

Epoch: 5| Step: 8
Training loss: 2.560253833614042
Validation loss: 2.623487504596157

Epoch: 5| Step: 9
Training loss: 3.0672940469387253
Validation loss: 2.625822581484441

Epoch: 5| Step: 10
Training loss: 3.09711358222438
Validation loss: 2.6290765829745384

Epoch: 60| Step: 0
Training loss: 3.0285245303098467
Validation loss: 2.6306494350364305

Epoch: 5| Step: 1
Training loss: 2.4661095900861625
Validation loss: 2.628246159714123

Epoch: 5| Step: 2
Training loss: 3.1053856796574215
Validation loss: 2.626066008036342

Epoch: 5| Step: 3
Training loss: 3.4255153852971127
Validation loss: 2.623230201296745

Epoch: 5| Step: 4
Training loss: 3.0749326310880343
Validation loss: 2.6221039105244177

Epoch: 5| Step: 5
Training loss: 3.0071763988497295
Validation loss: 2.6286407484372747

Epoch: 5| Step: 6
Training loss: 3.053128129846224
Validation loss: 2.6397655564375

Epoch: 5| Step: 7
Training loss: 2.3928515468767855
Validation loss: 2.645132192028457

Epoch: 5| Step: 8
Training loss: 3.3004699199053014
Validation loss: 2.7138101605811324

Epoch: 5| Step: 9
Training loss: 2.680074146725385
Validation loss: 2.6656848544666207

Epoch: 5| Step: 10
Training loss: 3.1254900738771028
Validation loss: 2.6245544004601724

Epoch: 61| Step: 0
Training loss: 3.055134069869191
Validation loss: 2.612739465502187

Epoch: 5| Step: 1
Training loss: 2.5907956498543454
Validation loss: 2.615394366156196

Epoch: 5| Step: 2
Training loss: 2.9388445759705335
Validation loss: 2.6131508202363714

Epoch: 5| Step: 3
Training loss: 3.2262202120576724
Validation loss: 2.6143199170398215

Epoch: 5| Step: 4
Training loss: 2.9353124711491434
Validation loss: 2.6165636426266228

Epoch: 5| Step: 5
Training loss: 2.6085540028137624
Validation loss: 2.6219832571593664

Epoch: 5| Step: 6
Training loss: 3.2491612452458285
Validation loss: 2.638900557835644

Epoch: 5| Step: 7
Training loss: 3.122961981921545
Validation loss: 2.656756732628719

Epoch: 5| Step: 8
Training loss: 3.613066267886618
Validation loss: 2.65921729568213

Epoch: 5| Step: 9
Training loss: 2.242750887918132
Validation loss: 2.633844573949419

Epoch: 5| Step: 10
Training loss: 2.8255190988467938
Validation loss: 2.624057109191475

Epoch: 62| Step: 0
Training loss: 3.2107334489794552
Validation loss: 2.6298807088554277

Epoch: 5| Step: 1
Training loss: 2.686967930132821
Validation loss: 2.6106187934782756

Epoch: 5| Step: 2
Training loss: 2.9135707409612435
Validation loss: 2.6129521738881243

Epoch: 5| Step: 3
Training loss: 3.1826955452631487
Validation loss: 2.61059636635239

Epoch: 5| Step: 4
Training loss: 2.733402449811721
Validation loss: 2.6269073598229653

Epoch: 5| Step: 5
Training loss: 2.9275390885607777
Validation loss: 2.6470031532530296

Epoch: 5| Step: 6
Training loss: 2.393336235919492
Validation loss: 2.657553053140447

Epoch: 5| Step: 7
Training loss: 3.2025406467261437
Validation loss: 2.6475681731025276

Epoch: 5| Step: 8
Training loss: 3.2538871993552463
Validation loss: 2.6477887668922953

Epoch: 5| Step: 9
Training loss: 3.0337914892879625
Validation loss: 2.6037712797858164

Epoch: 5| Step: 10
Training loss: 2.895255015050117
Validation loss: 2.6036396804342785

Epoch: 63| Step: 0
Training loss: 2.9183269316644638
Validation loss: 2.6074199311950967

Epoch: 5| Step: 1
Training loss: 3.2646669871687335
Validation loss: 2.6146718286287194

Epoch: 5| Step: 2
Training loss: 3.131687333257216
Validation loss: 2.61915550874025

Epoch: 5| Step: 3
Training loss: 2.8969429872306165
Validation loss: 2.612432841624001

Epoch: 5| Step: 4
Training loss: 3.1141820200384345
Validation loss: 2.600054777166279

Epoch: 5| Step: 5
Training loss: 2.527349693138057
Validation loss: 2.5954622877484095

Epoch: 5| Step: 6
Training loss: 3.0006551027287736
Validation loss: 2.5972974802254836

Epoch: 5| Step: 7
Training loss: 2.5863753118158543
Validation loss: 2.5918597932028296

Epoch: 5| Step: 8
Training loss: 3.2337884785796267
Validation loss: 2.600749412407818

Epoch: 5| Step: 9
Training loss: 2.602742337130672
Validation loss: 2.6029717123441714

Epoch: 5| Step: 10
Training loss: 3.1241008227852913
Validation loss: 2.6152353836995377

Epoch: 64| Step: 0
Training loss: 3.1626292809157794
Validation loss: 2.6209442588505096

Epoch: 5| Step: 1
Training loss: 2.956370512943573
Validation loss: 2.6473220459103497

Epoch: 5| Step: 2
Training loss: 2.5226416499098447
Validation loss: 2.636330093427956

Epoch: 5| Step: 3
Training loss: 3.198835077440088
Validation loss: 2.637719694084729

Epoch: 5| Step: 4
Training loss: 2.278389064309043
Validation loss: 2.629749189710785

Epoch: 5| Step: 5
Training loss: 3.2136475943856815
Validation loss: 2.6004795544075474

Epoch: 5| Step: 6
Training loss: 2.8903958616424
Validation loss: 2.594170138148088

Epoch: 5| Step: 7
Training loss: 3.055905150634236
Validation loss: 2.5967733013376

Epoch: 5| Step: 8
Training loss: 2.697946958236805
Validation loss: 2.60603638370114

Epoch: 5| Step: 9
Training loss: 2.9997739706721354
Validation loss: 2.604604415689986

Epoch: 5| Step: 10
Training loss: 3.450518699021549
Validation loss: 2.612627198677544

Epoch: 65| Step: 0
Training loss: 2.567432215909229
Validation loss: 2.6145724420664234

Epoch: 5| Step: 1
Training loss: 2.667953200734795
Validation loss: 2.6159406419613838

Epoch: 5| Step: 2
Training loss: 2.794768579145727
Validation loss: 2.627411095898001

Epoch: 5| Step: 3
Training loss: 2.5894764083020396
Validation loss: 2.6172950013608443

Epoch: 5| Step: 4
Training loss: 2.8935405152791644
Validation loss: 2.624908331399903

Epoch: 5| Step: 5
Training loss: 3.656872427363608
Validation loss: 2.6173580931383786

Epoch: 5| Step: 6
Training loss: 2.544687841491039
Validation loss: 2.610783279039313

Epoch: 5| Step: 7
Training loss: 3.2449025012212065
Validation loss: 2.6081027527165577

Epoch: 5| Step: 8
Training loss: 2.8634218022716476
Validation loss: 2.6173247691781714

Epoch: 5| Step: 9
Training loss: 3.535549415938969
Validation loss: 2.6230801614500447

Epoch: 5| Step: 10
Training loss: 3.0949103751324594
Validation loss: 2.632788793535559

Epoch: 66| Step: 0
Training loss: 2.963303720121025
Validation loss: 2.637466072206834

Epoch: 5| Step: 1
Training loss: 3.2650055366223816
Validation loss: 2.642745787008388

Epoch: 5| Step: 2
Training loss: 2.9733533004409622
Validation loss: 2.6453051347886043

Epoch: 5| Step: 3
Training loss: 3.088140314709246
Validation loss: 2.624534869455127

Epoch: 5| Step: 4
Training loss: 2.8150880562000467
Validation loss: 2.6483793700886893

Epoch: 5| Step: 5
Training loss: 2.7061640243440626
Validation loss: 2.6846101070400286

Epoch: 5| Step: 6
Training loss: 2.967072986966339
Validation loss: 2.762436093532337

Epoch: 5| Step: 7
Training loss: 2.7808643030765174
Validation loss: 2.7282205172310316

Epoch: 5| Step: 8
Training loss: 2.6313782359427655
Validation loss: 2.6354637085053025

Epoch: 5| Step: 9
Training loss: 3.5998349628765944
Validation loss: 2.615166370697151

Epoch: 5| Step: 10
Training loss: 2.7414564587399957
Validation loss: 2.594907138530304

Epoch: 67| Step: 0
Training loss: 3.2189819844912915
Validation loss: 2.590891370163024

Epoch: 5| Step: 1
Training loss: 2.896968829333917
Validation loss: 2.5970870364069882

Epoch: 5| Step: 2
Training loss: 2.930303646146277
Validation loss: 2.613132152684589

Epoch: 5| Step: 3
Training loss: 2.8195240894796423
Validation loss: 2.6098110322708368

Epoch: 5| Step: 4
Training loss: 3.119359380781921
Validation loss: 2.5864502907966935

Epoch: 5| Step: 5
Training loss: 2.432855827911024
Validation loss: 2.586034058380138

Epoch: 5| Step: 6
Training loss: 3.1437078878869764
Validation loss: 2.5803587036386

Epoch: 5| Step: 7
Training loss: 2.554934055201469
Validation loss: 2.581382339915911

Epoch: 5| Step: 8
Training loss: 3.30872950900268
Validation loss: 2.5911397063950212

Epoch: 5| Step: 9
Training loss: 2.820650624641248
Validation loss: 2.5939871724932106

Epoch: 5| Step: 10
Training loss: 3.287325801512982
Validation loss: 2.596457440091486

Epoch: 68| Step: 0
Training loss: 2.9390155859472604
Validation loss: 2.596137440391254

Epoch: 5| Step: 1
Training loss: 2.5594655189762507
Validation loss: 2.600790373172268

Epoch: 5| Step: 2
Training loss: 3.138959300583978
Validation loss: 2.5936662591491753

Epoch: 5| Step: 3
Training loss: 3.2538309260301816
Validation loss: 2.60711630326945

Epoch: 5| Step: 4
Training loss: 2.7091350444761857
Validation loss: 2.5880680911695255

Epoch: 5| Step: 5
Training loss: 3.006505588127258
Validation loss: 2.58464076221736

Epoch: 5| Step: 6
Training loss: 2.4463631319874333
Validation loss: 2.585681957802252

Epoch: 5| Step: 7
Training loss: 3.2639941656210123
Validation loss: 2.5824999766771737

Epoch: 5| Step: 8
Training loss: 2.9386170880738827
Validation loss: 2.584023849447089

Epoch: 5| Step: 9
Training loss: 2.7226898760477316
Validation loss: 2.596454689302475

Epoch: 5| Step: 10
Training loss: 3.2152078637874784
Validation loss: 2.5993535140471957

Epoch: 69| Step: 0
Training loss: 3.2135569336630017
Validation loss: 2.603455654088983

Epoch: 5| Step: 1
Training loss: 3.4584199519206416
Validation loss: 2.6082499967826407

Epoch: 5| Step: 2
Training loss: 2.802197129067223
Validation loss: 2.6098908495432385

Epoch: 5| Step: 3
Training loss: 2.7517772480282834
Validation loss: 2.6373079566029975

Epoch: 5| Step: 4
Training loss: 2.6009688516267486
Validation loss: 2.632382642333292

Epoch: 5| Step: 5
Training loss: 3.035839264164326
Validation loss: 2.602270608725652

Epoch: 5| Step: 6
Training loss: 3.0762441087749295
Validation loss: 2.5788819972621475

Epoch: 5| Step: 7
Training loss: 2.760109957564053
Validation loss: 2.572111791933155

Epoch: 5| Step: 8
Training loss: 3.1241666064021145
Validation loss: 2.581945021124056

Epoch: 5| Step: 9
Training loss: 2.660693502299258
Validation loss: 2.5920693103903707

Epoch: 5| Step: 10
Training loss: 2.832157021722298
Validation loss: 2.5852851685564344

Epoch: 70| Step: 0
Training loss: 2.7833063474553787
Validation loss: 2.5959807616688524

Epoch: 5| Step: 1
Training loss: 3.001850193420757
Validation loss: 2.598522820466558

Epoch: 5| Step: 2
Training loss: 3.222044656691517
Validation loss: 2.5909501447331493

Epoch: 5| Step: 3
Training loss: 3.1519112556183204
Validation loss: 2.5820934847950783

Epoch: 5| Step: 4
Training loss: 3.0575362480803387
Validation loss: 2.582525941536024

Epoch: 5| Step: 5
Training loss: 3.2089264226545833
Validation loss: 2.580843034459464

Epoch: 5| Step: 6
Training loss: 2.5331986073591173
Validation loss: 2.574305191865542

Epoch: 5| Step: 7
Training loss: 2.64603145988948
Validation loss: 2.5738152999724866

Epoch: 5| Step: 8
Training loss: 2.8351494821366243
Validation loss: 2.5698072990051317

Epoch: 5| Step: 9
Training loss: 3.0231252109794866
Validation loss: 2.570637760876199

Epoch: 5| Step: 10
Training loss: 2.879054320628204
Validation loss: 2.5748744505889416

Epoch: 71| Step: 0
Training loss: 2.9896803429223744
Validation loss: 2.5801659990651458

Epoch: 5| Step: 1
Training loss: 3.1226355190509936
Validation loss: 2.5887228041844974

Epoch: 5| Step: 2
Training loss: 2.771790609182509
Validation loss: 2.6070886726954514

Epoch: 5| Step: 3
Training loss: 3.4898717656664546
Validation loss: 2.584751976788081

Epoch: 5| Step: 4
Training loss: 2.5731760324157436
Validation loss: 2.57539881122682

Epoch: 5| Step: 5
Training loss: 2.964191510776764
Validation loss: 2.5766709469265376

Epoch: 5| Step: 6
Training loss: 2.855877514347057
Validation loss: 2.566283387597905

Epoch: 5| Step: 7
Training loss: 2.810357697822374
Validation loss: 2.570185972165808

Epoch: 5| Step: 8
Training loss: 3.175400752209678
Validation loss: 2.5652405360224715

Epoch: 5| Step: 9
Training loss: 2.4139737109796835
Validation loss: 2.5634103014029814

Epoch: 5| Step: 10
Training loss: 2.84199671091833
Validation loss: 2.565519776048271

Epoch: 72| Step: 0
Training loss: 2.8411160521981684
Validation loss: 2.5665690551988463

Epoch: 5| Step: 1
Training loss: 3.1797717783863155
Validation loss: 2.5647186860818554

Epoch: 5| Step: 2
Training loss: 2.6960082109931855
Validation loss: 2.5769677889708995

Epoch: 5| Step: 3
Training loss: 2.935190957143167
Validation loss: 2.5736832257510507

Epoch: 5| Step: 4
Training loss: 3.0810870330611975
Validation loss: 2.577667502005355

Epoch: 5| Step: 5
Training loss: 3.1581827421362196
Validation loss: 2.576954450277747

Epoch: 5| Step: 6
Training loss: 2.8152172949283285
Validation loss: 2.5918430079112134

Epoch: 5| Step: 7
Training loss: 2.776952101594181
Validation loss: 2.5788398852805114

Epoch: 5| Step: 8
Training loss: 2.9254202320761924
Validation loss: 2.576299042244359

Epoch: 5| Step: 9
Training loss: 2.653358950595099
Validation loss: 2.5657600836407215

Epoch: 5| Step: 10
Training loss: 3.12750311737759
Validation loss: 2.561247282562106

Epoch: 73| Step: 0
Training loss: 3.1804997486917403
Validation loss: 2.5660493022197923

Epoch: 5| Step: 1
Training loss: 2.800287051473151
Validation loss: 2.5670406551181464

Epoch: 5| Step: 2
Training loss: 3.024651335492067
Validation loss: 2.5643612919596706

Epoch: 5| Step: 3
Training loss: 2.8187392646940372
Validation loss: 2.569067004846306

Epoch: 5| Step: 4
Training loss: 2.6285117138127574
Validation loss: 2.5730256702744443

Epoch: 5| Step: 5
Training loss: 2.6771407857189837
Validation loss: 2.5708740231420837

Epoch: 5| Step: 6
Training loss: 2.482013275590507
Validation loss: 2.5747844304745495

Epoch: 5| Step: 7
Training loss: 3.1251414457735045
Validation loss: 2.588188274197564

Epoch: 5| Step: 8
Training loss: 3.1370818995594387
Validation loss: 2.597404354890026

Epoch: 5| Step: 9
Training loss: 2.7592020397478474
Validation loss: 2.5835376490662827

Epoch: 5| Step: 10
Training loss: 3.365608712584632
Validation loss: 2.5896071365204003

Epoch: 74| Step: 0
Training loss: 2.848464913793446
Validation loss: 2.5758555019303713

Epoch: 5| Step: 1
Training loss: 3.213829946751343
Validation loss: 2.5694421154197538

Epoch: 5| Step: 2
Training loss: 2.3360460951450803
Validation loss: 2.566614626737915

Epoch: 5| Step: 3
Training loss: 2.866485759290517
Validation loss: 2.5612785675781495

Epoch: 5| Step: 4
Training loss: 3.2254418003956076
Validation loss: 2.561745443232158

Epoch: 5| Step: 5
Training loss: 2.4838002817701907
Validation loss: 2.5630356123571385

Epoch: 5| Step: 6
Training loss: 2.704186027312563
Validation loss: 2.5583973297946967

Epoch: 5| Step: 7
Training loss: 2.8988203016986973
Validation loss: 2.5594116907470874

Epoch: 5| Step: 8
Training loss: 3.3448657019416905
Validation loss: 2.558739604986847

Epoch: 5| Step: 9
Training loss: 3.2632643640988634
Validation loss: 2.560291361417

Epoch: 5| Step: 10
Training loss: 2.6420983712871764
Validation loss: 2.558791070859943

Epoch: 75| Step: 0
Training loss: 2.480214023276484
Validation loss: 2.562355349560103

Epoch: 5| Step: 1
Training loss: 2.4934058963022045
Validation loss: 2.5637473455294653

Epoch: 5| Step: 2
Training loss: 2.9893900490903804
Validation loss: 2.5555172866163196

Epoch: 5| Step: 3
Training loss: 2.9668103758333366
Validation loss: 2.562067259938778

Epoch: 5| Step: 4
Training loss: 3.0232465028192923
Validation loss: 2.556029792353069

Epoch: 5| Step: 5
Training loss: 3.1809560883557264
Validation loss: 2.562328423919485

Epoch: 5| Step: 6
Training loss: 3.0895948153021133
Validation loss: 2.563645177746312

Epoch: 5| Step: 7
Training loss: 3.0860346911613403
Validation loss: 2.573373571065135

Epoch: 5| Step: 8
Training loss: 2.3740696339602363
Validation loss: 2.560532220273024

Epoch: 5| Step: 9
Training loss: 2.946374190848399
Validation loss: 2.560276570550772

Epoch: 5| Step: 10
Training loss: 3.320749626556539
Validation loss: 2.5582436789345904

Epoch: 76| Step: 0
Training loss: 3.14872918304189
Validation loss: 2.564410152259102

Epoch: 5| Step: 1
Training loss: 2.4139139567971997
Validation loss: 2.5625373053267566

Epoch: 5| Step: 2
Training loss: 2.8909941566431985
Validation loss: 2.554708328656387

Epoch: 5| Step: 3
Training loss: 2.9707194973044895
Validation loss: 2.553806582174442

Epoch: 5| Step: 4
Training loss: 2.640968796961342
Validation loss: 2.5528974093981653

Epoch: 5| Step: 5
Training loss: 2.9183238271765033
Validation loss: 2.546812504531892

Epoch: 5| Step: 6
Training loss: 3.0331248354955975
Validation loss: 2.5506900509174044

Epoch: 5| Step: 7
Training loss: 2.849531898203527
Validation loss: 2.5587349981756535

Epoch: 5| Step: 8
Training loss: 3.1117615095605915
Validation loss: 2.5675694302994256

Epoch: 5| Step: 9
Training loss: 3.567393104753494
Validation loss: 2.5757173544335155

Epoch: 5| Step: 10
Training loss: 2.1386005267779127
Validation loss: 2.574831596018512

Epoch: 77| Step: 0
Training loss: 2.772012865837592
Validation loss: 2.5721910378523916

Epoch: 5| Step: 1
Training loss: 2.547979852408097
Validation loss: 2.5871570490863185

Epoch: 5| Step: 2
Training loss: 3.2656726012342614
Validation loss: 2.583069720068081

Epoch: 5| Step: 3
Training loss: 2.9217666361088637
Validation loss: 2.5685302288263365

Epoch: 5| Step: 4
Training loss: 3.0431326551452735
Validation loss: 2.555287199218494

Epoch: 5| Step: 5
Training loss: 2.923647256377575
Validation loss: 2.55065025658197

Epoch: 5| Step: 6
Training loss: 2.9816303514373312
Validation loss: 2.5513895631660137

Epoch: 5| Step: 7
Training loss: 3.228685618019711
Validation loss: 2.5477965742459725

Epoch: 5| Step: 8
Training loss: 2.2251368191260883
Validation loss: 2.5477813994161007

Epoch: 5| Step: 9
Training loss: 2.779984432698306
Validation loss: 2.5510220284531124

Epoch: 5| Step: 10
Training loss: 3.2519726268653226
Validation loss: 2.5509016832721776

Epoch: 78| Step: 0
Training loss: 3.152979752339769
Validation loss: 2.552342263890912

Epoch: 5| Step: 1
Training loss: 2.8359134557456094
Validation loss: 2.561539369608121

Epoch: 5| Step: 2
Training loss: 2.882444611519285
Validation loss: 2.560196792623137

Epoch: 5| Step: 3
Training loss: 2.848822460851527
Validation loss: 2.5639187161684918

Epoch: 5| Step: 4
Training loss: 2.493721325549331
Validation loss: 2.5679364016486246

Epoch: 5| Step: 5
Training loss: 2.900347550711292
Validation loss: 2.577952941343787

Epoch: 5| Step: 6
Training loss: 2.5727217956960127
Validation loss: 2.599153567610256

Epoch: 5| Step: 7
Training loss: 2.847180990111816
Validation loss: 2.5863069669950085

Epoch: 5| Step: 8
Training loss: 3.2856234514226634
Validation loss: 2.5667138037676756

Epoch: 5| Step: 9
Training loss: 3.251704136019759
Validation loss: 2.546982180697246

Epoch: 5| Step: 10
Training loss: 2.781465414898874
Validation loss: 2.5658529551784883

Epoch: 79| Step: 0
Training loss: 2.821385990325072
Validation loss: 2.5915036892682854

Epoch: 5| Step: 1
Training loss: 2.6510365204427018
Validation loss: 2.6202728358688265

Epoch: 5| Step: 2
Training loss: 3.04289086845738
Validation loss: 2.6449912794063883

Epoch: 5| Step: 3
Training loss: 3.127084570843585
Validation loss: 2.656884298046608

Epoch: 5| Step: 4
Training loss: 2.574946993680389
Validation loss: 2.6301439944869536

Epoch: 5| Step: 5
Training loss: 2.9012496754959627
Validation loss: 2.632090598621226

Epoch: 5| Step: 6
Training loss: 3.3833758653745414
Validation loss: 2.6277391769028307

Epoch: 5| Step: 7
Training loss: 3.0245382981223896
Validation loss: 2.626841816494077

Epoch: 5| Step: 8
Training loss: 2.565738492400006
Validation loss: 2.6117935118773574

Epoch: 5| Step: 9
Training loss: 3.0998445841070286
Validation loss: 2.5963966989112435

Epoch: 5| Step: 10
Training loss: 3.0992898373712507
Validation loss: 2.6007450051985197

Epoch: 80| Step: 0
Training loss: 2.4014301330582075
Validation loss: 2.5998680743089806

Epoch: 5| Step: 1
Training loss: 3.3231713048934868
Validation loss: 2.5969415868804053

Epoch: 5| Step: 2
Training loss: 2.9162944192851334
Validation loss: 2.592669699265801

Epoch: 5| Step: 3
Training loss: 3.0297700080831023
Validation loss: 2.596256079768873

Epoch: 5| Step: 4
Training loss: 3.067409084126192
Validation loss: 2.595485709909609

Epoch: 5| Step: 5
Training loss: 2.5803618004417905
Validation loss: 2.5961347218501416

Epoch: 5| Step: 6
Training loss: 2.661040440627322
Validation loss: 2.594146715967674

Epoch: 5| Step: 7
Training loss: 3.1926718248745294
Validation loss: 2.6005103891342696

Epoch: 5| Step: 8
Training loss: 3.162494939867879
Validation loss: 2.60487305706058

Epoch: 5| Step: 9
Training loss: 3.0984347544940243
Validation loss: 2.6282044056066014

Epoch: 5| Step: 10
Training loss: 2.7579897210342477
Validation loss: 2.633484990727094

Epoch: 81| Step: 0
Training loss: 3.2225350651930733
Validation loss: 2.6519498102254646

Epoch: 5| Step: 1
Training loss: 2.666261006335698
Validation loss: 2.6493129437044494

Epoch: 5| Step: 2
Training loss: 3.75552101614705
Validation loss: 2.681638040938619

Epoch: 5| Step: 3
Training loss: 2.86527065469959
Validation loss: 2.7100520865304754

Epoch: 5| Step: 4
Training loss: 3.056299277066317
Validation loss: 2.6473808139520565

Epoch: 5| Step: 5
Training loss: 2.7078949402301817
Validation loss: 2.61570082908998

Epoch: 5| Step: 6
Training loss: 2.4898506138123153
Validation loss: 2.585504687781518

Epoch: 5| Step: 7
Training loss: 2.731266543689616
Validation loss: 2.5817408984330434

Epoch: 5| Step: 8
Training loss: 3.0834488890017986
Validation loss: 2.5822613708693622

Epoch: 5| Step: 9
Training loss: 2.9731841051033747
Validation loss: 2.582763864810821

Epoch: 5| Step: 10
Training loss: 2.7631979600014196
Validation loss: 2.5806204781838766

Epoch: 82| Step: 0
Training loss: 2.9065195594390647
Validation loss: 2.573703597866096

Epoch: 5| Step: 1
Training loss: 3.398594223442639
Validation loss: 2.576012574720636

Epoch: 5| Step: 2
Training loss: 2.8275082584870983
Validation loss: 2.5678204393382598

Epoch: 5| Step: 3
Training loss: 2.647584220692131
Validation loss: 2.558392297497413

Epoch: 5| Step: 4
Training loss: 3.3198441478042984
Validation loss: 2.5482101086584814

Epoch: 5| Step: 5
Training loss: 2.521206273847276
Validation loss: 2.534531725898038

Epoch: 5| Step: 6
Training loss: 2.725883421181618
Validation loss: 2.5312499848080554

Epoch: 5| Step: 7
Training loss: 2.581688470060885
Validation loss: 2.5298985563048704

Epoch: 5| Step: 8
Training loss: 3.0644778657282834
Validation loss: 2.534771381874848

Epoch: 5| Step: 9
Training loss: 2.992446449967052
Validation loss: 2.540667844124336

Epoch: 5| Step: 10
Training loss: 2.7832092070931354
Validation loss: 2.564193611112097

Epoch: 83| Step: 0
Training loss: 2.835401079712871
Validation loss: 2.561098768611299

Epoch: 5| Step: 1
Training loss: 2.5573296838693893
Validation loss: 2.5702349167361858

Epoch: 5| Step: 2
Training loss: 3.2306863141860345
Validation loss: 2.583592090952027

Epoch: 5| Step: 3
Training loss: 2.931215909910127
Validation loss: 2.5591329547952597

Epoch: 5| Step: 4
Training loss: 2.603109180635925
Validation loss: 2.540587467610151

Epoch: 5| Step: 5
Training loss: 2.7464525577122054
Validation loss: 2.534978547403224

Epoch: 5| Step: 6
Training loss: 2.9438881098589906
Validation loss: 2.5270679320392317

Epoch: 5| Step: 7
Training loss: 3.0751940720265836
Validation loss: 2.528676934015769

Epoch: 5| Step: 8
Training loss: 2.5468340911388134
Validation loss: 2.5283325815057394

Epoch: 5| Step: 9
Training loss: 3.3816414936069403
Validation loss: 2.5314487676489468

Epoch: 5| Step: 10
Training loss: 2.938512424745851
Validation loss: 2.535984412879293

Epoch: 84| Step: 0
Training loss: 2.7349603516879686
Validation loss: 2.541931222965225

Epoch: 5| Step: 1
Training loss: 2.7170682945667908
Validation loss: 2.5463454642654817

Epoch: 5| Step: 2
Training loss: 2.656180347202583
Validation loss: 2.5653744004862196

Epoch: 5| Step: 3
Training loss: 3.107894161449906
Validation loss: 2.58493161320532

Epoch: 5| Step: 4
Training loss: 2.819923860184879
Validation loss: 2.5817981515651804

Epoch: 5| Step: 5
Training loss: 3.099019196925078
Validation loss: 2.604843682341809

Epoch: 5| Step: 6
Training loss: 3.2907574198597964
Validation loss: 2.629811170659928

Epoch: 5| Step: 7
Training loss: 2.89194421306531
Validation loss: 2.617019293811202

Epoch: 5| Step: 8
Training loss: 2.8191103076929993
Validation loss: 2.6234119033534635

Epoch: 5| Step: 9
Training loss: 2.616536073604776
Validation loss: 2.6131938047398835

Epoch: 5| Step: 10
Training loss: 3.0268199836729655
Validation loss: 2.622608683588771

Epoch: 85| Step: 0
Training loss: 2.488942104955205
Validation loss: 2.5419106567237577

Epoch: 5| Step: 1
Training loss: 3.018041877541988
Validation loss: 2.527811553639574

Epoch: 5| Step: 2
Training loss: 3.3115349569432495
Validation loss: 2.53245446805508

Epoch: 5| Step: 3
Training loss: 2.5231340066381933
Validation loss: 2.5277455817772325

Epoch: 5| Step: 4
Training loss: 2.9302073106561677
Validation loss: 2.5252987957452318

Epoch: 5| Step: 5
Training loss: 3.075771303284336
Validation loss: 2.530366154587462

Epoch: 5| Step: 6
Training loss: 2.7503965265324237
Validation loss: 2.5283924260231783

Epoch: 5| Step: 7
Training loss: 2.832660726109925
Validation loss: 2.5288573532792995

Epoch: 5| Step: 8
Training loss: 3.001497054093984
Validation loss: 2.5232715949000135

Epoch: 5| Step: 9
Training loss: 2.8084011303635203
Validation loss: 2.526877658550984

Epoch: 5| Step: 10
Training loss: 2.9478232612684385
Validation loss: 2.5192660055459597

Epoch: 86| Step: 0
Training loss: 2.6160736902339687
Validation loss: 2.524662102794979

Epoch: 5| Step: 1
Training loss: 3.1715902567118794
Validation loss: 2.5323446143534682

Epoch: 5| Step: 2
Training loss: 3.120137054905448
Validation loss: 2.5312914149275136

Epoch: 5| Step: 3
Training loss: 2.7358773600157282
Validation loss: 2.535402012869614

Epoch: 5| Step: 4
Training loss: 2.649646134411869
Validation loss: 2.538049837395363

Epoch: 5| Step: 5
Training loss: 3.0043065631548056
Validation loss: 2.5462915932678296

Epoch: 5| Step: 6
Training loss: 2.8499380004563806
Validation loss: 2.5529835208115648

Epoch: 5| Step: 7
Training loss: 3.0874353564209445
Validation loss: 2.5555138607585945

Epoch: 5| Step: 8
Training loss: 2.7035580326805966
Validation loss: 2.567619352307578

Epoch: 5| Step: 9
Training loss: 2.6096595106518485
Validation loss: 2.5918745339028653

Epoch: 5| Step: 10
Training loss: 3.147143379593817
Validation loss: 2.589717243904584

Epoch: 87| Step: 0
Training loss: 2.717263878861551
Validation loss: 2.600663845562545

Epoch: 5| Step: 1
Training loss: 2.447225486627144
Validation loss: 2.6335623353670035

Epoch: 5| Step: 2
Training loss: 2.5222333272987307
Validation loss: 2.586938525303303

Epoch: 5| Step: 3
Training loss: 3.2402064142291187
Validation loss: 2.55159425818632

Epoch: 5| Step: 4
Training loss: 3.0404537517315497
Validation loss: 2.5317168519913134

Epoch: 5| Step: 5
Training loss: 2.7325047663780584
Validation loss: 2.52872225167103

Epoch: 5| Step: 6
Training loss: 2.76598584251063
Validation loss: 2.534567187299987

Epoch: 5| Step: 7
Training loss: 3.6181527285584965
Validation loss: 2.5250607032752703

Epoch: 5| Step: 8
Training loss: 2.9834029127421426
Validation loss: 2.523075089037645

Epoch: 5| Step: 9
Training loss: 2.736684031352044
Validation loss: 2.5205043004072234

Epoch: 5| Step: 10
Training loss: 2.830646549950571
Validation loss: 2.5200283223175437

Epoch: 88| Step: 0
Training loss: 2.6963290301728082
Validation loss: 2.523253394233835

Epoch: 5| Step: 1
Training loss: 3.1754000013797015
Validation loss: 2.527107718318554

Epoch: 5| Step: 2
Training loss: 2.8235342797653455
Validation loss: 2.5245170852940912

Epoch: 5| Step: 3
Training loss: 2.750636460606077
Validation loss: 2.52132658038428

Epoch: 5| Step: 4
Training loss: 3.081903762017861
Validation loss: 2.5200070788382862

Epoch: 5| Step: 5
Training loss: 3.205438587810125
Validation loss: 2.5217801475941926

Epoch: 5| Step: 6
Training loss: 2.658444922645245
Validation loss: 2.5170956842964567

Epoch: 5| Step: 7
Training loss: 2.5596404519016875
Validation loss: 2.5231550002605316

Epoch: 5| Step: 8
Training loss: 2.965359649202959
Validation loss: 2.55210639854457

Epoch: 5| Step: 9
Training loss: 2.6476003398378083
Validation loss: 2.588422194665858

Epoch: 5| Step: 10
Training loss: 3.04745618705768
Validation loss: 2.628913358032601

Epoch: 89| Step: 0
Training loss: 3.157664822273222
Validation loss: 2.7198065238478946

Epoch: 5| Step: 1
Training loss: 3.098012280779066
Validation loss: 2.7394574602483592

Epoch: 5| Step: 2
Training loss: 2.6250244321140244
Validation loss: 2.646796752526251

Epoch: 5| Step: 3
Training loss: 2.92419504680398
Validation loss: 2.576186240739098

Epoch: 5| Step: 4
Training loss: 3.080562652619464
Validation loss: 2.542978929058508

Epoch: 5| Step: 5
Training loss: 2.8783672350941387
Validation loss: 2.535483911680703

Epoch: 5| Step: 6
Training loss: 2.295423503188568
Validation loss: 2.5314744044443245

Epoch: 5| Step: 7
Training loss: 2.7794629474276227
Validation loss: 2.535290475857828

Epoch: 5| Step: 8
Training loss: 3.2065170563542043
Validation loss: 2.538362772075501

Epoch: 5| Step: 9
Training loss: 2.632212765810285
Validation loss: 2.5341197135878817

Epoch: 5| Step: 10
Training loss: 3.3670055225169544
Validation loss: 2.532985610270449

Epoch: 90| Step: 0
Training loss: 2.611296260528055
Validation loss: 2.5381337789432328

Epoch: 5| Step: 1
Training loss: 2.8897195583614272
Validation loss: 2.537079259152518

Epoch: 5| Step: 2
Training loss: 2.863577334303394
Validation loss: 2.55238100132025

Epoch: 5| Step: 3
Training loss: 3.35913610274286
Validation loss: 2.556376476134075

Epoch: 5| Step: 4
Training loss: 2.962494372913795
Validation loss: 2.5682037157869133

Epoch: 5| Step: 5
Training loss: 3.2044030593825084
Validation loss: 2.566587484081489

Epoch: 5| Step: 6
Training loss: 2.8855807444793773
Validation loss: 2.572493215204148

Epoch: 5| Step: 7
Training loss: 3.026531203959417
Validation loss: 2.5726173435679254

Epoch: 5| Step: 8
Training loss: 2.9050421717302575
Validation loss: 2.5808969709703

Epoch: 5| Step: 9
Training loss: 2.2394566936321425
Validation loss: 2.5900493908853157

Epoch: 5| Step: 10
Training loss: 2.743336928432082
Validation loss: 2.639550793623614

Epoch: 91| Step: 0
Training loss: 3.072769075286827
Validation loss: 2.644922767541465

Epoch: 5| Step: 1
Training loss: 2.7693925615673733
Validation loss: 2.6460093571371246

Epoch: 5| Step: 2
Training loss: 3.1243792108002606
Validation loss: 2.6156822914689104

Epoch: 5| Step: 3
Training loss: 2.9301620709378673
Validation loss: 2.585193465157889

Epoch: 5| Step: 4
Training loss: 2.6135384243493602
Validation loss: 2.572184452806759

Epoch: 5| Step: 5
Training loss: 3.2508508595497205
Validation loss: 2.5645121276214393

Epoch: 5| Step: 6
Training loss: 2.858872332972452
Validation loss: 2.560372490624725

Epoch: 5| Step: 7
Training loss: 2.5148621344272097
Validation loss: 2.5564705299132235

Epoch: 5| Step: 8
Training loss: 2.7652165170505967
Validation loss: 2.5544293032840595

Epoch: 5| Step: 9
Training loss: 3.0063579262376354
Validation loss: 2.560545339146096

Epoch: 5| Step: 10
Training loss: 3.055901249683134
Validation loss: 2.5532155277717785

Epoch: 92| Step: 0
Training loss: 2.6258693345472235
Validation loss: 2.557937643404393

Epoch: 5| Step: 1
Training loss: 3.275647130031469
Validation loss: 2.5592343981573054

Epoch: 5| Step: 2
Training loss: 2.931685841902292
Validation loss: 2.563209323467936

Epoch: 5| Step: 3
Training loss: 2.6737401152254625
Validation loss: 2.562769620783685

Epoch: 5| Step: 4
Training loss: 3.06176655608649
Validation loss: 2.570417975331098

Epoch: 5| Step: 5
Training loss: 2.738631417907831
Validation loss: 2.576456268094024

Epoch: 5| Step: 6
Training loss: 3.2751265290257
Validation loss: 2.5882746075755305

Epoch: 5| Step: 7
Training loss: 2.8122757716334563
Validation loss: 2.5812796832968656

Epoch: 5| Step: 8
Training loss: 2.643376739341195
Validation loss: 2.567842785806799

Epoch: 5| Step: 9
Training loss: 3.014523952473123
Validation loss: 2.564024124567715

Epoch: 5| Step: 10
Training loss: 2.5858569175865047
Validation loss: 2.5635100564248123

Epoch: 93| Step: 0
Training loss: 3.141856848696744
Validation loss: 2.5652023440725773

Epoch: 5| Step: 1
Training loss: 3.1036818635661567
Validation loss: 2.5750721167996926

Epoch: 5| Step: 2
Training loss: 2.9515618925563496
Validation loss: 2.580183372019296

Epoch: 5| Step: 3
Training loss: 2.7799654791081414
Validation loss: 2.5750995742178016

Epoch: 5| Step: 4
Training loss: 3.121449704455654
Validation loss: 2.5817063123901582

Epoch: 5| Step: 5
Training loss: 2.492382364816344
Validation loss: 2.5798272721393447

Epoch: 5| Step: 6
Training loss: 3.013868541814873
Validation loss: 2.582148728560319

Epoch: 5| Step: 7
Training loss: 2.7646253255392117
Validation loss: 2.583770786035117

Epoch: 5| Step: 8
Training loss: 2.6535692937043267
Validation loss: 2.583058012767565

Epoch: 5| Step: 9
Training loss: 3.1299707171255573
Validation loss: 2.5890119063631345

Epoch: 5| Step: 10
Training loss: 2.3544221137436376
Validation loss: 2.5670709387756827

Epoch: 94| Step: 0
Training loss: 3.10454517762066
Validation loss: 2.569757284822987

Epoch: 5| Step: 1
Training loss: 2.9697988163275384
Validation loss: 2.580139071500239

Epoch: 5| Step: 2
Training loss: 2.5511691162206604
Validation loss: 2.620041709163361

Epoch: 5| Step: 3
Training loss: 2.9390868101275642
Validation loss: 2.6106540648945926

Epoch: 5| Step: 4
Training loss: 2.6129072574605643
Validation loss: 2.5927286461108863

Epoch: 5| Step: 5
Training loss: 2.437409717159382
Validation loss: 2.5846713653483824

Epoch: 5| Step: 6
Training loss: 2.844285181010858
Validation loss: 2.5669921849433424

Epoch: 5| Step: 7
Training loss: 3.2394013348612396
Validation loss: 2.5532706212186485

Epoch: 5| Step: 8
Training loss: 2.9863179058850657
Validation loss: 2.5485792589927567

Epoch: 5| Step: 9
Training loss: 3.2725808563618073
Validation loss: 2.552920039130741

Epoch: 5| Step: 10
Training loss: 2.8140179246658286
Validation loss: 2.552980176908701

Epoch: 95| Step: 0
Training loss: 2.867841017249688
Validation loss: 2.5508497928992693

Epoch: 5| Step: 1
Training loss: 2.8369705378414785
Validation loss: 2.551269364947485

Epoch: 5| Step: 2
Training loss: 2.8229904352851043
Validation loss: 2.550469461087039

Epoch: 5| Step: 3
Training loss: 2.674369049529222
Validation loss: 2.544210340897286

Epoch: 5| Step: 4
Training loss: 2.386947895544115
Validation loss: 2.5429178893814957

Epoch: 5| Step: 5
Training loss: 2.8813436430900072
Validation loss: 2.543223074124505

Epoch: 5| Step: 6
Training loss: 3.4098108560230345
Validation loss: 2.5478226140474387

Epoch: 5| Step: 7
Training loss: 2.90699331970812
Validation loss: 2.5502901455493725

Epoch: 5| Step: 8
Training loss: 2.9820872220869523
Validation loss: 2.5718688731121246

Epoch: 5| Step: 9
Training loss: 2.390687630026213
Validation loss: 2.5966875027684098

Epoch: 5| Step: 10
Training loss: 3.4258036596419976
Validation loss: 2.647923881376546

Epoch: 96| Step: 0
Training loss: 2.7938438485104387
Validation loss: 2.676432366698833

Epoch: 5| Step: 1
Training loss: 2.554418520518184
Validation loss: 2.6795432113709388

Epoch: 5| Step: 2
Training loss: 3.098140491095179
Validation loss: 2.655937495901167

Epoch: 5| Step: 3
Training loss: 3.0305291331353716
Validation loss: 2.6013825485605144

Epoch: 5| Step: 4
Training loss: 2.7349787454284824
Validation loss: 2.5718403853877843

Epoch: 5| Step: 5
Training loss: 3.287373088519178
Validation loss: 2.556138074029002

Epoch: 5| Step: 6
Training loss: 2.7154317315162593
Validation loss: 2.555970302050172

Epoch: 5| Step: 7
Training loss: 2.8785554214027065
Validation loss: 2.533827659885554

Epoch: 5| Step: 8
Training loss: 2.7912266132965455
Validation loss: 2.5499845227618927

Epoch: 5| Step: 9
Training loss: 3.022249841174291
Validation loss: 2.542096237025972

Epoch: 5| Step: 10
Training loss: 2.5899871740428644
Validation loss: 2.554681413737404

Epoch: 97| Step: 0
Training loss: 2.9449967839947226
Validation loss: 2.5465625868521795

Epoch: 5| Step: 1
Training loss: 2.7700603716774905
Validation loss: 2.543781710396784

Epoch: 5| Step: 2
Training loss: 2.318933661659806
Validation loss: 2.540986797424651

Epoch: 5| Step: 3
Training loss: 2.8674540798564587
Validation loss: 2.537632029705469

Epoch: 5| Step: 4
Training loss: 2.7439726754376736
Validation loss: 2.5343809373316506

Epoch: 5| Step: 5
Training loss: 3.1376589913377857
Validation loss: 2.5361674660983433

Epoch: 5| Step: 6
Training loss: 2.8520953790945764
Validation loss: 2.5334121420907025

Epoch: 5| Step: 7
Training loss: 3.224254752702886
Validation loss: 2.533126550201556

Epoch: 5| Step: 8
Training loss: 2.4362151843460946
Validation loss: 2.528826387957141

Epoch: 5| Step: 9
Training loss: 2.998090136088528
Validation loss: 2.5471054356409946

Epoch: 5| Step: 10
Training loss: 3.226329582619171
Validation loss: 2.557258020452878

Epoch: 98| Step: 0
Training loss: 2.8377523368857416
Validation loss: 2.559109068684742

Epoch: 5| Step: 1
Training loss: 2.916057486722294
Validation loss: 2.5849395631687266

Epoch: 5| Step: 2
Training loss: 3.0808615356453215
Validation loss: 2.569056810404259

Epoch: 5| Step: 3
Training loss: 3.4645362898216567
Validation loss: 2.5494393024815767

Epoch: 5| Step: 4
Training loss: 2.1242595953485006
Validation loss: 2.5240387990840802

Epoch: 5| Step: 5
Training loss: 2.360075284597613
Validation loss: 2.525576766509352

Epoch: 5| Step: 6
Training loss: 2.0248893330792828
Validation loss: 2.528412643925021

Epoch: 5| Step: 7
Training loss: 3.131991081332276
Validation loss: 2.528217422883073

Epoch: 5| Step: 8
Training loss: 3.168817860254787
Validation loss: 2.523907979917356

Epoch: 5| Step: 9
Training loss: 3.182106990835325
Validation loss: 2.5247582386776717

Epoch: 5| Step: 10
Training loss: 3.087053855137063
Validation loss: 2.5099111184215035

Epoch: 99| Step: 0
Training loss: 2.7347777151824864
Validation loss: 2.498381207489233

Epoch: 5| Step: 1
Training loss: 3.17971524313181
Validation loss: 2.529908084191127

Epoch: 5| Step: 2
Training loss: 2.580714826547229
Validation loss: 2.531205048662662

Epoch: 5| Step: 3
Training loss: 3.599215655183714
Validation loss: 2.55332927580748

Epoch: 5| Step: 4
Training loss: 3.196327104350838
Validation loss: 2.535957308335709

Epoch: 5| Step: 5
Training loss: 3.0858050740474665
Validation loss: 2.5047621327175893

Epoch: 5| Step: 6
Training loss: 2.4095754062610806
Validation loss: 2.5610761951301586

Epoch: 5| Step: 7
Training loss: 2.853381269295912
Validation loss: 2.6258893750152783

Epoch: 5| Step: 8
Training loss: 2.5683455434216436
Validation loss: 2.6117434084801405

Epoch: 5| Step: 9
Training loss: 2.5128081289347532
Validation loss: 2.643232935978491

Epoch: 5| Step: 10
Training loss: 3.0069758056540086
Validation loss: 2.6558935458265136

Epoch: 100| Step: 0
Training loss: 3.057544045805557
Validation loss: 2.6586090614816884

Epoch: 5| Step: 1
Training loss: 2.8713594689964044
Validation loss: 2.668569000362565

Epoch: 5| Step: 2
Training loss: 2.8246293356454863
Validation loss: 2.646984091032945

Epoch: 5| Step: 3
Training loss: 2.9701899198696395
Validation loss: 2.6046101205274503

Epoch: 5| Step: 4
Training loss: 3.166174365140624
Validation loss: 2.5855499325118214

Epoch: 5| Step: 5
Training loss: 2.7203378534861025
Validation loss: 2.5601469001150052

Epoch: 5| Step: 6
Training loss: 2.8265833578188935
Validation loss: 2.540994138282281

Epoch: 5| Step: 7
Training loss: 2.799508330910345
Validation loss: 2.5251976616882374

Epoch: 5| Step: 8
Training loss: 2.9256112592994223
Validation loss: 2.5172073319173807

Epoch: 5| Step: 9
Training loss: 3.0190498787549296
Validation loss: 2.5317166676963705

Epoch: 5| Step: 10
Training loss: 2.8137708547760703
Validation loss: 2.5217726496528536

Epoch: 101| Step: 0
Training loss: 2.9061481088804664
Validation loss: 2.5263377757054384

Epoch: 5| Step: 1
Training loss: 2.903743196004055
Validation loss: 2.528827153351079

Epoch: 5| Step: 2
Training loss: 3.1304924572017687
Validation loss: 2.541193547049207

Epoch: 5| Step: 3
Training loss: 2.4713377126314136
Validation loss: 2.5466297342847706

Epoch: 5| Step: 4
Training loss: 2.380150981409671
Validation loss: 2.5464892603286837

Epoch: 5| Step: 5
Training loss: 3.033113673574357
Validation loss: 2.5610713592882473

Epoch: 5| Step: 6
Training loss: 3.4663223156709133
Validation loss: 2.5701862674119855

Epoch: 5| Step: 7
Training loss: 2.2458380246747427
Validation loss: 2.5263594114298704

Epoch: 5| Step: 8
Training loss: 3.2069222621078044
Validation loss: 2.5325131725107224

Epoch: 5| Step: 9
Training loss: 2.6650477402581787
Validation loss: 2.5253582802054115

Epoch: 5| Step: 10
Training loss: 2.935889269162114
Validation loss: 2.519963044997394

Epoch: 102| Step: 0
Training loss: 3.146634705052529
Validation loss: 2.537552148046814

Epoch: 5| Step: 1
Training loss: 3.017280084897286
Validation loss: 2.5408988366423833

Epoch: 5| Step: 2
Training loss: 2.557635644800239
Validation loss: 2.5278010417046954

Epoch: 5| Step: 3
Training loss: 2.786680256690269
Validation loss: 2.514108381938243

Epoch: 5| Step: 4
Training loss: 2.685135355544296
Validation loss: 2.5125553921486175

Epoch: 5| Step: 5
Training loss: 2.668795232813852
Validation loss: 2.532786653501972

Epoch: 5| Step: 6
Training loss: 2.3711575997568195
Validation loss: 2.578973523486425

Epoch: 5| Step: 7
Training loss: 3.1522619149364615
Validation loss: 2.572533908362491

Epoch: 5| Step: 8
Training loss: 3.1689617138924557
Validation loss: 2.5811805176847633

Epoch: 5| Step: 9
Training loss: 3.012209366197527
Validation loss: 2.5326526866813417

Epoch: 5| Step: 10
Training loss: 2.8837229213757807
Validation loss: 2.49591689820317

Epoch: 103| Step: 0
Training loss: 3.1540444098849285
Validation loss: 2.4824748673027197

Epoch: 5| Step: 1
Training loss: 3.357540179571062
Validation loss: 2.4862415352227387

Epoch: 5| Step: 2
Training loss: 3.0209444398288285
Validation loss: 2.4916637578948557

Epoch: 5| Step: 3
Training loss: 2.6796844749322393
Validation loss: 2.4960781571106314

Epoch: 5| Step: 4
Training loss: 2.547530388318604
Validation loss: 2.5127813528724734

Epoch: 5| Step: 5
Training loss: 2.4361137947851654
Validation loss: 2.52545483116428

Epoch: 5| Step: 6
Training loss: 2.7599363280982137
Validation loss: 2.539820800832609

Epoch: 5| Step: 7
Training loss: 3.117101070573022
Validation loss: 2.518826006749649

Epoch: 5| Step: 8
Training loss: 2.943080876267332
Validation loss: 2.545477343650475

Epoch: 5| Step: 9
Training loss: 2.265805151781557
Validation loss: 2.527647011744748

Epoch: 5| Step: 10
Training loss: 2.6444421750369695
Validation loss: 2.521202346842989

Epoch: 104| Step: 0
Training loss: 3.0324385367735127
Validation loss: 2.524527856144704

Epoch: 5| Step: 1
Training loss: 2.8598298925216086
Validation loss: 2.531955377133786

Epoch: 5| Step: 2
Training loss: 2.779491340015725
Validation loss: 2.50858240554502

Epoch: 5| Step: 3
Training loss: 2.7875685337006737
Validation loss: 2.5035443212929547

Epoch: 5| Step: 4
Training loss: 2.216728686657766
Validation loss: 2.4801747675051478

Epoch: 5| Step: 5
Training loss: 2.5106855910579475
Validation loss: 2.4812879709958895

Epoch: 5| Step: 6
Training loss: 3.4636204913737534
Validation loss: 2.477937691735452

Epoch: 5| Step: 7
Training loss: 3.17115843247117
Validation loss: 2.484009853984658

Epoch: 5| Step: 8
Training loss: 2.6378997644407054
Validation loss: 2.4851813168444963

Epoch: 5| Step: 9
Training loss: 3.157509278731557
Validation loss: 2.4788899738221652

Epoch: 5| Step: 10
Training loss: 2.5939155433864696
Validation loss: 2.4724703433767634

Epoch: 105| Step: 0
Training loss: 2.443846924559706
Validation loss: 2.472553051372212

Epoch: 5| Step: 1
Training loss: 2.797735923521019
Validation loss: 2.4805476825852537

Epoch: 5| Step: 2
Training loss: 3.2217721917134132
Validation loss: 2.486939476833392

Epoch: 5| Step: 3
Training loss: 3.0016200142016247
Validation loss: 2.504010815302632

Epoch: 5| Step: 4
Training loss: 2.67543675787673
Validation loss: 2.526880948730522

Epoch: 5| Step: 5
Training loss: 2.842801449374614
Validation loss: 2.5442118745204336

Epoch: 5| Step: 6
Training loss: 3.0906124967162087
Validation loss: 2.5390025752894494

Epoch: 5| Step: 7
Training loss: 2.5260238384653295
Validation loss: 2.5713211744951865

Epoch: 5| Step: 8
Training loss: 3.0695560678598706
Validation loss: 2.5898613243117374

Epoch: 5| Step: 9
Training loss: 2.186071528919679
Validation loss: 2.521792236967404

Epoch: 5| Step: 10
Training loss: 3.1200904427159704
Validation loss: 2.483985561299889

Epoch: 106| Step: 0
Training loss: 3.1002889560035807
Validation loss: 2.4686279162845133

Epoch: 5| Step: 1
Training loss: 2.8958610332088153
Validation loss: 2.494785398659128

Epoch: 5| Step: 2
Training loss: 2.937147565761564
Validation loss: 2.518368970628414

Epoch: 5| Step: 3
Training loss: 3.1248690768473044
Validation loss: 2.5238028686933105

Epoch: 5| Step: 4
Training loss: 2.761795927747196
Validation loss: 2.5449880644364504

Epoch: 5| Step: 5
Training loss: 3.1538768949316633
Validation loss: 2.553836752730312

Epoch: 5| Step: 6
Training loss: 3.137443335276013
Validation loss: 2.565528218845825

Epoch: 5| Step: 7
Training loss: 3.253414707677433
Validation loss: 2.572830816195635

Epoch: 5| Step: 8
Training loss: 2.8800306673536413
Validation loss: 2.549088389576681

Epoch: 5| Step: 9
Training loss: 2.4431343493376647
Validation loss: 2.5518195559457446

Epoch: 5| Step: 10
Training loss: 2.5313475790171327
Validation loss: 2.558565408048235

Epoch: 107| Step: 0
Training loss: 2.454469543143735
Validation loss: 2.5514989063611644

Epoch: 5| Step: 1
Training loss: 3.0871352563309156
Validation loss: 2.54660502722332

Epoch: 5| Step: 2
Training loss: 3.4270945416453698
Validation loss: 2.5409652680883585

Epoch: 5| Step: 3
Training loss: 2.478264545682367
Validation loss: 2.5358853361377536

Epoch: 5| Step: 4
Training loss: 2.6912194174709003
Validation loss: 2.542713529327047

Epoch: 5| Step: 5
Training loss: 2.892323257994402
Validation loss: 2.5478858061728724

Epoch: 5| Step: 6
Training loss: 3.5145031304621597
Validation loss: 2.532932737492956

Epoch: 5| Step: 7
Training loss: 3.347471358936678
Validation loss: 2.5056377236737863

Epoch: 5| Step: 8
Training loss: 2.375241518288748
Validation loss: 2.5119953613374277

Epoch: 5| Step: 9
Training loss: 2.8423433283135062
Validation loss: 2.5016697967681987

Epoch: 5| Step: 10
Training loss: 2.600449240827414
Validation loss: 2.5033616936703997

Epoch: 108| Step: 0
Training loss: 2.5154323148680375
Validation loss: 2.5060440450818864

Epoch: 5| Step: 1
Training loss: 2.820478355201586
Validation loss: 2.509719683117857

Epoch: 5| Step: 2
Training loss: 3.434594053132692
Validation loss: 2.5920752900736077

Epoch: 5| Step: 3
Training loss: 2.4727303010238626
Validation loss: 2.647170619251245

Epoch: 5| Step: 4
Training loss: 2.944353428119691
Validation loss: 2.703066210012913

Epoch: 5| Step: 5
Training loss: 2.9037113381881574
Validation loss: 2.7034623206295976

Epoch: 5| Step: 6
Training loss: 3.2097024514688792
Validation loss: 2.611508387514304

Epoch: 5| Step: 7
Training loss: 2.417778143202919
Validation loss: 2.5058718593513

Epoch: 5| Step: 8
Training loss: 3.6055992821966303
Validation loss: 2.5060777940891614

Epoch: 5| Step: 9
Training loss: 2.7518445677832237
Validation loss: 2.506150284736888

Epoch: 5| Step: 10
Training loss: 2.8183281593418132
Validation loss: 2.5250785924245998

Epoch: 109| Step: 0
Training loss: 3.2642354975060717
Validation loss: 2.5512909058059514

Epoch: 5| Step: 1
Training loss: 2.5651084835319535
Validation loss: 2.55656484095183

Epoch: 5| Step: 2
Training loss: 3.099377071182227
Validation loss: 2.5377637637873462

Epoch: 5| Step: 3
Training loss: 2.528659012534581
Validation loss: 2.514368537213703

Epoch: 5| Step: 4
Training loss: 2.8684195799849124
Validation loss: 2.5100445800752227

Epoch: 5| Step: 5
Training loss: 2.9003330828677503
Validation loss: 2.5048189315737175

Epoch: 5| Step: 6
Training loss: 3.3502287089150458
Validation loss: 2.50539699073742

Epoch: 5| Step: 7
Training loss: 2.4676176927011086
Validation loss: 2.510534247407706

Epoch: 5| Step: 8
Training loss: 2.97202497839924
Validation loss: 2.504900377012843

Epoch: 5| Step: 9
Training loss: 3.2117892061567734
Validation loss: 2.5107846860679524

Epoch: 5| Step: 10
Training loss: 2.9691293574439213
Validation loss: 2.51399250750265

Epoch: 110| Step: 0
Training loss: 2.8453570844748794
Validation loss: 2.51137436599617

Epoch: 5| Step: 1
Training loss: 3.25005003083674
Validation loss: 2.5472401972968632

Epoch: 5| Step: 2
Training loss: 2.9129544930850155
Validation loss: 2.548010774116328

Epoch: 5| Step: 3
Training loss: 2.8347669975968155
Validation loss: 2.554202847611862

Epoch: 5| Step: 4
Training loss: 2.6022325174178866
Validation loss: 2.5451831322924106

Epoch: 5| Step: 5
Training loss: 2.8341499348608012
Validation loss: 2.5482267638518183

Epoch: 5| Step: 6
Training loss: 2.730698997383773
Validation loss: 2.539908104520368

Epoch: 5| Step: 7
Training loss: 2.6557650852760655
Validation loss: 2.531064054910254

Epoch: 5| Step: 8
Training loss: 2.999437597328632
Validation loss: 2.5297598210477257

Epoch: 5| Step: 9
Training loss: 3.494396901847528
Validation loss: 2.5301232260139184

Epoch: 5| Step: 10
Training loss: 2.4111426018369015
Validation loss: 2.510206310139346

Epoch: 111| Step: 0
Training loss: 3.3883774863120095
Validation loss: 2.5109181206882893

Epoch: 5| Step: 1
Training loss: 2.863276253939195
Validation loss: 2.5158660697752087

Epoch: 5| Step: 2
Training loss: 2.478228853798724
Validation loss: 2.512470929687753

Epoch: 5| Step: 3
Training loss: 2.8079170186369513
Validation loss: 2.5054858039567094

Epoch: 5| Step: 4
Training loss: 2.8968463653498984
Validation loss: 2.5048829373617894

Epoch: 5| Step: 5
Training loss: 2.786020880375133
Validation loss: 2.522185894740638

Epoch: 5| Step: 6
Training loss: 2.8757421116236968
Validation loss: 2.513887366151988

Epoch: 5| Step: 7
Training loss: 2.950470715484587
Validation loss: 2.5216557574682934

Epoch: 5| Step: 8
Training loss: 2.9823756685905742
Validation loss: 2.518441031141668

Epoch: 5| Step: 9
Training loss: 2.5715131651118384
Validation loss: 2.5146241604407376

Epoch: 5| Step: 10
Training loss: 2.3834795909189466
Validation loss: 2.4930622022551625

Epoch: 112| Step: 0
Training loss: 3.4859585435233
Validation loss: 2.4833547920207826

Epoch: 5| Step: 1
Training loss: 3.044697771028635
Validation loss: 2.486320590777016

Epoch: 5| Step: 2
Training loss: 2.459328552350369
Validation loss: 2.489638003367189

Epoch: 5| Step: 3
Training loss: 2.7125296630643785
Validation loss: 2.4819934130832575

Epoch: 5| Step: 4
Training loss: 2.938350797771873
Validation loss: 2.473582059076581

Epoch: 5| Step: 5
Training loss: 2.4220047454535494
Validation loss: 2.474514160582921

Epoch: 5| Step: 6
Training loss: 2.6174758069105364
Validation loss: 2.473652618810699

Epoch: 5| Step: 7
Training loss: 2.961273415868632
Validation loss: 2.471273335965318

Epoch: 5| Step: 8
Training loss: 2.415763477930928
Validation loss: 2.47669327877354

Epoch: 5| Step: 9
Training loss: 3.185490891311405
Validation loss: 2.4797143459608253

Epoch: 5| Step: 10
Training loss: 2.559686651573185
Validation loss: 2.5113238536777396

Epoch: 113| Step: 0
Training loss: 2.7691535638374276
Validation loss: 2.557747547475253

Epoch: 5| Step: 1
Training loss: 2.7793332470828043
Validation loss: 2.573655958420787

Epoch: 5| Step: 2
Training loss: 3.295800201082296
Validation loss: 2.6300607271707492

Epoch: 5| Step: 3
Training loss: 2.7617249657373475
Validation loss: 2.5916619879045273

Epoch: 5| Step: 4
Training loss: 2.1452933314078995
Validation loss: 2.545647627449059

Epoch: 5| Step: 5
Training loss: 2.5850544600219347
Validation loss: 2.509545117543687

Epoch: 5| Step: 6
Training loss: 2.9526198828097194
Validation loss: 2.471019526720831

Epoch: 5| Step: 7
Training loss: 2.728589285618762
Validation loss: 2.465406348537451

Epoch: 5| Step: 8
Training loss: 3.0084819098333355
Validation loss: 2.4644056460344546

Epoch: 5| Step: 9
Training loss: 3.3257331670825327
Validation loss: 2.4708863611581218

Epoch: 5| Step: 10
Training loss: 2.7504183711074734
Validation loss: 2.4711487273201516

Epoch: 114| Step: 0
Training loss: 3.1311982293332044
Validation loss: 2.4713073108462367

Epoch: 5| Step: 1
Training loss: 2.8183033726786157
Validation loss: 2.4753446298229584

Epoch: 5| Step: 2
Training loss: 2.9481356014912667
Validation loss: 2.4788721774347184

Epoch: 5| Step: 3
Training loss: 2.5522768738727706
Validation loss: 2.479296950648845

Epoch: 5| Step: 4
Training loss: 3.1219953206410307
Validation loss: 2.4894079852943394

Epoch: 5| Step: 5
Training loss: 2.638943469726772
Validation loss: 2.5047464504999963

Epoch: 5| Step: 6
Training loss: 2.847044660619244
Validation loss: 2.5442149185883447

Epoch: 5| Step: 7
Training loss: 2.8509104362021938
Validation loss: 2.582180430493566

Epoch: 5| Step: 8
Training loss: 2.5448497372618486
Validation loss: 2.6119919528786655

Epoch: 5| Step: 9
Training loss: 3.3086960741814457
Validation loss: 2.6126339442724786

Epoch: 5| Step: 10
Training loss: 2.271770902030184
Validation loss: 2.6187102167332954

Epoch: 115| Step: 0
Training loss: 2.363666900190755
Validation loss: 2.6287815993478274

Epoch: 5| Step: 1
Training loss: 2.912156696306078
Validation loss: 2.6438827888961467

Epoch: 5| Step: 2
Training loss: 2.960950383382262
Validation loss: 2.6387097696402138

Epoch: 5| Step: 3
Training loss: 2.8336268067305155
Validation loss: 2.5906177797487415

Epoch: 5| Step: 4
Training loss: 2.89575630652719
Validation loss: 2.542257429593197

Epoch: 5| Step: 5
Training loss: 3.009294417303606
Validation loss: 2.511444749984817

Epoch: 5| Step: 6
Training loss: 2.598370767861629
Validation loss: 2.4890737741070286

Epoch: 5| Step: 7
Training loss: 2.884064689302249
Validation loss: 2.484628972023548

Epoch: 5| Step: 8
Training loss: 3.353927098282075
Validation loss: 2.4740555590105635

Epoch: 5| Step: 9
Training loss: 2.492048779875076
Validation loss: 2.46315517922051

Epoch: 5| Step: 10
Training loss: 3.0736694620757725
Validation loss: 2.45904588427338

Epoch: 116| Step: 0
Training loss: 2.6371462327079147
Validation loss: 2.458658636590174

Epoch: 5| Step: 1
Training loss: 2.6839817882664727
Validation loss: 2.4615420123630587

Epoch: 5| Step: 2
Training loss: 2.5871409586344054
Validation loss: 2.464076642656715

Epoch: 5| Step: 3
Training loss: 3.1365992617146468
Validation loss: 2.4646747620174883

Epoch: 5| Step: 4
Training loss: 3.113632737520229
Validation loss: 2.4642213277002427

Epoch: 5| Step: 5
Training loss: 2.6958540662609924
Validation loss: 2.4605184291668194

Epoch: 5| Step: 6
Training loss: 3.0856188645822447
Validation loss: 2.4665348057089314

Epoch: 5| Step: 7
Training loss: 2.536160638926089
Validation loss: 2.4713988916283403

Epoch: 5| Step: 8
Training loss: 2.9263082724810148
Validation loss: 2.4782809437287248

Epoch: 5| Step: 9
Training loss: 2.7717771046241264
Validation loss: 2.493534282415518

Epoch: 5| Step: 10
Training loss: 2.9084293848770693
Validation loss: 2.499442903938777

Epoch: 117| Step: 0
Training loss: 2.9932808335195396
Validation loss: 2.520280899687809

Epoch: 5| Step: 1
Training loss: 2.772003920867481
Validation loss: 2.514341665611951

Epoch: 5| Step: 2
Training loss: 2.633582752423224
Validation loss: 2.5173826238561405

Epoch: 5| Step: 3
Training loss: 3.2872262935051966
Validation loss: 2.5139243251590533

Epoch: 5| Step: 4
Training loss: 2.392534079632846
Validation loss: 2.4956288095741135

Epoch: 5| Step: 5
Training loss: 3.209095373108829
Validation loss: 2.495617743986938

Epoch: 5| Step: 6
Training loss: 2.654203636434957
Validation loss: 2.4862241698854985

Epoch: 5| Step: 7
Training loss: 2.564861604998486
Validation loss: 2.483138872448675

Epoch: 5| Step: 8
Training loss: 3.117317522057257
Validation loss: 2.4651882116268182

Epoch: 5| Step: 9
Training loss: 2.9199798476163905
Validation loss: 2.461412338749127

Epoch: 5| Step: 10
Training loss: 1.9308447205799473
Validation loss: 2.455171032678702

Epoch: 118| Step: 0
Training loss: 3.19415456221354
Validation loss: 2.4567164026932895

Epoch: 5| Step: 1
Training loss: 2.790369064367805
Validation loss: 2.458371506428147

Epoch: 5| Step: 2
Training loss: 2.376301860373848
Validation loss: 2.45711273110945

Epoch: 5| Step: 3
Training loss: 2.680993120741707
Validation loss: 2.4540148196913165

Epoch: 5| Step: 4
Training loss: 2.620472227447606
Validation loss: 2.4575006615762995

Epoch: 5| Step: 5
Training loss: 2.728909856541061
Validation loss: 2.451680448019374

Epoch: 5| Step: 6
Training loss: 3.1057761370079473
Validation loss: 2.4459461862888707

Epoch: 5| Step: 7
Training loss: 2.5101176567921955
Validation loss: 2.440381647187903

Epoch: 5| Step: 8
Training loss: 2.9114305816765382
Validation loss: 2.442508023821578

Epoch: 5| Step: 9
Training loss: 2.672898481331438
Validation loss: 2.447165758679987

Epoch: 5| Step: 10
Training loss: 3.2488982460570264
Validation loss: 2.4577399066489387

Epoch: 119| Step: 0
Training loss: 2.6494266609541963
Validation loss: 2.492204810412956

Epoch: 5| Step: 1
Training loss: 3.21224332741451
Validation loss: 2.530289745708464

Epoch: 5| Step: 2
Training loss: 2.945511140879029
Validation loss: 2.552994790635719

Epoch: 5| Step: 3
Training loss: 3.0711353548580185
Validation loss: 2.545994795554698

Epoch: 5| Step: 4
Training loss: 2.1320533379472595
Validation loss: 2.497049958381692

Epoch: 5| Step: 5
Training loss: 2.7924273199528824
Validation loss: 2.4880837765730237

Epoch: 5| Step: 6
Training loss: 2.0654284177374937
Validation loss: 2.4563692793860077

Epoch: 5| Step: 7
Training loss: 3.4674095794395785
Validation loss: 2.442392449293266

Epoch: 5| Step: 8
Training loss: 2.5356401589993354
Validation loss: 2.442132449329222

Epoch: 5| Step: 9
Training loss: 3.0332520156133036
Validation loss: 2.44834212509334

Epoch: 5| Step: 10
Training loss: 2.7398217584593785
Validation loss: 2.441690579041471

Epoch: 120| Step: 0
Training loss: 2.312338746093351
Validation loss: 2.4459208594303368

Epoch: 5| Step: 1
Training loss: 2.7446597874113308
Validation loss: 2.440954763361057

Epoch: 5| Step: 2
Training loss: 3.0948072996528984
Validation loss: 2.4517660761711673

Epoch: 5| Step: 3
Training loss: 3.034581506775629
Validation loss: 2.457610054326299

Epoch: 5| Step: 4
Training loss: 2.7983744773392254
Validation loss: 2.463522474560236

Epoch: 5| Step: 5
Training loss: 2.571298520266028
Validation loss: 2.473170559407672

Epoch: 5| Step: 6
Training loss: 2.41708816491889
Validation loss: 2.4747278113757236

Epoch: 5| Step: 7
Training loss: 3.1722889897820443
Validation loss: 2.476602262280811

Epoch: 5| Step: 8
Training loss: 2.7549402771169027
Validation loss: 2.5017840644112765

Epoch: 5| Step: 9
Training loss: 2.40440981961436
Validation loss: 2.4761280680168722

Epoch: 5| Step: 10
Training loss: 3.3275369473877325
Validation loss: 2.484987228491796

Epoch: 121| Step: 0
Training loss: 2.6230109717211967
Validation loss: 2.487727662781027

Epoch: 5| Step: 1
Training loss: 2.9080091505260874
Validation loss: 2.4878239393568222

Epoch: 5| Step: 2
Training loss: 3.220800690939953
Validation loss: 2.490716025131622

Epoch: 5| Step: 3
Training loss: 2.3745008245206853
Validation loss: 2.468972721128764

Epoch: 5| Step: 4
Training loss: 2.5866147909009505
Validation loss: 2.4525027269954505

Epoch: 5| Step: 5
Training loss: 2.9487983454500424
Validation loss: 2.436093569615878

Epoch: 5| Step: 6
Training loss: 2.8488626318740056
Validation loss: 2.440291551850963

Epoch: 5| Step: 7
Training loss: 3.1290458428989005
Validation loss: 2.44267813916673

Epoch: 5| Step: 8
Training loss: 2.606213144458009
Validation loss: 2.4401265437049102

Epoch: 5| Step: 9
Training loss: 2.2012044773886035
Validation loss: 2.4400962106015527

Epoch: 5| Step: 10
Training loss: 3.16974481921386
Validation loss: 2.427122775317202

Epoch: 122| Step: 0
Training loss: 2.9378903718026916
Validation loss: 2.441809609446414

Epoch: 5| Step: 1
Training loss: 3.4613249068938883
Validation loss: 2.4358139033146022

Epoch: 5| Step: 2
Training loss: 2.4540776632217702
Validation loss: 2.4463906329099934

Epoch: 5| Step: 3
Training loss: 2.648154184497078
Validation loss: 2.4631972093034675

Epoch: 5| Step: 4
Training loss: 2.7158420840326545
Validation loss: 2.473776789396027

Epoch: 5| Step: 5
Training loss: 2.7741504021585395
Validation loss: 2.4934196130563415

Epoch: 5| Step: 6
Training loss: 2.791140511496946
Validation loss: 2.5136580086896974

Epoch: 5| Step: 7
Training loss: 2.312965758562102
Validation loss: 2.508419504819177

Epoch: 5| Step: 8
Training loss: 3.4413788152460656
Validation loss: 2.514563094133594

Epoch: 5| Step: 9
Training loss: 2.1895783496610024
Validation loss: 2.5000865234251

Epoch: 5| Step: 10
Training loss: 2.4960439853154908
Validation loss: 2.50244178785976

Epoch: 123| Step: 0
Training loss: 2.8907652124989234
Validation loss: 2.4717025640064

Epoch: 5| Step: 1
Training loss: 2.5097422557885745
Validation loss: 2.4843271609087476

Epoch: 5| Step: 2
Training loss: 2.820074013218972
Validation loss: 2.458851350031045

Epoch: 5| Step: 3
Training loss: 2.217988864206853
Validation loss: 2.459623795510998

Epoch: 5| Step: 4
Training loss: 2.5909804299372605
Validation loss: 2.4376985055233504

Epoch: 5| Step: 5
Training loss: 2.883475374754639
Validation loss: 2.44730172131772

Epoch: 5| Step: 6
Training loss: 2.6653786369863885
Validation loss: 2.4513391102773547

Epoch: 5| Step: 7
Training loss: 3.2176544398994267
Validation loss: 2.4425257115078174

Epoch: 5| Step: 8
Training loss: 2.51915753572277
Validation loss: 2.441613923458998

Epoch: 5| Step: 9
Training loss: 2.866716143454659
Validation loss: 2.452058719095328

Epoch: 5| Step: 10
Training loss: 3.187309708244483
Validation loss: 2.4597446314455826

Epoch: 124| Step: 0
Training loss: 2.9190709331763487
Validation loss: 2.4638675162962884

Epoch: 5| Step: 1
Training loss: 2.872349387952261
Validation loss: 2.4315768083313873

Epoch: 5| Step: 2
Training loss: 3.048598833766615
Validation loss: 2.4472814608086284

Epoch: 5| Step: 3
Training loss: 2.4642550918698323
Validation loss: 2.4441373091969987

Epoch: 5| Step: 4
Training loss: 2.975442510440182
Validation loss: 2.4349862049952926

Epoch: 5| Step: 5
Training loss: 2.158505131230939
Validation loss: 2.4404258395616227

Epoch: 5| Step: 6
Training loss: 2.9494420251265354
Validation loss: 2.4469599582069907

Epoch: 5| Step: 7
Training loss: 3.15587681745319
Validation loss: 2.4579730551132326

Epoch: 5| Step: 8
Training loss: 2.570806670295368
Validation loss: 2.4597376369728448

Epoch: 5| Step: 9
Training loss: 2.5117777910902
Validation loss: 2.4564896534146303

Epoch: 5| Step: 10
Training loss: 2.5995711303007116
Validation loss: 2.452645274702726

Epoch: 125| Step: 0
Training loss: 2.9549301523903018
Validation loss: 2.4580425798248906

Epoch: 5| Step: 1
Training loss: 2.669562783751373
Validation loss: 2.465353836842059

Epoch: 5| Step: 2
Training loss: 2.4164236428849373
Validation loss: 2.4479446123282638

Epoch: 5| Step: 3
Training loss: 2.610119285196154
Validation loss: 2.463825404001907

Epoch: 5| Step: 4
Training loss: 3.0982525361025397
Validation loss: 2.470542299690611

Epoch: 5| Step: 5
Training loss: 2.4569826348715416
Validation loss: 2.448478752190939

Epoch: 5| Step: 6
Training loss: 2.5219743106389783
Validation loss: 2.4514657559232953

Epoch: 5| Step: 7
Training loss: 2.7635071830069498
Validation loss: 2.454839007957158

Epoch: 5| Step: 8
Training loss: 3.2679184156714154
Validation loss: 2.458454805532476

Epoch: 5| Step: 9
Training loss: 2.804273824547887
Validation loss: 2.476332541789683

Epoch: 5| Step: 10
Training loss: 2.6262116133704656
Validation loss: 2.4701634342369814

Epoch: 126| Step: 0
Training loss: 2.4808129259559433
Validation loss: 2.4530652307173875

Epoch: 5| Step: 1
Training loss: 2.956204539427315
Validation loss: 2.44036200680983

Epoch: 5| Step: 2
Training loss: 2.957125744135
Validation loss: 2.4430807786379325

Epoch: 5| Step: 3
Training loss: 2.9300299279048274
Validation loss: 2.433211349276302

Epoch: 5| Step: 4
Training loss: 2.8703132243147733
Validation loss: 2.4365170466016397

Epoch: 5| Step: 5
Training loss: 2.5623248901082514
Validation loss: 2.439219988851632

Epoch: 5| Step: 6
Training loss: 2.769255243706756
Validation loss: 2.4442169074075895

Epoch: 5| Step: 7
Training loss: 2.4550793874611414
Validation loss: 2.4330722105994878

Epoch: 5| Step: 8
Training loss: 2.3667678712867417
Validation loss: 2.4559848225916814

Epoch: 5| Step: 9
Training loss: 3.016765477650451
Validation loss: 2.4896894252059383

Epoch: 5| Step: 10
Training loss: 2.854302414684733
Validation loss: 2.513088313187177

Epoch: 127| Step: 0
Training loss: 2.497283508723652
Validation loss: 2.555565613292444

Epoch: 5| Step: 1
Training loss: 2.4299434024200735
Validation loss: 2.547671380454241

Epoch: 5| Step: 2
Training loss: 2.543742962951674
Validation loss: 2.5243601794629225

Epoch: 5| Step: 3
Training loss: 2.7141129861812705
Validation loss: 2.5143825897592222

Epoch: 5| Step: 4
Training loss: 2.935135234466121
Validation loss: 2.473178738015125

Epoch: 5| Step: 5
Training loss: 2.839834179134061
Validation loss: 2.485761333434356

Epoch: 5| Step: 6
Training loss: 2.923191854981933
Validation loss: 2.458121565062375

Epoch: 5| Step: 7
Training loss: 2.846291883694049
Validation loss: 2.439938400727599

Epoch: 5| Step: 8
Training loss: 3.001713898954522
Validation loss: 2.4345661888872296

Epoch: 5| Step: 9
Training loss: 2.928324715593135
Validation loss: 2.4302494826341774

Epoch: 5| Step: 10
Training loss: 2.5821535020935573
Validation loss: 2.4352955616685423

Epoch: 128| Step: 0
Training loss: 2.671520365776443
Validation loss: 2.4337464315975406

Epoch: 5| Step: 1
Training loss: 2.992162958348279
Validation loss: 2.4383586047610666

Epoch: 5| Step: 2
Training loss: 2.8192022362597338
Validation loss: 2.4354587565996564

Epoch: 5| Step: 3
Training loss: 2.3390499545304326
Validation loss: 2.4460514779737474

Epoch: 5| Step: 4
Training loss: 2.8034669563328625
Validation loss: 2.4459176914583196

Epoch: 5| Step: 5
Training loss: 2.633501817246696
Validation loss: 2.4561562413036153

Epoch: 5| Step: 6
Training loss: 2.869214913254987
Validation loss: 2.46102411131077

Epoch: 5| Step: 7
Training loss: 2.6915293805175087
Validation loss: 2.4573630797135713

Epoch: 5| Step: 8
Training loss: 3.256783082638953
Validation loss: 2.454718905460198

Epoch: 5| Step: 9
Training loss: 2.9335326329352625
Validation loss: 2.4387578913199786

Epoch: 5| Step: 10
Training loss: 2.2116130969361594
Validation loss: 2.436460452644913

Epoch: 129| Step: 0
Training loss: 2.9892868444359553
Validation loss: 2.4417309553897275

Epoch: 5| Step: 1
Training loss: 2.781518387435599
Validation loss: 2.446665492062408

Epoch: 5| Step: 2
Training loss: 2.5793229527695516
Validation loss: 2.445697745559

Epoch: 5| Step: 3
Training loss: 2.9283981537814
Validation loss: 2.4503250210351077

Epoch: 5| Step: 4
Training loss: 2.869370962184557
Validation loss: 2.46130657303037

Epoch: 5| Step: 5
Training loss: 2.301684475921228
Validation loss: 2.4666784028747157

Epoch: 5| Step: 6
Training loss: 2.670713562643007
Validation loss: 2.477293574881705

Epoch: 5| Step: 7
Training loss: 2.896683565828686
Validation loss: 2.484149275860086

Epoch: 5| Step: 8
Training loss: 2.506954913999535
Validation loss: 2.4639483764803956

Epoch: 5| Step: 9
Training loss: 3.07672660548828
Validation loss: 2.4493703278278245

Epoch: 5| Step: 10
Training loss: 2.4657558198558664
Validation loss: 2.4245706588128804

Epoch: 130| Step: 0
Training loss: 2.7335610186330817
Validation loss: 2.4237521219156726

Epoch: 5| Step: 1
Training loss: 2.6613414661605557
Validation loss: 2.4180482321226777

Epoch: 5| Step: 2
Training loss: 3.2328481710023023
Validation loss: 2.4282215661689306

Epoch: 5| Step: 3
Training loss: 2.6598837736737906
Validation loss: 2.4243641108730456

Epoch: 5| Step: 4
Training loss: 2.541390909546769
Validation loss: 2.424772322546532

Epoch: 5| Step: 5
Training loss: 3.0130541026730278
Validation loss: 2.434604156187695

Epoch: 5| Step: 6
Training loss: 2.8737876657985195
Validation loss: 2.444519739546636

Epoch: 5| Step: 7
Training loss: 2.6125410596915444
Validation loss: 2.4476143756145192

Epoch: 5| Step: 8
Training loss: 2.465000153671167
Validation loss: 2.4356505269322666

Epoch: 5| Step: 9
Training loss: 2.959011125601028
Validation loss: 2.4349944681630045

Epoch: 5| Step: 10
Training loss: 2.4557569440859806
Validation loss: 2.4377148199379546

Epoch: 131| Step: 0
Training loss: 2.394784039693609
Validation loss: 2.428543202788636

Epoch: 5| Step: 1
Training loss: 2.6381407117703364
Validation loss: 2.425142094324978

Epoch: 5| Step: 2
Training loss: 2.8779634875644957
Validation loss: 2.4275388776462603

Epoch: 5| Step: 3
Training loss: 3.317254307380057
Validation loss: 2.4440078040846394

Epoch: 5| Step: 4
Training loss: 2.478517067911075
Validation loss: 2.4648974103878394

Epoch: 5| Step: 5
Training loss: 2.465601978267047
Validation loss: 2.4584373555006307

Epoch: 5| Step: 6
Training loss: 2.438734671086519
Validation loss: 2.4543294954727246

Epoch: 5| Step: 7
Training loss: 2.6783235598727853
Validation loss: 2.4632791317141374

Epoch: 5| Step: 8
Training loss: 2.384814712556579
Validation loss: 2.458240245171081

Epoch: 5| Step: 9
Training loss: 3.331399086198019
Validation loss: 2.463171986968443

Epoch: 5| Step: 10
Training loss: 2.901364064864947
Validation loss: 2.461231382512037

Epoch: 132| Step: 0
Training loss: 3.139576143705004
Validation loss: 2.4525546587957927

Epoch: 5| Step: 1
Training loss: 2.870318208127064
Validation loss: 2.4390794134817835

Epoch: 5| Step: 2
Training loss: 2.51971993146461
Validation loss: 2.4355670826048104

Epoch: 5| Step: 3
Training loss: 2.353509040285135
Validation loss: 2.4501041037395326

Epoch: 5| Step: 4
Training loss: 2.753707294176255
Validation loss: 2.428522881845345

Epoch: 5| Step: 5
Training loss: 2.1178316494798
Validation loss: 2.441487761156096

Epoch: 5| Step: 6
Training loss: 2.726481614101755
Validation loss: 2.440508616695341

Epoch: 5| Step: 7
Training loss: 2.724794355559761
Validation loss: 2.4454107153758122

Epoch: 5| Step: 8
Training loss: 3.009015523924357
Validation loss: 2.4556910001714765

Epoch: 5| Step: 9
Training loss: 2.81480592929356
Validation loss: 2.433375699591329

Epoch: 5| Step: 10
Training loss: 2.97296068835708
Validation loss: 2.4355348596163755

Epoch: 133| Step: 0
Training loss: 2.9360835129920386
Validation loss: 2.424390017169909

Epoch: 5| Step: 1
Training loss: 2.6623880712058523
Validation loss: 2.42159970267279

Epoch: 5| Step: 2
Training loss: 3.0446838325009344
Validation loss: 2.4294857905149234

Epoch: 5| Step: 3
Training loss: 2.97216969341631
Validation loss: 2.4251973303076912

Epoch: 5| Step: 4
Training loss: 2.7158369923188794
Validation loss: 2.426184098463233

Epoch: 5| Step: 5
Training loss: 2.04981562087663
Validation loss: 2.4238246187799155

Epoch: 5| Step: 6
Training loss: 3.1264914958770484
Validation loss: 2.4216939127395545

Epoch: 5| Step: 7
Training loss: 2.735554990929343
Validation loss: 2.4437303055375974

Epoch: 5| Step: 8
Training loss: 2.73459471773491
Validation loss: 2.4755967239656527

Epoch: 5| Step: 9
Training loss: 2.757803336066131
Validation loss: 2.5136628011220097

Epoch: 5| Step: 10
Training loss: 2.340672214169376
Validation loss: 2.5229089385861734

Epoch: 134| Step: 0
Training loss: 2.7159586641090336
Validation loss: 2.500767655594885

Epoch: 5| Step: 1
Training loss: 2.335893407297068
Validation loss: 2.4800531820985197

Epoch: 5| Step: 2
Training loss: 3.0460034811259247
Validation loss: 2.454816918373881

Epoch: 5| Step: 3
Training loss: 2.4996249871318588
Validation loss: 2.4354253742677066

Epoch: 5| Step: 4
Training loss: 3.3276600400984866
Validation loss: 2.4182603243351526

Epoch: 5| Step: 5
Training loss: 3.0356488901996412
Validation loss: 2.418483074493694

Epoch: 5| Step: 6
Training loss: 2.355057359389708
Validation loss: 2.41882213631121

Epoch: 5| Step: 7
Training loss: 2.6064636984470013
Validation loss: 2.4165113913355585

Epoch: 5| Step: 8
Training loss: 2.6304886973808386
Validation loss: 2.422769487840233

Epoch: 5| Step: 9
Training loss: 2.7651548686468392
Validation loss: 2.4153197151865697

Epoch: 5| Step: 10
Training loss: 2.6618653127472074
Validation loss: 2.4265951533289956

Epoch: 135| Step: 0
Training loss: 2.53196103505651
Validation loss: 2.4326143852817097

Epoch: 5| Step: 1
Training loss: 3.014141290958802
Validation loss: 2.436862261579636

Epoch: 5| Step: 2
Training loss: 2.7533391273874765
Validation loss: 2.4295501944521867

Epoch: 5| Step: 3
Training loss: 2.446761899163613
Validation loss: 2.4585191049213866

Epoch: 5| Step: 4
Training loss: 2.6195379378281483
Validation loss: 2.4717796228565283

Epoch: 5| Step: 5
Training loss: 2.658310932156719
Validation loss: 2.487173778150575

Epoch: 5| Step: 6
Training loss: 2.773776095500935
Validation loss: 2.503777843842697

Epoch: 5| Step: 7
Training loss: 2.9097541275237675
Validation loss: 2.491196590107683

Epoch: 5| Step: 8
Training loss: 2.6334117354620483
Validation loss: 2.463424099832906

Epoch: 5| Step: 9
Training loss: 2.7927584055407926
Validation loss: 2.4370527422434245

Epoch: 5| Step: 10
Training loss: 2.9520046793479326
Validation loss: 2.423406310949976

Epoch: 136| Step: 0
Training loss: 2.4071594105111327
Validation loss: 2.4223582229941614

Epoch: 5| Step: 1
Training loss: 2.727119804198678
Validation loss: 2.4246898836371718

Epoch: 5| Step: 2
Training loss: 2.635668374406422
Validation loss: 2.4219227236022838

Epoch: 5| Step: 3
Training loss: 2.986944081444899
Validation loss: 2.4228538194450864

Epoch: 5| Step: 4
Training loss: 2.7815647590061463
Validation loss: 2.4133060166206604

Epoch: 5| Step: 5
Training loss: 3.1580465510333524
Validation loss: 2.4226416161467785

Epoch: 5| Step: 6
Training loss: 2.81533848260506
Validation loss: 2.4197285053227295

Epoch: 5| Step: 7
Training loss: 2.4364272471305815
Validation loss: 2.4170849602177014

Epoch: 5| Step: 8
Training loss: 2.6693454837439967
Validation loss: 2.4188700552765523

Epoch: 5| Step: 9
Training loss: 2.673279510235275
Validation loss: 2.4314647998607652

Epoch: 5| Step: 10
Training loss: 2.6844828325313457
Validation loss: 2.4684308667325765

Epoch: 137| Step: 0
Training loss: 2.5416035774614025
Validation loss: 2.4811095647873183

Epoch: 5| Step: 1
Training loss: 2.6811766643320776
Validation loss: 2.518758322680813

Epoch: 5| Step: 2
Training loss: 2.950083463102361
Validation loss: 2.496102999694562

Epoch: 5| Step: 3
Training loss: 2.8411816747113905
Validation loss: 2.52345250323759

Epoch: 5| Step: 4
Training loss: 2.3489008950754977
Validation loss: 2.4974322350328024

Epoch: 5| Step: 5
Training loss: 2.866757727071239
Validation loss: 2.4905231318870666

Epoch: 5| Step: 6
Training loss: 3.2553266742811884
Validation loss: 2.4524220089696183

Epoch: 5| Step: 7
Training loss: 3.1996269664297117
Validation loss: 2.425020142583537

Epoch: 5| Step: 8
Training loss: 2.5811791103133124
Validation loss: 2.4176990901313333

Epoch: 5| Step: 9
Training loss: 2.391962512478466
Validation loss: 2.4346515370865927

Epoch: 5| Step: 10
Training loss: 2.4338191679621737
Validation loss: 2.4321914625509424

Epoch: 138| Step: 0
Training loss: 2.828979026028987
Validation loss: 2.4224381442122427

Epoch: 5| Step: 1
Training loss: 2.8442648955970475
Validation loss: 2.4150129964472797

Epoch: 5| Step: 2
Training loss: 2.8636189634997242
Validation loss: 2.4249945168263514

Epoch: 5| Step: 3
Training loss: 2.549194216105988
Validation loss: 2.4218784370622912

Epoch: 5| Step: 4
Training loss: 2.6439171307629974
Validation loss: 2.451679997336979

Epoch: 5| Step: 5
Training loss: 2.8686747422662795
Validation loss: 2.4700334960498314

Epoch: 5| Step: 6
Training loss: 2.1619511299150287
Validation loss: 2.4912316835473276

Epoch: 5| Step: 7
Training loss: 3.1715123763236095
Validation loss: 2.506563704965246

Epoch: 5| Step: 8
Training loss: 2.5880272480150794
Validation loss: 2.496925340908602

Epoch: 5| Step: 9
Training loss: 2.625443194078293
Validation loss: 2.4938916091132843

Epoch: 5| Step: 10
Training loss: 2.755647928303023
Validation loss: 2.453232910633706

Epoch: 139| Step: 0
Training loss: 2.63028901734939
Validation loss: 2.434654399612447

Epoch: 5| Step: 1
Training loss: 2.460752062395854
Validation loss: 2.429202973133108

Epoch: 5| Step: 2
Training loss: 2.7983317923375925
Validation loss: 2.419033994285305

Epoch: 5| Step: 3
Training loss: 2.7514342122712634
Validation loss: 2.425531402303235

Epoch: 5| Step: 4
Training loss: 2.9358593843552914
Validation loss: 2.4201024915779947

Epoch: 5| Step: 5
Training loss: 2.9693599676620064
Validation loss: 2.4236141738835424

Epoch: 5| Step: 6
Training loss: 2.5365216027318764
Validation loss: 2.4188855539506737

Epoch: 5| Step: 7
Training loss: 2.623982822798122
Validation loss: 2.4178018774940444

Epoch: 5| Step: 8
Training loss: 2.818678279395649
Validation loss: 2.4229840542071597

Epoch: 5| Step: 9
Training loss: 2.912017022554717
Validation loss: 2.4305128047677784

Epoch: 5| Step: 10
Training loss: 2.4540042152026595
Validation loss: 2.4483181360870265

Epoch: 140| Step: 0
Training loss: 3.0431155755756363
Validation loss: 2.4707006606612114

Epoch: 5| Step: 1
Training loss: 1.984940095473208
Validation loss: 2.4915874349115894

Epoch: 5| Step: 2
Training loss: 2.505838252845995
Validation loss: 2.5481864159427854

Epoch: 5| Step: 3
Training loss: 2.890900469876713
Validation loss: 2.553370825590437

Epoch: 5| Step: 4
Training loss: 2.919930366835478
Validation loss: 2.50917226586708

Epoch: 5| Step: 5
Training loss: 2.9378093800052905
Validation loss: 2.4483207182410287

Epoch: 5| Step: 6
Training loss: 2.1120503731485765
Validation loss: 2.44159538077905

Epoch: 5| Step: 7
Training loss: 2.8065785273064683
Validation loss: 2.428477563945925

Epoch: 5| Step: 8
Training loss: 3.3076957555899624
Validation loss: 2.4234573122786403

Epoch: 5| Step: 9
Training loss: 2.85038469629454
Validation loss: 2.440852541376371

Epoch: 5| Step: 10
Training loss: 2.335684159744119
Validation loss: 2.4300675583065465

Epoch: 141| Step: 0
Training loss: 2.5294407159267807
Validation loss: 2.4249580070547974

Epoch: 5| Step: 1
Training loss: 2.897497636532416
Validation loss: 2.426456392801016

Epoch: 5| Step: 2
Training loss: 2.8255358905068753
Validation loss: 2.430254254942095

Epoch: 5| Step: 3
Training loss: 2.432055530616829
Validation loss: 2.4258552957284603

Epoch: 5| Step: 4
Training loss: 2.6131241413325808
Validation loss: 2.4312256274873483

Epoch: 5| Step: 5
Training loss: 2.8145061543516476
Validation loss: 2.4713193483671687

Epoch: 5| Step: 6
Training loss: 2.4714369818609696
Validation loss: 2.4737385983941627

Epoch: 5| Step: 7
Training loss: 3.1608668637644857
Validation loss: 2.489797009338575

Epoch: 5| Step: 8
Training loss: 2.714683033968156
Validation loss: 2.4768674893054308

Epoch: 5| Step: 9
Training loss: 2.6207900120035985
Validation loss: 2.4763868331781786

Epoch: 5| Step: 10
Training loss: 2.8466187145056723
Validation loss: 2.4834112009659366

Epoch: 142| Step: 0
Training loss: 2.7808346384617164
Validation loss: 2.472021030157165

Epoch: 5| Step: 1
Training loss: 2.771901653725035
Validation loss: 2.4703163203138896

Epoch: 5| Step: 2
Training loss: 2.81661398196936
Validation loss: 2.4793028290409964

Epoch: 5| Step: 3
Training loss: 2.866387445321085
Validation loss: 2.4513804216074138

Epoch: 5| Step: 4
Training loss: 3.146922312497332
Validation loss: 2.4750670463634883

Epoch: 5| Step: 5
Training loss: 2.3310598014580477
Validation loss: 2.4575000513099496

Epoch: 5| Step: 6
Training loss: 2.1988898077015078
Validation loss: 2.4533517154193984

Epoch: 5| Step: 7
Training loss: 2.536048955342551
Validation loss: 2.4669203878294947

Epoch: 5| Step: 8
Training loss: 2.5013946457826672
Validation loss: 2.449845542751844

Epoch: 5| Step: 9
Training loss: 2.975804990962661
Validation loss: 2.473062916461915

Epoch: 5| Step: 10
Training loss: 2.69162540069536
Validation loss: 2.4707417748491705

Epoch: 143| Step: 0
Training loss: 3.1447414162104175
Validation loss: 2.47468358927229

Epoch: 5| Step: 1
Training loss: 2.487745194355438
Validation loss: 2.4971462020074835

Epoch: 5| Step: 2
Training loss: 2.6747538800965964
Validation loss: 2.479560346843118

Epoch: 5| Step: 3
Training loss: 2.5335868127229744
Validation loss: 2.478954660463211

Epoch: 5| Step: 4
Training loss: 2.8273302510622593
Validation loss: 2.503338014799197

Epoch: 5| Step: 5
Training loss: 2.7780194325766403
Validation loss: 2.514063970477071

Epoch: 5| Step: 6
Training loss: 3.0446272946724293
Validation loss: 2.5224117417986016

Epoch: 5| Step: 7
Training loss: 2.884560982606873
Validation loss: 2.514382098826342

Epoch: 5| Step: 8
Training loss: 2.861490436415994
Validation loss: 2.491724248518379

Epoch: 5| Step: 9
Training loss: 2.026604254769648
Validation loss: 2.456958705186482

Epoch: 5| Step: 10
Training loss: 2.2477365340876503
Validation loss: 2.43619257652749

Epoch: 144| Step: 0
Training loss: 2.540145032902155
Validation loss: 2.4254657918787887

Epoch: 5| Step: 1
Training loss: 2.2547424986456823
Validation loss: 2.4301724935901086

Epoch: 5| Step: 2
Training loss: 2.5342720735207087
Validation loss: 2.4310391509775915

Epoch: 5| Step: 3
Training loss: 2.7824660653703837
Validation loss: 2.4469885042846333

Epoch: 5| Step: 4
Training loss: 3.19379148213719
Validation loss: 2.434887554915111

Epoch: 5| Step: 5
Training loss: 2.9462524856861165
Validation loss: 2.4338255490913947

Epoch: 5| Step: 6
Training loss: 2.761509651350941
Validation loss: 2.4623222854956492

Epoch: 5| Step: 7
Training loss: 3.2525533769407433
Validation loss: 2.4790103091283724

Epoch: 5| Step: 8
Training loss: 2.79482496774696
Validation loss: 2.4916366290816647

Epoch: 5| Step: 9
Training loss: 2.487942898680745
Validation loss: 2.45745581024705

Epoch: 5| Step: 10
Training loss: 2.1435192061770185
Validation loss: 2.460120284935366

Epoch: 145| Step: 0
Training loss: 2.8138788022455423
Validation loss: 2.4538039759699166

Epoch: 5| Step: 1
Training loss: 2.5630343740646007
Validation loss: 2.446846421208095

Epoch: 5| Step: 2
Training loss: 2.9884960222043873
Validation loss: 2.438733989897465

Epoch: 5| Step: 3
Training loss: 2.5370871034133606
Validation loss: 2.444027228453316

Epoch: 5| Step: 4
Training loss: 2.8690173055739168
Validation loss: 2.4453701481777315

Epoch: 5| Step: 5
Training loss: 2.1776156953367938
Validation loss: 2.4218519481629674

Epoch: 5| Step: 6
Training loss: 2.9763664120942788
Validation loss: 2.44492977737627

Epoch: 5| Step: 7
Training loss: 2.4180103600392875
Validation loss: 2.455172013163582

Epoch: 5| Step: 8
Training loss: 2.818886689722492
Validation loss: 2.4496987905004404

Epoch: 5| Step: 9
Training loss: 2.7831825657135387
Validation loss: 2.439289741178106

Epoch: 5| Step: 10
Training loss: 2.717391628431218
Validation loss: 2.458094736669294

Epoch: 146| Step: 0
Training loss: 2.164940611132658
Validation loss: 2.4781310742522886

Epoch: 5| Step: 1
Training loss: 2.7358277739476975
Validation loss: 2.474924426904959

Epoch: 5| Step: 2
Training loss: 2.7493937430986204
Validation loss: 2.4529132149387016

Epoch: 5| Step: 3
Training loss: 2.5575036442079058
Validation loss: 2.459020196084475

Epoch: 5| Step: 4
Training loss: 2.8263952540003916
Validation loss: 2.4511388258991236

Epoch: 5| Step: 5
Training loss: 2.9661707867294766
Validation loss: 2.4689844263420824

Epoch: 5| Step: 6
Training loss: 2.4881086783699056
Validation loss: 2.484882322801483

Epoch: 5| Step: 7
Training loss: 2.6135975371179576
Validation loss: 2.499714126444385

Epoch: 5| Step: 8
Training loss: 3.057700308026615
Validation loss: 2.489201914022649

Epoch: 5| Step: 9
Training loss: 2.412112933322274
Validation loss: 2.459582633060328

Epoch: 5| Step: 10
Training loss: 2.987976776768163
Validation loss: 2.4411655096990135

Epoch: 147| Step: 0
Training loss: 2.9180357490007363
Validation loss: 2.4376497719615013

Epoch: 5| Step: 1
Training loss: 2.457357751837106
Validation loss: 2.451224944654666

Epoch: 5| Step: 2
Training loss: 2.4357675117459086
Validation loss: 2.4516339520080814

Epoch: 5| Step: 3
Training loss: 2.598197800252055
Validation loss: 2.446773036919984

Epoch: 5| Step: 4
Training loss: 2.809535265330373
Validation loss: 2.4344884707482115

Epoch: 5| Step: 5
Training loss: 2.3894943854870063
Validation loss: 2.439801139864394

Epoch: 5| Step: 6
Training loss: 2.837501115840743
Validation loss: 2.4671164025179535

Epoch: 5| Step: 7
Training loss: 3.2037052280305613
Validation loss: 2.494313123614704

Epoch: 5| Step: 8
Training loss: 2.3885032862560207
Validation loss: 2.525422237469202

Epoch: 5| Step: 9
Training loss: 2.578168371587123
Validation loss: 2.5525493250804714

Epoch: 5| Step: 10
Training loss: 3.220787218429135
Validation loss: 2.595838453920221

Epoch: 148| Step: 0
Training loss: 2.9728766421052195
Validation loss: 2.6662491210654826

Epoch: 5| Step: 1
Training loss: 2.937143344735979
Validation loss: 2.6537369964586905

Epoch: 5| Step: 2
Training loss: 3.003924504932747
Validation loss: 2.6636958664021155

Epoch: 5| Step: 3
Training loss: 3.182235858800406
Validation loss: 2.67256462208513

Epoch: 5| Step: 4
Training loss: 2.618728867038136
Validation loss: 2.608716917475164

Epoch: 5| Step: 5
Training loss: 2.032959086992049
Validation loss: 2.541655786720631

Epoch: 5| Step: 6
Training loss: 3.056911429697248
Validation loss: 2.540637599927598

Epoch: 5| Step: 7
Training loss: 2.696733536883356
Validation loss: 2.504716458318036

Epoch: 5| Step: 8
Training loss: 2.847984933395394
Validation loss: 2.4730771866104564

Epoch: 5| Step: 9
Training loss: 2.372597533332567
Validation loss: 2.477312186686175

Epoch: 5| Step: 10
Training loss: 2.5311127613681097
Validation loss: 2.4709330032776613

Epoch: 149| Step: 0
Training loss: 2.444605325934017
Validation loss: 2.4687091704076822

Epoch: 5| Step: 1
Training loss: 2.698880959779181
Validation loss: 2.4619373056965737

Epoch: 5| Step: 2
Training loss: 2.533115594273707
Validation loss: 2.469039829365618

Epoch: 5| Step: 3
Training loss: 2.5487935147913574
Validation loss: 2.4838922451689016

Epoch: 5| Step: 4
Training loss: 3.048670625986742
Validation loss: 2.5139836397521624

Epoch: 5| Step: 5
Training loss: 2.871097569884789
Validation loss: 2.500163475967535

Epoch: 5| Step: 6
Training loss: 2.670436628122929
Validation loss: 2.525264203652095

Epoch: 5| Step: 7
Training loss: 2.8831150133980015
Validation loss: 2.5305898315187774

Epoch: 5| Step: 8
Training loss: 2.575384914924752
Validation loss: 2.531416133146831

Epoch: 5| Step: 9
Training loss: 2.370344819846244
Validation loss: 2.5450926673738805

Epoch: 5| Step: 10
Training loss: 3.0869979388418876
Validation loss: 2.526220175843533

Epoch: 150| Step: 0
Training loss: 2.0002538996704824
Validation loss: 2.5381280509463204

Epoch: 5| Step: 1
Training loss: 2.7367440560379914
Validation loss: 2.535583510651511

Epoch: 5| Step: 2
Training loss: 2.9151229769642986
Validation loss: 2.525555085507178

Epoch: 5| Step: 3
Training loss: 2.656170473591225
Validation loss: 2.5138899564207273

Epoch: 5| Step: 4
Training loss: 2.1230517039029144
Validation loss: 2.5034423048147407

Epoch: 5| Step: 5
Training loss: 2.6602312657202343
Validation loss: 2.491330640638893

Epoch: 5| Step: 6
Training loss: 2.8437959436750546
Validation loss: 2.4956256990519665

Epoch: 5| Step: 7
Training loss: 3.1572042099231936
Validation loss: 2.460822619133043

Epoch: 5| Step: 8
Training loss: 2.3576763176947244
Validation loss: 2.467131529004198

Epoch: 5| Step: 9
Training loss: 2.80769582090972
Validation loss: 2.4842692903666626

Epoch: 5| Step: 10
Training loss: 3.255346741849164
Validation loss: 2.471577346354277

Epoch: 151| Step: 0
Training loss: 2.2192109394802224
Validation loss: 2.4722956270165772

Epoch: 5| Step: 1
Training loss: 3.103239667758015
Validation loss: 2.4876051794530034

Epoch: 5| Step: 2
Training loss: 2.6117682531870456
Validation loss: 2.5145762591263296

Epoch: 5| Step: 3
Training loss: 2.059886548149572
Validation loss: 2.5369746441222434

Epoch: 5| Step: 4
Training loss: 2.8262571626460247
Validation loss: 2.583944851334902

Epoch: 5| Step: 5
Training loss: 3.033981193972035
Validation loss: 2.6239788942637494

Epoch: 5| Step: 6
Training loss: 2.772441072517112
Validation loss: 2.582807595234977

Epoch: 5| Step: 7
Training loss: 2.874007343917309
Validation loss: 2.5768351948360544

Epoch: 5| Step: 8
Training loss: 3.033844614082109
Validation loss: 2.498705245648945

Epoch: 5| Step: 9
Training loss: 2.8953691471855745
Validation loss: 2.4713992225345773

Epoch: 5| Step: 10
Training loss: 1.9382803176207262
Validation loss: 2.4558027711823747

Epoch: 152| Step: 0
Training loss: 2.8666857038649445
Validation loss: 2.4445745770114713

Epoch: 5| Step: 1
Training loss: 2.8515303936548704
Validation loss: 2.459522378628879

Epoch: 5| Step: 2
Training loss: 3.02797262243394
Validation loss: 2.4543918494262793

Epoch: 5| Step: 3
Training loss: 1.968069473602656
Validation loss: 2.4709387065145725

Epoch: 5| Step: 4
Training loss: 2.3390991860406927
Validation loss: 2.48018681573782

Epoch: 5| Step: 5
Training loss: 2.8972111084154832
Validation loss: 2.471400587652003

Epoch: 5| Step: 6
Training loss: 2.67314519304199
Validation loss: 2.4911443339053014

Epoch: 5| Step: 7
Training loss: 2.7451471512338808
Validation loss: 2.5115549135551287

Epoch: 5| Step: 8
Training loss: 2.5100247616705333
Validation loss: 2.5066778763359174

Epoch: 5| Step: 9
Training loss: 2.997858554753149
Validation loss: 2.4957538569553024

Epoch: 5| Step: 10
Training loss: 2.8492114264412667
Validation loss: 2.4956630682058614

Epoch: 153| Step: 0
Training loss: 2.6735843299306064
Validation loss: 2.5132031888416306

Epoch: 5| Step: 1
Training loss: 2.364374888190948
Validation loss: 2.4963916764646714

Epoch: 5| Step: 2
Training loss: 2.4618384271342215
Validation loss: 2.4931343556626837

Epoch: 5| Step: 3
Training loss: 2.466295011547559
Validation loss: 2.4816505516523653

Epoch: 5| Step: 4
Training loss: 2.8265943231262063
Validation loss: 2.475307375450322

Epoch: 5| Step: 5
Training loss: 2.7640076989261266
Validation loss: 2.5176322407600322

Epoch: 5| Step: 6
Training loss: 2.6805367861690717
Validation loss: 2.49849096612957

Epoch: 5| Step: 7
Training loss: 2.519410312322782
Validation loss: 2.52770351645052

Epoch: 5| Step: 8
Training loss: 2.0594295419234356
Validation loss: 2.493319299388691

Epoch: 5| Step: 9
Training loss: 3.4371157344703356
Validation loss: 2.4883064599335394

Epoch: 5| Step: 10
Training loss: 2.8662704955481613
Validation loss: 2.466258072651183

Epoch: 154| Step: 0
Training loss: 2.7704418068285053
Validation loss: 2.498182066468091

Epoch: 5| Step: 1
Training loss: 2.8872674361202955
Validation loss: 2.4845812982703843

Epoch: 5| Step: 2
Training loss: 2.6107558748273565
Validation loss: 2.500522926973662

Epoch: 5| Step: 3
Training loss: 2.7402005292089666
Validation loss: 2.5022088434625753

Epoch: 5| Step: 4
Training loss: 2.351652530201419
Validation loss: 2.511507451831599

Epoch: 5| Step: 5
Training loss: 2.434091189567149
Validation loss: 2.5084264422427363

Epoch: 5| Step: 6
Training loss: 2.620511804779371
Validation loss: 2.4921215983592986

Epoch: 5| Step: 7
Training loss: 2.419052546699606
Validation loss: 2.4826819616172005

Epoch: 5| Step: 8
Training loss: 2.545424440286389
Validation loss: 2.495093828018941

Epoch: 5| Step: 9
Training loss: 2.6744645269055765
Validation loss: 2.498080126564744

Epoch: 5| Step: 10
Training loss: 2.9247023015259637
Validation loss: 2.5136997583315246

Epoch: 155| Step: 0
Training loss: 2.8172799923016516
Validation loss: 2.5034926689494443

Epoch: 5| Step: 1
Training loss: 2.5606238777692636
Validation loss: 2.510557541085619

Epoch: 5| Step: 2
Training loss: 2.963812486624547
Validation loss: 2.5010291196359398

Epoch: 5| Step: 3
Training loss: 2.3814796597326753
Validation loss: 2.509116334920563

Epoch: 5| Step: 4
Training loss: 2.973523929400236
Validation loss: 2.519964463158683

Epoch: 5| Step: 5
Training loss: 2.3796830435878333
Validation loss: 2.5513978417139995

Epoch: 5| Step: 6
Training loss: 2.259618122954512
Validation loss: 2.5802262489829904

Epoch: 5| Step: 7
Training loss: 2.3045448388380487
Validation loss: 2.5361297081889123

Epoch: 5| Step: 8
Training loss: 2.506197590648591
Validation loss: 2.5172555681299937

Epoch: 5| Step: 9
Training loss: 2.8584886855308027
Validation loss: 2.452802432174054

Epoch: 5| Step: 10
Training loss: 2.5805833597627825
Validation loss: 2.4778283563017562

Epoch: 156| Step: 0
Training loss: 3.2323798323833075
Validation loss: 2.486762633795077

Epoch: 5| Step: 1
Training loss: 2.6202924387555693
Validation loss: 2.4569087196276436

Epoch: 5| Step: 2
Training loss: 2.5730329685463733
Validation loss: 2.4561450229324007

Epoch: 5| Step: 3
Training loss: 1.7490467472535915
Validation loss: 2.4856425048583373

Epoch: 5| Step: 4
Training loss: 2.4559538257433404
Validation loss: 2.4631396047085685

Epoch: 5| Step: 5
Training loss: 2.5001159641073403
Validation loss: 2.508067474881823

Epoch: 5| Step: 6
Training loss: 2.7569708471904995
Validation loss: 2.5624649241538195

Epoch: 5| Step: 7
Training loss: 2.914201584838495
Validation loss: 2.626297554361463

Epoch: 5| Step: 8
Training loss: 2.856110423744942
Validation loss: 2.612442195578828

Epoch: 5| Step: 9
Training loss: 2.6034213919731375
Validation loss: 2.5133729297297296

Epoch: 5| Step: 10
Training loss: 2.2820494831614435
Validation loss: 2.4622069215703886

Epoch: 157| Step: 0
Training loss: 2.7384113275430186
Validation loss: 2.4389677054179546

Epoch: 5| Step: 1
Training loss: 2.6630694644475845
Validation loss: 2.4305170043450657

Epoch: 5| Step: 2
Training loss: 2.4065115650247053
Validation loss: 2.426569887563137

Epoch: 5| Step: 3
Training loss: 2.7504050216655593
Validation loss: 2.4374822253601196

Epoch: 5| Step: 4
Training loss: 2.462504345265539
Validation loss: 2.4633568198762177

Epoch: 5| Step: 5
Training loss: 2.0520473677166975
Validation loss: 2.5283031033446854

Epoch: 5| Step: 6
Training loss: 2.2720836265512943
Validation loss: 2.5380244033815402

Epoch: 5| Step: 7
Training loss: 2.7042904144170263
Validation loss: 2.5362659475802936

Epoch: 5| Step: 8
Training loss: 3.020394462187738
Validation loss: 2.543394377711585

Epoch: 5| Step: 9
Training loss: 2.716161438314073
Validation loss: 2.527640439461182

Epoch: 5| Step: 10
Training loss: 2.7282504128276046
Validation loss: 2.5344978267655254

Epoch: 158| Step: 0
Training loss: 2.4339577783763926
Validation loss: 2.5348088444688064

Epoch: 5| Step: 1
Training loss: 2.6461638196661696
Validation loss: 2.5223609657062247

Epoch: 5| Step: 2
Training loss: 2.5612204543755825
Validation loss: 2.51922187835882

Epoch: 5| Step: 3
Training loss: 2.2312339632542564
Validation loss: 2.521220932440009

Epoch: 5| Step: 4
Training loss: 2.280405593734596
Validation loss: 2.5239639548350903

Epoch: 5| Step: 5
Training loss: 2.5923007455178504
Validation loss: 2.527925986381566

Epoch: 5| Step: 6
Training loss: 2.276213848197715
Validation loss: 2.538748916432913

Epoch: 5| Step: 7
Training loss: 2.656922468444726
Validation loss: 2.5527921551576753

Epoch: 5| Step: 8
Training loss: 3.12569587589022
Validation loss: 2.5533975705899947

Epoch: 5| Step: 9
Training loss: 2.7656786207615305
Validation loss: 2.553284982269367

Epoch: 5| Step: 10
Training loss: 2.514863177269197
Validation loss: 2.542850572352102

Epoch: 159| Step: 0
Training loss: 2.552950580666982
Validation loss: 2.5167413383733024

Epoch: 5| Step: 1
Training loss: 2.7237564119050814
Validation loss: 2.4981738137341045

Epoch: 5| Step: 2
Training loss: 2.695171496255122
Validation loss: 2.4724906141836933

Epoch: 5| Step: 3
Training loss: 2.4646988476994656
Validation loss: 2.4636666968329672

Epoch: 5| Step: 4
Training loss: 2.660947259155942
Validation loss: 2.460481118059482

Epoch: 5| Step: 5
Training loss: 2.823014505152474
Validation loss: 2.44993838516753

Epoch: 5| Step: 6
Training loss: 2.7680317379780193
Validation loss: 2.458403509343558

Epoch: 5| Step: 7
Training loss: 2.000373924586422
Validation loss: 2.459658963157554

Epoch: 5| Step: 8
Training loss: 2.0873106819238805
Validation loss: 2.47925069647078

Epoch: 5| Step: 9
Training loss: 2.850279135168425
Validation loss: 2.540844953080439

Epoch: 5| Step: 10
Training loss: 2.642840928502955
Validation loss: 2.61921444677715

Epoch: 160| Step: 0
Training loss: 2.770892713861758
Validation loss: 2.635655287073158

Epoch: 5| Step: 1
Training loss: 2.4761591922876316
Validation loss: 2.6515437717888095

Epoch: 5| Step: 2
Training loss: 2.0168058499733723
Validation loss: 2.637181394301332

Epoch: 5| Step: 3
Training loss: 2.737214886175246
Validation loss: 2.557852539672812

Epoch: 5| Step: 4
Training loss: 2.7625791512451787
Validation loss: 2.5112341076395954

Epoch: 5| Step: 5
Training loss: 2.276957196100967
Validation loss: 2.490497742635398

Epoch: 5| Step: 6
Training loss: 2.4936520091143057
Validation loss: 2.4811116716112616

Epoch: 5| Step: 7
Training loss: 2.2348463721674343
Validation loss: 2.488574519001706

Epoch: 5| Step: 8
Training loss: 2.4761447493991153
Validation loss: 2.513000825528891

Epoch: 5| Step: 9
Training loss: 2.8558624872820206
Validation loss: 2.514285877190089

Epoch: 5| Step: 10
Training loss: 2.7975166479847715
Validation loss: 2.499840881042005

Epoch: 161| Step: 0
Training loss: 2.7501609061590604
Validation loss: 2.4982175943715683

Epoch: 5| Step: 1
Training loss: 3.013853986062397
Validation loss: 2.4933183822306404

Epoch: 5| Step: 2
Training loss: 2.6339262918457806
Validation loss: 2.474227474751638

Epoch: 5| Step: 3
Training loss: 2.9646232432513697
Validation loss: 2.456286490900252

Epoch: 5| Step: 4
Training loss: 2.4305224195371165
Validation loss: 2.43084774032709

Epoch: 5| Step: 5
Training loss: 3.1174937315314195
Validation loss: 2.4196090370889536

Epoch: 5| Step: 6
Training loss: 2.2457247489011536
Validation loss: 2.4387771325465253

Epoch: 5| Step: 7
Training loss: 2.2704961567241146
Validation loss: 2.4834049296982066

Epoch: 5| Step: 8
Training loss: 2.295117594712648
Validation loss: 2.576543232882257

Epoch: 5| Step: 9
Training loss: 1.9189455609891697
Validation loss: 2.581040985536764

Epoch: 5| Step: 10
Training loss: 2.1571997057588623
Validation loss: 2.6113139663329505

Epoch: 162| Step: 0
Training loss: 2.3019312007111803
Validation loss: 2.5793683456898444

Epoch: 5| Step: 1
Training loss: 2.228901594807617
Validation loss: 2.5516487607107106

Epoch: 5| Step: 2
Training loss: 2.412117875427836
Validation loss: 2.5389723309455157

Epoch: 5| Step: 3
Training loss: 2.6609539790827625
Validation loss: 2.502936581757333

Epoch: 5| Step: 4
Training loss: 2.518044013574202
Validation loss: 2.4855846654564058

Epoch: 5| Step: 5
Training loss: 2.243436990225883
Validation loss: 2.4967003099034093

Epoch: 5| Step: 6
Training loss: 2.920311494177027
Validation loss: 2.473819259767286

Epoch: 5| Step: 7
Training loss: 3.203619197775458
Validation loss: 2.499873389863006

Epoch: 5| Step: 8
Training loss: 2.3479181483167313
Validation loss: 2.4926229168507072

Epoch: 5| Step: 9
Training loss: 2.3886304525805917
Validation loss: 2.51807173141066

Epoch: 5| Step: 10
Training loss: 2.357277853927117
Validation loss: 2.5066448728021546

Epoch: 163| Step: 0
Training loss: 1.9524719367165746
Validation loss: 2.5101727810689174

Epoch: 5| Step: 1
Training loss: 2.220451454791556
Validation loss: 2.5222434355447665

Epoch: 5| Step: 2
Training loss: 2.817694465946241
Validation loss: 2.5366375203255953

Epoch: 5| Step: 3
Training loss: 2.300623216366666
Validation loss: 2.5277412146264435

Epoch: 5| Step: 4
Training loss: 2.5338580976705973
Validation loss: 2.5268088539599005

Epoch: 5| Step: 5
Training loss: 2.9395423444723994
Validation loss: 2.581110055801607

Epoch: 5| Step: 6
Training loss: 2.601030633302345
Validation loss: 2.5088395870232105

Epoch: 5| Step: 7
Training loss: 2.681836481575622
Validation loss: 2.4848234814446206

Epoch: 5| Step: 8
Training loss: 2.8481965566272116
Validation loss: 2.4501794965702577

Epoch: 5| Step: 9
Training loss: 2.331414069162672
Validation loss: 2.4150814766900397

Epoch: 5| Step: 10
Training loss: 2.1889887512113186
Validation loss: 2.4070462104289923

Epoch: 164| Step: 0
Training loss: 2.5279892063332956
Validation loss: 2.4325922762036645

Epoch: 5| Step: 1
Training loss: 2.369862068444007
Validation loss: 2.447203725353412

Epoch: 5| Step: 2
Training loss: 2.360635483900024
Validation loss: 2.442047860709632

Epoch: 5| Step: 3
Training loss: 2.0389483774337798
Validation loss: 2.4702168763214307

Epoch: 5| Step: 4
Training loss: 2.7430830577217415
Validation loss: 2.474886868914722

Epoch: 5| Step: 5
Training loss: 2.7558803111469983
Validation loss: 2.5137886239333636

Epoch: 5| Step: 6
Training loss: 2.5090845987494403
Validation loss: 2.598371555195347

Epoch: 5| Step: 7
Training loss: 2.6857014337626395
Validation loss: 2.684259179115122

Epoch: 5| Step: 8
Training loss: 2.5030351334535794
Validation loss: 2.633452647683632

Epoch: 5| Step: 9
Training loss: 2.6238352598428656
Validation loss: 2.617438960403957

Epoch: 5| Step: 10
Training loss: 2.672016340833939
Validation loss: 2.5213690896668948

Epoch: 165| Step: 0
Training loss: 2.985327763286311
Validation loss: 2.4622164484977267

Epoch: 5| Step: 1
Training loss: 2.6042430001833368
Validation loss: 2.41372105852343

Epoch: 5| Step: 2
Training loss: 2.581828653348526
Validation loss: 2.4244941333913137

Epoch: 5| Step: 3
Training loss: 2.7471366193561826
Validation loss: 2.425643142574132

Epoch: 5| Step: 4
Training loss: 2.401067726727532
Validation loss: 2.4175099509408384

Epoch: 5| Step: 5
Training loss: 2.614736200451055
Validation loss: 2.4301601087829265

Epoch: 5| Step: 6
Training loss: 2.3406786312788728
Validation loss: 2.445604967532909

Epoch: 5| Step: 7
Training loss: 2.247407691426265
Validation loss: 2.466644751904004

Epoch: 5| Step: 8
Training loss: 2.5507261962557606
Validation loss: 2.5015991346810065

Epoch: 5| Step: 9
Training loss: 2.5828496008375854
Validation loss: 2.5123226732345376

Epoch: 5| Step: 10
Training loss: 2.7043575056906226
Validation loss: 2.53150763416528

Epoch: 166| Step: 0
Training loss: 2.618307392162638
Validation loss: 2.507806221260862

Epoch: 5| Step: 1
Training loss: 2.5316839905732706
Validation loss: 2.495655492312054

Epoch: 5| Step: 2
Training loss: 2.291864132320956
Validation loss: 2.476786132272168

Epoch: 5| Step: 3
Training loss: 2.597748764799924
Validation loss: 2.474454828170094

Epoch: 5| Step: 4
Training loss: 2.0435389931852783
Validation loss: 2.468037166049095

Epoch: 5| Step: 5
Training loss: 3.101535595217453
Validation loss: 2.4737822466857686

Epoch: 5| Step: 6
Training loss: 2.682780802055707
Validation loss: 2.4913005857347112

Epoch: 5| Step: 7
Training loss: 2.3588084367994178
Validation loss: 2.4932349842148067

Epoch: 5| Step: 8
Training loss: 2.6022215229007783
Validation loss: 2.5111848846902634

Epoch: 5| Step: 9
Training loss: 2.4543652163262712
Validation loss: 2.541383407929583

Epoch: 5| Step: 10
Training loss: 2.2866394967595722
Validation loss: 2.581616241526766

Epoch: 167| Step: 0
Training loss: 2.066245867845635
Validation loss: 2.639543738517681

Epoch: 5| Step: 1
Training loss: 2.8356893131327405
Validation loss: 2.6668533537361796

Epoch: 5| Step: 2
Training loss: 2.037212950724077
Validation loss: 2.6552567383279913

Epoch: 5| Step: 3
Training loss: 2.4788467991598098
Validation loss: 2.5901675361169803

Epoch: 5| Step: 4
Training loss: 2.4607594259109264
Validation loss: 2.575623344568584

Epoch: 5| Step: 5
Training loss: 2.7154296242829776
Validation loss: 2.5397404611044556

Epoch: 5| Step: 6
Training loss: 2.44782311010478
Validation loss: 2.516251862156958

Epoch: 5| Step: 7
Training loss: 2.34800770900962
Validation loss: 2.4990458605812615

Epoch: 5| Step: 8
Training loss: 2.8913675540127133
Validation loss: 2.4681240641879207

Epoch: 5| Step: 9
Training loss: 2.4088438841454245
Validation loss: 2.4665772324002098

Epoch: 5| Step: 10
Training loss: 2.808116378855849
Validation loss: 2.463876512395439

Epoch: 168| Step: 0
Training loss: 2.366142419947931
Validation loss: 2.4776120156416965

Epoch: 5| Step: 1
Training loss: 2.1177923598337296
Validation loss: 2.4633707434989964

Epoch: 5| Step: 2
Training loss: 2.406641346207387
Validation loss: 2.4687851425251193

Epoch: 5| Step: 3
Training loss: 2.501408942880777
Validation loss: 2.4832133201248356

Epoch: 5| Step: 4
Training loss: 2.3941168123076455
Validation loss: 2.4971920949448516

Epoch: 5| Step: 5
Training loss: 2.290520942270819
Validation loss: 2.5163542884560073

Epoch: 5| Step: 6
Training loss: 2.4243057358306213
Validation loss: 2.521920464930253

Epoch: 5| Step: 7
Training loss: 2.51531990049233
Validation loss: 2.515780713706537

Epoch: 5| Step: 8
Training loss: 2.337823317091879
Validation loss: 2.5121880820066034

Epoch: 5| Step: 9
Training loss: 2.8549887779536385
Validation loss: 2.503124747909298

Epoch: 5| Step: 10
Training loss: 2.5649319715197456
Validation loss: 2.5315435116066958

Epoch: 169| Step: 0
Training loss: 2.811226620099864
Validation loss: 2.5257622995125564

Epoch: 5| Step: 1
Training loss: 2.0317943137138035
Validation loss: 2.55532380824495

Epoch: 5| Step: 2
Training loss: 2.3993823647491634
Validation loss: 2.5201228995075495

Epoch: 5| Step: 3
Training loss: 2.519218768473706
Validation loss: 2.5458840649918373

Epoch: 5| Step: 4
Training loss: 2.463482028704393
Validation loss: 2.4937287808707844

Epoch: 5| Step: 5
Training loss: 2.1701117294307433
Validation loss: 2.4833152121888706

Epoch: 5| Step: 6
Training loss: 2.5059145581657702
Validation loss: 2.4802456120514047

Epoch: 5| Step: 7
Training loss: 2.264664229205937
Validation loss: 2.48444208431344

Epoch: 5| Step: 8
Training loss: 2.555550898902447
Validation loss: 2.4875685791573083

Epoch: 5| Step: 9
Training loss: 2.271470624991971
Validation loss: 2.4750627209159557

Epoch: 5| Step: 10
Training loss: 2.5094555377506222
Validation loss: 2.4973773099532344

Epoch: 170| Step: 0
Training loss: 2.879552802228206
Validation loss: 2.5365521133011435

Epoch: 5| Step: 1
Training loss: 2.8508952156969554
Validation loss: 2.5835148856375065

Epoch: 5| Step: 2
Training loss: 2.813101640564899
Validation loss: 2.5504701677173847

Epoch: 5| Step: 3
Training loss: 2.282546628578111
Validation loss: 2.522977189056441

Epoch: 5| Step: 4
Training loss: 2.545239444103408
Validation loss: 2.4899660797006247

Epoch: 5| Step: 5
Training loss: 2.306131511838872
Validation loss: 2.456920995686776

Epoch: 5| Step: 6
Training loss: 1.799795745810839
Validation loss: 2.466859151804158

Epoch: 5| Step: 7
Training loss: 2.052893954533943
Validation loss: 2.4686952062787615

Epoch: 5| Step: 8
Training loss: 2.062029004504418
Validation loss: 2.4677032020886136

Epoch: 5| Step: 9
Training loss: 2.4841282560067746
Validation loss: 2.4759909419055868

Epoch: 5| Step: 10
Training loss: 1.9161351406763028
Validation loss: 2.510020404542026

Epoch: 171| Step: 0
Training loss: 2.3457323972986193
Validation loss: 2.506933329648124

Epoch: 5| Step: 1
Training loss: 2.1246026733539622
Validation loss: 2.5169910677648613

Epoch: 5| Step: 2
Training loss: 2.3302437786554964
Validation loss: 2.5573068114620177

Epoch: 5| Step: 3
Training loss: 2.5584125949704664
Validation loss: 2.5284352291783603

Epoch: 5| Step: 4
Training loss: 2.3104971382934045
Validation loss: 2.5108615077914784

Epoch: 5| Step: 5
Training loss: 2.3064095997571217
Validation loss: 2.489173878830192

Epoch: 5| Step: 6
Training loss: 1.8070686781751273
Validation loss: 2.4772301860728416

Epoch: 5| Step: 7
Training loss: 2.6181481263793724
Validation loss: 2.463861739463971

Epoch: 5| Step: 8
Training loss: 2.4234673956300474
Validation loss: 2.4579001928572386

Epoch: 5| Step: 9
Training loss: 2.49596814241008
Validation loss: 2.4672339745541727

Epoch: 5| Step: 10
Training loss: 2.6275566003512307
Validation loss: 2.461539695074517

Epoch: 172| Step: 0
Training loss: 2.485959297626485
Validation loss: 2.4469679143058514

Epoch: 5| Step: 1
Training loss: 1.8764225967181831
Validation loss: 2.457188550541066

Epoch: 5| Step: 2
Training loss: 2.4422367727979895
Validation loss: 2.4476427171502713

Epoch: 5| Step: 3
Training loss: 2.737577818718145
Validation loss: 2.4729676051829905

Epoch: 5| Step: 4
Training loss: 2.553300393475572
Validation loss: 2.4763878352847963

Epoch: 5| Step: 5
Training loss: 2.102487353492106
Validation loss: 2.4617622770835843

Epoch: 5| Step: 6
Training loss: 2.312048687583924
Validation loss: 2.4726152962104435

Epoch: 5| Step: 7
Training loss: 1.8975649111655686
Validation loss: 2.4915866611646877

Epoch: 5| Step: 8
Training loss: 1.9720230143714894
Validation loss: 2.4769996357426107

Epoch: 5| Step: 9
Training loss: 2.3708067567896696
Validation loss: 2.484007267647584

Epoch: 5| Step: 10
Training loss: 2.822299331410962
Validation loss: 2.4986647311215493

Epoch: 173| Step: 0
Training loss: 2.0728967049051295
Validation loss: 2.521721135331377

Epoch: 5| Step: 1
Training loss: 1.9223581342601594
Validation loss: 2.582373671724178

Epoch: 5| Step: 2
Training loss: 2.6621976797189344
Validation loss: 2.614523184198459

Epoch: 5| Step: 3
Training loss: 2.2969536800272916
Validation loss: 2.5369504796590236

Epoch: 5| Step: 4
Training loss: 2.502821760347429
Validation loss: 2.4640830765203043

Epoch: 5| Step: 5
Training loss: 1.779544884223098
Validation loss: 2.4435155717009556

Epoch: 5| Step: 6
Training loss: 2.4864752187316688
Validation loss: 2.4281803549388092

Epoch: 5| Step: 7
Training loss: 2.292925286734052
Validation loss: 2.438028148724419

Epoch: 5| Step: 8
Training loss: 2.5149382607558817
Validation loss: 2.454651868370236

Epoch: 5| Step: 9
Training loss: 3.036230341540254
Validation loss: 2.4890201714426143

Epoch: 5| Step: 10
Training loss: 2.3111089698259915
Validation loss: 2.5261586206068207

Epoch: 174| Step: 0
Training loss: 1.8422122943947092
Validation loss: 2.5374401983640764

Epoch: 5| Step: 1
Training loss: 2.7925529970827974
Validation loss: 2.5310600277331243

Epoch: 5| Step: 2
Training loss: 2.287799265312199
Validation loss: 2.512911475023752

Epoch: 5| Step: 3
Training loss: 2.2636767198907384
Validation loss: 2.5055256945432087

Epoch: 5| Step: 4
Training loss: 2.01804945278915
Validation loss: 2.510854029827474

Epoch: 5| Step: 5
Training loss: 2.2441272386594875
Validation loss: 2.4798839548623652

Epoch: 5| Step: 6
Training loss: 2.3839090794500684
Validation loss: 2.525261379372471

Epoch: 5| Step: 7
Training loss: 2.045394828194387
Validation loss: 2.539117383592491

Epoch: 5| Step: 8
Training loss: 2.2488008058501068
Validation loss: 2.5946898731217085

Epoch: 5| Step: 9
Training loss: 2.504232257443137
Validation loss: 2.5658105853917985

Epoch: 5| Step: 10
Training loss: 2.8154193561746794
Validation loss: 2.483999805853943

Epoch: 175| Step: 0
Training loss: 2.239775207343619
Validation loss: 2.4432835818034917

Epoch: 5| Step: 1
Training loss: 2.1946781640259565
Validation loss: 2.4073427699722902

Epoch: 5| Step: 2
Training loss: 2.2816377075155763
Validation loss: 2.412971364416376

Epoch: 5| Step: 3
Training loss: 2.4448364574445267
Validation loss: 2.42053950097037

Epoch: 5| Step: 4
Training loss: 2.4558357763089482
Validation loss: 2.4157176956887203

Epoch: 5| Step: 5
Training loss: 2.3477203309616947
Validation loss: 2.40980684118958

Epoch: 5| Step: 6
Training loss: 2.666604538034852
Validation loss: 2.434069515196134

Epoch: 5| Step: 7
Training loss: 2.333124719104193
Validation loss: 2.4538011770514836

Epoch: 5| Step: 8
Training loss: 2.306020991008998
Validation loss: 2.5948008516163847

Epoch: 5| Step: 9
Training loss: 2.2671830706352645
Validation loss: 2.613186122225372

Epoch: 5| Step: 10
Training loss: 2.801886985356643
Validation loss: 2.5992195231106807

Epoch: 176| Step: 0
Training loss: 1.9063287312242578
Validation loss: 2.4917166575622645

Epoch: 5| Step: 1
Training loss: 2.4468372210512945
Validation loss: 2.445058019493932

Epoch: 5| Step: 2
Training loss: 2.4528247625224493
Validation loss: 2.407003976301047

Epoch: 5| Step: 3
Training loss: 2.7809322047030456
Validation loss: 2.430835081591555

Epoch: 5| Step: 4
Training loss: 2.4794083378644154
Validation loss: 2.4218826235605873

Epoch: 5| Step: 5
Training loss: 2.216845379941532
Validation loss: 2.4387471279824267

Epoch: 5| Step: 6
Training loss: 2.1078385019925454
Validation loss: 2.4531242747345265

Epoch: 5| Step: 7
Training loss: 2.4548056124238427
Validation loss: 2.4757699378526583

Epoch: 5| Step: 8
Training loss: 2.5126631460788453
Validation loss: 2.5127837310513335

Epoch: 5| Step: 9
Training loss: 2.3570100160627896
Validation loss: 2.5748410726331006

Epoch: 5| Step: 10
Training loss: 2.465587763632055
Validation loss: 2.6104342309038278

Epoch: 177| Step: 0
Training loss: 2.402796062284761
Validation loss: 2.6562530015690813

Epoch: 5| Step: 1
Training loss: 2.4017965546463107
Validation loss: 2.633440941436631

Epoch: 5| Step: 2
Training loss: 2.4380831876649256
Validation loss: 2.6028459802284605

Epoch: 5| Step: 3
Training loss: 2.6609883848422067
Validation loss: 2.589536630687534

Epoch: 5| Step: 4
Training loss: 1.9438438540059522
Validation loss: 2.5508706930919796

Epoch: 5| Step: 5
Training loss: 2.6520097884663505
Validation loss: 2.5603042126743434

Epoch: 5| Step: 6
Training loss: 2.4302206650372153
Validation loss: 2.5092160170529607

Epoch: 5| Step: 7
Training loss: 2.293810922089082
Validation loss: 2.459378180178842

Epoch: 5| Step: 8
Training loss: 2.012741154977385
Validation loss: 2.452174600175831

Epoch: 5| Step: 9
Training loss: 1.9064129619044081
Validation loss: 2.4158086172834707

Epoch: 5| Step: 10
Training loss: 2.464822373093465
Validation loss: 2.434588428513808

Epoch: 178| Step: 0
Training loss: 2.213374220554686
Validation loss: 2.4626583605835415

Epoch: 5| Step: 1
Training loss: 2.065786459840986
Validation loss: 2.490432526122137

Epoch: 5| Step: 2
Training loss: 2.127827726374925
Validation loss: 2.5141532749252513

Epoch: 5| Step: 3
Training loss: 2.062652235481627
Validation loss: 2.5292444694139813

Epoch: 5| Step: 4
Training loss: 2.9579168931017286
Validation loss: 2.5435888854504958

Epoch: 5| Step: 5
Training loss: 1.8926515673234068
Validation loss: 2.4611473649001177

Epoch: 5| Step: 6
Training loss: 2.1688359356215283
Validation loss: 2.4190675699601996

Epoch: 5| Step: 7
Training loss: 2.4211161747522008
Validation loss: 2.3907944009798303

Epoch: 5| Step: 8
Training loss: 2.711513666933434
Validation loss: 2.3727292613511417

Epoch: 5| Step: 9
Training loss: 2.6646499657271785
Validation loss: 2.3711916825299695

Epoch: 5| Step: 10
Training loss: 1.920370365819819
Validation loss: 2.3757972307536344

Epoch: 179| Step: 0
Training loss: 3.0793067483865877
Validation loss: 2.385044792375364

Epoch: 5| Step: 1
Training loss: 2.4643364579246168
Validation loss: 2.4358745863373676

Epoch: 5| Step: 2
Training loss: 2.331381549140625
Validation loss: 2.5025633130097003

Epoch: 5| Step: 3
Training loss: 2.4871099041566307
Validation loss: 2.5745020573607844

Epoch: 5| Step: 4
Training loss: 2.3650152229319175
Validation loss: 2.628819426887846

Epoch: 5| Step: 5
Training loss: 2.3951198234129873
Validation loss: 2.598938156550377

Epoch: 5| Step: 6
Training loss: 1.881874008862587
Validation loss: 2.5404433304253913

Epoch: 5| Step: 7
Training loss: 1.9509750129433105
Validation loss: 2.472587129977597

Epoch: 5| Step: 8
Training loss: 2.518775625548149
Validation loss: 2.416835248004961

Epoch: 5| Step: 9
Training loss: 1.5467881457673356
Validation loss: 2.391257442425496

Epoch: 5| Step: 10
Training loss: 2.335073764297542
Validation loss: 2.390465494274677

Epoch: 180| Step: 0
Training loss: 2.4576400706051906
Validation loss: 2.3724140257355275

Epoch: 5| Step: 1
Training loss: 2.611642183807007
Validation loss: 2.3743453426961088

Epoch: 5| Step: 2
Training loss: 2.5206418450717485
Validation loss: 2.364161961021143

Epoch: 5| Step: 3
Training loss: 2.0307485108107692
Validation loss: 2.36198403060305

Epoch: 5| Step: 4
Training loss: 1.7848995366395264
Validation loss: 2.4365445839519952

Epoch: 5| Step: 5
Training loss: 2.123935881816096
Validation loss: 2.488811399160098

Epoch: 5| Step: 6
Training loss: 2.549320287433001
Validation loss: 2.571224548161869

Epoch: 5| Step: 7
Training loss: 2.4965960216671124
Validation loss: 2.591010561424715

Epoch: 5| Step: 8
Training loss: 2.2167099721402295
Validation loss: 2.6338746608588197

Epoch: 5| Step: 9
Training loss: 2.0160498356184715
Validation loss: 2.5532194587542016

Epoch: 5| Step: 10
Training loss: 2.1946339491880997
Validation loss: 2.5316089247535176

Epoch: 181| Step: 0
Training loss: 2.0547860125578925
Validation loss: 2.488641401520334

Epoch: 5| Step: 1
Training loss: 2.1143313353267112
Validation loss: 2.4369691565730256

Epoch: 5| Step: 2
Training loss: 2.1881562474756455
Validation loss: 2.4216253648833863

Epoch: 5| Step: 3
Training loss: 2.574377862530937
Validation loss: 2.398491338855296

Epoch: 5| Step: 4
Training loss: 2.3074310008072456
Validation loss: 2.4059466519843737

Epoch: 5| Step: 5
Training loss: 2.151044228269762
Validation loss: 2.408248134607226

Epoch: 5| Step: 6
Training loss: 2.530037106630117
Validation loss: 2.419059155419696

Epoch: 5| Step: 7
Training loss: 2.203623181013797
Validation loss: 2.4006887456860824

Epoch: 5| Step: 8
Training loss: 2.202839068532476
Validation loss: 2.4408934777368527

Epoch: 5| Step: 9
Training loss: 2.2040794956250256
Validation loss: 2.478561668447029

Epoch: 5| Step: 10
Training loss: 2.1194906060005456
Validation loss: 2.5050082033516845

Epoch: 182| Step: 0
Training loss: 2.2072443766356495
Validation loss: 2.5015663695372874

Epoch: 5| Step: 1
Training loss: 2.057007846489064
Validation loss: 2.5495830899625713

Epoch: 5| Step: 2
Training loss: 2.634557581465042
Validation loss: 2.5403438907086913

Epoch: 5| Step: 3
Training loss: 2.257741748796849
Validation loss: 2.535779238271924

Epoch: 5| Step: 4
Training loss: 2.129946841082519
Validation loss: 2.506329837468821

Epoch: 5| Step: 5
Training loss: 1.939919099792312
Validation loss: 2.4631316904374194

Epoch: 5| Step: 6
Training loss: 2.3955380686277206
Validation loss: 2.4387188985677053

Epoch: 5| Step: 7
Training loss: 1.9158619421434728
Validation loss: 2.4169808478082664

Epoch: 5| Step: 8
Training loss: 2.4336445957707484
Validation loss: 2.39042582102056

Epoch: 5| Step: 9
Training loss: 2.3078722657437116
Validation loss: 2.3849856704703147

Epoch: 5| Step: 10
Training loss: 2.1230513670030677
Validation loss: 2.380222843338031

Epoch: 183| Step: 0
Training loss: 2.4162728767081703
Validation loss: 2.392157292844601

Epoch: 5| Step: 1
Training loss: 2.206799520294541
Validation loss: 2.428456674504807

Epoch: 5| Step: 2
Training loss: 1.7415342603057586
Validation loss: 2.459208488245373

Epoch: 5| Step: 3
Training loss: 2.1873883900098767
Validation loss: 2.4806057531148333

Epoch: 5| Step: 4
Training loss: 2.217451763467071
Validation loss: 2.501850413449458

Epoch: 5| Step: 5
Training loss: 2.1739302317313
Validation loss: 2.5241590985880165

Epoch: 5| Step: 6
Training loss: 2.319411285782659
Validation loss: 2.498742286605259

Epoch: 5| Step: 7
Training loss: 2.32560357903834
Validation loss: 2.466330888607091

Epoch: 5| Step: 8
Training loss: 1.5688275200281439
Validation loss: 2.44621958101861

Epoch: 5| Step: 9
Training loss: 2.6803197531898317
Validation loss: 2.4056998013916084

Epoch: 5| Step: 10
Training loss: 2.4440785179886317
Validation loss: 2.4121072254434544

Epoch: 184| Step: 0
Training loss: 2.255441866464416
Validation loss: 2.4359884315998817

Epoch: 5| Step: 1
Training loss: 1.8996335880933595
Validation loss: 2.440409963468885

Epoch: 5| Step: 2
Training loss: 2.1167481589461934
Validation loss: 2.4846321004397427

Epoch: 5| Step: 3
Training loss: 2.5377458650587057
Validation loss: 2.46752650560321

Epoch: 5| Step: 4
Training loss: 1.9285988149767277
Validation loss: 2.49608188330857

Epoch: 5| Step: 5
Training loss: 1.88981453414481
Validation loss: 2.4892978977409586

Epoch: 5| Step: 6
Training loss: 2.303460366665144
Validation loss: 2.5192201158196914

Epoch: 5| Step: 7
Training loss: 2.372848540129979
Validation loss: 2.4965415967632922

Epoch: 5| Step: 8
Training loss: 2.2475370065869402
Validation loss: 2.519031799930383

Epoch: 5| Step: 9
Training loss: 1.8051404508435704
Validation loss: 2.5340242363674217

Epoch: 5| Step: 10
Training loss: 2.474054456483082
Validation loss: 2.4879901597431457

Epoch: 185| Step: 0
Training loss: 1.9142483368012335
Validation loss: 2.455350308717066

Epoch: 5| Step: 1
Training loss: 2.397532935527877
Validation loss: 2.4195527665552476

Epoch: 5| Step: 2
Training loss: 1.808756876565322
Validation loss: 2.407214891390072

Epoch: 5| Step: 3
Training loss: 2.157640754997113
Validation loss: 2.41859494854603

Epoch: 5| Step: 4
Training loss: 2.312514124646739
Validation loss: 2.422618811818088

Epoch: 5| Step: 5
Training loss: 1.9959793804571437
Validation loss: 2.4142581180652045

Epoch: 5| Step: 6
Training loss: 1.46686985530203
Validation loss: 2.432094965399899

Epoch: 5| Step: 7
Training loss: 2.747685932674828
Validation loss: 2.4397254620467397

Epoch: 5| Step: 8
Training loss: 2.1491629190795614
Validation loss: 2.458030310410214

Epoch: 5| Step: 9
Training loss: 2.2271917156780665
Validation loss: 2.447490754752182

Epoch: 5| Step: 10
Training loss: 2.3214572946636918
Validation loss: 2.440864491722101

Epoch: 186| Step: 0
Training loss: 2.0668730181559662
Validation loss: 2.435154748170985

Epoch: 5| Step: 1
Training loss: 1.9717223723478272
Validation loss: 2.443089416851039

Epoch: 5| Step: 2
Training loss: 2.241136683478543
Validation loss: 2.4103110129386947

Epoch: 5| Step: 3
Training loss: 2.4206889540076073
Validation loss: 2.3909815447925515

Epoch: 5| Step: 4
Training loss: 2.592121118358946
Validation loss: 2.406546341273059

Epoch: 5| Step: 5
Training loss: 2.3075362880246404
Validation loss: 2.452289960394959

Epoch: 5| Step: 6
Training loss: 1.9008755197600196
Validation loss: 2.49567933344377

Epoch: 5| Step: 7
Training loss: 1.3293160875732877
Validation loss: 2.5395559028714083

Epoch: 5| Step: 8
Training loss: 1.9831195975253206
Validation loss: 2.5567619764776013

Epoch: 5| Step: 9
Training loss: 2.015507894263473
Validation loss: 2.5471051014857085

Epoch: 5| Step: 10
Training loss: 2.6135013869642973
Validation loss: 2.583207244124698

Epoch: 187| Step: 0
Training loss: 2.4602111713363874
Validation loss: 2.5377336809608586

Epoch: 5| Step: 1
Training loss: 2.1399479373053545
Validation loss: 2.484857747705373

Epoch: 5| Step: 2
Training loss: 2.221761781621991
Validation loss: 2.4370189946255527

Epoch: 5| Step: 3
Training loss: 2.088809433005345
Validation loss: 2.377585552125501

Epoch: 5| Step: 4
Training loss: 2.0235099632219615
Validation loss: 2.3646222501169385

Epoch: 5| Step: 5
Training loss: 2.1539609617770745
Validation loss: 2.344249474685961

Epoch: 5| Step: 6
Training loss: 1.7408863905507124
Validation loss: 2.34106763472572

Epoch: 5| Step: 7
Training loss: 2.6358758780122993
Validation loss: 2.3639032754653533

Epoch: 5| Step: 8
Training loss: 2.058120933827572
Validation loss: 2.3801670052475075

Epoch: 5| Step: 9
Training loss: 2.070948780098745
Validation loss: 2.4018349065358837

Epoch: 5| Step: 10
Training loss: 2.0010637792119774
Validation loss: 2.4301894608844656

Epoch: 188| Step: 0
Training loss: 1.8018145131025767
Validation loss: 2.4716936503257374

Epoch: 5| Step: 1
Training loss: 2.1022608848069515
Validation loss: 2.53793363076265

Epoch: 5| Step: 2
Training loss: 1.9977192391022867
Validation loss: 2.5591950231794893

Epoch: 5| Step: 3
Training loss: 1.9170910600377873
Validation loss: 2.5796499923412393

Epoch: 5| Step: 4
Training loss: 2.0853835381141756
Validation loss: 2.5381048337910066

Epoch: 5| Step: 5
Training loss: 2.184524146842609
Validation loss: 2.4793208529213246

Epoch: 5| Step: 6
Training loss: 2.2692314120593897
Validation loss: 2.456679735100397

Epoch: 5| Step: 7
Training loss: 2.065516491231507
Validation loss: 2.405537954196881

Epoch: 5| Step: 8
Training loss: 2.380185539642866
Validation loss: 2.356542125140887

Epoch: 5| Step: 9
Training loss: 2.5067462496434136
Validation loss: 2.3742754089410227

Epoch: 5| Step: 10
Training loss: 2.279659605215089
Validation loss: 2.3801521037388564

Epoch: 189| Step: 0
Training loss: 1.6155757520242016
Validation loss: 2.444281480651492

Epoch: 5| Step: 1
Training loss: 1.8543893987484268
Validation loss: 2.5011761318848578

Epoch: 5| Step: 2
Training loss: 2.0594661246762387
Validation loss: 2.550078405139616

Epoch: 5| Step: 3
Training loss: 2.233351466356747
Validation loss: 2.5527647018372965

Epoch: 5| Step: 4
Training loss: 2.4373937730383637
Validation loss: 2.525301399180925

Epoch: 5| Step: 5
Training loss: 2.115619712383475
Validation loss: 2.4768969254810616

Epoch: 5| Step: 6
Training loss: 2.219559964910994
Validation loss: 2.4175445594341247

Epoch: 5| Step: 7
Training loss: 2.724005431916231
Validation loss: 2.3821814341710414

Epoch: 5| Step: 8
Training loss: 1.6685316935985137
Validation loss: 2.369300721294332

Epoch: 5| Step: 9
Training loss: 2.390325190874129
Validation loss: 2.389125673644072

Epoch: 5| Step: 10
Training loss: 1.9834115400308847
Validation loss: 2.3977582270975204

Epoch: 190| Step: 0
Training loss: 1.6053697690129274
Validation loss: 2.4602868119216956

Epoch: 5| Step: 1
Training loss: 1.4934185602073116
Validation loss: 2.5162504897884244

Epoch: 5| Step: 2
Training loss: 1.9387941037934628
Validation loss: 2.5426211233477787

Epoch: 5| Step: 3
Training loss: 2.168604961899222
Validation loss: 2.544660244318771

Epoch: 5| Step: 4
Training loss: 2.2255024846203866
Validation loss: 2.5385542670917522

Epoch: 5| Step: 5
Training loss: 2.0985655563036394
Validation loss: 2.5123480113172167

Epoch: 5| Step: 6
Training loss: 2.304081931001866
Validation loss: 2.4796258575760857

Epoch: 5| Step: 7
Training loss: 2.3254559469764473
Validation loss: 2.468498276337984

Epoch: 5| Step: 8
Training loss: 2.494295287209869
Validation loss: 2.4518352499063893

Epoch: 5| Step: 9
Training loss: 1.9733144738395842
Validation loss: 2.433942305634436

Epoch: 5| Step: 10
Training loss: 2.001695867617143
Validation loss: 2.4151392870633037

Epoch: 191| Step: 0
Training loss: 1.7703169873981217
Validation loss: 2.4305174853209293

Epoch: 5| Step: 1
Training loss: 2.219299893001323
Validation loss: 2.4408531179939748

Epoch: 5| Step: 2
Training loss: 1.9070526684437705
Validation loss: 2.4907618368703095

Epoch: 5| Step: 3
Training loss: 2.2644661932451857
Validation loss: 2.52618839779483

Epoch: 5| Step: 4
Training loss: 1.7986508426017316
Validation loss: 2.5861641388261547

Epoch: 5| Step: 5
Training loss: 2.722235714193459
Validation loss: 2.552767623229282

Epoch: 5| Step: 6
Training loss: 2.1184337368673014
Validation loss: 2.4914122800587775

Epoch: 5| Step: 7
Training loss: 1.7868337283149887
Validation loss: 2.417828403342405

Epoch: 5| Step: 8
Training loss: 1.5851342182311026
Validation loss: 2.3872622300179778

Epoch: 5| Step: 9
Training loss: 2.0398999829176963
Validation loss: 2.3777444318261653

Epoch: 5| Step: 10
Training loss: 2.729979289748337
Validation loss: 2.371087291948154

Epoch: 192| Step: 0
Training loss: 2.221945060558954
Validation loss: 2.3912559307796255

Epoch: 5| Step: 1
Training loss: 2.3609201790397054
Validation loss: 2.4120810070763556

Epoch: 5| Step: 2
Training loss: 1.8565603157394035
Validation loss: 2.4506975679308685

Epoch: 5| Step: 3
Training loss: 1.6341283871091739
Validation loss: 2.485805119202024

Epoch: 5| Step: 4
Training loss: 2.1335821195416025
Validation loss: 2.5460425669255704

Epoch: 5| Step: 5
Training loss: 2.5277324772596126
Validation loss: 2.605825611641939

Epoch: 5| Step: 6
Training loss: 2.1410339410364148
Validation loss: 2.5544869316990892

Epoch: 5| Step: 7
Training loss: 1.8020819809160689
Validation loss: 2.4896110862296825

Epoch: 5| Step: 8
Training loss: 2.2134824737413346
Validation loss: 2.4233734650267977

Epoch: 5| Step: 9
Training loss: 1.8880276454057245
Validation loss: 2.387181863547311

Epoch: 5| Step: 10
Training loss: 2.023119220224538
Validation loss: 2.37248620359722

Epoch: 193| Step: 0
Training loss: 1.8601812329751473
Validation loss: 2.374205609179386

Epoch: 5| Step: 1
Training loss: 2.271525729484364
Validation loss: 2.400548418256895

Epoch: 5| Step: 2
Training loss: 2.146769038754662
Validation loss: 2.4315395075406383

Epoch: 5| Step: 3
Training loss: 1.8549593256272348
Validation loss: 2.44270991529041

Epoch: 5| Step: 4
Training loss: 2.0951321722685905
Validation loss: 2.4863222065073383

Epoch: 5| Step: 5
Training loss: 1.8296003338828906
Validation loss: 2.5008070391698367

Epoch: 5| Step: 6
Training loss: 1.837818691617502
Validation loss: 2.558401502325201

Epoch: 5| Step: 7
Training loss: 1.8566538027940387
Validation loss: 2.5934217709619287

Epoch: 5| Step: 8
Training loss: 2.0179413489749476
Validation loss: 2.5984135351285187

Epoch: 5| Step: 9
Training loss: 2.363138594932566
Validation loss: 2.5701269202535686

Epoch: 5| Step: 10
Training loss: 2.3067045017219177
Validation loss: 2.5271146622631724

Epoch: 194| Step: 0
Training loss: 2.0922685762725513
Validation loss: 2.4584882557731156

Epoch: 5| Step: 1
Training loss: 2.297169465373163
Validation loss: 2.4291742855941694

Epoch: 5| Step: 2
Training loss: 2.4779341596549656
Validation loss: 2.41330028128824

Epoch: 5| Step: 3
Training loss: 1.6037047410556518
Validation loss: 2.4095148748337083

Epoch: 5| Step: 4
Training loss: 1.997461615469353
Validation loss: 2.4410625808180986

Epoch: 5| Step: 5
Training loss: 2.1343652012880745
Validation loss: 2.47076911129656

Epoch: 5| Step: 6
Training loss: 1.792859308896089
Validation loss: 2.478272713685713

Epoch: 5| Step: 7
Training loss: 1.8257116053907172
Validation loss: 2.495157778123821

Epoch: 5| Step: 8
Training loss: 2.0214246952996024
Validation loss: 2.5350951190505553

Epoch: 5| Step: 9
Training loss: 1.7460799590041929
Validation loss: 2.5226123877684707

Epoch: 5| Step: 10
Training loss: 1.9997834446014708
Validation loss: 2.5240625640837404

Epoch: 195| Step: 0
Training loss: 2.1018752535418024
Validation loss: 2.530304641446688

Epoch: 5| Step: 1
Training loss: 1.926949230030082
Validation loss: 2.479218141623402

Epoch: 5| Step: 2
Training loss: 2.0864603480308532
Validation loss: 2.469487400086512

Epoch: 5| Step: 3
Training loss: 2.236565216689614
Validation loss: 2.448600821801423

Epoch: 5| Step: 4
Training loss: 2.030509813868805
Validation loss: 2.420508419849373

Epoch: 5| Step: 5
Training loss: 1.7136857765456488
Validation loss: 2.4215866621152027

Epoch: 5| Step: 6
Training loss: 1.8780356946077854
Validation loss: 2.4196637318933276

Epoch: 5| Step: 7
Training loss: 1.9444993859052486
Validation loss: 2.455575683844535

Epoch: 5| Step: 8
Training loss: 1.806883231704735
Validation loss: 2.536692401811013

Epoch: 5| Step: 9
Training loss: 2.1912080127721367
Validation loss: 2.6172833991568063

Epoch: 5| Step: 10
Training loss: 2.0688367658323523
Validation loss: 2.6178847859332413

Epoch: 196| Step: 0
Training loss: 2.3289971478167537
Validation loss: 2.5799891678300604

Epoch: 5| Step: 1
Training loss: 1.791610435963731
Validation loss: 2.5097288989372584

Epoch: 5| Step: 2
Training loss: 1.7588662612976649
Validation loss: 2.4413654587486096

Epoch: 5| Step: 3
Training loss: 2.3280539277768475
Validation loss: 2.3681024232941983

Epoch: 5| Step: 4
Training loss: 2.1337262665960033
Validation loss: 2.348964483698118

Epoch: 5| Step: 5
Training loss: 1.9894159522891472
Validation loss: 2.332634903349262

Epoch: 5| Step: 6
Training loss: 2.089241069274782
Validation loss: 2.343799765000412

Epoch: 5| Step: 7
Training loss: 1.7726029100122402
Validation loss: 2.3947252015916196

Epoch: 5| Step: 8
Training loss: 1.8403556095514648
Validation loss: 2.436049939547549

Epoch: 5| Step: 9
Training loss: 2.098990870019285
Validation loss: 2.487829073178499

Epoch: 5| Step: 10
Training loss: 1.7615213558473606
Validation loss: 2.527759559448801

Epoch: 197| Step: 0
Training loss: 2.006263699588765
Validation loss: 2.5453037760554014

Epoch: 5| Step: 1
Training loss: 2.0297983704577987
Validation loss: 2.5350996343230427

Epoch: 5| Step: 2
Training loss: 1.8230774799440173
Validation loss: 2.4871149642060706

Epoch: 5| Step: 3
Training loss: 2.1157620406738435
Validation loss: 2.4626694306100148

Epoch: 5| Step: 4
Training loss: 2.2567999130008305
Validation loss: 2.421644877212871

Epoch: 5| Step: 5
Training loss: 1.7856869232261185
Validation loss: 2.4151491450794103

Epoch: 5| Step: 6
Training loss: 1.9047780842320972
Validation loss: 2.4009512539787963

Epoch: 5| Step: 7
Training loss: 1.7265177587175269
Validation loss: 2.39563465088202

Epoch: 5| Step: 8
Training loss: 1.8384789590344786
Validation loss: 2.430652022979286

Epoch: 5| Step: 9
Training loss: 2.1669864663061023
Validation loss: 2.4877488887228814

Epoch: 5| Step: 10
Training loss: 1.7960598630890108
Validation loss: 2.511815280227097

Epoch: 198| Step: 0
Training loss: 1.8364406464392709
Validation loss: 2.542589940487151

Epoch: 5| Step: 1
Training loss: 1.7658567023369922
Validation loss: 2.5157661548701724

Epoch: 5| Step: 2
Training loss: 1.9256130555156048
Validation loss: 2.536551025810017

Epoch: 5| Step: 3
Training loss: 1.759303634578394
Validation loss: 2.52338995901925

Epoch: 5| Step: 4
Training loss: 1.4149670316002938
Validation loss: 2.524906846282262

Epoch: 5| Step: 5
Training loss: 2.1827057754323445
Validation loss: 2.5357512246697627

Epoch: 5| Step: 6
Training loss: 1.4527956681682688
Validation loss: 2.549785044411152

Epoch: 5| Step: 7
Training loss: 2.1578534563667784
Validation loss: 2.510138459010751

Epoch: 5| Step: 8
Training loss: 2.2304807218373983
Validation loss: 2.5000219672273656

Epoch: 5| Step: 9
Training loss: 1.993051857525817
Validation loss: 2.459375460571841

Epoch: 5| Step: 10
Training loss: 2.0813315756450486
Validation loss: 2.4211644745002157

Epoch: 199| Step: 0
Training loss: 2.017220981594834
Validation loss: 2.399429922436982

Epoch: 5| Step: 1
Training loss: 2.310196425108265
Validation loss: 2.4160862074576324

Epoch: 5| Step: 2
Training loss: 2.1586004521489897
Validation loss: 2.4105958489664814

Epoch: 5| Step: 3
Training loss: 2.04308521529584
Validation loss: 2.384586976807906

Epoch: 5| Step: 4
Training loss: 1.8626747663800136
Validation loss: 2.402260255400613

Epoch: 5| Step: 5
Training loss: 1.7835821310927265
Validation loss: 2.422400755617128

Epoch: 5| Step: 6
Training loss: 1.9821684576710885
Validation loss: 2.455661109356467

Epoch: 5| Step: 7
Training loss: 1.5061393507207999
Validation loss: 2.461052578632878

Epoch: 5| Step: 8
Training loss: 1.5184415621800325
Validation loss: 2.4705848983006655

Epoch: 5| Step: 9
Training loss: 1.4887954744685294
Validation loss: 2.4782816202544233

Epoch: 5| Step: 10
Training loss: 1.7115448174321517
Validation loss: 2.529909045844444

Epoch: 200| Step: 0
Training loss: 1.527620490483666
Validation loss: 2.566841244829891

Epoch: 5| Step: 1
Training loss: 2.066429094790428
Validation loss: 2.6086601352436243

Epoch: 5| Step: 2
Training loss: 2.228223535785233
Validation loss: 2.593120892531004

Epoch: 5| Step: 3
Training loss: 1.7916695202945192
Validation loss: 2.5463532155464796

Epoch: 5| Step: 4
Training loss: 1.9423841626990657
Validation loss: 2.508351248664668

Epoch: 5| Step: 5
Training loss: 1.512096742199313
Validation loss: 2.477059587164574

Epoch: 5| Step: 6
Training loss: 1.7531455244471053
Validation loss: 2.492995062481179

Epoch: 5| Step: 7
Training loss: 2.1301827899424253
Validation loss: 2.4789673382223847

Epoch: 5| Step: 8
Training loss: 2.1257576433277863
Validation loss: 2.465537881790516

Epoch: 5| Step: 9
Training loss: 1.5659098230952389
Validation loss: 2.445421673729496

Epoch: 5| Step: 10
Training loss: 1.8143129818179227
Validation loss: 2.458146830874993

Epoch: 201| Step: 0
Training loss: 1.7161529340196742
Validation loss: 2.4355253388432363

Epoch: 5| Step: 1
Training loss: 1.918171609689485
Validation loss: 2.4266328058575874

Epoch: 5| Step: 2
Training loss: 2.4561591366955335
Validation loss: 2.410980641519617

Epoch: 5| Step: 3
Training loss: 1.3240823591092148
Validation loss: 2.4049172814573034

Epoch: 5| Step: 4
Training loss: 1.515587875068834
Validation loss: 2.414296073431238

Epoch: 5| Step: 5
Training loss: 1.943471075327064
Validation loss: 2.457767064355348

Epoch: 5| Step: 6
Training loss: 1.8868355092947933
Validation loss: 2.5252617732693157

Epoch: 5| Step: 7
Training loss: 1.8995823175196502
Validation loss: 2.584221387236184

Epoch: 5| Step: 8
Training loss: 1.5770423121221677
Validation loss: 2.6270836823885353

Epoch: 5| Step: 9
Training loss: 1.9040170943310253
Validation loss: 2.620718822002094

Epoch: 5| Step: 10
Training loss: 1.8500849626981082
Validation loss: 2.618827649470284

Epoch: 202| Step: 0
Training loss: 0.8519961451635777
Validation loss: 2.560273015883796

Epoch: 5| Step: 1
Training loss: 1.600913013789996
Validation loss: 2.517355940750653

Epoch: 5| Step: 2
Training loss: 2.1016953436972035
Validation loss: 2.4887454668360385

Epoch: 5| Step: 3
Training loss: 2.161291889691508
Validation loss: 2.4581719858799604

Epoch: 5| Step: 4
Training loss: 1.7967604890907054
Validation loss: 2.4604055251260974

Epoch: 5| Step: 5
Training loss: 1.9247945304304561
Validation loss: 2.4152602352502446

Epoch: 5| Step: 6
Training loss: 1.9316580282725246
Validation loss: 2.4467323110432244

Epoch: 5| Step: 7
Training loss: 1.7549785912666978
Validation loss: 2.4751939952962765

Epoch: 5| Step: 8
Training loss: 2.0435251094730584
Validation loss: 2.501712741510996

Epoch: 5| Step: 9
Training loss: 1.919379995097968
Validation loss: 2.5166537525807557

Epoch: 5| Step: 10
Training loss: 1.6704877285088426
Validation loss: 2.5740724933135097

Epoch: 203| Step: 0
Training loss: 1.826529173143155
Validation loss: 2.5965223977545913

Epoch: 5| Step: 1
Training loss: 1.8960236953349197
Validation loss: 2.576173828450664

Epoch: 5| Step: 2
Training loss: 2.0252913889397557
Validation loss: 2.5827382110442554

Epoch: 5| Step: 3
Training loss: 2.0525276232404375
Validation loss: 2.574401068234088

Epoch: 5| Step: 4
Training loss: 1.5118938807885118
Validation loss: 2.5418309044858396

Epoch: 5| Step: 5
Training loss: 1.6421079926702977
Validation loss: 2.527950697518831

Epoch: 5| Step: 6
Training loss: 1.7591692626346076
Validation loss: 2.4950889269696486

Epoch: 5| Step: 7
Training loss: 1.752209630792069
Validation loss: 2.506682452000722

Epoch: 5| Step: 8
Training loss: 1.834703720766984
Validation loss: 2.467913071295237

Epoch: 5| Step: 9
Training loss: 1.289303150255347
Validation loss: 2.4702912241130237

Epoch: 5| Step: 10
Training loss: 1.9120720926922676
Validation loss: 2.4471282219860435

Epoch: 204| Step: 0
Training loss: 1.818063025495225
Validation loss: 2.458926681095466

Epoch: 5| Step: 1
Training loss: 2.0890415826861597
Validation loss: 2.448300810140188

Epoch: 5| Step: 2
Training loss: 1.458051145590565
Validation loss: 2.473884961908178

Epoch: 5| Step: 3
Training loss: 1.3603348248308513
Validation loss: 2.45676035184629

Epoch: 5| Step: 4
Training loss: 1.9303475305220377
Validation loss: 2.4986381020653265

Epoch: 5| Step: 5
Training loss: 1.514411046838546
Validation loss: 2.537600635008259

Epoch: 5| Step: 6
Training loss: 1.6853240784187757
Validation loss: 2.530906373377221

Epoch: 5| Step: 7
Training loss: 1.873767702147555
Validation loss: 2.52807341145419

Epoch: 5| Step: 8
Training loss: 2.031087193933725
Validation loss: 2.5326607870819555

Epoch: 5| Step: 9
Training loss: 1.7655940770504899
Validation loss: 2.5166694553356805

Epoch: 5| Step: 10
Training loss: 1.7384400027358387
Validation loss: 2.5043145900509884

Epoch: 205| Step: 0
Training loss: 2.215954698746839
Validation loss: 2.467416441809721

Epoch: 5| Step: 1
Training loss: 1.6156950619999344
Validation loss: 2.4978014990241535

Epoch: 5| Step: 2
Training loss: 1.6308839350695588
Validation loss: 2.513584580018637

Epoch: 5| Step: 3
Training loss: 1.834989392200545
Validation loss: 2.506574699729247

Epoch: 5| Step: 4
Training loss: 1.4990814098368646
Validation loss: 2.496172086824289

Epoch: 5| Step: 5
Training loss: 1.8347360128994115
Validation loss: 2.4782149133112186

Epoch: 5| Step: 6
Training loss: 1.6210765424067899
Validation loss: 2.5071146837563614

Epoch: 5| Step: 7
Training loss: 1.7907484348220515
Validation loss: 2.4997401927980514

Epoch: 5| Step: 8
Training loss: 1.819478773160447
Validation loss: 2.497450935932703

Epoch: 5| Step: 9
Training loss: 1.4331660243275177
Validation loss: 2.498593266851497

Epoch: 5| Step: 10
Training loss: 1.7296068098618775
Validation loss: 2.47965401002417

Epoch: 206| Step: 0
Training loss: 1.861626103857747
Validation loss: 2.499568108199738

Epoch: 5| Step: 1
Training loss: 1.8762325050712498
Validation loss: 2.480947949836385

Epoch: 5| Step: 2
Training loss: 1.7356520066926382
Validation loss: 2.4860377186774745

Epoch: 5| Step: 3
Training loss: 1.792741948162994
Validation loss: 2.4843280406251105

Epoch: 5| Step: 4
Training loss: 1.6493347763239212
Validation loss: 2.4524469901065653

Epoch: 5| Step: 5
Training loss: 1.7376344999220101
Validation loss: 2.4698432421818146

Epoch: 5| Step: 6
Training loss: 1.5850179477481754
Validation loss: 2.5050496023442026

Epoch: 5| Step: 7
Training loss: 1.5038408537678791
Validation loss: 2.534036141877912

Epoch: 5| Step: 8
Training loss: 1.5975865579714865
Validation loss: 2.5294472804921186

Epoch: 5| Step: 9
Training loss: 1.598979523194241
Validation loss: 2.546130954134425

Epoch: 5| Step: 10
Training loss: 1.9806634028555627
Validation loss: 2.5502396712007953

Epoch: 207| Step: 0
Training loss: 1.6011943114794074
Validation loss: 2.573177314646199

Epoch: 5| Step: 1
Training loss: 1.9933695558724922
Validation loss: 2.5826430749852416

Epoch: 5| Step: 2
Training loss: 1.7582634919504683
Validation loss: 2.5580564699883217

Epoch: 5| Step: 3
Training loss: 1.433028522875762
Validation loss: 2.5342895951855717

Epoch: 5| Step: 4
Training loss: 2.2256536402328506
Validation loss: 2.4701392762585863

Epoch: 5| Step: 5
Training loss: 1.7731433910213468
Validation loss: 2.4471473785421862

Epoch: 5| Step: 6
Training loss: 1.1553379276233446
Validation loss: 2.4355532252878755

Epoch: 5| Step: 7
Training loss: 1.5218889239729754
Validation loss: 2.4115714637975976

Epoch: 5| Step: 8
Training loss: 1.4617322911950863
Validation loss: 2.4446589565574257

Epoch: 5| Step: 9
Training loss: 1.8106934982895158
Validation loss: 2.464563159317252

Epoch: 5| Step: 10
Training loss: 1.937347529164808
Validation loss: 2.4400253235007012

Epoch: 208| Step: 0
Training loss: 1.7548997270026874
Validation loss: 2.4972696058241013

Epoch: 5| Step: 1
Training loss: 1.543463905171936
Validation loss: 2.5371949067460147

Epoch: 5| Step: 2
Training loss: 1.7368558032501056
Validation loss: 2.5431692992824164

Epoch: 5| Step: 3
Training loss: 1.4662997321420954
Validation loss: 2.5340405163903177

Epoch: 5| Step: 4
Training loss: 1.538956924147955
Validation loss: 2.5066953689530775

Epoch: 5| Step: 5
Training loss: 1.4580778806474382
Validation loss: 2.545019827340649

Epoch: 5| Step: 6
Training loss: 1.8731966883598932
Validation loss: 2.522674378106139

Epoch: 5| Step: 7
Training loss: 2.05262635561115
Validation loss: 2.531871352253194

Epoch: 5| Step: 8
Training loss: 1.8262408075225312
Validation loss: 2.545911185694786

Epoch: 5| Step: 9
Training loss: 1.5169535054755825
Validation loss: 2.5239172079212215

Epoch: 5| Step: 10
Training loss: 1.5768754752419596
Validation loss: 2.5141934328002016

Epoch: 209| Step: 0
Training loss: 1.833094111643072
Validation loss: 2.5439909673395196

Epoch: 5| Step: 1
Training loss: 1.9248023340374374
Validation loss: 2.527058446704618

Epoch: 5| Step: 2
Training loss: 1.122237788119702
Validation loss: 2.5393325730182883

Epoch: 5| Step: 3
Training loss: 1.3346435794735767
Validation loss: 2.532374316778131

Epoch: 5| Step: 4
Training loss: 1.3781771799186988
Validation loss: 2.4982125588625297

Epoch: 5| Step: 5
Training loss: 1.8476655407403832
Validation loss: 2.52331054900511

Epoch: 5| Step: 6
Training loss: 1.6210213150938662
Validation loss: 2.529855436914225

Epoch: 5| Step: 7
Training loss: 2.0546275082957153
Validation loss: 2.520956400673472

Epoch: 5| Step: 8
Training loss: 1.980543989148042
Validation loss: 2.503874494889958

Epoch: 5| Step: 9
Training loss: 1.6078740500188058
Validation loss: 2.450324543947279

Epoch: 5| Step: 10
Training loss: 1.4210251165072294
Validation loss: 2.4690626431133507

Epoch: 210| Step: 0
Training loss: 1.702822457135835
Validation loss: 2.451240743380411

Epoch: 5| Step: 1
Training loss: 1.6077884891003524
Validation loss: 2.4511542894488967

Epoch: 5| Step: 2
Training loss: 1.7935046224202211
Validation loss: 2.5063129734133707

Epoch: 5| Step: 3
Training loss: 1.4156738710704408
Validation loss: 2.470830466232071

Epoch: 5| Step: 4
Training loss: 1.247638474387355
Validation loss: 2.4774261476946364

Epoch: 5| Step: 5
Training loss: 1.7175359426232921
Validation loss: 2.4586815466634837

Epoch: 5| Step: 6
Training loss: 1.8212415428200899
Validation loss: 2.502918228098151

Epoch: 5| Step: 7
Training loss: 1.3512159134679254
Validation loss: 2.4771755343927175

Epoch: 5| Step: 8
Training loss: 1.6343786586042195
Validation loss: 2.4817818401453144

Epoch: 5| Step: 9
Training loss: 1.6946573705595827
Validation loss: 2.5167866804614687

Epoch: 5| Step: 10
Training loss: 2.0702317707948428
Validation loss: 2.5244996222319775

Epoch: 211| Step: 0
Training loss: 2.0821783933479026
Validation loss: 2.498190794304949

Epoch: 5| Step: 1
Training loss: 1.1442898440384301
Validation loss: 2.495910296805437

Epoch: 5| Step: 2
Training loss: 1.6597829601004743
Validation loss: 2.473596138641392

Epoch: 5| Step: 3
Training loss: 1.6218238749007612
Validation loss: 2.4690999865165604

Epoch: 5| Step: 4
Training loss: 1.718202885332994
Validation loss: 2.4832388081151335

Epoch: 5| Step: 5
Training loss: 1.144050419026504
Validation loss: 2.466362230063201

Epoch: 5| Step: 6
Training loss: 1.7489396016077918
Validation loss: 2.514075044608959

Epoch: 5| Step: 7
Training loss: 1.5752681140666398
Validation loss: 2.4995212414403563

Epoch: 5| Step: 8
Training loss: 1.7460652803493852
Validation loss: 2.5488117302198487

Epoch: 5| Step: 9
Training loss: 1.738476894384202
Validation loss: 2.5821760710168227

Epoch: 5| Step: 10
Training loss: 1.4379050471984967
Validation loss: 2.567575128560473

Epoch: 212| Step: 0
Training loss: 1.6564630335428983
Validation loss: 2.5537422797055482

Epoch: 5| Step: 1
Training loss: 1.9830109721624216
Validation loss: 2.562931382639935

Epoch: 5| Step: 2
Training loss: 1.8118059868513732
Validation loss: 2.5186326371918466

Epoch: 5| Step: 3
Training loss: 1.3908400637168767
Validation loss: 2.510284205540833

Epoch: 5| Step: 4
Training loss: 1.6569755692324135
Validation loss: 2.5177635229554447

Epoch: 5| Step: 5
Training loss: 1.504659251168744
Validation loss: 2.5047244213321225

Epoch: 5| Step: 6
Training loss: 1.5763485418338792
Validation loss: 2.518748720555973

Epoch: 5| Step: 7
Training loss: 1.6938915010585531
Validation loss: 2.5208293664247288

Epoch: 5| Step: 8
Training loss: 1.5660101563378885
Validation loss: 2.5203917064052663

Epoch: 5| Step: 9
Training loss: 1.314533429576464
Validation loss: 2.5618149947051876

Epoch: 5| Step: 10
Training loss: 1.51392631115094
Validation loss: 2.5423185713445657

Epoch: 213| Step: 0
Training loss: 1.4948883379824356
Validation loss: 2.4980596262233328

Epoch: 5| Step: 1
Training loss: 1.667159158739272
Validation loss: 2.4734316312583102

Epoch: 5| Step: 2
Training loss: 1.328131372773084
Validation loss: 2.4950411684631164

Epoch: 5| Step: 3
Training loss: 1.68632275525498
Validation loss: 2.466587517800764

Epoch: 5| Step: 4
Training loss: 1.597160206387817
Validation loss: 2.4694045105126534

Epoch: 5| Step: 5
Training loss: 1.4292416737320435
Validation loss: 2.451839630969377

Epoch: 5| Step: 6
Training loss: 1.5361941956455991
Validation loss: 2.462487243541014

Epoch: 5| Step: 7
Training loss: 1.6022972840444742
Validation loss: 2.480496581792426

Epoch: 5| Step: 8
Training loss: 1.7341572392855287
Validation loss: 2.5055473339946763

Epoch: 5| Step: 9
Training loss: 1.6040971006031561
Validation loss: 2.5246317237203884

Epoch: 5| Step: 10
Training loss: 1.7250289665775518
Validation loss: 2.5307058242892957

Epoch: 214| Step: 0
Training loss: 1.3474941874928992
Validation loss: 2.546782050445706

Epoch: 5| Step: 1
Training loss: 1.0096405365015226
Validation loss: 2.536341418350208

Epoch: 5| Step: 2
Training loss: 1.7259863673276234
Validation loss: 2.53455156609721

Epoch: 5| Step: 3
Training loss: 1.5218438836584514
Validation loss: 2.522850260626068

Epoch: 5| Step: 4
Training loss: 1.522917595205098
Validation loss: 2.5092721858693525

Epoch: 5| Step: 5
Training loss: 1.4736798925444077
Validation loss: 2.5025368176351157

Epoch: 5| Step: 6
Training loss: 1.9881148053183388
Validation loss: 2.4866714425461605

Epoch: 5| Step: 7
Training loss: 1.4456034599444345
Validation loss: 2.4899745120168015

Epoch: 5| Step: 8
Training loss: 1.4229930631906798
Validation loss: 2.5105515375178933

Epoch: 5| Step: 9
Training loss: 1.8157927758967374
Validation loss: 2.5198583399650483

Epoch: 5| Step: 10
Training loss: 1.796436953017214
Validation loss: 2.54415198796579

Epoch: 215| Step: 0
Training loss: 1.7365549495053034
Validation loss: 2.572230929493119

Epoch: 5| Step: 1
Training loss: 1.497730684296244
Validation loss: 2.561991693447872

Epoch: 5| Step: 2
Training loss: 1.3331870157703136
Validation loss: 2.5499023079984107

Epoch: 5| Step: 3
Training loss: 1.6778988563281343
Validation loss: 2.531514251094178

Epoch: 5| Step: 4
Training loss: 1.6003694137646176
Validation loss: 2.5498288447627364

Epoch: 5| Step: 5
Training loss: 1.6882284499512659
Validation loss: 2.5462600274567433

Epoch: 5| Step: 6
Training loss: 1.6464055993907085
Validation loss: 2.537017630893497

Epoch: 5| Step: 7
Training loss: 1.4980426574408932
Validation loss: 2.5260100282887286

Epoch: 5| Step: 8
Training loss: 1.5607822130952407
Validation loss: 2.5324587592530396

Epoch: 5| Step: 9
Training loss: 1.4522191987950293
Validation loss: 2.543897690196479

Epoch: 5| Step: 10
Training loss: 1.5844471510610934
Validation loss: 2.5122302586495904

Epoch: 216| Step: 0
Training loss: 1.2530905188480275
Validation loss: 2.5238846136684123

Epoch: 5| Step: 1
Training loss: 1.446262851351363
Validation loss: 2.4774551788391945

Epoch: 5| Step: 2
Training loss: 1.7387274351650912
Validation loss: 2.454216070900263

Epoch: 5| Step: 3
Training loss: 1.6960714021578371
Validation loss: 2.4476869020171805

Epoch: 5| Step: 4
Training loss: 1.2454921023326329
Validation loss: 2.480569236088761

Epoch: 5| Step: 5
Training loss: 1.7359594032972776
Validation loss: 2.4802420718877207

Epoch: 5| Step: 6
Training loss: 1.6381245041038348
Validation loss: 2.5081690487303896

Epoch: 5| Step: 7
Training loss: 1.2819395768273047
Validation loss: 2.5635965213707865

Epoch: 5| Step: 8
Training loss: 1.883230012687092
Validation loss: 2.553239494119496

Epoch: 5| Step: 9
Training loss: 1.3313800193083862
Validation loss: 2.5294086317106355

Epoch: 5| Step: 10
Training loss: 1.6876343567661365
Validation loss: 2.507386022162851

Epoch: 217| Step: 0
Training loss: 2.0312443659777633
Validation loss: 2.4735620013880997

Epoch: 5| Step: 1
Training loss: 1.3505900859424267
Validation loss: 2.4244279910350968

Epoch: 5| Step: 2
Training loss: 1.6712123234909406
Validation loss: 2.4723950993839185

Epoch: 5| Step: 3
Training loss: 1.2699189518425822
Validation loss: 2.4680458737629944

Epoch: 5| Step: 4
Training loss: 1.3021213627665849
Validation loss: 2.494980029746853

Epoch: 5| Step: 5
Training loss: 1.7322508029701904
Validation loss: 2.557135979707049

Epoch: 5| Step: 6
Training loss: 1.2370425987710838
Validation loss: 2.581461805740152

Epoch: 5| Step: 7
Training loss: 1.6248039714244424
Validation loss: 2.5605802810962897

Epoch: 5| Step: 8
Training loss: 1.5685360857649409
Validation loss: 2.5717893456292855

Epoch: 5| Step: 9
Training loss: 1.3721180537596114
Validation loss: 2.5333161585289843

Epoch: 5| Step: 10
Training loss: 1.7995296605520408
Validation loss: 2.4831195872964265

Epoch: 218| Step: 0
Training loss: 1.5931049612348165
Validation loss: 2.43686866419691

Epoch: 5| Step: 1
Training loss: 1.3780795204460632
Validation loss: 2.4396850966418664

Epoch: 5| Step: 2
Training loss: 1.3774826005781815
Validation loss: 2.383689333066515

Epoch: 5| Step: 3
Training loss: 1.3749440788688387
Validation loss: 2.430014889572442

Epoch: 5| Step: 4
Training loss: 1.495850067611781
Validation loss: 2.4261035403564195

Epoch: 5| Step: 5
Training loss: 1.6367537829307468
Validation loss: 2.4519144999300977

Epoch: 5| Step: 6
Training loss: 1.384473718778799
Validation loss: 2.533707681834664

Epoch: 5| Step: 7
Training loss: 1.4295972785206545
Validation loss: 2.5716539957752516

Epoch: 5| Step: 8
Training loss: 1.8218412733146068
Validation loss: 2.600627452874825

Epoch: 5| Step: 9
Training loss: 1.6770655550123006
Validation loss: 2.6250077016534834

Epoch: 5| Step: 10
Training loss: 1.811353123311162
Validation loss: 2.60482421809886

Epoch: 219| Step: 0
Training loss: 1.4315408669306744
Validation loss: 2.5707507460081533

Epoch: 5| Step: 1
Training loss: 1.3559976474831579
Validation loss: 2.5122554680667144

Epoch: 5| Step: 2
Training loss: 1.4979228897213053
Validation loss: 2.4843130683777033

Epoch: 5| Step: 3
Training loss: 1.0334994318480237
Validation loss: 2.4807439722283475

Epoch: 5| Step: 4
Training loss: 1.8075080397599887
Validation loss: 2.4656286480325815

Epoch: 5| Step: 5
Training loss: 1.5376213801162815
Validation loss: 2.4218421110790667

Epoch: 5| Step: 6
Training loss: 1.8689380563887514
Validation loss: 2.4555802075269915

Epoch: 5| Step: 7
Training loss: 1.1044250521843182
Validation loss: 2.487078231456017

Epoch: 5| Step: 8
Training loss: 1.8840819072372388
Validation loss: 2.5395113176169146

Epoch: 5| Step: 9
Training loss: 1.4107946498875399
Validation loss: 2.5528041649510227

Epoch: 5| Step: 10
Training loss: 1.4334343346044578
Validation loss: 2.616370622018157

Epoch: 220| Step: 0
Training loss: 1.4282405180507005
Validation loss: 2.6295973750573687

Epoch: 5| Step: 1
Training loss: 1.3816558828420045
Validation loss: 2.64761722866981

Epoch: 5| Step: 2
Training loss: 1.6966848839466944
Validation loss: 2.5969176970905643

Epoch: 5| Step: 3
Training loss: 1.5299075723293238
Validation loss: 2.566050913705216

Epoch: 5| Step: 4
Training loss: 1.3751192041224152
Validation loss: 2.511961594880109

Epoch: 5| Step: 5
Training loss: 1.7142101325108046
Validation loss: 2.4657205707330556

Epoch: 5| Step: 6
Training loss: 1.4237127479723617
Validation loss: 2.4347619664404663

Epoch: 5| Step: 7
Training loss: 1.5016106858793399
Validation loss: 2.418356760261707

Epoch: 5| Step: 8
Training loss: 1.5120650493616261
Validation loss: 2.4318407441818835

Epoch: 5| Step: 9
Training loss: 1.5074272651902205
Validation loss: 2.4322486391078275

Epoch: 5| Step: 10
Training loss: 1.6083040840902088
Validation loss: 2.431655244717017

Epoch: 221| Step: 0
Training loss: 1.5588076643078226
Validation loss: 2.467799379467153

Epoch: 5| Step: 1
Training loss: 1.7242710563631716
Validation loss: 2.488348802857015

Epoch: 5| Step: 2
Training loss: 1.329269678833632
Validation loss: 2.4761941199169937

Epoch: 5| Step: 3
Training loss: 1.4282744882421683
Validation loss: 2.4984110735793723

Epoch: 5| Step: 4
Training loss: 1.1426418188877288
Validation loss: 2.481715494835811

Epoch: 5| Step: 5
Training loss: 1.2901472209491123
Validation loss: 2.5136849472624263

Epoch: 5| Step: 6
Training loss: 1.6694493746283599
Validation loss: 2.515243435095289

Epoch: 5| Step: 7
Training loss: 1.6975257595169602
Validation loss: 2.501771892698307

Epoch: 5| Step: 8
Training loss: 1.4114815779269918
Validation loss: 2.486001279379419

Epoch: 5| Step: 9
Training loss: 1.4999038347571778
Validation loss: 2.4740440891776125

Epoch: 5| Step: 10
Training loss: 1.3346401406801558
Validation loss: 2.459490930207516

Epoch: 222| Step: 0
Training loss: 1.32507202204609
Validation loss: 2.4513475395101403

Epoch: 5| Step: 1
Training loss: 1.6834386767419922
Validation loss: 2.454420381137948

Epoch: 5| Step: 2
Training loss: 1.4793294181296301
Validation loss: 2.435175117995625

Epoch: 5| Step: 3
Training loss: 1.466885133569316
Validation loss: 2.4434240800230267

Epoch: 5| Step: 4
Training loss: 1.7071882302319163
Validation loss: 2.470505478778704

Epoch: 5| Step: 5
Training loss: 1.3140942110460576
Validation loss: 2.4709528592419012

Epoch: 5| Step: 6
Training loss: 1.37764429371688
Validation loss: 2.4773641582584967

Epoch: 5| Step: 7
Training loss: 1.501213933557523
Validation loss: 2.4894379157854254

Epoch: 5| Step: 8
Training loss: 1.4498182018358832
Validation loss: 2.536471435556159

Epoch: 5| Step: 9
Training loss: 1.3361185408500427
Validation loss: 2.5398221554182605

Epoch: 5| Step: 10
Training loss: 1.3440766048511714
Validation loss: 2.5520953467971355

Epoch: 223| Step: 0
Training loss: 1.0291446812143694
Validation loss: 2.5637179835834942

Epoch: 5| Step: 1
Training loss: 1.0916236917515625
Validation loss: 2.5463816491251956

Epoch: 5| Step: 2
Training loss: 1.2046782635484368
Validation loss: 2.5102404719512244

Epoch: 5| Step: 3
Training loss: 1.3166037391561984
Validation loss: 2.5237646657529824

Epoch: 5| Step: 4
Training loss: 1.2303534559700442
Validation loss: 2.5238682478204586

Epoch: 5| Step: 5
Training loss: 1.9479807130888858
Validation loss: 2.5236656502104817

Epoch: 5| Step: 6
Training loss: 1.9495335020917692
Validation loss: 2.5329443110982317

Epoch: 5| Step: 7
Training loss: 1.4561354104992148
Validation loss: 2.535004827081335

Epoch: 5| Step: 8
Training loss: 1.7097795304170234
Validation loss: 2.5279120846761165

Epoch: 5| Step: 9
Training loss: 1.3970313648206336
Validation loss: 2.542021223527866

Epoch: 5| Step: 10
Training loss: 1.0897905890512265
Validation loss: 2.492954217090056

Epoch: 224| Step: 0
Training loss: 1.4490776713097209
Validation loss: 2.5156839616423956

Epoch: 5| Step: 1
Training loss: 1.5228318012908002
Validation loss: 2.485506821123745

Epoch: 5| Step: 2
Training loss: 1.0827696446336814
Validation loss: 2.49539010682247

Epoch: 5| Step: 3
Training loss: 1.0652380053210393
Validation loss: 2.4711438280582136

Epoch: 5| Step: 4
Training loss: 1.60834447958976
Validation loss: 2.5031891713439114

Epoch: 5| Step: 5
Training loss: 1.658031153663451
Validation loss: 2.5119016456960974

Epoch: 5| Step: 6
Training loss: 1.3016503440641076
Validation loss: 2.5221113644834796

Epoch: 5| Step: 7
Training loss: 1.087194141039805
Validation loss: 2.5313708186512747

Epoch: 5| Step: 8
Training loss: 1.6865032219130782
Validation loss: 2.544948096324363

Epoch: 5| Step: 9
Training loss: 1.5230604438734987
Validation loss: 2.5564142839850645

Epoch: 5| Step: 10
Training loss: 1.4086210395255636
Validation loss: 2.5792313524709614

Epoch: 225| Step: 0
Training loss: 1.3982427024494006
Validation loss: 2.554467120886299

Epoch: 5| Step: 1
Training loss: 1.2674504996119866
Validation loss: 2.5516980608466344

Epoch: 5| Step: 2
Training loss: 1.0777922407034128
Validation loss: 2.5703233976158364

Epoch: 5| Step: 3
Training loss: 1.6714454883492524
Validation loss: 2.551281598955517

Epoch: 5| Step: 4
Training loss: 1.527211527454879
Validation loss: 2.513899563846945

Epoch: 5| Step: 5
Training loss: 1.1155265251743747
Validation loss: 2.476857830354695

Epoch: 5| Step: 6
Training loss: 1.7457027808321572
Validation loss: 2.4801737483228634

Epoch: 5| Step: 7
Training loss: 1.5753729968949268
Validation loss: 2.4708651786738174

Epoch: 5| Step: 8
Training loss: 1.7278191321651557
Validation loss: 2.467710051396601

Epoch: 5| Step: 9
Training loss: 1.07431895395571
Validation loss: 2.5061033779091684

Epoch: 5| Step: 10
Training loss: 1.0610588622308625
Validation loss: 2.4608274352863764

Epoch: 226| Step: 0
Training loss: 1.0603810667246425
Validation loss: 2.5113178685305293

Epoch: 5| Step: 1
Training loss: 1.4498431975985129
Validation loss: 2.5494087761989452

Epoch: 5| Step: 2
Training loss: 1.7228302813656668
Validation loss: 2.5319408075195677

Epoch: 5| Step: 3
Training loss: 1.2653234146035575
Validation loss: 2.4817624344342684

Epoch: 5| Step: 4
Training loss: 1.4008958402655916
Validation loss: 2.4846734963821384

Epoch: 5| Step: 5
Training loss: 1.2655345743159538
Validation loss: 2.465099613114973

Epoch: 5| Step: 6
Training loss: 1.590216140811198
Validation loss: 2.44598271503049

Epoch: 5| Step: 7
Training loss: 1.2622487753010108
Validation loss: 2.4552070138157234

Epoch: 5| Step: 8
Training loss: 1.6149844583997712
Validation loss: 2.481109601984814

Epoch: 5| Step: 9
Training loss: 1.4057456065636218
Validation loss: 2.497806306484308

Epoch: 5| Step: 10
Training loss: 1.2615731925974238
Validation loss: 2.511048944811915

Epoch: 227| Step: 0
Training loss: 1.0443396541657026
Validation loss: 2.5082561908137913

Epoch: 5| Step: 1
Training loss: 1.5735996439329751
Validation loss: 2.487563415426409

Epoch: 5| Step: 2
Training loss: 1.2186452869523074
Validation loss: 2.4973308537627394

Epoch: 5| Step: 3
Training loss: 1.1477102455228945
Validation loss: 2.471272102524471

Epoch: 5| Step: 4
Training loss: 1.4624259832187858
Validation loss: 2.4529490112858214

Epoch: 5| Step: 5
Training loss: 1.7990951091440985
Validation loss: 2.4745289590164576

Epoch: 5| Step: 6
Training loss: 1.311241272932745
Validation loss: 2.518529370126235

Epoch: 5| Step: 7
Training loss: 1.109058657392572
Validation loss: 2.5312646368898153

Epoch: 5| Step: 8
Training loss: 1.6387506586534704
Validation loss: 2.515254461226287

Epoch: 5| Step: 9
Training loss: 1.4072191925173507
Validation loss: 2.5336531121000916

Epoch: 5| Step: 10
Training loss: 1.4171211504729573
Validation loss: 2.5153476422319163

Epoch: 228| Step: 0
Training loss: 1.1829050408347765
Validation loss: 2.4621812726081522

Epoch: 5| Step: 1
Training loss: 0.8677199164110123
Validation loss: 2.4559919749323207

Epoch: 5| Step: 2
Training loss: 1.2578832476130484
Validation loss: 2.4339613911263474

Epoch: 5| Step: 3
Training loss: 1.2857344697700068
Validation loss: 2.471505504421048

Epoch: 5| Step: 4
Training loss: 1.9769397722331121
Validation loss: 2.479946313419836

Epoch: 5| Step: 5
Training loss: 1.3123608469993366
Validation loss: 2.486601601736688

Epoch: 5| Step: 6
Training loss: 1.4481668690640963
Validation loss: 2.519584878152199

Epoch: 5| Step: 7
Training loss: 1.592157353498567
Validation loss: 2.531257396440576

Epoch: 5| Step: 8
Training loss: 1.1869020462369464
Validation loss: 2.484434007792761

Epoch: 5| Step: 9
Training loss: 1.3424278674646557
Validation loss: 2.47321929480123

Epoch: 5| Step: 10
Training loss: 1.3774190344442319
Validation loss: 2.491174136509549

Epoch: 229| Step: 0
Training loss: 1.2962903462883975
Validation loss: 2.434248608653749

Epoch: 5| Step: 1
Training loss: 1.187707280589727
Validation loss: 2.4575037358559304

Epoch: 5| Step: 2
Training loss: 1.6289093968935056
Validation loss: 2.446203263588182

Epoch: 5| Step: 3
Training loss: 1.6376843210396284
Validation loss: 2.4678503671247594

Epoch: 5| Step: 4
Training loss: 1.5261941861781385
Validation loss: 2.4651827545509404

Epoch: 5| Step: 5
Training loss: 1.4648981923476736
Validation loss: 2.4594291600054095

Epoch: 5| Step: 6
Training loss: 0.7879356420589924
Validation loss: 2.5085590345085866

Epoch: 5| Step: 7
Training loss: 1.3307228262414947
Validation loss: 2.465751956336215

Epoch: 5| Step: 8
Training loss: 1.1812263708425617
Validation loss: 2.5080392560137557

Epoch: 5| Step: 9
Training loss: 1.4851345327556358
Validation loss: 2.5131631518349806

Epoch: 5| Step: 10
Training loss: 1.1843587084130325
Validation loss: 2.52874505719505

Epoch: 230| Step: 0
Training loss: 1.1258860383778566
Validation loss: 2.5406194338627626

Epoch: 5| Step: 1
Training loss: 1.4282801637727827
Validation loss: 2.573038831061351

Epoch: 5| Step: 2
Training loss: 1.1220485329900538
Validation loss: 2.5901405155658273

Epoch: 5| Step: 3
Training loss: 1.4545571437821163
Validation loss: 2.5283914272911385

Epoch: 5| Step: 4
Training loss: 1.4457905571552547
Validation loss: 2.5500777496719627

Epoch: 5| Step: 5
Training loss: 1.3801592356268297
Validation loss: 2.525423261738664

Epoch: 5| Step: 6
Training loss: 1.7040311170297877
Validation loss: 2.485512999416313

Epoch: 5| Step: 7
Training loss: 0.9858989726184956
Validation loss: 2.4759287658819735

Epoch: 5| Step: 8
Training loss: 1.446379231817391
Validation loss: 2.480756966367722

Epoch: 5| Step: 9
Training loss: 1.248588623525182
Validation loss: 2.4705139666216724

Epoch: 5| Step: 10
Training loss: 1.1083367553218322
Validation loss: 2.4919375379353266

Epoch: 231| Step: 0
Training loss: 1.3862427660217587
Validation loss: 2.503733320812358

Epoch: 5| Step: 1
Training loss: 1.2002507345192968
Validation loss: 2.530102371271162

Epoch: 5| Step: 2
Training loss: 1.2568922289592694
Validation loss: 2.5510420388691557

Epoch: 5| Step: 3
Training loss: 1.4338627284863974
Validation loss: 2.5404024199169957

Epoch: 5| Step: 4
Training loss: 1.3326483496844266
Validation loss: 2.5425706933720194

Epoch: 5| Step: 5
Training loss: 1.2317197223191547
Validation loss: 2.534078205273898

Epoch: 5| Step: 6
Training loss: 1.093859966744516
Validation loss: 2.5042659049509033

Epoch: 5| Step: 7
Training loss: 1.7893567238959265
Validation loss: 2.4922961088165203

Epoch: 5| Step: 8
Training loss: 1.2933846810231937
Validation loss: 2.4446193133620118

Epoch: 5| Step: 9
Training loss: 1.1658794381053204
Validation loss: 2.3975224912857653

Epoch: 5| Step: 10
Training loss: 1.5070291965088962
Validation loss: 2.411331032713095

Epoch: 232| Step: 0
Training loss: 1.0764522014305706
Validation loss: 2.4237466492885407

Epoch: 5| Step: 1
Training loss: 1.3556691222267494
Validation loss: 2.432841980441281

Epoch: 5| Step: 2
Training loss: 1.3710545808680183
Validation loss: 2.4526413100459163

Epoch: 5| Step: 3
Training loss: 1.306910511192967
Validation loss: 2.489635485690115

Epoch: 5| Step: 4
Training loss: 1.4970634644433232
Validation loss: 2.5379953504158883

Epoch: 5| Step: 5
Training loss: 1.3897219951406723
Validation loss: 2.5082457349048375

Epoch: 5| Step: 6
Training loss: 0.9375299131071678
Validation loss: 2.5260613597478163

Epoch: 5| Step: 7
Training loss: 1.4329028218628317
Validation loss: 2.5275785841045426

Epoch: 5| Step: 8
Training loss: 1.653680643831646
Validation loss: 2.5016848803387024

Epoch: 5| Step: 9
Training loss: 1.1518217811978486
Validation loss: 2.4885175986824977

Epoch: 5| Step: 10
Training loss: 1.2757271151903709
Validation loss: 2.481278485781713

Epoch: 233| Step: 0
Training loss: 1.7701340884265016
Validation loss: 2.4534449611969706

Epoch: 5| Step: 1
Training loss: 0.9630906088875694
Validation loss: 2.436421690386931

Epoch: 5| Step: 2
Training loss: 1.379469110953983
Validation loss: 2.4356752985384036

Epoch: 5| Step: 3
Training loss: 1.2386911959120224
Validation loss: 2.450540664639859

Epoch: 5| Step: 4
Training loss: 1.2365011422583536
Validation loss: 2.488609644266065

Epoch: 5| Step: 5
Training loss: 1.5597488597309916
Validation loss: 2.497775629002579

Epoch: 5| Step: 6
Training loss: 1.2155477072652046
Validation loss: 2.503709425309386

Epoch: 5| Step: 7
Training loss: 1.0145916890786586
Validation loss: 2.514619500335905

Epoch: 5| Step: 8
Training loss: 1.2055982953995499
Validation loss: 2.5160964679937745

Epoch: 5| Step: 9
Training loss: 0.8826876864353073
Validation loss: 2.5377211028211994

Epoch: 5| Step: 10
Training loss: 1.6185908471302495
Validation loss: 2.544304931068208

Epoch: 234| Step: 0
Training loss: 1.2056527769251748
Validation loss: 2.482549001340666

Epoch: 5| Step: 1
Training loss: 1.2266904922085793
Validation loss: 2.4830238825317803

Epoch: 5| Step: 2
Training loss: 1.0077495703160424
Validation loss: 2.440639706610745

Epoch: 5| Step: 3
Training loss: 1.2973823014754136
Validation loss: 2.439986415619627

Epoch: 5| Step: 4
Training loss: 1.1313906461000292
Validation loss: 2.4408006783195653

Epoch: 5| Step: 5
Training loss: 0.8643972510661732
Validation loss: 2.439455048160755

Epoch: 5| Step: 6
Training loss: 1.7442015223962426
Validation loss: 2.4285308751218713

Epoch: 5| Step: 7
Training loss: 1.4945592754984713
Validation loss: 2.4263777101682633

Epoch: 5| Step: 8
Training loss: 1.5891089838631598
Validation loss: 2.4669461007912825

Epoch: 5| Step: 9
Training loss: 1.2715170954231199
Validation loss: 2.4470550032952962

Epoch: 5| Step: 10
Training loss: 0.7720768452258683
Validation loss: 2.427389728068405

Epoch: 235| Step: 0
Training loss: 1.3231665107511374
Validation loss: 2.4743521283152687

Epoch: 5| Step: 1
Training loss: 0.6974104829654533
Validation loss: 2.501215700695157

Epoch: 5| Step: 2
Training loss: 1.245462096070536
Validation loss: 2.5129820791617776

Epoch: 5| Step: 3
Training loss: 1.4987779248509867
Validation loss: 2.5221764311951613

Epoch: 5| Step: 4
Training loss: 1.1547727168826578
Validation loss: 2.5183485784389728

Epoch: 5| Step: 5
Training loss: 0.991413114627673
Validation loss: 2.488990280217754

Epoch: 5| Step: 6
Training loss: 1.3326295197112081
Validation loss: 2.4555137117922166

Epoch: 5| Step: 7
Training loss: 1.5363922191123909
Validation loss: 2.4750864040986844

Epoch: 5| Step: 8
Training loss: 0.9039231386972579
Validation loss: 2.444063244629917

Epoch: 5| Step: 9
Training loss: 1.5234179373243164
Validation loss: 2.456672572239596

Epoch: 5| Step: 10
Training loss: 1.4060229224076954
Validation loss: 2.4826739733383274

Epoch: 236| Step: 0
Training loss: 0.8628267153156444
Validation loss: 2.492684855418541

Epoch: 5| Step: 1
Training loss: 0.9351951877834033
Validation loss: 2.4934783903594866

Epoch: 5| Step: 2
Training loss: 1.1732375806423048
Validation loss: 2.526038882160248

Epoch: 5| Step: 3
Training loss: 1.2969398482321977
Validation loss: 2.5432895456609246

Epoch: 5| Step: 4
Training loss: 1.177173132832801
Validation loss: 2.5656078809536966

Epoch: 5| Step: 5
Training loss: 1.2081350569447054
Validation loss: 2.5805035753050323

Epoch: 5| Step: 6
Training loss: 1.657137075423504
Validation loss: 2.546549226817639

Epoch: 5| Step: 7
Training loss: 1.397978467565351
Validation loss: 2.52051423759306

Epoch: 5| Step: 8
Training loss: 1.4318439500589988
Validation loss: 2.517836460150718

Epoch: 5| Step: 9
Training loss: 0.9697685424691964
Validation loss: 2.536961226522484

Epoch: 5| Step: 10
Training loss: 1.400021300835008
Validation loss: 2.504861393493754

Epoch: 237| Step: 0
Training loss: 0.8300997024424389
Validation loss: 2.551805669878765

Epoch: 5| Step: 1
Training loss: 0.8235933362669928
Validation loss: 2.5257460960517677

Epoch: 5| Step: 2
Training loss: 1.3584853582593526
Validation loss: 2.5260635955200392

Epoch: 5| Step: 3
Training loss: 1.2802356798786076
Validation loss: 2.543976490839875

Epoch: 5| Step: 4
Training loss: 1.2696760828592568
Validation loss: 2.550543234047699

Epoch: 5| Step: 5
Training loss: 1.0340720202600575
Validation loss: 2.554960266084305

Epoch: 5| Step: 6
Training loss: 1.1590432630697698
Validation loss: 2.5553587925003165

Epoch: 5| Step: 7
Training loss: 1.3385205199158203
Validation loss: 2.599479673475

Epoch: 5| Step: 8
Training loss: 1.4774482129311033
Validation loss: 2.5675905413596753

Epoch: 5| Step: 9
Training loss: 1.5871311450078274
Validation loss: 2.533113944631028

Epoch: 5| Step: 10
Training loss: 1.2252757618423245
Validation loss: 2.5220038322781395

Epoch: 238| Step: 0
Training loss: 1.0930970559057236
Validation loss: 2.471409234761281

Epoch: 5| Step: 1
Training loss: 1.2224148155443009
Validation loss: 2.4934732856475974

Epoch: 5| Step: 2
Training loss: 1.1137012425634525
Validation loss: 2.4499646813159623

Epoch: 5| Step: 3
Training loss: 1.3891330816918939
Validation loss: 2.4795747181414862

Epoch: 5| Step: 4
Training loss: 1.2912751599175116
Validation loss: 2.5252082666932445

Epoch: 5| Step: 5
Training loss: 0.9651889878350284
Validation loss: 2.4911656609156982

Epoch: 5| Step: 6
Training loss: 1.397005125466449
Validation loss: 2.5181401730523665

Epoch: 5| Step: 7
Training loss: 1.272682246814383
Validation loss: 2.543412986607115

Epoch: 5| Step: 8
Training loss: 1.460285469652358
Validation loss: 2.522234989139851

Epoch: 5| Step: 9
Training loss: 1.1448074372130623
Validation loss: 2.514986116440337

Epoch: 5| Step: 10
Training loss: 0.9976972053264634
Validation loss: 2.4944947775745345

Epoch: 239| Step: 0
Training loss: 1.0859164777957613
Validation loss: 2.4759167735507894

Epoch: 5| Step: 1
Training loss: 1.2488378844776222
Validation loss: 2.4883111837412155

Epoch: 5| Step: 2
Training loss: 1.0848789132578711
Validation loss: 2.4557840329003313

Epoch: 5| Step: 3
Training loss: 1.602430601477034
Validation loss: 2.4514631969514253

Epoch: 5| Step: 4
Training loss: 1.5716733587020737
Validation loss: 2.5095304694108043

Epoch: 5| Step: 5
Training loss: 1.0219128149659351
Validation loss: 2.519319542673069

Epoch: 5| Step: 6
Training loss: 1.086989188532682
Validation loss: 2.5432291202705986

Epoch: 5| Step: 7
Training loss: 1.4221003427204513
Validation loss: 2.5651165129220406

Epoch: 5| Step: 8
Training loss: 1.140867233682937
Validation loss: 2.5382552375140164

Epoch: 5| Step: 9
Training loss: 0.8901452562651976
Validation loss: 2.5142754111789203

Epoch: 5| Step: 10
Training loss: 1.1711982298720383
Validation loss: 2.5164257485411983

Epoch: 240| Step: 0
Training loss: 1.419151128451273
Validation loss: 2.507651733974152

Epoch: 5| Step: 1
Training loss: 1.1592872010580675
Validation loss: 2.523425010102401

Epoch: 5| Step: 2
Training loss: 1.2818425831817908
Validation loss: 2.514650745607825

Epoch: 5| Step: 3
Training loss: 1.3448879834862122
Validation loss: 2.507601788702576

Epoch: 5| Step: 4
Training loss: 1.2053314882404278
Validation loss: 2.516726267624399

Epoch: 5| Step: 5
Training loss: 1.0319196665273385
Validation loss: 2.4994898696052568

Epoch: 5| Step: 6
Training loss: 0.8816100176499954
Validation loss: 2.483513634591845

Epoch: 5| Step: 7
Training loss: 1.0564325660166518
Validation loss: 2.502478911296119

Epoch: 5| Step: 8
Training loss: 1.3605803046115785
Validation loss: 2.48271709073915

Epoch: 5| Step: 9
Training loss: 1.363191967857902
Validation loss: 2.474183164957598

Epoch: 5| Step: 10
Training loss: 1.0093653935308937
Validation loss: 2.507843638919908

Epoch: 241| Step: 0
Training loss: 1.145975497125308
Validation loss: 2.5062774538861485

Epoch: 5| Step: 1
Training loss: 1.4426398232325406
Validation loss: 2.5480663523602165

Epoch: 5| Step: 2
Training loss: 1.0932477615371912
Validation loss: 2.5578550809090643

Epoch: 5| Step: 3
Training loss: 1.227110139114687
Validation loss: 2.479204137416752

Epoch: 5| Step: 4
Training loss: 0.891740435077093
Validation loss: 2.4995338169361108

Epoch: 5| Step: 5
Training loss: 1.2240529720431281
Validation loss: 2.4805451515477883

Epoch: 5| Step: 6
Training loss: 0.9129304967749919
Validation loss: 2.497308616488647

Epoch: 5| Step: 7
Training loss: 1.1398269265118404
Validation loss: 2.4979418168100147

Epoch: 5| Step: 8
Training loss: 1.2784753855460587
Validation loss: 2.5263969256990455

Epoch: 5| Step: 9
Training loss: 0.9943450837397465
Validation loss: 2.5689136209202306

Epoch: 5| Step: 10
Training loss: 1.7043066562649067
Validation loss: 2.55353838936601

Epoch: 242| Step: 0
Training loss: 0.8698454324395266
Validation loss: 2.5615549813566205

Epoch: 5| Step: 1
Training loss: 1.2270494697099288
Validation loss: 2.5131341598251637

Epoch: 5| Step: 2
Training loss: 0.9516881837822977
Validation loss: 2.524485969753049

Epoch: 5| Step: 3
Training loss: 1.420349224694308
Validation loss: 2.4475139778049204

Epoch: 5| Step: 4
Training loss: 1.0205693130578795
Validation loss: 2.448145828743841

Epoch: 5| Step: 5
Training loss: 0.7152407434951872
Validation loss: 2.4451229374898036

Epoch: 5| Step: 6
Training loss: 1.1533282196523238
Validation loss: 2.489261822855433

Epoch: 5| Step: 7
Training loss: 0.8885893731020353
Validation loss: 2.4788262979902806

Epoch: 5| Step: 8
Training loss: 1.2607654005021929
Validation loss: 2.4864264578175987

Epoch: 5| Step: 9
Training loss: 1.5206569238362038
Validation loss: 2.503251989854801

Epoch: 5| Step: 10
Training loss: 1.6930759285102743
Validation loss: 2.5311963576883487

Epoch: 243| Step: 0
Training loss: 1.2130721443213883
Validation loss: 2.5515953041007893

Epoch: 5| Step: 1
Training loss: 0.8332944781463905
Validation loss: 2.5131438772504686

Epoch: 5| Step: 2
Training loss: 0.961886611779155
Validation loss: 2.5435844104449243

Epoch: 5| Step: 3
Training loss: 0.8111713990867091
Validation loss: 2.5480900985096384

Epoch: 5| Step: 4
Training loss: 1.4193239907858644
Validation loss: 2.5203185573278484

Epoch: 5| Step: 5
Training loss: 1.1654522683455852
Validation loss: 2.531570878092697

Epoch: 5| Step: 6
Training loss: 1.466705034938989
Validation loss: 2.5172984384428

Epoch: 5| Step: 7
Training loss: 0.7004201785999357
Validation loss: 2.5420414676685943

Epoch: 5| Step: 8
Training loss: 1.6030064470205518
Validation loss: 2.5279259306045225

Epoch: 5| Step: 9
Training loss: 1.1984117010291473
Validation loss: 2.5130754301140263

Epoch: 5| Step: 10
Training loss: 0.9519852248936601
Validation loss: 2.5549409415795865

Epoch: 244| Step: 0
Training loss: 0.9915102652356442
Validation loss: 2.5132174942484156

Epoch: 5| Step: 1
Training loss: 0.8426592098546968
Validation loss: 2.536134380322228

Epoch: 5| Step: 2
Training loss: 1.3007133397426385
Validation loss: 2.5422131206313217

Epoch: 5| Step: 3
Training loss: 1.225873036591988
Validation loss: 2.5405382556059757

Epoch: 5| Step: 4
Training loss: 1.1637602035943795
Validation loss: 2.558950779501416

Epoch: 5| Step: 5
Training loss: 1.209755548343442
Validation loss: 2.518668534157788

Epoch: 5| Step: 6
Training loss: 1.7169757354923603
Validation loss: 2.509192380146034

Epoch: 5| Step: 7
Training loss: 0.8861795542149766
Validation loss: 2.4925151204183047

Epoch: 5| Step: 8
Training loss: 1.2525203092531285
Validation loss: 2.477203524267455

Epoch: 5| Step: 9
Training loss: 0.9860402508619439
Validation loss: 2.456081250090173

Epoch: 5| Step: 10
Training loss: 0.8669471063857881
Validation loss: 2.467287881165617

Epoch: 245| Step: 0
Training loss: 1.5088231943954868
Validation loss: 2.468844693747005

Epoch: 5| Step: 1
Training loss: 1.0933706988272625
Validation loss: 2.502687179057505

Epoch: 5| Step: 2
Training loss: 0.946989573732481
Validation loss: 2.502177961255004

Epoch: 5| Step: 3
Training loss: 1.2767434298957094
Validation loss: 2.5182801964159545

Epoch: 5| Step: 4
Training loss: 1.245114841832962
Validation loss: 2.490422731402401

Epoch: 5| Step: 5
Training loss: 1.2065909857401997
Validation loss: 2.475731578779806

Epoch: 5| Step: 6
Training loss: 0.8412091533499371
Validation loss: 2.4597195904951334

Epoch: 5| Step: 7
Training loss: 1.141859405611537
Validation loss: 2.488821199191147

Epoch: 5| Step: 8
Training loss: 0.6424440284573202
Validation loss: 2.5019481871791074

Epoch: 5| Step: 9
Training loss: 0.8277389778272065
Validation loss: 2.501580288012069

Epoch: 5| Step: 10
Training loss: 1.6138453201756986
Validation loss: 2.491159309346864

Epoch: 246| Step: 0
Training loss: 1.60193596183998
Validation loss: 2.494321908156516

Epoch: 5| Step: 1
Training loss: 1.0248467447103653
Validation loss: 2.487748481672902

Epoch: 5| Step: 2
Training loss: 1.1263962134862513
Validation loss: 2.513623047318656

Epoch: 5| Step: 3
Training loss: 1.2325156972632212
Validation loss: 2.491841979970087

Epoch: 5| Step: 4
Training loss: 0.8543257720204347
Validation loss: 2.5330126661514614

Epoch: 5| Step: 5
Training loss: 1.2168235224810873
Validation loss: 2.4877625717464773

Epoch: 5| Step: 6
Training loss: 1.0912271012637986
Validation loss: 2.5233566696401457

Epoch: 5| Step: 7
Training loss: 0.9147567394912216
Validation loss: 2.507471366474038

Epoch: 5| Step: 8
Training loss: 1.238763083688138
Validation loss: 2.526478113888201

Epoch: 5| Step: 9
Training loss: 1.0693842628742225
Validation loss: 2.534714565180314

Epoch: 5| Step: 10
Training loss: 1.178916224291491
Validation loss: 2.562113157696611

Epoch: 247| Step: 0
Training loss: 1.2745351448855387
Validation loss: 2.522699309379661

Epoch: 5| Step: 1
Training loss: 1.3495425968238608
Validation loss: 2.526190338140616

Epoch: 5| Step: 2
Training loss: 1.1019778178902384
Validation loss: 2.477869087361586

Epoch: 5| Step: 3
Training loss: 1.1486348611871449
Validation loss: 2.44368871695874

Epoch: 5| Step: 4
Training loss: 1.2149096897297422
Validation loss: 2.4486149832370696

Epoch: 5| Step: 5
Training loss: 0.7949890558221245
Validation loss: 2.4620138137396

Epoch: 5| Step: 6
Training loss: 1.1783570119339268
Validation loss: 2.4811684673561634

Epoch: 5| Step: 7
Training loss: 1.1514828844641183
Validation loss: 2.506411986616423

Epoch: 5| Step: 8
Training loss: 1.3451724397099567
Validation loss: 2.5120044636907815

Epoch: 5| Step: 9
Training loss: 1.2079380419233472
Validation loss: 2.515893446812099

Epoch: 5| Step: 10
Training loss: 1.135866560157275
Validation loss: 2.538889634879408

Epoch: 248| Step: 0
Training loss: 0.8997948055002082
Validation loss: 2.5224459171850393

Epoch: 5| Step: 1
Training loss: 1.0518596461734369
Validation loss: 2.5178347500968767

Epoch: 5| Step: 2
Training loss: 1.240993381645512
Validation loss: 2.5203036173182505

Epoch: 5| Step: 3
Training loss: 1.1554586434583254
Validation loss: 2.5259272047183345

Epoch: 5| Step: 4
Training loss: 0.7950711121933475
Validation loss: 2.4963810568714204

Epoch: 5| Step: 5
Training loss: 1.3223507288897725
Validation loss: 2.5257585460516245

Epoch: 5| Step: 6
Training loss: 1.3041069886484762
Validation loss: 2.5337030204037667

Epoch: 5| Step: 7
Training loss: 1.1115483768006684
Validation loss: 2.4974178392068067

Epoch: 5| Step: 8
Training loss: 1.1954312733001258
Validation loss: 2.5415998716031623

Epoch: 5| Step: 9
Training loss: 1.0359462962057622
Validation loss: 2.481765274644031

Epoch: 5| Step: 10
Training loss: 1.371437008049821
Validation loss: 2.504787298572048

Epoch: 249| Step: 0
Training loss: 1.4331998777729635
Validation loss: 2.504650172663846

Epoch: 5| Step: 1
Training loss: 1.0114752281236794
Validation loss: 2.4879881210835246

Epoch: 5| Step: 2
Training loss: 1.2755055397687993
Validation loss: 2.5176883608045517

Epoch: 5| Step: 3
Training loss: 1.0234214257295642
Validation loss: 2.4953471251833728

Epoch: 5| Step: 4
Training loss: 0.9048318289892237
Validation loss: 2.532581992188512

Epoch: 5| Step: 5
Training loss: 1.0272871226670084
Validation loss: 2.4828241013899452

Epoch: 5| Step: 6
Training loss: 0.8408309811791399
Validation loss: 2.489143866889639

Epoch: 5| Step: 7
Training loss: 1.2264210807767686
Validation loss: 2.4501905513048468

Epoch: 5| Step: 8
Training loss: 0.9655791040272326
Validation loss: 2.4558025269070827

Epoch: 5| Step: 9
Training loss: 0.950801769527286
Validation loss: 2.5028876547554684

Epoch: 5| Step: 10
Training loss: 1.5254037541448426
Validation loss: 2.5211275088895473

Epoch: 250| Step: 0
Training loss: 1.0730096844594301
Validation loss: 2.548512118664464

Epoch: 5| Step: 1
Training loss: 0.9485492935784492
Validation loss: 2.541963688685753

Epoch: 5| Step: 2
Training loss: 0.8838443970613297
Validation loss: 2.519071210901225

Epoch: 5| Step: 3
Training loss: 1.2611175143900422
Validation loss: 2.520601037296516

Epoch: 5| Step: 4
Training loss: 1.197074040926646
Validation loss: 2.512644589007981

Epoch: 5| Step: 5
Training loss: 1.4739499670359633
Validation loss: 2.466644570022472

Epoch: 5| Step: 6
Training loss: 1.0885987639472556
Validation loss: 2.478807253355378

Epoch: 5| Step: 7
Training loss: 0.9032895964477903
Validation loss: 2.431422722074668

Epoch: 5| Step: 8
Training loss: 1.0938875384365736
Validation loss: 2.4737384926872172

Epoch: 5| Step: 9
Training loss: 0.885038186504858
Validation loss: 2.48988714710037

Epoch: 5| Step: 10
Training loss: 1.2394391251142154
Validation loss: 2.503348917225722

Epoch: 251| Step: 0
Training loss: 1.0429895520368164
Validation loss: 2.545243969582204

Epoch: 5| Step: 1
Training loss: 1.1903661471551128
Validation loss: 2.5493788146948138

Epoch: 5| Step: 2
Training loss: 0.6517433555858417
Validation loss: 2.573223248362416

Epoch: 5| Step: 3
Training loss: 0.901140475873257
Validation loss: 2.5254478258089095

Epoch: 5| Step: 4
Training loss: 1.1526410252808115
Validation loss: 2.500926300431853

Epoch: 5| Step: 5
Training loss: 0.6892432522877562
Validation loss: 2.511497789320377

Epoch: 5| Step: 6
Training loss: 1.5621540449527869
Validation loss: 2.4945067525320503

Epoch: 5| Step: 7
Training loss: 0.9646951352463886
Validation loss: 2.491948405880532

Epoch: 5| Step: 8
Training loss: 1.3084089006278066
Validation loss: 2.466919991891642

Epoch: 5| Step: 9
Training loss: 1.0901863899454936
Validation loss: 2.4734571837688963

Epoch: 5| Step: 10
Training loss: 1.2787354613341837
Validation loss: 2.4784040931895697

Epoch: 252| Step: 0
Training loss: 1.0624008132414406
Validation loss: 2.471339803926872

Epoch: 5| Step: 1
Training loss: 1.5535303151119786
Validation loss: 2.47705610040494

Epoch: 5| Step: 2
Training loss: 1.024508374639327
Validation loss: 2.4616949095308245

Epoch: 5| Step: 3
Training loss: 1.2852226634387907
Validation loss: 2.46661671600662

Epoch: 5| Step: 4
Training loss: 0.9289991892142807
Validation loss: 2.476035352912812

Epoch: 5| Step: 5
Training loss: 0.9870543874831011
Validation loss: 2.5116427797345944

Epoch: 5| Step: 6
Training loss: 1.0895013305459864
Validation loss: 2.54029914772228

Epoch: 5| Step: 7
Training loss: 0.8280331182790266
Validation loss: 2.5275663342599684

Epoch: 5| Step: 8
Training loss: 1.2204480202188672
Validation loss: 2.51634680338292

Epoch: 5| Step: 9
Training loss: 0.8506664496419544
Validation loss: 2.506449102901802

Epoch: 5| Step: 10
Training loss: 0.9032323186132578
Validation loss: 2.509015666905644

Epoch: 253| Step: 0
Training loss: 0.9375172931347762
Validation loss: 2.539772385529032

Epoch: 5| Step: 1
Training loss: 0.9724412550258851
Validation loss: 2.5286329588926626

Epoch: 5| Step: 2
Training loss: 0.6778839342069143
Validation loss: 2.541643343986073

Epoch: 5| Step: 3
Training loss: 1.4895217811654056
Validation loss: 2.5287318767525733

Epoch: 5| Step: 4
Training loss: 1.2864100129271587
Validation loss: 2.497650647431915

Epoch: 5| Step: 5
Training loss: 1.0741218661921035
Validation loss: 2.522571013281458

Epoch: 5| Step: 6
Training loss: 0.9405128386785787
Validation loss: 2.512307802515124

Epoch: 5| Step: 7
Training loss: 0.9249389293202589
Validation loss: 2.5188364044899476

Epoch: 5| Step: 8
Training loss: 1.2641288485284097
Validation loss: 2.4909919017990547

Epoch: 5| Step: 9
Training loss: 0.8553797706070715
Validation loss: 2.488763608777394

Epoch: 5| Step: 10
Training loss: 1.2491001227894523
Validation loss: 2.478622247142892

Epoch: 254| Step: 0
Training loss: 1.2355229797850646
Validation loss: 2.489108230072579

Epoch: 5| Step: 1
Training loss: 1.2445123377702225
Validation loss: 2.474809332930467

Epoch: 5| Step: 2
Training loss: 1.1870811125142158
Validation loss: 2.462080861753515

Epoch: 5| Step: 3
Training loss: 1.050223503848242
Validation loss: 2.4856060824570783

Epoch: 5| Step: 4
Training loss: 0.9346153065085794
Validation loss: 2.465451967158437

Epoch: 5| Step: 5
Training loss: 1.065776485292091
Validation loss: 2.5135519282729883

Epoch: 5| Step: 6
Training loss: 1.2858910590461632
Validation loss: 2.5545003846989074

Epoch: 5| Step: 7
Training loss: 1.0153828258820974
Validation loss: 2.5486685339281436

Epoch: 5| Step: 8
Training loss: 1.0847677063913401
Validation loss: 2.5899771698365868

Epoch: 5| Step: 9
Training loss: 1.0351712783586275
Validation loss: 2.5637282592528714

Epoch: 5| Step: 10
Training loss: 0.3728164240653764
Validation loss: 2.610116424066662

Epoch: 255| Step: 0
Training loss: 0.72220069341687
Validation loss: 2.6135397063957453

Epoch: 5| Step: 1
Training loss: 1.1118345799424583
Validation loss: 2.5655686737400907

Epoch: 5| Step: 2
Training loss: 0.9093438972319121
Validation loss: 2.5656334552013793

Epoch: 5| Step: 3
Training loss: 0.8743218791495957
Validation loss: 2.5245838589528753

Epoch: 5| Step: 4
Training loss: 0.8792744861194443
Validation loss: 2.462892569413921

Epoch: 5| Step: 5
Training loss: 1.418463502432528
Validation loss: 2.4648200838511567

Epoch: 5| Step: 6
Training loss: 1.2902901554551935
Validation loss: 2.4678376977012544

Epoch: 5| Step: 7
Training loss: 1.0023630355918207
Validation loss: 2.4400610310207362

Epoch: 5| Step: 8
Training loss: 1.029123020147511
Validation loss: 2.447482807161423

Epoch: 5| Step: 9
Training loss: 1.239694649108628
Validation loss: 2.505920991007454

Epoch: 5| Step: 10
Training loss: 1.136598770783723
Validation loss: 2.5629800996550234

Epoch: 256| Step: 0
Training loss: 1.0255801071207584
Validation loss: 2.567170182061332

Epoch: 5| Step: 1
Training loss: 1.1444644843407585
Validation loss: 2.591589788053626

Epoch: 5| Step: 2
Training loss: 1.0488752926355653
Validation loss: 2.599362437720151

Epoch: 5| Step: 3
Training loss: 1.1262474561317497
Validation loss: 2.613405532465321

Epoch: 5| Step: 4
Training loss: 1.0506974084014895
Validation loss: 2.6229802187329936

Epoch: 5| Step: 5
Training loss: 1.092964816955514
Validation loss: 2.536960777853214

Epoch: 5| Step: 6
Training loss: 1.400226152410055
Validation loss: 2.534289978574956

Epoch: 5| Step: 7
Training loss: 0.7740444537612944
Validation loss: 2.5246074360387083

Epoch: 5| Step: 8
Training loss: 0.9888449407008021
Validation loss: 2.4990943047470378

Epoch: 5| Step: 9
Training loss: 1.1224643423793135
Validation loss: 2.480441206253575

Epoch: 5| Step: 10
Training loss: 0.8584380504160625
Validation loss: 2.4759212424663506

Epoch: 257| Step: 0
Training loss: 0.9200110260675888
Validation loss: 2.478553703090141

Epoch: 5| Step: 1
Training loss: 0.982635110878543
Validation loss: 2.4576454145596833

Epoch: 5| Step: 2
Training loss: 1.100682224776786
Validation loss: 2.489975627057206

Epoch: 5| Step: 3
Training loss: 1.0357271167824744
Validation loss: 2.5092066634645875

Epoch: 5| Step: 4
Training loss: 1.1116038216800068
Validation loss: 2.4987609582073134

Epoch: 5| Step: 5
Training loss: 1.071261076096525
Validation loss: 2.5296062812839426

Epoch: 5| Step: 6
Training loss: 1.070824159714013
Validation loss: 2.486414305524421

Epoch: 5| Step: 7
Training loss: 1.0888245989078726
Validation loss: 2.48227570811658

Epoch: 5| Step: 8
Training loss: 1.242376876886441
Validation loss: 2.5222386146940177

Epoch: 5| Step: 9
Training loss: 0.9299548750358623
Validation loss: 2.567346560161652

Epoch: 5| Step: 10
Training loss: 0.8198413040534688
Validation loss: 2.564920188427949

Epoch: 258| Step: 0
Training loss: 1.1816125283171768
Validation loss: 2.561249085244413

Epoch: 5| Step: 1
Training loss: 1.1423625514450706
Validation loss: 2.4984775563114714

Epoch: 5| Step: 2
Training loss: 0.919177943103152
Validation loss: 2.546208947644182

Epoch: 5| Step: 3
Training loss: 0.7839700268932586
Validation loss: 2.49629268790348

Epoch: 5| Step: 4
Training loss: 0.9459740711876701
Validation loss: 2.4749101736225803

Epoch: 5| Step: 5
Training loss: 0.9417136549127453
Validation loss: 2.4942986717581737

Epoch: 5| Step: 6
Training loss: 1.2679056411616467
Validation loss: 2.490441219353997

Epoch: 5| Step: 7
Training loss: 1.2221829896949485
Validation loss: 2.47280712309239

Epoch: 5| Step: 8
Training loss: 1.1208241633686526
Validation loss: 2.4835438033435255

Epoch: 5| Step: 9
Training loss: 0.8468655884842655
Validation loss: 2.496452846331827

Epoch: 5| Step: 10
Training loss: 0.6985015174150198
Validation loss: 2.509643039939233

Epoch: 259| Step: 0
Training loss: 0.9338173379069988
Validation loss: 2.5037743901953022

Epoch: 5| Step: 1
Training loss: 0.6926639131534738
Validation loss: 2.522324527215709

Epoch: 5| Step: 2
Training loss: 0.9374503122513833
Validation loss: 2.567358416994339

Epoch: 5| Step: 3
Training loss: 1.1599431725262646
Validation loss: 2.563969367673895

Epoch: 5| Step: 4
Training loss: 1.2077706550564367
Validation loss: 2.532226062371529

Epoch: 5| Step: 5
Training loss: 0.8307401283680971
Validation loss: 2.5292694676920444

Epoch: 5| Step: 6
Training loss: 1.0078315437351053
Validation loss: 2.5385852086823095

Epoch: 5| Step: 7
Training loss: 0.8735001515965366
Validation loss: 2.504507605416599

Epoch: 5| Step: 8
Training loss: 1.2876958364783317
Validation loss: 2.49447944189875

Epoch: 5| Step: 9
Training loss: 0.8820979509567474
Validation loss: 2.510911857883007

Epoch: 5| Step: 10
Training loss: 1.2633623218649443
Validation loss: 2.5474767013808415

Epoch: 260| Step: 0
Training loss: 1.3709760653425895
Validation loss: 2.5367478369292606

Epoch: 5| Step: 1
Training loss: 1.0078342050979987
Validation loss: 2.5515336335985825

Epoch: 5| Step: 2
Training loss: 0.773195710583633
Validation loss: 2.559677364232203

Epoch: 5| Step: 3
Training loss: 0.6887707237407487
Validation loss: 2.5660546212168147

Epoch: 5| Step: 4
Training loss: 0.7679044306568998
Validation loss: 2.5743973503366155

Epoch: 5| Step: 5
Training loss: 1.3323818875152769
Validation loss: 2.545517143824175

Epoch: 5| Step: 6
Training loss: 1.0040557987429986
Validation loss: 2.4943823281513287

Epoch: 5| Step: 7
Training loss: 1.2276590875838245
Validation loss: 2.4917397945761683

Epoch: 5| Step: 8
Training loss: 1.0054769733510605
Validation loss: 2.499804573214224

Epoch: 5| Step: 9
Training loss: 0.9220673958397526
Validation loss: 2.4887999118347204

Epoch: 5| Step: 10
Training loss: 1.0073319701554344
Validation loss: 2.5613576772470252

Epoch: 261| Step: 0
Training loss: 0.868037623326199
Validation loss: 2.5206432089470523

Epoch: 5| Step: 1
Training loss: 0.8540719530271269
Validation loss: 2.5350859853325507

Epoch: 5| Step: 2
Training loss: 0.689008726240522
Validation loss: 2.538640481286472

Epoch: 5| Step: 3
Training loss: 0.9311245622576246
Validation loss: 2.607394397113493

Epoch: 5| Step: 4
Training loss: 1.13147240660125
Validation loss: 2.6092902603227905

Epoch: 5| Step: 5
Training loss: 0.9259515275771321
Validation loss: 2.625119401410678

Epoch: 5| Step: 6
Training loss: 1.1788819954553038
Validation loss: 2.573650792596802

Epoch: 5| Step: 7
Training loss: 1.3563381781677082
Validation loss: 2.5151729188989167

Epoch: 5| Step: 8
Training loss: 0.9920012532041694
Validation loss: 2.4668582746916243

Epoch: 5| Step: 9
Training loss: 1.1526708623542417
Validation loss: 2.4444513142148336

Epoch: 5| Step: 10
Training loss: 1.048646936092376
Validation loss: 2.4132831623181343

Epoch: 262| Step: 0
Training loss: 1.1222537217005193
Validation loss: 2.44062505562936

Epoch: 5| Step: 1
Training loss: 0.8976886447940893
Validation loss: 2.4641269166526234

Epoch: 5| Step: 2
Training loss: 0.6262517553293446
Validation loss: 2.5119195397689964

Epoch: 5| Step: 3
Training loss: 1.0948724164621981
Validation loss: 2.560547588861377

Epoch: 5| Step: 4
Training loss: 1.001144112311066
Validation loss: 2.594751629423555

Epoch: 5| Step: 5
Training loss: 1.2694704950907223
Validation loss: 2.631050629175375

Epoch: 5| Step: 6
Training loss: 1.2485250354009034
Validation loss: 2.554926550703874

Epoch: 5| Step: 7
Training loss: 0.9341954163940528
Validation loss: 2.521814656339076

Epoch: 5| Step: 8
Training loss: 0.6683001895028656
Validation loss: 2.4814009910858212

Epoch: 5| Step: 9
Training loss: 1.0450462766375592
Validation loss: 2.4036299535741654

Epoch: 5| Step: 10
Training loss: 1.1383130406199493
Validation loss: 2.458997706188388

Epoch: 263| Step: 0
Training loss: 1.0630695835855137
Validation loss: 2.453244162176641

Epoch: 5| Step: 1
Training loss: 1.1524342646853123
Validation loss: 2.4266663323859348

Epoch: 5| Step: 2
Training loss: 1.0915045440691078
Validation loss: 2.4881974781186442

Epoch: 5| Step: 3
Training loss: 0.8093981220374391
Validation loss: 2.49403536114767

Epoch: 5| Step: 4
Training loss: 1.20020082501976
Validation loss: 2.5290245949465007

Epoch: 5| Step: 5
Training loss: 1.092719219045658
Validation loss: 2.6130994998452417

Epoch: 5| Step: 6
Training loss: 0.9457442503554454
Validation loss: 2.610742548703611

Epoch: 5| Step: 7
Training loss: 1.0614491483211717
Validation loss: 2.64291959790848

Epoch: 5| Step: 8
Training loss: 0.8477437901450846
Validation loss: 2.657027363536648

Epoch: 5| Step: 9
Training loss: 0.9822499786516762
Validation loss: 2.5692063062073083

Epoch: 5| Step: 10
Training loss: 1.029028088329935
Validation loss: 2.5407082559361878

Epoch: 264| Step: 0
Training loss: 0.92148966737192
Validation loss: 2.464808403585834

Epoch: 5| Step: 1
Training loss: 0.7594828336783522
Validation loss: 2.4002649180266697

Epoch: 5| Step: 2
Training loss: 1.1037007134429293
Validation loss: 2.3941288256780795

Epoch: 5| Step: 3
Training loss: 1.3806747464171212
Validation loss: 2.3752126528360202

Epoch: 5| Step: 4
Training loss: 1.1852868186125707
Validation loss: 2.473089466377435

Epoch: 5| Step: 5
Training loss: 1.0163147564815973
Validation loss: 2.478930368913677

Epoch: 5| Step: 6
Training loss: 0.8146069059026302
Validation loss: 2.5186791686896646

Epoch: 5| Step: 7
Training loss: 0.9891213325732352
Validation loss: 2.585144518193534

Epoch: 5| Step: 8
Training loss: 0.8939989330170172
Validation loss: 2.611803184184119

Epoch: 5| Step: 9
Training loss: 1.0674868408213956
Validation loss: 2.6253592825879224

Epoch: 5| Step: 10
Training loss: 0.855782124851651
Validation loss: 2.5876732103495206

Epoch: 265| Step: 0
Training loss: 0.5768527388487917
Validation loss: 2.518061182888182

Epoch: 5| Step: 1
Training loss: 1.3207416175664373
Validation loss: 2.496948922478746

Epoch: 5| Step: 2
Training loss: 0.8880251700704662
Validation loss: 2.4547543350154597

Epoch: 5| Step: 3
Training loss: 0.76087247347424
Validation loss: 2.438269609105841

Epoch: 5| Step: 4
Training loss: 0.645081025512428
Validation loss: 2.4798949200835603

Epoch: 5| Step: 5
Training loss: 1.1291404929887154
Validation loss: 2.4990399393808898

Epoch: 5| Step: 6
Training loss: 1.4166840757908465
Validation loss: 2.5459473535669437

Epoch: 5| Step: 7
Training loss: 0.904471922177694
Validation loss: 2.574329343283658

Epoch: 5| Step: 8
Training loss: 0.8805869753380121
Validation loss: 2.5380082357817915

Epoch: 5| Step: 9
Training loss: 1.2181774163748924
Validation loss: 2.5194221719079937

Epoch: 5| Step: 10
Training loss: 0.8459996150829802
Validation loss: 2.5565374802888328

Epoch: 266| Step: 0
Training loss: 1.0581109328892429
Validation loss: 2.5445620776440068

Epoch: 5| Step: 1
Training loss: 0.9201387769271174
Validation loss: 2.5610943642405526

Epoch: 5| Step: 2
Training loss: 1.004734158062866
Validation loss: 2.5790369831548223

Epoch: 5| Step: 3
Training loss: 1.0778704356535196
Validation loss: 2.536293017996683

Epoch: 5| Step: 4
Training loss: 0.779778697274342
Validation loss: 2.545780170279592

Epoch: 5| Step: 5
Training loss: 0.7854585208078773
Validation loss: 2.491599640942949

Epoch: 5| Step: 6
Training loss: 0.8745545206932024
Validation loss: 2.4921842000217267

Epoch: 5| Step: 7
Training loss: 1.2316014480530273
Validation loss: 2.4971143557985833

Epoch: 5| Step: 8
Training loss: 0.8576573285391251
Validation loss: 2.4751684829842344

Epoch: 5| Step: 9
Training loss: 1.09462975134346
Validation loss: 2.478040985792439

Epoch: 5| Step: 10
Training loss: 0.9423512191615605
Validation loss: 2.4174902520012536

Epoch: 267| Step: 0
Training loss: 0.5838780896483408
Validation loss: 2.4615319173008943

Epoch: 5| Step: 1
Training loss: 0.8895469632780311
Validation loss: 2.4872021069704524

Epoch: 5| Step: 2
Training loss: 1.3757243415981095
Validation loss: 2.4719668814129143

Epoch: 5| Step: 3
Training loss: 1.0908611293386028
Validation loss: 2.469442996935041

Epoch: 5| Step: 4
Training loss: 1.0884907845951193
Validation loss: 2.514932821671938

Epoch: 5| Step: 5
Training loss: 0.4516357415276248
Validation loss: 2.5055980579208708

Epoch: 5| Step: 6
Training loss: 0.7983543651321712
Validation loss: 2.5564323067239374

Epoch: 5| Step: 7
Training loss: 0.7759016068476456
Validation loss: 2.58881275851043

Epoch: 5| Step: 8
Training loss: 1.125438075073251
Validation loss: 2.5841206083025057

Epoch: 5| Step: 9
Training loss: 1.0747649312833385
Validation loss: 2.6021738656638305

Epoch: 5| Step: 10
Training loss: 0.9157522835647058
Validation loss: 2.61762465191882

Epoch: 268| Step: 0
Training loss: 0.8260191286980203
Validation loss: 2.594641166562886

Epoch: 5| Step: 1
Training loss: 0.8949098077540746
Validation loss: 2.585053015090887

Epoch: 5| Step: 2
Training loss: 0.8762464500932169
Validation loss: 2.564109254919809

Epoch: 5| Step: 3
Training loss: 0.7587932257617849
Validation loss: 2.5231497493312034

Epoch: 5| Step: 4
Training loss: 0.5283013585440162
Validation loss: 2.522371438314479

Epoch: 5| Step: 5
Training loss: 1.009506162737041
Validation loss: 2.4700081255624977

Epoch: 5| Step: 6
Training loss: 1.179759143397004
Validation loss: 2.4868246291512444

Epoch: 5| Step: 7
Training loss: 1.0252331422035172
Validation loss: 2.4499983217670183

Epoch: 5| Step: 8
Training loss: 1.1783526112185867
Validation loss: 2.4719975649481563

Epoch: 5| Step: 9
Training loss: 1.0761950814017585
Validation loss: 2.463081690681842

Epoch: 5| Step: 10
Training loss: 0.7634440128456159
Validation loss: 2.5024573615861336

Epoch: 269| Step: 0
Training loss: 0.836435722118302
Validation loss: 2.520994019749473

Epoch: 5| Step: 1
Training loss: 0.6880187764932372
Validation loss: 2.5359303703053966

Epoch: 5| Step: 2
Training loss: 0.9153136469350956
Validation loss: 2.56190111458708

Epoch: 5| Step: 3
Training loss: 0.9322652582161304
Validation loss: 2.581519286517622

Epoch: 5| Step: 4
Training loss: 1.0289167538326138
Validation loss: 2.591151638378002

Epoch: 5| Step: 5
Training loss: 0.6163886006080366
Validation loss: 2.5927519579996225

Epoch: 5| Step: 6
Training loss: 0.8547418022688708
Validation loss: 2.5407620435147047

Epoch: 5| Step: 7
Training loss: 1.1168385741063376
Validation loss: 2.5404865935299688

Epoch: 5| Step: 8
Training loss: 1.2346622760487287
Validation loss: 2.477720101937384

Epoch: 5| Step: 9
Training loss: 1.23311164040538
Validation loss: 2.477705243927443

Epoch: 5| Step: 10
Training loss: 0.5495312351186673
Validation loss: 2.4471325297623667

Epoch: 270| Step: 0
Training loss: 0.9356144699492837
Validation loss: 2.4265163927878786

Epoch: 5| Step: 1
Training loss: 1.1393174293022617
Validation loss: 2.481575600476124

Epoch: 5| Step: 2
Training loss: 0.5891301973738086
Validation loss: 2.4871669525512816

Epoch: 5| Step: 3
Training loss: 1.219644804902906
Validation loss: 2.5557544210513683

Epoch: 5| Step: 4
Training loss: 0.6968128860914629
Validation loss: 2.5802465614896453

Epoch: 5| Step: 5
Training loss: 1.0059917473956965
Validation loss: 2.5827848214015052

Epoch: 5| Step: 6
Training loss: 0.8720025765660918
Validation loss: 2.592383846151045

Epoch: 5| Step: 7
Training loss: 0.5822776170604054
Validation loss: 2.58949155857634

Epoch: 5| Step: 8
Training loss: 1.22748016240392
Validation loss: 2.586344148982242

Epoch: 5| Step: 9
Training loss: 0.8593695553693825
Validation loss: 2.538525802393948

Epoch: 5| Step: 10
Training loss: 0.7997404452316889
Validation loss: 2.5679413583381527

Epoch: 271| Step: 0
Training loss: 0.9434544612121798
Validation loss: 2.56950351274333

Epoch: 5| Step: 1
Training loss: 1.0403753605532249
Validation loss: 2.5646034269591245

Epoch: 5| Step: 2
Training loss: 0.7336319756019433
Validation loss: 2.5247593353099127

Epoch: 5| Step: 3
Training loss: 0.9525364794216052
Validation loss: 2.5441378937838928

Epoch: 5| Step: 4
Training loss: 0.905657804959883
Validation loss: 2.514914811168653

Epoch: 5| Step: 5
Training loss: 0.9756105589790646
Validation loss: 2.511623296995722

Epoch: 5| Step: 6
Training loss: 1.2535631417469064
Validation loss: 2.4862763284314653

Epoch: 5| Step: 7
Training loss: 0.7478529477050577
Validation loss: 2.5064411755402833

Epoch: 5| Step: 8
Training loss: 0.6235992709350117
Validation loss: 2.494699809442612

Epoch: 5| Step: 9
Training loss: 0.8864325511035483
Validation loss: 2.494744751623322

Epoch: 5| Step: 10
Training loss: 0.8883741613695151
Validation loss: 2.527809418802502

Epoch: 272| Step: 0
Training loss: 1.1186673693270137
Validation loss: 2.4932239337092827

Epoch: 5| Step: 1
Training loss: 1.071045227955065
Validation loss: 2.5356024427795543

Epoch: 5| Step: 2
Training loss: 0.9714211278067231
Validation loss: 2.5293321199155323

Epoch: 5| Step: 3
Training loss: 0.9345427601737984
Validation loss: 2.533287126959545

Epoch: 5| Step: 4
Training loss: 0.6456563435319906
Validation loss: 2.5836927128901603

Epoch: 5| Step: 5
Training loss: 0.7590924494784305
Validation loss: 2.610958049242594

Epoch: 5| Step: 6
Training loss: 1.0194130313779057
Validation loss: 2.593521108064493

Epoch: 5| Step: 7
Training loss: 0.5014739365389417
Validation loss: 2.583739729210569

Epoch: 5| Step: 8
Training loss: 1.0560129384924353
Validation loss: 2.603174220489427

Epoch: 5| Step: 9
Training loss: 0.951011691225152
Validation loss: 2.6118268102181847

Epoch: 5| Step: 10
Training loss: 0.74216445083967
Validation loss: 2.57086180757955

Epoch: 273| Step: 0
Training loss: 0.8059293552917512
Validation loss: 2.5025083141011155

Epoch: 5| Step: 1
Training loss: 1.0033727037007427
Validation loss: 2.4788101279778423

Epoch: 5| Step: 2
Training loss: 0.9708540125651419
Validation loss: 2.4549841183772196

Epoch: 5| Step: 3
Training loss: 0.7021110853677565
Validation loss: 2.490813835553884

Epoch: 5| Step: 4
Training loss: 0.832303141553423
Validation loss: 2.4664415413354415

Epoch: 5| Step: 5
Training loss: 0.8406238924607706
Validation loss: 2.5038309928582323

Epoch: 5| Step: 6
Training loss: 0.9355306604051387
Validation loss: 2.5329902760578884

Epoch: 5| Step: 7
Training loss: 1.1894503187826093
Validation loss: 2.5640630589479603

Epoch: 5| Step: 8
Training loss: 0.694127068846079
Validation loss: 2.5521409979795853

Epoch: 5| Step: 9
Training loss: 0.9387695934724604
Validation loss: 2.558110173403519

Epoch: 5| Step: 10
Training loss: 1.0881586207016756
Validation loss: 2.5248751979149033

Epoch: 274| Step: 0
Training loss: 0.8095475620436865
Validation loss: 2.5490561765201503

Epoch: 5| Step: 1
Training loss: 0.8920091614466562
Validation loss: 2.5546276603203957

Epoch: 5| Step: 2
Training loss: 0.8464378002610977
Validation loss: 2.544131447737882

Epoch: 5| Step: 3
Training loss: 0.7194600951293835
Validation loss: 2.569527361591655

Epoch: 5| Step: 4
Training loss: 0.8266679433330809
Validation loss: 2.5340453390690403

Epoch: 5| Step: 5
Training loss: 0.9864176190254512
Validation loss: 2.5417724565841153

Epoch: 5| Step: 6
Training loss: 0.9869750667812308
Validation loss: 2.5291096571031013

Epoch: 5| Step: 7
Training loss: 0.9625937601966339
Validation loss: 2.5137637480821526

Epoch: 5| Step: 8
Training loss: 0.8682422581269021
Validation loss: 2.5508074211425407

Epoch: 5| Step: 9
Training loss: 1.0581335214540997
Validation loss: 2.4957319589902145

Epoch: 5| Step: 10
Training loss: 0.8548124748509448
Validation loss: 2.5121095746531834

Epoch: 275| Step: 0
Training loss: 0.7987663039929906
Validation loss: 2.514577380589264

Epoch: 5| Step: 1
Training loss: 0.8350503438631957
Validation loss: 2.5600983645111266

Epoch: 5| Step: 2
Training loss: 1.2550163702638013
Validation loss: 2.5598076583499294

Epoch: 5| Step: 3
Training loss: 0.9492417948872814
Validation loss: 2.5708057000073885

Epoch: 5| Step: 4
Training loss: 1.0522702809538869
Validation loss: 2.5538206039231297

Epoch: 5| Step: 5
Training loss: 0.6957720405933728
Validation loss: 2.54959326171851

Epoch: 5| Step: 6
Training loss: 0.836037496129716
Validation loss: 2.520097962073947

Epoch: 5| Step: 7
Training loss: 0.830563894511377
Validation loss: 2.5266323419380647

Epoch: 5| Step: 8
Training loss: 0.608452391949166
Validation loss: 2.551927334653363

Epoch: 5| Step: 9
Training loss: 0.8320052451784518
Validation loss: 2.56737637788461

Epoch: 5| Step: 10
Training loss: 1.0461128079285864
Validation loss: 2.525643895838796

Epoch: 276| Step: 0
Training loss: 0.900995477510506
Validation loss: 2.5144346938631608

Epoch: 5| Step: 1
Training loss: 0.8308292715253293
Validation loss: 2.502621469905987

Epoch: 5| Step: 2
Training loss: 0.9106383131699571
Validation loss: 2.486177599125113

Epoch: 5| Step: 3
Training loss: 1.0708506546895546
Validation loss: 2.497305550147856

Epoch: 5| Step: 4
Training loss: 1.1998514997468237
Validation loss: 2.475023122418234

Epoch: 5| Step: 5
Training loss: 0.3613622082280728
Validation loss: 2.4310140136540124

Epoch: 5| Step: 6
Training loss: 1.025885181144541
Validation loss: 2.4337514266830023

Epoch: 5| Step: 7
Training loss: 0.9098733617886022
Validation loss: 2.451912146357883

Epoch: 5| Step: 8
Training loss: 0.8697426072102804
Validation loss: 2.488128162347847

Epoch: 5| Step: 9
Training loss: 0.8847852961561858
Validation loss: 2.4977949765052436

Epoch: 5| Step: 10
Training loss: 0.7505531258202163
Validation loss: 2.5187155678037154

Epoch: 277| Step: 0
Training loss: 0.9513817150343605
Validation loss: 2.5225267741877615

Epoch: 5| Step: 1
Training loss: 0.8621833690006501
Validation loss: 2.5696568305310867

Epoch: 5| Step: 2
Training loss: 0.7960061965729947
Validation loss: 2.6131170394044765

Epoch: 5| Step: 3
Training loss: 0.8505165255722277
Validation loss: 2.5982144448336784

Epoch: 5| Step: 4
Training loss: 0.6538809293996967
Validation loss: 2.5997366313916315

Epoch: 5| Step: 5
Training loss: 0.8895229079356068
Validation loss: 2.5672092509746802

Epoch: 5| Step: 6
Training loss: 0.6627147686320174
Validation loss: 2.52854234593015

Epoch: 5| Step: 7
Training loss: 1.325797431231128
Validation loss: 2.491474068139871

Epoch: 5| Step: 8
Training loss: 0.9236104438575368
Validation loss: 2.461951398749623

Epoch: 5| Step: 9
Training loss: 0.925970162862578
Validation loss: 2.4691284520979067

Epoch: 5| Step: 10
Training loss: 0.48279992244596576
Validation loss: 2.437916651965434

Epoch: 278| Step: 0
Training loss: 0.9499025432891965
Validation loss: 2.4436967587174223

Epoch: 5| Step: 1
Training loss: 0.6630849936567058
Validation loss: 2.4679045677548808

Epoch: 5| Step: 2
Training loss: 1.0212120728938219
Validation loss: 2.4948724101708466

Epoch: 5| Step: 3
Training loss: 0.7583338330515239
Validation loss: 2.4937565818681464

Epoch: 5| Step: 4
Training loss: 0.7805023430514799
Validation loss: 2.533008574768194

Epoch: 5| Step: 5
Training loss: 0.9142873112630521
Validation loss: 2.572149549391391

Epoch: 5| Step: 6
Training loss: 0.9374367374691995
Validation loss: 2.5445503029902494

Epoch: 5| Step: 7
Training loss: 1.015148226997057
Validation loss: 2.592267875773026

Epoch: 5| Step: 8
Training loss: 0.6526954753431938
Validation loss: 2.6067891740405242

Epoch: 5| Step: 9
Training loss: 0.7733582350062272
Validation loss: 2.5957477114858647

Epoch: 5| Step: 10
Training loss: 1.1148867090258106
Validation loss: 2.58234115214501

Epoch: 279| Step: 0
Training loss: 0.7510023174656492
Validation loss: 2.574114885960642

Epoch: 5| Step: 1
Training loss: 0.856366457293933
Validation loss: 2.58769810287634

Epoch: 5| Step: 2
Training loss: 1.0864371927069227
Validation loss: 2.5546052052769994

Epoch: 5| Step: 3
Training loss: 0.7825277560616015
Validation loss: 2.557769725861184

Epoch: 5| Step: 4
Training loss: 1.0352899429070097
Validation loss: 2.549873465773186

Epoch: 5| Step: 5
Training loss: 0.6837587647861341
Validation loss: 2.5585810910478264

Epoch: 5| Step: 6
Training loss: 0.8377693995566418
Validation loss: 2.5495214250858664

Epoch: 5| Step: 7
Training loss: 1.0042945318739986
Validation loss: 2.537349714016153

Epoch: 5| Step: 8
Training loss: 0.7339809253199435
Validation loss: 2.5291215462160364

Epoch: 5| Step: 9
Training loss: 0.9281997637707525
Validation loss: 2.555043618958261

Epoch: 5| Step: 10
Training loss: 0.7538605513088625
Validation loss: 2.5451428831940848

Epoch: 280| Step: 0
Training loss: 0.9850048593217298
Validation loss: 2.5759372590819862

Epoch: 5| Step: 1
Training loss: 0.6447642974303673
Validation loss: 2.5727470859857124

Epoch: 5| Step: 2
Training loss: 0.9582917301159104
Validation loss: 2.6207357882019333

Epoch: 5| Step: 3
Training loss: 0.6626943294249151
Validation loss: 2.5631660478218965

Epoch: 5| Step: 4
Training loss: 1.0900262932712141
Validation loss: 2.540605518869944

Epoch: 5| Step: 5
Training loss: 0.6628134705618696
Validation loss: 2.51307041162451

Epoch: 5| Step: 6
Training loss: 0.7378432170285494
Validation loss: 2.4788101434911765

Epoch: 5| Step: 7
Training loss: 0.8362051989724252
Validation loss: 2.464843122830225

Epoch: 5| Step: 8
Training loss: 1.061445779074168
Validation loss: 2.4187044696953497

Epoch: 5| Step: 9
Training loss: 0.8253112711494655
Validation loss: 2.4293168608929827

Epoch: 5| Step: 10
Training loss: 0.9923661439123032
Validation loss: 2.460096806774772

Epoch: 281| Step: 0
Training loss: 0.9367414266531467
Validation loss: 2.5039452258650723

Epoch: 5| Step: 1
Training loss: 0.7919119948346652
Validation loss: 2.526809279067377

Epoch: 5| Step: 2
Training loss: 0.9224627286209917
Validation loss: 2.593221969219993

Epoch: 5| Step: 3
Training loss: 0.6035569062666526
Validation loss: 2.600370984236646

Epoch: 5| Step: 4
Training loss: 0.8949852003973062
Validation loss: 2.6179660677992125

Epoch: 5| Step: 5
Training loss: 0.7476669820973919
Validation loss: 2.5976054475676933

Epoch: 5| Step: 6
Training loss: 0.9289310808127441
Validation loss: 2.5990543007859626

Epoch: 5| Step: 7
Training loss: 1.0439144233437316
Validation loss: 2.5592043603540913

Epoch: 5| Step: 8
Training loss: 0.9671286890147647
Validation loss: 2.4389019077539795

Epoch: 5| Step: 9
Training loss: 0.9034755594001481
Validation loss: 2.410284175679815

Epoch: 5| Step: 10
Training loss: 0.6161754374245729
Validation loss: 2.4130378585190773

Epoch: 282| Step: 0
Training loss: 0.7318412819253122
Validation loss: 2.4129191469822437

Epoch: 5| Step: 1
Training loss: 0.7987129855944742
Validation loss: 2.41360504555641

Epoch: 5| Step: 2
Training loss: 1.098646809806666
Validation loss: 2.4363946156798013

Epoch: 5| Step: 3
Training loss: 0.892603967739093
Validation loss: 2.521518785613892

Epoch: 5| Step: 4
Training loss: 0.8201608790192338
Validation loss: 2.5679913719482608

Epoch: 5| Step: 5
Training loss: 0.9380030871627206
Validation loss: 2.5696107303017905

Epoch: 5| Step: 6
Training loss: 1.0449934034732526
Validation loss: 2.593855192381732

Epoch: 5| Step: 7
Training loss: 0.6093500572381728
Validation loss: 2.547075537627761

Epoch: 5| Step: 8
Training loss: 0.9761310997820115
Validation loss: 2.5314276676069754

Epoch: 5| Step: 9
Training loss: 0.7774524708537787
Validation loss: 2.5020087129811315

Epoch: 5| Step: 10
Training loss: 0.6141964346539667
Validation loss: 2.4985267748855824

Epoch: 283| Step: 0
Training loss: 0.8117667337284142
Validation loss: 2.493676809044411

Epoch: 5| Step: 1
Training loss: 0.7915500672121147
Validation loss: 2.5192019632231286

Epoch: 5| Step: 2
Training loss: 0.7471294703778252
Validation loss: 2.476931398689683

Epoch: 5| Step: 3
Training loss: 0.8051979149806112
Validation loss: 2.509446506857803

Epoch: 5| Step: 4
Training loss: 0.879272181309501
Validation loss: 2.4762988656852567

Epoch: 5| Step: 5
Training loss: 0.5763579246011935
Validation loss: 2.453722255431392

Epoch: 5| Step: 6
Training loss: 0.9775241237112458
Validation loss: 2.5159518738355273

Epoch: 5| Step: 7
Training loss: 1.0108170781056356
Validation loss: 2.502766491063324

Epoch: 5| Step: 8
Training loss: 0.44318779805735153
Validation loss: 2.533387680542092

Epoch: 5| Step: 9
Training loss: 0.972340574705299
Validation loss: 2.5567241727654495

Epoch: 5| Step: 10
Training loss: 0.971652574017131
Validation loss: 2.5219147641505764

Epoch: 284| Step: 0
Training loss: 0.8969360410540086
Validation loss: 2.4814093646910416

Epoch: 5| Step: 1
Training loss: 0.599234000637344
Validation loss: 2.4938173712471605

Epoch: 5| Step: 2
Training loss: 0.9585131946346045
Validation loss: 2.4825537020257755

Epoch: 5| Step: 3
Training loss: 1.139099878187142
Validation loss: 2.486655851399614

Epoch: 5| Step: 4
Training loss: 0.78515537698422
Validation loss: 2.5037824616679694

Epoch: 5| Step: 5
Training loss: 0.9093817825326626
Validation loss: 2.474175282903571

Epoch: 5| Step: 6
Training loss: 0.7758107236428354
Validation loss: 2.440601165664769

Epoch: 5| Step: 7
Training loss: 0.8014263624916593
Validation loss: 2.4604278286692893

Epoch: 5| Step: 8
Training loss: 0.7624150932441154
Validation loss: 2.504688421756421

Epoch: 5| Step: 9
Training loss: 0.7315958069426197
Validation loss: 2.504246155470601

Epoch: 5| Step: 10
Training loss: 0.6233286922795445
Validation loss: 2.5224622241673846

Epoch: 285| Step: 0
Training loss: 0.8709223967886159
Validation loss: 2.5897802977636135

Epoch: 5| Step: 1
Training loss: 1.0477340931031924
Validation loss: 2.5839980415131216

Epoch: 5| Step: 2
Training loss: 0.9758891110939779
Validation loss: 2.583260109095548

Epoch: 5| Step: 3
Training loss: 0.7628654260961265
Validation loss: 2.5665811153942446

Epoch: 5| Step: 4
Training loss: 0.8483053086853661
Validation loss: 2.5422532043471366

Epoch: 5| Step: 5
Training loss: 1.0371968435410834
Validation loss: 2.508951367024652

Epoch: 5| Step: 6
Training loss: 0.42017067923830875
Validation loss: 2.4668244827584975

Epoch: 5| Step: 7
Training loss: 0.7834180503716403
Validation loss: 2.4736266449538857

Epoch: 5| Step: 8
Training loss: 0.48458503968301125
Validation loss: 2.481722686651424

Epoch: 5| Step: 9
Training loss: 0.7011262034043546
Validation loss: 2.4868688734909394

Epoch: 5| Step: 10
Training loss: 0.8715421950695862
Validation loss: 2.498930283846627

Epoch: 286| Step: 0
Training loss: 0.5301562156868364
Validation loss: 2.4764479485172637

Epoch: 5| Step: 1
Training loss: 0.915805491601891
Validation loss: 2.472932663082837

Epoch: 5| Step: 2
Training loss: 0.9040316034042246
Validation loss: 2.4991723669785646

Epoch: 5| Step: 3
Training loss: 0.7710883560687696
Validation loss: 2.4913272263327713

Epoch: 5| Step: 4
Training loss: 0.7026935101131366
Validation loss: 2.5237575937421277

Epoch: 5| Step: 5
Training loss: 0.7781105285279323
Validation loss: 2.5160853110578008

Epoch: 5| Step: 6
Training loss: 0.8815117088920704
Validation loss: 2.54224509467858

Epoch: 5| Step: 7
Training loss: 0.7865286831412057
Validation loss: 2.5533734114479425

Epoch: 5| Step: 8
Training loss: 1.0400999239454745
Validation loss: 2.4899796918540082

Epoch: 5| Step: 9
Training loss: 0.6959645503542055
Validation loss: 2.4907870422821388

Epoch: 5| Step: 10
Training loss: 1.0508024646078131
Validation loss: 2.480115970028885

Epoch: 287| Step: 0
Training loss: 0.63709884251274
Validation loss: 2.467016932416157

Epoch: 5| Step: 1
Training loss: 0.9425015231456642
Validation loss: 2.4933923953891073

Epoch: 5| Step: 2
Training loss: 0.8011788474402156
Validation loss: 2.5046296987178747

Epoch: 5| Step: 3
Training loss: 0.7681329483725977
Validation loss: 2.5349950655264006

Epoch: 5| Step: 4
Training loss: 1.0907331003212815
Validation loss: 2.5200471037560783

Epoch: 5| Step: 5
Training loss: 0.7294630175047708
Validation loss: 2.577010500577686

Epoch: 5| Step: 6
Training loss: 0.6749830217345456
Validation loss: 2.561267636483235

Epoch: 5| Step: 7
Training loss: 1.0940975182079316
Validation loss: 2.585219122822477

Epoch: 5| Step: 8
Training loss: 0.7958967150336039
Validation loss: 2.554272585396049

Epoch: 5| Step: 9
Training loss: 0.7288484605652418
Validation loss: 2.548605376298769

Epoch: 5| Step: 10
Training loss: 0.8557350057881385
Validation loss: 2.502849001460936

Epoch: 288| Step: 0
Training loss: 0.7530590297566145
Validation loss: 2.507644459083075

Epoch: 5| Step: 1
Training loss: 0.9009505907603504
Validation loss: 2.4701570774433863

Epoch: 5| Step: 2
Training loss: 0.9925945378207235
Validation loss: 2.4921076625478134

Epoch: 5| Step: 3
Training loss: 0.91236044064722
Validation loss: 2.5166718858668693

Epoch: 5| Step: 4
Training loss: 0.7862168924611529
Validation loss: 2.510386015464459

Epoch: 5| Step: 5
Training loss: 0.9850610733946465
Validation loss: 2.4913602547632276

Epoch: 5| Step: 6
Training loss: 0.8352210994768341
Validation loss: 2.4698300821545565

Epoch: 5| Step: 7
Training loss: 0.7600867369998384
Validation loss: 2.5420872363701967

Epoch: 5| Step: 8
Training loss: 0.5865181144297503
Validation loss: 2.570313063533345

Epoch: 5| Step: 9
Training loss: 0.743599161511934
Validation loss: 2.587503084035554

Epoch: 5| Step: 10
Training loss: 0.77545949788582
Validation loss: 2.6589523293613198

Epoch: 289| Step: 0
Training loss: 1.0555053930465568
Validation loss: 2.582987301370506

Epoch: 5| Step: 1
Training loss: 0.679986953540074
Validation loss: 2.5240095226695267

Epoch: 5| Step: 2
Training loss: 0.8099187416361201
Validation loss: 2.5316724517114997

Epoch: 5| Step: 3
Training loss: 1.1366522071474292
Validation loss: 2.496312981956705

Epoch: 5| Step: 4
Training loss: 1.1700773056281089
Validation loss: 2.480731701415828

Epoch: 5| Step: 5
Training loss: 0.7491046011069871
Validation loss: 2.447080326796696

Epoch: 5| Step: 6
Training loss: 0.6311734011414789
Validation loss: 2.439180382330495

Epoch: 5| Step: 7
Training loss: 0.8157903730155962
Validation loss: 2.4747072574364792

Epoch: 5| Step: 8
Training loss: 0.4316318735469675
Validation loss: 2.483831200496409

Epoch: 5| Step: 9
Training loss: 0.5655434449554653
Validation loss: 2.488445429885419

Epoch: 5| Step: 10
Training loss: 0.5589016685905946
Validation loss: 2.5252821700370327

Epoch: 290| Step: 0
Training loss: 1.023543840081591
Validation loss: 2.5208930094350537

Epoch: 5| Step: 1
Training loss: 0.6881448582443904
Validation loss: 2.5377158254593213

Epoch: 5| Step: 2
Training loss: 0.9884950308590428
Validation loss: 2.5169757000790214

Epoch: 5| Step: 3
Training loss: 0.8411136695845861
Validation loss: 2.5139588586290276

Epoch: 5| Step: 4
Training loss: 0.800542358492912
Validation loss: 2.4938964169147346

Epoch: 5| Step: 5
Training loss: 0.6816847603836331
Validation loss: 2.481470480305431

Epoch: 5| Step: 6
Training loss: 0.8762082205048277
Validation loss: 2.471240272483532

Epoch: 5| Step: 7
Training loss: 0.7747681470889352
Validation loss: 2.484537112250304

Epoch: 5| Step: 8
Training loss: 0.4564967004514698
Validation loss: 2.5398545739096323

Epoch: 5| Step: 9
Training loss: 0.5901166524573439
Validation loss: 2.5286744481110484

Epoch: 5| Step: 10
Training loss: 0.8362933675927888
Validation loss: 2.5224687896163314

Epoch: 291| Step: 0
Training loss: 0.8646942243738516
Validation loss: 2.565949728840144

Epoch: 5| Step: 1
Training loss: 0.9392905937339526
Validation loss: 2.5826305746111227

Epoch: 5| Step: 2
Training loss: 1.0604737539357398
Validation loss: 2.5395297207636633

Epoch: 5| Step: 3
Training loss: 0.849162473103579
Validation loss: 2.5041348272999495

Epoch: 5| Step: 4
Training loss: 0.5413359372057952
Validation loss: 2.4929298758206997

Epoch: 5| Step: 5
Training loss: 0.7198206349647085
Validation loss: 2.4351371974970166

Epoch: 5| Step: 6
Training loss: 0.6607742576923727
Validation loss: 2.4338655661216775

Epoch: 5| Step: 7
Training loss: 0.9570452007911757
Validation loss: 2.4577081131008205

Epoch: 5| Step: 8
Training loss: 0.8208604345027091
Validation loss: 2.4621925498964834

Epoch: 5| Step: 9
Training loss: 0.5249037631703192
Validation loss: 2.508516852859512

Epoch: 5| Step: 10
Training loss: 0.4884481221201498
Validation loss: 2.4880455424328063

Epoch: 292| Step: 0
Training loss: 0.7483777143774192
Validation loss: 2.5206796122453614

Epoch: 5| Step: 1
Training loss: 0.7298561015765258
Validation loss: 2.5505151805716078

Epoch: 5| Step: 2
Training loss: 0.8167202359425565
Validation loss: 2.575210309860987

Epoch: 5| Step: 3
Training loss: 0.9483597875993766
Validation loss: 2.593440458802117

Epoch: 5| Step: 4
Training loss: 0.8606640944123581
Validation loss: 2.592693079416974

Epoch: 5| Step: 5
Training loss: 0.7455816458722822
Validation loss: 2.5714673763129894

Epoch: 5| Step: 6
Training loss: 0.7795079072204983
Validation loss: 2.5722629779043946

Epoch: 5| Step: 7
Training loss: 0.7859348972042357
Validation loss: 2.530118447534938

Epoch: 5| Step: 8
Training loss: 0.7144483296028498
Validation loss: 2.5313734143229683

Epoch: 5| Step: 9
Training loss: 0.8212542985777512
Validation loss: 2.4784370745496322

Epoch: 5| Step: 10
Training loss: 0.5208966375662419
Validation loss: 2.456243309277615

Epoch: 293| Step: 0
Training loss: 0.745707626688874
Validation loss: 2.4875109952989822

Epoch: 5| Step: 1
Training loss: 0.7850646539656587
Validation loss: 2.5264317483543794

Epoch: 5| Step: 2
Training loss: 0.7688913153422968
Validation loss: 2.5306745640012

Epoch: 5| Step: 3
Training loss: 0.7513304274758664
Validation loss: 2.545044801617759

Epoch: 5| Step: 4
Training loss: 0.9825629252504499
Validation loss: 2.545041020185664

Epoch: 5| Step: 5
Training loss: 0.6450202705096066
Validation loss: 2.5695808946082415

Epoch: 5| Step: 6
Training loss: 0.5689411921405978
Validation loss: 2.5227150324284433

Epoch: 5| Step: 7
Training loss: 0.7646191665678838
Validation loss: 2.5057596810851472

Epoch: 5| Step: 8
Training loss: 0.8628279242264655
Validation loss: 2.4865018749433268

Epoch: 5| Step: 9
Training loss: 0.9052390346142151
Validation loss: 2.4735167821199933

Epoch: 5| Step: 10
Training loss: 0.6310346141516385
Validation loss: 2.4745776168935434

Epoch: 294| Step: 0
Training loss: 0.4664898105829168
Validation loss: 2.473277803785033

Epoch: 5| Step: 1
Training loss: 1.0988521916384404
Validation loss: 2.506962625500125

Epoch: 5| Step: 2
Training loss: 0.7355874786271676
Validation loss: 2.503706033003916

Epoch: 5| Step: 3
Training loss: 0.7966753391634442
Validation loss: 2.5174588007507457

Epoch: 5| Step: 4
Training loss: 0.7819352006187046
Validation loss: 2.528936072628899

Epoch: 5| Step: 5
Training loss: 0.8055084263143582
Validation loss: 2.538591242647425

Epoch: 5| Step: 6
Training loss: 0.7078964672009631
Validation loss: 2.5717965432410717

Epoch: 5| Step: 7
Training loss: 0.6175425027590637
Validation loss: 2.547515659216723

Epoch: 5| Step: 8
Training loss: 0.6084804326581056
Validation loss: 2.538150240675837

Epoch: 5| Step: 9
Training loss: 0.8970665464648182
Validation loss: 2.520394931816314

Epoch: 5| Step: 10
Training loss: 0.6849415163148143
Validation loss: 2.4689355741271384

Epoch: 295| Step: 0
Training loss: 0.8920032812088117
Validation loss: 2.4782413594127233

Epoch: 5| Step: 1
Training loss: 0.6727966817722979
Validation loss: 2.4525984750377026

Epoch: 5| Step: 2
Training loss: 0.7575119051611509
Validation loss: 2.4554394255372287

Epoch: 5| Step: 3
Training loss: 0.8281449729382231
Validation loss: 2.435219666984182

Epoch: 5| Step: 4
Training loss: 0.9280607593023467
Validation loss: 2.449747910169603

Epoch: 5| Step: 5
Training loss: 0.7667689438336976
Validation loss: 2.4549506590286434

Epoch: 5| Step: 6
Training loss: 0.6879659937435805
Validation loss: 2.469066452652271

Epoch: 5| Step: 7
Training loss: 0.8386316468354531
Validation loss: 2.560172359684946

Epoch: 5| Step: 8
Training loss: 0.6769374592460287
Validation loss: 2.4998620733545143

Epoch: 5| Step: 9
Training loss: 0.6007123116376064
Validation loss: 2.564948750013315

Epoch: 5| Step: 10
Training loss: 0.8240167089939393
Validation loss: 2.56666271849724

Epoch: 296| Step: 0
Training loss: 0.6800981793632083
Validation loss: 2.5424207929946214

Epoch: 5| Step: 1
Training loss: 0.7339667951052954
Validation loss: 2.4835762777484427

Epoch: 5| Step: 2
Training loss: 0.6911075614982508
Validation loss: 2.5152152355810475

Epoch: 5| Step: 3
Training loss: 0.8030230149406765
Validation loss: 2.4811465563879733

Epoch: 5| Step: 4
Training loss: 0.5631809087047333
Validation loss: 2.452271144045518

Epoch: 5| Step: 5
Training loss: 0.8055685830615781
Validation loss: 2.4230817791145145

Epoch: 5| Step: 6
Training loss: 0.7617595172634329
Validation loss: 2.441935760895182

Epoch: 5| Step: 7
Training loss: 0.9073027711196772
Validation loss: 2.4384910371519424

Epoch: 5| Step: 8
Training loss: 0.9082879139688391
Validation loss: 2.4586329068176918

Epoch: 5| Step: 9
Training loss: 0.6866660912713476
Validation loss: 2.478178181054534

Epoch: 5| Step: 10
Training loss: 0.6761806167927771
Validation loss: 2.5219821551217443

Epoch: 297| Step: 0
Training loss: 0.7999042453680394
Validation loss: 2.523581493062255

Epoch: 5| Step: 1
Training loss: 1.0312269959629445
Validation loss: 2.5681918199330056

Epoch: 5| Step: 2
Training loss: 0.5122573871424321
Validation loss: 2.5859613811858804

Epoch: 5| Step: 3
Training loss: 0.6239160675185896
Validation loss: 2.5591850338374975

Epoch: 5| Step: 4
Training loss: 0.8264019512743407
Validation loss: 2.5279064105921405

Epoch: 5| Step: 5
Training loss: 0.6982057788666546
Validation loss: 2.5148879555976995

Epoch: 5| Step: 6
Training loss: 0.8777908028636844
Validation loss: 2.5143801279567226

Epoch: 5| Step: 7
Training loss: 0.577551428333835
Validation loss: 2.448635171988229

Epoch: 5| Step: 8
Training loss: 0.6708545476114054
Validation loss: 2.4622991708720168

Epoch: 5| Step: 9
Training loss: 0.8400003686404555
Validation loss: 2.506299109350244

Epoch: 5| Step: 10
Training loss: 0.7674197356287346
Validation loss: 2.4553826882512158

Epoch: 298| Step: 0
Training loss: 0.871059194657768
Validation loss: 2.4602721924940725

Epoch: 5| Step: 1
Training loss: 0.7243154500291779
Validation loss: 2.4911441291140735

Epoch: 5| Step: 2
Training loss: 0.7373325367903704
Validation loss: 2.4743321535401583

Epoch: 5| Step: 3
Training loss: 0.46248169231265024
Validation loss: 2.5095449071031615

Epoch: 5| Step: 4
Training loss: 0.6343135456328794
Validation loss: 2.499861137061123

Epoch: 5| Step: 5
Training loss: 1.1063698375039706
Validation loss: 2.5080774787198825

Epoch: 5| Step: 6
Training loss: 0.8760240897019144
Validation loss: 2.5015092129490384

Epoch: 5| Step: 7
Training loss: 0.7303425889025759
Validation loss: 2.5067922511329432

Epoch: 5| Step: 8
Training loss: 0.6819565267802504
Validation loss: 2.508568801337081

Epoch: 5| Step: 9
Training loss: 0.6438710385946652
Validation loss: 2.512930209165322

Epoch: 5| Step: 10
Training loss: 0.6329430574971889
Validation loss: 2.545494094273247

Epoch: 299| Step: 0
Training loss: 0.7494787153004517
Validation loss: 2.5367633344526985

Epoch: 5| Step: 1
Training loss: 0.8451020393045449
Validation loss: 2.514088123952452

Epoch: 5| Step: 2
Training loss: 0.6491101923590021
Validation loss: 2.535247153913709

Epoch: 5| Step: 3
Training loss: 0.6104021951654691
Validation loss: 2.5191267259406263

Epoch: 5| Step: 4
Training loss: 0.9275928268867544
Validation loss: 2.539532498890303

Epoch: 5| Step: 5
Training loss: 0.6221150093249825
Validation loss: 2.5517153126551597

Epoch: 5| Step: 6
Training loss: 0.7727479268949919
Validation loss: 2.5111289661573206

Epoch: 5| Step: 7
Training loss: 0.7033478065970681
Validation loss: 2.513541595366646

Epoch: 5| Step: 8
Training loss: 0.963934527888425
Validation loss: 2.5221126360822166

Epoch: 5| Step: 9
Training loss: 0.4859265427411991
Validation loss: 2.4650412578974312

Epoch: 5| Step: 10
Training loss: 0.7044098241434511
Validation loss: 2.476976250299689

Epoch: 300| Step: 0
Training loss: 0.6741538545886641
Validation loss: 2.447134067653439

Epoch: 5| Step: 1
Training loss: 0.8544722374903257
Validation loss: 2.448042073874234

Epoch: 5| Step: 2
Training loss: 0.4726260309568802
Validation loss: 2.463765317846017

Epoch: 5| Step: 3
Training loss: 0.5944148657793904
Validation loss: 2.4990014348226404

Epoch: 5| Step: 4
Training loss: 0.7596952901022609
Validation loss: 2.4972378238109387

Epoch: 5| Step: 5
Training loss: 0.8515142724615656
Validation loss: 2.5190313093947307

Epoch: 5| Step: 6
Training loss: 0.7561940479860534
Validation loss: 2.5749601725241997

Epoch: 5| Step: 7
Training loss: 1.009916843919077
Validation loss: 2.547098449572101

Epoch: 5| Step: 8
Training loss: 0.6915885124709762
Validation loss: 2.5599268357655776

Epoch: 5| Step: 9
Training loss: 0.5580668064719849
Validation loss: 2.5623342481440257

Epoch: 5| Step: 10
Training loss: 0.8106742299233198
Validation loss: 2.504553217091428

Epoch: 301| Step: 0
Training loss: 0.7087953173565593
Validation loss: 2.5148425660236673

Epoch: 5| Step: 1
Training loss: 0.791615915344819
Validation loss: 2.4641159192386404

Epoch: 5| Step: 2
Training loss: 0.5863262412837074
Validation loss: 2.470519019154732

Epoch: 5| Step: 3
Training loss: 0.8254851966330041
Validation loss: 2.431952056992634

Epoch: 5| Step: 4
Training loss: 0.6491311281569837
Validation loss: 2.4215253309589095

Epoch: 5| Step: 5
Training loss: 0.6038925080506284
Validation loss: 2.453306944985183

Epoch: 5| Step: 6
Training loss: 0.8551120101327966
Validation loss: 2.485344232648765

Epoch: 5| Step: 7
Training loss: 0.7881467056008088
Validation loss: 2.500634774252024

Epoch: 5| Step: 8
Training loss: 0.8345619720820701
Validation loss: 2.544816141794647

Epoch: 5| Step: 9
Training loss: 0.7424822974743813
Validation loss: 2.5626064051344257

Epoch: 5| Step: 10
Training loss: 0.7885961381918773
Validation loss: 2.5579923715667303

Epoch: 302| Step: 0
Training loss: 0.9499115476086889
Validation loss: 2.52165624495179

Epoch: 5| Step: 1
Training loss: 0.5444285029015067
Validation loss: 2.522728016674259

Epoch: 5| Step: 2
Training loss: 0.7177138530886203
Validation loss: 2.4878348819478986

Epoch: 5| Step: 3
Training loss: 0.9392042246678848
Validation loss: 2.461127794405295

Epoch: 5| Step: 4
Training loss: 0.7478783718991414
Validation loss: 2.449005237495745

Epoch: 5| Step: 5
Training loss: 0.8083297003503808
Validation loss: 2.449741540166889

Epoch: 5| Step: 6
Training loss: 0.5811027442869954
Validation loss: 2.4580798851859935

Epoch: 5| Step: 7
Training loss: 0.5656802292726274
Validation loss: 2.5096539660510784

Epoch: 5| Step: 8
Training loss: 0.6708332901909224
Validation loss: 2.4971165199574274

Epoch: 5| Step: 9
Training loss: 0.5926267891844571
Validation loss: 2.529567272109555

Epoch: 5| Step: 10
Training loss: 0.7322153436020584
Validation loss: 2.5753230416255146

Epoch: 303| Step: 0
Training loss: 0.7541242689435499
Validation loss: 2.576283554172533

Epoch: 5| Step: 1
Training loss: 0.7126180467358372
Validation loss: 2.559900784894809

Epoch: 5| Step: 2
Training loss: 0.7948359412530931
Validation loss: 2.5380778983521406

Epoch: 5| Step: 3
Training loss: 0.674672115127548
Validation loss: 2.494048686920403

Epoch: 5| Step: 4
Training loss: 0.7453255818176608
Validation loss: 2.4890569064330434

Epoch: 5| Step: 5
Training loss: 0.8856583358962444
Validation loss: 2.4752308909456224

Epoch: 5| Step: 6
Training loss: 0.6904044787432935
Validation loss: 2.4591367572155067

Epoch: 5| Step: 7
Training loss: 0.6803647974718645
Validation loss: 2.47659422333738

Epoch: 5| Step: 8
Training loss: 0.49763221682691294
Validation loss: 2.4499316619724554

Epoch: 5| Step: 9
Training loss: 0.9219560102655696
Validation loss: 2.4547834306377014

Epoch: 5| Step: 10
Training loss: 0.41210440320817043
Validation loss: 2.4420261047375047

Epoch: 304| Step: 0
Training loss: 0.7067094776693155
Validation loss: 2.4533807482602734

Epoch: 5| Step: 1
Training loss: 0.6010782348597806
Validation loss: 2.507525094080865

Epoch: 5| Step: 2
Training loss: 0.9680486416733246
Validation loss: 2.5056054052591055

Epoch: 5| Step: 3
Training loss: 0.653808001175399
Validation loss: 2.5296755651457103

Epoch: 5| Step: 4
Training loss: 0.7706133984066018
Validation loss: 2.545494389361994

Epoch: 5| Step: 5
Training loss: 0.3456595334086
Validation loss: 2.559852611166135

Epoch: 5| Step: 6
Training loss: 1.0964249733767755
Validation loss: 2.567087595433974

Epoch: 5| Step: 7
Training loss: 0.8264329646526357
Validation loss: 2.560700420698289

Epoch: 5| Step: 8
Training loss: 0.9566692679787424
Validation loss: 2.5206506100681034

Epoch: 5| Step: 9
Training loss: 0.4645258513700525
Validation loss: 2.5190482948993544

Epoch: 5| Step: 10
Training loss: 0.3287776405622928
Validation loss: 2.5396993818033793

Epoch: 305| Step: 0
Training loss: 0.6358332414947817
Validation loss: 2.538999721359958

Epoch: 5| Step: 1
Training loss: 0.8308823224096973
Validation loss: 2.52651576033448

Epoch: 5| Step: 2
Training loss: 0.4132427702442679
Validation loss: 2.5651653983128297

Epoch: 5| Step: 3
Training loss: 0.6003466617965755
Validation loss: 2.5615294734777425

Epoch: 5| Step: 4
Training loss: 0.8058168208637285
Validation loss: 2.5674370827066997

Epoch: 5| Step: 5
Training loss: 0.813257487863287
Validation loss: 2.5968239867745195

Epoch: 5| Step: 6
Training loss: 0.8889776353608242
Validation loss: 2.5723445283271964

Epoch: 5| Step: 7
Training loss: 0.8693638547049924
Validation loss: 2.5582562633964154

Epoch: 5| Step: 8
Training loss: 0.5985237258663664
Validation loss: 2.500580808380254

Epoch: 5| Step: 9
Training loss: 0.7660213145385659
Validation loss: 2.496555964782074

Epoch: 5| Step: 10
Training loss: 0.6935680881195028
Validation loss: 2.4957920469657813

Epoch: 306| Step: 0
Training loss: 0.7762356244781702
Validation loss: 2.4847377956695973

Epoch: 5| Step: 1
Training loss: 0.8539389252409607
Validation loss: 2.515998657680242

Epoch: 5| Step: 2
Training loss: 0.6625273743857921
Validation loss: 2.505573201023199

Epoch: 5| Step: 3
Training loss: 0.4943671027901907
Validation loss: 2.5434467266005374

Epoch: 5| Step: 4
Training loss: 0.4497432135027007
Validation loss: 2.5627229665080535

Epoch: 5| Step: 5
Training loss: 1.0603726913137417
Validation loss: 2.5661788412387407

Epoch: 5| Step: 6
Training loss: 0.5787830731394242
Validation loss: 2.5663613030939882

Epoch: 5| Step: 7
Training loss: 0.7371994246569089
Validation loss: 2.5952660243901606

Epoch: 5| Step: 8
Training loss: 0.6791917374045978
Validation loss: 2.567986784729094

Epoch: 5| Step: 9
Training loss: 0.6890405820098433
Validation loss: 2.5407113707974758

Epoch: 5| Step: 10
Training loss: 0.5181924305328021
Validation loss: 2.5182129425602935

Epoch: 307| Step: 0
Training loss: 0.8895330930067918
Validation loss: 2.4844877976272968

Epoch: 5| Step: 1
Training loss: 0.6390727473698851
Validation loss: 2.520294653269982

Epoch: 5| Step: 2
Training loss: 0.8009538790084455
Validation loss: 2.482558911803685

Epoch: 5| Step: 3
Training loss: 0.7597465610809172
Validation loss: 2.499886838341237

Epoch: 5| Step: 4
Training loss: 0.8636111841569506
Validation loss: 2.4844152372876884

Epoch: 5| Step: 5
Training loss: 0.7683633374653562
Validation loss: 2.5119501817842984

Epoch: 5| Step: 6
Training loss: 0.7443682304990548
Validation loss: 2.5058850474975114

Epoch: 5| Step: 7
Training loss: 0.6777825242234191
Validation loss: 2.5772236222496714

Epoch: 5| Step: 8
Training loss: 0.7144474536134634
Validation loss: 2.569967817862583

Epoch: 5| Step: 9
Training loss: 0.3193067834827381
Validation loss: 2.5656822747871386

Epoch: 5| Step: 10
Training loss: 0.339930775341101
Validation loss: 2.5493164318932804

Epoch: 308| Step: 0
Training loss: 0.6794171069518984
Validation loss: 2.549781539465738

Epoch: 5| Step: 1
Training loss: 0.5312330860362523
Validation loss: 2.5373448268925425

Epoch: 5| Step: 2
Training loss: 0.8416993334697429
Validation loss: 2.5236768289975324

Epoch: 5| Step: 3
Training loss: 0.421191898719788
Validation loss: 2.4846184187488336

Epoch: 5| Step: 4
Training loss: 0.6735940941456
Validation loss: 2.5300884703781015

Epoch: 5| Step: 5
Training loss: 0.6043624862038125
Validation loss: 2.517386284913183

Epoch: 5| Step: 6
Training loss: 0.9139477910504135
Validation loss: 2.4953736568297233

Epoch: 5| Step: 7
Training loss: 0.8163761699190929
Validation loss: 2.4804718867637305

Epoch: 5| Step: 8
Training loss: 0.4903621127214419
Validation loss: 2.477385854323657

Epoch: 5| Step: 9
Training loss: 0.6366440430794126
Validation loss: 2.484264071792186

Epoch: 5| Step: 10
Training loss: 0.8385781621790286
Validation loss: 2.4800704448934954

Epoch: 309| Step: 0
Training loss: 0.7442098670443756
Validation loss: 2.5093112316357202

Epoch: 5| Step: 1
Training loss: 0.5835884819150455
Validation loss: 2.507473811033068

Epoch: 5| Step: 2
Training loss: 0.5767116281405038
Validation loss: 2.5413991187812153

Epoch: 5| Step: 3
Training loss: 0.696725908932604
Validation loss: 2.5556597851879004

Epoch: 5| Step: 4
Training loss: 0.8779841014730407
Validation loss: 2.534743080010264

Epoch: 5| Step: 5
Training loss: 0.6238056453507479
Validation loss: 2.5708690252389426

Epoch: 5| Step: 6
Training loss: 0.634731303534267
Validation loss: 2.5525500622697344

Epoch: 5| Step: 7
Training loss: 0.7280959078498378
Validation loss: 2.5882275874596905

Epoch: 5| Step: 8
Training loss: 0.4951877280401716
Validation loss: 2.517391828934907

Epoch: 5| Step: 9
Training loss: 0.7798355267809045
Validation loss: 2.5334942438573895

Epoch: 5| Step: 10
Training loss: 0.8090348077413134
Validation loss: 2.5040187467749835

Epoch: 310| Step: 0
Training loss: 0.6470802073782903
Validation loss: 2.4624416990922766

Epoch: 5| Step: 1
Training loss: 0.5958096768500301
Validation loss: 2.485711193781586

Epoch: 5| Step: 2
Training loss: 0.6155603181194361
Validation loss: 2.4919486630729057

Epoch: 5| Step: 3
Training loss: 0.80104789946421
Validation loss: 2.5196224342730846

Epoch: 5| Step: 4
Training loss: 0.6456992461358606
Validation loss: 2.5160014602610854

Epoch: 5| Step: 5
Training loss: 0.8161989888934392
Validation loss: 2.5613052410155586

Epoch: 5| Step: 6
Training loss: 0.7348091789936937
Validation loss: 2.50409902451552

Epoch: 5| Step: 7
Training loss: 0.7932316386601149
Validation loss: 2.5191594153362598

Epoch: 5| Step: 8
Training loss: 0.4322088652520195
Validation loss: 2.5080999169371907

Epoch: 5| Step: 9
Training loss: 0.7624231846998762
Validation loss: 2.559548520808452

Epoch: 5| Step: 10
Training loss: 0.5371535127017317
Validation loss: 2.555403251740414

Epoch: 311| Step: 0
Training loss: 0.3219604665747181
Validation loss: 2.5444560675271894

Epoch: 5| Step: 1
Training loss: 0.7871998623690833
Validation loss: 2.5367957945601374

Epoch: 5| Step: 2
Training loss: 0.49796931840991643
Validation loss: 2.4973861812370943

Epoch: 5| Step: 3
Training loss: 0.6063988217825502
Validation loss: 2.5149375630002804

Epoch: 5| Step: 4
Training loss: 0.3105777269308939
Validation loss: 2.487638466503214

Epoch: 5| Step: 5
Training loss: 1.1548512736258516
Validation loss: 2.5023171566526674

Epoch: 5| Step: 6
Training loss: 0.7042935938872437
Validation loss: 2.4932802149955866

Epoch: 5| Step: 7
Training loss: 0.687563394744793
Validation loss: 2.4961639334860473

Epoch: 5| Step: 8
Training loss: 0.80747045362526
Validation loss: 2.495866535270036

Epoch: 5| Step: 9
Training loss: 0.538818552961777
Validation loss: 2.5364412727160373

Epoch: 5| Step: 10
Training loss: 0.6300295873158068
Validation loss: 2.542887025714593

Epoch: 312| Step: 0
Training loss: 0.6222523373551876
Validation loss: 2.549473677673099

Epoch: 5| Step: 1
Training loss: 0.7872857968092298
Validation loss: 2.5413572844958945

Epoch: 5| Step: 2
Training loss: 0.7296093051353623
Validation loss: 2.574491326800682

Epoch: 5| Step: 3
Training loss: 0.6878484796440557
Validation loss: 2.52774846210479

Epoch: 5| Step: 4
Training loss: 0.6621236433894234
Validation loss: 2.512034923013457

Epoch: 5| Step: 5
Training loss: 0.827848064253398
Validation loss: 2.517851465708815

Epoch: 5| Step: 6
Training loss: 0.7348193589578494
Validation loss: 2.523542441550564

Epoch: 5| Step: 7
Training loss: 0.45921355673860514
Validation loss: 2.517636376987532

Epoch: 5| Step: 8
Training loss: 0.41815505822085064
Validation loss: 2.513672752095608

Epoch: 5| Step: 9
Training loss: 0.772543727908697
Validation loss: 2.473274928433447

Epoch: 5| Step: 10
Training loss: 0.7042606084185082
Validation loss: 2.487867850604951

Epoch: 313| Step: 0
Training loss: 0.664572710492449
Validation loss: 2.4809701074558834

Epoch: 5| Step: 1
Training loss: 0.46691229123628725
Validation loss: 2.518419066793675

Epoch: 5| Step: 2
Training loss: 0.7994432016705728
Validation loss: 2.5116949345507043

Epoch: 5| Step: 3
Training loss: 0.8196588000597077
Validation loss: 2.5076757616157805

Epoch: 5| Step: 4
Training loss: 0.7723681060142562
Validation loss: 2.513327289920947

Epoch: 5| Step: 5
Training loss: 0.5768898579925144
Validation loss: 2.5150991491604837

Epoch: 5| Step: 6
Training loss: 0.6057523493923924
Validation loss: 2.5238364066377814

Epoch: 5| Step: 7
Training loss: 0.9450432575255553
Validation loss: 2.544620647853167

Epoch: 5| Step: 8
Training loss: 0.47584752089510096
Validation loss: 2.52397495709001

Epoch: 5| Step: 9
Training loss: 0.829294314854426
Validation loss: 2.536919213454773

Epoch: 5| Step: 10
Training loss: 0.4250126472162113
Validation loss: 2.5642249011718987

Epoch: 314| Step: 0
Training loss: 0.6914117672802466
Validation loss: 2.542092993768135

Epoch: 5| Step: 1
Training loss: 0.7086275321873486
Validation loss: 2.551891299756286

Epoch: 5| Step: 2
Training loss: 0.6392284616176914
Validation loss: 2.5328516570094473

Epoch: 5| Step: 3
Training loss: 0.6944708284028444
Validation loss: 2.5740599821927037

Epoch: 5| Step: 4
Training loss: 0.5894105343507975
Validation loss: 2.551452596614022

Epoch: 5| Step: 5
Training loss: 0.7036582408256302
Validation loss: 2.57848172372094

Epoch: 5| Step: 6
Training loss: 0.9417651430193043
Validation loss: 2.574497333370645

Epoch: 5| Step: 7
Training loss: 0.4920495460575608
Validation loss: 2.5766027695476783

Epoch: 5| Step: 8
Training loss: 0.6437641549637464
Validation loss: 2.5786407541505065

Epoch: 5| Step: 9
Training loss: 0.6631188363409906
Validation loss: 2.558278902845713

Epoch: 5| Step: 10
Training loss: 0.4332198343588797
Validation loss: 2.510372596680346

Epoch: 315| Step: 0
Training loss: 0.7933373557584498
Validation loss: 2.515959207750287

Epoch: 5| Step: 1
Training loss: 0.6026888124917856
Validation loss: 2.539520316297873

Epoch: 5| Step: 2
Training loss: 0.1986722837557171
Validation loss: 2.536898648013917

Epoch: 5| Step: 3
Training loss: 0.599768924920208
Validation loss: 2.540363216254186

Epoch: 5| Step: 4
Training loss: 0.780983612421015
Validation loss: 2.504872393682874

Epoch: 5| Step: 5
Training loss: 0.6311515155298677
Validation loss: 2.5173408120684977

Epoch: 5| Step: 6
Training loss: 0.5858591154438506
Validation loss: 2.502165108583034

Epoch: 5| Step: 7
Training loss: 0.7304075082820238
Validation loss: 2.5339496607496304

Epoch: 5| Step: 8
Training loss: 0.7762224170372898
Validation loss: 2.518901565467111

Epoch: 5| Step: 9
Training loss: 0.7074704571139747
Validation loss: 2.5376182539104826

Epoch: 5| Step: 10
Training loss: 0.6380070950852027
Validation loss: 2.5332157184886372

Epoch: 316| Step: 0
Training loss: 0.5454038177367807
Validation loss: 2.5444769033639534

Epoch: 5| Step: 1
Training loss: 0.5815794042132155
Validation loss: 2.5624868341083187

Epoch: 5| Step: 2
Training loss: 0.5857224387629878
Validation loss: 2.5057062716702747

Epoch: 5| Step: 3
Training loss: 0.6072020792327433
Validation loss: 2.5217129413337127

Epoch: 5| Step: 4
Training loss: 0.5298860655986002
Validation loss: 2.5183244683709787

Epoch: 5| Step: 5
Training loss: 0.7844249299104268
Validation loss: 2.493236515261723

Epoch: 5| Step: 6
Training loss: 0.7426465271374105
Validation loss: 2.5298189579124575

Epoch: 5| Step: 7
Training loss: 0.6287939077938195
Validation loss: 2.544322305048823

Epoch: 5| Step: 8
Training loss: 0.4737730624793116
Validation loss: 2.5019962984971857

Epoch: 5| Step: 9
Training loss: 0.863852954585971
Validation loss: 2.5032130953684124

Epoch: 5| Step: 10
Training loss: 0.7106894594882907
Validation loss: 2.4949182267659595

Epoch: 317| Step: 0
Training loss: 0.7206580088483827
Validation loss: 2.5288890541989795

Epoch: 5| Step: 1
Training loss: 0.7953339429561499
Validation loss: 2.487012296478626

Epoch: 5| Step: 2
Training loss: 0.6983275034607266
Validation loss: 2.5031607203013775

Epoch: 5| Step: 3
Training loss: 0.5054600439250515
Validation loss: 2.4890922731080733

Epoch: 5| Step: 4
Training loss: 0.5118865982716558
Validation loss: 2.4895047061129967

Epoch: 5| Step: 5
Training loss: 0.5996050756840852
Validation loss: 2.511588190428444

Epoch: 5| Step: 6
Training loss: 0.3972355158825888
Validation loss: 2.525178556120241

Epoch: 5| Step: 7
Training loss: 0.692388946118647
Validation loss: 2.5095937288322028

Epoch: 5| Step: 8
Training loss: 0.6519128209861752
Validation loss: 2.5188222734862977

Epoch: 5| Step: 9
Training loss: 0.8573494361395496
Validation loss: 2.5598046778920236

Epoch: 5| Step: 10
Training loss: 0.606026866002568
Validation loss: 2.5286988275123705

Epoch: 318| Step: 0
Training loss: 0.5781785579307845
Validation loss: 2.5551149010073786

Epoch: 5| Step: 1
Training loss: 0.5641414217275675
Validation loss: 2.567687402791464

Epoch: 5| Step: 2
Training loss: 0.7563134537235227
Validation loss: 2.5199477066266307

Epoch: 5| Step: 3
Training loss: 0.6860177794729899
Validation loss: 2.5441215806306596

Epoch: 5| Step: 4
Training loss: 0.5709095011894224
Validation loss: 2.544186237096923

Epoch: 5| Step: 5
Training loss: 0.8276420480562194
Validation loss: 2.537651494101455

Epoch: 5| Step: 6
Training loss: 0.7326571074074194
Validation loss: 2.569951628766896

Epoch: 5| Step: 7
Training loss: 0.587102875511757
Validation loss: 2.5580711118396384

Epoch: 5| Step: 8
Training loss: 0.6482061869758265
Validation loss: 2.5633946169458093

Epoch: 5| Step: 9
Training loss: 0.43997874720679403
Validation loss: 2.5555300801228866

Epoch: 5| Step: 10
Training loss: 0.5890682503498005
Validation loss: 2.5629619139048643

Epoch: 319| Step: 0
Training loss: 0.8738971981327998
Validation loss: 2.538832161349527

Epoch: 5| Step: 1
Training loss: 0.7522933388494857
Validation loss: 2.5225509934853814

Epoch: 5| Step: 2
Training loss: 0.6197765946893095
Validation loss: 2.502151560159068

Epoch: 5| Step: 3
Training loss: 0.6395624699953718
Validation loss: 2.5259616745687152

Epoch: 5| Step: 4
Training loss: 0.48576932615785356
Validation loss: 2.5198278053070653

Epoch: 5| Step: 5
Training loss: 0.6837115594982784
Validation loss: 2.517553924052438

Epoch: 5| Step: 6
Training loss: 0.6772332441215207
Validation loss: 2.518317929783364

Epoch: 5| Step: 7
Training loss: 0.6665590368253339
Validation loss: 2.488956480793416

Epoch: 5| Step: 8
Training loss: 0.38260691825167376
Validation loss: 2.475987954257534

Epoch: 5| Step: 9
Training loss: 0.5554476888234412
Validation loss: 2.496325650380077

Epoch: 5| Step: 10
Training loss: 0.5949776155604813
Validation loss: 2.4814306668913653

Epoch: 320| Step: 0
Training loss: 0.7835638495052754
Validation loss: 2.502927085888524

Epoch: 5| Step: 1
Training loss: 0.6607513454162317
Validation loss: 2.502068172750882

Epoch: 5| Step: 2
Training loss: 0.5724012194707797
Validation loss: 2.5348369145026513

Epoch: 5| Step: 3
Training loss: 0.6160650791014767
Validation loss: 2.537893532360795

Epoch: 5| Step: 4
Training loss: 0.9256649346658806
Validation loss: 2.5578170011889725

Epoch: 5| Step: 5
Training loss: 0.46278368845399026
Validation loss: 2.517261456667099

Epoch: 5| Step: 6
Training loss: 0.7174064268841521
Validation loss: 2.527679603121906

Epoch: 5| Step: 7
Training loss: 0.3572489210570308
Validation loss: 2.522287108393951

Epoch: 5| Step: 8
Training loss: 0.6038116914020949
Validation loss: 2.541584204861312

Epoch: 5| Step: 9
Training loss: 0.6246414586666685
Validation loss: 2.5103274165162026

Epoch: 5| Step: 10
Training loss: 0.29002548597009187
Validation loss: 2.5085926135067913

Epoch: 321| Step: 0
Training loss: 0.5972920723168502
Validation loss: 2.508070822957335

Epoch: 5| Step: 1
Training loss: 0.7363330628409118
Validation loss: 2.553841597754089

Epoch: 5| Step: 2
Training loss: 0.25752001846608785
Validation loss: 2.5375710725593024

Epoch: 5| Step: 3
Training loss: 0.5492878139260131
Validation loss: 2.5578749521769897

Epoch: 5| Step: 4
Training loss: 0.5455507320970768
Validation loss: 2.5820470287604214

Epoch: 5| Step: 5
Training loss: 0.8057253912500472
Validation loss: 2.560064278186265

Epoch: 5| Step: 6
Training loss: 0.5846401092635498
Validation loss: 2.565823274619814

Epoch: 5| Step: 7
Training loss: 0.5161587235900211
Validation loss: 2.5791009501926596

Epoch: 5| Step: 8
Training loss: 0.53854774001907
Validation loss: 2.5632352081921566

Epoch: 5| Step: 9
Training loss: 0.9011691155823393
Validation loss: 2.5644315907343693

Epoch: 5| Step: 10
Training loss: 0.782716252545227
Validation loss: 2.4964598354939764

Epoch: 322| Step: 0
Training loss: 0.9042065041785485
Validation loss: 2.5355202737915605

Epoch: 5| Step: 1
Training loss: 0.5056342135652055
Validation loss: 2.507723892880714

Epoch: 5| Step: 2
Training loss: 0.4868966268943986
Validation loss: 2.493067819391864

Epoch: 5| Step: 3
Training loss: 0.6908956463446232
Validation loss: 2.5147320754911338

Epoch: 5| Step: 4
Training loss: 0.5418709834212847
Validation loss: 2.503620185564441

Epoch: 5| Step: 5
Training loss: 0.6355261369638232
Validation loss: 2.5509075102201644

Epoch: 5| Step: 6
Training loss: 0.4427937331762409
Validation loss: 2.5555768742377314

Epoch: 5| Step: 7
Training loss: 0.4554547073790623
Validation loss: 2.5236224492109915

Epoch: 5| Step: 8
Training loss: 0.6165450651755712
Validation loss: 2.6000775712954436

Epoch: 5| Step: 9
Training loss: 0.7134787445912173
Validation loss: 2.5430823414265644

Epoch: 5| Step: 10
Training loss: 0.7896351766215859
Validation loss: 2.523358172759081

Epoch: 323| Step: 0
Training loss: 0.29293959154619875
Validation loss: 2.5333565752871685

Epoch: 5| Step: 1
Training loss: 0.855998985363457
Validation loss: 2.4839188816234015

Epoch: 5| Step: 2
Training loss: 0.3347609899104291
Validation loss: 2.4695662009455748

Epoch: 5| Step: 3
Training loss: 1.015007829213131
Validation loss: 2.4511726458161434

Epoch: 5| Step: 4
Training loss: 0.6047102083580008
Validation loss: 2.489026361613846

Epoch: 5| Step: 5
Training loss: 0.5095137635300866
Validation loss: 2.51916584488604

Epoch: 5| Step: 6
Training loss: 0.46911565506143066
Validation loss: 2.542063751820026

Epoch: 5| Step: 7
Training loss: 0.667034857126519
Validation loss: 2.518989134166279

Epoch: 5| Step: 8
Training loss: 0.6227528945797388
Validation loss: 2.531991677530718

Epoch: 5| Step: 9
Training loss: 0.6276790896023846
Validation loss: 2.5676128583777964

Epoch: 5| Step: 10
Training loss: 0.39316846576921566
Validation loss: 2.560903201245514

Epoch: 324| Step: 0
Training loss: 0.5776097346989999
Validation loss: 2.5586343751544174

Epoch: 5| Step: 1
Training loss: 0.5969012858809138
Validation loss: 2.5642798600574124

Epoch: 5| Step: 2
Training loss: 0.6049276333475336
Validation loss: 2.5287774529525944

Epoch: 5| Step: 3
Training loss: 0.508878469391149
Validation loss: 2.522987887732251

Epoch: 5| Step: 4
Training loss: 0.6600967922183029
Validation loss: 2.493729636195814

Epoch: 5| Step: 5
Training loss: 0.706278806284602
Validation loss: 2.475285516169853

Epoch: 5| Step: 6
Training loss: 0.6636114495999836
Validation loss: 2.4659633961201375

Epoch: 5| Step: 7
Training loss: 0.4571973384755513
Validation loss: 2.4558079265336663

Epoch: 5| Step: 8
Training loss: 0.8164688159386172
Validation loss: 2.4474751308378937

Epoch: 5| Step: 9
Training loss: 0.6382077365035729
Validation loss: 2.47126288230123

Epoch: 5| Step: 10
Training loss: 0.4881873994279454
Validation loss: 2.4975822509438146

Epoch: 325| Step: 0
Training loss: 0.7911564831061905
Validation loss: 2.516748019590936

Epoch: 5| Step: 1
Training loss: 0.7197473489355439
Validation loss: 2.5256045955523523

Epoch: 5| Step: 2
Training loss: 0.3802027397092669
Validation loss: 2.5280698322954565

Epoch: 5| Step: 3
Training loss: 0.6198637436915728
Validation loss: 2.5644170101914137

Epoch: 5| Step: 4
Training loss: 0.6127823179010902
Validation loss: 2.5609652077056277

Epoch: 5| Step: 5
Training loss: 0.6205689714386129
Validation loss: 2.563160846353711

Epoch: 5| Step: 6
Training loss: 0.48101970438538566
Validation loss: 2.5420252000592285

Epoch: 5| Step: 7
Training loss: 0.6430775287335394
Validation loss: 2.5424356519424847

Epoch: 5| Step: 8
Training loss: 0.4320252030071874
Validation loss: 2.523753570650982

Epoch: 5| Step: 9
Training loss: 0.7291860078335521
Validation loss: 2.4873155097238504

Epoch: 5| Step: 10
Training loss: 0.6825124417383129
Validation loss: 2.503071037488064

Epoch: 326| Step: 0
Training loss: 0.23994345999845235
Validation loss: 2.4814975937043706

Epoch: 5| Step: 1
Training loss: 0.7725675294735687
Validation loss: 2.49714624307261

Epoch: 5| Step: 2
Training loss: 0.7982318023461571
Validation loss: 2.5061754826839904

Epoch: 5| Step: 3
Training loss: 0.5849639943445797
Validation loss: 2.491335203330004

Epoch: 5| Step: 4
Training loss: 0.5476965319393614
Validation loss: 2.533837489173023

Epoch: 5| Step: 5
Training loss: 0.6876204341826299
Validation loss: 2.5033712790333413

Epoch: 5| Step: 6
Training loss: 0.7585156511516372
Validation loss: 2.5336302758775746

Epoch: 5| Step: 7
Training loss: 0.402028339789095
Validation loss: 2.520157586076537

Epoch: 5| Step: 8
Training loss: 0.6608675223025426
Validation loss: 2.5247866788685136

Epoch: 5| Step: 9
Training loss: 0.5049620221276039
Validation loss: 2.527773001551121

Epoch: 5| Step: 10
Training loss: 0.7101550564897535
Validation loss: 2.517268890136245

Epoch: 327| Step: 0
Training loss: 0.8774875295464788
Validation loss: 2.529438858142575

Epoch: 5| Step: 1
Training loss: 0.464684306777008
Validation loss: 2.526070528126638

Epoch: 5| Step: 2
Training loss: 0.6972158291343343
Validation loss: 2.5315987597252185

Epoch: 5| Step: 3
Training loss: 0.5200222248132998
Validation loss: 2.5282019885723734

Epoch: 5| Step: 4
Training loss: 0.6452386846189433
Validation loss: 2.5571409543241836

Epoch: 5| Step: 5
Training loss: 0.4976690617084467
Validation loss: 2.5291539371511593

Epoch: 5| Step: 6
Training loss: 0.33451488812989205
Validation loss: 2.5327721053707157

Epoch: 5| Step: 7
Training loss: 0.7143437455650118
Validation loss: 2.5474588447312234

Epoch: 5| Step: 8
Training loss: 0.7267195419080836
Validation loss: 2.580494615226366

Epoch: 5| Step: 9
Training loss: 0.636078237383301
Validation loss: 2.569538860661279

Epoch: 5| Step: 10
Training loss: 0.631419827495328
Validation loss: 2.525662293958646

Epoch: 328| Step: 0
Training loss: 0.6272502919816348
Validation loss: 2.457562895429945

Epoch: 5| Step: 1
Training loss: 0.5133937764603813
Validation loss: 2.443234356306605

Epoch: 5| Step: 2
Training loss: 0.46255020307306133
Validation loss: 2.4084981413226996

Epoch: 5| Step: 3
Training loss: 0.5689796130981385
Validation loss: 2.439874034588288

Epoch: 5| Step: 4
Training loss: 0.8379951536338892
Validation loss: 2.4908499291305977

Epoch: 5| Step: 5
Training loss: 0.6188472449825173
Validation loss: 2.5357311845786903

Epoch: 5| Step: 6
Training loss: 0.642721189208546
Validation loss: 2.56185741956609

Epoch: 5| Step: 7
Training loss: 0.7352737446374803
Validation loss: 2.6375336133281455

Epoch: 5| Step: 8
Training loss: 0.6275958275669659
Validation loss: 2.675628432115229

Epoch: 5| Step: 9
Training loss: 0.810133568971364
Validation loss: 2.699105768534322

Epoch: 5| Step: 10
Training loss: 0.37423007127683333
Validation loss: 2.6990906266031955

Epoch: 329| Step: 0
Training loss: 0.7022443554638825
Validation loss: 2.6634192436680535

Epoch: 5| Step: 1
Training loss: 0.5615755272629528
Validation loss: 2.626648480497252

Epoch: 5| Step: 2
Training loss: 0.28549996654790893
Validation loss: 2.580136732551592

Epoch: 5| Step: 3
Training loss: 0.7883098525273002
Validation loss: 2.5130241175115824

Epoch: 5| Step: 4
Training loss: 0.788913523896793
Validation loss: 2.4966728096858786

Epoch: 5| Step: 5
Training loss: 0.6083452620926193
Validation loss: 2.4738019595679086

Epoch: 5| Step: 6
Training loss: 0.5572814999897857
Validation loss: 2.473117531003433

Epoch: 5| Step: 7
Training loss: 0.6174158084479153
Validation loss: 2.491160382178608

Epoch: 5| Step: 8
Training loss: 0.9060810852481325
Validation loss: 2.5463438418194078

Epoch: 5| Step: 9
Training loss: 0.45908215069764186
Validation loss: 2.5490029109408354

Epoch: 5| Step: 10
Training loss: 0.3690195036285041
Validation loss: 2.581532519199669

Epoch: 330| Step: 0
Training loss: 0.3624679115496855
Validation loss: 2.56346368764368

Epoch: 5| Step: 1
Training loss: 0.7672000953899002
Validation loss: 2.5808597999060754

Epoch: 5| Step: 2
Training loss: 0.5672433389547483
Validation loss: 2.5737938480219675

Epoch: 5| Step: 3
Training loss: 0.5042742782482459
Validation loss: 2.5803143653946887

Epoch: 5| Step: 4
Training loss: 0.8304466237433805
Validation loss: 2.549243478230607

Epoch: 5| Step: 5
Training loss: 0.48509293848004365
Validation loss: 2.5219354304321304

Epoch: 5| Step: 6
Training loss: 0.6349632073053526
Validation loss: 2.508811988419735

Epoch: 5| Step: 7
Training loss: 0.5330943181733513
Validation loss: 2.508308427800335

Epoch: 5| Step: 8
Training loss: 0.8007186120819257
Validation loss: 2.5041643877708206

Epoch: 5| Step: 9
Training loss: 0.44682275093177215
Validation loss: 2.5156194418935764

Epoch: 5| Step: 10
Training loss: 0.46301209992567344
Validation loss: 2.4962158707323114

Epoch: 331| Step: 0
Training loss: 0.5266850065808538
Validation loss: 2.5394443575051953

Epoch: 5| Step: 1
Training loss: 0.5701786563534101
Validation loss: 2.5477193639003937

Epoch: 5| Step: 2
Training loss: 0.7198424123126866
Validation loss: 2.5479946729007716

Epoch: 5| Step: 3
Training loss: 0.6350976163820307
Validation loss: 2.5800165510588715

Epoch: 5| Step: 4
Training loss: 0.5899879835004237
Validation loss: 2.58257549005327

Epoch: 5| Step: 5
Training loss: 0.5332257332392889
Validation loss: 2.5709664516860293

Epoch: 5| Step: 6
Training loss: 0.6494288622094755
Validation loss: 2.615221603987173

Epoch: 5| Step: 7
Training loss: 0.49466478494434496
Validation loss: 2.5998195890082436

Epoch: 5| Step: 8
Training loss: 0.6340745186077935
Validation loss: 2.5782262797767728

Epoch: 5| Step: 9
Training loss: 0.6605535135775888
Validation loss: 2.5510653865009947

Epoch: 5| Step: 10
Training loss: 0.4693457314703246
Validation loss: 2.552451119323027

Epoch: 332| Step: 0
Training loss: 0.5749068775649455
Validation loss: 2.559223290041252

Epoch: 5| Step: 1
Training loss: 0.7386597162836661
Validation loss: 2.5603117504732498

Epoch: 5| Step: 2
Training loss: 0.5103141201575234
Validation loss: 2.515847051796304

Epoch: 5| Step: 3
Training loss: 0.6085902810150903
Validation loss: 2.5375529754667903

Epoch: 5| Step: 4
Training loss: 0.4153808622448792
Validation loss: 2.5178911909330193

Epoch: 5| Step: 5
Training loss: 0.45837599021195063
Validation loss: 2.551507622627697

Epoch: 5| Step: 6
Training loss: 0.6946505706896793
Validation loss: 2.4985914292246503

Epoch: 5| Step: 7
Training loss: 0.6103219719389574
Validation loss: 2.516468783765032

Epoch: 5| Step: 8
Training loss: 0.665699321555545
Validation loss: 2.48762101713665

Epoch: 5| Step: 9
Training loss: 0.34857559803168126
Validation loss: 2.5189507808714886

Epoch: 5| Step: 10
Training loss: 0.8400570265962944
Validation loss: 2.531749123651653

Epoch: 333| Step: 0
Training loss: 0.5891754709887171
Validation loss: 2.5304385107043306

Epoch: 5| Step: 1
Training loss: 0.7426406280203599
Validation loss: 2.5239316973936092

Epoch: 5| Step: 2
Training loss: 0.5458863722776436
Validation loss: 2.5711795987398367

Epoch: 5| Step: 3
Training loss: 0.3891999381108446
Validation loss: 2.544430069846152

Epoch: 5| Step: 4
Training loss: 0.360779299063713
Validation loss: 2.5652665061836375

Epoch: 5| Step: 5
Training loss: 0.5678808026127532
Validation loss: 2.583275563774716

Epoch: 5| Step: 6
Training loss: 0.7603881952538349
Validation loss: 2.601457027992547

Epoch: 5| Step: 7
Training loss: 0.4862051352516884
Validation loss: 2.6070707995435316

Epoch: 5| Step: 8
Training loss: 0.5957927198729088
Validation loss: 2.5978210283462335

Epoch: 5| Step: 9
Training loss: 0.7214886279515199
Validation loss: 2.583930310458438

Epoch: 5| Step: 10
Training loss: 0.535887086905045
Validation loss: 2.5677423594520254

Epoch: 334| Step: 0
Training loss: 0.5242015329822479
Validation loss: 2.5412348846656996

Epoch: 5| Step: 1
Training loss: 0.3513697625702524
Validation loss: 2.5155533367841802

Epoch: 5| Step: 2
Training loss: 0.773016342940296
Validation loss: 2.5233590596953492

Epoch: 5| Step: 3
Training loss: 0.5316907512905735
Validation loss: 2.4888723103526074

Epoch: 5| Step: 4
Training loss: 0.58547838661768
Validation loss: 2.5051078913547498

Epoch: 5| Step: 5
Training loss: 0.7165453726863108
Validation loss: 2.5202414389714427

Epoch: 5| Step: 6
Training loss: 0.7196101970624427
Validation loss: 2.554823676961119

Epoch: 5| Step: 7
Training loss: 0.20599561450165027
Validation loss: 2.5658761350703716

Epoch: 5| Step: 8
Training loss: 0.7196865614149075
Validation loss: 2.56453383515021

Epoch: 5| Step: 9
Training loss: 0.5036010409308804
Validation loss: 2.6117749239471673

Epoch: 5| Step: 10
Training loss: 0.5235424221269668
Validation loss: 2.6192770587299536

Epoch: 335| Step: 0
Training loss: 0.4208707158635676
Validation loss: 2.6384282778942763

Epoch: 5| Step: 1
Training loss: 0.6254797048226421
Validation loss: 2.595833416186247

Epoch: 5| Step: 2
Training loss: 0.5070648264531241
Validation loss: 2.544950807088204

Epoch: 5| Step: 3
Training loss: 0.4788718940895026
Validation loss: 2.5581164920267017

Epoch: 5| Step: 4
Training loss: 0.4161327895538057
Validation loss: 2.560892950279122

Epoch: 5| Step: 5
Training loss: 0.5692989016701379
Validation loss: 2.5592953552020465

Epoch: 5| Step: 6
Training loss: 0.6891225611316433
Validation loss: 2.5286261651114947

Epoch: 5| Step: 7
Training loss: 0.48678106640764945
Validation loss: 2.531826381570689

Epoch: 5| Step: 8
Training loss: 0.6063995835513569
Validation loss: 2.4718481322882195

Epoch: 5| Step: 9
Training loss: 0.7552712688311329
Validation loss: 2.4448890213195966

Epoch: 5| Step: 10
Training loss: 0.6939626943320866
Validation loss: 2.455878048571232

Epoch: 336| Step: 0
Training loss: 0.6943406374486566
Validation loss: 2.4865910650818464

Epoch: 5| Step: 1
Training loss: 0.41269696186131455
Validation loss: 2.5171213195977344

Epoch: 5| Step: 2
Training loss: 0.39108312445306526
Validation loss: 2.5409842095554085

Epoch: 5| Step: 3
Training loss: 0.6901735210956538
Validation loss: 2.5630456277012117

Epoch: 5| Step: 4
Training loss: 0.5865721253960385
Validation loss: 2.6494055744754226

Epoch: 5| Step: 5
Training loss: 0.682427288485947
Validation loss: 2.687499381864438

Epoch: 5| Step: 6
Training loss: 0.562356506694773
Validation loss: 2.6226043101807828

Epoch: 5| Step: 7
Training loss: 0.6366237733365863
Validation loss: 2.6175189691615026

Epoch: 5| Step: 8
Training loss: 0.6057568510709557
Validation loss: 2.565073459346289

Epoch: 5| Step: 9
Training loss: 0.5742776542086437
Validation loss: 2.539365472757661

Epoch: 5| Step: 10
Training loss: 0.5476590394562603
Validation loss: 2.5350826592837974

Epoch: 337| Step: 0
Training loss: 0.5446921243651858
Validation loss: 2.518782945643068

Epoch: 5| Step: 1
Training loss: 0.6001951853847897
Validation loss: 2.517373642787121

Epoch: 5| Step: 2
Training loss: 0.6014835751765154
Validation loss: 2.4939460132094426

Epoch: 5| Step: 3
Training loss: 0.6260625866416436
Validation loss: 2.473605129414683

Epoch: 5| Step: 4
Training loss: 0.43630264125844614
Validation loss: 2.5154400941426363

Epoch: 5| Step: 5
Training loss: 0.39402933581662763
Validation loss: 2.5287210472659996

Epoch: 5| Step: 6
Training loss: 0.6145094218234047
Validation loss: 2.511323384094814

Epoch: 5| Step: 7
Training loss: 0.655285580745694
Validation loss: 2.5038199241006254

Epoch: 5| Step: 8
Training loss: 0.7155393957385875
Validation loss: 2.518595638362982

Epoch: 5| Step: 9
Training loss: 0.5955770640582577
Validation loss: 2.559767345760397

Epoch: 5| Step: 10
Training loss: 0.16673053632758564
Validation loss: 2.5196422870725885

Epoch: 338| Step: 0
Training loss: 0.794018055866677
Validation loss: 2.53951408062118

Epoch: 5| Step: 1
Training loss: 0.474926658037752
Validation loss: 2.5766661294081903

Epoch: 5| Step: 2
Training loss: 0.6632598963379133
Validation loss: 2.5835297513501367

Epoch: 5| Step: 3
Training loss: 0.48151918660813725
Validation loss: 2.5282615109425945

Epoch: 5| Step: 4
Training loss: 0.5767258131100614
Validation loss: 2.589154958643815

Epoch: 5| Step: 5
Training loss: 0.526315293735346
Validation loss: 2.5781830274925888

Epoch: 5| Step: 6
Training loss: 0.5588386372319172
Validation loss: 2.5590453853251787

Epoch: 5| Step: 7
Training loss: 0.4361896305341023
Validation loss: 2.5326436170361655

Epoch: 5| Step: 8
Training loss: 0.47562683994874705
Validation loss: 2.547118784706241

Epoch: 5| Step: 9
Training loss: 0.5126845876389416
Validation loss: 2.545860628556689

Epoch: 5| Step: 10
Training loss: 0.5524886700603406
Validation loss: 2.5541738777986946

Epoch: 339| Step: 0
Training loss: 0.5680507595457753
Validation loss: 2.542569967405372

Epoch: 5| Step: 1
Training loss: 0.38236888171535893
Validation loss: 2.536073578232943

Epoch: 5| Step: 2
Training loss: 0.5758588554846791
Validation loss: 2.551529920058397

Epoch: 5| Step: 3
Training loss: 0.4716756911335538
Validation loss: 2.5543254279485876

Epoch: 5| Step: 4
Training loss: 0.8974765448307958
Validation loss: 2.551955857817322

Epoch: 5| Step: 5
Training loss: 0.22745699077721732
Validation loss: 2.5768787174641203

Epoch: 5| Step: 6
Training loss: 0.22054739327391787
Validation loss: 2.553049269286418

Epoch: 5| Step: 7
Training loss: 0.4095296342010817
Validation loss: 2.565174814695005

Epoch: 5| Step: 8
Training loss: 0.9220808413598721
Validation loss: 2.544879922333803

Epoch: 5| Step: 9
Training loss: 0.4643522116048441
Validation loss: 2.5707631096883814

Epoch: 5| Step: 10
Training loss: 0.42890975964609396
Validation loss: 2.544108313583648

Epoch: 340| Step: 0
Training loss: 0.48820922320325694
Validation loss: 2.518805470170441

Epoch: 5| Step: 1
Training loss: 0.5860734908920378
Validation loss: 2.5283056747884873

Epoch: 5| Step: 2
Training loss: 0.42160680864629807
Validation loss: 2.5527774539046764

Epoch: 5| Step: 3
Training loss: 0.4493871456144312
Validation loss: 2.5241390731058875

Epoch: 5| Step: 4
Training loss: 0.3800377615562221
Validation loss: 2.5321126511340135

Epoch: 5| Step: 5
Training loss: 0.5963516957149927
Validation loss: 2.5315989936489225

Epoch: 5| Step: 6
Training loss: 0.41156486950817145
Validation loss: 2.554577350954436

Epoch: 5| Step: 7
Training loss: 0.5186684693760341
Validation loss: 2.5607768161772517

Epoch: 5| Step: 8
Training loss: 0.5541243582424283
Validation loss: 2.5889600104300454

Epoch: 5| Step: 9
Training loss: 0.7223689152424523
Validation loss: 2.5891305940140645

Epoch: 5| Step: 10
Training loss: 0.7781189929776251
Validation loss: 2.556770239635663

Epoch: 341| Step: 0
Training loss: 0.47571410032564937
Validation loss: 2.580004584967439

Epoch: 5| Step: 1
Training loss: 0.7154704197674386
Validation loss: 2.5754579751877413

Epoch: 5| Step: 2
Training loss: 0.5745801242667754
Validation loss: 2.556199761817748

Epoch: 5| Step: 3
Training loss: 0.5451417704895488
Validation loss: 2.546488067347071

Epoch: 5| Step: 4
Training loss: 0.7631429806652215
Validation loss: 2.560913737474361

Epoch: 5| Step: 5
Training loss: 0.34305099378844134
Validation loss: 2.5604547982296935

Epoch: 5| Step: 6
Training loss: 0.32556959041388783
Validation loss: 2.5272155233167504

Epoch: 5| Step: 7
Training loss: 0.4471589673401145
Validation loss: 2.542368020642582

Epoch: 5| Step: 8
Training loss: 0.39413936905901814
Validation loss: 2.532484158055986

Epoch: 5| Step: 9
Training loss: 0.7097150332150429
Validation loss: 2.537106329985163

Epoch: 5| Step: 10
Training loss: 0.4220503866354567
Validation loss: 2.5096911651417733

Epoch: 342| Step: 0
Training loss: 0.3498018576690187
Validation loss: 2.5312230523853922

Epoch: 5| Step: 1
Training loss: 0.547202775002367
Validation loss: 2.531872861961436

Epoch: 5| Step: 2
Training loss: 0.45389947804111913
Validation loss: 2.567265648348585

Epoch: 5| Step: 3
Training loss: 0.5962543376229013
Validation loss: 2.557424641870252

Epoch: 5| Step: 4
Training loss: 0.35542565388439246
Validation loss: 2.5735662184354995

Epoch: 5| Step: 5
Training loss: 0.518004878468536
Validation loss: 2.5651527048310387

Epoch: 5| Step: 6
Training loss: 0.5758084977844267
Validation loss: 2.5680705852920562

Epoch: 5| Step: 7
Training loss: 0.49844483576431753
Validation loss: 2.5450114343651733

Epoch: 5| Step: 8
Training loss: 0.5685644140430416
Validation loss: 2.5423334687041605

Epoch: 5| Step: 9
Training loss: 0.5301098088105193
Validation loss: 2.510826018916181

Epoch: 5| Step: 10
Training loss: 0.8269990067689368
Validation loss: 2.5165184970237364

Epoch: 343| Step: 0
Training loss: 0.4176300851523153
Validation loss: 2.4900541748889022

Epoch: 5| Step: 1
Training loss: 0.4428515782204422
Validation loss: 2.504568250542007

Epoch: 5| Step: 2
Training loss: 0.7168627300725641
Validation loss: 2.5524148557871786

Epoch: 5| Step: 3
Training loss: 0.3480694169473561
Validation loss: 2.5314471574287603

Epoch: 5| Step: 4
Training loss: 0.7852390682135998
Validation loss: 2.570116064696305

Epoch: 5| Step: 5
Training loss: 0.33717614636472754
Validation loss: 2.583355585638211

Epoch: 5| Step: 6
Training loss: 0.33016365116993074
Validation loss: 2.5906480693330547

Epoch: 5| Step: 7
Training loss: 0.722712622840829
Validation loss: 2.5829690530178326

Epoch: 5| Step: 8
Training loss: 0.6819102019289054
Validation loss: 2.6152421407020556

Epoch: 5| Step: 9
Training loss: 0.3993245703090495
Validation loss: 2.5886912809083804

Epoch: 5| Step: 10
Training loss: 0.4192262076881471
Validation loss: 2.620106587983569

Epoch: 344| Step: 0
Training loss: 0.5699821194554677
Validation loss: 2.553227979376296

Epoch: 5| Step: 1
Training loss: 0.5327962363884857
Validation loss: 2.5773197590834545

Epoch: 5| Step: 2
Training loss: 0.42987580074846915
Validation loss: 2.5510425694766856

Epoch: 5| Step: 3
Training loss: 0.7842582007755504
Validation loss: 2.5576202627236024

Epoch: 5| Step: 4
Training loss: 0.3945673557794222
Validation loss: 2.536539625317356

Epoch: 5| Step: 5
Training loss: 0.38431394758958415
Validation loss: 2.54168826100257

Epoch: 5| Step: 6
Training loss: 0.49430648372325175
Validation loss: 2.5434385411100044

Epoch: 5| Step: 7
Training loss: 0.5358490462196877
Validation loss: 2.5205956203485362

Epoch: 5| Step: 8
Training loss: 0.5348810755381724
Validation loss: 2.5362741552086367

Epoch: 5| Step: 9
Training loss: 0.5860263502784432
Validation loss: 2.5624990935965553

Epoch: 5| Step: 10
Training loss: 0.4895715678269014
Validation loss: 2.568893454320277

Epoch: 345| Step: 0
Training loss: 0.4835007222169218
Validation loss: 2.5140444233935586

Epoch: 5| Step: 1
Training loss: 0.6412954079016112
Validation loss: 2.57869528251964

Epoch: 5| Step: 2
Training loss: 0.5682067141713916
Validation loss: 2.5486044478534478

Epoch: 5| Step: 3
Training loss: 0.660275555726701
Validation loss: 2.5460006518576304

Epoch: 5| Step: 4
Training loss: 0.35175221940189705
Validation loss: 2.5551844618978303

Epoch: 5| Step: 5
Training loss: 0.5506143519988153
Validation loss: 2.527075375212169

Epoch: 5| Step: 6
Training loss: 0.42919755225785683
Validation loss: 2.556192953547952

Epoch: 5| Step: 7
Training loss: 0.6771217457561239
Validation loss: 2.557997725356716

Epoch: 5| Step: 8
Training loss: 0.4685356921805498
Validation loss: 2.5511249173222237

Epoch: 5| Step: 9
Training loss: 0.408400966758686
Validation loss: 2.55468071128242

Epoch: 5| Step: 10
Training loss: 0.5536431434209533
Validation loss: 2.5809832030758995

Epoch: 346| Step: 0
Training loss: 0.4185055289547027
Validation loss: 2.5614996412372726

Epoch: 5| Step: 1
Training loss: 0.6959005291029691
Validation loss: 2.595297934050048

Epoch: 5| Step: 2
Training loss: 0.5536845367435022
Validation loss: 2.5646802939388724

Epoch: 5| Step: 3
Training loss: 0.4565243477517287
Validation loss: 2.565084850954187

Epoch: 5| Step: 4
Training loss: 0.5824344441767316
Validation loss: 2.554354910907909

Epoch: 5| Step: 5
Training loss: 0.3649861517330194
Validation loss: 2.546782055478804

Epoch: 5| Step: 6
Training loss: 0.507311941077223
Validation loss: 2.5629853520029386

Epoch: 5| Step: 7
Training loss: 0.5887695029039324
Validation loss: 2.5504312987369167

Epoch: 5| Step: 8
Training loss: 0.292986004639185
Validation loss: 2.5478976408756098

Epoch: 5| Step: 9
Training loss: 0.5673712829363872
Validation loss: 2.545982345328092

Epoch: 5| Step: 10
Training loss: 0.5663945690134417
Validation loss: 2.545445645877051

Epoch: 347| Step: 0
Training loss: 0.31974534088525214
Validation loss: 2.569764707103253

Epoch: 5| Step: 1
Training loss: 0.30399495671349097
Validation loss: 2.5362482111281817

Epoch: 5| Step: 2
Training loss: 0.4435473812279245
Validation loss: 2.5621051579176717

Epoch: 5| Step: 3
Training loss: 0.47982256165270837
Validation loss: 2.5421516047288035

Epoch: 5| Step: 4
Training loss: 0.4262759458358551
Validation loss: 2.5784758188975596

Epoch: 5| Step: 5
Training loss: 0.519200011473995
Validation loss: 2.531064008824637

Epoch: 5| Step: 6
Training loss: 0.41138995684890706
Validation loss: 2.5757545847796157

Epoch: 5| Step: 7
Training loss: 0.43932384708700223
Validation loss: 2.589313994921576

Epoch: 5| Step: 8
Training loss: 0.7381492375618544
Validation loss: 2.6386327201634474

Epoch: 5| Step: 9
Training loss: 0.813292960046899
Validation loss: 2.6143799412496684

Epoch: 5| Step: 10
Training loss: 0.6129548972122995
Validation loss: 2.651243155804685

Epoch: 348| Step: 0
Training loss: 0.4022286815352246
Validation loss: 2.6555207189362258

Epoch: 5| Step: 1
Training loss: 0.5342633392835768
Validation loss: 2.6007738515342242

Epoch: 5| Step: 2
Training loss: 0.4892674062553496
Validation loss: 2.6068872533944765

Epoch: 5| Step: 3
Training loss: 0.5307628979007428
Validation loss: 2.5622807610799647

Epoch: 5| Step: 4
Training loss: 0.3109686524394184
Validation loss: 2.5544988743134245

Epoch: 5| Step: 5
Training loss: 0.6342303557460651
Validation loss: 2.5525888999915307

Epoch: 5| Step: 6
Training loss: 0.5891028291774528
Validation loss: 2.532276569786355

Epoch: 5| Step: 7
Training loss: 0.614164845719694
Validation loss: 2.5342294873077313

Epoch: 5| Step: 8
Training loss: 0.6049959613334221
Validation loss: 2.5214691635695696

Epoch: 5| Step: 9
Training loss: 0.4330441884207485
Validation loss: 2.5587718564405773

Epoch: 5| Step: 10
Training loss: 0.4828345660997261
Validation loss: 2.554075663240393

Epoch: 349| Step: 0
Training loss: 0.4501437076938544
Validation loss: 2.573478782468081

Epoch: 5| Step: 1
Training loss: 0.6309251071946619
Validation loss: 2.588806079086305

Epoch: 5| Step: 2
Training loss: 0.541783088008106
Validation loss: 2.6129480335245305

Epoch: 5| Step: 3
Training loss: 0.37693656133915315
Validation loss: 2.5817206552773806

Epoch: 5| Step: 4
Training loss: 0.3564938655863183
Validation loss: 2.571119819836218

Epoch: 5| Step: 5
Training loss: 0.5699247845162999
Validation loss: 2.581927800521265

Epoch: 5| Step: 6
Training loss: 0.4883981793587607
Validation loss: 2.5864282260201863

Epoch: 5| Step: 7
Training loss: 0.3627892310462112
Validation loss: 2.5381511487042436

Epoch: 5| Step: 8
Training loss: 0.5050475923377152
Validation loss: 2.578326707433957

Epoch: 5| Step: 9
Training loss: 0.6598443191601744
Validation loss: 2.5478098583110262

Epoch: 5| Step: 10
Training loss: 0.5802721925540436
Validation loss: 2.546783499977465

Epoch: 350| Step: 0
Training loss: 0.6629292860654231
Validation loss: 2.539366184497036

Epoch: 5| Step: 1
Training loss: 0.32444332571867396
Validation loss: 2.534783883627067

Epoch: 5| Step: 2
Training loss: 0.4144104089754776
Validation loss: 2.5603805068313017

Epoch: 5| Step: 3
Training loss: 0.4338476623224663
Validation loss: 2.569128041924628

Epoch: 5| Step: 4
Training loss: 0.5269042267391472
Validation loss: 2.547459843032341

Epoch: 5| Step: 5
Training loss: 0.580127932275826
Validation loss: 2.5782785349423

Epoch: 5| Step: 6
Training loss: 0.4458531895193913
Validation loss: 2.5551036114375254

Epoch: 5| Step: 7
Training loss: 0.529490671187326
Validation loss: 2.6005959087818336

Epoch: 5| Step: 8
Training loss: 0.7328208955393654
Validation loss: 2.5778229487712583

Epoch: 5| Step: 9
Training loss: 0.4071714880862521
Validation loss: 2.5947623285621124

Epoch: 5| Step: 10
Training loss: 0.300625934381282
Validation loss: 2.5887541230751685

Epoch: 351| Step: 0
Training loss: 0.554470476489348
Validation loss: 2.579084853216694

Epoch: 5| Step: 1
Training loss: 0.4430608542626061
Validation loss: 2.565616842061604

Epoch: 5| Step: 2
Training loss: 0.701909816554384
Validation loss: 2.573722739658076

Epoch: 5| Step: 3
Training loss: 0.2905095199118283
Validation loss: 2.562716194074879

Epoch: 5| Step: 4
Training loss: 0.5593825153293513
Validation loss: 2.5893651372509794

Epoch: 5| Step: 5
Training loss: 0.6566268883152767
Validation loss: 2.5532837663574846

Epoch: 5| Step: 6
Training loss: 0.4076115825799626
Validation loss: 2.5551013328487224

Epoch: 5| Step: 7
Training loss: 0.5090307734223338
Validation loss: 2.5936671398343485

Epoch: 5| Step: 8
Training loss: 0.40190378225435175
Validation loss: 2.53787377182604

Epoch: 5| Step: 9
Training loss: 0.36132958901598466
Validation loss: 2.581527368144184

Epoch: 5| Step: 10
Training loss: 0.5481605406475213
Validation loss: 2.5668233541033665

Epoch: 352| Step: 0
Training loss: 0.33281532161035926
Validation loss: 2.5545992583102985

Epoch: 5| Step: 1
Training loss: 0.593160889145719
Validation loss: 2.570720611407632

Epoch: 5| Step: 2
Training loss: 0.5537685788140054
Validation loss: 2.5473748672871843

Epoch: 5| Step: 3
Training loss: 0.34920565774770534
Validation loss: 2.5348917798538526

Epoch: 5| Step: 4
Training loss: 0.4116528952408374
Validation loss: 2.548949439072654

Epoch: 5| Step: 5
Training loss: 0.46755922386062915
Validation loss: 2.5711804961007876

Epoch: 5| Step: 6
Training loss: 0.42213972051435833
Validation loss: 2.543834838899647

Epoch: 5| Step: 7
Training loss: 0.723993579546243
Validation loss: 2.544422009433012

Epoch: 5| Step: 8
Training loss: 0.5811775141813039
Validation loss: 2.5725633650081168

Epoch: 5| Step: 9
Training loss: 0.40932771467891693
Validation loss: 2.5558373768961298

Epoch: 5| Step: 10
Training loss: 0.5129522351974155
Validation loss: 2.582503206912018

Epoch: 353| Step: 0
Training loss: 0.5602006806824678
Validation loss: 2.5711355219785834

Epoch: 5| Step: 1
Training loss: 0.495892626625803
Validation loss: 2.5924462072083805

Epoch: 5| Step: 2
Training loss: 0.5950585301646137
Validation loss: 2.580021718048188

Epoch: 5| Step: 3
Training loss: 0.49197804066065215
Validation loss: 2.575025751128694

Epoch: 5| Step: 4
Training loss: 0.23344483173811464
Validation loss: 2.5836348031895255

Epoch: 5| Step: 5
Training loss: 0.6083158433916958
Validation loss: 2.5793726492840596

Epoch: 5| Step: 6
Training loss: 0.5643448247267191
Validation loss: 2.5822530135581947

Epoch: 5| Step: 7
Training loss: 0.5932317781153653
Validation loss: 2.591406533370924

Epoch: 5| Step: 8
Training loss: 0.3676183485994333
Validation loss: 2.5754294007450436

Epoch: 5| Step: 9
Training loss: 0.3446812802581035
Validation loss: 2.59552233371382

Epoch: 5| Step: 10
Training loss: 0.4616392580335865
Validation loss: 2.6034366560702664

Epoch: 354| Step: 0
Training loss: 0.5994381240683974
Validation loss: 2.570107569639659

Epoch: 5| Step: 1
Training loss: 0.6384841923157154
Validation loss: 2.5794163725991086

Epoch: 5| Step: 2
Training loss: 0.43869575510221276
Validation loss: 2.5777128534653513

Epoch: 5| Step: 3
Training loss: 0.5532355580588881
Validation loss: 2.5708612371861506

Epoch: 5| Step: 4
Training loss: 0.5653928701902527
Validation loss: 2.5640792672260067

Epoch: 5| Step: 5
Training loss: 0.40983848978521636
Validation loss: 2.567936023282606

Epoch: 5| Step: 6
Training loss: 0.4856827371658538
Validation loss: 2.5958150349418476

Epoch: 5| Step: 7
Training loss: 0.5615472141705234
Validation loss: 2.5858141181255685

Epoch: 5| Step: 8
Training loss: 0.5304221828060991
Validation loss: 2.5853398998817045

Epoch: 5| Step: 9
Training loss: 0.3877821471933793
Validation loss: 2.6049907356708255

Epoch: 5| Step: 10
Training loss: 0.40346260424100655
Validation loss: 2.615761107303574

Epoch: 355| Step: 0
Training loss: 0.24872176653493017
Validation loss: 2.5839035332441527

Epoch: 5| Step: 1
Training loss: 0.5111040981158281
Validation loss: 2.560952017906759

Epoch: 5| Step: 2
Training loss: 0.7256110740199301
Validation loss: 2.5878409286064414

Epoch: 5| Step: 3
Training loss: 0.5313403669802749
Validation loss: 2.5517438939478345

Epoch: 5| Step: 4
Training loss: 0.5369284307695025
Validation loss: 2.5683456462329577

Epoch: 5| Step: 5
Training loss: 0.581343327484855
Validation loss: 2.5498348491045104

Epoch: 5| Step: 6
Training loss: 0.5797639760368039
Validation loss: 2.560954524534359

Epoch: 5| Step: 7
Training loss: 0.46320908291530644
Validation loss: 2.550246194290761

Epoch: 5| Step: 8
Training loss: 0.4434399468567476
Validation loss: 2.5537271151093672

Epoch: 5| Step: 9
Training loss: 0.18619876585724507
Validation loss: 2.5144010509070798

Epoch: 5| Step: 10
Training loss: 0.5078378817744058
Validation loss: 2.5473452119587536

Epoch: 356| Step: 0
Training loss: 0.4143862448327382
Validation loss: 2.5197872753259607

Epoch: 5| Step: 1
Training loss: 0.676019593472627
Validation loss: 2.511841567503561

Epoch: 5| Step: 2
Training loss: 0.3541057361287386
Validation loss: 2.493386678736446

Epoch: 5| Step: 3
Training loss: 0.34050026324551863
Validation loss: 2.5320479394850497

Epoch: 5| Step: 4
Training loss: 0.4587715142321821
Validation loss: 2.536624267194619

Epoch: 5| Step: 5
Training loss: 0.6318376591230046
Validation loss: 2.5254985428841197

Epoch: 5| Step: 6
Training loss: 0.33963293354959856
Validation loss: 2.5497497026575893

Epoch: 5| Step: 7
Training loss: 0.5887620620139868
Validation loss: 2.5572844150307485

Epoch: 5| Step: 8
Training loss: 0.6272921967374837
Validation loss: 2.542325684999701

Epoch: 5| Step: 9
Training loss: 0.3256991152517689
Validation loss: 2.535867057175085

Epoch: 5| Step: 10
Training loss: 0.5515424730160955
Validation loss: 2.572411875290906

Epoch: 357| Step: 0
Training loss: 0.30104468315531574
Validation loss: 2.5754308162355946

Epoch: 5| Step: 1
Training loss: 0.4636856848340178
Validation loss: 2.600737923681738

Epoch: 5| Step: 2
Training loss: 0.6605904635277208
Validation loss: 2.569684013096595

Epoch: 5| Step: 3
Training loss: 0.40528229853123593
Validation loss: 2.5907132770536525

Epoch: 5| Step: 4
Training loss: 0.5274631223850161
Validation loss: 2.57224819358615

Epoch: 5| Step: 5
Training loss: 0.8219258020749295
Validation loss: 2.5812401619178234

Epoch: 5| Step: 6
Training loss: 0.26437172024182737
Validation loss: 2.5556883579784113

Epoch: 5| Step: 7
Training loss: 0.5897264174419304
Validation loss: 2.566905934251403

Epoch: 5| Step: 8
Training loss: 0.35455073774231693
Validation loss: 2.54981896250233

Epoch: 5| Step: 9
Training loss: 0.43075787134556015
Validation loss: 2.5393993483020325

Epoch: 5| Step: 10
Training loss: 0.41711400774154783
Validation loss: 2.5510106976562645

Epoch: 358| Step: 0
Training loss: 0.5045928417520588
Validation loss: 2.5536007935154004

Epoch: 5| Step: 1
Training loss: 0.506999553518456
Validation loss: 2.564602719224821

Epoch: 5| Step: 2
Training loss: 0.2478150463334212
Validation loss: 2.5988639768217756

Epoch: 5| Step: 3
Training loss: 0.6112111622616192
Validation loss: 2.5810376524077414

Epoch: 5| Step: 4
Training loss: 0.5972054720040245
Validation loss: 2.594884505960243

Epoch: 5| Step: 5
Training loss: 0.407219152588975
Validation loss: 2.5684198110466263

Epoch: 5| Step: 6
Training loss: 0.6320093026140503
Validation loss: 2.5419679305494602

Epoch: 5| Step: 7
Training loss: 0.5155683544139614
Validation loss: 2.531587591109011

Epoch: 5| Step: 8
Training loss: 0.48024043419290413
Validation loss: 2.541167285469834

Epoch: 5| Step: 9
Training loss: 0.5062244526574682
Validation loss: 2.5454229225011704

Epoch: 5| Step: 10
Training loss: 0.25744623118183324
Validation loss: 2.5553002336571273

Epoch: 359| Step: 0
Training loss: 0.5566667517168966
Validation loss: 2.5390434735187144

Epoch: 5| Step: 1
Training loss: 0.32150226696188117
Validation loss: 2.5432677807912696

Epoch: 5| Step: 2
Training loss: 0.5077500525004492
Validation loss: 2.575957368547115

Epoch: 5| Step: 3
Training loss: 0.5050481234178839
Validation loss: 2.5836998153270545

Epoch: 5| Step: 4
Training loss: 0.325706309565812
Validation loss: 2.5838472157564025

Epoch: 5| Step: 5
Training loss: 0.5268948092192819
Validation loss: 2.5964045007144336

Epoch: 5| Step: 6
Training loss: 0.5643523235137686
Validation loss: 2.6261939865295543

Epoch: 5| Step: 7
Training loss: 0.3656448057304164
Validation loss: 2.587981719698578

Epoch: 5| Step: 8
Training loss: 0.492448192766483
Validation loss: 2.6153527323053125

Epoch: 5| Step: 9
Training loss: 0.626694789438909
Validation loss: 2.5895895317742044

Epoch: 5| Step: 10
Training loss: 0.4025428427528443
Validation loss: 2.588217131715636

Epoch: 360| Step: 0
Training loss: 0.49399449898093223
Validation loss: 2.5737741021487905

Epoch: 5| Step: 1
Training loss: 0.4180540372163329
Validation loss: 2.566794189145297

Epoch: 5| Step: 2
Training loss: 0.23001964907575545
Validation loss: 2.5265953131288605

Epoch: 5| Step: 3
Training loss: 0.5133887551422206
Validation loss: 2.523226526827633

Epoch: 5| Step: 4
Training loss: 0.43780854108328826
Validation loss: 2.530861658032104

Epoch: 5| Step: 5
Training loss: 0.6227737354210138
Validation loss: 2.4944957189653123

Epoch: 5| Step: 6
Training loss: 0.5824755822331591
Validation loss: 2.524939053698571

Epoch: 5| Step: 7
Training loss: 0.6639095354616136
Validation loss: 2.524387137374023

Epoch: 5| Step: 8
Training loss: 0.5079709612758055
Validation loss: 2.5686047665780096

Epoch: 5| Step: 9
Training loss: 0.3264550333377648
Validation loss: 2.5551624205998142

Epoch: 5| Step: 10
Training loss: 0.2216357889276425
Validation loss: 2.548858612975797

Epoch: 361| Step: 0
Training loss: 0.6714754469068825
Validation loss: 2.5922144231022597

Epoch: 5| Step: 1
Training loss: 0.49834525949928055
Validation loss: 2.5749380949109577

Epoch: 5| Step: 2
Training loss: 0.5350607626714886
Validation loss: 2.597471585565472

Epoch: 5| Step: 3
Training loss: 0.2747282218693152
Validation loss: 2.53455729509651

Epoch: 5| Step: 4
Training loss: 0.5174372067340638
Validation loss: 2.5136737969608487

Epoch: 5| Step: 5
Training loss: 0.38307371763988013
Validation loss: 2.5124825597957825

Epoch: 5| Step: 6
Training loss: 0.34750580479212645
Validation loss: 2.562823094394027

Epoch: 5| Step: 7
Training loss: 0.498030748293214
Validation loss: 2.4889630532543743

Epoch: 5| Step: 8
Training loss: 0.4021352209037927
Validation loss: 2.5008144805435193

Epoch: 5| Step: 9
Training loss: 0.47732166108064633
Validation loss: 2.5389563481028317

Epoch: 5| Step: 10
Training loss: 0.5727315574767142
Validation loss: 2.5272522590072217

Epoch: 362| Step: 0
Training loss: 0.5673331995691948
Validation loss: 2.5453648682997607

Epoch: 5| Step: 1
Training loss: 0.44217024995296345
Validation loss: 2.5542434497631197

Epoch: 5| Step: 2
Training loss: 0.6459464056234354
Validation loss: 2.610616342392715

Epoch: 5| Step: 3
Training loss: 0.3489613094013142
Validation loss: 2.59627813310453

Epoch: 5| Step: 4
Training loss: 0.4124532412990437
Validation loss: 2.6241182691259266

Epoch: 5| Step: 5
Training loss: 0.4308282102517586
Validation loss: 2.625670091640529

Epoch: 5| Step: 6
Training loss: 0.3643519302969304
Validation loss: 2.620783975562484

Epoch: 5| Step: 7
Training loss: 0.438393106993248
Validation loss: 2.581723510141921

Epoch: 5| Step: 8
Training loss: 0.517192135239773
Validation loss: 2.5717988289682925

Epoch: 5| Step: 9
Training loss: 0.4983448109798771
Validation loss: 2.536273302101706

Epoch: 5| Step: 10
Training loss: 0.46897707843076947
Validation loss: 2.53078269924079

Epoch: 363| Step: 0
Training loss: 0.4543397832338256
Validation loss: 2.5050477801991216

Epoch: 5| Step: 1
Training loss: 0.4542748889539412
Validation loss: 2.507159703505726

Epoch: 5| Step: 2
Training loss: 0.5148513365028848
Validation loss: 2.5331183966396984

Epoch: 5| Step: 3
Training loss: 0.484885070249734
Validation loss: 2.5312588437218464

Epoch: 5| Step: 4
Training loss: 0.5391878175885986
Validation loss: 2.5293969922639965

Epoch: 5| Step: 5
Training loss: 0.32293264544341155
Validation loss: 2.570978962903656

Epoch: 5| Step: 6
Training loss: 0.39375347484084716
Validation loss: 2.5641542542992344

Epoch: 5| Step: 7
Training loss: 0.4787755921747046
Validation loss: 2.60103539090953

Epoch: 5| Step: 8
Training loss: 0.6119643486880345
Validation loss: 2.6214051410802597

Epoch: 5| Step: 9
Training loss: 0.14805154440770618
Validation loss: 2.5764792958747877

Epoch: 5| Step: 10
Training loss: 0.5975209999384387
Validation loss: 2.6119407579253804

Epoch: 364| Step: 0
Training loss: 0.5855180128846587
Validation loss: 2.6209160150135955

Epoch: 5| Step: 1
Training loss: 0.38276541673369874
Validation loss: 2.6529379640622146

Epoch: 5| Step: 2
Training loss: 0.43435648254333853
Validation loss: 2.5993664833451664

Epoch: 5| Step: 3
Training loss: 0.6203414391366072
Validation loss: 2.5721929295424197

Epoch: 5| Step: 4
Training loss: 0.4767163606756968
Validation loss: 2.546278481754156

Epoch: 5| Step: 5
Training loss: 0.2758435116908711
Validation loss: 2.5607359952515756

Epoch: 5| Step: 6
Training loss: 0.5250553067911898
Validation loss: 2.567452711514653

Epoch: 5| Step: 7
Training loss: 0.38473859198241867
Validation loss: 2.599518871201186

Epoch: 5| Step: 8
Training loss: 0.42474836655763515
Validation loss: 2.630707249229031

Epoch: 5| Step: 9
Training loss: 0.5272003544007414
Validation loss: 2.593237013581983

Epoch: 5| Step: 10
Training loss: 0.45846312122999217
Validation loss: 2.567426961674767

Epoch: 365| Step: 0
Training loss: 0.458358630291425
Validation loss: 2.597077008219587

Epoch: 5| Step: 1
Training loss: 0.3207899350171898
Validation loss: 2.58230823405519

Epoch: 5| Step: 2
Training loss: 0.5479539853672053
Validation loss: 2.5879381747761863

Epoch: 5| Step: 3
Training loss: 0.4475694149406324
Validation loss: 2.5854706726544405

Epoch: 5| Step: 4
Training loss: 0.33294668223854335
Validation loss: 2.5829269113957434

Epoch: 5| Step: 5
Training loss: 0.4903253417706931
Validation loss: 2.5746099280735715

Epoch: 5| Step: 6
Training loss: 0.557176619683975
Validation loss: 2.544072123597495

Epoch: 5| Step: 7
Training loss: 0.5481741324471419
Validation loss: 2.582692503133138

Epoch: 5| Step: 8
Training loss: 0.4399236576001527
Validation loss: 2.567112329058902

Epoch: 5| Step: 9
Training loss: 0.29264064217662666
Validation loss: 2.5575940209639754

Epoch: 5| Step: 10
Training loss: 0.5677056239585503
Validation loss: 2.534487137227313

Epoch: 366| Step: 0
Training loss: 0.41191080018836723
Validation loss: 2.544252169583197

Epoch: 5| Step: 1
Training loss: 0.5081902492806791
Validation loss: 2.5346610798871145

Epoch: 5| Step: 2
Training loss: 0.23413896596357078
Validation loss: 2.532393189886247

Epoch: 5| Step: 3
Training loss: 0.43001117652961524
Validation loss: 2.5282194772688116

Epoch: 5| Step: 4
Training loss: 0.41904857225478687
Validation loss: 2.5692575983388384

Epoch: 5| Step: 5
Training loss: 0.5547493376313184
Validation loss: 2.5356863986185485

Epoch: 5| Step: 6
Training loss: 0.41332701373780983
Validation loss: 2.5659281871524238

Epoch: 5| Step: 7
Training loss: 0.285962806165501
Validation loss: 2.5772379920734827

Epoch: 5| Step: 8
Training loss: 0.47471451085422595
Validation loss: 2.5560143123498618

Epoch: 5| Step: 9
Training loss: 0.5188755687727966
Validation loss: 2.596051310727274

Epoch: 5| Step: 10
Training loss: 0.6861940464632073
Validation loss: 2.56724990106703

Epoch: 367| Step: 0
Training loss: 0.2728625383401776
Validation loss: 2.5965864760725803

Epoch: 5| Step: 1
Training loss: 0.5877457500403086
Validation loss: 2.601732108507803

Epoch: 5| Step: 2
Training loss: 0.3996306114482934
Validation loss: 2.5974987825180422

Epoch: 5| Step: 3
Training loss: 0.3353439787871992
Validation loss: 2.596573789084125

Epoch: 5| Step: 4
Training loss: 0.642122379537489
Validation loss: 2.5741663357363427

Epoch: 5| Step: 5
Training loss: 0.47545515451540626
Validation loss: 2.566822757843544

Epoch: 5| Step: 6
Training loss: 0.5255845856976995
Validation loss: 2.5495618926408943

Epoch: 5| Step: 7
Training loss: 0.36065479122455524
Validation loss: 2.5626816243760655

Epoch: 5| Step: 8
Training loss: 0.357689908111694
Validation loss: 2.557909210996911

Epoch: 5| Step: 9
Training loss: 0.4352560226871695
Validation loss: 2.596960003586561

Epoch: 5| Step: 10
Training loss: 0.5361439298995329
Validation loss: 2.574070375430634

Epoch: 368| Step: 0
Training loss: 0.4763877735952823
Validation loss: 2.6075676965473984

Epoch: 5| Step: 1
Training loss: 0.5328001798396766
Validation loss: 2.594237209540873

Epoch: 5| Step: 2
Training loss: 0.41878860494956743
Validation loss: 2.569293783800745

Epoch: 5| Step: 3
Training loss: 0.38632615708948237
Validation loss: 2.5638321785947396

Epoch: 5| Step: 4
Training loss: 0.3979644772465356
Validation loss: 2.538962045958915

Epoch: 5| Step: 5
Training loss: 0.34636904271047225
Validation loss: 2.5486865822700286

Epoch: 5| Step: 6
Training loss: 0.6038969742431489
Validation loss: 2.568933891147584

Epoch: 5| Step: 7
Training loss: 0.31589176594055063
Validation loss: 2.5638521815221784

Epoch: 5| Step: 8
Training loss: 0.504304063481305
Validation loss: 2.549325897765857

Epoch: 5| Step: 9
Training loss: 0.49875966844293923
Validation loss: 2.6083184025558044

Epoch: 5| Step: 10
Training loss: 0.4207485312607913
Validation loss: 2.5765678528536995

Epoch: 369| Step: 0
Training loss: 0.5473406308036524
Validation loss: 2.598965895476525

Epoch: 5| Step: 1
Training loss: 0.23252543378224938
Validation loss: 2.6071734883546434

Epoch: 5| Step: 2
Training loss: 0.49406477756928346
Validation loss: 2.575061261182784

Epoch: 5| Step: 3
Training loss: 0.38650117398487155
Validation loss: 2.5776113859282614

Epoch: 5| Step: 4
Training loss: 0.4439982713695761
Validation loss: 2.5561151623750638

Epoch: 5| Step: 5
Training loss: 0.4687753988378526
Validation loss: 2.572873237771097

Epoch: 5| Step: 6
Training loss: 0.5721860967063676
Validation loss: 2.5420190320459652

Epoch: 5| Step: 7
Training loss: 0.4038490911654662
Validation loss: 2.598945430390097

Epoch: 5| Step: 8
Training loss: 0.3865906088870026
Validation loss: 2.5630531314318072

Epoch: 5| Step: 9
Training loss: 0.5008355550140173
Validation loss: 2.5503871347987452

Epoch: 5| Step: 10
Training loss: 0.37127791402535115
Validation loss: 2.557473621161198

Epoch: 370| Step: 0
Training loss: 0.43815247382902506
Validation loss: 2.592593185517842

Epoch: 5| Step: 1
Training loss: 0.5616662150766989
Validation loss: 2.560331493032927

Epoch: 5| Step: 2
Training loss: 0.47760042135696895
Validation loss: 2.570997931536464

Epoch: 5| Step: 3
Training loss: 0.5725579670540394
Validation loss: 2.5690446111484646

Epoch: 5| Step: 4
Training loss: 0.32698795310849105
Validation loss: 2.5748121981220056

Epoch: 5| Step: 5
Training loss: 0.16940433788293566
Validation loss: 2.5332976480071743

Epoch: 5| Step: 6
Training loss: 0.33289463883231474
Validation loss: 2.571084833666402

Epoch: 5| Step: 7
Training loss: 0.5922847033921136
Validation loss: 2.5667568258339153

Epoch: 5| Step: 8
Training loss: 0.5308924200847958
Validation loss: 2.55754986318293

Epoch: 5| Step: 9
Training loss: 0.3702448320330772
Validation loss: 2.5723190656498414

Epoch: 5| Step: 10
Training loss: 0.29342960984872357
Validation loss: 2.618508926742534

Epoch: 371| Step: 0
Training loss: 0.47693916194137814
Validation loss: 2.5836737342653864

Epoch: 5| Step: 1
Training loss: 0.4239815640782485
Validation loss: 2.6270590410747783

Epoch: 5| Step: 2
Training loss: 0.32638942293479645
Validation loss: 2.5950453244718696

Epoch: 5| Step: 3
Training loss: 0.4053790402994771
Validation loss: 2.5601165796148555

Epoch: 5| Step: 4
Training loss: 0.444853244676148
Validation loss: 2.600081420582766

Epoch: 5| Step: 5
Training loss: 0.28954594368455744
Validation loss: 2.5833002773740934

Epoch: 5| Step: 6
Training loss: 0.39830661942806755
Validation loss: 2.606880461951821

Epoch: 5| Step: 7
Training loss: 0.3485644831868609
Validation loss: 2.561272217719701

Epoch: 5| Step: 8
Training loss: 0.6538572741982555
Validation loss: 2.555894547274964

Epoch: 5| Step: 9
Training loss: 0.6725155194700492
Validation loss: 2.609608954663437

Epoch: 5| Step: 10
Training loss: 0.3760277056898304
Validation loss: 2.5593701989670774

Epoch: 372| Step: 0
Training loss: 0.4032017161687117
Validation loss: 2.5916247506483416

Epoch: 5| Step: 1
Training loss: 0.45502054071173187
Validation loss: 2.5854572494214634

Epoch: 5| Step: 2
Training loss: 0.40489878054835843
Validation loss: 2.5718240067222764

Epoch: 5| Step: 3
Training loss: 0.5073827539036152
Validation loss: 2.5846291384077373

Epoch: 5| Step: 4
Training loss: 0.4174312272506525
Validation loss: 2.61197313963515

Epoch: 5| Step: 5
Training loss: 0.39761990454154217
Validation loss: 2.5932485174972975

Epoch: 5| Step: 6
Training loss: 0.5480004038722228
Validation loss: 2.6028448130772506

Epoch: 5| Step: 7
Training loss: 0.4206807930207257
Validation loss: 2.5777811834807642

Epoch: 5| Step: 8
Training loss: 0.12684583531921345
Validation loss: 2.5992467431985427

Epoch: 5| Step: 9
Training loss: 0.5784542847129688
Validation loss: 2.599223042268456

Epoch: 5| Step: 10
Training loss: 0.3939731162552382
Validation loss: 2.579425482523671

Epoch: 373| Step: 0
Training loss: 0.4185190232783218
Validation loss: 2.545611324397691

Epoch: 5| Step: 1
Training loss: 0.5740283728326055
Validation loss: 2.53210194646425

Epoch: 5| Step: 2
Training loss: 0.339772184005586
Validation loss: 2.5524590228071626

Epoch: 5| Step: 3
Training loss: 0.5022711729596817
Validation loss: 2.563557985418044

Epoch: 5| Step: 4
Training loss: 0.372524394894262
Validation loss: 2.5790943937237767

Epoch: 5| Step: 5
Training loss: 0.47930668429881657
Validation loss: 2.542496411793542

Epoch: 5| Step: 6
Training loss: 0.5951330239793234
Validation loss: 2.5645416174269697

Epoch: 5| Step: 7
Training loss: 0.2074849268166706
Validation loss: 2.5723017671503188

Epoch: 5| Step: 8
Training loss: 0.354477621993022
Validation loss: 2.5911304303780853

Epoch: 5| Step: 9
Training loss: 0.48621262860289466
Validation loss: 2.6022022163769245

Epoch: 5| Step: 10
Training loss: 0.3858653970307546
Validation loss: 2.6036356306180872

Epoch: 374| Step: 0
Training loss: 0.10249318958690799
Validation loss: 2.584653905519975

Epoch: 5| Step: 1
Training loss: 0.6070136756267677
Validation loss: 2.5637543572280186

Epoch: 5| Step: 2
Training loss: 0.2231286792425067
Validation loss: 2.584072470406331

Epoch: 5| Step: 3
Training loss: 0.37073841148111875
Validation loss: 2.5769297902267607

Epoch: 5| Step: 4
Training loss: 0.4004118936983955
Validation loss: 2.564073176260918

Epoch: 5| Step: 5
Training loss: 0.3432417493413436
Validation loss: 2.556772006871134

Epoch: 5| Step: 6
Training loss: 0.20761253516797337
Validation loss: 2.534771910831393

Epoch: 5| Step: 7
Training loss: 0.6202898400921848
Validation loss: 2.558005061995124

Epoch: 5| Step: 8
Training loss: 0.4873128366648974
Validation loss: 2.554369802804373

Epoch: 5| Step: 9
Training loss: 0.38709550865428566
Validation loss: 2.5592479253714107

Epoch: 5| Step: 10
Training loss: 0.666421604315016
Validation loss: 2.56516741811073

Epoch: 375| Step: 0
Training loss: 0.5021609458715645
Validation loss: 2.555671298504065

Epoch: 5| Step: 1
Training loss: 0.4297792336771597
Validation loss: 2.578692676819949

Epoch: 5| Step: 2
Training loss: 0.4874611796303518
Validation loss: 2.5957314792275366

Epoch: 5| Step: 3
Training loss: 0.5693443651049975
Validation loss: 2.6014836747858676

Epoch: 5| Step: 4
Training loss: 0.3757115210159979
Validation loss: 2.5921807620600155

Epoch: 5| Step: 5
Training loss: 0.32863217847883774
Validation loss: 2.5746834106037655

Epoch: 5| Step: 6
Training loss: 0.5389783765970804
Validation loss: 2.596368821948276

Epoch: 5| Step: 7
Training loss: 0.3278905621397455
Validation loss: 2.5760771599734635

Epoch: 5| Step: 8
Training loss: 0.4464413072268044
Validation loss: 2.549910531051852

Epoch: 5| Step: 9
Training loss: 0.45046303953533356
Validation loss: 2.5924232105007774

Epoch: 5| Step: 10
Training loss: 0.4172510420167413
Validation loss: 2.5682108081532444

Epoch: 376| Step: 0
Training loss: 0.2864973200652721
Validation loss: 2.6027318431674384

Epoch: 5| Step: 1
Training loss: 0.533538964113389
Validation loss: 2.567003194526436

Epoch: 5| Step: 2
Training loss: 0.40449121199729215
Validation loss: 2.596531303512114

Epoch: 5| Step: 3
Training loss: 0.5623609317953968
Validation loss: 2.5641315857406

Epoch: 5| Step: 4
Training loss: 0.3570705834556614
Validation loss: 2.603101974566877

Epoch: 5| Step: 5
Training loss: 0.5325807845038206
Validation loss: 2.5930466818333113

Epoch: 5| Step: 6
Training loss: 0.501470549048606
Validation loss: 2.5947894491838763

Epoch: 5| Step: 7
Training loss: 0.3756215785310271
Validation loss: 2.585952919841956

Epoch: 5| Step: 8
Training loss: 0.5881570611498895
Validation loss: 2.569407825288476

Epoch: 5| Step: 9
Training loss: 0.2283801630968022
Validation loss: 2.546451203436406

Epoch: 5| Step: 10
Training loss: 0.322594723134715
Validation loss: 2.54509995509023

Epoch: 377| Step: 0
Training loss: 0.6049542363647243
Validation loss: 2.5256248555645966

Epoch: 5| Step: 1
Training loss: 0.3001836438166626
Validation loss: 2.553287337783224

Epoch: 5| Step: 2
Training loss: 0.37864713559283125
Validation loss: 2.5532237773054374

Epoch: 5| Step: 3
Training loss: 0.4131835749965836
Validation loss: 2.5802577688695902

Epoch: 5| Step: 4
Training loss: 0.4828768295344277
Validation loss: 2.5466754723693925

Epoch: 5| Step: 5
Training loss: 0.522341990968582
Validation loss: 2.616912598146994

Epoch: 5| Step: 6
Training loss: 0.3086236021837583
Validation loss: 2.5877734447533207

Epoch: 5| Step: 7
Training loss: 0.4380887021688845
Validation loss: 2.585067240238257

Epoch: 5| Step: 8
Training loss: 0.4873474041213806
Validation loss: 2.5947879340921363

Epoch: 5| Step: 9
Training loss: 0.45546460419693374
Validation loss: 2.621545298687424

Epoch: 5| Step: 10
Training loss: 0.45074877365779087
Validation loss: 2.6474987503978866

Epoch: 378| Step: 0
Training loss: 0.3751791883555506
Validation loss: 2.638501938963205

Epoch: 5| Step: 1
Training loss: 0.546694507786411
Validation loss: 2.638500555365502

Epoch: 5| Step: 2
Training loss: 0.5533618398393634
Validation loss: 2.628157346334559

Epoch: 5| Step: 3
Training loss: 0.4392372279180201
Validation loss: 2.6051612014844445

Epoch: 5| Step: 4
Training loss: 0.4408056680108513
Validation loss: 2.6224675109108966

Epoch: 5| Step: 5
Training loss: 0.4581521463613036
Validation loss: 2.5757603475424045

Epoch: 5| Step: 6
Training loss: 0.44405344272641006
Validation loss: 2.555509016397328

Epoch: 5| Step: 7
Training loss: 0.3658800384922639
Validation loss: 2.5519116861072324

Epoch: 5| Step: 8
Training loss: 0.3173408128385543
Validation loss: 2.5430378321120073

Epoch: 5| Step: 9
Training loss: 0.3874459990436727
Validation loss: 2.548518604932927

Epoch: 5| Step: 10
Training loss: 0.4064585443897309
Validation loss: 2.556965292946016

Epoch: 379| Step: 0
Training loss: 0.4118265564581056
Validation loss: 2.547168820683958

Epoch: 5| Step: 1
Training loss: 0.575961472192988
Validation loss: 2.5749136218919206

Epoch: 5| Step: 2
Training loss: 0.29708681581140495
Validation loss: 2.6009302799641882

Epoch: 5| Step: 3
Training loss: 0.1708526550004063
Validation loss: 2.58741106044246

Epoch: 5| Step: 4
Training loss: 0.5802022114082043
Validation loss: 2.6057351200928043

Epoch: 5| Step: 5
Training loss: 0.4081634611727162
Validation loss: 2.5927793977616123

Epoch: 5| Step: 6
Training loss: 0.2652701925327242
Validation loss: 2.6260312267349004

Epoch: 5| Step: 7
Training loss: 0.6141834790203081
Validation loss: 2.6217280332693407

Epoch: 5| Step: 8
Training loss: 0.40311160471935453
Validation loss: 2.6018094708634774

Epoch: 5| Step: 9
Training loss: 0.28942596936224607
Validation loss: 2.59852119360198

Epoch: 5| Step: 10
Training loss: 0.49750595637929923
Validation loss: 2.5955072285190726

Epoch: 380| Step: 0
Training loss: 0.36082916863411585
Validation loss: 2.57746970461606

Epoch: 5| Step: 1
Training loss: 0.341318231318325
Validation loss: 2.574074648542637

Epoch: 5| Step: 2
Training loss: 0.5412575081178959
Validation loss: 2.5695034977775557

Epoch: 5| Step: 3
Training loss: 0.38107567538245546
Validation loss: 2.5648343910650575

Epoch: 5| Step: 4
Training loss: 0.2528885620146175
Validation loss: 2.5609592514827657

Epoch: 5| Step: 5
Training loss: 0.48526657250713473
Validation loss: 2.5752508635221263

Epoch: 5| Step: 6
Training loss: 0.42928414920345226
Validation loss: 2.5808983963752414

Epoch: 5| Step: 7
Training loss: 0.4975573958063351
Validation loss: 2.574585716555364

Epoch: 5| Step: 8
Training loss: 0.19520212869612052
Validation loss: 2.600234263939687

Epoch: 5| Step: 9
Training loss: 0.6815415231099329
Validation loss: 2.587849495720159

Epoch: 5| Step: 10
Training loss: 0.2723719817393043
Validation loss: 2.5831128865584243

Epoch: 381| Step: 0
Training loss: 0.31119974952487867
Validation loss: 2.5766852083995513

Epoch: 5| Step: 1
Training loss: 0.45876818496147326
Validation loss: 2.571865781034564

Epoch: 5| Step: 2
Training loss: 0.5961789591471703
Validation loss: 2.5835458692543054

Epoch: 5| Step: 3
Training loss: 0.4152424213135821
Validation loss: 2.5963680093223673

Epoch: 5| Step: 4
Training loss: 0.46579886333098397
Validation loss: 2.5877068151050855

Epoch: 5| Step: 5
Training loss: 0.3579119048654846
Validation loss: 2.556046009947979

Epoch: 5| Step: 6
Training loss: 0.6101980275640176
Validation loss: 2.5673912985986944

Epoch: 5| Step: 7
Training loss: 0.3159168013443522
Validation loss: 2.5729806337496055

Epoch: 5| Step: 8
Training loss: 0.30065382698303134
Validation loss: 2.6111456041589416

Epoch: 5| Step: 9
Training loss: 0.2627622384397921
Validation loss: 2.578776015653578

Epoch: 5| Step: 10
Training loss: 0.3618226662118723
Validation loss: 2.565383566271104

Epoch: 382| Step: 0
Training loss: 0.3305673641489595
Validation loss: 2.618907507634666

Epoch: 5| Step: 1
Training loss: 0.48527669041284993
Validation loss: 2.609784702329942

Epoch: 5| Step: 2
Training loss: 0.5449352467854903
Validation loss: 2.656843807434423

Epoch: 5| Step: 3
Training loss: 0.32596099340926915
Validation loss: 2.6009101023794905

Epoch: 5| Step: 4
Training loss: 0.38172126472509865
Validation loss: 2.5951646983582406

Epoch: 5| Step: 5
Training loss: 0.3413239940830776
Validation loss: 2.5955530989298334

Epoch: 5| Step: 6
Training loss: 0.2578136270671831
Validation loss: 2.5965426400430767

Epoch: 5| Step: 7
Training loss: 0.32102851390610276
Validation loss: 2.6343585864595696

Epoch: 5| Step: 8
Training loss: 0.49743575956133834
Validation loss: 2.610452535724423

Epoch: 5| Step: 9
Training loss: 0.5733778369019216
Validation loss: 2.619033562548317

Epoch: 5| Step: 10
Training loss: 0.4460451056151698
Validation loss: 2.6167522089859037

Epoch: 383| Step: 0
Training loss: 0.46573243021932526
Validation loss: 2.598176596978617

Epoch: 5| Step: 1
Training loss: 0.41221716677873754
Validation loss: 2.607278922325827

Epoch: 5| Step: 2
Training loss: 0.4027414115934843
Validation loss: 2.573896969538656

Epoch: 5| Step: 3
Training loss: 0.5885599324815578
Validation loss: 2.5245224425451482

Epoch: 5| Step: 4
Training loss: 0.3042134240325413
Validation loss: 2.547814769131205

Epoch: 5| Step: 5
Training loss: 0.3871436433992762
Validation loss: 2.5528134823184634

Epoch: 5| Step: 6
Training loss: 0.41170087337591205
Validation loss: 2.587053333378112

Epoch: 5| Step: 7
Training loss: 0.3856873485359039
Validation loss: 2.6090020029888397

Epoch: 5| Step: 8
Training loss: 0.3977057900138464
Validation loss: 2.6079776827971304

Epoch: 5| Step: 9
Training loss: 0.4920761194300602
Validation loss: 2.6096249350709444

Epoch: 5| Step: 10
Training loss: 0.2774189860419911
Validation loss: 2.6330439719986147

Epoch: 384| Step: 0
Training loss: 0.4991656285589862
Validation loss: 2.6600797113738532

Epoch: 5| Step: 1
Training loss: 0.2294695498075785
Validation loss: 2.657679148845717

Epoch: 5| Step: 2
Training loss: 0.5404821306321929
Validation loss: 2.6557417564900603

Epoch: 5| Step: 3
Training loss: 0.40926172713184056
Validation loss: 2.6658476652101535

Epoch: 5| Step: 4
Training loss: 0.27845847732608336
Validation loss: 2.68906865386498

Epoch: 5| Step: 5
Training loss: 0.26985316471624676
Validation loss: 2.6592401428027936

Epoch: 5| Step: 6
Training loss: 0.5014572068685007
Validation loss: 2.6435430793248686

Epoch: 5| Step: 7
Training loss: 0.3680697251937184
Validation loss: 2.604383326880076

Epoch: 5| Step: 8
Training loss: 0.43285736925581425
Validation loss: 2.621354750007569

Epoch: 5| Step: 9
Training loss: 0.37193546204352373
Validation loss: 2.569306921796157

Epoch: 5| Step: 10
Training loss: 0.5116119855786113
Validation loss: 2.558860256803412

Epoch: 385| Step: 0
Training loss: 0.6110655491875647
Validation loss: 2.5774172888271663

Epoch: 5| Step: 1
Training loss: 0.47470364988276725
Validation loss: 2.534316919879505

Epoch: 5| Step: 2
Training loss: 0.39760236543655986
Validation loss: 2.576108983645539

Epoch: 5| Step: 3
Training loss: 0.38089294285665004
Validation loss: 2.5476435016418613

Epoch: 5| Step: 4
Training loss: 0.2652337053203415
Validation loss: 2.5954608268812702

Epoch: 5| Step: 5
Training loss: 0.4577606445212395
Validation loss: 2.5722434001757954

Epoch: 5| Step: 6
Training loss: 0.4071435088944776
Validation loss: 2.6054135780859773

Epoch: 5| Step: 7
Training loss: 0.3420107798857288
Validation loss: 2.5882809986558004

Epoch: 5| Step: 8
Training loss: 0.33835378226055657
Validation loss: 2.6073619054442663

Epoch: 5| Step: 9
Training loss: 0.44044423555085194
Validation loss: 2.5794697575312906

Epoch: 5| Step: 10
Training loss: 0.3400353954627981
Validation loss: 2.6057062460366325

Epoch: 386| Step: 0
Training loss: 0.21856566734789704
Validation loss: 2.6208929208656997

Epoch: 5| Step: 1
Training loss: 0.21342699918705416
Validation loss: 2.5874571982314296

Epoch: 5| Step: 2
Training loss: 0.27343150541001554
Validation loss: 2.6318716726613425

Epoch: 5| Step: 3
Training loss: 0.36964063739175934
Validation loss: 2.6173472072143817

Epoch: 5| Step: 4
Training loss: 0.4879469986317567
Validation loss: 2.6240865076980002

Epoch: 5| Step: 5
Training loss: 0.30421619153624563
Validation loss: 2.649244049113362

Epoch: 5| Step: 6
Training loss: 0.5310429001089592
Validation loss: 2.627327157488499

Epoch: 5| Step: 7
Training loss: 0.6376797263795048
Validation loss: 2.59095611017854

Epoch: 5| Step: 8
Training loss: 0.19892290063644114
Validation loss: 2.614882998437858

Epoch: 5| Step: 9
Training loss: 0.5697341756276053
Validation loss: 2.596115897380747

Epoch: 5| Step: 10
Training loss: 0.34589978459600473
Validation loss: 2.5623898776382994

Epoch: 387| Step: 0
Training loss: 0.4370489179240169
Validation loss: 2.574437303885201

Epoch: 5| Step: 1
Training loss: 0.4982344031239855
Validation loss: 2.604735587374281

Epoch: 5| Step: 2
Training loss: 0.23385169895940303
Validation loss: 2.610377694232436

Epoch: 5| Step: 3
Training loss: 0.5068976745049419
Validation loss: 2.5762363415727125

Epoch: 5| Step: 4
Training loss: 0.31562880381567643
Validation loss: 2.5734023765424783

Epoch: 5| Step: 5
Training loss: 0.3532392359252444
Validation loss: 2.6054475872028178

Epoch: 5| Step: 6
Training loss: 0.24417834181316372
Validation loss: 2.595593610319781

Epoch: 5| Step: 7
Training loss: 0.5463892823296372
Validation loss: 2.6004842075389103

Epoch: 5| Step: 8
Training loss: 0.35713561638235924
Validation loss: 2.6173559461251013

Epoch: 5| Step: 9
Training loss: 0.37225039071676785
Validation loss: 2.6310961303352127

Epoch: 5| Step: 10
Training loss: 0.3600135810263901
Validation loss: 2.5856322655578974

Epoch: 388| Step: 0
Training loss: 0.45685622947740107
Validation loss: 2.596180307645928

Epoch: 5| Step: 1
Training loss: 0.4027037815199207
Validation loss: 2.5888305349042215

Epoch: 5| Step: 2
Training loss: 0.3278060111866416
Validation loss: 2.5691663925492563

Epoch: 5| Step: 3
Training loss: 0.48444939626517713
Validation loss: 2.6142479001919843

Epoch: 5| Step: 4
Training loss: 0.4515144896806679
Validation loss: 2.600329526385357

Epoch: 5| Step: 5
Training loss: 0.35806262839593517
Validation loss: 2.617822236407501

Epoch: 5| Step: 6
Training loss: 0.4173725724916563
Validation loss: 2.5836197386356843

Epoch: 5| Step: 7
Training loss: 0.2605364841751232
Validation loss: 2.600797864602939

Epoch: 5| Step: 8
Training loss: 0.41851870283768555
Validation loss: 2.5899286843493066

Epoch: 5| Step: 9
Training loss: 0.4787451680091457
Validation loss: 2.603227834159048

Epoch: 5| Step: 10
Training loss: 0.26699764745636684
Validation loss: 2.597794411089423

Epoch: 389| Step: 0
Training loss: 0.45459499007937193
Validation loss: 2.6141660241494993

Epoch: 5| Step: 1
Training loss: 0.3986833786094332
Validation loss: 2.6519494071114154

Epoch: 5| Step: 2
Training loss: 0.3782515227444109
Validation loss: 2.633351410533353

Epoch: 5| Step: 3
Training loss: 0.44738602995725174
Validation loss: 2.6749060444762365

Epoch: 5| Step: 4
Training loss: 0.24692681257765067
Validation loss: 2.6458817257055673

Epoch: 5| Step: 5
Training loss: 0.38532363782689066
Validation loss: 2.6571186959100843

Epoch: 5| Step: 6
Training loss: 0.5907221184461797
Validation loss: 2.627957179918392

Epoch: 5| Step: 7
Training loss: 0.4911580749339955
Validation loss: 2.591524628107971

Epoch: 5| Step: 8
Training loss: 0.500121399923466
Validation loss: 2.556937691928451

Epoch: 5| Step: 9
Training loss: 0.37208711280839774
Validation loss: 2.5868794029148483

Epoch: 5| Step: 10
Training loss: 0.32337991367687047
Validation loss: 2.549561107328073

Epoch: 390| Step: 0
Training loss: 0.5250782374714074
Validation loss: 2.5716676670056273

Epoch: 5| Step: 1
Training loss: 0.5172642457843111
Validation loss: 2.602483506850573

Epoch: 5| Step: 2
Training loss: 0.37827661643012844
Validation loss: 2.64929755202092

Epoch: 5| Step: 3
Training loss: 0.33364315337169603
Validation loss: 2.640408613796684

Epoch: 5| Step: 4
Training loss: 0.2562257313284932
Validation loss: 2.6998962100204564

Epoch: 5| Step: 5
Training loss: 0.3425966333937595
Validation loss: 2.6691463872241172

Epoch: 5| Step: 6
Training loss: 0.7073179053794162
Validation loss: 2.6499974687083983

Epoch: 5| Step: 7
Training loss: 0.300725485846669
Validation loss: 2.5980124786377123

Epoch: 5| Step: 8
Training loss: 0.44096316827238474
Validation loss: 2.546260722166544

Epoch: 5| Step: 9
Training loss: 0.4004412363210586
Validation loss: 2.5429640440493038

Epoch: 5| Step: 10
Training loss: 0.40512920708665506
Validation loss: 2.5134660346342264

Epoch: 391| Step: 0
Training loss: 0.3938772049045862
Validation loss: 2.5333901132487697

Epoch: 5| Step: 1
Training loss: 0.4465578968192584
Validation loss: 2.5321359019703724

Epoch: 5| Step: 2
Training loss: 0.40448307043656434
Validation loss: 2.567805400813221

Epoch: 5| Step: 3
Training loss: 0.26141650269279976
Validation loss: 2.586650948617323

Epoch: 5| Step: 4
Training loss: 0.5357081219908939
Validation loss: 2.691424732795782

Epoch: 5| Step: 5
Training loss: 0.5055330615867466
Validation loss: 2.7027135466265513

Epoch: 5| Step: 6
Training loss: 0.30687789484433925
Validation loss: 2.699087463712615

Epoch: 5| Step: 7
Training loss: 0.7749650685836568
Validation loss: 2.6415825806716815

Epoch: 5| Step: 8
Training loss: 0.5275901501354323
Validation loss: 2.582377457061167

Epoch: 5| Step: 9
Training loss: 0.3818702974982033
Validation loss: 2.5642321215161807

Epoch: 5| Step: 10
Training loss: 0.26887900449962077
Validation loss: 2.5522859219639655

Epoch: 392| Step: 0
Training loss: 0.6064009596474208
Validation loss: 2.541120924138589

Epoch: 5| Step: 1
Training loss: 0.45905491712940955
Validation loss: 2.5323611810402116

Epoch: 5| Step: 2
Training loss: 0.5285346254033355
Validation loss: 2.535916471031148

Epoch: 5| Step: 3
Training loss: 0.33650213297016296
Validation loss: 2.5025354930639065

Epoch: 5| Step: 4
Training loss: 0.42338662070585986
Validation loss: 2.5500350760529296

Epoch: 5| Step: 5
Training loss: 0.4708729038095665
Validation loss: 2.5888199875193445

Epoch: 5| Step: 6
Training loss: 0.3940205809935059
Validation loss: 2.620316330676174

Epoch: 5| Step: 7
Training loss: 0.46042928318786863
Validation loss: 2.6032521968399016

Epoch: 5| Step: 8
Training loss: 0.29304713154361794
Validation loss: 2.577635103070224

Epoch: 5| Step: 9
Training loss: 0.47809185025354906
Validation loss: 2.558107661483402

Epoch: 5| Step: 10
Training loss: 0.6242858382781717
Validation loss: 2.584655145357161

Epoch: 393| Step: 0
Training loss: 0.5477814655032591
Validation loss: 2.589963865479048

Epoch: 5| Step: 1
Training loss: 0.5361794484462518
Validation loss: 2.6228376653957235

Epoch: 5| Step: 2
Training loss: 0.5496391738372306
Validation loss: 2.6411706368354553

Epoch: 5| Step: 3
Training loss: 0.2808755129871853
Validation loss: 2.643491967351265

Epoch: 5| Step: 4
Training loss: 0.46835358069671823
Validation loss: 2.647015861000655

Epoch: 5| Step: 5
Training loss: 0.4271099462203551
Validation loss: 2.6342349577723168

Epoch: 5| Step: 6
Training loss: 0.5528509603419057
Validation loss: 2.631339775862822

Epoch: 5| Step: 7
Training loss: 0.2655272163595642
Validation loss: 2.585983830132263

Epoch: 5| Step: 8
Training loss: 0.2787524031420043
Validation loss: 2.6096988344644143

Epoch: 5| Step: 9
Training loss: 0.3244426597562641
Validation loss: 2.6006750911332435

Epoch: 5| Step: 10
Training loss: 0.3754316865214686
Validation loss: 2.587769895164884

Epoch: 394| Step: 0
Training loss: 0.38476380478481653
Validation loss: 2.6135878591905786

Epoch: 5| Step: 1
Training loss: 0.5817693082492912
Validation loss: 2.573521605274965

Epoch: 5| Step: 2
Training loss: 0.3515922004022034
Validation loss: 2.587541322327146

Epoch: 5| Step: 3
Training loss: 0.3620168359856325
Validation loss: 2.5614018431969865

Epoch: 5| Step: 4
Training loss: 0.38805188517737427
Validation loss: 2.523219614347612

Epoch: 5| Step: 5
Training loss: 0.43803631743445715
Validation loss: 2.5272062586645574

Epoch: 5| Step: 6
Training loss: 0.32314757838214664
Validation loss: 2.538282208440661

Epoch: 5| Step: 7
Training loss: 0.45098468480781667
Validation loss: 2.5663764999212897

Epoch: 5| Step: 8
Training loss: 0.45505764305290175
Validation loss: 2.536771647594499

Epoch: 5| Step: 9
Training loss: 0.37730734987205233
Validation loss: 2.5802035596723236

Epoch: 5| Step: 10
Training loss: 0.42670255255225115
Validation loss: 2.5634099513715087

Epoch: 395| Step: 0
Training loss: 0.36777186056600236
Validation loss: 2.5887494483644886

Epoch: 5| Step: 1
Training loss: 0.45604615948890465
Validation loss: 2.567533188583903

Epoch: 5| Step: 2
Training loss: 0.4195048901110357
Validation loss: 2.5826151259987924

Epoch: 5| Step: 3
Training loss: 0.45626385158258054
Validation loss: 2.535674679808491

Epoch: 5| Step: 4
Training loss: 0.46428701576113374
Validation loss: 2.5224862387891474

Epoch: 5| Step: 5
Training loss: 0.387070890451805
Validation loss: 2.572297130809771

Epoch: 5| Step: 6
Training loss: 0.45509858965394295
Validation loss: 2.5501985117166823

Epoch: 5| Step: 7
Training loss: 0.4430734157533287
Validation loss: 2.5292586709150764

Epoch: 5| Step: 8
Training loss: 0.42687740439747357
Validation loss: 2.5291588015840425

Epoch: 5| Step: 9
Training loss: 0.5696378139856858
Validation loss: 2.537644186004538

Epoch: 5| Step: 10
Training loss: 0.4318629939153557
Validation loss: 2.5437883226089406

Epoch: 396| Step: 0
Training loss: 0.5058020481927927
Validation loss: 2.5651154795167597

Epoch: 5| Step: 1
Training loss: 0.35726579270316167
Validation loss: 2.610290644731118

Epoch: 5| Step: 2
Training loss: 0.33345673805017917
Validation loss: 2.585085216928184

Epoch: 5| Step: 3
Training loss: 0.4309616271879728
Validation loss: 2.5859323369000573

Epoch: 5| Step: 4
Training loss: 0.34468108571535305
Validation loss: 2.5735764229067954

Epoch: 5| Step: 5
Training loss: 0.23349428802391897
Validation loss: 2.596871180472507

Epoch: 5| Step: 6
Training loss: 0.43067080953074766
Validation loss: 2.6124850435648708

Epoch: 5| Step: 7
Training loss: 0.5374276068085515
Validation loss: 2.6176426880582864

Epoch: 5| Step: 8
Training loss: 0.33263554278814234
Validation loss: 2.587984491380697

Epoch: 5| Step: 9
Training loss: 0.3730137196132119
Validation loss: 2.598581512205374

Epoch: 5| Step: 10
Training loss: 0.6105047903365042
Validation loss: 2.6277325281329724

Epoch: 397| Step: 0
Training loss: 0.42178391426976364
Validation loss: 2.618681895936094

Epoch: 5| Step: 1
Training loss: 0.3402172425924239
Validation loss: 2.6418147971160955

Epoch: 5| Step: 2
Training loss: 0.4474614809816374
Validation loss: 2.618732153417387

Epoch: 5| Step: 3
Training loss: 0.4758176141381625
Validation loss: 2.6126900700477638

Epoch: 5| Step: 4
Training loss: 0.48066679431769854
Validation loss: 2.662737840767921

Epoch: 5| Step: 5
Training loss: 0.3328064564259145
Validation loss: 2.649010466122703

Epoch: 5| Step: 6
Training loss: 0.5551541742768632
Validation loss: 2.7002286087294807

Epoch: 5| Step: 7
Training loss: 0.3730413226767964
Validation loss: 2.7001714475760505

Epoch: 5| Step: 8
Training loss: 0.3948805744976775
Validation loss: 2.7075441755239193

Epoch: 5| Step: 9
Training loss: 0.3866145831757366
Validation loss: 2.6815107506062708

Epoch: 5| Step: 10
Training loss: 0.48809537783038126
Validation loss: 2.6513683052508585

Epoch: 398| Step: 0
Training loss: 0.4325606091704241
Validation loss: 2.6189921289742837

Epoch: 5| Step: 1
Training loss: 0.43898885998570764
Validation loss: 2.5633257384106174

Epoch: 5| Step: 2
Training loss: 0.45957256532206875
Validation loss: 2.553689596250537

Epoch: 5| Step: 3
Training loss: 0.39156940737246543
Validation loss: 2.517934196019511

Epoch: 5| Step: 4
Training loss: 0.5177274668462771
Validation loss: 2.557325080533156

Epoch: 5| Step: 5
Training loss: 0.39201895903214473
Validation loss: 2.59205906597211

Epoch: 5| Step: 6
Training loss: 0.6619949241901703
Validation loss: 2.6455655926987713

Epoch: 5| Step: 7
Training loss: 0.21326198036701147
Validation loss: 2.6343709922170992

Epoch: 5| Step: 8
Training loss: 0.3270203980359953
Validation loss: 2.650013452249267

Epoch: 5| Step: 9
Training loss: 0.4101390835030652
Validation loss: 2.657622371888257

Epoch: 5| Step: 10
Training loss: 0.48851244221560547
Validation loss: 2.660996978505251

Epoch: 399| Step: 0
Training loss: 0.28493160387044114
Validation loss: 2.6518962506220602

Epoch: 5| Step: 1
Training loss: 0.4762109491653197
Validation loss: 2.5648449488770875

Epoch: 5| Step: 2
Training loss: 0.3883451305624867
Validation loss: 2.5801589644013103

Epoch: 5| Step: 3
Training loss: 0.3109511377228826
Validation loss: 2.5505519555904135

Epoch: 5| Step: 4
Training loss: 0.3259417927313936
Validation loss: 2.56856671048584

Epoch: 5| Step: 5
Training loss: 0.5341115904646231
Validation loss: 2.524148290108444

Epoch: 5| Step: 6
Training loss: 0.3322877454177541
Validation loss: 2.6093715986760566

Epoch: 5| Step: 7
Training loss: 0.5166313869470092
Validation loss: 2.5974372691900562

Epoch: 5| Step: 8
Training loss: 0.5237178336487777
Validation loss: 2.6193626233684393

Epoch: 5| Step: 9
Training loss: 0.34490861489198144
Validation loss: 2.657943109741078

Epoch: 5| Step: 10
Training loss: 0.4785033711012714
Validation loss: 2.6801029829032683

Epoch: 400| Step: 0
Training loss: 0.46535654393705345
Validation loss: 2.6263120763931447

Epoch: 5| Step: 1
Training loss: 0.37689570251463134
Validation loss: 2.650902258972535

Epoch: 5| Step: 2
Training loss: 0.33335162897365683
Validation loss: 2.5999914922882676

Epoch: 5| Step: 3
Training loss: 0.38860606110769447
Validation loss: 2.6336802535112405

Epoch: 5| Step: 4
Training loss: 0.43021152793800393
Validation loss: 2.6190045492777707

Epoch: 5| Step: 5
Training loss: 0.35818993014761136
Validation loss: 2.6055826481190754

Epoch: 5| Step: 6
Training loss: 0.45253684249550724
Validation loss: 2.5845835899082616

Epoch: 5| Step: 7
Training loss: 0.43779889182943393
Validation loss: 2.557939530601897

Epoch: 5| Step: 8
Training loss: 0.4052173621668069
Validation loss: 2.588311306176728

Epoch: 5| Step: 9
Training loss: 0.3916105045810218
Validation loss: 2.6024428603812715

Epoch: 5| Step: 10
Training loss: 0.3434940382191613
Validation loss: 2.5843348657262006

Epoch: 401| Step: 0
Training loss: 0.2964918902101831
Validation loss: 2.601002028338338

Epoch: 5| Step: 1
Training loss: 0.3879111431492067
Validation loss: 2.6087684331615004

Epoch: 5| Step: 2
Training loss: 0.29611846246986595
Validation loss: 2.6406927214761926

Epoch: 5| Step: 3
Training loss: 0.5214425973909399
Validation loss: 2.6672276962942942

Epoch: 5| Step: 4
Training loss: 0.4681703162064065
Validation loss: 2.6753252635358082

Epoch: 5| Step: 5
Training loss: 0.4096316843252842
Validation loss: 2.67336557219063

Epoch: 5| Step: 6
Training loss: 0.23453615529104313
Validation loss: 2.6652387159308875

Epoch: 5| Step: 7
Training loss: 0.28651508144891497
Validation loss: 2.6582107150230527

Epoch: 5| Step: 8
Training loss: 0.5258754209440127
Validation loss: 2.6454525409434133

Epoch: 5| Step: 9
Training loss: 0.40581503837963057
Validation loss: 2.6205590703166766

Epoch: 5| Step: 10
Training loss: 0.42118140884729494
Validation loss: 2.6262150207051174

Epoch: 402| Step: 0
Training loss: 0.4257690357941136
Validation loss: 2.6053264522669544

Epoch: 5| Step: 1
Training loss: 0.5691996651779176
Validation loss: 2.5689622524319793

Epoch: 5| Step: 2
Training loss: 0.26742368264552735
Validation loss: 2.607574228614455

Epoch: 5| Step: 3
Training loss: 0.3882566179410309
Validation loss: 2.5968049560347133

Epoch: 5| Step: 4
Training loss: 0.3690529370986831
Validation loss: 2.5782194839322212

Epoch: 5| Step: 5
Training loss: 0.44295167032244026
Validation loss: 2.6155118683765313

Epoch: 5| Step: 6
Training loss: 0.4136410493685341
Validation loss: 2.625418751214224

Epoch: 5| Step: 7
Training loss: 0.43373839225407923
Validation loss: 2.667356815809485

Epoch: 5| Step: 8
Training loss: 0.39837696513160187
Validation loss: 2.6707110352027446

Epoch: 5| Step: 9
Training loss: 0.37665848755114506
Validation loss: 2.69356060307767

Epoch: 5| Step: 10
Training loss: 0.3417124289689815
Validation loss: 2.6625845101579704

Epoch: 403| Step: 0
Training loss: 0.3556683996230442
Validation loss: 2.6467572950926894

Epoch: 5| Step: 1
Training loss: 0.39562815024641845
Validation loss: 2.635989704224571

Epoch: 5| Step: 2
Training loss: 0.4949904812032441
Validation loss: 2.6391617158081853

Epoch: 5| Step: 3
Training loss: 0.5115679453173733
Validation loss: 2.628638876888972

Epoch: 5| Step: 4
Training loss: 0.3052933367334725
Validation loss: 2.562083228189194

Epoch: 5| Step: 5
Training loss: 0.2721842382829045
Validation loss: 2.546457562063666

Epoch: 5| Step: 6
Training loss: 0.39669039029549524
Validation loss: 2.561609450091112

Epoch: 5| Step: 7
Training loss: 0.3512057719775185
Validation loss: 2.585239733754801

Epoch: 5| Step: 8
Training loss: 0.5070392884262342
Validation loss: 2.5935715323491486

Epoch: 5| Step: 9
Training loss: 0.40514252168263726
Validation loss: 2.5991717940628183

Epoch: 5| Step: 10
Training loss: 0.4005364129352107
Validation loss: 2.5907380176676322

Epoch: 404| Step: 0
Training loss: 0.5973073402142809
Validation loss: 2.622346045258953

Epoch: 5| Step: 1
Training loss: 0.28696435392797587
Validation loss: 2.625015315388634

Epoch: 5| Step: 2
Training loss: 0.4828593783783333
Validation loss: 2.6094756809141506

Epoch: 5| Step: 3
Training loss: 0.24253312183341502
Validation loss: 2.628829590465755

Epoch: 5| Step: 4
Training loss: 0.31883450023855014
Validation loss: 2.606136775523677

Epoch: 5| Step: 5
Training loss: 0.28782964394420574
Validation loss: 2.6321843779696406

Epoch: 5| Step: 6
Training loss: 0.3772737197181354
Validation loss: 2.622812827800358

Epoch: 5| Step: 7
Training loss: 0.48063244395946386
Validation loss: 2.571679510893795

Epoch: 5| Step: 8
Training loss: 0.2982449044913871
Validation loss: 2.5517839254038694

Epoch: 5| Step: 9
Training loss: 0.3753976501696658
Validation loss: 2.5291620857551513

Epoch: 5| Step: 10
Training loss: 0.38761760788148664
Validation loss: 2.5303226029439454

Epoch: 405| Step: 0
Training loss: 0.3932708208704125
Validation loss: 2.561268565342853

Epoch: 5| Step: 1
Training loss: 0.43821683128060385
Validation loss: 2.560262196648729

Epoch: 5| Step: 2
Training loss: 0.37695901500468376
Validation loss: 2.5549353024369994

Epoch: 5| Step: 3
Training loss: 0.31636075293189575
Validation loss: 2.5536542638606927

Epoch: 5| Step: 4
Training loss: 0.38292398581014686
Validation loss: 2.6143869465911163

Epoch: 5| Step: 5
Training loss: 0.47958846980453296
Validation loss: 2.6147027999345243

Epoch: 5| Step: 6
Training loss: 0.34221662632556105
Validation loss: 2.5875014447931504

Epoch: 5| Step: 7
Training loss: 0.2769064746946614
Validation loss: 2.604765761507788

Epoch: 5| Step: 8
Training loss: 0.3142058780638144
Validation loss: 2.6367142463745887

Epoch: 5| Step: 9
Training loss: 0.3678037868948885
Validation loss: 2.594279230681983

Epoch: 5| Step: 10
Training loss: 0.2702454627156377
Validation loss: 2.585944752908698

Epoch: 406| Step: 0
Training loss: 0.418879506026859
Validation loss: 2.574356729454926

Epoch: 5| Step: 1
Training loss: 0.29244803884112464
Validation loss: 2.5798508422113087

Epoch: 5| Step: 2
Training loss: 0.3866490195244286
Validation loss: 2.5985722938297044

Epoch: 5| Step: 3
Training loss: 0.34920030242190203
Validation loss: 2.5607154749196295

Epoch: 5| Step: 4
Training loss: 0.44034854792795897
Validation loss: 2.575407369957787

Epoch: 5| Step: 5
Training loss: 0.2115707781255406
Validation loss: 2.5825482967566646

Epoch: 5| Step: 6
Training loss: 0.4341710345889938
Validation loss: 2.58337297882187

Epoch: 5| Step: 7
Training loss: 0.438146386161962
Validation loss: 2.5907736725517285

Epoch: 5| Step: 8
Training loss: 0.40791995434252815
Validation loss: 2.620121257828156

Epoch: 5| Step: 9
Training loss: 0.38623131753126555
Validation loss: 2.623281634266777

Epoch: 5| Step: 10
Training loss: 0.2645467302329765
Validation loss: 2.6238367562075853

Epoch: 407| Step: 0
Training loss: 0.2332105319126407
Validation loss: 2.63920934235773

Epoch: 5| Step: 1
Training loss: 0.37784743091537215
Validation loss: 2.650594527130212

Epoch: 5| Step: 2
Training loss: 0.37054434813848924
Validation loss: 2.624092414910133

Epoch: 5| Step: 3
Training loss: 0.3235782593427454
Validation loss: 2.6282340840020133

Epoch: 5| Step: 4
Training loss: 0.5224551191629878
Validation loss: 2.601356443742689

Epoch: 5| Step: 5
Training loss: 0.5465665492348928
Validation loss: 2.584495285267815

Epoch: 5| Step: 6
Training loss: 0.1948930623502986
Validation loss: 2.608306827257816

Epoch: 5| Step: 7
Training loss: 0.3382427167199961
Validation loss: 2.5838382107181745

Epoch: 5| Step: 8
Training loss: 0.4881725953326982
Validation loss: 2.5879551250695454

Epoch: 5| Step: 9
Training loss: 0.2685852172144187
Validation loss: 2.6112077493383814

Epoch: 5| Step: 10
Training loss: 0.23726333446232345
Validation loss: 2.6211384635458783

Epoch: 408| Step: 0
Training loss: 0.4729685894222636
Validation loss: 2.628157463388764

Epoch: 5| Step: 1
Training loss: 0.29760036194135847
Validation loss: 2.654318465422018

Epoch: 5| Step: 2
Training loss: 0.3041289908229197
Validation loss: 2.645989862420256

Epoch: 5| Step: 3
Training loss: 0.4854350181379608
Validation loss: 2.642557847294055

Epoch: 5| Step: 4
Training loss: 0.3614586671649956
Validation loss: 2.635845940384663

Epoch: 5| Step: 5
Training loss: 0.31164852010882615
Validation loss: 2.59878340063829

Epoch: 5| Step: 6
Training loss: 0.21658761862751957
Validation loss: 2.5905189057909443

Epoch: 5| Step: 7
Training loss: 0.4214300175386838
Validation loss: 2.591360527234542

Epoch: 5| Step: 8
Training loss: 0.37196480764539874
Validation loss: 2.5934421007159436

Epoch: 5| Step: 9
Training loss: 0.333216649236052
Validation loss: 2.5711408284594226

Epoch: 5| Step: 10
Training loss: 0.38451917859551726
Validation loss: 2.588071869168366

Epoch: 409| Step: 0
Training loss: 0.3394313699930517
Validation loss: 2.6132317254811444

Epoch: 5| Step: 1
Training loss: 0.34671094511718853
Validation loss: 2.594049317116566

Epoch: 5| Step: 2
Training loss: 0.22703141981041078
Validation loss: 2.6299561933542597

Epoch: 5| Step: 3
Training loss: 0.23043077770285011
Validation loss: 2.6301363878005923

Epoch: 5| Step: 4
Training loss: 0.5280583096894539
Validation loss: 2.615964069908339

Epoch: 5| Step: 5
Training loss: 0.5615355913256701
Validation loss: 2.671471175274094

Epoch: 5| Step: 6
Training loss: 0.4809736839548468
Validation loss: 2.639618351329786

Epoch: 5| Step: 7
Training loss: 0.24269751714309543
Validation loss: 2.656022206237935

Epoch: 5| Step: 8
Training loss: 0.2113655920890249
Validation loss: 2.6937434102720537

Epoch: 5| Step: 9
Training loss: 0.32760739372899866
Validation loss: 2.642929387163287

Epoch: 5| Step: 10
Training loss: 0.33516112148416993
Validation loss: 2.6246882779485303

Epoch: 410| Step: 0
Training loss: 0.29439703870996314
Validation loss: 2.6386110077082128

Epoch: 5| Step: 1
Training loss: 0.3595706365729948
Validation loss: 2.6160257992800187

Epoch: 5| Step: 2
Training loss: 0.32002323161300317
Validation loss: 2.6438881898404754

Epoch: 5| Step: 3
Training loss: 0.43685743282946116
Validation loss: 2.6402567042141474

Epoch: 5| Step: 4
Training loss: 0.25009996680488655
Validation loss: 2.606483220279902

Epoch: 5| Step: 5
Training loss: 0.4765808383352507
Validation loss: 2.5959137264366317

Epoch: 5| Step: 6
Training loss: 0.32028260905662037
Validation loss: 2.5876637549705226

Epoch: 5| Step: 7
Training loss: 0.33026367254276096
Validation loss: 2.582487424982591

Epoch: 5| Step: 8
Training loss: 0.27392578125
Validation loss: 2.5914694976535158

Epoch: 5| Step: 9
Training loss: 0.4720196495916258
Validation loss: 2.580624673394174

Epoch: 5| Step: 10
Training loss: 0.3852025567125874
Validation loss: 2.601453352211543

Epoch: 411| Step: 0
Training loss: 0.451393403332298
Validation loss: 2.5916517685843585

Epoch: 5| Step: 1
Training loss: 0.3736046022173561
Validation loss: 2.610715925220124

Epoch: 5| Step: 2
Training loss: 0.501569608834059
Validation loss: 2.6305551809308403

Epoch: 5| Step: 3
Training loss: 0.2808146153252961
Validation loss: 2.637045634131564

Epoch: 5| Step: 4
Training loss: 0.3364964426187035
Validation loss: 2.6413774810766646

Epoch: 5| Step: 5
Training loss: 0.26642299442862605
Validation loss: 2.6331641341318144

Epoch: 5| Step: 6
Training loss: 0.3446286524412021
Validation loss: 2.6475331407399514

Epoch: 5| Step: 7
Training loss: 0.33919454367855584
Validation loss: 2.6151199139935963

Epoch: 5| Step: 8
Training loss: 0.2682423387768409
Validation loss: 2.588341102267001

Epoch: 5| Step: 9
Training loss: 0.4813121588309109
Validation loss: 2.5660077419308562

Epoch: 5| Step: 10
Training loss: 0.2312394929122685
Validation loss: 2.5932522654587715

Epoch: 412| Step: 0
Training loss: 0.2206895199523632
Validation loss: 2.5491767546491384

Epoch: 5| Step: 1
Training loss: 0.5075040026915604
Validation loss: 2.5728882915129

Epoch: 5| Step: 2
Training loss: 0.3357849107225906
Validation loss: 2.563778262556135

Epoch: 5| Step: 3
Training loss: 0.38474401422991406
Validation loss: 2.6047233632961206

Epoch: 5| Step: 4
Training loss: 0.3896827587031974
Validation loss: 2.6060663204526775

Epoch: 5| Step: 5
Training loss: 0.3188356219090071
Validation loss: 2.627905265812394

Epoch: 5| Step: 6
Training loss: 0.2952981279297035
Validation loss: 2.6350839263681927

Epoch: 5| Step: 7
Training loss: 0.3258520374189913
Validation loss: 2.66438703683615

Epoch: 5| Step: 8
Training loss: 0.2978903072984764
Validation loss: 2.6420643745004506

Epoch: 5| Step: 9
Training loss: 0.4042781512213994
Validation loss: 2.7002405124828646

Epoch: 5| Step: 10
Training loss: 0.5332194455062944
Validation loss: 2.6820465221180325

Epoch: 413| Step: 0
Training loss: 0.3642155108804899
Validation loss: 2.6670033869757503

Epoch: 5| Step: 1
Training loss: 0.16556735385102944
Validation loss: 2.609978293490219

Epoch: 5| Step: 2
Training loss: 0.4870163976407454
Validation loss: 2.584722422494574

Epoch: 5| Step: 3
Training loss: 0.28175763835555195
Validation loss: 2.5632147493750597

Epoch: 5| Step: 4
Training loss: 0.4481002316885709
Validation loss: 2.5880916703882897

Epoch: 5| Step: 5
Training loss: 0.37342397992547105
Validation loss: 2.5816565962519253

Epoch: 5| Step: 6
Training loss: 0.3561698999201624
Validation loss: 2.553712647121272

Epoch: 5| Step: 7
Training loss: 0.5969542076321687
Validation loss: 2.5746119454408767

Epoch: 5| Step: 8
Training loss: 0.3041180277282709
Validation loss: 2.54285053353733

Epoch: 5| Step: 9
Training loss: 0.3611786816826334
Validation loss: 2.588771540890644

Epoch: 5| Step: 10
Training loss: 0.5148394698802995
Validation loss: 2.6496439119698105

Epoch: 414| Step: 0
Training loss: 0.4365863285374563
Validation loss: 2.6326464704153536

Epoch: 5| Step: 1
Training loss: 0.5547541726029794
Validation loss: 2.698074047993588

Epoch: 5| Step: 2
Training loss: 0.414019312495667
Validation loss: 2.683412160182455

Epoch: 5| Step: 3
Training loss: 0.27014857928283564
Validation loss: 2.641376264952699

Epoch: 5| Step: 4
Training loss: 0.4013534877694463
Validation loss: 2.561324351353236

Epoch: 5| Step: 5
Training loss: 0.36347076640973097
Validation loss: 2.5314099656146403

Epoch: 5| Step: 6
Training loss: 0.35637432070760705
Validation loss: 2.4839108679076674

Epoch: 5| Step: 7
Training loss: 0.533165172302133
Validation loss: 2.448880940432302

Epoch: 5| Step: 8
Training loss: 0.5047647422991818
Validation loss: 2.488027512720082

Epoch: 5| Step: 9
Training loss: 0.3374349023592158
Validation loss: 2.5041829483065032

Epoch: 5| Step: 10
Training loss: 0.5494559284617624
Validation loss: 2.5477928240660024

Epoch: 415| Step: 0
Training loss: 0.22666956575084748
Validation loss: 2.5661781449280485

Epoch: 5| Step: 1
Training loss: 0.4097499651684842
Validation loss: 2.632063712351591

Epoch: 5| Step: 2
Training loss: 0.5274515112516497
Validation loss: 2.6521510686211336

Epoch: 5| Step: 3
Training loss: 0.33964810275411755
Validation loss: 2.668184260671072

Epoch: 5| Step: 4
Training loss: 0.5154431918428852
Validation loss: 2.6598251536907878

Epoch: 5| Step: 5
Training loss: 0.27161357741689285
Validation loss: 2.5966991229509433

Epoch: 5| Step: 6
Training loss: 0.3950582704539444
Validation loss: 2.6160533442803926

Epoch: 5| Step: 7
Training loss: 0.34777999133066434
Validation loss: 2.574132053262823

Epoch: 5| Step: 8
Training loss: 0.39012390421230986
Validation loss: 2.5451631896332154

Epoch: 5| Step: 9
Training loss: 0.41037762435227326
Validation loss: 2.5882687879892146

Epoch: 5| Step: 10
Training loss: 0.271010059993435
Validation loss: 2.6166148862567713

Epoch: 416| Step: 0
Training loss: 0.376252169967173
Validation loss: 2.6003258470387496

Epoch: 5| Step: 1
Training loss: 0.4164423119995354
Validation loss: 2.6073744386674336

Epoch: 5| Step: 2
Training loss: 0.12165633003438987
Validation loss: 2.630647250144512

Epoch: 5| Step: 3
Training loss: 0.39849434241439274
Validation loss: 2.6381526993792184

Epoch: 5| Step: 4
Training loss: 0.4238151864744549
Validation loss: 2.6021155958360245

Epoch: 5| Step: 5
Training loss: 0.48584261946148827
Validation loss: 2.6090565138868813

Epoch: 5| Step: 6
Training loss: 0.3463034401462225
Validation loss: 2.6301021301472685

Epoch: 5| Step: 7
Training loss: 0.23533163342445035
Validation loss: 2.627519338092547

Epoch: 5| Step: 8
Training loss: 0.38888218236241795
Validation loss: 2.6225397052779997

Epoch: 5| Step: 9
Training loss: 0.38441588874369914
Validation loss: 2.622078510637564

Epoch: 5| Step: 10
Training loss: 0.36251980957625624
Validation loss: 2.631684255889227

Epoch: 417| Step: 0
Training loss: 0.2734030838152016
Validation loss: 2.6202245667061743

Epoch: 5| Step: 1
Training loss: 0.28780617788787305
Validation loss: 2.6222063532922615

Epoch: 5| Step: 2
Training loss: 0.4850906499719259
Validation loss: 2.6320264427979225

Epoch: 5| Step: 3
Training loss: 0.40125956333802115
Validation loss: 2.631677539154611

Epoch: 5| Step: 4
Training loss: 0.26627349230502684
Validation loss: 2.615947355002016

Epoch: 5| Step: 5
Training loss: 0.31973378307878875
Validation loss: 2.614940945529395

Epoch: 5| Step: 6
Training loss: 0.3453064059241914
Validation loss: 2.60844791913799

Epoch: 5| Step: 7
Training loss: 0.35667754668430013
Validation loss: 2.603748329934812

Epoch: 5| Step: 8
Training loss: 0.41545097106446394
Validation loss: 2.6116376349751937

Epoch: 5| Step: 9
Training loss: 0.2879037183788793
Validation loss: 2.5920354981178018

Epoch: 5| Step: 10
Training loss: 0.37101294993088646
Validation loss: 2.5980697698691357

Epoch: 418| Step: 0
Training loss: 0.43117848853810464
Validation loss: 2.5958475664559373

Epoch: 5| Step: 1
Training loss: 0.3498801136753891
Validation loss: 2.6025397283961906

Epoch: 5| Step: 2
Training loss: 0.3326703036463203
Validation loss: 2.6026527923408005

Epoch: 5| Step: 3
Training loss: 0.30270448352538604
Validation loss: 2.6013254909279326

Epoch: 5| Step: 4
Training loss: 0.34121853536652713
Validation loss: 2.6039532483336676

Epoch: 5| Step: 5
Training loss: 0.23286507128160502
Validation loss: 2.590349770990955

Epoch: 5| Step: 6
Training loss: 0.4541852976392728
Validation loss: 2.6114944330314573

Epoch: 5| Step: 7
Training loss: 0.3381404063721745
Validation loss: 2.623644909233799

Epoch: 5| Step: 8
Training loss: 0.3601053115007018
Validation loss: 2.633598218427769

Epoch: 5| Step: 9
Training loss: 0.21305444521406053
Validation loss: 2.641488648747703

Epoch: 5| Step: 10
Training loss: 0.35080267069774845
Validation loss: 2.619484738233521

Epoch: 419| Step: 0
Training loss: 0.20715024515363517
Validation loss: 2.626729525337678

Epoch: 5| Step: 1
Training loss: 0.47744004172717097
Validation loss: 2.6502325066269576

Epoch: 5| Step: 2
Training loss: 0.25438225949025417
Validation loss: 2.6563327416906803

Epoch: 5| Step: 3
Training loss: 0.18725265639449196
Validation loss: 2.6792552117020105

Epoch: 5| Step: 4
Training loss: 0.254657543503494
Validation loss: 2.664170672432321

Epoch: 5| Step: 5
Training loss: 0.28091333690602327
Validation loss: 2.673917801076326

Epoch: 5| Step: 6
Training loss: 0.37489583635060797
Validation loss: 2.6761713445251853

Epoch: 5| Step: 7
Training loss: 0.3688557852934247
Validation loss: 2.66197929985118

Epoch: 5| Step: 8
Training loss: 0.5355146280119751
Validation loss: 2.6325813523786548

Epoch: 5| Step: 9
Training loss: 0.18217733521674645
Validation loss: 2.6081753850005263

Epoch: 5| Step: 10
Training loss: 0.3264301100136711
Validation loss: 2.645834195039425

Epoch: 420| Step: 0
Training loss: 0.38022952695679035
Validation loss: 2.640415206374095

Epoch: 5| Step: 1
Training loss: 0.19106017180319881
Validation loss: 2.6202495031939828

Epoch: 5| Step: 2
Training loss: 0.23249644197284636
Validation loss: 2.6066634913208206

Epoch: 5| Step: 3
Training loss: 0.30221418172211634
Validation loss: 2.625526156727055

Epoch: 5| Step: 4
Training loss: 0.40525690987218604
Validation loss: 2.6474888216534285

Epoch: 5| Step: 5
Training loss: 0.3173000990852733
Validation loss: 2.601426578966837

Epoch: 5| Step: 6
Training loss: 0.28392529981627057
Validation loss: 2.645055151782586

Epoch: 5| Step: 7
Training loss: 0.4242862739004249
Validation loss: 2.6413897723412427

Epoch: 5| Step: 8
Training loss: 0.4125974034415831
Validation loss: 2.6552712854213434

Epoch: 5| Step: 9
Training loss: 0.2404117472173956
Validation loss: 2.6615439697138084

Epoch: 5| Step: 10
Training loss: 0.4045908867824626
Validation loss: 2.6332410870858536

Epoch: 421| Step: 0
Training loss: 0.22368184847219388
Validation loss: 2.631174442557887

Epoch: 5| Step: 1
Training loss: 0.28479078466887636
Validation loss: 2.6452188140725577

Epoch: 5| Step: 2
Training loss: 0.25770450989074634
Validation loss: 2.640937532804504

Epoch: 5| Step: 3
Training loss: 0.38948430402369977
Validation loss: 2.627222545156541

Epoch: 5| Step: 4
Training loss: 0.2676421179439433
Validation loss: 2.5993346796018577

Epoch: 5| Step: 5
Training loss: 0.2094526214622014
Validation loss: 2.648931349503742

Epoch: 5| Step: 6
Training loss: 0.2850888316265342
Validation loss: 2.6529860197257307

Epoch: 5| Step: 7
Training loss: 0.41340738329543536
Validation loss: 2.5970512066081675

Epoch: 5| Step: 8
Training loss: 0.523174703873318
Validation loss: 2.6153074473638287

Epoch: 5| Step: 9
Training loss: 0.4037723179013705
Validation loss: 2.6010228665663018

Epoch: 5| Step: 10
Training loss: 0.23233930740008496
Validation loss: 2.6133081882444067

Epoch: 422| Step: 0
Training loss: 0.32155079022320665
Validation loss: 2.5847757052763822

Epoch: 5| Step: 1
Training loss: 0.3863735584971387
Validation loss: 2.624675889913279

Epoch: 5| Step: 2
Training loss: 0.401670429553745
Validation loss: 2.6171395275535625

Epoch: 5| Step: 3
Training loss: 0.36353135472331166
Validation loss: 2.5617121113746237

Epoch: 5| Step: 4
Training loss: 0.2922422939064468
Validation loss: 2.563663853645196

Epoch: 5| Step: 5
Training loss: 0.2652854432057606
Validation loss: 2.5838670850697496

Epoch: 5| Step: 6
Training loss: 0.19804377092566058
Validation loss: 2.611515734325679

Epoch: 5| Step: 7
Training loss: 0.19519327339357734
Validation loss: 2.593862161238703

Epoch: 5| Step: 8
Training loss: 0.3143376914499602
Validation loss: 2.591364582384195

Epoch: 5| Step: 9
Training loss: 0.4060969798130995
Validation loss: 2.6142363178066184

Epoch: 5| Step: 10
Training loss: 0.38532738897387037
Validation loss: 2.5907933205263762

Epoch: 423| Step: 0
Training loss: 0.41971639884475953
Validation loss: 2.634729781190887

Epoch: 5| Step: 1
Training loss: 0.2269974430560949
Validation loss: 2.6692243754588114

Epoch: 5| Step: 2
Training loss: 0.3708936252050793
Validation loss: 2.648941656573291

Epoch: 5| Step: 3
Training loss: 0.14955755586338992
Validation loss: 2.6428059130209167

Epoch: 5| Step: 4
Training loss: 0.388145358523797
Validation loss: 2.635734162682792

Epoch: 5| Step: 5
Training loss: 0.40555656378909566
Validation loss: 2.6526994634761643

Epoch: 5| Step: 6
Training loss: 0.13787508787850963
Validation loss: 2.6273067123105602

Epoch: 5| Step: 7
Training loss: 0.24073851805884225
Validation loss: 2.658696610779098

Epoch: 5| Step: 8
Training loss: 0.42396717163858355
Validation loss: 2.637151773825085

Epoch: 5| Step: 9
Training loss: 0.31211735425162
Validation loss: 2.6445419736150875

Epoch: 5| Step: 10
Training loss: 0.23058884126572243
Validation loss: 2.640301181592913

Epoch: 424| Step: 0
Training loss: 0.33446436962248544
Validation loss: 2.6485987773971695

Epoch: 5| Step: 1
Training loss: 0.3454572805625497
Validation loss: 2.6333814514808638

Epoch: 5| Step: 2
Training loss: 0.3826472645923875
Validation loss: 2.645586150656176

Epoch: 5| Step: 3
Training loss: 0.236477788714363
Validation loss: 2.6273068167176863

Epoch: 5| Step: 4
Training loss: 0.20804873140132127
Validation loss: 2.6447822644463277

Epoch: 5| Step: 5
Training loss: 0.1616940175369678
Validation loss: 2.636240838605168

Epoch: 5| Step: 6
Training loss: 0.2702331250027555
Validation loss: 2.6361125105390397

Epoch: 5| Step: 7
Training loss: 0.35293962119498434
Validation loss: 2.6454497160896966

Epoch: 5| Step: 8
Training loss: 0.2551771780706483
Validation loss: 2.672310847885118

Epoch: 5| Step: 9
Training loss: 0.4356845586773487
Validation loss: 2.611772347323919

Epoch: 5| Step: 10
Training loss: 0.5396842687849142
Validation loss: 2.6121911796387853

Epoch: 425| Step: 0
Training loss: 0.31938775251724266
Validation loss: 2.57114653575579

Epoch: 5| Step: 1
Training loss: 0.4009053155375378
Validation loss: 2.528487003652787

Epoch: 5| Step: 2
Training loss: 0.3365825736170354
Validation loss: 2.5005237502426945

Epoch: 5| Step: 3
Training loss: 0.3721915020155001
Validation loss: 2.5428107737933625

Epoch: 5| Step: 4
Training loss: 0.5141010304768446
Validation loss: 2.5217612103061366

Epoch: 5| Step: 5
Training loss: 0.506417603475811
Validation loss: 2.513916293387493

Epoch: 5| Step: 6
Training loss: 0.3480257149888427
Validation loss: 2.5563709925904106

Epoch: 5| Step: 7
Training loss: 0.36149772581464107
Validation loss: 2.5935154292475633

Epoch: 5| Step: 8
Training loss: 0.3428449854937601
Validation loss: 2.605382993756325

Epoch: 5| Step: 9
Training loss: 0.27106646749536367
Validation loss: 2.691045737707356

Epoch: 5| Step: 10
Training loss: 0.3926999107219885
Validation loss: 2.661605809362479

Epoch: 426| Step: 0
Training loss: 0.37967617426177186
Validation loss: 2.6699489652713693

Epoch: 5| Step: 1
Training loss: 0.362068099022245
Validation loss: 2.663369371250787

Epoch: 5| Step: 2
Training loss: 0.4724176766316417
Validation loss: 2.657679968769448

Epoch: 5| Step: 3
Training loss: 0.4603411485985506
Validation loss: 2.6323467388067

Epoch: 5| Step: 4
Training loss: 0.4185752034110098
Validation loss: 2.6199663353089253

Epoch: 5| Step: 5
Training loss: 0.4038026525574691
Validation loss: 2.59443947851883

Epoch: 5| Step: 6
Training loss: 0.40086773614038684
Validation loss: 2.595758208499608

Epoch: 5| Step: 7
Training loss: 0.23682099957288277
Validation loss: 2.5863251234015343

Epoch: 5| Step: 8
Training loss: 0.26813517315556384
Validation loss: 2.595873108445543

Epoch: 5| Step: 9
Training loss: 0.294600090157721
Validation loss: 2.594596206838964

Epoch: 5| Step: 10
Training loss: 0.4263872855705466
Validation loss: 2.5650754522316865

Epoch: 427| Step: 0
Training loss: 0.22495380198864431
Validation loss: 2.5392960610572515

Epoch: 5| Step: 1
Training loss: 0.44725056585422157
Validation loss: 2.557908255861377

Epoch: 5| Step: 2
Training loss: 0.39888995790663
Validation loss: 2.5395651366032728

Epoch: 5| Step: 3
Training loss: 0.4069644258086779
Validation loss: 2.5172575199442773

Epoch: 5| Step: 4
Training loss: 0.309578543472373
Validation loss: 2.587730250993533

Epoch: 5| Step: 5
Training loss: 0.25777104073289037
Validation loss: 2.5718149994584483

Epoch: 5| Step: 6
Training loss: 0.15039323829262938
Validation loss: 2.628538337969415

Epoch: 5| Step: 7
Training loss: 0.4480279481144466
Validation loss: 2.596258298540007

Epoch: 5| Step: 8
Training loss: 0.3359434770451597
Validation loss: 2.613183278188285

Epoch: 5| Step: 9
Training loss: 0.4424056158862211
Validation loss: 2.613772519320156

Epoch: 5| Step: 10
Training loss: 0.49531855053019025
Validation loss: 2.5852556020129795

Epoch: 428| Step: 0
Training loss: 0.2862361552084557
Validation loss: 2.5826060114429237

Epoch: 5| Step: 1
Training loss: 0.22500977693614582
Validation loss: 2.617687618228707

Epoch: 5| Step: 2
Training loss: 0.25566852527800354
Validation loss: 2.6185148940209766

Epoch: 5| Step: 3
Training loss: 0.3939093607893559
Validation loss: 2.6195186962959203

Epoch: 5| Step: 4
Training loss: 0.32920543717967354
Validation loss: 2.6203102080253884

Epoch: 5| Step: 5
Training loss: 0.21002625624820526
Validation loss: 2.6145780182778573

Epoch: 5| Step: 6
Training loss: 0.47272829815008915
Validation loss: 2.6116486683817772

Epoch: 5| Step: 7
Training loss: 0.3990563093883717
Validation loss: 2.5883757165277634

Epoch: 5| Step: 8
Training loss: 0.347011267899597
Validation loss: 2.588997223629911

Epoch: 5| Step: 9
Training loss: 0.3040503785284227
Validation loss: 2.6029336066737416

Epoch: 5| Step: 10
Training loss: 0.3996546424143172
Validation loss: 2.606019640533602

Epoch: 429| Step: 0
Training loss: 0.31564333267602784
Validation loss: 2.6106942577511645

Epoch: 5| Step: 1
Training loss: 0.25853421600625
Validation loss: 2.61719603472074

Epoch: 5| Step: 2
Training loss: 0.47270000665066275
Validation loss: 2.6007811754401806

Epoch: 5| Step: 3
Training loss: 0.2818851583938334
Validation loss: 2.6113030797560652

Epoch: 5| Step: 4
Training loss: 0.3176897882562631
Validation loss: 2.565863259765331

Epoch: 5| Step: 5
Training loss: 0.3456488313443549
Validation loss: 2.6112635268076

Epoch: 5| Step: 6
Training loss: 0.3260775903811371
Validation loss: 2.6326040946976113

Epoch: 5| Step: 7
Training loss: 0.2968989914686497
Validation loss: 2.6357542015797955

Epoch: 5| Step: 8
Training loss: 0.37316225674181425
Validation loss: 2.631797322407704

Epoch: 5| Step: 9
Training loss: 0.2784203065301054
Validation loss: 2.63011845293275

Epoch: 5| Step: 10
Training loss: 0.2681919769628186
Validation loss: 2.612080693655214

Epoch: 430| Step: 0
Training loss: 0.36428080222881226
Validation loss: 2.6054054667424835

Epoch: 5| Step: 1
Training loss: 0.1713173826548925
Validation loss: 2.591718651923772

Epoch: 5| Step: 2
Training loss: 0.24719098126049427
Validation loss: 2.5664816435580193

Epoch: 5| Step: 3
Training loss: 0.4739327650893865
Validation loss: 2.5727277486021776

Epoch: 5| Step: 4
Training loss: 0.3873733221154989
Validation loss: 2.5899244538511326

Epoch: 5| Step: 5
Training loss: 0.3559288359099124
Validation loss: 2.5914981648052304

Epoch: 5| Step: 6
Training loss: 0.1577824190949835
Validation loss: 2.6261084765639557

Epoch: 5| Step: 7
Training loss: 0.22605066197306203
Validation loss: 2.637114513962607

Epoch: 5| Step: 8
Training loss: 0.26055085380753246
Validation loss: 2.6417077413760786

Epoch: 5| Step: 9
Training loss: 0.3591658356709319
Validation loss: 2.616430827971069

Epoch: 5| Step: 10
Training loss: 0.3849535255744362
Validation loss: 2.610736299512729

Epoch: 431| Step: 0
Training loss: 0.38887858046008716
Validation loss: 2.623647815215093

Epoch: 5| Step: 1
Training loss: 0.30689474376398473
Validation loss: 2.6800310745819216

Epoch: 5| Step: 2
Training loss: 0.2616946365862918
Validation loss: 2.6341925453223665

Epoch: 5| Step: 3
Training loss: 0.27467770655579626
Validation loss: 2.6643676429087675

Epoch: 5| Step: 4
Training loss: 0.49397268947213663
Validation loss: 2.661246364489315

Epoch: 5| Step: 5
Training loss: 0.2016432064590244
Validation loss: 2.655351040541922

Epoch: 5| Step: 6
Training loss: 0.29891909043788417
Validation loss: 2.6373319247557325

Epoch: 5| Step: 7
Training loss: 0.3516152554242237
Validation loss: 2.6539734728467375

Epoch: 5| Step: 8
Training loss: 0.2692704251776331
Validation loss: 2.6483957873780346

Epoch: 5| Step: 9
Training loss: 0.18491001253875744
Validation loss: 2.632180030211427

Epoch: 5| Step: 10
Training loss: 0.2397637758901521
Validation loss: 2.6209635838175087

Epoch: 432| Step: 0
Training loss: 0.2838576809493503
Validation loss: 2.6462609695849784

Epoch: 5| Step: 1
Training loss: 0.22481205130281232
Validation loss: 2.6433402926713625

Epoch: 5| Step: 2
Training loss: 0.20920625833108988
Validation loss: 2.638093146585944

Epoch: 5| Step: 3
Training loss: 0.46920453921815075
Validation loss: 2.6068630938335855

Epoch: 5| Step: 4
Training loss: 0.2551934406580317
Validation loss: 2.6304062752493675

Epoch: 5| Step: 5
Training loss: 0.2182667622847567
Validation loss: 2.628379318560506

Epoch: 5| Step: 6
Training loss: 0.33105420362949173
Validation loss: 2.63293282264426

Epoch: 5| Step: 7
Training loss: 0.40718083845355857
Validation loss: 2.6083004189022874

Epoch: 5| Step: 8
Training loss: 0.19130292361211923
Validation loss: 2.665525958311091

Epoch: 5| Step: 9
Training loss: 0.2852183496450049
Validation loss: 2.6068363456627504

Epoch: 5| Step: 10
Training loss: 0.35901665443850245
Validation loss: 2.6365688817050796

Epoch: 433| Step: 0
Training loss: 0.3448272104276673
Validation loss: 2.623880850463623

Epoch: 5| Step: 1
Training loss: 0.24654506746220983
Validation loss: 2.6199624100477585

Epoch: 5| Step: 2
Training loss: 0.31820827244885436
Validation loss: 2.605337959626877

Epoch: 5| Step: 3
Training loss: 0.3660144736680006
Validation loss: 2.623274173817169

Epoch: 5| Step: 4
Training loss: 0.36272644418808453
Validation loss: 2.622726844955423

Epoch: 5| Step: 5
Training loss: 0.28686845493537927
Validation loss: 2.5824509339890604

Epoch: 5| Step: 6
Training loss: 0.22742141498190227
Validation loss: 2.6216621389666055

Epoch: 5| Step: 7
Training loss: 0.20432190203862471
Validation loss: 2.5912477768914095

Epoch: 5| Step: 8
Training loss: 0.30575240933364956
Validation loss: 2.60746571592042

Epoch: 5| Step: 9
Training loss: 0.40159956616277553
Validation loss: 2.571775917775487

Epoch: 5| Step: 10
Training loss: 0.2102894364530927
Validation loss: 2.6066606834409463

Epoch: 434| Step: 0
Training loss: 0.260316851878339
Validation loss: 2.5927066851934795

Epoch: 5| Step: 1
Training loss: 0.43692395911435705
Validation loss: 2.6151556344586506

Epoch: 5| Step: 2
Training loss: 0.2055536750964835
Validation loss: 2.6222534059543734

Epoch: 5| Step: 3
Training loss: 0.3103676884796672
Validation loss: 2.6058008853956784

Epoch: 5| Step: 4
Training loss: 0.3674838919255859
Validation loss: 2.6291539363911394

Epoch: 5| Step: 5
Training loss: 0.36316923239762877
Validation loss: 2.6319115227456433

Epoch: 5| Step: 6
Training loss: 0.2729308748308133
Validation loss: 2.6510292290014768

Epoch: 5| Step: 7
Training loss: 0.15591226674610428
Validation loss: 2.6434347212912512

Epoch: 5| Step: 8
Training loss: 0.25045071147232
Validation loss: 2.597574553684211

Epoch: 5| Step: 9
Training loss: 0.3394679150799788
Validation loss: 2.633100523405118

Epoch: 5| Step: 10
Training loss: 0.3398111810095557
Validation loss: 2.615317172351032

Epoch: 435| Step: 0
Training loss: 0.3292368262804692
Validation loss: 2.630444490708209

Epoch: 5| Step: 1
Training loss: 0.4450645090879294
Validation loss: 2.59660232139235

Epoch: 5| Step: 2
Training loss: 0.2417351744138469
Validation loss: 2.616972484030321

Epoch: 5| Step: 3
Training loss: 0.3481963708918781
Validation loss: 2.60335655622836

Epoch: 5| Step: 4
Training loss: 0.1986450274077218
Validation loss: 2.6206009662919607

Epoch: 5| Step: 5
Training loss: 0.38136285612363585
Validation loss: 2.619089696049675

Epoch: 5| Step: 6
Training loss: 0.401862847780729
Validation loss: 2.6199151689729225

Epoch: 5| Step: 7
Training loss: 0.2003897583256769
Validation loss: 2.620790681088097

Epoch: 5| Step: 8
Training loss: 0.2589154636537024
Validation loss: 2.6404686017608796

Epoch: 5| Step: 9
Training loss: 0.22329932755632964
Validation loss: 2.6632176768589595

Epoch: 5| Step: 10
Training loss: 0.27531787912524125
Validation loss: 2.6230473128537493

Epoch: 436| Step: 0
Training loss: 0.23736277995562377
Validation loss: 2.624014733495312

Epoch: 5| Step: 1
Training loss: 0.38048180669356596
Validation loss: 2.657975284021413

Epoch: 5| Step: 2
Training loss: 0.3245588609890677
Validation loss: 2.648640975615863

Epoch: 5| Step: 3
Training loss: 0.3643299266621597
Validation loss: 2.630935266986366

Epoch: 5| Step: 4
Training loss: 0.340934963671431
Validation loss: 2.6273483450547848

Epoch: 5| Step: 5
Training loss: 0.20678719044293073
Validation loss: 2.6135905581063783

Epoch: 5| Step: 6
Training loss: 0.32257919084073067
Validation loss: 2.638417946272046

Epoch: 5| Step: 7
Training loss: 0.17355957074178088
Validation loss: 2.6075085414659704

Epoch: 5| Step: 8
Training loss: 0.3551816514510516
Validation loss: 2.6240102285826805

Epoch: 5| Step: 9
Training loss: 0.3591558990981312
Validation loss: 2.558600495270135

Epoch: 5| Step: 10
Training loss: 0.27651730830910004
Validation loss: 2.5900185216913787

Epoch: 437| Step: 0
Training loss: 0.22693471916005692
Validation loss: 2.6000561319228583

Epoch: 5| Step: 1
Training loss: 0.19538920803540077
Validation loss: 2.5672012670759217

Epoch: 5| Step: 2
Training loss: 0.3394463726113979
Validation loss: 2.594701023056316

Epoch: 5| Step: 3
Training loss: 0.3999227628047841
Validation loss: 2.5989874710881806

Epoch: 5| Step: 4
Training loss: 0.19569102800028387
Validation loss: 2.5938424643600593

Epoch: 5| Step: 5
Training loss: 0.29253313103132095
Validation loss: 2.6300148328140374

Epoch: 5| Step: 6
Training loss: 0.24645340085568906
Validation loss: 2.627289889048358

Epoch: 5| Step: 7
Training loss: 0.3746212198654145
Validation loss: 2.6466513032974346

Epoch: 5| Step: 8
Training loss: 0.18322567872101156
Validation loss: 2.650387783162214

Epoch: 5| Step: 9
Training loss: 0.3471297445594583
Validation loss: 2.6370120544036126

Epoch: 5| Step: 10
Training loss: 0.3800700101544817
Validation loss: 2.6088423823661935

Epoch: 438| Step: 0
Training loss: 0.3891072925382769
Validation loss: 2.5952415007989287

Epoch: 5| Step: 1
Training loss: 0.2582175656203441
Validation loss: 2.627250530917382

Epoch: 5| Step: 2
Training loss: 0.24512557665082535
Validation loss: 2.6230049755765195

Epoch: 5| Step: 3
Training loss: 0.1460605657597983
Validation loss: 2.6398452478370023

Epoch: 5| Step: 4
Training loss: 0.22415247346362985
Validation loss: 2.6286993821321927

Epoch: 5| Step: 5
Training loss: 0.20263828139104748
Validation loss: 2.627164975323337

Epoch: 5| Step: 6
Training loss: 0.2879816674798615
Validation loss: 2.6213301394364086

Epoch: 5| Step: 7
Training loss: 0.40260154835128
Validation loss: 2.613033752429746

Epoch: 5| Step: 8
Training loss: 0.3499387436292965
Validation loss: 2.592595714950374

Epoch: 5| Step: 9
Training loss: 0.3273631060574606
Validation loss: 2.5830632513345644

Epoch: 5| Step: 10
Training loss: 0.2494340241882276
Validation loss: 2.604832994593909

Epoch: 439| Step: 0
Training loss: 0.19652542193629166
Validation loss: 2.6162851604023944

Epoch: 5| Step: 1
Training loss: 0.2817307310894274
Validation loss: 2.635643173328996

Epoch: 5| Step: 2
Training loss: 0.33133984552874995
Validation loss: 2.59589770013798

Epoch: 5| Step: 3
Training loss: 0.2781213685130802
Validation loss: 2.6436517170493685

Epoch: 5| Step: 4
Training loss: 0.30160333327322103
Validation loss: 2.623404434479344

Epoch: 5| Step: 5
Training loss: 0.3325887487577235
Validation loss: 2.625206376678023

Epoch: 5| Step: 6
Training loss: 0.18526834362281314
Validation loss: 2.6341190596108217

Epoch: 5| Step: 7
Training loss: 0.1955098299728399
Validation loss: 2.6516744777582213

Epoch: 5| Step: 8
Training loss: 0.3179042464867841
Validation loss: 2.6146464163532075

Epoch: 5| Step: 9
Training loss: 0.3283947675837261
Validation loss: 2.6220432335321564

Epoch: 5| Step: 10
Training loss: 0.34307687050105795
Validation loss: 2.6200926851650346

Epoch: 440| Step: 0
Training loss: 0.2454535391700432
Validation loss: 2.6403779770287628

Epoch: 5| Step: 1
Training loss: 0.2939727998472603
Validation loss: 2.6325182154617472

Epoch: 5| Step: 2
Training loss: 0.16486700671329374
Validation loss: 2.6513157583644724

Epoch: 5| Step: 3
Training loss: 0.13169101237504433
Validation loss: 2.6388105330809584

Epoch: 5| Step: 4
Training loss: 0.47229182168323924
Validation loss: 2.6422650517739608

Epoch: 5| Step: 5
Training loss: 0.33359264802415717
Validation loss: 2.651093261965796

Epoch: 5| Step: 6
Training loss: 0.2295833487750104
Validation loss: 2.6554736668370458

Epoch: 5| Step: 7
Training loss: 0.3316285664732932
Validation loss: 2.610311590499966

Epoch: 5| Step: 8
Training loss: 0.29694148624195826
Validation loss: 2.6332748249133155

Epoch: 5| Step: 9
Training loss: 0.14131632390262272
Validation loss: 2.615271421171316

Epoch: 5| Step: 10
Training loss: 0.3558126400053257
Validation loss: 2.611377784774127

Epoch: 441| Step: 0
Training loss: 0.45622834977293514
Validation loss: 2.5828949734659394

Epoch: 5| Step: 1
Training loss: 0.38174240254509556
Validation loss: 2.609793571671518

Epoch: 5| Step: 2
Training loss: 0.3053323694946001
Validation loss: 2.6121835746516937

Epoch: 5| Step: 3
Training loss: 0.1632475822818829
Validation loss: 2.5909152502139907

Epoch: 5| Step: 4
Training loss: 0.17832130941590726
Validation loss: 2.6026236201028463

Epoch: 5| Step: 5
Training loss: 0.23411219485673068
Validation loss: 2.6145749296445424

Epoch: 5| Step: 6
Training loss: 0.23164618101098763
Validation loss: 2.6237219957957554

Epoch: 5| Step: 7
Training loss: 0.30307545060320396
Validation loss: 2.608854150839141

Epoch: 5| Step: 8
Training loss: 0.19027583436155243
Validation loss: 2.628997792363991

Epoch: 5| Step: 9
Training loss: 0.2569676050853959
Validation loss: 2.6040741754329693

Epoch: 5| Step: 10
Training loss: 0.3408061027297217
Validation loss: 2.626480598127096

Epoch: 442| Step: 0
Training loss: 0.3118812754005423
Validation loss: 2.614456578311515

Epoch: 5| Step: 1
Training loss: 0.13785301808739703
Validation loss: 2.611959202357773

Epoch: 5| Step: 2
Training loss: 0.4479120239490341
Validation loss: 2.6258437345720806

Epoch: 5| Step: 3
Training loss: 0.31702639006851485
Validation loss: 2.6246784587529586

Epoch: 5| Step: 4
Training loss: 0.22534111907294968
Validation loss: 2.628032938177932

Epoch: 5| Step: 5
Training loss: 0.15167985433274103
Validation loss: 2.604412985360737

Epoch: 5| Step: 6
Training loss: 0.36355637827548004
Validation loss: 2.614715307774943

Epoch: 5| Step: 7
Training loss: 0.22267350749011033
Validation loss: 2.6233598572791017

Epoch: 5| Step: 8
Training loss: 0.13996262985045288
Validation loss: 2.6442278065985048

Epoch: 5| Step: 9
Training loss: 0.3066282330578542
Validation loss: 2.6254887435958967

Epoch: 5| Step: 10
Training loss: 0.3453523397118718
Validation loss: 2.6397326352889645

Epoch: 443| Step: 0
Training loss: 0.2522480738994457
Validation loss: 2.6241975701465505

Epoch: 5| Step: 1
Training loss: 0.1627234467798718
Validation loss: 2.624985415041672

Epoch: 5| Step: 2
Training loss: 0.3111978461719045
Validation loss: 2.583667947478637

Epoch: 5| Step: 3
Training loss: 0.20319634798416686
Validation loss: 2.6022418043498097

Epoch: 5| Step: 4
Training loss: 0.33437266839185986
Validation loss: 2.6259879085902598

Epoch: 5| Step: 5
Training loss: 0.3624638621634375
Validation loss: 2.6107439980738407

Epoch: 5| Step: 6
Training loss: 0.3128306070550058
Validation loss: 2.6178673733083677

Epoch: 5| Step: 7
Training loss: 0.27583985178833387
Validation loss: 2.59762161531566

Epoch: 5| Step: 8
Training loss: 0.21078730463504022
Validation loss: 2.5863448829818614

Epoch: 5| Step: 9
Training loss: 0.29805118562673405
Validation loss: 2.5804156556095874

Epoch: 5| Step: 10
Training loss: 0.405201365485343
Validation loss: 2.6311286075758926

Epoch: 444| Step: 0
Training loss: 0.24567257701878045
Validation loss: 2.623154977699307

Epoch: 5| Step: 1
Training loss: 0.22829287015725686
Validation loss: 2.647159196411207

Epoch: 5| Step: 2
Training loss: 0.3029913273268896
Validation loss: 2.6531186683593053

Epoch: 5| Step: 3
Training loss: 0.18857912623194736
Validation loss: 2.6560255811207827

Epoch: 5| Step: 4
Training loss: 0.30362674490645947
Validation loss: 2.6516949651518646

Epoch: 5| Step: 5
Training loss: 0.31033314241513715
Validation loss: 2.6463676919435755

Epoch: 5| Step: 6
Training loss: 0.43707885226536697
Validation loss: 2.599502654108641

Epoch: 5| Step: 7
Training loss: 0.28272791488025917
Validation loss: 2.6036445489686484

Epoch: 5| Step: 8
Training loss: 0.27832424763357066
Validation loss: 2.584057377152888

Epoch: 5| Step: 9
Training loss: 0.36614483045908225
Validation loss: 2.61062563018794

Epoch: 5| Step: 10
Training loss: 0.15453210838164325
Validation loss: 2.580130711289159

Epoch: 445| Step: 0
Training loss: 0.3007277651706689
Validation loss: 2.5890579354197456

Epoch: 5| Step: 1
Training loss: 0.30440853259256145
Validation loss: 2.6067288909541033

Epoch: 5| Step: 2
Training loss: 0.3759267006049885
Validation loss: 2.5706644538821277

Epoch: 5| Step: 3
Training loss: 0.3176714245145359
Validation loss: 2.5889282127771343

Epoch: 5| Step: 4
Training loss: 0.27875542342465265
Validation loss: 2.5823906917985826

Epoch: 5| Step: 5
Training loss: 0.2853066557236558
Validation loss: 2.6319890115142734

Epoch: 5| Step: 6
Training loss: 0.30503395141743483
Validation loss: 2.6135253262525935

Epoch: 5| Step: 7
Training loss: 0.23120725436401995
Validation loss: 2.620138180932422

Epoch: 5| Step: 8
Training loss: 0.307595485345576
Validation loss: 2.6416385892405447

Epoch: 5| Step: 9
Training loss: 0.20198991798213287
Validation loss: 2.642368460248963

Epoch: 5| Step: 10
Training loss: 0.3118699875698282
Validation loss: 2.6593814437231145

Epoch: 446| Step: 0
Training loss: 0.2810656950321344
Validation loss: 2.683464755429235

Epoch: 5| Step: 1
Training loss: 0.3824982813254246
Validation loss: 2.682937412126494

Epoch: 5| Step: 2
Training loss: 0.4078604797844026
Validation loss: 2.653913422100781

Epoch: 5| Step: 3
Training loss: 0.33298511371832223
Validation loss: 2.643861085618573

Epoch: 5| Step: 4
Training loss: 0.2203925318806184
Validation loss: 2.656309220041746

Epoch: 5| Step: 5
Training loss: 0.2612511457299475
Validation loss: 2.6390832326064664

Epoch: 5| Step: 6
Training loss: 0.18390866927027888
Validation loss: 2.597449211723085

Epoch: 5| Step: 7
Training loss: 0.16305753609056767
Validation loss: 2.6184110496867516

Epoch: 5| Step: 8
Training loss: 0.3520872438465676
Validation loss: 2.5848638074340244

Epoch: 5| Step: 9
Training loss: 0.25203032382858764
Validation loss: 2.5727343153173057

Epoch: 5| Step: 10
Training loss: 0.25701962998394956
Validation loss: 2.5915475731881554

Epoch: 447| Step: 0
Training loss: 0.28635166378507043
Validation loss: 2.594996022943288

Epoch: 5| Step: 1
Training loss: 0.3048503391681929
Validation loss: 2.58520525005379

Epoch: 5| Step: 2
Training loss: 0.30425726029158245
Validation loss: 2.59278817399448

Epoch: 5| Step: 3
Training loss: 0.27588264665346685
Validation loss: 2.6104066452702033

Epoch: 5| Step: 4
Training loss: 0.3088658979781444
Validation loss: 2.595414089563996

Epoch: 5| Step: 5
Training loss: 0.28410919206482566
Validation loss: 2.6189590592680965

Epoch: 5| Step: 6
Training loss: 0.3423859125531216
Validation loss: 2.635708705939276

Epoch: 5| Step: 7
Training loss: 0.31289648891102345
Validation loss: 2.6282703958325477

Epoch: 5| Step: 8
Training loss: 0.2442141765427396
Validation loss: 2.6309121467791172

Epoch: 5| Step: 9
Training loss: 0.1955946981709066
Validation loss: 2.5788801134610337

Epoch: 5| Step: 10
Training loss: 0.20000281033925615
Validation loss: 2.604971101287343

Epoch: 448| Step: 0
Training loss: 0.14534187455813768
Validation loss: 2.6085089674100685

Epoch: 5| Step: 1
Training loss: 0.33419136414898776
Validation loss: 2.6149444935288946

Epoch: 5| Step: 2
Training loss: 0.28582804726883354
Validation loss: 2.6062850198679683

Epoch: 5| Step: 3
Training loss: 0.1895678163211213
Validation loss: 2.603133052997684

Epoch: 5| Step: 4
Training loss: 0.2426566993380069
Validation loss: 2.6141769556825967

Epoch: 5| Step: 5
Training loss: 0.29383276372045813
Validation loss: 2.6000819870309444

Epoch: 5| Step: 6
Training loss: 0.39046373853333477
Validation loss: 2.6501012700350333

Epoch: 5| Step: 7
Training loss: 0.25164239041343656
Validation loss: 2.6483589799833918

Epoch: 5| Step: 8
Training loss: 0.28361483934241255
Validation loss: 2.6164044813620233

Epoch: 5| Step: 9
Training loss: 0.2785366756621657
Validation loss: 2.61287083759855

Epoch: 5| Step: 10
Training loss: 0.33254871436403827
Validation loss: 2.607520158651413

Epoch: 449| Step: 0
Training loss: 0.2509673744033812
Validation loss: 2.5962521892621737

Epoch: 5| Step: 1
Training loss: 0.20540683379120062
Validation loss: 2.6245576341241783

Epoch: 5| Step: 2
Training loss: 0.29541387634457106
Validation loss: 2.6140041973967434

Epoch: 5| Step: 3
Training loss: 0.16763620392730214
Validation loss: 2.6036523822239226

Epoch: 5| Step: 4
Training loss: 0.4052685289200577
Validation loss: 2.6020422796130056

Epoch: 5| Step: 5
Training loss: 0.18492760967263608
Validation loss: 2.62538045576453

Epoch: 5| Step: 6
Training loss: 0.40486074370005304
Validation loss: 2.6452367095540046

Epoch: 5| Step: 7
Training loss: 0.27583204563470315
Validation loss: 2.611377467678692

Epoch: 5| Step: 8
Training loss: 0.26030332801019845
Validation loss: 2.5778578733272752

Epoch: 5| Step: 9
Training loss: 0.23455830399571598
Validation loss: 2.6235504836099666

Epoch: 5| Step: 10
Training loss: 0.3559267007597823
Validation loss: 2.5701864569280954

Epoch: 450| Step: 0
Training loss: 0.13458573041273184
Validation loss: 2.586266449905146

Epoch: 5| Step: 1
Training loss: 0.40693429022688893
Validation loss: 2.6036352653170707

Epoch: 5| Step: 2
Training loss: 0.36138534092894326
Validation loss: 2.61217735148086

Epoch: 5| Step: 3
Training loss: 0.1523028587824419
Validation loss: 2.601095243663714

Epoch: 5| Step: 4
Training loss: 0.15693843694025128
Validation loss: 2.605417676796738

Epoch: 5| Step: 5
Training loss: 0.3658866361912216
Validation loss: 2.6040184014885632

Epoch: 5| Step: 6
Training loss: 0.3301951861045647
Validation loss: 2.6185596310428685

Epoch: 5| Step: 7
Training loss: 0.2373465512871941
Validation loss: 2.6261674508677477

Epoch: 5| Step: 8
Training loss: 0.18171044515195914
Validation loss: 2.5943642526570585

Epoch: 5| Step: 9
Training loss: 0.2595232786760717
Validation loss: 2.6155570453926624

Epoch: 5| Step: 10
Training loss: 0.3119203078397744
Validation loss: 2.621636317245722

Epoch: 451| Step: 0
Training loss: 0.2122040886637645
Validation loss: 2.6131113604969802

Epoch: 5| Step: 1
Training loss: 0.33567611372605183
Validation loss: 2.598145193338897

Epoch: 5| Step: 2
Training loss: 0.24896883646438148
Validation loss: 2.575408566963427

Epoch: 5| Step: 3
Training loss: 0.2763981751232314
Validation loss: 2.5656509335551787

Epoch: 5| Step: 4
Training loss: 0.24791684083905766
Validation loss: 2.566990782776068

Epoch: 5| Step: 5
Training loss: 0.2896358628736321
Validation loss: 2.566581706216507

Epoch: 5| Step: 6
Training loss: 0.34144155289243205
Validation loss: 2.604747518097984

Epoch: 5| Step: 7
Training loss: 0.2640222834824176
Validation loss: 2.5885176437259196

Epoch: 5| Step: 8
Training loss: 0.15856088993170772
Validation loss: 2.580448540717053

Epoch: 5| Step: 9
Training loss: 0.13098861233886652
Validation loss: 2.6170593485024316

Epoch: 5| Step: 10
Training loss: 0.4204536796485928
Validation loss: 2.596021770023675

Epoch: 452| Step: 0
Training loss: 0.3686236035594445
Validation loss: 2.6288776616478984

Epoch: 5| Step: 1
Training loss: 0.1982014243023254
Validation loss: 2.610342655033412

Epoch: 5| Step: 2
Training loss: 0.17036710156984217
Validation loss: 2.5770028489708268

Epoch: 5| Step: 3
Training loss: 0.3536402656480201
Validation loss: 2.604119607479709

Epoch: 5| Step: 4
Training loss: 0.3367861629367372
Validation loss: 2.6149483375980775

Epoch: 5| Step: 5
Training loss: 0.3373286474539174
Validation loss: 2.6126108210718293

Epoch: 5| Step: 6
Training loss: 0.20234415466680528
Validation loss: 2.627446866359617

Epoch: 5| Step: 7
Training loss: 0.2151199386224033
Validation loss: 2.630946842117271

Epoch: 5| Step: 8
Training loss: 0.2800626460523848
Validation loss: 2.640799247544426

Epoch: 5| Step: 9
Training loss: 0.22889204078812994
Validation loss: 2.636171660246264

Epoch: 5| Step: 10
Training loss: 0.249880255393427
Validation loss: 2.6183920064614

Epoch: 453| Step: 0
Training loss: 0.421643193456048
Validation loss: 2.6406206404117296

Epoch: 5| Step: 1
Training loss: 0.24724033220326525
Validation loss: 2.615978109327922

Epoch: 5| Step: 2
Training loss: 0.3090352991822321
Validation loss: 2.6022199948956652

Epoch: 5| Step: 3
Training loss: 0.2379311898133505
Validation loss: 2.6138111657986154

Epoch: 5| Step: 4
Training loss: 0.1451752529804416
Validation loss: 2.612331540622647

Epoch: 5| Step: 5
Training loss: 0.19716281855801784
Validation loss: 2.594835224593618

Epoch: 5| Step: 6
Training loss: 0.24189726297055017
Validation loss: 2.5818795239370758

Epoch: 5| Step: 7
Training loss: 0.39467287826335057
Validation loss: 2.569445916814437

Epoch: 5| Step: 8
Training loss: 0.22038770602733032
Validation loss: 2.551080536269341

Epoch: 5| Step: 9
Training loss: 0.19061383855693553
Validation loss: 2.5747561960502487

Epoch: 5| Step: 10
Training loss: 0.27702034644256496
Validation loss: 2.577129151545

Epoch: 454| Step: 0
Training loss: 0.24249897431864567
Validation loss: 2.5935030326781483

Epoch: 5| Step: 1
Training loss: 0.3408205966893626
Validation loss: 2.539148563664952

Epoch: 5| Step: 2
Training loss: 0.3335399124155766
Validation loss: 2.589550490647043

Epoch: 5| Step: 3
Training loss: 0.3058461996385558
Validation loss: 2.561616511676316

Epoch: 5| Step: 4
Training loss: 0.2739505586620886
Validation loss: 2.580111824703554

Epoch: 5| Step: 5
Training loss: 0.3145604039460974
Validation loss: 2.555173639677874

Epoch: 5| Step: 6
Training loss: 0.269742302569992
Validation loss: 2.5622217811157877

Epoch: 5| Step: 7
Training loss: 0.1469583092464077
Validation loss: 2.5952444800730023

Epoch: 5| Step: 8
Training loss: 0.23424955030650532
Validation loss: 2.5719486249010193

Epoch: 5| Step: 9
Training loss: 0.17408945498991327
Validation loss: 2.5759710776465803

Epoch: 5| Step: 10
Training loss: 0.23777426268144697
Validation loss: 2.5993167558449923

Epoch: 455| Step: 0
Training loss: 0.24501880631961062
Validation loss: 2.6141062936493666

Epoch: 5| Step: 1
Training loss: 0.28307431678928724
Validation loss: 2.6134404621785143

Epoch: 5| Step: 2
Training loss: 0.1429871935491065
Validation loss: 2.5924014467549092

Epoch: 5| Step: 3
Training loss: 0.15314244929950208
Validation loss: 2.615565113492489

Epoch: 5| Step: 4
Training loss: 0.3052374571465699
Validation loss: 2.6186334877997814

Epoch: 5| Step: 5
Training loss: 0.37310994199339664
Validation loss: 2.5964630877898696

Epoch: 5| Step: 6
Training loss: 0.2968356708776916
Validation loss: 2.6262790046602076

Epoch: 5| Step: 7
Training loss: 0.23975944093427592
Validation loss: 2.6139136182535654

Epoch: 5| Step: 8
Training loss: 0.27191271027112457
Validation loss: 2.630638297623504

Epoch: 5| Step: 9
Training loss: 0.3253219403776085
Validation loss: 2.6256551535370707

Epoch: 5| Step: 10
Training loss: 0.15646070340347093
Validation loss: 2.631330722911933

Epoch: 456| Step: 0
Training loss: 0.30871948867494786
Validation loss: 2.614882751376146

Epoch: 5| Step: 1
Training loss: 0.35351416023751814
Validation loss: 2.670778656604432

Epoch: 5| Step: 2
Training loss: 0.21162283790619535
Validation loss: 2.644968358636516

Epoch: 5| Step: 3
Training loss: 0.20868188589084244
Validation loss: 2.669125761966555

Epoch: 5| Step: 4
Training loss: 0.1731589219362719
Validation loss: 2.6119119308776244

Epoch: 5| Step: 5
Training loss: 0.27340214364485327
Validation loss: 2.6339403464805384

Epoch: 5| Step: 6
Training loss: 0.2813696871509705
Validation loss: 2.575607638930178

Epoch: 5| Step: 7
Training loss: 0.36589150293611994
Validation loss: 2.600076641510279

Epoch: 5| Step: 8
Training loss: 0.24178590857514493
Validation loss: 2.5968597960153827

Epoch: 5| Step: 9
Training loss: 0.23345672007415288
Validation loss: 2.62031801542992

Epoch: 5| Step: 10
Training loss: 0.16817416339094568
Validation loss: 2.6132570661654526

Epoch: 457| Step: 0
Training loss: 0.2175374998179344
Validation loss: 2.6533064262234527

Epoch: 5| Step: 1
Training loss: 0.15295496009530912
Validation loss: 2.6323711504532574

Epoch: 5| Step: 2
Training loss: 0.29002346934521395
Validation loss: 2.6389847245990854

Epoch: 5| Step: 3
Training loss: 0.17559406062294036
Validation loss: 2.6477874636685685

Epoch: 5| Step: 4
Training loss: 0.38245503610104725
Validation loss: 2.667717894851299

Epoch: 5| Step: 5
Training loss: 0.1811177614008202
Validation loss: 2.6557151955774057

Epoch: 5| Step: 6
Training loss: 0.25384001234684805
Validation loss: 2.6633603540163064

Epoch: 5| Step: 7
Training loss: 0.21917999104390587
Validation loss: 2.662713378246873

Epoch: 5| Step: 8
Training loss: 0.19138242612218048
Validation loss: 2.635784108152651

Epoch: 5| Step: 9
Training loss: 0.33755805346324264
Validation loss: 2.6189143770351744

Epoch: 5| Step: 10
Training loss: 0.4109442634170986
Validation loss: 2.6010516230861596

Epoch: 458| Step: 0
Training loss: 0.2141677103654191
Validation loss: 2.583165446795909

Epoch: 5| Step: 1
Training loss: 0.2068966932101869
Validation loss: 2.579688573122666

Epoch: 5| Step: 2
Training loss: 0.36040351720574476
Validation loss: 2.5814332163203404

Epoch: 5| Step: 3
Training loss: 0.2737089036332711
Validation loss: 2.5607178596395292

Epoch: 5| Step: 4
Training loss: 0.30696710591117204
Validation loss: 2.560990425899423

Epoch: 5| Step: 5
Training loss: 0.23040253286029105
Validation loss: 2.5565151974522764

Epoch: 5| Step: 6
Training loss: 0.19106943312641975
Validation loss: 2.564038277661519

Epoch: 5| Step: 7
Training loss: 0.1691591970629927
Validation loss: 2.599650723532741

Epoch: 5| Step: 8
Training loss: 0.21049866239333412
Validation loss: 2.579830445103521

Epoch: 5| Step: 9
Training loss: 0.324777718787522
Validation loss: 2.576422075793225

Epoch: 5| Step: 10
Training loss: 0.3582453387729854
Validation loss: 2.5954443730551797

Epoch: 459| Step: 0
Training loss: 0.3014325855272919
Validation loss: 2.5981497564194127

Epoch: 5| Step: 1
Training loss: 0.14098797418751535
Validation loss: 2.5680236270055183

Epoch: 5| Step: 2
Training loss: 0.14450054229111534
Validation loss: 2.5937803730951194

Epoch: 5| Step: 3
Training loss: 0.15331163807038445
Validation loss: 2.5657741120046182

Epoch: 5| Step: 4
Training loss: 0.3107898649207881
Validation loss: 2.5721560622664015

Epoch: 5| Step: 5
Training loss: 0.19927298985530922
Validation loss: 2.6087658299839456

Epoch: 5| Step: 6
Training loss: 0.2192009127232856
Validation loss: 2.575228311556384

Epoch: 5| Step: 7
Training loss: 0.22722830446627124
Validation loss: 2.580983523905525

Epoch: 5| Step: 8
Training loss: 0.32631383307943995
Validation loss: 2.586844896474952

Epoch: 5| Step: 9
Training loss: 0.29506682313944943
Validation loss: 2.5654002128995894

Epoch: 5| Step: 10
Training loss: 0.40091005452888956
Validation loss: 2.578834250680597

Epoch: 460| Step: 0
Training loss: 0.26030832262110504
Validation loss: 2.596563031259199

Epoch: 5| Step: 1
Training loss: 0.2325072332123565
Validation loss: 2.571137751459654

Epoch: 5| Step: 2
Training loss: 0.15955496939547503
Validation loss: 2.5776359265747235

Epoch: 5| Step: 3
Training loss: 0.20033125564917467
Validation loss: 2.5897639642530397

Epoch: 5| Step: 4
Training loss: 0.14634654872612163
Validation loss: 2.616561221604318

Epoch: 5| Step: 5
Training loss: 0.3058589033997701
Validation loss: 2.6304587929769627

Epoch: 5| Step: 6
Training loss: 0.1682721547119008
Validation loss: 2.635603959393615

Epoch: 5| Step: 7
Training loss: 0.2881034069906851
Validation loss: 2.620360999764963

Epoch: 5| Step: 8
Training loss: 0.29297211962987313
Validation loss: 2.5920753494154165

Epoch: 5| Step: 9
Training loss: 0.4144462210954767
Validation loss: 2.631518499989497

Epoch: 5| Step: 10
Training loss: 0.30610343627636577
Validation loss: 2.6150677803353175

Epoch: 461| Step: 0
Training loss: 0.3275777476604462
Validation loss: 2.6335675978311732

Epoch: 5| Step: 1
Training loss: 0.240569632836015
Validation loss: 2.6361462709397903

Epoch: 5| Step: 2
Training loss: 0.14781165573370963
Validation loss: 2.624918837300928

Epoch: 5| Step: 3
Training loss: 0.28027225454260235
Validation loss: 2.591943245249944

Epoch: 5| Step: 4
Training loss: 0.18238859097625928
Validation loss: 2.588415902977059

Epoch: 5| Step: 5
Training loss: 0.28258110664952446
Validation loss: 2.612676361296889

Epoch: 5| Step: 6
Training loss: 0.25037196918563337
Validation loss: 2.58549637169194

Epoch: 5| Step: 7
Training loss: 0.2808391829064448
Validation loss: 2.606748146249425

Epoch: 5| Step: 8
Training loss: 0.3077041503055447
Validation loss: 2.607907864326425

Epoch: 5| Step: 9
Training loss: 0.2414973639478618
Validation loss: 2.5905674568022943

Epoch: 5| Step: 10
Training loss: 0.16105008747194088
Validation loss: 2.6060828921540558

Epoch: 462| Step: 0
Training loss: 0.3157067160058773
Validation loss: 2.610582228758076

Epoch: 5| Step: 1
Training loss: 0.2276311205188254
Validation loss: 2.60366242348633

Epoch: 5| Step: 2
Training loss: 0.2996514888842286
Validation loss: 2.616973857458299

Epoch: 5| Step: 3
Training loss: 0.14305936906712444
Validation loss: 2.584257663753834

Epoch: 5| Step: 4
Training loss: 0.399387088228535
Validation loss: 2.616418382712197

Epoch: 5| Step: 5
Training loss: 0.18548124055975196
Validation loss: 2.5946328540673114

Epoch: 5| Step: 6
Training loss: 0.28915561001240037
Validation loss: 2.6253509833748034

Epoch: 5| Step: 7
Training loss: 0.167298910863789
Validation loss: 2.630671838357386

Epoch: 5| Step: 8
Training loss: 0.21424816113331618
Validation loss: 2.62511423920064

Epoch: 5| Step: 9
Training loss: 0.2512570902549901
Validation loss: 2.6404330606222244

Epoch: 5| Step: 10
Training loss: 0.2337686961647765
Validation loss: 2.6532235379793305

Epoch: 463| Step: 0
Training loss: 0.15791791355421683
Validation loss: 2.6121909539135872

Epoch: 5| Step: 1
Training loss: 0.28189131681070756
Validation loss: 2.6024618939758466

Epoch: 5| Step: 2
Training loss: 0.3224645751895815
Validation loss: 2.6002131960776076

Epoch: 5| Step: 3
Training loss: 0.31578643749266544
Validation loss: 2.6057222021700572

Epoch: 5| Step: 4
Training loss: 0.16864493021881274
Validation loss: 2.6040740779701435

Epoch: 5| Step: 5
Training loss: 0.21468923387563035
Validation loss: 2.5876763083061856

Epoch: 5| Step: 6
Training loss: 0.26460279796120106
Validation loss: 2.5821006288627824

Epoch: 5| Step: 7
Training loss: 0.21244110104594252
Validation loss: 2.617512189633381

Epoch: 5| Step: 8
Training loss: 0.2741620002342695
Validation loss: 2.614963234170615

Epoch: 5| Step: 9
Training loss: 0.25689310808236365
Validation loss: 2.628623720126919

Epoch: 5| Step: 10
Training loss: 0.24913697739781213
Validation loss: 2.599398067999767

Epoch: 464| Step: 0
Training loss: 0.26613251502847557
Validation loss: 2.6169612085708107

Epoch: 5| Step: 1
Training loss: 0.19134324846976064
Validation loss: 2.5992383517329025

Epoch: 5| Step: 2
Training loss: 0.2504392430897184
Validation loss: 2.57497063281633

Epoch: 5| Step: 3
Training loss: 0.3712453833527372
Validation loss: 2.576452996446892

Epoch: 5| Step: 4
Training loss: 0.19570465772565376
Validation loss: 2.556382164245213

Epoch: 5| Step: 5
Training loss: 0.19197253711683934
Validation loss: 2.576618848201283

Epoch: 5| Step: 6
Training loss: 0.28882091324387305
Validation loss: 2.552151577413571

Epoch: 5| Step: 7
Training loss: 0.3142425827404374
Validation loss: 2.548438529972832

Epoch: 5| Step: 8
Training loss: 0.2928440591584372
Validation loss: 2.5398864338153704

Epoch: 5| Step: 9
Training loss: 0.22660419475076757
Validation loss: 2.560506285696159

Epoch: 5| Step: 10
Training loss: 0.2532976191818434
Validation loss: 2.546444272957579

Epoch: 465| Step: 0
Training loss: 0.34030789436117226
Validation loss: 2.5852751848285

Epoch: 5| Step: 1
Training loss: 0.25212950040708987
Validation loss: 2.551890484017571

Epoch: 5| Step: 2
Training loss: 0.33890051774013275
Validation loss: 2.562731404514597

Epoch: 5| Step: 3
Training loss: 0.20909980010671197
Validation loss: 2.542539591565131

Epoch: 5| Step: 4
Training loss: 0.20730700212490732
Validation loss: 2.5548483798009345

Epoch: 5| Step: 5
Training loss: 0.19616444745695052
Validation loss: 2.579600301666707

Epoch: 5| Step: 6
Training loss: 0.28478289683935437
Validation loss: 2.5784188210967627

Epoch: 5| Step: 7
Training loss: 0.2583208130422508
Validation loss: 2.5599535943896177

Epoch: 5| Step: 8
Training loss: 0.3978128585753881
Validation loss: 2.5744404456518533

Epoch: 5| Step: 9
Training loss: 0.1484024608816737
Validation loss: 2.5655218575217127

Epoch: 5| Step: 10
Training loss: 0.22140237713309108
Validation loss: 2.566544995569009

Epoch: 466| Step: 0
Training loss: 0.28945487687253857
Validation loss: 2.5835373464152105

Epoch: 5| Step: 1
Training loss: 0.28330974544950777
Validation loss: 2.6063355645932407

Epoch: 5| Step: 2
Training loss: 0.18488113026968908
Validation loss: 2.6053509562060477

Epoch: 5| Step: 3
Training loss: 0.3005430095474604
Validation loss: 2.5862834071898755

Epoch: 5| Step: 4
Training loss: 0.22006031543900892
Validation loss: 2.5948895954282913

Epoch: 5| Step: 5
Training loss: 0.15076611447835497
Validation loss: 2.5516819366824217

Epoch: 5| Step: 6
Training loss: 0.2502238046710372
Validation loss: 2.5696918141948695

Epoch: 5| Step: 7
Training loss: 0.23704216804329556
Validation loss: 2.576434085886851

Epoch: 5| Step: 8
Training loss: 0.26955572652941295
Validation loss: 2.564726636726158

Epoch: 5| Step: 9
Training loss: 0.4251507281442863
Validation loss: 2.5613599372586013

Epoch: 5| Step: 10
Training loss: 0.3417460812565141
Validation loss: 2.5496351368296293

Epoch: 467| Step: 0
Training loss: 0.32257913309846553
Validation loss: 2.5542338555770754

Epoch: 5| Step: 1
Training loss: 0.23883809234514541
Validation loss: 2.6503184154524617

Epoch: 5| Step: 2
Training loss: 0.23050283729499169
Validation loss: 2.6135904354953263

Epoch: 5| Step: 3
Training loss: 0.30595936998045103
Validation loss: 2.60776515162153

Epoch: 5| Step: 4
Training loss: 0.3721607729061749
Validation loss: 2.5885109348189084

Epoch: 5| Step: 5
Training loss: 0.46139222684090814
Validation loss: 2.6232845699684035

Epoch: 5| Step: 6
Training loss: 0.23720717290730367
Validation loss: 2.650745006727547

Epoch: 5| Step: 7
Training loss: 0.3806705495830614
Validation loss: 2.584846718845437

Epoch: 5| Step: 8
Training loss: 0.3720544125821648
Validation loss: 2.559077052892771

Epoch: 5| Step: 9
Training loss: 0.480947659009056
Validation loss: 2.5590213290922237

Epoch: 5| Step: 10
Training loss: 0.3301865439140288
Validation loss: 2.559233865241305

Epoch: 468| Step: 0
Training loss: 0.4289790468678772
Validation loss: 2.585120327987468

Epoch: 5| Step: 1
Training loss: 0.3974846497756726
Validation loss: 2.6045638899209216

Epoch: 5| Step: 2
Training loss: 0.31165539329500563
Validation loss: 2.5775990018861092

Epoch: 5| Step: 3
Training loss: 0.5074805128180245
Validation loss: 2.6206900954241497

Epoch: 5| Step: 4
Training loss: 0.18293769779787622
Validation loss: 2.5756044398613462

Epoch: 5| Step: 5
Training loss: 0.33001154165964314
Validation loss: 2.526567858251208

Epoch: 5| Step: 6
Training loss: 0.3055552328474094
Validation loss: 2.5067500960020284

Epoch: 5| Step: 7
Training loss: 0.3217186186810115
Validation loss: 2.524524118111811

Epoch: 5| Step: 8
Training loss: 0.4564194782537998
Validation loss: 2.489180843114155

Epoch: 5| Step: 9
Training loss: 0.3677544174097589
Validation loss: 2.565683302968107

Epoch: 5| Step: 10
Training loss: 0.21273184463447456
Validation loss: 2.587716119245572

Epoch: 469| Step: 0
Training loss: 0.3903784927764022
Validation loss: 2.6340619373531524

Epoch: 5| Step: 1
Training loss: 0.3783226237622796
Validation loss: 2.642848674198224

Epoch: 5| Step: 2
Training loss: 0.30853613786468187
Validation loss: 2.6923632979186523

Epoch: 5| Step: 3
Training loss: 0.33177109792669857
Validation loss: 2.6530511867624815

Epoch: 5| Step: 4
Training loss: 0.4463145042196011
Validation loss: 2.613996122027308

Epoch: 5| Step: 5
Training loss: 0.1935194008358355
Validation loss: 2.591423506484858

Epoch: 5| Step: 6
Training loss: 0.23789029019587465
Validation loss: 2.568691055040314

Epoch: 5| Step: 7
Training loss: 0.30078346697498076
Validation loss: 2.541058966134053

Epoch: 5| Step: 8
Training loss: 0.26500649529720116
Validation loss: 2.510748195461919

Epoch: 5| Step: 9
Training loss: 0.3849928518969333
Validation loss: 2.508472634692561

Epoch: 5| Step: 10
Training loss: 0.21076551242892952
Validation loss: 2.5428446110010845

Epoch: 470| Step: 0
Training loss: 0.32359231616061257
Validation loss: 2.5551553471976107

Epoch: 5| Step: 1
Training loss: 0.3264255450961194
Validation loss: 2.5693815457724263

Epoch: 5| Step: 2
Training loss: 0.14068009701193254
Validation loss: 2.607517998621781

Epoch: 5| Step: 3
Training loss: 0.17489688189576363
Validation loss: 2.6097965323687076

Epoch: 5| Step: 4
Training loss: 0.384710046462286
Validation loss: 2.649473686913058

Epoch: 5| Step: 5
Training loss: 0.29906307284181716
Validation loss: 2.6615674405253174

Epoch: 5| Step: 6
Training loss: 0.26797683970526903
Validation loss: 2.6847551949786865

Epoch: 5| Step: 7
Training loss: 0.2585437403607771
Validation loss: 2.674054341057718

Epoch: 5| Step: 8
Training loss: 0.33723100874713835
Validation loss: 2.6670103982792632

Epoch: 5| Step: 9
Training loss: 0.2453464104971325
Validation loss: 2.6734102399997908

Epoch: 5| Step: 10
Training loss: 0.3811676342902824
Validation loss: 2.684592177033288

Epoch: 471| Step: 0
Training loss: 0.2898104502013315
Validation loss: 2.676089981648141

Epoch: 5| Step: 1
Training loss: 0.23796634502535652
Validation loss: 2.640671908928001

Epoch: 5| Step: 2
Training loss: 0.2299655415414441
Validation loss: 2.6745915851430224

Epoch: 5| Step: 3
Training loss: 0.2692338297645087
Validation loss: 2.663809213135364

Epoch: 5| Step: 4
Training loss: 0.28984204417752385
Validation loss: 2.609345228931566

Epoch: 5| Step: 5
Training loss: 0.292926365647466
Validation loss: 2.6183407525723195

Epoch: 5| Step: 6
Training loss: 0.2218442045922625
Validation loss: 2.586422785375011

Epoch: 5| Step: 7
Training loss: 0.3961154555594035
Validation loss: 2.5621009814127764

Epoch: 5| Step: 8
Training loss: 0.39139602860983125
Validation loss: 2.5660688737566617

Epoch: 5| Step: 9
Training loss: 0.2767293060632839
Validation loss: 2.571649535712518

Epoch: 5| Step: 10
Training loss: 0.4445637716186391
Validation loss: 2.581398630127558

Epoch: 472| Step: 0
Training loss: 0.1808446548601436
Validation loss: 2.616109950364465

Epoch: 5| Step: 1
Training loss: 0.291222274938234
Validation loss: 2.6084288935956197

Epoch: 5| Step: 2
Training loss: 0.23392381951212693
Validation loss: 2.6484847947091392

Epoch: 5| Step: 3
Training loss: 0.24848670712076865
Validation loss: 2.658742762139981

Epoch: 5| Step: 4
Training loss: 0.36200720406313686
Validation loss: 2.6523159371849894

Epoch: 5| Step: 5
Training loss: 0.3141311276358483
Validation loss: 2.649379437246276

Epoch: 5| Step: 6
Training loss: 0.32937264526654686
Validation loss: 2.699037343274911

Epoch: 5| Step: 7
Training loss: 0.2836941375863567
Validation loss: 2.705332059703771

Epoch: 5| Step: 8
Training loss: 0.3916167448910658
Validation loss: 2.717210983037803

Epoch: 5| Step: 9
Training loss: 0.32280158355881666
Validation loss: 2.6396717103907616

Epoch: 5| Step: 10
Training loss: 0.1670043673172683
Validation loss: 2.6376376330112983

Epoch: 473| Step: 0
Training loss: 0.25713463011563326
Validation loss: 2.609428175812431

Epoch: 5| Step: 1
Training loss: 0.36822527470166316
Validation loss: 2.5345591349683616

Epoch: 5| Step: 2
Training loss: 0.3188516403346574
Validation loss: 2.563693915196685

Epoch: 5| Step: 3
Training loss: 0.1675836562197512
Validation loss: 2.5385157317162728

Epoch: 5| Step: 4
Training loss: 0.39735139279172443
Validation loss: 2.4886577662168343

Epoch: 5| Step: 5
Training loss: 0.3682082172497361
Validation loss: 2.548221492653355

Epoch: 5| Step: 6
Training loss: 0.30839839014846604
Validation loss: 2.5504433286938815

Epoch: 5| Step: 7
Training loss: 0.19647507844625572
Validation loss: 2.608744016845933

Epoch: 5| Step: 8
Training loss: 0.24202770683694655
Validation loss: 2.7025334815126416

Epoch: 5| Step: 9
Training loss: 0.2979349738722745
Validation loss: 2.7221878865213807

Epoch: 5| Step: 10
Training loss: 0.4217836316384791
Validation loss: 2.712331162720425

Epoch: 474| Step: 0
Training loss: 0.25098092635698815
Validation loss: 2.693027025643201

Epoch: 5| Step: 1
Training loss: 0.2236360108259284
Validation loss: 2.6276230507670086

Epoch: 5| Step: 2
Training loss: 0.38813267019927317
Validation loss: 2.590782297255161

Epoch: 5| Step: 3
Training loss: 0.3526866635554831
Validation loss: 2.60363285491986

Epoch: 5| Step: 4
Training loss: 0.30307991243085014
Validation loss: 2.572962840513167

Epoch: 5| Step: 5
Training loss: 0.3713303062973627
Validation loss: 2.5433738303572655

Epoch: 5| Step: 6
Training loss: 0.26424567342029415
Validation loss: 2.5485783255083705

Epoch: 5| Step: 7
Training loss: 0.17023660845645971
Validation loss: 2.61030271407941

Epoch: 5| Step: 8
Training loss: 0.36561843752066053
Validation loss: 2.634710312966211

Epoch: 5| Step: 9
Training loss: 0.1995422504233568
Validation loss: 2.653752980661445

Epoch: 5| Step: 10
Training loss: 0.31878133320608665
Validation loss: 2.658062601500713

Epoch: 475| Step: 0
Training loss: 0.3069665476640301
Validation loss: 2.6602720035132963

Epoch: 5| Step: 1
Training loss: 0.3017898221615053
Validation loss: 2.6720394267909926

Epoch: 5| Step: 2
Training loss: 0.19272581012623352
Validation loss: 2.644889933363229

Epoch: 5| Step: 3
Training loss: 0.36577484614108485
Validation loss: 2.6261489432002114

Epoch: 5| Step: 4
Training loss: 0.1842260834234845
Validation loss: 2.5967317282933666

Epoch: 5| Step: 5
Training loss: 0.41104650610916893
Validation loss: 2.5538902949274345

Epoch: 5| Step: 6
Training loss: 0.3213157178958434
Validation loss: 2.556592152688299

Epoch: 5| Step: 7
Training loss: 0.2978115117395902
Validation loss: 2.52402806321934

Epoch: 5| Step: 8
Training loss: 0.3389647945139153
Validation loss: 2.558535499664285

Epoch: 5| Step: 9
Training loss: 0.1649070810181753
Validation loss: 2.578494196484928

Epoch: 5| Step: 10
Training loss: 0.17107485793162303
Validation loss: 2.6298211953904187

Epoch: 476| Step: 0
Training loss: 0.26579612941456854
Validation loss: 2.6313600425906767

Epoch: 5| Step: 1
Training loss: 0.26822753399595867
Validation loss: 2.6828429137826904

Epoch: 5| Step: 2
Training loss: 0.3526991166482024
Validation loss: 2.698451559090939

Epoch: 5| Step: 3
Training loss: 0.24789424014769057
Validation loss: 2.7046570740406257

Epoch: 5| Step: 4
Training loss: 0.21669886495759885
Validation loss: 2.6535902176387833

Epoch: 5| Step: 5
Training loss: 0.27394601675759234
Validation loss: 2.6381952930430543

Epoch: 5| Step: 6
Training loss: 0.21007259859566774
Validation loss: 2.640276185916764

Epoch: 5| Step: 7
Training loss: 0.2273718583863555
Validation loss: 2.626233826125775

Epoch: 5| Step: 8
Training loss: 0.3982898401147393
Validation loss: 2.630450380231091

Epoch: 5| Step: 9
Training loss: 0.27535975398189266
Validation loss: 2.625625137939265

Epoch: 5| Step: 10
Training loss: 0.2793567699953348
Validation loss: 2.612537107082933

Epoch: 477| Step: 0
Training loss: 0.23619214393994512
Validation loss: 2.619169014246957

Epoch: 5| Step: 1
Training loss: 0.23138991228032899
Validation loss: 2.613450182341718

Epoch: 5| Step: 2
Training loss: 0.22738236037174814
Validation loss: 2.661254679160577

Epoch: 5| Step: 3
Training loss: 0.3458043505213226
Validation loss: 2.6323209624878325

Epoch: 5| Step: 4
Training loss: 0.36905313898241876
Validation loss: 2.6246628610713394

Epoch: 5| Step: 5
Training loss: 0.19731885361856163
Validation loss: 2.6111653536199064

Epoch: 5| Step: 6
Training loss: 0.36805549457637515
Validation loss: 2.60832032210225

Epoch: 5| Step: 7
Training loss: 0.313396526826761
Validation loss: 2.6187076860927525

Epoch: 5| Step: 8
Training loss: 0.13693940884440614
Validation loss: 2.583927962043654

Epoch: 5| Step: 9
Training loss: 0.16858695175599073
Validation loss: 2.56263582083262

Epoch: 5| Step: 10
Training loss: 0.2418366706034782
Validation loss: 2.5504983913081247

Epoch: 478| Step: 0
Training loss: 0.22821237543379216
Validation loss: 2.589302415853016

Epoch: 5| Step: 1
Training loss: 0.33633839173990016
Validation loss: 2.5473753694734023

Epoch: 5| Step: 2
Training loss: 0.262569893887008
Validation loss: 2.575565824776484

Epoch: 5| Step: 3
Training loss: 0.2759768016946435
Validation loss: 2.590473280242094

Epoch: 5| Step: 4
Training loss: 0.21903004771885154
Validation loss: 2.5843600800669027

Epoch: 5| Step: 5
Training loss: 0.20338144070544356
Validation loss: 2.6052903210207816

Epoch: 5| Step: 6
Training loss: 0.2875951951444595
Validation loss: 2.651953358979834

Epoch: 5| Step: 7
Training loss: 0.34405995613148643
Validation loss: 2.6440139870272024

Epoch: 5| Step: 8
Training loss: 0.30793870139657054
Validation loss: 2.6314138399513123

Epoch: 5| Step: 9
Training loss: 0.26066583951518424
Validation loss: 2.6324172267461896

Epoch: 5| Step: 10
Training loss: 0.16136725161386553
Validation loss: 2.605988917229985

Epoch: 479| Step: 0
Training loss: 0.19432118613839966
Validation loss: 2.6074945449304043

Epoch: 5| Step: 1
Training loss: 0.21275712123141233
Validation loss: 2.616554645347884

Epoch: 5| Step: 2
Training loss: 0.26023466744087254
Validation loss: 2.557575652574403

Epoch: 5| Step: 3
Training loss: 0.4126781136882267
Validation loss: 2.5715785808958485

Epoch: 5| Step: 4
Training loss: 0.20762821717270197
Validation loss: 2.55489782791117

Epoch: 5| Step: 5
Training loss: 0.2544288246045743
Validation loss: 2.5285792666382974

Epoch: 5| Step: 6
Training loss: 0.205957615843839
Validation loss: 2.588977986826102

Epoch: 5| Step: 7
Training loss: 0.16030314152340827
Validation loss: 2.6216638482800607

Epoch: 5| Step: 8
Training loss: 0.3160843094355501
Validation loss: 2.5830420064517

Epoch: 5| Step: 9
Training loss: 0.3113367124974156
Validation loss: 2.6279782497328927

Epoch: 5| Step: 10
Training loss: 0.20793417401716632
Validation loss: 2.616835869407316

Epoch: 480| Step: 0
Training loss: 0.2718421307787551
Validation loss: 2.6806820455578135

Epoch: 5| Step: 1
Training loss: 0.15243435879435122
Validation loss: 2.614783420872519

Epoch: 5| Step: 2
Training loss: 0.12402076417940376
Validation loss: 2.6397590544982847

Epoch: 5| Step: 3
Training loss: 0.3439111115295292
Validation loss: 2.635270810487774

Epoch: 5| Step: 4
Training loss: 0.29016078616752666
Validation loss: 2.633896825534984

Epoch: 5| Step: 5
Training loss: 0.22899573175281857
Validation loss: 2.5972108550239086

Epoch: 5| Step: 6
Training loss: 0.3366140384227968
Validation loss: 2.594818490164899

Epoch: 5| Step: 7
Training loss: 0.3010394486782288
Validation loss: 2.5975733022486738

Epoch: 5| Step: 8
Training loss: 0.1975948494695541
Validation loss: 2.5528842843626207

Epoch: 5| Step: 9
Training loss: 0.1984158868358459
Validation loss: 2.5496040226601058

Epoch: 5| Step: 10
Training loss: 0.26768263286518484
Validation loss: 2.554587222835667

Epoch: 481| Step: 0
Training loss: 0.18527637641018685
Validation loss: 2.5374008590136237

Epoch: 5| Step: 1
Training loss: 0.17940061929554935
Validation loss: 2.537117444498997

Epoch: 5| Step: 2
Training loss: 0.2971800817652828
Validation loss: 2.563011246991088

Epoch: 5| Step: 3
Training loss: 0.2355721891854289
Validation loss: 2.597844736146319

Epoch: 5| Step: 4
Training loss: 0.34092143616214715
Validation loss: 2.555698839470016

Epoch: 5| Step: 5
Training loss: 0.18259980634092024
Validation loss: 2.5419620770580758

Epoch: 5| Step: 6
Training loss: 0.3152745104343617
Validation loss: 2.5410058749337705

Epoch: 5| Step: 7
Training loss: 0.12838076643682095
Validation loss: 2.5538837189083083

Epoch: 5| Step: 8
Training loss: 0.16407529463150863
Validation loss: 2.582808821069778

Epoch: 5| Step: 9
Training loss: 0.20131840970716233
Validation loss: 2.593424241263894

Epoch: 5| Step: 10
Training loss: 0.3238340531417424
Validation loss: 2.5640429781781204

Epoch: 482| Step: 0
Training loss: 0.2542332670759586
Validation loss: 2.551270057288397

Epoch: 5| Step: 1
Training loss: 0.20740463666531256
Validation loss: 2.5646729758961855

Epoch: 5| Step: 2
Training loss: 0.26624513211971634
Validation loss: 2.530933195722379

Epoch: 5| Step: 3
Training loss: 0.2528157658831657
Validation loss: 2.5553009590168685

Epoch: 5| Step: 4
Training loss: 0.1715525561110445
Validation loss: 2.5844930995472373

Epoch: 5| Step: 5
Training loss: 0.3154170621347069
Validation loss: 2.5801827470520275

Epoch: 5| Step: 6
Training loss: 0.2989960989984668
Validation loss: 2.5761345914731546

Epoch: 5| Step: 7
Training loss: 0.2905314725694669
Validation loss: 2.5851090306185918

Epoch: 5| Step: 8
Training loss: 0.30885926425237303
Validation loss: 2.588686361473973

Epoch: 5| Step: 9
Training loss: 0.1507180476772421
Validation loss: 2.6096426512330133

Epoch: 5| Step: 10
Training loss: 0.2193385704065932
Validation loss: 2.614228483413229

Epoch: 483| Step: 0
Training loss: 0.3199005618232964
Validation loss: 2.6331464924955306

Epoch: 5| Step: 1
Training loss: 0.2760274841455938
Validation loss: 2.602022273710162

Epoch: 5| Step: 2
Training loss: 0.19677357634542011
Validation loss: 2.590492105139981

Epoch: 5| Step: 3
Training loss: 0.2622003252532245
Validation loss: 2.594545424524731

Epoch: 5| Step: 4
Training loss: 0.15720274253148814
Validation loss: 2.603917797051169

Epoch: 5| Step: 5
Training loss: 0.15672804897100304
Validation loss: 2.5805282136224004

Epoch: 5| Step: 6
Training loss: 0.19729523389331177
Validation loss: 2.563942309000793

Epoch: 5| Step: 7
Training loss: 0.23665579629137026
Validation loss: 2.581617707249069

Epoch: 5| Step: 8
Training loss: 0.1961717302359074
Validation loss: 2.56206883390428

Epoch: 5| Step: 9
Training loss: 0.3169474035982661
Validation loss: 2.5743518115073756

Epoch: 5| Step: 10
Training loss: 0.20537278940586431
Validation loss: 2.5467821073197108

Epoch: 484| Step: 0
Training loss: 0.2496448467762214
Validation loss: 2.549032314659838

Epoch: 5| Step: 1
Training loss: 0.2234227222277433
Validation loss: 2.5727874507858868

Epoch: 5| Step: 2
Training loss: 0.2234062813243772
Validation loss: 2.5996309926065724

Epoch: 5| Step: 3
Training loss: 0.312438267332395
Validation loss: 2.59728503261416

Epoch: 5| Step: 4
Training loss: 0.23940625937814997
Validation loss: 2.587334716180101

Epoch: 5| Step: 5
Training loss: 0.33084180620875836
Validation loss: 2.6178419293781796

Epoch: 5| Step: 6
Training loss: 0.14270131132735314
Validation loss: 2.654698110007089

Epoch: 5| Step: 7
Training loss: 0.14109380383031078
Validation loss: 2.6586720937179646

Epoch: 5| Step: 8
Training loss: 0.2741720958701653
Validation loss: 2.6247257142103395

Epoch: 5| Step: 9
Training loss: 0.17103594561215324
Validation loss: 2.6329146147183926

Epoch: 5| Step: 10
Training loss: 0.26625320535619784
Validation loss: 2.578487842292814

Epoch: 485| Step: 0
Training loss: 0.16868124152676126
Validation loss: 2.5786636679770063

Epoch: 5| Step: 1
Training loss: 0.33110543371291085
Validation loss: 2.5699216972754413

Epoch: 5| Step: 2
Training loss: 0.11691508020913323
Validation loss: 2.5602023090276127

Epoch: 5| Step: 3
Training loss: 0.2400732818373206
Validation loss: 2.5481903793319494

Epoch: 5| Step: 4
Training loss: 0.3701558155847901
Validation loss: 2.529276917562911

Epoch: 5| Step: 5
Training loss: 0.2638435228919028
Validation loss: 2.504220018802492

Epoch: 5| Step: 6
Training loss: 0.2432212915445809
Validation loss: 2.553965329710485

Epoch: 5| Step: 7
Training loss: 0.24986559264826208
Validation loss: 2.522943943513315

Epoch: 5| Step: 8
Training loss: 0.20997067805916764
Validation loss: 2.580073311359466

Epoch: 5| Step: 9
Training loss: 0.23262526324368463
Validation loss: 2.5885984458662348

Epoch: 5| Step: 10
Training loss: 0.18905121162700236
Validation loss: 2.5732831278400625

Epoch: 486| Step: 0
Training loss: 0.20268850928604323
Validation loss: 2.592045169974156

Epoch: 5| Step: 1
Training loss: 0.31555751891198847
Validation loss: 2.6267294374993

Epoch: 5| Step: 2
Training loss: 0.20367072230555364
Validation loss: 2.6102168426295482

Epoch: 5| Step: 3
Training loss: 0.24478205533469227
Validation loss: 2.6214867118131324

Epoch: 5| Step: 4
Training loss: 0.16029733165940296
Validation loss: 2.620123583587343

Epoch: 5| Step: 5
Training loss: 0.20679732368400386
Validation loss: 2.6393393294198777

Epoch: 5| Step: 6
Training loss: 0.19472989927932002
Validation loss: 2.6393858471802454

Epoch: 5| Step: 7
Training loss: 0.18889961792668425
Validation loss: 2.6228885059326865

Epoch: 5| Step: 8
Training loss: 0.1635960066219801
Validation loss: 2.629221381946856

Epoch: 5| Step: 9
Training loss: 0.21485177805379893
Validation loss: 2.591378211953879

Epoch: 5| Step: 10
Training loss: 0.41025068013485283
Validation loss: 2.5846433004243177

Epoch: 487| Step: 0
Training loss: 0.3354723726635771
Validation loss: 2.600367108266359

Epoch: 5| Step: 1
Training loss: 0.16984662768567788
Validation loss: 2.5546794338173613

Epoch: 5| Step: 2
Training loss: 0.18434423901263008
Validation loss: 2.614377292668735

Epoch: 5| Step: 3
Training loss: 0.254702069152512
Validation loss: 2.616443469624431

Epoch: 5| Step: 4
Training loss: 0.1409841428363947
Validation loss: 2.5748527416252123

Epoch: 5| Step: 5
Training loss: 0.1701652712921983
Validation loss: 2.5845263429324534

Epoch: 5| Step: 6
Training loss: 0.24133979197389008
Validation loss: 2.593547314482065

Epoch: 5| Step: 7
Training loss: 0.20751470223586366
Validation loss: 2.6061038117353568

Epoch: 5| Step: 8
Training loss: 0.16988809841806476
Validation loss: 2.596027028597665

Epoch: 5| Step: 9
Training loss: 0.27543538318285443
Validation loss: 2.602512105135593

Epoch: 5| Step: 10
Training loss: 0.2674875732681685
Validation loss: 2.600377240591605

Epoch: 488| Step: 0
Training loss: 0.23520328076772487
Validation loss: 2.618731138233054

Epoch: 5| Step: 1
Training loss: 0.16708714869258157
Validation loss: 2.615783338237915

Epoch: 5| Step: 2
Training loss: 0.2800611828690254
Validation loss: 2.5932492453412124

Epoch: 5| Step: 3
Training loss: 0.2597235308507657
Validation loss: 2.5813590539608753

Epoch: 5| Step: 4
Training loss: 0.3079311887536817
Validation loss: 2.586991847169561

Epoch: 5| Step: 5
Training loss: 0.22582940178847202
Validation loss: 2.569194227900891

Epoch: 5| Step: 6
Training loss: 0.23673673253008756
Validation loss: 2.5873698606217483

Epoch: 5| Step: 7
Training loss: 0.13230329960516607
Validation loss: 2.5824354495568143

Epoch: 5| Step: 8
Training loss: 0.22120574668898368
Validation loss: 2.597787741929777

Epoch: 5| Step: 9
Training loss: 0.17534965937298272
Validation loss: 2.578945811081868

Epoch: 5| Step: 10
Training loss: 0.2877942176173011
Validation loss: 2.6120035422717467

Epoch: 489| Step: 0
Training loss: 0.22604558610960687
Validation loss: 2.6210512554819148

Epoch: 5| Step: 1
Training loss: 0.2828887246612461
Validation loss: 2.6328318946230893

Epoch: 5| Step: 2
Training loss: 0.16810219476205698
Validation loss: 2.587916010745469

Epoch: 5| Step: 3
Training loss: 0.277143056547096
Validation loss: 2.585723831444744

Epoch: 5| Step: 4
Training loss: 0.14318995300208212
Validation loss: 2.582500971359631

Epoch: 5| Step: 5
Training loss: 0.2176247846338301
Validation loss: 2.605458884446442

Epoch: 5| Step: 6
Training loss: 0.27974134704700526
Validation loss: 2.577824347035541

Epoch: 5| Step: 7
Training loss: 0.19777954312144166
Validation loss: 2.5467296020065366

Epoch: 5| Step: 8
Training loss: 0.29654517172383504
Validation loss: 2.5506139805086216

Epoch: 5| Step: 9
Training loss: 0.11675451875790363
Validation loss: 2.5996922799748248

Epoch: 5| Step: 10
Training loss: 0.2526091529249191
Validation loss: 2.5399988681447367

Epoch: 490| Step: 0
Training loss: 0.23986417267174565
Validation loss: 2.5450632352632887

Epoch: 5| Step: 1
Training loss: 0.2733907795910154
Validation loss: 2.56263387406885

Epoch: 5| Step: 2
Training loss: 0.1418350005585095
Validation loss: 2.5601607819956795

Epoch: 5| Step: 3
Training loss: 0.2107245907229324
Validation loss: 2.5826376621013747

Epoch: 5| Step: 4
Training loss: 0.2859183800146685
Validation loss: 2.608843092839137

Epoch: 5| Step: 5
Training loss: 0.1320858670304042
Validation loss: 2.617178567556738

Epoch: 5| Step: 6
Training loss: 0.3224789924580859
Validation loss: 2.6026100504090994

Epoch: 5| Step: 7
Training loss: 0.1962633638023171
Validation loss: 2.609880263011242

Epoch: 5| Step: 8
Training loss: 0.16523624243255916
Validation loss: 2.5990423715465503

Epoch: 5| Step: 9
Training loss: 0.2913889442602791
Validation loss: 2.586683847121137

Epoch: 5| Step: 10
Training loss: 0.17798409368201262
Validation loss: 2.583677691340496

Epoch: 491| Step: 0
Training loss: 0.304565185057517
Validation loss: 2.586735489415683

Epoch: 5| Step: 1
Training loss: 0.210825934753033
Validation loss: 2.5415756217516634

Epoch: 5| Step: 2
Training loss: 0.12734994492937762
Validation loss: 2.5599680631578443

Epoch: 5| Step: 3
Training loss: 0.1801372166328618
Validation loss: 2.596352484218456

Epoch: 5| Step: 4
Training loss: 0.2203936136686079
Validation loss: 2.5879623723237373

Epoch: 5| Step: 5
Training loss: 0.23480736271018515
Validation loss: 2.6059306490879277

Epoch: 5| Step: 6
Training loss: 0.23986703809323434
Validation loss: 2.607156023365887

Epoch: 5| Step: 7
Training loss: 0.2772580135157376
Validation loss: 2.6309559575335557

Epoch: 5| Step: 8
Training loss: 0.2006658281690826
Validation loss: 2.6163885688183695

Epoch: 5| Step: 9
Training loss: 0.19432186670018833
Validation loss: 2.5958809330553345

Epoch: 5| Step: 10
Training loss: 0.22084156690549242
Validation loss: 2.5694754672281706

Epoch: 492| Step: 0
Training loss: 0.1373811275692316
Validation loss: 2.591089393585193

Epoch: 5| Step: 1
Training loss: 0.1748121995217527
Validation loss: 2.5851259359941485

Epoch: 5| Step: 2
Training loss: 0.21065367925071568
Validation loss: 2.549411537526763

Epoch: 5| Step: 3
Training loss: 0.1541105424901929
Validation loss: 2.553158135743267

Epoch: 5| Step: 4
Training loss: 0.3074393590974443
Validation loss: 2.5243033643036354

Epoch: 5| Step: 5
Training loss: 0.3061428646585335
Validation loss: 2.558721601004581

Epoch: 5| Step: 6
Training loss: 0.22721543443359624
Validation loss: 2.575809549466226

Epoch: 5| Step: 7
Training loss: 0.2398887334259678
Validation loss: 2.534159606655502

Epoch: 5| Step: 8
Training loss: 0.18001740687696705
Validation loss: 2.5482802921314005

Epoch: 5| Step: 9
Training loss: 0.23388690988297905
Validation loss: 2.568609322751569

Epoch: 5| Step: 10
Training loss: 0.18606872455985896
Validation loss: 2.569720787642656

Epoch: 493| Step: 0
Training loss: 0.14019417996930952
Validation loss: 2.5926768631365977

Epoch: 5| Step: 1
Training loss: 0.20066492778167497
Validation loss: 2.5673035010450516

Epoch: 5| Step: 2
Training loss: 0.3175665807561283
Validation loss: 2.5387199106364733

Epoch: 5| Step: 3
Training loss: 0.10421911995205851
Validation loss: 2.5681738442818305

Epoch: 5| Step: 4
Training loss: 0.1872088834683879
Validation loss: 2.6009749054718183

Epoch: 5| Step: 5
Training loss: 0.31802348104041767
Validation loss: 2.5527226008834214

Epoch: 5| Step: 6
Training loss: 0.16889429700305697
Validation loss: 2.5883923955473245

Epoch: 5| Step: 7
Training loss: 0.2991217000159964
Validation loss: 2.58724012369247

Epoch: 5| Step: 8
Training loss: 0.1067838840145793
Validation loss: 2.584045015074232

Epoch: 5| Step: 9
Training loss: 0.22417834845018528
Validation loss: 2.606572973782448

Epoch: 5| Step: 10
Training loss: 0.1959181740460914
Validation loss: 2.583213383261294

Epoch: 494| Step: 0
Training loss: 0.23367998866027748
Validation loss: 2.5886262698405105

Epoch: 5| Step: 1
Training loss: 0.12077361135151335
Validation loss: 2.5771309819139168

Epoch: 5| Step: 2
Training loss: 0.195827139890076
Validation loss: 2.595515295235398

Epoch: 5| Step: 3
Training loss: 0.29307175415000125
Validation loss: 2.5547703158845776

Epoch: 5| Step: 4
Training loss: 0.1850620561341255
Validation loss: 2.5485240208739715

Epoch: 5| Step: 5
Training loss: 0.18749203267653972
Validation loss: 2.5838717601800973

Epoch: 5| Step: 6
Training loss: 0.15735392417326732
Validation loss: 2.569385268433351

Epoch: 5| Step: 7
Training loss: 0.2791472747933111
Validation loss: 2.5462441004274488

Epoch: 5| Step: 8
Training loss: 0.3666765025654707
Validation loss: 2.5771917548950287

Epoch: 5| Step: 9
Training loss: 0.1081909780535509
Validation loss: 2.5874342780604107

Epoch: 5| Step: 10
Training loss: 0.19463728538809055
Validation loss: 2.571935851264715

Epoch: 495| Step: 0
Training loss: 0.23995896190964597
Validation loss: 2.5638272569577363

Epoch: 5| Step: 1
Training loss: 0.15656408094989888
Validation loss: 2.579445464413316

Epoch: 5| Step: 2
Training loss: 0.2001301263888871
Validation loss: 2.6161018589562812

Epoch: 5| Step: 3
Training loss: 0.33338627047201724
Validation loss: 2.6064564878821637

Epoch: 5| Step: 4
Training loss: 0.15673018817863663
Validation loss: 2.632975852730579

Epoch: 5| Step: 5
Training loss: 0.3063649317084294
Validation loss: 2.6099435443435537

Epoch: 5| Step: 6
Training loss: 0.2723519165250361
Validation loss: 2.607894639647215

Epoch: 5| Step: 7
Training loss: 0.0970775480663078
Validation loss: 2.6711049184195685

Epoch: 5| Step: 8
Training loss: 0.18818521464292648
Validation loss: 2.616225025079804

Epoch: 5| Step: 9
Training loss: 0.2351927557836222
Validation loss: 2.6096166801274685

Epoch: 5| Step: 10
Training loss: 0.2801499044675186
Validation loss: 2.630752226205645

Epoch: 496| Step: 0
Training loss: 0.14205414366155147
Validation loss: 2.601113623815115

Epoch: 5| Step: 1
Training loss: 0.2511145067923106
Validation loss: 2.5887265990534187

Epoch: 5| Step: 2
Training loss: 0.18403677548498631
Validation loss: 2.5966691295444604

Epoch: 5| Step: 3
Training loss: 0.3228502692388812
Validation loss: 2.5614553093306975

Epoch: 5| Step: 4
Training loss: 0.28725930276220796
Validation loss: 2.585449483993591

Epoch: 5| Step: 5
Training loss: 0.16589677707891196
Validation loss: 2.5653761508019004

Epoch: 5| Step: 6
Training loss: 0.21802370376781163
Validation loss: 2.509386873544707

Epoch: 5| Step: 7
Training loss: 0.2078786278681643
Validation loss: 2.521808160856589

Epoch: 5| Step: 8
Training loss: 0.22521999948376503
Validation loss: 2.5268745357679214

Epoch: 5| Step: 9
Training loss: 0.2986126665264596
Validation loss: 2.555805630569489

Epoch: 5| Step: 10
Training loss: 0.2200871962498137
Validation loss: 2.5714790239764582

Epoch: 497| Step: 0
Training loss: 0.20691612929654513
Validation loss: 2.605869893595299

Epoch: 5| Step: 1
Training loss: 0.128864360996873
Validation loss: 2.6743987533919804

Epoch: 5| Step: 2
Training loss: 0.2552968896601667
Validation loss: 2.6553459496556986

Epoch: 5| Step: 3
Training loss: 0.2182761236638765
Validation loss: 2.7130600592788037

Epoch: 5| Step: 4
Training loss: 0.2541291945355687
Validation loss: 2.6949906382754945

Epoch: 5| Step: 5
Training loss: 0.2307953540828591
Validation loss: 2.709434862366501

Epoch: 5| Step: 6
Training loss: 0.23058324329857907
Validation loss: 2.6820356100847063

Epoch: 5| Step: 7
Training loss: 0.3840300989722765
Validation loss: 2.662376664547164

Epoch: 5| Step: 8
Training loss: 0.18914047477555485
Validation loss: 2.6453232923181336

Epoch: 5| Step: 9
Training loss: 0.21476265503851288
Validation loss: 2.5975650169011764

Epoch: 5| Step: 10
Training loss: 0.3077098888408694
Validation loss: 2.5927511012285107

Epoch: 498| Step: 0
Training loss: 0.2154998730677919
Validation loss: 2.5408772798233725

Epoch: 5| Step: 1
Training loss: 0.273051125161815
Validation loss: 2.5141590769177276

Epoch: 5| Step: 2
Training loss: 0.3546146359991529
Validation loss: 2.498860806178741

Epoch: 5| Step: 3
Training loss: 0.23468150124839035
Validation loss: 2.5257185933724733

Epoch: 5| Step: 4
Training loss: 0.163612805270536
Validation loss: 2.534874613289253

Epoch: 5| Step: 5
Training loss: 0.2514934190236066
Validation loss: 2.558865396381948

Epoch: 5| Step: 6
Training loss: 0.26528670703435286
Validation loss: 2.5943288126383814

Epoch: 5| Step: 7
Training loss: 0.2410791168172709
Validation loss: 2.6247060115980947

Epoch: 5| Step: 8
Training loss: 0.22027335901423026
Validation loss: 2.6174557451196168

Epoch: 5| Step: 9
Training loss: 0.37337263972555196
Validation loss: 2.6457769555701627

Epoch: 5| Step: 10
Training loss: 0.17684905716192026
Validation loss: 2.61356180810953

Epoch: 499| Step: 0
Training loss: 0.19988796553269791
Validation loss: 2.670931537448044

Epoch: 5| Step: 1
Training loss: 0.25162897771712944
Validation loss: 2.665726607184073

Epoch: 5| Step: 2
Training loss: 0.27796003882324705
Validation loss: 2.670203038350176

Epoch: 5| Step: 3
Training loss: 0.30664904394558984
Validation loss: 2.64163440552534

Epoch: 5| Step: 4
Training loss: 0.2860081502004896
Validation loss: 2.6309214603678863

Epoch: 5| Step: 5
Training loss: 0.19280728600498906
Validation loss: 2.627184019361216

Epoch: 5| Step: 6
Training loss: 0.22007003218152793
Validation loss: 2.6042094365371176

Epoch: 5| Step: 7
Training loss: 0.30751889792964937
Validation loss: 2.5984614330003497

Epoch: 5| Step: 8
Training loss: 0.15920621264794999
Validation loss: 2.593025675696556

Epoch: 5| Step: 9
Training loss: 0.29838941196655117
Validation loss: 2.544062016428593

Epoch: 5| Step: 10
Training loss: 0.18181605737431197
Validation loss: 2.5390894451872956

Epoch: 500| Step: 0
Training loss: 0.45649730433600927
Validation loss: 2.56964431187853

Epoch: 5| Step: 1
Training loss: 0.320325223158313
Validation loss: 2.518316041397825

Epoch: 5| Step: 2
Training loss: 0.1876301214591643
Validation loss: 2.5280297832982788

Epoch: 5| Step: 3
Training loss: 0.16436253088807867
Validation loss: 2.5411425802805163

Epoch: 5| Step: 4
Training loss: 0.3096418207894973
Validation loss: 2.542102630749763

Epoch: 5| Step: 5
Training loss: 0.3823386198135366
Validation loss: 2.562451585001647

Epoch: 5| Step: 6
Training loss: 0.31534646179315495
Validation loss: 2.529876464948065

Epoch: 5| Step: 7
Training loss: 0.1439532372248469
Validation loss: 2.583827993692384

Epoch: 5| Step: 8
Training loss: 0.2400764473466386
Validation loss: 2.6080662313591083

Epoch: 5| Step: 9
Training loss: 0.2363510357178772
Validation loss: 2.593876160173773

Epoch: 5| Step: 10
Training loss: 0.3519215022369959
Validation loss: 2.615021293450073

Epoch: 501| Step: 0
Training loss: 0.3010945855501753
Validation loss: 2.582460576718955

Epoch: 5| Step: 1
Training loss: 0.5235806454458928
Validation loss: 2.618401072816295

Epoch: 5| Step: 2
Training loss: 0.4312969755765415
Validation loss: 2.570554564599711

Epoch: 5| Step: 3
Training loss: 0.16689932622656406
Validation loss: 2.5570511706204497

Epoch: 5| Step: 4
Training loss: 0.2171709596386957
Validation loss: 2.532177277097915

Epoch: 5| Step: 5
Training loss: 0.28779923995595624
Validation loss: 2.53517391926071

Epoch: 5| Step: 6
Training loss: 0.30124061977455685
Validation loss: 2.5638358328191084

Epoch: 5| Step: 7
Training loss: 0.1942624475511824
Validation loss: 2.575685189752124

Epoch: 5| Step: 8
Training loss: 0.504834023337377
Validation loss: 2.5768997517612986

Epoch: 5| Step: 9
Training loss: 0.522640675083167
Validation loss: 2.5684722467589713

Epoch: 5| Step: 10
Training loss: 0.25892595233438237
Validation loss: 2.6065034068501607

Epoch: 502| Step: 0
Training loss: 0.2983977391184497
Validation loss: 2.617975190466936

Epoch: 5| Step: 1
Training loss: 0.3222080410459791
Validation loss: 2.626750658190089

Epoch: 5| Step: 2
Training loss: 0.6067225610307319
Validation loss: 2.6262892102821995

Epoch: 5| Step: 3
Training loss: 0.4853599133147286
Validation loss: 2.6241554556075273

Epoch: 5| Step: 4
Training loss: 0.37649494451571025
Validation loss: 2.5999571909310655

Epoch: 5| Step: 5
Training loss: 0.35095626695952964
Validation loss: 2.5725652056012867

Epoch: 5| Step: 6
Training loss: 0.2968881378278441
Validation loss: 2.5544077106092007

Epoch: 5| Step: 7
Training loss: 0.2894620067762731
Validation loss: 2.507121319049983

Epoch: 5| Step: 8
Training loss: 0.4456291077091459
Validation loss: 2.538675056221762

Epoch: 5| Step: 9
Training loss: 0.28058505927384847
Validation loss: 2.5526039670255374

Epoch: 5| Step: 10
Training loss: 0.3885896682064725
Validation loss: 2.484066460653441

Epoch: 503| Step: 0
Training loss: 0.26061611485144026
Validation loss: 2.4844479598186933

Epoch: 5| Step: 1
Training loss: 0.33519958802774874
Validation loss: 2.5199368709275234

Epoch: 5| Step: 2
Training loss: 0.36906095179815285
Validation loss: 2.524098376717239

Epoch: 5| Step: 3
Training loss: 0.37029785336529747
Validation loss: 2.5453556858229676

Epoch: 5| Step: 4
Training loss: 0.3767458093608832
Validation loss: 2.6121931689639273

Epoch: 5| Step: 5
Training loss: 0.2073427681658912
Validation loss: 2.5998520457622254

Epoch: 5| Step: 6
Training loss: 0.28930931894857287
Validation loss: 2.612778463319607

Epoch: 5| Step: 7
Training loss: 0.3681652767252441
Validation loss: 2.580459077612727

Epoch: 5| Step: 8
Training loss: 0.28154340645408416
Validation loss: 2.5845720541207386

Epoch: 5| Step: 9
Training loss: 0.4929350217232376
Validation loss: 2.605936359875967

Epoch: 5| Step: 10
Training loss: 0.4384153191630897
Validation loss: 2.6261519811257883

Epoch: 504| Step: 0
Training loss: 0.224864599097638
Validation loss: 2.656383501398097

Epoch: 5| Step: 1
Training loss: 0.39610926731269613
Validation loss: 2.6667215574931955

Epoch: 5| Step: 2
Training loss: 0.295921022667421
Validation loss: 2.6676025043153326

Epoch: 5| Step: 3
Training loss: 0.3585307529272788
Validation loss: 2.648308565490449

Epoch: 5| Step: 4
Training loss: 0.3462537916437212
Validation loss: 2.612037224634981

Epoch: 5| Step: 5
Training loss: 0.3020693087884873
Validation loss: 2.588728965892126

Epoch: 5| Step: 6
Training loss: 0.2556645765656388
Validation loss: 2.518415921306645

Epoch: 5| Step: 7
Training loss: 0.30676587699336133
Validation loss: 2.518554414702379

Epoch: 5| Step: 8
Training loss: 0.29369977663744085
Validation loss: 2.479879739126634

Epoch: 5| Step: 9
Training loss: 0.4576265745221841
Validation loss: 2.488193334166521

Epoch: 5| Step: 10
Training loss: 0.2657417573691244
Validation loss: 2.5273990108054614

Epoch: 505| Step: 0
Training loss: 0.36439650607888907
Validation loss: 2.5218807121940325

Epoch: 5| Step: 1
Training loss: 0.2393045963557301
Validation loss: 2.563470623112999

Epoch: 5| Step: 2
Training loss: 0.38179310512067055
Validation loss: 2.6029192393418645

Epoch: 5| Step: 3
Training loss: 0.1735760006899519
Validation loss: 2.629728046834563

Epoch: 5| Step: 4
Training loss: 0.19525833332445772
Validation loss: 2.638977539748118

Epoch: 5| Step: 5
Training loss: 0.26463398066937355
Validation loss: 2.6667547102463036

Epoch: 5| Step: 6
Training loss: 0.2048348300629937
Validation loss: 2.645505588519521

Epoch: 5| Step: 7
Training loss: 0.3464396115602919
Validation loss: 2.6708245036828537

Epoch: 5| Step: 8
Training loss: 0.23929287400545263
Validation loss: 2.6932567059394725

Epoch: 5| Step: 9
Training loss: 0.2959501768899535
Validation loss: 2.621522284405132

Epoch: 5| Step: 10
Training loss: 0.2663261751890775
Validation loss: 2.624628963704767

Epoch: 506| Step: 0
Training loss: 0.21837398022990573
Validation loss: 2.587995950541026

Epoch: 5| Step: 1
Training loss: 0.22615960076319203
Validation loss: 2.56527294209388

Epoch: 5| Step: 2
Training loss: 0.3048013083331621
Validation loss: 2.5308223126560825

Epoch: 5| Step: 3
Training loss: 0.4075748226009316
Validation loss: 2.5507024073076376

Epoch: 5| Step: 4
Training loss: 0.2050802866503913
Validation loss: 2.5380150493982527

Epoch: 5| Step: 5
Training loss: 0.26415932420751154
Validation loss: 2.5422504216305315

Epoch: 5| Step: 6
Training loss: 0.35378887091007377
Validation loss: 2.5301102665472155

Epoch: 5| Step: 7
Training loss: 0.27099617622992833
Validation loss: 2.593339974860708

Epoch: 5| Step: 8
Training loss: 0.30746799060096947
Validation loss: 2.6285626918435847

Epoch: 5| Step: 9
Training loss: 0.2112216977623328
Validation loss: 2.6647742700323556

Epoch: 5| Step: 10
Training loss: 0.3119263987529175
Validation loss: 2.6358891636313677

Epoch: 507| Step: 0
Training loss: 0.28334579820188205
Validation loss: 2.6797279869792083

Epoch: 5| Step: 1
Training loss: 0.3521664306478406
Validation loss: 2.6545260747239974

Epoch: 5| Step: 2
Training loss: 0.2656368926134813
Validation loss: 2.6378845374643247

Epoch: 5| Step: 3
Training loss: 0.4190449807290551
Validation loss: 2.6291982349675433

Epoch: 5| Step: 4
Training loss: 0.26679178235847206
Validation loss: 2.5960673691592024

Epoch: 5| Step: 5
Training loss: 0.21151250597884633
Validation loss: 2.589563887217402

Epoch: 5| Step: 6
Training loss: 0.28511092727212645
Validation loss: 2.6057556263027797

Epoch: 5| Step: 7
Training loss: 0.27910754315513453
Validation loss: 2.5779911388102144

Epoch: 5| Step: 8
Training loss: 0.3718503567199822
Validation loss: 2.5470463704969006

Epoch: 5| Step: 9
Training loss: 0.4690615572275018
Validation loss: 2.559032128528486

Epoch: 5| Step: 10
Training loss: 0.23186483869883162
Validation loss: 2.550500894388692

Epoch: 508| Step: 0
Training loss: 0.33249733692551164
Validation loss: 2.5759835506244704

Epoch: 5| Step: 1
Training loss: 0.4176180250412608
Validation loss: 2.565464433017176

Epoch: 5| Step: 2
Training loss: 0.23209613124128695
Validation loss: 2.55348624736572

Epoch: 5| Step: 3
Training loss: 0.3926209573485987
Validation loss: 2.578398572739082

Epoch: 5| Step: 4
Training loss: 0.3169084495932287
Validation loss: 2.612401175117696

Epoch: 5| Step: 5
Training loss: 0.289263500747542
Validation loss: 2.560526995933187

Epoch: 5| Step: 6
Training loss: 0.3096973868369127
Validation loss: 2.607879915771008

Epoch: 5| Step: 7
Training loss: 0.24737732550340924
Validation loss: 2.5737720290922557

Epoch: 5| Step: 8
Training loss: 0.36692804950544494
Validation loss: 2.5323990422118055

Epoch: 5| Step: 9
Training loss: 0.3688841640351431
Validation loss: 2.5252893966550984

Epoch: 5| Step: 10
Training loss: 0.2222778216402901
Validation loss: 2.5225172057175245

Epoch: 509| Step: 0
Training loss: 0.2887709539208765
Validation loss: 2.5291627983386284

Epoch: 5| Step: 1
Training loss: 0.3064971393744192
Validation loss: 2.4744976567648536

Epoch: 5| Step: 2
Training loss: 0.35134577958951674
Validation loss: 2.515923365872805

Epoch: 5| Step: 3
Training loss: 0.3739781165490842
Validation loss: 2.4928157725666185

Epoch: 5| Step: 4
Training loss: 0.29636305034219024
Validation loss: 2.5012244527948186

Epoch: 5| Step: 5
Training loss: 0.3284759801468647
Validation loss: 2.550576681710501

Epoch: 5| Step: 6
Training loss: 0.1974108888190668
Validation loss: 2.5638388220897608

Epoch: 5| Step: 7
Training loss: 0.26522902819001354
Validation loss: 2.6507160755537518

Epoch: 5| Step: 8
Training loss: 0.20636839286283218
Validation loss: 2.673015546545512

Epoch: 5| Step: 9
Training loss: 0.4063487666453413
Validation loss: 2.699737064068545

Epoch: 5| Step: 10
Training loss: 0.31901061259153407
Validation loss: 2.73545046047265

Epoch: 510| Step: 0
Training loss: 0.3277269628548206
Validation loss: 2.7160909924410546

Epoch: 5| Step: 1
Training loss: 0.3123795515631743
Validation loss: 2.7103084798910633

Epoch: 5| Step: 2
Training loss: 0.31856233177158166
Validation loss: 2.690976420617685

Epoch: 5| Step: 3
Training loss: 0.3315627102037747
Validation loss: 2.6500690591674805

Epoch: 5| Step: 4
Training loss: 0.3219599111832738
Validation loss: 2.6244388894738466

Epoch: 5| Step: 5
Training loss: 0.3158854566586127
Validation loss: 2.6124817247944314

Epoch: 5| Step: 6
Training loss: 0.34574970642747643
Validation loss: 2.561964753978773

Epoch: 5| Step: 7
Training loss: 0.30710835835383915
Validation loss: 2.6274000272073526

Epoch: 5| Step: 8
Training loss: 0.3132575152150982
Validation loss: 2.6261959174148353

Epoch: 5| Step: 9
Training loss: 0.27712649580466214
Validation loss: 2.6444835690352186

Epoch: 5| Step: 10
Training loss: 0.2282202352020774
Validation loss: 2.652024868123511

Epoch: 511| Step: 0
Training loss: 0.24824664564353913
Validation loss: 2.6417525402836763

Epoch: 5| Step: 1
Training loss: 0.3077565437615921
Validation loss: 2.603160354281011

Epoch: 5| Step: 2
Training loss: 0.2936682298154468
Validation loss: 2.5652846116371557

Epoch: 5| Step: 3
Training loss: 0.18828440540882851
Validation loss: 2.5699647195075928

Epoch: 5| Step: 4
Training loss: 0.3880235450018361
Validation loss: 2.5795118830822408

Epoch: 5| Step: 5
Training loss: 0.3346992894330388
Validation loss: 2.546386323590451

Epoch: 5| Step: 6
Training loss: 0.24827391078849484
Validation loss: 2.519432664872403

Epoch: 5| Step: 7
Training loss: 0.1859821434281309
Validation loss: 2.5216066589084214

Epoch: 5| Step: 8
Training loss: 0.25856033869986433
Validation loss: 2.540221122125858

Epoch: 5| Step: 9
Training loss: 0.32859445095667716
Validation loss: 2.510300587441002

Epoch: 5| Step: 10
Training loss: 0.2770137569844975
Validation loss: 2.525988169844595

Epoch: 512| Step: 0
Training loss: 0.3603531131866089
Validation loss: 2.509773968321662

Epoch: 5| Step: 1
Training loss: 0.23944796576861552
Validation loss: 2.5561356424116566

Epoch: 5| Step: 2
Training loss: 0.3954930055460359
Validation loss: 2.5513777285838435

Epoch: 5| Step: 3
Training loss: 0.18345406473742895
Validation loss: 2.596180906050454

Epoch: 5| Step: 4
Training loss: 0.3219483865946015
Validation loss: 2.6218807039848193

Epoch: 5| Step: 5
Training loss: 0.31970398950793155
Validation loss: 2.582733001844358

Epoch: 5| Step: 6
Training loss: 0.3039069815580296
Validation loss: 2.591104573014942

Epoch: 5| Step: 7
Training loss: 0.3255767647058078
Validation loss: 2.562787725370917

Epoch: 5| Step: 8
Training loss: 0.2650689588199234
Validation loss: 2.553041997232507

Epoch: 5| Step: 9
Training loss: 0.20951307569249103
Validation loss: 2.5241531758678866

Epoch: 5| Step: 10
Training loss: 0.2925666338264473
Validation loss: 2.5409260731096697

Epoch: 513| Step: 0
Training loss: 0.4367461862970768
Validation loss: 2.5362592156879584

Epoch: 5| Step: 1
Training loss: 0.25744313454718926
Validation loss: 2.554385896954748

Epoch: 5| Step: 2
Training loss: 0.20690212181454343
Validation loss: 2.5543558202012857

Epoch: 5| Step: 3
Training loss: 0.20068510662910113
Validation loss: 2.5646407316776823

Epoch: 5| Step: 4
Training loss: 0.21199345310129322
Validation loss: 2.580333781043219

Epoch: 5| Step: 5
Training loss: 0.3284328469800689
Validation loss: 2.570884002964296

Epoch: 5| Step: 6
Training loss: 0.2601647143662356
Validation loss: 2.6349947733264028

Epoch: 5| Step: 7
Training loss: 0.19453351122909232
Validation loss: 2.6030694539406984

Epoch: 5| Step: 8
Training loss: 0.1600216555841424
Validation loss: 2.615760733895181

Epoch: 5| Step: 9
Training loss: 0.16521172266770998
Validation loss: 2.613983535228555

Epoch: 5| Step: 10
Training loss: 0.2661281896492315
Validation loss: 2.604852736801781

Epoch: 514| Step: 0
Training loss: 0.3329721247100588
Validation loss: 2.599719484758455

Epoch: 5| Step: 1
Training loss: 0.3181234433336525
Validation loss: 2.6162764865067247

Epoch: 5| Step: 2
Training loss: 0.23949468914685965
Validation loss: 2.616940234715418

Epoch: 5| Step: 3
Training loss: 0.12192165096296108
Validation loss: 2.591143305783403

Epoch: 5| Step: 4
Training loss: 0.21014216386462897
Validation loss: 2.608808423892263

Epoch: 5| Step: 5
Training loss: 0.2631618512006787
Validation loss: 2.627559678603271

Epoch: 5| Step: 6
Training loss: 0.2813329574309756
Validation loss: 2.570156393513649

Epoch: 5| Step: 7
Training loss: 0.15944527778212034
Validation loss: 2.6107245002454142

Epoch: 5| Step: 8
Training loss: 0.2293536640659198
Validation loss: 2.6125721828409434

Epoch: 5| Step: 9
Training loss: 0.23831899531597092
Validation loss: 2.5897276351864216

Epoch: 5| Step: 10
Training loss: 0.23698788756089306
Validation loss: 2.542103719899847

Epoch: 515| Step: 0
Training loss: 0.23951071004772576
Validation loss: 2.5605673626422942

Epoch: 5| Step: 1
Training loss: 0.1283753255382188
Validation loss: 2.5280979026207118

Epoch: 5| Step: 2
Training loss: 0.16911589549638095
Validation loss: 2.535825516804814

Epoch: 5| Step: 3
Training loss: 0.223466578172029
Validation loss: 2.500417473504335

Epoch: 5| Step: 4
Training loss: 0.25271806738006414
Validation loss: 2.488627451886232

Epoch: 5| Step: 5
Training loss: 0.2765001711681036
Validation loss: 2.4861385096999506

Epoch: 5| Step: 6
Training loss: 0.203970561354227
Validation loss: 2.493931661506748

Epoch: 5| Step: 7
Training loss: 0.3150770737951834
Validation loss: 2.5007487734428273

Epoch: 5| Step: 8
Training loss: 0.16155526817376437
Validation loss: 2.505451460667322

Epoch: 5| Step: 9
Training loss: 0.2857229402308494
Validation loss: 2.5710492786630574

Epoch: 5| Step: 10
Training loss: 0.2722273751842133
Validation loss: 2.5807990050252343

Epoch: 516| Step: 0
Training loss: 0.2163205111215199
Validation loss: 2.6209706219356796

Epoch: 5| Step: 1
Training loss: 0.3259413012706262
Validation loss: 2.6452516238164523

Epoch: 5| Step: 2
Training loss: 0.2013829244537936
Validation loss: 2.62917586979379

Epoch: 5| Step: 3
Training loss: 0.20685254787644466
Validation loss: 2.672447347179968

Epoch: 5| Step: 4
Training loss: 0.3022054419965417
Validation loss: 2.6250833926844552

Epoch: 5| Step: 5
Training loss: 0.24085156314541376
Validation loss: 2.621319389323241

Epoch: 5| Step: 6
Training loss: 0.2502133234168579
Validation loss: 2.582574745551992

Epoch: 5| Step: 7
Training loss: 0.20640668588862282
Validation loss: 2.6015181526115114

Epoch: 5| Step: 8
Training loss: 0.15846690804116814
Validation loss: 2.5913320302061393

Epoch: 5| Step: 9
Training loss: 0.14458388581523088
Validation loss: 2.559656659139464

Epoch: 5| Step: 10
Training loss: 0.17996109989159761
Validation loss: 2.5463054273505223

Epoch: 517| Step: 0
Training loss: 0.26666349872306777
Validation loss: 2.54259038917137

Epoch: 5| Step: 1
Training loss: 0.2084803072739759
Validation loss: 2.5413040078578915

Epoch: 5| Step: 2
Training loss: 0.23857498824643095
Validation loss: 2.532909551662713

Epoch: 5| Step: 3
Training loss: 0.24764239004684174
Validation loss: 2.5671357085416964

Epoch: 5| Step: 4
Training loss: 0.15136806118620713
Validation loss: 2.5355291481179516

Epoch: 5| Step: 5
Training loss: 0.24070014616235164
Validation loss: 2.589186786681547

Epoch: 5| Step: 6
Training loss: 0.1376723344717475
Validation loss: 2.554067951456039

Epoch: 5| Step: 7
Training loss: 0.2758206466329183
Validation loss: 2.575523819576343

Epoch: 5| Step: 8
Training loss: 0.18774608516802227
Validation loss: 2.5981121809468064

Epoch: 5| Step: 9
Training loss: 0.21979712306989166
Validation loss: 2.5994457539370384

Epoch: 5| Step: 10
Training loss: 0.27198381931811155
Validation loss: 2.5621345778697706

Epoch: 518| Step: 0
Training loss: 0.22195391561172
Validation loss: 2.569129364094217

Epoch: 5| Step: 1
Training loss: 0.28324812169895797
Validation loss: 2.525067791941998

Epoch: 5| Step: 2
Training loss: 0.20542984728345443
Validation loss: 2.5161301086582295

Epoch: 5| Step: 3
Training loss: 0.21482569878778726
Validation loss: 2.5212262138238586

Epoch: 5| Step: 4
Training loss: 0.23727081590839358
Validation loss: 2.513694236762929

Epoch: 5| Step: 5
Training loss: 0.17314363577278197
Validation loss: 2.549082757601157

Epoch: 5| Step: 6
Training loss: 0.19324727132111935
Validation loss: 2.5329992219980983

Epoch: 5| Step: 7
Training loss: 0.14665972704639796
Validation loss: 2.5425762449934415

Epoch: 5| Step: 8
Training loss: 0.16028795990497516
Validation loss: 2.5890559976312812

Epoch: 5| Step: 9
Training loss: 0.16360350389377512
Validation loss: 2.575382206331642

Epoch: 5| Step: 10
Training loss: 0.2362993317395446
Validation loss: 2.576303483809536

Epoch: 519| Step: 0
Training loss: 0.1838618917616332
Validation loss: 2.5712855514724797

Epoch: 5| Step: 1
Training loss: 0.18600937271665471
Validation loss: 2.5882126694891565

Epoch: 5| Step: 2
Training loss: 0.2180002169301765
Validation loss: 2.5935674386405547

Epoch: 5| Step: 3
Training loss: 0.24597058165804467
Validation loss: 2.575582231903575

Epoch: 5| Step: 4
Training loss: 0.18745860993994543
Validation loss: 2.5946283702686737

Epoch: 5| Step: 5
Training loss: 0.3064589478551191
Validation loss: 2.5584695027660946

Epoch: 5| Step: 6
Training loss: 0.14995138006217612
Validation loss: 2.535377496705687

Epoch: 5| Step: 7
Training loss: 0.21111931735657924
Validation loss: 2.5517953693058026

Epoch: 5| Step: 8
Training loss: 0.19725978011735154
Validation loss: 2.598685977280948

Epoch: 5| Step: 9
Training loss: 0.24971791088167106
Validation loss: 2.5325975901107225

Epoch: 5| Step: 10
Training loss: 0.14230890854704387
Validation loss: 2.5316344667639443

Epoch: 520| Step: 0
Training loss: 0.12339958471747296
Validation loss: 2.5593575478620263

Epoch: 5| Step: 1
Training loss: 0.1836110877920573
Validation loss: 2.511343784329487

Epoch: 5| Step: 2
Training loss: 0.1298688077905303
Validation loss: 2.5697972222243397

Epoch: 5| Step: 3
Training loss: 0.21131218199605856
Validation loss: 2.5575200033170926

Epoch: 5| Step: 4
Training loss: 0.20039073431000878
Validation loss: 2.5538659903742804

Epoch: 5| Step: 5
Training loss: 0.1381027200689938
Validation loss: 2.548002959460459

Epoch: 5| Step: 6
Training loss: 0.2733418297295147
Validation loss: 2.587194243628958

Epoch: 5| Step: 7
Training loss: 0.23018217049601367
Validation loss: 2.559819837530463

Epoch: 5| Step: 8
Training loss: 0.22936064825972105
Validation loss: 2.560592622799531

Epoch: 5| Step: 9
Training loss: 0.23219738866046555
Validation loss: 2.586132264666376

Epoch: 5| Step: 10
Training loss: 0.24384888574964741
Validation loss: 2.565759480139585

Epoch: 521| Step: 0
Training loss: 0.09838648526244315
Validation loss: 2.615134217727056

Epoch: 5| Step: 1
Training loss: 0.18834187334947627
Validation loss: 2.5915120493922377

Epoch: 5| Step: 2
Training loss: 0.19206061710560626
Validation loss: 2.6082822591884267

Epoch: 5| Step: 3
Training loss: 0.14208687454739377
Validation loss: 2.584985383083805

Epoch: 5| Step: 4
Training loss: 0.24557545745899814
Validation loss: 2.594724116162379

Epoch: 5| Step: 5
Training loss: 0.2625445958130358
Validation loss: 2.625859896621949

Epoch: 5| Step: 6
Training loss: 0.2055718156188932
Validation loss: 2.587673535303256

Epoch: 5| Step: 7
Training loss: 0.1511317729741657
Validation loss: 2.607866301665689

Epoch: 5| Step: 8
Training loss: 0.3062034819754129
Validation loss: 2.626245994985152

Epoch: 5| Step: 9
Training loss: 0.1415432711356286
Validation loss: 2.6263850689583497

Epoch: 5| Step: 10
Training loss: 0.22693110767923066
Validation loss: 2.62186420377877

Epoch: 522| Step: 0
Training loss: 0.11214777724052759
Validation loss: 2.597911620403874

Epoch: 5| Step: 1
Training loss: 0.17227644529550146
Validation loss: 2.569924765755658

Epoch: 5| Step: 2
Training loss: 0.3141502082347711
Validation loss: 2.574922430891353

Epoch: 5| Step: 3
Training loss: 0.2762865548739387
Validation loss: 2.578927120597683

Epoch: 5| Step: 4
Training loss: 0.21063587027665137
Validation loss: 2.590094767546474

Epoch: 5| Step: 5
Training loss: 0.17611714166270812
Validation loss: 2.580520000710506

Epoch: 5| Step: 6
Training loss: 0.20384851310588636
Validation loss: 2.6276127215393266

Epoch: 5| Step: 7
Training loss: 0.16762687023059675
Validation loss: 2.607685180804882

Epoch: 5| Step: 8
Training loss: 0.1632136398861546
Validation loss: 2.6287416023418797

Epoch: 5| Step: 9
Training loss: 0.18833510867128841
Validation loss: 2.5945951639316984

Epoch: 5| Step: 10
Training loss: 0.30139645912084523
Validation loss: 2.6005421994475157

Epoch: 523| Step: 0
Training loss: 0.1719342368089081
Validation loss: 2.623788029873785

Epoch: 5| Step: 1
Training loss: 0.17857692467371805
Validation loss: 2.56823546308263

Epoch: 5| Step: 2
Training loss: 0.14847572988805077
Validation loss: 2.5746264194572794

Epoch: 5| Step: 3
Training loss: 0.20929519320869902
Validation loss: 2.5784276790196894

Epoch: 5| Step: 4
Training loss: 0.30232480554100477
Validation loss: 2.6197784181460992

Epoch: 5| Step: 5
Training loss: 0.12334809823100013
Validation loss: 2.586135630137823

Epoch: 5| Step: 6
Training loss: 0.1696788046823679
Validation loss: 2.642589357125142

Epoch: 5| Step: 7
Training loss: 0.29137118591355415
Validation loss: 2.653601728727314

Epoch: 5| Step: 8
Training loss: 0.22240348321829304
Validation loss: 2.602543999584274

Epoch: 5| Step: 9
Training loss: 0.2502074870736588
Validation loss: 2.648610421489629

Epoch: 5| Step: 10
Training loss: 0.1802941633814493
Validation loss: 2.604498090430154

Epoch: 524| Step: 0
Training loss: 0.15821469229336402
Validation loss: 2.5886027836331036

Epoch: 5| Step: 1
Training loss: 0.20037975653608836
Validation loss: 2.613532491811305

Epoch: 5| Step: 2
Training loss: 0.18987623140929002
Validation loss: 2.6089787621104077

Epoch: 5| Step: 3
Training loss: 0.19834940223820136
Validation loss: 2.6324588166472918

Epoch: 5| Step: 4
Training loss: 0.13933530125580998
Validation loss: 2.5760021012434646

Epoch: 5| Step: 5
Training loss: 0.1651336466606697
Validation loss: 2.569551628254799

Epoch: 5| Step: 6
Training loss: 0.24051907579752674
Validation loss: 2.586294508119411

Epoch: 5| Step: 7
Training loss: 0.25337930432141864
Validation loss: 2.57905437266043

Epoch: 5| Step: 8
Training loss: 0.1575269613387869
Validation loss: 2.554323991729561

Epoch: 5| Step: 9
Training loss: 0.2133818218110577
Validation loss: 2.533902303845086

Epoch: 5| Step: 10
Training loss: 0.3130697064110056
Validation loss: 2.5778482481875535

Epoch: 525| Step: 0
Training loss: 0.2882635829649955
Validation loss: 2.614074577784827

Epoch: 5| Step: 1
Training loss: 0.25227660475694824
Validation loss: 2.6136775516499227

Epoch: 5| Step: 2
Training loss: 0.22486387015657983
Validation loss: 2.657188187592172

Epoch: 5| Step: 3
Training loss: 0.12584141571754034
Validation loss: 2.6478004251972624

Epoch: 5| Step: 4
Training loss: 0.17776315057907868
Validation loss: 2.6520647812648854

Epoch: 5| Step: 5
Training loss: 0.14896290425865708
Validation loss: 2.6158371001926883

Epoch: 5| Step: 6
Training loss: 0.18587957970698718
Validation loss: 2.6369924717835884

Epoch: 5| Step: 7
Training loss: 0.2631003225085327
Validation loss: 2.634952149331175

Epoch: 5| Step: 8
Training loss: 0.1365735713717655
Validation loss: 2.6224979482952597

Epoch: 5| Step: 9
Training loss: 0.2029317707031942
Validation loss: 2.6329183721824965

Epoch: 5| Step: 10
Training loss: 0.19979948594527897
Validation loss: 2.606261483274831

Epoch: 526| Step: 0
Training loss: 0.23037067039745154
Validation loss: 2.621136059463965

Epoch: 5| Step: 1
Training loss: 0.18181692816900868
Validation loss: 2.5898878508632857

Epoch: 5| Step: 2
Training loss: 0.1679957889262564
Validation loss: 2.6042141824304657

Epoch: 5| Step: 3
Training loss: 0.266442387610537
Validation loss: 2.6241526449516104

Epoch: 5| Step: 4
Training loss: 0.20051447850020496
Validation loss: 2.590848319418119

Epoch: 5| Step: 5
Training loss: 0.2108487012945284
Validation loss: 2.6130659224156503

Epoch: 5| Step: 6
Training loss: 0.11673425204449657
Validation loss: 2.62137814081392

Epoch: 5| Step: 7
Training loss: 0.1702294799149916
Validation loss: 2.5729010713810494

Epoch: 5| Step: 8
Training loss: 0.1274359690942338
Validation loss: 2.6161607932727358

Epoch: 5| Step: 9
Training loss: 0.260788159835998
Validation loss: 2.582798024770321

Epoch: 5| Step: 10
Training loss: 0.4821884579009296
Validation loss: 2.59613349835759

Epoch: 527| Step: 0
Training loss: 0.2500523720959235
Validation loss: 2.5750419929474067

Epoch: 5| Step: 1
Training loss: 0.25898457465300767
Validation loss: 2.571192707158065

Epoch: 5| Step: 2
Training loss: 0.13067371806006162
Validation loss: 2.5399270326751364

Epoch: 5| Step: 3
Training loss: 0.31452578540343423
Validation loss: 2.5195108427973456

Epoch: 5| Step: 4
Training loss: 0.265058994316803
Validation loss: 2.555307998406761

Epoch: 5| Step: 5
Training loss: 0.26937495413069545
Validation loss: 2.584032296273422

Epoch: 5| Step: 6
Training loss: 0.25067729399626204
Validation loss: 2.633381815576058

Epoch: 5| Step: 7
Training loss: 0.22729923231911572
Validation loss: 2.635985863608567

Epoch: 5| Step: 8
Training loss: 0.14480513320249175
Validation loss: 2.620735241380208

Epoch: 5| Step: 9
Training loss: 0.2959126006409882
Validation loss: 2.643844722107017

Epoch: 5| Step: 10
Training loss: 0.23444619686843765
Validation loss: 2.631077444924797

Epoch: 528| Step: 0
Training loss: 0.26769997265793866
Validation loss: 2.626219583822625

Epoch: 5| Step: 1
Training loss: 0.20506626276495565
Validation loss: 2.5892109275095034

Epoch: 5| Step: 2
Training loss: 0.11278894755804224
Validation loss: 2.560074686685311

Epoch: 5| Step: 3
Training loss: 0.1683656306332649
Validation loss: 2.55516912074912

Epoch: 5| Step: 4
Training loss: 0.16298378240503014
Validation loss: 2.5382458616562933

Epoch: 5| Step: 5
Training loss: 0.21895950366674413
Validation loss: 2.540149539198109

Epoch: 5| Step: 6
Training loss: 0.24920229005419597
Validation loss: 2.5602875879844134

Epoch: 5| Step: 7
Training loss: 0.2985325517125892
Validation loss: 2.568719271298484

Epoch: 5| Step: 8
Training loss: 0.1952344070715418
Validation loss: 2.550544844273688

Epoch: 5| Step: 9
Training loss: 0.29335279089069993
Validation loss: 2.593570861679235

Epoch: 5| Step: 10
Training loss: 0.21689825007562433
Validation loss: 2.6322225189161492

Epoch: 529| Step: 0
Training loss: 0.21972314620011277
Validation loss: 2.6344852585832905

Epoch: 5| Step: 1
Training loss: 0.2646692697131173
Validation loss: 2.657334745970272

Epoch: 5| Step: 2
Training loss: 0.18907858015673473
Validation loss: 2.63918940060532

Epoch: 5| Step: 3
Training loss: 0.22203633527415353
Validation loss: 2.679025268331958

Epoch: 5| Step: 4
Training loss: 0.29584910670840747
Validation loss: 2.699354117516099

Epoch: 5| Step: 5
Training loss: 0.15484729807048125
Validation loss: 2.6207792899990285

Epoch: 5| Step: 6
Training loss: 0.11718324812487134
Validation loss: 2.589290199112232

Epoch: 5| Step: 7
Training loss: 0.24524609341168813
Validation loss: 2.596381370716319

Epoch: 5| Step: 8
Training loss: 0.1931333376649443
Validation loss: 2.5890020033499552

Epoch: 5| Step: 9
Training loss: 0.3053780335655485
Validation loss: 2.542320037034441

Epoch: 5| Step: 10
Training loss: 0.2096309908208163
Validation loss: 2.539598538063348

Epoch: 530| Step: 0
Training loss: 0.22518440114275798
Validation loss: 2.529009466628906

Epoch: 5| Step: 1
Training loss: 0.20052468721393674
Validation loss: 2.5698241454268564

Epoch: 5| Step: 2
Training loss: 0.2576707103273365
Validation loss: 2.5241120059010806

Epoch: 5| Step: 3
Training loss: 0.23775778790232735
Validation loss: 2.5461213253516974

Epoch: 5| Step: 4
Training loss: 0.24277831891308974
Validation loss: 2.544418804404142

Epoch: 5| Step: 5
Training loss: 0.12043631811631048
Validation loss: 2.5421776042812465

Epoch: 5| Step: 6
Training loss: 0.1759834927497242
Validation loss: 2.5905341286430605

Epoch: 5| Step: 7
Training loss: 0.2192281113200742
Validation loss: 2.603842072141046

Epoch: 5| Step: 8
Training loss: 0.19842691693657868
Validation loss: 2.640344745287611

Epoch: 5| Step: 9
Training loss: 0.17777697084184968
Validation loss: 2.6284347999098494

Epoch: 5| Step: 10
Training loss: 0.20889961448978991
Validation loss: 2.6348255303027055

Epoch: 531| Step: 0
Training loss: 0.18970466903712951
Validation loss: 2.6719563367526997

Epoch: 5| Step: 1
Training loss: 0.2579380943248974
Validation loss: 2.640845512672413

Epoch: 5| Step: 2
Training loss: 0.1716538816723036
Validation loss: 2.6459400335386056

Epoch: 5| Step: 3
Training loss: 0.25109795035722465
Validation loss: 2.6533883505331293

Epoch: 5| Step: 4
Training loss: 0.17568188083867506
Validation loss: 2.61815036870267

Epoch: 5| Step: 5
Training loss: 0.16202094067338677
Validation loss: 2.6427364297249625

Epoch: 5| Step: 6
Training loss: 0.15671129083424812
Validation loss: 2.624340232289013

Epoch: 5| Step: 7
Training loss: 0.12093863242750268
Validation loss: 2.6581195035966316

Epoch: 5| Step: 8
Training loss: 0.1849838146011444
Validation loss: 2.582802223391727

Epoch: 5| Step: 9
Training loss: 0.16314432389620528
Validation loss: 2.6027727771660114

Epoch: 5| Step: 10
Training loss: 0.26070090835081616
Validation loss: 2.598399950354692

Epoch: 532| Step: 0
Training loss: 0.12617615848982178
Validation loss: 2.571002150425362

Epoch: 5| Step: 1
Training loss: 0.11417923368976522
Validation loss: 2.570243933527041

Epoch: 5| Step: 2
Training loss: 0.15692558268126963
Validation loss: 2.573534401423187

Epoch: 5| Step: 3
Training loss: 0.26414444571718604
Validation loss: 2.5866508901421743

Epoch: 5| Step: 4
Training loss: 0.12827695784781837
Validation loss: 2.560607864876122

Epoch: 5| Step: 5
Training loss: 0.24311389175721587
Validation loss: 2.6038115924240426

Epoch: 5| Step: 6
Training loss: 0.12082079534252242
Validation loss: 2.587278573456416

Epoch: 5| Step: 7
Training loss: 0.25353081162493674
Validation loss: 2.6110306020994183

Epoch: 5| Step: 8
Training loss: 0.23780107582262403
Validation loss: 2.579952097959447

Epoch: 5| Step: 9
Training loss: 0.09871935116801292
Validation loss: 2.606667160738262

Epoch: 5| Step: 10
Training loss: 0.2613501871600958
Validation loss: 2.6347321300563302

Epoch: 533| Step: 0
Training loss: 0.09062109396179059
Validation loss: 2.6482361360539097

Epoch: 5| Step: 1
Training loss: 0.1348359988472318
Validation loss: 2.6568019498578335

Epoch: 5| Step: 2
Training loss: 0.13984410376477382
Validation loss: 2.6031607619958637

Epoch: 5| Step: 3
Training loss: 0.10679644668984353
Validation loss: 2.6097918378841127

Epoch: 5| Step: 4
Training loss: 0.19289550626750174
Validation loss: 2.624927262891827

Epoch: 5| Step: 5
Training loss: 0.1823601571344856
Validation loss: 2.6135922746604976

Epoch: 5| Step: 6
Training loss: 0.25108281717670444
Validation loss: 2.577564516418698

Epoch: 5| Step: 7
Training loss: 0.20025177136243769
Validation loss: 2.6221226804124336

Epoch: 5| Step: 8
Training loss: 0.2625477316012124
Validation loss: 2.5900375330090815

Epoch: 5| Step: 9
Training loss: 0.21497037797176388
Validation loss: 2.5898674080802744

Epoch: 5| Step: 10
Training loss: 0.1660166684286201
Validation loss: 2.5696054850114285

Epoch: 534| Step: 0
Training loss: 0.09582757157216162
Validation loss: 2.5549282906174335

Epoch: 5| Step: 1
Training loss: 0.16574839233104957
Validation loss: 2.5860813974360086

Epoch: 5| Step: 2
Training loss: 0.23092426930624058
Validation loss: 2.537152462553413

Epoch: 5| Step: 3
Training loss: 0.24007726975154267
Validation loss: 2.5557380456253465

Epoch: 5| Step: 4
Training loss: 0.24411005973219332
Validation loss: 2.539184635023566

Epoch: 5| Step: 5
Training loss: 0.12503627161440636
Validation loss: 2.5977416129423188

Epoch: 5| Step: 6
Training loss: 0.23620733216406004
Validation loss: 2.5820879804092316

Epoch: 5| Step: 7
Training loss: 0.162286225335014
Validation loss: 2.5803364337686254

Epoch: 5| Step: 8
Training loss: 0.11962347602197364
Validation loss: 2.598352221051738

Epoch: 5| Step: 9
Training loss: 0.1672396527259213
Validation loss: 2.603971271362656

Epoch: 5| Step: 10
Training loss: 0.16436789675873734
Validation loss: 2.6348807144056408

Epoch: 535| Step: 0
Training loss: 0.21689867086981585
Validation loss: 2.6286746282050486

Epoch: 5| Step: 1
Training loss: 0.1783022872488467
Validation loss: 2.599044263420651

Epoch: 5| Step: 2
Training loss: 0.10165127212445647
Validation loss: 2.6570278295605725

Epoch: 5| Step: 3
Training loss: 0.13756212597457737
Validation loss: 2.6578788362109393

Epoch: 5| Step: 4
Training loss: 0.1914249333196581
Validation loss: 2.665086291056903

Epoch: 5| Step: 5
Training loss: 0.1216500448243603
Validation loss: 2.6344471513693524

Epoch: 5| Step: 6
Training loss: 0.20787240039888247
Validation loss: 2.646032658372112

Epoch: 5| Step: 7
Training loss: 0.24639587173666966
Validation loss: 2.6509266660830897

Epoch: 5| Step: 8
Training loss: 0.17066416350344452
Validation loss: 2.6321849555274826

Epoch: 5| Step: 9
Training loss: 0.22958025764238607
Validation loss: 2.6202435780234126

Epoch: 5| Step: 10
Training loss: 0.2170227952824953
Validation loss: 2.584775890747323

Epoch: 536| Step: 0
Training loss: 0.21941610656242536
Validation loss: 2.606953355452121

Epoch: 5| Step: 1
Training loss: 0.12822245084305964
Validation loss: 2.579961757481414

Epoch: 5| Step: 2
Training loss: 0.12428023942700064
Validation loss: 2.592316343097927

Epoch: 5| Step: 3
Training loss: 0.1782087137699712
Validation loss: 2.590048112058537

Epoch: 5| Step: 4
Training loss: 0.17053757306225784
Validation loss: 2.569693393466694

Epoch: 5| Step: 5
Training loss: 0.16162948356127224
Validation loss: 2.5391736714121067

Epoch: 5| Step: 6
Training loss: 0.16764457047799303
Validation loss: 2.589382673228632

Epoch: 5| Step: 7
Training loss: 0.31433443234304803
Validation loss: 2.5927708232070734

Epoch: 5| Step: 8
Training loss: 0.1974922049770742
Validation loss: 2.585200258040324

Epoch: 5| Step: 9
Training loss: 0.09730990026439977
Validation loss: 2.6318635897738365

Epoch: 5| Step: 10
Training loss: 0.18111216672803093
Validation loss: 2.622057383149026

Epoch: 537| Step: 0
Training loss: 0.18156816206161253
Validation loss: 2.609486091758682

Epoch: 5| Step: 1
Training loss: 0.1394085858381719
Validation loss: 2.660044795598306

Epoch: 5| Step: 2
Training loss: 0.258628161811584
Validation loss: 2.6375385441986836

Epoch: 5| Step: 3
Training loss: 0.23178743274409816
Validation loss: 2.6392406842964915

Epoch: 5| Step: 4
Training loss: 0.14263554292204894
Validation loss: 2.6645569181805016

Epoch: 5| Step: 5
Training loss: 0.22648360259814895
Validation loss: 2.604389769482834

Epoch: 5| Step: 6
Training loss: 0.22905615106919985
Validation loss: 2.5627554829412715

Epoch: 5| Step: 7
Training loss: 0.150429813431514
Validation loss: 2.590972397585222

Epoch: 5| Step: 8
Training loss: 0.20320144461963988
Validation loss: 2.5860033177157975

Epoch: 5| Step: 9
Training loss: 0.18220370191177385
Validation loss: 2.60775261265728

Epoch: 5| Step: 10
Training loss: 0.16703102151053978
Validation loss: 2.582403975112145

Epoch: 538| Step: 0
Training loss: 0.17491505511177424
Validation loss: 2.5784593039126853

Epoch: 5| Step: 1
Training loss: 0.1766947849932203
Validation loss: 2.579938289778422

Epoch: 5| Step: 2
Training loss: 0.28164285137762096
Validation loss: 2.613140247401919

Epoch: 5| Step: 3
Training loss: 0.18892061962947035
Validation loss: 2.586459027052125

Epoch: 5| Step: 4
Training loss: 0.19458198307114793
Validation loss: 2.5737411362432834

Epoch: 5| Step: 5
Training loss: 0.11881520432420106
Validation loss: 2.5610773803154396

Epoch: 5| Step: 6
Training loss: 0.2112782604596765
Validation loss: 2.5538293785192243

Epoch: 5| Step: 7
Training loss: 0.18868556318524177
Validation loss: 2.507535992615779

Epoch: 5| Step: 8
Training loss: 0.17280138224870126
Validation loss: 2.520036737461033

Epoch: 5| Step: 9
Training loss: 0.1344447877882428
Validation loss: 2.5528457262933006

Epoch: 5| Step: 10
Training loss: 0.30342977087703865
Validation loss: 2.567813111275586

Epoch: 539| Step: 0
Training loss: 0.118166962895383
Validation loss: 2.561879574881139

Epoch: 5| Step: 1
Training loss: 0.1899238911768461
Validation loss: 2.5900797380909264

Epoch: 5| Step: 2
Training loss: 0.2433620168012873
Validation loss: 2.591758051105442

Epoch: 5| Step: 3
Training loss: 0.11576983942595219
Validation loss: 2.5844321763679896

Epoch: 5| Step: 4
Training loss: 0.09224979793001803
Validation loss: 2.6126028385402322

Epoch: 5| Step: 5
Training loss: 0.14937405268715898
Validation loss: 2.585729861494811

Epoch: 5| Step: 6
Training loss: 0.17913765330455475
Validation loss: 2.6084124213226643

Epoch: 5| Step: 7
Training loss: 0.27866279544481837
Validation loss: 2.6122298352819895

Epoch: 5| Step: 8
Training loss: 0.17467262564713743
Validation loss: 2.623828683253623

Epoch: 5| Step: 9
Training loss: 0.19145321756328143
Validation loss: 2.607369660180416

Epoch: 5| Step: 10
Training loss: 0.2355408204345937
Validation loss: 2.5986921272032357

Epoch: 540| Step: 0
Training loss: 0.14314392905850978
Validation loss: 2.5928354460943326

Epoch: 5| Step: 1
Training loss: 0.29495366664084394
Validation loss: 2.5963261424519497

Epoch: 5| Step: 2
Training loss: 0.17773811629832575
Validation loss: 2.6044045819947823

Epoch: 5| Step: 3
Training loss: 0.17712428633856372
Validation loss: 2.590006171733183

Epoch: 5| Step: 4
Training loss: 0.18741474597597488
Validation loss: 2.559020664895352

Epoch: 5| Step: 5
Training loss: 0.25968518840252147
Validation loss: 2.5800680729319017

Epoch: 5| Step: 6
Training loss: 0.1524427837869205
Validation loss: 2.5443596320549737

Epoch: 5| Step: 7
Training loss: 0.1176736364525309
Validation loss: 2.5523005225905524

Epoch: 5| Step: 8
Training loss: 0.1290387498579622
Validation loss: 2.565099270790283

Epoch: 5| Step: 9
Training loss: 0.2079727161152527
Validation loss: 2.562270338530172

Epoch: 5| Step: 10
Training loss: 0.20177826643863814
Validation loss: 2.578187063594403

Epoch: 541| Step: 0
Training loss: 0.22336210499363027
Validation loss: 2.582681696421167

Epoch: 5| Step: 1
Training loss: 0.13438425143132213
Validation loss: 2.549603965346297

Epoch: 5| Step: 2
Training loss: 0.13885212989647844
Validation loss: 2.5049782910600733

Epoch: 5| Step: 3
Training loss: 0.2028838431716176
Validation loss: 2.5663843695109474

Epoch: 5| Step: 4
Training loss: 0.11580524233960696
Validation loss: 2.5402676184601245

Epoch: 5| Step: 5
Training loss: 0.15787419515383444
Validation loss: 2.5454432780708687

Epoch: 5| Step: 6
Training loss: 0.2693572519345826
Validation loss: 2.5365523962913232

Epoch: 5| Step: 7
Training loss: 0.2921699314649505
Validation loss: 2.5587657207805985

Epoch: 5| Step: 8
Training loss: 0.10787120823920572
Validation loss: 2.5639899512018642

Epoch: 5| Step: 9
Training loss: 0.1368404051530242
Validation loss: 2.597737034835194

Epoch: 5| Step: 10
Training loss: 0.11515935379281327
Validation loss: 2.5501597883833518

Epoch: 542| Step: 0
Training loss: 0.26792519051314656
Validation loss: 2.5684335773463323

Epoch: 5| Step: 1
Training loss: 0.14510859057092332
Validation loss: 2.5886345422034474

Epoch: 5| Step: 2
Training loss: 0.14670274987489204
Validation loss: 2.592231828793083

Epoch: 5| Step: 3
Training loss: 0.20414056359694177
Validation loss: 2.588797439876747

Epoch: 5| Step: 4
Training loss: 0.17073367759811417
Validation loss: 2.5844825513240073

Epoch: 5| Step: 5
Training loss: 0.13134767043102996
Validation loss: 2.580984744646985

Epoch: 5| Step: 6
Training loss: 0.12796053623672454
Validation loss: 2.5748903289611023

Epoch: 5| Step: 7
Training loss: 0.1569365557502041
Validation loss: 2.554326068275189

Epoch: 5| Step: 8
Training loss: 0.2350946821046986
Validation loss: 2.5913313901200072

Epoch: 5| Step: 9
Training loss: 0.13880386920970522
Validation loss: 2.5980542423532618

Epoch: 5| Step: 10
Training loss: 0.251418603886365
Validation loss: 2.5956446284272596

Epoch: 543| Step: 0
Training loss: 0.1482140779545078
Validation loss: 2.5788324930964532

Epoch: 5| Step: 1
Training loss: 0.17989376916973077
Validation loss: 2.5767775926561334

Epoch: 5| Step: 2
Training loss: 0.13371537957041346
Validation loss: 2.5775313831609843

Epoch: 5| Step: 3
Training loss: 0.10687748207589774
Validation loss: 2.5637316361352274

Epoch: 5| Step: 4
Training loss: 0.15475840292211415
Validation loss: 2.553340951743314

Epoch: 5| Step: 5
Training loss: 0.23971387254290494
Validation loss: 2.5881442018251013

Epoch: 5| Step: 6
Training loss: 0.30163959545482455
Validation loss: 2.576032660708465

Epoch: 5| Step: 7
Training loss: 0.2190347078953606
Validation loss: 2.5952009681070876

Epoch: 5| Step: 8
Training loss: 0.12035483986967987
Validation loss: 2.6383538758048197

Epoch: 5| Step: 9
Training loss: 0.1200624860868292
Validation loss: 2.622327229066321

Epoch: 5| Step: 10
Training loss: 0.20958088921897064
Validation loss: 2.6336595086837296

Epoch: 544| Step: 0
Training loss: 0.162589161739757
Validation loss: 2.6358881249045596

Epoch: 5| Step: 1
Training loss: 0.21552031366855023
Validation loss: 2.6079554197304953

Epoch: 5| Step: 2
Training loss: 0.17357636017828923
Validation loss: 2.590779639392983

Epoch: 5| Step: 3
Training loss: 0.09017918000933152
Validation loss: 2.5753732911480176

Epoch: 5| Step: 4
Training loss: 0.14661549739541418
Validation loss: 2.5846407701523604

Epoch: 5| Step: 5
Training loss: 0.2460283010735594
Validation loss: 2.6169892335328777

Epoch: 5| Step: 6
Training loss: 0.1261884991349772
Validation loss: 2.5881778925836536

Epoch: 5| Step: 7
Training loss: 0.12586661279516478
Validation loss: 2.5691245304384682

Epoch: 5| Step: 8
Training loss: 0.23398189957317087
Validation loss: 2.586532783501482

Epoch: 5| Step: 9
Training loss: 0.11388852686682334
Validation loss: 2.5671544446798022

Epoch: 5| Step: 10
Training loss: 0.27052446169519834
Validation loss: 2.5765544324910623

Epoch: 545| Step: 0
Training loss: 0.12790621476647074
Validation loss: 2.537428639203259

Epoch: 5| Step: 1
Training loss: 0.23093423872052846
Validation loss: 2.5922220817294077

Epoch: 5| Step: 2
Training loss: 0.1852540667205904
Validation loss: 2.5438825213341296

Epoch: 5| Step: 3
Training loss: 0.16516497847879266
Validation loss: 2.5951491613633673

Epoch: 5| Step: 4
Training loss: 0.21754818544251361
Validation loss: 2.5912230925910182

Epoch: 5| Step: 5
Training loss: 0.1892255517412786
Validation loss: 2.646365380530371

Epoch: 5| Step: 6
Training loss: 0.14947796371410108
Validation loss: 2.610783754299732

Epoch: 5| Step: 7
Training loss: 0.14527803878903064
Validation loss: 2.625293002400742

Epoch: 5| Step: 8
Training loss: 0.173609118781314
Validation loss: 2.6220022743019813

Epoch: 5| Step: 9
Training loss: 0.15389843693376948
Validation loss: 2.575764814421168

Epoch: 5| Step: 10
Training loss: 0.2734560551478482
Validation loss: 2.561301640733289

Epoch: 546| Step: 0
Training loss: 0.1783030916319827
Validation loss: 2.5180694926149205

Epoch: 5| Step: 1
Training loss: 0.12199323891300523
Validation loss: 2.5440704226131556

Epoch: 5| Step: 2
Training loss: 0.22332398358714464
Validation loss: 2.529411011486408

Epoch: 5| Step: 3
Training loss: 0.21105402800749787
Validation loss: 2.52464668228958

Epoch: 5| Step: 4
Training loss: 0.23341746232772076
Validation loss: 2.5173315894904458

Epoch: 5| Step: 5
Training loss: 0.13746550165151042
Validation loss: 2.5550040840755397

Epoch: 5| Step: 6
Training loss: 0.14799612705416507
Validation loss: 2.5699910693713535

Epoch: 5| Step: 7
Training loss: 0.13050940673913966
Validation loss: 2.616874128255354

Epoch: 5| Step: 8
Training loss: 0.2699738337941896
Validation loss: 2.5948894126561473

Epoch: 5| Step: 9
Training loss: 0.1904126086279124
Validation loss: 2.5998331486146857

Epoch: 5| Step: 10
Training loss: 0.1613132333694483
Validation loss: 2.6190068848383676

Epoch: 547| Step: 0
Training loss: 0.18612749706576195
Validation loss: 2.6125934498351016

Epoch: 5| Step: 1
Training loss: 0.14469600643215857
Validation loss: 2.604735938741863

Epoch: 5| Step: 2
Training loss: 0.21218391675269113
Validation loss: 2.5747610141551425

Epoch: 5| Step: 3
Training loss: 0.07326329880680676
Validation loss: 2.5968727915883183

Epoch: 5| Step: 4
Training loss: 0.15451000077169294
Validation loss: 2.5691311552587264

Epoch: 5| Step: 5
Training loss: 0.22627595341656165
Validation loss: 2.5575325301941136

Epoch: 5| Step: 6
Training loss: 0.15271661440521325
Validation loss: 2.5508037457413795

Epoch: 5| Step: 7
Training loss: 0.1212845498933298
Validation loss: 2.523010251262792

Epoch: 5| Step: 8
Training loss: 0.16586533082500807
Validation loss: 2.53948598505843

Epoch: 5| Step: 9
Training loss: 0.1236422041027226
Validation loss: 2.527411328914267

Epoch: 5| Step: 10
Training loss: 0.21746737094282376
Validation loss: 2.5477563845466595

Epoch: 548| Step: 0
Training loss: 0.11462109026746202
Validation loss: 2.5392012141272913

Epoch: 5| Step: 1
Training loss: 0.14834165615961045
Validation loss: 2.542519765300666

Epoch: 5| Step: 2
Training loss: 0.16333076237419733
Validation loss: 2.5431154476979287

Epoch: 5| Step: 3
Training loss: 0.1865295289328166
Validation loss: 2.5880006251268695

Epoch: 5| Step: 4
Training loss: 0.21325002308942664
Validation loss: 2.559730163313462

Epoch: 5| Step: 5
Training loss: 0.20716583627757904
Validation loss: 2.583329388962459

Epoch: 5| Step: 6
Training loss: 0.14799992790776184
Validation loss: 2.612959219359055

Epoch: 5| Step: 7
Training loss: 0.2206253910736638
Validation loss: 2.599826990544604

Epoch: 5| Step: 8
Training loss: 0.21272822844346015
Validation loss: 2.6074546775952903

Epoch: 5| Step: 9
Training loss: 0.1996373005871084
Validation loss: 2.594547431084785

Epoch: 5| Step: 10
Training loss: 0.12171934409235281
Validation loss: 2.620276842360148

Epoch: 549| Step: 0
Training loss: 0.2441616201909956
Validation loss: 2.590579456734689

Epoch: 5| Step: 1
Training loss: 0.13799383391204942
Validation loss: 2.582967192047831

Epoch: 5| Step: 2
Training loss: 0.19861613553386084
Validation loss: 2.5653840929130043

Epoch: 5| Step: 3
Training loss: 0.1129527508419044
Validation loss: 2.5673803910335002

Epoch: 5| Step: 4
Training loss: 0.16053562472945007
Validation loss: 2.577822831420452

Epoch: 5| Step: 5
Training loss: 0.20076317613052114
Validation loss: 2.590040820160344

Epoch: 5| Step: 6
Training loss: 0.16455758417482533
Validation loss: 2.620927054355228

Epoch: 5| Step: 7
Training loss: 0.13741261295423965
Validation loss: 2.633978655685889

Epoch: 5| Step: 8
Training loss: 0.14314450160268402
Validation loss: 2.649266950309297

Epoch: 5| Step: 9
Training loss: 0.23808863937935254
Validation loss: 2.655459032998905

Epoch: 5| Step: 10
Training loss: 0.17204880596252076
Validation loss: 2.623579134896494

Epoch: 550| Step: 0
Training loss: 0.19352139322295234
Validation loss: 2.6423114716988194

Epoch: 5| Step: 1
Training loss: 0.28833090501839514
Validation loss: 2.605224659929964

Epoch: 5| Step: 2
Training loss: 0.1030487427025263
Validation loss: 2.600692712513515

Epoch: 5| Step: 3
Training loss: 0.1264739014905663
Validation loss: 2.6011755200741757

Epoch: 5| Step: 4
Training loss: 0.190289812802817
Validation loss: 2.5782220756921546

Epoch: 5| Step: 5
Training loss: 0.1964122897837758
Validation loss: 2.5643333571601326

Epoch: 5| Step: 6
Training loss: 0.1612448274074809
Validation loss: 2.6448495964413654

Epoch: 5| Step: 7
Training loss: 0.1966551218914298
Validation loss: 2.5647550035525533

Epoch: 5| Step: 8
Training loss: 0.11802358395024554
Validation loss: 2.5656827044449306

Epoch: 5| Step: 9
Training loss: 0.13911572466484087
Validation loss: 2.6042887029458686

Epoch: 5| Step: 10
Training loss: 0.12859216631149384
Validation loss: 2.6059621748428046

Epoch: 551| Step: 0
Training loss: 0.17417305039060296
Validation loss: 2.5904202160950187

Epoch: 5| Step: 1
Training loss: 0.14862228486602483
Validation loss: 2.628291670409047

Epoch: 5| Step: 2
Training loss: 0.11183099776433407
Validation loss: 2.6270353524654975

Epoch: 5| Step: 3
Training loss: 0.1734076407650564
Validation loss: 2.645336791182112

Epoch: 5| Step: 4
Training loss: 0.29637583377967014
Validation loss: 2.620211330810842

Epoch: 5| Step: 5
Training loss: 0.2563656319264861
Validation loss: 2.619732428793724

Epoch: 5| Step: 6
Training loss: 0.174275230438508
Validation loss: 2.6177205585649186

Epoch: 5| Step: 7
Training loss: 0.15646117364533504
Validation loss: 2.5247216220567497

Epoch: 5| Step: 8
Training loss: 0.13378315237314903
Validation loss: 2.519896195183488

Epoch: 5| Step: 9
Training loss: 0.13426254190878112
Validation loss: 2.499416535494432

Epoch: 5| Step: 10
Training loss: 0.19230777225813672
Validation loss: 2.5303055968702455

Epoch: 552| Step: 0
Training loss: 0.31717215956625316
Validation loss: 2.5164869244964203

Epoch: 5| Step: 1
Training loss: 0.20842252947793707
Validation loss: 2.505583386712702

Epoch: 5| Step: 2
Training loss: 0.14476714343917968
Validation loss: 2.5593544061111615

Epoch: 5| Step: 3
Training loss: 0.18435169573775545
Validation loss: 2.540389325185877

Epoch: 5| Step: 4
Training loss: 0.27893006305921986
Validation loss: 2.586140984152739

Epoch: 5| Step: 5
Training loss: 0.1714964784161232
Validation loss: 2.5636919072376294

Epoch: 5| Step: 6
Training loss: 0.08365169604609812
Validation loss: 2.568760371548408

Epoch: 5| Step: 7
Training loss: 0.1446387690053862
Validation loss: 2.580463026702181

Epoch: 5| Step: 8
Training loss: 0.14960636902819668
Validation loss: 2.6171442617543397

Epoch: 5| Step: 9
Training loss: 0.13522571311197748
Validation loss: 2.6207712638734773

Epoch: 5| Step: 10
Training loss: 0.2367527433732914
Validation loss: 2.61207745485047

Epoch: 553| Step: 0
Training loss: 0.220734467433009
Validation loss: 2.605740559768606

Epoch: 5| Step: 1
Training loss: 0.1741556928044935
Validation loss: 2.6144894583593055

Epoch: 5| Step: 2
Training loss: 0.12208650863014911
Validation loss: 2.6198974537783513

Epoch: 5| Step: 3
Training loss: 0.22010267492481755
Validation loss: 2.6081071887765774

Epoch: 5| Step: 4
Training loss: 0.1558412330987187
Validation loss: 2.6066836961647804

Epoch: 5| Step: 5
Training loss: 0.15490608425335448
Validation loss: 2.60814593001397

Epoch: 5| Step: 6
Training loss: 0.13822551536217328
Validation loss: 2.545780013185136

Epoch: 5| Step: 7
Training loss: 0.2201715921697004
Validation loss: 2.5642189435227523

Epoch: 5| Step: 8
Training loss: 0.10177405954353737
Validation loss: 2.570486383571716

Epoch: 5| Step: 9
Training loss: 0.2307028147601384
Validation loss: 2.535773753659826

Epoch: 5| Step: 10
Training loss: 0.1710394413859834
Validation loss: 2.571245504083179

Epoch: 554| Step: 0
Training loss: 0.16819364994114563
Validation loss: 2.563937804526894

Epoch: 5| Step: 1
Training loss: 0.16463539596802065
Validation loss: 2.5909714576064524

Epoch: 5| Step: 2
Training loss: 0.27542085684552786
Validation loss: 2.6055181800278757

Epoch: 5| Step: 3
Training loss: 0.14435651887953777
Validation loss: 2.584540168509667

Epoch: 5| Step: 4
Training loss: 0.19286872765743587
Validation loss: 2.6081739980930663

Epoch: 5| Step: 5
Training loss: 0.13759597279132718
Validation loss: 2.631701774844865

Epoch: 5| Step: 6
Training loss: 0.24202443601499024
Validation loss: 2.6092971496385093

Epoch: 5| Step: 7
Training loss: 0.10244472341921565
Validation loss: 2.59222283730555

Epoch: 5| Step: 8
Training loss: 0.14178719027735187
Validation loss: 2.6531510190288086

Epoch: 5| Step: 9
Training loss: 0.17783618987079394
Validation loss: 2.6185084470099604

Epoch: 5| Step: 10
Training loss: 0.12455268260813981
Validation loss: 2.621173858457612

Epoch: 555| Step: 0
Training loss: 0.11901180150362249
Validation loss: 2.5954040025612524

Epoch: 5| Step: 1
Training loss: 0.18316627001596508
Validation loss: 2.547776294832962

Epoch: 5| Step: 2
Training loss: 0.0748932611611139
Validation loss: 2.565288312261399

Epoch: 5| Step: 3
Training loss: 0.13160066450882096
Validation loss: 2.5004351637098794

Epoch: 5| Step: 4
Training loss: 0.14890308519864956
Validation loss: 2.542835600896082

Epoch: 5| Step: 5
Training loss: 0.1316578333103239
Validation loss: 2.5056665640307414

Epoch: 5| Step: 6
Training loss: 0.1972566073783223
Validation loss: 2.4877605973066887

Epoch: 5| Step: 7
Training loss: 0.1681674846163625
Validation loss: 2.554525475031698

Epoch: 5| Step: 8
Training loss: 0.14641947262146376
Validation loss: 2.5453708156908226

Epoch: 5| Step: 9
Training loss: 0.33752636762333044
Validation loss: 2.581030465915629

Epoch: 5| Step: 10
Training loss: 0.2735943616798138
Validation loss: 2.5985181505041637

Epoch: 556| Step: 0
Training loss: 0.2323097150716249
Validation loss: 2.6052895101935984

Epoch: 5| Step: 1
Training loss: 0.1769775900023044
Validation loss: 2.666946270215109

Epoch: 5| Step: 2
Training loss: 0.14097215267692798
Validation loss: 2.6095846788353327

Epoch: 5| Step: 3
Training loss: 0.10227863300435912
Validation loss: 2.6050654918059197

Epoch: 5| Step: 4
Training loss: 0.20699816565403437
Validation loss: 2.60712202768518

Epoch: 5| Step: 5
Training loss: 0.0993634347963577
Validation loss: 2.6015807923507746

Epoch: 5| Step: 6
Training loss: 0.11016534182722298
Validation loss: 2.5644715291011644

Epoch: 5| Step: 7
Training loss: 0.1483686626333475
Validation loss: 2.596268867053121

Epoch: 5| Step: 8
Training loss: 0.17822585429627485
Validation loss: 2.5715505939007977

Epoch: 5| Step: 9
Training loss: 0.2240136913517568
Validation loss: 2.62145027325506

Epoch: 5| Step: 10
Training loss: 0.12672638819542428
Validation loss: 2.5971748344510583

Epoch: 557| Step: 0
Training loss: 0.20256686557795894
Validation loss: 2.6044324841758373

Epoch: 5| Step: 1
Training loss: 0.1696796554346905
Validation loss: 2.5703555017275272

Epoch: 5| Step: 2
Training loss: 0.2096639262335168
Validation loss: 2.5902604925781656

Epoch: 5| Step: 3
Training loss: 0.19051556729240987
Validation loss: 2.5599646262319338

Epoch: 5| Step: 4
Training loss: 0.2292944929138912
Validation loss: 2.550042529096323

Epoch: 5| Step: 5
Training loss: 0.22204253459980788
Validation loss: 2.565879294313559

Epoch: 5| Step: 6
Training loss: 0.06645935053268652
Validation loss: 2.586185657676621

Epoch: 5| Step: 7
Training loss: 0.1438705641044464
Validation loss: 2.567090837947181

Epoch: 5| Step: 8
Training loss: 0.15460521937216964
Validation loss: 2.6042516974236447

Epoch: 5| Step: 9
Training loss: 0.13534198055506724
Validation loss: 2.608747048506653

Epoch: 5| Step: 10
Training loss: 0.1476559896315444
Validation loss: 2.621497652425431

Epoch: 558| Step: 0
Training loss: 0.1722436765498357
Validation loss: 2.5839366095968046

Epoch: 5| Step: 1
Training loss: 0.16660462965830777
Validation loss: 2.589549389772971

Epoch: 5| Step: 2
Training loss: 0.2644892421384329
Validation loss: 2.59089367367633

Epoch: 5| Step: 3
Training loss: 0.10277242898536831
Validation loss: 2.575088304566023

Epoch: 5| Step: 4
Training loss: 0.1609492788356138
Validation loss: 2.5463879404721923

Epoch: 5| Step: 5
Training loss: 0.1364573977950352
Validation loss: 2.563995834143518

Epoch: 5| Step: 6
Training loss: 0.21593496461917328
Validation loss: 2.5460489285871977

Epoch: 5| Step: 7
Training loss: 0.17209548787676346
Validation loss: 2.563345600773407

Epoch: 5| Step: 8
Training loss: 0.26863654536363013
Validation loss: 2.570003067622224

Epoch: 5| Step: 9
Training loss: 0.15614673062864723
Validation loss: 2.530446965185747

Epoch: 5| Step: 10
Training loss: 0.1391189447247951
Validation loss: 2.548878732908933

Epoch: 559| Step: 0
Training loss: 0.20024731588648337
Validation loss: 2.5344720708495028

Epoch: 5| Step: 1
Training loss: 0.10689547917680887
Validation loss: 2.5256425473519806

Epoch: 5| Step: 2
Training loss: 0.22095338591639865
Validation loss: 2.5600018783772023

Epoch: 5| Step: 3
Training loss: 0.24456886118037988
Validation loss: 2.5248452884724286

Epoch: 5| Step: 4
Training loss: 0.16382637515973142
Validation loss: 2.5543605071719457

Epoch: 5| Step: 5
Training loss: 0.1771715390957216
Validation loss: 2.5321140088307845

Epoch: 5| Step: 6
Training loss: 0.20021641317676622
Validation loss: 2.531709692325441

Epoch: 5| Step: 7
Training loss: 0.13379974044178047
Validation loss: 2.5676420489823415

Epoch: 5| Step: 8
Training loss: 0.22933261274404299
Validation loss: 2.5852674619898606

Epoch: 5| Step: 9
Training loss: 0.1978984069348318
Validation loss: 2.570960481738699

Epoch: 5| Step: 10
Training loss: 0.1477262560581856
Validation loss: 2.6035643861037276

Epoch: 560| Step: 0
Training loss: 0.18506473339836957
Validation loss: 2.595931107570555

Epoch: 5| Step: 1
Training loss: 0.1709155373873882
Validation loss: 2.6019445220922637

Epoch: 5| Step: 2
Training loss: 0.21950160060507531
Validation loss: 2.5776667401735764

Epoch: 5| Step: 3
Training loss: 0.28613656207547483
Validation loss: 2.5979209180946246

Epoch: 5| Step: 4
Training loss: 0.16412781936427626
Validation loss: 2.618967268123672

Epoch: 5| Step: 5
Training loss: 0.21147371942389692
Validation loss: 2.632668970674336

Epoch: 5| Step: 6
Training loss: 0.08223357114121733
Validation loss: 2.5793159406545123

Epoch: 5| Step: 7
Training loss: 0.10766593344895045
Validation loss: 2.583613187680573

Epoch: 5| Step: 8
Training loss: 0.1401213129062124
Validation loss: 2.5967376913166125

Epoch: 5| Step: 9
Training loss: 0.07468689852935223
Validation loss: 2.5259142693956145

Epoch: 5| Step: 10
Training loss: 0.20694579754101872
Validation loss: 2.525078240125323

Epoch: 561| Step: 0
Training loss: 0.195238270959224
Validation loss: 2.5210226061295873

Epoch: 5| Step: 1
Training loss: 0.1866181617398698
Validation loss: 2.545545860171705

Epoch: 5| Step: 2
Training loss: 0.21455326382742143
Validation loss: 2.565947812565433

Epoch: 5| Step: 3
Training loss: 0.16064544144114595
Validation loss: 2.5766341825267034

Epoch: 5| Step: 4
Training loss: 0.20625317311013489
Validation loss: 2.5516221234720096

Epoch: 5| Step: 5
Training loss: 0.18199568061235608
Validation loss: 2.560559321990613

Epoch: 5| Step: 6
Training loss: 0.16838206406050304
Validation loss: 2.5853226369412186

Epoch: 5| Step: 7
Training loss: 0.15400505839553655
Validation loss: 2.586234961616619

Epoch: 5| Step: 8
Training loss: 0.13540378075202975
Validation loss: 2.6176896268812633

Epoch: 5| Step: 9
Training loss: 0.09724481218255493
Validation loss: 2.6346929969453767

Epoch: 5| Step: 10
Training loss: 0.10617260164962367
Validation loss: 2.6116290163208986

Epoch: 562| Step: 0
Training loss: 0.15159364188659688
Validation loss: 2.628144649824147

Epoch: 5| Step: 1
Training loss: 0.09257044921312452
Validation loss: 2.620104287648992

Epoch: 5| Step: 2
Training loss: 0.22766396364799157
Validation loss: 2.6157409951184114

Epoch: 5| Step: 3
Training loss: 0.10359198524876416
Validation loss: 2.618003250109054

Epoch: 5| Step: 4
Training loss: 0.16399544526308524
Validation loss: 2.6257865750787857

Epoch: 5| Step: 5
Training loss: 0.2234882903893245
Validation loss: 2.5863761657429825

Epoch: 5| Step: 6
Training loss: 0.1408489219396431
Validation loss: 2.6042149335428495

Epoch: 5| Step: 7
Training loss: 0.09884016035323459
Validation loss: 2.5788489097605116

Epoch: 5| Step: 8
Training loss: 0.22789240076931386
Validation loss: 2.61310062513541

Epoch: 5| Step: 9
Training loss: 0.20162871256494808
Validation loss: 2.5625374884055425

Epoch: 5| Step: 10
Training loss: 0.10565314245294093
Validation loss: 2.5896944942069644

Epoch: 563| Step: 0
Training loss: 0.17212324205205887
Validation loss: 2.594348681717666

Epoch: 5| Step: 1
Training loss: 0.16913423834497537
Validation loss: 2.5332677960081735

Epoch: 5| Step: 2
Training loss: 0.11583095022435577
Validation loss: 2.5572604104019447

Epoch: 5| Step: 3
Training loss: 0.1601138349518528
Validation loss: 2.5683115825232607

Epoch: 5| Step: 4
Training loss: 0.15627539547536226
Validation loss: 2.5548037914932302

Epoch: 5| Step: 5
Training loss: 0.16185706968126823
Validation loss: 2.5640551487391603

Epoch: 5| Step: 6
Training loss: 0.20632416157669412
Validation loss: 2.541726145123193

Epoch: 5| Step: 7
Training loss: 0.15583173081225113
Validation loss: 2.5655193653492794

Epoch: 5| Step: 8
Training loss: 0.1430142017720041
Validation loss: 2.5832928284861256

Epoch: 5| Step: 9
Training loss: 0.22866025244158203
Validation loss: 2.5642859895217494

Epoch: 5| Step: 10
Training loss: 0.24926514955957235
Validation loss: 2.59991519648086

Epoch: 564| Step: 0
Training loss: 0.2410044152792229
Validation loss: 2.5999116757948393

Epoch: 5| Step: 1
Training loss: 0.10780724844374277
Validation loss: 2.5740313314770624

Epoch: 5| Step: 2
Training loss: 0.14642861894613418
Validation loss: 2.594164444940195

Epoch: 5| Step: 3
Training loss: 0.14287100066405553
Validation loss: 2.573571319680064

Epoch: 5| Step: 4
Training loss: 0.11651911064756736
Validation loss: 2.539731412732803

Epoch: 5| Step: 5
Training loss: 0.21254553517359107
Validation loss: 2.5627124447201304

Epoch: 5| Step: 6
Training loss: 0.18747951475135777
Validation loss: 2.5516209132983523

Epoch: 5| Step: 7
Training loss: 0.15131955781790107
Validation loss: 2.539578258802048

Epoch: 5| Step: 8
Training loss: 0.21088200298274498
Validation loss: 2.5539323776359586

Epoch: 5| Step: 9
Training loss: 0.2355873145947304
Validation loss: 2.58364724264243

Epoch: 5| Step: 10
Training loss: 0.10769406859295583
Validation loss: 2.564357003161693

Epoch: 565| Step: 0
Training loss: 0.14882033320177526
Validation loss: 2.5782670445246443

Epoch: 5| Step: 1
Training loss: 0.252807337209564
Validation loss: 2.600650228183845

Epoch: 5| Step: 2
Training loss: 0.13656849097285417
Validation loss: 2.5928318253251947

Epoch: 5| Step: 3
Training loss: 0.22801398783417362
Validation loss: 2.5580876036150677

Epoch: 5| Step: 4
Training loss: 0.12818514819338292
Validation loss: 2.6020461323979363

Epoch: 5| Step: 5
Training loss: 0.16159527621399622
Validation loss: 2.6093671512565546

Epoch: 5| Step: 6
Training loss: 0.18243858456918174
Validation loss: 2.5837327008040556

Epoch: 5| Step: 7
Training loss: 0.1344716971701867
Validation loss: 2.587832718098965

Epoch: 5| Step: 8
Training loss: 0.1692763156492131
Validation loss: 2.5941953250819463

Epoch: 5| Step: 9
Training loss: 0.1722297042798913
Validation loss: 2.5358889922177594

Epoch: 5| Step: 10
Training loss: 0.08114321883459742
Validation loss: 2.5468292876438814

Epoch: 566| Step: 0
Training loss: 0.21207128572688613
Validation loss: 2.565115294872977

Epoch: 5| Step: 1
Training loss: 0.17995515874117712
Validation loss: 2.567500621825414

Epoch: 5| Step: 2
Training loss: 0.2546610104645692
Validation loss: 2.5390712387653975

Epoch: 5| Step: 3
Training loss: 0.19457035207910753
Validation loss: 2.5363031202424104

Epoch: 5| Step: 4
Training loss: 0.13368238943942087
Validation loss: 2.574488287662132

Epoch: 5| Step: 5
Training loss: 0.18046684842119318
Validation loss: 2.5544334481735738

Epoch: 5| Step: 6
Training loss: 0.20959055856993933
Validation loss: 2.5828765606897974

Epoch: 5| Step: 7
Training loss: 0.13764082730222435
Validation loss: 2.553093553860204

Epoch: 5| Step: 8
Training loss: 0.17493483424259565
Validation loss: 2.5461038362758592

Epoch: 5| Step: 9
Training loss: 0.21378124374012686
Validation loss: 2.564404175046288

Epoch: 5| Step: 10
Training loss: 0.10835199821902207
Validation loss: 2.588132790866931

Epoch: 567| Step: 0
Training loss: 0.1247142154891532
Validation loss: 2.5763129853599636

Epoch: 5| Step: 1
Training loss: 0.22707040353297758
Validation loss: 2.56463291371561

Epoch: 5| Step: 2
Training loss: 0.18889089118041968
Validation loss: 2.5858027960278402

Epoch: 5| Step: 3
Training loss: 0.2574346837285403
Validation loss: 2.566536327374591

Epoch: 5| Step: 4
Training loss: 0.13614039707810538
Validation loss: 2.587006337145026

Epoch: 5| Step: 5
Training loss: 0.138183627448735
Validation loss: 2.5859999243142533

Epoch: 5| Step: 6
Training loss: 0.1305540137447914
Validation loss: 2.6180281906182565

Epoch: 5| Step: 7
Training loss: 0.15285512487684724
Validation loss: 2.65820416658005

Epoch: 5| Step: 8
Training loss: 0.1680490944794272
Validation loss: 2.6273228114500538

Epoch: 5| Step: 9
Training loss: 0.14403257817437923
Validation loss: 2.616310014893346

Epoch: 5| Step: 10
Training loss: 0.2553412892324933
Validation loss: 2.608014275678046

Epoch: 568| Step: 0
Training loss: 0.1491868217122832
Validation loss: 2.5960952824403867

Epoch: 5| Step: 1
Training loss: 0.17256579510914977
Validation loss: 2.6036766562546667

Epoch: 5| Step: 2
Training loss: 0.21831254132715724
Validation loss: 2.567696631207581

Epoch: 5| Step: 3
Training loss: 0.18845630200846178
Validation loss: 2.551605302056948

Epoch: 5| Step: 4
Training loss: 0.1339898586541226
Validation loss: 2.5387794105851205

Epoch: 5| Step: 5
Training loss: 0.2680038073326226
Validation loss: 2.5379337944035605

Epoch: 5| Step: 6
Training loss: 0.14276817797406915
Validation loss: 2.5260105869896035

Epoch: 5| Step: 7
Training loss: 0.21601301540019457
Validation loss: 2.5464708450599467

Epoch: 5| Step: 8
Training loss: 0.07574153650996586
Validation loss: 2.5269764472924128

Epoch: 5| Step: 9
Training loss: 0.11099494887175534
Validation loss: 2.5424822620511947

Epoch: 5| Step: 10
Training loss: 0.0813034273971627
Validation loss: 2.5371970448006373

Epoch: 569| Step: 0
Training loss: 0.2141906434783814
Validation loss: 2.53727707909376

Epoch: 5| Step: 1
Training loss: 0.20993674382831368
Validation loss: 2.5851952258548967

Epoch: 5| Step: 2
Training loss: 0.13351094094280364
Validation loss: 2.5550182969172437

Epoch: 5| Step: 3
Training loss: 0.18015032746107634
Validation loss: 2.5438737094049806

Epoch: 5| Step: 4
Training loss: 0.17036966536882062
Validation loss: 2.594726594116626

Epoch: 5| Step: 5
Training loss: 0.1095676173594358
Validation loss: 2.608964398098513

Epoch: 5| Step: 6
Training loss: 0.13758443196238523
Validation loss: 2.633697567916757

Epoch: 5| Step: 7
Training loss: 0.20906845077176664
Validation loss: 2.578933450843854

Epoch: 5| Step: 8
Training loss: 0.17636728086078324
Validation loss: 2.576864458056937

Epoch: 5| Step: 9
Training loss: 0.17652645038448658
Validation loss: 2.590948852498518

Epoch: 5| Step: 10
Training loss: 0.186620018205882
Validation loss: 2.5438380240046827

Epoch: 570| Step: 0
Training loss: 0.21132362311569142
Validation loss: 2.53413130503996

Epoch: 5| Step: 1
Training loss: 0.2246346915531344
Validation loss: 2.5473421082284466

Epoch: 5| Step: 2
Training loss: 0.09083055623027825
Validation loss: 2.5283596805879354

Epoch: 5| Step: 3
Training loss: 0.14975012590087794
Validation loss: 2.528602000961134

Epoch: 5| Step: 4
Training loss: 0.14656918931348417
Validation loss: 2.531755976643234

Epoch: 5| Step: 5
Training loss: 0.09332609201851814
Validation loss: 2.5430934777062006

Epoch: 5| Step: 6
Training loss: 0.12410585413432282
Validation loss: 2.549284928677199

Epoch: 5| Step: 7
Training loss: 0.21995314042138128
Validation loss: 2.564041871351589

Epoch: 5| Step: 8
Training loss: 0.10952223081500198
Validation loss: 2.5858939464304123

Epoch: 5| Step: 9
Training loss: 0.0703698659372059
Validation loss: 2.5751953831814283

Epoch: 5| Step: 10
Training loss: 0.19281368125417664
Validation loss: 2.5827585117359764

Epoch: 571| Step: 0
Training loss: 0.12990875271920702
Validation loss: 2.6143831389589485

Epoch: 5| Step: 1
Training loss: 0.09165170533462264
Validation loss: 2.5994510238296025

Epoch: 5| Step: 2
Training loss: 0.16665607781350358
Validation loss: 2.5843396173655946

Epoch: 5| Step: 3
Training loss: 0.1495399007517155
Validation loss: 2.607930193661189

Epoch: 5| Step: 4
Training loss: 0.20258908918480845
Validation loss: 2.6161541131173838

Epoch: 5| Step: 5
Training loss: 0.14540596412164922
Validation loss: 2.5901117032316985

Epoch: 5| Step: 6
Training loss: 0.18606302848538403
Validation loss: 2.58087459449282

Epoch: 5| Step: 7
Training loss: 0.1194916424235357
Validation loss: 2.559013498971531

Epoch: 5| Step: 8
Training loss: 0.15873813234672338
Validation loss: 2.562484241440142

Epoch: 5| Step: 9
Training loss: 0.1196747244460677
Validation loss: 2.5624554462896554

Epoch: 5| Step: 10
Training loss: 0.2299971604819826
Validation loss: 2.5665509078641255

Epoch: 572| Step: 0
Training loss: 0.15089889196475068
Validation loss: 2.5550615500263243

Epoch: 5| Step: 1
Training loss: 0.1293409200484553
Validation loss: 2.5597218686477006

Epoch: 5| Step: 2
Training loss: 0.2512207179537547
Validation loss: 2.578621486813228

Epoch: 5| Step: 3
Training loss: 0.20807540941396352
Validation loss: 2.5662208672851827

Epoch: 5| Step: 4
Training loss: 0.09747754912913921
Validation loss: 2.5885766984912104

Epoch: 5| Step: 5
Training loss: 0.11594172558063032
Validation loss: 2.587944273962383

Epoch: 5| Step: 6
Training loss: 0.125701396780895
Validation loss: 2.576208222075506

Epoch: 5| Step: 7
Training loss: 0.09817130639292398
Validation loss: 2.5977732045234836

Epoch: 5| Step: 8
Training loss: 0.1657946574625716
Validation loss: 2.5899041281604362

Epoch: 5| Step: 9
Training loss: 0.1880503168175424
Validation loss: 2.5440413968733586

Epoch: 5| Step: 10
Training loss: 0.13657399416154595
Validation loss: 2.552753934134012

Epoch: 573| Step: 0
Training loss: 0.09606856039235881
Validation loss: 2.5882197426840987

Epoch: 5| Step: 1
Training loss: 0.20905958587029594
Validation loss: 2.551216166678507

Epoch: 5| Step: 2
Training loss: 0.10817795316085967
Validation loss: 2.543295471697055

Epoch: 5| Step: 3
Training loss: 0.25911999541849434
Validation loss: 2.5670984518139695

Epoch: 5| Step: 4
Training loss: 0.08265310401824652
Validation loss: 2.5318655331346003

Epoch: 5| Step: 5
Training loss: 0.08797403721987182
Validation loss: 2.5902833649779424

Epoch: 5| Step: 6
Training loss: 0.12370215500714749
Validation loss: 2.5695216916050176

Epoch: 5| Step: 7
Training loss: 0.13015267295089364
Validation loss: 2.5483089416280227

Epoch: 5| Step: 8
Training loss: 0.18293357410004377
Validation loss: 2.574651086634136

Epoch: 5| Step: 9
Training loss: 0.2146372843405549
Validation loss: 2.5815540994979536

Epoch: 5| Step: 10
Training loss: 0.09941293944378375
Validation loss: 2.597049709123653

Epoch: 574| Step: 0
Training loss: 0.12942339017525248
Validation loss: 2.601819214772498

Epoch: 5| Step: 1
Training loss: 0.21555800917635182
Validation loss: 2.605866422765766

Epoch: 5| Step: 2
Training loss: 0.14589971212420128
Validation loss: 2.5958568547505783

Epoch: 5| Step: 3
Training loss: 0.13722731823798615
Validation loss: 2.5869645873240272

Epoch: 5| Step: 4
Training loss: 0.09630801786127932
Validation loss: 2.5662942646121625

Epoch: 5| Step: 5
Training loss: 0.10715700353105514
Validation loss: 2.5674998549799124

Epoch: 5| Step: 6
Training loss: 0.1541261694423678
Validation loss: 2.5534552212860024

Epoch: 5| Step: 7
Training loss: 0.1550969374269767
Validation loss: 2.5390960575028614

Epoch: 5| Step: 8
Training loss: 0.1960025043132932
Validation loss: 2.5546501081417805

Epoch: 5| Step: 9
Training loss: 0.14739736234952458
Validation loss: 2.509928943952124

Epoch: 5| Step: 10
Training loss: 0.23519683436984917
Validation loss: 2.50544453854046

Epoch: 575| Step: 0
Training loss: 0.1275081313686522
Validation loss: 2.52127519269201

Epoch: 5| Step: 1
Training loss: 0.07975595493154453
Validation loss: 2.5084275102445117

Epoch: 5| Step: 2
Training loss: 0.1393333628710441
Validation loss: 2.514364164161748

Epoch: 5| Step: 3
Training loss: 0.26222692090968497
Validation loss: 2.5404529544914496

Epoch: 5| Step: 4
Training loss: 0.2085395874827415
Validation loss: 2.5135175034455997

Epoch: 5| Step: 5
Training loss: 0.11646868468314249
Validation loss: 2.524267443878199

Epoch: 5| Step: 6
Training loss: 0.05506010293329983
Validation loss: 2.507583836214702

Epoch: 5| Step: 7
Training loss: 0.10037998298910418
Validation loss: 2.5642143245605404

Epoch: 5| Step: 8
Training loss: 0.16755054776044687
Validation loss: 2.5357447411282172

Epoch: 5| Step: 9
Training loss: 0.13512928588997353
Validation loss: 2.5495690066992918

Epoch: 5| Step: 10
Training loss: 0.06762891897380884
Validation loss: 2.577731487114664

Epoch: 576| Step: 0
Training loss: 0.08346617871054794
Validation loss: 2.5768293608557773

Epoch: 5| Step: 1
Training loss: 0.07746740989364605
Validation loss: 2.5831345479369086

Epoch: 5| Step: 2
Training loss: 0.10275723997014742
Validation loss: 2.581573719329115

Epoch: 5| Step: 3
Training loss: 0.13392448532592363
Validation loss: 2.549468052582061

Epoch: 5| Step: 4
Training loss: 0.15453986458251798
Validation loss: 2.5454352037445815

Epoch: 5| Step: 5
Training loss: 0.1917964403104809
Validation loss: 2.567927480082529

Epoch: 5| Step: 6
Training loss: 0.23596217455901378
Validation loss: 2.578440475179681

Epoch: 5| Step: 7
Training loss: 0.1138247818282433
Validation loss: 2.525113326658398

Epoch: 5| Step: 8
Training loss: 0.1626371788127426
Validation loss: 2.542523948763226

Epoch: 5| Step: 9
Training loss: 0.15637623932497516
Validation loss: 2.5209227217023957

Epoch: 5| Step: 10
Training loss: 0.12906916755836673
Validation loss: 2.5036263242778354

Epoch: 577| Step: 0
Training loss: 0.1364167283480782
Validation loss: 2.474870072877432

Epoch: 5| Step: 1
Training loss: 0.20762586674173453
Validation loss: 2.508721789240831

Epoch: 5| Step: 2
Training loss: 0.12324922060961865
Validation loss: 2.5277310766411807

Epoch: 5| Step: 3
Training loss: 0.2095782673971144
Validation loss: 2.5339849087341952

Epoch: 5| Step: 4
Training loss: 0.11109750686334484
Validation loss: 2.5240696758672185

Epoch: 5| Step: 5
Training loss: 0.10502701991409384
Validation loss: 2.551170468800291

Epoch: 5| Step: 6
Training loss: 0.19768790568292935
Validation loss: 2.5659329449026407

Epoch: 5| Step: 7
Training loss: 0.09658880489653243
Validation loss: 2.5443211463169293

Epoch: 5| Step: 8
Training loss: 0.11672158605508086
Validation loss: 2.5941511373515374

Epoch: 5| Step: 9
Training loss: 0.1613962678416788
Validation loss: 2.585391456971796

Epoch: 5| Step: 10
Training loss: 0.19738103304479288
Validation loss: 2.5730327951815193

Epoch: 578| Step: 0
Training loss: 0.12913912632067398
Validation loss: 2.5865044176388388

Epoch: 5| Step: 1
Training loss: 0.09239553480877795
Validation loss: 2.59943164643088

Epoch: 5| Step: 2
Training loss: 0.16408704960026682
Validation loss: 2.5930724402440015

Epoch: 5| Step: 3
Training loss: 0.09290760778557033
Validation loss: 2.590727702675147

Epoch: 5| Step: 4
Training loss: 0.20699437730749937
Validation loss: 2.563025826028871

Epoch: 5| Step: 5
Training loss: 0.1715701933388283
Validation loss: 2.585445431960963

Epoch: 5| Step: 6
Training loss: 0.13891109464540877
Validation loss: 2.5618642683207953

Epoch: 5| Step: 7
Training loss: 0.12448726488716132
Validation loss: 2.569443100191042

Epoch: 5| Step: 8
Training loss: 0.19920295764934917
Validation loss: 2.5164118627675807

Epoch: 5| Step: 9
Training loss: 0.14519591474267068
Validation loss: 2.56598803704939

Epoch: 5| Step: 10
Training loss: 0.11562809521166535
Validation loss: 2.545145416471502

Epoch: 579| Step: 0
Training loss: 0.11198822713022522
Validation loss: 2.5612751143941552

Epoch: 5| Step: 1
Training loss: 0.08767754102807405
Validation loss: 2.5424065611549107

Epoch: 5| Step: 2
Training loss: 0.08223203371289467
Validation loss: 2.5418294965073183

Epoch: 5| Step: 3
Training loss: 0.1416290125055396
Validation loss: 2.5216481244505964

Epoch: 5| Step: 4
Training loss: 0.1339315157237437
Validation loss: 2.4986707434992255

Epoch: 5| Step: 5
Training loss: 0.10308444894783429
Validation loss: 2.485000002367009

Epoch: 5| Step: 6
Training loss: 0.10831897417679966
Validation loss: 2.54031945856843

Epoch: 5| Step: 7
Training loss: 0.23180546483965725
Validation loss: 2.4770325426560382

Epoch: 5| Step: 8
Training loss: 0.23803330638488526
Validation loss: 2.532016111053887

Epoch: 5| Step: 9
Training loss: 0.11264092655302912
Validation loss: 2.500163991738251

Epoch: 5| Step: 10
Training loss: 0.16529673150508245
Validation loss: 2.5406164672209397

Epoch: 580| Step: 0
Training loss: 0.08438204166380608
Validation loss: 2.5113603461275105

Epoch: 5| Step: 1
Training loss: 0.12426736827900074
Validation loss: 2.5353139574224506

Epoch: 5| Step: 2
Training loss: 0.2566349127611326
Validation loss: 2.5477536838115524

Epoch: 5| Step: 3
Training loss: 0.1298593485582839
Validation loss: 2.5568631589697075

Epoch: 5| Step: 4
Training loss: 0.1354682752189544
Validation loss: 2.5643751625230395

Epoch: 5| Step: 5
Training loss: 0.08468944096892317
Validation loss: 2.577984730673065

Epoch: 5| Step: 6
Training loss: 0.11654005009605509
Validation loss: 2.5609102317429806

Epoch: 5| Step: 7
Training loss: 0.12017254212972618
Validation loss: 2.5570446964714177

Epoch: 5| Step: 8
Training loss: 0.19096530025152245
Validation loss: 2.5790446610326203

Epoch: 5| Step: 9
Training loss: 0.12963005798802987
Validation loss: 2.5307542155092975

Epoch: 5| Step: 10
Training loss: 0.10811131917255923
Validation loss: 2.5860232904157843

Epoch: 581| Step: 0
Training loss: 0.2354428284520339
Validation loss: 2.5585115338276143

Epoch: 5| Step: 1
Training loss: 0.09115157676947896
Validation loss: 2.6027302839425217

Epoch: 5| Step: 2
Training loss: 0.18517906474942308
Validation loss: 2.602438939227269

Epoch: 5| Step: 3
Training loss: 0.1300255485908342
Validation loss: 2.608848960375235

Epoch: 5| Step: 4
Training loss: 0.11594164927016205
Validation loss: 2.584975974898635

Epoch: 5| Step: 5
Training loss: 0.12326789865852077
Validation loss: 2.5958546721771536

Epoch: 5| Step: 6
Training loss: 0.18719813764019688
Validation loss: 2.5830901174014964

Epoch: 5| Step: 7
Training loss: 0.12637156282895434
Validation loss: 2.5757333450555175

Epoch: 5| Step: 8
Training loss: 0.09879117470953566
Validation loss: 2.5627753877365613

Epoch: 5| Step: 9
Training loss: 0.08286322173976618
Validation loss: 2.5783559268809144

Epoch: 5| Step: 10
Training loss: 0.11701175704341613
Validation loss: 2.5982993059735544

Epoch: 582| Step: 0
Training loss: 0.11868805602974437
Validation loss: 2.536411100420602

Epoch: 5| Step: 1
Training loss: 0.13698722500782623
Validation loss: 2.5293011310120477

Epoch: 5| Step: 2
Training loss: 0.09654304693466993
Validation loss: 2.565082478289719

Epoch: 5| Step: 3
Training loss: 0.16247508151393805
Validation loss: 2.5357959275955473

Epoch: 5| Step: 4
Training loss: 0.19151087256584717
Validation loss: 2.541480378482589

Epoch: 5| Step: 5
Training loss: 0.25009908798624225
Validation loss: 2.5527793338701605

Epoch: 5| Step: 6
Training loss: 0.0871936581728727
Validation loss: 2.5375967980315655

Epoch: 5| Step: 7
Training loss: 0.11577454542395342
Validation loss: 2.5607946930850503

Epoch: 5| Step: 8
Training loss: 0.12418784860802971
Validation loss: 2.54502457884846

Epoch: 5| Step: 9
Training loss: 0.10161738563237319
Validation loss: 2.5482691241931077

Epoch: 5| Step: 10
Training loss: 0.12695010255003397
Validation loss: 2.565405981933471

Epoch: 583| Step: 0
Training loss: 0.10104440627202027
Validation loss: 2.5855026035560233

Epoch: 5| Step: 1
Training loss: 0.205080577290723
Validation loss: 2.5636161176330954

Epoch: 5| Step: 2
Training loss: 0.142653001432836
Validation loss: 2.6023849896362194

Epoch: 5| Step: 3
Training loss: 0.13439150032491973
Validation loss: 2.5631755228084208

Epoch: 5| Step: 4
Training loss: 0.12237755447888461
Validation loss: 2.6303301226330817

Epoch: 5| Step: 5
Training loss: 0.10940341495211911
Validation loss: 2.623201465572271

Epoch: 5| Step: 6
Training loss: 0.08724297480135287
Validation loss: 2.6122019849830647

Epoch: 5| Step: 7
Training loss: 0.17752794707263728
Validation loss: 2.6118416904855786

Epoch: 5| Step: 8
Training loss: 0.1420524718436946
Validation loss: 2.592787320201611

Epoch: 5| Step: 9
Training loss: 0.12250988969002162
Validation loss: 2.616071476509383

Epoch: 5| Step: 10
Training loss: 0.20136177951125697
Validation loss: 2.617766824175758

Epoch: 584| Step: 0
Training loss: 0.11907271106742712
Validation loss: 2.5913478423609644

Epoch: 5| Step: 1
Training loss: 0.23057956779169725
Validation loss: 2.5359477192708053

Epoch: 5| Step: 2
Training loss: 0.13089079977740845
Validation loss: 2.5707827470553526

Epoch: 5| Step: 3
Training loss: 0.12061254967045955
Validation loss: 2.542618965655767

Epoch: 5| Step: 4
Training loss: 0.12811977881748865
Validation loss: 2.551841107229242

Epoch: 5| Step: 5
Training loss: 0.12427168503965316
Validation loss: 2.56332850474892

Epoch: 5| Step: 6
Training loss: 0.17910658185575162
Validation loss: 2.5100921685285864

Epoch: 5| Step: 7
Training loss: 0.12504129174821488
Validation loss: 2.5415684885973513

Epoch: 5| Step: 8
Training loss: 0.10017852772744418
Validation loss: 2.5241158613450536

Epoch: 5| Step: 9
Training loss: 0.20122680099419263
Validation loss: 2.560644464912471

Epoch: 5| Step: 10
Training loss: 0.13718317713693642
Validation loss: 2.543925520369368

Epoch: 585| Step: 0
Training loss: 0.1786874641052829
Validation loss: 2.5683167161646385

Epoch: 5| Step: 1
Training loss: 0.12996718885534822
Validation loss: 2.553338341254082

Epoch: 5| Step: 2
Training loss: 0.1534087114558199
Validation loss: 2.5366244910536992

Epoch: 5| Step: 3
Training loss: 0.18178556668561693
Validation loss: 2.5846825713955033

Epoch: 5| Step: 4
Training loss: 0.08722487605608999
Validation loss: 2.5803715369178244

Epoch: 5| Step: 5
Training loss: 0.12222564732278139
Validation loss: 2.5938588680583066

Epoch: 5| Step: 6
Training loss: 0.10742201371617464
Validation loss: 2.556599172980303

Epoch: 5| Step: 7
Training loss: 0.1305703772409635
Validation loss: 2.5863263054419248

Epoch: 5| Step: 8
Training loss: 0.09889472519138746
Validation loss: 2.612459316605153

Epoch: 5| Step: 9
Training loss: 0.19759982664509942
Validation loss: 2.5525499859395206

Epoch: 5| Step: 10
Training loss: 0.15782725458761462
Validation loss: 2.550013538158172

Epoch: 586| Step: 0
Training loss: 0.11750269859466689
Validation loss: 2.5530808847066973

Epoch: 5| Step: 1
Training loss: 0.09366686432953056
Validation loss: 2.580362497892622

Epoch: 5| Step: 2
Training loss: 0.10936714041944802
Validation loss: 2.573281589625211

Epoch: 5| Step: 3
Training loss: 0.1950152232879103
Validation loss: 2.5616251514833217

Epoch: 5| Step: 4
Training loss: 0.19855715718404174
Validation loss: 2.572788494561586

Epoch: 5| Step: 5
Training loss: 0.21401587417029908
Validation loss: 2.5415326528119424

Epoch: 5| Step: 6
Training loss: 0.09131732429747534
Validation loss: 2.553758079661348

Epoch: 5| Step: 7
Training loss: 0.2066677789568451
Validation loss: 2.5360866982804153

Epoch: 5| Step: 8
Training loss: 0.16475323185044544
Validation loss: 2.568579572738557

Epoch: 5| Step: 9
Training loss: 0.09245268435564194
Validation loss: 2.555956312154666

Epoch: 5| Step: 10
Training loss: 0.11306670030221874
Validation loss: 2.575503273978548

Epoch: 587| Step: 0
Training loss: 0.118031817908028
Validation loss: 2.5388584950467354

Epoch: 5| Step: 1
Training loss: 0.07804829288794676
Validation loss: 2.5956334820522144

Epoch: 5| Step: 2
Training loss: 0.1582002345162527
Validation loss: 2.579051816030739

Epoch: 5| Step: 3
Training loss: 0.203305375267806
Validation loss: 2.5686385539308834

Epoch: 5| Step: 4
Training loss: 0.1012552179504932
Validation loss: 2.591196885917203

Epoch: 5| Step: 5
Training loss: 0.144802444786402
Validation loss: 2.5846330240927244

Epoch: 5| Step: 6
Training loss: 0.14271616458868916
Validation loss: 2.57588149992703

Epoch: 5| Step: 7
Training loss: 0.11802662194116677
Validation loss: 2.5601996544659698

Epoch: 5| Step: 8
Training loss: 0.16703495236531965
Validation loss: 2.601427225438301

Epoch: 5| Step: 9
Training loss: 0.19537990360671648
Validation loss: 2.590778625624654

Epoch: 5| Step: 10
Training loss: 0.2247710351090659
Validation loss: 2.5908384659728974

Epoch: 588| Step: 0
Training loss: 0.17581398447205387
Validation loss: 2.566389633871365

Epoch: 5| Step: 1
Training loss: 0.16360131793657162
Validation loss: 2.5974281977631906

Epoch: 5| Step: 2
Training loss: 0.12606469110231058
Validation loss: 2.5775940150333945

Epoch: 5| Step: 3
Training loss: 0.10819367667030369
Validation loss: 2.616163938829199

Epoch: 5| Step: 4
Training loss: 0.21461168240034778
Validation loss: 2.601365423616711

Epoch: 5| Step: 5
Training loss: 0.11236526265379133
Validation loss: 2.583917032511027

Epoch: 5| Step: 6
Training loss: 0.13803746615061147
Validation loss: 2.553256725974251

Epoch: 5| Step: 7
Training loss: 0.13025919794958735
Validation loss: 2.548328217835718

Epoch: 5| Step: 8
Training loss: 0.08074993557288933
Validation loss: 2.558008630336818

Epoch: 5| Step: 9
Training loss: 0.18147075051817219
Validation loss: 2.535050026560043

Epoch: 5| Step: 10
Training loss: 0.07579519595785382
Validation loss: 2.537672547445205

Epoch: 589| Step: 0
Training loss: 0.14849228224503197
Validation loss: 2.5645736229789526

Epoch: 5| Step: 1
Training loss: 0.17949916464908752
Validation loss: 2.547776472935089

Epoch: 5| Step: 2
Training loss: 0.17878615250489396
Validation loss: 2.557482501508104

Epoch: 5| Step: 3
Training loss: 0.13192193793729395
Validation loss: 2.5928675497954816

Epoch: 5| Step: 4
Training loss: 0.1584268212904945
Validation loss: 2.6061517679580364

Epoch: 5| Step: 5
Training loss: 0.15422864805844005
Validation loss: 2.597569270608791

Epoch: 5| Step: 6
Training loss: 0.10669195840019716
Validation loss: 2.602778633762562

Epoch: 5| Step: 7
Training loss: 0.08985454038423907
Validation loss: 2.585075137224022

Epoch: 5| Step: 8
Training loss: 0.1947005795023973
Validation loss: 2.6340542466008627

Epoch: 5| Step: 9
Training loss: 0.10053257776823696
Validation loss: 2.6064734554474613

Epoch: 5| Step: 10
Training loss: 0.1692794461382183
Validation loss: 2.6329581372941036

Epoch: 590| Step: 0
Training loss: 0.20065515321302005
Validation loss: 2.581518702589827

Epoch: 5| Step: 1
Training loss: 0.09651585385871471
Validation loss: 2.57798802076223

Epoch: 5| Step: 2
Training loss: 0.06798837668859571
Validation loss: 2.5512756281640185

Epoch: 5| Step: 3
Training loss: 0.15197953678641202
Validation loss: 2.550687383440891

Epoch: 5| Step: 4
Training loss: 0.08649294877908188
Validation loss: 2.541532828325507

Epoch: 5| Step: 5
Training loss: 0.1609064535175636
Validation loss: 2.5412148807571486

Epoch: 5| Step: 6
Training loss: 0.21657986132346344
Validation loss: 2.5362257722714605

Epoch: 5| Step: 7
Training loss: 0.1888382164590872
Validation loss: 2.508880783314846

Epoch: 5| Step: 8
Training loss: 0.16822906770693424
Validation loss: 2.513908387023564

Epoch: 5| Step: 9
Training loss: 0.09662010784583074
Validation loss: 2.505613178209969

Epoch: 5| Step: 10
Training loss: 0.12544818341443992
Validation loss: 2.5167138096137776

Epoch: 591| Step: 0
Training loss: 0.13118262008952217
Validation loss: 2.5390036824294624

Epoch: 5| Step: 1
Training loss: 0.1127206273132781
Validation loss: 2.5327325548418305

Epoch: 5| Step: 2
Training loss: 0.11006491912834666
Validation loss: 2.55973591708357

Epoch: 5| Step: 3
Training loss: 0.203350876884502
Validation loss: 2.5607282759939283

Epoch: 5| Step: 4
Training loss: 0.120566767301626
Validation loss: 2.5896763059863432

Epoch: 5| Step: 5
Training loss: 0.2087534850080907
Validation loss: 2.5779586842756856

Epoch: 5| Step: 6
Training loss: 0.1932146416951832
Validation loss: 2.5977861826979147

Epoch: 5| Step: 7
Training loss: 0.12941371847441474
Validation loss: 2.606597897276786

Epoch: 5| Step: 8
Training loss: 0.07864145401999538
Validation loss: 2.565265314938853

Epoch: 5| Step: 9
Training loss: 0.1651669351104113
Validation loss: 2.552372587351885

Epoch: 5| Step: 10
Training loss: 0.12603237335239803
Validation loss: 2.5393278073262695

Epoch: 592| Step: 0
Training loss: 0.13274691869909708
Validation loss: 2.544532247474988

Epoch: 5| Step: 1
Training loss: 0.17286476796025319
Validation loss: 2.563628742722751

Epoch: 5| Step: 2
Training loss: 0.09121024603244637
Validation loss: 2.5512792516382774

Epoch: 5| Step: 3
Training loss: 0.0964370630845255
Validation loss: 2.552469500987535

Epoch: 5| Step: 4
Training loss: 0.1468584941659425
Validation loss: 2.5417583078546193

Epoch: 5| Step: 5
Training loss: 0.2024854256100572
Validation loss: 2.582636173134448

Epoch: 5| Step: 6
Training loss: 0.09667357993822843
Validation loss: 2.530769177903448

Epoch: 5| Step: 7
Training loss: 0.09052865563422498
Validation loss: 2.5481889975037326

Epoch: 5| Step: 8
Training loss: 0.12266333158666565
Validation loss: 2.548064623858876

Epoch: 5| Step: 9
Training loss: 0.17227527760041972
Validation loss: 2.537277150831484

Epoch: 5| Step: 10
Training loss: 0.2145965194045708
Validation loss: 2.5274187589039316

Epoch: 593| Step: 0
Training loss: 0.11851101374095048
Validation loss: 2.5273437880385625

Epoch: 5| Step: 1
Training loss: 0.20554269214406276
Validation loss: 2.543247549435996

Epoch: 5| Step: 2
Training loss: 0.1009038189077992
Validation loss: 2.4985426346586035

Epoch: 5| Step: 3
Training loss: 0.16017814812169137
Validation loss: 2.5117313960924466

Epoch: 5| Step: 4
Training loss: 0.17563153885143315
Validation loss: 2.509441466297837

Epoch: 5| Step: 5
Training loss: 0.15615929116354108
Validation loss: 2.5481800968419943

Epoch: 5| Step: 6
Training loss: 0.15018555667777203
Validation loss: 2.52001950022205

Epoch: 5| Step: 7
Training loss: 0.24114240220981534
Validation loss: 2.52849405229683

Epoch: 5| Step: 8
Training loss: 0.0685420252851962
Validation loss: 2.5774736572910633

Epoch: 5| Step: 9
Training loss: 0.11900885909276473
Validation loss: 2.532510436792451

Epoch: 5| Step: 10
Training loss: 0.1747682416205871
Validation loss: 2.5825228165545964

Epoch: 594| Step: 0
Training loss: 0.08312841237654035
Validation loss: 2.5990347113164853

Epoch: 5| Step: 1
Training loss: 0.15713217372116747
Validation loss: 2.595576891151399

Epoch: 5| Step: 2
Training loss: 0.16324213394452614
Validation loss: 2.6412013051755148

Epoch: 5| Step: 3
Training loss: 0.1428849368060805
Validation loss: 2.6299143884122618

Epoch: 5| Step: 4
Training loss: 0.11098788369830254
Validation loss: 2.5871441454198716

Epoch: 5| Step: 5
Training loss: 0.17874744438465245
Validation loss: 2.609278256049517

Epoch: 5| Step: 6
Training loss: 0.17861208240071244
Validation loss: 2.5946152004239496

Epoch: 5| Step: 7
Training loss: 0.13592940394090625
Validation loss: 2.6385187305735616

Epoch: 5| Step: 8
Training loss: 0.2637861498696335
Validation loss: 2.6061640315694645

Epoch: 5| Step: 9
Training loss: 0.1049919698758229
Validation loss: 2.57995612235063

Epoch: 5| Step: 10
Training loss: 0.13233060223148765
Validation loss: 2.5754516065367192

Epoch: 595| Step: 0
Training loss: 0.11886784328012782
Validation loss: 2.5378840647584835

Epoch: 5| Step: 1
Training loss: 0.2067476885803615
Validation loss: 2.5257850414283305

Epoch: 5| Step: 2
Training loss: 0.14726949099821474
Validation loss: 2.534479553980069

Epoch: 5| Step: 3
Training loss: 0.11311579410625597
Validation loss: 2.5285631983313857

Epoch: 5| Step: 4
Training loss: 0.1521246630759728
Validation loss: 2.526518153996728

Epoch: 5| Step: 5
Training loss: 0.24284920741463
Validation loss: 2.5097454496855724

Epoch: 5| Step: 6
Training loss: 0.19942405817608794
Validation loss: 2.504679356019176

Epoch: 5| Step: 7
Training loss: 0.18488773923717478
Validation loss: 2.541248366458658

Epoch: 5| Step: 8
Training loss: 0.06708031285425786
Validation loss: 2.5479908153551727

Epoch: 5| Step: 9
Training loss: 0.20262524675734295
Validation loss: 2.5424797896446067

Epoch: 5| Step: 10
Training loss: 0.19753344456365324
Validation loss: 2.6128199547098294

Epoch: 596| Step: 0
Training loss: 0.10900040751291357
Validation loss: 2.5981486019593194

Epoch: 5| Step: 1
Training loss: 0.1810644918706832
Validation loss: 2.5836214373962485

Epoch: 5| Step: 2
Training loss: 0.3063083233084467
Validation loss: 2.6162498639738367

Epoch: 5| Step: 3
Training loss: 0.13342588094917596
Validation loss: 2.5853436312954154

Epoch: 5| Step: 4
Training loss: 0.0772183318954659
Validation loss: 2.5848077736985307

Epoch: 5| Step: 5
Training loss: 0.20305752550514894
Validation loss: 2.5747508990119385

Epoch: 5| Step: 6
Training loss: 0.26062626351249196
Validation loss: 2.5445592244087036

Epoch: 5| Step: 7
Training loss: 0.11842865128286846
Validation loss: 2.5508251146526364

Epoch: 5| Step: 8
Training loss: 0.19884899831749284
Validation loss: 2.594591220048847

Epoch: 5| Step: 9
Training loss: 0.14467266613325463
Validation loss: 2.5529730387158156

Epoch: 5| Step: 10
Training loss: 0.1309108561695527
Validation loss: 2.581998904828311

Epoch: 597| Step: 0
Training loss: 0.1409219282602526
Validation loss: 2.5610790429773123

Epoch: 5| Step: 1
Training loss: 0.17142662170697862
Validation loss: 2.5733898228133913

Epoch: 5| Step: 2
Training loss: 0.09487757983645535
Validation loss: 2.591213708537778

Epoch: 5| Step: 3
Training loss: 0.18700852154819922
Validation loss: 2.585811841812879

Epoch: 5| Step: 4
Training loss: 0.28587668350584705
Validation loss: 2.5883362470420965

Epoch: 5| Step: 5
Training loss: 0.24836714786103128
Validation loss: 2.578155774939338

Epoch: 5| Step: 6
Training loss: 0.1405905177967316
Validation loss: 2.600216366841939

Epoch: 5| Step: 7
Training loss: 0.16560553782754406
Validation loss: 2.6108948617232866

Epoch: 5| Step: 8
Training loss: 0.14317749709810446
Validation loss: 2.6219994740486126

Epoch: 5| Step: 9
Training loss: 0.13610422444465206
Validation loss: 2.6603529780589805

Epoch: 5| Step: 10
Training loss: 0.11194167553772474
Validation loss: 2.5959306295909284

Epoch: 598| Step: 0
Training loss: 0.11740932530149294
Validation loss: 2.5739138997502073

Epoch: 5| Step: 1
Training loss: 0.2032298496041945
Validation loss: 2.567978004599045

Epoch: 5| Step: 2
Training loss: 0.22464210437649185
Validation loss: 2.590209077932477

Epoch: 5| Step: 3
Training loss: 0.20894335406561057
Validation loss: 2.5845597693927207

Epoch: 5| Step: 4
Training loss: 0.14328352951308193
Validation loss: 2.546246277197808

Epoch: 5| Step: 5
Training loss: 0.21926387815854068
Validation loss: 2.598147435658089

Epoch: 5| Step: 6
Training loss: 0.15413903359791825
Validation loss: 2.57235698201506

Epoch: 5| Step: 7
Training loss: 0.32372796013091704
Validation loss: 2.552409038306745

Epoch: 5| Step: 8
Training loss: 0.2069470306253733
Validation loss: 2.5399988731912755

Epoch: 5| Step: 9
Training loss: 0.23971613368522554
Validation loss: 2.5067378338597237

Epoch: 5| Step: 10
Training loss: 0.1674106997535336
Validation loss: 2.4816629801077865

Epoch: 599| Step: 0
Training loss: 0.15049686642565593
Validation loss: 2.493537844832333

Epoch: 5| Step: 1
Training loss: 0.25612437378754216
Validation loss: 2.470182963242422

Epoch: 5| Step: 2
Training loss: 0.2349433603791364
Validation loss: 2.5083447821958207

Epoch: 5| Step: 3
Training loss: 0.180699360466455
Validation loss: 2.5152388566580473

Epoch: 5| Step: 4
Training loss: 0.1717292590392299
Validation loss: 2.5435879289691106

Epoch: 5| Step: 5
Training loss: 0.1965149580738015
Validation loss: 2.5957334159831102

Epoch: 5| Step: 6
Training loss: 0.15665496560754844
Validation loss: 2.616117296992559

Epoch: 5| Step: 7
Training loss: 0.20354679220462474
Validation loss: 2.551094460953024

Epoch: 5| Step: 8
Training loss: 0.20750184825280896
Validation loss: 2.5949872581290347

Epoch: 5| Step: 9
Training loss: 0.1189519412130752
Validation loss: 2.5798654776280405

Epoch: 5| Step: 10
Training loss: 0.2041119933314859
Validation loss: 2.536998404154742

Epoch: 600| Step: 0
Training loss: 0.1327182070409107
Validation loss: 2.5696005280400733

Epoch: 5| Step: 1
Training loss: 0.12351385694392891
Validation loss: 2.537539840521669

Epoch: 5| Step: 2
Training loss: 0.18054905916920685
Validation loss: 2.512167360540728

Epoch: 5| Step: 3
Training loss: 0.1685550901865652
Validation loss: 2.5434045278518513

Epoch: 5| Step: 4
Training loss: 0.17056738259654036
Validation loss: 2.5153474409400403

Epoch: 5| Step: 5
Training loss: 0.24146034690115
Validation loss: 2.54018920132242

Epoch: 5| Step: 6
Training loss: 0.1846441797258248
Validation loss: 2.5393670279836544

Epoch: 5| Step: 7
Training loss: 0.18192863191400024
Validation loss: 2.5324153964593177

Epoch: 5| Step: 8
Training loss: 0.13117528616745133
Validation loss: 2.605530048132714

Epoch: 5| Step: 9
Training loss: 0.3733689680222061
Validation loss: 2.5877892905401705

Epoch: 5| Step: 10
Training loss: 0.1602983251610732
Validation loss: 2.6026132950853382

Epoch: 601| Step: 0
Training loss: 0.11063777468624286
Validation loss: 2.5552084474018573

Epoch: 5| Step: 1
Training loss: 0.13810410926310487
Validation loss: 2.581301072043054

Epoch: 5| Step: 2
Training loss: 0.17608037505175
Validation loss: 2.588972613427635

Epoch: 5| Step: 3
Training loss: 0.24173384139104592
Validation loss: 2.5983718847309425

Epoch: 5| Step: 4
Training loss: 0.2309243015704114
Validation loss: 2.5769585450092123

Epoch: 5| Step: 5
Training loss: 0.25661457515990366
Validation loss: 2.613834554474775

Epoch: 5| Step: 6
Training loss: 0.10041054461229153
Validation loss: 2.5929048438514526

Epoch: 5| Step: 7
Training loss: 0.22790341001054282
Validation loss: 2.6123070830260473

Epoch: 5| Step: 8
Training loss: 0.15438578253321902
Validation loss: 2.5917131017059667

Epoch: 5| Step: 9
Training loss: 0.1398071374329458
Validation loss: 2.5733903408433396

Epoch: 5| Step: 10
Training loss: 0.11785600244834234
Validation loss: 2.5286624737616963

Epoch: 602| Step: 0
Training loss: 0.1919973937344487
Validation loss: 2.505831002359078

Epoch: 5| Step: 1
Training loss: 0.18213357996121332
Validation loss: 2.4881586841923014

Epoch: 5| Step: 2
Training loss: 0.2325911586621736
Validation loss: 2.458926858334949

Epoch: 5| Step: 3
Training loss: 0.12997337998363623
Validation loss: 2.5059863814201666

Epoch: 5| Step: 4
Training loss: 0.2028697776292671
Validation loss: 2.4776693737789324

Epoch: 5| Step: 5
Training loss: 0.20585759395574474
Validation loss: 2.4700174947382045

Epoch: 5| Step: 6
Training loss: 0.18877497949843863
Validation loss: 2.4733319310848043

Epoch: 5| Step: 7
Training loss: 0.16341249812632505
Validation loss: 2.5515926214950944

Epoch: 5| Step: 8
Training loss: 0.1552173885215092
Validation loss: 2.536613169722305

Epoch: 5| Step: 9
Training loss: 0.1392250846509082
Validation loss: 2.5323682690120712

Epoch: 5| Step: 10
Training loss: 0.19326274075461972
Validation loss: 2.5571641530356644

Epoch: 603| Step: 0
Training loss: 0.14373978858420935
Validation loss: 2.570749654036442

Epoch: 5| Step: 1
Training loss: 0.1647982222615114
Validation loss: 2.532303064794396

Epoch: 5| Step: 2
Training loss: 0.20530936510198128
Validation loss: 2.5413957223120325

Epoch: 5| Step: 3
Training loss: 0.2235850737145923
Validation loss: 2.5291398120987103

Epoch: 5| Step: 4
Training loss: 0.29273085790332976
Validation loss: 2.5554376018827383

Epoch: 5| Step: 5
Training loss: 0.14275598536751996
Validation loss: 2.5179322065490206

Epoch: 5| Step: 6
Training loss: 0.13825467306874034
Validation loss: 2.549916027985919

Epoch: 5| Step: 7
Training loss: 0.10198767321504457
Validation loss: 2.555096233357612

Epoch: 5| Step: 8
Training loss: 0.14206157809561293
Validation loss: 2.528824422262245

Epoch: 5| Step: 9
Training loss: 0.1177054719942865
Validation loss: 2.521360128898255

Epoch: 5| Step: 10
Training loss: 0.09668069896746881
Validation loss: 2.539918095995528

Epoch: 604| Step: 0
Training loss: 0.18086666397335985
Validation loss: 2.5154329783443803

Epoch: 5| Step: 1
Training loss: 0.12961526433108764
Validation loss: 2.547535311250212

Epoch: 5| Step: 2
Training loss: 0.11155750669529915
Validation loss: 2.5180162648890563

Epoch: 5| Step: 3
Training loss: 0.19148389059042076
Validation loss: 2.5244114809988414

Epoch: 5| Step: 4
Training loss: 0.18912173320611336
Validation loss: 2.5452163875050484

Epoch: 5| Step: 5
Training loss: 0.22426164495890813
Validation loss: 2.537813735706786

Epoch: 5| Step: 6
Training loss: 0.14112861180435124
Validation loss: 2.5199716414434663

Epoch: 5| Step: 7
Training loss: 0.09561610644876625
Validation loss: 2.5128146012614936

Epoch: 5| Step: 8
Training loss: 0.08734020496366907
Validation loss: 2.5778919918881913

Epoch: 5| Step: 9
Training loss: 0.10773096266606014
Validation loss: 2.5603678627208675

Epoch: 5| Step: 10
Training loss: 0.11456480924107215
Validation loss: 2.5501951940688707

Epoch: 605| Step: 0
Training loss: 0.13900342447278596
Validation loss: 2.575973731879041

Epoch: 5| Step: 1
Training loss: 0.18944959538898065
Validation loss: 2.562727460112625

Epoch: 5| Step: 2
Training loss: 0.14491775743336496
Validation loss: 2.5203230329560373

Epoch: 5| Step: 3
Training loss: 0.12273689992846164
Validation loss: 2.553713540079197

Epoch: 5| Step: 4
Training loss: 0.13366257472990925
Validation loss: 2.5557699818719937

Epoch: 5| Step: 5
Training loss: 0.13983263525667336
Validation loss: 2.5467372373617216

Epoch: 5| Step: 6
Training loss: 0.13265155408745477
Validation loss: 2.5524752214080424

Epoch: 5| Step: 7
Training loss: 0.2323802221464523
Validation loss: 2.552181261271115

Epoch: 5| Step: 8
Training loss: 0.11208014638868266
Validation loss: 2.6039371518956287

Epoch: 5| Step: 9
Training loss: 0.12846736900582065
Validation loss: 2.563758986518486

Epoch: 5| Step: 10
Training loss: 0.16435576522174825
Validation loss: 2.5863507296952277

Epoch: 606| Step: 0
Training loss: 0.14902496162125123
Validation loss: 2.576584381454564

Epoch: 5| Step: 1
Training loss: 0.13008744747675444
Validation loss: 2.5943689745636362

Epoch: 5| Step: 2
Training loss: 0.1422783823174655
Validation loss: 2.549295961433967

Epoch: 5| Step: 3
Training loss: 0.17638150618547974
Validation loss: 2.591999938726709

Epoch: 5| Step: 4
Training loss: 0.1407230485729332
Validation loss: 2.5491387479361967

Epoch: 5| Step: 5
Training loss: 0.12564154738955904
Validation loss: 2.5345752203881466

Epoch: 5| Step: 6
Training loss: 0.21824881496304357
Validation loss: 2.529954911925846

Epoch: 5| Step: 7
Training loss: 0.13591785179294313
Validation loss: 2.5273212270130445

Epoch: 5| Step: 8
Training loss: 0.17289080955505864
Validation loss: 2.534634919535372

Epoch: 5| Step: 9
Training loss: 0.13379572413211388
Validation loss: 2.5857596169387986

Epoch: 5| Step: 10
Training loss: 0.1082105640925183
Validation loss: 2.5827064752602618

Epoch: 607| Step: 0
Training loss: 0.18592750257975216
Validation loss: 2.5329362384255703

Epoch: 5| Step: 1
Training loss: 0.19711934699840766
Validation loss: 2.549260738102271

Epoch: 5| Step: 2
Training loss: 0.1298560781857893
Validation loss: 2.5659173647864417

Epoch: 5| Step: 3
Training loss: 0.16795247021227272
Validation loss: 2.5694609065767815

Epoch: 5| Step: 4
Training loss: 0.2048162059320606
Validation loss: 2.553076355044815

Epoch: 5| Step: 5
Training loss: 0.16287200853370154
Validation loss: 2.571846402634687

Epoch: 5| Step: 6
Training loss: 0.09787184282395689
Validation loss: 2.5582963888572414

Epoch: 5| Step: 7
Training loss: 0.1482460958797411
Validation loss: 2.585660264224571

Epoch: 5| Step: 8
Training loss: 0.14529925639806643
Validation loss: 2.582558219553692

Epoch: 5| Step: 9
Training loss: 0.18080977672275872
Validation loss: 2.5952717369134004

Epoch: 5| Step: 10
Training loss: 0.1388040369503484
Validation loss: 2.596275807707908

Epoch: 608| Step: 0
Training loss: 0.11978383444668358
Validation loss: 2.570549730631969

Epoch: 5| Step: 1
Training loss: 0.22621373759298638
Validation loss: 2.5532929163060953

Epoch: 5| Step: 2
Training loss: 0.2333350953535126
Validation loss: 2.563204526656423

Epoch: 5| Step: 3
Training loss: 0.1251830608306463
Validation loss: 2.5203785016046676

Epoch: 5| Step: 4
Training loss: 0.14690842603213186
Validation loss: 2.551474052529772

Epoch: 5| Step: 5
Training loss: 0.17401794185159633
Validation loss: 2.528059336645646

Epoch: 5| Step: 6
Training loss: 0.11713267474388073
Validation loss: 2.5107372965754498

Epoch: 5| Step: 7
Training loss: 0.21471786278763588
Validation loss: 2.516300208888071

Epoch: 5| Step: 8
Training loss: 0.07735157430934017
Validation loss: 2.5456880931396633

Epoch: 5| Step: 9
Training loss: 0.16438482615070296
Validation loss: 2.549027674213112

Epoch: 5| Step: 10
Training loss: 0.10016190397607005
Validation loss: 2.518636972805436

Epoch: 609| Step: 0
Training loss: 0.1851442989081747
Validation loss: 2.5455759241943285

Epoch: 5| Step: 1
Training loss: 0.08488670756676248
Validation loss: 2.53801304991104

Epoch: 5| Step: 2
Training loss: 0.08083890722671921
Validation loss: 2.5298577179743935

Epoch: 5| Step: 3
Training loss: 0.12746331329890548
Validation loss: 2.5705071265972235

Epoch: 5| Step: 4
Training loss: 0.09950559483066797
Validation loss: 2.5581957786477787

Epoch: 5| Step: 5
Training loss: 0.10966304333191436
Validation loss: 2.564537097011667

Epoch: 5| Step: 6
Training loss: 0.1225929971866797
Validation loss: 2.56431454167522

Epoch: 5| Step: 7
Training loss: 0.1333755800315915
Validation loss: 2.596315557385927

Epoch: 5| Step: 8
Training loss: 0.2069502798124635
Validation loss: 2.549239807614153

Epoch: 5| Step: 9
Training loss: 0.18023624801158578
Validation loss: 2.5521391670158384

Epoch: 5| Step: 10
Training loss: 0.1665780246470605
Validation loss: 2.528255147872132

Epoch: 610| Step: 0
Training loss: 0.12181489544436643
Validation loss: 2.5318907890451547

Epoch: 5| Step: 1
Training loss: 0.13853488791404947
Validation loss: 2.520910826464591

Epoch: 5| Step: 2
Training loss: 0.1392835973058679
Validation loss: 2.5583360076416803

Epoch: 5| Step: 3
Training loss: 0.127110706245002
Validation loss: 2.5551756352679798

Epoch: 5| Step: 4
Training loss: 0.17083519446611367
Validation loss: 2.506281876337658

Epoch: 5| Step: 5
Training loss: 0.13385499596493483
Validation loss: 2.5360113847059766

Epoch: 5| Step: 6
Training loss: 0.2118439536430617
Validation loss: 2.535968232273959

Epoch: 5| Step: 7
Training loss: 0.12244962506161886
Validation loss: 2.4995915458652087

Epoch: 5| Step: 8
Training loss: 0.13910463128886666
Validation loss: 2.4924791543245437

Epoch: 5| Step: 9
Training loss: 0.22924378119939373
Validation loss: 2.537427236864635

Epoch: 5| Step: 10
Training loss: 0.16851592761999837
Validation loss: 2.5429721272300294

Epoch: 611| Step: 0
Training loss: 0.09171800065587427
Validation loss: 2.5642553760454003

Epoch: 5| Step: 1
Training loss: 0.1238523264077961
Validation loss: 2.539618451738593

Epoch: 5| Step: 2
Training loss: 0.17574299819972972
Validation loss: 2.572452282224191

Epoch: 5| Step: 3
Training loss: 0.14865896368366568
Validation loss: 2.5449162237302794

Epoch: 5| Step: 4
Training loss: 0.14628472391781927
Validation loss: 2.52898005413893

Epoch: 5| Step: 5
Training loss: 0.11432364189494323
Validation loss: 2.548827079961639

Epoch: 5| Step: 6
Training loss: 0.15657492470313863
Validation loss: 2.5377852546214146

Epoch: 5| Step: 7
Training loss: 0.19196027255695125
Validation loss: 2.560832958278337

Epoch: 5| Step: 8
Training loss: 0.19736203585405887
Validation loss: 2.50438563309696

Epoch: 5| Step: 9
Training loss: 0.09818186453181896
Validation loss: 2.5412557262324684

Epoch: 5| Step: 10
Training loss: 0.1895305337758695
Validation loss: 2.5245745074669843

Epoch: 612| Step: 0
Training loss: 0.11403863212962621
Validation loss: 2.5428171813474356

Epoch: 5| Step: 1
Training loss: 0.14261930994373334
Validation loss: 2.542905689738764

Epoch: 5| Step: 2
Training loss: 0.08939495673316944
Validation loss: 2.553086724755468

Epoch: 5| Step: 3
Training loss: 0.08978354987217113
Validation loss: 2.5794435362994013

Epoch: 5| Step: 4
Training loss: 0.13676039878798996
Validation loss: 2.56909807888464

Epoch: 5| Step: 5
Training loss: 0.0917515998140214
Validation loss: 2.5593984318410996

Epoch: 5| Step: 6
Training loss: 0.22387883342589782
Validation loss: 2.5632659393679504

Epoch: 5| Step: 7
Training loss: 0.09431831143860982
Validation loss: 2.536190921348451

Epoch: 5| Step: 8
Training loss: 0.19001378345059808
Validation loss: 2.543211271094656

Epoch: 5| Step: 9
Training loss: 0.17436117778023508
Validation loss: 2.544682538279326

Epoch: 5| Step: 10
Training loss: 0.10270478616622018
Validation loss: 2.5537077381058544

Epoch: 613| Step: 0
Training loss: 0.1284018749407104
Validation loss: 2.5580837011590942

Epoch: 5| Step: 1
Training loss: 0.13382645940551413
Validation loss: 2.532828625298242

Epoch: 5| Step: 2
Training loss: 0.13268839423084486
Validation loss: 2.5444695493808958

Epoch: 5| Step: 3
Training loss: 0.09068083564003178
Validation loss: 2.557176682658422

Epoch: 5| Step: 4
Training loss: 0.13320263893284867
Validation loss: 2.5570304778491826

Epoch: 5| Step: 5
Training loss: 0.17539946102662504
Validation loss: 2.551437321949837

Epoch: 5| Step: 6
Training loss: 0.20422667907522393
Validation loss: 2.583343372530555

Epoch: 5| Step: 7
Training loss: 0.17170706043598535
Validation loss: 2.535516314357802

Epoch: 5| Step: 8
Training loss: 0.12049408452686874
Validation loss: 2.5738498575861333

Epoch: 5| Step: 9
Training loss: 0.14917568439147966
Validation loss: 2.5801476333855065

Epoch: 5| Step: 10
Training loss: 0.08513808144102153
Validation loss: 2.6017312305526192

Epoch: 614| Step: 0
Training loss: 0.08655182489009626
Validation loss: 2.577984451236554

Epoch: 5| Step: 1
Training loss: 0.09666011111184603
Validation loss: 2.595546883295161

Epoch: 5| Step: 2
Training loss: 0.1317008704136085
Validation loss: 2.5938284988474285

Epoch: 5| Step: 3
Training loss: 0.09746521862007321
Validation loss: 2.5988565685969567

Epoch: 5| Step: 4
Training loss: 0.22155608709978716
Validation loss: 2.585750852542651

Epoch: 5| Step: 5
Training loss: 0.11666027520616114
Validation loss: 2.561237226153962

Epoch: 5| Step: 6
Training loss: 0.09224884893311748
Validation loss: 2.56509314127047

Epoch: 5| Step: 7
Training loss: 0.14029480660100518
Validation loss: 2.5621013954113794

Epoch: 5| Step: 8
Training loss: 0.21723980376742208
Validation loss: 2.5468622364977818

Epoch: 5| Step: 9
Training loss: 0.10386727989769391
Validation loss: 2.5374201046776204

Epoch: 5| Step: 10
Training loss: 0.08410219588707857
Validation loss: 2.536449734478519

Epoch: 615| Step: 0
Training loss: 0.08171604542240961
Validation loss: 2.49904735626687

Epoch: 5| Step: 1
Training loss: 0.15023269039405748
Validation loss: 2.522332170891207

Epoch: 5| Step: 2
Training loss: 0.11433904564102507
Validation loss: 2.545284788171132

Epoch: 5| Step: 3
Training loss: 0.22618340971790848
Validation loss: 2.531250885183812

Epoch: 5| Step: 4
Training loss: 0.15454940411549384
Validation loss: 2.4981949411712465

Epoch: 5| Step: 5
Training loss: 0.11888384898761022
Validation loss: 2.5742388728897954

Epoch: 5| Step: 6
Training loss: 0.19775577120431373
Validation loss: 2.5625430818063086

Epoch: 5| Step: 7
Training loss: 0.11372966231502908
Validation loss: 2.5666949962442356

Epoch: 5| Step: 8
Training loss: 0.11775439157416003
Validation loss: 2.5619936567098964

Epoch: 5| Step: 9
Training loss: 0.09850619469868538
Validation loss: 2.612302817987159

Epoch: 5| Step: 10
Training loss: 0.13152506875730804
Validation loss: 2.5916750362490455

Epoch: 616| Step: 0
Training loss: 0.09843365230306508
Validation loss: 2.594240516075861

Epoch: 5| Step: 1
Training loss: 0.1360934125236943
Validation loss: 2.5720655283864975

Epoch: 5| Step: 2
Training loss: 0.12513798310111623
Validation loss: 2.574750517664587

Epoch: 5| Step: 3
Training loss: 0.15736142884066473
Validation loss: 2.5862517307689474

Epoch: 5| Step: 4
Training loss: 0.11994285648464953
Validation loss: 2.5621164831758536

Epoch: 5| Step: 5
Training loss: 0.17078023364889344
Validation loss: 2.550787671201114

Epoch: 5| Step: 6
Training loss: 0.17855318329619183
Validation loss: 2.5734785234620214

Epoch: 5| Step: 7
Training loss: 0.20742210345067089
Validation loss: 2.529764035745276

Epoch: 5| Step: 8
Training loss: 0.1342381021206217
Validation loss: 2.5137098060458465

Epoch: 5| Step: 9
Training loss: 0.13006318983191112
Validation loss: 2.5051313631526537

Epoch: 5| Step: 10
Training loss: 0.1092362247248224
Validation loss: 2.5484634067436343

Epoch: 617| Step: 0
Training loss: 0.17421898136209085
Validation loss: 2.5216080131118606

Epoch: 5| Step: 1
Training loss: 0.15080580437313876
Validation loss: 2.542884550677063

Epoch: 5| Step: 2
Training loss: 0.08947846540983755
Validation loss: 2.4990230794758888

Epoch: 5| Step: 3
Training loss: 0.08934453470006257
Validation loss: 2.5318797827117066

Epoch: 5| Step: 4
Training loss: 0.14976414327032744
Validation loss: 2.5534021272923177

Epoch: 5| Step: 5
Training loss: 0.10579932469743328
Validation loss: 2.5157226592459994

Epoch: 5| Step: 6
Training loss: 0.09058172409437859
Validation loss: 2.5536962425401897

Epoch: 5| Step: 7
Training loss: 0.20434449991945278
Validation loss: 2.534927781324217

Epoch: 5| Step: 8
Training loss: 0.14021143765529562
Validation loss: 2.529263724688178

Epoch: 5| Step: 9
Training loss: 0.10431201946303283
Validation loss: 2.5092838164997495

Epoch: 5| Step: 10
Training loss: 0.17799215172961214
Validation loss: 2.5203011663853263

Epoch: 618| Step: 0
Training loss: 0.1349247393941845
Validation loss: 2.5541199199807854

Epoch: 5| Step: 1
Training loss: 0.20797260864083017
Validation loss: 2.5877084933500103

Epoch: 5| Step: 2
Training loss: 0.10841904693435749
Validation loss: 2.564035003417291

Epoch: 5| Step: 3
Training loss: 0.0986846608148516
Validation loss: 2.5764511058946478

Epoch: 5| Step: 4
Training loss: 0.11054957608943315
Validation loss: 2.5546203144841617

Epoch: 5| Step: 5
Training loss: 0.15911485955005736
Validation loss: 2.5669366010078583

Epoch: 5| Step: 6
Training loss: 0.10485627568575395
Validation loss: 2.5998924655147966

Epoch: 5| Step: 7
Training loss: 0.15854123566210088
Validation loss: 2.5967319415407917

Epoch: 5| Step: 8
Training loss: 0.12353199739903174
Validation loss: 2.558794625581843

Epoch: 5| Step: 9
Training loss: 0.11209540147125804
Validation loss: 2.5497268522421495

Epoch: 5| Step: 10
Training loss: 0.1722842026984571
Validation loss: 2.5723457780838057

Epoch: 619| Step: 0
Training loss: 0.19034068644276386
Validation loss: 2.550435792386822

Epoch: 5| Step: 1
Training loss: 0.18767835161344787
Validation loss: 2.540200021277368

Epoch: 5| Step: 2
Training loss: 0.07497938848931072
Validation loss: 2.592086062567711

Epoch: 5| Step: 3
Training loss: 0.1155849232682326
Validation loss: 2.569619532787832

Epoch: 5| Step: 4
Training loss: 0.0916357045913711
Validation loss: 2.5553143635876956

Epoch: 5| Step: 5
Training loss: 0.11278893104361129
Validation loss: 2.5828188371605085

Epoch: 5| Step: 6
Training loss: 0.1206939735461789
Validation loss: 2.524775162300145

Epoch: 5| Step: 7
Training loss: 0.10687890679346296
Validation loss: 2.580846813101446

Epoch: 5| Step: 8
Training loss: 0.08689930876333081
Validation loss: 2.5294475409662605

Epoch: 5| Step: 9
Training loss: 0.14390628601388553
Validation loss: 2.5574897388828224

Epoch: 5| Step: 10
Training loss: 0.17596701237276696
Validation loss: 2.55751833533428

Epoch: 620| Step: 0
Training loss: 0.1587333858424249
Validation loss: 2.5540388235263074

Epoch: 5| Step: 1
Training loss: 0.09964801468978181
Validation loss: 2.5282623705554035

Epoch: 5| Step: 2
Training loss: 0.1349600481371138
Validation loss: 2.5462076145795516

Epoch: 5| Step: 3
Training loss: 0.12508790829131478
Validation loss: 2.55792413632139

Epoch: 5| Step: 4
Training loss: 0.09889807298947031
Validation loss: 2.5510716381591982

Epoch: 5| Step: 5
Training loss: 0.09762557978616643
Validation loss: 2.5675651518526013

Epoch: 5| Step: 6
Training loss: 0.10949286003055952
Validation loss: 2.5134108540672653

Epoch: 5| Step: 7
Training loss: 0.16402522867182748
Validation loss: 2.5578668223800096

Epoch: 5| Step: 8
Training loss: 0.09321736983921781
Validation loss: 2.5655817908415495

Epoch: 5| Step: 9
Training loss: 0.19471184876771347
Validation loss: 2.5455182541734773

Epoch: 5| Step: 10
Training loss: 0.10540602726295024
Validation loss: 2.539523169137569

Epoch: 621| Step: 0
Training loss: 0.08841966774439193
Validation loss: 2.549303775645941

Epoch: 5| Step: 1
Training loss: 0.18242237082828552
Validation loss: 2.566703520574046

Epoch: 5| Step: 2
Training loss: 0.09154899589535084
Validation loss: 2.532862073590014

Epoch: 5| Step: 3
Training loss: 0.13580805051987188
Validation loss: 2.5711650529736763

Epoch: 5| Step: 4
Training loss: 0.1566994639783089
Validation loss: 2.5476354403265282

Epoch: 5| Step: 5
Training loss: 0.11824793243062422
Validation loss: 2.5890031618886002

Epoch: 5| Step: 6
Training loss: 0.13047199416552935
Validation loss: 2.5939710947594623

Epoch: 5| Step: 7
Training loss: 0.1546649706935679
Validation loss: 2.570845606413229

Epoch: 5| Step: 8
Training loss: 0.16370035119531695
Validation loss: 2.562948786395757

Epoch: 5| Step: 9
Training loss: 0.07573259982021142
Validation loss: 2.5389055000022003

Epoch: 5| Step: 10
Training loss: 0.0762785354310577
Validation loss: 2.557602160649352

Epoch: 622| Step: 0
Training loss: 0.08705198403105885
Validation loss: 2.5335696889217023

Epoch: 5| Step: 1
Training loss: 0.10983532867870696
Validation loss: 2.5440494463999994

Epoch: 5| Step: 2
Training loss: 0.1446224260134116
Validation loss: 2.540046556480671

Epoch: 5| Step: 3
Training loss: 0.08505611186123878
Validation loss: 2.513193085037986

Epoch: 5| Step: 4
Training loss: 0.09758384404553047
Validation loss: 2.5769130260723663

Epoch: 5| Step: 5
Training loss: 0.15039306490021215
Validation loss: 2.5562829403911467

Epoch: 5| Step: 6
Training loss: 0.10315930020059016
Validation loss: 2.5511686047323368

Epoch: 5| Step: 7
Training loss: 0.09338398852358192
Validation loss: 2.544434331275506

Epoch: 5| Step: 8
Training loss: 0.1645097539902839
Validation loss: 2.5878578319859415

Epoch: 5| Step: 9
Training loss: 0.17767671551080852
Validation loss: 2.580106783090563

Epoch: 5| Step: 10
Training loss: 0.20212720676555085
Validation loss: 2.564381828604426

Epoch: 623| Step: 0
Training loss: 0.08954815855522445
Validation loss: 2.5938361314591023

Epoch: 5| Step: 1
Training loss: 0.15359517383012503
Validation loss: 2.589385083030191

Epoch: 5| Step: 2
Training loss: 0.06109897138461684
Validation loss: 2.561421080924851

Epoch: 5| Step: 3
Training loss: 0.13522124326429255
Validation loss: 2.557632794121314

Epoch: 5| Step: 4
Training loss: 0.22030552352518837
Validation loss: 2.573119532941529

Epoch: 5| Step: 5
Training loss: 0.07589017300807915
Validation loss: 2.5508434623060503

Epoch: 5| Step: 6
Training loss: 0.12056709945630212
Validation loss: 2.537676158015498

Epoch: 5| Step: 7
Training loss: 0.19461152170866336
Validation loss: 2.5427556044427098

Epoch: 5| Step: 8
Training loss: 0.129605233285502
Validation loss: 2.5462400066442954

Epoch: 5| Step: 9
Training loss: 0.13862271176170377
Validation loss: 2.5685667309465248

Epoch: 5| Step: 10
Training loss: 0.06717553253935224
Validation loss: 2.5486424635400415

Epoch: 624| Step: 0
Training loss: 0.08033747079816661
Validation loss: 2.5342740016077694

Epoch: 5| Step: 1
Training loss: 0.07904823589661553
Validation loss: 2.5838024497109076

Epoch: 5| Step: 2
Training loss: 0.08754239502827271
Validation loss: 2.6031872421509252

Epoch: 5| Step: 3
Training loss: 0.09834679121612862
Validation loss: 2.6030277372050894

Epoch: 5| Step: 4
Training loss: 0.14905070709067514
Validation loss: 2.6269308988087827

Epoch: 5| Step: 5
Training loss: 0.1032368622228056
Validation loss: 2.656779184294995

Epoch: 5| Step: 6
Training loss: 0.10229116628667549
Validation loss: 2.6252946566183337

Epoch: 5| Step: 7
Training loss: 0.19471837278111298
Validation loss: 2.626635585394055

Epoch: 5| Step: 8
Training loss: 0.20394583971809904
Validation loss: 2.6085671622352224

Epoch: 5| Step: 9
Training loss: 0.15472408497826873
Validation loss: 2.60201252465003

Epoch: 5| Step: 10
Training loss: 0.13101289057053309
Validation loss: 2.5895958428860375

Epoch: 625| Step: 0
Training loss: 0.18683863266825954
Validation loss: 2.564138047494998

Epoch: 5| Step: 1
Training loss: 0.10206282695150246
Validation loss: 2.5293262229918003

Epoch: 5| Step: 2
Training loss: 0.11171856810148142
Validation loss: 2.519320146105341

Epoch: 5| Step: 3
Training loss: 0.16516623027460295
Validation loss: 2.4972778227930457

Epoch: 5| Step: 4
Training loss: 0.15536224176976374
Validation loss: 2.504799865028602

Epoch: 5| Step: 5
Training loss: 0.13324010956418014
Validation loss: 2.516763466082598

Epoch: 5| Step: 6
Training loss: 0.12948589338422994
Validation loss: 2.5128036195169248

Epoch: 5| Step: 7
Training loss: 0.12950329797643495
Validation loss: 2.544811306283531

Epoch: 5| Step: 8
Training loss: 0.13501226274550565
Validation loss: 2.550320060159035

Epoch: 5| Step: 9
Training loss: 0.11002483781084493
Validation loss: 2.572644538200405

Epoch: 5| Step: 10
Training loss: 0.16859680127059892
Validation loss: 2.615440173996952

Epoch: 626| Step: 0
Training loss: 0.1337951951118028
Validation loss: 2.558261022387228

Epoch: 5| Step: 1
Training loss: 0.17794094029173527
Validation loss: 2.5861113798107422

Epoch: 5| Step: 2
Training loss: 0.07232438739795065
Validation loss: 2.6136615646332824

Epoch: 5| Step: 3
Training loss: 0.12484386870792746
Validation loss: 2.6113995837658495

Epoch: 5| Step: 4
Training loss: 0.13091090596875937
Validation loss: 2.6008423425567337

Epoch: 5| Step: 5
Training loss: 0.1266735225733622
Validation loss: 2.6567292719051405

Epoch: 5| Step: 6
Training loss: 0.1639225396842887
Validation loss: 2.6016805195160906

Epoch: 5| Step: 7
Training loss: 0.07988001869837692
Validation loss: 2.6028295996812076

Epoch: 5| Step: 8
Training loss: 0.13303403749876772
Validation loss: 2.5743625137697927

Epoch: 5| Step: 9
Training loss: 0.1649189912913451
Validation loss: 2.5301291418516128

Epoch: 5| Step: 10
Training loss: 0.15996209448092058
Validation loss: 2.536474235225235

Epoch: 627| Step: 0
Training loss: 0.0963827350724676
Validation loss: 2.5656287008926837

Epoch: 5| Step: 1
Training loss: 0.18596825185089494
Validation loss: 2.485253968286859

Epoch: 5| Step: 2
Training loss: 0.15452600318826523
Validation loss: 2.479924297323123

Epoch: 5| Step: 3
Training loss: 0.13287312862840459
Validation loss: 2.500666158378607

Epoch: 5| Step: 4
Training loss: 0.16579127579806968
Validation loss: 2.5099029798378094

Epoch: 5| Step: 5
Training loss: 0.20279588997217585
Validation loss: 2.459073077597842

Epoch: 5| Step: 6
Training loss: 0.14653336023807206
Validation loss: 2.4948981022168635

Epoch: 5| Step: 7
Training loss: 0.09397843465003418
Validation loss: 2.513909379272072

Epoch: 5| Step: 8
Training loss: 0.11647807599951607
Validation loss: 2.5182525032705443

Epoch: 5| Step: 9
Training loss: 0.1262644501952324
Validation loss: 2.573929339830755

Epoch: 5| Step: 10
Training loss: 0.20803969770163572
Validation loss: 2.551580556767649

Epoch: 628| Step: 0
Training loss: 0.1330533018480722
Validation loss: 2.575174739144361

Epoch: 5| Step: 1
Training loss: 0.15269945872394505
Validation loss: 2.5882908271704554

Epoch: 5| Step: 2
Training loss: 0.1557120240917958
Validation loss: 2.5848249272598243

Epoch: 5| Step: 3
Training loss: 0.1341213777049425
Validation loss: 2.5758358076910053

Epoch: 5| Step: 4
Training loss: 0.1246123150625147
Validation loss: 2.576215507350972

Epoch: 5| Step: 5
Training loss: 0.10150345589892198
Validation loss: 2.5859836125287585

Epoch: 5| Step: 6
Training loss: 0.10871170930523343
Validation loss: 2.55325909055077

Epoch: 5| Step: 7
Training loss: 0.11757254127855292
Validation loss: 2.574126685225307

Epoch: 5| Step: 8
Training loss: 0.20787801857005095
Validation loss: 2.5315610177258803

Epoch: 5| Step: 9
Training loss: 0.1836480202511295
Validation loss: 2.505683033415887

Epoch: 5| Step: 10
Training loss: 0.23037588543858875
Validation loss: 2.496474551077023

Epoch: 629| Step: 0
Training loss: 0.11059423786733723
Validation loss: 2.4963426170782754

Epoch: 5| Step: 1
Training loss: 0.1287104969856469
Validation loss: 2.4292027852821727

Epoch: 5| Step: 2
Training loss: 0.13675594505074523
Validation loss: 2.486127882401127

Epoch: 5| Step: 3
Training loss: 0.10634452527974542
Validation loss: 2.4950522098926773

Epoch: 5| Step: 4
Training loss: 0.10287815972159553
Validation loss: 2.4777967501602705

Epoch: 5| Step: 5
Training loss: 0.1355167547834433
Validation loss: 2.5071467168570605

Epoch: 5| Step: 6
Training loss: 0.18685195114095962
Validation loss: 2.511721193487232

Epoch: 5| Step: 7
Training loss: 0.12463802214634499
Validation loss: 2.544639830096997

Epoch: 5| Step: 8
Training loss: 0.18049188605957328
Validation loss: 2.5491336631678645

Epoch: 5| Step: 9
Training loss: 0.15662228817049637
Validation loss: 2.5834424283282824

Epoch: 5| Step: 10
Training loss: 0.09931386327347995
Validation loss: 2.5541280973363825

Epoch: 630| Step: 0
Training loss: 0.2198587825111906
Validation loss: 2.5910487187655566

Epoch: 5| Step: 1
Training loss: 0.1756365710481991
Validation loss: 2.5419645590449558

Epoch: 5| Step: 2
Training loss: 0.12206053503933578
Validation loss: 2.6053796620032723

Epoch: 5| Step: 3
Training loss: 0.13781450402063491
Validation loss: 2.5519016240524337

Epoch: 5| Step: 4
Training loss: 0.2899368182982423
Validation loss: 2.5615321967188898

Epoch: 5| Step: 5
Training loss: 0.09999234777467968
Validation loss: 2.54502637186797

Epoch: 5| Step: 6
Training loss: 0.079416613071086
Validation loss: 2.5308495471525236

Epoch: 5| Step: 7
Training loss: 0.10091392042376399
Validation loss: 2.530784342299185

Epoch: 5| Step: 8
Training loss: 0.1534359611193214
Validation loss: 2.5379094643188043

Epoch: 5| Step: 9
Training loss: 0.13937246623964936
Validation loss: 2.491776031638504

Epoch: 5| Step: 10
Training loss: 0.15263682076810137
Validation loss: 2.533656023655606

Epoch: 631| Step: 0
Training loss: 0.13538404600620635
Validation loss: 2.4886011537572332

Epoch: 5| Step: 1
Training loss: 0.18387300477673152
Validation loss: 2.505056222128308

Epoch: 5| Step: 2
Training loss: 0.15405943262014063
Validation loss: 2.535175341047869

Epoch: 5| Step: 3
Training loss: 0.15415640968169103
Validation loss: 2.541692055491855

Epoch: 5| Step: 4
Training loss: 0.16373952227842767
Validation loss: 2.5330172453553974

Epoch: 5| Step: 5
Training loss: 0.18865183848261938
Validation loss: 2.559944152793279

Epoch: 5| Step: 6
Training loss: 0.14292803377381738
Validation loss: 2.559846126576332

Epoch: 5| Step: 7
Training loss: 0.10546676315979325
Validation loss: 2.5957744746637035

Epoch: 5| Step: 8
Training loss: 0.12457342675647386
Validation loss: 2.5871314418549405

Epoch: 5| Step: 9
Training loss: 0.19264154415203727
Validation loss: 2.577539450436824

Epoch: 5| Step: 10
Training loss: 0.23351498810166627
Validation loss: 2.564411519848234

Epoch: 632| Step: 0
Training loss: 0.1244571715904554
Validation loss: 2.564817564595059

Epoch: 5| Step: 1
Training loss: 0.1601036380787225
Validation loss: 2.552161185956635

Epoch: 5| Step: 2
Training loss: 0.1454487495112569
Validation loss: 2.5550643885236313

Epoch: 5| Step: 3
Training loss: 0.17434417011978232
Validation loss: 2.572481402966107

Epoch: 5| Step: 4
Training loss: 0.11368408186740603
Validation loss: 2.5614595919777803

Epoch: 5| Step: 5
Training loss: 0.11862603040997344
Validation loss: 2.565587573456507

Epoch: 5| Step: 6
Training loss: 0.14463149924210833
Validation loss: 2.590580254353164

Epoch: 5| Step: 7
Training loss: 0.19274694575711376
Validation loss: 2.5603198169348524

Epoch: 5| Step: 8
Training loss: 0.08989386612002057
Validation loss: 2.546173653415183

Epoch: 5| Step: 9
Training loss: 0.12424391575572968
Validation loss: 2.553563875670296

Epoch: 5| Step: 10
Training loss: 0.22639993063806424
Validation loss: 2.5497717294136173

Epoch: 633| Step: 0
Training loss: 0.12862478941899255
Validation loss: 2.562760659723441

Epoch: 5| Step: 1
Training loss: 0.2300885993114726
Validation loss: 2.559442397716962

Epoch: 5| Step: 2
Training loss: 0.11701070244172185
Validation loss: 2.5695706722742204

Epoch: 5| Step: 3
Training loss: 0.11505693173831041
Validation loss: 2.5531414896247178

Epoch: 5| Step: 4
Training loss: 0.1664111810499841
Validation loss: 2.5624985943742122

Epoch: 5| Step: 5
Training loss: 0.14879618775123804
Validation loss: 2.5437321580668937

Epoch: 5| Step: 6
Training loss: 0.15061435530274353
Validation loss: 2.524540394406956

Epoch: 5| Step: 7
Training loss: 0.09865477761162833
Validation loss: 2.4873624735070705

Epoch: 5| Step: 8
Training loss: 0.11431031773196001
Validation loss: 2.5079823471166125

Epoch: 5| Step: 9
Training loss: 0.20168712518761808
Validation loss: 2.4663766730683268

Epoch: 5| Step: 10
Training loss: 0.10452333324828346
Validation loss: 2.516204062130146

Epoch: 634| Step: 0
Training loss: 0.11199549114276326
Validation loss: 2.5308339313661143

Epoch: 5| Step: 1
Training loss: 0.06865283781392069
Validation loss: 2.52824942284417

Epoch: 5| Step: 2
Training loss: 0.07256423625339169
Validation loss: 2.4986054130076885

Epoch: 5| Step: 3
Training loss: 0.17241956316042356
Validation loss: 2.509220401120447

Epoch: 5| Step: 4
Training loss: 0.08909364812337349
Validation loss: 2.5130318613951146

Epoch: 5| Step: 5
Training loss: 0.17914233227268525
Validation loss: 2.5348847489996933

Epoch: 5| Step: 6
Training loss: 0.23497981870008197
Validation loss: 2.5252699070223823

Epoch: 5| Step: 7
Training loss: 0.12059770396947728
Validation loss: 2.535582937377392

Epoch: 5| Step: 8
Training loss: 0.099732962775388
Validation loss: 2.548847444554042

Epoch: 5| Step: 9
Training loss: 0.11798764686938049
Validation loss: 2.559074060063435

Epoch: 5| Step: 10
Training loss: 0.2035287640479957
Validation loss: 2.55567272142697

Epoch: 635| Step: 0
Training loss: 0.21142538480303028
Validation loss: 2.577967631290591

Epoch: 5| Step: 1
Training loss: 0.152840355107134
Validation loss: 2.541100732691957

Epoch: 5| Step: 2
Training loss: 0.13946071091222625
Validation loss: 2.538736132272986

Epoch: 5| Step: 3
Training loss: 0.1277385040222467
Validation loss: 2.480186619344655

Epoch: 5| Step: 4
Training loss: 0.17968907562891898
Validation loss: 2.4791281567797965

Epoch: 5| Step: 5
Training loss: 0.13174046485623844
Validation loss: 2.4853324734839783

Epoch: 5| Step: 6
Training loss: 0.2157443245072748
Validation loss: 2.496356816795097

Epoch: 5| Step: 7
Training loss: 0.1760761172022481
Validation loss: 2.4591752474363933

Epoch: 5| Step: 8
Training loss: 0.1616306820701893
Validation loss: 2.473571803796559

Epoch: 5| Step: 9
Training loss: 0.12574304332127872
Validation loss: 2.470386862804527

Epoch: 5| Step: 10
Training loss: 0.1528838621250964
Validation loss: 2.494880535104777

Epoch: 636| Step: 0
Training loss: 0.1908386826823927
Validation loss: 2.468582124766939

Epoch: 5| Step: 1
Training loss: 0.14215849826910773
Validation loss: 2.529413841267973

Epoch: 5| Step: 2
Training loss: 0.1079164995081109
Validation loss: 2.5215446250378477

Epoch: 5| Step: 3
Training loss: 0.09790982702729908
Validation loss: 2.554576335363799

Epoch: 5| Step: 4
Training loss: 0.12345255476251753
Validation loss: 2.5841115883437378

Epoch: 5| Step: 5
Training loss: 0.19812311627367954
Validation loss: 2.5976528826770457

Epoch: 5| Step: 6
Training loss: 0.09654994890746528
Validation loss: 2.616413470338673

Epoch: 5| Step: 7
Training loss: 0.20001244916019445
Validation loss: 2.610684990576176

Epoch: 5| Step: 8
Training loss: 0.13353941241795234
Validation loss: 2.5840004077223906

Epoch: 5| Step: 9
Training loss: 0.19141297425895334
Validation loss: 2.5582639450184907

Epoch: 5| Step: 10
Training loss: 0.10049241542189774
Validation loss: 2.561007188172925

Epoch: 637| Step: 0
Training loss: 0.13586657471579205
Validation loss: 2.527201950432484

Epoch: 5| Step: 1
Training loss: 0.21012307936944
Validation loss: 2.525751869383969

Epoch: 5| Step: 2
Training loss: 0.2549003653493009
Validation loss: 2.491550743404434

Epoch: 5| Step: 3
Training loss: 0.21808646246949231
Validation loss: 2.500993792604292

Epoch: 5| Step: 4
Training loss: 0.07622204864311388
Validation loss: 2.4871540001469103

Epoch: 5| Step: 5
Training loss: 0.0927035168627107
Validation loss: 2.499495471784177

Epoch: 5| Step: 6
Training loss: 0.13306059525238761
Validation loss: 2.510006773401513

Epoch: 5| Step: 7
Training loss: 0.135768311545859
Validation loss: 2.5187589435504614

Epoch: 5| Step: 8
Training loss: 0.15740505890682444
Validation loss: 2.52045604703207

Epoch: 5| Step: 9
Training loss: 0.18424094547709913
Validation loss: 2.4960408866086397

Epoch: 5| Step: 10
Training loss: 0.1274643581374467
Validation loss: 2.501457156807615

Epoch: 638| Step: 0
Training loss: 0.17779718064887756
Validation loss: 2.474625801929125

Epoch: 5| Step: 1
Training loss: 0.13964789730581095
Validation loss: 2.502394462683379

Epoch: 5| Step: 2
Training loss: 0.16821609626893502
Validation loss: 2.511904365587064

Epoch: 5| Step: 3
Training loss: 0.1371979761359817
Validation loss: 2.5031651083171313

Epoch: 5| Step: 4
Training loss: 0.1941363973176424
Validation loss: 2.51356607462706

Epoch: 5| Step: 5
Training loss: 0.2100641928209889
Validation loss: 2.4749875754165407

Epoch: 5| Step: 6
Training loss: 0.16656160892942454
Validation loss: 2.5151021673060585

Epoch: 5| Step: 7
Training loss: 0.1513270601797379
Validation loss: 2.4933434060267654

Epoch: 5| Step: 8
Training loss: 0.20829192087721748
Validation loss: 2.517854440845996

Epoch: 5| Step: 9
Training loss: 0.10195995468707704
Validation loss: 2.5119202697460796

Epoch: 5| Step: 10
Training loss: 0.07086373522885221
Validation loss: 2.542949754761752

Epoch: 639| Step: 0
Training loss: 0.15091046987697526
Validation loss: 2.5571159949223015

Epoch: 5| Step: 1
Training loss: 0.0988448338085868
Validation loss: 2.5133388563954813

Epoch: 5| Step: 2
Training loss: 0.1935736018542345
Validation loss: 2.539069771704977

Epoch: 5| Step: 3
Training loss: 0.10166875617802949
Validation loss: 2.548451865390702

Epoch: 5| Step: 4
Training loss: 0.15520001120839189
Validation loss: 2.564575917143009

Epoch: 5| Step: 5
Training loss: 0.17224295200952178
Validation loss: 2.526452301583212

Epoch: 5| Step: 6
Training loss: 0.13305720757879855
Validation loss: 2.49244952983751

Epoch: 5| Step: 7
Training loss: 0.09778962087871806
Validation loss: 2.499681425818556

Epoch: 5| Step: 8
Training loss: 0.11027591357287285
Validation loss: 2.5436837824396115

Epoch: 5| Step: 9
Training loss: 0.19686693561022683
Validation loss: 2.537898594192684

Epoch: 5| Step: 10
Training loss: 0.12891741184113983
Validation loss: 2.5201506504285436

Epoch: 640| Step: 0
Training loss: 0.14497023364280467
Validation loss: 2.5397016790053946

Epoch: 5| Step: 1
Training loss: 0.1611749420576848
Validation loss: 2.5150486912643086

Epoch: 5| Step: 2
Training loss: 0.19212891918669783
Validation loss: 2.5201313743538463

Epoch: 5| Step: 3
Training loss: 0.14532763571513796
Validation loss: 2.5524828385717293

Epoch: 5| Step: 4
Training loss: 0.1137495637324634
Validation loss: 2.552470362240323

Epoch: 5| Step: 5
Training loss: 0.129477765645278
Validation loss: 2.551369688110471

Epoch: 5| Step: 6
Training loss: 0.09047774341828091
Validation loss: 2.535892280309544

Epoch: 5| Step: 7
Training loss: 0.11643290758521058
Validation loss: 2.540660548739995

Epoch: 5| Step: 8
Training loss: 0.1058691688877473
Validation loss: 2.5301649532219

Epoch: 5| Step: 9
Training loss: 0.21211586410122552
Validation loss: 2.544339344392278

Epoch: 5| Step: 10
Training loss: 0.12550899319845812
Validation loss: 2.5534139449617514

Epoch: 641| Step: 0
Training loss: 0.19224060921992558
Validation loss: 2.525135691670244

Epoch: 5| Step: 1
Training loss: 0.14492782750205171
Validation loss: 2.548733249058804

Epoch: 5| Step: 2
Training loss: 0.1824763463806213
Validation loss: 2.538043500127595

Epoch: 5| Step: 3
Training loss: 0.15906329668141564
Validation loss: 2.5608678202218016

Epoch: 5| Step: 4
Training loss: 0.09477748681825537
Validation loss: 2.5279436027384334

Epoch: 5| Step: 5
Training loss: 0.1216391999682462
Validation loss: 2.519424522449785

Epoch: 5| Step: 6
Training loss: 0.07963036166955274
Validation loss: 2.5165398188504002

Epoch: 5| Step: 7
Training loss: 0.06831538965102579
Validation loss: 2.486968818535215

Epoch: 5| Step: 8
Training loss: 0.10759143884781956
Validation loss: 2.5416612899080557

Epoch: 5| Step: 9
Training loss: 0.14510731978001767
Validation loss: 2.499154205197098

Epoch: 5| Step: 10
Training loss: 0.08946435578821162
Validation loss: 2.491832840488718

Epoch: 642| Step: 0
Training loss: 0.16893452405936926
Validation loss: 2.4737639078231206

Epoch: 5| Step: 1
Training loss: 0.10048952389199936
Validation loss: 2.4997902105353855

Epoch: 5| Step: 2
Training loss: 0.13440763221443308
Validation loss: 2.52551131487522

Epoch: 5| Step: 3
Training loss: 0.11115432440548664
Validation loss: 2.5523083150481853

Epoch: 5| Step: 4
Training loss: 0.0873964403598939
Validation loss: 2.5198901663031683

Epoch: 5| Step: 5
Training loss: 0.15927338329188334
Validation loss: 2.5294532004444914

Epoch: 5| Step: 6
Training loss: 0.09505926283629695
Validation loss: 2.5463422223926813

Epoch: 5| Step: 7
Training loss: 0.10036761933129378
Validation loss: 2.5314988925822504

Epoch: 5| Step: 8
Training loss: 0.10950430821681202
Validation loss: 2.5125552860340883

Epoch: 5| Step: 9
Training loss: 0.079708040853106
Validation loss: 2.5101970051778264

Epoch: 5| Step: 10
Training loss: 0.08861025673285138
Validation loss: 2.5193406250659747

Epoch: 643| Step: 0
Training loss: 0.17285299569952817
Validation loss: 2.495540236247566

Epoch: 5| Step: 1
Training loss: 0.10632301006445088
Validation loss: 2.4843094008908397

Epoch: 5| Step: 2
Training loss: 0.09937978914404798
Validation loss: 2.512303929970645

Epoch: 5| Step: 3
Training loss: 0.09882983274077503
Validation loss: 2.507692105351246

Epoch: 5| Step: 4
Training loss: 0.1112465727069215
Validation loss: 2.5278774112098263

Epoch: 5| Step: 5
Training loss: 0.09465209255647233
Validation loss: 2.5042891276917683

Epoch: 5| Step: 6
Training loss: 0.15219749864322374
Validation loss: 2.482010701633374

Epoch: 5| Step: 7
Training loss: 0.053388507780664056
Validation loss: 2.4948571312775547

Epoch: 5| Step: 8
Training loss: 0.1487125934521658
Validation loss: 2.481762793398948

Epoch: 5| Step: 9
Training loss: 0.08940109797223247
Validation loss: 2.5152826287047634

Epoch: 5| Step: 10
Training loss: 0.13290592021484146
Validation loss: 2.507164445474172

Epoch: 644| Step: 0
Training loss: 0.17997205013926287
Validation loss: 2.4830893658984188

Epoch: 5| Step: 1
Training loss: 0.12646301003087723
Validation loss: 2.515427513577027

Epoch: 5| Step: 2
Training loss: 0.08208093103786025
Validation loss: 2.509363439508252

Epoch: 5| Step: 3
Training loss: 0.14092512026673903
Validation loss: 2.516426993468883

Epoch: 5| Step: 4
Training loss: 0.10918690908361633
Validation loss: 2.5323688278286904

Epoch: 5| Step: 5
Training loss: 0.10256228411080504
Validation loss: 2.5360852598194743

Epoch: 5| Step: 6
Training loss: 0.08685166283485277
Validation loss: 2.5285953434609074

Epoch: 5| Step: 7
Training loss: 0.08007115240677294
Validation loss: 2.5029896385315307

Epoch: 5| Step: 8
Training loss: 0.05948375839437874
Validation loss: 2.5252013865414233

Epoch: 5| Step: 9
Training loss: 0.1694741214356058
Validation loss: 2.566130373767191

Epoch: 5| Step: 10
Training loss: 0.10553407412142682
Validation loss: 2.544502237617443

Epoch: 645| Step: 0
Training loss: 0.18391826032962974
Validation loss: 2.582158751182836

Epoch: 5| Step: 1
Training loss: 0.18584177774935431
Validation loss: 2.553934477587411

Epoch: 5| Step: 2
Training loss: 0.05683699841181001
Validation loss: 2.5397240510652823

Epoch: 5| Step: 3
Training loss: 0.11993317348922335
Validation loss: 2.5610503721690874

Epoch: 5| Step: 4
Training loss: 0.15824111435261937
Validation loss: 2.555653966065831

Epoch: 5| Step: 5
Training loss: 0.1298826475787729
Validation loss: 2.545629461889035

Epoch: 5| Step: 6
Training loss: 0.12051850631600011
Validation loss: 2.5483733691230905

Epoch: 5| Step: 7
Training loss: 0.10260120053126898
Validation loss: 2.5427307901699243

Epoch: 5| Step: 8
Training loss: 0.08521752416874735
Validation loss: 2.536683135388366

Epoch: 5| Step: 9
Training loss: 0.1919399333949906
Validation loss: 2.536714901219422

Epoch: 5| Step: 10
Training loss: 0.16489319308422976
Validation loss: 2.5051686948929883

Epoch: 646| Step: 0
Training loss: 0.06874504288228347
Validation loss: 2.5066167642283332

Epoch: 5| Step: 1
Training loss: 0.12152665957057524
Validation loss: 2.4838752452891817

Epoch: 5| Step: 2
Training loss: 0.13704845998950238
Validation loss: 2.5171334527345226

Epoch: 5| Step: 3
Training loss: 0.053777865412793426
Validation loss: 2.5143829879092863

Epoch: 5| Step: 4
Training loss: 0.1712719405260698
Validation loss: 2.4904558305032802

Epoch: 5| Step: 5
Training loss: 0.11651730024753296
Validation loss: 2.51665505189449

Epoch: 5| Step: 6
Training loss: 0.21037318544460903
Validation loss: 2.4981275827318234

Epoch: 5| Step: 7
Training loss: 0.16356636711748557
Validation loss: 2.495529059319953

Epoch: 5| Step: 8
Training loss: 0.13202530717736344
Validation loss: 2.528624541941557

Epoch: 5| Step: 9
Training loss: 0.17798479485129465
Validation loss: 2.498111130240648

Epoch: 5| Step: 10
Training loss: 0.1302917324642816
Validation loss: 2.532896819001085

Epoch: 647| Step: 0
Training loss: 0.15255494028995395
Validation loss: 2.5286154101971974

Epoch: 5| Step: 1
Training loss: 0.15146133202343853
Validation loss: 2.5245948483515734

Epoch: 5| Step: 2
Training loss: 0.13692358204266042
Validation loss: 2.5167397268923284

Epoch: 5| Step: 3
Training loss: 0.10041099445591964
Validation loss: 2.53314542023528

Epoch: 5| Step: 4
Training loss: 0.13987330358846967
Validation loss: 2.5374359337763934

Epoch: 5| Step: 5
Training loss: 0.1556684280415152
Validation loss: 2.4834062169868827

Epoch: 5| Step: 6
Training loss: 0.12071373362046638
Validation loss: 2.5277935945834207

Epoch: 5| Step: 7
Training loss: 0.1155126089855316
Validation loss: 2.491634529613845

Epoch: 5| Step: 8
Training loss: 0.12705217312307684
Validation loss: 2.5165086581571874

Epoch: 5| Step: 9
Training loss: 0.17007335400318258
Validation loss: 2.5258690810080306

Epoch: 5| Step: 10
Training loss: 0.11342274527183682
Validation loss: 2.5583903805723276

Epoch: 648| Step: 0
Training loss: 0.11105580234404089
Validation loss: 2.537376488709028

Epoch: 5| Step: 1
Training loss: 0.12000030164879397
Validation loss: 2.56148605135182

Epoch: 5| Step: 2
Training loss: 0.12802197861941597
Validation loss: 2.567570331917532

Epoch: 5| Step: 3
Training loss: 0.12953867530937438
Validation loss: 2.574578698508262

Epoch: 5| Step: 4
Training loss: 0.2257439361414766
Validation loss: 2.546066016789523

Epoch: 5| Step: 5
Training loss: 0.09378813921479116
Validation loss: 2.5640501530420434

Epoch: 5| Step: 6
Training loss: 0.13162206326484371
Validation loss: 2.549060396524127

Epoch: 5| Step: 7
Training loss: 0.20427383562812898
Validation loss: 2.5045303673429893

Epoch: 5| Step: 8
Training loss: 0.2183500448291087
Validation loss: 2.529465584563018

Epoch: 5| Step: 9
Training loss: 0.15015150852636477
Validation loss: 2.5288180111868903

Epoch: 5| Step: 10
Training loss: 0.1203648874247908
Validation loss: 2.525511154489784

Epoch: 649| Step: 0
Training loss: 0.06681242310115432
Validation loss: 2.5337265015031964

Epoch: 5| Step: 1
Training loss: 0.09972487559910864
Validation loss: 2.5292469375272764

Epoch: 5| Step: 2
Training loss: 0.10903165776019876
Validation loss: 2.5328298732974526

Epoch: 5| Step: 3
Training loss: 0.1778101497555162
Validation loss: 2.566106561782158

Epoch: 5| Step: 4
Training loss: 0.14754592896699217
Validation loss: 2.539189844716444

Epoch: 5| Step: 5
Training loss: 0.18634652940557156
Validation loss: 2.5542515092931644

Epoch: 5| Step: 6
Training loss: 0.12915064301493165
Validation loss: 2.5438988813695884

Epoch: 5| Step: 7
Training loss: 0.11302296197735433
Validation loss: 2.5968846073942595

Epoch: 5| Step: 8
Training loss: 0.1771506375614648
Validation loss: 2.5512027593534747

Epoch: 5| Step: 9
Training loss: 0.14175521143915495
Validation loss: 2.5868747595020305

Epoch: 5| Step: 10
Training loss: 0.1090275960762625
Validation loss: 2.5681118217042314

Epoch: 650| Step: 0
Training loss: 0.13985533160196084
Validation loss: 2.530418340396055

Epoch: 5| Step: 1
Training loss: 0.09542461664419147
Validation loss: 2.5403542145040277

Epoch: 5| Step: 2
Training loss: 0.12874514453722863
Validation loss: 2.5400048997609077

Epoch: 5| Step: 3
Training loss: 0.1794909044454416
Validation loss: 2.5428805664160685

Epoch: 5| Step: 4
Training loss: 0.10603011814416119
Validation loss: 2.5594492814806244

Epoch: 5| Step: 5
Training loss: 0.10222559653304258
Validation loss: 2.602799674949469

Epoch: 5| Step: 6
Training loss: 0.1715183024635755
Validation loss: 2.5125915402102192

Epoch: 5| Step: 7
Training loss: 0.13116361352329164
Validation loss: 2.5406227597264834

Epoch: 5| Step: 8
Training loss: 0.12347803566912817
Validation loss: 2.535346053867833

Epoch: 5| Step: 9
Training loss: 0.16489065144875836
Validation loss: 2.491204623093364

Epoch: 5| Step: 10
Training loss: 0.14835049563970526
Validation loss: 2.499767246486426

Testing loss: 2.6543531838380234
