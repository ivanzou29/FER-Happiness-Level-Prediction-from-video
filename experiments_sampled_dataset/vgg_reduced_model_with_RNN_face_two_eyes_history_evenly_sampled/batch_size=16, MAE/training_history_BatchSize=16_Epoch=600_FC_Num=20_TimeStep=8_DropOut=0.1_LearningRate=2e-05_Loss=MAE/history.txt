Epoch: 1| Step: 0
Training loss: 6.230530738830566
Validation loss: 5.136793551906463

Epoch: 6| Step: 1
Training loss: 5.193445205688477
Validation loss: 5.1142812082844396

Epoch: 6| Step: 2
Training loss: 5.320389747619629
Validation loss: 5.093583599213631

Epoch: 6| Step: 3
Training loss: 3.8713643550872803
Validation loss: 5.072175441249724

Epoch: 6| Step: 4
Training loss: 5.40273904800415
Validation loss: 5.048674414234776

Epoch: 6| Step: 5
Training loss: 4.38768196105957
Validation loss: 5.022114466595394

Epoch: 6| Step: 6
Training loss: 3.2729249000549316
Validation loss: 4.992326931286883

Epoch: 6| Step: 7
Training loss: 4.901392936706543
Validation loss: 4.959106342766875

Epoch: 6| Step: 8
Training loss: 4.363587379455566
Validation loss: 4.92274607381513

Epoch: 6| Step: 9
Training loss: 3.596086263656616
Validation loss: 4.880754998935166

Epoch: 6| Step: 10
Training loss: 4.8879852294921875
Validation loss: 4.836228514230379

Epoch: 6| Step: 11
Training loss: 5.373366355895996
Validation loss: 4.786364698922762

Epoch: 6| Step: 12
Training loss: 4.710366249084473
Validation loss: 4.733104510973859

Epoch: 6| Step: 13
Training loss: 5.0831732749938965
Validation loss: 4.67838361699094

Epoch: 2| Step: 0
Training loss: 3.167081832885742
Validation loss: 4.623744867181265

Epoch: 6| Step: 1
Training loss: 5.3636250495910645
Validation loss: 4.570220296100904

Epoch: 6| Step: 2
Training loss: 4.304445266723633
Validation loss: 4.516595953254289

Epoch: 6| Step: 3
Training loss: 4.84279203414917
Validation loss: 4.461025140618765

Epoch: 6| Step: 4
Training loss: 4.306828498840332
Validation loss: 4.405505108576949

Epoch: 6| Step: 5
Training loss: 4.261411190032959
Validation loss: 4.343934738507834

Epoch: 6| Step: 6
Training loss: 4.553112030029297
Validation loss: 4.275387846013551

Epoch: 6| Step: 7
Training loss: 3.23514986038208
Validation loss: 4.199222149387483

Epoch: 6| Step: 8
Training loss: 4.599349021911621
Validation loss: 4.1246943525088735

Epoch: 6| Step: 9
Training loss: 3.909979820251465
Validation loss: 4.060818756780317

Epoch: 6| Step: 10
Training loss: 3.6810007095336914
Validation loss: 4.006849755523025

Epoch: 6| Step: 11
Training loss: 4.489039421081543
Validation loss: 3.9672904501679125

Epoch: 6| Step: 12
Training loss: 3.047062873840332
Validation loss: 3.9294767020851054

Epoch: 6| Step: 13
Training loss: 2.3831734657287598
Validation loss: 3.8907601551343034

Epoch: 3| Step: 0
Training loss: 3.3428378105163574
Validation loss: 3.850678707963677

Epoch: 6| Step: 1
Training loss: 3.9586541652679443
Validation loss: 3.8162458122417493

Epoch: 6| Step: 2
Training loss: 2.7519097328186035
Validation loss: 3.7812146115046676

Epoch: 6| Step: 3
Training loss: 3.4049649238586426
Validation loss: 3.749703832851943

Epoch: 6| Step: 4
Training loss: 3.3698132038116455
Validation loss: 3.732286350701445

Epoch: 6| Step: 5
Training loss: 3.5084991455078125
Validation loss: 3.707572042301137

Epoch: 6| Step: 6
Training loss: 3.740987777709961
Validation loss: 3.677590616287724

Epoch: 6| Step: 7
Training loss: 2.9230968952178955
Validation loss: 3.659009272052396

Epoch: 6| Step: 8
Training loss: 3.3662097454071045
Validation loss: 3.6482011554061726

Epoch: 6| Step: 9
Training loss: 3.3794193267822266
Validation loss: 3.6300802538471837

Epoch: 6| Step: 10
Training loss: 4.047277450561523
Validation loss: 3.614460519565049

Epoch: 6| Step: 11
Training loss: 3.916287422180176
Validation loss: 3.592908784907351

Epoch: 6| Step: 12
Training loss: 4.2874755859375
Validation loss: 3.574943040006904

Epoch: 6| Step: 13
Training loss: 4.732660293579102
Validation loss: 3.5579377605069067

Epoch: 4| Step: 0
Training loss: 3.261613368988037
Validation loss: 3.5468020977512484

Epoch: 6| Step: 1
Training loss: 3.945910930633545
Validation loss: 3.531083135194676

Epoch: 6| Step: 2
Training loss: 4.058677673339844
Validation loss: 3.513638880945021

Epoch: 6| Step: 3
Training loss: 2.2719039916992188
Validation loss: 3.5041302096459175

Epoch: 6| Step: 4
Training loss: 3.2562386989593506
Validation loss: 3.4880344175523326

Epoch: 6| Step: 5
Training loss: 3.353191614151001
Validation loss: 3.4696224709992767

Epoch: 6| Step: 6
Training loss: 4.081022262573242
Validation loss: 3.4566868735897924

Epoch: 6| Step: 7
Training loss: 3.8449597358703613
Validation loss: 3.4551828702290854

Epoch: 6| Step: 8
Training loss: 3.336329460144043
Validation loss: 3.43553493356192

Epoch: 6| Step: 9
Training loss: 3.7864599227905273
Validation loss: 3.4184820190552743

Epoch: 6| Step: 10
Training loss: 2.8036930561065674
Validation loss: 3.409423202596685

Epoch: 6| Step: 11
Training loss: 2.957736015319824
Validation loss: 3.392643831109488

Epoch: 6| Step: 12
Training loss: 3.5111584663391113
Validation loss: 3.3829155916808755

Epoch: 6| Step: 13
Training loss: 2.8319222927093506
Validation loss: 3.3670108882329797

Epoch: 5| Step: 0
Training loss: 3.9863345623016357
Validation loss: 3.351729331477996

Epoch: 6| Step: 1
Training loss: 2.701076030731201
Validation loss: 3.3391154760955484

Epoch: 6| Step: 2
Training loss: 3.031796455383301
Validation loss: 3.3299872567576747

Epoch: 6| Step: 3
Training loss: 4.464843273162842
Validation loss: 3.3239766320874615

Epoch: 6| Step: 4
Training loss: 3.2928009033203125
Validation loss: 3.303374890358217

Epoch: 6| Step: 5
Training loss: 3.0230822563171387
Validation loss: 3.306384886464765

Epoch: 6| Step: 6
Training loss: 2.47464919090271
Validation loss: 3.307681337479622

Epoch: 6| Step: 7
Training loss: 2.9236056804656982
Validation loss: 3.292339409551313

Epoch: 6| Step: 8
Training loss: 3.460787296295166
Validation loss: 3.2746221045012116

Epoch: 6| Step: 9
Training loss: 3.8987793922424316
Validation loss: 3.2610086343621694

Epoch: 6| Step: 10
Training loss: 3.000715970993042
Validation loss: 3.2648943393461165

Epoch: 6| Step: 11
Training loss: 2.4659433364868164
Validation loss: 3.3141765722664456

Epoch: 6| Step: 12
Training loss: 3.599421977996826
Validation loss: 3.2747273445129395

Epoch: 6| Step: 13
Training loss: 3.699131488800049
Validation loss: 3.228914322391633

Epoch: 6| Step: 0
Training loss: 2.02964448928833
Validation loss: 3.2172384723540275

Epoch: 6| Step: 1
Training loss: 3.86258864402771
Validation loss: 3.2239408749406055

Epoch: 6| Step: 2
Training loss: 3.698047161102295
Validation loss: 3.2064896116974535

Epoch: 6| Step: 3
Training loss: 3.6429736614227295
Validation loss: 3.1860714984196488

Epoch: 6| Step: 4
Training loss: 3.0212693214416504
Validation loss: 3.1698743194662113

Epoch: 6| Step: 5
Training loss: 2.7272205352783203
Validation loss: 3.160711916544104

Epoch: 6| Step: 6
Training loss: 3.106416702270508
Validation loss: 3.1646135237909134

Epoch: 6| Step: 7
Training loss: 2.950542449951172
Validation loss: 3.144602567918839

Epoch: 6| Step: 8
Training loss: 2.2953226566314697
Validation loss: 3.127662548454859

Epoch: 6| Step: 9
Training loss: 3.977780818939209
Validation loss: 3.117646114800566

Epoch: 6| Step: 10
Training loss: 3.191606283187866
Validation loss: 3.112466186605474

Epoch: 6| Step: 11
Training loss: 3.0142812728881836
Validation loss: 3.104182243347168

Epoch: 6| Step: 12
Training loss: 3.1897709369659424
Validation loss: 3.095895218592818

Epoch: 6| Step: 13
Training loss: 3.877974271774292
Validation loss: 3.088824554156232

Epoch: 7| Step: 0
Training loss: 3.662402629852295
Validation loss: 3.0736423923123266

Epoch: 6| Step: 1
Training loss: 3.9297335147857666
Validation loss: 3.060342178549818

Epoch: 6| Step: 2
Training loss: 4.083253383636475
Validation loss: 3.0469683703555854

Epoch: 6| Step: 3
Training loss: 2.599916934967041
Validation loss: 3.037386950626168

Epoch: 6| Step: 4
Training loss: 2.690157413482666
Validation loss: 3.028354719120969

Epoch: 6| Step: 5
Training loss: 3.059293746948242
Validation loss: 3.015517293765981

Epoch: 6| Step: 6
Training loss: 2.773745536804199
Validation loss: 3.01033539413124

Epoch: 6| Step: 7
Training loss: 2.087928533554077
Validation loss: 3.0015170676733858

Epoch: 6| Step: 8
Training loss: 2.6867446899414062
Validation loss: 3.019695041000202

Epoch: 6| Step: 9
Training loss: 3.3349547386169434
Validation loss: 2.997769930029428

Epoch: 6| Step: 10
Training loss: 3.173408031463623
Validation loss: 2.992178434966713

Epoch: 6| Step: 11
Training loss: 3.764017105102539
Validation loss: 2.9823504468446136

Epoch: 6| Step: 12
Training loss: 3.1104533672332764
Validation loss: 2.9741955572558987

Epoch: 6| Step: 13
Training loss: 1.2723362445831299
Validation loss: 2.963756933007189

Epoch: 8| Step: 0
Training loss: 3.498307228088379
Validation loss: 2.977840751729986

Epoch: 6| Step: 1
Training loss: 2.3898050785064697
Validation loss: 2.9520324404521654

Epoch: 6| Step: 2
Training loss: 3.084649085998535
Validation loss: 2.9697213044730564

Epoch: 6| Step: 3
Training loss: 3.2440452575683594
Validation loss: 2.946126781484132

Epoch: 6| Step: 4
Training loss: 3.46806001663208
Validation loss: 2.9329052535436486

Epoch: 6| Step: 5
Training loss: 2.7255654335021973
Validation loss: 2.927244160764961

Epoch: 6| Step: 6
Training loss: 3.4077224731445312
Validation loss: 2.927565126008885

Epoch: 6| Step: 7
Training loss: 2.911903142929077
Validation loss: 2.9272226364381853

Epoch: 6| Step: 8
Training loss: 3.760148763656616
Validation loss: 2.915591157892699

Epoch: 6| Step: 9
Training loss: 3.2365856170654297
Validation loss: 2.908951349155877

Epoch: 6| Step: 10
Training loss: 1.966817855834961
Validation loss: 2.9037978085138465

Epoch: 6| Step: 11
Training loss: 3.0291900634765625
Validation loss: 2.894880069199429

Epoch: 6| Step: 12
Training loss: 2.7846107482910156
Validation loss: 2.8894770196689072

Epoch: 6| Step: 13
Training loss: 2.4995944499969482
Validation loss: 2.888248118021155

Epoch: 9| Step: 0
Training loss: 3.357964038848877
Validation loss: 2.888544087768883

Epoch: 6| Step: 1
Training loss: 2.6991848945617676
Validation loss: 2.9055907700651433

Epoch: 6| Step: 2
Training loss: 3.7255568504333496
Validation loss: 2.9022616263358825

Epoch: 6| Step: 3
Training loss: 2.0333454608917236
Validation loss: 2.87212013429211

Epoch: 6| Step: 4
Training loss: 3.1311583518981934
Validation loss: 2.8742923582753828

Epoch: 6| Step: 5
Training loss: 2.6053965091705322
Validation loss: 2.8745584821188324

Epoch: 6| Step: 6
Training loss: 3.049985647201538
Validation loss: 2.8727537585842993

Epoch: 6| Step: 7
Training loss: 2.944298505783081
Validation loss: 2.8642398798337547

Epoch: 6| Step: 8
Training loss: 3.3407576084136963
Validation loss: 2.8659661764739663

Epoch: 6| Step: 9
Training loss: 2.9530768394470215
Validation loss: 2.8805195721246863

Epoch: 6| Step: 10
Training loss: 3.2745304107666016
Validation loss: 2.875459227510678

Epoch: 6| Step: 11
Training loss: 2.378948211669922
Validation loss: 2.8640405747198288

Epoch: 6| Step: 12
Training loss: 2.3345656394958496
Validation loss: 2.8489649500898135

Epoch: 6| Step: 13
Training loss: 4.406881809234619
Validation loss: 2.840954867742395

Epoch: 10| Step: 0
Training loss: 3.9206931591033936
Validation loss: 2.840439586229222

Epoch: 6| Step: 1
Training loss: 2.866727352142334
Validation loss: 2.837081565651842

Epoch: 6| Step: 2
Training loss: 3.298152208328247
Validation loss: 2.832373478079355

Epoch: 6| Step: 3
Training loss: 2.0583698749542236
Validation loss: 2.8266664679332445

Epoch: 6| Step: 4
Training loss: 3.410754919052124
Validation loss: 2.8270052914978354

Epoch: 6| Step: 5
Training loss: 2.672278881072998
Validation loss: 2.8222276754276727

Epoch: 6| Step: 6
Training loss: 3.3334951400756836
Validation loss: 2.8530567538353706

Epoch: 6| Step: 7
Training loss: 2.5787353515625
Validation loss: 2.820424715677897

Epoch: 6| Step: 8
Training loss: 2.338615894317627
Validation loss: 2.8142465109466226

Epoch: 6| Step: 9
Training loss: 3.209714889526367
Validation loss: 2.811004854017688

Epoch: 6| Step: 10
Training loss: 2.677993059158325
Validation loss: 2.8066066644525014

Epoch: 6| Step: 11
Training loss: 3.0852560997009277
Validation loss: 2.7989283582215667

Epoch: 6| Step: 12
Training loss: 3.3672306537628174
Validation loss: 2.8002789917812554

Epoch: 6| Step: 13
Training loss: 1.993154764175415
Validation loss: 2.806806077239334

Epoch: 11| Step: 0
Training loss: 2.7983155250549316
Validation loss: 2.8228719849740305

Epoch: 6| Step: 1
Training loss: 2.4621646404266357
Validation loss: 2.852219720040598

Epoch: 6| Step: 2
Training loss: 3.487905979156494
Validation loss: 2.8353622446778

Epoch: 6| Step: 3
Training loss: 2.5016276836395264
Validation loss: 2.804798098020656

Epoch: 6| Step: 4
Training loss: 2.6507132053375244
Validation loss: 2.8022646852718887

Epoch: 6| Step: 5
Training loss: 2.3448870182037354
Validation loss: 2.804723867806055

Epoch: 6| Step: 6
Training loss: 3.735761880874634
Validation loss: 2.79073271700131

Epoch: 6| Step: 7
Training loss: 3.90047025680542
Validation loss: 2.7798779856774116

Epoch: 6| Step: 8
Training loss: 2.412062406539917
Validation loss: 2.8071244814062632

Epoch: 6| Step: 9
Training loss: 2.9078853130340576
Validation loss: 2.8637270671065136

Epoch: 6| Step: 10
Training loss: 2.506664752960205
Validation loss: 2.8601188121303434

Epoch: 6| Step: 11
Training loss: 2.687358856201172
Validation loss: 2.8354040935475338

Epoch: 6| Step: 12
Training loss: 3.536057949066162
Validation loss: 2.8464565405281643

Epoch: 6| Step: 13
Training loss: 3.361969470977783
Validation loss: 2.8233015537261963

Epoch: 12| Step: 0
Training loss: 2.185591220855713
Validation loss: 2.79432931253987

Epoch: 6| Step: 1
Training loss: 2.255079984664917
Validation loss: 2.75088329469004

Epoch: 6| Step: 2
Training loss: 2.7307066917419434
Validation loss: 2.7658839071950605

Epoch: 6| Step: 3
Training loss: 2.9725537300109863
Validation loss: 2.788428150197511

Epoch: 6| Step: 4
Training loss: 2.9290151596069336
Validation loss: 2.769209861755371

Epoch: 6| Step: 5
Training loss: 2.821925640106201
Validation loss: 2.768681405692972

Epoch: 6| Step: 6
Training loss: 2.8260977268218994
Validation loss: 2.761350395858929

Epoch: 6| Step: 7
Training loss: 3.0074620246887207
Validation loss: 2.7586847505261822

Epoch: 6| Step: 8
Training loss: 2.7793612480163574
Validation loss: 2.7529463050185994

Epoch: 6| Step: 9
Training loss: 3.933359146118164
Validation loss: 2.7472457552468903

Epoch: 6| Step: 10
Training loss: 3.1989169120788574
Validation loss: 2.739150772812546

Epoch: 6| Step: 11
Training loss: 3.4712743759155273
Validation loss: 2.7352457507964103

Epoch: 6| Step: 12
Training loss: 2.738528251647949
Validation loss: 2.7398897652984946

Epoch: 6| Step: 13
Training loss: 2.5461902618408203
Validation loss: 2.755592087263702

Epoch: 13| Step: 0
Training loss: 2.6763298511505127
Validation loss: 2.78282650568152

Epoch: 6| Step: 1
Training loss: 2.908524513244629
Validation loss: 2.7258977479832147

Epoch: 6| Step: 2
Training loss: 2.2213189601898193
Validation loss: 2.7192138292456187

Epoch: 6| Step: 3
Training loss: 2.513385772705078
Validation loss: 2.717469523029943

Epoch: 6| Step: 4
Training loss: 3.1564197540283203
Validation loss: 2.7285455221770913

Epoch: 6| Step: 5
Training loss: 2.833425521850586
Validation loss: 2.7354353550941712

Epoch: 6| Step: 6
Training loss: 3.3090367317199707
Validation loss: 2.7430925317989883

Epoch: 6| Step: 7
Training loss: 2.0027108192443848
Validation loss: 2.7305124780183196

Epoch: 6| Step: 8
Training loss: 3.5904388427734375
Validation loss: 2.722198640146563

Epoch: 6| Step: 9
Training loss: 2.889814853668213
Validation loss: 2.7036270967093845

Epoch: 6| Step: 10
Training loss: 3.1590654850006104
Validation loss: 2.701472346500684

Epoch: 6| Step: 11
Training loss: 3.1137890815734863
Validation loss: 2.695535793099352

Epoch: 6| Step: 12
Training loss: 3.4593796730041504
Validation loss: 2.693695601596627

Epoch: 6| Step: 13
Training loss: 2.193100929260254
Validation loss: 2.6948089445790937

Epoch: 14| Step: 0
Training loss: 2.7586801052093506
Validation loss: 2.6959389742984565

Epoch: 6| Step: 1
Training loss: 2.271286964416504
Validation loss: 2.704679917263728

Epoch: 6| Step: 2
Training loss: 2.8444533348083496
Validation loss: 2.707378807888236

Epoch: 6| Step: 3
Training loss: 2.941368579864502
Validation loss: 2.7057081294316117

Epoch: 6| Step: 4
Training loss: 2.379917621612549
Validation loss: 2.6967216973663657

Epoch: 6| Step: 5
Training loss: 2.9136369228363037
Validation loss: 2.6935997496369066

Epoch: 6| Step: 6
Training loss: 2.3712995052337646
Validation loss: 2.690111662751885

Epoch: 6| Step: 7
Training loss: 2.2414052486419678
Validation loss: 2.6831998645618396

Epoch: 6| Step: 8
Training loss: 3.395020008087158
Validation loss: 2.6847280866356305

Epoch: 6| Step: 9
Training loss: 2.2772655487060547
Validation loss: 2.676344417756604

Epoch: 6| Step: 10
Training loss: 3.4079623222351074
Validation loss: 2.681330014300603

Epoch: 6| Step: 11
Training loss: 3.7767786979675293
Validation loss: 2.6902645044429327

Epoch: 6| Step: 12
Training loss: 3.472921371459961
Validation loss: 2.7395716303138324

Epoch: 6| Step: 13
Training loss: 3.1218109130859375
Validation loss: 2.744798824351321

Epoch: 15| Step: 0
Training loss: 2.8075220584869385
Validation loss: 2.72600830242198

Epoch: 6| Step: 1
Training loss: 2.509331464767456
Validation loss: 2.7046905691905687

Epoch: 6| Step: 2
Training loss: 2.4018421173095703
Validation loss: 2.671263112816759

Epoch: 6| Step: 3
Training loss: 3.3092997074127197
Validation loss: 2.65735077088879

Epoch: 6| Step: 4
Training loss: 3.0697906017303467
Validation loss: 2.6497107551943873

Epoch: 6| Step: 5
Training loss: 2.525731086730957
Validation loss: 2.6480428993061023

Epoch: 6| Step: 6
Training loss: 3.2749345302581787
Validation loss: 2.678685657439693

Epoch: 6| Step: 7
Training loss: 2.8623690605163574
Validation loss: 2.697793940062164

Epoch: 6| Step: 8
Training loss: 3.1494994163513184
Validation loss: 2.6883375542138213

Epoch: 6| Step: 9
Training loss: 3.0762686729431152
Validation loss: 2.6764562770884526

Epoch: 6| Step: 10
Training loss: 3.0912389755249023
Validation loss: 2.6233567601890972

Epoch: 6| Step: 11
Training loss: 2.6252260208129883
Validation loss: 2.626012986706149

Epoch: 6| Step: 12
Training loss: 2.212190628051758
Validation loss: 2.645774707999281

Epoch: 6| Step: 13
Training loss: 2.7511940002441406
Validation loss: 2.650426323695849

Epoch: 16| Step: 0
Training loss: 3.4566473960876465
Validation loss: 2.63519315309422

Epoch: 6| Step: 1
Training loss: 3.135544538497925
Validation loss: 2.640731273158904

Epoch: 6| Step: 2
Training loss: 2.210681438446045
Validation loss: 2.639747752938219

Epoch: 6| Step: 3
Training loss: 3.083071708679199
Validation loss: 2.6407417481945408

Epoch: 6| Step: 4
Training loss: 4.169829368591309
Validation loss: 2.6131882488086657

Epoch: 6| Step: 5
Training loss: 2.1898951530456543
Validation loss: 2.6165626228496595

Epoch: 6| Step: 6
Training loss: 2.992138624191284
Validation loss: 2.6299078208143993

Epoch: 6| Step: 7
Training loss: 3.2469661235809326
Validation loss: 2.655420864782026

Epoch: 6| Step: 8
Training loss: 1.8064732551574707
Validation loss: 2.6332048036718882

Epoch: 6| Step: 9
Training loss: 2.79354190826416
Validation loss: 2.6522640464126424

Epoch: 6| Step: 10
Training loss: 2.188385486602783
Validation loss: 2.670394310387232

Epoch: 6| Step: 11
Training loss: 2.6075901985168457
Validation loss: 2.676110641930693

Epoch: 6| Step: 12
Training loss: 3.259894847869873
Validation loss: 2.668140539558985

Epoch: 6| Step: 13
Training loss: 1.8417614698410034
Validation loss: 2.6579179789430354

Epoch: 17| Step: 0
Training loss: 3.058406352996826
Validation loss: 2.6437525364660446

Epoch: 6| Step: 1
Training loss: 2.6407084465026855
Validation loss: 2.626124438419137

Epoch: 6| Step: 2
Training loss: 2.5278780460357666
Validation loss: 2.6172064581224994

Epoch: 6| Step: 3
Training loss: 2.845025062561035
Validation loss: 2.6165967807974866

Epoch: 6| Step: 4
Training loss: 2.8042023181915283
Validation loss: 2.624176436854947

Epoch: 6| Step: 5
Training loss: 2.2866716384887695
Validation loss: 2.628979277867143

Epoch: 6| Step: 6
Training loss: 3.2018227577209473
Validation loss: 2.6162424343888477

Epoch: 6| Step: 7
Training loss: 2.827911376953125
Validation loss: 2.603818352504443

Epoch: 6| Step: 8
Training loss: 3.120725154876709
Validation loss: 2.599212372174827

Epoch: 6| Step: 9
Training loss: 2.864635705947876
Validation loss: 2.594944930845691

Epoch: 6| Step: 10
Training loss: 2.8002893924713135
Validation loss: 2.5947088579977713

Epoch: 6| Step: 11
Training loss: 2.0841064453125
Validation loss: 2.599527100081085

Epoch: 6| Step: 12
Training loss: 3.3593149185180664
Validation loss: 2.6135993003845215

Epoch: 6| Step: 13
Training loss: 2.580106019973755
Validation loss: 2.5946211507243495

Epoch: 18| Step: 0
Training loss: 2.7938952445983887
Validation loss: 2.596680502737722

Epoch: 6| Step: 1
Training loss: 2.99825119972229
Validation loss: 2.592856849393537

Epoch: 6| Step: 2
Training loss: 3.4223732948303223
Validation loss: 2.59291826012314

Epoch: 6| Step: 3
Training loss: 2.240355968475342
Validation loss: 2.5923698281729095

Epoch: 6| Step: 4
Training loss: 1.817863941192627
Validation loss: 2.5922799776959162

Epoch: 6| Step: 5
Training loss: 2.6996240615844727
Validation loss: 2.596146998866912

Epoch: 6| Step: 6
Training loss: 2.2544660568237305
Validation loss: 2.5761479485419487

Epoch: 6| Step: 7
Training loss: 2.2691500186920166
Validation loss: 2.58317425686826

Epoch: 6| Step: 8
Training loss: 3.264352560043335
Validation loss: 2.590527572939473

Epoch: 6| Step: 9
Training loss: 2.4826931953430176
Validation loss: 2.5904307544872327

Epoch: 6| Step: 10
Training loss: 3.4004898071289062
Validation loss: 2.605499429087485

Epoch: 6| Step: 11
Training loss: 2.1874778270721436
Validation loss: 2.608594076607817

Epoch: 6| Step: 12
Training loss: 3.8279330730438232
Validation loss: 2.6188723271892917

Epoch: 6| Step: 13
Training loss: 3.8439877033233643
Validation loss: 2.6317162975188224

Epoch: 19| Step: 0
Training loss: 3.455738067626953
Validation loss: 2.581632544917445

Epoch: 6| Step: 1
Training loss: 2.4760122299194336
Validation loss: 2.604695604693505

Epoch: 6| Step: 2
Training loss: 2.1608853340148926
Validation loss: 2.664791081541328

Epoch: 6| Step: 3
Training loss: 2.6319122314453125
Validation loss: 2.719636127512942

Epoch: 6| Step: 4
Training loss: 2.3474133014678955
Validation loss: 2.7767049650992117

Epoch: 6| Step: 5
Training loss: 2.600942611694336
Validation loss: 2.7877201854541735

Epoch: 6| Step: 6
Training loss: 3.491499423980713
Validation loss: 2.72720161561043

Epoch: 6| Step: 7
Training loss: 2.793553590774536
Validation loss: 2.6756818320161555

Epoch: 6| Step: 8
Training loss: 2.2610623836517334
Validation loss: 2.6333809386017504

Epoch: 6| Step: 9
Training loss: 2.297999143600464
Validation loss: 2.60425752721807

Epoch: 6| Step: 10
Training loss: 3.577688217163086
Validation loss: 2.5812899630556823

Epoch: 6| Step: 11
Training loss: 3.0041816234588623
Validation loss: 2.5769755840301514

Epoch: 6| Step: 12
Training loss: 3.231703042984009
Validation loss: 2.5806544262875795

Epoch: 6| Step: 13
Training loss: 3.0085301399230957
Validation loss: 2.601397200297284

Epoch: 20| Step: 0
Training loss: 2.705153465270996
Validation loss: 2.5959638651981147

Epoch: 6| Step: 1
Training loss: 2.1432762145996094
Validation loss: 2.5837242731484036

Epoch: 6| Step: 2
Training loss: 2.931887149810791
Validation loss: 2.584527366904802

Epoch: 6| Step: 3
Training loss: 3.221773386001587
Validation loss: 2.577171251338015

Epoch: 6| Step: 4
Training loss: 2.4932708740234375
Validation loss: 2.5698071115760395

Epoch: 6| Step: 5
Training loss: 3.033289909362793
Validation loss: 2.571211099624634

Epoch: 6| Step: 6
Training loss: 3.5225095748901367
Validation loss: 2.5634584760153167

Epoch: 6| Step: 7
Training loss: 2.4306252002716064
Validation loss: 2.5577844778696694

Epoch: 6| Step: 8
Training loss: 2.6715900897979736
Validation loss: 2.5626409540894213

Epoch: 6| Step: 9
Training loss: 2.258082389831543
Validation loss: 2.5635718402042182

Epoch: 6| Step: 10
Training loss: 2.9002914428710938
Validation loss: 2.576556372386153

Epoch: 6| Step: 11
Training loss: 2.806966781616211
Validation loss: 2.5916684904406146

Epoch: 6| Step: 12
Training loss: 2.807065010070801
Validation loss: 2.6068455967851865

Epoch: 6| Step: 13
Training loss: 3.1174325942993164
Validation loss: 2.5928165348627235

Epoch: 21| Step: 0
Training loss: 3.24514102935791
Validation loss: 2.575274275195214

Epoch: 6| Step: 1
Training loss: 1.972704291343689
Validation loss: 2.5827626746187926

Epoch: 6| Step: 2
Training loss: 3.8248114585876465
Validation loss: 2.5692838507313884

Epoch: 6| Step: 3
Training loss: 2.627631902694702
Validation loss: 2.548304929528185

Epoch: 6| Step: 4
Training loss: 2.2850329875946045
Validation loss: 2.540236593574606

Epoch: 6| Step: 5
Training loss: 3.224724531173706
Validation loss: 2.5445534465133504

Epoch: 6| Step: 6
Training loss: 2.8194222450256348
Validation loss: 2.543259205356721

Epoch: 6| Step: 7
Training loss: 2.200254440307617
Validation loss: 2.5419062645204606

Epoch: 6| Step: 8
Training loss: 2.375845432281494
Validation loss: 2.545724033027567

Epoch: 6| Step: 9
Training loss: 2.902554512023926
Validation loss: 2.5435394779328377

Epoch: 6| Step: 10
Training loss: 2.6292319297790527
Validation loss: 2.5397811602520686

Epoch: 6| Step: 11
Training loss: 2.4383647441864014
Validation loss: 2.535983613742295

Epoch: 6| Step: 12
Training loss: 3.044611692428589
Validation loss: 2.530035957213371

Epoch: 6| Step: 13
Training loss: 3.1232287883758545
Validation loss: 2.5253055121309016

Epoch: 22| Step: 0
Training loss: 2.6814825534820557
Validation loss: 2.524592358578918

Epoch: 6| Step: 1
Training loss: 2.989513874053955
Validation loss: 2.525503432878884

Epoch: 6| Step: 2
Training loss: 2.048689365386963
Validation loss: 2.5270605984554497

Epoch: 6| Step: 3
Training loss: 2.1077237129211426
Validation loss: 2.527606746201874

Epoch: 6| Step: 4
Training loss: 3.100574016571045
Validation loss: 2.5230081696664133

Epoch: 6| Step: 5
Training loss: 2.4555907249450684
Validation loss: 2.5213956884158555

Epoch: 6| Step: 6
Training loss: 2.874211311340332
Validation loss: 2.5321080761571086

Epoch: 6| Step: 7
Training loss: 2.9236268997192383
Validation loss: 2.551607475485853

Epoch: 6| Step: 8
Training loss: 2.538490056991577
Validation loss: 2.5738038016903784

Epoch: 6| Step: 9
Training loss: 2.899294853210449
Validation loss: 2.543335853084441

Epoch: 6| Step: 10
Training loss: 2.954073905944824
Validation loss: 2.5276170187099005

Epoch: 6| Step: 11
Training loss: 2.9784514904022217
Validation loss: 2.5137192100606938

Epoch: 6| Step: 12
Training loss: 2.8449065685272217
Validation loss: 2.5092359281355336

Epoch: 6| Step: 13
Training loss: 2.867908239364624
Validation loss: 2.5136771868633967

Epoch: 23| Step: 0
Training loss: 2.8033394813537598
Validation loss: 2.5120445579610844

Epoch: 6| Step: 1
Training loss: 3.3757708072662354
Validation loss: 2.510785159244332

Epoch: 6| Step: 2
Training loss: 2.291727304458618
Validation loss: 2.509526514237927

Epoch: 6| Step: 3
Training loss: 2.9723024368286133
Validation loss: 2.509783965285106

Epoch: 6| Step: 4
Training loss: 2.439716339111328
Validation loss: 2.508843304008566

Epoch: 6| Step: 5
Training loss: 2.5044164657592773
Validation loss: 2.5074165072492374

Epoch: 6| Step: 6
Training loss: 3.087475061416626
Validation loss: 2.5117985176783737

Epoch: 6| Step: 7
Training loss: 2.31021785736084
Validation loss: 2.5092126195148756

Epoch: 6| Step: 8
Training loss: 2.885554790496826
Validation loss: 2.5054015780007965

Epoch: 6| Step: 9
Training loss: 2.639558792114258
Validation loss: 2.504767425598637

Epoch: 6| Step: 10
Training loss: 2.709740161895752
Validation loss: 2.5080839126340804

Epoch: 6| Step: 11
Training loss: 3.304408311843872
Validation loss: 2.5122265572189004

Epoch: 6| Step: 12
Training loss: 2.637065887451172
Validation loss: 2.514384541460263

Epoch: 6| Step: 13
Training loss: 1.761352300643921
Validation loss: 2.5103339969470935

Epoch: 24| Step: 0
Training loss: 2.033344268798828
Validation loss: 2.501945044404717

Epoch: 6| Step: 1
Training loss: 3.2081384658813477
Validation loss: 2.4994552878923315

Epoch: 6| Step: 2
Training loss: 2.471536636352539
Validation loss: 2.4994615047208724

Epoch: 6| Step: 3
Training loss: 3.1394870281219482
Validation loss: 2.495206589339882

Epoch: 6| Step: 4
Training loss: 2.765115737915039
Validation loss: 2.503834109152517

Epoch: 6| Step: 5
Training loss: 1.8614593744277954
Validation loss: 2.514843956116707

Epoch: 6| Step: 6
Training loss: 1.874286413192749
Validation loss: 2.5166562141910678

Epoch: 6| Step: 7
Training loss: 2.4448041915893555
Validation loss: 2.5077565793068177

Epoch: 6| Step: 8
Training loss: 3.401273488998413
Validation loss: 2.49861055292109

Epoch: 6| Step: 9
Training loss: 2.750284194946289
Validation loss: 2.492757071730911

Epoch: 6| Step: 10
Training loss: 3.3916168212890625
Validation loss: 2.490085450551843

Epoch: 6| Step: 11
Training loss: 3.252981662750244
Validation loss: 2.4965536312390397

Epoch: 6| Step: 12
Training loss: 2.897622585296631
Validation loss: 2.4993005952527447

Epoch: 6| Step: 13
Training loss: 2.5806398391723633
Validation loss: 2.49906571449772

Epoch: 25| Step: 0
Training loss: 2.4618606567382812
Validation loss: 2.4965077882171958

Epoch: 6| Step: 1
Training loss: 2.566152572631836
Validation loss: 2.497257730012299

Epoch: 6| Step: 2
Training loss: 2.488581418991089
Validation loss: 2.495203661662276

Epoch: 6| Step: 3
Training loss: 2.5655040740966797
Validation loss: 2.4933827769371772

Epoch: 6| Step: 4
Training loss: 3.382801055908203
Validation loss: 2.4883437541223343

Epoch: 6| Step: 5
Training loss: 1.8611946105957031
Validation loss: 2.485720367841823

Epoch: 6| Step: 6
Training loss: 2.9828763008117676
Validation loss: 2.4849873870931645

Epoch: 6| Step: 7
Training loss: 2.202404022216797
Validation loss: 2.4889707796035276

Epoch: 6| Step: 8
Training loss: 1.8576085567474365
Validation loss: 2.487330690506966

Epoch: 6| Step: 9
Training loss: 3.3515775203704834
Validation loss: 2.491582157791302

Epoch: 6| Step: 10
Training loss: 2.6882216930389404
Validation loss: 2.4891918897628784

Epoch: 6| Step: 11
Training loss: 3.5753302574157715
Validation loss: 2.4904846170897126

Epoch: 6| Step: 12
Training loss: 2.910667896270752
Validation loss: 2.495832348382601

Epoch: 6| Step: 13
Training loss: 3.1412742137908936
Validation loss: 2.5039525237134708

Epoch: 26| Step: 0
Training loss: 2.4440369606018066
Validation loss: 2.509182955629082

Epoch: 6| Step: 1
Training loss: 2.1055986881256104
Validation loss: 2.5151717175719557

Epoch: 6| Step: 2
Training loss: 1.872093677520752
Validation loss: 2.5087007912256385

Epoch: 6| Step: 3
Training loss: 3.51560115814209
Validation loss: 2.51367417458565

Epoch: 6| Step: 4
Training loss: 2.6248788833618164
Validation loss: 2.5126075283173592

Epoch: 6| Step: 5
Training loss: 2.321561813354492
Validation loss: 2.5305457217718965

Epoch: 6| Step: 6
Training loss: 3.192824125289917
Validation loss: 2.5155677308318434

Epoch: 6| Step: 7
Training loss: 3.2925829887390137
Validation loss: 2.4913270704207884

Epoch: 6| Step: 8
Training loss: 2.838843822479248
Validation loss: 2.4775081014120452

Epoch: 6| Step: 9
Training loss: 3.0632810592651367
Validation loss: 2.475048465113486

Epoch: 6| Step: 10
Training loss: 2.59879207611084
Validation loss: 2.478793236517137

Epoch: 6| Step: 11
Training loss: 2.5455150604248047
Validation loss: 2.4865363592742593

Epoch: 6| Step: 12
Training loss: 2.487175941467285
Validation loss: 2.4918718543103946

Epoch: 6| Step: 13
Training loss: 2.9185285568237305
Validation loss: 2.4870676071413103

Epoch: 27| Step: 0
Training loss: 3.409456729888916
Validation loss: 2.491870936527047

Epoch: 6| Step: 1
Training loss: 3.0425596237182617
Validation loss: 2.5051839172199206

Epoch: 6| Step: 2
Training loss: 2.594555377960205
Validation loss: 2.502664710885735

Epoch: 6| Step: 3
Training loss: 3.1656174659729004
Validation loss: 2.5198713335939633

Epoch: 6| Step: 4
Training loss: 2.628627300262451
Validation loss: 2.521106048296857

Epoch: 6| Step: 5
Training loss: 2.8284049034118652
Validation loss: 2.539139191309611

Epoch: 6| Step: 6
Training loss: 2.1602389812469482
Validation loss: 2.5483914908542427

Epoch: 6| Step: 7
Training loss: 3.3366007804870605
Validation loss: 2.5624782834001767

Epoch: 6| Step: 8
Training loss: 3.1234726905822754
Validation loss: 2.5627514034189205

Epoch: 6| Step: 9
Training loss: 2.247692584991455
Validation loss: 2.5524529821129254

Epoch: 6| Step: 10
Training loss: 2.7026889324188232
Validation loss: 2.54824266382443

Epoch: 6| Step: 11
Training loss: 3.099369764328003
Validation loss: 2.545087165729974

Epoch: 6| Step: 12
Training loss: 1.6614162921905518
Validation loss: 2.5487122612614788

Epoch: 6| Step: 13
Training loss: 1.68001127243042
Validation loss: 2.545508961523733

Epoch: 28| Step: 0
Training loss: 2.6397035121917725
Validation loss: 2.5426851421274166

Epoch: 6| Step: 1
Training loss: 3.1422739028930664
Validation loss: 2.55153347856255

Epoch: 6| Step: 2
Training loss: 1.735552191734314
Validation loss: 2.5497014855825775

Epoch: 6| Step: 3
Training loss: 3.4211173057556152
Validation loss: 2.5675372744119294

Epoch: 6| Step: 4
Training loss: 2.960836172103882
Validation loss: 2.5500934303447766

Epoch: 6| Step: 5
Training loss: 2.300102472305298
Validation loss: 2.548795102744974

Epoch: 6| Step: 6
Training loss: 2.9885947704315186
Validation loss: 2.5311458495355423

Epoch: 6| Step: 7
Training loss: 2.6923398971557617
Validation loss: 2.5181436128513788

Epoch: 6| Step: 8
Training loss: 3.5519416332244873
Validation loss: 2.517376430573002

Epoch: 6| Step: 9
Training loss: 2.6142284870147705
Validation loss: 2.5122166910479145

Epoch: 6| Step: 10
Training loss: 3.117748260498047
Validation loss: 2.511703996248143

Epoch: 6| Step: 11
Training loss: 2.435316562652588
Validation loss: 2.508639133104714

Epoch: 6| Step: 12
Training loss: 1.76621413230896
Validation loss: 2.5067380679550992

Epoch: 6| Step: 13
Training loss: 2.554903745651245
Validation loss: 2.506613644220496

Epoch: 29| Step: 0
Training loss: 3.8048057556152344
Validation loss: 2.5067746536706084

Epoch: 6| Step: 1
Training loss: 3.095898151397705
Validation loss: 2.515174973395563

Epoch: 6| Step: 2
Training loss: 2.5485825538635254
Validation loss: 2.520268532537645

Epoch: 6| Step: 3
Training loss: 2.1374895572662354
Validation loss: 2.526685366066553

Epoch: 6| Step: 4
Training loss: 1.9472460746765137
Validation loss: 2.532792429770193

Epoch: 6| Step: 5
Training loss: 2.697770118713379
Validation loss: 2.5256312662555325

Epoch: 6| Step: 6
Training loss: 2.5977163314819336
Validation loss: 2.522632555295062

Epoch: 6| Step: 7
Training loss: 2.781548023223877
Validation loss: 2.5031578233165126

Epoch: 6| Step: 8
Training loss: 2.599217414855957
Validation loss: 2.499742733534946

Epoch: 6| Step: 9
Training loss: 2.939754009246826
Validation loss: 2.49656343460083

Epoch: 6| Step: 10
Training loss: 2.252562999725342
Validation loss: 2.497222008243684

Epoch: 6| Step: 11
Training loss: 2.5421454906463623
Validation loss: 2.4972698701325284

Epoch: 6| Step: 12
Training loss: 3.192277431488037
Validation loss: 2.4957936117725987

Epoch: 6| Step: 13
Training loss: 2.816483736038208
Validation loss: 2.495089905236357

Epoch: 30| Step: 0
Training loss: 2.883586883544922
Validation loss: 2.4935994225163616

Epoch: 6| Step: 1
Training loss: 1.7072144746780396
Validation loss: 2.4998500680410736

Epoch: 6| Step: 2
Training loss: 2.6808974742889404
Validation loss: 2.509074616175826

Epoch: 6| Step: 3
Training loss: 2.374497413635254
Validation loss: 2.5159920646298315

Epoch: 6| Step: 4
Training loss: 2.0270791053771973
Validation loss: 2.5081055702701693

Epoch: 6| Step: 5
Training loss: 3.2701656818389893
Validation loss: 2.495723283419045

Epoch: 6| Step: 6
Training loss: 2.682631254196167
Validation loss: 2.492889601697204

Epoch: 6| Step: 7
Training loss: 3.325230121612549
Validation loss: 2.4907292063518236

Epoch: 6| Step: 8
Training loss: 2.8294620513916016
Validation loss: 2.4890328145796254

Epoch: 6| Step: 9
Training loss: 3.1545915603637695
Validation loss: 2.489211005549277

Epoch: 6| Step: 10
Training loss: 2.5982608795166016
Validation loss: 2.488972851025161

Epoch: 6| Step: 11
Training loss: 2.5661983489990234
Validation loss: 2.489708403105377

Epoch: 6| Step: 12
Training loss: 2.754530906677246
Validation loss: 2.482461613993491

Epoch: 6| Step: 13
Training loss: 3.1841018199920654
Validation loss: 2.485040792854883

Epoch: 31| Step: 0
Training loss: 2.5440123081207275
Validation loss: 2.478075074893172

Epoch: 6| Step: 1
Training loss: 1.9981188774108887
Validation loss: 2.4813088345271286

Epoch: 6| Step: 2
Training loss: 2.5797042846679688
Validation loss: 2.4817271770969516

Epoch: 6| Step: 3
Training loss: 3.122171640396118
Validation loss: 2.4847198686292096

Epoch: 6| Step: 4
Training loss: 2.77020263671875
Validation loss: 2.4881570313566472

Epoch: 6| Step: 5
Training loss: 3.2036385536193848
Validation loss: 2.4952974832186134

Epoch: 6| Step: 6
Training loss: 2.291323661804199
Validation loss: 2.498031275246733

Epoch: 6| Step: 7
Training loss: 2.752464532852173
Validation loss: 2.5040068370039745

Epoch: 6| Step: 8
Training loss: 2.9699289798736572
Validation loss: 2.5007513261610463

Epoch: 6| Step: 9
Training loss: 1.8459489345550537
Validation loss: 2.4956719106243503

Epoch: 6| Step: 10
Training loss: 3.5678815841674805
Validation loss: 2.497979333323817

Epoch: 6| Step: 11
Training loss: 2.268537998199463
Validation loss: 2.4982250275150424

Epoch: 6| Step: 12
Training loss: 3.0961766242980957
Validation loss: 2.503295624127952

Epoch: 6| Step: 13
Training loss: 2.551549196243286
Validation loss: 2.4903520461051696

Epoch: 32| Step: 0
Training loss: 3.0046920776367188
Validation loss: 2.4849647680918374

Epoch: 6| Step: 1
Training loss: 2.7375755310058594
Validation loss: 2.4872629411758913

Epoch: 6| Step: 2
Training loss: 2.714015483856201
Validation loss: 2.4933001328540105

Epoch: 6| Step: 3
Training loss: 2.534611701965332
Validation loss: 2.4863065006912395

Epoch: 6| Step: 4
Training loss: 2.111447811126709
Validation loss: 2.4821134459587837

Epoch: 6| Step: 5
Training loss: 1.8319954872131348
Validation loss: 2.4779501140758557

Epoch: 6| Step: 6
Training loss: 2.7852041721343994
Validation loss: 2.4742927166723434

Epoch: 6| Step: 7
Training loss: 2.8102879524230957
Validation loss: 2.480382652692897

Epoch: 6| Step: 8
Training loss: 2.8961074352264404
Validation loss: 2.477573871612549

Epoch: 6| Step: 9
Training loss: 3.1136598587036133
Validation loss: 2.473304581898515

Epoch: 6| Step: 10
Training loss: 2.784487724304199
Validation loss: 2.4701509347525974

Epoch: 6| Step: 11
Training loss: 2.8877482414245605
Validation loss: 2.472344470280473

Epoch: 6| Step: 12
Training loss: 2.7787294387817383
Validation loss: 2.4717277993438063

Epoch: 6| Step: 13
Training loss: 2.299448013305664
Validation loss: 2.472011294416202

Epoch: 33| Step: 0
Training loss: 2.338064193725586
Validation loss: 2.465226868147491

Epoch: 6| Step: 1
Training loss: 2.6607913970947266
Validation loss: 2.471511984384188

Epoch: 6| Step: 2
Training loss: 2.8706283569335938
Validation loss: 2.4693415587948215

Epoch: 6| Step: 3
Training loss: 3.0110535621643066
Validation loss: 2.474748255104147

Epoch: 6| Step: 4
Training loss: 2.8063507080078125
Validation loss: 2.4747024441278107

Epoch: 6| Step: 5
Training loss: 2.7879552841186523
Validation loss: 2.4744570588552826

Epoch: 6| Step: 6
Training loss: 2.1025214195251465
Validation loss: 2.4720728115368913

Epoch: 6| Step: 7
Training loss: 2.203430652618408
Validation loss: 2.4773932092933246

Epoch: 6| Step: 8
Training loss: 3.0276780128479004
Validation loss: 2.474244717628725

Epoch: 6| Step: 9
Training loss: 2.970527172088623
Validation loss: 2.4753132738092893

Epoch: 6| Step: 10
Training loss: 2.981445789337158
Validation loss: 2.4744554745253695

Epoch: 6| Step: 11
Training loss: 2.932196855545044
Validation loss: 2.466786778101357

Epoch: 6| Step: 12
Training loss: 2.1630494594573975
Validation loss: 2.470161650770454

Epoch: 6| Step: 13
Training loss: 2.6703922748565674
Validation loss: 2.4695275573320288

Epoch: 34| Step: 0
Training loss: 1.9780404567718506
Validation loss: 2.461723627582673

Epoch: 6| Step: 1
Training loss: 2.9558722972869873
Validation loss: 2.466417880468471

Epoch: 6| Step: 2
Training loss: 2.9393599033355713
Validation loss: 2.467435880373883

Epoch: 6| Step: 3
Training loss: 2.947373390197754
Validation loss: 2.4696297594296035

Epoch: 6| Step: 4
Training loss: 3.0565009117126465
Validation loss: 2.465280426445828

Epoch: 6| Step: 5
Training loss: 2.6403250694274902
Validation loss: 2.4601438712048274

Epoch: 6| Step: 6
Training loss: 2.778629779815674
Validation loss: 2.4647967482125885

Epoch: 6| Step: 7
Training loss: 2.787914276123047
Validation loss: 2.462781813836867

Epoch: 6| Step: 8
Training loss: 2.3665785789489746
Validation loss: 2.464107277572796

Epoch: 6| Step: 9
Training loss: 3.0763821601867676
Validation loss: 2.4603685127791537

Epoch: 6| Step: 10
Training loss: 2.1559345722198486
Validation loss: 2.4605336881452993

Epoch: 6| Step: 11
Training loss: 2.1301229000091553
Validation loss: 2.4588876078205724

Epoch: 6| Step: 12
Training loss: 2.470163345336914
Validation loss: 2.457607844824432

Epoch: 6| Step: 13
Training loss: 3.368030548095703
Validation loss: 2.458233294948455

Epoch: 35| Step: 0
Training loss: 3.179989814758301
Validation loss: 2.4562557589623237

Epoch: 6| Step: 1
Training loss: 2.524048328399658
Validation loss: 2.4573067003680813

Epoch: 6| Step: 2
Training loss: 2.3618693351745605
Validation loss: 2.4591050917102444

Epoch: 6| Step: 3
Training loss: 2.6015212535858154
Validation loss: 2.462716881946851

Epoch: 6| Step: 4
Training loss: 1.9081670045852661
Validation loss: 2.4659669373625066

Epoch: 6| Step: 5
Training loss: 2.3191747665405273
Validation loss: 2.4716773340778966

Epoch: 6| Step: 6
Training loss: 2.7597172260284424
Validation loss: 2.470102466562743

Epoch: 6| Step: 7
Training loss: 2.546048164367676
Validation loss: 2.4706297843686995

Epoch: 6| Step: 8
Training loss: 3.163696765899658
Validation loss: 2.463749888122723

Epoch: 6| Step: 9
Training loss: 2.9396002292633057
Validation loss: 2.468004172848117

Epoch: 6| Step: 10
Training loss: 2.201585292816162
Validation loss: 2.470439226396622

Epoch: 6| Step: 11
Training loss: 3.168118953704834
Validation loss: 2.469957100447788

Epoch: 6| Step: 12
Training loss: 2.937079906463623
Validation loss: 2.4638670926452964

Epoch: 6| Step: 13
Training loss: 2.7705137729644775
Validation loss: 2.4543541477572535

Epoch: 36| Step: 0
Training loss: 2.849959373474121
Validation loss: 2.450283896538519

Epoch: 6| Step: 1
Training loss: 2.6196250915527344
Validation loss: 2.4481529599876812

Epoch: 6| Step: 2
Training loss: 1.7491629123687744
Validation loss: 2.451338050185993

Epoch: 6| Step: 3
Training loss: 3.2220983505249023
Validation loss: 2.454861564020957

Epoch: 6| Step: 4
Training loss: 2.6353139877319336
Validation loss: 2.45842723179889

Epoch: 6| Step: 5
Training loss: 2.165680408477783
Validation loss: 2.465821873757147

Epoch: 6| Step: 6
Training loss: 2.81953763961792
Validation loss: 2.4947327913776522

Epoch: 6| Step: 7
Training loss: 2.377807140350342
Validation loss: 2.4899455911369732

Epoch: 6| Step: 8
Training loss: 2.391328811645508
Validation loss: 2.470504653069281

Epoch: 6| Step: 9
Training loss: 3.539928436279297
Validation loss: 2.4513490789680072

Epoch: 6| Step: 10
Training loss: 3.1850802898406982
Validation loss: 2.440443423486525

Epoch: 6| Step: 11
Training loss: 2.1792964935302734
Validation loss: 2.4373920066382295

Epoch: 6| Step: 12
Training loss: 2.663590908050537
Validation loss: 2.4354346977767123

Epoch: 6| Step: 13
Training loss: 3.108480453491211
Validation loss: 2.4326313823781986

Epoch: 37| Step: 0
Training loss: 2.0014591217041016
Validation loss: 2.4355180135337253

Epoch: 6| Step: 1
Training loss: 2.180637836456299
Validation loss: 2.440317343640071

Epoch: 6| Step: 2
Training loss: 3.7639694213867188
Validation loss: 2.4350990005718764

Epoch: 6| Step: 3
Training loss: 2.660860776901245
Validation loss: 2.4303221292393182

Epoch: 6| Step: 4
Training loss: 2.0516505241394043
Validation loss: 2.430279883005286

Epoch: 6| Step: 5
Training loss: 3.117532968521118
Validation loss: 2.430586399570588

Epoch: 6| Step: 6
Training loss: 2.8898189067840576
Validation loss: 2.439188967468918

Epoch: 6| Step: 7
Training loss: 2.02461838722229
Validation loss: 2.44798868702304

Epoch: 6| Step: 8
Training loss: 2.831871271133423
Validation loss: 2.4587451988650906

Epoch: 6| Step: 9
Training loss: 2.0557267665863037
Validation loss: 2.4950946441260715

Epoch: 6| Step: 10
Training loss: 2.957014560699463
Validation loss: 2.5251924632697977

Epoch: 6| Step: 11
Training loss: 3.3099758625030518
Validation loss: 2.517983723712224

Epoch: 6| Step: 12
Training loss: 3.1232762336730957
Validation loss: 2.4943830531130553

Epoch: 6| Step: 13
Training loss: 2.2012929916381836
Validation loss: 2.4749531515182985

Epoch: 38| Step: 0
Training loss: 2.323367118835449
Validation loss: 2.443405077021609

Epoch: 6| Step: 1
Training loss: 2.676304340362549
Validation loss: 2.42773711809548

Epoch: 6| Step: 2
Training loss: 3.145890951156616
Validation loss: 2.4239504875675326

Epoch: 6| Step: 3
Training loss: 3.3185362815856934
Validation loss: 2.4203346083241124

Epoch: 6| Step: 4
Training loss: 3.0082836151123047
Validation loss: 2.4309716122124785

Epoch: 6| Step: 5
Training loss: 2.377969264984131
Validation loss: 2.436386900563394

Epoch: 6| Step: 6
Training loss: 2.5586934089660645
Validation loss: 2.4381942749023438

Epoch: 6| Step: 7
Training loss: 1.9762756824493408
Validation loss: 2.430977139421689

Epoch: 6| Step: 8
Training loss: 3.0231008529663086
Validation loss: 2.4235687050768124

Epoch: 6| Step: 9
Training loss: 3.1181483268737793
Validation loss: 2.417016690777194

Epoch: 6| Step: 10
Training loss: 2.6907670497894287
Validation loss: 2.4160888900039015

Epoch: 6| Step: 11
Training loss: 2.2918589115142822
Validation loss: 2.4203887408779514

Epoch: 6| Step: 12
Training loss: 2.3449578285217285
Validation loss: 2.4310077441635953

Epoch: 6| Step: 13
Training loss: 2.2222776412963867
Validation loss: 2.4738204017762215

Epoch: 39| Step: 0
Training loss: 3.033846378326416
Validation loss: 2.520653111960298

Epoch: 6| Step: 1
Training loss: 2.9229345321655273
Validation loss: 2.5464050513441845

Epoch: 6| Step: 2
Training loss: 3.043618679046631
Validation loss: 2.5756269014009865

Epoch: 6| Step: 3
Training loss: 2.5741443634033203
Validation loss: 2.51785764386577

Epoch: 6| Step: 4
Training loss: 2.7817277908325195
Validation loss: 2.4925081883707354

Epoch: 6| Step: 5
Training loss: 2.761932373046875
Validation loss: 2.4637779702422438

Epoch: 6| Step: 6
Training loss: 2.6624441146850586
Validation loss: 2.443875141041253

Epoch: 6| Step: 7
Training loss: 2.408484935760498
Validation loss: 2.4262908735582904

Epoch: 6| Step: 8
Training loss: 1.6985208988189697
Validation loss: 2.4141627562943326

Epoch: 6| Step: 9
Training loss: 2.193241834640503
Validation loss: 2.4116399159995456

Epoch: 6| Step: 10
Training loss: 2.939588785171509
Validation loss: 2.430719860138432

Epoch: 6| Step: 11
Training loss: 3.086028814315796
Validation loss: 2.421361561744444

Epoch: 6| Step: 12
Training loss: 2.8774707317352295
Validation loss: 2.4213703575954644

Epoch: 6| Step: 13
Training loss: 2.293959617614746
Validation loss: 2.4101180479090702

Epoch: 40| Step: 0
Training loss: 2.847179889678955
Validation loss: 2.403570757117323

Epoch: 6| Step: 1
Training loss: 2.783453941345215
Validation loss: 2.408957025056244

Epoch: 6| Step: 2
Training loss: 3.166779041290283
Validation loss: 2.4034659721518077

Epoch: 6| Step: 3
Training loss: 2.8144519329071045
Validation loss: 2.4024357347078222

Epoch: 6| Step: 4
Training loss: 2.409933567047119
Validation loss: 2.402324127894576

Epoch: 6| Step: 5
Training loss: 2.674138307571411
Validation loss: 2.406578638220346

Epoch: 6| Step: 6
Training loss: 2.7947187423706055
Validation loss: 2.40231760855644

Epoch: 6| Step: 7
Training loss: 2.0765671730041504
Validation loss: 2.408860583459177

Epoch: 6| Step: 8
Training loss: 2.5035018920898438
Validation loss: 2.4259136928025113

Epoch: 6| Step: 9
Training loss: 2.2721290588378906
Validation loss: 2.4432379045794086

Epoch: 6| Step: 10
Training loss: 3.058779239654541
Validation loss: 2.462951772956438

Epoch: 6| Step: 11
Training loss: 2.53013277053833
Validation loss: 2.4892661776593936

Epoch: 6| Step: 12
Training loss: 2.633108139038086
Validation loss: 2.5038694976478495

Epoch: 6| Step: 13
Training loss: 2.0698766708374023
Validation loss: 2.5129668840798

Epoch: 41| Step: 0
Training loss: 3.6113383769989014
Validation loss: 2.5580639275171424

Epoch: 6| Step: 1
Training loss: 2.803709030151367
Validation loss: 2.5314822863507014

Epoch: 6| Step: 2
Training loss: 2.041531562805176
Validation loss: 2.4956256138381137

Epoch: 6| Step: 3
Training loss: 2.2230002880096436
Validation loss: 2.461845353085508

Epoch: 6| Step: 4
Training loss: 2.2654004096984863
Validation loss: 2.4316579705925396

Epoch: 6| Step: 5
Training loss: 3.1509408950805664
Validation loss: 2.414857074778567

Epoch: 6| Step: 6
Training loss: 2.928321123123169
Validation loss: 2.4009226137591946

Epoch: 6| Step: 7
Training loss: 3.0136427879333496
Validation loss: 2.401699055907547

Epoch: 6| Step: 8
Training loss: 2.765630006790161
Validation loss: 2.3969069668041763

Epoch: 6| Step: 9
Training loss: 2.7391433715820312
Validation loss: 2.394555445640318

Epoch: 6| Step: 10
Training loss: 1.8621203899383545
Validation loss: 2.3913011499630508

Epoch: 6| Step: 11
Training loss: 3.1374707221984863
Validation loss: 2.394914368147491

Epoch: 6| Step: 12
Training loss: 1.862422227859497
Validation loss: 2.394646147246002

Epoch: 6| Step: 13
Training loss: 3.096567392349243
Validation loss: 2.395123871423865

Epoch: 42| Step: 0
Training loss: 3.5392541885375977
Validation loss: 2.406553009504913

Epoch: 6| Step: 1
Training loss: 2.1475322246551514
Validation loss: 2.4144182923019573

Epoch: 6| Step: 2
Training loss: 2.8274409770965576
Validation loss: 2.4263185839499197

Epoch: 6| Step: 3
Training loss: 2.2885913848876953
Validation loss: 2.425469003697877

Epoch: 6| Step: 4
Training loss: 3.2096893787384033
Validation loss: 2.441503888817244

Epoch: 6| Step: 5
Training loss: 2.514470100402832
Validation loss: 2.449971091362738

Epoch: 6| Step: 6
Training loss: 2.8047375679016113
Validation loss: 2.456954433071998

Epoch: 6| Step: 7
Training loss: 2.9656755924224854
Validation loss: 2.4663675369754916

Epoch: 6| Step: 8
Training loss: 1.8498616218566895
Validation loss: 2.4367298541530484

Epoch: 6| Step: 9
Training loss: 2.3231775760650635
Validation loss: 2.422074435859598

Epoch: 6| Step: 10
Training loss: 2.8357646465301514
Validation loss: 2.4137574472735004

Epoch: 6| Step: 11
Training loss: 2.4399008750915527
Validation loss: 2.4168383588073072

Epoch: 6| Step: 12
Training loss: 2.903578758239746
Validation loss: 2.402225694348735

Epoch: 6| Step: 13
Training loss: 2.0697131156921387
Validation loss: 2.4005679609954997

Epoch: 43| Step: 0
Training loss: 2.698352813720703
Validation loss: 2.3875689275803103

Epoch: 6| Step: 1
Training loss: 2.5910654067993164
Validation loss: 2.384701264801846

Epoch: 6| Step: 2
Training loss: 2.2915608882904053
Validation loss: 2.3815627098083496

Epoch: 6| Step: 3
Training loss: 1.99000883102417
Validation loss: 2.3789440906176003

Epoch: 6| Step: 4
Training loss: 2.6116514205932617
Validation loss: 2.374550014413813

Epoch: 6| Step: 5
Training loss: 2.77077317237854
Validation loss: 2.3806454520071707

Epoch: 6| Step: 6
Training loss: 2.298243999481201
Validation loss: 2.3811617974312074

Epoch: 6| Step: 7
Training loss: 3.040287733078003
Validation loss: 2.378567695617676

Epoch: 6| Step: 8
Training loss: 2.8976597785949707
Validation loss: 2.376747408220845

Epoch: 6| Step: 9
Training loss: 3.091980457305908
Validation loss: 2.3768956891952024

Epoch: 6| Step: 10
Training loss: 2.479001045227051
Validation loss: 2.381959225541802

Epoch: 6| Step: 11
Training loss: 3.117948532104492
Validation loss: 2.3734923049967778

Epoch: 6| Step: 12
Training loss: 2.2029528617858887
Validation loss: 2.3780150541695217

Epoch: 6| Step: 13
Training loss: 2.7183029651641846
Validation loss: 2.3800693814472487

Epoch: 44| Step: 0
Training loss: 2.637169599533081
Validation loss: 2.3787003050568285

Epoch: 6| Step: 1
Training loss: 2.343242883682251
Validation loss: 2.3853193765045493

Epoch: 6| Step: 2
Training loss: 3.2921395301818848
Validation loss: 2.383947971046612

Epoch: 6| Step: 3
Training loss: 3.131964683532715
Validation loss: 2.403905104565364

Epoch: 6| Step: 4
Training loss: 3.158668041229248
Validation loss: 2.427033362850066

Epoch: 6| Step: 5
Training loss: 3.0442655086517334
Validation loss: 2.4200299324527865

Epoch: 6| Step: 6
Training loss: 2.397122859954834
Validation loss: 2.4149319715397333

Epoch: 6| Step: 7
Training loss: 2.362569570541382
Validation loss: 2.398243696458878

Epoch: 6| Step: 8
Training loss: 2.6277012825012207
Validation loss: 2.386960111638551

Epoch: 6| Step: 9
Training loss: 2.7436683177948
Validation loss: 2.384276964331186

Epoch: 6| Step: 10
Training loss: 2.2911312580108643
Validation loss: 2.3779774122340704

Epoch: 6| Step: 11
Training loss: 2.177987575531006
Validation loss: 2.373799415044887

Epoch: 6| Step: 12
Training loss: 1.6765986680984497
Validation loss: 2.3828132998558784

Epoch: 6| Step: 13
Training loss: 3.125967502593994
Validation loss: 2.376864451234059

Epoch: 45| Step: 0
Training loss: 2.664447784423828
Validation loss: 2.3754946852243073

Epoch: 6| Step: 1
Training loss: 2.82124662399292
Validation loss: 2.380120518387005

Epoch: 6| Step: 2
Training loss: 1.7446317672729492
Validation loss: 2.3766319597921064

Epoch: 6| Step: 3
Training loss: 2.312422752380371
Validation loss: 2.3799232308582594

Epoch: 6| Step: 4
Training loss: 2.8692569732666016
Validation loss: 2.383037392811109

Epoch: 6| Step: 5
Training loss: 2.6587724685668945
Validation loss: 2.380759862161452

Epoch: 6| Step: 6
Training loss: 2.9792635440826416
Validation loss: 2.3798498363905054

Epoch: 6| Step: 7
Training loss: 2.3768396377563477
Validation loss: 2.3663871442118

Epoch: 6| Step: 8
Training loss: 2.8780665397644043
Validation loss: 2.3662888055206626

Epoch: 6| Step: 9
Training loss: 1.9645426273345947
Validation loss: 2.3698762104075444

Epoch: 6| Step: 10
Training loss: 3.1383283138275146
Validation loss: 2.369456124562089

Epoch: 6| Step: 11
Training loss: 3.0303919315338135
Validation loss: 2.383908746063068

Epoch: 6| Step: 12
Training loss: 2.6654181480407715
Validation loss: 2.3876243124726

Epoch: 6| Step: 13
Training loss: 2.52176570892334
Validation loss: 2.3914013472936486

Epoch: 46| Step: 0
Training loss: 2.213609218597412
Validation loss: 2.3927218683304323

Epoch: 6| Step: 1
Training loss: 3.069901704788208
Validation loss: 2.387349695287725

Epoch: 6| Step: 2
Training loss: 2.5615015029907227
Validation loss: 2.3960447670311056

Epoch: 6| Step: 3
Training loss: 1.860300064086914
Validation loss: 2.4079648628029773

Epoch: 6| Step: 4
Training loss: 3.2779738903045654
Validation loss: 2.393399997424054

Epoch: 6| Step: 5
Training loss: 2.677720785140991
Validation loss: 2.3802521203153875

Epoch: 6| Step: 6
Training loss: 2.909606456756592
Validation loss: 2.3652500260260796

Epoch: 6| Step: 7
Training loss: 2.0005338191986084
Validation loss: 2.357208462171657

Epoch: 6| Step: 8
Training loss: 2.8323192596435547
Validation loss: 2.3619886213733303

Epoch: 6| Step: 9
Training loss: 1.8275758028030396
Validation loss: 2.3635312100892425

Epoch: 6| Step: 10
Training loss: 2.9697391986846924
Validation loss: 2.3685276457058486

Epoch: 6| Step: 11
Training loss: 3.650053024291992
Validation loss: 2.3571512378672117

Epoch: 6| Step: 12
Training loss: 2.788029909133911
Validation loss: 2.3540694893047376

Epoch: 6| Step: 13
Training loss: 1.852724313735962
Validation loss: 2.356028510678199

Epoch: 47| Step: 0
Training loss: 1.905154824256897
Validation loss: 2.374958474148986

Epoch: 6| Step: 1
Training loss: 3.0421290397644043
Validation loss: 2.390448183141729

Epoch: 6| Step: 2
Training loss: 2.86944580078125
Validation loss: 2.4445425746261433

Epoch: 6| Step: 3
Training loss: 2.7899370193481445
Validation loss: 2.460123654334776

Epoch: 6| Step: 4
Training loss: 2.701385974884033
Validation loss: 2.442850576933994

Epoch: 6| Step: 5
Training loss: 3.3124027252197266
Validation loss: 2.412929747694282

Epoch: 6| Step: 6
Training loss: 2.477538585662842
Validation loss: 2.395590974438575

Epoch: 6| Step: 7
Training loss: 2.8030858039855957
Validation loss: 2.3821420220918554

Epoch: 6| Step: 8
Training loss: 2.50292706489563
Validation loss: 2.354148610945671

Epoch: 6| Step: 9
Training loss: 3.130094051361084
Validation loss: 2.3484163527847617

Epoch: 6| Step: 10
Training loss: 2.1850905418395996
Validation loss: 2.349523203347319

Epoch: 6| Step: 11
Training loss: 1.9124102592468262
Validation loss: 2.353654376922115

Epoch: 6| Step: 12
Training loss: 2.5782580375671387
Validation loss: 2.3616259610781105

Epoch: 6| Step: 13
Training loss: 2.4792301654815674
Validation loss: 2.366008391944311

Epoch: 48| Step: 0
Training loss: 2.570469856262207
Validation loss: 2.383438943534769

Epoch: 6| Step: 1
Training loss: 2.61899995803833
Validation loss: 2.402040368767195

Epoch: 6| Step: 2
Training loss: 3.2866806983947754
Validation loss: 2.4250725546190814

Epoch: 6| Step: 3
Training loss: 1.6992897987365723
Validation loss: 2.4082106595398276

Epoch: 6| Step: 4
Training loss: 2.9315848350524902
Validation loss: 2.39438965500042

Epoch: 6| Step: 5
Training loss: 2.6409177780151367
Validation loss: 2.3805148498986357

Epoch: 6| Step: 6
Training loss: 2.2840576171875
Validation loss: 2.369613189851084

Epoch: 6| Step: 7
Training loss: 2.9780232906341553
Validation loss: 2.3663480166466004

Epoch: 6| Step: 8
Training loss: 2.3275365829467773
Validation loss: 2.363619327545166

Epoch: 6| Step: 9
Training loss: 2.8840107917785645
Validation loss: 2.3623705653734106

Epoch: 6| Step: 10
Training loss: 2.0238752365112305
Validation loss: 2.358884508891772

Epoch: 6| Step: 11
Training loss: 2.7900681495666504
Validation loss: 2.3545467469000045

Epoch: 6| Step: 12
Training loss: 2.9413328170776367
Validation loss: 2.3672520909258115

Epoch: 6| Step: 13
Training loss: 3.2013731002807617
Validation loss: 2.3837033010298208

Epoch: 49| Step: 0
Training loss: 3.116593837738037
Validation loss: 2.401713122603714

Epoch: 6| Step: 1
Training loss: 2.6249027252197266
Validation loss: 2.43617485671915

Epoch: 6| Step: 2
Training loss: 1.757541298866272
Validation loss: 2.4205871038539435

Epoch: 6| Step: 3
Training loss: 2.349325180053711
Validation loss: 2.4265512112648255

Epoch: 6| Step: 4
Training loss: 1.8046505451202393
Validation loss: 2.3976624345266693

Epoch: 6| Step: 5
Training loss: 2.759897232055664
Validation loss: 2.371850571324748

Epoch: 6| Step: 6
Training loss: 3.2696971893310547
Validation loss: 2.3533735711087465

Epoch: 6| Step: 7
Training loss: 3.186412811279297
Validation loss: 2.34674390926156

Epoch: 6| Step: 8
Training loss: 2.1679725646972656
Validation loss: 2.3396956433532057

Epoch: 6| Step: 9
Training loss: 2.429738759994507
Validation loss: 2.344631364268641

Epoch: 6| Step: 10
Training loss: 2.441683292388916
Validation loss: 2.346273891387447

Epoch: 6| Step: 11
Training loss: 3.210442543029785
Validation loss: 2.343637148539225

Epoch: 6| Step: 12
Training loss: 3.1544885635375977
Validation loss: 2.3385963183577343

Epoch: 6| Step: 13
Training loss: 2.2853519916534424
Validation loss: 2.335576723980647

Epoch: 50| Step: 0
Training loss: 2.720975637435913
Validation loss: 2.334044243699761

Epoch: 6| Step: 1
Training loss: 2.8519480228424072
Validation loss: 2.335457491618331

Epoch: 6| Step: 2
Training loss: 2.1985678672790527
Validation loss: 2.333222048256987

Epoch: 6| Step: 3
Training loss: 2.7603089809417725
Validation loss: 2.3354623266445693

Epoch: 6| Step: 4
Training loss: 2.066507339477539
Validation loss: 2.3381160895029702

Epoch: 6| Step: 5
Training loss: 3.005885601043701
Validation loss: 2.336838678647113

Epoch: 6| Step: 6
Training loss: 2.7319283485412598
Validation loss: 2.3566148691279913

Epoch: 6| Step: 7
Training loss: 2.2496337890625
Validation loss: 2.356290696769632

Epoch: 6| Step: 8
Training loss: 2.7357189655303955
Validation loss: 2.3457896863260577

Epoch: 6| Step: 9
Training loss: 2.893700122833252
Validation loss: 2.3572065727685088

Epoch: 6| Step: 10
Training loss: 2.7581539154052734
Validation loss: 2.347347935040792

Epoch: 6| Step: 11
Training loss: 2.1854023933410645
Validation loss: 2.3436966198746876

Epoch: 6| Step: 12
Training loss: 2.8197333812713623
Validation loss: 2.341259087285688

Epoch: 6| Step: 13
Training loss: 2.431020498275757
Validation loss: 2.341977286082442

Epoch: 51| Step: 0
Training loss: 2.5990450382232666
Validation loss: 2.3361250277488463

Epoch: 6| Step: 1
Training loss: 2.967863082885742
Validation loss: 2.3400538531682824

Epoch: 6| Step: 2
Training loss: 2.772906541824341
Validation loss: 2.3442292187803533

Epoch: 6| Step: 3
Training loss: 2.442023754119873
Validation loss: 2.3838159358629616

Epoch: 6| Step: 4
Training loss: 2.6283907890319824
Validation loss: 2.4287219432092484

Epoch: 6| Step: 5
Training loss: 2.018956422805786
Validation loss: 2.3947137043040287

Epoch: 6| Step: 6
Training loss: 2.7382314205169678
Validation loss: 2.352630897234845

Epoch: 6| Step: 7
Training loss: 2.163656234741211
Validation loss: 2.3270958713305894

Epoch: 6| Step: 8
Training loss: 3.110288619995117
Validation loss: 2.318047003079486

Epoch: 6| Step: 9
Training loss: 2.499117374420166
Validation loss: 2.3169914599387877

Epoch: 6| Step: 10
Training loss: 2.6557698249816895
Validation loss: 2.3165067318947083

Epoch: 6| Step: 11
Training loss: 2.665912628173828
Validation loss: 2.3156570567879626

Epoch: 6| Step: 12
Training loss: 2.488862991333008
Validation loss: 2.3191810525873655

Epoch: 6| Step: 13
Training loss: 2.882899284362793
Validation loss: 2.31824077329328

Epoch: 52| Step: 0
Training loss: 3.1480872631073
Validation loss: 2.3280265433813936

Epoch: 6| Step: 1
Training loss: 1.8443009853363037
Validation loss: 2.3560456127248783

Epoch: 6| Step: 2
Training loss: 2.2385666370391846
Validation loss: 2.373025930056008

Epoch: 6| Step: 3
Training loss: 2.7248780727386475
Validation loss: 2.4080489297066965

Epoch: 6| Step: 4
Training loss: 2.3025412559509277
Validation loss: 2.4122004457699355

Epoch: 6| Step: 5
Training loss: 2.5250186920166016
Validation loss: 2.3920286009388585

Epoch: 6| Step: 6
Training loss: 3.161635637283325
Validation loss: 2.36217160378733

Epoch: 6| Step: 7
Training loss: 2.0928404331207275
Validation loss: 2.349593540673615

Epoch: 6| Step: 8
Training loss: 2.307905673980713
Validation loss: 2.3296294955797094

Epoch: 6| Step: 9
Training loss: 2.381408214569092
Validation loss: 2.320421532918048

Epoch: 6| Step: 10
Training loss: 3.256213426589966
Validation loss: 2.3236511573996594

Epoch: 6| Step: 11
Training loss: 2.944289207458496
Validation loss: 2.3311799008359193

Epoch: 6| Step: 12
Training loss: 2.6560957431793213
Validation loss: 2.319282211283202

Epoch: 6| Step: 13
Training loss: 3.6284701824188232
Validation loss: 2.3148568637909426

Epoch: 53| Step: 0
Training loss: 2.251220226287842
Validation loss: 2.312891640970784

Epoch: 6| Step: 1
Training loss: 2.380962610244751
Validation loss: 2.314292525732389

Epoch: 6| Step: 2
Training loss: 2.9908251762390137
Validation loss: 2.307075177469561

Epoch: 6| Step: 3
Training loss: 2.651726722717285
Validation loss: 2.3047054172844015

Epoch: 6| Step: 4
Training loss: 2.7735161781311035
Validation loss: 2.305325354299238

Epoch: 6| Step: 5
Training loss: 2.4027228355407715
Validation loss: 2.301855407735353

Epoch: 6| Step: 6
Training loss: 2.254915475845337
Validation loss: 2.303586544529084

Epoch: 6| Step: 7
Training loss: 2.831801414489746
Validation loss: 2.303758400742726

Epoch: 6| Step: 8
Training loss: 2.8120925426483154
Validation loss: 2.3035456903519167

Epoch: 6| Step: 9
Training loss: 2.7147932052612305
Validation loss: 2.307541016609438

Epoch: 6| Step: 10
Training loss: 2.571653127670288
Validation loss: 2.307714964753838

Epoch: 6| Step: 11
Training loss: 3.1497268676757812
Validation loss: 2.311458682501188

Epoch: 6| Step: 12
Training loss: 1.9705456495285034
Validation loss: 2.320408959542551

Epoch: 6| Step: 13
Training loss: 2.424994945526123
Validation loss: 2.3360248022182013

Epoch: 54| Step: 0
Training loss: 2.207014560699463
Validation loss: 2.3513696732059604

Epoch: 6| Step: 1
Training loss: 2.569453716278076
Validation loss: 2.367533242830666

Epoch: 6| Step: 2
Training loss: 2.8037078380584717
Validation loss: 2.3849483741227018

Epoch: 6| Step: 3
Training loss: 2.0669057369232178
Validation loss: 2.3702026554333266

Epoch: 6| Step: 4
Training loss: 3.111797332763672
Validation loss: 2.357545247641943

Epoch: 6| Step: 5
Training loss: 2.589127540588379
Validation loss: 2.3453571309325514

Epoch: 6| Step: 6
Training loss: 2.369750499725342
Validation loss: 2.316640761590773

Epoch: 6| Step: 7
Training loss: 2.973924398422241
Validation loss: 2.302577039246918

Epoch: 6| Step: 8
Training loss: 2.5933587551116943
Validation loss: 2.2962331528304727

Epoch: 6| Step: 9
Training loss: 2.81711745262146
Validation loss: 2.294890880584717

Epoch: 6| Step: 10
Training loss: 2.054156541824341
Validation loss: 2.2975535700398106

Epoch: 6| Step: 11
Training loss: 2.487636089324951
Validation loss: 2.3074280356848114

Epoch: 6| Step: 12
Training loss: 2.854279041290283
Validation loss: 2.3100623956290622

Epoch: 6| Step: 13
Training loss: 3.178339719772339
Validation loss: 2.3143443292187107

Epoch: 55| Step: 0
Training loss: 2.5754380226135254
Validation loss: 2.303213360489056

Epoch: 6| Step: 1
Training loss: 2.5038604736328125
Validation loss: 2.292515052262173

Epoch: 6| Step: 2
Training loss: 2.194702625274658
Validation loss: 2.302129783938008

Epoch: 6| Step: 3
Training loss: 2.6878578662872314
Validation loss: 2.3370119269176195

Epoch: 6| Step: 4
Training loss: 2.8204829692840576
Validation loss: 2.393416848233951

Epoch: 6| Step: 5
Training loss: 2.572065830230713
Validation loss: 2.4256428877512612

Epoch: 6| Step: 6
Training loss: 2.7114040851593018
Validation loss: 2.4203204826642106

Epoch: 6| Step: 7
Training loss: 2.2255871295928955
Validation loss: 2.381058189176744

Epoch: 6| Step: 8
Training loss: 3.4944770336151123
Validation loss: 2.347485347460675

Epoch: 6| Step: 9
Training loss: 2.3223605155944824
Validation loss: 2.3337143980046755

Epoch: 6| Step: 10
Training loss: 2.3891594409942627
Validation loss: 2.3350968719810568

Epoch: 6| Step: 11
Training loss: 2.5831351280212402
Validation loss: 2.3104098048261417

Epoch: 6| Step: 12
Training loss: 3.246427059173584
Validation loss: 2.303039432853781

Epoch: 6| Step: 13
Training loss: 1.657612919807434
Validation loss: 2.291273809248401

Epoch: 56| Step: 0
Training loss: 2.303283452987671
Validation loss: 2.289874279370872

Epoch: 6| Step: 1
Training loss: 3.308671712875366
Validation loss: 2.285568147577265

Epoch: 6| Step: 2
Training loss: 2.423670530319214
Validation loss: 2.286195844732305

Epoch: 6| Step: 3
Training loss: 2.9265480041503906
Validation loss: 2.283505106485018

Epoch: 6| Step: 4
Training loss: 2.4808056354522705
Validation loss: 2.2919085153969387

Epoch: 6| Step: 5
Training loss: 2.4763736724853516
Validation loss: 2.2951963127300306

Epoch: 6| Step: 6
Training loss: 3.445730209350586
Validation loss: 2.2907013534217753

Epoch: 6| Step: 7
Training loss: 2.8919825553894043
Validation loss: 2.280091377996629

Epoch: 6| Step: 8
Training loss: 2.8147804737091064
Validation loss: 2.2799819964234547

Epoch: 6| Step: 9
Training loss: 2.157705783843994
Validation loss: 2.2790071707899853

Epoch: 6| Step: 10
Training loss: 2.299403429031372
Validation loss: 2.2791009795281196

Epoch: 6| Step: 11
Training loss: 2.120490074157715
Validation loss: 2.2786191573707004

Epoch: 6| Step: 12
Training loss: 2.020472526550293
Validation loss: 2.293065091615082

Epoch: 6| Step: 13
Training loss: 2.2245211601257324
Validation loss: 2.3157271646684214

Epoch: 57| Step: 0
Training loss: 2.7744085788726807
Validation loss: 2.37788551597185

Epoch: 6| Step: 1
Training loss: 3.039602756500244
Validation loss: 2.43782461971365

Epoch: 6| Step: 2
Training loss: 2.757542848587036
Validation loss: 2.4474137931741695

Epoch: 6| Step: 3
Training loss: 2.4199655055999756
Validation loss: 2.4668792447736188

Epoch: 6| Step: 4
Training loss: 2.3502843379974365
Validation loss: 2.424025340746808

Epoch: 6| Step: 5
Training loss: 2.8064827919006348
Validation loss: 2.4188872768032934

Epoch: 6| Step: 6
Training loss: 2.256101369857788
Validation loss: 2.359042139463527

Epoch: 6| Step: 7
Training loss: 1.8589715957641602
Validation loss: 2.312891629434401

Epoch: 6| Step: 8
Training loss: 2.433156967163086
Validation loss: 2.2873232185199694

Epoch: 6| Step: 9
Training loss: 2.589297294616699
Validation loss: 2.2808259225660756

Epoch: 6| Step: 10
Training loss: 2.430283308029175
Validation loss: 2.2854280651256604

Epoch: 6| Step: 11
Training loss: 3.1207387447357178
Validation loss: 2.2969736386370916

Epoch: 6| Step: 12
Training loss: 2.689600706100464
Validation loss: 2.3201979052635933

Epoch: 6| Step: 13
Training loss: 3.126072883605957
Validation loss: 2.3183318235540904

Epoch: 58| Step: 0
Training loss: 2.5904016494750977
Validation loss: 2.3126303149807836

Epoch: 6| Step: 1
Training loss: 2.5756213665008545
Validation loss: 2.2944379839845883

Epoch: 6| Step: 2
Training loss: 2.284966230392456
Validation loss: 2.288978206214084

Epoch: 6| Step: 3
Training loss: 2.0126800537109375
Validation loss: 2.277081270371714

Epoch: 6| Step: 4
Training loss: 2.3076391220092773
Validation loss: 2.2762929188307894

Epoch: 6| Step: 5
Training loss: 2.6566476821899414
Validation loss: 2.32130749763981

Epoch: 6| Step: 6
Training loss: 2.5640244483947754
Validation loss: 2.4419052831588255

Epoch: 6| Step: 7
Training loss: 2.779879093170166
Validation loss: 2.4878069200823383

Epoch: 6| Step: 8
Training loss: 2.8338799476623535
Validation loss: 2.4840442980489423

Epoch: 6| Step: 9
Training loss: 1.8639007806777954
Validation loss: 2.4413119080246135

Epoch: 6| Step: 10
Training loss: 3.3160271644592285
Validation loss: 2.4206923489929526

Epoch: 6| Step: 11
Training loss: 2.844167709350586
Validation loss: 2.3890468638430358

Epoch: 6| Step: 12
Training loss: 2.578986167907715
Validation loss: 2.351737312091294

Epoch: 6| Step: 13
Training loss: 4.031610012054443
Validation loss: 2.3012107444065872

Epoch: 59| Step: 0
Training loss: 2.492969036102295
Validation loss: 2.289290681962044

Epoch: 6| Step: 1
Training loss: 2.6550445556640625
Validation loss: 2.2851077664283013

Epoch: 6| Step: 2
Training loss: 3.1342453956604004
Validation loss: 2.2963562473174064

Epoch: 6| Step: 3
Training loss: 2.745715856552124
Validation loss: 2.30820607882674

Epoch: 6| Step: 4
Training loss: 2.165456771850586
Validation loss: 2.299574641771214

Epoch: 6| Step: 5
Training loss: 2.6209194660186768
Validation loss: 2.2978519278187908

Epoch: 6| Step: 6
Training loss: 2.243699550628662
Validation loss: 2.286504260955318

Epoch: 6| Step: 7
Training loss: 3.1814494132995605
Validation loss: 2.2776620593122257

Epoch: 6| Step: 8
Training loss: 3.0336740016937256
Validation loss: 2.2675112755067888

Epoch: 6| Step: 9
Training loss: 2.8554739952087402
Validation loss: 2.2565448412331204

Epoch: 6| Step: 10
Training loss: 2.632028579711914
Validation loss: 2.256711600929178

Epoch: 6| Step: 11
Training loss: 2.0989842414855957
Validation loss: 2.2569277901803293

Epoch: 6| Step: 12
Training loss: 1.8510314226150513
Validation loss: 2.264552693213186

Epoch: 6| Step: 13
Training loss: 2.123857259750366
Validation loss: 2.2659618700704267

Epoch: 60| Step: 0
Training loss: 2.466968297958374
Validation loss: 2.2821345431830293

Epoch: 6| Step: 1
Training loss: 3.015091896057129
Validation loss: 2.2991382280985513

Epoch: 6| Step: 2
Training loss: 2.4180212020874023
Validation loss: 2.329807008466413

Epoch: 6| Step: 3
Training loss: 2.320833444595337
Validation loss: 2.3561917094774145

Epoch: 6| Step: 4
Training loss: 2.8885550498962402
Validation loss: 2.360527046265141

Epoch: 6| Step: 5
Training loss: 2.046933889389038
Validation loss: 2.3354825614601054

Epoch: 6| Step: 6
Training loss: 2.813495635986328
Validation loss: 2.3176549019352084

Epoch: 6| Step: 7
Training loss: 2.0285086631774902
Validation loss: 2.3106699028322772

Epoch: 6| Step: 8
Training loss: 2.9897797107696533
Validation loss: 2.3123828570048013

Epoch: 6| Step: 9
Training loss: 2.5501821041107178
Validation loss: 2.3036044002861105

Epoch: 6| Step: 10
Training loss: 2.6385912895202637
Validation loss: 2.287036153577989

Epoch: 6| Step: 11
Training loss: 2.5924859046936035
Validation loss: 2.2682909465605214

Epoch: 6| Step: 12
Training loss: 2.736555576324463
Validation loss: 2.2608013640167894

Epoch: 6| Step: 13
Training loss: 2.295659065246582
Validation loss: 2.2603326689812446

Epoch: 61| Step: 0
Training loss: 3.1931777000427246
Validation loss: 2.264885861386535

Epoch: 6| Step: 1
Training loss: 2.995715618133545
Validation loss: 2.248023192087809

Epoch: 6| Step: 2
Training loss: 2.5879247188568115
Validation loss: 2.2486889798154115

Epoch: 6| Step: 3
Training loss: 3.2137362957000732
Validation loss: 2.2520318851676038

Epoch: 6| Step: 4
Training loss: 2.150177001953125
Validation loss: 2.2499934293890513

Epoch: 6| Step: 5
Training loss: 2.2019097805023193
Validation loss: 2.2462393699153775

Epoch: 6| Step: 6
Training loss: 3.1990208625793457
Validation loss: 2.2530823292270785

Epoch: 6| Step: 7
Training loss: 2.5270652770996094
Validation loss: 2.251689023869012

Epoch: 6| Step: 8
Training loss: 2.2340657711029053
Validation loss: 2.2521599928538003

Epoch: 6| Step: 9
Training loss: 2.9824583530426025
Validation loss: 2.2579570021680606

Epoch: 6| Step: 10
Training loss: 2.2410941123962402
Validation loss: 2.258917857241887

Epoch: 6| Step: 11
Training loss: 1.7661021947860718
Validation loss: 2.2588956176593737

Epoch: 6| Step: 12
Training loss: 2.080138683319092
Validation loss: 2.253283387871199

Epoch: 6| Step: 13
Training loss: 2.51316499710083
Validation loss: 2.274953870363133

Epoch: 62| Step: 0
Training loss: 2.109401226043701
Validation loss: 2.254676926520563

Epoch: 6| Step: 1
Training loss: 2.724466323852539
Validation loss: 2.2514544097326135

Epoch: 6| Step: 2
Training loss: 1.8971248865127563
Validation loss: 2.2479447498116443

Epoch: 6| Step: 3
Training loss: 2.604545831680298
Validation loss: 2.253900780472704

Epoch: 6| Step: 4
Training loss: 1.929593801498413
Validation loss: 2.2644674957439466

Epoch: 6| Step: 5
Training loss: 2.234387159347534
Validation loss: 2.256733286765314

Epoch: 6| Step: 6
Training loss: 2.731440305709839
Validation loss: 2.247997678736205

Epoch: 6| Step: 7
Training loss: 3.0447044372558594
Validation loss: 2.240925363315049

Epoch: 6| Step: 8
Training loss: 3.0202836990356445
Validation loss: 2.2400248589054232

Epoch: 6| Step: 9
Training loss: 2.3527328968048096
Validation loss: 2.248196159639666

Epoch: 6| Step: 10
Training loss: 3.393512725830078
Validation loss: 2.2511519898650465

Epoch: 6| Step: 11
Training loss: 2.9246506690979004
Validation loss: 2.2594225765556417

Epoch: 6| Step: 12
Training loss: 2.5873665809631348
Validation loss: 2.2694336932192565

Epoch: 6| Step: 13
Training loss: 1.9453727006912231
Validation loss: 2.266034549282443

Epoch: 63| Step: 0
Training loss: 2.7943778038024902
Validation loss: 2.265019278372488

Epoch: 6| Step: 1
Training loss: 1.863180160522461
Validation loss: 2.2588914594342633

Epoch: 6| Step: 2
Training loss: 3.247816324234009
Validation loss: 2.2465702590122016

Epoch: 6| Step: 3
Training loss: 1.9372334480285645
Validation loss: 2.2478676560104534

Epoch: 6| Step: 4
Training loss: 2.2087669372558594
Validation loss: 2.234340613888156

Epoch: 6| Step: 5
Training loss: 2.6031336784362793
Validation loss: 2.238649627213837

Epoch: 6| Step: 6
Training loss: 2.520780563354492
Validation loss: 2.249414354242304

Epoch: 6| Step: 7
Training loss: 2.557568073272705
Validation loss: 2.250966456628615

Epoch: 6| Step: 8
Training loss: 2.8957085609436035
Validation loss: 2.25878809344384

Epoch: 6| Step: 9
Training loss: 2.48214054107666
Validation loss: 2.265047255382743

Epoch: 6| Step: 10
Training loss: 2.5641443729400635
Validation loss: 2.2767898882589033

Epoch: 6| Step: 11
Training loss: 2.8903932571411133
Validation loss: 2.266071419562063

Epoch: 6| Step: 12
Training loss: 2.485800266265869
Validation loss: 2.2535026560547533

Epoch: 6| Step: 13
Training loss: 2.4567134380340576
Validation loss: 2.256624401256602

Epoch: 64| Step: 0
Training loss: 1.9309778213500977
Validation loss: 2.255356986035583

Epoch: 6| Step: 1
Training loss: 3.1206135749816895
Validation loss: 2.2536624170118764

Epoch: 6| Step: 2
Training loss: 2.376455068588257
Validation loss: 2.259573631389167

Epoch: 6| Step: 3
Training loss: 2.5557591915130615
Validation loss: 2.2538137948641213

Epoch: 6| Step: 4
Training loss: 2.092288017272949
Validation loss: 2.250511000233312

Epoch: 6| Step: 5
Training loss: 2.607151985168457
Validation loss: 2.2392015969881447

Epoch: 6| Step: 6
Training loss: 2.3891870975494385
Validation loss: 2.273339840673631

Epoch: 6| Step: 7
Training loss: 1.792628288269043
Validation loss: 2.301905301309401

Epoch: 6| Step: 8
Training loss: 2.248593807220459
Validation loss: 2.329055880987516

Epoch: 6| Step: 9
Training loss: 3.431114673614502
Validation loss: 2.3471025625864663

Epoch: 6| Step: 10
Training loss: 3.050147533416748
Validation loss: 2.3148570547821703

Epoch: 6| Step: 11
Training loss: 2.512568950653076
Validation loss: 2.2885456828660864

Epoch: 6| Step: 12
Training loss: 3.0021426677703857
Validation loss: 2.2619616421320106

Epoch: 6| Step: 13
Training loss: 2.838087797164917
Validation loss: 2.2531096678908153

Epoch: 65| Step: 0
Training loss: 2.395617723464966
Validation loss: 2.23481055741669

Epoch: 6| Step: 1
Training loss: 2.9528515338897705
Validation loss: 2.2203967801986204

Epoch: 6| Step: 2
Training loss: 2.5373101234436035
Validation loss: 2.212814079817905

Epoch: 6| Step: 3
Training loss: 1.9666783809661865
Validation loss: 2.2110698300023235

Epoch: 6| Step: 4
Training loss: 2.652477264404297
Validation loss: 2.2090092743596723

Epoch: 6| Step: 5
Training loss: 2.3706040382385254
Validation loss: 2.216032088443797

Epoch: 6| Step: 6
Training loss: 2.815484046936035
Validation loss: 2.215461295138123

Epoch: 6| Step: 7
Training loss: 2.5940005779266357
Validation loss: 2.224624195406514

Epoch: 6| Step: 8
Training loss: 3.4003217220306396
Validation loss: 2.2267337101762013

Epoch: 6| Step: 9
Training loss: 2.289365768432617
Validation loss: 2.226770674028704

Epoch: 6| Step: 10
Training loss: 2.0402350425720215
Validation loss: 2.225318475436139

Epoch: 6| Step: 11
Training loss: 2.88028883934021
Validation loss: 2.2256126249990156

Epoch: 6| Step: 12
Training loss: 2.303913116455078
Validation loss: 2.225299827514156

Epoch: 6| Step: 13
Training loss: 1.9100481271743774
Validation loss: 2.2173521672525713

Epoch: 66| Step: 0
Training loss: 1.9336532354354858
Validation loss: 2.2110698479478077

Epoch: 6| Step: 1
Training loss: 2.653320789337158
Validation loss: 2.201219258769866

Epoch: 6| Step: 2
Training loss: 2.9246597290039062
Validation loss: 2.1955666183143534

Epoch: 6| Step: 3
Training loss: 3.134045124053955
Validation loss: 2.1988374776737665

Epoch: 6| Step: 4
Training loss: 2.5905351638793945
Validation loss: 2.198425268614164

Epoch: 6| Step: 5
Training loss: 2.5682783126831055
Validation loss: 2.198174117713846

Epoch: 6| Step: 6
Training loss: 1.7506282329559326
Validation loss: 2.196935857495954

Epoch: 6| Step: 7
Training loss: 2.330620288848877
Validation loss: 2.200438291795792

Epoch: 6| Step: 8
Training loss: 2.409432888031006
Validation loss: 2.2030804669985207

Epoch: 6| Step: 9
Training loss: 2.7052154541015625
Validation loss: 2.205277596750567

Epoch: 6| Step: 10
Training loss: 2.636629819869995
Validation loss: 2.2087200328867924

Epoch: 6| Step: 11
Training loss: 3.10174560546875
Validation loss: 2.237713021616782

Epoch: 6| Step: 12
Training loss: 2.1384518146514893
Validation loss: 2.2858720133381505

Epoch: 6| Step: 13
Training loss: 2.4039783477783203
Validation loss: 2.3542744677553893

Epoch: 67| Step: 0
Training loss: 2.4720897674560547
Validation loss: 2.3965436617533364

Epoch: 6| Step: 1
Training loss: 3.095916271209717
Validation loss: 2.4538583601674726

Epoch: 6| Step: 2
Training loss: 2.8468940258026123
Validation loss: 2.4590604125812487

Epoch: 6| Step: 3
Training loss: 2.4855175018310547
Validation loss: 2.433578292528788

Epoch: 6| Step: 4
Training loss: 2.5885396003723145
Validation loss: 2.391434274693971

Epoch: 6| Step: 5
Training loss: 2.7391064167022705
Validation loss: 2.360210872465564

Epoch: 6| Step: 6
Training loss: 1.9503909349441528
Validation loss: 2.3271941215761247

Epoch: 6| Step: 7
Training loss: 2.954967975616455
Validation loss: 2.2975885175889537

Epoch: 6| Step: 8
Training loss: 2.116957187652588
Validation loss: 2.267106533050537

Epoch: 6| Step: 9
Training loss: 3.0505409240722656
Validation loss: 2.251115201621927

Epoch: 6| Step: 10
Training loss: 2.2777795791625977
Validation loss: 2.2307774584780455

Epoch: 6| Step: 11
Training loss: 2.209470748901367
Validation loss: 2.219480958036197

Epoch: 6| Step: 12
Training loss: 2.7675905227661133
Validation loss: 2.214925450663413

Epoch: 6| Step: 13
Training loss: 2.1252450942993164
Validation loss: 2.2084362301775204

Epoch: 68| Step: 0
Training loss: 2.5088753700256348
Validation loss: 2.2013020220623223

Epoch: 6| Step: 1
Training loss: 3.0012948513031006
Validation loss: 2.209247350692749

Epoch: 6| Step: 2
Training loss: 3.0247294902801514
Validation loss: 2.2034058135042907

Epoch: 6| Step: 3
Training loss: 2.488114356994629
Validation loss: 2.2003901876429075

Epoch: 6| Step: 4
Training loss: 2.630661964416504
Validation loss: 2.2010824013781805

Epoch: 6| Step: 5
Training loss: 1.6272331476211548
Validation loss: 2.1956236721366964

Epoch: 6| Step: 6
Training loss: 2.9847326278686523
Validation loss: 2.206865364505399

Epoch: 6| Step: 7
Training loss: 2.472135066986084
Validation loss: 2.2297547248102005

Epoch: 6| Step: 8
Training loss: 2.315542221069336
Validation loss: 2.240993833029142

Epoch: 6| Step: 9
Training loss: 3.2057812213897705
Validation loss: 2.2082452389501754

Epoch: 6| Step: 10
Training loss: 3.4659383296966553
Validation loss: 2.191701618573999

Epoch: 6| Step: 11
Training loss: 1.956344485282898
Validation loss: 2.179716281993415

Epoch: 6| Step: 12
Training loss: 1.5485453605651855
Validation loss: 2.1730971374819354

Epoch: 6| Step: 13
Training loss: 1.5458494424819946
Validation loss: 2.1794964087906705

Epoch: 69| Step: 0
Training loss: 3.1700997352600098
Validation loss: 2.177483461236441

Epoch: 6| Step: 1
Training loss: 3.1125664710998535
Validation loss: 2.1737943874892367

Epoch: 6| Step: 2
Training loss: 1.5697892904281616
Validation loss: 2.176817701708886

Epoch: 6| Step: 3
Training loss: 2.368773937225342
Validation loss: 2.1774653773153982

Epoch: 6| Step: 4
Training loss: 2.809901714324951
Validation loss: 2.187147025139101

Epoch: 6| Step: 5
Training loss: 2.1092138290405273
Validation loss: 2.190759930559384

Epoch: 6| Step: 6
Training loss: 2.7338595390319824
Validation loss: 2.198842622900522

Epoch: 6| Step: 7
Training loss: 2.51908016204834
Validation loss: 2.200791080792745

Epoch: 6| Step: 8
Training loss: 2.890575408935547
Validation loss: 2.20369642267945

Epoch: 6| Step: 9
Training loss: 2.582618236541748
Validation loss: 2.189046202167388

Epoch: 6| Step: 10
Training loss: 2.300781488418579
Validation loss: 2.195329535392023

Epoch: 6| Step: 11
Training loss: 2.4999067783355713
Validation loss: 2.196633820892662

Epoch: 6| Step: 12
Training loss: 2.031694173812866
Validation loss: 2.17887124963986

Epoch: 6| Step: 13
Training loss: 2.2843332290649414
Validation loss: 2.1747623156475764

Epoch: 70| Step: 0
Training loss: 2.363426446914673
Validation loss: 2.175551402953363

Epoch: 6| Step: 1
Training loss: 2.4568769931793213
Validation loss: 2.162771330084852

Epoch: 6| Step: 2
Training loss: 2.925337791442871
Validation loss: 2.1594254304003972

Epoch: 6| Step: 3
Training loss: 2.726091146469116
Validation loss: 2.16715479922551

Epoch: 6| Step: 4
Training loss: 2.394070625305176
Validation loss: 2.1704737345377603

Epoch: 6| Step: 5
Training loss: 3.2005562782287598
Validation loss: 2.171343449623354

Epoch: 6| Step: 6
Training loss: 2.384432077407837
Validation loss: 2.1650471764226116

Epoch: 6| Step: 7
Training loss: 2.248748540878296
Validation loss: 2.186720476355604

Epoch: 6| Step: 8
Training loss: 2.3315012454986572
Validation loss: 2.228647485856087

Epoch: 6| Step: 9
Training loss: 2.2923784255981445
Validation loss: 2.235490711786414

Epoch: 6| Step: 10
Training loss: 2.265972852706909
Validation loss: 2.2685603582730858

Epoch: 6| Step: 11
Training loss: 2.608844757080078
Validation loss: 2.308892439770442

Epoch: 6| Step: 12
Training loss: 2.8610992431640625
Validation loss: 2.3242007840064263

Epoch: 6| Step: 13
Training loss: 1.8231648206710815
Validation loss: 2.2768756164017545

Epoch: 71| Step: 0
Training loss: 3.5966084003448486
Validation loss: 2.2443067130222114

Epoch: 6| Step: 1
Training loss: 2.1311516761779785
Validation loss: 2.222213519516812

Epoch: 6| Step: 2
Training loss: 2.2813773155212402
Validation loss: 2.1840732789808706

Epoch: 6| Step: 3
Training loss: 2.0877115726470947
Validation loss: 2.1641947095112135

Epoch: 6| Step: 4
Training loss: 2.4038801193237305
Validation loss: 2.1628247307192896

Epoch: 6| Step: 5
Training loss: 2.4761414527893066
Validation loss: 2.16517363825152

Epoch: 6| Step: 6
Training loss: 3.2298269271850586
Validation loss: 2.162113940843972

Epoch: 6| Step: 7
Training loss: 2.8365001678466797
Validation loss: 2.1630688149441957

Epoch: 6| Step: 8
Training loss: 2.6935908794403076
Validation loss: 2.1694293445156467

Epoch: 6| Step: 9
Training loss: 2.5736095905303955
Validation loss: 2.1797841851429274

Epoch: 6| Step: 10
Training loss: 1.6708078384399414
Validation loss: 2.198937850613748

Epoch: 6| Step: 11
Training loss: 2.5064074993133545
Validation loss: 2.1685609381685973

Epoch: 6| Step: 12
Training loss: 1.970832347869873
Validation loss: 2.1539306332988124

Epoch: 6| Step: 13
Training loss: 2.741159439086914
Validation loss: 2.1528489435872724

Epoch: 72| Step: 0
Training loss: 2.591970443725586
Validation loss: 2.1636209962188557

Epoch: 6| Step: 1
Training loss: 2.8937506675720215
Validation loss: 2.172602084375197

Epoch: 6| Step: 2
Training loss: 1.3193923234939575
Validation loss: 2.186968735469285

Epoch: 6| Step: 3
Training loss: 2.642608165740967
Validation loss: 2.17971045483825

Epoch: 6| Step: 4
Training loss: 2.442636489868164
Validation loss: 2.2020114801263295

Epoch: 6| Step: 5
Training loss: 2.013652801513672
Validation loss: 2.250302073776081

Epoch: 6| Step: 6
Training loss: 2.593993902206421
Validation loss: 2.3360455369436615

Epoch: 6| Step: 7
Training loss: 2.8592982292175293
Validation loss: 2.337244972105949

Epoch: 6| Step: 8
Training loss: 2.7727715969085693
Validation loss: 2.3021791135111163

Epoch: 6| Step: 9
Training loss: 2.930414915084839
Validation loss: 2.2486852497182865

Epoch: 6| Step: 10
Training loss: 2.6377692222595215
Validation loss: 2.2225866445931057

Epoch: 6| Step: 11
Training loss: 2.4576447010040283
Validation loss: 2.193510848988769

Epoch: 6| Step: 12
Training loss: 2.669778347015381
Validation loss: 2.18291219844613

Epoch: 6| Step: 13
Training loss: 1.8490641117095947
Validation loss: 2.1789257577670518

Epoch: 73| Step: 0
Training loss: 1.95093834400177
Validation loss: 2.202120416907854

Epoch: 6| Step: 1
Training loss: 3.15985107421875
Validation loss: 2.2448294085841023

Epoch: 6| Step: 2
Training loss: 2.4749584197998047
Validation loss: 2.266564981911772

Epoch: 6| Step: 3
Training loss: 2.528364896774292
Validation loss: 2.273835059135191

Epoch: 6| Step: 4
Training loss: 2.41180682182312
Validation loss: 2.236418524096089

Epoch: 6| Step: 5
Training loss: 2.8996434211730957
Validation loss: 2.207467843127507

Epoch: 6| Step: 6
Training loss: 2.31723690032959
Validation loss: 2.1904561865714287

Epoch: 6| Step: 7
Training loss: 2.8458385467529297
Validation loss: 2.2013417508012507

Epoch: 6| Step: 8
Training loss: 2.408146381378174
Validation loss: 2.1993983496901808

Epoch: 6| Step: 9
Training loss: 2.214465379714966
Validation loss: 2.209432286600913

Epoch: 6| Step: 10
Training loss: 3.2957935333251953
Validation loss: 2.2098534184117473

Epoch: 6| Step: 11
Training loss: 2.5062785148620605
Validation loss: 2.193075608181697

Epoch: 6| Step: 12
Training loss: 2.751447916030884
Validation loss: 2.1890808895070064

Epoch: 6| Step: 13
Training loss: 1.2617268562316895
Validation loss: 2.1767419768917944

Epoch: 74| Step: 0
Training loss: 2.6437394618988037
Validation loss: 2.1850766725437616

Epoch: 6| Step: 1
Training loss: 2.656130313873291
Validation loss: 2.186655241955993

Epoch: 6| Step: 2
Training loss: 2.6862130165100098
Validation loss: 2.178619461674844

Epoch: 6| Step: 3
Training loss: 1.8373252153396606
Validation loss: 2.187434696382092

Epoch: 6| Step: 4
Training loss: 2.538848400115967
Validation loss: 2.1889789617189797

Epoch: 6| Step: 5
Training loss: 1.8794167041778564
Validation loss: 2.203149111040177

Epoch: 6| Step: 6
Training loss: 2.939973831176758
Validation loss: 2.207801659901937

Epoch: 6| Step: 7
Training loss: 2.456085443496704
Validation loss: 2.233126171173588

Epoch: 6| Step: 8
Training loss: 2.414869546890259
Validation loss: 2.202730042960054

Epoch: 6| Step: 9
Training loss: 2.226984739303589
Validation loss: 2.1860246171233473

Epoch: 6| Step: 10
Training loss: 2.4040093421936035
Validation loss: 2.184197933443131

Epoch: 6| Step: 11
Training loss: 2.391523599624634
Validation loss: 2.1800016280143493

Epoch: 6| Step: 12
Training loss: 2.6441304683685303
Validation loss: 2.185226514775266

Epoch: 6| Step: 13
Training loss: 3.5112226009368896
Validation loss: 2.1861453594699984

Epoch: 75| Step: 0
Training loss: 2.5413336753845215
Validation loss: 2.1774208391866376

Epoch: 6| Step: 1
Training loss: 2.4189958572387695
Validation loss: 2.1632242459122852

Epoch: 6| Step: 2
Training loss: 2.5879900455474854
Validation loss: 2.155170561164938

Epoch: 6| Step: 3
Training loss: 2.350691318511963
Validation loss: 2.1636439138843166

Epoch: 6| Step: 4
Training loss: 2.6397342681884766
Validation loss: 2.164831974173105

Epoch: 6| Step: 5
Training loss: 2.2253990173339844
Validation loss: 2.1634187929091917

Epoch: 6| Step: 6
Training loss: 2.871166229248047
Validation loss: 2.1739951936147546

Epoch: 6| Step: 7
Training loss: 2.0369343757629395
Validation loss: 2.163415919068039

Epoch: 6| Step: 8
Training loss: 2.306070327758789
Validation loss: 2.173787014458769

Epoch: 6| Step: 9
Training loss: 2.682072162628174
Validation loss: 2.1748935689208326

Epoch: 6| Step: 10
Training loss: 2.621331214904785
Validation loss: 2.20931738679127

Epoch: 6| Step: 11
Training loss: 3.0054128170013428
Validation loss: 2.245869690372098

Epoch: 6| Step: 12
Training loss: 2.267989158630371
Validation loss: 2.25523191882718

Epoch: 6| Step: 13
Training loss: 2.7529544830322266
Validation loss: 2.2381510119284354

Epoch: 76| Step: 0
Training loss: 2.436823844909668
Validation loss: 2.2098276756143056

Epoch: 6| Step: 1
Training loss: 2.6215548515319824
Validation loss: 2.1854398532580306

Epoch: 6| Step: 2
Training loss: 3.003455400466919
Validation loss: 2.1732895117934032

Epoch: 6| Step: 3
Training loss: 2.449019432067871
Validation loss: 2.159555688981087

Epoch: 6| Step: 4
Training loss: 2.3165817260742188
Validation loss: 2.1494604695227837

Epoch: 6| Step: 5
Training loss: 1.6918801069259644
Validation loss: 2.1467405352541196

Epoch: 6| Step: 6
Training loss: 2.446455478668213
Validation loss: 2.1389048304609073

Epoch: 6| Step: 7
Training loss: 2.5287795066833496
Validation loss: 2.1428106215692337

Epoch: 6| Step: 8
Training loss: 2.644655466079712
Validation loss: 2.1396337157936505

Epoch: 6| Step: 9
Training loss: 2.7069644927978516
Validation loss: 2.1351683998620636

Epoch: 6| Step: 10
Training loss: 3.473080635070801
Validation loss: 2.1424764356305523

Epoch: 6| Step: 11
Training loss: 2.089258909225464
Validation loss: 2.14577119581161

Epoch: 6| Step: 12
Training loss: 1.8452930450439453
Validation loss: 2.1615853822359474

Epoch: 6| Step: 13
Training loss: 2.296855926513672
Validation loss: 2.15903724649901

Epoch: 77| Step: 0
Training loss: 2.205822467803955
Validation loss: 2.155077188245712

Epoch: 6| Step: 1
Training loss: 1.6868212223052979
Validation loss: 2.149277353799471

Epoch: 6| Step: 2
Training loss: 2.6620349884033203
Validation loss: 2.1479470217099754

Epoch: 6| Step: 3
Training loss: 2.3433570861816406
Validation loss: 2.1338247381230837

Epoch: 6| Step: 4
Training loss: 2.330092430114746
Validation loss: 2.149499941897649

Epoch: 6| Step: 5
Training loss: 3.115144729614258
Validation loss: 2.1469251648072274

Epoch: 6| Step: 6
Training loss: 2.676121234893799
Validation loss: 2.157170041914909

Epoch: 6| Step: 7
Training loss: 2.769042491912842
Validation loss: 2.1679489458760908

Epoch: 6| Step: 8
Training loss: 3.1112866401672363
Validation loss: 2.1772415509787937

Epoch: 6| Step: 9
Training loss: 2.3517611026763916
Validation loss: 2.181002083645072

Epoch: 6| Step: 10
Training loss: 2.344723701477051
Validation loss: 2.1857938010205507

Epoch: 6| Step: 11
Training loss: 2.3865718841552734
Validation loss: 2.1859141601029264

Epoch: 6| Step: 12
Training loss: 2.5961756706237793
Validation loss: 2.1896212741892827

Epoch: 6| Step: 13
Training loss: 2.5356903076171875
Validation loss: 2.1949744032275293

Epoch: 78| Step: 0
Training loss: 2.268324613571167
Validation loss: 2.2014758356155886

Epoch: 6| Step: 1
Training loss: 1.9373992681503296
Validation loss: 2.200883629501507

Epoch: 6| Step: 2
Training loss: 2.750652313232422
Validation loss: 2.2045993497294765

Epoch: 6| Step: 3
Training loss: 2.37191104888916
Validation loss: 2.221600817095849

Epoch: 6| Step: 4
Training loss: 2.246234178543091
Validation loss: 2.2238790245466333

Epoch: 6| Step: 5
Training loss: 2.1181044578552246
Validation loss: 2.2321561331390054

Epoch: 6| Step: 6
Training loss: 3.3709444999694824
Validation loss: 2.2261145448171966

Epoch: 6| Step: 7
Training loss: 2.1182403564453125
Validation loss: 2.239833313931701

Epoch: 6| Step: 8
Training loss: 2.354386806488037
Validation loss: 2.2481358769119426

Epoch: 6| Step: 9
Training loss: 2.4695849418640137
Validation loss: 2.2487290085002942

Epoch: 6| Step: 10
Training loss: 3.1399831771850586
Validation loss: 2.246181303454984

Epoch: 6| Step: 11
Training loss: 2.712122917175293
Validation loss: 2.2457881563453266

Epoch: 6| Step: 12
Training loss: 2.5433452129364014
Validation loss: 2.22890579828652

Epoch: 6| Step: 13
Training loss: 2.5872318744659424
Validation loss: 2.211117221463111

Epoch: 79| Step: 0
Training loss: 1.8223400115966797
Validation loss: 2.2022133104262815

Epoch: 6| Step: 1
Training loss: 2.3036022186279297
Validation loss: 2.2044803301493325

Epoch: 6| Step: 2
Training loss: 2.100628614425659
Validation loss: 2.200096471335298

Epoch: 6| Step: 3
Training loss: 2.776158332824707
Validation loss: 2.1981958099590835

Epoch: 6| Step: 4
Training loss: 1.9267657995224
Validation loss: 2.196035313349898

Epoch: 6| Step: 5
Training loss: 2.5187814235687256
Validation loss: 2.203252120684552

Epoch: 6| Step: 6
Training loss: 2.39334774017334
Validation loss: 2.2154557166561

Epoch: 6| Step: 7
Training loss: 2.5711236000061035
Validation loss: 2.221074778546569

Epoch: 6| Step: 8
Training loss: 2.5705385208129883
Validation loss: 2.232238508039905

Epoch: 6| Step: 9
Training loss: 2.6456704139709473
Validation loss: 2.2142727246848484

Epoch: 6| Step: 10
Training loss: 3.021505117416382
Validation loss: 2.210614317206926

Epoch: 6| Step: 11
Training loss: 2.793039083480835
Validation loss: 2.2079919794554352

Epoch: 6| Step: 12
Training loss: 2.7085156440734863
Validation loss: 2.198172528256652

Epoch: 6| Step: 13
Training loss: 2.6536457538604736
Validation loss: 2.1926228897545927

Epoch: 80| Step: 0
Training loss: 3.220646381378174
Validation loss: 2.205557084852649

Epoch: 6| Step: 1
Training loss: 1.9698355197906494
Validation loss: 2.2024643856992006

Epoch: 6| Step: 2
Training loss: 2.104106903076172
Validation loss: 2.210801129700035

Epoch: 6| Step: 3
Training loss: 2.2883245944976807
Validation loss: 2.2143160937934794

Epoch: 6| Step: 4
Training loss: 2.2677745819091797
Validation loss: 2.2262944303533083

Epoch: 6| Step: 5
Training loss: 2.366450786590576
Validation loss: 2.211454902925799

Epoch: 6| Step: 6
Training loss: 2.836228847503662
Validation loss: 2.212246451326596

Epoch: 6| Step: 7
Training loss: 2.344210624694824
Validation loss: 2.210404049965643

Epoch: 6| Step: 8
Training loss: 2.8298025131225586
Validation loss: 2.206750269859068

Epoch: 6| Step: 9
Training loss: 2.8084115982055664
Validation loss: 2.183373915251865

Epoch: 6| Step: 10
Training loss: 2.403529405593872
Validation loss: 2.172175976537889

Epoch: 6| Step: 11
Training loss: 2.940817356109619
Validation loss: 2.1699390693377425

Epoch: 6| Step: 12
Training loss: 1.9599096775054932
Validation loss: 2.168033730599188

Epoch: 6| Step: 13
Training loss: 2.061984062194824
Validation loss: 2.1687927194820937

Epoch: 81| Step: 0
Training loss: 1.729183554649353
Validation loss: 2.1708334697190153

Epoch: 6| Step: 1
Training loss: 1.429826021194458
Validation loss: 2.1601319620686192

Epoch: 6| Step: 2
Training loss: 2.520965337753296
Validation loss: 2.1644626509758735

Epoch: 6| Step: 3
Training loss: 2.4562888145446777
Validation loss: 2.1659188270568848

Epoch: 6| Step: 4
Training loss: 2.4528231620788574
Validation loss: 2.161150663129745

Epoch: 6| Step: 5
Training loss: 3.0652530193328857
Validation loss: 2.1859028980296147

Epoch: 6| Step: 6
Training loss: 2.6472182273864746
Validation loss: 2.1942688739427956

Epoch: 6| Step: 7
Training loss: 3.286799192428589
Validation loss: 2.2141944567362466

Epoch: 6| Step: 8
Training loss: 2.5892090797424316
Validation loss: 2.280569407247728

Epoch: 6| Step: 9
Training loss: 2.665424346923828
Validation loss: 2.2563921123422603

Epoch: 6| Step: 10
Training loss: 2.912738800048828
Validation loss: 2.228912986734862

Epoch: 6| Step: 11
Training loss: 2.607133388519287
Validation loss: 2.182485206152803

Epoch: 6| Step: 12
Training loss: 2.0161428451538086
Validation loss: 2.178636393239421

Epoch: 6| Step: 13
Training loss: 2.484579563140869
Validation loss: 2.1511562819121988

Epoch: 82| Step: 0
Training loss: 1.1526411771774292
Validation loss: 2.13327798792111

Epoch: 6| Step: 1
Training loss: 2.5285017490386963
Validation loss: 2.1174097778976604

Epoch: 6| Step: 2
Training loss: 2.3007822036743164
Validation loss: 2.1069498446679886

Epoch: 6| Step: 3
Training loss: 2.113767147064209
Validation loss: 2.1065769041738203

Epoch: 6| Step: 4
Training loss: 3.1738128662109375
Validation loss: 2.1059354223230833

Epoch: 6| Step: 5
Training loss: 3.1323721408843994
Validation loss: 2.114202259689249

Epoch: 6| Step: 6
Training loss: 2.3894548416137695
Validation loss: 2.1216940879821777

Epoch: 6| Step: 7
Training loss: 2.633492946624756
Validation loss: 2.1316974701419955

Epoch: 6| Step: 8
Training loss: 2.2841577529907227
Validation loss: 2.1522601855698453

Epoch: 6| Step: 9
Training loss: 1.9631624221801758
Validation loss: 2.1466737536973852

Epoch: 6| Step: 10
Training loss: 2.569474458694458
Validation loss: 2.151535423853064

Epoch: 6| Step: 11
Training loss: 3.0508816242218018
Validation loss: 2.153710462713754

Epoch: 6| Step: 12
Training loss: 2.2008724212646484
Validation loss: 2.1421086736904678

Epoch: 6| Step: 13
Training loss: 3.133244037628174
Validation loss: 2.1240028976112284

Epoch: 83| Step: 0
Training loss: 2.5418405532836914
Validation loss: 2.096752441057595

Epoch: 6| Step: 1
Training loss: 2.040825843811035
Validation loss: 2.0898868383899813

Epoch: 6| Step: 2
Training loss: 2.1508255004882812
Validation loss: 2.092025492780952

Epoch: 6| Step: 3
Training loss: 2.7454447746276855
Validation loss: 2.089619871108763

Epoch: 6| Step: 4
Training loss: 2.2813501358032227
Validation loss: 2.0855843251751316

Epoch: 6| Step: 5
Training loss: 3.0233068466186523
Validation loss: 2.0973359833481493

Epoch: 6| Step: 6
Training loss: 2.568465232849121
Validation loss: 2.111980445923344

Epoch: 6| Step: 7
Training loss: 2.012371063232422
Validation loss: 2.1333870349391812

Epoch: 6| Step: 8
Training loss: 3.1598222255706787
Validation loss: 2.1822027724276305

Epoch: 6| Step: 9
Training loss: 2.512167453765869
Validation loss: 2.188128104773901

Epoch: 6| Step: 10
Training loss: 1.9533801078796387
Validation loss: 2.186283270517985

Epoch: 6| Step: 11
Training loss: 2.12178635597229
Validation loss: 2.1709741225806614

Epoch: 6| Step: 12
Training loss: 2.6060733795166016
Validation loss: 2.1413430103691677

Epoch: 6| Step: 13
Training loss: 2.4877803325653076
Validation loss: 2.1277712955269763

Epoch: 84| Step: 0
Training loss: 3.2091124057769775
Validation loss: 2.124717486801968

Epoch: 6| Step: 1
Training loss: 2.6783571243286133
Validation loss: 2.113218771514072

Epoch: 6| Step: 2
Training loss: 2.0264742374420166
Validation loss: 2.106787153469619

Epoch: 6| Step: 3
Training loss: 1.971256971359253
Validation loss: 2.1279512836087133

Epoch: 6| Step: 4
Training loss: 2.1941938400268555
Validation loss: 2.14040175560982

Epoch: 6| Step: 5
Training loss: 2.24355411529541
Validation loss: 2.1605878337737052

Epoch: 6| Step: 6
Training loss: 2.322758197784424
Validation loss: 2.1663948233409593

Epoch: 6| Step: 7
Training loss: 2.1829121112823486
Validation loss: 2.174602608526907

Epoch: 6| Step: 8
Training loss: 2.3903846740722656
Validation loss: 2.142491317564441

Epoch: 6| Step: 9
Training loss: 2.4397664070129395
Validation loss: 2.129569656105452

Epoch: 6| Step: 10
Training loss: 2.3010458946228027
Validation loss: 2.1117604035203175

Epoch: 6| Step: 11
Training loss: 2.850965976715088
Validation loss: 2.1051788381350938

Epoch: 6| Step: 12
Training loss: 2.776301860809326
Validation loss: 2.105068700287932

Epoch: 6| Step: 13
Training loss: 2.8167877197265625
Validation loss: 2.1001756332253896

Epoch: 85| Step: 0
Training loss: 2.0782594680786133
Validation loss: 2.0920868278831564

Epoch: 6| Step: 1
Training loss: 2.073402166366577
Validation loss: 2.0870091479311705

Epoch: 6| Step: 2
Training loss: 2.705749988555908
Validation loss: 2.0862604571926977

Epoch: 6| Step: 3
Training loss: 2.1532888412475586
Validation loss: 2.085598828972027

Epoch: 6| Step: 4
Training loss: 2.561021566390991
Validation loss: 2.0882494475251887

Epoch: 6| Step: 5
Training loss: 1.6508384943008423
Validation loss: 2.097643816342918

Epoch: 6| Step: 6
Training loss: 2.530879259109497
Validation loss: 2.10162438115766

Epoch: 6| Step: 7
Training loss: 2.4166088104248047
Validation loss: 2.1121573525090374

Epoch: 6| Step: 8
Training loss: 2.363374948501587
Validation loss: 2.1149602423432055

Epoch: 6| Step: 9
Training loss: 2.794584274291992
Validation loss: 2.1286074269202446

Epoch: 6| Step: 10
Training loss: 2.834186553955078
Validation loss: 2.123866378620107

Epoch: 6| Step: 11
Training loss: 2.4372777938842773
Validation loss: 2.1239632509088002

Epoch: 6| Step: 12
Training loss: 2.6649129390716553
Validation loss: 2.134038112496817

Epoch: 6| Step: 13
Training loss: 3.0144052505493164
Validation loss: 2.134764967426177

Epoch: 86| Step: 0
Training loss: 1.7523362636566162
Validation loss: 2.127870718638102

Epoch: 6| Step: 1
Training loss: 1.5915861129760742
Validation loss: 2.121323013818392

Epoch: 6| Step: 2
Training loss: 2.9147348403930664
Validation loss: 2.1171652347810808

Epoch: 6| Step: 3
Training loss: 1.3451073169708252
Validation loss: 2.1027648090034403

Epoch: 6| Step: 4
Training loss: 2.3327691555023193
Validation loss: 2.101578966263802

Epoch: 6| Step: 5
Training loss: 2.6325507164001465
Validation loss: 2.097793142000834

Epoch: 6| Step: 6
Training loss: 3.3371784687042236
Validation loss: 2.0963208803566555

Epoch: 6| Step: 7
Training loss: 2.176774024963379
Validation loss: 2.08901483269148

Epoch: 6| Step: 8
Training loss: 2.4376962184906006
Validation loss: 2.091492429856331

Epoch: 6| Step: 9
Training loss: 2.6388111114501953
Validation loss: 2.0904545771178378

Epoch: 6| Step: 10
Training loss: 2.9399678707122803
Validation loss: 2.082347095653575

Epoch: 6| Step: 11
Training loss: 2.570601224899292
Validation loss: 2.0804618789303686

Epoch: 6| Step: 12
Training loss: 2.669475555419922
Validation loss: 2.092750313461468

Epoch: 6| Step: 13
Training loss: 2.4861180782318115
Validation loss: 2.0966444348776214

Epoch: 87| Step: 0
Training loss: 2.7474822998046875
Validation loss: 2.102973722642468

Epoch: 6| Step: 1
Training loss: 1.9365456104278564
Validation loss: 2.1094510632176555

Epoch: 6| Step: 2
Training loss: 2.5684521198272705
Validation loss: 2.1197811326672955

Epoch: 6| Step: 3
Training loss: 2.343106985092163
Validation loss: 2.1240550817981845

Epoch: 6| Step: 4
Training loss: 2.575925350189209
Validation loss: 2.1077350416491107

Epoch: 6| Step: 5
Training loss: 1.8315927982330322
Validation loss: 2.0984587566826933

Epoch: 6| Step: 6
Training loss: 2.812623977661133
Validation loss: 2.0979244926924348

Epoch: 6| Step: 7
Training loss: 2.6344337463378906
Validation loss: 2.084347833869278

Epoch: 6| Step: 8
Training loss: 2.098726272583008
Validation loss: 2.1005078695153676

Epoch: 6| Step: 9
Training loss: 2.4332761764526367
Validation loss: 2.100669526284741

Epoch: 6| Step: 10
Training loss: 2.0384156703948975
Validation loss: 2.0836067071524997

Epoch: 6| Step: 11
Training loss: 2.8897576332092285
Validation loss: 2.0979392374715498

Epoch: 6| Step: 12
Training loss: 2.434569835662842
Validation loss: 2.0922729994661067

Epoch: 6| Step: 13
Training loss: 2.6009795665740967
Validation loss: 2.1022352377573648

Epoch: 88| Step: 0
Training loss: 2.056821346282959
Validation loss: 2.1039359851550032

Epoch: 6| Step: 1
Training loss: 2.1576640605926514
Validation loss: 2.1160477002461753

Epoch: 6| Step: 2
Training loss: 2.2707886695861816
Validation loss: 2.1169442540855816

Epoch: 6| Step: 3
Training loss: 3.0581517219543457
Validation loss: 2.1208304576976325

Epoch: 6| Step: 4
Training loss: 2.189235210418701
Validation loss: 2.1133905226184475

Epoch: 6| Step: 5
Training loss: 2.470513105392456
Validation loss: 2.098610734426847

Epoch: 6| Step: 6
Training loss: 2.441342353820801
Validation loss: 2.10237168881201

Epoch: 6| Step: 7
Training loss: 2.016383409500122
Validation loss: 2.1075550330582487

Epoch: 6| Step: 8
Training loss: 2.463609457015991
Validation loss: 2.119658459899246

Epoch: 6| Step: 9
Training loss: 2.3870694637298584
Validation loss: 2.1142763835127636

Epoch: 6| Step: 10
Training loss: 2.627523183822632
Validation loss: 2.1252246210652013

Epoch: 6| Step: 11
Training loss: 3.0454530715942383
Validation loss: 2.1204191228394866

Epoch: 6| Step: 12
Training loss: 1.9022189378738403
Validation loss: 2.1158189081376597

Epoch: 6| Step: 13
Training loss: 2.5173048973083496
Validation loss: 2.103584715115127

Epoch: 89| Step: 0
Training loss: 2.492819309234619
Validation loss: 2.0994867586320445

Epoch: 6| Step: 1
Training loss: 2.0505294799804688
Validation loss: 2.099898730554888

Epoch: 6| Step: 2
Training loss: 2.638514995574951
Validation loss: 2.0910940170288086

Epoch: 6| Step: 3
Training loss: 2.9112281799316406
Validation loss: 2.094097809125018

Epoch: 6| Step: 4
Training loss: 1.7381024360656738
Validation loss: 2.098490204862369

Epoch: 6| Step: 5
Training loss: 2.267831325531006
Validation loss: 2.0928124894378004

Epoch: 6| Step: 6
Training loss: 2.5238678455352783
Validation loss: 2.09815949650221

Epoch: 6| Step: 7
Training loss: 2.545823097229004
Validation loss: 2.098656387739284

Epoch: 6| Step: 8
Training loss: 1.8669872283935547
Validation loss: 2.0916469430410736

Epoch: 6| Step: 9
Training loss: 2.663945198059082
Validation loss: 2.093799885883126

Epoch: 6| Step: 10
Training loss: 2.4993791580200195
Validation loss: 2.113091040683049

Epoch: 6| Step: 11
Training loss: 2.3434736728668213
Validation loss: 2.118257414910101

Epoch: 6| Step: 12
Training loss: 2.094008207321167
Validation loss: 2.1288002460233626

Epoch: 6| Step: 13
Training loss: 3.122009754180908
Validation loss: 2.1389320460698937

Epoch: 90| Step: 0
Training loss: 2.409698247909546
Validation loss: 2.130245215149336

Epoch: 6| Step: 1
Training loss: 2.2367210388183594
Validation loss: 2.1452513176907777

Epoch: 6| Step: 2
Training loss: 2.651237726211548
Validation loss: 2.138661858856037

Epoch: 6| Step: 3
Training loss: 2.2869653701782227
Validation loss: 2.1647685445765013

Epoch: 6| Step: 4
Training loss: 2.0723588466644287
Validation loss: 2.1704853170661518

Epoch: 6| Step: 5
Training loss: 2.1377201080322266
Validation loss: 2.1794671858510664

Epoch: 6| Step: 6
Training loss: 2.711322784423828
Validation loss: 2.1691000282123523

Epoch: 6| Step: 7
Training loss: 2.146937370300293
Validation loss: 2.1450961610322357

Epoch: 6| Step: 8
Training loss: 2.4191195964813232
Validation loss: 2.1734443505605063

Epoch: 6| Step: 9
Training loss: 2.2751283645629883
Validation loss: 2.1699508467028217

Epoch: 6| Step: 10
Training loss: 2.750908851623535
Validation loss: 2.1275096324182328

Epoch: 6| Step: 11
Training loss: 2.5027480125427246
Validation loss: 2.092886774770675

Epoch: 6| Step: 12
Training loss: 2.8489573001861572
Validation loss: 2.0805299692256476

Epoch: 6| Step: 13
Training loss: 1.5877504348754883
Validation loss: 2.0633635110752557

Epoch: 91| Step: 0
Training loss: 2.7584545612335205
Validation loss: 2.0620487531026206

Epoch: 6| Step: 1
Training loss: 2.6798346042633057
Validation loss: 2.0640852502597276

Epoch: 6| Step: 2
Training loss: 2.572201728820801
Validation loss: 2.072284888195735

Epoch: 6| Step: 3
Training loss: 2.7094078063964844
Validation loss: 2.066250870304723

Epoch: 6| Step: 4
Training loss: 2.067843437194824
Validation loss: 2.0804035099603797

Epoch: 6| Step: 5
Training loss: 1.9619808197021484
Validation loss: 2.0860079206446165

Epoch: 6| Step: 6
Training loss: 2.805957794189453
Validation loss: 2.0995177684291715

Epoch: 6| Step: 7
Training loss: 1.8328628540039062
Validation loss: 2.1425410509109497

Epoch: 6| Step: 8
Training loss: 1.7207622528076172
Validation loss: 2.1438070881751274

Epoch: 6| Step: 9
Training loss: 3.0315651893615723
Validation loss: 2.145916085089407

Epoch: 6| Step: 10
Training loss: 2.517286539077759
Validation loss: 2.124732122626356

Epoch: 6| Step: 11
Training loss: 2.561755657196045
Validation loss: 2.105820555840769

Epoch: 6| Step: 12
Training loss: 2.520822048187256
Validation loss: 2.08889518501938

Epoch: 6| Step: 13
Training loss: 1.7646645307540894
Validation loss: 2.065296721714799

Epoch: 92| Step: 0
Training loss: 1.9852205514907837
Validation loss: 2.0722641714157595

Epoch: 6| Step: 1
Training loss: 1.6370790004730225
Validation loss: 2.060775406898991

Epoch: 6| Step: 2
Training loss: 2.999551296234131
Validation loss: 2.0526801270823323

Epoch: 6| Step: 3
Training loss: 2.1852827072143555
Validation loss: 2.051128028541483

Epoch: 6| Step: 4
Training loss: 3.032797336578369
Validation loss: 2.053468281222928

Epoch: 6| Step: 5
Training loss: 2.761253833770752
Validation loss: 2.052840086721605

Epoch: 6| Step: 6
Training loss: 2.605844020843506
Validation loss: 2.048522783863929

Epoch: 6| Step: 7
Training loss: 2.3063607215881348
Validation loss: 2.0687762280946136

Epoch: 6| Step: 8
Training loss: 2.387800693511963
Validation loss: 2.0812868020867787

Epoch: 6| Step: 9
Training loss: 2.345674753189087
Validation loss: 2.0952190660661265

Epoch: 6| Step: 10
Training loss: 2.2925021648406982
Validation loss: 2.1508692259429605

Epoch: 6| Step: 11
Training loss: 2.509378671646118
Validation loss: 2.207484288882184

Epoch: 6| Step: 12
Training loss: 2.2973766326904297
Validation loss: 2.2991520807307255

Epoch: 6| Step: 13
Training loss: 2.2551965713500977
Validation loss: 2.395716908157513

Epoch: 93| Step: 0
Training loss: 2.838369607925415
Validation loss: 2.39251265218181

Epoch: 6| Step: 1
Training loss: 2.181427001953125
Validation loss: 2.3023251077180267

Epoch: 6| Step: 2
Training loss: 2.526278495788574
Validation loss: 2.2054545905000422

Epoch: 6| Step: 3
Training loss: 2.356757640838623
Validation loss: 2.1230281270960325

Epoch: 6| Step: 4
Training loss: 2.8318302631378174
Validation loss: 2.099603755499727

Epoch: 6| Step: 5
Training loss: 2.6092262268066406
Validation loss: 2.0622077757312405

Epoch: 6| Step: 6
Training loss: 2.312394618988037
Validation loss: 2.0610183233855874

Epoch: 6| Step: 7
Training loss: 1.819536566734314
Validation loss: 2.0606055951887563

Epoch: 6| Step: 8
Training loss: 2.505415916442871
Validation loss: 2.0559201727631273

Epoch: 6| Step: 9
Training loss: 2.7280027866363525
Validation loss: 2.0732175124588834

Epoch: 6| Step: 10
Training loss: 2.13763689994812
Validation loss: 2.075213675857872

Epoch: 6| Step: 11
Training loss: 2.2619946002960205
Validation loss: 2.0644073332509687

Epoch: 6| Step: 12
Training loss: 2.007033586502075
Validation loss: 2.0782456885101976

Epoch: 6| Step: 13
Training loss: 2.4754583835601807
Validation loss: 2.0796253206909343

Epoch: 94| Step: 0
Training loss: 2.6813902854919434
Validation loss: 2.1240689344303583

Epoch: 6| Step: 1
Training loss: 2.823302745819092
Validation loss: 2.149036466434438

Epoch: 6| Step: 2
Training loss: 2.9285247325897217
Validation loss: 2.203050108366115

Epoch: 6| Step: 3
Training loss: 1.9320203065872192
Validation loss: 2.2356547309506323

Epoch: 6| Step: 4
Training loss: 2.2830610275268555
Validation loss: 2.2291770853022093

Epoch: 6| Step: 5
Training loss: 2.9419772624969482
Validation loss: 2.2156986882609706

Epoch: 6| Step: 6
Training loss: 2.1841704845428467
Validation loss: 2.18287254148914

Epoch: 6| Step: 7
Training loss: 2.0223960876464844
Validation loss: 2.1940202302830194

Epoch: 6| Step: 8
Training loss: 1.6474323272705078
Validation loss: 2.1910172482972503

Epoch: 6| Step: 9
Training loss: 2.8905141353607178
Validation loss: 2.1867085925994383

Epoch: 6| Step: 10
Training loss: 1.9285780191421509
Validation loss: 2.164728213382024

Epoch: 6| Step: 11
Training loss: 2.662120819091797
Validation loss: 2.129799947943739

Epoch: 6| Step: 12
Training loss: 2.3624682426452637
Validation loss: 2.13356029090061

Epoch: 6| Step: 13
Training loss: 2.2197837829589844
Validation loss: 2.127940159971996

Epoch: 95| Step: 0
Training loss: 2.634765863418579
Validation loss: 2.1531485126864527

Epoch: 6| Step: 1
Training loss: 2.6389968395233154
Validation loss: 2.154992736795897

Epoch: 6| Step: 2
Training loss: 2.480447292327881
Validation loss: 2.155683225201022

Epoch: 6| Step: 3
Training loss: 2.9639177322387695
Validation loss: 2.152777462877253

Epoch: 6| Step: 4
Training loss: 2.150876045227051
Validation loss: 2.113479229711717

Epoch: 6| Step: 5
Training loss: 2.1636552810668945
Validation loss: 2.1290960542617308

Epoch: 6| Step: 6
Training loss: 2.655601739883423
Validation loss: 2.135752404889753

Epoch: 6| Step: 7
Training loss: 2.352768898010254
Validation loss: 2.135135191743092

Epoch: 6| Step: 8
Training loss: 2.5454258918762207
Validation loss: 2.1316259830228743

Epoch: 6| Step: 9
Training loss: 1.984642744064331
Validation loss: 2.1265253610508417

Epoch: 6| Step: 10
Training loss: 1.6162302494049072
Validation loss: 2.1434422436580864

Epoch: 6| Step: 11
Training loss: 2.7889344692230225
Validation loss: 2.111731339526433

Epoch: 6| Step: 12
Training loss: 2.088019847869873
Validation loss: 2.0702843678894864

Epoch: 6| Step: 13
Training loss: 2.24133563041687
Validation loss: 2.0563395574528682

Epoch: 96| Step: 0
Training loss: 1.7696505784988403
Validation loss: 2.0756103774552703

Epoch: 6| Step: 1
Training loss: 2.307535171508789
Validation loss: 2.0579288364738546

Epoch: 6| Step: 2
Training loss: 2.6152381896972656
Validation loss: 2.0562214530924314

Epoch: 6| Step: 3
Training loss: 2.7700343132019043
Validation loss: 2.0671498493481706

Epoch: 6| Step: 4
Training loss: 2.4744679927825928
Validation loss: 2.08490159691021

Epoch: 6| Step: 5
Training loss: 2.3736186027526855
Validation loss: 2.080521577148027

Epoch: 6| Step: 6
Training loss: 1.9486275911331177
Validation loss: 2.1119803279958744

Epoch: 6| Step: 7
Training loss: 2.435901403427124
Validation loss: 2.121647814268707

Epoch: 6| Step: 8
Training loss: 2.7622971534729004
Validation loss: 2.093015765631071

Epoch: 6| Step: 9
Training loss: 2.289931535720825
Validation loss: 2.063520439209477

Epoch: 6| Step: 10
Training loss: 2.238394021987915
Validation loss: 2.0523175142144643

Epoch: 6| Step: 11
Training loss: 2.326301097869873
Validation loss: 2.040239618670556

Epoch: 6| Step: 12
Training loss: 2.247175931930542
Validation loss: 2.0368302816985757

Epoch: 6| Step: 13
Training loss: 2.9329168796539307
Validation loss: 2.0421040135045208

Epoch: 97| Step: 0
Training loss: 2.6130857467651367
Validation loss: 2.0476893558297107

Epoch: 6| Step: 1
Training loss: 2.1754684448242188
Validation loss: 2.0597137187116887

Epoch: 6| Step: 2
Training loss: 2.67464017868042
Validation loss: 2.0589808904996483

Epoch: 6| Step: 3
Training loss: 2.5172810554504395
Validation loss: 2.069429269400976

Epoch: 6| Step: 4
Training loss: 2.106832504272461
Validation loss: 2.0956831388576056

Epoch: 6| Step: 5
Training loss: 2.4380903244018555
Validation loss: 2.107228958478538

Epoch: 6| Step: 6
Training loss: 2.0196516513824463
Validation loss: 2.1368750705513904

Epoch: 6| Step: 7
Training loss: 1.8440510034561157
Validation loss: 2.161841848845123

Epoch: 6| Step: 8
Training loss: 2.2067394256591797
Validation loss: 2.151035665183939

Epoch: 6| Step: 9
Training loss: 2.818211078643799
Validation loss: 2.139322979475862

Epoch: 6| Step: 10
Training loss: 2.6497559547424316
Validation loss: 2.129312192240069

Epoch: 6| Step: 11
Training loss: 2.4070942401885986
Validation loss: 2.1124385761958298

Epoch: 6| Step: 12
Training loss: 2.009967088699341
Validation loss: 2.0907015005747476

Epoch: 6| Step: 13
Training loss: 2.21282958984375
Validation loss: 2.072409038902611

Epoch: 98| Step: 0
Training loss: 2.227369785308838
Validation loss: 2.051641356560492

Epoch: 6| Step: 1
Training loss: 2.451319932937622
Validation loss: 2.0554559756350774

Epoch: 6| Step: 2
Training loss: 1.7865650653839111
Validation loss: 2.057401259740194

Epoch: 6| Step: 3
Training loss: 1.8941142559051514
Validation loss: 2.0598000403373473

Epoch: 6| Step: 4
Training loss: 2.775871753692627
Validation loss: 2.0574500663306123

Epoch: 6| Step: 5
Training loss: 2.503190279006958
Validation loss: 2.0577686960979173

Epoch: 6| Step: 6
Training loss: 2.7639708518981934
Validation loss: 2.0758148316414125

Epoch: 6| Step: 7
Training loss: 2.2884562015533447
Validation loss: 2.101435069114931

Epoch: 6| Step: 8
Training loss: 2.5832877159118652
Validation loss: 2.109399321258709

Epoch: 6| Step: 9
Training loss: 1.9539885520935059
Validation loss: 2.107149798382995

Epoch: 6| Step: 10
Training loss: 2.797572612762451
Validation loss: 2.1004065236737652

Epoch: 6| Step: 11
Training loss: 1.2859777212142944
Validation loss: 2.108170014555736

Epoch: 6| Step: 12
Training loss: 3.3757057189941406
Validation loss: 2.1051009957508375

Epoch: 6| Step: 13
Training loss: 2.086552143096924
Validation loss: 2.068705630558793

Epoch: 99| Step: 0
Training loss: 2.7658205032348633
Validation loss: 2.046242980546849

Epoch: 6| Step: 1
Training loss: 2.737265110015869
Validation loss: 2.026031986359627

Epoch: 6| Step: 2
Training loss: 2.1935489177703857
Validation loss: 2.019800364330251

Epoch: 6| Step: 3
Training loss: 2.123257637023926
Validation loss: 2.028007532960625

Epoch: 6| Step: 4
Training loss: 2.409613609313965
Validation loss: 2.0339526617398827

Epoch: 6| Step: 5
Training loss: 2.2867202758789062
Validation loss: 2.036611746716243

Epoch: 6| Step: 6
Training loss: 2.7163825035095215
Validation loss: 2.0402921322853333

Epoch: 6| Step: 7
Training loss: 2.1189918518066406
Validation loss: 2.0372171863432853

Epoch: 6| Step: 8
Training loss: 2.257878065109253
Validation loss: 2.054005444690745

Epoch: 6| Step: 9
Training loss: 1.9785624742507935
Validation loss: 2.054456760806422

Epoch: 6| Step: 10
Training loss: 1.975979208946228
Validation loss: 2.076770185142435

Epoch: 6| Step: 11
Training loss: 2.15647029876709
Validation loss: 2.090277353922526

Epoch: 6| Step: 12
Training loss: 2.208768367767334
Validation loss: 2.122840025091684

Epoch: 6| Step: 13
Training loss: 3.405707359313965
Validation loss: 2.144250350613748

Epoch: 100| Step: 0
Training loss: 2.6421966552734375
Validation loss: 2.2059859024581088

Epoch: 6| Step: 1
Training loss: 2.2504515647888184
Validation loss: 2.2036867487815117

Epoch: 6| Step: 2
Training loss: 1.7166643142700195
Validation loss: 2.1859493614524923

Epoch: 6| Step: 3
Training loss: 2.288785219192505
Validation loss: 2.1449694056664743

Epoch: 6| Step: 4
Training loss: 1.951167106628418
Validation loss: 2.108685274277964

Epoch: 6| Step: 5
Training loss: 2.892138957977295
Validation loss: 2.0689606282018844

Epoch: 6| Step: 6
Training loss: 2.322558879852295
Validation loss: 2.0786535073352117

Epoch: 6| Step: 7
Training loss: 1.8046379089355469
Validation loss: 2.079075890202676

Epoch: 6| Step: 8
Training loss: 2.444122552871704
Validation loss: 2.0767463496936265

Epoch: 6| Step: 9
Training loss: 2.63822078704834
Validation loss: 2.0730894842455463

Epoch: 6| Step: 10
Training loss: 2.8337020874023438
Validation loss: 2.0700483475961993

Epoch: 6| Step: 11
Training loss: 2.177279472351074
Validation loss: 2.0681837386982416

Epoch: 6| Step: 12
Training loss: 2.5981404781341553
Validation loss: 2.062575342834637

Epoch: 6| Step: 13
Training loss: 2.6065409183502197
Validation loss: 2.0546578771324566

Epoch: 101| Step: 0
Training loss: 2.2139968872070312
Validation loss: 2.053062613292407

Epoch: 6| Step: 1
Training loss: 2.1192822456359863
Validation loss: 2.0492551788207023

Epoch: 6| Step: 2
Training loss: 3.03922438621521
Validation loss: 2.047826697749476

Epoch: 6| Step: 3
Training loss: 2.7428793907165527
Validation loss: 2.0291024920760945

Epoch: 6| Step: 4
Training loss: 1.7388135194778442
Validation loss: 2.0257363729579474

Epoch: 6| Step: 5
Training loss: 2.400940418243408
Validation loss: 2.03777825960549

Epoch: 6| Step: 6
Training loss: 2.109748363494873
Validation loss: 2.0238814225760837

Epoch: 6| Step: 7
Training loss: 1.9864267110824585
Validation loss: 2.0435345890701457

Epoch: 6| Step: 8
Training loss: 2.3871264457702637
Validation loss: 2.0677582140891784

Epoch: 6| Step: 9
Training loss: 2.5418732166290283
Validation loss: 2.1141361562154626

Epoch: 6| Step: 10
Training loss: 2.4061245918273926
Validation loss: 2.158513581880959

Epoch: 6| Step: 11
Training loss: 2.928363561630249
Validation loss: 2.1368249001041537

Epoch: 6| Step: 12
Training loss: 2.1233320236206055
Validation loss: 2.1619667788987518

Epoch: 6| Step: 13
Training loss: 1.7013163566589355
Validation loss: 2.15832116014214

Epoch: 102| Step: 0
Training loss: 2.807626485824585
Validation loss: 2.136540174484253

Epoch: 6| Step: 1
Training loss: 2.4877431392669678
Validation loss: 2.102669961990849

Epoch: 6| Step: 2
Training loss: 2.434208869934082
Validation loss: 2.0813694282244612

Epoch: 6| Step: 3
Training loss: 2.326218366622925
Validation loss: 2.0616542677725516

Epoch: 6| Step: 4
Training loss: 1.9641776084899902
Validation loss: 2.059573401686966

Epoch: 6| Step: 5
Training loss: 2.2933435440063477
Validation loss: 2.062363750191145

Epoch: 6| Step: 6
Training loss: 2.5226709842681885
Validation loss: 2.0682539786061933

Epoch: 6| Step: 7
Training loss: 1.5260820388793945
Validation loss: 2.074894153943626

Epoch: 6| Step: 8
Training loss: 2.1162149906158447
Validation loss: 2.0861274298801216

Epoch: 6| Step: 9
Training loss: 2.9203271865844727
Validation loss: 2.0927082620641237

Epoch: 6| Step: 10
Training loss: 2.4375643730163574
Validation loss: 2.0835922712920816

Epoch: 6| Step: 11
Training loss: 1.993958830833435
Validation loss: 2.090353924741027

Epoch: 6| Step: 12
Training loss: 2.3596110343933105
Validation loss: 2.103908020962951

Epoch: 6| Step: 13
Training loss: 2.2411820888519287
Validation loss: 2.08061154811613

Epoch: 103| Step: 0
Training loss: 2.248109817504883
Validation loss: 2.059851005513181

Epoch: 6| Step: 1
Training loss: 1.7969276905059814
Validation loss: 2.0513327839553996

Epoch: 6| Step: 2
Training loss: 1.9573606252670288
Validation loss: 2.0516736635597805

Epoch: 6| Step: 3
Training loss: 2.5727248191833496
Validation loss: 2.0427979423153784

Epoch: 6| Step: 4
Training loss: 2.5618529319763184
Validation loss: 2.0306321843977897

Epoch: 6| Step: 5
Training loss: 2.105181932449341
Validation loss: 2.0327806524051133

Epoch: 6| Step: 6
Training loss: 2.2107064723968506
Validation loss: 2.0316833193584154

Epoch: 6| Step: 7
Training loss: 2.0521998405456543
Validation loss: 2.0720154264921784

Epoch: 6| Step: 8
Training loss: 2.8741044998168945
Validation loss: 2.159035787787489

Epoch: 6| Step: 9
Training loss: 2.3719277381896973
Validation loss: 2.1987399067929996

Epoch: 6| Step: 10
Training loss: 2.990280866622925
Validation loss: 2.178858377600229

Epoch: 6| Step: 11
Training loss: 2.2260639667510986
Validation loss: 2.1284827775852655

Epoch: 6| Step: 12
Training loss: 2.655043125152588
Validation loss: 2.0527301052565217

Epoch: 6| Step: 13
Training loss: 2.271094799041748
Validation loss: 2.0213614099769184

Epoch: 104| Step: 0
Training loss: 2.4629459381103516
Validation loss: 2.0175477061220395

Epoch: 6| Step: 1
Training loss: 1.8155076503753662
Validation loss: 2.0189186398701002

Epoch: 6| Step: 2
Training loss: 2.94427752494812
Validation loss: 2.0298114874029674

Epoch: 6| Step: 3
Training loss: 1.9792115688323975
Validation loss: 2.0412613320094284

Epoch: 6| Step: 4
Training loss: 2.523843765258789
Validation loss: 2.058110132012316

Epoch: 6| Step: 5
Training loss: 2.4439990520477295
Validation loss: 2.0711131275341077

Epoch: 6| Step: 6
Training loss: 2.512681245803833
Validation loss: 2.0784600755219818

Epoch: 6| Step: 7
Training loss: 2.1929879188537598
Validation loss: 2.0804839877672094

Epoch: 6| Step: 8
Training loss: 2.106034755706787
Validation loss: 2.0974901389050227

Epoch: 6| Step: 9
Training loss: 2.7908051013946533
Validation loss: 2.1059129212492254

Epoch: 6| Step: 10
Training loss: 1.9030568599700928
Validation loss: 2.134698724233976

Epoch: 6| Step: 11
Training loss: 2.197683811187744
Validation loss: 2.1343295907461517

Epoch: 6| Step: 12
Training loss: 1.8979462385177612
Validation loss: 2.132835724020517

Epoch: 6| Step: 13
Training loss: 2.6845879554748535
Validation loss: 2.092068269688596

Epoch: 105| Step: 0
Training loss: 1.4302165508270264
Validation loss: 2.0546399931753836

Epoch: 6| Step: 1
Training loss: 2.178480386734009
Validation loss: 2.039021549686309

Epoch: 6| Step: 2
Training loss: 2.3803062438964844
Validation loss: 2.039202050496173

Epoch: 6| Step: 3
Training loss: 2.4583277702331543
Validation loss: 2.036928479389478

Epoch: 6| Step: 4
Training loss: 2.8416810035705566
Validation loss: 2.025833743874745

Epoch: 6| Step: 5
Training loss: 1.7371950149536133
Validation loss: 2.031263792386619

Epoch: 6| Step: 6
Training loss: 1.8218412399291992
Validation loss: 2.026275893693329

Epoch: 6| Step: 7
Training loss: 2.4615185260772705
Validation loss: 2.0395788441422167

Epoch: 6| Step: 8
Training loss: 2.560576915740967
Validation loss: 2.0376060662731046

Epoch: 6| Step: 9
Training loss: 2.1374430656433105
Validation loss: 2.040049840045232

Epoch: 6| Step: 10
Training loss: 2.5034892559051514
Validation loss: 2.041092526528143

Epoch: 6| Step: 11
Training loss: 2.761601209640503
Validation loss: 2.052509818025815

Epoch: 6| Step: 12
Training loss: 2.7136998176574707
Validation loss: 2.065281045052313

Epoch: 6| Step: 13
Training loss: 1.8564553260803223
Validation loss: 2.077886963403353

Epoch: 106| Step: 0
Training loss: 1.7643451690673828
Validation loss: 2.1147761357727872

Epoch: 6| Step: 1
Training loss: 1.8971256017684937
Validation loss: 2.1677504688180904

Epoch: 6| Step: 2
Training loss: 2.030376672744751
Validation loss: 2.2149912003547914

Epoch: 6| Step: 3
Training loss: 2.5837488174438477
Validation loss: 2.2421596716809016

Epoch: 6| Step: 4
Training loss: 2.5472381114959717
Validation loss: 2.1633492733842585

Epoch: 6| Step: 5
Training loss: 2.651134729385376
Validation loss: 2.132135134871288

Epoch: 6| Step: 6
Training loss: 2.2404768466949463
Validation loss: 2.0862209591814267

Epoch: 6| Step: 7
Training loss: 1.9381091594696045
Validation loss: 2.0510307652975923

Epoch: 6| Step: 8
Training loss: 2.558049201965332
Validation loss: 2.0501754668451126

Epoch: 6| Step: 9
Training loss: 3.016979217529297
Validation loss: 2.056417654919368

Epoch: 6| Step: 10
Training loss: 1.9597004652023315
Validation loss: 2.0473426682974702

Epoch: 6| Step: 11
Training loss: 2.4913489818573
Validation loss: 2.0377823460486626

Epoch: 6| Step: 12
Training loss: 2.497910976409912
Validation loss: 2.027742708882978

Epoch: 6| Step: 13
Training loss: 1.9735785722732544
Validation loss: 2.0321661708175496

Epoch: 107| Step: 0
Training loss: 2.2609755992889404
Validation loss: 2.030610854907702

Epoch: 6| Step: 1
Training loss: 2.418400764465332
Validation loss: 2.035722756898531

Epoch: 6| Step: 2
Training loss: 1.9938199520111084
Validation loss: 2.0445663954622004

Epoch: 6| Step: 3
Training loss: 2.263927936553955
Validation loss: 2.04771581772835

Epoch: 6| Step: 4
Training loss: 2.0706188678741455
Validation loss: 2.0593242747809297

Epoch: 6| Step: 5
Training loss: 1.635696530342102
Validation loss: 2.0629070420419016

Epoch: 6| Step: 6
Training loss: 2.818925380706787
Validation loss: 2.073768800304782

Epoch: 6| Step: 7
Training loss: 1.8228025436401367
Validation loss: 2.093741310540066

Epoch: 6| Step: 8
Training loss: 2.660270929336548
Validation loss: 2.101139550567955

Epoch: 6| Step: 9
Training loss: 1.9640300273895264
Validation loss: 2.150114905449652

Epoch: 6| Step: 10
Training loss: 2.6872401237487793
Validation loss: 2.178378294872981

Epoch: 6| Step: 11
Training loss: 1.7605252265930176
Validation loss: 2.151648195840979

Epoch: 6| Step: 12
Training loss: 3.486992359161377
Validation loss: 2.115155294377317

Epoch: 6| Step: 13
Training loss: 1.6238884925842285
Validation loss: 2.0865691195252123

Epoch: 108| Step: 0
Training loss: 2.981802225112915
Validation loss: 2.0634162707995345

Epoch: 6| Step: 1
Training loss: 2.583580493927002
Validation loss: 2.049030501355407

Epoch: 6| Step: 2
Training loss: 2.312505006790161
Validation loss: 2.052415177386294

Epoch: 6| Step: 3
Training loss: 2.4257659912109375
Validation loss: 2.05182134976951

Epoch: 6| Step: 4
Training loss: 1.9838058948516846
Validation loss: 2.0530846811109975

Epoch: 6| Step: 5
Training loss: 1.8714239597320557
Validation loss: 2.0544214325566448

Epoch: 6| Step: 6
Training loss: 2.580988645553589
Validation loss: 2.0481056039051344

Epoch: 6| Step: 7
Training loss: 2.3187806606292725
Validation loss: 2.0535931741037676

Epoch: 6| Step: 8
Training loss: 1.6898629665374756
Validation loss: 2.0722793635501655

Epoch: 6| Step: 9
Training loss: 1.6684495210647583
Validation loss: 2.070500571240661

Epoch: 6| Step: 10
Training loss: 1.8830214738845825
Validation loss: 2.0927727132715206

Epoch: 6| Step: 11
Training loss: 2.493497610092163
Validation loss: 2.0962427764810543

Epoch: 6| Step: 12
Training loss: 2.0657992362976074
Validation loss: 2.1041334162476244

Epoch: 6| Step: 13
Training loss: 3.042965888977051
Validation loss: 2.082146724065145

Epoch: 109| Step: 0
Training loss: 2.731621265411377
Validation loss: 2.0759423419993412

Epoch: 6| Step: 1
Training loss: 2.3802490234375
Validation loss: 2.0726148672001337

Epoch: 6| Step: 2
Training loss: 2.1691668033599854
Validation loss: 2.082413319618471

Epoch: 6| Step: 3
Training loss: 1.7076979875564575
Validation loss: 2.0816186666488647

Epoch: 6| Step: 4
Training loss: 2.8019843101501465
Validation loss: 2.0952958573577223

Epoch: 6| Step: 5
Training loss: 2.0320687294006348
Validation loss: 2.1025995016098022

Epoch: 6| Step: 6
Training loss: 2.273192882537842
Validation loss: 2.074680218132593

Epoch: 6| Step: 7
Training loss: 2.100432872772217
Validation loss: 2.0537500381469727

Epoch: 6| Step: 8
Training loss: 1.9598027467727661
Validation loss: 2.06452444548248

Epoch: 6| Step: 9
Training loss: 2.446570873260498
Validation loss: 2.055452649311353

Epoch: 6| Step: 10
Training loss: 1.5457773208618164
Validation loss: 2.0577532424721667

Epoch: 6| Step: 11
Training loss: 2.0747671127319336
Validation loss: 2.059424252920253

Epoch: 6| Step: 12
Training loss: 2.2059104442596436
Validation loss: 2.0638350863610544

Epoch: 6| Step: 13
Training loss: 3.071352243423462
Validation loss: 2.064599424280146

Epoch: 110| Step: 0
Training loss: 2.302639961242676
Validation loss: 2.068104710630191

Epoch: 6| Step: 1
Training loss: 2.268765926361084
Validation loss: 2.068238527544083

Epoch: 6| Step: 2
Training loss: 1.597977876663208
Validation loss: 2.0899312227003035

Epoch: 6| Step: 3
Training loss: 2.251260280609131
Validation loss: 2.1122592341515327

Epoch: 6| Step: 4
Training loss: 2.2079215049743652
Validation loss: 2.1284696517452115

Epoch: 6| Step: 5
Training loss: 1.6636486053466797
Validation loss: 2.134073434337493

Epoch: 6| Step: 6
Training loss: 2.3019254207611084
Validation loss: 2.109231964234383

Epoch: 6| Step: 7
Training loss: 2.2879605293273926
Validation loss: 2.089390088153142

Epoch: 6| Step: 8
Training loss: 2.9950363636016846
Validation loss: 2.075829646920645

Epoch: 6| Step: 9
Training loss: 2.729344367980957
Validation loss: 2.0632812361563406

Epoch: 6| Step: 10
Training loss: 1.3841350078582764
Validation loss: 2.043807696270686

Epoch: 6| Step: 11
Training loss: 2.2399983406066895
Validation loss: 2.039766491100352

Epoch: 6| Step: 12
Training loss: 2.540548801422119
Validation loss: 2.0358283891472766

Epoch: 6| Step: 13
Training loss: 2.355499505996704
Validation loss: 2.0301214700104087

Epoch: 111| Step: 0
Training loss: 2.1963582038879395
Validation loss: 2.0357934377526723

Epoch: 6| Step: 1
Training loss: 2.053680896759033
Validation loss: 2.0469409188916607

Epoch: 6| Step: 2
Training loss: 1.8164457082748413
Validation loss: 2.0470251549956617

Epoch: 6| Step: 3
Training loss: 2.6363773345947266
Validation loss: 2.055060322566699

Epoch: 6| Step: 4
Training loss: 1.7370781898498535
Validation loss: 2.0649293955936225

Epoch: 6| Step: 5
Training loss: 1.9413459300994873
Validation loss: 2.0980431213173816

Epoch: 6| Step: 6
Training loss: 2.131545066833496
Validation loss: 2.0917564976599907

Epoch: 6| Step: 7
Training loss: 2.5343239307403564
Validation loss: 2.112520581932478

Epoch: 6| Step: 8
Training loss: 2.017058849334717
Validation loss: 2.117820538500304

Epoch: 6| Step: 9
Training loss: 2.687066078186035
Validation loss: 2.118496033453172

Epoch: 6| Step: 10
Training loss: 2.3538970947265625
Validation loss: 2.0979491638880905

Epoch: 6| Step: 11
Training loss: 2.4424145221710205
Validation loss: 2.099696336253997

Epoch: 6| Step: 12
Training loss: 2.145125389099121
Validation loss: 2.092632248837461

Epoch: 6| Step: 13
Training loss: 1.6372674703598022
Validation loss: 2.068194600843614

Epoch: 112| Step: 0
Training loss: 2.05368971824646
Validation loss: 2.0538428239924933

Epoch: 6| Step: 1
Training loss: 2.0378785133361816
Validation loss: 2.058509539532405

Epoch: 6| Step: 2
Training loss: 2.1082980632781982
Validation loss: 2.039390176855108

Epoch: 6| Step: 3
Training loss: 2.642850160598755
Validation loss: 2.0437465201142015

Epoch: 6| Step: 4
Training loss: 2.1911044120788574
Validation loss: 2.048476901105655

Epoch: 6| Step: 5
Training loss: 2.237683057785034
Validation loss: 2.044214235839023

Epoch: 6| Step: 6
Training loss: 2.6246395111083984
Validation loss: 2.0840910327049995

Epoch: 6| Step: 7
Training loss: 2.6463680267333984
Validation loss: 2.1100791936279624

Epoch: 6| Step: 8
Training loss: 2.013963222503662
Validation loss: 2.1462394422100437

Epoch: 6| Step: 9
Training loss: 2.131279945373535
Validation loss: 2.1028773041181665

Epoch: 6| Step: 10
Training loss: 1.7031046152114868
Validation loss: 2.077286911267106

Epoch: 6| Step: 11
Training loss: 1.9400136470794678
Validation loss: 2.032492450488511

Epoch: 6| Step: 12
Training loss: 2.1414506435394287
Validation loss: 2.0203917308520247

Epoch: 6| Step: 13
Training loss: 2.178687810897827
Validation loss: 1.9983189887897943

Epoch: 113| Step: 0
Training loss: 1.9430487155914307
Validation loss: 2.008883686475856

Epoch: 6| Step: 1
Training loss: 2.5932767391204834
Validation loss: 2.024524668211578

Epoch: 6| Step: 2
Training loss: 2.0748238563537598
Validation loss: 2.037125687445364

Epoch: 6| Step: 3
Training loss: 2.276803493499756
Validation loss: 2.042733989736085

Epoch: 6| Step: 4
Training loss: 1.964583158493042
Validation loss: 2.0490000299228135

Epoch: 6| Step: 5
Training loss: 1.2959758043289185
Validation loss: 2.0618252138937674

Epoch: 6| Step: 6
Training loss: 1.970057725906372
Validation loss: 2.0525367644525345

Epoch: 6| Step: 7
Training loss: 2.3155221939086914
Validation loss: 2.078303647297685

Epoch: 6| Step: 8
Training loss: 2.5460283756256104
Validation loss: 2.096036075263895

Epoch: 6| Step: 9
Training loss: 2.1198432445526123
Validation loss: 2.108392312962522

Epoch: 6| Step: 10
Training loss: 2.4337432384490967
Validation loss: 2.1168797913418023

Epoch: 6| Step: 11
Training loss: 2.612328052520752
Validation loss: 2.137430837077479

Epoch: 6| Step: 12
Training loss: 1.381699800491333
Validation loss: 2.13045004106337

Epoch: 6| Step: 13
Training loss: 2.3852882385253906
Validation loss: 2.0897546532333537

Epoch: 114| Step: 0
Training loss: 1.675359845161438
Validation loss: 2.076745371664724

Epoch: 6| Step: 1
Training loss: 2.515017032623291
Validation loss: 2.074123744041689

Epoch: 6| Step: 2
Training loss: 1.9908313751220703
Validation loss: 2.090804510219123

Epoch: 6| Step: 3
Training loss: 2.064121723175049
Validation loss: 2.09679106743105

Epoch: 6| Step: 4
Training loss: 2.5414540767669678
Validation loss: 2.0892507107027116

Epoch: 6| Step: 5
Training loss: 1.4682289361953735
Validation loss: 2.099202794413413

Epoch: 6| Step: 6
Training loss: 2.747704029083252
Validation loss: 2.1217148816713722

Epoch: 6| Step: 7
Training loss: 2.680670976638794
Validation loss: 2.133231774453194

Epoch: 6| Step: 8
Training loss: 2.0997605323791504
Validation loss: 2.1381583188169744

Epoch: 6| Step: 9
Training loss: 2.241870641708374
Validation loss: 2.106766047016267

Epoch: 6| Step: 10
Training loss: 1.9898204803466797
Validation loss: 2.0680591906270673

Epoch: 6| Step: 11
Training loss: 1.784521222114563
Validation loss: 2.043401946303665

Epoch: 6| Step: 12
Training loss: 2.3888230323791504
Validation loss: 2.0481562832350373

Epoch: 6| Step: 13
Training loss: 1.478460669517517
Validation loss: 2.047784334869795

Epoch: 115| Step: 0
Training loss: 1.7632604837417603
Validation loss: 2.023241448146041

Epoch: 6| Step: 1
Training loss: 2.494668960571289
Validation loss: 2.0097578289688274

Epoch: 6| Step: 2
Training loss: 2.131849527359009
Validation loss: 2.0081052369968866

Epoch: 6| Step: 3
Training loss: 2.5293641090393066
Validation loss: 2.0085491224001815

Epoch: 6| Step: 4
Training loss: 2.0740914344787598
Validation loss: 2.0186655457301805

Epoch: 6| Step: 5
Training loss: 1.6373342275619507
Validation loss: 2.019021595678022

Epoch: 6| Step: 6
Training loss: 2.470815420150757
Validation loss: 2.0155179180124754

Epoch: 6| Step: 7
Training loss: 1.7359814643859863
Validation loss: 2.0524613882905696

Epoch: 6| Step: 8
Training loss: 1.528342604637146
Validation loss: 2.0567061593455653

Epoch: 6| Step: 9
Training loss: 2.1211142539978027
Validation loss: 2.0740089044776013

Epoch: 6| Step: 10
Training loss: 2.2402806282043457
Validation loss: 2.086568567060655

Epoch: 6| Step: 11
Training loss: 2.2556447982788086
Validation loss: 2.0812746619665496

Epoch: 6| Step: 12
Training loss: 2.0442566871643066
Validation loss: 2.057233513042491

Epoch: 6| Step: 13
Training loss: 2.5804615020751953
Validation loss: 2.038511477490907

Epoch: 116| Step: 0
Training loss: 2.6302895545959473
Validation loss: 2.04509154699182

Epoch: 6| Step: 1
Training loss: 2.288696050643921
Validation loss: 2.0449741501961984

Epoch: 6| Step: 2
Training loss: 2.290628433227539
Validation loss: 2.0418759187062583

Epoch: 6| Step: 3
Training loss: 2.005117416381836
Validation loss: 2.050969631441178

Epoch: 6| Step: 4
Training loss: 2.1863622665405273
Validation loss: 2.053649979252969

Epoch: 6| Step: 5
Training loss: 1.6872525215148926
Validation loss: 2.0812060397158385

Epoch: 6| Step: 6
Training loss: 2.3920516967773438
Validation loss: 2.149321307418167

Epoch: 6| Step: 7
Training loss: 2.7241294384002686
Validation loss: 2.2469237953104

Epoch: 6| Step: 8
Training loss: 1.3033583164215088
Validation loss: 2.301584215574367

Epoch: 6| Step: 9
Training loss: 1.948423147201538
Validation loss: 2.2754034201304116

Epoch: 6| Step: 10
Training loss: 1.8623203039169312
Validation loss: 2.1732643983697377

Epoch: 6| Step: 11
Training loss: 2.692826509475708
Validation loss: 2.1027279053964922

Epoch: 6| Step: 12
Training loss: 2.0761313438415527
Validation loss: 2.0684380915857132

Epoch: 6| Step: 13
Training loss: 2.0583012104034424
Validation loss: 2.0791729316916516

Epoch: 117| Step: 0
Training loss: 2.0596649646759033
Validation loss: 2.121847455219556

Epoch: 6| Step: 1
Training loss: 2.271193027496338
Validation loss: 2.152808232973981

Epoch: 6| Step: 2
Training loss: 2.5147593021392822
Validation loss: 2.151864537628748

Epoch: 6| Step: 3
Training loss: 2.900829315185547
Validation loss: 2.0801010131835938

Epoch: 6| Step: 4
Training loss: 2.286351203918457
Validation loss: 2.016322612762451

Epoch: 6| Step: 5
Training loss: 1.9150400161743164
Validation loss: 2.004425325701314

Epoch: 6| Step: 6
Training loss: 1.265981674194336
Validation loss: 1.9907478145373765

Epoch: 6| Step: 7
Training loss: 2.616986036300659
Validation loss: 2.0219608391484907

Epoch: 6| Step: 8
Training loss: 2.930969715118408
Validation loss: 2.0941056205380346

Epoch: 6| Step: 9
Training loss: 1.7299189567565918
Validation loss: 2.1436615144052813

Epoch: 6| Step: 10
Training loss: 1.8593918085098267
Validation loss: 2.2148324366538756

Epoch: 6| Step: 11
Training loss: 1.9517443180084229
Validation loss: 2.2379768099836124

Epoch: 6| Step: 12
Training loss: 2.2152259349823
Validation loss: 2.222252194599439

Epoch: 6| Step: 13
Training loss: 2.462202787399292
Validation loss: 2.1272976334377

Epoch: 118| Step: 0
Training loss: 2.449507713317871
Validation loss: 2.0346187622316423

Epoch: 6| Step: 1
Training loss: 1.9954291582107544
Validation loss: 2.0183655382484518

Epoch: 6| Step: 2
Training loss: 2.440401077270508
Validation loss: 2.043478247939899

Epoch: 6| Step: 3
Training loss: 1.8353878259658813
Validation loss: 2.0701730687131166

Epoch: 6| Step: 4
Training loss: 2.6688289642333984
Validation loss: 2.159184766072099

Epoch: 6| Step: 5
Training loss: 2.104248046875
Validation loss: 2.2261413297345563

Epoch: 6| Step: 6
Training loss: 2.6997203826904297
Validation loss: 2.160648453620172

Epoch: 6| Step: 7
Training loss: 2.423018217086792
Validation loss: 2.080169872571063

Epoch: 6| Step: 8
Training loss: 2.2148056030273438
Validation loss: 2.017621191599036

Epoch: 6| Step: 9
Training loss: 2.297020435333252
Validation loss: 2.015898842965403

Epoch: 6| Step: 10
Training loss: 1.4608538150787354
Validation loss: 2.0424171006807716

Epoch: 6| Step: 11
Training loss: 1.3420593738555908
Validation loss: 2.1070547872974026

Epoch: 6| Step: 12
Training loss: 2.345623016357422
Validation loss: 2.2095347655716764

Epoch: 6| Step: 13
Training loss: 3.117377519607544
Validation loss: 2.2943546746366765

Epoch: 119| Step: 0
Training loss: 1.7769043445587158
Validation loss: 2.2597208356344574

Epoch: 6| Step: 1
Training loss: 2.0027616024017334
Validation loss: 2.270522955925234

Epoch: 6| Step: 2
Training loss: 2.2320704460144043
Validation loss: 2.2151399350935415

Epoch: 6| Step: 3
Training loss: 1.5701875686645508
Validation loss: 2.1717884796921925

Epoch: 6| Step: 4
Training loss: 1.9472880363464355
Validation loss: 2.1301290706921647

Epoch: 6| Step: 5
Training loss: 1.921981930732727
Validation loss: 2.090953749995078

Epoch: 6| Step: 6
Training loss: 2.2659173011779785
Validation loss: 2.083102080129808

Epoch: 6| Step: 7
Training loss: 2.086505889892578
Validation loss: 2.071499806578441

Epoch: 6| Step: 8
Training loss: 1.3504164218902588
Validation loss: 2.0753223793480986

Epoch: 6| Step: 9
Training loss: 2.1290178298950195
Validation loss: 2.0847633602798625

Epoch: 6| Step: 10
Training loss: 2.713332176208496
Validation loss: 2.0880469455513904

Epoch: 6| Step: 11
Training loss: 2.779313564300537
Validation loss: 2.094277648515599

Epoch: 6| Step: 12
Training loss: 2.0679545402526855
Validation loss: 2.1081322072654642

Epoch: 6| Step: 13
Training loss: 2.8014721870422363
Validation loss: 2.1033773909332933

Epoch: 120| Step: 0
Training loss: 1.906314492225647
Validation loss: 2.120690211173027

Epoch: 6| Step: 1
Training loss: 1.774104356765747
Validation loss: 2.1209002592230357

Epoch: 6| Step: 2
Training loss: 2.130016803741455
Validation loss: 2.098490515062886

Epoch: 6| Step: 3
Training loss: 1.572307825088501
Validation loss: 2.0783456269130913

Epoch: 6| Step: 4
Training loss: 1.7707622051239014
Validation loss: 2.08989054413252

Epoch: 6| Step: 5
Training loss: 1.8459398746490479
Validation loss: 2.08012750071864

Epoch: 6| Step: 6
Training loss: 1.7168561220169067
Validation loss: 2.0461791061585948

Epoch: 6| Step: 7
Training loss: 1.6626484394073486
Validation loss: 2.023848545166754

Epoch: 6| Step: 8
Training loss: 2.6120457649230957
Validation loss: 1.982350900609006

Epoch: 6| Step: 9
Training loss: 2.4138174057006836
Validation loss: 1.9817744916485203

Epoch: 6| Step: 10
Training loss: 2.244558334350586
Validation loss: 1.9742239752123434

Epoch: 6| Step: 11
Training loss: 2.49125337600708
Validation loss: 1.981500292337069

Epoch: 6| Step: 12
Training loss: 2.3907082080841064
Validation loss: 1.971118006654965

Epoch: 6| Step: 13
Training loss: 2.559985637664795
Validation loss: 1.9801873981311757

Epoch: 121| Step: 0
Training loss: 2.3164000511169434
Validation loss: 2.0045623061477498

Epoch: 6| Step: 1
Training loss: 2.0102081298828125
Validation loss: 2.0015976454622004

Epoch: 6| Step: 2
Training loss: 1.703283429145813
Validation loss: 2.01859026826838

Epoch: 6| Step: 3
Training loss: 1.7512177228927612
Validation loss: 2.032794198682231

Epoch: 6| Step: 4
Training loss: 1.469942569732666
Validation loss: 2.026387999134679

Epoch: 6| Step: 5
Training loss: 2.1320877075195312
Validation loss: 2.051004999427385

Epoch: 6| Step: 6
Training loss: 2.3151144981384277
Validation loss: 2.044440043869839

Epoch: 6| Step: 7
Training loss: 1.947574257850647
Validation loss: 2.0246334101564143

Epoch: 6| Step: 8
Training loss: 2.8421735763549805
Validation loss: 2.0309418337319487

Epoch: 6| Step: 9
Training loss: 2.1610872745513916
Validation loss: 2.021610765046971

Epoch: 6| Step: 10
Training loss: 2.0259475708007812
Validation loss: 2.0290092358025174

Epoch: 6| Step: 11
Training loss: 1.8040927648544312
Validation loss: 2.0125586858359714

Epoch: 6| Step: 12
Training loss: 1.8390108346939087
Validation loss: 2.0234070208764847

Epoch: 6| Step: 13
Training loss: 1.531254768371582
Validation loss: 2.014032930456182

Epoch: 122| Step: 0
Training loss: 1.680215835571289
Validation loss: 2.0283865749195056

Epoch: 6| Step: 1
Training loss: 2.311944007873535
Validation loss: 2.0284260754944174

Epoch: 6| Step: 2
Training loss: 1.9760767221450806
Validation loss: 2.0542807297040055

Epoch: 6| Step: 3
Training loss: 2.1916115283966064
Validation loss: 2.0995867342077275

Epoch: 6| Step: 4
Training loss: 1.9710571765899658
Validation loss: 2.117796141614196

Epoch: 6| Step: 5
Training loss: 2.0186004638671875
Validation loss: 2.167205359346123

Epoch: 6| Step: 6
Training loss: 1.6577719449996948
Validation loss: 2.1813030781284457

Epoch: 6| Step: 7
Training loss: 2.427001953125
Validation loss: 2.1867816640484716

Epoch: 6| Step: 8
Training loss: 1.836454153060913
Validation loss: 2.130193748781758

Epoch: 6| Step: 9
Training loss: 2.5079736709594727
Validation loss: 2.061338399046211

Epoch: 6| Step: 10
Training loss: 2.132131576538086
Validation loss: 2.0250904688271145

Epoch: 6| Step: 11
Training loss: 1.8998979330062866
Validation loss: 2.000587095496475

Epoch: 6| Step: 12
Training loss: 1.5240572690963745
Validation loss: 1.9947174749066752

Epoch: 6| Step: 13
Training loss: 2.471633195877075
Validation loss: 1.9938656668509207

Epoch: 123| Step: 0
Training loss: 1.9808590412139893
Validation loss: 2.0009950360944195

Epoch: 6| Step: 1
Training loss: 1.8408939838409424
Validation loss: 2.0116845151429534

Epoch: 6| Step: 2
Training loss: 2.380187511444092
Validation loss: 2.005608061308502

Epoch: 6| Step: 3
Training loss: 1.6024601459503174
Validation loss: 2.03467438297887

Epoch: 6| Step: 4
Training loss: 1.6438359022140503
Validation loss: 2.036684592564901

Epoch: 6| Step: 5
Training loss: 2.3321142196655273
Validation loss: 2.05707912675796

Epoch: 6| Step: 6
Training loss: 2.4601032733917236
Validation loss: 2.0698957802146993

Epoch: 6| Step: 7
Training loss: 1.990112543106079
Validation loss: 2.0563402996268323

Epoch: 6| Step: 8
Training loss: 1.9378278255462646
Validation loss: 2.0320051895674838

Epoch: 6| Step: 9
Training loss: 2.1939477920532227
Validation loss: 2.0175914187585153

Epoch: 6| Step: 10
Training loss: 1.9515495300292969
Validation loss: 2.0173686909419235

Epoch: 6| Step: 11
Training loss: 1.8555924892425537
Validation loss: 2.0350493743855465

Epoch: 6| Step: 12
Training loss: 2.2441859245300293
Validation loss: 2.0414424891112954

Epoch: 6| Step: 13
Training loss: 1.1455525159835815
Validation loss: 2.0647773229947655

Epoch: 124| Step: 0
Training loss: 1.8600834608078003
Validation loss: 2.100003429638442

Epoch: 6| Step: 1
Training loss: 1.3899667263031006
Validation loss: 2.118662941840387

Epoch: 6| Step: 2
Training loss: 2.3489043712615967
Validation loss: 2.1621240800426853

Epoch: 6| Step: 3
Training loss: 2.280534267425537
Validation loss: 2.1330502802325833

Epoch: 6| Step: 4
Training loss: 2.215479612350464
Validation loss: 2.113300859287221

Epoch: 6| Step: 5
Training loss: 2.1099939346313477
Validation loss: 2.0639225603431783

Epoch: 6| Step: 6
Training loss: 1.6383891105651855
Validation loss: 2.047874240465062

Epoch: 6| Step: 7
Training loss: 2.498533010482788
Validation loss: 2.053820043481806

Epoch: 6| Step: 8
Training loss: 1.5910556316375732
Validation loss: 2.0680792690605245

Epoch: 6| Step: 9
Training loss: 1.6710039377212524
Validation loss: 2.0839110497505433

Epoch: 6| Step: 10
Training loss: 1.867092251777649
Validation loss: 2.0938429217184744

Epoch: 6| Step: 11
Training loss: 1.8522567749023438
Validation loss: 2.0813242543128228

Epoch: 6| Step: 12
Training loss: 1.4118809700012207
Validation loss: 2.0679440639352284

Epoch: 6| Step: 13
Training loss: 3.6670215129852295
Validation loss: 2.0394836818018267

Epoch: 125| Step: 0
Training loss: 1.4291629791259766
Validation loss: 2.0303628111398346

Epoch: 6| Step: 1
Training loss: 2.074171543121338
Validation loss: 2.003117033230361

Epoch: 6| Step: 2
Training loss: 1.8575129508972168
Validation loss: 1.9955252883254841

Epoch: 6| Step: 3
Training loss: 2.1174356937408447
Validation loss: 1.9901527204821188

Epoch: 6| Step: 4
Training loss: 2.2990803718566895
Validation loss: 1.999113432822689

Epoch: 6| Step: 5
Training loss: 2.557034969329834
Validation loss: 2.008370504584364

Epoch: 6| Step: 6
Training loss: 1.6795769929885864
Validation loss: 2.0194020258483065

Epoch: 6| Step: 7
Training loss: 1.7293933629989624
Validation loss: 2.0600778390002508

Epoch: 6| Step: 8
Training loss: 1.5404084920883179
Validation loss: 2.0929691073715047

Epoch: 6| Step: 9
Training loss: 1.7460873126983643
Validation loss: 2.0980261346345306

Epoch: 6| Step: 10
Training loss: 1.9004995822906494
Validation loss: 2.1147264588263726

Epoch: 6| Step: 11
Training loss: 2.534423351287842
Validation loss: 2.078488502451169

Epoch: 6| Step: 12
Training loss: 1.8197685480117798
Validation loss: 2.0752980709075928

Epoch: 6| Step: 13
Training loss: 2.221390962600708
Validation loss: 2.065466942325715

Epoch: 126| Step: 0
Training loss: 1.8096110820770264
Validation loss: 2.0252289913033925

Epoch: 6| Step: 1
Training loss: 1.5822514295578003
Validation loss: 2.0337069470395326

Epoch: 6| Step: 2
Training loss: 2.0887722969055176
Validation loss: 2.0143374922454997

Epoch: 6| Step: 3
Training loss: 1.9849343299865723
Validation loss: 2.0237074026497464

Epoch: 6| Step: 4
Training loss: 2.291222095489502
Validation loss: 2.0287444104430494

Epoch: 6| Step: 5
Training loss: 1.6632932424545288
Validation loss: 2.02720731817266

Epoch: 6| Step: 6
Training loss: 2.123063564300537
Validation loss: 2.028555352200744

Epoch: 6| Step: 7
Training loss: 1.4675378799438477
Validation loss: 2.0322584208621772

Epoch: 6| Step: 8
Training loss: 1.932783842086792
Validation loss: 2.0425271731550976

Epoch: 6| Step: 9
Training loss: 2.6373956203460693
Validation loss: 2.0550395365684264

Epoch: 6| Step: 10
Training loss: 2.0841739177703857
Validation loss: 2.083255793458672

Epoch: 6| Step: 11
Training loss: 1.8255960941314697
Validation loss: 2.0850959465067875

Epoch: 6| Step: 12
Training loss: 1.9541391134262085
Validation loss: 2.0827229612617084

Epoch: 6| Step: 13
Training loss: 1.1862698793411255
Validation loss: 2.1043252534763788

Epoch: 127| Step: 0
Training loss: 1.837854027748108
Validation loss: 2.1237336384352816

Epoch: 6| Step: 1
Training loss: 1.9712172746658325
Validation loss: 2.120619170127376

Epoch: 6| Step: 2
Training loss: 2.011096477508545
Validation loss: 2.095257254057033

Epoch: 6| Step: 3
Training loss: 2.2391772270202637
Validation loss: 2.098012916503414

Epoch: 6| Step: 4
Training loss: 2.9274587631225586
Validation loss: 2.060941373148272

Epoch: 6| Step: 5
Training loss: 1.8655896186828613
Validation loss: 2.044849959752893

Epoch: 6| Step: 6
Training loss: 1.8297574520111084
Validation loss: 2.0166488001423497

Epoch: 6| Step: 7
Training loss: 1.7227685451507568
Validation loss: 2.0142951306476387

Epoch: 6| Step: 8
Training loss: 2.25455379486084
Validation loss: 2.0115704485165176

Epoch: 6| Step: 9
Training loss: 1.8954403400421143
Validation loss: 1.9915042397796467

Epoch: 6| Step: 10
Training loss: 2.087789297103882
Validation loss: 1.992827029638393

Epoch: 6| Step: 11
Training loss: 1.6292657852172852
Validation loss: 1.9876158519457745

Epoch: 6| Step: 12
Training loss: 1.404210090637207
Validation loss: 2.006569130446321

Epoch: 6| Step: 13
Training loss: 0.6325126886367798
Validation loss: 2.042161836419054

Epoch: 128| Step: 0
Training loss: 2.005514144897461
Validation loss: 2.0718959057202904

Epoch: 6| Step: 1
Training loss: 1.6867471933364868
Validation loss: 2.1070757501868793

Epoch: 6| Step: 2
Training loss: 2.369429588317871
Validation loss: 2.1266198030082126

Epoch: 6| Step: 3
Training loss: 2.1254258155822754
Validation loss: 2.1153122455843034

Epoch: 6| Step: 4
Training loss: 1.0748404264450073
Validation loss: 2.1218160813854587

Epoch: 6| Step: 5
Training loss: 1.5111336708068848
Validation loss: 2.11956871709516

Epoch: 6| Step: 6
Training loss: 2.645817518234253
Validation loss: 2.101115006272511

Epoch: 6| Step: 7
Training loss: 1.5615553855895996
Validation loss: 2.12049529885733

Epoch: 6| Step: 8
Training loss: 1.4344037771224976
Validation loss: 2.128844076587308

Epoch: 6| Step: 9
Training loss: 2.215451717376709
Validation loss: 2.121735603578629

Epoch: 6| Step: 10
Training loss: 1.9596558809280396
Validation loss: 2.1188476982937066

Epoch: 6| Step: 11
Training loss: 1.791162371635437
Validation loss: 2.0978038413550264

Epoch: 6| Step: 12
Training loss: 1.7391037940979004
Validation loss: 2.0758196564130884

Epoch: 6| Step: 13
Training loss: 2.968040704727173
Validation loss: 2.055432960551272

Epoch: 129| Step: 0
Training loss: 1.3465080261230469
Validation loss: 2.0395473293078843

Epoch: 6| Step: 1
Training loss: 1.7821602821350098
Validation loss: 2.0164839644585886

Epoch: 6| Step: 2
Training loss: 2.2430410385131836
Validation loss: 2.00946649941065

Epoch: 6| Step: 3
Training loss: 1.666435956954956
Validation loss: 1.9836141883686025

Epoch: 6| Step: 4
Training loss: 1.8848955631256104
Validation loss: 1.9816815007117488

Epoch: 6| Step: 5
Training loss: 1.8717271089553833
Validation loss: 1.9864282326031757

Epoch: 6| Step: 6
Training loss: 2.0833749771118164
Validation loss: 2.011135689673885

Epoch: 6| Step: 7
Training loss: 2.092313051223755
Validation loss: 2.0437131684313536

Epoch: 6| Step: 8
Training loss: 1.2149608135223389
Validation loss: 2.0588803573321273

Epoch: 6| Step: 9
Training loss: 1.7351183891296387
Validation loss: 2.074358412014541

Epoch: 6| Step: 10
Training loss: 2.446725606918335
Validation loss: 2.083491881688436

Epoch: 6| Step: 11
Training loss: 2.0017611980438232
Validation loss: 2.1094544267141693

Epoch: 6| Step: 12
Training loss: 2.635232925415039
Validation loss: 2.1137804985046387

Epoch: 6| Step: 13
Training loss: 1.1430212259292603
Validation loss: 2.1092729324935586

Epoch: 130| Step: 0
Training loss: 1.7104088068008423
Validation loss: 2.087344761817686

Epoch: 6| Step: 1
Training loss: 1.5413905382156372
Validation loss: 2.055236852297219

Epoch: 6| Step: 2
Training loss: 1.5215222835540771
Validation loss: 2.0473320227797314

Epoch: 6| Step: 3
Training loss: 2.0762674808502197
Validation loss: 2.0142783118832495

Epoch: 6| Step: 4
Training loss: 1.639390468597412
Validation loss: 2.0349762491000596

Epoch: 6| Step: 5
Training loss: 2.1999897956848145
Validation loss: 2.0317448262245423

Epoch: 6| Step: 6
Training loss: 2.403409957885742
Validation loss: 2.028798169987176

Epoch: 6| Step: 7
Training loss: 2.230997085571289
Validation loss: 2.0519345857763804

Epoch: 6| Step: 8
Training loss: 1.394355058670044
Validation loss: 2.088191077273379

Epoch: 6| Step: 9
Training loss: 1.2840155363082886
Validation loss: 2.107953566376881

Epoch: 6| Step: 10
Training loss: 1.8910698890686035
Validation loss: 2.1392056172893894

Epoch: 6| Step: 11
Training loss: 1.9983906745910645
Validation loss: 2.093959249475951

Epoch: 6| Step: 12
Training loss: 2.6484856605529785
Validation loss: 2.054528651698943

Epoch: 6| Step: 13
Training loss: 1.3347657918930054
Validation loss: 2.0439853796394925

Epoch: 131| Step: 0
Training loss: 2.166243553161621
Validation loss: 2.0198704311924596

Epoch: 6| Step: 1
Training loss: 1.8660454750061035
Validation loss: 2.0221023046842186

Epoch: 6| Step: 2
Training loss: 2.064042806625366
Validation loss: 2.030874939375026

Epoch: 6| Step: 3
Training loss: 2.009525775909424
Validation loss: 2.0119054702020462

Epoch: 6| Step: 4
Training loss: 2.0978641510009766
Validation loss: 2.020115916446973

Epoch: 6| Step: 5
Training loss: 1.5686469078063965
Validation loss: 2.021347920099894

Epoch: 6| Step: 6
Training loss: 1.4824838638305664
Validation loss: 2.0262597145572787

Epoch: 6| Step: 7
Training loss: 2.577456474304199
Validation loss: 2.0625149562794673

Epoch: 6| Step: 8
Training loss: 2.007715940475464
Validation loss: 2.055437857745796

Epoch: 6| Step: 9
Training loss: 2.0892791748046875
Validation loss: 2.0502296852809128

Epoch: 6| Step: 10
Training loss: 1.6418653726577759
Validation loss: 2.06717881079643

Epoch: 6| Step: 11
Training loss: 1.3009834289550781
Validation loss: 2.0742047166311615

Epoch: 6| Step: 12
Training loss: 1.6788047552108765
Validation loss: 2.072958257890517

Epoch: 6| Step: 13
Training loss: 1.2450990676879883
Validation loss: 2.066036948593714

Epoch: 132| Step: 0
Training loss: 2.5890326499938965
Validation loss: 2.067858390910651

Epoch: 6| Step: 1
Training loss: 1.5282137393951416
Validation loss: 2.0926591606550318

Epoch: 6| Step: 2
Training loss: 1.8897862434387207
Validation loss: 2.0750590242365354

Epoch: 6| Step: 3
Training loss: 1.9575291872024536
Validation loss: 2.0565443628577778

Epoch: 6| Step: 4
Training loss: 2.1224207878112793
Validation loss: 2.047826054275677

Epoch: 6| Step: 5
Training loss: 1.752866268157959
Validation loss: 2.080419760878368

Epoch: 6| Step: 6
Training loss: 2.1646642684936523
Validation loss: 2.079088226441414

Epoch: 6| Step: 7
Training loss: 1.5262680053710938
Validation loss: 2.1061435925063265

Epoch: 6| Step: 8
Training loss: 1.624403476715088
Validation loss: 2.129238227362274

Epoch: 6| Step: 9
Training loss: 1.7841596603393555
Validation loss: 2.075490302937005

Epoch: 6| Step: 10
Training loss: 1.5247423648834229
Validation loss: 2.044866397816648

Epoch: 6| Step: 11
Training loss: 1.9433598518371582
Validation loss: 2.032024234853765

Epoch: 6| Step: 12
Training loss: 2.331266164779663
Validation loss: 2.0142852170493013

Epoch: 6| Step: 13
Training loss: 1.6301941871643066
Validation loss: 2.0049248203154533

Epoch: 133| Step: 0
Training loss: 1.9881014823913574
Validation loss: 2.008805005781112

Epoch: 6| Step: 1
Training loss: 2.0558595657348633
Validation loss: 1.9945129143294467

Epoch: 6| Step: 2
Training loss: 1.9539375305175781
Validation loss: 1.9923613161169074

Epoch: 6| Step: 3
Training loss: 2.005098581314087
Validation loss: 2.005553845436342

Epoch: 6| Step: 4
Training loss: 1.8707330226898193
Validation loss: 2.0154825846354165

Epoch: 6| Step: 5
Training loss: 1.572859764099121
Validation loss: 2.024310596527592

Epoch: 6| Step: 6
Training loss: 1.2104032039642334
Validation loss: 2.0423200925191245

Epoch: 6| Step: 7
Training loss: 1.7828357219696045
Validation loss: 2.0557377364045832

Epoch: 6| Step: 8
Training loss: 2.146935224533081
Validation loss: 2.0465042962822864

Epoch: 6| Step: 9
Training loss: 1.1768077611923218
Validation loss: 2.0549645731526036

Epoch: 6| Step: 10
Training loss: 2.1439361572265625
Validation loss: 2.0339087875940467

Epoch: 6| Step: 11
Training loss: 2.023688316345215
Validation loss: 2.014624385423558

Epoch: 6| Step: 12
Training loss: 1.6013786792755127
Validation loss: 2.0275499000344226

Epoch: 6| Step: 13
Training loss: 1.8827239274978638
Validation loss: 2.0180055825941023

Epoch: 134| Step: 0
Training loss: 2.2120914459228516
Validation loss: 2.0269953768740416

Epoch: 6| Step: 1
Training loss: 1.8804383277893066
Validation loss: 2.0317528376015286

Epoch: 6| Step: 2
Training loss: 1.3880717754364014
Validation loss: 2.0447446684683523

Epoch: 6| Step: 3
Training loss: 2.1683216094970703
Validation loss: 2.03853283005376

Epoch: 6| Step: 4
Training loss: 1.610515832901001
Validation loss: 2.05160713964893

Epoch: 6| Step: 5
Training loss: 1.8977067470550537
Validation loss: 2.0679639590683805

Epoch: 6| Step: 6
Training loss: 0.9152828454971313
Validation loss: 2.088397891290726

Epoch: 6| Step: 7
Training loss: 2.5152621269226074
Validation loss: 2.089272270920456

Epoch: 6| Step: 8
Training loss: 1.7400248050689697
Validation loss: 2.0958079727747108

Epoch: 6| Step: 9
Training loss: 1.9197214841842651
Validation loss: 2.0892007453467256

Epoch: 6| Step: 10
Training loss: 1.8892786502838135
Validation loss: 2.071947140078391

Epoch: 6| Step: 11
Training loss: 1.4754369258880615
Validation loss: 2.0717965402910785

Epoch: 6| Step: 12
Training loss: 1.610265851020813
Validation loss: 2.0458119043739895

Epoch: 6| Step: 13
Training loss: 2.1000027656555176
Validation loss: 2.0462916256279073

Epoch: 135| Step: 0
Training loss: 0.8952107429504395
Validation loss: 2.0331152690354215

Epoch: 6| Step: 1
Training loss: 2.1816823482513428
Validation loss: 2.03134947951122

Epoch: 6| Step: 2
Training loss: 1.2844452857971191
Validation loss: 2.0186059936400382

Epoch: 6| Step: 3
Training loss: 1.631404995918274
Validation loss: 2.035583629403063

Epoch: 6| Step: 4
Training loss: 1.8498127460479736
Validation loss: 2.068730474800192

Epoch: 6| Step: 5
Training loss: 1.3851573467254639
Validation loss: 2.077901815855375

Epoch: 6| Step: 6
Training loss: 1.4871747493743896
Validation loss: 2.088634944731189

Epoch: 6| Step: 7
Training loss: 2.6645355224609375
Validation loss: 2.097113673404981

Epoch: 6| Step: 8
Training loss: 1.3135944604873657
Validation loss: 2.09639803055794

Epoch: 6| Step: 9
Training loss: 1.7086975574493408
Validation loss: 2.1101303459495626

Epoch: 6| Step: 10
Training loss: 1.9125531911849976
Validation loss: 2.110325353119963

Epoch: 6| Step: 11
Training loss: 2.500601291656494
Validation loss: 2.095898123197658

Epoch: 6| Step: 12
Training loss: 2.2636022567749023
Validation loss: 2.076015580085016

Epoch: 6| Step: 13
Training loss: 1.6449720859527588
Validation loss: 2.071335889959848

Epoch: 136| Step: 0
Training loss: 1.0490731000900269
Validation loss: 2.0392258961995444

Epoch: 6| Step: 1
Training loss: 1.6201741695404053
Validation loss: 2.048533844691451

Epoch: 6| Step: 2
Training loss: 1.6119807958602905
Validation loss: 2.057273277672388

Epoch: 6| Step: 3
Training loss: 1.9303354024887085
Validation loss: 2.082994835351103

Epoch: 6| Step: 4
Training loss: 1.7699923515319824
Validation loss: 2.080703277741709

Epoch: 6| Step: 5
Training loss: 2.151144504547119
Validation loss: 2.067323682128742

Epoch: 6| Step: 6
Training loss: 1.323791265487671
Validation loss: 2.099642224209283

Epoch: 6| Step: 7
Training loss: 2.331943988800049
Validation loss: 2.0967845686020388

Epoch: 6| Step: 8
Training loss: 1.821398377418518
Validation loss: 2.1308042951809463

Epoch: 6| Step: 9
Training loss: 2.2976574897766113
Validation loss: 2.1378169777572795

Epoch: 6| Step: 10
Training loss: 1.5119972229003906
Validation loss: 2.1790016364025813

Epoch: 6| Step: 11
Training loss: 2.182814598083496
Validation loss: 2.223211339724961

Epoch: 6| Step: 12
Training loss: 1.1109936237335205
Validation loss: 2.182726393463791

Epoch: 6| Step: 13
Training loss: 1.7296701669692993
Validation loss: 2.1522099664134364

Epoch: 137| Step: 0
Training loss: 1.2370707988739014
Validation loss: 2.147247729762908

Epoch: 6| Step: 1
Training loss: 2.032982349395752
Validation loss: 2.1266782411964993

Epoch: 6| Step: 2
Training loss: 1.6650986671447754
Validation loss: 2.127483093610374

Epoch: 6| Step: 3
Training loss: 1.3595468997955322
Validation loss: 2.1074522772142963

Epoch: 6| Step: 4
Training loss: 1.8222488164901733
Validation loss: 2.090508048252393

Epoch: 6| Step: 5
Training loss: 1.9854832887649536
Validation loss: 2.1077752933707288

Epoch: 6| Step: 6
Training loss: 1.7808185815811157
Validation loss: 2.1002634417626167

Epoch: 6| Step: 7
Training loss: 1.6849608421325684
Validation loss: 2.122041533070226

Epoch: 6| Step: 8
Training loss: 2.567957878112793
Validation loss: 2.118420285563315

Epoch: 6| Step: 9
Training loss: 1.5457009077072144
Validation loss: 2.1406835843158025

Epoch: 6| Step: 10
Training loss: 1.813008189201355
Validation loss: 2.162272076452932

Epoch: 6| Step: 11
Training loss: 1.3916468620300293
Validation loss: 2.1811342726471605

Epoch: 6| Step: 12
Training loss: 1.8897202014923096
Validation loss: 2.18796101180456

Epoch: 6| Step: 13
Training loss: 1.3866667747497559
Validation loss: 2.1801570410369546

Epoch: 138| Step: 0
Training loss: 1.7148845195770264
Validation loss: 2.164956477380568

Epoch: 6| Step: 1
Training loss: 2.1441149711608887
Validation loss: 2.1341103161534956

Epoch: 6| Step: 2
Training loss: 1.1301400661468506
Validation loss: 2.114390883394467

Epoch: 6| Step: 3
Training loss: 0.9880454540252686
Validation loss: 2.1067939599355063

Epoch: 6| Step: 4
Training loss: 1.1342072486877441
Validation loss: 2.0641006885036344

Epoch: 6| Step: 5
Training loss: 1.6017341613769531
Validation loss: 2.061564134013268

Epoch: 6| Step: 6
Training loss: 2.3891022205352783
Validation loss: 2.0501935597388976

Epoch: 6| Step: 7
Training loss: 1.7444360256195068
Validation loss: 2.05980517530954

Epoch: 6| Step: 8
Training loss: 1.6950089931488037
Validation loss: 2.0616442362467446

Epoch: 6| Step: 9
Training loss: 2.0205254554748535
Validation loss: 2.045841601587111

Epoch: 6| Step: 10
Training loss: 1.8890140056610107
Validation loss: 2.052846330468373

Epoch: 6| Step: 11
Training loss: 2.335907459259033
Validation loss: 2.0563680254003054

Epoch: 6| Step: 12
Training loss: 1.6042505502700806
Validation loss: 2.0586823032748316

Epoch: 6| Step: 13
Training loss: 1.6753336191177368
Validation loss: 2.0841487171829387

Epoch: 139| Step: 0
Training loss: 1.599931240081787
Validation loss: 2.087271854441653

Epoch: 6| Step: 1
Training loss: 1.5478525161743164
Validation loss: 2.113168890758227

Epoch: 6| Step: 2
Training loss: 1.010487675666809
Validation loss: 2.107049060124223

Epoch: 6| Step: 3
Training loss: 2.1791634559631348
Validation loss: 2.1231164368250037

Epoch: 6| Step: 4
Training loss: 1.6479804515838623
Validation loss: 2.108031165215277

Epoch: 6| Step: 5
Training loss: 1.9620330333709717
Validation loss: 2.0837814577164187

Epoch: 6| Step: 6
Training loss: 1.733269453048706
Validation loss: 2.0917116954762447

Epoch: 6| Step: 7
Training loss: 1.1881486177444458
Validation loss: 2.083283265431722

Epoch: 6| Step: 8
Training loss: 1.922494888305664
Validation loss: 2.0966132635711343

Epoch: 6| Step: 9
Training loss: 1.7262451648712158
Validation loss: 2.139089627932477

Epoch: 6| Step: 10
Training loss: 2.0208942890167236
Validation loss: 2.147368723346341

Epoch: 6| Step: 11
Training loss: 1.629402756690979
Validation loss: 2.1686941474996586

Epoch: 6| Step: 12
Training loss: 1.7729740142822266
Validation loss: 2.166971757847776

Epoch: 6| Step: 13
Training loss: 1.1423237323760986
Validation loss: 2.162130637835431

Epoch: 140| Step: 0
Training loss: 1.6240177154541016
Validation loss: 2.14951479306785

Epoch: 6| Step: 1
Training loss: 1.2296711206436157
Validation loss: 2.125894695199946

Epoch: 6| Step: 2
Training loss: 1.585132360458374
Validation loss: 2.0964047293509207

Epoch: 6| Step: 3
Training loss: 1.5878194570541382
Validation loss: 2.060723594439927

Epoch: 6| Step: 4
Training loss: 1.8607804775238037
Validation loss: 2.056581874047556

Epoch: 6| Step: 5
Training loss: 1.4929697513580322
Validation loss: 2.0470837316205426

Epoch: 6| Step: 6
Training loss: 2.0147788524627686
Validation loss: 2.0546771826282626

Epoch: 6| Step: 7
Training loss: 0.9222053289413452
Validation loss: 2.0599387243229854

Epoch: 6| Step: 8
Training loss: 2.314512014389038
Validation loss: 2.0634117152101252

Epoch: 6| Step: 9
Training loss: 1.5722415447235107
Validation loss: 2.0685665774089035

Epoch: 6| Step: 10
Training loss: 1.4621260166168213
Validation loss: 2.0780524246154295

Epoch: 6| Step: 11
Training loss: 1.439871907234192
Validation loss: 2.0995935470827165

Epoch: 6| Step: 12
Training loss: 2.325894594192505
Validation loss: 2.0990421259275047

Epoch: 6| Step: 13
Training loss: 2.0717508792877197
Validation loss: 2.1105131167237476

Epoch: 141| Step: 0
Training loss: 1.2269023656845093
Validation loss: 2.1067318019046577

Epoch: 6| Step: 1
Training loss: 2.3401098251342773
Validation loss: 2.11545608633308

Epoch: 6| Step: 2
Training loss: 1.3530783653259277
Validation loss: 2.1324000922582482

Epoch: 6| Step: 3
Training loss: 0.9122156500816345
Validation loss: 2.1637453776533886

Epoch: 6| Step: 4
Training loss: 1.1313774585723877
Validation loss: 2.1839722612852692

Epoch: 6| Step: 5
Training loss: 2.4704418182373047
Validation loss: 2.170302144942745

Epoch: 6| Step: 6
Training loss: 1.589261770248413
Validation loss: 2.1874154754864272

Epoch: 6| Step: 7
Training loss: 2.1101555824279785
Validation loss: 2.1774833535635345

Epoch: 6| Step: 8
Training loss: 2.068563222885132
Validation loss: 2.172528853980444

Epoch: 6| Step: 9
Training loss: 1.351202130317688
Validation loss: 2.1926175112365396

Epoch: 6| Step: 10
Training loss: 1.9491839408874512
Validation loss: 2.164182445054413

Epoch: 6| Step: 11
Training loss: 1.4176639318466187
Validation loss: 2.132928858521164

Epoch: 6| Step: 12
Training loss: 1.4735190868377686
Validation loss: 2.1395025637841996

Epoch: 6| Step: 13
Training loss: 1.4450907707214355
Validation loss: 2.11512134152074

Epoch: 142| Step: 0
Training loss: 1.8057810068130493
Validation loss: 2.1010754749339116

Epoch: 6| Step: 1
Training loss: 1.800208330154419
Validation loss: 2.0905835679782334

Epoch: 6| Step: 2
Training loss: 1.814495325088501
Validation loss: 2.093060608833067

Epoch: 6| Step: 3
Training loss: 1.7748022079467773
Validation loss: 2.068110017366307

Epoch: 6| Step: 4
Training loss: 1.1445351839065552
Validation loss: 2.0605289961702082

Epoch: 6| Step: 5
Training loss: 1.5129003524780273
Validation loss: 2.0635314897824357

Epoch: 6| Step: 6
Training loss: 1.2342967987060547
Validation loss: 2.0583179612313547

Epoch: 6| Step: 7
Training loss: 1.7274439334869385
Validation loss: 2.064122966540757

Epoch: 6| Step: 8
Training loss: 1.9419260025024414
Validation loss: 2.0596296389897666

Epoch: 6| Step: 9
Training loss: 1.3577090501785278
Validation loss: 2.0697400057187645

Epoch: 6| Step: 10
Training loss: 0.988855242729187
Validation loss: 2.0749558684646443

Epoch: 6| Step: 11
Training loss: 2.1439740657806396
Validation loss: 2.070095254528907

Epoch: 6| Step: 12
Training loss: 1.5890650749206543
Validation loss: 2.1049269424971713

Epoch: 6| Step: 13
Training loss: 1.7704682350158691
Validation loss: 2.0948319537665254

Epoch: 143| Step: 0
Training loss: 0.6406458020210266
Validation loss: 2.1208789758784796

Epoch: 6| Step: 1
Training loss: 1.9649794101715088
Validation loss: 2.1282346838264057

Epoch: 6| Step: 2
Training loss: 1.5010097026824951
Validation loss: 2.1458939941980506

Epoch: 6| Step: 3
Training loss: 2.4870240688323975
Validation loss: 2.182826695903655

Epoch: 6| Step: 4
Training loss: 1.0038118362426758
Validation loss: 2.171287263593366

Epoch: 6| Step: 5
Training loss: 1.7619596719741821
Validation loss: 2.136810028424827

Epoch: 6| Step: 6
Training loss: 1.3069984912872314
Validation loss: 2.121661406691356

Epoch: 6| Step: 7
Training loss: 2.198676824569702
Validation loss: 2.124940379973381

Epoch: 6| Step: 8
Training loss: 1.8556030988693237
Validation loss: 2.1055368454225603

Epoch: 6| Step: 9
Training loss: 2.282534122467041
Validation loss: 2.098277904654062

Epoch: 6| Step: 10
Training loss: 1.4937703609466553
Validation loss: 2.1146035245669785

Epoch: 6| Step: 11
Training loss: 1.2906746864318848
Validation loss: 2.1344772846468034

Epoch: 6| Step: 12
Training loss: 1.6987762451171875
Validation loss: 2.1111210161639797

Epoch: 6| Step: 13
Training loss: 0.7842668294906616
Validation loss: 2.1276282623249996

Epoch: 144| Step: 0
Training loss: 1.5463652610778809
Validation loss: 2.147553200362831

Epoch: 6| Step: 1
Training loss: 1.0449213981628418
Validation loss: 2.1627451386502994

Epoch: 6| Step: 2
Training loss: 1.5454689264297485
Validation loss: 2.21182418382296

Epoch: 6| Step: 3
Training loss: 1.8776005506515503
Validation loss: 2.1875679185313563

Epoch: 6| Step: 4
Training loss: 1.9479789733886719
Validation loss: 2.143726525768157

Epoch: 6| Step: 5
Training loss: 0.9599834680557251
Validation loss: 2.125786877447559

Epoch: 6| Step: 6
Training loss: 2.046396493911743
Validation loss: 2.091310954863025

Epoch: 6| Step: 7
Training loss: 1.255624771118164
Validation loss: 2.0816600720087686

Epoch: 6| Step: 8
Training loss: 1.766248106956482
Validation loss: 2.0764473253680813

Epoch: 6| Step: 9
Training loss: 1.7151103019714355
Validation loss: 2.0655546239627305

Epoch: 6| Step: 10
Training loss: 2.3045129776000977
Validation loss: 2.091889524972567

Epoch: 6| Step: 11
Training loss: 1.2329148054122925
Validation loss: 2.090773291485284

Epoch: 6| Step: 12
Training loss: 1.9157617092132568
Validation loss: 2.0860948216530586

Epoch: 6| Step: 13
Training loss: 1.8921018838882446
Validation loss: 2.1037761767705283

Epoch: 145| Step: 0
Training loss: 2.0293426513671875
Validation loss: 2.1209370167024675

Epoch: 6| Step: 1
Training loss: 1.4367787837982178
Validation loss: 2.1322248571662494

Epoch: 6| Step: 2
Training loss: 2.071869373321533
Validation loss: 2.14725302368082

Epoch: 6| Step: 3
Training loss: 1.7680842876434326
Validation loss: 2.169284180928302

Epoch: 6| Step: 4
Training loss: 2.1228530406951904
Validation loss: 2.1791622600247784

Epoch: 6| Step: 5
Training loss: 1.0603477954864502
Validation loss: 2.1873508678969515

Epoch: 6| Step: 6
Training loss: 1.7118778228759766
Validation loss: 2.165052144758163

Epoch: 6| Step: 7
Training loss: 0.7881423234939575
Validation loss: 2.1301750982961347

Epoch: 6| Step: 8
Training loss: 1.553297519683838
Validation loss: 2.138291617875458

Epoch: 6| Step: 9
Training loss: 1.899291753768921
Validation loss: 2.106556929567809

Epoch: 6| Step: 10
Training loss: 0.8331332206726074
Validation loss: 2.0852038475774948

Epoch: 6| Step: 11
Training loss: 1.7606924772262573
Validation loss: 2.076304558784731

Epoch: 6| Step: 12
Training loss: 1.4802138805389404
Validation loss: 2.079747648649318

Epoch: 6| Step: 13
Training loss: 1.9352480173110962
Validation loss: 2.069915143392419

Epoch: 146| Step: 0
Training loss: 2.1008787155151367
Validation loss: 2.067052771968226

Epoch: 6| Step: 1
Training loss: 1.6039316654205322
Validation loss: 2.054090602423555

Epoch: 6| Step: 2
Training loss: 2.0446972846984863
Validation loss: 2.058189897127049

Epoch: 6| Step: 3
Training loss: 0.9548207521438599
Validation loss: 2.0690424057745163

Epoch: 6| Step: 4
Training loss: 1.425682544708252
Validation loss: 2.074559009203347

Epoch: 6| Step: 5
Training loss: 2.07086443901062
Validation loss: 2.0569601571688088

Epoch: 6| Step: 6
Training loss: 1.4306855201721191
Validation loss: 2.0892568660038773

Epoch: 6| Step: 7
Training loss: 1.299691915512085
Validation loss: 2.1040244461387716

Epoch: 6| Step: 8
Training loss: 1.6394495964050293
Validation loss: 2.1277189895670903

Epoch: 6| Step: 9
Training loss: 1.7423127889633179
Validation loss: 2.1411240305951846

Epoch: 6| Step: 10
Training loss: 1.4654139280319214
Validation loss: 2.147599817604147

Epoch: 6| Step: 11
Training loss: 1.3960516452789307
Validation loss: 2.139369801808429

Epoch: 6| Step: 12
Training loss: 1.4332082271575928
Validation loss: 2.135150750478109

Epoch: 6| Step: 13
Training loss: 1.66141939163208
Validation loss: 2.105261787291496

Epoch: 147| Step: 0
Training loss: 1.1983487606048584
Validation loss: 2.082253320242769

Epoch: 6| Step: 1
Training loss: 1.5675749778747559
Validation loss: 2.0827496718334895

Epoch: 6| Step: 2
Training loss: 2.0248050689697266
Validation loss: 2.0927135175274265

Epoch: 6| Step: 3
Training loss: 1.1542316675186157
Validation loss: 2.1153357644234934

Epoch: 6| Step: 4
Training loss: 2.2982659339904785
Validation loss: 2.114612753673266

Epoch: 6| Step: 5
Training loss: 1.808661937713623
Validation loss: 2.119555104163385

Epoch: 6| Step: 6
Training loss: 1.285170078277588
Validation loss: 2.1134922863334737

Epoch: 6| Step: 7
Training loss: 2.290648937225342
Validation loss: 2.122939162356879

Epoch: 6| Step: 8
Training loss: 1.2548637390136719
Validation loss: 2.111293936288485

Epoch: 6| Step: 9
Training loss: 1.364530086517334
Validation loss: 2.107547608754968

Epoch: 6| Step: 10
Training loss: 1.143431305885315
Validation loss: 2.1177374662891513

Epoch: 6| Step: 11
Training loss: 1.4211465120315552
Validation loss: 2.131199780330863

Epoch: 6| Step: 12
Training loss: 1.2545264959335327
Validation loss: 2.178443060126356

Epoch: 6| Step: 13
Training loss: 1.672609806060791
Validation loss: 2.1984652037261636

Epoch: 148| Step: 0
Training loss: 1.1483696699142456
Validation loss: 2.213103676355013

Epoch: 6| Step: 1
Training loss: 1.4934310913085938
Validation loss: 2.222350658908967

Epoch: 6| Step: 2
Training loss: 1.4701884984970093
Validation loss: 2.154277302885568

Epoch: 6| Step: 3
Training loss: 0.92545086145401
Validation loss: 2.1607363198393132

Epoch: 6| Step: 4
Training loss: 1.8095768690109253
Validation loss: 2.1444433325080463

Epoch: 6| Step: 5
Training loss: 1.0914448499679565
Validation loss: 2.127247970591309

Epoch: 6| Step: 6
Training loss: 1.5901415348052979
Validation loss: 2.0905386440215574

Epoch: 6| Step: 7
Training loss: 1.8776681423187256
Validation loss: 2.10559598348474

Epoch: 6| Step: 8
Training loss: 1.090139389038086
Validation loss: 2.1238077391860304

Epoch: 6| Step: 9
Training loss: 2.6265954971313477
Validation loss: 2.1192534790244153

Epoch: 6| Step: 10
Training loss: 1.7520356178283691
Validation loss: 2.1248315688102477

Epoch: 6| Step: 11
Training loss: 1.142146348953247
Validation loss: 2.1342685273898545

Epoch: 6| Step: 12
Training loss: 1.7771525382995605
Validation loss: 2.1175564078874487

Epoch: 6| Step: 13
Training loss: 1.6427253484725952
Validation loss: 2.1049887288001274

Epoch: 149| Step: 0
Training loss: 1.6991865634918213
Validation loss: 2.105193461141279

Epoch: 6| Step: 1
Training loss: 1.8849424123764038
Validation loss: 2.1157944792060444

Epoch: 6| Step: 2
Training loss: 1.7277032136917114
Validation loss: 2.0954558592970653

Epoch: 6| Step: 3
Training loss: 1.4611271619796753
Validation loss: 2.0854952694267355

Epoch: 6| Step: 4
Training loss: 1.916014313697815
Validation loss: 2.073265890921316

Epoch: 6| Step: 5
Training loss: 1.8369075059890747
Validation loss: 2.0736297048548216

Epoch: 6| Step: 6
Training loss: 1.3508434295654297
Validation loss: 2.0876483045598513

Epoch: 6| Step: 7
Training loss: 0.5867708921432495
Validation loss: 2.0746096564877416

Epoch: 6| Step: 8
Training loss: 1.4282033443450928
Validation loss: 2.0422766618831183

Epoch: 6| Step: 9
Training loss: 1.2573519945144653
Validation loss: 2.059401700573583

Epoch: 6| Step: 10
Training loss: 1.3591113090515137
Validation loss: 2.0619991056380735

Epoch: 6| Step: 11
Training loss: 1.3728113174438477
Validation loss: 2.0633321782594085

Epoch: 6| Step: 12
Training loss: 1.8210046291351318
Validation loss: 2.0791208077502508

Epoch: 6| Step: 13
Training loss: 1.4590903520584106
Validation loss: 2.065009319654075

Epoch: 150| Step: 0
Training loss: 0.8200104236602783
Validation loss: 2.0698013203118437

Epoch: 6| Step: 1
Training loss: 1.6215943098068237
Validation loss: 2.0814413178351616

Epoch: 6| Step: 2
Training loss: 1.0320227146148682
Validation loss: 2.086257110359848

Epoch: 6| Step: 3
Training loss: 1.8648473024368286
Validation loss: 2.1118041648659656

Epoch: 6| Step: 4
Training loss: 1.51273775100708
Validation loss: 2.1308684502878497

Epoch: 6| Step: 5
Training loss: 1.5066009759902954
Validation loss: 2.146694926805394

Epoch: 6| Step: 6
Training loss: 2.2515971660614014
Validation loss: 2.1667294194621425

Epoch: 6| Step: 7
Training loss: 2.098484992980957
Validation loss: 2.1737879117329917

Epoch: 6| Step: 8
Training loss: 2.244385242462158
Validation loss: 2.1904290235170754

Epoch: 6| Step: 9
Training loss: 1.1951578855514526
Validation loss: 2.1714775280285905

Epoch: 6| Step: 10
Training loss: 1.5946553945541382
Validation loss: 2.154542003908465

Epoch: 6| Step: 11
Training loss: 1.2318222522735596
Validation loss: 2.1158209923774964

Epoch: 6| Step: 12
Training loss: 0.9202888607978821
Validation loss: 2.0880713206465527

Epoch: 6| Step: 13
Training loss: 0.8851126432418823
Validation loss: 2.071337301244018

Epoch: 151| Step: 0
Training loss: 1.598803997039795
Validation loss: 2.0666633831557406

Epoch: 6| Step: 1
Training loss: 1.8078229427337646
Validation loss: 2.0496517176269204

Epoch: 6| Step: 2
Training loss: 1.5454970598220825
Validation loss: 2.0419612879394204

Epoch: 6| Step: 3
Training loss: 1.230677843093872
Validation loss: 2.0203237123386835

Epoch: 6| Step: 4
Training loss: 0.9316449165344238
Validation loss: 2.036559166446809

Epoch: 6| Step: 5
Training loss: 1.5621851682662964
Validation loss: 2.0237657895652195

Epoch: 6| Step: 6
Training loss: 1.4530147314071655
Validation loss: 2.052157691729966

Epoch: 6| Step: 7
Training loss: 1.9211418628692627
Validation loss: 2.097024740711335

Epoch: 6| Step: 8
Training loss: 1.4771363735198975
Validation loss: 2.1025152565330587

Epoch: 6| Step: 9
Training loss: 1.7427423000335693
Validation loss: 2.126264690071024

Epoch: 6| Step: 10
Training loss: 1.053372859954834
Validation loss: 2.1471980899892826

Epoch: 6| Step: 11
Training loss: 1.7823430299758911
Validation loss: 2.1819090048472085

Epoch: 6| Step: 12
Training loss: 1.7951455116271973
Validation loss: 2.2347798065472673

Epoch: 6| Step: 13
Training loss: 1.0558092594146729
Validation loss: 2.2830360320306595

Epoch: 152| Step: 0
Training loss: 1.5028809309005737
Validation loss: 2.2892440749752905

Epoch: 6| Step: 1
Training loss: 1.8627281188964844
Validation loss: 2.2809877395629883

Epoch: 6| Step: 2
Training loss: 1.2465603351593018
Validation loss: 2.2668715446226058

Epoch: 6| Step: 3
Training loss: 1.0623669624328613
Validation loss: 2.2460886329732914

Epoch: 6| Step: 4
Training loss: 1.9326649904251099
Validation loss: 2.239337034122918

Epoch: 6| Step: 5
Training loss: 1.9035282135009766
Validation loss: 2.224904206491286

Epoch: 6| Step: 6
Training loss: 1.8233978748321533
Validation loss: 2.1999158756707304

Epoch: 6| Step: 7
Training loss: 1.8911787271499634
Validation loss: 2.174197126460332

Epoch: 6| Step: 8
Training loss: 1.4240208864212036
Validation loss: 2.144092421377859

Epoch: 6| Step: 9
Training loss: 1.281276822090149
Validation loss: 2.137818133959206

Epoch: 6| Step: 10
Training loss: 0.6184004545211792
Validation loss: 2.125076268308906

Epoch: 6| Step: 11
Training loss: 1.087752342224121
Validation loss: 2.110757109939411

Epoch: 6| Step: 12
Training loss: 1.6511685848236084
Validation loss: 2.0973022086645967

Epoch: 6| Step: 13
Training loss: 1.4429972171783447
Validation loss: 2.095752344336561

Epoch: 153| Step: 0
Training loss: 1.5783966779708862
Validation loss: 2.0802370963558072

Epoch: 6| Step: 1
Training loss: 1.6417007446289062
Validation loss: 2.074032574571589

Epoch: 6| Step: 2
Training loss: 0.9715384244918823
Validation loss: 2.0661541479890064

Epoch: 6| Step: 3
Training loss: 1.1771492958068848
Validation loss: 2.056392623532203

Epoch: 6| Step: 4
Training loss: 2.357309579849243
Validation loss: 2.0729150092729958

Epoch: 6| Step: 5
Training loss: 1.6452419757843018
Validation loss: 2.0936598495770524

Epoch: 6| Step: 6
Training loss: 1.1490442752838135
Validation loss: 2.0806845465014057

Epoch: 6| Step: 7
Training loss: 1.5791594982147217
Validation loss: 2.0872370068744948

Epoch: 6| Step: 8
Training loss: 1.153738260269165
Validation loss: 2.0817394692410707

Epoch: 6| Step: 9
Training loss: 1.1149470806121826
Validation loss: 2.120911669987504

Epoch: 6| Step: 10
Training loss: 1.9595832824707031
Validation loss: 2.1270640537302983

Epoch: 6| Step: 11
Training loss: 1.5751519203186035
Validation loss: 2.1368050882893224

Epoch: 6| Step: 12
Training loss: 1.390647530555725
Validation loss: 2.144957906456404

Epoch: 6| Step: 13
Training loss: 0.964116096496582
Validation loss: 2.1309419050011584

Epoch: 154| Step: 0
Training loss: 1.9215731620788574
Validation loss: 2.1303153537934825

Epoch: 6| Step: 1
Training loss: 1.0747759342193604
Validation loss: 2.131424243732165

Epoch: 6| Step: 2
Training loss: 1.8298176527023315
Validation loss: 2.1217350011230796

Epoch: 6| Step: 3
Training loss: 1.495850682258606
Validation loss: 2.1527860369733585

Epoch: 6| Step: 4
Training loss: 1.3174668550491333
Validation loss: 2.163105862115019

Epoch: 6| Step: 5
Training loss: 1.8533989191055298
Validation loss: 2.139106268523842

Epoch: 6| Step: 6
Training loss: 1.7085908651351929
Validation loss: 2.1373842582907727

Epoch: 6| Step: 7
Training loss: 1.1337411403656006
Validation loss: 2.1281768916755595

Epoch: 6| Step: 8
Training loss: 1.6201086044311523
Validation loss: 2.1219753655054236

Epoch: 6| Step: 9
Training loss: 0.93921959400177
Validation loss: 2.121812346161053

Epoch: 6| Step: 10
Training loss: 1.4491524696350098
Validation loss: 2.1244880896742626

Epoch: 6| Step: 11
Training loss: 0.9471732974052429
Validation loss: 2.1446966278937554

Epoch: 6| Step: 12
Training loss: 2.2184934616088867
Validation loss: 2.1518467241717922

Epoch: 6| Step: 13
Training loss: 0.5855875015258789
Validation loss: 2.164984454390823

Epoch: 155| Step: 0
Training loss: 1.155188798904419
Validation loss: 2.1677150880136797

Epoch: 6| Step: 1
Training loss: 1.8368704319000244
Validation loss: 2.1486736882117485

Epoch: 6| Step: 2
Training loss: 1.3549121618270874
Validation loss: 2.1443010248163694

Epoch: 6| Step: 3
Training loss: 1.462742805480957
Validation loss: 2.1176333132610528

Epoch: 6| Step: 4
Training loss: 1.7331832647323608
Validation loss: 2.1083764799179567

Epoch: 6| Step: 5
Training loss: 0.94708251953125
Validation loss: 2.065390384325417

Epoch: 6| Step: 6
Training loss: 1.2298462390899658
Validation loss: 2.0733753724764754

Epoch: 6| Step: 7
Training loss: 1.4968228340148926
Validation loss: 2.066677426779142

Epoch: 6| Step: 8
Training loss: 1.4766950607299805
Validation loss: 2.0719949212125552

Epoch: 6| Step: 9
Training loss: 1.770556926727295
Validation loss: 2.087100536592545

Epoch: 6| Step: 10
Training loss: 1.3235547542572021
Validation loss: 2.1156524176238687

Epoch: 6| Step: 11
Training loss: 1.775648593902588
Validation loss: 2.105036617607199

Epoch: 6| Step: 12
Training loss: 1.4154011011123657
Validation loss: 2.114310300478371

Epoch: 6| Step: 13
Training loss: 1.385295033454895
Validation loss: 2.1149017939003567

Epoch: 156| Step: 0
Training loss: 1.6558868885040283
Validation loss: 2.126986425410035

Epoch: 6| Step: 1
Training loss: 1.1851019859313965
Validation loss: 2.1196508407592773

Epoch: 6| Step: 2
Training loss: 1.879547119140625
Validation loss: 2.106018602207143

Epoch: 6| Step: 3
Training loss: 1.8304831981658936
Validation loss: 2.1080031830777406

Epoch: 6| Step: 4
Training loss: 1.4180214405059814
Validation loss: 2.105208461002637

Epoch: 6| Step: 5
Training loss: 1.6630761623382568
Validation loss: 2.0720590186375443

Epoch: 6| Step: 6
Training loss: 1.6034739017486572
Validation loss: 2.0581512169171403

Epoch: 6| Step: 7
Training loss: 1.8004648685455322
Validation loss: 2.054888625298777

Epoch: 6| Step: 8
Training loss: 0.7493773698806763
Validation loss: 2.0251947051735333

Epoch: 6| Step: 9
Training loss: 1.6503660678863525
Validation loss: 2.0476843823668776

Epoch: 6| Step: 10
Training loss: 1.4758245944976807
Validation loss: 2.0542693445759435

Epoch: 6| Step: 11
Training loss: 1.2235186100006104
Validation loss: 2.0805912466459375

Epoch: 6| Step: 12
Training loss: 1.3706333637237549
Validation loss: 2.0965721658481065

Epoch: 6| Step: 13
Training loss: 0.5912425518035889
Validation loss: 2.1046608212173625

Epoch: 157| Step: 0
Training loss: 0.9089506268501282
Validation loss: 2.0953459457684587

Epoch: 6| Step: 1
Training loss: 1.482318639755249
Validation loss: 2.0904955748588807

Epoch: 6| Step: 2
Training loss: 0.7658834457397461
Validation loss: 2.064117799523056

Epoch: 6| Step: 3
Training loss: 1.9908175468444824
Validation loss: 2.063005906279369

Epoch: 6| Step: 4
Training loss: 1.4158624410629272
Validation loss: 2.0828550605363745

Epoch: 6| Step: 5
Training loss: 1.6793975830078125
Validation loss: 2.0886800135335615

Epoch: 6| Step: 6
Training loss: 1.185781717300415
Validation loss: 2.0881334671410183

Epoch: 6| Step: 7
Training loss: 1.2975969314575195
Validation loss: 2.1317713734924153

Epoch: 6| Step: 8
Training loss: 2.0915207862854004
Validation loss: 2.1201081468212988

Epoch: 6| Step: 9
Training loss: 1.9365698099136353
Validation loss: 2.143476797688392

Epoch: 6| Step: 10
Training loss: 0.7451164722442627
Validation loss: 2.1280718080459105

Epoch: 6| Step: 11
Training loss: 0.8969912528991699
Validation loss: 2.108840820609882

Epoch: 6| Step: 12
Training loss: 1.424694299697876
Validation loss: 2.0707243834772417

Epoch: 6| Step: 13
Training loss: 1.9835537672042847
Validation loss: 2.060388224099272

Epoch: 158| Step: 0
Training loss: 1.1975295543670654
Validation loss: 2.0479861895243325

Epoch: 6| Step: 1
Training loss: 2.7109479904174805
Validation loss: 2.0462410988346225

Epoch: 6| Step: 2
Training loss: 1.2805085182189941
Validation loss: 2.0548190404010076

Epoch: 6| Step: 3
Training loss: 1.4463316202163696
Validation loss: 2.0458729818303096

Epoch: 6| Step: 4
Training loss: 1.3918812274932861
Validation loss: 2.0523523681907245

Epoch: 6| Step: 5
Training loss: 1.3222765922546387
Validation loss: 2.0522313041071736

Epoch: 6| Step: 6
Training loss: 1.1644442081451416
Validation loss: 2.014987604592436

Epoch: 6| Step: 7
Training loss: 1.5346558094024658
Validation loss: 2.03023430737116

Epoch: 6| Step: 8
Training loss: 0.7715275287628174
Validation loss: 2.0559735528884397

Epoch: 6| Step: 9
Training loss: 0.9466013312339783
Validation loss: 2.0677064541847474

Epoch: 6| Step: 10
Training loss: 1.5203003883361816
Validation loss: 2.0781736937902306

Epoch: 6| Step: 11
Training loss: 1.5771011114120483
Validation loss: 2.061242475304552

Epoch: 6| Step: 12
Training loss: 1.4350861310958862
Validation loss: 2.0655881717640865

Epoch: 6| Step: 13
Training loss: 0.9869757890701294
Validation loss: 2.0914299359885593

Epoch: 159| Step: 0
Training loss: 1.5337799787521362
Validation loss: 2.087348104805075

Epoch: 6| Step: 1
Training loss: 1.7031371593475342
Validation loss: 2.0956347655224543

Epoch: 6| Step: 2
Training loss: 1.1915851831436157
Validation loss: 2.0857104857762656

Epoch: 6| Step: 3
Training loss: 1.6418993473052979
Validation loss: 2.1075990969134915

Epoch: 6| Step: 4
Training loss: 1.2235034704208374
Validation loss: 2.0821124610080513

Epoch: 6| Step: 5
Training loss: 1.3629586696624756
Validation loss: 2.1196221843842538

Epoch: 6| Step: 6
Training loss: 1.1986639499664307
Validation loss: 2.1096651067015944

Epoch: 6| Step: 7
Training loss: 1.4168509244918823
Validation loss: 2.1119327506711407

Epoch: 6| Step: 8
Training loss: 1.565025806427002
Validation loss: 2.1294476421930457

Epoch: 6| Step: 9
Training loss: 1.6010370254516602
Validation loss: 2.119710017276067

Epoch: 6| Step: 10
Training loss: 0.8087633848190308
Validation loss: 2.11752418036102

Epoch: 6| Step: 11
Training loss: 1.2426352500915527
Validation loss: 2.1481070595402874

Epoch: 6| Step: 12
Training loss: 1.039212942123413
Validation loss: 2.1606848047625635

Epoch: 6| Step: 13
Training loss: 2.1938836574554443
Validation loss: 2.1694953672347532

Epoch: 160| Step: 0
Training loss: 1.3228282928466797
Validation loss: 2.1705810818620908

Epoch: 6| Step: 1
Training loss: 1.4661725759506226
Validation loss: 2.1512756219474216

Epoch: 6| Step: 2
Training loss: 0.9975970983505249
Validation loss: 2.146926136427028

Epoch: 6| Step: 3
Training loss: 1.5753569602966309
Validation loss: 2.1281924581014984

Epoch: 6| Step: 4
Training loss: 1.4409363269805908
Validation loss: 2.138716872020434

Epoch: 6| Step: 5
Training loss: 1.3630974292755127
Validation loss: 2.150685820528256

Epoch: 6| Step: 6
Training loss: 1.4745104312896729
Validation loss: 2.156296001967563

Epoch: 6| Step: 7
Training loss: 2.065213680267334
Validation loss: 2.135069380524338

Epoch: 6| Step: 8
Training loss: 1.1525821685791016
Validation loss: 2.1121425442798163

Epoch: 6| Step: 9
Training loss: 1.3932507038116455
Validation loss: 2.09569602499726

Epoch: 6| Step: 10
Training loss: 0.6705552935600281
Validation loss: 2.087114049542335

Epoch: 6| Step: 11
Training loss: 1.6098947525024414
Validation loss: 2.072675302464475

Epoch: 6| Step: 12
Training loss: 1.3719769716262817
Validation loss: 2.049570947565058

Epoch: 6| Step: 13
Training loss: 1.0165871381759644
Validation loss: 2.0536993421534055

Epoch: 161| Step: 0
Training loss: 0.9205083847045898
Validation loss: 2.0517094186557236

Epoch: 6| Step: 1
Training loss: 1.4978097677230835
Validation loss: 2.0623069552965063

Epoch: 6| Step: 2
Training loss: 1.2354315519332886
Validation loss: 2.0449467256505

Epoch: 6| Step: 3
Training loss: 1.3154497146606445
Validation loss: 2.0501010264119794

Epoch: 6| Step: 4
Training loss: 1.2316975593566895
Validation loss: 2.0444079675982074

Epoch: 6| Step: 5
Training loss: 1.9266295433044434
Validation loss: 2.0315500318363147

Epoch: 6| Step: 6
Training loss: 1.2204052209854126
Validation loss: 2.0002971823497484

Epoch: 6| Step: 7
Training loss: 0.6964223384857178
Validation loss: 2.013697947225263

Epoch: 6| Step: 8
Training loss: 1.3582227230072021
Validation loss: 2.0098957361713534

Epoch: 6| Step: 9
Training loss: 1.2508962154388428
Validation loss: 2.0357971934862036

Epoch: 6| Step: 10
Training loss: 1.741978645324707
Validation loss: 2.0683912436167398

Epoch: 6| Step: 11
Training loss: 1.5012454986572266
Validation loss: 2.0907236312025335

Epoch: 6| Step: 12
Training loss: 1.7277294397354126
Validation loss: 2.115163016062911

Epoch: 6| Step: 13
Training loss: 2.069415807723999
Validation loss: 2.102479334800474

Epoch: 162| Step: 0
Training loss: 1.4592955112457275
Validation loss: 2.145583962881437

Epoch: 6| Step: 1
Training loss: 1.6885972023010254
Validation loss: 2.1674944482823855

Epoch: 6| Step: 2
Training loss: 1.973341703414917
Validation loss: 2.1421935660864717

Epoch: 6| Step: 3
Training loss: 0.8547742366790771
Validation loss: 2.157132807598319

Epoch: 6| Step: 4
Training loss: 1.1106541156768799
Validation loss: 2.1613150694036998

Epoch: 6| Step: 5
Training loss: 1.4838542938232422
Validation loss: 2.1383101324881277

Epoch: 6| Step: 6
Training loss: 1.382023811340332
Validation loss: 2.0952846875754734

Epoch: 6| Step: 7
Training loss: 1.2969112396240234
Validation loss: 2.067265719495794

Epoch: 6| Step: 8
Training loss: 0.9040254354476929
Validation loss: 2.051028205502418

Epoch: 6| Step: 9
Training loss: 1.0825893878936768
Validation loss: 2.0720455851606143

Epoch: 6| Step: 10
Training loss: 1.1687867641448975
Validation loss: 2.046939097424989

Epoch: 6| Step: 11
Training loss: 1.5241388082504272
Validation loss: 2.0539639175579114

Epoch: 6| Step: 12
Training loss: 1.8667349815368652
Validation loss: 2.047087582208777

Epoch: 6| Step: 13
Training loss: 1.3826103210449219
Validation loss: 2.0505003621501308

Epoch: 163| Step: 0
Training loss: 1.112863302230835
Validation loss: 2.0550035853539743

Epoch: 6| Step: 1
Training loss: 1.2680418491363525
Validation loss: 2.089904726192515

Epoch: 6| Step: 2
Training loss: 1.5556323528289795
Validation loss: 2.1201874504807177

Epoch: 6| Step: 3
Training loss: 0.900680661201477
Validation loss: 2.156561154191212

Epoch: 6| Step: 4
Training loss: 1.4528732299804688
Validation loss: 2.149134466725011

Epoch: 6| Step: 5
Training loss: 1.1263107061386108
Validation loss: 2.1409111151131253

Epoch: 6| Step: 6
Training loss: 1.6415425539016724
Validation loss: 2.1024782837078138

Epoch: 6| Step: 7
Training loss: 1.1937389373779297
Validation loss: 2.066288412258189

Epoch: 6| Step: 8
Training loss: 0.9438766241073608
Validation loss: 2.0422726690128283

Epoch: 6| Step: 9
Training loss: 1.9567474126815796
Validation loss: 2.0323669295157156

Epoch: 6| Step: 10
Training loss: 1.2195427417755127
Validation loss: 2.042343972831644

Epoch: 6| Step: 11
Training loss: 1.4417740106582642
Validation loss: 2.0765438643834924

Epoch: 6| Step: 12
Training loss: 1.7541168928146362
Validation loss: 2.0816583505240818

Epoch: 6| Step: 13
Training loss: 0.7615005970001221
Validation loss: 2.1204687933767996

Epoch: 164| Step: 0
Training loss: 0.8322287797927856
Validation loss: 2.1369766061024

Epoch: 6| Step: 1
Training loss: 1.2000694274902344
Validation loss: 2.159066851421069

Epoch: 6| Step: 2
Training loss: 1.335100769996643
Validation loss: 2.178442424343478

Epoch: 6| Step: 3
Training loss: 1.1087212562561035
Validation loss: 2.1910395340252946

Epoch: 6| Step: 4
Training loss: 0.9144734144210815
Validation loss: 2.2042687426331224

Epoch: 6| Step: 5
Training loss: 1.5888755321502686
Validation loss: 2.216932301880211

Epoch: 6| Step: 6
Training loss: 1.5405786037445068
Validation loss: 2.1636842655879196

Epoch: 6| Step: 7
Training loss: 1.2899892330169678
Validation loss: 2.1313763305705082

Epoch: 6| Step: 8
Training loss: 1.2677559852600098
Validation loss: 2.094698746999105

Epoch: 6| Step: 9
Training loss: 1.3086717128753662
Validation loss: 2.0685699498781593

Epoch: 6| Step: 10
Training loss: 1.423085331916809
Validation loss: 2.058412275006694

Epoch: 6| Step: 11
Training loss: 1.8056221008300781
Validation loss: 2.0525083580324726

Epoch: 6| Step: 12
Training loss: 1.5892844200134277
Validation loss: 2.034842155312979

Epoch: 6| Step: 13
Training loss: 1.0753649473190308
Validation loss: 1.9968393156605382

Epoch: 165| Step: 0
Training loss: 1.613552451133728
Validation loss: 2.0377546638570805

Epoch: 6| Step: 1
Training loss: 2.1847853660583496
Validation loss: 2.022019124800159

Epoch: 6| Step: 2
Training loss: 1.317378282546997
Validation loss: 2.0682144011220625

Epoch: 6| Step: 3
Training loss: 1.6100482940673828
Validation loss: 2.0796485972660843

Epoch: 6| Step: 4
Training loss: 1.3915817737579346
Validation loss: 2.1400538900847077

Epoch: 6| Step: 5
Training loss: 1.6160602569580078
Validation loss: 2.1397619452527774

Epoch: 6| Step: 6
Training loss: 0.846464991569519
Validation loss: 2.125567356745402

Epoch: 6| Step: 7
Training loss: 1.1356136798858643
Validation loss: 2.1420567753494426

Epoch: 6| Step: 8
Training loss: 0.5841761827468872
Validation loss: 2.142633404783023

Epoch: 6| Step: 9
Training loss: 1.4267597198486328
Validation loss: 2.168207601834369

Epoch: 6| Step: 10
Training loss: 1.2275021076202393
Validation loss: 2.1871822239250265

Epoch: 6| Step: 11
Training loss: 0.7760778665542603
Validation loss: 2.1660035989617787

Epoch: 6| Step: 12
Training loss: 1.3592493534088135
Validation loss: 2.147191043822996

Epoch: 6| Step: 13
Training loss: 1.7704854011535645
Validation loss: 2.0707483214716755

Epoch: 166| Step: 0
Training loss: 0.7403655052185059
Validation loss: 2.078923522785146

Epoch: 6| Step: 1
Training loss: 1.7077593803405762
Validation loss: 2.03640515189017

Epoch: 6| Step: 2
Training loss: 0.873048722743988
Validation loss: 2.028516028517036

Epoch: 6| Step: 3
Training loss: 1.4135911464691162
Validation loss: 2.008728124762094

Epoch: 6| Step: 4
Training loss: 1.3271725177764893
Validation loss: 1.986374242331392

Epoch: 6| Step: 5
Training loss: 1.3145320415496826
Validation loss: 1.995344679842713

Epoch: 6| Step: 6
Training loss: 1.1112442016601562
Validation loss: 2.0360877411339873

Epoch: 6| Step: 7
Training loss: 0.7008454203605652
Validation loss: 2.0308245946002264

Epoch: 6| Step: 8
Training loss: 1.2398604154586792
Validation loss: 2.044587590361154

Epoch: 6| Step: 9
Training loss: 1.9602584838867188
Validation loss: 2.0441361114542973

Epoch: 6| Step: 10
Training loss: 1.7707432508468628
Validation loss: 2.0885988255982757

Epoch: 6| Step: 11
Training loss: 0.9790269732475281
Validation loss: 2.119901095667193

Epoch: 6| Step: 12
Training loss: 1.2989929914474487
Validation loss: 2.1093976882196244

Epoch: 6| Step: 13
Training loss: 1.763466238975525
Validation loss: 2.0670085594218266

Epoch: 167| Step: 0
Training loss: 0.9690874814987183
Validation loss: 2.085211584644933

Epoch: 6| Step: 1
Training loss: 1.0029352903366089
Validation loss: 2.0904822746912637

Epoch: 6| Step: 2
Training loss: 1.4351634979248047
Validation loss: 2.073927342250783

Epoch: 6| Step: 3
Training loss: 1.254364013671875
Validation loss: 2.056180884761195

Epoch: 6| Step: 4
Training loss: 1.6384351253509521
Validation loss: 2.069714880758716

Epoch: 6| Step: 5
Training loss: 1.3298535346984863
Validation loss: 2.0864949816016742

Epoch: 6| Step: 6
Training loss: 1.7168340682983398
Validation loss: 2.076474001330714

Epoch: 6| Step: 7
Training loss: 1.525034785270691
Validation loss: 2.0912615470988776

Epoch: 6| Step: 8
Training loss: 0.7544565200805664
Validation loss: 2.087344664399342

Epoch: 6| Step: 9
Training loss: 1.192080020904541
Validation loss: 2.0899270349933254

Epoch: 6| Step: 10
Training loss: 1.3138554096221924
Validation loss: 2.095963829307146

Epoch: 6| Step: 11
Training loss: 1.2438807487487793
Validation loss: 2.0785036381854805

Epoch: 6| Step: 12
Training loss: 1.1221637725830078
Validation loss: 2.0367782218481905

Epoch: 6| Step: 13
Training loss: 0.9075682163238525
Validation loss: 1.9971829524604223

Epoch: 168| Step: 0
Training loss: 1.0005944967269897
Validation loss: 2.016740791259273

Epoch: 6| Step: 1
Training loss: 1.5885950326919556
Validation loss: 2.0116776650951755

Epoch: 6| Step: 2
Training loss: 1.2765581607818604
Validation loss: 2.048456807290354

Epoch: 6| Step: 3
Training loss: 1.2077481746673584
Validation loss: 2.0937621285838466

Epoch: 6| Step: 4
Training loss: 1.1907072067260742
Validation loss: 2.0879296487377537

Epoch: 6| Step: 5
Training loss: 1.2440708875656128
Validation loss: 2.0836567109630955

Epoch: 6| Step: 6
Training loss: 1.0766868591308594
Validation loss: 2.0724840548730667

Epoch: 6| Step: 7
Training loss: 1.3700847625732422
Validation loss: 2.0432061918320192

Epoch: 6| Step: 8
Training loss: 1.2356524467468262
Validation loss: 2.048634291977011

Epoch: 6| Step: 9
Training loss: 0.9029000997543335
Validation loss: 2.088928355965563

Epoch: 6| Step: 10
Training loss: 0.9747576713562012
Validation loss: 2.1442250436352146

Epoch: 6| Step: 11
Training loss: 1.6272382736206055
Validation loss: 2.1160544195482807

Epoch: 6| Step: 12
Training loss: 1.2062104940414429
Validation loss: 2.1344450981386247

Epoch: 6| Step: 13
Training loss: 1.3994210958480835
Validation loss: 2.0951901866543676

Epoch: 169| Step: 0
Training loss: 1.899329662322998
Validation loss: 2.0990864692195768

Epoch: 6| Step: 1
Training loss: 0.7637776136398315
Validation loss: 2.0839515039997716

Epoch: 6| Step: 2
Training loss: 1.173027753829956
Validation loss: 2.066745969556993

Epoch: 6| Step: 3
Training loss: 1.2048444747924805
Validation loss: 2.0398984621929865

Epoch: 6| Step: 4
Training loss: 0.9692121744155884
Validation loss: 2.0410787238869617

Epoch: 6| Step: 5
Training loss: 0.9682415723800659
Validation loss: 2.0488144351590063

Epoch: 6| Step: 6
Training loss: 1.0947494506835938
Validation loss: 2.0420218565130748

Epoch: 6| Step: 7
Training loss: 1.0778095722198486
Validation loss: 2.0175858518128753

Epoch: 6| Step: 8
Training loss: 1.626562476158142
Validation loss: 2.0221372791515884

Epoch: 6| Step: 9
Training loss: 1.4766790866851807
Validation loss: 2.0000980784816127

Epoch: 6| Step: 10
Training loss: 1.334182858467102
Validation loss: 1.9997284463656846

Epoch: 6| Step: 11
Training loss: 1.3642336130142212
Validation loss: 2.0044153698029055

Epoch: 6| Step: 12
Training loss: 1.2451105117797852
Validation loss: 2.02646961263431

Epoch: 6| Step: 13
Training loss: 0.9847699403762817
Validation loss: 2.0372800455298474

Epoch: 170| Step: 0
Training loss: 0.9300862550735474
Validation loss: 2.0348130041553127

Epoch: 6| Step: 1
Training loss: 1.1057738065719604
Validation loss: 2.043293624795893

Epoch: 6| Step: 2
Training loss: 1.375165581703186
Validation loss: 2.0403263389423327

Epoch: 6| Step: 3
Training loss: 0.8896831274032593
Validation loss: 2.0862072731858943

Epoch: 6| Step: 4
Training loss: 1.502568244934082
Validation loss: 2.0842670586801346

Epoch: 6| Step: 5
Training loss: 1.3477416038513184
Validation loss: 2.1172982159481255

Epoch: 6| Step: 6
Training loss: 1.0718821287155151
Validation loss: 2.1100360860106764

Epoch: 6| Step: 7
Training loss: 0.8128584623336792
Validation loss: 2.106717212225801

Epoch: 6| Step: 8
Training loss: 1.838577389717102
Validation loss: 2.1274679963306715

Epoch: 6| Step: 9
Training loss: 1.5394128561019897
Validation loss: 2.1317257163345174

Epoch: 6| Step: 10
Training loss: 1.1109750270843506
Validation loss: 2.1837367396200857

Epoch: 6| Step: 11
Training loss: 1.2436250448226929
Validation loss: 2.1386804785779727

Epoch: 6| Step: 12
Training loss: 1.32722806930542
Validation loss: 2.152956421657275

Epoch: 6| Step: 13
Training loss: 0.9122964143753052
Validation loss: 2.119061303395097

Epoch: 171| Step: 0
Training loss: 1.1552557945251465
Validation loss: 2.079676761422106

Epoch: 6| Step: 1
Training loss: 1.3965123891830444
Validation loss: 2.0507861439899733

Epoch: 6| Step: 2
Training loss: 1.181765079498291
Validation loss: 2.0988629287289036

Epoch: 6| Step: 3
Training loss: 1.2276108264923096
Validation loss: 2.1125558499367005

Epoch: 6| Step: 4
Training loss: 1.2747697830200195
Validation loss: 2.088816068505728

Epoch: 6| Step: 5
Training loss: 0.5662826299667358
Validation loss: 2.0522135816594607

Epoch: 6| Step: 6
Training loss: 1.2799484729766846
Validation loss: 2.0678675290076964

Epoch: 6| Step: 7
Training loss: 1.1985723972320557
Validation loss: 2.0939876840960596

Epoch: 6| Step: 8
Training loss: 0.972986102104187
Validation loss: 2.104655178644324

Epoch: 6| Step: 9
Training loss: 1.7287006378173828
Validation loss: 2.1035994637397026

Epoch: 6| Step: 10
Training loss: 1.3698432445526123
Validation loss: 2.095045466576853

Epoch: 6| Step: 11
Training loss: 0.886092483997345
Validation loss: 2.0411633958098707

Epoch: 6| Step: 12
Training loss: 1.649864912033081
Validation loss: 2.0507354377418436

Epoch: 6| Step: 13
Training loss: 1.413023591041565
Validation loss: 2.0396354506092687

Epoch: 172| Step: 0
Training loss: 1.2165474891662598
Validation loss: 2.0290192686101443

Epoch: 6| Step: 1
Training loss: 1.9773261547088623
Validation loss: 2.0272857835215907

Epoch: 6| Step: 2
Training loss: 0.7036107778549194
Validation loss: 2.01186623368212

Epoch: 6| Step: 3
Training loss: 1.4526125192642212
Validation loss: 2.0467168169636882

Epoch: 6| Step: 4
Training loss: 1.4419893026351929
Validation loss: 2.055333488730974

Epoch: 6| Step: 5
Training loss: 0.9789338111877441
Validation loss: 2.0751981196864957

Epoch: 6| Step: 6
Training loss: 1.1686702966690063
Validation loss: 2.0725388526916504

Epoch: 6| Step: 7
Training loss: 1.120410680770874
Validation loss: 2.065139585925687

Epoch: 6| Step: 8
Training loss: 0.7145507335662842
Validation loss: 2.0824847554647796

Epoch: 6| Step: 9
Training loss: 1.1690587997436523
Validation loss: 2.118675842080065

Epoch: 6| Step: 10
Training loss: 0.9081699252128601
Validation loss: 2.1082811253045195

Epoch: 6| Step: 11
Training loss: 1.1556072235107422
Validation loss: 2.1112883039700088

Epoch: 6| Step: 12
Training loss: 1.146435260772705
Validation loss: 2.099821682899229

Epoch: 6| Step: 13
Training loss: 1.5721086263656616
Validation loss: 2.121885561173962

Epoch: 173| Step: 0
Training loss: 1.1078321933746338
Validation loss: 2.0845908529014996

Epoch: 6| Step: 1
Training loss: 1.0609445571899414
Validation loss: 2.0961522466392926

Epoch: 6| Step: 2
Training loss: 1.0108816623687744
Validation loss: 2.0692809422810874

Epoch: 6| Step: 3
Training loss: 0.837370753288269
Validation loss: 2.069519830006425

Epoch: 6| Step: 4
Training loss: 0.9386200904846191
Validation loss: 2.0498754234724146

Epoch: 6| Step: 5
Training loss: 1.5262974500656128
Validation loss: 2.0484488010406494

Epoch: 6| Step: 6
Training loss: 0.6014528870582581
Validation loss: 2.033948060004942

Epoch: 6| Step: 7
Training loss: 1.9065508842468262
Validation loss: 2.0251844826564995

Epoch: 6| Step: 8
Training loss: 1.6036818027496338
Validation loss: 2.052051685189688

Epoch: 6| Step: 9
Training loss: 1.3630919456481934
Validation loss: 2.0674183625046925

Epoch: 6| Step: 10
Training loss: 1.444460391998291
Validation loss: 2.068274792804513

Epoch: 6| Step: 11
Training loss: 1.2444490194320679
Validation loss: 2.0702051603665916

Epoch: 6| Step: 12
Training loss: 1.1143442392349243
Validation loss: 2.0701062525472333

Epoch: 6| Step: 13
Training loss: 0.9914436340332031
Validation loss: 2.0409010648727417

Epoch: 174| Step: 0
Training loss: 1.032961130142212
Validation loss: 2.0131070575406476

Epoch: 6| Step: 1
Training loss: 1.2345969676971436
Validation loss: 1.9891773910932644

Epoch: 6| Step: 2
Training loss: 0.826480507850647
Validation loss: 1.999948578496133

Epoch: 6| Step: 3
Training loss: 1.0811103582382202
Validation loss: 1.995231859145626

Epoch: 6| Step: 4
Training loss: 1.0596535205841064
Validation loss: 2.0137763907832484

Epoch: 6| Step: 5
Training loss: 1.29914391040802
Validation loss: 2.0103726297296505

Epoch: 6| Step: 6
Training loss: 1.6318634748458862
Validation loss: 2.0226399244800692

Epoch: 6| Step: 7
Training loss: 1.690463662147522
Validation loss: 2.0086536843289613

Epoch: 6| Step: 8
Training loss: 1.3368046283721924
Validation loss: 2.009331851877192

Epoch: 6| Step: 9
Training loss: 1.155779480934143
Validation loss: 2.0697315662137923

Epoch: 6| Step: 10
Training loss: 1.0493237972259521
Validation loss: 2.031019026233304

Epoch: 6| Step: 11
Training loss: 0.7163385152816772
Validation loss: 2.058961991340883

Epoch: 6| Step: 12
Training loss: 1.2813878059387207
Validation loss: 2.0635195509079964

Epoch: 6| Step: 13
Training loss: 1.0827088356018066
Validation loss: 2.039613800664102

Epoch: 175| Step: 0
Training loss: 1.4199140071868896
Validation loss: 1.9921950704307967

Epoch: 6| Step: 1
Training loss: 0.7862989902496338
Validation loss: 2.0053524842826267

Epoch: 6| Step: 2
Training loss: 0.7773230075836182
Validation loss: 2.0008235810905375

Epoch: 6| Step: 3
Training loss: 1.012142300605774
Validation loss: 1.9850249572466778

Epoch: 6| Step: 4
Training loss: 1.3898022174835205
Validation loss: 1.966136488863217

Epoch: 6| Step: 5
Training loss: 0.9815694093704224
Validation loss: 1.996177666930742

Epoch: 6| Step: 6
Training loss: 0.866949200630188
Validation loss: 1.9929444559158818

Epoch: 6| Step: 7
Training loss: 0.9746931791305542
Validation loss: 1.9743773501406434

Epoch: 6| Step: 8
Training loss: 1.1026579141616821
Validation loss: 1.9968911114559378

Epoch: 6| Step: 9
Training loss: 1.0575063228607178
Validation loss: 2.0353035632000176

Epoch: 6| Step: 10
Training loss: 1.3447285890579224
Validation loss: 2.044766879850818

Epoch: 6| Step: 11
Training loss: 1.5141019821166992
Validation loss: 2.0714847862079577

Epoch: 6| Step: 12
Training loss: 1.3769915103912354
Validation loss: 2.1101889674381544

Epoch: 6| Step: 13
Training loss: 1.6673399209976196
Validation loss: 2.1030741519825433

Epoch: 176| Step: 0
Training loss: 1.185896873474121
Validation loss: 2.0692521115785003

Epoch: 6| Step: 1
Training loss: 0.896132230758667
Validation loss: 2.0434512297312417

Epoch: 6| Step: 2
Training loss: 1.2266888618469238
Validation loss: 2.025689471152521

Epoch: 6| Step: 3
Training loss: 1.3436393737792969
Validation loss: 2.020952373422602

Epoch: 6| Step: 4
Training loss: 1.8827171325683594
Validation loss: 2.01827908074984

Epoch: 6| Step: 5
Training loss: 1.1162683963775635
Validation loss: 2.027667450648482

Epoch: 6| Step: 6
Training loss: 1.2551617622375488
Validation loss: 2.0298001971296085

Epoch: 6| Step: 7
Training loss: 1.2863171100616455
Validation loss: 2.0231542356552614

Epoch: 6| Step: 8
Training loss: 1.0166916847229004
Validation loss: 2.035586057170745

Epoch: 6| Step: 9
Training loss: 1.0384992361068726
Validation loss: 2.0638921773561867

Epoch: 6| Step: 10
Training loss: 0.9159823060035706
Validation loss: 2.0141014347794237

Epoch: 6| Step: 11
Training loss: 1.0231695175170898
Validation loss: 2.0333725303731938

Epoch: 6| Step: 12
Training loss: 0.6402984857559204
Validation loss: 2.0058681529055358

Epoch: 6| Step: 13
Training loss: 1.5006921291351318
Validation loss: 1.9989541320390598

Epoch: 177| Step: 0
Training loss: 1.1501030921936035
Validation loss: 1.9744399644995247

Epoch: 6| Step: 1
Training loss: 0.7943644523620605
Validation loss: 1.9753872438143658

Epoch: 6| Step: 2
Training loss: 0.7591936588287354
Validation loss: 2.0079074700673423

Epoch: 6| Step: 3
Training loss: 1.0993802547454834
Validation loss: 2.010520239030161

Epoch: 6| Step: 4
Training loss: 1.361094355583191
Validation loss: 1.9977979416488318

Epoch: 6| Step: 5
Training loss: 0.8376277685165405
Validation loss: 1.9885644348718787

Epoch: 6| Step: 6
Training loss: 0.575924277305603
Validation loss: 1.9885762391551849

Epoch: 6| Step: 7
Training loss: 1.654801607131958
Validation loss: 1.9918598026357672

Epoch: 6| Step: 8
Training loss: 1.3944385051727295
Validation loss: 1.9942004834451983

Epoch: 6| Step: 9
Training loss: 1.464276909828186
Validation loss: 2.003971206244602

Epoch: 6| Step: 10
Training loss: 0.7642173767089844
Validation loss: 2.0489364208713656

Epoch: 6| Step: 11
Training loss: 1.5406711101531982
Validation loss: 2.0494632310764764

Epoch: 6| Step: 12
Training loss: 1.345679521560669
Validation loss: 2.0763261882207726

Epoch: 6| Step: 13
Training loss: 1.5967209339141846
Validation loss: 2.0685425407143048

Epoch: 178| Step: 0
Training loss: 0.6670525074005127
Validation loss: 2.096866758920813

Epoch: 6| Step: 1
Training loss: 1.610378384590149
Validation loss: 2.097700172855008

Epoch: 6| Step: 2
Training loss: 0.9811898469924927
Validation loss: 2.0949586565776537

Epoch: 6| Step: 3
Training loss: 1.53047776222229
Validation loss: 2.068492789422312

Epoch: 6| Step: 4
Training loss: 0.7092018723487854
Validation loss: 2.0706675783280404

Epoch: 6| Step: 5
Training loss: 1.3873200416564941
Validation loss: 2.0569225613788893

Epoch: 6| Step: 6
Training loss: 1.169081211090088
Validation loss: 2.039637009302775

Epoch: 6| Step: 7
Training loss: 1.085957646369934
Validation loss: 2.029778518984395

Epoch: 6| Step: 8
Training loss: 0.9740229845046997
Validation loss: 2.0093355332651446

Epoch: 6| Step: 9
Training loss: 1.2865276336669922
Validation loss: 1.9924008025917956

Epoch: 6| Step: 10
Training loss: 0.9733558893203735
Validation loss: 1.9940112560026106

Epoch: 6| Step: 11
Training loss: 1.3497581481933594
Validation loss: 2.025587219063954

Epoch: 6| Step: 12
Training loss: 1.3964130878448486
Validation loss: 2.0941302673791045

Epoch: 6| Step: 13
Training loss: 0.7907196283340454
Validation loss: 2.0909672501266643

Epoch: 179| Step: 0
Training loss: 1.41257643699646
Validation loss: 2.101596781002578

Epoch: 6| Step: 1
Training loss: 0.9662768840789795
Validation loss: 2.1066861383376585

Epoch: 6| Step: 2
Training loss: 0.8660590648651123
Validation loss: 2.089751911419694

Epoch: 6| Step: 3
Training loss: 0.8500493764877319
Validation loss: 2.049077058351168

Epoch: 6| Step: 4
Training loss: 1.1605256795883179
Validation loss: 2.0588917552783923

Epoch: 6| Step: 5
Training loss: 0.8866377472877502
Validation loss: 2.0434951551498903

Epoch: 6| Step: 6
Training loss: 0.7542240619659424
Validation loss: 2.0045600552712717

Epoch: 6| Step: 7
Training loss: 1.3978427648544312
Validation loss: 2.001712244044068

Epoch: 6| Step: 8
Training loss: 1.4785913228988647
Validation loss: 1.9936672808021627

Epoch: 6| Step: 9
Training loss: 1.134953260421753
Validation loss: 1.9974313205288303

Epoch: 6| Step: 10
Training loss: 1.0710426568984985
Validation loss: 1.9620263115052254

Epoch: 6| Step: 11
Training loss: 1.0124759674072266
Validation loss: 1.9663732462031867

Epoch: 6| Step: 12
Training loss: 1.518514633178711
Validation loss: 2.0034158806647024

Epoch: 6| Step: 13
Training loss: 1.4425947666168213
Validation loss: 2.02534838902053

Epoch: 180| Step: 0
Training loss: 1.1184349060058594
Validation loss: 2.0064623509683917

Epoch: 6| Step: 1
Training loss: 1.4947009086608887
Validation loss: 2.02161753818553

Epoch: 6| Step: 2
Training loss: 0.9960945844650269
Validation loss: 2.007692167835851

Epoch: 6| Step: 3
Training loss: 0.5259494781494141
Validation loss: 1.985762273111651

Epoch: 6| Step: 4
Training loss: 1.387221336364746
Validation loss: 2.0002124027539323

Epoch: 6| Step: 5
Training loss: 1.3293685913085938
Validation loss: 2.0413384822107132

Epoch: 6| Step: 6
Training loss: 0.6161810159683228
Validation loss: 2.0375024336640553

Epoch: 6| Step: 7
Training loss: 1.0243124961853027
Validation loss: 2.033133306810933

Epoch: 6| Step: 8
Training loss: 1.0652393102645874
Validation loss: 2.020553027429888

Epoch: 6| Step: 9
Training loss: 0.9635763764381409
Validation loss: 2.0313006652298795

Epoch: 6| Step: 10
Training loss: 1.2267102003097534
Validation loss: 2.0022242915245796

Epoch: 6| Step: 11
Training loss: 1.0122750997543335
Validation loss: 2.0021414756774902

Epoch: 6| Step: 12
Training loss: 1.4089914560317993
Validation loss: 2.008520024438058

Epoch: 6| Step: 13
Training loss: 1.4647812843322754
Validation loss: 1.9902078515739852

Epoch: 181| Step: 0
Training loss: 1.314990520477295
Validation loss: 1.971699345496393

Epoch: 6| Step: 1
Training loss: 1.1541650295257568
Validation loss: 1.9446951766167917

Epoch: 6| Step: 2
Training loss: 1.008182406425476
Validation loss: 1.9495054111685803

Epoch: 6| Step: 3
Training loss: 1.5608808994293213
Validation loss: 1.9711115693533292

Epoch: 6| Step: 4
Training loss: 0.759505569934845
Validation loss: 2.0184738546289425

Epoch: 6| Step: 5
Training loss: 1.1449850797653198
Validation loss: 2.0229335933603267

Epoch: 6| Step: 6
Training loss: 1.171407699584961
Validation loss: 2.0360245832832913

Epoch: 6| Step: 7
Training loss: 0.9866598844528198
Validation loss: 2.0500623282565864

Epoch: 6| Step: 8
Training loss: 0.7934310436248779
Validation loss: 2.048899876174106

Epoch: 6| Step: 9
Training loss: 1.420644998550415
Validation loss: 2.03005821986865

Epoch: 6| Step: 10
Training loss: 0.6866266131401062
Validation loss: 2.018044399958785

Epoch: 6| Step: 11
Training loss: 0.7974283695220947
Validation loss: 2.04019146837214

Epoch: 6| Step: 12
Training loss: 1.6796249151229858
Validation loss: 2.0136445747908724

Epoch: 6| Step: 13
Training loss: 0.832066535949707
Validation loss: 1.9815106007360643

Epoch: 182| Step: 0
Training loss: 1.6746175289154053
Validation loss: 1.9738942179628598

Epoch: 6| Step: 1
Training loss: 1.1463909149169922
Validation loss: 1.9293755203165033

Epoch: 6| Step: 2
Training loss: 0.3112473785877228
Validation loss: 1.9341400464375813

Epoch: 6| Step: 3
Training loss: 1.0394892692565918
Validation loss: 1.9154009844667168

Epoch: 6| Step: 4
Training loss: 0.738503098487854
Validation loss: 1.9398462746732978

Epoch: 6| Step: 5
Training loss: 1.5760776996612549
Validation loss: 1.951068027045137

Epoch: 6| Step: 6
Training loss: 1.4043115377426147
Validation loss: 1.9363125678031676

Epoch: 6| Step: 7
Training loss: 1.0197432041168213
Validation loss: 1.9343907384462253

Epoch: 6| Step: 8
Training loss: 1.6159954071044922
Validation loss: 1.9245293704412316

Epoch: 6| Step: 9
Training loss: 0.5679193139076233
Validation loss: 1.9360038465069187

Epoch: 6| Step: 10
Training loss: 0.7887115478515625
Validation loss: 1.9704048531029814

Epoch: 6| Step: 11
Training loss: 0.8700494170188904
Validation loss: 2.0198193596255396

Epoch: 6| Step: 12
Training loss: 1.1482607126235962
Validation loss: 2.0212591207155617

Epoch: 6| Step: 13
Training loss: 1.2658228874206543
Validation loss: 2.0427260873138264

Epoch: 183| Step: 0
Training loss: 1.2440602779388428
Validation loss: 2.0547969520732923

Epoch: 6| Step: 1
Training loss: 0.6665374636650085
Validation loss: 2.0456369012914677

Epoch: 6| Step: 2
Training loss: 0.8976391553878784
Validation loss: 2.0571959633981027

Epoch: 6| Step: 3
Training loss: 0.8134810924530029
Validation loss: 2.0285014388381795

Epoch: 6| Step: 4
Training loss: 1.4881786108016968
Validation loss: 2.030334113746561

Epoch: 6| Step: 5
Training loss: 0.8300232291221619
Validation loss: 2.0109025509126726

Epoch: 6| Step: 6
Training loss: 1.1691434383392334
Validation loss: 2.0189226878586637

Epoch: 6| Step: 7
Training loss: 1.2035679817199707
Validation loss: 2.020151771524901

Epoch: 6| Step: 8
Training loss: 0.9794890880584717
Validation loss: 2.017781251220293

Epoch: 6| Step: 9
Training loss: 0.9998719692230225
Validation loss: 2.0180388676222933

Epoch: 6| Step: 10
Training loss: 0.9737851619720459
Validation loss: 2.0314526288740096

Epoch: 6| Step: 11
Training loss: 1.1172178983688354
Validation loss: 2.0581481123483307

Epoch: 6| Step: 12
Training loss: 1.0952692031860352
Validation loss: 2.05667346139108

Epoch: 6| Step: 13
Training loss: 1.1610817909240723
Validation loss: 2.088228892254573

Epoch: 184| Step: 0
Training loss: 0.9544532299041748
Validation loss: 2.0938946559864986

Epoch: 6| Step: 1
Training loss: 0.9461456537246704
Validation loss: 2.0669624023540045

Epoch: 6| Step: 2
Training loss: 1.1892131567001343
Validation loss: 2.0414819550770584

Epoch: 6| Step: 3
Training loss: 1.3756630420684814
Validation loss: 2.026115127789077

Epoch: 6| Step: 4
Training loss: 0.8855066895484924
Validation loss: 2.026270338284072

Epoch: 6| Step: 5
Training loss: 0.87824547290802
Validation loss: 2.0119667706951017

Epoch: 6| Step: 6
Training loss: 0.5978699326515198
Validation loss: 2.0127372485335155

Epoch: 6| Step: 7
Training loss: 1.2237975597381592
Validation loss: 1.9991550432738436

Epoch: 6| Step: 8
Training loss: 1.3692678213119507
Validation loss: 1.9702793808393582

Epoch: 6| Step: 9
Training loss: 0.6212084293365479
Validation loss: 1.9838581059568672

Epoch: 6| Step: 10
Training loss: 0.9390140175819397
Validation loss: 1.9690899618210331

Epoch: 6| Step: 11
Training loss: 0.6823691725730896
Validation loss: 1.9740582614816644

Epoch: 6| Step: 12
Training loss: 1.4493992328643799
Validation loss: 1.9773022128689675

Epoch: 6| Step: 13
Training loss: 1.292936086654663
Validation loss: 1.9513481047845656

Epoch: 185| Step: 0
Training loss: 0.9915517568588257
Validation loss: 1.9902095845950547

Epoch: 6| Step: 1
Training loss: 1.15425705909729
Validation loss: 1.999954115959906

Epoch: 6| Step: 2
Training loss: 1.1166410446166992
Validation loss: 2.0224630371216805

Epoch: 6| Step: 3
Training loss: 0.932560920715332
Validation loss: 2.0584355810637116

Epoch: 6| Step: 4
Training loss: 0.6619991660118103
Validation loss: 2.0570690401138796

Epoch: 6| Step: 5
Training loss: 1.2714431285858154
Validation loss: 2.0547257854092504

Epoch: 6| Step: 6
Training loss: 0.833304226398468
Validation loss: 2.004101240506736

Epoch: 6| Step: 7
Training loss: 1.2264939546585083
Validation loss: 1.9892813415937527

Epoch: 6| Step: 8
Training loss: 1.492147445678711
Validation loss: 1.957855155391078

Epoch: 6| Step: 9
Training loss: 1.2196015119552612
Validation loss: 1.9452343140878985

Epoch: 6| Step: 10
Training loss: 0.7298899292945862
Validation loss: 1.907690828846347

Epoch: 6| Step: 11
Training loss: 1.0502939224243164
Validation loss: 1.9276977841572096

Epoch: 6| Step: 12
Training loss: 0.7596859931945801
Validation loss: 1.8834096372768443

Epoch: 6| Step: 13
Training loss: 0.9200477600097656
Validation loss: 1.8759142378325104

Epoch: 186| Step: 0
Training loss: 1.1891298294067383
Validation loss: 1.919547527067123

Epoch: 6| Step: 1
Training loss: 0.9241620302200317
Validation loss: 1.9287447903745918

Epoch: 6| Step: 2
Training loss: 1.0128400325775146
Validation loss: 1.9600341358492452

Epoch: 6| Step: 3
Training loss: 1.3512414693832397
Validation loss: 1.9752712916302424

Epoch: 6| Step: 4
Training loss: 0.8752947449684143
Validation loss: 2.007812069308373

Epoch: 6| Step: 5
Training loss: 1.0624444484710693
Validation loss: 2.0420943716520905

Epoch: 6| Step: 6
Training loss: 0.8454959392547607
Validation loss: 2.0252709209278064

Epoch: 6| Step: 7
Training loss: 0.7389801740646362
Validation loss: 2.050837065583916

Epoch: 6| Step: 8
Training loss: 0.7306236624717712
Validation loss: 2.0608674146795787

Epoch: 6| Step: 9
Training loss: 0.9783362746238708
Validation loss: 2.06841306788947

Epoch: 6| Step: 10
Training loss: 0.9115246534347534
Validation loss: 2.0281171080886677

Epoch: 6| Step: 11
Training loss: 1.1626663208007812
Validation loss: 2.0259265515112106

Epoch: 6| Step: 12
Training loss: 1.139290690422058
Validation loss: 2.02154202102333

Epoch: 6| Step: 13
Training loss: 1.0786893367767334
Validation loss: 2.010151877198168

Epoch: 187| Step: 0
Training loss: 0.9876291751861572
Validation loss: 1.9889966236647738

Epoch: 6| Step: 1
Training loss: 1.0786566734313965
Validation loss: 1.9561133153976933

Epoch: 6| Step: 2
Training loss: 1.3492822647094727
Validation loss: 1.97643821085653

Epoch: 6| Step: 3
Training loss: 1.5731593370437622
Validation loss: 1.9528903409998903

Epoch: 6| Step: 4
Training loss: 0.8434665203094482
Validation loss: 1.9702918503874092

Epoch: 6| Step: 5
Training loss: 1.17411208152771
Validation loss: 1.974298918119041

Epoch: 6| Step: 6
Training loss: 0.9977399110794067
Validation loss: 2.0019901542253393

Epoch: 6| Step: 7
Training loss: 0.8405291438102722
Validation loss: 1.9951127036925285

Epoch: 6| Step: 8
Training loss: 0.9422830939292908
Validation loss: 2.0382955356310775

Epoch: 6| Step: 9
Training loss: 0.3406871557235718
Validation loss: 2.0507453051946496

Epoch: 6| Step: 10
Training loss: 1.303557276725769
Validation loss: 2.049290654479816

Epoch: 6| Step: 11
Training loss: 0.6407754421234131
Validation loss: 2.0641857475362797

Epoch: 6| Step: 12
Training loss: 0.9087393879890442
Validation loss: 2.0985176435080906

Epoch: 6| Step: 13
Training loss: 0.8164413571357727
Validation loss: 2.0952547519437728

Epoch: 188| Step: 0
Training loss: 1.3185025453567505
Validation loss: 2.1206163539681384

Epoch: 6| Step: 1
Training loss: 0.4491741359233856
Validation loss: 2.1025852387951267

Epoch: 6| Step: 2
Training loss: 0.5438365340232849
Validation loss: 2.0717305239810737

Epoch: 6| Step: 3
Training loss: 1.035811185836792
Validation loss: 2.085515993897633

Epoch: 6| Step: 4
Training loss: 1.1256165504455566
Validation loss: 2.049335300281484

Epoch: 6| Step: 5
Training loss: 0.888303816318512
Validation loss: 2.061163806146191

Epoch: 6| Step: 6
Training loss: 1.0430819988250732
Validation loss: 2.0346458022312452

Epoch: 6| Step: 7
Training loss: 1.5346380472183228
Validation loss: 2.019365679833197

Epoch: 6| Step: 8
Training loss: 1.0258872509002686
Validation loss: 2.027084894077752

Epoch: 6| Step: 9
Training loss: 1.0638219118118286
Validation loss: 1.97449839756053

Epoch: 6| Step: 10
Training loss: 0.6065027713775635
Validation loss: 1.9720087423119494

Epoch: 6| Step: 11
Training loss: 1.0927770137786865
Validation loss: 1.9492421816754084

Epoch: 6| Step: 12
Training loss: 1.098512887954712
Validation loss: 1.9652802726273895

Epoch: 6| Step: 13
Training loss: 1.3287287950515747
Validation loss: 2.001942620482496

Epoch: 189| Step: 0
Training loss: 0.7117990255355835
Validation loss: 2.005628833206751

Epoch: 6| Step: 1
Training loss: 0.9106450080871582
Validation loss: 2.0149358895517167

Epoch: 6| Step: 2
Training loss: 0.8926894664764404
Validation loss: 1.9596383212715067

Epoch: 6| Step: 3
Training loss: 1.316454291343689
Validation loss: 1.9743904580352127

Epoch: 6| Step: 4
Training loss: 1.1055761575698853
Validation loss: 1.9631764427308114

Epoch: 6| Step: 5
Training loss: 0.8445233106613159
Validation loss: 1.987245955774861

Epoch: 6| Step: 6
Training loss: 1.3979140520095825
Validation loss: 1.9718514924408288

Epoch: 6| Step: 7
Training loss: 0.9708113670349121
Validation loss: 1.9631411439629012

Epoch: 6| Step: 8
Training loss: 1.2633482217788696
Validation loss: 1.9593646705791514

Epoch: 6| Step: 9
Training loss: 1.0508875846862793
Validation loss: 1.9895817490034207

Epoch: 6| Step: 10
Training loss: 1.3687729835510254
Validation loss: 1.9730815669541717

Epoch: 6| Step: 11
Training loss: 0.818038284778595
Validation loss: 1.9960914888689596

Epoch: 6| Step: 12
Training loss: 1.0086091756820679
Validation loss: 2.002034902572632

Epoch: 6| Step: 13
Training loss: 0.855400025844574
Validation loss: 1.9921897021673058

Epoch: 190| Step: 0
Training loss: 1.0318546295166016
Validation loss: 2.020703015788909

Epoch: 6| Step: 1
Training loss: 0.7813282012939453
Validation loss: 2.0175420776490243

Epoch: 6| Step: 2
Training loss: 0.7300058603286743
Validation loss: 2.047287062932086

Epoch: 6| Step: 3
Training loss: 1.2276909351348877
Validation loss: 2.0524102205871255

Epoch: 6| Step: 4
Training loss: 0.4547603726387024
Validation loss: 2.0504876259834535

Epoch: 6| Step: 5
Training loss: 1.1246721744537354
Validation loss: 2.050935991348759

Epoch: 6| Step: 6
Training loss: 0.9220358729362488
Validation loss: 2.0234944820404053

Epoch: 6| Step: 7
Training loss: 0.8490840792655945
Validation loss: 1.9966038093771985

Epoch: 6| Step: 8
Training loss: 0.8768284320831299
Validation loss: 1.9706701591450682

Epoch: 6| Step: 9
Training loss: 1.2212682962417603
Validation loss: 1.8985480211114372

Epoch: 6| Step: 10
Training loss: 0.9731152057647705
Validation loss: 1.8805261273537912

Epoch: 6| Step: 11
Training loss: 1.0154926776885986
Validation loss: 1.8914461494773946

Epoch: 6| Step: 12
Training loss: 1.2012519836425781
Validation loss: 1.9022821585337322

Epoch: 6| Step: 13
Training loss: 1.101722240447998
Validation loss: 1.9172249929879301

Epoch: 191| Step: 0
Training loss: 0.8371375799179077
Validation loss: 1.9161629048726891

Epoch: 6| Step: 1
Training loss: 1.0875930786132812
Validation loss: 1.9624380014275993

Epoch: 6| Step: 2
Training loss: 0.9964714050292969
Validation loss: 1.980437760711998

Epoch: 6| Step: 3
Training loss: 0.6711770296096802
Validation loss: 2.0072730971920874

Epoch: 6| Step: 4
Training loss: 0.991779088973999
Validation loss: 1.9821716047102405

Epoch: 6| Step: 5
Training loss: 0.8539285063743591
Validation loss: 1.9995439552491712

Epoch: 6| Step: 6
Training loss: 1.171942949295044
Validation loss: 1.9819290817424815

Epoch: 6| Step: 7
Training loss: 0.5755932331085205
Validation loss: 1.977022232547883

Epoch: 6| Step: 8
Training loss: 0.9038345217704773
Validation loss: 1.979502066489189

Epoch: 6| Step: 9
Training loss: 1.0663259029388428
Validation loss: 1.9403122740407144

Epoch: 6| Step: 10
Training loss: 1.1880711317062378
Validation loss: 1.9447856756948656

Epoch: 6| Step: 11
Training loss: 1.0661226511001587
Validation loss: 1.941757449539759

Epoch: 6| Step: 12
Training loss: 0.7413504123687744
Validation loss: 1.9457980612272858

Epoch: 6| Step: 13
Training loss: 0.7080170512199402
Validation loss: 1.9588263598821496

Epoch: 192| Step: 0
Training loss: 1.1224865913391113
Validation loss: 1.9877915549021896

Epoch: 6| Step: 1
Training loss: 1.017534613609314
Validation loss: 1.9571462997826197

Epoch: 6| Step: 2
Training loss: 1.119398593902588
Validation loss: 1.9772477867782756

Epoch: 6| Step: 3
Training loss: 1.0010201930999756
Validation loss: 1.9514036704135198

Epoch: 6| Step: 4
Training loss: 0.9037777185440063
Validation loss: 1.97620560789621

Epoch: 6| Step: 5
Training loss: 0.5799064636230469
Validation loss: 1.9617824246806483

Epoch: 6| Step: 6
Training loss: 0.47499436140060425
Validation loss: 1.9476656272847166

Epoch: 6| Step: 7
Training loss: 0.6599749326705933
Validation loss: 1.965244625204353

Epoch: 6| Step: 8
Training loss: 1.2171926498413086
Validation loss: 1.9921597767901678

Epoch: 6| Step: 9
Training loss: 0.8980579972267151
Validation loss: 1.9723559297541136

Epoch: 6| Step: 10
Training loss: 0.9244108200073242
Validation loss: 1.9658522170077088

Epoch: 6| Step: 11
Training loss: 0.8970458507537842
Validation loss: 1.959790446424997

Epoch: 6| Step: 12
Training loss: 1.1870558261871338
Validation loss: 1.9302468992048694

Epoch: 6| Step: 13
Training loss: 0.6746103167533875
Validation loss: 1.9333159641552997

Epoch: 193| Step: 0
Training loss: 0.6569828987121582
Validation loss: 1.9620666375724218

Epoch: 6| Step: 1
Training loss: 0.9711492657661438
Validation loss: 1.9539128836765085

Epoch: 6| Step: 2
Training loss: 0.7322628498077393
Validation loss: 1.9393101687072425

Epoch: 6| Step: 3
Training loss: 0.34917545318603516
Validation loss: 1.9650738175197313

Epoch: 6| Step: 4
Training loss: 0.8855339288711548
Validation loss: 1.9956842084084787

Epoch: 6| Step: 5
Training loss: 0.9714820384979248
Validation loss: 1.9942703605980001

Epoch: 6| Step: 6
Training loss: 0.9010111689567566
Validation loss: 2.0192576454531763

Epoch: 6| Step: 7
Training loss: 1.1980953216552734
Validation loss: 2.0549979209899902

Epoch: 6| Step: 8
Training loss: 1.1397686004638672
Validation loss: 2.034772901124852

Epoch: 6| Step: 9
Training loss: 1.3586455583572388
Validation loss: 2.046950856844584

Epoch: 6| Step: 10
Training loss: 0.5799580812454224
Validation loss: 2.078106270041517

Epoch: 6| Step: 11
Training loss: 0.7247316837310791
Validation loss: 2.0457624517461306

Epoch: 6| Step: 12
Training loss: 1.2599188089370728
Validation loss: 2.0778011583512828

Epoch: 6| Step: 13
Training loss: 1.4583802223205566
Validation loss: 2.067790831288984

Epoch: 194| Step: 0
Training loss: 0.5994305610656738
Validation loss: 2.0568944420865787

Epoch: 6| Step: 1
Training loss: 0.8137280344963074
Validation loss: 2.0048956576214043

Epoch: 6| Step: 2
Training loss: 1.2164387702941895
Validation loss: 1.9928311378725114

Epoch: 6| Step: 3
Training loss: 1.312244176864624
Validation loss: 1.9650263196678572

Epoch: 6| Step: 4
Training loss: 1.0895044803619385
Validation loss: 1.925596962692917

Epoch: 6| Step: 5
Training loss: 0.70423823595047
Validation loss: 1.923433808870213

Epoch: 6| Step: 6
Training loss: 0.8411300778388977
Validation loss: 1.936488675814803

Epoch: 6| Step: 7
Training loss: 0.5998676419258118
Validation loss: 1.9385866170288415

Epoch: 6| Step: 8
Training loss: 0.7553418874740601
Validation loss: 1.9411757838341497

Epoch: 6| Step: 9
Training loss: 0.5816743969917297
Validation loss: 1.9162938479454286

Epoch: 6| Step: 10
Training loss: 0.6394075155258179
Validation loss: 1.9419898781725156

Epoch: 6| Step: 11
Training loss: 1.6580345630645752
Validation loss: 1.984277812383508

Epoch: 6| Step: 12
Training loss: 0.8628082275390625
Validation loss: 1.9742026200858496

Epoch: 6| Step: 13
Training loss: 1.1585444211959839
Validation loss: 2.034577759363318

Epoch: 195| Step: 0
Training loss: 1.5457097291946411
Validation loss: 2.027940220730279

Epoch: 6| Step: 1
Training loss: 0.9206819534301758
Validation loss: 2.0382092229781614

Epoch: 6| Step: 2
Training loss: 0.8760033845901489
Validation loss: 2.0075360639120943

Epoch: 6| Step: 3
Training loss: 0.8067570328712463
Validation loss: 2.0101723747868694

Epoch: 6| Step: 4
Training loss: 0.7125281691551208
Validation loss: 1.9703099868630851

Epoch: 6| Step: 5
Training loss: 0.7881003022193909
Validation loss: 1.9842554741008307

Epoch: 6| Step: 6
Training loss: 0.7262693047523499
Validation loss: 1.9959752072570145

Epoch: 6| Step: 7
Training loss: 0.4289984107017517
Validation loss: 1.9491259923545263

Epoch: 6| Step: 8
Training loss: 0.8804898262023926
Validation loss: 1.9079998590612923

Epoch: 6| Step: 9
Training loss: 0.8589882254600525
Validation loss: 1.9297573592073174

Epoch: 6| Step: 10
Training loss: 1.5638341903686523
Validation loss: 1.9101917948774112

Epoch: 6| Step: 11
Training loss: 1.065455675125122
Validation loss: 1.9112630326260802

Epoch: 6| Step: 12
Training loss: 0.722038984298706
Validation loss: 1.9483639886302333

Epoch: 6| Step: 13
Training loss: 1.144561767578125
Validation loss: 1.9686735278816634

Epoch: 196| Step: 0
Training loss: 0.9785460829734802
Validation loss: 1.997183112687962

Epoch: 6| Step: 1
Training loss: 0.858080267906189
Validation loss: 2.007470659030381

Epoch: 6| Step: 2
Training loss: 0.7900991439819336
Validation loss: 1.991770992996872

Epoch: 6| Step: 3
Training loss: 0.8242939710617065
Validation loss: 1.9832064874710575

Epoch: 6| Step: 4
Training loss: 0.6465017795562744
Validation loss: 1.9728960221813572

Epoch: 6| Step: 5
Training loss: 0.878057599067688
Validation loss: 2.004298351144278

Epoch: 6| Step: 6
Training loss: 0.8092861175537109
Validation loss: 1.9598994229429512

Epoch: 6| Step: 7
Training loss: 0.8328050374984741
Validation loss: 1.9819540926205215

Epoch: 6| Step: 8
Training loss: 1.0495409965515137
Validation loss: 1.9683978455041045

Epoch: 6| Step: 9
Training loss: 1.004258394241333
Validation loss: 1.9427967968807425

Epoch: 6| Step: 10
Training loss: 1.2463090419769287
Validation loss: 1.9450530813586326

Epoch: 6| Step: 11
Training loss: 0.43844103813171387
Validation loss: 1.9303389736401138

Epoch: 6| Step: 12
Training loss: 0.7519124746322632
Validation loss: 1.926475304429249

Epoch: 6| Step: 13
Training loss: 1.3763569593429565
Validation loss: 1.9286711087790869

Epoch: 197| Step: 0
Training loss: 0.7544397115707397
Validation loss: 1.945925699767246

Epoch: 6| Step: 1
Training loss: 1.0685985088348389
Validation loss: 1.9561117977224372

Epoch: 6| Step: 2
Training loss: 1.1187503337860107
Validation loss: 1.9790504465820968

Epoch: 6| Step: 3
Training loss: 0.7411364912986755
Validation loss: 1.9988058279919367

Epoch: 6| Step: 4
Training loss: 0.7231210470199585
Validation loss: 1.9721586191526024

Epoch: 6| Step: 5
Training loss: 0.6301795244216919
Validation loss: 2.0003936290740967

Epoch: 6| Step: 6
Training loss: 0.8813104629516602
Validation loss: 1.9886023741896435

Epoch: 6| Step: 7
Training loss: 1.1021159887313843
Validation loss: 2.0077401053520942

Epoch: 6| Step: 8
Training loss: 0.9743164777755737
Validation loss: 2.0472536727946293

Epoch: 6| Step: 9
Training loss: 0.7948422431945801
Validation loss: 2.069776245342788

Epoch: 6| Step: 10
Training loss: 0.9954349994659424
Validation loss: 2.0520738337629583

Epoch: 6| Step: 11
Training loss: 0.5773401856422424
Validation loss: 2.0485617742743543

Epoch: 6| Step: 12
Training loss: 0.7589039206504822
Validation loss: 1.9976467624787362

Epoch: 6| Step: 13
Training loss: 0.9466565251350403
Validation loss: 1.9911202948580506

Epoch: 198| Step: 0
Training loss: 0.7090133428573608
Validation loss: 1.9680048650310886

Epoch: 6| Step: 1
Training loss: 1.064993977546692
Validation loss: 1.9844768431878859

Epoch: 6| Step: 2
Training loss: 0.8188800811767578
Validation loss: 2.0066115779261433

Epoch: 6| Step: 3
Training loss: 0.9370030164718628
Validation loss: 1.9998687569813063

Epoch: 6| Step: 4
Training loss: 1.0908865928649902
Validation loss: 1.949164157272667

Epoch: 6| Step: 5
Training loss: 0.8960853219032288
Validation loss: 1.9129486365984845

Epoch: 6| Step: 6
Training loss: 1.0352250337600708
Validation loss: 1.8894282156421291

Epoch: 6| Step: 7
Training loss: 1.2021225690841675
Validation loss: 1.8872326676563551

Epoch: 6| Step: 8
Training loss: 1.0975940227508545
Validation loss: 1.8870469177922895

Epoch: 6| Step: 9
Training loss: 0.6746838092803955
Validation loss: 1.9360034132516513

Epoch: 6| Step: 10
Training loss: 0.7281658053398132
Validation loss: 1.9444354426476262

Epoch: 6| Step: 11
Training loss: 1.016289472579956
Validation loss: 2.031244449718024

Epoch: 6| Step: 12
Training loss: 0.9393751621246338
Validation loss: 2.0586978953371764

Epoch: 6| Step: 13
Training loss: 0.7265588641166687
Validation loss: 2.06239648660024

Epoch: 199| Step: 0
Training loss: 0.8463301658630371
Validation loss: 2.0846936241272958

Epoch: 6| Step: 1
Training loss: 0.8845632076263428
Validation loss: 2.127798475244994

Epoch: 6| Step: 2
Training loss: 0.8690481185913086
Validation loss: 2.1012770488697994

Epoch: 6| Step: 3
Training loss: 0.9997354745864868
Validation loss: 2.0890877913403254

Epoch: 6| Step: 4
Training loss: 1.087285041809082
Validation loss: 2.035948386756323

Epoch: 6| Step: 5
Training loss: 0.7912940979003906
Validation loss: 2.0185034044327272

Epoch: 6| Step: 6
Training loss: 0.8334563970565796
Validation loss: 1.9819606029859154

Epoch: 6| Step: 7
Training loss: 1.1325803995132446
Validation loss: 1.918238955159341

Epoch: 6| Step: 8
Training loss: 1.0881717205047607
Validation loss: 1.9385441118671047

Epoch: 6| Step: 9
Training loss: 0.6829819679260254
Validation loss: 1.9218950502334102

Epoch: 6| Step: 10
Training loss: 1.1391032934188843
Validation loss: 1.893797428377213

Epoch: 6| Step: 11
Training loss: 1.1264389753341675
Validation loss: 1.8890639428169496

Epoch: 6| Step: 12
Training loss: 0.4789622724056244
Validation loss: 1.8713961775584886

Epoch: 6| Step: 13
Training loss: 0.4734799563884735
Validation loss: 1.8996833255214076

Epoch: 200| Step: 0
Training loss: 1.1459243297576904
Validation loss: 1.8932906581509499

Epoch: 6| Step: 1
Training loss: 0.8052875995635986
Validation loss: 1.9064800982834191

Epoch: 6| Step: 2
Training loss: 0.659007728099823
Validation loss: 1.9180122908725534

Epoch: 6| Step: 3
Training loss: 0.5675760507583618
Validation loss: 1.958796621650778

Epoch: 6| Step: 4
Training loss: 0.7686843872070312
Validation loss: 1.9589740563464422

Epoch: 6| Step: 5
Training loss: 0.8923555016517639
Validation loss: 2.0061494099196566

Epoch: 6| Step: 6
Training loss: 1.436716079711914
Validation loss: 2.02839631419028

Epoch: 6| Step: 7
Training loss: 0.9362082481384277
Validation loss: 2.028677676313667

Epoch: 6| Step: 8
Training loss: 0.756009578704834
Validation loss: 2.0783542958639

Epoch: 6| Step: 9
Training loss: 1.1276130676269531
Validation loss: 2.0442896453283166

Epoch: 6| Step: 10
Training loss: 0.9027556777000427
Validation loss: 2.0161543392365977

Epoch: 6| Step: 11
Training loss: 1.0923433303833008
Validation loss: 1.9849598100108485

Epoch: 6| Step: 12
Training loss: 1.0275897979736328
Validation loss: 1.9880908586645638

Epoch: 6| Step: 13
Training loss: 0.9073079228401184
Validation loss: 1.9517176202548447

Epoch: 201| Step: 0
Training loss: 0.9508939385414124
Validation loss: 1.9472241491399787

Epoch: 6| Step: 1
Training loss: 0.8176965713500977
Validation loss: 1.9112471931724138

Epoch: 6| Step: 2
Training loss: 0.8918713927268982
Validation loss: 1.9160718789664648

Epoch: 6| Step: 3
Training loss: 1.0815397500991821
Validation loss: 1.8948016551233107

Epoch: 6| Step: 4
Training loss: 0.709668755531311
Validation loss: 1.8849710905423729

Epoch: 6| Step: 5
Training loss: 0.7850483655929565
Validation loss: 1.8699035029257498

Epoch: 6| Step: 6
Training loss: 0.5923384428024292
Validation loss: 1.8848404435701267

Epoch: 6| Step: 7
Training loss: 1.0096043348312378
Validation loss: 1.8962578440225253

Epoch: 6| Step: 8
Training loss: 1.0411109924316406
Validation loss: 1.9134353937641266

Epoch: 6| Step: 9
Training loss: 0.9641766548156738
Validation loss: 1.9323438611081851

Epoch: 6| Step: 10
Training loss: 1.079695701599121
Validation loss: 1.9028774563984205

Epoch: 6| Step: 11
Training loss: 0.7334659099578857
Validation loss: 1.8979637968924739

Epoch: 6| Step: 12
Training loss: 0.7272782325744629
Validation loss: 1.8795815680616645

Epoch: 6| Step: 13
Training loss: 0.49698150157928467
Validation loss: 1.8843877815431165

Epoch: 202| Step: 0
Training loss: 0.6869765520095825
Validation loss: 1.8897844232538694

Epoch: 6| Step: 1
Training loss: 0.6623215675354004
Validation loss: 1.9192842539920603

Epoch: 6| Step: 2
Training loss: 0.6844187378883362
Validation loss: 1.9108187139675181

Epoch: 6| Step: 3
Training loss: 0.7939255237579346
Validation loss: 1.8704472639227425

Epoch: 6| Step: 4
Training loss: 1.2878954410552979
Validation loss: 1.913032998320877

Epoch: 6| Step: 5
Training loss: 1.1217994689941406
Validation loss: 1.8884679271328835

Epoch: 6| Step: 6
Training loss: 1.2077704668045044
Validation loss: 1.93414395342591

Epoch: 6| Step: 7
Training loss: 0.39016568660736084
Validation loss: 1.9111566364124257

Epoch: 6| Step: 8
Training loss: 0.801449716091156
Validation loss: 1.9097077718345068

Epoch: 6| Step: 9
Training loss: 0.7866990566253662
Validation loss: 1.9381396847386514

Epoch: 6| Step: 10
Training loss: 0.9159895777702332
Validation loss: 1.9411017382016746

Epoch: 6| Step: 11
Training loss: 0.4494403600692749
Validation loss: 1.9574232357804493

Epoch: 6| Step: 12
Training loss: 0.8992728590965271
Validation loss: 1.9611484773697392

Epoch: 6| Step: 13
Training loss: 1.2964518070220947
Validation loss: 2.001013135397306

Epoch: 203| Step: 0
Training loss: 1.0112839937210083
Validation loss: 1.9854693310235136

Epoch: 6| Step: 1
Training loss: 0.7392542958259583
Validation loss: 1.9762382609869844

Epoch: 6| Step: 2
Training loss: 1.017926812171936
Validation loss: 1.958750855538153

Epoch: 6| Step: 3
Training loss: 0.605650007724762
Validation loss: 1.92018977544641

Epoch: 6| Step: 4
Training loss: 1.023470163345337
Validation loss: 1.9187018025305964

Epoch: 6| Step: 5
Training loss: 0.9079650640487671
Validation loss: 1.8853668025744859

Epoch: 6| Step: 6
Training loss: 0.574687659740448
Validation loss: 1.8406664491981588

Epoch: 6| Step: 7
Training loss: 0.9216352105140686
Validation loss: 1.845923041784635

Epoch: 6| Step: 8
Training loss: 0.6852654814720154
Validation loss: 1.8660227098772604

Epoch: 6| Step: 9
Training loss: 1.2880802154541016
Validation loss: 1.8766298652977071

Epoch: 6| Step: 10
Training loss: 0.8675077557563782
Validation loss: 1.920301906524166

Epoch: 6| Step: 11
Training loss: 0.6632410287857056
Validation loss: 1.9581140779679822

Epoch: 6| Step: 12
Training loss: 0.5949228405952454
Validation loss: 1.9344889976645028

Epoch: 6| Step: 13
Training loss: 0.5538007616996765
Validation loss: 1.9933805081152147

Epoch: 204| Step: 0
Training loss: 0.9233572483062744
Validation loss: 2.0425810736994587

Epoch: 6| Step: 1
Training loss: 0.8537093997001648
Validation loss: 2.079876720264394

Epoch: 6| Step: 2
Training loss: 0.944648027420044
Validation loss: 2.069130325830111

Epoch: 6| Step: 3
Training loss: 0.875597357749939
Validation loss: 2.077575191374748

Epoch: 6| Step: 4
Training loss: 1.0113276243209839
Validation loss: 2.073791821797689

Epoch: 6| Step: 5
Training loss: 0.6369364857673645
Validation loss: 2.0332193759179886

Epoch: 6| Step: 6
Training loss: 0.8023144006729126
Validation loss: 2.038894832775157

Epoch: 6| Step: 7
Training loss: 0.4723600745201111
Validation loss: 2.0084837828913042

Epoch: 6| Step: 8
Training loss: 0.7264620065689087
Validation loss: 1.9193588251708655

Epoch: 6| Step: 9
Training loss: 0.5443857908248901
Validation loss: 1.8878069654587777

Epoch: 6| Step: 10
Training loss: 0.9333482980728149
Validation loss: 1.8679316505309074

Epoch: 6| Step: 11
Training loss: 1.029282808303833
Validation loss: 1.854508489690801

Epoch: 6| Step: 12
Training loss: 0.7554117441177368
Validation loss: 1.8365840847774217

Epoch: 6| Step: 13
Training loss: 0.7269313335418701
Validation loss: 1.815386897774153

Epoch: 205| Step: 0
Training loss: 0.919524073600769
Validation loss: 1.7948451772812875

Epoch: 6| Step: 1
Training loss: 0.9720708131790161
Validation loss: 1.8283241397591048

Epoch: 6| Step: 2
Training loss: 0.8696762323379517
Validation loss: 1.8298237541670441

Epoch: 6| Step: 3
Training loss: 0.9053328037261963
Validation loss: 1.816618916808918

Epoch: 6| Step: 4
Training loss: 0.6086239218711853
Validation loss: 1.830163291705552

Epoch: 6| Step: 5
Training loss: 0.8819113969802856
Validation loss: 1.8623425409358034

Epoch: 6| Step: 6
Training loss: 1.0067603588104248
Validation loss: 1.8430060622512654

Epoch: 6| Step: 7
Training loss: 1.096484661102295
Validation loss: 1.819844393319981

Epoch: 6| Step: 8
Training loss: 0.7311320304870605
Validation loss: 1.8281429006207375

Epoch: 6| Step: 9
Training loss: 0.43680840730667114
Validation loss: 1.8510921719253703

Epoch: 6| Step: 10
Training loss: 0.731343150138855
Validation loss: 1.8792587044418498

Epoch: 6| Step: 11
Training loss: 0.7114138603210449
Validation loss: 1.8945132070972073

Epoch: 6| Step: 12
Training loss: 0.8156722187995911
Validation loss: 1.9055744806925456

Epoch: 6| Step: 13
Training loss: 0.4990784227848053
Validation loss: 1.9507516507179505

Epoch: 206| Step: 0
Training loss: 1.137679934501648
Validation loss: 1.9894526132973291

Epoch: 6| Step: 1
Training loss: 0.6807591915130615
Validation loss: 1.9713890603793565

Epoch: 6| Step: 2
Training loss: 1.1399638652801514
Validation loss: 1.9403369785636984

Epoch: 6| Step: 3
Training loss: 1.2319653034210205
Validation loss: 1.9807193381811983

Epoch: 6| Step: 4
Training loss: 0.24461111426353455
Validation loss: 1.9815196516693279

Epoch: 6| Step: 5
Training loss: 0.4327276349067688
Validation loss: 1.984499728807839

Epoch: 6| Step: 6
Training loss: 0.8526553511619568
Validation loss: 1.984988344612942

Epoch: 6| Step: 7
Training loss: 0.5667799711227417
Validation loss: 1.9688564808137956

Epoch: 6| Step: 8
Training loss: 0.7957988977432251
Validation loss: 1.9693701933788996

Epoch: 6| Step: 9
Training loss: 0.6361064910888672
Validation loss: 1.968241395488862

Epoch: 6| Step: 10
Training loss: 0.9281867742538452
Validation loss: 1.9318285744677308

Epoch: 6| Step: 11
Training loss: 1.0267611742019653
Validation loss: 1.906049027237841

Epoch: 6| Step: 12
Training loss: 0.5970838665962219
Validation loss: 1.8703446490790254

Epoch: 6| Step: 13
Training loss: 0.4909442365169525
Validation loss: 1.9043598482685704

Epoch: 207| Step: 0
Training loss: 1.1367712020874023
Validation loss: 1.8816455564191263

Epoch: 6| Step: 1
Training loss: 0.7001512050628662
Validation loss: 1.9107602847519742

Epoch: 6| Step: 2
Training loss: 0.9096306562423706
Validation loss: 1.9201278865978282

Epoch: 6| Step: 3
Training loss: 0.7362167835235596
Validation loss: 1.9257327074645667

Epoch: 6| Step: 4
Training loss: 0.7312077283859253
Validation loss: 1.9281862269165695

Epoch: 6| Step: 5
Training loss: 0.6435955762863159
Validation loss: 1.9155090342285812

Epoch: 6| Step: 6
Training loss: 0.6412045359611511
Validation loss: 1.9444127428916194

Epoch: 6| Step: 7
Training loss: 0.49979591369628906
Validation loss: 1.9267790702081495

Epoch: 6| Step: 8
Training loss: 0.6524136662483215
Validation loss: 1.9237739655279344

Epoch: 6| Step: 9
Training loss: 0.5460795760154724
Validation loss: 1.9269537207900838

Epoch: 6| Step: 10
Training loss: 0.5819311141967773
Validation loss: 1.9497471060804141

Epoch: 6| Step: 11
Training loss: 0.8997964859008789
Validation loss: 1.9287649303354242

Epoch: 6| Step: 12
Training loss: 0.7371556162834167
Validation loss: 1.9329667809189006

Epoch: 6| Step: 13
Training loss: 0.6595897674560547
Validation loss: 1.9108624637767833

Epoch: 208| Step: 0
Training loss: 0.6179115176200867
Validation loss: 1.9663169012274793

Epoch: 6| Step: 1
Training loss: 0.9398056268692017
Validation loss: 1.9510948914353565

Epoch: 6| Step: 2
Training loss: 0.6251662969589233
Validation loss: 1.9533176934847267

Epoch: 6| Step: 3
Training loss: 0.7942498922348022
Validation loss: 1.9344273690254457

Epoch: 6| Step: 4
Training loss: 0.9347139596939087
Validation loss: 1.9204808076222737

Epoch: 6| Step: 5
Training loss: 0.9377602338790894
Validation loss: 1.8782541790316183

Epoch: 6| Step: 6
Training loss: 0.4573163092136383
Validation loss: 1.9019452858996648

Epoch: 6| Step: 7
Training loss: 0.8903719782829285
Validation loss: 1.8753970605070873

Epoch: 6| Step: 8
Training loss: 0.5514102578163147
Validation loss: 1.8945832252502441

Epoch: 6| Step: 9
Training loss: 0.5733240246772766
Validation loss: 1.8712745212739514

Epoch: 6| Step: 10
Training loss: 0.5312297344207764
Validation loss: 1.8911557351389239

Epoch: 6| Step: 11
Training loss: 0.8014695644378662
Validation loss: 1.8881661276663504

Epoch: 6| Step: 12
Training loss: 0.9723676443099976
Validation loss: 1.868796786954326

Epoch: 6| Step: 13
Training loss: 0.503180742263794
Validation loss: 1.8786245853670183

Epoch: 209| Step: 0
Training loss: 0.7513800859451294
Validation loss: 1.874119343296174

Epoch: 6| Step: 1
Training loss: 0.8643260598182678
Validation loss: 1.8550538555268319

Epoch: 6| Step: 2
Training loss: 0.592430830001831
Validation loss: 1.8779813166587584

Epoch: 6| Step: 3
Training loss: 1.2580628395080566
Validation loss: 1.8757774445318407

Epoch: 6| Step: 4
Training loss: 0.768613338470459
Validation loss: 1.875506426698418

Epoch: 6| Step: 5
Training loss: 0.8349244594573975
Validation loss: 1.8930072848514845

Epoch: 6| Step: 6
Training loss: 0.7759503126144409
Validation loss: 1.8677375508892922

Epoch: 6| Step: 7
Training loss: 0.8210093975067139
Validation loss: 1.8776934505790792

Epoch: 6| Step: 8
Training loss: 0.6066619157791138
Validation loss: 1.8991355549904607

Epoch: 6| Step: 9
Training loss: 0.6847579479217529
Validation loss: 1.910144405980264

Epoch: 6| Step: 10
Training loss: 0.6468508839607239
Validation loss: 1.9227088112984934

Epoch: 6| Step: 11
Training loss: 0.6265599131584167
Validation loss: 1.9111143876147527

Epoch: 6| Step: 12
Training loss: 0.2075936496257782
Validation loss: 1.8980247000212311

Epoch: 6| Step: 13
Training loss: 0.5693190097808838
Validation loss: 1.890631785956762

Epoch: 210| Step: 0
Training loss: 0.6831527948379517
Validation loss: 1.8903698254657049

Epoch: 6| Step: 1
Training loss: 0.4122142493724823
Validation loss: 1.8479186886100358

Epoch: 6| Step: 2
Training loss: 0.6112708449363708
Validation loss: 1.836261253203115

Epoch: 6| Step: 3
Training loss: 0.8405517935752869
Validation loss: 1.8231302768953386

Epoch: 6| Step: 4
Training loss: 0.9650770425796509
Validation loss: 1.8326873010204685

Epoch: 6| Step: 5
Training loss: 0.6648913621902466
Validation loss: 1.8814447208117413

Epoch: 6| Step: 6
Training loss: 0.8749443888664246
Validation loss: 1.849887345426826

Epoch: 6| Step: 7
Training loss: 0.8655474185943604
Validation loss: 1.8636753789840206

Epoch: 6| Step: 8
Training loss: 0.4260367751121521
Validation loss: 1.8703513606902091

Epoch: 6| Step: 9
Training loss: 0.6279187202453613
Validation loss: 1.8829388503105409

Epoch: 6| Step: 10
Training loss: 1.0124537944793701
Validation loss: 1.8885293211988223

Epoch: 6| Step: 11
Training loss: 0.46559983491897583
Validation loss: 1.9178298801504157

Epoch: 6| Step: 12
Training loss: 1.0229063034057617
Validation loss: 1.9464192134077831

Epoch: 6| Step: 13
Training loss: 0.4902347922325134
Validation loss: 1.9309080967339136

Epoch: 211| Step: 0
Training loss: 0.38347312808036804
Validation loss: 1.954515810935728

Epoch: 6| Step: 1
Training loss: 0.5998755693435669
Validation loss: 1.9243659755235076

Epoch: 6| Step: 2
Training loss: 0.9921056628227234
Validation loss: 1.9528405948351788

Epoch: 6| Step: 3
Training loss: 0.920168399810791
Validation loss: 1.9305895272121634

Epoch: 6| Step: 4
Training loss: 0.5343583822250366
Validation loss: 1.92591046133349

Epoch: 6| Step: 5
Training loss: 0.782787024974823
Validation loss: 1.9050810670339933

Epoch: 6| Step: 6
Training loss: 0.5454913973808289
Validation loss: 1.9176507790883381

Epoch: 6| Step: 7
Training loss: 0.9863582849502563
Validation loss: 1.8881334502209899

Epoch: 6| Step: 8
Training loss: 0.6851365566253662
Validation loss: 1.8885980985497917

Epoch: 6| Step: 9
Training loss: 0.5568047761917114
Validation loss: 1.848772524505533

Epoch: 6| Step: 10
Training loss: 0.8331196308135986
Validation loss: 1.8284149990286878

Epoch: 6| Step: 11
Training loss: 0.4223906397819519
Validation loss: 1.8679417256386048

Epoch: 6| Step: 12
Training loss: 0.9670990705490112
Validation loss: 1.829026537556802

Epoch: 6| Step: 13
Training loss: 0.6030513644218445
Validation loss: 1.8234255531782746

Epoch: 212| Step: 0
Training loss: 0.948596715927124
Validation loss: 1.8407373095071444

Epoch: 6| Step: 1
Training loss: 0.504235029220581
Validation loss: 1.8563478364739368

Epoch: 6| Step: 2
Training loss: 0.6065484285354614
Validation loss: 1.827974856540721

Epoch: 6| Step: 3
Training loss: 0.6681779623031616
Validation loss: 1.8241245233884422

Epoch: 6| Step: 4
Training loss: 0.5206069946289062
Validation loss: 1.82578456530007

Epoch: 6| Step: 5
Training loss: 0.5937464833259583
Validation loss: 1.8416074270843177

Epoch: 6| Step: 6
Training loss: 0.32711249589920044
Validation loss: 1.8570229161170222

Epoch: 6| Step: 7
Training loss: 0.8242509365081787
Validation loss: 1.8857610174404678

Epoch: 6| Step: 8
Training loss: 0.6005282998085022
Validation loss: 1.9020066222836893

Epoch: 6| Step: 9
Training loss: 0.5031155943870544
Validation loss: 1.9056054110168128

Epoch: 6| Step: 10
Training loss: 0.8840229511260986
Validation loss: 1.8895500488178705

Epoch: 6| Step: 11
Training loss: 0.8528668880462646
Validation loss: 1.90350382174215

Epoch: 6| Step: 12
Training loss: 1.1449692249298096
Validation loss: 1.900927500058246

Epoch: 6| Step: 13
Training loss: 0.47466257214546204
Validation loss: 1.879928647830922

Epoch: 213| Step: 0
Training loss: 0.7003321647644043
Validation loss: 1.89618484691907

Epoch: 6| Step: 1
Training loss: 0.5495359301567078
Validation loss: 1.8970815789315008

Epoch: 6| Step: 2
Training loss: 0.6405197381973267
Validation loss: 1.9189663497350549

Epoch: 6| Step: 3
Training loss: 0.7905555963516235
Validation loss: 1.9336284655396656

Epoch: 6| Step: 4
Training loss: 0.6566011905670166
Validation loss: 1.9061596649949268

Epoch: 6| Step: 5
Training loss: 0.8640329241752625
Validation loss: 1.8548045901842014

Epoch: 6| Step: 6
Training loss: 0.46032071113586426
Validation loss: 1.916801155254405

Epoch: 6| Step: 7
Training loss: 0.48269471526145935
Validation loss: 1.8942483753286383

Epoch: 6| Step: 8
Training loss: 0.8399794101715088
Validation loss: 1.9155076267898723

Epoch: 6| Step: 9
Training loss: 0.7224051356315613
Validation loss: 1.8987721473939958

Epoch: 6| Step: 10
Training loss: 0.5282824039459229
Validation loss: 1.8976651430130005

Epoch: 6| Step: 11
Training loss: 0.7511235475540161
Validation loss: 1.8939838550424064

Epoch: 6| Step: 12
Training loss: 0.8591530323028564
Validation loss: 1.8592393782831007

Epoch: 6| Step: 13
Training loss: 0.9025421142578125
Validation loss: 1.8689623673756917

Epoch: 214| Step: 0
Training loss: 0.8743169903755188
Validation loss: 1.9007029353931386

Epoch: 6| Step: 1
Training loss: 0.9943212270736694
Validation loss: 1.8671756867439515

Epoch: 6| Step: 2
Training loss: 0.8605747222900391
Validation loss: 1.8630534000294183

Epoch: 6| Step: 3
Training loss: 0.5472570657730103
Validation loss: 1.831254146432364

Epoch: 6| Step: 4
Training loss: 0.5378188490867615
Validation loss: 1.8658058694613877

Epoch: 6| Step: 5
Training loss: 0.27652618288993835
Validation loss: 1.8761560019626413

Epoch: 6| Step: 6
Training loss: 0.5339598655700684
Validation loss: 1.9105717994833504

Epoch: 6| Step: 7
Training loss: 0.6448315382003784
Validation loss: 1.9082395107515397

Epoch: 6| Step: 8
Training loss: 0.29667699337005615
Validation loss: 1.9185930118765882

Epoch: 6| Step: 9
Training loss: 0.6206117868423462
Validation loss: 1.8969997821315643

Epoch: 6| Step: 10
Training loss: 0.22940108180046082
Validation loss: 1.895678711193864

Epoch: 6| Step: 11
Training loss: 0.7993892431259155
Validation loss: 1.8614632121978267

Epoch: 6| Step: 12
Training loss: 1.0140734910964966
Validation loss: 1.8519485881251674

Epoch: 6| Step: 13
Training loss: 1.1665304899215698
Validation loss: 1.8476115477982389

Epoch: 215| Step: 0
Training loss: 0.6675060391426086
Validation loss: 1.8611157055824035

Epoch: 6| Step: 1
Training loss: 0.5580532550811768
Validation loss: 1.8417341632227744

Epoch: 6| Step: 2
Training loss: 0.7795479893684387
Validation loss: 1.8736398758426789

Epoch: 6| Step: 3
Training loss: 0.41829344630241394
Validation loss: 1.8699461465240808

Epoch: 6| Step: 4
Training loss: 0.9888217449188232
Validation loss: 1.8888518194998465

Epoch: 6| Step: 5
Training loss: 0.8471373319625854
Validation loss: 1.870719253375966

Epoch: 6| Step: 6
Training loss: 0.5599135756492615
Validation loss: 1.8539277289503364

Epoch: 6| Step: 7
Training loss: 0.744084894657135
Validation loss: 1.8589632075320008

Epoch: 6| Step: 8
Training loss: 0.6917761564254761
Validation loss: 1.837206405978049

Epoch: 6| Step: 9
Training loss: 0.4190063774585724
Validation loss: 1.8750885071293

Epoch: 6| Step: 10
Training loss: 0.6953163146972656
Validation loss: 1.8565690043152019

Epoch: 6| Step: 11
Training loss: 0.9339292645454407
Validation loss: 1.899092605037074

Epoch: 6| Step: 12
Training loss: 0.49496930837631226
Validation loss: 1.859536188904957

Epoch: 6| Step: 13
Training loss: 0.5862107276916504
Validation loss: 1.8847955067952473

Epoch: 216| Step: 0
Training loss: 0.7474151849746704
Validation loss: 1.8740525578939786

Epoch: 6| Step: 1
Training loss: 0.5883797407150269
Validation loss: 1.884060400788502

Epoch: 6| Step: 2
Training loss: 1.0168713331222534
Validation loss: 1.8804309534770187

Epoch: 6| Step: 3
Training loss: 0.48787766695022583
Validation loss: 1.8641486449908184

Epoch: 6| Step: 4
Training loss: 0.5336726307868958
Validation loss: 1.8645152712381015

Epoch: 6| Step: 5
Training loss: 0.47941115498542786
Validation loss: 1.830374381234569

Epoch: 6| Step: 6
Training loss: 0.3708480894565582
Validation loss: 1.8681993535769883

Epoch: 6| Step: 7
Training loss: 0.4549505114555359
Validation loss: 1.8084208837119482

Epoch: 6| Step: 8
Training loss: 0.8945471048355103
Validation loss: 1.8303184868187032

Epoch: 6| Step: 9
Training loss: 1.0105761289596558
Validation loss: 1.843744416390696

Epoch: 6| Step: 10
Training loss: 0.4372973144054413
Validation loss: 1.8553623691681893

Epoch: 6| Step: 11
Training loss: 0.855548083782196
Validation loss: 1.8291921179781678

Epoch: 6| Step: 12
Training loss: 0.7703738212585449
Validation loss: 1.8234929371905584

Epoch: 6| Step: 13
Training loss: 0.6019985675811768
Validation loss: 1.8068644756911902

Epoch: 217| Step: 0
Training loss: 0.46790987253189087
Validation loss: 1.7948518773560882

Epoch: 6| Step: 1
Training loss: 0.7304786443710327
Validation loss: 1.7855707137815413

Epoch: 6| Step: 2
Training loss: 0.7200073599815369
Validation loss: 1.813337528577415

Epoch: 6| Step: 3
Training loss: 0.886877179145813
Validation loss: 1.8218312859535217

Epoch: 6| Step: 4
Training loss: 0.5812004804611206
Validation loss: 1.844128934285974

Epoch: 6| Step: 5
Training loss: 0.7117832899093628
Validation loss: 1.86139815597124

Epoch: 6| Step: 6
Training loss: 0.6502523422241211
Validation loss: 1.9048306095984675

Epoch: 6| Step: 7
Training loss: 0.6477468609809875
Validation loss: 1.906292703843886

Epoch: 6| Step: 8
Training loss: 0.4140755534172058
Validation loss: 1.9200894947974914

Epoch: 6| Step: 9
Training loss: 0.6163840293884277
Validation loss: 1.945193757293045

Epoch: 6| Step: 10
Training loss: 1.0113528966903687
Validation loss: 1.9270833307696926

Epoch: 6| Step: 11
Training loss: 0.6419665813446045
Validation loss: 1.9261764787858533

Epoch: 6| Step: 12
Training loss: 0.5652766823768616
Validation loss: 1.888768663970373

Epoch: 6| Step: 13
Training loss: 0.2840898931026459
Validation loss: 1.910433433389151

Epoch: 218| Step: 0
Training loss: 0.41137006878852844
Validation loss: 1.8825837790325124

Epoch: 6| Step: 1
Training loss: 0.36672043800354004
Validation loss: 1.841996846660491

Epoch: 6| Step: 2
Training loss: 0.6539160013198853
Validation loss: 1.8579932387157152

Epoch: 6| Step: 3
Training loss: 0.354402095079422
Validation loss: 1.8134888205476987

Epoch: 6| Step: 4
Training loss: 0.40452513098716736
Validation loss: 1.803201331887194

Epoch: 6| Step: 5
Training loss: 0.7897781133651733
Validation loss: 1.8197067117178312

Epoch: 6| Step: 6
Training loss: 0.899753212928772
Validation loss: 1.8188102424785655

Epoch: 6| Step: 7
Training loss: 0.8148852586746216
Validation loss: 1.8232757968287314

Epoch: 6| Step: 8
Training loss: 0.7894641160964966
Validation loss: 1.8294484410234677

Epoch: 6| Step: 9
Training loss: 0.9061064720153809
Validation loss: 1.8160416951743505

Epoch: 6| Step: 10
Training loss: 0.5064313411712646
Validation loss: 1.8195394533936695

Epoch: 6| Step: 11
Training loss: 0.5765836238861084
Validation loss: 1.8439756131941272

Epoch: 6| Step: 12
Training loss: 0.8548908233642578
Validation loss: 1.8427916944667857

Epoch: 6| Step: 13
Training loss: 0.6412497162818909
Validation loss: 1.8798034409041047

Epoch: 219| Step: 0
Training loss: 0.4995543360710144
Validation loss: 1.9448546440370622

Epoch: 6| Step: 1
Training loss: 0.6122581362724304
Validation loss: 1.9400936044672483

Epoch: 6| Step: 2
Training loss: 0.5133717060089111
Validation loss: 1.9229578587316698

Epoch: 6| Step: 3
Training loss: 0.8360049724578857
Validation loss: 1.9167129416619577

Epoch: 6| Step: 4
Training loss: 0.7308185696601868
Validation loss: 1.9348036601979246

Epoch: 6| Step: 5
Training loss: 0.704574465751648
Validation loss: 1.8924221377218924

Epoch: 6| Step: 6
Training loss: 0.547580361366272
Validation loss: 1.918166975821218

Epoch: 6| Step: 7
Training loss: 0.7154349088668823
Validation loss: 1.9291889129146453

Epoch: 6| Step: 8
Training loss: 0.6568396091461182
Validation loss: 1.9302626604674964

Epoch: 6| Step: 9
Training loss: 0.5978531837463379
Validation loss: 1.8973734212178055

Epoch: 6| Step: 10
Training loss: 0.7611502408981323
Validation loss: 1.8991529659558368

Epoch: 6| Step: 11
Training loss: 0.5344411134719849
Validation loss: 1.8651034037272136

Epoch: 6| Step: 12
Training loss: 0.5031408667564392
Validation loss: 1.8621935280420447

Epoch: 6| Step: 13
Training loss: 0.7005071043968201
Validation loss: 1.8430287555981708

Epoch: 220| Step: 0
Training loss: 0.8712080121040344
Validation loss: 1.8261902370760519

Epoch: 6| Step: 1
Training loss: 0.28940632939338684
Validation loss: 1.8315576994290916

Epoch: 6| Step: 2
Training loss: 0.7285330891609192
Validation loss: 1.809107900947653

Epoch: 6| Step: 3
Training loss: 1.0263373851776123
Validation loss: 1.8058685628316735

Epoch: 6| Step: 4
Training loss: 0.37226903438568115
Validation loss: 1.8074810351094892

Epoch: 6| Step: 5
Training loss: 0.47900381684303284
Validation loss: 1.823682641470304

Epoch: 6| Step: 6
Training loss: 0.38484829664230347
Validation loss: 1.827446226150759

Epoch: 6| Step: 7
Training loss: 0.7628884315490723
Validation loss: 1.8365418462343113

Epoch: 6| Step: 8
Training loss: 0.4739346504211426
Validation loss: 1.8698220009444861

Epoch: 6| Step: 9
Training loss: 1.1997909545898438
Validation loss: 1.8434014192191504

Epoch: 6| Step: 10
Training loss: 0.5773816108703613
Validation loss: 1.8490047121560702

Epoch: 6| Step: 11
Training loss: 0.46708592772483826
Validation loss: 1.8589316029702463

Epoch: 6| Step: 12
Training loss: 0.35758426785469055
Validation loss: 1.877125314486924

Epoch: 6| Step: 13
Training loss: 0.6357645392417908
Validation loss: 1.8562582436428274

Epoch: 221| Step: 0
Training loss: 0.5025849342346191
Validation loss: 1.8476007958894134

Epoch: 6| Step: 1
Training loss: 0.6058171987533569
Validation loss: 1.8268862360267228

Epoch: 6| Step: 2
Training loss: 0.7185553312301636
Validation loss: 1.8279855840949601

Epoch: 6| Step: 3
Training loss: 0.32858532667160034
Validation loss: 1.8301452821300876

Epoch: 6| Step: 4
Training loss: 0.5106168985366821
Validation loss: 1.8148053346141693

Epoch: 6| Step: 5
Training loss: 0.8658298254013062
Validation loss: 1.8398636771786598

Epoch: 6| Step: 6
Training loss: 0.49295592308044434
Validation loss: 1.81748632589976

Epoch: 6| Step: 7
Training loss: 0.4215189218521118
Validation loss: 1.8081561070616528

Epoch: 6| Step: 8
Training loss: 0.5054455995559692
Validation loss: 1.8332762359290995

Epoch: 6| Step: 9
Training loss: 0.43575507402420044
Validation loss: 1.81772861173076

Epoch: 6| Step: 10
Training loss: 0.8767668008804321
Validation loss: 1.8451344197796238

Epoch: 6| Step: 11
Training loss: 0.5812150239944458
Validation loss: 1.818010204581804

Epoch: 6| Step: 12
Training loss: 0.8873457312583923
Validation loss: 1.7950515990616174

Epoch: 6| Step: 13
Training loss: 0.6080257892608643
Validation loss: 1.787969736642735

Epoch: 222| Step: 0
Training loss: 0.8082283735275269
Validation loss: 1.8039054614241405

Epoch: 6| Step: 1
Training loss: 0.8174692392349243
Validation loss: 1.8145841167819114

Epoch: 6| Step: 2
Training loss: 0.4702606201171875
Validation loss: 1.8206671784001012

Epoch: 6| Step: 3
Training loss: 0.6083952188491821
Validation loss: 1.820962077827864

Epoch: 6| Step: 4
Training loss: 0.6702218055725098
Validation loss: 1.8217766067033172

Epoch: 6| Step: 5
Training loss: 0.7127063274383545
Validation loss: 1.812460744252769

Epoch: 6| Step: 6
Training loss: 0.6267357468605042
Validation loss: 1.8363208950206797

Epoch: 6| Step: 7
Training loss: 0.5063707828521729
Validation loss: 1.848162913835177

Epoch: 6| Step: 8
Training loss: 0.66843581199646
Validation loss: 1.857545885988461

Epoch: 6| Step: 9
Training loss: 0.5066013336181641
Validation loss: 1.8740266292325911

Epoch: 6| Step: 10
Training loss: 0.661798357963562
Validation loss: 1.8392566596308062

Epoch: 6| Step: 11
Training loss: 0.32761701941490173
Validation loss: 1.871536757356377

Epoch: 6| Step: 12
Training loss: 0.6928531527519226
Validation loss: 1.856506573256626

Epoch: 6| Step: 13
Training loss: 0.35230326652526855
Validation loss: 1.862656831741333

Epoch: 223| Step: 0
Training loss: 0.7588772773742676
Validation loss: 1.8496436111388668

Epoch: 6| Step: 1
Training loss: 0.7672921419143677
Validation loss: 1.8858983106510614

Epoch: 6| Step: 2
Training loss: 0.8046658039093018
Validation loss: 1.8926201789609847

Epoch: 6| Step: 3
Training loss: 0.4040900468826294
Validation loss: 1.8997534692928355

Epoch: 6| Step: 4
Training loss: 0.4910857379436493
Validation loss: 1.8775129087509648

Epoch: 6| Step: 5
Training loss: 0.6504725813865662
Validation loss: 1.8752833784267466

Epoch: 6| Step: 6
Training loss: 0.6666324734687805
Validation loss: 1.8636667702787666

Epoch: 6| Step: 7
Training loss: 0.5489633679389954
Validation loss: 1.8868472447959326

Epoch: 6| Step: 8
Training loss: 0.6080915331840515
Validation loss: 1.8826477078981296

Epoch: 6| Step: 9
Training loss: 0.5843318700790405
Validation loss: 1.870739298482095

Epoch: 6| Step: 10
Training loss: 0.5803134441375732
Validation loss: 1.852727537514061

Epoch: 6| Step: 11
Training loss: 0.6740866899490356
Validation loss: 1.8311703935746224

Epoch: 6| Step: 12
Training loss: 0.7358284592628479
Validation loss: 1.7922159023182367

Epoch: 6| Step: 13
Training loss: 0.5702512860298157
Validation loss: 1.7962048797197239

Epoch: 224| Step: 0
Training loss: 0.6408060789108276
Validation loss: 1.8072648753402054

Epoch: 6| Step: 1
Training loss: 0.8388094902038574
Validation loss: 1.785055346386407

Epoch: 6| Step: 2
Training loss: 0.5456957817077637
Validation loss: 1.7666948149281163

Epoch: 6| Step: 3
Training loss: 0.5292478799819946
Validation loss: 1.8072876712327361

Epoch: 6| Step: 4
Training loss: 0.678651750087738
Validation loss: 1.8277927560191

Epoch: 6| Step: 5
Training loss: 0.8896328210830688
Validation loss: 1.8294137767566148

Epoch: 6| Step: 6
Training loss: 0.4561532735824585
Validation loss: 1.8159956765431229

Epoch: 6| Step: 7
Training loss: 0.16229934990406036
Validation loss: 1.8848008353223082

Epoch: 6| Step: 8
Training loss: 0.8441864252090454
Validation loss: 1.8909192495448615

Epoch: 6| Step: 9
Training loss: 0.6049572229385376
Validation loss: 1.9238624418935468

Epoch: 6| Step: 10
Training loss: 0.257144570350647
Validation loss: 1.926136092473102

Epoch: 6| Step: 11
Training loss: 0.7509967684745789
Validation loss: 1.8988600571950276

Epoch: 6| Step: 12
Training loss: 0.9349566102027893
Validation loss: 1.865431507428487

Epoch: 6| Step: 13
Training loss: 0.45664262771606445
Validation loss: 1.8603631347738288

Epoch: 225| Step: 0
Training loss: 0.4300612807273865
Validation loss: 1.8473926680062407

Epoch: 6| Step: 1
Training loss: 0.617896556854248
Validation loss: 1.8447102051909252

Epoch: 6| Step: 2
Training loss: 0.5225090980529785
Validation loss: 1.8376569606924569

Epoch: 6| Step: 3
Training loss: 0.4330137372016907
Validation loss: 1.8537146276043308

Epoch: 6| Step: 4
Training loss: 0.9877328276634216
Validation loss: 1.8267797680311306

Epoch: 6| Step: 5
Training loss: 0.5648188591003418
Validation loss: 1.7608263851493917

Epoch: 6| Step: 6
Training loss: 0.6256220936775208
Validation loss: 1.7880466189435733

Epoch: 6| Step: 7
Training loss: 0.28812354803085327
Validation loss: 1.7633122526189333

Epoch: 6| Step: 8
Training loss: 0.5994311571121216
Validation loss: 1.783550198360156

Epoch: 6| Step: 9
Training loss: 0.43519216775894165
Validation loss: 1.7594400413574711

Epoch: 6| Step: 10
Training loss: 0.7174077033996582
Validation loss: 1.7988374694701164

Epoch: 6| Step: 11
Training loss: 0.5722094774246216
Validation loss: 1.7901778310857794

Epoch: 6| Step: 12
Training loss: 0.6328439712524414
Validation loss: 1.817752020333403

Epoch: 6| Step: 13
Training loss: 1.0286567211151123
Validation loss: 1.8469736986262824

Epoch: 226| Step: 0
Training loss: 0.5678391456604004
Validation loss: 1.8997240476710822

Epoch: 6| Step: 1
Training loss: 0.7273012399673462
Validation loss: 1.9432178812642251

Epoch: 6| Step: 2
Training loss: 0.8543597459793091
Validation loss: 1.9558214320931384

Epoch: 6| Step: 3
Training loss: 0.6146533489227295
Validation loss: 1.9034621471999793

Epoch: 6| Step: 4
Training loss: 0.6511896848678589
Validation loss: 1.8944845109857538

Epoch: 6| Step: 5
Training loss: 0.4212333559989929
Validation loss: 1.8781762225653535

Epoch: 6| Step: 6
Training loss: 0.3701510429382324
Validation loss: 1.8368967399802258

Epoch: 6| Step: 7
Training loss: 0.4046333134174347
Validation loss: 1.832957495925247

Epoch: 6| Step: 8
Training loss: 0.4473009705543518
Validation loss: 1.8233465577966423

Epoch: 6| Step: 9
Training loss: 0.7602781057357788
Validation loss: 1.8209049599145049

Epoch: 6| Step: 10
Training loss: 0.5251826643943787
Validation loss: 1.7981900784277147

Epoch: 6| Step: 11
Training loss: 0.8374215364456177
Validation loss: 1.7971860311364616

Epoch: 6| Step: 12
Training loss: 0.5448906421661377
Validation loss: 1.7809423246691305

Epoch: 6| Step: 13
Training loss: 0.5182451605796814
Validation loss: 1.8236998768262966

Epoch: 227| Step: 0
Training loss: 0.5272494554519653
Validation loss: 1.8012123671911096

Epoch: 6| Step: 1
Training loss: 0.30022501945495605
Validation loss: 1.8395659064733854

Epoch: 6| Step: 2
Training loss: 0.7370913028717041
Validation loss: 1.8354519451818159

Epoch: 6| Step: 3
Training loss: 0.5282198786735535
Validation loss: 1.8299143455361808

Epoch: 6| Step: 4
Training loss: 0.5518958568572998
Validation loss: 1.8458909757675663

Epoch: 6| Step: 5
Training loss: 0.5273779034614563
Validation loss: 1.8426293467962613

Epoch: 6| Step: 6
Training loss: 0.3202962875366211
Validation loss: 1.8425037912143174

Epoch: 6| Step: 7
Training loss: 0.7817306518554688
Validation loss: 1.8348992422062864

Epoch: 6| Step: 8
Training loss: 0.5342614650726318
Validation loss: 1.82267169285846

Epoch: 6| Step: 9
Training loss: 0.6698483824729919
Validation loss: 1.8477038978248514

Epoch: 6| Step: 10
Training loss: 0.48189160227775574
Validation loss: 1.8026801565641999

Epoch: 6| Step: 11
Training loss: 0.8066061735153198
Validation loss: 1.8283494800649664

Epoch: 6| Step: 12
Training loss: 0.7255150079727173
Validation loss: 1.786616797088295

Epoch: 6| Step: 13
Training loss: 0.5937017798423767
Validation loss: 1.7795242237788376

Epoch: 228| Step: 0
Training loss: 0.4817739725112915
Validation loss: 1.7912637418316257

Epoch: 6| Step: 1
Training loss: 0.28538578748703003
Validation loss: 1.7861586475885043

Epoch: 6| Step: 2
Training loss: 0.8708137273788452
Validation loss: 1.785952051480611

Epoch: 6| Step: 3
Training loss: 0.42980825901031494
Validation loss: 1.8358446910817137

Epoch: 6| Step: 4
Training loss: 0.8385888934135437
Validation loss: 1.7956967405093613

Epoch: 6| Step: 5
Training loss: 0.46431854367256165
Validation loss: 1.7765973550017162

Epoch: 6| Step: 6
Training loss: 0.32077670097351074
Validation loss: 1.7695236218872892

Epoch: 6| Step: 7
Training loss: 0.5139492750167847
Validation loss: 1.788113776073661

Epoch: 6| Step: 8
Training loss: 0.4067263603210449
Validation loss: 1.8126649959113008

Epoch: 6| Step: 9
Training loss: 0.5497658252716064
Validation loss: 1.8108215485849688

Epoch: 6| Step: 10
Training loss: 0.5948840379714966
Validation loss: 1.808621250173097

Epoch: 6| Step: 11
Training loss: 0.4553699791431427
Validation loss: 1.798464843021926

Epoch: 6| Step: 12
Training loss: 0.5945183038711548
Validation loss: 1.825524414739301

Epoch: 6| Step: 13
Training loss: 0.8941885828971863
Validation loss: 1.7974473917356102

Epoch: 229| Step: 0
Training loss: 0.6251726150512695
Validation loss: 1.808848645097466

Epoch: 6| Step: 1
Training loss: 0.4358081817626953
Validation loss: 1.8293761950667187

Epoch: 6| Step: 2
Training loss: 0.4934161603450775
Validation loss: 1.8072753811395297

Epoch: 6| Step: 3
Training loss: 0.5390781164169312
Validation loss: 1.7962728367056897

Epoch: 6| Step: 4
Training loss: 0.5533393621444702
Validation loss: 1.789190291076578

Epoch: 6| Step: 5
Training loss: 0.5859799385070801
Validation loss: 1.8085133824297177

Epoch: 6| Step: 6
Training loss: 0.34109413623809814
Validation loss: 1.7993538597578644

Epoch: 6| Step: 7
Training loss: 0.6418837904930115
Validation loss: 1.8034535864348054

Epoch: 6| Step: 8
Training loss: 0.5716150999069214
Validation loss: 1.7805509413442304

Epoch: 6| Step: 9
Training loss: 0.5310297012329102
Validation loss: 1.7905401991259666

Epoch: 6| Step: 10
Training loss: 0.5008828043937683
Validation loss: 1.807100720303033

Epoch: 6| Step: 11
Training loss: 0.5729919672012329
Validation loss: 1.7808858028022192

Epoch: 6| Step: 12
Training loss: 0.6217098832130432
Validation loss: 1.7850195823177215

Epoch: 6| Step: 13
Training loss: 0.5963656902313232
Validation loss: 1.7950898985708914

Epoch: 230| Step: 0
Training loss: 0.6322776675224304
Validation loss: 1.794099562911577

Epoch: 6| Step: 1
Training loss: 0.4661971926689148
Validation loss: 1.8081285568975634

Epoch: 6| Step: 2
Training loss: 0.5155889987945557
Validation loss: 1.8357153964299027

Epoch: 6| Step: 3
Training loss: 0.5793170928955078
Validation loss: 1.7942111748521046

Epoch: 6| Step: 4
Training loss: 0.25337398052215576
Validation loss: 1.800861559888368

Epoch: 6| Step: 5
Training loss: 0.5551963448524475
Validation loss: 1.811182233595079

Epoch: 6| Step: 6
Training loss: 0.584104061126709
Validation loss: 1.818805358743155

Epoch: 6| Step: 7
Training loss: 0.8366787433624268
Validation loss: 1.8313395746292607

Epoch: 6| Step: 8
Training loss: 0.7477357387542725
Validation loss: 1.8451718412419802

Epoch: 6| Step: 9
Training loss: 0.489574670791626
Validation loss: 1.8157876371055521

Epoch: 6| Step: 10
Training loss: 0.5297854542732239
Validation loss: 1.8472756544748943

Epoch: 6| Step: 11
Training loss: 0.44205421209335327
Validation loss: 1.8324465943920998

Epoch: 6| Step: 12
Training loss: 0.40953731536865234
Validation loss: 1.8115094425857707

Epoch: 6| Step: 13
Training loss: 0.6053903102874756
Validation loss: 1.810826002910573

Epoch: 231| Step: 0
Training loss: 0.726701021194458
Validation loss: 1.7834884684572938

Epoch: 6| Step: 1
Training loss: 0.5120344161987305
Validation loss: 1.733755842331917

Epoch: 6| Step: 2
Training loss: 0.3803916573524475
Validation loss: 1.761359896711124

Epoch: 6| Step: 3
Training loss: 0.3864407539367676
Validation loss: 1.7452454246500486

Epoch: 6| Step: 4
Training loss: 0.43464016914367676
Validation loss: 1.7408984348338137

Epoch: 6| Step: 5
Training loss: 0.5308611392974854
Validation loss: 1.7577666685145388

Epoch: 6| Step: 6
Training loss: 0.5442301034927368
Validation loss: 1.7611571204277776

Epoch: 6| Step: 7
Training loss: 0.4912857413291931
Validation loss: 1.7935890023426344

Epoch: 6| Step: 8
Training loss: 0.5899161100387573
Validation loss: 1.7628589150726155

Epoch: 6| Step: 9
Training loss: 0.3547368347644806
Validation loss: 1.7795023315696306

Epoch: 6| Step: 10
Training loss: 0.516385018825531
Validation loss: 1.8214571629801104

Epoch: 6| Step: 11
Training loss: 0.7656064033508301
Validation loss: 1.8354226235420472

Epoch: 6| Step: 12
Training loss: 0.8130278587341309
Validation loss: 1.8433227769790157

Epoch: 6| Step: 13
Training loss: 0.18478184938430786
Validation loss: 1.8133466730835617

Epoch: 232| Step: 0
Training loss: 0.6042309999465942
Validation loss: 1.7744550128136911

Epoch: 6| Step: 1
Training loss: 0.5135745406150818
Validation loss: 1.7773320174986316

Epoch: 6| Step: 2
Training loss: 0.7762142419815063
Validation loss: 1.7865659665035944

Epoch: 6| Step: 3
Training loss: 0.3687794804573059
Validation loss: 1.777433036476053

Epoch: 6| Step: 4
Training loss: 0.5223354697227478
Validation loss: 1.771672857704983

Epoch: 6| Step: 5
Training loss: 0.24584874510765076
Validation loss: 1.77610186863971

Epoch: 6| Step: 6
Training loss: 0.4634120464324951
Validation loss: 1.784046011586343

Epoch: 6| Step: 7
Training loss: 0.5073070526123047
Validation loss: 1.7916749908078102

Epoch: 6| Step: 8
Training loss: 0.6948150396347046
Validation loss: 1.8013664343023812

Epoch: 6| Step: 9
Training loss: 0.6700394749641418
Validation loss: 1.8355290351375457

Epoch: 6| Step: 10
Training loss: 0.5453948378562927
Validation loss: 1.8437811969428934

Epoch: 6| Step: 11
Training loss: 0.8361915349960327
Validation loss: 1.8492179365568264

Epoch: 6| Step: 12
Training loss: 0.7721903324127197
Validation loss: 1.8285868757514543

Epoch: 6| Step: 13
Training loss: 0.5549623966217041
Validation loss: 1.836872120057383

Epoch: 233| Step: 0
Training loss: 0.6057896614074707
Validation loss: 1.8032133425435712

Epoch: 6| Step: 1
Training loss: 0.549254298210144
Validation loss: 1.821004142043411

Epoch: 6| Step: 2
Training loss: 0.5734092593193054
Validation loss: 1.8445911061379217

Epoch: 6| Step: 3
Training loss: 0.7139908075332642
Validation loss: 1.8231769402821858

Epoch: 6| Step: 4
Training loss: 0.3556215465068817
Validation loss: 1.7981505752891622

Epoch: 6| Step: 5
Training loss: 0.651037335395813
Validation loss: 1.7778208332677041

Epoch: 6| Step: 6
Training loss: 0.6558718681335449
Validation loss: 1.770869542193669

Epoch: 6| Step: 7
Training loss: 0.4011547565460205
Validation loss: 1.7588418247879192

Epoch: 6| Step: 8
Training loss: 0.44235995411872864
Validation loss: 1.7764721916567894

Epoch: 6| Step: 9
Training loss: 0.32167309522628784
Validation loss: 1.7795949059147989

Epoch: 6| Step: 10
Training loss: 0.6581017374992371
Validation loss: 1.7958678045580465

Epoch: 6| Step: 11
Training loss: 0.4863390028476715
Validation loss: 1.7767998608209754

Epoch: 6| Step: 12
Training loss: 0.39236247539520264
Validation loss: 1.8103172573992001

Epoch: 6| Step: 13
Training loss: 0.6460747122764587
Validation loss: 1.8241095209634433

Epoch: 234| Step: 0
Training loss: 0.6425390243530273
Validation loss: 1.8609071995622368

Epoch: 6| Step: 1
Training loss: 0.34850171208381653
Validation loss: 1.797855188769679

Epoch: 6| Step: 2
Training loss: 0.47357702255249023
Validation loss: 1.7971659821848716

Epoch: 6| Step: 3
Training loss: 0.435577929019928
Validation loss: 1.8135694688366306

Epoch: 6| Step: 4
Training loss: 0.6406506299972534
Validation loss: 1.813981225413661

Epoch: 6| Step: 5
Training loss: 0.4925927221775055
Validation loss: 1.8149619794660998

Epoch: 6| Step: 6
Training loss: 0.5304397344589233
Validation loss: 1.7929481460202126

Epoch: 6| Step: 7
Training loss: 0.7357620596885681
Validation loss: 1.8209461704377206

Epoch: 6| Step: 8
Training loss: 0.8096829652786255
Validation loss: 1.8551130346072617

Epoch: 6| Step: 9
Training loss: 0.3245795965194702
Validation loss: 1.845694354785386

Epoch: 6| Step: 10
Training loss: 0.3392944931983948
Validation loss: 1.8243740579133392

Epoch: 6| Step: 11
Training loss: 0.6576961874961853
Validation loss: 1.8414252483716576

Epoch: 6| Step: 12
Training loss: 0.5549315214157104
Validation loss: 1.8783785784116356

Epoch: 6| Step: 13
Training loss: 0.18446724116802216
Validation loss: 1.8827894631252493

Epoch: 235| Step: 0
Training loss: 0.24189819395542145
Validation loss: 1.874385973458649

Epoch: 6| Step: 1
Training loss: 0.4886331260204315
Validation loss: 1.9045138230887793

Epoch: 6| Step: 2
Training loss: 0.5013410449028015
Validation loss: 1.9199679410585793

Epoch: 6| Step: 3
Training loss: 0.8491270542144775
Validation loss: 1.9353957765845842

Epoch: 6| Step: 4
Training loss: 0.3309769034385681
Validation loss: 1.91521071105875

Epoch: 6| Step: 5
Training loss: 0.6966369152069092
Validation loss: 1.8460343960792787

Epoch: 6| Step: 6
Training loss: 0.8808469772338867
Validation loss: 1.7864292924122145

Epoch: 6| Step: 7
Training loss: 0.22503361105918884
Validation loss: 1.778354937030423

Epoch: 6| Step: 8
Training loss: 0.6292439699172974
Validation loss: 1.7703293446571595

Epoch: 6| Step: 9
Training loss: 0.5653567910194397
Validation loss: 1.7591316610254266

Epoch: 6| Step: 10
Training loss: 0.5457006692886353
Validation loss: 1.7640767712746896

Epoch: 6| Step: 11
Training loss: 0.3520403504371643
Validation loss: 1.7390612504815544

Epoch: 6| Step: 12
Training loss: 0.6229923367500305
Validation loss: 1.7589746880274948

Epoch: 6| Step: 13
Training loss: 0.4011615514755249
Validation loss: 1.7490305592936854

Epoch: 236| Step: 0
Training loss: 0.352824866771698
Validation loss: 1.7889031210253317

Epoch: 6| Step: 1
Training loss: 0.4757438600063324
Validation loss: 1.8104138861420334

Epoch: 6| Step: 2
Training loss: 0.5934407711029053
Validation loss: 1.795102124573082

Epoch: 6| Step: 3
Training loss: 0.4553014039993286
Validation loss: 1.8096309708010765

Epoch: 6| Step: 4
Training loss: 0.5867745280265808
Validation loss: 1.8171716441390335

Epoch: 6| Step: 5
Training loss: 0.5777535438537598
Validation loss: 1.8412653015505882

Epoch: 6| Step: 6
Training loss: 0.5484725832939148
Validation loss: 1.8427261165393296

Epoch: 6| Step: 7
Training loss: 0.788275957107544
Validation loss: 1.8344166317293722

Epoch: 6| Step: 8
Training loss: 0.4483906626701355
Validation loss: 1.8503675089087537

Epoch: 6| Step: 9
Training loss: 0.38621431589126587
Validation loss: 1.8724021309165544

Epoch: 6| Step: 10
Training loss: 0.6099022626876831
Validation loss: 1.7933510388097456

Epoch: 6| Step: 11
Training loss: 0.22226053476333618
Validation loss: 1.835258695387071

Epoch: 6| Step: 12
Training loss: 0.4717986583709717
Validation loss: 1.8128668621022215

Epoch: 6| Step: 13
Training loss: 0.6662856936454773
Validation loss: 1.8393153067558043

Epoch: 237| Step: 0
Training loss: 0.6561437845230103
Validation loss: 1.8176137708848523

Epoch: 6| Step: 1
Training loss: 0.3788885474205017
Validation loss: 1.8300660092343566

Epoch: 6| Step: 2
Training loss: 0.5985661149024963
Validation loss: 1.8378123032149447

Epoch: 6| Step: 3
Training loss: 0.5099166631698608
Validation loss: 1.8006079709658058

Epoch: 6| Step: 4
Training loss: 0.588802695274353
Validation loss: 1.8147637369812175

Epoch: 6| Step: 5
Training loss: 0.5468786358833313
Validation loss: 1.8558801617673648

Epoch: 6| Step: 6
Training loss: 0.4307783842086792
Validation loss: 1.8198538877630746

Epoch: 6| Step: 7
Training loss: 0.5119882822036743
Validation loss: 1.8088512600109141

Epoch: 6| Step: 8
Training loss: 0.34043264389038086
Validation loss: 1.8140549954547678

Epoch: 6| Step: 9
Training loss: 0.4186558425426483
Validation loss: 1.8372372376021517

Epoch: 6| Step: 10
Training loss: 0.4639776647090912
Validation loss: 1.8260489586860902

Epoch: 6| Step: 11
Training loss: 0.4049927890300751
Validation loss: 1.8180593457273257

Epoch: 6| Step: 12
Training loss: 0.3600667417049408
Validation loss: 1.81205738423973

Epoch: 6| Step: 13
Training loss: 0.38268160820007324
Validation loss: 1.8540507747280983

Epoch: 238| Step: 0
Training loss: 0.6355470418930054
Validation loss: 1.8688589142214866

Epoch: 6| Step: 1
Training loss: 0.6892076730728149
Validation loss: 1.873780640222693

Epoch: 6| Step: 2
Training loss: 0.29469752311706543
Validation loss: 1.8661129782276769

Epoch: 6| Step: 3
Training loss: 0.43946510553359985
Validation loss: 1.8381326301123506

Epoch: 6| Step: 4
Training loss: 0.2777681350708008
Validation loss: 1.8089486475913756

Epoch: 6| Step: 5
Training loss: 0.6771637797355652
Validation loss: 1.7866200747028473

Epoch: 6| Step: 6
Training loss: 0.5196972489356995
Validation loss: 1.7905704744400517

Epoch: 6| Step: 7
Training loss: 0.4944922924041748
Validation loss: 1.781065660138284

Epoch: 6| Step: 8
Training loss: 0.40644556283950806
Validation loss: 1.7490410804748535

Epoch: 6| Step: 9
Training loss: 0.5443803071975708
Validation loss: 1.771047463981054

Epoch: 6| Step: 10
Training loss: 0.4229394197463989
Validation loss: 1.7541499150696622

Epoch: 6| Step: 11
Training loss: 0.5403823256492615
Validation loss: 1.7352742982167069

Epoch: 6| Step: 12
Training loss: 0.7306268215179443
Validation loss: 1.7335866484590756

Epoch: 6| Step: 13
Training loss: 0.5026068091392517
Validation loss: 1.7742601902254167

Epoch: 239| Step: 0
Training loss: 0.3899780511856079
Validation loss: 1.7526070507623817

Epoch: 6| Step: 1
Training loss: 0.5789293646812439
Validation loss: 1.7526726722717285

Epoch: 6| Step: 2
Training loss: 0.2557482123374939
Validation loss: 1.7704348846148419

Epoch: 6| Step: 3
Training loss: 0.400854229927063
Validation loss: 1.787347161641685

Epoch: 6| Step: 4
Training loss: 0.32096990942955017
Validation loss: 1.7906664212544758

Epoch: 6| Step: 5
Training loss: 0.6178197264671326
Validation loss: 1.7829746354010798

Epoch: 6| Step: 6
Training loss: 0.75818932056427
Validation loss: 1.7910777163761917

Epoch: 6| Step: 7
Training loss: 0.4394749402999878
Validation loss: 1.7875953400006859

Epoch: 6| Step: 8
Training loss: 0.4622914791107178
Validation loss: 1.7416119152499783

Epoch: 6| Step: 9
Training loss: 0.25194162130355835
Validation loss: 1.7598152019644295

Epoch: 6| Step: 10
Training loss: 0.3502054512500763
Validation loss: 1.7202156256603938

Epoch: 6| Step: 11
Training loss: 0.5499447584152222
Validation loss: 1.7286417266373992

Epoch: 6| Step: 12
Training loss: 0.6161820888519287
Validation loss: 1.752125423441651

Epoch: 6| Step: 13
Training loss: 0.7388816475868225
Validation loss: 1.7546077979508268

Epoch: 240| Step: 0
Training loss: 0.5884364247322083
Validation loss: 1.720596267331031

Epoch: 6| Step: 1
Training loss: 0.5118609666824341
Validation loss: 1.721592636518581

Epoch: 6| Step: 2
Training loss: 0.49122172594070435
Validation loss: 1.7275463611848894

Epoch: 6| Step: 3
Training loss: 0.5095334053039551
Validation loss: 1.7722219254380913

Epoch: 6| Step: 4
Training loss: 0.16235551238059998
Validation loss: 1.763031203259704

Epoch: 6| Step: 5
Training loss: 0.44801852107048035
Validation loss: 1.7693991122707244

Epoch: 6| Step: 6
Training loss: 0.46887069940567017
Validation loss: 1.7961343167930521

Epoch: 6| Step: 7
Training loss: 0.33672046661376953
Validation loss: 1.8288934922987414

Epoch: 6| Step: 8
Training loss: 0.639173150062561
Validation loss: 1.843512491513324

Epoch: 6| Step: 9
Training loss: 0.6577103137969971
Validation loss: 1.874469869880266

Epoch: 6| Step: 10
Training loss: 0.30682462453842163
Validation loss: 1.8638168124742405

Epoch: 6| Step: 11
Training loss: 0.5790135860443115
Validation loss: 1.8584841707701325

Epoch: 6| Step: 12
Training loss: 0.28637567162513733
Validation loss: 1.8066253905655236

Epoch: 6| Step: 13
Training loss: 0.5330679416656494
Validation loss: 1.8028228949475031

Epoch: 241| Step: 0
Training loss: 0.4397770166397095
Validation loss: 1.7943047836262693

Epoch: 6| Step: 1
Training loss: 0.6124516725540161
Validation loss: 1.754006886994967

Epoch: 6| Step: 2
Training loss: 0.23223134875297546
Validation loss: 1.7694073466844455

Epoch: 6| Step: 3
Training loss: 0.4960761070251465
Validation loss: 1.729296661192371

Epoch: 6| Step: 4
Training loss: 0.3719909191131592
Validation loss: 1.735288477713062

Epoch: 6| Step: 5
Training loss: 0.5676503777503967
Validation loss: 1.7194786552459962

Epoch: 6| Step: 6
Training loss: 0.40711647272109985
Validation loss: 1.7361015530042752

Epoch: 6| Step: 7
Training loss: 0.4899466335773468
Validation loss: 1.7335574985832296

Epoch: 6| Step: 8
Training loss: 0.45230329036712646
Validation loss: 1.7197698213720833

Epoch: 6| Step: 9
Training loss: 0.6579940319061279
Validation loss: 1.7553771259964153

Epoch: 6| Step: 10
Training loss: 0.4128175377845764
Validation loss: 1.749596680364301

Epoch: 6| Step: 11
Training loss: 0.42327868938446045
Validation loss: 1.7629586727388444

Epoch: 6| Step: 12
Training loss: 0.35909754037857056
Validation loss: 1.7646005679202337

Epoch: 6| Step: 13
Training loss: 0.9586701989173889
Validation loss: 1.7982110592626757

Epoch: 242| Step: 0
Training loss: 0.445748507976532
Validation loss: 1.8388417292666692

Epoch: 6| Step: 1
Training loss: 0.6983907222747803
Validation loss: 1.820134771767483

Epoch: 6| Step: 2
Training loss: 0.43935078382492065
Validation loss: 1.8098598680188578

Epoch: 6| Step: 3
Training loss: 0.3186039924621582
Validation loss: 1.8135801874181277

Epoch: 6| Step: 4
Training loss: 0.25582611560821533
Validation loss: 1.8050959751170168

Epoch: 6| Step: 5
Training loss: 0.39645612239837646
Validation loss: 1.7749824934108283

Epoch: 6| Step: 6
Training loss: 0.648524284362793
Validation loss: 1.7912496559081539

Epoch: 6| Step: 7
Training loss: 0.5206936597824097
Validation loss: 1.7930047986327962

Epoch: 6| Step: 8
Training loss: 0.4123210906982422
Validation loss: 1.762620250384013

Epoch: 6| Step: 9
Training loss: 0.3856341242790222
Validation loss: 1.8074267448917511

Epoch: 6| Step: 10
Training loss: 0.4265880584716797
Validation loss: 1.804540200900006

Epoch: 6| Step: 11
Training loss: 0.5169863700866699
Validation loss: 1.791329603041372

Epoch: 6| Step: 12
Training loss: 0.5947069525718689
Validation loss: 1.7854937327805387

Epoch: 6| Step: 13
Training loss: 0.47783857583999634
Validation loss: 1.8165816876196093

Epoch: 243| Step: 0
Training loss: 0.4151133894920349
Validation loss: 1.793098029269967

Epoch: 6| Step: 1
Training loss: 0.2992043197154999
Validation loss: 1.8312316594585296

Epoch: 6| Step: 2
Training loss: 0.2867003381252289
Validation loss: 1.8045428094043527

Epoch: 6| Step: 3
Training loss: 0.26324641704559326
Validation loss: 1.7868144512176514

Epoch: 6| Step: 4
Training loss: 0.5237380266189575
Validation loss: 1.7476633197517806

Epoch: 6| Step: 5
Training loss: 0.4244978725910187
Validation loss: 1.7475411891937256

Epoch: 6| Step: 6
Training loss: 0.36573243141174316
Validation loss: 1.7606390958191247

Epoch: 6| Step: 7
Training loss: 0.8009441494941711
Validation loss: 1.7441892931538243

Epoch: 6| Step: 8
Training loss: 0.4306594133377075
Validation loss: 1.7534292718415618

Epoch: 6| Step: 9
Training loss: 0.5940793752670288
Validation loss: 1.7893230722796531

Epoch: 6| Step: 10
Training loss: 0.3476642966270447
Validation loss: 1.805868484640634

Epoch: 6| Step: 11
Training loss: 0.5675028562545776
Validation loss: 1.8063545150141562

Epoch: 6| Step: 12
Training loss: 0.5419557094573975
Validation loss: 1.7866557362259075

Epoch: 6| Step: 13
Training loss: 0.20402288436889648
Validation loss: 1.7998942931493123

Epoch: 244| Step: 0
Training loss: 0.5704280138015747
Validation loss: 1.830882013484996

Epoch: 6| Step: 1
Training loss: 0.44531744718551636
Validation loss: 1.8031258160068142

Epoch: 6| Step: 2
Training loss: 0.5487439632415771
Validation loss: 1.8463428469114407

Epoch: 6| Step: 3
Training loss: 0.2615600526332855
Validation loss: 1.8049427437525924

Epoch: 6| Step: 4
Training loss: 0.3898319900035858
Validation loss: 1.823606773089337

Epoch: 6| Step: 5
Training loss: 0.44557252526283264
Validation loss: 1.8105159485211937

Epoch: 6| Step: 6
Training loss: 0.2701525390148163
Validation loss: 1.8287160883667648

Epoch: 6| Step: 7
Training loss: 0.4563261866569519
Validation loss: 1.791606681321257

Epoch: 6| Step: 8
Training loss: 0.45816609263420105
Validation loss: 1.7676545253363989

Epoch: 6| Step: 9
Training loss: 0.40946483612060547
Validation loss: 1.7643735703601633

Epoch: 6| Step: 10
Training loss: 0.3808819353580475
Validation loss: 1.7773467276685981

Epoch: 6| Step: 11
Training loss: 0.46896159648895264
Validation loss: 1.7757426974593953

Epoch: 6| Step: 12
Training loss: 0.49031275510787964
Validation loss: 1.8017781716521069

Epoch: 6| Step: 13
Training loss: 0.5350930094718933
Validation loss: 1.7755838978675105

Epoch: 245| Step: 0
Training loss: 0.3741512894630432
Validation loss: 1.7701585292816162

Epoch: 6| Step: 1
Training loss: 0.8014363050460815
Validation loss: 1.7449719162397488

Epoch: 6| Step: 2
Training loss: 0.43522730469703674
Validation loss: 1.729612179981765

Epoch: 6| Step: 3
Training loss: 0.6600158214569092
Validation loss: 1.768399448804958

Epoch: 6| Step: 4
Training loss: 0.3250020742416382
Validation loss: 1.7148788923858314

Epoch: 6| Step: 5
Training loss: 0.6364160776138306
Validation loss: 1.7244739135106404

Epoch: 6| Step: 6
Training loss: 0.3119468092918396
Validation loss: 1.70888352394104

Epoch: 6| Step: 7
Training loss: 0.536222517490387
Validation loss: 1.763040118320014

Epoch: 6| Step: 8
Training loss: 0.2387460321187973
Validation loss: 1.7716149027629564

Epoch: 6| Step: 9
Training loss: 0.5774276256561279
Validation loss: 1.777344790838098

Epoch: 6| Step: 10
Training loss: 0.39823389053344727
Validation loss: 1.7945505803631199

Epoch: 6| Step: 11
Training loss: 0.3707675337791443
Validation loss: 1.8215697696132045

Epoch: 6| Step: 12
Training loss: 0.35604143142700195
Validation loss: 1.8140542853263117

Epoch: 6| Step: 13
Training loss: 0.2848525941371918
Validation loss: 1.8239224726153958

Epoch: 246| Step: 0
Training loss: 0.47648149728775024
Validation loss: 1.8215529713579404

Epoch: 6| Step: 1
Training loss: 0.5666314959526062
Validation loss: 1.863472879573863

Epoch: 6| Step: 2
Training loss: 0.6459363698959351
Validation loss: 1.8172069775160922

Epoch: 6| Step: 3
Training loss: 0.4464598298072815
Validation loss: 1.8098761061186432

Epoch: 6| Step: 4
Training loss: 0.3572109341621399
Validation loss: 1.7979710409718175

Epoch: 6| Step: 5
Training loss: 0.4901575744152069
Validation loss: 1.7879066134011874

Epoch: 6| Step: 6
Training loss: 0.5504745244979858
Validation loss: 1.7655921315634122

Epoch: 6| Step: 7
Training loss: 0.23893237113952637
Validation loss: 1.7681450113173454

Epoch: 6| Step: 8
Training loss: 0.2939586043357849
Validation loss: 1.7920885073241366

Epoch: 6| Step: 9
Training loss: 0.6522966623306274
Validation loss: 1.7881919068674887

Epoch: 6| Step: 10
Training loss: 0.666228175163269
Validation loss: 1.8216531712521788

Epoch: 6| Step: 11
Training loss: 0.4289044439792633
Validation loss: 1.8251605828603108

Epoch: 6| Step: 12
Training loss: 0.6816078424453735
Validation loss: 1.783062409329158

Epoch: 6| Step: 13
Training loss: 0.2227771282196045
Validation loss: 1.7148142630054104

Epoch: 247| Step: 0
Training loss: 0.5871411561965942
Validation loss: 1.7260950316664994

Epoch: 6| Step: 1
Training loss: 0.34655284881591797
Validation loss: 1.73501254153508

Epoch: 6| Step: 2
Training loss: 0.3404228091239929
Validation loss: 1.7451831935554423

Epoch: 6| Step: 3
Training loss: 0.6097285151481628
Validation loss: 1.7648221318439772

Epoch: 6| Step: 4
Training loss: 0.44017553329467773
Validation loss: 1.773974125103284

Epoch: 6| Step: 5
Training loss: 0.43593016266822815
Validation loss: 1.783430842943089

Epoch: 6| Step: 6
Training loss: 0.7494910359382629
Validation loss: 1.792962287061958

Epoch: 6| Step: 7
Training loss: 0.5132661461830139
Validation loss: 1.7642108407071841

Epoch: 6| Step: 8
Training loss: 0.4470534026622772
Validation loss: 1.7695306834354196

Epoch: 6| Step: 9
Training loss: 0.4386940598487854
Validation loss: 1.7232416240117883

Epoch: 6| Step: 10
Training loss: 0.5717566013336182
Validation loss: 1.70900982938787

Epoch: 6| Step: 11
Training loss: 0.3714138865470886
Validation loss: 1.7235922967233965

Epoch: 6| Step: 12
Training loss: 0.28727102279663086
Validation loss: 1.683440758335975

Epoch: 6| Step: 13
Training loss: 0.3403993844985962
Validation loss: 1.6738234694286058

Epoch: 248| Step: 0
Training loss: 0.38941240310668945
Validation loss: 1.7014385974535378

Epoch: 6| Step: 1
Training loss: 0.47359853982925415
Validation loss: 1.7645048761880526

Epoch: 6| Step: 2
Training loss: 0.18566802144050598
Validation loss: 1.7378740618305821

Epoch: 6| Step: 3
Training loss: 0.5224281549453735
Validation loss: 1.7305749065132552

Epoch: 6| Step: 4
Training loss: 0.7354234457015991
Validation loss: 1.743093599555313

Epoch: 6| Step: 5
Training loss: 0.5086547136306763
Validation loss: 1.7657293465829664

Epoch: 6| Step: 6
Training loss: 0.34206926822662354
Validation loss: 1.7893520683370612

Epoch: 6| Step: 7
Training loss: 0.5769294500350952
Validation loss: 1.7842659155527751

Epoch: 6| Step: 8
Training loss: 0.4948995113372803
Validation loss: 1.807028635855644

Epoch: 6| Step: 9
Training loss: 0.48654380440711975
Validation loss: 1.7966269549503122

Epoch: 6| Step: 10
Training loss: 0.2018185406923294
Validation loss: 1.8268629145878617

Epoch: 6| Step: 11
Training loss: 0.8110203742980957
Validation loss: 1.78254529224929

Epoch: 6| Step: 12
Training loss: 0.3142322897911072
Validation loss: 1.7684939010168916

Epoch: 6| Step: 13
Training loss: 0.13536739349365234
Validation loss: 1.7545628470759238

Epoch: 249| Step: 0
Training loss: 0.3683995008468628
Validation loss: 1.752424330480637

Epoch: 6| Step: 1
Training loss: 0.3864794373512268
Validation loss: 1.7333246610497917

Epoch: 6| Step: 2
Training loss: 0.5899477005004883
Validation loss: 1.7227611772475704

Epoch: 6| Step: 3
Training loss: 0.48653361201286316
Validation loss: 1.7044860714225358

Epoch: 6| Step: 4
Training loss: 0.4899558424949646
Validation loss: 1.6874694414036249

Epoch: 6| Step: 5
Training loss: 0.49346622824668884
Validation loss: 1.7140120242231636

Epoch: 6| Step: 6
Training loss: 0.3027510643005371
Validation loss: 1.7479732523682296

Epoch: 6| Step: 7
Training loss: 0.2873969078063965
Validation loss: 1.7507765754576652

Epoch: 6| Step: 8
Training loss: 0.512533962726593
Validation loss: 1.803584401325513

Epoch: 6| Step: 9
Training loss: 0.3707005977630615
Validation loss: 1.791292449479462

Epoch: 6| Step: 10
Training loss: 0.27223166823387146
Validation loss: 1.818482260550222

Epoch: 6| Step: 11
Training loss: 0.29925304651260376
Validation loss: 1.8099378514033493

Epoch: 6| Step: 12
Training loss: 0.5645394325256348
Validation loss: 1.82819749206625

Epoch: 6| Step: 13
Training loss: 1.025526523590088
Validation loss: 1.8231028561951013

Epoch: 250| Step: 0
Training loss: 0.49941444396972656
Validation loss: 1.8109838603645243

Epoch: 6| Step: 1
Training loss: 0.3287394344806671
Validation loss: 1.802976131439209

Epoch: 6| Step: 2
Training loss: 0.4030172526836395
Validation loss: 1.7630077331296858

Epoch: 6| Step: 3
Training loss: 0.3519333302974701
Validation loss: 1.7756849078721897

Epoch: 6| Step: 4
Training loss: 0.3032969534397125
Validation loss: 1.751543906427199

Epoch: 6| Step: 5
Training loss: 0.18350476026535034
Validation loss: 1.7797888735289216

Epoch: 6| Step: 6
Training loss: 0.44671887159347534
Validation loss: 1.7674764971579275

Epoch: 6| Step: 7
Training loss: 0.37678635120391846
Validation loss: 1.778814149159257

Epoch: 6| Step: 8
Training loss: 0.42521440982818604
Validation loss: 1.746110257282052

Epoch: 6| Step: 9
Training loss: 0.3865908086299896
Validation loss: 1.7535571564910233

Epoch: 6| Step: 10
Training loss: 0.6112813353538513
Validation loss: 1.7253374047176813

Epoch: 6| Step: 11
Training loss: 0.47071918845176697
Validation loss: 1.7582878528102752

Epoch: 6| Step: 12
Training loss: 0.42295563220977783
Validation loss: 1.7412284035836496

Epoch: 6| Step: 13
Training loss: 0.27369534969329834
Validation loss: 1.7871193770439393

Epoch: 251| Step: 0
Training loss: 0.29367557168006897
Validation loss: 1.76608270342632

Epoch: 6| Step: 1
Training loss: 0.32713159918785095
Validation loss: 1.7843371296441684

Epoch: 6| Step: 2
Training loss: 0.21866731345653534
Validation loss: 1.784099244302319

Epoch: 6| Step: 3
Training loss: 0.4852084517478943
Validation loss: 1.7770551814827868

Epoch: 6| Step: 4
Training loss: 0.5861802101135254
Validation loss: 1.782779453903116

Epoch: 6| Step: 5
Training loss: 0.7010847926139832
Validation loss: 1.7369186237294187

Epoch: 6| Step: 6
Training loss: 0.36251112818717957
Validation loss: 1.728177015499402

Epoch: 6| Step: 7
Training loss: 0.5213766694068909
Validation loss: 1.7628696759541829

Epoch: 6| Step: 8
Training loss: 0.3190910220146179
Validation loss: 1.7465376674488027

Epoch: 6| Step: 9
Training loss: 0.39874503016471863
Validation loss: 1.778659205282888

Epoch: 6| Step: 10
Training loss: 0.44341978430747986
Validation loss: 1.7468477679837136

Epoch: 6| Step: 11
Training loss: 0.45635271072387695
Validation loss: 1.7665566936615975

Epoch: 6| Step: 12
Training loss: 0.4644874036312103
Validation loss: 1.7505119718531126

Epoch: 6| Step: 13
Training loss: 0.38041362166404724
Validation loss: 1.7753743189637379

Epoch: 252| Step: 0
Training loss: 0.23472648859024048
Validation loss: 1.758984226052479

Epoch: 6| Step: 1
Training loss: 0.3059872090816498
Validation loss: 1.7909097504872147

Epoch: 6| Step: 2
Training loss: 0.3216703534126282
Validation loss: 1.7685977938354656

Epoch: 6| Step: 3
Training loss: 0.22592268884181976
Validation loss: 1.7491270431908228

Epoch: 6| Step: 4
Training loss: 0.34298327565193176
Validation loss: 1.7546089362072688

Epoch: 6| Step: 5
Training loss: 0.41993939876556396
Validation loss: 1.7807580001892582

Epoch: 6| Step: 6
Training loss: 0.281609445810318
Validation loss: 1.7638796811462731

Epoch: 6| Step: 7
Training loss: 0.5698047280311584
Validation loss: 1.7578463785109981

Epoch: 6| Step: 8
Training loss: 0.2429506927728653
Validation loss: 1.7497297922770183

Epoch: 6| Step: 9
Training loss: 0.4236457943916321
Validation loss: 1.736103625707729

Epoch: 6| Step: 10
Training loss: 0.41942405700683594
Validation loss: 1.7382875296377367

Epoch: 6| Step: 11
Training loss: 0.7685195803642273
Validation loss: 1.7423490324328024

Epoch: 6| Step: 12
Training loss: 0.4974591135978699
Validation loss: 1.7444823044602589

Epoch: 6| Step: 13
Training loss: 0.42891982197761536
Validation loss: 1.72384931964259

Epoch: 253| Step: 0
Training loss: 0.2828245162963867
Validation loss: 1.708598010001644

Epoch: 6| Step: 1
Training loss: 0.6658999919891357
Validation loss: 1.719588069505589

Epoch: 6| Step: 2
Training loss: 0.401947021484375
Validation loss: 1.7142533192070581

Epoch: 6| Step: 3
Training loss: 0.6440698504447937
Validation loss: 1.7236617508754934

Epoch: 6| Step: 4
Training loss: 0.28403589129447937
Validation loss: 1.7047323693511307

Epoch: 6| Step: 5
Training loss: 0.23756125569343567
Validation loss: 1.7058114210764568

Epoch: 6| Step: 6
Training loss: 0.3813977837562561
Validation loss: 1.6925302936184792

Epoch: 6| Step: 7
Training loss: 0.31565460562705994
Validation loss: 1.7057624696403422

Epoch: 6| Step: 8
Training loss: 0.4983389675617218
Validation loss: 1.761734313862298

Epoch: 6| Step: 9
Training loss: 0.6054456830024719
Validation loss: 1.769578250505591

Epoch: 6| Step: 10
Training loss: 0.2634485065937042
Validation loss: 1.752750309564734

Epoch: 6| Step: 11
Training loss: 0.5078297257423401
Validation loss: 1.7839326973884337

Epoch: 6| Step: 12
Training loss: 0.4193580448627472
Validation loss: 1.7659179382426764

Epoch: 6| Step: 13
Training loss: 0.09530798345804214
Validation loss: 1.7730388641357422

Epoch: 254| Step: 0
Training loss: 0.4431535601615906
Validation loss: 1.7620560379438504

Epoch: 6| Step: 1
Training loss: 0.6367225050926208
Validation loss: 1.7539022276478429

Epoch: 6| Step: 2
Training loss: 0.39347517490386963
Validation loss: 1.7448137165397726

Epoch: 6| Step: 3
Training loss: 0.42579981684684753
Validation loss: 1.7636092619229389

Epoch: 6| Step: 4
Training loss: 0.376251220703125
Validation loss: 1.7791576898226173

Epoch: 6| Step: 5
Training loss: 0.38328516483306885
Validation loss: 1.7706179913654123

Epoch: 6| Step: 6
Training loss: 0.28495025634765625
Validation loss: 1.7566970945686422

Epoch: 6| Step: 7
Training loss: 0.3023761212825775
Validation loss: 1.788766235433599

Epoch: 6| Step: 8
Training loss: 0.20946231484413147
Validation loss: 1.7520082471191243

Epoch: 6| Step: 9
Training loss: 0.2642011046409607
Validation loss: 1.7483055732583488

Epoch: 6| Step: 10
Training loss: 0.3526611030101776
Validation loss: 1.7729899883270264

Epoch: 6| Step: 11
Training loss: 0.4724762439727783
Validation loss: 1.7805339213340514

Epoch: 6| Step: 12
Training loss: 0.47353771328926086
Validation loss: 1.7580979293392551

Epoch: 6| Step: 13
Training loss: 0.31939074397087097
Validation loss: 1.7541999804076327

Epoch: 255| Step: 0
Training loss: 0.5216976404190063
Validation loss: 1.7444074064172723

Epoch: 6| Step: 1
Training loss: 0.4931178092956543
Validation loss: 1.7388523611971127

Epoch: 6| Step: 2
Training loss: 0.29405519366264343
Validation loss: 1.7439998580563454

Epoch: 6| Step: 3
Training loss: 0.30043286085128784
Validation loss: 1.7707997855319773

Epoch: 6| Step: 4
Training loss: 0.4804973602294922
Validation loss: 1.7864127979483655

Epoch: 6| Step: 5
Training loss: 0.24367959797382355
Validation loss: 1.7754408774837371

Epoch: 6| Step: 6
Training loss: 0.2795112729072571
Validation loss: 1.788270773426179

Epoch: 6| Step: 7
Training loss: 0.4100036025047302
Validation loss: 1.7966797467200988

Epoch: 6| Step: 8
Training loss: 0.40581995248794556
Validation loss: 1.7841340649512507

Epoch: 6| Step: 9
Training loss: 0.5492939352989197
Validation loss: 1.73701613180099

Epoch: 6| Step: 10
Training loss: 0.5105623006820679
Validation loss: 1.7850527391638806

Epoch: 6| Step: 11
Training loss: 0.3546978831291199
Validation loss: 1.7534016575864566

Epoch: 6| Step: 12
Training loss: 0.2525010108947754
Validation loss: 1.7268379913863314

Epoch: 6| Step: 13
Training loss: 0.37698113918304443
Validation loss: 1.731452149729575

Epoch: 256| Step: 0
Training loss: 0.45914942026138306
Validation loss: 1.7251955732222526

Epoch: 6| Step: 1
Training loss: 0.3266843557357788
Validation loss: 1.7035219156613914

Epoch: 6| Step: 2
Training loss: 0.6144422888755798
Validation loss: 1.7089499132607573

Epoch: 6| Step: 3
Training loss: 0.4308716058731079
Validation loss: 1.6682589695017824

Epoch: 6| Step: 4
Training loss: 0.3511078953742981
Validation loss: 1.6749990012056084

Epoch: 6| Step: 5
Training loss: 0.34399306774139404
Validation loss: 1.6657243056963849

Epoch: 6| Step: 6
Training loss: 0.29282253980636597
Validation loss: 1.67258208797824

Epoch: 6| Step: 7
Training loss: 0.33557063341140747
Validation loss: 1.6953431572965396

Epoch: 6| Step: 8
Training loss: 0.5302178263664246
Validation loss: 1.6910634220287364

Epoch: 6| Step: 9
Training loss: 0.3954942226409912
Validation loss: 1.6255630716200797

Epoch: 6| Step: 10
Training loss: 0.43413183093070984
Validation loss: 1.6948928140824842

Epoch: 6| Step: 11
Training loss: 0.3228098750114441
Validation loss: 1.6796918197344708

Epoch: 6| Step: 12
Training loss: 0.31970956921577454
Validation loss: 1.7123658772437804

Epoch: 6| Step: 13
Training loss: 0.14785833656787872
Validation loss: 1.6931855140193817

Epoch: 257| Step: 0
Training loss: 0.22114546597003937
Validation loss: 1.697276428181638

Epoch: 6| Step: 1
Training loss: 0.49280065298080444
Validation loss: 1.703900835847342

Epoch: 6| Step: 2
Training loss: 0.47882533073425293
Validation loss: 1.699621840189862

Epoch: 6| Step: 3
Training loss: 0.49559488892555237
Validation loss: 1.7189323030492312

Epoch: 6| Step: 4
Training loss: 0.20783469080924988
Validation loss: 1.7249787725428098

Epoch: 6| Step: 5
Training loss: 0.3144156336784363
Validation loss: 1.728525968008144

Epoch: 6| Step: 6
Training loss: 0.35961827635765076
Validation loss: 1.7714827675973215

Epoch: 6| Step: 7
Training loss: 0.26673686504364014
Validation loss: 1.7872438148785663

Epoch: 6| Step: 8
Training loss: 0.3948899805545807
Validation loss: 1.7610666969771027

Epoch: 6| Step: 9
Training loss: 0.39554062485694885
Validation loss: 1.7556579356552453

Epoch: 6| Step: 10
Training loss: 0.38912302255630493
Validation loss: 1.7151208295617053

Epoch: 6| Step: 11
Training loss: 0.25373509526252747
Validation loss: 1.6998004503147577

Epoch: 6| Step: 12
Training loss: 0.6679714918136597
Validation loss: 1.7003601289564563

Epoch: 6| Step: 13
Training loss: 0.45954322814941406
Validation loss: 1.7114148883409397

Epoch: 258| Step: 0
Training loss: 0.5599777698516846
Validation loss: 1.7217753253957278

Epoch: 6| Step: 1
Training loss: 0.5510319471359253
Validation loss: 1.7390291767735635

Epoch: 6| Step: 2
Training loss: 0.37880557775497437
Validation loss: 1.7177692280020764

Epoch: 6| Step: 3
Training loss: 0.23148693144321442
Validation loss: 1.7435714108969576

Epoch: 6| Step: 4
Training loss: 0.32430747151374817
Validation loss: 1.7441168318512619

Epoch: 6| Step: 5
Training loss: 0.220883309841156
Validation loss: 1.7344567352725613

Epoch: 6| Step: 6
Training loss: 0.3884769678115845
Validation loss: 1.727828392418482

Epoch: 6| Step: 7
Training loss: 0.4105473756790161
Validation loss: 1.7307165553492885

Epoch: 6| Step: 8
Training loss: 0.3147062659263611
Validation loss: 1.72657310962677

Epoch: 6| Step: 9
Training loss: 0.09616658091545105
Validation loss: 1.7337287600322435

Epoch: 6| Step: 10
Training loss: 0.39463484287261963
Validation loss: 1.743882522788099

Epoch: 6| Step: 11
Training loss: 0.38747018575668335
Validation loss: 1.7543335025028517

Epoch: 6| Step: 12
Training loss: 0.3851372003555298
Validation loss: 1.725059865623392

Epoch: 6| Step: 13
Training loss: 0.49167102575302124
Validation loss: 1.720237539660546

Epoch: 259| Step: 0
Training loss: 0.3422546982765198
Validation loss: 1.6926890342466292

Epoch: 6| Step: 1
Training loss: 0.31281381845474243
Validation loss: 1.6914992819550216

Epoch: 6| Step: 2
Training loss: 0.35914376378059387
Validation loss: 1.7085008787852463

Epoch: 6| Step: 3
Training loss: 0.667709231376648
Validation loss: 1.7121356264237435

Epoch: 6| Step: 4
Training loss: 0.30919384956359863
Validation loss: 1.6963469136145808

Epoch: 6| Step: 5
Training loss: 0.4135170578956604
Validation loss: 1.7210729250343897

Epoch: 6| Step: 6
Training loss: 0.46470406651496887
Validation loss: 1.718587689502265

Epoch: 6| Step: 7
Training loss: 0.31068500876426697
Validation loss: 1.7406242611587688

Epoch: 6| Step: 8
Training loss: 0.40737929940223694
Validation loss: 1.6855946074249923

Epoch: 6| Step: 9
Training loss: 0.20430929958820343
Validation loss: 1.7225843180892288

Epoch: 6| Step: 10
Training loss: 0.3770916759967804
Validation loss: 1.721983189223915

Epoch: 6| Step: 11
Training loss: 0.3162350058555603
Validation loss: 1.7407545146121775

Epoch: 6| Step: 12
Training loss: 0.4126994013786316
Validation loss: 1.7202034445219143

Epoch: 6| Step: 13
Training loss: 0.4772284924983978
Validation loss: 1.6784591751713906

Epoch: 260| Step: 0
Training loss: 0.2995157837867737
Validation loss: 1.6648665012851838

Epoch: 6| Step: 1
Training loss: 0.439377099275589
Validation loss: 1.6875022098582277

Epoch: 6| Step: 2
Training loss: 0.3360753655433655
Validation loss: 1.704894801621796

Epoch: 6| Step: 3
Training loss: 0.24203255772590637
Validation loss: 1.7134498139863372

Epoch: 6| Step: 4
Training loss: 0.3923136591911316
Validation loss: 1.6985927602296234

Epoch: 6| Step: 5
Training loss: 0.32122501730918884
Validation loss: 1.7221021959858556

Epoch: 6| Step: 6
Training loss: 0.644668698310852
Validation loss: 1.6802244147946757

Epoch: 6| Step: 7
Training loss: 0.21240763366222382
Validation loss: 1.7213041320923836

Epoch: 6| Step: 8
Training loss: 0.425330251455307
Validation loss: 1.7353369882029872

Epoch: 6| Step: 9
Training loss: 0.3375886380672455
Validation loss: 1.748982576913731

Epoch: 6| Step: 10
Training loss: 0.4104667603969574
Validation loss: 1.7443278528028918

Epoch: 6| Step: 11
Training loss: 0.29884231090545654
Validation loss: 1.7651705139426774

Epoch: 6| Step: 12
Training loss: 0.33965879678726196
Validation loss: 1.7722189298240087

Epoch: 6| Step: 13
Training loss: 0.26561152935028076
Validation loss: 1.7243043709826726

Epoch: 261| Step: 0
Training loss: 0.2644980251789093
Validation loss: 1.7225890364698184

Epoch: 6| Step: 1
Training loss: 0.4202044904232025
Validation loss: 1.72919838787407

Epoch: 6| Step: 2
Training loss: 0.33761394023895264
Validation loss: 1.7156210278951993

Epoch: 6| Step: 3
Training loss: 0.39110785722732544
Validation loss: 1.727011222993174

Epoch: 6| Step: 4
Training loss: 0.36501437425613403
Validation loss: 1.7137266743567683

Epoch: 6| Step: 5
Training loss: 0.28046953678131104
Validation loss: 1.6931072819617488

Epoch: 6| Step: 6
Training loss: 0.2779349684715271
Validation loss: 1.7151197374507945

Epoch: 6| Step: 7
Training loss: 0.3148857355117798
Validation loss: 1.7467529145620202

Epoch: 6| Step: 8
Training loss: 0.26974719762802124
Validation loss: 1.7308514579649894

Epoch: 6| Step: 9
Training loss: 0.3212587833404541
Validation loss: 1.7328278326219129

Epoch: 6| Step: 10
Training loss: 0.3189275860786438
Validation loss: 1.7433600553902246

Epoch: 6| Step: 11
Training loss: 0.5219947099685669
Validation loss: 1.752551999143375

Epoch: 6| Step: 12
Training loss: 0.21080593764781952
Validation loss: 1.7436734399487894

Epoch: 6| Step: 13
Training loss: 0.8102231621742249
Validation loss: 1.7480518433355516

Epoch: 262| Step: 0
Training loss: 0.4677553176879883
Validation loss: 1.740205228969615

Epoch: 6| Step: 1
Training loss: 0.414644718170166
Validation loss: 1.7003374458641134

Epoch: 6| Step: 2
Training loss: 0.2755559980869293
Validation loss: 1.748630169899233

Epoch: 6| Step: 3
Training loss: 0.46778565645217896
Validation loss: 1.6964236151787542

Epoch: 6| Step: 4
Training loss: 0.2016420066356659
Validation loss: 1.6898603080421366

Epoch: 6| Step: 5
Training loss: 0.33845680952072144
Validation loss: 1.6805964336600354

Epoch: 6| Step: 6
Training loss: 0.36151981353759766
Validation loss: 1.669861106462376

Epoch: 6| Step: 7
Training loss: 0.32671841979026794
Validation loss: 1.708655595779419

Epoch: 6| Step: 8
Training loss: 0.3544802665710449
Validation loss: 1.7134783485884308

Epoch: 6| Step: 9
Training loss: 0.46865418553352356
Validation loss: 1.7503288510025188

Epoch: 6| Step: 10
Training loss: 0.4277827739715576
Validation loss: 1.7497023908040856

Epoch: 6| Step: 11
Training loss: 0.42044565081596375
Validation loss: 1.7442853655866397

Epoch: 6| Step: 12
Training loss: 0.5349234342575073
Validation loss: 1.7688518365224202

Epoch: 6| Step: 13
Training loss: 0.42327138781547546
Validation loss: 1.7780190398616176

Epoch: 263| Step: 0
Training loss: 0.3600088357925415
Validation loss: 1.7111884304272231

Epoch: 6| Step: 1
Training loss: 0.46256470680236816
Validation loss: 1.7394005957470144

Epoch: 6| Step: 2
Training loss: 0.3207619786262512
Validation loss: 1.752480701733661

Epoch: 6| Step: 3
Training loss: 0.37039411067962646
Validation loss: 1.7404178227147749

Epoch: 6| Step: 4
Training loss: 0.5523245930671692
Validation loss: 1.7443549761208155

Epoch: 6| Step: 5
Training loss: 0.29296162724494934
Validation loss: 1.7195189973359466

Epoch: 6| Step: 6
Training loss: 0.5056682825088501
Validation loss: 1.7112693389256795

Epoch: 6| Step: 7
Training loss: 0.605982780456543
Validation loss: 1.68547619799132

Epoch: 6| Step: 8
Training loss: 0.34252071380615234
Validation loss: 1.6730092994628414

Epoch: 6| Step: 9
Training loss: 0.2018056958913803
Validation loss: 1.7041888160090293

Epoch: 6| Step: 10
Training loss: 0.31485337018966675
Validation loss: 1.7449488742377168

Epoch: 6| Step: 11
Training loss: 0.20500507950782776
Validation loss: 1.74729738953293

Epoch: 6| Step: 12
Training loss: 0.27653053402900696
Validation loss: 1.7549419390257968

Epoch: 6| Step: 13
Training loss: 0.35105016827583313
Validation loss: 1.7728445863211026

Epoch: 264| Step: 0
Training loss: 0.3334987759590149
Validation loss: 1.7275785297475836

Epoch: 6| Step: 1
Training loss: 0.28286558389663696
Validation loss: 1.7286665413969307

Epoch: 6| Step: 2
Training loss: 0.20207136869430542
Validation loss: 1.7528580157987532

Epoch: 6| Step: 3
Training loss: 0.38502562046051025
Validation loss: 1.7453563854258547

Epoch: 6| Step: 4
Training loss: 0.5276103615760803
Validation loss: 1.7366086334310553

Epoch: 6| Step: 5
Training loss: 0.271030068397522
Validation loss: 1.7532191955915062

Epoch: 6| Step: 6
Training loss: 0.173686683177948
Validation loss: 1.7488712521009548

Epoch: 6| Step: 7
Training loss: 0.4679333567619324
Validation loss: 1.7568538881117297

Epoch: 6| Step: 8
Training loss: 0.4134768843650818
Validation loss: 1.7524935404459636

Epoch: 6| Step: 9
Training loss: 0.6760329008102417
Validation loss: 1.731260089464085

Epoch: 6| Step: 10
Training loss: 0.529956579208374
Validation loss: 1.7591175827928769

Epoch: 6| Step: 11
Training loss: 0.41455334424972534
Validation loss: 1.7338752400490545

Epoch: 6| Step: 12
Training loss: 0.38809525966644287
Validation loss: 1.7192889310980355

Epoch: 6| Step: 13
Training loss: 0.23945876955986023
Validation loss: 1.7533006398908553

Epoch: 265| Step: 0
Training loss: 0.4254109561443329
Validation loss: 1.743110285010389

Epoch: 6| Step: 1
Training loss: 0.28877586126327515
Validation loss: 1.7316049401478102

Epoch: 6| Step: 2
Training loss: 0.4455346465110779
Validation loss: 1.7186332197599514

Epoch: 6| Step: 3
Training loss: 0.25977784395217896
Validation loss: 1.7002832005100865

Epoch: 6| Step: 4
Training loss: 0.28355908393859863
Validation loss: 1.7009435533195414

Epoch: 6| Step: 5
Training loss: 0.2429259717464447
Validation loss: 1.6868089578484977

Epoch: 6| Step: 6
Training loss: 0.43938982486724854
Validation loss: 1.6455420806843748

Epoch: 6| Step: 7
Training loss: 0.5157454609870911
Validation loss: 1.6249920052866782

Epoch: 6| Step: 8
Training loss: 0.15948502719402313
Validation loss: 1.625467364506055

Epoch: 6| Step: 9
Training loss: 0.433454692363739
Validation loss: 1.6300844133541148

Epoch: 6| Step: 10
Training loss: 0.20530307292938232
Validation loss: 1.6437165275696786

Epoch: 6| Step: 11
Training loss: 0.3809511661529541
Validation loss: 1.6724827251126688

Epoch: 6| Step: 12
Training loss: 0.3145882487297058
Validation loss: 1.7135054244790027

Epoch: 6| Step: 13
Training loss: 0.4285997450351715
Validation loss: 1.725104183279058

Epoch: 266| Step: 0
Training loss: 0.3530866503715515
Validation loss: 1.7493012361629035

Epoch: 6| Step: 1
Training loss: 0.4762886166572571
Validation loss: 1.7541637305290467

Epoch: 6| Step: 2
Training loss: 0.359691858291626
Validation loss: 1.7298690349824968

Epoch: 6| Step: 3
Training loss: 0.46214017271995544
Validation loss: 1.7890321003493441

Epoch: 6| Step: 4
Training loss: 0.36358606815338135
Validation loss: 1.7519586342637257

Epoch: 6| Step: 5
Training loss: 0.27145159244537354
Validation loss: 1.7132789076015513

Epoch: 6| Step: 6
Training loss: 0.34124886989593506
Validation loss: 1.74447218320703

Epoch: 6| Step: 7
Training loss: 0.4606054425239563
Validation loss: 1.7186821301778157

Epoch: 6| Step: 8
Training loss: 0.18037979304790497
Validation loss: 1.7122059413181838

Epoch: 6| Step: 9
Training loss: 0.3450493812561035
Validation loss: 1.6970382659666

Epoch: 6| Step: 10
Training loss: 0.30001041293144226
Validation loss: 1.6838324275068057

Epoch: 6| Step: 11
Training loss: 0.29272952675819397
Validation loss: 1.6823703755614579

Epoch: 6| Step: 12
Training loss: 0.48007363080978394
Validation loss: 1.699161378286218

Epoch: 6| Step: 13
Training loss: 0.23202064633369446
Validation loss: 1.6849157271846649

Epoch: 267| Step: 0
Training loss: 0.31740742921829224
Validation loss: 1.6628101205313077

Epoch: 6| Step: 1
Training loss: 0.22286555171012878
Validation loss: 1.708216913284794

Epoch: 6| Step: 2
Training loss: 0.4691942036151886
Validation loss: 1.6834015794979629

Epoch: 6| Step: 3
Training loss: 0.14916013181209564
Validation loss: 1.704838647637316

Epoch: 6| Step: 4
Training loss: 0.374068945646286
Validation loss: 1.7138296993829871

Epoch: 6| Step: 5
Training loss: 0.3901195526123047
Validation loss: 1.6861065690235426

Epoch: 6| Step: 6
Training loss: 0.24499765038490295
Validation loss: 1.7220250073299612

Epoch: 6| Step: 7
Training loss: 0.4031161069869995
Validation loss: 1.7349268992741902

Epoch: 6| Step: 8
Training loss: 0.4565632939338684
Validation loss: 1.743665434980905

Epoch: 6| Step: 9
Training loss: 0.26607418060302734
Validation loss: 1.7465873354224748

Epoch: 6| Step: 10
Training loss: 0.10922585427761078
Validation loss: 1.740849277024628

Epoch: 6| Step: 11
Training loss: 0.27885064482688904
Validation loss: 1.7225918154562674

Epoch: 6| Step: 12
Training loss: 0.609544038772583
Validation loss: 1.7508632739384968

Epoch: 6| Step: 13
Training loss: 0.43026939034461975
Validation loss: 1.763591210047404

Epoch: 268| Step: 0
Training loss: 0.3234535753726959
Validation loss: 1.7671304107994161

Epoch: 6| Step: 1
Training loss: 0.448096364736557
Validation loss: 1.7353302676190612

Epoch: 6| Step: 2
Training loss: 0.41356366872787476
Validation loss: 1.7470790955328173

Epoch: 6| Step: 3
Training loss: 0.17908203601837158
Validation loss: 1.7253278795109

Epoch: 6| Step: 4
Training loss: 0.19027018547058105
Validation loss: 1.707444675507084

Epoch: 6| Step: 5
Training loss: 0.6291756629943848
Validation loss: 1.695139726003011

Epoch: 6| Step: 6
Training loss: 0.294036328792572
Validation loss: 1.7000787758058118

Epoch: 6| Step: 7
Training loss: 0.3901258111000061
Validation loss: 1.7006648535369544

Epoch: 6| Step: 8
Training loss: 0.27963483333587646
Validation loss: 1.6878829707381546

Epoch: 6| Step: 9
Training loss: 0.41811609268188477
Validation loss: 1.7025953518447055

Epoch: 6| Step: 10
Training loss: 0.2626092731952667
Validation loss: 1.696808659902183

Epoch: 6| Step: 11
Training loss: 0.26837360858917236
Validation loss: 1.7506592504439815

Epoch: 6| Step: 12
Training loss: 0.11573607474565506
Validation loss: 1.7060300970590243

Epoch: 6| Step: 13
Training loss: 0.1940290927886963
Validation loss: 1.719428421348654

Epoch: 269| Step: 0
Training loss: 0.28819048404693604
Validation loss: 1.7861453589572702

Epoch: 6| Step: 1
Training loss: 0.3684895634651184
Validation loss: 1.7792555978221278

Epoch: 6| Step: 2
Training loss: 0.23868560791015625
Validation loss: 1.7808693903748707

Epoch: 6| Step: 3
Training loss: 0.38503724336624146
Validation loss: 1.749085557076239

Epoch: 6| Step: 4
Training loss: 0.363997220993042
Validation loss: 1.739264965057373

Epoch: 6| Step: 5
Training loss: 0.12242794036865234
Validation loss: 1.7188279269843973

Epoch: 6| Step: 6
Training loss: 0.362619549036026
Validation loss: 1.6960731693493423

Epoch: 6| Step: 7
Training loss: 0.38312920928001404
Validation loss: 1.7091282003669328

Epoch: 6| Step: 8
Training loss: 0.26288583874702454
Validation loss: 1.6773800491004862

Epoch: 6| Step: 9
Training loss: 0.3642469048500061
Validation loss: 1.6569800184619041

Epoch: 6| Step: 10
Training loss: 0.274611234664917
Validation loss: 1.6949786793801092

Epoch: 6| Step: 11
Training loss: 0.49576684832572937
Validation loss: 1.6557924600057705

Epoch: 6| Step: 12
Training loss: 0.2989395260810852
Validation loss: 1.6754402704136346

Epoch: 6| Step: 13
Training loss: 0.3125031292438507
Validation loss: 1.6933661776204263

Epoch: 270| Step: 0
Training loss: 0.3511483073234558
Validation loss: 1.659692765564047

Epoch: 6| Step: 1
Training loss: 0.1537376344203949
Validation loss: 1.7002863563517088

Epoch: 6| Step: 2
Training loss: 0.36645376682281494
Validation loss: 1.6808990804097985

Epoch: 6| Step: 3
Training loss: 0.5202692747116089
Validation loss: 1.7066657594455186

Epoch: 6| Step: 4
Training loss: 0.22916176915168762
Validation loss: 1.7026539810242192

Epoch: 6| Step: 5
Training loss: 0.3585469126701355
Validation loss: 1.7085420482902116

Epoch: 6| Step: 6
Training loss: 0.3012450337409973
Validation loss: 1.6752569803627588

Epoch: 6| Step: 7
Training loss: 0.5692396759986877
Validation loss: 1.6785051220206804

Epoch: 6| Step: 8
Training loss: 0.2965714931488037
Validation loss: 1.6376103944675897

Epoch: 6| Step: 9
Training loss: 0.2767750024795532
Validation loss: 1.6787372225074357

Epoch: 6| Step: 10
Training loss: 0.3293895721435547
Validation loss: 1.6747231944914787

Epoch: 6| Step: 11
Training loss: 0.29361772537231445
Validation loss: 1.6950112863253521

Epoch: 6| Step: 12
Training loss: 0.3306906521320343
Validation loss: 1.7059172020163587

Epoch: 6| Step: 13
Training loss: 0.21077485382556915
Validation loss: 1.7234538114199074

Epoch: 271| Step: 0
Training loss: 0.3811737895011902
Validation loss: 1.6877351217372443

Epoch: 6| Step: 1
Training loss: 0.3576279878616333
Validation loss: 1.7375110656984392

Epoch: 6| Step: 2
Training loss: 0.2544223666191101
Validation loss: 1.718511212897557

Epoch: 6| Step: 3
Training loss: 0.24587062001228333
Validation loss: 1.7371216153585782

Epoch: 6| Step: 4
Training loss: 0.21058513224124908
Validation loss: 1.7238111342153242

Epoch: 6| Step: 5
Training loss: 0.4719504714012146
Validation loss: 1.7461333659387404

Epoch: 6| Step: 6
Training loss: 0.49143850803375244
Validation loss: 1.7144972278225807

Epoch: 6| Step: 7
Training loss: 0.34337109327316284
Validation loss: 1.6875206872981081

Epoch: 6| Step: 8
Training loss: 0.2031608372926712
Validation loss: 1.6754181282494658

Epoch: 6| Step: 9
Training loss: 0.2664196789264679
Validation loss: 1.6612315088190057

Epoch: 6| Step: 10
Training loss: 0.33640170097351074
Validation loss: 1.6711260349519792

Epoch: 6| Step: 11
Training loss: 0.4324570894241333
Validation loss: 1.6554806565725675

Epoch: 6| Step: 12
Training loss: 0.23310020565986633
Validation loss: 1.633811343100763

Epoch: 6| Step: 13
Training loss: 0.22326642274856567
Validation loss: 1.6709611095407957

Epoch: 272| Step: 0
Training loss: 0.47617512941360474
Validation loss: 1.6722558518891693

Epoch: 6| Step: 1
Training loss: 0.32035601139068604
Validation loss: 1.6768924715698406

Epoch: 6| Step: 2
Training loss: 0.3035167157649994
Validation loss: 1.720170436366912

Epoch: 6| Step: 3
Training loss: 0.20896773040294647
Validation loss: 1.712302428419872

Epoch: 6| Step: 4
Training loss: 0.23296429216861725
Validation loss: 1.7193809991241784

Epoch: 6| Step: 5
Training loss: 0.3954448997974396
Validation loss: 1.7100987511296426

Epoch: 6| Step: 6
Training loss: 0.24498210847377777
Validation loss: 1.706500325151669

Epoch: 6| Step: 7
Training loss: 0.2054482251405716
Validation loss: 1.7208923485971266

Epoch: 6| Step: 8
Training loss: 0.44432908296585083
Validation loss: 1.7059641973946684

Epoch: 6| Step: 9
Training loss: 0.2470497190952301
Validation loss: 1.7418961755691036

Epoch: 6| Step: 10
Training loss: 0.39959248900413513
Validation loss: 1.7008383120259931

Epoch: 6| Step: 11
Training loss: 0.30250921845436096
Validation loss: 1.715904712677002

Epoch: 6| Step: 12
Training loss: 0.27475160360336304
Validation loss: 1.7174432816043976

Epoch: 6| Step: 13
Training loss: 0.3111782371997833
Validation loss: 1.7376014558217858

Epoch: 273| Step: 0
Training loss: 0.16657684743404388
Validation loss: 1.728272307303644

Epoch: 6| Step: 1
Training loss: 0.24349167943000793
Validation loss: 1.7447702705219228

Epoch: 6| Step: 2
Training loss: 0.2702759802341461
Validation loss: 1.7330484018530896

Epoch: 6| Step: 3
Training loss: 0.26560330390930176
Validation loss: 1.734654329156363

Epoch: 6| Step: 4
Training loss: 0.3106141984462738
Validation loss: 1.7073465906163698

Epoch: 6| Step: 5
Training loss: 0.42322027683258057
Validation loss: 1.722153381634784

Epoch: 6| Step: 6
Training loss: 0.33872056007385254
Validation loss: 1.690889104720085

Epoch: 6| Step: 7
Training loss: 0.3954891562461853
Validation loss: 1.7118518301235732

Epoch: 6| Step: 8
Training loss: 0.42286691069602966
Validation loss: 1.6963422324067803

Epoch: 6| Step: 9
Training loss: 0.33786627650260925
Validation loss: 1.7046024953165362

Epoch: 6| Step: 10
Training loss: 0.27503231167793274
Validation loss: 1.7018496823567215

Epoch: 6| Step: 11
Training loss: 0.29474306106567383
Validation loss: 1.7029090068673576

Epoch: 6| Step: 12
Training loss: 0.2497389316558838
Validation loss: 1.6956082979838054

Epoch: 6| Step: 13
Training loss: 0.265027791261673
Validation loss: 1.7166743355412637

Epoch: 274| Step: 0
Training loss: 0.29909294843673706
Validation loss: 1.7030535256990822

Epoch: 6| Step: 1
Training loss: 0.2960161864757538
Validation loss: 1.6669128812769407

Epoch: 6| Step: 2
Training loss: 0.2508111298084259
Validation loss: 1.6756101269875803

Epoch: 6| Step: 3
Training loss: 0.32686883211135864
Validation loss: 1.660536584033761

Epoch: 6| Step: 4
Training loss: 0.2061610221862793
Validation loss: 1.677538687183011

Epoch: 6| Step: 5
Training loss: 0.4299335479736328
Validation loss: 1.68337970395242

Epoch: 6| Step: 6
Training loss: 0.3092800974845886
Validation loss: 1.68229410084345

Epoch: 6| Step: 7
Training loss: 0.5168707370758057
Validation loss: 1.6640729109446208

Epoch: 6| Step: 8
Training loss: 0.3209276795387268
Validation loss: 1.6896161699807772

Epoch: 6| Step: 9
Training loss: 0.1599297970533371
Validation loss: 1.7072814164623138

Epoch: 6| Step: 10
Training loss: 0.31973621249198914
Validation loss: 1.7012551830660911

Epoch: 6| Step: 11
Training loss: 0.16234831511974335
Validation loss: 1.7026542796883533

Epoch: 6| Step: 12
Training loss: 0.40886038541793823
Validation loss: 1.7350310625568512

Epoch: 6| Step: 13
Training loss: 0.28167521953582764
Validation loss: 1.6889019704634143

Epoch: 275| Step: 0
Training loss: 0.1578507125377655
Validation loss: 1.672687558717625

Epoch: 6| Step: 1
Training loss: 0.26918113231658936
Validation loss: 1.65269608395074

Epoch: 6| Step: 2
Training loss: 0.1981511116027832
Validation loss: 1.6080637708786996

Epoch: 6| Step: 3
Training loss: 0.2551303505897522
Validation loss: 1.637487070534819

Epoch: 6| Step: 4
Training loss: 0.17665977776050568
Validation loss: 1.6489010344269455

Epoch: 6| Step: 5
Training loss: 0.3570379614830017
Validation loss: 1.6368604321633615

Epoch: 6| Step: 6
Training loss: 0.3188508152961731
Validation loss: 1.6523010743561612

Epoch: 6| Step: 7
Training loss: 0.3384169936180115
Validation loss: 1.6414308829974102

Epoch: 6| Step: 8
Training loss: 0.3607669174671173
Validation loss: 1.6415065091143373

Epoch: 6| Step: 9
Training loss: 0.4666176438331604
Validation loss: 1.637774068822143

Epoch: 6| Step: 10
Training loss: 0.3354862332344055
Validation loss: 1.6385257487655969

Epoch: 6| Step: 11
Training loss: 0.6176581382751465
Validation loss: 1.6196007869576896

Epoch: 6| Step: 12
Training loss: 0.21969811618328094
Validation loss: 1.6411737626598728

Epoch: 6| Step: 13
Training loss: 0.14123234152793884
Validation loss: 1.6437676593821535

Epoch: 276| Step: 0
Training loss: 0.13461972773075104
Validation loss: 1.6507525533758185

Epoch: 6| Step: 1
Training loss: 0.4160476326942444
Validation loss: 1.7064794468623337

Epoch: 6| Step: 2
Training loss: 0.23621788620948792
Validation loss: 1.6796153770980013

Epoch: 6| Step: 3
Training loss: 0.2419670671224594
Validation loss: 1.682556939381425

Epoch: 6| Step: 4
Training loss: 0.23331201076507568
Validation loss: 1.6681540486633137

Epoch: 6| Step: 5
Training loss: 0.31912660598754883
Validation loss: 1.6888365835271857

Epoch: 6| Step: 6
Training loss: 0.4217676520347595
Validation loss: 1.6819596393134004

Epoch: 6| Step: 7
Training loss: 0.5481190085411072
Validation loss: 1.689649478081734

Epoch: 6| Step: 8
Training loss: 0.19994452595710754
Validation loss: 1.6911356333763368

Epoch: 6| Step: 9
Training loss: 0.3284834623336792
Validation loss: 1.6484413775064612

Epoch: 6| Step: 10
Training loss: 0.4812532067298889
Validation loss: 1.6551660645392634

Epoch: 6| Step: 11
Training loss: 0.17884589731693268
Validation loss: 1.664387790105676

Epoch: 6| Step: 12
Training loss: 0.25275087356567383
Validation loss: 1.6579023112532913

Epoch: 6| Step: 13
Training loss: 0.2693997919559479
Validation loss: 1.6620081586222495

Epoch: 277| Step: 0
Training loss: 0.21334557235240936
Validation loss: 1.661683891409187

Epoch: 6| Step: 1
Training loss: 0.36753201484680176
Validation loss: 1.6788161852026497

Epoch: 6| Step: 2
Training loss: 0.32342788577079773
Validation loss: 1.6800481875737507

Epoch: 6| Step: 3
Training loss: 0.24462173879146576
Validation loss: 1.7035423658227409

Epoch: 6| Step: 4
Training loss: 0.16055378317832947
Validation loss: 1.6792820807426208

Epoch: 6| Step: 5
Training loss: 0.3814099133014679
Validation loss: 1.6867938144232637

Epoch: 6| Step: 6
Training loss: 0.1663697361946106
Validation loss: 1.7056667112535047

Epoch: 6| Step: 7
Training loss: 0.42718741297721863
Validation loss: 1.6742261801996539

Epoch: 6| Step: 8
Training loss: 0.2630225718021393
Validation loss: 1.6652648820671985

Epoch: 6| Step: 9
Training loss: 0.372383713722229
Validation loss: 1.6486526432857718

Epoch: 6| Step: 10
Training loss: 0.5102115273475647
Validation loss: 1.6479812488760999

Epoch: 6| Step: 11
Training loss: 0.20322567224502563
Validation loss: 1.684165709762163

Epoch: 6| Step: 12
Training loss: 0.2883807122707367
Validation loss: 1.6577804832048313

Epoch: 6| Step: 13
Training loss: 0.20416900515556335
Validation loss: 1.716001892602572

Epoch: 278| Step: 0
Training loss: 0.3916296362876892
Validation loss: 1.6916345242531068

Epoch: 6| Step: 1
Training loss: 0.1628115475177765
Validation loss: 1.700664750991329

Epoch: 6| Step: 2
Training loss: 0.4058162271976471
Validation loss: 1.7311967829222321

Epoch: 6| Step: 3
Training loss: 0.33717378973960876
Validation loss: 1.729451781959944

Epoch: 6| Step: 4
Training loss: 0.20860421657562256
Validation loss: 1.7183932924783358

Epoch: 6| Step: 5
Training loss: 0.4006853699684143
Validation loss: 1.7065144251751643

Epoch: 6| Step: 6
Training loss: 0.1671624779701233
Validation loss: 1.703966804729995

Epoch: 6| Step: 7
Training loss: 0.31683921813964844
Validation loss: 1.7013603064321703

Epoch: 6| Step: 8
Training loss: 0.2485971748828888
Validation loss: 1.697033155348993

Epoch: 6| Step: 9
Training loss: 0.2614052891731262
Validation loss: 1.6786459774099372

Epoch: 6| Step: 10
Training loss: 0.44005465507507324
Validation loss: 1.666882429071652

Epoch: 6| Step: 11
Training loss: 0.2459237277507782
Validation loss: 1.647093693415324

Epoch: 6| Step: 12
Training loss: 0.23309460282325745
Validation loss: 1.6237178925544984

Epoch: 6| Step: 13
Training loss: 0.1592199206352234
Validation loss: 1.639105946786942

Epoch: 279| Step: 0
Training loss: 0.3260701894760132
Validation loss: 1.6295084581580213

Epoch: 6| Step: 1
Training loss: 0.1449635624885559
Validation loss: 1.6611758457717074

Epoch: 6| Step: 2
Training loss: 0.44524967670440674
Validation loss: 1.6844640470320178

Epoch: 6| Step: 3
Training loss: 0.6527059078216553
Validation loss: 1.6668585333772885

Epoch: 6| Step: 4
Training loss: 0.13001437485218048
Validation loss: 1.666069176889235

Epoch: 6| Step: 5
Training loss: 0.15596771240234375
Validation loss: 1.6651685955703899

Epoch: 6| Step: 6
Training loss: 0.23377470672130585
Validation loss: 1.6448822149666407

Epoch: 6| Step: 7
Training loss: 0.3366238474845886
Validation loss: 1.6490620195224721

Epoch: 6| Step: 8
Training loss: 0.2229214757680893
Validation loss: 1.6528447212711457

Epoch: 6| Step: 9
Training loss: 0.3254133462905884
Validation loss: 1.6361289434535529

Epoch: 6| Step: 10
Training loss: 0.2737439274787903
Validation loss: 1.6573910636286582

Epoch: 6| Step: 11
Training loss: 0.1845506876707077
Validation loss: 1.6646975445491012

Epoch: 6| Step: 12
Training loss: 0.38889920711517334
Validation loss: 1.6528726521358694

Epoch: 6| Step: 13
Training loss: 0.1445738971233368
Validation loss: 1.6659763743800502

Epoch: 280| Step: 0
Training loss: 0.1908298134803772
Validation loss: 1.6748240942596107

Epoch: 6| Step: 1
Training loss: 0.3165329694747925
Validation loss: 1.7150348181365638

Epoch: 6| Step: 2
Training loss: 0.24472260475158691
Validation loss: 1.7315280565651514

Epoch: 6| Step: 3
Training loss: 0.2686641216278076
Validation loss: 1.7440418774081814

Epoch: 6| Step: 4
Training loss: 0.27529022097587585
Validation loss: 1.7063447442106021

Epoch: 6| Step: 5
Training loss: 0.2703205347061157
Validation loss: 1.6906388549394504

Epoch: 6| Step: 6
Training loss: 0.2793819308280945
Validation loss: 1.7037187942894556

Epoch: 6| Step: 7
Training loss: 0.380069375038147
Validation loss: 1.6967988385949084

Epoch: 6| Step: 8
Training loss: 0.735639214515686
Validation loss: 1.683109780793549

Epoch: 6| Step: 9
Training loss: 0.2215142548084259
Validation loss: 1.691624690127629

Epoch: 6| Step: 10
Training loss: 0.1643848419189453
Validation loss: 1.6793979470447828

Epoch: 6| Step: 11
Training loss: 0.16911272704601288
Validation loss: 1.6623247464497883

Epoch: 6| Step: 12
Training loss: 0.44165104627609253
Validation loss: 1.637464024687326

Epoch: 6| Step: 13
Training loss: 0.2682579755783081
Validation loss: 1.6280839186842724

Epoch: 281| Step: 0
Training loss: 0.153940811753273
Validation loss: 1.615731195736957

Epoch: 6| Step: 1
Training loss: 0.26195821166038513
Validation loss: 1.6286286936011365

Epoch: 6| Step: 2
Training loss: 0.365707129240036
Validation loss: 1.6494930687771048

Epoch: 6| Step: 3
Training loss: 0.5339337587356567
Validation loss: 1.6305267144274969

Epoch: 6| Step: 4
Training loss: 0.2771235704421997
Validation loss: 1.6521705773568922

Epoch: 6| Step: 5
Training loss: 0.25171542167663574
Validation loss: 1.6705413441504202

Epoch: 6| Step: 6
Training loss: 0.2336270660161972
Validation loss: 1.6681404549588439

Epoch: 6| Step: 7
Training loss: 0.27006861567497253
Validation loss: 1.6336744369999054

Epoch: 6| Step: 8
Training loss: 0.33591142296791077
Validation loss: 1.6656113747627503

Epoch: 6| Step: 9
Training loss: 0.2544481158256531
Validation loss: 1.6564687644281695

Epoch: 6| Step: 10
Training loss: 0.23457090556621552
Validation loss: 1.6228559581182336

Epoch: 6| Step: 11
Training loss: 0.24835418164730072
Validation loss: 1.665225310992169

Epoch: 6| Step: 12
Training loss: 0.17850089073181152
Validation loss: 1.6637003652511104

Epoch: 6| Step: 13
Training loss: 0.911162793636322
Validation loss: 1.693240511801935

Epoch: 282| Step: 0
Training loss: 0.32159268856048584
Validation loss: 1.673817237218221

Epoch: 6| Step: 1
Training loss: 0.3060944974422455
Validation loss: 1.694159423151324

Epoch: 6| Step: 2
Training loss: 0.19710740447044373
Validation loss: 1.709679570249332

Epoch: 6| Step: 3
Training loss: 0.27278444170951843
Validation loss: 1.6946315227016326

Epoch: 6| Step: 4
Training loss: 0.26394882798194885
Validation loss: 1.6894115837671424

Epoch: 6| Step: 5
Training loss: 0.4550272822380066
Validation loss: 1.6924985442110287

Epoch: 6| Step: 6
Training loss: 0.7141513228416443
Validation loss: 1.711042035010553

Epoch: 6| Step: 7
Training loss: 0.17027679085731506
Validation loss: 1.7075581242961269

Epoch: 6| Step: 8
Training loss: 0.12559129297733307
Validation loss: 1.7021555426300212

Epoch: 6| Step: 9
Training loss: 0.19045612215995789
Validation loss: 1.6891739906803254

Epoch: 6| Step: 10
Training loss: 0.223871648311615
Validation loss: 1.64275743884425

Epoch: 6| Step: 11
Training loss: 0.32240575551986694
Validation loss: 1.6728554848701722

Epoch: 6| Step: 12
Training loss: 0.19778695702552795
Validation loss: 1.6847510286556777

Epoch: 6| Step: 13
Training loss: 0.3489094078540802
Validation loss: 1.6533186128062587

Epoch: 283| Step: 0
Training loss: 0.2654268741607666
Validation loss: 1.6372904008434666

Epoch: 6| Step: 1
Training loss: 0.1907791793346405
Validation loss: 1.649435103580516

Epoch: 6| Step: 2
Training loss: 0.1233547180891037
Validation loss: 1.6794456756243141

Epoch: 6| Step: 3
Training loss: 0.3345562815666199
Validation loss: 1.6188118810294776

Epoch: 6| Step: 4
Training loss: 0.21508654952049255
Validation loss: 1.6577588101868987

Epoch: 6| Step: 5
Training loss: 0.2965700626373291
Validation loss: 1.6517009350561327

Epoch: 6| Step: 6
Training loss: 0.21840058267116547
Validation loss: 1.6279415366470174

Epoch: 6| Step: 7
Training loss: 0.37266629934310913
Validation loss: 1.6303407274266726

Epoch: 6| Step: 8
Training loss: 0.4431971311569214
Validation loss: 1.616635573807583

Epoch: 6| Step: 9
Training loss: 0.24562832713127136
Validation loss: 1.632908841615082

Epoch: 6| Step: 10
Training loss: 0.2885618209838867
Validation loss: 1.6341696400796213

Epoch: 6| Step: 11
Training loss: 0.36514317989349365
Validation loss: 1.6527035159449424

Epoch: 6| Step: 12
Training loss: 0.3426988124847412
Validation loss: 1.6320128415220527

Epoch: 6| Step: 13
Training loss: 0.30810782313346863
Validation loss: 1.6178638832543486

Epoch: 284| Step: 0
Training loss: 0.5177403688430786
Validation loss: 1.6339730601156912

Epoch: 6| Step: 1
Training loss: 0.2997848391532898
Validation loss: 1.6344153470890497

Epoch: 6| Step: 2
Training loss: 0.3626674711704254
Validation loss: 1.6370828061975458

Epoch: 6| Step: 3
Training loss: 0.15872026979923248
Validation loss: 1.6586897091198993

Epoch: 6| Step: 4
Training loss: 0.4174547791481018
Validation loss: 1.6772469999969646

Epoch: 6| Step: 5
Training loss: 0.138133704662323
Validation loss: 1.6676707934307795

Epoch: 6| Step: 6
Training loss: 0.36777085065841675
Validation loss: 1.6633970532366025

Epoch: 6| Step: 7
Training loss: 0.3843182325363159
Validation loss: 1.6971536528679632

Epoch: 6| Step: 8
Training loss: 0.2453199326992035
Validation loss: 1.7048014107570852

Epoch: 6| Step: 9
Training loss: 0.24773287773132324
Validation loss: 1.67175873889718

Epoch: 6| Step: 10
Training loss: 0.2133108228445053
Validation loss: 1.6676533734926613

Epoch: 6| Step: 11
Training loss: 0.17941319942474365
Validation loss: 1.6628406881004252

Epoch: 6| Step: 12
Training loss: 0.22395479679107666
Validation loss: 1.6418742133725075

Epoch: 6| Step: 13
Training loss: 0.18465688824653625
Validation loss: 1.6205741974615282

Epoch: 285| Step: 0
Training loss: 0.24602219462394714
Validation loss: 1.6267482388404109

Epoch: 6| Step: 1
Training loss: 0.21358318626880646
Validation loss: 1.6264032715110368

Epoch: 6| Step: 2
Training loss: 0.44025295972824097
Validation loss: 1.661735212931069

Epoch: 6| Step: 3
Training loss: 0.4464474022388458
Validation loss: 1.6763775976755286

Epoch: 6| Step: 4
Training loss: 0.21234160661697388
Validation loss: 1.6871848337111934

Epoch: 6| Step: 5
Training loss: 0.39879438281059265
Validation loss: 1.6627489546293854

Epoch: 6| Step: 6
Training loss: 0.1660539209842682
Validation loss: 1.671903823011665

Epoch: 6| Step: 7
Training loss: 0.26625487208366394
Validation loss: 1.6870953959803427

Epoch: 6| Step: 8
Training loss: 0.2902179956436157
Validation loss: 1.6907075515357397

Epoch: 6| Step: 9
Training loss: 0.35818833112716675
Validation loss: 1.7007379698496994

Epoch: 6| Step: 10
Training loss: 0.19221001863479614
Validation loss: 1.6881583980334702

Epoch: 6| Step: 11
Training loss: 0.47297587990760803
Validation loss: 1.673320980482204

Epoch: 6| Step: 12
Training loss: 0.15920117497444153
Validation loss: 1.6760236934948993

Epoch: 6| Step: 13
Training loss: 0.16561579704284668
Validation loss: 1.6589560111363728

Epoch: 286| Step: 0
Training loss: 0.1620757281780243
Validation loss: 1.6372493569568922

Epoch: 6| Step: 1
Training loss: 0.24049434065818787
Validation loss: 1.641287601122292

Epoch: 6| Step: 2
Training loss: 0.17094826698303223
Validation loss: 1.6485822521230227

Epoch: 6| Step: 3
Training loss: 0.1818314492702484
Validation loss: 1.6022674633610634

Epoch: 6| Step: 4
Training loss: 0.3122480511665344
Validation loss: 1.6453589226609917

Epoch: 6| Step: 5
Training loss: 0.34963738918304443
Validation loss: 1.6335852658876808

Epoch: 6| Step: 6
Training loss: 0.3234875202178955
Validation loss: 1.649079808624842

Epoch: 6| Step: 7
Training loss: 0.4761146008968353
Validation loss: 1.677631308955531

Epoch: 6| Step: 8
Training loss: 0.318569540977478
Validation loss: 1.6666058635198941

Epoch: 6| Step: 9
Training loss: 0.2328999638557434
Validation loss: 1.6531670683173723

Epoch: 6| Step: 10
Training loss: 0.3821362555027008
Validation loss: 1.6285256083293627

Epoch: 6| Step: 11
Training loss: 0.1797296106815338
Validation loss: 1.6432633329463262

Epoch: 6| Step: 12
Training loss: 0.22574998438358307
Validation loss: 1.6666169666474866

Epoch: 6| Step: 13
Training loss: 0.3748609125614166
Validation loss: 1.654387394587199

Epoch: 287| Step: 0
Training loss: 0.2028007060289383
Validation loss: 1.6236703190752255

Epoch: 6| Step: 1
Training loss: 0.21939148008823395
Validation loss: 1.6259069801658712

Epoch: 6| Step: 2
Training loss: 0.15554995834827423
Validation loss: 1.6295760652070403

Epoch: 6| Step: 3
Training loss: 0.2564293444156647
Validation loss: 1.6598748199401363

Epoch: 6| Step: 4
Training loss: 0.42689594626426697
Validation loss: 1.6427475854914675

Epoch: 6| Step: 5
Training loss: 0.25743407011032104
Validation loss: 1.6263179573961484

Epoch: 6| Step: 6
Training loss: 0.3318560719490051
Validation loss: 1.6549151302665792

Epoch: 6| Step: 7
Training loss: 0.15608105063438416
Validation loss: 1.6613640272489159

Epoch: 6| Step: 8
Training loss: 0.0745188444852829
Validation loss: 1.6353273519905664

Epoch: 6| Step: 9
Training loss: 0.1915002167224884
Validation loss: 1.656232464698053

Epoch: 6| Step: 10
Training loss: 0.21230638027191162
Validation loss: 1.6859314262226064

Epoch: 6| Step: 11
Training loss: 0.29510071873664856
Validation loss: 1.6828591310849754

Epoch: 6| Step: 12
Training loss: 0.42138516902923584
Validation loss: 1.7022059579049387

Epoch: 6| Step: 13
Training loss: 0.7224717736244202
Validation loss: 1.6638679312121483

Epoch: 288| Step: 0
Training loss: 0.412128746509552
Validation loss: 1.6721096051636564

Epoch: 6| Step: 1
Training loss: 0.4126388132572174
Validation loss: 1.6538276133998748

Epoch: 6| Step: 2
Training loss: 0.27361488342285156
Validation loss: 1.6260035076448995

Epoch: 6| Step: 3
Training loss: 0.1797301322221756
Validation loss: 1.623067307215865

Epoch: 6| Step: 4
Training loss: 0.1517643928527832
Validation loss: 1.6275306619623655

Epoch: 6| Step: 5
Training loss: 0.39884328842163086
Validation loss: 1.6045850259001537

Epoch: 6| Step: 6
Training loss: 0.27610498666763306
Validation loss: 1.6032439188290668

Epoch: 6| Step: 7
Training loss: 0.20983752608299255
Validation loss: 1.5948066852426017

Epoch: 6| Step: 8
Training loss: 0.23198212683200836
Validation loss: 1.5908563034508818

Epoch: 6| Step: 9
Training loss: 0.2841724753379822
Validation loss: 1.5844943933589484

Epoch: 6| Step: 10
Training loss: 0.26668673753738403
Validation loss: 1.5933729525535338

Epoch: 6| Step: 11
Training loss: 0.18144848942756653
Validation loss: 1.6346360060476488

Epoch: 6| Step: 12
Training loss: 0.24925655126571655
Validation loss: 1.645374939005862

Epoch: 6| Step: 13
Training loss: 0.2913241982460022
Validation loss: 1.6885338887091605

Epoch: 289| Step: 0
Training loss: 0.4920954704284668
Validation loss: 1.7154786996943976

Epoch: 6| Step: 1
Training loss: 0.22047275304794312
Validation loss: 1.6942193879876086

Epoch: 6| Step: 2
Training loss: 0.26564472913742065
Validation loss: 1.6859629487478605

Epoch: 6| Step: 3
Training loss: 0.2865672707557678
Validation loss: 1.6885508824420232

Epoch: 6| Step: 4
Training loss: 0.18066680431365967
Validation loss: 1.698542869219216

Epoch: 6| Step: 5
Training loss: 0.3409193754196167
Validation loss: 1.6770119154325096

Epoch: 6| Step: 6
Training loss: 0.27275344729423523
Validation loss: 1.6464724758619904

Epoch: 6| Step: 7
Training loss: 0.178960382938385
Validation loss: 1.6565777191551783

Epoch: 6| Step: 8
Training loss: 0.16010919213294983
Validation loss: 1.6231313149134319

Epoch: 6| Step: 9
Training loss: 0.2602322995662689
Validation loss: 1.6377481465698571

Epoch: 6| Step: 10
Training loss: 0.23133544623851776
Validation loss: 1.6222002198619228

Epoch: 6| Step: 11
Training loss: 0.290050745010376
Validation loss: 1.5872672552703528

Epoch: 6| Step: 12
Training loss: 0.2308531105518341
Validation loss: 1.5874258875846863

Epoch: 6| Step: 13
Training loss: 0.2072690725326538
Validation loss: 1.5961634548761512

Epoch: 290| Step: 0
Training loss: 0.27910563349723816
Validation loss: 1.5806378638872536

Epoch: 6| Step: 1
Training loss: 0.5168460607528687
Validation loss: 1.6304201618317635

Epoch: 6| Step: 2
Training loss: 0.2086694836616516
Validation loss: 1.6009549953604256

Epoch: 6| Step: 3
Training loss: 0.353180855512619
Validation loss: 1.6310667389182634

Epoch: 6| Step: 4
Training loss: 0.3318145275115967
Validation loss: 1.6352041511125461

Epoch: 6| Step: 5
Training loss: 0.13567501306533813
Validation loss: 1.609918958397322

Epoch: 6| Step: 6
Training loss: 0.22635960578918457
Validation loss: 1.612495139080991

Epoch: 6| Step: 7
Training loss: 0.17294561862945557
Validation loss: 1.5804053198906682

Epoch: 6| Step: 8
Training loss: 0.1409631371498108
Validation loss: 1.5932708042924122

Epoch: 6| Step: 9
Training loss: 0.28451424837112427
Validation loss: 1.612087675320205

Epoch: 6| Step: 10
Training loss: 0.24290597438812256
Validation loss: 1.615436779555454

Epoch: 6| Step: 11
Training loss: 0.4215649962425232
Validation loss: 1.649098987220436

Epoch: 6| Step: 12
Training loss: 0.14427688717842102
Validation loss: 1.6770890784519974

Epoch: 6| Step: 13
Training loss: 0.31741926074028015
Validation loss: 1.6343046042226976

Epoch: 291| Step: 0
Training loss: 0.32007861137390137
Validation loss: 1.6103623464543333

Epoch: 6| Step: 1
Training loss: 0.3410123288631439
Validation loss: 1.6381532812631259

Epoch: 6| Step: 2
Training loss: 0.4454241394996643
Validation loss: 1.6343603775065432

Epoch: 6| Step: 3
Training loss: 0.2214978188276291
Validation loss: 1.6074038449154104

Epoch: 6| Step: 4
Training loss: 0.1678672432899475
Validation loss: 1.6439815234112483

Epoch: 6| Step: 5
Training loss: 0.15564703941345215
Validation loss: 1.6075275623670189

Epoch: 6| Step: 6
Training loss: 0.26108160614967346
Validation loss: 1.6432266030260312

Epoch: 6| Step: 7
Training loss: 0.30559706687927246
Validation loss: 1.6028149858597787

Epoch: 6| Step: 8
Training loss: 0.2697659730911255
Validation loss: 1.623201234366304

Epoch: 6| Step: 9
Training loss: 0.1650201976299286
Validation loss: 1.6308926831009567

Epoch: 6| Step: 10
Training loss: 0.14715725183486938
Validation loss: 1.6055329486887941

Epoch: 6| Step: 11
Training loss: 0.16781745851039886
Validation loss: 1.6098215080076648

Epoch: 6| Step: 12
Training loss: 0.15949766337871552
Validation loss: 1.5938474375714538

Epoch: 6| Step: 13
Training loss: 0.42678213119506836
Validation loss: 1.6052241210014588

Epoch: 292| Step: 0
Training loss: 0.2843376100063324
Validation loss: 1.5849330168898388

Epoch: 6| Step: 1
Training loss: 0.25205671787261963
Validation loss: 1.595919075832572

Epoch: 6| Step: 2
Training loss: 0.33109915256500244
Validation loss: 1.6258937440892702

Epoch: 6| Step: 3
Training loss: 0.1854182779788971
Validation loss: 1.6078064339135283

Epoch: 6| Step: 4
Training loss: 0.2151106745004654
Validation loss: 1.6296253063345467

Epoch: 6| Step: 5
Training loss: 0.22378623485565186
Validation loss: 1.5894957973111061

Epoch: 6| Step: 6
Training loss: 0.5099804401397705
Validation loss: 1.605722632459415

Epoch: 6| Step: 7
Training loss: 0.20175455510616302
Validation loss: 1.6194672308942324

Epoch: 6| Step: 8
Training loss: 0.265941321849823
Validation loss: 1.6195849398131013

Epoch: 6| Step: 9
Training loss: 0.2654421925544739
Validation loss: 1.643208033295088

Epoch: 6| Step: 10
Training loss: 0.19406947493553162
Validation loss: 1.6339640643007012

Epoch: 6| Step: 11
Training loss: 0.15586180984973907
Validation loss: 1.6345187758886686

Epoch: 6| Step: 12
Training loss: 0.23813927173614502
Validation loss: 1.6446982186327699

Epoch: 6| Step: 13
Training loss: 0.12472948431968689
Validation loss: 1.6565135935301423

Epoch: 293| Step: 0
Training loss: 0.2973026931285858
Validation loss: 1.6461775789978683

Epoch: 6| Step: 1
Training loss: 0.1061217412352562
Validation loss: 1.6353635262417536

Epoch: 6| Step: 2
Training loss: 0.2582102417945862
Validation loss: 1.628694616338258

Epoch: 6| Step: 3
Training loss: 0.3602314591407776
Validation loss: 1.6026815240101149

Epoch: 6| Step: 4
Training loss: 0.21634221076965332
Validation loss: 1.594401683858646

Epoch: 6| Step: 5
Training loss: 0.22714069485664368
Validation loss: 1.583068552837577

Epoch: 6| Step: 6
Training loss: 0.25722581148147583
Validation loss: 1.6167284865533151

Epoch: 6| Step: 7
Training loss: 0.38216161727905273
Validation loss: 1.5961196230303856

Epoch: 6| Step: 8
Training loss: 0.2438674122095108
Validation loss: 1.6016224359953275

Epoch: 6| Step: 9
Training loss: 0.3517322540283203
Validation loss: 1.6047755197812152

Epoch: 6| Step: 10
Training loss: 0.1766606569290161
Validation loss: 1.610654664936886

Epoch: 6| Step: 11
Training loss: 0.1812581717967987
Validation loss: 1.6291923253766951

Epoch: 6| Step: 12
Training loss: 0.23044072091579437
Validation loss: 1.6261898497099518

Epoch: 6| Step: 13
Training loss: 0.38450413942337036
Validation loss: 1.6686405904831425

Epoch: 294| Step: 0
Training loss: 0.2424740195274353
Validation loss: 1.6693794086415281

Epoch: 6| Step: 1
Training loss: 0.26939985156059265
Validation loss: 1.6961758534113567

Epoch: 6| Step: 2
Training loss: 0.27181780338287354
Validation loss: 1.6578645334448865

Epoch: 6| Step: 3
Training loss: 0.2032858431339264
Validation loss: 1.6858411758176741

Epoch: 6| Step: 4
Training loss: 0.23458661139011383
Validation loss: 1.6571245231936056

Epoch: 6| Step: 5
Training loss: 0.25040286779403687
Validation loss: 1.6719894755271174

Epoch: 6| Step: 6
Training loss: 0.2879035472869873
Validation loss: 1.7077890083354006

Epoch: 6| Step: 7
Training loss: 0.26358163356781006
Validation loss: 1.690485212110704

Epoch: 6| Step: 8
Training loss: 0.35059553384780884
Validation loss: 1.6651217963105889

Epoch: 6| Step: 9
Training loss: 0.4909712076187134
Validation loss: 1.6812880193033526

Epoch: 6| Step: 10
Training loss: 0.18170933425426483
Validation loss: 1.6112960474465483

Epoch: 6| Step: 11
Training loss: 0.25257164239883423
Validation loss: 1.6353271392083937

Epoch: 6| Step: 12
Training loss: 0.2691839337348938
Validation loss: 1.6323153818807294

Epoch: 6| Step: 13
Training loss: 0.2784522473812103
Validation loss: 1.6480484636881019

Epoch: 295| Step: 0
Training loss: 0.2168421894311905
Validation loss: 1.6144634613426783

Epoch: 6| Step: 1
Training loss: 0.16982844471931458
Validation loss: 1.625125450472678

Epoch: 6| Step: 2
Training loss: 0.2630382776260376
Validation loss: 1.6159675313580422

Epoch: 6| Step: 3
Training loss: 0.33682554960250854
Validation loss: 1.6035007687025173

Epoch: 6| Step: 4
Training loss: 0.3589183986186981
Validation loss: 1.6341230151473836

Epoch: 6| Step: 5
Training loss: 0.14151719212532043
Validation loss: 1.646346079405918

Epoch: 6| Step: 6
Training loss: 0.2576915919780731
Validation loss: 1.6356711567089122

Epoch: 6| Step: 7
Training loss: 0.2152484655380249
Validation loss: 1.6713018519904024

Epoch: 6| Step: 8
Training loss: 0.27281785011291504
Validation loss: 1.6432165945729902

Epoch: 6| Step: 9
Training loss: 0.2242932915687561
Validation loss: 1.6493457184042981

Epoch: 6| Step: 10
Training loss: 0.48312389850616455
Validation loss: 1.6553159875254477

Epoch: 6| Step: 11
Training loss: 0.3623061180114746
Validation loss: 1.6468985542174308

Epoch: 6| Step: 12
Training loss: 0.22325435280799866
Validation loss: 1.6609291389424314

Epoch: 6| Step: 13
Training loss: 0.17948777973651886
Validation loss: 1.6205746999350927

Epoch: 296| Step: 0
Training loss: 0.37633776664733887
Validation loss: 1.637713941194678

Epoch: 6| Step: 1
Training loss: 0.2655513286590576
Validation loss: 1.678720797261884

Epoch: 6| Step: 2
Training loss: 0.16952574253082275
Validation loss: 1.6558288656255251

Epoch: 6| Step: 3
Training loss: 0.3025987446308136
Validation loss: 1.672067480702554

Epoch: 6| Step: 4
Training loss: 0.3373737335205078
Validation loss: 1.6855208412293465

Epoch: 6| Step: 5
Training loss: 0.26916182041168213
Validation loss: 1.6880880363525883

Epoch: 6| Step: 6
Training loss: 0.23168498277664185
Validation loss: 1.7029111090526785

Epoch: 6| Step: 7
Training loss: 0.25789541006088257
Validation loss: 1.677702211564587

Epoch: 6| Step: 8
Training loss: 0.2581899166107178
Validation loss: 1.6450414221773866

Epoch: 6| Step: 9
Training loss: 0.44718462228775024
Validation loss: 1.6400358382091726

Epoch: 6| Step: 10
Training loss: 0.21118584275245667
Validation loss: 1.6111517516515588

Epoch: 6| Step: 11
Training loss: 0.2898476719856262
Validation loss: 1.5988412710928148

Epoch: 6| Step: 12
Training loss: 0.22098761796951294
Validation loss: 1.588547157984908

Epoch: 6| Step: 13
Training loss: 0.39492732286453247
Validation loss: 1.593580243408039

Epoch: 297| Step: 0
Training loss: 0.3355344235897064
Validation loss: 1.6309368777018722

Epoch: 6| Step: 1
Training loss: 0.3016800284385681
Validation loss: 1.6280468330588391

Epoch: 6| Step: 2
Training loss: 0.3566261827945709
Validation loss: 1.6039095104381602

Epoch: 6| Step: 3
Training loss: 0.26850441098213196
Validation loss: 1.6197813992859216

Epoch: 6| Step: 4
Training loss: 0.18441593647003174
Validation loss: 1.623072939534341

Epoch: 6| Step: 5
Training loss: 0.3607947826385498
Validation loss: 1.6357187481336697

Epoch: 6| Step: 6
Training loss: 0.2789502441883087
Validation loss: 1.57869137999832

Epoch: 6| Step: 7
Training loss: 0.33587682247161865
Validation loss: 1.5944338178121915

Epoch: 6| Step: 8
Training loss: 0.25588902831077576
Validation loss: 1.5502836999072824

Epoch: 6| Step: 9
Training loss: 0.16769710183143616
Validation loss: 1.555754916642302

Epoch: 6| Step: 10
Training loss: 0.481852263212204
Validation loss: 1.624005215142363

Epoch: 6| Step: 11
Training loss: 0.2616509199142456
Validation loss: 1.5674989274753037

Epoch: 6| Step: 12
Training loss: 0.13232389092445374
Validation loss: 1.5815547820060485

Epoch: 6| Step: 13
Training loss: 0.3995111584663391
Validation loss: 1.641241140263055

Epoch: 298| Step: 0
Training loss: 0.2728271484375
Validation loss: 1.5820886550411102

Epoch: 6| Step: 1
Training loss: 0.20021897554397583
Validation loss: 1.5906230365076373

Epoch: 6| Step: 2
Training loss: 0.30366820096969604
Validation loss: 1.5637773903467322

Epoch: 6| Step: 3
Training loss: 0.23898068070411682
Validation loss: 1.560869219482586

Epoch: 6| Step: 4
Training loss: 0.25694912672042847
Validation loss: 1.557662333211591

Epoch: 6| Step: 5
Training loss: 0.3237300515174866
Validation loss: 1.534685387406298

Epoch: 6| Step: 6
Training loss: 0.2376406490802765
Validation loss: 1.5493107124041485

Epoch: 6| Step: 7
Training loss: 0.4272683262825012
Validation loss: 1.5785004387619674

Epoch: 6| Step: 8
Training loss: 0.32511281967163086
Validation loss: 1.591673485694393

Epoch: 6| Step: 9
Training loss: 0.24784590303897858
Validation loss: 1.6171963522511144

Epoch: 6| Step: 10
Training loss: 0.22456741333007812
Validation loss: 1.6478773829757527

Epoch: 6| Step: 11
Training loss: 0.38602498173713684
Validation loss: 1.6200145380471342

Epoch: 6| Step: 12
Training loss: 0.18684417009353638
Validation loss: 1.619724928691823

Epoch: 6| Step: 13
Training loss: 0.22824311256408691
Validation loss: 1.6238342638938659

Epoch: 299| Step: 0
Training loss: 0.19644945859909058
Validation loss: 1.619602567406111

Epoch: 6| Step: 1
Training loss: 0.16811800003051758
Validation loss: 1.6276012800073112

Epoch: 6| Step: 2
Training loss: 0.2735418975353241
Validation loss: 1.6175393366044568

Epoch: 6| Step: 3
Training loss: 0.25685328245162964
Validation loss: 1.6140381366975847

Epoch: 6| Step: 4
Training loss: 0.1659059226512909
Validation loss: 1.5985161553147018

Epoch: 6| Step: 5
Training loss: 0.1652601659297943
Validation loss: 1.5793251158088766

Epoch: 6| Step: 6
Training loss: 0.29946595430374146
Validation loss: 1.617341867057226

Epoch: 6| Step: 7
Training loss: 0.290024071931839
Validation loss: 1.6056376067540978

Epoch: 6| Step: 8
Training loss: 0.26185518503189087
Validation loss: 1.6035627959876932

Epoch: 6| Step: 9
Training loss: 0.2711550295352936
Validation loss: 1.6109450376161965

Epoch: 6| Step: 10
Training loss: 0.42619746923446655
Validation loss: 1.613998391294992

Epoch: 6| Step: 11
Training loss: 0.21370315551757812
Validation loss: 1.5635487982021865

Epoch: 6| Step: 12
Training loss: 0.3144179880619049
Validation loss: 1.5950179023127402

Epoch: 6| Step: 13
Training loss: 0.16685938835144043
Validation loss: 1.593403204794853

Epoch: 300| Step: 0
Training loss: 0.3045298755168915
Validation loss: 1.612131469993181

Epoch: 6| Step: 1
Training loss: 0.4115998446941376
Validation loss: 1.644249241839173

Epoch: 6| Step: 2
Training loss: 0.2678000330924988
Validation loss: 1.6651112418020926

Epoch: 6| Step: 3
Training loss: 0.1901978850364685
Validation loss: 1.661282225321698

Epoch: 6| Step: 4
Training loss: 0.42125916481018066
Validation loss: 1.6849799771462717

Epoch: 6| Step: 5
Training loss: 0.3376754820346832
Validation loss: 1.646302225769207

Epoch: 6| Step: 6
Training loss: 0.16809970140457153
Validation loss: 1.6574718670178485

Epoch: 6| Step: 7
Training loss: 0.20260581374168396
Validation loss: 1.6322576179299304

Epoch: 6| Step: 8
Training loss: 0.23050570487976074
Validation loss: 1.5879899609473445

Epoch: 6| Step: 9
Training loss: 0.17865407466888428
Validation loss: 1.6120871395193122

Epoch: 6| Step: 10
Training loss: 0.19768589735031128
Validation loss: 1.6152302577931394

Epoch: 6| Step: 11
Training loss: 0.288685142993927
Validation loss: 1.5949904854579637

Epoch: 6| Step: 12
Training loss: 0.18879744410514832
Validation loss: 1.583006194842759

Epoch: 6| Step: 13
Training loss: 0.2645743191242218
Validation loss: 1.6084605827126452

Epoch: 301| Step: 0
Training loss: 0.21763555705547333
Validation loss: 1.6359623811578239

Epoch: 6| Step: 1
Training loss: 0.11725547909736633
Validation loss: 1.619143304004464

Epoch: 6| Step: 2
Training loss: 0.2698410451412201
Validation loss: 1.6254502547684537

Epoch: 6| Step: 3
Training loss: 0.22914880514144897
Validation loss: 1.6313131381106634

Epoch: 6| Step: 4
Training loss: 0.405917763710022
Validation loss: 1.6236954953080864

Epoch: 6| Step: 5
Training loss: 0.2589685320854187
Validation loss: 1.6140264836690759

Epoch: 6| Step: 6
Training loss: 0.1514272540807724
Validation loss: 1.6503600933218514

Epoch: 6| Step: 7
Training loss: 0.21083003282546997
Validation loss: 1.5975704346933672

Epoch: 6| Step: 8
Training loss: 0.4184409976005554
Validation loss: 1.6330466090991933

Epoch: 6| Step: 9
Training loss: 0.25753676891326904
Validation loss: 1.5986549867096769

Epoch: 6| Step: 10
Training loss: 0.2246943712234497
Validation loss: 1.5769115442870765

Epoch: 6| Step: 11
Training loss: 0.27682533860206604
Validation loss: 1.5821535087400866

Epoch: 6| Step: 12
Training loss: 0.14277003705501556
Validation loss: 1.6098619084204397

Epoch: 6| Step: 13
Training loss: 0.34685227274894714
Validation loss: 1.5836935799608949

Epoch: 302| Step: 0
Training loss: 0.2696276307106018
Validation loss: 1.618622910591864

Epoch: 6| Step: 1
Training loss: 0.35049062967300415
Validation loss: 1.6327655366671983

Epoch: 6| Step: 2
Training loss: 0.3255169987678528
Validation loss: 1.6528000139421033

Epoch: 6| Step: 3
Training loss: 0.3599996566772461
Validation loss: 1.6191499951065227

Epoch: 6| Step: 4
Training loss: 0.39742347598075867
Validation loss: 1.6035479422538512

Epoch: 6| Step: 5
Training loss: 0.20161858201026917
Validation loss: 1.6329308299608127

Epoch: 6| Step: 6
Training loss: 0.22693811357021332
Validation loss: 1.6421986049221409

Epoch: 6| Step: 7
Training loss: 0.09869818389415741
Validation loss: 1.6065699464531356

Epoch: 6| Step: 8
Training loss: 0.2509082555770874
Validation loss: 1.6025974160881453

Epoch: 6| Step: 9
Training loss: 0.1570538729429245
Validation loss: 1.6059698327895133

Epoch: 6| Step: 10
Training loss: 0.15268316864967346
Validation loss: 1.6325479745864868

Epoch: 6| Step: 11
Training loss: 0.14756757020950317
Validation loss: 1.6380229560277795

Epoch: 6| Step: 12
Training loss: 0.22792205214500427
Validation loss: 1.6415218281489548

Epoch: 6| Step: 13
Training loss: 0.22908848524093628
Validation loss: 1.6199946518867248

Epoch: 303| Step: 0
Training loss: 0.2844040095806122
Validation loss: 1.5953043917173981

Epoch: 6| Step: 1
Training loss: 0.19310355186462402
Validation loss: 1.5666309684835455

Epoch: 6| Step: 2
Training loss: 0.37094420194625854
Validation loss: 1.5587607327327933

Epoch: 6| Step: 3
Training loss: 0.15904316306114197
Validation loss: 1.5758279574814664

Epoch: 6| Step: 4
Training loss: 0.21729911863803864
Validation loss: 1.563896212526547

Epoch: 6| Step: 5
Training loss: 0.21866190433502197
Validation loss: 1.6050075997588455

Epoch: 6| Step: 6
Training loss: 0.27809587121009827
Validation loss: 1.563589430624439

Epoch: 6| Step: 7
Training loss: 0.2397375851869583
Validation loss: 1.5874203430709017

Epoch: 6| Step: 8
Training loss: 0.23869746923446655
Validation loss: 1.5971307318697694

Epoch: 6| Step: 9
Training loss: 0.1392296403646469
Validation loss: 1.5685295776654316

Epoch: 6| Step: 10
Training loss: 0.30284106731414795
Validation loss: 1.6128709200889833

Epoch: 6| Step: 11
Training loss: 0.2968995273113251
Validation loss: 1.5997010225890784

Epoch: 6| Step: 12
Training loss: 0.28926071524620056
Validation loss: 1.628657611467505

Epoch: 6| Step: 13
Training loss: 0.09173446893692017
Validation loss: 1.6464279274786673

Epoch: 304| Step: 0
Training loss: 0.17372116446495056
Validation loss: 1.6318892868616248

Epoch: 6| Step: 1
Training loss: 0.2771134376525879
Validation loss: 1.6342700245559856

Epoch: 6| Step: 2
Training loss: 0.22625334560871124
Validation loss: 1.6333779269649136

Epoch: 6| Step: 3
Training loss: 0.21979336440563202
Validation loss: 1.6139573666357225

Epoch: 6| Step: 4
Training loss: 0.190365269780159
Validation loss: 1.6202510441503217

Epoch: 6| Step: 5
Training loss: 0.35207635164260864
Validation loss: 1.5934316778695712

Epoch: 6| Step: 6
Training loss: 0.24870774149894714
Validation loss: 1.6043061671718475

Epoch: 6| Step: 7
Training loss: 0.18059173226356506
Validation loss: 1.5979695666220881

Epoch: 6| Step: 8
Training loss: 0.2226199209690094
Validation loss: 1.593451294847714

Epoch: 6| Step: 9
Training loss: 0.3669224679470062
Validation loss: 1.58389328628458

Epoch: 6| Step: 10
Training loss: 0.22380249202251434
Validation loss: 1.6075819307757961

Epoch: 6| Step: 11
Training loss: 0.33856528997421265
Validation loss: 1.5961911857769053

Epoch: 6| Step: 12
Training loss: 0.21229799091815948
Validation loss: 1.6229659741924656

Epoch: 6| Step: 13
Training loss: 0.08807650208473206
Validation loss: 1.6136625069443897

Epoch: 305| Step: 0
Training loss: 0.10394355654716492
Validation loss: 1.5959329143647225

Epoch: 6| Step: 1
Training loss: 0.24670612812042236
Validation loss: 1.5943052768707275

Epoch: 6| Step: 2
Training loss: 0.21327035129070282
Validation loss: 1.6307879776083014

Epoch: 6| Step: 3
Training loss: 0.36089015007019043
Validation loss: 1.647951672154088

Epoch: 6| Step: 4
Training loss: 0.2720854878425598
Validation loss: 1.6256532803658517

Epoch: 6| Step: 5
Training loss: 0.32975339889526367
Validation loss: 1.6309381864404167

Epoch: 6| Step: 6
Training loss: 0.34345316886901855
Validation loss: 1.6043852324126868

Epoch: 6| Step: 7
Training loss: 0.2774813771247864
Validation loss: 1.6155391457260295

Epoch: 6| Step: 8
Training loss: 0.24040475487709045
Validation loss: 1.569199187781221

Epoch: 6| Step: 9
Training loss: 0.13820768892765045
Validation loss: 1.6010725741745324

Epoch: 6| Step: 10
Training loss: 0.31790536642074585
Validation loss: 1.612675251499299

Epoch: 6| Step: 11
Training loss: 0.28133851289749146
Validation loss: 1.6056344304033505

Epoch: 6| Step: 12
Training loss: 0.3082219064235687
Validation loss: 1.640814878607309

Epoch: 6| Step: 13
Training loss: 0.2573661804199219
Validation loss: 1.6328586070768294

Epoch: 306| Step: 0
Training loss: 0.29103124141693115
Validation loss: 1.6583024481291413

Epoch: 6| Step: 1
Training loss: 0.336112916469574
Validation loss: 1.6336579848361272

Epoch: 6| Step: 2
Training loss: 0.17647016048431396
Validation loss: 1.6539981877931984

Epoch: 6| Step: 3
Training loss: 0.23269324004650116
Validation loss: 1.6222907984128563

Epoch: 6| Step: 4
Training loss: 0.1548883318901062
Validation loss: 1.6443626419190438

Epoch: 6| Step: 5
Training loss: 0.2067030370235443
Validation loss: 1.6563296548781856

Epoch: 6| Step: 6
Training loss: 0.5485829710960388
Validation loss: 1.5993310712998914

Epoch: 6| Step: 7
Training loss: 0.21987693011760712
Validation loss: 1.6059277916467318

Epoch: 6| Step: 8
Training loss: 0.27971151471138
Validation loss: 1.5895098832345778

Epoch: 6| Step: 9
Training loss: 0.1581575870513916
Validation loss: 1.6088855240934639

Epoch: 6| Step: 10
Training loss: 0.28571879863739014
Validation loss: 1.5834263345246673

Epoch: 6| Step: 11
Training loss: 0.22587338089942932
Validation loss: 1.6036219186680292

Epoch: 6| Step: 12
Training loss: 0.2875736951828003
Validation loss: 1.5952872653161325

Epoch: 6| Step: 13
Training loss: 0.1645418405532837
Validation loss: 1.5882563065457087

Epoch: 307| Step: 0
Training loss: 0.14047513902187347
Validation loss: 1.5582420146593483

Epoch: 6| Step: 1
Training loss: 0.4133087396621704
Validation loss: 1.5530666330809235

Epoch: 6| Step: 2
Training loss: 0.2537825107574463
Validation loss: 1.5722247656955515

Epoch: 6| Step: 3
Training loss: 0.21850165724754333
Validation loss: 1.5775597018580283

Epoch: 6| Step: 4
Training loss: 0.33848610520362854
Validation loss: 1.5660022227994856

Epoch: 6| Step: 5
Training loss: 0.22696378827095032
Validation loss: 1.582154381659723

Epoch: 6| Step: 6
Training loss: 0.28695330023765564
Validation loss: 1.57926054411037

Epoch: 6| Step: 7
Training loss: 0.2069421410560608
Validation loss: 1.6219074469740673

Epoch: 6| Step: 8
Training loss: 0.19788400828838348
Validation loss: 1.611978764175087

Epoch: 6| Step: 9
Training loss: 0.33148160576820374
Validation loss: 1.6117463804060412

Epoch: 6| Step: 10
Training loss: 0.09781083464622498
Validation loss: 1.636845402820136

Epoch: 6| Step: 11
Training loss: 0.23176385462284088
Validation loss: 1.6356308203871532

Epoch: 6| Step: 12
Training loss: 0.2839207649230957
Validation loss: 1.642045069766301

Epoch: 6| Step: 13
Training loss: 0.25791776180267334
Validation loss: 1.6388823601507372

Epoch: 308| Step: 0
Training loss: 0.2030535787343979
Validation loss: 1.6470433896587742

Epoch: 6| Step: 1
Training loss: 0.31228798627853394
Validation loss: 1.6283211765750762

Epoch: 6| Step: 2
Training loss: 0.19696378707885742
Validation loss: 1.5858512001652871

Epoch: 6| Step: 3
Training loss: 0.12698578834533691
Validation loss: 1.5557145149477067

Epoch: 6| Step: 4
Training loss: 0.360193133354187
Validation loss: 1.5982991956895398

Epoch: 6| Step: 5
Training loss: 0.22114652395248413
Validation loss: 1.626155440525342

Epoch: 6| Step: 6
Training loss: 0.09313076734542847
Validation loss: 1.618202555564142

Epoch: 6| Step: 7
Training loss: 0.3821898102760315
Validation loss: 1.652956517793799

Epoch: 6| Step: 8
Training loss: 0.22725659608840942
Validation loss: 1.6062426400440994

Epoch: 6| Step: 9
Training loss: 0.2916452884674072
Validation loss: 1.617771247381805

Epoch: 6| Step: 10
Training loss: 0.2228819727897644
Validation loss: 1.6237736145655315

Epoch: 6| Step: 11
Training loss: 0.2623048424720764
Validation loss: 1.6289962119953607

Epoch: 6| Step: 12
Training loss: 0.27859416604042053
Validation loss: 1.6314489123641804

Epoch: 6| Step: 13
Training loss: 0.1808122992515564
Validation loss: 1.674736580541057

Epoch: 309| Step: 0
Training loss: 0.33472785353660583
Validation loss: 1.670503681705844

Epoch: 6| Step: 1
Training loss: 0.2383744716644287
Validation loss: 1.676119387790721

Epoch: 6| Step: 2
Training loss: 0.22427210211753845
Validation loss: 1.6573795208366968

Epoch: 6| Step: 3
Training loss: 0.2918132543563843
Validation loss: 1.6693710063093452

Epoch: 6| Step: 4
Training loss: 0.23274269700050354
Validation loss: 1.6473148868929954

Epoch: 6| Step: 5
Training loss: 0.32677221298217773
Validation loss: 1.659210007677796

Epoch: 6| Step: 6
Training loss: 0.14966359734535217
Validation loss: 1.6239076968162292

Epoch: 6| Step: 7
Training loss: 0.28898221254348755
Validation loss: 1.6687581628881476

Epoch: 6| Step: 8
Training loss: 0.13646261394023895
Validation loss: 1.6512629293626355

Epoch: 6| Step: 9
Training loss: 0.28332218527793884
Validation loss: 1.6106114707967287

Epoch: 6| Step: 10
Training loss: 0.2585113048553467
Validation loss: 1.6308974424997966

Epoch: 6| Step: 11
Training loss: 0.22233276069164276
Validation loss: 1.6085809635859665

Epoch: 6| Step: 12
Training loss: 0.22004136443138123
Validation loss: 1.5716065975927538

Epoch: 6| Step: 13
Training loss: 0.3360007703304291
Validation loss: 1.5790137513991325

Epoch: 310| Step: 0
Training loss: 0.16843634843826294
Validation loss: 1.6028280847816057

Epoch: 6| Step: 1
Training loss: 0.1962219774723053
Validation loss: 1.587882989196367

Epoch: 6| Step: 2
Training loss: 0.21542346477508545
Validation loss: 1.6018124190709924

Epoch: 6| Step: 3
Training loss: 0.09065547585487366
Validation loss: 1.614906939127112

Epoch: 6| Step: 4
Training loss: 0.23141159117221832
Validation loss: 1.6288462249181603

Epoch: 6| Step: 5
Training loss: 0.21648594737052917
Validation loss: 1.6274818451173845

Epoch: 6| Step: 6
Training loss: 0.27282220125198364
Validation loss: 1.6298827253362185

Epoch: 6| Step: 7
Training loss: 0.4505975842475891
Validation loss: 1.6265298743401804

Epoch: 6| Step: 8
Training loss: 0.20166873931884766
Validation loss: 1.5857681279541345

Epoch: 6| Step: 9
Training loss: 0.2561885714530945
Validation loss: 1.599044188376396

Epoch: 6| Step: 10
Training loss: 0.14084485173225403
Validation loss: 1.59272555382021

Epoch: 6| Step: 11
Training loss: 0.19206616282463074
Validation loss: 1.5977972489531322

Epoch: 6| Step: 12
Training loss: 0.24440142512321472
Validation loss: 1.6128709482890304

Epoch: 6| Step: 13
Training loss: 0.22519026696681976
Validation loss: 1.61470151716663

Epoch: 311| Step: 0
Training loss: 0.26838672161102295
Validation loss: 1.6398850922943444

Epoch: 6| Step: 1
Training loss: 0.13931965827941895
Validation loss: 1.627159321179954

Epoch: 6| Step: 2
Training loss: 0.20373284816741943
Validation loss: 1.6307605684444468

Epoch: 6| Step: 3
Training loss: 0.2540391981601715
Validation loss: 1.6216362137948312

Epoch: 6| Step: 4
Training loss: 0.20234531164169312
Validation loss: 1.6109633253466698

Epoch: 6| Step: 5
Training loss: 0.2843734920024872
Validation loss: 1.6081262468009867

Epoch: 6| Step: 6
Training loss: 0.41019171476364136
Validation loss: 1.6065119210109915

Epoch: 6| Step: 7
Training loss: 0.20613446831703186
Validation loss: 1.6293202228443597

Epoch: 6| Step: 8
Training loss: 0.18769146502017975
Validation loss: 1.645174305926087

Epoch: 6| Step: 9
Training loss: 0.21699291467666626
Validation loss: 1.6221406113716863

Epoch: 6| Step: 10
Training loss: 0.15552978217601776
Validation loss: 1.5919789806489022

Epoch: 6| Step: 11
Training loss: 0.19097070395946503
Validation loss: 1.5975539915023311

Epoch: 6| Step: 12
Training loss: 0.28870928287506104
Validation loss: 1.5836459487997077

Epoch: 6| Step: 13
Training loss: 0.26349079608917236
Validation loss: 1.5560592477039625

Epoch: 312| Step: 0
Training loss: 0.15221057832241058
Validation loss: 1.5853925135827833

Epoch: 6| Step: 1
Training loss: 0.15453052520751953
Validation loss: 1.5359704571385537

Epoch: 6| Step: 2
Training loss: 0.3978697955608368
Validation loss: 1.542164070631868

Epoch: 6| Step: 3
Training loss: 0.20226046442985535
Validation loss: 1.5530004655161211

Epoch: 6| Step: 4
Training loss: 0.1802089661359787
Validation loss: 1.558968884970552

Epoch: 6| Step: 5
Training loss: 0.2316388487815857
Validation loss: 1.5281338352029041

Epoch: 6| Step: 6
Training loss: 0.1902218759059906
Validation loss: 1.579051128638688

Epoch: 6| Step: 7
Training loss: 0.3767259120941162
Validation loss: 1.5458246918134793

Epoch: 6| Step: 8
Training loss: 0.20109523832798004
Validation loss: 1.5845234394073486

Epoch: 6| Step: 9
Training loss: 0.26219141483306885
Validation loss: 1.5713543917543145

Epoch: 6| Step: 10
Training loss: 0.24053159356117249
Validation loss: 1.5956502781119397

Epoch: 6| Step: 11
Training loss: 0.16367575526237488
Validation loss: 1.6344004343914729

Epoch: 6| Step: 12
Training loss: 0.23700949549674988
Validation loss: 1.6309830616879206

Epoch: 6| Step: 13
Training loss: 0.1505565345287323
Validation loss: 1.6523286347748132

Epoch: 313| Step: 0
Training loss: 0.17434179782867432
Validation loss: 1.6213715281537784

Epoch: 6| Step: 1
Training loss: 0.2471722662448883
Validation loss: 1.598958001341871

Epoch: 6| Step: 2
Training loss: 0.07868144661188126
Validation loss: 1.6003892601177256

Epoch: 6| Step: 3
Training loss: 0.19348111748695374
Validation loss: 1.6030662418693624

Epoch: 6| Step: 4
Training loss: 0.21514379978179932
Validation loss: 1.60669142969193

Epoch: 6| Step: 5
Training loss: 0.17242431640625
Validation loss: 1.5670347880291682

Epoch: 6| Step: 6
Training loss: 0.2580103576183319
Validation loss: 1.6233819171946535

Epoch: 6| Step: 7
Training loss: 0.24983367323875427
Validation loss: 1.594964946469953

Epoch: 6| Step: 8
Training loss: 0.3821250796318054
Validation loss: 1.5904654187540854

Epoch: 6| Step: 9
Training loss: 0.3515145182609558
Validation loss: 1.5966265457932667

Epoch: 6| Step: 10
Training loss: 0.11816583573818207
Validation loss: 1.586522106201418

Epoch: 6| Step: 11
Training loss: 0.20189757645130157
Validation loss: 1.6103826517699866

Epoch: 6| Step: 12
Training loss: 0.2311326563358307
Validation loss: 1.6133669960883357

Epoch: 6| Step: 13
Training loss: 0.17241661250591278
Validation loss: 1.6053252681609123

Epoch: 314| Step: 0
Training loss: 0.47663477063179016
Validation loss: 1.6035422445625387

Epoch: 6| Step: 1
Training loss: 0.17997053265571594
Validation loss: 1.5889889687620184

Epoch: 6| Step: 2
Training loss: 0.2242080569267273
Validation loss: 1.5411971269115325

Epoch: 6| Step: 3
Training loss: 0.17241215705871582
Validation loss: 1.5931791349123883

Epoch: 6| Step: 4
Training loss: 0.20708614587783813
Validation loss: 1.5639393957712318

Epoch: 6| Step: 5
Training loss: 0.20881563425064087
Validation loss: 1.570985883794805

Epoch: 6| Step: 6
Training loss: 0.3122941851615906
Validation loss: 1.5682310212043025

Epoch: 6| Step: 7
Training loss: 0.21766941249370575
Validation loss: 1.590673772237634

Epoch: 6| Step: 8
Training loss: 0.30235934257507324
Validation loss: 1.60257121439903

Epoch: 6| Step: 9
Training loss: 0.2448083907365799
Validation loss: 1.610527874321066

Epoch: 6| Step: 10
Training loss: 0.2904219925403595
Validation loss: 1.5880220192734913

Epoch: 6| Step: 11
Training loss: 0.41135919094085693
Validation loss: 1.5762415060433008

Epoch: 6| Step: 12
Training loss: 0.2174435555934906
Validation loss: 1.5324044125054472

Epoch: 6| Step: 13
Training loss: 0.16527561843395233
Validation loss: 1.563552027107567

Epoch: 315| Step: 0
Training loss: 0.14213426411151886
Validation loss: 1.5845368639115365

Epoch: 6| Step: 1
Training loss: 0.2846968173980713
Validation loss: 1.5993089727176133

Epoch: 6| Step: 2
Training loss: 0.21915972232818604
Validation loss: 1.6152527896306847

Epoch: 6| Step: 3
Training loss: 0.20776095986366272
Validation loss: 1.6225520859482467

Epoch: 6| Step: 4
Training loss: 0.2824331521987915
Validation loss: 1.618651674639794

Epoch: 6| Step: 5
Training loss: 0.246363565325737
Validation loss: 1.5600561198367868

Epoch: 6| Step: 6
Training loss: 0.19897693395614624
Validation loss: 1.5448651108690488

Epoch: 6| Step: 7
Training loss: 0.5006631016731262
Validation loss: 1.5573137729398665

Epoch: 6| Step: 8
Training loss: 0.2882065176963806
Validation loss: 1.5569326390502274

Epoch: 6| Step: 9
Training loss: 0.2042783498764038
Validation loss: 1.581417522122783

Epoch: 6| Step: 10
Training loss: 0.21901854872703552
Validation loss: 1.5468668873592089

Epoch: 6| Step: 11
Training loss: 0.3434829115867615
Validation loss: 1.563190101295389

Epoch: 6| Step: 12
Training loss: 0.20812134444713593
Validation loss: 1.5907247848408197

Epoch: 6| Step: 13
Training loss: 0.19261223077774048
Validation loss: 1.6157839836612824

Epoch: 316| Step: 0
Training loss: 0.2652663588523865
Validation loss: 1.586919330781506

Epoch: 6| Step: 1
Training loss: 0.31655627489089966
Validation loss: 1.6006055057689708

Epoch: 6| Step: 2
Training loss: 0.2709704041481018
Validation loss: 1.5998156455255323

Epoch: 6| Step: 3
Training loss: 0.2547309994697571
Validation loss: 1.5999811400649369

Epoch: 6| Step: 4
Training loss: 0.2589247226715088
Validation loss: 1.6097369411940217

Epoch: 6| Step: 5
Training loss: 0.17610320448875427
Validation loss: 1.5846577767402894

Epoch: 6| Step: 6
Training loss: 0.36142319440841675
Validation loss: 1.6362424435154084

Epoch: 6| Step: 7
Training loss: 0.2784714996814728
Validation loss: 1.6344340514111262

Epoch: 6| Step: 8
Training loss: 0.20749837160110474
Validation loss: 1.640540438313638

Epoch: 6| Step: 9
Training loss: 0.2000528872013092
Validation loss: 1.5990614852597635

Epoch: 6| Step: 10
Training loss: 0.21495069563388824
Validation loss: 1.5941649149822932

Epoch: 6| Step: 11
Training loss: 0.22161510586738586
Validation loss: 1.600568199670443

Epoch: 6| Step: 12
Training loss: 0.23070570826530457
Validation loss: 1.611513417254212

Epoch: 6| Step: 13
Training loss: 0.19919386506080627
Validation loss: 1.6375863193183817

Epoch: 317| Step: 0
Training loss: 0.328269898891449
Validation loss: 1.6413257801404564

Epoch: 6| Step: 1
Training loss: 0.20617298781871796
Validation loss: 1.6412148039828065

Epoch: 6| Step: 2
Training loss: 0.23726500570774078
Validation loss: 1.6307808288963892

Epoch: 6| Step: 3
Training loss: 0.3822210729122162
Validation loss: 1.6204652106890114

Epoch: 6| Step: 4
Training loss: 0.2437131404876709
Validation loss: 1.5966347712342457

Epoch: 6| Step: 5
Training loss: 0.1445195972919464
Validation loss: 1.6537922531045892

Epoch: 6| Step: 6
Training loss: 0.17144185304641724
Validation loss: 1.6247713412007978

Epoch: 6| Step: 7
Training loss: 0.35066646337509155
Validation loss: 1.6098537457886564

Epoch: 6| Step: 8
Training loss: 0.2747268080711365
Validation loss: 1.6048212999938636

Epoch: 6| Step: 9
Training loss: 0.2074182629585266
Validation loss: 1.6386419316773773

Epoch: 6| Step: 10
Training loss: 0.2774026393890381
Validation loss: 1.583385955902838

Epoch: 6| Step: 11
Training loss: 0.26695865392684937
Validation loss: 1.5895307756239367

Epoch: 6| Step: 12
Training loss: 0.14768275618553162
Validation loss: 1.6081855104815574

Epoch: 6| Step: 13
Training loss: 0.15463274717330933
Validation loss: 1.5580221824748541

Epoch: 318| Step: 0
Training loss: 0.3396846354007721
Validation loss: 1.6109291276624125

Epoch: 6| Step: 1
Training loss: 0.2143121063709259
Validation loss: 1.5996240415880758

Epoch: 6| Step: 2
Training loss: 0.26265576481819153
Validation loss: 1.6068964235244259

Epoch: 6| Step: 3
Training loss: 0.243679940700531
Validation loss: 1.6323577678331764

Epoch: 6| Step: 4
Training loss: 0.19793277978897095
Validation loss: 1.5757248170914189

Epoch: 6| Step: 5
Training loss: 0.28250592947006226
Validation loss: 1.5691550252258137

Epoch: 6| Step: 6
Training loss: 0.33471938967704773
Validation loss: 1.5487090990107546

Epoch: 6| Step: 7
Training loss: 0.09969277679920197
Validation loss: 1.5896804281460342

Epoch: 6| Step: 8
Training loss: 0.14490029215812683
Validation loss: 1.5956206296079902

Epoch: 6| Step: 9
Training loss: 0.36561119556427
Validation loss: 1.5863446932966991

Epoch: 6| Step: 10
Training loss: 0.19074401259422302
Validation loss: 1.6241561571757

Epoch: 6| Step: 11
Training loss: 0.22040382027626038
Validation loss: 1.5844233138586885

Epoch: 6| Step: 12
Training loss: 0.22275739908218384
Validation loss: 1.551847445067539

Epoch: 6| Step: 13
Training loss: 0.09471777081489563
Validation loss: 1.5467681448946717

Epoch: 319| Step: 0
Training loss: 0.1589793711900711
Validation loss: 1.589495643492668

Epoch: 6| Step: 1
Training loss: 0.1270468533039093
Validation loss: 1.5708420507369503

Epoch: 6| Step: 2
Training loss: 0.19654187560081482
Validation loss: 1.5874325959913191

Epoch: 6| Step: 3
Training loss: 0.2903974652290344
Validation loss: 1.5855081209572413

Epoch: 6| Step: 4
Training loss: 0.24638688564300537
Validation loss: 1.5838165219112108

Epoch: 6| Step: 5
Training loss: 0.22126275300979614
Validation loss: 1.5764442618175218

Epoch: 6| Step: 6
Training loss: 0.18828172981739044
Validation loss: 1.5261960939694477

Epoch: 6| Step: 7
Training loss: 0.2143820971250534
Validation loss: 1.5608254491641957

Epoch: 6| Step: 8
Training loss: 0.2795880436897278
Validation loss: 1.533569848665627

Epoch: 6| Step: 9
Training loss: 0.1939847767353058
Validation loss: 1.5513322712272726

Epoch: 6| Step: 10
Training loss: 0.3250342309474945
Validation loss: 1.5130772103545487

Epoch: 6| Step: 11
Training loss: 0.30670151114463806
Validation loss: 1.5414545561677666

Epoch: 6| Step: 12
Training loss: 0.18295474350452423
Validation loss: 1.54750689383476

Epoch: 6| Step: 13
Training loss: 0.18915459513664246
Validation loss: 1.5408246305681044

Epoch: 320| Step: 0
Training loss: 0.20378854870796204
Validation loss: 1.5378220414602628

Epoch: 6| Step: 1
Training loss: 0.24408067762851715
Validation loss: 1.589239021783234

Epoch: 6| Step: 2
Training loss: 0.369467169046402
Validation loss: 1.6245001234034055

Epoch: 6| Step: 3
Training loss: 0.2721523940563202
Validation loss: 1.6348721493956864

Epoch: 6| Step: 4
Training loss: 0.30898675322532654
Validation loss: 1.639170559503699

Epoch: 6| Step: 5
Training loss: 0.2555559575557709
Validation loss: 1.6270288171306733

Epoch: 6| Step: 6
Training loss: 0.14713476598262787
Validation loss: 1.6165655992364372

Epoch: 6| Step: 7
Training loss: 0.12001847475767136
Validation loss: 1.5766199673375776

Epoch: 6| Step: 8
Training loss: 0.3355333209037781
Validation loss: 1.6193579448166715

Epoch: 6| Step: 9
Training loss: 0.23721039295196533
Validation loss: 1.619044085984589

Epoch: 6| Step: 10
Training loss: 0.29803362488746643
Validation loss: 1.6066391698775753

Epoch: 6| Step: 11
Training loss: 0.23092800378799438
Validation loss: 1.6001715724186232

Epoch: 6| Step: 12
Training loss: 0.2836131453514099
Validation loss: 1.552011844932392

Epoch: 6| Step: 13
Training loss: 0.17067816853523254
Validation loss: 1.531607147186033

Epoch: 321| Step: 0
Training loss: 0.18815629184246063
Validation loss: 1.5492153565088909

Epoch: 6| Step: 1
Training loss: 0.16246265172958374
Validation loss: 1.534436741182881

Epoch: 6| Step: 2
Training loss: 0.22788450121879578
Validation loss: 1.5503936006176857

Epoch: 6| Step: 3
Training loss: 0.24346673488616943
Validation loss: 1.5813718431739396

Epoch: 6| Step: 4
Training loss: 0.36996912956237793
Validation loss: 1.5863386225956742

Epoch: 6| Step: 5
Training loss: 0.22462448477745056
Validation loss: 1.5580257497807986

Epoch: 6| Step: 6
Training loss: 0.22823065519332886
Validation loss: 1.5476905709953719

Epoch: 6| Step: 7
Training loss: 0.25539761781692505
Validation loss: 1.5687714417775471

Epoch: 6| Step: 8
Training loss: 0.18746598064899445
Validation loss: 1.5181447049622894

Epoch: 6| Step: 9
Training loss: 0.2687852382659912
Validation loss: 1.5103606665006248

Epoch: 6| Step: 10
Training loss: 0.25067707896232605
Validation loss: 1.47406013934843

Epoch: 6| Step: 11
Training loss: 0.16335435211658478
Validation loss: 1.4807993429963306

Epoch: 6| Step: 12
Training loss: 0.1712343692779541
Validation loss: 1.5367576447866296

Epoch: 6| Step: 13
Training loss: 0.18978312611579895
Validation loss: 1.5073809739082091

Epoch: 322| Step: 0
Training loss: 0.20763513445854187
Validation loss: 1.5364793474956224

Epoch: 6| Step: 1
Training loss: 0.21482859551906586
Validation loss: 1.547808430528128

Epoch: 6| Step: 2
Training loss: 0.133734792470932
Validation loss: 1.5315505150825746

Epoch: 6| Step: 3
Training loss: 0.21055863797664642
Validation loss: 1.562894836548836

Epoch: 6| Step: 4
Training loss: 0.18701085448265076
Validation loss: 1.5665906808709587

Epoch: 6| Step: 5
Training loss: 0.29038020968437195
Validation loss: 1.5702162916942308

Epoch: 6| Step: 6
Training loss: 0.15008404850959778
Validation loss: 1.6004703634528703

Epoch: 6| Step: 7
Training loss: 0.388027548789978
Validation loss: 1.5527901636656893

Epoch: 6| Step: 8
Training loss: 0.09702488034963608
Validation loss: 1.5824377780319543

Epoch: 6| Step: 9
Training loss: 0.2966713011264801
Validation loss: 1.5972803946464293

Epoch: 6| Step: 10
Training loss: 0.12066654860973358
Validation loss: 1.5839164513413624

Epoch: 6| Step: 11
Training loss: 0.2613416910171509
Validation loss: 1.588595595411075

Epoch: 6| Step: 12
Training loss: 0.22415569424629211
Validation loss: 1.5973932973800167

Epoch: 6| Step: 13
Training loss: 0.19153763353824615
Validation loss: 1.6095750126787411

Epoch: 323| Step: 0
Training loss: 0.3148612976074219
Validation loss: 1.576349740387291

Epoch: 6| Step: 1
Training loss: 0.2150668203830719
Validation loss: 1.5908155748921056

Epoch: 6| Step: 2
Training loss: 0.24700474739074707
Validation loss: 1.605009832689839

Epoch: 6| Step: 3
Training loss: 0.16220946609973907
Validation loss: 1.597627265478975

Epoch: 6| Step: 4
Training loss: 0.27332252264022827
Validation loss: 1.575497038902775

Epoch: 6| Step: 5
Training loss: 0.09534786641597748
Validation loss: 1.5513327519098918

Epoch: 6| Step: 6
Training loss: 0.3655359745025635
Validation loss: 1.5923172491852955

Epoch: 6| Step: 7
Training loss: 0.27640587091445923
Validation loss: 1.5657804191753428

Epoch: 6| Step: 8
Training loss: 0.15767940878868103
Validation loss: 1.5413431993094824

Epoch: 6| Step: 9
Training loss: 0.15124553442001343
Validation loss: 1.5303765471263597

Epoch: 6| Step: 10
Training loss: 0.13789105415344238
Validation loss: 1.544900724964757

Epoch: 6| Step: 11
Training loss: 0.11112605035305023
Validation loss: 1.509070647660122

Epoch: 6| Step: 12
Training loss: 0.13140633702278137
Validation loss: 1.5226325988769531

Epoch: 6| Step: 13
Training loss: 0.28563612699508667
Validation loss: 1.5233863169147122

Epoch: 324| Step: 0
Training loss: 0.20499946177005768
Validation loss: 1.516729554822368

Epoch: 6| Step: 1
Training loss: 0.1955309808254242
Validation loss: 1.5171071278151644

Epoch: 6| Step: 2
Training loss: 0.23755568265914917
Validation loss: 1.5171584294688316

Epoch: 6| Step: 3
Training loss: 0.17302928864955902
Validation loss: 1.5086087513995428

Epoch: 6| Step: 4
Training loss: 0.15754084289073944
Validation loss: 1.5303847917946436

Epoch: 6| Step: 5
Training loss: 0.1576022058725357
Validation loss: 1.5546851260687715

Epoch: 6| Step: 6
Training loss: 0.3618308901786804
Validation loss: 1.591960072517395

Epoch: 6| Step: 7
Training loss: 0.2172755002975464
Validation loss: 1.5349157420537805

Epoch: 6| Step: 8
Training loss: 0.23818424344062805
Validation loss: 1.5484800518199962

Epoch: 6| Step: 9
Training loss: 0.13937628269195557
Validation loss: 1.5513721627573813

Epoch: 6| Step: 10
Training loss: 0.1624651998281479
Validation loss: 1.5373582814329414

Epoch: 6| Step: 11
Training loss: 0.1251106709241867
Validation loss: 1.5721471848026398

Epoch: 6| Step: 12
Training loss: 0.28194138407707214
Validation loss: 1.5960987421774095

Epoch: 6| Step: 13
Training loss: 0.12815682590007782
Validation loss: 1.5934696748692503

Epoch: 325| Step: 0
Training loss: 0.17572882771492004
Validation loss: 1.6304086010943177

Epoch: 6| Step: 1
Training loss: 0.21520617604255676
Validation loss: 1.5767485915973622

Epoch: 6| Step: 2
Training loss: 0.2492724061012268
Validation loss: 1.5778603258953299

Epoch: 6| Step: 3
Training loss: 0.1808086484670639
Validation loss: 1.6064011178990847

Epoch: 6| Step: 4
Training loss: 0.3404545783996582
Validation loss: 1.5693602767041934

Epoch: 6| Step: 5
Training loss: 0.2391365021467209
Validation loss: 1.5781444772597282

Epoch: 6| Step: 6
Training loss: 0.29656410217285156
Validation loss: 1.5776401565920921

Epoch: 6| Step: 7
Training loss: 0.17622217535972595
Validation loss: 1.5923932008845831

Epoch: 6| Step: 8
Training loss: 0.2332427203655243
Validation loss: 1.5708278084313998

Epoch: 6| Step: 9
Training loss: 0.17170217633247375
Validation loss: 1.5803511501640402

Epoch: 6| Step: 10
Training loss: 0.20697307586669922
Validation loss: 1.5656382665839246

Epoch: 6| Step: 11
Training loss: 0.138278529047966
Validation loss: 1.527224168982557

Epoch: 6| Step: 12
Training loss: 0.2527540326118469
Validation loss: 1.5791225497440626

Epoch: 6| Step: 13
Training loss: 0.22036714851856232
Validation loss: 1.5601528126706359

Epoch: 326| Step: 0
Training loss: 0.19241702556610107
Validation loss: 1.529317453343381

Epoch: 6| Step: 1
Training loss: 0.14360687136650085
Validation loss: 1.5378171308066255

Epoch: 6| Step: 2
Training loss: 0.19777266681194305
Validation loss: 1.5104263239009406

Epoch: 6| Step: 3
Training loss: 0.08894731104373932
Validation loss: 1.5559286097044587

Epoch: 6| Step: 4
Training loss: 0.21457557380199432
Validation loss: 1.5478987591240996

Epoch: 6| Step: 5
Training loss: 0.24436505138874054
Validation loss: 1.5734223127365112

Epoch: 6| Step: 6
Training loss: 0.17090532183647156
Validation loss: 1.5291302370768722

Epoch: 6| Step: 7
Training loss: 0.19085261225700378
Validation loss: 1.5711974636200936

Epoch: 6| Step: 8
Training loss: 0.4022756814956665
Validation loss: 1.5756107453377015

Epoch: 6| Step: 9
Training loss: 0.35218241810798645
Validation loss: 1.5650060433213429

Epoch: 6| Step: 10
Training loss: 0.24669893085956573
Validation loss: 1.5812732814460673

Epoch: 6| Step: 11
Training loss: 0.20366612076759338
Validation loss: 1.580779839587468

Epoch: 6| Step: 12
Training loss: 0.21425306797027588
Validation loss: 1.5839901175550235

Epoch: 6| Step: 13
Training loss: 0.21022047102451324
Validation loss: 1.5760546384319183

Epoch: 327| Step: 0
Training loss: 0.2189873605966568
Validation loss: 1.56086270014445

Epoch: 6| Step: 1
Training loss: 0.31147652864456177
Validation loss: 1.6216001869529806

Epoch: 6| Step: 2
Training loss: 0.343450665473938
Validation loss: 1.6027184481261878

Epoch: 6| Step: 3
Training loss: 0.16691024601459503
Validation loss: 1.6112748051202426

Epoch: 6| Step: 4
Training loss: 0.3225191831588745
Validation loss: 1.6083356898318055

Epoch: 6| Step: 5
Training loss: 0.1924920529127121
Validation loss: 1.5901996595885164

Epoch: 6| Step: 6
Training loss: 0.16303464770317078
Validation loss: 1.5610811864176104

Epoch: 6| Step: 7
Training loss: 0.22832271456718445
Validation loss: 1.5603134093746063

Epoch: 6| Step: 8
Training loss: 0.2136978805065155
Validation loss: 1.5678492592227073

Epoch: 6| Step: 9
Training loss: 0.14727401733398438
Validation loss: 1.5480879340120541

Epoch: 6| Step: 10
Training loss: 0.1448519229888916
Validation loss: 1.527385889842946

Epoch: 6| Step: 11
Training loss: 0.10780716687440872
Validation loss: 1.543389255000699

Epoch: 6| Step: 12
Training loss: 0.246845543384552
Validation loss: 1.5227614756553405

Epoch: 6| Step: 13
Training loss: 0.2085445672273636
Validation loss: 1.5482478398148731

Epoch: 328| Step: 0
Training loss: 0.22006694972515106
Validation loss: 1.5608836425248014

Epoch: 6| Step: 1
Training loss: 0.1356794387102127
Validation loss: 1.549574621262089

Epoch: 6| Step: 2
Training loss: 0.27012884616851807
Validation loss: 1.5619322305084558

Epoch: 6| Step: 3
Training loss: 0.0962035208940506
Validation loss: 1.573336693548387

Epoch: 6| Step: 4
Training loss: 0.22129128873348236
Validation loss: 1.568342016589257

Epoch: 6| Step: 5
Training loss: 0.2553386688232422
Validation loss: 1.5751304139373123

Epoch: 6| Step: 6
Training loss: 0.20195847749710083
Validation loss: 1.5841868987647436

Epoch: 6| Step: 7
Training loss: 0.20167237520217896
Validation loss: 1.5707916444347751

Epoch: 6| Step: 8
Training loss: 0.18523868918418884
Validation loss: 1.5878230371782858

Epoch: 6| Step: 9
Training loss: 0.25436657667160034
Validation loss: 1.5628513482309156

Epoch: 6| Step: 10
Training loss: 0.15825292468070984
Validation loss: 1.5772807072567683

Epoch: 6| Step: 11
Training loss: 0.31415069103240967
Validation loss: 1.5674508322951615

Epoch: 6| Step: 12
Training loss: 0.1935102641582489
Validation loss: 1.583290853808003

Epoch: 6| Step: 13
Training loss: 0.18449608981609344
Validation loss: 1.5845835734439153

Epoch: 329| Step: 0
Training loss: 0.350692480802536
Validation loss: 1.5264969666798909

Epoch: 6| Step: 1
Training loss: 0.12444332987070084
Validation loss: 1.589507496485146

Epoch: 6| Step: 2
Training loss: 0.15988577902317047
Validation loss: 1.5761435416436964

Epoch: 6| Step: 3
Training loss: 0.16561269760131836
Validation loss: 1.6081070579508299

Epoch: 6| Step: 4
Training loss: 0.17803889513015747
Validation loss: 1.5819538062618625

Epoch: 6| Step: 5
Training loss: 0.1832546591758728
Validation loss: 1.604802381607794

Epoch: 6| Step: 6
Training loss: 0.18406492471694946
Validation loss: 1.6029429974094513

Epoch: 6| Step: 7
Training loss: 0.19746965169906616
Validation loss: 1.61631610444797

Epoch: 6| Step: 8
Training loss: 0.2122173309326172
Validation loss: 1.5794446532444288

Epoch: 6| Step: 9
Training loss: 0.21617698669433594
Validation loss: 1.5663189477817987

Epoch: 6| Step: 10
Training loss: 0.10651934146881104
Validation loss: 1.5683011213938396

Epoch: 6| Step: 11
Training loss: 0.21246910095214844
Validation loss: 1.604757821688088

Epoch: 6| Step: 12
Training loss: 0.272365003824234
Validation loss: 1.5815392399346957

Epoch: 6| Step: 13
Training loss: 0.13338500261306763
Validation loss: 1.571786683092835

Epoch: 330| Step: 0
Training loss: 0.2713068723678589
Validation loss: 1.5691629199571506

Epoch: 6| Step: 1
Training loss: 0.3623584508895874
Validation loss: 1.5777426663265433

Epoch: 6| Step: 2
Training loss: 0.17837193608283997
Validation loss: 1.512818585159958

Epoch: 6| Step: 3
Training loss: 0.20695573091506958
Validation loss: 1.5250177973060197

Epoch: 6| Step: 4
Training loss: 0.14814627170562744
Validation loss: 1.5621387484253093

Epoch: 6| Step: 5
Training loss: 0.15779927372932434
Validation loss: 1.5368070217870897

Epoch: 6| Step: 6
Training loss: 0.20719113945960999
Validation loss: 1.5504681307782409

Epoch: 6| Step: 7
Training loss: 0.20657780766487122
Validation loss: 1.5454868808869393

Epoch: 6| Step: 8
Training loss: 0.14506512880325317
Validation loss: 1.5712526959757651

Epoch: 6| Step: 9
Training loss: 0.13598033785820007
Validation loss: 1.5639663588616155

Epoch: 6| Step: 10
Training loss: 0.15123417973518372
Validation loss: 1.556267366614393

Epoch: 6| Step: 11
Training loss: 0.20815083384513855
Validation loss: 1.575382863321612

Epoch: 6| Step: 12
Training loss: 0.15253055095672607
Validation loss: 1.5595623472685456

Epoch: 6| Step: 13
Training loss: 0.09387321025133133
Validation loss: 1.5386631719527706

Epoch: 331| Step: 0
Training loss: 0.202175110578537
Validation loss: 1.5642689331885307

Epoch: 6| Step: 1
Training loss: 0.2014734447002411
Validation loss: 1.5371135614251579

Epoch: 6| Step: 2
Training loss: 0.3666222095489502
Validation loss: 1.5364444537829327

Epoch: 6| Step: 3
Training loss: 0.15225206315517426
Validation loss: 1.5285598975355907

Epoch: 6| Step: 4
Training loss: 0.2162289023399353
Validation loss: 1.531341939844111

Epoch: 6| Step: 5
Training loss: 0.2919366955757141
Validation loss: 1.5267078697040517

Epoch: 6| Step: 6
Training loss: 0.12777411937713623
Validation loss: 1.5374597464838335

Epoch: 6| Step: 7
Training loss: 0.18226411938667297
Validation loss: 1.5062431590531462

Epoch: 6| Step: 8
Training loss: 0.15884844958782196
Validation loss: 1.5385277053361297

Epoch: 6| Step: 9
Training loss: 0.08686257153749466
Validation loss: 1.542705742261743

Epoch: 6| Step: 10
Training loss: 0.14528392255306244
Validation loss: 1.497392515982351

Epoch: 6| Step: 11
Training loss: 0.16290873289108276
Validation loss: 1.550423724676973

Epoch: 6| Step: 12
Training loss: 0.09776714444160461
Validation loss: 1.5196726706720167

Epoch: 6| Step: 13
Training loss: 0.08892806619405746
Validation loss: 1.5488053355165707

Epoch: 332| Step: 0
Training loss: 0.17587600648403168
Validation loss: 1.5703576585297943

Epoch: 6| Step: 1
Training loss: 0.18112331628799438
Validation loss: 1.525122166961752

Epoch: 6| Step: 2
Training loss: 0.1617092490196228
Validation loss: 1.5639416530568113

Epoch: 6| Step: 3
Training loss: 0.20764866471290588
Validation loss: 1.5585493015986618

Epoch: 6| Step: 4
Training loss: 0.1753130704164505
Validation loss: 1.5624400249091528

Epoch: 6| Step: 5
Training loss: 0.0983337014913559
Validation loss: 1.5529796269632155

Epoch: 6| Step: 6
Training loss: 0.19491297006607056
Validation loss: 1.5575447915702738

Epoch: 6| Step: 7
Training loss: 0.1624646782875061
Validation loss: 1.5528311242339432

Epoch: 6| Step: 8
Training loss: 0.2292201668024063
Validation loss: 1.580098585415912

Epoch: 6| Step: 9
Training loss: 0.14850303530693054
Validation loss: 1.55728256317877

Epoch: 6| Step: 10
Training loss: 0.339402973651886
Validation loss: 1.587041921513055

Epoch: 6| Step: 11
Training loss: 0.16464266180992126
Validation loss: 1.5900110467787711

Epoch: 6| Step: 12
Training loss: 0.151918426156044
Validation loss: 1.556764720588602

Epoch: 6| Step: 13
Training loss: 0.18569093942642212
Validation loss: 1.5648252605110087

Epoch: 333| Step: 0
Training loss: 0.14680126309394836
Validation loss: 1.5609957223297448

Epoch: 6| Step: 1
Training loss: 0.16910918056964874
Validation loss: 1.5373163812903947

Epoch: 6| Step: 2
Training loss: 0.06769689172506332
Validation loss: 1.534694177489127

Epoch: 6| Step: 3
Training loss: 0.1979120820760727
Validation loss: 1.5259902836174093

Epoch: 6| Step: 4
Training loss: 0.16223755478858948
Validation loss: 1.5293385777422177

Epoch: 6| Step: 5
Training loss: 0.13591574132442474
Validation loss: 1.5446747079972298

Epoch: 6| Step: 6
Training loss: 0.1867099404335022
Validation loss: 1.5341727105520104

Epoch: 6| Step: 7
Training loss: 0.09372885525226593
Validation loss: 1.5307510091412453

Epoch: 6| Step: 8
Training loss: 0.1810537874698639
Validation loss: 1.508991829810604

Epoch: 6| Step: 9
Training loss: 0.16231971979141235
Validation loss: 1.505157874476525

Epoch: 6| Step: 10
Training loss: 0.35090172290802
Validation loss: 1.5109054439811296

Epoch: 6| Step: 11
Training loss: 0.18547272682189941
Validation loss: 1.495440218397366

Epoch: 6| Step: 12
Training loss: 0.20689299702644348
Validation loss: 1.5400176894280218

Epoch: 6| Step: 13
Training loss: 0.3027375042438507
Validation loss: 1.5040802365990096

Epoch: 334| Step: 0
Training loss: 0.17224660515785217
Validation loss: 1.5534202552610827

Epoch: 6| Step: 1
Training loss: 0.14325419068336487
Validation loss: 1.560175282980806

Epoch: 6| Step: 2
Training loss: 0.3242507576942444
Validation loss: 1.5630332782704344

Epoch: 6| Step: 3
Training loss: 0.20340454578399658
Validation loss: 1.5819716197188183

Epoch: 6| Step: 4
Training loss: 0.25124621391296387
Validation loss: 1.5781465102267522

Epoch: 6| Step: 5
Training loss: 0.13243061304092407
Validation loss: 1.562422029433712

Epoch: 6| Step: 6
Training loss: 0.32034844160079956
Validation loss: 1.5625642358615834

Epoch: 6| Step: 7
Training loss: 0.09712104499340057
Validation loss: 1.541426489430089

Epoch: 6| Step: 8
Training loss: 0.19584304094314575
Validation loss: 1.518644819977463

Epoch: 6| Step: 9
Training loss: 0.17044572532176971
Validation loss: 1.550400286592463

Epoch: 6| Step: 10
Training loss: 0.19168271124362946
Validation loss: 1.5533052311148694

Epoch: 6| Step: 11
Training loss: 0.14338475465774536
Validation loss: 1.5405263182937459

Epoch: 6| Step: 12
Training loss: 0.2074078470468521
Validation loss: 1.546894440086939

Epoch: 6| Step: 13
Training loss: 0.15920035541057587
Validation loss: 1.5339824050985358

Epoch: 335| Step: 0
Training loss: 0.17227467894554138
Validation loss: 1.5103146235148113

Epoch: 6| Step: 1
Training loss: 0.13528503477573395
Validation loss: 1.4906935191923572

Epoch: 6| Step: 2
Training loss: 0.22665345668792725
Validation loss: 1.5131903284339494

Epoch: 6| Step: 3
Training loss: 0.17370569705963135
Validation loss: 1.5936593560762302

Epoch: 6| Step: 4
Training loss: 0.3310405910015106
Validation loss: 1.5781178269335019

Epoch: 6| Step: 5
Training loss: 0.2567175328731537
Validation loss: 1.5628330887004893

Epoch: 6| Step: 6
Training loss: 0.1005900651216507
Validation loss: 1.5310563348954724

Epoch: 6| Step: 7
Training loss: 0.1065361499786377
Validation loss: 1.561429662089194

Epoch: 6| Step: 8
Training loss: 0.2789098620414734
Validation loss: 1.519872594905156

Epoch: 6| Step: 9
Training loss: 0.27405887842178345
Validation loss: 1.544259758405788

Epoch: 6| Step: 10
Training loss: 0.17572438716888428
Validation loss: 1.5780487816820863

Epoch: 6| Step: 11
Training loss: 0.16692814230918884
Validation loss: 1.5408225456873577

Epoch: 6| Step: 12
Training loss: 0.2439003884792328
Validation loss: 1.5690027526629868

Epoch: 6| Step: 13
Training loss: 0.5971496105194092
Validation loss: 1.5710765020821684

Epoch: 336| Step: 0
Training loss: 0.3549688756465912
Validation loss: 1.5730873397601548

Epoch: 6| Step: 1
Training loss: 0.1872103214263916
Validation loss: 1.5487770239512126

Epoch: 6| Step: 2
Training loss: 0.16662746667861938
Validation loss: 1.5615503390630086

Epoch: 6| Step: 3
Training loss: 0.26822564005851746
Validation loss: 1.5928278007814962

Epoch: 6| Step: 4
Training loss: 0.2366846650838852
Validation loss: 1.6029805085992301

Epoch: 6| Step: 5
Training loss: 0.21148264408111572
Validation loss: 1.5763299657452492

Epoch: 6| Step: 6
Training loss: 0.32363957166671753
Validation loss: 1.5644611697043143

Epoch: 6| Step: 7
Training loss: 0.18124203383922577
Validation loss: 1.5448333217251686

Epoch: 6| Step: 8
Training loss: 0.1452522575855255
Validation loss: 1.5626962466906476

Epoch: 6| Step: 9
Training loss: 0.11108314245939255
Validation loss: 1.5690573838449293

Epoch: 6| Step: 10
Training loss: 0.12464532256126404
Validation loss: 1.5674836225407098

Epoch: 6| Step: 11
Training loss: 0.13950811326503754
Validation loss: 1.6003751998306603

Epoch: 6| Step: 12
Training loss: 0.20047415792942047
Validation loss: 1.6211353642966158

Epoch: 6| Step: 13
Training loss: 0.3100228011608124
Validation loss: 1.582922040775258

Epoch: 337| Step: 0
Training loss: 0.2405739426612854
Validation loss: 1.5950377833458684

Epoch: 6| Step: 1
Training loss: 0.3854411542415619
Validation loss: 1.562795986411392

Epoch: 6| Step: 2
Training loss: 0.24131731688976288
Validation loss: 1.5273796922417098

Epoch: 6| Step: 3
Training loss: 0.20801608264446259
Validation loss: 1.5282912972152873

Epoch: 6| Step: 4
Training loss: 0.16247601807117462
Validation loss: 1.5116417510535127

Epoch: 6| Step: 5
Training loss: 0.1473645120859146
Validation loss: 1.5129271322681057

Epoch: 6| Step: 6
Training loss: 0.22727152705192566
Validation loss: 1.522648713921988

Epoch: 6| Step: 7
Training loss: 0.13045233488082886
Validation loss: 1.531846829639968

Epoch: 6| Step: 8
Training loss: 0.15860620141029358
Validation loss: 1.5170593800083283

Epoch: 6| Step: 9
Training loss: 0.2469111829996109
Validation loss: 1.507920620261982

Epoch: 6| Step: 10
Training loss: 0.09730201959609985
Validation loss: 1.4892774833145963

Epoch: 6| Step: 11
Training loss: 0.1541401445865631
Validation loss: 1.5115089647231563

Epoch: 6| Step: 12
Training loss: 0.2121071070432663
Validation loss: 1.5098246092437415

Epoch: 6| Step: 13
Training loss: 0.26703211665153503
Validation loss: 1.5350766079400175

Epoch: 338| Step: 0
Training loss: 0.1672898828983307
Validation loss: 1.484483657985605

Epoch: 6| Step: 1
Training loss: 0.19673234224319458
Validation loss: 1.4696013530095418

Epoch: 6| Step: 2
Training loss: 0.19041761755943298
Validation loss: 1.48729637745888

Epoch: 6| Step: 3
Training loss: 0.2580978274345398
Validation loss: 1.4916059727309852

Epoch: 6| Step: 4
Training loss: 0.2447340488433838
Validation loss: 1.4978562907506061

Epoch: 6| Step: 5
Training loss: 0.15199151635169983
Validation loss: 1.5213490314381097

Epoch: 6| Step: 6
Training loss: 0.1628694236278534
Validation loss: 1.5423646973025413

Epoch: 6| Step: 7
Training loss: 0.1075325757265091
Validation loss: 1.544848971469428

Epoch: 6| Step: 8
Training loss: 0.26488685607910156
Validation loss: 1.545736341066258

Epoch: 6| Step: 9
Training loss: 0.1745232790708542
Validation loss: 1.5633525386933358

Epoch: 6| Step: 10
Training loss: 0.17223849892616272
Validation loss: 1.5839944411349554

Epoch: 6| Step: 11
Training loss: 0.19620713591575623
Validation loss: 1.555003187989676

Epoch: 6| Step: 12
Training loss: 0.3875972032546997
Validation loss: 1.5627786536370554

Epoch: 6| Step: 13
Training loss: 0.1641521453857422
Validation loss: 1.5831572842854325

Epoch: 339| Step: 0
Training loss: 0.1827375292778015
Validation loss: 1.5619798078331897

Epoch: 6| Step: 1
Training loss: 0.1013651043176651
Validation loss: 1.566907270621228

Epoch: 6| Step: 2
Training loss: 0.19200366735458374
Validation loss: 1.5716053298724595

Epoch: 6| Step: 3
Training loss: 0.1579376459121704
Validation loss: 1.5321024002567414

Epoch: 6| Step: 4
Training loss: 0.1903693526983261
Validation loss: 1.5714845695803243

Epoch: 6| Step: 5
Training loss: 0.2156989872455597
Validation loss: 1.5060275575166107

Epoch: 6| Step: 6
Training loss: 0.26909589767456055
Validation loss: 1.5391884721735472

Epoch: 6| Step: 7
Training loss: 0.46811914443969727
Validation loss: 1.5182201862335205

Epoch: 6| Step: 8
Training loss: 0.1532028615474701
Validation loss: 1.470967609395263

Epoch: 6| Step: 9
Training loss: 0.20392213761806488
Validation loss: 1.4944460699635167

Epoch: 6| Step: 10
Training loss: 0.13478361070156097
Validation loss: 1.4890578472486107

Epoch: 6| Step: 11
Training loss: 0.145682692527771
Validation loss: 1.4973054919191586

Epoch: 6| Step: 12
Training loss: 0.22682364284992218
Validation loss: 1.5320502199152464

Epoch: 6| Step: 13
Training loss: 0.27613914012908936
Validation loss: 1.5430105809242494

Epoch: 340| Step: 0
Training loss: 0.21338814496994019
Validation loss: 1.5314884108881797

Epoch: 6| Step: 1
Training loss: 0.14798197150230408
Validation loss: 1.5232568363989554

Epoch: 6| Step: 2
Training loss: 0.19915851950645447
Validation loss: 1.4888133579684841

Epoch: 6| Step: 3
Training loss: 0.1286424696445465
Validation loss: 1.4843694010088522

Epoch: 6| Step: 4
Training loss: 0.1683276742696762
Validation loss: 1.4852073192596436

Epoch: 6| Step: 5
Training loss: 0.15554633736610413
Validation loss: 1.4981146166401524

Epoch: 6| Step: 6
Training loss: 0.28703927993774414
Validation loss: 1.4940831430496708

Epoch: 6| Step: 7
Training loss: 0.22132548689842224
Validation loss: 1.4778503064186341

Epoch: 6| Step: 8
Training loss: 0.33174294233322144
Validation loss: 1.5112378135804208

Epoch: 6| Step: 9
Training loss: 0.28240013122558594
Validation loss: 1.5032705222406695

Epoch: 6| Step: 10
Training loss: 0.13951867818832397
Validation loss: 1.46908357579221

Epoch: 6| Step: 11
Training loss: 0.14091847836971283
Validation loss: 1.5031726655139719

Epoch: 6| Step: 12
Training loss: 0.20766320824623108
Validation loss: 1.499647799358573

Epoch: 6| Step: 13
Training loss: 0.18845170736312866
Validation loss: 1.5149568742321384

Epoch: 341| Step: 0
Training loss: 0.28169387578964233
Validation loss: 1.53523455127593

Epoch: 6| Step: 1
Training loss: 0.17135944962501526
Validation loss: 1.5594748694409606

Epoch: 6| Step: 2
Training loss: 0.2787628173828125
Validation loss: 1.5439477056585333

Epoch: 6| Step: 3
Training loss: 0.14746183156967163
Validation loss: 1.5899269657750283

Epoch: 6| Step: 4
Training loss: 0.1868864744901657
Validation loss: 1.5654836457262757

Epoch: 6| Step: 5
Training loss: 0.21568334102630615
Validation loss: 1.5775659481684368

Epoch: 6| Step: 6
Training loss: 0.1707541048526764
Validation loss: 1.5732151744186238

Epoch: 6| Step: 7
Training loss: 0.14441969990730286
Validation loss: 1.5812862611586047

Epoch: 6| Step: 8
Training loss: 0.2698647677898407
Validation loss: 1.6044142079609696

Epoch: 6| Step: 9
Training loss: 0.19959691166877747
Validation loss: 1.591622188527097

Epoch: 6| Step: 10
Training loss: 0.18785154819488525
Validation loss: 1.585464253220507

Epoch: 6| Step: 11
Training loss: 0.32658615708351135
Validation loss: 1.5626224561404156

Epoch: 6| Step: 12
Training loss: 0.1122409775853157
Validation loss: 1.560553422538183

Epoch: 6| Step: 13
Training loss: 0.23914378881454468
Validation loss: 1.530535997882966

Epoch: 342| Step: 0
Training loss: 0.1267520785331726
Validation loss: 1.5386895069511988

Epoch: 6| Step: 1
Training loss: 0.15277177095413208
Validation loss: 1.5362353876072874

Epoch: 6| Step: 2
Training loss: 0.2199448198080063
Validation loss: 1.5295519059704197

Epoch: 6| Step: 3
Training loss: 0.16472119092941284
Validation loss: 1.5315480065602127

Epoch: 6| Step: 4
Training loss: 0.24843940138816833
Validation loss: 1.537278030508308

Epoch: 6| Step: 5
Training loss: 0.26246607303619385
Validation loss: 1.5231738090515137

Epoch: 6| Step: 6
Training loss: 0.1938687562942505
Validation loss: 1.5492502412488383

Epoch: 6| Step: 7
Training loss: 0.15364950895309448
Validation loss: 1.5390692962113248

Epoch: 6| Step: 8
Training loss: 0.11055260896682739
Validation loss: 1.5284101014496179

Epoch: 6| Step: 9
Training loss: 0.30244749784469604
Validation loss: 1.5309154820698563

Epoch: 6| Step: 10
Training loss: 0.2202836126089096
Validation loss: 1.5257845450473089

Epoch: 6| Step: 11
Training loss: 0.226528137922287
Validation loss: 1.546157362640545

Epoch: 6| Step: 12
Training loss: 0.19773045182228088
Validation loss: 1.5223134256178332

Epoch: 6| Step: 13
Training loss: 0.21729224920272827
Validation loss: 1.5397889883287492

Epoch: 343| Step: 0
Training loss: 0.18310239911079407
Validation loss: 1.4965165494590678

Epoch: 6| Step: 1
Training loss: 0.14308291673660278
Validation loss: 1.5176060802193099

Epoch: 6| Step: 2
Training loss: 0.11647172272205353
Validation loss: 1.4828040381913543

Epoch: 6| Step: 3
Training loss: 0.1858539879322052
Validation loss: 1.4859016351802374

Epoch: 6| Step: 4
Training loss: 0.13028958439826965
Validation loss: 1.467108985429169

Epoch: 6| Step: 5
Training loss: 0.2745472192764282
Validation loss: 1.4924368935246621

Epoch: 6| Step: 6
Training loss: 0.22870947420597076
Validation loss: 1.501623567714486

Epoch: 6| Step: 7
Training loss: 0.20009905099868774
Validation loss: 1.4970227236388831

Epoch: 6| Step: 8
Training loss: 0.14988142251968384
Validation loss: 1.5004934418585993

Epoch: 6| Step: 9
Training loss: 0.12339186668395996
Validation loss: 1.503325331595636

Epoch: 6| Step: 10
Training loss: 0.24908670783042908
Validation loss: 1.5277546246846516

Epoch: 6| Step: 11
Training loss: 0.15496936440467834
Validation loss: 1.5216810139276649

Epoch: 6| Step: 12
Training loss: 0.1406070441007614
Validation loss: 1.5443770167648152

Epoch: 6| Step: 13
Training loss: 0.20910769701004028
Validation loss: 1.5654754715581094

Epoch: 344| Step: 0
Training loss: 0.11997600644826889
Validation loss: 1.5854067892156622

Epoch: 6| Step: 1
Training loss: 0.39484554529190063
Validation loss: 1.5898144738648528

Epoch: 6| Step: 2
Training loss: 0.21307115256786346
Validation loss: 1.583640315199411

Epoch: 6| Step: 3
Training loss: 0.17949515581130981
Validation loss: 1.5654139339282949

Epoch: 6| Step: 4
Training loss: 0.18563629686832428
Validation loss: 1.5803919428138322

Epoch: 6| Step: 5
Training loss: 0.13302981853485107
Validation loss: 1.6004465421040852

Epoch: 6| Step: 6
Training loss: 0.11845983564853668
Validation loss: 1.536339896340524

Epoch: 6| Step: 7
Training loss: 0.12327256798744202
Validation loss: 1.554543866906115

Epoch: 6| Step: 8
Training loss: 0.18325573205947876
Validation loss: 1.5411243605357345

Epoch: 6| Step: 9
Training loss: 0.1277114748954773
Validation loss: 1.551131583029224

Epoch: 6| Step: 10
Training loss: 0.14784269034862518
Validation loss: 1.5072748994314542

Epoch: 6| Step: 11
Training loss: 0.10357426851987839
Validation loss: 1.5508817229219662

Epoch: 6| Step: 12
Training loss: 0.09767434000968933
Validation loss: 1.5162497566592308

Epoch: 6| Step: 13
Training loss: 0.10966711491346359
Validation loss: 1.491068927190637

Epoch: 345| Step: 0
Training loss: 0.1291728913784027
Validation loss: 1.4873668673217937

Epoch: 6| Step: 1
Training loss: 0.127198725938797
Validation loss: 1.52742035670947

Epoch: 6| Step: 2
Training loss: 0.08720014989376068
Validation loss: 1.5379477418879026

Epoch: 6| Step: 3
Training loss: 0.15705159306526184
Validation loss: 1.5161103894633632

Epoch: 6| Step: 4
Training loss: 0.16019999980926514
Validation loss: 1.5177676113702918

Epoch: 6| Step: 5
Training loss: 0.13135746121406555
Validation loss: 1.4915305940053796

Epoch: 6| Step: 6
Training loss: 0.2086198329925537
Validation loss: 1.4813434193211217

Epoch: 6| Step: 7
Training loss: 0.21802166104316711
Validation loss: 1.4854530403690953

Epoch: 6| Step: 8
Training loss: 0.3221733272075653
Validation loss: 1.5311242008721957

Epoch: 6| Step: 9
Training loss: 0.15488594770431519
Validation loss: 1.5225250695341377

Epoch: 6| Step: 10
Training loss: 0.15916672348976135
Validation loss: 1.5093751286947599

Epoch: 6| Step: 11
Training loss: 0.147931769490242
Validation loss: 1.487315413772419

Epoch: 6| Step: 12
Training loss: 0.18485665321350098
Validation loss: 1.5115471475867814

Epoch: 6| Step: 13
Training loss: 0.16866986453533173
Validation loss: 1.518513717959004

Epoch: 346| Step: 0
Training loss: 0.14764204621315002
Validation loss: 1.5745885038888583

Epoch: 6| Step: 1
Training loss: 0.18157415091991425
Validation loss: 1.5701301277324717

Epoch: 6| Step: 2
Training loss: 0.20624439418315887
Validation loss: 1.5158927620098155

Epoch: 6| Step: 3
Training loss: 0.17654678225517273
Validation loss: 1.5541884283865652

Epoch: 6| Step: 4
Training loss: 0.3044853210449219
Validation loss: 1.5469129252177414

Epoch: 6| Step: 5
Training loss: 0.34640705585479736
Validation loss: 1.5275814456324424

Epoch: 6| Step: 6
Training loss: 0.1443398892879486
Validation loss: 1.5180189878709855

Epoch: 6| Step: 7
Training loss: 0.1467210352420807
Validation loss: 1.494526655443253

Epoch: 6| Step: 8
Training loss: 0.19106212258338928
Validation loss: 1.4932542577866585

Epoch: 6| Step: 9
Training loss: 0.16690784692764282
Validation loss: 1.498637523702396

Epoch: 6| Step: 10
Training loss: 0.14895814657211304
Validation loss: 1.4709639805619434

Epoch: 6| Step: 11
Training loss: 0.2620134949684143
Validation loss: 1.4300267978381085

Epoch: 6| Step: 12
Training loss: 0.11573731899261475
Validation loss: 1.4821606246373986

Epoch: 6| Step: 13
Training loss: 0.2098078578710556
Validation loss: 1.4919950205792663

Epoch: 347| Step: 0
Training loss: 0.17153462767601013
Validation loss: 1.511679191743174

Epoch: 6| Step: 1
Training loss: 0.14158368110656738
Validation loss: 1.4918118599922425

Epoch: 6| Step: 2
Training loss: 0.2574537992477417
Validation loss: 1.51589883142902

Epoch: 6| Step: 3
Training loss: 0.1433674544095993
Validation loss: 1.5219555785579066

Epoch: 6| Step: 4
Training loss: 0.14070099592208862
Validation loss: 1.5530477262312365

Epoch: 6| Step: 5
Training loss: 0.15217985212802887
Validation loss: 1.5243763410916893

Epoch: 6| Step: 6
Training loss: 0.12354440987110138
Validation loss: 1.5179505220023535

Epoch: 6| Step: 7
Training loss: 0.18526671826839447
Validation loss: 1.5221350308387511

Epoch: 6| Step: 8
Training loss: 0.11708825826644897
Validation loss: 1.4954935786544636

Epoch: 6| Step: 9
Training loss: 0.11193902045488358
Validation loss: 1.4981853385125437

Epoch: 6| Step: 10
Training loss: 0.339124470949173
Validation loss: 1.5219013216674968

Epoch: 6| Step: 11
Training loss: 0.16356968879699707
Validation loss: 1.4980506499608357

Epoch: 6| Step: 12
Training loss: 0.08977320790290833
Validation loss: 1.5030679869395431

Epoch: 6| Step: 13
Training loss: 0.26821988821029663
Validation loss: 1.5129280782515002

Epoch: 348| Step: 0
Training loss: 0.15620160102844238
Validation loss: 1.5116082891341178

Epoch: 6| Step: 1
Training loss: 0.19698506593704224
Validation loss: 1.5124124019376692

Epoch: 6| Step: 2
Training loss: 0.24692770838737488
Validation loss: 1.5100450285019413

Epoch: 6| Step: 3
Training loss: 0.22605659067630768
Validation loss: 1.5137039589625534

Epoch: 6| Step: 4
Training loss: 0.33745449781417847
Validation loss: 1.514154455995047

Epoch: 6| Step: 5
Training loss: 0.12137597799301147
Validation loss: 1.4885340890576761

Epoch: 6| Step: 6
Training loss: 0.14134547114372253
Validation loss: 1.4943568373239169

Epoch: 6| Step: 7
Training loss: 0.11553427577018738
Validation loss: 1.4668720986253472

Epoch: 6| Step: 8
Training loss: 0.11299668997526169
Validation loss: 1.476269365638815

Epoch: 6| Step: 9
Training loss: 0.1760530322790146
Validation loss: 1.5196123033441522

Epoch: 6| Step: 10
Training loss: 0.193151593208313
Validation loss: 1.4883546316495506

Epoch: 6| Step: 11
Training loss: 0.17740017175674438
Validation loss: 1.4824334062555784

Epoch: 6| Step: 12
Training loss: 0.1434411257505417
Validation loss: 1.4979029701602073

Epoch: 6| Step: 13
Training loss: 0.15008392930030823
Validation loss: 1.5045643314238517

Epoch: 349| Step: 0
Training loss: 0.23657062649726868
Validation loss: 1.5008298953374226

Epoch: 6| Step: 1
Training loss: 0.15259549021720886
Validation loss: 1.4964642499082832

Epoch: 6| Step: 2
Training loss: 0.1528911590576172
Validation loss: 1.4994273621548888

Epoch: 6| Step: 3
Training loss: 0.09728799015283585
Validation loss: 1.4967573394057572

Epoch: 6| Step: 4
Training loss: 0.3837352693080902
Validation loss: 1.4502181391562186

Epoch: 6| Step: 5
Training loss: 0.21992218494415283
Validation loss: 1.4981754185051046

Epoch: 6| Step: 6
Training loss: 0.20051833987236023
Validation loss: 1.5253549468132757

Epoch: 6| Step: 7
Training loss: 0.19083350896835327
Validation loss: 1.5170043540257279

Epoch: 6| Step: 8
Training loss: 0.20701032876968384
Validation loss: 1.5698391634930846

Epoch: 6| Step: 9
Training loss: 0.20783762633800507
Validation loss: 1.5589124489856023

Epoch: 6| Step: 10
Training loss: 0.15793642401695251
Validation loss: 1.557507570071887

Epoch: 6| Step: 11
Training loss: 0.14956295490264893
Validation loss: 1.5286342328594578

Epoch: 6| Step: 12
Training loss: 0.15000227093696594
Validation loss: 1.5427736723294823

Epoch: 6| Step: 13
Training loss: 0.13316446542739868
Validation loss: 1.5668823744661065

Epoch: 350| Step: 0
Training loss: 0.16590210795402527
Validation loss: 1.5393265960037068

Epoch: 6| Step: 1
Training loss: 0.22169584035873413
Validation loss: 1.5602162422672394

Epoch: 6| Step: 2
Training loss: 0.1575736701488495
Validation loss: 1.545522407818866

Epoch: 6| Step: 3
Training loss: 0.17534546554088593
Validation loss: 1.5559762780384352

Epoch: 6| Step: 4
Training loss: 0.1204085499048233
Validation loss: 1.5267218030909055

Epoch: 6| Step: 5
Training loss: 0.1016979068517685
Validation loss: 1.5053366256016556

Epoch: 6| Step: 6
Training loss: 0.1580648422241211
Validation loss: 1.5185452770161372

Epoch: 6| Step: 7
Training loss: 0.12887002527713776
Validation loss: 1.5002363535665697

Epoch: 6| Step: 8
Training loss: 0.10501956939697266
Validation loss: 1.5172604258342455

Epoch: 6| Step: 9
Training loss: 0.12703323364257812
Validation loss: 1.4931419792995657

Epoch: 6| Step: 10
Training loss: 0.20048289000988007
Validation loss: 1.4873196835158973

Epoch: 6| Step: 11
Training loss: 0.37966495752334595
Validation loss: 1.523878917899183

Epoch: 6| Step: 12
Training loss: 0.1546052098274231
Validation loss: 1.5001063269953574

Epoch: 6| Step: 13
Training loss: 0.08861524611711502
Validation loss: 1.4845769238728348

Epoch: 351| Step: 0
Training loss: 0.22858579456806183
Validation loss: 1.526686183867916

Epoch: 6| Step: 1
Training loss: 0.20295190811157227
Validation loss: 1.4840164812662269

Epoch: 6| Step: 2
Training loss: 0.20020151138305664
Validation loss: 1.5329574538815407

Epoch: 6| Step: 3
Training loss: 0.10985562950372696
Validation loss: 1.5032890189078547

Epoch: 6| Step: 4
Training loss: 0.17096740007400513
Validation loss: 1.497489098579653

Epoch: 6| Step: 5
Training loss: 0.17437449097633362
Validation loss: 1.5087571861923381

Epoch: 6| Step: 6
Training loss: 0.35319724678993225
Validation loss: 1.5089537789744716

Epoch: 6| Step: 7
Training loss: 0.17600104212760925
Validation loss: 1.501541478659517

Epoch: 6| Step: 8
Training loss: 0.08894827961921692
Validation loss: 1.5062227044054257

Epoch: 6| Step: 9
Training loss: 0.16754522919654846
Validation loss: 1.4970049832456855

Epoch: 6| Step: 10
Training loss: 0.18549972772598267
Validation loss: 1.5226979204403457

Epoch: 6| Step: 11
Training loss: 0.22688791155815125
Validation loss: 1.535328843260324

Epoch: 6| Step: 12
Training loss: 0.13067632913589478
Validation loss: 1.5157033346032585

Epoch: 6| Step: 13
Training loss: 0.20767715573310852
Validation loss: 1.5006873684544717

Epoch: 352| Step: 0
Training loss: 0.20498239994049072
Validation loss: 1.5262606464406496

Epoch: 6| Step: 1
Training loss: 0.10520166158676147
Validation loss: 1.5135298223905667

Epoch: 6| Step: 2
Training loss: 0.10054921358823776
Validation loss: 1.5299336794883973

Epoch: 6| Step: 3
Training loss: 0.12678632140159607
Validation loss: 1.4900053880547965

Epoch: 6| Step: 4
Training loss: 0.2750281095504761
Validation loss: 1.5151980461612824

Epoch: 6| Step: 5
Training loss: 0.1178753674030304
Validation loss: 1.476138464866146

Epoch: 6| Step: 6
Training loss: 0.1422051191329956
Validation loss: 1.521166907843723

Epoch: 6| Step: 7
Training loss: 0.07826458662748337
Validation loss: 1.513438441420114

Epoch: 6| Step: 8
Training loss: 0.16735920310020447
Validation loss: 1.5258779115574335

Epoch: 6| Step: 9
Training loss: 0.1493198424577713
Validation loss: 1.4874440213685394

Epoch: 6| Step: 10
Training loss: 0.1229647770524025
Validation loss: 1.5047761817132272

Epoch: 6| Step: 11
Training loss: 0.15543514490127563
Validation loss: 1.5176843879043416

Epoch: 6| Step: 12
Training loss: 0.26184093952178955
Validation loss: 1.5439439845341507

Epoch: 6| Step: 13
Training loss: 0.12330561131238937
Validation loss: 1.5217144540561143

Epoch: 353| Step: 0
Training loss: 0.287444531917572
Validation loss: 1.5473551788637716

Epoch: 6| Step: 1
Training loss: 0.14765644073486328
Validation loss: 1.5342236398368754

Epoch: 6| Step: 2
Training loss: 0.11447273194789886
Validation loss: 1.5124947935022333

Epoch: 6| Step: 3
Training loss: 0.1377164125442505
Validation loss: 1.5222690143892843

Epoch: 6| Step: 4
Training loss: 0.1861158311367035
Validation loss: 1.5221160393889233

Epoch: 6| Step: 5
Training loss: 0.20130912959575653
Validation loss: 1.4980669790698635

Epoch: 6| Step: 6
Training loss: 0.16371262073516846
Validation loss: 1.4884799667583999

Epoch: 6| Step: 7
Training loss: 0.1752764880657196
Validation loss: 1.4958105779463244

Epoch: 6| Step: 8
Training loss: 0.1640380322933197
Validation loss: 1.4814470314210462

Epoch: 6| Step: 9
Training loss: 0.09568345546722412
Validation loss: 1.505980421138066

Epoch: 6| Step: 10
Training loss: 0.13862860202789307
Validation loss: 1.4975604869986092

Epoch: 6| Step: 11
Training loss: 0.15476498007774353
Validation loss: 1.5067891561856834

Epoch: 6| Step: 12
Training loss: 0.14190420508384705
Validation loss: 1.531075987764584

Epoch: 6| Step: 13
Training loss: 0.09202151745557785
Validation loss: 1.512424898403947

Epoch: 354| Step: 0
Training loss: 0.17445828020572662
Validation loss: 1.5168965849825131

Epoch: 6| Step: 1
Training loss: 0.10663209110498428
Validation loss: 1.5562199802808865

Epoch: 6| Step: 2
Training loss: 0.13153411448001862
Validation loss: 1.5356653403210383

Epoch: 6| Step: 3
Training loss: 0.15938769280910492
Validation loss: 1.5364847016590897

Epoch: 6| Step: 4
Training loss: 0.2526751160621643
Validation loss: 1.5520259103467386

Epoch: 6| Step: 5
Training loss: 0.0960429310798645
Validation loss: 1.5471709812841108

Epoch: 6| Step: 6
Training loss: 0.15279942750930786
Validation loss: 1.5505445285509991

Epoch: 6| Step: 7
Training loss: 0.06511581689119339
Validation loss: 1.5427118103991273

Epoch: 6| Step: 8
Training loss: 0.2871491312980652
Validation loss: 1.5211654747686079

Epoch: 6| Step: 9
Training loss: 0.16178461909294128
Validation loss: 1.5220897159268778

Epoch: 6| Step: 10
Training loss: 0.17542284727096558
Validation loss: 1.5562147248175837

Epoch: 6| Step: 11
Training loss: 0.16319280862808228
Validation loss: 1.5857870489038446

Epoch: 6| Step: 12
Training loss: 0.19179673492908478
Validation loss: 1.5525915622711182

Epoch: 6| Step: 13
Training loss: 0.12070213258266449
Validation loss: 1.5446291815850042

Epoch: 355| Step: 0
Training loss: 0.09434369206428528
Validation loss: 1.5343349172223

Epoch: 6| Step: 1
Training loss: 0.16231635212898254
Validation loss: 1.5475333211242512

Epoch: 6| Step: 2
Training loss: 0.1259269118309021
Validation loss: 1.5870326372884935

Epoch: 6| Step: 3
Training loss: 0.2703743577003479
Validation loss: 1.5543577414686962

Epoch: 6| Step: 4
Training loss: 0.2688854932785034
Validation loss: 1.5717291511515135

Epoch: 6| Step: 5
Training loss: 0.16987918317317963
Validation loss: 1.5195459088971537

Epoch: 6| Step: 6
Training loss: 0.12700602412223816
Validation loss: 1.5260090315213768

Epoch: 6| Step: 7
Training loss: 0.1716630905866623
Validation loss: 1.534504113658782

Epoch: 6| Step: 8
Training loss: 0.14880147576332092
Validation loss: 1.5024461105305662

Epoch: 6| Step: 9
Training loss: 0.1630607694387436
Validation loss: 1.4944737701005832

Epoch: 6| Step: 10
Training loss: 0.12815232574939728
Validation loss: 1.5088039649430143

Epoch: 6| Step: 11
Training loss: 0.18608368933200836
Validation loss: 1.4691194347155991

Epoch: 6| Step: 12
Training loss: 0.11377132683992386
Validation loss: 1.504324423369541

Epoch: 6| Step: 13
Training loss: 0.12449349462985992
Validation loss: 1.5196341494078278

Epoch: 356| Step: 0
Training loss: 0.32203394174575806
Validation loss: 1.4644748459580124

Epoch: 6| Step: 1
Training loss: 0.08295058459043503
Validation loss: 1.5051865385424705

Epoch: 6| Step: 2
Training loss: 0.09235812723636627
Validation loss: 1.5075053694427654

Epoch: 6| Step: 3
Training loss: 0.11255335807800293
Validation loss: 1.568284983276039

Epoch: 6| Step: 4
Training loss: 0.116811603307724
Validation loss: 1.532073397790232

Epoch: 6| Step: 5
Training loss: 0.159412682056427
Validation loss: 1.5229753050752866

Epoch: 6| Step: 6
Training loss: 0.24393166601657867
Validation loss: 1.543834319678686

Epoch: 6| Step: 7
Training loss: 0.16951927542686462
Validation loss: 1.5513206476806312

Epoch: 6| Step: 8
Training loss: 0.1633794754743576
Validation loss: 1.5065870913126136

Epoch: 6| Step: 9
Training loss: 0.11593270301818848
Validation loss: 1.5029125431532502

Epoch: 6| Step: 10
Training loss: 0.11323843896389008
Validation loss: 1.5288847672042025

Epoch: 6| Step: 11
Training loss: 0.16108107566833496
Validation loss: 1.472935652220121

Epoch: 6| Step: 12
Training loss: 0.10551449656486511
Validation loss: 1.5003012572565386

Epoch: 6| Step: 13
Training loss: 0.1403065323829651
Validation loss: 1.4743493795394897

Epoch: 357| Step: 0
Training loss: 0.30347469449043274
Validation loss: 1.4979274490828156

Epoch: 6| Step: 1
Training loss: 0.0861605778336525
Validation loss: 1.4571213478683143

Epoch: 6| Step: 2
Training loss: 0.20968669652938843
Validation loss: 1.4890844052837742

Epoch: 6| Step: 3
Training loss: 0.2337856888771057
Validation loss: 1.4754711530541862

Epoch: 6| Step: 4
Training loss: 0.14507056772708893
Validation loss: 1.5261458857085115

Epoch: 6| Step: 5
Training loss: 0.15514534711837769
Validation loss: 1.5198050442562308

Epoch: 6| Step: 6
Training loss: 0.1714230179786682
Validation loss: 1.5069747881222797

Epoch: 6| Step: 7
Training loss: 0.09137493371963501
Validation loss: 1.5009764125270229

Epoch: 6| Step: 8
Training loss: 0.13403993844985962
Validation loss: 1.5070463124141897

Epoch: 6| Step: 9
Training loss: 0.12854096293449402
Validation loss: 1.4807947303659172

Epoch: 6| Step: 10
Training loss: 0.19457100331783295
Validation loss: 1.5274599482936244

Epoch: 6| Step: 11
Training loss: 0.1053103506565094
Validation loss: 1.4905978556602233

Epoch: 6| Step: 12
Training loss: 0.08896730840206146
Validation loss: 1.5007181347057383

Epoch: 6| Step: 13
Training loss: 0.09638525545597076
Validation loss: 1.5440667547205442

Epoch: 358| Step: 0
Training loss: 0.14026004076004028
Validation loss: 1.5178783093729327

Epoch: 6| Step: 1
Training loss: 0.13218483328819275
Validation loss: 1.479287144958332

Epoch: 6| Step: 2
Training loss: 0.0769168883562088
Validation loss: 1.4959153385572537

Epoch: 6| Step: 3
Training loss: 0.16911324858665466
Validation loss: 1.4966265482287253

Epoch: 6| Step: 4
Training loss: 0.12024156004190445
Validation loss: 1.5248645056960404

Epoch: 6| Step: 5
Training loss: 0.10753007978200912
Validation loss: 1.5016444447220012

Epoch: 6| Step: 6
Training loss: 0.13474032282829285
Validation loss: 1.4797511754497406

Epoch: 6| Step: 7
Training loss: 0.3225688636302948
Validation loss: 1.511738548996628

Epoch: 6| Step: 8
Training loss: 0.12938430905342102
Validation loss: 1.4746248568257978

Epoch: 6| Step: 9
Training loss: 0.13169826567173004
Validation loss: 1.5057123194458664

Epoch: 6| Step: 10
Training loss: 0.20714624226093292
Validation loss: 1.4669011305737238

Epoch: 6| Step: 11
Training loss: 0.11118322610855103
Validation loss: 1.4435288342096473

Epoch: 6| Step: 12
Training loss: 0.20636369287967682
Validation loss: 1.4734902663897442

Epoch: 6| Step: 13
Training loss: 0.15475040674209595
Validation loss: 1.4836411591499084

Epoch: 359| Step: 0
Training loss: 0.16585803031921387
Validation loss: 1.4726460121011222

Epoch: 6| Step: 1
Training loss: 0.26138579845428467
Validation loss: 1.4615758657455444

Epoch: 6| Step: 2
Training loss: 0.16384971141815186
Validation loss: 1.4806469807060816

Epoch: 6| Step: 3
Training loss: 0.2099267840385437
Validation loss: 1.459684452062012

Epoch: 6| Step: 4
Training loss: 0.15984781086444855
Validation loss: 1.4740486183474142

Epoch: 6| Step: 5
Training loss: 0.20195956528186798
Validation loss: 1.4971053754129717

Epoch: 6| Step: 6
Training loss: 0.17371870577335358
Validation loss: 1.4783832706430906

Epoch: 6| Step: 7
Training loss: 0.16975900530815125
Validation loss: 1.4979943306215349

Epoch: 6| Step: 8
Training loss: 0.15286770462989807
Validation loss: 1.5107369781822286

Epoch: 6| Step: 9
Training loss: 0.1257466822862625
Validation loss: 1.499020754650075

Epoch: 6| Step: 10
Training loss: 0.16230031847953796
Validation loss: 1.5101359736534856

Epoch: 6| Step: 11
Training loss: 0.13700279593467712
Validation loss: 1.560411835870435

Epoch: 6| Step: 12
Training loss: 0.21466925740242004
Validation loss: 1.5430286584361907

Epoch: 6| Step: 13
Training loss: 0.16442807018756866
Validation loss: 1.5305039536568426

Epoch: 360| Step: 0
Training loss: 0.13643214106559753
Validation loss: 1.5270359381552665

Epoch: 6| Step: 1
Training loss: 0.14023445546627045
Validation loss: 1.5000377367901545

Epoch: 6| Step: 2
Training loss: 0.34183239936828613
Validation loss: 1.499511662349906

Epoch: 6| Step: 3
Training loss: 0.16230805218219757
Validation loss: 1.499158009406059

Epoch: 6| Step: 4
Training loss: 0.16725477576255798
Validation loss: 1.5039502356642036

Epoch: 6| Step: 5
Training loss: 0.20531576871871948
Validation loss: 1.4663307730869581

Epoch: 6| Step: 6
Training loss: 0.21081696450710297
Validation loss: 1.5134784322912975

Epoch: 6| Step: 7
Training loss: 0.17684023082256317
Validation loss: 1.4750716737521592

Epoch: 6| Step: 8
Training loss: 0.11388357728719711
Validation loss: 1.5189931367033271

Epoch: 6| Step: 9
Training loss: 0.1410362422466278
Validation loss: 1.4847046495765768

Epoch: 6| Step: 10
Training loss: 0.0885283499956131
Validation loss: 1.4998486932887827

Epoch: 6| Step: 11
Training loss: 0.16685378551483154
Validation loss: 1.465938377124007

Epoch: 6| Step: 12
Training loss: 0.07387842237949371
Validation loss: 1.5077516212258288

Epoch: 6| Step: 13
Training loss: 0.13515342772006989
Validation loss: 1.4713277163044098

Epoch: 361| Step: 0
Training loss: 0.1418055295944214
Validation loss: 1.5065312885469007

Epoch: 6| Step: 1
Training loss: 0.12634128332138062
Validation loss: 1.4747862995311778

Epoch: 6| Step: 2
Training loss: 0.10943566262722015
Validation loss: 1.4940076079419864

Epoch: 6| Step: 3
Training loss: 0.14123709499835968
Validation loss: 1.4759884829162269

Epoch: 6| Step: 4
Training loss: 0.35587066411972046
Validation loss: 1.4834544453569638

Epoch: 6| Step: 5
Training loss: 0.25030505657196045
Validation loss: 1.465549220320999

Epoch: 6| Step: 6
Training loss: 0.0809163898229599
Validation loss: 1.4834203207364647

Epoch: 6| Step: 7
Training loss: 0.24774281680583954
Validation loss: 1.5022873602887636

Epoch: 6| Step: 8
Training loss: 0.10992707312107086
Validation loss: 1.5031935796942761

Epoch: 6| Step: 9
Training loss: 0.1747632622718811
Validation loss: 1.4903758623266732

Epoch: 6| Step: 10
Training loss: 0.21173229813575745
Validation loss: 1.498917604005465

Epoch: 6| Step: 11
Training loss: 0.1107858419418335
Validation loss: 1.5018843438035698

Epoch: 6| Step: 12
Training loss: 0.15138059854507446
Validation loss: 1.5037760542285057

Epoch: 6| Step: 13
Training loss: 0.12253395467996597
Validation loss: 1.5410330103289696

Epoch: 362| Step: 0
Training loss: 0.24515295028686523
Validation loss: 1.5405595405127412

Epoch: 6| Step: 1
Training loss: 0.15774084627628326
Validation loss: 1.5203001973449544

Epoch: 6| Step: 2
Training loss: 0.16288627684116364
Validation loss: 1.5318772485179286

Epoch: 6| Step: 3
Training loss: 0.13445746898651123
Validation loss: 1.5344436924944642

Epoch: 6| Step: 4
Training loss: 0.21102163195610046
Validation loss: 1.518135477137822

Epoch: 6| Step: 5
Training loss: 0.0860355794429779
Validation loss: 1.5501089442160823

Epoch: 6| Step: 6
Training loss: 0.32821106910705566
Validation loss: 1.5491141324402184

Epoch: 6| Step: 7
Training loss: 0.13290607929229736
Validation loss: 1.5221335054725729

Epoch: 6| Step: 8
Training loss: 0.18578675389289856
Validation loss: 1.5238991975784302

Epoch: 6| Step: 9
Training loss: 0.14469702541828156
Validation loss: 1.5382899084398824

Epoch: 6| Step: 10
Training loss: 0.12859037518501282
Validation loss: 1.5380498196489067

Epoch: 6| Step: 11
Training loss: 0.1675034910440445
Validation loss: 1.5542578312658495

Epoch: 6| Step: 12
Training loss: 0.15586337447166443
Validation loss: 1.5505655542496712

Epoch: 6| Step: 13
Training loss: 0.15430468320846558
Validation loss: 1.524400737977797

Epoch: 363| Step: 0
Training loss: 0.25116419792175293
Validation loss: 1.532635522145097

Epoch: 6| Step: 1
Training loss: 0.1097472682595253
Validation loss: 1.519286055718699

Epoch: 6| Step: 2
Training loss: 0.17511388659477234
Validation loss: 1.5260790189107258

Epoch: 6| Step: 3
Training loss: 0.10166262090206146
Validation loss: 1.5588877598444622

Epoch: 6| Step: 4
Training loss: 0.12688922882080078
Validation loss: 1.5673827163634761

Epoch: 6| Step: 5
Training loss: 0.13267509639263153
Validation loss: 1.5578490072681057

Epoch: 6| Step: 6
Training loss: 0.13520923256874084
Validation loss: 1.5836615562438965

Epoch: 6| Step: 7
Training loss: 0.18225261569023132
Validation loss: 1.6168720465834423

Epoch: 6| Step: 8
Training loss: 0.35002732276916504
Validation loss: 1.571676590109384

Epoch: 6| Step: 9
Training loss: 0.12990322709083557
Validation loss: 1.5858694686684558

Epoch: 6| Step: 10
Training loss: 0.2334211766719818
Validation loss: 1.5637354530313963

Epoch: 6| Step: 11
Training loss: 0.17384393513202667
Validation loss: 1.566971960888114

Epoch: 6| Step: 12
Training loss: 0.1762416511774063
Validation loss: 1.5478440612875006

Epoch: 6| Step: 13
Training loss: 0.12819819152355194
Validation loss: 1.5558872376718829

Epoch: 364| Step: 0
Training loss: 0.160039484500885
Validation loss: 1.4970579172975274

Epoch: 6| Step: 1
Training loss: 0.14651107788085938
Validation loss: 1.4898596566210511

Epoch: 6| Step: 2
Training loss: 0.1675775796175003
Validation loss: 1.4453558344994821

Epoch: 6| Step: 3
Training loss: 0.15850037336349487
Validation loss: 1.48577897010311

Epoch: 6| Step: 4
Training loss: 0.3304254412651062
Validation loss: 1.4567025246158722

Epoch: 6| Step: 5
Training loss: 0.20760376751422882
Validation loss: 1.4823342446357972

Epoch: 6| Step: 6
Training loss: 0.1766597181558609
Validation loss: 1.4765432310360733

Epoch: 6| Step: 7
Training loss: 0.14207760989665985
Validation loss: 1.4991405804951985

Epoch: 6| Step: 8
Training loss: 0.12024189531803131
Validation loss: 1.479590101908612

Epoch: 6| Step: 9
Training loss: 0.18058475852012634
Validation loss: 1.5203365420782438

Epoch: 6| Step: 10
Training loss: 0.14539851248264313
Validation loss: 1.5501004970201882

Epoch: 6| Step: 11
Training loss: 0.1648872047662735
Validation loss: 1.5123050853770266

Epoch: 6| Step: 12
Training loss: 0.10634948313236237
Validation loss: 1.5390436828777354

Epoch: 6| Step: 13
Training loss: 0.2906494438648224
Validation loss: 1.5224901912032918

Epoch: 365| Step: 0
Training loss: 0.163247212767601
Validation loss: 1.485845132540631

Epoch: 6| Step: 1
Training loss: 0.11942789703607559
Validation loss: 1.5005829808532551

Epoch: 6| Step: 2
Training loss: 0.09955909103155136
Validation loss: 1.478835408405591

Epoch: 6| Step: 3
Training loss: 0.12925715744495392
Validation loss: 1.5021186477394515

Epoch: 6| Step: 4
Training loss: 0.146277517080307
Validation loss: 1.4752929902845813

Epoch: 6| Step: 5
Training loss: 0.16748899221420288
Validation loss: 1.4687448957914948

Epoch: 6| Step: 6
Training loss: 0.15404033660888672
Validation loss: 1.4527094312893447

Epoch: 6| Step: 7
Training loss: 0.07731149345636368
Validation loss: 1.4668497488062868

Epoch: 6| Step: 8
Training loss: 0.12267900258302689
Validation loss: 1.4925444542720754

Epoch: 6| Step: 9
Training loss: 0.17545261979103088
Validation loss: 1.4960342978918424

Epoch: 6| Step: 10
Training loss: 0.16685247421264648
Validation loss: 1.5186507496782529

Epoch: 6| Step: 11
Training loss: 0.3205987811088562
Validation loss: 1.520649572854401

Epoch: 6| Step: 12
Training loss: 0.09952150285243988
Validation loss: 1.5119957590615878

Epoch: 6| Step: 13
Training loss: 0.13719606399536133
Validation loss: 1.5223179324980705

Epoch: 366| Step: 0
Training loss: 0.07138846814632416
Validation loss: 1.5543429915623

Epoch: 6| Step: 1
Training loss: 0.2769509553909302
Validation loss: 1.5752338145368843

Epoch: 6| Step: 2
Training loss: 0.16965290904045105
Validation loss: 1.567280868048309

Epoch: 6| Step: 3
Training loss: 0.0663876086473465
Validation loss: 1.5344477674012542

Epoch: 6| Step: 4
Training loss: 0.09755000472068787
Validation loss: 1.5702214978074516

Epoch: 6| Step: 5
Training loss: 0.19075316190719604
Validation loss: 1.5870377447015496

Epoch: 6| Step: 6
Training loss: 0.15146911144256592
Validation loss: 1.5527754573411838

Epoch: 6| Step: 7
Training loss: 0.09207149595022202
Validation loss: 1.5329614070154005

Epoch: 6| Step: 8
Training loss: 0.11622684448957443
Validation loss: 1.5952188507203133

Epoch: 6| Step: 9
Training loss: 0.18427306413650513
Validation loss: 1.5462096711640716

Epoch: 6| Step: 10
Training loss: 0.18453249335289001
Validation loss: 1.5536297059828235

Epoch: 6| Step: 11
Training loss: 0.13777852058410645
Validation loss: 1.559331609356788

Epoch: 6| Step: 12
Training loss: 0.1447121500968933
Validation loss: 1.5590464748362058

Epoch: 6| Step: 13
Training loss: 0.10961520671844482
Validation loss: 1.536226176446484

Epoch: 367| Step: 0
Training loss: 0.15007659792900085
Validation loss: 1.5404086087339668

Epoch: 6| Step: 1
Training loss: 0.09888189285993576
Validation loss: 1.5385327146899315

Epoch: 6| Step: 2
Training loss: 0.17070308327674866
Validation loss: 1.5314064589879846

Epoch: 6| Step: 3
Training loss: 0.11251267790794373
Validation loss: 1.4880108923040412

Epoch: 6| Step: 4
Training loss: 0.08849652111530304
Validation loss: 1.5088080783044138

Epoch: 6| Step: 5
Training loss: 0.09722518920898438
Validation loss: 1.4626939911996164

Epoch: 6| Step: 6
Training loss: 0.2838147282600403
Validation loss: 1.476858062128867

Epoch: 6| Step: 7
Training loss: 0.24268905818462372
Validation loss: 1.4683693365384174

Epoch: 6| Step: 8
Training loss: 0.12084279209375381
Validation loss: 1.4508929175715293

Epoch: 6| Step: 9
Training loss: 0.12283532321453094
Validation loss: 1.4656887644080705

Epoch: 6| Step: 10
Training loss: 0.10353395342826843
Validation loss: 1.47214630598663

Epoch: 6| Step: 11
Training loss: 0.15130135416984558
Validation loss: 1.4906856872702157

Epoch: 6| Step: 12
Training loss: 0.17366918921470642
Validation loss: 1.489364803478282

Epoch: 6| Step: 13
Training loss: 0.11702872812747955
Validation loss: 1.4842950515849616

Epoch: 368| Step: 0
Training loss: 0.12502965331077576
Validation loss: 1.4863061545997538

Epoch: 6| Step: 1
Training loss: 0.17936590313911438
Validation loss: 1.4811223770982476

Epoch: 6| Step: 2
Training loss: 0.11794183403253555
Validation loss: 1.5012226591828048

Epoch: 6| Step: 3
Training loss: 0.14098235964775085
Validation loss: 1.4958865950184483

Epoch: 6| Step: 4
Training loss: 0.2275647521018982
Validation loss: 1.5451863799043881

Epoch: 6| Step: 5
Training loss: 0.24493439495563507
Validation loss: 1.5276345142754175

Epoch: 6| Step: 6
Training loss: 0.18112805485725403
Validation loss: 1.5116886092770485

Epoch: 6| Step: 7
Training loss: 0.0837792307138443
Validation loss: 1.5195132788791452

Epoch: 6| Step: 8
Training loss: 0.2830715775489807
Validation loss: 1.5147420180741178

Epoch: 6| Step: 9
Training loss: 0.1565253734588623
Validation loss: 1.5070154577173211

Epoch: 6| Step: 10
Training loss: 0.24537910521030426
Validation loss: 1.5374689358536915

Epoch: 6| Step: 11
Training loss: 0.14884372055530548
Validation loss: 1.5390810133308492

Epoch: 6| Step: 12
Training loss: 0.15047012269496918
Validation loss: 1.4738601625606578

Epoch: 6| Step: 13
Training loss: 0.10899832844734192
Validation loss: 1.494712136125052

Epoch: 369| Step: 0
Training loss: 0.1391659379005432
Validation loss: 1.4829532818127704

Epoch: 6| Step: 1
Training loss: 0.14458045363426208
Validation loss: 1.469363897077499

Epoch: 6| Step: 2
Training loss: 0.16242438554763794
Validation loss: 1.456235457492131

Epoch: 6| Step: 3
Training loss: 0.10344317555427551
Validation loss: 1.4509034118344706

Epoch: 6| Step: 4
Training loss: 0.1399305760860443
Validation loss: 1.4467795971901185

Epoch: 6| Step: 5
Training loss: 0.16481702029705048
Validation loss: 1.428860354167159

Epoch: 6| Step: 6
Training loss: 0.1365060806274414
Validation loss: 1.4604590669755013

Epoch: 6| Step: 7
Training loss: 0.0893319845199585
Validation loss: 1.4552717503680979

Epoch: 6| Step: 8
Training loss: 0.24708235263824463
Validation loss: 1.474205860527613

Epoch: 6| Step: 9
Training loss: 0.20174624025821686
Validation loss: 1.4846924158834642

Epoch: 6| Step: 10
Training loss: 0.12163541465997696
Validation loss: 1.5084272353879866

Epoch: 6| Step: 11
Training loss: 0.28691595792770386
Validation loss: 1.51261721375168

Epoch: 6| Step: 12
Training loss: 0.0987406075000763
Validation loss: 1.523671583462787

Epoch: 6| Step: 13
Training loss: 0.09776674211025238
Validation loss: 1.4846925389382146

Epoch: 370| Step: 0
Training loss: 0.08960287272930145
Validation loss: 1.4878080878206479

Epoch: 6| Step: 1
Training loss: 0.09354837238788605
Validation loss: 1.5035094420115154

Epoch: 6| Step: 2
Training loss: 0.29161006212234497
Validation loss: 1.4904748034733597

Epoch: 6| Step: 3
Training loss: 0.13398054242134094
Validation loss: 1.5092956795487353

Epoch: 6| Step: 4
Training loss: 0.09895338118076324
Validation loss: 1.5033908556866389

Epoch: 6| Step: 5
Training loss: 0.15014351904392242
Validation loss: 1.5273022369671894

Epoch: 6| Step: 6
Training loss: 0.18055036664009094
Validation loss: 1.5275593803774925

Epoch: 6| Step: 7
Training loss: 0.2188975065946579
Validation loss: 1.5253916684017386

Epoch: 6| Step: 8
Training loss: 0.08996860682964325
Validation loss: 1.506922298862088

Epoch: 6| Step: 9
Training loss: 0.18494912981987
Validation loss: 1.4971500878692956

Epoch: 6| Step: 10
Training loss: 0.1537448912858963
Validation loss: 1.4492405435090423

Epoch: 6| Step: 11
Training loss: 0.08707538992166519
Validation loss: 1.4609573015602686

Epoch: 6| Step: 12
Training loss: 0.1352246105670929
Validation loss: 1.4986834743971467

Epoch: 6| Step: 13
Training loss: 0.21597348153591156
Validation loss: 1.4587767412585597

Epoch: 371| Step: 0
Training loss: 0.10013101249933243
Validation loss: 1.4428728947075464

Epoch: 6| Step: 1
Training loss: 0.11686231195926666
Validation loss: 1.4686979645042009

Epoch: 6| Step: 2
Training loss: 0.2878648042678833
Validation loss: 1.4533972958082795

Epoch: 6| Step: 3
Training loss: 0.0970156192779541
Validation loss: 1.4751334190368652

Epoch: 6| Step: 4
Training loss: 0.07756896317005157
Validation loss: 1.4650343464266868

Epoch: 6| Step: 5
Training loss: 0.19507548213005066
Validation loss: 1.4822635163543045

Epoch: 6| Step: 6
Training loss: 0.1624443531036377
Validation loss: 1.4751472960236252

Epoch: 6| Step: 7
Training loss: 0.14106494188308716
Validation loss: 1.4994662692469936

Epoch: 6| Step: 8
Training loss: 0.1388658881187439
Validation loss: 1.543818171306323

Epoch: 6| Step: 9
Training loss: 0.0640067607164383
Validation loss: 1.4976697910216548

Epoch: 6| Step: 10
Training loss: 0.10770152509212494
Validation loss: 1.5505847495089295

Epoch: 6| Step: 11
Training loss: 0.16815802454948425
Validation loss: 1.5644679325883106

Epoch: 6| Step: 12
Training loss: 0.15595488250255585
Validation loss: 1.5662502114490797

Epoch: 6| Step: 13
Training loss: 0.18056374788284302
Validation loss: 1.5578274521776425

Epoch: 372| Step: 0
Training loss: 0.10989256203174591
Validation loss: 1.5417990710145684

Epoch: 6| Step: 1
Training loss: 0.1570308357477188
Validation loss: 1.522202544314887

Epoch: 6| Step: 2
Training loss: 0.09904193878173828
Validation loss: 1.5261924459088234

Epoch: 6| Step: 3
Training loss: 0.1629980057477951
Validation loss: 1.5141745357103245

Epoch: 6| Step: 4
Training loss: 0.06327322870492935
Validation loss: 1.5400817278892762

Epoch: 6| Step: 5
Training loss: 0.11363819241523743
Validation loss: 1.4799388762443297

Epoch: 6| Step: 6
Training loss: 0.11630886793136597
Validation loss: 1.5205507720670393

Epoch: 6| Step: 7
Training loss: 0.13035890460014343
Validation loss: 1.5231585887170607

Epoch: 6| Step: 8
Training loss: 0.356375128030777
Validation loss: 1.4936969434061358

Epoch: 6| Step: 9
Training loss: 0.15542227029800415
Validation loss: 1.504828082617893

Epoch: 6| Step: 10
Training loss: 0.11272066831588745
Validation loss: 1.4800834886489376

Epoch: 6| Step: 11
Training loss: 0.08976628631353378
Validation loss: 1.506810378002864

Epoch: 6| Step: 12
Training loss: 0.07458943128585815
Validation loss: 1.4935999352444884

Epoch: 6| Step: 13
Training loss: 0.23844559490680695
Validation loss: 1.5145981965526458

Epoch: 373| Step: 0
Training loss: 0.12579454481601715
Validation loss: 1.4956651682494788

Epoch: 6| Step: 1
Training loss: 0.1385863870382309
Validation loss: 1.4992340815964567

Epoch: 6| Step: 2
Training loss: 0.11355401575565338
Validation loss: 1.5000045171347998

Epoch: 6| Step: 3
Training loss: 0.11841501295566559
Validation loss: 1.5074933510954662

Epoch: 6| Step: 4
Training loss: 0.1498725265264511
Validation loss: 1.4905180418363182

Epoch: 6| Step: 5
Training loss: 0.07802334427833557
Validation loss: 1.532677520987808

Epoch: 6| Step: 6
Training loss: 0.29466933012008667
Validation loss: 1.5162917772928874

Epoch: 6| Step: 7
Training loss: 0.11354557424783707
Validation loss: 1.4904980249302362

Epoch: 6| Step: 8
Training loss: 0.09009575843811035
Validation loss: 1.4818740737053655

Epoch: 6| Step: 9
Training loss: 0.13253718614578247
Validation loss: 1.4678690343774774

Epoch: 6| Step: 10
Training loss: 0.1313982754945755
Validation loss: 1.4610304794003885

Epoch: 6| Step: 11
Training loss: 0.1784953474998474
Validation loss: 1.4426111117486031

Epoch: 6| Step: 12
Training loss: 0.10205930471420288
Validation loss: 1.4614388814536474

Epoch: 6| Step: 13
Training loss: 0.20457638800144196
Validation loss: 1.4482076360333351

Epoch: 374| Step: 0
Training loss: 0.15639406442642212
Validation loss: 1.447863366014214

Epoch: 6| Step: 1
Training loss: 0.0993434339761734
Validation loss: 1.4476892544377236

Epoch: 6| Step: 2
Training loss: 0.1816321760416031
Validation loss: 1.4493756191704863

Epoch: 6| Step: 3
Training loss: 0.06400178372859955
Validation loss: 1.4693264345968924

Epoch: 6| Step: 4
Training loss: 0.12282099574804306
Validation loss: 1.4608792220392535

Epoch: 6| Step: 5
Training loss: 0.09556593000888824
Validation loss: 1.4614744429947228

Epoch: 6| Step: 6
Training loss: 0.06996306777000427
Validation loss: 1.4681746908413467

Epoch: 6| Step: 7
Training loss: 0.1856135129928589
Validation loss: 1.4750808977311658

Epoch: 6| Step: 8
Training loss: 0.09116248786449432
Validation loss: 1.484930169197821

Epoch: 6| Step: 9
Training loss: 0.08195061981678009
Validation loss: 1.461333215877574

Epoch: 6| Step: 10
Training loss: 0.16710464656352997
Validation loss: 1.5052042571447228

Epoch: 6| Step: 11
Training loss: 0.27855056524276733
Validation loss: 1.4894050885272283

Epoch: 6| Step: 12
Training loss: 0.15361830592155457
Validation loss: 1.4884140799122472

Epoch: 6| Step: 13
Training loss: 0.11940794438123703
Validation loss: 1.5055865062180387

Epoch: 375| Step: 0
Training loss: 0.15119129419326782
Validation loss: 1.4720772402260893

Epoch: 6| Step: 1
Training loss: 0.1095295399427414
Validation loss: 1.4611389060174265

Epoch: 6| Step: 2
Training loss: 0.13087716698646545
Validation loss: 1.4570437291617035

Epoch: 6| Step: 3
Training loss: 0.125698983669281
Validation loss: 1.456868411392294

Epoch: 6| Step: 4
Training loss: 0.13652348518371582
Validation loss: 1.4481576527318647

Epoch: 6| Step: 5
Training loss: 0.16725262999534607
Validation loss: 1.4500671561046312

Epoch: 6| Step: 6
Training loss: 0.28118664026260376
Validation loss: 1.4659644378128873

Epoch: 6| Step: 7
Training loss: 0.12875781953334808
Validation loss: 1.4617241826108707

Epoch: 6| Step: 8
Training loss: 0.10166895389556885
Validation loss: 1.4756720912071966

Epoch: 6| Step: 9
Training loss: 0.11771806329488754
Validation loss: 1.4905439012794084

Epoch: 6| Step: 10
Training loss: 0.08221772313117981
Validation loss: 1.5030076401208037

Epoch: 6| Step: 11
Training loss: 0.13619402050971985
Validation loss: 1.5352456723490069

Epoch: 6| Step: 12
Training loss: 0.13427138328552246
Validation loss: 1.5082474549611409

Epoch: 6| Step: 13
Training loss: 0.20136618614196777
Validation loss: 1.5532770182496758

Epoch: 376| Step: 0
Training loss: 0.2303992211818695
Validation loss: 1.542606407596219

Epoch: 6| Step: 1
Training loss: 0.21172863245010376
Validation loss: 1.5587886943612048

Epoch: 6| Step: 2
Training loss: 0.16112014651298523
Validation loss: 1.5440560931800513

Epoch: 6| Step: 3
Training loss: 0.20168136060237885
Validation loss: 1.5348594009235341

Epoch: 6| Step: 4
Training loss: 0.0790390595793724
Validation loss: 1.522239455612757

Epoch: 6| Step: 5
Training loss: 0.10239580273628235
Validation loss: 1.4958847081789406

Epoch: 6| Step: 6
Training loss: 0.12403810024261475
Validation loss: 1.4921275454182779

Epoch: 6| Step: 7
Training loss: 0.11730702221393585
Validation loss: 1.477401811589477

Epoch: 6| Step: 8
Training loss: 0.1226152703166008
Validation loss: 1.4875116117538945

Epoch: 6| Step: 9
Training loss: 0.21821212768554688
Validation loss: 1.4668408337459768

Epoch: 6| Step: 10
Training loss: 0.2465764433145523
Validation loss: 1.4654587545702535

Epoch: 6| Step: 11
Training loss: 0.07465734332799911
Validation loss: 1.475366529598031

Epoch: 6| Step: 12
Training loss: 0.12039371579885483
Validation loss: 1.5076453403760028

Epoch: 6| Step: 13
Training loss: 0.2660781443119049
Validation loss: 1.4737341378324775

Epoch: 377| Step: 0
Training loss: 0.1415574848651886
Validation loss: 1.4985324426363873

Epoch: 6| Step: 1
Training loss: 0.08901757001876831
Validation loss: 1.4947902476915749

Epoch: 6| Step: 2
Training loss: 0.09639348089694977
Validation loss: 1.4980934025138937

Epoch: 6| Step: 3
Training loss: 0.08711180090904236
Validation loss: 1.4937691893628848

Epoch: 6| Step: 4
Training loss: 0.15993806719779968
Validation loss: 1.4943912093357374

Epoch: 6| Step: 5
Training loss: 0.1557847410440445
Validation loss: 1.4853949021267634

Epoch: 6| Step: 6
Training loss: 0.1704825758934021
Validation loss: 1.498812848521817

Epoch: 6| Step: 7
Training loss: 0.3230091333389282
Validation loss: 1.5145445921087777

Epoch: 6| Step: 8
Training loss: 0.14216668903827667
Validation loss: 1.518867814412681

Epoch: 6| Step: 9
Training loss: 0.13682705163955688
Validation loss: 1.4888245687689832

Epoch: 6| Step: 10
Training loss: 0.1399468332529068
Validation loss: 1.4497223067027267

Epoch: 6| Step: 11
Training loss: 0.06506459414958954
Validation loss: 1.4288973449378886

Epoch: 6| Step: 12
Training loss: 0.18257102370262146
Validation loss: 1.4717568018103158

Epoch: 6| Step: 13
Training loss: 0.11935705691576004
Validation loss: 1.4403000723931096

Epoch: 378| Step: 0
Training loss: 0.1724274754524231
Validation loss: 1.4723865332141999

Epoch: 6| Step: 1
Training loss: 0.18881060183048248
Validation loss: 1.4613247366361721

Epoch: 6| Step: 2
Training loss: 0.37927937507629395
Validation loss: 1.4792596511943366

Epoch: 6| Step: 3
Training loss: 0.12667155265808105
Validation loss: 1.478957188385789

Epoch: 6| Step: 4
Training loss: 0.1692761331796646
Validation loss: 1.4943195850618425

Epoch: 6| Step: 5
Training loss: 0.10496565699577332
Validation loss: 1.4585077903603996

Epoch: 6| Step: 6
Training loss: 0.10302915424108505
Validation loss: 1.4689927190862677

Epoch: 6| Step: 7
Training loss: 0.09642434865236282
Validation loss: 1.4216081365462272

Epoch: 6| Step: 8
Training loss: 0.14401023089885712
Validation loss: 1.4375369728252452

Epoch: 6| Step: 9
Training loss: 0.17202085256576538
Validation loss: 1.4674656814144504

Epoch: 6| Step: 10
Training loss: 0.10152681171894073
Validation loss: 1.472249355367435

Epoch: 6| Step: 11
Training loss: 0.16895897686481476
Validation loss: 1.4717615797955503

Epoch: 6| Step: 12
Training loss: 0.1925727277994156
Validation loss: 1.4792409968632523

Epoch: 6| Step: 13
Training loss: 0.14576154947280884
Validation loss: 1.4770611550218316

Epoch: 379| Step: 0
Training loss: 0.07833756506443024
Validation loss: 1.4761008395943591

Epoch: 6| Step: 1
Training loss: 0.14642448723316193
Validation loss: 1.4735485994687645

Epoch: 6| Step: 2
Training loss: 0.18612107634544373
Validation loss: 1.5098898564615557

Epoch: 6| Step: 3
Training loss: 0.13497266173362732
Validation loss: 1.512958780411751

Epoch: 6| Step: 4
Training loss: 0.2244747281074524
Validation loss: 1.5029086887195546

Epoch: 6| Step: 5
Training loss: 0.38761192560195923
Validation loss: 1.4904815458482312

Epoch: 6| Step: 6
Training loss: 0.09954085946083069
Validation loss: 1.5053232228884132

Epoch: 6| Step: 7
Training loss: 0.1361461579799652
Validation loss: 1.527654852277489

Epoch: 6| Step: 8
Training loss: 0.12080361694097519
Validation loss: 1.5057553866858124

Epoch: 6| Step: 9
Training loss: 0.14705422520637512
Validation loss: 1.4980828813327256

Epoch: 6| Step: 10
Training loss: 0.1612919270992279
Validation loss: 1.5049601588197934

Epoch: 6| Step: 11
Training loss: 0.10853752493858337
Validation loss: 1.4924361680143623

Epoch: 6| Step: 12
Training loss: 0.174812451004982
Validation loss: 1.4773002824475687

Epoch: 6| Step: 13
Training loss: 0.06947781890630722
Validation loss: 1.4795259378289665

Epoch: 380| Step: 0
Training loss: 0.12104122340679169
Validation loss: 1.4615059142471643

Epoch: 6| Step: 1
Training loss: 0.08105425536632538
Validation loss: 1.4697664181391399

Epoch: 6| Step: 2
Training loss: 0.1697559356689453
Validation loss: 1.4554082962774462

Epoch: 6| Step: 3
Training loss: 0.15897628664970398
Validation loss: 1.4814500936897852

Epoch: 6| Step: 4
Training loss: 0.09760407358407974
Validation loss: 1.4758182430780062

Epoch: 6| Step: 5
Training loss: 0.2936934232711792
Validation loss: 1.5014136337464856

Epoch: 6| Step: 6
Training loss: 0.07429075241088867
Validation loss: 1.5024523811955606

Epoch: 6| Step: 7
Training loss: 0.0717359408736229
Validation loss: 1.482946031837053

Epoch: 6| Step: 8
Training loss: 0.13290643692016602
Validation loss: 1.4984364855674006

Epoch: 6| Step: 9
Training loss: 0.09759530425071716
Validation loss: 1.4567688767628004

Epoch: 6| Step: 10
Training loss: 0.11605408787727356
Validation loss: 1.4643708390574302

Epoch: 6| Step: 11
Training loss: 0.11443887650966644
Validation loss: 1.4896714200255692

Epoch: 6| Step: 12
Training loss: 0.1645297408103943
Validation loss: 1.477333664894104

Epoch: 6| Step: 13
Training loss: 0.1412196159362793
Validation loss: 1.4744724086535874

Epoch: 381| Step: 0
Training loss: 0.08804381638765335
Validation loss: 1.4794818650009811

Epoch: 6| Step: 1
Training loss: 0.16552811861038208
Validation loss: 1.4585251013437908

Epoch: 6| Step: 2
Training loss: 0.1046476662158966
Validation loss: 1.477334878777945

Epoch: 6| Step: 3
Training loss: 0.10807985812425613
Validation loss: 1.4882231617486605

Epoch: 6| Step: 4
Training loss: 0.09427995979785919
Validation loss: 1.4878220647893927

Epoch: 6| Step: 5
Training loss: 0.13104362785816193
Validation loss: 1.4811558902904551

Epoch: 6| Step: 6
Training loss: 0.05335260182619095
Validation loss: 1.5017477645668933

Epoch: 6| Step: 7
Training loss: 0.11598028242588043
Validation loss: 1.4839667684288436

Epoch: 6| Step: 8
Training loss: 0.1232973113656044
Validation loss: 1.4738618712271414

Epoch: 6| Step: 9
Training loss: 0.11406368762254715
Validation loss: 1.505377431069651

Epoch: 6| Step: 10
Training loss: 0.13504604995250702
Validation loss: 1.526170829931895

Epoch: 6| Step: 11
Training loss: 0.34326696395874023
Validation loss: 1.5285648210074312

Epoch: 6| Step: 12
Training loss: 0.12265007197856903
Validation loss: 1.4769725274014216

Epoch: 6| Step: 13
Training loss: 0.14796003699302673
Validation loss: 1.4741159395505024

Epoch: 382| Step: 0
Training loss: 0.0856475681066513
Validation loss: 1.474149473251835

Epoch: 6| Step: 1
Training loss: 0.2582828998565674
Validation loss: 1.4454277112919798

Epoch: 6| Step: 2
Training loss: 0.1142660528421402
Validation loss: 1.4849576693709179

Epoch: 6| Step: 3
Training loss: 0.2285514622926712
Validation loss: 1.4708784857103903

Epoch: 6| Step: 4
Training loss: 0.13702784478664398
Validation loss: 1.4699635838949552

Epoch: 6| Step: 5
Training loss: 0.20275001227855682
Validation loss: 1.5059816273309852

Epoch: 6| Step: 6
Training loss: 0.1468704640865326
Validation loss: 1.473484262343376

Epoch: 6| Step: 7
Training loss: 0.19898706674575806
Validation loss: 1.4929693975756246

Epoch: 6| Step: 8
Training loss: 0.1618427336215973
Validation loss: 1.4715921660905242

Epoch: 6| Step: 9
Training loss: 0.10756929218769073
Validation loss: 1.5139391793999621

Epoch: 6| Step: 10
Training loss: 0.17213448882102966
Validation loss: 1.5302372401760471

Epoch: 6| Step: 11
Training loss: 0.12170204520225525
Validation loss: 1.5294189119851718

Epoch: 6| Step: 12
Training loss: 0.1570478081703186
Validation loss: 1.545241690451099

Epoch: 6| Step: 13
Training loss: 0.1626647710800171
Validation loss: 1.5718682812106224

Epoch: 383| Step: 0
Training loss: 0.12920719385147095
Validation loss: 1.5404336952394055

Epoch: 6| Step: 1
Training loss: 0.07666804641485214
Validation loss: 1.552806008246637

Epoch: 6| Step: 2
Training loss: 0.3168680965900421
Validation loss: 1.507013085067913

Epoch: 6| Step: 3
Training loss: 0.13849051296710968
Validation loss: 1.489952851367253

Epoch: 6| Step: 4
Training loss: 0.10056297481060028
Validation loss: 1.4707623515077817

Epoch: 6| Step: 5
Training loss: 0.1822873055934906
Validation loss: 1.473344502910491

Epoch: 6| Step: 6
Training loss: 0.1429702490568161
Validation loss: 1.467468254027828

Epoch: 6| Step: 7
Training loss: 0.1305520236492157
Validation loss: 1.4784745285587926

Epoch: 6| Step: 8
Training loss: 0.09710271656513214
Validation loss: 1.466986007587884

Epoch: 6| Step: 9
Training loss: 0.14225250482559204
Validation loss: 1.4324712368749803

Epoch: 6| Step: 10
Training loss: 0.08652441948652267
Validation loss: 1.4693212368155038

Epoch: 6| Step: 11
Training loss: 0.1445574313402176
Validation loss: 1.4448342054120955

Epoch: 6| Step: 12
Training loss: 0.12463027238845825
Validation loss: 1.4561082573347195

Epoch: 6| Step: 13
Training loss: 0.117497019469738
Validation loss: 1.444878913061593

Epoch: 384| Step: 0
Training loss: 0.2324177622795105
Validation loss: 1.4620019338464225

Epoch: 6| Step: 1
Training loss: 0.12596705555915833
Validation loss: 1.4663166461452362

Epoch: 6| Step: 2
Training loss: 0.1481727510690689
Validation loss: 1.4738080283646942

Epoch: 6| Step: 3
Training loss: 0.09643809497356415
Validation loss: 1.4495098898487706

Epoch: 6| Step: 4
Training loss: 0.10792556405067444
Validation loss: 1.4773287644950293

Epoch: 6| Step: 5
Training loss: 0.05825779587030411
Validation loss: 1.4536017294852965

Epoch: 6| Step: 6
Training loss: 0.07943073660135269
Validation loss: 1.500840417800411

Epoch: 6| Step: 7
Training loss: 0.08736804127693176
Validation loss: 1.4834002499939294

Epoch: 6| Step: 8
Training loss: 0.3149230480194092
Validation loss: 1.4976806576533983

Epoch: 6| Step: 9
Training loss: 0.14779484272003174
Validation loss: 1.4897390360473304

Epoch: 6| Step: 10
Training loss: 0.11462334543466568
Validation loss: 1.4664841339152346

Epoch: 6| Step: 11
Training loss: 0.11588622629642487
Validation loss: 1.457810942844678

Epoch: 6| Step: 12
Training loss: 0.16067174077033997
Validation loss: 1.451172190327798

Epoch: 6| Step: 13
Training loss: 0.09616817533969879
Validation loss: 1.4471743542660949

Epoch: 385| Step: 0
Training loss: 0.1925813853740692
Validation loss: 1.4743625412705124

Epoch: 6| Step: 1
Training loss: 0.3296494483947754
Validation loss: 1.4835469857338937

Epoch: 6| Step: 2
Training loss: 0.11071570217609406
Validation loss: 1.489539486105724

Epoch: 6| Step: 3
Training loss: 0.1561562418937683
Validation loss: 1.47075524509594

Epoch: 6| Step: 4
Training loss: 0.09976702183485031
Validation loss: 1.480364579026417

Epoch: 6| Step: 5
Training loss: 0.12303347885608673
Validation loss: 1.5074786524618826

Epoch: 6| Step: 6
Training loss: 0.10006456077098846
Validation loss: 1.518335860262635

Epoch: 6| Step: 7
Training loss: 0.13983960449695587
Validation loss: 1.5190441582792549

Epoch: 6| Step: 8
Training loss: 0.14099720120429993
Validation loss: 1.5200542352532829

Epoch: 6| Step: 9
Training loss: 0.12777484953403473
Validation loss: 1.4942297025393414

Epoch: 6| Step: 10
Training loss: 0.16655124723911285
Validation loss: 1.5063175732089626

Epoch: 6| Step: 11
Training loss: 0.10691696405410767
Validation loss: 1.5025251591077415

Epoch: 6| Step: 12
Training loss: 0.14313676953315735
Validation loss: 1.4958558851672756

Epoch: 6| Step: 13
Training loss: 0.12013275176286697
Validation loss: 1.4589371245394471

Epoch: 386| Step: 0
Training loss: 0.21984562277793884
Validation loss: 1.4866467919400943

Epoch: 6| Step: 1
Training loss: 0.19359688460826874
Validation loss: 1.4398173734705935

Epoch: 6| Step: 2
Training loss: 0.19515562057495117
Validation loss: 1.4324603683205062

Epoch: 6| Step: 3
Training loss: 0.12766104936599731
Validation loss: 1.4306706690019177

Epoch: 6| Step: 4
Training loss: 0.14127671718597412
Validation loss: 1.4156968170596707

Epoch: 6| Step: 5
Training loss: 0.16165271401405334
Validation loss: 1.4339256773712814

Epoch: 6| Step: 6
Training loss: 0.12858113646507263
Validation loss: 1.44067237582258

Epoch: 6| Step: 7
Training loss: 0.1392735093832016
Validation loss: 1.4676341164496638

Epoch: 6| Step: 8
Training loss: 0.13294285535812378
Validation loss: 1.4537671009699504

Epoch: 6| Step: 9
Training loss: 0.1107911542057991
Validation loss: 1.491487121069303

Epoch: 6| Step: 10
Training loss: 0.20018942654132843
Validation loss: 1.489980798895641

Epoch: 6| Step: 11
Training loss: 0.2883930504322052
Validation loss: 1.4853303368373583

Epoch: 6| Step: 12
Training loss: 0.09803453832864761
Validation loss: 1.4653793893834597

Epoch: 6| Step: 13
Training loss: 0.09305387735366821
Validation loss: 1.4360532452983241

Epoch: 387| Step: 0
Training loss: 0.1656443327665329
Validation loss: 1.4406828982855684

Epoch: 6| Step: 1
Training loss: 0.08159958571195602
Validation loss: 1.4502724236057651

Epoch: 6| Step: 2
Training loss: 0.24051892757415771
Validation loss: 1.4497158347919423

Epoch: 6| Step: 3
Training loss: 0.13614855706691742
Validation loss: 1.4454399654942174

Epoch: 6| Step: 4
Training loss: 0.1626882553100586
Validation loss: 1.4105771651832006

Epoch: 6| Step: 5
Training loss: 0.09473363310098648
Validation loss: 1.4145300478063605

Epoch: 6| Step: 6
Training loss: 0.08334752172231674
Validation loss: 1.4473428546741445

Epoch: 6| Step: 7
Training loss: 0.13695555925369263
Validation loss: 1.420848508675893

Epoch: 6| Step: 8
Training loss: 0.12952780723571777
Validation loss: 1.441382182541714

Epoch: 6| Step: 9
Training loss: 0.10908272862434387
Validation loss: 1.4280388310391416

Epoch: 6| Step: 10
Training loss: 0.11965502053499222
Validation loss: 1.433180816711918

Epoch: 6| Step: 11
Training loss: 0.10708089172840118
Validation loss: 1.416817936846005

Epoch: 6| Step: 12
Training loss: 0.13816489279270172
Validation loss: 1.4251312696805565

Epoch: 6| Step: 13
Training loss: 0.07108712196350098
Validation loss: 1.4633842052951935

Epoch: 388| Step: 0
Training loss: 0.12290839105844498
Validation loss: 1.4599933803722422

Epoch: 6| Step: 1
Training loss: 0.09937737137079239
Validation loss: 1.4310855711660078

Epoch: 6| Step: 2
Training loss: 0.14466385543346405
Validation loss: 1.4102807467983616

Epoch: 6| Step: 3
Training loss: 0.09936408698558807
Validation loss: 1.4217244168763519

Epoch: 6| Step: 4
Training loss: 0.1608758568763733
Validation loss: 1.4435089608674407

Epoch: 6| Step: 5
Training loss: 0.12469947338104248
Validation loss: 1.4419144238195112

Epoch: 6| Step: 6
Training loss: 0.11552741378545761
Validation loss: 1.4629700978597004

Epoch: 6| Step: 7
Training loss: 0.24956411123275757
Validation loss: 1.4549883091321556

Epoch: 6| Step: 8
Training loss: 0.16352686285972595
Validation loss: 1.4678448874463317

Epoch: 6| Step: 9
Training loss: 0.1238488107919693
Validation loss: 1.4413809244350722

Epoch: 6| Step: 10
Training loss: 0.11506389826536179
Validation loss: 1.4428307125645299

Epoch: 6| Step: 11
Training loss: 0.1687154471874237
Validation loss: 1.4376783806790587

Epoch: 6| Step: 12
Training loss: 0.06851717829704285
Validation loss: 1.439863242128844

Epoch: 6| Step: 13
Training loss: 0.09308269619941711
Validation loss: 1.447724602555716

Epoch: 389| Step: 0
Training loss: 0.09696567058563232
Validation loss: 1.430521156198235

Epoch: 6| Step: 1
Training loss: 0.11744814366102219
Validation loss: 1.428087479324751

Epoch: 6| Step: 2
Training loss: 0.10106280446052551
Validation loss: 1.4392142859838342

Epoch: 6| Step: 3
Training loss: 0.07527487725019455
Validation loss: 1.4292721850897676

Epoch: 6| Step: 4
Training loss: 0.08392046391963959
Validation loss: 1.4224405442514727

Epoch: 6| Step: 5
Training loss: 0.08509548753499985
Validation loss: 1.4274353647744784

Epoch: 6| Step: 6
Training loss: 0.09438461065292358
Validation loss: 1.4492134112183765

Epoch: 6| Step: 7
Training loss: 0.14107301831245422
Validation loss: 1.465880060708651

Epoch: 6| Step: 8
Training loss: 0.06054103374481201
Validation loss: 1.454045138051433

Epoch: 6| Step: 9
Training loss: 0.11061151325702667
Validation loss: 1.4595965070109214

Epoch: 6| Step: 10
Training loss: 0.28345900774002075
Validation loss: 1.4278855285336893

Epoch: 6| Step: 11
Training loss: 0.13609278202056885
Validation loss: 1.4621579980337491

Epoch: 6| Step: 12
Training loss: 0.10729475319385529
Validation loss: 1.4574378651957358

Epoch: 6| Step: 13
Training loss: 0.2100573182106018
Validation loss: 1.4589010412975023

Epoch: 390| Step: 0
Training loss: 0.24835944175720215
Validation loss: 1.4964394697579004

Epoch: 6| Step: 1
Training loss: 0.12771499156951904
Validation loss: 1.455433617356003

Epoch: 6| Step: 2
Training loss: 0.10898298025131226
Validation loss: 1.4653711485606369

Epoch: 6| Step: 3
Training loss: 0.10848318040370941
Validation loss: 1.4442163654552993

Epoch: 6| Step: 4
Training loss: 0.1419171392917633
Validation loss: 1.4117522669094864

Epoch: 6| Step: 5
Training loss: 0.0925101488828659
Validation loss: 1.4169750662260159

Epoch: 6| Step: 6
Training loss: 0.11483181267976761
Validation loss: 1.4147392549822408

Epoch: 6| Step: 7
Training loss: 0.10690845549106598
Validation loss: 1.4190438729460522

Epoch: 6| Step: 8
Training loss: 0.16498512029647827
Validation loss: 1.4145388500664824

Epoch: 6| Step: 9
Training loss: 0.15049277245998383
Validation loss: 1.4067790597997687

Epoch: 6| Step: 10
Training loss: 0.14787645637989044
Validation loss: 1.4095428784688313

Epoch: 6| Step: 11
Training loss: 0.148586243391037
Validation loss: 1.3997260896108483

Epoch: 6| Step: 12
Training loss: 0.07946090400218964
Validation loss: 1.3974413487219042

Epoch: 6| Step: 13
Training loss: 0.21797312796115875
Validation loss: 1.4086365097312517

Epoch: 391| Step: 0
Training loss: 0.08269185572862625
Validation loss: 1.4077597151520431

Epoch: 6| Step: 1
Training loss: 0.14517006278038025
Validation loss: 1.4023853425056703

Epoch: 6| Step: 2
Training loss: 0.11900229752063751
Validation loss: 1.4177456379577678

Epoch: 6| Step: 3
Training loss: 0.2510807514190674
Validation loss: 1.4281747812224972

Epoch: 6| Step: 4
Training loss: 0.13828980922698975
Validation loss: 1.4319227459610149

Epoch: 6| Step: 5
Training loss: 0.1457975208759308
Validation loss: 1.413493816570569

Epoch: 6| Step: 6
Training loss: 0.11894341558218002
Validation loss: 1.4200801426364529

Epoch: 6| Step: 7
Training loss: 0.08457600325345993
Validation loss: 1.4201095155490342

Epoch: 6| Step: 8
Training loss: 0.1267351508140564
Validation loss: 1.4256730784652054

Epoch: 6| Step: 9
Training loss: 0.09081951528787613
Validation loss: 1.4364245219897198

Epoch: 6| Step: 10
Training loss: 0.09140496701002121
Validation loss: 1.4201548830155404

Epoch: 6| Step: 11
Training loss: 0.1435312181711197
Validation loss: 1.4235982548805974

Epoch: 6| Step: 12
Training loss: 0.13086427748203278
Validation loss: 1.4047624552121727

Epoch: 6| Step: 13
Training loss: 0.09173215925693512
Validation loss: 1.433905691228887

Epoch: 392| Step: 0
Training loss: 0.12283582240343094
Validation loss: 1.4275651618998537

Epoch: 6| Step: 1
Training loss: 0.05317448824644089
Validation loss: 1.4401499238065494

Epoch: 6| Step: 2
Training loss: 0.07609796524047852
Validation loss: 1.4084811005541074

Epoch: 6| Step: 3
Training loss: 0.14913327991962433
Validation loss: 1.4322929818143126

Epoch: 6| Step: 4
Training loss: 0.17076781392097473
Validation loss: 1.4652760964567944

Epoch: 6| Step: 5
Training loss: 0.14525918662548065
Validation loss: 1.4616486475031862

Epoch: 6| Step: 6
Training loss: 0.29716920852661133
Validation loss: 1.4620648942967898

Epoch: 6| Step: 7
Training loss: 0.1375856101512909
Validation loss: 1.451476913626476

Epoch: 6| Step: 8
Training loss: 0.08438662439584732
Validation loss: 1.4747792546467116

Epoch: 6| Step: 9
Training loss: 0.13894349336624146
Validation loss: 1.446449306703383

Epoch: 6| Step: 10
Training loss: 0.11603116244077682
Validation loss: 1.3915921885480163

Epoch: 6| Step: 11
Training loss: 0.08181439340114594
Validation loss: 1.4728247260534635

Epoch: 6| Step: 12
Training loss: 0.13564112782478333
Validation loss: 1.4474018401997064

Epoch: 6| Step: 13
Training loss: 0.10557486116886139
Validation loss: 1.433735029671782

Epoch: 393| Step: 0
Training loss: 0.15001018345355988
Validation loss: 1.4608447423545263

Epoch: 6| Step: 1
Training loss: 0.14285209774971008
Validation loss: 1.4819736173076015

Epoch: 6| Step: 2
Training loss: 0.11747536063194275
Validation loss: 1.4768028541277813

Epoch: 6| Step: 3
Training loss: 0.13351291418075562
Validation loss: 1.4872486283702235

Epoch: 6| Step: 4
Training loss: 0.13271760940551758
Validation loss: 1.4985764680370208

Epoch: 6| Step: 5
Training loss: 0.12524691224098206
Validation loss: 1.4767627312291054

Epoch: 6| Step: 6
Training loss: 0.11095581948757172
Validation loss: 1.4687751390600716

Epoch: 6| Step: 7
Training loss: 0.07324854284524918
Validation loss: 1.4997744739696544

Epoch: 6| Step: 8
Training loss: 0.1408141553401947
Validation loss: 1.493010131261682

Epoch: 6| Step: 9
Training loss: 0.11023370176553726
Validation loss: 1.500728057276818

Epoch: 6| Step: 10
Training loss: 0.1176747977733612
Validation loss: 1.4726598621696554

Epoch: 6| Step: 11
Training loss: 0.16167160868644714
Validation loss: 1.5119921148464244

Epoch: 6| Step: 12
Training loss: 0.24217185378074646
Validation loss: 1.486135463560781

Epoch: 6| Step: 13
Training loss: 0.1131121963262558
Validation loss: 1.4821085391506073

Epoch: 394| Step: 0
Training loss: 0.0928068608045578
Validation loss: 1.4732725825361026

Epoch: 6| Step: 1
Training loss: 0.08983615785837173
Validation loss: 1.459671119207977

Epoch: 6| Step: 2
Training loss: 0.1652417778968811
Validation loss: 1.464088047704389

Epoch: 6| Step: 3
Training loss: 0.10971037298440933
Validation loss: 1.4535985992800804

Epoch: 6| Step: 4
Training loss: 0.0816279873251915
Validation loss: 1.47317797394209

Epoch: 6| Step: 5
Training loss: 0.12849777936935425
Validation loss: 1.4752813923743464

Epoch: 6| Step: 6
Training loss: 0.1187249943614006
Validation loss: 1.4600416165526195

Epoch: 6| Step: 7
Training loss: 0.17736798524856567
Validation loss: 1.4791316947629374

Epoch: 6| Step: 8
Training loss: 0.13144151866436005
Validation loss: 1.4880961782188826

Epoch: 6| Step: 9
Training loss: 0.27234670519828796
Validation loss: 1.5144853117645427

Epoch: 6| Step: 10
Training loss: 0.15321969985961914
Validation loss: 1.5079310773521342

Epoch: 6| Step: 11
Training loss: 0.11426683515310287
Validation loss: 1.5166457647918372

Epoch: 6| Step: 12
Training loss: 0.12793079018592834
Validation loss: 1.543372631072998

Epoch: 6| Step: 13
Training loss: 0.11824791878461838
Validation loss: 1.5220140564826228

Epoch: 395| Step: 0
Training loss: 0.15215659141540527
Validation loss: 1.5024915433699084

Epoch: 6| Step: 1
Training loss: 0.17190684378147125
Validation loss: 1.4867575476246495

Epoch: 6| Step: 2
Training loss: 0.14133581519126892
Validation loss: 1.4906784821582097

Epoch: 6| Step: 3
Training loss: 0.126170352101326
Validation loss: 1.4883194578591215

Epoch: 6| Step: 4
Training loss: 0.3665401041507721
Validation loss: 1.4966083444574827

Epoch: 6| Step: 5
Training loss: 0.1232646182179451
Validation loss: 1.4448247558327132

Epoch: 6| Step: 6
Training loss: 0.13614314794540405
Validation loss: 1.4577904785833051

Epoch: 6| Step: 7
Training loss: 0.14128009974956512
Validation loss: 1.4664238422147688

Epoch: 6| Step: 8
Training loss: 0.09266707301139832
Validation loss: 1.4527170709384385

Epoch: 6| Step: 9
Training loss: 0.06438137590885162
Validation loss: 1.447481119504539

Epoch: 6| Step: 10
Training loss: 0.1119363009929657
Validation loss: 1.4672043233789422

Epoch: 6| Step: 11
Training loss: 0.07224217057228088
Validation loss: 1.5147895172078123

Epoch: 6| Step: 12
Training loss: 0.11966745555400848
Validation loss: 1.4862330305960871

Epoch: 6| Step: 13
Training loss: 0.14288949966430664
Validation loss: 1.531482978533673

Epoch: 396| Step: 0
Training loss: 0.23428070545196533
Validation loss: 1.5253170626137846

Epoch: 6| Step: 1
Training loss: 0.16956548392772675
Validation loss: 1.4879940568759877

Epoch: 6| Step: 2
Training loss: 0.16903600096702576
Validation loss: 1.5305617201712824

Epoch: 6| Step: 3
Training loss: 0.09150976687669754
Validation loss: 1.5260652944605837

Epoch: 6| Step: 4
Training loss: 0.12215586006641388
Validation loss: 1.5091043685072212

Epoch: 6| Step: 5
Training loss: 0.14597289264202118
Validation loss: 1.483279243592293

Epoch: 6| Step: 6
Training loss: 0.1014387384057045
Validation loss: 1.492924323645971

Epoch: 6| Step: 7
Training loss: 0.1463910937309265
Validation loss: 1.5062816527581984

Epoch: 6| Step: 8
Training loss: 0.29925084114074707
Validation loss: 1.4781182414741927

Epoch: 6| Step: 9
Training loss: 0.10572478175163269
Validation loss: 1.469817324351239

Epoch: 6| Step: 10
Training loss: 0.16578228771686554
Validation loss: 1.4650221729791293

Epoch: 6| Step: 11
Training loss: 0.17068105936050415
Validation loss: 1.460252869513727

Epoch: 6| Step: 12
Training loss: 0.06813906133174896
Validation loss: 1.4978375716875958

Epoch: 6| Step: 13
Training loss: 0.09579847753047943
Validation loss: 1.5048387550538587

Epoch: 397| Step: 0
Training loss: 0.10339514166116714
Validation loss: 1.4990862505410307

Epoch: 6| Step: 1
Training loss: 0.1426321566104889
Validation loss: 1.5197378486715338

Epoch: 6| Step: 2
Training loss: 0.10828006267547607
Validation loss: 1.465474356887161

Epoch: 6| Step: 3
Training loss: 0.12298893928527832
Validation loss: 1.467590183340093

Epoch: 6| Step: 4
Training loss: 0.24133159220218658
Validation loss: 1.4645119508107503

Epoch: 6| Step: 5
Training loss: 0.3395906686782837
Validation loss: 1.4831504142412575

Epoch: 6| Step: 6
Training loss: 0.12240272760391235
Validation loss: 1.4403536460732902

Epoch: 6| Step: 7
Training loss: 0.07760486751794815
Validation loss: 1.4510759140855523

Epoch: 6| Step: 8
Training loss: 0.08839275687932968
Validation loss: 1.463245722555345

Epoch: 6| Step: 9
Training loss: 0.147798091173172
Validation loss: 1.4373165022942327

Epoch: 6| Step: 10
Training loss: 0.1534372866153717
Validation loss: 1.4362804517951062

Epoch: 6| Step: 11
Training loss: 0.1117185428738594
Validation loss: 1.4018283473548068

Epoch: 6| Step: 12
Training loss: 0.16023626923561096
Validation loss: 1.4529855764040382

Epoch: 6| Step: 13
Training loss: 0.08424728363752365
Validation loss: 1.450666977513221

Epoch: 398| Step: 0
Training loss: 0.2644626498222351
Validation loss: 1.4437459168895599

Epoch: 6| Step: 1
Training loss: 0.09428513795137405
Validation loss: 1.4604300478453278

Epoch: 6| Step: 2
Training loss: 0.12962447106838226
Validation loss: 1.4725737635807326

Epoch: 6| Step: 3
Training loss: 0.13584831357002258
Validation loss: 1.464150148053323

Epoch: 6| Step: 4
Training loss: 0.1743299663066864
Validation loss: 1.447356035632472

Epoch: 6| Step: 5
Training loss: 0.12456633150577545
Validation loss: 1.4605230541639431

Epoch: 6| Step: 6
Training loss: 0.10614945739507675
Validation loss: 1.466178471683174

Epoch: 6| Step: 7
Training loss: 0.12049014121294022
Validation loss: 1.457364147709262

Epoch: 6| Step: 8
Training loss: 0.0812707245349884
Validation loss: 1.4618275204012472

Epoch: 6| Step: 9
Training loss: 0.1340915858745575
Validation loss: 1.4634599993305821

Epoch: 6| Step: 10
Training loss: 0.1374884396791458
Validation loss: 1.4168049161152174

Epoch: 6| Step: 11
Training loss: 0.09099364280700684
Validation loss: 1.4419876862597722

Epoch: 6| Step: 12
Training loss: 0.048377931118011475
Validation loss: 1.4699299732844036

Epoch: 6| Step: 13
Training loss: 0.13525445759296417
Validation loss: 1.4396977745076662

Epoch: 399| Step: 0
Training loss: 0.09596693515777588
Validation loss: 1.389027774974864

Epoch: 6| Step: 1
Training loss: 0.2671672999858856
Validation loss: 1.4374673148637176

Epoch: 6| Step: 2
Training loss: 0.12521648406982422
Validation loss: 1.4417414088403024

Epoch: 6| Step: 3
Training loss: 0.08985458314418793
Validation loss: 1.4389172818071099

Epoch: 6| Step: 4
Training loss: 0.11797450482845306
Validation loss: 1.438511598494745

Epoch: 6| Step: 5
Training loss: 0.06529384851455688
Validation loss: 1.45113706076017

Epoch: 6| Step: 6
Training loss: 0.14259383082389832
Validation loss: 1.4426547263258247

Epoch: 6| Step: 7
Training loss: 0.08782370388507843
Validation loss: 1.4010054802381864

Epoch: 6| Step: 8
Training loss: 0.09867484122514725
Validation loss: 1.428637029022299

Epoch: 6| Step: 9
Training loss: 0.13247713446617126
Validation loss: 1.4502872215804232

Epoch: 6| Step: 10
Training loss: 0.1130223274230957
Validation loss: 1.4179055639492568

Epoch: 6| Step: 11
Training loss: 0.12021873146295547
Validation loss: 1.4370277491948937

Epoch: 6| Step: 12
Training loss: 0.1252872496843338
Validation loss: 1.4230652573288127

Epoch: 6| Step: 13
Training loss: 0.1853356957435608
Validation loss: 1.4524006112929313

Epoch: 400| Step: 0
Training loss: 0.13966308534145355
Validation loss: 1.4473422752913607

Epoch: 6| Step: 1
Training loss: 0.10902812331914902
Validation loss: 1.4425682278089627

Epoch: 6| Step: 2
Training loss: 0.1174045205116272
Validation loss: 1.42789545495023

Epoch: 6| Step: 3
Training loss: 0.24215427041053772
Validation loss: 1.4639843548497846

Epoch: 6| Step: 4
Training loss: 0.1269204318523407
Validation loss: 1.4648582858424033

Epoch: 6| Step: 5
Training loss: 0.11623768508434296
Validation loss: 1.4589110061686525

Epoch: 6| Step: 6
Training loss: 0.1256742924451828
Validation loss: 1.4582185822148477

Epoch: 6| Step: 7
Training loss: 0.12849664688110352
Validation loss: 1.4491717097579793

Epoch: 6| Step: 8
Training loss: 0.06218639016151428
Validation loss: 1.4655584032817552

Epoch: 6| Step: 9
Training loss: 0.07827678322792053
Validation loss: 1.4515061737388693

Epoch: 6| Step: 10
Training loss: 0.15593810379505157
Validation loss: 1.4618904661106806

Epoch: 6| Step: 11
Training loss: 0.19101449847221375
Validation loss: 1.4498769147421724

Epoch: 6| Step: 12
Training loss: 0.10467326641082764
Validation loss: 1.4649594137745519

Epoch: 6| Step: 13
Training loss: 0.09416460990905762
Validation loss: 1.4275541087632537

Epoch: 401| Step: 0
Training loss: 0.2786494791507721
Validation loss: 1.446621657699667

Epoch: 6| Step: 1
Training loss: 0.1130293756723404
Validation loss: 1.4204508835269558

Epoch: 6| Step: 2
Training loss: 0.11747371405363083
Validation loss: 1.4308304568772674

Epoch: 6| Step: 3
Training loss: 0.22461266815662384
Validation loss: 1.4273828050141693

Epoch: 6| Step: 4
Training loss: 0.18270930647850037
Validation loss: 1.4211514842125677

Epoch: 6| Step: 5
Training loss: 0.13769212365150452
Validation loss: 1.4587672038744854

Epoch: 6| Step: 6
Training loss: 0.14730608463287354
Validation loss: 1.449116288974721

Epoch: 6| Step: 7
Training loss: 0.13978800177574158
Validation loss: 1.4271765319249963

Epoch: 6| Step: 8
Training loss: 0.13461799919605255
Validation loss: 1.4524661526885083

Epoch: 6| Step: 9
Training loss: 0.09712432324886322
Validation loss: 1.4939675497752365

Epoch: 6| Step: 10
Training loss: 0.1187763512134552
Validation loss: 1.486752768998505

Epoch: 6| Step: 11
Training loss: 0.1362881064414978
Validation loss: 1.5231514720506565

Epoch: 6| Step: 12
Training loss: 0.13455967605113983
Validation loss: 1.5161627966870543

Epoch: 6| Step: 13
Training loss: 0.14068946242332458
Validation loss: 1.503567668699449

Epoch: 402| Step: 0
Training loss: 0.17168813943862915
Validation loss: 1.4977041675198464

Epoch: 6| Step: 1
Training loss: 0.1051422655582428
Validation loss: 1.512893598566773

Epoch: 6| Step: 2
Training loss: 0.121864914894104
Validation loss: 1.4712398564943703

Epoch: 6| Step: 3
Training loss: 0.14802685379981995
Validation loss: 1.468387456350429

Epoch: 6| Step: 4
Training loss: 0.2336958348751068
Validation loss: 1.4248600980286956

Epoch: 6| Step: 5
Training loss: 0.2810916006565094
Validation loss: 1.441981001566815

Epoch: 6| Step: 6
Training loss: 0.11479099094867706
Validation loss: 1.3973452942345732

Epoch: 6| Step: 7
Training loss: 0.13410475850105286
Validation loss: 1.4044105314439344

Epoch: 6| Step: 8
Training loss: 0.08026038110256195
Validation loss: 1.4034000699238112

Epoch: 6| Step: 9
Training loss: 0.06243070960044861
Validation loss: 1.3763840993245442

Epoch: 6| Step: 10
Training loss: 0.17055454850196838
Validation loss: 1.4122661608521656

Epoch: 6| Step: 11
Training loss: 0.07260836660861969
Validation loss: 1.3973703474126837

Epoch: 6| Step: 12
Training loss: 0.08601231873035431
Validation loss: 1.429828215670842

Epoch: 6| Step: 13
Training loss: 0.15500934422016144
Validation loss: 1.4375665187835693

Epoch: 403| Step: 0
Training loss: 0.14347782731056213
Validation loss: 1.4454201190702376

Epoch: 6| Step: 1
Training loss: 0.10210143029689789
Validation loss: 1.42437284223495

Epoch: 6| Step: 2
Training loss: 0.16730210185050964
Validation loss: 1.4379606375130274

Epoch: 6| Step: 3
Training loss: 0.11988195776939392
Validation loss: 1.4322539606401998

Epoch: 6| Step: 4
Training loss: 0.11188243329524994
Validation loss: 1.444314472136959

Epoch: 6| Step: 5
Training loss: 0.08588628470897675
Validation loss: 1.4104815221601916

Epoch: 6| Step: 6
Training loss: 0.15784761309623718
Validation loss: 1.4372783181487874

Epoch: 6| Step: 7
Training loss: 0.09693998098373413
Validation loss: 1.4243718597196764

Epoch: 6| Step: 8
Training loss: 0.13093556463718414
Validation loss: 1.4434329014952465

Epoch: 6| Step: 9
Training loss: 0.29162609577178955
Validation loss: 1.4305598005171745

Epoch: 6| Step: 10
Training loss: 0.1349727213382721
Validation loss: 1.4843597617200626

Epoch: 6| Step: 11
Training loss: 0.14789190888404846
Validation loss: 1.4394917488098145

Epoch: 6| Step: 12
Training loss: 0.14183349907398224
Validation loss: 1.438491653370601

Epoch: 6| Step: 13
Training loss: 0.09803108125925064
Validation loss: 1.4390467495046637

Epoch: 404| Step: 0
Training loss: 0.09754008054733276
Validation loss: 1.4687853526043635

Epoch: 6| Step: 1
Training loss: 0.0526607446372509
Validation loss: 1.4579105261833436

Epoch: 6| Step: 2
Training loss: 0.2245226800441742
Validation loss: 1.443108102326752

Epoch: 6| Step: 3
Training loss: 0.10569390654563904
Validation loss: 1.416257325039115

Epoch: 6| Step: 4
Training loss: 0.2719016373157501
Validation loss: 1.4388768769079638

Epoch: 6| Step: 5
Training loss: 0.12373089790344238
Validation loss: 1.4526359817033172

Epoch: 6| Step: 6
Training loss: 0.14230933785438538
Validation loss: 1.4616441265229256

Epoch: 6| Step: 7
Training loss: 0.07471054792404175
Validation loss: 1.4596475119231849

Epoch: 6| Step: 8
Training loss: 0.08463343977928162
Validation loss: 1.4388470970174319

Epoch: 6| Step: 9
Training loss: 0.10468009114265442
Validation loss: 1.456576802397287

Epoch: 6| Step: 10
Training loss: 0.11832893639802933
Validation loss: 1.462529351634364

Epoch: 6| Step: 11
Training loss: 0.1872689127922058
Validation loss: 1.443793458323325

Epoch: 6| Step: 12
Training loss: 0.12582364678382874
Validation loss: 1.4240368297023158

Epoch: 6| Step: 13
Training loss: 0.10397402942180634
Validation loss: 1.4472759039171281

Epoch: 405| Step: 0
Training loss: 0.05462285503745079
Validation loss: 1.4146171872333815

Epoch: 6| Step: 1
Training loss: 0.09218497574329376
Validation loss: 1.3877870036709694

Epoch: 6| Step: 2
Training loss: 0.05795031413435936
Validation loss: 1.410878780067608

Epoch: 6| Step: 3
Training loss: 0.10471206903457642
Validation loss: 1.4006476697101389

Epoch: 6| Step: 4
Training loss: 0.1600974202156067
Validation loss: 1.4016130752460931

Epoch: 6| Step: 5
Training loss: 0.16304709017276764
Validation loss: 1.4105048153990059

Epoch: 6| Step: 6
Training loss: 0.10144010186195374
Validation loss: 1.4293613446656095

Epoch: 6| Step: 7
Training loss: 0.2745334506034851
Validation loss: 1.449334272774317

Epoch: 6| Step: 8
Training loss: 0.17131799459457397
Validation loss: 1.4499261904788274

Epoch: 6| Step: 9
Training loss: 0.18191349506378174
Validation loss: 1.4909030775870047

Epoch: 6| Step: 10
Training loss: 0.11657465249300003
Validation loss: 1.4391367730273996

Epoch: 6| Step: 11
Training loss: 0.11528665572404861
Validation loss: 1.5000417617059523

Epoch: 6| Step: 12
Training loss: 0.14633432030677795
Validation loss: 1.5085745498698244

Epoch: 6| Step: 13
Training loss: 0.19956350326538086
Validation loss: 1.4988900487140944

Epoch: 406| Step: 0
Training loss: 0.13297611474990845
Validation loss: 1.4822427380469538

Epoch: 6| Step: 1
Training loss: 0.11321135610342026
Validation loss: 1.4379412140897525

Epoch: 6| Step: 2
Training loss: 0.13678023219108582
Validation loss: 1.4547016748818018

Epoch: 6| Step: 3
Training loss: 0.11152780801057816
Validation loss: 1.4179396103787165

Epoch: 6| Step: 4
Training loss: 0.17052975296974182
Validation loss: 1.4151514140508508

Epoch: 6| Step: 5
Training loss: 0.1055770143866539
Validation loss: 1.405081364416307

Epoch: 6| Step: 6
Training loss: 0.3029080033302307
Validation loss: 1.4111506810752295

Epoch: 6| Step: 7
Training loss: 0.16010399162769318
Validation loss: 1.404129877526273

Epoch: 6| Step: 8
Training loss: 0.10984136909246445
Validation loss: 1.4053589131242485

Epoch: 6| Step: 9
Training loss: 0.0908191129565239
Validation loss: 1.408884927790652

Epoch: 6| Step: 10
Training loss: 0.10880156606435776
Validation loss: 1.3900187233442902

Epoch: 6| Step: 11
Training loss: 0.15628813207149506
Validation loss: 1.4307746656479374

Epoch: 6| Step: 12
Training loss: 0.12629444897174835
Validation loss: 1.4215500508585284

Epoch: 6| Step: 13
Training loss: 0.1669234186410904
Validation loss: 1.4245950868052821

Epoch: 407| Step: 0
Training loss: 0.1345411092042923
Validation loss: 1.43649370695955

Epoch: 6| Step: 1
Training loss: 0.10732695460319519
Validation loss: 1.4297082129345144

Epoch: 6| Step: 2
Training loss: 0.09845593571662903
Validation loss: 1.4379134107661504

Epoch: 6| Step: 3
Training loss: 0.06604967266321182
Validation loss: 1.4346896589443248

Epoch: 6| Step: 4
Training loss: 0.13093319535255432
Validation loss: 1.4327392911398282

Epoch: 6| Step: 5
Training loss: 0.2545744478702545
Validation loss: 1.4296624019581785

Epoch: 6| Step: 6
Training loss: 0.12134584039449692
Validation loss: 1.4268403437829786

Epoch: 6| Step: 7
Training loss: 0.10913357883691788
Validation loss: 1.4461596678662043

Epoch: 6| Step: 8
Training loss: 0.20427121222019196
Validation loss: 1.4342806903264855

Epoch: 6| Step: 9
Training loss: 0.1055326759815216
Validation loss: 1.4558371138829056

Epoch: 6| Step: 10
Training loss: 0.09293274581432343
Validation loss: 1.451821510509778

Epoch: 6| Step: 11
Training loss: 0.20595911145210266
Validation loss: 1.4473402897516887

Epoch: 6| Step: 12
Training loss: 0.11106833070516586
Validation loss: 1.4783967156564035

Epoch: 6| Step: 13
Training loss: 0.17416569590568542
Validation loss: 1.4442763738734747

Epoch: 408| Step: 0
Training loss: 0.10224869102239609
Validation loss: 1.462572536160869

Epoch: 6| Step: 1
Training loss: 0.12004425376653671
Validation loss: 1.4925707431249722

Epoch: 6| Step: 2
Training loss: 0.14638084173202515
Validation loss: 1.450619601434277

Epoch: 6| Step: 3
Training loss: 0.16388779878616333
Validation loss: 1.4683820688596336

Epoch: 6| Step: 4
Training loss: 0.06219995766878128
Validation loss: 1.4710551897684734

Epoch: 6| Step: 5
Training loss: 0.12120294570922852
Validation loss: 1.4375632347599152

Epoch: 6| Step: 6
Training loss: 0.19515734910964966
Validation loss: 1.4382895320974372

Epoch: 6| Step: 7
Training loss: 0.26503103971481323
Validation loss: 1.4510038578382103

Epoch: 6| Step: 8
Training loss: 0.12117551267147064
Validation loss: 1.4509547897564468

Epoch: 6| Step: 9
Training loss: 0.08103399723768234
Validation loss: 1.4334507321798673

Epoch: 6| Step: 10
Training loss: 0.2042357623577118
Validation loss: 1.4384238976304249

Epoch: 6| Step: 11
Training loss: 0.1790851205587387
Validation loss: 1.4233375595461937

Epoch: 6| Step: 12
Training loss: 0.12648844718933105
Validation loss: 1.4160304697611

Epoch: 6| Step: 13
Training loss: 0.18820133805274963
Validation loss: 1.4418265909276984

Epoch: 409| Step: 0
Training loss: 0.14911720156669617
Validation loss: 1.4350543675884124

Epoch: 6| Step: 1
Training loss: 0.10037528723478317
Validation loss: 1.4557738349001894

Epoch: 6| Step: 2
Training loss: 0.16801723837852478
Validation loss: 1.4694643802540277

Epoch: 6| Step: 3
Training loss: 0.16614022850990295
Validation loss: 1.4591939308310067

Epoch: 6| Step: 4
Training loss: 0.18842554092407227
Validation loss: 1.4810969047648932

Epoch: 6| Step: 5
Training loss: 0.1373962163925171
Validation loss: 1.463686473907963

Epoch: 6| Step: 6
Training loss: 0.35001707077026367
Validation loss: 1.4531921648210095

Epoch: 6| Step: 7
Training loss: 0.19161349534988403
Validation loss: 1.4408652449166903

Epoch: 6| Step: 8
Training loss: 0.11762358248233795
Validation loss: 1.4375668379568285

Epoch: 6| Step: 9
Training loss: 0.11970317363739014
Validation loss: 1.4690819568531488

Epoch: 6| Step: 10
Training loss: 0.11452174931764603
Validation loss: 1.5090278156342045

Epoch: 6| Step: 11
Training loss: 0.11338095366954803
Validation loss: 1.4952720378034858

Epoch: 6| Step: 12
Training loss: 0.08870582282543182
Validation loss: 1.5073908919929175

Epoch: 6| Step: 13
Training loss: 0.11116096377372742
Validation loss: 1.5110585035816315

Epoch: 410| Step: 0
Training loss: 0.1304413229227066
Validation loss: 1.4701693622014855

Epoch: 6| Step: 1
Training loss: 0.19618196785449982
Validation loss: 1.4759668406619821

Epoch: 6| Step: 2
Training loss: 0.06013430655002594
Validation loss: 1.4870615543857697

Epoch: 6| Step: 3
Training loss: 0.12848857045173645
Validation loss: 1.4699071165054076

Epoch: 6| Step: 4
Training loss: 0.11030013859272003
Validation loss: 1.4684511384656351

Epoch: 6| Step: 5
Training loss: 0.08911100775003433
Validation loss: 1.495356664862684

Epoch: 6| Step: 6
Training loss: 0.1547749936580658
Validation loss: 1.4850826987656214

Epoch: 6| Step: 7
Training loss: 0.10994084179401398
Validation loss: 1.4834363947632492

Epoch: 6| Step: 8
Training loss: 0.11291702091693878
Validation loss: 1.4723822634707215

Epoch: 6| Step: 9
Training loss: 0.11453722417354584
Validation loss: 1.4364263248699967

Epoch: 6| Step: 10
Training loss: 0.13608044385910034
Validation loss: 1.4571478315578994

Epoch: 6| Step: 11
Training loss: 0.09542033076286316
Validation loss: 1.4301688094292917

Epoch: 6| Step: 12
Training loss: 0.2860661745071411
Validation loss: 1.4421369362902898

Epoch: 6| Step: 13
Training loss: 0.2498415857553482
Validation loss: 1.4537466238903742

Epoch: 411| Step: 0
Training loss: 0.18555369973182678
Validation loss: 1.3956042438425043

Epoch: 6| Step: 1
Training loss: 0.2526881694793701
Validation loss: 1.4204726654996154

Epoch: 6| Step: 2
Training loss: 0.11494413018226624
Validation loss: 1.4403677627604494

Epoch: 6| Step: 3
Training loss: 0.09142343699932098
Validation loss: 1.3895322456154773

Epoch: 6| Step: 4
Training loss: 0.08708681166172028
Validation loss: 1.4077011795454129

Epoch: 6| Step: 5
Training loss: 0.11992648988962173
Validation loss: 1.420325143362886

Epoch: 6| Step: 6
Training loss: 0.1275930404663086
Validation loss: 1.4271137752840597

Epoch: 6| Step: 7
Training loss: 0.1327710747718811
Validation loss: 1.4317547813538583

Epoch: 6| Step: 8
Training loss: 0.18433937430381775
Validation loss: 1.4333740306156937

Epoch: 6| Step: 9
Training loss: 0.18269844353199005
Validation loss: 1.4047563434928976

Epoch: 6| Step: 10
Training loss: 0.0927780494093895
Validation loss: 1.4530292409722523

Epoch: 6| Step: 11
Training loss: 0.11002442240715027
Validation loss: 1.4586781173624017

Epoch: 6| Step: 12
Training loss: 0.1442132145166397
Validation loss: 1.4459885115264564

Epoch: 6| Step: 13
Training loss: 0.1289241909980774
Validation loss: 1.4737559294187894

Epoch: 412| Step: 0
Training loss: 0.085595041513443
Validation loss: 1.4331800424924461

Epoch: 6| Step: 1
Training loss: 0.1478947550058365
Validation loss: 1.4288342768146145

Epoch: 6| Step: 2
Training loss: 0.08546145260334015
Validation loss: 1.4343089685645154

Epoch: 6| Step: 3
Training loss: 0.09972093999385834
Validation loss: 1.446424558598508

Epoch: 6| Step: 4
Training loss: 0.09660771489143372
Validation loss: 1.4420559021734423

Epoch: 6| Step: 5
Training loss: 0.1306927353143692
Validation loss: 1.4182240860436552

Epoch: 6| Step: 6
Training loss: 0.15856114029884338
Validation loss: 1.444419087902192

Epoch: 6| Step: 7
Training loss: 0.10983560234308243
Validation loss: 1.4332861259419432

Epoch: 6| Step: 8
Training loss: 0.16493675112724304
Validation loss: 1.4334040188020276

Epoch: 6| Step: 9
Training loss: 0.2970079779624939
Validation loss: 1.4037344788992276

Epoch: 6| Step: 10
Training loss: 0.08534489572048187
Validation loss: 1.4210581228297243

Epoch: 6| Step: 11
Training loss: 0.12033230811357498
Validation loss: 1.432468605297868

Epoch: 6| Step: 12
Training loss: 0.09765462577342987
Validation loss: 1.4303728406147291

Epoch: 6| Step: 13
Training loss: 0.031936246901750565
Validation loss: 1.4471985191427252

Epoch: 413| Step: 0
Training loss: 0.11971289664506912
Validation loss: 1.4587230643918436

Epoch: 6| Step: 1
Training loss: 0.18478228151798248
Validation loss: 1.4466795613688808

Epoch: 6| Step: 2
Training loss: 0.1482047587633133
Validation loss: 1.471490474157436

Epoch: 6| Step: 3
Training loss: 0.14667022228240967
Validation loss: 1.4646840992794241

Epoch: 6| Step: 4
Training loss: 0.11849646270275116
Validation loss: 1.430836695496754

Epoch: 6| Step: 5
Training loss: 0.21348677575588226
Validation loss: 1.4259237845738728

Epoch: 6| Step: 6
Training loss: 0.13808299601078033
Validation loss: 1.4140309121019097

Epoch: 6| Step: 7
Training loss: 0.08162243664264679
Validation loss: 1.382133464018504

Epoch: 6| Step: 8
Training loss: 0.14700523018836975
Validation loss: 1.3780141902226273

Epoch: 6| Step: 9
Training loss: 0.08105430006980896
Validation loss: 1.4086137958752212

Epoch: 6| Step: 10
Training loss: 0.1860029101371765
Validation loss: 1.4031717456797117

Epoch: 6| Step: 11
Training loss: 0.1256864368915558
Validation loss: 1.4258878897595149

Epoch: 6| Step: 12
Training loss: 0.10620377957820892
Validation loss: 1.4080594585787864

Epoch: 6| Step: 13
Training loss: 0.21932931244373322
Validation loss: 1.4251103119183612

Epoch: 414| Step: 0
Training loss: 0.15886731445789337
Validation loss: 1.4537305485817693

Epoch: 6| Step: 1
Training loss: 0.12021954357624054
Validation loss: 1.4354865204903386

Epoch: 6| Step: 2
Training loss: 0.15111763775348663
Validation loss: 1.40878681085443

Epoch: 6| Step: 3
Training loss: 0.29758864641189575
Validation loss: 1.432166318739614

Epoch: 6| Step: 4
Training loss: 0.14889836311340332
Validation loss: 1.4452286369057112

Epoch: 6| Step: 5
Training loss: 0.1311274915933609
Validation loss: 1.435388111299084

Epoch: 6| Step: 6
Training loss: 0.12818850576877594
Validation loss: 1.4366680306773032

Epoch: 6| Step: 7
Training loss: 0.08868925273418427
Validation loss: 1.4502420963779572

Epoch: 6| Step: 8
Training loss: 0.09767059236764908
Validation loss: 1.4650045889680103

Epoch: 6| Step: 9
Training loss: 0.14293643832206726
Validation loss: 1.487584734475741

Epoch: 6| Step: 10
Training loss: 0.1331457793712616
Validation loss: 1.5005779471448673

Epoch: 6| Step: 11
Training loss: 0.11807946115732193
Validation loss: 1.4895981434852845

Epoch: 6| Step: 12
Training loss: 0.12019257992506027
Validation loss: 1.4527673759768087

Epoch: 6| Step: 13
Training loss: 0.15404349565505981
Validation loss: 1.4511981036073418

Epoch: 415| Step: 0
Training loss: 0.15916931629180908
Validation loss: 1.4807739501358361

Epoch: 6| Step: 1
Training loss: 0.08348600566387177
Validation loss: 1.459455455503156

Epoch: 6| Step: 2
Training loss: 0.11167237162590027
Validation loss: 1.461153095768344

Epoch: 6| Step: 3
Training loss: 0.10197140276432037
Validation loss: 1.4467416437723304

Epoch: 6| Step: 4
Training loss: 0.13859519362449646
Validation loss: 1.4426529228046376

Epoch: 6| Step: 5
Training loss: 0.07479597628116608
Validation loss: 1.462662717347504

Epoch: 6| Step: 6
Training loss: 0.1172044426202774
Validation loss: 1.4357376867725002

Epoch: 6| Step: 7
Training loss: 0.11737945675849915
Validation loss: 1.4212639536908878

Epoch: 6| Step: 8
Training loss: 0.11968962103128433
Validation loss: 1.4492247950646184

Epoch: 6| Step: 9
Training loss: 0.08834907412528992
Validation loss: 1.4154411951700847

Epoch: 6| Step: 10
Training loss: 0.14353108406066895
Validation loss: 1.4148213081462409

Epoch: 6| Step: 11
Training loss: 0.11149801313877106
Validation loss: 1.4324150598177345

Epoch: 6| Step: 12
Training loss: 0.11156730353832245
Validation loss: 1.4196983877048697

Epoch: 6| Step: 13
Training loss: 0.394508957862854
Validation loss: 1.4655230814410793

Epoch: 416| Step: 0
Training loss: 0.08868792653083801
Validation loss: 1.4482334031853625

Epoch: 6| Step: 1
Training loss: 0.10198449343442917
Validation loss: 1.4717126648913148

Epoch: 6| Step: 2
Training loss: 0.10368762910366058
Validation loss: 1.4729554781349756

Epoch: 6| Step: 3
Training loss: 0.13484802842140198
Validation loss: 1.442835727045613

Epoch: 6| Step: 4
Training loss: 0.1669604480266571
Validation loss: 1.4539178366302161

Epoch: 6| Step: 5
Training loss: 0.28098323941230774
Validation loss: 1.4300490733115905

Epoch: 6| Step: 6
Training loss: 0.09973794966936111
Validation loss: 1.4386594080796806

Epoch: 6| Step: 7
Training loss: 0.12238439172506332
Validation loss: 1.433038285983506

Epoch: 6| Step: 8
Training loss: 0.0992463231086731
Validation loss: 1.4520693132954259

Epoch: 6| Step: 9
Training loss: 0.1381475180387497
Validation loss: 1.4179083134538384

Epoch: 6| Step: 10
Training loss: 0.14109140634536743
Validation loss: 1.4335983132803312

Epoch: 6| Step: 11
Training loss: 0.12511706352233887
Validation loss: 1.42811289013073

Epoch: 6| Step: 12
Training loss: 0.06214369833469391
Validation loss: 1.4581980730897637

Epoch: 6| Step: 13
Training loss: 0.10221020132303238
Validation loss: 1.4231592378308695

Epoch: 417| Step: 0
Training loss: 0.1070864126086235
Validation loss: 1.4505807891968758

Epoch: 6| Step: 1
Training loss: 0.12906871736049652
Validation loss: 1.4886939141058153

Epoch: 6| Step: 2
Training loss: 0.06898467242717743
Validation loss: 1.4825661554131457

Epoch: 6| Step: 3
Training loss: 0.09560821950435638
Validation loss: 1.4990425558500393

Epoch: 6| Step: 4
Training loss: 0.3096233308315277
Validation loss: 1.4851894602980664

Epoch: 6| Step: 5
Training loss: 0.12695789337158203
Validation loss: 1.4736431567899642

Epoch: 6| Step: 6
Training loss: 0.10651048272848129
Validation loss: 1.483515917613942

Epoch: 6| Step: 7
Training loss: 0.11330568790435791
Validation loss: 1.4403819704568515

Epoch: 6| Step: 8
Training loss: 0.14490634202957153
Validation loss: 1.4407127864899174

Epoch: 6| Step: 9
Training loss: 0.13834248483181
Validation loss: 1.4822064330500941

Epoch: 6| Step: 10
Training loss: 0.12752856314182281
Validation loss: 1.4382161094296364

Epoch: 6| Step: 11
Training loss: 0.11061453074216843
Validation loss: 1.4668080396549676

Epoch: 6| Step: 12
Training loss: 0.09296248108148575
Validation loss: 1.4665126415991014

Epoch: 6| Step: 13
Training loss: 0.08133348822593689
Validation loss: 1.4500806882817259

Epoch: 418| Step: 0
Training loss: 0.1188463419675827
Validation loss: 1.4412489488560667

Epoch: 6| Step: 1
Training loss: 0.1673090159893036
Validation loss: 1.4463476096430132

Epoch: 6| Step: 2
Training loss: 0.11517570912837982
Validation loss: 1.4448541082361692

Epoch: 6| Step: 3
Training loss: 0.0751505047082901
Validation loss: 1.4720906942121443

Epoch: 6| Step: 4
Training loss: 0.07526074349880219
Validation loss: 1.4647015974085817

Epoch: 6| Step: 5
Training loss: 0.1651519536972046
Validation loss: 1.447970672320294

Epoch: 6| Step: 6
Training loss: 0.07387268543243408
Validation loss: 1.4744115234703146

Epoch: 6| Step: 7
Training loss: 0.11002828180789948
Validation loss: 1.4905657345248806

Epoch: 6| Step: 8
Training loss: 0.08937282115221024
Validation loss: 1.5090548184610182

Epoch: 6| Step: 9
Training loss: 0.12721097469329834
Validation loss: 1.4998604302765222

Epoch: 6| Step: 10
Training loss: 0.11615331470966339
Validation loss: 1.5407051732463222

Epoch: 6| Step: 11
Training loss: 0.27479487657546997
Validation loss: 1.5055316378993373

Epoch: 6| Step: 12
Training loss: 0.07695138454437256
Validation loss: 1.5268298874619186

Epoch: 6| Step: 13
Training loss: 0.0664573609828949
Validation loss: 1.5199707323505032

Epoch: 419| Step: 0
Training loss: 0.07338310778141022
Validation loss: 1.519779634732072

Epoch: 6| Step: 1
Training loss: 0.12719443440437317
Validation loss: 1.5390299968822028

Epoch: 6| Step: 2
Training loss: 0.1074364185333252
Validation loss: 1.5632020478607507

Epoch: 6| Step: 3
Training loss: 0.16646456718444824
Validation loss: 1.5367712679729666

Epoch: 6| Step: 4
Training loss: 0.14542120695114136
Validation loss: 1.5448201702487083

Epoch: 6| Step: 5
Training loss: 0.1505848467350006
Validation loss: 1.5149711716559626

Epoch: 6| Step: 6
Training loss: 0.10608185827732086
Validation loss: 1.4954966627141482

Epoch: 6| Step: 7
Training loss: 0.085884690284729
Validation loss: 1.464342100645906

Epoch: 6| Step: 8
Training loss: 0.24300456047058105
Validation loss: 1.492635864083485

Epoch: 6| Step: 9
Training loss: 0.16317185759544373
Validation loss: 1.4466769092826433

Epoch: 6| Step: 10
Training loss: 0.12594908475875854
Validation loss: 1.427796188221183

Epoch: 6| Step: 11
Training loss: 0.06779499351978302
Validation loss: 1.443488629915381

Epoch: 6| Step: 12
Training loss: 0.10192888975143433
Validation loss: 1.418742936144593

Epoch: 6| Step: 13
Training loss: 0.15891098976135254
Validation loss: 1.4045772065398514

Epoch: 420| Step: 0
Training loss: 0.20589280128479004
Validation loss: 1.407155066408137

Epoch: 6| Step: 1
Training loss: 0.14425882697105408
Validation loss: 1.438031582422154

Epoch: 6| Step: 2
Training loss: 0.08052989840507507
Validation loss: 1.4432273699391274

Epoch: 6| Step: 3
Training loss: 0.15405157208442688
Validation loss: 1.4321969503997474

Epoch: 6| Step: 4
Training loss: 0.08298931270837784
Validation loss: 1.4237139314733527

Epoch: 6| Step: 5
Training loss: 0.16863548755645752
Validation loss: 1.4296040714427989

Epoch: 6| Step: 6
Training loss: 0.11924943327903748
Validation loss: 1.43436360743738

Epoch: 6| Step: 7
Training loss: 0.10125549137592316
Validation loss: 1.4240629301276257

Epoch: 6| Step: 8
Training loss: 0.08203615993261337
Validation loss: 1.4514692983319681

Epoch: 6| Step: 9
Training loss: 0.3095608949661255
Validation loss: 1.4301646960678922

Epoch: 6| Step: 10
Training loss: 0.06874921917915344
Validation loss: 1.4320919872612081

Epoch: 6| Step: 11
Training loss: 0.08355474472045898
Validation loss: 1.4082431177939139

Epoch: 6| Step: 12
Training loss: 0.1095568835735321
Validation loss: 1.4458121997053905

Epoch: 6| Step: 13
Training loss: 0.1574181616306305
Validation loss: 1.4490983011902019

Epoch: 421| Step: 0
Training loss: 0.11621486395597458
Validation loss: 1.441522729012274

Epoch: 6| Step: 1
Training loss: 0.08652758598327637
Validation loss: 1.4528593927301385

Epoch: 6| Step: 2
Training loss: 0.13956521451473236
Validation loss: 1.4330986212658625

Epoch: 6| Step: 3
Training loss: 0.2331792414188385
Validation loss: 1.421220633291429

Epoch: 6| Step: 4
Training loss: 0.10152869671583176
Validation loss: 1.431202716724847

Epoch: 6| Step: 5
Training loss: 0.12245829403400421
Validation loss: 1.4043796908470891

Epoch: 6| Step: 6
Training loss: 0.09413346648216248
Validation loss: 1.4208007012644122

Epoch: 6| Step: 7
Training loss: 0.10786591470241547
Validation loss: 1.4386388383885866

Epoch: 6| Step: 8
Training loss: 0.10922868549823761
Validation loss: 1.4475211225530153

Epoch: 6| Step: 9
Training loss: 0.08600476384162903
Validation loss: 1.4317072117200462

Epoch: 6| Step: 10
Training loss: 0.1050552949309349
Validation loss: 1.4521375227999944

Epoch: 6| Step: 11
Training loss: 0.13224203884601593
Validation loss: 1.4588941515132945

Epoch: 6| Step: 12
Training loss: 0.15806898474693298
Validation loss: 1.4340605017959431

Epoch: 6| Step: 13
Training loss: 0.1290879249572754
Validation loss: 1.4447239022101126

Epoch: 422| Step: 0
Training loss: 0.11543221771717072
Validation loss: 1.4448732752953806

Epoch: 6| Step: 1
Training loss: 0.09168042242527008
Validation loss: 1.4583201985205374

Epoch: 6| Step: 2
Training loss: 0.10592862218618393
Validation loss: 1.4478509156934676

Epoch: 6| Step: 3
Training loss: 0.08565963059663773
Validation loss: 1.463366889184521

Epoch: 6| Step: 4
Training loss: 0.10313273221254349
Validation loss: 1.449170776592788

Epoch: 6| Step: 5
Training loss: 0.10857744514942169
Validation loss: 1.4474889732176257

Epoch: 6| Step: 6
Training loss: 0.1317136436700821
Validation loss: 1.4465742470115743

Epoch: 6| Step: 7
Training loss: 0.15386249125003815
Validation loss: 1.4419014274433095

Epoch: 6| Step: 8
Training loss: 0.06769484281539917
Validation loss: 1.4451460299953338

Epoch: 6| Step: 9
Training loss: 0.11969822645187378
Validation loss: 1.4271222070981098

Epoch: 6| Step: 10
Training loss: 0.2841428518295288
Validation loss: 1.4571513706637966

Epoch: 6| Step: 11
Training loss: 0.17129231989383698
Validation loss: 1.4561952134614349

Epoch: 6| Step: 12
Training loss: 0.1193837970495224
Validation loss: 1.453237129795936

Epoch: 6| Step: 13
Training loss: 0.06695906072854996
Validation loss: 1.4732699471135293

Epoch: 423| Step: 0
Training loss: 0.10670841485261917
Validation loss: 1.4375781038756013

Epoch: 6| Step: 1
Training loss: 0.09899722039699554
Validation loss: 1.4321922409919001

Epoch: 6| Step: 2
Training loss: 0.35243546962738037
Validation loss: 1.4311734463578911

Epoch: 6| Step: 3
Training loss: 0.11056295037269592
Validation loss: 1.4243963508195774

Epoch: 6| Step: 4
Training loss: 0.11356641352176666
Validation loss: 1.4187256456703268

Epoch: 6| Step: 5
Training loss: 0.13961900770664215
Validation loss: 1.415940939098276

Epoch: 6| Step: 6
Training loss: 0.07142343372106552
Validation loss: 1.4333274114516474

Epoch: 6| Step: 7
Training loss: 0.07191608101129532
Validation loss: 1.4300629951620614

Epoch: 6| Step: 8
Training loss: 0.1121770367026329
Validation loss: 1.424883887331973

Epoch: 6| Step: 9
Training loss: 0.11015452444553375
Validation loss: 1.4085146791191512

Epoch: 6| Step: 10
Training loss: 0.07475243508815765
Validation loss: 1.4206828019952262

Epoch: 6| Step: 11
Training loss: 0.1285504847764969
Validation loss: 1.4196843793315272

Epoch: 6| Step: 12
Training loss: 0.11331374943256378
Validation loss: 1.4181221223646594

Epoch: 6| Step: 13
Training loss: 0.09857576340436935
Validation loss: 1.4396592199161489

Epoch: 424| Step: 0
Training loss: 0.08563212305307388
Validation loss: 1.432487432674695

Epoch: 6| Step: 1
Training loss: 0.06531578302383423
Validation loss: 1.4415833257859754

Epoch: 6| Step: 2
Training loss: 0.2448253631591797
Validation loss: 1.4408947934386551

Epoch: 6| Step: 3
Training loss: 0.1053076982498169
Validation loss: 1.438936295047883

Epoch: 6| Step: 4
Training loss: 0.1202651783823967
Validation loss: 1.4457394410205144

Epoch: 6| Step: 5
Training loss: 0.10452458262443542
Validation loss: 1.4450928921340613

Epoch: 6| Step: 6
Training loss: 0.14193573594093323
Validation loss: 1.4452554955277392

Epoch: 6| Step: 7
Training loss: 0.1466750204563141
Validation loss: 1.4342540130820325

Epoch: 6| Step: 8
Training loss: 0.15365295112133026
Validation loss: 1.4283453905454246

Epoch: 6| Step: 9
Training loss: 0.10830025374889374
Validation loss: 1.4214255066328152

Epoch: 6| Step: 10
Training loss: 0.10039187967777252
Validation loss: 1.4328701649942706

Epoch: 6| Step: 11
Training loss: 0.14414826035499573
Validation loss: 1.4457630906053769

Epoch: 6| Step: 12
Training loss: 0.09625241160392761
Validation loss: 1.4258993582058979

Epoch: 6| Step: 13
Training loss: 0.06702463328838348
Validation loss: 1.415175304617933

Epoch: 425| Step: 0
Training loss: 0.0859488695859909
Validation loss: 1.4752588195185508

Epoch: 6| Step: 1
Training loss: 0.08161940425634384
Validation loss: 1.4419154659394295

Epoch: 6| Step: 2
Training loss: 0.07124076038599014
Validation loss: 1.4534650553939163

Epoch: 6| Step: 3
Training loss: 0.13858765363693237
Validation loss: 1.4562784708956236

Epoch: 6| Step: 4
Training loss: 0.09562702476978302
Validation loss: 1.4541039441221504

Epoch: 6| Step: 5
Training loss: 0.10673806816339493
Validation loss: 1.4262908927855953

Epoch: 6| Step: 6
Training loss: 0.2390345335006714
Validation loss: 1.433030443806802

Epoch: 6| Step: 7
Training loss: 0.09500862658023834
Validation loss: 1.4754783043297388

Epoch: 6| Step: 8
Training loss: 0.06741845607757568
Validation loss: 1.434548843291498

Epoch: 6| Step: 9
Training loss: 0.17849530279636383
Validation loss: 1.441827666374945

Epoch: 6| Step: 10
Training loss: 0.14454935491085052
Validation loss: 1.4305358182999395

Epoch: 6| Step: 11
Training loss: 0.16440024971961975
Validation loss: 1.4408783451203377

Epoch: 6| Step: 12
Training loss: 0.09509395062923431
Validation loss: 1.432347425850489

Epoch: 6| Step: 13
Training loss: 0.12866070866584778
Validation loss: 1.413667437850788

Epoch: 426| Step: 0
Training loss: 0.07639389485120773
Validation loss: 1.4288134562071932

Epoch: 6| Step: 1
Training loss: 0.28478577733039856
Validation loss: 1.427910324065916

Epoch: 6| Step: 2
Training loss: 0.06343217194080353
Validation loss: 1.4261115161321496

Epoch: 6| Step: 3
Training loss: 0.09793126583099365
Validation loss: 1.4469357536685081

Epoch: 6| Step: 4
Training loss: 0.10627756267786026
Validation loss: 1.4063365690169796

Epoch: 6| Step: 5
Training loss: 0.10422615706920624
Validation loss: 1.4143752128847185

Epoch: 6| Step: 6
Training loss: 0.08171841502189636
Validation loss: 1.4231288689439014

Epoch: 6| Step: 7
Training loss: 0.06976567208766937
Validation loss: 1.4435028594027284

Epoch: 6| Step: 8
Training loss: 0.08786578476428986
Validation loss: 1.4274178134497775

Epoch: 6| Step: 9
Training loss: 0.11486981809139252
Validation loss: 1.490911672192235

Epoch: 6| Step: 10
Training loss: 0.09717537462711334
Validation loss: 1.4604888590433265

Epoch: 6| Step: 11
Training loss: 0.09711959958076477
Validation loss: 1.4620402045147394

Epoch: 6| Step: 12
Training loss: 0.10393521934747696
Validation loss: 1.4591637298625002

Epoch: 6| Step: 13
Training loss: 0.10709026455879211
Validation loss: 1.452357958080948

Epoch: 427| Step: 0
Training loss: 0.14211106300354004
Validation loss: 1.4878138342211324

Epoch: 6| Step: 1
Training loss: 0.08869647979736328
Validation loss: 1.445233315549871

Epoch: 6| Step: 2
Training loss: 0.13744579255580902
Validation loss: 1.4628810831295547

Epoch: 6| Step: 3
Training loss: 0.12650978565216064
Validation loss: 1.4775230243641844

Epoch: 6| Step: 4
Training loss: 0.10153984278440475
Validation loss: 1.46658226366966

Epoch: 6| Step: 5
Training loss: 0.12774458527565002
Validation loss: 1.4545483589172363

Epoch: 6| Step: 6
Training loss: 0.2252008318901062
Validation loss: 1.4488651931926768

Epoch: 6| Step: 7
Training loss: 0.06563520431518555
Validation loss: 1.4555258622733496

Epoch: 6| Step: 8
Training loss: 0.08729317784309387
Validation loss: 1.4614210846603557

Epoch: 6| Step: 9
Training loss: 0.0890122503042221
Validation loss: 1.4435570099020516

Epoch: 6| Step: 10
Training loss: 0.06844209134578705
Validation loss: 1.4333258046898791

Epoch: 6| Step: 11
Training loss: 0.1398543417453766
Validation loss: 1.4313773019339449

Epoch: 6| Step: 12
Training loss: 0.0848206952214241
Validation loss: 1.4211914821337628

Epoch: 6| Step: 13
Training loss: 0.09647522866725922
Validation loss: 1.4255391038874143

Epoch: 428| Step: 0
Training loss: 0.05939183011651039
Validation loss: 1.4328362326468191

Epoch: 6| Step: 1
Training loss: 0.2783529460430145
Validation loss: 1.450549872972632

Epoch: 6| Step: 2
Training loss: 0.0978097915649414
Validation loss: 1.4445200004885275

Epoch: 6| Step: 3
Training loss: 0.08889560401439667
Validation loss: 1.4591258712994155

Epoch: 6| Step: 4
Training loss: 0.07829976081848145
Validation loss: 1.471254587173462

Epoch: 6| Step: 5
Training loss: 0.11025901883840561
Validation loss: 1.4675504802375712

Epoch: 6| Step: 6
Training loss: 0.09668949991464615
Validation loss: 1.4545851125512073

Epoch: 6| Step: 7
Training loss: 0.14544078707695007
Validation loss: 1.4273608435866654

Epoch: 6| Step: 8
Training loss: 0.1103304848074913
Validation loss: 1.433090526570556

Epoch: 6| Step: 9
Training loss: 0.14550065994262695
Validation loss: 1.4545952081680298

Epoch: 6| Step: 10
Training loss: 0.16280855238437653
Validation loss: 1.4679228810853855

Epoch: 6| Step: 11
Training loss: 0.12555791437625885
Validation loss: 1.4743960397217863

Epoch: 6| Step: 12
Training loss: 0.0726926401257515
Validation loss: 1.4512064059575398

Epoch: 6| Step: 13
Training loss: 0.08809249848127365
Validation loss: 1.422205667341909

Epoch: 429| Step: 0
Training loss: 0.0824139267206192
Validation loss: 1.453383707231091

Epoch: 6| Step: 1
Training loss: 0.10059130191802979
Validation loss: 1.4484211501254831

Epoch: 6| Step: 2
Training loss: 0.24145829677581787
Validation loss: 1.4013943133815643

Epoch: 6| Step: 3
Training loss: 0.14358104765415192
Validation loss: 1.4330481303635465

Epoch: 6| Step: 4
Training loss: 0.11731476336717606
Validation loss: 1.4350964459039832

Epoch: 6| Step: 5
Training loss: 0.08973130583763123
Validation loss: 1.44288436571757

Epoch: 6| Step: 6
Training loss: 0.08688397705554962
Validation loss: 1.433670074709

Epoch: 6| Step: 7
Training loss: 0.2025773525238037
Validation loss: 1.461374431528071

Epoch: 6| Step: 8
Training loss: 0.08292058110237122
Validation loss: 1.417855849830053

Epoch: 6| Step: 9
Training loss: 0.16805146634578705
Validation loss: 1.476355832110169

Epoch: 6| Step: 10
Training loss: 0.11834590137004852
Validation loss: 1.4855260041452223

Epoch: 6| Step: 11
Training loss: 0.14695358276367188
Validation loss: 1.4910435484301658

Epoch: 6| Step: 12
Training loss: 0.10532434284687042
Validation loss: 1.4611774144634124

Epoch: 6| Step: 13
Training loss: 0.07962317019701004
Validation loss: 1.4734369016462756

Epoch: 430| Step: 0
Training loss: 0.15161530673503876
Validation loss: 1.4952662567938528

Epoch: 6| Step: 1
Training loss: 0.06785191595554352
Validation loss: 1.4687491142621605

Epoch: 6| Step: 2
Training loss: 0.09972912073135376
Validation loss: 1.4727224380739274

Epoch: 6| Step: 3
Training loss: 0.1328115314245224
Validation loss: 1.4690001523622902

Epoch: 6| Step: 4
Training loss: 0.18132297694683075
Validation loss: 1.4328813475947226

Epoch: 6| Step: 5
Training loss: 0.06717625260353088
Validation loss: 1.4476166130394064

Epoch: 6| Step: 6
Training loss: 0.06937196105718613
Validation loss: 1.393840438576155

Epoch: 6| Step: 7
Training loss: 0.0729379653930664
Validation loss: 1.4318890635685255

Epoch: 6| Step: 8
Training loss: 0.24663960933685303
Validation loss: 1.4276204314283145

Epoch: 6| Step: 9
Training loss: 0.10448163002729416
Validation loss: 1.419595737611094

Epoch: 6| Step: 10
Training loss: 0.08841998875141144
Validation loss: 1.4321295298555845

Epoch: 6| Step: 11
Training loss: 0.16878372430801392
Validation loss: 1.4413991910155102

Epoch: 6| Step: 12
Training loss: 0.08676605671644211
Validation loss: 1.3990806700080953

Epoch: 6| Step: 13
Training loss: 0.14622464776039124
Validation loss: 1.4197603361580962

Epoch: 431| Step: 0
Training loss: 0.1686038076877594
Validation loss: 1.4309107257473854

Epoch: 6| Step: 1
Training loss: 0.16477446258068085
Validation loss: 1.3981998402585265

Epoch: 6| Step: 2
Training loss: 0.11181977391242981
Validation loss: 1.4500635054803663

Epoch: 6| Step: 3
Training loss: 0.12337645888328552
Validation loss: 1.404903748983978

Epoch: 6| Step: 4
Training loss: 0.14686675369739532
Validation loss: 1.4149476341021958

Epoch: 6| Step: 5
Training loss: 0.1120288074016571
Validation loss: 1.4229796342952277

Epoch: 6| Step: 6
Training loss: 0.12420015037059784
Validation loss: 1.3726812921544558

Epoch: 6| Step: 7
Training loss: 0.12222743779420853
Validation loss: 1.3671394669881431

Epoch: 6| Step: 8
Training loss: 0.242618590593338
Validation loss: 1.3640691977675243

Epoch: 6| Step: 9
Training loss: 0.1104210838675499
Validation loss: 1.3882901463457333

Epoch: 6| Step: 10
Training loss: 0.07008248567581177
Validation loss: 1.401018036309109

Epoch: 6| Step: 11
Training loss: 0.16830433905124664
Validation loss: 1.4035145608327722

Epoch: 6| Step: 12
Training loss: 0.10541538149118423
Validation loss: 1.4132301820221769

Epoch: 6| Step: 13
Training loss: 0.11973907053470612
Validation loss: 1.387612565871208

Epoch: 432| Step: 0
Training loss: 0.09521013498306274
Validation loss: 1.4286214638781805

Epoch: 6| Step: 1
Training loss: 0.10500293970108032
Validation loss: 1.4092590821686612

Epoch: 6| Step: 2
Training loss: 0.07421726733446121
Validation loss: 1.430121346186566

Epoch: 6| Step: 3
Training loss: 0.10636632144451141
Validation loss: 1.4068593235426052

Epoch: 6| Step: 4
Training loss: 0.09816700965166092
Validation loss: 1.4419100079485165

Epoch: 6| Step: 5
Training loss: 0.07270181179046631
Validation loss: 1.4576243072427728

Epoch: 6| Step: 6
Training loss: 0.06699279695749283
Validation loss: 1.4681648785068142

Epoch: 6| Step: 7
Training loss: 0.1190636157989502
Validation loss: 1.4563454056298861

Epoch: 6| Step: 8
Training loss: 0.11805008351802826
Validation loss: 1.4586308976655364

Epoch: 6| Step: 9
Training loss: 0.05994771420955658
Validation loss: 1.4614950149290022

Epoch: 6| Step: 10
Training loss: 0.25905585289001465
Validation loss: 1.4292400543407728

Epoch: 6| Step: 11
Training loss: 0.12044861167669296
Validation loss: 1.455291199427779

Epoch: 6| Step: 12
Training loss: 0.09728944301605225
Validation loss: 1.4498158667677192

Epoch: 6| Step: 13
Training loss: 0.11889412999153137
Validation loss: 1.425378361696838

Epoch: 433| Step: 0
Training loss: 0.07803031802177429
Validation loss: 1.4544932291071901

Epoch: 6| Step: 1
Training loss: 0.06463515758514404
Validation loss: 1.4318073206050421

Epoch: 6| Step: 2
Training loss: 0.09439064562320709
Validation loss: 1.431650043815695

Epoch: 6| Step: 3
Training loss: 0.15212054550647736
Validation loss: 1.4111511450941845

Epoch: 6| Step: 4
Training loss: 0.23871910572052002
Validation loss: 1.4221573568159533

Epoch: 6| Step: 5
Training loss: 0.07292747497558594
Validation loss: 1.4346322872305428

Epoch: 6| Step: 6
Training loss: 0.05180969089269638
Validation loss: 1.4191202989188574

Epoch: 6| Step: 7
Training loss: 0.09197089076042175
Validation loss: 1.4260673574222031

Epoch: 6| Step: 8
Training loss: 0.14904963970184326
Validation loss: 1.4580356164645123

Epoch: 6| Step: 9
Training loss: 0.05489480495452881
Validation loss: 1.4495076274359098

Epoch: 6| Step: 10
Training loss: 0.11151968687772751
Validation loss: 1.4377343731541787

Epoch: 6| Step: 11
Training loss: 0.08198244869709015
Validation loss: 1.4177913858044533

Epoch: 6| Step: 12
Training loss: 0.11181029677391052
Validation loss: 1.4648413465869041

Epoch: 6| Step: 13
Training loss: 0.11196466535329819
Validation loss: 1.460809394877444

Epoch: 434| Step: 0
Training loss: 0.06572210788726807
Validation loss: 1.4502734779029764

Epoch: 6| Step: 1
Training loss: 0.07970242202281952
Validation loss: 1.4336117134299329

Epoch: 6| Step: 2
Training loss: 0.1152978166937828
Validation loss: 1.438860349757697

Epoch: 6| Step: 3
Training loss: 0.11063797771930695
Validation loss: 1.4573165998663953

Epoch: 6| Step: 4
Training loss: 0.07648821175098419
Validation loss: 1.4485561475958875

Epoch: 6| Step: 5
Training loss: 0.11310743540525436
Validation loss: 1.4701999515615485

Epoch: 6| Step: 6
Training loss: 0.10295082628726959
Validation loss: 1.4564984434394426

Epoch: 6| Step: 7
Training loss: 0.07750137895345688
Validation loss: 1.4625300066445464

Epoch: 6| Step: 8
Training loss: 0.1650022268295288
Validation loss: 1.472654567610833

Epoch: 6| Step: 9
Training loss: 0.08660275489091873
Validation loss: 1.4509242555146575

Epoch: 6| Step: 10
Training loss: 0.3295557498931885
Validation loss: 1.4361807018197992

Epoch: 6| Step: 11
Training loss: 0.0810963585972786
Validation loss: 1.4307810427040182

Epoch: 6| Step: 12
Training loss: 0.08223441988229752
Validation loss: 1.4286533312131

Epoch: 6| Step: 13
Training loss: 0.12956489622592926
Validation loss: 1.4483341965624081

Epoch: 435| Step: 0
Training loss: 0.08992113173007965
Validation loss: 1.4698801502104728

Epoch: 6| Step: 1
Training loss: 0.10060209035873413
Validation loss: 1.4596229317367717

Epoch: 6| Step: 2
Training loss: 0.19591552019119263
Validation loss: 1.4394832157319593

Epoch: 6| Step: 3
Training loss: 0.08853604644536972
Validation loss: 1.4789332343686012

Epoch: 6| Step: 4
Training loss: 0.09614290297031403
Validation loss: 1.4230036145897322

Epoch: 6| Step: 5
Training loss: 0.08304795622825623
Validation loss: 1.4557006493691476

Epoch: 6| Step: 6
Training loss: 0.06761415302753448
Validation loss: 1.448834228259261

Epoch: 6| Step: 7
Training loss: 0.10100449621677399
Validation loss: 1.438653645335987

Epoch: 6| Step: 8
Training loss: 0.1234285831451416
Validation loss: 1.4223884254373529

Epoch: 6| Step: 9
Training loss: 0.08581626415252686
Validation loss: 1.4219922288771598

Epoch: 6| Step: 10
Training loss: 0.07957100868225098
Validation loss: 1.4228877220102536

Epoch: 6| Step: 11
Training loss: 0.1525728702545166
Validation loss: 1.4511155582243396

Epoch: 6| Step: 12
Training loss: 0.10938957333564758
Validation loss: 1.4382292891061434

Epoch: 6| Step: 13
Training loss: 0.07248903810977936
Validation loss: 1.4266913212755674

Epoch: 436| Step: 0
Training loss: 0.15755371749401093
Validation loss: 1.4085378992942073

Epoch: 6| Step: 1
Training loss: 0.12078990787267685
Validation loss: 1.4096309459337624

Epoch: 6| Step: 2
Training loss: 0.05194242298603058
Validation loss: 1.4381613885202715

Epoch: 6| Step: 3
Training loss: 0.0855012834072113
Validation loss: 1.4316244932913011

Epoch: 6| Step: 4
Training loss: 0.08276679366827011
Validation loss: 1.440342846737113

Epoch: 6| Step: 5
Training loss: 0.09768494963645935
Validation loss: 1.459126869837443

Epoch: 6| Step: 6
Training loss: 0.11312273144721985
Validation loss: 1.45648907461474

Epoch: 6| Step: 7
Training loss: 0.11693538725376129
Validation loss: 1.4457922186902774

Epoch: 6| Step: 8
Training loss: 0.08996310830116272
Validation loss: 1.45674640645263

Epoch: 6| Step: 9
Training loss: 0.23747123777866364
Validation loss: 1.4908222459977674

Epoch: 6| Step: 10
Training loss: 0.11475392431020737
Validation loss: 1.4844176102710027

Epoch: 6| Step: 11
Training loss: 0.10155957192182541
Validation loss: 1.4552300604440833

Epoch: 6| Step: 12
Training loss: 0.10202863067388535
Validation loss: 1.4530044114717873

Epoch: 6| Step: 13
Training loss: 0.08215732127428055
Validation loss: 1.4446669406788324

Epoch: 437| Step: 0
Training loss: 0.08125407993793488
Validation loss: 1.4279863962563135

Epoch: 6| Step: 1
Training loss: 0.058652445673942566
Validation loss: 1.4226846438582226

Epoch: 6| Step: 2
Training loss: 0.10466795414686203
Validation loss: 1.433904650390789

Epoch: 6| Step: 3
Training loss: 0.12445743381977081
Validation loss: 1.409145870516377

Epoch: 6| Step: 4
Training loss: 0.14249801635742188
Validation loss: 1.42124544676914

Epoch: 6| Step: 5
Training loss: 0.07454235106706619
Validation loss: 1.4178924765638126

Epoch: 6| Step: 6
Training loss: 0.10717546939849854
Validation loss: 1.3935812339987805

Epoch: 6| Step: 7
Training loss: 0.07782649993896484
Validation loss: 1.4300699727509611

Epoch: 6| Step: 8
Training loss: 0.23327487707138062
Validation loss: 1.40733294076817

Epoch: 6| Step: 9
Training loss: 0.10915323346853256
Validation loss: 1.3935505549112956

Epoch: 6| Step: 10
Training loss: 0.11544730514287949
Validation loss: 1.4204245164830198

Epoch: 6| Step: 11
Training loss: 0.08495863527059555
Validation loss: 1.4112494953217045

Epoch: 6| Step: 12
Training loss: 0.10245952010154724
Validation loss: 1.4201683934016893

Epoch: 6| Step: 13
Training loss: 0.12911111116409302
Validation loss: 1.4128257343845982

Epoch: 438| Step: 0
Training loss: 0.26310887932777405
Validation loss: 1.440928755267974

Epoch: 6| Step: 1
Training loss: 0.10952287912368774
Validation loss: 1.4164283301240654

Epoch: 6| Step: 2
Training loss: 0.15533101558685303
Validation loss: 1.4399869685531945

Epoch: 6| Step: 3
Training loss: 0.12095151096582413
Validation loss: 1.4264186530984857

Epoch: 6| Step: 4
Training loss: 0.11266409605741501
Validation loss: 1.441477144918134

Epoch: 6| Step: 5
Training loss: 0.1504281908273697
Validation loss: 1.4302787370579217

Epoch: 6| Step: 6
Training loss: 0.08009923994541168
Validation loss: 1.4227118094762166

Epoch: 6| Step: 7
Training loss: 0.09558233618736267
Validation loss: 1.4527486242273802

Epoch: 6| Step: 8
Training loss: 0.08370383083820343
Validation loss: 1.4227814071921892

Epoch: 6| Step: 9
Training loss: 0.13164778053760529
Validation loss: 1.4204124071264779

Epoch: 6| Step: 10
Training loss: 0.17112156748771667
Validation loss: 1.4457551279375631

Epoch: 6| Step: 11
Training loss: 0.1388019174337387
Validation loss: 1.4369046124078895

Epoch: 6| Step: 12
Training loss: 0.10757321119308472
Validation loss: 1.454582166928117

Epoch: 6| Step: 13
Training loss: 0.06662721186876297
Validation loss: 1.4534109959038355

Epoch: 439| Step: 0
Training loss: 0.12848308682441711
Validation loss: 1.4236818487926195

Epoch: 6| Step: 1
Training loss: 0.263965368270874
Validation loss: 1.4400571725701774

Epoch: 6| Step: 2
Training loss: 0.12249495089054108
Validation loss: 1.4419389322239866

Epoch: 6| Step: 3
Training loss: 0.13302084803581238
Validation loss: 1.4467181415968045

Epoch: 6| Step: 4
Training loss: 0.09188303351402283
Validation loss: 1.4444541277423981

Epoch: 6| Step: 5
Training loss: 0.09561854600906372
Validation loss: 1.4399821322451356

Epoch: 6| Step: 6
Training loss: 0.04385555535554886
Validation loss: 1.4642254024423578

Epoch: 6| Step: 7
Training loss: 0.07510010153055191
Validation loss: 1.4663640914424774

Epoch: 6| Step: 8
Training loss: 0.0817253440618515
Validation loss: 1.4435383427527644

Epoch: 6| Step: 9
Training loss: 0.136177197098732
Validation loss: 1.461792403651822

Epoch: 6| Step: 10
Training loss: 0.07829797267913818
Validation loss: 1.4281408953410324

Epoch: 6| Step: 11
Training loss: 0.17971962690353394
Validation loss: 1.4657636489919437

Epoch: 6| Step: 12
Training loss: 0.16627535223960876
Validation loss: 1.4652703026289582

Epoch: 6| Step: 13
Training loss: 0.18633964657783508
Validation loss: 1.4192573985745829

Epoch: 440| Step: 0
Training loss: 0.09079818427562714
Validation loss: 1.4195193693202028

Epoch: 6| Step: 1
Training loss: 0.1183028370141983
Validation loss: 1.4344702612969182

Epoch: 6| Step: 2
Training loss: 0.06739877164363861
Validation loss: 1.4145661656574537

Epoch: 6| Step: 3
Training loss: 0.10526487231254578
Validation loss: 1.4187810395353584

Epoch: 6| Step: 4
Training loss: 0.12971021234989166
Validation loss: 1.4397333591215071

Epoch: 6| Step: 5
Training loss: 0.2319580316543579
Validation loss: 1.4340276666866836

Epoch: 6| Step: 6
Training loss: 0.11054778844118118
Validation loss: 1.4251299558147308

Epoch: 6| Step: 7
Training loss: 0.11188963800668716
Validation loss: 1.4427417644890406

Epoch: 6| Step: 8
Training loss: 0.1221056878566742
Validation loss: 1.4476039858274563

Epoch: 6| Step: 9
Training loss: 0.06905742734670639
Validation loss: 1.4643037985729914

Epoch: 6| Step: 10
Training loss: 0.06360894441604614
Validation loss: 1.420190147174302

Epoch: 6| Step: 11
Training loss: 0.08559861034154892
Validation loss: 1.4820826989348217

Epoch: 6| Step: 12
Training loss: 0.11904212087392807
Validation loss: 1.4308432975123007

Epoch: 6| Step: 13
Training loss: 0.2249973863363266
Validation loss: 1.461982992387587

Epoch: 441| Step: 0
Training loss: 0.14942394196987152
Validation loss: 1.4893643010047175

Epoch: 6| Step: 1
Training loss: 0.10348901152610779
Validation loss: 1.5140072466224752

Epoch: 6| Step: 2
Training loss: 0.0982002541422844
Validation loss: 1.4459174602262435

Epoch: 6| Step: 3
Training loss: 0.15077143907546997
Validation loss: 1.4777990605241509

Epoch: 6| Step: 4
Training loss: 0.2834162414073944
Validation loss: 1.460076980693366

Epoch: 6| Step: 5
Training loss: 0.12045038491487503
Validation loss: 1.4658247834892684

Epoch: 6| Step: 6
Training loss: 0.08899828791618347
Validation loss: 1.4588656117839198

Epoch: 6| Step: 7
Training loss: 0.08015606552362442
Validation loss: 1.4623180986732565

Epoch: 6| Step: 8
Training loss: 0.08175020664930344
Validation loss: 1.4391051870520397

Epoch: 6| Step: 9
Training loss: 0.09590964019298553
Validation loss: 1.490198378921837

Epoch: 6| Step: 10
Training loss: 0.2023245096206665
Validation loss: 1.4704801959376181

Epoch: 6| Step: 11
Training loss: 0.15173427760601044
Validation loss: 1.4654085956593996

Epoch: 6| Step: 12
Training loss: 0.14022985100746155
Validation loss: 1.4592285809978363

Epoch: 6| Step: 13
Training loss: 0.16931039094924927
Validation loss: 1.4500543314923522

Epoch: 442| Step: 0
Training loss: 0.2608729600906372
Validation loss: 1.4331063775606052

Epoch: 6| Step: 1
Training loss: 0.14904016256332397
Validation loss: 1.4289252527298466

Epoch: 6| Step: 2
Training loss: 0.06029988452792168
Validation loss: 1.4046670185622347

Epoch: 6| Step: 3
Training loss: 0.13517341017723083
Validation loss: 1.3799203300988803

Epoch: 6| Step: 4
Training loss: 0.11377741396427155
Validation loss: 1.4055930081234183

Epoch: 6| Step: 5
Training loss: 0.14967671036720276
Validation loss: 1.3862832336015598

Epoch: 6| Step: 6
Training loss: 0.16377270221710205
Validation loss: 1.3944333394368489

Epoch: 6| Step: 7
Training loss: 0.1540144681930542
Validation loss: 1.3633725707248976

Epoch: 6| Step: 8
Training loss: 0.2568950653076172
Validation loss: 1.3457349961803806

Epoch: 6| Step: 9
Training loss: 0.07386033982038498
Validation loss: 1.3866997764956566

Epoch: 6| Step: 10
Training loss: 0.09988683462142944
Validation loss: 1.3654856861278575

Epoch: 6| Step: 11
Training loss: 0.0829988420009613
Validation loss: 1.4056668191827753

Epoch: 6| Step: 12
Training loss: 0.14325380325317383
Validation loss: 1.4410802920659382

Epoch: 6| Step: 13
Training loss: 0.15501755475997925
Validation loss: 1.4305552218549995

Epoch: 443| Step: 0
Training loss: 0.07881708443164825
Validation loss: 1.418500191421919

Epoch: 6| Step: 1
Training loss: 0.13871131837368011
Validation loss: 1.4451339232024325

Epoch: 6| Step: 2
Training loss: 0.1332947313785553
Validation loss: 1.4224917709186513

Epoch: 6| Step: 3
Training loss: 0.13926467299461365
Validation loss: 1.4083789228111185

Epoch: 6| Step: 4
Training loss: 0.13784542679786682
Validation loss: 1.4023919464439474

Epoch: 6| Step: 5
Training loss: 0.10224856436252594
Validation loss: 1.3697282652701102

Epoch: 6| Step: 6
Training loss: 0.1180490106344223
Validation loss: 1.4211798867871683

Epoch: 6| Step: 7
Training loss: 0.09847509115934372
Validation loss: 1.4097577442405045

Epoch: 6| Step: 8
Training loss: 0.24981175363063812
Validation loss: 1.4292361121023855

Epoch: 6| Step: 9
Training loss: 0.07417542487382889
Validation loss: 1.4123083801679714

Epoch: 6| Step: 10
Training loss: 0.1330851912498474
Validation loss: 1.4294861337190032

Epoch: 6| Step: 11
Training loss: 0.13983026146888733
Validation loss: 1.4130826637309084

Epoch: 6| Step: 12
Training loss: 0.10661998391151428
Validation loss: 1.3934058784156718

Epoch: 6| Step: 13
Training loss: 0.14106853306293488
Validation loss: 1.416651616814316

Epoch: 444| Step: 0
Training loss: 0.08477406948804855
Validation loss: 1.4095997361726658

Epoch: 6| Step: 1
Training loss: 0.14747418463230133
Validation loss: 1.3875539302825928

Epoch: 6| Step: 2
Training loss: 0.14287976920604706
Validation loss: 1.4171142911398282

Epoch: 6| Step: 3
Training loss: 0.0821133553981781
Validation loss: 1.4013875889521774

Epoch: 6| Step: 4
Training loss: 0.09614112228155136
Validation loss: 1.422979554822368

Epoch: 6| Step: 5
Training loss: 0.13646778464317322
Validation loss: 1.4177226263989684

Epoch: 6| Step: 6
Training loss: 0.12171517312526703
Validation loss: 1.4351364848434285

Epoch: 6| Step: 7
Training loss: 0.3196769058704376
Validation loss: 1.4209507255144016

Epoch: 6| Step: 8
Training loss: 0.11514832079410553
Validation loss: 1.4311888525562901

Epoch: 6| Step: 9
Training loss: 0.12983371317386627
Validation loss: 1.4230831541040891

Epoch: 6| Step: 10
Training loss: 0.06825327128171921
Validation loss: 1.4428792897091116

Epoch: 6| Step: 11
Training loss: 0.10930503904819489
Validation loss: 1.419548834523847

Epoch: 6| Step: 12
Training loss: 0.14536163210868835
Validation loss: 1.413025156144173

Epoch: 6| Step: 13
Training loss: 0.10353843867778778
Validation loss: 1.43043726810845

Epoch: 445| Step: 0
Training loss: 0.1688634157180786
Validation loss: 1.42714814729588

Epoch: 6| Step: 1
Training loss: 0.12105930596590042
Validation loss: 1.4412556258581017

Epoch: 6| Step: 2
Training loss: 0.09801431745290756
Validation loss: 1.4179455195703814

Epoch: 6| Step: 3
Training loss: 0.11935194581747055
Validation loss: 1.4215735940523044

Epoch: 6| Step: 4
Training loss: 0.07752086222171783
Validation loss: 1.4032162966266755

Epoch: 6| Step: 5
Training loss: 0.07320480048656464
Validation loss: 1.4043334728928023

Epoch: 6| Step: 6
Training loss: 0.14864569902420044
Validation loss: 1.4145818051471506

Epoch: 6| Step: 7
Training loss: 0.10642850399017334
Validation loss: 1.4196686757508146

Epoch: 6| Step: 8
Training loss: 0.28616297245025635
Validation loss: 1.4029334450280795

Epoch: 6| Step: 9
Training loss: 0.12547478079795837
Validation loss: 1.4274206546045118

Epoch: 6| Step: 10
Training loss: 0.06199260056018829
Validation loss: 1.4306176407362825

Epoch: 6| Step: 11
Training loss: 0.1171179711818695
Validation loss: 1.4282219025396532

Epoch: 6| Step: 12
Training loss: 0.10330106317996979
Validation loss: 1.4324667043583368

Epoch: 6| Step: 13
Training loss: 0.1174536794424057
Validation loss: 1.4304381801236061

Epoch: 446| Step: 0
Training loss: 0.06876688450574875
Validation loss: 1.442499565821822

Epoch: 6| Step: 1
Training loss: 0.13889732956886292
Validation loss: 1.4350586886047034

Epoch: 6| Step: 2
Training loss: 0.08724337071180344
Validation loss: 1.454902502798265

Epoch: 6| Step: 3
Training loss: 0.09141217172145844
Validation loss: 1.4487003241815875

Epoch: 6| Step: 4
Training loss: 0.31422412395477295
Validation loss: 1.446028632502402

Epoch: 6| Step: 5
Training loss: 0.10063396394252777
Validation loss: 1.4577251313835062

Epoch: 6| Step: 6
Training loss: 0.14539089798927307
Validation loss: 1.494664280645309

Epoch: 6| Step: 7
Training loss: 0.11188916862010956
Validation loss: 1.4645296950494089

Epoch: 6| Step: 8
Training loss: 0.0750383585691452
Validation loss: 1.4256105410155429

Epoch: 6| Step: 9
Training loss: 0.09144529700279236
Validation loss: 1.416157071308423

Epoch: 6| Step: 10
Training loss: 0.1338447779417038
Validation loss: 1.3949709220599102

Epoch: 6| Step: 11
Training loss: 0.08512812852859497
Validation loss: 1.3927512514975764

Epoch: 6| Step: 12
Training loss: 0.13248977065086365
Validation loss: 1.401649821189142

Epoch: 6| Step: 13
Training loss: 0.0834859311580658
Validation loss: 1.3988892993619364

Epoch: 447| Step: 0
Training loss: 0.13931065797805786
Validation loss: 1.3323780951961395

Epoch: 6| Step: 1
Training loss: 0.2255251407623291
Validation loss: 1.3794081685363606

Epoch: 6| Step: 2
Training loss: 0.08533234149217606
Validation loss: 1.3729884637299405

Epoch: 6| Step: 3
Training loss: 0.10624687373638153
Validation loss: 1.4039724270502727

Epoch: 6| Step: 4
Training loss: 0.05791813135147095
Validation loss: 1.3667981483603036

Epoch: 6| Step: 5
Training loss: 0.09786111861467361
Validation loss: 1.4063273322197698

Epoch: 6| Step: 6
Training loss: 0.11567635834217072
Validation loss: 1.404371719206533

Epoch: 6| Step: 7
Training loss: 0.07674060761928558
Validation loss: 1.3943567993820354

Epoch: 6| Step: 8
Training loss: 0.11672019958496094
Validation loss: 1.4161228890060096

Epoch: 6| Step: 9
Training loss: 0.14476072788238525
Validation loss: 1.4045384596752863

Epoch: 6| Step: 10
Training loss: 0.16953149437904358
Validation loss: 1.4424076323868127

Epoch: 6| Step: 11
Training loss: 0.1136845201253891
Validation loss: 1.3891929522637398

Epoch: 6| Step: 12
Training loss: 0.11901642382144928
Validation loss: 1.400932377384555

Epoch: 6| Step: 13
Training loss: 0.14664320647716522
Validation loss: 1.3817288401306316

Epoch: 448| Step: 0
Training loss: 0.06734994053840637
Validation loss: 1.4161966769926009

Epoch: 6| Step: 1
Training loss: 0.07904322445392609
Validation loss: 1.4240367989386282

Epoch: 6| Step: 2
Training loss: 0.05045760050415993
Validation loss: 1.4219277110151065

Epoch: 6| Step: 3
Training loss: 0.07889211922883987
Validation loss: 1.4110072876817437

Epoch: 6| Step: 4
Training loss: 0.07720508426427841
Validation loss: 1.4281326775909753

Epoch: 6| Step: 5
Training loss: 0.08630560338497162
Validation loss: 1.4427999065768333

Epoch: 6| Step: 6
Training loss: 0.2644679844379425
Validation loss: 1.443464691920947

Epoch: 6| Step: 7
Training loss: 0.10953706502914429
Validation loss: 1.4583155403855026

Epoch: 6| Step: 8
Training loss: 0.12805715203285217
Validation loss: 1.4395916090216687

Epoch: 6| Step: 9
Training loss: 0.12461250275373459
Validation loss: 1.4438036718676168

Epoch: 6| Step: 10
Training loss: 0.12305358052253723
Validation loss: 1.4627321035631242

Epoch: 6| Step: 11
Training loss: 0.06488174945116043
Validation loss: 1.4470698141282605

Epoch: 6| Step: 12
Training loss: 0.11840106546878815
Validation loss: 1.4703214655640304

Epoch: 6| Step: 13
Training loss: 0.11163464933633804
Validation loss: 1.448953850294954

Epoch: 449| Step: 0
Training loss: 0.13759845495224
Validation loss: 1.4474225396751075

Epoch: 6| Step: 1
Training loss: 0.14464405179023743
Validation loss: 1.4519758147578086

Epoch: 6| Step: 2
Training loss: 0.08125895261764526
Validation loss: 1.4417172055090628

Epoch: 6| Step: 3
Training loss: 0.11245295405387878
Validation loss: 1.4138367291419738

Epoch: 6| Step: 4
Training loss: 0.0734073668718338
Validation loss: 1.4440295119439401

Epoch: 6| Step: 5
Training loss: 0.07402534782886505
Validation loss: 1.453585692631301

Epoch: 6| Step: 6
Training loss: 0.11103744804859161
Validation loss: 1.4389700017949587

Epoch: 6| Step: 7
Training loss: 0.11172585189342499
Validation loss: 1.4386212748865927

Epoch: 6| Step: 8
Training loss: 0.09024444222450256
Validation loss: 1.3891099550390755

Epoch: 6| Step: 9
Training loss: 0.07244153320789337
Validation loss: 1.417013502890064

Epoch: 6| Step: 10
Training loss: 0.14028659462928772
Validation loss: 1.3970681441727506

Epoch: 6| Step: 11
Training loss: 0.23650595545768738
Validation loss: 1.431731217650957

Epoch: 6| Step: 12
Training loss: 0.14375056326389313
Validation loss: 1.3653795731964933

Epoch: 6| Step: 13
Training loss: 0.05181025341153145
Validation loss: 1.3972876687203684

Epoch: 450| Step: 0
Training loss: 0.09217283129692078
Validation loss: 1.3930991285590715

Epoch: 6| Step: 1
Training loss: 0.09119579195976257
Validation loss: 1.387233994340384

Epoch: 6| Step: 2
Training loss: 0.062107086181640625
Validation loss: 1.402331417606723

Epoch: 6| Step: 3
Training loss: 0.06513296067714691
Validation loss: 1.3952513292271604

Epoch: 6| Step: 4
Training loss: 0.05987255275249481
Validation loss: 1.4080424795868576

Epoch: 6| Step: 5
Training loss: 0.06663136184215546
Validation loss: 1.422892988369029

Epoch: 6| Step: 6
Training loss: 0.06997451186180115
Validation loss: 1.4412138333884619

Epoch: 6| Step: 7
Training loss: 0.12124152481555939
Validation loss: 1.458112556447265

Epoch: 6| Step: 8
Training loss: 0.07149211317300797
Validation loss: 1.445599757215028

Epoch: 6| Step: 9
Training loss: 0.08382078260183334
Validation loss: 1.45553978156018

Epoch: 6| Step: 10
Training loss: 0.2484644204378128
Validation loss: 1.465294813597074

Epoch: 6| Step: 11
Training loss: 0.06686878204345703
Validation loss: 1.4269678246590398

Epoch: 6| Step: 12
Training loss: 0.07329133152961731
Validation loss: 1.4310549484786166

Epoch: 6| Step: 13
Training loss: 0.13364087045192719
Validation loss: 1.40350006985408

Epoch: 451| Step: 0
Training loss: 0.050829581916332245
Validation loss: 1.4113704536550788

Epoch: 6| Step: 1
Training loss: 0.08877906203269958
Validation loss: 1.4210958211652693

Epoch: 6| Step: 2
Training loss: 0.11462768167257309
Validation loss: 1.4306925342928978

Epoch: 6| Step: 3
Training loss: 0.0987042486667633
Validation loss: 1.441809364544448

Epoch: 6| Step: 4
Training loss: 0.10674671828746796
Validation loss: 1.4549852865998463

Epoch: 6| Step: 5
Training loss: 0.10431733727455139
Validation loss: 1.4338307034584783

Epoch: 6| Step: 6
Training loss: 0.2067175805568695
Validation loss: 1.4060593420459377

Epoch: 6| Step: 7
Training loss: 0.09265676140785217
Validation loss: 1.4327172028121127

Epoch: 6| Step: 8
Training loss: 0.05351029708981514
Validation loss: 1.4356811995147376

Epoch: 6| Step: 9
Training loss: 0.07117316126823425
Validation loss: 1.4065629346396333

Epoch: 6| Step: 10
Training loss: 0.09630084037780762
Validation loss: 1.402255594089467

Epoch: 6| Step: 11
Training loss: 0.08789176493883133
Validation loss: 1.3716406360749276

Epoch: 6| Step: 12
Training loss: 0.07483932375907898
Validation loss: 1.398195623069681

Epoch: 6| Step: 13
Training loss: 0.12099745869636536
Validation loss: 1.3802589562631422

Epoch: 452| Step: 0
Training loss: 0.09567900747060776
Validation loss: 1.3547163701826526

Epoch: 6| Step: 1
Training loss: 0.1689128428697586
Validation loss: 1.3820342325395154

Epoch: 6| Step: 2
Training loss: 0.0959525853395462
Validation loss: 1.3944376848077262

Epoch: 6| Step: 3
Training loss: 0.06731400638818741
Validation loss: 1.394582663812945

Epoch: 6| Step: 4
Training loss: 0.2155553102493286
Validation loss: 1.3911350798863236

Epoch: 6| Step: 5
Training loss: 0.08255994319915771
Validation loss: 1.3925130008369364

Epoch: 6| Step: 6
Training loss: 0.10693924874067307
Validation loss: 1.395285084683408

Epoch: 6| Step: 7
Training loss: 0.08950424194335938
Validation loss: 1.4220483200524443

Epoch: 6| Step: 8
Training loss: 0.12062467634677887
Validation loss: 1.421182688846383

Epoch: 6| Step: 9
Training loss: 0.09191348403692245
Validation loss: 1.3999956256599837

Epoch: 6| Step: 10
Training loss: 0.11244089901447296
Validation loss: 1.3979933787417669

Epoch: 6| Step: 11
Training loss: 0.08910222351551056
Validation loss: 1.411870688520452

Epoch: 6| Step: 12
Training loss: 0.10115060210227966
Validation loss: 1.4069059164293352

Epoch: 6| Step: 13
Training loss: 0.15176548063755035
Validation loss: 1.4140544847775531

Epoch: 453| Step: 0
Training loss: 0.07313141226768494
Validation loss: 1.406022919121609

Epoch: 6| Step: 1
Training loss: 0.0846690908074379
Validation loss: 1.3894241215080343

Epoch: 6| Step: 2
Training loss: 0.1333790421485901
Validation loss: 1.4384699854799496

Epoch: 6| Step: 3
Training loss: 0.14182767271995544
Validation loss: 1.4479078951702322

Epoch: 6| Step: 4
Training loss: 0.1699235439300537
Validation loss: 1.4597905925525132

Epoch: 6| Step: 5
Training loss: 0.1748446822166443
Validation loss: 1.457795666110131

Epoch: 6| Step: 6
Training loss: 0.05391430854797363
Validation loss: 1.4594700913275442

Epoch: 6| Step: 7
Training loss: 0.08959957957267761
Validation loss: 1.4465017844271917

Epoch: 6| Step: 8
Training loss: 0.09482073783874512
Validation loss: 1.443107694707891

Epoch: 6| Step: 9
Training loss: 0.27362725138664246
Validation loss: 1.4451889107304234

Epoch: 6| Step: 10
Training loss: 0.07704352587461472
Validation loss: 1.4210431396320302

Epoch: 6| Step: 11
Training loss: 0.11724992096424103
Validation loss: 1.4553782151591392

Epoch: 6| Step: 12
Training loss: 0.08756284415721893
Validation loss: 1.4516641914203603

Epoch: 6| Step: 13
Training loss: 0.08339986205101013
Validation loss: 1.4633050355859982

Epoch: 454| Step: 0
Training loss: 0.07564917206764221
Validation loss: 1.4573224424034037

Epoch: 6| Step: 1
Training loss: 0.09928365051746368
Validation loss: 1.4818276564280193

Epoch: 6| Step: 2
Training loss: 0.07697468996047974
Validation loss: 1.4681163372532013

Epoch: 6| Step: 3
Training loss: 0.06284025311470032
Validation loss: 1.439249764206589

Epoch: 6| Step: 4
Training loss: 0.06743273884057999
Validation loss: 1.437621118560914

Epoch: 6| Step: 5
Training loss: 0.20812146365642548
Validation loss: 1.4211923896625478

Epoch: 6| Step: 6
Training loss: 0.07940816134214401
Validation loss: 1.4519085602093769

Epoch: 6| Step: 7
Training loss: 0.10581528395414352
Validation loss: 1.4421724375858103

Epoch: 6| Step: 8
Training loss: 0.08475203812122345
Validation loss: 1.4420277739083895

Epoch: 6| Step: 9
Training loss: 0.11395758390426636
Validation loss: 1.4506258131355367

Epoch: 6| Step: 10
Training loss: 0.09798315912485123
Validation loss: 1.416574792195392

Epoch: 6| Step: 11
Training loss: 0.08595439791679382
Validation loss: 1.433815158823485

Epoch: 6| Step: 12
Training loss: 0.08368983864784241
Validation loss: 1.4048428035551501

Epoch: 6| Step: 13
Training loss: 0.12940140068531036
Validation loss: 1.4027343244962795

Epoch: 455| Step: 0
Training loss: 0.09102899581193924
Validation loss: 1.4034173693708194

Epoch: 6| Step: 1
Training loss: 0.08302684128284454
Validation loss: 1.4300862320007817

Epoch: 6| Step: 2
Training loss: 0.100186787545681
Validation loss: 1.4107890654635686

Epoch: 6| Step: 3
Training loss: 0.10613466054201126
Validation loss: 1.4034676667182677

Epoch: 6| Step: 4
Training loss: 0.07195437699556351
Validation loss: 1.3750048260534964

Epoch: 6| Step: 5
Training loss: 0.09145531058311462
Validation loss: 1.4167366053468438

Epoch: 6| Step: 6
Training loss: 0.08431874215602875
Validation loss: 1.4047315018151396

Epoch: 6| Step: 7
Training loss: 0.09540042281150818
Validation loss: 1.3953578126045965

Epoch: 6| Step: 8
Training loss: 0.09478004276752472
Validation loss: 1.4009464953535347

Epoch: 6| Step: 9
Training loss: 0.10090576857328415
Validation loss: 1.3975389529299993

Epoch: 6| Step: 10
Training loss: 0.2426343709230423
Validation loss: 1.4220562609293128

Epoch: 6| Step: 11
Training loss: 0.06867705285549164
Validation loss: 1.4126989482551493

Epoch: 6| Step: 12
Training loss: 0.1493133157491684
Validation loss: 1.4158555794787664

Epoch: 6| Step: 13
Training loss: 0.12835998833179474
Validation loss: 1.4305136255038682

Epoch: 456| Step: 0
Training loss: 0.11856763064861298
Validation loss: 1.4076166524681994

Epoch: 6| Step: 1
Training loss: 0.0754278302192688
Validation loss: 1.4286116169344993

Epoch: 6| Step: 2
Training loss: 0.23305942118167877
Validation loss: 1.4026214153535905

Epoch: 6| Step: 3
Training loss: 0.11501440405845642
Validation loss: 1.4375949649400608

Epoch: 6| Step: 4
Training loss: 0.09033375233411789
Validation loss: 1.426551124101044

Epoch: 6| Step: 5
Training loss: 0.08346565067768097
Validation loss: 1.4309581095172512

Epoch: 6| Step: 6
Training loss: 0.10196740180253983
Validation loss: 1.4327823410751999

Epoch: 6| Step: 7
Training loss: 0.14707759022712708
Validation loss: 1.4216211688133977

Epoch: 6| Step: 8
Training loss: 0.0922883003950119
Validation loss: 1.3870745512746996

Epoch: 6| Step: 9
Training loss: 0.08414728194475174
Validation loss: 1.3939128364286115

Epoch: 6| Step: 10
Training loss: 0.0841517224907875
Validation loss: 1.3912128043431107

Epoch: 6| Step: 11
Training loss: 0.09473654627799988
Validation loss: 1.3955071920989661

Epoch: 6| Step: 12
Training loss: 0.10042032599449158
Validation loss: 1.4151306524071643

Epoch: 6| Step: 13
Training loss: 0.11472974717617035
Validation loss: 1.4070100438210271

Epoch: 457| Step: 0
Training loss: 0.06895315647125244
Validation loss: 1.4393590560523413

Epoch: 6| Step: 1
Training loss: 0.0573199987411499
Validation loss: 1.4217354687311317

Epoch: 6| Step: 2
Training loss: 0.07254532724618912
Validation loss: 1.4558584920821651

Epoch: 6| Step: 3
Training loss: 0.08751316368579865
Validation loss: 1.4535781696278562

Epoch: 6| Step: 4
Training loss: 0.1289469599723816
Validation loss: 1.420861251892582

Epoch: 6| Step: 5
Training loss: 0.13089750707149506
Validation loss: 1.4205947576030609

Epoch: 6| Step: 6
Training loss: 0.05766073614358902
Validation loss: 1.4300005333397978

Epoch: 6| Step: 7
Training loss: 0.09496237337589264
Validation loss: 1.4315016538866105

Epoch: 6| Step: 8
Training loss: 0.2450859546661377
Validation loss: 1.4261273209766676

Epoch: 6| Step: 9
Training loss: 0.0677546039223671
Validation loss: 1.4407698569759246

Epoch: 6| Step: 10
Training loss: 0.08034293353557587
Validation loss: 1.4228293985448859

Epoch: 6| Step: 11
Training loss: 0.06265746802091599
Validation loss: 1.4188533547104045

Epoch: 6| Step: 12
Training loss: 0.09744353592395782
Validation loss: 1.439051530694449

Epoch: 6| Step: 13
Training loss: 0.07197228074073792
Validation loss: 1.4223298321488083

Epoch: 458| Step: 0
Training loss: 0.10346437990665436
Validation loss: 1.4168846530299033

Epoch: 6| Step: 1
Training loss: 0.061415668576955795
Validation loss: 1.4573081795887282

Epoch: 6| Step: 2
Training loss: 0.09761684387922287
Validation loss: 1.4304384749422792

Epoch: 6| Step: 3
Training loss: 0.07880756258964539
Validation loss: 1.4203080848980976

Epoch: 6| Step: 4
Training loss: 0.21085551381111145
Validation loss: 1.423252353104212

Epoch: 6| Step: 5
Training loss: 0.05463408678770065
Validation loss: 1.4189498937258156

Epoch: 6| Step: 6
Training loss: 0.10094563663005829
Validation loss: 1.4157172633755593

Epoch: 6| Step: 7
Training loss: 0.11587253957986832
Validation loss: 1.4281656357549852

Epoch: 6| Step: 8
Training loss: 0.10588521510362625
Validation loss: 1.4232357522492767

Epoch: 6| Step: 9
Training loss: 0.05117369070649147
Validation loss: 1.4222372539581791

Epoch: 6| Step: 10
Training loss: 0.07770393788814545
Validation loss: 1.4250128679378058

Epoch: 6| Step: 11
Training loss: 0.12023632228374481
Validation loss: 1.422556584881198

Epoch: 6| Step: 12
Training loss: 0.04362725466489792
Validation loss: 1.4697575005151893

Epoch: 6| Step: 13
Training loss: 0.1339147388935089
Validation loss: 1.4542553617108254

Epoch: 459| Step: 0
Training loss: 0.07972842454910278
Validation loss: 1.4450541286058323

Epoch: 6| Step: 1
Training loss: 0.11359825730323792
Validation loss: 1.4403485393011441

Epoch: 6| Step: 2
Training loss: 0.10005108267068863
Validation loss: 1.4338912886957969

Epoch: 6| Step: 3
Training loss: 0.11096449941396713
Validation loss: 1.4174444393445087

Epoch: 6| Step: 4
Training loss: 0.09030680358409882
Validation loss: 1.405847353319968

Epoch: 6| Step: 5
Training loss: 0.07030723989009857
Validation loss: 1.3850825255916965

Epoch: 6| Step: 6
Training loss: 0.10392211377620697
Validation loss: 1.3683411305950535

Epoch: 6| Step: 7
Training loss: 0.11317674815654755
Validation loss: 1.3784671393773889

Epoch: 6| Step: 8
Training loss: 0.08511291444301605
Validation loss: 1.4111593589987805

Epoch: 6| Step: 9
Training loss: 0.09735197573900223
Validation loss: 1.4024713911036009

Epoch: 6| Step: 10
Training loss: 0.12224440276622772
Validation loss: 1.4094238742705314

Epoch: 6| Step: 11
Training loss: 0.08778337389230728
Validation loss: 1.3914463071412937

Epoch: 6| Step: 12
Training loss: 0.2364237904548645
Validation loss: 1.4322359613192979

Epoch: 6| Step: 13
Training loss: 0.05440043658018112
Validation loss: 1.4349214453851022

Epoch: 460| Step: 0
Training loss: 0.11285780370235443
Validation loss: 1.4208845489768571

Epoch: 6| Step: 1
Training loss: 0.034000251442193985
Validation loss: 1.4268618277324143

Epoch: 6| Step: 2
Training loss: 0.07286252826452255
Validation loss: 1.413170228722275

Epoch: 6| Step: 3
Training loss: 0.10138991475105286
Validation loss: 1.4129784132844658

Epoch: 6| Step: 4
Training loss: 0.08819839358329773
Validation loss: 1.4336754256679165

Epoch: 6| Step: 5
Training loss: 0.08209462463855743
Validation loss: 1.4283806354768815

Epoch: 6| Step: 6
Training loss: 0.28096169233322144
Validation loss: 1.4351572657144198

Epoch: 6| Step: 7
Training loss: 0.07854463905096054
Validation loss: 1.4444774966086111

Epoch: 6| Step: 8
Training loss: 0.11928490549325943
Validation loss: 1.4421794606793312

Epoch: 6| Step: 9
Training loss: 0.11949692666530609
Validation loss: 1.4508645258924013

Epoch: 6| Step: 10
Training loss: 0.06120816618204117
Validation loss: 1.4444621788558138

Epoch: 6| Step: 11
Training loss: 0.07894175499677658
Validation loss: 1.4365630213932326

Epoch: 6| Step: 12
Training loss: 0.09403890371322632
Validation loss: 1.4771416917923959

Epoch: 6| Step: 13
Training loss: 0.10215335339307785
Validation loss: 1.4606444476753153

Epoch: 461| Step: 0
Training loss: 0.07116445153951645
Validation loss: 1.4480799833933513

Epoch: 6| Step: 1
Training loss: 0.10100892931222916
Validation loss: 1.4490730172844344

Epoch: 6| Step: 2
Training loss: 0.05595807731151581
Validation loss: 1.4463475814429663

Epoch: 6| Step: 3
Training loss: 0.050604190677404404
Validation loss: 1.451436190194981

Epoch: 6| Step: 4
Training loss: 0.05218196660280228
Validation loss: 1.4378419306970411

Epoch: 6| Step: 5
Training loss: 0.07639409601688385
Validation loss: 1.4909686183416715

Epoch: 6| Step: 6
Training loss: 0.11006514728069305
Validation loss: 1.4832969224581154

Epoch: 6| Step: 7
Training loss: 0.190393328666687
Validation loss: 1.469824339753838

Epoch: 6| Step: 8
Training loss: 0.08770795166492462
Validation loss: 1.4615515367959135

Epoch: 6| Step: 9
Training loss: 0.10247373580932617
Validation loss: 1.4348290710039036

Epoch: 6| Step: 10
Training loss: 0.10881932079792023
Validation loss: 1.418391134790195

Epoch: 6| Step: 11
Training loss: 0.11141542345285416
Validation loss: 1.4108800093332927

Epoch: 6| Step: 12
Training loss: 0.11586517095565796
Validation loss: 1.4289785021094865

Epoch: 6| Step: 13
Training loss: 0.06367519497871399
Validation loss: 1.4126218377902944

Epoch: 462| Step: 0
Training loss: 0.06701700389385223
Validation loss: 1.3895337748271164

Epoch: 6| Step: 1
Training loss: 0.12057217955589294
Validation loss: 1.3969329505838373

Epoch: 6| Step: 2
Training loss: 0.06171303987503052
Validation loss: 1.4020807960981965

Epoch: 6| Step: 3
Training loss: 0.10657259076833725
Validation loss: 1.4378230815292687

Epoch: 6| Step: 4
Training loss: 0.13609188795089722
Validation loss: 1.4237851981193788

Epoch: 6| Step: 5
Training loss: 0.0675988495349884
Validation loss: 1.4368110625974593

Epoch: 6| Step: 6
Training loss: 0.06871536374092102
Validation loss: 1.4661826363173864

Epoch: 6| Step: 7
Training loss: 0.22209720313549042
Validation loss: 1.4239135557605374

Epoch: 6| Step: 8
Training loss: 0.09380698949098587
Validation loss: 1.444182918276838

Epoch: 6| Step: 9
Training loss: 0.08821797370910645
Validation loss: 1.4262194479665449

Epoch: 6| Step: 10
Training loss: 0.0925118625164032
Validation loss: 1.404234904114918

Epoch: 6| Step: 11
Training loss: 0.060388196259737015
Validation loss: 1.4209248558167489

Epoch: 6| Step: 12
Training loss: 0.1724848598241806
Validation loss: 1.4106672489514915

Epoch: 6| Step: 13
Training loss: 0.13066847622394562
Validation loss: 1.4361762859488045

Epoch: 463| Step: 0
Training loss: 0.10265249758958817
Validation loss: 1.4704811137209657

Epoch: 6| Step: 1
Training loss: 0.1003236323595047
Validation loss: 1.4335574411576795

Epoch: 6| Step: 2
Training loss: 0.11360646039247513
Validation loss: 1.4694976652822187

Epoch: 6| Step: 3
Training loss: 0.11250007152557373
Validation loss: 1.4599845191483856

Epoch: 6| Step: 4
Training loss: 0.09479007124900818
Validation loss: 1.479092159578877

Epoch: 6| Step: 5
Training loss: 0.10653135925531387
Validation loss: 1.4510105348402453

Epoch: 6| Step: 6
Training loss: 0.11934525519609451
Validation loss: 1.4592199774198635

Epoch: 6| Step: 7
Training loss: 0.13301002979278564
Validation loss: 1.4306701062827982

Epoch: 6| Step: 8
Training loss: 0.2525891959667206
Validation loss: 1.4269778202938777

Epoch: 6| Step: 9
Training loss: 0.12761487066745758
Validation loss: 1.4118910297270744

Epoch: 6| Step: 10
Training loss: 0.07872584462165833
Validation loss: 1.4085229058419504

Epoch: 6| Step: 11
Training loss: 0.11056461930274963
Validation loss: 1.4044856384236326

Epoch: 6| Step: 12
Training loss: 0.19320261478424072
Validation loss: 1.4098658484797324

Epoch: 6| Step: 13
Training loss: 0.11437475681304932
Validation loss: 1.3514049014737528

Epoch: 464| Step: 0
Training loss: 0.10994713753461838
Validation loss: 1.3873359951921689

Epoch: 6| Step: 1
Training loss: 0.12495449930429459
Validation loss: 1.3739490233441836

Epoch: 6| Step: 2
Training loss: 0.17981389164924622
Validation loss: 1.3957486280830957

Epoch: 6| Step: 3
Training loss: 0.09811259806156158
Validation loss: 1.3778172244307816

Epoch: 6| Step: 4
Training loss: 0.06553392112255096
Validation loss: 1.3931843529465378

Epoch: 6| Step: 5
Training loss: 0.05853649973869324
Validation loss: 1.39627674189947

Epoch: 6| Step: 6
Training loss: 0.13878852128982544
Validation loss: 1.4232579783726764

Epoch: 6| Step: 7
Training loss: 0.07377920299768448
Validation loss: 1.4064185850081905

Epoch: 6| Step: 8
Training loss: 0.06348436325788498
Validation loss: 1.4034393910438783

Epoch: 6| Step: 9
Training loss: 0.20339059829711914
Validation loss: 1.4132349837210871

Epoch: 6| Step: 10
Training loss: 0.08833904564380646
Validation loss: 1.3927544868120583

Epoch: 6| Step: 11
Training loss: 0.08318918943405151
Validation loss: 1.4066228969122774

Epoch: 6| Step: 12
Training loss: 0.12830203771591187
Validation loss: 1.4168108868342575

Epoch: 6| Step: 13
Training loss: 0.06166643649339676
Validation loss: 1.4281112263279576

Epoch: 465| Step: 0
Training loss: 0.09557157009840012
Validation loss: 1.443260226198422

Epoch: 6| Step: 1
Training loss: 0.14386793971061707
Validation loss: 1.4312473336855571

Epoch: 6| Step: 2
Training loss: 0.20207439363002777
Validation loss: 1.4301069045579562

Epoch: 6| Step: 3
Training loss: 0.12200210988521576
Validation loss: 1.4385896831430414

Epoch: 6| Step: 4
Training loss: 0.08637461066246033
Validation loss: 1.429512471281072

Epoch: 6| Step: 5
Training loss: 0.12722086906433105
Validation loss: 1.4037313166485037

Epoch: 6| Step: 6
Training loss: 0.07906316220760345
Validation loss: 1.4210909284571165

Epoch: 6| Step: 7
Training loss: 0.047601595520973206
Validation loss: 1.399455375568841

Epoch: 6| Step: 8
Training loss: 0.11420653760433197
Validation loss: 1.392655885347756

Epoch: 6| Step: 9
Training loss: 0.0786047950387001
Validation loss: 1.404906576679599

Epoch: 6| Step: 10
Training loss: 0.06239672005176544
Validation loss: 1.374600652725466

Epoch: 6| Step: 11
Training loss: 0.09929639846086502
Validation loss: 1.3780675831661429

Epoch: 6| Step: 12
Training loss: 0.1169244647026062
Validation loss: 1.3776865018311368

Epoch: 6| Step: 13
Training loss: 0.06219567358493805
Validation loss: 1.3810900731753277

Epoch: 466| Step: 0
Training loss: 0.09218308329582214
Validation loss: 1.3732590636899393

Epoch: 6| Step: 1
Training loss: 0.05530492961406708
Validation loss: 1.3768056387542396

Epoch: 6| Step: 2
Training loss: 0.07505044341087341
Validation loss: 1.374715571762413

Epoch: 6| Step: 3
Training loss: 0.09028276801109314
Validation loss: 1.3727912351649294

Epoch: 6| Step: 4
Training loss: 0.2464457005262375
Validation loss: 1.3907351314380605

Epoch: 6| Step: 5
Training loss: 0.044084664434194565
Validation loss: 1.4039237153145574

Epoch: 6| Step: 6
Training loss: 0.07261461764574051
Validation loss: 1.3842837502879481

Epoch: 6| Step: 7
Training loss: 0.10432746261358261
Validation loss: 1.3967451087890133

Epoch: 6| Step: 8
Training loss: 0.05887867882847786
Validation loss: 1.3566053355893781

Epoch: 6| Step: 9
Training loss: 0.06380922347307205
Validation loss: 1.3708336571211457

Epoch: 6| Step: 10
Training loss: 0.10044196248054504
Validation loss: 1.3971573037485923

Epoch: 6| Step: 11
Training loss: 0.07260029017925262
Validation loss: 1.4194545271576091

Epoch: 6| Step: 12
Training loss: 0.05840069428086281
Validation loss: 1.4156498832087363

Epoch: 6| Step: 13
Training loss: 0.0630289763212204
Validation loss: 1.4263391635751212

Epoch: 467| Step: 0
Training loss: 0.09213872253894806
Validation loss: 1.4177614860637213

Epoch: 6| Step: 1
Training loss: 0.1211845651268959
Validation loss: 1.4023474108788274

Epoch: 6| Step: 2
Training loss: 0.07936836779117584
Validation loss: 1.4269651853910057

Epoch: 6| Step: 3
Training loss: 0.23791903257369995
Validation loss: 1.3829874556551698

Epoch: 6| Step: 4
Training loss: 0.06395039707422256
Validation loss: 1.4038527973236576

Epoch: 6| Step: 5
Training loss: 0.1037641242146492
Validation loss: 1.3993448429210211

Epoch: 6| Step: 6
Training loss: 0.08459052443504333
Validation loss: 1.4194489358573832

Epoch: 6| Step: 7
Training loss: 0.07448476552963257
Validation loss: 1.406136223064956

Epoch: 6| Step: 8
Training loss: 0.08485476672649384
Validation loss: 1.403991924819126

Epoch: 6| Step: 9
Training loss: 0.08484159409999847
Validation loss: 1.385714348926339

Epoch: 6| Step: 10
Training loss: 0.0817420482635498
Validation loss: 1.409696868670884

Epoch: 6| Step: 11
Training loss: 0.1105085015296936
Validation loss: 1.42986931467569

Epoch: 6| Step: 12
Training loss: 0.12705540657043457
Validation loss: 1.4289780432178127

Epoch: 6| Step: 13
Training loss: 0.16403734683990479
Validation loss: 1.4646507886148268

Epoch: 468| Step: 0
Training loss: 0.09273187816143036
Validation loss: 1.4399276471907092

Epoch: 6| Step: 1
Training loss: 0.05555921047925949
Validation loss: 1.4530532898441437

Epoch: 6| Step: 2
Training loss: 0.0920770913362503
Validation loss: 1.4445812253541843

Epoch: 6| Step: 3
Training loss: 0.13170722126960754
Validation loss: 1.4107861121495564

Epoch: 6| Step: 4
Training loss: 0.05653524026274681
Validation loss: 1.4343469976097025

Epoch: 6| Step: 5
Training loss: 0.13041990995407104
Validation loss: 1.4143461206907868

Epoch: 6| Step: 6
Training loss: 0.07900644838809967
Validation loss: 1.4187868961723902

Epoch: 6| Step: 7
Training loss: 0.08515281975269318
Validation loss: 1.3942957398711995

Epoch: 6| Step: 8
Training loss: 0.22909623384475708
Validation loss: 1.413109875494434

Epoch: 6| Step: 9
Training loss: 0.13235719501972198
Validation loss: 1.4390226871736589

Epoch: 6| Step: 10
Training loss: 0.10818715393543243
Validation loss: 1.4436419933072981

Epoch: 6| Step: 11
Training loss: 0.06674177199602127
Validation loss: 1.442512075106303

Epoch: 6| Step: 12
Training loss: 0.14000824093818665
Validation loss: 1.4559664880075762

Epoch: 6| Step: 13
Training loss: 0.1260613650083542
Validation loss: 1.4547206791498328

Epoch: 469| Step: 0
Training loss: 0.06963714957237244
Validation loss: 1.4658106950021559

Epoch: 6| Step: 1
Training loss: 0.16587969660758972
Validation loss: 1.466131761509885

Epoch: 6| Step: 2
Training loss: 0.11886271834373474
Validation loss: 1.4712680110367395

Epoch: 6| Step: 3
Training loss: 0.07377302646636963
Validation loss: 1.4552729591246574

Epoch: 6| Step: 4
Training loss: 0.09223867952823639
Validation loss: 1.4645171473103185

Epoch: 6| Step: 5
Training loss: 0.07761770486831665
Validation loss: 1.4157490102193688

Epoch: 6| Step: 6
Training loss: 0.2919621765613556
Validation loss: 1.4316562350078295

Epoch: 6| Step: 7
Training loss: 0.07890239357948303
Validation loss: 1.4353230640452395

Epoch: 6| Step: 8
Training loss: 0.07671982049942017
Validation loss: 1.4139482064913678

Epoch: 6| Step: 9
Training loss: 0.13731107115745544
Validation loss: 1.3952001134554546

Epoch: 6| Step: 10
Training loss: 0.0901031494140625
Validation loss: 1.4318928308384393

Epoch: 6| Step: 11
Training loss: 0.13119710981845856
Validation loss: 1.4156321492246402

Epoch: 6| Step: 12
Training loss: 0.07387780398130417
Validation loss: 1.4465818366696757

Epoch: 6| Step: 13
Training loss: 0.062114834785461426
Validation loss: 1.4530210033539803

Epoch: 470| Step: 0
Training loss: 0.2497847080230713
Validation loss: 1.4558631297080749

Epoch: 6| Step: 1
Training loss: 0.09941577166318893
Validation loss: 1.4570530729909097

Epoch: 6| Step: 2
Training loss: 0.0868341475725174
Validation loss: 1.4543954762079383

Epoch: 6| Step: 3
Training loss: 0.10968633741140366
Validation loss: 1.4360807134259133

Epoch: 6| Step: 4
Training loss: 0.09359083324670792
Validation loss: 1.4500866820735316

Epoch: 6| Step: 5
Training loss: 0.099759042263031
Validation loss: 1.440969664563415

Epoch: 6| Step: 6
Training loss: 0.06606805324554443
Validation loss: 1.4281258865069317

Epoch: 6| Step: 7
Training loss: 0.09284055978059769
Validation loss: 1.401101880176093

Epoch: 6| Step: 8
Training loss: 0.11371096968650818
Validation loss: 1.3918653380486272

Epoch: 6| Step: 9
Training loss: 0.1218297928571701
Validation loss: 1.3862149612877959

Epoch: 6| Step: 10
Training loss: 0.04920095577836037
Validation loss: 1.4078683128920935

Epoch: 6| Step: 11
Training loss: 0.09487488865852356
Validation loss: 1.369199634880148

Epoch: 6| Step: 12
Training loss: 0.07284793257713318
Validation loss: 1.376784913001522

Epoch: 6| Step: 13
Training loss: 0.10183051973581314
Validation loss: 1.353310041530158

Epoch: 471| Step: 0
Training loss: 0.0762782096862793
Validation loss: 1.399354374536904

Epoch: 6| Step: 1
Training loss: 0.126938134431839
Validation loss: 1.3878723639313892

Epoch: 6| Step: 2
Training loss: 0.11047076433897018
Validation loss: 1.423963850544345

Epoch: 6| Step: 3
Training loss: 0.12357483059167862
Validation loss: 1.4204550199611212

Epoch: 6| Step: 4
Training loss: 0.04862575978040695
Validation loss: 1.432921241688472

Epoch: 6| Step: 5
Training loss: 0.09907188266515732
Validation loss: 1.454808844033108

Epoch: 6| Step: 6
Training loss: 0.10065329074859619
Validation loss: 1.4262573411387782

Epoch: 6| Step: 7
Training loss: 0.07956220954656601
Validation loss: 1.4312447770949333

Epoch: 6| Step: 8
Training loss: 0.09288038313388824
Validation loss: 1.4278100511079193

Epoch: 6| Step: 9
Training loss: 0.08646952360868454
Validation loss: 1.4485789473338793

Epoch: 6| Step: 10
Training loss: 0.23261520266532898
Validation loss: 1.4185382557171646

Epoch: 6| Step: 11
Training loss: 0.09217095375061035
Validation loss: 1.405605814790213

Epoch: 6| Step: 12
Training loss: 0.08997665345668793
Validation loss: 1.4182388397955126

Epoch: 6| Step: 13
Training loss: 0.074672631919384
Validation loss: 1.4383919738954114

Epoch: 472| Step: 0
Training loss: 0.07327196002006531
Validation loss: 1.413894937884423

Epoch: 6| Step: 1
Training loss: 0.0687323659658432
Validation loss: 1.4241647194790583

Epoch: 6| Step: 2
Training loss: 0.11463351547718048
Validation loss: 1.4005360257241033

Epoch: 6| Step: 3
Training loss: 0.09740406274795532
Validation loss: 1.4291200689090195

Epoch: 6| Step: 4
Training loss: 0.04633596912026405
Validation loss: 1.420531249815418

Epoch: 6| Step: 5
Training loss: 0.25405269861221313
Validation loss: 1.3867609770067277

Epoch: 6| Step: 6
Training loss: 0.10728560388088226
Validation loss: 1.4008918526352092

Epoch: 6| Step: 7
Training loss: 0.06276454031467438
Validation loss: 1.407000514127875

Epoch: 6| Step: 8
Training loss: 0.0803680345416069
Validation loss: 1.3918688963818293

Epoch: 6| Step: 9
Training loss: 0.0855390802025795
Validation loss: 1.3609030580007901

Epoch: 6| Step: 10
Training loss: 0.05825481563806534
Validation loss: 1.394575890674386

Epoch: 6| Step: 11
Training loss: 0.11826124787330627
Validation loss: 1.3856801230420348

Epoch: 6| Step: 12
Training loss: 0.1212514340877533
Validation loss: 1.3680083187677528

Epoch: 6| Step: 13
Training loss: 0.10432962328195572
Validation loss: 1.3671855913695468

Epoch: 473| Step: 0
Training loss: 0.0776979923248291
Validation loss: 1.3659258260521838

Epoch: 6| Step: 1
Training loss: 0.08339707553386688
Validation loss: 1.3491601892696914

Epoch: 6| Step: 2
Training loss: 0.1067100241780281
Validation loss: 1.4016266317777737

Epoch: 6| Step: 3
Training loss: 0.09200288355350494
Validation loss: 1.3813098822870562

Epoch: 6| Step: 4
Training loss: 0.05986684188246727
Validation loss: 1.4007656779340518

Epoch: 6| Step: 5
Training loss: 0.07820312678813934
Validation loss: 1.4044486861075125

Epoch: 6| Step: 6
Training loss: 0.28595590591430664
Validation loss: 1.4063561847133021

Epoch: 6| Step: 7
Training loss: 0.10136756300926208
Validation loss: 1.460258351859226

Epoch: 6| Step: 8
Training loss: 0.1083560511469841
Validation loss: 1.4298493451969598

Epoch: 6| Step: 9
Training loss: 0.06759075820446014
Validation loss: 1.4405157591706963

Epoch: 6| Step: 10
Training loss: 0.08470858633518219
Validation loss: 1.4510259243749803

Epoch: 6| Step: 11
Training loss: 0.08394253253936768
Validation loss: 1.4477673858724616

Epoch: 6| Step: 12
Training loss: 0.07513304054737091
Validation loss: 1.4722779553423646

Epoch: 6| Step: 13
Training loss: 0.17593951523303986
Validation loss: 1.485046298273148

Epoch: 474| Step: 0
Training loss: 0.1461380124092102
Validation loss: 1.4632625297833515

Epoch: 6| Step: 1
Training loss: 0.06982284784317017
Validation loss: 1.4733136430863412

Epoch: 6| Step: 2
Training loss: 0.10266666114330292
Validation loss: 1.4550101769867765

Epoch: 6| Step: 3
Training loss: 0.11565521359443665
Validation loss: 1.440510985671833

Epoch: 6| Step: 4
Training loss: 0.09478636085987091
Validation loss: 1.4158269538674304

Epoch: 6| Step: 5
Training loss: 0.08700040727853775
Validation loss: 1.3885450452886603

Epoch: 6| Step: 6
Training loss: 0.14462439715862274
Validation loss: 1.3801828994545886

Epoch: 6| Step: 7
Training loss: 0.09329403936862946
Validation loss: 1.391084050619474

Epoch: 6| Step: 8
Training loss: 0.11860103160142899
Validation loss: 1.3593443747489684

Epoch: 6| Step: 9
Training loss: 0.05451325327157974
Validation loss: 1.356516376618416

Epoch: 6| Step: 10
Training loss: 0.30662399530410767
Validation loss: 1.3695706603347615

Epoch: 6| Step: 11
Training loss: 0.11800570040941238
Validation loss: 1.387064117257313

Epoch: 6| Step: 12
Training loss: 0.13226157426834106
Validation loss: 1.3714964389801025

Epoch: 6| Step: 13
Training loss: 0.08390801399946213
Validation loss: 1.3828074445006668

Epoch: 475| Step: 0
Training loss: 0.09829548746347427
Validation loss: 1.3771494921817575

Epoch: 6| Step: 1
Training loss: 0.10910020768642426
Validation loss: 1.3905175796119116

Epoch: 6| Step: 2
Training loss: 0.11295410245656967
Validation loss: 1.3773501342342747

Epoch: 6| Step: 3
Training loss: 0.0928460955619812
Validation loss: 1.4031532861853158

Epoch: 6| Step: 4
Training loss: 0.11855553835630417
Validation loss: 1.391843459939444

Epoch: 6| Step: 5
Training loss: 0.08818237483501434
Validation loss: 1.3692961482591526

Epoch: 6| Step: 6
Training loss: 0.07571268081665039
Validation loss: 1.386362055296539

Epoch: 6| Step: 7
Training loss: 0.05281246453523636
Validation loss: 1.3904200894858247

Epoch: 6| Step: 8
Training loss: 0.06544611603021622
Validation loss: 1.3689486893915361

Epoch: 6| Step: 9
Training loss: 0.05524205416440964
Validation loss: 1.4192048932916375

Epoch: 6| Step: 10
Training loss: 0.0653436928987503
Validation loss: 1.3975619000773276

Epoch: 6| Step: 11
Training loss: 0.05347757041454315
Validation loss: 1.400718863933317

Epoch: 6| Step: 12
Training loss: 0.07299496978521347
Validation loss: 1.4128719657979987

Epoch: 6| Step: 13
Training loss: 0.3896535038948059
Validation loss: 1.3780344699018745

Epoch: 476| Step: 0
Training loss: 0.08660480380058289
Validation loss: 1.4006524009089316

Epoch: 6| Step: 1
Training loss: 0.06773427128791809
Validation loss: 1.3836407648619784

Epoch: 6| Step: 2
Training loss: 0.12069173902273178
Validation loss: 1.4072970882538827

Epoch: 6| Step: 3
Training loss: 0.09367289394140244
Validation loss: 1.3872477444269324

Epoch: 6| Step: 4
Training loss: 0.10197640210390091
Validation loss: 1.4016535730772122

Epoch: 6| Step: 5
Training loss: 0.09136699885129929
Validation loss: 1.4074626891843733

Epoch: 6| Step: 6
Training loss: 0.10542409867048264
Validation loss: 1.4262180712915236

Epoch: 6| Step: 7
Training loss: 0.0963723212480545
Validation loss: 1.4495576274010442

Epoch: 6| Step: 8
Training loss: 0.05180920660495758
Validation loss: 1.4273192568491864

Epoch: 6| Step: 9
Training loss: 0.08302079141139984
Validation loss: 1.4742139129228489

Epoch: 6| Step: 10
Training loss: 0.10442923754453659
Validation loss: 1.4462241729100545

Epoch: 6| Step: 11
Training loss: 0.15047556161880493
Validation loss: 1.4727000549275389

Epoch: 6| Step: 12
Training loss: 0.14359869062900543
Validation loss: 1.4324996689314484

Epoch: 6| Step: 13
Training loss: 0.33363309502601624
Validation loss: 1.4284689977604856

Epoch: 477| Step: 0
Training loss: 0.08211466670036316
Validation loss: 1.4279492625626184

Epoch: 6| Step: 1
Training loss: 0.0780569463968277
Validation loss: 1.4197494522217782

Epoch: 6| Step: 2
Training loss: 0.04198145121335983
Validation loss: 1.4178053076549242

Epoch: 6| Step: 3
Training loss: 0.09297949075698853
Validation loss: 1.4150629376852384

Epoch: 6| Step: 4
Training loss: 0.06594592332839966
Validation loss: 1.4431124476976291

Epoch: 6| Step: 5
Training loss: 0.06558717042207718
Validation loss: 1.428296830064507

Epoch: 6| Step: 6
Training loss: 0.12111187726259232
Validation loss: 1.4303079599975257

Epoch: 6| Step: 7
Training loss: 0.14277976751327515
Validation loss: 1.4424212472413176

Epoch: 6| Step: 8
Training loss: 0.05605874955654144
Validation loss: 1.4283403504279353

Epoch: 6| Step: 9
Training loss: 0.05361459404230118
Validation loss: 1.4251549295199815

Epoch: 6| Step: 10
Training loss: 0.062227703630924225
Validation loss: 1.443069863063033

Epoch: 6| Step: 11
Training loss: 0.07320170104503632
Validation loss: 1.426284029919614

Epoch: 6| Step: 12
Training loss: 0.07403293251991272
Validation loss: 1.384645365899609

Epoch: 6| Step: 13
Training loss: 0.3167728781700134
Validation loss: 1.4341806442506853

Epoch: 478| Step: 0
Training loss: 0.09660501778125763
Validation loss: 1.4415993587945097

Epoch: 6| Step: 1
Training loss: 0.06803730875253677
Validation loss: 1.4106314874464465

Epoch: 6| Step: 2
Training loss: 0.08977952599525452
Validation loss: 1.410406292125743

Epoch: 6| Step: 3
Training loss: 0.0453139990568161
Validation loss: 1.3937745094299316

Epoch: 6| Step: 4
Training loss: 0.052299343049526215
Validation loss: 1.4128356223465295

Epoch: 6| Step: 5
Training loss: 0.08954860270023346
Validation loss: 1.4189589100499307

Epoch: 6| Step: 6
Training loss: 0.0619477853178978
Validation loss: 1.4059993733641922

Epoch: 6| Step: 7
Training loss: 0.07178598642349243
Validation loss: 1.4086510724918817

Epoch: 6| Step: 8
Training loss: 0.04386921972036362
Validation loss: 1.4212379699112268

Epoch: 6| Step: 9
Training loss: 0.0647544115781784
Validation loss: 1.410774827003479

Epoch: 6| Step: 10
Training loss: 0.11741966009140015
Validation loss: 1.4261394405877719

Epoch: 6| Step: 11
Training loss: 0.10885730385780334
Validation loss: 1.413364832119275

Epoch: 6| Step: 12
Training loss: 0.2587236762046814
Validation loss: 1.4551407226952173

Epoch: 6| Step: 13
Training loss: 0.15059266984462738
Validation loss: 1.4526502945089852

Epoch: 479| Step: 0
Training loss: 0.0772579237818718
Validation loss: 1.4614254018311859

Epoch: 6| Step: 1
Training loss: 0.09853547811508179
Validation loss: 1.4769547857264036

Epoch: 6| Step: 2
Training loss: 0.0516246035695076
Validation loss: 1.4370373179835658

Epoch: 6| Step: 3
Training loss: 0.07771280407905579
Validation loss: 1.4505940227098362

Epoch: 6| Step: 4
Training loss: 0.07718074321746826
Validation loss: 1.406324795497361

Epoch: 6| Step: 5
Training loss: 0.07222414016723633
Validation loss: 1.4063207545588094

Epoch: 6| Step: 6
Training loss: 0.23491063714027405
Validation loss: 1.4410591933035082

Epoch: 6| Step: 7
Training loss: 0.06899724900722504
Validation loss: 1.4305285241014214

Epoch: 6| Step: 8
Training loss: 0.07797320932149887
Validation loss: 1.4402945439020793

Epoch: 6| Step: 9
Training loss: 0.06665576249361038
Validation loss: 1.4196763807727444

Epoch: 6| Step: 10
Training loss: 0.05461055040359497
Validation loss: 1.4420758729339929

Epoch: 6| Step: 11
Training loss: 0.11787593364715576
Validation loss: 1.4161151993659236

Epoch: 6| Step: 12
Training loss: 0.13255174458026886
Validation loss: 1.4053936184093516

Epoch: 6| Step: 13
Training loss: 0.11619199812412262
Validation loss: 1.3937101953773088

Epoch: 480| Step: 0
Training loss: 0.07703353464603424
Validation loss: 1.4115731837928935

Epoch: 6| Step: 1
Training loss: 0.08430323004722595
Validation loss: 1.3861929062874085

Epoch: 6| Step: 2
Training loss: 0.04617748409509659
Validation loss: 1.3820249060148835

Epoch: 6| Step: 3
Training loss: 0.10212886333465576
Validation loss: 1.4225453266533472

Epoch: 6| Step: 4
Training loss: 0.06915506720542908
Validation loss: 1.3835539587082402

Epoch: 6| Step: 5
Training loss: 0.06616148352622986
Validation loss: 1.3855622378728722

Epoch: 6| Step: 6
Training loss: 0.058567434549331665
Validation loss: 1.3524016590528591

Epoch: 6| Step: 7
Training loss: 0.11758491396903992
Validation loss: 1.3701624851072989

Epoch: 6| Step: 8
Training loss: 0.10274720191955566
Validation loss: 1.3438028968790525

Epoch: 6| Step: 9
Training loss: 0.08906879276037216
Validation loss: 1.3681129781148766

Epoch: 6| Step: 10
Training loss: 0.0684078186750412
Validation loss: 1.3715358754639984

Epoch: 6| Step: 11
Training loss: 0.11858443915843964
Validation loss: 1.3686931902362454

Epoch: 6| Step: 12
Training loss: 0.20871910452842712
Validation loss: 1.385989890303663

Epoch: 6| Step: 13
Training loss: 0.06365332007408142
Validation loss: 1.4010741223571122

Epoch: 481| Step: 0
Training loss: 0.08096788078546524
Validation loss: 1.4081774475753948

Epoch: 6| Step: 1
Training loss: 0.08905358612537384
Validation loss: 1.4039608073490921

Epoch: 6| Step: 2
Training loss: 0.06761579215526581
Validation loss: 1.4258737282086444

Epoch: 6| Step: 3
Training loss: 0.09859541058540344
Validation loss: 1.4307698870217929

Epoch: 6| Step: 4
Training loss: 0.09790416061878204
Validation loss: 1.4497746241989957

Epoch: 6| Step: 5
Training loss: 0.08535462617874146
Validation loss: 1.4691520339699202

Epoch: 6| Step: 6
Training loss: 0.2369527518749237
Validation loss: 1.4367689304454352

Epoch: 6| Step: 7
Training loss: 0.061192888766527176
Validation loss: 1.455841479762908

Epoch: 6| Step: 8
Training loss: 0.1000039130449295
Validation loss: 1.4396404271484704

Epoch: 6| Step: 9
Training loss: 0.13382813334465027
Validation loss: 1.4409442819574827

Epoch: 6| Step: 10
Training loss: 0.10170630365610123
Validation loss: 1.4184939938206826

Epoch: 6| Step: 11
Training loss: 0.1208101361989975
Validation loss: 1.4289637034939182

Epoch: 6| Step: 12
Training loss: 0.07248449325561523
Validation loss: 1.4282563517811477

Epoch: 6| Step: 13
Training loss: 0.1179783046245575
Validation loss: 1.390427827835083

Epoch: 482| Step: 0
Training loss: 0.10528551042079926
Validation loss: 1.4152036533560803

Epoch: 6| Step: 1
Training loss: 0.13251417875289917
Validation loss: 1.3818144170186852

Epoch: 6| Step: 2
Training loss: 0.09622525423765182
Validation loss: 1.3760590296919628

Epoch: 6| Step: 3
Training loss: 0.14317981898784637
Validation loss: 1.3958239952723186

Epoch: 6| Step: 4
Training loss: 0.13538338243961334
Validation loss: 1.4186612175356956

Epoch: 6| Step: 5
Training loss: 0.1168857142329216
Validation loss: 1.4349788363261888

Epoch: 6| Step: 6
Training loss: 0.07763862609863281
Validation loss: 1.432867129643758

Epoch: 6| Step: 7
Training loss: 0.1556517481803894
Validation loss: 1.4372626543045044

Epoch: 6| Step: 8
Training loss: 0.08494317531585693
Validation loss: 1.4324266244006414

Epoch: 6| Step: 9
Training loss: 0.10812082886695862
Validation loss: 1.4113292014727028

Epoch: 6| Step: 10
Training loss: 0.06563452631235123
Validation loss: 1.3919607170166508

Epoch: 6| Step: 11
Training loss: 0.0856611579656601
Validation loss: 1.3722066340907928

Epoch: 6| Step: 12
Training loss: 0.07031910121440887
Validation loss: 1.3888254909105198

Epoch: 6| Step: 13
Training loss: 0.29476863145828247
Validation loss: 1.3809239031166158

Epoch: 483| Step: 0
Training loss: 0.07800091803073883
Validation loss: 1.3898834272097516

Epoch: 6| Step: 1
Training loss: 0.10754143446683884
Validation loss: 1.4423055879531368

Epoch: 6| Step: 2
Training loss: 0.08019990473985672
Validation loss: 1.4317489452259515

Epoch: 6| Step: 3
Training loss: 0.11266148090362549
Validation loss: 1.4133224320668045

Epoch: 6| Step: 4
Training loss: 0.05924030765891075
Validation loss: 1.3948214925745481

Epoch: 6| Step: 5
Training loss: 0.07650725543498993
Validation loss: 1.393332217329292

Epoch: 6| Step: 6
Training loss: 0.11098837852478027
Validation loss: 1.4358832002967916

Epoch: 6| Step: 7
Training loss: 0.09342153370380402
Validation loss: 1.4221721990134126

Epoch: 6| Step: 8
Training loss: 0.25889521837234497
Validation loss: 1.4249186195353025

Epoch: 6| Step: 9
Training loss: 0.11476922035217285
Validation loss: 1.4091996057059175

Epoch: 6| Step: 10
Training loss: 0.1311948299407959
Validation loss: 1.423264180460284

Epoch: 6| Step: 11
Training loss: 0.07533606141805649
Validation loss: 1.3756506250750633

Epoch: 6| Step: 12
Training loss: 0.08571402728557587
Validation loss: 1.3825767437616985

Epoch: 6| Step: 13
Training loss: 0.09348967671394348
Validation loss: 1.3684706611018027

Epoch: 484| Step: 0
Training loss: 0.07699894905090332
Validation loss: 1.3881273244016914

Epoch: 6| Step: 1
Training loss: 0.06606639176607132
Validation loss: 1.375499249786459

Epoch: 6| Step: 2
Training loss: 0.08661875128746033
Validation loss: 1.3823207475805794

Epoch: 6| Step: 3
Training loss: 0.13231804966926575
Validation loss: 1.393238131717969

Epoch: 6| Step: 4
Training loss: 0.1571507453918457
Validation loss: 1.3699961599483286

Epoch: 6| Step: 5
Training loss: 0.1267029345035553
Validation loss: 1.3985376832305745

Epoch: 6| Step: 6
Training loss: 0.07284416258335114
Validation loss: 1.3969671649317588

Epoch: 6| Step: 7
Training loss: 0.0836496353149414
Validation loss: 1.4038824906913183

Epoch: 6| Step: 8
Training loss: 0.06726439297199249
Validation loss: 1.393331592441887

Epoch: 6| Step: 9
Training loss: 0.20927228033542633
Validation loss: 1.3978156389728669

Epoch: 6| Step: 10
Training loss: 0.07941171526908875
Validation loss: 1.4255342201520038

Epoch: 6| Step: 11
Training loss: 0.0935923233628273
Validation loss: 1.4407238742356658

Epoch: 6| Step: 12
Training loss: 0.08246025443077087
Validation loss: 1.4104526145483858

Epoch: 6| Step: 13
Training loss: 0.048820093274116516
Validation loss: 1.4142671451773694

Epoch: 485| Step: 0
Training loss: 0.09627749025821686
Validation loss: 1.3901511174376293

Epoch: 6| Step: 1
Training loss: 0.052945129573345184
Validation loss: 1.4049287162801272

Epoch: 6| Step: 2
Training loss: 0.06858967244625092
Validation loss: 1.4078022049319359

Epoch: 6| Step: 3
Training loss: 0.24889881908893585
Validation loss: 1.4171282911813388

Epoch: 6| Step: 4
Training loss: 0.06978769600391388
Validation loss: 1.4150090332954162

Epoch: 6| Step: 5
Training loss: 0.09371735155582428
Validation loss: 1.4577121298800233

Epoch: 6| Step: 6
Training loss: 0.08180299401283264
Validation loss: 1.4476021297516362

Epoch: 6| Step: 7
Training loss: 0.05230806767940521
Validation loss: 1.4580767616148917

Epoch: 6| Step: 8
Training loss: 0.08713456988334656
Validation loss: 1.4488302648708384

Epoch: 6| Step: 9
Training loss: 0.050680771470069885
Validation loss: 1.4399588268290284

Epoch: 6| Step: 10
Training loss: 0.06053026020526886
Validation loss: 1.443321599755236

Epoch: 6| Step: 11
Training loss: 0.08952616900205612
Validation loss: 1.4383329127424507

Epoch: 6| Step: 12
Training loss: 0.11700676381587982
Validation loss: 1.4491171817625723

Epoch: 6| Step: 13
Training loss: 0.13223522901535034
Validation loss: 1.4682683278155584

Epoch: 486| Step: 0
Training loss: 0.07723747938871384
Validation loss: 1.4435952645476147

Epoch: 6| Step: 1
Training loss: 0.09671196341514587
Validation loss: 1.4339461429144746

Epoch: 6| Step: 2
Training loss: 0.08073797076940536
Validation loss: 1.4411404491752706

Epoch: 6| Step: 3
Training loss: 0.0823461189866066
Validation loss: 1.4368545086153093

Epoch: 6| Step: 4
Training loss: 0.13435351848602295
Validation loss: 1.4299322988397332

Epoch: 6| Step: 5
Training loss: 0.08001812547445297
Validation loss: 1.3990473747253418

Epoch: 6| Step: 6
Training loss: 0.060825105756521225
Validation loss: 1.4079883611330422

Epoch: 6| Step: 7
Training loss: 0.08254114538431168
Validation loss: 1.4000812717663345

Epoch: 6| Step: 8
Training loss: 0.05947183072566986
Validation loss: 1.3847699754981584

Epoch: 6| Step: 9
Training loss: 0.12207935005426407
Validation loss: 1.3880161380255094

Epoch: 6| Step: 10
Training loss: 0.24353700876235962
Validation loss: 1.4113186841369958

Epoch: 6| Step: 11
Training loss: 0.08166749030351639
Validation loss: 1.4082285973333544

Epoch: 6| Step: 12
Training loss: 0.10267335176467896
Validation loss: 1.3877733625391477

Epoch: 6| Step: 13
Training loss: 0.09765369445085526
Validation loss: 1.4090172347202097

Epoch: 487| Step: 0
Training loss: 0.10814744234085083
Validation loss: 1.4021393111957017

Epoch: 6| Step: 1
Training loss: 0.07753588259220123
Validation loss: 1.4010314492769138

Epoch: 6| Step: 2
Training loss: 0.10908128321170807
Validation loss: 1.3778859998590203

Epoch: 6| Step: 3
Training loss: 0.11736753582954407
Validation loss: 1.395579106064253

Epoch: 6| Step: 4
Training loss: 0.10563167929649353
Validation loss: 1.4044796266863424

Epoch: 6| Step: 5
Training loss: 0.08688868582248688
Validation loss: 1.4110525449117024

Epoch: 6| Step: 6
Training loss: 0.09472902864217758
Validation loss: 1.3881953377877512

Epoch: 6| Step: 7
Training loss: 0.09489626437425613
Validation loss: 1.4255022438623572

Epoch: 6| Step: 8
Training loss: 0.23677486181259155
Validation loss: 1.392412712497096

Epoch: 6| Step: 9
Training loss: 0.08590304106473923
Validation loss: 1.4068610257999872

Epoch: 6| Step: 10
Training loss: 0.09807811677455902
Validation loss: 1.3812252321550924

Epoch: 6| Step: 11
Training loss: 0.0811900869011879
Validation loss: 1.3990949148772864

Epoch: 6| Step: 12
Training loss: 0.061636969447135925
Validation loss: 1.4260658576924314

Epoch: 6| Step: 13
Training loss: 0.04952896013855934
Validation loss: 1.391573744435464

Epoch: 488| Step: 0
Training loss: 0.07568009197711945
Validation loss: 1.4281333851557907

Epoch: 6| Step: 1
Training loss: 0.08113372325897217
Validation loss: 1.4121806313914638

Epoch: 6| Step: 2
Training loss: 0.06559183448553085
Validation loss: 1.4060131542144283

Epoch: 6| Step: 3
Training loss: 0.06503033638000488
Validation loss: 1.41552512491903

Epoch: 6| Step: 4
Training loss: 0.06640654802322388
Validation loss: 1.3970530276657434

Epoch: 6| Step: 5
Training loss: 0.09337049722671509
Validation loss: 1.399557331556915

Epoch: 6| Step: 6
Training loss: 0.22838863730430603
Validation loss: 1.3928307820391912

Epoch: 6| Step: 7
Training loss: 0.08012261986732483
Validation loss: 1.3992711613255162

Epoch: 6| Step: 8
Training loss: 0.09753350913524628
Validation loss: 1.4289693358123943

Epoch: 6| Step: 9
Training loss: 0.06675732135772705
Validation loss: 1.4149498439604236

Epoch: 6| Step: 10
Training loss: 0.054473333060741425
Validation loss: 1.4055662501242854

Epoch: 6| Step: 11
Training loss: 0.05743399262428284
Validation loss: 1.3806262247024044

Epoch: 6| Step: 12
Training loss: 0.10515255481004715
Validation loss: 1.4043703399678713

Epoch: 6| Step: 13
Training loss: 0.0426400825381279
Validation loss: 1.4283850372478526

Epoch: 489| Step: 0
Training loss: 0.04868875443935394
Validation loss: 1.4116754044768631

Epoch: 6| Step: 1
Training loss: 0.0787096619606018
Validation loss: 1.4445856745525072

Epoch: 6| Step: 2
Training loss: 0.08278929442167282
Validation loss: 1.4528364302009664

Epoch: 6| Step: 3
Training loss: 0.09704689681529999
Validation loss: 1.4645290310664842

Epoch: 6| Step: 4
Training loss: 0.20451337099075317
Validation loss: 1.4437188153625817

Epoch: 6| Step: 5
Training loss: 0.05600736290216446
Validation loss: 1.4737226565678914

Epoch: 6| Step: 6
Training loss: 0.12003672122955322
Validation loss: 1.4447058939164685

Epoch: 6| Step: 7
Training loss: 0.1323583424091339
Validation loss: 1.458147677042151

Epoch: 6| Step: 8
Training loss: 0.10986535996198654
Validation loss: 1.4514666449639104

Epoch: 6| Step: 9
Training loss: 0.07106921821832657
Validation loss: 1.4714119280538251

Epoch: 6| Step: 10
Training loss: 0.11011584848165512
Validation loss: 1.44776818701016

Epoch: 6| Step: 11
Training loss: 0.10880780220031738
Validation loss: 1.4579045618734052

Epoch: 6| Step: 12
Training loss: 0.09586568176746368
Validation loss: 1.4454233979666105

Epoch: 6| Step: 13
Training loss: 0.08267819136381149
Validation loss: 1.4397869353653283

Epoch: 490| Step: 0
Training loss: 0.0673704519867897
Validation loss: 1.3970876316870413

Epoch: 6| Step: 1
Training loss: 0.24336659908294678
Validation loss: 1.381873466635263

Epoch: 6| Step: 2
Training loss: 0.09914396703243256
Validation loss: 1.3845322670475129

Epoch: 6| Step: 3
Training loss: 0.10331737995147705
Validation loss: 1.3724689111914685

Epoch: 6| Step: 4
Training loss: 0.049952782690525055
Validation loss: 1.3562831744070976

Epoch: 6| Step: 5
Training loss: 0.0767173320055008
Validation loss: 1.3837204620402346

Epoch: 6| Step: 6
Training loss: 0.12306851893663406
Validation loss: 1.3574563316119614

Epoch: 6| Step: 7
Training loss: 0.10164559632539749
Validation loss: 1.3760457269607052

Epoch: 6| Step: 8
Training loss: 0.09976896643638611
Validation loss: 1.377258586627181

Epoch: 6| Step: 9
Training loss: 0.12154564261436462
Validation loss: 1.3883207856967885

Epoch: 6| Step: 10
Training loss: 0.10607103258371353
Validation loss: 1.3991472387826571

Epoch: 6| Step: 11
Training loss: 0.0681920126080513
Validation loss: 1.4134010640523766

Epoch: 6| Step: 12
Training loss: 0.06204550713300705
Validation loss: 1.3996474460888935

Epoch: 6| Step: 13
Training loss: 0.05944359302520752
Validation loss: 1.4146056931505921

Epoch: 491| Step: 0
Training loss: 0.08804769814014435
Validation loss: 1.4206698594554779

Epoch: 6| Step: 1
Training loss: 0.08382102847099304
Validation loss: 1.3915524021271737

Epoch: 6| Step: 2
Training loss: 0.08238354325294495
Validation loss: 1.400624297639375

Epoch: 6| Step: 3
Training loss: 0.1238197386264801
Validation loss: 1.378500812797136

Epoch: 6| Step: 4
Training loss: 0.08040015399456024
Validation loss: 1.3692918439065256

Epoch: 6| Step: 5
Training loss: 0.06716495752334595
Validation loss: 1.3898210698558437

Epoch: 6| Step: 6
Training loss: 0.24524351954460144
Validation loss: 1.4021533689191263

Epoch: 6| Step: 7
Training loss: 0.09177424013614655
Validation loss: 1.4219072659810383

Epoch: 6| Step: 8
Training loss: 0.061847418546676636
Validation loss: 1.406812483905464

Epoch: 6| Step: 9
Training loss: 0.06363265961408615
Validation loss: 1.3814592528086838

Epoch: 6| Step: 10
Training loss: 0.06067824363708496
Validation loss: 1.4173043850929505

Epoch: 6| Step: 11
Training loss: 0.08603569865226746
Validation loss: 1.4261113712864537

Epoch: 6| Step: 12
Training loss: 0.07388844341039658
Validation loss: 1.431688698389197

Epoch: 6| Step: 13
Training loss: 0.09103449434041977
Validation loss: 1.4073997377067484

Epoch: 492| Step: 0
Training loss: 0.06357377022504807
Validation loss: 1.3975435033921273

Epoch: 6| Step: 1
Training loss: 0.0787612572312355
Validation loss: 1.4021061799859489

Epoch: 6| Step: 2
Training loss: 0.06692064553499222
Validation loss: 1.4197168991129885

Epoch: 6| Step: 3
Training loss: 0.05895155668258667
Validation loss: 1.4408490888534053

Epoch: 6| Step: 4
Training loss: 0.21145278215408325
Validation loss: 1.4228029866372385

Epoch: 6| Step: 5
Training loss: 0.09424877166748047
Validation loss: 1.4404811820676249

Epoch: 6| Step: 6
Training loss: 0.08008749037981033
Validation loss: 1.4604331037049652

Epoch: 6| Step: 7
Training loss: 0.06365792453289032
Validation loss: 1.4266973708265571

Epoch: 6| Step: 8
Training loss: 0.06263324618339539
Validation loss: 1.4414006176815237

Epoch: 6| Step: 9
Training loss: 0.08124101161956787
Validation loss: 1.4447484195873301

Epoch: 6| Step: 10
Training loss: 0.05485673248767853
Validation loss: 1.4238411431671472

Epoch: 6| Step: 11
Training loss: 0.10040891170501709
Validation loss: 1.4445913299437492

Epoch: 6| Step: 12
Training loss: 0.09897643327713013
Validation loss: 1.4127244712204061

Epoch: 6| Step: 13
Training loss: 0.10847190022468567
Validation loss: 1.4490569586394935

Epoch: 493| Step: 0
Training loss: 0.02705630660057068
Validation loss: 1.4208272349449895

Epoch: 6| Step: 1
Training loss: 0.07023265957832336
Validation loss: 1.3958486997953026

Epoch: 6| Step: 2
Training loss: 0.04198477044701576
Validation loss: 1.4362508263639224

Epoch: 6| Step: 3
Training loss: 0.0680304691195488
Validation loss: 1.3930415504722184

Epoch: 6| Step: 4
Training loss: 0.09895320236682892
Validation loss: 1.4169908851705573

Epoch: 6| Step: 5
Training loss: 0.10190307348966599
Validation loss: 1.4029742376778715

Epoch: 6| Step: 6
Training loss: 0.0923650935292244
Validation loss: 1.417142419404881

Epoch: 6| Step: 7
Training loss: 0.05237520486116409
Validation loss: 1.3974603837536228

Epoch: 6| Step: 8
Training loss: 0.21825511753559113
Validation loss: 1.4204263866588633

Epoch: 6| Step: 9
Training loss: 0.13797219097614288
Validation loss: 1.4188687121996315

Epoch: 6| Step: 10
Training loss: 0.07791636884212494
Validation loss: 1.3877168816904868

Epoch: 6| Step: 11
Training loss: 0.07106044888496399
Validation loss: 1.3725634813308716

Epoch: 6| Step: 12
Training loss: 0.08587378263473511
Validation loss: 1.3691875319327078

Epoch: 6| Step: 13
Training loss: 0.12260481715202332
Validation loss: 1.4086316657322708

Epoch: 494| Step: 0
Training loss: 0.1240803599357605
Validation loss: 1.4080431371606805

Epoch: 6| Step: 1
Training loss: 0.0648977980017662
Validation loss: 1.392140180833878

Epoch: 6| Step: 2
Training loss: 0.0658564567565918
Validation loss: 1.4214565471936298

Epoch: 6| Step: 3
Training loss: 0.049891289323568344
Validation loss: 1.4356019176462644

Epoch: 6| Step: 4
Training loss: 0.08612895011901855
Validation loss: 1.45794589032409

Epoch: 6| Step: 5
Training loss: 0.09205535054206848
Validation loss: 1.438990878802474

Epoch: 6| Step: 6
Training loss: 0.1061304435133934
Validation loss: 1.4093731026495657

Epoch: 6| Step: 7
Training loss: 0.057038091123104095
Validation loss: 1.4175608658021497

Epoch: 6| Step: 8
Training loss: 0.09423715621232986
Validation loss: 1.4180722544270177

Epoch: 6| Step: 9
Training loss: 0.21980033814907074
Validation loss: 1.3876584960568337

Epoch: 6| Step: 10
Training loss: 0.07373719662427902
Validation loss: 1.4026003947821997

Epoch: 6| Step: 11
Training loss: 0.059612423181533813
Validation loss: 1.3890362644708285

Epoch: 6| Step: 12
Training loss: 0.06633786112070084
Validation loss: 1.3929000875001312

Epoch: 6| Step: 13
Training loss: 0.07594111561775208
Validation loss: 1.4067831077883322

Epoch: 495| Step: 0
Training loss: 0.09685620665550232
Validation loss: 1.3928507989452732

Epoch: 6| Step: 1
Training loss: 0.09912246465682983
Validation loss: 1.3836646310744747

Epoch: 6| Step: 2
Training loss: 0.05378950759768486
Validation loss: 1.3978744411981234

Epoch: 6| Step: 3
Training loss: 0.0768560841679573
Validation loss: 1.4112376314337536

Epoch: 6| Step: 4
Training loss: 0.12381050735712051
Validation loss: 1.4168754149508733

Epoch: 6| Step: 5
Training loss: 0.0722300186753273
Validation loss: 1.4237587054570515

Epoch: 6| Step: 6
Training loss: 0.059404581785202026
Validation loss: 1.39850668368801

Epoch: 6| Step: 7
Training loss: 0.05407562851905823
Validation loss: 1.4123163402721446

Epoch: 6| Step: 8
Training loss: 0.05694189667701721
Validation loss: 1.404832519510741

Epoch: 6| Step: 9
Training loss: 0.07648956030607224
Validation loss: 1.4161747911924958

Epoch: 6| Step: 10
Training loss: 0.08004647493362427
Validation loss: 1.408924195074266

Epoch: 6| Step: 11
Training loss: 0.23585209250450134
Validation loss: 1.428458659879623

Epoch: 6| Step: 12
Training loss: 0.07049025595188141
Validation loss: 1.4241701524744752

Epoch: 6| Step: 13
Training loss: 0.06462976336479187
Validation loss: 1.452531099319458

Epoch: 496| Step: 0
Training loss: 0.09218058735132217
Validation loss: 1.4009171519228207

Epoch: 6| Step: 1
Training loss: 0.039590731263160706
Validation loss: 1.4303433632337919

Epoch: 6| Step: 2
Training loss: 0.0396992564201355
Validation loss: 1.4240621289899271

Epoch: 6| Step: 3
Training loss: 0.1059870570898056
Validation loss: 1.42720381675228

Epoch: 6| Step: 4
Training loss: 0.09831950813531876
Validation loss: 1.416134415134307

Epoch: 6| Step: 5
Training loss: 0.06292083859443665
Validation loss: 1.441001009556555

Epoch: 6| Step: 6
Training loss: 0.08982841670513153
Validation loss: 1.4154705418053495

Epoch: 6| Step: 7
Training loss: 0.07946044206619263
Validation loss: 1.4185182343247116

Epoch: 6| Step: 8
Training loss: 0.11046726256608963
Validation loss: 1.437710795351254

Epoch: 6| Step: 9
Training loss: 0.21456854045391083
Validation loss: 1.4319908529199579

Epoch: 6| Step: 10
Training loss: 0.041859693825244904
Validation loss: 1.4023138669229323

Epoch: 6| Step: 11
Training loss: 0.058277882635593414
Validation loss: 1.4191461788710726

Epoch: 6| Step: 12
Training loss: 0.08720764517784119
Validation loss: 1.3981550291020384

Epoch: 6| Step: 13
Training loss: 0.04638456553220749
Validation loss: 1.4157572292512464

Epoch: 497| Step: 0
Training loss: 0.05197807028889656
Validation loss: 1.418770000498782

Epoch: 6| Step: 1
Training loss: 0.08710560947656631
Validation loss: 1.4288527657908778

Epoch: 6| Step: 2
Training loss: 0.05198242515325546
Validation loss: 1.4325905333283127

Epoch: 6| Step: 3
Training loss: 0.07776163518428802
Validation loss: 1.4255511863257295

Epoch: 6| Step: 4
Training loss: 0.08770740777254105
Validation loss: 1.4059180572468748

Epoch: 6| Step: 5
Training loss: 0.056314367800951004
Validation loss: 1.4456204765586442

Epoch: 6| Step: 6
Training loss: 0.2746012806892395
Validation loss: 1.4419492444684427

Epoch: 6| Step: 7
Training loss: 0.06377752870321274
Validation loss: 1.4625973880931895

Epoch: 6| Step: 8
Training loss: 0.09381719678640366
Validation loss: 1.4445001002280944

Epoch: 6| Step: 9
Training loss: 0.040679559111595154
Validation loss: 1.4419486343219716

Epoch: 6| Step: 10
Training loss: 0.06790906935930252
Validation loss: 1.4416909083243339

Epoch: 6| Step: 11
Training loss: 0.0464477613568306
Validation loss: 1.4282905760631766

Epoch: 6| Step: 12
Training loss: 0.11061415076255798
Validation loss: 1.4069863442451722

Epoch: 6| Step: 13
Training loss: 0.07308091223239899
Validation loss: 1.4343633190278084

Epoch: 498| Step: 0
Training loss: 0.07105915248394012
Validation loss: 1.4354774093115201

Epoch: 6| Step: 1
Training loss: 0.06121806800365448
Validation loss: 1.4327156069458171

Epoch: 6| Step: 2
Training loss: 0.06873861700296402
Validation loss: 1.4278965867975706

Epoch: 6| Step: 3
Training loss: 0.071420818567276
Validation loss: 1.4285989672906938

Epoch: 6| Step: 4
Training loss: 0.054517678916454315
Validation loss: 1.4077837992739934

Epoch: 6| Step: 5
Training loss: 0.22282198071479797
Validation loss: 1.4253536180783344

Epoch: 6| Step: 6
Training loss: 0.08636029809713364
Validation loss: 1.4017816987088931

Epoch: 6| Step: 7
Training loss: 0.057086870074272156
Validation loss: 1.4092361478395359

Epoch: 6| Step: 8
Training loss: 0.10696117579936981
Validation loss: 1.426155036495578

Epoch: 6| Step: 9
Training loss: 0.0588311031460762
Validation loss: 1.4000705647212204

Epoch: 6| Step: 10
Training loss: 0.05916327238082886
Validation loss: 1.383541750651534

Epoch: 6| Step: 11
Training loss: 0.07945707440376282
Validation loss: 1.3730475518011278

Epoch: 6| Step: 12
Training loss: 0.05550694465637207
Validation loss: 1.3859356462314565

Epoch: 6| Step: 13
Training loss: 0.052066802978515625
Validation loss: 1.394645224335373

Epoch: 499| Step: 0
Training loss: 0.08652293682098389
Validation loss: 1.407268149878389

Epoch: 6| Step: 1
Training loss: 0.0618492066860199
Validation loss: 1.3927788939527286

Epoch: 6| Step: 2
Training loss: 0.13004964590072632
Validation loss: 1.3959676732299149

Epoch: 6| Step: 3
Training loss: 0.04438026249408722
Validation loss: 1.3882031318961934

Epoch: 6| Step: 4
Training loss: 0.08074015378952026
Validation loss: 1.391478753858997

Epoch: 6| Step: 5
Training loss: 0.22835925221443176
Validation loss: 1.37564637584071

Epoch: 6| Step: 6
Training loss: 0.0629223883152008
Validation loss: 1.4093999067942302

Epoch: 6| Step: 7
Training loss: 0.07680226862430573
Validation loss: 1.38240691666962

Epoch: 6| Step: 8
Training loss: 0.08185017108917236
Validation loss: 1.3717206242263957

Epoch: 6| Step: 9
Training loss: 0.07772329449653625
Validation loss: 1.387768909495364

Epoch: 6| Step: 10
Training loss: 0.07344058901071548
Validation loss: 1.3753199186376346

Epoch: 6| Step: 11
Training loss: 0.10204765200614929
Validation loss: 1.3730310214463102

Epoch: 6| Step: 12
Training loss: 0.10442912578582764
Validation loss: 1.3860961814080515

Epoch: 6| Step: 13
Training loss: 0.08198688179254532
Validation loss: 1.390739256335843

Epoch: 500| Step: 0
Training loss: 0.09022770822048187
Validation loss: 1.4172933242654289

Epoch: 6| Step: 1
Training loss: 0.06322336196899414
Validation loss: 1.404522495244139

Epoch: 6| Step: 2
Training loss: 0.0635145902633667
Validation loss: 1.4258285978788972

Epoch: 6| Step: 3
Training loss: 0.07753327488899231
Validation loss: 1.4203293464517082

Epoch: 6| Step: 4
Training loss: 0.08399656414985657
Validation loss: 1.4501297364952743

Epoch: 6| Step: 5
Training loss: 0.055940255522727966
Validation loss: 1.4337775489335418

Epoch: 6| Step: 6
Training loss: 0.0991617888212204
Validation loss: 1.4455027605897637

Epoch: 6| Step: 7
Training loss: 0.08541324734687805
Validation loss: 1.451205390114938

Epoch: 6| Step: 8
Training loss: 0.11633539199829102
Validation loss: 1.4533401958404049

Epoch: 6| Step: 9
Training loss: 0.09395696222782135
Validation loss: 1.4542618079852032

Epoch: 6| Step: 10
Training loss: 0.23210984468460083
Validation loss: 1.467211966873497

Epoch: 6| Step: 11
Training loss: 0.07702986150979996
Validation loss: 1.4599373571334346

Epoch: 6| Step: 12
Training loss: 0.06401270627975464
Validation loss: 1.4361295212981522

Epoch: 6| Step: 13
Training loss: 0.07299330830574036
Validation loss: 1.4330573645971154

Epoch: 501| Step: 0
Training loss: 0.046659454703330994
Validation loss: 1.4113973289407709

Epoch: 6| Step: 1
Training loss: 0.10487255454063416
Validation loss: 1.3936795880717616

Epoch: 6| Step: 2
Training loss: 0.06407523155212402
Validation loss: 1.4281772490470641

Epoch: 6| Step: 3
Training loss: 0.07268045097589493
Validation loss: 1.3973359369462537

Epoch: 6| Step: 4
Training loss: 0.1830463707447052
Validation loss: 1.4004779156818186

Epoch: 6| Step: 5
Training loss: 0.04658966511487961
Validation loss: 1.4255320538756668

Epoch: 6| Step: 6
Training loss: 0.08126315474510193
Validation loss: 1.3917695309526177

Epoch: 6| Step: 7
Training loss: 0.055156007409095764
Validation loss: 1.3951247046070714

Epoch: 6| Step: 8
Training loss: 0.09519487619400024
Validation loss: 1.39444532509773

Epoch: 6| Step: 9
Training loss: 0.04291677474975586
Validation loss: 1.388706172666242

Epoch: 6| Step: 10
Training loss: 0.034938160330057144
Validation loss: 1.3877878547996603

Epoch: 6| Step: 11
Training loss: 0.08199974149465561
Validation loss: 1.3954110472433028

Epoch: 6| Step: 12
Training loss: 0.07641077041625977
Validation loss: 1.3835168243736349

Epoch: 6| Step: 13
Training loss: 0.1271432340145111
Validation loss: 1.3999661117471673

Epoch: 502| Step: 0
Training loss: 0.058913327753543854
Validation loss: 1.3881207512271019

Epoch: 6| Step: 1
Training loss: 0.058878302574157715
Validation loss: 1.3932174803108297

Epoch: 6| Step: 2
Training loss: 0.06076623126864433
Validation loss: 1.3926664308835102

Epoch: 6| Step: 3
Training loss: 0.1134997010231018
Validation loss: 1.3933110480667443

Epoch: 6| Step: 4
Training loss: 0.08920028805732727
Validation loss: 1.3963008670396702

Epoch: 6| Step: 5
Training loss: 0.21091531217098236
Validation loss: 1.4189075346915954

Epoch: 6| Step: 6
Training loss: 0.06950999051332474
Validation loss: 1.4225097760077445

Epoch: 6| Step: 7
Training loss: 0.06362734735012054
Validation loss: 1.438576312475307

Epoch: 6| Step: 8
Training loss: 0.06609305739402771
Validation loss: 1.4203445462770359

Epoch: 6| Step: 9
Training loss: 0.1113712340593338
Validation loss: 1.436263169011762

Epoch: 6| Step: 10
Training loss: 0.08658169209957123
Validation loss: 1.43676632706837

Epoch: 6| Step: 11
Training loss: 0.0788150206208229
Validation loss: 1.4322095865844398

Epoch: 6| Step: 12
Training loss: 0.08099284768104553
Validation loss: 1.460323590104298

Epoch: 6| Step: 13
Training loss: 0.07609168440103531
Validation loss: 1.4183340239268478

Epoch: 503| Step: 0
Training loss: 0.10527153313159943
Validation loss: 1.4390736818313599

Epoch: 6| Step: 1
Training loss: 0.08602091670036316
Validation loss: 1.4240478764298141

Epoch: 6| Step: 2
Training loss: 0.09711812436580658
Validation loss: 1.3992991319266699

Epoch: 6| Step: 3
Training loss: 0.05684512108564377
Validation loss: 1.402042027442686

Epoch: 6| Step: 4
Training loss: 0.2095094621181488
Validation loss: 1.426674949225559

Epoch: 6| Step: 5
Training loss: 0.08755974471569061
Validation loss: 1.4054627803064161

Epoch: 6| Step: 6
Training loss: 0.08050814270973206
Validation loss: 1.393835836841214

Epoch: 6| Step: 7
Training loss: 0.08765062689781189
Validation loss: 1.4139909026443318

Epoch: 6| Step: 8
Training loss: 0.06583087891340256
Validation loss: 1.4238556110730736

Epoch: 6| Step: 9
Training loss: 0.09239396452903748
Validation loss: 1.4061968614978175

Epoch: 6| Step: 10
Training loss: 0.0575651079416275
Validation loss: 1.4228304586102885

Epoch: 6| Step: 11
Training loss: 0.06695491820573807
Validation loss: 1.4209465147346578

Epoch: 6| Step: 12
Training loss: 0.07964084297418594
Validation loss: 1.4449388365591727

Epoch: 6| Step: 13
Training loss: 0.06922076642513275
Validation loss: 1.4236141776525846

Epoch: 504| Step: 0
Training loss: 0.0740623027086258
Validation loss: 1.4667376702831638

Epoch: 6| Step: 1
Training loss: 0.1040322482585907
Validation loss: 1.478416665907829

Epoch: 6| Step: 2
Training loss: 0.08355240523815155
Validation loss: 1.4250978846703806

Epoch: 6| Step: 3
Training loss: 0.07746760547161102
Validation loss: 1.4545068958754181

Epoch: 6| Step: 4
Training loss: 0.06915752589702606
Validation loss: 1.4369563659032185

Epoch: 6| Step: 5
Training loss: 0.07454336434602737
Validation loss: 1.430628648368261

Epoch: 6| Step: 6
Training loss: 0.09190249443054199
Validation loss: 1.4263584831709504

Epoch: 6| Step: 7
Training loss: 0.2387133240699768
Validation loss: 1.410469344867173

Epoch: 6| Step: 8
Training loss: 0.09312821179628372
Validation loss: 1.3926626418226509

Epoch: 6| Step: 9
Training loss: 0.13271740078926086
Validation loss: 1.3936268232202018

Epoch: 6| Step: 10
Training loss: 0.10697408765554428
Validation loss: 1.3939262308100218

Epoch: 6| Step: 11
Training loss: 0.0891280397772789
Validation loss: 1.3877395327373216

Epoch: 6| Step: 12
Training loss: 0.10822909325361252
Validation loss: 1.3823517804504724

Epoch: 6| Step: 13
Training loss: 0.10947278887033463
Validation loss: 1.3810239350923927

Epoch: 505| Step: 0
Training loss: 0.05758048593997955
Validation loss: 1.401433434537662

Epoch: 6| Step: 1
Training loss: 0.10433725267648697
Validation loss: 1.3624847858182845

Epoch: 6| Step: 2
Training loss: 0.05366349592804909
Validation loss: 1.3645083250537995

Epoch: 6| Step: 3
Training loss: 0.05665190517902374
Validation loss: 1.3727760148304764

Epoch: 6| Step: 4
Training loss: 0.08264730870723724
Validation loss: 1.3822007948352444

Epoch: 6| Step: 5
Training loss: 0.23626065254211426
Validation loss: 1.3799149490171863

Epoch: 6| Step: 6
Training loss: 0.11876659095287323
Validation loss: 1.400195087155988

Epoch: 6| Step: 7
Training loss: 0.08182822167873383
Validation loss: 1.4086786841833463

Epoch: 6| Step: 8
Training loss: 0.08773617446422577
Validation loss: 1.395544719311499

Epoch: 6| Step: 9
Training loss: 0.06225108727812767
Validation loss: 1.400947214454733

Epoch: 6| Step: 10
Training loss: 0.08827221393585205
Validation loss: 1.4304615887262488

Epoch: 6| Step: 11
Training loss: 0.06593462079763412
Validation loss: 1.4146538319126252

Epoch: 6| Step: 12
Training loss: 0.09794767200946808
Validation loss: 1.42810651563829

Epoch: 6| Step: 13
Training loss: 0.10323265194892883
Validation loss: 1.4194625077709075

Epoch: 506| Step: 0
Training loss: 0.200124129652977
Validation loss: 1.4114681841224752

Epoch: 6| Step: 1
Training loss: 0.09550979733467102
Validation loss: 1.4122595050001656

Epoch: 6| Step: 2
Training loss: 0.06273333728313446
Validation loss: 1.3803954996088499

Epoch: 6| Step: 3
Training loss: 0.07698230445384979
Validation loss: 1.4036243961703392

Epoch: 6| Step: 4
Training loss: 0.06517450511455536
Validation loss: 1.4009932459041636

Epoch: 6| Step: 5
Training loss: 0.0956302359700203
Validation loss: 1.398479397578906

Epoch: 6| Step: 6
Training loss: 0.06316523998975754
Validation loss: 1.387753411005902

Epoch: 6| Step: 7
Training loss: 0.11493060737848282
Validation loss: 1.4425134761359102

Epoch: 6| Step: 8
Training loss: 0.08584421873092651
Validation loss: 1.420162921310753

Epoch: 6| Step: 9
Training loss: 0.07040400058031082
Validation loss: 1.3825764258702595

Epoch: 6| Step: 10
Training loss: 0.06514166295528412
Validation loss: 1.3726992222570604

Epoch: 6| Step: 11
Training loss: 0.07366977632045746
Validation loss: 1.3726458895590998

Epoch: 6| Step: 12
Training loss: 0.08294018357992172
Validation loss: 1.3916669199543614

Epoch: 6| Step: 13
Training loss: 0.12119264155626297
Validation loss: 1.3752142960025417

Epoch: 507| Step: 0
Training loss: 0.06910780072212219
Validation loss: 1.3838799486878097

Epoch: 6| Step: 1
Training loss: 0.060796886682510376
Validation loss: 1.4177653161428307

Epoch: 6| Step: 2
Training loss: 0.06437590718269348
Validation loss: 1.3720427873314067

Epoch: 6| Step: 3
Training loss: 0.05294764041900635
Validation loss: 1.3725892138737503

Epoch: 6| Step: 4
Training loss: 0.07089705765247345
Validation loss: 1.407461158690914

Epoch: 6| Step: 5
Training loss: 0.07007476687431335
Validation loss: 1.3976601298137377

Epoch: 6| Step: 6
Training loss: 0.0485772080719471
Validation loss: 1.3871329471629152

Epoch: 6| Step: 7
Training loss: 0.08529161661863327
Validation loss: 1.4241493780125853

Epoch: 6| Step: 8
Training loss: 0.22664491832256317
Validation loss: 1.3964280902698476

Epoch: 6| Step: 9
Training loss: 0.06829197704792023
Validation loss: 1.422049581363637

Epoch: 6| Step: 10
Training loss: 0.08659754693508148
Validation loss: 1.4191673212153937

Epoch: 6| Step: 11
Training loss: 0.0749548077583313
Validation loss: 1.4368320844506706

Epoch: 6| Step: 12
Training loss: 0.09242380410432816
Validation loss: 1.4178411460691882

Epoch: 6| Step: 13
Training loss: 0.03926842287182808
Validation loss: 1.42964941840018

Epoch: 508| Step: 0
Training loss: 0.057482004165649414
Validation loss: 1.4311037973691059

Epoch: 6| Step: 1
Training loss: 0.09684338420629501
Validation loss: 1.4499762135167276

Epoch: 6| Step: 2
Training loss: 0.09559813141822815
Validation loss: 1.448451042175293

Epoch: 6| Step: 3
Training loss: 0.06462155282497406
Validation loss: 1.4172975965725478

Epoch: 6| Step: 4
Training loss: 0.0606129914522171
Validation loss: 1.4530033629427674

Epoch: 6| Step: 5
Training loss: 0.0471186637878418
Validation loss: 1.4558332126627687

Epoch: 6| Step: 6
Training loss: 0.06194544583559036
Validation loss: 1.427910861148629

Epoch: 6| Step: 7
Training loss: 0.08196677267551422
Validation loss: 1.4568068673533778

Epoch: 6| Step: 8
Training loss: 0.06115227937698364
Validation loss: 1.4377533453767017

Epoch: 6| Step: 9
Training loss: 0.10059648752212524
Validation loss: 1.4272721159842707

Epoch: 6| Step: 10
Training loss: 0.08634721487760544
Validation loss: 1.433662514532766

Epoch: 6| Step: 11
Training loss: 0.20823246240615845
Validation loss: 1.4298902403923772

Epoch: 6| Step: 12
Training loss: 0.06707703322172165
Validation loss: 1.440487680896636

Epoch: 6| Step: 13
Training loss: 0.15767168998718262
Validation loss: 1.4243226448694866

Epoch: 509| Step: 0
Training loss: 0.0925973504781723
Validation loss: 1.4466110179501195

Epoch: 6| Step: 1
Training loss: 0.10297161340713501
Validation loss: 1.414868051005948

Epoch: 6| Step: 2
Training loss: 0.06508055329322815
Validation loss: 1.4287962118784587

Epoch: 6| Step: 3
Training loss: 0.09146858751773834
Validation loss: 1.433547176340575

Epoch: 6| Step: 4
Training loss: 0.07702934741973877
Validation loss: 1.4609769794248766

Epoch: 6| Step: 5
Training loss: 0.19979046285152435
Validation loss: 1.4356683146569036

Epoch: 6| Step: 6
Training loss: 0.1499292105436325
Validation loss: 1.4527202498528264

Epoch: 6| Step: 7
Training loss: 0.08353983610868454
Validation loss: 1.4442772685840566

Epoch: 6| Step: 8
Training loss: 0.05807308480143547
Validation loss: 1.4556325340783725

Epoch: 6| Step: 9
Training loss: 0.054914578795433044
Validation loss: 1.4648670406751736

Epoch: 6| Step: 10
Training loss: 0.07437492161989212
Validation loss: 1.478110582597794

Epoch: 6| Step: 11
Training loss: 0.06991459429264069
Validation loss: 1.50527984352522

Epoch: 6| Step: 12
Training loss: 0.061188772320747375
Validation loss: 1.4790973881239533

Epoch: 6| Step: 13
Training loss: 0.09960530698299408
Validation loss: 1.514972750858594

Epoch: 510| Step: 0
Training loss: 0.31915175914764404
Validation loss: 1.4636202384066839

Epoch: 6| Step: 1
Training loss: 0.04943946376442909
Validation loss: 1.4553342032176193

Epoch: 6| Step: 2
Training loss: 0.09348806738853455
Validation loss: 1.441029610813305

Epoch: 6| Step: 3
Training loss: 0.0703745037317276
Validation loss: 1.4074440040896017

Epoch: 6| Step: 4
Training loss: 0.0619855672121048
Validation loss: 1.4088373773841447

Epoch: 6| Step: 5
Training loss: 0.10528659075498581
Validation loss: 1.3904974127328524

Epoch: 6| Step: 6
Training loss: 0.15130764245986938
Validation loss: 1.3867601867645019

Epoch: 6| Step: 7
Training loss: 0.13992929458618164
Validation loss: 1.3610643930332635

Epoch: 6| Step: 8
Training loss: 0.12494084984064102
Validation loss: 1.3754571458344818

Epoch: 6| Step: 9
Training loss: 0.06521210074424744
Validation loss: 1.3619877061536234

Epoch: 6| Step: 10
Training loss: 0.07419688999652863
Validation loss: 1.3639475953194402

Epoch: 6| Step: 11
Training loss: 0.052834976464509964
Validation loss: 1.3706865015850271

Epoch: 6| Step: 12
Training loss: 0.05791914835572243
Validation loss: 1.387217539612965

Epoch: 6| Step: 13
Training loss: 0.07995729893445969
Validation loss: 1.4033362705220458

Epoch: 511| Step: 0
Training loss: 0.09557660669088364
Validation loss: 1.4011809466987528

Epoch: 6| Step: 1
Training loss: 0.05513677000999451
Validation loss: 1.3924170822225592

Epoch: 6| Step: 2
Training loss: 0.04521278291940689
Validation loss: 1.402539760835709

Epoch: 6| Step: 3
Training loss: 0.049946971237659454
Validation loss: 1.3965527062774987

Epoch: 6| Step: 4
Training loss: 0.07361001521348953
Validation loss: 1.4162086312488844

Epoch: 6| Step: 5
Training loss: 0.06045607104897499
Validation loss: 1.3946795925017326

Epoch: 6| Step: 6
Training loss: 0.06538723409175873
Validation loss: 1.4061223050599456

Epoch: 6| Step: 7
Training loss: 0.09350313246250153
Validation loss: 1.4277378743694675

Epoch: 6| Step: 8
Training loss: 0.25139376521110535
Validation loss: 1.4258970733611815

Epoch: 6| Step: 9
Training loss: 0.061420049518346786
Validation loss: 1.3862710691267444

Epoch: 6| Step: 10
Training loss: 0.08133401721715927
Validation loss: 1.4223565542569725

Epoch: 6| Step: 11
Training loss: 0.07524088025093079
Validation loss: 1.4232037939051145

Epoch: 6| Step: 12
Training loss: 0.11651011556386948
Validation loss: 1.4523389467629053

Epoch: 6| Step: 13
Training loss: 0.12078913301229477
Validation loss: 1.4550413752114901

Epoch: 512| Step: 0
Training loss: 0.0822867900133133
Validation loss: 1.4649275361850698

Epoch: 6| Step: 1
Training loss: 0.06600221246480942
Validation loss: 1.4446436961491902

Epoch: 6| Step: 2
Training loss: 0.045996274799108505
Validation loss: 1.4443243895807574

Epoch: 6| Step: 3
Training loss: 0.09465289115905762
Validation loss: 1.4186891791641072

Epoch: 6| Step: 4
Training loss: 0.20245614647865295
Validation loss: 1.42964018032115

Epoch: 6| Step: 5
Training loss: 0.11146757751703262
Validation loss: 1.4067316273207306

Epoch: 6| Step: 6
Training loss: 0.06218477338552475
Validation loss: 1.4088721083056541

Epoch: 6| Step: 7
Training loss: 0.10763467848300934
Validation loss: 1.405749540175161

Epoch: 6| Step: 8
Training loss: 0.0767935961484909
Validation loss: 1.4035284583286574

Epoch: 6| Step: 9
Training loss: 0.0782490149140358
Validation loss: 1.3896495892155556

Epoch: 6| Step: 10
Training loss: 0.09017963707447052
Validation loss: 1.3794890437074887

Epoch: 6| Step: 11
Training loss: 0.05651209130883217
Validation loss: 1.4038710376267791

Epoch: 6| Step: 12
Training loss: 0.060366224497556686
Validation loss: 1.3809807454386065

Epoch: 6| Step: 13
Training loss: 0.12668289244174957
Validation loss: 1.4086623230288107

Epoch: 513| Step: 0
Training loss: 0.07497739791870117
Validation loss: 1.3906741014090918

Epoch: 6| Step: 1
Training loss: 0.06953519582748413
Validation loss: 1.3973635127467494

Epoch: 6| Step: 2
Training loss: 0.06865286082029343
Validation loss: 1.3915355910537064

Epoch: 6| Step: 3
Training loss: 0.09050461649894714
Validation loss: 1.4023573475499307

Epoch: 6| Step: 4
Training loss: 0.062060222029685974
Validation loss: 1.4068033310674852

Epoch: 6| Step: 5
Training loss: 0.07495485246181488
Validation loss: 1.4215713342030842

Epoch: 6| Step: 6
Training loss: 0.19791582226753235
Validation loss: 1.4251908858617146

Epoch: 6| Step: 7
Training loss: 0.061975106596946716
Validation loss: 1.418816497248988

Epoch: 6| Step: 8
Training loss: 0.04253695160150528
Validation loss: 1.4355764260856054

Epoch: 6| Step: 9
Training loss: 0.08597458899021149
Validation loss: 1.4140406372726604

Epoch: 6| Step: 10
Training loss: 0.06265154480934143
Validation loss: 1.4231519429914412

Epoch: 6| Step: 11
Training loss: 0.1100301668047905
Validation loss: 1.4172713346378778

Epoch: 6| Step: 12
Training loss: 0.10330478847026825
Validation loss: 1.4039438821936165

Epoch: 6| Step: 13
Training loss: 0.07768971472978592
Validation loss: 1.4197501892684607

Epoch: 514| Step: 0
Training loss: 0.05365217849612236
Validation loss: 1.426773739117448

Epoch: 6| Step: 1
Training loss: 0.084821417927742
Validation loss: 1.4039901571889077

Epoch: 6| Step: 2
Training loss: 0.05166703835129738
Validation loss: 1.4134245226460118

Epoch: 6| Step: 3
Training loss: 0.042821794748306274
Validation loss: 1.4260540136726954

Epoch: 6| Step: 4
Training loss: 0.08974470943212509
Validation loss: 1.4353125608095558

Epoch: 6| Step: 5
Training loss: 0.08233529329299927
Validation loss: 1.4314959510680167

Epoch: 6| Step: 6
Training loss: 0.07258816063404083
Validation loss: 1.4321113978662798

Epoch: 6| Step: 7
Training loss: 0.08103777468204498
Validation loss: 1.413631933991627

Epoch: 6| Step: 8
Training loss: 0.09548811614513397
Validation loss: 1.4160076431048814

Epoch: 6| Step: 9
Training loss: 0.12252043187618256
Validation loss: 1.391899102477617

Epoch: 6| Step: 10
Training loss: 0.07763531059026718
Validation loss: 1.3977943466555687

Epoch: 6| Step: 11
Training loss: 0.19897571206092834
Validation loss: 1.3819549634892454

Epoch: 6| Step: 12
Training loss: 0.06753066182136536
Validation loss: 1.4026702072030754

Epoch: 6| Step: 13
Training loss: 0.0592142753303051
Validation loss: 1.3855588602763351

Epoch: 515| Step: 0
Training loss: 0.0776766687631607
Validation loss: 1.3996707970096218

Epoch: 6| Step: 1
Training loss: 0.07309089601039886
Validation loss: 1.38671826547192

Epoch: 6| Step: 2
Training loss: 0.05477077513933182
Validation loss: 1.3882995574705062

Epoch: 6| Step: 3
Training loss: 0.11008370667695999
Validation loss: 1.3763214965020456

Epoch: 6| Step: 4
Training loss: 0.13206298649311066
Validation loss: 1.3792205741328578

Epoch: 6| Step: 5
Training loss: 0.07558378577232361
Validation loss: 1.4097568963163642

Epoch: 6| Step: 6
Training loss: 0.05916392430663109
Validation loss: 1.4017653144815916

Epoch: 6| Step: 7
Training loss: 0.0694458931684494
Validation loss: 1.4132373743159796

Epoch: 6| Step: 8
Training loss: 0.06616178900003433
Validation loss: 1.441322518933204

Epoch: 6| Step: 9
Training loss: 0.09505128860473633
Validation loss: 1.4652961146446966

Epoch: 6| Step: 10
Training loss: 0.17726171016693115
Validation loss: 1.4640895423068796

Epoch: 6| Step: 11
Training loss: 0.0859641432762146
Validation loss: 1.4382741169262958

Epoch: 6| Step: 12
Training loss: 0.13270694017410278
Validation loss: 1.4335582025589482

Epoch: 6| Step: 13
Training loss: 0.3225524425506592
Validation loss: 1.40478499474064

Epoch: 516| Step: 0
Training loss: 0.05912051722407341
Validation loss: 1.4009170045134842

Epoch: 6| Step: 1
Training loss: 0.055353760719299316
Validation loss: 1.3578074375788372

Epoch: 6| Step: 2
Training loss: 0.08621882647275925
Validation loss: 1.3639177071150912

Epoch: 6| Step: 3
Training loss: 0.11638976633548737
Validation loss: 1.3617945947954733

Epoch: 6| Step: 4
Training loss: 0.10788502544164658
Validation loss: 1.3783518050306587

Epoch: 6| Step: 5
Training loss: 0.10126342624425888
Validation loss: 1.3608637727716917

Epoch: 6| Step: 6
Training loss: 0.0916660726070404
Validation loss: 1.3384193951083767

Epoch: 6| Step: 7
Training loss: 0.08490996807813644
Validation loss: 1.367186705271403

Epoch: 6| Step: 8
Training loss: 0.05335170030593872
Validation loss: 1.37817806325933

Epoch: 6| Step: 9
Training loss: 0.11860775947570801
Validation loss: 1.4088693908465806

Epoch: 6| Step: 10
Training loss: 0.24703744053840637
Validation loss: 1.4086322451150546

Epoch: 6| Step: 11
Training loss: 0.11946029961109161
Validation loss: 1.4373928129032094

Epoch: 6| Step: 12
Training loss: 0.06209927052259445
Validation loss: 1.4166099070220866

Epoch: 6| Step: 13
Training loss: 0.10311122983694077
Validation loss: 1.4353999732643046

Epoch: 517| Step: 0
Training loss: 0.06838764250278473
Validation loss: 1.4335280631178169

Epoch: 6| Step: 1
Training loss: 0.06859040260314941
Validation loss: 1.427635173643789

Epoch: 6| Step: 2
Training loss: 0.07186279445886612
Validation loss: 1.4516790489996634

Epoch: 6| Step: 3
Training loss: 0.10119420289993286
Validation loss: 1.435131044798

Epoch: 6| Step: 4
Training loss: 0.07574118673801422
Validation loss: 1.4454582211791829

Epoch: 6| Step: 5
Training loss: 0.2538505494594574
Validation loss: 1.467311309229943

Epoch: 6| Step: 6
Training loss: 0.045041605830192566
Validation loss: 1.42211498496353

Epoch: 6| Step: 7
Training loss: 0.10088986158370972
Validation loss: 1.414367942399876

Epoch: 6| Step: 8
Training loss: 0.07698699831962585
Validation loss: 1.4330706916829592

Epoch: 6| Step: 9
Training loss: 0.09007143974304199
Validation loss: 1.4527596536503042

Epoch: 6| Step: 10
Training loss: 0.073020800948143
Validation loss: 1.4266384365738078

Epoch: 6| Step: 11
Training loss: 0.07768523693084717
Validation loss: 1.4292344688087382

Epoch: 6| Step: 12
Training loss: 0.09785100817680359
Validation loss: 1.423237044324157

Epoch: 6| Step: 13
Training loss: 0.0719740092754364
Validation loss: 1.4439124907216718

Epoch: 518| Step: 0
Training loss: 0.09001898765563965
Validation loss: 1.4220003286997478

Epoch: 6| Step: 1
Training loss: 0.25087594985961914
Validation loss: 1.4177060037530878

Epoch: 6| Step: 2
Training loss: 0.08593311160802841
Validation loss: 1.434541472824671

Epoch: 6| Step: 3
Training loss: 0.07369878143072128
Validation loss: 1.4259885100908176

Epoch: 6| Step: 4
Training loss: 0.07392959296703339
Validation loss: 1.4412778615951538

Epoch: 6| Step: 5
Training loss: 0.05758267641067505
Validation loss: 1.4369144683243127

Epoch: 6| Step: 6
Training loss: 0.10379261523485184
Validation loss: 1.4586854404018772

Epoch: 6| Step: 7
Training loss: 0.05375415086746216
Validation loss: 1.450612510404279

Epoch: 6| Step: 8
Training loss: 0.0897136926651001
Validation loss: 1.43455627400388

Epoch: 6| Step: 9
Training loss: 0.057950906455516815
Validation loss: 1.4612975059657969

Epoch: 6| Step: 10
Training loss: 0.09014963358640671
Validation loss: 1.452509722402019

Epoch: 6| Step: 11
Training loss: 0.06363113224506378
Validation loss: 1.4373596701570737

Epoch: 6| Step: 12
Training loss: 0.08031881600618362
Validation loss: 1.4359190784474856

Epoch: 6| Step: 13
Training loss: 0.1003943383693695
Validation loss: 1.4140229635341193

Epoch: 519| Step: 0
Training loss: 0.09077545255422592
Validation loss: 1.4252193397091282

Epoch: 6| Step: 1
Training loss: 0.11782464385032654
Validation loss: 1.4217503006740282

Epoch: 6| Step: 2
Training loss: 0.09345299005508423
Validation loss: 1.415335423202925

Epoch: 6| Step: 3
Training loss: 0.07543322443962097
Validation loss: 1.428965676215387

Epoch: 6| Step: 4
Training loss: 0.08755584061145782
Validation loss: 1.4256025770659089

Epoch: 6| Step: 5
Training loss: 0.05592793971300125
Validation loss: 1.4255228792467425

Epoch: 6| Step: 6
Training loss: 0.10517331212759018
Validation loss: 1.4350651118063158

Epoch: 6| Step: 7
Training loss: 0.20333069562911987
Validation loss: 1.4380348228639173

Epoch: 6| Step: 8
Training loss: 0.09301261603832245
Validation loss: 1.4257988878475722

Epoch: 6| Step: 9
Training loss: 0.0676441341638565
Validation loss: 1.4462292950640443

Epoch: 6| Step: 10
Training loss: 0.0960640013217926
Validation loss: 1.4049681271276167

Epoch: 6| Step: 11
Training loss: 0.05625777691602707
Validation loss: 1.4071858095866379

Epoch: 6| Step: 12
Training loss: 0.08634352684020996
Validation loss: 1.4300353296341435

Epoch: 6| Step: 13
Training loss: 0.10987330973148346
Validation loss: 1.4230963132714713

Epoch: 520| Step: 0
Training loss: 0.0739227682352066
Validation loss: 1.3929292181486725

Epoch: 6| Step: 1
Training loss: 0.07767447084188461
Validation loss: 1.4017677691675001

Epoch: 6| Step: 2
Training loss: 0.07336686551570892
Validation loss: 1.375122481776822

Epoch: 6| Step: 3
Training loss: 0.0998065397143364
Validation loss: 1.367459629171638

Epoch: 6| Step: 4
Training loss: 0.10051598399877548
Validation loss: 1.3935574395682222

Epoch: 6| Step: 5
Training loss: 0.08214263617992401
Validation loss: 1.3561495465617026

Epoch: 6| Step: 6
Training loss: 0.06200044974684715
Validation loss: 1.3733440240224202

Epoch: 6| Step: 7
Training loss: 0.15211260318756104
Validation loss: 1.3761641812580887

Epoch: 6| Step: 8
Training loss: 0.08572087436914444
Validation loss: 1.3784874780203706

Epoch: 6| Step: 9
Training loss: 0.08787254989147186
Validation loss: 1.4129147747511506

Epoch: 6| Step: 10
Training loss: 0.2037266343832016
Validation loss: 1.440716835760301

Epoch: 6| Step: 11
Training loss: 0.10823892056941986
Validation loss: 1.4574770760792557

Epoch: 6| Step: 12
Training loss: 0.12189147621393204
Validation loss: 1.4379381242618765

Epoch: 6| Step: 13
Training loss: 0.03477276861667633
Validation loss: 1.457807852375892

Epoch: 521| Step: 0
Training loss: 0.23219561576843262
Validation loss: 1.4456611128263577

Epoch: 6| Step: 1
Training loss: 0.06936276704072952
Validation loss: 1.4417149007961314

Epoch: 6| Step: 2
Training loss: 0.08503150939941406
Validation loss: 1.4575019767207484

Epoch: 6| Step: 3
Training loss: 0.06842443346977234
Validation loss: 1.466087322081289

Epoch: 6| Step: 4
Training loss: 0.10972490906715393
Validation loss: 1.4566850739140664

Epoch: 6| Step: 5
Training loss: 0.08804162591695786
Validation loss: 1.4703037251708329

Epoch: 6| Step: 6
Training loss: 0.09642476588487625
Validation loss: 1.4755044060368692

Epoch: 6| Step: 7
Training loss: 0.06378865987062454
Validation loss: 1.4857758732252224

Epoch: 6| Step: 8
Training loss: 0.10065436363220215
Validation loss: 1.4663638504602576

Epoch: 6| Step: 9
Training loss: 0.07526180148124695
Validation loss: 1.4656884490802724

Epoch: 6| Step: 10
Training loss: 0.08088833093643188
Validation loss: 1.4634672826336277

Epoch: 6| Step: 11
Training loss: 0.09783226251602173
Validation loss: 1.4572763622448008

Epoch: 6| Step: 12
Training loss: 0.10567772388458252
Validation loss: 1.456300494491413

Epoch: 6| Step: 13
Training loss: 0.09877962619066238
Validation loss: 1.4453631299798206

Epoch: 522| Step: 0
Training loss: 0.12103581428527832
Validation loss: 1.432110482646573

Epoch: 6| Step: 1
Training loss: 0.0738455206155777
Validation loss: 1.416729606607909

Epoch: 6| Step: 2
Training loss: 0.04543878138065338
Validation loss: 1.3993590198537356

Epoch: 6| Step: 3
Training loss: 0.0840776339173317
Validation loss: 1.401415615953425

Epoch: 6| Step: 4
Training loss: 0.06823554635047913
Validation loss: 1.3811249143333846

Epoch: 6| Step: 5
Training loss: 0.08361417800188065
Validation loss: 1.371049161880247

Epoch: 6| Step: 6
Training loss: 0.04393254593014717
Validation loss: 1.3789167891266525

Epoch: 6| Step: 7
Training loss: 0.09692618250846863
Validation loss: 1.398965512552569

Epoch: 6| Step: 8
Training loss: 0.06718167662620544
Validation loss: 1.4048605580483713

Epoch: 6| Step: 9
Training loss: 0.052063509821891785
Validation loss: 1.387395692128007

Epoch: 6| Step: 10
Training loss: 0.2484215348958969
Validation loss: 1.3909384633905144

Epoch: 6| Step: 11
Training loss: 0.05824461951851845
Validation loss: 1.412339933456913

Epoch: 6| Step: 12
Training loss: 0.08632303774356842
Validation loss: 1.3939546128754974

Epoch: 6| Step: 13
Training loss: 0.13730274140834808
Validation loss: 1.411738311090777

Epoch: 523| Step: 0
Training loss: 0.05367665737867355
Validation loss: 1.3954617086277212

Epoch: 6| Step: 1
Training loss: 0.20236524939537048
Validation loss: 1.4284389313831125

Epoch: 6| Step: 2
Training loss: 0.11445499956607819
Validation loss: 1.433246160066256

Epoch: 6| Step: 3
Training loss: 0.06100703030824661
Validation loss: 1.4068313349959671

Epoch: 6| Step: 4
Training loss: 0.08472033590078354
Validation loss: 1.4273064341596378

Epoch: 6| Step: 5
Training loss: 0.09300409257411957
Validation loss: 1.4362653891245525

Epoch: 6| Step: 6
Training loss: 0.07729989290237427
Validation loss: 1.4272959398966965

Epoch: 6| Step: 7
Training loss: 0.030469508841633797
Validation loss: 1.418191207352505

Epoch: 6| Step: 8
Training loss: 0.07726147770881653
Validation loss: 1.4328242694177935

Epoch: 6| Step: 9
Training loss: 0.07159608602523804
Validation loss: 1.4314842083120858

Epoch: 6| Step: 10
Training loss: 0.05209798365831375
Validation loss: 1.4341404989201536

Epoch: 6| Step: 11
Training loss: 0.11956055462360382
Validation loss: 1.433485419519486

Epoch: 6| Step: 12
Training loss: 0.10562925040721893
Validation loss: 1.4293578491416028

Epoch: 6| Step: 13
Training loss: 0.11313923448324203
Validation loss: 1.413465546023461

Epoch: 524| Step: 0
Training loss: 0.20244716107845306
Validation loss: 1.4118892364604498

Epoch: 6| Step: 1
Training loss: 0.09952228516340256
Validation loss: 1.427419541984476

Epoch: 6| Step: 2
Training loss: 0.05346265807747841
Validation loss: 1.4181584773525115

Epoch: 6| Step: 3
Training loss: 0.05165736377239227
Validation loss: 1.4201081952741068

Epoch: 6| Step: 4
Training loss: 0.04885520040988922
Validation loss: 1.4192240379189933

Epoch: 6| Step: 5
Training loss: 0.0893409252166748
Validation loss: 1.4372748367248043

Epoch: 6| Step: 6
Training loss: 0.1296834945678711
Validation loss: 1.4172805381077591

Epoch: 6| Step: 7
Training loss: 0.08444701880216599
Validation loss: 1.4434294572440527

Epoch: 6| Step: 8
Training loss: 0.07200591266155243
Validation loss: 1.4489406257547357

Epoch: 6| Step: 9
Training loss: 0.08346739411354065
Validation loss: 1.4570597717838902

Epoch: 6| Step: 10
Training loss: 0.08233122527599335
Validation loss: 1.4297266493561447

Epoch: 6| Step: 11
Training loss: 0.07889287918806076
Validation loss: 1.4121646265829764

Epoch: 6| Step: 12
Training loss: 0.05678611993789673
Validation loss: 1.4272256012885802

Epoch: 6| Step: 13
Training loss: 0.05913437157869339
Validation loss: 1.4214848497862458

Epoch: 525| Step: 0
Training loss: 0.06464944034814835
Validation loss: 1.4258932926321541

Epoch: 6| Step: 1
Training loss: 0.07860362529754639
Validation loss: 1.4541247429386261

Epoch: 6| Step: 2
Training loss: 0.0651276484131813
Validation loss: 1.4084755323266471

Epoch: 6| Step: 3
Training loss: 0.058831822127103806
Validation loss: 1.3760433325203516

Epoch: 6| Step: 4
Training loss: 0.06556540727615356
Validation loss: 1.3757611692592662

Epoch: 6| Step: 5
Training loss: 0.07434232532978058
Validation loss: 1.398314800313724

Epoch: 6| Step: 6
Training loss: 0.04683136194944382
Validation loss: 1.3934025290191814

Epoch: 6| Step: 7
Training loss: 0.071208655834198
Validation loss: 1.4007999461184266

Epoch: 6| Step: 8
Training loss: 0.0640706792473793
Validation loss: 1.3701478845329695

Epoch: 6| Step: 9
Training loss: 0.05706700682640076
Validation loss: 1.3789106210072835

Epoch: 6| Step: 10
Training loss: 0.14526447653770447
Validation loss: 1.371174249597775

Epoch: 6| Step: 11
Training loss: 0.10228972882032394
Validation loss: 1.3836748683324425

Epoch: 6| Step: 12
Training loss: 0.20665113627910614
Validation loss: 1.3840681160649946

Epoch: 6| Step: 13
Training loss: 0.04673223942518234
Validation loss: 1.407905988795783

Epoch: 526| Step: 0
Training loss: 0.071591816842556
Validation loss: 1.4133910825175624

Epoch: 6| Step: 1
Training loss: 0.057200320065021515
Validation loss: 1.4006615543878207

Epoch: 6| Step: 2
Training loss: 0.08686819672584534
Validation loss: 1.4114980812995666

Epoch: 6| Step: 3
Training loss: 0.06865295022726059
Validation loss: 1.4089189819110337

Epoch: 6| Step: 4
Training loss: 0.06334377825260162
Validation loss: 1.4001335033806421

Epoch: 6| Step: 5
Training loss: 0.06474760174751282
Validation loss: 1.4071563956558064

Epoch: 6| Step: 6
Training loss: 0.03764096274971962
Validation loss: 1.4307393976437148

Epoch: 6| Step: 7
Training loss: 0.068185955286026
Validation loss: 1.4176414910183157

Epoch: 6| Step: 8
Training loss: 0.03893159329891205
Validation loss: 1.3939505994960826

Epoch: 6| Step: 9
Training loss: 0.08953113853931427
Validation loss: 1.3893624736416725

Epoch: 6| Step: 10
Training loss: 0.1975448727607727
Validation loss: 1.3968171727272771

Epoch: 6| Step: 11
Training loss: 0.0666889101266861
Validation loss: 1.395209147084144

Epoch: 6| Step: 12
Training loss: 0.04947805404663086
Validation loss: 1.41046578268851

Epoch: 6| Step: 13
Training loss: 0.11667527258396149
Validation loss: 1.382529531755755

Epoch: 527| Step: 0
Training loss: 0.053358860313892365
Validation loss: 1.395653525988261

Epoch: 6| Step: 1
Training loss: 0.06324467062950134
Validation loss: 1.3663160416387743

Epoch: 6| Step: 2
Training loss: 0.05299268290400505
Validation loss: 1.3793192666064027

Epoch: 6| Step: 3
Training loss: 0.08088058978319168
Validation loss: 1.4052500981156544

Epoch: 6| Step: 4
Training loss: 0.059138208627700806
Validation loss: 1.3860503588953326

Epoch: 6| Step: 5
Training loss: 0.10797074437141418
Validation loss: 1.3846822342564982

Epoch: 6| Step: 6
Training loss: 0.06865692138671875
Validation loss: 1.3871348519479074

Epoch: 6| Step: 7
Training loss: 0.04720436409115791
Validation loss: 1.3975726609588952

Epoch: 6| Step: 8
Training loss: 0.0875992625951767
Validation loss: 1.3919346230004424

Epoch: 6| Step: 9
Training loss: 0.22156046330928802
Validation loss: 1.4117304509685886

Epoch: 6| Step: 10
Training loss: 0.0686677023768425
Validation loss: 1.404482424900096

Epoch: 6| Step: 11
Training loss: 0.07689773291349411
Validation loss: 1.4094087987817743

Epoch: 6| Step: 12
Training loss: 0.09521937370300293
Validation loss: 1.3944065904104581

Epoch: 6| Step: 13
Training loss: 0.06911339610815048
Validation loss: 1.4170937615056192

Epoch: 528| Step: 0
Training loss: 0.052470043301582336
Validation loss: 1.4354078833774855

Epoch: 6| Step: 1
Training loss: 0.08269430696964264
Validation loss: 1.420756427190637

Epoch: 6| Step: 2
Training loss: 0.0895891934633255
Validation loss: 1.4212174377133768

Epoch: 6| Step: 3
Training loss: 0.04936537891626358
Validation loss: 1.4156028929577078

Epoch: 6| Step: 4
Training loss: 0.05459652096033096
Validation loss: 1.4369003490735126

Epoch: 6| Step: 5
Training loss: 0.057073015719652176
Validation loss: 1.4308642571972263

Epoch: 6| Step: 6
Training loss: 0.10606934875249863
Validation loss: 1.4392315610762565

Epoch: 6| Step: 7
Training loss: 0.0815131664276123
Validation loss: 1.4303229265315558

Epoch: 6| Step: 8
Training loss: 0.09676815569400787
Validation loss: 1.398039964578485

Epoch: 6| Step: 9
Training loss: 0.06019331514835358
Validation loss: 1.4151791564879879

Epoch: 6| Step: 10
Training loss: 0.05984725058078766
Validation loss: 1.400769651577037

Epoch: 6| Step: 11
Training loss: 0.06549163907766342
Validation loss: 1.419152953291452

Epoch: 6| Step: 12
Training loss: 0.18635475635528564
Validation loss: 1.4083285793181388

Epoch: 6| Step: 13
Training loss: 0.038185689598321915
Validation loss: 1.3922267729236233

Epoch: 529| Step: 0
Training loss: 0.07451744377613068
Validation loss: 1.4111894683171344

Epoch: 6| Step: 1
Training loss: 0.07452715933322906
Validation loss: 1.406152065082263

Epoch: 6| Step: 2
Training loss: 0.05396469682455063
Validation loss: 1.4235253282772597

Epoch: 6| Step: 3
Training loss: 0.09793451428413391
Validation loss: 1.4066101081909672

Epoch: 6| Step: 4
Training loss: 0.060703665018081665
Validation loss: 1.3961509748171734

Epoch: 6| Step: 5
Training loss: 0.11623187363147736
Validation loss: 1.3861903490558747

Epoch: 6| Step: 6
Training loss: 0.05016206204891205
Validation loss: 1.3811972038720244

Epoch: 6| Step: 7
Training loss: 0.07552342861890793
Validation loss: 1.378743722874631

Epoch: 6| Step: 8
Training loss: 0.2286522388458252
Validation loss: 1.4106801325275051

Epoch: 6| Step: 9
Training loss: 0.0476294569671154
Validation loss: 1.38736036516005

Epoch: 6| Step: 10
Training loss: 0.03725359961390495
Validation loss: 1.4163152671629382

Epoch: 6| Step: 11
Training loss: 0.055520374327898026
Validation loss: 1.403174413147793

Epoch: 6| Step: 12
Training loss: 0.05653718486428261
Validation loss: 1.4033400858602216

Epoch: 6| Step: 13
Training loss: 0.0689980685710907
Validation loss: 1.4118842360793904

Epoch: 530| Step: 0
Training loss: 0.06429959833621979
Validation loss: 1.4141605284906202

Epoch: 6| Step: 1
Training loss: 0.09064948558807373
Validation loss: 1.3986032086033975

Epoch: 6| Step: 2
Training loss: 0.0585375651717186
Validation loss: 1.4316761314228017

Epoch: 6| Step: 3
Training loss: 0.04465173929929733
Validation loss: 1.4289889168995682

Epoch: 6| Step: 4
Training loss: 0.20965071022510529
Validation loss: 1.4353989388353081

Epoch: 6| Step: 5
Training loss: 0.04785333573818207
Validation loss: 1.4109864786107054

Epoch: 6| Step: 6
Training loss: 0.07139246165752411
Validation loss: 1.4624887115211898

Epoch: 6| Step: 7
Training loss: 0.09454986453056335
Validation loss: 1.4450620400008334

Epoch: 6| Step: 8
Training loss: 0.0407034307718277
Validation loss: 1.465326673241072

Epoch: 6| Step: 9
Training loss: 0.08477770537137985
Validation loss: 1.4344387503080471

Epoch: 6| Step: 10
Training loss: 0.07264426350593567
Validation loss: 1.4465709437606156

Epoch: 6| Step: 11
Training loss: 0.07448148727416992
Validation loss: 1.4399824424456524

Epoch: 6| Step: 12
Training loss: 0.11829166114330292
Validation loss: 1.44017433222904

Epoch: 6| Step: 13
Training loss: 0.10489317029714584
Validation loss: 1.4213210267405356

Epoch: 531| Step: 0
Training loss: 0.05260562151670456
Validation loss: 1.4376690701771808

Epoch: 6| Step: 1
Training loss: 0.07531920075416565
Validation loss: 1.410503545115071

Epoch: 6| Step: 2
Training loss: 0.07426675409078598
Validation loss: 1.4201498172616447

Epoch: 6| Step: 3
Training loss: 0.07578051090240479
Validation loss: 1.3847427791164768

Epoch: 6| Step: 4
Training loss: 0.07638786733150482
Validation loss: 1.414097087357634

Epoch: 6| Step: 5
Training loss: 0.04015061631798744
Validation loss: 1.406485826738419

Epoch: 6| Step: 6
Training loss: 0.07219240814447403
Validation loss: 1.4274727747004519

Epoch: 6| Step: 7
Training loss: 0.046023063361644745
Validation loss: 1.3965561441195908

Epoch: 6| Step: 8
Training loss: 0.07130436599254608
Validation loss: 1.3890333893478557

Epoch: 6| Step: 9
Training loss: 0.08171896636486053
Validation loss: 1.394303883275678

Epoch: 6| Step: 10
Training loss: 0.04291405528783798
Validation loss: 1.4302357307044409

Epoch: 6| Step: 11
Training loss: 0.06942969560623169
Validation loss: 1.393072259041571

Epoch: 6| Step: 12
Training loss: 0.20019571483135223
Validation loss: 1.4147122252372004

Epoch: 6| Step: 13
Training loss: 0.03175447881221771
Validation loss: 1.4021901949759452

Epoch: 532| Step: 0
Training loss: 0.053728170692920685
Validation loss: 1.4418033194798294

Epoch: 6| Step: 1
Training loss: 0.06808428466320038
Validation loss: 1.4207612301713677

Epoch: 6| Step: 2
Training loss: 0.063560351729393
Validation loss: 1.4244602540487885

Epoch: 6| Step: 3
Training loss: 0.050037529319524765
Validation loss: 1.4165362158129293

Epoch: 6| Step: 4
Training loss: 0.04100163280963898
Validation loss: 1.4163628009057814

Epoch: 6| Step: 5
Training loss: 0.08949296176433563
Validation loss: 1.4073857056197299

Epoch: 6| Step: 6
Training loss: 0.1177951768040657
Validation loss: 1.41046852578399

Epoch: 6| Step: 7
Training loss: 0.09729306399822235
Validation loss: 1.4387710222633936

Epoch: 6| Step: 8
Training loss: 0.2876488268375397
Validation loss: 1.4343708074221047

Epoch: 6| Step: 9
Training loss: 0.09199012070894241
Validation loss: 1.4233994919766662

Epoch: 6| Step: 10
Training loss: 0.07963094860315323
Validation loss: 1.434852296306241

Epoch: 6| Step: 11
Training loss: 0.05057711899280548
Validation loss: 1.4398846485281502

Epoch: 6| Step: 12
Training loss: 0.043315693736076355
Validation loss: 1.4412601468383626

Epoch: 6| Step: 13
Training loss: 0.04912582039833069
Validation loss: 1.417941148563098

Epoch: 533| Step: 0
Training loss: 0.09383928030729294
Validation loss: 1.4484951534578878

Epoch: 6| Step: 1
Training loss: 0.07007910311222076
Validation loss: 1.4180727774097073

Epoch: 6| Step: 2
Training loss: 0.057322949171066284
Validation loss: 1.42361000404563

Epoch: 6| Step: 3
Training loss: 0.06575630605220795
Validation loss: 1.420821512899091

Epoch: 6| Step: 4
Training loss: 0.05923037230968475
Validation loss: 1.4453451646271573

Epoch: 6| Step: 5
Training loss: 0.09195218980312347
Validation loss: 1.4272551434014433

Epoch: 6| Step: 6
Training loss: 0.050244566053152084
Validation loss: 1.4233419279898367

Epoch: 6| Step: 7
Training loss: 0.07739762216806412
Validation loss: 1.4341070972463137

Epoch: 6| Step: 8
Training loss: 0.06551649421453476
Validation loss: 1.422008962400498

Epoch: 6| Step: 9
Training loss: 0.05668535828590393
Validation loss: 1.4305366239240092

Epoch: 6| Step: 10
Training loss: 0.2281588912010193
Validation loss: 1.4515826945663781

Epoch: 6| Step: 11
Training loss: 0.056577377021312714
Validation loss: 1.4170800139827113

Epoch: 6| Step: 12
Training loss: 0.040808722376823425
Validation loss: 1.4529092760496243

Epoch: 6| Step: 13
Training loss: 0.1083587035536766
Validation loss: 1.4208533827976515

Epoch: 534| Step: 0
Training loss: 0.06092322990298271
Validation loss: 1.415566235460261

Epoch: 6| Step: 1
Training loss: 0.035223811864852905
Validation loss: 1.4088393962511452

Epoch: 6| Step: 2
Training loss: 0.13903391361236572
Validation loss: 1.4089147698494695

Epoch: 6| Step: 3
Training loss: 0.057927075773477554
Validation loss: 1.4210707936235654

Epoch: 6| Step: 4
Training loss: 0.08448542654514313
Validation loss: 1.409624243295321

Epoch: 6| Step: 5
Training loss: 0.11952812969684601
Validation loss: 1.4128495711152271

Epoch: 6| Step: 6
Training loss: 0.04279005900025368
Validation loss: 1.3967593651945873

Epoch: 6| Step: 7
Training loss: 0.06352228671312332
Validation loss: 1.4213314312760548

Epoch: 6| Step: 8
Training loss: 0.06883765012025833
Validation loss: 1.4071245270390664

Epoch: 6| Step: 9
Training loss: 0.06976823508739471
Validation loss: 1.4017587489979242

Epoch: 6| Step: 10
Training loss: 0.11265093088150024
Validation loss: 1.4248324645462858

Epoch: 6| Step: 11
Training loss: 0.08990366756916046
Validation loss: 1.3881122207128873

Epoch: 6| Step: 12
Training loss: 0.08530496060848236
Validation loss: 1.414380645239225

Epoch: 6| Step: 13
Training loss: 0.2997733950614929
Validation loss: 1.391680956527751

Epoch: 535| Step: 0
Training loss: 0.06637103855609894
Validation loss: 1.3977637701137091

Epoch: 6| Step: 1
Training loss: 0.07885397970676422
Validation loss: 1.4003006822319441

Epoch: 6| Step: 2
Training loss: 0.0644809827208519
Validation loss: 1.4155044722300705

Epoch: 6| Step: 3
Training loss: 0.07326900959014893
Validation loss: 1.3773803089254646

Epoch: 6| Step: 4
Training loss: 0.1040545254945755
Validation loss: 1.4039364437903128

Epoch: 6| Step: 5
Training loss: 0.1165151447057724
Validation loss: 1.403497725404719

Epoch: 6| Step: 6
Training loss: 0.09368051588535309
Validation loss: 1.4000633368569035

Epoch: 6| Step: 7
Training loss: 0.08150027692317963
Validation loss: 1.4096154794898084

Epoch: 6| Step: 8
Training loss: 0.032368265092372894
Validation loss: 1.4226176354192919

Epoch: 6| Step: 9
Training loss: 0.06868460029363632
Validation loss: 1.4224867487466464

Epoch: 6| Step: 10
Training loss: 0.046316660940647125
Validation loss: 1.4137392095340195

Epoch: 6| Step: 11
Training loss: 0.07068636268377304
Validation loss: 1.4298882817709317

Epoch: 6| Step: 12
Training loss: 0.1788700520992279
Validation loss: 1.4072027225648203

Epoch: 6| Step: 13
Training loss: 0.08394616097211838
Validation loss: 1.4104771126982987

Epoch: 536| Step: 0
Training loss: 0.08755993098020554
Validation loss: 1.4214075150028351

Epoch: 6| Step: 1
Training loss: 0.12609049677848816
Validation loss: 1.4095096408679921

Epoch: 6| Step: 2
Training loss: 0.08002904057502747
Validation loss: 1.421014153829185

Epoch: 6| Step: 3
Training loss: 0.09972770512104034
Validation loss: 1.413377651604273

Epoch: 6| Step: 4
Training loss: 0.2142394781112671
Validation loss: 1.3994451620245492

Epoch: 6| Step: 5
Training loss: 0.08154545724391937
Validation loss: 1.3916712294342697

Epoch: 6| Step: 6
Training loss: 0.0975199043750763
Validation loss: 1.390901480951617

Epoch: 6| Step: 7
Training loss: 0.12514913082122803
Validation loss: 1.407172227418551

Epoch: 6| Step: 8
Training loss: 0.09604118764400482
Validation loss: 1.3938450524883885

Epoch: 6| Step: 9
Training loss: 0.06331979483366013
Validation loss: 1.3889054290709957

Epoch: 6| Step: 10
Training loss: 0.05740665644407272
Validation loss: 1.4100776641599593

Epoch: 6| Step: 11
Training loss: 0.10086619853973389
Validation loss: 1.3992902950573993

Epoch: 6| Step: 12
Training loss: 0.0523909255862236
Validation loss: 1.3891920428122244

Epoch: 6| Step: 13
Training loss: 0.06669510900974274
Validation loss: 1.3871437157354047

Epoch: 537| Step: 0
Training loss: 0.10100125521421432
Validation loss: 1.37996680121268

Epoch: 6| Step: 1
Training loss: 0.06675733625888824
Validation loss: 1.4025744545844294

Epoch: 6| Step: 2
Training loss: 0.07132145762443542
Validation loss: 1.3732560911486227

Epoch: 6| Step: 3
Training loss: 0.07133013010025024
Validation loss: 1.3819761801791448

Epoch: 6| Step: 4
Training loss: 0.08625821769237518
Validation loss: 1.368419263952522

Epoch: 6| Step: 5
Training loss: 0.08685044944286346
Validation loss: 1.3710011487366052

Epoch: 6| Step: 6
Training loss: 0.047930315136909485
Validation loss: 1.394289707624784

Epoch: 6| Step: 7
Training loss: 0.07509537041187286
Validation loss: 1.3804195901399017

Epoch: 6| Step: 8
Training loss: 0.19258245825767517
Validation loss: 1.3841033481782483

Epoch: 6| Step: 9
Training loss: 0.10143083333969116
Validation loss: 1.3775366064040893

Epoch: 6| Step: 10
Training loss: 0.06385507434606552
Validation loss: 1.4020557762474142

Epoch: 6| Step: 11
Training loss: 0.050725579261779785
Validation loss: 1.4118147780818324

Epoch: 6| Step: 12
Training loss: 0.05417429283261299
Validation loss: 1.4326013390735914

Epoch: 6| Step: 13
Training loss: 0.08064600080251694
Validation loss: 1.43884579853345

Epoch: 538| Step: 0
Training loss: 0.04943118989467621
Validation loss: 1.431792119497894

Epoch: 6| Step: 1
Training loss: 0.04138112813234329
Validation loss: 1.4383227863619406

Epoch: 6| Step: 2
Training loss: 0.052989691495895386
Validation loss: 1.440846263721425

Epoch: 6| Step: 3
Training loss: 0.09268935769796371
Validation loss: 1.4311181806748914

Epoch: 6| Step: 4
Training loss: 0.08173032850027084
Validation loss: 1.4260211285724436

Epoch: 6| Step: 5
Training loss: 0.048485711216926575
Validation loss: 1.427454005005539

Epoch: 6| Step: 6
Training loss: 0.06468470394611359
Validation loss: 1.402590815738965

Epoch: 6| Step: 7
Training loss: 0.19515761733055115
Validation loss: 1.4082348859438332

Epoch: 6| Step: 8
Training loss: 0.07899610698223114
Validation loss: 1.371387380425648

Epoch: 6| Step: 9
Training loss: 0.06859356164932251
Validation loss: 1.40412728376286

Epoch: 6| Step: 10
Training loss: 0.12452313303947449
Validation loss: 1.395373563612661

Epoch: 6| Step: 11
Training loss: 0.07450409978628159
Validation loss: 1.3891943879024957

Epoch: 6| Step: 12
Training loss: 0.07238607108592987
Validation loss: 1.3731578485940092

Epoch: 6| Step: 13
Training loss: 0.13355731964111328
Validation loss: 1.3756477627702939

Epoch: 539| Step: 0
Training loss: 0.05876949429512024
Validation loss: 1.3633586642562703

Epoch: 6| Step: 1
Training loss: 0.054572343826293945
Validation loss: 1.3932348470534048

Epoch: 6| Step: 2
Training loss: 0.04646828770637512
Validation loss: 1.3992286241182716

Epoch: 6| Step: 3
Training loss: 0.10645429790019989
Validation loss: 1.404056796463587

Epoch: 6| Step: 4
Training loss: 0.05819256603717804
Validation loss: 1.3911073361673663

Epoch: 6| Step: 5
Training loss: 0.07115716487169266
Validation loss: 1.4157295265505392

Epoch: 6| Step: 6
Training loss: 0.09262221306562424
Validation loss: 1.394014048319991

Epoch: 6| Step: 7
Training loss: 0.0758456438779831
Validation loss: 1.4106770279586955

Epoch: 6| Step: 8
Training loss: 0.11028485000133514
Validation loss: 1.431275620255419

Epoch: 6| Step: 9
Training loss: 0.06361830979585648
Validation loss: 1.3989102962196514

Epoch: 6| Step: 10
Training loss: 0.18817847967147827
Validation loss: 1.403446235323465

Epoch: 6| Step: 11
Training loss: 0.042256347835063934
Validation loss: 1.4043242918547763

Epoch: 6| Step: 12
Training loss: 0.04778186231851578
Validation loss: 1.3889629481941141

Epoch: 6| Step: 13
Training loss: 0.06989134848117828
Validation loss: 1.3660764566031836

Epoch: 540| Step: 0
Training loss: 0.08857493102550507
Validation loss: 1.4127296170880717

Epoch: 6| Step: 1
Training loss: 0.08569974452257156
Validation loss: 1.4227071936412523

Epoch: 6| Step: 2
Training loss: 0.07121461629867554
Validation loss: 1.412091387215481

Epoch: 6| Step: 3
Training loss: 0.09032861143350601
Validation loss: 1.4238774033002957

Epoch: 6| Step: 4
Training loss: 0.0738883912563324
Validation loss: 1.440721909205119

Epoch: 6| Step: 5
Training loss: 0.0478031262755394
Validation loss: 1.4136823556756462

Epoch: 6| Step: 6
Training loss: 0.06974740326404572
Validation loss: 1.4385199739087013

Epoch: 6| Step: 7
Training loss: 0.09447619318962097
Validation loss: 1.407737414042155

Epoch: 6| Step: 8
Training loss: 0.04685308039188385
Validation loss: 1.413551220329859

Epoch: 6| Step: 9
Training loss: 0.041111722588539124
Validation loss: 1.422292829841696

Epoch: 6| Step: 10
Training loss: 0.19341892004013062
Validation loss: 1.4396140210090145

Epoch: 6| Step: 11
Training loss: 0.08025111258029938
Validation loss: 1.4510195473188996

Epoch: 6| Step: 12
Training loss: 0.125593900680542
Validation loss: 1.4370708811667658

Epoch: 6| Step: 13
Training loss: 0.04409467428922653
Validation loss: 1.4126751038335985

Epoch: 541| Step: 0
Training loss: 0.03979060798883438
Validation loss: 1.4159449531186012

Epoch: 6| Step: 1
Training loss: 0.08956053853034973
Validation loss: 1.4409265428461053

Epoch: 6| Step: 2
Training loss: 0.059336110949516296
Validation loss: 1.4484305394593107

Epoch: 6| Step: 3
Training loss: 0.09260890632867813
Validation loss: 1.4575569680942002

Epoch: 6| Step: 4
Training loss: 0.07546074688434601
Validation loss: 1.4369375859537432

Epoch: 6| Step: 5
Training loss: 0.06287089735269547
Validation loss: 1.425673105383432

Epoch: 6| Step: 6
Training loss: 0.08003470301628113
Validation loss: 1.4169048660544938

Epoch: 6| Step: 7
Training loss: 0.04852835088968277
Validation loss: 1.4301474402027745

Epoch: 6| Step: 8
Training loss: 0.07919146120548248
Validation loss: 1.4135356756948656

Epoch: 6| Step: 9
Training loss: 0.06528396904468536
Validation loss: 1.4020826855013448

Epoch: 6| Step: 10
Training loss: 0.09676811099052429
Validation loss: 1.4330144441255959

Epoch: 6| Step: 11
Training loss: 0.2291031926870346
Validation loss: 1.418228817242448

Epoch: 6| Step: 12
Training loss: 0.11064645648002625
Validation loss: 1.423232360552716

Epoch: 6| Step: 13
Training loss: 0.03975893557071686
Validation loss: 1.424379010354319

Epoch: 542| Step: 0
Training loss: 0.05711092799901962
Validation loss: 1.431308832219852

Epoch: 6| Step: 1
Training loss: 0.04309094697237015
Validation loss: 1.4351468816880257

Epoch: 6| Step: 2
Training loss: 0.0884062647819519
Validation loss: 1.4521036109616678

Epoch: 6| Step: 3
Training loss: 0.08066798746585846
Validation loss: 1.4428157165486326

Epoch: 6| Step: 4
Training loss: 0.04201388359069824
Validation loss: 1.4185464882081555

Epoch: 6| Step: 5
Training loss: 0.0907314270734787
Validation loss: 1.4410733901044375

Epoch: 6| Step: 6
Training loss: 0.18534183502197266
Validation loss: 1.4295945769997054

Epoch: 6| Step: 7
Training loss: 0.07008414715528488
Validation loss: 1.4350197597216534

Epoch: 6| Step: 8
Training loss: 0.055062174797058105
Validation loss: 1.420861150628777

Epoch: 6| Step: 9
Training loss: 0.05802583321928978
Validation loss: 1.4289438737336027

Epoch: 6| Step: 10
Training loss: 0.061744462698698044
Validation loss: 1.4314477917968587

Epoch: 6| Step: 11
Training loss: 0.05318209528923035
Validation loss: 1.4234662414878927

Epoch: 6| Step: 12
Training loss: 0.11195772886276245
Validation loss: 1.4329836868470716

Epoch: 6| Step: 13
Training loss: 0.13068772852420807
Validation loss: 1.4153227754818496

Epoch: 543| Step: 0
Training loss: 0.0753544494509697
Validation loss: 1.4040728422903246

Epoch: 6| Step: 1
Training loss: 0.09522556513547897
Validation loss: 1.409548981215364

Epoch: 6| Step: 2
Training loss: 0.05558014661073685
Validation loss: 1.4299749648699196

Epoch: 6| Step: 3
Training loss: 0.09940838068723679
Validation loss: 1.4165316602235198

Epoch: 6| Step: 4
Training loss: 0.09563885629177094
Validation loss: 1.4252914908111736

Epoch: 6| Step: 5
Training loss: 0.04913899302482605
Validation loss: 1.424582346793144

Epoch: 6| Step: 6
Training loss: 0.053989481180906296
Validation loss: 1.4394464274888397

Epoch: 6| Step: 7
Training loss: 0.08187068998813629
Validation loss: 1.4503829709945186

Epoch: 6| Step: 8
Training loss: 0.09953269362449646
Validation loss: 1.42360056472081

Epoch: 6| Step: 9
Training loss: 0.10121932625770569
Validation loss: 1.440624387033524

Epoch: 6| Step: 10
Training loss: 0.10069197416305542
Validation loss: 1.4335010564455422

Epoch: 6| Step: 11
Training loss: 0.18374399840831757
Validation loss: 1.4179886476967924

Epoch: 6| Step: 12
Training loss: 0.06139323115348816
Validation loss: 1.4052147160294235

Epoch: 6| Step: 13
Training loss: 0.08752057701349258
Validation loss: 1.4002201608432236

Epoch: 544| Step: 0
Training loss: 0.11113445460796356
Validation loss: 1.411780026651198

Epoch: 6| Step: 1
Training loss: 0.08135400712490082
Validation loss: 1.4077915504414549

Epoch: 6| Step: 2
Training loss: 0.20016270875930786
Validation loss: 1.4084374391904442

Epoch: 6| Step: 3
Training loss: 0.09293611347675323
Validation loss: 1.4152025356087634

Epoch: 6| Step: 4
Training loss: 0.04319022223353386
Validation loss: 1.409546701497929

Epoch: 6| Step: 5
Training loss: 0.08237816393375397
Validation loss: 1.3916785973374561

Epoch: 6| Step: 6
Training loss: 0.0722021535038948
Validation loss: 1.3812612333605367

Epoch: 6| Step: 7
Training loss: 0.09011399745941162
Validation loss: 1.3914177635664582

Epoch: 6| Step: 8
Training loss: 0.050904035568237305
Validation loss: 1.4287150829069075

Epoch: 6| Step: 9
Training loss: 0.06608004868030548
Validation loss: 1.4388988107763312

Epoch: 6| Step: 10
Training loss: 0.08435527980327606
Validation loss: 1.4287176478293635

Epoch: 6| Step: 11
Training loss: 0.0687786340713501
Validation loss: 1.4438045896509641

Epoch: 6| Step: 12
Training loss: 0.07507441192865372
Validation loss: 1.4549381220212547

Epoch: 6| Step: 13
Training loss: 0.07201826572418213
Validation loss: 1.4869191223575222

Epoch: 545| Step: 0
Training loss: 0.1264077126979828
Validation loss: 1.4900562532486454

Epoch: 6| Step: 1
Training loss: 0.10880577564239502
Validation loss: 1.4905975146960186

Epoch: 6| Step: 2
Training loss: 0.08118904381990433
Validation loss: 1.4771481175576486

Epoch: 6| Step: 3
Training loss: 0.09608696401119232
Validation loss: 1.4888287590396019

Epoch: 6| Step: 4
Training loss: 0.06412632018327713
Validation loss: 1.480633730529457

Epoch: 6| Step: 5
Training loss: 0.13509289920330048
Validation loss: 1.4984994562723304

Epoch: 6| Step: 6
Training loss: 0.10317480564117432
Validation loss: 1.4913106913207679

Epoch: 6| Step: 7
Training loss: 0.09348490834236145
Validation loss: 1.4397148675816034

Epoch: 6| Step: 8
Training loss: 0.09384357184171677
Validation loss: 1.4529567918469828

Epoch: 6| Step: 9
Training loss: 0.06228805333375931
Validation loss: 1.4497312884176932

Epoch: 6| Step: 10
Training loss: 0.08640776574611664
Validation loss: 1.4496437567536549

Epoch: 6| Step: 11
Training loss: 0.07184481620788574
Validation loss: 1.3983807333054081

Epoch: 6| Step: 12
Training loss: 0.11485641449689865
Validation loss: 1.4095547096703642

Epoch: 6| Step: 13
Training loss: 0.3061258792877197
Validation loss: 1.4200869773023872

Epoch: 546| Step: 0
Training loss: 0.08318866044282913
Validation loss: 1.399435665017815

Epoch: 6| Step: 1
Training loss: 0.0846407487988472
Validation loss: 1.381751653968647

Epoch: 6| Step: 2
Training loss: 0.08882403373718262
Validation loss: 1.411080741113232

Epoch: 6| Step: 3
Training loss: 0.04967162758111954
Validation loss: 1.4306668235409645

Epoch: 6| Step: 4
Training loss: 0.06125947833061218
Validation loss: 1.4143869094951178

Epoch: 6| Step: 5
Training loss: 0.10980360209941864
Validation loss: 1.441988032351258

Epoch: 6| Step: 6
Training loss: 0.09375341236591339
Validation loss: 1.4254518119237756

Epoch: 6| Step: 7
Training loss: 0.082851842045784
Validation loss: 1.4456123434087282

Epoch: 6| Step: 8
Training loss: 0.2728145122528076
Validation loss: 1.4193221792098014

Epoch: 6| Step: 9
Training loss: 0.03611208498477936
Validation loss: 1.3956051052257579

Epoch: 6| Step: 10
Training loss: 0.06923098117113113
Validation loss: 1.3885254539469236

Epoch: 6| Step: 11
Training loss: 0.08610150218009949
Validation loss: 1.3879024450496962

Epoch: 6| Step: 12
Training loss: 0.06570135056972504
Validation loss: 1.3865665389645485

Epoch: 6| Step: 13
Training loss: 0.093792624771595
Validation loss: 1.3907850160393664

Epoch: 547| Step: 0
Training loss: 0.07820270955562592
Validation loss: 1.3769318544736473

Epoch: 6| Step: 1
Training loss: 0.130803182721138
Validation loss: 1.387563596489609

Epoch: 6| Step: 2
Training loss: 0.1782856285572052
Validation loss: 1.388630736258722

Epoch: 6| Step: 3
Training loss: 0.10768523812294006
Validation loss: 1.409938955819735

Epoch: 6| Step: 4
Training loss: 0.05372733995318413
Validation loss: 1.4424747023531186

Epoch: 6| Step: 5
Training loss: 0.09665115922689438
Validation loss: 1.3853119624558317

Epoch: 6| Step: 6
Training loss: 0.08680073171854019
Validation loss: 1.4178365065205483

Epoch: 6| Step: 7
Training loss: 0.0406561940908432
Validation loss: 1.4195507200815345

Epoch: 6| Step: 8
Training loss: 0.06451798975467682
Validation loss: 1.404336683211788

Epoch: 6| Step: 9
Training loss: 0.09334079921245575
Validation loss: 1.4018733668070968

Epoch: 6| Step: 10
Training loss: 0.19516630470752716
Validation loss: 1.4094921081296858

Epoch: 6| Step: 11
Training loss: 0.08632668852806091
Validation loss: 1.4065080188935803

Epoch: 6| Step: 12
Training loss: 0.07320740818977356
Validation loss: 1.4086859341590636

Epoch: 6| Step: 13
Training loss: 0.03422047570347786
Validation loss: 1.4193629667323122

Epoch: 548| Step: 0
Training loss: 0.036171212792396545
Validation loss: 1.4307388772246659

Epoch: 6| Step: 1
Training loss: 0.10176244378089905
Validation loss: 1.4271204522860947

Epoch: 6| Step: 2
Training loss: 0.07082407176494598
Validation loss: 1.4336864345817155

Epoch: 6| Step: 3
Training loss: 0.0423344150185585
Validation loss: 1.408324646693404

Epoch: 6| Step: 4
Training loss: 0.05000030994415283
Validation loss: 1.4015791634077668

Epoch: 6| Step: 5
Training loss: 0.039134882390499115
Validation loss: 1.4139921408827587

Epoch: 6| Step: 6
Training loss: 0.20225080847740173
Validation loss: 1.4185110099854008

Epoch: 6| Step: 7
Training loss: 0.0777432918548584
Validation loss: 1.441441212930987

Epoch: 6| Step: 8
Training loss: 0.06644275784492493
Validation loss: 1.440749474751052

Epoch: 6| Step: 9
Training loss: 0.09893887490034103
Validation loss: 1.4196745605878933

Epoch: 6| Step: 10
Training loss: 0.10767421126365662
Validation loss: 1.4421542652191655

Epoch: 6| Step: 11
Training loss: 0.07080534845590591
Validation loss: 1.4240286190022704

Epoch: 6| Step: 12
Training loss: 0.09601885080337524
Validation loss: 1.4303748902454172

Epoch: 6| Step: 13
Training loss: 0.12032736837863922
Validation loss: 1.4487368663152058

Epoch: 549| Step: 0
Training loss: 0.07039634883403778
Validation loss: 1.434031387811066

Epoch: 6| Step: 1
Training loss: 0.07252824306488037
Validation loss: 1.4476594155834568

Epoch: 6| Step: 2
Training loss: 0.07501780241727829
Validation loss: 1.426209884305154

Epoch: 6| Step: 3
Training loss: 0.09089145064353943
Validation loss: 1.3952930037693312

Epoch: 6| Step: 4
Training loss: 0.12618404626846313
Validation loss: 1.4221598999474638

Epoch: 6| Step: 5
Training loss: 0.055246785283088684
Validation loss: 1.4182886519739706

Epoch: 6| Step: 6
Training loss: 0.05856936424970627
Validation loss: 1.4377525186025968

Epoch: 6| Step: 7
Training loss: 0.06900594383478165
Validation loss: 1.411715643380278

Epoch: 6| Step: 8
Training loss: 0.23438946902751923
Validation loss: 1.4051260717453495

Epoch: 6| Step: 9
Training loss: 0.09868629276752472
Validation loss: 1.4317250559406896

Epoch: 6| Step: 10
Training loss: 0.07796754688024521
Validation loss: 1.4303540427197692

Epoch: 6| Step: 11
Training loss: 0.13309624791145325
Validation loss: 1.413696050643921

Epoch: 6| Step: 12
Training loss: 0.13676568865776062
Validation loss: 1.4141524120043683

Epoch: 6| Step: 13
Training loss: 0.08432189375162125
Validation loss: 1.4336881201754335

Epoch: 550| Step: 0
Training loss: 0.04789712280035019
Validation loss: 1.434242122916765

Epoch: 6| Step: 1
Training loss: 0.031358297914266586
Validation loss: 1.4362162338790072

Epoch: 6| Step: 2
Training loss: 0.08642256259918213
Validation loss: 1.4317636451413553

Epoch: 6| Step: 3
Training loss: 0.06958040595054626
Validation loss: 1.4259013873274609

Epoch: 6| Step: 4
Training loss: 0.08229875564575195
Validation loss: 1.4174824055805002

Epoch: 6| Step: 5
Training loss: 0.05912851542234421
Validation loss: 1.4337394968155892

Epoch: 6| Step: 6
Training loss: 0.07742425799369812
Validation loss: 1.3904391001629572

Epoch: 6| Step: 7
Training loss: 0.06774509698152542
Validation loss: 1.4187016025666268

Epoch: 6| Step: 8
Training loss: 0.07416103035211563
Validation loss: 1.3931085063565163

Epoch: 6| Step: 9
Training loss: 0.20218628644943237
Validation loss: 1.384165980482614

Epoch: 6| Step: 10
Training loss: 0.08166888356208801
Validation loss: 1.4082921064028175

Epoch: 6| Step: 11
Training loss: 0.10340665280818939
Validation loss: 1.41151713684041

Epoch: 6| Step: 12
Training loss: 0.08965366333723068
Validation loss: 1.3918337411777948

Epoch: 6| Step: 13
Training loss: 0.049819257110357285
Validation loss: 1.4090912418980752

Epoch: 551| Step: 0
Training loss: 0.12693427503108978
Validation loss: 1.4003090153458297

Epoch: 6| Step: 1
Training loss: 0.06980763375759125
Validation loss: 1.400141769198961

Epoch: 6| Step: 2
Training loss: 0.04741253703832626
Validation loss: 1.375366953111464

Epoch: 6| Step: 3
Training loss: 0.2017967849969864
Validation loss: 1.368802478236537

Epoch: 6| Step: 4
Training loss: 0.04944422096014023
Validation loss: 1.372991414480312

Epoch: 6| Step: 5
Training loss: 0.0758698359131813
Validation loss: 1.3951932307212584

Epoch: 6| Step: 6
Training loss: 0.11082030087709427
Validation loss: 1.3902292700224026

Epoch: 6| Step: 7
Training loss: 0.08502645790576935
Validation loss: 1.398550538606541

Epoch: 6| Step: 8
Training loss: 0.13832984864711761
Validation loss: 1.4071011107455018

Epoch: 6| Step: 9
Training loss: 0.06386376172304153
Validation loss: 1.4092725182092318

Epoch: 6| Step: 10
Training loss: 0.0661163404583931
Validation loss: 1.4048420677902878

Epoch: 6| Step: 11
Training loss: 0.07803785800933838
Validation loss: 1.4095298154379732

Epoch: 6| Step: 12
Training loss: 0.028495680540800095
Validation loss: 1.4158119360605876

Epoch: 6| Step: 13
Training loss: 0.0336214043200016
Validation loss: 1.4138058282995736

Epoch: 552| Step: 0
Training loss: 0.06242537125945091
Validation loss: 1.427665304112178

Epoch: 6| Step: 1
Training loss: 0.06980305910110474
Validation loss: 1.4254644263175227

Epoch: 6| Step: 2
Training loss: 0.05840137600898743
Validation loss: 1.421703210441015

Epoch: 6| Step: 3
Training loss: 0.08620015531778336
Validation loss: 1.4078858962623022

Epoch: 6| Step: 4
Training loss: 0.2100946605205536
Validation loss: 1.4358646036476217

Epoch: 6| Step: 5
Training loss: 0.05279508978128433
Validation loss: 1.4207434026143884

Epoch: 6| Step: 6
Training loss: 0.10478755831718445
Validation loss: 1.4321001498929915

Epoch: 6| Step: 7
Training loss: 0.07657253742218018
Validation loss: 1.4332320549154793

Epoch: 6| Step: 8
Training loss: 0.07412693649530411
Validation loss: 1.437620230900344

Epoch: 6| Step: 9
Training loss: 0.05132897198200226
Validation loss: 1.402315922962722

Epoch: 6| Step: 10
Training loss: 0.09563528001308441
Validation loss: 1.3818634543367612

Epoch: 6| Step: 11
Training loss: 0.05020088702440262
Validation loss: 1.3842863126467633

Epoch: 6| Step: 12
Training loss: 0.09548605978488922
Validation loss: 1.376785921794112

Epoch: 6| Step: 13
Training loss: 0.04895000532269478
Validation loss: 1.3720238234407158

Epoch: 553| Step: 0
Training loss: 0.0843837559223175
Validation loss: 1.3586368330063359

Epoch: 6| Step: 1
Training loss: 0.04401110112667084
Validation loss: 1.3955170569881317

Epoch: 6| Step: 2
Training loss: 0.07160124182701111
Validation loss: 1.3732058181557605

Epoch: 6| Step: 3
Training loss: 0.07558608055114746
Validation loss: 1.37279728792047

Epoch: 6| Step: 4
Training loss: 0.06049247086048126
Validation loss: 1.3990948456589893

Epoch: 6| Step: 5
Training loss: 0.06592019647359848
Validation loss: 1.377707915921365

Epoch: 6| Step: 6
Training loss: 0.07099731266498566
Validation loss: 1.3948851580260901

Epoch: 6| Step: 7
Training loss: 0.09633129090070724
Validation loss: 1.4125049203954718

Epoch: 6| Step: 8
Training loss: 0.04468044638633728
Validation loss: 1.3729749488574203

Epoch: 6| Step: 9
Training loss: 0.17841264605522156
Validation loss: 1.4314488262258551

Epoch: 6| Step: 10
Training loss: 0.08014257252216339
Validation loss: 1.425432724337424

Epoch: 6| Step: 11
Training loss: 0.07501845806837082
Validation loss: 1.414248247300425

Epoch: 6| Step: 12
Training loss: 0.07540151476860046
Validation loss: 1.412448981756805

Epoch: 6| Step: 13
Training loss: 0.13032226264476776
Validation loss: 1.4283863703409831

Epoch: 554| Step: 0
Training loss: 0.07937471568584442
Validation loss: 1.4368062788440334

Epoch: 6| Step: 1
Training loss: 0.10987457633018494
Validation loss: 1.4314039650783743

Epoch: 6| Step: 2
Training loss: 0.08622545748949051
Validation loss: 1.4241561479465936

Epoch: 6| Step: 3
Training loss: 0.0872674211859703
Validation loss: 1.4391034674900833

Epoch: 6| Step: 4
Training loss: 0.07621286809444427
Validation loss: 1.435612847728114

Epoch: 6| Step: 5
Training loss: 0.1731695830821991
Validation loss: 1.4195433252601213

Epoch: 6| Step: 6
Training loss: 0.049472108483314514
Validation loss: 1.4500985325023692

Epoch: 6| Step: 7
Training loss: 0.07862863689661026
Validation loss: 1.4457607179559686

Epoch: 6| Step: 8
Training loss: 0.06688912212848663
Validation loss: 1.428384070755333

Epoch: 6| Step: 9
Training loss: 0.07660429179668427
Validation loss: 1.4593730101021387

Epoch: 6| Step: 10
Training loss: 0.08294791728258133
Validation loss: 1.4595558015249108

Epoch: 6| Step: 11
Training loss: 0.09879948198795319
Validation loss: 1.452943774961656

Epoch: 6| Step: 12
Training loss: 0.04864911362528801
Validation loss: 1.4316133600409313

Epoch: 6| Step: 13
Training loss: 0.06715069711208344
Validation loss: 1.431709090868632

Epoch: 555| Step: 0
Training loss: 0.030984103679656982
Validation loss: 1.4286416140935754

Epoch: 6| Step: 1
Training loss: 0.08983427286148071
Validation loss: 1.4298808779767764

Epoch: 6| Step: 2
Training loss: 0.1167995035648346
Validation loss: 1.4241231897825837

Epoch: 6| Step: 3
Training loss: 0.05203305929899216
Validation loss: 1.4212479168368923

Epoch: 6| Step: 4
Training loss: 0.055676527321338654
Validation loss: 1.4223152129880843

Epoch: 6| Step: 5
Training loss: 0.21781140565872192
Validation loss: 1.4017489661452591

Epoch: 6| Step: 6
Training loss: 0.07841569185256958
Validation loss: 1.4275107101727558

Epoch: 6| Step: 7
Training loss: 0.062954381108284
Validation loss: 1.4047051937349382

Epoch: 6| Step: 8
Training loss: 0.08103737980127335
Validation loss: 1.4264557784603489

Epoch: 6| Step: 9
Training loss: 0.057379350066185
Validation loss: 1.4485197977353168

Epoch: 6| Step: 10
Training loss: 0.062810018658638
Validation loss: 1.4309952028336064

Epoch: 6| Step: 11
Training loss: 0.06986457109451294
Validation loss: 1.4454977768723682

Epoch: 6| Step: 12
Training loss: 0.06819214671850204
Validation loss: 1.4285204513098604

Epoch: 6| Step: 13
Training loss: 0.09430977702140808
Validation loss: 1.4247980245979883

Epoch: 556| Step: 0
Training loss: 0.21570251882076263
Validation loss: 1.44305552974824

Epoch: 6| Step: 1
Training loss: 0.07294639199972153
Validation loss: 1.4422129943806639

Epoch: 6| Step: 2
Training loss: 0.041612591594457626
Validation loss: 1.4305534503793205

Epoch: 6| Step: 3
Training loss: 0.05736247077584267
Validation loss: 1.4431248095727736

Epoch: 6| Step: 4
Training loss: 0.06180936470627785
Validation loss: 1.4404471651200326

Epoch: 6| Step: 5
Training loss: 0.058285050094127655
Validation loss: 1.4294440272033855

Epoch: 6| Step: 6
Training loss: 0.05257020145654678
Validation loss: 1.433203584404402

Epoch: 6| Step: 7
Training loss: 0.07448486983776093
Validation loss: 1.4183332227891492

Epoch: 6| Step: 8
Training loss: 0.07533740252256393
Validation loss: 1.3992745120038268

Epoch: 6| Step: 9
Training loss: 0.07118046283721924
Validation loss: 1.4196012340566164

Epoch: 6| Step: 10
Training loss: 0.08345186710357666
Validation loss: 1.4302524328231812

Epoch: 6| Step: 11
Training loss: 0.08935481309890747
Validation loss: 1.3984497766340933

Epoch: 6| Step: 12
Training loss: 0.08029171079397202
Validation loss: 1.4152527804015784

Epoch: 6| Step: 13
Training loss: 0.11838609725236893
Validation loss: 1.4285509304333759

Epoch: 557| Step: 0
Training loss: 0.07657019793987274
Validation loss: 1.397057000026908

Epoch: 6| Step: 1
Training loss: 0.04896331951022148
Validation loss: 1.4222327086233324

Epoch: 6| Step: 2
Training loss: 0.07827617228031158
Validation loss: 1.4128765194646773

Epoch: 6| Step: 3
Training loss: 0.08354467153549194
Validation loss: 1.4257831765759377

Epoch: 6| Step: 4
Training loss: 0.08413603156805038
Validation loss: 1.4357328338007773

Epoch: 6| Step: 5
Training loss: 0.04665352404117584
Validation loss: 1.419396742697685

Epoch: 6| Step: 6
Training loss: 0.06031695753335953
Validation loss: 1.4214808940887451

Epoch: 6| Step: 7
Training loss: 0.07907866686582565
Validation loss: 1.4353217796612812

Epoch: 6| Step: 8
Training loss: 0.054560888558626175
Validation loss: 1.4406435810109621

Epoch: 6| Step: 9
Training loss: 0.19025549292564392
Validation loss: 1.4527082904692619

Epoch: 6| Step: 10
Training loss: 0.05675370246171951
Validation loss: 1.4282665009139686

Epoch: 6| Step: 11
Training loss: 0.1202448233962059
Validation loss: 1.4176435255876152

Epoch: 6| Step: 12
Training loss: 0.04941346496343613
Validation loss: 1.4395945187537902

Epoch: 6| Step: 13
Training loss: 0.0640864148736
Validation loss: 1.425303557867645

Epoch: 558| Step: 0
Training loss: 0.06948515772819519
Validation loss: 1.4331255484652776

Epoch: 6| Step: 1
Training loss: 0.09712758660316467
Validation loss: 1.4333701351637482

Epoch: 6| Step: 2
Training loss: 0.06602146476507187
Validation loss: 1.410069655346614

Epoch: 6| Step: 3
Training loss: 0.06427307426929474
Validation loss: 1.415203244455399

Epoch: 6| Step: 4
Training loss: 0.10890388488769531
Validation loss: 1.411201718033001

Epoch: 6| Step: 5
Training loss: 0.055588096380233765
Validation loss: 1.4253859135412401

Epoch: 6| Step: 6
Training loss: 0.09347770363092422
Validation loss: 1.4094926593124226

Epoch: 6| Step: 7
Training loss: 0.055483378469944
Validation loss: 1.4089301273386965

Epoch: 6| Step: 8
Training loss: 0.06534281373023987
Validation loss: 1.3851217518570602

Epoch: 6| Step: 9
Training loss: 0.07115524262189865
Validation loss: 1.405897214848508

Epoch: 6| Step: 10
Training loss: 0.22077205777168274
Validation loss: 1.4093277633831065

Epoch: 6| Step: 11
Training loss: 0.08221698552370071
Validation loss: 1.4111869162128818

Epoch: 6| Step: 12
Training loss: 0.06839923560619354
Validation loss: 1.426456364252234

Epoch: 6| Step: 13
Training loss: 0.08035806566476822
Validation loss: 1.4210775142074914

Epoch: 559| Step: 0
Training loss: 0.054283060133457184
Validation loss: 1.4221889165139967

Epoch: 6| Step: 1
Training loss: 0.04724365472793579
Validation loss: 1.4675311209053121

Epoch: 6| Step: 2
Training loss: 0.1437074840068817
Validation loss: 1.4651343617387997

Epoch: 6| Step: 3
Training loss: 0.09860193729400635
Validation loss: 1.4875465118756859

Epoch: 6| Step: 4
Training loss: 0.10151338577270508
Validation loss: 1.4512740437702467

Epoch: 6| Step: 5
Training loss: 0.0747852772474289
Validation loss: 1.483420757837193

Epoch: 6| Step: 6
Training loss: 0.06183798611164093
Validation loss: 1.4719755777748682

Epoch: 6| Step: 7
Training loss: 0.08389989286661148
Validation loss: 1.4503684761703655

Epoch: 6| Step: 8
Training loss: 0.05752554535865784
Validation loss: 1.4499518640579716

Epoch: 6| Step: 9
Training loss: 0.2544425427913666
Validation loss: 1.4332661000631188

Epoch: 6| Step: 10
Training loss: 0.1195048987865448
Validation loss: 1.4204234371903122

Epoch: 6| Step: 11
Training loss: 0.05022429674863815
Validation loss: 1.3960523977074573

Epoch: 6| Step: 12
Training loss: 0.06262955814599991
Validation loss: 1.4118290473056097

Epoch: 6| Step: 13
Training loss: 0.08720847964286804
Validation loss: 1.387573165278281

Epoch: 560| Step: 0
Training loss: 0.09924701601266861
Validation loss: 1.4222924222228348

Epoch: 6| Step: 1
Training loss: 0.04489007592201233
Validation loss: 1.4071313514504382

Epoch: 6| Step: 2
Training loss: 0.06661830097436905
Validation loss: 1.402428150177002

Epoch: 6| Step: 3
Training loss: 0.07386958599090576
Validation loss: 1.4019814543826605

Epoch: 6| Step: 4
Training loss: 0.04146956652402878
Validation loss: 1.430047967100656

Epoch: 6| Step: 5
Training loss: 0.06914345920085907
Validation loss: 1.425683621437319

Epoch: 6| Step: 6
Training loss: 0.21665064990520477
Validation loss: 1.4188677636525964

Epoch: 6| Step: 7
Training loss: 0.060493431985378265
Validation loss: 1.3895144885586155

Epoch: 6| Step: 8
Training loss: 0.07022661715745926
Validation loss: 1.3980861402327014

Epoch: 6| Step: 9
Training loss: 0.09330211579799652
Validation loss: 1.4251723417671778

Epoch: 6| Step: 10
Training loss: 0.10775241255760193
Validation loss: 1.408667892538091

Epoch: 6| Step: 11
Training loss: 0.056908804923295975
Validation loss: 1.4384824627189225

Epoch: 6| Step: 12
Training loss: 0.06520584225654602
Validation loss: 1.4210189516826341

Epoch: 6| Step: 13
Training loss: 0.1421622484922409
Validation loss: 1.4076935668145456

Epoch: 561| Step: 0
Training loss: 0.08701692521572113
Validation loss: 1.4060563836046445

Epoch: 6| Step: 1
Training loss: 0.07547494024038315
Validation loss: 1.4071088067946895

Epoch: 6| Step: 2
Training loss: 0.057975638657808304
Validation loss: 1.4088698715291998

Epoch: 6| Step: 3
Training loss: 0.05962604656815529
Validation loss: 1.3947724437200895

Epoch: 6| Step: 4
Training loss: 0.1026621162891388
Validation loss: 1.4210348077999648

Epoch: 6| Step: 5
Training loss: 0.08032353967428207
Validation loss: 1.4222724296713387

Epoch: 6| Step: 6
Training loss: 0.0766357034444809
Validation loss: 1.4045664084854947

Epoch: 6| Step: 7
Training loss: 0.07219915091991425
Validation loss: 1.4175091161522815

Epoch: 6| Step: 8
Training loss: 0.23131239414215088
Validation loss: 1.4323969464148245

Epoch: 6| Step: 9
Training loss: 0.09697876125574112
Validation loss: 1.449300701900195

Epoch: 6| Step: 10
Training loss: 0.08521322906017303
Validation loss: 1.4481995259561846

Epoch: 6| Step: 11
Training loss: 0.15107403695583344
Validation loss: 1.4183699366866902

Epoch: 6| Step: 12
Training loss: 0.05389819294214249
Validation loss: 1.4247854384042884

Epoch: 6| Step: 13
Training loss: 0.11844449490308762
Validation loss: 1.4351407199777582

Epoch: 562| Step: 0
Training loss: 0.0395982526242733
Validation loss: 1.4320105865437498

Epoch: 6| Step: 1
Training loss: 0.10870429128408432
Validation loss: 1.4076750688655402

Epoch: 6| Step: 2
Training loss: 0.08636900037527084
Validation loss: 1.4058977903858307

Epoch: 6| Step: 3
Training loss: 0.07385361194610596
Validation loss: 1.427343564007872

Epoch: 6| Step: 4
Training loss: 0.06250015646219254
Validation loss: 1.4178766909465994

Epoch: 6| Step: 5
Training loss: 0.0817970559000969
Validation loss: 1.4434064254965833

Epoch: 6| Step: 6
Training loss: 0.1111149936914444
Validation loss: 1.4466637834425895

Epoch: 6| Step: 7
Training loss: 0.12339898943901062
Validation loss: 1.4575413247590423

Epoch: 6| Step: 8
Training loss: 0.08245733380317688
Validation loss: 1.4339068320489698

Epoch: 6| Step: 9
Training loss: 0.059731245040893555
Validation loss: 1.453751378161933

Epoch: 6| Step: 10
Training loss: 0.11921549588441849
Validation loss: 1.4486814929592995

Epoch: 6| Step: 11
Training loss: 0.2151721715927124
Validation loss: 1.4665862885854577

Epoch: 6| Step: 12
Training loss: 0.07535994797945023
Validation loss: 1.4831944486146331

Epoch: 6| Step: 13
Training loss: 0.11093078553676605
Validation loss: 1.511158517611924

Epoch: 563| Step: 0
Training loss: 0.08700050413608551
Validation loss: 1.4837975437923143

Epoch: 6| Step: 1
Training loss: 0.057562604546546936
Validation loss: 1.456033827156149

Epoch: 6| Step: 2
Training loss: 0.06908944994211197
Validation loss: 1.458183572497419

Epoch: 6| Step: 3
Training loss: 0.051733314990997314
Validation loss: 1.4557463712589715

Epoch: 6| Step: 4
Training loss: 0.09384666383266449
Validation loss: 1.432935345557428

Epoch: 6| Step: 5
Training loss: 0.07903589308261871
Validation loss: 1.4471796610022103

Epoch: 6| Step: 6
Training loss: 0.08032768964767456
Validation loss: 1.4614178455004128

Epoch: 6| Step: 7
Training loss: 0.08942773938179016
Validation loss: 1.4634182799247004

Epoch: 6| Step: 8
Training loss: 0.11112601310014725
Validation loss: 1.4399014365288518

Epoch: 6| Step: 9
Training loss: 0.15409913659095764
Validation loss: 1.4790886486730268

Epoch: 6| Step: 10
Training loss: 0.1446024477481842
Validation loss: 1.4130409468886673

Epoch: 6| Step: 11
Training loss: 0.10657617449760437
Validation loss: 1.4341580149947957

Epoch: 6| Step: 12
Training loss: 0.1867799460887909
Validation loss: 1.4407067606526036

Epoch: 6| Step: 13
Training loss: 0.0556827113032341
Validation loss: 1.457640722233762

Epoch: 564| Step: 0
Training loss: 0.09757977724075317
Validation loss: 1.449277703480054

Epoch: 6| Step: 1
Training loss: 0.07072242349386215
Validation loss: 1.4672447263553579

Epoch: 6| Step: 2
Training loss: 0.22094367444515228
Validation loss: 1.4492186077179448

Epoch: 6| Step: 3
Training loss: 0.1290002316236496
Validation loss: 1.4469161161812403

Epoch: 6| Step: 4
Training loss: 0.08396206051111221
Validation loss: 1.4457465333323325

Epoch: 6| Step: 5
Training loss: 0.06213944032788277
Validation loss: 1.4283693682762884

Epoch: 6| Step: 6
Training loss: 0.05638909712433815
Validation loss: 1.4256845930571198

Epoch: 6| Step: 7
Training loss: 0.06750008463859558
Validation loss: 1.3952872381415418

Epoch: 6| Step: 8
Training loss: 0.09227313101291656
Validation loss: 1.4205361220144457

Epoch: 6| Step: 9
Training loss: 0.0866401344537735
Validation loss: 1.4146190945820143

Epoch: 6| Step: 10
Training loss: 0.0691753625869751
Validation loss: 1.431037393949365

Epoch: 6| Step: 11
Training loss: 0.11028411984443665
Validation loss: 1.4040809414720024

Epoch: 6| Step: 12
Training loss: 0.059939391911029816
Validation loss: 1.3991558679970362

Epoch: 6| Step: 13
Training loss: 0.05693618580698967
Validation loss: 1.3783002207356114

Epoch: 565| Step: 0
Training loss: 0.10301636159420013
Validation loss: 1.3910281901718469

Epoch: 6| Step: 1
Training loss: 0.06458653509616852
Validation loss: 1.404970609372662

Epoch: 6| Step: 2
Training loss: 0.06369199603796005
Validation loss: 1.4003418004640968

Epoch: 6| Step: 3
Training loss: 0.06582623720169067
Validation loss: 1.426137678084835

Epoch: 6| Step: 4
Training loss: 0.09333167970180511
Validation loss: 1.4242261872496655

Epoch: 6| Step: 5
Training loss: 0.04967750608921051
Validation loss: 1.3906839355345695

Epoch: 6| Step: 6
Training loss: 0.08919724822044373
Validation loss: 1.4330318563727922

Epoch: 6| Step: 7
Training loss: 0.06088576093316078
Validation loss: 1.42928094889528

Epoch: 6| Step: 8
Training loss: 0.06685657054185867
Validation loss: 1.4273820718129475

Epoch: 6| Step: 9
Training loss: 0.20179329812526703
Validation loss: 1.441285842208452

Epoch: 6| Step: 10
Training loss: 0.09489801526069641
Validation loss: 1.4338271060297567

Epoch: 6| Step: 11
Training loss: 0.06133691221475601
Validation loss: 1.4315098601002847

Epoch: 6| Step: 12
Training loss: 0.06497813016176224
Validation loss: 1.4207342927173903

Epoch: 6| Step: 13
Training loss: 0.0618201345205307
Validation loss: 1.4347378899974208

Epoch: 566| Step: 0
Training loss: 0.0606268011033535
Validation loss: 1.4012234531423098

Epoch: 6| Step: 1
Training loss: 0.10528664290904999
Validation loss: 1.427625197236256

Epoch: 6| Step: 2
Training loss: 0.08757472038269043
Validation loss: 1.4522773758057625

Epoch: 6| Step: 3
Training loss: 0.0792049765586853
Validation loss: 1.4417803761779622

Epoch: 6| Step: 4
Training loss: 0.06743380427360535
Validation loss: 1.4262705605517152

Epoch: 6| Step: 5
Training loss: 0.09761212021112442
Validation loss: 1.4391140822441346

Epoch: 6| Step: 6
Training loss: 0.11287270486354828
Validation loss: 1.4187939974569506

Epoch: 6| Step: 7
Training loss: 0.052412234246730804
Validation loss: 1.4353177419272802

Epoch: 6| Step: 8
Training loss: 0.0802769884467125
Validation loss: 1.470499014341703

Epoch: 6| Step: 9
Training loss: 0.02805536612868309
Validation loss: 1.4289341267719065

Epoch: 6| Step: 10
Training loss: 0.1827535629272461
Validation loss: 1.4529656928072694

Epoch: 6| Step: 11
Training loss: 0.07753936201334
Validation loss: 1.4599639279868013

Epoch: 6| Step: 12
Training loss: 0.0472598597407341
Validation loss: 1.469031003213698

Epoch: 6| Step: 13
Training loss: 0.07615669816732407
Validation loss: 1.488490116852586

Epoch: 567| Step: 0
Training loss: 0.042666226625442505
Validation loss: 1.4569207429885864

Epoch: 6| Step: 1
Training loss: 0.08385855704545975
Validation loss: 1.4869216718981344

Epoch: 6| Step: 2
Training loss: 0.07543712109327316
Validation loss: 1.4945055477080806

Epoch: 6| Step: 3
Training loss: 0.07422025501728058
Validation loss: 1.4891017476717632

Epoch: 6| Step: 4
Training loss: 0.09394843876361847
Validation loss: 1.4661603486666115

Epoch: 6| Step: 5
Training loss: 0.21042132377624512
Validation loss: 1.487722248159429

Epoch: 6| Step: 6
Training loss: 0.06909003853797913
Validation loss: 1.5013933822672854

Epoch: 6| Step: 7
Training loss: 0.061301931738853455
Validation loss: 1.4817540184144051

Epoch: 6| Step: 8
Training loss: 0.06038037687540054
Validation loss: 1.4557602572184738

Epoch: 6| Step: 9
Training loss: 0.0580659955739975
Validation loss: 1.4360275665918987

Epoch: 6| Step: 10
Training loss: 0.045338716357946396
Validation loss: 1.4304978321957331

Epoch: 6| Step: 11
Training loss: 0.03551433980464935
Validation loss: 1.4255359583003546

Epoch: 6| Step: 12
Training loss: 0.07644540816545486
Validation loss: 1.4324318811457644

Epoch: 6| Step: 13
Training loss: 0.07070062309503555
Validation loss: 1.4196433341631325

Epoch: 568| Step: 0
Training loss: 0.06301744282245636
Validation loss: 1.435040908475076

Epoch: 6| Step: 1
Training loss: 0.23896878957748413
Validation loss: 1.432801572225427

Epoch: 6| Step: 2
Training loss: 0.05287870764732361
Validation loss: 1.4550540306234871

Epoch: 6| Step: 3
Training loss: 0.06125640124082565
Validation loss: 1.4253516056204354

Epoch: 6| Step: 4
Training loss: 0.045681409537792206
Validation loss: 1.4616450058516635

Epoch: 6| Step: 5
Training loss: 0.04423684626817703
Validation loss: 1.436697075443883

Epoch: 6| Step: 6
Training loss: 0.04427714645862579
Validation loss: 1.4667847041160829

Epoch: 6| Step: 7
Training loss: 0.066218800842762
Validation loss: 1.4792285234697404

Epoch: 6| Step: 8
Training loss: 0.08044017106294632
Validation loss: 1.4742065322014593

Epoch: 6| Step: 9
Training loss: 0.04912630841135979
Validation loss: 1.5023065010706584

Epoch: 6| Step: 10
Training loss: 0.0513845831155777
Validation loss: 1.4579210717190978

Epoch: 6| Step: 11
Training loss: 0.07124897837638855
Validation loss: 1.4548107026725687

Epoch: 6| Step: 12
Training loss: 0.044359490275382996
Validation loss: 1.4375343053571639

Epoch: 6| Step: 13
Training loss: 0.04828723147511482
Validation loss: 1.4276445963049447

Epoch: 569| Step: 0
Training loss: 0.07663115113973618
Validation loss: 1.4119566358545774

Epoch: 6| Step: 1
Training loss: 0.06407290697097778
Validation loss: 1.4250824989811066

Epoch: 6| Step: 2
Training loss: 0.05850119888782501
Validation loss: 1.3858335800068353

Epoch: 6| Step: 3
Training loss: 0.07842087745666504
Validation loss: 1.391386470487041

Epoch: 6| Step: 4
Training loss: 0.06306568533182144
Validation loss: 1.3838797589784027

Epoch: 6| Step: 5
Training loss: 0.19402579963207245
Validation loss: 1.4033153967190815

Epoch: 6| Step: 6
Training loss: 0.0744326114654541
Validation loss: 1.4176139344451248

Epoch: 6| Step: 7
Training loss: 0.045528098940849304
Validation loss: 1.424350651361609

Epoch: 6| Step: 8
Training loss: 0.04824419319629669
Validation loss: 1.4182328319036832

Epoch: 6| Step: 9
Training loss: 0.05644531920552254
Validation loss: 1.416095100423341

Epoch: 6| Step: 10
Training loss: 0.05545687675476074
Validation loss: 1.4449484566206574

Epoch: 6| Step: 11
Training loss: 0.07279802858829498
Validation loss: 1.443605121745858

Epoch: 6| Step: 12
Training loss: 0.082011878490448
Validation loss: 1.454000453795156

Epoch: 6| Step: 13
Training loss: 0.07725852727890015
Validation loss: 1.4672478629696755

Epoch: 570| Step: 0
Training loss: 0.1943238377571106
Validation loss: 1.4514668205732941

Epoch: 6| Step: 1
Training loss: 0.07222771644592285
Validation loss: 1.453762908776601

Epoch: 6| Step: 2
Training loss: 0.07168889045715332
Validation loss: 1.4539725229304323

Epoch: 6| Step: 3
Training loss: 0.08736532181501389
Validation loss: 1.4430442240930372

Epoch: 6| Step: 4
Training loss: 0.05158745497465134
Validation loss: 1.4174932638804119

Epoch: 6| Step: 5
Training loss: 0.06989441812038422
Validation loss: 1.4348813372273599

Epoch: 6| Step: 6
Training loss: 0.06365936994552612
Validation loss: 1.4065878442538682

Epoch: 6| Step: 7
Training loss: 0.0551857054233551
Validation loss: 1.4201375220411567

Epoch: 6| Step: 8
Training loss: 0.10240239650011063
Validation loss: 1.415989871947996

Epoch: 6| Step: 9
Training loss: 0.09421145170927048
Validation loss: 1.4094639888373754

Epoch: 6| Step: 10
Training loss: 0.057760320603847504
Validation loss: 1.3871750511148924

Epoch: 6| Step: 11
Training loss: 0.0741148293018341
Validation loss: 1.432403895162767

Epoch: 6| Step: 12
Training loss: 0.04536236822605133
Validation loss: 1.417953436413119

Epoch: 6| Step: 13
Training loss: 0.05635996535420418
Validation loss: 1.406236171722412

Epoch: 571| Step: 0
Training loss: 0.06158025562763214
Validation loss: 1.4001826137624762

Epoch: 6| Step: 1
Training loss: 0.06913270801305771
Validation loss: 1.4031568496457991

Epoch: 6| Step: 2
Training loss: 0.05355222523212433
Validation loss: 1.3997671963066183

Epoch: 6| Step: 3
Training loss: 0.03823414444923401
Validation loss: 1.400954197811824

Epoch: 6| Step: 4
Training loss: 0.04799116402864456
Validation loss: 1.344627111188827

Epoch: 6| Step: 5
Training loss: 0.07263607531785965
Validation loss: 1.36717527720236

Epoch: 6| Step: 6
Training loss: 0.08225955069065094
Validation loss: 1.3846838589637511

Epoch: 6| Step: 7
Training loss: 0.11622579395771027
Validation loss: 1.3691582038838377

Epoch: 6| Step: 8
Training loss: 0.06627237796783447
Validation loss: 1.3572651647752332

Epoch: 6| Step: 9
Training loss: 0.09599136561155319
Validation loss: 1.3450414621701805

Epoch: 6| Step: 10
Training loss: 0.06897974014282227
Validation loss: 1.3722923276244954

Epoch: 6| Step: 11
Training loss: 0.06389350444078445
Validation loss: 1.3847050679627286

Epoch: 6| Step: 12
Training loss: 0.23268403112888336
Validation loss: 1.4101381763335197

Epoch: 6| Step: 13
Training loss: 0.052569225430488586
Validation loss: 1.393418118517886

Epoch: 572| Step: 0
Training loss: 0.047594182193279266
Validation loss: 1.4008887711391653

Epoch: 6| Step: 1
Training loss: 0.06131265312433243
Validation loss: 1.4235232414737824

Epoch: 6| Step: 2
Training loss: 0.18219691514968872
Validation loss: 1.4280844446151488

Epoch: 6| Step: 3
Training loss: 0.07770918309688568
Validation loss: 1.4317166382266628

Epoch: 6| Step: 4
Training loss: 0.059067826718091965
Validation loss: 1.4442701160266835

Epoch: 6| Step: 5
Training loss: 0.061186373233795166
Validation loss: 1.4348980162733345

Epoch: 6| Step: 6
Training loss: 0.08219362795352936
Validation loss: 1.4371403455734253

Epoch: 6| Step: 7
Training loss: 0.04605653136968613
Validation loss: 1.4344545423343618

Epoch: 6| Step: 8
Training loss: 0.05341286212205887
Validation loss: 1.4334348452988492

Epoch: 6| Step: 9
Training loss: 0.06255899369716644
Validation loss: 1.4310155357083967

Epoch: 6| Step: 10
Training loss: 0.0860309973359108
Validation loss: 1.4215780073596584

Epoch: 6| Step: 11
Training loss: 0.06648524105548859
Validation loss: 1.4248688426069034

Epoch: 6| Step: 12
Training loss: 0.05226399749517441
Validation loss: 1.391986749505484

Epoch: 6| Step: 13
Training loss: 0.10164925456047058
Validation loss: 1.417452194357431

Epoch: 573| Step: 0
Training loss: 0.0626087561249733
Validation loss: 1.4521622439866424

Epoch: 6| Step: 1
Training loss: 0.0284670889377594
Validation loss: 1.4256778160730998

Epoch: 6| Step: 2
Training loss: 0.04871160537004471
Validation loss: 1.4309995764045305

Epoch: 6| Step: 3
Training loss: 0.07658255100250244
Validation loss: 1.4210353282190138

Epoch: 6| Step: 4
Training loss: 0.07889091968536377
Validation loss: 1.43188351456837

Epoch: 6| Step: 5
Training loss: 0.08821593970060349
Validation loss: 1.4354570834867415

Epoch: 6| Step: 6
Training loss: 0.05317344516515732
Validation loss: 1.4489856913525572

Epoch: 6| Step: 7
Training loss: 0.04049190506339073
Validation loss: 1.4115409402437107

Epoch: 6| Step: 8
Training loss: 0.18622048199176788
Validation loss: 1.4268704216967347

Epoch: 6| Step: 9
Training loss: 0.06740230321884155
Validation loss: 1.4403275033479095

Epoch: 6| Step: 10
Training loss: 0.056109458208084106
Validation loss: 1.4149538188852289

Epoch: 6| Step: 11
Training loss: 0.07361587136983871
Validation loss: 1.4396073613115536

Epoch: 6| Step: 12
Training loss: 0.05924268811941147
Validation loss: 1.417205850283305

Epoch: 6| Step: 13
Training loss: 0.11234782636165619
Validation loss: 1.4289030887747323

Epoch: 574| Step: 0
Training loss: 0.07950432598590851
Validation loss: 1.4292927826604536

Epoch: 6| Step: 1
Training loss: 0.049312520772218704
Validation loss: 1.4260313023803055

Epoch: 6| Step: 2
Training loss: 0.04275389388203621
Validation loss: 1.421471256081776

Epoch: 6| Step: 3
Training loss: 0.12806525826454163
Validation loss: 1.4220790311854372

Epoch: 6| Step: 4
Training loss: 0.04870814085006714
Validation loss: 1.4382670489690637

Epoch: 6| Step: 5
Training loss: 0.04369951784610748
Validation loss: 1.408688901573099

Epoch: 6| Step: 6
Training loss: 0.0411643385887146
Validation loss: 1.424897692536795

Epoch: 6| Step: 7
Training loss: 0.05229109525680542
Validation loss: 1.3804045325966292

Epoch: 6| Step: 8
Training loss: 0.05254025384783745
Validation loss: 1.4029108670450026

Epoch: 6| Step: 9
Training loss: 0.08307594060897827
Validation loss: 1.4092777582906908

Epoch: 6| Step: 10
Training loss: 0.0603908970952034
Validation loss: 1.4242840825870473

Epoch: 6| Step: 11
Training loss: 0.10749965906143188
Validation loss: 1.4119839783637755

Epoch: 6| Step: 12
Training loss: 0.20814135670661926
Validation loss: 1.3888541088309339

Epoch: 6| Step: 13
Training loss: 0.08355580270290375
Validation loss: 1.4091239295979983

Epoch: 575| Step: 0
Training loss: 0.0701470598578453
Validation loss: 1.4105593799262919

Epoch: 6| Step: 1
Training loss: 0.21775510907173157
Validation loss: 1.4297550186034171

Epoch: 6| Step: 2
Training loss: 0.04419533163309097
Validation loss: 1.4369352684226087

Epoch: 6| Step: 3
Training loss: 0.06446756422519684
Validation loss: 1.463985877652322

Epoch: 6| Step: 4
Training loss: 0.04012032598257065
Validation loss: 1.431181324425564

Epoch: 6| Step: 5
Training loss: 0.06329434365034103
Validation loss: 1.4550041473040016

Epoch: 6| Step: 6
Training loss: 0.08003704994916916
Validation loss: 1.4388800974815124

Epoch: 6| Step: 7
Training loss: 0.07146026194095612
Validation loss: 1.440100989034099

Epoch: 6| Step: 8
Training loss: 0.05666758865118027
Validation loss: 1.4477426057220788

Epoch: 6| Step: 9
Training loss: 0.06692902743816376
Validation loss: 1.4295761226325907

Epoch: 6| Step: 10
Training loss: 0.08007782697677612
Validation loss: 1.4249208274707998

Epoch: 6| Step: 11
Training loss: 0.04493574798107147
Validation loss: 1.4444183098372592

Epoch: 6| Step: 12
Training loss: 0.05975450575351715
Validation loss: 1.4336884310168605

Epoch: 6| Step: 13
Training loss: 0.039431557059288025
Validation loss: 1.4321185004326604

Epoch: 576| Step: 0
Training loss: 0.07513944804668427
Validation loss: 1.4458276264129146

Epoch: 6| Step: 1
Training loss: 0.024399789050221443
Validation loss: 1.4276853761365336

Epoch: 6| Step: 2
Training loss: 0.08481346815824509
Validation loss: 1.4309284430678173

Epoch: 6| Step: 3
Training loss: 0.05074179545044899
Validation loss: 1.4302653766447497

Epoch: 6| Step: 4
Training loss: 0.05129465460777283
Validation loss: 1.454884233013276

Epoch: 6| Step: 5
Training loss: 0.06356877088546753
Validation loss: 1.4265147063039965

Epoch: 6| Step: 6
Training loss: 0.0792384073138237
Validation loss: 1.437161482790465

Epoch: 6| Step: 7
Training loss: 0.07121915370225906
Validation loss: 1.4277176267357283

Epoch: 6| Step: 8
Training loss: 0.06746044754981995
Validation loss: 1.4285623206887195

Epoch: 6| Step: 9
Training loss: 0.06135523319244385
Validation loss: 1.3929631261415378

Epoch: 6| Step: 10
Training loss: 0.08335894346237183
Validation loss: 1.3891036074648622

Epoch: 6| Step: 11
Training loss: 0.18934790790081024
Validation loss: 1.4187266083173855

Epoch: 6| Step: 12
Training loss: 0.06596007943153381
Validation loss: 1.4220818601628786

Epoch: 6| Step: 13
Training loss: 0.07717463374137878
Validation loss: 1.435079272075366

Epoch: 577| Step: 0
Training loss: 0.07912788540124893
Validation loss: 1.4027844449525237

Epoch: 6| Step: 1
Training loss: 0.17971867322921753
Validation loss: 1.4073455128618466

Epoch: 6| Step: 2
Training loss: 0.056594908237457275
Validation loss: 1.42712370041878

Epoch: 6| Step: 3
Training loss: 0.08623862266540527
Validation loss: 1.4208499090645903

Epoch: 6| Step: 4
Training loss: 0.07321144640445709
Validation loss: 1.3796565981321438

Epoch: 6| Step: 5
Training loss: 0.059091515839099884
Validation loss: 1.3927202775914183

Epoch: 6| Step: 6
Training loss: 0.1102103665471077
Validation loss: 1.377671915997741

Epoch: 6| Step: 7
Training loss: 0.08699661493301392
Validation loss: 1.396752513864989

Epoch: 6| Step: 8
Training loss: 0.05940931662917137
Validation loss: 1.4038168358546432

Epoch: 6| Step: 9
Training loss: 0.04313836246728897
Validation loss: 1.4116034917933966

Epoch: 6| Step: 10
Training loss: 0.0505816824734211
Validation loss: 1.4326128985292168

Epoch: 6| Step: 11
Training loss: 0.10627833008766174
Validation loss: 1.4205070657114829

Epoch: 6| Step: 12
Training loss: 0.05317948758602142
Validation loss: 1.4320586041737629

Epoch: 6| Step: 13
Training loss: 0.1038382425904274
Validation loss: 1.423864508828809

Epoch: 578| Step: 0
Training loss: 0.08136789500713348
Validation loss: 1.4211374700710337

Epoch: 6| Step: 1
Training loss: 0.08339035511016846
Validation loss: 1.4391159947200487

Epoch: 6| Step: 2
Training loss: 0.08162042498588562
Validation loss: 1.4414581585955877

Epoch: 6| Step: 3
Training loss: 0.0534568727016449
Validation loss: 1.437261712166571

Epoch: 6| Step: 4
Training loss: 0.17786788940429688
Validation loss: 1.4220839815755044

Epoch: 6| Step: 5
Training loss: 0.10399531573057175
Validation loss: 1.4507274909686017

Epoch: 6| Step: 6
Training loss: 0.05859088525176048
Validation loss: 1.42510857248819

Epoch: 6| Step: 7
Training loss: 0.0813080221414566
Validation loss: 1.4480805704670567

Epoch: 6| Step: 8
Training loss: 0.08349614590406418
Validation loss: 1.4413133026451193

Epoch: 6| Step: 9
Training loss: 0.06038375198841095
Validation loss: 1.4365371542592202

Epoch: 6| Step: 10
Training loss: 0.07289721816778183
Validation loss: 1.444954849058582

Epoch: 6| Step: 11
Training loss: 0.09297951310873032
Validation loss: 1.4409238676871023

Epoch: 6| Step: 12
Training loss: 0.04826388508081436
Validation loss: 1.438483799657514

Epoch: 6| Step: 13
Training loss: 0.044276997447013855
Validation loss: 1.4200771765042377

Epoch: 579| Step: 0
Training loss: 0.05878114700317383
Validation loss: 1.43824141768999

Epoch: 6| Step: 1
Training loss: 0.20455580949783325
Validation loss: 1.4184506798303256

Epoch: 6| Step: 2
Training loss: 0.056831493973731995
Validation loss: 1.4082294625620688

Epoch: 6| Step: 3
Training loss: 0.12755858898162842
Validation loss: 1.4189872959608674

Epoch: 6| Step: 4
Training loss: 0.04217886924743652
Validation loss: 1.4023464431044876

Epoch: 6| Step: 5
Training loss: 0.06849826872348785
Validation loss: 1.3904969974230694

Epoch: 6| Step: 6
Training loss: 0.07582483440637589
Validation loss: 1.4010415064391268

Epoch: 6| Step: 7
Training loss: 0.07524337619543076
Validation loss: 1.4144107077711372

Epoch: 6| Step: 8
Training loss: 0.050342775881290436
Validation loss: 1.3977073584833453

Epoch: 6| Step: 9
Training loss: 0.04612020403146744
Validation loss: 1.3895240240199591

Epoch: 6| Step: 10
Training loss: 0.05922475457191467
Validation loss: 1.3883012161459973

Epoch: 6| Step: 11
Training loss: 0.08616763353347778
Validation loss: 1.3945345609418807

Epoch: 6| Step: 12
Training loss: 0.04049421846866608
Validation loss: 1.4081038339163667

Epoch: 6| Step: 13
Training loss: 0.06751661747694016
Validation loss: 1.403530910450925

Epoch: 580| Step: 0
Training loss: 0.11609221994876862
Validation loss: 1.408036999164089

Epoch: 6| Step: 1
Training loss: 0.086946502327919
Validation loss: 1.4455348676250828

Epoch: 6| Step: 2
Training loss: 0.0807151347398758
Validation loss: 1.410157290838098

Epoch: 6| Step: 3
Training loss: 0.05017564818263054
Validation loss: 1.4159318644513366

Epoch: 6| Step: 4
Training loss: 0.07491403073072433
Validation loss: 1.4129975444527083

Epoch: 6| Step: 5
Training loss: 0.1849273294210434
Validation loss: 1.4257632583700202

Epoch: 6| Step: 6
Training loss: 0.06104408949613571
Validation loss: 1.3951888545866935

Epoch: 6| Step: 7
Training loss: 0.03357774019241333
Validation loss: 1.3984722565579157

Epoch: 6| Step: 8
Training loss: 0.05709388107061386
Validation loss: 1.4174208243687947

Epoch: 6| Step: 9
Training loss: 0.049204811453819275
Validation loss: 1.4580233443167903

Epoch: 6| Step: 10
Training loss: 0.07351931929588318
Validation loss: 1.4425613777611845

Epoch: 6| Step: 11
Training loss: 0.06922715902328491
Validation loss: 1.4610549890866844

Epoch: 6| Step: 12
Training loss: 0.08070560544729233
Validation loss: 1.4494794696889899

Epoch: 6| Step: 13
Training loss: 0.05534258112311363
Validation loss: 1.4350727027462375

Epoch: 581| Step: 0
Training loss: 0.12268811464309692
Validation loss: 1.4652122630867908

Epoch: 6| Step: 1
Training loss: 0.04984160512685776
Validation loss: 1.447605271493235

Epoch: 6| Step: 2
Training loss: 0.20179636776447296
Validation loss: 1.4453643893682828

Epoch: 6| Step: 3
Training loss: 0.06943497061729431
Validation loss: 1.4378194905096484

Epoch: 6| Step: 4
Training loss: 0.08995764702558517
Validation loss: 1.4127167540211831

Epoch: 6| Step: 5
Training loss: 0.047628410160541534
Validation loss: 1.429796920027784

Epoch: 6| Step: 6
Training loss: 0.06763111799955368
Validation loss: 1.4175042401077926

Epoch: 6| Step: 7
Training loss: 0.07300862669944763
Validation loss: 1.4198725928542435

Epoch: 6| Step: 8
Training loss: 0.04546953737735748
Validation loss: 1.4111376321443947

Epoch: 6| Step: 9
Training loss: 0.07489437609910965
Validation loss: 1.3768384520725538

Epoch: 6| Step: 10
Training loss: 0.03969203680753708
Validation loss: 1.4070963366057283

Epoch: 6| Step: 11
Training loss: 0.03834179416298866
Validation loss: 1.394205653539268

Epoch: 6| Step: 12
Training loss: 0.03086547553539276
Validation loss: 1.3597840660361833

Epoch: 6| Step: 13
Training loss: 0.06243160739541054
Validation loss: 1.3614791311243528

Epoch: 582| Step: 0
Training loss: 0.06423855572938919
Validation loss: 1.3804414528672413

Epoch: 6| Step: 1
Training loss: 0.11346409469842911
Validation loss: 1.3692374678068264

Epoch: 6| Step: 2
Training loss: 0.07524321973323822
Validation loss: 1.3618689647284887

Epoch: 6| Step: 3
Training loss: 0.05384105443954468
Validation loss: 1.3491291884453065

Epoch: 6| Step: 4
Training loss: 0.12444518506526947
Validation loss: 1.3708357734064902

Epoch: 6| Step: 5
Training loss: 0.058582305908203125
Validation loss: 1.3643300200021395

Epoch: 6| Step: 6
Training loss: 0.20468781888484955
Validation loss: 1.3883976333884782

Epoch: 6| Step: 7
Training loss: 0.05227196589112282
Validation loss: 1.3819182829190326

Epoch: 6| Step: 8
Training loss: 0.06813594698905945
Validation loss: 1.3774493804541967

Epoch: 6| Step: 9
Training loss: 0.05550935119390488
Validation loss: 1.4242811792640275

Epoch: 6| Step: 10
Training loss: 0.06787289679050446
Validation loss: 1.41122765310349

Epoch: 6| Step: 11
Training loss: 0.06010589748620987
Validation loss: 1.4278217900183894

Epoch: 6| Step: 12
Training loss: 0.07520686089992523
Validation loss: 1.4044280270094514

Epoch: 6| Step: 13
Training loss: 0.04125164449214935
Validation loss: 1.451828945067621

Epoch: 583| Step: 0
Training loss: 0.08330830931663513
Validation loss: 1.4207687608657344

Epoch: 6| Step: 1
Training loss: 0.040288060903549194
Validation loss: 1.4484630656498734

Epoch: 6| Step: 2
Training loss: 0.06933337450027466
Validation loss: 1.4613919386299707

Epoch: 6| Step: 3
Training loss: 0.05654948204755783
Validation loss: 1.4764509329231836

Epoch: 6| Step: 4
Training loss: 0.1849166601896286
Validation loss: 1.4841825462156726

Epoch: 6| Step: 5
Training loss: 0.05731046944856644
Validation loss: 1.466623984357362

Epoch: 6| Step: 6
Training loss: 0.09207567572593689
Validation loss: 1.4658833114049767

Epoch: 6| Step: 7
Training loss: 0.0577128604054451
Validation loss: 1.4464330557853944

Epoch: 6| Step: 8
Training loss: 0.042688995599746704
Validation loss: 1.4245790922513573

Epoch: 6| Step: 9
Training loss: 0.05288742855191231
Validation loss: 1.4246669264249905

Epoch: 6| Step: 10
Training loss: 0.050533778965473175
Validation loss: 1.4310765227963846

Epoch: 6| Step: 11
Training loss: 0.05334920063614845
Validation loss: 1.3960319719006937

Epoch: 6| Step: 12
Training loss: 0.059731077402830124
Validation loss: 1.4251698691357848

Epoch: 6| Step: 13
Training loss: 0.05726144090294838
Validation loss: 1.3754514801886775

Epoch: 584| Step: 0
Training loss: 0.0751863569021225
Validation loss: 1.3912513730346516

Epoch: 6| Step: 1
Training loss: 0.09597248584032059
Validation loss: 1.3935220010818974

Epoch: 6| Step: 2
Training loss: 0.10946394503116608
Validation loss: 1.395941178003947

Epoch: 6| Step: 3
Training loss: 0.07275130599737167
Validation loss: 1.3991377545941261

Epoch: 6| Step: 4
Training loss: 0.07198990136384964
Validation loss: 1.3763321163833782

Epoch: 6| Step: 5
Training loss: 0.08585470169782639
Validation loss: 1.3921782816610029

Epoch: 6| Step: 6
Training loss: 0.08960249274969101
Validation loss: 1.4036725971006578

Epoch: 6| Step: 7
Training loss: 0.08521252870559692
Validation loss: 1.39392521432651

Epoch: 6| Step: 8
Training loss: 0.2230599820613861
Validation loss: 1.404773787785602

Epoch: 6| Step: 9
Training loss: 0.07205052673816681
Validation loss: 1.3668079953039847

Epoch: 6| Step: 10
Training loss: 0.057913973927497864
Validation loss: 1.367094987182207

Epoch: 6| Step: 11
Training loss: 0.12844055891036987
Validation loss: 1.3506080745368876

Epoch: 6| Step: 12
Training loss: 0.07704398036003113
Validation loss: 1.359044216012442

Epoch: 6| Step: 13
Training loss: 0.12347725033760071
Validation loss: 1.3676479567763626

Epoch: 585| Step: 0
Training loss: 0.10848113149404526
Validation loss: 1.4046897888183594

Epoch: 6| Step: 1
Training loss: 0.08116453886032104
Validation loss: 1.3858369412601634

Epoch: 6| Step: 2
Training loss: 0.09799113124608994
Validation loss: 1.417310062275138

Epoch: 6| Step: 3
Training loss: 0.09165608882904053
Validation loss: 1.4016559290629562

Epoch: 6| Step: 4
Training loss: 0.07766488194465637
Validation loss: 1.4300511947242163

Epoch: 6| Step: 5
Training loss: 0.096085324883461
Validation loss: 1.418680585840697

Epoch: 6| Step: 6
Training loss: 0.05702164024114609
Validation loss: 1.396279332458332

Epoch: 6| Step: 7
Training loss: 0.05191469192504883
Validation loss: 1.4310694894483011

Epoch: 6| Step: 8
Training loss: 0.23373034596443176
Validation loss: 1.4056667461190173

Epoch: 6| Step: 9
Training loss: 0.04207810014486313
Validation loss: 1.38871733860303

Epoch: 6| Step: 10
Training loss: 0.04426342993974686
Validation loss: 1.382731487674098

Epoch: 6| Step: 11
Training loss: 0.12044810503721237
Validation loss: 1.3945330804394138

Epoch: 6| Step: 12
Training loss: 0.07798706740140915
Validation loss: 1.408822597995881

Epoch: 6| Step: 13
Training loss: 0.16627679765224457
Validation loss: 1.3841518919955018

Epoch: 586| Step: 0
Training loss: 0.06825979053974152
Validation loss: 1.3891534869388869

Epoch: 6| Step: 1
Training loss: 0.08231418579816818
Validation loss: 1.44828837789515

Epoch: 6| Step: 2
Training loss: 0.22525200247764587
Validation loss: 1.41296039858172

Epoch: 6| Step: 3
Training loss: 0.05209343880414963
Validation loss: 1.4341261143325477

Epoch: 6| Step: 4
Training loss: 0.1105012446641922
Validation loss: 1.4277978879149242

Epoch: 6| Step: 5
Training loss: 0.09706539660692215
Validation loss: 1.4380358983111639

Epoch: 6| Step: 6
Training loss: 0.10947646200656891
Validation loss: 1.4869214821887273

Epoch: 6| Step: 7
Training loss: 0.07698746025562286
Validation loss: 1.4512756306638

Epoch: 6| Step: 8
Training loss: 0.0798082947731018
Validation loss: 1.4627897547137352

Epoch: 6| Step: 9
Training loss: 0.07656396925449371
Validation loss: 1.4415984813885023

Epoch: 6| Step: 10
Training loss: 0.07350809872150421
Validation loss: 1.4368153470818714

Epoch: 6| Step: 11
Training loss: 0.06654666364192963
Validation loss: 1.4276338456779398

Epoch: 6| Step: 12
Training loss: 0.07745037972927094
Validation loss: 1.4193579221284518

Epoch: 6| Step: 13
Training loss: 0.053171779960393906
Validation loss: 1.4210308456933627

Epoch: 587| Step: 0
Training loss: 0.09219401329755783
Validation loss: 1.4128699815401466

Epoch: 6| Step: 1
Training loss: 0.05181848257780075
Validation loss: 1.3953502370465187

Epoch: 6| Step: 2
Training loss: 0.08083313703536987
Validation loss: 1.4105979242632467

Epoch: 6| Step: 3
Training loss: 0.06943023204803467
Validation loss: 1.3570947160003006

Epoch: 6| Step: 4
Training loss: 0.10668227076530457
Validation loss: 1.3915653715851486

Epoch: 6| Step: 5
Training loss: 0.0836096853017807
Validation loss: 1.3791081238818426

Epoch: 6| Step: 6
Training loss: 0.05465900897979736
Validation loss: 1.3690102433645597

Epoch: 6| Step: 7
Training loss: 0.04618212953209877
Validation loss: 1.4129159553076631

Epoch: 6| Step: 8
Training loss: 0.20771168172359467
Validation loss: 1.4042908997945889

Epoch: 6| Step: 9
Training loss: 0.06665222346782684
Validation loss: 1.4093044868079565

Epoch: 6| Step: 10
Training loss: 0.07900518923997879
Validation loss: 1.3983345057374688

Epoch: 6| Step: 11
Training loss: 0.07871448993682861
Validation loss: 1.3805662124387679

Epoch: 6| Step: 12
Training loss: 0.08623282611370087
Validation loss: 1.395309676406204

Epoch: 6| Step: 13
Training loss: 0.10091926157474518
Validation loss: 1.3674291923481932

Epoch: 588| Step: 0
Training loss: 0.03705417364835739
Validation loss: 1.3550946340766004

Epoch: 6| Step: 1
Training loss: 0.05440244823694229
Validation loss: 1.3586207333431448

Epoch: 6| Step: 2
Training loss: 0.04411543905735016
Validation loss: 1.3619153140693583

Epoch: 6| Step: 3
Training loss: 0.06379163265228271
Validation loss: 1.3870500133883568

Epoch: 6| Step: 4
Training loss: 0.06751996278762817
Validation loss: 1.373867627113096

Epoch: 6| Step: 5
Training loss: 0.04676768183708191
Validation loss: 1.3589419479011207

Epoch: 6| Step: 6
Training loss: 0.05348825454711914
Validation loss: 1.3665883162970185

Epoch: 6| Step: 7
Training loss: 0.08247940987348557
Validation loss: 1.3746279452436714

Epoch: 6| Step: 8
Training loss: 0.05949859693646431
Validation loss: 1.3621099700209915

Epoch: 6| Step: 9
Training loss: 0.06748281419277191
Validation loss: 1.3752034498799233

Epoch: 6| Step: 10
Training loss: 0.07391710579395294
Validation loss: 1.3988915258838284

Epoch: 6| Step: 11
Training loss: 0.04542437195777893
Validation loss: 1.400981967808098

Epoch: 6| Step: 12
Training loss: 0.1801959127187729
Validation loss: 1.3865799186050252

Epoch: 6| Step: 13
Training loss: 0.04149554669857025
Validation loss: 1.388598003695088

Epoch: 589| Step: 0
Training loss: 0.07110630720853806
Validation loss: 1.4004005539801814

Epoch: 6| Step: 1
Training loss: 0.04176142066717148
Validation loss: 1.4120401925938104

Epoch: 6| Step: 2
Training loss: 0.06285169720649719
Validation loss: 1.4081166905741538

Epoch: 6| Step: 3
Training loss: 0.04882131144404411
Validation loss: 1.37232833011176

Epoch: 6| Step: 4
Training loss: 0.04409956559538841
Validation loss: 1.4126163374993108

Epoch: 6| Step: 5
Training loss: 0.05192093551158905
Validation loss: 1.4041909235779957

Epoch: 6| Step: 6
Training loss: 0.06910210102796555
Validation loss: 1.4116386828884002

Epoch: 6| Step: 7
Training loss: 0.10286872833967209
Validation loss: 1.3884955849698795

Epoch: 6| Step: 8
Training loss: 0.063592329621315
Validation loss: 1.3954056155297063

Epoch: 6| Step: 9
Training loss: 0.06426547467708588
Validation loss: 1.3611623471783054

Epoch: 6| Step: 10
Training loss: 0.03727599233388901
Validation loss: 1.3807228688270814

Epoch: 6| Step: 11
Training loss: 0.21135616302490234
Validation loss: 1.4040555569433397

Epoch: 6| Step: 12
Training loss: 0.0415225476026535
Validation loss: 1.3926663129560408

Epoch: 6| Step: 13
Training loss: 0.04829803481698036
Validation loss: 1.392064695717186

Epoch: 590| Step: 0
Training loss: 0.04952061176300049
Validation loss: 1.3896715987113215

Epoch: 6| Step: 1
Training loss: 0.09589982032775879
Validation loss: 1.411439436738209

Epoch: 6| Step: 2
Training loss: 0.1033107116818428
Validation loss: 1.439093989710654

Epoch: 6| Step: 3
Training loss: 0.1435047835111618
Validation loss: 1.459544768897436

Epoch: 6| Step: 4
Training loss: 0.13246911764144897
Validation loss: 1.437367436706379

Epoch: 6| Step: 5
Training loss: 0.06187213212251663
Validation loss: 1.4027156137651013

Epoch: 6| Step: 6
Training loss: 0.04033881425857544
Validation loss: 1.3815493763134044

Epoch: 6| Step: 7
Training loss: 0.09466907382011414
Validation loss: 1.3831201355944398

Epoch: 6| Step: 8
Training loss: 0.2058108150959015
Validation loss: 1.3872858631995417

Epoch: 6| Step: 9
Training loss: 0.06867996603250504
Validation loss: 1.400987014975599

Epoch: 6| Step: 10
Training loss: 0.11395007371902466
Validation loss: 1.3833908419455252

Epoch: 6| Step: 11
Training loss: 0.08906006813049316
Validation loss: 1.3948942070366235

Epoch: 6| Step: 12
Training loss: 0.031238920986652374
Validation loss: 1.3682698524126442

Epoch: 6| Step: 13
Training loss: 0.061903756111860275
Validation loss: 1.371839028532787

Epoch: 591| Step: 0
Training loss: 0.054501406848430634
Validation loss: 1.4056815921619374

Epoch: 6| Step: 1
Training loss: 0.06927823275327682
Validation loss: 1.3956383505175192

Epoch: 6| Step: 2
Training loss: 0.07652996480464935
Validation loss: 1.4243788155176307

Epoch: 6| Step: 3
Training loss: 0.08851583302021027
Validation loss: 1.438650381180548

Epoch: 6| Step: 4
Training loss: 0.03583522140979767
Validation loss: 1.4220603194928938

Epoch: 6| Step: 5
Training loss: 0.04996183142066002
Validation loss: 1.4491849535255021

Epoch: 6| Step: 6
Training loss: 0.048875078558921814
Validation loss: 1.4364522016176613

Epoch: 6| Step: 7
Training loss: 0.07196754217147827
Validation loss: 1.4428679904630106

Epoch: 6| Step: 8
Training loss: 0.20475536584854126
Validation loss: 1.4472973660756183

Epoch: 6| Step: 9
Training loss: 0.06294907629489899
Validation loss: 1.4363074148854902

Epoch: 6| Step: 10
Training loss: 0.08010980486869812
Validation loss: 1.4532495801166823

Epoch: 6| Step: 11
Training loss: 0.04771909862756729
Validation loss: 1.456691103596841

Epoch: 6| Step: 12
Training loss: 0.04150097817182541
Validation loss: 1.4465768164204014

Epoch: 6| Step: 13
Training loss: 0.03757195919752121
Validation loss: 1.4667766350571827

Epoch: 592| Step: 0
Training loss: 0.0811840370297432
Validation loss: 1.4254621433955368

Epoch: 6| Step: 1
Training loss: 0.056335464119911194
Validation loss: 1.4325162262044928

Epoch: 6| Step: 2
Training loss: 0.04569782689213753
Validation loss: 1.4210943060536538

Epoch: 6| Step: 3
Training loss: 0.04263126105070114
Validation loss: 1.428159768863391

Epoch: 6| Step: 4
Training loss: 0.0595782995223999
Validation loss: 1.4198261396859282

Epoch: 6| Step: 5
Training loss: 0.0865136981010437
Validation loss: 1.416486878548899

Epoch: 6| Step: 6
Training loss: 0.039547428488731384
Validation loss: 1.4371716027618737

Epoch: 6| Step: 7
Training loss: 0.06642740219831467
Validation loss: 1.4256842802929621

Epoch: 6| Step: 8
Training loss: 0.06470752507448196
Validation loss: 1.4238611062367756

Epoch: 6| Step: 9
Training loss: 0.1772775799036026
Validation loss: 1.3952343649761652

Epoch: 6| Step: 10
Training loss: 0.035710178315639496
Validation loss: 1.4206347068150837

Epoch: 6| Step: 11
Training loss: 0.05756104737520218
Validation loss: 1.4507820663913604

Epoch: 6| Step: 12
Training loss: 0.05081869661808014
Validation loss: 1.4370547930399578

Epoch: 6| Step: 13
Training loss: 0.04800472408533096
Validation loss: 1.4461072811516382

Epoch: 593| Step: 0
Training loss: 0.19635452330112457
Validation loss: 1.4135241739211544

Epoch: 6| Step: 1
Training loss: 0.08170603960752487
Validation loss: 1.4156307225586267

Epoch: 6| Step: 2
Training loss: 0.070203498005867
Validation loss: 1.428960661734304

Epoch: 6| Step: 3
Training loss: 0.055218178778886795
Validation loss: 1.431019765074535

Epoch: 6| Step: 4
Training loss: 0.032236117869615555
Validation loss: 1.4205967546791158

Epoch: 6| Step: 5
Training loss: 0.0559561625123024
Validation loss: 1.4158465195727605

Epoch: 6| Step: 6
Training loss: 0.07282871007919312
Validation loss: 1.4014694479203993

Epoch: 6| Step: 7
Training loss: 0.03890469670295715
Validation loss: 1.4116246866923507

Epoch: 6| Step: 8
Training loss: 0.07915821671485901
Validation loss: 1.402596826194435

Epoch: 6| Step: 9
Training loss: 0.0575389638543129
Validation loss: 1.4325550063963859

Epoch: 6| Step: 10
Training loss: 0.08599436283111572
Validation loss: 1.408971441689358

Epoch: 6| Step: 11
Training loss: 0.061595018953084946
Validation loss: 1.4164373772118681

Epoch: 6| Step: 12
Training loss: 0.09276871383190155
Validation loss: 1.4077081238069842

Epoch: 6| Step: 13
Training loss: 0.02828807942569256
Validation loss: 1.3978390706482755

Epoch: 594| Step: 0
Training loss: 0.05526747554540634
Validation loss: 1.4048395541406447

Epoch: 6| Step: 1
Training loss: 0.05215150862932205
Validation loss: 1.420262248285355

Epoch: 6| Step: 2
Training loss: 0.03917749598622322
Validation loss: 1.3890717593572472

Epoch: 6| Step: 3
Training loss: 0.059591472148895264
Validation loss: 1.4087522427241008

Epoch: 6| Step: 4
Training loss: 0.04421905055642128
Validation loss: 1.3805519470604517

Epoch: 6| Step: 5
Training loss: 0.055126968771219254
Validation loss: 1.419119264489861

Epoch: 6| Step: 6
Training loss: 0.06433356553316116
Validation loss: 1.43012523522941

Epoch: 6| Step: 7
Training loss: 0.0823255330324173
Validation loss: 1.4186383229430004

Epoch: 6| Step: 8
Training loss: 0.19980627298355103
Validation loss: 1.3813699624871696

Epoch: 6| Step: 9
Training loss: 0.06810696423053741
Validation loss: 1.4115754955558366

Epoch: 6| Step: 10
Training loss: 0.0490422286093235
Validation loss: 1.413844305981872

Epoch: 6| Step: 11
Training loss: 0.0496658980846405
Validation loss: 1.418239370469124

Epoch: 6| Step: 12
Training loss: 0.046116605401039124
Validation loss: 1.413519746513777

Epoch: 6| Step: 13
Training loss: 0.04001687467098236
Validation loss: 1.4040378255228843

Epoch: 595| Step: 0
Training loss: 0.05975288897752762
Validation loss: 1.3905878605381135

Epoch: 6| Step: 1
Training loss: 0.09897531569004059
Validation loss: 1.435546589154069

Epoch: 6| Step: 2
Training loss: 0.08887051790952682
Validation loss: 1.4127918520281393

Epoch: 6| Step: 3
Training loss: 0.03143225610256195
Validation loss: 1.4182939157691052

Epoch: 6| Step: 4
Training loss: 0.04502132534980774
Validation loss: 1.4076533362429628

Epoch: 6| Step: 5
Training loss: 0.06652338802814484
Validation loss: 1.4200775879685597

Epoch: 6| Step: 6
Training loss: 0.05256204679608345
Validation loss: 1.4056496581723612

Epoch: 6| Step: 7
Training loss: 0.18321780860424042
Validation loss: 1.3628681532798275

Epoch: 6| Step: 8
Training loss: 0.059071071445941925
Validation loss: 1.3754992792683263

Epoch: 6| Step: 9
Training loss: 0.05656792223453522
Validation loss: 1.3797986879143664

Epoch: 6| Step: 10
Training loss: 0.047357119619846344
Validation loss: 1.3692853373865927

Epoch: 6| Step: 11
Training loss: 0.07855182886123657
Validation loss: 1.3656702727399848

Epoch: 6| Step: 12
Training loss: 0.05423590913414955
Validation loss: 1.3846430458048338

Epoch: 6| Step: 13
Training loss: 0.037754639983177185
Validation loss: 1.384570155092465

Epoch: 596| Step: 0
Training loss: 0.08033829182386398
Validation loss: 1.4002829290205432

Epoch: 6| Step: 1
Training loss: 0.07507501542568207
Validation loss: 1.4004854265079703

Epoch: 6| Step: 2
Training loss: 0.06194733828306198
Validation loss: 1.3821810650569137

Epoch: 6| Step: 3
Training loss: 0.07414566725492477
Validation loss: 1.3956767051450667

Epoch: 6| Step: 4
Training loss: 0.0772223025560379
Validation loss: 1.4058650821767829

Epoch: 6| Step: 5
Training loss: 0.06666368246078491
Validation loss: 1.4243151167387604

Epoch: 6| Step: 6
Training loss: 0.08128552883863449
Validation loss: 1.4060901364972513

Epoch: 6| Step: 7
Training loss: 0.17319847643375397
Validation loss: 1.3850478331247966

Epoch: 6| Step: 8
Training loss: 0.04221181571483612
Validation loss: 1.4007697541226622

Epoch: 6| Step: 9
Training loss: 0.07374110072851181
Validation loss: 1.391585701255388

Epoch: 6| Step: 10
Training loss: 0.06534845381975174
Validation loss: 1.4173967120467976

Epoch: 6| Step: 11
Training loss: 0.06778381019830704
Validation loss: 1.3750708359543995

Epoch: 6| Step: 12
Training loss: 0.14524255692958832
Validation loss: 1.394616703833303

Epoch: 6| Step: 13
Training loss: 0.03677580505609512
Validation loss: 1.3921917984562535

Epoch: 597| Step: 0
Training loss: 0.04799198359251022
Validation loss: 1.4022336877802366

Epoch: 6| Step: 1
Training loss: 0.2363555133342743
Validation loss: 1.4015794966810493

Epoch: 6| Step: 2
Training loss: 0.04137026518583298
Validation loss: 1.402361277611025

Epoch: 6| Step: 3
Training loss: 0.07365068048238754
Validation loss: 1.3987858051894813

Epoch: 6| Step: 4
Training loss: 0.11180223524570465
Validation loss: 1.4046491999779978

Epoch: 6| Step: 5
Training loss: 0.0708451122045517
Validation loss: 1.404746699076827

Epoch: 6| Step: 6
Training loss: 0.09679080545902252
Validation loss: 1.4153696875418387

Epoch: 6| Step: 7
Training loss: 0.06925974786281586
Validation loss: 1.41075478189735

Epoch: 6| Step: 8
Training loss: 0.05794934183359146
Validation loss: 1.3904440582439463

Epoch: 6| Step: 9
Training loss: 0.06107727438211441
Validation loss: 1.3600971583397157

Epoch: 6| Step: 10
Training loss: 0.046724408864974976
Validation loss: 1.3725216529702629

Epoch: 6| Step: 11
Training loss: 0.05446544289588928
Validation loss: 1.377787523372199

Epoch: 6| Step: 12
Training loss: 0.04891079664230347
Validation loss: 1.4031666337802846

Epoch: 6| Step: 13
Training loss: 0.0770576223731041
Validation loss: 1.4057472213622062

Epoch: 598| Step: 0
Training loss: 0.04941350221633911
Validation loss: 1.4195890798363635

Epoch: 6| Step: 1
Training loss: 0.0490877628326416
Validation loss: 1.406176119722346

Epoch: 6| Step: 2
Training loss: 0.04739544540643692
Validation loss: 1.390875784940617

Epoch: 6| Step: 3
Training loss: 0.039103809744119644
Validation loss: 1.4093945269943566

Epoch: 6| Step: 4
Training loss: 0.0843764916062355
Validation loss: 1.4317854995368628

Epoch: 6| Step: 5
Training loss: 0.07822578400373459
Validation loss: 1.4182330087948871

Epoch: 6| Step: 6
Training loss: 0.08718032389879227
Validation loss: 1.4272753384805494

Epoch: 6| Step: 7
Training loss: 0.06972192227840424
Validation loss: 1.4161783482438774

Epoch: 6| Step: 8
Training loss: 0.07465743273496628
Validation loss: 1.4285284037231116

Epoch: 6| Step: 9
Training loss: 0.06789004802703857
Validation loss: 1.4242631081611878

Epoch: 6| Step: 10
Training loss: 0.07759075611829758
Validation loss: 1.4394389801127936

Epoch: 6| Step: 11
Training loss: 0.04294735938310623
Validation loss: 1.4381375799896896

Epoch: 6| Step: 12
Training loss: 0.20675262808799744
Validation loss: 1.4689967619475497

Epoch: 6| Step: 13
Training loss: 0.03648151457309723
Validation loss: 1.4298707759508522

Epoch: 599| Step: 0
Training loss: 0.053435903042554855
Validation loss: 1.4426644463692941

Epoch: 6| Step: 1
Training loss: 0.08583968877792358
Validation loss: 1.433672143566993

Epoch: 6| Step: 2
Training loss: 0.07350382208824158
Validation loss: 1.4464474160184142

Epoch: 6| Step: 3
Training loss: 0.10234175622463226
Validation loss: 1.4252406038263792

Epoch: 6| Step: 4
Training loss: 0.04690101742744446
Validation loss: 1.4414159713252899

Epoch: 6| Step: 5
Training loss: 0.06998924165964127
Validation loss: 1.4214782984026018

Epoch: 6| Step: 6
Training loss: 0.04788697510957718
Validation loss: 1.4076778850247782

Epoch: 6| Step: 7
Training loss: 0.04521743953227997
Validation loss: 1.4184529704432334

Epoch: 6| Step: 8
Training loss: 0.06453114748001099
Validation loss: 1.437842353697746

Epoch: 6| Step: 9
Training loss: 0.0566474050283432
Validation loss: 1.4257706275550268

Epoch: 6| Step: 10
Training loss: 0.06886592507362366
Validation loss: 1.4270010148325274

Epoch: 6| Step: 11
Training loss: 0.2463608682155609
Validation loss: 1.4246591329574585

Epoch: 6| Step: 12
Training loss: 0.05027923732995987
Validation loss: 1.4150053877984323

Epoch: 6| Step: 13
Training loss: 0.05692452937364578
Validation loss: 1.4225552799881145

Epoch: 600| Step: 0
Training loss: 0.05970747023820877
Validation loss: 1.4284210576806018

Epoch: 6| Step: 1
Training loss: 0.055841296911239624
Validation loss: 1.4365017760184504

Epoch: 6| Step: 2
Training loss: 0.1932535022497177
Validation loss: 1.4128273251236125

Epoch: 6| Step: 3
Training loss: 0.07286285609006882
Validation loss: 1.4126842034760343

Epoch: 6| Step: 4
Training loss: 0.06009254604578018
Validation loss: 1.4386244179100118

Epoch: 6| Step: 5
Training loss: 0.08009961247444153
Validation loss: 1.4401511146176247

Epoch: 6| Step: 6
Training loss: 0.04711039736866951
Validation loss: 1.4416807825847338

Epoch: 6| Step: 7
Training loss: 0.054893609136343
Validation loss: 1.4356640859316754

Epoch: 6| Step: 8
Training loss: 0.06632804870605469
Validation loss: 1.4256847379028157

Epoch: 6| Step: 9
Training loss: 0.09407820552587509
Validation loss: 1.419232432560254

Epoch: 6| Step: 10
Training loss: 0.06220915913581848
Validation loss: 1.4263887995032853

Epoch: 6| Step: 11
Training loss: 0.07875321060419083
Validation loss: 1.446854063259658

Epoch: 6| Step: 12
Training loss: 0.07505098730325699
Validation loss: 1.4230549040661062

Epoch: 6| Step: 13
Training loss: 0.13579948246479034
Validation loss: 1.4174419577403734

Testing loss: 2.132106637954712
