Epoch: 1| Step: 0
Training loss: 5.803213596343994
Validation loss: 5.146650765531806

Epoch: 6| Step: 1
Training loss: 4.84573221206665
Validation loss: 5.133040633252872

Epoch: 6| Step: 2
Training loss: 6.786744117736816
Validation loss: 5.120914438719391

Epoch: 6| Step: 3
Training loss: 4.521029472351074
Validation loss: 5.108609825052241

Epoch: 6| Step: 4
Training loss: 4.754149436950684
Validation loss: 5.095045915213964

Epoch: 6| Step: 5
Training loss: 4.898947715759277
Validation loss: 5.079802451595183

Epoch: 6| Step: 6
Training loss: 4.978780269622803
Validation loss: 5.062880680125247

Epoch: 6| Step: 7
Training loss: 3.886600971221924
Validation loss: 5.04349983379405

Epoch: 6| Step: 8
Training loss: 4.913555145263672
Validation loss: 5.02190629897579

Epoch: 6| Step: 9
Training loss: 4.56756591796875
Validation loss: 4.9971911009921826

Epoch: 6| Step: 10
Training loss: 4.373998165130615
Validation loss: 4.97143696200463

Epoch: 6| Step: 11
Training loss: 4.717780590057373
Validation loss: 4.942469699408418

Epoch: 6| Step: 12
Training loss: 4.056545257568359
Validation loss: 4.9117676981033815

Epoch: 6| Step: 13
Training loss: 4.429755210876465
Validation loss: 4.88031513972949

Epoch: 2| Step: 0
Training loss: 5.097294807434082
Validation loss: 4.845088722885296

Epoch: 6| Step: 1
Training loss: 4.659646034240723
Validation loss: 4.808922249783752

Epoch: 6| Step: 2
Training loss: 4.229125022888184
Validation loss: 4.770174334126134

Epoch: 6| Step: 3
Training loss: 4.100622177124023
Validation loss: 4.733435251379526

Epoch: 6| Step: 4
Training loss: 5.385235786437988
Validation loss: 4.697668024288711

Epoch: 6| Step: 5
Training loss: 4.395614147186279
Validation loss: 4.664036007337673

Epoch: 6| Step: 6
Training loss: 3.469478130340576
Validation loss: 4.630370714331186

Epoch: 6| Step: 7
Training loss: 4.784090518951416
Validation loss: 4.596571260882962

Epoch: 6| Step: 8
Training loss: 4.510360240936279
Validation loss: 4.562367690506802

Epoch: 6| Step: 9
Training loss: 4.963491439819336
Validation loss: 4.529675586249239

Epoch: 6| Step: 10
Training loss: 3.4966893196105957
Validation loss: 4.5012514924490326

Epoch: 6| Step: 11
Training loss: 5.147479057312012
Validation loss: 4.474157861483994

Epoch: 6| Step: 12
Training loss: 3.299381732940674
Validation loss: 4.446857862575079

Epoch: 6| Step: 13
Training loss: 4.274816036224365
Validation loss: 4.420493684789186

Epoch: 3| Step: 0
Training loss: 4.734328269958496
Validation loss: 4.394001294207829

Epoch: 6| Step: 1
Training loss: 4.761730194091797
Validation loss: 4.369992389473864

Epoch: 6| Step: 2
Training loss: 3.474836826324463
Validation loss: 4.346403906422276

Epoch: 6| Step: 3
Training loss: 4.485162258148193
Validation loss: 4.323046991902013

Epoch: 6| Step: 4
Training loss: 3.482713222503662
Validation loss: 4.300940534119965

Epoch: 6| Step: 5
Training loss: 3.855745553970337
Validation loss: 4.280537512994582

Epoch: 6| Step: 6
Training loss: 3.431196451187134
Validation loss: 4.25888829846536

Epoch: 6| Step: 7
Training loss: 4.054347991943359
Validation loss: 4.239248865394182

Epoch: 6| Step: 8
Training loss: 4.124104022979736
Validation loss: 4.216787471566149

Epoch: 6| Step: 9
Training loss: 5.137922286987305
Validation loss: 4.190835850213164

Epoch: 6| Step: 10
Training loss: 4.053744792938232
Validation loss: 4.163663912844914

Epoch: 6| Step: 11
Training loss: 3.7588958740234375
Validation loss: 4.138577443297192

Epoch: 6| Step: 12
Training loss: 3.795724868774414
Validation loss: 4.115369868534867

Epoch: 6| Step: 13
Training loss: 3.5237064361572266
Validation loss: 4.086360890378234

Epoch: 4| Step: 0
Training loss: 2.9995572566986084
Validation loss: 4.0561896319030435

Epoch: 6| Step: 1
Training loss: 2.8982865810394287
Validation loss: 4.031767068370696

Epoch: 6| Step: 2
Training loss: 4.106773376464844
Validation loss: 4.0112005741365495

Epoch: 6| Step: 3
Training loss: 3.145578384399414
Validation loss: 3.9861365697717153

Epoch: 6| Step: 4
Training loss: 3.9995410442352295
Validation loss: 3.9611070566279913

Epoch: 6| Step: 5
Training loss: 3.634143590927124
Validation loss: 3.93680303840227

Epoch: 6| Step: 6
Training loss: 3.6890687942504883
Validation loss: 3.916337408045287

Epoch: 6| Step: 7
Training loss: 3.9542832374572754
Validation loss: 3.901808774599465

Epoch: 6| Step: 8
Training loss: 4.022286415100098
Validation loss: 3.8851601898029284

Epoch: 6| Step: 9
Training loss: 4.659832000732422
Validation loss: 3.870409263077603

Epoch: 6| Step: 10
Training loss: 2.970193386077881
Validation loss: 3.8544740881971133

Epoch: 6| Step: 11
Training loss: 4.5128326416015625
Validation loss: 3.8427009274882655

Epoch: 6| Step: 12
Training loss: 4.8992815017700195
Validation loss: 3.8285157962511946

Epoch: 6| Step: 13
Training loss: 3.2782275676727295
Validation loss: 3.8158609585095475

Epoch: 5| Step: 0
Training loss: 4.821601867675781
Validation loss: 3.801610623636553

Epoch: 6| Step: 1
Training loss: 3.748868465423584
Validation loss: 3.783476516764651

Epoch: 6| Step: 2
Training loss: 4.397343635559082
Validation loss: 3.767792901685161

Epoch: 6| Step: 3
Training loss: 3.0960898399353027
Validation loss: 3.7540771422847623

Epoch: 6| Step: 4
Training loss: 4.4056549072265625
Validation loss: 3.737982790957215

Epoch: 6| Step: 5
Training loss: 3.011965751647949
Validation loss: 3.7229510481639574

Epoch: 6| Step: 6
Training loss: 3.3773844242095947
Validation loss: 3.7151905054687173

Epoch: 6| Step: 7
Training loss: 3.7116191387176514
Validation loss: 3.717932011491509

Epoch: 6| Step: 8
Training loss: 3.4278693199157715
Validation loss: 3.6917922983887377

Epoch: 6| Step: 9
Training loss: 4.353932857513428
Validation loss: 3.6819162394410823

Epoch: 6| Step: 10
Training loss: 3.4484431743621826
Validation loss: 3.6872502347474456

Epoch: 6| Step: 11
Training loss: 2.6239073276519775
Validation loss: 3.668072433881862

Epoch: 6| Step: 12
Training loss: 3.385988235473633
Validation loss: 3.6501225245896207

Epoch: 6| Step: 13
Training loss: 2.3321657180786133
Validation loss: 3.6374653898259646

Epoch: 6| Step: 0
Training loss: 4.262782096862793
Validation loss: 3.6313151031412105

Epoch: 6| Step: 1
Training loss: 3.6021289825439453
Validation loss: 3.623284932105772

Epoch: 6| Step: 2
Training loss: 2.6153676509857178
Validation loss: 3.6099888073500765

Epoch: 6| Step: 3
Training loss: 2.809141159057617
Validation loss: 3.6048075383709324

Epoch: 6| Step: 4
Training loss: 2.25146222114563
Validation loss: 3.5966538870206444

Epoch: 6| Step: 5
Training loss: 3.7911763191223145
Validation loss: 3.592439543816351

Epoch: 6| Step: 6
Training loss: 3.621534824371338
Validation loss: 3.590015149885608

Epoch: 6| Step: 7
Training loss: 3.7774441242218018
Validation loss: 3.5775417512462986

Epoch: 6| Step: 8
Training loss: 3.6982860565185547
Validation loss: 3.5724003673881612

Epoch: 6| Step: 9
Training loss: 4.271698474884033
Validation loss: 3.5650019107326383

Epoch: 6| Step: 10
Training loss: 4.091156482696533
Validation loss: 3.5601672357128513

Epoch: 6| Step: 11
Training loss: 3.7793731689453125
Validation loss: 3.5542120702805056

Epoch: 6| Step: 12
Training loss: 3.3317413330078125
Validation loss: 3.5477532878998788

Epoch: 6| Step: 13
Training loss: 2.911105155944824
Validation loss: 3.541437333629977

Epoch: 7| Step: 0
Training loss: 2.823850154876709
Validation loss: 3.5399735717363257

Epoch: 6| Step: 1
Training loss: 4.071054458618164
Validation loss: 3.536115241307084

Epoch: 6| Step: 2
Training loss: 2.871119976043701
Validation loss: 3.5256781090972242

Epoch: 6| Step: 3
Training loss: 4.129674434661865
Validation loss: 3.5366817879420456

Epoch: 6| Step: 4
Training loss: 3.8217124938964844
Validation loss: 3.5430799350943616

Epoch: 6| Step: 5
Training loss: 3.7584595680236816
Validation loss: 3.528537368261686

Epoch: 6| Step: 6
Training loss: 3.0468549728393555
Validation loss: 3.525275863626952

Epoch: 6| Step: 7
Training loss: 2.8109521865844727
Validation loss: 3.522339023569579

Epoch: 6| Step: 8
Training loss: 2.581937074661255
Validation loss: 3.5253037586007068

Epoch: 6| Step: 9
Training loss: 3.095571517944336
Validation loss: 3.5285152466066423

Epoch: 6| Step: 10
Training loss: 3.818786382675171
Validation loss: 3.515581202763383

Epoch: 6| Step: 11
Training loss: 3.797152280807495
Validation loss: 3.5005780163631646

Epoch: 6| Step: 12
Training loss: 3.469801425933838
Validation loss: 3.493792515929027

Epoch: 6| Step: 13
Training loss: 4.849621295928955
Validation loss: 3.4933941851380053

Epoch: 8| Step: 0
Training loss: 3.089567184448242
Validation loss: 3.4904049801570114

Epoch: 6| Step: 1
Training loss: 3.773451328277588
Validation loss: 3.5118170348546838

Epoch: 6| Step: 2
Training loss: 3.5118608474731445
Validation loss: 3.4781254696589645

Epoch: 6| Step: 3
Training loss: 3.3120529651641846
Validation loss: 3.4929470810838925

Epoch: 6| Step: 4
Training loss: 3.781639575958252
Validation loss: 3.5122329804205124

Epoch: 6| Step: 5
Training loss: 3.5794267654418945
Validation loss: 3.5295979105016237

Epoch: 6| Step: 6
Training loss: 3.124130964279175
Validation loss: 3.5346652718000513

Epoch: 6| Step: 7
Training loss: 2.7164554595947266
Validation loss: 3.5406175428821194

Epoch: 6| Step: 8
Training loss: 4.226149559020996
Validation loss: 3.4838939097619828

Epoch: 6| Step: 9
Training loss: 3.1851232051849365
Validation loss: 3.4635602428067114

Epoch: 6| Step: 10
Training loss: 2.5378217697143555
Validation loss: 3.45891543357603

Epoch: 6| Step: 11
Training loss: 4.704485893249512
Validation loss: 3.4593297768664617

Epoch: 6| Step: 12
Training loss: 2.595357894897461
Validation loss: 3.4460624392314623

Epoch: 6| Step: 13
Training loss: 4.0914530754089355
Validation loss: 3.4434168979685795

Epoch: 9| Step: 0
Training loss: 3.143725872039795
Validation loss: 3.439725696399648

Epoch: 6| Step: 1
Training loss: 2.813912868499756
Validation loss: 3.4318014011588147

Epoch: 6| Step: 2
Training loss: 4.2464189529418945
Validation loss: 3.421377110224898

Epoch: 6| Step: 3
Training loss: 3.3326807022094727
Validation loss: 3.4165553713357575

Epoch: 6| Step: 4
Training loss: 3.259444236755371
Validation loss: 3.412972491274598

Epoch: 6| Step: 5
Training loss: 3.451354503631592
Validation loss: 3.4010370008407103

Epoch: 6| Step: 6
Training loss: 2.9149465560913086
Validation loss: 3.403448227913149

Epoch: 6| Step: 7
Training loss: 4.410068988800049
Validation loss: 3.4042044685732935

Epoch: 6| Step: 8
Training loss: 3.1905484199523926
Validation loss: 3.38744346813489

Epoch: 6| Step: 9
Training loss: 3.13154673576355
Validation loss: 3.3839447344503095

Epoch: 6| Step: 10
Training loss: 3.4569509029388428
Validation loss: 3.3773274703692366

Epoch: 6| Step: 11
Training loss: 2.9501073360443115
Validation loss: 3.371444989276189

Epoch: 6| Step: 12
Training loss: 3.3195700645446777
Validation loss: 3.3688296092453824

Epoch: 6| Step: 13
Training loss: 3.2795464992523193
Validation loss: 3.3728883420267413

Epoch: 10| Step: 0
Training loss: 3.1960372924804688
Validation loss: 3.3609675361264135

Epoch: 6| Step: 1
Training loss: 4.215232849121094
Validation loss: 3.358918974476476

Epoch: 6| Step: 2
Training loss: 3.683406352996826
Validation loss: 3.3539020117893013

Epoch: 6| Step: 3
Training loss: 3.4253652095794678
Validation loss: 3.344343195679367

Epoch: 6| Step: 4
Training loss: 2.9843320846557617
Validation loss: 3.341771141175301

Epoch: 6| Step: 5
Training loss: 2.583988666534424
Validation loss: 3.3364645178600023

Epoch: 6| Step: 6
Training loss: 3.184554100036621
Validation loss: 3.333362125581311

Epoch: 6| Step: 7
Training loss: 4.026760578155518
Validation loss: 3.3330109247597317

Epoch: 6| Step: 8
Training loss: 3.5167489051818848
Validation loss: 3.3253785128234536

Epoch: 6| Step: 9
Training loss: 3.6714401245117188
Validation loss: 3.3209473497124127

Epoch: 6| Step: 10
Training loss: 3.0140068531036377
Validation loss: 3.3146623078212945

Epoch: 6| Step: 11
Training loss: 3.0381903648376465
Validation loss: 3.310977610208655

Epoch: 6| Step: 12
Training loss: 2.884769916534424
Validation loss: 3.3069678685998403

Epoch: 6| Step: 13
Training loss: 2.365790367126465
Validation loss: 3.3009039381498932

Epoch: 11| Step: 0
Training loss: 3.244753360748291
Validation loss: 3.2986354776608047

Epoch: 6| Step: 1
Training loss: 3.4803872108459473
Validation loss: 3.296636555784492

Epoch: 6| Step: 2
Training loss: 3.103372097015381
Validation loss: 3.2908796469370523

Epoch: 6| Step: 3
Training loss: 3.4759223461151123
Validation loss: 3.2875003737788044

Epoch: 6| Step: 4
Training loss: 3.906527042388916
Validation loss: 3.2857750846493627

Epoch: 6| Step: 5
Training loss: 4.0918169021606445
Validation loss: 3.282795757375738

Epoch: 6| Step: 6
Training loss: 4.054897308349609
Validation loss: 3.2815061692268617

Epoch: 6| Step: 7
Training loss: 2.2310118675231934
Validation loss: 3.2731158400094635

Epoch: 6| Step: 8
Training loss: 1.9813365936279297
Validation loss: 3.2713975726917224

Epoch: 6| Step: 9
Training loss: 2.872285842895508
Validation loss: 3.2705374712585122

Epoch: 6| Step: 10
Training loss: 3.4455742835998535
Validation loss: 3.2687017225450083

Epoch: 6| Step: 11
Training loss: 3.4156932830810547
Validation loss: 3.2678926862696165

Epoch: 6| Step: 12
Training loss: 3.02315616607666
Validation loss: 3.2652749348712224

Epoch: 6| Step: 13
Training loss: 3.3172154426574707
Validation loss: 3.2637074480774584

Epoch: 12| Step: 0
Training loss: 3.574916362762451
Validation loss: 3.261053390400384

Epoch: 6| Step: 1
Training loss: 3.272304058074951
Validation loss: 3.257294726628129

Epoch: 6| Step: 2
Training loss: 3.9679691791534424
Validation loss: 3.252268337434338

Epoch: 6| Step: 3
Training loss: 3.5941002368927
Validation loss: 3.244787549459806

Epoch: 6| Step: 4
Training loss: 3.2136473655700684
Validation loss: 3.240949187227475

Epoch: 6| Step: 5
Training loss: 2.56819486618042
Validation loss: 3.2363941079826763

Epoch: 6| Step: 6
Training loss: 2.9042792320251465
Validation loss: 3.2311685956934446

Epoch: 6| Step: 7
Training loss: 2.3142738342285156
Validation loss: 3.2269312797054166

Epoch: 6| Step: 8
Training loss: 3.5569708347320557
Validation loss: 3.225677946562408

Epoch: 6| Step: 9
Training loss: 3.3490591049194336
Validation loss: 3.2218507412941224

Epoch: 6| Step: 10
Training loss: 2.5836548805236816
Validation loss: 3.222626970660302

Epoch: 6| Step: 11
Training loss: 3.689605474472046
Validation loss: 3.218802800742529

Epoch: 6| Step: 12
Training loss: 3.1723744869232178
Validation loss: 3.217544073699623

Epoch: 6| Step: 13
Training loss: 3.5031378269195557
Validation loss: 3.2118577085515505

Epoch: 13| Step: 0
Training loss: 2.7643020153045654
Validation loss: 3.2115056002011864

Epoch: 6| Step: 1
Training loss: 3.2712366580963135
Validation loss: 3.2087622150298087

Epoch: 6| Step: 2
Training loss: 2.8537063598632812
Validation loss: 3.206006339801255

Epoch: 6| Step: 3
Training loss: 2.8500783443450928
Validation loss: 3.2018142900159283

Epoch: 6| Step: 4
Training loss: 3.74930477142334
Validation loss: 3.2024762143370924

Epoch: 6| Step: 5
Training loss: 4.503355026245117
Validation loss: 3.200619661679832

Epoch: 6| Step: 6
Training loss: 1.652496576309204
Validation loss: 3.1962948845278834

Epoch: 6| Step: 7
Training loss: 4.105041980743408
Validation loss: 3.1954456375491236

Epoch: 6| Step: 8
Training loss: 2.8086957931518555
Validation loss: 3.1910338171066774

Epoch: 6| Step: 9
Training loss: 3.5861551761627197
Validation loss: 3.1902397653108

Epoch: 6| Step: 10
Training loss: 2.8528237342834473
Validation loss: 3.190790443010228

Epoch: 6| Step: 11
Training loss: 2.8201754093170166
Validation loss: 3.1907221066054476

Epoch: 6| Step: 12
Training loss: 3.9908604621887207
Validation loss: 3.1846028092086955

Epoch: 6| Step: 13
Training loss: 2.7457704544067383
Validation loss: 3.180369541209231

Epoch: 14| Step: 0
Training loss: 3.158914089202881
Validation loss: 3.1806181502598587

Epoch: 6| Step: 1
Training loss: 4.147639274597168
Validation loss: 3.178338937861945

Epoch: 6| Step: 2
Training loss: 2.777223587036133
Validation loss: 3.177322103131202

Epoch: 6| Step: 3
Training loss: 2.8659145832061768
Validation loss: 3.1755724824884886

Epoch: 6| Step: 4
Training loss: 3.30926775932312
Validation loss: 3.17443339286312

Epoch: 6| Step: 5
Training loss: 2.878136396408081
Validation loss: 3.1754936249025407

Epoch: 6| Step: 6
Training loss: 3.255202293395996
Validation loss: 3.1679952964987805

Epoch: 6| Step: 7
Training loss: 2.2530579566955566
Validation loss: 3.165494582986319

Epoch: 6| Step: 8
Training loss: 3.058204412460327
Validation loss: 3.1652869742403746

Epoch: 6| Step: 9
Training loss: 3.770763397216797
Validation loss: 3.165974775950114

Epoch: 6| Step: 10
Training loss: 3.6278328895568848
Validation loss: 3.1629544611900084

Epoch: 6| Step: 11
Training loss: 2.8956379890441895
Validation loss: 3.1586941596000426

Epoch: 6| Step: 12
Training loss: 3.0947179794311523
Validation loss: 3.1582073088615172

Epoch: 6| Step: 13
Training loss: 3.5262503623962402
Validation loss: 3.159155076549899

Epoch: 15| Step: 0
Training loss: 3.209383010864258
Validation loss: 3.1596356745689147

Epoch: 6| Step: 1
Training loss: 3.0397658348083496
Validation loss: 3.1580201477132817

Epoch: 6| Step: 2
Training loss: 3.4104480743408203
Validation loss: 3.1497870081214496

Epoch: 6| Step: 3
Training loss: 4.287873268127441
Validation loss: 3.149378732968402

Epoch: 6| Step: 4
Training loss: 2.183851718902588
Validation loss: 3.151443850609564

Epoch: 6| Step: 5
Training loss: 3.3773458003997803
Validation loss: 3.1503567131616736

Epoch: 6| Step: 6
Training loss: 4.841765880584717
Validation loss: 3.147557855934225

Epoch: 6| Step: 7
Training loss: 2.9599790573120117
Validation loss: 3.1437349652731292

Epoch: 6| Step: 8
Training loss: 3.702986001968384
Validation loss: 3.1416060616893153

Epoch: 6| Step: 9
Training loss: 3.147305727005005
Validation loss: 3.1388505248613257

Epoch: 6| Step: 10
Training loss: 1.8382983207702637
Validation loss: 3.135132820375504

Epoch: 6| Step: 11
Training loss: 2.54231595993042
Validation loss: 3.1449382740964174

Epoch: 6| Step: 12
Training loss: 2.773143768310547
Validation loss: 3.143815778916882

Epoch: 6| Step: 13
Training loss: 2.832655906677246
Validation loss: 3.1379354077000774

Epoch: 16| Step: 0
Training loss: 2.448071241378784
Validation loss: 3.135899607853223

Epoch: 6| Step: 1
Training loss: 2.974641799926758
Validation loss: 3.1411235409398235

Epoch: 6| Step: 2
Training loss: 3.1536026000976562
Validation loss: 3.1266309343358523

Epoch: 6| Step: 3
Training loss: 2.8975839614868164
Validation loss: 3.1261902727106565

Epoch: 6| Step: 4
Training loss: 3.2976701259613037
Validation loss: 3.132551829020182

Epoch: 6| Step: 5
Training loss: 3.4726927280426025
Validation loss: 3.1218545975223666

Epoch: 6| Step: 6
Training loss: 4.036315441131592
Validation loss: 3.121660811926729

Epoch: 6| Step: 7
Training loss: 3.432002544403076
Validation loss: 3.1227881575143464

Epoch: 6| Step: 8
Training loss: 2.9164719581604004
Validation loss: 3.1251895299521824

Epoch: 6| Step: 9
Training loss: 3.3684749603271484
Validation loss: 3.1283392470370055

Epoch: 6| Step: 10
Training loss: 2.9485864639282227
Validation loss: 3.1273699370763635

Epoch: 6| Step: 11
Training loss: 3.133608341217041
Validation loss: 3.125029292157901

Epoch: 6| Step: 12
Training loss: 3.0889134407043457
Validation loss: 3.141443811437135

Epoch: 6| Step: 13
Training loss: 2.724828004837036
Validation loss: 3.117658753548899

Epoch: 17| Step: 0
Training loss: 3.3781356811523438
Validation loss: 3.112399803694858

Epoch: 6| Step: 1
Training loss: 3.234264373779297
Validation loss: 3.1151638620643207

Epoch: 6| Step: 2
Training loss: 2.753046989440918
Validation loss: 3.1178706845929547

Epoch: 6| Step: 3
Training loss: 3.522749423980713
Validation loss: 3.1157405940435265

Epoch: 6| Step: 4
Training loss: 3.170257568359375
Validation loss: 3.1091583903117845

Epoch: 6| Step: 5
Training loss: 2.9424824714660645
Validation loss: 3.105539111680882

Epoch: 6| Step: 6
Training loss: 3.970710039138794
Validation loss: 3.1004605729092836

Epoch: 6| Step: 7
Training loss: 2.632774591445923
Validation loss: 3.1037404127018426

Epoch: 6| Step: 8
Training loss: 3.323410987854004
Validation loss: 3.1025225167633383

Epoch: 6| Step: 9
Training loss: 2.1897363662719727
Validation loss: 3.097845615879182

Epoch: 6| Step: 10
Training loss: 2.743434429168701
Validation loss: 3.0928299119395595

Epoch: 6| Step: 11
Training loss: 3.1046018600463867
Validation loss: 3.0987228347409155

Epoch: 6| Step: 12
Training loss: 4.359475135803223
Validation loss: 3.0966051445212415

Epoch: 6| Step: 13
Training loss: 2.0568346977233887
Validation loss: 3.0921411950101136

Epoch: 18| Step: 0
Training loss: 2.674586772918701
Validation loss: 3.094367293901341

Epoch: 6| Step: 1
Training loss: 3.8600785732269287
Validation loss: 3.086710701706589

Epoch: 6| Step: 2
Training loss: 2.3051395416259766
Validation loss: 3.0892328190547165

Epoch: 6| Step: 3
Training loss: 2.558849334716797
Validation loss: 3.0879942704272527

Epoch: 6| Step: 4
Training loss: 2.908283233642578
Validation loss: 3.086255596530053

Epoch: 6| Step: 5
Training loss: 3.439535140991211
Validation loss: 3.0836741078284478

Epoch: 6| Step: 6
Training loss: 3.405820846557617
Validation loss: 3.0817866658651702

Epoch: 6| Step: 7
Training loss: 2.876461982727051
Validation loss: 3.07567887408759

Epoch: 6| Step: 8
Training loss: 2.9802465438842773
Validation loss: 3.076315282493509

Epoch: 6| Step: 9
Training loss: 2.7374212741851807
Validation loss: 3.0732185353514967

Epoch: 6| Step: 10
Training loss: 4.3111443519592285
Validation loss: 3.0682678761020785

Epoch: 6| Step: 11
Training loss: 2.6801669597625732
Validation loss: 3.069935957590739

Epoch: 6| Step: 12
Training loss: 3.339463710784912
Validation loss: 3.069152875613141

Epoch: 6| Step: 13
Training loss: 3.8950397968292236
Validation loss: 3.0684303288818686

Epoch: 19| Step: 0
Training loss: 3.720928192138672
Validation loss: 3.066695600427607

Epoch: 6| Step: 1
Training loss: 4.044791221618652
Validation loss: 3.0654044279488186

Epoch: 6| Step: 2
Training loss: 3.0146102905273438
Validation loss: 3.0645773667161182

Epoch: 6| Step: 3
Training loss: 3.7666146755218506
Validation loss: 3.068878166137203

Epoch: 6| Step: 4
Training loss: 3.218252658843994
Validation loss: 3.061063894661524

Epoch: 6| Step: 5
Training loss: 2.866137742996216
Validation loss: 3.0603371948324223

Epoch: 6| Step: 6
Training loss: 1.7290253639221191
Validation loss: 3.0567665048824844

Epoch: 6| Step: 7
Training loss: 4.126712322235107
Validation loss: 3.054939011091827

Epoch: 6| Step: 8
Training loss: 3.3005588054656982
Validation loss: 3.055196585193757

Epoch: 6| Step: 9
Training loss: 3.8655636310577393
Validation loss: 3.054721765620734

Epoch: 6| Step: 10
Training loss: 2.9649910926818848
Validation loss: 3.052441091947658

Epoch: 6| Step: 11
Training loss: 2.628049373626709
Validation loss: 3.0502331231230047

Epoch: 6| Step: 12
Training loss: 1.8052122592926025
Validation loss: 3.0495738778063046

Epoch: 6| Step: 13
Training loss: 1.8588619232177734
Validation loss: 3.0478418334837882

Epoch: 20| Step: 0
Training loss: 3.332505941390991
Validation loss: 3.0477236163231636

Epoch: 6| Step: 1
Training loss: 2.0874524116516113
Validation loss: 3.0440590971259662

Epoch: 6| Step: 2
Training loss: 2.5548596382141113
Validation loss: 3.043619471211587

Epoch: 6| Step: 3
Training loss: 3.086257219314575
Validation loss: 3.041013558705648

Epoch: 6| Step: 4
Training loss: 2.9689464569091797
Validation loss: 3.0413297299415833

Epoch: 6| Step: 5
Training loss: 2.7680227756500244
Validation loss: 3.044863147120322

Epoch: 6| Step: 6
Training loss: 2.9840736389160156
Validation loss: 3.040027500480734

Epoch: 6| Step: 7
Training loss: 3.187783718109131
Validation loss: 3.038918184977706

Epoch: 6| Step: 8
Training loss: 4.401158332824707
Validation loss: 3.042434541128015

Epoch: 6| Step: 9
Training loss: 3.0586981773376465
Validation loss: 3.0386002166296846

Epoch: 6| Step: 10
Training loss: 3.88531494140625
Validation loss: 3.0382729909753285

Epoch: 6| Step: 11
Training loss: 3.0507986545562744
Validation loss: 3.032157290366388

Epoch: 6| Step: 12
Training loss: 3.0495715141296387
Validation loss: 3.036215848820184

Epoch: 6| Step: 13
Training loss: 2.627168893814087
Validation loss: 3.033274450609761

Epoch: 21| Step: 0
Training loss: 4.168865203857422
Validation loss: 3.0372598017415693

Epoch: 6| Step: 1
Training loss: 3.15417742729187
Validation loss: 3.038803413350095

Epoch: 6| Step: 2
Training loss: 2.658975839614868
Validation loss: 3.0406204218505533

Epoch: 6| Step: 3
Training loss: 3.0906600952148438
Validation loss: 3.0553689464446037

Epoch: 6| Step: 4
Training loss: 2.641209363937378
Validation loss: 3.041895063974524

Epoch: 6| Step: 5
Training loss: 3.519256591796875
Validation loss: 3.0426247965904976

Epoch: 6| Step: 6
Training loss: 2.700413227081299
Validation loss: 3.0348042365043395

Epoch: 6| Step: 7
Training loss: 2.483558416366577
Validation loss: 3.0292040660817134

Epoch: 6| Step: 8
Training loss: 3.2851691246032715
Validation loss: 3.0235793359817995

Epoch: 6| Step: 9
Training loss: 3.0425806045532227
Validation loss: 3.0265422226280294

Epoch: 6| Step: 10
Training loss: 2.8352296352386475
Validation loss: 3.027043060589862

Epoch: 6| Step: 11
Training loss: 3.023099184036255
Validation loss: 3.02647300176723

Epoch: 6| Step: 12
Training loss: 3.7547709941864014
Validation loss: 3.029713974204115

Epoch: 6| Step: 13
Training loss: 2.4301974773406982
Validation loss: 3.024863471267044

Epoch: 22| Step: 0
Training loss: 3.121860980987549
Validation loss: 3.025831819862448

Epoch: 6| Step: 1
Training loss: 3.7699103355407715
Validation loss: 3.0226360341554046

Epoch: 6| Step: 2
Training loss: 3.0539774894714355
Validation loss: 3.0220825390149186

Epoch: 6| Step: 3
Training loss: 3.1764230728149414
Validation loss: 3.0192039576909875

Epoch: 6| Step: 4
Training loss: 2.9796342849731445
Validation loss: 3.0175149620220227

Epoch: 6| Step: 5
Training loss: 3.538912296295166
Validation loss: 3.01368744655322

Epoch: 6| Step: 6
Training loss: 3.1983461380004883
Validation loss: 3.0139654015982025

Epoch: 6| Step: 7
Training loss: 2.3289451599121094
Validation loss: 3.0127423322328957

Epoch: 6| Step: 8
Training loss: 2.820650577545166
Validation loss: 3.011173322636594

Epoch: 6| Step: 9
Training loss: 2.6019225120544434
Validation loss: 3.0126896494178363

Epoch: 6| Step: 10
Training loss: 2.8140623569488525
Validation loss: 3.020239681325933

Epoch: 6| Step: 11
Training loss: 3.1036078929901123
Validation loss: 3.008858767888879

Epoch: 6| Step: 12
Training loss: 3.1711106300354004
Validation loss: 3.0108513421909784

Epoch: 6| Step: 13
Training loss: 3.464846611022949
Validation loss: 3.0089121223777853

Epoch: 23| Step: 0
Training loss: 3.3381552696228027
Validation loss: 3.0118945644747828

Epoch: 6| Step: 1
Training loss: 3.843946933746338
Validation loss: 3.01820570166393

Epoch: 6| Step: 2
Training loss: 2.7128612995147705
Validation loss: 3.0291367858968754

Epoch: 6| Step: 3
Training loss: 2.961857795715332
Validation loss: 3.0846189709119898

Epoch: 6| Step: 4
Training loss: 2.753915309906006
Validation loss: 3.0689428980632494

Epoch: 6| Step: 5
Training loss: 2.6451680660247803
Validation loss: 3.01809633931806

Epoch: 6| Step: 6
Training loss: 2.8760745525360107
Validation loss: 3.004994187303769

Epoch: 6| Step: 7
Training loss: 3.2801148891448975
Validation loss: 3.01423297133497

Epoch: 6| Step: 8
Training loss: 3.533921718597412
Validation loss: 3.041334705968057

Epoch: 6| Step: 9
Training loss: 2.501056432723999
Validation loss: 3.037774929436304

Epoch: 6| Step: 10
Training loss: 3.624854564666748
Validation loss: 3.031683357813025

Epoch: 6| Step: 11
Training loss: 2.7668421268463135
Validation loss: 3.0201365101721978

Epoch: 6| Step: 12
Training loss: 2.876774311065674
Validation loss: 3.0109703002437467

Epoch: 6| Step: 13
Training loss: 3.2363440990448
Validation loss: 3.0040503394219185

Epoch: 24| Step: 0
Training loss: 3.3398380279541016
Validation loss: 2.9975711145708637

Epoch: 6| Step: 1
Training loss: 2.7565462589263916
Validation loss: 2.997559585878926

Epoch: 6| Step: 2
Training loss: 3.895263433456421
Validation loss: 3.0071204016285558

Epoch: 6| Step: 3
Training loss: 3.1885480880737305
Validation loss: 2.9983957736722884

Epoch: 6| Step: 4
Training loss: 3.1821181774139404
Validation loss: 3.0140701493909283

Epoch: 6| Step: 5
Training loss: 2.56363582611084
Validation loss: 3.038646541615968

Epoch: 6| Step: 6
Training loss: 2.70462703704834
Validation loss: 3.0662912860993417

Epoch: 6| Step: 7
Training loss: 2.93527889251709
Validation loss: 3.0940279012085288

Epoch: 6| Step: 8
Training loss: 2.67293643951416
Validation loss: 3.099102158700266

Epoch: 6| Step: 9
Training loss: 1.740572214126587
Validation loss: 3.1036742143733527

Epoch: 6| Step: 10
Training loss: 3.859069347381592
Validation loss: 3.0791208513321413

Epoch: 6| Step: 11
Training loss: 3.6106555461883545
Validation loss: 3.0455231076927594

Epoch: 6| Step: 12
Training loss: 3.292264699935913
Validation loss: 3.035352332617647

Epoch: 6| Step: 13
Training loss: 3.6103570461273193
Validation loss: 3.027681960854479

Epoch: 25| Step: 0
Training loss: 3.441006660461426
Validation loss: 3.0310729729231967

Epoch: 6| Step: 1
Training loss: 3.8812174797058105
Validation loss: 3.1045671175884944

Epoch: 6| Step: 2
Training loss: 3.5564332008361816
Validation loss: 3.0648576008376254

Epoch: 6| Step: 3
Training loss: 3.243791103363037
Validation loss: 3.0149627654783187

Epoch: 6| Step: 4
Training loss: 2.918257236480713
Validation loss: 3.004873078356507

Epoch: 6| Step: 5
Training loss: 2.964841604232788
Validation loss: 2.9925592945468042

Epoch: 6| Step: 6
Training loss: 1.8301613330841064
Validation loss: 2.994037914019759

Epoch: 6| Step: 7
Training loss: 3.3012518882751465
Validation loss: 2.9943223614846506

Epoch: 6| Step: 8
Training loss: 3.660752534866333
Validation loss: 2.9932929367147465

Epoch: 6| Step: 9
Training loss: 2.2135658264160156
Validation loss: 2.988632002184468

Epoch: 6| Step: 10
Training loss: 3.4008474349975586
Validation loss: 2.982231124754875

Epoch: 6| Step: 11
Training loss: 2.592033624649048
Validation loss: 2.9774437027592815

Epoch: 6| Step: 12
Training loss: 2.0446438789367676
Validation loss: 2.975405239289807

Epoch: 6| Step: 13
Training loss: 4.571922302246094
Validation loss: 2.972418574876683

Epoch: 26| Step: 0
Training loss: 3.3375802040100098
Validation loss: 2.973938636882331

Epoch: 6| Step: 1
Training loss: 3.0493531227111816
Validation loss: 2.9755640260634886

Epoch: 6| Step: 2
Training loss: 2.855994462966919
Validation loss: 2.9731275625126337

Epoch: 6| Step: 3
Training loss: 3.3506550788879395
Validation loss: 2.977224449957571

Epoch: 6| Step: 4
Training loss: 2.9029345512390137
Validation loss: 2.986162316414618

Epoch: 6| Step: 5
Training loss: 3.2770018577575684
Validation loss: 3.0395329126747708

Epoch: 6| Step: 6
Training loss: 2.6980881690979004
Validation loss: 3.0142862591692197

Epoch: 6| Step: 7
Training loss: 2.524717092514038
Validation loss: 3.0345106304332776

Epoch: 6| Step: 8
Training loss: 3.109799385070801
Validation loss: 2.981243089963031

Epoch: 6| Step: 9
Training loss: 2.920546054840088
Validation loss: 2.968733846500356

Epoch: 6| Step: 10
Training loss: 3.3475728034973145
Validation loss: 2.9670557052858415

Epoch: 6| Step: 11
Training loss: 2.5967600345611572
Validation loss: 2.9715486059906664

Epoch: 6| Step: 12
Training loss: 3.5391476154327393
Validation loss: 3.0073014164483673

Epoch: 6| Step: 13
Training loss: 3.395153522491455
Validation loss: 2.965534030750234

Epoch: 27| Step: 0
Training loss: 3.3620498180389404
Validation loss: 2.961240958142024

Epoch: 6| Step: 1
Training loss: 3.4722862243652344
Validation loss: 2.9677130996540027

Epoch: 6| Step: 2
Training loss: 2.479841947555542
Validation loss: 2.9766391092731106

Epoch: 6| Step: 3
Training loss: 3.919395685195923
Validation loss: 2.9886966084921234

Epoch: 6| Step: 4
Training loss: 2.2735440731048584
Validation loss: 2.995750045263639

Epoch: 6| Step: 5
Training loss: 3.8767776489257812
Validation loss: 3.0271764006665958

Epoch: 6| Step: 6
Training loss: 2.9931185245513916
Validation loss: 3.0151700588964645

Epoch: 6| Step: 7
Training loss: 2.697598934173584
Validation loss: 2.9859018248896443

Epoch: 6| Step: 8
Training loss: 2.4294252395629883
Validation loss: 2.9758976505648707

Epoch: 6| Step: 9
Training loss: 3.350426435470581
Validation loss: 2.962625947049869

Epoch: 6| Step: 10
Training loss: 1.715414047241211
Validation loss: 2.965607681582051

Epoch: 6| Step: 11
Training loss: 3.0441603660583496
Validation loss: 2.9749257103089364

Epoch: 6| Step: 12
Training loss: 3.3031506538391113
Validation loss: 2.983907066365724

Epoch: 6| Step: 13
Training loss: 4.31702995300293
Validation loss: 2.9887370319776636

Epoch: 28| Step: 0
Training loss: 2.8343703746795654
Validation loss: 2.983860872125113

Epoch: 6| Step: 1
Training loss: 3.646183490753174
Validation loss: 2.9763424652878956

Epoch: 6| Step: 2
Training loss: 2.850541114807129
Validation loss: 2.9691317081451416

Epoch: 6| Step: 3
Training loss: 3.1130311489105225
Validation loss: 2.9590492222898748

Epoch: 6| Step: 4
Training loss: 2.687351703643799
Validation loss: 2.9549066969143447

Epoch: 6| Step: 5
Training loss: 2.4147837162017822
Validation loss: 2.953427142994378

Epoch: 6| Step: 6
Training loss: 2.76578426361084
Validation loss: 2.9557669598569154

Epoch: 6| Step: 7
Training loss: 2.9193224906921387
Validation loss: 2.9534432042029595

Epoch: 6| Step: 8
Training loss: 3.299842119216919
Validation loss: 2.9509850317432034

Epoch: 6| Step: 9
Training loss: 3.6101150512695312
Validation loss: 2.9486454814992924

Epoch: 6| Step: 10
Training loss: 2.626861095428467
Validation loss: 2.947819230377033

Epoch: 6| Step: 11
Training loss: 3.5743775367736816
Validation loss: 2.946888364771361

Epoch: 6| Step: 12
Training loss: 3.230403423309326
Validation loss: 2.946648177280221

Epoch: 6| Step: 13
Training loss: 2.5979580879211426
Validation loss: 2.9434547501225627

Epoch: 29| Step: 0
Training loss: 2.9919402599334717
Validation loss: 2.9530967076619468

Epoch: 6| Step: 1
Training loss: 3.3415653705596924
Validation loss: 2.9585469897075365

Epoch: 6| Step: 2
Training loss: 3.120417833328247
Validation loss: 2.9529768677167993

Epoch: 6| Step: 3
Training loss: 2.915012836456299
Validation loss: 2.9600832539220012

Epoch: 6| Step: 4
Training loss: 2.702578067779541
Validation loss: 2.957701785590059

Epoch: 6| Step: 5
Training loss: 3.432828664779663
Validation loss: 2.945695377165271

Epoch: 6| Step: 6
Training loss: 3.2292041778564453
Validation loss: 2.9446141565999677

Epoch: 6| Step: 7
Training loss: 2.962716579437256
Validation loss: 2.9442319664903867

Epoch: 6| Step: 8
Training loss: 2.556447982788086
Validation loss: 2.946071163300545

Epoch: 6| Step: 9
Training loss: 2.284212827682495
Validation loss: 2.9404170590062297

Epoch: 6| Step: 10
Training loss: 3.4794631004333496
Validation loss: 2.932101349676809

Epoch: 6| Step: 11
Training loss: 2.8044662475585938
Validation loss: 2.9412759478374193

Epoch: 6| Step: 12
Training loss: 3.0071356296539307
Validation loss: 2.9367233501967562

Epoch: 6| Step: 13
Training loss: 3.527618885040283
Validation loss: 2.9408786835209018

Epoch: 30| Step: 0
Training loss: 3.4986953735351562
Validation loss: 2.934901281069684

Epoch: 6| Step: 1
Training loss: 2.635261058807373
Validation loss: 2.93170149864689

Epoch: 6| Step: 2
Training loss: 3.0666298866271973
Validation loss: 2.9243922566854827

Epoch: 6| Step: 3
Training loss: 2.1697611808776855
Validation loss: 2.9246909695286907

Epoch: 6| Step: 4
Training loss: 3.0351932048797607
Validation loss: 2.9259407007566063

Epoch: 6| Step: 5
Training loss: 3.5563912391662598
Validation loss: 2.9234942518254763

Epoch: 6| Step: 6
Training loss: 3.4863739013671875
Validation loss: 2.919849844389064

Epoch: 6| Step: 7
Training loss: 2.6787068843841553
Validation loss: 2.919179031925817

Epoch: 6| Step: 8
Training loss: 2.7400598526000977
Validation loss: 2.9187470200241252

Epoch: 6| Step: 9
Training loss: 2.821929693222046
Validation loss: 2.9162806310961322

Epoch: 6| Step: 10
Training loss: 3.2741708755493164
Validation loss: 2.9179780226881786

Epoch: 6| Step: 11
Training loss: 3.1118323802948
Validation loss: 2.915842394674978

Epoch: 6| Step: 12
Training loss: 3.197145700454712
Validation loss: 2.911223965306436

Epoch: 6| Step: 13
Training loss: 2.7011783123016357
Validation loss: 2.911003743448565

Epoch: 31| Step: 0
Training loss: 3.0232982635498047
Validation loss: 2.919315666280767

Epoch: 6| Step: 1
Training loss: 3.250775098800659
Validation loss: 2.9459394306264897

Epoch: 6| Step: 2
Training loss: 2.132500648498535
Validation loss: 2.9516446359695925

Epoch: 6| Step: 3
Training loss: 2.0799367427825928
Validation loss: 2.9383678436279297

Epoch: 6| Step: 4
Training loss: 3.8129897117614746
Validation loss: 2.946200901462186

Epoch: 6| Step: 5
Training loss: 2.894962787628174
Validation loss: 2.9416012815249863

Epoch: 6| Step: 6
Training loss: 3.590400218963623
Validation loss: 2.9425288682342856

Epoch: 6| Step: 7
Training loss: 3.1452503204345703
Validation loss: 2.9478490583358274

Epoch: 6| Step: 8
Training loss: 3.054342031478882
Validation loss: 2.9528761858581216

Epoch: 6| Step: 9
Training loss: 2.193997621536255
Validation loss: 2.9212466670620825

Epoch: 6| Step: 10
Training loss: 3.4716248512268066
Validation loss: 2.91219747963772

Epoch: 6| Step: 11
Training loss: 3.088099956512451
Validation loss: 2.9047952467395413

Epoch: 6| Step: 12
Training loss: 3.011902332305908
Validation loss: 2.905666602555142

Epoch: 6| Step: 13
Training loss: 3.2612767219543457
Validation loss: 2.908826881839383

Epoch: 32| Step: 0
Training loss: 3.4071645736694336
Validation loss: 3.0088012321020967

Epoch: 6| Step: 1
Training loss: 2.0635993480682373
Validation loss: 3.0230976227791078

Epoch: 6| Step: 2
Training loss: 3.4726486206054688
Validation loss: 3.025509644580144

Epoch: 6| Step: 3
Training loss: 2.5831899642944336
Validation loss: 3.018822408491565

Epoch: 6| Step: 4
Training loss: 3.908385992050171
Validation loss: 3.014472051333356

Epoch: 6| Step: 5
Training loss: 3.3684542179107666
Validation loss: 3.006417061692925

Epoch: 6| Step: 6
Training loss: 3.346012592315674
Validation loss: 3.0064865337905062

Epoch: 6| Step: 7
Training loss: 2.93709659576416
Validation loss: 3.0031066299766622

Epoch: 6| Step: 8
Training loss: 2.9881067276000977
Validation loss: 3.006249035558393

Epoch: 6| Step: 9
Training loss: 2.8877625465393066
Validation loss: 3.0055487361005557

Epoch: 6| Step: 10
Training loss: 2.919466257095337
Validation loss: 3.01711025545674

Epoch: 6| Step: 11
Training loss: 2.8666906356811523
Validation loss: 3.021431633221206

Epoch: 6| Step: 12
Training loss: 3.3704795837402344
Validation loss: 3.053238679003972

Epoch: 6| Step: 13
Training loss: 2.406682014465332
Validation loss: 3.031647966754052

Epoch: 33| Step: 0
Training loss: 2.938361167907715
Validation loss: 3.000320070533342

Epoch: 6| Step: 1
Training loss: 2.790358781814575
Validation loss: 2.9862905215191584

Epoch: 6| Step: 2
Training loss: 3.015439033508301
Validation loss: 2.9783550923870457

Epoch: 6| Step: 3
Training loss: 1.8906892538070679
Validation loss: 2.981396634091613

Epoch: 6| Step: 4
Training loss: 4.037327766418457
Validation loss: 2.9821793007594284

Epoch: 6| Step: 5
Training loss: 3.3357043266296387
Validation loss: 2.988309524392569

Epoch: 6| Step: 6
Training loss: 3.082744598388672
Validation loss: 2.989241664127637

Epoch: 6| Step: 7
Training loss: 2.093019485473633
Validation loss: 2.9831944537419144

Epoch: 6| Step: 8
Training loss: 4.100759506225586
Validation loss: 2.972995847784063

Epoch: 6| Step: 9
Training loss: 2.8642308712005615
Validation loss: 2.9731691088727725

Epoch: 6| Step: 10
Training loss: 2.574458122253418
Validation loss: 2.9709363675886586

Epoch: 6| Step: 11
Training loss: 3.584517002105713
Validation loss: 2.9701066042787287

Epoch: 6| Step: 12
Training loss: 3.026041030883789
Validation loss: 2.9617482231509302

Epoch: 6| Step: 13
Training loss: 3.468366861343384
Validation loss: 2.9534041984106905

Epoch: 34| Step: 0
Training loss: 3.2205886840820312
Validation loss: 2.939318380048198

Epoch: 6| Step: 1
Training loss: 3.132432222366333
Validation loss: 2.900628984615367

Epoch: 6| Step: 2
Training loss: 4.066391944885254
Validation loss: 2.888569413974721

Epoch: 6| Step: 3
Training loss: 2.6148924827575684
Validation loss: 2.8964621995085027

Epoch: 6| Step: 4
Training loss: 3.3445968627929688
Validation loss: 2.9022058030610443

Epoch: 6| Step: 5
Training loss: 2.5423595905303955
Validation loss: 2.9108797145146195

Epoch: 6| Step: 6
Training loss: 3.481574058532715
Validation loss: 2.9134702067221365

Epoch: 6| Step: 7
Training loss: 3.335965156555176
Validation loss: 2.9260312049619612

Epoch: 6| Step: 8
Training loss: 2.20613169670105
Validation loss: 2.8938090391056512

Epoch: 6| Step: 9
Training loss: 2.814265727996826
Validation loss: 2.8759268893990466

Epoch: 6| Step: 10
Training loss: 2.600463390350342
Validation loss: 2.8736926612033638

Epoch: 6| Step: 11
Training loss: 3.008352041244507
Validation loss: 2.869283458238007

Epoch: 6| Step: 12
Training loss: 2.421839952468872
Validation loss: 2.8727946640342794

Epoch: 6| Step: 13
Training loss: 2.804877996444702
Validation loss: 2.8684816411746445

Epoch: 35| Step: 0
Training loss: 2.9295828342437744
Validation loss: 2.8718378056762037

Epoch: 6| Step: 1
Training loss: 3.4371023178100586
Validation loss: 2.873474790203956

Epoch: 6| Step: 2
Training loss: 2.979567050933838
Validation loss: 2.8718009815421155

Epoch: 6| Step: 3
Training loss: 2.972808837890625
Validation loss: 2.866213716486449

Epoch: 6| Step: 4
Training loss: 2.057006359100342
Validation loss: 2.8690565247689523

Epoch: 6| Step: 5
Training loss: 2.708578109741211
Validation loss: 2.8659590034074682

Epoch: 6| Step: 6
Training loss: 3.744318962097168
Validation loss: 2.8631488379611763

Epoch: 6| Step: 7
Training loss: 2.116250991821289
Validation loss: 2.8633458614349365

Epoch: 6| Step: 8
Training loss: 2.7008814811706543
Validation loss: 2.861083092228059

Epoch: 6| Step: 9
Training loss: 3.654686450958252
Validation loss: 2.8607753502425326

Epoch: 6| Step: 10
Training loss: 2.8188462257385254
Validation loss: 2.85821174293436

Epoch: 6| Step: 11
Training loss: 2.4095773696899414
Validation loss: 2.859994237140943

Epoch: 6| Step: 12
Training loss: 3.641622543334961
Validation loss: 2.861553761266893

Epoch: 6| Step: 13
Training loss: 3.587021827697754
Validation loss: 2.866608565853488

Epoch: 36| Step: 0
Training loss: 2.6871466636657715
Validation loss: 2.8720357264241865

Epoch: 6| Step: 1
Training loss: 2.3064329624176025
Validation loss: 2.871512148969917

Epoch: 6| Step: 2
Training loss: 2.7499237060546875
Validation loss: 2.8851053868570635

Epoch: 6| Step: 3
Training loss: 2.696234941482544
Validation loss: 2.905093741673295

Epoch: 6| Step: 4
Training loss: 3.370162010192871
Validation loss: 2.886935641688685

Epoch: 6| Step: 5
Training loss: 2.531064033508301
Validation loss: 2.860797018133184

Epoch: 6| Step: 6
Training loss: 2.818392515182495
Validation loss: 2.861692382443336

Epoch: 6| Step: 7
Training loss: 2.563352584838867
Validation loss: 2.8588850318744616

Epoch: 6| Step: 8
Training loss: 2.7765052318573
Validation loss: 2.8504352518307265

Epoch: 6| Step: 9
Training loss: 3.8235220909118652
Validation loss: 2.849204022397277

Epoch: 6| Step: 10
Training loss: 3.9681801795959473
Validation loss: 2.8521583387928624

Epoch: 6| Step: 11
Training loss: 3.115464210510254
Validation loss: 2.8487358195807344

Epoch: 6| Step: 12
Training loss: 3.0943450927734375
Validation loss: 2.8479483563412904

Epoch: 6| Step: 13
Training loss: 2.7225875854492188
Validation loss: 2.8481792429442048

Epoch: 37| Step: 0
Training loss: 2.739117383956909
Validation loss: 2.851144293303131

Epoch: 6| Step: 1
Training loss: 3.051687240600586
Validation loss: 2.8559768687012377

Epoch: 6| Step: 2
Training loss: 2.3872504234313965
Validation loss: 2.865338635701005

Epoch: 6| Step: 3
Training loss: 2.4484286308288574
Validation loss: 2.8665046230439217

Epoch: 6| Step: 4
Training loss: 2.5822343826293945
Validation loss: 2.852550523255461

Epoch: 6| Step: 5
Training loss: 3.308802843093872
Validation loss: 2.845554023660639

Epoch: 6| Step: 6
Training loss: 2.5607237815856934
Validation loss: 2.8446526476131972

Epoch: 6| Step: 7
Training loss: 3.454505443572998
Validation loss: 2.846316119675995

Epoch: 6| Step: 8
Training loss: 3.389349937438965
Validation loss: 2.8420115363213325

Epoch: 6| Step: 9
Training loss: 2.5402731895446777
Validation loss: 2.8427141071647726

Epoch: 6| Step: 10
Training loss: 3.4952731132507324
Validation loss: 2.844510696267569

Epoch: 6| Step: 11
Training loss: 3.8124685287475586
Validation loss: 2.843008666910151

Epoch: 6| Step: 12
Training loss: 2.427377700805664
Validation loss: 2.841859415013303

Epoch: 6| Step: 13
Training loss: 2.9675846099853516
Validation loss: 2.8413396496926584

Epoch: 38| Step: 0
Training loss: 4.074672698974609
Validation loss: 2.8408993905590427

Epoch: 6| Step: 1
Training loss: 1.7345924377441406
Validation loss: 2.8378179406607025

Epoch: 6| Step: 2
Training loss: 3.2612900733947754
Validation loss: 2.8384950724981164

Epoch: 6| Step: 3
Training loss: 2.778019905090332
Validation loss: 2.8434817790985107

Epoch: 6| Step: 4
Training loss: 2.4217634201049805
Validation loss: 2.8425908216866116

Epoch: 6| Step: 5
Training loss: 2.5901412963867188
Validation loss: 2.8490402929244505

Epoch: 6| Step: 6
Training loss: 4.036925315856934
Validation loss: 2.8456220421739804

Epoch: 6| Step: 7
Training loss: 2.513596534729004
Validation loss: 2.837260361640684

Epoch: 6| Step: 8
Training loss: 2.9145097732543945
Validation loss: 2.8327270964140534

Epoch: 6| Step: 9
Training loss: 2.996887683868408
Validation loss: 2.8328933690183904

Epoch: 6| Step: 10
Training loss: 3.063721179962158
Validation loss: 2.8316088594416136

Epoch: 6| Step: 11
Training loss: 2.9350199699401855
Validation loss: 2.834111072683847

Epoch: 6| Step: 12
Training loss: 2.58012056350708
Validation loss: 2.8422576227495746

Epoch: 6| Step: 13
Training loss: 3.5194344520568848
Validation loss: 2.848575948387064

Epoch: 39| Step: 0
Training loss: 3.5206892490386963
Validation loss: 2.8645920804751817

Epoch: 6| Step: 1
Training loss: 2.414936065673828
Validation loss: 2.873292412809146

Epoch: 6| Step: 2
Training loss: 2.9484806060791016
Validation loss: 2.869164961640553

Epoch: 6| Step: 3
Training loss: 3.734266757965088
Validation loss: 2.848881616387316

Epoch: 6| Step: 4
Training loss: 2.2904293537139893
Validation loss: 2.8328459878121652

Epoch: 6| Step: 5
Training loss: 2.866304636001587
Validation loss: 2.8271159792459137

Epoch: 6| Step: 6
Training loss: 2.895504951477051
Validation loss: 2.8343810522428123

Epoch: 6| Step: 7
Training loss: 2.9538564682006836
Validation loss: 2.8311712613669773

Epoch: 6| Step: 8
Training loss: 2.4136719703674316
Validation loss: 2.8388388849073842

Epoch: 6| Step: 9
Training loss: 2.84806752204895
Validation loss: 2.8380431257268435

Epoch: 6| Step: 10
Training loss: 3.0607171058654785
Validation loss: 2.839124766729211

Epoch: 6| Step: 11
Training loss: 3.0400774478912354
Validation loss: 2.8331682476946103

Epoch: 6| Step: 12
Training loss: 3.3055567741394043
Validation loss: 2.8284937950872604

Epoch: 6| Step: 13
Training loss: 2.798386812210083
Validation loss: 2.8279831050544657

Epoch: 40| Step: 0
Training loss: 3.346343755722046
Validation loss: 2.8250705708739576

Epoch: 6| Step: 1
Training loss: 2.5638513565063477
Validation loss: 2.824075324561006

Epoch: 6| Step: 2
Training loss: 3.5801949501037598
Validation loss: 2.8193119854055424

Epoch: 6| Step: 3
Training loss: 2.9977712631225586
Validation loss: 2.814815508422031

Epoch: 6| Step: 4
Training loss: 2.7690482139587402
Validation loss: 2.8162191401245775

Epoch: 6| Step: 5
Training loss: 3.1442582607269287
Validation loss: 2.812576978437362

Epoch: 6| Step: 6
Training loss: 2.576368808746338
Validation loss: 2.8129908448906353

Epoch: 6| Step: 7
Training loss: 2.754775047302246
Validation loss: 2.811483447269727

Epoch: 6| Step: 8
Training loss: 3.761404514312744
Validation loss: 2.8100653771431214

Epoch: 6| Step: 9
Training loss: 2.176483631134033
Validation loss: 2.816760496426654

Epoch: 6| Step: 10
Training loss: 2.7435755729675293
Validation loss: 2.81827635406166

Epoch: 6| Step: 11
Training loss: 2.663607120513916
Validation loss: 2.817975474942115

Epoch: 6| Step: 12
Training loss: 2.7957208156585693
Validation loss: 2.819803717315838

Epoch: 6| Step: 13
Training loss: 3.193067789077759
Validation loss: 2.8281286147332962

Epoch: 41| Step: 0
Training loss: 3.160053253173828
Validation loss: 2.810483447967037

Epoch: 6| Step: 1
Training loss: 2.8247127532958984
Validation loss: 2.8086819725651897

Epoch: 6| Step: 2
Training loss: 3.1774144172668457
Validation loss: 2.800654847134826

Epoch: 6| Step: 3
Training loss: 2.633082389831543
Validation loss: 2.7989870835376043

Epoch: 6| Step: 4
Training loss: 2.6848042011260986
Validation loss: 2.813711427873181

Epoch: 6| Step: 5
Training loss: 2.081637144088745
Validation loss: 2.821797122237503

Epoch: 6| Step: 6
Training loss: 2.5940322875976562
Validation loss: 2.823918237481066

Epoch: 6| Step: 7
Training loss: 3.2650089263916016
Validation loss: 2.8224950272549867

Epoch: 6| Step: 8
Training loss: 2.6882448196411133
Validation loss: 2.8173668025642313

Epoch: 6| Step: 9
Training loss: 3.0139148235321045
Validation loss: 2.8161726767016995

Epoch: 6| Step: 10
Training loss: 3.688483953475952
Validation loss: 2.811135450998942

Epoch: 6| Step: 11
Training loss: 2.6617431640625
Validation loss: 2.8025557097568305

Epoch: 6| Step: 12
Training loss: 3.6228997707366943
Validation loss: 2.799893053629065

Epoch: 6| Step: 13
Training loss: 2.9450738430023193
Validation loss: 2.7987065956156743

Epoch: 42| Step: 0
Training loss: 2.8002233505249023
Validation loss: 2.803189259703441

Epoch: 6| Step: 1
Training loss: 3.857196807861328
Validation loss: 2.801811654080627

Epoch: 6| Step: 2
Training loss: 3.2641992568969727
Validation loss: 2.799979717500748

Epoch: 6| Step: 3
Training loss: 3.0044524669647217
Validation loss: 2.798046919607347

Epoch: 6| Step: 4
Training loss: 2.570969581604004
Validation loss: 2.799810476200555

Epoch: 6| Step: 5
Training loss: 1.7715790271759033
Validation loss: 2.7959221075939875

Epoch: 6| Step: 6
Training loss: 2.2745256423950195
Validation loss: 2.7922134809596564

Epoch: 6| Step: 7
Training loss: 2.186586380004883
Validation loss: 2.793071387916483

Epoch: 6| Step: 8
Training loss: 3.903026580810547
Validation loss: 2.7904690978347615

Epoch: 6| Step: 9
Training loss: 1.8555940389633179
Validation loss: 2.788696878699846

Epoch: 6| Step: 10
Training loss: 3.4699621200561523
Validation loss: 2.79230398003773

Epoch: 6| Step: 11
Training loss: 3.269463300704956
Validation loss: 2.7987680794090353

Epoch: 6| Step: 12
Training loss: 3.152596950531006
Validation loss: 2.8113243426046064

Epoch: 6| Step: 13
Training loss: 3.6403210163116455
Validation loss: 2.8232764223570466

Epoch: 43| Step: 0
Training loss: 2.4487006664276123
Validation loss: 2.8490061862494356

Epoch: 6| Step: 1
Training loss: 3.731649875640869
Validation loss: 2.8445848931548414

Epoch: 6| Step: 2
Training loss: 2.6463096141815186
Validation loss: 2.817876790159492

Epoch: 6| Step: 3
Training loss: 2.805868148803711
Validation loss: 2.8095452913673977

Epoch: 6| Step: 4
Training loss: 2.9224698543548584
Validation loss: 2.804133574167887

Epoch: 6| Step: 5
Training loss: 2.7716803550720215
Validation loss: 2.7982994125735376

Epoch: 6| Step: 6
Training loss: 2.9597818851470947
Validation loss: 2.79534500645053

Epoch: 6| Step: 7
Training loss: 3.40071177482605
Validation loss: 2.7869764194693616

Epoch: 6| Step: 8
Training loss: 3.21724796295166
Validation loss: 2.7772719142257527

Epoch: 6| Step: 9
Training loss: 2.4826173782348633
Validation loss: 2.7697131197939635

Epoch: 6| Step: 10
Training loss: 3.3494749069213867
Validation loss: 2.786973673810241

Epoch: 6| Step: 11
Training loss: 2.8424973487854004
Validation loss: 2.853568382160638

Epoch: 6| Step: 12
Training loss: 2.708984851837158
Validation loss: 2.767402187470467

Epoch: 6| Step: 13
Training loss: 2.1317107677459717
Validation loss: 2.7668211383204304

Epoch: 44| Step: 0
Training loss: 3.3897321224212646
Validation loss: 2.778527336735879

Epoch: 6| Step: 1
Training loss: 1.9272979497909546
Validation loss: 2.785587638937017

Epoch: 6| Step: 2
Training loss: 3.030616044998169
Validation loss: 2.784140856035294

Epoch: 6| Step: 3
Training loss: 3.772554397583008
Validation loss: 2.784429227152178

Epoch: 6| Step: 4
Training loss: 2.50168514251709
Validation loss: 2.781647620662566

Epoch: 6| Step: 5
Training loss: 2.804112434387207
Validation loss: 2.7837899192687003

Epoch: 6| Step: 6
Training loss: 2.748272180557251
Validation loss: 2.7889435752745597

Epoch: 6| Step: 7
Training loss: 2.7785255908966064
Validation loss: 2.7937464534595446

Epoch: 6| Step: 8
Training loss: 2.7835450172424316
Validation loss: 2.7915796643944195

Epoch: 6| Step: 9
Training loss: 1.9254025220870972
Validation loss: 2.787893631125009

Epoch: 6| Step: 10
Training loss: 3.0815885066986084
Validation loss: 2.7920259916654198

Epoch: 6| Step: 11
Training loss: 3.183222770690918
Validation loss: 2.7859956807987665

Epoch: 6| Step: 12
Training loss: 3.6290059089660645
Validation loss: 2.782327357158866

Epoch: 6| Step: 13
Training loss: 2.943769693374634
Validation loss: 2.785735748147452

Epoch: 45| Step: 0
Training loss: 2.89223313331604
Validation loss: 2.7803052112620366

Epoch: 6| Step: 1
Training loss: 2.986208438873291
Validation loss: 2.78017016636428

Epoch: 6| Step: 2
Training loss: 3.125290870666504
Validation loss: 2.7813036903258292

Epoch: 6| Step: 3
Training loss: 2.588759422302246
Validation loss: 2.787744942531791

Epoch: 6| Step: 4
Training loss: 2.531456708908081
Validation loss: 2.794158758655671

Epoch: 6| Step: 5
Training loss: 2.049344301223755
Validation loss: 2.7908424536387124

Epoch: 6| Step: 6
Training loss: 3.1187338829040527
Validation loss: 2.7840691843340473

Epoch: 6| Step: 7
Training loss: 2.461347818374634
Validation loss: 2.7743187027592815

Epoch: 6| Step: 8
Training loss: 3.4573702812194824
Validation loss: 2.7742861522141324

Epoch: 6| Step: 9
Training loss: 3.010072708129883
Validation loss: 2.777518267272621

Epoch: 6| Step: 10
Training loss: 2.5996313095092773
Validation loss: 2.7737276349016415

Epoch: 6| Step: 11
Training loss: 3.5314526557922363
Validation loss: 2.7745113424075547

Epoch: 6| Step: 12
Training loss: 3.353273868560791
Validation loss: 2.774954313872963

Epoch: 6| Step: 13
Training loss: 2.520096778869629
Validation loss: 2.7734467291062876

Epoch: 46| Step: 0
Training loss: 2.699580192565918
Validation loss: 2.776239323359664

Epoch: 6| Step: 1
Training loss: 3.437911033630371
Validation loss: 2.7718792705125708

Epoch: 6| Step: 2
Training loss: 2.452450752258301
Validation loss: 2.7685856434606735

Epoch: 6| Step: 3
Training loss: 2.648448944091797
Validation loss: 2.7679466765414

Epoch: 6| Step: 4
Training loss: 2.280813217163086
Validation loss: 2.7717221321598178

Epoch: 6| Step: 5
Training loss: 2.314263343811035
Validation loss: 2.7728527694620113

Epoch: 6| Step: 6
Training loss: 4.181235313415527
Validation loss: 2.778388979614422

Epoch: 6| Step: 7
Training loss: 3.765813112258911
Validation loss: 2.769782563691498

Epoch: 6| Step: 8
Training loss: 2.5296072959899902
Validation loss: 2.7700193723042807

Epoch: 6| Step: 9
Training loss: 2.905622959136963
Validation loss: 2.7701810918828493

Epoch: 6| Step: 10
Training loss: 2.7308077812194824
Validation loss: 2.7694507798840924

Epoch: 6| Step: 11
Training loss: 2.7369420528411865
Validation loss: 2.769604634213191

Epoch: 6| Step: 12
Training loss: 3.011117458343506
Validation loss: 2.768566349501251

Epoch: 6| Step: 13
Training loss: 2.6736598014831543
Validation loss: 2.7702011216071343

Epoch: 47| Step: 0
Training loss: 3.7399654388427734
Validation loss: 2.768641774372388

Epoch: 6| Step: 1
Training loss: 1.7018985748291016
Validation loss: 2.764180552574896

Epoch: 6| Step: 2
Training loss: 1.8372365236282349
Validation loss: 2.7637729978048675

Epoch: 6| Step: 3
Training loss: 2.520458698272705
Validation loss: 2.7698136683433288

Epoch: 6| Step: 4
Training loss: 2.9614603519439697
Validation loss: 2.7688546898544475

Epoch: 6| Step: 5
Training loss: 2.385580062866211
Validation loss: 2.7615416844685874

Epoch: 6| Step: 6
Training loss: 2.154547691345215
Validation loss: 2.7635533758389053

Epoch: 6| Step: 7
Training loss: 2.2760543823242188
Validation loss: 2.757745140342302

Epoch: 6| Step: 8
Training loss: 3.5180931091308594
Validation loss: 2.7575862125683854

Epoch: 6| Step: 9
Training loss: 4.389348983764648
Validation loss: 2.7567641940168155

Epoch: 6| Step: 10
Training loss: 3.5689148902893066
Validation loss: 2.753486712773641

Epoch: 6| Step: 11
Training loss: 2.8293683528900146
Validation loss: 2.754006511421614

Epoch: 6| Step: 12
Training loss: 3.3375892639160156
Validation loss: 2.7544870350950506

Epoch: 6| Step: 13
Training loss: 3.2393710613250732
Validation loss: 2.756544413105134

Epoch: 48| Step: 0
Training loss: 3.0078954696655273
Validation loss: 2.7552008346844743

Epoch: 6| Step: 1
Training loss: 2.9725112915039062
Validation loss: 2.7544106821860037

Epoch: 6| Step: 2
Training loss: 2.525829792022705
Validation loss: 2.748579381614603

Epoch: 6| Step: 3
Training loss: 2.979491710662842
Validation loss: 2.748580043033887

Epoch: 6| Step: 4
Training loss: 3.1756322383880615
Validation loss: 2.7498038840550247

Epoch: 6| Step: 5
Training loss: 2.653407096862793
Validation loss: 2.747640412340882

Epoch: 6| Step: 6
Training loss: 3.0747721195220947
Validation loss: 2.7394536515717864

Epoch: 6| Step: 7
Training loss: 3.572723388671875
Validation loss: 2.7286987791779223

Epoch: 6| Step: 8
Training loss: 2.2264089584350586
Validation loss: 2.7222072309063328

Epoch: 6| Step: 9
Training loss: 2.5539889335632324
Validation loss: 2.727341305825018

Epoch: 6| Step: 10
Training loss: 2.761648178100586
Validation loss: 2.7919592985542874

Epoch: 6| Step: 11
Training loss: 3.4753005504608154
Validation loss: 2.8128357959050003

Epoch: 6| Step: 12
Training loss: 2.5243430137634277
Validation loss: 2.745410144969981

Epoch: 6| Step: 13
Training loss: 2.4252405166625977
Validation loss: 2.7221464213504585

Epoch: 49| Step: 0
Training loss: 2.192042112350464
Validation loss: 2.745274661689676

Epoch: 6| Step: 1
Training loss: 3.4589133262634277
Validation loss: 2.748092992331392

Epoch: 6| Step: 2
Training loss: 2.964940309524536
Validation loss: 2.758589590749433

Epoch: 6| Step: 3
Training loss: 2.575923442840576
Validation loss: 2.759706069064397

Epoch: 6| Step: 4
Training loss: 2.7393555641174316
Validation loss: 2.7698712861666115

Epoch: 6| Step: 5
Training loss: 3.016876220703125
Validation loss: 2.7912264024057696

Epoch: 6| Step: 6
Training loss: 3.7033627033233643
Validation loss: 2.8420220318660943

Epoch: 6| Step: 7
Training loss: 2.885413646697998
Validation loss: 2.820708995224327

Epoch: 6| Step: 8
Training loss: 2.8338966369628906
Validation loss: 2.791671247892482

Epoch: 6| Step: 9
Training loss: 2.851541757583618
Validation loss: 2.759075108394828

Epoch: 6| Step: 10
Training loss: 2.7894163131713867
Validation loss: 2.75288801552147

Epoch: 6| Step: 11
Training loss: 3.1950156688690186
Validation loss: 2.752324532437068

Epoch: 6| Step: 12
Training loss: 2.661374092102051
Validation loss: 2.750526228258687

Epoch: 6| Step: 13
Training loss: 2.1572065353393555
Validation loss: 2.750172035668486

Epoch: 50| Step: 0
Training loss: 3.450638771057129
Validation loss: 2.751990282407371

Epoch: 6| Step: 1
Training loss: 2.4203550815582275
Validation loss: 2.7542625037572717

Epoch: 6| Step: 2
Training loss: 2.762712240219116
Validation loss: 2.7484964683491695

Epoch: 6| Step: 3
Training loss: 1.9488657712936401
Validation loss: 2.7508396076899704

Epoch: 6| Step: 4
Training loss: 2.9711365699768066
Validation loss: 2.7476649694545294

Epoch: 6| Step: 5
Training loss: 3.1009716987609863
Validation loss: 2.7447830579614125

Epoch: 6| Step: 6
Training loss: 2.8041703701019287
Validation loss: 2.7414403551368305

Epoch: 6| Step: 7
Training loss: 2.537252187728882
Validation loss: 2.735235998707433

Epoch: 6| Step: 8
Training loss: 3.233503818511963
Validation loss: 2.7291729552771455

Epoch: 6| Step: 9
Training loss: 2.7747719287872314
Validation loss: 2.7262594366586335

Epoch: 6| Step: 10
Training loss: 3.801896810531616
Validation loss: 2.7279395980219685

Epoch: 6| Step: 11
Training loss: 2.41127347946167
Validation loss: 2.7260760235530075

Epoch: 6| Step: 12
Training loss: 3.0402369499206543
Validation loss: 2.7277913785749868

Epoch: 6| Step: 13
Training loss: 2.7382750511169434
Validation loss: 2.752060128796485

Epoch: 51| Step: 0
Training loss: 3.611294746398926
Validation loss: 2.8110772127746255

Epoch: 6| Step: 1
Training loss: 2.932645797729492
Validation loss: 2.836847610371087

Epoch: 6| Step: 2
Training loss: 2.937918186187744
Validation loss: 2.8450541701368106

Epoch: 6| Step: 3
Training loss: 2.867497444152832
Validation loss: 2.867509913700883

Epoch: 6| Step: 4
Training loss: 2.9781205654144287
Validation loss: 2.862055132465978

Epoch: 6| Step: 5
Training loss: 2.7608718872070312
Validation loss: 2.8505493056389595

Epoch: 6| Step: 6
Training loss: 3.430981397628784
Validation loss: 2.8125878175099692

Epoch: 6| Step: 7
Training loss: 2.701606273651123
Validation loss: 2.8169002250958513

Epoch: 6| Step: 8
Training loss: 2.8593592643737793
Validation loss: 2.8212201364578737

Epoch: 6| Step: 9
Training loss: 2.9349350929260254
Validation loss: 2.8262314232446815

Epoch: 6| Step: 10
Training loss: 2.5296168327331543
Validation loss: 2.8337377066253335

Epoch: 6| Step: 11
Training loss: 2.4938063621520996
Validation loss: 2.8355845302663822

Epoch: 6| Step: 12
Training loss: 2.8769726753234863
Validation loss: 2.7714349351903445

Epoch: 6| Step: 13
Training loss: 3.0610759258270264
Validation loss: 2.756237135138563

Epoch: 52| Step: 0
Training loss: 2.1381607055664062
Validation loss: 2.7491754588260444

Epoch: 6| Step: 1
Training loss: 3.9745919704437256
Validation loss: 2.731279468023649

Epoch: 6| Step: 2
Training loss: 2.7509970664978027
Validation loss: 2.741328357368387

Epoch: 6| Step: 3
Training loss: 2.7492783069610596
Validation loss: 2.702893011031612

Epoch: 6| Step: 4
Training loss: 2.3438515663146973
Validation loss: 2.7008965656321537

Epoch: 6| Step: 5
Training loss: 2.6705129146575928
Validation loss: 2.7110742189550914

Epoch: 6| Step: 6
Training loss: 2.980529546737671
Validation loss: 2.7217822715800297

Epoch: 6| Step: 7
Training loss: 3.3577513694763184
Validation loss: 2.7302837038552887

Epoch: 6| Step: 8
Training loss: 2.668336868286133
Validation loss: 2.7371053593133086

Epoch: 6| Step: 9
Training loss: 3.0757360458374023
Validation loss: 2.744337915092386

Epoch: 6| Step: 10
Training loss: 2.6189517974853516
Validation loss: 2.728310708076723

Epoch: 6| Step: 11
Training loss: 3.436173677444458
Validation loss: 2.7290668846458517

Epoch: 6| Step: 12
Training loss: 2.160529375076294
Validation loss: 2.730562899702339

Epoch: 6| Step: 13
Training loss: 3.2899839878082275
Validation loss: 2.727933601666522

Epoch: 53| Step: 0
Training loss: 2.419132947921753
Validation loss: 2.728566420975552

Epoch: 6| Step: 1
Training loss: 2.4249234199523926
Validation loss: 2.738528461866481

Epoch: 6| Step: 2
Training loss: 2.782618999481201
Validation loss: 2.782322311914095

Epoch: 6| Step: 3
Training loss: 2.6672372817993164
Validation loss: 2.793259502739035

Epoch: 6| Step: 4
Training loss: 2.6252079010009766
Validation loss: 2.777877971690188

Epoch: 6| Step: 5
Training loss: 2.100675582885742
Validation loss: 2.7627033828407206

Epoch: 6| Step: 6
Training loss: 2.9499776363372803
Validation loss: 2.7371690375830537

Epoch: 6| Step: 7
Training loss: 3.1061782836914062
Validation loss: 2.7308319973689255

Epoch: 6| Step: 8
Training loss: 3.0089240074157715
Validation loss: 2.7176543538288405

Epoch: 6| Step: 9
Training loss: 3.6704602241516113
Validation loss: 2.710186812185472

Epoch: 6| Step: 10
Training loss: 3.0277011394500732
Validation loss: 2.715399001234321

Epoch: 6| Step: 11
Training loss: 3.2978110313415527
Validation loss: 2.7192170876328663

Epoch: 6| Step: 12
Training loss: 3.0028133392333984
Validation loss: 2.7232072943000385

Epoch: 6| Step: 13
Training loss: 2.880420207977295
Validation loss: 2.7223115813347603

Epoch: 54| Step: 0
Training loss: 2.4624602794647217
Validation loss: 2.723017813057028

Epoch: 6| Step: 1
Training loss: 2.469028949737549
Validation loss: 2.721429258264521

Epoch: 6| Step: 2
Training loss: 2.751356840133667
Validation loss: 2.7181429709157636

Epoch: 6| Step: 3
Training loss: 3.4281818866729736
Validation loss: 2.7167475710632982

Epoch: 6| Step: 4
Training loss: 2.489760637283325
Validation loss: 2.715224555743638

Epoch: 6| Step: 5
Training loss: 2.2642040252685547
Validation loss: 2.711629454807569

Epoch: 6| Step: 6
Training loss: 3.278207302093506
Validation loss: 2.7092561260346444

Epoch: 6| Step: 7
Training loss: 3.2876105308532715
Validation loss: 2.7067152479643464

Epoch: 6| Step: 8
Training loss: 2.5473928451538086
Validation loss: 2.70448883118168

Epoch: 6| Step: 9
Training loss: 3.5955088138580322
Validation loss: 2.70194306296687

Epoch: 6| Step: 10
Training loss: 3.1758718490600586
Validation loss: 2.7008940199370026

Epoch: 6| Step: 11
Training loss: 2.7071967124938965
Validation loss: 2.6994866376282065

Epoch: 6| Step: 12
Training loss: 2.5899457931518555
Validation loss: 2.6986988513700423

Epoch: 6| Step: 13
Training loss: 2.749199390411377
Validation loss: 2.694890573460569

Epoch: 55| Step: 0
Training loss: 2.6685233116149902
Validation loss: 2.6947424181046022

Epoch: 6| Step: 1
Training loss: 2.40653395652771
Validation loss: 2.69701950780807

Epoch: 6| Step: 2
Training loss: 3.8104734420776367
Validation loss: 2.7047465283383607

Epoch: 6| Step: 3
Training loss: 2.6265554428100586
Validation loss: 2.706848375258907

Epoch: 6| Step: 4
Training loss: 3.7120440006256104
Validation loss: 2.7135324478149414

Epoch: 6| Step: 5
Training loss: 3.03507399559021
Validation loss: 2.71872111546096

Epoch: 6| Step: 6
Training loss: 3.159794330596924
Validation loss: 2.7196213199246313

Epoch: 6| Step: 7
Training loss: 2.071885108947754
Validation loss: 2.7148180879572386

Epoch: 6| Step: 8
Training loss: 2.8268041610717773
Validation loss: 2.732824807525963

Epoch: 6| Step: 9
Training loss: 2.4282097816467285
Validation loss: 2.7212075366768786

Epoch: 6| Step: 10
Training loss: 2.463191509246826
Validation loss: 2.7130981312003186

Epoch: 6| Step: 11
Training loss: 3.1665468215942383
Validation loss: 2.717890347203901

Epoch: 6| Step: 12
Training loss: 1.9034725427627563
Validation loss: 2.7162209505675943

Epoch: 6| Step: 13
Training loss: 3.8057806491851807
Validation loss: 2.7059002614790395

Epoch: 56| Step: 0
Training loss: 3.125199794769287
Validation loss: 2.680288073837116

Epoch: 6| Step: 1
Training loss: 3.147646903991699
Validation loss: 2.6777919594959547

Epoch: 6| Step: 2
Training loss: 2.672600507736206
Validation loss: 2.6703238820516937

Epoch: 6| Step: 3
Training loss: 2.3729774951934814
Validation loss: 2.6665558020273843

Epoch: 6| Step: 4
Training loss: 2.8479089736938477
Validation loss: 2.667922960814609

Epoch: 6| Step: 5
Training loss: 3.371415376663208
Validation loss: 2.6658317914573093

Epoch: 6| Step: 6
Training loss: 2.1816694736480713
Validation loss: 2.6593983865553334

Epoch: 6| Step: 7
Training loss: 3.023075580596924
Validation loss: 2.6624443736127628

Epoch: 6| Step: 8
Training loss: 2.8953003883361816
Validation loss: 2.6599539966993433

Epoch: 6| Step: 9
Training loss: 2.243447780609131
Validation loss: 2.661037104104155

Epoch: 6| Step: 10
Training loss: 3.0552093982696533
Validation loss: 2.662057517677225

Epoch: 6| Step: 11
Training loss: 2.976266384124756
Validation loss: 2.6585520595632572

Epoch: 6| Step: 12
Training loss: 2.2183048725128174
Validation loss: 2.658023500955233

Epoch: 6| Step: 13
Training loss: 3.349874258041382
Validation loss: 2.656860920690721

Epoch: 57| Step: 0
Training loss: 2.866750478744507
Validation loss: 2.65485373620064

Epoch: 6| Step: 1
Training loss: 2.7827699184417725
Validation loss: 2.655102422160487

Epoch: 6| Step: 2
Training loss: 2.876753330230713
Validation loss: 2.6529788740219606

Epoch: 6| Step: 3
Training loss: 2.2662553787231445
Validation loss: 2.64914704907325

Epoch: 6| Step: 4
Training loss: 3.544442892074585
Validation loss: 2.649928487757201

Epoch: 6| Step: 5
Training loss: 2.86504864692688
Validation loss: 2.646825590441304

Epoch: 6| Step: 6
Training loss: 3.1275196075439453
Validation loss: 2.645392871672107

Epoch: 6| Step: 7
Training loss: 3.122860908508301
Validation loss: 2.646268529276694

Epoch: 6| Step: 8
Training loss: 2.1940791606903076
Validation loss: 2.6489946611465944

Epoch: 6| Step: 9
Training loss: 3.6984143257141113
Validation loss: 2.6461251115286224

Epoch: 6| Step: 10
Training loss: 2.201834201812744
Validation loss: 2.6463998235682005

Epoch: 6| Step: 11
Training loss: 2.652364492416382
Validation loss: 2.6443716326067523

Epoch: 6| Step: 12
Training loss: 2.1172683238983154
Validation loss: 2.646616312765306

Epoch: 6| Step: 13
Training loss: 2.761626958847046
Validation loss: 2.641690279847832

Epoch: 58| Step: 0
Training loss: 3.938469171524048
Validation loss: 2.6425350712191675

Epoch: 6| Step: 1
Training loss: 2.515472650527954
Validation loss: 2.645596983612225

Epoch: 6| Step: 2
Training loss: 2.5229697227478027
Validation loss: 2.643062622316422

Epoch: 6| Step: 3
Training loss: 3.746765613555908
Validation loss: 2.6443072518994732

Epoch: 6| Step: 4
Training loss: 2.4924635887145996
Validation loss: 2.6439665902045464

Epoch: 6| Step: 5
Training loss: 2.693504810333252
Validation loss: 2.6455091097021617

Epoch: 6| Step: 6
Training loss: 2.5338637828826904
Validation loss: 2.64428626337359

Epoch: 6| Step: 7
Training loss: 1.943826675415039
Validation loss: 2.6418036542912966

Epoch: 6| Step: 8
Training loss: 3.150747776031494
Validation loss: 2.6437517340465257

Epoch: 6| Step: 9
Training loss: 2.939181089401245
Validation loss: 2.6423762716272825

Epoch: 6| Step: 10
Training loss: 2.719186782836914
Validation loss: 2.639065009291454

Epoch: 6| Step: 11
Training loss: 2.8911495208740234
Validation loss: 2.633284545713855

Epoch: 6| Step: 12
Training loss: 2.3354156017303467
Validation loss: 2.637718867230159

Epoch: 6| Step: 13
Training loss: 2.360541820526123
Validation loss: 2.6383178208463933

Epoch: 59| Step: 0
Training loss: 2.520650625228882
Validation loss: 2.643162024918423

Epoch: 6| Step: 1
Training loss: 2.98770809173584
Validation loss: 2.657802815078407

Epoch: 6| Step: 2
Training loss: 2.8011014461517334
Validation loss: 2.661441787596672

Epoch: 6| Step: 3
Training loss: 2.773514747619629
Validation loss: 2.64019940745446

Epoch: 6| Step: 4
Training loss: 3.6228511333465576
Validation loss: 2.6286988642907914

Epoch: 6| Step: 5
Training loss: 2.921579360961914
Validation loss: 2.627465622399443

Epoch: 6| Step: 6
Training loss: 2.9268527030944824
Validation loss: 2.6306777436246156

Epoch: 6| Step: 7
Training loss: 3.357480049133301
Validation loss: 2.6339697530192714

Epoch: 6| Step: 8
Training loss: 2.607149124145508
Validation loss: 2.6339748392822924

Epoch: 6| Step: 9
Training loss: 2.558197021484375
Validation loss: 2.6398231342274654

Epoch: 6| Step: 10
Training loss: 2.2726361751556396
Validation loss: 2.645503379965341

Epoch: 6| Step: 11
Training loss: 2.2812912464141846
Validation loss: 2.6443716813159246

Epoch: 6| Step: 12
Training loss: 3.008394241333008
Validation loss: 2.637787906072473

Epoch: 6| Step: 13
Training loss: 2.142331123352051
Validation loss: 2.6445994915500766

Epoch: 60| Step: 0
Training loss: 1.7920422554016113
Validation loss: 2.642544646416941

Epoch: 6| Step: 1
Training loss: 2.747767925262451
Validation loss: 2.6372132250057754

Epoch: 6| Step: 2
Training loss: 2.726040840148926
Validation loss: 2.6653300434030514

Epoch: 6| Step: 3
Training loss: 3.213756561279297
Validation loss: 2.7499678801464778

Epoch: 6| Step: 4
Training loss: 3.9184608459472656
Validation loss: 2.748561736076109

Epoch: 6| Step: 5
Training loss: 2.818554162979126
Validation loss: 2.710385776335193

Epoch: 6| Step: 6
Training loss: 2.522125482559204
Validation loss: 2.6642253527077298

Epoch: 6| Step: 7
Training loss: 2.056380271911621
Validation loss: 2.6359703181892313

Epoch: 6| Step: 8
Training loss: 4.124251365661621
Validation loss: 2.6294615986526653

Epoch: 6| Step: 9
Training loss: 2.8777060508728027
Validation loss: 2.6344609798923617

Epoch: 6| Step: 10
Training loss: 2.659182548522949
Validation loss: 2.629913314696281

Epoch: 6| Step: 11
Training loss: 2.7597641944885254
Validation loss: 2.640365913350095

Epoch: 6| Step: 12
Training loss: 2.737208366394043
Validation loss: 2.6349062458161385

Epoch: 6| Step: 13
Training loss: 1.9929509162902832
Validation loss: 2.6264996195352204

Epoch: 61| Step: 0
Training loss: 2.333503484725952
Validation loss: 2.6245408417076193

Epoch: 6| Step: 1
Training loss: 2.8357958793640137
Validation loss: 2.6249590073862383

Epoch: 6| Step: 2
Training loss: 2.335984230041504
Validation loss: 2.6400541515760523

Epoch: 6| Step: 3
Training loss: 2.7274975776672363
Validation loss: 2.632519655330207

Epoch: 6| Step: 4
Training loss: 2.700221061706543
Validation loss: 2.6221364441738335

Epoch: 6| Step: 5
Training loss: 2.6734633445739746
Validation loss: 2.619858923778739

Epoch: 6| Step: 6
Training loss: 4.238052845001221
Validation loss: 2.616366676104966

Epoch: 6| Step: 7
Training loss: 2.840941905975342
Validation loss: 2.6125253759404665

Epoch: 6| Step: 8
Training loss: 2.1868844032287598
Validation loss: 2.6083181699117026

Epoch: 6| Step: 9
Training loss: 2.6286532878875732
Validation loss: 2.604332649579612

Epoch: 6| Step: 10
Training loss: 2.660417079925537
Validation loss: 2.602425923911474

Epoch: 6| Step: 11
Training loss: 2.6604714393615723
Validation loss: 2.603768951149397

Epoch: 6| Step: 12
Training loss: 3.496279239654541
Validation loss: 2.599473343100599

Epoch: 6| Step: 13
Training loss: 2.168433666229248
Validation loss: 2.600958083265571

Epoch: 62| Step: 0
Training loss: 2.4041008949279785
Validation loss: 2.5951898790174917

Epoch: 6| Step: 1
Training loss: 2.573098659515381
Validation loss: 2.593681573867798

Epoch: 6| Step: 2
Training loss: 2.458312511444092
Validation loss: 2.591253717740377

Epoch: 6| Step: 3
Training loss: 3.7740635871887207
Validation loss: 2.5842074271171325

Epoch: 6| Step: 4
Training loss: 2.2933759689331055
Validation loss: 2.5863599161947928

Epoch: 6| Step: 5
Training loss: 3.407724380493164
Validation loss: 2.5876640299315095

Epoch: 6| Step: 6
Training loss: 2.27755069732666
Validation loss: 2.589520292897378

Epoch: 6| Step: 7
Training loss: 3.0628724098205566
Validation loss: 2.5887524722724833

Epoch: 6| Step: 8
Training loss: 2.6700220108032227
Validation loss: 2.5891101770503546

Epoch: 6| Step: 9
Training loss: 2.00480318069458
Validation loss: 2.5883383340733026

Epoch: 6| Step: 10
Training loss: 2.6614952087402344
Validation loss: 2.586572616331039

Epoch: 6| Step: 11
Training loss: 2.9609692096710205
Validation loss: 2.580219094471265

Epoch: 6| Step: 12
Training loss: 2.967306613922119
Validation loss: 2.5771793729515484

Epoch: 6| Step: 13
Training loss: 3.415860891342163
Validation loss: 2.577127674574493

Epoch: 63| Step: 0
Training loss: 2.1183714866638184
Validation loss: 2.5746837687748734

Epoch: 6| Step: 1
Training loss: 2.8148608207702637
Validation loss: 2.5769148488198557

Epoch: 6| Step: 2
Training loss: 3.4068775177001953
Validation loss: 2.5765263495906705

Epoch: 6| Step: 3
Training loss: 2.30733585357666
Validation loss: 2.576173577257382

Epoch: 6| Step: 4
Training loss: 2.699256658554077
Validation loss: 2.5796968167827976

Epoch: 6| Step: 5
Training loss: 1.5744552612304688
Validation loss: 2.575794296879922

Epoch: 6| Step: 6
Training loss: 3.064671039581299
Validation loss: 2.5725333947007374

Epoch: 6| Step: 7
Training loss: 3.109978437423706
Validation loss: 2.5671200367712204

Epoch: 6| Step: 8
Training loss: 3.1304895877838135
Validation loss: 2.5665500651123705

Epoch: 6| Step: 9
Training loss: 2.7384400367736816
Validation loss: 2.565081068264541

Epoch: 6| Step: 10
Training loss: 2.4583194255828857
Validation loss: 2.563930170510405

Epoch: 6| Step: 11
Training loss: 3.266672372817993
Validation loss: 2.560687800889374

Epoch: 6| Step: 12
Training loss: 2.48408842086792
Validation loss: 2.567829321789485

Epoch: 6| Step: 13
Training loss: 3.5441136360168457
Validation loss: 2.571074757524716

Epoch: 64| Step: 0
Training loss: 2.211212396621704
Validation loss: 2.5866489666764454

Epoch: 6| Step: 1
Training loss: 2.2995047569274902
Validation loss: 2.5996423254730883

Epoch: 6| Step: 2
Training loss: 3.153205394744873
Validation loss: 2.597825393881849

Epoch: 6| Step: 3
Training loss: 2.83111572265625
Validation loss: 2.58911467623967

Epoch: 6| Step: 4
Training loss: 2.0949172973632812
Validation loss: 2.5785176010542017

Epoch: 6| Step: 5
Training loss: 2.125978469848633
Validation loss: 2.555411666952154

Epoch: 6| Step: 6
Training loss: 3.1232614517211914
Validation loss: 2.564986034106183

Epoch: 6| Step: 7
Training loss: 2.74137020111084
Validation loss: 2.589192423769223

Epoch: 6| Step: 8
Training loss: 2.8019683361053467
Validation loss: 2.6232636205611692

Epoch: 6| Step: 9
Training loss: 3.231307029724121
Validation loss: 2.6291207216119252

Epoch: 6| Step: 10
Training loss: 2.775381565093994
Validation loss: 2.6135706593913417

Epoch: 6| Step: 11
Training loss: 3.6042795181274414
Validation loss: 2.611987870226624

Epoch: 6| Step: 12
Training loss: 3.3858494758605957
Validation loss: 2.606127941480247

Epoch: 6| Step: 13
Training loss: 1.986003041267395
Validation loss: 2.6104557360372236

Epoch: 65| Step: 0
Training loss: 2.6761646270751953
Validation loss: 2.6243371322590816

Epoch: 6| Step: 1
Training loss: 2.877511501312256
Validation loss: 2.6337326290786907

Epoch: 6| Step: 2
Training loss: 2.818903923034668
Validation loss: 2.6457286188679356

Epoch: 6| Step: 3
Training loss: 2.0018064975738525
Validation loss: 2.627707794148435

Epoch: 6| Step: 4
Training loss: 3.5662262439727783
Validation loss: 2.5936355231910624

Epoch: 6| Step: 5
Training loss: 2.067244529724121
Validation loss: 2.5816845252949703

Epoch: 6| Step: 6
Training loss: 2.8318443298339844
Validation loss: 2.5909257858030257

Epoch: 6| Step: 7
Training loss: 3.1001181602478027
Validation loss: 2.5974165444732993

Epoch: 6| Step: 8
Training loss: 2.4063384532928467
Validation loss: 2.603245201931205

Epoch: 6| Step: 9
Training loss: 2.1104726791381836
Validation loss: 2.6081454241147606

Epoch: 6| Step: 10
Training loss: 3.6049368381500244
Validation loss: 2.623770426678401

Epoch: 6| Step: 11
Training loss: 3.4894495010375977
Validation loss: 2.6145710381128455

Epoch: 6| Step: 12
Training loss: 2.6667709350585938
Validation loss: 2.600724120293894

Epoch: 6| Step: 13
Training loss: 2.7788853645324707
Validation loss: 2.5880650140905894

Epoch: 66| Step: 0
Training loss: 2.5201172828674316
Validation loss: 2.583117505555512

Epoch: 6| Step: 1
Training loss: 2.474353313446045
Validation loss: 2.5671413842067925

Epoch: 6| Step: 2
Training loss: 2.5380642414093018
Validation loss: 2.526885663309405

Epoch: 6| Step: 3
Training loss: 3.4392528533935547
Validation loss: 2.515525605088921

Epoch: 6| Step: 4
Training loss: 2.354224681854248
Validation loss: 2.5164149217708136

Epoch: 6| Step: 5
Training loss: 3.4374642372131348
Validation loss: 2.539935617036717

Epoch: 6| Step: 6
Training loss: 2.422109603881836
Validation loss: 2.5441230548325406

Epoch: 6| Step: 7
Training loss: 2.4651808738708496
Validation loss: 2.5599963306098856

Epoch: 6| Step: 8
Training loss: 2.761101245880127
Validation loss: 2.544211974707983

Epoch: 6| Step: 9
Training loss: 2.30918288230896
Validation loss: 2.528492635296237

Epoch: 6| Step: 10
Training loss: 2.1340720653533936
Validation loss: 2.516211668650309

Epoch: 6| Step: 11
Training loss: 2.4920153617858887
Validation loss: 2.5104434080021356

Epoch: 6| Step: 12
Training loss: 3.406738042831421
Validation loss: 2.513161390058456

Epoch: 6| Step: 13
Training loss: 3.9306423664093018
Validation loss: 2.5167569883408083

Epoch: 67| Step: 0
Training loss: 2.480059862136841
Validation loss: 2.517833214934154

Epoch: 6| Step: 1
Training loss: 2.8152332305908203
Validation loss: 2.5152754270902244

Epoch: 6| Step: 2
Training loss: 2.5245232582092285
Validation loss: 2.5164186159769693

Epoch: 6| Step: 3
Training loss: 2.361131191253662
Validation loss: 2.5163152615229287

Epoch: 6| Step: 4
Training loss: 2.561391830444336
Validation loss: 2.5180869692115375

Epoch: 6| Step: 5
Training loss: 2.6906590461730957
Validation loss: 2.5168907283454813

Epoch: 6| Step: 6
Training loss: 2.7616465091705322
Validation loss: 2.5104023615519204

Epoch: 6| Step: 7
Training loss: 2.9637231826782227
Validation loss: 2.5066249498756985

Epoch: 6| Step: 8
Training loss: 2.4405324459075928
Validation loss: 2.5122150785179547

Epoch: 6| Step: 9
Training loss: 2.896371841430664
Validation loss: 2.508201773448657

Epoch: 6| Step: 10
Training loss: 3.0900816917419434
Validation loss: 2.509377646189864

Epoch: 6| Step: 11
Training loss: 2.8417351245880127
Validation loss: 2.5095038849820375

Epoch: 6| Step: 12
Training loss: 3.016852617263794
Validation loss: 2.507870699769707

Epoch: 6| Step: 13
Training loss: 2.2067112922668457
Validation loss: 2.500325915633991

Epoch: 68| Step: 0
Training loss: 2.370497226715088
Validation loss: 2.4988951606135212

Epoch: 6| Step: 1
Training loss: 3.8462963104248047
Validation loss: 2.5022443058670207

Epoch: 6| Step: 2
Training loss: 2.512838363647461
Validation loss: 2.5096906051840833

Epoch: 6| Step: 3
Training loss: 2.7256369590759277
Validation loss: 2.506060678471801

Epoch: 6| Step: 4
Training loss: 2.565567970275879
Validation loss: 2.5068535010019937

Epoch: 6| Step: 5
Training loss: 2.571263074874878
Validation loss: 2.5055503076122654

Epoch: 6| Step: 6
Training loss: 2.6352219581604004
Validation loss: 2.5070953651141097

Epoch: 6| Step: 7
Training loss: 2.7202792167663574
Validation loss: 2.507617945312172

Epoch: 6| Step: 8
Training loss: 3.0885696411132812
Validation loss: 2.5047141390462078

Epoch: 6| Step: 9
Training loss: 2.3485920429229736
Validation loss: 2.508920782355852

Epoch: 6| Step: 10
Training loss: 3.2666478157043457
Validation loss: 2.513830989919683

Epoch: 6| Step: 11
Training loss: 2.2450809478759766
Validation loss: 2.5146283872665895

Epoch: 6| Step: 12
Training loss: 2.8513545989990234
Validation loss: 2.4956561749981296

Epoch: 6| Step: 13
Training loss: 1.5827499628067017
Validation loss: 2.4866289579740135

Epoch: 69| Step: 0
Training loss: 2.4295811653137207
Validation loss: 2.4882390012023268

Epoch: 6| Step: 1
Training loss: 2.7720730304718018
Validation loss: 2.4878666759819112

Epoch: 6| Step: 2
Training loss: 2.805276393890381
Validation loss: 2.491665663257722

Epoch: 6| Step: 3
Training loss: 2.852041721343994
Validation loss: 2.486492201846133

Epoch: 6| Step: 4
Training loss: 3.2367749214172363
Validation loss: 2.484622747667374

Epoch: 6| Step: 5
Training loss: 2.615018844604492
Validation loss: 2.4843561828777356

Epoch: 6| Step: 6
Training loss: 2.7584569454193115
Validation loss: 2.4844323460773756

Epoch: 6| Step: 7
Training loss: 3.382477283477783
Validation loss: 2.4858211548097673

Epoch: 6| Step: 8
Training loss: 2.082430601119995
Validation loss: 2.485405597635495

Epoch: 6| Step: 9
Training loss: 2.64231014251709
Validation loss: 2.4850230550253265

Epoch: 6| Step: 10
Training loss: 2.5543274879455566
Validation loss: 2.4846902355071037

Epoch: 6| Step: 11
Training loss: 2.524625778198242
Validation loss: 2.480614190460533

Epoch: 6| Step: 12
Training loss: 2.6106839179992676
Validation loss: 2.478409808169129

Epoch: 6| Step: 13
Training loss: 2.2216691970825195
Validation loss: 2.480315257144231

Epoch: 70| Step: 0
Training loss: 2.9738388061523438
Validation loss: 2.4780986155233076

Epoch: 6| Step: 1
Training loss: 3.0399093627929688
Validation loss: 2.478431458114296

Epoch: 6| Step: 2
Training loss: 2.8657796382904053
Validation loss: 2.483594350917365

Epoch: 6| Step: 3
Training loss: 1.5950472354888916
Validation loss: 2.4879107936736076

Epoch: 6| Step: 4
Training loss: 3.229173183441162
Validation loss: 2.4921537086527836

Epoch: 6| Step: 5
Training loss: 2.8932137489318848
Validation loss: 2.499147771507181

Epoch: 6| Step: 6
Training loss: 2.406336784362793
Validation loss: 2.4905948638916016

Epoch: 6| Step: 7
Training loss: 3.206082820892334
Validation loss: 2.481269739007437

Epoch: 6| Step: 8
Training loss: 2.2014315128326416
Validation loss: 2.4746861688552366

Epoch: 6| Step: 9
Training loss: 2.4029150009155273
Validation loss: 2.477155003496396

Epoch: 6| Step: 10
Training loss: 2.801344394683838
Validation loss: 2.478415478942215

Epoch: 6| Step: 11
Training loss: 2.4859886169433594
Validation loss: 2.4818917935894382

Epoch: 6| Step: 12
Training loss: 2.5061938762664795
Validation loss: 2.4845936426552395

Epoch: 6| Step: 13
Training loss: 3.2076618671417236
Validation loss: 2.4947701679762972

Epoch: 71| Step: 0
Training loss: 2.1310300827026367
Validation loss: 2.4917126740178754

Epoch: 6| Step: 1
Training loss: 2.6494674682617188
Validation loss: 2.499366839726766

Epoch: 6| Step: 2
Training loss: 2.633082389831543
Validation loss: 2.5084390460803943

Epoch: 6| Step: 3
Training loss: 2.431392192840576
Validation loss: 2.539269265308175

Epoch: 6| Step: 4
Training loss: 2.786545991897583
Validation loss: 2.622589562528877

Epoch: 6| Step: 5
Training loss: 2.871462345123291
Validation loss: 2.5723261628099667

Epoch: 6| Step: 6
Training loss: 3.2992541790008545
Validation loss: 2.5029576337465675

Epoch: 6| Step: 7
Training loss: 3.0160770416259766
Validation loss: 2.4757902570950088

Epoch: 6| Step: 8
Training loss: 2.9197633266448975
Validation loss: 2.476031934061358

Epoch: 6| Step: 9
Training loss: 2.578075885772705
Validation loss: 2.48797099051937

Epoch: 6| Step: 10
Training loss: 3.170945644378662
Validation loss: 2.5084716248255905

Epoch: 6| Step: 11
Training loss: 3.535304069519043
Validation loss: 2.5305531922207085

Epoch: 6| Step: 12
Training loss: 1.6404057741165161
Validation loss: 2.5350795843267955

Epoch: 6| Step: 13
Training loss: 2.13960862159729
Validation loss: 2.578752553591164

Epoch: 72| Step: 0
Training loss: 2.6795101165771484
Validation loss: 2.58007905303791

Epoch: 6| Step: 1
Training loss: 2.315847158432007
Validation loss: 2.537823671935707

Epoch: 6| Step: 2
Training loss: 3.457343578338623
Validation loss: 2.5113070959685952

Epoch: 6| Step: 3
Training loss: 2.4503884315490723
Validation loss: 2.4928817595205

Epoch: 6| Step: 4
Training loss: 2.635408878326416
Validation loss: 2.4867824944116736

Epoch: 6| Step: 5
Training loss: 3.082761287689209
Validation loss: 2.4874543605312223

Epoch: 6| Step: 6
Training loss: 2.3691582679748535
Validation loss: 2.4903666255294636

Epoch: 6| Step: 7
Training loss: 3.315258502960205
Validation loss: 2.5006113026731756

Epoch: 6| Step: 8
Training loss: 2.522761344909668
Validation loss: 2.5310030650067072

Epoch: 6| Step: 9
Training loss: 3.0392768383026123
Validation loss: 2.587888991960915

Epoch: 6| Step: 10
Training loss: 2.081026554107666
Validation loss: 2.6375505283314693

Epoch: 6| Step: 11
Training loss: 2.616051197052002
Validation loss: 2.616395693953319

Epoch: 6| Step: 12
Training loss: 3.005303382873535
Validation loss: 2.582656571941991

Epoch: 6| Step: 13
Training loss: 2.643028974533081
Validation loss: 2.521249612172445

Epoch: 73| Step: 0
Training loss: 2.755676031112671
Validation loss: 2.4994493351187757

Epoch: 6| Step: 1
Training loss: 2.557966709136963
Validation loss: 2.4795155743116974

Epoch: 6| Step: 2
Training loss: 2.305436611175537
Validation loss: 2.4838563652448755

Epoch: 6| Step: 3
Training loss: 2.79451060295105
Validation loss: 2.496399187272595

Epoch: 6| Step: 4
Training loss: 2.8256425857543945
Validation loss: 2.528342375191309

Epoch: 6| Step: 5
Training loss: 2.626068115234375
Validation loss: 2.5408117181511334

Epoch: 6| Step: 6
Training loss: 2.038257598876953
Validation loss: 2.550329828775057

Epoch: 6| Step: 7
Training loss: 3.078700065612793
Validation loss: 2.546299090949438

Epoch: 6| Step: 8
Training loss: 3.0146613121032715
Validation loss: 2.5437405981043333

Epoch: 6| Step: 9
Training loss: 2.4116950035095215
Validation loss: 2.491211211809548

Epoch: 6| Step: 10
Training loss: 2.367755651473999
Validation loss: 2.462667308827882

Epoch: 6| Step: 11
Training loss: 3.7920398712158203
Validation loss: 2.462437650208832

Epoch: 6| Step: 12
Training loss: 2.5830373764038086
Validation loss: 2.4630153461169173

Epoch: 6| Step: 13
Training loss: 2.60311222076416
Validation loss: 2.4618878467108614

Epoch: 74| Step: 0
Training loss: 2.4058799743652344
Validation loss: 2.464704918605025

Epoch: 6| Step: 1
Training loss: 2.820817232131958
Validation loss: 2.4735373297045307

Epoch: 6| Step: 2
Training loss: 2.934077501296997
Validation loss: 2.4851434640986945

Epoch: 6| Step: 3
Training loss: 2.442081928253174
Validation loss: 2.484409469430165

Epoch: 6| Step: 4
Training loss: 2.51289701461792
Validation loss: 2.49202230668837

Epoch: 6| Step: 5
Training loss: 2.7765657901763916
Validation loss: 2.484569557251469

Epoch: 6| Step: 6
Training loss: 2.3095462322235107
Validation loss: 2.494288872647029

Epoch: 6| Step: 7
Training loss: 2.4038259983062744
Validation loss: 2.4946755132367535

Epoch: 6| Step: 8
Training loss: 3.03151798248291
Validation loss: 2.5220984438414216

Epoch: 6| Step: 9
Training loss: 3.3036110401153564
Validation loss: 2.495709608959895

Epoch: 6| Step: 10
Training loss: 2.6793692111968994
Validation loss: 2.4767395065676783

Epoch: 6| Step: 11
Training loss: 2.006807804107666
Validation loss: 2.471100107316048

Epoch: 6| Step: 12
Training loss: 3.4083924293518066
Validation loss: 2.461629359952865

Epoch: 6| Step: 13
Training loss: 2.4941532611846924
Validation loss: 2.4476383040028233

Epoch: 75| Step: 0
Training loss: 3.141998529434204
Validation loss: 2.444257079914052

Epoch: 6| Step: 1
Training loss: 2.8585116863250732
Validation loss: 2.446510325195969

Epoch: 6| Step: 2
Training loss: 2.2174134254455566
Validation loss: 2.4445988952472644

Epoch: 6| Step: 3
Training loss: 2.266720771789551
Validation loss: 2.445688896281745

Epoch: 6| Step: 4
Training loss: 2.118338108062744
Validation loss: 2.4426510654469973

Epoch: 6| Step: 5
Training loss: 2.6677231788635254
Validation loss: 2.4448877047466975

Epoch: 6| Step: 6
Training loss: 2.8066396713256836
Validation loss: 2.445059863469934

Epoch: 6| Step: 7
Training loss: 2.708080768585205
Validation loss: 2.4438692895315026

Epoch: 6| Step: 8
Training loss: 2.869307041168213
Validation loss: 2.4414494883629585

Epoch: 6| Step: 9
Training loss: 2.830583333969116
Validation loss: 2.4477662655615036

Epoch: 6| Step: 10
Training loss: 2.7653822898864746
Validation loss: 2.4454035707699355

Epoch: 6| Step: 11
Training loss: 2.763758420944214
Validation loss: 2.4476858492820495

Epoch: 6| Step: 12
Training loss: 3.0065841674804688
Validation loss: 2.4517079989115396

Epoch: 6| Step: 13
Training loss: 2.2283976078033447
Validation loss: 2.4530250795425905

Testing loss: 2.5962614642249213
