Epoch: 1| Step: 0
Training loss: 4.5011444091796875
Validation loss: 5.144134526611657

Epoch: 6| Step: 1
Training loss: 5.19766902923584
Validation loss: 5.124401318129673

Epoch: 6| Step: 2
Training loss: 6.568962097167969
Validation loss: 5.106957820154006

Epoch: 6| Step: 3
Training loss: 5.999413013458252
Validation loss: 5.088562606483378

Epoch: 6| Step: 4
Training loss: 4.613358974456787
Validation loss: 5.067686998715964

Epoch: 6| Step: 5
Training loss: 4.565983295440674
Validation loss: 5.0435998516698035

Epoch: 6| Step: 6
Training loss: 6.036647796630859
Validation loss: 5.016312163363221

Epoch: 6| Step: 7
Training loss: 4.785833358764648
Validation loss: 4.985808193042714

Epoch: 6| Step: 8
Training loss: 3.997437000274658
Validation loss: 4.952531860720727

Epoch: 6| Step: 9
Training loss: 4.384434700012207
Validation loss: 4.916353666654197

Epoch: 6| Step: 10
Training loss: 5.357926368713379
Validation loss: 4.876893351154942

Epoch: 6| Step: 11
Training loss: 3.4542481899261475
Validation loss: 4.833986538712696

Epoch: 6| Step: 12
Training loss: 3.916461944580078
Validation loss: 4.7876820666815645

Epoch: 6| Step: 13
Training loss: 2.530564546585083
Validation loss: 4.7403923978087725

Epoch: 2| Step: 0
Training loss: 5.050482749938965
Validation loss: 4.692782166183636

Epoch: 6| Step: 1
Training loss: 3.6555817127227783
Validation loss: 4.641041324984643

Epoch: 6| Step: 2
Training loss: 4.778921604156494
Validation loss: 4.589176685579361

Epoch: 6| Step: 3
Training loss: 3.7495973110198975
Validation loss: 4.534373027022167

Epoch: 6| Step: 4
Training loss: 3.555753231048584
Validation loss: 4.476859318312778

Epoch: 6| Step: 5
Training loss: 2.917492628097534
Validation loss: 4.41236941019694

Epoch: 6| Step: 6
Training loss: 4.311925411224365
Validation loss: 4.344990427776049

Epoch: 6| Step: 7
Training loss: 5.025112628936768
Validation loss: 4.268716327605709

Epoch: 6| Step: 8
Training loss: 5.661924362182617
Validation loss: 4.18283530973619

Epoch: 6| Step: 9
Training loss: 4.33047342300415
Validation loss: 4.104620725877823

Epoch: 6| Step: 10
Training loss: 3.8312976360321045
Validation loss: 4.036287456430415

Epoch: 6| Step: 11
Training loss: 3.743532657623291
Validation loss: 3.9753514848729616

Epoch: 6| Step: 12
Training loss: 3.0031073093414307
Validation loss: 3.9171895673198085

Epoch: 6| Step: 13
Training loss: 3.9043383598327637
Validation loss: 3.8677093393059185

Epoch: 3| Step: 0
Training loss: 3.532421350479126
Validation loss: 3.81522019960547

Epoch: 6| Step: 1
Training loss: 3.8283073902130127
Validation loss: 3.775547524934174

Epoch: 6| Step: 2
Training loss: 4.580894947052002
Validation loss: 3.738904960693852

Epoch: 6| Step: 3
Training loss: 3.113705635070801
Validation loss: 3.7112269375913884

Epoch: 6| Step: 4
Training loss: 2.6096854209899902
Validation loss: 3.6851074439223095

Epoch: 6| Step: 5
Training loss: 2.7514615058898926
Validation loss: 3.6557181112227903

Epoch: 6| Step: 6
Training loss: 4.192414283752441
Validation loss: 3.634436376633183

Epoch: 6| Step: 7
Training loss: 4.598586559295654
Validation loss: 3.6158839835915515

Epoch: 6| Step: 8
Training loss: 3.4076666831970215
Validation loss: 3.587145556685745

Epoch: 6| Step: 9
Training loss: 3.334404468536377
Validation loss: 3.5645973733676377

Epoch: 6| Step: 10
Training loss: 2.914849042892456
Validation loss: 3.544357845860143

Epoch: 6| Step: 11
Training loss: 3.201401710510254
Validation loss: 3.5300317502790883

Epoch: 6| Step: 12
Training loss: 3.7501425743103027
Validation loss: 3.5159078464713147

Epoch: 6| Step: 13
Training loss: 4.111263751983643
Validation loss: 3.497883963328536

Epoch: 4| Step: 0
Training loss: 3.9146881103515625
Validation loss: 3.4764467208616194

Epoch: 6| Step: 1
Training loss: 4.054310321807861
Validation loss: 3.4750419483389905

Epoch: 6| Step: 2
Training loss: 3.9078848361968994
Validation loss: 3.4492107847685456

Epoch: 6| Step: 3
Training loss: 3.7354681491851807
Validation loss: 3.4262052915429555

Epoch: 6| Step: 4
Training loss: 3.5222301483154297
Validation loss: 3.3989348924288185

Epoch: 6| Step: 5
Training loss: 4.1222968101501465
Validation loss: 3.380531916054346

Epoch: 6| Step: 6
Training loss: 2.8490519523620605
Validation loss: 3.3467947513826433

Epoch: 6| Step: 7
Training loss: 3.2295851707458496
Validation loss: 3.3190623355168167

Epoch: 6| Step: 8
Training loss: 1.7569470405578613
Validation loss: 3.316784317775439

Epoch: 6| Step: 9
Training loss: 3.9838004112243652
Validation loss: 3.325415160066338

Epoch: 6| Step: 10
Training loss: 3.6994245052337646
Validation loss: 3.2813276911294587

Epoch: 6| Step: 11
Training loss: 2.7184391021728516
Validation loss: 3.2996453521072224

Epoch: 6| Step: 12
Training loss: 2.4084527492523193
Validation loss: 3.3011618147614183

Epoch: 6| Step: 13
Training loss: 2.2760801315307617
Validation loss: 3.3022261255530903

Epoch: 5| Step: 0
Training loss: 4.12726354598999
Validation loss: 3.313407410857498

Epoch: 6| Step: 1
Training loss: 3.745842456817627
Validation loss: 3.307533848670221

Epoch: 6| Step: 2
Training loss: 3.9022066593170166
Validation loss: 3.272362611627066

Epoch: 6| Step: 3
Training loss: 3.373333692550659
Validation loss: 3.2299226304536224

Epoch: 6| Step: 4
Training loss: 3.667131185531616
Validation loss: 3.222283632524552

Epoch: 6| Step: 5
Training loss: 2.7642221450805664
Validation loss: 3.2226001703610985

Epoch: 6| Step: 6
Training loss: 2.0021073818206787
Validation loss: 3.2339964630783244

Epoch: 6| Step: 7
Training loss: 2.265326976776123
Validation loss: 3.253013362166702

Epoch: 6| Step: 8
Training loss: 4.535592079162598
Validation loss: 3.2585611599747852

Epoch: 6| Step: 9
Training loss: 2.5486550331115723
Validation loss: 3.2209630320149083

Epoch: 6| Step: 10
Training loss: 2.9777541160583496
Validation loss: 3.196488611159786

Epoch: 6| Step: 11
Training loss: 3.0680155754089355
Validation loss: 3.185544588232553

Epoch: 6| Step: 12
Training loss: 3.1419081687927246
Validation loss: 3.1868731514100106

Epoch: 6| Step: 13
Training loss: 3.13667893409729
Validation loss: 3.208554652429396

Epoch: 6| Step: 0
Training loss: 4.541815757751465
Validation loss: 3.2035709504158265

Epoch: 6| Step: 1
Training loss: 3.2049436569213867
Validation loss: 3.1860642689530567

Epoch: 6| Step: 2
Training loss: 2.3209152221679688
Validation loss: 3.1585784342981156

Epoch: 6| Step: 3
Training loss: 2.6524839401245117
Validation loss: 3.147211041501773

Epoch: 6| Step: 4
Training loss: 3.5303237438201904
Validation loss: 3.1408500133022184

Epoch: 6| Step: 5
Training loss: 4.147046089172363
Validation loss: 3.1390003876019548

Epoch: 6| Step: 6
Training loss: 2.324611186981201
Validation loss: 3.1384474615896902

Epoch: 6| Step: 7
Training loss: 2.479599952697754
Validation loss: 3.1466632299525763

Epoch: 6| Step: 8
Training loss: 2.6263046264648438
Validation loss: 3.175154383464526

Epoch: 6| Step: 9
Training loss: 3.4766135215759277
Validation loss: 3.1755685601183163

Epoch: 6| Step: 10
Training loss: 3.4331536293029785
Validation loss: 3.1663070032673497

Epoch: 6| Step: 11
Training loss: 3.951934814453125
Validation loss: 3.146590458449497

Epoch: 6| Step: 12
Training loss: 3.1290135383605957
Validation loss: 3.126142619758524

Epoch: 6| Step: 13
Training loss: 1.998826503753662
Validation loss: 3.109410111622144

Epoch: 7| Step: 0
Training loss: 3.221135377883911
Validation loss: 3.1135292412132345

Epoch: 6| Step: 1
Training loss: 3.585197925567627
Validation loss: 3.1139181839522494

Epoch: 6| Step: 2
Training loss: 3.297300100326538
Validation loss: 3.1034316708964687

Epoch: 6| Step: 3
Training loss: 2.3261094093322754
Validation loss: 3.10475613481255

Epoch: 6| Step: 4
Training loss: 1.9913744926452637
Validation loss: 3.098154088502289

Epoch: 6| Step: 5
Training loss: 3.5330653190612793
Validation loss: 3.0906581391570387

Epoch: 6| Step: 6
Training loss: 2.3453168869018555
Validation loss: 3.0670199958227014

Epoch: 6| Step: 7
Training loss: 3.7870607376098633
Validation loss: 3.057240473326816

Epoch: 6| Step: 8
Training loss: 3.1720972061157227
Validation loss: 3.0515899376202653

Epoch: 6| Step: 9
Training loss: 3.3229339122772217
Validation loss: 3.048760350032519

Epoch: 6| Step: 10
Training loss: 2.764169692993164
Validation loss: 3.0528855169973066

Epoch: 6| Step: 11
Training loss: 3.018515110015869
Validation loss: 3.0527762289970153

Epoch: 6| Step: 12
Training loss: 3.344169855117798
Validation loss: 3.0484506853165163

Epoch: 6| Step: 13
Training loss: 4.321935653686523
Validation loss: 3.0418109688707577

Epoch: 8| Step: 0
Training loss: 4.6628875732421875
Validation loss: 3.0255147949341805

Epoch: 6| Step: 1
Training loss: 3.567565441131592
Validation loss: 3.0165650229300223

Epoch: 6| Step: 2
Training loss: 2.433414936065674
Validation loss: 3.0135234196980796

Epoch: 6| Step: 3
Training loss: 2.438112735748291
Validation loss: 3.0153363417553645

Epoch: 6| Step: 4
Training loss: 3.874424457550049
Validation loss: 3.017754888021818

Epoch: 6| Step: 5
Training loss: 2.67427659034729
Validation loss: 3.006621668415685

Epoch: 6| Step: 6
Training loss: 2.8264291286468506
Validation loss: 2.998673874844787

Epoch: 6| Step: 7
Training loss: 2.800529718399048
Validation loss: 2.987428862561462

Epoch: 6| Step: 8
Training loss: 3.300956964492798
Validation loss: 2.9843768381303355

Epoch: 6| Step: 9
Training loss: 3.0069098472595215
Validation loss: 2.9810733743893203

Epoch: 6| Step: 10
Training loss: 2.455502986907959
Validation loss: 2.979169440525834

Epoch: 6| Step: 11
Training loss: 3.017449378967285
Validation loss: 2.9753638313662623

Epoch: 6| Step: 12
Training loss: 3.2838258743286133
Validation loss: 2.96637741468286

Epoch: 6| Step: 13
Training loss: 2.165273904800415
Validation loss: 2.961001644852341

Epoch: 9| Step: 0
Training loss: 3.3167076110839844
Validation loss: 2.9579875469207764

Epoch: 6| Step: 1
Training loss: 3.2912278175354004
Validation loss: 2.9522962108735116

Epoch: 6| Step: 2
Training loss: 2.296787977218628
Validation loss: 2.949596110210624

Epoch: 6| Step: 3
Training loss: 2.7413830757141113
Validation loss: 2.9406468509345927

Epoch: 6| Step: 4
Training loss: 2.8555126190185547
Validation loss: 2.9401840138179

Epoch: 6| Step: 5
Training loss: 2.9494056701660156
Validation loss: 2.9353703145057923

Epoch: 6| Step: 6
Training loss: 3.661651849746704
Validation loss: 2.9284205334160918

Epoch: 6| Step: 7
Training loss: 3.379398822784424
Validation loss: 2.924733272162817

Epoch: 6| Step: 8
Training loss: 3.0668540000915527
Validation loss: 2.9200885603504796

Epoch: 6| Step: 9
Training loss: 3.200646162033081
Validation loss: 2.9175893747678368

Epoch: 6| Step: 10
Training loss: 2.251415729522705
Validation loss: 2.9149410327275596

Epoch: 6| Step: 11
Training loss: 2.3710522651672363
Validation loss: 2.9138845474489274

Epoch: 6| Step: 12
Training loss: 3.4670965671539307
Validation loss: 2.9123585634334113

Epoch: 6| Step: 13
Training loss: 3.7693896293640137
Validation loss: 2.9065847807033087

Epoch: 10| Step: 0
Training loss: 2.866311550140381
Validation loss: 2.9001455691552933

Epoch: 6| Step: 1
Training loss: 3.6458816528320312
Validation loss: 2.8995539783149638

Epoch: 6| Step: 2
Training loss: 4.357715129852295
Validation loss: 2.8959919406521704

Epoch: 6| Step: 3
Training loss: 3.433102607727051
Validation loss: 2.888209460884012

Epoch: 6| Step: 4
Training loss: 2.6513915061950684
Validation loss: 2.884441739769392

Epoch: 6| Step: 5
Training loss: 3.2190561294555664
Validation loss: 2.881178538004557

Epoch: 6| Step: 6
Training loss: 3.4002039432525635
Validation loss: 2.8776830370708177

Epoch: 6| Step: 7
Training loss: 2.8613815307617188
Validation loss: 2.872278646756244

Epoch: 6| Step: 8
Training loss: 3.2334585189819336
Validation loss: 2.8678893222603747

Epoch: 6| Step: 9
Training loss: 2.3837883472442627
Validation loss: 2.864619037156464

Epoch: 6| Step: 10
Training loss: 2.3873705863952637
Validation loss: 2.862495953036893

Epoch: 6| Step: 11
Training loss: 2.024383068084717
Validation loss: 2.859594650166009

Epoch: 6| Step: 12
Training loss: 2.6959075927734375
Validation loss: 2.8568301995595298

Epoch: 6| Step: 13
Training loss: 2.344242811203003
Validation loss: 2.8519998417105725

Epoch: 11| Step: 0
Training loss: 2.726252555847168
Validation loss: 2.8514470797713085

Epoch: 6| Step: 1
Training loss: 3.4869909286499023
Validation loss: 2.848869113511937

Epoch: 6| Step: 2
Training loss: 3.2387189865112305
Validation loss: 2.8448953525994414

Epoch: 6| Step: 3
Training loss: 2.854668378829956
Validation loss: 2.8448061276507635

Epoch: 6| Step: 4
Training loss: 3.0447700023651123
Validation loss: 2.8437728984381563

Epoch: 6| Step: 5
Training loss: 2.572918176651001
Validation loss: 2.843042501839258

Epoch: 6| Step: 6
Training loss: 3.088474750518799
Validation loss: 2.839374816545876

Epoch: 6| Step: 7
Training loss: 3.802417516708374
Validation loss: 2.8372647967389835

Epoch: 6| Step: 8
Training loss: 2.9839701652526855
Validation loss: 2.833962009799096

Epoch: 6| Step: 9
Training loss: 2.501840829849243
Validation loss: 2.8301725361936834

Epoch: 6| Step: 10
Training loss: 2.6384363174438477
Validation loss: 2.8309849282746673

Epoch: 6| Step: 11
Training loss: 3.0094170570373535
Validation loss: 2.827435508851082

Epoch: 6| Step: 12
Training loss: 2.52164888381958
Validation loss: 2.8260015672253025

Epoch: 6| Step: 13
Training loss: 2.90274977684021
Validation loss: 2.821681809681718

Epoch: 12| Step: 0
Training loss: 3.907644510269165
Validation loss: 2.820090993758171

Epoch: 6| Step: 1
Training loss: 2.8243567943573
Validation loss: 2.8185482255874144

Epoch: 6| Step: 2
Training loss: 3.1128830909729004
Validation loss: 2.81675600236462

Epoch: 6| Step: 3
Training loss: 2.318732738494873
Validation loss: 2.8135708429480113

Epoch: 6| Step: 4
Training loss: 3.392228603363037
Validation loss: 2.8110991165202153

Epoch: 6| Step: 5
Training loss: 3.074925184249878
Validation loss: 2.8104719449115056

Epoch: 6| Step: 6
Training loss: 2.599963665008545
Validation loss: 2.808068170342394

Epoch: 6| Step: 7
Training loss: 2.9670660495758057
Validation loss: 2.8060698688671155

Epoch: 6| Step: 8
Training loss: 2.702104091644287
Validation loss: 2.804560253697057

Epoch: 6| Step: 9
Training loss: 2.8026037216186523
Validation loss: 2.8028896547132924

Epoch: 6| Step: 10
Training loss: 2.316908597946167
Validation loss: 2.800009322422807

Epoch: 6| Step: 11
Training loss: 3.10385799407959
Validation loss: 2.800049384435018

Epoch: 6| Step: 12
Training loss: 3.0763957500457764
Validation loss: 2.7969270803595103

Epoch: 6| Step: 13
Training loss: 2.978287696838379
Validation loss: 2.7956358463533464

Epoch: 13| Step: 0
Training loss: 3.276942014694214
Validation loss: 2.7927648072601645

Epoch: 6| Step: 1
Training loss: 3.3479902744293213
Validation loss: 2.791353623072306

Epoch: 6| Step: 2
Training loss: 2.782505989074707
Validation loss: 2.7893018876352618

Epoch: 6| Step: 3
Training loss: 2.2643916606903076
Validation loss: 2.7881100664856615

Epoch: 6| Step: 4
Training loss: 2.654865026473999
Validation loss: 2.7869769962885047

Epoch: 6| Step: 5
Training loss: 3.2961947917938232
Validation loss: 2.7852098275256414

Epoch: 6| Step: 6
Training loss: 3.122340679168701
Validation loss: 2.784903541687996

Epoch: 6| Step: 7
Training loss: 2.8207781314849854
Validation loss: 2.7840522694331344

Epoch: 6| Step: 8
Training loss: 2.8764090538024902
Validation loss: 2.78183102479545

Epoch: 6| Step: 9
Training loss: 3.028114080429077
Validation loss: 2.7797471733503443

Epoch: 6| Step: 10
Training loss: 2.528745174407959
Validation loss: 2.7780462336796585

Epoch: 6| Step: 11
Training loss: 3.104139804840088
Validation loss: 2.77569398572368

Epoch: 6| Step: 12
Training loss: 2.594783306121826
Validation loss: 2.7759299662805375

Epoch: 6| Step: 13
Training loss: 3.4865875244140625
Validation loss: 2.785173649428993

Epoch: 14| Step: 0
Training loss: 2.7924273014068604
Validation loss: 2.7718171534999723

Epoch: 6| Step: 1
Training loss: 2.8071680068969727
Validation loss: 2.776224413225728

Epoch: 6| Step: 2
Training loss: 2.636916399002075
Validation loss: 2.784207823455975

Epoch: 6| Step: 3
Training loss: 2.9040396213531494
Validation loss: 2.7739564244465162

Epoch: 6| Step: 4
Training loss: 2.7555413246154785
Validation loss: 2.772443494489116

Epoch: 6| Step: 5
Training loss: 2.6298160552978516
Validation loss: 2.768733734725624

Epoch: 6| Step: 6
Training loss: 3.3419241905212402
Validation loss: 2.7720296754631946

Epoch: 6| Step: 7
Training loss: 2.6717772483825684
Validation loss: 2.777052381987213

Epoch: 6| Step: 8
Training loss: 2.5442163944244385
Validation loss: 2.8070310700324272

Epoch: 6| Step: 9
Training loss: 3.472048759460449
Validation loss: 2.8121372243409515

Epoch: 6| Step: 10
Training loss: 3.0849485397338867
Validation loss: 2.808116679550499

Epoch: 6| Step: 11
Training loss: 3.712923765182495
Validation loss: 2.8069644076849825

Epoch: 6| Step: 12
Training loss: 2.897169589996338
Validation loss: 2.8075523299555623

Epoch: 6| Step: 13
Training loss: 2.6057896614074707
Validation loss: 2.805763926557315

Epoch: 15| Step: 0
Training loss: 2.236996650695801
Validation loss: 2.8012342606821368

Epoch: 6| Step: 1
Training loss: 3.063493251800537
Validation loss: 2.796354119495679

Epoch: 6| Step: 2
Training loss: 2.6177802085876465
Validation loss: 2.793081716824603

Epoch: 6| Step: 3
Training loss: 2.7739956378936768
Validation loss: 2.7924443649989303

Epoch: 6| Step: 4
Training loss: 3.0699338912963867
Validation loss: 2.7886717345124934

Epoch: 6| Step: 5
Training loss: 2.632214307785034
Validation loss: 2.7866975774047194

Epoch: 6| Step: 6
Training loss: 3.561048984527588
Validation loss: 2.7842523154392036

Epoch: 6| Step: 7
Training loss: 3.2167716026306152
Validation loss: 2.7946392490017797

Epoch: 6| Step: 8
Training loss: 2.6067967414855957
Validation loss: 2.7951227759802215

Epoch: 6| Step: 9
Training loss: 3.150090217590332
Validation loss: 2.7868616350235476

Epoch: 6| Step: 10
Training loss: 2.6519734859466553
Validation loss: 2.784573257610362

Epoch: 6| Step: 11
Training loss: 3.5388848781585693
Validation loss: 2.777576264514718

Epoch: 6| Step: 12
Training loss: 2.9988322257995605
Validation loss: 2.7682366166063535

Epoch: 6| Step: 13
Training loss: 2.745464563369751
Validation loss: 2.7596407936465357

Epoch: 16| Step: 0
Training loss: 2.8281068801879883
Validation loss: 2.7578716124257734

Epoch: 6| Step: 1
Training loss: 2.6214983463287354
Validation loss: 2.7435226389156875

Epoch: 6| Step: 2
Training loss: 3.2918074131011963
Validation loss: 2.7365798027284685

Epoch: 6| Step: 3
Training loss: 3.1852402687072754
Validation loss: 2.728335134444698

Epoch: 6| Step: 4
Training loss: 2.279278039932251
Validation loss: 2.727348727564658

Epoch: 6| Step: 5
Training loss: 2.9276599884033203
Validation loss: 2.7243789319069154

Epoch: 6| Step: 6
Training loss: 2.8781862258911133
Validation loss: 2.7257886830196587

Epoch: 6| Step: 7
Training loss: 2.3575658798217773
Validation loss: 2.731099062068488

Epoch: 6| Step: 8
Training loss: 3.3864474296569824
Validation loss: 2.725528509386124

Epoch: 6| Step: 9
Training loss: 2.3465771675109863
Validation loss: 2.7228128833155476

Epoch: 6| Step: 10
Training loss: 1.6795504093170166
Validation loss: 2.720217312535932

Epoch: 6| Step: 11
Training loss: 3.9151597023010254
Validation loss: 2.7183866603400118

Epoch: 6| Step: 12
Training loss: 3.1481151580810547
Validation loss: 2.713068905697074

Epoch: 6| Step: 13
Training loss: 4.066805362701416
Validation loss: 2.712506091722878

Epoch: 17| Step: 0
Training loss: 3.0296196937561035
Validation loss: 2.714457365774339

Epoch: 6| Step: 1
Training loss: 2.509526252746582
Validation loss: 2.7231561650512037

Epoch: 6| Step: 2
Training loss: 3.0415639877319336
Validation loss: 2.7190217869256132

Epoch: 6| Step: 3
Training loss: 3.0351450443267822
Validation loss: 2.7084355610673145

Epoch: 6| Step: 4
Training loss: 2.7625732421875
Validation loss: 2.702752765788827

Epoch: 6| Step: 5
Training loss: 2.3552188873291016
Validation loss: 2.7071237410268476

Epoch: 6| Step: 6
Training loss: 2.5858094692230225
Validation loss: 2.713799843224146

Epoch: 6| Step: 7
Training loss: 3.2519030570983887
Validation loss: 2.707086834856259

Epoch: 6| Step: 8
Training loss: 3.1903634071350098
Validation loss: 2.7298153984931206

Epoch: 6| Step: 9
Training loss: 2.541311502456665
Validation loss: 2.6996269174801406

Epoch: 6| Step: 10
Training loss: 2.7810161113739014
Validation loss: 2.694680070364347

Epoch: 6| Step: 11
Training loss: 3.0619821548461914
Validation loss: 2.7071321395135697

Epoch: 6| Step: 12
Training loss: 3.0975515842437744
Validation loss: 2.737426145102388

Epoch: 6| Step: 13
Training loss: 3.1602206230163574
Validation loss: 2.774409155691824

Epoch: 18| Step: 0
Training loss: 2.9974145889282227
Validation loss: 2.848165178811678

Epoch: 6| Step: 1
Training loss: 2.6821722984313965
Validation loss: 2.884024968711279

Epoch: 6| Step: 2
Training loss: 2.6389334201812744
Validation loss: 2.8184511712802354

Epoch: 6| Step: 3
Training loss: 2.969076156616211
Validation loss: 2.7242743866417998

Epoch: 6| Step: 4
Training loss: 3.4128780364990234
Validation loss: 2.688344581152803

Epoch: 6| Step: 5
Training loss: 3.565638542175293
Validation loss: 2.6907040585753736

Epoch: 6| Step: 6
Training loss: 2.9173641204833984
Validation loss: 2.727664696272983

Epoch: 6| Step: 7
Training loss: 2.3001646995544434
Validation loss: 2.7479311881526822

Epoch: 6| Step: 8
Training loss: 3.3787198066711426
Validation loss: 2.7832376264756724

Epoch: 6| Step: 9
Training loss: 3.330742359161377
Validation loss: 2.728537272381526

Epoch: 6| Step: 10
Training loss: 2.895113945007324
Validation loss: 2.699468510125273

Epoch: 6| Step: 11
Training loss: 2.809929847717285
Validation loss: 2.6814733064302834

Epoch: 6| Step: 12
Training loss: 2.5027637481689453
Validation loss: 2.6900334460760957

Epoch: 6| Step: 13
Training loss: 1.404585361480713
Validation loss: 2.7034647618570635

Epoch: 19| Step: 0
Training loss: 2.524725914001465
Validation loss: 2.71683435029881

Epoch: 6| Step: 1
Training loss: 2.607224941253662
Validation loss: 2.7178975100158365

Epoch: 6| Step: 2
Training loss: 3.7893574237823486
Validation loss: 2.740674331624021

Epoch: 6| Step: 3
Training loss: 3.0139565467834473
Validation loss: 2.7144480315587853

Epoch: 6| Step: 4
Training loss: 3.5070018768310547
Validation loss: 2.6906679881516324

Epoch: 6| Step: 5
Training loss: 3.7091240882873535
Validation loss: 2.681152794950752

Epoch: 6| Step: 6
Training loss: 2.8775320053100586
Validation loss: 2.675950550263928

Epoch: 6| Step: 7
Training loss: 2.4270591735839844
Validation loss: 2.6776765367036224

Epoch: 6| Step: 8
Training loss: 1.8492552042007446
Validation loss: 2.7104469242916314

Epoch: 6| Step: 9
Training loss: 2.617465019226074
Validation loss: 2.7350759506225586

Epoch: 6| Step: 10
Training loss: 3.0896103382110596
Validation loss: 2.7283680977359897

Epoch: 6| Step: 11
Training loss: 2.8797006607055664
Validation loss: 2.66270960018199

Epoch: 6| Step: 12
Training loss: 2.885071277618408
Validation loss: 2.6631155526766213

Epoch: 6| Step: 13
Training loss: 2.123833179473877
Validation loss: 2.669640915368193

Epoch: 20| Step: 0
Training loss: 2.550100803375244
Validation loss: 2.6787504303839897

Epoch: 6| Step: 1
Training loss: 2.646026134490967
Validation loss: 2.686115652002314

Epoch: 6| Step: 2
Training loss: 2.5039403438568115
Validation loss: 2.679434594287667

Epoch: 6| Step: 3
Training loss: 2.4884531497955322
Validation loss: 2.676667200621738

Epoch: 6| Step: 4
Training loss: 3.198509454727173
Validation loss: 2.6727368652179675

Epoch: 6| Step: 5
Training loss: 4.067265033721924
Validation loss: 2.675172334076256

Epoch: 6| Step: 6
Training loss: 2.729712963104248
Validation loss: 2.674267843205442

Epoch: 6| Step: 7
Training loss: 3.0593628883361816
Validation loss: 2.6693533235980618

Epoch: 6| Step: 8
Training loss: 3.701545476913452
Validation loss: 2.6679623537166144

Epoch: 6| Step: 9
Training loss: 2.7625694274902344
Validation loss: 2.666921441273023

Epoch: 6| Step: 10
Training loss: 2.5539729595184326
Validation loss: 2.6667946051525813

Epoch: 6| Step: 11
Training loss: 2.7108469009399414
Validation loss: 2.6602267501174763

Epoch: 6| Step: 12
Training loss: 1.7465860843658447
Validation loss: 2.659122951569096

Epoch: 6| Step: 13
Training loss: 3.479799509048462
Validation loss: 2.656068560897663

Epoch: 21| Step: 0
Training loss: 1.9039756059646606
Validation loss: 2.6528368867853636

Epoch: 6| Step: 1
Training loss: 3.1049916744232178
Validation loss: 2.650334181324128

Epoch: 6| Step: 2
Training loss: 2.6027374267578125
Validation loss: 2.6479116716692523

Epoch: 6| Step: 3
Training loss: 3.068742275238037
Validation loss: 2.6487185903774795

Epoch: 6| Step: 4
Training loss: 2.726372241973877
Validation loss: 2.651271163776357

Epoch: 6| Step: 5
Training loss: 3.4916000366210938
Validation loss: 2.654761473337809

Epoch: 6| Step: 6
Training loss: 2.1571807861328125
Validation loss: 2.6492092711951143

Epoch: 6| Step: 7
Training loss: 2.239964485168457
Validation loss: 2.6521843915344565

Epoch: 6| Step: 8
Training loss: 2.802713394165039
Validation loss: 2.652690590068858

Epoch: 6| Step: 9
Training loss: 3.2877414226531982
Validation loss: 2.653154626969368

Epoch: 6| Step: 10
Training loss: 2.3893678188323975
Validation loss: 2.6495166542709514

Epoch: 6| Step: 11
Training loss: 3.665565252304077
Validation loss: 2.6452021496270293

Epoch: 6| Step: 12
Training loss: 2.6287953853607178
Validation loss: 2.643280795825425

Epoch: 6| Step: 13
Training loss: 4.090615272521973
Validation loss: 2.6421914536465883

Epoch: 22| Step: 0
Training loss: 2.757521629333496
Validation loss: 2.6412051467485327

Epoch: 6| Step: 1
Training loss: 2.754300594329834
Validation loss: 2.642003684915522

Epoch: 6| Step: 2
Training loss: 2.8042023181915283
Validation loss: 2.642056726640271

Epoch: 6| Step: 3
Training loss: 2.180234432220459
Validation loss: 2.63624841936173

Epoch: 6| Step: 4
Training loss: 2.7671163082122803
Validation loss: 2.6406720556238645

Epoch: 6| Step: 5
Training loss: 2.3098723888397217
Validation loss: 2.646763816956551

Epoch: 6| Step: 6
Training loss: 3.5289783477783203
Validation loss: 2.6352459743458736

Epoch: 6| Step: 7
Training loss: 3.097773551940918
Validation loss: 2.637865420310728

Epoch: 6| Step: 8
Training loss: 2.4526286125183105
Validation loss: 2.6333099206288657

Epoch: 6| Step: 9
Training loss: 3.0438625812530518
Validation loss: 2.6375075847871843

Epoch: 6| Step: 10
Training loss: 3.345919370651245
Validation loss: 2.6484822509109334

Epoch: 6| Step: 11
Training loss: 2.7249536514282227
Validation loss: 2.6507326249153382

Epoch: 6| Step: 12
Training loss: 2.8448758125305176
Validation loss: 2.657770479879072

Epoch: 6| Step: 13
Training loss: 3.118380308151245
Validation loss: 2.654344215187975

Epoch: 23| Step: 0
Training loss: 1.7259190082550049
Validation loss: 2.6415373176656742

Epoch: 6| Step: 1
Training loss: 2.5553150177001953
Validation loss: 2.634571152348672

Epoch: 6| Step: 2
Training loss: 3.524937629699707
Validation loss: 2.6410181112186883

Epoch: 6| Step: 3
Training loss: 3.630030393600464
Validation loss: 2.6415495205950994

Epoch: 6| Step: 4
Training loss: 2.4844613075256348
Validation loss: 2.631960622725948

Epoch: 6| Step: 5
Training loss: 3.2929108142852783
Validation loss: 2.6251570922072216

Epoch: 6| Step: 6
Training loss: 3.2578110694885254
Validation loss: 2.6241243347044914

Epoch: 6| Step: 7
Training loss: 2.7336385250091553
Validation loss: 2.6211890379587808

Epoch: 6| Step: 8
Training loss: 2.546816349029541
Validation loss: 2.621802132616761

Epoch: 6| Step: 9
Training loss: 1.675437331199646
Validation loss: 2.6204666168459

Epoch: 6| Step: 10
Training loss: 3.2722678184509277
Validation loss: 2.622801060317665

Epoch: 6| Step: 11
Training loss: 3.3126091957092285
Validation loss: 2.649727946968489

Epoch: 6| Step: 12
Training loss: 2.619874954223633
Validation loss: 2.6335445373289046

Epoch: 6| Step: 13
Training loss: 2.941783905029297
Validation loss: 2.6231119786539385

Epoch: 24| Step: 0
Training loss: 2.5204854011535645
Validation loss: 2.6242155003291305

Epoch: 6| Step: 1
Training loss: 3.401602268218994
Validation loss: 2.6175784141786638

Epoch: 6| Step: 2
Training loss: 3.2460672855377197
Validation loss: 2.6161255349395094

Epoch: 6| Step: 3
Training loss: 3.0983147621154785
Validation loss: 2.623067617416382

Epoch: 6| Step: 4
Training loss: 2.5788228511810303
Validation loss: 2.6268947227026826

Epoch: 6| Step: 5
Training loss: 2.341904878616333
Validation loss: 2.6421571546985256

Epoch: 6| Step: 6
Training loss: 2.128156900405884
Validation loss: 2.6471583945776826

Epoch: 6| Step: 7
Training loss: 3.0940752029418945
Validation loss: 2.6448947921875985

Epoch: 6| Step: 8
Training loss: 2.6183321475982666
Validation loss: 2.629285479104647

Epoch: 6| Step: 9
Training loss: 2.772195816040039
Validation loss: 2.6192813457981234

Epoch: 6| Step: 10
Training loss: 3.512948989868164
Validation loss: 2.6146131818012526

Epoch: 6| Step: 11
Training loss: 3.509478807449341
Validation loss: 2.610450029373169

Epoch: 6| Step: 12
Training loss: 2.6582045555114746
Validation loss: 2.60999555741587

Epoch: 6| Step: 13
Training loss: 1.2933547496795654
Validation loss: 2.6130379451218473

Epoch: 25| Step: 0
Training loss: 2.9709677696228027
Validation loss: 2.635685174695907

Epoch: 6| Step: 1
Training loss: 2.514967441558838
Validation loss: 2.6847909650494977

Epoch: 6| Step: 2
Training loss: 2.4139750003814697
Validation loss: 2.629677567430722

Epoch: 6| Step: 3
Training loss: 2.7977800369262695
Validation loss: 2.6043365360588155

Epoch: 6| Step: 4
Training loss: 3.1925997734069824
Validation loss: 2.604589921171947

Epoch: 6| Step: 5
Training loss: 2.9435300827026367
Validation loss: 2.6067772885804534

Epoch: 6| Step: 6
Training loss: 2.9151360988616943
Validation loss: 2.6249858230672856

Epoch: 6| Step: 7
Training loss: 3.069808006286621
Validation loss: 2.6336946282335507

Epoch: 6| Step: 8
Training loss: 2.5749402046203613
Validation loss: 2.615862456701135

Epoch: 6| Step: 9
Training loss: 2.7852742671966553
Validation loss: 2.6099335480761785

Epoch: 6| Step: 10
Training loss: 3.3751869201660156
Validation loss: 2.607779441341277

Epoch: 6| Step: 11
Training loss: 2.4705538749694824
Validation loss: 2.6057520707448325

Epoch: 6| Step: 12
Training loss: 2.9928066730499268
Validation loss: 2.6034679079568512

Epoch: 6| Step: 13
Training loss: 1.7186466455459595
Validation loss: 2.6003913161575154

Epoch: 26| Step: 0
Training loss: 2.898904323577881
Validation loss: 2.610971268787179

Epoch: 6| Step: 1
Training loss: 2.4003052711486816
Validation loss: 2.6055863570141535

Epoch: 6| Step: 2
Training loss: 3.406383514404297
Validation loss: 2.601553076057024

Epoch: 6| Step: 3
Training loss: 2.5326125621795654
Validation loss: 2.599588589001727

Epoch: 6| Step: 4
Training loss: 1.8929866552352905
Validation loss: 2.595079291251398

Epoch: 6| Step: 5
Training loss: 2.1794345378875732
Validation loss: 2.5991846566559165

Epoch: 6| Step: 6
Training loss: 2.869473695755005
Validation loss: 2.6028717640907533

Epoch: 6| Step: 7
Training loss: 2.786585807800293
Validation loss: 2.6096097833366803

Epoch: 6| Step: 8
Training loss: 3.715980052947998
Validation loss: 2.6085472030024373

Epoch: 6| Step: 9
Training loss: 2.8092806339263916
Validation loss: 2.5952640810320453

Epoch: 6| Step: 10
Training loss: 2.8612122535705566
Validation loss: 2.5892310578336

Epoch: 6| Step: 11
Training loss: 3.052229642868042
Validation loss: 2.588951777386409

Epoch: 6| Step: 12
Training loss: 3.175222873687744
Validation loss: 2.5865076908501248

Epoch: 6| Step: 13
Training loss: 2.0563390254974365
Validation loss: 2.5854461551994405

Epoch: 27| Step: 0
Training loss: 2.8240697383880615
Validation loss: 2.5866113221773537

Epoch: 6| Step: 1
Training loss: 3.036865711212158
Validation loss: 2.5949843160567747

Epoch: 6| Step: 2
Training loss: 3.028048515319824
Validation loss: 2.5913477918153167

Epoch: 6| Step: 3
Training loss: 1.9064174890518188
Validation loss: 2.5945151006021807

Epoch: 6| Step: 4
Training loss: 2.1608524322509766
Validation loss: 2.5937732163295952

Epoch: 6| Step: 5
Training loss: 3.3285298347473145
Validation loss: 2.5987681111981793

Epoch: 6| Step: 6
Training loss: 3.260120153427124
Validation loss: 2.582356265796128

Epoch: 6| Step: 7
Training loss: 2.7490320205688477
Validation loss: 2.578461911088677

Epoch: 6| Step: 8
Training loss: 2.8266515731811523
Validation loss: 2.577471407510901

Epoch: 6| Step: 9
Training loss: 2.763333797454834
Validation loss: 2.5767051173794653

Epoch: 6| Step: 10
Training loss: 2.02895450592041
Validation loss: 2.5762219070106425

Epoch: 6| Step: 11
Training loss: 3.144606828689575
Validation loss: 2.570414222696776

Epoch: 6| Step: 12
Training loss: 2.9010205268859863
Validation loss: 2.5725931198366228

Epoch: 6| Step: 13
Training loss: 2.7061519622802734
Validation loss: 2.5761272958529893

Epoch: 28| Step: 0
Training loss: 2.3554718494415283
Validation loss: 2.5919122747195664

Epoch: 6| Step: 1
Training loss: 2.471325397491455
Validation loss: 2.6076128252090944

Epoch: 6| Step: 2
Training loss: 2.7671918869018555
Validation loss: 2.604303372803555

Epoch: 6| Step: 3
Training loss: 2.3744139671325684
Validation loss: 2.6095448155556955

Epoch: 6| Step: 4
Training loss: 3.222693920135498
Validation loss: 2.6154678098617063

Epoch: 6| Step: 5
Training loss: 2.73576021194458
Validation loss: 2.6038809258450746

Epoch: 6| Step: 6
Training loss: 2.3766424655914307
Validation loss: 2.5935118788032123

Epoch: 6| Step: 7
Training loss: 3.298933744430542
Validation loss: 2.5753865857278146

Epoch: 6| Step: 8
Training loss: 2.9339256286621094
Validation loss: 2.5600667794545493

Epoch: 6| Step: 9
Training loss: 2.756568431854248
Validation loss: 2.563872811614826

Epoch: 6| Step: 10
Training loss: 3.84228777885437
Validation loss: 2.574515417057981

Epoch: 6| Step: 11
Training loss: 2.082575559616089
Validation loss: 2.5731662114461265

Epoch: 6| Step: 12
Training loss: 2.672896385192871
Validation loss: 2.5819792926952405

Epoch: 6| Step: 13
Training loss: 2.6685962677001953
Validation loss: 2.5873170411714943

Epoch: 29| Step: 0
Training loss: 2.755082368850708
Validation loss: 2.5905845601071595

Epoch: 6| Step: 1
Training loss: 2.2245922088623047
Validation loss: 2.582798086186891

Epoch: 6| Step: 2
Training loss: 3.030531883239746
Validation loss: 2.577326765624426

Epoch: 6| Step: 3
Training loss: 3.345663070678711
Validation loss: 2.5686912587893906

Epoch: 6| Step: 4
Training loss: 2.4364213943481445
Validation loss: 2.564169963200887

Epoch: 6| Step: 5
Training loss: 2.8427083492279053
Validation loss: 2.5630807671495663

Epoch: 6| Step: 6
Training loss: 2.49800443649292
Validation loss: 2.558136283710439

Epoch: 6| Step: 7
Training loss: 2.720761299133301
Validation loss: 2.561777250741118

Epoch: 6| Step: 8
Training loss: 2.581420421600342
Validation loss: 2.5662311507809545

Epoch: 6| Step: 9
Training loss: 2.9822962284088135
Validation loss: 2.5601575041329987

Epoch: 6| Step: 10
Training loss: 2.6803197860717773
Validation loss: 2.550121335573094

Epoch: 6| Step: 11
Training loss: 3.082580804824829
Validation loss: 2.551159825376285

Epoch: 6| Step: 12
Training loss: 2.5519204139709473
Validation loss: 2.555237070206673

Epoch: 6| Step: 13
Training loss: 3.0385935306549072
Validation loss: 2.561802648728894

Epoch: 30| Step: 0
Training loss: 2.7639355659484863
Validation loss: 2.55672021835081

Epoch: 6| Step: 1
Training loss: 2.7617571353912354
Validation loss: 2.5551215910142466

Epoch: 6| Step: 2
Training loss: 2.640437126159668
Validation loss: 2.554339244801511

Epoch: 6| Step: 3
Training loss: 2.7838096618652344
Validation loss: 2.5499749183654785

Epoch: 6| Step: 4
Training loss: 2.550649881362915
Validation loss: 2.549798286089333

Epoch: 6| Step: 5
Training loss: 1.7603840827941895
Validation loss: 2.5434470971425376

Epoch: 6| Step: 6
Training loss: 3.131692409515381
Validation loss: 2.5402841003992225

Epoch: 6| Step: 7
Training loss: 3.140424966812134
Validation loss: 2.5439764094609085

Epoch: 6| Step: 8
Training loss: 2.8243041038513184
Validation loss: 2.5671349827961256

Epoch: 6| Step: 9
Training loss: 3.510965347290039
Validation loss: 2.5763937298969557

Epoch: 6| Step: 10
Training loss: 2.294036865234375
Validation loss: 2.5542160003416

Epoch: 6| Step: 11
Training loss: 2.620647430419922
Validation loss: 2.5460868009956936

Epoch: 6| Step: 12
Training loss: 3.306295394897461
Validation loss: 2.5402774656972578

Epoch: 6| Step: 13
Training loss: 2.066822052001953
Validation loss: 2.5300699305790726

Epoch: 31| Step: 0
Training loss: 3.180769443511963
Validation loss: 2.530701429613175

Epoch: 6| Step: 1
Training loss: 2.8597967624664307
Validation loss: 2.5371063729768157

Epoch: 6| Step: 2
Training loss: 3.077388048171997
Validation loss: 2.547847132528982

Epoch: 6| Step: 3
Training loss: 2.0609078407287598
Validation loss: 2.5486934185028076

Epoch: 6| Step: 4
Training loss: 2.1138877868652344
Validation loss: 2.562953769519765

Epoch: 6| Step: 5
Training loss: 2.296499252319336
Validation loss: 2.5556600914206555

Epoch: 6| Step: 6
Training loss: 2.7520666122436523
Validation loss: 2.5430598041062713

Epoch: 6| Step: 7
Training loss: 3.168400526046753
Validation loss: 2.535620238191338

Epoch: 6| Step: 8
Training loss: 3.3354852199554443
Validation loss: 2.5349026392864924

Epoch: 6| Step: 9
Training loss: 2.455919027328491
Validation loss: 2.5294678236848567

Epoch: 6| Step: 10
Training loss: 2.7955117225646973
Validation loss: 2.5338408690626903

Epoch: 6| Step: 11
Training loss: 2.6673824787139893
Validation loss: 2.6529796995142454

Epoch: 6| Step: 12
Training loss: 3.2446277141571045
Validation loss: 2.7552627978786344

Epoch: 6| Step: 13
Training loss: 2.634402275085449
Validation loss: 2.741926631619853

Epoch: 32| Step: 0
Training loss: 3.0915708541870117
Validation loss: 2.6320771325019097

Epoch: 6| Step: 1
Training loss: 2.6234846115112305
Validation loss: 2.529870653665194

Epoch: 6| Step: 2
Training loss: 2.337001323699951
Validation loss: 2.5273120903199717

Epoch: 6| Step: 3
Training loss: 3.683685779571533
Validation loss: 2.6071452735572733

Epoch: 6| Step: 4
Training loss: 2.490070343017578
Validation loss: 2.7217249883118497

Epoch: 6| Step: 5
Training loss: 3.3471527099609375
Validation loss: 2.786136060632685

Epoch: 6| Step: 6
Training loss: 3.340172052383423
Validation loss: 2.7766952668466875

Epoch: 6| Step: 7
Training loss: 2.9613497257232666
Validation loss: 2.6767566152798232

Epoch: 6| Step: 8
Training loss: 2.463884115219116
Validation loss: 2.568013750096803

Epoch: 6| Step: 9
Training loss: 2.4402318000793457
Validation loss: 2.5675593653032855

Epoch: 6| Step: 10
Training loss: 2.525359630584717
Validation loss: 2.6011428961189846

Epoch: 6| Step: 11
Training loss: 2.455554485321045
Validation loss: 2.6606412856809554

Epoch: 6| Step: 12
Training loss: 2.613203525543213
Validation loss: 2.763033605390979

Epoch: 6| Step: 13
Training loss: 3.5675015449523926
Validation loss: 2.722569619455645

Epoch: 33| Step: 0
Training loss: 2.044626235961914
Validation loss: 2.664622752897201

Epoch: 6| Step: 1
Training loss: 3.1187546253204346
Validation loss: 2.6230998039245605

Epoch: 6| Step: 2
Training loss: 2.4983134269714355
Validation loss: 2.556076434350783

Epoch: 6| Step: 3
Training loss: 3.419565200805664
Validation loss: 2.5379621956938054

Epoch: 6| Step: 4
Training loss: 2.0980405807495117
Validation loss: 2.5403185634202856

Epoch: 6| Step: 5
Training loss: 3.2601559162139893
Validation loss: 2.5548610225800545

Epoch: 6| Step: 6
Training loss: 3.0953192710876465
Validation loss: 2.563824825389411

Epoch: 6| Step: 7
Training loss: 3.077467441558838
Validation loss: 2.5864064001267955

Epoch: 6| Step: 8
Training loss: 1.8502038717269897
Validation loss: 2.594145167258478

Epoch: 6| Step: 9
Training loss: 3.1802873611450195
Validation loss: 2.6127329308499574

Epoch: 6| Step: 10
Training loss: 2.5143706798553467
Validation loss: 2.616142670313517

Epoch: 6| Step: 11
Training loss: 2.941067934036255
Validation loss: 2.6041397868946032

Epoch: 6| Step: 12
Training loss: 3.164891242980957
Validation loss: 2.598332792200068

Epoch: 6| Step: 13
Training loss: 2.310633420944214
Validation loss: 2.5567401019475793

Epoch: 34| Step: 0
Training loss: 2.8856184482574463
Validation loss: 2.529587968703239

Epoch: 6| Step: 1
Training loss: 2.9943647384643555
Validation loss: 2.535752455393473

Epoch: 6| Step: 2
Training loss: 1.620474100112915
Validation loss: 2.5484145482381186

Epoch: 6| Step: 3
Training loss: 3.31797456741333
Validation loss: 2.5656085296343734

Epoch: 6| Step: 4
Training loss: 2.8311896324157715
Validation loss: 2.5663941239797943

Epoch: 6| Step: 5
Training loss: 3.191037178039551
Validation loss: 2.550356149673462

Epoch: 6| Step: 6
Training loss: 2.5325727462768555
Validation loss: 2.5471986673211537

Epoch: 6| Step: 7
Training loss: 2.0218544006347656
Validation loss: 2.539370157385385

Epoch: 6| Step: 8
Training loss: 3.4001617431640625
Validation loss: 2.532175751142604

Epoch: 6| Step: 9
Training loss: 2.5594308376312256
Validation loss: 2.540141631198186

Epoch: 6| Step: 10
Training loss: 3.0620813369750977
Validation loss: 2.548422746760871

Epoch: 6| Step: 11
Training loss: 2.222426414489746
Validation loss: 2.5511626223082184

Epoch: 6| Step: 12
Training loss: 3.009962558746338
Validation loss: 2.5940766437079317

Epoch: 6| Step: 13
Training loss: 2.2311792373657227
Validation loss: 2.5570728394293014

Epoch: 35| Step: 0
Training loss: 3.968900680541992
Validation loss: 2.5343762956639773

Epoch: 6| Step: 1
Training loss: 2.63297700881958
Validation loss: 2.504573619493874

Epoch: 6| Step: 2
Training loss: 2.44930362701416
Validation loss: 2.497314242906468

Epoch: 6| Step: 3
Training loss: 1.9213507175445557
Validation loss: 2.491525883315712

Epoch: 6| Step: 4
Training loss: 3.2452144622802734
Validation loss: 2.4965025660812215

Epoch: 6| Step: 5
Training loss: 2.775761127471924
Validation loss: 2.493375496197772

Epoch: 6| Step: 6
Training loss: 2.412759304046631
Validation loss: 2.494161759653399

Epoch: 6| Step: 7
Training loss: 2.603250026702881
Validation loss: 2.4922318048374628

Epoch: 6| Step: 8
Training loss: 2.6781976222991943
Validation loss: 2.489334532009658

Epoch: 6| Step: 9
Training loss: 2.677319049835205
Validation loss: 2.487057496142644

Epoch: 6| Step: 10
Training loss: 2.30648136138916
Validation loss: 2.487804482060094

Epoch: 6| Step: 11
Training loss: 2.7078826427459717
Validation loss: 2.4886465867360434

Epoch: 6| Step: 12
Training loss: 2.6585302352905273
Validation loss: 2.486400632448094

Epoch: 6| Step: 13
Training loss: 2.8404417037963867
Validation loss: 2.4847212401769494

Epoch: 36| Step: 0
Training loss: 3.199181079864502
Validation loss: 2.4875185669109388

Epoch: 6| Step: 1
Training loss: 2.59072208404541
Validation loss: 2.48542114996141

Epoch: 6| Step: 2
Training loss: 2.6167235374450684
Validation loss: 2.4882842904777935

Epoch: 6| Step: 3
Training loss: 2.601510524749756
Validation loss: 2.485231476445352

Epoch: 6| Step: 4
Training loss: 2.710951328277588
Validation loss: 2.4864448116671656

Epoch: 6| Step: 5
Training loss: 2.595139503479004
Validation loss: 2.4871003679049912

Epoch: 6| Step: 6
Training loss: 3.1112117767333984
Validation loss: 2.4854790215851157

Epoch: 6| Step: 7
Training loss: 3.3528683185577393
Validation loss: 2.484407373653945

Epoch: 6| Step: 8
Training loss: 2.192896842956543
Validation loss: 2.4844585951938423

Epoch: 6| Step: 9
Training loss: 3.106477737426758
Validation loss: 2.484492242977183

Epoch: 6| Step: 10
Training loss: 3.162813186645508
Validation loss: 2.4827442143553045

Epoch: 6| Step: 11
Training loss: 1.4887394905090332
Validation loss: 2.484287892618487

Epoch: 6| Step: 12
Training loss: 2.0985350608825684
Validation loss: 2.4848189366761075

Epoch: 6| Step: 13
Training loss: 3.290701389312744
Validation loss: 2.4844762689323834

Epoch: 37| Step: 0
Training loss: 3.0925469398498535
Validation loss: 2.4798730060618412

Epoch: 6| Step: 1
Training loss: 2.8438525199890137
Validation loss: 2.476488859422745

Epoch: 6| Step: 2
Training loss: 2.399644136428833
Validation loss: 2.474122408897646

Epoch: 6| Step: 3
Training loss: 2.426201105117798
Validation loss: 2.476360146717359

Epoch: 6| Step: 4
Training loss: 2.8262929916381836
Validation loss: 2.474019911981398

Epoch: 6| Step: 5
Training loss: 1.936589002609253
Validation loss: 2.4722327622034217

Epoch: 6| Step: 6
Training loss: 3.597557306289673
Validation loss: 2.4732886770720124

Epoch: 6| Step: 7
Training loss: 2.7183098793029785
Validation loss: 2.47086904510375

Epoch: 6| Step: 8
Training loss: 2.640047788619995
Validation loss: 2.4710905090455086

Epoch: 6| Step: 9
Training loss: 2.3941993713378906
Validation loss: 2.471595311677584

Epoch: 6| Step: 10
Training loss: 2.913017511367798
Validation loss: 2.4682125506862516

Epoch: 6| Step: 11
Training loss: 2.4434897899627686
Validation loss: 2.470013144195721

Epoch: 6| Step: 12
Training loss: 2.9422311782836914
Validation loss: 2.473374451360395

Epoch: 6| Step: 13
Training loss: 2.314417839050293
Validation loss: 2.4780394441337994

Epoch: 38| Step: 0
Training loss: 2.6211366653442383
Validation loss: 2.4758276221572713

Epoch: 6| Step: 1
Training loss: 3.392157554626465
Validation loss: 2.4820691898304927

Epoch: 6| Step: 2
Training loss: 2.760404109954834
Validation loss: 2.483707087014311

Epoch: 6| Step: 3
Training loss: 2.1943492889404297
Validation loss: 2.4909911565883185

Epoch: 6| Step: 4
Training loss: 2.9895896911621094
Validation loss: 2.496445886550411

Epoch: 6| Step: 5
Training loss: 3.208031177520752
Validation loss: 2.5027677346301336

Epoch: 6| Step: 6
Training loss: 2.090115547180176
Validation loss: 2.5041909884381037

Epoch: 6| Step: 7
Training loss: 2.7700304985046387
Validation loss: 2.51542224935306

Epoch: 6| Step: 8
Training loss: 2.994525909423828
Validation loss: 2.4965787574809086

Epoch: 6| Step: 9
Training loss: 2.496950626373291
Validation loss: 2.4849568772059616

Epoch: 6| Step: 10
Training loss: 2.5957870483398438
Validation loss: 2.4719669844514582

Epoch: 6| Step: 11
Training loss: 2.5376627445220947
Validation loss: 2.462814538709579

Epoch: 6| Step: 12
Training loss: 2.3098702430725098
Validation loss: 2.456350226556101

Epoch: 6| Step: 13
Training loss: 2.625023603439331
Validation loss: 2.452979580048592

Epoch: 39| Step: 0
Training loss: 2.3451404571533203
Validation loss: 2.451867118958504

Epoch: 6| Step: 1
Training loss: 2.539729118347168
Validation loss: 2.453773572880735

Epoch: 6| Step: 2
Training loss: 3.268479108810425
Validation loss: 2.454297763045116

Epoch: 6| Step: 3
Training loss: 2.3865644931793213
Validation loss: 2.4547201330943773

Epoch: 6| Step: 4
Training loss: 3.358578681945801
Validation loss: 2.4580466824193157

Epoch: 6| Step: 5
Training loss: 1.7581772804260254
Validation loss: 2.465574966963901

Epoch: 6| Step: 6
Training loss: 3.0920867919921875
Validation loss: 2.4681943526832004

Epoch: 6| Step: 7
Training loss: 2.290954828262329
Validation loss: 2.4822430969566427

Epoch: 6| Step: 8
Training loss: 2.605334758758545
Validation loss: 2.495746430530343

Epoch: 6| Step: 9
Training loss: 3.1193573474884033
Validation loss: 2.498668163053451

Epoch: 6| Step: 10
Training loss: 2.703049421310425
Validation loss: 2.502298903721635

Epoch: 6| Step: 11
Training loss: 2.886359930038452
Validation loss: 2.5006370134251092

Epoch: 6| Step: 12
Training loss: 2.8547191619873047
Validation loss: 2.497703206154608

Epoch: 6| Step: 13
Training loss: 2.107158899307251
Validation loss: 2.4943914746725433

Epoch: 40| Step: 0
Training loss: 2.2496211528778076
Validation loss: 2.4867441461932276

Epoch: 6| Step: 1
Training loss: 3.0186104774475098
Validation loss: 2.4833862935343096

Epoch: 6| Step: 2
Training loss: 2.8223156929016113
Validation loss: 2.476511119514383

Epoch: 6| Step: 3
Training loss: 2.8278303146362305
Validation loss: 2.475278715933523

Epoch: 6| Step: 4
Training loss: 2.5658674240112305
Validation loss: 2.4753162527597077

Epoch: 6| Step: 5
Training loss: 2.93019700050354
Validation loss: 2.4791899137599493

Epoch: 6| Step: 6
Training loss: 3.036644220352173
Validation loss: 2.476446041496851

Epoch: 6| Step: 7
Training loss: 2.8233566284179688
Validation loss: 2.4630415260150866

Epoch: 6| Step: 8
Training loss: 3.1005992889404297
Validation loss: 2.4540797754000594

Epoch: 6| Step: 9
Training loss: 2.2395355701446533
Validation loss: 2.4472749335791475

Epoch: 6| Step: 10
Training loss: 2.6184277534484863
Validation loss: 2.4433761899189284

Epoch: 6| Step: 11
Training loss: 2.910231828689575
Validation loss: 2.4385425916282077

Epoch: 6| Step: 12
Training loss: 2.463801383972168
Validation loss: 2.433298777508479

Epoch: 6| Step: 13
Training loss: 1.765938639640808
Validation loss: 2.426182685359832

Epoch: 41| Step: 0
Training loss: 1.8450759649276733
Validation loss: 2.4299440717184417

Epoch: 6| Step: 1
Training loss: 2.4901723861694336
Validation loss: 2.4394922846107074

Epoch: 6| Step: 2
Training loss: 2.821467876434326
Validation loss: 2.442967884002193

Epoch: 6| Step: 3
Training loss: 1.6852083206176758
Validation loss: 2.4489850023741364

Epoch: 6| Step: 4
Training loss: 2.559715986251831
Validation loss: 2.4620092914950464

Epoch: 6| Step: 5
Training loss: 2.7787814140319824
Validation loss: 2.4644879679526053

Epoch: 6| Step: 6
Training loss: 2.6376171112060547
Validation loss: 2.4632153305956113

Epoch: 6| Step: 7
Training loss: 2.6195459365844727
Validation loss: 2.4755411173707698

Epoch: 6| Step: 8
Training loss: 2.8339037895202637
Validation loss: 2.461656880635087

Epoch: 6| Step: 9
Training loss: 2.7728445529937744
Validation loss: 2.450545472483481

Epoch: 6| Step: 10
Training loss: 2.9093196392059326
Validation loss: 2.445617224580498

Epoch: 6| Step: 11
Training loss: 3.297593832015991
Validation loss: 2.4322597647225983

Epoch: 6| Step: 12
Training loss: 3.086594820022583
Validation loss: 2.4264886174150693

Epoch: 6| Step: 13
Training loss: 3.2880964279174805
Validation loss: 2.4246061668601087

Epoch: 42| Step: 0
Training loss: 2.8091163635253906
Validation loss: 2.4282963763001146

Epoch: 6| Step: 1
Training loss: 2.8995091915130615
Validation loss: 2.421874882072531

Epoch: 6| Step: 2
Training loss: 2.531747817993164
Validation loss: 2.4197887374508764

Epoch: 6| Step: 3
Training loss: 2.854109764099121
Validation loss: 2.4231582969747563

Epoch: 6| Step: 4
Training loss: 2.2725210189819336
Validation loss: 2.419489619552448

Epoch: 6| Step: 5
Training loss: 2.7957451343536377
Validation loss: 2.4213007957704606

Epoch: 6| Step: 6
Training loss: 3.556522846221924
Validation loss: 2.421522794231292

Epoch: 6| Step: 7
Training loss: 1.9075748920440674
Validation loss: 2.4254321539273827

Epoch: 6| Step: 8
Training loss: 2.776496410369873
Validation loss: 2.424610144348555

Epoch: 6| Step: 9
Training loss: 2.5853281021118164
Validation loss: 2.423562208811442

Epoch: 6| Step: 10
Training loss: 2.048841953277588
Validation loss: 2.4294109011209137

Epoch: 6| Step: 11
Training loss: 2.9085545539855957
Validation loss: 2.4350011425633586

Epoch: 6| Step: 12
Training loss: 2.690980911254883
Validation loss: 2.440882352090651

Epoch: 6| Step: 13
Training loss: 2.5488381385803223
Validation loss: 2.457007882415607

Epoch: 43| Step: 0
Training loss: 3.0092997550964355
Validation loss: 2.473411403676515

Epoch: 6| Step: 1
Training loss: 2.9197001457214355
Validation loss: 2.4740075013970815

Epoch: 6| Step: 2
Training loss: 2.1258811950683594
Validation loss: 2.4752199906174854

Epoch: 6| Step: 3
Training loss: 2.48154878616333
Validation loss: 2.4572165025177823

Epoch: 6| Step: 4
Training loss: 3.4819939136505127
Validation loss: 2.430493272760863

Epoch: 6| Step: 5
Training loss: 3.0567128658294678
Validation loss: 2.4179814554029897

Epoch: 6| Step: 6
Training loss: 2.9042270183563232
Validation loss: 2.4129519616403887

Epoch: 6| Step: 7
Training loss: 1.850663423538208
Validation loss: 2.4078180918129544

Epoch: 6| Step: 8
Training loss: 1.776330828666687
Validation loss: 2.411178027429888

Epoch: 6| Step: 9
Training loss: 2.6460161209106445
Validation loss: 2.408555930660617

Epoch: 6| Step: 10
Training loss: 2.464296579360962
Validation loss: 2.406655027020362

Epoch: 6| Step: 11
Training loss: 2.825448989868164
Validation loss: 2.4036693085906324

Epoch: 6| Step: 12
Training loss: 2.539949655532837
Validation loss: 2.40072964596492

Epoch: 6| Step: 13
Training loss: 3.4969711303710938
Validation loss: 2.4031542808778825

Epoch: 44| Step: 0
Training loss: 2.7205748558044434
Validation loss: 2.4032097401157504

Epoch: 6| Step: 1
Training loss: 2.636460065841675
Validation loss: 2.4075141722156155

Epoch: 6| Step: 2
Training loss: 3.2415478229522705
Validation loss: 2.4083303892484276

Epoch: 6| Step: 3
Training loss: 2.3483099937438965
Validation loss: 2.407445844783578

Epoch: 6| Step: 4
Training loss: 2.4943041801452637
Validation loss: 2.4194925779937417

Epoch: 6| Step: 5
Training loss: 2.6423909664154053
Validation loss: 2.418499098029188

Epoch: 6| Step: 6
Training loss: 2.2885665893554688
Validation loss: 2.417066115205006

Epoch: 6| Step: 7
Training loss: 2.9569733142852783
Validation loss: 2.4049842896000033

Epoch: 6| Step: 8
Training loss: 2.673832416534424
Validation loss: 2.40103345019843

Epoch: 6| Step: 9
Training loss: 2.927354335784912
Validation loss: 2.396897513379333

Epoch: 6| Step: 10
Training loss: 2.9561004638671875
Validation loss: 2.3961932710421983

Epoch: 6| Step: 11
Training loss: 2.171790838241577
Validation loss: 2.3965449666464202

Epoch: 6| Step: 12
Training loss: 2.307100534439087
Validation loss: 2.400763537294121

Epoch: 6| Step: 13
Training loss: 2.6411337852478027
Validation loss: 2.3957687706075688

Epoch: 45| Step: 0
Training loss: 2.2823398113250732
Validation loss: 2.4078017434766217

Epoch: 6| Step: 1
Training loss: 2.798130512237549
Validation loss: 2.4149177920433784

Epoch: 6| Step: 2
Training loss: 2.7377657890319824
Validation loss: 2.4360217484094764

Epoch: 6| Step: 3
Training loss: 2.618000030517578
Validation loss: 2.4481134747946136

Epoch: 6| Step: 4
Training loss: 3.1043994426727295
Validation loss: 2.4097212924752185

Epoch: 6| Step: 5
Training loss: 3.3554649353027344
Validation loss: 2.4021261994556715

Epoch: 6| Step: 6
Training loss: 2.936769962310791
Validation loss: 2.3899616426037205

Epoch: 6| Step: 7
Training loss: 2.654118299484253
Validation loss: 2.3869939465676584

Epoch: 6| Step: 8
Training loss: 2.1381139755249023
Validation loss: 2.3874546507353425

Epoch: 6| Step: 9
Training loss: 2.5027589797973633
Validation loss: 2.397579723788846

Epoch: 6| Step: 10
Training loss: 2.6889090538024902
Validation loss: 2.3947556864830757

Epoch: 6| Step: 11
Training loss: 2.3320305347442627
Validation loss: 2.3988927013130596

Epoch: 6| Step: 12
Training loss: 2.8600573539733887
Validation loss: 2.391914065166186

Epoch: 6| Step: 13
Training loss: 1.785768985748291
Validation loss: 2.393000720649637

Epoch: 46| Step: 0
Training loss: 2.8393049240112305
Validation loss: 2.384962833055886

Epoch: 6| Step: 1
Training loss: 2.424896478652954
Validation loss: 2.385268211364746

Epoch: 6| Step: 2
Training loss: 3.1549172401428223
Validation loss: 2.3879672609349734

Epoch: 6| Step: 3
Training loss: 2.750948429107666
Validation loss: 2.390641223999762

Epoch: 6| Step: 4
Training loss: 2.9010677337646484
Validation loss: 2.398102339877877

Epoch: 6| Step: 5
Training loss: 2.6000614166259766
Validation loss: 2.3965471175409134

Epoch: 6| Step: 6
Training loss: 2.594836950302124
Validation loss: 2.4016297401920443

Epoch: 6| Step: 7
Training loss: 2.289072275161743
Validation loss: 2.399901097820651

Epoch: 6| Step: 8
Training loss: 2.722684860229492
Validation loss: 2.401772496520832

Epoch: 6| Step: 9
Training loss: 2.6594512462615967
Validation loss: 2.403419780474837

Epoch: 6| Step: 10
Training loss: 2.3958678245544434
Validation loss: 2.405428214739728

Epoch: 6| Step: 11
Training loss: 1.9610233306884766
Validation loss: 2.4026234611388175

Epoch: 6| Step: 12
Training loss: 3.213644027709961
Validation loss: 2.394416933418602

Epoch: 6| Step: 13
Training loss: 2.2701306343078613
Validation loss: 2.3898362446856756

Epoch: 47| Step: 0
Training loss: 2.6014552116394043
Validation loss: 2.392583170244771

Epoch: 6| Step: 1
Training loss: 2.8152384757995605
Validation loss: 2.396958799772365

Epoch: 6| Step: 2
Training loss: 2.4619460105895996
Validation loss: 2.3932532853977655

Epoch: 6| Step: 3
Training loss: 2.6686930656433105
Validation loss: 2.3932189608132965

Epoch: 6| Step: 4
Training loss: 2.7936530113220215
Validation loss: 2.3848396270505843

Epoch: 6| Step: 5
Training loss: 2.213679552078247
Validation loss: 2.382841697303198

Epoch: 6| Step: 6
Training loss: 2.7233035564422607
Validation loss: 2.3789286895464827

Epoch: 6| Step: 7
Training loss: 2.5249998569488525
Validation loss: 2.376889803076303

Epoch: 6| Step: 8
Training loss: 2.929187536239624
Validation loss: 2.3848522837444017

Epoch: 6| Step: 9
Training loss: 2.4270458221435547
Validation loss: 2.3904550190894835

Epoch: 6| Step: 10
Training loss: 2.9811506271362305
Validation loss: 2.383756793955321

Epoch: 6| Step: 11
Training loss: 2.758591651916504
Validation loss: 2.376098335430186

Epoch: 6| Step: 12
Training loss: 2.3518049716949463
Validation loss: 2.3731778744728333

Epoch: 6| Step: 13
Training loss: 2.4090166091918945
Validation loss: 2.368606082854732

Epoch: 48| Step: 0
Training loss: 2.974684000015259
Validation loss: 2.373051763862692

Epoch: 6| Step: 1
Training loss: 2.6605191230773926
Validation loss: 2.3844173595469487

Epoch: 6| Step: 2
Training loss: 1.8227722644805908
Validation loss: 2.416589275483162

Epoch: 6| Step: 3
Training loss: 2.1360092163085938
Validation loss: 2.456879351728706

Epoch: 6| Step: 4
Training loss: 3.166926383972168
Validation loss: 2.5021409860221286

Epoch: 6| Step: 5
Training loss: 3.0470731258392334
Validation loss: 2.501995627598096

Epoch: 6| Step: 6
Training loss: 2.9821956157684326
Validation loss: 2.4974071774431454

Epoch: 6| Step: 7
Training loss: 2.652853488922119
Validation loss: 2.4770553650394564

Epoch: 6| Step: 8
Training loss: 2.315086841583252
Validation loss: 2.4587145928413636

Epoch: 6| Step: 9
Training loss: 2.738950729370117
Validation loss: 2.4439021259225826

Epoch: 6| Step: 10
Training loss: 3.090480327606201
Validation loss: 2.4369154130258868

Epoch: 6| Step: 11
Training loss: 3.1748709678649902
Validation loss: 2.433711333941388

Epoch: 6| Step: 12
Training loss: 1.956197738647461
Validation loss: 2.432399788210469

Epoch: 6| Step: 13
Training loss: 2.5330941677093506
Validation loss: 2.436657372341361

Epoch: 49| Step: 0
Training loss: 2.509608507156372
Validation loss: 2.430767713054534

Epoch: 6| Step: 1
Training loss: 2.3229479789733887
Validation loss: 2.4316501489249607

Epoch: 6| Step: 2
Training loss: 2.224567413330078
Validation loss: 2.4302113184364895

Epoch: 6| Step: 3
Training loss: 2.9730112552642822
Validation loss: 2.4383727324906217

Epoch: 6| Step: 4
Training loss: 2.500694513320923
Validation loss: 2.449313986685968

Epoch: 6| Step: 5
Training loss: 2.985171318054199
Validation loss: 2.446007517076308

Epoch: 6| Step: 6
Training loss: 2.9869234561920166
Validation loss: 2.4438440825349543

Epoch: 6| Step: 7
Training loss: 2.9552698135375977
Validation loss: 2.4384562200115574

Epoch: 6| Step: 8
Training loss: 3.111130714416504
Validation loss: 2.4367102884477183

Epoch: 6| Step: 9
Training loss: 2.121640682220459
Validation loss: 2.4298408262191282

Epoch: 6| Step: 10
Training loss: 2.868948459625244
Validation loss: 2.430620680573166

Epoch: 6| Step: 11
Training loss: 3.0488901138305664
Validation loss: 2.4280537969322613

Epoch: 6| Step: 12
Training loss: 1.9412004947662354
Validation loss: 2.4302718126645653

Epoch: 6| Step: 13
Training loss: 2.6594648361206055
Validation loss: 2.4267595685938352

Epoch: 50| Step: 0
Training loss: 2.418905019760132
Validation loss: 2.425862853245069

Epoch: 6| Step: 1
Training loss: 2.4837541580200195
Validation loss: 2.4267751939835085

Epoch: 6| Step: 2
Training loss: 2.27414608001709
Validation loss: 2.426641848779494

Epoch: 6| Step: 3
Training loss: 2.373924732208252
Validation loss: 2.4258662372507076

Epoch: 6| Step: 4
Training loss: 2.332892656326294
Validation loss: 2.425239493769984

Epoch: 6| Step: 5
Training loss: 2.934767961502075
Validation loss: 2.424368304591025

Epoch: 6| Step: 6
Training loss: 2.946995258331299
Validation loss: 2.431640307108561

Epoch: 6| Step: 7
Training loss: 2.51226806640625
Validation loss: 2.4383103975685696

Epoch: 6| Step: 8
Training loss: 2.0848028659820557
Validation loss: 2.447473668283032

Epoch: 6| Step: 9
Training loss: 3.3918752670288086
Validation loss: 2.454412260363179

Epoch: 6| Step: 10
Training loss: 2.8559134006500244
Validation loss: 2.4586396883892756

Epoch: 6| Step: 11
Training loss: 2.6880061626434326
Validation loss: 2.4442203813983547

Epoch: 6| Step: 12
Training loss: 3.105739116668701
Validation loss: 2.4249059692505868

Epoch: 6| Step: 13
Training loss: 2.729454755783081
Validation loss: 2.4186790835472847

Epoch: 51| Step: 0
Training loss: 2.1281871795654297
Validation loss: 2.4121694334091677

Epoch: 6| Step: 1
Training loss: 2.8026764392852783
Validation loss: 2.4081873022099978

Epoch: 6| Step: 2
Training loss: 3.0330445766448975
Validation loss: 2.4057802461808726

Epoch: 6| Step: 3
Training loss: 2.6675374507904053
Validation loss: 2.403958797454834

Epoch: 6| Step: 4
Training loss: 1.973134994506836
Validation loss: 2.4031984985515638

Epoch: 6| Step: 5
Training loss: 2.1364121437072754
Validation loss: 2.4028083406468874

Epoch: 6| Step: 6
Training loss: 2.149148941040039
Validation loss: 2.402457701262607

Epoch: 6| Step: 7
Training loss: 2.392575740814209
Validation loss: 2.403510788435577

Epoch: 6| Step: 8
Training loss: 2.5455336570739746
Validation loss: 2.4079605097411783

Epoch: 6| Step: 9
Training loss: 3.2892653942108154
Validation loss: 2.406928659767233

Epoch: 6| Step: 10
Training loss: 2.4436540603637695
Validation loss: 2.392451681116576

Epoch: 6| Step: 11
Training loss: 3.4845128059387207
Validation loss: 2.376343765566426

Epoch: 6| Step: 12
Training loss: 2.8925704956054688
Validation loss: 2.3562965546884844

Epoch: 6| Step: 13
Training loss: 3.0985710620880127
Validation loss: 2.348089046375726

Epoch: 52| Step: 0
Training loss: 2.8225209712982178
Validation loss: 2.3389687063873454

Epoch: 6| Step: 1
Training loss: 2.5676639080047607
Validation loss: 2.3465369055348058

Epoch: 6| Step: 2
Training loss: 2.227172374725342
Validation loss: 2.3426099438821115

Epoch: 6| Step: 3
Training loss: 3.1264681816101074
Validation loss: 2.347846684917327

Epoch: 6| Step: 4
Training loss: 2.7645907402038574
Validation loss: 2.347306807835897

Epoch: 6| Step: 5
Training loss: 2.9479193687438965
Validation loss: 2.346297041062386

Epoch: 6| Step: 6
Training loss: 2.5256595611572266
Validation loss: 2.34644175985808

Epoch: 6| Step: 7
Training loss: 2.897033452987671
Validation loss: 2.3400318263679423

Epoch: 6| Step: 8
Training loss: 3.143373966217041
Validation loss: 2.3395565068849953

Epoch: 6| Step: 9
Training loss: 1.6679885387420654
Validation loss: 2.335115841639939

Epoch: 6| Step: 10
Training loss: 2.7753052711486816
Validation loss: 2.337653285713606

Epoch: 6| Step: 11
Training loss: 1.808387279510498
Validation loss: 2.342194757153911

Epoch: 6| Step: 12
Training loss: 2.941706657409668
Validation loss: 2.352741902874362

Epoch: 6| Step: 13
Training loss: 2.431363821029663
Validation loss: 2.357335723856444

Epoch: 53| Step: 0
Training loss: 2.0565242767333984
Validation loss: 2.3572350753250944

Epoch: 6| Step: 1
Training loss: 2.5314688682556152
Validation loss: 2.3493954955890612

Epoch: 6| Step: 2
Training loss: 2.8271820545196533
Validation loss: 2.3402059514035463

Epoch: 6| Step: 3
Training loss: 2.5997204780578613
Validation loss: 2.341833511988322

Epoch: 6| Step: 4
Training loss: 1.9546703100204468
Validation loss: 2.342510349007063

Epoch: 6| Step: 5
Training loss: 3.534393787384033
Validation loss: 2.3411747178723736

Epoch: 6| Step: 6
Training loss: 2.508970260620117
Validation loss: 2.3438111300109536

Epoch: 6| Step: 7
Training loss: 3.290559768676758
Validation loss: 2.345457882009527

Epoch: 6| Step: 8
Training loss: 2.4147789478302
Validation loss: 2.347498099009196

Epoch: 6| Step: 9
Training loss: 1.8939529657363892
Validation loss: 2.3462604758560017

Epoch: 6| Step: 10
Training loss: 3.049544095993042
Validation loss: 2.34658900127616

Epoch: 6| Step: 11
Training loss: 2.624826192855835
Validation loss: 2.3435215129647204

Epoch: 6| Step: 12
Training loss: 2.9305412769317627
Validation loss: 2.34042259570091

Epoch: 6| Step: 13
Training loss: 2.203707218170166
Validation loss: 2.339659398601901

Epoch: 54| Step: 0
Training loss: 2.2126221656799316
Validation loss: 2.337424806369248

Epoch: 6| Step: 1
Training loss: 2.2713842391967773
Validation loss: 2.339629221987981

Epoch: 6| Step: 2
Training loss: 2.9928503036499023
Validation loss: 2.346325166763798

Epoch: 6| Step: 3
Training loss: 2.71635103225708
Validation loss: 2.356091776201802

Epoch: 6| Step: 4
Training loss: 3.0799942016601562
Validation loss: 2.3507986453271683

Epoch: 6| Step: 5
Training loss: 3.1801576614379883
Validation loss: 2.3616645310514714

Epoch: 6| Step: 6
Training loss: 1.8599587678909302
Validation loss: 2.356716368788032

Epoch: 6| Step: 7
Training loss: 2.7017359733581543
Validation loss: 2.343750479400799

Epoch: 6| Step: 8
Training loss: 2.991433620452881
Validation loss: 2.337806035113591

Epoch: 6| Step: 9
Training loss: 1.953057050704956
Validation loss: 2.3372982496856363

Epoch: 6| Step: 10
Training loss: 2.2395591735839844
Validation loss: 2.333857073578783

Epoch: 6| Step: 11
Training loss: 2.5228934288024902
Validation loss: 2.3295073175943024

Epoch: 6| Step: 12
Training loss: 3.338205099105835
Validation loss: 2.3274559872124785

Epoch: 6| Step: 13
Training loss: 2.2105417251586914
Validation loss: 2.323381318840929

Epoch: 55| Step: 0
Training loss: 2.408291816711426
Validation loss: 2.3251034188014206

Epoch: 6| Step: 1
Training loss: 1.650831937789917
Validation loss: 2.3242634624563236

Epoch: 6| Step: 2
Training loss: 1.965139389038086
Validation loss: 2.3191159181697394

Epoch: 6| Step: 3
Training loss: 3.1952288150787354
Validation loss: 2.3198694977709042

Epoch: 6| Step: 4
Training loss: 2.4506630897521973
Validation loss: 2.3183176184213288

Epoch: 6| Step: 5
Training loss: 2.3538014888763428
Validation loss: 2.322240557721866

Epoch: 6| Step: 6
Training loss: 3.839855194091797
Validation loss: 2.3260785046444146

Epoch: 6| Step: 7
Training loss: 2.7545201778411865
Validation loss: 2.33070945483382

Epoch: 6| Step: 8
Training loss: 3.315098285675049
Validation loss: 2.340061241580594

Epoch: 6| Step: 9
Training loss: 1.6666269302368164
Validation loss: 2.341303648487214

Epoch: 6| Step: 10
Training loss: 2.1310856342315674
Validation loss: 2.349425538893669

Epoch: 6| Step: 11
Training loss: 2.7039666175842285
Validation loss: 2.345466177950623

Epoch: 6| Step: 12
Training loss: 3.2708983421325684
Validation loss: 2.343410327870359

Epoch: 6| Step: 13
Training loss: 2.475590467453003
Validation loss: 2.343271807957721

Epoch: 56| Step: 0
Training loss: 2.1965842247009277
Validation loss: 2.3421248159100934

Epoch: 6| Step: 1
Training loss: 2.1208786964416504
Validation loss: 2.3510709526718303

Epoch: 6| Step: 2
Training loss: 2.3721771240234375
Validation loss: 2.3600629837282243

Epoch: 6| Step: 3
Training loss: 2.911778450012207
Validation loss: 2.3529719178394606

Epoch: 6| Step: 4
Training loss: 2.820213794708252
Validation loss: 2.3455093291498

Epoch: 6| Step: 5
Training loss: 3.0964555740356445
Validation loss: 2.3302964651456444

Epoch: 6| Step: 6
Training loss: 3.1800570487976074
Validation loss: 2.330450206674555

Epoch: 6| Step: 7
Training loss: 2.240232467651367
Validation loss: 2.322575858844224

Epoch: 6| Step: 8
Training loss: 1.892003059387207
Validation loss: 2.309240330931961

Epoch: 6| Step: 9
Training loss: 2.2159504890441895
Validation loss: 2.310211863569034

Epoch: 6| Step: 10
Training loss: 2.7728734016418457
Validation loss: 2.3081426774301836

Epoch: 6| Step: 11
Training loss: 2.5512919425964355
Validation loss: 2.313423861739456

Epoch: 6| Step: 12
Training loss: 2.656146287918091
Validation loss: 2.310090770003616

Epoch: 6| Step: 13
Training loss: 3.7089433670043945
Validation loss: 2.304192537902504

Epoch: 57| Step: 0
Training loss: 2.557908058166504
Validation loss: 2.3117594642023884

Epoch: 6| Step: 1
Training loss: 3.0403859615325928
Validation loss: 2.3089840899231615

Epoch: 6| Step: 2
Training loss: 2.3981308937072754
Validation loss: 2.3168989791665027

Epoch: 6| Step: 3
Training loss: 2.372572422027588
Validation loss: 2.3278155634480138

Epoch: 6| Step: 4
Training loss: 2.6076066493988037
Validation loss: 2.336964835402786

Epoch: 6| Step: 5
Training loss: 2.289884090423584
Validation loss: 2.3478117604409494

Epoch: 6| Step: 6
Training loss: 2.2798266410827637
Validation loss: 2.3552906179940827

Epoch: 6| Step: 7
Training loss: 2.82328724861145
Validation loss: 2.3455251929580525

Epoch: 6| Step: 8
Training loss: 1.9484777450561523
Validation loss: 2.3266942654886553

Epoch: 6| Step: 9
Training loss: 1.981793761253357
Validation loss: 2.3172646773758756

Epoch: 6| Step: 10
Training loss: 3.066342353820801
Validation loss: 2.325836084222281

Epoch: 6| Step: 11
Training loss: 2.956956624984741
Validation loss: 2.3154393524251957

Epoch: 6| Step: 12
Training loss: 2.9108123779296875
Validation loss: 2.3080748845172185

Epoch: 6| Step: 13
Training loss: 3.136171340942383
Validation loss: 2.303982521898003

Epoch: 58| Step: 0
Training loss: 3.1132805347442627
Validation loss: 2.302040135988625

Epoch: 6| Step: 1
Training loss: 2.3951361179351807
Validation loss: 2.2969473613205778

Epoch: 6| Step: 2
Training loss: 1.7243093252182007
Validation loss: 2.305776003868349

Epoch: 6| Step: 3
Training loss: 2.405433177947998
Validation loss: 2.309309321065103

Epoch: 6| Step: 4
Training loss: 1.9998533725738525
Validation loss: 2.301745422424809

Epoch: 6| Step: 5
Training loss: 1.7772274017333984
Validation loss: 2.3031506769118772

Epoch: 6| Step: 6
Training loss: 3.158264398574829
Validation loss: 2.3076922790978545

Epoch: 6| Step: 7
Training loss: 3.0682449340820312
Validation loss: 2.3034443406648535

Epoch: 6| Step: 8
Training loss: 3.1208062171936035
Validation loss: 2.2987401767443587

Epoch: 6| Step: 9
Training loss: 2.5356881618499756
Validation loss: 2.2977278001846804

Epoch: 6| Step: 10
Training loss: 2.071638822555542
Validation loss: 2.2986467064067884

Epoch: 6| Step: 11
Training loss: 2.5566904544830322
Validation loss: 2.302276416491437

Epoch: 6| Step: 12
Training loss: 2.9999234676361084
Validation loss: 2.2960853807387815

Epoch: 6| Step: 13
Training loss: 3.366149425506592
Validation loss: 2.2944842269343715

Epoch: 59| Step: 0
Training loss: 2.5702662467956543
Validation loss: 2.2951531076944

Epoch: 6| Step: 1
Training loss: 2.765279769897461
Validation loss: 2.2989237180320163

Epoch: 6| Step: 2
Training loss: 2.2606120109558105
Validation loss: 2.2987130200991066

Epoch: 6| Step: 3
Training loss: 3.083510398864746
Validation loss: 2.3005383065951768

Epoch: 6| Step: 4
Training loss: 4.100902557373047
Validation loss: 2.3014337760145946

Epoch: 6| Step: 5
Training loss: 2.2005653381347656
Validation loss: 2.30574171773849

Epoch: 6| Step: 6
Training loss: 2.1943740844726562
Validation loss: 2.2937048481356714

Epoch: 6| Step: 7
Training loss: 1.7890009880065918
Validation loss: 2.2923221434316328

Epoch: 6| Step: 8
Training loss: 2.475250244140625
Validation loss: 2.2906282255726476

Epoch: 6| Step: 9
Training loss: 3.0289063453674316
Validation loss: 2.3160976030493297

Epoch: 6| Step: 10
Training loss: 2.3814430236816406
Validation loss: 2.3448795477549234

Epoch: 6| Step: 11
Training loss: 2.1193838119506836
Validation loss: 2.371989768038514

Epoch: 6| Step: 12
Training loss: 2.5748074054718018
Validation loss: 2.3759222261367308

Epoch: 6| Step: 13
Training loss: 2.3378546237945557
Validation loss: 2.3567155868776384

Epoch: 60| Step: 0
Training loss: 2.4913487434387207
Validation loss: 2.3320388768308904

Epoch: 6| Step: 1
Training loss: 2.4016051292419434
Validation loss: 2.3141124556141515

Epoch: 6| Step: 2
Training loss: 2.533104419708252
Validation loss: 2.3057257206209245

Epoch: 6| Step: 3
Training loss: 2.66158390045166
Validation loss: 2.2986921046369817

Epoch: 6| Step: 4
Training loss: 2.8703417778015137
Validation loss: 2.2911167760049143

Epoch: 6| Step: 5
Training loss: 2.5076823234558105
Validation loss: 2.2860177229809504

Epoch: 6| Step: 6
Training loss: 3.1850533485412598
Validation loss: 2.2970537216432634

Epoch: 6| Step: 7
Training loss: 2.8866539001464844
Validation loss: 2.3021431071783907

Epoch: 6| Step: 8
Training loss: 2.2122392654418945
Validation loss: 2.3029265916475685

Epoch: 6| Step: 9
Training loss: 2.623717784881592
Validation loss: 2.3067637310233167

Epoch: 6| Step: 10
Training loss: 2.229274272918701
Validation loss: 2.308502697175549

Epoch: 6| Step: 11
Training loss: 2.4309396743774414
Validation loss: 2.3023973203474477

Epoch: 6| Step: 12
Training loss: 2.7845206260681152
Validation loss: 2.2972138004918254

Epoch: 6| Step: 13
Training loss: 2.068607807159424
Validation loss: 2.29485910425904

Epoch: 61| Step: 0
Training loss: 2.078181266784668
Validation loss: 2.288481914868919

Epoch: 6| Step: 1
Training loss: 2.4624691009521484
Validation loss: 2.2884810675856886

Epoch: 6| Step: 2
Training loss: 2.7812745571136475
Validation loss: 2.293799300347605

Epoch: 6| Step: 3
Training loss: 2.583621025085449
Validation loss: 2.294452000689763

Epoch: 6| Step: 4
Training loss: 2.757493495941162
Validation loss: 2.3015121977816344

Epoch: 6| Step: 5
Training loss: 2.7608234882354736
Validation loss: 2.301571576826034

Epoch: 6| Step: 6
Training loss: 2.4292306900024414
Validation loss: 2.304931086878623

Epoch: 6| Step: 7
Training loss: 2.491518020629883
Validation loss: 2.301088143420476

Epoch: 6| Step: 8
Training loss: 2.848893880844116
Validation loss: 2.2987944310711277

Epoch: 6| Step: 9
Training loss: 2.0068116188049316
Validation loss: 2.3055850254592074

Epoch: 6| Step: 10
Training loss: 3.3951869010925293
Validation loss: 2.3145219305510163

Epoch: 6| Step: 11
Training loss: 2.933730125427246
Validation loss: 2.320975019085792

Epoch: 6| Step: 12
Training loss: 1.93107008934021
Validation loss: 2.313068389892578

Epoch: 6| Step: 13
Training loss: 2.314666509628296
Validation loss: 2.290264662875924

Epoch: 62| Step: 0
Training loss: 2.654550552368164
Validation loss: 2.278902812670636

Epoch: 6| Step: 1
Training loss: 2.3911685943603516
Validation loss: 2.2731904137519097

Epoch: 6| Step: 2
Training loss: 2.1550240516662598
Validation loss: 2.268676588612218

Epoch: 6| Step: 3
Training loss: 2.129851818084717
Validation loss: 2.2670915639528664

Epoch: 6| Step: 4
Training loss: 2.455594062805176
Validation loss: 2.2702737623645413

Epoch: 6| Step: 5
Training loss: 2.1352081298828125
Validation loss: 2.2730708481163107

Epoch: 6| Step: 6
Training loss: 3.341301202774048
Validation loss: 2.2818009648271786

Epoch: 6| Step: 7
Training loss: 2.8489503860473633
Validation loss: 2.2935061352227324

Epoch: 6| Step: 8
Training loss: 3.1150689125061035
Validation loss: 2.309074935092721

Epoch: 6| Step: 9
Training loss: 2.667489767074585
Validation loss: 2.319591078706967

Epoch: 6| Step: 10
Training loss: 2.4216907024383545
Validation loss: 2.322931448618571

Epoch: 6| Step: 11
Training loss: 1.9691822528839111
Validation loss: 2.323523759841919

Epoch: 6| Step: 12
Training loss: 3.0126848220825195
Validation loss: 2.3103816868156515

Epoch: 6| Step: 13
Training loss: 2.6659772396087646
Validation loss: 2.306609671602967

Epoch: 63| Step: 0
Training loss: 2.3651952743530273
Validation loss: 2.288084158333399

Epoch: 6| Step: 1
Training loss: 2.438512086868286
Validation loss: 2.2788959241682485

Epoch: 6| Step: 2
Training loss: 2.112494468688965
Validation loss: 2.269709607606293

Epoch: 6| Step: 3
Training loss: 2.0943801403045654
Validation loss: 2.270288816062353

Epoch: 6| Step: 4
Training loss: 2.8773655891418457
Validation loss: 2.2638140173368555

Epoch: 6| Step: 5
Training loss: 3.052449941635132
Validation loss: 2.263948978916291

Epoch: 6| Step: 6
Training loss: 2.6367030143737793
Validation loss: 2.268872884012038

Epoch: 6| Step: 7
Training loss: 2.4761409759521484
Validation loss: 2.2766500852441274

Epoch: 6| Step: 8
Training loss: 2.906843900680542
Validation loss: 2.2906987359446864

Epoch: 6| Step: 9
Training loss: 2.8979244232177734
Validation loss: 2.3124545620333765

Epoch: 6| Step: 10
Training loss: 2.1402807235717773
Validation loss: 2.318416997950564

Epoch: 6| Step: 11
Training loss: 2.9562172889709473
Validation loss: 2.303067216309168

Epoch: 6| Step: 12
Training loss: 2.275050640106201
Validation loss: 2.2947768947129608

Epoch: 6| Step: 13
Training loss: 2.5930445194244385
Validation loss: 2.3096191242176998

Epoch: 64| Step: 0
Training loss: 3.0825390815734863
Validation loss: 2.285934199569046

Epoch: 6| Step: 1
Training loss: 2.523332118988037
Validation loss: 2.2648136756753408

Epoch: 6| Step: 2
Training loss: 3.2330398559570312
Validation loss: 2.261238646763627

Epoch: 6| Step: 3
Training loss: 3.225527048110962
Validation loss: 2.2763843818377425

Epoch: 6| Step: 4
Training loss: 2.055874824523926
Validation loss: 2.287545806618147

Epoch: 6| Step: 5
Training loss: 1.8720358610153198
Validation loss: 2.2838774547781995

Epoch: 6| Step: 6
Training loss: 3.015991687774658
Validation loss: 2.2888842449393323

Epoch: 6| Step: 7
Training loss: 3.176283597946167
Validation loss: 2.2791570207124114

Epoch: 6| Step: 8
Training loss: 2.526733160018921
Validation loss: 2.277981391517065

Epoch: 6| Step: 9
Training loss: 2.58960223197937
Validation loss: 2.274023199594149

Epoch: 6| Step: 10
Training loss: 1.6339850425720215
Validation loss: 2.2724208524150233

Epoch: 6| Step: 11
Training loss: 2.4764835834503174
Validation loss: 2.2759744774910713

Epoch: 6| Step: 12
Training loss: 2.418567180633545
Validation loss: 2.2917637132829234

Epoch: 6| Step: 13
Training loss: 2.0040218830108643
Validation loss: 2.3224194460017706

Epoch: 65| Step: 0
Training loss: 2.789254665374756
Validation loss: 2.449134547223327

Epoch: 6| Step: 1
Training loss: 2.7805819511413574
Validation loss: 2.4611202850136706

Epoch: 6| Step: 2
Training loss: 2.9160685539245605
Validation loss: 2.3979930595685075

Epoch: 6| Step: 3
Training loss: 2.889476776123047
Validation loss: 2.3859217141264226

Epoch: 6| Step: 4
Training loss: 2.631680965423584
Validation loss: 2.3413968086242676

Epoch: 6| Step: 5
Training loss: 2.5864500999450684
Validation loss: 2.337783258448365

Epoch: 6| Step: 6
Training loss: 2.3811774253845215
Validation loss: 2.3436447471700688

Epoch: 6| Step: 7
Training loss: 2.3909640312194824
Validation loss: 2.3883839320111018

Epoch: 6| Step: 8
Training loss: 3.193192481994629
Validation loss: 2.394733344354937

Epoch: 6| Step: 9
Training loss: 1.8945077657699585
Validation loss: 2.343001796353248

Epoch: 6| Step: 10
Training loss: 2.9053969383239746
Validation loss: 2.293886661529541

Epoch: 6| Step: 11
Training loss: 2.445971965789795
Validation loss: 2.277503623757311

Epoch: 6| Step: 12
Training loss: 2.3657546043395996
Validation loss: 2.264804332487045

Epoch: 6| Step: 13
Training loss: 1.5699337720870972
Validation loss: 2.2579333807832453

Epoch: 66| Step: 0
Training loss: 2.5213723182678223
Validation loss: 2.256956369646134

Epoch: 6| Step: 1
Training loss: 2.084590196609497
Validation loss: 2.2491196227330033

Epoch: 6| Step: 2
Training loss: 2.7408394813537598
Validation loss: 2.2561250950700495

Epoch: 6| Step: 3
Training loss: 2.7443065643310547
Validation loss: 2.2712152055514756

Epoch: 6| Step: 4
Training loss: 2.0928800106048584
Validation loss: 2.2918712092984106

Epoch: 6| Step: 5
Training loss: 2.592296600341797
Validation loss: 2.3063894189814085

Epoch: 6| Step: 6
Training loss: 2.6613011360168457
Validation loss: 2.3122777913206365

Epoch: 6| Step: 7
Training loss: 2.630601644515991
Validation loss: 2.3086237087044665

Epoch: 6| Step: 8
Training loss: 2.868001699447632
Validation loss: 2.29283840938281

Epoch: 6| Step: 9
Training loss: 2.744356155395508
Validation loss: 2.282122660708684

Epoch: 6| Step: 10
Training loss: 2.6650538444519043
Validation loss: 2.2658867400179625

Epoch: 6| Step: 11
Training loss: 2.911005735397339
Validation loss: 2.259058813894949

Epoch: 6| Step: 12
Training loss: 1.9177664518356323
Validation loss: 2.2495566029702463

Epoch: 6| Step: 13
Training loss: 2.249009847640991
Validation loss: 2.241459115859001

Epoch: 67| Step: 0
Training loss: 2.1199493408203125
Validation loss: 2.2378476191592473

Epoch: 6| Step: 1
Training loss: 2.378387451171875
Validation loss: 2.232729152966571

Epoch: 6| Step: 2
Training loss: 2.1392436027526855
Validation loss: 2.2331464316255305

Epoch: 6| Step: 3
Training loss: 2.989311695098877
Validation loss: 2.238273569332656

Epoch: 6| Step: 4
Training loss: 2.3715357780456543
Validation loss: 2.2473034499793925

Epoch: 6| Step: 5
Training loss: 3.526543140411377
Validation loss: 2.253191460845291

Epoch: 6| Step: 6
Training loss: 3.1379692554473877
Validation loss: 2.2647851949097006

Epoch: 6| Step: 7
Training loss: 2.8306429386138916
Validation loss: 2.266886950821005

Epoch: 6| Step: 8
Training loss: 2.2523627281188965
Validation loss: 2.2690745194753013

Epoch: 6| Step: 9
Training loss: 2.894662380218506
Validation loss: 2.2747083812631588

Epoch: 6| Step: 10
Training loss: 2.116377830505371
Validation loss: 2.280329845284903

Epoch: 6| Step: 11
Training loss: 2.2302205562591553
Validation loss: 2.308776637559296

Epoch: 6| Step: 12
Training loss: 2.122842311859131
Validation loss: 2.307658403150497

Epoch: 6| Step: 13
Training loss: 2.3886594772338867
Validation loss: 2.293233097240489

Epoch: 68| Step: 0
Training loss: 3.0329275131225586
Validation loss: 2.2564194843333256

Epoch: 6| Step: 1
Training loss: 1.6979824304580688
Validation loss: 2.248549335746355

Epoch: 6| Step: 2
Training loss: 2.238607883453369
Validation loss: 2.2363770674633723

Epoch: 6| Step: 3
Training loss: 2.6512718200683594
Validation loss: 2.2385467970243065

Epoch: 6| Step: 4
Training loss: 2.7120821475982666
Validation loss: 2.2324997660934285

Epoch: 6| Step: 5
Training loss: 2.618607521057129
Validation loss: 2.2315540159902265

Epoch: 6| Step: 6
Training loss: 2.516695976257324
Validation loss: 2.2373092841076594

Epoch: 6| Step: 7
Training loss: 2.6644957065582275
Validation loss: 2.2379267959184546

Epoch: 6| Step: 8
Training loss: 2.4811363220214844
Validation loss: 2.2381168526987874

Epoch: 6| Step: 9
Training loss: 3.520888566970825
Validation loss: 2.247775605929795

Epoch: 6| Step: 10
Training loss: 1.8956332206726074
Validation loss: 2.250638528536725

Epoch: 6| Step: 11
Training loss: 2.271699905395508
Validation loss: 2.251361195759107

Epoch: 6| Step: 12
Training loss: 2.609203815460205
Validation loss: 2.2476115149836384

Epoch: 6| Step: 13
Training loss: 2.0436782836914062
Validation loss: 2.2518135655310845

Epoch: 69| Step: 0
Training loss: 1.822962999343872
Validation loss: 2.2448691116866244

Epoch: 6| Step: 1
Training loss: 2.0708961486816406
Validation loss: 2.2507272843391664

Epoch: 6| Step: 2
Training loss: 2.477153778076172
Validation loss: 2.2515075822030344

Epoch: 6| Step: 3
Training loss: 2.2260076999664307
Validation loss: 2.2349484402646302

Epoch: 6| Step: 4
Training loss: 2.607119560241699
Validation loss: 2.2254113099908315

Epoch: 6| Step: 5
Training loss: 2.6492249965667725
Validation loss: 2.2136211651627735

Epoch: 6| Step: 6
Training loss: 3.4928059577941895
Validation loss: 2.2148408428315194

Epoch: 6| Step: 7
Training loss: 2.590456008911133
Validation loss: 2.2202172087084864

Epoch: 6| Step: 8
Training loss: 2.442568063735962
Validation loss: 2.2227806660436813

Epoch: 6| Step: 9
Training loss: 2.044114589691162
Validation loss: 2.2145958792778755

Epoch: 6| Step: 10
Training loss: 3.397679328918457
Validation loss: 2.2127136338141655

Epoch: 6| Step: 11
Training loss: 2.503917694091797
Validation loss: 2.223467726861277

Epoch: 6| Step: 12
Training loss: 2.6245083808898926
Validation loss: 2.236929432038338

Epoch: 6| Step: 13
Training loss: 2.2921693325042725
Validation loss: 2.2553986067413003

Epoch: 70| Step: 0
Training loss: 2.0614702701568604
Validation loss: 2.2796761015410065

Epoch: 6| Step: 1
Training loss: 2.801754951477051
Validation loss: 2.2953677767066547

Epoch: 6| Step: 2
Training loss: 2.758803367614746
Validation loss: 2.288338863721458

Epoch: 6| Step: 3
Training loss: 2.5656840801239014
Validation loss: 2.2724556128184

Epoch: 6| Step: 4
Training loss: 2.734546184539795
Validation loss: 2.2625493900750273

Epoch: 6| Step: 5
Training loss: 1.918033480644226
Validation loss: 2.2488293135037987

Epoch: 6| Step: 6
Training loss: 2.182030200958252
Validation loss: 2.237155056768848

Epoch: 6| Step: 7
Training loss: 3.5375113487243652
Validation loss: 2.22751679471744

Epoch: 6| Step: 8
Training loss: 2.4171247482299805
Validation loss: 2.219059660870542

Epoch: 6| Step: 9
Training loss: 2.537287712097168
Validation loss: 2.219468770488616

Epoch: 6| Step: 10
Training loss: 2.577873706817627
Validation loss: 2.212023781191918

Epoch: 6| Step: 11
Training loss: 1.7681275606155396
Validation loss: 2.210430342664001

Epoch: 6| Step: 12
Training loss: 2.3548407554626465
Validation loss: 2.209691530914717

Epoch: 6| Step: 13
Training loss: 2.9532108306884766
Validation loss: 2.2046085967812488

Epoch: 71| Step: 0
Training loss: 2.72035813331604
Validation loss: 2.203349087827949

Epoch: 6| Step: 1
Training loss: 3.0054244995117188
Validation loss: 2.206276047614313

Epoch: 6| Step: 2
Training loss: 2.677338123321533
Validation loss: 2.209020012168474

Epoch: 6| Step: 3
Training loss: 1.899623155593872
Validation loss: 2.2186115454601985

Epoch: 6| Step: 4
Training loss: 2.4380006790161133
Validation loss: 2.218972644498271

Epoch: 6| Step: 5
Training loss: 3.173811435699463
Validation loss: 2.221056274188462

Epoch: 6| Step: 6
Training loss: 2.487380266189575
Validation loss: 2.231042315883021

Epoch: 6| Step: 7
Training loss: 1.808988094329834
Validation loss: 2.2327440323368197

Epoch: 6| Step: 8
Training loss: 2.0387256145477295
Validation loss: 2.235015937077102

Epoch: 6| Step: 9
Training loss: 3.1830267906188965
Validation loss: 2.2388901120872906

Epoch: 6| Step: 10
Training loss: 2.429544448852539
Validation loss: 2.2315489092180805

Epoch: 6| Step: 11
Training loss: 2.238028049468994
Validation loss: 2.227771620596609

Epoch: 6| Step: 12
Training loss: 2.287748098373413
Validation loss: 2.2207339707241265

Epoch: 6| Step: 13
Training loss: 2.4425270557403564
Validation loss: 2.210911427774737

Epoch: 72| Step: 0
Training loss: 2.143455982208252
Validation loss: 2.2098938367700063

Epoch: 6| Step: 1
Training loss: 2.1161012649536133
Validation loss: 2.204292192254015

Epoch: 6| Step: 2
Training loss: 2.066624402999878
Validation loss: 2.2054715387282835

Epoch: 6| Step: 3
Training loss: 2.1947569847106934
Validation loss: 2.203593889872233

Epoch: 6| Step: 4
Training loss: 2.8086905479431152
Validation loss: 2.2059150177945375

Epoch: 6| Step: 5
Training loss: 1.9636883735656738
Validation loss: 2.2011603437444216

Epoch: 6| Step: 6
Training loss: 2.3586907386779785
Validation loss: 2.204407068990892

Epoch: 6| Step: 7
Training loss: 2.7260398864746094
Validation loss: 2.1990639740420925

Epoch: 6| Step: 8
Training loss: 2.567497730255127
Validation loss: 2.2038407351381037

Epoch: 6| Step: 9
Training loss: 3.181197166442871
Validation loss: 2.2017506373825895

Epoch: 6| Step: 10
Training loss: 2.899958372116089
Validation loss: 2.1959879270163913

Epoch: 6| Step: 11
Training loss: 2.944974899291992
Validation loss: 2.1943682111719602

Epoch: 6| Step: 12
Training loss: 2.3862433433532715
Validation loss: 2.1988962286262104

Epoch: 6| Step: 13
Training loss: 2.3696491718292236
Validation loss: 2.2004296574541318

Epoch: 73| Step: 0
Training loss: 2.644099235534668
Validation loss: 2.2018994977397304

Epoch: 6| Step: 1
Training loss: 2.025238513946533
Validation loss: 2.2026778446730746

Epoch: 6| Step: 2
Training loss: 3.1178126335144043
Validation loss: 2.2095681685273365

Epoch: 6| Step: 3
Training loss: 2.6791014671325684
Validation loss: 2.217306493431009

Epoch: 6| Step: 4
Training loss: 1.7177584171295166
Validation loss: 2.2301864572750625

Epoch: 6| Step: 5
Training loss: 2.4766111373901367
Validation loss: 2.2275262519877446

Epoch: 6| Step: 6
Training loss: 2.7278265953063965
Validation loss: 2.2076202951451784

Epoch: 6| Step: 7
Training loss: 2.2835803031921387
Validation loss: 2.195644650408017

Epoch: 6| Step: 8
Training loss: 2.5630578994750977
Validation loss: 2.1845778944671794

Epoch: 6| Step: 9
Training loss: 1.9478166103363037
Validation loss: 2.1867448270961805

Epoch: 6| Step: 10
Training loss: 2.4367527961730957
Validation loss: 2.1880949953550934

Epoch: 6| Step: 11
Training loss: 2.3908729553222656
Validation loss: 2.1900868723469396

Epoch: 6| Step: 12
Training loss: 2.75665545463562
Validation loss: 2.185290249445105

Epoch: 6| Step: 13
Training loss: 3.2887489795684814
Validation loss: 2.1792596309415755

Epoch: 74| Step: 0
Training loss: 2.2728891372680664
Validation loss: 2.1792353019919446

Epoch: 6| Step: 1
Training loss: 2.6143715381622314
Validation loss: 2.1829230682824248

Epoch: 6| Step: 2
Training loss: 2.6512155532836914
Validation loss: 2.1873292282063472

Epoch: 6| Step: 3
Training loss: 2.410982131958008
Validation loss: 2.1900943607412358

Epoch: 6| Step: 4
Training loss: 2.5195326805114746
Validation loss: 2.194190113775192

Epoch: 6| Step: 5
Training loss: 1.95779287815094
Validation loss: 2.204127282224676

Epoch: 6| Step: 6
Training loss: 2.7066447734832764
Validation loss: 2.1893783871845534

Epoch: 6| Step: 7
Training loss: 2.749605178833008
Validation loss: 2.1781117300833426

Epoch: 6| Step: 8
Training loss: 2.102128028869629
Validation loss: 2.1739347596322336

Epoch: 6| Step: 9
Training loss: 2.8100383281707764
Validation loss: 2.179698021181168

Epoch: 6| Step: 10
Training loss: 2.4837615489959717
Validation loss: 2.1846176449970534

Epoch: 6| Step: 11
Training loss: 2.518890142440796
Validation loss: 2.1852498054504395

Epoch: 6| Step: 12
Training loss: 2.7327353954315186
Validation loss: 2.1794515976341824

Epoch: 6| Step: 13
Training loss: 2.2193374633789062
Validation loss: 2.1734658979600474

Epoch: 75| Step: 0
Training loss: 2.3144350051879883
Validation loss: 2.1741669588191535

Epoch: 6| Step: 1
Training loss: 2.1374459266662598
Validation loss: 2.193107824171743

Epoch: 6| Step: 2
Training loss: 2.2796621322631836
Validation loss: 2.2004197643649195

Epoch: 6| Step: 3
Training loss: 3.0428626537323
Validation loss: 2.194629625607562

Epoch: 6| Step: 4
Training loss: 2.437164783477783
Validation loss: 2.196515416586271

Epoch: 6| Step: 5
Training loss: 2.5259103775024414
Validation loss: 2.1792518041467153

Epoch: 6| Step: 6
Training loss: 1.7418285608291626
Validation loss: 2.1769027248505624

Epoch: 6| Step: 7
Training loss: 2.2410807609558105
Validation loss: 2.1768374622509046

Epoch: 6| Step: 8
Training loss: 2.314394950866699
Validation loss: 2.1821126873775194

Epoch: 6| Step: 9
Training loss: 2.8014822006225586
Validation loss: 2.1813686804104875

Epoch: 6| Step: 10
Training loss: 2.1908133029937744
Validation loss: 2.177611565077177

Epoch: 6| Step: 11
Training loss: 2.726243734359741
Validation loss: 2.1763741406061317

Epoch: 6| Step: 12
Training loss: 2.673513650894165
Validation loss: 2.1806220623754684

Epoch: 6| Step: 13
Training loss: 3.7141308784484863
Validation loss: 2.176536567749516

Epoch: 76| Step: 0
Training loss: 2.0564544200897217
Validation loss: 2.1756153157962266

Epoch: 6| Step: 1
Training loss: 2.8182766437530518
Validation loss: 2.177264844217608

Epoch: 6| Step: 2
Training loss: 3.163376808166504
Validation loss: 2.1863929430643716

Epoch: 6| Step: 3
Training loss: 2.3269002437591553
Validation loss: 2.193158834211288

Epoch: 6| Step: 4
Training loss: 2.608196258544922
Validation loss: 2.198243066828738

Epoch: 6| Step: 5
Training loss: 2.3880834579467773
Validation loss: 2.2022758427486626

Epoch: 6| Step: 6
Training loss: 2.5229854583740234
Validation loss: 2.1947843567017586

Epoch: 6| Step: 7
Training loss: 1.679381012916565
Validation loss: 2.199841248091831

Epoch: 6| Step: 8
Training loss: 2.637784004211426
Validation loss: 2.186039904112457

Epoch: 6| Step: 9
Training loss: 2.717219352722168
Validation loss: 2.1799233575021066

Epoch: 6| Step: 10
Training loss: 2.818420886993408
Validation loss: 2.175695147565616

Epoch: 6| Step: 11
Training loss: 2.8264265060424805
Validation loss: 2.17138889656272

Epoch: 6| Step: 12
Training loss: 1.4941688776016235
Validation loss: 2.17656567019801

Epoch: 6| Step: 13
Training loss: 2.3899552822113037
Validation loss: 2.176349755256407

Epoch: 77| Step: 0
Training loss: 1.9033793210983276
Validation loss: 2.174741333530795

Epoch: 6| Step: 1
Training loss: 1.9019453525543213
Validation loss: 2.1820299369032665

Epoch: 6| Step: 2
Training loss: 1.7989177703857422
Validation loss: 2.2020900223844793

Epoch: 6| Step: 3
Training loss: 2.4248476028442383
Validation loss: 2.2209466657330914

Epoch: 6| Step: 4
Training loss: 2.0409135818481445
Validation loss: 2.2181935002726894

Epoch: 6| Step: 5
Training loss: 2.62743878364563
Validation loss: 2.193200660008256

Epoch: 6| Step: 6
Training loss: 2.9558751583099365
Validation loss: 2.174385150273641

Epoch: 6| Step: 7
Training loss: 1.6566839218139648
Validation loss: 2.167458548340746

Epoch: 6| Step: 8
Training loss: 2.7401914596557617
Validation loss: 2.1625720326618483

Epoch: 6| Step: 9
Training loss: 2.665938377380371
Validation loss: 2.1649340301431637

Epoch: 6| Step: 10
Training loss: 2.1925039291381836
Validation loss: 2.159169917465538

Epoch: 6| Step: 11
Training loss: 3.8886823654174805
Validation loss: 2.1682962961094354

Epoch: 6| Step: 12
Training loss: 2.853355884552002
Validation loss: 2.169618647585633

Epoch: 6| Step: 13
Training loss: 2.876821756362915
Validation loss: 2.171146388976805

Epoch: 78| Step: 0
Training loss: 2.432636260986328
Validation loss: 2.173641356088782

Epoch: 6| Step: 1
Training loss: 2.901785135269165
Validation loss: 2.1787238941397717

Epoch: 6| Step: 2
Training loss: 2.5929508209228516
Validation loss: 2.173179316264327

Epoch: 6| Step: 3
Training loss: 2.520887851715088
Validation loss: 2.1661326513495496

Epoch: 6| Step: 4
Training loss: 2.0700740814208984
Validation loss: 2.158817442514563

Epoch: 6| Step: 5
Training loss: 2.2953338623046875
Validation loss: 2.1561056503685574

Epoch: 6| Step: 6
Training loss: 2.4750194549560547
Validation loss: 2.157257064696281

Epoch: 6| Step: 7
Training loss: 2.944129705429077
Validation loss: 2.1608286673022854

Epoch: 6| Step: 8
Training loss: 3.0505642890930176
Validation loss: 2.166396515343779

Epoch: 6| Step: 9
Training loss: 2.5834097862243652
Validation loss: 2.1690910118882374

Epoch: 6| Step: 10
Training loss: 2.3723483085632324
Validation loss: 2.1760918324993503

Epoch: 6| Step: 11
Training loss: 1.6750073432922363
Validation loss: 2.1713443750976236

Epoch: 6| Step: 12
Training loss: 2.737732410430908
Validation loss: 2.177829493758499

Epoch: 6| Step: 13
Training loss: 1.0336177349090576
Validation loss: 2.1875593675080167

Epoch: 79| Step: 0
Training loss: 3.041161060333252
Validation loss: 2.1887266558985554

Epoch: 6| Step: 1
Training loss: 1.9729236364364624
Validation loss: 2.1800232356594456

Epoch: 6| Step: 2
Training loss: 2.7649569511413574
Validation loss: 2.172036709324006

Epoch: 6| Step: 3
Training loss: 3.0172038078308105
Validation loss: 2.170080274663946

Epoch: 6| Step: 4
Training loss: 1.7741812467575073
Validation loss: 2.170198602061118

Epoch: 6| Step: 5
Training loss: 2.3555541038513184
Validation loss: 2.1575636158707323

Epoch: 6| Step: 6
Training loss: 2.1899585723876953
Validation loss: 2.153443483896153

Epoch: 6| Step: 7
Training loss: 3.0347161293029785
Validation loss: 2.146964293654247

Epoch: 6| Step: 8
Training loss: 2.3439323902130127
Validation loss: 2.1486428911967943

Epoch: 6| Step: 9
Training loss: 2.448424816131592
Validation loss: 2.144968089237008

Epoch: 6| Step: 10
Training loss: 2.0366532802581787
Validation loss: 2.1471271437983357

Epoch: 6| Step: 11
Training loss: 2.455233097076416
Validation loss: 2.150054770131265

Epoch: 6| Step: 12
Training loss: 2.0046801567077637
Validation loss: 2.147263180825018

Epoch: 6| Step: 13
Training loss: 2.992388963699341
Validation loss: 2.1581955917419924

Epoch: 80| Step: 0
Training loss: 1.5884363651275635
Validation loss: 2.1694432330387894

Epoch: 6| Step: 1
Training loss: 2.4851813316345215
Validation loss: 2.179703894481864

Epoch: 6| Step: 2
Training loss: 2.897491455078125
Validation loss: 2.1818118967035764

Epoch: 6| Step: 3
Training loss: 2.309755802154541
Validation loss: 2.1912046991368777

Epoch: 6| Step: 4
Training loss: 2.9469661712646484
Validation loss: 2.190970495182981

Epoch: 6| Step: 5
Training loss: 2.596740484237671
Validation loss: 2.1925599369951474

Epoch: 6| Step: 6
Training loss: 2.728788375854492
Validation loss: 2.180635226670132

Epoch: 6| Step: 7
Training loss: 2.654426097869873
Validation loss: 2.165550139642531

Epoch: 6| Step: 8
Training loss: 2.3465797901153564
Validation loss: 2.1572954564966182

Epoch: 6| Step: 9
Training loss: 2.3147757053375244
Validation loss: 2.156021643710393

Epoch: 6| Step: 10
Training loss: 2.58400297164917
Validation loss: 2.1568711239804506

Epoch: 6| Step: 11
Training loss: 2.5284786224365234
Validation loss: 2.156064700054866

Epoch: 6| Step: 12
Training loss: 1.8118778467178345
Validation loss: 2.1507249160479476

Epoch: 6| Step: 13
Training loss: 2.120006799697876
Validation loss: 2.148702823987571

Epoch: 81| Step: 0
Training loss: 2.292118787765503
Validation loss: 2.1548323759468655

Epoch: 6| Step: 1
Training loss: 2.027327537536621
Validation loss: 2.163381625247258

Epoch: 6| Step: 2
Training loss: 2.977126121520996
Validation loss: 2.16237098299047

Epoch: 6| Step: 3
Training loss: 1.8388395309448242
Validation loss: 2.1556046137245755

Epoch: 6| Step: 4
Training loss: 2.612121105194092
Validation loss: 2.150435722002419

Epoch: 6| Step: 5
Training loss: 2.694777488708496
Validation loss: 2.1504897917470625

Epoch: 6| Step: 6
Training loss: 2.5801284313201904
Validation loss: 2.1440956823287474

Epoch: 6| Step: 7
Training loss: 2.155069351196289
Validation loss: 2.1471185145839566

Epoch: 6| Step: 8
Training loss: 2.2542388439178467
Validation loss: 2.1885689073993313

Epoch: 6| Step: 9
Training loss: 2.840956211090088
Validation loss: 2.2137167171765397

Epoch: 6| Step: 10
Training loss: 2.22503924369812
Validation loss: 2.211657826618482

Epoch: 6| Step: 11
Training loss: 2.834906578063965
Validation loss: 2.1862819502430577

Epoch: 6| Step: 12
Training loss: 3.073012351989746
Validation loss: 2.15429861058471

Epoch: 6| Step: 13
Training loss: 2.0310444831848145
Validation loss: 2.1378750519085954

Epoch: 82| Step: 0
Training loss: 2.890857696533203
Validation loss: 2.135495601161834

Epoch: 6| Step: 1
Training loss: 2.0816986560821533
Validation loss: 2.1332942132026917

Epoch: 6| Step: 2
Training loss: 3.0003232955932617
Validation loss: 2.136313082069479

Epoch: 6| Step: 3
Training loss: 2.3577005863189697
Validation loss: 2.135082685819236

Epoch: 6| Step: 4
Training loss: 2.5914833545684814
Validation loss: 2.138524193917551

Epoch: 6| Step: 5
Training loss: 2.5057995319366455
Validation loss: 2.1350692933605564

Epoch: 6| Step: 6
Training loss: 2.634641170501709
Validation loss: 2.134302426409978

Epoch: 6| Step: 7
Training loss: 2.085638999938965
Validation loss: 2.1306019470255864

Epoch: 6| Step: 8
Training loss: 2.32041072845459
Validation loss: 2.1358856437026814

Epoch: 6| Step: 9
Training loss: 1.842572569847107
Validation loss: 2.1520177651477117

Epoch: 6| Step: 10
Training loss: 2.628206491470337
Validation loss: 2.1672993988119145

Epoch: 6| Step: 11
Training loss: 2.4257819652557373
Validation loss: 2.197230346741215

Epoch: 6| Step: 12
Training loss: 2.4771556854248047
Validation loss: 2.2003358564069195

Epoch: 6| Step: 13
Training loss: 2.1856706142425537
Validation loss: 2.2085794043797318

Epoch: 83| Step: 0
Training loss: 2.794949531555176
Validation loss: 2.1789911613669446

Epoch: 6| Step: 1
Training loss: 2.5231223106384277
Validation loss: 2.165550867716471

Epoch: 6| Step: 2
Training loss: 1.9658305644989014
Validation loss: 2.1531300365283923

Epoch: 6| Step: 3
Training loss: 2.74275803565979
Validation loss: 2.139754447885739

Epoch: 6| Step: 4
Training loss: 3.112126350402832
Validation loss: 2.1342015010054394

Epoch: 6| Step: 5
Training loss: 2.1955618858337402
Validation loss: 2.143419900248128

Epoch: 6| Step: 6
Training loss: 2.379955768585205
Validation loss: 2.1438486781171573

Epoch: 6| Step: 7
Training loss: 2.1532504558563232
Validation loss: 2.1375182059503373

Epoch: 6| Step: 8
Training loss: 2.1879444122314453
Validation loss: 2.121905381961535

Epoch: 6| Step: 9
Training loss: 2.3010244369506836
Validation loss: 2.118602132284513

Epoch: 6| Step: 10
Training loss: 2.075899600982666
Validation loss: 2.134819375571384

Epoch: 6| Step: 11
Training loss: 2.7675156593322754
Validation loss: 2.1490540453182754

Epoch: 6| Step: 12
Training loss: 2.247291088104248
Validation loss: 2.1716090761205202

Epoch: 6| Step: 13
Training loss: 2.570777416229248
Validation loss: 2.2046010853141866

Epoch: 84| Step: 0
Training loss: 2.482175350189209
Validation loss: 2.2300728700494252

Epoch: 6| Step: 1
Training loss: 2.6366615295410156
Validation loss: 2.2278879278449604

Epoch: 6| Step: 2
Training loss: 2.1177196502685547
Validation loss: 2.199079357167726

Epoch: 6| Step: 3
Training loss: 2.5066895484924316
Validation loss: 2.15795277267374

Epoch: 6| Step: 4
Training loss: 2.144273281097412
Validation loss: 2.147628240687873

Epoch: 6| Step: 5
Training loss: 2.4426844120025635
Validation loss: 2.1391911852744316

Epoch: 6| Step: 6
Training loss: 1.790654182434082
Validation loss: 2.1224279608777774

Epoch: 6| Step: 7
Training loss: 2.491164207458496
Validation loss: 2.1173759737322406

Epoch: 6| Step: 8
Training loss: 2.46923828125
Validation loss: 2.1108351330603323

Epoch: 6| Step: 9
Training loss: 2.9323995113372803
Validation loss: 2.1060191738990044

Epoch: 6| Step: 10
Training loss: 2.4560248851776123
Validation loss: 2.105084280813894

Epoch: 6| Step: 11
Training loss: 2.4112930297851562
Validation loss: 2.1075692407546507

Epoch: 6| Step: 12
Training loss: 2.7679686546325684
Validation loss: 2.103824705205938

Epoch: 6| Step: 13
Training loss: 2.4142332077026367
Validation loss: 2.1084861883553128

Epoch: 85| Step: 0
Training loss: 2.8037638664245605
Validation loss: 2.1129607872296403

Epoch: 6| Step: 1
Training loss: 2.4735350608825684
Validation loss: 2.1018781456896054

Epoch: 6| Step: 2
Training loss: 2.048217296600342
Validation loss: 2.1044174676300376

Epoch: 6| Step: 3
Training loss: 2.326427459716797
Validation loss: 2.1075470729540755

Epoch: 6| Step: 4
Training loss: 2.915909767150879
Validation loss: 2.102814725650254

Epoch: 6| Step: 5
Training loss: 2.088207244873047
Validation loss: 2.102077376457953

Epoch: 6| Step: 6
Training loss: 2.4809131622314453
Validation loss: 2.106303899518905

Epoch: 6| Step: 7
Training loss: 2.315006732940674
Validation loss: 2.1068059347009145

Epoch: 6| Step: 8
Training loss: 2.290192127227783
Validation loss: 2.106855312983195

Epoch: 6| Step: 9
Training loss: 2.5442309379577637
Validation loss: 2.1139694695831626

Epoch: 6| Step: 10
Training loss: 2.0202207565307617
Validation loss: 2.1198763244895527

Epoch: 6| Step: 11
Training loss: 2.230015516281128
Validation loss: 2.126835342376463

Epoch: 6| Step: 12
Training loss: 2.593959331512451
Validation loss: 2.1303121466790476

Epoch: 6| Step: 13
Training loss: 2.6185848712921143
Validation loss: 2.1330685230993454

Epoch: 86| Step: 0
Training loss: 2.2964160442352295
Validation loss: 2.128296870057301

Epoch: 6| Step: 1
Training loss: 2.930605411529541
Validation loss: 2.125611061690956

Epoch: 6| Step: 2
Training loss: 2.189361095428467
Validation loss: 2.1187809718552457

Epoch: 6| Step: 3
Training loss: 2.301069974899292
Validation loss: 2.102417253678845

Epoch: 6| Step: 4
Training loss: 2.132678985595703
Validation loss: 2.099840025747976

Epoch: 6| Step: 5
Training loss: 3.1600091457366943
Validation loss: 2.105010538972834

Epoch: 6| Step: 6
Training loss: 2.1165671348571777
Validation loss: 2.1003828984434887

Epoch: 6| Step: 7
Training loss: 1.9097892045974731
Validation loss: 2.1039517156539427

Epoch: 6| Step: 8
Training loss: 2.842393398284912
Validation loss: 2.1100591844128025

Epoch: 6| Step: 9
Training loss: 2.554152488708496
Validation loss: 2.109049907294653

Epoch: 6| Step: 10
Training loss: 1.9507102966308594
Validation loss: 2.1070026351559545

Epoch: 6| Step: 11
Training loss: 1.9250699281692505
Validation loss: 2.1067451200177594

Epoch: 6| Step: 12
Training loss: 2.8385748863220215
Validation loss: 2.119319341515982

Epoch: 6| Step: 13
Training loss: 2.5458216667175293
Validation loss: 2.130114424613214

Epoch: 87| Step: 0
Training loss: 1.6870931386947632
Validation loss: 2.1410166166161977

Epoch: 6| Step: 1
Training loss: 2.160804271697998
Validation loss: 2.132493834341726

Epoch: 6| Step: 2
Training loss: 2.6503801345825195
Validation loss: 2.124228051913682

Epoch: 6| Step: 3
Training loss: 3.1082544326782227
Validation loss: 2.1153715272103586

Epoch: 6| Step: 4
Training loss: 2.71753191947937
Validation loss: 2.11734442300694

Epoch: 6| Step: 5
Training loss: 1.7940326929092407
Validation loss: 2.1202713981751473

Epoch: 6| Step: 6
Training loss: 2.6985366344451904
Validation loss: 2.1312690550281155

Epoch: 6| Step: 7
Training loss: 2.4275879859924316
Validation loss: 2.1489270938340055

Epoch: 6| Step: 8
Training loss: 2.3301239013671875
Validation loss: 2.1502177689665105

Epoch: 6| Step: 9
Training loss: 2.2177610397338867
Validation loss: 2.144726278961346

Epoch: 6| Step: 10
Training loss: 2.8242523670196533
Validation loss: 2.126545891966871

Epoch: 6| Step: 11
Training loss: 2.17164945602417
Validation loss: 2.1015315248120214

Epoch: 6| Step: 12
Training loss: 2.222074031829834
Validation loss: 2.097779708523904

Epoch: 6| Step: 13
Training loss: 2.6419193744659424
Validation loss: 2.1000672283992974

Epoch: 88| Step: 0
Training loss: 2.5460708141326904
Validation loss: 2.1174857488242527

Epoch: 6| Step: 1
Training loss: 2.6168432235717773
Validation loss: 2.123342098728303

Epoch: 6| Step: 2
Training loss: 2.393876075744629
Validation loss: 2.1302215053189184

Epoch: 6| Step: 3
Training loss: 2.943235397338867
Validation loss: 2.1317820856648106

Epoch: 6| Step: 4
Training loss: 1.9740407466888428
Validation loss: 2.1403588402655815

Epoch: 6| Step: 5
Training loss: 2.529334783554077
Validation loss: 2.136438209523437

Epoch: 6| Step: 6
Training loss: 3.4142353534698486
Validation loss: 2.1176499602615193

Epoch: 6| Step: 7
Training loss: 2.332960605621338
Validation loss: 2.1033745119648595

Epoch: 6| Step: 8
Training loss: 2.3308205604553223
Validation loss: 2.0913855055327057

Epoch: 6| Step: 9
Training loss: 2.1104345321655273
Validation loss: 2.093356583708076

Epoch: 6| Step: 10
Training loss: 2.2481706142425537
Validation loss: 2.1085061411703787

Epoch: 6| Step: 11
Training loss: 2.368136167526245
Validation loss: 2.131145595222391

Epoch: 6| Step: 12
Training loss: 2.1809966564178467
Validation loss: 2.1715640970455703

Epoch: 6| Step: 13
Training loss: 2.128448963165283
Validation loss: 2.1888283632134877

Epoch: 89| Step: 0
Training loss: 2.414499282836914
Validation loss: 2.172297339285574

Epoch: 6| Step: 1
Training loss: 2.158423662185669
Validation loss: 2.1560218116288543

Epoch: 6| Step: 2
Training loss: 2.266502857208252
Validation loss: 2.1357490554932625

Epoch: 6| Step: 3
Training loss: 2.7014381885528564
Validation loss: 2.1222563277008715

Epoch: 6| Step: 4
Training loss: 2.0833041667938232
Validation loss: 2.1230301151993456

Epoch: 6| Step: 5
Training loss: 2.609544277191162
Validation loss: 2.119775487530616

Epoch: 6| Step: 6
Training loss: 1.9049955606460571
Validation loss: 2.1201553165271716

Epoch: 6| Step: 7
Training loss: 2.823391914367676
Validation loss: 2.1209292232349353

Epoch: 6| Step: 8
Training loss: 2.8108572959899902
Validation loss: 2.1368855686597925

Epoch: 6| Step: 9
Training loss: 2.7326297760009766
Validation loss: 2.1447103100438274

Epoch: 6| Step: 10
Training loss: 2.2069053649902344
Validation loss: 2.149172857243528

Epoch: 6| Step: 11
Training loss: 2.082226276397705
Validation loss: 2.1619004126518004

Epoch: 6| Step: 12
Training loss: 3.150714635848999
Validation loss: 2.149238113434084

Epoch: 6| Step: 13
Training loss: 1.5614951848983765
Validation loss: 2.145285916584794

Epoch: 90| Step: 0
Training loss: 2.0908565521240234
Validation loss: 2.1459181526655793

Epoch: 6| Step: 1
Training loss: 2.9504737854003906
Validation loss: 2.1468041968602005

Epoch: 6| Step: 2
Training loss: 2.5322747230529785
Validation loss: 2.1788360239357076

Epoch: 6| Step: 3
Training loss: 2.0908122062683105
Validation loss: 2.204565486600322

Epoch: 6| Step: 4
Training loss: 2.62011456489563
Validation loss: 2.2016833930887203

Epoch: 6| Step: 5
Training loss: 2.0573220252990723
Validation loss: 2.1981455049207135

Epoch: 6| Step: 6
Training loss: 2.667086601257324
Validation loss: 2.188423034965351

Epoch: 6| Step: 7
Training loss: 2.6947736740112305
Validation loss: 2.166931342053157

Epoch: 6| Step: 8
Training loss: 2.084333896636963
Validation loss: 2.1489690478130052

Epoch: 6| Step: 9
Training loss: 2.274883270263672
Validation loss: 2.139017742167237

Epoch: 6| Step: 10
Training loss: 2.2466249465942383
Validation loss: 2.1292174913549937

Epoch: 6| Step: 11
Training loss: 2.3297476768493652
Validation loss: 2.1262844352311987

Epoch: 6| Step: 12
Training loss: 2.5399093627929688
Validation loss: 2.1205266906369116

Epoch: 6| Step: 13
Training loss: 2.3873941898345947
Validation loss: 2.124780503652429

Epoch: 91| Step: 0
Training loss: 1.9058353900909424
Validation loss: 2.1138130734043736

Epoch: 6| Step: 1
Training loss: 1.6962642669677734
Validation loss: 2.1190167024571407

Epoch: 6| Step: 2
Training loss: 2.4591448307037354
Validation loss: 2.1150151837256645

Epoch: 6| Step: 3
Training loss: 1.9838696718215942
Validation loss: 2.1301478262870543

Epoch: 6| Step: 4
Training loss: 2.9562220573425293
Validation loss: 2.143537932826627

Epoch: 6| Step: 5
Training loss: 2.981802225112915
Validation loss: 2.1499550316923406

Epoch: 6| Step: 6
Training loss: 2.5025458335876465
Validation loss: 2.1641907999592442

Epoch: 6| Step: 7
Training loss: 3.0880212783813477
Validation loss: 2.159226025304487

Epoch: 6| Step: 8
Training loss: 2.35391902923584
Validation loss: 2.1579597047580186

Epoch: 6| Step: 9
Training loss: 2.532668352127075
Validation loss: 2.1649064376790035

Epoch: 6| Step: 10
Training loss: 1.82346510887146
Validation loss: 2.14748187475307

Epoch: 6| Step: 11
Training loss: 2.2927417755126953
Validation loss: 2.132476137530419

Epoch: 6| Step: 12
Training loss: 2.2305080890655518
Validation loss: 2.121337854734031

Epoch: 6| Step: 13
Training loss: 3.167632818222046
Validation loss: 2.1106044195031606

Epoch: 92| Step: 0
Training loss: 2.2283544540405273
Validation loss: 2.1111586042629775

Epoch: 6| Step: 1
Training loss: 2.5417871475219727
Validation loss: 2.1089613463288996

Epoch: 6| Step: 2
Training loss: 2.2293646335601807
Validation loss: 2.1188731065360447

Epoch: 6| Step: 3
Training loss: 2.3976011276245117
Validation loss: 2.1183701689525316

Epoch: 6| Step: 4
Training loss: 3.179828405380249
Validation loss: 2.111605462207589

Epoch: 6| Step: 5
Training loss: 1.9870750904083252
Validation loss: 2.113935011689381

Epoch: 6| Step: 6
Training loss: 1.9040136337280273
Validation loss: 2.1196021033871557

Epoch: 6| Step: 7
Training loss: 2.1984269618988037
Validation loss: 2.1297471074647802

Epoch: 6| Step: 8
Training loss: 1.7169432640075684
Validation loss: 2.129112421825368

Epoch: 6| Step: 9
Training loss: 2.47043514251709
Validation loss: 2.13750002461095

Epoch: 6| Step: 10
Training loss: 2.241250991821289
Validation loss: 2.145664830361643

Epoch: 6| Step: 11
Training loss: 2.9327259063720703
Validation loss: 2.1333313244645313

Epoch: 6| Step: 12
Training loss: 2.6436235904693604
Validation loss: 2.1232807866988646

Epoch: 6| Step: 13
Training loss: 2.9150705337524414
Validation loss: 2.1147422405981247

Epoch: 93| Step: 0
Training loss: 1.4761135578155518
Validation loss: 2.1088505227078675

Epoch: 6| Step: 1
Training loss: 2.6253201961517334
Validation loss: 2.1110063881002445

Epoch: 6| Step: 2
Training loss: 2.279719829559326
Validation loss: 2.1227964919100524

Epoch: 6| Step: 3
Training loss: 1.9501029253005981
Validation loss: 2.1282111496053715

Epoch: 6| Step: 4
Training loss: 3.4524078369140625
Validation loss: 2.1371270507894535

Epoch: 6| Step: 5
Training loss: 2.2758655548095703
Validation loss: 2.1256505981568368

Epoch: 6| Step: 6
Training loss: 2.610532760620117
Validation loss: 2.1223250050698557

Epoch: 6| Step: 7
Training loss: 2.098806381225586
Validation loss: 2.104220523629137

Epoch: 6| Step: 8
Training loss: 2.1355533599853516
Validation loss: 2.104881504530548

Epoch: 6| Step: 9
Training loss: 1.862991213798523
Validation loss: 2.105342859862953

Epoch: 6| Step: 10
Training loss: 2.290769100189209
Validation loss: 2.1021242116087224

Epoch: 6| Step: 11
Training loss: 3.407956600189209
Validation loss: 2.1061449563631447

Epoch: 6| Step: 12
Training loss: 2.4797348976135254
Validation loss: 2.104350506618459

Epoch: 6| Step: 13
Training loss: 2.2984564304351807
Validation loss: 2.1045626491628666

Epoch: 94| Step: 0
Training loss: 2.827902317047119
Validation loss: 2.092905811084214

Epoch: 6| Step: 1
Training loss: 1.9561185836791992
Validation loss: 2.0935290013590167

Epoch: 6| Step: 2
Training loss: 2.730020046234131
Validation loss: 2.0955481836872716

Epoch: 6| Step: 3
Training loss: 2.3992228507995605
Validation loss: 2.1079439399062947

Epoch: 6| Step: 4
Training loss: 2.4384713172912598
Validation loss: 2.1178179351232385

Epoch: 6| Step: 5
Training loss: 2.267005443572998
Validation loss: 2.1217082315875637

Epoch: 6| Step: 6
Training loss: 2.0666396617889404
Validation loss: 2.1072092543366137

Epoch: 6| Step: 7
Training loss: 1.9923452138900757
Validation loss: 2.1039831971609466

Epoch: 6| Step: 8
Training loss: 2.551405429840088
Validation loss: 2.1062534752712456

Epoch: 6| Step: 9
Training loss: 2.20460844039917
Validation loss: 2.098129382697485

Epoch: 6| Step: 10
Training loss: 2.256089925765991
Validation loss: 2.099033953041159

Epoch: 6| Step: 11
Training loss: 2.5034046173095703
Validation loss: 2.1080395995929675

Epoch: 6| Step: 12
Training loss: 2.673654556274414
Validation loss: 2.1141978489455355

Epoch: 6| Step: 13
Training loss: 1.8776065111160278
Validation loss: 2.1255029427107943

Epoch: 95| Step: 0
Training loss: 2.1528725624084473
Validation loss: 2.1361812622316423

Epoch: 6| Step: 1
Training loss: 2.167393922805786
Validation loss: 2.116525198823662

Epoch: 6| Step: 2
Training loss: 2.8512964248657227
Validation loss: 2.1098389805004163

Epoch: 6| Step: 3
Training loss: 2.6805644035339355
Validation loss: 2.1033504803975425

Epoch: 6| Step: 4
Training loss: 2.5860812664031982
Validation loss: 2.093131980588359

Epoch: 6| Step: 5
Training loss: 2.5665454864501953
Validation loss: 2.0804816599815124

Epoch: 6| Step: 6
Training loss: 2.8766860961914062
Validation loss: 2.062754995079451

Epoch: 6| Step: 7
Training loss: 2.1094181537628174
Validation loss: 2.07072465906861

Epoch: 6| Step: 8
Training loss: 2.13657808303833
Validation loss: 2.0635499723495974

Epoch: 6| Step: 9
Training loss: 2.1166810989379883
Validation loss: 2.0606480606140627

Epoch: 6| Step: 10
Training loss: 2.8058700561523438
Validation loss: 2.0662918347184376

Epoch: 6| Step: 11
Training loss: 1.8451043367385864
Validation loss: 2.0715171367891374

Epoch: 6| Step: 12
Training loss: 2.015449047088623
Validation loss: 2.0865127655767624

Epoch: 6| Step: 13
Training loss: 1.7452504634857178
Validation loss: 2.1079720720168083

Epoch: 96| Step: 0
Training loss: 2.106719493865967
Validation loss: 2.1238105271452214

Epoch: 6| Step: 1
Training loss: 2.7914865016937256
Validation loss: 2.1325844052017375

Epoch: 6| Step: 2
Training loss: 2.794647693634033
Validation loss: 2.1278207417457335

Epoch: 6| Step: 3
Training loss: 2.0869359970092773
Validation loss: 2.1352614587353123

Epoch: 6| Step: 4
Training loss: 1.9619028568267822
Validation loss: 2.1191291680899997

Epoch: 6| Step: 5
Training loss: 2.4206156730651855
Validation loss: 2.0963859481196248

Epoch: 6| Step: 6
Training loss: 2.287881374359131
Validation loss: 2.0836834933168147

Epoch: 6| Step: 7
Training loss: 2.1693453788757324
Validation loss: 2.081940856031192

Epoch: 6| Step: 8
Training loss: 2.4238691329956055
Validation loss: 2.086195645793792

Epoch: 6| Step: 9
Training loss: 2.6015918254852295
Validation loss: 2.090406430664883

Epoch: 6| Step: 10
Training loss: 2.203829765319824
Validation loss: 2.0994410489195134

Epoch: 6| Step: 11
Training loss: 2.1952850818634033
Validation loss: 2.0909645313857705

Epoch: 6| Step: 12
Training loss: 2.1872267723083496
Validation loss: 2.0906884772803194

Epoch: 6| Step: 13
Training loss: 2.951097011566162
Validation loss: 2.0866097519474645

Epoch: 97| Step: 0
Training loss: 2.204339027404785
Validation loss: 2.082610736611069

Epoch: 6| Step: 1
Training loss: 2.1304445266723633
Validation loss: 2.0892503312838975

Epoch: 6| Step: 2
Training loss: 3.5562357902526855
Validation loss: 2.07769646311319

Epoch: 6| Step: 3
Training loss: 2.068488121032715
Validation loss: 2.0649687756774244

Epoch: 6| Step: 4
Training loss: 2.096759796142578
Validation loss: 2.0679412862306

Epoch: 6| Step: 5
Training loss: 2.6050567626953125
Validation loss: 2.06429640195703

Epoch: 6| Step: 6
Training loss: 2.2092971801757812
Validation loss: 2.0669046294304634

Epoch: 6| Step: 7
Training loss: 1.6385575532913208
Validation loss: 2.061093566238239

Epoch: 6| Step: 8
Training loss: 1.9482852220535278
Validation loss: 2.0591981026434127

Epoch: 6| Step: 9
Training loss: 2.207521915435791
Validation loss: 2.0623253571089877

Epoch: 6| Step: 10
Training loss: 1.575728416442871
Validation loss: 2.071494052487035

Epoch: 6| Step: 11
Training loss: 2.5140233039855957
Validation loss: 2.069500707810925

Epoch: 6| Step: 12
Training loss: 3.29941725730896
Validation loss: 2.0652061277820217

Epoch: 6| Step: 13
Training loss: 2.5894815921783447
Validation loss: 2.05865567217591

Epoch: 98| Step: 0
Training loss: 1.6391735076904297
Validation loss: 2.0583504451218473

Epoch: 6| Step: 1
Training loss: 1.9972953796386719
Validation loss: 2.056258805336491

Epoch: 6| Step: 2
Training loss: 2.0478906631469727
Validation loss: 2.060095347383971

Epoch: 6| Step: 3
Training loss: 2.193942070007324
Validation loss: 2.051207883383638

Epoch: 6| Step: 4
Training loss: 2.446442127227783
Validation loss: 2.0596007224052184

Epoch: 6| Step: 5
Training loss: 2.344841718673706
Validation loss: 2.0568426039911087

Epoch: 6| Step: 6
Training loss: 2.9337868690490723
Validation loss: 2.0616092425520702

Epoch: 6| Step: 7
Training loss: 2.5203542709350586
Validation loss: 2.0570884058552403

Epoch: 6| Step: 8
Training loss: 2.70114803314209
Validation loss: 2.059826179217267

Epoch: 6| Step: 9
Training loss: 1.972368597984314
Validation loss: 2.0722551666280276

Epoch: 6| Step: 10
Training loss: 2.4980106353759766
Validation loss: 2.0706600604518766

Epoch: 6| Step: 11
Training loss: 2.359889507293701
Validation loss: 2.069087800159249

Epoch: 6| Step: 12
Training loss: 2.3106613159179688
Validation loss: 2.0633383258696525

Epoch: 6| Step: 13
Training loss: 2.299104928970337
Validation loss: 2.0578419457199755

Epoch: 99| Step: 0
Training loss: 2.4910271167755127
Validation loss: 2.0630440891429944

Epoch: 6| Step: 1
Training loss: 3.0277504920959473
Validation loss: 2.0588644319964993

Epoch: 6| Step: 2
Training loss: 2.8876538276672363
Validation loss: 2.0586452881495156

Epoch: 6| Step: 3
Training loss: 2.5727829933166504
Validation loss: 2.054327223890571

Epoch: 6| Step: 4
Training loss: 2.4178872108459473
Validation loss: 2.0506071993099746

Epoch: 6| Step: 5
Training loss: 2.2059502601623535
Validation loss: 2.050418717886812

Epoch: 6| Step: 6
Training loss: 2.401691436767578
Validation loss: 2.049233031529252

Epoch: 6| Step: 7
Training loss: 1.8745315074920654
Validation loss: 2.050652460385394

Epoch: 6| Step: 8
Training loss: 2.0801429748535156
Validation loss: 2.0526705095844884

Epoch: 6| Step: 9
Training loss: 1.8466640710830688
Validation loss: 2.0694138414116314

Epoch: 6| Step: 10
Training loss: 2.452258825302124
Validation loss: 2.0870603874165523

Epoch: 6| Step: 11
Training loss: 1.3689038753509521
Validation loss: 2.093708333148751

Epoch: 6| Step: 12
Training loss: 3.008455514907837
Validation loss: 2.0647296700426327

Epoch: 6| Step: 13
Training loss: 1.6172891855239868
Validation loss: 2.053337897023847

Epoch: 100| Step: 0
Training loss: 1.8243722915649414
Validation loss: 2.042471161452673

Epoch: 6| Step: 1
Training loss: 1.9205217361450195
Validation loss: 2.0460298445916947

Epoch: 6| Step: 2
Training loss: 2.5381522178649902
Validation loss: 2.050870697985413

Epoch: 6| Step: 3
Training loss: 2.357703447341919
Validation loss: 2.051702473753242

Epoch: 6| Step: 4
Training loss: 2.3756628036499023
Validation loss: 2.0426691603916947

Epoch: 6| Step: 5
Training loss: 1.9144858121871948
Validation loss: 2.0460630283560803

Epoch: 6| Step: 6
Training loss: 2.7104835510253906
Validation loss: 2.046172015128597

Epoch: 6| Step: 7
Training loss: 2.567502021789551
Validation loss: 2.0504269407641504

Epoch: 6| Step: 8
Training loss: 1.973360538482666
Validation loss: 2.0560760574956096

Epoch: 6| Step: 9
Training loss: 2.9012460708618164
Validation loss: 2.06730285767586

Epoch: 6| Step: 10
Training loss: 2.42193865776062
Validation loss: 2.0802353710256596

Epoch: 6| Step: 11
Training loss: 2.57641863822937
Validation loss: 2.091482949513261

Epoch: 6| Step: 12
Training loss: 2.0773799419403076
Validation loss: 2.099849865000735

Epoch: 6| Step: 13
Training loss: 2.016585350036621
Validation loss: 2.0892971382346204

Epoch: 101| Step: 0
Training loss: 1.8875572681427002
Validation loss: 2.0943588941327986

Epoch: 6| Step: 1
Training loss: 2.398664712905884
Validation loss: 2.0892361492239018

Epoch: 6| Step: 2
Training loss: 2.4245660305023193
Validation loss: 2.080039815236163

Epoch: 6| Step: 3
Training loss: 2.099893569946289
Validation loss: 2.0599145953373244

Epoch: 6| Step: 4
Training loss: 2.1001453399658203
Validation loss: 2.0518630704572125

Epoch: 6| Step: 5
Training loss: 3.291414499282837
Validation loss: 2.057649523981156

Epoch: 6| Step: 6
Training loss: 1.936132788658142
Validation loss: 2.0577052690649547

Epoch: 6| Step: 7
Training loss: 2.52144455909729
Validation loss: 2.0537471322603125

Epoch: 6| Step: 8
Training loss: 2.294550895690918
Validation loss: 2.0582690328680058

Epoch: 6| Step: 9
Training loss: 2.5739822387695312
Validation loss: 2.0591575484122

Epoch: 6| Step: 10
Training loss: 1.9489076137542725
Validation loss: 2.0612354406746487

Epoch: 6| Step: 11
Training loss: 2.4872002601623535
Validation loss: 2.0544820472758305

Epoch: 6| Step: 12
Training loss: 2.356842517852783
Validation loss: 2.051463862901093

Epoch: 6| Step: 13
Training loss: 1.9296226501464844
Validation loss: 2.063244274867478

Epoch: 102| Step: 0
Training loss: 2.354964017868042
Validation loss: 2.054573719219495

Epoch: 6| Step: 1
Training loss: 2.2565553188323975
Validation loss: 2.0491095871053715

Epoch: 6| Step: 2
Training loss: 2.4237067699432373
Validation loss: 2.0517678030075563

Epoch: 6| Step: 3
Training loss: 2.058614492416382
Validation loss: 2.0517809698658604

Epoch: 6| Step: 4
Training loss: 2.2755846977233887
Validation loss: 2.051525224921524

Epoch: 6| Step: 5
Training loss: 2.530629873275757
Validation loss: 2.0421929974709787

Epoch: 6| Step: 6
Training loss: 1.2978777885437012
Validation loss: 2.0399641439478886

Epoch: 6| Step: 7
Training loss: 2.7916767597198486
Validation loss: 2.0468759152197067

Epoch: 6| Step: 8
Training loss: 2.3133862018585205
Validation loss: 2.0465062651582944

Epoch: 6| Step: 9
Training loss: 1.8959261178970337
Validation loss: 2.059154151588358

Epoch: 6| Step: 10
Training loss: 3.0193867683410645
Validation loss: 2.071640032593922

Epoch: 6| Step: 11
Training loss: 2.0284862518310547
Validation loss: 2.0731307050233245

Epoch: 6| Step: 12
Training loss: 2.581026554107666
Validation loss: 2.055139098116147

Epoch: 6| Step: 13
Training loss: 2.1772401332855225
Validation loss: 2.043479952760922

Epoch: 103| Step: 0
Training loss: 2.0247602462768555
Validation loss: 2.0419173548298497

Epoch: 6| Step: 1
Training loss: 2.5084476470947266
Validation loss: 2.0334354049415997

Epoch: 6| Step: 2
Training loss: 2.0957672595977783
Validation loss: 2.0325487711096324

Epoch: 6| Step: 3
Training loss: 2.4838438034057617
Validation loss: 2.035334067959939

Epoch: 6| Step: 4
Training loss: 2.312319278717041
Validation loss: 2.0336084724754415

Epoch: 6| Step: 5
Training loss: 2.152508497238159
Validation loss: 2.034614755261329

Epoch: 6| Step: 6
Training loss: 2.965207099914551
Validation loss: 2.0296944405442927

Epoch: 6| Step: 7
Training loss: 2.7500102519989014
Validation loss: 2.031978007285826

Epoch: 6| Step: 8
Training loss: 1.8742854595184326
Validation loss: 2.0385431756255445

Epoch: 6| Step: 9
Training loss: 1.7415030002593994
Validation loss: 2.0438639194734636

Epoch: 6| Step: 10
Training loss: 2.5111312866210938
Validation loss: 2.0604017562763666

Epoch: 6| Step: 11
Training loss: 2.3823299407958984
Validation loss: 2.072468770447598

Epoch: 6| Step: 12
Training loss: 2.068528413772583
Validation loss: 2.074171990476629

Epoch: 6| Step: 13
Training loss: 2.0355873107910156
Validation loss: 2.0703648367235736

Epoch: 104| Step: 0
Training loss: 2.3892273902893066
Validation loss: 2.0633905215929915

Epoch: 6| Step: 1
Training loss: 2.468996047973633
Validation loss: 2.0544612407684326

Epoch: 6| Step: 2
Training loss: 2.1527743339538574
Validation loss: 2.0506656323709795

Epoch: 6| Step: 3
Training loss: 2.28741455078125
Validation loss: 2.02977930730389

Epoch: 6| Step: 4
Training loss: 2.3420028686523438
Validation loss: 2.043499385156939

Epoch: 6| Step: 5
Training loss: 2.3842759132385254
Validation loss: 2.0382010552190963

Epoch: 6| Step: 6
Training loss: 2.292137384414673
Validation loss: 2.0444347832792547

Epoch: 6| Step: 7
Training loss: 2.6448006629943848
Validation loss: 2.034431316519296

Epoch: 6| Step: 8
Training loss: 2.574862480163574
Validation loss: 2.0280344742600636

Epoch: 6| Step: 9
Training loss: 1.8785251379013062
Validation loss: 2.032477335263324

Epoch: 6| Step: 10
Training loss: 1.7729711532592773
Validation loss: 2.0370168750004103

Epoch: 6| Step: 11
Training loss: 2.6010985374450684
Validation loss: 2.0671399357498332

Epoch: 6| Step: 12
Training loss: 2.1950032711029053
Validation loss: 2.078750500115015

Epoch: 6| Step: 13
Training loss: 1.5119520425796509
Validation loss: 2.0863692183648386

Epoch: 105| Step: 0
Training loss: 1.8835889101028442
Validation loss: 2.081117973532728

Epoch: 6| Step: 1
Training loss: 2.1556944847106934
Validation loss: 2.0712180881090063

Epoch: 6| Step: 2
Training loss: 2.4821624755859375
Validation loss: 2.0700754337413336

Epoch: 6| Step: 3
Training loss: 1.9228596687316895
Validation loss: 2.0646851652412006

Epoch: 6| Step: 4
Training loss: 2.7402923107147217
Validation loss: 2.0490579758920977

Epoch: 6| Step: 5
Training loss: 1.654628038406372
Validation loss: 2.0464785727121497

Epoch: 6| Step: 6
Training loss: 1.783443570137024
Validation loss: 2.0657660768878077

Epoch: 6| Step: 7
Training loss: 2.218628406524658
Validation loss: 2.0700164174520843

Epoch: 6| Step: 8
Training loss: 2.6863303184509277
Validation loss: 2.073125877688008

Epoch: 6| Step: 9
Training loss: 2.625528573989868
Validation loss: 2.0684358791638444

Epoch: 6| Step: 10
Training loss: 1.994682788848877
Validation loss: 2.057799426458215

Epoch: 6| Step: 11
Training loss: 3.0811471939086914
Validation loss: 2.0431361518880373

Epoch: 6| Step: 12
Training loss: 3.180741548538208
Validation loss: 2.046374221001902

Epoch: 6| Step: 13
Training loss: 2.294227123260498
Validation loss: 2.05354570317012

Epoch: 106| Step: 0
Training loss: 2.1504199504852295
Validation loss: 2.0511089499278734

Epoch: 6| Step: 1
Training loss: 1.8501653671264648
Validation loss: 2.050781060290593

Epoch: 6| Step: 2
Training loss: 2.278515338897705
Validation loss: 2.0496795421005576

Epoch: 6| Step: 3
Training loss: 2.640073299407959
Validation loss: 2.03810009648723

Epoch: 6| Step: 4
Training loss: 2.5106282234191895
Validation loss: 2.026631757777224

Epoch: 6| Step: 5
Training loss: 2.707427978515625
Validation loss: 2.0167793086780015

Epoch: 6| Step: 6
Training loss: 2.265645980834961
Validation loss: 2.0260125372999456

Epoch: 6| Step: 7
Training loss: 1.698959231376648
Validation loss: 2.025673638107956

Epoch: 6| Step: 8
Training loss: 2.4941625595092773
Validation loss: 2.0287887434805594

Epoch: 6| Step: 9
Training loss: 2.6075599193573
Validation loss: 2.0311049453673826

Epoch: 6| Step: 10
Training loss: 1.9570225477218628
Validation loss: 2.033959286187285

Epoch: 6| Step: 11
Training loss: 2.4517340660095215
Validation loss: 2.024977550711683

Epoch: 6| Step: 12
Training loss: 2.6907200813293457
Validation loss: 2.032170536697552

Epoch: 6| Step: 13
Training loss: 1.2734293937683105
Validation loss: 2.0456820611030824

Epoch: 107| Step: 0
Training loss: 2.725170373916626
Validation loss: 2.082726373467394

Epoch: 6| Step: 1
Training loss: 2.3869380950927734
Validation loss: 2.1148739553266958

Epoch: 6| Step: 2
Training loss: 1.6313166618347168
Validation loss: 2.15184711897245

Epoch: 6| Step: 3
Training loss: 2.095602512359619
Validation loss: 2.177800820719811

Epoch: 6| Step: 4
Training loss: 2.056737184524536
Validation loss: 2.1792124804630073

Epoch: 6| Step: 5
Training loss: 2.8912558555603027
Validation loss: 2.1832875679898005

Epoch: 6| Step: 6
Training loss: 2.8948628902435303
Validation loss: 2.1649913146931636

Epoch: 6| Step: 7
Training loss: 2.4319608211517334
Validation loss: 2.1207079682298886

Epoch: 6| Step: 8
Training loss: 2.5493199825286865
Validation loss: 2.0980445159378873

Epoch: 6| Step: 9
Training loss: 1.824277400970459
Validation loss: 2.047490805707952

Epoch: 6| Step: 10
Training loss: 2.6037936210632324
Validation loss: 2.0458650973535355

Epoch: 6| Step: 11
Training loss: 1.995922565460205
Validation loss: 2.059299415157687

Epoch: 6| Step: 12
Training loss: 2.5768191814422607
Validation loss: 2.0515843386291177

Epoch: 6| Step: 13
Training loss: 2.293656349182129
Validation loss: 2.0494840350202335

Epoch: 108| Step: 0
Training loss: 2.5883874893188477
Validation loss: 2.033097259459957

Epoch: 6| Step: 1
Training loss: 2.6163251399993896
Validation loss: 2.019030406910886

Epoch: 6| Step: 2
Training loss: 2.2817628383636475
Validation loss: 2.0202489129958616

Epoch: 6| Step: 3
Training loss: 2.3855361938476562
Validation loss: 2.0209591824521302

Epoch: 6| Step: 4
Training loss: 2.0001583099365234
Validation loss: 2.0322094117441485

Epoch: 6| Step: 5
Training loss: 1.9240429401397705
Validation loss: 2.0469153683672667

Epoch: 6| Step: 6
Training loss: 2.204411029815674
Validation loss: 2.066817464367036

Epoch: 6| Step: 7
Training loss: 2.0536999702453613
Validation loss: 2.062519613132682

Epoch: 6| Step: 8
Training loss: 2.0862979888916016
Validation loss: 2.0560480215216197

Epoch: 6| Step: 9
Training loss: 2.5043396949768066
Validation loss: 2.0525743679333757

Epoch: 6| Step: 10
Training loss: 2.0653839111328125
Validation loss: 2.056728893710721

Epoch: 6| Step: 11
Training loss: 3.139611005783081
Validation loss: 2.0595471115522486

Epoch: 6| Step: 12
Training loss: 2.346802234649658
Validation loss: 2.05243847703421

Epoch: 6| Step: 13
Training loss: 0.7186034321784973
Validation loss: 2.034417703587522

Epoch: 109| Step: 0
Training loss: 2.321902275085449
Validation loss: 2.0248388577533025

Epoch: 6| Step: 1
Training loss: 2.301206588745117
Validation loss: 2.025483064754035

Epoch: 6| Step: 2
Training loss: 2.2692322731018066
Validation loss: 2.03303889818089

Epoch: 6| Step: 3
Training loss: 1.772322177886963
Validation loss: 2.0312697041419243

Epoch: 6| Step: 4
Training loss: 2.1384849548339844
Validation loss: 2.0333943892550725

Epoch: 6| Step: 5
Training loss: 2.7942452430725098
Validation loss: 2.0222831823492564

Epoch: 6| Step: 6
Training loss: 2.774811267852783
Validation loss: 2.0154330499710573

Epoch: 6| Step: 7
Training loss: 2.274144172668457
Validation loss: 2.0120590309942923

Epoch: 6| Step: 8
Training loss: 2.2437400817871094
Validation loss: 2.0023700139855825

Epoch: 6| Step: 9
Training loss: 1.607930064201355
Validation loss: 2.00004485858384

Epoch: 6| Step: 10
Training loss: 2.7596776485443115
Validation loss: 2.0004743978541386

Epoch: 6| Step: 11
Training loss: 1.7949893474578857
Validation loss: 1.9938917916308168

Epoch: 6| Step: 12
Training loss: 2.0952212810516357
Validation loss: 1.9899576710116478

Epoch: 6| Step: 13
Training loss: 2.4403185844421387
Validation loss: 1.997416155312651

Epoch: 110| Step: 0
Training loss: 2.9311459064483643
Validation loss: 1.9979229396389377

Epoch: 6| Step: 1
Training loss: 2.697449207305908
Validation loss: 1.9955405009690153

Epoch: 6| Step: 2
Training loss: 1.6931838989257812
Validation loss: 2.00079337755839

Epoch: 6| Step: 3
Training loss: 2.2249574661254883
Validation loss: 2.004153945112741

Epoch: 6| Step: 4
Training loss: 2.2623934745788574
Validation loss: 1.999743761554841

Epoch: 6| Step: 5
Training loss: 1.9262700080871582
Validation loss: 2.0022162929657967

Epoch: 6| Step: 6
Training loss: 1.6353356838226318
Validation loss: 2.0013869911111812

Epoch: 6| Step: 7
Training loss: 1.7904760837554932
Validation loss: 2.0079661710287935

Epoch: 6| Step: 8
Training loss: 2.8314061164855957
Validation loss: 2.0116371929004626

Epoch: 6| Step: 9
Training loss: 3.1910266876220703
Validation loss: 2.021678097786442

Epoch: 6| Step: 10
Training loss: 2.272498846054077
Validation loss: 2.02276034508982

Epoch: 6| Step: 11
Training loss: 2.452141761779785
Validation loss: 2.024390105278261

Epoch: 6| Step: 12
Training loss: 1.6338491439819336
Validation loss: 2.028999267085906

Epoch: 6| Step: 13
Training loss: 1.5139412879943848
Validation loss: 2.029675213239526

Epoch: 111| Step: 0
Training loss: 1.915290117263794
Validation loss: 2.0130644511151057

Epoch: 6| Step: 1
Training loss: 2.402798652648926
Validation loss: 1.9961743688070646

Epoch: 6| Step: 2
Training loss: 2.512418746948242
Validation loss: 1.9879666220757268

Epoch: 6| Step: 3
Training loss: 1.9812805652618408
Validation loss: 1.982543453093498

Epoch: 6| Step: 4
Training loss: 2.5544958114624023
Validation loss: 1.9789551740051599

Epoch: 6| Step: 5
Training loss: 2.6479122638702393
Validation loss: 1.9798844283626926

Epoch: 6| Step: 6
Training loss: 2.296381711959839
Validation loss: 1.9750167285242388

Epoch: 6| Step: 7
Training loss: 1.6459968090057373
Validation loss: 1.985861486004245

Epoch: 6| Step: 8
Training loss: 1.9311420917510986
Validation loss: 1.98849457053728

Epoch: 6| Step: 9
Training loss: 1.6882872581481934
Validation loss: 1.9959901148273098

Epoch: 6| Step: 10
Training loss: 2.5238966941833496
Validation loss: 2.0177135493165705

Epoch: 6| Step: 11
Training loss: 3.3515501022338867
Validation loss: 2.026075542614024

Epoch: 6| Step: 12
Training loss: 1.6777856349945068
Validation loss: 2.0475216975776096

Epoch: 6| Step: 13
Training loss: 2.4419498443603516
Validation loss: 2.0463481795403267

Epoch: 112| Step: 0
Training loss: 2.318589925765991
Validation loss: 2.0410720673940514

Epoch: 6| Step: 1
Training loss: 2.081894874572754
Validation loss: 2.029072142416431

Epoch: 6| Step: 2
Training loss: 2.444502592086792
Validation loss: 2.016436863971013

Epoch: 6| Step: 3
Training loss: 2.3655519485473633
Validation loss: 1.9986643765562324

Epoch: 6| Step: 4
Training loss: 1.8659658432006836
Validation loss: 2.003733547784949

Epoch: 6| Step: 5
Training loss: 2.578372001647949
Validation loss: 2.0033472661049134

Epoch: 6| Step: 6
Training loss: 2.3539814949035645
Validation loss: 2.0083867132022815

Epoch: 6| Step: 7
Training loss: 2.5341551303863525
Validation loss: 2.0047506081160678

Epoch: 6| Step: 8
Training loss: 1.931071162223816
Validation loss: 2.0174582260911182

Epoch: 6| Step: 9
Training loss: 1.8811039924621582
Validation loss: 2.0350255812368085

Epoch: 6| Step: 10
Training loss: 2.139984130859375
Validation loss: 2.0495173290211666

Epoch: 6| Step: 11
Training loss: 2.0158512592315674
Validation loss: 2.047505715841888

Epoch: 6| Step: 12
Training loss: 2.9322879314422607
Validation loss: 2.0264825256921912

Epoch: 6| Step: 13
Training loss: 1.424750804901123
Validation loss: 2.014928415257444

Epoch: 113| Step: 0
Training loss: 1.6540310382843018
Validation loss: 2.016882586222823

Epoch: 6| Step: 1
Training loss: 2.45342755317688
Validation loss: 2.008257478796026

Epoch: 6| Step: 2
Training loss: 2.5154924392700195
Validation loss: 1.9953837907442482

Epoch: 6| Step: 3
Training loss: 2.2251296043395996
Validation loss: 1.9950641816662205

Epoch: 6| Step: 4
Training loss: 2.130354881286621
Validation loss: 1.9975479341322375

Epoch: 6| Step: 5
Training loss: 2.4429054260253906
Validation loss: 2.000804998541391

Epoch: 6| Step: 6
Training loss: 2.355377435684204
Validation loss: 2.0132803763112714

Epoch: 6| Step: 7
Training loss: 2.247572898864746
Validation loss: 2.030040640984812

Epoch: 6| Step: 8
Training loss: 1.6624767780303955
Validation loss: 2.0431619895401822

Epoch: 6| Step: 9
Training loss: 2.261460781097412
Validation loss: 2.0381842018455587

Epoch: 6| Step: 10
Training loss: 2.2269952297210693
Validation loss: 2.0179924311176425

Epoch: 6| Step: 11
Training loss: 2.167712688446045
Validation loss: 2.0067986108923472

Epoch: 6| Step: 12
Training loss: 2.7991909980773926
Validation loss: 1.9845199841325

Epoch: 6| Step: 13
Training loss: 2.353457450866699
Validation loss: 1.980981380708756

Epoch: 114| Step: 0
Training loss: 2.935002565383911
Validation loss: 1.9795534623566495

Epoch: 6| Step: 1
Training loss: 2.5477161407470703
Validation loss: 1.9719333699954453

Epoch: 6| Step: 2
Training loss: 1.8853555917739868
Validation loss: 1.9798448611331243

Epoch: 6| Step: 3
Training loss: 2.195770263671875
Validation loss: 1.9839778715564358

Epoch: 6| Step: 4
Training loss: 2.2413039207458496
Validation loss: 1.9839744567871094

Epoch: 6| Step: 5
Training loss: 3.002406120300293
Validation loss: 1.994261384010315

Epoch: 6| Step: 6
Training loss: 1.4997670650482178
Validation loss: 2.002714075067992

Epoch: 6| Step: 7
Training loss: 2.305576801300049
Validation loss: 1.9904960688724314

Epoch: 6| Step: 8
Training loss: 2.1577324867248535
Validation loss: 2.001447077720396

Epoch: 6| Step: 9
Training loss: 2.3446245193481445
Validation loss: 1.9977614366880028

Epoch: 6| Step: 10
Training loss: 2.142068862915039
Validation loss: 1.9890873970523957

Epoch: 6| Step: 11
Training loss: 1.7109403610229492
Validation loss: 1.988369652020034

Epoch: 6| Step: 12
Training loss: 1.9043192863464355
Validation loss: 1.9832024061551659

Epoch: 6| Step: 13
Training loss: 2.137977123260498
Validation loss: 1.9775126941742436

Epoch: 115| Step: 0
Training loss: 1.8983473777770996
Validation loss: 1.9812814830451884

Epoch: 6| Step: 1
Training loss: 2.3921360969543457
Validation loss: 1.969811821496615

Epoch: 6| Step: 2
Training loss: 2.4056315422058105
Validation loss: 1.9699124290097145

Epoch: 6| Step: 3
Training loss: 1.8934037685394287
Validation loss: 1.975668607219573

Epoch: 6| Step: 4
Training loss: 2.338590383529663
Validation loss: 1.9881609255267727

Epoch: 6| Step: 5
Training loss: 2.005000591278076
Validation loss: 1.9929350806820778

Epoch: 6| Step: 6
Training loss: 2.5489468574523926
Validation loss: 1.9932037450933968

Epoch: 6| Step: 7
Training loss: 2.4395318031311035
Validation loss: 1.9857994741009128

Epoch: 6| Step: 8
Training loss: 1.9227650165557861
Validation loss: 1.9829227924346924

Epoch: 6| Step: 9
Training loss: 2.274191379547119
Validation loss: 1.9844488892503964

Epoch: 6| Step: 10
Training loss: 2.7619781494140625
Validation loss: 1.9847578540925057

Epoch: 6| Step: 11
Training loss: 1.7087482213974
Validation loss: 1.9913126178967056

Epoch: 6| Step: 12
Training loss: 2.455139636993408
Validation loss: 1.99072217172192

Epoch: 6| Step: 13
Training loss: 1.5808476209640503
Validation loss: 1.9901634749545847

Epoch: 116| Step: 0
Training loss: 1.887779951095581
Validation loss: 1.9973355018964378

Epoch: 6| Step: 1
Training loss: 2.037059783935547
Validation loss: 1.9992074069156442

Epoch: 6| Step: 2
Training loss: 1.8784935474395752
Validation loss: 2.002733222899898

Epoch: 6| Step: 3
Training loss: 2.210653781890869
Validation loss: 2.0047690419740576

Epoch: 6| Step: 4
Training loss: 2.218768835067749
Validation loss: 1.995147635859828

Epoch: 6| Step: 5
Training loss: 2.3404269218444824
Validation loss: 1.978387168658677

Epoch: 6| Step: 6
Training loss: 2.308312177658081
Validation loss: 1.9814047044323337

Epoch: 6| Step: 7
Training loss: 2.4200634956359863
Validation loss: 1.9791337956664383

Epoch: 6| Step: 8
Training loss: 2.843228578567505
Validation loss: 1.9757506129562215

Epoch: 6| Step: 9
Training loss: 2.4450807571411133
Validation loss: 1.9852575781524822

Epoch: 6| Step: 10
Training loss: 2.0851426124572754
Validation loss: 1.978249349901753

Epoch: 6| Step: 11
Training loss: 2.5199673175811768
Validation loss: 1.9790023706292594

Epoch: 6| Step: 12
Training loss: 1.4313870668411255
Validation loss: 1.9794327264191003

Epoch: 6| Step: 13
Training loss: 2.228170156478882
Validation loss: 1.9902717092985749

Epoch: 117| Step: 0
Training loss: 2.732222318649292
Validation loss: 2.010056185465987

Epoch: 6| Step: 1
Training loss: 1.5721564292907715
Validation loss: 2.044954522963493

Epoch: 6| Step: 2
Training loss: 2.289638042449951
Validation loss: 2.064880924840127

Epoch: 6| Step: 3
Training loss: 2.084595203399658
Validation loss: 2.0933276812235513

Epoch: 6| Step: 4
Training loss: 3.0838871002197266
Validation loss: 2.108750133104222

Epoch: 6| Step: 5
Training loss: 1.4190900325775146
Validation loss: 2.09459146248397

Epoch: 6| Step: 6
Training loss: 2.6321263313293457
Validation loss: 2.0400896226206133

Epoch: 6| Step: 7
Training loss: 1.3419525623321533
Validation loss: 2.0201549324938046

Epoch: 6| Step: 8
Training loss: 2.6384434700012207
Validation loss: 1.9902442411709858

Epoch: 6| Step: 9
Training loss: 1.4143157005310059
Validation loss: 2.005933351414178

Epoch: 6| Step: 10
Training loss: 2.549591064453125
Validation loss: 2.0314439394140757

Epoch: 6| Step: 11
Training loss: 2.1530377864837646
Validation loss: 2.058880659841722

Epoch: 6| Step: 12
Training loss: 3.478461265563965
Validation loss: 2.073068981529564

Epoch: 6| Step: 13
Training loss: 1.9747958183288574
Validation loss: 2.0435091859550885

Epoch: 118| Step: 0
Training loss: 2.2839810848236084
Validation loss: 2.0343561672395274

Epoch: 6| Step: 1
Training loss: 1.7400104999542236
Validation loss: 2.030071746918463

Epoch: 6| Step: 2
Training loss: 2.1832799911499023
Validation loss: 2.0185551745917207

Epoch: 6| Step: 3
Training loss: 2.6118040084838867
Validation loss: 2.019803959836242

Epoch: 6| Step: 4
Training loss: 2.1179256439208984
Validation loss: 2.0286460999519593

Epoch: 6| Step: 5
Training loss: 1.9632294178009033
Validation loss: 2.0523083645810365

Epoch: 6| Step: 6
Training loss: 1.8666551113128662
Validation loss: 2.0414294312077184

Epoch: 6| Step: 7
Training loss: 2.0372540950775146
Validation loss: 2.0422831658394105

Epoch: 6| Step: 8
Training loss: 2.8101344108581543
Validation loss: 2.0122478085179485

Epoch: 6| Step: 9
Training loss: 3.314680576324463
Validation loss: 1.988628359251125

Epoch: 6| Step: 10
Training loss: 1.7547810077667236
Validation loss: 1.9850435372321837

Epoch: 6| Step: 11
Training loss: 2.2938554286956787
Validation loss: 1.9838961080838275

Epoch: 6| Step: 12
Training loss: 2.0946261882781982
Validation loss: 1.9954879117268387

Epoch: 6| Step: 13
Training loss: 2.190535306930542
Validation loss: 1.9976515564867245

Epoch: 119| Step: 0
Training loss: 2.30377197265625
Validation loss: 1.9964208013267928

Epoch: 6| Step: 1
Training loss: 2.5666275024414062
Validation loss: 1.986289132025934

Epoch: 6| Step: 2
Training loss: 1.940428614616394
Validation loss: 1.9785319630817702

Epoch: 6| Step: 3
Training loss: 2.747706413269043
Validation loss: 1.974317140476678

Epoch: 6| Step: 4
Training loss: 2.194923162460327
Validation loss: 1.9724524277512745

Epoch: 6| Step: 5
Training loss: 1.5002176761627197
Validation loss: 1.9743704078018025

Epoch: 6| Step: 6
Training loss: 2.186427116394043
Validation loss: 1.990129634898196

Epoch: 6| Step: 7
Training loss: 2.7766928672790527
Validation loss: 1.9977514359258837

Epoch: 6| Step: 8
Training loss: 1.8670989274978638
Validation loss: 2.01716455464722

Epoch: 6| Step: 9
Training loss: 2.4713218212127686
Validation loss: 2.0084914327949606

Epoch: 6| Step: 10
Training loss: 1.6184413433074951
Validation loss: 2.008706272289317

Epoch: 6| Step: 11
Training loss: 2.6496033668518066
Validation loss: 1.995242812300241

Epoch: 6| Step: 12
Training loss: 2.2717456817626953
Validation loss: 1.972595440444126

Epoch: 6| Step: 13
Training loss: 2.0243146419525146
Validation loss: 1.9792489723492694

Epoch: 120| Step: 0
Training loss: 1.653708815574646
Validation loss: 1.9819342115873932

Epoch: 6| Step: 1
Training loss: 1.5799976587295532
Validation loss: 1.9840063177129275

Epoch: 6| Step: 2
Training loss: 3.005500316619873
Validation loss: 1.999918818473816

Epoch: 6| Step: 3
Training loss: 2.4311022758483887
Validation loss: 2.003774986472181

Epoch: 6| Step: 4
Training loss: 2.65641450881958
Validation loss: 2.021187383641479

Epoch: 6| Step: 5
Training loss: 2.2367379665374756
Validation loss: 2.009351150963896

Epoch: 6| Step: 6
Training loss: 2.227618932723999
Validation loss: 2.0055809995179534

Epoch: 6| Step: 7
Training loss: 1.8889602422714233
Validation loss: 1.9929572664281374

Epoch: 6| Step: 8
Training loss: 2.206559181213379
Validation loss: 1.9856434406772736

Epoch: 6| Step: 9
Training loss: 1.7292029857635498
Validation loss: 1.976313442312261

Epoch: 6| Step: 10
Training loss: 2.8981142044067383
Validation loss: 1.9944277476238947

Epoch: 6| Step: 11
Training loss: 2.4850411415100098
Validation loss: 2.007336019187845

Epoch: 6| Step: 12
Training loss: 1.866442084312439
Validation loss: 2.0241040363106677

Epoch: 6| Step: 13
Training loss: 2.9974007606506348
Validation loss: 2.0318335307541715

Epoch: 121| Step: 0
Training loss: 2.310654640197754
Validation loss: 2.0334803519710416

Epoch: 6| Step: 1
Training loss: 2.1733391284942627
Validation loss: 2.047766318885229

Epoch: 6| Step: 2
Training loss: 1.4671452045440674
Validation loss: 2.0371095980367353

Epoch: 6| Step: 3
Training loss: 2.491209030151367
Validation loss: 2.0054009755452475

Epoch: 6| Step: 4
Training loss: 1.4549585580825806
Validation loss: 1.9930078291123914

Epoch: 6| Step: 5
Training loss: 1.865551471710205
Validation loss: 1.9788300119420534

Epoch: 6| Step: 6
Training loss: 2.4019722938537598
Validation loss: 1.9938912468571817

Epoch: 6| Step: 7
Training loss: 2.299182415008545
Validation loss: 2.006131734899295

Epoch: 6| Step: 8
Training loss: 2.5316028594970703
Validation loss: 2.008782035561018

Epoch: 6| Step: 9
Training loss: 2.1562299728393555
Validation loss: 2.011396587535899

Epoch: 6| Step: 10
Training loss: 2.2832894325256348
Validation loss: 2.040842999694168

Epoch: 6| Step: 11
Training loss: 2.2568540573120117
Validation loss: 2.037086868798861

Epoch: 6| Step: 12
Training loss: 2.5203311443328857
Validation loss: 2.0434776147206626

Epoch: 6| Step: 13
Training loss: 3.00754714012146
Validation loss: 2.0623854911455544

Epoch: 122| Step: 0
Training loss: 2.3197126388549805
Validation loss: 2.056625609756798

Epoch: 6| Step: 1
Training loss: 2.643277406692505
Validation loss: 2.035877404674407

Epoch: 6| Step: 2
Training loss: 1.7497321367263794
Validation loss: 2.017878382436691

Epoch: 6| Step: 3
Training loss: 2.5755484104156494
Validation loss: 2.008094363315131

Epoch: 6| Step: 4
Training loss: 2.439478635787964
Validation loss: 2.0079676797313075

Epoch: 6| Step: 5
Training loss: 2.075626850128174
Validation loss: 2.0121815576348254

Epoch: 6| Step: 6
Training loss: 1.9554247856140137
Validation loss: 2.0263255462851575

Epoch: 6| Step: 7
Training loss: 2.4425199031829834
Validation loss: 2.0385659868999193

Epoch: 6| Step: 8
Training loss: 1.8932572603225708
Validation loss: 2.0351641831859464

Epoch: 6| Step: 9
Training loss: 1.8518610000610352
Validation loss: 2.026095631302044

Epoch: 6| Step: 10
Training loss: 2.006659984588623
Validation loss: 2.013625737159483

Epoch: 6| Step: 11
Training loss: 2.1383399963378906
Validation loss: 2.0113584200541177

Epoch: 6| Step: 12
Training loss: 2.4631872177124023
Validation loss: 2.01956658850434

Epoch: 6| Step: 13
Training loss: 2.6475653648376465
Validation loss: 2.0140452807949436

Epoch: 123| Step: 0
Training loss: 1.902418613433838
Validation loss: 1.9980699477657196

Epoch: 6| Step: 1
Training loss: 2.1999728679656982
Validation loss: 1.9902883703990648

Epoch: 6| Step: 2
Training loss: 2.1980037689208984
Validation loss: 1.9848877947817567

Epoch: 6| Step: 3
Training loss: 1.4495151042938232
Validation loss: 1.9730252437694098

Epoch: 6| Step: 4
Training loss: 2.383054494857788
Validation loss: 1.9712766601193337

Epoch: 6| Step: 5
Training loss: 1.594316840171814
Validation loss: 1.9639873902002971

Epoch: 6| Step: 6
Training loss: 1.567680835723877
Validation loss: 1.9594825865120016

Epoch: 6| Step: 7
Training loss: 2.573777198791504
Validation loss: 1.955838156002824

Epoch: 6| Step: 8
Training loss: 2.461998224258423
Validation loss: 1.9609307191705192

Epoch: 6| Step: 9
Training loss: 2.188870668411255
Validation loss: 1.9579846384704753

Epoch: 6| Step: 10
Training loss: 3.519896984100342
Validation loss: 1.9566526682146135

Epoch: 6| Step: 11
Training loss: 1.7319811582565308
Validation loss: 1.9561572203072168

Epoch: 6| Step: 12
Training loss: 2.370851516723633
Validation loss: 1.9551937477563017

Epoch: 6| Step: 13
Training loss: 2.343945264816284
Validation loss: 1.9645545738999561

Epoch: 124| Step: 0
Training loss: 2.274606704711914
Validation loss: 1.9646223360492336

Epoch: 6| Step: 1
Training loss: 2.0462241172790527
Validation loss: 1.97023864458966

Epoch: 6| Step: 2
Training loss: 1.3535444736480713
Validation loss: 1.9722456419339744

Epoch: 6| Step: 3
Training loss: 2.3741133213043213
Validation loss: 1.977610558591863

Epoch: 6| Step: 4
Training loss: 2.7499446868896484
Validation loss: 1.979929304892017

Epoch: 6| Step: 5
Training loss: 2.3747262954711914
Validation loss: 1.9824084351139684

Epoch: 6| Step: 6
Training loss: 1.56855309009552
Validation loss: 1.9852832850589548

Epoch: 6| Step: 7
Training loss: 2.190825939178467
Validation loss: 1.9815379445270827

Epoch: 6| Step: 8
Training loss: 2.149171829223633
Validation loss: 1.9726931728342527

Epoch: 6| Step: 9
Training loss: 1.7110180854797363
Validation loss: 1.9769816026892713

Epoch: 6| Step: 10
Training loss: 2.655670166015625
Validation loss: 1.9753849557650986

Epoch: 6| Step: 11
Training loss: 2.168959140777588
Validation loss: 1.9895078418075398

Epoch: 6| Step: 12
Training loss: 2.405320644378662
Validation loss: 1.9976854990887385

Epoch: 6| Step: 13
Training loss: 2.459209442138672
Validation loss: 2.0018644666159027

Epoch: 125| Step: 0
Training loss: 1.6974366903305054
Validation loss: 2.006486767081804

Epoch: 6| Step: 1
Training loss: 1.7552623748779297
Validation loss: 2.0089661716133036

Epoch: 6| Step: 2
Training loss: 1.5379104614257812
Validation loss: 2.025937754620788

Epoch: 6| Step: 3
Training loss: 2.584219455718994
Validation loss: 2.0170694922888153

Epoch: 6| Step: 4
Training loss: 2.4897942543029785
Validation loss: 2.0093298958193873

Epoch: 6| Step: 5
Training loss: 2.9130771160125732
Validation loss: 2.0062247322451685

Epoch: 6| Step: 6
Training loss: 2.7954390048980713
Validation loss: 1.9960134516480148

Epoch: 6| Step: 7
Training loss: 2.3783607482910156
Validation loss: 2.018735603619647

Epoch: 6| Step: 8
Training loss: 2.1711738109588623
Validation loss: 2.008601301459856

Epoch: 6| Step: 9
Training loss: 2.02618670463562
Validation loss: 2.0158741448515203

Epoch: 6| Step: 10
Training loss: 2.374978542327881
Validation loss: 2.0173966038611626

Epoch: 6| Step: 11
Training loss: 2.1951913833618164
Validation loss: 2.0150742453913533

Epoch: 6| Step: 12
Training loss: 1.5660415887832642
Validation loss: 2.0037851359254573

Epoch: 6| Step: 13
Training loss: 1.4868136644363403
Validation loss: 1.9834811046559324

Epoch: 126| Step: 0
Training loss: 1.470874547958374
Validation loss: 1.9815464993958831

Epoch: 6| Step: 1
Training loss: 2.2641234397888184
Validation loss: 1.9824350841583744

Epoch: 6| Step: 2
Training loss: 1.7431590557098389
Validation loss: 1.9741024253188924

Epoch: 6| Step: 3
Training loss: 2.58469820022583
Validation loss: 1.9655191026708132

Epoch: 6| Step: 4
Training loss: 2.819587469100952
Validation loss: 1.96422666118991

Epoch: 6| Step: 5
Training loss: 1.885276436805725
Validation loss: 1.960079526388517

Epoch: 6| Step: 6
Training loss: 1.6177873611450195
Validation loss: 1.9549916764741302

Epoch: 6| Step: 7
Training loss: 2.3000383377075195
Validation loss: 1.9671586700665054

Epoch: 6| Step: 8
Training loss: 2.1633949279785156
Validation loss: 1.9861079364694574

Epoch: 6| Step: 9
Training loss: 2.8640151023864746
Validation loss: 2.002531954037246

Epoch: 6| Step: 10
Training loss: 1.8075108528137207
Validation loss: 2.0294499499823457

Epoch: 6| Step: 11
Training loss: 1.7542983293533325
Validation loss: 2.0471956704252507

Epoch: 6| Step: 12
Training loss: 2.5945730209350586
Validation loss: 2.0716750878159718

Epoch: 6| Step: 13
Training loss: 2.4865760803222656
Validation loss: 2.072139738708414

Epoch: 127| Step: 0
Training loss: 2.4120373725891113
Validation loss: 2.0522363737065303

Epoch: 6| Step: 1
Training loss: 2.459162712097168
Validation loss: 2.036279568108179

Epoch: 6| Step: 2
Training loss: 1.317144751548767
Validation loss: 1.9882222683198991

Epoch: 6| Step: 3
Training loss: 1.9660717248916626
Validation loss: 1.9632655676975046

Epoch: 6| Step: 4
Training loss: 1.8227622509002686
Validation loss: 1.9743730534789383

Epoch: 6| Step: 5
Training loss: 2.361168622970581
Validation loss: 1.98687574683979

Epoch: 6| Step: 6
Training loss: 1.6648396253585815
Validation loss: 1.9966543412977649

Epoch: 6| Step: 7
Training loss: 3.3346893787384033
Validation loss: 1.9911331156248688

Epoch: 6| Step: 8
Training loss: 2.3330159187316895
Validation loss: 1.9949422369721115

Epoch: 6| Step: 9
Training loss: 1.4957969188690186
Validation loss: 1.9676776265585294

Epoch: 6| Step: 10
Training loss: 2.402406930923462
Validation loss: 1.9652392530954013

Epoch: 6| Step: 11
Training loss: 2.2339353561401367
Validation loss: 1.9563261437159714

Epoch: 6| Step: 12
Training loss: 2.2117252349853516
Validation loss: 1.9665014038803756

Epoch: 6| Step: 13
Training loss: 2.3820910453796387
Validation loss: 1.9670799496353313

Epoch: 128| Step: 0
Training loss: 1.8778738975524902
Validation loss: 1.9786380362767044

Epoch: 6| Step: 1
Training loss: 1.8142400979995728
Validation loss: 1.981231245943295

Epoch: 6| Step: 2
Training loss: 2.4262263774871826
Validation loss: 1.9811163384427306

Epoch: 6| Step: 3
Training loss: 2.4882748126983643
Validation loss: 1.9750525912930887

Epoch: 6| Step: 4
Training loss: 2.083791732788086
Validation loss: 1.9694273394923056

Epoch: 6| Step: 5
Training loss: 2.339116096496582
Validation loss: 1.974257653759372

Epoch: 6| Step: 6
Training loss: 2.2608542442321777
Validation loss: 1.9820373865865892

Epoch: 6| Step: 7
Training loss: 2.0726735591888428
Validation loss: 2.004514512195382

Epoch: 6| Step: 8
Training loss: 2.8184285163879395
Validation loss: 1.993134105077354

Epoch: 6| Step: 9
Training loss: 1.27516770362854
Validation loss: 2.007508111256425

Epoch: 6| Step: 10
Training loss: 1.6362416744232178
Validation loss: 2.0085664615836194

Epoch: 6| Step: 11
Training loss: 2.5397021770477295
Validation loss: 2.0154811489966606

Epoch: 6| Step: 12
Training loss: 2.1008360385894775
Validation loss: 2.0040236801229496

Epoch: 6| Step: 13
Training loss: 1.8076348304748535
Validation loss: 2.0157222363256637

Epoch: 129| Step: 0
Training loss: 3.0584402084350586
Validation loss: 1.990211816244228

Epoch: 6| Step: 1
Training loss: 1.8259871006011963
Validation loss: 1.9769668425283125

Epoch: 6| Step: 2
Training loss: 2.4176673889160156
Validation loss: 1.9835071935448596

Epoch: 6| Step: 3
Training loss: 1.7164613008499146
Validation loss: 1.9722833633422852

Epoch: 6| Step: 4
Training loss: 2.29093337059021
Validation loss: 1.956922750319204

Epoch: 6| Step: 5
Training loss: 2.2360167503356934
Validation loss: 1.9449093111099736

Epoch: 6| Step: 6
Training loss: 1.7094637155532837
Validation loss: 1.9637012584235078

Epoch: 6| Step: 7
Training loss: 2.43978214263916
Validation loss: 1.9555388086585588

Epoch: 6| Step: 8
Training loss: 1.0745031833648682
Validation loss: 1.9603620652229554

Epoch: 6| Step: 9
Training loss: 2.532189130783081
Validation loss: 1.9595565411352343

Epoch: 6| Step: 10
Training loss: 1.5804693698883057
Validation loss: 1.9635789791742961

Epoch: 6| Step: 11
Training loss: 2.1371264457702637
Validation loss: 1.9612331339108047

Epoch: 6| Step: 12
Training loss: 2.2262473106384277
Validation loss: 1.9707240391803045

Epoch: 6| Step: 13
Training loss: 2.5076146125793457
Validation loss: 1.9898074262885637

Epoch: 130| Step: 0
Training loss: 1.8586692810058594
Validation loss: 2.018968436025804

Epoch: 6| Step: 1
Training loss: 1.778857707977295
Validation loss: 2.020350589547106

Epoch: 6| Step: 2
Training loss: 2.2500557899475098
Validation loss: 2.00006849791414

Epoch: 6| Step: 3
Training loss: 1.5797982215881348
Validation loss: 1.984593117108909

Epoch: 6| Step: 4
Training loss: 2.679443359375
Validation loss: 1.968580784336213

Epoch: 6| Step: 5
Training loss: 1.7226319313049316
Validation loss: 1.9733919699986775

Epoch: 6| Step: 6
Training loss: 2.47116756439209
Validation loss: 1.9856250645011984

Epoch: 6| Step: 7
Training loss: 2.0352258682250977
Validation loss: 1.9957232500917168

Epoch: 6| Step: 8
Training loss: 3.0586256980895996
Validation loss: 2.0096690244572137

Epoch: 6| Step: 9
Training loss: 2.559323787689209
Validation loss: 2.0362783388424943

Epoch: 6| Step: 10
Training loss: 2.2477385997772217
Validation loss: 2.025257605378346

Epoch: 6| Step: 11
Training loss: 1.8346638679504395
Validation loss: 2.0116352317153767

Epoch: 6| Step: 12
Training loss: 2.4112210273742676
Validation loss: 1.9958008361119095

Epoch: 6| Step: 13
Training loss: 1.1842045783996582
Validation loss: 1.9929414769654632

Epoch: 131| Step: 0
Training loss: 1.9684081077575684
Validation loss: 1.9839247170314993

Epoch: 6| Step: 1
Training loss: 2.5555453300476074
Validation loss: 1.97867589740343

Epoch: 6| Step: 2
Training loss: 2.297252655029297
Validation loss: 1.9864657899384857

Epoch: 6| Step: 3
Training loss: 2.0764212608337402
Validation loss: 1.997073140195621

Epoch: 6| Step: 4
Training loss: 1.6787967681884766
Validation loss: 2.0063048767787155

Epoch: 6| Step: 5
Training loss: 2.046565532684326
Validation loss: 2.008015964620857

Epoch: 6| Step: 6
Training loss: 1.8339194059371948
Validation loss: 1.9766346241838189

Epoch: 6| Step: 7
Training loss: 2.6398558616638184
Validation loss: 1.9652599929481425

Epoch: 6| Step: 8
Training loss: 1.7559168338775635
Validation loss: 1.9691266577730897

Epoch: 6| Step: 9
Training loss: 2.283329725265503
Validation loss: 1.9744376649138748

Epoch: 6| Step: 10
Training loss: 1.985633134841919
Validation loss: 1.980364825135918

Epoch: 6| Step: 11
Training loss: 2.316927433013916
Validation loss: 1.955173292467671

Epoch: 6| Step: 12
Training loss: 2.217137098312378
Validation loss: 1.947211398873278

Epoch: 6| Step: 13
Training loss: 2.4554405212402344
Validation loss: 1.9449855601915749

Epoch: 132| Step: 0
Training loss: 2.516871452331543
Validation loss: 1.981519240205006

Epoch: 6| Step: 1
Training loss: 1.8684980869293213
Validation loss: 2.0224299328301543

Epoch: 6| Step: 2
Training loss: 2.070460319519043
Validation loss: 2.0571244455152944

Epoch: 6| Step: 3
Training loss: 2.75828218460083
Validation loss: 2.0433740679935744

Epoch: 6| Step: 4
Training loss: 2.2836928367614746
Validation loss: 2.0094862702072307

Epoch: 6| Step: 5
Training loss: 2.4832539558410645
Validation loss: 2.0003179298934115

Epoch: 6| Step: 6
Training loss: 2.5068671703338623
Validation loss: 1.9833047082347255

Epoch: 6| Step: 7
Training loss: 2.072483539581299
Validation loss: 1.963811371916084

Epoch: 6| Step: 8
Training loss: 2.9091763496398926
Validation loss: 1.9581122680376934

Epoch: 6| Step: 9
Training loss: 1.3857996463775635
Validation loss: 1.9722519933536489

Epoch: 6| Step: 10
Training loss: 2.3534719944000244
Validation loss: 1.9689064102788125

Epoch: 6| Step: 11
Training loss: 2.109549045562744
Validation loss: 1.9732705521327194

Epoch: 6| Step: 12
Training loss: 1.3256646394729614
Validation loss: 1.97221290808852

Epoch: 6| Step: 13
Training loss: 1.9471206665039062
Validation loss: 1.957603773763103

Epoch: 133| Step: 0
Training loss: 2.448838233947754
Validation loss: 1.9506635640257148

Epoch: 6| Step: 1
Training loss: 2.8780412673950195
Validation loss: 1.956295645365151

Epoch: 6| Step: 2
Training loss: 2.309626579284668
Validation loss: 1.974914885336353

Epoch: 6| Step: 3
Training loss: 1.896483302116394
Validation loss: 1.9975236615827006

Epoch: 6| Step: 4
Training loss: 1.3570730686187744
Validation loss: 1.984235191857943

Epoch: 6| Step: 5
Training loss: 2.307016134262085
Validation loss: 1.9876893976683259

Epoch: 6| Step: 6
Training loss: 2.409858226776123
Validation loss: 1.984881567698653

Epoch: 6| Step: 7
Training loss: 2.146838665008545
Validation loss: 1.9782549796565887

Epoch: 6| Step: 8
Training loss: 1.9444339275360107
Validation loss: 1.982173745350171

Epoch: 6| Step: 9
Training loss: 2.5555193424224854
Validation loss: 1.9767662299576627

Epoch: 6| Step: 10
Training loss: 1.9552119970321655
Validation loss: 1.9894804928892402

Epoch: 6| Step: 11
Training loss: 2.184454917907715
Validation loss: 1.9840492394662672

Epoch: 6| Step: 12
Training loss: 1.4603477716445923
Validation loss: 1.9947702397582352

Epoch: 6| Step: 13
Training loss: 1.9693074226379395
Validation loss: 2.0053518741361556

Epoch: 134| Step: 0
Training loss: 2.6341028213500977
Validation loss: 1.9935031270468107

Epoch: 6| Step: 1
Training loss: 2.2714896202087402
Validation loss: 1.9716629879449004

Epoch: 6| Step: 2
Training loss: 0.9352638721466064
Validation loss: 1.971934772306873

Epoch: 6| Step: 3
Training loss: 2.0781097412109375
Validation loss: 1.9804638508827455

Epoch: 6| Step: 4
Training loss: 2.144331693649292
Validation loss: 1.9726211717051845

Epoch: 6| Step: 5
Training loss: 2.6512436866760254
Validation loss: 1.9626514488650906

Epoch: 6| Step: 6
Training loss: 2.095641851425171
Validation loss: 1.9604317667663738

Epoch: 6| Step: 7
Training loss: 1.9940338134765625
Validation loss: 1.962375001240802

Epoch: 6| Step: 8
Training loss: 2.0226845741271973
Validation loss: 1.958625296110748

Epoch: 6| Step: 9
Training loss: 1.6962727308273315
Validation loss: 1.9405049111253472

Epoch: 6| Step: 10
Training loss: 3.024000883102417
Validation loss: 1.9522534365295081

Epoch: 6| Step: 11
Training loss: 1.7273036241531372
Validation loss: 1.947847839324705

Epoch: 6| Step: 12
Training loss: 1.7022100687026978
Validation loss: 1.9574542058411466

Epoch: 6| Step: 13
Training loss: 2.430730104446411
Validation loss: 1.964565291199633

Epoch: 135| Step: 0
Training loss: 1.6536037921905518
Validation loss: 1.9582464361703524

Epoch: 6| Step: 1
Training loss: 1.5299301147460938
Validation loss: 1.9520137668937765

Epoch: 6| Step: 2
Training loss: 2.369051933288574
Validation loss: 1.9363079032590311

Epoch: 6| Step: 3
Training loss: 2.124783515930176
Validation loss: 1.9457144455243183

Epoch: 6| Step: 4
Training loss: 1.9060287475585938
Validation loss: 1.9483972775038851

Epoch: 6| Step: 5
Training loss: 2.443171977996826
Validation loss: 1.9623955603568786

Epoch: 6| Step: 6
Training loss: 2.5853590965270996
Validation loss: 1.9528078571442635

Epoch: 6| Step: 7
Training loss: 2.040151834487915
Validation loss: 1.9579665930040422

Epoch: 6| Step: 8
Training loss: 2.596400499343872
Validation loss: 1.9513701918304607

Epoch: 6| Step: 9
Training loss: 2.545043468475342
Validation loss: 1.9422360004917267

Epoch: 6| Step: 10
Training loss: 2.0404531955718994
Validation loss: 1.9421684049790906

Epoch: 6| Step: 11
Training loss: 1.554286241531372
Validation loss: 1.9344740913760277

Epoch: 6| Step: 12
Training loss: 2.0565600395202637
Validation loss: 1.9298209144223122

Epoch: 6| Step: 13
Training loss: 1.5693410634994507
Validation loss: 1.936539723027137

Epoch: 136| Step: 0
Training loss: 2.5447936058044434
Validation loss: 1.9405801398779756

Epoch: 6| Step: 1
Training loss: 2.5190749168395996
Validation loss: 1.9434881723055275

Epoch: 6| Step: 2
Training loss: 2.904381275177002
Validation loss: 1.941938397704914

Epoch: 6| Step: 3
Training loss: 1.7760756015777588
Validation loss: 1.9450223804802023

Epoch: 6| Step: 4
Training loss: 1.6922422647476196
Validation loss: 1.946211035533618

Epoch: 6| Step: 5
Training loss: 2.543125629425049
Validation loss: 1.950001093649095

Epoch: 6| Step: 6
Training loss: 1.8610386848449707
Validation loss: 1.9607066428789528

Epoch: 6| Step: 7
Training loss: 2.3684167861938477
Validation loss: 1.941165126780028

Epoch: 6| Step: 8
Training loss: 2.0323541164398193
Validation loss: 1.9534117111595728

Epoch: 6| Step: 9
Training loss: 1.4908323287963867
Validation loss: 1.9586556124430832

Epoch: 6| Step: 10
Training loss: 1.9227981567382812
Validation loss: 1.9654558781654603

Epoch: 6| Step: 11
Training loss: 1.934424877166748
Validation loss: 1.9727635409242363

Epoch: 6| Step: 12
Training loss: 1.2909643650054932
Validation loss: 1.9706038633982341

Epoch: 6| Step: 13
Training loss: 2.0736684799194336
Validation loss: 1.9623813321513515

Epoch: 137| Step: 0
Training loss: 0.9811290502548218
Validation loss: 1.9629409595202374

Epoch: 6| Step: 1
Training loss: 2.225325584411621
Validation loss: 1.9525610605875652

Epoch: 6| Step: 2
Training loss: 2.8428328037261963
Validation loss: 1.9540136129625383

Epoch: 6| Step: 3
Training loss: 2.2086586952209473
Validation loss: 1.9504104109220608

Epoch: 6| Step: 4
Training loss: 2.3112380504608154
Validation loss: 1.9543645715200773

Epoch: 6| Step: 5
Training loss: 2.502732992172241
Validation loss: 1.9623995980908793

Epoch: 6| Step: 6
Training loss: 2.2659966945648193
Validation loss: 1.9618282689843127

Epoch: 6| Step: 7
Training loss: 2.2824184894561768
Validation loss: 1.950892815025904

Epoch: 6| Step: 8
Training loss: 1.8825936317443848
Validation loss: 1.941904934503699

Epoch: 6| Step: 9
Training loss: 1.7578296661376953
Validation loss: 1.9524754042266517

Epoch: 6| Step: 10
Training loss: 1.616478443145752
Validation loss: 1.964528997739156

Epoch: 6| Step: 11
Training loss: 2.075338363647461
Validation loss: 1.964911776204263

Epoch: 6| Step: 12
Training loss: 2.020453453063965
Validation loss: 1.9643200071909095

Epoch: 6| Step: 13
Training loss: 1.880751132965088
Validation loss: 1.9587276340812765

Epoch: 138| Step: 0
Training loss: 2.334324836730957
Validation loss: 1.961898173055341

Epoch: 6| Step: 1
Training loss: 2.1792852878570557
Validation loss: 1.978625992292999

Epoch: 6| Step: 2
Training loss: 1.622178316116333
Validation loss: 1.9814146821216871

Epoch: 6| Step: 3
Training loss: 2.0103092193603516
Validation loss: 1.9826211878048476

Epoch: 6| Step: 4
Training loss: 1.782101035118103
Validation loss: 1.971475144868256

Epoch: 6| Step: 5
Training loss: 2.158975124359131
Validation loss: 1.9642867298536404

Epoch: 6| Step: 6
Training loss: 1.786938190460205
Validation loss: 1.9569101782255276

Epoch: 6| Step: 7
Training loss: 1.1889619827270508
Validation loss: 1.967687729866274

Epoch: 6| Step: 8
Training loss: 2.365173578262329
Validation loss: 1.9829421325396466

Epoch: 6| Step: 9
Training loss: 1.978196382522583
Validation loss: 2.0085393613384617

Epoch: 6| Step: 10
Training loss: 1.3252840042114258
Validation loss: 2.0337329538919593

Epoch: 6| Step: 11
Training loss: 2.943105697631836
Validation loss: 2.038913692197492

Epoch: 6| Step: 12
Training loss: 3.0131969451904297
Validation loss: 2.0306349826115433

Epoch: 6| Step: 13
Training loss: 2.0061330795288086
Validation loss: 2.0092338746593845

Epoch: 139| Step: 0
Training loss: 2.111665725708008
Validation loss: 2.009026288986206

Epoch: 6| Step: 1
Training loss: 2.758457899093628
Validation loss: 1.9955965729169949

Epoch: 6| Step: 2
Training loss: 1.8256443738937378
Validation loss: 2.015255061529016

Epoch: 6| Step: 3
Training loss: 1.8536607027053833
Validation loss: 2.0166094431313137

Epoch: 6| Step: 4
Training loss: 1.7425516843795776
Validation loss: 2.013356683074787

Epoch: 6| Step: 5
Training loss: 1.7750530242919922
Validation loss: 2.012329015680539

Epoch: 6| Step: 6
Training loss: 2.358290195465088
Validation loss: 2.0011645235041136

Epoch: 6| Step: 7
Training loss: 1.9232062101364136
Validation loss: 1.9959486505036712

Epoch: 6| Step: 8
Training loss: 2.4258570671081543
Validation loss: 1.9786296300990607

Epoch: 6| Step: 9
Training loss: 2.7184433937072754
Validation loss: 1.960912081503099

Epoch: 6| Step: 10
Training loss: 1.5025136470794678
Validation loss: 1.9586372913852814

Epoch: 6| Step: 11
Training loss: 2.0101168155670166
Validation loss: 1.962453201252927

Epoch: 6| Step: 12
Training loss: 1.6745022535324097
Validation loss: 1.9699036921224287

Epoch: 6| Step: 13
Training loss: 1.8201192617416382
Validation loss: 1.9751636674327235

Epoch: 140| Step: 0
Training loss: 2.5194602012634277
Validation loss: 1.958669380475116

Epoch: 6| Step: 1
Training loss: 1.7372004985809326
Validation loss: 1.958064720194827

Epoch: 6| Step: 2
Training loss: 1.9957027435302734
Validation loss: 1.940600097820323

Epoch: 6| Step: 3
Training loss: 2.016132354736328
Validation loss: 1.9441811564148113

Epoch: 6| Step: 4
Training loss: 1.3894338607788086
Validation loss: 1.953089496140839

Epoch: 6| Step: 5
Training loss: 2.18381667137146
Validation loss: 1.9559390096254246

Epoch: 6| Step: 6
Training loss: 1.7985877990722656
Validation loss: 1.960500955581665

Epoch: 6| Step: 7
Training loss: 2.143249034881592
Validation loss: 1.9608130096107401

Epoch: 6| Step: 8
Training loss: 2.2214291095733643
Validation loss: 1.96157467749811

Epoch: 6| Step: 9
Training loss: 2.218754768371582
Validation loss: 1.977908589506662

Epoch: 6| Step: 10
Training loss: 2.6878600120544434
Validation loss: 1.9894556614660448

Epoch: 6| Step: 11
Training loss: 1.6218489408493042
Validation loss: 1.9874543977040116

Epoch: 6| Step: 12
Training loss: 1.703906774520874
Validation loss: 1.9852129772145262

Epoch: 6| Step: 13
Training loss: 2.126971960067749
Validation loss: 1.9841512903090446

Epoch: 141| Step: 0
Training loss: 2.4061825275421143
Validation loss: 1.9998145539273497

Epoch: 6| Step: 1
Training loss: 1.856952428817749
Validation loss: 2.0039712472628524

Epoch: 6| Step: 2
Training loss: 2.2560691833496094
Validation loss: 2.01216665006453

Epoch: 6| Step: 3
Training loss: 1.3907079696655273
Validation loss: 2.026522026267103

Epoch: 6| Step: 4
Training loss: 1.772347331047058
Validation loss: 2.043376194533481

Epoch: 6| Step: 5
Training loss: 2.70638370513916
Validation loss: 2.0328916785537556

Epoch: 6| Step: 6
Training loss: 1.4672187566757202
Validation loss: 2.005603867192422

Epoch: 6| Step: 7
Training loss: 2.228794574737549
Validation loss: 1.9770669501314881

Epoch: 6| Step: 8
Training loss: 1.3775544166564941
Validation loss: 1.9794073976496214

Epoch: 6| Step: 9
Training loss: 1.9069768190383911
Validation loss: 1.9878871222977996

Epoch: 6| Step: 10
Training loss: 2.2879815101623535
Validation loss: 1.9890287396728352

Epoch: 6| Step: 11
Training loss: 2.35803484916687
Validation loss: 1.9727377481358026

Epoch: 6| Step: 12
Training loss: 2.363218307495117
Validation loss: 1.9574488901322888

Epoch: 6| Step: 13
Training loss: 2.3028016090393066
Validation loss: 1.9628866628933979

Epoch: 142| Step: 0
Training loss: 1.6128907203674316
Validation loss: 1.9419445683879237

Epoch: 6| Step: 1
Training loss: 2.2078745365142822
Validation loss: 1.959463724526026

Epoch: 6| Step: 2
Training loss: 1.1668648719787598
Validation loss: 1.9805299851202196

Epoch: 6| Step: 3
Training loss: 2.0831332206726074
Validation loss: 1.9863879155087214

Epoch: 6| Step: 4
Training loss: 1.9663431644439697
Validation loss: 1.9900946668399278

Epoch: 6| Step: 5
Training loss: 2.1758155822753906
Validation loss: 1.989038780171384

Epoch: 6| Step: 6
Training loss: 2.0454025268554688
Validation loss: 1.9936934812094576

Epoch: 6| Step: 7
Training loss: 2.29130220413208
Validation loss: 1.9837513623699066

Epoch: 6| Step: 8
Training loss: 1.9101825952529907
Validation loss: 1.9756490953506962

Epoch: 6| Step: 9
Training loss: 2.1344547271728516
Validation loss: 1.9689655701319377

Epoch: 6| Step: 10
Training loss: 1.9371633529663086
Validation loss: 1.9521827120934763

Epoch: 6| Step: 11
Training loss: 2.0926618576049805
Validation loss: 1.9410016536712646

Epoch: 6| Step: 12
Training loss: 2.278571605682373
Validation loss: 1.945545963061753

Epoch: 6| Step: 13
Training loss: 2.6338651180267334
Validation loss: 1.9627382652733916

Epoch: 143| Step: 0
Training loss: 2.5823354721069336
Validation loss: 1.9603048793731197

Epoch: 6| Step: 1
Training loss: 2.597440719604492
Validation loss: 1.950754007985515

Epoch: 6| Step: 2
Training loss: 1.7272142171859741
Validation loss: 1.9554491696819183

Epoch: 6| Step: 3
Training loss: 1.9603874683380127
Validation loss: 1.9694384759472263

Epoch: 6| Step: 4
Training loss: 1.4984054565429688
Validation loss: 1.9701932284139818

Epoch: 6| Step: 5
Training loss: 1.2548227310180664
Validation loss: 1.9962046466847903

Epoch: 6| Step: 6
Training loss: 1.743026852607727
Validation loss: 1.995983874926003

Epoch: 6| Step: 7
Training loss: 1.808264970779419
Validation loss: 2.0118542486621487

Epoch: 6| Step: 8
Training loss: 2.1422133445739746
Validation loss: 2.0132214100130144

Epoch: 6| Step: 9
Training loss: 1.9208016395568848
Validation loss: 2.0058457902682725

Epoch: 6| Step: 10
Training loss: 1.7126710414886475
Validation loss: 2.0074413361087924

Epoch: 6| Step: 11
Training loss: 2.818300247192383
Validation loss: 1.9967080495690788

Epoch: 6| Step: 12
Training loss: 2.2735483646392822
Validation loss: 1.9710292021433513

Epoch: 6| Step: 13
Training loss: 2.3943796157836914
Validation loss: 1.955024141137318

Epoch: 144| Step: 0
Training loss: 2.028017997741699
Validation loss: 1.9440126508794806

Epoch: 6| Step: 1
Training loss: 1.7154295444488525
Validation loss: 1.9446091498098066

Epoch: 6| Step: 2
Training loss: 2.398940086364746
Validation loss: 1.9470525403176584

Epoch: 6| Step: 3
Training loss: 1.9437131881713867
Validation loss: 1.9711634330852057

Epoch: 6| Step: 4
Training loss: 1.9250351190567017
Validation loss: 1.9879237195496917

Epoch: 6| Step: 5
Training loss: 1.911473274230957
Validation loss: 2.008304536983531

Epoch: 6| Step: 6
Training loss: 1.9515068531036377
Validation loss: 2.0012532613610707

Epoch: 6| Step: 7
Training loss: 1.6952377557754517
Validation loss: 1.9933680744581326

Epoch: 6| Step: 8
Training loss: 2.2320454120635986
Validation loss: 1.97741138550543

Epoch: 6| Step: 9
Training loss: 1.6396747827529907
Validation loss: 1.9956131442900626

Epoch: 6| Step: 10
Training loss: 2.0164003372192383
Validation loss: 2.0261315863619567

Epoch: 6| Step: 11
Training loss: 2.550518035888672
Validation loss: 2.033756202267062

Epoch: 6| Step: 12
Training loss: 1.9318344593048096
Validation loss: 2.0417309243191957

Epoch: 6| Step: 13
Training loss: 2.203643321990967
Validation loss: 2.0266155453138452

Epoch: 145| Step: 0
Training loss: 1.5212428569793701
Validation loss: 2.029610349285987

Epoch: 6| Step: 1
Training loss: 2.1442551612854004
Validation loss: 2.0011608574980047

Epoch: 6| Step: 2
Training loss: 2.1007041931152344
Validation loss: 2.014806967909618

Epoch: 6| Step: 3
Training loss: 1.7648688554763794
Validation loss: 2.0260209562957927

Epoch: 6| Step: 4
Training loss: 2.253906726837158
Validation loss: 2.008367730725196

Epoch: 6| Step: 5
Training loss: 2.4001595973968506
Validation loss: 2.0021661327731226

Epoch: 6| Step: 6
Training loss: 1.804466724395752
Validation loss: 1.9637954799077844

Epoch: 6| Step: 7
Training loss: 2.0363430976867676
Validation loss: 1.949051180193501

Epoch: 6| Step: 8
Training loss: 2.019124984741211
Validation loss: 1.9327320232186267

Epoch: 6| Step: 9
Training loss: 1.4083364009857178
Validation loss: 1.9390161755264446

Epoch: 6| Step: 10
Training loss: 2.2164039611816406
Validation loss: 1.9377955775107107

Epoch: 6| Step: 11
Training loss: 2.3860435485839844
Validation loss: 1.9377165532881213

Epoch: 6| Step: 12
Training loss: 1.682210087776184
Validation loss: 1.9542331336646952

Epoch: 6| Step: 13
Training loss: 2.3245608806610107
Validation loss: 1.946526574832137

Epoch: 146| Step: 0
Training loss: 1.854899287223816
Validation loss: 1.9549113678675827

Epoch: 6| Step: 1
Training loss: 2.4953012466430664
Validation loss: 1.9483177097894813

Epoch: 6| Step: 2
Training loss: 1.9245319366455078
Validation loss: 1.942077705937047

Epoch: 6| Step: 3
Training loss: 2.1905031204223633
Validation loss: 1.9504919231578868

Epoch: 6| Step: 4
Training loss: 2.004837989807129
Validation loss: 1.9461523948177215

Epoch: 6| Step: 5
Training loss: 1.9359257221221924
Validation loss: 1.9737374103197487

Epoch: 6| Step: 6
Training loss: 2.029613733291626
Validation loss: 2.0012594628077682

Epoch: 6| Step: 7
Training loss: 1.7145978212356567
Validation loss: 2.011073048396777

Epoch: 6| Step: 8
Training loss: 2.059217929840088
Validation loss: 2.0277672377965783

Epoch: 6| Step: 9
Training loss: 2.147245407104492
Validation loss: 2.024961353630148

Epoch: 6| Step: 10
Training loss: 1.7063695192337036
Validation loss: 2.016717435211264

Epoch: 6| Step: 11
Training loss: 2.324681043624878
Validation loss: 2.015844282283578

Epoch: 6| Step: 12
Training loss: 1.2250216007232666
Validation loss: 1.9912779408116494

Epoch: 6| Step: 13
Training loss: 1.9896159172058105
Validation loss: 1.9868174804154264

Epoch: 147| Step: 0
Training loss: 1.9954886436462402
Validation loss: 1.9708739903665358

Epoch: 6| Step: 1
Training loss: 1.7308499813079834
Validation loss: 1.958493899273616

Epoch: 6| Step: 2
Training loss: 1.3647289276123047
Validation loss: 1.949129560942291

Epoch: 6| Step: 3
Training loss: 1.917378544807434
Validation loss: 1.964252209150663

Epoch: 6| Step: 4
Training loss: 1.3776601552963257
Validation loss: 1.9701899995086014

Epoch: 6| Step: 5
Training loss: 1.5313546657562256
Validation loss: 1.9628350503983036

Epoch: 6| Step: 6
Training loss: 2.2152481079101562
Validation loss: 1.9493636341505154

Epoch: 6| Step: 7
Training loss: 1.8897063732147217
Validation loss: 1.9616923370668966

Epoch: 6| Step: 8
Training loss: 2.278947353363037
Validation loss: 1.9585716762850363

Epoch: 6| Step: 9
Training loss: 1.850853443145752
Validation loss: 1.9631796780452933

Epoch: 6| Step: 10
Training loss: 2.237114906311035
Validation loss: 1.9703844888235933

Epoch: 6| Step: 11
Training loss: 2.7066526412963867
Validation loss: 1.9796824519352247

Epoch: 6| Step: 12
Training loss: 2.492546558380127
Validation loss: 1.9848720014736216

Epoch: 6| Step: 13
Training loss: 1.8015046119689941
Validation loss: 1.9793077848290885

Epoch: 148| Step: 0
Training loss: 1.1770257949829102
Validation loss: 1.9975460472927298

Epoch: 6| Step: 1
Training loss: 1.454010009765625
Validation loss: 2.013128803622338

Epoch: 6| Step: 2
Training loss: 1.9281480312347412
Validation loss: 2.0160900418476393

Epoch: 6| Step: 3
Training loss: 1.515139102935791
Validation loss: 2.0095645496922154

Epoch: 6| Step: 4
Training loss: 2.7388792037963867
Validation loss: 2.0206992216007684

Epoch: 6| Step: 5
Training loss: 1.6694326400756836
Validation loss: 2.0057902977030766

Epoch: 6| Step: 6
Training loss: 2.4610531330108643
Validation loss: 1.9892732456166258

Epoch: 6| Step: 7
Training loss: 1.9439412355422974
Validation loss: 1.9637997675967473

Epoch: 6| Step: 8
Training loss: 2.2971303462982178
Validation loss: 1.9439796734881658

Epoch: 6| Step: 9
Training loss: 1.536926031112671
Validation loss: 1.9460183369216097

Epoch: 6| Step: 10
Training loss: 1.6694366931915283
Validation loss: 1.9467711576851465

Epoch: 6| Step: 11
Training loss: 2.016432762145996
Validation loss: 1.9493390924187117

Epoch: 6| Step: 12
Training loss: 2.2298483848571777
Validation loss: 1.947995743443889

Epoch: 6| Step: 13
Training loss: 2.6599793434143066
Validation loss: 1.9315215003105901

Epoch: 149| Step: 0
Training loss: 2.098447799682617
Validation loss: 1.9362162082426009

Epoch: 6| Step: 1
Training loss: 2.1209473609924316
Validation loss: 1.9481092473512054

Epoch: 6| Step: 2
Training loss: 2.1486973762512207
Validation loss: 1.9542260105891893

Epoch: 6| Step: 3
Training loss: 1.6415412425994873
Validation loss: 1.9760681813763035

Epoch: 6| Step: 4
Training loss: 1.9178662300109863
Validation loss: 2.0373146649329894

Epoch: 6| Step: 5
Training loss: 2.0138580799102783
Validation loss: 2.0877464048324095

Epoch: 6| Step: 6
Training loss: 2.6689772605895996
Validation loss: 2.0907504456017607

Epoch: 6| Step: 7
Training loss: 2.1125974655151367
Validation loss: 2.0517239314253612

Epoch: 6| Step: 8
Training loss: 1.4057056903839111
Validation loss: 2.0307601433928295

Epoch: 6| Step: 9
Training loss: 1.1542279720306396
Validation loss: 1.986472043939816

Epoch: 6| Step: 10
Training loss: 2.1688127517700195
Validation loss: 1.9562580188115437

Epoch: 6| Step: 11
Training loss: 1.9245210886001587
Validation loss: 1.9457546408458422

Epoch: 6| Step: 12
Training loss: 1.8898502588272095
Validation loss: 1.9485629720072593

Epoch: 6| Step: 13
Training loss: 1.4214024543762207
Validation loss: 1.9387265136165004

Epoch: 150| Step: 0
Training loss: 1.7063449621200562
Validation loss: 1.925784618623795

Epoch: 6| Step: 1
Training loss: 1.5656579732894897
Validation loss: 1.9318778117497761

Epoch: 6| Step: 2
Training loss: 1.7476308345794678
Validation loss: 1.9295320382682226

Epoch: 6| Step: 3
Training loss: 1.771142840385437
Validation loss: 1.934495742603015

Epoch: 6| Step: 4
Training loss: 1.6400632858276367
Validation loss: 1.9377614221265238

Epoch: 6| Step: 5
Training loss: 1.9895871877670288
Validation loss: 1.9360433393909084

Epoch: 6| Step: 6
Training loss: 2.3129632472991943
Validation loss: 1.9363612859479842

Epoch: 6| Step: 7
Training loss: 2.233585834503174
Validation loss: 1.9723448317538026

Epoch: 6| Step: 8
Training loss: 1.9216464757919312
Validation loss: 1.9822519312622726

Epoch: 6| Step: 9
Training loss: 2.049480438232422
Validation loss: 2.0338836318703106

Epoch: 6| Step: 10
Training loss: 2.096721649169922
Validation loss: 2.0439211988961823

Epoch: 6| Step: 11
Training loss: 1.7187145948410034
Validation loss: 2.0756858061718684

Epoch: 6| Step: 12
Training loss: 2.397770643234253
Validation loss: 2.1094440849878455

Epoch: 6| Step: 13
Training loss: 1.629679560661316
Validation loss: 2.1065810085624777

Testing loss: 2.3330184088812933
