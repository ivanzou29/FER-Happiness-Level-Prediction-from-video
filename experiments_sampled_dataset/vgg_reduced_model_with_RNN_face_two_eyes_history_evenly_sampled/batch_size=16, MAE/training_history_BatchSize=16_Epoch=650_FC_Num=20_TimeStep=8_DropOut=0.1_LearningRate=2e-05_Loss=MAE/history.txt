Epoch: 1| Step: 0
Training loss: 4.172155380249023
Validation loss: 5.1970060717674995

Epoch: 6| Step: 1
Training loss: 4.585995674133301
Validation loss: 5.175298783086961

Epoch: 6| Step: 2
Training loss: 3.863701820373535
Validation loss: 5.152653089133642

Epoch: 6| Step: 3
Training loss: 4.933708190917969
Validation loss: 5.127908183682349

Epoch: 6| Step: 4
Training loss: 6.503320693969727
Validation loss: 5.100309771876181

Epoch: 6| Step: 5
Training loss: 5.9515533447265625
Validation loss: 5.069381739503594

Epoch: 6| Step: 6
Training loss: 3.510152578353882
Validation loss: 5.035510140080606

Epoch: 6| Step: 7
Training loss: 4.411593437194824
Validation loss: 4.997554553452359

Epoch: 6| Step: 8
Training loss: 4.217635154724121
Validation loss: 4.956492465029481

Epoch: 6| Step: 9
Training loss: 6.201717376708984
Validation loss: 4.910190428456953

Epoch: 6| Step: 10
Training loss: 4.75794792175293
Validation loss: 4.857500481349166

Epoch: 6| Step: 11
Training loss: 4.882378578186035
Validation loss: 4.799168166293893

Epoch: 6| Step: 12
Training loss: 3.384289026260376
Validation loss: 4.737656306195003

Epoch: 6| Step: 13
Training loss: 6.475977420806885
Validation loss: 4.67167826109035

Epoch: 2| Step: 0
Training loss: 4.578126907348633
Validation loss: 4.604591646502095

Epoch: 6| Step: 1
Training loss: 4.706555366516113
Validation loss: 4.537694182447208

Epoch: 6| Step: 2
Training loss: 3.9090213775634766
Validation loss: 4.471368994764102

Epoch: 6| Step: 3
Training loss: 4.810061454772949
Validation loss: 4.407806709248533

Epoch: 6| Step: 4
Training loss: 4.1573662757873535
Validation loss: 4.347087337124732

Epoch: 6| Step: 5
Training loss: 3.6813364028930664
Validation loss: 4.291449936487341

Epoch: 6| Step: 6
Training loss: 3.851742744445801
Validation loss: 4.236347019031483

Epoch: 6| Step: 7
Training loss: 3.56217360496521
Validation loss: 4.178366661071777

Epoch: 6| Step: 8
Training loss: 3.998166561126709
Validation loss: 4.123403221048335

Epoch: 6| Step: 9
Training loss: 3.932807683944702
Validation loss: 4.0706012582266204

Epoch: 6| Step: 10
Training loss: 3.425839424133301
Validation loss: 4.022530955653036

Epoch: 6| Step: 11
Training loss: 4.7225341796875
Validation loss: 3.9787310913044918

Epoch: 6| Step: 12
Training loss: 3.184203624725342
Validation loss: 3.93582663484799

Epoch: 6| Step: 13
Training loss: 4.351048469543457
Validation loss: 3.896627995275682

Epoch: 3| Step: 0
Training loss: 3.261234760284424
Validation loss: 3.8585917513857604

Epoch: 6| Step: 1
Training loss: 3.745431423187256
Validation loss: 3.826044649206182

Epoch: 6| Step: 2
Training loss: 3.3724172115325928
Validation loss: 3.7904807726542153

Epoch: 6| Step: 3
Training loss: 4.280984878540039
Validation loss: 3.7609449458378617

Epoch: 6| Step: 4
Training loss: 3.6173806190490723
Validation loss: 3.7310449641237975

Epoch: 6| Step: 5
Training loss: 3.699094772338867
Validation loss: 3.703108808045746

Epoch: 6| Step: 6
Training loss: 3.80793833732605
Validation loss: 3.6763134746141333

Epoch: 6| Step: 7
Training loss: 4.474070072174072
Validation loss: 3.661815430528374

Epoch: 6| Step: 8
Training loss: 3.927644729614258
Validation loss: 3.6323186941044305

Epoch: 6| Step: 9
Training loss: 2.731642246246338
Validation loss: 3.616234346102643

Epoch: 6| Step: 10
Training loss: 3.6842703819274902
Validation loss: 3.6054428700477845

Epoch: 6| Step: 11
Training loss: 3.761500120162964
Validation loss: 3.5858239076470815

Epoch: 6| Step: 12
Training loss: 2.8748016357421875
Validation loss: 3.571617139283047

Epoch: 6| Step: 13
Training loss: 2.4807116985321045
Validation loss: 3.5599222901046916

Epoch: 4| Step: 0
Training loss: 2.484839677810669
Validation loss: 3.5562902471070648

Epoch: 6| Step: 1
Training loss: 4.398961067199707
Validation loss: 3.536572556341848

Epoch: 6| Step: 2
Training loss: 3.680360794067383
Validation loss: 3.5230880091267247

Epoch: 6| Step: 3
Training loss: 3.5039353370666504
Validation loss: 3.503707419159592

Epoch: 6| Step: 4
Training loss: 2.8226077556610107
Validation loss: 3.4853415848106466

Epoch: 6| Step: 5
Training loss: 3.3799185752868652
Validation loss: 3.4664391702221287

Epoch: 6| Step: 6
Training loss: 3.742601156234741
Validation loss: 3.4467931742309244

Epoch: 6| Step: 7
Training loss: 4.013900279998779
Validation loss: 3.420596673924436

Epoch: 6| Step: 8
Training loss: 2.7912745475769043
Validation loss: 3.4030520659621044

Epoch: 6| Step: 9
Training loss: 3.123599052429199
Validation loss: 3.3886625100207586

Epoch: 6| Step: 10
Training loss: 3.2148704528808594
Validation loss: 3.3802454240860476

Epoch: 6| Step: 11
Training loss: 3.65840482711792
Validation loss: 3.3714447944395003

Epoch: 6| Step: 12
Training loss: 3.1085500717163086
Validation loss: 3.371625743886476

Epoch: 6| Step: 13
Training loss: 3.68821382522583
Validation loss: 3.361459024490849

Epoch: 5| Step: 0
Training loss: 3.4313125610351562
Validation loss: 3.3572835614604335

Epoch: 6| Step: 1
Training loss: 3.2842509746551514
Validation loss: 3.3459876609104935

Epoch: 6| Step: 2
Training loss: 3.207306146621704
Validation loss: 3.3259551473843154

Epoch: 6| Step: 3
Training loss: 4.0278239250183105
Validation loss: 3.315893021962976

Epoch: 6| Step: 4
Training loss: 3.7250237464904785
Validation loss: 3.3031601931459162

Epoch: 6| Step: 5
Training loss: 3.2423741817474365
Validation loss: 3.2910107694646364

Epoch: 6| Step: 6
Training loss: 2.592806577682495
Validation loss: 3.2816395862128145

Epoch: 6| Step: 7
Training loss: 3.61397123336792
Validation loss: 3.2721011100276822

Epoch: 6| Step: 8
Training loss: 3.079470634460449
Validation loss: 3.267053391343804

Epoch: 6| Step: 9
Training loss: 2.3435139656066895
Validation loss: 3.253780093244327

Epoch: 6| Step: 10
Training loss: 3.4472429752349854
Validation loss: 3.2464992307847544

Epoch: 6| Step: 11
Training loss: 2.835803508758545
Validation loss: 3.2362909624653478

Epoch: 6| Step: 12
Training loss: 3.485661029815674
Validation loss: 3.2300833912305933

Epoch: 6| Step: 13
Training loss: 3.471665620803833
Validation loss: 3.227373510278681

Epoch: 6| Step: 0
Training loss: 3.214195489883423
Validation loss: 3.2191032542977283

Epoch: 6| Step: 1
Training loss: 2.727149248123169
Validation loss: 3.2093409056304605

Epoch: 6| Step: 2
Training loss: 3.574183940887451
Validation loss: 3.2040550913862003

Epoch: 6| Step: 3
Training loss: 3.700157880783081
Validation loss: 3.197010701702487

Epoch: 6| Step: 4
Training loss: 3.0795373916625977
Validation loss: 3.1862314029406478

Epoch: 6| Step: 5
Training loss: 3.1983144283294678
Validation loss: 3.1790491662999636

Epoch: 6| Step: 6
Training loss: 3.914710760116577
Validation loss: 3.1875628758502264

Epoch: 6| Step: 7
Training loss: 2.983675956726074
Validation loss: 3.1703884319592546

Epoch: 6| Step: 8
Training loss: 2.189642906188965
Validation loss: 3.158904183295465

Epoch: 6| Step: 9
Training loss: 3.251983165740967
Validation loss: 3.1596779105483845

Epoch: 6| Step: 10
Training loss: 3.5940568447113037
Validation loss: 3.1526885417199906

Epoch: 6| Step: 11
Training loss: 3.504220724105835
Validation loss: 3.149215603387484

Epoch: 6| Step: 12
Training loss: 3.1036994457244873
Validation loss: 3.142563207175142

Epoch: 6| Step: 13
Training loss: 1.9540303945541382
Validation loss: 3.1398592738695044

Epoch: 7| Step: 0
Training loss: 2.9442076683044434
Validation loss: 3.1457521889799382

Epoch: 6| Step: 1
Training loss: 3.636054277420044
Validation loss: 3.140410582224528

Epoch: 6| Step: 2
Training loss: 3.3922815322875977
Validation loss: 3.1229744290792816

Epoch: 6| Step: 3
Training loss: 3.831461191177368
Validation loss: 3.122684412105109

Epoch: 6| Step: 4
Training loss: 3.415248394012451
Validation loss: 3.1126717880208004

Epoch: 6| Step: 5
Training loss: 3.4004740715026855
Validation loss: 3.1012382968779533

Epoch: 6| Step: 6
Training loss: 2.3913702964782715
Validation loss: 3.1044213643638034

Epoch: 6| Step: 7
Training loss: 3.8484416007995605
Validation loss: 3.136178442226943

Epoch: 6| Step: 8
Training loss: 2.708716869354248
Validation loss: 3.0956839771680933

Epoch: 6| Step: 9
Training loss: 2.8412327766418457
Validation loss: 3.0900116684616252

Epoch: 6| Step: 10
Training loss: 2.408548355102539
Validation loss: 3.092557214921521

Epoch: 6| Step: 11
Training loss: 3.1038737297058105
Validation loss: 3.1262352594765286

Epoch: 6| Step: 12
Training loss: 3.5734527111053467
Validation loss: 3.0889587709980626

Epoch: 6| Step: 13
Training loss: 1.9222685098648071
Validation loss: 3.0767099934239543

Epoch: 8| Step: 0
Training loss: 2.3490829467773438
Validation loss: 3.0780154505083637

Epoch: 6| Step: 1
Training loss: 1.717153787612915
Validation loss: 3.0828654253354637

Epoch: 6| Step: 2
Training loss: 2.591602087020874
Validation loss: 3.091435053015268

Epoch: 6| Step: 3
Training loss: 2.9650604724884033
Validation loss: 3.10099519196377

Epoch: 6| Step: 4
Training loss: 3.497535467147827
Validation loss: 3.081657948032502

Epoch: 6| Step: 5
Training loss: 3.5725529193878174
Validation loss: 3.0689467871060936

Epoch: 6| Step: 6
Training loss: 3.5614023208618164
Validation loss: 3.095315179517192

Epoch: 6| Step: 7
Training loss: 3.7327663898468018
Validation loss: 3.1164030362200994

Epoch: 6| Step: 8
Training loss: 2.798097610473633
Validation loss: 3.083773292520995

Epoch: 6| Step: 9
Training loss: 3.538839817047119
Validation loss: 3.046198880800637

Epoch: 6| Step: 10
Training loss: 3.2211661338806152
Validation loss: 3.0490650387220484

Epoch: 6| Step: 11
Training loss: 3.5763320922851562
Validation loss: 3.062845855630854

Epoch: 6| Step: 12
Training loss: 3.3559398651123047
Validation loss: 3.0713042648889686

Epoch: 6| Step: 13
Training loss: 3.107619524002075
Validation loss: 3.0762544908831195

Epoch: 9| Step: 0
Training loss: 2.445436477661133
Validation loss: 3.064106136239985

Epoch: 6| Step: 1
Training loss: 2.869328260421753
Validation loss: 3.0571558244766726

Epoch: 6| Step: 2
Training loss: 3.017612934112549
Validation loss: 3.0462471259537565

Epoch: 6| Step: 3
Training loss: 3.0119948387145996
Validation loss: 3.0427664608083744

Epoch: 6| Step: 4
Training loss: 3.381242275238037
Validation loss: 3.0400123032190467

Epoch: 6| Step: 5
Training loss: 2.901460647583008
Validation loss: 3.0352336463107856

Epoch: 6| Step: 6
Training loss: 2.4848337173461914
Validation loss: 3.018582172291253

Epoch: 6| Step: 7
Training loss: 3.0955512523651123
Validation loss: 3.0123091154201056

Epoch: 6| Step: 8
Training loss: 2.7686142921447754
Validation loss: 3.0033202735326623

Epoch: 6| Step: 9
Training loss: 3.7992660999298096
Validation loss: 2.9979776208118727

Epoch: 6| Step: 10
Training loss: 2.956430196762085
Validation loss: 2.9931439968847458

Epoch: 6| Step: 11
Training loss: 4.231607437133789
Validation loss: 2.984700031177972

Epoch: 6| Step: 12
Training loss: 3.3625130653381348
Validation loss: 2.9851448407737156

Epoch: 6| Step: 13
Training loss: 2.593677043914795
Validation loss: 2.9862956257276636

Epoch: 10| Step: 0
Training loss: 2.6569411754608154
Validation loss: 2.9841970730853338

Epoch: 6| Step: 1
Training loss: 3.038757801055908
Validation loss: 2.9753422224393455

Epoch: 6| Step: 2
Training loss: 2.8114843368530273
Validation loss: 2.9760756851524435

Epoch: 6| Step: 3
Training loss: 2.893498182296753
Validation loss: 2.9713189166079284

Epoch: 6| Step: 4
Training loss: 3.548029661178589
Validation loss: 2.9704734356172624

Epoch: 6| Step: 5
Training loss: 3.384216070175171
Validation loss: 2.9676753141546763

Epoch: 6| Step: 6
Training loss: 3.912024736404419
Validation loss: 2.9659486329683693

Epoch: 6| Step: 7
Training loss: 2.7722678184509277
Validation loss: 2.9638903064112507

Epoch: 6| Step: 8
Training loss: 2.239349126815796
Validation loss: 2.9746088879082793

Epoch: 6| Step: 9
Training loss: 2.4638266563415527
Validation loss: 3.011181664723222

Epoch: 6| Step: 10
Training loss: 3.5843491554260254
Validation loss: 2.99421077646235

Epoch: 6| Step: 11
Training loss: 3.13437557220459
Validation loss: 2.95026824807608

Epoch: 6| Step: 12
Training loss: 3.3793985843658447
Validation loss: 2.9563267333533174

Epoch: 6| Step: 13
Training loss: 2.723316192626953
Validation loss: 2.9788121408031834

Epoch: 11| Step: 0
Training loss: 3.279797315597534
Validation loss: 3.0149844154234855

Epoch: 6| Step: 1
Training loss: 3.7270278930664062
Validation loss: 2.9765734262363885

Epoch: 6| Step: 2
Training loss: 2.9932193756103516
Validation loss: 2.931375813740556

Epoch: 6| Step: 3
Training loss: 3.5072543621063232
Validation loss: 2.925832943249774

Epoch: 6| Step: 4
Training loss: 3.3932137489318848
Validation loss: 2.928777071737474

Epoch: 6| Step: 5
Training loss: 2.5848195552825928
Validation loss: 2.9395265220313944

Epoch: 6| Step: 6
Training loss: 3.1149051189422607
Validation loss: 2.946703210953743

Epoch: 6| Step: 7
Training loss: 2.8050284385681152
Validation loss: 2.937582569737588

Epoch: 6| Step: 8
Training loss: 3.0448009967803955
Validation loss: 2.9379064036953833

Epoch: 6| Step: 9
Training loss: 2.590482234954834
Validation loss: 2.9340236289526826

Epoch: 6| Step: 10
Training loss: 1.7726871967315674
Validation loss: 2.9238897600481586

Epoch: 6| Step: 11
Training loss: 3.501664400100708
Validation loss: 2.9170520279997136

Epoch: 6| Step: 12
Training loss: 3.2003493309020996
Validation loss: 2.9162118845088507

Epoch: 6| Step: 13
Training loss: 2.7252373695373535
Validation loss: 2.905230442682902

Epoch: 12| Step: 0
Training loss: 3.5680184364318848
Validation loss: 2.901123754439815

Epoch: 6| Step: 1
Training loss: 1.897335171699524
Validation loss: 2.8971429306973695

Epoch: 6| Step: 2
Training loss: 2.287217855453491
Validation loss: 2.8974251285676034

Epoch: 6| Step: 3
Training loss: 2.927703380584717
Validation loss: 2.8986443524719565

Epoch: 6| Step: 4
Training loss: 3.521397590637207
Validation loss: 2.891111584119899

Epoch: 6| Step: 5
Training loss: 3.2253427505493164
Validation loss: 2.880326670985068

Epoch: 6| Step: 6
Training loss: 2.3366289138793945
Validation loss: 2.87504586609461

Epoch: 6| Step: 7
Training loss: 3.5333175659179688
Validation loss: 2.8736902770175727

Epoch: 6| Step: 8
Training loss: 3.230799436569214
Validation loss: 2.87033127456583

Epoch: 6| Step: 9
Training loss: 3.4196555614471436
Validation loss: 2.8676530109938754

Epoch: 6| Step: 10
Training loss: 2.9332876205444336
Validation loss: 2.865221897761027

Epoch: 6| Step: 11
Training loss: 2.575796604156494
Validation loss: 2.855746364080778

Epoch: 6| Step: 12
Training loss: 3.701953411102295
Validation loss: 2.8498435892084593

Epoch: 6| Step: 13
Training loss: 2.3501040935516357
Validation loss: 2.84797699733447

Epoch: 13| Step: 0
Training loss: 3.241823196411133
Validation loss: 2.8471475954978698

Epoch: 6| Step: 1
Training loss: 3.2061259746551514
Validation loss: 2.845380852299352

Epoch: 6| Step: 2
Training loss: 3.3284313678741455
Validation loss: 2.843311817415299

Epoch: 6| Step: 3
Training loss: 2.868036985397339
Validation loss: 2.835732977877381

Epoch: 6| Step: 4
Training loss: 2.9988303184509277
Validation loss: 2.834254262267902

Epoch: 6| Step: 5
Training loss: 1.936935305595398
Validation loss: 2.865662197912893

Epoch: 6| Step: 6
Training loss: 3.185171365737915
Validation loss: 2.8542427811571347

Epoch: 6| Step: 7
Training loss: 2.8561792373657227
Validation loss: 2.8309587073582474

Epoch: 6| Step: 8
Training loss: 3.5939385890960693
Validation loss: 2.845316779228949

Epoch: 6| Step: 9
Training loss: 4.066760540008545
Validation loss: 2.8190365401647424

Epoch: 6| Step: 10
Training loss: 2.5438907146453857
Validation loss: 2.8164923370525403

Epoch: 6| Step: 11
Training loss: 2.6619760990142822
Validation loss: 2.8189530834074943

Epoch: 6| Step: 12
Training loss: 1.9244420528411865
Validation loss: 2.822733094615321

Epoch: 6| Step: 13
Training loss: 2.9436163902282715
Validation loss: 2.821849612779515

Epoch: 14| Step: 0
Training loss: 2.8880503177642822
Validation loss: 2.8152634661684752

Epoch: 6| Step: 1
Training loss: 2.937249183654785
Validation loss: 2.8115607423167073

Epoch: 6| Step: 2
Training loss: 3.445622682571411
Validation loss: 2.806195717985912

Epoch: 6| Step: 3
Training loss: 3.1622793674468994
Validation loss: 2.8043879078280542

Epoch: 6| Step: 4
Training loss: 2.570059299468994
Validation loss: 2.803778971395185

Epoch: 6| Step: 5
Training loss: 3.0717902183532715
Validation loss: 2.7987271790863364

Epoch: 6| Step: 6
Training loss: 2.5880253314971924
Validation loss: 2.7960884699257473

Epoch: 6| Step: 7
Training loss: 2.7773306369781494
Validation loss: 2.794015540871569

Epoch: 6| Step: 8
Training loss: 3.354346513748169
Validation loss: 2.7894912150598343

Epoch: 6| Step: 9
Training loss: 2.950937509536743
Validation loss: 2.789240667896886

Epoch: 6| Step: 10
Training loss: 3.280524253845215
Validation loss: 2.785828185337846

Epoch: 6| Step: 11
Training loss: 2.0697720050811768
Validation loss: 2.7805912084476923

Epoch: 6| Step: 12
Training loss: 3.141610622406006
Validation loss: 2.7795212884103098

Epoch: 6| Step: 13
Training loss: 2.725679874420166
Validation loss: 2.775986102319533

Epoch: 15| Step: 0
Training loss: 3.686556577682495
Validation loss: 2.7749253831883913

Epoch: 6| Step: 1
Training loss: 2.9448916912078857
Validation loss: 2.7711789095273582

Epoch: 6| Step: 2
Training loss: 2.60444974899292
Validation loss: 2.7677096218191166

Epoch: 6| Step: 3
Training loss: 2.494004726409912
Validation loss: 2.764677598912229

Epoch: 6| Step: 4
Training loss: 3.5240213871002197
Validation loss: 2.7669661045074463

Epoch: 6| Step: 5
Training loss: 2.7909862995147705
Validation loss: 2.765236839171379

Epoch: 6| Step: 6
Training loss: 2.8281874656677246
Validation loss: 2.7760675927644134

Epoch: 6| Step: 7
Training loss: 2.735457420349121
Validation loss: 2.7831491065281693

Epoch: 6| Step: 8
Training loss: 3.0507116317749023
Validation loss: 2.823377522089148

Epoch: 6| Step: 9
Training loss: 3.5664196014404297
Validation loss: 2.777922443164292

Epoch: 6| Step: 10
Training loss: 2.277649402618408
Validation loss: 2.7528658092662854

Epoch: 6| Step: 11
Training loss: 3.235809326171875
Validation loss: 2.75355940224022

Epoch: 6| Step: 12
Training loss: 2.2342352867126465
Validation loss: 2.778681696102183

Epoch: 6| Step: 13
Training loss: 2.6752004623413086
Validation loss: 2.7570394444209274

Epoch: 16| Step: 0
Training loss: 3.410263776779175
Validation loss: 2.75292650089469

Epoch: 6| Step: 1
Training loss: 3.1872787475585938
Validation loss: 2.7481434165790515

Epoch: 6| Step: 2
Training loss: 2.2947490215301514
Validation loss: 2.749504114991875

Epoch: 6| Step: 3
Training loss: 3.256598472595215
Validation loss: 2.7470045140994492

Epoch: 6| Step: 4
Training loss: 3.022416591644287
Validation loss: 2.7427383622815533

Epoch: 6| Step: 5
Training loss: 3.1775307655334473
Validation loss: 2.74284702731717

Epoch: 6| Step: 6
Training loss: 2.9679067134857178
Validation loss: 2.7400527615701

Epoch: 6| Step: 7
Training loss: 2.897019386291504
Validation loss: 2.739454689846244

Epoch: 6| Step: 8
Training loss: 3.050424098968506
Validation loss: 2.7371470518009637

Epoch: 6| Step: 9
Training loss: 2.6232080459594727
Validation loss: 2.7355482962823685

Epoch: 6| Step: 10
Training loss: 2.6174418926239014
Validation loss: 2.7333055362906507

Epoch: 6| Step: 11
Training loss: 2.6927390098571777
Validation loss: 2.729912463054862

Epoch: 6| Step: 12
Training loss: 1.9764443635940552
Validation loss: 2.7278127106287147

Epoch: 6| Step: 13
Training loss: 3.750553607940674
Validation loss: 2.7288892140952488

Epoch: 17| Step: 0
Training loss: 2.5260517597198486
Validation loss: 2.7266293136022424

Epoch: 6| Step: 1
Training loss: 3.348348617553711
Validation loss: 2.724692549756778

Epoch: 6| Step: 2
Training loss: 2.9847826957702637
Validation loss: 2.7245437509270123

Epoch: 6| Step: 3
Training loss: 2.9079461097717285
Validation loss: 2.7245688976780063

Epoch: 6| Step: 4
Training loss: 2.212186813354492
Validation loss: 2.7238992285984818

Epoch: 6| Step: 5
Training loss: 2.7576096057891846
Validation loss: 2.723298183051489

Epoch: 6| Step: 6
Training loss: 3.6282641887664795
Validation loss: 2.7246729609786824

Epoch: 6| Step: 7
Training loss: 2.892043352127075
Validation loss: 2.716925908160466

Epoch: 6| Step: 8
Training loss: 3.586738109588623
Validation loss: 2.7198551444597143

Epoch: 6| Step: 9
Training loss: 2.354816198348999
Validation loss: 2.7184338415822675

Epoch: 6| Step: 10
Training loss: 3.1962265968322754
Validation loss: 2.716034948184926

Epoch: 6| Step: 11
Training loss: 3.077035427093506
Validation loss: 2.7166305536864908

Epoch: 6| Step: 12
Training loss: 2.404005527496338
Validation loss: 2.714924253443236

Epoch: 6| Step: 13
Training loss: 2.167595148086548
Validation loss: 2.711983924270958

Epoch: 18| Step: 0
Training loss: 2.022765874862671
Validation loss: 2.711253530235701

Epoch: 6| Step: 1
Training loss: 2.6429030895233154
Validation loss: 2.7104335446511545

Epoch: 6| Step: 2
Training loss: 3.575793743133545
Validation loss: 2.7075474364783174

Epoch: 6| Step: 3
Training loss: 3.696626663208008
Validation loss: 2.704064702474943

Epoch: 6| Step: 4
Training loss: 2.6368751525878906
Validation loss: 2.705220442946239

Epoch: 6| Step: 5
Training loss: 3.129094362258911
Validation loss: 2.707907220368744

Epoch: 6| Step: 6
Training loss: 2.944098472595215
Validation loss: 2.7075932461728334

Epoch: 6| Step: 7
Training loss: 2.719698429107666
Validation loss: 2.7052453871696227

Epoch: 6| Step: 8
Training loss: 2.1587765216827393
Validation loss: 2.7046286803419872

Epoch: 6| Step: 9
Training loss: 2.6745176315307617
Validation loss: 2.7085219865204184

Epoch: 6| Step: 10
Training loss: 2.536470890045166
Validation loss: 2.708945725553779

Epoch: 6| Step: 11
Training loss: 3.275204658508301
Validation loss: 2.7081800353142524

Epoch: 6| Step: 12
Training loss: 3.411214828491211
Validation loss: 2.70798433467906

Epoch: 6| Step: 13
Training loss: 2.6741790771484375
Validation loss: 2.6997932541754937

Epoch: 19| Step: 0
Training loss: 3.2221455574035645
Validation loss: 2.696387998519405

Epoch: 6| Step: 1
Training loss: 2.3302431106567383
Validation loss: 2.6951774140839935

Epoch: 6| Step: 2
Training loss: 3.544217824935913
Validation loss: 2.692226763694517

Epoch: 6| Step: 3
Training loss: 3.578864097595215
Validation loss: 2.6927426297177552

Epoch: 6| Step: 4
Training loss: 2.1081559658050537
Validation loss: 2.6926573194483274

Epoch: 6| Step: 5
Training loss: 3.3631792068481445
Validation loss: 2.693488697851858

Epoch: 6| Step: 6
Training loss: 2.7007460594177246
Validation loss: 2.6869390190288587

Epoch: 6| Step: 7
Training loss: 3.3665285110473633
Validation loss: 2.6867079914257093

Epoch: 6| Step: 8
Training loss: 2.6876583099365234
Validation loss: 2.686014526633806

Epoch: 6| Step: 9
Training loss: 2.332314968109131
Validation loss: 2.7138852637301207

Epoch: 6| Step: 10
Training loss: 3.2314743995666504
Validation loss: 2.699018019501881

Epoch: 6| Step: 11
Training loss: 2.1409339904785156
Validation loss: 2.6832234295465613

Epoch: 6| Step: 12
Training loss: 2.5871171951293945
Validation loss: 2.6839829849940475

Epoch: 6| Step: 13
Training loss: 2.910590171813965
Validation loss: 2.6940291414978685

Epoch: 20| Step: 0
Training loss: 2.723255157470703
Validation loss: 2.7219924542211715

Epoch: 6| Step: 1
Training loss: 2.4995956420898438
Validation loss: 2.707721802496141

Epoch: 6| Step: 2
Training loss: 2.249319553375244
Validation loss: 2.6939396909488145

Epoch: 6| Step: 3
Training loss: 3.011624336242676
Validation loss: 2.6867799579456286

Epoch: 6| Step: 4
Training loss: 2.8814525604248047
Validation loss: 2.6783871548150175

Epoch: 6| Step: 5
Training loss: 2.966836452484131
Validation loss: 2.679627383908918

Epoch: 6| Step: 6
Training loss: 3.492154598236084
Validation loss: 2.6785819838123937

Epoch: 6| Step: 7
Training loss: 2.993239641189575
Validation loss: 2.6758579797642206

Epoch: 6| Step: 8
Training loss: 2.5640439987182617
Validation loss: 2.6762061426716466

Epoch: 6| Step: 9
Training loss: 2.7363839149475098
Validation loss: 2.6819659330511607

Epoch: 6| Step: 10
Training loss: 2.6993660926818848
Validation loss: 2.690514418386644

Epoch: 6| Step: 11
Training loss: 3.9028141498565674
Validation loss: 2.6866424724619877

Epoch: 6| Step: 12
Training loss: 3.184171199798584
Validation loss: 2.6849273917495564

Epoch: 6| Step: 13
Training loss: 1.5933369398117065
Validation loss: 2.6927153628359557

Epoch: 21| Step: 0
Training loss: 3.646427869796753
Validation loss: 2.7212467398694766

Epoch: 6| Step: 1
Training loss: 2.410963535308838
Validation loss: 2.704747258975942

Epoch: 6| Step: 2
Training loss: 2.3502421379089355
Validation loss: 2.692178508286835

Epoch: 6| Step: 3
Training loss: 3.4692749977111816
Validation loss: 2.669742594483078

Epoch: 6| Step: 4
Training loss: 2.827559471130371
Validation loss: 2.67151302419683

Epoch: 6| Step: 5
Training loss: 2.9800453186035156
Validation loss: 2.6781957175142024

Epoch: 6| Step: 6
Training loss: 3.408957004547119
Validation loss: 2.6978143594598256

Epoch: 6| Step: 7
Training loss: 2.1234006881713867
Validation loss: 2.6703943565327632

Epoch: 6| Step: 8
Training loss: 3.339794635772705
Validation loss: 2.6671519458934827

Epoch: 6| Step: 9
Training loss: 2.7320706844329834
Validation loss: 2.6673299010081957

Epoch: 6| Step: 10
Training loss: 2.4333040714263916
Validation loss: 2.6843880966145504

Epoch: 6| Step: 11
Training loss: 2.10788631439209
Validation loss: 2.7107499696875132

Epoch: 6| Step: 12
Training loss: 2.5994932651519775
Validation loss: 2.7300919127720658

Epoch: 6| Step: 13
Training loss: 4.211957931518555
Validation loss: 2.743236941675986

Epoch: 22| Step: 0
Training loss: 3.134366512298584
Validation loss: 2.7265395605435936

Epoch: 6| Step: 1
Training loss: 2.870361804962158
Validation loss: 2.660272052211146

Epoch: 6| Step: 2
Training loss: 2.8406131267547607
Validation loss: 2.6674136551477576

Epoch: 6| Step: 3
Training loss: 2.4107666015625
Validation loss: 2.6984548799453245

Epoch: 6| Step: 4
Training loss: 2.6229748725891113
Validation loss: 2.736031304123581

Epoch: 6| Step: 5
Training loss: 2.5017924308776855
Validation loss: 2.7946342934844313

Epoch: 6| Step: 6
Training loss: 2.681342124938965
Validation loss: 2.9043054452506443

Epoch: 6| Step: 7
Training loss: 4.196682929992676
Validation loss: 3.0271782721242597

Epoch: 6| Step: 8
Training loss: 2.8807835578918457
Validation loss: 2.9054808180819274

Epoch: 6| Step: 9
Training loss: 2.9397037029266357
Validation loss: 2.6783094944492465

Epoch: 6| Step: 10
Training loss: 2.5804991722106934
Validation loss: 2.661009152730306

Epoch: 6| Step: 11
Training loss: 2.924344539642334
Validation loss: 2.726514511210944

Epoch: 6| Step: 12
Training loss: 3.296963691711426
Validation loss: 2.860570053900442

Epoch: 6| Step: 13
Training loss: 2.8666677474975586
Validation loss: 2.899781245057301

Epoch: 23| Step: 0
Training loss: 3.4492549896240234
Validation loss: 2.913949615211897

Epoch: 6| Step: 1
Training loss: 3.299325942993164
Validation loss: 2.7978667084888746

Epoch: 6| Step: 2
Training loss: 3.2482104301452637
Validation loss: 2.702692885552683

Epoch: 6| Step: 3
Training loss: 2.125142812728882
Validation loss: 2.6629340084650184

Epoch: 6| Step: 4
Training loss: 3.563967704772949
Validation loss: 2.6892394070984214

Epoch: 6| Step: 5
Training loss: 2.3735713958740234
Validation loss: 2.784166648823728

Epoch: 6| Step: 6
Training loss: 3.763101816177368
Validation loss: 2.9168381690979004

Epoch: 6| Step: 7
Training loss: 2.160489797592163
Validation loss: 2.9265174019721245

Epoch: 6| Step: 8
Training loss: 2.9133450984954834
Validation loss: 2.923024695406678

Epoch: 6| Step: 9
Training loss: 2.6638476848602295
Validation loss: 2.888418387341243

Epoch: 6| Step: 10
Training loss: 3.114994764328003
Validation loss: 2.8462659441014773

Epoch: 6| Step: 11
Training loss: 2.854656219482422
Validation loss: 2.790990965340727

Epoch: 6| Step: 12
Training loss: 2.642699718475342
Validation loss: 2.751808899705128

Epoch: 6| Step: 13
Training loss: 3.7678096294403076
Validation loss: 2.7111834787553355

Epoch: 24| Step: 0
Training loss: 2.6281347274780273
Validation loss: 2.686713203307121

Epoch: 6| Step: 1
Training loss: 2.969918966293335
Validation loss: 2.67518263734797

Epoch: 6| Step: 2
Training loss: 3.449462413787842
Validation loss: 2.6708674584665606

Epoch: 6| Step: 3
Training loss: 2.8518216609954834
Validation loss: 2.69435513916836

Epoch: 6| Step: 4
Training loss: 2.7133026123046875
Validation loss: 2.7457991287272465

Epoch: 6| Step: 5
Training loss: 2.7616868019104004
Validation loss: 2.8000929073620866

Epoch: 6| Step: 6
Training loss: 3.201631784439087
Validation loss: 2.8036934919254755

Epoch: 6| Step: 7
Training loss: 2.2001516819000244
Validation loss: 2.7363737808760775

Epoch: 6| Step: 8
Training loss: 2.8727893829345703
Validation loss: 2.6733998124317457

Epoch: 6| Step: 9
Training loss: 3.1865439414978027
Validation loss: 2.651704106279599

Epoch: 6| Step: 10
Training loss: 3.5544419288635254
Validation loss: 2.642282942289947

Epoch: 6| Step: 11
Training loss: 2.211393356323242
Validation loss: 2.6451769259668167

Epoch: 6| Step: 12
Training loss: 2.8471648693084717
Validation loss: 2.653320348390969

Epoch: 6| Step: 13
Training loss: 2.3867437839508057
Validation loss: 2.659232683079217

Epoch: 25| Step: 0
Training loss: 4.104618072509766
Validation loss: 2.6720343789746686

Epoch: 6| Step: 1
Training loss: 2.5391058921813965
Validation loss: 2.667752783785584

Epoch: 6| Step: 2
Training loss: 2.6469318866729736
Validation loss: 2.660311411785823

Epoch: 6| Step: 3
Training loss: 2.3985440731048584
Validation loss: 2.6536670679687173

Epoch: 6| Step: 4
Training loss: 1.952628254890442
Validation loss: 2.6487009602208293

Epoch: 6| Step: 5
Training loss: 3.270689010620117
Validation loss: 2.6597326801669214

Epoch: 6| Step: 6
Training loss: 3.2720961570739746
Validation loss: 2.6447261328338296

Epoch: 6| Step: 7
Training loss: 2.3245744705200195
Validation loss: 2.635426567446801

Epoch: 6| Step: 8
Training loss: 3.0932207107543945
Validation loss: 2.6286875919629167

Epoch: 6| Step: 9
Training loss: 2.697810649871826
Validation loss: 2.6257180680510817

Epoch: 6| Step: 10
Training loss: 3.6645007133483887
Validation loss: 2.624256908252675

Epoch: 6| Step: 11
Training loss: 2.478820323944092
Validation loss: 2.6222534512960785

Epoch: 6| Step: 12
Training loss: 2.477834701538086
Validation loss: 2.621304629951395

Epoch: 6| Step: 13
Training loss: 2.6377804279327393
Validation loss: 2.6169127546330935

Epoch: 26| Step: 0
Training loss: 1.704078197479248
Validation loss: 2.6220999404948246

Epoch: 6| Step: 1
Training loss: 3.4773855209350586
Validation loss: 2.6291965259018766

Epoch: 6| Step: 2
Training loss: 2.7477378845214844
Validation loss: 2.626570740053731

Epoch: 6| Step: 3
Training loss: 2.8768396377563477
Validation loss: 2.6283315689333024

Epoch: 6| Step: 4
Training loss: 2.451939582824707
Validation loss: 2.629962959597188

Epoch: 6| Step: 5
Training loss: 2.8498308658599854
Validation loss: 2.623701592927338

Epoch: 6| Step: 6
Training loss: 2.5033998489379883
Validation loss: 2.613472297627439

Epoch: 6| Step: 7
Training loss: 3.417290210723877
Validation loss: 2.6188439681965816

Epoch: 6| Step: 8
Training loss: 3.211805582046509
Validation loss: 2.6142773833326114

Epoch: 6| Step: 9
Training loss: 3.212461471557617
Validation loss: 2.6084262376190512

Epoch: 6| Step: 10
Training loss: 2.3940138816833496
Validation loss: 2.6092208995614

Epoch: 6| Step: 11
Training loss: 2.8824961185455322
Validation loss: 2.605332254081644

Epoch: 6| Step: 12
Training loss: 2.996405601501465
Validation loss: 2.607733452191917

Epoch: 6| Step: 13
Training loss: 2.509575366973877
Validation loss: 2.6031342475645003

Epoch: 27| Step: 0
Training loss: 2.7860324382781982
Validation loss: 2.6023528575897217

Epoch: 6| Step: 1
Training loss: 2.7107222080230713
Validation loss: 2.600523546177854

Epoch: 6| Step: 2
Training loss: 3.065657615661621
Validation loss: 2.601588879862139

Epoch: 6| Step: 3
Training loss: 3.1828739643096924
Validation loss: 2.596488824454687

Epoch: 6| Step: 4
Training loss: 2.852222204208374
Validation loss: 2.5975325517756964

Epoch: 6| Step: 5
Training loss: 2.589568614959717
Validation loss: 2.596982597022928

Epoch: 6| Step: 6
Training loss: 2.3396124839782715
Validation loss: 2.5930352236634944

Epoch: 6| Step: 7
Training loss: 3.0611062049865723
Validation loss: 2.6168312949519

Epoch: 6| Step: 8
Training loss: 2.475043773651123
Validation loss: 2.6097392497524137

Epoch: 6| Step: 9
Training loss: 3.023167610168457
Validation loss: 2.592736926130069

Epoch: 6| Step: 10
Training loss: 3.2949817180633545
Validation loss: 2.593604623630483

Epoch: 6| Step: 11
Training loss: 3.048825740814209
Validation loss: 2.5922944238108974

Epoch: 6| Step: 12
Training loss: 1.8801493644714355
Validation loss: 2.5920075396055817

Epoch: 6| Step: 13
Training loss: 2.8230648040771484
Validation loss: 2.588361091511224

Epoch: 28| Step: 0
Training loss: 3.4833076000213623
Validation loss: 2.584657866467712

Epoch: 6| Step: 1
Training loss: 2.699216365814209
Validation loss: 2.585098179437781

Epoch: 6| Step: 2
Training loss: 3.1381564140319824
Validation loss: 2.5851809311938543

Epoch: 6| Step: 3
Training loss: 2.203335762023926
Validation loss: 2.581313176821637

Epoch: 6| Step: 4
Training loss: 2.2406392097473145
Validation loss: 2.583040778354932

Epoch: 6| Step: 5
Training loss: 3.5346999168395996
Validation loss: 2.580210393474948

Epoch: 6| Step: 6
Training loss: 2.5135648250579834
Validation loss: 2.579010545566518

Epoch: 6| Step: 7
Training loss: 2.5040245056152344
Validation loss: 2.574600327399469

Epoch: 6| Step: 8
Training loss: 2.568141222000122
Validation loss: 2.5734259159334245

Epoch: 6| Step: 9
Training loss: 3.047651529312134
Validation loss: 2.579482529752998

Epoch: 6| Step: 10
Training loss: 2.294081687927246
Validation loss: 2.57521919281252

Epoch: 6| Step: 11
Training loss: 3.169590711593628
Validation loss: 2.5772127951345136

Epoch: 6| Step: 12
Training loss: 3.2509775161743164
Validation loss: 2.574086396924911

Epoch: 6| Step: 13
Training loss: 1.7558412551879883
Validation loss: 2.581003891524448

Epoch: 29| Step: 0
Training loss: 2.7039687633514404
Validation loss: 2.587889917435185

Epoch: 6| Step: 1
Training loss: 2.7670645713806152
Validation loss: 2.6023982083925636

Epoch: 6| Step: 2
Training loss: 2.1330339908599854
Validation loss: 2.5796036028092906

Epoch: 6| Step: 3
Training loss: 2.469834089279175
Validation loss: 2.567820038846744

Epoch: 6| Step: 4
Training loss: 2.321272373199463
Validation loss: 2.5679717525359123

Epoch: 6| Step: 5
Training loss: 3.117100715637207
Validation loss: 2.5736879687155447

Epoch: 6| Step: 6
Training loss: 2.295055389404297
Validation loss: 2.578899106671733

Epoch: 6| Step: 7
Training loss: 2.550022602081299
Validation loss: 2.5956664059751775

Epoch: 6| Step: 8
Training loss: 3.551146984100342
Validation loss: 2.603164188323482

Epoch: 6| Step: 9
Training loss: 3.2910165786743164
Validation loss: 2.5872888436881443

Epoch: 6| Step: 10
Training loss: 3.0405337810516357
Validation loss: 2.5759936532666607

Epoch: 6| Step: 11
Training loss: 3.3224358558654785
Validation loss: 2.5722196076505925

Epoch: 6| Step: 12
Training loss: 2.493084669113159
Validation loss: 2.568808473566527

Epoch: 6| Step: 13
Training loss: 2.8892202377319336
Validation loss: 2.5663606915422665

Epoch: 30| Step: 0
Training loss: 3.0930368900299072
Validation loss: 2.5642929230966875

Epoch: 6| Step: 1
Training loss: 2.6191253662109375
Validation loss: 2.565048207518875

Epoch: 6| Step: 2
Training loss: 3.025195598602295
Validation loss: 2.570287976213681

Epoch: 6| Step: 3
Training loss: 2.0555670261383057
Validation loss: 2.598087808137299

Epoch: 6| Step: 4
Training loss: 3.2571828365325928
Validation loss: 2.6081021216607865

Epoch: 6| Step: 5
Training loss: 2.60917067527771
Validation loss: 2.6177571127491612

Epoch: 6| Step: 6
Training loss: 2.705477237701416
Validation loss: 2.6134062454264653

Epoch: 6| Step: 7
Training loss: 2.0844168663024902
Validation loss: 2.6002047984830794

Epoch: 6| Step: 8
Training loss: 2.205322265625
Validation loss: 2.56749040080655

Epoch: 6| Step: 9
Training loss: 2.775646209716797
Validation loss: 2.567158781072145

Epoch: 6| Step: 10
Training loss: 3.1597540378570557
Validation loss: 2.568963832752679

Epoch: 6| Step: 11
Training loss: 2.9809162616729736
Validation loss: 2.571634102893132

Epoch: 6| Step: 12
Training loss: 3.3763163089752197
Validation loss: 2.577107060340143

Epoch: 6| Step: 13
Training loss: 2.809535264968872
Validation loss: 2.5816226159372637

Epoch: 31| Step: 0
Training loss: 2.7006359100341797
Validation loss: 2.5852093286411737

Epoch: 6| Step: 1
Training loss: 3.1383578777313232
Validation loss: 2.585017957995015

Epoch: 6| Step: 2
Training loss: 3.09201979637146
Validation loss: 2.576933007086477

Epoch: 6| Step: 3
Training loss: 2.4888505935668945
Validation loss: 2.575096091916484

Epoch: 6| Step: 4
Training loss: 2.2831101417541504
Validation loss: 2.57201753124114

Epoch: 6| Step: 5
Training loss: 3.5483903884887695
Validation loss: 2.565826790307158

Epoch: 6| Step: 6
Training loss: 2.658831834793091
Validation loss: 2.5640103791349675

Epoch: 6| Step: 7
Training loss: 2.3873350620269775
Validation loss: 2.5633586786126576

Epoch: 6| Step: 8
Training loss: 3.2485127449035645
Validation loss: 2.5618546291064193

Epoch: 6| Step: 9
Training loss: 1.9323627948760986
Validation loss: 2.5672773033060055

Epoch: 6| Step: 10
Training loss: 2.9430992603302
Validation loss: 2.582234110883487

Epoch: 6| Step: 11
Training loss: 2.578564405441284
Validation loss: 2.5709863990865727

Epoch: 6| Step: 12
Training loss: 3.3258306980133057
Validation loss: 2.5781948028072232

Epoch: 6| Step: 13
Training loss: 2.4487504959106445
Validation loss: 2.5471277826575824

Epoch: 32| Step: 0
Training loss: 2.734490156173706
Validation loss: 2.548429209698913

Epoch: 6| Step: 1
Training loss: 2.6996946334838867
Validation loss: 2.549328475870112

Epoch: 6| Step: 2
Training loss: 2.9697153568267822
Validation loss: 2.555091852782875

Epoch: 6| Step: 3
Training loss: 3.4065005779266357
Validation loss: 2.5678815572492537

Epoch: 6| Step: 4
Training loss: 2.8546833992004395
Validation loss: 2.576179696667579

Epoch: 6| Step: 5
Training loss: 2.641695499420166
Validation loss: 2.582426154485313

Epoch: 6| Step: 6
Training loss: 2.3966073989868164
Validation loss: 2.559903762673819

Epoch: 6| Step: 7
Training loss: 2.6655335426330566
Validation loss: 2.553217949405793

Epoch: 6| Step: 8
Training loss: 2.201289653778076
Validation loss: 2.54333431490006

Epoch: 6| Step: 9
Training loss: 3.133533477783203
Validation loss: 2.5490250920736663

Epoch: 6| Step: 10
Training loss: 3.5649890899658203
Validation loss: 2.55229413893915

Epoch: 6| Step: 11
Training loss: 2.1290698051452637
Validation loss: 2.5514873022674234

Epoch: 6| Step: 12
Training loss: 2.3469977378845215
Validation loss: 2.539562048450593

Epoch: 6| Step: 13
Training loss: 2.8776097297668457
Validation loss: 2.5367427743891233

Epoch: 33| Step: 0
Training loss: 2.779303550720215
Validation loss: 2.5380359618894515

Epoch: 6| Step: 1
Training loss: 3.0417678356170654
Validation loss: 2.53742838674976

Epoch: 6| Step: 2
Training loss: 2.7948849201202393
Validation loss: 2.5385687915227746

Epoch: 6| Step: 3
Training loss: 2.6274914741516113
Validation loss: 2.537355387082664

Epoch: 6| Step: 4
Training loss: 3.0268702507019043
Validation loss: 2.5384121479526645

Epoch: 6| Step: 5
Training loss: 1.9796535968780518
Validation loss: 2.53428997788378

Epoch: 6| Step: 6
Training loss: 3.8196868896484375
Validation loss: 2.534597627578243

Epoch: 6| Step: 7
Training loss: 2.909125328063965
Validation loss: 2.5334009252568728

Epoch: 6| Step: 8
Training loss: 2.5967869758605957
Validation loss: 2.5319988830115205

Epoch: 6| Step: 9
Training loss: 2.082723617553711
Validation loss: 2.529366675243583

Epoch: 6| Step: 10
Training loss: 2.354224681854248
Validation loss: 2.5294358499588503

Epoch: 6| Step: 11
Training loss: 2.7917842864990234
Validation loss: 2.527331313779277

Epoch: 6| Step: 12
Training loss: 2.4279656410217285
Validation loss: 2.5284290518811954

Epoch: 6| Step: 13
Training loss: 3.499088764190674
Validation loss: 2.528515072279079

Epoch: 34| Step: 0
Training loss: 2.727532386779785
Validation loss: 2.5348332928073023

Epoch: 6| Step: 1
Training loss: 2.4486727714538574
Validation loss: 2.534824930211549

Epoch: 6| Step: 2
Training loss: 2.3572795391082764
Validation loss: 2.538338602230113

Epoch: 6| Step: 3
Training loss: 3.155379295349121
Validation loss: 2.5387636564111196

Epoch: 6| Step: 4
Training loss: 2.524876594543457
Validation loss: 2.523239020378359

Epoch: 6| Step: 5
Training loss: 2.3308088779449463
Validation loss: 2.50775436944859

Epoch: 6| Step: 6
Training loss: 2.433271884918213
Validation loss: 2.5038395004887737

Epoch: 6| Step: 7
Training loss: 2.917421817779541
Validation loss: 2.496936562240765

Epoch: 6| Step: 8
Training loss: 3.4094324111938477
Validation loss: 2.5001969363099787

Epoch: 6| Step: 9
Training loss: 2.4853856563568115
Validation loss: 2.495681175621607

Epoch: 6| Step: 10
Training loss: 2.453413963317871
Validation loss: 2.4954735925120692

Epoch: 6| Step: 11
Training loss: 2.5714242458343506
Validation loss: 2.4989974319293933

Epoch: 6| Step: 12
Training loss: 3.467970371246338
Validation loss: 2.5067893305132465

Epoch: 6| Step: 13
Training loss: 2.888103485107422
Validation loss: 2.5143224321385866

Epoch: 35| Step: 0
Training loss: 2.2191975116729736
Validation loss: 2.515644314468548

Epoch: 6| Step: 1
Training loss: 2.5301687717437744
Validation loss: 2.521366068111953

Epoch: 6| Step: 2
Training loss: 2.63569974899292
Validation loss: 2.5261581841335503

Epoch: 6| Step: 3
Training loss: 3.830495595932007
Validation loss: 2.547984056575324

Epoch: 6| Step: 4
Training loss: 2.6149871349334717
Validation loss: 2.543183729212771

Epoch: 6| Step: 5
Training loss: 3.373563766479492
Validation loss: 2.5563858760300504

Epoch: 6| Step: 6
Training loss: 3.0819525718688965
Validation loss: 2.5315505381553405

Epoch: 6| Step: 7
Training loss: 3.0657265186309814
Validation loss: 2.5203781897021877

Epoch: 6| Step: 8
Training loss: 2.3868584632873535
Validation loss: 2.5076868213633055

Epoch: 6| Step: 9
Training loss: 1.9961061477661133
Validation loss: 2.496307216664796

Epoch: 6| Step: 10
Training loss: 1.9027023315429688
Validation loss: 2.4858445941760974

Epoch: 6| Step: 11
Training loss: 1.9547137022018433
Validation loss: 2.497917680330174

Epoch: 6| Step: 12
Training loss: 3.436117649078369
Validation loss: 2.502988802489414

Epoch: 6| Step: 13
Training loss: 3.111334800720215
Validation loss: 2.500472440514513

Epoch: 36| Step: 0
Training loss: 3.1676993370056152
Validation loss: 2.487624540123888

Epoch: 6| Step: 1
Training loss: 2.5873451232910156
Validation loss: 2.4844777814803587

Epoch: 6| Step: 2
Training loss: 3.4137706756591797
Validation loss: 2.488777070917109

Epoch: 6| Step: 3
Training loss: 2.504730463027954
Validation loss: 2.488316512876941

Epoch: 6| Step: 4
Training loss: 2.514775276184082
Validation loss: 2.4887735074566257

Epoch: 6| Step: 5
Training loss: 2.6452603340148926
Validation loss: 2.4947142806104434

Epoch: 6| Step: 6
Training loss: 2.6696624755859375
Validation loss: 2.4926187376822195

Epoch: 6| Step: 7
Training loss: 1.7337400913238525
Validation loss: 2.4972124074095037

Epoch: 6| Step: 8
Training loss: 2.987154960632324
Validation loss: 2.4956143492011615

Epoch: 6| Step: 9
Training loss: 2.688058376312256
Validation loss: 2.4933010942192486

Epoch: 6| Step: 10
Training loss: 2.567525863647461
Validation loss: 2.4853143512561755

Epoch: 6| Step: 11
Training loss: 2.5529654026031494
Validation loss: 2.4805698215320544

Epoch: 6| Step: 12
Training loss: 2.726818799972534
Validation loss: 2.4740707079569497

Epoch: 6| Step: 13
Training loss: 3.415050506591797
Validation loss: 2.4698335111782117

Epoch: 37| Step: 0
Training loss: 2.254866123199463
Validation loss: 2.4718081899868545

Epoch: 6| Step: 1
Training loss: 2.8422422409057617
Validation loss: 2.479175265117358

Epoch: 6| Step: 2
Training loss: 2.5454137325286865
Validation loss: 2.4739499989376275

Epoch: 6| Step: 3
Training loss: 3.371365547180176
Validation loss: 2.4698895638988865

Epoch: 6| Step: 4
Training loss: 2.2902824878692627
Validation loss: 2.4670000717204106

Epoch: 6| Step: 5
Training loss: 2.204787254333496
Validation loss: 2.463745747843096

Epoch: 6| Step: 6
Training loss: 3.031970500946045
Validation loss: 2.465007053908481

Epoch: 6| Step: 7
Training loss: 2.5474746227264404
Validation loss: 2.4681645593335553

Epoch: 6| Step: 8
Training loss: 2.6113502979278564
Validation loss: 2.466714664172101

Epoch: 6| Step: 9
Training loss: 3.2317886352539062
Validation loss: 2.466906524473621

Epoch: 6| Step: 10
Training loss: 2.4302890300750732
Validation loss: 2.4659490764781995

Epoch: 6| Step: 11
Training loss: 2.527052879333496
Validation loss: 2.466470774783883

Epoch: 6| Step: 12
Training loss: 3.2925961017608643
Validation loss: 2.469813382753762

Epoch: 6| Step: 13
Training loss: 2.436321973800659
Validation loss: 2.474925269362747

Epoch: 38| Step: 0
Training loss: 2.8245935440063477
Validation loss: 2.480967608831262

Epoch: 6| Step: 1
Training loss: 2.5037288665771484
Validation loss: 2.5257037185853526

Epoch: 6| Step: 2
Training loss: 2.9092648029327393
Validation loss: 2.53013753121899

Epoch: 6| Step: 3
Training loss: 3.440999984741211
Validation loss: 2.5351489128605014

Epoch: 6| Step: 4
Training loss: 2.281599760055542
Validation loss: 2.51380988090269

Epoch: 6| Step: 5
Training loss: 3.4328551292419434
Validation loss: 2.4899926852154475

Epoch: 6| Step: 6
Training loss: 2.0265958309173584
Validation loss: 2.472026659596351

Epoch: 6| Step: 7
Training loss: 2.544750928878784
Validation loss: 2.4574283758799234

Epoch: 6| Step: 8
Training loss: 2.554107666015625
Validation loss: 2.4619420728375836

Epoch: 6| Step: 9
Training loss: 2.9436302185058594
Validation loss: 2.4621342715396675

Epoch: 6| Step: 10
Training loss: 2.587512493133545
Validation loss: 2.464290286905022

Epoch: 6| Step: 11
Training loss: 2.382253646850586
Validation loss: 2.4675419740779425

Epoch: 6| Step: 12
Training loss: 2.820709705352783
Validation loss: 2.470560250743743

Epoch: 6| Step: 13
Training loss: 2.5061051845550537
Validation loss: 2.4724498948743268

Epoch: 39| Step: 0
Training loss: 2.4932165145874023
Validation loss: 2.4850572898823726

Epoch: 6| Step: 1
Training loss: 2.8254165649414062
Validation loss: 2.48609431071948

Epoch: 6| Step: 2
Training loss: 2.638868808746338
Validation loss: 2.4809755740627164

Epoch: 6| Step: 3
Training loss: 3.1013591289520264
Validation loss: 2.4645288452025382

Epoch: 6| Step: 4
Training loss: 2.6508193016052246
Validation loss: 2.457245662648191

Epoch: 6| Step: 5
Training loss: 2.9053707122802734
Validation loss: 2.4509849240702968

Epoch: 6| Step: 6
Training loss: 2.1385364532470703
Validation loss: 2.4526678567291587

Epoch: 6| Step: 7
Training loss: 3.025900363922119
Validation loss: 2.457487972833777

Epoch: 6| Step: 8
Training loss: 2.8801326751708984
Validation loss: 2.4599067190642

Epoch: 6| Step: 9
Training loss: 3.3612680435180664
Validation loss: 2.471254006508858

Epoch: 6| Step: 10
Training loss: 3.831087112426758
Validation loss: 2.4676807926547144

Epoch: 6| Step: 11
Training loss: 2.1455841064453125
Validation loss: 2.461827555010396

Epoch: 6| Step: 12
Training loss: 1.699714183807373
Validation loss: 2.4551117266378095

Epoch: 6| Step: 13
Training loss: 1.6608315706253052
Validation loss: 2.4539525790881087

Epoch: 40| Step: 0
Training loss: 2.904029130935669
Validation loss: 2.4532918058415896

Epoch: 6| Step: 1
Training loss: 2.9567153453826904
Validation loss: 2.4559838464183192

Epoch: 6| Step: 2
Training loss: 2.881850481033325
Validation loss: 2.456534206226308

Epoch: 6| Step: 3
Training loss: 3.183715581893921
Validation loss: 2.4547134650650846

Epoch: 6| Step: 4
Training loss: 3.042693614959717
Validation loss: 2.4559575485926803

Epoch: 6| Step: 5
Training loss: 3.4859936237335205
Validation loss: 2.456563203565536

Epoch: 6| Step: 6
Training loss: 2.2921175956726074
Validation loss: 2.452170330991027

Epoch: 6| Step: 7
Training loss: 1.775298833847046
Validation loss: 2.445879918272777

Epoch: 6| Step: 8
Training loss: 2.1683239936828613
Validation loss: 2.449765225892426

Epoch: 6| Step: 9
Training loss: 3.1650028228759766
Validation loss: 2.451512421331098

Epoch: 6| Step: 10
Training loss: 2.6824026107788086
Validation loss: 2.4526554256357174

Epoch: 6| Step: 11
Training loss: 2.112804412841797
Validation loss: 2.4673938443583827

Epoch: 6| Step: 12
Training loss: 2.2277565002441406
Validation loss: 2.4539608032472673

Epoch: 6| Step: 13
Training loss: 2.625037670135498
Validation loss: 2.450462605363579

Epoch: 41| Step: 0
Training loss: 2.897670269012451
Validation loss: 2.4457362108333136

Epoch: 6| Step: 1
Training loss: 2.259053945541382
Validation loss: 2.4416443827331706

Epoch: 6| Step: 2
Training loss: 2.6354575157165527
Validation loss: 2.4389330699879634

Epoch: 6| Step: 3
Training loss: 2.6648941040039062
Validation loss: 2.440100439133183

Epoch: 6| Step: 4
Training loss: 2.512047290802002
Validation loss: 2.4398790303096978

Epoch: 6| Step: 5
Training loss: 2.1111035346984863
Validation loss: 2.440322688830796

Epoch: 6| Step: 6
Training loss: 2.8072586059570312
Validation loss: 2.4417563100014963

Epoch: 6| Step: 7
Training loss: 2.782496929168701
Validation loss: 2.446438007457282

Epoch: 6| Step: 8
Training loss: 3.715388774871826
Validation loss: 2.446671485900879

Epoch: 6| Step: 9
Training loss: 2.492659568786621
Validation loss: 2.4516694007381314

Epoch: 6| Step: 10
Training loss: 2.134157180786133
Validation loss: 2.4607542278946086

Epoch: 6| Step: 11
Training loss: 2.804096221923828
Validation loss: 2.4788455040224138

Epoch: 6| Step: 12
Training loss: 2.8442912101745605
Validation loss: 2.4855083880885953

Epoch: 6| Step: 13
Training loss: 2.774847984313965
Validation loss: 2.472294471597159

Epoch: 42| Step: 0
Training loss: 3.497957229614258
Validation loss: 2.4576501384858163

Epoch: 6| Step: 1
Training loss: 3.301053524017334
Validation loss: 2.4413869816769838

Epoch: 6| Step: 2
Training loss: 2.7962048053741455
Validation loss: 2.437011223967357

Epoch: 6| Step: 3
Training loss: 2.325801372528076
Validation loss: 2.4330309847349763

Epoch: 6| Step: 4
Training loss: 2.4054317474365234
Validation loss: 2.4365033821393083

Epoch: 6| Step: 5
Training loss: 2.4406800270080566
Validation loss: 2.4356666354722876

Epoch: 6| Step: 6
Training loss: 2.5178990364074707
Validation loss: 2.435226509647985

Epoch: 6| Step: 7
Training loss: 2.971961736679077
Validation loss: 2.429581780587473

Epoch: 6| Step: 8
Training loss: 3.1079940795898438
Validation loss: 2.42958471339236

Epoch: 6| Step: 9
Training loss: 1.9429287910461426
Validation loss: 2.432585846993231

Epoch: 6| Step: 10
Training loss: 2.4693500995635986
Validation loss: 2.427470373850997

Epoch: 6| Step: 11
Training loss: 2.171436071395874
Validation loss: 2.428337297131938

Epoch: 6| Step: 12
Training loss: 2.9594712257385254
Validation loss: 2.428958034002653

Epoch: 6| Step: 13
Training loss: 2.4450652599334717
Validation loss: 2.4313394818254697

Epoch: 43| Step: 0
Training loss: 3.125016212463379
Validation loss: 2.429794260250625

Epoch: 6| Step: 1
Training loss: 2.8343207836151123
Validation loss: 2.43818252061003

Epoch: 6| Step: 2
Training loss: 2.744218349456787
Validation loss: 2.4617936995721634

Epoch: 6| Step: 3
Training loss: 3.236790180206299
Validation loss: 2.483567689054756

Epoch: 6| Step: 4
Training loss: 2.1896767616271973
Validation loss: 2.4667210758373304

Epoch: 6| Step: 5
Training loss: 3.0450353622436523
Validation loss: 2.4327007262937483

Epoch: 6| Step: 6
Training loss: 2.6697816848754883
Validation loss: 2.4216067714075886

Epoch: 6| Step: 7
Training loss: 2.5389649868011475
Validation loss: 2.4211481104614916

Epoch: 6| Step: 8
Training loss: 2.048417568206787
Validation loss: 2.4232570022665043

Epoch: 6| Step: 9
Training loss: 2.684664487838745
Validation loss: 2.4264071936248452

Epoch: 6| Step: 10
Training loss: 2.822195529937744
Validation loss: 2.427143012323687

Epoch: 6| Step: 11
Training loss: 2.909569501876831
Validation loss: 2.4386228797256306

Epoch: 6| Step: 12
Training loss: 2.3244190216064453
Validation loss: 2.4540234765698834

Epoch: 6| Step: 13
Training loss: 1.715689778327942
Validation loss: 2.4684861834331224

Epoch: 44| Step: 0
Training loss: 3.029496908187866
Validation loss: 2.475688067815637

Epoch: 6| Step: 1
Training loss: 2.2967722415924072
Validation loss: 2.4780103288671023

Epoch: 6| Step: 2
Training loss: 2.339850902557373
Validation loss: 2.473132908985179

Epoch: 6| Step: 3
Training loss: 2.8685784339904785
Validation loss: 2.4405230834919918

Epoch: 6| Step: 4
Training loss: 3.1891791820526123
Validation loss: 2.426698115564162

Epoch: 6| Step: 5
Training loss: 2.6303110122680664
Validation loss: 2.416378682659518

Epoch: 6| Step: 6
Training loss: 3.6679091453552246
Validation loss: 2.416817885573192

Epoch: 6| Step: 7
Training loss: 1.8593674898147583
Validation loss: 2.4171466160846014

Epoch: 6| Step: 8
Training loss: 2.695910692214966
Validation loss: 2.4187465739506546

Epoch: 6| Step: 9
Training loss: 2.929624557495117
Validation loss: 2.4202291504029305

Epoch: 6| Step: 10
Training loss: 1.642587423324585
Validation loss: 2.412756040532102

Epoch: 6| Step: 11
Training loss: 2.039989471435547
Validation loss: 2.415737044426703

Epoch: 6| Step: 12
Training loss: 3.522559404373169
Validation loss: 2.4137586726937243

Epoch: 6| Step: 13
Training loss: 2.4409985542297363
Validation loss: 2.41667987069776

Epoch: 45| Step: 0
Training loss: 2.4698126316070557
Validation loss: 2.4195601247972056

Epoch: 6| Step: 1
Training loss: 2.7337090969085693
Validation loss: 2.41695471220119

Epoch: 6| Step: 2
Training loss: 1.83224618434906
Validation loss: 2.4185128211975098

Epoch: 6| Step: 3
Training loss: 2.247933864593506
Validation loss: 2.4180672886551067

Epoch: 6| Step: 4
Training loss: 3.0330939292907715
Validation loss: 2.421574769481536

Epoch: 6| Step: 5
Training loss: 2.756951332092285
Validation loss: 2.432911293480986

Epoch: 6| Step: 6
Training loss: 2.122596025466919
Validation loss: 2.430579875105171

Epoch: 6| Step: 7
Training loss: 2.4995744228363037
Validation loss: 2.436269006421489

Epoch: 6| Step: 8
Training loss: 2.433791160583496
Validation loss: 2.451480006658903

Epoch: 6| Step: 9
Training loss: 3.345346212387085
Validation loss: 2.4347018170100387

Epoch: 6| Step: 10
Training loss: 3.8405003547668457
Validation loss: 2.42406952252952

Epoch: 6| Step: 11
Training loss: 2.000558853149414
Validation loss: 2.410187772525254

Epoch: 6| Step: 12
Training loss: 3.1000256538391113
Validation loss: 2.405729463023524

Epoch: 6| Step: 13
Training loss: 2.9161198139190674
Validation loss: 2.408957540348012

Epoch: 46| Step: 0
Training loss: 2.337785243988037
Validation loss: 2.416193390405306

Epoch: 6| Step: 1
Training loss: 2.844191551208496
Validation loss: 2.4157519366151545

Epoch: 6| Step: 2
Training loss: 3.698117256164551
Validation loss: 2.4182865670932236

Epoch: 6| Step: 3
Training loss: 1.9811443090438843
Validation loss: 2.415724198023478

Epoch: 6| Step: 4
Training loss: 2.225633144378662
Validation loss: 2.410142583231772

Epoch: 6| Step: 5
Training loss: 2.639263153076172
Validation loss: 2.403496209011283

Epoch: 6| Step: 6
Training loss: 2.601914405822754
Validation loss: 2.406252175249079

Epoch: 6| Step: 7
Training loss: 1.9969093799591064
Validation loss: 2.417085584773812

Epoch: 6| Step: 8
Training loss: 3.0367722511291504
Validation loss: 2.4389374333043254

Epoch: 6| Step: 9
Training loss: 3.1552622318267822
Validation loss: 2.447893947683355

Epoch: 6| Step: 10
Training loss: 2.9362778663635254
Validation loss: 2.4597200219349196

Epoch: 6| Step: 11
Training loss: 2.5267603397369385
Validation loss: 2.4733805579523884

Epoch: 6| Step: 12
Training loss: 2.7030673027038574
Validation loss: 2.4856237249989666

Epoch: 6| Step: 13
Training loss: 2.6702966690063477
Validation loss: 2.4650838349455144

Epoch: 47| Step: 0
Training loss: 2.9494380950927734
Validation loss: 2.4483501424071608

Epoch: 6| Step: 1
Training loss: 2.69299578666687
Validation loss: 2.4155587060477144

Epoch: 6| Step: 2
Training loss: 2.670081377029419
Validation loss: 2.405340195983969

Epoch: 6| Step: 3
Training loss: 2.495926856994629
Validation loss: 2.3989638410588747

Epoch: 6| Step: 4
Training loss: 2.785355567932129
Validation loss: 2.3968300422032676

Epoch: 6| Step: 5
Training loss: 3.2156190872192383
Validation loss: 2.3960644250274985

Epoch: 6| Step: 6
Training loss: 2.371734380722046
Validation loss: 2.410380748010451

Epoch: 6| Step: 7
Training loss: 2.569632053375244
Validation loss: 2.4272505749938307

Epoch: 6| Step: 8
Training loss: 2.957174301147461
Validation loss: 2.4252550114867506

Epoch: 6| Step: 9
Training loss: 2.5936245918273926
Validation loss: 2.4196321477172194

Epoch: 6| Step: 10
Training loss: 1.9006162881851196
Validation loss: 2.404092514386741

Epoch: 6| Step: 11
Training loss: 1.8411684036254883
Validation loss: 2.3985796384913947

Epoch: 6| Step: 12
Training loss: 2.4830737113952637
Validation loss: 2.403912967251193

Epoch: 6| Step: 13
Training loss: 4.512086868286133
Validation loss: 2.405957906476913

Epoch: 48| Step: 0
Training loss: 2.496049404144287
Validation loss: 2.404405581053867

Epoch: 6| Step: 1
Training loss: 2.800257682800293
Validation loss: 2.400768951703143

Epoch: 6| Step: 2
Training loss: 2.8293704986572266
Validation loss: 2.4025912207941853

Epoch: 6| Step: 3
Training loss: 2.156519889831543
Validation loss: 2.4070552472145326

Epoch: 6| Step: 4
Training loss: 1.982121229171753
Validation loss: 2.4076157334030315

Epoch: 6| Step: 5
Training loss: 2.706409454345703
Validation loss: 2.407830261415051

Epoch: 6| Step: 6
Training loss: 2.884650707244873
Validation loss: 2.4102906411693943

Epoch: 6| Step: 7
Training loss: 3.5141351222991943
Validation loss: 2.4079014767882643

Epoch: 6| Step: 8
Training loss: 2.6854991912841797
Validation loss: 2.3995811144510903

Epoch: 6| Step: 9
Training loss: 2.579415798187256
Validation loss: 2.3979093900290867

Epoch: 6| Step: 10
Training loss: 2.580307960510254
Validation loss: 2.392910036989438

Epoch: 6| Step: 11
Training loss: 2.498721122741699
Validation loss: 2.394101781229819

Epoch: 6| Step: 12
Training loss: 2.647735357284546
Validation loss: 2.3939018826330862

Epoch: 6| Step: 13
Training loss: 2.5608255863189697
Validation loss: 2.3994282394327144

Epoch: 49| Step: 0
Training loss: 2.9817142486572266
Validation loss: 2.412564341739942

Epoch: 6| Step: 1
Training loss: 1.6937066316604614
Validation loss: 2.4111173973288587

Epoch: 6| Step: 2
Training loss: 2.949230432510376
Validation loss: 2.4221252177351262

Epoch: 6| Step: 3
Training loss: 2.7313036918640137
Validation loss: 2.426566434162919

Epoch: 6| Step: 4
Training loss: 2.778164863586426
Validation loss: 2.4240959741735972

Epoch: 6| Step: 5
Training loss: 2.6554577350616455
Validation loss: 2.4120807032431326

Epoch: 6| Step: 6
Training loss: 2.9433207511901855
Validation loss: 2.414532523001394

Epoch: 6| Step: 7
Training loss: 3.0598535537719727
Validation loss: 2.414974938156784

Epoch: 6| Step: 8
Training loss: 2.5646257400512695
Validation loss: 2.41256574661501

Epoch: 6| Step: 9
Training loss: 2.391780376434326
Validation loss: 2.4052664977247997

Epoch: 6| Step: 10
Training loss: 2.5611073970794678
Validation loss: 2.392399764830066

Epoch: 6| Step: 11
Training loss: 1.9746413230895996
Validation loss: 2.377097042657996

Epoch: 6| Step: 12
Training loss: 2.899587631225586
Validation loss: 2.380473482993341

Epoch: 6| Step: 13
Training loss: 2.6745429039001465
Validation loss: 2.3824611274144982

Epoch: 50| Step: 0
Training loss: 3.5448813438415527
Validation loss: 2.386432687441508

Epoch: 6| Step: 1
Training loss: 2.4764866828918457
Validation loss: 2.3926943707209762

Epoch: 6| Step: 2
Training loss: 2.7606396675109863
Validation loss: 2.397570063990931

Epoch: 6| Step: 3
Training loss: 2.210491180419922
Validation loss: 2.3921316951833744

Epoch: 6| Step: 4
Training loss: 2.3700757026672363
Validation loss: 2.386460801606537

Epoch: 6| Step: 5
Training loss: 2.578768253326416
Validation loss: 2.38980689612768

Epoch: 6| Step: 6
Training loss: 2.9216980934143066
Validation loss: 2.379277315191043

Epoch: 6| Step: 7
Training loss: 2.608128309249878
Validation loss: 2.3766029124618857

Epoch: 6| Step: 8
Training loss: 2.3975284099578857
Validation loss: 2.376364933547153

Epoch: 6| Step: 9
Training loss: 2.8945324420928955
Validation loss: 2.3728736190385717

Epoch: 6| Step: 10
Training loss: 2.1292340755462646
Validation loss: 2.3821476838921987

Epoch: 6| Step: 11
Training loss: 2.6985409259796143
Validation loss: 2.402989351621238

Epoch: 6| Step: 12
Training loss: 2.5565662384033203
Validation loss: 2.42771650386113

Epoch: 6| Step: 13
Training loss: 2.880812168121338
Validation loss: 2.462835798981369

Epoch: 51| Step: 0
Training loss: 2.8739781379699707
Validation loss: 2.5175319281957482

Epoch: 6| Step: 1
Training loss: 2.85024356842041
Validation loss: 2.5302865095036005

Epoch: 6| Step: 2
Training loss: 2.0522546768188477
Validation loss: 2.4725342309603127

Epoch: 6| Step: 3
Training loss: 2.5767221450805664
Validation loss: 2.4176554397870134

Epoch: 6| Step: 4
Training loss: 3.0761454105377197
Validation loss: 2.4017635878696235

Epoch: 6| Step: 5
Training loss: 2.472609043121338
Validation loss: 2.3853648324166574

Epoch: 6| Step: 6
Training loss: 2.461582660675049
Validation loss: 2.3723374617997037

Epoch: 6| Step: 7
Training loss: 2.5142369270324707
Validation loss: 2.364697592232817

Epoch: 6| Step: 8
Training loss: 2.2857799530029297
Validation loss: 2.3627590851117204

Epoch: 6| Step: 9
Training loss: 2.9360945224761963
Validation loss: 2.3637267479332547

Epoch: 6| Step: 10
Training loss: 2.1010899543762207
Validation loss: 2.359882108626827

Epoch: 6| Step: 11
Training loss: 3.1885645389556885
Validation loss: 2.3608283612035934

Epoch: 6| Step: 12
Training loss: 2.954021453857422
Validation loss: 2.368346029712308

Epoch: 6| Step: 13
Training loss: 2.3707826137542725
Validation loss: 2.374832699375768

Epoch: 52| Step: 0
Training loss: 3.2327866554260254
Validation loss: 2.375558464757858

Epoch: 6| Step: 1
Training loss: 2.79116153717041
Validation loss: 2.379828355645621

Epoch: 6| Step: 2
Training loss: 3.3845295906066895
Validation loss: 2.389297510987969

Epoch: 6| Step: 3
Training loss: 1.709438681602478
Validation loss: 2.407965878004669

Epoch: 6| Step: 4
Training loss: 2.9335365295410156
Validation loss: 2.4352256739011375

Epoch: 6| Step: 5
Training loss: 2.804992198944092
Validation loss: 2.4636945878305743

Epoch: 6| Step: 6
Training loss: 2.005676746368408
Validation loss: 2.4541901080839095

Epoch: 6| Step: 7
Training loss: 2.686142921447754
Validation loss: 2.4245520932700044

Epoch: 6| Step: 8
Training loss: 2.94718337059021
Validation loss: 2.410875407598352

Epoch: 6| Step: 9
Training loss: 2.8501453399658203
Validation loss: 2.387916480341265

Epoch: 6| Step: 10
Training loss: 2.561082363128662
Validation loss: 2.3616211747610443

Epoch: 6| Step: 11
Training loss: 2.0570409297943115
Validation loss: 2.3644635677337646

Epoch: 6| Step: 12
Training loss: 2.5968732833862305
Validation loss: 2.364743125054144

Epoch: 6| Step: 13
Training loss: 2.1441638469696045
Validation loss: 2.367152187132066

Epoch: 53| Step: 0
Training loss: 2.8457987308502197
Validation loss: 2.3640508190278084

Epoch: 6| Step: 1
Training loss: 2.4902126789093018
Validation loss: 2.3610963641956286

Epoch: 6| Step: 2
Training loss: 2.249443531036377
Validation loss: 2.356859540426603

Epoch: 6| Step: 3
Training loss: 2.643045425415039
Validation loss: 2.356974947837091

Epoch: 6| Step: 4
Training loss: 3.217573642730713
Validation loss: 2.3555473666037283

Epoch: 6| Step: 5
Training loss: 2.5853219032287598
Validation loss: 2.359921460510582

Epoch: 6| Step: 6
Training loss: 2.466383695602417
Validation loss: 2.3568606530466387

Epoch: 6| Step: 7
Training loss: 2.9574384689331055
Validation loss: 2.3565678032495643

Epoch: 6| Step: 8
Training loss: 2.4274373054504395
Validation loss: 2.355012778312929

Epoch: 6| Step: 9
Training loss: 3.0405454635620117
Validation loss: 2.360250375604117

Epoch: 6| Step: 10
Training loss: 2.309256076812744
Validation loss: 2.3641980899277555

Epoch: 6| Step: 11
Training loss: 1.8694840669631958
Validation loss: 2.370038999024258

Epoch: 6| Step: 12
Training loss: 2.9720327854156494
Validation loss: 2.3861488552503687

Epoch: 6| Step: 13
Training loss: 2.6729736328125
Validation loss: 2.394938915006576

Epoch: 54| Step: 0
Training loss: 2.653390884399414
Validation loss: 2.392389243648898

Epoch: 6| Step: 1
Training loss: 2.945525646209717
Validation loss: 2.397447737314368

Epoch: 6| Step: 2
Training loss: 2.7824923992156982
Validation loss: 2.4153392584093156

Epoch: 6| Step: 3
Training loss: 2.5182361602783203
Validation loss: 2.407232789583104

Epoch: 6| Step: 4
Training loss: 2.426696300506592
Validation loss: 2.3898330914076937

Epoch: 6| Step: 5
Training loss: 2.5198845863342285
Validation loss: 2.363433994272704

Epoch: 6| Step: 6
Training loss: 2.48884916305542
Validation loss: 2.350671919443274

Epoch: 6| Step: 7
Training loss: 2.263925075531006
Validation loss: 2.3400561424993698

Epoch: 6| Step: 8
Training loss: 3.0873188972473145
Validation loss: 2.3399251430265364

Epoch: 6| Step: 9
Training loss: 2.4685449600219727
Validation loss: 2.3516893335568008

Epoch: 6| Step: 10
Training loss: 2.1690969467163086
Validation loss: 2.3473753185682398

Epoch: 6| Step: 11
Training loss: 2.99153470993042
Validation loss: 2.3416496464001235

Epoch: 6| Step: 12
Training loss: 2.8094587326049805
Validation loss: 2.3413885024286087

Epoch: 6| Step: 13
Training loss: 2.7323131561279297
Validation loss: 2.3367999651098765

Epoch: 55| Step: 0
Training loss: 2.4962782859802246
Validation loss: 2.3401487899082962

Epoch: 6| Step: 1
Training loss: 2.8172128200531006
Validation loss: 2.346237018544187

Epoch: 6| Step: 2
Training loss: 2.2326643466949463
Validation loss: 2.3455915502322617

Epoch: 6| Step: 3
Training loss: 2.459651470184326
Validation loss: 2.3462781444672616

Epoch: 6| Step: 4
Training loss: 2.6344475746154785
Validation loss: 2.3488279696433776

Epoch: 6| Step: 5
Training loss: 2.505950927734375
Validation loss: 2.3580221514548025

Epoch: 6| Step: 6
Training loss: 2.6234421730041504
Validation loss: 2.368451192814817

Epoch: 6| Step: 7
Training loss: 2.541731834411621
Validation loss: 2.367185023523146

Epoch: 6| Step: 8
Training loss: 3.4817469120025635
Validation loss: 2.3606057987418225

Epoch: 6| Step: 9
Training loss: 2.972163200378418
Validation loss: 2.3517776458494124

Epoch: 6| Step: 10
Training loss: 1.806039571762085
Validation loss: 2.35132332258327

Epoch: 6| Step: 11
Training loss: 2.428666830062866
Validation loss: 2.3506855964660645

Epoch: 6| Step: 12
Training loss: 2.851099729537964
Validation loss: 2.3503323062773673

Epoch: 6| Step: 13
Training loss: 2.67374849319458
Validation loss: 2.3479792943564792

Epoch: 56| Step: 0
Training loss: 3.402894973754883
Validation loss: 2.3395365950881795

Epoch: 6| Step: 1
Training loss: 2.537795066833496
Validation loss: 2.336514180706393

Epoch: 6| Step: 2
Training loss: 2.380624771118164
Validation loss: 2.336941765200707

Epoch: 6| Step: 3
Training loss: 2.1022627353668213
Validation loss: 2.3413266879256054

Epoch: 6| Step: 4
Training loss: 2.783942222595215
Validation loss: 2.3538541127276678

Epoch: 6| Step: 5
Training loss: 3.442533016204834
Validation loss: 2.3738822116646716

Epoch: 6| Step: 6
Training loss: 3.06705904006958
Validation loss: 2.3676820634513773

Epoch: 6| Step: 7
Training loss: 2.581818103790283
Validation loss: 2.361053402705859

Epoch: 6| Step: 8
Training loss: 1.781036376953125
Validation loss: 2.3445652556675736

Epoch: 6| Step: 9
Training loss: 2.920499086380005
Validation loss: 2.341372166910479

Epoch: 6| Step: 10
Training loss: 1.7778966426849365
Validation loss: 2.337232840958462

Epoch: 6| Step: 11
Training loss: 2.446976661682129
Validation loss: 2.333817763995099

Epoch: 6| Step: 12
Training loss: 2.4933810234069824
Validation loss: 2.3290141192815637

Epoch: 6| Step: 13
Training loss: 2.9186689853668213
Validation loss: 2.3341009360487743

Epoch: 57| Step: 0
Training loss: 2.744277000427246
Validation loss: 2.331307557321364

Epoch: 6| Step: 1
Training loss: 2.976707935333252
Validation loss: 2.3364011113361647

Epoch: 6| Step: 2
Training loss: 2.065216064453125
Validation loss: 2.338059861172912

Epoch: 6| Step: 3
Training loss: 2.4240365028381348
Validation loss: 2.3430366362294843

Epoch: 6| Step: 4
Training loss: 3.5574347972869873
Validation loss: 2.339906782232305

Epoch: 6| Step: 5
Training loss: 2.464555025100708
Validation loss: 2.343452425413234

Epoch: 6| Step: 6
Training loss: 2.3611111640930176
Validation loss: 2.349559099443497

Epoch: 6| Step: 7
Training loss: 3.391061544418335
Validation loss: 2.359219499813613

Epoch: 6| Step: 8
Training loss: 2.2970709800720215
Validation loss: 2.372561731646138

Epoch: 6| Step: 9
Training loss: 1.8328938484191895
Validation loss: 2.3809618514071227

Epoch: 6| Step: 10
Training loss: 2.60646915435791
Validation loss: 2.4264623657349618

Epoch: 6| Step: 11
Training loss: 2.948397159576416
Validation loss: 2.4405971624517955

Epoch: 6| Step: 12
Training loss: 2.2052345275878906
Validation loss: 2.4164648696940434

Epoch: 6| Step: 13
Training loss: 2.3699393272399902
Validation loss: 2.3789863048061246

Epoch: 58| Step: 0
Training loss: 2.804898738861084
Validation loss: 2.3715437996772026

Epoch: 6| Step: 1
Training loss: 2.2780096530914307
Validation loss: 2.352574053631034

Epoch: 6| Step: 2
Training loss: 3.1430373191833496
Validation loss: 2.343484245320802

Epoch: 6| Step: 3
Training loss: 2.5244715213775635
Validation loss: 2.3335134701062272

Epoch: 6| Step: 4
Training loss: 2.8842015266418457
Validation loss: 2.3351735453451834

Epoch: 6| Step: 5
Training loss: 2.6545772552490234
Validation loss: 2.334145983060201

Epoch: 6| Step: 6
Training loss: 2.9943370819091797
Validation loss: 2.3424223161512807

Epoch: 6| Step: 7
Training loss: 3.1850509643554688
Validation loss: 2.352839869837607

Epoch: 6| Step: 8
Training loss: 3.064145803451538
Validation loss: 2.3461189731474845

Epoch: 6| Step: 9
Training loss: 1.6854444742202759
Validation loss: 2.3411099398007957

Epoch: 6| Step: 10
Training loss: 2.095175266265869
Validation loss: 2.339047357600222

Epoch: 6| Step: 11
Training loss: 1.936366319656372
Validation loss: 2.3514769308028685

Epoch: 6| Step: 12
Training loss: 2.463388442993164
Validation loss: 2.343571627011863

Epoch: 6| Step: 13
Training loss: 2.6321988105773926
Validation loss: 2.3438788793420278

Epoch: 59| Step: 0
Training loss: 1.997097373008728
Validation loss: 2.3417996770592144

Epoch: 6| Step: 1
Training loss: 2.7736992835998535
Validation loss: 2.339381625575404

Epoch: 6| Step: 2
Training loss: 2.8360652923583984
Validation loss: 2.3296258244463193

Epoch: 6| Step: 3
Training loss: 3.096522569656372
Validation loss: 2.3377021358859156

Epoch: 6| Step: 4
Training loss: 1.7309596538543701
Validation loss: 2.3274201885346444

Epoch: 6| Step: 5
Training loss: 2.0668702125549316
Validation loss: 2.325527775672174

Epoch: 6| Step: 6
Training loss: 2.5400445461273193
Validation loss: 2.3192638838162987

Epoch: 6| Step: 7
Training loss: 2.0199544429779053
Validation loss: 2.3202747427007204

Epoch: 6| Step: 8
Training loss: 2.5517630577087402
Validation loss: 2.3283325779822563

Epoch: 6| Step: 9
Training loss: 2.743908405303955
Validation loss: 2.327991429195609

Epoch: 6| Step: 10
Training loss: 2.9404025077819824
Validation loss: 2.320974432012086

Epoch: 6| Step: 11
Training loss: 2.4129905700683594
Validation loss: 2.332024751170989

Epoch: 6| Step: 12
Training loss: 3.040982246398926
Validation loss: 2.3311794291260424

Epoch: 6| Step: 13
Training loss: 4.062077522277832
Validation loss: 2.3432784259960218

Epoch: 60| Step: 0
Training loss: 2.9169437885284424
Validation loss: 2.3379946729188323

Epoch: 6| Step: 1
Training loss: 2.4063608646392822
Validation loss: 2.3302111651307795

Epoch: 6| Step: 2
Training loss: 2.1634249687194824
Validation loss: 2.3352782393014557

Epoch: 6| Step: 3
Training loss: 2.9660820960998535
Validation loss: 2.3262815654918714

Epoch: 6| Step: 4
Training loss: 3.240659475326538
Validation loss: 2.3241290289868592

Epoch: 6| Step: 5
Training loss: 2.5882859230041504
Validation loss: 2.317590891674001

Epoch: 6| Step: 6
Training loss: 2.5771279335021973
Validation loss: 2.3185733620838453

Epoch: 6| Step: 7
Training loss: 2.4933438301086426
Validation loss: 2.3423703819192867

Epoch: 6| Step: 8
Training loss: 2.2375710010528564
Validation loss: 2.3298638456611225

Epoch: 6| Step: 9
Training loss: 2.1378064155578613
Validation loss: 2.3422948955207743

Epoch: 6| Step: 10
Training loss: 2.1996512413024902
Validation loss: 2.355270706197267

Epoch: 6| Step: 11
Training loss: 1.8155330419540405
Validation loss: 2.343927808987197

Epoch: 6| Step: 12
Training loss: 3.662782669067383
Validation loss: 2.327527000058082

Epoch: 6| Step: 13
Training loss: 2.6913833618164062
Validation loss: 2.3118804167675715

Epoch: 61| Step: 0
Training loss: 2.1637771129608154
Validation loss: 2.303864989229428

Epoch: 6| Step: 1
Training loss: 1.9558727741241455
Validation loss: 2.3051062886432936

Epoch: 6| Step: 2
Training loss: 2.1383206844329834
Validation loss: 2.2996620529441425

Epoch: 6| Step: 3
Training loss: 3.87503981590271
Validation loss: 2.3017698077745337

Epoch: 6| Step: 4
Training loss: 2.511575222015381
Validation loss: 2.3013759710455455

Epoch: 6| Step: 5
Training loss: 2.5064380168914795
Validation loss: 2.3002919714937926

Epoch: 6| Step: 6
Training loss: 2.8630013465881348
Validation loss: 2.298770980168414

Epoch: 6| Step: 7
Training loss: 2.795046806335449
Validation loss: 2.2983900859791744

Epoch: 6| Step: 8
Training loss: 2.9322965145111084
Validation loss: 2.300578635226014

Epoch: 6| Step: 9
Training loss: 2.411195993423462
Validation loss: 2.3076504174099175

Epoch: 6| Step: 10
Training loss: 2.7798917293548584
Validation loss: 2.316880979845601

Epoch: 6| Step: 11
Training loss: 2.019683361053467
Validation loss: 2.323175417479648

Epoch: 6| Step: 12
Training loss: 2.6179850101470947
Validation loss: 2.3512065769523702

Epoch: 6| Step: 13
Training loss: 2.265744209289551
Validation loss: 2.408607757219704

Epoch: 62| Step: 0
Training loss: 2.3683207035064697
Validation loss: 2.420570486335344

Epoch: 6| Step: 1
Training loss: 2.438718318939209
Validation loss: 2.4526841691745225

Epoch: 6| Step: 2
Training loss: 2.915616512298584
Validation loss: 2.501428761789876

Epoch: 6| Step: 3
Training loss: 1.9930970668792725
Validation loss: 2.467295100612025

Epoch: 6| Step: 4
Training loss: 2.8739142417907715
Validation loss: 2.4081510395132084

Epoch: 6| Step: 5
Training loss: 2.4747323989868164
Validation loss: 2.348506453216717

Epoch: 6| Step: 6
Training loss: 2.6733016967773438
Validation loss: 2.3169970666208575

Epoch: 6| Step: 7
Training loss: 3.0590105056762695
Validation loss: 2.3085007103540565

Epoch: 6| Step: 8
Training loss: 2.8527088165283203
Validation loss: 2.303635754892903

Epoch: 6| Step: 9
Training loss: 2.1805899143218994
Validation loss: 2.3132285302685154

Epoch: 6| Step: 10
Training loss: 2.522902011871338
Validation loss: 2.3165242671966553

Epoch: 6| Step: 11
Training loss: 2.1938533782958984
Validation loss: 2.313688296143727

Epoch: 6| Step: 12
Training loss: 3.2100563049316406
Validation loss: 2.3146925151989026

Epoch: 6| Step: 13
Training loss: 2.683208703994751
Validation loss: 2.3112717597715315

Epoch: 63| Step: 0
Training loss: 2.658555030822754
Validation loss: 2.3287207977746123

Epoch: 6| Step: 1
Training loss: 2.651834487915039
Validation loss: 2.33315356316105

Epoch: 6| Step: 2
Training loss: 1.948051929473877
Validation loss: 2.3556988572561615

Epoch: 6| Step: 3
Training loss: 3.3355138301849365
Validation loss: 2.3830601348671863

Epoch: 6| Step: 4
Training loss: 2.8458919525146484
Validation loss: 2.389842576878045

Epoch: 6| Step: 5
Training loss: 2.8094606399536133
Validation loss: 2.374363371120986

Epoch: 6| Step: 6
Training loss: 2.4667248725891113
Validation loss: 2.3503880731521116

Epoch: 6| Step: 7
Training loss: 2.0206377506256104
Validation loss: 2.3608122359039965

Epoch: 6| Step: 8
Training loss: 1.861293077468872
Validation loss: 2.3817411084328928

Epoch: 6| Step: 9
Training loss: 2.4509644508361816
Validation loss: 2.3843088201297227

Epoch: 6| Step: 10
Training loss: 3.1425418853759766
Validation loss: 2.369687993039367

Epoch: 6| Step: 11
Training loss: 2.6479363441467285
Validation loss: 2.3459997741124963

Epoch: 6| Step: 12
Training loss: 2.895564556121826
Validation loss: 2.31649043995847

Epoch: 6| Step: 13
Training loss: 2.0941615104675293
Validation loss: 2.2929808503837994

Epoch: 64| Step: 0
Training loss: 2.5843605995178223
Validation loss: 2.2855480999074955

Epoch: 6| Step: 1
Training loss: 2.819222927093506
Validation loss: 2.2904950495689147

Epoch: 6| Step: 2
Training loss: 2.3960046768188477
Validation loss: 2.2956283220680813

Epoch: 6| Step: 3
Training loss: 2.614452362060547
Validation loss: 2.2923856217374086

Epoch: 6| Step: 4
Training loss: 2.2024424076080322
Validation loss: 2.2777684093803487

Epoch: 6| Step: 5
Training loss: 2.426624059677124
Validation loss: 2.280584253290648

Epoch: 6| Step: 6
Training loss: 2.760190486907959
Validation loss: 2.2809404609023884

Epoch: 6| Step: 7
Training loss: 2.6872477531433105
Validation loss: 2.2864561850024807

Epoch: 6| Step: 8
Training loss: 2.282599925994873
Validation loss: 2.2930707905882146

Epoch: 6| Step: 9
Training loss: 2.5441946983337402
Validation loss: 2.295486852686892

Epoch: 6| Step: 10
Training loss: 2.2821247577667236
Validation loss: 2.31677500150537

Epoch: 6| Step: 11
Training loss: 3.052730083465576
Validation loss: 2.323358625494024

Epoch: 6| Step: 12
Training loss: 2.963412284851074
Validation loss: 2.3223180770874023

Epoch: 6| Step: 13
Training loss: 2.4263384342193604
Validation loss: 2.295696004744499

Epoch: 65| Step: 0
Training loss: 2.493196725845337
Validation loss: 2.314494259895817

Epoch: 6| Step: 1
Training loss: 2.724024534225464
Validation loss: 2.3022572173867175

Epoch: 6| Step: 2
Training loss: 3.153904914855957
Validation loss: 2.2995837247499855

Epoch: 6| Step: 3
Training loss: 2.4749889373779297
Validation loss: 2.3008643196475123

Epoch: 6| Step: 4
Training loss: 2.075294017791748
Validation loss: 2.2928169824743785

Epoch: 6| Step: 5
Training loss: 2.224132776260376
Validation loss: 2.2915333496626986

Epoch: 6| Step: 6
Training loss: 2.6990485191345215
Validation loss: 2.3050237189057055

Epoch: 6| Step: 7
Training loss: 2.382359743118286
Validation loss: 2.3083239755322857

Epoch: 6| Step: 8
Training loss: 2.14689302444458
Validation loss: 2.3132025990434872

Epoch: 6| Step: 9
Training loss: 2.9994077682495117
Validation loss: 2.3365357588696223

Epoch: 6| Step: 10
Training loss: 2.5735907554626465
Validation loss: 2.3173222003444547

Epoch: 6| Step: 11
Training loss: 2.437716007232666
Validation loss: 2.314610714553505

Epoch: 6| Step: 12
Training loss: 2.428021192550659
Validation loss: 2.3064151758788736

Epoch: 6| Step: 13
Training loss: 3.119072437286377
Validation loss: 2.301240644147319

Epoch: 66| Step: 0
Training loss: 2.5500640869140625
Validation loss: 2.2907258977172194

Epoch: 6| Step: 1
Training loss: 2.1451518535614014
Validation loss: 2.2821623548384635

Epoch: 6| Step: 2
Training loss: 2.763652801513672
Validation loss: 2.2784128394178165

Epoch: 6| Step: 3
Training loss: 2.226139545440674
Validation loss: 2.274913946787516

Epoch: 6| Step: 4
Training loss: 3.1714487075805664
Validation loss: 2.2669400181821597

Epoch: 6| Step: 5
Training loss: 2.41405987739563
Validation loss: 2.2711646736309095

Epoch: 6| Step: 6
Training loss: 2.5466744899749756
Validation loss: 2.273399568373157

Epoch: 6| Step: 7
Training loss: 2.5055761337280273
Validation loss: 2.2779877467822005

Epoch: 6| Step: 8
Training loss: 2.3341636657714844
Validation loss: 2.2895668552767847

Epoch: 6| Step: 9
Training loss: 2.781806468963623
Validation loss: 2.2994800177953576

Epoch: 6| Step: 10
Training loss: 2.557218074798584
Validation loss: 2.3165369956724104

Epoch: 6| Step: 11
Training loss: 2.9341578483581543
Validation loss: 2.324331957806823

Epoch: 6| Step: 12
Training loss: 2.1466903686523438
Validation loss: 2.3242593631949475

Epoch: 6| Step: 13
Training loss: 2.749176263809204
Validation loss: 2.3447984392924974

Epoch: 67| Step: 0
Training loss: 2.7541632652282715
Validation loss: 2.37122687216728

Epoch: 6| Step: 1
Training loss: 2.444188117980957
Validation loss: 2.364420839535293

Epoch: 6| Step: 2
Training loss: 2.136481761932373
Validation loss: 2.426354992774225

Epoch: 6| Step: 3
Training loss: 2.05426025390625
Validation loss: 2.395961917856688

Epoch: 6| Step: 4
Training loss: 2.676023006439209
Validation loss: 2.3724561147792365

Epoch: 6| Step: 5
Training loss: 2.96911883354187
Validation loss: 2.329149402597899

Epoch: 6| Step: 6
Training loss: 2.327017307281494
Validation loss: 2.2868341579232165

Epoch: 6| Step: 7
Training loss: 1.8850282430648804
Validation loss: 2.2678026537741385

Epoch: 6| Step: 8
Training loss: 2.4182229042053223
Validation loss: 2.2654449785909345

Epoch: 6| Step: 9
Training loss: 2.5224123001098633
Validation loss: 2.263043011388471

Epoch: 6| Step: 10
Training loss: 2.5918145179748535
Validation loss: 2.25972669611695

Epoch: 6| Step: 11
Training loss: 2.9245645999908447
Validation loss: 2.2662522933816396

Epoch: 6| Step: 12
Training loss: 2.980306386947632
Validation loss: 2.2684791011195027

Epoch: 6| Step: 13
Training loss: 2.794922113418579
Validation loss: 2.267071395791987

Epoch: 68| Step: 0
Training loss: 2.6831536293029785
Validation loss: 2.2795759683014243

Epoch: 6| Step: 1
Training loss: 2.310896873474121
Validation loss: 2.2865391854316957

Epoch: 6| Step: 2
Training loss: 2.428363084793091
Validation loss: 2.2805116253514446

Epoch: 6| Step: 3
Training loss: 2.649272918701172
Validation loss: 2.270104344173144

Epoch: 6| Step: 4
Training loss: 2.695228099822998
Validation loss: 2.2661302371691634

Epoch: 6| Step: 5
Training loss: 2.1632509231567383
Validation loss: 2.2738947022345757

Epoch: 6| Step: 6
Training loss: 1.9466663599014282
Validation loss: 2.306232529301797

Epoch: 6| Step: 7
Training loss: 2.5074281692504883
Validation loss: 2.3394030729929605

Epoch: 6| Step: 8
Training loss: 2.7679710388183594
Validation loss: 2.3826252875789518

Epoch: 6| Step: 9
Training loss: 2.6217565536499023
Validation loss: 2.3716474502317366

Epoch: 6| Step: 10
Training loss: 3.3001556396484375
Validation loss: 2.351163323207568

Epoch: 6| Step: 11
Training loss: 2.6067514419555664
Validation loss: 2.3218237815364713

Epoch: 6| Step: 12
Training loss: 2.390692710876465
Validation loss: 2.288974892708563

Epoch: 6| Step: 13
Training loss: 2.913782835006714
Validation loss: 2.263389622011492

Epoch: 69| Step: 0
Training loss: 2.7469420433044434
Validation loss: 2.2528281006761777

Epoch: 6| Step: 1
Training loss: 3.0277607440948486
Validation loss: 2.266071154225257

Epoch: 6| Step: 2
Training loss: 1.9560964107513428
Validation loss: 2.2683749762914514

Epoch: 6| Step: 3
Training loss: 2.5519726276397705
Validation loss: 2.311208555775304

Epoch: 6| Step: 4
Training loss: 2.5039944648742676
Validation loss: 2.3032711116216515

Epoch: 6| Step: 5
Training loss: 2.8207550048828125
Validation loss: 2.2642574310302734

Epoch: 6| Step: 6
Training loss: 2.60054349899292
Validation loss: 2.265656558416223

Epoch: 6| Step: 7
Training loss: 2.6122937202453613
Validation loss: 2.277525705675925

Epoch: 6| Step: 8
Training loss: 2.947674036026001
Validation loss: 2.323667695445399

Epoch: 6| Step: 9
Training loss: 2.750978708267212
Validation loss: 2.360898220410911

Epoch: 6| Step: 10
Training loss: 2.3433141708374023
Validation loss: 2.358796819563835

Epoch: 6| Step: 11
Training loss: 2.8464033603668213
Validation loss: 2.3410881078371437

Epoch: 6| Step: 12
Training loss: 1.6199721097946167
Validation loss: 2.29901820869856

Epoch: 6| Step: 13
Training loss: 2.447293281555176
Validation loss: 2.281010368818878

Epoch: 70| Step: 0
Training loss: 2.956171989440918
Validation loss: 2.2758607326015348

Epoch: 6| Step: 1
Training loss: 2.2870986461639404
Validation loss: 2.2762535272106046

Epoch: 6| Step: 2
Training loss: 3.0865910053253174
Validation loss: 2.3156975392372376

Epoch: 6| Step: 3
Training loss: 1.7015275955200195
Validation loss: 2.3742187510254564

Epoch: 6| Step: 4
Training loss: 2.7352004051208496
Validation loss: 2.4160533079537014

Epoch: 6| Step: 5
Training loss: 2.571051597595215
Validation loss: 2.4266282461022817

Epoch: 6| Step: 6
Training loss: 2.1582999229431152
Validation loss: 2.445335308710734

Epoch: 6| Step: 7
Training loss: 2.777798652648926
Validation loss: 2.4757074963661934

Epoch: 6| Step: 8
Training loss: 2.7346153259277344
Validation loss: 2.471477388053812

Epoch: 6| Step: 9
Training loss: 2.7089414596557617
Validation loss: 2.4494997916683072

Epoch: 6| Step: 10
Training loss: 2.2351150512695312
Validation loss: 2.451696547128821

Epoch: 6| Step: 11
Training loss: 3.2962212562561035
Validation loss: 2.4228470581834034

Epoch: 6| Step: 12
Training loss: 2.779419183731079
Validation loss: 2.3920740209599978

Epoch: 6| Step: 13
Training loss: 3.0317468643188477
Validation loss: 2.381232287294121

Epoch: 71| Step: 0
Training loss: 2.7549962997436523
Validation loss: 2.3877294012295303

Epoch: 6| Step: 1
Training loss: 2.5734004974365234
Validation loss: 2.38623389633753

Epoch: 6| Step: 2
Training loss: 2.0810272693634033
Validation loss: 2.452357102465886

Epoch: 6| Step: 3
Training loss: 2.9937362670898438
Validation loss: 2.467401783953431

Epoch: 6| Step: 4
Training loss: 2.1919989585876465
Validation loss: 2.509884072888282

Epoch: 6| Step: 5
Training loss: 2.4307303428649902
Validation loss: 2.5150228879785024

Epoch: 6| Step: 6
Training loss: 3.582237482070923
Validation loss: 2.486397022842079

Epoch: 6| Step: 7
Training loss: 2.830017566680908
Validation loss: 2.439781927293347

Epoch: 6| Step: 8
Training loss: 2.7132654190063477
Validation loss: 2.3879252069739887

Epoch: 6| Step: 9
Training loss: 2.653709888458252
Validation loss: 2.3398419605788363

Epoch: 6| Step: 10
Training loss: 2.8670387268066406
Validation loss: 2.2910655595922984

Epoch: 6| Step: 11
Training loss: 1.2506006956100464
Validation loss: 2.2542185245021695

Epoch: 6| Step: 12
Training loss: 2.4620041847229004
Validation loss: 2.255099058151245

Epoch: 6| Step: 13
Training loss: 3.264434814453125
Validation loss: 2.2812869779525267

Epoch: 72| Step: 0
Training loss: 1.915212631225586
Validation loss: 2.283456612658757

Epoch: 6| Step: 1
Training loss: 2.6117403507232666
Validation loss: 2.274767908998715

Epoch: 6| Step: 2
Training loss: 2.74373722076416
Validation loss: 2.2666867317691928

Epoch: 6| Step: 3
Training loss: 2.55830979347229
Validation loss: 2.2681877279794342

Epoch: 6| Step: 4
Training loss: 2.7449655532836914
Validation loss: 2.278772461798883

Epoch: 6| Step: 5
Training loss: 2.038006544113159
Validation loss: 2.275385279809275

Epoch: 6| Step: 6
Training loss: 2.898192882537842
Validation loss: 2.2733126481374106

Epoch: 6| Step: 7
Training loss: 2.453031063079834
Validation loss: 2.265574719316216

Epoch: 6| Step: 8
Training loss: 1.9490723609924316
Validation loss: 2.2685982206816315

Epoch: 6| Step: 9
Training loss: 2.9565093517303467
Validation loss: 2.2757429204961306

Epoch: 6| Step: 10
Training loss: 2.408813953399658
Validation loss: 2.2654921367604244

Epoch: 6| Step: 11
Training loss: 2.9045357704162598
Validation loss: 2.266424596950572

Epoch: 6| Step: 12
Training loss: 2.63325834274292
Validation loss: 2.2514596139231036

Epoch: 6| Step: 13
Training loss: 3.0834038257598877
Validation loss: 2.245555349575576

Epoch: 73| Step: 0
Training loss: 2.5556466579437256
Validation loss: 2.243809841012442

Epoch: 6| Step: 1
Training loss: 2.119529962539673
Validation loss: 2.239832408966557

Epoch: 6| Step: 2
Training loss: 2.8744349479675293
Validation loss: 2.2369734343662055

Epoch: 6| Step: 3
Training loss: 2.445920944213867
Validation loss: 2.235792867598995

Epoch: 6| Step: 4
Training loss: 3.0611743927001953
Validation loss: 2.2336911104058705

Epoch: 6| Step: 5
Training loss: 1.7265148162841797
Validation loss: 2.2373596493915846

Epoch: 6| Step: 6
Training loss: 2.689561128616333
Validation loss: 2.2352216961563274

Epoch: 6| Step: 7
Training loss: 2.4843411445617676
Validation loss: 2.2350226012609338

Epoch: 6| Step: 8
Training loss: 2.3371505737304688
Validation loss: 2.2394668953393095

Epoch: 6| Step: 9
Training loss: 1.9270670413970947
Validation loss: 2.2448802455779044

Epoch: 6| Step: 10
Training loss: 2.558560609817505
Validation loss: 2.2876142545412947

Epoch: 6| Step: 11
Training loss: 3.013554334640503
Validation loss: 2.338632622072774

Epoch: 6| Step: 12
Training loss: 3.3106284141540527
Validation loss: 2.320074401875978

Epoch: 6| Step: 13
Training loss: 2.630732536315918
Validation loss: 2.2660054852885585

Epoch: 74| Step: 0
Training loss: 2.5757060050964355
Validation loss: 2.228119957831598

Epoch: 6| Step: 1
Training loss: 2.992661476135254
Validation loss: 2.230379343032837

Epoch: 6| Step: 2
Training loss: 2.927934169769287
Validation loss: 2.2365502465155815

Epoch: 6| Step: 3
Training loss: 2.7474617958068848
Validation loss: 2.250471794477073

Epoch: 6| Step: 4
Training loss: 2.5320136547088623
Validation loss: 2.2700992784192486

Epoch: 6| Step: 5
Training loss: 2.354757308959961
Validation loss: 2.293038142624722

Epoch: 6| Step: 6
Training loss: 2.870746612548828
Validation loss: 2.298609851509012

Epoch: 6| Step: 7
Training loss: 2.3387317657470703
Validation loss: 2.2474996735972743

Epoch: 6| Step: 8
Training loss: 1.9530971050262451
Validation loss: 2.227881408506824

Epoch: 6| Step: 9
Training loss: 2.1137728691101074
Validation loss: 2.2208336527629564

Epoch: 6| Step: 10
Training loss: 2.311950445175171
Validation loss: 2.235234611777849

Epoch: 6| Step: 11
Training loss: 3.3416309356689453
Validation loss: 2.301731721047432

Epoch: 6| Step: 12
Training loss: 2.5811607837677
Validation loss: 2.3947165114905244

Epoch: 6| Step: 13
Training loss: 2.4186599254608154
Validation loss: 2.364579677581787

Epoch: 75| Step: 0
Training loss: 2.548135995864868
Validation loss: 2.3409607743704193

Epoch: 6| Step: 1
Training loss: 3.364168643951416
Validation loss: 2.328598468534408

Epoch: 6| Step: 2
Training loss: 2.7834372520446777
Validation loss: 2.260214597948136

Epoch: 6| Step: 3
Training loss: 2.800370216369629
Validation loss: 2.2229495715069514

Epoch: 6| Step: 4
Training loss: 2.1398022174835205
Validation loss: 2.2175998469834686

Epoch: 6| Step: 5
Training loss: 2.833878517150879
Validation loss: 2.2167275067298644

Epoch: 6| Step: 6
Training loss: 2.292485475540161
Validation loss: 2.221454358869983

Epoch: 6| Step: 7
Training loss: 2.1963138580322266
Validation loss: 2.2185914875358663

Epoch: 6| Step: 8
Training loss: 3.04007887840271
Validation loss: 2.2189737955729165

Epoch: 6| Step: 9
Training loss: 2.981487274169922
Validation loss: 2.220223262745847

Epoch: 6| Step: 10
Training loss: 2.0540785789489746
Validation loss: 2.215704707689183

Epoch: 6| Step: 11
Training loss: 1.4813886880874634
Validation loss: 2.217009118808213

Epoch: 6| Step: 12
Training loss: 2.159226894378662
Validation loss: 2.2283894951625536

Epoch: 6| Step: 13
Training loss: 2.8950722217559814
Validation loss: 2.2485977193360687

Epoch: 76| Step: 0
Training loss: 2.232776165008545
Validation loss: 2.246432682519318

Epoch: 6| Step: 1
Training loss: 2.7284085750579834
Validation loss: 2.2533854130775697

Epoch: 6| Step: 2
Training loss: 2.6371188163757324
Validation loss: 2.231420332385648

Epoch: 6| Step: 3
Training loss: 2.8111681938171387
Validation loss: 2.224174073947373

Epoch: 6| Step: 4
Training loss: 3.010188341140747
Validation loss: 2.2198529961288616

Epoch: 6| Step: 5
Training loss: 2.49588680267334
Validation loss: 2.213633506528793

Epoch: 6| Step: 6
Training loss: 2.9724297523498535
Validation loss: 2.2148093702972576

Epoch: 6| Step: 7
Training loss: 1.9519240856170654
Validation loss: 2.215507302232968

Epoch: 6| Step: 8
Training loss: 2.855644464492798
Validation loss: 2.217812348437566

Epoch: 6| Step: 9
Training loss: 1.551944375038147
Validation loss: 2.216751857470441

Epoch: 6| Step: 10
Training loss: 2.0324249267578125
Validation loss: 2.2135573305109495

Epoch: 6| Step: 11
Training loss: 3.050629138946533
Validation loss: 2.2189446444152505

Epoch: 6| Step: 12
Training loss: 2.7136101722717285
Validation loss: 2.225749320881341

Epoch: 6| Step: 13
Training loss: 1.9232330322265625
Validation loss: 2.2306471819518716

Epoch: 77| Step: 0
Training loss: 2.709542751312256
Validation loss: 2.243171573967062

Epoch: 6| Step: 1
Training loss: 2.9692158699035645
Validation loss: 2.2651538579694686

Epoch: 6| Step: 2
Training loss: 2.31117582321167
Validation loss: 2.3103247919390277

Epoch: 6| Step: 3
Training loss: 1.878828763961792
Validation loss: 2.326865857647311

Epoch: 6| Step: 4
Training loss: 1.9244637489318848
Validation loss: 2.314536713784741

Epoch: 6| Step: 5
Training loss: 2.664121150970459
Validation loss: 2.3088074063742035

Epoch: 6| Step: 6
Training loss: 2.5808770656585693
Validation loss: 2.2841878732045493

Epoch: 6| Step: 7
Training loss: 2.6127562522888184
Validation loss: 2.265478495628603

Epoch: 6| Step: 8
Training loss: 2.84855580329895
Validation loss: 2.247912135175479

Epoch: 6| Step: 9
Training loss: 2.6227705478668213
Validation loss: 2.2318739609051774

Epoch: 6| Step: 10
Training loss: 2.490957260131836
Validation loss: 2.222533336249731

Epoch: 6| Step: 11
Training loss: 2.2976136207580566
Validation loss: 2.218248026345366

Epoch: 6| Step: 12
Training loss: 2.52370285987854
Validation loss: 2.2161182203600482

Epoch: 6| Step: 13
Training loss: 2.8433408737182617
Validation loss: 2.20687295288168

Epoch: 78| Step: 0
Training loss: 2.7017972469329834
Validation loss: 2.207813519303517

Epoch: 6| Step: 1
Training loss: 2.169832229614258
Validation loss: 2.211013920845524

Epoch: 6| Step: 2
Training loss: 2.51469087600708
Validation loss: 2.2369624645479265

Epoch: 6| Step: 3
Training loss: 2.3100786209106445
Validation loss: 2.2726904653733775

Epoch: 6| Step: 4
Training loss: 3.108102560043335
Validation loss: 2.3314491548845844

Epoch: 6| Step: 5
Training loss: 2.0351223945617676
Validation loss: 2.357827599330615

Epoch: 6| Step: 6
Training loss: 2.264402389526367
Validation loss: 2.330583018641318

Epoch: 6| Step: 7
Training loss: 2.466747760772705
Validation loss: 2.3210910315154702

Epoch: 6| Step: 8
Training loss: 2.205414295196533
Validation loss: 2.3208324140118015

Epoch: 6| Step: 9
Training loss: 3.1578264236450195
Validation loss: 2.283642412513815

Epoch: 6| Step: 10
Training loss: 2.5809717178344727
Validation loss: 2.2392569562440277

Epoch: 6| Step: 11
Training loss: 2.965144634246826
Validation loss: 2.2099109208712013

Epoch: 6| Step: 12
Training loss: 2.0490550994873047
Validation loss: 2.1971448083077707

Epoch: 6| Step: 13
Training loss: 2.7549400329589844
Validation loss: 2.206737185037264

Epoch: 79| Step: 0
Training loss: 2.7013473510742188
Validation loss: 2.207409171647923

Epoch: 6| Step: 1
Training loss: 2.443563461303711
Validation loss: 2.207612288895474

Epoch: 6| Step: 2
Training loss: 2.5471229553222656
Validation loss: 2.2120387092713387

Epoch: 6| Step: 3
Training loss: 2.3197402954101562
Validation loss: 2.2290618688829484

Epoch: 6| Step: 4
Training loss: 2.453575611114502
Validation loss: 2.2364393511126117

Epoch: 6| Step: 5
Training loss: 2.4473025798797607
Validation loss: 2.245064015029579

Epoch: 6| Step: 6
Training loss: 2.8173131942749023
Validation loss: 2.2455583003259476

Epoch: 6| Step: 7
Training loss: 2.0096960067749023
Validation loss: 2.246451184313784

Epoch: 6| Step: 8
Training loss: 2.386263132095337
Validation loss: 2.226275433776199

Epoch: 6| Step: 9
Training loss: 2.692298412322998
Validation loss: 2.2152895465973885

Epoch: 6| Step: 10
Training loss: 2.630232810974121
Validation loss: 2.207413927201302

Epoch: 6| Step: 11
Training loss: 2.740260601043701
Validation loss: 2.208912331570861

Epoch: 6| Step: 12
Training loss: 2.285031795501709
Validation loss: 2.1992480908670733

Epoch: 6| Step: 13
Training loss: 2.237082004547119
Validation loss: 2.205267316551619

Epoch: 80| Step: 0
Training loss: 2.525940179824829
Validation loss: 2.2101923163219164

Epoch: 6| Step: 1
Training loss: 2.4603111743927
Validation loss: 2.221939056150375

Epoch: 6| Step: 2
Training loss: 3.0898001194000244
Validation loss: 2.2217905418847197

Epoch: 6| Step: 3
Training loss: 2.40962553024292
Validation loss: 2.242147014987084

Epoch: 6| Step: 4
Training loss: 2.5514988899230957
Validation loss: 2.228840776669082

Epoch: 6| Step: 5
Training loss: 2.8054347038269043
Validation loss: 2.241258810925227

Epoch: 6| Step: 6
Training loss: 2.161871910095215
Validation loss: 2.2321332167553645

Epoch: 6| Step: 7
Training loss: 2.428677558898926
Validation loss: 2.232499150819676

Epoch: 6| Step: 8
Training loss: 2.581702709197998
Validation loss: 2.2106687458612586

Epoch: 6| Step: 9
Training loss: 2.438612461090088
Validation loss: 2.2055155102924635

Epoch: 6| Step: 10
Training loss: 2.36191463470459
Validation loss: 2.209423970150691

Epoch: 6| Step: 11
Training loss: 2.1980555057525635
Validation loss: 2.2016236666710145

Epoch: 6| Step: 12
Training loss: 2.311884880065918
Validation loss: 2.200409068856188

Epoch: 6| Step: 13
Training loss: 2.1826820373535156
Validation loss: 2.2051374527715866

Epoch: 81| Step: 0
Training loss: 2.594480037689209
Validation loss: 2.2383058148045696

Epoch: 6| Step: 1
Training loss: 2.845825672149658
Validation loss: 2.2696450166804816

Epoch: 6| Step: 2
Training loss: 2.5608787536621094
Validation loss: 2.3355869605977047

Epoch: 6| Step: 3
Training loss: 3.8548312187194824
Validation loss: 2.3560031049995014

Epoch: 6| Step: 4
Training loss: 1.8665720224380493
Validation loss: 2.3535686539065455

Epoch: 6| Step: 5
Training loss: 2.55293607711792
Validation loss: 2.3188949323469594

Epoch: 6| Step: 6
Training loss: 2.06901478767395
Validation loss: 2.2723509393712527

Epoch: 6| Step: 7
Training loss: 1.778425693511963
Validation loss: 2.224030743363083

Epoch: 6| Step: 8
Training loss: 2.9757392406463623
Validation loss: 2.205943786969749

Epoch: 6| Step: 9
Training loss: 2.2754573822021484
Validation loss: 2.202098769526328

Epoch: 6| Step: 10
Training loss: 2.2626523971557617
Validation loss: 2.194224606278122

Epoch: 6| Step: 11
Training loss: 2.8381900787353516
Validation loss: 2.191413338466357

Epoch: 6| Step: 12
Training loss: 2.053792953491211
Validation loss: 2.2064159070291827

Epoch: 6| Step: 13
Training loss: 2.2552826404571533
Validation loss: 2.199325848651189

Epoch: 82| Step: 0
Training loss: 2.9859390258789062
Validation loss: 2.22240355706984

Epoch: 6| Step: 1
Training loss: 2.3091416358947754
Validation loss: 2.2307906843000844

Epoch: 6| Step: 2
Training loss: 2.121839761734009
Validation loss: 2.204275249153055

Epoch: 6| Step: 3
Training loss: 3.025634765625
Validation loss: 2.1933853369887157

Epoch: 6| Step: 4
Training loss: 2.8081135749816895
Validation loss: 2.1967047747745307

Epoch: 6| Step: 5
Training loss: 2.3362088203430176
Validation loss: 2.224450083189113

Epoch: 6| Step: 6
Training loss: 2.2065374851226807
Validation loss: 2.265776052269884

Epoch: 6| Step: 7
Training loss: 2.356336832046509
Validation loss: 2.302806378692709

Epoch: 6| Step: 8
Training loss: 2.35819149017334
Validation loss: 2.3297158056689846

Epoch: 6| Step: 9
Training loss: 2.630117177963257
Validation loss: 2.3224934377977924

Epoch: 6| Step: 10
Training loss: 2.328338146209717
Validation loss: 2.2918364309495494

Epoch: 6| Step: 11
Training loss: 2.33591890335083
Validation loss: 2.229525416128097

Epoch: 6| Step: 12
Training loss: 2.845215320587158
Validation loss: 2.194528300275085

Epoch: 6| Step: 13
Training loss: 2.615314245223999
Validation loss: 2.1848147607618764

Epoch: 83| Step: 0
Training loss: 2.593613624572754
Validation loss: 2.1769297379319386

Epoch: 6| Step: 1
Training loss: 2.8007383346557617
Validation loss: 2.1819760491771083

Epoch: 6| Step: 2
Training loss: 2.2621285915374756
Validation loss: 2.1800881355039534

Epoch: 6| Step: 3
Training loss: 2.082442045211792
Validation loss: 2.1809659593848774

Epoch: 6| Step: 4
Training loss: 2.6481411457061768
Validation loss: 2.1963617660666026

Epoch: 6| Step: 5
Training loss: 2.743741512298584
Validation loss: 2.2072832263926023

Epoch: 6| Step: 6
Training loss: 1.8306057453155518
Validation loss: 2.200055919667726

Epoch: 6| Step: 7
Training loss: 2.425433397293091
Validation loss: 2.2056778541175266

Epoch: 6| Step: 8
Training loss: 3.1962549686431885
Validation loss: 2.2113407939992924

Epoch: 6| Step: 9
Training loss: 2.049748182296753
Validation loss: 2.198379983184158

Epoch: 6| Step: 10
Training loss: 2.1170010566711426
Validation loss: 2.2004700860669537

Epoch: 6| Step: 11
Training loss: 2.345022678375244
Validation loss: 2.189412442586755

Epoch: 6| Step: 12
Training loss: 2.7264480590820312
Validation loss: 2.1828343868255615

Epoch: 6| Step: 13
Training loss: 2.942655086517334
Validation loss: 2.1847993840453444

Epoch: 84| Step: 0
Training loss: 2.8201394081115723
Validation loss: 2.186665124790643

Epoch: 6| Step: 1
Training loss: 2.9555904865264893
Validation loss: 2.185500446186271

Epoch: 6| Step: 2
Training loss: 2.2966270446777344
Validation loss: 2.205116128408781

Epoch: 6| Step: 3
Training loss: 2.0202317237854004
Validation loss: 2.2113429282301214

Epoch: 6| Step: 4
Training loss: 2.5661489963531494
Validation loss: 2.2082849574345413

Epoch: 6| Step: 5
Training loss: 2.7945165634155273
Validation loss: 2.2044192898658013

Epoch: 6| Step: 6
Training loss: 2.056558132171631
Validation loss: 2.198010483095723

Epoch: 6| Step: 7
Training loss: 1.9462844133377075
Validation loss: 2.17817227173877

Epoch: 6| Step: 8
Training loss: 2.5049710273742676
Validation loss: 2.18601349348663

Epoch: 6| Step: 9
Training loss: 2.616042375564575
Validation loss: 2.1885035319994857

Epoch: 6| Step: 10
Training loss: 2.615997791290283
Validation loss: 2.210755407169301

Epoch: 6| Step: 11
Training loss: 2.697737216949463
Validation loss: 2.212347424158486

Epoch: 6| Step: 12
Training loss: 2.37595796585083
Validation loss: 2.1980336532797864

Epoch: 6| Step: 13
Training loss: 1.9610775709152222
Validation loss: 2.185909730131908

Epoch: 85| Step: 0
Training loss: 2.018052101135254
Validation loss: 2.1716445287068686

Epoch: 6| Step: 1
Training loss: 2.1154351234436035
Validation loss: 2.178215090946485

Epoch: 6| Step: 2
Training loss: 2.387580633163452
Validation loss: 2.2050904356023318

Epoch: 6| Step: 3
Training loss: 2.278557777404785
Validation loss: 2.2372093021228747

Epoch: 6| Step: 4
Training loss: 2.1290388107299805
Validation loss: 2.2319771551316783

Epoch: 6| Step: 5
Training loss: 3.1955366134643555
Validation loss: 2.1981093704059558

Epoch: 6| Step: 6
Training loss: 2.603719711303711
Validation loss: 2.185380966432633

Epoch: 6| Step: 7
Training loss: 2.713090419769287
Validation loss: 2.168628623408656

Epoch: 6| Step: 8
Training loss: 2.2278709411621094
Validation loss: 2.1673993090147614

Epoch: 6| Step: 9
Training loss: 2.4444167613983154
Validation loss: 2.164131636260658

Epoch: 6| Step: 10
Training loss: 2.9369559288024902
Validation loss: 2.1627692842996247

Epoch: 6| Step: 11
Training loss: 2.1135945320129395
Validation loss: 2.1659644470419934

Epoch: 6| Step: 12
Training loss: 2.06139874458313
Validation loss: 2.165372625474007

Epoch: 6| Step: 13
Training loss: 3.20890474319458
Validation loss: 2.1748372764997583

Epoch: 86| Step: 0
Training loss: 1.7900818586349487
Validation loss: 2.184141275703266

Epoch: 6| Step: 1
Training loss: 3.15929913520813
Validation loss: 2.182115685555243

Epoch: 6| Step: 2
Training loss: 2.6622321605682373
Validation loss: 2.1976280443130003

Epoch: 6| Step: 3
Training loss: 2.2784271240234375
Validation loss: 2.1922903035276677

Epoch: 6| Step: 4
Training loss: 2.9088525772094727
Validation loss: 2.194581979064531

Epoch: 6| Step: 5
Training loss: 2.3952603340148926
Validation loss: 2.179423798796951

Epoch: 6| Step: 6
Training loss: 1.88302743434906
Validation loss: 2.183375930273405

Epoch: 6| Step: 7
Training loss: 2.1523277759552
Validation loss: 2.183396650898841

Epoch: 6| Step: 8
Training loss: 2.7404332160949707
Validation loss: 2.1878378493811494

Epoch: 6| Step: 9
Training loss: 2.389496088027954
Validation loss: 2.1813202878480316

Epoch: 6| Step: 10
Training loss: 2.305210828781128
Validation loss: 2.1865213942784134

Epoch: 6| Step: 11
Training loss: 2.368351459503174
Validation loss: 2.1857198848519275

Epoch: 6| Step: 12
Training loss: 2.1928021907806396
Validation loss: 2.181290841871692

Epoch: 6| Step: 13
Training loss: 3.1070852279663086
Validation loss: 2.1747111710168983

Epoch: 87| Step: 0
Training loss: 2.46768856048584
Validation loss: 2.16412522972271

Epoch: 6| Step: 1
Training loss: 1.8648097515106201
Validation loss: 2.155327145771314

Epoch: 6| Step: 2
Training loss: 2.9835362434387207
Validation loss: 2.1587051089091966

Epoch: 6| Step: 3
Training loss: 2.6406524181365967
Validation loss: 2.151663790466965

Epoch: 6| Step: 4
Training loss: 2.990894317626953
Validation loss: 2.1698339369989212

Epoch: 6| Step: 5
Training loss: 2.6737163066864014
Validation loss: 2.1934669030609952

Epoch: 6| Step: 6
Training loss: 2.980907917022705
Validation loss: 2.213186225583476

Epoch: 6| Step: 7
Training loss: 1.7052545547485352
Validation loss: 2.220280603695941

Epoch: 6| Step: 8
Training loss: 2.2991631031036377
Validation loss: 2.1998034831016295

Epoch: 6| Step: 9
Training loss: 2.4174299240112305
Validation loss: 2.2069355403223345

Epoch: 6| Step: 10
Training loss: 2.398983955383301
Validation loss: 2.2163275428997573

Epoch: 6| Step: 11
Training loss: 2.343606948852539
Validation loss: 2.1926611444001556

Epoch: 6| Step: 12
Training loss: 1.844465732574463
Validation loss: 2.1704179650993756

Epoch: 6| Step: 13
Training loss: 2.090104579925537
Validation loss: 2.1702481033981487

Epoch: 88| Step: 0
Training loss: 2.3155508041381836
Validation loss: 2.1547803417328866

Epoch: 6| Step: 1
Training loss: 2.6276979446411133
Validation loss: 2.1549448274797007

Epoch: 6| Step: 2
Training loss: 2.3782591819763184
Validation loss: 2.1569447209758144

Epoch: 6| Step: 3
Training loss: 2.6377482414245605
Validation loss: 2.1430103355838406

Epoch: 6| Step: 4
Training loss: 2.922572374343872
Validation loss: 2.15986983237728

Epoch: 6| Step: 5
Training loss: 2.3822479248046875
Validation loss: 2.1485681072358163

Epoch: 6| Step: 6
Training loss: 1.924619436264038
Validation loss: 2.155456348132062

Epoch: 6| Step: 7
Training loss: 2.5785531997680664
Validation loss: 2.148879425500029

Epoch: 6| Step: 8
Training loss: 1.9858036041259766
Validation loss: 2.1622973642041607

Epoch: 6| Step: 9
Training loss: 1.9703004360198975
Validation loss: 2.1573726502797936

Epoch: 6| Step: 10
Training loss: 2.467409133911133
Validation loss: 2.161015410577097

Epoch: 6| Step: 11
Training loss: 2.250917673110962
Validation loss: 2.1649942551889727

Epoch: 6| Step: 12
Training loss: 2.6295247077941895
Validation loss: 2.167093489759712

Epoch: 6| Step: 13
Training loss: 2.875369071960449
Validation loss: 2.170322759177095

Epoch: 89| Step: 0
Training loss: 2.0457122325897217
Validation loss: 2.1902559790559994

Epoch: 6| Step: 1
Training loss: 2.876980781555176
Validation loss: 2.1884416739145913

Epoch: 6| Step: 2
Training loss: 2.0541365146636963
Validation loss: 2.1956443402074997

Epoch: 6| Step: 3
Training loss: 2.113410234451294
Validation loss: 2.193845816837844

Epoch: 6| Step: 4
Training loss: 2.14288592338562
Validation loss: 2.1820407721304123

Epoch: 6| Step: 5
Training loss: 2.2431068420410156
Validation loss: 2.1700596283840876

Epoch: 6| Step: 6
Training loss: 2.4555771350860596
Validation loss: 2.1616304946202103

Epoch: 6| Step: 7
Training loss: 2.5611867904663086
Validation loss: 2.1514929340731714

Epoch: 6| Step: 8
Training loss: 2.6716456413269043
Validation loss: 2.1465216246984338

Epoch: 6| Step: 9
Training loss: 2.861309289932251
Validation loss: 2.1468281630546815

Epoch: 6| Step: 10
Training loss: 2.6274831295013428
Validation loss: 2.1491578009820755

Epoch: 6| Step: 11
Training loss: 2.0180201530456543
Validation loss: 2.1476859943841093

Epoch: 6| Step: 12
Training loss: 2.4025747776031494
Validation loss: 2.1475830821580786

Epoch: 6| Step: 13
Training loss: 2.699286699295044
Validation loss: 2.158858058273151

Epoch: 90| Step: 0
Training loss: 3.233555555343628
Validation loss: 2.179307576148741

Epoch: 6| Step: 1
Training loss: 2.1101512908935547
Validation loss: 2.1924056340289373

Epoch: 6| Step: 2
Training loss: 2.569565534591675
Validation loss: 2.1857940637937157

Epoch: 6| Step: 3
Training loss: 2.3654942512512207
Validation loss: 2.1850167166802192

Epoch: 6| Step: 4
Training loss: 1.367431640625
Validation loss: 2.1855093330465336

Epoch: 6| Step: 5
Training loss: 2.463500499725342
Validation loss: 2.1842583379437848

Epoch: 6| Step: 6
Training loss: 1.6333744525909424
Validation loss: 2.1837466429638606

Epoch: 6| Step: 7
Training loss: 2.010437250137329
Validation loss: 2.1735240233841764

Epoch: 6| Step: 8
Training loss: 2.3210835456848145
Validation loss: 2.1794510349150626

Epoch: 6| Step: 9
Training loss: 2.3333230018615723
Validation loss: 2.158195008513748

Epoch: 6| Step: 10
Training loss: 2.5542664527893066
Validation loss: 2.149805870107425

Epoch: 6| Step: 11
Training loss: 2.6859917640686035
Validation loss: 2.1412964213278984

Epoch: 6| Step: 12
Training loss: 2.7402889728546143
Validation loss: 2.1361187799002535

Epoch: 6| Step: 13
Training loss: 3.631282329559326
Validation loss: 2.1399696462897846

Epoch: 91| Step: 0
Training loss: 1.6027748584747314
Validation loss: 2.1480322999338948

Epoch: 6| Step: 1
Training loss: 2.299165725708008
Validation loss: 2.1502500246929865

Epoch: 6| Step: 2
Training loss: 2.589120864868164
Validation loss: 2.1666995556123796

Epoch: 6| Step: 3
Training loss: 2.359118938446045
Validation loss: 2.1698134009556105

Epoch: 6| Step: 4
Training loss: 2.4661760330200195
Validation loss: 2.1354994081681773

Epoch: 6| Step: 5
Training loss: 2.749873638153076
Validation loss: 2.1388835958255235

Epoch: 6| Step: 6
Training loss: 2.4227476119995117
Validation loss: 2.136815191597067

Epoch: 6| Step: 7
Training loss: 2.385042190551758
Validation loss: 2.133152308002595

Epoch: 6| Step: 8
Training loss: 2.2091710567474365
Validation loss: 2.1260018143602597

Epoch: 6| Step: 9
Training loss: 2.114523410797119
Validation loss: 2.1258894346093618

Epoch: 6| Step: 10
Training loss: 2.9837594032287598
Validation loss: 2.129707392825875

Epoch: 6| Step: 11
Training loss: 2.1061148643493652
Validation loss: 2.1303867114487516

Epoch: 6| Step: 12
Training loss: 2.7437539100646973
Validation loss: 2.1452559322439213

Epoch: 6| Step: 13
Training loss: 2.959662437438965
Validation loss: 2.1530824835582445

Epoch: 92| Step: 0
Training loss: 3.0874085426330566
Validation loss: 2.166893806508792

Epoch: 6| Step: 1
Training loss: 2.0088205337524414
Validation loss: 2.215488200546593

Epoch: 6| Step: 2
Training loss: 2.859117031097412
Validation loss: 2.2285798006160285

Epoch: 6| Step: 3
Training loss: 2.5214715003967285
Validation loss: 2.241596862833987

Epoch: 6| Step: 4
Training loss: 2.3173177242279053
Validation loss: 2.2327120778381184

Epoch: 6| Step: 5
Training loss: 1.9909436702728271
Validation loss: 2.2066893462211854

Epoch: 6| Step: 6
Training loss: 2.472506523132324
Validation loss: 2.189501157370947

Epoch: 6| Step: 7
Training loss: 2.157747268676758
Validation loss: 2.1545654932657876

Epoch: 6| Step: 8
Training loss: 2.2720212936401367
Validation loss: 2.1375213335919123

Epoch: 6| Step: 9
Training loss: 2.649559259414673
Validation loss: 2.1276105321863645

Epoch: 6| Step: 10
Training loss: 1.8482255935668945
Validation loss: 2.1254851484811432

Epoch: 6| Step: 11
Training loss: 2.651251792907715
Validation loss: 2.1312157441211004

Epoch: 6| Step: 12
Training loss: 2.447770118713379
Validation loss: 2.120140214120188

Epoch: 6| Step: 13
Training loss: 2.348193883895874
Validation loss: 2.126548554307671

Epoch: 93| Step: 0
Training loss: 2.068068027496338
Validation loss: 2.126279111831419

Epoch: 6| Step: 1
Training loss: 2.25203537940979
Validation loss: 2.1348667836958364

Epoch: 6| Step: 2
Training loss: 2.850736141204834
Validation loss: 2.1334274327883156

Epoch: 6| Step: 3
Training loss: 1.855031967163086
Validation loss: 2.146031936009725

Epoch: 6| Step: 4
Training loss: 2.3662099838256836
Validation loss: 2.1412293552070536

Epoch: 6| Step: 5
Training loss: 2.3344273567199707
Validation loss: 2.152885421629875

Epoch: 6| Step: 6
Training loss: 2.461498498916626
Validation loss: 2.1542044980551607

Epoch: 6| Step: 7
Training loss: 2.4047722816467285
Validation loss: 2.159086827308901

Epoch: 6| Step: 8
Training loss: 2.6339683532714844
Validation loss: 2.1719179614897697

Epoch: 6| Step: 9
Training loss: 2.1987152099609375
Validation loss: 2.1704226386162544

Epoch: 6| Step: 10
Training loss: 2.3261656761169434
Validation loss: 2.19158419229651

Epoch: 6| Step: 11
Training loss: 2.9203128814697266
Validation loss: 2.1916203832113617

Epoch: 6| Step: 12
Training loss: 2.2460789680480957
Validation loss: 2.1814142081045333

Epoch: 6| Step: 13
Training loss: 2.75920033454895
Validation loss: 2.1621466631530435

Epoch: 94| Step: 0
Training loss: 2.5218095779418945
Validation loss: 2.13484243295526

Epoch: 6| Step: 1
Training loss: 2.1058855056762695
Validation loss: 2.13269716693509

Epoch: 6| Step: 2
Training loss: 2.725158929824829
Validation loss: 2.157044579905848

Epoch: 6| Step: 3
Training loss: 1.831416130065918
Validation loss: 2.163914777899301

Epoch: 6| Step: 4
Training loss: 2.5927462577819824
Validation loss: 2.1628243564277567

Epoch: 6| Step: 5
Training loss: 2.705357074737549
Validation loss: 2.160909975728681

Epoch: 6| Step: 6
Training loss: 2.24359130859375
Validation loss: 2.1736006634209746

Epoch: 6| Step: 7
Training loss: 2.223083257675171
Validation loss: 2.1398475349590345

Epoch: 6| Step: 8
Training loss: 2.833582878112793
Validation loss: 2.11901831370528

Epoch: 6| Step: 9
Training loss: 2.4243104457855225
Validation loss: 2.121697497624223

Epoch: 6| Step: 10
Training loss: 2.7714033126831055
Validation loss: 2.1219330961986254

Epoch: 6| Step: 11
Training loss: 2.410905361175537
Validation loss: 2.1459015774470505

Epoch: 6| Step: 12
Training loss: 1.9485678672790527
Validation loss: 2.1827052562467513

Epoch: 6| Step: 13
Training loss: 3.4063425064086914
Validation loss: 2.207620641236664

Epoch: 95| Step: 0
Training loss: 2.1110761165618896
Validation loss: 2.2874073046509937

Epoch: 6| Step: 1
Training loss: 2.6679606437683105
Validation loss: 2.3108493461403796

Epoch: 6| Step: 2
Training loss: 2.786891222000122
Validation loss: 2.3325829108556113

Epoch: 6| Step: 3
Training loss: 2.133662223815918
Validation loss: 2.307097368342902

Epoch: 6| Step: 4
Training loss: 2.4209494590759277
Validation loss: 2.270024461130942

Epoch: 6| Step: 5
Training loss: 1.9669134616851807
Validation loss: 2.2183354131637083

Epoch: 6| Step: 6
Training loss: 2.25783371925354
Validation loss: 2.162171786831271

Epoch: 6| Step: 7
Training loss: 2.9892916679382324
Validation loss: 2.1438113310003795

Epoch: 6| Step: 8
Training loss: 2.174910068511963
Validation loss: 2.1349889642448834

Epoch: 6| Step: 9
Training loss: 2.5536208152770996
Validation loss: 2.1268403107120144

Epoch: 6| Step: 10
Training loss: 2.4632232189178467
Validation loss: 2.1259775725744103

Epoch: 6| Step: 11
Training loss: 1.8077527284622192
Validation loss: 2.118855402033816

Epoch: 6| Step: 12
Training loss: 3.067251443862915
Validation loss: 2.1260860197005735

Epoch: 6| Step: 13
Training loss: 2.5170907974243164
Validation loss: 2.124031982114238

Epoch: 96| Step: 0
Training loss: 2.0444600582122803
Validation loss: 2.1299622776687785

Epoch: 6| Step: 1
Training loss: 2.5625126361846924
Validation loss: 2.128528953880392

Epoch: 6| Step: 2
Training loss: 3.013857126235962
Validation loss: 2.1210592639061714

Epoch: 6| Step: 3
Training loss: 2.5024497509002686
Validation loss: 2.1234488743607716

Epoch: 6| Step: 4
Training loss: 1.9029306173324585
Validation loss: 2.13469519153718

Epoch: 6| Step: 5
Training loss: 2.0298240184783936
Validation loss: 2.1487081307236866

Epoch: 6| Step: 6
Training loss: 2.8413305282592773
Validation loss: 2.136228294782741

Epoch: 6| Step: 7
Training loss: 2.9175398349761963
Validation loss: 2.1284668983951693

Epoch: 6| Step: 8
Training loss: 2.2823843955993652
Validation loss: 2.1207332841811644

Epoch: 6| Step: 9
Training loss: 1.7336218357086182
Validation loss: 2.113626833884947

Epoch: 6| Step: 10
Training loss: 2.2314717769622803
Validation loss: 2.1082166176970287

Epoch: 6| Step: 11
Training loss: 2.2620437145233154
Validation loss: 2.100581548547232

Epoch: 6| Step: 12
Training loss: 2.182060718536377
Validation loss: 2.1061014116451306

Epoch: 6| Step: 13
Training loss: 2.928215980529785
Validation loss: 2.1114592949549356

Epoch: 97| Step: 0
Training loss: 2.206890106201172
Validation loss: 2.1056093631252164

Epoch: 6| Step: 1
Training loss: 3.041181802749634
Validation loss: 2.1051130140981367

Epoch: 6| Step: 2
Training loss: 2.9036431312561035
Validation loss: 2.115146685672063

Epoch: 6| Step: 3
Training loss: 2.791351318359375
Validation loss: 2.124290748309064

Epoch: 6| Step: 4
Training loss: 2.5134191513061523
Validation loss: 2.139901397048786

Epoch: 6| Step: 5
Training loss: 2.6696696281433105
Validation loss: 2.149673782369142

Epoch: 6| Step: 6
Training loss: 2.2958521842956543
Validation loss: 2.163950099739977

Epoch: 6| Step: 7
Training loss: 2.0970335006713867
Validation loss: 2.158487594255837

Epoch: 6| Step: 8
Training loss: 1.2605384588241577
Validation loss: 2.1495402013101885

Epoch: 6| Step: 9
Training loss: 2.297031879425049
Validation loss: 2.1250969709888583

Epoch: 6| Step: 10
Training loss: 2.2009971141815186
Validation loss: 2.1005072593688965

Epoch: 6| Step: 11
Training loss: 2.0631263256073
Validation loss: 2.098604872662534

Epoch: 6| Step: 12
Training loss: 3.053037166595459
Validation loss: 2.1097763366596674

Epoch: 6| Step: 13
Training loss: 1.310104250907898
Validation loss: 2.1241932261374687

Epoch: 98| Step: 0
Training loss: 2.787444829940796
Validation loss: 2.1231234483821417

Epoch: 6| Step: 1
Training loss: 2.7262792587280273
Validation loss: 2.1247839748218493

Epoch: 6| Step: 2
Training loss: 2.361203670501709
Validation loss: 2.125461406605218

Epoch: 6| Step: 3
Training loss: 1.927901029586792
Validation loss: 2.1337220822611163

Epoch: 6| Step: 4
Training loss: 2.3404366970062256
Validation loss: 2.156209099677301

Epoch: 6| Step: 5
Training loss: 2.3109171390533447
Validation loss: 2.183741077300041

Epoch: 6| Step: 6
Training loss: 2.169919490814209
Validation loss: 2.154619270755399

Epoch: 6| Step: 7
Training loss: 2.581202983856201
Validation loss: 2.165275317366405

Epoch: 6| Step: 8
Training loss: 2.5433812141418457
Validation loss: 2.1497885924513622

Epoch: 6| Step: 9
Training loss: 2.3596718311309814
Validation loss: 2.111545829362767

Epoch: 6| Step: 10
Training loss: 2.9955267906188965
Validation loss: 2.1011748698449906

Epoch: 6| Step: 11
Training loss: 1.968653917312622
Validation loss: 2.100792137525415

Epoch: 6| Step: 12
Training loss: 2.602933883666992
Validation loss: 2.108413586052515

Epoch: 6| Step: 13
Training loss: 1.98691987991333
Validation loss: 2.107950634853814

Epoch: 99| Step: 0
Training loss: 1.875275731086731
Validation loss: 2.110804637273153

Epoch: 6| Step: 1
Training loss: 2.2521066665649414
Validation loss: 2.1062166434462353

Epoch: 6| Step: 2
Training loss: 2.304600477218628
Validation loss: 2.098693473364717

Epoch: 6| Step: 3
Training loss: 2.066532611846924
Validation loss: 2.09466593111715

Epoch: 6| Step: 4
Training loss: 2.4914774894714355
Validation loss: 2.098232493605665

Epoch: 6| Step: 5
Training loss: 2.7598180770874023
Validation loss: 2.0983107320723997

Epoch: 6| Step: 6
Training loss: 2.9363105297088623
Validation loss: 2.095216643425726

Epoch: 6| Step: 7
Training loss: 2.661818027496338
Validation loss: 2.1076339060260403

Epoch: 6| Step: 8
Training loss: 2.003863573074341
Validation loss: 2.095799881924865

Epoch: 6| Step: 9
Training loss: 2.2542004585266113
Validation loss: 2.0972373844474874

Epoch: 6| Step: 10
Training loss: 1.6394953727722168
Validation loss: 2.083797585579657

Epoch: 6| Step: 11
Training loss: 2.882730007171631
Validation loss: 2.0881385034130466

Epoch: 6| Step: 12
Training loss: 2.520738124847412
Validation loss: 2.1060330278129986

Epoch: 6| Step: 13
Training loss: 2.0184519290924072
Validation loss: 2.1300641695658364

Epoch: 100| Step: 0
Training loss: 2.5348846912384033
Validation loss: 2.1444202123149747

Epoch: 6| Step: 1
Training loss: 2.1619036197662354
Validation loss: 2.143376096602409

Epoch: 6| Step: 2
Training loss: 2.408881187438965
Validation loss: 2.1427972880742883

Epoch: 6| Step: 3
Training loss: 2.2495179176330566
Validation loss: 2.110430904614028

Epoch: 6| Step: 4
Training loss: 1.2772471904754639
Validation loss: 2.1021133750997563

Epoch: 6| Step: 5
Training loss: 2.7563974857330322
Validation loss: 2.0899494796670894

Epoch: 6| Step: 6
Training loss: 2.581071376800537
Validation loss: 2.095541500276135

Epoch: 6| Step: 7
Training loss: 2.8216936588287354
Validation loss: 2.0911047766285558

Epoch: 6| Step: 8
Training loss: 2.2006540298461914
Validation loss: 2.097726821899414

Epoch: 6| Step: 9
Training loss: 2.09370493888855
Validation loss: 2.090910291159025

Epoch: 6| Step: 10
Training loss: 2.4435553550720215
Validation loss: 2.0967275891252743

Epoch: 6| Step: 11
Training loss: 2.8479795455932617
Validation loss: 2.085780741066061

Epoch: 6| Step: 12
Training loss: 2.076775312423706
Validation loss: 2.090829962043352

Epoch: 6| Step: 13
Training loss: 2.1802642345428467
Validation loss: 2.0932007092301563

Epoch: 101| Step: 0
Training loss: 2.3957736492156982
Validation loss: 2.086984593381164

Epoch: 6| Step: 1
Training loss: 1.8208297491073608
Validation loss: 2.089265928473524

Epoch: 6| Step: 2
Training loss: 2.0305113792419434
Validation loss: 2.08082043099147

Epoch: 6| Step: 3
Training loss: 2.0660221576690674
Validation loss: 2.0776514263563257

Epoch: 6| Step: 4
Training loss: 2.629403829574585
Validation loss: 2.0906643944401897

Epoch: 6| Step: 5
Training loss: 1.7779011726379395
Validation loss: 2.1026949446688414

Epoch: 6| Step: 6
Training loss: 2.437349319458008
Validation loss: 2.1022114599904707

Epoch: 6| Step: 7
Training loss: 2.0931906700134277
Validation loss: 2.106297469908191

Epoch: 6| Step: 8
Training loss: 2.783191204071045
Validation loss: 2.0873633289849884

Epoch: 6| Step: 9
Training loss: 2.1276297569274902
Validation loss: 2.097009128139865

Epoch: 6| Step: 10
Training loss: 2.6886658668518066
Validation loss: 2.1029989783481886

Epoch: 6| Step: 11
Training loss: 2.8169708251953125
Validation loss: 2.1178327939843618

Epoch: 6| Step: 12
Training loss: 2.1136980056762695
Validation loss: 2.1119741444946616

Epoch: 6| Step: 13
Training loss: 2.873110055923462
Validation loss: 2.10097292289939

Epoch: 102| Step: 0
Training loss: 2.2565932273864746
Validation loss: 2.084390289040022

Epoch: 6| Step: 1
Training loss: 2.3458194732666016
Validation loss: 2.080006327680362

Epoch: 6| Step: 2
Training loss: 2.815215587615967
Validation loss: 2.074632065270537

Epoch: 6| Step: 3
Training loss: 2.0604000091552734
Validation loss: 2.0780254589614047

Epoch: 6| Step: 4
Training loss: 3.3653407096862793
Validation loss: 2.0857782940710745

Epoch: 6| Step: 5
Training loss: 2.4816160202026367
Validation loss: 2.081689009102442

Epoch: 6| Step: 6
Training loss: 2.6399431228637695
Validation loss: 2.102424201144967

Epoch: 6| Step: 7
Training loss: 1.2364422082901
Validation loss: 2.0923540412738757

Epoch: 6| Step: 8
Training loss: 1.9228628873825073
Validation loss: 2.105134376915552

Epoch: 6| Step: 9
Training loss: 1.7382619380950928
Validation loss: 2.12848307753122

Epoch: 6| Step: 10
Training loss: 2.6149497032165527
Validation loss: 2.1740618034075667

Epoch: 6| Step: 11
Training loss: 2.571958065032959
Validation loss: 2.171544095521332

Epoch: 6| Step: 12
Training loss: 2.912842273712158
Validation loss: 2.1343499191345705

Epoch: 6| Step: 13
Training loss: 1.502530813217163
Validation loss: 2.0939820569048644

Epoch: 103| Step: 0
Training loss: 1.621333360671997
Validation loss: 2.0943285380640337

Epoch: 6| Step: 1
Training loss: 3.0489258766174316
Validation loss: 2.0985807270132084

Epoch: 6| Step: 2
Training loss: 2.058239698410034
Validation loss: 2.0952882382177536

Epoch: 6| Step: 3
Training loss: 2.3566691875457764
Validation loss: 2.1129322257093204

Epoch: 6| Step: 4
Training loss: 2.1478097438812256
Validation loss: 2.12035785951922

Epoch: 6| Step: 5
Training loss: 2.9611387252807617
Validation loss: 2.119173821582589

Epoch: 6| Step: 6
Training loss: 1.8934935331344604
Validation loss: 2.1053036592339955

Epoch: 6| Step: 7
Training loss: 2.159153461456299
Validation loss: 2.1100188878274735

Epoch: 6| Step: 8
Training loss: 1.8010042905807495
Validation loss: 2.0984547753487863

Epoch: 6| Step: 9
Training loss: 2.293731689453125
Validation loss: 2.0951740382820048

Epoch: 6| Step: 10
Training loss: 2.5661892890930176
Validation loss: 2.0930186010176137

Epoch: 6| Step: 11
Training loss: 3.142176628112793
Validation loss: 2.0802448616232923

Epoch: 6| Step: 12
Training loss: 1.9063341617584229
Validation loss: 2.0830463312005483

Epoch: 6| Step: 13
Training loss: 2.561166524887085
Validation loss: 2.086767229982602

Epoch: 104| Step: 0
Training loss: 1.9416524171829224
Validation loss: 2.0682813839245866

Epoch: 6| Step: 1
Training loss: 2.893866539001465
Validation loss: 2.0803607279254543

Epoch: 6| Step: 2
Training loss: 2.221554756164551
Validation loss: 2.077289512080531

Epoch: 6| Step: 3
Training loss: 2.903149366378784
Validation loss: 2.0612132126285183

Epoch: 6| Step: 4
Training loss: 2.36336088180542
Validation loss: 2.0685798814219813

Epoch: 6| Step: 5
Training loss: 1.9419314861297607
Validation loss: 2.0809244955739667

Epoch: 6| Step: 6
Training loss: 2.2360846996307373
Validation loss: 2.0985276058156

Epoch: 6| Step: 7
Training loss: 2.9687161445617676
Validation loss: 2.12472257819227

Epoch: 6| Step: 8
Training loss: 1.9702295064926147
Validation loss: 2.1456992510826356

Epoch: 6| Step: 9
Training loss: 1.9603965282440186
Validation loss: 2.1586188923928047

Epoch: 6| Step: 10
Training loss: 2.375861644744873
Validation loss: 2.1564534146298646

Epoch: 6| Step: 11
Training loss: 2.7801427841186523
Validation loss: 2.14917730516003

Epoch: 6| Step: 12
Training loss: 2.195549964904785
Validation loss: 2.1251970465465257

Epoch: 6| Step: 13
Training loss: 1.5176156759262085
Validation loss: 2.11973266319562

Epoch: 105| Step: 0
Training loss: 1.5492948293685913
Validation loss: 2.0886073727761545

Epoch: 6| Step: 1
Training loss: 2.5482277870178223
Validation loss: 2.0835408818337227

Epoch: 6| Step: 2
Training loss: 2.449326992034912
Validation loss: 2.0763945451346775

Epoch: 6| Step: 3
Training loss: 2.0886991024017334
Validation loss: 2.08222024415129

Epoch: 6| Step: 4
Training loss: 1.9126863479614258
Validation loss: 2.082183976327219

Epoch: 6| Step: 5
Training loss: 2.923588752746582
Validation loss: 2.094957959267401

Epoch: 6| Step: 6
Training loss: 2.6576309204101562
Validation loss: 2.090523858224192

Epoch: 6| Step: 7
Training loss: 2.0952348709106445
Validation loss: 2.08553990497384

Epoch: 6| Step: 8
Training loss: 2.3020107746124268
Validation loss: 2.0878207324653544

Epoch: 6| Step: 9
Training loss: 2.612725019454956
Validation loss: 2.0885723726723784

Epoch: 6| Step: 10
Training loss: 2.2112343311309814
Validation loss: 2.0846432178251204

Epoch: 6| Step: 11
Training loss: 1.8758699893951416
Validation loss: 2.081637640153208

Epoch: 6| Step: 12
Training loss: 2.6652636528015137
Validation loss: 2.0644920487557687

Epoch: 6| Step: 13
Training loss: 2.376544237136841
Validation loss: 2.07190776384005

Epoch: 106| Step: 0
Training loss: 2.6058027744293213
Validation loss: 2.067336449059107

Epoch: 6| Step: 1
Training loss: 2.083559989929199
Validation loss: 2.0695271697095645

Epoch: 6| Step: 2
Training loss: 2.6089282035827637
Validation loss: 2.0649756693070933

Epoch: 6| Step: 3
Training loss: 2.4878416061401367
Validation loss: 2.053964981468775

Epoch: 6| Step: 4
Training loss: 2.2021751403808594
Validation loss: 2.05898033162599

Epoch: 6| Step: 5
Training loss: 2.5755834579467773
Validation loss: 2.0564744728867725

Epoch: 6| Step: 6
Training loss: 1.752264142036438
Validation loss: 2.0570110979900567

Epoch: 6| Step: 7
Training loss: 2.022739887237549
Validation loss: 2.060175634199573

Epoch: 6| Step: 8
Training loss: 1.609697699546814
Validation loss: 2.0646311301057056

Epoch: 6| Step: 9
Training loss: 2.5243020057678223
Validation loss: 2.0622039200157247

Epoch: 6| Step: 10
Training loss: 2.5700671672821045
Validation loss: 2.0565603522844214

Epoch: 6| Step: 11
Training loss: 2.4790923595428467
Validation loss: 2.0729101832194994

Epoch: 6| Step: 12
Training loss: 2.3134775161743164
Validation loss: 2.0795459093586093

Epoch: 6| Step: 13
Training loss: 2.804805278778076
Validation loss: 2.0926786263783774

Epoch: 107| Step: 0
Training loss: 2.4439456462860107
Validation loss: 2.0983320718170493

Epoch: 6| Step: 1
Training loss: 2.1261003017425537
Validation loss: 2.0861448639182636

Epoch: 6| Step: 2
Training loss: 1.9700766801834106
Validation loss: 2.0836558726526078

Epoch: 6| Step: 3
Training loss: 1.5238606929779053
Validation loss: 2.0816194959866103

Epoch: 6| Step: 4
Training loss: 2.352424383163452
Validation loss: 2.079544472438033

Epoch: 6| Step: 5
Training loss: 2.4296624660491943
Validation loss: 2.0671231067308815

Epoch: 6| Step: 6
Training loss: 2.6105728149414062
Validation loss: 2.0602560350971837

Epoch: 6| Step: 7
Training loss: 2.088791847229004
Validation loss: 2.051412243996897

Epoch: 6| Step: 8
Training loss: 2.0364837646484375
Validation loss: 2.019997207067346

Epoch: 6| Step: 9
Training loss: 2.836550235748291
Validation loss: 2.030291126620385

Epoch: 6| Step: 10
Training loss: 2.2711572647094727
Validation loss: 2.0218965930323445

Epoch: 6| Step: 11
Training loss: 2.7640023231506348
Validation loss: 2.013429214877467

Epoch: 6| Step: 12
Training loss: 2.901461124420166
Validation loss: 2.0124890291562645

Epoch: 6| Step: 13
Training loss: 1.4203099012374878
Validation loss: 2.007427301458133

Epoch: 108| Step: 0
Training loss: 2.5484633445739746
Validation loss: 2.0273632234142673

Epoch: 6| Step: 1
Training loss: 2.5062429904937744
Validation loss: 2.0289188866974204

Epoch: 6| Step: 2
Training loss: 1.7291030883789062
Validation loss: 2.0779412869484193

Epoch: 6| Step: 3
Training loss: 3.003382444381714
Validation loss: 2.0834918893793577

Epoch: 6| Step: 4
Training loss: 2.1406850814819336
Validation loss: 2.0841410467701573

Epoch: 6| Step: 5
Training loss: 2.4881844520568848
Validation loss: 2.039137631334284

Epoch: 6| Step: 6
Training loss: 1.9976023435592651
Validation loss: 2.0098286982505553

Epoch: 6| Step: 7
Training loss: 2.7358102798461914
Validation loss: 1.996622557281166

Epoch: 6| Step: 8
Training loss: 2.292752742767334
Validation loss: 2.012991113047446

Epoch: 6| Step: 9
Training loss: 1.7110153436660767
Validation loss: 2.0143837928771973

Epoch: 6| Step: 10
Training loss: 2.0478146076202393
Validation loss: 2.0074253018184374

Epoch: 6| Step: 11
Training loss: 2.855433464050293
Validation loss: 2.002484151112136

Epoch: 6| Step: 12
Training loss: 2.171286106109619
Validation loss: 2.012365015604163

Epoch: 6| Step: 13
Training loss: 1.7971091270446777
Validation loss: 2.008636337454601

Epoch: 109| Step: 0
Training loss: 2.086775541305542
Validation loss: 2.0206970553244314

Epoch: 6| Step: 1
Training loss: 2.614560127258301
Validation loss: 2.0368441638126167

Epoch: 6| Step: 2
Training loss: 1.766312837600708
Validation loss: 2.069792958997911

Epoch: 6| Step: 3
Training loss: 3.011795997619629
Validation loss: 2.0650248886436544

Epoch: 6| Step: 4
Training loss: 2.3887643814086914
Validation loss: 2.0428260628895094

Epoch: 6| Step: 5
Training loss: 2.5712289810180664
Validation loss: 2.034232517724396

Epoch: 6| Step: 6
Training loss: 2.6604533195495605
Validation loss: 2.007646814469368

Epoch: 6| Step: 7
Training loss: 2.4725584983825684
Validation loss: 1.9908420552489579

Epoch: 6| Step: 8
Training loss: 2.184938907623291
Validation loss: 2.008306134131647

Epoch: 6| Step: 9
Training loss: 1.9345464706420898
Validation loss: 2.0276973016800417

Epoch: 6| Step: 10
Training loss: 2.2142789363861084
Validation loss: 2.0470472638325026

Epoch: 6| Step: 11
Training loss: 2.2253994941711426
Validation loss: 2.0451346302545197

Epoch: 6| Step: 12
Training loss: 2.1063435077667236
Validation loss: 2.0663817428773448

Epoch: 6| Step: 13
Training loss: 1.8625414371490479
Validation loss: 2.1130470716825096

Epoch: 110| Step: 0
Training loss: 2.1296355724334717
Validation loss: 2.1219998213552658

Epoch: 6| Step: 1
Training loss: 2.7182188034057617
Validation loss: 2.116153701659172

Epoch: 6| Step: 2
Training loss: 1.9117070436477661
Validation loss: 2.1072949376157535

Epoch: 6| Step: 3
Training loss: 2.29274845123291
Validation loss: 2.1057103423662085

Epoch: 6| Step: 4
Training loss: 2.594320297241211
Validation loss: 2.064762606415697

Epoch: 6| Step: 5
Training loss: 1.8736586570739746
Validation loss: 2.027921712526711

Epoch: 6| Step: 6
Training loss: 2.7687766551971436
Validation loss: 1.9956719670244443

Epoch: 6| Step: 7
Training loss: 2.754047393798828
Validation loss: 1.985928080415213

Epoch: 6| Step: 8
Training loss: 1.6313648223876953
Validation loss: 1.9876751104990642

Epoch: 6| Step: 9
Training loss: 2.432384729385376
Validation loss: 1.993049834364204

Epoch: 6| Step: 10
Training loss: 2.5782177448272705
Validation loss: 2.0006768318914596

Epoch: 6| Step: 11
Training loss: 2.1840267181396484
Validation loss: 2.0037425500090404

Epoch: 6| Step: 12
Training loss: 2.2754998207092285
Validation loss: 2.0331791523964173

Epoch: 6| Step: 13
Training loss: 2.274797201156616
Validation loss: 2.051929466186031

Epoch: 111| Step: 0
Training loss: 2.5350444316864014
Validation loss: 2.087124057995376

Epoch: 6| Step: 1
Training loss: 2.2505180835723877
Validation loss: 2.0822418889691754

Epoch: 6| Step: 2
Training loss: 2.1539535522460938
Validation loss: 2.0630570432191253

Epoch: 6| Step: 3
Training loss: 2.653275966644287
Validation loss: 2.0495924103644585

Epoch: 6| Step: 4
Training loss: 2.4268059730529785
Validation loss: 2.0352526044332855

Epoch: 6| Step: 5
Training loss: 1.4166920185089111
Validation loss: 2.0290393149980934

Epoch: 6| Step: 6
Training loss: 2.089900493621826
Validation loss: 2.0344917671654814

Epoch: 6| Step: 7
Training loss: 2.3210272789001465
Validation loss: 2.014387830611198

Epoch: 6| Step: 8
Training loss: 2.264146566390991
Validation loss: 2.0279936713557087

Epoch: 6| Step: 9
Training loss: 2.3690853118896484
Validation loss: 2.012833345320917

Epoch: 6| Step: 10
Training loss: 2.339167594909668
Validation loss: 2.0223735019724858

Epoch: 6| Step: 11
Training loss: 2.165562629699707
Validation loss: 2.0182729369850567

Epoch: 6| Step: 12
Training loss: 2.411653518676758
Validation loss: 2.013099285864061

Epoch: 6| Step: 13
Training loss: 2.6380815505981445
Validation loss: 2.010196921645954

Epoch: 112| Step: 0
Training loss: 2.160010814666748
Validation loss: 2.0171859982193157

Epoch: 6| Step: 1
Training loss: 1.627890944480896
Validation loss: 2.0053130247259654

Epoch: 6| Step: 2
Training loss: 1.6615403890609741
Validation loss: 2.0102442105611167

Epoch: 6| Step: 3
Training loss: 2.5553619861602783
Validation loss: 2.0170241427677933

Epoch: 6| Step: 4
Training loss: 2.567197799682617
Validation loss: 2.003692373152702

Epoch: 6| Step: 5
Training loss: 2.0497283935546875
Validation loss: 2.0221541543160715

Epoch: 6| Step: 6
Training loss: 2.1008520126342773
Validation loss: 2.0293272490142495

Epoch: 6| Step: 7
Training loss: 2.297834873199463
Validation loss: 2.0298197705258607

Epoch: 6| Step: 8
Training loss: 2.8799142837524414
Validation loss: 2.06283555235914

Epoch: 6| Step: 9
Training loss: 2.721409559249878
Validation loss: 2.0769895558716147

Epoch: 6| Step: 10
Training loss: 1.8160123825073242
Validation loss: 2.085382569220758

Epoch: 6| Step: 11
Training loss: 2.796591281890869
Validation loss: 2.0917338043130855

Epoch: 6| Step: 12
Training loss: 2.0119056701660156
Validation loss: 2.0858829611091205

Epoch: 6| Step: 13
Training loss: 2.412625312805176
Validation loss: 2.076490640640259

Epoch: 113| Step: 0
Training loss: 2.957035541534424
Validation loss: 2.0335339384694255

Epoch: 6| Step: 1
Training loss: 2.2465500831604004
Validation loss: 2.0079344741759764

Epoch: 6| Step: 2
Training loss: 1.8186588287353516
Validation loss: 2.0215603895084833

Epoch: 6| Step: 3
Training loss: 1.9890364408493042
Validation loss: 2.0150118617601294

Epoch: 6| Step: 4
Training loss: 2.1879804134368896
Validation loss: 2.025156251845821

Epoch: 6| Step: 5
Training loss: 2.1840109825134277
Validation loss: 2.0852195550036687

Epoch: 6| Step: 6
Training loss: 2.184481620788574
Validation loss: 2.099629820034068

Epoch: 6| Step: 7
Training loss: 2.6962857246398926
Validation loss: 2.101210965905138

Epoch: 6| Step: 8
Training loss: 2.970771312713623
Validation loss: 2.1013134448759017

Epoch: 6| Step: 9
Training loss: 2.324005603790283
Validation loss: 2.1252472528847317

Epoch: 6| Step: 10
Training loss: 1.8731203079223633
Validation loss: 2.137791739997043

Epoch: 6| Step: 11
Training loss: 2.208942413330078
Validation loss: 2.1332991174472276

Epoch: 6| Step: 12
Training loss: 1.8254482746124268
Validation loss: 2.1704058852247012

Epoch: 6| Step: 13
Training loss: 3.174032688140869
Validation loss: 2.123123812419112

Epoch: 114| Step: 0
Training loss: 2.408518075942993
Validation loss: 2.134641191010834

Epoch: 6| Step: 1
Training loss: 2.0620548725128174
Validation loss: 2.1419440674525436

Epoch: 6| Step: 2
Training loss: 2.095170259475708
Validation loss: 2.1534598283870245

Epoch: 6| Step: 3
Training loss: 2.0842113494873047
Validation loss: 2.169121132102064

Epoch: 6| Step: 4
Training loss: 2.1604418754577637
Validation loss: 2.166781138348323

Epoch: 6| Step: 5
Training loss: 2.203394651412964
Validation loss: 2.1509541798663396

Epoch: 6| Step: 6
Training loss: 1.9387571811676025
Validation loss: 2.139761224869759

Epoch: 6| Step: 7
Training loss: 2.594033718109131
Validation loss: 2.140748667460616

Epoch: 6| Step: 8
Training loss: 3.124875545501709
Validation loss: 2.1079906007295013

Epoch: 6| Step: 9
Training loss: 1.958580732345581
Validation loss: 2.1017034438348587

Epoch: 6| Step: 10
Training loss: 2.476799726486206
Validation loss: 2.0843712258082565

Epoch: 6| Step: 11
Training loss: 2.2701504230499268
Validation loss: 2.070130576369583

Epoch: 6| Step: 12
Training loss: 2.8168792724609375
Validation loss: 2.0603784540648102

Epoch: 6| Step: 13
Training loss: 1.7190982103347778
Validation loss: 2.0662856691627094

Epoch: 115| Step: 0
Training loss: 1.5921645164489746
Validation loss: 2.062585051341723

Epoch: 6| Step: 1
Training loss: 2.303539514541626
Validation loss: 2.0693301590540076

Epoch: 6| Step: 2
Training loss: 2.8909802436828613
Validation loss: 2.062150593726866

Epoch: 6| Step: 3
Training loss: 2.3788552284240723
Validation loss: 2.0589621208047353

Epoch: 6| Step: 4
Training loss: 2.226053237915039
Validation loss: 2.077690680821737

Epoch: 6| Step: 5
Training loss: 2.4168591499328613
Validation loss: 2.086100891072263

Epoch: 6| Step: 6
Training loss: 2.4270358085632324
Validation loss: 2.1152732615829795

Epoch: 6| Step: 7
Training loss: 1.9026167392730713
Validation loss: 2.1424099835016395

Epoch: 6| Step: 8
Training loss: 2.839090347290039
Validation loss: 2.130947346328407

Epoch: 6| Step: 9
Training loss: 2.599506139755249
Validation loss: 2.0818171924160374

Epoch: 6| Step: 10
Training loss: 2.4626760482788086
Validation loss: 2.0398361836710284

Epoch: 6| Step: 11
Training loss: 2.2122111320495605
Validation loss: 2.018180534403811

Epoch: 6| Step: 12
Training loss: 1.5998890399932861
Validation loss: 1.991303929718592

Epoch: 6| Step: 13
Training loss: 1.9425348043441772
Validation loss: 1.9835078536823232

Epoch: 116| Step: 0
Training loss: 1.758570671081543
Validation loss: 1.9844052445503972

Epoch: 6| Step: 1
Training loss: 2.870724678039551
Validation loss: 1.979075522832973

Epoch: 6| Step: 2
Training loss: 1.8430029153823853
Validation loss: 1.9881787030927596

Epoch: 6| Step: 3
Training loss: 2.155892848968506
Validation loss: 1.9844016836535545

Epoch: 6| Step: 4
Training loss: 2.1617836952209473
Validation loss: 1.9769087312042073

Epoch: 6| Step: 5
Training loss: 2.9558684825897217
Validation loss: 1.9804489561306533

Epoch: 6| Step: 6
Training loss: 2.811222553253174
Validation loss: 2.016115196289555

Epoch: 6| Step: 7
Training loss: 2.227337598800659
Validation loss: 2.0478403504176805

Epoch: 6| Step: 8
Training loss: 1.8062080144882202
Validation loss: 2.071604008315712

Epoch: 6| Step: 9
Training loss: 2.2670211791992188
Validation loss: 2.051215242314082

Epoch: 6| Step: 10
Training loss: 2.5544159412384033
Validation loss: 2.034642202879793

Epoch: 6| Step: 11
Training loss: 2.1474897861480713
Validation loss: 1.9898722594784153

Epoch: 6| Step: 12
Training loss: 2.021660804748535
Validation loss: 1.9761495359482304

Epoch: 6| Step: 13
Training loss: 1.762480616569519
Validation loss: 1.9748500444555794

Epoch: 117| Step: 0
Training loss: 2.7692463397979736
Validation loss: 1.9711372467779344

Epoch: 6| Step: 1
Training loss: 2.293701648712158
Validation loss: 1.982552259199081

Epoch: 6| Step: 2
Training loss: 2.1844565868377686
Validation loss: 1.9853465095643075

Epoch: 6| Step: 3
Training loss: 2.1586623191833496
Validation loss: 1.9842214609986992

Epoch: 6| Step: 4
Training loss: 1.6653156280517578
Validation loss: 1.9861480343726374

Epoch: 6| Step: 5
Training loss: 2.2006311416625977
Validation loss: 2.0154922495606127

Epoch: 6| Step: 6
Training loss: 1.9176993370056152
Validation loss: 2.007142020810035

Epoch: 6| Step: 7
Training loss: 2.314095973968506
Validation loss: 2.036094496327062

Epoch: 6| Step: 8
Training loss: 2.2037808895111084
Validation loss: 2.0358793389412666

Epoch: 6| Step: 9
Training loss: 1.875610589981079
Validation loss: 2.037760021866009

Epoch: 6| Step: 10
Training loss: 2.1479902267456055
Validation loss: 2.028689120405464

Epoch: 6| Step: 11
Training loss: 2.6058247089385986
Validation loss: 2.0050842864539034

Epoch: 6| Step: 12
Training loss: 1.901943325996399
Validation loss: 1.9752549458575506

Epoch: 6| Step: 13
Training loss: 3.3925957679748535
Validation loss: 1.9751778251381331

Epoch: 118| Step: 0
Training loss: 2.393659830093384
Validation loss: 1.9760623452483967

Epoch: 6| Step: 1
Training loss: 1.68223237991333
Validation loss: 1.9685920130821966

Epoch: 6| Step: 2
Training loss: 2.8462979793548584
Validation loss: 1.9714580582034202

Epoch: 6| Step: 3
Training loss: 1.9502546787261963
Validation loss: 1.9596969837783484

Epoch: 6| Step: 4
Training loss: 2.1554055213928223
Validation loss: 1.974834426756828

Epoch: 6| Step: 5
Training loss: 2.320251703262329
Validation loss: 1.9911757233322307

Epoch: 6| Step: 6
Training loss: 2.588078737258911
Validation loss: 1.9823553780073762

Epoch: 6| Step: 7
Training loss: 1.7266814708709717
Validation loss: 1.9802577354574715

Epoch: 6| Step: 8
Training loss: 2.468960762023926
Validation loss: 1.9974837187797791

Epoch: 6| Step: 9
Training loss: 2.237213134765625
Validation loss: 2.0044663465151222

Epoch: 6| Step: 10
Training loss: 2.634767532348633
Validation loss: 2.0076924318908365

Epoch: 6| Step: 11
Training loss: 1.6040173768997192
Validation loss: 2.0183520342714045

Epoch: 6| Step: 12
Training loss: 2.5645928382873535
Validation loss: 2.0329853180916078

Epoch: 6| Step: 13
Training loss: 1.9548310041427612
Validation loss: 2.0351963825123285

Epoch: 119| Step: 0
Training loss: 2.223942756652832
Validation loss: 2.0369332144337315

Epoch: 6| Step: 1
Training loss: 2.3014652729034424
Validation loss: 2.0374352085974907

Epoch: 6| Step: 2
Training loss: 2.825922727584839
Validation loss: 2.023750538467079

Epoch: 6| Step: 3
Training loss: 2.7803683280944824
Validation loss: 2.0128796741526616

Epoch: 6| Step: 4
Training loss: 1.871798038482666
Validation loss: 2.0144208579935055

Epoch: 6| Step: 5
Training loss: 1.8083484172821045
Validation loss: 1.992304959604817

Epoch: 6| Step: 6
Training loss: 2.8024301528930664
Validation loss: 1.985824961816111

Epoch: 6| Step: 7
Training loss: 1.9051717519760132
Validation loss: 1.9641117524075251

Epoch: 6| Step: 8
Training loss: 1.8159244060516357
Validation loss: 1.9804493842586395

Epoch: 6| Step: 9
Training loss: 2.3871755599975586
Validation loss: 1.9778676584202757

Epoch: 6| Step: 10
Training loss: 2.467895269393921
Validation loss: 1.9717020706463886

Epoch: 6| Step: 11
Training loss: 1.6053789854049683
Validation loss: 1.980666087519738

Epoch: 6| Step: 12
Training loss: 2.0470991134643555
Validation loss: 1.9892801636008806

Epoch: 6| Step: 13
Training loss: 2.164470672607422
Validation loss: 2.0010016323417745

Epoch: 120| Step: 0
Training loss: 2.2101950645446777
Validation loss: 2.031772211033811

Epoch: 6| Step: 1
Training loss: 2.529480457305908
Validation loss: 2.0596973357662076

Epoch: 6| Step: 2
Training loss: 1.9738922119140625
Validation loss: 2.072443458341783

Epoch: 6| Step: 3
Training loss: 2.02955961227417
Validation loss: 2.0697816571881695

Epoch: 6| Step: 4
Training loss: 2.901360511779785
Validation loss: 2.0638413634351505

Epoch: 6| Step: 5
Training loss: 2.7139034271240234
Validation loss: 2.0573657853629

Epoch: 6| Step: 6
Training loss: 1.752450942993164
Validation loss: 2.0350509946064284

Epoch: 6| Step: 7
Training loss: 1.8271183967590332
Validation loss: 2.002911880452146

Epoch: 6| Step: 8
Training loss: 2.0855302810668945
Validation loss: 2.007067726504418

Epoch: 6| Step: 9
Training loss: 1.563077449798584
Validation loss: 2.0035734150999334

Epoch: 6| Step: 10
Training loss: 3.0827012062072754
Validation loss: 2.022138117462076

Epoch: 6| Step: 11
Training loss: 1.8857810497283936
Validation loss: 2.031493035695886

Epoch: 6| Step: 12
Training loss: 2.0605835914611816
Validation loss: 2.066871540520781

Epoch: 6| Step: 13
Training loss: 2.852217435836792
Validation loss: 2.0655309974506335

Epoch: 121| Step: 0
Training loss: 1.728158950805664
Validation loss: 2.0739474578570296

Epoch: 6| Step: 1
Training loss: 2.2290377616882324
Validation loss: 2.096434839310185

Epoch: 6| Step: 2
Training loss: 2.1661458015441895
Validation loss: 2.1242157541295534

Epoch: 6| Step: 3
Training loss: 3.4544260501861572
Validation loss: 2.1262705543989777

Epoch: 6| Step: 4
Training loss: 1.9173028469085693
Validation loss: 2.083758415714387

Epoch: 6| Step: 5
Training loss: 2.0799150466918945
Validation loss: 2.083748008615227

Epoch: 6| Step: 6
Training loss: 2.421400785446167
Validation loss: 2.067158455489784

Epoch: 6| Step: 7
Training loss: 2.5591845512390137
Validation loss: 2.0342315589227984

Epoch: 6| Step: 8
Training loss: 1.9837052822113037
Validation loss: 2.0118209059520433

Epoch: 6| Step: 9
Training loss: 2.35227632522583
Validation loss: 2.011554641108359

Epoch: 6| Step: 10
Training loss: 2.3470258712768555
Validation loss: 2.014026085535685

Epoch: 6| Step: 11
Training loss: 2.2182958126068115
Validation loss: 2.0394987278087164

Epoch: 6| Step: 12
Training loss: 2.49165415763855
Validation loss: 2.05393797351468

Epoch: 6| Step: 13
Training loss: 1.4126791954040527
Validation loss: 2.0577465821337957

Epoch: 122| Step: 0
Training loss: 1.8898804187774658
Validation loss: 2.0631795044868224

Epoch: 6| Step: 1
Training loss: 2.387526273727417
Validation loss: 2.049047035555686

Epoch: 6| Step: 2
Training loss: 2.8202333450317383
Validation loss: 2.061883916137039

Epoch: 6| Step: 3
Training loss: 2.41469144821167
Validation loss: 2.0540547652911116

Epoch: 6| Step: 4
Training loss: 1.5958080291748047
Validation loss: 2.0282579378415178

Epoch: 6| Step: 5
Training loss: 2.392695426940918
Validation loss: 2.017222155806839

Epoch: 6| Step: 6
Training loss: 2.7695138454437256
Validation loss: 2.0012710068815496

Epoch: 6| Step: 7
Training loss: 1.772830843925476
Validation loss: 1.992809034162952

Epoch: 6| Step: 8
Training loss: 1.5563666820526123
Validation loss: 1.999859684257097

Epoch: 6| Step: 9
Training loss: 2.392253875732422
Validation loss: 2.015756522455523

Epoch: 6| Step: 10
Training loss: 2.423086404800415
Validation loss: 2.019910584213913

Epoch: 6| Step: 11
Training loss: 1.8695342540740967
Validation loss: 2.0397188612209853

Epoch: 6| Step: 12
Training loss: 2.902477979660034
Validation loss: 2.028267382293619

Epoch: 6| Step: 13
Training loss: 1.129272699356079
Validation loss: 2.045483991663943

Epoch: 123| Step: 0
Training loss: 2.3771491050720215
Validation loss: 2.096421924970483

Epoch: 6| Step: 1
Training loss: 2.2770638465881348
Validation loss: 2.0928102462522444

Epoch: 6| Step: 2
Training loss: 1.8375110626220703
Validation loss: 2.086344295932401

Epoch: 6| Step: 3
Training loss: 2.867521047592163
Validation loss: 2.090492756136002

Epoch: 6| Step: 4
Training loss: 2.0404181480407715
Validation loss: 2.105817033398536

Epoch: 6| Step: 5
Training loss: 2.55960750579834
Validation loss: 2.1353447180922314

Epoch: 6| Step: 6
Training loss: 3.149965763092041
Validation loss: 2.1523122787475586

Epoch: 6| Step: 7
Training loss: 3.0454330444335938
Validation loss: 2.173771901797223

Epoch: 6| Step: 8
Training loss: 2.4498648643493652
Validation loss: 2.168451416877008

Epoch: 6| Step: 9
Training loss: 2.1281723976135254
Validation loss: 2.155684262193659

Epoch: 6| Step: 10
Training loss: 1.8200249671936035
Validation loss: 2.1263477930458645

Epoch: 6| Step: 11
Training loss: 1.6215189695358276
Validation loss: 2.075977844576682

Epoch: 6| Step: 12
Training loss: 1.9647066593170166
Validation loss: 2.0612628203566357

Epoch: 6| Step: 13
Training loss: 1.4484728574752808
Validation loss: 2.0338297146622852

Epoch: 124| Step: 0
Training loss: 2.080566883087158
Validation loss: 2.0304114036662604

Epoch: 6| Step: 1
Training loss: 2.998262882232666
Validation loss: 2.0236939179000033

Epoch: 6| Step: 2
Training loss: 1.7664705514907837
Validation loss: 2.0145002359985025

Epoch: 6| Step: 3
Training loss: 2.0299270153045654
Validation loss: 2.0208491599687965

Epoch: 6| Step: 4
Training loss: 2.423330783843994
Validation loss: 2.027097293125686

Epoch: 6| Step: 5
Training loss: 2.3408384323120117
Validation loss: 2.0130736238212994

Epoch: 6| Step: 6
Training loss: 1.7233445644378662
Validation loss: 2.038320332445124

Epoch: 6| Step: 7
Training loss: 2.273098945617676
Validation loss: 2.0240824376383135

Epoch: 6| Step: 8
Training loss: 2.112483501434326
Validation loss: 2.0118160324711956

Epoch: 6| Step: 9
Training loss: 1.9383907318115234
Validation loss: 2.0239563116463284

Epoch: 6| Step: 10
Training loss: 2.5378124713897705
Validation loss: 2.0068940706150507

Epoch: 6| Step: 11
Training loss: 2.241940498352051
Validation loss: 2.0184591752226635

Epoch: 6| Step: 12
Training loss: 2.250114917755127
Validation loss: 2.014350473239858

Epoch: 6| Step: 13
Training loss: 1.7137264013290405
Validation loss: 2.010140662552208

Epoch: 125| Step: 0
Training loss: 2.1942174434661865
Validation loss: 2.042062222316701

Epoch: 6| Step: 1
Training loss: 1.87832510471344
Validation loss: 2.0594858200319353

Epoch: 6| Step: 2
Training loss: 1.5412509441375732
Validation loss: 2.053877660023269

Epoch: 6| Step: 3
Training loss: 1.5718713998794556
Validation loss: 2.0179118366651636

Epoch: 6| Step: 4
Training loss: 2.1379542350769043
Validation loss: 2.0188585583881666

Epoch: 6| Step: 5
Training loss: 2.8423399925231934
Validation loss: 2.01739029858702

Epoch: 6| Step: 6
Training loss: 2.106423854827881
Validation loss: 2.0075601403431227

Epoch: 6| Step: 7
Training loss: 2.2896785736083984
Validation loss: 1.994181453540761

Epoch: 6| Step: 8
Training loss: 2.9454033374786377
Validation loss: 2.0015779567021195

Epoch: 6| Step: 9
Training loss: 1.797422170639038
Validation loss: 1.9807434594759377

Epoch: 6| Step: 10
Training loss: 2.010676383972168
Validation loss: 2.035171954862533

Epoch: 6| Step: 11
Training loss: 2.158909320831299
Validation loss: 2.061430174817321

Epoch: 6| Step: 12
Training loss: 2.908306837081909
Validation loss: 2.084452062524775

Epoch: 6| Step: 13
Training loss: 2.5407660007476807
Validation loss: 2.0896943141055364

Epoch: 126| Step: 0
Training loss: 2.3857154846191406
Validation loss: 2.0748528229293

Epoch: 6| Step: 1
Training loss: 2.020813226699829
Validation loss: 2.016905637197597

Epoch: 6| Step: 2
Training loss: 2.523700714111328
Validation loss: 1.977442023574665

Epoch: 6| Step: 3
Training loss: 2.0877857208251953
Validation loss: 1.9669821826360558

Epoch: 6| Step: 4
Training loss: 1.7660213708877563
Validation loss: 1.970761114551175

Epoch: 6| Step: 5
Training loss: 2.4673261642456055
Validation loss: 1.9648424745887838

Epoch: 6| Step: 6
Training loss: 1.9587634801864624
Validation loss: 1.971826353380757

Epoch: 6| Step: 7
Training loss: 1.5933890342712402
Validation loss: 1.9755207941096316

Epoch: 6| Step: 8
Training loss: 2.301623582839966
Validation loss: 2.000039346756474

Epoch: 6| Step: 9
Training loss: 2.1873931884765625
Validation loss: 2.0349219383731967

Epoch: 6| Step: 10
Training loss: 2.4904980659484863
Validation loss: 2.0752592958429807

Epoch: 6| Step: 11
Training loss: 2.4290390014648438
Validation loss: 2.1331802183581936

Epoch: 6| Step: 12
Training loss: 2.690568685531616
Validation loss: 2.0972030880630657

Epoch: 6| Step: 13
Training loss: 2.2114298343658447
Validation loss: 2.044411943804833

Epoch: 127| Step: 0
Training loss: 1.6259087324142456
Validation loss: 2.009926688286566

Epoch: 6| Step: 1
Training loss: 2.873767375946045
Validation loss: 2.0028282519309752

Epoch: 6| Step: 2
Training loss: 1.7419874668121338
Validation loss: 1.9879926584100212

Epoch: 6| Step: 3
Training loss: 2.14003324508667
Validation loss: 1.9881685574849446

Epoch: 6| Step: 4
Training loss: 1.8859093189239502
Validation loss: 1.9810252048635995

Epoch: 6| Step: 5
Training loss: 1.9940526485443115
Validation loss: 2.0020545067325717

Epoch: 6| Step: 6
Training loss: 2.8368067741394043
Validation loss: 1.9802584776314356

Epoch: 6| Step: 7
Training loss: 1.5958960056304932
Validation loss: 1.99767082096428

Epoch: 6| Step: 8
Training loss: 2.2523324489593506
Validation loss: 2.005888032656844

Epoch: 6| Step: 9
Training loss: 2.229304313659668
Validation loss: 2.006505294512677

Epoch: 6| Step: 10
Training loss: 2.085223913192749
Validation loss: 2.028243057189449

Epoch: 6| Step: 11
Training loss: 2.8091342449188232
Validation loss: 2.0304054124380952

Epoch: 6| Step: 12
Training loss: 2.3796327114105225
Validation loss: 1.9941829763432986

Epoch: 6| Step: 13
Training loss: 1.426378607749939
Validation loss: 1.9664048302558161

Epoch: 128| Step: 0
Training loss: 1.8248586654663086
Validation loss: 1.9650946932454263

Epoch: 6| Step: 1
Training loss: 2.0197062492370605
Validation loss: 1.965531615800755

Epoch: 6| Step: 2
Training loss: 2.5130932331085205
Validation loss: 1.9704990310053672

Epoch: 6| Step: 3
Training loss: 2.7868571281433105
Validation loss: 1.9679199623805221

Epoch: 6| Step: 4
Training loss: 2.441708564758301
Validation loss: 1.9755718759311143

Epoch: 6| Step: 5
Training loss: 3.3384828567504883
Validation loss: 1.9954584734414214

Epoch: 6| Step: 6
Training loss: 1.8565806150436401
Validation loss: 2.0169294265008744

Epoch: 6| Step: 7
Training loss: 2.1869289875030518
Validation loss: 2.0162891085429857

Epoch: 6| Step: 8
Training loss: 1.8071281909942627
Validation loss: 2.0134434571830173

Epoch: 6| Step: 9
Training loss: 2.788219451904297
Validation loss: 1.99778885738824

Epoch: 6| Step: 10
Training loss: 1.517471432685852
Validation loss: 1.967669225508167

Epoch: 6| Step: 11
Training loss: 1.4611501693725586
Validation loss: 1.9993562442000195

Epoch: 6| Step: 12
Training loss: 1.620630145072937
Validation loss: 1.9845562865657191

Epoch: 6| Step: 13
Training loss: 1.882770299911499
Validation loss: 1.9977838031707271

Epoch: 129| Step: 0
Training loss: 2.104175090789795
Validation loss: 1.99780656701775

Epoch: 6| Step: 1
Training loss: 2.182461738586426
Validation loss: 2.0061937224480415

Epoch: 6| Step: 2
Training loss: 1.9033730030059814
Validation loss: 2.006902446029007

Epoch: 6| Step: 3
Training loss: 2.6318249702453613
Validation loss: 1.982719721332673

Epoch: 6| Step: 4
Training loss: 2.128812551498413
Validation loss: 1.9947490794684297

Epoch: 6| Step: 5
Training loss: 1.6436841487884521
Validation loss: 2.022552518434422

Epoch: 6| Step: 6
Training loss: 2.524940252304077
Validation loss: 2.035599808539114

Epoch: 6| Step: 7
Training loss: 2.6096954345703125
Validation loss: 2.00512856565496

Epoch: 6| Step: 8
Training loss: 2.2024364471435547
Validation loss: 1.9799826452808995

Epoch: 6| Step: 9
Training loss: 2.1386122703552246
Validation loss: 1.9731573238167712

Epoch: 6| Step: 10
Training loss: 2.6163973808288574
Validation loss: 1.9569891229752572

Epoch: 6| Step: 11
Training loss: 1.3752167224884033
Validation loss: 1.9644204147400395

Epoch: 6| Step: 12
Training loss: 1.8546679019927979
Validation loss: 1.9631811034294866

Epoch: 6| Step: 13
Training loss: 2.4171981811523438
Validation loss: 1.9631516933441162

Epoch: 130| Step: 0
Training loss: 2.038102388381958
Validation loss: 1.9697459051685948

Epoch: 6| Step: 1
Training loss: 2.0658726692199707
Validation loss: 1.986532647122619

Epoch: 6| Step: 2
Training loss: 2.3240814208984375
Validation loss: 1.9963090086496005

Epoch: 6| Step: 3
Training loss: 1.3650542497634888
Validation loss: 2.003590723519684

Epoch: 6| Step: 4
Training loss: 2.2335338592529297
Validation loss: 2.004985968271891

Epoch: 6| Step: 5
Training loss: 2.7722465991973877
Validation loss: 2.0107364039267264

Epoch: 6| Step: 6
Training loss: 1.967606544494629
Validation loss: 2.0002113311521468

Epoch: 6| Step: 7
Training loss: 2.0219569206237793
Validation loss: 1.9972651850792669

Epoch: 6| Step: 8
Training loss: 1.889589548110962
Validation loss: 1.9917394204806256

Epoch: 6| Step: 9
Training loss: 3.1238393783569336
Validation loss: 1.9780494141322311

Epoch: 6| Step: 10
Training loss: 2.4556055068969727
Validation loss: 1.9741392917530511

Epoch: 6| Step: 11
Training loss: 1.848904013633728
Validation loss: 1.9723515408013457

Epoch: 6| Step: 12
Training loss: 1.606087327003479
Validation loss: 1.9826466191199519

Epoch: 6| Step: 13
Training loss: 2.4271039962768555
Validation loss: 1.9846503580770185

Epoch: 131| Step: 0
Training loss: 2.196981430053711
Validation loss: 1.9956173396879626

Epoch: 6| Step: 1
Training loss: 2.9027693271636963
Validation loss: 1.9741622376185592

Epoch: 6| Step: 2
Training loss: 2.3561792373657227
Validation loss: 1.9549687895723569

Epoch: 6| Step: 3
Training loss: 2.558694839477539
Validation loss: 1.93355974330697

Epoch: 6| Step: 4
Training loss: 1.5720654726028442
Validation loss: 1.9387329611726987

Epoch: 6| Step: 5
Training loss: 1.5329493284225464
Validation loss: 1.936226603805378

Epoch: 6| Step: 6
Training loss: 1.554765224456787
Validation loss: 1.956747842091386

Epoch: 6| Step: 7
Training loss: 2.3388373851776123
Validation loss: 1.98095872581646

Epoch: 6| Step: 8
Training loss: 2.1325385570526123
Validation loss: 2.020816306914053

Epoch: 6| Step: 9
Training loss: 1.8908683061599731
Validation loss: 2.010966052291214

Epoch: 6| Step: 10
Training loss: 2.521185874938965
Validation loss: 2.0104079105520762

Epoch: 6| Step: 11
Training loss: 2.1878771781921387
Validation loss: 1.9663226296824794

Epoch: 6| Step: 12
Training loss: 1.8635119199752808
Validation loss: 1.9420765728078864

Epoch: 6| Step: 13
Training loss: 2.465853452682495
Validation loss: 1.9441638121040918

Epoch: 132| Step: 0
Training loss: 2.2181410789489746
Validation loss: 1.953946118713707

Epoch: 6| Step: 1
Training loss: 2.4222593307495117
Validation loss: 1.9659851084473312

Epoch: 6| Step: 2
Training loss: 2.572721481323242
Validation loss: 1.9952046717366865

Epoch: 6| Step: 3
Training loss: 2.3378958702087402
Validation loss: 1.9582905923166583

Epoch: 6| Step: 4
Training loss: 2.0541305541992188
Validation loss: 1.9602114910720496

Epoch: 6| Step: 5
Training loss: 2.1778488159179688
Validation loss: 1.961176485143682

Epoch: 6| Step: 6
Training loss: 2.0939369201660156
Validation loss: 1.9697021233138217

Epoch: 6| Step: 7
Training loss: 1.9687451124191284
Validation loss: 1.9768932993694017

Epoch: 6| Step: 8
Training loss: 1.736858606338501
Validation loss: 1.976752399116434

Epoch: 6| Step: 9
Training loss: 1.5325524806976318
Validation loss: 1.9751445234462779

Epoch: 6| Step: 10
Training loss: 1.8788273334503174
Validation loss: 1.975395276982297

Epoch: 6| Step: 11
Training loss: 2.492994546890259
Validation loss: 1.9934866056647351

Epoch: 6| Step: 12
Training loss: 2.249870777130127
Validation loss: 2.00656101652371

Epoch: 6| Step: 13
Training loss: 2.11429762840271
Validation loss: 1.9907988207314604

Epoch: 133| Step: 0
Training loss: 1.5508921146392822
Validation loss: 1.9736431913991128

Epoch: 6| Step: 1
Training loss: 2.069232702255249
Validation loss: 1.9700602510923981

Epoch: 6| Step: 2
Training loss: 2.388336181640625
Validation loss: 1.9706240648864417

Epoch: 6| Step: 3
Training loss: 2.031026601791382
Validation loss: 1.9615758516455208

Epoch: 6| Step: 4
Training loss: 2.5129005908966064
Validation loss: 1.962729202803745

Epoch: 6| Step: 5
Training loss: 2.2163190841674805
Validation loss: 1.949130053161293

Epoch: 6| Step: 6
Training loss: 2.058415412902832
Validation loss: 1.946718720979588

Epoch: 6| Step: 7
Training loss: 2.8374905586242676
Validation loss: 1.9396325900990476

Epoch: 6| Step: 8
Training loss: 2.379413366317749
Validation loss: 1.9441765995435818

Epoch: 6| Step: 9
Training loss: 2.3398170471191406
Validation loss: 1.9579400580416444

Epoch: 6| Step: 10
Training loss: 1.705021619796753
Validation loss: 1.9824919521167714

Epoch: 6| Step: 11
Training loss: 2.0441102981567383
Validation loss: 2.0144554722693657

Epoch: 6| Step: 12
Training loss: 1.5270256996154785
Validation loss: 2.0287549982788744

Epoch: 6| Step: 13
Training loss: 2.0740084648132324
Validation loss: 2.0277320005560435

Epoch: 134| Step: 0
Training loss: 2.009614944458008
Validation loss: 2.0384116941882717

Epoch: 6| Step: 1
Training loss: 1.9967241287231445
Validation loss: 2.0586924245280604

Epoch: 6| Step: 2
Training loss: 2.5882935523986816
Validation loss: 2.0567982478808333

Epoch: 6| Step: 3
Training loss: 1.8843324184417725
Validation loss: 2.0370781742116457

Epoch: 6| Step: 4
Training loss: 2.0161054134368896
Validation loss: 2.0237366153347875

Epoch: 6| Step: 5
Training loss: 1.8627651929855347
Validation loss: 2.0043113436750186

Epoch: 6| Step: 6
Training loss: 2.032792091369629
Validation loss: 1.988720691332253

Epoch: 6| Step: 7
Training loss: 2.8052806854248047
Validation loss: 1.9888396570759435

Epoch: 6| Step: 8
Training loss: 2.002772808074951
Validation loss: 1.9754646311524093

Epoch: 6| Step: 9
Training loss: 2.2018351554870605
Validation loss: 1.9776198043618152

Epoch: 6| Step: 10
Training loss: 1.7557282447814941
Validation loss: 1.9818555821654618

Epoch: 6| Step: 11
Training loss: 1.7700072526931763
Validation loss: 1.9953480920483988

Epoch: 6| Step: 12
Training loss: 2.455730438232422
Validation loss: 1.99545467540782

Epoch: 6| Step: 13
Training loss: 2.8992435932159424
Validation loss: 1.999346415201823

Epoch: 135| Step: 0
Training loss: 2.3722453117370605
Validation loss: 1.9933574584222609

Epoch: 6| Step: 1
Training loss: 2.354034900665283
Validation loss: 2.0364589870616956

Epoch: 6| Step: 2
Training loss: 2.552539348602295
Validation loss: 2.109089959052301

Epoch: 6| Step: 3
Training loss: 2.434123992919922
Validation loss: 2.16818574167067

Epoch: 6| Step: 4
Training loss: 2.2485270500183105
Validation loss: 2.13549655483615

Epoch: 6| Step: 5
Training loss: 2.44431209564209
Validation loss: 2.101009504769438

Epoch: 6| Step: 6
Training loss: 2.844254970550537
Validation loss: 2.0396514887450845

Epoch: 6| Step: 7
Training loss: 1.7026926279067993
Validation loss: 1.9729764717881397

Epoch: 6| Step: 8
Training loss: 1.8539804220199585
Validation loss: 1.9397300392068841

Epoch: 6| Step: 9
Training loss: 1.4119267463684082
Validation loss: 1.934248931946293

Epoch: 6| Step: 10
Training loss: 1.9460010528564453
Validation loss: 1.9399204190059374

Epoch: 6| Step: 11
Training loss: 2.326558828353882
Validation loss: 1.9378139998323174

Epoch: 6| Step: 12
Training loss: 1.7140414714813232
Validation loss: 1.933123396288964

Epoch: 6| Step: 13
Training loss: 2.2786338329315186
Validation loss: 1.9345085236334032

Epoch: 136| Step: 0
Training loss: 1.9941802024841309
Validation loss: 1.9420994635551208

Epoch: 6| Step: 1
Training loss: 2.506437063217163
Validation loss: 1.9555948126700617

Epoch: 6| Step: 2
Training loss: 1.9958497285842896
Validation loss: 1.995168144984912

Epoch: 6| Step: 3
Training loss: 2.145463466644287
Validation loss: 1.9931203626817273

Epoch: 6| Step: 4
Training loss: 2.5691137313842773
Validation loss: 1.9721260019527969

Epoch: 6| Step: 5
Training loss: 2.0974531173706055
Validation loss: 1.9668847514737038

Epoch: 6| Step: 6
Training loss: 2.6335959434509277
Validation loss: 1.9638753757681897

Epoch: 6| Step: 7
Training loss: 1.1540871858596802
Validation loss: 1.9528356982815651

Epoch: 6| Step: 8
Training loss: 1.955161690711975
Validation loss: 1.9552417224453342

Epoch: 6| Step: 9
Training loss: 2.4634037017822266
Validation loss: 1.9445343786670315

Epoch: 6| Step: 10
Training loss: 2.390592098236084
Validation loss: 1.9620932737986247

Epoch: 6| Step: 11
Training loss: 1.920160174369812
Validation loss: 1.9486212781680528

Epoch: 6| Step: 12
Training loss: 1.8759194612503052
Validation loss: 1.9477787043458672

Epoch: 6| Step: 13
Training loss: 2.3167872428894043
Validation loss: 1.9604600693589898

Epoch: 137| Step: 0
Training loss: 1.5674604177474976
Validation loss: 1.958811672784949

Epoch: 6| Step: 1
Training loss: 2.2819623947143555
Validation loss: 1.978938446250013

Epoch: 6| Step: 2
Training loss: 2.5555782318115234
Validation loss: 1.994220890024657

Epoch: 6| Step: 3
Training loss: 2.279324531555176
Validation loss: 2.0049884370578233

Epoch: 6| Step: 4
Training loss: 1.6946020126342773
Validation loss: 1.997756483734295

Epoch: 6| Step: 5
Training loss: 2.3151473999023438
Validation loss: 2.0005086545021302

Epoch: 6| Step: 6
Training loss: 2.1193971633911133
Validation loss: 1.9644552302616898

Epoch: 6| Step: 7
Training loss: 1.9601818323135376
Validation loss: 1.9692498048146565

Epoch: 6| Step: 8
Training loss: 2.4808506965637207
Validation loss: 1.9656844357008576

Epoch: 6| Step: 9
Training loss: 2.5284481048583984
Validation loss: 1.9726994857993176

Epoch: 6| Step: 10
Training loss: 2.2695584297180176
Validation loss: 1.9584972089336765

Epoch: 6| Step: 11
Training loss: 1.9703558683395386
Validation loss: 1.9660179743202784

Epoch: 6| Step: 12
Training loss: 1.4171044826507568
Validation loss: 1.9640867838295557

Epoch: 6| Step: 13
Training loss: 1.9727126359939575
Validation loss: 1.9650368908400178

Epoch: 138| Step: 0
Training loss: 1.4401652812957764
Validation loss: 1.9592407172726047

Epoch: 6| Step: 1
Training loss: 2.4492156505584717
Validation loss: 1.9691489691375403

Epoch: 6| Step: 2
Training loss: 2.2665648460388184
Validation loss: 1.9653657943971696

Epoch: 6| Step: 3
Training loss: 1.6869107484817505
Validation loss: 1.9731647993928643

Epoch: 6| Step: 4
Training loss: 2.987395763397217
Validation loss: 1.9638656954611502

Epoch: 6| Step: 5
Training loss: 1.6994712352752686
Validation loss: 1.9793258328591623

Epoch: 6| Step: 6
Training loss: 2.2897214889526367
Validation loss: 1.9789756216028684

Epoch: 6| Step: 7
Training loss: 2.2865653038024902
Validation loss: 1.9561497921584754

Epoch: 6| Step: 8
Training loss: 2.180258274078369
Validation loss: 1.9786343292523456

Epoch: 6| Step: 9
Training loss: 1.6123751401901245
Validation loss: 2.014105555831745

Epoch: 6| Step: 10
Training loss: 1.824489712715149
Validation loss: 2.035780709276917

Epoch: 6| Step: 11
Training loss: 2.9801197052001953
Validation loss: 2.040896386228582

Epoch: 6| Step: 12
Training loss: 2.065370559692383
Validation loss: 2.062950914905917

Epoch: 6| Step: 13
Training loss: 1.221157431602478
Validation loss: 1.991701897754464

Epoch: 139| Step: 0
Training loss: 1.392216682434082
Validation loss: 1.9611817585524691

Epoch: 6| Step: 1
Training loss: 2.3444504737854004
Validation loss: 1.9658887335049209

Epoch: 6| Step: 2
Training loss: 2.031169891357422
Validation loss: 1.9744055245512275

Epoch: 6| Step: 3
Training loss: 1.9170575141906738
Validation loss: 1.9677892038899083

Epoch: 6| Step: 4
Training loss: 2.2354140281677246
Validation loss: 1.9806046767901349

Epoch: 6| Step: 5
Training loss: 2.4797000885009766
Validation loss: 1.9694782098134358

Epoch: 6| Step: 6
Training loss: 2.3879611492156982
Validation loss: 2.0004582071817048

Epoch: 6| Step: 7
Training loss: 2.3413636684417725
Validation loss: 1.9991332613011843

Epoch: 6| Step: 8
Training loss: 2.5328681468963623
Validation loss: 1.9928309173994168

Epoch: 6| Step: 9
Training loss: 2.322260856628418
Validation loss: 1.9942857270599694

Epoch: 6| Step: 10
Training loss: 2.3693385124206543
Validation loss: 1.9922430464016494

Epoch: 6| Step: 11
Training loss: 1.4229599237442017
Validation loss: 1.9856684759098997

Epoch: 6| Step: 12
Training loss: 2.0590760707855225
Validation loss: 1.980494540224793

Epoch: 6| Step: 13
Training loss: 2.340165138244629
Validation loss: 1.9915538449441232

Epoch: 140| Step: 0
Training loss: 1.818678379058838
Validation loss: 2.0216694031992266

Epoch: 6| Step: 1
Training loss: 1.591947078704834
Validation loss: 2.042087362658593

Epoch: 6| Step: 2
Training loss: 1.8657710552215576
Validation loss: 2.0462228123859694

Epoch: 6| Step: 3
Training loss: 2.5608978271484375
Validation loss: 2.021945099676809

Epoch: 6| Step: 4
Training loss: 1.8519432544708252
Validation loss: 1.9930981897538709

Epoch: 6| Step: 5
Training loss: 2.3883280754089355
Validation loss: 1.9743668187049128

Epoch: 6| Step: 6
Training loss: 2.1050846576690674
Validation loss: 1.963984925259826

Epoch: 6| Step: 7
Training loss: 1.6908204555511475
Validation loss: 1.9710836025976366

Epoch: 6| Step: 8
Training loss: 2.3271219730377197
Validation loss: 1.959163922135548

Epoch: 6| Step: 9
Training loss: 2.404170513153076
Validation loss: 1.9668379163229337

Epoch: 6| Step: 10
Training loss: 2.138456344604492
Validation loss: 1.982396193729934

Epoch: 6| Step: 11
Training loss: 2.6297760009765625
Validation loss: 1.9993911635491155

Epoch: 6| Step: 12
Training loss: 2.5119075775146484
Validation loss: 2.012268720134612

Epoch: 6| Step: 13
Training loss: 1.238890528678894
Validation loss: 2.008873471649744

Epoch: 141| Step: 0
Training loss: 2.163465738296509
Validation loss: 1.992081029440767

Epoch: 6| Step: 1
Training loss: 2.4849987030029297
Validation loss: 1.9836673339207966

Epoch: 6| Step: 2
Training loss: 2.7998125553131104
Validation loss: 1.9648793640957083

Epoch: 6| Step: 3
Training loss: 1.9575122594833374
Validation loss: 1.9681424607512772

Epoch: 6| Step: 4
Training loss: 1.9868087768554688
Validation loss: 1.9624389294655091

Epoch: 6| Step: 5
Training loss: 1.8565622568130493
Validation loss: 1.9635426882774598

Epoch: 6| Step: 6
Training loss: 1.6752588748931885
Validation loss: 1.9749420368543236

Epoch: 6| Step: 7
Training loss: 1.3393769264221191
Validation loss: 1.990479015534924

Epoch: 6| Step: 8
Training loss: 1.8044754266738892
Validation loss: 1.9826487712962653

Epoch: 6| Step: 9
Training loss: 2.432450771331787
Validation loss: 1.9835547990696405

Epoch: 6| Step: 10
Training loss: 2.1373825073242188
Validation loss: 1.9746642651096467

Epoch: 6| Step: 11
Training loss: 2.398077964782715
Validation loss: 1.9594430615825038

Epoch: 6| Step: 12
Training loss: 2.3672235012054443
Validation loss: 1.9679239616599133

Epoch: 6| Step: 13
Training loss: 1.2934305667877197
Validation loss: 1.9932519748646726

Epoch: 142| Step: 0
Training loss: 2.1684513092041016
Validation loss: 1.977141526437575

Epoch: 6| Step: 1
Training loss: 2.5073299407958984
Validation loss: 1.9788808643176992

Epoch: 6| Step: 2
Training loss: 2.6517858505249023
Validation loss: 1.980035674187445

Epoch: 6| Step: 3
Training loss: 2.2786378860473633
Validation loss: 1.9912863008437618

Epoch: 6| Step: 4
Training loss: 2.3431363105773926
Validation loss: 1.9940832302134524

Epoch: 6| Step: 5
Training loss: 1.9312362670898438
Validation loss: 2.008323016987052

Epoch: 6| Step: 6
Training loss: 1.8263615369796753
Validation loss: 2.0210073263414445

Epoch: 6| Step: 7
Training loss: 1.7583751678466797
Validation loss: 2.051252849640385

Epoch: 6| Step: 8
Training loss: 1.9598281383514404
Validation loss: 2.0761848624034593

Epoch: 6| Step: 9
Training loss: 1.4634833335876465
Validation loss: 2.0518944519822315

Epoch: 6| Step: 10
Training loss: 1.2800519466400146
Validation loss: 2.0094935432557137

Epoch: 6| Step: 11
Training loss: 2.6405105590820312
Validation loss: 1.9881157029059626

Epoch: 6| Step: 12
Training loss: 1.9017932415008545
Validation loss: 1.978302712081581

Epoch: 6| Step: 13
Training loss: 2.5067529678344727
Validation loss: 1.9759982811507357

Epoch: 143| Step: 0
Training loss: 2.38828182220459
Validation loss: 1.9624353711323073

Epoch: 6| Step: 1
Training loss: 1.8724040985107422
Validation loss: 1.9665311946663806

Epoch: 6| Step: 2
Training loss: 2.0319714546203613
Validation loss: 1.9528543487671883

Epoch: 6| Step: 3
Training loss: 1.9790687561035156
Validation loss: 1.9634682311806628

Epoch: 6| Step: 4
Training loss: 1.5601840019226074
Validation loss: 1.9678289890289307

Epoch: 6| Step: 5
Training loss: 1.7637255191802979
Validation loss: 1.955985851185296

Epoch: 6| Step: 6
Training loss: 2.005002498626709
Validation loss: 1.975559942183956

Epoch: 6| Step: 7
Training loss: 2.635580062866211
Validation loss: 2.0132423754661315

Epoch: 6| Step: 8
Training loss: 2.049138069152832
Validation loss: 2.0369480297129643

Epoch: 6| Step: 9
Training loss: 1.976836085319519
Validation loss: 2.0320188973539617

Epoch: 6| Step: 10
Training loss: 2.5530765056610107
Validation loss: 1.997736955201754

Epoch: 6| Step: 11
Training loss: 2.2665960788726807
Validation loss: 1.9614315109868203

Epoch: 6| Step: 12
Training loss: 2.105679988861084
Validation loss: 1.9583109783869919

Epoch: 6| Step: 13
Training loss: 2.0828404426574707
Validation loss: 1.9739781451481644

Epoch: 144| Step: 0
Training loss: 1.6181795597076416
Validation loss: 1.9509921971187796

Epoch: 6| Step: 1
Training loss: 1.9239656925201416
Validation loss: 1.967353913091844

Epoch: 6| Step: 2
Training loss: 2.0312654972076416
Validation loss: 1.965466424983035

Epoch: 6| Step: 3
Training loss: 2.6183252334594727
Validation loss: 1.9544299879381735

Epoch: 6| Step: 4
Training loss: 2.202587604522705
Validation loss: 1.9678290608108684

Epoch: 6| Step: 5
Training loss: 1.3712133169174194
Validation loss: 1.961988373469281

Epoch: 6| Step: 6
Training loss: 1.9934730529785156
Validation loss: 1.9770527475623674

Epoch: 6| Step: 7
Training loss: 1.6950256824493408
Validation loss: 1.988279358033211

Epoch: 6| Step: 8
Training loss: 2.518749713897705
Validation loss: 1.9764693885721185

Epoch: 6| Step: 9
Training loss: 2.2356488704681396
Validation loss: 1.9821991279561033

Epoch: 6| Step: 10
Training loss: 2.5668764114379883
Validation loss: 2.003388862456045

Epoch: 6| Step: 11
Training loss: 2.3415541648864746
Validation loss: 1.9991323922270088

Epoch: 6| Step: 12
Training loss: 1.9673759937286377
Validation loss: 1.9799441265803512

Epoch: 6| Step: 13
Training loss: 1.4518811702728271
Validation loss: 1.9715795017057849

Epoch: 145| Step: 0
Training loss: 2.194612503051758
Validation loss: 1.9561154816740303

Epoch: 6| Step: 1
Training loss: 1.595218539237976
Validation loss: 1.9563741094322615

Epoch: 6| Step: 2
Training loss: 2.0601024627685547
Validation loss: 1.9506423742540422

Epoch: 6| Step: 3
Training loss: 2.7544684410095215
Validation loss: 1.9660490225720149

Epoch: 6| Step: 4
Training loss: 1.9074009656906128
Validation loss: 1.9578747518600956

Epoch: 6| Step: 5
Training loss: 3.0904974937438965
Validation loss: 1.9750080377824846

Epoch: 6| Step: 6
Training loss: 1.9106193780899048
Validation loss: 1.9757835993202784

Epoch: 6| Step: 7
Training loss: 1.7434707880020142
Validation loss: 1.9666634759595316

Epoch: 6| Step: 8
Training loss: 2.06325101852417
Validation loss: 1.9730051204722414

Epoch: 6| Step: 9
Training loss: 1.4021944999694824
Validation loss: 1.9610125787796513

Epoch: 6| Step: 10
Training loss: 2.2234277725219727
Validation loss: 1.9800400413492674

Epoch: 6| Step: 11
Training loss: 2.15069580078125
Validation loss: 1.9789694586107809

Epoch: 6| Step: 12
Training loss: 1.863877773284912
Validation loss: 1.9705997756732407

Epoch: 6| Step: 13
Training loss: 1.798779845237732
Validation loss: 1.9702948742015387

Epoch: 146| Step: 0
Training loss: 1.332032561302185
Validation loss: 1.9688490526650542

Epoch: 6| Step: 1
Training loss: 1.7764558792114258
Validation loss: 1.9804432110119892

Epoch: 6| Step: 2
Training loss: 2.267946243286133
Validation loss: 1.9982913335164387

Epoch: 6| Step: 3
Training loss: 2.1577260494232178
Validation loss: 2.0401581666802846

Epoch: 6| Step: 4
Training loss: 2.3575563430786133
Validation loss: 2.036112170065603

Epoch: 6| Step: 5
Training loss: 2.428295612335205
Validation loss: 2.016295704790341

Epoch: 6| Step: 6
Training loss: 1.9291300773620605
Validation loss: 2.0044262524574035

Epoch: 6| Step: 7
Training loss: 2.2932422161102295
Validation loss: 1.9943835286683933

Epoch: 6| Step: 8
Training loss: 2.291808605194092
Validation loss: 1.9735705621780888

Epoch: 6| Step: 9
Training loss: 2.573556661605835
Validation loss: 1.9561806417280627

Epoch: 6| Step: 10
Training loss: 1.579787254333496
Validation loss: 1.9358010061325566

Epoch: 6| Step: 11
Training loss: 1.5905745029449463
Validation loss: 1.9440982777585265

Epoch: 6| Step: 12
Training loss: 2.146846294403076
Validation loss: 1.93673191788376

Epoch: 6| Step: 13
Training loss: 2.0795297622680664
Validation loss: 1.928358224130446

Epoch: 147| Step: 0
Training loss: 2.521092414855957
Validation loss: 1.958702387348298

Epoch: 6| Step: 1
Training loss: 2.4671592712402344
Validation loss: 1.998402241737612

Epoch: 6| Step: 2
Training loss: 1.1669251918792725
Validation loss: 2.020003529005153

Epoch: 6| Step: 3
Training loss: 2.1438732147216797
Validation loss: 2.0584785656262468

Epoch: 6| Step: 4
Training loss: 1.9798468351364136
Validation loss: 2.055190970820765

Epoch: 6| Step: 5
Training loss: 2.1565117835998535
Validation loss: 2.0482497817726544

Epoch: 6| Step: 6
Training loss: 1.8335015773773193
Validation loss: 2.0076992383567234

Epoch: 6| Step: 7
Training loss: 2.3599014282226562
Validation loss: 1.9803138727782874

Epoch: 6| Step: 8
Training loss: 2.945305824279785
Validation loss: 1.9875096710779334

Epoch: 6| Step: 9
Training loss: 1.6129838228225708
Validation loss: 1.971821213281283

Epoch: 6| Step: 10
Training loss: 1.4716376066207886
Validation loss: 1.9752165220117057

Epoch: 6| Step: 11
Training loss: 1.995020866394043
Validation loss: 1.976807478935488

Epoch: 6| Step: 12
Training loss: 2.28887939453125
Validation loss: 1.9923489324508175

Epoch: 6| Step: 13
Training loss: 1.7160173654556274
Validation loss: 1.9942159011799803

Epoch: 148| Step: 0
Training loss: 2.151310443878174
Validation loss: 2.005897601445516

Epoch: 6| Step: 1
Training loss: 1.7512847185134888
Validation loss: 2.0002262002678326

Epoch: 6| Step: 2
Training loss: 2.1483547687530518
Validation loss: 1.981046861217868

Epoch: 6| Step: 3
Training loss: 2.0177841186523438
Validation loss: 1.9772826215272308

Epoch: 6| Step: 4
Training loss: 2.8382911682128906
Validation loss: 1.9830578450233705

Epoch: 6| Step: 5
Training loss: 2.636277437210083
Validation loss: 1.9870892019682034

Epoch: 6| Step: 6
Training loss: 2.1679463386535645
Validation loss: 1.9784131921747679

Epoch: 6| Step: 7
Training loss: 2.127897024154663
Validation loss: 1.9806683294234737

Epoch: 6| Step: 8
Training loss: 1.9900522232055664
Validation loss: 1.9872219113893406

Epoch: 6| Step: 9
Training loss: 1.1558380126953125
Validation loss: 1.9805251398394186

Epoch: 6| Step: 10
Training loss: 1.6287376880645752
Validation loss: 1.964027254812179

Epoch: 6| Step: 11
Training loss: 1.6266629695892334
Validation loss: 1.9624184177767845

Epoch: 6| Step: 12
Training loss: 1.9288848638534546
Validation loss: 1.9609097062900502

Epoch: 6| Step: 13
Training loss: 2.3997089862823486
Validation loss: 1.9593390136636712

Epoch: 149| Step: 0
Training loss: 2.1952781677246094
Validation loss: 1.9490474526600172

Epoch: 6| Step: 1
Training loss: 2.0030879974365234
Validation loss: 1.9533827330476494

Epoch: 6| Step: 2
Training loss: 1.7222858667373657
Validation loss: 1.9899341675543016

Epoch: 6| Step: 3
Training loss: 3.0602571964263916
Validation loss: 2.0022864239190215

Epoch: 6| Step: 4
Training loss: 1.8188488483428955
Validation loss: 2.0257468608117875

Epoch: 6| Step: 5
Training loss: 1.9724419116973877
Validation loss: 2.0168143933819187

Epoch: 6| Step: 6
Training loss: 2.2563674449920654
Validation loss: 2.01122203693595

Epoch: 6| Step: 7
Training loss: 2.1378114223480225
Validation loss: 1.9892737660356747

Epoch: 6| Step: 8
Training loss: 1.8006658554077148
Validation loss: 1.9869365743411485

Epoch: 6| Step: 9
Training loss: 2.0699658393859863
Validation loss: 1.9800538709086757

Epoch: 6| Step: 10
Training loss: 2.1180922985076904
Validation loss: 1.9876287855127805

Epoch: 6| Step: 11
Training loss: 1.367410659790039
Validation loss: 1.9886961649822932

Epoch: 6| Step: 12
Training loss: 1.8056612014770508
Validation loss: 2.0026524938562864

Epoch: 6| Step: 13
Training loss: 1.7680708169937134
Validation loss: 2.0262068599782963

Epoch: 150| Step: 0
Training loss: 1.4708709716796875
Validation loss: 2.029775381088257

Epoch: 6| Step: 1
Training loss: 1.6484861373901367
Validation loss: 2.0486822794842463

Epoch: 6| Step: 2
Training loss: 2.173001766204834
Validation loss: 2.068883301109396

Epoch: 6| Step: 3
Training loss: 2.5147862434387207
Validation loss: 2.0594229185453026

Epoch: 6| Step: 4
Training loss: 1.5894804000854492
Validation loss: 2.0477194504071305

Epoch: 6| Step: 5
Training loss: 2.9447731971740723
Validation loss: 2.021272813120196

Epoch: 6| Step: 6
Training loss: 2.1018922328948975
Validation loss: 2.0049239384230746

Epoch: 6| Step: 7
Training loss: 2.660468339920044
Validation loss: 2.0146325531826226

Epoch: 6| Step: 8
Training loss: 1.6617152690887451
Validation loss: 1.9898512183978994

Epoch: 6| Step: 9
Training loss: 2.4305803775787354
Validation loss: 2.009794713348471

Epoch: 6| Step: 10
Training loss: 1.632720708847046
Validation loss: 2.013637755506782

Epoch: 6| Step: 11
Training loss: 1.6955254077911377
Validation loss: 2.0014024011550413

Epoch: 6| Step: 12
Training loss: 1.9664342403411865
Validation loss: 1.9978105714244228

Epoch: 6| Step: 13
Training loss: 2.020493507385254
Validation loss: 1.997184027907669

Epoch: 151| Step: 0
Training loss: 1.9847121238708496
Validation loss: 2.0075191169656734

Epoch: 6| Step: 1
Training loss: 1.9346339702606201
Validation loss: 2.002568714080318

Epoch: 6| Step: 2
Training loss: 2.1096608638763428
Validation loss: 2.012551999861194

Epoch: 6| Step: 3
Training loss: 1.6541582345962524
Validation loss: 2.000371097236551

Epoch: 6| Step: 4
Training loss: 1.9275572299957275
Validation loss: 2.007397319680901

Epoch: 6| Step: 5
Training loss: 3.0387048721313477
Validation loss: 2.005614798556092

Epoch: 6| Step: 6
Training loss: 2.244875907897949
Validation loss: 1.9817518982835995

Epoch: 6| Step: 7
Training loss: 1.7164361476898193
Validation loss: 1.9812499220653246

Epoch: 6| Step: 8
Training loss: 1.8716435432434082
Validation loss: 1.9710357266087686

Epoch: 6| Step: 9
Training loss: 2.3061676025390625
Validation loss: 1.9666540738075011

Epoch: 6| Step: 10
Training loss: 1.576215147972107
Validation loss: 1.958930787219796

Epoch: 6| Step: 11
Training loss: 2.462858200073242
Validation loss: 1.9620312618952926

Epoch: 6| Step: 12
Training loss: 1.7330631017684937
Validation loss: 1.9596757940066758

Epoch: 6| Step: 13
Training loss: 1.4348890781402588
Validation loss: 1.9709603940286944

Epoch: 152| Step: 0
Training loss: 1.8547066450119019
Validation loss: 1.962630694912326

Epoch: 6| Step: 1
Training loss: 2.1539039611816406
Validation loss: 1.9756485736498268

Epoch: 6| Step: 2
Training loss: 1.8996036052703857
Validation loss: 1.9668063553430701

Epoch: 6| Step: 3
Training loss: 1.8632440567016602
Validation loss: 1.96812649696104

Epoch: 6| Step: 4
Training loss: 1.6470754146575928
Validation loss: 1.969102330105279

Epoch: 6| Step: 5
Training loss: 2.14970326423645
Validation loss: 1.9875187284202986

Epoch: 6| Step: 6
Training loss: 1.6045737266540527
Validation loss: 1.9831105791112429

Epoch: 6| Step: 7
Training loss: 2.7533011436462402
Validation loss: 1.9881474587225145

Epoch: 6| Step: 8
Training loss: 2.483391284942627
Validation loss: 2.0131456518685944

Epoch: 6| Step: 9
Training loss: 1.6810688972473145
Validation loss: 1.9936227772825508

Epoch: 6| Step: 10
Training loss: 1.5457077026367188
Validation loss: 1.9870614441492225

Epoch: 6| Step: 11
Training loss: 1.763924241065979
Validation loss: 1.9886964405736616

Epoch: 6| Step: 12
Training loss: 2.5508360862731934
Validation loss: 1.9892133384622552

Epoch: 6| Step: 13
Training loss: 1.795371174812317
Validation loss: 1.9850071168714953

Epoch: 153| Step: 0
Training loss: 1.9698033332824707
Validation loss: 1.986700032346992

Epoch: 6| Step: 1
Training loss: 2.0471930503845215
Validation loss: 1.9914772023436844

Epoch: 6| Step: 2
Training loss: 2.1806774139404297
Validation loss: 2.0017989502158215

Epoch: 6| Step: 3
Training loss: 2.3867578506469727
Validation loss: 2.0055767989927724

Epoch: 6| Step: 4
Training loss: 2.1641201972961426
Validation loss: 2.0013843377431235

Epoch: 6| Step: 5
Training loss: 1.2769219875335693
Validation loss: 2.005301962616623

Epoch: 6| Step: 6
Training loss: 2.0075159072875977
Validation loss: 2.002713244448426

Epoch: 6| Step: 7
Training loss: 1.7379803657531738
Validation loss: 1.9904184520885508

Epoch: 6| Step: 8
Training loss: 1.7431663274765015
Validation loss: 1.9886821598135016

Epoch: 6| Step: 9
Training loss: 1.671724557876587
Validation loss: 1.9988068880573395

Epoch: 6| Step: 10
Training loss: 2.3500332832336426
Validation loss: 1.995054025803843

Epoch: 6| Step: 11
Training loss: 1.6210427284240723
Validation loss: 2.0042052909892094

Epoch: 6| Step: 12
Training loss: 1.7950589656829834
Validation loss: 2.004883421364651

Epoch: 6| Step: 13
Training loss: 3.3157358169555664
Validation loss: 2.021726058375451

Epoch: 154| Step: 0
Training loss: 1.8951160907745361
Validation loss: 2.0235106752764795

Epoch: 6| Step: 1
Training loss: 1.6665266752243042
Validation loss: 2.0258957186052875

Epoch: 6| Step: 2
Training loss: 2.543684482574463
Validation loss: 2.0289092961178032

Epoch: 6| Step: 3
Training loss: 2.2590866088867188
Validation loss: 1.996130475433924

Epoch: 6| Step: 4
Training loss: 2.1320302486419678
Validation loss: 1.9772527858775149

Epoch: 6| Step: 5
Training loss: 2.3285741806030273
Validation loss: 1.9833954059949486

Epoch: 6| Step: 6
Training loss: 2.001574993133545
Validation loss: 1.9729475218762633

Epoch: 6| Step: 7
Training loss: 1.7333738803863525
Validation loss: 1.9748557126650246

Epoch: 6| Step: 8
Training loss: 1.4515682458877563
Validation loss: 1.9555419311728528

Epoch: 6| Step: 9
Training loss: 1.5504354238510132
Validation loss: 1.9803479768896615

Epoch: 6| Step: 10
Training loss: 2.7798895835876465
Validation loss: 1.999194473348638

Epoch: 6| Step: 11
Training loss: 1.6572341918945312
Validation loss: 2.016558675355809

Epoch: 6| Step: 12
Training loss: 2.38057541847229
Validation loss: 2.0350037223549298

Epoch: 6| Step: 13
Training loss: 1.4268068075180054
Validation loss: 2.0397650567434167

Epoch: 155| Step: 0
Training loss: 2.236687183380127
Validation loss: 2.0453260483280307

Epoch: 6| Step: 1
Training loss: 2.36267352104187
Validation loss: 2.0441791754896923

Epoch: 6| Step: 2
Training loss: 1.898771047592163
Validation loss: 2.036411012372663

Epoch: 6| Step: 3
Training loss: 1.795539379119873
Validation loss: 2.0202774270888297

Epoch: 6| Step: 4
Training loss: 1.7841213941574097
Validation loss: 2.0078241761012743

Epoch: 6| Step: 5
Training loss: 2.2584457397460938
Validation loss: 1.9922505937596804

Epoch: 6| Step: 6
Training loss: 2.554307460784912
Validation loss: 1.9875921395517164

Epoch: 6| Step: 7
Training loss: 1.6069176197052002
Validation loss: 1.9730302697868758

Epoch: 6| Step: 8
Training loss: 1.8813648223876953
Validation loss: 1.9758260788456086

Epoch: 6| Step: 9
Training loss: 1.263254165649414
Validation loss: 1.9774212452673143

Epoch: 6| Step: 10
Training loss: 2.3283190727233887
Validation loss: 1.972425809470556

Epoch: 6| Step: 11
Training loss: 1.953193187713623
Validation loss: 1.9815880419105611

Epoch: 6| Step: 12
Training loss: 2.0095646381378174
Validation loss: 1.9807248987177366

Epoch: 6| Step: 13
Training loss: 1.944983959197998
Validation loss: 1.988932216039268

Epoch: 156| Step: 0
Training loss: 1.779188871383667
Validation loss: 1.9960530291321457

Epoch: 6| Step: 1
Training loss: 2.3860397338867188
Validation loss: 2.016839543978373

Epoch: 6| Step: 2
Training loss: 1.849259853363037
Validation loss: 2.0556938686678485

Epoch: 6| Step: 3
Training loss: 2.6565775871276855
Validation loss: 2.0675998464707406

Epoch: 6| Step: 4
Training loss: 2.8122191429138184
Validation loss: 2.066596878472195

Epoch: 6| Step: 5
Training loss: 1.568265438079834
Validation loss: 2.0781518156810472

Epoch: 6| Step: 6
Training loss: 1.3029032945632935
Validation loss: 2.041024946397351

Epoch: 6| Step: 7
Training loss: 2.377403736114502
Validation loss: 2.007895190228698

Epoch: 6| Step: 8
Training loss: 1.6284892559051514
Validation loss: 2.0066394575180544

Epoch: 6| Step: 9
Training loss: 1.7100424766540527
Validation loss: 1.9980317854112195

Epoch: 6| Step: 10
Training loss: 2.078129768371582
Validation loss: 1.999060179597588

Epoch: 6| Step: 11
Training loss: 2.21525239944458
Validation loss: 1.9921918684436428

Epoch: 6| Step: 12
Training loss: 2.4045238494873047
Validation loss: 1.9978549647074875

Epoch: 6| Step: 13
Training loss: 1.1175258159637451
Validation loss: 2.033360165934409

Epoch: 157| Step: 0
Training loss: 2.054109573364258
Validation loss: 2.0521409332111316

Epoch: 6| Step: 1
Training loss: 1.8261663913726807
Validation loss: 2.0485429827884962

Epoch: 6| Step: 2
Training loss: 2.036823272705078
Validation loss: 2.030023136446553

Epoch: 6| Step: 3
Training loss: 1.14371657371521
Validation loss: 1.993241540847286

Epoch: 6| Step: 4
Training loss: 1.8985521793365479
Validation loss: 1.968661521070747

Epoch: 6| Step: 5
Training loss: 2.258298397064209
Validation loss: 1.9435712419530398

Epoch: 6| Step: 6
Training loss: 2.061796188354492
Validation loss: 1.953845275345669

Epoch: 6| Step: 7
Training loss: 2.5313048362731934
Validation loss: 1.9539110135006648

Epoch: 6| Step: 8
Training loss: 1.4852359294891357
Validation loss: 1.9511452515920003

Epoch: 6| Step: 9
Training loss: 2.006329298019409
Validation loss: 1.9461070004329886

Epoch: 6| Step: 10
Training loss: 2.2501940727233887
Validation loss: 1.9794199671796573

Epoch: 6| Step: 11
Training loss: 2.2836952209472656
Validation loss: 2.044292301260015

Epoch: 6| Step: 12
Training loss: 2.684969902038574
Validation loss: 2.0647539746376777

Epoch: 6| Step: 13
Training loss: 1.5677268505096436
Validation loss: 2.0527493876795613

Epoch: 158| Step: 0
Training loss: 2.4712181091308594
Validation loss: 2.073740215711696

Epoch: 6| Step: 1
Training loss: 1.4536892175674438
Validation loss: 2.0746787337846655

Epoch: 6| Step: 2
Training loss: 1.9067308902740479
Validation loss: 2.047385113213652

Epoch: 6| Step: 3
Training loss: 1.3622007369995117
Validation loss: 2.0051882395180325

Epoch: 6| Step: 4
Training loss: 1.4257268905639648
Validation loss: 1.9902379564059678

Epoch: 6| Step: 5
Training loss: 1.7549545764923096
Validation loss: 1.9685332493115497

Epoch: 6| Step: 6
Training loss: 2.259927749633789
Validation loss: 1.962112711321923

Epoch: 6| Step: 7
Training loss: 2.3843400478363037
Validation loss: 1.971918982844199

Epoch: 6| Step: 8
Training loss: 1.894892692565918
Validation loss: 1.9867105176371913

Epoch: 6| Step: 9
Training loss: 2.1364097595214844
Validation loss: 1.9931623781881025

Epoch: 6| Step: 10
Training loss: 2.1927096843719482
Validation loss: 2.0030368938240954

Epoch: 6| Step: 11
Training loss: 2.207139730453491
Validation loss: 2.0229580351101455

Epoch: 6| Step: 12
Training loss: 2.442664384841919
Validation loss: 2.0298456209962086

Epoch: 6| Step: 13
Training loss: 1.9728611707687378
Validation loss: 2.0485805490965485

Epoch: 159| Step: 0
Training loss: 1.7421414852142334
Validation loss: 2.07996303291731

Epoch: 6| Step: 1
Training loss: 1.7990202903747559
Validation loss: 2.086032106030372

Epoch: 6| Step: 2
Training loss: 1.9848105907440186
Validation loss: 2.0642609468070408

Epoch: 6| Step: 3
Training loss: 2.230454921722412
Validation loss: 2.048450714798384

Epoch: 6| Step: 4
Training loss: 1.89992356300354
Validation loss: 2.023364395223638

Epoch: 6| Step: 5
Training loss: 1.6815649271011353
Validation loss: 2.027808718783881

Epoch: 6| Step: 6
Training loss: 2.076785087585449
Validation loss: 2.0195960537079842

Epoch: 6| Step: 7
Training loss: 2.0902299880981445
Validation loss: 2.035369460300733

Epoch: 6| Step: 8
Training loss: 1.5087354183197021
Validation loss: 2.0233331521352134

Epoch: 6| Step: 9
Training loss: 2.4286468029022217
Validation loss: 2.0147453174796155

Epoch: 6| Step: 10
Training loss: 1.998852252960205
Validation loss: 2.0277816608387935

Epoch: 6| Step: 11
Training loss: 2.4801578521728516
Validation loss: 2.014733801605881

Epoch: 6| Step: 12
Training loss: 2.0354137420654297
Validation loss: 2.0181884227260465

Epoch: 6| Step: 13
Training loss: 2.0743424892425537
Validation loss: 2.0327077937382523

Epoch: 160| Step: 0
Training loss: 1.5652258396148682
Validation loss: 2.0512391803085164

Epoch: 6| Step: 1
Training loss: 2.005016803741455
Validation loss: 2.0511416953097106

Epoch: 6| Step: 2
Training loss: 1.8939361572265625
Validation loss: 2.054485051862655

Epoch: 6| Step: 3
Training loss: 2.382585287094116
Validation loss: 2.041898701780586

Epoch: 6| Step: 4
Training loss: 2.383098602294922
Validation loss: 1.9877040386199951

Epoch: 6| Step: 5
Training loss: 1.7978342771530151
Validation loss: 1.9662361529565626

Epoch: 6| Step: 6
Training loss: 2.181558847427368
Validation loss: 1.9606365003893453

Epoch: 6| Step: 7
Training loss: 1.441178321838379
Validation loss: 1.942569399392733

Epoch: 6| Step: 8
Training loss: 1.2323271036148071
Validation loss: 1.9375551439100696

Epoch: 6| Step: 9
Training loss: 1.9503575563430786
Validation loss: 1.9434982897132955

Epoch: 6| Step: 10
Training loss: 2.412851572036743
Validation loss: 1.9365985547342608

Epoch: 6| Step: 11
Training loss: 2.186408042907715
Validation loss: 1.93150528271993

Epoch: 6| Step: 12
Training loss: 1.837343454360962
Validation loss: 1.9370749624826575

Epoch: 6| Step: 13
Training loss: 2.5150864124298096
Validation loss: 1.9510446581789243

Epoch: 161| Step: 0
Training loss: 2.346708297729492
Validation loss: 1.963703368299751

Epoch: 6| Step: 1
Training loss: 1.1402039527893066
Validation loss: 1.9834241277428084

Epoch: 6| Step: 2
Training loss: 1.2569867372512817
Validation loss: 1.9836154727525608

Epoch: 6| Step: 3
Training loss: 1.676445722579956
Validation loss: 1.984337083755001

Epoch: 6| Step: 4
Training loss: 2.7641468048095703
Validation loss: 1.9898836074336883

Epoch: 6| Step: 5
Training loss: 1.8392828702926636
Validation loss: 1.9922388202400618

Epoch: 6| Step: 6
Training loss: 1.9039239883422852
Validation loss: 2.001458808939944

Epoch: 6| Step: 7
Training loss: 3.213778257369995
Validation loss: 2.0082480792076356

Epoch: 6| Step: 8
Training loss: 1.0939828157424927
Validation loss: 2.001156827454926

Epoch: 6| Step: 9
Training loss: 2.947275400161743
Validation loss: 2.025763342457433

Epoch: 6| Step: 10
Training loss: 1.6385998725891113
Validation loss: 2.0080905601542485

Epoch: 6| Step: 11
Training loss: 1.9845550060272217
Validation loss: 2.006725336915703

Epoch: 6| Step: 12
Training loss: 1.4139834642410278
Validation loss: 1.991467104163221

Epoch: 6| Step: 13
Training loss: 2.0645298957824707
Validation loss: 1.9820155866684452

Epoch: 162| Step: 0
Training loss: 1.8533329963684082
Validation loss: 1.9835385173879645

Epoch: 6| Step: 1
Training loss: 1.8805639743804932
Validation loss: 1.996270679658459

Epoch: 6| Step: 2
Training loss: 2.0387535095214844
Validation loss: 1.9967403693865704

Epoch: 6| Step: 3
Training loss: 1.819034218788147
Validation loss: 1.9907366780824558

Epoch: 6| Step: 4
Training loss: 1.283912181854248
Validation loss: 2.0086446218593146

Epoch: 6| Step: 5
Training loss: 2.3036489486694336
Validation loss: 1.994636724072118

Epoch: 6| Step: 6
Training loss: 1.3905967473983765
Validation loss: 2.005185991205195

Epoch: 6| Step: 7
Training loss: 2.3710107803344727
Validation loss: 1.9978643604504165

Epoch: 6| Step: 8
Training loss: 2.679779291152954
Validation loss: 1.9909845526500414

Epoch: 6| Step: 9
Training loss: 1.4707040786743164
Validation loss: 1.9736351556675409

Epoch: 6| Step: 10
Training loss: 2.715656042098999
Validation loss: 1.9658412561621716

Epoch: 6| Step: 11
Training loss: 1.592897891998291
Validation loss: 1.9739315035522624

Epoch: 6| Step: 12
Training loss: 1.8209553956985474
Validation loss: 1.966574179228916

Epoch: 6| Step: 13
Training loss: 2.081334352493286
Validation loss: 1.9571995401895175

Epoch: 163| Step: 0
Training loss: 2.0775675773620605
Validation loss: 1.9498665037975516

Epoch: 6| Step: 1
Training loss: 1.8026978969573975
Validation loss: 1.9537716475866174

Epoch: 6| Step: 2
Training loss: 2.628910541534424
Validation loss: 1.9612811380817043

Epoch: 6| Step: 3
Training loss: 1.116552710533142
Validation loss: 1.9690228521182973

Epoch: 6| Step: 4
Training loss: 1.2850881814956665
Validation loss: 1.9706219498829176

Epoch: 6| Step: 5
Training loss: 2.4920315742492676
Validation loss: 1.9737917928285496

Epoch: 6| Step: 6
Training loss: 1.4825491905212402
Validation loss: 1.9704894186348043

Epoch: 6| Step: 7
Training loss: 2.1269195079803467
Validation loss: 1.9747753066401328

Epoch: 6| Step: 8
Training loss: 1.2301247119903564
Validation loss: 1.9671505189711047

Epoch: 6| Step: 9
Training loss: 2.9194869995117188
Validation loss: 1.9712449414755708

Epoch: 6| Step: 10
Training loss: 1.8497658967971802
Validation loss: 1.9749487343654837

Epoch: 6| Step: 11
Training loss: 1.6051669120788574
Validation loss: 1.9919676152608727

Epoch: 6| Step: 12
Training loss: 2.7728984355926514
Validation loss: 2.0203448700648483

Epoch: 6| Step: 13
Training loss: 1.4457019567489624
Validation loss: 2.0083394986326977

Epoch: 164| Step: 0
Training loss: 1.8055559396743774
Validation loss: 1.9990442465710383

Epoch: 6| Step: 1
Training loss: 1.2659270763397217
Validation loss: 2.001833697800995

Epoch: 6| Step: 2
Training loss: 2.3941521644592285
Validation loss: 1.9954091912956649

Epoch: 6| Step: 3
Training loss: 1.538254737854004
Validation loss: 1.9800088892700851

Epoch: 6| Step: 4
Training loss: 1.34013032913208
Validation loss: 1.979012381645941

Epoch: 6| Step: 5
Training loss: 1.8962547779083252
Validation loss: 1.9637990190136818

Epoch: 6| Step: 6
Training loss: 1.4290934801101685
Validation loss: 1.964917726414178

Epoch: 6| Step: 7
Training loss: 2.0369205474853516
Validation loss: 1.9571851299655052

Epoch: 6| Step: 8
Training loss: 2.2848634719848633
Validation loss: 1.9610803883562806

Epoch: 6| Step: 9
Training loss: 2.2673377990722656
Validation loss: 1.9618142984246696

Epoch: 6| Step: 10
Training loss: 2.055614471435547
Validation loss: 1.9671298432093796

Epoch: 6| Step: 11
Training loss: 2.1910555362701416
Validation loss: 1.9816780423605314

Epoch: 6| Step: 12
Training loss: 1.9588357210159302
Validation loss: 1.9890133898745301

Epoch: 6| Step: 13
Training loss: 2.524071216583252
Validation loss: 2.008465190087595

Epoch: 165| Step: 0
Training loss: 1.8643872737884521
Validation loss: 2.0311601187593196

Epoch: 6| Step: 1
Training loss: 1.7423927783966064
Validation loss: 2.019790667359547

Epoch: 6| Step: 2
Training loss: 2.5591940879821777
Validation loss: 2.00859337083755

Epoch: 6| Step: 3
Training loss: 1.8366057872772217
Validation loss: 1.9963476580958213

Epoch: 6| Step: 4
Training loss: 1.3852182626724243
Validation loss: 1.9977499823416434

Epoch: 6| Step: 5
Training loss: 2.039881706237793
Validation loss: 2.0006812028987433

Epoch: 6| Step: 6
Training loss: 2.0564661026000977
Validation loss: 1.9993405521556895

Epoch: 6| Step: 7
Training loss: 2.098716974258423
Validation loss: 2.000623808112196

Epoch: 6| Step: 8
Training loss: 2.0668673515319824
Validation loss: 1.9806604718649259

Epoch: 6| Step: 9
Training loss: 2.552135944366455
Validation loss: 2.013521316230938

Epoch: 6| Step: 10
Training loss: 2.0112786293029785
Validation loss: 2.0200491515539025

Epoch: 6| Step: 11
Training loss: 1.3052418231964111
Validation loss: 2.051640274704144

Epoch: 6| Step: 12
Training loss: 1.7950769662857056
Validation loss: 2.079664368783274

Epoch: 6| Step: 13
Training loss: 1.3391351699829102
Validation loss: 2.092656273995676

Epoch: 166| Step: 0
Training loss: 1.9975156784057617
Validation loss: 2.0800550355706164

Epoch: 6| Step: 1
Training loss: 2.396005630493164
Validation loss: 2.0526733500983125

Epoch: 6| Step: 2
Training loss: 1.642595648765564
Validation loss: 2.031384996188584

Epoch: 6| Step: 3
Training loss: 1.4190937280654907
Validation loss: 1.9937576632345877

Epoch: 6| Step: 4
Training loss: 1.1501678228378296
Validation loss: 1.9842686960774083

Epoch: 6| Step: 5
Training loss: 2.548058032989502
Validation loss: 1.996575511911864

Epoch: 6| Step: 6
Training loss: 1.8816862106323242
Validation loss: 1.9905797845573836

Epoch: 6| Step: 7
Training loss: 1.8211530447006226
Validation loss: 1.9761869292105398

Epoch: 6| Step: 8
Training loss: 2.1363577842712402
Validation loss: 1.9733751794343353

Epoch: 6| Step: 9
Training loss: 1.4792709350585938
Validation loss: 1.9807811847297094

Epoch: 6| Step: 10
Training loss: 1.9809858798980713
Validation loss: 2.0118470602138068

Epoch: 6| Step: 11
Training loss: 1.9430606365203857
Validation loss: 2.03082533549237

Epoch: 6| Step: 12
Training loss: 2.251138210296631
Validation loss: 2.0532778245146557

Epoch: 6| Step: 13
Training loss: 2.6222994327545166
Validation loss: 2.0381854926386187

Epoch: 167| Step: 0
Training loss: 1.884316325187683
Validation loss: 1.9922516448523409

Epoch: 6| Step: 1
Training loss: 1.8818418979644775
Validation loss: 1.9669775501374276

Epoch: 6| Step: 2
Training loss: 1.8282296657562256
Validation loss: 1.9476098514372302

Epoch: 6| Step: 3
Training loss: 2.338855266571045
Validation loss: 1.9695187089263753

Epoch: 6| Step: 4
Training loss: 2.4039382934570312
Validation loss: 1.9697212673002673

Epoch: 6| Step: 5
Training loss: 1.8838403224945068
Validation loss: 1.9886408851992698

Epoch: 6| Step: 6
Training loss: 1.6122827529907227
Validation loss: 1.9819598826028968

Epoch: 6| Step: 7
Training loss: 2.2953457832336426
Validation loss: 2.0149851665701917

Epoch: 6| Step: 8
Training loss: 1.474503755569458
Validation loss: 2.034206246816984

Epoch: 6| Step: 9
Training loss: 1.73737370967865
Validation loss: 2.0423766387406217

Epoch: 6| Step: 10
Training loss: 1.3957569599151611
Validation loss: 2.043091336886088

Epoch: 6| Step: 11
Training loss: 1.8968168497085571
Validation loss: 2.0233101229513846

Epoch: 6| Step: 12
Training loss: 2.1622719764709473
Validation loss: 2.016286334683818

Epoch: 6| Step: 13
Training loss: 2.624049425125122
Validation loss: 1.9962283654879498

Epoch: 168| Step: 0
Training loss: 1.962829828262329
Validation loss: 1.9816277975677161

Epoch: 6| Step: 1
Training loss: 2.367033004760742
Validation loss: 1.978866930930845

Epoch: 6| Step: 2
Training loss: 2.3577513694763184
Validation loss: 1.9864680728604716

Epoch: 6| Step: 3
Training loss: 2.363616704940796
Validation loss: 1.9893455877098987

Epoch: 6| Step: 4
Training loss: 1.859891414642334
Validation loss: 1.9947397042346258

Epoch: 6| Step: 5
Training loss: 1.9103589057922363
Validation loss: 1.9831561144962107

Epoch: 6| Step: 6
Training loss: 1.5333110094070435
Validation loss: 1.9954590387241815

Epoch: 6| Step: 7
Training loss: 2.5653138160705566
Validation loss: 2.0025731735332037

Epoch: 6| Step: 8
Training loss: 2.421189546585083
Validation loss: 2.02494324919998

Epoch: 6| Step: 9
Training loss: 1.30221688747406
Validation loss: 2.031236251195272

Epoch: 6| Step: 10
Training loss: 1.296788215637207
Validation loss: 2.041608028514411

Epoch: 6| Step: 11
Training loss: 0.9964764714241028
Validation loss: 2.025158974432176

Epoch: 6| Step: 12
Training loss: 1.7268157005310059
Validation loss: 2.0123502310886177

Epoch: 6| Step: 13
Training loss: 1.9269158840179443
Validation loss: 2.001267122965987

Epoch: 169| Step: 0
Training loss: 1.5481197834014893
Validation loss: 2.013758852917661

Epoch: 6| Step: 1
Training loss: 1.5245575904846191
Validation loss: 2.0246378862729637

Epoch: 6| Step: 2
Training loss: 1.7542916536331177
Validation loss: 2.037676167744462

Epoch: 6| Step: 3
Training loss: 1.6752500534057617
Validation loss: 2.0447524260449153

Epoch: 6| Step: 4
Training loss: 1.9771217107772827
Validation loss: 2.047266969116785

Epoch: 6| Step: 5
Training loss: 1.472055435180664
Validation loss: 2.015829551604486

Epoch: 6| Step: 6
Training loss: 2.630002975463867
Validation loss: 2.008863259387273

Epoch: 6| Step: 7
Training loss: 2.7690768241882324
Validation loss: 1.9785691794528757

Epoch: 6| Step: 8
Training loss: 2.093339443206787
Validation loss: 1.9800840321407522

Epoch: 6| Step: 9
Training loss: 1.7641761302947998
Validation loss: 1.973174072081043

Epoch: 6| Step: 10
Training loss: 2.1284780502319336
Validation loss: 1.9831194287987166

Epoch: 6| Step: 11
Training loss: 1.7623603343963623
Validation loss: 1.9782964657711726

Epoch: 6| Step: 12
Training loss: 1.4065052270889282
Validation loss: 1.984573850067713

Epoch: 6| Step: 13
Training loss: 2.1055469512939453
Validation loss: 1.9914463194467689

Epoch: 170| Step: 0
Training loss: 1.581491470336914
Validation loss: 2.0147727689435406

Epoch: 6| Step: 1
Training loss: 1.5666730403900146
Validation loss: 1.9813615263149302

Epoch: 6| Step: 2
Training loss: 1.8520517349243164
Validation loss: 1.965343072850217

Epoch: 6| Step: 3
Training loss: 2.0223031044006348
Validation loss: 1.9624464819508214

Epoch: 6| Step: 4
Training loss: 1.502880573272705
Validation loss: 1.94998804343644

Epoch: 6| Step: 5
Training loss: 2.36431884765625
Validation loss: 1.9414961030406337

Epoch: 6| Step: 6
Training loss: 2.609180212020874
Validation loss: 1.948963608793033

Epoch: 6| Step: 7
Training loss: 1.8539137840270996
Validation loss: 1.953681884273406

Epoch: 6| Step: 8
Training loss: 1.6896520853042603
Validation loss: 1.9714082261567474

Epoch: 6| Step: 9
Training loss: 1.7286887168884277
Validation loss: 1.9728906410996632

Epoch: 6| Step: 10
Training loss: 2.047494888305664
Validation loss: 1.9877298698630383

Epoch: 6| Step: 11
Training loss: 1.9765373468399048
Validation loss: 1.9982097969260266

Epoch: 6| Step: 12
Training loss: 2.0558643341064453
Validation loss: 1.9925490156296761

Epoch: 6| Step: 13
Training loss: 1.583240270614624
Validation loss: 1.996009244713732

Epoch: 171| Step: 0
Training loss: 1.2055842876434326
Validation loss: 1.9977125903611541

Epoch: 6| Step: 1
Training loss: 2.502312421798706
Validation loss: 2.0154166272891465

Epoch: 6| Step: 2
Training loss: 2.5885987281799316
Validation loss: 2.009721940563571

Epoch: 6| Step: 3
Training loss: 1.3153836727142334
Validation loss: 2.0167072537124797

Epoch: 6| Step: 4
Training loss: 2.351431369781494
Validation loss: 2.0210248552342898

Epoch: 6| Step: 5
Training loss: 1.6544305086135864
Validation loss: 2.006966365280972

Epoch: 6| Step: 6
Training loss: 1.6207289695739746
Validation loss: 1.9965552514599216

Epoch: 6| Step: 7
Training loss: 2.5173678398132324
Validation loss: 1.9902192520838913

Epoch: 6| Step: 8
Training loss: 1.780814528465271
Validation loss: 1.9691818888469408

Epoch: 6| Step: 9
Training loss: 1.7228827476501465
Validation loss: 1.993227489532963

Epoch: 6| Step: 10
Training loss: 1.4113609790802002
Validation loss: 2.0406772833998486

Epoch: 6| Step: 11
Training loss: 2.060236692428589
Validation loss: 2.0472873051961265

Epoch: 6| Step: 12
Training loss: 1.9808354377746582
Validation loss: 2.0210469807347944

Epoch: 6| Step: 13
Training loss: 2.1062283515930176
Validation loss: 2.0041701473215574

Epoch: 172| Step: 0
Training loss: 1.2283055782318115
Validation loss: 1.9925909785814182

Epoch: 6| Step: 1
Training loss: 1.8520082235336304
Validation loss: 1.9786570636175012

Epoch: 6| Step: 2
Training loss: 1.7548092603683472
Validation loss: 1.9688037082713137

Epoch: 6| Step: 3
Training loss: 1.3184620141983032
Validation loss: 1.9817553438166136

Epoch: 6| Step: 4
Training loss: 1.9424465894699097
Validation loss: 1.9768780380166986

Epoch: 6| Step: 5
Training loss: 1.6985338926315308
Validation loss: 1.9731923046932425

Epoch: 6| Step: 6
Training loss: 2.108445167541504
Validation loss: 1.9915598259177258

Epoch: 6| Step: 7
Training loss: 2.029325008392334
Validation loss: 1.99140880825699

Epoch: 6| Step: 8
Training loss: 1.925099492073059
Validation loss: 1.9977250253000567

Epoch: 6| Step: 9
Training loss: 2.152878761291504
Validation loss: 2.014604801772743

Epoch: 6| Step: 10
Training loss: 1.7417429685592651
Validation loss: 2.011596051595544

Epoch: 6| Step: 11
Training loss: 1.995974063873291
Validation loss: 2.016075438068759

Epoch: 6| Step: 12
Training loss: 2.2597696781158447
Validation loss: 2.0295133923971527

Epoch: 6| Step: 13
Training loss: 2.290217876434326
Validation loss: 2.013703002724596

Epoch: 173| Step: 0
Training loss: 1.9212275743484497
Validation loss: 2.013852355300739

Epoch: 6| Step: 1
Training loss: 2.038637161254883
Validation loss: 1.98732957788693

Epoch: 6| Step: 2
Training loss: 2.1945199966430664
Validation loss: 1.9665928117690548

Epoch: 6| Step: 3
Training loss: 1.9194256067276
Validation loss: 1.9787149121684413

Epoch: 6| Step: 4
Training loss: 1.8570184707641602
Validation loss: 1.9638604335887457

Epoch: 6| Step: 5
Training loss: 1.5785834789276123
Validation loss: 1.9684335903454853

Epoch: 6| Step: 6
Training loss: 1.5791959762573242
Validation loss: 1.962814482309485

Epoch: 6| Step: 7
Training loss: 2.1583797931671143
Validation loss: 1.964765179541803

Epoch: 6| Step: 8
Training loss: 1.6191473007202148
Validation loss: 1.9766443980637418

Epoch: 6| Step: 9
Training loss: 1.6944289207458496
Validation loss: 1.9687367664870394

Epoch: 6| Step: 10
Training loss: 1.718739628791809
Validation loss: 1.961734285918615

Epoch: 6| Step: 11
Training loss: 1.916947364807129
Validation loss: 1.9525271026037072

Epoch: 6| Step: 12
Training loss: 2.256070613861084
Validation loss: 1.952852156854445

Epoch: 6| Step: 13
Training loss: 1.2596230506896973
Validation loss: 1.9570397997415194

Epoch: 174| Step: 0
Training loss: 2.296022415161133
Validation loss: 1.9603031989066833

Epoch: 6| Step: 1
Training loss: 1.5599316358566284
Validation loss: 1.9474454848997054

Epoch: 6| Step: 2
Training loss: 1.3717761039733887
Validation loss: 1.9685369640268304

Epoch: 6| Step: 3
Training loss: 1.814976692199707
Validation loss: 1.9746364162814232

Epoch: 6| Step: 4
Training loss: 1.8878655433654785
Validation loss: 1.9479237653875863

Epoch: 6| Step: 5
Training loss: 2.4883036613464355
Validation loss: 1.9702661319445538

Epoch: 6| Step: 6
Training loss: 1.3102729320526123
Validation loss: 1.9682801256897628

Epoch: 6| Step: 7
Training loss: 2.2531063556671143
Validation loss: 1.9810168948224796

Epoch: 6| Step: 8
Training loss: 2.090118885040283
Validation loss: 1.9825267407201952

Epoch: 6| Step: 9
Training loss: 1.831252932548523
Validation loss: 1.9968398488977903

Epoch: 6| Step: 10
Training loss: 1.51304030418396
Validation loss: 2.0033450959831156

Epoch: 6| Step: 11
Training loss: 1.8515479564666748
Validation loss: 2.0070807779988935

Epoch: 6| Step: 12
Training loss: 1.5781707763671875
Validation loss: 1.9723867139508646

Epoch: 6| Step: 13
Training loss: 2.082573890686035
Validation loss: 1.9834226433948805

Epoch: 175| Step: 0
Training loss: 1.3794612884521484
Validation loss: 1.9724733547497821

Epoch: 6| Step: 1
Training loss: 2.122771739959717
Validation loss: 1.987188054669288

Epoch: 6| Step: 2
Training loss: 1.576735258102417
Validation loss: 1.9924149564517442

Epoch: 6| Step: 3
Training loss: 2.8701138496398926
Validation loss: 1.9904836326517084

Epoch: 6| Step: 4
Training loss: 1.9440176486968994
Validation loss: 1.9887117788355837

Epoch: 6| Step: 5
Training loss: 1.7458728551864624
Validation loss: 1.9946881955669773

Epoch: 6| Step: 6
Training loss: 1.9685965776443481
Validation loss: 1.9990391526170956

Epoch: 6| Step: 7
Training loss: 1.7396293878555298
Validation loss: 2.0027707289623957

Epoch: 6| Step: 8
Training loss: 2.2187633514404297
Validation loss: 2.008861866048587

Epoch: 6| Step: 9
Training loss: 1.2842212915420532
Validation loss: 2.0100514555490143

Epoch: 6| Step: 10
Training loss: 1.9689640998840332
Validation loss: 2.030612612283358

Epoch: 6| Step: 11
Training loss: 1.0760838985443115
Validation loss: 2.0179750534795944

Epoch: 6| Step: 12
Training loss: 1.941692590713501
Validation loss: 2.038882940046249

Epoch: 6| Step: 13
Training loss: 1.8744394779205322
Validation loss: 2.0271342364690637

Epoch: 176| Step: 0
Training loss: 2.538872718811035
Validation loss: 2.0300071085652998

Epoch: 6| Step: 1
Training loss: 1.4433770179748535
Validation loss: 2.0225146496167747

Epoch: 6| Step: 2
Training loss: 2.068007707595825
Validation loss: 2.006310711624802

Epoch: 6| Step: 3
Training loss: 1.7399818897247314
Validation loss: 2.0164238329856627

Epoch: 6| Step: 4
Training loss: 2.4043450355529785
Validation loss: 2.0111438394874654

Epoch: 6| Step: 5
Training loss: 1.6551547050476074
Validation loss: 2.020616146825975

Epoch: 6| Step: 6
Training loss: 1.9272748231887817
Validation loss: 1.9922532163640505

Epoch: 6| Step: 7
Training loss: 1.2809607982635498
Validation loss: 2.001463823421027

Epoch: 6| Step: 8
Training loss: 1.581536054611206
Validation loss: 1.9855174454309608

Epoch: 6| Step: 9
Training loss: 1.502213478088379
Validation loss: 1.985045890654287

Epoch: 6| Step: 10
Training loss: 2.14582896232605
Validation loss: 1.9812261930076025

Epoch: 6| Step: 11
Training loss: 2.0485687255859375
Validation loss: 1.9670549259390882

Epoch: 6| Step: 12
Training loss: 1.7602053880691528
Validation loss: 1.9753299502916233

Epoch: 6| Step: 13
Training loss: 1.5988097190856934
Validation loss: 1.970766552032963

Epoch: 177| Step: 0
Training loss: 2.9656596183776855
Validation loss: 1.9936259420969153

Epoch: 6| Step: 1
Training loss: 1.7035465240478516
Validation loss: 2.0019472645175074

Epoch: 6| Step: 2
Training loss: 1.2689423561096191
Validation loss: 2.009510399192892

Epoch: 6| Step: 3
Training loss: 1.2428576946258545
Validation loss: 2.001514397641664

Epoch: 6| Step: 4
Training loss: 2.016064167022705
Validation loss: 1.994593099881244

Epoch: 6| Step: 5
Training loss: 1.4078105688095093
Validation loss: 1.9754613676378805

Epoch: 6| Step: 6
Training loss: 2.2803702354431152
Validation loss: 1.9738489556056198

Epoch: 6| Step: 7
Training loss: 1.8188261985778809
Validation loss: 1.9525485128484747

Epoch: 6| Step: 8
Training loss: 2.011178970336914
Validation loss: 1.9590948499659055

Epoch: 6| Step: 9
Training loss: 1.5046288967132568
Validation loss: 1.9542015521757063

Epoch: 6| Step: 10
Training loss: 1.5417050123214722
Validation loss: 1.9623015580638763

Epoch: 6| Step: 11
Training loss: 2.0464718341827393
Validation loss: 1.9741362487116167

Epoch: 6| Step: 12
Training loss: 1.675950527191162
Validation loss: 2.025736326812416

Epoch: 6| Step: 13
Training loss: 2.4112794399261475
Validation loss: 2.0374271997841458

Epoch: 178| Step: 0
Training loss: 2.5124611854553223
Validation loss: 2.0276203463154454

Epoch: 6| Step: 1
Training loss: 2.3523051738739014
Validation loss: 1.987170814186014

Epoch: 6| Step: 2
Training loss: 1.9809895753860474
Validation loss: 1.993186766101468

Epoch: 6| Step: 3
Training loss: 1.8675893545150757
Validation loss: 1.9778188736208024

Epoch: 6| Step: 4
Training loss: 1.789180874824524
Validation loss: 1.9780210653940837

Epoch: 6| Step: 5
Training loss: 1.7801423072814941
Validation loss: 1.9686721319793372

Epoch: 6| Step: 6
Training loss: 1.9010106325149536
Validation loss: 1.9740685634715582

Epoch: 6| Step: 7
Training loss: 1.529242753982544
Validation loss: 1.992697661922824

Epoch: 6| Step: 8
Training loss: 1.7918418645858765
Validation loss: 2.0037169020663024

Epoch: 6| Step: 9
Training loss: 1.146088719367981
Validation loss: 2.0274079179251068

Epoch: 6| Step: 10
Training loss: 2.4133141040802
Validation loss: 2.057836094210225

Epoch: 6| Step: 11
Training loss: 1.4932503700256348
Validation loss: 2.0616424596437843

Epoch: 6| Step: 12
Training loss: 1.843846321105957
Validation loss: 2.0399876666325394

Epoch: 6| Step: 13
Training loss: 1.5165715217590332
Validation loss: 2.0149576817789385

Epoch: 179| Step: 0
Training loss: 1.9359264373779297
Validation loss: 2.0105322971138904

Epoch: 6| Step: 1
Training loss: 1.3310414552688599
Validation loss: 1.9803944300579768

Epoch: 6| Step: 2
Training loss: 2.037085771560669
Validation loss: 1.9853557514887985

Epoch: 6| Step: 3
Training loss: 1.784117579460144
Validation loss: 1.9748128819209274

Epoch: 6| Step: 4
Training loss: 1.942444086074829
Validation loss: 1.9803210855812154

Epoch: 6| Step: 5
Training loss: 2.0348010063171387
Validation loss: 1.9849398341230167

Epoch: 6| Step: 6
Training loss: 1.7659528255462646
Validation loss: 1.9841293416997439

Epoch: 6| Step: 7
Training loss: 2.0889291763305664
Validation loss: 1.9854233111104658

Epoch: 6| Step: 8
Training loss: 1.30625319480896
Validation loss: 1.9679066224764752

Epoch: 6| Step: 9
Training loss: 1.1909533739089966
Validation loss: 1.9663422492242628

Epoch: 6| Step: 10
Training loss: 2.136159896850586
Validation loss: 1.9667265927919777

Epoch: 6| Step: 11
Training loss: 2.0112123489379883
Validation loss: 1.9932220674330188

Epoch: 6| Step: 12
Training loss: 1.9604324102401733
Validation loss: 2.0165420988554597

Epoch: 6| Step: 13
Training loss: 1.366447925567627
Validation loss: 2.0116627113793486

Epoch: 180| Step: 0
Training loss: 1.6740493774414062
Validation loss: 1.9932633599927347

Epoch: 6| Step: 1
Training loss: 1.7695133686065674
Validation loss: 1.9769285391735774

Epoch: 6| Step: 2
Training loss: 2.066183567047119
Validation loss: 1.9571579553747689

Epoch: 6| Step: 3
Training loss: 1.7955071926116943
Validation loss: 1.9723889763637255

Epoch: 6| Step: 4
Training loss: 2.466888427734375
Validation loss: 1.9653065102074736

Epoch: 6| Step: 5
Training loss: 1.3359243869781494
Validation loss: 1.9889436998674948

Epoch: 6| Step: 6
Training loss: 1.7927886247634888
Validation loss: 1.9928193015436972

Epoch: 6| Step: 7
Training loss: 2.2350053787231445
Validation loss: 2.0069212708421933

Epoch: 6| Step: 8
Training loss: 1.7212727069854736
Validation loss: 2.0084041433949626

Epoch: 6| Step: 9
Training loss: 1.9541494846343994
Validation loss: 2.0229495750960482

Epoch: 6| Step: 10
Training loss: 1.769912838935852
Validation loss: 2.0372097030762704

Epoch: 6| Step: 11
Training loss: 1.7517225742340088
Validation loss: 2.027203295820503

Epoch: 6| Step: 12
Training loss: 1.9520217180252075
Validation loss: 2.042384724463186

Epoch: 6| Step: 13
Training loss: 0.6489931344985962
Validation loss: 2.011639586058996

Epoch: 181| Step: 0
Training loss: 2.07078218460083
Validation loss: 1.9659118601070937

Epoch: 6| Step: 1
Training loss: 1.8258731365203857
Validation loss: 1.9588911956356418

Epoch: 6| Step: 2
Training loss: 1.8106327056884766
Validation loss: 1.9723000616155646

Epoch: 6| Step: 3
Training loss: 1.8181711435317993
Validation loss: 1.949777885149884

Epoch: 6| Step: 4
Training loss: 1.9696381092071533
Validation loss: 1.9503851654709026

Epoch: 6| Step: 5
Training loss: 1.7255524396896362
Validation loss: 1.967631027262698

Epoch: 6| Step: 6
Training loss: 2.1160717010498047
Validation loss: 1.9494107769381614

Epoch: 6| Step: 7
Training loss: 1.458034634590149
Validation loss: 1.9616937086146364

Epoch: 6| Step: 8
Training loss: 2.474595308303833
Validation loss: 1.9850312099661878

Epoch: 6| Step: 9
Training loss: 1.9674816131591797
Validation loss: 2.036469167278659

Epoch: 6| Step: 10
Training loss: 1.4482181072235107
Validation loss: 2.04701582847103

Epoch: 6| Step: 11
Training loss: 1.8661750555038452
Validation loss: 2.036778078284315

Epoch: 6| Step: 12
Training loss: 1.5763111114501953
Validation loss: 2.0238668431517897

Epoch: 6| Step: 13
Training loss: 1.461256980895996
Validation loss: 1.989075494068925

Epoch: 182| Step: 0
Training loss: 1.5746376514434814
Validation loss: 1.978660068204326

Epoch: 6| Step: 1
Training loss: 1.4083881378173828
Validation loss: 1.965982085915022

Epoch: 6| Step: 2
Training loss: 1.8107218742370605
Validation loss: 1.9921234448750813

Epoch: 6| Step: 3
Training loss: 2.0796823501586914
Validation loss: 1.976575461767053

Epoch: 6| Step: 4
Training loss: 1.7757662534713745
Validation loss: 1.9984362125396729

Epoch: 6| Step: 5
Training loss: 2.046794891357422
Validation loss: 2.0019213768743698

Epoch: 6| Step: 6
Training loss: 2.1560282707214355
Validation loss: 1.9932284893528107

Epoch: 6| Step: 7
Training loss: 2.0382962226867676
Validation loss: 2.0087564094092256

Epoch: 6| Step: 8
Training loss: 1.5750384330749512
Validation loss: 2.010968041676347

Epoch: 6| Step: 9
Training loss: 2.176427125930786
Validation loss: 2.006908837185111

Epoch: 6| Step: 10
Training loss: 1.4094579219818115
Validation loss: 2.0047863760302143

Epoch: 6| Step: 11
Training loss: 1.9775224924087524
Validation loss: 2.0080965924006637

Epoch: 6| Step: 12
Training loss: 1.2386322021484375
Validation loss: 1.9932296583729405

Epoch: 6| Step: 13
Training loss: 1.4233403205871582
Validation loss: 1.9963674917015979

Epoch: 183| Step: 0
Training loss: 1.9734880924224854
Validation loss: 1.9960691236680554

Epoch: 6| Step: 1
Training loss: 1.9158005714416504
Validation loss: 1.9855239570781749

Epoch: 6| Step: 2
Training loss: 1.2203330993652344
Validation loss: 1.9831077206519343

Epoch: 6| Step: 3
Training loss: 1.6318796873092651
Validation loss: 2.0024506084380613

Epoch: 6| Step: 4
Training loss: 1.5892212390899658
Validation loss: 1.984687730830203

Epoch: 6| Step: 5
Training loss: 1.6177808046340942
Validation loss: 1.9774237063623243

Epoch: 6| Step: 6
Training loss: 1.4386322498321533
Validation loss: 1.9666963495234007

Epoch: 6| Step: 7
Training loss: 2.1698150634765625
Validation loss: 1.9673863969823366

Epoch: 6| Step: 8
Training loss: 2.409651279449463
Validation loss: 1.9777543903678976

Epoch: 6| Step: 9
Training loss: 1.381974220275879
Validation loss: 1.9774936040242512

Epoch: 6| Step: 10
Training loss: 2.113168239593506
Validation loss: 1.982458891407136

Epoch: 6| Step: 11
Training loss: 1.5605134963989258
Validation loss: 1.9859237311988749

Epoch: 6| Step: 12
Training loss: 2.2999954223632812
Validation loss: 1.9832667753260622

Epoch: 6| Step: 13
Training loss: 1.0944619178771973
Validation loss: 1.9705992014177385

Epoch: 184| Step: 0
Training loss: 2.506059408187866
Validation loss: 1.9819364675911524

Epoch: 6| Step: 1
Training loss: 1.6376473903656006
Validation loss: 1.9733453617301038

Epoch: 6| Step: 2
Training loss: 1.968654751777649
Validation loss: 1.9804801453826248

Epoch: 6| Step: 3
Training loss: 1.6232205629348755
Validation loss: 1.9924166817818918

Epoch: 6| Step: 4
Training loss: 1.5665154457092285
Validation loss: 1.998967670625256

Epoch: 6| Step: 5
Training loss: 1.8947354555130005
Validation loss: 1.9714656747797483

Epoch: 6| Step: 6
Training loss: 1.1945686340332031
Validation loss: 1.9657521042772519

Epoch: 6| Step: 7
Training loss: 1.5922505855560303
Validation loss: 1.974703381138463

Epoch: 6| Step: 8
Training loss: 2.2963011264801025
Validation loss: 2.00537339333565

Epoch: 6| Step: 9
Training loss: 2.168858528137207
Validation loss: 2.045885593660416

Epoch: 6| Step: 10
Training loss: 1.183068037033081
Validation loss: 2.030230577274035

Epoch: 6| Step: 11
Training loss: 1.9415814876556396
Validation loss: 2.009798187081532

Epoch: 6| Step: 12
Training loss: 1.8760055303573608
Validation loss: 1.9934237567327355

Epoch: 6| Step: 13
Training loss: 1.3535608053207397
Validation loss: 1.9828705069839314

Epoch: 185| Step: 0
Training loss: 1.6603686809539795
Validation loss: 1.950618996415087

Epoch: 6| Step: 1
Training loss: 1.7766669988632202
Validation loss: 1.9407888330439085

Epoch: 6| Step: 2
Training loss: 1.3198078870773315
Validation loss: 1.9375662572922245

Epoch: 6| Step: 3
Training loss: 2.058938980102539
Validation loss: 1.9264074140979397

Epoch: 6| Step: 4
Training loss: 1.8546466827392578
Validation loss: 1.9380881606891591

Epoch: 6| Step: 5
Training loss: 2.039079427719116
Validation loss: 1.948668195355323

Epoch: 6| Step: 6
Training loss: 1.4484789371490479
Validation loss: 1.9549720312959404

Epoch: 6| Step: 7
Training loss: 1.6771855354309082
Validation loss: 1.9773721002763318

Epoch: 6| Step: 8
Training loss: 2.063502550125122
Validation loss: 1.976422857212764

Epoch: 6| Step: 9
Training loss: 1.5036416053771973
Validation loss: 1.957834675747861

Epoch: 6| Step: 10
Training loss: 2.0248546600341797
Validation loss: 1.948158820470174

Epoch: 6| Step: 11
Training loss: 2.3935928344726562
Validation loss: 1.954806726465943

Epoch: 6| Step: 12
Training loss: 1.85066819190979
Validation loss: 1.9533226951476066

Epoch: 6| Step: 13
Training loss: 1.195504069328308
Validation loss: 1.9589539997039302

Epoch: 186| Step: 0
Training loss: 1.96145761013031
Validation loss: 1.9585484894373084

Epoch: 6| Step: 1
Training loss: 1.1161692142486572
Validation loss: 1.9618098581990888

Epoch: 6| Step: 2
Training loss: 1.418424129486084
Validation loss: 1.9761005934848581

Epoch: 6| Step: 3
Training loss: 1.309650182723999
Validation loss: 1.9664732986880886

Epoch: 6| Step: 4
Training loss: 1.9907783269882202
Validation loss: 1.972117434265793

Epoch: 6| Step: 5
Training loss: 1.9124963283538818
Validation loss: 1.9845111959724016

Epoch: 6| Step: 6
Training loss: 2.71388840675354
Validation loss: 2.0006514159581994

Epoch: 6| Step: 7
Training loss: 2.0367331504821777
Validation loss: 2.0031845415792158

Epoch: 6| Step: 8
Training loss: 2.130728006362915
Validation loss: 2.017884151909941

Epoch: 6| Step: 9
Training loss: 1.4953261613845825
Validation loss: 2.0098128831514748

Epoch: 6| Step: 10
Training loss: 1.3059592247009277
Validation loss: 1.988822280719716

Epoch: 6| Step: 11
Training loss: 1.7442697286605835
Validation loss: 1.9867992272941015

Epoch: 6| Step: 12
Training loss: 1.5139029026031494
Validation loss: 1.9989294903252715

Epoch: 6| Step: 13
Training loss: 1.7741327285766602
Validation loss: 2.003558046074324

Epoch: 187| Step: 0
Training loss: 1.4832074642181396
Validation loss: 2.014447105828152

Epoch: 6| Step: 1
Training loss: 2.5985567569732666
Validation loss: 1.9741048787229805

Epoch: 6| Step: 2
Training loss: 1.7887444496154785
Validation loss: 1.9924748879607006

Epoch: 6| Step: 3
Training loss: 1.8260427713394165
Validation loss: 1.9936032833591584

Epoch: 6| Step: 4
Training loss: 2.2955079078674316
Validation loss: 1.9923664292981547

Epoch: 6| Step: 5
Training loss: 1.9567246437072754
Validation loss: 2.005438562362425

Epoch: 6| Step: 6
Training loss: 2.129685401916504
Validation loss: 2.0140673345135105

Epoch: 6| Step: 7
Training loss: 0.9444092512130737
Validation loss: 1.9975766956165273

Epoch: 6| Step: 8
Training loss: 1.400069236755371
Validation loss: 2.001390826317572

Epoch: 6| Step: 9
Training loss: 2.125706911087036
Validation loss: 2.001818741521528

Epoch: 6| Step: 10
Training loss: 1.2237697839736938
Validation loss: 1.981132540651547

Epoch: 6| Step: 11
Training loss: 1.6012578010559082
Validation loss: 1.9671074190447408

Epoch: 6| Step: 12
Training loss: 1.3498060703277588
Validation loss: 1.9648326007268762

Epoch: 6| Step: 13
Training loss: 1.0498017072677612
Validation loss: 1.9613555016056183

Epoch: 188| Step: 0
Training loss: 1.4076100587844849
Validation loss: 1.9554399521120134

Epoch: 6| Step: 1
Training loss: 1.9514832496643066
Validation loss: 1.9848263314975205

Epoch: 6| Step: 2
Training loss: 1.836165428161621
Validation loss: 2.024357880315473

Epoch: 6| Step: 3
Training loss: 1.6149635314941406
Validation loss: 2.0020133128730198

Epoch: 6| Step: 4
Training loss: 1.3350603580474854
Validation loss: 2.0063221275165515

Epoch: 6| Step: 5
Training loss: 1.8504611253738403
Validation loss: 1.969189272131971

Epoch: 6| Step: 6
Training loss: 1.5848517417907715
Validation loss: 1.9794435180643553

Epoch: 6| Step: 7
Training loss: 2.1057660579681396
Validation loss: 1.9564712380850187

Epoch: 6| Step: 8
Training loss: 2.162649393081665
Validation loss: 1.9649898031706452

Epoch: 6| Step: 9
Training loss: 1.6657497882843018
Validation loss: 1.9755975200283913

Epoch: 6| Step: 10
Training loss: 1.3382011651992798
Validation loss: 1.9474876619154406

Epoch: 6| Step: 11
Training loss: 1.8801263570785522
Validation loss: 1.9870771490117556

Epoch: 6| Step: 12
Training loss: 1.4159727096557617
Validation loss: 1.9831907031356648

Epoch: 6| Step: 13
Training loss: 1.9455655813217163
Validation loss: 1.9751527668327413

Epoch: 189| Step: 0
Training loss: 1.5157201290130615
Validation loss: 1.973218781973726

Epoch: 6| Step: 1
Training loss: 1.7862062454223633
Validation loss: 1.9862437376412012

Epoch: 6| Step: 2
Training loss: 1.8324670791625977
Validation loss: 1.9886633888367684

Epoch: 6| Step: 3
Training loss: 2.021580696105957
Validation loss: 1.9566931622002715

Epoch: 6| Step: 4
Training loss: 2.0958940982818604
Validation loss: 1.9624801220432404

Epoch: 6| Step: 5
Training loss: 2.1715340614318848
Validation loss: 1.963146694244877

Epoch: 6| Step: 6
Training loss: 1.5180375576019287
Validation loss: 1.9591613969495218

Epoch: 6| Step: 7
Training loss: 1.9254997968673706
Validation loss: 1.9561232136141868

Epoch: 6| Step: 8
Training loss: 1.0352141857147217
Validation loss: 1.959585751256635

Epoch: 6| Step: 9
Training loss: 1.5868302583694458
Validation loss: 1.978671012386199

Epoch: 6| Step: 10
Training loss: 1.2166736125946045
Validation loss: 1.9768901178913731

Epoch: 6| Step: 11
Training loss: 1.5956010818481445
Validation loss: 2.00397277134721

Epoch: 6| Step: 12
Training loss: 1.6273612976074219
Validation loss: 2.018661683605563

Epoch: 6| Step: 13
Training loss: 1.9014006853103638
Validation loss: 2.0540350419218822

Epoch: 190| Step: 0
Training loss: 2.165445327758789
Validation loss: 1.9999366242398497

Epoch: 6| Step: 1
Training loss: 1.5549137592315674
Validation loss: 1.9864797130707772

Epoch: 6| Step: 2
Training loss: 2.086500644683838
Validation loss: 1.979397245632705

Epoch: 6| Step: 3
Training loss: 1.6058385372161865
Validation loss: 1.9959394726701962

Epoch: 6| Step: 4
Training loss: 0.9789758324623108
Validation loss: 1.9932737106918006

Epoch: 6| Step: 5
Training loss: 1.6395752429962158
Validation loss: 1.9928515829065794

Epoch: 6| Step: 6
Training loss: 2.3495707511901855
Validation loss: 1.9843550689758793

Epoch: 6| Step: 7
Training loss: 1.3608125448226929
Validation loss: 1.9989569751165246

Epoch: 6| Step: 8
Training loss: 1.6995617151260376
Validation loss: 1.9748913575244207

Epoch: 6| Step: 9
Training loss: 1.4646066427230835
Validation loss: 1.9540444843230709

Epoch: 6| Step: 10
Training loss: 1.3762593269348145
Validation loss: 1.9960320688063098

Epoch: 6| Step: 11
Training loss: 1.5990607738494873
Validation loss: 2.031032713510657

Epoch: 6| Step: 12
Training loss: 1.9150351285934448
Validation loss: 2.0800818717607887

Epoch: 6| Step: 13
Training loss: 2.050105094909668
Validation loss: 2.0756461363966747

Epoch: 191| Step: 0
Training loss: 2.3913021087646484
Validation loss: 2.0399394009702947

Epoch: 6| Step: 1
Training loss: 1.8624290227890015
Validation loss: 1.9703422797623502

Epoch: 6| Step: 2
Training loss: 1.9429773092269897
Validation loss: 1.9635731353554675

Epoch: 6| Step: 3
Training loss: 2.0815658569335938
Validation loss: 1.9539852680698517

Epoch: 6| Step: 4
Training loss: 1.6510727405548096
Validation loss: 1.9755576913074782

Epoch: 6| Step: 5
Training loss: 1.4776631593704224
Validation loss: 1.9728334180770382

Epoch: 6| Step: 6
Training loss: 1.967285394668579
Validation loss: 1.9972580261127924

Epoch: 6| Step: 7
Training loss: 2.217768907546997
Validation loss: 1.9766941532011955

Epoch: 6| Step: 8
Training loss: 1.2395648956298828
Validation loss: 1.9707679979262813

Epoch: 6| Step: 9
Training loss: 1.692530870437622
Validation loss: 2.00069010385903

Epoch: 6| Step: 10
Training loss: 1.5706712007522583
Validation loss: 2.010852083083122

Epoch: 6| Step: 11
Training loss: 1.1250791549682617
Validation loss: 2.0209711597811792

Epoch: 6| Step: 12
Training loss: 1.1831142902374268
Validation loss: 2.0053438986501386

Epoch: 6| Step: 13
Training loss: 0.7570598125457764
Validation loss: 1.987042418090246

Epoch: 192| Step: 0
Training loss: 2.3080544471740723
Validation loss: 1.9871930742776522

Epoch: 6| Step: 1
Training loss: 1.621199131011963
Validation loss: 1.9869168766083256

Epoch: 6| Step: 2
Training loss: 2.6431150436401367
Validation loss: 1.9708932240804036

Epoch: 6| Step: 3
Training loss: 1.436765432357788
Validation loss: 1.951330315682196

Epoch: 6| Step: 4
Training loss: 1.2622201442718506
Validation loss: 1.9616965606648435

Epoch: 6| Step: 5
Training loss: 1.5049526691436768
Validation loss: 1.9721975147083242

Epoch: 6| Step: 6
Training loss: 1.6763393878936768
Validation loss: 1.9601742247099518

Epoch: 6| Step: 7
Training loss: 1.3166017532348633
Validation loss: 1.9534215452850505

Epoch: 6| Step: 8
Training loss: 1.5870100259780884
Validation loss: 1.9476478868915188

Epoch: 6| Step: 9
Training loss: 1.3975648880004883
Validation loss: 1.9457631213690645

Epoch: 6| Step: 10
Training loss: 1.970953106880188
Validation loss: 1.9520999308555358

Epoch: 6| Step: 11
Training loss: 1.2487640380859375
Validation loss: 1.967170020585419

Epoch: 6| Step: 12
Training loss: 1.548575758934021
Validation loss: 1.9695338126151793

Epoch: 6| Step: 13
Training loss: 1.7907445430755615
Validation loss: 1.9851688672137517

Epoch: 193| Step: 0
Training loss: 2.0140767097473145
Validation loss: 1.9906623325040262

Epoch: 6| Step: 1
Training loss: 2.1423957347869873
Validation loss: 2.00177090655091

Epoch: 6| Step: 2
Training loss: 2.5706589221954346
Validation loss: 2.0332430870302263

Epoch: 6| Step: 3
Training loss: 1.9397788047790527
Validation loss: 2.0265199394636255

Epoch: 6| Step: 4
Training loss: 1.0225346088409424
Validation loss: 1.9991137366141043

Epoch: 6| Step: 5
Training loss: 1.5082331895828247
Validation loss: 1.9984307442941973

Epoch: 6| Step: 6
Training loss: 1.6940228939056396
Validation loss: 1.9735568800280172

Epoch: 6| Step: 7
Training loss: 1.6131021976470947
Validation loss: 1.964253947299014

Epoch: 6| Step: 8
Training loss: 1.0150222778320312
Validation loss: 1.965380346903237

Epoch: 6| Step: 9
Training loss: 1.976712703704834
Validation loss: 1.9656885952077887

Epoch: 6| Step: 10
Training loss: 1.642284870147705
Validation loss: 1.9569285005651496

Epoch: 6| Step: 11
Training loss: 1.907493233680725
Validation loss: 1.973822703925512

Epoch: 6| Step: 12
Training loss: 1.3826782703399658
Validation loss: 1.9691571048510972

Epoch: 6| Step: 13
Training loss: 0.7242547273635864
Validation loss: 1.956081462162797

Epoch: 194| Step: 0
Training loss: 1.6852407455444336
Validation loss: 1.9677819231505036

Epoch: 6| Step: 1
Training loss: 1.2760354280471802
Validation loss: 1.9990784122097878

Epoch: 6| Step: 2
Training loss: 1.6046080589294434
Validation loss: 2.0265517311711467

Epoch: 6| Step: 3
Training loss: 2.4715676307678223
Validation loss: 2.0331923166910806

Epoch: 6| Step: 4
Training loss: 1.9920904636383057
Validation loss: 2.0459776488683556

Epoch: 6| Step: 5
Training loss: 1.505014181137085
Validation loss: 2.0209979805895077

Epoch: 6| Step: 6
Training loss: 1.5435807704925537
Validation loss: 2.0236220129074587

Epoch: 6| Step: 7
Training loss: 1.858149766921997
Validation loss: 2.02026359240214

Epoch: 6| Step: 8
Training loss: 1.6883238554000854
Validation loss: 2.036162737877138

Epoch: 6| Step: 9
Training loss: 1.4317266941070557
Validation loss: 2.0218153551060665

Epoch: 6| Step: 10
Training loss: 0.7260138392448425
Validation loss: 2.0056225330598894

Epoch: 6| Step: 11
Training loss: 2.281785488128662
Validation loss: 1.9743159458201418

Epoch: 6| Step: 12
Training loss: 1.4620287418365479
Validation loss: 1.965303180038288

Epoch: 6| Step: 13
Training loss: 2.3115367889404297
Validation loss: 1.9580324721592728

Epoch: 195| Step: 0
Training loss: 2.1558291912078857
Validation loss: 1.9508283522821241

Epoch: 6| Step: 1
Training loss: 0.9792382717132568
Validation loss: 1.9476424314642464

Epoch: 6| Step: 2
Training loss: 1.7875398397445679
Validation loss: 1.952980960569074

Epoch: 6| Step: 3
Training loss: 1.9219648838043213
Validation loss: 1.9835031596563195

Epoch: 6| Step: 4
Training loss: 0.8987886905670166
Validation loss: 1.9874058718322425

Epoch: 6| Step: 5
Training loss: 1.521882176399231
Validation loss: 1.9818044836803148

Epoch: 6| Step: 6
Training loss: 1.287269115447998
Validation loss: 1.9918947194212226

Epoch: 6| Step: 7
Training loss: 1.2692627906799316
Validation loss: 1.9754124764473207

Epoch: 6| Step: 8
Training loss: 2.2133898735046387
Validation loss: 1.9702968366684452

Epoch: 6| Step: 9
Training loss: 1.6286072731018066
Validation loss: 1.9700720938303138

Epoch: 6| Step: 10
Training loss: 2.094576835632324
Validation loss: 1.9599230802187355

Epoch: 6| Step: 11
Training loss: 1.7156744003295898
Validation loss: 1.9835573319465882

Epoch: 6| Step: 12
Training loss: 1.7697501182556152
Validation loss: 1.965234443705569

Epoch: 6| Step: 13
Training loss: 1.9596909284591675
Validation loss: 1.9660287121290803

Epoch: 196| Step: 0
Training loss: 1.5502173900604248
Validation loss: 1.9651117619647775

Epoch: 6| Step: 1
Training loss: 1.3152539730072021
Validation loss: 1.9797420065890077

Epoch: 6| Step: 2
Training loss: 1.0218970775604248
Validation loss: 2.000722389067373

Epoch: 6| Step: 3
Training loss: 1.946614384651184
Validation loss: 1.9950438750687467

Epoch: 6| Step: 4
Training loss: 1.4661633968353271
Validation loss: 1.9826124739903275

Epoch: 6| Step: 5
Training loss: 2.294863224029541
Validation loss: 1.996675729751587

Epoch: 6| Step: 6
Training loss: 1.8632457256317139
Validation loss: 1.99812561978576

Epoch: 6| Step: 7
Training loss: 1.565401315689087
Validation loss: 1.997490062508532

Epoch: 6| Step: 8
Training loss: 1.965080976486206
Validation loss: 1.9772699263788038

Epoch: 6| Step: 9
Training loss: 1.8833884000778198
Validation loss: 1.9956445488878476

Epoch: 6| Step: 10
Training loss: 1.6370577812194824
Validation loss: 1.9854167776723062

Epoch: 6| Step: 11
Training loss: 1.7111743688583374
Validation loss: 1.9815474530701995

Epoch: 6| Step: 12
Training loss: 1.4896295070648193
Validation loss: 1.9785022389504217

Epoch: 6| Step: 13
Training loss: 0.9825601577758789
Validation loss: 1.9707330119225286

Epoch: 197| Step: 0
Training loss: 1.4657436609268188
Validation loss: 1.950688822295076

Epoch: 6| Step: 1
Training loss: 2.0944154262542725
Validation loss: 1.9803687269969652

Epoch: 6| Step: 2
Training loss: 1.3138337135314941
Validation loss: 1.9764908782897457

Epoch: 6| Step: 3
Training loss: 1.653149127960205
Validation loss: 1.9851759197891399

Epoch: 6| Step: 4
Training loss: 2.045515298843384
Validation loss: 1.9905424528224493

Epoch: 6| Step: 5
Training loss: 1.7285979986190796
Validation loss: 2.0117394988254835

Epoch: 6| Step: 6
Training loss: 2.10872745513916
Validation loss: 2.0104886049865396

Epoch: 6| Step: 7
Training loss: 1.7993885278701782
Validation loss: 1.9935557265435495

Epoch: 6| Step: 8
Training loss: 1.3778407573699951
Validation loss: 1.9400213662014212

Epoch: 6| Step: 9
Training loss: 2.0778303146362305
Validation loss: 1.9335122980097288

Epoch: 6| Step: 10
Training loss: 1.323500156402588
Validation loss: 1.925731138516498

Epoch: 6| Step: 11
Training loss: 1.3112945556640625
Validation loss: 1.9531421379376483

Epoch: 6| Step: 12
Training loss: 1.110243797302246
Validation loss: 1.9435261628961051

Epoch: 6| Step: 13
Training loss: 1.8144209384918213
Validation loss: 1.9307560638714862

Epoch: 198| Step: 0
Training loss: 1.6984550952911377
Validation loss: 1.9638148456491449

Epoch: 6| Step: 1
Training loss: 1.3393985033035278
Validation loss: 1.9753993941891579

Epoch: 6| Step: 2
Training loss: 1.453031063079834
Validation loss: 1.9682352786423059

Epoch: 6| Step: 3
Training loss: 1.2646174430847168
Validation loss: 1.9792939039968676

Epoch: 6| Step: 4
Training loss: 1.5790945291519165
Validation loss: 2.0052172753118698

Epoch: 6| Step: 5
Training loss: 1.4904067516326904
Validation loss: 2.0022592467646443

Epoch: 6| Step: 6
Training loss: 2.2228379249572754
Validation loss: 1.998511791229248

Epoch: 6| Step: 7
Training loss: 2.2391350269317627
Validation loss: 1.9929512264908

Epoch: 6| Step: 8
Training loss: 1.562182068824768
Validation loss: 1.9677529027385097

Epoch: 6| Step: 9
Training loss: 1.9920567274093628
Validation loss: 1.970857112638412

Epoch: 6| Step: 10
Training loss: 1.5237480401992798
Validation loss: 1.991525016805177

Epoch: 6| Step: 11
Training loss: 1.253474473953247
Validation loss: 2.026008818739204

Epoch: 6| Step: 12
Training loss: 1.0866515636444092
Validation loss: 2.0416052072278914

Epoch: 6| Step: 13
Training loss: 2.153529167175293
Validation loss: 2.0659931782753236

Epoch: 199| Step: 0
Training loss: 1.2222503423690796
Validation loss: 2.070815460656279

Epoch: 6| Step: 1
Training loss: 1.740860939025879
Validation loss: 2.0530735087651077

Epoch: 6| Step: 2
Training loss: 1.5031392574310303
Validation loss: 1.9827165719001525

Epoch: 6| Step: 3
Training loss: 1.7443076372146606
Validation loss: 1.9492025067729335

Epoch: 6| Step: 4
Training loss: 1.6551775932312012
Validation loss: 1.9659271893962738

Epoch: 6| Step: 5
Training loss: 2.1323628425598145
Validation loss: 1.9611943896098802

Epoch: 6| Step: 6
Training loss: 1.6667957305908203
Validation loss: 1.9658569802520096

Epoch: 6| Step: 7
Training loss: 1.7491614818572998
Validation loss: 1.959915712315549

Epoch: 6| Step: 8
Training loss: 1.9959681034088135
Validation loss: 1.973219948430215

Epoch: 6| Step: 9
Training loss: 1.8524377346038818
Validation loss: 1.9767675092143397

Epoch: 6| Step: 10
Training loss: 1.326009750366211
Validation loss: 1.9998602239034509

Epoch: 6| Step: 11
Training loss: 1.8506548404693604
Validation loss: 2.0066170000260874

Epoch: 6| Step: 12
Training loss: 1.5825364589691162
Validation loss: 2.042149007961314

Epoch: 6| Step: 13
Training loss: 1.3756901025772095
Validation loss: 2.0600807102777625

Epoch: 200| Step: 0
Training loss: 1.6106812953948975
Validation loss: 2.0135632638008363

Epoch: 6| Step: 1
Training loss: 1.6632051467895508
Validation loss: 1.9941446191521102

Epoch: 6| Step: 2
Training loss: 1.703879952430725
Validation loss: 1.9821981922272713

Epoch: 6| Step: 3
Training loss: 1.881957769393921
Validation loss: 1.9656816554325882

Epoch: 6| Step: 4
Training loss: 0.829951286315918
Validation loss: 1.9911879185707337

Epoch: 6| Step: 5
Training loss: 1.6136198043823242
Validation loss: 1.9764536862732263

Epoch: 6| Step: 6
Training loss: 0.9714305400848389
Validation loss: 1.9865522064188474

Epoch: 6| Step: 7
Training loss: 1.9183815717697144
Validation loss: 1.977767385462279

Epoch: 6| Step: 8
Training loss: 1.31923246383667
Validation loss: 1.9904989170771774

Epoch: 6| Step: 9
Training loss: 1.457837462425232
Validation loss: 1.9684407711029053

Epoch: 6| Step: 10
Training loss: 2.133906841278076
Validation loss: 1.9791603921562113

Epoch: 6| Step: 11
Training loss: 2.0049819946289062
Validation loss: 1.9792623340442617

Epoch: 6| Step: 12
Training loss: 2.10107421875
Validation loss: 1.9941003399510537

Epoch: 6| Step: 13
Training loss: 1.7585387229919434
Validation loss: 1.9909931690462175

Epoch: 201| Step: 0
Training loss: 1.7414549589157104
Validation loss: 2.0123178215437036

Epoch: 6| Step: 1
Training loss: 1.0157191753387451
Validation loss: 2.0015023741670834

Epoch: 6| Step: 2
Training loss: 1.7460298538208008
Validation loss: 2.0280651072020173

Epoch: 6| Step: 3
Training loss: 1.3459386825561523
Validation loss: 2.023531916320965

Epoch: 6| Step: 4
Training loss: 1.6070036888122559
Validation loss: 1.981730648266372

Epoch: 6| Step: 5
Training loss: 1.6353790760040283
Validation loss: 1.989142374325824

Epoch: 6| Step: 6
Training loss: 1.615384578704834
Validation loss: 1.982318893555672

Epoch: 6| Step: 7
Training loss: 1.5534628629684448
Validation loss: 1.9772799168863604

Epoch: 6| Step: 8
Training loss: 1.4070069789886475
Validation loss: 1.9609329623560752

Epoch: 6| Step: 9
Training loss: 1.8457903861999512
Validation loss: 1.965464925253263

Epoch: 6| Step: 10
Training loss: 1.1659047603607178
Validation loss: 1.963195998181579

Epoch: 6| Step: 11
Training loss: 2.122405767440796
Validation loss: 1.9631731843435636

Epoch: 6| Step: 12
Training loss: 1.9176089763641357
Validation loss: 1.9521685018334338

Epoch: 6| Step: 13
Training loss: 1.266457438468933
Validation loss: 1.9449789036986649

Epoch: 202| Step: 0
Training loss: 1.4429914951324463
Validation loss: 1.933018043477048

Epoch: 6| Step: 1
Training loss: 1.4163517951965332
Validation loss: 1.9418489317740164

Epoch: 6| Step: 2
Training loss: 1.3037207126617432
Validation loss: 1.979876305467339

Epoch: 6| Step: 3
Training loss: 1.0998115539550781
Validation loss: 1.9899377938239806

Epoch: 6| Step: 4
Training loss: 2.1035592555999756
Validation loss: 1.9926857935485018

Epoch: 6| Step: 5
Training loss: 1.6888033151626587
Validation loss: 1.975849287484282

Epoch: 6| Step: 6
Training loss: 1.9523578882217407
Validation loss: 1.9990254307305941

Epoch: 6| Step: 7
Training loss: 1.1696131229400635
Validation loss: 2.0280896502156414

Epoch: 6| Step: 8
Training loss: 2.274855136871338
Validation loss: 2.0587833145613312

Epoch: 6| Step: 9
Training loss: 1.731370210647583
Validation loss: 2.0433113357072235

Epoch: 6| Step: 10
Training loss: 1.8467392921447754
Validation loss: 2.0291456945480837

Epoch: 6| Step: 11
Training loss: 1.6532241106033325
Validation loss: 1.9804263371293263

Epoch: 6| Step: 12
Training loss: 1.5970485210418701
Validation loss: 1.9417457811294063

Epoch: 6| Step: 13
Training loss: 1.526686191558838
Validation loss: 1.9320145730049378

Epoch: 203| Step: 0
Training loss: 1.4093701839447021
Validation loss: 1.9588650567557222

Epoch: 6| Step: 1
Training loss: 0.8997768759727478
Validation loss: 1.97650025480537

Epoch: 6| Step: 2
Training loss: 1.805068016052246
Validation loss: 1.958267327277891

Epoch: 6| Step: 3
Training loss: 1.6169874668121338
Validation loss: 1.9671657290509952

Epoch: 6| Step: 4
Training loss: 1.9324774742126465
Validation loss: 1.976514607347468

Epoch: 6| Step: 5
Training loss: 1.8449467420578003
Validation loss: 1.9930755656252626

Epoch: 6| Step: 6
Training loss: 1.1212000846862793
Validation loss: 1.9886900173720492

Epoch: 6| Step: 7
Training loss: 1.655670166015625
Validation loss: 1.975011512797366

Epoch: 6| Step: 8
Training loss: 2.1109225749969482
Validation loss: 1.9563043040613974

Epoch: 6| Step: 9
Training loss: 1.5393321514129639
Validation loss: 1.9272846893597675

Epoch: 6| Step: 10
Training loss: 2.320275068283081
Validation loss: 1.929783071241071

Epoch: 6| Step: 11
Training loss: 1.8590303659439087
Validation loss: 1.9544516148105744

Epoch: 6| Step: 12
Training loss: 1.6314334869384766
Validation loss: 1.9695683371636175

Epoch: 6| Step: 13
Training loss: 1.4566137790679932
Validation loss: 1.9620472359400924

Epoch: 204| Step: 0
Training loss: 1.9905540943145752
Validation loss: 1.9727512610855924

Epoch: 6| Step: 1
Training loss: 1.675803303718567
Validation loss: 1.9494841342331262

Epoch: 6| Step: 2
Training loss: 1.2043087482452393
Validation loss: 1.958898780166462

Epoch: 6| Step: 3
Training loss: 1.7534230947494507
Validation loss: 1.974156907809678

Epoch: 6| Step: 4
Training loss: 1.7162697315216064
Validation loss: 2.0124857220598447

Epoch: 6| Step: 5
Training loss: 1.3682096004486084
Validation loss: 1.997475730475559

Epoch: 6| Step: 6
Training loss: 1.6364058256149292
Validation loss: 2.0291720564647386

Epoch: 6| Step: 7
Training loss: 1.74922513961792
Validation loss: 2.014479811473559

Epoch: 6| Step: 8
Training loss: 1.5788012742996216
Validation loss: 2.0012559108836676

Epoch: 6| Step: 9
Training loss: 1.7635200023651123
Validation loss: 1.9477790927374234

Epoch: 6| Step: 10
Training loss: 1.7150739431381226
Validation loss: 1.9516401842076292

Epoch: 6| Step: 11
Training loss: 1.3747282028198242
Validation loss: 1.9396996087925409

Epoch: 6| Step: 12
Training loss: 2.131937026977539
Validation loss: 1.94217594720984

Epoch: 6| Step: 13
Training loss: 1.386415958404541
Validation loss: 1.9538406300288376

Epoch: 205| Step: 0
Training loss: 1.13655686378479
Validation loss: 1.9445589229624758

Epoch: 6| Step: 1
Training loss: 1.7859606742858887
Validation loss: 1.9474744848025742

Epoch: 6| Step: 2
Training loss: 1.4338492155075073
Validation loss: 1.9804751411561043

Epoch: 6| Step: 3
Training loss: 1.4577126502990723
Validation loss: 1.9928498204036424

Epoch: 6| Step: 4
Training loss: 1.8360741138458252
Validation loss: 1.9815159356722267

Epoch: 6| Step: 5
Training loss: 1.4189153909683228
Validation loss: 1.9924292654119513

Epoch: 6| Step: 6
Training loss: 1.3586078882217407
Validation loss: 1.979611574962575

Epoch: 6| Step: 7
Training loss: 1.6494672298431396
Validation loss: 1.9913417805907547

Epoch: 6| Step: 8
Training loss: 1.6501504182815552
Validation loss: 1.983105408248081

Epoch: 6| Step: 9
Training loss: 0.9711050987243652
Validation loss: 1.9530738784420876

Epoch: 6| Step: 10
Training loss: 1.860055685043335
Validation loss: 1.9426679559933242

Epoch: 6| Step: 11
Training loss: 2.131167411804199
Validation loss: 1.9482202376088789

Epoch: 6| Step: 12
Training loss: 1.600692868232727
Validation loss: 1.939128016912809

Epoch: 6| Step: 13
Training loss: 2.5122036933898926
Validation loss: 1.947236632788053

Epoch: 206| Step: 0
Training loss: 1.091675043106079
Validation loss: 1.9393164598813621

Epoch: 6| Step: 1
Training loss: 1.4305245876312256
Validation loss: 1.9570339110589796

Epoch: 6| Step: 2
Training loss: 1.2928135395050049
Validation loss: 1.9714902857298493

Epoch: 6| Step: 3
Training loss: 1.4316986799240112
Validation loss: 1.9815684454415434

Epoch: 6| Step: 4
Training loss: 1.4911071062088013
Validation loss: 1.9749227390494397

Epoch: 6| Step: 5
Training loss: 1.6744329929351807
Validation loss: 1.9629569143377326

Epoch: 6| Step: 6
Training loss: 1.6201303005218506
Validation loss: 1.9793493286255868

Epoch: 6| Step: 7
Training loss: 1.6186494827270508
Validation loss: 2.0000991718743437

Epoch: 6| Step: 8
Training loss: 2.1673340797424316
Validation loss: 2.0286690752993346

Epoch: 6| Step: 9
Training loss: 1.418639063835144
Validation loss: 2.020758016135103

Epoch: 6| Step: 10
Training loss: 2.5653584003448486
Validation loss: 1.9913197717358988

Epoch: 6| Step: 11
Training loss: 1.2101457118988037
Validation loss: 1.9533421839437177

Epoch: 6| Step: 12
Training loss: 1.2776434421539307
Validation loss: 1.9452452249424432

Epoch: 6| Step: 13
Training loss: 1.3842201232910156
Validation loss: 1.9489796302651847

Epoch: 207| Step: 0
Training loss: 1.3717539310455322
Validation loss: 1.9370410493625108

Epoch: 6| Step: 1
Training loss: 1.860321283340454
Validation loss: 1.9355757967118294

Epoch: 6| Step: 2
Training loss: 1.5331554412841797
Validation loss: 1.9346959860094133

Epoch: 6| Step: 3
Training loss: 1.7333790063858032
Validation loss: 1.9337171175146615

Epoch: 6| Step: 4
Training loss: 1.6658098697662354
Validation loss: 1.9577470748655257

Epoch: 6| Step: 5
Training loss: 1.3136224746704102
Validation loss: 1.940488092360958

Epoch: 6| Step: 6
Training loss: 1.7759218215942383
Validation loss: 1.9319184082810597

Epoch: 6| Step: 7
Training loss: 1.718069314956665
Validation loss: 1.921741198467952

Epoch: 6| Step: 8
Training loss: 1.753618597984314
Validation loss: 1.9546373390382337

Epoch: 6| Step: 9
Training loss: 1.7799265384674072
Validation loss: 1.9434279344415153

Epoch: 6| Step: 10
Training loss: 1.3944344520568848
Validation loss: 1.9527248605605094

Epoch: 6| Step: 11
Training loss: 1.8255243301391602
Validation loss: 1.960131299111151

Epoch: 6| Step: 12
Training loss: 1.5982766151428223
Validation loss: 1.9658936685131443

Epoch: 6| Step: 13
Training loss: 0.9620797634124756
Validation loss: 1.95831085020496

Epoch: 208| Step: 0
Training loss: 1.9457545280456543
Validation loss: 1.9421313693446498

Epoch: 6| Step: 1
Training loss: 1.9895336627960205
Validation loss: 1.9519710771499141

Epoch: 6| Step: 2
Training loss: 1.7844703197479248
Validation loss: 1.9618321003452424

Epoch: 6| Step: 3
Training loss: 1.1902989149093628
Validation loss: 1.959269751784622

Epoch: 6| Step: 4
Training loss: 1.4822056293487549
Validation loss: 1.9364797261453444

Epoch: 6| Step: 5
Training loss: 1.3991320133209229
Validation loss: 1.9300815161838327

Epoch: 6| Step: 6
Training loss: 1.0323165655136108
Validation loss: 1.920884475913099

Epoch: 6| Step: 7
Training loss: 1.3300213813781738
Validation loss: 1.9402531039330266

Epoch: 6| Step: 8
Training loss: 1.3857495784759521
Validation loss: 1.9512937504758117

Epoch: 6| Step: 9
Training loss: 1.7444605827331543
Validation loss: 1.9981130425648024

Epoch: 6| Step: 10
Training loss: 1.5724287033081055
Validation loss: 2.0109918117523193

Epoch: 6| Step: 11
Training loss: 1.8935734033584595
Validation loss: 1.9842168387546335

Epoch: 6| Step: 12
Training loss: 1.4776288270950317
Validation loss: 1.94680207262757

Epoch: 6| Step: 13
Training loss: 2.117479085922241
Validation loss: 1.9497505926316785

Epoch: 209| Step: 0
Training loss: 1.5908923149108887
Validation loss: 1.9449822261769285

Epoch: 6| Step: 1
Training loss: 0.6955134272575378
Validation loss: 1.9786161376583962

Epoch: 6| Step: 2
Training loss: 2.3399486541748047
Validation loss: 1.9686944882074993

Epoch: 6| Step: 3
Training loss: 1.839975118637085
Validation loss: 1.9872596340794717

Epoch: 6| Step: 4
Training loss: 2.70979642868042
Validation loss: 1.9721110508006106

Epoch: 6| Step: 5
Training loss: 1.2494587898254395
Validation loss: 1.9667531623635242

Epoch: 6| Step: 6
Training loss: 1.4175314903259277
Validation loss: 1.9879054766829296

Epoch: 6| Step: 7
Training loss: 1.0198357105255127
Validation loss: 1.9829074336636452

Epoch: 6| Step: 8
Training loss: 0.7095276713371277
Validation loss: 1.9961783219409246

Epoch: 6| Step: 9
Training loss: 1.7867701053619385
Validation loss: 1.9682680176150413

Epoch: 6| Step: 10
Training loss: 1.4394481182098389
Validation loss: 1.9711525722216534

Epoch: 6| Step: 11
Training loss: 1.748617172241211
Validation loss: 1.9423617368103356

Epoch: 6| Step: 12
Training loss: 1.6420011520385742
Validation loss: 1.9205164473543885

Epoch: 6| Step: 13
Training loss: 1.2313685417175293
Validation loss: 1.9298248893471175

Epoch: 210| Step: 0
Training loss: 1.7303417921066284
Validation loss: 1.9292418649119716

Epoch: 6| Step: 1
Training loss: 1.6012954711914062
Validation loss: 1.9371814317600702

Epoch: 6| Step: 2
Training loss: 1.674755573272705
Validation loss: 1.967972146567478

Epoch: 6| Step: 3
Training loss: 1.9502384662628174
Validation loss: 1.991109691640382

Epoch: 6| Step: 4
Training loss: 1.7502381801605225
Validation loss: 1.956374563196654

Epoch: 6| Step: 5
Training loss: 1.7491183280944824
Validation loss: 1.9213829425073439

Epoch: 6| Step: 6
Training loss: 0.953376054763794
Validation loss: 1.9081758222272318

Epoch: 6| Step: 7
Training loss: 1.2556613683700562
Validation loss: 1.9174386852531022

Epoch: 6| Step: 8
Training loss: 2.310739040374756
Validation loss: 1.9288878222947479

Epoch: 6| Step: 9
Training loss: 1.1759780645370483
Validation loss: 1.8890470227887552

Epoch: 6| Step: 10
Training loss: 1.400390625
Validation loss: 1.9000230796875492

Epoch: 6| Step: 11
Training loss: 1.8480079174041748
Validation loss: 1.8935165969274377

Epoch: 6| Step: 12
Training loss: 1.2304966449737549
Validation loss: 1.9005824955560828

Epoch: 6| Step: 13
Training loss: 1.082384705543518
Validation loss: 1.9248282755574873

Epoch: 211| Step: 0
Training loss: 2.166245222091675
Validation loss: 1.9388300090707757

Epoch: 6| Step: 1
Training loss: 1.279072880744934
Validation loss: 1.9611330775804416

Epoch: 6| Step: 2
Training loss: 1.2703571319580078
Validation loss: 1.9756172241703156

Epoch: 6| Step: 3
Training loss: 1.843289852142334
Validation loss: 2.0041902962551323

Epoch: 6| Step: 4
Training loss: 0.9842448234558105
Validation loss: 1.9703107277552288

Epoch: 6| Step: 5
Training loss: 1.526132583618164
Validation loss: 1.9790449373183712

Epoch: 6| Step: 6
Training loss: 1.548037052154541
Validation loss: 1.9354334544110041

Epoch: 6| Step: 7
Training loss: 1.542658805847168
Validation loss: 1.9242292937412058

Epoch: 6| Step: 8
Training loss: 1.2680466175079346
Validation loss: 1.9085871199125886

Epoch: 6| Step: 9
Training loss: 1.6994681358337402
Validation loss: 1.9181923430453065

Epoch: 6| Step: 10
Training loss: 0.9210072159767151
Validation loss: 1.9107931480612805

Epoch: 6| Step: 11
Training loss: 1.4139777421951294
Validation loss: 1.922072918184342

Epoch: 6| Step: 12
Training loss: 2.698042631149292
Validation loss: 1.924167602292953

Epoch: 6| Step: 13
Training loss: 1.1757395267486572
Validation loss: 1.9416415140192995

Epoch: 212| Step: 0
Training loss: 1.7574870586395264
Validation loss: 1.9705818160887687

Epoch: 6| Step: 1
Training loss: 0.9330685138702393
Validation loss: 1.978038159749841

Epoch: 6| Step: 2
Training loss: 1.2350704669952393
Validation loss: 1.96732497215271

Epoch: 6| Step: 3
Training loss: 1.7505282163619995
Validation loss: 1.956097331098331

Epoch: 6| Step: 4
Training loss: 1.4353041648864746
Validation loss: 1.929751496161184

Epoch: 6| Step: 5
Training loss: 1.144300937652588
Validation loss: 1.9164022630260837

Epoch: 6| Step: 6
Training loss: 1.196159839630127
Validation loss: 1.907735845094086

Epoch: 6| Step: 7
Training loss: 1.0837030410766602
Validation loss: 1.8900264206752981

Epoch: 6| Step: 8
Training loss: 1.9246129989624023
Validation loss: 1.9280706349239554

Epoch: 6| Step: 9
Training loss: 2.055887222290039
Validation loss: 1.9130024679245488

Epoch: 6| Step: 10
Training loss: 2.5729689598083496
Validation loss: 1.9387534805523452

Epoch: 6| Step: 11
Training loss: 1.7573598623275757
Validation loss: 1.9573690199082898

Epoch: 6| Step: 12
Training loss: 1.029553771018982
Validation loss: 1.925556331552485

Epoch: 6| Step: 13
Training loss: 0.7669211030006409
Validation loss: 1.9277740447751937

Epoch: 213| Step: 0
Training loss: 1.2571669816970825
Validation loss: 1.9480664294253114

Epoch: 6| Step: 1
Training loss: 2.101346969604492
Validation loss: 1.9359633807213075

Epoch: 6| Step: 2
Training loss: 1.3847126960754395
Validation loss: 1.9371375550505936

Epoch: 6| Step: 3
Training loss: 1.3130537271499634
Validation loss: 1.9362608848079559

Epoch: 6| Step: 4
Training loss: 1.2799484729766846
Validation loss: 1.9220347660844044

Epoch: 6| Step: 5
Training loss: 1.876702904701233
Validation loss: 1.9212831822774743

Epoch: 6| Step: 6
Training loss: 1.8553199768066406
Validation loss: 1.913857436949207

Epoch: 6| Step: 7
Training loss: 1.7590657472610474
Validation loss: 1.9234329397960375

Epoch: 6| Step: 8
Training loss: 1.180739164352417
Validation loss: 1.9432732917929207

Epoch: 6| Step: 9
Training loss: 1.6994423866271973
Validation loss: 1.935757726751348

Epoch: 6| Step: 10
Training loss: 1.2406775951385498
Validation loss: 1.9342847165241037

Epoch: 6| Step: 11
Training loss: 1.0983048677444458
Validation loss: 1.94718240281587

Epoch: 6| Step: 12
Training loss: 0.9200869798660278
Validation loss: 1.94611148424046

Epoch: 6| Step: 13
Training loss: 1.5966243743896484
Validation loss: 1.929491425073275

Epoch: 214| Step: 0
Training loss: 1.5071181058883667
Validation loss: 1.9192470978665095

Epoch: 6| Step: 1
Training loss: 1.3905531167984009
Validation loss: 1.9171360026123703

Epoch: 6| Step: 2
Training loss: 1.7128876447677612
Validation loss: 1.915876534677321

Epoch: 6| Step: 3
Training loss: 1.327280044555664
Validation loss: 1.9241266583883634

Epoch: 6| Step: 4
Training loss: 1.9823977947235107
Validation loss: 1.9370028562443231

Epoch: 6| Step: 5
Training loss: 1.9063009023666382
Validation loss: 1.9237170629603888

Epoch: 6| Step: 6
Training loss: 1.0807304382324219
Validation loss: 1.9644544919331868

Epoch: 6| Step: 7
Training loss: 1.2047616243362427
Validation loss: 2.009955885589764

Epoch: 6| Step: 8
Training loss: 1.058675765991211
Validation loss: 2.006635673584477

Epoch: 6| Step: 9
Training loss: 1.6074353456497192
Validation loss: 1.9788726170857747

Epoch: 6| Step: 10
Training loss: 1.4583674669265747
Validation loss: 1.9767170131847422

Epoch: 6| Step: 11
Training loss: 1.4943222999572754
Validation loss: 1.941252129052275

Epoch: 6| Step: 12
Training loss: 1.0370668172836304
Validation loss: 1.9036817114840272

Epoch: 6| Step: 13
Training loss: 2.039158821105957
Validation loss: 1.8727606983594998

Epoch: 215| Step: 0
Training loss: 1.6340539455413818
Validation loss: 1.8681690462173954

Epoch: 6| Step: 1
Training loss: 1.3801413774490356
Validation loss: 1.8431294695023568

Epoch: 6| Step: 2
Training loss: 1.5318129062652588
Validation loss: 1.8595186600121119

Epoch: 6| Step: 3
Training loss: 1.32658052444458
Validation loss: 1.855657345505171

Epoch: 6| Step: 4
Training loss: 1.3366641998291016
Validation loss: 1.88359958382063

Epoch: 6| Step: 5
Training loss: 1.5224934816360474
Validation loss: 1.9192248467476136

Epoch: 6| Step: 6
Training loss: 1.5924042463302612
Validation loss: 1.9560553643011278

Epoch: 6| Step: 7
Training loss: 1.8047876358032227
Validation loss: 1.9350792284934752

Epoch: 6| Step: 8
Training loss: 1.4273755550384521
Validation loss: 1.913904277227258

Epoch: 6| Step: 9
Training loss: 1.2502175569534302
Validation loss: 1.8870745243564728

Epoch: 6| Step: 10
Training loss: 2.138925313949585
Validation loss: 1.8800027575544132

Epoch: 6| Step: 11
Training loss: 1.0279396772384644
Validation loss: 1.8939801364816644

Epoch: 6| Step: 12
Training loss: 1.7454028129577637
Validation loss: 1.8688920582494428

Epoch: 6| Step: 13
Training loss: 1.0939934253692627
Validation loss: 1.8789007086907663

Epoch: 216| Step: 0
Training loss: 1.0854685306549072
Validation loss: 1.8847741414141912

Epoch: 6| Step: 1
Training loss: 2.024763584136963
Validation loss: 1.9068747643501527

Epoch: 6| Step: 2
Training loss: 1.9188435077667236
Validation loss: 1.9238877655357443

Epoch: 6| Step: 3
Training loss: 1.090334415435791
Validation loss: 1.9292072531997517

Epoch: 6| Step: 4
Training loss: 1.7166777849197388
Validation loss: 1.8879151011026034

Epoch: 6| Step: 5
Training loss: 1.0261967182159424
Validation loss: 1.8949887829442178

Epoch: 6| Step: 6
Training loss: 1.3888249397277832
Validation loss: 1.8910653950065694

Epoch: 6| Step: 7
Training loss: 2.1901824474334717
Validation loss: 1.8886256230774747

Epoch: 6| Step: 8
Training loss: 0.6785540580749512
Validation loss: 1.8994999367703673

Epoch: 6| Step: 9
Training loss: 1.3414852619171143
Validation loss: 1.9024816482297835

Epoch: 6| Step: 10
Training loss: 1.328221321105957
Validation loss: 1.9098114646891111

Epoch: 6| Step: 11
Training loss: 1.9732149839401245
Validation loss: 1.9071149659413162

Epoch: 6| Step: 12
Training loss: 1.4328161478042603
Validation loss: 1.9477962511841969

Epoch: 6| Step: 13
Training loss: 0.9705896377563477
Validation loss: 1.9435006213444534

Epoch: 217| Step: 0
Training loss: 1.4985387325286865
Validation loss: 2.001950971541866

Epoch: 6| Step: 1
Training loss: 1.192895531654358
Validation loss: 2.032876432582896

Epoch: 6| Step: 2
Training loss: 1.8615754842758179
Validation loss: 2.0247012235785045

Epoch: 6| Step: 3
Training loss: 1.4692840576171875
Validation loss: 1.9788264036178589

Epoch: 6| Step: 4
Training loss: 0.890555739402771
Validation loss: 1.9211835720205819

Epoch: 6| Step: 5
Training loss: 1.7832636833190918
Validation loss: 1.9090051561273553

Epoch: 6| Step: 6
Training loss: 1.858350157737732
Validation loss: 1.9131507668443906

Epoch: 6| Step: 7
Training loss: 1.7348403930664062
Validation loss: 1.9095777080905052

Epoch: 6| Step: 8
Training loss: 1.4217344522476196
Validation loss: 1.904673175145221

Epoch: 6| Step: 9
Training loss: 1.0079400539398193
Validation loss: 1.9162962705858293

Epoch: 6| Step: 10
Training loss: 1.475594401359558
Validation loss: 1.8933300484893143

Epoch: 6| Step: 11
Training loss: 1.356570839881897
Validation loss: 1.9073869976946103

Epoch: 6| Step: 12
Training loss: 1.5094329118728638
Validation loss: 1.8855448615166448

Epoch: 6| Step: 13
Training loss: 1.06524658203125
Validation loss: 1.9307948453451997

Epoch: 218| Step: 0
Training loss: 1.286056637763977
Validation loss: 1.9689225458329724

Epoch: 6| Step: 1
Training loss: 1.2493939399719238
Validation loss: 2.0387618605808546

Epoch: 6| Step: 2
Training loss: 2.3024797439575195
Validation loss: 1.9875761924251434

Epoch: 6| Step: 3
Training loss: 1.5486810207366943
Validation loss: 1.985762769176114

Epoch: 6| Step: 4
Training loss: 1.1687783002853394
Validation loss: 1.9453591390322613

Epoch: 6| Step: 5
Training loss: 1.1415605545043945
Validation loss: 1.908244832869499

Epoch: 6| Step: 6
Training loss: 1.6348545551300049
Validation loss: 1.9095947960371613

Epoch: 6| Step: 7
Training loss: 1.6873900890350342
Validation loss: 1.8969267914372105

Epoch: 6| Step: 8
Training loss: 1.2597159147262573
Validation loss: 1.910290289950627

Epoch: 6| Step: 9
Training loss: 1.3895173072814941
Validation loss: 1.9101365984127086

Epoch: 6| Step: 10
Training loss: 1.9930505752563477
Validation loss: 1.9200393089684107

Epoch: 6| Step: 11
Training loss: 1.1029503345489502
Validation loss: 1.9193876776643979

Epoch: 6| Step: 12
Training loss: 0.8501263856887817
Validation loss: 1.9163799824253205

Epoch: 6| Step: 13
Training loss: 1.3721555471420288
Validation loss: 1.9322874033322899

Epoch: 219| Step: 0
Training loss: 1.501473069190979
Validation loss: 1.9603571763602636

Epoch: 6| Step: 1
Training loss: 1.1624016761779785
Validation loss: 1.9760873599718976

Epoch: 6| Step: 2
Training loss: 1.6420974731445312
Validation loss: 1.9950149341296124

Epoch: 6| Step: 3
Training loss: 2.0251564979553223
Validation loss: 1.969193507266301

Epoch: 6| Step: 4
Training loss: 1.8896949291229248
Validation loss: 1.9588198918168263

Epoch: 6| Step: 5
Training loss: 0.7134717702865601
Validation loss: 1.923342139490189

Epoch: 6| Step: 6
Training loss: 1.2296288013458252
Validation loss: 1.8897084664273005

Epoch: 6| Step: 7
Training loss: 1.6250293254852295
Validation loss: 1.8781201160082253

Epoch: 6| Step: 8
Training loss: 1.0929005146026611
Validation loss: 1.9062081178029378

Epoch: 6| Step: 9
Training loss: 1.5663577318191528
Validation loss: 1.8978378029279812

Epoch: 6| Step: 10
Training loss: 1.020031452178955
Validation loss: 1.9176342897517706

Epoch: 6| Step: 11
Training loss: 1.5464725494384766
Validation loss: 1.9296276518093642

Epoch: 6| Step: 12
Training loss: 2.151445150375366
Validation loss: 1.9562437175422587

Epoch: 6| Step: 13
Training loss: 0.6303769946098328
Validation loss: 1.9577137475372643

Epoch: 220| Step: 0
Training loss: 0.9633148908615112
Validation loss: 1.9354559298484557

Epoch: 6| Step: 1
Training loss: 1.9243803024291992
Validation loss: 1.9042737689069522

Epoch: 6| Step: 2
Training loss: 1.213169813156128
Validation loss: 1.9061736035090622

Epoch: 6| Step: 3
Training loss: 1.9610694646835327
Validation loss: 1.8827215779212214

Epoch: 6| Step: 4
Training loss: 1.0289840698242188
Validation loss: 1.8749512446823942

Epoch: 6| Step: 5
Training loss: 1.685745120048523
Validation loss: 1.8530296548720329

Epoch: 6| Step: 6
Training loss: 1.538618564605713
Validation loss: 1.8791592556943175

Epoch: 6| Step: 7
Training loss: 0.9635955691337585
Validation loss: 1.8780269494620703

Epoch: 6| Step: 8
Training loss: 1.4380677938461304
Validation loss: 1.8650285108115083

Epoch: 6| Step: 9
Training loss: 1.0237561464309692
Validation loss: 1.8732546862735544

Epoch: 6| Step: 10
Training loss: 1.2017486095428467
Validation loss: 1.857784302003922

Epoch: 6| Step: 11
Training loss: 1.5441986322402954
Validation loss: 1.9057750368631015

Epoch: 6| Step: 12
Training loss: 1.5859923362731934
Validation loss: 1.937938162075576

Epoch: 6| Step: 13
Training loss: 2.0499961376190186
Validation loss: 1.9926053400962584

Epoch: 221| Step: 0
Training loss: 1.8411165475845337
Validation loss: 1.9844497929337204

Epoch: 6| Step: 1
Training loss: 1.5094767808914185
Validation loss: 1.9806493405372865

Epoch: 6| Step: 2
Training loss: 1.351170539855957
Validation loss: 1.938754916191101

Epoch: 6| Step: 3
Training loss: 1.0258383750915527
Validation loss: 1.9240287170615247

Epoch: 6| Step: 4
Training loss: 0.7755277156829834
Validation loss: 1.8760818819845877

Epoch: 6| Step: 5
Training loss: 1.4486634731292725
Validation loss: 1.9022514435552782

Epoch: 6| Step: 6
Training loss: 1.4424887895584106
Validation loss: 1.9175014752213673

Epoch: 6| Step: 7
Training loss: 1.7159113883972168
Validation loss: 1.8926483918261785

Epoch: 6| Step: 8
Training loss: 1.1212778091430664
Validation loss: 1.9050451363286665

Epoch: 6| Step: 9
Training loss: 1.3442261219024658
Validation loss: 1.898717398284584

Epoch: 6| Step: 10
Training loss: 0.9501394629478455
Validation loss: 1.8999917122625536

Epoch: 6| Step: 11
Training loss: 1.945009469985962
Validation loss: 1.8996987483834709

Epoch: 6| Step: 12
Training loss: 1.440584659576416
Validation loss: 1.9094799872367614

Epoch: 6| Step: 13
Training loss: 2.0455822944641113
Validation loss: 1.8900956748634257

Epoch: 222| Step: 0
Training loss: 1.3379756212234497
Validation loss: 1.8840336799621582

Epoch: 6| Step: 1
Training loss: 1.5156612396240234
Validation loss: 1.8674349413123181

Epoch: 6| Step: 2
Training loss: 0.9753632545471191
Validation loss: 1.8752823670705159

Epoch: 6| Step: 3
Training loss: 1.2932935953140259
Validation loss: 1.8933232356143255

Epoch: 6| Step: 4
Training loss: 1.9516205787658691
Validation loss: 1.9154252352253083

Epoch: 6| Step: 5
Training loss: 1.610318899154663
Validation loss: 1.9262504577636719

Epoch: 6| Step: 6
Training loss: 1.526984691619873
Validation loss: 1.9370541559752597

Epoch: 6| Step: 7
Training loss: 1.0023086071014404
Validation loss: 1.9337281193784488

Epoch: 6| Step: 8
Training loss: 1.3074426651000977
Validation loss: 1.9205203440881544

Epoch: 6| Step: 9
Training loss: 1.34505033493042
Validation loss: 1.8935026776406072

Epoch: 6| Step: 10
Training loss: 0.8125675916671753
Validation loss: 1.9160158813640635

Epoch: 6| Step: 11
Training loss: 1.8479442596435547
Validation loss: 1.8998125073730305

Epoch: 6| Step: 12
Training loss: 1.1094359159469604
Validation loss: 1.8834587886769285

Epoch: 6| Step: 13
Training loss: 1.810201644897461
Validation loss: 1.9155684799276373

Epoch: 223| Step: 0
Training loss: 1.1960692405700684
Validation loss: 1.897876352392217

Epoch: 6| Step: 1
Training loss: 1.1611104011535645
Validation loss: 1.9129357748134161

Epoch: 6| Step: 2
Training loss: 0.7513723373413086
Validation loss: 1.9462001105790496

Epoch: 6| Step: 3
Training loss: 1.2741611003875732
Validation loss: 1.9507653713226318

Epoch: 6| Step: 4
Training loss: 1.6796166896820068
Validation loss: 1.9288586032006048

Epoch: 6| Step: 5
Training loss: 1.1900513172149658
Validation loss: 1.9240739037913661

Epoch: 6| Step: 6
Training loss: 1.1838700771331787
Validation loss: 1.939151870307102

Epoch: 6| Step: 7
Training loss: 1.4426684379577637
Validation loss: 1.9285277320492653

Epoch: 6| Step: 8
Training loss: 1.4414746761322021
Validation loss: 1.9108125317481257

Epoch: 6| Step: 9
Training loss: 1.085187315940857
Validation loss: 1.916281170742486

Epoch: 6| Step: 10
Training loss: 1.7718398571014404
Validation loss: 1.9067587955023653

Epoch: 6| Step: 11
Training loss: 1.492801547050476
Validation loss: 1.8903231774607012

Epoch: 6| Step: 12
Training loss: 1.8719942569732666
Validation loss: 1.8613457551566504

Epoch: 6| Step: 13
Training loss: 1.3962483406066895
Validation loss: 1.8654871115120508

Epoch: 224| Step: 0
Training loss: 1.3632971048355103
Validation loss: 1.8635276209923528

Epoch: 6| Step: 1
Training loss: 1.36183500289917
Validation loss: 1.8597089962292743

Epoch: 6| Step: 2
Training loss: 1.067494511604309
Validation loss: 1.8676171430977442

Epoch: 6| Step: 3
Training loss: 0.7747472524642944
Validation loss: 1.8778618497233237

Epoch: 6| Step: 4
Training loss: 1.3514301776885986
Validation loss: 1.916704144529117

Epoch: 6| Step: 5
Training loss: 1.159966230392456
Validation loss: 1.9254327435647287

Epoch: 6| Step: 6
Training loss: 1.6176565885543823
Validation loss: 1.9193683542231077

Epoch: 6| Step: 7
Training loss: 2.023407220840454
Validation loss: 1.9304408360553045

Epoch: 6| Step: 8
Training loss: 1.240473985671997
Validation loss: 1.939669120696283

Epoch: 6| Step: 9
Training loss: 0.9194002747535706
Validation loss: 1.9380505213173487

Epoch: 6| Step: 10
Training loss: 1.3325262069702148
Validation loss: 1.8983177908005253

Epoch: 6| Step: 11
Training loss: 1.367082118988037
Validation loss: 1.9159430175699212

Epoch: 6| Step: 12
Training loss: 1.639459490776062
Validation loss: 1.9218107487565728

Epoch: 6| Step: 13
Training loss: 1.4681636095046997
Validation loss: 1.9021906839903964

Epoch: 225| Step: 0
Training loss: 0.8381808400154114
Validation loss: 1.9290585979338615

Epoch: 6| Step: 1
Training loss: 1.3152518272399902
Validation loss: 1.9059379254617999

Epoch: 6| Step: 2
Training loss: 1.3000812530517578
Validation loss: 1.9015576172900457

Epoch: 6| Step: 3
Training loss: 1.3336539268493652
Validation loss: 1.896051770897322

Epoch: 6| Step: 4
Training loss: 1.9777107238769531
Validation loss: 1.89564012968412

Epoch: 6| Step: 5
Training loss: 1.3488552570343018
Validation loss: 1.8830768985133017

Epoch: 6| Step: 6
Training loss: 0.6068322658538818
Validation loss: 1.8961395089344313

Epoch: 6| Step: 7
Training loss: 1.9784773588180542
Validation loss: 1.9444051481062365

Epoch: 6| Step: 8
Training loss: 1.2654919624328613
Validation loss: 1.9639350829585906

Epoch: 6| Step: 9
Training loss: 0.8557837009429932
Validation loss: 1.9737500067680114

Epoch: 6| Step: 10
Training loss: 1.285662293434143
Validation loss: 1.947809216796711

Epoch: 6| Step: 11
Training loss: 1.6582491397857666
Validation loss: 1.9567749397729033

Epoch: 6| Step: 12
Training loss: 1.2023993730545044
Validation loss: 1.9131247766556279

Epoch: 6| Step: 13
Training loss: 1.4520471096038818
Validation loss: 1.89203215670842

Epoch: 226| Step: 0
Training loss: 2.0801219940185547
Validation loss: 1.9141280907456593

Epoch: 6| Step: 1
Training loss: 1.988887906074524
Validation loss: 1.9151682469152636

Epoch: 6| Step: 2
Training loss: 1.0988653898239136
Validation loss: 1.908423380185199

Epoch: 6| Step: 3
Training loss: 1.262350082397461
Validation loss: 1.896103109082868

Epoch: 6| Step: 4
Training loss: 1.0869462490081787
Validation loss: 1.8829440993647422

Epoch: 6| Step: 5
Training loss: 1.1287380456924438
Validation loss: 1.8974936828818372

Epoch: 6| Step: 6
Training loss: 1.2898776531219482
Validation loss: 1.9048730199055006

Epoch: 6| Step: 7
Training loss: 1.1840764284133911
Validation loss: 1.9223431182164017

Epoch: 6| Step: 8
Training loss: 1.2222241163253784
Validation loss: 1.9451214113543112

Epoch: 6| Step: 9
Training loss: 1.3202283382415771
Validation loss: 1.9635091520124865

Epoch: 6| Step: 10
Training loss: 0.726218581199646
Validation loss: 1.9410510575899513

Epoch: 6| Step: 11
Training loss: 1.4557921886444092
Validation loss: 1.9354167984377952

Epoch: 6| Step: 12
Training loss: 1.1729934215545654
Validation loss: 1.8938073137755036

Epoch: 6| Step: 13
Training loss: 0.9644317626953125
Validation loss: 1.8893099177268244

Epoch: 227| Step: 0
Training loss: 0.6728272438049316
Validation loss: 1.8589927099084342

Epoch: 6| Step: 1
Training loss: 1.4846062660217285
Validation loss: 1.8654792411352998

Epoch: 6| Step: 2
Training loss: 1.5137028694152832
Validation loss: 1.8525774914731261

Epoch: 6| Step: 3
Training loss: 1.2651152610778809
Validation loss: 1.8677019226935603

Epoch: 6| Step: 4
Training loss: 1.1823506355285645
Validation loss: 1.8945700686465028

Epoch: 6| Step: 5
Training loss: 1.3795207738876343
Validation loss: 1.928306015588904

Epoch: 6| Step: 6
Training loss: 1.7138258218765259
Validation loss: 1.9444197236850698

Epoch: 6| Step: 7
Training loss: 0.9980084896087646
Validation loss: 1.9600897219873243

Epoch: 6| Step: 8
Training loss: 1.6036319732666016
Validation loss: 1.958755652109782

Epoch: 6| Step: 9
Training loss: 1.30024254322052
Validation loss: 1.9371086243660218

Epoch: 6| Step: 10
Training loss: 0.9716687798500061
Validation loss: 1.9147446988731303

Epoch: 6| Step: 11
Training loss: 1.6472126245498657
Validation loss: 1.893027522230661

Epoch: 6| Step: 12
Training loss: 1.307236909866333
Validation loss: 1.8833312552462342

Epoch: 6| Step: 13
Training loss: 1.621694803237915
Validation loss: 1.8986889444371706

Epoch: 228| Step: 0
Training loss: 1.2525765895843506
Validation loss: 1.9223388036092122

Epoch: 6| Step: 1
Training loss: 1.181326150894165
Validation loss: 1.9487270360351892

Epoch: 6| Step: 2
Training loss: 1.3278063535690308
Validation loss: 2.0043541308372252

Epoch: 6| Step: 3
Training loss: 1.3756664991378784
Validation loss: 2.043089343655494

Epoch: 6| Step: 4
Training loss: 1.6138432025909424
Validation loss: 2.0198763557659682

Epoch: 6| Step: 5
Training loss: 1.338193655014038
Validation loss: 1.9619983191131263

Epoch: 6| Step: 6
Training loss: 1.4798402786254883
Validation loss: 1.911791229760775

Epoch: 6| Step: 7
Training loss: 1.546720027923584
Validation loss: 1.8812670528247792

Epoch: 6| Step: 8
Training loss: 1.3457878828048706
Validation loss: 1.8395748176882345

Epoch: 6| Step: 9
Training loss: 1.2952015399932861
Validation loss: 1.8342837005533197

Epoch: 6| Step: 10
Training loss: 1.7048698663711548
Validation loss: 1.8489195762142059

Epoch: 6| Step: 11
Training loss: 1.2298622131347656
Validation loss: 1.864537118583597

Epoch: 6| Step: 12
Training loss: 0.5460050106048584
Validation loss: 1.863503247179011

Epoch: 6| Step: 13
Training loss: 1.5261789560317993
Validation loss: 1.852348824983002

Epoch: 229| Step: 0
Training loss: 1.0204715728759766
Validation loss: 1.8987463405055385

Epoch: 6| Step: 1
Training loss: 1.0184342861175537
Validation loss: 1.9354864153810727

Epoch: 6| Step: 2
Training loss: 1.3543307781219482
Validation loss: 1.951762209656418

Epoch: 6| Step: 3
Training loss: 1.8317011594772339
Validation loss: 1.966578160562823

Epoch: 6| Step: 4
Training loss: 1.7617865800857544
Validation loss: 1.9858138356157529

Epoch: 6| Step: 5
Training loss: 1.5618364810943604
Validation loss: 1.97155539835653

Epoch: 6| Step: 6
Training loss: 0.8929458856582642
Validation loss: 1.9226017126473047

Epoch: 6| Step: 7
Training loss: 1.485002040863037
Validation loss: 1.9235576173310638

Epoch: 6| Step: 8
Training loss: 1.5118926763534546
Validation loss: 1.9252471667464062

Epoch: 6| Step: 9
Training loss: 1.3946762084960938
Validation loss: 1.9121052052385064

Epoch: 6| Step: 10
Training loss: 1.3264597654342651
Validation loss: 1.9073502197060535

Epoch: 6| Step: 11
Training loss: 1.0048283338546753
Validation loss: 1.913363246507542

Epoch: 6| Step: 12
Training loss: 0.8643560409545898
Validation loss: 1.9064013035066667

Epoch: 6| Step: 13
Training loss: 0.9353256225585938
Validation loss: 1.935875295310892

Epoch: 230| Step: 0
Training loss: 1.3280613422393799
Validation loss: 1.933685468089196

Epoch: 6| Step: 1
Training loss: 1.3217597007751465
Validation loss: 1.9619339614786127

Epoch: 6| Step: 2
Training loss: 1.5739673376083374
Validation loss: 1.9526351369837278

Epoch: 6| Step: 3
Training loss: 1.0291321277618408
Validation loss: 1.9751629701224707

Epoch: 6| Step: 4
Training loss: 1.4530160427093506
Validation loss: 1.9454408819957445

Epoch: 6| Step: 5
Training loss: 1.272935390472412
Validation loss: 1.9294937784953783

Epoch: 6| Step: 6
Training loss: 1.4873178005218506
Validation loss: 1.8689731308208999

Epoch: 6| Step: 7
Training loss: 1.0579544305801392
Validation loss: 1.864891134282594

Epoch: 6| Step: 8
Training loss: 1.0842854976654053
Validation loss: 1.8574370081706713

Epoch: 6| Step: 9
Training loss: 1.5466420650482178
Validation loss: 1.8639760043031426

Epoch: 6| Step: 10
Training loss: 1.3386428356170654
Validation loss: 1.847990366720384

Epoch: 6| Step: 11
Training loss: 1.0665063858032227
Validation loss: 1.8481017953606063

Epoch: 6| Step: 12
Training loss: 1.2493747472763062
Validation loss: 1.8830832550602574

Epoch: 6| Step: 13
Training loss: 1.1363128423690796
Validation loss: 1.9257041113350981

Epoch: 231| Step: 0
Training loss: 1.249396562576294
Validation loss: 1.9589152977030764

Epoch: 6| Step: 1
Training loss: 0.7495947480201721
Validation loss: 1.9460200212335075

Epoch: 6| Step: 2
Training loss: 1.3364145755767822
Validation loss: 1.94438874336981

Epoch: 6| Step: 3
Training loss: 1.4833478927612305
Validation loss: 1.87911743246099

Epoch: 6| Step: 4
Training loss: 1.0334447622299194
Validation loss: 1.8592512543483446

Epoch: 6| Step: 5
Training loss: 1.2583801746368408
Validation loss: 1.8528541082976966

Epoch: 6| Step: 6
Training loss: 1.0314490795135498
Validation loss: 1.8246469254134803

Epoch: 6| Step: 7
Training loss: 0.879940927028656
Validation loss: 1.8391579043480657

Epoch: 6| Step: 8
Training loss: 1.5748405456542969
Validation loss: 1.8577937105650544

Epoch: 6| Step: 9
Training loss: 1.3792345523834229
Validation loss: 1.8520740001432356

Epoch: 6| Step: 10
Training loss: 1.473050832748413
Validation loss: 1.849865355799275

Epoch: 6| Step: 11
Training loss: 1.36159086227417
Validation loss: 1.86844806004596

Epoch: 6| Step: 12
Training loss: 2.002389430999756
Validation loss: 1.8918317235926145

Epoch: 6| Step: 13
Training loss: 0.8498789072036743
Validation loss: 1.8905292941677956

Epoch: 232| Step: 0
Training loss: 1.0000908374786377
Validation loss: 1.902380927916496

Epoch: 6| Step: 1
Training loss: 1.1009800434112549
Validation loss: 1.8856205542882283

Epoch: 6| Step: 2
Training loss: 1.1343849897384644
Validation loss: 1.9207026266282605

Epoch: 6| Step: 3
Training loss: 1.1854075193405151
Validation loss: 1.9037296695093955

Epoch: 6| Step: 4
Training loss: 1.5722239017486572
Validation loss: 1.9014867838992868

Epoch: 6| Step: 5
Training loss: 0.5338819622993469
Validation loss: 1.9010985435978058

Epoch: 6| Step: 6
Training loss: 1.734834909439087
Validation loss: 1.8816046689146309

Epoch: 6| Step: 7
Training loss: 1.2840654850006104
Validation loss: 1.8959529669054094

Epoch: 6| Step: 8
Training loss: 1.311279535293579
Validation loss: 1.8763656718756563

Epoch: 6| Step: 9
Training loss: 1.3435180187225342
Validation loss: 1.873392717812651

Epoch: 6| Step: 10
Training loss: 1.2715308666229248
Validation loss: 1.9033464988072712

Epoch: 6| Step: 11
Training loss: 1.2686777114868164
Validation loss: 1.909497562275138

Epoch: 6| Step: 12
Training loss: 1.3359184265136719
Validation loss: 1.920215670780469

Epoch: 6| Step: 13
Training loss: 1.4014657735824585
Validation loss: 1.9022697056493452

Epoch: 233| Step: 0
Training loss: 1.1930937767028809
Validation loss: 1.8720434276006555

Epoch: 6| Step: 1
Training loss: 0.9470945596694946
Validation loss: 1.848588405116912

Epoch: 6| Step: 2
Training loss: 1.2281982898712158
Validation loss: 1.827599399833269

Epoch: 6| Step: 3
Training loss: 1.1757410764694214
Validation loss: 1.824121799520267

Epoch: 6| Step: 4
Training loss: 1.6634119749069214
Validation loss: 1.8409439184332406

Epoch: 6| Step: 5
Training loss: 1.4812647104263306
Validation loss: 1.8405502137317453

Epoch: 6| Step: 6
Training loss: 1.410733938217163
Validation loss: 1.8598941115922825

Epoch: 6| Step: 7
Training loss: 1.3136097192764282
Validation loss: 1.8434503886007494

Epoch: 6| Step: 8
Training loss: 1.1464587450027466
Validation loss: 1.858871054905717

Epoch: 6| Step: 9
Training loss: 0.8699074983596802
Validation loss: 1.887961015906385

Epoch: 6| Step: 10
Training loss: 1.0091809034347534
Validation loss: 1.9234275997325938

Epoch: 6| Step: 11
Training loss: 1.1659929752349854
Validation loss: 1.9209669302868586

Epoch: 6| Step: 12
Training loss: 0.9173118472099304
Validation loss: 1.908723097975536

Epoch: 6| Step: 13
Training loss: 1.4402101039886475
Validation loss: 1.8760657502758888

Epoch: 234| Step: 0
Training loss: 1.0722134113311768
Validation loss: 1.8605270142196326

Epoch: 6| Step: 1
Training loss: 1.7008509635925293
Validation loss: 1.850015224949006

Epoch: 6| Step: 2
Training loss: 0.8388038873672485
Validation loss: 1.8481152224284347

Epoch: 6| Step: 3
Training loss: 1.5213048458099365
Validation loss: 1.859536745214975

Epoch: 6| Step: 4
Training loss: 0.7655643820762634
Validation loss: 1.8880769655268679

Epoch: 6| Step: 5
Training loss: 1.4332280158996582
Validation loss: 1.8814298440051336

Epoch: 6| Step: 6
Training loss: 0.8550915122032166
Validation loss: 1.901345173517863

Epoch: 6| Step: 7
Training loss: 1.7242566347122192
Validation loss: 1.8828485960601478

Epoch: 6| Step: 8
Training loss: 0.7581027746200562
Validation loss: 1.86361107390414

Epoch: 6| Step: 9
Training loss: 0.9315887689590454
Validation loss: 1.8820874601282098

Epoch: 6| Step: 10
Training loss: 1.4660285711288452
Validation loss: 1.9000815089030931

Epoch: 6| Step: 11
Training loss: 0.8712601065635681
Validation loss: 1.8810080712841404

Epoch: 6| Step: 12
Training loss: 1.323409080505371
Validation loss: 1.8656175533930461

Epoch: 6| Step: 13
Training loss: 1.4798330068588257
Validation loss: 1.868872800180989

Epoch: 235| Step: 0
Training loss: 1.1196907758712769
Validation loss: 1.8669991672679942

Epoch: 6| Step: 1
Training loss: 0.9710105061531067
Validation loss: 1.8804578319672616

Epoch: 6| Step: 2
Training loss: 1.555948257446289
Validation loss: 1.881469157434279

Epoch: 6| Step: 3
Training loss: 1.5305516719818115
Validation loss: 1.8979043870843866

Epoch: 6| Step: 4
Training loss: 1.0714675188064575
Validation loss: 1.8897600007313553

Epoch: 6| Step: 5
Training loss: 1.1498574018478394
Validation loss: 1.8827491947399673

Epoch: 6| Step: 6
Training loss: 0.9579454660415649
Validation loss: 1.8553272626733268

Epoch: 6| Step: 7
Training loss: 0.6273369789123535
Validation loss: 1.8273268899609965

Epoch: 6| Step: 8
Training loss: 1.22675621509552
Validation loss: 1.819844263856129

Epoch: 6| Step: 9
Training loss: 0.648147702217102
Validation loss: 1.82726804671749

Epoch: 6| Step: 10
Training loss: 1.2043613195419312
Validation loss: 1.8283123867486113

Epoch: 6| Step: 11
Training loss: 1.2742478847503662
Validation loss: 1.8249741023586643

Epoch: 6| Step: 12
Training loss: 1.6297054290771484
Validation loss: 1.8244033654530842

Epoch: 6| Step: 13
Training loss: 1.1550829410552979
Validation loss: 1.8514492627113097

Epoch: 236| Step: 0
Training loss: 0.7762314081192017
Validation loss: 1.8382407029469807

Epoch: 6| Step: 1
Training loss: 0.9036256074905396
Validation loss: 1.8695070307741883

Epoch: 6| Step: 2
Training loss: 1.4777052402496338
Validation loss: 1.864730304287326

Epoch: 6| Step: 3
Training loss: 1.1757972240447998
Validation loss: 1.8747031227234872

Epoch: 6| Step: 4
Training loss: 1.3705816268920898
Validation loss: 1.892515404250032

Epoch: 6| Step: 5
Training loss: 1.3585240840911865
Validation loss: 1.8709313202929754

Epoch: 6| Step: 6
Training loss: 1.126689076423645
Validation loss: 1.8580304858505086

Epoch: 6| Step: 7
Training loss: 1.1134371757507324
Validation loss: 1.840821691738662

Epoch: 6| Step: 8
Training loss: 0.9066897630691528
Validation loss: 1.8477741979783582

Epoch: 6| Step: 9
Training loss: 1.5079268217086792
Validation loss: 1.8286652026637908

Epoch: 6| Step: 10
Training loss: 1.4937586784362793
Validation loss: 1.8383322543995355

Epoch: 6| Step: 11
Training loss: 0.8388386964797974
Validation loss: 1.8760628930984005

Epoch: 6| Step: 12
Training loss: 1.2649271488189697
Validation loss: 1.8698962209045247

Epoch: 6| Step: 13
Training loss: 0.5991595387458801
Validation loss: 1.9091223465499056

Epoch: 237| Step: 0
Training loss: 1.5979704856872559
Validation loss: 1.9004602944979103

Epoch: 6| Step: 1
Training loss: 1.3239555358886719
Validation loss: 1.8781472098442815

Epoch: 6| Step: 2
Training loss: 1.0645116567611694
Validation loss: 1.869477125906175

Epoch: 6| Step: 3
Training loss: 1.0276658535003662
Validation loss: 1.8418197862563594

Epoch: 6| Step: 4
Training loss: 0.9398858547210693
Validation loss: 1.8346234521558207

Epoch: 6| Step: 5
Training loss: 1.1768499612808228
Validation loss: 1.8329233905320526

Epoch: 6| Step: 6
Training loss: 0.9569169282913208
Validation loss: 1.8340057762720252

Epoch: 6| Step: 7
Training loss: 1.4103589057922363
Validation loss: 1.8636052954581477

Epoch: 6| Step: 8
Training loss: 1.2975789308547974
Validation loss: 1.860334316889445

Epoch: 6| Step: 9
Training loss: 0.9463523626327515
Validation loss: 1.860565157346828

Epoch: 6| Step: 10
Training loss: 1.2248345613479614
Validation loss: 1.8553733492410311

Epoch: 6| Step: 11
Training loss: 0.9715139865875244
Validation loss: 1.8413494274180422

Epoch: 6| Step: 12
Training loss: 0.9436116218566895
Validation loss: 1.839188027125533

Epoch: 6| Step: 13
Training loss: 1.2513059377670288
Validation loss: 1.8109635217215425

Epoch: 238| Step: 0
Training loss: 1.1058709621429443
Validation loss: 1.7886082292884908

Epoch: 6| Step: 1
Training loss: 1.5927555561065674
Validation loss: 1.8114427302473335

Epoch: 6| Step: 2
Training loss: 1.2172935009002686
Validation loss: 1.806430100112833

Epoch: 6| Step: 3
Training loss: 1.180978536605835
Validation loss: 1.8378266442206599

Epoch: 6| Step: 4
Training loss: 1.0556788444519043
Validation loss: 1.8747288821845927

Epoch: 6| Step: 5
Training loss: 1.0080571174621582
Validation loss: 1.904346267382304

Epoch: 6| Step: 6
Training loss: 0.9451302289962769
Validation loss: 1.898538399768132

Epoch: 6| Step: 7
Training loss: 1.7305431365966797
Validation loss: 1.9059359514585106

Epoch: 6| Step: 8
Training loss: 0.8382420539855957
Validation loss: 1.9242427169635732

Epoch: 6| Step: 9
Training loss: 0.9179473519325256
Validation loss: 1.9317991246459305

Epoch: 6| Step: 10
Training loss: 1.016944408416748
Validation loss: 1.9216179732353456

Epoch: 6| Step: 11
Training loss: 0.8120389580726624
Validation loss: 1.8799024012780958

Epoch: 6| Step: 12
Training loss: 1.5161633491516113
Validation loss: 1.869309320244738

Epoch: 6| Step: 13
Training loss: 1.384575366973877
Validation loss: 1.8437626618210987

Epoch: 239| Step: 0
Training loss: 1.0983209609985352
Validation loss: 1.8431041830329484

Epoch: 6| Step: 1
Training loss: 1.020421028137207
Validation loss: 1.8329646818099483

Epoch: 6| Step: 2
Training loss: 1.3142246007919312
Validation loss: 1.8267746048588906

Epoch: 6| Step: 3
Training loss: 1.4304063320159912
Validation loss: 1.799774823650237

Epoch: 6| Step: 4
Training loss: 0.8287225961685181
Validation loss: 1.8118371232863395

Epoch: 6| Step: 5
Training loss: 1.2392990589141846
Validation loss: 1.8336368530027327

Epoch: 6| Step: 6
Training loss: 1.1628358364105225
Validation loss: 1.8295234813485095

Epoch: 6| Step: 7
Training loss: 1.8307760953903198
Validation loss: 1.8715961479371594

Epoch: 6| Step: 8
Training loss: 0.6627674102783203
Validation loss: 1.8894370422568372

Epoch: 6| Step: 9
Training loss: 1.233931541442871
Validation loss: 1.8910939667814521

Epoch: 6| Step: 10
Training loss: 1.2184884548187256
Validation loss: 1.8643301610023744

Epoch: 6| Step: 11
Training loss: 0.8830613493919373
Validation loss: 1.8392950501493228

Epoch: 6| Step: 12
Training loss: 0.873416543006897
Validation loss: 1.8441895977143319

Epoch: 6| Step: 13
Training loss: 0.7590298652648926
Validation loss: 1.820591244646298

Epoch: 240| Step: 0
Training loss: 1.0833091735839844
Validation loss: 1.83179804202049

Epoch: 6| Step: 1
Training loss: 1.0811249017715454
Validation loss: 1.8327891980448077

Epoch: 6| Step: 2
Training loss: 1.0211304426193237
Validation loss: 1.8324436936327206

Epoch: 6| Step: 3
Training loss: 0.7574495077133179
Validation loss: 1.8504928491448844

Epoch: 6| Step: 4
Training loss: 1.314742088317871
Validation loss: 1.870112496037637

Epoch: 6| Step: 5
Training loss: 0.6336988806724548
Validation loss: 1.8523955140062558

Epoch: 6| Step: 6
Training loss: 0.8199177980422974
Validation loss: 1.8471538379628172

Epoch: 6| Step: 7
Training loss: 1.4924299716949463
Validation loss: 1.8658250429297005

Epoch: 6| Step: 8
Training loss: 1.8642113208770752
Validation loss: 1.863325777874198

Epoch: 6| Step: 9
Training loss: 1.5721142292022705
Validation loss: 1.9085865277116016

Epoch: 6| Step: 10
Training loss: 1.243504285812378
Validation loss: 1.8879133052723382

Epoch: 6| Step: 11
Training loss: 0.5170872211456299
Validation loss: 1.8618140861552248

Epoch: 6| Step: 12
Training loss: 0.8791793584823608
Validation loss: 1.8420386622028966

Epoch: 6| Step: 13
Training loss: 0.8115697503089905
Validation loss: 1.815494414298765

Epoch: 241| Step: 0
Training loss: 1.2454915046691895
Validation loss: 1.798001572649966

Epoch: 6| Step: 1
Training loss: 1.2219994068145752
Validation loss: 1.799427188852782

Epoch: 6| Step: 2
Training loss: 0.7197571992874146
Validation loss: 1.8028252368332238

Epoch: 6| Step: 3
Training loss: 0.999108612537384
Validation loss: 1.8159422759086854

Epoch: 6| Step: 4
Training loss: 1.2501652240753174
Validation loss: 1.837028157326483

Epoch: 6| Step: 5
Training loss: 0.714479386806488
Validation loss: 1.8666117704042824

Epoch: 6| Step: 6
Training loss: 1.4268910884857178
Validation loss: 1.9064088803465649

Epoch: 6| Step: 7
Training loss: 0.7239583730697632
Validation loss: 1.9128692739753312

Epoch: 6| Step: 8
Training loss: 0.9762343168258667
Validation loss: 1.8904413997486074

Epoch: 6| Step: 9
Training loss: 1.439312219619751
Validation loss: 1.8316212379804222

Epoch: 6| Step: 10
Training loss: 0.8367612361907959
Validation loss: 1.82181167346175

Epoch: 6| Step: 11
Training loss: 1.1965584754943848
Validation loss: 1.8195044122716433

Epoch: 6| Step: 12
Training loss: 1.5199410915374756
Validation loss: 1.8145782819358252

Epoch: 6| Step: 13
Training loss: 1.66553795337677
Validation loss: 1.8280980330641552

Epoch: 242| Step: 0
Training loss: 0.8494571447372437
Validation loss: 1.8354999557618172

Epoch: 6| Step: 1
Training loss: 1.0739002227783203
Validation loss: 1.889217899691674

Epoch: 6| Step: 2
Training loss: 1.0002639293670654
Validation loss: 1.8886148109230945

Epoch: 6| Step: 3
Training loss: 1.4456982612609863
Validation loss: 1.911063414747997

Epoch: 6| Step: 4
Training loss: 1.06494140625
Validation loss: 1.8938073586392146

Epoch: 6| Step: 5
Training loss: 0.9497409462928772
Validation loss: 1.8856575745408253

Epoch: 6| Step: 6
Training loss: 0.7805194854736328
Validation loss: 1.8476149138583933

Epoch: 6| Step: 7
Training loss: 0.9390090703964233
Validation loss: 1.80762892641047

Epoch: 6| Step: 8
Training loss: 0.9402577877044678
Validation loss: 1.8309913271216935

Epoch: 6| Step: 9
Training loss: 1.3579051494598389
Validation loss: 1.8249289733107372

Epoch: 6| Step: 10
Training loss: 1.062025785446167
Validation loss: 1.8314689051720403

Epoch: 6| Step: 11
Training loss: 1.4676706790924072
Validation loss: 1.8509497129788963

Epoch: 6| Step: 12
Training loss: 1.4431779384613037
Validation loss: 1.8680670671565558

Epoch: 6| Step: 13
Training loss: 0.8541958928108215
Validation loss: 1.870705953208349

Epoch: 243| Step: 0
Training loss: 1.0730013847351074
Validation loss: 1.891488508511615

Epoch: 6| Step: 1
Training loss: 0.9659961462020874
Validation loss: 1.8816244268930087

Epoch: 6| Step: 2
Training loss: 1.18190598487854
Validation loss: 1.8948577514258764

Epoch: 6| Step: 3
Training loss: 1.093544840812683
Validation loss: 1.9115525304630239

Epoch: 6| Step: 4
Training loss: 1.2966670989990234
Validation loss: 1.884842057381907

Epoch: 6| Step: 5
Training loss: 1.0581625699996948
Validation loss: 1.896841924677613

Epoch: 6| Step: 6
Training loss: 0.8924268484115601
Validation loss: 1.906313891051918

Epoch: 6| Step: 7
Training loss: 0.8858617544174194
Validation loss: 1.8823705962909165

Epoch: 6| Step: 8
Training loss: 1.002812147140503
Validation loss: 1.8731438703434442

Epoch: 6| Step: 9
Training loss: 1.205819845199585
Validation loss: 1.8683557228375507

Epoch: 6| Step: 10
Training loss: 1.2197213172912598
Validation loss: 1.8739055266944311

Epoch: 6| Step: 11
Training loss: 1.5223441123962402
Validation loss: 1.8718916626386746

Epoch: 6| Step: 12
Training loss: 0.6212087869644165
Validation loss: 1.9046845359186972

Epoch: 6| Step: 13
Training loss: 0.7586070895195007
Validation loss: 1.9130063851674397

Epoch: 244| Step: 0
Training loss: 1.2136093378067017
Validation loss: 1.9369861413073797

Epoch: 6| Step: 1
Training loss: 0.8343626856803894
Validation loss: 1.9302815365534958

Epoch: 6| Step: 2
Training loss: 1.5261261463165283
Validation loss: 1.9249695142110188

Epoch: 6| Step: 3
Training loss: 0.8078954219818115
Validation loss: 1.8824019150067401

Epoch: 6| Step: 4
Training loss: 1.8477513790130615
Validation loss: 1.8415439308330577

Epoch: 6| Step: 5
Training loss: 1.145507574081421
Validation loss: 1.824733567494218

Epoch: 6| Step: 6
Training loss: 1.0470829010009766
Validation loss: 1.80350923538208

Epoch: 6| Step: 7
Training loss: 1.4048762321472168
Validation loss: 1.8250041533541936

Epoch: 6| Step: 8
Training loss: 1.2179105281829834
Validation loss: 1.8513137781491844

Epoch: 6| Step: 9
Training loss: 0.5119812488555908
Validation loss: 1.8503193906558457

Epoch: 6| Step: 10
Training loss: 0.8393226265907288
Validation loss: 1.870941703037549

Epoch: 6| Step: 11
Training loss: 0.812239408493042
Validation loss: 1.8898045734692646

Epoch: 6| Step: 12
Training loss: 0.998837947845459
Validation loss: 1.9028702551318752

Epoch: 6| Step: 13
Training loss: 0.8920079469680786
Validation loss: 1.87887413911922

Epoch: 245| Step: 0
Training loss: 0.9397772550582886
Validation loss: 1.8596678626152776

Epoch: 6| Step: 1
Training loss: 0.9686332941055298
Validation loss: 1.8585599904419274

Epoch: 6| Step: 2
Training loss: 0.9479207992553711
Validation loss: 1.8457920628209268

Epoch: 6| Step: 3
Training loss: 0.4339905381202698
Validation loss: 1.8556560931667205

Epoch: 6| Step: 4
Training loss: 1.5256247520446777
Validation loss: 1.8537246181118874

Epoch: 6| Step: 5
Training loss: 1.0058114528656006
Validation loss: 1.8436760742177245

Epoch: 6| Step: 6
Training loss: 1.0886698961257935
Validation loss: 1.8634024871292936

Epoch: 6| Step: 7
Training loss: 1.7060514688491821
Validation loss: 1.8475247377990394

Epoch: 6| Step: 8
Training loss: 1.1706514358520508
Validation loss: 1.8639025521534744

Epoch: 6| Step: 9
Training loss: 0.8386037349700928
Validation loss: 1.9006122722420642

Epoch: 6| Step: 10
Training loss: 0.9472724199295044
Validation loss: 1.8738948939948954

Epoch: 6| Step: 11
Training loss: 1.1571400165557861
Validation loss: 1.881774825434531

Epoch: 6| Step: 12
Training loss: 1.4625353813171387
Validation loss: 1.8653897982771679

Epoch: 6| Step: 13
Training loss: 0.7464317679405212
Validation loss: 1.8499099541735906

Epoch: 246| Step: 0
Training loss: 0.9503597021102905
Validation loss: 1.8226528808634768

Epoch: 6| Step: 1
Training loss: 0.8050014972686768
Validation loss: 1.841554311013991

Epoch: 6| Step: 2
Training loss: 0.8333973288536072
Validation loss: 1.844712681667779

Epoch: 6| Step: 3
Training loss: 1.0420567989349365
Validation loss: 1.860438560926786

Epoch: 6| Step: 4
Training loss: 0.7196379899978638
Validation loss: 1.8545980632946055

Epoch: 6| Step: 5
Training loss: 1.2138721942901611
Validation loss: 1.8470394983086535

Epoch: 6| Step: 6
Training loss: 0.824627161026001
Validation loss: 1.8232426130643455

Epoch: 6| Step: 7
Training loss: 1.5734210014343262
Validation loss: 1.818811761435642

Epoch: 6| Step: 8
Training loss: 1.215145468711853
Validation loss: 1.7928940339754986

Epoch: 6| Step: 9
Training loss: 0.8969289660453796
Validation loss: 1.8093964643375848

Epoch: 6| Step: 10
Training loss: 1.0303850173950195
Validation loss: 1.7779902232590543

Epoch: 6| Step: 11
Training loss: 0.907893180847168
Validation loss: 1.8118925145877305

Epoch: 6| Step: 12
Training loss: 1.3378089666366577
Validation loss: 1.8199142768818846

Epoch: 6| Step: 13
Training loss: 1.8021833896636963
Validation loss: 1.874350627263387

Epoch: 247| Step: 0
Training loss: 1.3606808185577393
Validation loss: 1.887371326005587

Epoch: 6| Step: 1
Training loss: 0.6561294198036194
Validation loss: 1.8795055291985954

Epoch: 6| Step: 2
Training loss: 1.1296998262405396
Validation loss: 1.857560326976161

Epoch: 6| Step: 3
Training loss: 1.243760347366333
Validation loss: 1.843616129249655

Epoch: 6| Step: 4
Training loss: 1.269761085510254
Validation loss: 1.8246047548068467

Epoch: 6| Step: 5
Training loss: 0.8509392142295837
Validation loss: 1.8239274101872598

Epoch: 6| Step: 6
Training loss: 1.0242176055908203
Validation loss: 1.855085483161352

Epoch: 6| Step: 7
Training loss: 0.9630993604660034
Validation loss: 1.8988436575858825

Epoch: 6| Step: 8
Training loss: 1.2167935371398926
Validation loss: 1.9061295447811004

Epoch: 6| Step: 9
Training loss: 0.7154395580291748
Validation loss: 1.9189458060008224

Epoch: 6| Step: 10
Training loss: 0.8624743819236755
Validation loss: 1.9135035596868044

Epoch: 6| Step: 11
Training loss: 1.377220869064331
Validation loss: 1.8965924452709895

Epoch: 6| Step: 12
Training loss: 1.2242100238800049
Validation loss: 1.8832772854835755

Epoch: 6| Step: 13
Training loss: 0.5576406717300415
Validation loss: 1.8440641933871853

Epoch: 248| Step: 0
Training loss: 1.4972100257873535
Validation loss: 1.8184181567161315

Epoch: 6| Step: 1
Training loss: 1.1112133264541626
Validation loss: 1.8239717586066133

Epoch: 6| Step: 2
Training loss: 0.7556025981903076
Validation loss: 1.821180446173555

Epoch: 6| Step: 3
Training loss: 0.7969944477081299
Validation loss: 1.8248825823107073

Epoch: 6| Step: 4
Training loss: 0.9521048069000244
Validation loss: 1.8368587980988205

Epoch: 6| Step: 5
Training loss: 1.568859338760376
Validation loss: 1.8620894006503526

Epoch: 6| Step: 6
Training loss: 1.0635731220245361
Validation loss: 1.8648352443530996

Epoch: 6| Step: 7
Training loss: 1.0127472877502441
Validation loss: 1.8692447946917625

Epoch: 6| Step: 8
Training loss: 0.8952727317810059
Validation loss: 1.8675639783182452

Epoch: 6| Step: 9
Training loss: 0.8362614512443542
Validation loss: 1.84144349252024

Epoch: 6| Step: 10
Training loss: 1.0038197040557861
Validation loss: 1.854647437731425

Epoch: 6| Step: 11
Training loss: 0.8550020456314087
Validation loss: 1.8215808073679607

Epoch: 6| Step: 12
Training loss: 1.0728654861450195
Validation loss: 1.8254042697209183

Epoch: 6| Step: 13
Training loss: 0.7472081780433655
Validation loss: 1.8273001268345823

Epoch: 249| Step: 0
Training loss: 0.9123069643974304
Validation loss: 1.8278530823287142

Epoch: 6| Step: 1
Training loss: 1.2157964706420898
Validation loss: 1.8493319531922698

Epoch: 6| Step: 2
Training loss: 1.303487777709961
Validation loss: 1.8518398615621752

Epoch: 6| Step: 3
Training loss: 0.9973996877670288
Validation loss: 1.8595812115617978

Epoch: 6| Step: 4
Training loss: 1.1648203134536743
Validation loss: 1.8917819787097234

Epoch: 6| Step: 5
Training loss: 0.5523769855499268
Validation loss: 1.8707029614397275

Epoch: 6| Step: 6
Training loss: 1.018012523651123
Validation loss: 1.8508992143856582

Epoch: 6| Step: 7
Training loss: 0.8854738473892212
Validation loss: 1.883074680964152

Epoch: 6| Step: 8
Training loss: 1.095415711402893
Validation loss: 1.8765336582737584

Epoch: 6| Step: 9
Training loss: 1.089245080947876
Validation loss: 1.8661141754478536

Epoch: 6| Step: 10
Training loss: 1.6706969738006592
Validation loss: 1.8734051540333738

Epoch: 6| Step: 11
Training loss: 1.1188631057739258
Validation loss: 1.8930721218867967

Epoch: 6| Step: 12
Training loss: 0.38078540563583374
Validation loss: 1.864355948663527

Epoch: 6| Step: 13
Training loss: 0.7312983870506287
Validation loss: 1.8853426697433635

Epoch: 250| Step: 0
Training loss: 1.1797997951507568
Validation loss: 1.8569367188279347

Epoch: 6| Step: 1
Training loss: 0.9112441539764404
Validation loss: 1.8696255568535096

Epoch: 6| Step: 2
Training loss: 0.6298552751541138
Validation loss: 1.8455018215281989

Epoch: 6| Step: 3
Training loss: 1.1036734580993652
Validation loss: 1.844843642686003

Epoch: 6| Step: 4
Training loss: 1.0666106939315796
Validation loss: 1.8188462462476505

Epoch: 6| Step: 5
Training loss: 1.127846360206604
Validation loss: 1.8249760520073675

Epoch: 6| Step: 6
Training loss: 0.6702768802642822
Validation loss: 1.817483535376928

Epoch: 6| Step: 7
Training loss: 1.0583757162094116
Validation loss: 1.843384858100645

Epoch: 6| Step: 8
Training loss: 1.2273876667022705
Validation loss: 1.8484160515569872

Epoch: 6| Step: 9
Training loss: 1.0166285037994385
Validation loss: 1.843757672976422

Epoch: 6| Step: 10
Training loss: 0.8687275648117065
Validation loss: 1.8090865278756747

Epoch: 6| Step: 11
Training loss: 1.03424072265625
Validation loss: 1.8087229638971307

Epoch: 6| Step: 12
Training loss: 1.3895552158355713
Validation loss: 1.8438631052611976

Epoch: 6| Step: 13
Training loss: 0.8525838255882263
Validation loss: 1.8559691803429716

Epoch: 251| Step: 0
Training loss: 1.1244771480560303
Validation loss: 1.890024362071868

Epoch: 6| Step: 1
Training loss: 1.0988411903381348
Validation loss: 1.918946317447129

Epoch: 6| Step: 2
Training loss: 1.184464931488037
Validation loss: 1.9491487356924242

Epoch: 6| Step: 3
Training loss: 1.2423114776611328
Validation loss: 1.985661140052221

Epoch: 6| Step: 4
Training loss: 1.0435806512832642
Validation loss: 1.9244389175086893

Epoch: 6| Step: 5
Training loss: 0.7518850564956665
Validation loss: 1.87402678561467

Epoch: 6| Step: 6
Training loss: 1.153458833694458
Validation loss: 1.8685777507802492

Epoch: 6| Step: 7
Training loss: 0.8563424348831177
Validation loss: 1.8433684610551404

Epoch: 6| Step: 8
Training loss: 0.5876908302307129
Validation loss: 1.8194012257360643

Epoch: 6| Step: 9
Training loss: 1.0054821968078613
Validation loss: 1.8174598088828466

Epoch: 6| Step: 10
Training loss: 1.4318468570709229
Validation loss: 1.8386337487928328

Epoch: 6| Step: 11
Training loss: 0.9705874919891357
Validation loss: 1.8442729211622668

Epoch: 6| Step: 12
Training loss: 0.6704274415969849
Validation loss: 1.8637364167039112

Epoch: 6| Step: 13
Training loss: 1.5005567073822021
Validation loss: 1.9244569014477473

Epoch: 252| Step: 0
Training loss: 1.1083985567092896
Validation loss: 1.9265889172912927

Epoch: 6| Step: 1
Training loss: 0.7347234487533569
Validation loss: 1.9121748939637215

Epoch: 6| Step: 2
Training loss: 0.9773337841033936
Validation loss: 1.876356981133902

Epoch: 6| Step: 3
Training loss: 1.024350643157959
Validation loss: 1.8519291134290798

Epoch: 6| Step: 4
Training loss: 1.0919780731201172
Validation loss: 1.8545331506318943

Epoch: 6| Step: 5
Training loss: 1.0686994791030884
Validation loss: 1.840879476198586

Epoch: 6| Step: 6
Training loss: 1.19121515750885
Validation loss: 1.8401132181126585

Epoch: 6| Step: 7
Training loss: 1.066068410873413
Validation loss: 1.8476455391094249

Epoch: 6| Step: 8
Training loss: 0.6761573553085327
Validation loss: 1.8531995563096897

Epoch: 6| Step: 9
Training loss: 0.9447684288024902
Validation loss: 1.8506882703432472

Epoch: 6| Step: 10
Training loss: 0.8719384074211121
Validation loss: 1.8672243805341824

Epoch: 6| Step: 11
Training loss: 1.5346877574920654
Validation loss: 1.860609910821402

Epoch: 6| Step: 12
Training loss: 1.0501047372817993
Validation loss: 1.8707131596021755

Epoch: 6| Step: 13
Training loss: 0.6740436553955078
Validation loss: 1.841639261091909

Epoch: 253| Step: 0
Training loss: 0.9630489349365234
Validation loss: 1.8498354368312384

Epoch: 6| Step: 1
Training loss: 0.8057141304016113
Validation loss: 1.8362919553633659

Epoch: 6| Step: 2
Training loss: 0.8072435855865479
Validation loss: 1.8067559715240233

Epoch: 6| Step: 3
Training loss: 1.2998664379119873
Validation loss: 1.8162283935854513

Epoch: 6| Step: 4
Training loss: 0.7715283036231995
Validation loss: 1.7888768488360989

Epoch: 6| Step: 5
Training loss: 1.0089625120162964
Validation loss: 1.7978646832127725

Epoch: 6| Step: 6
Training loss: 1.261535406112671
Validation loss: 1.7964668325198594

Epoch: 6| Step: 7
Training loss: 0.7251497507095337
Validation loss: 1.7996343310161302

Epoch: 6| Step: 8
Training loss: 0.7205439805984497
Validation loss: 1.80588395877551

Epoch: 6| Step: 9
Training loss: 1.2549898624420166
Validation loss: 1.8099415327913018

Epoch: 6| Step: 10
Training loss: 1.2235805988311768
Validation loss: 1.799791674460134

Epoch: 6| Step: 11
Training loss: 0.7827712893486023
Validation loss: 1.7720880918605353

Epoch: 6| Step: 12
Training loss: 0.8069311380386353
Validation loss: 1.771739468779615

Epoch: 6| Step: 13
Training loss: 0.6759785413742065
Validation loss: 1.7561982011282316

Epoch: 254| Step: 0
Training loss: 0.9982786178588867
Validation loss: 1.8213331801916963

Epoch: 6| Step: 1
Training loss: 0.7280641794204712
Validation loss: 1.8134647928258425

Epoch: 6| Step: 2
Training loss: 1.1768550872802734
Validation loss: 1.8093082020359654

Epoch: 6| Step: 3
Training loss: 0.5452527403831482
Validation loss: 1.822874479396369

Epoch: 6| Step: 4
Training loss: 0.9858713746070862
Validation loss: 1.828917783434673

Epoch: 6| Step: 5
Training loss: 1.0074886083602905
Validation loss: 1.835828568345757

Epoch: 6| Step: 6
Training loss: 0.6327934265136719
Validation loss: 1.8614798694528558

Epoch: 6| Step: 7
Training loss: 0.5583175420761108
Validation loss: 1.8821075795799174

Epoch: 6| Step: 8
Training loss: 1.3650035858154297
Validation loss: 1.8615205441751788

Epoch: 6| Step: 9
Training loss: 1.3668208122253418
Validation loss: 1.8442667120246476

Epoch: 6| Step: 10
Training loss: 0.9867709279060364
Validation loss: 1.8304238985943537

Epoch: 6| Step: 11
Training loss: 0.8040580749511719
Validation loss: 1.7985835383015294

Epoch: 6| Step: 12
Training loss: 0.887173056602478
Validation loss: 1.8007163975828437

Epoch: 6| Step: 13
Training loss: 1.2841683626174927
Validation loss: 1.812241913169943

Epoch: 255| Step: 0
Training loss: 0.8431131839752197
Validation loss: 1.7663823750711256

Epoch: 6| Step: 1
Training loss: 0.8870396018028259
Validation loss: 1.796560723294494

Epoch: 6| Step: 2
Training loss: 0.7443088293075562
Validation loss: 1.8119860631163403

Epoch: 6| Step: 3
Training loss: 0.8855327367782593
Validation loss: 1.8105176738513413

Epoch: 6| Step: 4
Training loss: 0.8588295578956604
Validation loss: 1.8487769583220124

Epoch: 6| Step: 5
Training loss: 1.1404341459274292
Validation loss: 1.8669594334017845

Epoch: 6| Step: 6
Training loss: 1.0608134269714355
Validation loss: 1.8734018213005477

Epoch: 6| Step: 7
Training loss: 1.3832578659057617
Validation loss: 1.8507815458441292

Epoch: 6| Step: 8
Training loss: 1.1863610744476318
Validation loss: 1.8542650950852262

Epoch: 6| Step: 9
Training loss: 0.6851625442504883
Validation loss: 1.833089159381005

Epoch: 6| Step: 10
Training loss: 0.790407657623291
Validation loss: 1.8168712380111858

Epoch: 6| Step: 11
Training loss: 0.9836703538894653
Validation loss: 1.8231576360682005

Epoch: 6| Step: 12
Training loss: 0.9403100609779358
Validation loss: 1.815422801561253

Epoch: 6| Step: 13
Training loss: 0.5775226950645447
Validation loss: 1.8176321239881619

Epoch: 256| Step: 0
Training loss: 0.6636759042739868
Validation loss: 1.8164252440134685

Epoch: 6| Step: 1
Training loss: 1.5369863510131836
Validation loss: 1.8489053390359367

Epoch: 6| Step: 2
Training loss: 0.870384156703949
Validation loss: 1.8803047646758377

Epoch: 6| Step: 3
Training loss: 0.6954208612442017
Validation loss: 1.8700812478219309

Epoch: 6| Step: 4
Training loss: 0.8148036003112793
Validation loss: 1.9297306665810205

Epoch: 6| Step: 5
Training loss: 0.7627046704292297
Validation loss: 1.86430614097144

Epoch: 6| Step: 6
Training loss: 0.8498318195343018
Validation loss: 1.8532442674841931

Epoch: 6| Step: 7
Training loss: 1.1971067190170288
Validation loss: 1.8372445285961192

Epoch: 6| Step: 8
Training loss: 0.8319478631019592
Validation loss: 1.8546310342768186

Epoch: 6| Step: 9
Training loss: 1.087044596672058
Validation loss: 1.8402422910095544

Epoch: 6| Step: 10
Training loss: 1.205071210861206
Validation loss: 1.83917240301768

Epoch: 6| Step: 11
Training loss: 0.727318525314331
Validation loss: 1.8350616655042093

Epoch: 6| Step: 12
Training loss: 0.7087970972061157
Validation loss: 1.8135009299042404

Epoch: 6| Step: 13
Training loss: 0.5828787088394165
Validation loss: 1.837672757846053

Epoch: 257| Step: 0
Training loss: 1.0857276916503906
Validation loss: 1.8223097632008214

Epoch: 6| Step: 1
Training loss: 0.7735692858695984
Validation loss: 1.8058452990747267

Epoch: 6| Step: 2
Training loss: 0.4252077043056488
Validation loss: 1.7897358902039067

Epoch: 6| Step: 3
Training loss: 1.152430534362793
Validation loss: 1.8134803900154688

Epoch: 6| Step: 4
Training loss: 0.937411904335022
Validation loss: 1.8518816386499712

Epoch: 6| Step: 5
Training loss: 0.7814532518386841
Validation loss: 1.8448641018200946

Epoch: 6| Step: 6
Training loss: 1.109778642654419
Validation loss: 1.855640419067875

Epoch: 6| Step: 7
Training loss: 0.7529477477073669
Validation loss: 1.8367351690928142

Epoch: 6| Step: 8
Training loss: 0.8703246116638184
Validation loss: 1.7870185862305343

Epoch: 6| Step: 9
Training loss: 0.6640005111694336
Validation loss: 1.7611882827615226

Epoch: 6| Step: 10
Training loss: 1.526334524154663
Validation loss: 1.7824180049280967

Epoch: 6| Step: 11
Training loss: 0.8600406646728516
Validation loss: 1.7728358686611216

Epoch: 6| Step: 12
Training loss: 1.1056592464447021
Validation loss: 1.7656474728738107

Epoch: 6| Step: 13
Training loss: 0.7684584856033325
Validation loss: 1.7853648560021513

Epoch: 258| Step: 0
Training loss: 0.7153294086456299
Validation loss: 1.7981855189928444

Epoch: 6| Step: 1
Training loss: 1.0536293983459473
Validation loss: 1.8259147495351813

Epoch: 6| Step: 2
Training loss: 0.9060440063476562
Validation loss: 1.8582369114762993

Epoch: 6| Step: 3
Training loss: 0.9643818140029907
Validation loss: 1.8688487968137186

Epoch: 6| Step: 4
Training loss: 0.6443538665771484
Validation loss: 1.888870971177214

Epoch: 6| Step: 5
Training loss: 0.7179096937179565
Validation loss: 1.8849360135293776

Epoch: 6| Step: 6
Training loss: 0.760710597038269
Validation loss: 1.876529159084443

Epoch: 6| Step: 7
Training loss: 0.9159122705459595
Validation loss: 1.831747511381744

Epoch: 6| Step: 8
Training loss: 1.0898250341415405
Validation loss: 1.8584539223742742

Epoch: 6| Step: 9
Training loss: 0.9077867269515991
Validation loss: 1.8298191408957205

Epoch: 6| Step: 10
Training loss: 0.7925978302955627
Validation loss: 1.857398066469418

Epoch: 6| Step: 11
Training loss: 0.9573376178741455
Validation loss: 1.8602636873081166

Epoch: 6| Step: 12
Training loss: 1.2283759117126465
Validation loss: 1.8704473049409929

Epoch: 6| Step: 13
Training loss: 0.6342787742614746
Validation loss: 1.865265069469329

Epoch: 259| Step: 0
Training loss: 0.7431751489639282
Validation loss: 1.868357619931621

Epoch: 6| Step: 1
Training loss: 1.075580358505249
Validation loss: 1.8673665292801396

Epoch: 6| Step: 2
Training loss: 1.02101731300354
Validation loss: 1.9305144766325593

Epoch: 6| Step: 3
Training loss: 1.3632299900054932
Validation loss: 1.9267373200385802

Epoch: 6| Step: 4
Training loss: 1.1664856672286987
Validation loss: 1.8884862853634743

Epoch: 6| Step: 5
Training loss: 0.997019350528717
Validation loss: 1.8582495425337104

Epoch: 6| Step: 6
Training loss: 0.859743595123291
Validation loss: 1.8345843540724887

Epoch: 6| Step: 7
Training loss: 0.5167493224143982
Validation loss: 1.826337133684466

Epoch: 6| Step: 8
Training loss: 0.561228334903717
Validation loss: 1.8458560948730798

Epoch: 6| Step: 9
Training loss: 1.2768455743789673
Validation loss: 1.8715589943752493

Epoch: 6| Step: 10
Training loss: 0.7978278398513794
Validation loss: 1.8725619508374123

Epoch: 6| Step: 11
Training loss: 0.5710410475730896
Validation loss: 1.8620264478909072

Epoch: 6| Step: 12
Training loss: 0.6330578327178955
Validation loss: 1.8699721482492262

Epoch: 6| Step: 13
Training loss: 1.0289082527160645
Validation loss: 1.8354664066786408

Epoch: 260| Step: 0
Training loss: 1.0869131088256836
Validation loss: 1.8234762530173025

Epoch: 6| Step: 1
Training loss: 0.9812880754470825
Validation loss: 1.8087336068512292

Epoch: 6| Step: 2
Training loss: 0.7846320867538452
Validation loss: 1.8354531180474065

Epoch: 6| Step: 3
Training loss: 0.8807346820831299
Validation loss: 1.8233446203252321

Epoch: 6| Step: 4
Training loss: 1.0186457633972168
Validation loss: 1.823153676525239

Epoch: 6| Step: 5
Training loss: 1.1650481224060059
Validation loss: 1.854309546050205

Epoch: 6| Step: 6
Training loss: 0.7164716124534607
Validation loss: 1.8820893661950224

Epoch: 6| Step: 7
Training loss: 0.9466891288757324
Validation loss: 1.9294642094642884

Epoch: 6| Step: 8
Training loss: 1.2302093505859375
Validation loss: 1.9270772216140584

Epoch: 6| Step: 9
Training loss: 0.688390851020813
Validation loss: 1.9015739758809407

Epoch: 6| Step: 10
Training loss: 0.6853747367858887
Validation loss: 1.8807470260127899

Epoch: 6| Step: 11
Training loss: 0.7536877393722534
Validation loss: 1.828420405746788

Epoch: 6| Step: 12
Training loss: 0.7986304759979248
Validation loss: 1.8104993220298522

Epoch: 6| Step: 13
Training loss: 0.6661297678947449
Validation loss: 1.7992846132606588

Epoch: 261| Step: 0
Training loss: 0.6696290969848633
Validation loss: 1.7943443175285094

Epoch: 6| Step: 1
Training loss: 0.6500697731971741
Validation loss: 1.76830957910066

Epoch: 6| Step: 2
Training loss: 1.0279648303985596
Validation loss: 1.7773362218692739

Epoch: 6| Step: 3
Training loss: 1.1530050039291382
Validation loss: 1.792578366494948

Epoch: 6| Step: 4
Training loss: 0.5762013792991638
Validation loss: 1.8199007831593996

Epoch: 6| Step: 5
Training loss: 0.4993017017841339
Validation loss: 1.8103626261475265

Epoch: 6| Step: 6
Training loss: 0.8960516452789307
Validation loss: 1.8678874700300154

Epoch: 6| Step: 7
Training loss: 0.7123604416847229
Validation loss: 1.8464286775999172

Epoch: 6| Step: 8
Training loss: 0.9803518056869507
Validation loss: 1.8187592106480752

Epoch: 6| Step: 9
Training loss: 0.9006248116493225
Validation loss: 1.7935749253919047

Epoch: 6| Step: 10
Training loss: 0.6887177228927612
Validation loss: 1.7947492727669336

Epoch: 6| Step: 11
Training loss: 1.0234081745147705
Validation loss: 1.788118416263211

Epoch: 6| Step: 12
Training loss: 1.0359809398651123
Validation loss: 1.7707936956036476

Epoch: 6| Step: 13
Training loss: 2.026756763458252
Validation loss: 1.7697678304487658

Epoch: 262| Step: 0
Training loss: 0.9499106407165527
Validation loss: 1.7581168913072156

Epoch: 6| Step: 1
Training loss: 1.1117305755615234
Validation loss: 1.7996981349042667

Epoch: 6| Step: 2
Training loss: 0.9926246404647827
Validation loss: 1.8159413529980568

Epoch: 6| Step: 3
Training loss: 0.81839519739151
Validation loss: 1.8156359708437355

Epoch: 6| Step: 4
Training loss: 0.5112136006355286
Validation loss: 1.847149528482909

Epoch: 6| Step: 5
Training loss: 0.7425146102905273
Validation loss: 1.8272687799187117

Epoch: 6| Step: 6
Training loss: 1.5775158405303955
Validation loss: 1.8284640927468576

Epoch: 6| Step: 7
Training loss: 0.8139834403991699
Validation loss: 1.7956556312499508

Epoch: 6| Step: 8
Training loss: 0.7675097584724426
Validation loss: 1.8156225207031413

Epoch: 6| Step: 9
Training loss: 0.8525661826133728
Validation loss: 1.7991924978071643

Epoch: 6| Step: 10
Training loss: 0.8340149521827698
Validation loss: 1.824230351755696

Epoch: 6| Step: 11
Training loss: 0.6443910598754883
Validation loss: 1.8248237012535014

Epoch: 6| Step: 12
Training loss: 0.7867156267166138
Validation loss: 1.8538745833981423

Epoch: 6| Step: 13
Training loss: 0.5173605680465698
Validation loss: 1.8486421749156008

Epoch: 263| Step: 0
Training loss: 0.8933364748954773
Validation loss: 1.876687853567062

Epoch: 6| Step: 1
Training loss: 0.6847988367080688
Validation loss: 1.886110487804618

Epoch: 6| Step: 2
Training loss: 0.6334061026573181
Validation loss: 1.9210328543058006

Epoch: 6| Step: 3
Training loss: 1.0051331520080566
Validation loss: 1.8813858801318752

Epoch: 6| Step: 4
Training loss: 1.2121591567993164
Validation loss: 1.861179938880346

Epoch: 6| Step: 5
Training loss: 0.7730038166046143
Validation loss: 1.8486158078716648

Epoch: 6| Step: 6
Training loss: 0.6477138996124268
Validation loss: 1.8150928251204952

Epoch: 6| Step: 7
Training loss: 0.8666484951972961
Validation loss: 1.7988057674900177

Epoch: 6| Step: 8
Training loss: 1.3878915309906006
Validation loss: 1.8065915274363693

Epoch: 6| Step: 9
Training loss: 1.2054191827774048
Validation loss: 1.8280728222221456

Epoch: 6| Step: 10
Training loss: 0.6820600032806396
Validation loss: 1.8285782721734816

Epoch: 6| Step: 11
Training loss: 0.7371562719345093
Validation loss: 1.8347854627076017

Epoch: 6| Step: 12
Training loss: 0.6023792624473572
Validation loss: 1.8532128077681347

Epoch: 6| Step: 13
Training loss: 0.6845618486404419
Validation loss: 1.8427792313278362

Epoch: 264| Step: 0
Training loss: 0.7544180154800415
Validation loss: 1.8317891474693053

Epoch: 6| Step: 1
Training loss: 0.8192631006240845
Validation loss: 1.8323914043364986

Epoch: 6| Step: 2
Training loss: 0.7789207100868225
Validation loss: 1.8235824069669169

Epoch: 6| Step: 3
Training loss: 0.8488248586654663
Validation loss: 1.7863834263176046

Epoch: 6| Step: 4
Training loss: 1.3337891101837158
Validation loss: 1.8250358053432998

Epoch: 6| Step: 5
Training loss: 1.1657594442367554
Validation loss: 1.8307129426669049

Epoch: 6| Step: 6
Training loss: 0.4331797957420349
Validation loss: 1.8260335550513318

Epoch: 6| Step: 7
Training loss: 1.118361234664917
Validation loss: 1.8239265423949047

Epoch: 6| Step: 8
Training loss: 0.6595484614372253
Validation loss: 1.796203483817398

Epoch: 6| Step: 9
Training loss: 1.0652923583984375
Validation loss: 1.8286350952681674

Epoch: 6| Step: 10
Training loss: 0.9217477440834045
Validation loss: 1.8585062783251527

Epoch: 6| Step: 11
Training loss: 0.943358302116394
Validation loss: 1.869947261707757

Epoch: 6| Step: 12
Training loss: 1.06504225730896
Validation loss: 1.8751575998080674

Epoch: 6| Step: 13
Training loss: 0.32585278153419495
Validation loss: 1.8480126319393035

Epoch: 265| Step: 0
Training loss: 0.774684727191925
Validation loss: 1.813966102497552

Epoch: 6| Step: 1
Training loss: 0.4076572060585022
Validation loss: 1.79470855446272

Epoch: 6| Step: 2
Training loss: 0.6071158051490784
Validation loss: 1.7659591013385403

Epoch: 6| Step: 3
Training loss: 0.8884080648422241
Validation loss: 1.7832693143557476

Epoch: 6| Step: 4
Training loss: 0.7872481346130371
Validation loss: 1.765136823859266

Epoch: 6| Step: 5
Training loss: 0.7909259796142578
Validation loss: 1.7928709778734433

Epoch: 6| Step: 6
Training loss: 0.8001692295074463
Validation loss: 1.796742667434036

Epoch: 6| Step: 7
Training loss: 1.055230975151062
Validation loss: 1.8059663400855115

Epoch: 6| Step: 8
Training loss: 0.9074438214302063
Validation loss: 1.819476172488223

Epoch: 6| Step: 9
Training loss: 0.6083276867866516
Validation loss: 1.8271008499207035

Epoch: 6| Step: 10
Training loss: 1.1278756856918335
Validation loss: 1.7966478537487727

Epoch: 6| Step: 11
Training loss: 1.3605024814605713
Validation loss: 1.8233151897307365

Epoch: 6| Step: 12
Training loss: 0.7493286728858948
Validation loss: 1.791997617290866

Epoch: 6| Step: 13
Training loss: 0.7639901041984558
Validation loss: 1.786229766825194

Epoch: 266| Step: 0
Training loss: 0.9192957878112793
Validation loss: 1.760126918874761

Epoch: 6| Step: 1
Training loss: 0.8235832452774048
Validation loss: 1.7626367845842916

Epoch: 6| Step: 2
Training loss: 0.9154747724533081
Validation loss: 1.7535280373788649

Epoch: 6| Step: 3
Training loss: 0.87969970703125
Validation loss: 1.750918963904022

Epoch: 6| Step: 4
Training loss: 1.2673205137252808
Validation loss: 1.752866570667554

Epoch: 6| Step: 5
Training loss: 0.7990337610244751
Validation loss: 1.8015937343720467

Epoch: 6| Step: 6
Training loss: 0.37747904658317566
Validation loss: 1.7750944501610213

Epoch: 6| Step: 7
Training loss: 1.1696546077728271
Validation loss: 1.7815490050982403

Epoch: 6| Step: 8
Training loss: 0.6746147274971008
Validation loss: 1.764362983806159

Epoch: 6| Step: 9
Training loss: 0.7335952520370483
Validation loss: 1.7523237274539085

Epoch: 6| Step: 10
Training loss: 0.30906808376312256
Validation loss: 1.7731332304657146

Epoch: 6| Step: 11
Training loss: 0.7782534956932068
Validation loss: 1.8005742892142265

Epoch: 6| Step: 12
Training loss: 0.5751045942306519
Validation loss: 1.8163770450058805

Epoch: 6| Step: 13
Training loss: 1.089012622833252
Validation loss: 1.8244917405548917

Epoch: 267| Step: 0
Training loss: 0.8111779689788818
Validation loss: 1.8396747830093547

Epoch: 6| Step: 1
Training loss: 0.7339069247245789
Validation loss: 1.8542075644257248

Epoch: 6| Step: 2
Training loss: 0.6420450210571289
Validation loss: 1.8596827548037294

Epoch: 6| Step: 3
Training loss: 0.6466874480247498
Validation loss: 1.7893779893075266

Epoch: 6| Step: 4
Training loss: 0.9357173442840576
Validation loss: 1.7663492925705448

Epoch: 6| Step: 5
Training loss: 1.0067496299743652
Validation loss: 1.7510952231704549

Epoch: 6| Step: 6
Training loss: 0.8708877563476562
Validation loss: 1.7067936261494954

Epoch: 6| Step: 7
Training loss: 0.5482503175735474
Validation loss: 1.737267530092629

Epoch: 6| Step: 8
Training loss: 1.116861343383789
Validation loss: 1.7039821737556047

Epoch: 6| Step: 9
Training loss: 1.3689683675765991
Validation loss: 1.7072137683950446

Epoch: 6| Step: 10
Training loss: 0.6348673105239868
Validation loss: 1.7194147161258164

Epoch: 6| Step: 11
Training loss: 0.504374623298645
Validation loss: 1.7490612550448346

Epoch: 6| Step: 12
Training loss: 0.8204586505889893
Validation loss: 1.7520671993173578

Epoch: 6| Step: 13
Training loss: 0.5751873850822449
Validation loss: 1.7879602985997354

Epoch: 268| Step: 0
Training loss: 1.1484216451644897
Validation loss: 1.8304544302725023

Epoch: 6| Step: 1
Training loss: 0.803740382194519
Validation loss: 1.8102644989567418

Epoch: 6| Step: 2
Training loss: 0.39451417326927185
Validation loss: 1.766403748784014

Epoch: 6| Step: 3
Training loss: 0.9089580178260803
Validation loss: 1.7665731394162743

Epoch: 6| Step: 4
Training loss: 0.6968056559562683
Validation loss: 1.7605640093485515

Epoch: 6| Step: 5
Training loss: 0.5441826581954956
Validation loss: 1.7662210195295271

Epoch: 6| Step: 6
Training loss: 0.723762571811676
Validation loss: 1.7428621963788105

Epoch: 6| Step: 7
Training loss: 0.545137882232666
Validation loss: 1.7403116585105978

Epoch: 6| Step: 8
Training loss: 0.5274021625518799
Validation loss: 1.7555107673009236

Epoch: 6| Step: 9
Training loss: 0.9787999987602234
Validation loss: 1.7733090000767862

Epoch: 6| Step: 10
Training loss: 1.0768996477127075
Validation loss: 1.7998256939713673

Epoch: 6| Step: 11
Training loss: 0.6455034017562866
Validation loss: 1.8064300244854343

Epoch: 6| Step: 12
Training loss: 0.8303212523460388
Validation loss: 1.7994961661677207

Epoch: 6| Step: 13
Training loss: 1.9536895751953125
Validation loss: 1.773014073730797

Epoch: 269| Step: 0
Training loss: 0.7379521727561951
Validation loss: 1.7408267272415983

Epoch: 6| Step: 1
Training loss: 0.9448988437652588
Validation loss: 1.7394981717550626

Epoch: 6| Step: 2
Training loss: 0.15490078926086426
Validation loss: 1.7292190610721547

Epoch: 6| Step: 3
Training loss: 0.5512581467628479
Validation loss: 1.7349547160569059

Epoch: 6| Step: 4
Training loss: 0.7909871339797974
Validation loss: 1.7334105968475342

Epoch: 6| Step: 5
Training loss: 0.5336240530014038
Validation loss: 1.7609089330960346

Epoch: 6| Step: 6
Training loss: 0.6100095510482788
Validation loss: 1.7883717988127021

Epoch: 6| Step: 7
Training loss: 0.8979199528694153
Validation loss: 1.7858325037904965

Epoch: 6| Step: 8
Training loss: 0.940197229385376
Validation loss: 1.7961789420855943

Epoch: 6| Step: 9
Training loss: 0.9482611417770386
Validation loss: 1.815099065021802

Epoch: 6| Step: 10
Training loss: 0.7741460204124451
Validation loss: 1.8073779024103636

Epoch: 6| Step: 11
Training loss: 0.7204263806343079
Validation loss: 1.8062162655656055

Epoch: 6| Step: 12
Training loss: 1.467610478401184
Validation loss: 1.7998969439537293

Epoch: 6| Step: 13
Training loss: 0.496755450963974
Validation loss: 1.7745786700197446

Epoch: 270| Step: 0
Training loss: 0.6347944736480713
Validation loss: 1.7738038711650397

Epoch: 6| Step: 1
Training loss: 0.6407452821731567
Validation loss: 1.7539606325088009

Epoch: 6| Step: 2
Training loss: 0.7579776048660278
Validation loss: 1.7581155889777726

Epoch: 6| Step: 3
Training loss: 0.8453953862190247
Validation loss: 1.7680651000750962

Epoch: 6| Step: 4
Training loss: 0.7241111397743225
Validation loss: 1.7565725644429524

Epoch: 6| Step: 5
Training loss: 0.8076560497283936
Validation loss: 1.7677624879344818

Epoch: 6| Step: 6
Training loss: 0.7757927179336548
Validation loss: 1.7989758663280035

Epoch: 6| Step: 7
Training loss: 0.553929328918457
Validation loss: 1.7832935394779328

Epoch: 6| Step: 8
Training loss: 1.2596951723098755
Validation loss: 1.7845522306298698

Epoch: 6| Step: 9
Training loss: 0.6529750823974609
Validation loss: 1.7768080695982902

Epoch: 6| Step: 10
Training loss: 0.6203780174255371
Validation loss: 1.762987958487644

Epoch: 6| Step: 11
Training loss: 0.5149227976799011
Validation loss: 1.7547730527898318

Epoch: 6| Step: 12
Training loss: 0.8988456130027771
Validation loss: 1.7224216089453748

Epoch: 6| Step: 13
Training loss: 1.0912202596664429
Validation loss: 1.735247883745419

Epoch: 271| Step: 0
Training loss: 0.7040735483169556
Validation loss: 1.7547264637485627

Epoch: 6| Step: 1
Training loss: 0.4794061481952667
Validation loss: 1.7148367692065496

Epoch: 6| Step: 2
Training loss: 1.0760598182678223
Validation loss: 1.7530135082942184

Epoch: 6| Step: 3
Training loss: 0.9823293089866638
Validation loss: 1.740695418850068

Epoch: 6| Step: 4
Training loss: 0.8586186170578003
Validation loss: 1.7561553543613804

Epoch: 6| Step: 5
Training loss: 0.7452259063720703
Validation loss: 1.7817955183726486

Epoch: 6| Step: 6
Training loss: 0.569582462310791
Validation loss: 1.7498808958197152

Epoch: 6| Step: 7
Training loss: 0.4211632311344147
Validation loss: 1.7623579809742589

Epoch: 6| Step: 8
Training loss: 0.7010416984558105
Validation loss: 1.7351249520496657

Epoch: 6| Step: 9
Training loss: 0.8217052221298218
Validation loss: 1.7524297455305695

Epoch: 6| Step: 10
Training loss: 0.6687588691711426
Validation loss: 1.7328223797582811

Epoch: 6| Step: 11
Training loss: 1.0190110206604004
Validation loss: 1.7460006013993294

Epoch: 6| Step: 12
Training loss: 0.365551620721817
Validation loss: 1.7421037586786414

Epoch: 6| Step: 13
Training loss: 1.3468127250671387
Validation loss: 1.7467807236538138

Epoch: 272| Step: 0
Training loss: 0.5266469120979309
Validation loss: 1.7294388791566253

Epoch: 6| Step: 1
Training loss: 1.0951025485992432
Validation loss: 1.738586256580968

Epoch: 6| Step: 2
Training loss: 0.6872878074645996
Validation loss: 1.7218388460015739

Epoch: 6| Step: 3
Training loss: 0.7357743382453918
Validation loss: 1.7439155719613517

Epoch: 6| Step: 4
Training loss: 0.763835072517395
Validation loss: 1.7357429958158923

Epoch: 6| Step: 5
Training loss: 0.5608599185943604
Validation loss: 1.7373722176398

Epoch: 6| Step: 6
Training loss: 0.8941600918769836
Validation loss: 1.727093670957832

Epoch: 6| Step: 7
Training loss: 0.6383073329925537
Validation loss: 1.73129980410299

Epoch: 6| Step: 8
Training loss: 0.6283851861953735
Validation loss: 1.7568749612377537

Epoch: 6| Step: 9
Training loss: 0.8925347328186035
Validation loss: 1.7449946288139588

Epoch: 6| Step: 10
Training loss: 0.713564395904541
Validation loss: 1.7491753498713176

Epoch: 6| Step: 11
Training loss: 0.564867377281189
Validation loss: 1.7732901419362714

Epoch: 6| Step: 12
Training loss: 0.5377575159072876
Validation loss: 1.7743192975239088

Epoch: 6| Step: 13
Training loss: 0.9579665660858154
Validation loss: 1.7789449666136055

Epoch: 273| Step: 0
Training loss: 0.6887561678886414
Validation loss: 1.7568860515471427

Epoch: 6| Step: 1
Training loss: 0.9161085486412048
Validation loss: 1.7720235086256457

Epoch: 6| Step: 2
Training loss: 1.0320427417755127
Validation loss: 1.7283249170549455

Epoch: 6| Step: 3
Training loss: 0.9546754956245422
Validation loss: 1.7545863325877855

Epoch: 6| Step: 4
Training loss: 0.5174576044082642
Validation loss: 1.7263922742618028

Epoch: 6| Step: 5
Training loss: 0.5563210248947144
Validation loss: 1.7342456681754

Epoch: 6| Step: 6
Training loss: 0.965115487575531
Validation loss: 1.7623480058485461

Epoch: 6| Step: 7
Training loss: 0.5436556339263916
Validation loss: 1.7875373132767216

Epoch: 6| Step: 8
Training loss: 0.6306567192077637
Validation loss: 1.8040490740089006

Epoch: 6| Step: 9
Training loss: 0.5900154113769531
Validation loss: 1.783811221840561

Epoch: 6| Step: 10
Training loss: 0.7422573566436768
Validation loss: 1.7563931672803816

Epoch: 6| Step: 11
Training loss: 0.8136061429977417
Validation loss: 1.7256560710168654

Epoch: 6| Step: 12
Training loss: 0.7051190137863159
Validation loss: 1.7387837620191677

Epoch: 6| Step: 13
Training loss: 0.6443223357200623
Validation loss: 1.749805832421908

Epoch: 274| Step: 0
Training loss: 0.44322121143341064
Validation loss: 1.7296480645415604

Epoch: 6| Step: 1
Training loss: 0.8221451044082642
Validation loss: 1.7119480820112332

Epoch: 6| Step: 2
Training loss: 1.1436386108398438
Validation loss: 1.7025773217601161

Epoch: 6| Step: 3
Training loss: 0.4978187680244446
Validation loss: 1.7601486867473972

Epoch: 6| Step: 4
Training loss: 0.6311355829238892
Validation loss: 1.7729464102816839

Epoch: 6| Step: 5
Training loss: 0.8582807779312134
Validation loss: 1.7498290641333467

Epoch: 6| Step: 6
Training loss: 1.0827851295471191
Validation loss: 1.7719320110095444

Epoch: 6| Step: 7
Training loss: 0.7903184294700623
Validation loss: 1.755833323283862

Epoch: 6| Step: 8
Training loss: 0.9198114275932312
Validation loss: 1.7493533626679452

Epoch: 6| Step: 9
Training loss: 0.4468206763267517
Validation loss: 1.7369695940325338

Epoch: 6| Step: 10
Training loss: 0.4558004140853882
Validation loss: 1.701588943440427

Epoch: 6| Step: 11
Training loss: 0.3541620373725891
Validation loss: 1.7155541912201913

Epoch: 6| Step: 12
Training loss: 0.9392063617706299
Validation loss: 1.7248649674077188

Epoch: 6| Step: 13
Training loss: 0.9428132176399231
Validation loss: 1.728249410147308

Epoch: 275| Step: 0
Training loss: 0.6677435636520386
Validation loss: 1.785043349830053

Epoch: 6| Step: 1
Training loss: 1.2368801832199097
Validation loss: 1.7648743391036987

Epoch: 6| Step: 2
Training loss: 0.7742549180984497
Validation loss: 1.8033231086628412

Epoch: 6| Step: 3
Training loss: 0.5995254516601562
Validation loss: 1.827621481751883

Epoch: 6| Step: 4
Training loss: 0.8231431245803833
Validation loss: 1.8117106165937198

Epoch: 6| Step: 5
Training loss: 0.41001927852630615
Validation loss: 1.7734237165861233

Epoch: 6| Step: 6
Training loss: 1.1294909715652466
Validation loss: 1.7760941290086316

Epoch: 6| Step: 7
Training loss: 0.8283645510673523
Validation loss: 1.7787935451794696

Epoch: 6| Step: 8
Training loss: 0.34535080194473267
Validation loss: 1.774654669146384

Epoch: 6| Step: 9
Training loss: 0.8231586813926697
Validation loss: 1.7792832133590535

Epoch: 6| Step: 10
Training loss: 0.9441772699356079
Validation loss: 1.7702866164586877

Epoch: 6| Step: 11
Training loss: 0.5452123284339905
Validation loss: 1.77026584968772

Epoch: 6| Step: 12
Training loss: 0.7157106399536133
Validation loss: 1.7852244838591544

Epoch: 6| Step: 13
Training loss: 0.46364444494247437
Validation loss: 1.8379250905847038

Epoch: 276| Step: 0
Training loss: 0.8453318476676941
Validation loss: 1.8147410769616403

Epoch: 6| Step: 1
Training loss: 0.9381190538406372
Validation loss: 1.7906615452099872

Epoch: 6| Step: 2
Training loss: 0.5886258482933044
Validation loss: 1.7834348909316524

Epoch: 6| Step: 3
Training loss: 0.8753225207328796
Validation loss: 1.7760674709914832

Epoch: 6| Step: 4
Training loss: 0.5300788879394531
Validation loss: 1.773346447175549

Epoch: 6| Step: 5
Training loss: 0.7538895010948181
Validation loss: 1.7825771685569518

Epoch: 6| Step: 6
Training loss: 1.1857573986053467
Validation loss: 1.7724158392157605

Epoch: 6| Step: 7
Training loss: 0.6379773616790771
Validation loss: 1.7866173251982658

Epoch: 6| Step: 8
Training loss: 0.7424240112304688
Validation loss: 1.8068255403990388

Epoch: 6| Step: 9
Training loss: 0.5074682235717773
Validation loss: 1.7927502047631048

Epoch: 6| Step: 10
Training loss: 1.2079343795776367
Validation loss: 1.8312936111163067

Epoch: 6| Step: 11
Training loss: 0.4516356587409973
Validation loss: 1.8183055231648106

Epoch: 6| Step: 12
Training loss: 0.6364551186561584
Validation loss: 1.8271177173942648

Epoch: 6| Step: 13
Training loss: 0.6313669681549072
Validation loss: 1.8202341237375814

Epoch: 277| Step: 0
Training loss: 0.5559734106063843
Validation loss: 1.7751021026283182

Epoch: 6| Step: 1
Training loss: 0.6019209027290344
Validation loss: 1.7581889680636826

Epoch: 6| Step: 2
Training loss: 0.5769743919372559
Validation loss: 1.7274179791891446

Epoch: 6| Step: 3
Training loss: 0.6344121098518372
Validation loss: 1.7312463201502317

Epoch: 6| Step: 4
Training loss: 0.6980553865432739
Validation loss: 1.7093182507381643

Epoch: 6| Step: 5
Training loss: 0.7276245355606079
Validation loss: 1.6879053282481369

Epoch: 6| Step: 6
Training loss: 0.8286952376365662
Validation loss: 1.7183698505483649

Epoch: 6| Step: 7
Training loss: 0.5620824098587036
Validation loss: 1.7366694032504995

Epoch: 6| Step: 8
Training loss: 0.682938814163208
Validation loss: 1.7504124513236425

Epoch: 6| Step: 9
Training loss: 0.4444504380226135
Validation loss: 1.7699322367227206

Epoch: 6| Step: 10
Training loss: 0.8334926962852478
Validation loss: 1.732151468594869

Epoch: 6| Step: 11
Training loss: 1.2062517404556274
Validation loss: 1.7660842249470372

Epoch: 6| Step: 12
Training loss: 0.8190147280693054
Validation loss: 1.7709868774619153

Epoch: 6| Step: 13
Training loss: 0.6637861728668213
Validation loss: 1.775652616254745

Epoch: 278| Step: 0
Training loss: 0.6543481349945068
Validation loss: 1.8128548360640002

Epoch: 6| Step: 1
Training loss: 0.738178014755249
Validation loss: 1.780752871626167

Epoch: 6| Step: 2
Training loss: 0.5040401220321655
Validation loss: 1.7922554003295077

Epoch: 6| Step: 3
Training loss: 0.5716645121574402
Validation loss: 1.7670286342661867

Epoch: 6| Step: 4
Training loss: 0.8721222877502441
Validation loss: 1.7575244301108903

Epoch: 6| Step: 5
Training loss: 0.5078473687171936
Validation loss: 1.767397872222367

Epoch: 6| Step: 6
Training loss: 0.6547622680664062
Validation loss: 1.7782608014281078

Epoch: 6| Step: 7
Training loss: 0.6536306142807007
Validation loss: 1.8234545389811199

Epoch: 6| Step: 8
Training loss: 1.194244146347046
Validation loss: 1.7732123982521795

Epoch: 6| Step: 9
Training loss: 0.3621490001678467
Validation loss: 1.7628127541593326

Epoch: 6| Step: 10
Training loss: 1.1460802555084229
Validation loss: 1.7621003978995866

Epoch: 6| Step: 11
Training loss: 0.8312110900878906
Validation loss: 1.7294867705273371

Epoch: 6| Step: 12
Training loss: 0.6193921566009521
Validation loss: 1.73672362296812

Epoch: 6| Step: 13
Training loss: 0.6657000184059143
Validation loss: 1.7192919690121886

Epoch: 279| Step: 0
Training loss: 1.010247826576233
Validation loss: 1.7156466514833513

Epoch: 6| Step: 1
Training loss: 0.36093175411224365
Validation loss: 1.717286317579208

Epoch: 6| Step: 2
Training loss: 0.6114232540130615
Validation loss: 1.7452483484821935

Epoch: 6| Step: 3
Training loss: 0.8777243494987488
Validation loss: 1.739114671625117

Epoch: 6| Step: 4
Training loss: 0.839678943157196
Validation loss: 1.7680522062445199

Epoch: 6| Step: 5
Training loss: 0.6264373660087585
Validation loss: 1.7538700642124299

Epoch: 6| Step: 6
Training loss: 0.5020661950111389
Validation loss: 1.7775559591990646

Epoch: 6| Step: 7
Training loss: 0.7437046766281128
Validation loss: 1.7765982356122745

Epoch: 6| Step: 8
Training loss: 0.8217861652374268
Validation loss: 1.7457001606623332

Epoch: 6| Step: 9
Training loss: 0.30460435152053833
Validation loss: 1.7519343168504777

Epoch: 6| Step: 10
Training loss: 0.7223004698753357
Validation loss: 1.749151998950589

Epoch: 6| Step: 11
Training loss: 0.7253836989402771
Validation loss: 1.7329066273986653

Epoch: 6| Step: 12
Training loss: 0.6198824048042297
Validation loss: 1.7206860678170317

Epoch: 6| Step: 13
Training loss: 0.58690345287323
Validation loss: 1.7072508591477589

Epoch: 280| Step: 0
Training loss: 0.8309245705604553
Validation loss: 1.7198530884199246

Epoch: 6| Step: 1
Training loss: 0.658413290977478
Validation loss: 1.7029364826858684

Epoch: 6| Step: 2
Training loss: 0.36634981632232666
Validation loss: 1.696692071935182

Epoch: 6| Step: 3
Training loss: 0.4294203519821167
Validation loss: 1.7107307744282547

Epoch: 6| Step: 4
Training loss: 0.7879922389984131
Validation loss: 1.717654166683074

Epoch: 6| Step: 5
Training loss: 0.9195394515991211
Validation loss: 1.701264032753565

Epoch: 6| Step: 6
Training loss: 0.5898441076278687
Validation loss: 1.7116925421581473

Epoch: 6| Step: 7
Training loss: 0.6696659326553345
Validation loss: 1.7347187175545642

Epoch: 6| Step: 8
Training loss: 0.5486874580383301
Validation loss: 1.750282520888954

Epoch: 6| Step: 9
Training loss: 0.6665361523628235
Validation loss: 1.756465136363942

Epoch: 6| Step: 10
Training loss: 0.8059319853782654
Validation loss: 1.7778597224143244

Epoch: 6| Step: 11
Training loss: 0.5839697122573853
Validation loss: 1.7802370325211556

Epoch: 6| Step: 12
Training loss: 0.7595456838607788
Validation loss: 1.7877080530248664

Epoch: 6| Step: 13
Training loss: 0.5755929350852966
Validation loss: 1.744316824020878

Epoch: 281| Step: 0
Training loss: 0.7630191445350647
Validation loss: 1.7389961699003815

Epoch: 6| Step: 1
Training loss: 0.7196341753005981
Validation loss: 1.7343246372797156

Epoch: 6| Step: 2
Training loss: 0.7898439168930054
Validation loss: 1.7124503389481576

Epoch: 6| Step: 3
Training loss: 0.64718097448349
Validation loss: 1.7271876232598418

Epoch: 6| Step: 4
Training loss: 0.576982855796814
Validation loss: 1.715100578082505

Epoch: 6| Step: 5
Training loss: 0.7030030488967896
Validation loss: 1.7512413071047874

Epoch: 6| Step: 6
Training loss: 0.5203253030776978
Validation loss: 1.7596618360088718

Epoch: 6| Step: 7
Training loss: 0.7767232656478882
Validation loss: 1.7530314678786902

Epoch: 6| Step: 8
Training loss: 0.16990718245506287
Validation loss: 1.7910767498836722

Epoch: 6| Step: 9
Training loss: 0.8438068628311157
Validation loss: 1.8016263643900554

Epoch: 6| Step: 10
Training loss: 0.4461662173271179
Validation loss: 1.783563498527773

Epoch: 6| Step: 11
Training loss: 1.0109208822250366
Validation loss: 1.7610902542709022

Epoch: 6| Step: 12
Training loss: 0.5595026612281799
Validation loss: 1.7361360288435412

Epoch: 6| Step: 13
Training loss: 0.5204870700836182
Validation loss: 1.7353707513501566

Epoch: 282| Step: 0
Training loss: 0.848910391330719
Validation loss: 1.7233801375153244

Epoch: 6| Step: 1
Training loss: 0.8564558029174805
Validation loss: 1.7486736876990205

Epoch: 6| Step: 2
Training loss: 0.4010942578315735
Validation loss: 1.7713149106630715

Epoch: 6| Step: 3
Training loss: 0.38897964358329773
Validation loss: 1.7147532432310042

Epoch: 6| Step: 4
Training loss: 0.5288569331169128
Validation loss: 1.7710457873600784

Epoch: 6| Step: 5
Training loss: 0.21504047513008118
Validation loss: 1.7450671618984592

Epoch: 6| Step: 6
Training loss: 0.8042663335800171
Validation loss: 1.737742374020238

Epoch: 6| Step: 7
Training loss: 0.8663836717605591
Validation loss: 1.7585178395753265

Epoch: 6| Step: 8
Training loss: 0.7283086776733398
Validation loss: 1.7631178517495432

Epoch: 6| Step: 9
Training loss: 0.7987942695617676
Validation loss: 1.7541568266448153

Epoch: 6| Step: 10
Training loss: 0.6219830513000488
Validation loss: 1.7222358360085437

Epoch: 6| Step: 11
Training loss: 0.7020570039749146
Validation loss: 1.7125620893252793

Epoch: 6| Step: 12
Training loss: 0.7085000872612
Validation loss: 1.7250983048510808

Epoch: 6| Step: 13
Training loss: 1.1244759559631348
Validation loss: 1.7223140398661296

Epoch: 283| Step: 0
Training loss: 0.67020583152771
Validation loss: 1.6839765297469271

Epoch: 6| Step: 1
Training loss: 0.6120495796203613
Validation loss: 1.704537994118147

Epoch: 6| Step: 2
Training loss: 0.4968069791793823
Validation loss: 1.714537153961838

Epoch: 6| Step: 3
Training loss: 0.6303675174713135
Validation loss: 1.7081116066184094

Epoch: 6| Step: 4
Training loss: 0.536752462387085
Validation loss: 1.7264233186680784

Epoch: 6| Step: 5
Training loss: 0.586359441280365
Validation loss: 1.714135673097385

Epoch: 6| Step: 6
Training loss: 1.5667304992675781
Validation loss: 1.7377322181578605

Epoch: 6| Step: 7
Training loss: 0.6134417057037354
Validation loss: 1.7779685451138405

Epoch: 6| Step: 8
Training loss: 0.49102115631103516
Validation loss: 1.7352313790270077

Epoch: 6| Step: 9
Training loss: 0.7701862454414368
Validation loss: 1.7129858052858742

Epoch: 6| Step: 10
Training loss: 0.3276384770870209
Validation loss: 1.713838086333326

Epoch: 6| Step: 11
Training loss: 0.7142695784568787
Validation loss: 1.7288380489554456

Epoch: 6| Step: 12
Training loss: 0.7334312796592712
Validation loss: 1.7183260840754355

Epoch: 6| Step: 13
Training loss: 0.5163209438323975
Validation loss: 1.7241414746930521

Epoch: 284| Step: 0
Training loss: 0.2705754041671753
Validation loss: 1.6998626314183718

Epoch: 6| Step: 1
Training loss: 1.144948124885559
Validation loss: 1.6913889454257103

Epoch: 6| Step: 2
Training loss: 0.2817770838737488
Validation loss: 1.7131417925639818

Epoch: 6| Step: 3
Training loss: 0.5984197854995728
Validation loss: 1.707725481320453

Epoch: 6| Step: 4
Training loss: 0.8937885761260986
Validation loss: 1.7141289390543455

Epoch: 6| Step: 5
Training loss: 0.8031766414642334
Validation loss: 1.712994211463518

Epoch: 6| Step: 6
Training loss: 0.6160848140716553
Validation loss: 1.7310963330730316

Epoch: 6| Step: 7
Training loss: 0.8350355625152588
Validation loss: 1.7302525697215911

Epoch: 6| Step: 8
Training loss: 0.496705561876297
Validation loss: 1.7086876541055658

Epoch: 6| Step: 9
Training loss: 0.8376111388206482
Validation loss: 1.7125856325190554

Epoch: 6| Step: 10
Training loss: 0.4875076413154602
Validation loss: 1.691334004043251

Epoch: 6| Step: 11
Training loss: 0.5065217018127441
Validation loss: 1.711490705449094

Epoch: 6| Step: 12
Training loss: 0.8207787275314331
Validation loss: 1.752665424859652

Epoch: 6| Step: 13
Training loss: 0.19027474522590637
Validation loss: 1.7163303795681204

Epoch: 285| Step: 0
Training loss: 0.5462690591812134
Validation loss: 1.709975928388616

Epoch: 6| Step: 1
Training loss: 0.2329023778438568
Validation loss: 1.723663023723069

Epoch: 6| Step: 2
Training loss: 0.5531357526779175
Validation loss: 1.726471706103253

Epoch: 6| Step: 3
Training loss: 0.3935569226741791
Validation loss: 1.7314953778379707

Epoch: 6| Step: 4
Training loss: 0.8382413387298584
Validation loss: 1.7421742459779144

Epoch: 6| Step: 5
Training loss: 0.45558565855026245
Validation loss: 1.7513530638910109

Epoch: 6| Step: 6
Training loss: 0.5838291645050049
Validation loss: 1.701821009318034

Epoch: 6| Step: 7
Training loss: 0.7535306215286255
Validation loss: 1.7065816976690804

Epoch: 6| Step: 8
Training loss: 0.8059988021850586
Validation loss: 1.6690410298685874

Epoch: 6| Step: 9
Training loss: 0.5347853899002075
Validation loss: 1.6742407782103426

Epoch: 6| Step: 10
Training loss: 1.1333417892456055
Validation loss: 1.6720283159645655

Epoch: 6| Step: 11
Training loss: 0.7172040939331055
Validation loss: 1.667738796562277

Epoch: 6| Step: 12
Training loss: 0.38453906774520874
Validation loss: 1.700462720727408

Epoch: 6| Step: 13
Training loss: 0.722189724445343
Validation loss: 1.6795857798668645

Epoch: 286| Step: 0
Training loss: 0.5911071300506592
Validation loss: 1.6996668961740309

Epoch: 6| Step: 1
Training loss: 0.7021113634109497
Validation loss: 1.6849715491776824

Epoch: 6| Step: 2
Training loss: 0.943225622177124
Validation loss: 1.6930481080086

Epoch: 6| Step: 3
Training loss: 0.8449599742889404
Validation loss: 1.6789079943010885

Epoch: 6| Step: 4
Training loss: 0.369027316570282
Validation loss: 1.684998514831707

Epoch: 6| Step: 5
Training loss: 0.5699154138565063
Validation loss: 1.6854392649025045

Epoch: 6| Step: 6
Training loss: 0.7086740136146545
Validation loss: 1.7153455070270005

Epoch: 6| Step: 7
Training loss: 0.2529428005218506
Validation loss: 1.7273979199829923

Epoch: 6| Step: 8
Training loss: 0.6255005598068237
Validation loss: 1.7296140104211786

Epoch: 6| Step: 9
Training loss: 0.5554416179656982
Validation loss: 1.6927939454714458

Epoch: 6| Step: 10
Training loss: 0.5173193216323853
Validation loss: 1.6676344230610838

Epoch: 6| Step: 11
Training loss: 0.5774264931678772
Validation loss: 1.6899221225451397

Epoch: 6| Step: 12
Training loss: 0.7724809646606445
Validation loss: 1.687648925089067

Epoch: 6| Step: 13
Training loss: 0.4562196731567383
Validation loss: 1.6811785877391856

Epoch: 287| Step: 0
Training loss: 0.4498381018638611
Validation loss: 1.6656419333591257

Epoch: 6| Step: 1
Training loss: 0.46560347080230713
Validation loss: 1.69946833707953

Epoch: 6| Step: 2
Training loss: 0.5301807522773743
Validation loss: 1.7372795330580844

Epoch: 6| Step: 3
Training loss: 0.8733879327774048
Validation loss: 1.7411636652485016

Epoch: 6| Step: 4
Training loss: 0.45131024718284607
Validation loss: 1.741378584215718

Epoch: 6| Step: 5
Training loss: 0.7798330187797546
Validation loss: 1.717669572881473

Epoch: 6| Step: 6
Training loss: 0.8700425624847412
Validation loss: 1.7013953911360873

Epoch: 6| Step: 7
Training loss: 0.7128342390060425
Validation loss: 1.7043854780094598

Epoch: 6| Step: 8
Training loss: 0.7006288170814514
Validation loss: 1.7011580505678732

Epoch: 6| Step: 9
Training loss: 0.5909817218780518
Validation loss: 1.7206825787021267

Epoch: 6| Step: 10
Training loss: 0.5961437225341797
Validation loss: 1.7064716726221063

Epoch: 6| Step: 11
Training loss: 0.42970380187034607
Validation loss: 1.7023004690806072

Epoch: 6| Step: 12
Training loss: 0.7536913156509399
Validation loss: 1.7250480882583126

Epoch: 6| Step: 13
Training loss: 0.7001574039459229
Validation loss: 1.7116333720504597

Epoch: 288| Step: 0
Training loss: 0.6715821027755737
Validation loss: 1.7307443054773475

Epoch: 6| Step: 1
Training loss: 0.3369183838367462
Validation loss: 1.7790870397321639

Epoch: 6| Step: 2
Training loss: 1.120622158050537
Validation loss: 1.8299895230159964

Epoch: 6| Step: 3
Training loss: 0.7059797644615173
Validation loss: 1.774144834087741

Epoch: 6| Step: 4
Training loss: 0.660463273525238
Validation loss: 1.754831039777366

Epoch: 6| Step: 5
Training loss: 0.6038329601287842
Validation loss: 1.7603902239953317

Epoch: 6| Step: 6
Training loss: 0.47936034202575684
Validation loss: 1.7734410532059208

Epoch: 6| Step: 7
Training loss: 0.2907015085220337
Validation loss: 1.7378877798716228

Epoch: 6| Step: 8
Training loss: 0.6687137484550476
Validation loss: 1.749646525229177

Epoch: 6| Step: 9
Training loss: 0.7225403785705566
Validation loss: 1.7162503760348085

Epoch: 6| Step: 10
Training loss: 0.49357637763023376
Validation loss: 1.7302110977070306

Epoch: 6| Step: 11
Training loss: 0.3523786664009094
Validation loss: 1.7510084900804745

Epoch: 6| Step: 12
Training loss: 0.8394333124160767
Validation loss: 1.7562166516498854

Epoch: 6| Step: 13
Training loss: 0.8252049684524536
Validation loss: 1.7372910873864287

Epoch: 289| Step: 0
Training loss: 0.522520124912262
Validation loss: 1.7142236002029911

Epoch: 6| Step: 1
Training loss: 0.42849230766296387
Validation loss: 1.7148305895507976

Epoch: 6| Step: 2
Training loss: 0.4938996732234955
Validation loss: 1.681546224060879

Epoch: 6| Step: 3
Training loss: 0.6274995803833008
Validation loss: 1.7197738949970534

Epoch: 6| Step: 4
Training loss: 0.6733070611953735
Validation loss: 1.705749660409907

Epoch: 6| Step: 5
Training loss: 0.5350241661071777
Validation loss: 1.7200640170804915

Epoch: 6| Step: 6
Training loss: 0.7675749063491821
Validation loss: 1.716430353221073

Epoch: 6| Step: 7
Training loss: 0.6297342777252197
Validation loss: 1.7263032659407584

Epoch: 6| Step: 8
Training loss: 0.7695397138595581
Validation loss: 1.728436855859654

Epoch: 6| Step: 9
Training loss: 0.5145247578620911
Validation loss: 1.730485644391788

Epoch: 6| Step: 10
Training loss: 0.7069515585899353
Validation loss: 1.7610127631054129

Epoch: 6| Step: 11
Training loss: 0.6779277324676514
Validation loss: 1.7671950606889621

Epoch: 6| Step: 12
Training loss: 0.5891176462173462
Validation loss: 1.7510170372583533

Epoch: 6| Step: 13
Training loss: 0.3583586513996124
Validation loss: 1.6983589920946347

Epoch: 290| Step: 0
Training loss: 0.42632120847702026
Validation loss: 1.6897632037439654

Epoch: 6| Step: 1
Training loss: 0.547683835029602
Validation loss: 1.683146156290526

Epoch: 6| Step: 2
Training loss: 0.5434161424636841
Validation loss: 1.6799980427629204

Epoch: 6| Step: 3
Training loss: 0.7484668493270874
Validation loss: 1.6795656629787978

Epoch: 6| Step: 4
Training loss: 0.6127105951309204
Validation loss: 1.6867462883713424

Epoch: 6| Step: 5
Training loss: 0.6240519285202026
Validation loss: 1.713263318102847

Epoch: 6| Step: 6
Training loss: 0.4692140221595764
Validation loss: 1.7298468492364372

Epoch: 6| Step: 7
Training loss: 0.45711883902549744
Validation loss: 1.7340098965552546

Epoch: 6| Step: 8
Training loss: 0.5495622158050537
Validation loss: 1.7461516113691433

Epoch: 6| Step: 9
Training loss: 0.569217324256897
Validation loss: 1.817235380090693

Epoch: 6| Step: 10
Training loss: 0.7169348001480103
Validation loss: 1.8174081002512286

Epoch: 6| Step: 11
Training loss: 1.3892512321472168
Validation loss: 1.863364734957295

Epoch: 6| Step: 12
Training loss: 0.410749614238739
Validation loss: 1.785641017780509

Epoch: 6| Step: 13
Training loss: 0.5439396500587463
Validation loss: 1.795545442129976

Epoch: 291| Step: 0
Training loss: 0.7926828861236572
Validation loss: 1.7752159000724874

Epoch: 6| Step: 1
Training loss: 0.9442257881164551
Validation loss: 1.7455549291385117

Epoch: 6| Step: 2
Training loss: 0.47274935245513916
Validation loss: 1.7004673532260361

Epoch: 6| Step: 3
Training loss: 0.538028359413147
Validation loss: 1.7225889467423963

Epoch: 6| Step: 4
Training loss: 1.2455992698669434
Validation loss: 1.7143072908924473

Epoch: 6| Step: 5
Training loss: 0.49629196524620056
Validation loss: 1.7199276711351128

Epoch: 6| Step: 6
Training loss: 0.19825643301010132
Validation loss: 1.7355685246888028

Epoch: 6| Step: 7
Training loss: 0.5737157464027405
Validation loss: 1.7396395962725404

Epoch: 6| Step: 8
Training loss: 0.42367279529571533
Validation loss: 1.7877546318115727

Epoch: 6| Step: 9
Training loss: 0.9257104396820068
Validation loss: 1.755727256498029

Epoch: 6| Step: 10
Training loss: 0.42418789863586426
Validation loss: 1.7508518836831535

Epoch: 6| Step: 11
Training loss: 0.7217482924461365
Validation loss: 1.7461573885333153

Epoch: 6| Step: 12
Training loss: 0.22701258957386017
Validation loss: 1.7183830045884656

Epoch: 6| Step: 13
Training loss: 0.5933194160461426
Validation loss: 1.6953297199741486

Epoch: 292| Step: 0
Training loss: 0.39806899428367615
Validation loss: 1.6685433990211898

Epoch: 6| Step: 1
Training loss: 0.8079056739807129
Validation loss: 1.6693766591369466

Epoch: 6| Step: 2
Training loss: 0.4888644814491272
Validation loss: 1.6605994765476515

Epoch: 6| Step: 3
Training loss: 0.4900446832180023
Validation loss: 1.6538399445113314

Epoch: 6| Step: 4
Training loss: 0.8748773336410522
Validation loss: 1.6947918143323673

Epoch: 6| Step: 5
Training loss: 0.5446655750274658
Validation loss: 1.646153885831115

Epoch: 6| Step: 6
Training loss: 0.7169736623764038
Validation loss: 1.69775188866482

Epoch: 6| Step: 7
Training loss: 0.3378375172615051
Validation loss: 1.6676220765677832

Epoch: 6| Step: 8
Training loss: 0.762313723564148
Validation loss: 1.703939845485072

Epoch: 6| Step: 9
Training loss: 0.5407314300537109
Validation loss: 1.717488355534051

Epoch: 6| Step: 10
Training loss: 0.4490910768508911
Validation loss: 1.6945206221713816

Epoch: 6| Step: 11
Training loss: 0.5654285550117493
Validation loss: 1.7253431248408493

Epoch: 6| Step: 12
Training loss: 0.29543644189834595
Validation loss: 1.740718203206216

Epoch: 6| Step: 13
Training loss: 0.7377909421920776
Validation loss: 1.7488185282676452

Epoch: 293| Step: 0
Training loss: 0.7857140302658081
Validation loss: 1.7929021748163367

Epoch: 6| Step: 1
Training loss: 0.8645972609519958
Validation loss: 1.7616065291948215

Epoch: 6| Step: 2
Training loss: 0.47644200921058655
Validation loss: 1.766168612305836

Epoch: 6| Step: 3
Training loss: 0.25992944836616516
Validation loss: 1.755774873559193

Epoch: 6| Step: 4
Training loss: 0.5619466304779053
Validation loss: 1.7394113489376601

Epoch: 6| Step: 5
Training loss: 0.4255012571811676
Validation loss: 1.6972123064020628

Epoch: 6| Step: 6
Training loss: 1.0750668048858643
Validation loss: 1.6928429693304083

Epoch: 6| Step: 7
Training loss: 0.6061150431632996
Validation loss: 1.7111420118680565

Epoch: 6| Step: 8
Training loss: 0.4890746772289276
Validation loss: 1.6972141842688284

Epoch: 6| Step: 9
Training loss: 0.5555309653282166
Validation loss: 1.717297355333964

Epoch: 6| Step: 10
Training loss: 0.6894540786743164
Validation loss: 1.7634796275887439

Epoch: 6| Step: 11
Training loss: 0.4401107728481293
Validation loss: 1.783979578684735

Epoch: 6| Step: 12
Training loss: 0.32546383142471313
Validation loss: 1.799421993635034

Epoch: 6| Step: 13
Training loss: 0.33245494961738586
Validation loss: 1.7830072667009087

Epoch: 294| Step: 0
Training loss: 0.5598561763763428
Validation loss: 1.7555706552279893

Epoch: 6| Step: 1
Training loss: 0.5009815096855164
Validation loss: 1.7253648491315945

Epoch: 6| Step: 2
Training loss: 0.7226088643074036
Validation loss: 1.7270079415331605

Epoch: 6| Step: 3
Training loss: 0.5038632154464722
Validation loss: 1.7067681230524534

Epoch: 6| Step: 4
Training loss: 0.6988271474838257
Validation loss: 1.6874563950364307

Epoch: 6| Step: 5
Training loss: 0.4424220621585846
Validation loss: 1.7071484263225267

Epoch: 6| Step: 6
Training loss: 0.2958351969718933
Validation loss: 1.7024227419207174

Epoch: 6| Step: 7
Training loss: 0.8460547924041748
Validation loss: 1.6909533803180983

Epoch: 6| Step: 8
Training loss: 0.5198574066162109
Validation loss: 1.697681671829634

Epoch: 6| Step: 9
Training loss: 0.34306174516677856
Validation loss: 1.7021015869673861

Epoch: 6| Step: 10
Training loss: 0.5836589336395264
Validation loss: 1.7003917963274064

Epoch: 6| Step: 11
Training loss: 0.5574308633804321
Validation loss: 1.7149577345899356

Epoch: 6| Step: 12
Training loss: 0.5439852476119995
Validation loss: 1.7139301338503439

Epoch: 6| Step: 13
Training loss: 0.5890135765075684
Validation loss: 1.7337839949515559

Epoch: 295| Step: 0
Training loss: 0.6328813433647156
Validation loss: 1.7645000501345562

Epoch: 6| Step: 1
Training loss: 0.6919002532958984
Validation loss: 1.7566900689114806

Epoch: 6| Step: 2
Training loss: 0.3949293792247772
Validation loss: 1.7642524101400887

Epoch: 6| Step: 3
Training loss: 0.46897125244140625
Validation loss: 1.7322018069605674

Epoch: 6| Step: 4
Training loss: 0.5551881790161133
Validation loss: 1.7598847266166442

Epoch: 6| Step: 5
Training loss: 0.6121342182159424
Validation loss: 1.7635954759454215

Epoch: 6| Step: 6
Training loss: 0.36490267515182495
Validation loss: 1.7248431098076604

Epoch: 6| Step: 7
Training loss: 0.934384286403656
Validation loss: 1.7199764905437347

Epoch: 6| Step: 8
Training loss: 0.48204290866851807
Validation loss: 1.7174312709480204

Epoch: 6| Step: 9
Training loss: 0.45748645067214966
Validation loss: 1.7418443977191884

Epoch: 6| Step: 10
Training loss: 0.4400044083595276
Validation loss: 1.7417069353083128

Epoch: 6| Step: 11
Training loss: 0.5530619025230408
Validation loss: 1.7054189917861775

Epoch: 6| Step: 12
Training loss: 0.3892979025840759
Validation loss: 1.7123855160128685

Epoch: 6| Step: 13
Training loss: 0.7357649803161621
Validation loss: 1.6950189682745165

Epoch: 296| Step: 0
Training loss: 0.4461468458175659
Validation loss: 1.689035056739725

Epoch: 6| Step: 1
Training loss: 0.3244597911834717
Validation loss: 1.6889027626283708

Epoch: 6| Step: 2
Training loss: 0.4536483585834503
Validation loss: 1.695122161219197

Epoch: 6| Step: 3
Training loss: 0.7531670928001404
Validation loss: 1.6877437080106428

Epoch: 6| Step: 4
Training loss: 0.6719951033592224
Validation loss: 1.7060605543915943

Epoch: 6| Step: 5
Training loss: 0.6321978569030762
Validation loss: 1.6948933729561426

Epoch: 6| Step: 6
Training loss: 0.5396241545677185
Validation loss: 1.6789382093696184

Epoch: 6| Step: 7
Training loss: 0.3991881310939789
Validation loss: 1.7191839320685274

Epoch: 6| Step: 8
Training loss: 0.9062745571136475
Validation loss: 1.7035182804189704

Epoch: 6| Step: 9
Training loss: 0.6172139644622803
Validation loss: 1.6324522020996257

Epoch: 6| Step: 10
Training loss: 0.42413330078125
Validation loss: 1.6968702834139588

Epoch: 6| Step: 11
Training loss: 0.5667462348937988
Validation loss: 1.6964319008652882

Epoch: 6| Step: 12
Training loss: 0.48679181933403015
Validation loss: 1.7221142220240768

Epoch: 6| Step: 13
Training loss: 0.4786219000816345
Validation loss: 1.7331731447609522

Epoch: 297| Step: 0
Training loss: 0.35166794061660767
Validation loss: 1.6842369494899627

Epoch: 6| Step: 1
Training loss: 0.641934871673584
Validation loss: 1.7147486658506497

Epoch: 6| Step: 2
Training loss: 0.5894213914871216
Validation loss: 1.7136714061101277

Epoch: 6| Step: 3
Training loss: 0.5933754444122314
Validation loss: 1.7166876305815995

Epoch: 6| Step: 4
Training loss: 0.45194581151008606
Validation loss: 1.7383076708803895

Epoch: 6| Step: 5
Training loss: 0.9915748834609985
Validation loss: 1.7560107067067137

Epoch: 6| Step: 6
Training loss: 0.3281474709510803
Validation loss: 1.7576367855072021

Epoch: 6| Step: 7
Training loss: 0.2132696807384491
Validation loss: 1.7175097850061232

Epoch: 6| Step: 8
Training loss: 0.5247451066970825
Validation loss: 1.7092036201107887

Epoch: 6| Step: 9
Training loss: 0.5138164758682251
Validation loss: 1.6946916644291212

Epoch: 6| Step: 10
Training loss: 0.5722165107727051
Validation loss: 1.6782510331881944

Epoch: 6| Step: 11
Training loss: 0.5741706490516663
Validation loss: 1.6970244543526762

Epoch: 6| Step: 12
Training loss: 0.4899716377258301
Validation loss: 1.6972873415998233

Epoch: 6| Step: 13
Training loss: 0.9512143731117249
Validation loss: 1.6833915274630311

Epoch: 298| Step: 0
Training loss: 0.42041727900505066
Validation loss: 1.7090936886366976

Epoch: 6| Step: 1
Training loss: 0.22150838375091553
Validation loss: 1.7143519924532982

Epoch: 6| Step: 2
Training loss: 0.28814029693603516
Validation loss: 1.7129813355784262

Epoch: 6| Step: 3
Training loss: 0.3538465201854706
Validation loss: 1.7439181394474481

Epoch: 6| Step: 4
Training loss: 0.8624098300933838
Validation loss: 1.7267111719295543

Epoch: 6| Step: 5
Training loss: 0.5386958122253418
Validation loss: 1.7388171867657733

Epoch: 6| Step: 6
Training loss: 0.8372279405593872
Validation loss: 1.7286760319945633

Epoch: 6| Step: 7
Training loss: 0.8826113343238831
Validation loss: 1.711430226602862

Epoch: 6| Step: 8
Training loss: 0.4423452317714691
Validation loss: 1.7122621510618476

Epoch: 6| Step: 9
Training loss: 0.4484546184539795
Validation loss: 1.7100738991973221

Epoch: 6| Step: 10
Training loss: 0.3034353256225586
Validation loss: 1.7139745796880415

Epoch: 6| Step: 11
Training loss: 0.5329703092575073
Validation loss: 1.6873642654829129

Epoch: 6| Step: 12
Training loss: 0.7010048627853394
Validation loss: 1.690287346480995

Epoch: 6| Step: 13
Training loss: 0.6089243292808533
Validation loss: 1.706025864488335

Epoch: 299| Step: 0
Training loss: 0.45141586661338806
Validation loss: 1.691063727101972

Epoch: 6| Step: 1
Training loss: 0.5378336906433105
Validation loss: 1.6955002841129099

Epoch: 6| Step: 2
Training loss: 0.3745496869087219
Validation loss: 1.7049056304398404

Epoch: 6| Step: 3
Training loss: 0.5338649749755859
Validation loss: 1.7026403962924916

Epoch: 6| Step: 4
Training loss: 1.0392193794250488
Validation loss: 1.7207003613953948

Epoch: 6| Step: 5
Training loss: 0.3655377924442291
Validation loss: 1.7158235862690916

Epoch: 6| Step: 6
Training loss: 0.40574055910110474
Validation loss: 1.7137399950335104

Epoch: 6| Step: 7
Training loss: 0.4091135263442993
Validation loss: 1.6828619100714242

Epoch: 6| Step: 8
Training loss: 0.7144503593444824
Validation loss: 1.6933725956947572

Epoch: 6| Step: 9
Training loss: 0.4524446725845337
Validation loss: 1.7006451519586707

Epoch: 6| Step: 10
Training loss: 0.287272572517395
Validation loss: 1.6593500548793423

Epoch: 6| Step: 11
Training loss: 0.44640445709228516
Validation loss: 1.6631551199061896

Epoch: 6| Step: 12
Training loss: 0.6739373803138733
Validation loss: 1.6671676276832499

Epoch: 6| Step: 13
Training loss: 0.5052751898765564
Validation loss: 1.6814540086253997

Epoch: 300| Step: 0
Training loss: 0.5571340918540955
Validation loss: 1.673001480358903

Epoch: 6| Step: 1
Training loss: 0.15462055802345276
Validation loss: 1.6938501942542292

Epoch: 6| Step: 2
Training loss: 0.7027684450149536
Validation loss: 1.6524077756430513

Epoch: 6| Step: 3
Training loss: 0.7248972058296204
Validation loss: 1.6776614086602324

Epoch: 6| Step: 4
Training loss: 0.594428539276123
Validation loss: 1.6785156521745908

Epoch: 6| Step: 5
Training loss: 0.5779805779457092
Validation loss: 1.6588023900985718

Epoch: 6| Step: 6
Training loss: 0.5347365736961365
Validation loss: 1.6539564030144804

Epoch: 6| Step: 7
Training loss: 0.35221344232559204
Validation loss: 1.6630949461331932

Epoch: 6| Step: 8
Training loss: 0.6331161260604858
Validation loss: 1.646799498988736

Epoch: 6| Step: 9
Training loss: 0.4235624074935913
Validation loss: 1.669117509677846

Epoch: 6| Step: 10
Training loss: 0.3508644700050354
Validation loss: 1.6895763233143797

Epoch: 6| Step: 11
Training loss: 0.8516029119491577
Validation loss: 1.6896380429626794

Epoch: 6| Step: 12
Training loss: 0.2788088321685791
Validation loss: 1.6793312129154

Epoch: 6| Step: 13
Training loss: 0.18890607357025146
Validation loss: 1.7103245360876924

Epoch: 301| Step: 0
Training loss: 0.556205689907074
Validation loss: 1.6912662085666452

Epoch: 6| Step: 1
Training loss: 0.4278683662414551
Validation loss: 1.6950494256070865

Epoch: 6| Step: 2
Training loss: 0.31515008211135864
Validation loss: 1.6803721125407884

Epoch: 6| Step: 3
Training loss: 0.3686784505844116
Validation loss: 1.6928918720573507

Epoch: 6| Step: 4
Training loss: 0.4802515208721161
Validation loss: 1.6639508508866834

Epoch: 6| Step: 5
Training loss: 0.3834621012210846
Validation loss: 1.6748512380866594

Epoch: 6| Step: 6
Training loss: 0.2813565135002136
Validation loss: 1.6746448227154311

Epoch: 6| Step: 7
Training loss: 0.5805887579917908
Validation loss: 1.6688089665546213

Epoch: 6| Step: 8
Training loss: 0.670081377029419
Validation loss: 1.6688931372857863

Epoch: 6| Step: 9
Training loss: 0.7744952440261841
Validation loss: 1.6775082798414334

Epoch: 6| Step: 10
Training loss: 0.6638709306716919
Validation loss: 1.6904991160156906

Epoch: 6| Step: 11
Training loss: 0.3292984962463379
Validation loss: 1.7106867169821134

Epoch: 6| Step: 12
Training loss: 0.3655050992965698
Validation loss: 1.6879211548836

Epoch: 6| Step: 13
Training loss: 0.8245449066162109
Validation loss: 1.6640097248938777

Epoch: 302| Step: 0
Training loss: 0.6929289102554321
Validation loss: 1.6511764218730312

Epoch: 6| Step: 1
Training loss: 0.5388473868370056
Validation loss: 1.6408043074351486

Epoch: 6| Step: 2
Training loss: 0.3653314709663391
Validation loss: 1.6492867021150486

Epoch: 6| Step: 3
Training loss: 0.7683016657829285
Validation loss: 1.650776950261926

Epoch: 6| Step: 4
Training loss: 0.3991403877735138
Validation loss: 1.6472209063909387

Epoch: 6| Step: 5
Training loss: 0.38961082696914673
Validation loss: 1.6567202268108245

Epoch: 6| Step: 6
Training loss: 0.6029142737388611
Validation loss: 1.678474671097212

Epoch: 6| Step: 7
Training loss: 0.8250417709350586
Validation loss: 1.6857757542722969

Epoch: 6| Step: 8
Training loss: 0.31560444831848145
Validation loss: 1.7045785803948679

Epoch: 6| Step: 9
Training loss: 0.34987446665763855
Validation loss: 1.700893735372892

Epoch: 6| Step: 10
Training loss: 0.5386812686920166
Validation loss: 1.7348789399670017

Epoch: 6| Step: 11
Training loss: 0.3785412609577179
Validation loss: 1.7087775763644968

Epoch: 6| Step: 12
Training loss: 0.6541564464569092
Validation loss: 1.7171714613514562

Epoch: 6| Step: 13
Training loss: 0.43089810013771057
Validation loss: 1.733909587706289

Epoch: 303| Step: 0
Training loss: 0.8182483315467834
Validation loss: 1.7592392121591875

Epoch: 6| Step: 1
Training loss: 0.5373193025588989
Validation loss: 1.7379718416480607

Epoch: 6| Step: 2
Training loss: 0.3912670910358429
Validation loss: 1.7679995221476401

Epoch: 6| Step: 3
Training loss: 0.4320020079612732
Validation loss: 1.765417383563134

Epoch: 6| Step: 4
Training loss: 0.6747477054595947
Validation loss: 1.7294188032868087

Epoch: 6| Step: 5
Training loss: 0.7232691049575806
Validation loss: 1.722702423731486

Epoch: 6| Step: 6
Training loss: 0.40822744369506836
Validation loss: 1.7402605548981698

Epoch: 6| Step: 7
Training loss: 0.36451464891433716
Validation loss: 1.739475869363354

Epoch: 6| Step: 8
Training loss: 0.5081847906112671
Validation loss: 1.7401282966777842

Epoch: 6| Step: 9
Training loss: 0.6382790803909302
Validation loss: 1.7552740522610244

Epoch: 6| Step: 10
Training loss: 0.6802184581756592
Validation loss: 1.7075871049716909

Epoch: 6| Step: 11
Training loss: 0.3715085983276367
Validation loss: 1.6726481760701826

Epoch: 6| Step: 12
Training loss: 0.3677929639816284
Validation loss: 1.6410810665417743

Epoch: 6| Step: 13
Training loss: 0.6399016380310059
Validation loss: 1.6515740502265193

Epoch: 304| Step: 0
Training loss: 0.4602697491645813
Validation loss: 1.6689645398047663

Epoch: 6| Step: 1
Training loss: 0.7084769606590271
Validation loss: 1.6390662808572092

Epoch: 6| Step: 2
Training loss: 0.7060946226119995
Validation loss: 1.6406556572965396

Epoch: 6| Step: 3
Training loss: 0.6087522506713867
Validation loss: 1.6498810552781629

Epoch: 6| Step: 4
Training loss: 0.9003273248672485
Validation loss: 1.669011587737709

Epoch: 6| Step: 5
Training loss: 0.4924928843975067
Validation loss: 1.6782108096666233

Epoch: 6| Step: 6
Training loss: 0.3934365510940552
Validation loss: 1.70309668074372

Epoch: 6| Step: 7
Training loss: 0.40091943740844727
Validation loss: 1.6942115483745452

Epoch: 6| Step: 8
Training loss: 0.4507102072238922
Validation loss: 1.7221082423322944

Epoch: 6| Step: 9
Training loss: 0.4194068908691406
Validation loss: 1.703698831219827

Epoch: 6| Step: 10
Training loss: 0.3072770833969116
Validation loss: 1.6813660219151487

Epoch: 6| Step: 11
Training loss: 0.4294881224632263
Validation loss: 1.6561911080473213

Epoch: 6| Step: 12
Training loss: 0.29289090633392334
Validation loss: 1.6680635201033724

Epoch: 6| Step: 13
Training loss: 0.6227689981460571
Validation loss: 1.7136968387070524

Epoch: 305| Step: 0
Training loss: 0.6577340364456177
Validation loss: 1.6706647834470194

Epoch: 6| Step: 1
Training loss: 0.5098422765731812
Validation loss: 1.6852010283418881

Epoch: 6| Step: 2
Training loss: 0.786988377571106
Validation loss: 1.6739653771923435

Epoch: 6| Step: 3
Training loss: 0.5436517000198364
Validation loss: 1.6820424269604426

Epoch: 6| Step: 4
Training loss: 0.5931594371795654
Validation loss: 1.6923306167766612

Epoch: 6| Step: 5
Training loss: 0.3592716455459595
Validation loss: 1.674345790698964

Epoch: 6| Step: 6
Training loss: 0.29396650195121765
Validation loss: 1.7211906627942157

Epoch: 6| Step: 7
Training loss: 0.6673758029937744
Validation loss: 1.7230890476575462

Epoch: 6| Step: 8
Training loss: 0.393984317779541
Validation loss: 1.7118151649352042

Epoch: 6| Step: 9
Training loss: 0.359477162361145
Validation loss: 1.6702257407608854

Epoch: 6| Step: 10
Training loss: 0.36436718702316284
Validation loss: 1.6702069979841991

Epoch: 6| Step: 11
Training loss: 0.5299813747406006
Validation loss: 1.6812008657763082

Epoch: 6| Step: 12
Training loss: 0.33111321926116943
Validation loss: 1.6763903351240261

Epoch: 6| Step: 13
Training loss: 0.424843966960907
Validation loss: 1.6868992236352736

Epoch: 306| Step: 0
Training loss: 0.4792293608188629
Validation loss: 1.6934105580852878

Epoch: 6| Step: 1
Training loss: 0.25128090381622314
Validation loss: 1.676656658931445

Epoch: 6| Step: 2
Training loss: 0.16216561198234558
Validation loss: 1.645401377831736

Epoch: 6| Step: 3
Training loss: 0.6766109466552734
Validation loss: 1.687578401257915

Epoch: 6| Step: 4
Training loss: 0.31191515922546387
Validation loss: 1.6874585356763614

Epoch: 6| Step: 5
Training loss: 0.3729003667831421
Validation loss: 1.6955099362199024

Epoch: 6| Step: 6
Training loss: 0.6439538598060608
Validation loss: 1.6385395719159035

Epoch: 6| Step: 7
Training loss: 0.6539336442947388
Validation loss: 1.698480447133382

Epoch: 6| Step: 8
Training loss: 0.3396468460559845
Validation loss: 1.6975448721198625

Epoch: 6| Step: 9
Training loss: 0.5260542631149292
Validation loss: 1.6780439269158147

Epoch: 6| Step: 10
Training loss: 0.7474974393844604
Validation loss: 1.7071421274574854

Epoch: 6| Step: 11
Training loss: 0.6357913017272949
Validation loss: 1.6890843094036143

Epoch: 6| Step: 12
Training loss: 0.4787774085998535
Validation loss: 1.7227037657973587

Epoch: 6| Step: 13
Training loss: 0.5082035660743713
Validation loss: 1.7469188795294812

Epoch: 307| Step: 0
Training loss: 0.5703564882278442
Validation loss: 1.7205017471826205

Epoch: 6| Step: 1
Training loss: 0.38618195056915283
Validation loss: 1.7003115966755857

Epoch: 6| Step: 2
Training loss: 0.4494672417640686
Validation loss: 1.701490476567258

Epoch: 6| Step: 3
Training loss: 0.5055125951766968
Validation loss: 1.7371339336518319

Epoch: 6| Step: 4
Training loss: 0.4599807560443878
Validation loss: 1.7017181201647686

Epoch: 6| Step: 5
Training loss: 0.5606207847595215
Validation loss: 1.6989388696609005

Epoch: 6| Step: 6
Training loss: 0.46029233932495117
Validation loss: 1.7004417142560404

Epoch: 6| Step: 7
Training loss: 0.6326788067817688
Validation loss: 1.710000172738106

Epoch: 6| Step: 8
Training loss: 0.5053232908248901
Validation loss: 1.6995373246490315

Epoch: 6| Step: 9
Training loss: 0.6215312480926514
Validation loss: 1.6975567084486767

Epoch: 6| Step: 10
Training loss: 0.45397254824638367
Validation loss: 1.7330076643215713

Epoch: 6| Step: 11
Training loss: 0.4620051980018616
Validation loss: 1.7091814279556274

Epoch: 6| Step: 12
Training loss: 0.3890378177165985
Validation loss: 1.672828370524991

Epoch: 6| Step: 13
Training loss: 0.3315817415714264
Validation loss: 1.708893875921926

Epoch: 308| Step: 0
Training loss: 0.42811471223831177
Validation loss: 1.6931432126670756

Epoch: 6| Step: 1
Training loss: 0.5250176191329956
Validation loss: 1.7175840716208182

Epoch: 6| Step: 2
Training loss: 0.7807403802871704
Validation loss: 1.7314903723296298

Epoch: 6| Step: 3
Training loss: 0.19327476620674133
Validation loss: 1.7419529743092035

Epoch: 6| Step: 4
Training loss: 0.7029456496238708
Validation loss: 1.7420980353509226

Epoch: 6| Step: 5
Training loss: 0.491573691368103
Validation loss: 1.7547158092580817

Epoch: 6| Step: 6
Training loss: 0.3874141275882721
Validation loss: 1.7343312053270237

Epoch: 6| Step: 7
Training loss: 0.23658005893230438
Validation loss: 1.7149688556630125

Epoch: 6| Step: 8
Training loss: 0.6217926740646362
Validation loss: 1.7518592598617717

Epoch: 6| Step: 9
Training loss: 0.49582746624946594
Validation loss: 1.706360004281485

Epoch: 6| Step: 10
Training loss: 0.3914605975151062
Validation loss: 1.704951109424714

Epoch: 6| Step: 11
Training loss: 0.4211193025112152
Validation loss: 1.7116893529891968

Epoch: 6| Step: 12
Training loss: 0.5574356317520142
Validation loss: 1.6857047388630528

Epoch: 6| Step: 13
Training loss: 0.38104474544525146
Validation loss: 1.6587609065476285

Epoch: 309| Step: 0
Training loss: 0.4044479429721832
Validation loss: 1.6681453540760984

Epoch: 6| Step: 1
Training loss: 0.42413610219955444
Validation loss: 1.6690162048544934

Epoch: 6| Step: 2
Training loss: 0.6024487614631653
Validation loss: 1.67350818393051

Epoch: 6| Step: 3
Training loss: 0.477396696805954
Validation loss: 1.6654228689850017

Epoch: 6| Step: 4
Training loss: 0.5710747241973877
Validation loss: 1.68210671922212

Epoch: 6| Step: 5
Training loss: 0.609505295753479
Validation loss: 1.6905916736971947

Epoch: 6| Step: 6
Training loss: 0.2853345274925232
Validation loss: 1.679063573960335

Epoch: 6| Step: 7
Training loss: 0.3567369878292084
Validation loss: 1.6859841705650411

Epoch: 6| Step: 8
Training loss: 0.6685172319412231
Validation loss: 1.7240655678574757

Epoch: 6| Step: 9
Training loss: 0.4814896285533905
Validation loss: 1.7243839553607407

Epoch: 6| Step: 10
Training loss: 0.3854281008243561
Validation loss: 1.7086129752538537

Epoch: 6| Step: 11
Training loss: 0.36652040481567383
Validation loss: 1.6775881180199244

Epoch: 6| Step: 12
Training loss: 0.4831545948982239
Validation loss: 1.692089388447423

Epoch: 6| Step: 13
Training loss: 0.2597341537475586
Validation loss: 1.663851038743091

Epoch: 310| Step: 0
Training loss: 0.4371955394744873
Validation loss: 1.661216107747888

Epoch: 6| Step: 1
Training loss: 0.49974900484085083
Validation loss: 1.6265171445826048

Epoch: 6| Step: 2
Training loss: 0.27465179562568665
Validation loss: 1.6673781269340104

Epoch: 6| Step: 3
Training loss: 0.8656467795372009
Validation loss: 1.6492891978192072

Epoch: 6| Step: 4
Training loss: 0.4138193428516388
Validation loss: 1.6449480505399807

Epoch: 6| Step: 5
Training loss: 0.49731096625328064
Validation loss: 1.6502592050901024

Epoch: 6| Step: 6
Training loss: 0.5154396295547485
Validation loss: 1.6571286391186457

Epoch: 6| Step: 7
Training loss: 0.3561275005340576
Validation loss: 1.6493034029519686

Epoch: 6| Step: 8
Training loss: 0.4181516766548157
Validation loss: 1.6738846853215208

Epoch: 6| Step: 9
Training loss: 0.35620325803756714
Validation loss: 1.6360196785260273

Epoch: 6| Step: 10
Training loss: 0.4467923641204834
Validation loss: 1.6509817441304524

Epoch: 6| Step: 11
Training loss: 0.34265464544296265
Validation loss: 1.6349950593004945

Epoch: 6| Step: 12
Training loss: 0.5318986177444458
Validation loss: 1.6600675288067068

Epoch: 6| Step: 13
Training loss: 0.20005816221237183
Validation loss: 1.6660587082626999

Epoch: 311| Step: 0
Training loss: 0.39741232991218567
Validation loss: 1.644807247705357

Epoch: 6| Step: 1
Training loss: 0.5610608458518982
Validation loss: 1.6613442026158816

Epoch: 6| Step: 2
Training loss: 0.33413320779800415
Validation loss: 1.6677735172292238

Epoch: 6| Step: 3
Training loss: 0.20035098493099213
Validation loss: 1.683428136251306

Epoch: 6| Step: 4
Training loss: 0.45759594440460205
Validation loss: 1.7021152486083329

Epoch: 6| Step: 5
Training loss: 0.5148621797561646
Validation loss: 1.6873700182924989

Epoch: 6| Step: 6
Training loss: 0.36325669288635254
Validation loss: 1.702036185931134

Epoch: 6| Step: 7
Training loss: 0.3267207145690918
Validation loss: 1.6800080114795315

Epoch: 6| Step: 8
Training loss: 0.5499224066734314
Validation loss: 1.662038654409429

Epoch: 6| Step: 9
Training loss: 0.4720853865146637
Validation loss: 1.6212804253383348

Epoch: 6| Step: 10
Training loss: 0.7073440551757812
Validation loss: 1.6341621773217314

Epoch: 6| Step: 11
Training loss: 0.5430828332901001
Validation loss: 1.6247571373498568

Epoch: 6| Step: 12
Training loss: 0.40521296858787537
Validation loss: 1.6087863727282452

Epoch: 6| Step: 13
Training loss: 0.23783662915229797
Validation loss: 1.6207325279071767

Epoch: 312| Step: 0
Training loss: 0.4420676827430725
Validation loss: 1.6266283809497792

Epoch: 6| Step: 1
Training loss: 0.38294610381126404
Validation loss: 1.652570524523335

Epoch: 6| Step: 2
Training loss: 0.2536565065383911
Validation loss: 1.659074539779335

Epoch: 6| Step: 3
Training loss: 0.25041860342025757
Validation loss: 1.66035093286986

Epoch: 6| Step: 4
Training loss: 0.4164104461669922
Validation loss: 1.7190938431729552

Epoch: 6| Step: 5
Training loss: 0.5468252301216125
Validation loss: 1.6872703388173094

Epoch: 6| Step: 6
Training loss: 0.5344969630241394
Validation loss: 1.6987269616896106

Epoch: 6| Step: 7
Training loss: 0.3792322874069214
Validation loss: 1.684156294791929

Epoch: 6| Step: 8
Training loss: 0.39665961265563965
Validation loss: 1.699801193770542

Epoch: 6| Step: 9
Training loss: 0.4844532012939453
Validation loss: 1.7072194814682007

Epoch: 6| Step: 10
Training loss: 0.7008807063102722
Validation loss: 1.7018755366725307

Epoch: 6| Step: 11
Training loss: 0.17815233767032623
Validation loss: 1.7053682393925165

Epoch: 6| Step: 12
Training loss: 0.48527970910072327
Validation loss: 1.7015317268269037

Epoch: 6| Step: 13
Training loss: 0.6384838819503784
Validation loss: 1.7091291886503979

Epoch: 313| Step: 0
Training loss: 0.3625583052635193
Validation loss: 1.6682495865770566

Epoch: 6| Step: 1
Training loss: 0.34947073459625244
Validation loss: 1.66257575122259

Epoch: 6| Step: 2
Training loss: 0.7232275605201721
Validation loss: 1.6497509479522705

Epoch: 6| Step: 3
Training loss: 0.36600765585899353
Validation loss: 1.6147355341142224

Epoch: 6| Step: 4
Training loss: 0.4277143180370331
Validation loss: 1.6384499406301847

Epoch: 6| Step: 5
Training loss: 0.2965453565120697
Validation loss: 1.656778065107202

Epoch: 6| Step: 6
Training loss: 0.9266438484191895
Validation loss: 1.6557036554941567

Epoch: 6| Step: 7
Training loss: 0.44231465458869934
Validation loss: 1.6682795196451166

Epoch: 6| Step: 8
Training loss: 0.3222292363643646
Validation loss: 1.6692534954317155

Epoch: 6| Step: 9
Training loss: 0.37476518750190735
Validation loss: 1.6970793803532918

Epoch: 6| Step: 10
Training loss: 0.5069112181663513
Validation loss: 1.7140014786874094

Epoch: 6| Step: 11
Training loss: 0.3017328381538391
Validation loss: 1.7280567506308198

Epoch: 6| Step: 12
Training loss: 0.6047970056533813
Validation loss: 1.7273671088680145

Epoch: 6| Step: 13
Training loss: 0.0787564143538475
Validation loss: 1.6768528325583345

Epoch: 314| Step: 0
Training loss: 0.7647373676300049
Validation loss: 1.6911770694999284

Epoch: 6| Step: 1
Training loss: 0.315310001373291
Validation loss: 1.654475035205964

Epoch: 6| Step: 2
Training loss: 0.3317732512950897
Validation loss: 1.6628747012025566

Epoch: 6| Step: 3
Training loss: 0.39572882652282715
Validation loss: 1.6411156180084392

Epoch: 6| Step: 4
Training loss: 0.28258126974105835
Validation loss: 1.6602670556755477

Epoch: 6| Step: 5
Training loss: 0.5064828991889954
Validation loss: 1.6628415533291396

Epoch: 6| Step: 6
Training loss: 0.40922603011131287
Validation loss: 1.6602911141610914

Epoch: 6| Step: 7
Training loss: 0.3102321922779083
Validation loss: 1.6667994453061012

Epoch: 6| Step: 8
Training loss: 0.5891743898391724
Validation loss: 1.686905796809863

Epoch: 6| Step: 9
Training loss: 0.5299243330955505
Validation loss: 1.6674535146323584

Epoch: 6| Step: 10
Training loss: 0.6128475666046143
Validation loss: 1.7185404172507666

Epoch: 6| Step: 11
Training loss: 0.3964017629623413
Validation loss: 1.6650362053225118

Epoch: 6| Step: 12
Training loss: 0.39708542823791504
Validation loss: 1.6803368265910814

Epoch: 6| Step: 13
Training loss: 0.39614197611808777
Validation loss: 1.6537641248395365

Epoch: 315| Step: 0
Training loss: 0.5880446434020996
Validation loss: 1.6507344527911114

Epoch: 6| Step: 1
Training loss: 0.37887483835220337
Validation loss: 1.658209047009868

Epoch: 6| Step: 2
Training loss: 0.28644904494285583
Validation loss: 1.6838677698566067

Epoch: 6| Step: 3
Training loss: 0.1505439281463623
Validation loss: 1.6356968187516736

Epoch: 6| Step: 4
Training loss: 0.5206184983253479
Validation loss: 1.6445660975671583

Epoch: 6| Step: 5
Training loss: 0.3411019444465637
Validation loss: 1.6619959928656136

Epoch: 6| Step: 6
Training loss: 0.42018115520477295
Validation loss: 1.6477016966830018

Epoch: 6| Step: 7
Training loss: 0.31404560804367065
Validation loss: 1.6481461832600255

Epoch: 6| Step: 8
Training loss: 0.24327963590621948
Validation loss: 1.6587995047210364

Epoch: 6| Step: 9
Training loss: 0.7832504510879517
Validation loss: 1.6883852892024542

Epoch: 6| Step: 10
Training loss: 0.5574394464492798
Validation loss: 1.6723311690873996

Epoch: 6| Step: 11
Training loss: 0.6057084202766418
Validation loss: 1.6501192931205995

Epoch: 6| Step: 12
Training loss: 0.7539499998092651
Validation loss: 1.6752739491001252

Epoch: 6| Step: 13
Training loss: 0.6831604838371277
Validation loss: 1.6593882704293856

Epoch: 316| Step: 0
Training loss: 0.4066656827926636
Validation loss: 1.6508950674405662

Epoch: 6| Step: 1
Training loss: 0.43034178018569946
Validation loss: 1.657313089216909

Epoch: 6| Step: 2
Training loss: 0.5312739610671997
Validation loss: 1.6825146047017907

Epoch: 6| Step: 3
Training loss: 0.35640978813171387
Validation loss: 1.7288330998471988

Epoch: 6| Step: 4
Training loss: 0.8640407919883728
Validation loss: 1.7494836315031974

Epoch: 6| Step: 5
Training loss: 0.4709237813949585
Validation loss: 1.7924435959067395

Epoch: 6| Step: 6
Training loss: 0.438425749540329
Validation loss: 1.744769593720795

Epoch: 6| Step: 7
Training loss: 0.5723220109939575
Validation loss: 1.7177015812166276

Epoch: 6| Step: 8
Training loss: 0.3528147339820862
Validation loss: 1.6857561142213884

Epoch: 6| Step: 9
Training loss: 0.47265303134918213
Validation loss: 1.6951183196037047

Epoch: 6| Step: 10
Training loss: 0.5355724692344666
Validation loss: 1.7198408983087028

Epoch: 6| Step: 11
Training loss: 0.5703574419021606
Validation loss: 1.7465027263087611

Epoch: 6| Step: 12
Training loss: 0.32607024908065796
Validation loss: 1.7255404444151028

Epoch: 6| Step: 13
Training loss: 0.5183027386665344
Validation loss: 1.707474377847487

Epoch: 317| Step: 0
Training loss: 0.9275225400924683
Validation loss: 1.6819354231639574

Epoch: 6| Step: 1
Training loss: 0.33052876591682434
Validation loss: 1.6663284635031095

Epoch: 6| Step: 2
Training loss: 0.41705429553985596
Validation loss: 1.683503153503582

Epoch: 6| Step: 3
Training loss: 0.47869813442230225
Validation loss: 1.6850589295869232

Epoch: 6| Step: 4
Training loss: 0.28955233097076416
Validation loss: 1.6951779652667303

Epoch: 6| Step: 5
Training loss: 0.4679552912712097
Validation loss: 1.6815485646647792

Epoch: 6| Step: 6
Training loss: 0.447776734828949
Validation loss: 1.7020071860282653

Epoch: 6| Step: 7
Training loss: 0.2586005628108978
Validation loss: 1.6842547385923323

Epoch: 6| Step: 8
Training loss: 0.23540255427360535
Validation loss: 1.7001473788292176

Epoch: 6| Step: 9
Training loss: 0.5678244829177856
Validation loss: 1.6844490753707064

Epoch: 6| Step: 10
Training loss: 0.7467516660690308
Validation loss: 1.6733295763692548

Epoch: 6| Step: 11
Training loss: 0.28059959411621094
Validation loss: 1.652547114638872

Epoch: 6| Step: 12
Training loss: 0.7564777135848999
Validation loss: 1.6656991550999303

Epoch: 6| Step: 13
Training loss: 0.4493327736854553
Validation loss: 1.6830015618314025

Epoch: 318| Step: 0
Training loss: 0.44140100479125977
Validation loss: 1.6809131060877154

Epoch: 6| Step: 1
Training loss: 0.38147038221359253
Validation loss: 1.71499454334218

Epoch: 6| Step: 2
Training loss: 0.5076773166656494
Validation loss: 1.6724062286397463

Epoch: 6| Step: 3
Training loss: 0.4574728012084961
Validation loss: 1.6912959211616105

Epoch: 6| Step: 4
Training loss: 0.46427515149116516
Validation loss: 1.6466465470611409

Epoch: 6| Step: 5
Training loss: 0.4143443703651428
Validation loss: 1.6327016738153273

Epoch: 6| Step: 6
Training loss: 0.35599595308303833
Validation loss: 1.6419267897964807

Epoch: 6| Step: 7
Training loss: 0.5422637462615967
Validation loss: 1.6316131955833846

Epoch: 6| Step: 8
Training loss: 0.4267749786376953
Validation loss: 1.6738310142229962

Epoch: 6| Step: 9
Training loss: 0.3555378317832947
Validation loss: 1.7005778833102154

Epoch: 6| Step: 10
Training loss: 0.5432106256484985
Validation loss: 1.6763984593012

Epoch: 6| Step: 11
Training loss: 0.39197874069213867
Validation loss: 1.6708736086404452

Epoch: 6| Step: 12
Training loss: 0.35294079780578613
Validation loss: 1.7194892385954499

Epoch: 6| Step: 13
Training loss: 0.7328153252601624
Validation loss: 1.724056730988205

Epoch: 319| Step: 0
Training loss: 0.4105393886566162
Validation loss: 1.7108886831550187

Epoch: 6| Step: 1
Training loss: 0.44917723536491394
Validation loss: 1.7091508680774319

Epoch: 6| Step: 2
Training loss: 0.27500537037849426
Validation loss: 1.6901443658336517

Epoch: 6| Step: 3
Training loss: 0.36110880970954895
Validation loss: 1.700097180181934

Epoch: 6| Step: 4
Training loss: 0.6199914813041687
Validation loss: 1.695537551756828

Epoch: 6| Step: 5
Training loss: 0.3534015119075775
Validation loss: 1.6811762791807934

Epoch: 6| Step: 6
Training loss: 0.46645113825798035
Validation loss: 1.7152403400790306

Epoch: 6| Step: 7
Training loss: 0.38766422867774963
Validation loss: 1.6962779427087435

Epoch: 6| Step: 8
Training loss: 0.3075360655784607
Validation loss: 1.7354854922140799

Epoch: 6| Step: 9
Training loss: 0.23301668465137482
Validation loss: 1.6915860288245703

Epoch: 6| Step: 10
Training loss: 0.915031909942627
Validation loss: 1.7218412942783807

Epoch: 6| Step: 11
Training loss: 0.41902676224708557
Validation loss: 1.7099858189141879

Epoch: 6| Step: 12
Training loss: 0.3404815196990967
Validation loss: 1.7563371658325195

Epoch: 6| Step: 13
Training loss: 0.6723650693893433
Validation loss: 1.7790344274172218

Epoch: 320| Step: 0
Training loss: 0.3044092059135437
Validation loss: 1.7530836777020526

Epoch: 6| Step: 1
Training loss: 0.24657899141311646
Validation loss: 1.7449252195255731

Epoch: 6| Step: 2
Training loss: 0.5796716809272766
Validation loss: 1.7067741860625565

Epoch: 6| Step: 3
Training loss: 0.42557093501091003
Validation loss: 1.7289511798530497

Epoch: 6| Step: 4
Training loss: 0.712323784828186
Validation loss: 1.6882842945796188

Epoch: 6| Step: 5
Training loss: 0.33860236406326294
Validation loss: 1.6725355207279164

Epoch: 6| Step: 6
Training loss: 0.4800831377506256
Validation loss: 1.6871691737123715

Epoch: 6| Step: 7
Training loss: 0.127956360578537
Validation loss: 1.662661487056363

Epoch: 6| Step: 8
Training loss: 0.28787410259246826
Validation loss: 1.6560882445304625

Epoch: 6| Step: 9
Training loss: 0.4956440329551697
Validation loss: 1.626029952879875

Epoch: 6| Step: 10
Training loss: 0.9034520387649536
Validation loss: 1.6144955363324893

Epoch: 6| Step: 11
Training loss: 0.3591158986091614
Validation loss: 1.636250970184162

Epoch: 6| Step: 12
Training loss: 0.5003830790519714
Validation loss: 1.6054248245813514

Epoch: 6| Step: 13
Training loss: 0.4462743401527405
Validation loss: 1.654079250110093

Epoch: 321| Step: 0
Training loss: 0.5352278351783752
Validation loss: 1.6381320004822106

Epoch: 6| Step: 1
Training loss: 0.3004193902015686
Validation loss: 1.6958422301917948

Epoch: 6| Step: 2
Training loss: 0.3656679391860962
Validation loss: 1.6859280640079128

Epoch: 6| Step: 3
Training loss: 0.37092652916908264
Validation loss: 1.7198557943426154

Epoch: 6| Step: 4
Training loss: 0.4765110909938812
Validation loss: 1.6845464937148555

Epoch: 6| Step: 5
Training loss: 0.7142669558525085
Validation loss: 1.6716908395931285

Epoch: 6| Step: 6
Training loss: 0.42480698227882385
Validation loss: 1.6713401476542156

Epoch: 6| Step: 7
Training loss: 0.35031020641326904
Validation loss: 1.6588848944633239

Epoch: 6| Step: 8
Training loss: 0.4276542365550995
Validation loss: 1.6387751935630717

Epoch: 6| Step: 9
Training loss: 0.4846052825450897
Validation loss: 1.6319141669939923

Epoch: 6| Step: 10
Training loss: 0.31359782814979553
Validation loss: 1.6377951765573153

Epoch: 6| Step: 11
Training loss: 0.2973986864089966
Validation loss: 1.631930342284582

Epoch: 6| Step: 12
Training loss: 0.24502459168434143
Validation loss: 1.6420014955664193

Epoch: 6| Step: 13
Training loss: 0.17457333207130432
Validation loss: 1.6193403210691226

Epoch: 322| Step: 0
Training loss: 0.451396107673645
Validation loss: 1.6532063971283615

Epoch: 6| Step: 1
Training loss: 0.18550291657447815
Validation loss: 1.6223081786145446

Epoch: 6| Step: 2
Training loss: 0.3536774516105652
Validation loss: 1.6398442650354037

Epoch: 6| Step: 3
Training loss: 0.27987128496170044
Validation loss: 1.6279076478814567

Epoch: 6| Step: 4
Training loss: 0.4774990975856781
Validation loss: 1.6620125270658923

Epoch: 6| Step: 5
Training loss: 0.2739875614643097
Validation loss: 1.636164362712573

Epoch: 6| Step: 6
Training loss: 0.4993436336517334
Validation loss: 1.6697974563926778

Epoch: 6| Step: 7
Training loss: 0.5159714221954346
Validation loss: 1.6280700083701842

Epoch: 6| Step: 8
Training loss: 0.35284367203712463
Validation loss: 1.6330860237921438

Epoch: 6| Step: 9
Training loss: 0.36271876096725464
Validation loss: 1.6551790057971913

Epoch: 6| Step: 10
Training loss: 0.39047741889953613
Validation loss: 1.6727662394123692

Epoch: 6| Step: 11
Training loss: 0.8174073100090027
Validation loss: 1.6632122660195956

Epoch: 6| Step: 12
Training loss: 0.26704925298690796
Validation loss: 1.6639838513507639

Epoch: 6| Step: 13
Training loss: 0.24011993408203125
Validation loss: 1.6712437739936254

Epoch: 323| Step: 0
Training loss: 0.2826235890388489
Validation loss: 1.6489596136154667

Epoch: 6| Step: 1
Training loss: 0.5197333693504333
Validation loss: 1.6542300319158902

Epoch: 6| Step: 2
Training loss: 0.5336498022079468
Validation loss: 1.6746002281865766

Epoch: 6| Step: 3
Training loss: 0.2524186968803406
Validation loss: 1.6893849565136818

Epoch: 6| Step: 4
Training loss: 0.2583359479904175
Validation loss: 1.649178481871082

Epoch: 6| Step: 5
Training loss: 0.3836521804332733
Validation loss: 1.6351739783440866

Epoch: 6| Step: 6
Training loss: 0.39292600750923157
Validation loss: 1.64313204057755

Epoch: 6| Step: 7
Training loss: 0.4243127107620239
Validation loss: 1.6341507819391066

Epoch: 6| Step: 8
Training loss: 0.410147488117218
Validation loss: 1.6722028781008977

Epoch: 6| Step: 9
Training loss: 0.3036971688270569
Validation loss: 1.6240574698294363

Epoch: 6| Step: 10
Training loss: 0.7042975425720215
Validation loss: 1.6551773291762157

Epoch: 6| Step: 11
Training loss: 0.3201824426651001
Validation loss: 1.6573832701611262

Epoch: 6| Step: 12
Training loss: 0.39640671014785767
Validation loss: 1.6238260653711134

Epoch: 6| Step: 13
Training loss: 0.276422381401062
Validation loss: 1.6326682734233078

Epoch: 324| Step: 0
Training loss: 0.2601792812347412
Validation loss: 1.6821483873551892

Epoch: 6| Step: 1
Training loss: 0.5239319801330566
Validation loss: 1.6576900161722654

Epoch: 6| Step: 2
Training loss: 0.3993017077445984
Validation loss: 1.6874028751927037

Epoch: 6| Step: 3
Training loss: 0.4725818634033203
Validation loss: 1.6888256829272035

Epoch: 6| Step: 4
Training loss: 0.6674860715866089
Validation loss: 1.6717101579071374

Epoch: 6| Step: 5
Training loss: 0.25799956917762756
Validation loss: 1.666365638855965

Epoch: 6| Step: 6
Training loss: 0.3482125401496887
Validation loss: 1.6225877192712599

Epoch: 6| Step: 7
Training loss: 0.25580888986587524
Validation loss: 1.6361669660896383

Epoch: 6| Step: 8
Training loss: 0.6647362112998962
Validation loss: 1.6014301289794266

Epoch: 6| Step: 9
Training loss: 0.411877304315567
Validation loss: 1.6047956764057119

Epoch: 6| Step: 10
Training loss: 0.1988627314567566
Validation loss: 1.565174723184237

Epoch: 6| Step: 11
Training loss: 0.4650062322616577
Validation loss: 1.6572157721365652

Epoch: 6| Step: 12
Training loss: 0.7186707854270935
Validation loss: 1.6633705862106816

Epoch: 6| Step: 13
Training loss: 0.5981778502464294
Validation loss: 1.6316085553938342

Epoch: 325| Step: 0
Training loss: 0.3938189446926117
Validation loss: 1.611242542984665

Epoch: 6| Step: 1
Training loss: 0.4322035014629364
Validation loss: 1.5418356080209055

Epoch: 6| Step: 2
Training loss: 0.23530495166778564
Validation loss: 1.59951598669893

Epoch: 6| Step: 3
Training loss: 0.30744269490242004
Validation loss: 1.5877431272178568

Epoch: 6| Step: 4
Training loss: 0.49406659603118896
Validation loss: 1.5709217158696984

Epoch: 6| Step: 5
Training loss: 0.5218586921691895
Validation loss: 1.5960556819874754

Epoch: 6| Step: 6
Training loss: 0.4370502829551697
Validation loss: 1.6435631577686598

Epoch: 6| Step: 7
Training loss: 0.3905053436756134
Validation loss: 1.6634142334743212

Epoch: 6| Step: 8
Training loss: 0.4143534302711487
Validation loss: 1.7239213758899319

Epoch: 6| Step: 9
Training loss: 0.7372744083404541
Validation loss: 1.7628154241910545

Epoch: 6| Step: 10
Training loss: 0.5449907183647156
Validation loss: 1.7725639343261719

Epoch: 6| Step: 11
Training loss: 0.3911733627319336
Validation loss: 1.748524050558767

Epoch: 6| Step: 12
Training loss: 0.41824591159820557
Validation loss: 1.7251368684153403

Epoch: 6| Step: 13
Training loss: 0.138010174036026
Validation loss: 1.66730543105833

Epoch: 326| Step: 0
Training loss: 0.4666164517402649
Validation loss: 1.6629727514841224

Epoch: 6| Step: 1
Training loss: 0.32387059926986694
Validation loss: 1.6296374669639013

Epoch: 6| Step: 2
Training loss: 0.5566325187683105
Validation loss: 1.6294554664242653

Epoch: 6| Step: 3
Training loss: 0.36581653356552124
Validation loss: 1.6234089379669518

Epoch: 6| Step: 4
Training loss: 0.2582148611545563
Validation loss: 1.5865059975654847

Epoch: 6| Step: 5
Training loss: 0.34518420696258545
Validation loss: 1.6220033745611868

Epoch: 6| Step: 6
Training loss: 0.32655274868011475
Validation loss: 1.6405572045233943

Epoch: 6| Step: 7
Training loss: 0.28246375918388367
Validation loss: 1.615685962861584

Epoch: 6| Step: 8
Training loss: 0.5161892771720886
Validation loss: 1.6111605808299074

Epoch: 6| Step: 9
Training loss: 0.3396832346916199
Validation loss: 1.6261714209792435

Epoch: 6| Step: 10
Training loss: 0.4175419807434082
Validation loss: 1.6241410432323333

Epoch: 6| Step: 11
Training loss: 0.4716476798057556
Validation loss: 1.5914690699628604

Epoch: 6| Step: 12
Training loss: 0.4060506224632263
Validation loss: 1.6095514233394335

Epoch: 6| Step: 13
Training loss: 0.23316730558872223
Validation loss: 1.5897837736273324

Epoch: 327| Step: 0
Training loss: 0.3035658597946167
Validation loss: 1.6486254110131213

Epoch: 6| Step: 1
Training loss: 0.3064178228378296
Validation loss: 1.6556439553537676

Epoch: 6| Step: 2
Training loss: 0.3163161277770996
Validation loss: 1.648542865630119

Epoch: 6| Step: 3
Training loss: 0.15093383193016052
Validation loss: 1.6374837326747116

Epoch: 6| Step: 4
Training loss: 0.517189085483551
Validation loss: 1.6199690513713385

Epoch: 6| Step: 5
Training loss: 0.4263085126876831
Validation loss: 1.6160541413932719

Epoch: 6| Step: 6
Training loss: 0.6141149997711182
Validation loss: 1.6385344920619842

Epoch: 6| Step: 7
Training loss: 0.7044719457626343
Validation loss: 1.6412351810803978

Epoch: 6| Step: 8
Training loss: 0.5100970268249512
Validation loss: 1.615011748447213

Epoch: 6| Step: 9
Training loss: 0.5827961564064026
Validation loss: 1.6415518637626403

Epoch: 6| Step: 10
Training loss: 0.3095555007457733
Validation loss: 1.6538441104273642

Epoch: 6| Step: 11
Training loss: 0.3247228264808655
Validation loss: 1.6231951226470291

Epoch: 6| Step: 12
Training loss: 0.2710403501987457
Validation loss: 1.6206769507418397

Epoch: 6| Step: 13
Training loss: 0.22323375940322876
Validation loss: 1.6024913864751016

Epoch: 328| Step: 0
Training loss: 0.25785374641418457
Validation loss: 1.6506598136758293

Epoch: 6| Step: 1
Training loss: 0.6201010942459106
Validation loss: 1.6577117314902685

Epoch: 6| Step: 2
Training loss: 0.38383400440216064
Validation loss: 1.6632797525775047

Epoch: 6| Step: 3
Training loss: 0.5919784307479858
Validation loss: 1.687919278298655

Epoch: 6| Step: 4
Training loss: 0.20746475458145142
Validation loss: 1.656505270670819

Epoch: 6| Step: 5
Training loss: 0.3102201521396637
Validation loss: 1.6381817005013908

Epoch: 6| Step: 6
Training loss: 0.24302655458450317
Validation loss: 1.6045099766023698

Epoch: 6| Step: 7
Training loss: 0.6786162853240967
Validation loss: 1.592039963250519

Epoch: 6| Step: 8
Training loss: 0.23774836957454681
Validation loss: 1.5780550485016198

Epoch: 6| Step: 9
Training loss: 0.6269962787628174
Validation loss: 1.5571775500492384

Epoch: 6| Step: 10
Training loss: 0.2908448874950409
Validation loss: 1.5695965930979738

Epoch: 6| Step: 11
Training loss: 0.21238884329795837
Validation loss: 1.5472692687024352

Epoch: 6| Step: 12
Training loss: 0.32781553268432617
Validation loss: 1.6002436478932698

Epoch: 6| Step: 13
Training loss: 0.250223845243454
Validation loss: 1.5596457617257231

Epoch: 329| Step: 0
Training loss: 0.20580554008483887
Validation loss: 1.5471481354005876

Epoch: 6| Step: 1
Training loss: 0.3365813195705414
Validation loss: 1.5602101779753161

Epoch: 6| Step: 2
Training loss: 0.4972584843635559
Validation loss: 1.5761194177853164

Epoch: 6| Step: 3
Training loss: 0.3767749071121216
Validation loss: 1.5959712177194574

Epoch: 6| Step: 4
Training loss: 0.4944669306278229
Validation loss: 1.5898323847401528

Epoch: 6| Step: 5
Training loss: 0.3049979507923126
Validation loss: 1.6153348850947555

Epoch: 6| Step: 6
Training loss: 0.2524155378341675
Validation loss: 1.6538526281233756

Epoch: 6| Step: 7
Training loss: 0.24971479177474976
Validation loss: 1.624640412868992

Epoch: 6| Step: 8
Training loss: 0.4106673002243042
Validation loss: 1.6361477118666454

Epoch: 6| Step: 9
Training loss: 0.3804832100868225
Validation loss: 1.6335872578364548

Epoch: 6| Step: 10
Training loss: 0.6382051110267639
Validation loss: 1.6571572070480676

Epoch: 6| Step: 11
Training loss: 0.3502686023712158
Validation loss: 1.6701781083178777

Epoch: 6| Step: 12
Training loss: 0.4520832598209381
Validation loss: 1.6527576613169845

Epoch: 6| Step: 13
Training loss: 0.18042537569999695
Validation loss: 1.6731122770617086

Epoch: 330| Step: 0
Training loss: 0.308915376663208
Validation loss: 1.6926863936967746

Epoch: 6| Step: 1
Training loss: 0.5138474702835083
Validation loss: 1.7348154821703512

Epoch: 6| Step: 2
Training loss: 0.24305470287799835
Validation loss: 1.7618328166264359

Epoch: 6| Step: 3
Training loss: 0.5282598733901978
Validation loss: 1.7377694153016614

Epoch: 6| Step: 4
Training loss: 0.5138261318206787
Validation loss: 1.7379364057253766

Epoch: 6| Step: 5
Training loss: 0.29202553629875183
Validation loss: 1.704685212463461

Epoch: 6| Step: 6
Training loss: 0.33016860485076904
Validation loss: 1.6650452113920642

Epoch: 6| Step: 7
Training loss: 0.3988693356513977
Validation loss: 1.6282843082181868

Epoch: 6| Step: 8
Training loss: 0.3293197751045227
Validation loss: 1.605300312401146

Epoch: 6| Step: 9
Training loss: 0.36175480484962463
Validation loss: 1.6673931332044705

Epoch: 6| Step: 10
Training loss: 0.4173884391784668
Validation loss: 1.6151372399381412

Epoch: 6| Step: 11
Training loss: 0.20490124821662903
Validation loss: 1.6324621451798307

Epoch: 6| Step: 12
Training loss: 0.13602189719676971
Validation loss: 1.6409534139017905

Epoch: 6| Step: 13
Training loss: 0.4605522155761719
Validation loss: 1.621185330934422

Epoch: 331| Step: 0
Training loss: 0.45803123712539673
Validation loss: 1.6001607448823991

Epoch: 6| Step: 1
Training loss: 0.3231082558631897
Validation loss: 1.603627480486388

Epoch: 6| Step: 2
Training loss: 0.18141308426856995
Validation loss: 1.6090335384491952

Epoch: 6| Step: 3
Training loss: 0.3812413513660431
Validation loss: 1.5911275443210398

Epoch: 6| Step: 4
Training loss: 0.2511245012283325
Validation loss: 1.587638407625178

Epoch: 6| Step: 5
Training loss: 0.24402660131454468
Validation loss: 1.5967223375074324

Epoch: 6| Step: 6
Training loss: 0.5068562030792236
Validation loss: 1.5970399751458118

Epoch: 6| Step: 7
Training loss: 0.34718483686447144
Validation loss: 1.6158124028995473

Epoch: 6| Step: 8
Training loss: 0.5034765005111694
Validation loss: 1.6414162356366393

Epoch: 6| Step: 9
Training loss: 0.381669819355011
Validation loss: 1.6445515066064813

Epoch: 6| Step: 10
Training loss: 0.3353494107723236
Validation loss: 1.6177424833338747

Epoch: 6| Step: 11
Training loss: 0.35163623094558716
Validation loss: 1.6292095889327347

Epoch: 6| Step: 12
Training loss: 0.4537190794944763
Validation loss: 1.630407948647776

Epoch: 6| Step: 13
Training loss: 0.3279055953025818
Validation loss: 1.6753474679044498

Epoch: 332| Step: 0
Training loss: 0.42551660537719727
Validation loss: 1.639234942774619

Epoch: 6| Step: 1
Training loss: 0.27402520179748535
Validation loss: 1.5960842332532328

Epoch: 6| Step: 2
Training loss: 0.556454062461853
Validation loss: 1.6049155548054685

Epoch: 6| Step: 3
Training loss: 0.3182682394981384
Validation loss: 1.5761267510793542

Epoch: 6| Step: 4
Training loss: 0.23975352942943573
Validation loss: 1.5597746628586964

Epoch: 6| Step: 5
Training loss: 0.3999975919723511
Validation loss: 1.5846920051882345

Epoch: 6| Step: 6
Training loss: 0.40706342458724976
Validation loss: 1.5886066177839875

Epoch: 6| Step: 7
Training loss: 0.2842783033847809
Validation loss: 1.5987904417899348

Epoch: 6| Step: 8
Training loss: 0.35619527101516724
Validation loss: 1.5922966669964533

Epoch: 6| Step: 9
Training loss: 0.38659435510635376
Validation loss: 1.6297457859080324

Epoch: 6| Step: 10
Training loss: 0.42270228266716003
Validation loss: 1.6441354187585975

Epoch: 6| Step: 11
Training loss: 0.27070868015289307
Validation loss: 1.6668425260051605

Epoch: 6| Step: 12
Training loss: 0.7640148997306824
Validation loss: 1.7198149658018542

Epoch: 6| Step: 13
Training loss: 0.34268853068351746
Validation loss: 1.7179784813234884

Epoch: 333| Step: 0
Training loss: 0.3565298318862915
Validation loss: 1.7349343684411818

Epoch: 6| Step: 1
Training loss: 0.21777132153511047
Validation loss: 1.7053302436746576

Epoch: 6| Step: 2
Training loss: 0.17784397304058075
Validation loss: 1.654862719197427

Epoch: 6| Step: 3
Training loss: 0.40210404992103577
Validation loss: 1.652256679791276

Epoch: 6| Step: 4
Training loss: 0.24656999111175537
Validation loss: 1.614250624051658

Epoch: 6| Step: 5
Training loss: 0.3779038190841675
Validation loss: 1.5900319250681068

Epoch: 6| Step: 6
Training loss: 0.39982932806015015
Validation loss: 1.573057843792823

Epoch: 6| Step: 7
Training loss: 0.6152521371841431
Validation loss: 1.575214018103897

Epoch: 6| Step: 8
Training loss: 0.2272348254919052
Validation loss: 1.5321701136968469

Epoch: 6| Step: 9
Training loss: 0.3342306613922119
Validation loss: 1.5641048851833548

Epoch: 6| Step: 10
Training loss: 0.2751551866531372
Validation loss: 1.6119546108348395

Epoch: 6| Step: 11
Training loss: 0.42398950457572937
Validation loss: 1.6247611712383967

Epoch: 6| Step: 12
Training loss: 0.36835694313049316
Validation loss: 1.6072871069754324

Epoch: 6| Step: 13
Training loss: 0.6206867694854736
Validation loss: 1.6126168286928566

Epoch: 334| Step: 0
Training loss: 0.3820244073867798
Validation loss: 1.6034443160539031

Epoch: 6| Step: 1
Training loss: 0.5377327799797058
Validation loss: 1.5638875448575584

Epoch: 6| Step: 2
Training loss: 0.7638875246047974
Validation loss: 1.61394142143188

Epoch: 6| Step: 3
Training loss: 0.25122764706611633
Validation loss: 1.605014334442795

Epoch: 6| Step: 4
Training loss: 0.25716254115104675
Validation loss: 1.6061151104588662

Epoch: 6| Step: 5
Training loss: 0.19406741857528687
Validation loss: 1.5822816330899474

Epoch: 6| Step: 6
Training loss: 0.299541175365448
Validation loss: 1.6266807381824782

Epoch: 6| Step: 7
Training loss: 0.5112330317497253
Validation loss: 1.578391994199445

Epoch: 6| Step: 8
Training loss: 0.4164646863937378
Validation loss: 1.6151119624414751

Epoch: 6| Step: 9
Training loss: 0.3070828914642334
Validation loss: 1.6285557157249861

Epoch: 6| Step: 10
Training loss: 0.29456162452697754
Validation loss: 1.6470552285512288

Epoch: 6| Step: 11
Training loss: 0.3640657067298889
Validation loss: 1.6498859941318471

Epoch: 6| Step: 12
Training loss: 0.18402481079101562
Validation loss: 1.6416258196676932

Epoch: 6| Step: 13
Training loss: 0.3548678457736969
Validation loss: 1.6647487699344594

Epoch: 335| Step: 0
Training loss: 0.1873777061700821
Validation loss: 1.6289904220129854

Epoch: 6| Step: 1
Training loss: 0.30433520674705505
Validation loss: 1.611126842037324

Epoch: 6| Step: 2
Training loss: 0.25206947326660156
Validation loss: 1.61316006670716

Epoch: 6| Step: 3
Training loss: 0.6464641690254211
Validation loss: 1.574761479131637

Epoch: 6| Step: 4
Training loss: 0.41300877928733826
Validation loss: 1.5795833885028798

Epoch: 6| Step: 5
Training loss: 0.41438716650009155
Validation loss: 1.591546526519201

Epoch: 6| Step: 6
Training loss: 0.22800618410110474
Validation loss: 1.5906255552845616

Epoch: 6| Step: 7
Training loss: 0.43239259719848633
Validation loss: 1.5857094398108862

Epoch: 6| Step: 8
Training loss: 0.2834567129611969
Validation loss: 1.6033967002745597

Epoch: 6| Step: 9
Training loss: 0.31396037340164185
Validation loss: 1.5859965201347106

Epoch: 6| Step: 10
Training loss: 0.2503150999546051
Validation loss: 1.6309096415837605

Epoch: 6| Step: 11
Training loss: 0.21701699495315552
Validation loss: 1.643757979075114

Epoch: 6| Step: 12
Training loss: 0.4656543731689453
Validation loss: 1.6171054019722888

Epoch: 6| Step: 13
Training loss: 0.5469080209732056
Validation loss: 1.6629246998858709

Epoch: 336| Step: 0
Training loss: 0.3181523084640503
Validation loss: 1.6580005012532717

Epoch: 6| Step: 1
Training loss: 0.49152860045433044
Validation loss: 1.6704157347320228

Epoch: 6| Step: 2
Training loss: 0.3430520296096802
Validation loss: 1.6642817028107182

Epoch: 6| Step: 3
Training loss: 0.2872545123100281
Validation loss: 1.656147865838902

Epoch: 6| Step: 4
Training loss: 0.2797020375728607
Validation loss: 1.670526107152303

Epoch: 6| Step: 5
Training loss: 0.41840165853500366
Validation loss: 1.6555349801176338

Epoch: 6| Step: 6
Training loss: 0.37069347500801086
Validation loss: 1.6325526763034124

Epoch: 6| Step: 7
Training loss: 0.22702351212501526
Validation loss: 1.625645322184409

Epoch: 6| Step: 8
Training loss: 0.3397397994995117
Validation loss: 1.6224752831202682

Epoch: 6| Step: 9
Training loss: 0.4051799178123474
Validation loss: 1.6424130829431678

Epoch: 6| Step: 10
Training loss: 0.3375244140625
Validation loss: 1.6516569199100617

Epoch: 6| Step: 11
Training loss: 0.19086569547653198
Validation loss: 1.65608230457511

Epoch: 6| Step: 12
Training loss: 0.41188615560531616
Validation loss: 1.667087375476796

Epoch: 6| Step: 13
Training loss: 0.288452684879303
Validation loss: 1.672137975692749

Epoch: 337| Step: 0
Training loss: 0.24103593826293945
Validation loss: 1.6589687370484876

Epoch: 6| Step: 1
Training loss: 0.19189494848251343
Validation loss: 1.662343099553098

Epoch: 6| Step: 2
Training loss: 0.35146206617355347
Validation loss: 1.630518772268808

Epoch: 6| Step: 3
Training loss: 0.33885282278060913
Validation loss: 1.615379887242471

Epoch: 6| Step: 4
Training loss: 0.18751250207424164
Validation loss: 1.5949797707219278

Epoch: 6| Step: 5
Training loss: 0.5245827436447144
Validation loss: 1.5984877309491556

Epoch: 6| Step: 6
Training loss: 0.24998347461223602
Validation loss: 1.6146582903400544

Epoch: 6| Step: 7
Training loss: 0.4116534888744354
Validation loss: 1.6711507407567834

Epoch: 6| Step: 8
Training loss: 0.31809201836586
Validation loss: 1.6831283325790076

Epoch: 6| Step: 9
Training loss: 0.5165557861328125
Validation loss: 1.7019620249348302

Epoch: 6| Step: 10
Training loss: 0.3545434772968292
Validation loss: 1.6724506847320064

Epoch: 6| Step: 11
Training loss: 0.2183612734079361
Validation loss: 1.645864882776814

Epoch: 6| Step: 12
Training loss: 0.32174357771873474
Validation loss: 1.6685368944239873

Epoch: 6| Step: 13
Training loss: 0.438104510307312
Validation loss: 1.6627508158324866

Epoch: 338| Step: 0
Training loss: 0.17420165240764618
Validation loss: 1.6661012787972727

Epoch: 6| Step: 1
Training loss: 0.2882811427116394
Validation loss: 1.6642856174899685

Epoch: 6| Step: 2
Training loss: 0.26533639430999756
Validation loss: 1.6543176251073037

Epoch: 6| Step: 3
Training loss: 0.37682443857192993
Validation loss: 1.6111626009787283

Epoch: 6| Step: 4
Training loss: 0.39053070545196533
Validation loss: 1.6166072801877094

Epoch: 6| Step: 5
Training loss: 0.5132128000259399
Validation loss: 1.6151270161392868

Epoch: 6| Step: 6
Training loss: 0.36555373668670654
Validation loss: 1.593188130086468

Epoch: 6| Step: 7
Training loss: 0.32680755853652954
Validation loss: 1.6005463420703847

Epoch: 6| Step: 8
Training loss: 0.42236629128456116
Validation loss: 1.5807366986428537

Epoch: 6| Step: 9
Training loss: 0.43030697107315063
Validation loss: 1.586458703523041

Epoch: 6| Step: 10
Training loss: 0.21852682530879974
Validation loss: 1.5963057266768588

Epoch: 6| Step: 11
Training loss: 0.21217778325080872
Validation loss: 1.6118950228537283

Epoch: 6| Step: 12
Training loss: 0.4027669429779053
Validation loss: 1.5990354643073132

Epoch: 6| Step: 13
Training loss: 0.37487226724624634
Validation loss: 1.6022984238081082

Epoch: 339| Step: 0
Training loss: 0.3509454131126404
Validation loss: 1.5640317618205983

Epoch: 6| Step: 1
Training loss: 0.12566599249839783
Validation loss: 1.5833701702856249

Epoch: 6| Step: 2
Training loss: 0.375124990940094
Validation loss: 1.5766890177162745

Epoch: 6| Step: 3
Training loss: 0.3477148115634918
Validation loss: 1.5533124323814147

Epoch: 6| Step: 4
Training loss: 0.1933557689189911
Validation loss: 1.5549827186010217

Epoch: 6| Step: 5
Training loss: 0.2492516040802002
Validation loss: 1.5675782849711757

Epoch: 6| Step: 6
Training loss: 0.2288927435874939
Validation loss: 1.5591597621158888

Epoch: 6| Step: 7
Training loss: 0.24641305208206177
Validation loss: 1.6129264177814606

Epoch: 6| Step: 8
Training loss: 0.47640174627304077
Validation loss: 1.575649521684134

Epoch: 6| Step: 9
Training loss: 0.3593347668647766
Validation loss: 1.5845094034748692

Epoch: 6| Step: 10
Training loss: 0.4028659462928772
Validation loss: 1.6283321867706955

Epoch: 6| Step: 11
Training loss: 0.2746797800064087
Validation loss: 1.6283326148986816

Epoch: 6| Step: 12
Training loss: 0.22433744370937347
Validation loss: 1.6156418349153252

Epoch: 6| Step: 13
Training loss: 0.46043920516967773
Validation loss: 1.639478354043858

Epoch: 340| Step: 0
Training loss: 0.20810629427433014
Validation loss: 1.6436652509115075

Epoch: 6| Step: 1
Training loss: 0.17181625962257385
Validation loss: 1.637313304408904

Epoch: 6| Step: 2
Training loss: 0.41720497608184814
Validation loss: 1.6232443509563323

Epoch: 6| Step: 3
Training loss: 0.18906179070472717
Validation loss: 1.6127278093368775

Epoch: 6| Step: 4
Training loss: 0.27924638986587524
Validation loss: 1.6291229840247863

Epoch: 6| Step: 5
Training loss: 0.22376544773578644
Validation loss: 1.6144266307994883

Epoch: 6| Step: 6
Training loss: 0.2922908663749695
Validation loss: 1.591399222291926

Epoch: 6| Step: 7
Training loss: 0.2821252942085266
Validation loss: 1.561707724807083

Epoch: 6| Step: 8
Training loss: 0.3926367163658142
Validation loss: 1.5515117209444764

Epoch: 6| Step: 9
Training loss: 0.3976671099662781
Validation loss: 1.5950175562212545

Epoch: 6| Step: 10
Training loss: 0.4202372133731842
Validation loss: 1.596711504843927

Epoch: 6| Step: 11
Training loss: 0.27199363708496094
Validation loss: 1.626264646489133

Epoch: 6| Step: 12
Training loss: 0.3228045105934143
Validation loss: 1.594267656726222

Epoch: 6| Step: 13
Training loss: 0.35644078254699707
Validation loss: 1.634372471481241

Epoch: 341| Step: 0
Training loss: 0.27701374888420105
Validation loss: 1.6228286297090593

Epoch: 6| Step: 1
Training loss: 0.42972332239151
Validation loss: 1.6107591659792009

Epoch: 6| Step: 2
Training loss: 0.3623315095901489
Validation loss: 1.6304032469308505

Epoch: 6| Step: 3
Training loss: 0.15090906620025635
Validation loss: 1.5928049779707385

Epoch: 6| Step: 4
Training loss: 0.28127914667129517
Validation loss: 1.6011440907755206

Epoch: 6| Step: 5
Training loss: 0.11204669624567032
Validation loss: 1.6246811023322485

Epoch: 6| Step: 6
Training loss: 0.4235568344593048
Validation loss: 1.6180536875160791

Epoch: 6| Step: 7
Training loss: 0.18408554792404175
Validation loss: 1.612408798228028

Epoch: 6| Step: 8
Training loss: 0.40797656774520874
Validation loss: 1.6044703452817854

Epoch: 6| Step: 9
Training loss: 0.31473207473754883
Validation loss: 1.6173297737234382

Epoch: 6| Step: 10
Training loss: 0.42199236154556274
Validation loss: 1.656413306472122

Epoch: 6| Step: 11
Training loss: 0.23591026663780212
Validation loss: 1.6227008693961686

Epoch: 6| Step: 12
Training loss: 0.25922977924346924
Validation loss: 1.6551965654537242

Epoch: 6| Step: 13
Training loss: 0.296761691570282
Validation loss: 1.648269002155591

Epoch: 342| Step: 0
Training loss: 0.24088549613952637
Validation loss: 1.6536324613837785

Epoch: 6| Step: 1
Training loss: 0.2661301791667938
Validation loss: 1.624844071685627

Epoch: 6| Step: 2
Training loss: 0.4224769175052643
Validation loss: 1.6480756357151976

Epoch: 6| Step: 3
Training loss: 0.2609425485134125
Validation loss: 1.6281202454720773

Epoch: 6| Step: 4
Training loss: 0.13450196385383606
Validation loss: 1.6207310127955612

Epoch: 6| Step: 5
Training loss: 0.3892093598842621
Validation loss: 1.6237333782257573

Epoch: 6| Step: 6
Training loss: 0.19763866066932678
Validation loss: 1.6182894629816855

Epoch: 6| Step: 7
Training loss: 0.37740397453308105
Validation loss: 1.5968517590594549

Epoch: 6| Step: 8
Training loss: 0.3732971251010895
Validation loss: 1.626552144686381

Epoch: 6| Step: 9
Training loss: 0.1762322336435318
Validation loss: 1.6034920228424894

Epoch: 6| Step: 10
Training loss: 0.21727988123893738
Validation loss: 1.6176003102333314

Epoch: 6| Step: 11
Training loss: 0.246148481965065
Validation loss: 1.6146809413868894

Epoch: 6| Step: 12
Training loss: 0.3713379204273224
Validation loss: 1.6304704809701571

Epoch: 6| Step: 13
Training loss: 0.3896547853946686
Validation loss: 1.6147389104289394

Epoch: 343| Step: 0
Training loss: 0.14709395170211792
Validation loss: 1.594466378611903

Epoch: 6| Step: 1
Training loss: 0.32422852516174316
Validation loss: 1.6136402148072437

Epoch: 6| Step: 2
Training loss: 0.2258332222700119
Validation loss: 1.5901560655204199

Epoch: 6| Step: 3
Training loss: 0.196942538022995
Validation loss: 1.5908361442627446

Epoch: 6| Step: 4
Training loss: 0.44088083505630493
Validation loss: 1.5881416464364657

Epoch: 6| Step: 5
Training loss: 0.21904785931110382
Validation loss: 1.574986425138289

Epoch: 6| Step: 6
Training loss: 0.4270225763320923
Validation loss: 1.5371146932724984

Epoch: 6| Step: 7
Training loss: 0.21007417142391205
Validation loss: 1.5748120828341412

Epoch: 6| Step: 8
Training loss: 0.17179463803768158
Validation loss: 1.5403261607693088

Epoch: 6| Step: 9
Training loss: 0.47499555349349976
Validation loss: 1.5910335868917487

Epoch: 6| Step: 10
Training loss: 0.23094765841960907
Validation loss: 1.5923102658282045

Epoch: 6| Step: 11
Training loss: 0.2598375082015991
Validation loss: 1.6084284974682717

Epoch: 6| Step: 12
Training loss: 0.24487090110778809
Validation loss: 1.6265078577944028

Epoch: 6| Step: 13
Training loss: 0.32157886028289795
Validation loss: 1.5978056461580339

Epoch: 344| Step: 0
Training loss: 0.15964660048484802
Validation loss: 1.6265063324282247

Epoch: 6| Step: 1
Training loss: 0.24691441655158997
Validation loss: 1.6140837092553415

Epoch: 6| Step: 2
Training loss: 0.37564384937286377
Validation loss: 1.626236968143012

Epoch: 6| Step: 3
Training loss: 0.30609190464019775
Validation loss: 1.6248810188744658

Epoch: 6| Step: 4
Training loss: 0.4305925965309143
Validation loss: 1.6322568937014508

Epoch: 6| Step: 5
Training loss: 0.21398258209228516
Validation loss: 1.6128915215051303

Epoch: 6| Step: 6
Training loss: 0.2804541289806366
Validation loss: 1.6305999179040231

Epoch: 6| Step: 7
Training loss: 0.20045843720436096
Validation loss: 1.6080300961771319

Epoch: 6| Step: 8
Training loss: 0.28407222032546997
Validation loss: 1.6147448273115261

Epoch: 6| Step: 9
Training loss: 0.20161214470863342
Validation loss: 1.6168922865262596

Epoch: 6| Step: 10
Training loss: 0.3762246370315552
Validation loss: 1.640250567466982

Epoch: 6| Step: 11
Training loss: 0.2848031520843506
Validation loss: 1.612887317134488

Epoch: 6| Step: 12
Training loss: 0.2030135989189148
Validation loss: 1.6310182335556194

Epoch: 6| Step: 13
Training loss: 0.2809360921382904
Validation loss: 1.6195056310264013

Epoch: 345| Step: 0
Training loss: 0.2594471573829651
Validation loss: 1.6155927450426164

Epoch: 6| Step: 1
Training loss: 0.2506004869937897
Validation loss: 1.645670711353261

Epoch: 6| Step: 2
Training loss: 0.239375039935112
Validation loss: 1.650307455370503

Epoch: 6| Step: 3
Training loss: 0.2965036630630493
Validation loss: 1.6774483701234222

Epoch: 6| Step: 4
Training loss: 0.26992154121398926
Validation loss: 1.6814258893330891

Epoch: 6| Step: 5
Training loss: 0.4930679202079773
Validation loss: 1.652511291606452

Epoch: 6| Step: 6
Training loss: 0.38298702239990234
Validation loss: 1.6317238564132361

Epoch: 6| Step: 7
Training loss: 0.25544220209121704
Validation loss: 1.6421855649640482

Epoch: 6| Step: 8
Training loss: 0.19114957749843597
Validation loss: 1.63432228308852

Epoch: 6| Step: 9
Training loss: 0.2825384736061096
Validation loss: 1.6266332082850958

Epoch: 6| Step: 10
Training loss: 0.34649544954299927
Validation loss: 1.6255858380307433

Epoch: 6| Step: 11
Training loss: 0.19923795759677887
Validation loss: 1.6437230751078615

Epoch: 6| Step: 12
Training loss: 0.29018741846084595
Validation loss: 1.6679493637495144

Epoch: 6| Step: 13
Training loss: 0.2768857479095459
Validation loss: 1.6494675105617893

Epoch: 346| Step: 0
Training loss: 0.25792908668518066
Validation loss: 1.6370792119733748

Epoch: 6| Step: 1
Training loss: 0.1557755023241043
Validation loss: 1.6144242619955411

Epoch: 6| Step: 2
Training loss: 0.2533125579357147
Validation loss: 1.622349774965676

Epoch: 6| Step: 3
Training loss: 0.35706138610839844
Validation loss: 1.635576243041664

Epoch: 6| Step: 4
Training loss: 0.2134087085723877
Validation loss: 1.6542072552506641

Epoch: 6| Step: 5
Training loss: 0.29851391911506653
Validation loss: 1.6198223419086908

Epoch: 6| Step: 6
Training loss: 0.43248212337493896
Validation loss: 1.6505596624907626

Epoch: 6| Step: 7
Training loss: 0.3100191354751587
Validation loss: 1.607826227782875

Epoch: 6| Step: 8
Training loss: 0.23219269514083862
Validation loss: 1.549830339288199

Epoch: 6| Step: 9
Training loss: 0.18475766479969025
Validation loss: 1.581644291518837

Epoch: 6| Step: 10
Training loss: 0.22098799049854279
Validation loss: 1.5762800260256695

Epoch: 6| Step: 11
Training loss: 0.18019098043441772
Validation loss: 1.6017073713323122

Epoch: 6| Step: 12
Training loss: 0.240618497133255
Validation loss: 1.6234936329626268

Epoch: 6| Step: 13
Training loss: 0.4097386598587036
Validation loss: 1.598124106725057

Epoch: 347| Step: 0
Training loss: 0.18764536082744598
Validation loss: 1.616401272435342

Epoch: 6| Step: 1
Training loss: 0.395990788936615
Validation loss: 1.6663951027777888

Epoch: 6| Step: 2
Training loss: 0.3595138192176819
Validation loss: 1.6642797890529837

Epoch: 6| Step: 3
Training loss: 0.33747217059135437
Validation loss: 1.6765898209746166

Epoch: 6| Step: 4
Training loss: 0.4367865324020386
Validation loss: 1.7098056693230905

Epoch: 6| Step: 5
Training loss: 0.1690758466720581
Validation loss: 1.7201876653138028

Epoch: 6| Step: 6
Training loss: 0.15193352103233337
Validation loss: 1.7129342696999992

Epoch: 6| Step: 7
Training loss: 0.30363261699676514
Validation loss: 1.6622443276066934

Epoch: 6| Step: 8
Training loss: 0.3243759870529175
Validation loss: 1.6407910444403206

Epoch: 6| Step: 9
Training loss: 0.21242180466651917
Validation loss: 1.6744685916490452

Epoch: 6| Step: 10
Training loss: 0.24915850162506104
Validation loss: 1.642670492972097

Epoch: 6| Step: 11
Training loss: 0.40095388889312744
Validation loss: 1.6377143103589293

Epoch: 6| Step: 12
Training loss: 0.35233479738235474
Validation loss: 1.6372151567089943

Epoch: 6| Step: 13
Training loss: 0.282213032245636
Validation loss: 1.6536400215600127

Epoch: 348| Step: 0
Training loss: 0.3445156216621399
Validation loss: 1.669660141391139

Epoch: 6| Step: 1
Training loss: 0.3606978952884674
Validation loss: 1.65120284018978

Epoch: 6| Step: 2
Training loss: 0.27311959862709045
Validation loss: 1.6420794148598947

Epoch: 6| Step: 3
Training loss: 0.1576923429965973
Validation loss: 1.6494708708537522

Epoch: 6| Step: 4
Training loss: 0.1993558704853058
Validation loss: 1.6500629122539232

Epoch: 6| Step: 5
Training loss: 0.2339223325252533
Validation loss: 1.6525745263663671

Epoch: 6| Step: 6
Training loss: 0.4137468934059143
Validation loss: 1.629048680746427

Epoch: 6| Step: 7
Training loss: 0.2731746435165405
Validation loss: 1.5931949436023671

Epoch: 6| Step: 8
Training loss: 0.31015196442604065
Validation loss: 1.5760321085171034

Epoch: 6| Step: 9
Training loss: 0.2946384847164154
Validation loss: 1.5565752842093026

Epoch: 6| Step: 10
Training loss: 0.32224225997924805
Validation loss: 1.58783551954454

Epoch: 6| Step: 11
Training loss: 0.2039433717727661
Validation loss: 1.5876833982365106

Epoch: 6| Step: 12
Training loss: 0.3160651922225952
Validation loss: 1.579817941111903

Epoch: 6| Step: 13
Training loss: 0.32612699270248413
Validation loss: 1.5913557916559198

Epoch: 349| Step: 0
Training loss: 0.2871151268482208
Validation loss: 1.6085637871937086

Epoch: 6| Step: 1
Training loss: 0.44660627841949463
Validation loss: 1.6137542122153825

Epoch: 6| Step: 2
Training loss: 0.2884906828403473
Validation loss: 1.6226625698868946

Epoch: 6| Step: 3
Training loss: 0.24389560520648956
Validation loss: 1.6160428472744521

Epoch: 6| Step: 4
Training loss: 0.1459140032529831
Validation loss: 1.617217275404161

Epoch: 6| Step: 5
Training loss: 0.2901287078857422
Validation loss: 1.6223858684621832

Epoch: 6| Step: 6
Training loss: 0.38992494344711304
Validation loss: 1.583418688466472

Epoch: 6| Step: 7
Training loss: 0.20972232520580292
Validation loss: 1.6044205491260817

Epoch: 6| Step: 8
Training loss: 0.16456139087677002
Validation loss: 1.561161042541586

Epoch: 6| Step: 9
Training loss: 0.2448091208934784
Validation loss: 1.5773301534755255

Epoch: 6| Step: 10
Training loss: 0.23046955466270447
Validation loss: 1.5621180149816698

Epoch: 6| Step: 11
Training loss: 0.3966236114501953
Validation loss: 1.5853903767883137

Epoch: 6| Step: 12
Training loss: 0.3663285970687866
Validation loss: 1.574648021369852

Epoch: 6| Step: 13
Training loss: 0.2032766044139862
Validation loss: 1.587310475687827

Epoch: 350| Step: 0
Training loss: 0.2426026165485382
Validation loss: 1.5947204200170373

Epoch: 6| Step: 1
Training loss: 0.3941792845726013
Validation loss: 1.568767519407375

Epoch: 6| Step: 2
Training loss: 0.2949178218841553
Validation loss: 1.6032647778910976

Epoch: 6| Step: 3
Training loss: 0.1657211184501648
Validation loss: 1.6246228384715256

Epoch: 6| Step: 4
Training loss: 0.2715061902999878
Validation loss: 1.5998613116561726

Epoch: 6| Step: 5
Training loss: 0.34628263115882874
Validation loss: 1.623578679177069

Epoch: 6| Step: 6
Training loss: 0.17912855744361877
Validation loss: 1.6113652939437537

Epoch: 6| Step: 7
Training loss: 0.37534254789352417
Validation loss: 1.6241441388284006

Epoch: 6| Step: 8
Training loss: 0.2981887459754944
Validation loss: 1.5885105286875079

Epoch: 6| Step: 9
Training loss: 0.15700280666351318
Validation loss: 1.5836234387531076

Epoch: 6| Step: 10
Training loss: 0.20866969227790833
Validation loss: 1.5618913840222102

Epoch: 6| Step: 11
Training loss: 0.18283537030220032
Validation loss: 1.6006070772806804

Epoch: 6| Step: 12
Training loss: 0.3665516674518585
Validation loss: 1.5846011010549401

Epoch: 6| Step: 13
Training loss: 0.35154998302459717
Validation loss: 1.5818331805608605

Epoch: 351| Step: 0
Training loss: 0.17644473910331726
Validation loss: 1.578135669872325

Epoch: 6| Step: 1
Training loss: 0.14138637483119965
Validation loss: 1.5612706689424412

Epoch: 6| Step: 2
Training loss: 0.21798467636108398
Validation loss: 1.5682520020392634

Epoch: 6| Step: 3
Training loss: 0.46065205335617065
Validation loss: 1.5672530320382887

Epoch: 6| Step: 4
Training loss: 0.3041756749153137
Validation loss: 1.5857280172327513

Epoch: 6| Step: 5
Training loss: 0.3650394082069397
Validation loss: 1.5932110009654876

Epoch: 6| Step: 6
Training loss: 0.13883104920387268
Validation loss: 1.5952202889227098

Epoch: 6| Step: 7
Training loss: 0.30428576469421387
Validation loss: 1.593275261181657

Epoch: 6| Step: 8
Training loss: 0.25357285141944885
Validation loss: 1.6073413600203812

Epoch: 6| Step: 9
Training loss: 0.15630120038986206
Validation loss: 1.600322659297656

Epoch: 6| Step: 10
Training loss: 0.25388583540916443
Validation loss: 1.6243289260454075

Epoch: 6| Step: 11
Training loss: 0.3896755576133728
Validation loss: 1.613288599957702

Epoch: 6| Step: 12
Training loss: 0.3380654454231262
Validation loss: 1.6193832658952283

Epoch: 6| Step: 13
Training loss: 0.23999370634555817
Validation loss: 1.573475641589011

Epoch: 352| Step: 0
Training loss: 0.18841244280338287
Validation loss: 1.5930243807454263

Epoch: 6| Step: 1
Training loss: 0.14865784347057343
Validation loss: 1.5793197449817453

Epoch: 6| Step: 2
Training loss: 0.3067346215248108
Validation loss: 1.5775494806228145

Epoch: 6| Step: 3
Training loss: 0.19107729196548462
Validation loss: 1.5883875200825353

Epoch: 6| Step: 4
Training loss: 0.451506108045578
Validation loss: 1.5621707823968702

Epoch: 6| Step: 5
Training loss: 0.3192048668861389
Validation loss: 1.571076597577782

Epoch: 6| Step: 6
Training loss: 0.20004227757453918
Validation loss: 1.6151685253266366

Epoch: 6| Step: 7
Training loss: 0.2745468318462372
Validation loss: 1.5875981610308412

Epoch: 6| Step: 8
Training loss: 0.23536747694015503
Validation loss: 1.635009047805622

Epoch: 6| Step: 9
Training loss: 0.314303994178772
Validation loss: 1.6683555495354436

Epoch: 6| Step: 10
Training loss: 0.3056131601333618
Validation loss: 1.675627557180261

Epoch: 6| Step: 11
Training loss: 0.21397586166858673
Validation loss: 1.6851738511875112

Epoch: 6| Step: 12
Training loss: 0.36668696999549866
Validation loss: 1.689170963020735

Epoch: 6| Step: 13
Training loss: 0.24701417982578278
Validation loss: 1.6600273680943314

Epoch: 353| Step: 0
Training loss: 0.30768007040023804
Validation loss: 1.6520810716895646

Epoch: 6| Step: 1
Training loss: 0.2791586220264435
Validation loss: 1.6082021985002743

Epoch: 6| Step: 2
Training loss: 0.15023094415664673
Validation loss: 1.602326726400724

Epoch: 6| Step: 3
Training loss: 0.34191811084747314
Validation loss: 1.5789428962174283

Epoch: 6| Step: 4
Training loss: 0.2643502652645111
Validation loss: 1.5729306519672435

Epoch: 6| Step: 5
Training loss: 0.18946652114391327
Validation loss: 1.5517275025767665

Epoch: 6| Step: 6
Training loss: 0.4117256999015808
Validation loss: 1.569919478508734

Epoch: 6| Step: 7
Training loss: 0.351408988237381
Validation loss: 1.5739971489034674

Epoch: 6| Step: 8
Training loss: 0.16438734531402588
Validation loss: 1.6186336432733843

Epoch: 6| Step: 9
Training loss: 0.20824196934700012
Validation loss: 1.712277466251004

Epoch: 6| Step: 10
Training loss: 0.3163588047027588
Validation loss: 1.7170559847226707

Epoch: 6| Step: 11
Training loss: 0.5797771215438843
Validation loss: 1.7480727164976058

Epoch: 6| Step: 12
Training loss: 0.37100353837013245
Validation loss: 1.6841484231333579

Epoch: 6| Step: 13
Training loss: 0.23718422651290894
Validation loss: 1.6308858484350226

Epoch: 354| Step: 0
Training loss: 0.34586605429649353
Validation loss: 1.5825693889330792

Epoch: 6| Step: 1
Training loss: 0.17279019951820374
Validation loss: 1.5604721423118346

Epoch: 6| Step: 2
Training loss: 0.26097550988197327
Validation loss: 1.546951509291126

Epoch: 6| Step: 3
Training loss: 0.4570949077606201
Validation loss: 1.5327421337045648

Epoch: 6| Step: 4
Training loss: 0.24486374855041504
Validation loss: 1.5815430559137815

Epoch: 6| Step: 5
Training loss: 0.09626339375972748
Validation loss: 1.5898986183187014

Epoch: 6| Step: 6
Training loss: 0.3292770981788635
Validation loss: 1.5583498965027511

Epoch: 6| Step: 7
Training loss: 0.22381024062633514
Validation loss: 1.5740337294916953

Epoch: 6| Step: 8
Training loss: 0.3604021370410919
Validation loss: 1.583292317646806

Epoch: 6| Step: 9
Training loss: 0.2016061544418335
Validation loss: 1.5798118306744484

Epoch: 6| Step: 10
Training loss: 0.24578069150447845
Validation loss: 1.5965297234955655

Epoch: 6| Step: 11
Training loss: 0.31031879782676697
Validation loss: 1.5855109935165734

Epoch: 6| Step: 12
Training loss: 0.25495654344558716
Validation loss: 1.5740401655115106

Epoch: 6| Step: 13
Training loss: 0.16351628303527832
Validation loss: 1.585944378247825

Epoch: 355| Step: 0
Training loss: 0.2174302637577057
Validation loss: 1.5844506935406757

Epoch: 6| Step: 1
Training loss: 0.1216481626033783
Validation loss: 1.5525207275985389

Epoch: 6| Step: 2
Training loss: 0.4390034079551697
Validation loss: 1.5924465976735598

Epoch: 6| Step: 3
Training loss: 0.12569661438465118
Validation loss: 1.546602564473306

Epoch: 6| Step: 4
Training loss: 0.31683188676834106
Validation loss: 1.5658572450760873

Epoch: 6| Step: 5
Training loss: 0.203508198261261
Validation loss: 1.56579339760606

Epoch: 6| Step: 6
Training loss: 0.2645370662212372
Validation loss: 1.5898258583520049

Epoch: 6| Step: 7
Training loss: 0.23057147860527039
Validation loss: 1.5586213898915116

Epoch: 6| Step: 8
Training loss: 0.2086908519268036
Validation loss: 1.5910805502245504

Epoch: 6| Step: 9
Training loss: 0.25638458132743835
Validation loss: 1.5771587420535345

Epoch: 6| Step: 10
Training loss: 0.13331370055675507
Validation loss: 1.5632157402653848

Epoch: 6| Step: 11
Training loss: 0.1553356796503067
Validation loss: 1.5658036854959303

Epoch: 6| Step: 12
Training loss: 0.1935482919216156
Validation loss: 1.539944396224073

Epoch: 6| Step: 13
Training loss: 0.1129164844751358
Validation loss: 1.5541936146315707

Epoch: 356| Step: 0
Training loss: 0.27644920349121094
Validation loss: 1.5485105181253085

Epoch: 6| Step: 1
Training loss: 0.19663774967193604
Validation loss: 1.5428415344607445

Epoch: 6| Step: 2
Training loss: 0.43323206901550293
Validation loss: 1.5599279493413947

Epoch: 6| Step: 3
Training loss: 0.29567113518714905
Validation loss: 1.5826042941821519

Epoch: 6| Step: 4
Training loss: 0.1894201785326004
Validation loss: 1.5942697858297696

Epoch: 6| Step: 5
Training loss: 0.1605236828327179
Validation loss: 1.6013199308867097

Epoch: 6| Step: 6
Training loss: 0.130407452583313
Validation loss: 1.589846803295997

Epoch: 6| Step: 7
Training loss: 0.2663182020187378
Validation loss: 1.6152387242163382

Epoch: 6| Step: 8
Training loss: 0.3204551339149475
Validation loss: 1.58360549711412

Epoch: 6| Step: 9
Training loss: 0.1586333066225052
Validation loss: 1.5451938644532235

Epoch: 6| Step: 10
Training loss: 0.2223048061132431
Validation loss: 1.5659495130661996

Epoch: 6| Step: 11
Training loss: 0.21510303020477295
Validation loss: 1.5763164207499514

Epoch: 6| Step: 12
Training loss: 0.19908349215984344
Validation loss: 1.5481470502832884

Epoch: 6| Step: 13
Training loss: 0.22000752389431
Validation loss: 1.5617204071373068

Epoch: 357| Step: 0
Training loss: 0.3423919081687927
Validation loss: 1.5439344426637054

Epoch: 6| Step: 1
Training loss: 0.21302315592765808
Validation loss: 1.54455643059105

Epoch: 6| Step: 2
Training loss: 0.23442932963371277
Validation loss: 1.5605314457288353

Epoch: 6| Step: 3
Training loss: 0.25607597827911377
Validation loss: 1.544786645520118

Epoch: 6| Step: 4
Training loss: 0.305976927280426
Validation loss: 1.5452990160193494

Epoch: 6| Step: 5
Training loss: 0.27088820934295654
Validation loss: 1.5635276475260336

Epoch: 6| Step: 6
Training loss: 0.2915201783180237
Validation loss: 1.5701567883132606

Epoch: 6| Step: 7
Training loss: 0.30054619908332825
Validation loss: 1.5721473860484299

Epoch: 6| Step: 8
Training loss: 0.23840124905109406
Validation loss: 1.5883558097706045

Epoch: 6| Step: 9
Training loss: 0.2388656735420227
Validation loss: 1.617283251977736

Epoch: 6| Step: 10
Training loss: 0.1636003851890564
Validation loss: 1.6305660188839

Epoch: 6| Step: 11
Training loss: 0.15620732307434082
Validation loss: 1.583149830500285

Epoch: 6| Step: 12
Training loss: 0.15658307075500488
Validation loss: 1.6053455914220502

Epoch: 6| Step: 13
Training loss: 0.2623579502105713
Validation loss: 1.5951374448755735

Epoch: 358| Step: 0
Training loss: 0.22192882001399994
Validation loss: 1.6074846598409838

Epoch: 6| Step: 1
Training loss: 0.1488213986158371
Validation loss: 1.6111118665305517

Epoch: 6| Step: 2
Training loss: 0.43657413125038147
Validation loss: 1.5906902577287407

Epoch: 6| Step: 3
Training loss: 0.2117210030555725
Validation loss: 1.5883730150038196

Epoch: 6| Step: 4
Training loss: 0.2759368419647217
Validation loss: 1.5947309591436898

Epoch: 6| Step: 5
Training loss: 0.11990565061569214
Validation loss: 1.5713386804826799

Epoch: 6| Step: 6
Training loss: 0.27077269554138184
Validation loss: 1.5993216640205794

Epoch: 6| Step: 7
Training loss: 0.16267870366573334
Validation loss: 1.5663551579239547

Epoch: 6| Step: 8
Training loss: 0.29527047276496887
Validation loss: 1.5774171211386239

Epoch: 6| Step: 9
Training loss: 0.1892777681350708
Validation loss: 1.5576775804642709

Epoch: 6| Step: 10
Training loss: 0.10110444575548172
Validation loss: 1.552850592520929

Epoch: 6| Step: 11
Training loss: 0.23271259665489197
Validation loss: 1.5643600699722127

Epoch: 6| Step: 12
Training loss: 0.23313495516777039
Validation loss: 1.564280617621637

Epoch: 6| Step: 13
Training loss: 0.1319565623998642
Validation loss: 1.6047200272160191

Epoch: 359| Step: 0
Training loss: 0.20607498288154602
Validation loss: 1.5837052111984582

Epoch: 6| Step: 1
Training loss: 0.3764106035232544
Validation loss: 1.631954562279486

Epoch: 6| Step: 2
Training loss: 0.25097936391830444
Validation loss: 1.6154789540075487

Epoch: 6| Step: 3
Training loss: 0.1461363136768341
Validation loss: 1.6024770480330273

Epoch: 6| Step: 4
Training loss: 0.10528579354286194
Validation loss: 1.5924669927166355

Epoch: 6| Step: 5
Training loss: 0.1431325376033783
Validation loss: 1.585680600135557

Epoch: 6| Step: 6
Training loss: 0.13701514899730682
Validation loss: 1.5648431918954337

Epoch: 6| Step: 7
Training loss: 0.18219345808029175
Validation loss: 1.5910811206345916

Epoch: 6| Step: 8
Training loss: 0.3147311806678772
Validation loss: 1.601850386588804

Epoch: 6| Step: 9
Training loss: 0.22922185063362122
Validation loss: 1.6118530188837359

Epoch: 6| Step: 10
Training loss: 0.283486008644104
Validation loss: 1.6250869868904032

Epoch: 6| Step: 11
Training loss: 0.22904250025749207
Validation loss: 1.6103650382770005

Epoch: 6| Step: 12
Training loss: 0.2425607144832611
Validation loss: 1.642871699025554

Epoch: 6| Step: 13
Training loss: 0.24576261639595032
Validation loss: 1.6049757875421995

Epoch: 360| Step: 0
Training loss: 0.2759582996368408
Validation loss: 1.6017650840102986

Epoch: 6| Step: 1
Training loss: 0.19597142934799194
Validation loss: 1.5696248380086755

Epoch: 6| Step: 2
Training loss: 0.20805099606513977
Validation loss: 1.5742393411615843

Epoch: 6| Step: 3
Training loss: 0.24727235734462738
Validation loss: 1.5599533537382722

Epoch: 6| Step: 4
Training loss: 0.21125981211662292
Validation loss: 1.564023280656466

Epoch: 6| Step: 5
Training loss: 0.1911713182926178
Validation loss: 1.5672861094115882

Epoch: 6| Step: 6
Training loss: 0.24883198738098145
Validation loss: 1.5879376190964893

Epoch: 6| Step: 7
Training loss: 0.191463440656662
Validation loss: 1.5740186681029618

Epoch: 6| Step: 8
Training loss: 0.14744699001312256
Validation loss: 1.5718366228124148

Epoch: 6| Step: 9
Training loss: 0.18121537566184998
Validation loss: 1.582249520927347

Epoch: 6| Step: 10
Training loss: 0.267299622297287
Validation loss: 1.5773859613685197

Epoch: 6| Step: 11
Training loss: 0.15071001648902893
Validation loss: 1.571279869284681

Epoch: 6| Step: 12
Training loss: 0.1041024699807167
Validation loss: 1.5482265051975046

Epoch: 6| Step: 13
Training loss: 0.17514808475971222
Validation loss: 1.5629771870951499

Epoch: 361| Step: 0
Training loss: 0.17408400774002075
Validation loss: 1.5638518359071465

Epoch: 6| Step: 1
Training loss: 0.23775970935821533
Validation loss: 1.572597006315826

Epoch: 6| Step: 2
Training loss: 0.28098589181900024
Validation loss: 1.546957322346267

Epoch: 6| Step: 3
Training loss: 0.2388736605644226
Validation loss: 1.5560135533732753

Epoch: 6| Step: 4
Training loss: 0.3338775634765625
Validation loss: 1.5498944226131643

Epoch: 6| Step: 5
Training loss: 0.29517242312431335
Validation loss: 1.5374881990494267

Epoch: 6| Step: 6
Training loss: 0.2541787624359131
Validation loss: 1.5480956172430387

Epoch: 6| Step: 7
Training loss: 0.13889330625534058
Validation loss: 1.5809327479331725

Epoch: 6| Step: 8
Training loss: 0.11334603279829025
Validation loss: 1.5489805218993977

Epoch: 6| Step: 9
Training loss: 0.3104868531227112
Validation loss: 1.5476556388280724

Epoch: 6| Step: 10
Training loss: 0.13969966769218445
Validation loss: 1.5695018845219766

Epoch: 6| Step: 11
Training loss: 0.20758786797523499
Validation loss: 1.57521447443193

Epoch: 6| Step: 12
Training loss: 0.19166386127471924
Validation loss: 1.5689786864865212

Epoch: 6| Step: 13
Training loss: 0.17012587189674377
Validation loss: 1.578227045715496

Epoch: 362| Step: 0
Training loss: 0.14328497648239136
Validation loss: 1.5458004038820985

Epoch: 6| Step: 1
Training loss: 0.18171995878219604
Validation loss: 1.5247199432824248

Epoch: 6| Step: 2
Training loss: 0.119499571621418
Validation loss: 1.5416165346740394

Epoch: 6| Step: 3
Training loss: 0.12695327401161194
Validation loss: 1.523016777089847

Epoch: 6| Step: 4
Training loss: 0.15564988553524017
Validation loss: 1.5371768538669874

Epoch: 6| Step: 5
Training loss: 0.2552117109298706
Validation loss: 1.5200099355431014

Epoch: 6| Step: 6
Training loss: 0.18709009885787964
Validation loss: 1.5152029068239274

Epoch: 6| Step: 7
Training loss: 0.23280134797096252
Validation loss: 1.5308234089164323

Epoch: 6| Step: 8
Training loss: 0.3773996829986572
Validation loss: 1.5547576617169123

Epoch: 6| Step: 9
Training loss: 0.10081446915864944
Validation loss: 1.5333917743416243

Epoch: 6| Step: 10
Training loss: 0.15606343746185303
Validation loss: 1.5646806955337524

Epoch: 6| Step: 11
Training loss: 0.35611671209335327
Validation loss: 1.5564079066758514

Epoch: 6| Step: 12
Training loss: 0.16438595950603485
Validation loss: 1.5363231538444437

Epoch: 6| Step: 13
Training loss: 0.15279452502727509
Validation loss: 1.5780330268285607

Epoch: 363| Step: 0
Training loss: 0.22521668672561646
Validation loss: 1.5580300759243708

Epoch: 6| Step: 1
Training loss: 0.26360422372817993
Validation loss: 1.5900340663489474

Epoch: 6| Step: 2
Training loss: 0.3183901011943817
Validation loss: 1.5793898464531027

Epoch: 6| Step: 3
Training loss: 0.28512439131736755
Validation loss: 1.5730076579637424

Epoch: 6| Step: 4
Training loss: 0.13194483518600464
Validation loss: 1.5587165817137687

Epoch: 6| Step: 5
Training loss: 0.13272365927696228
Validation loss: 1.5509232090365501

Epoch: 6| Step: 6
Training loss: 0.21310099959373474
Validation loss: 1.5541613730051185

Epoch: 6| Step: 7
Training loss: 0.2959824502468109
Validation loss: 1.551769160455273

Epoch: 6| Step: 8
Training loss: 0.1745298206806183
Validation loss: 1.527122506531336

Epoch: 6| Step: 9
Training loss: 0.11011630296707153
Validation loss: 1.5381366386208484

Epoch: 6| Step: 10
Training loss: 0.22654560208320618
Validation loss: 1.5278888979265768

Epoch: 6| Step: 11
Training loss: 0.1575775444507599
Validation loss: 1.5535340386052285

Epoch: 6| Step: 12
Training loss: 0.12821169197559357
Validation loss: 1.5531549434508047

Epoch: 6| Step: 13
Training loss: 0.09772121161222458
Validation loss: 1.5544778313688052

Epoch: 364| Step: 0
Training loss: 0.16383396089076996
Validation loss: 1.5761685320126113

Epoch: 6| Step: 1
Training loss: 0.16053244471549988
Validation loss: 1.5670709891985821

Epoch: 6| Step: 2
Training loss: 0.28653669357299805
Validation loss: 1.5710507541574457

Epoch: 6| Step: 3
Training loss: 0.1338055431842804
Validation loss: 1.5525189702228834

Epoch: 6| Step: 4
Training loss: 0.20208898186683655
Validation loss: 1.556399103133909

Epoch: 6| Step: 5
Training loss: 0.19090664386749268
Validation loss: 1.5171658877403504

Epoch: 6| Step: 6
Training loss: 0.3058308959007263
Validation loss: 1.5382888727290656

Epoch: 6| Step: 7
Training loss: 0.14112702012062073
Validation loss: 1.5225724648403864

Epoch: 6| Step: 8
Training loss: 0.2263486534357071
Validation loss: 1.5494684891034198

Epoch: 6| Step: 9
Training loss: 0.30057400465011597
Validation loss: 1.5644111159027263

Epoch: 6| Step: 10
Training loss: 0.22943603992462158
Validation loss: 1.575792533095165

Epoch: 6| Step: 11
Training loss: 0.24493718147277832
Validation loss: 1.5932816279831754

Epoch: 6| Step: 12
Training loss: 0.14832961559295654
Validation loss: 1.624667788064608

Epoch: 6| Step: 13
Training loss: 0.10288860648870468
Validation loss: 1.5960389209050003

Epoch: 365| Step: 0
Training loss: 0.1948843151330948
Validation loss: 1.624234999379804

Epoch: 6| Step: 1
Training loss: 0.24929112195968628
Validation loss: 1.6098901969130321

Epoch: 6| Step: 2
Training loss: 0.1353357434272766
Validation loss: 1.6057399613882906

Epoch: 6| Step: 3
Training loss: 0.1625402867794037
Validation loss: 1.6141539824906217

Epoch: 6| Step: 4
Training loss: 0.13136164844036102
Validation loss: 1.553955654944143

Epoch: 6| Step: 5
Training loss: 0.26820456981658936
Validation loss: 1.561506441844407

Epoch: 6| Step: 6
Training loss: 0.11024661362171173
Validation loss: 1.5561747576600762

Epoch: 6| Step: 7
Training loss: 0.1937512457370758
Validation loss: 1.540080396077966

Epoch: 6| Step: 8
Training loss: 0.32662951946258545
Validation loss: 1.5298752554001347

Epoch: 6| Step: 9
Training loss: 0.2904638648033142
Validation loss: 1.5139596423795145

Epoch: 6| Step: 10
Training loss: 0.20537614822387695
Validation loss: 1.5206976423981369

Epoch: 6| Step: 11
Training loss: 0.3784778416156769
Validation loss: 1.5192602501120618

Epoch: 6| Step: 12
Training loss: 0.23697826266288757
Validation loss: 1.5279150021973478

Epoch: 6| Step: 13
Training loss: 0.4299292266368866
Validation loss: 1.5477157536373343

Epoch: 366| Step: 0
Training loss: 0.20242318511009216
Validation loss: 1.5790550913862003

Epoch: 6| Step: 1
Training loss: 0.16968384385108948
Validation loss: 1.5827850859652284

Epoch: 6| Step: 2
Training loss: 0.19940204918384552
Validation loss: 1.591207838827564

Epoch: 6| Step: 3
Training loss: 0.2534756660461426
Validation loss: 1.5851754591029177

Epoch: 6| Step: 4
Training loss: 0.19101360440254211
Validation loss: 1.5925902807584373

Epoch: 6| Step: 5
Training loss: 0.18703791499137878
Validation loss: 1.5877675446130897

Epoch: 6| Step: 6
Training loss: 0.15598677098751068
Validation loss: 1.6006249599559332

Epoch: 6| Step: 7
Training loss: 0.184373140335083
Validation loss: 1.579130349620696

Epoch: 6| Step: 8
Training loss: 0.16193023324012756
Validation loss: 1.5640957252953642

Epoch: 6| Step: 9
Training loss: 0.12569046020507812
Validation loss: 1.5672928428137174

Epoch: 6| Step: 10
Training loss: 0.14508101344108582
Validation loss: 1.531553497878454

Epoch: 6| Step: 11
Training loss: 0.27924084663391113
Validation loss: 1.5586183314682336

Epoch: 6| Step: 12
Training loss: 0.22334253787994385
Validation loss: 1.5747927004291165

Epoch: 6| Step: 13
Training loss: 0.1848362684249878
Validation loss: 1.5559465968480675

Epoch: 367| Step: 0
Training loss: 0.25116369128227234
Validation loss: 1.5735407529338714

Epoch: 6| Step: 1
Training loss: 0.16143925487995148
Validation loss: 1.5177646535699085

Epoch: 6| Step: 2
Training loss: 0.30500996112823486
Validation loss: 1.5500819349801669

Epoch: 6| Step: 3
Training loss: 0.1130964532494545
Validation loss: 1.5952159730336999

Epoch: 6| Step: 4
Training loss: 0.20440673828125
Validation loss: 1.5744437363839918

Epoch: 6| Step: 5
Training loss: 0.3542635440826416
Validation loss: 1.576503324252303

Epoch: 6| Step: 6
Training loss: 0.1465429961681366
Validation loss: 1.6246742958663611

Epoch: 6| Step: 7
Training loss: 0.11053917557001114
Validation loss: 1.6042302398271457

Epoch: 6| Step: 8
Training loss: 0.1514652818441391
Validation loss: 1.5928699406244422

Epoch: 6| Step: 9
Training loss: 0.1618480533361435
Validation loss: 1.5809072461179507

Epoch: 6| Step: 10
Training loss: 0.1137080192565918
Validation loss: 1.5789221794374528

Epoch: 6| Step: 11
Training loss: 0.2056616246700287
Validation loss: 1.5914878768305625

Epoch: 6| Step: 12
Training loss: 0.38779473304748535
Validation loss: 1.556771050217331

Epoch: 6| Step: 13
Training loss: 0.049247223883867264
Validation loss: 1.5591694411411081

Epoch: 368| Step: 0
Training loss: 0.17525455355644226
Validation loss: 1.5696070450608448

Epoch: 6| Step: 1
Training loss: 0.21133452653884888
Validation loss: 1.5534616221663773

Epoch: 6| Step: 2
Training loss: 0.2021532952785492
Validation loss: 1.549072616202857

Epoch: 6| Step: 3
Training loss: 0.22489652037620544
Validation loss: 1.5683116618023123

Epoch: 6| Step: 4
Training loss: 0.2735059857368469
Validation loss: 1.55120837560264

Epoch: 6| Step: 5
Training loss: 0.30315881967544556
Validation loss: 1.578815661450868

Epoch: 6| Step: 6
Training loss: 0.14110904932022095
Validation loss: 1.5728804097380689

Epoch: 6| Step: 7
Training loss: 0.14012411236763
Validation loss: 1.5899631682262625

Epoch: 6| Step: 8
Training loss: 0.20157232880592346
Validation loss: 1.6051448827148767

Epoch: 6| Step: 9
Training loss: 0.17008885741233826
Validation loss: 1.5957925268398818

Epoch: 6| Step: 10
Training loss: 0.20001265406608582
Validation loss: 1.5846758260521838

Epoch: 6| Step: 11
Training loss: 0.10025603324174881
Validation loss: 1.5842864897943312

Epoch: 6| Step: 12
Training loss: 0.17898908257484436
Validation loss: 1.578587426934191

Epoch: 6| Step: 13
Training loss: 0.10517100244760513
Validation loss: 1.6210474923092832

Epoch: 369| Step: 0
Training loss: 0.1308331936597824
Validation loss: 1.5952129979287424

Epoch: 6| Step: 1
Training loss: 0.11339634656906128
Validation loss: 1.5401052018647552

Epoch: 6| Step: 2
Training loss: 0.1728309988975525
Validation loss: 1.5529305242723035

Epoch: 6| Step: 3
Training loss: 0.21234551072120667
Validation loss: 1.5569045671852686

Epoch: 6| Step: 4
Training loss: 0.21846632659435272
Validation loss: 1.560729153694645

Epoch: 6| Step: 5
Training loss: 0.21863286197185516
Validation loss: 1.5788180110275105

Epoch: 6| Step: 6
Training loss: 0.3290715217590332
Validation loss: 1.6035149007715204

Epoch: 6| Step: 7
Training loss: 0.22209908068180084
Validation loss: 1.589509435879287

Epoch: 6| Step: 8
Training loss: 0.11066339164972305
Validation loss: 1.6054268652392971

Epoch: 6| Step: 9
Training loss: 0.19095531105995178
Validation loss: 1.6181191603342693

Epoch: 6| Step: 10
Training loss: 0.2730700969696045
Validation loss: 1.5882221767979283

Epoch: 6| Step: 11
Training loss: 0.122161366045475
Validation loss: 1.5829422320089033

Epoch: 6| Step: 12
Training loss: 0.36430200934410095
Validation loss: 1.6215133282446093

Epoch: 6| Step: 13
Training loss: 0.1575959324836731
Validation loss: 1.6291134254906767

Epoch: 370| Step: 0
Training loss: 0.16868528723716736
Validation loss: 1.6326459787225212

Epoch: 6| Step: 1
Training loss: 0.16467224061489105
Validation loss: 1.6117500105211813

Epoch: 6| Step: 2
Training loss: 0.31270501017570496
Validation loss: 1.647110104560852

Epoch: 6| Step: 3
Training loss: 0.2861211895942688
Validation loss: 1.6989607221336775

Epoch: 6| Step: 4
Training loss: 0.28242433071136475
Validation loss: 1.668014910913283

Epoch: 6| Step: 5
Training loss: 0.2110770046710968
Validation loss: 1.6950812416691934

Epoch: 6| Step: 6
Training loss: 0.20144815742969513
Validation loss: 1.6662549254714802

Epoch: 6| Step: 7
Training loss: 0.20957469940185547
Validation loss: 1.6391419159468783

Epoch: 6| Step: 8
Training loss: 0.40680131316185
Validation loss: 1.5897216002146404

Epoch: 6| Step: 9
Training loss: 0.12439365684986115
Validation loss: 1.5481055757050872

Epoch: 6| Step: 10
Training loss: 0.333625465631485
Validation loss: 1.5214688893287414

Epoch: 6| Step: 11
Training loss: 0.17683058977127075
Validation loss: 1.547475371309506

Epoch: 6| Step: 12
Training loss: 0.23428770899772644
Validation loss: 1.5167051233271116

Epoch: 6| Step: 13
Training loss: 0.16017204523086548
Validation loss: 1.5304934722121044

Epoch: 371| Step: 0
Training loss: 0.18287652730941772
Validation loss: 1.5489833380586358

Epoch: 6| Step: 1
Training loss: 0.32882821559906006
Validation loss: 1.557310309461368

Epoch: 6| Step: 2
Training loss: 0.18600186705589294
Validation loss: 1.5899932743400655

Epoch: 6| Step: 3
Training loss: 0.17108669877052307
Validation loss: 1.626023425850817

Epoch: 6| Step: 4
Training loss: 0.22302278876304626
Validation loss: 1.6142511111433788

Epoch: 6| Step: 5
Training loss: 0.15879863500595093
Validation loss: 1.6072629523533646

Epoch: 6| Step: 6
Training loss: 0.291910320520401
Validation loss: 1.6635882200733307

Epoch: 6| Step: 7
Training loss: 0.3398173749446869
Validation loss: 1.6161578470660793

Epoch: 6| Step: 8
Training loss: 0.144974946975708
Validation loss: 1.5951534637840845

Epoch: 6| Step: 9
Training loss: 0.2402735948562622
Validation loss: 1.6172136593890447

Epoch: 6| Step: 10
Training loss: 0.2004052996635437
Validation loss: 1.601418992524506

Epoch: 6| Step: 11
Training loss: 0.3390386700630188
Validation loss: 1.5994318749314995

Epoch: 6| Step: 12
Training loss: 0.2282595932483673
Validation loss: 1.5819566108847176

Epoch: 6| Step: 13
Training loss: 0.1137624979019165
Validation loss: 1.5488126572742258

Epoch: 372| Step: 0
Training loss: 0.2101876139640808
Validation loss: 1.5779360032850696

Epoch: 6| Step: 1
Training loss: 0.33306318521499634
Validation loss: 1.5552860549701157

Epoch: 6| Step: 2
Training loss: 0.16640987992286682
Validation loss: 1.565366950086368

Epoch: 6| Step: 3
Training loss: 0.20490434765815735
Validation loss: 1.6143173940720097

Epoch: 6| Step: 4
Training loss: 0.3484947085380554
Validation loss: 1.6052402706556423

Epoch: 6| Step: 5
Training loss: 0.22326749563217163
Validation loss: 1.6009198709200787

Epoch: 6| Step: 6
Training loss: 0.23447445034980774
Validation loss: 1.603973565563079

Epoch: 6| Step: 7
Training loss: 0.1515219807624817
Validation loss: 1.5833725096077047

Epoch: 6| Step: 8
Training loss: 0.2021230161190033
Validation loss: 1.587931336895112

Epoch: 6| Step: 9
Training loss: 0.17758585512638092
Validation loss: 1.6093317078005882

Epoch: 6| Step: 10
Training loss: 0.1794397383928299
Validation loss: 1.6201003751447123

Epoch: 6| Step: 11
Training loss: 0.22767165303230286
Validation loss: 1.6484556069938086

Epoch: 6| Step: 12
Training loss: 0.3031080365180969
Validation loss: 1.6488896544261644

Epoch: 6| Step: 13
Training loss: 0.2918210029602051
Validation loss: 1.6733709253290647

Epoch: 373| Step: 0
Training loss: 0.2548716068267822
Validation loss: 1.649639585966705

Epoch: 6| Step: 1
Training loss: 0.2013925313949585
Validation loss: 1.6035516185145224

Epoch: 6| Step: 2
Training loss: 0.24206851422786713
Validation loss: 1.626447266788893

Epoch: 6| Step: 3
Training loss: 0.24532833695411682
Validation loss: 1.6492183195647372

Epoch: 6| Step: 4
Training loss: 0.23142443597316742
Validation loss: 1.6217042489718365

Epoch: 6| Step: 5
Training loss: 0.19540996849536896
Validation loss: 1.6372558570677234

Epoch: 6| Step: 6
Training loss: 0.17501235008239746
Validation loss: 1.6099683430887037

Epoch: 6| Step: 7
Training loss: 0.3919152021408081
Validation loss: 1.5711919159017584

Epoch: 6| Step: 8
Training loss: 0.1482890248298645
Validation loss: 1.5653459859150711

Epoch: 6| Step: 9
Training loss: 0.24167339503765106
Validation loss: 1.5336996765546902

Epoch: 6| Step: 10
Training loss: 0.16877120733261108
Validation loss: 1.564124236824692

Epoch: 6| Step: 11
Training loss: 0.25169795751571655
Validation loss: 1.5537456927760955

Epoch: 6| Step: 12
Training loss: 0.1915273368358612
Validation loss: 1.548693121120494

Epoch: 6| Step: 13
Training loss: 0.23062896728515625
Validation loss: 1.5587747443106867

Epoch: 374| Step: 0
Training loss: 0.13892854750156403
Validation loss: 1.5723431084745674

Epoch: 6| Step: 1
Training loss: 0.23246851563453674
Validation loss: 1.5598642326170398

Epoch: 6| Step: 2
Training loss: 0.23962433636188507
Validation loss: 1.5718348782549623

Epoch: 6| Step: 3
Training loss: 0.3266327381134033
Validation loss: 1.5596327243312713

Epoch: 6| Step: 4
Training loss: 0.13786567747592926
Validation loss: 1.555103668602564

Epoch: 6| Step: 5
Training loss: 0.22968679666519165
Validation loss: 1.5392530579720773

Epoch: 6| Step: 6
Training loss: 0.2544691860675812
Validation loss: 1.542778632974112

Epoch: 6| Step: 7
Training loss: 0.12636393308639526
Validation loss: 1.5499682304679707

Epoch: 6| Step: 8
Training loss: 0.15360857546329498
Validation loss: 1.5569626656911706

Epoch: 6| Step: 9
Training loss: 0.2624133229255676
Validation loss: 1.5618149465130222

Epoch: 6| Step: 10
Training loss: 0.16433125734329224
Validation loss: 1.580348047517961

Epoch: 6| Step: 11
Training loss: 0.19786719977855682
Validation loss: 1.5705665619142595

Epoch: 6| Step: 12
Training loss: 0.25566062331199646
Validation loss: 1.576909206246817

Epoch: 6| Step: 13
Training loss: 0.16362741589546204
Validation loss: 1.5985757638049383

Epoch: 375| Step: 0
Training loss: 0.11034148186445236
Validation loss: 1.5240357960424116

Epoch: 6| Step: 1
Training loss: 0.2000371366739273
Validation loss: 1.5550275605211976

Epoch: 6| Step: 2
Training loss: 0.20149528980255127
Validation loss: 1.5742459092088925

Epoch: 6| Step: 3
Training loss: 0.2674422860145569
Validation loss: 1.5416060660475044

Epoch: 6| Step: 4
Training loss: 0.14890651404857635
Validation loss: 1.582526514607091

Epoch: 6| Step: 5
Training loss: 0.19827188551425934
Validation loss: 1.529488202064268

Epoch: 6| Step: 6
Training loss: 0.14178825914859772
Validation loss: 1.5313560244857625

Epoch: 6| Step: 7
Training loss: 0.20855477452278137
Validation loss: 1.5461598109173518

Epoch: 6| Step: 8
Training loss: 0.19804832339286804
Validation loss: 1.5237712180742653

Epoch: 6| Step: 9
Training loss: 0.19566740095615387
Validation loss: 1.548012259185955

Epoch: 6| Step: 10
Training loss: 0.21752777695655823
Validation loss: 1.572528770533941

Epoch: 6| Step: 11
Training loss: 0.125631183385849
Validation loss: 1.5485802555596957

Epoch: 6| Step: 12
Training loss: 0.17051386833190918
Validation loss: 1.5877885292935114

Epoch: 6| Step: 13
Training loss: 0.26878485083580017
Validation loss: 1.5951126185796594

Epoch: 376| Step: 0
Training loss: 0.19570432603359222
Validation loss: 1.5778236132796093

Epoch: 6| Step: 1
Training loss: 0.15732890367507935
Validation loss: 1.6055296339014524

Epoch: 6| Step: 2
Training loss: 0.26770666241645813
Validation loss: 1.5735245763614614

Epoch: 6| Step: 3
Training loss: 0.16797199845314026
Validation loss: 1.5368052708205355

Epoch: 6| Step: 4
Training loss: 0.16212080419063568
Validation loss: 1.5572950455450243

Epoch: 6| Step: 5
Training loss: 0.20400643348693848
Validation loss: 1.5375551433973416

Epoch: 6| Step: 6
Training loss: 0.17173898220062256
Validation loss: 1.5100519182861492

Epoch: 6| Step: 7
Training loss: 0.1602165251970291
Validation loss: 1.5234563081495223

Epoch: 6| Step: 8
Training loss: 0.22142022848129272
Validation loss: 1.504368584643128

Epoch: 6| Step: 9
Training loss: 0.24556243419647217
Validation loss: 1.5040162532560286

Epoch: 6| Step: 10
Training loss: 0.1776016354560852
Validation loss: 1.5081820616158106

Epoch: 6| Step: 11
Training loss: 0.11878649890422821
Validation loss: 1.5113400131143548

Epoch: 6| Step: 12
Training loss: 0.20494306087493896
Validation loss: 1.4692472514285837

Epoch: 6| Step: 13
Training loss: 0.180700421333313
Validation loss: 1.496711205410701

Epoch: 377| Step: 0
Training loss: 0.21037361025810242
Validation loss: 1.472244479322946

Epoch: 6| Step: 1
Training loss: 0.21164292097091675
Validation loss: 1.4673707498017179

Epoch: 6| Step: 2
Training loss: 0.13511395454406738
Validation loss: 1.5105086693199732

Epoch: 6| Step: 3
Training loss: 0.19311359524726868
Validation loss: 1.512305389168442

Epoch: 6| Step: 4
Training loss: 0.09537535905838013
Validation loss: 1.5132803814385527

Epoch: 6| Step: 5
Training loss: 0.1699644923210144
Validation loss: 1.5327077552836428

Epoch: 6| Step: 6
Training loss: 0.10223376750946045
Validation loss: 1.5388964779915348

Epoch: 6| Step: 7
Training loss: 0.09154297411441803
Validation loss: 1.5432370119197394

Epoch: 6| Step: 8
Training loss: 0.1622840315103531
Validation loss: 1.5227493291260095

Epoch: 6| Step: 9
Training loss: 0.2095855474472046
Validation loss: 1.5198095985638198

Epoch: 6| Step: 10
Training loss: 0.2719452977180481
Validation loss: 1.5374256628815846

Epoch: 6| Step: 11
Training loss: 0.14726905524730682
Validation loss: 1.5257501320172382

Epoch: 6| Step: 12
Training loss: 0.14811626076698303
Validation loss: 1.516045525509824

Epoch: 6| Step: 13
Training loss: 0.25161319971084595
Validation loss: 1.4933939967104184

Epoch: 378| Step: 0
Training loss: 0.20080797374248505
Validation loss: 1.53229933656672

Epoch: 6| Step: 1
Training loss: 0.107851043343544
Validation loss: 1.5173754204985916

Epoch: 6| Step: 2
Training loss: 0.17061835527420044
Validation loss: 1.4964336887482674

Epoch: 6| Step: 3
Training loss: 0.1808045506477356
Validation loss: 1.490832039104995

Epoch: 6| Step: 4
Training loss: 0.1776965856552124
Validation loss: 1.5187438816152594

Epoch: 6| Step: 5
Training loss: 0.20844796299934387
Validation loss: 1.5447204920553392

Epoch: 6| Step: 6
Training loss: 0.106681689620018
Validation loss: 1.5080438237036429

Epoch: 6| Step: 7
Training loss: 0.15162436664104462
Validation loss: 1.5059709689950431

Epoch: 6| Step: 8
Training loss: 0.18018168210983276
Validation loss: 1.5488255126501924

Epoch: 6| Step: 9
Training loss: 0.20844563841819763
Validation loss: 1.5439544787970922

Epoch: 6| Step: 10
Training loss: 0.23316477239131927
Validation loss: 1.5709562891273088

Epoch: 6| Step: 11
Training loss: 0.15191924571990967
Validation loss: 1.5472955831917383

Epoch: 6| Step: 12
Training loss: 0.14643988013267517
Validation loss: 1.5838580657077093

Epoch: 6| Step: 13
Training loss: 0.18033896386623383
Validation loss: 1.5543829869198542

Epoch: 379| Step: 0
Training loss: 0.1742514967918396
Validation loss: 1.6155335275075768

Epoch: 6| Step: 1
Training loss: 0.15342175960540771
Validation loss: 1.6033462016813216

Epoch: 6| Step: 2
Training loss: 0.16929644346237183
Validation loss: 1.5811369688280168

Epoch: 6| Step: 3
Training loss: 0.23716479539871216
Validation loss: 1.5860603996502456

Epoch: 6| Step: 4
Training loss: 0.14170874655246735
Validation loss: 1.6123216331646006

Epoch: 6| Step: 5
Training loss: 0.23769958317279816
Validation loss: 1.5996763270388368

Epoch: 6| Step: 6
Training loss: 0.24128878116607666
Validation loss: 1.5763993968245804

Epoch: 6| Step: 7
Training loss: 0.28100085258483887
Validation loss: 1.6078962151722243

Epoch: 6| Step: 8
Training loss: 0.13077348470687866
Validation loss: 1.5824478646760345

Epoch: 6| Step: 9
Training loss: 0.15601801872253418
Validation loss: 1.5492341826038976

Epoch: 6| Step: 10
Training loss: 0.11484548449516296
Validation loss: 1.582932847802357

Epoch: 6| Step: 11
Training loss: 0.143662691116333
Validation loss: 1.5530139694931686

Epoch: 6| Step: 12
Training loss: 0.17430856823921204
Validation loss: 1.5489028076971731

Epoch: 6| Step: 13
Training loss: 0.19823689758777618
Validation loss: 1.5375792557193386

Epoch: 380| Step: 0
Training loss: 0.08900731056928635
Validation loss: 1.5620248843264837

Epoch: 6| Step: 1
Training loss: 0.1151941642165184
Validation loss: 1.5610618001671248

Epoch: 6| Step: 2
Training loss: 0.13437971472740173
Validation loss: 1.588526620659777

Epoch: 6| Step: 3
Training loss: 0.1849323809146881
Validation loss: 1.595978078021798

Epoch: 6| Step: 4
Training loss: 0.21164163947105408
Validation loss: 1.5808110057666738

Epoch: 6| Step: 5
Training loss: 0.1902153640985489
Validation loss: 1.5667896245115547

Epoch: 6| Step: 6
Training loss: 0.11746668070554733
Validation loss: 1.5594853290947535

Epoch: 6| Step: 7
Training loss: 0.12238548696041107
Validation loss: 1.5492012680217784

Epoch: 6| Step: 8
Training loss: 0.20419639348983765
Validation loss: 1.55281416831478

Epoch: 6| Step: 9
Training loss: 0.1472458690404892
Validation loss: 1.5318827193270448

Epoch: 6| Step: 10
Training loss: 0.32187721133232117
Validation loss: 1.5639729833090177

Epoch: 6| Step: 11
Training loss: 0.17478787899017334
Validation loss: 1.5464552551187494

Epoch: 6| Step: 12
Training loss: 0.2190716415643692
Validation loss: 1.5476485759981218

Epoch: 6| Step: 13
Training loss: 0.16559630632400513
Validation loss: 1.549829775287259

Epoch: 381| Step: 0
Training loss: 0.17152836918830872
Validation loss: 1.5718850948477303

Epoch: 6| Step: 1
Training loss: 0.3036451041698456
Validation loss: 1.5659341119950818

Epoch: 6| Step: 2
Training loss: 0.23529142141342163
Validation loss: 1.5508875885317404

Epoch: 6| Step: 3
Training loss: 0.10686401277780533
Validation loss: 1.542264788381515

Epoch: 6| Step: 4
Training loss: 0.206824392080307
Validation loss: 1.5580389704755557

Epoch: 6| Step: 5
Training loss: 0.10532571375370026
Validation loss: 1.5233101139786422

Epoch: 6| Step: 6
Training loss: 0.13577497005462646
Validation loss: 1.518109147266675

Epoch: 6| Step: 7
Training loss: 0.1906791627407074
Validation loss: 1.5210222633936072

Epoch: 6| Step: 8
Training loss: 0.09108144044876099
Validation loss: 1.524442829111571

Epoch: 6| Step: 9
Training loss: 0.1319301575422287
Validation loss: 1.5330301292480961

Epoch: 6| Step: 10
Training loss: 0.1532776951789856
Validation loss: 1.5058600389829246

Epoch: 6| Step: 11
Training loss: 0.18080638349056244
Validation loss: 1.548106292242645

Epoch: 6| Step: 12
Training loss: 0.14266154170036316
Validation loss: 1.5174863671743741

Epoch: 6| Step: 13
Training loss: 0.19725541770458221
Validation loss: 1.54200622599612

Epoch: 382| Step: 0
Training loss: 0.1306212693452835
Validation loss: 1.5335367674468665

Epoch: 6| Step: 1
Training loss: 0.13308322429656982
Validation loss: 1.5345976570601105

Epoch: 6| Step: 2
Training loss: 0.11367055773735046
Validation loss: 1.5382673317386257

Epoch: 6| Step: 3
Training loss: 0.14127585291862488
Validation loss: 1.513807762053705

Epoch: 6| Step: 4
Training loss: 0.13714179396629333
Validation loss: 1.5418017628372356

Epoch: 6| Step: 5
Training loss: 0.138001948595047
Validation loss: 1.5617757401158732

Epoch: 6| Step: 6
Training loss: 0.19754663109779358
Validation loss: 1.5849696910509499

Epoch: 6| Step: 7
Training loss: 0.11891837418079376
Validation loss: 1.5687736618903376

Epoch: 6| Step: 8
Training loss: 0.24362792074680328
Validation loss: 1.5292140527438092

Epoch: 6| Step: 9
Training loss: 0.21718484163284302
Validation loss: 1.5600706492700884

Epoch: 6| Step: 10
Training loss: 0.09642361104488373
Validation loss: 1.5668363417348554

Epoch: 6| Step: 11
Training loss: 0.1642874926328659
Validation loss: 1.5955070449459938

Epoch: 6| Step: 12
Training loss: 0.2350165843963623
Validation loss: 1.5584128011939347

Epoch: 6| Step: 13
Training loss: 0.25556519627571106
Validation loss: 1.5763082350454023

Epoch: 383| Step: 0
Training loss: 0.19036683440208435
Validation loss: 1.5999766780484108

Epoch: 6| Step: 1
Training loss: 0.1301274299621582
Validation loss: 1.6031540324611049

Epoch: 6| Step: 2
Training loss: 0.27733317017555237
Validation loss: 1.6428190610742057

Epoch: 6| Step: 3
Training loss: 0.10123224556446075
Validation loss: 1.6387129015820001

Epoch: 6| Step: 4
Training loss: 0.13977518677711487
Validation loss: 1.632929580186003

Epoch: 6| Step: 5
Training loss: 0.1736232042312622
Validation loss: 1.627136920088081

Epoch: 6| Step: 6
Training loss: 0.16182008385658264
Validation loss: 1.596798304588564

Epoch: 6| Step: 7
Training loss: 0.17798756062984467
Validation loss: 1.5981807772831251

Epoch: 6| Step: 8
Training loss: 0.14753007888793945
Validation loss: 1.5531465840596024

Epoch: 6| Step: 9
Training loss: 0.15132832527160645
Validation loss: 1.5288951294396513

Epoch: 6| Step: 10
Training loss: 0.13445478677749634
Validation loss: 1.5129313340751074

Epoch: 6| Step: 11
Training loss: 0.24235227704048157
Validation loss: 1.519800527121431

Epoch: 6| Step: 12
Training loss: 0.18014101684093475
Validation loss: 1.5336560831275037

Epoch: 6| Step: 13
Training loss: 0.266231507062912
Validation loss: 1.5475499937611241

Epoch: 384| Step: 0
Training loss: 0.13328686356544495
Validation loss: 1.57218006221197

Epoch: 6| Step: 1
Training loss: 0.20251435041427612
Validation loss: 1.5758478551782586

Epoch: 6| Step: 2
Training loss: 0.19285868108272552
Validation loss: 1.5740958311224496

Epoch: 6| Step: 3
Training loss: 0.23006358742713928
Validation loss: 1.5466098567490936

Epoch: 6| Step: 4
Training loss: 0.1418362855911255
Validation loss: 1.5660192658824306

Epoch: 6| Step: 5
Training loss: 0.14555412530899048
Validation loss: 1.5504456873862975

Epoch: 6| Step: 6
Training loss: 0.12949281930923462
Validation loss: 1.503684563021506

Epoch: 6| Step: 7
Training loss: 0.13219837844371796
Validation loss: 1.546357657319756

Epoch: 6| Step: 8
Training loss: 0.12878760695457458
Validation loss: 1.5218088191042665

Epoch: 6| Step: 9
Training loss: 0.1922384351491928
Validation loss: 1.5509700787964689

Epoch: 6| Step: 10
Training loss: 0.14023911952972412
Validation loss: 1.5149615708217825

Epoch: 6| Step: 11
Training loss: 0.1362760066986084
Validation loss: 1.5172165081065188

Epoch: 6| Step: 12
Training loss: 0.14865896105766296
Validation loss: 1.567607997566141

Epoch: 6| Step: 13
Training loss: 0.3004802167415619
Validation loss: 1.5295414424711657

Epoch: 385| Step: 0
Training loss: 0.16106778383255005
Validation loss: 1.5439737996747416

Epoch: 6| Step: 1
Training loss: 0.0801427811384201
Validation loss: 1.5777514211593135

Epoch: 6| Step: 2
Training loss: 0.12243581563234329
Validation loss: 1.592402260790589

Epoch: 6| Step: 3
Training loss: 0.23306119441986084
Validation loss: 1.5357904357294883

Epoch: 6| Step: 4
Training loss: 0.1171499565243721
Validation loss: 1.5611516544895787

Epoch: 6| Step: 5
Training loss: 0.20922496914863586
Validation loss: 1.5319126985406364

Epoch: 6| Step: 6
Training loss: 0.17975205183029175
Validation loss: 1.557447229021339

Epoch: 6| Step: 7
Training loss: 0.07834576070308685
Validation loss: 1.56021071762167

Epoch: 6| Step: 8
Training loss: 0.1317218840122223
Validation loss: 1.5617068031782746

Epoch: 6| Step: 9
Training loss: 0.09089156240224838
Validation loss: 1.5327081911025509

Epoch: 6| Step: 10
Training loss: 0.15186457335948944
Validation loss: 1.5248567660649617

Epoch: 6| Step: 11
Training loss: 0.194825679063797
Validation loss: 1.5435977174389748

Epoch: 6| Step: 12
Training loss: 0.10567094385623932
Validation loss: 1.5275910746666692

Epoch: 6| Step: 13
Training loss: 0.15639671683311462
Validation loss: 1.5562922685377059

Epoch: 386| Step: 0
Training loss: 0.12523356080055237
Validation loss: 1.5497810250969344

Epoch: 6| Step: 1
Training loss: 0.1298038363456726
Validation loss: 1.5634600122769673

Epoch: 6| Step: 2
Training loss: 0.11883912980556488
Validation loss: 1.5659510268959949

Epoch: 6| Step: 3
Training loss: 0.18526339530944824
Validation loss: 1.5474001899842293

Epoch: 6| Step: 4
Training loss: 0.16630145907402039
Validation loss: 1.5815266178500267

Epoch: 6| Step: 5
Training loss: 0.20932717621326447
Validation loss: 1.5719283755107591

Epoch: 6| Step: 6
Training loss: 0.13162708282470703
Validation loss: 1.558195690954885

Epoch: 6| Step: 7
Training loss: 0.13124951720237732
Validation loss: 1.5458028419043428

Epoch: 6| Step: 8
Training loss: 0.1306532621383667
Validation loss: 1.5916165844086678

Epoch: 6| Step: 9
Training loss: 0.14575377106666565
Validation loss: 1.576932559731186

Epoch: 6| Step: 10
Training loss: 0.22714927792549133
Validation loss: 1.5320819603499545

Epoch: 6| Step: 11
Training loss: 0.1384279727935791
Validation loss: 1.549587724029377

Epoch: 6| Step: 12
Training loss: 0.20059499144554138
Validation loss: 1.5509108010158743

Epoch: 6| Step: 13
Training loss: 0.15349292755126953
Validation loss: 1.5536388222889235

Epoch: 387| Step: 0
Training loss: 0.13702911138534546
Validation loss: 1.5375069854080037

Epoch: 6| Step: 1
Training loss: 0.05905884504318237
Validation loss: 1.5216293309324531

Epoch: 6| Step: 2
Training loss: 0.14145179092884064
Validation loss: 1.5349376675903157

Epoch: 6| Step: 3
Training loss: 0.09909284859895706
Validation loss: 1.5172155698140461

Epoch: 6| Step: 4
Training loss: 0.1338321715593338
Validation loss: 1.532962385044303

Epoch: 6| Step: 5
Training loss: 0.18822163343429565
Validation loss: 1.5842074681353826

Epoch: 6| Step: 6
Training loss: 0.09320518374443054
Validation loss: 1.5672159130855272

Epoch: 6| Step: 7
Training loss: 0.10729663074016571
Validation loss: 1.5471640363816292

Epoch: 6| Step: 8
Training loss: 0.12213180959224701
Validation loss: 1.5565138029795822

Epoch: 6| Step: 9
Training loss: 0.18965688347816467
Validation loss: 1.5377423686365927

Epoch: 6| Step: 10
Training loss: 0.12337222695350647
Validation loss: 1.5386922615830616

Epoch: 6| Step: 11
Training loss: 0.10559220612049103
Validation loss: 1.5067866117723527

Epoch: 6| Step: 12
Training loss: 0.22251588106155396
Validation loss: 1.5224270218162126

Epoch: 6| Step: 13
Training loss: 0.4811471700668335
Validation loss: 1.494981256864404

Epoch: 388| Step: 0
Training loss: 0.12145161628723145
Validation loss: 1.5128915591906476

Epoch: 6| Step: 1
Training loss: 0.17644736170768738
Validation loss: 1.4800927997917257

Epoch: 6| Step: 2
Training loss: 0.2257433980703354
Validation loss: 1.5018753569613221

Epoch: 6| Step: 3
Training loss: 0.10539668798446655
Validation loss: 1.53552576931574

Epoch: 6| Step: 4
Training loss: 0.21930678188800812
Validation loss: 1.5174719620776433

Epoch: 6| Step: 5
Training loss: 0.1183423101902008
Validation loss: 1.5327905531852477

Epoch: 6| Step: 6
Training loss: 0.09056688845157623
Validation loss: 1.5338232747970089

Epoch: 6| Step: 7
Training loss: 0.18047848343849182
Validation loss: 1.5678744085373417

Epoch: 6| Step: 8
Training loss: 0.1357707679271698
Validation loss: 1.543529752762087

Epoch: 6| Step: 9
Training loss: 0.14435774087905884
Validation loss: 1.5089176713779409

Epoch: 6| Step: 10
Training loss: 0.0992022305727005
Validation loss: 1.493309655497151

Epoch: 6| Step: 11
Training loss: 0.1352866291999817
Validation loss: 1.4774734384270125

Epoch: 6| Step: 12
Training loss: 0.17196057736873627
Validation loss: 1.4787610538544194

Epoch: 6| Step: 13
Training loss: 0.1309957504272461
Validation loss: 1.4606823498202908

Epoch: 389| Step: 0
Training loss: 0.15019938349723816
Validation loss: 1.460106078014579

Epoch: 6| Step: 1
Training loss: 0.13800489902496338
Validation loss: 1.4676187217876475

Epoch: 6| Step: 2
Training loss: 0.26099786162376404
Validation loss: 1.4735092309213453

Epoch: 6| Step: 3
Training loss: 0.1130523607134819
Validation loss: 1.4856140446919266

Epoch: 6| Step: 4
Training loss: 0.10015441477298737
Validation loss: 1.506387158106732

Epoch: 6| Step: 5
Training loss: 0.22633236646652222
Validation loss: 1.506463945552867

Epoch: 6| Step: 6
Training loss: 0.11834120750427246
Validation loss: 1.5403264414879583

Epoch: 6| Step: 7
Training loss: 0.17765775322914124
Validation loss: 1.5909642340034567

Epoch: 6| Step: 8
Training loss: 0.15156769752502441
Validation loss: 1.5895071798755276

Epoch: 6| Step: 9
Training loss: 0.1646348237991333
Validation loss: 1.5952686596942205

Epoch: 6| Step: 10
Training loss: 0.23402950167655945
Validation loss: 1.5493902442275838

Epoch: 6| Step: 11
Training loss: 0.2626383304595947
Validation loss: 1.53275139229272

Epoch: 6| Step: 12
Training loss: 0.17166025936603546
Validation loss: 1.5109404620303903

Epoch: 6| Step: 13
Training loss: 0.16608035564422607
Validation loss: 1.4886235101248628

Epoch: 390| Step: 0
Training loss: 0.20983317494392395
Validation loss: 1.5147431537669191

Epoch: 6| Step: 1
Training loss: 0.1634238213300705
Validation loss: 1.4820870789148475

Epoch: 6| Step: 2
Training loss: 0.20607662200927734
Validation loss: 1.5249614510484921

Epoch: 6| Step: 3
Training loss: 0.15205644071102142
Validation loss: 1.4905076039734708

Epoch: 6| Step: 4
Training loss: 0.12646546959877014
Validation loss: 1.4890203770770822

Epoch: 6| Step: 5
Training loss: 0.2839949131011963
Validation loss: 1.4794406621686873

Epoch: 6| Step: 6
Training loss: 0.14357027411460876
Validation loss: 1.5068386780318392

Epoch: 6| Step: 7
Training loss: 0.13056547939777374
Validation loss: 1.5182058042095554

Epoch: 6| Step: 8
Training loss: 0.19709047675132751
Validation loss: 1.5313905932570016

Epoch: 6| Step: 9
Training loss: 0.2557387948036194
Validation loss: 1.551544779090471

Epoch: 6| Step: 10
Training loss: 0.12038760632276535
Validation loss: 1.5066820613799556

Epoch: 6| Step: 11
Training loss: 0.13468949496746063
Validation loss: 1.513538122177124

Epoch: 6| Step: 12
Training loss: 0.09372623264789581
Validation loss: 1.531820261350242

Epoch: 6| Step: 13
Training loss: 0.2609966993331909
Validation loss: 1.5208907825972444

Epoch: 391| Step: 0
Training loss: 0.23014484345912933
Validation loss: 1.5210130381327804

Epoch: 6| Step: 1
Training loss: 0.16287469863891602
Validation loss: 1.521998792566279

Epoch: 6| Step: 2
Training loss: 0.13805410265922546
Validation loss: 1.5558322386075092

Epoch: 6| Step: 3
Training loss: 0.11421643197536469
Validation loss: 1.571412124941426

Epoch: 6| Step: 4
Training loss: 0.1303851455450058
Validation loss: 1.550222913424174

Epoch: 6| Step: 5
Training loss: 0.16016465425491333
Validation loss: 1.5418096101412209

Epoch: 6| Step: 6
Training loss: 0.31928566098213196
Validation loss: 1.59068734991935

Epoch: 6| Step: 7
Training loss: 0.22641697525978088
Validation loss: 1.5428473949432373

Epoch: 6| Step: 8
Training loss: 0.16617970168590546
Validation loss: 1.5341747460826751

Epoch: 6| Step: 9
Training loss: 0.14520981907844543
Validation loss: 1.5345940705268615

Epoch: 6| Step: 10
Training loss: 0.1594771146774292
Validation loss: 1.5317862085116807

Epoch: 6| Step: 11
Training loss: 0.10569831728935242
Validation loss: 1.546803964081631

Epoch: 6| Step: 12
Training loss: 0.22481584548950195
Validation loss: 1.5303142519407376

Epoch: 6| Step: 13
Training loss: 0.052671439945697784
Validation loss: 1.5636421352304437

Epoch: 392| Step: 0
Training loss: 0.20006993412971497
Validation loss: 1.5593047321483653

Epoch: 6| Step: 1
Training loss: 0.2168823480606079
Validation loss: 1.548304162999635

Epoch: 6| Step: 2
Training loss: 0.17060431838035583
Validation loss: 1.5695605098560292

Epoch: 6| Step: 3
Training loss: 0.0647958517074585
Validation loss: 1.56205322921917

Epoch: 6| Step: 4
Training loss: 0.15459087491035461
Validation loss: 1.5699388801410634

Epoch: 6| Step: 5
Training loss: 0.13189247250556946
Validation loss: 1.5703883709446076

Epoch: 6| Step: 6
Training loss: 0.24268102645874023
Validation loss: 1.538862064320554

Epoch: 6| Step: 7
Training loss: 0.23103642463684082
Validation loss: 1.5388912026600172

Epoch: 6| Step: 8
Training loss: 0.11487014591693878
Validation loss: 1.5101735027887488

Epoch: 6| Step: 9
Training loss: 0.10545690357685089
Validation loss: 1.5046287044402091

Epoch: 6| Step: 10
Training loss: 0.0887584537267685
Validation loss: 1.4978770184260544

Epoch: 6| Step: 11
Training loss: 0.1660405695438385
Validation loss: 1.5103628936634268

Epoch: 6| Step: 12
Training loss: 0.19531819224357605
Validation loss: 1.5686780419400943

Epoch: 6| Step: 13
Training loss: 0.11273162811994553
Validation loss: 1.5141464689726472

Epoch: 393| Step: 0
Training loss: 0.18742413818836212
Validation loss: 1.5183073692424323

Epoch: 6| Step: 1
Training loss: 0.18756413459777832
Validation loss: 1.5081580185121106

Epoch: 6| Step: 2
Training loss: 0.09744025021791458
Validation loss: 1.5315091699682257

Epoch: 6| Step: 3
Training loss: 0.11396390199661255
Validation loss: 1.5240138217967043

Epoch: 6| Step: 4
Training loss: 0.11922063678503036
Validation loss: 1.517021329172196

Epoch: 6| Step: 5
Training loss: 0.11149043589830399
Validation loss: 1.5511394662241782

Epoch: 6| Step: 6
Training loss: 0.10781936347484589
Validation loss: 1.5151119808996878

Epoch: 6| Step: 7
Training loss: 0.12699151039123535
Validation loss: 1.5293081601460774

Epoch: 6| Step: 8
Training loss: 0.1932470202445984
Validation loss: 1.547050283801171

Epoch: 6| Step: 9
Training loss: 0.13335341215133667
Validation loss: 1.5319489368828394

Epoch: 6| Step: 10
Training loss: 0.1551954746246338
Validation loss: 1.530552766656363

Epoch: 6| Step: 11
Training loss: 0.1558161973953247
Validation loss: 1.5433078017286075

Epoch: 6| Step: 12
Training loss: 0.1424589604139328
Validation loss: 1.5499912320926625

Epoch: 6| Step: 13
Training loss: 0.09371645748615265
Validation loss: 1.5258055912551058

Epoch: 394| Step: 0
Training loss: 0.06446713209152222
Validation loss: 1.5862526906433927

Epoch: 6| Step: 1
Training loss: 0.16741342842578888
Validation loss: 1.5893460345524613

Epoch: 6| Step: 2
Training loss: 0.1313207745552063
Validation loss: 1.6069886158871394

Epoch: 6| Step: 3
Training loss: 0.11506830155849457
Validation loss: 1.5748450371526903

Epoch: 6| Step: 4
Training loss: 0.23573368787765503
Validation loss: 1.5962612404618213

Epoch: 6| Step: 5
Training loss: 0.21502670645713806
Validation loss: 1.6116773146455006

Epoch: 6| Step: 6
Training loss: 0.13085271418094635
Validation loss: 1.6114775070580103

Epoch: 6| Step: 7
Training loss: 0.11168065667152405
Validation loss: 1.6006724590896277

Epoch: 6| Step: 8
Training loss: 0.08850757777690887
Validation loss: 1.593614996120494

Epoch: 6| Step: 9
Training loss: 0.1465330421924591
Validation loss: 1.567129768351073

Epoch: 6| Step: 10
Training loss: 0.19027763605117798
Validation loss: 1.5321178513188516

Epoch: 6| Step: 11
Training loss: 0.1359851062297821
Validation loss: 1.5662118606669928

Epoch: 6| Step: 12
Training loss: 0.1417674571275711
Validation loss: 1.553804955174846

Epoch: 6| Step: 13
Training loss: 0.1595098376274109
Validation loss: 1.5676372089693624

Epoch: 395| Step: 0
Training loss: 0.1452048122882843
Validation loss: 1.5856150273353822

Epoch: 6| Step: 1
Training loss: 0.28228670358657837
Validation loss: 1.5637006323824647

Epoch: 6| Step: 2
Training loss: 0.2120768278837204
Validation loss: 1.5817473267996183

Epoch: 6| Step: 3
Training loss: 0.15651051700115204
Validation loss: 1.5891063751712922

Epoch: 6| Step: 4
Training loss: 0.12300267070531845
Validation loss: 1.5958164033069406

Epoch: 6| Step: 5
Training loss: 0.17160192131996155
Validation loss: 1.5528415608149704

Epoch: 6| Step: 6
Training loss: 0.2659503221511841
Validation loss: 1.5542821717518631

Epoch: 6| Step: 7
Training loss: 0.22994808852672577
Validation loss: 1.570485266306067

Epoch: 6| Step: 8
Training loss: 0.1868860274553299
Validation loss: 1.523046592230438

Epoch: 6| Step: 9
Training loss: 0.13887342810630798
Validation loss: 1.5573220547809397

Epoch: 6| Step: 10
Training loss: 0.25671470165252686
Validation loss: 1.5597018093191168

Epoch: 6| Step: 11
Training loss: 0.21159641444683075
Validation loss: 1.536079668229626

Epoch: 6| Step: 12
Training loss: 0.1702781766653061
Validation loss: 1.5386900504430134

Epoch: 6| Step: 13
Training loss: 0.167262002825737
Validation loss: 1.5164604046011483

Epoch: 396| Step: 0
Training loss: 0.16860033571720123
Validation loss: 1.5223436278681601

Epoch: 6| Step: 1
Training loss: 0.14246326684951782
Validation loss: 1.5124739023946947

Epoch: 6| Step: 2
Training loss: 0.2607801854610443
Validation loss: 1.5508069415246286

Epoch: 6| Step: 3
Training loss: 0.23848813772201538
Validation loss: 1.580858975328425

Epoch: 6| Step: 4
Training loss: 0.15221074223518372
Validation loss: 1.585739194705922

Epoch: 6| Step: 5
Training loss: 0.17392589151859283
Validation loss: 1.607877669795867

Epoch: 6| Step: 6
Training loss: 0.1702834665775299
Validation loss: 1.594972482291601

Epoch: 6| Step: 7
Training loss: 0.2947874069213867
Validation loss: 1.5988399392815047

Epoch: 6| Step: 8
Training loss: 0.1311713457107544
Validation loss: 1.5973142270118958

Epoch: 6| Step: 9
Training loss: 0.1496436595916748
Validation loss: 1.5831236621384979

Epoch: 6| Step: 10
Training loss: 0.16109555959701538
Validation loss: 1.5740615219198248

Epoch: 6| Step: 11
Training loss: 0.20986083149909973
Validation loss: 1.5771829133392663

Epoch: 6| Step: 12
Training loss: 0.1381182223558426
Validation loss: 1.5428209253536758

Epoch: 6| Step: 13
Training loss: 0.11234964430332184
Validation loss: 1.571447431400258

Epoch: 397| Step: 0
Training loss: 0.18037550151348114
Validation loss: 1.5896850606446624

Epoch: 6| Step: 1
Training loss: 0.2069525420665741
Validation loss: 1.5753058618114841

Epoch: 6| Step: 2
Training loss: 0.16810989379882812
Validation loss: 1.5274596086112402

Epoch: 6| Step: 3
Training loss: 0.15104542672634125
Validation loss: 1.5233754701511835

Epoch: 6| Step: 4
Training loss: 0.13237464427947998
Validation loss: 1.5251523166574457

Epoch: 6| Step: 5
Training loss: 0.19567769765853882
Validation loss: 1.532331819175392

Epoch: 6| Step: 6
Training loss: 0.08987386524677277
Validation loss: 1.5394460507618484

Epoch: 6| Step: 7
Training loss: 0.1463775336742401
Validation loss: 1.5291049941893546

Epoch: 6| Step: 8
Training loss: 0.2183687388896942
Validation loss: 1.5510903289241176

Epoch: 6| Step: 9
Training loss: 0.1554524451494217
Validation loss: 1.516991376876831

Epoch: 6| Step: 10
Training loss: 0.10301156342029572
Validation loss: 1.522731920724274

Epoch: 6| Step: 11
Training loss: 0.16594046354293823
Validation loss: 1.5340836509581535

Epoch: 6| Step: 12
Training loss: 0.14318710565567017
Validation loss: 1.4861154120455506

Epoch: 6| Step: 13
Training loss: 0.12459193170070648
Validation loss: 1.514799980707066

Epoch: 398| Step: 0
Training loss: 0.12171836942434311
Validation loss: 1.5084244589651785

Epoch: 6| Step: 1
Training loss: 0.133292093873024
Validation loss: 1.4829572259738881

Epoch: 6| Step: 2
Training loss: 0.1741853952407837
Validation loss: 1.5196932509381285

Epoch: 6| Step: 3
Training loss: 0.2341982126235962
Validation loss: 1.5106540162076232

Epoch: 6| Step: 4
Training loss: 0.10590539127588272
Validation loss: 1.5175178730359642

Epoch: 6| Step: 5
Training loss: 0.12431835383176804
Validation loss: 1.5373652083899385

Epoch: 6| Step: 6
Training loss: 0.13793009519577026
Validation loss: 1.5591078445475588

Epoch: 6| Step: 7
Training loss: 0.1935020536184311
Validation loss: 1.5802670659557465

Epoch: 6| Step: 8
Training loss: 0.08460503816604614
Validation loss: 1.5872606500502555

Epoch: 6| Step: 9
Training loss: 0.09422001242637634
Validation loss: 1.5733135810462378

Epoch: 6| Step: 10
Training loss: 0.19118042290210724
Validation loss: 1.5635073620785949

Epoch: 6| Step: 11
Training loss: 0.15703532099723816
Validation loss: 1.534133211258919

Epoch: 6| Step: 12
Training loss: 0.10429902374744415
Validation loss: 1.5390437495323919

Epoch: 6| Step: 13
Training loss: 0.1629462093114853
Validation loss: 1.5247116563140706

Epoch: 399| Step: 0
Training loss: 0.15991538763046265
Validation loss: 1.4926396633989067

Epoch: 6| Step: 1
Training loss: 0.14748209714889526
Validation loss: 1.5011379218870593

Epoch: 6| Step: 2
Training loss: 0.1988641321659088
Validation loss: 1.5082145224335373

Epoch: 6| Step: 3
Training loss: 0.09193690121173859
Validation loss: 1.4919052406023907

Epoch: 6| Step: 4
Training loss: 0.16435439884662628
Validation loss: 1.4983611363236622

Epoch: 6| Step: 5
Training loss: 0.18156698346138
Validation loss: 1.5158249690968504

Epoch: 6| Step: 6
Training loss: 0.19853287935256958
Validation loss: 1.5078512186645179

Epoch: 6| Step: 7
Training loss: 0.18088756501674652
Validation loss: 1.5289748073906027

Epoch: 6| Step: 8
Training loss: 0.12602217495441437
Validation loss: 1.5078757462962982

Epoch: 6| Step: 9
Training loss: 0.12466470897197723
Validation loss: 1.5246732414409678

Epoch: 6| Step: 10
Training loss: 0.16202948987483978
Validation loss: 1.521886452551811

Epoch: 6| Step: 11
Training loss: 0.2965383231639862
Validation loss: 1.518822234164002

Epoch: 6| Step: 12
Training loss: 0.142063170671463
Validation loss: 1.5463372930403678

Epoch: 6| Step: 13
Training loss: 0.16159537434577942
Validation loss: 1.5417744792917722

Epoch: 400| Step: 0
Training loss: 0.13637036085128784
Validation loss: 1.5408354689998012

Epoch: 6| Step: 1
Training loss: 0.1785331666469574
Validation loss: 1.5610550859923005

Epoch: 6| Step: 2
Training loss: 0.1697385013103485
Validation loss: 1.5374812810651717

Epoch: 6| Step: 3
Training loss: 0.15866777300834656
Validation loss: 1.5697327339521019

Epoch: 6| Step: 4
Training loss: 0.08375350385904312
Validation loss: 1.5505716544325634

Epoch: 6| Step: 5
Training loss: 0.11076944321393967
Validation loss: 1.5577752103087723

Epoch: 6| Step: 6
Training loss: 0.16616955399513245
Validation loss: 1.5384976543406004

Epoch: 6| Step: 7
Training loss: 0.12239119410514832
Validation loss: 1.5582732513386717

Epoch: 6| Step: 8
Training loss: 0.2336989939212799
Validation loss: 1.5617716312408447

Epoch: 6| Step: 9
Training loss: 0.06718657910823822
Validation loss: 1.5583248343518985

Epoch: 6| Step: 10
Training loss: 0.13094717264175415
Validation loss: 1.5965769181969345

Epoch: 6| Step: 11
Training loss: 0.24694404006004333
Validation loss: 1.561221190678176

Epoch: 6| Step: 12
Training loss: 0.13759471476078033
Validation loss: 1.5751904313282301

Epoch: 6| Step: 13
Training loss: 0.13117355108261108
Validation loss: 1.5451370221312328

Epoch: 401| Step: 0
Training loss: 0.1336851418018341
Validation loss: 1.537575787113559

Epoch: 6| Step: 1
Training loss: 0.09686833620071411
Validation loss: 1.5468093233723794

Epoch: 6| Step: 2
Training loss: 0.20537811517715454
Validation loss: 1.5214538804946407

Epoch: 6| Step: 3
Training loss: 0.11549963057041168
Validation loss: 1.5170548833826536

Epoch: 6| Step: 4
Training loss: 0.12631353735923767
Validation loss: 1.5620897226436163

Epoch: 6| Step: 5
Training loss: 0.14396539330482483
Validation loss: 1.5325810460634128

Epoch: 6| Step: 6
Training loss: 0.18422600626945496
Validation loss: 1.511628488058685

Epoch: 6| Step: 7
Training loss: 0.1607227623462677
Validation loss: 1.5230761804888326

Epoch: 6| Step: 8
Training loss: 0.08668588101863861
Validation loss: 1.5306838712384623

Epoch: 6| Step: 9
Training loss: 0.06319929659366608
Validation loss: 1.5226081494362123

Epoch: 6| Step: 10
Training loss: 0.23171965777873993
Validation loss: 1.5016732805518693

Epoch: 6| Step: 11
Training loss: 0.1147414818406105
Validation loss: 1.4837792733664155

Epoch: 6| Step: 12
Training loss: 0.13631007075309753
Validation loss: 1.5001097417646838

Epoch: 6| Step: 13
Training loss: 0.09243959188461304
Validation loss: 1.5089577115992063

Epoch: 402| Step: 0
Training loss: 0.1693437695503235
Validation loss: 1.5052107085463822

Epoch: 6| Step: 1
Training loss: 0.11396494507789612
Validation loss: 1.519008283974022

Epoch: 6| Step: 2
Training loss: 0.12665008008480072
Validation loss: 1.5150243889900945

Epoch: 6| Step: 3
Training loss: 0.11908159404993057
Validation loss: 1.5172444825531335

Epoch: 6| Step: 4
Training loss: 0.09721677005290985
Validation loss: 1.4953388308966031

Epoch: 6| Step: 5
Training loss: 0.14633417129516602
Validation loss: 1.5044825538512199

Epoch: 6| Step: 6
Training loss: 0.22374999523162842
Validation loss: 1.5326416454007548

Epoch: 6| Step: 7
Training loss: 0.14452244341373444
Validation loss: 1.5470214748895297

Epoch: 6| Step: 8
Training loss: 0.06560295075178146
Validation loss: 1.560069913505226

Epoch: 6| Step: 9
Training loss: 0.23914307355880737
Validation loss: 1.5614236426609818

Epoch: 6| Step: 10
Training loss: 0.19181329011917114
Validation loss: 1.5604708707460793

Epoch: 6| Step: 11
Training loss: 0.14399684965610504
Validation loss: 1.5477524931712816

Epoch: 6| Step: 12
Training loss: 0.17262233793735504
Validation loss: 1.55127534045968

Epoch: 6| Step: 13
Training loss: 0.12703721225261688
Validation loss: 1.5560019323902745

Epoch: 403| Step: 0
Training loss: 0.21049919724464417
Validation loss: 1.5449894192398235

Epoch: 6| Step: 1
Training loss: 0.08999568969011307
Validation loss: 1.535561361620503

Epoch: 6| Step: 2
Training loss: 0.15004222095012665
Validation loss: 1.4816953597530242

Epoch: 6| Step: 3
Training loss: 0.11313968151807785
Validation loss: 1.5176578311509983

Epoch: 6| Step: 4
Training loss: 0.0956277996301651
Validation loss: 1.4937298733700988

Epoch: 6| Step: 5
Training loss: 0.19640740752220154
Validation loss: 1.5200883502601295

Epoch: 6| Step: 6
Training loss: 0.10627985000610352
Validation loss: 1.501135810728996

Epoch: 6| Step: 7
Training loss: 0.18823206424713135
Validation loss: 1.540451249768657

Epoch: 6| Step: 8
Training loss: 0.1298651546239853
Validation loss: 1.518733105351848

Epoch: 6| Step: 9
Training loss: 0.13788580894470215
Validation loss: 1.5341553431685253

Epoch: 6| Step: 10
Training loss: 0.11551603674888611
Validation loss: 1.5409806710417553

Epoch: 6| Step: 11
Training loss: 0.1263781189918518
Validation loss: 1.5381341595803537

Epoch: 6| Step: 12
Training loss: 0.17067033052444458
Validation loss: 1.526558970892301

Epoch: 6| Step: 13
Training loss: 0.14599087834358215
Validation loss: 1.5581769699691443

Epoch: 404| Step: 0
Training loss: 0.10831871628761292
Validation loss: 1.5401251880071496

Epoch: 6| Step: 1
Training loss: 0.09209022670984268
Validation loss: 1.5365015024779944

Epoch: 6| Step: 2
Training loss: 0.18743902444839478
Validation loss: 1.5614102860932708

Epoch: 6| Step: 3
Training loss: 0.13250160217285156
Validation loss: 1.5600341737911265

Epoch: 6| Step: 4
Training loss: 0.12362093478441238
Validation loss: 1.5801436311455184

Epoch: 6| Step: 5
Training loss: 0.1188664510846138
Validation loss: 1.5744426891367922

Epoch: 6| Step: 6
Training loss: 0.10658428817987442
Validation loss: 1.5597233131367674

Epoch: 6| Step: 7
Training loss: 0.13613958656787872
Validation loss: 1.539217145212235

Epoch: 6| Step: 8
Training loss: 0.14156413078308105
Validation loss: 1.5475364167203185

Epoch: 6| Step: 9
Training loss: 0.22258494794368744
Validation loss: 1.5399153886302825

Epoch: 6| Step: 10
Training loss: 0.10686831176280975
Validation loss: 1.52882073643387

Epoch: 6| Step: 11
Training loss: 0.18040123581886292
Validation loss: 1.5290100689857238

Epoch: 6| Step: 12
Training loss: 0.14612968266010284
Validation loss: 1.542173586865907

Epoch: 6| Step: 13
Training loss: 0.17101256549358368
Validation loss: 1.5498794842791814

Epoch: 405| Step: 0
Training loss: 0.12133365124464035
Validation loss: 1.533186621563409

Epoch: 6| Step: 1
Training loss: 0.16355113685131073
Validation loss: 1.5340841713772024

Epoch: 6| Step: 2
Training loss: 0.16839347779750824
Validation loss: 1.5386997217773108

Epoch: 6| Step: 3
Training loss: 0.08990146219730377
Validation loss: 1.5377209314735987

Epoch: 6| Step: 4
Training loss: 0.15264976024627686
Validation loss: 1.5300065368734381

Epoch: 6| Step: 5
Training loss: 0.16549691557884216
Validation loss: 1.5465055204206897

Epoch: 6| Step: 6
Training loss: 0.10764927417039871
Validation loss: 1.575770496040262

Epoch: 6| Step: 7
Training loss: 0.15590016543865204
Validation loss: 1.5839638197293846

Epoch: 6| Step: 8
Training loss: 0.1549604833126068
Validation loss: 1.5789163599732101

Epoch: 6| Step: 9
Training loss: 0.09660910815000534
Validation loss: 1.58239487935138

Epoch: 6| Step: 10
Training loss: 0.21215805411338806
Validation loss: 1.5778804991834907

Epoch: 6| Step: 11
Training loss: 0.09404274821281433
Validation loss: 1.6029714089567944

Epoch: 6| Step: 12
Training loss: 0.14261522889137268
Validation loss: 1.565781948386982

Epoch: 6| Step: 13
Training loss: 0.16453753411769867
Validation loss: 1.5562336009035829

Epoch: 406| Step: 0
Training loss: 0.1346464455127716
Validation loss: 1.555628389440557

Epoch: 6| Step: 1
Training loss: 0.12800805270671844
Validation loss: 1.5114626987006075

Epoch: 6| Step: 2
Training loss: 0.08717351406812668
Validation loss: 1.5243544886189122

Epoch: 6| Step: 3
Training loss: 0.13589882850646973
Validation loss: 1.5383604393210462

Epoch: 6| Step: 4
Training loss: 0.2306501567363739
Validation loss: 1.5258107172545565

Epoch: 6| Step: 5
Training loss: 0.1559801995754242
Validation loss: 1.5195590552463327

Epoch: 6| Step: 6
Training loss: 0.14982742071151733
Validation loss: 1.5364857527517504

Epoch: 6| Step: 7
Training loss: 0.10880780965089798
Validation loss: 1.5105441321608841

Epoch: 6| Step: 8
Training loss: 0.17810964584350586
Validation loss: 1.5515770758351972

Epoch: 6| Step: 9
Training loss: 0.16353988647460938
Validation loss: 1.544434944788615

Epoch: 6| Step: 10
Training loss: 0.11725974828004837
Validation loss: 1.5434584233068651

Epoch: 6| Step: 11
Training loss: 0.20074190199375153
Validation loss: 1.5672960915873129

Epoch: 6| Step: 12
Training loss: 0.13312046229839325
Validation loss: 1.5466733389003302

Epoch: 6| Step: 13
Training loss: 0.11339427530765533
Validation loss: 1.540536509406182

Epoch: 407| Step: 0
Training loss: 0.1822156012058258
Validation loss: 1.5166324261696107

Epoch: 6| Step: 1
Training loss: 0.08653159439563751
Validation loss: 1.5199863410765124

Epoch: 6| Step: 2
Training loss: 0.23461756110191345
Validation loss: 1.5640525023142497

Epoch: 6| Step: 3
Training loss: 0.18205243349075317
Validation loss: 1.5274451676235403

Epoch: 6| Step: 4
Training loss: 0.1263616979122162
Validation loss: 1.5624813008052048

Epoch: 6| Step: 5
Training loss: 0.13408580422401428
Validation loss: 1.5378083400828864

Epoch: 6| Step: 6
Training loss: 0.1323280930519104
Validation loss: 1.530450842713797

Epoch: 6| Step: 7
Training loss: 0.1392315775156021
Validation loss: 1.486592735013654

Epoch: 6| Step: 8
Training loss: 0.1957642287015915
Validation loss: 1.4992027090441795

Epoch: 6| Step: 9
Training loss: 0.16384825110435486
Validation loss: 1.4998936332682127

Epoch: 6| Step: 10
Training loss: 0.1260722279548645
Validation loss: 1.5060752284142278

Epoch: 6| Step: 11
Training loss: 0.10779058933258057
Validation loss: 1.5154344663825086

Epoch: 6| Step: 12
Training loss: 0.09241856634616852
Validation loss: 1.5031680945427186

Epoch: 6| Step: 13
Training loss: 0.13035964965820312
Validation loss: 1.528431104075524

Epoch: 408| Step: 0
Training loss: 0.11365370452404022
Validation loss: 1.5225311568988267

Epoch: 6| Step: 1
Training loss: 0.12975123524665833
Validation loss: 1.5353369687193184

Epoch: 6| Step: 2
Training loss: 0.10611803829669952
Validation loss: 1.5567616275561753

Epoch: 6| Step: 3
Training loss: 0.1339094042778015
Validation loss: 1.5506721158181467

Epoch: 6| Step: 4
Training loss: 0.22290262579917908
Validation loss: 1.5685103195969776

Epoch: 6| Step: 5
Training loss: 0.20014292001724243
Validation loss: 1.5653148645995765

Epoch: 6| Step: 6
Training loss: 0.2693273425102234
Validation loss: 1.5562085451618317

Epoch: 6| Step: 7
Training loss: 0.17006678879261017
Validation loss: 1.5403051940343713

Epoch: 6| Step: 8
Training loss: 0.20588108897209167
Validation loss: 1.5314778012614096

Epoch: 6| Step: 9
Training loss: 0.18718501925468445
Validation loss: 1.516531890438449

Epoch: 6| Step: 10
Training loss: 0.23920521140098572
Validation loss: 1.4870020971503308

Epoch: 6| Step: 11
Training loss: 0.14829254150390625
Validation loss: 1.5142108714708717

Epoch: 6| Step: 12
Training loss: 0.15847089886665344
Validation loss: 1.5032033381923553

Epoch: 6| Step: 13
Training loss: 0.22217480838298798
Validation loss: 1.518918215587575

Epoch: 409| Step: 0
Training loss: 0.16672135889530182
Validation loss: 1.5070942307031283

Epoch: 6| Step: 1
Training loss: 0.20786607265472412
Validation loss: 1.5127077346206994

Epoch: 6| Step: 2
Training loss: 0.24033966660499573
Validation loss: 1.5460024585006058

Epoch: 6| Step: 3
Training loss: 0.15909960865974426
Validation loss: 1.550310387406298

Epoch: 6| Step: 4
Training loss: 0.15192189812660217
Validation loss: 1.5367550978096582

Epoch: 6| Step: 5
Training loss: 0.19075235724449158
Validation loss: 1.5568887405498053

Epoch: 6| Step: 6
Training loss: 0.24802401661872864
Validation loss: 1.5292407351155435

Epoch: 6| Step: 7
Training loss: 0.17870523035526276
Validation loss: 1.5375049268045733

Epoch: 6| Step: 8
Training loss: 0.09498587250709534
Validation loss: 1.5379376437074395

Epoch: 6| Step: 9
Training loss: 0.11092188209295273
Validation loss: 1.5694990004262617

Epoch: 6| Step: 10
Training loss: 0.1301206350326538
Validation loss: 1.5415979431521507

Epoch: 6| Step: 11
Training loss: 0.08295310288667679
Validation loss: 1.545623428078108

Epoch: 6| Step: 12
Training loss: 0.09026191383600235
Validation loss: 1.5299981371048959

Epoch: 6| Step: 13
Training loss: 0.30511167645454407
Validation loss: 1.5401780695043585

Epoch: 410| Step: 0
Training loss: 0.1701754778623581
Validation loss: 1.5148699437418292

Epoch: 6| Step: 1
Training loss: 0.16857001185417175
Validation loss: 1.5191403435122581

Epoch: 6| Step: 2
Training loss: 0.09091193974018097
Validation loss: 1.5184895043732018

Epoch: 6| Step: 3
Training loss: 0.09060220420360565
Validation loss: 1.523632881461933

Epoch: 6| Step: 4
Training loss: 0.10706193745136261
Validation loss: 1.5364985581367248

Epoch: 6| Step: 5
Training loss: 0.12849608063697815
Validation loss: 1.485197490261447

Epoch: 6| Step: 6
Training loss: 0.22085270285606384
Validation loss: 1.5415717658176218

Epoch: 6| Step: 7
Training loss: 0.1535795032978058
Validation loss: 1.5095714728037517

Epoch: 6| Step: 8
Training loss: 0.14562320709228516
Validation loss: 1.4980851616910709

Epoch: 6| Step: 9
Training loss: 0.18154487013816833
Validation loss: 1.491372094359449

Epoch: 6| Step: 10
Training loss: 0.14196188747882843
Validation loss: 1.475149934009839

Epoch: 6| Step: 11
Training loss: 0.10458576679229736
Validation loss: 1.4999203976764475

Epoch: 6| Step: 12
Training loss: 0.16408124566078186
Validation loss: 1.4810772890685706

Epoch: 6| Step: 13
Training loss: 0.24811533093452454
Validation loss: 1.4931266397558234

Epoch: 411| Step: 0
Training loss: 0.15808390080928802
Validation loss: 1.4960476659959363

Epoch: 6| Step: 1
Training loss: 0.17281872034072876
Validation loss: 1.4744216319053405

Epoch: 6| Step: 2
Training loss: 0.11725126206874847
Validation loss: 1.4889315892291326

Epoch: 6| Step: 3
Training loss: 0.13349804282188416
Validation loss: 1.5114648342132568

Epoch: 6| Step: 4
Training loss: 0.1300208419561386
Validation loss: 1.5085964824563713

Epoch: 6| Step: 5
Training loss: 0.0888979583978653
Validation loss: 1.5183188915252686

Epoch: 6| Step: 6
Training loss: 0.1614069640636444
Validation loss: 1.4990028264702007

Epoch: 6| Step: 7
Training loss: 0.06716153025627136
Validation loss: 1.5003004868825276

Epoch: 6| Step: 8
Training loss: 0.11946110427379608
Validation loss: 1.5415758061152633

Epoch: 6| Step: 9
Training loss: 0.2832871079444885
Validation loss: 1.513250684225431

Epoch: 6| Step: 10
Training loss: 0.0799914002418518
Validation loss: 1.4766849266585482

Epoch: 6| Step: 11
Training loss: 0.17793110013008118
Validation loss: 1.500438013384419

Epoch: 6| Step: 12
Training loss: 0.15716098248958588
Validation loss: 1.50286574773891

Epoch: 6| Step: 13
Training loss: 0.15088818967342377
Validation loss: 1.5069581231763285

Epoch: 412| Step: 0
Training loss: 0.10763217508792877
Validation loss: 1.5154266049785

Epoch: 6| Step: 1
Training loss: 0.0947309285402298
Validation loss: 1.5162800281278548

Epoch: 6| Step: 2
Training loss: 0.1552809327840805
Validation loss: 1.484736038792518

Epoch: 6| Step: 3
Training loss: 0.13593432307243347
Validation loss: 1.48626027184148

Epoch: 6| Step: 4
Training loss: 0.12199624627828598
Validation loss: 1.4705021387787276

Epoch: 6| Step: 5
Training loss: 0.18785327672958374
Validation loss: 1.4925863499282508

Epoch: 6| Step: 6
Training loss: 0.18259704113006592
Validation loss: 1.4871909054376746

Epoch: 6| Step: 7
Training loss: 0.14827406406402588
Validation loss: 1.4897522887875956

Epoch: 6| Step: 8
Training loss: 0.10153597593307495
Validation loss: 1.4743164380391438

Epoch: 6| Step: 9
Training loss: 0.12114858627319336
Validation loss: 1.5073791626961

Epoch: 6| Step: 10
Training loss: 0.09383465349674225
Validation loss: 1.4765945596079673

Epoch: 6| Step: 11
Training loss: 0.13566619157791138
Validation loss: 1.5038529288384221

Epoch: 6| Step: 12
Training loss: 0.14619822800159454
Validation loss: 1.5287646696131716

Epoch: 6| Step: 13
Training loss: 0.18221057951450348
Validation loss: 1.5438350887708767

Epoch: 413| Step: 0
Training loss: 0.120806023478508
Validation loss: 1.5554393991347282

Epoch: 6| Step: 1
Training loss: 0.21439209580421448
Validation loss: 1.5440065386474773

Epoch: 6| Step: 2
Training loss: 0.16225464642047882
Validation loss: 1.539757909313325

Epoch: 6| Step: 3
Training loss: 0.13468623161315918
Validation loss: 1.5251327624884985

Epoch: 6| Step: 4
Training loss: 0.16398154199123383
Validation loss: 1.5033960842317151

Epoch: 6| Step: 5
Training loss: 0.14989477396011353
Validation loss: 1.5052829224576232

Epoch: 6| Step: 6
Training loss: 0.204138845205307
Validation loss: 1.5003422152611516

Epoch: 6| Step: 7
Training loss: 0.16524291038513184
Validation loss: 1.486338629517504

Epoch: 6| Step: 8
Training loss: 0.11417965590953827
Validation loss: 1.4965490653950682

Epoch: 6| Step: 9
Training loss: 0.15918245911598206
Validation loss: 1.4874216702676588

Epoch: 6| Step: 10
Training loss: 0.21872872114181519
Validation loss: 1.46360388494307

Epoch: 6| Step: 11
Training loss: 0.17983490228652954
Validation loss: 1.4743435331570205

Epoch: 6| Step: 12
Training loss: 0.11168543994426727
Validation loss: 1.4661134853157947

Epoch: 6| Step: 13
Training loss: 0.06793832778930664
Validation loss: 1.465063420675134

Epoch: 414| Step: 0
Training loss: 0.13122177124023438
Validation loss: 1.4646018487150951

Epoch: 6| Step: 1
Training loss: 0.15223047137260437
Validation loss: 1.4422800746015323

Epoch: 6| Step: 2
Training loss: 0.12606051564216614
Validation loss: 1.4534739223859643

Epoch: 6| Step: 3
Training loss: 0.18661226332187653
Validation loss: 1.4616965145193122

Epoch: 6| Step: 4
Training loss: 0.07861842215061188
Validation loss: 1.461576163127858

Epoch: 6| Step: 5
Training loss: 0.11417832225561142
Validation loss: 1.464932817925689

Epoch: 6| Step: 6
Training loss: 0.09873782098293304
Validation loss: 1.4787562636918918

Epoch: 6| Step: 7
Training loss: 0.11421775817871094
Validation loss: 1.5131832925222253

Epoch: 6| Step: 8
Training loss: 0.07772158086299896
Validation loss: 1.5452736103406517

Epoch: 6| Step: 9
Training loss: 0.17637833952903748
Validation loss: 1.5248171860171902

Epoch: 6| Step: 10
Training loss: 0.19356434047222137
Validation loss: 1.5419816317096833

Epoch: 6| Step: 11
Training loss: 0.15086916089057922
Validation loss: 1.5473038252963816

Epoch: 6| Step: 12
Training loss: 0.19371449947357178
Validation loss: 1.5554995972623107

Epoch: 6| Step: 13
Training loss: 0.10985999554395676
Validation loss: 1.5387378046589513

Epoch: 415| Step: 0
Training loss: 0.1401626318693161
Validation loss: 1.5199444511885285

Epoch: 6| Step: 1
Training loss: 0.1160505935549736
Validation loss: 1.5332601378040929

Epoch: 6| Step: 2
Training loss: 0.09656237065792084
Validation loss: 1.5336445275173392

Epoch: 6| Step: 3
Training loss: 0.11844882369041443
Validation loss: 1.528177486952915

Epoch: 6| Step: 4
Training loss: 0.14167369902133942
Validation loss: 1.5279760886264104

Epoch: 6| Step: 5
Training loss: 0.18549415469169617
Validation loss: 1.5486821141294254

Epoch: 6| Step: 6
Training loss: 0.2029435634613037
Validation loss: 1.586061054660428

Epoch: 6| Step: 7
Training loss: 0.1594271957874298
Validation loss: 1.5831694013328963

Epoch: 6| Step: 8
Training loss: 0.13703134655952454
Validation loss: 1.5678741829369658

Epoch: 6| Step: 9
Training loss: 0.09620416164398193
Validation loss: 1.5638024358339206

Epoch: 6| Step: 10
Training loss: 0.0977998673915863
Validation loss: 1.5174065994960007

Epoch: 6| Step: 11
Training loss: 0.07942447066307068
Validation loss: 1.53411695777729

Epoch: 6| Step: 12
Training loss: 0.08245822787284851
Validation loss: 1.5357439594884073

Epoch: 6| Step: 13
Training loss: 0.10394848883152008
Validation loss: 1.4924551697187527

Epoch: 416| Step: 0
Training loss: 0.1006360799074173
Validation loss: 1.5130408092211651

Epoch: 6| Step: 1
Training loss: 0.1168152391910553
Validation loss: 1.4962542992766186

Epoch: 6| Step: 2
Training loss: 0.1800205111503601
Validation loss: 1.520647515532791

Epoch: 6| Step: 3
Training loss: 0.17769771814346313
Validation loss: 1.5717835823694866

Epoch: 6| Step: 4
Training loss: 0.16933077573776245
Validation loss: 1.5487669667889994

Epoch: 6| Step: 5
Training loss: 0.18531879782676697
Validation loss: 1.547746794839059

Epoch: 6| Step: 6
Training loss: 0.2188647985458374
Validation loss: 1.5810842424310663

Epoch: 6| Step: 7
Training loss: 0.08691282570362091
Validation loss: 1.5820728873693815

Epoch: 6| Step: 8
Training loss: 0.10475729405879974
Validation loss: 1.5663272539774578

Epoch: 6| Step: 9
Training loss: 0.1746056228876114
Validation loss: 1.6011674365689677

Epoch: 6| Step: 10
Training loss: 0.14867648482322693
Validation loss: 1.5921449622800272

Epoch: 6| Step: 11
Training loss: 0.1314375400543213
Validation loss: 1.5900284936351161

Epoch: 6| Step: 12
Training loss: 0.1593170166015625
Validation loss: 1.5764212621155607

Epoch: 6| Step: 13
Training loss: 0.1339678317308426
Validation loss: 1.5604040109983055

Epoch: 417| Step: 0
Training loss: 0.17347587645053864
Validation loss: 1.5473462509852585

Epoch: 6| Step: 1
Training loss: 0.13155007362365723
Validation loss: 1.5332004793228642

Epoch: 6| Step: 2
Training loss: 0.10328136384487152
Validation loss: 1.5177713376219555

Epoch: 6| Step: 3
Training loss: 0.1243792474269867
Validation loss: 1.5080599015758884

Epoch: 6| Step: 4
Training loss: 0.1382269561290741
Validation loss: 1.5301487317649267

Epoch: 6| Step: 5
Training loss: 0.1246485784649849
Validation loss: 1.5118468910135248

Epoch: 6| Step: 6
Training loss: 0.12164409458637238
Validation loss: 1.5149770129111506

Epoch: 6| Step: 7
Training loss: 0.113075390458107
Validation loss: 1.4938462434276458

Epoch: 6| Step: 8
Training loss: 0.08741961419582367
Validation loss: 1.5006956413228025

Epoch: 6| Step: 9
Training loss: 0.10256429016590118
Validation loss: 1.5044348124534852

Epoch: 6| Step: 10
Training loss: 0.11364090442657471
Validation loss: 1.5206930470722977

Epoch: 6| Step: 11
Training loss: 0.12142978608608246
Validation loss: 1.5078680989562825

Epoch: 6| Step: 12
Training loss: 0.1019967719912529
Validation loss: 1.5458465289044123

Epoch: 6| Step: 13
Training loss: 0.19407548010349274
Validation loss: 1.5327454869465162

Epoch: 418| Step: 0
Training loss: 0.12036261707544327
Validation loss: 1.534644898547921

Epoch: 6| Step: 1
Training loss: 0.12535741925239563
Validation loss: 1.5521475711176473

Epoch: 6| Step: 2
Training loss: 0.19003064930438995
Validation loss: 1.521285524932287

Epoch: 6| Step: 3
Training loss: 0.173383429646492
Validation loss: 1.548173899291664

Epoch: 6| Step: 4
Training loss: 0.14189986884593964
Validation loss: 1.5325735589509368

Epoch: 6| Step: 5
Training loss: 0.13148412108421326
Validation loss: 1.5499547796864663

Epoch: 6| Step: 6
Training loss: 0.0745151937007904
Validation loss: 1.532042295702042

Epoch: 6| Step: 7
Training loss: 0.13010777533054352
Validation loss: 1.5067687483244045

Epoch: 6| Step: 8
Training loss: 0.06338932365179062
Validation loss: 1.5105671856992988

Epoch: 6| Step: 9
Training loss: 0.10595721006393433
Validation loss: 1.5011858453032791

Epoch: 6| Step: 10
Training loss: 0.1621420532464981
Validation loss: 1.501413647846509

Epoch: 6| Step: 11
Training loss: 0.0898578017950058
Validation loss: 1.4874802045924689

Epoch: 6| Step: 12
Training loss: 0.12636035680770874
Validation loss: 1.5327552903083064

Epoch: 6| Step: 13
Training loss: 0.11991024017333984
Validation loss: 1.5209091927415581

Epoch: 419| Step: 0
Training loss: 0.12753070890903473
Validation loss: 1.5142706978705622

Epoch: 6| Step: 1
Training loss: 0.08845105022192001
Validation loss: 1.510413351879325

Epoch: 6| Step: 2
Training loss: 0.11967118084430695
Validation loss: 1.5088314215342205

Epoch: 6| Step: 3
Training loss: 0.11721333861351013
Validation loss: 1.5225724481767224

Epoch: 6| Step: 4
Training loss: 0.06832389533519745
Validation loss: 1.5146624465142526

Epoch: 6| Step: 5
Training loss: 0.18925097584724426
Validation loss: 1.496443175500439

Epoch: 6| Step: 6
Training loss: 0.15551991760730743
Validation loss: 1.5241290036068167

Epoch: 6| Step: 7
Training loss: 0.14011812210083008
Validation loss: 1.5536857401171038

Epoch: 6| Step: 8
Training loss: 0.11022158712148666
Validation loss: 1.5111356307101507

Epoch: 6| Step: 9
Training loss: 0.13608676195144653
Validation loss: 1.5108878766336749

Epoch: 6| Step: 10
Training loss: 0.07355918735265732
Validation loss: 1.5339033462667977

Epoch: 6| Step: 11
Training loss: 0.07840710878372192
Validation loss: 1.5002877455885693

Epoch: 6| Step: 12
Training loss: 0.14047834277153015
Validation loss: 1.5061972211765986

Epoch: 6| Step: 13
Training loss: 0.12738434970378876
Validation loss: 1.5022063050218808

Epoch: 420| Step: 0
Training loss: 0.08500021696090698
Validation loss: 1.4932939570437196

Epoch: 6| Step: 1
Training loss: 0.12136147916316986
Validation loss: 1.4587608332275062

Epoch: 6| Step: 2
Training loss: 0.08701539784669876
Validation loss: 1.4972843329111736

Epoch: 6| Step: 3
Training loss: 0.2195848822593689
Validation loss: 1.4770991468942294

Epoch: 6| Step: 4
Training loss: 0.15324030816555023
Validation loss: 1.5072687851485385

Epoch: 6| Step: 5
Training loss: 0.06792549788951874
Validation loss: 1.5188885683654456

Epoch: 6| Step: 6
Training loss: 0.12424163520336151
Validation loss: 1.4871875855230516

Epoch: 6| Step: 7
Training loss: 0.188048854470253
Validation loss: 1.5085483007533576

Epoch: 6| Step: 8
Training loss: 0.08924078941345215
Validation loss: 1.4717955025293494

Epoch: 6| Step: 9
Training loss: 0.1206996738910675
Validation loss: 1.467816129807503

Epoch: 6| Step: 10
Training loss: 0.08498696982860565
Validation loss: 1.4860964411048478

Epoch: 6| Step: 11
Training loss: 0.06506728380918503
Validation loss: 1.4854734546394759

Epoch: 6| Step: 12
Training loss: 0.27660703659057617
Validation loss: 1.5081238298005955

Epoch: 6| Step: 13
Training loss: 0.09076926112174988
Validation loss: 1.4821780285527628

Epoch: 421| Step: 0
Training loss: 0.2004106044769287
Validation loss: 1.464751092336511

Epoch: 6| Step: 1
Training loss: 0.07503694295883179
Validation loss: 1.4770901126246299

Epoch: 6| Step: 2
Training loss: 0.14436164498329163
Validation loss: 1.460029830855708

Epoch: 6| Step: 3
Training loss: 0.07749339938163757
Validation loss: 1.4750781905266546

Epoch: 6| Step: 4
Training loss: 0.08921913802623749
Validation loss: 1.480654070454259

Epoch: 6| Step: 5
Training loss: 0.07992903143167496
Validation loss: 1.4852004653664046

Epoch: 6| Step: 6
Training loss: 0.11678227037191391
Validation loss: 1.491803797342444

Epoch: 6| Step: 7
Training loss: 0.08865006268024445
Validation loss: 1.4971294044166483

Epoch: 6| Step: 8
Training loss: 0.09721411019563675
Validation loss: 1.4948337680550032

Epoch: 6| Step: 9
Training loss: 0.09424007683992386
Validation loss: 1.5131183619140296

Epoch: 6| Step: 10
Training loss: 0.12955918908119202
Validation loss: 1.5129597007587392

Epoch: 6| Step: 11
Training loss: 0.08379562199115753
Validation loss: 1.4984601659159507

Epoch: 6| Step: 12
Training loss: 0.09214991331100464
Validation loss: 1.5364071912662958

Epoch: 6| Step: 13
Training loss: 0.16850239038467407
Validation loss: 1.5473905404408772

Epoch: 422| Step: 0
Training loss: 0.08768589794635773
Validation loss: 1.549098576268842

Epoch: 6| Step: 1
Training loss: 0.19247037172317505
Validation loss: 1.5067660706017607

Epoch: 6| Step: 2
Training loss: 0.09302562475204468
Validation loss: 1.47530750689968

Epoch: 6| Step: 3
Training loss: 0.1481245905160904
Validation loss: 1.4524845730873845

Epoch: 6| Step: 4
Training loss: 0.0756310224533081
Validation loss: 1.471848104589729

Epoch: 6| Step: 5
Training loss: 0.12328721582889557
Validation loss: 1.4540927679308

Epoch: 6| Step: 6
Training loss: 0.10222683846950531
Validation loss: 1.4815344220848494

Epoch: 6| Step: 7
Training loss: 0.10167046636343002
Validation loss: 1.4669322147164294

Epoch: 6| Step: 8
Training loss: 0.1575155258178711
Validation loss: 1.4746892618876632

Epoch: 6| Step: 9
Training loss: 0.14164716005325317
Validation loss: 1.4662986929698656

Epoch: 6| Step: 10
Training loss: 0.16058796644210815
Validation loss: 1.4564498983403689

Epoch: 6| Step: 11
Training loss: 0.11845531314611435
Validation loss: 1.4656943480173747

Epoch: 6| Step: 12
Training loss: 0.10056134313344955
Validation loss: 1.4717076401556692

Epoch: 6| Step: 13
Training loss: 0.1546711027622223
Validation loss: 1.4492950567635157

Epoch: 423| Step: 0
Training loss: 0.08269411325454712
Validation loss: 1.471316546522161

Epoch: 6| Step: 1
Training loss: 0.07004572451114655
Validation loss: 1.4692969065840527

Epoch: 6| Step: 2
Training loss: 0.09197110682725906
Validation loss: 1.4705372433508597

Epoch: 6| Step: 3
Training loss: 0.10543699562549591
Validation loss: 1.4541928024702175

Epoch: 6| Step: 4
Training loss: 0.18354609608650208
Validation loss: 1.47496864744412

Epoch: 6| Step: 5
Training loss: 0.06555217504501343
Validation loss: 1.492427259363154

Epoch: 6| Step: 6
Training loss: 0.09502483904361725
Validation loss: 1.4983381558490056

Epoch: 6| Step: 7
Training loss: 0.15295784175395966
Validation loss: 1.4879452143946001

Epoch: 6| Step: 8
Training loss: 0.12072315812110901
Validation loss: 1.4984926190427554

Epoch: 6| Step: 9
Training loss: 0.11553315073251724
Validation loss: 1.5185448674745456

Epoch: 6| Step: 10
Training loss: 0.13083824515342712
Validation loss: 1.5242424780322659

Epoch: 6| Step: 11
Training loss: 0.07811527699232101
Validation loss: 1.5023992561524915

Epoch: 6| Step: 12
Training loss: 0.1727607250213623
Validation loss: 1.520480695591178

Epoch: 6| Step: 13
Training loss: 0.12986382842063904
Validation loss: 1.5208921253040273

Epoch: 424| Step: 0
Training loss: 0.11694571375846863
Validation loss: 1.5192548754394695

Epoch: 6| Step: 1
Training loss: 0.1143593043088913
Validation loss: 1.5315764386166808

Epoch: 6| Step: 2
Training loss: 0.13083060085773468
Validation loss: 1.5134450594584148

Epoch: 6| Step: 3
Training loss: 0.09123485535383224
Validation loss: 1.5222008356484034

Epoch: 6| Step: 4
Training loss: 0.08569732308387756
Validation loss: 1.5166756337688816

Epoch: 6| Step: 5
Training loss: 0.17339462041854858
Validation loss: 1.5156637840373541

Epoch: 6| Step: 6
Training loss: 0.03806321322917938
Validation loss: 1.5216459997238652

Epoch: 6| Step: 7
Training loss: 0.14791566133499146
Validation loss: 1.5348661958530385

Epoch: 6| Step: 8
Training loss: 0.1685740351676941
Validation loss: 1.548292544580275

Epoch: 6| Step: 9
Training loss: 0.07940196245908737
Validation loss: 1.5560811963132632

Epoch: 6| Step: 10
Training loss: 0.10321858525276184
Validation loss: 1.5635257472274124

Epoch: 6| Step: 11
Training loss: 0.15510830283164978
Validation loss: 1.5180867346384193

Epoch: 6| Step: 12
Training loss: 0.08839324116706848
Validation loss: 1.5487345585259058

Epoch: 6| Step: 13
Training loss: 0.18672747910022736
Validation loss: 1.5351025705696435

Epoch: 425| Step: 0
Training loss: 0.07757703959941864
Validation loss: 1.5323898933267082

Epoch: 6| Step: 1
Training loss: 0.09971509873867035
Validation loss: 1.5337131100316201

Epoch: 6| Step: 2
Training loss: 0.14902645349502563
Validation loss: 1.5129984899233746

Epoch: 6| Step: 3
Training loss: 0.12028788030147552
Validation loss: 1.5086448525869718

Epoch: 6| Step: 4
Training loss: 0.14717739820480347
Validation loss: 1.487279188248419

Epoch: 6| Step: 5
Training loss: 0.14801247417926788
Validation loss: 1.4804122178785262

Epoch: 6| Step: 6
Training loss: 0.12347917258739471
Validation loss: 1.4805260678773284

Epoch: 6| Step: 7
Training loss: 0.2094179093837738
Validation loss: 1.4878099861965384

Epoch: 6| Step: 8
Training loss: 0.2293369174003601
Validation loss: 1.5198329225663216

Epoch: 6| Step: 9
Training loss: 0.17466670274734497
Validation loss: 1.4967205973081692

Epoch: 6| Step: 10
Training loss: 0.12043532729148865
Validation loss: 1.499440618740615

Epoch: 6| Step: 11
Training loss: 0.10186672955751419
Validation loss: 1.51331441825436

Epoch: 6| Step: 12
Training loss: 0.14138494431972504
Validation loss: 1.535939440932325

Epoch: 6| Step: 13
Training loss: 0.23092563450336456
Validation loss: 1.518861944957446

Epoch: 426| Step: 0
Training loss: 0.10359834879636765
Validation loss: 1.5272395392899871

Epoch: 6| Step: 1
Training loss: 0.10804446041584015
Validation loss: 1.5552886801381265

Epoch: 6| Step: 2
Training loss: 0.09218518435955048
Validation loss: 1.5211641750028055

Epoch: 6| Step: 3
Training loss: 0.18850259482860565
Validation loss: 1.5291532149878881

Epoch: 6| Step: 4
Training loss: 0.14907272160053253
Validation loss: 1.5183434845298849

Epoch: 6| Step: 5
Training loss: 0.15591734647750854
Validation loss: 1.5007491637301702

Epoch: 6| Step: 6
Training loss: 0.09137770533561707
Validation loss: 1.5287316435126848

Epoch: 6| Step: 7
Training loss: 0.16715645790100098
Validation loss: 1.5011625597553868

Epoch: 6| Step: 8
Training loss: 0.18305572867393494
Validation loss: 1.5099094362669094

Epoch: 6| Step: 9
Training loss: 0.11733640730381012
Validation loss: 1.5106352119035618

Epoch: 6| Step: 10
Training loss: 0.11513695120811462
Validation loss: 1.4988058908011324

Epoch: 6| Step: 11
Training loss: 0.09458624571561813
Validation loss: 1.5301222929390528

Epoch: 6| Step: 12
Training loss: 0.17667897045612335
Validation loss: 1.4927153587341309

Epoch: 6| Step: 13
Training loss: 0.10101857781410217
Validation loss: 1.485835841906968

Epoch: 427| Step: 0
Training loss: 0.14871272444725037
Validation loss: 1.4643268867205548

Epoch: 6| Step: 1
Training loss: 0.13765807449817657
Validation loss: 1.4732853751028738

Epoch: 6| Step: 2
Training loss: 0.17738711833953857
Validation loss: 1.4987185732010873

Epoch: 6| Step: 3
Training loss: 0.10876161605119705
Validation loss: 1.4730720558474142

Epoch: 6| Step: 4
Training loss: 0.12625084817409515
Validation loss: 1.5229750705021683

Epoch: 6| Step: 5
Training loss: 0.19257593154907227
Validation loss: 1.5013334174310007

Epoch: 6| Step: 6
Training loss: 0.11033742129802704
Validation loss: 1.508207417303516

Epoch: 6| Step: 7
Training loss: 0.13374479115009308
Validation loss: 1.4747689385567941

Epoch: 6| Step: 8
Training loss: 0.051932238042354584
Validation loss: 1.4872603954807404

Epoch: 6| Step: 9
Training loss: 0.11940301954746246
Validation loss: 1.5015899148038638

Epoch: 6| Step: 10
Training loss: 0.08704371005296707
Validation loss: 1.522061421025184

Epoch: 6| Step: 11
Training loss: 0.0629349946975708
Validation loss: 1.4981442548895394

Epoch: 6| Step: 12
Training loss: 0.08235492557287216
Validation loss: 1.5060857380590131

Epoch: 6| Step: 13
Training loss: 0.05100954324007034
Validation loss: 1.5243164864919518

Epoch: 428| Step: 0
Training loss: 0.0934223085641861
Validation loss: 1.5390735646729827

Epoch: 6| Step: 1
Training loss: 0.14646396040916443
Validation loss: 1.5163666509812879

Epoch: 6| Step: 2
Training loss: 0.12712107598781586
Validation loss: 1.5303018708382883

Epoch: 6| Step: 3
Training loss: 0.12037470191717148
Validation loss: 1.5039465318443954

Epoch: 6| Step: 4
Training loss: 0.14761649072170258
Validation loss: 1.4799723112454979

Epoch: 6| Step: 5
Training loss: 0.10261721909046173
Validation loss: 1.4751744501052364

Epoch: 6| Step: 6
Training loss: 0.11337213218212128
Validation loss: 1.4485145230447092

Epoch: 6| Step: 7
Training loss: 0.13839828968048096
Validation loss: 1.4478414199685539

Epoch: 6| Step: 8
Training loss: 0.11032534390687943
Validation loss: 1.4582443698760001

Epoch: 6| Step: 9
Training loss: 0.1405450999736786
Validation loss: 1.4311543869715866

Epoch: 6| Step: 10
Training loss: 0.0982639491558075
Validation loss: 1.4382362916905393

Epoch: 6| Step: 11
Training loss: 0.10903128236532211
Validation loss: 1.4216610295798189

Epoch: 6| Step: 12
Training loss: 0.09193751215934753
Validation loss: 1.4635197475392332

Epoch: 6| Step: 13
Training loss: 0.11034427583217621
Validation loss: 1.452947303812991

Epoch: 429| Step: 0
Training loss: 0.09121756255626678
Validation loss: 1.453666797248266

Epoch: 6| Step: 1
Training loss: 0.16198578476905823
Validation loss: 1.480485588632604

Epoch: 6| Step: 2
Training loss: 0.10230036079883575
Validation loss: 1.4806846213597122

Epoch: 6| Step: 3
Training loss: 0.14780811965465546
Validation loss: 1.4932842857094222

Epoch: 6| Step: 4
Training loss: 0.07846713811159134
Validation loss: 1.4850587806394022

Epoch: 6| Step: 5
Training loss: 0.09924232959747314
Validation loss: 1.5171139163355674

Epoch: 6| Step: 6
Training loss: 0.13305845856666565
Validation loss: 1.5070611488434575

Epoch: 6| Step: 7
Training loss: 0.1046459972858429
Validation loss: 1.5396760612405755

Epoch: 6| Step: 8
Training loss: 0.13991543650627136
Validation loss: 1.5313023226235503

Epoch: 6| Step: 9
Training loss: 0.1187341958284378
Validation loss: 1.5457278246520667

Epoch: 6| Step: 10
Training loss: 0.11834223568439484
Validation loss: 1.5544676960155528

Epoch: 6| Step: 11
Training loss: 0.18561123311519623
Validation loss: 1.546858077408165

Epoch: 6| Step: 12
Training loss: 0.16959604620933533
Validation loss: 1.5466915176760765

Epoch: 6| Step: 13
Training loss: 0.1206444501876831
Validation loss: 1.528490072937422

Epoch: 430| Step: 0
Training loss: 0.131529301404953
Validation loss: 1.5176528628154466

Epoch: 6| Step: 1
Training loss: 0.11027584969997406
Validation loss: 1.5146011985758299

Epoch: 6| Step: 2
Training loss: 0.12626710534095764
Validation loss: 1.5246638277525544

Epoch: 6| Step: 3
Training loss: 0.2163238525390625
Validation loss: 1.505473756021069

Epoch: 6| Step: 4
Training loss: 0.17540380358695984
Validation loss: 1.5124860963513773

Epoch: 6| Step: 5
Training loss: 0.13625334203243256
Validation loss: 1.5166545837156233

Epoch: 6| Step: 6
Training loss: 0.10080084204673767
Validation loss: 1.5119157234827678

Epoch: 6| Step: 7
Training loss: 0.09379754960536957
Validation loss: 1.540935698375907

Epoch: 6| Step: 8
Training loss: 0.09333529323339462
Validation loss: 1.508508401532327

Epoch: 6| Step: 9
Training loss: 0.1574205458164215
Validation loss: 1.4787689255129906

Epoch: 6| Step: 10
Training loss: 0.08620991557836533
Validation loss: 1.4700940501305364

Epoch: 6| Step: 11
Training loss: 0.14631667733192444
Validation loss: 1.4750779405716927

Epoch: 6| Step: 12
Training loss: 0.15748867392539978
Validation loss: 1.5046139506883518

Epoch: 6| Step: 13
Training loss: 0.10020378232002258
Validation loss: 1.505932900213426

Epoch: 431| Step: 0
Training loss: 0.15154573321342468
Validation loss: 1.516876269412297

Epoch: 6| Step: 1
Training loss: 0.14272171258926392
Validation loss: 1.5280716855038878

Epoch: 6| Step: 2
Training loss: 0.14516325294971466
Validation loss: 1.542849732983497

Epoch: 6| Step: 3
Training loss: 0.18382641673088074
Validation loss: 1.5549878317822692

Epoch: 6| Step: 4
Training loss: 0.15917611122131348
Validation loss: 1.5564791592218543

Epoch: 6| Step: 5
Training loss: 0.12223993986845016
Validation loss: 1.5355799262241652

Epoch: 6| Step: 6
Training loss: 0.13550172746181488
Validation loss: 1.5414429723575551

Epoch: 6| Step: 7
Training loss: 0.19957396388053894
Validation loss: 1.5453831008685532

Epoch: 6| Step: 8
Training loss: 0.11875467747449875
Validation loss: 1.5357822923250095

Epoch: 6| Step: 9
Training loss: 0.10494499653577805
Validation loss: 1.4826680793557117

Epoch: 6| Step: 10
Training loss: 0.15001511573791504
Validation loss: 1.509183112011161

Epoch: 6| Step: 11
Training loss: 0.155255988240242
Validation loss: 1.5190340408714869

Epoch: 6| Step: 12
Training loss: 0.13706378638744354
Validation loss: 1.5193061444067186

Epoch: 6| Step: 13
Training loss: 0.17436684668064117
Validation loss: 1.4989256589643416

Epoch: 432| Step: 0
Training loss: 0.11978452652692795
Validation loss: 1.502234996006053

Epoch: 6| Step: 1
Training loss: 0.12366385012865067
Validation loss: 1.4950812567946732

Epoch: 6| Step: 2
Training loss: 0.11496227979660034
Validation loss: 1.4831985286487046

Epoch: 6| Step: 3
Training loss: 0.1414414346218109
Validation loss: 1.5103065403558875

Epoch: 6| Step: 4
Training loss: 0.11325706541538239
Validation loss: 1.5046481547817108

Epoch: 6| Step: 5
Training loss: 0.16063368320465088
Validation loss: 1.4934092087130393

Epoch: 6| Step: 6
Training loss: 0.08847828209400177
Validation loss: 1.4661278135033065

Epoch: 6| Step: 7
Training loss: 0.12149515748023987
Validation loss: 1.4656594055955128

Epoch: 6| Step: 8
Training loss: 0.12485171109437943
Validation loss: 1.4806362672518658

Epoch: 6| Step: 9
Training loss: 0.17248022556304932
Validation loss: 1.5041176939523349

Epoch: 6| Step: 10
Training loss: 0.11850933730602264
Validation loss: 1.4798744647733626

Epoch: 6| Step: 11
Training loss: 0.1549806296825409
Validation loss: 1.4996730512188328

Epoch: 6| Step: 12
Training loss: 0.08074183017015457
Validation loss: 1.489081778833943

Epoch: 6| Step: 13
Training loss: 0.04641490802168846
Validation loss: 1.5093427652953773

Epoch: 433| Step: 0
Training loss: 0.11429715156555176
Validation loss: 1.5132160545677267

Epoch: 6| Step: 1
Training loss: 0.14651569724082947
Validation loss: 1.5106570592490576

Epoch: 6| Step: 2
Training loss: 0.07869857549667358
Validation loss: 1.505293055247235

Epoch: 6| Step: 3
Training loss: 0.09196952730417252
Validation loss: 1.5037315141770147

Epoch: 6| Step: 4
Training loss: 0.17669817805290222
Validation loss: 1.5172675527552122

Epoch: 6| Step: 5
Training loss: 0.07499656081199646
Validation loss: 1.4810753035288986

Epoch: 6| Step: 6
Training loss: 0.13067424297332764
Validation loss: 1.4887689813490836

Epoch: 6| Step: 7
Training loss: 0.09170476347208023
Validation loss: 1.5074128309885662

Epoch: 6| Step: 8
Training loss: 0.11274918913841248
Validation loss: 1.485275887673901

Epoch: 6| Step: 9
Training loss: 0.14817824959754944
Validation loss: 1.487452894128779

Epoch: 6| Step: 10
Training loss: 0.16470873355865479
Validation loss: 1.4760520522312452

Epoch: 6| Step: 11
Training loss: 0.08037406951189041
Validation loss: 1.4973629559240034

Epoch: 6| Step: 12
Training loss: 0.16578981280326843
Validation loss: 1.473036193078564

Epoch: 6| Step: 13
Training loss: 0.10883251577615738
Validation loss: 1.4927231201561548

Epoch: 434| Step: 0
Training loss: 0.1471666842699051
Validation loss: 1.4881326895888134

Epoch: 6| Step: 1
Training loss: 0.10932612419128418
Validation loss: 1.496608588003343

Epoch: 6| Step: 2
Training loss: 0.13263322412967682
Validation loss: 1.5020523071289062

Epoch: 6| Step: 3
Training loss: 0.128859281539917
Validation loss: 1.4894100517354987

Epoch: 6| Step: 4
Training loss: 0.1318105012178421
Validation loss: 1.4930747491057201

Epoch: 6| Step: 5
Training loss: 0.10754051804542542
Validation loss: 1.477576950544952

Epoch: 6| Step: 6
Training loss: 0.11567636579275131
Validation loss: 1.4818826619014944

Epoch: 6| Step: 7
Training loss: 0.09918786585330963
Validation loss: 1.453570468451387

Epoch: 6| Step: 8
Training loss: 0.11814714968204498
Validation loss: 1.493582769106793

Epoch: 6| Step: 9
Training loss: 0.09761141240596771
Validation loss: 1.4984308961899049

Epoch: 6| Step: 10
Training loss: 0.11930907517671585
Validation loss: 1.4675347292295067

Epoch: 6| Step: 11
Training loss: 0.09002529084682465
Validation loss: 1.4735300015377741

Epoch: 6| Step: 12
Training loss: 0.16828469932079315
Validation loss: 1.5014096485671176

Epoch: 6| Step: 13
Training loss: 0.13510163128376007
Validation loss: 1.5250732475711453

Epoch: 435| Step: 0
Training loss: 0.1496885120868683
Validation loss: 1.5249415648880826

Epoch: 6| Step: 1
Training loss: 0.1714724749326706
Validation loss: 1.4892344820883967

Epoch: 6| Step: 2
Training loss: 0.11706539988517761
Validation loss: 1.4661264759238049

Epoch: 6| Step: 3
Training loss: 0.09570947289466858
Validation loss: 1.4630786795769968

Epoch: 6| Step: 4
Training loss: 0.07977460324764252
Validation loss: 1.4902015809089906

Epoch: 6| Step: 5
Training loss: 0.14609724283218384
Validation loss: 1.4776907031254103

Epoch: 6| Step: 6
Training loss: 0.15113966166973114
Validation loss: 1.4970802850620721

Epoch: 6| Step: 7
Training loss: 0.08245112001895905
Validation loss: 1.471189102818889

Epoch: 6| Step: 8
Training loss: 0.09856535494327545
Validation loss: 1.4706565731315202

Epoch: 6| Step: 9
Training loss: 0.0710810050368309
Validation loss: 1.4795333070139731

Epoch: 6| Step: 10
Training loss: 0.13405567407608032
Validation loss: 1.5018116530551706

Epoch: 6| Step: 11
Training loss: 0.1329454481601715
Validation loss: 1.4729762551605061

Epoch: 6| Step: 12
Training loss: 0.10105197131633759
Validation loss: 1.491435718792741

Epoch: 6| Step: 13
Training loss: 0.2840512692928314
Validation loss: 1.5061128511223743

Epoch: 436| Step: 0
Training loss: 0.08147792518138885
Validation loss: 1.5225874403471589

Epoch: 6| Step: 1
Training loss: 0.07942050695419312
Validation loss: 1.5336784073101577

Epoch: 6| Step: 2
Training loss: 0.10665346682071686
Validation loss: 1.5493407326359903

Epoch: 6| Step: 3
Training loss: 0.12175381183624268
Validation loss: 1.5630356675835066

Epoch: 6| Step: 4
Training loss: 0.20225009322166443
Validation loss: 1.5680200540891258

Epoch: 6| Step: 5
Training loss: 0.11883209645748138
Validation loss: 1.5539219328152236

Epoch: 6| Step: 6
Training loss: 0.09461918473243713
Validation loss: 1.5374360302443146

Epoch: 6| Step: 7
Training loss: 0.17729738354682922
Validation loss: 1.5617259446010794

Epoch: 6| Step: 8
Training loss: 0.12435656040906906
Validation loss: 1.5457198094296198

Epoch: 6| Step: 9
Training loss: 0.08580853044986725
Validation loss: 1.53881210665549

Epoch: 6| Step: 10
Training loss: 0.13994038105010986
Validation loss: 1.5107349490606656

Epoch: 6| Step: 11
Training loss: 0.11551091820001602
Validation loss: 1.4970913279441096

Epoch: 6| Step: 12
Training loss: 0.14102181792259216
Validation loss: 1.5049814280643259

Epoch: 6| Step: 13
Training loss: 0.20728087425231934
Validation loss: 1.476624313221183

Epoch: 437| Step: 0
Training loss: 0.1382361501455307
Validation loss: 1.493965418108048

Epoch: 6| Step: 1
Training loss: 0.07058273255825043
Validation loss: 1.4809521693055347

Epoch: 6| Step: 2
Training loss: 0.14045080542564392
Validation loss: 1.492399509235095

Epoch: 6| Step: 3
Training loss: 0.1123216524720192
Validation loss: 1.4944250006829538

Epoch: 6| Step: 4
Training loss: 0.10847633332014084
Validation loss: 1.4911196199796533

Epoch: 6| Step: 5
Training loss: 0.15720464289188385
Validation loss: 1.5167386467738817

Epoch: 6| Step: 6
Training loss: 0.15101665258407593
Validation loss: 1.4740656127211869

Epoch: 6| Step: 7
Training loss: 0.10665417462587357
Validation loss: 1.4795393315694665

Epoch: 6| Step: 8
Training loss: 0.14781850576400757
Validation loss: 1.437535116749425

Epoch: 6| Step: 9
Training loss: 0.09221752732992172
Validation loss: 1.4395393735619002

Epoch: 6| Step: 10
Training loss: 0.18031978607177734
Validation loss: 1.4458490853668542

Epoch: 6| Step: 11
Training loss: 0.06916825473308563
Validation loss: 1.4607337982423845

Epoch: 6| Step: 12
Training loss: 0.10691823065280914
Validation loss: 1.4546604784586097

Epoch: 6| Step: 13
Training loss: 0.1581777036190033
Validation loss: 1.4472388836645311

Epoch: 438| Step: 0
Training loss: 0.05122051388025284
Validation loss: 1.4661246320252777

Epoch: 6| Step: 1
Training loss: 0.10209882259368896
Validation loss: 1.4454508481487152

Epoch: 6| Step: 2
Training loss: 0.16449329257011414
Validation loss: 1.4727469041783323

Epoch: 6| Step: 3
Training loss: 0.09082914888858795
Validation loss: 1.449749114692852

Epoch: 6| Step: 4
Training loss: 0.09586206078529358
Validation loss: 1.4974154195477885

Epoch: 6| Step: 5
Training loss: 0.18828079104423523
Validation loss: 1.519720555633627

Epoch: 6| Step: 6
Training loss: 0.13962611556053162
Validation loss: 1.489631816905032

Epoch: 6| Step: 7
Training loss: 0.1438097357749939
Validation loss: 1.4989853341092345

Epoch: 6| Step: 8
Training loss: 0.13443727791309357
Validation loss: 1.507311136491837

Epoch: 6| Step: 9
Training loss: 0.11137920618057251
Validation loss: 1.504398480538399

Epoch: 6| Step: 10
Training loss: 0.11036501824855804
Validation loss: 1.4892074805434032

Epoch: 6| Step: 11
Training loss: 0.09128859639167786
Validation loss: 1.4853975644675634

Epoch: 6| Step: 12
Training loss: 0.08805044740438461
Validation loss: 1.4780418385741532

Epoch: 6| Step: 13
Training loss: 0.1257418543100357
Validation loss: 1.483765056697271

Epoch: 439| Step: 0
Training loss: 0.08951960504055023
Validation loss: 1.4452742068998274

Epoch: 6| Step: 1
Training loss: 0.07474550604820251
Validation loss: 1.4448277386285926

Epoch: 6| Step: 2
Training loss: 0.11634296923875809
Validation loss: 1.4726656354883665

Epoch: 6| Step: 3
Training loss: 0.10536327213048935
Validation loss: 1.4839266487347182

Epoch: 6| Step: 4
Training loss: 0.11116841435432434
Validation loss: 1.4909148113701933

Epoch: 6| Step: 5
Training loss: 0.09765152633190155
Validation loss: 1.448932675905125

Epoch: 6| Step: 6
Training loss: 0.1275385171175003
Validation loss: 1.4816128476973502

Epoch: 6| Step: 7
Training loss: 0.06264759600162506
Validation loss: 1.470146253544797

Epoch: 6| Step: 8
Training loss: 0.07984249293804169
Validation loss: 1.4770281776305167

Epoch: 6| Step: 9
Training loss: 0.08344748616218567
Validation loss: 1.4672562601745769

Epoch: 6| Step: 10
Training loss: 0.1502251923084259
Validation loss: 1.4895172349868282

Epoch: 6| Step: 11
Training loss: 0.06745728105306625
Validation loss: 1.495393414651194

Epoch: 6| Step: 12
Training loss: 0.13772477209568024
Validation loss: 1.4678712737175725

Epoch: 6| Step: 13
Training loss: 0.08006636053323746
Validation loss: 1.4958919620001188

Epoch: 440| Step: 0
Training loss: 0.12576593458652496
Validation loss: 1.5035982362685665

Epoch: 6| Step: 1
Training loss: 0.0838305875658989
Validation loss: 1.498086493502381

Epoch: 6| Step: 2
Training loss: 0.16041067242622375
Validation loss: 1.485333417051582

Epoch: 6| Step: 3
Training loss: 0.1496259570121765
Validation loss: 1.5047299426089051

Epoch: 6| Step: 4
Training loss: 0.19038866460323334
Validation loss: 1.5124988543089999

Epoch: 6| Step: 5
Training loss: 0.1683022379875183
Validation loss: 1.4920544150055095

Epoch: 6| Step: 6
Training loss: 0.11668053269386292
Validation loss: 1.4772178152556061

Epoch: 6| Step: 7
Training loss: 0.08613280951976776
Validation loss: 1.4743087906991281

Epoch: 6| Step: 8
Training loss: 0.10989521443843842
Validation loss: 1.5062228415601997

Epoch: 6| Step: 9
Training loss: 0.14658105373382568
Validation loss: 1.466656138820033

Epoch: 6| Step: 10
Training loss: 0.09360042214393616
Validation loss: 1.4680655451231106

Epoch: 6| Step: 11
Training loss: 0.08190173655748367
Validation loss: 1.4382298870753216

Epoch: 6| Step: 12
Training loss: 0.06251965463161469
Validation loss: 1.4622321410845684

Epoch: 6| Step: 13
Training loss: 0.09186509996652603
Validation loss: 1.456928950484081

Epoch: 441| Step: 0
Training loss: 0.07453072816133499
Validation loss: 1.4245214846826368

Epoch: 6| Step: 1
Training loss: 0.1744256615638733
Validation loss: 1.4582454594232703

Epoch: 6| Step: 2
Training loss: 0.07606267929077148
Validation loss: 1.4515351300598474

Epoch: 6| Step: 3
Training loss: 0.1044849306344986
Validation loss: 1.4730574469412527

Epoch: 6| Step: 4
Training loss: 0.08535431325435638
Validation loss: 1.4794721680302774

Epoch: 6| Step: 5
Training loss: 0.09096047282218933
Validation loss: 1.4553674369729974

Epoch: 6| Step: 6
Training loss: 0.07250769436359406
Validation loss: 1.445270121738475

Epoch: 6| Step: 7
Training loss: 0.05441034585237503
Validation loss: 1.478194212400785

Epoch: 6| Step: 8
Training loss: 0.08112738281488419
Validation loss: 1.477738981605858

Epoch: 6| Step: 9
Training loss: 0.1266608089208603
Validation loss: 1.4928255863087152

Epoch: 6| Step: 10
Training loss: 0.0872003585100174
Validation loss: 1.4909427358258156

Epoch: 6| Step: 11
Training loss: 0.1724170744419098
Validation loss: 1.4963441100171817

Epoch: 6| Step: 12
Training loss: 0.1418805718421936
Validation loss: 1.4989313412738103

Epoch: 6| Step: 13
Training loss: 0.05183735117316246
Validation loss: 1.487385788271504

Epoch: 442| Step: 0
Training loss: 0.11196219176054001
Validation loss: 1.4853033276014431

Epoch: 6| Step: 1
Training loss: 0.10478401929140091
Validation loss: 1.4652706916614244

Epoch: 6| Step: 2
Training loss: 0.08043863624334335
Validation loss: 1.465489484930551

Epoch: 6| Step: 3
Training loss: 0.08742175996303558
Validation loss: 1.4909387910237877

Epoch: 6| Step: 4
Training loss: 0.0762743279337883
Validation loss: 1.5001340220051427

Epoch: 6| Step: 5
Training loss: 0.08366066217422485
Validation loss: 1.4752592732829433

Epoch: 6| Step: 6
Training loss: 0.14715638756752014
Validation loss: 1.4815157972356325

Epoch: 6| Step: 7
Training loss: 0.06797826290130615
Validation loss: 1.47350146437204

Epoch: 6| Step: 8
Training loss: 0.11157561093568802
Validation loss: 1.4889484656754362

Epoch: 6| Step: 9
Training loss: 0.14129319787025452
Validation loss: 1.4788200778345908

Epoch: 6| Step: 10
Training loss: 0.13889500498771667
Validation loss: 1.4763427319065217

Epoch: 6| Step: 11
Training loss: 0.07382301986217499
Validation loss: 1.4644869053235618

Epoch: 6| Step: 12
Training loss: 0.12080725282430649
Validation loss: 1.4714643083592898

Epoch: 6| Step: 13
Training loss: 0.07830796390771866
Validation loss: 1.4934119120720895

Epoch: 443| Step: 0
Training loss: 0.04889781028032303
Validation loss: 1.5014831898032979

Epoch: 6| Step: 1
Training loss: 0.11403080821037292
Validation loss: 1.4792239665985107

Epoch: 6| Step: 2
Training loss: 0.09980620443820953
Validation loss: 1.5120187190271193

Epoch: 6| Step: 3
Training loss: 0.0841120034456253
Validation loss: 1.480587532443385

Epoch: 6| Step: 4
Training loss: 0.18692824244499207
Validation loss: 1.5078632139390515

Epoch: 6| Step: 5
Training loss: 0.10499897599220276
Validation loss: 1.5066827215174192

Epoch: 6| Step: 6
Training loss: 0.1309066265821457
Validation loss: 1.506518575452989

Epoch: 6| Step: 7
Training loss: 0.08555100113153458
Validation loss: 1.4716422045102684

Epoch: 6| Step: 8
Training loss: 0.10368824005126953
Validation loss: 1.496321988362138

Epoch: 6| Step: 9
Training loss: 0.1067289188504219
Validation loss: 1.4430221761426618

Epoch: 6| Step: 10
Training loss: 0.07392503321170807
Validation loss: 1.4810746587732786

Epoch: 6| Step: 11
Training loss: 0.1251099854707718
Validation loss: 1.4883119893330399

Epoch: 6| Step: 12
Training loss: 0.12607136368751526
Validation loss: 1.464776869743101

Epoch: 6| Step: 13
Training loss: 0.09761134535074234
Validation loss: 1.4536097767532512

Epoch: 444| Step: 0
Training loss: 0.1498032808303833
Validation loss: 1.4929438137239026

Epoch: 6| Step: 1
Training loss: 0.11771678924560547
Validation loss: 1.4909711839050375

Epoch: 6| Step: 2
Training loss: 0.09669704735279083
Validation loss: 1.4693511711653842

Epoch: 6| Step: 3
Training loss: 0.07168442010879517
Validation loss: 1.475265843893892

Epoch: 6| Step: 4
Training loss: 0.06487804651260376
Validation loss: 1.5038652676408009

Epoch: 6| Step: 5
Training loss: 0.10204225778579712
Validation loss: 1.4932216649414392

Epoch: 6| Step: 6
Training loss: 0.0732453390955925
Validation loss: 1.4973605236699503

Epoch: 6| Step: 7
Training loss: 0.07442053407430649
Validation loss: 1.4986796609817012

Epoch: 6| Step: 8
Training loss: 0.1011117696762085
Validation loss: 1.499558005281674

Epoch: 6| Step: 9
Training loss: 0.08803141117095947
Validation loss: 1.5084808218863703

Epoch: 6| Step: 10
Training loss: 0.1435822695493698
Validation loss: 1.5037561091043616

Epoch: 6| Step: 11
Training loss: 0.10264357924461365
Validation loss: 1.5150177632608721

Epoch: 6| Step: 12
Training loss: 0.09452889859676361
Validation loss: 1.5106303461136357

Epoch: 6| Step: 13
Training loss: 0.057679638266563416
Validation loss: 1.4985120283660067

Epoch: 445| Step: 0
Training loss: 0.07630448043346405
Validation loss: 1.514209657587031

Epoch: 6| Step: 1
Training loss: 0.0900377482175827
Validation loss: 1.5274361423266831

Epoch: 6| Step: 2
Training loss: 0.11868306994438171
Validation loss: 1.528236573742282

Epoch: 6| Step: 3
Training loss: 0.15435636043548584
Validation loss: 1.5197655244540142

Epoch: 6| Step: 4
Training loss: 0.09656567871570587
Validation loss: 1.5237037020344888

Epoch: 6| Step: 5
Training loss: 0.07662834227085114
Validation loss: 1.4870450868401477

Epoch: 6| Step: 6
Training loss: 0.10952451825141907
Validation loss: 1.4958170678025933

Epoch: 6| Step: 7
Training loss: 0.1505827158689499
Validation loss: 1.4673831642314952

Epoch: 6| Step: 8
Training loss: 0.10531200468540192
Validation loss: 1.4297092447998703

Epoch: 6| Step: 9
Training loss: 0.11181347817182541
Validation loss: 1.4721395700208602

Epoch: 6| Step: 10
Training loss: 0.12308727204799652
Validation loss: 1.4639591170895485

Epoch: 6| Step: 11
Training loss: 0.06175939738750458
Validation loss: 1.4482877023758427

Epoch: 6| Step: 12
Training loss: 0.11662526428699493
Validation loss: 1.4690555526364235

Epoch: 6| Step: 13
Training loss: 0.11386789381504059
Validation loss: 1.4834673007329304

Epoch: 446| Step: 0
Training loss: 0.09532548487186432
Validation loss: 1.4672819645174089

Epoch: 6| Step: 1
Training loss: 0.10607694089412689
Validation loss: 1.4640814540206746

Epoch: 6| Step: 2
Training loss: 0.11416658014059067
Validation loss: 1.4717965241401427

Epoch: 6| Step: 3
Training loss: 0.06700630486011505
Validation loss: 1.4608077926020469

Epoch: 6| Step: 4
Training loss: 0.08686606585979462
Validation loss: 1.4696983957803378

Epoch: 6| Step: 5
Training loss: 0.12153186649084091
Validation loss: 1.475188955183952

Epoch: 6| Step: 6
Training loss: 0.09120316803455353
Validation loss: 1.4916256102182532

Epoch: 6| Step: 7
Training loss: 0.11814899742603302
Validation loss: 1.4861142340526785

Epoch: 6| Step: 8
Training loss: 0.06766559928655624
Validation loss: 1.4694378388825284

Epoch: 6| Step: 9
Training loss: 0.08284269273281097
Validation loss: 1.4823240528824508

Epoch: 6| Step: 10
Training loss: 0.09135011583566666
Validation loss: 1.4714924802062332

Epoch: 6| Step: 11
Training loss: 0.0784677267074585
Validation loss: 1.4773112548294889

Epoch: 6| Step: 12
Training loss: 0.11167585849761963
Validation loss: 1.476857526327974

Epoch: 6| Step: 13
Training loss: 0.040005918592214584
Validation loss: 1.4905614545268397

Epoch: 447| Step: 0
Training loss: 0.16906467080116272
Validation loss: 1.5024221904816166

Epoch: 6| Step: 1
Training loss: 0.08875548839569092
Validation loss: 1.479131385844241

Epoch: 6| Step: 2
Training loss: 0.12840749323368073
Validation loss: 1.5065341995608421

Epoch: 6| Step: 3
Training loss: 0.09981635212898254
Validation loss: 1.510331315378989

Epoch: 6| Step: 4
Training loss: 0.09708604216575623
Validation loss: 1.5006136945498887

Epoch: 6| Step: 5
Training loss: 0.06859176605939865
Validation loss: 1.460433192150567

Epoch: 6| Step: 6
Training loss: 0.08067187666893005
Validation loss: 1.4878297249476116

Epoch: 6| Step: 7
Training loss: 0.12297764420509338
Validation loss: 1.4804992265598749

Epoch: 6| Step: 8
Training loss: 0.09853626787662506
Validation loss: 1.4748064433374712

Epoch: 6| Step: 9
Training loss: 0.13020473718643188
Validation loss: 1.4585586311996623

Epoch: 6| Step: 10
Training loss: 0.11176346242427826
Validation loss: 1.499652663866679

Epoch: 6| Step: 11
Training loss: 0.06919039785861969
Validation loss: 1.4726510394004084

Epoch: 6| Step: 12
Training loss: 0.08684622496366501
Validation loss: 1.4767939647038777

Epoch: 6| Step: 13
Training loss: 0.060062553733587265
Validation loss: 1.480042508853379

Epoch: 448| Step: 0
Training loss: 0.1382695734500885
Validation loss: 1.4937047073918004

Epoch: 6| Step: 1
Training loss: 0.15824703872203827
Validation loss: 1.538462733709684

Epoch: 6| Step: 2
Training loss: 0.08725259453058243
Validation loss: 1.5139644953512377

Epoch: 6| Step: 3
Training loss: 0.09735017269849777
Validation loss: 1.4926829914892874

Epoch: 6| Step: 4
Training loss: 0.09182922542095184
Validation loss: 1.5294303483860467

Epoch: 6| Step: 5
Training loss: 0.13617831468582153
Validation loss: 1.5035667611706642

Epoch: 6| Step: 6
Training loss: 0.0692480057477951
Validation loss: 1.5107956355617893

Epoch: 6| Step: 7
Training loss: 0.06542333215475082
Validation loss: 1.4982610261568459

Epoch: 6| Step: 8
Training loss: 0.07782294601202011
Validation loss: 1.4861140443432717

Epoch: 6| Step: 9
Training loss: 0.08579222857952118
Validation loss: 1.492039954790505

Epoch: 6| Step: 10
Training loss: 0.16566798090934753
Validation loss: 1.480784623853622

Epoch: 6| Step: 11
Training loss: 0.07740587741136551
Validation loss: 1.4972710609436035

Epoch: 6| Step: 12
Training loss: 0.11569734662771225
Validation loss: 1.4879245937511485

Epoch: 6| Step: 13
Training loss: 0.06392993032932281
Validation loss: 1.4688214403326794

Epoch: 449| Step: 0
Training loss: 0.0987226665019989
Validation loss: 1.4744071973267423

Epoch: 6| Step: 1
Training loss: 0.0918428972363472
Validation loss: 1.4665372422946397

Epoch: 6| Step: 2
Training loss: 0.1577228605747223
Validation loss: 1.4643284172140143

Epoch: 6| Step: 3
Training loss: 0.11791808903217316
Validation loss: 1.4867721693490141

Epoch: 6| Step: 4
Training loss: 0.1667511761188507
Validation loss: 1.5017529123572892

Epoch: 6| Step: 5
Training loss: 0.11919910460710526
Validation loss: 1.4761287884045673

Epoch: 6| Step: 6
Training loss: 0.0799807757139206
Validation loss: 1.4715841393316946

Epoch: 6| Step: 7
Training loss: 0.08196042478084564
Validation loss: 1.4631463744307076

Epoch: 6| Step: 8
Training loss: 0.06218474730849266
Validation loss: 1.4362715444257181

Epoch: 6| Step: 9
Training loss: 0.08989818394184113
Validation loss: 1.4532188753927908

Epoch: 6| Step: 10
Training loss: 0.09254098683595657
Validation loss: 1.447121843214958

Epoch: 6| Step: 11
Training loss: 0.05908634513616562
Validation loss: 1.4574538507769186

Epoch: 6| Step: 12
Training loss: 0.06410045921802521
Validation loss: 1.4243185180489735

Epoch: 6| Step: 13
Training loss: 0.0691247284412384
Validation loss: 1.449066779305858

Epoch: 450| Step: 0
Training loss: 0.13935208320617676
Validation loss: 1.4454109373913016

Epoch: 6| Step: 1
Training loss: 0.1875312626361847
Validation loss: 1.44599905449857

Epoch: 6| Step: 2
Training loss: 0.10640069842338562
Validation loss: 1.4668603725330804

Epoch: 6| Step: 3
Training loss: 0.14512823522090912
Validation loss: 1.4746162276114188

Epoch: 6| Step: 4
Training loss: 0.07443159818649292
Validation loss: 1.4725549618403118

Epoch: 6| Step: 5
Training loss: 0.0911727324128151
Validation loss: 1.4348752255080848

Epoch: 6| Step: 6
Training loss: 0.0431760773062706
Validation loss: 1.4511503173458962

Epoch: 6| Step: 7
Training loss: 0.07478611916303635
Validation loss: 1.4615966299528718

Epoch: 6| Step: 8
Training loss: 0.09910408407449722
Validation loss: 1.4468696309674172

Epoch: 6| Step: 9
Training loss: 0.08219189196825027
Validation loss: 1.449496563403837

Epoch: 6| Step: 10
Training loss: 0.1108362227678299
Validation loss: 1.453824326556216

Epoch: 6| Step: 11
Training loss: 0.04712459444999695
Validation loss: 1.462899834878983

Epoch: 6| Step: 12
Training loss: 0.11004641652107239
Validation loss: 1.5066241269470544

Epoch: 6| Step: 13
Training loss: 0.08731581270694733
Validation loss: 1.4437752744202972

Epoch: 451| Step: 0
Training loss: 0.12067900598049164
Validation loss: 1.4841197613746888

Epoch: 6| Step: 1
Training loss: 0.13378581404685974
Validation loss: 1.4724084613143757

Epoch: 6| Step: 2
Training loss: 0.055145263671875
Validation loss: 1.452673799248152

Epoch: 6| Step: 3
Training loss: 0.08600200712680817
Validation loss: 1.4841441428789528

Epoch: 6| Step: 4
Training loss: 0.05182379484176636
Validation loss: 1.4645161308268064

Epoch: 6| Step: 5
Training loss: 0.10909469425678253
Validation loss: 1.4701017551524664

Epoch: 6| Step: 6
Training loss: 0.125645712018013
Validation loss: 1.4793937065268075

Epoch: 6| Step: 7
Training loss: 0.1505417674779892
Validation loss: 1.4600150841538624

Epoch: 6| Step: 8
Training loss: 0.07626283913850784
Validation loss: 1.463650954666958

Epoch: 6| Step: 9
Training loss: 0.0629149004817009
Validation loss: 1.4871796484916442

Epoch: 6| Step: 10
Training loss: 0.10894843190908432
Validation loss: 1.4841099298128517

Epoch: 6| Step: 11
Training loss: 0.08407037705183029
Validation loss: 1.4968219226406467

Epoch: 6| Step: 12
Training loss: 0.05042180046439171
Validation loss: 1.4921160872264574

Epoch: 6| Step: 13
Training loss: 0.08768367767333984
Validation loss: 1.4826027385650142

Epoch: 452| Step: 0
Training loss: 0.16607972979545593
Validation loss: 1.4960085576580417

Epoch: 6| Step: 1
Training loss: 0.050091277807950974
Validation loss: 1.4942707137394977

Epoch: 6| Step: 2
Training loss: 0.13735331594944
Validation loss: 1.4957369168599446

Epoch: 6| Step: 3
Training loss: 0.12027623504400253
Validation loss: 1.523799257893716

Epoch: 6| Step: 4
Training loss: 0.0973597913980484
Validation loss: 1.5009620484485422

Epoch: 6| Step: 5
Training loss: 0.058390043675899506
Validation loss: 1.4925524329626432

Epoch: 6| Step: 6
Training loss: 0.10686782002449036
Validation loss: 1.4892975694389754

Epoch: 6| Step: 7
Training loss: 0.09375067055225372
Validation loss: 1.485743139379768

Epoch: 6| Step: 8
Training loss: 0.13276557624340057
Validation loss: 1.529807734233077

Epoch: 6| Step: 9
Training loss: 0.11006508022546768
Validation loss: 1.491059491711278

Epoch: 6| Step: 10
Training loss: 0.10883286595344543
Validation loss: 1.5017679314459524

Epoch: 6| Step: 11
Training loss: 0.09023848176002502
Validation loss: 1.4633774642021424

Epoch: 6| Step: 12
Training loss: 0.10675803571939468
Validation loss: 1.4783277005277655

Epoch: 6| Step: 13
Training loss: 0.08072871714830399
Validation loss: 1.4805927507338985

Epoch: 453| Step: 0
Training loss: 0.1053866446018219
Validation loss: 1.4654580405963364

Epoch: 6| Step: 1
Training loss: 0.06859646737575531
Validation loss: 1.4928101942103396

Epoch: 6| Step: 2
Training loss: 0.05211808532476425
Validation loss: 1.498133655517332

Epoch: 6| Step: 3
Training loss: 0.16097111999988556
Validation loss: 1.5073056996509593

Epoch: 6| Step: 4
Training loss: 0.09152135252952576
Validation loss: 1.4908880213255524

Epoch: 6| Step: 5
Training loss: 0.08608987927436829
Validation loss: 1.504239510464412

Epoch: 6| Step: 6
Training loss: 0.16290153563022614
Validation loss: 1.5263858072219356

Epoch: 6| Step: 7
Training loss: 0.08625796437263489
Validation loss: 1.4856608580517512

Epoch: 6| Step: 8
Training loss: 0.09060174226760864
Validation loss: 1.4905950279646023

Epoch: 6| Step: 9
Training loss: 0.1645703911781311
Validation loss: 1.491916024556724

Epoch: 6| Step: 10
Training loss: 0.13692879676818848
Validation loss: 1.5074988116500199

Epoch: 6| Step: 11
Training loss: 0.18362471461296082
Validation loss: 1.4883935105416082

Epoch: 6| Step: 12
Training loss: 0.11682817339897156
Validation loss: 1.4996452882725706

Epoch: 6| Step: 13
Training loss: 0.08804314583539963
Validation loss: 1.4659930685515046

Epoch: 454| Step: 0
Training loss: 0.1652870774269104
Validation loss: 1.4581944686110302

Epoch: 6| Step: 1
Training loss: 0.1435467004776001
Validation loss: 1.487419428363923

Epoch: 6| Step: 2
Training loss: 0.15283679962158203
Validation loss: 1.454224419850175

Epoch: 6| Step: 3
Training loss: 0.05897951126098633
Validation loss: 1.4870090407709922

Epoch: 6| Step: 4
Training loss: 0.16707885265350342
Validation loss: 1.4825301157530917

Epoch: 6| Step: 5
Training loss: 0.10751843452453613
Validation loss: 1.5099969807491507

Epoch: 6| Step: 6
Training loss: 0.14024263620376587
Validation loss: 1.5026157158677296

Epoch: 6| Step: 7
Training loss: 0.09475111961364746
Validation loss: 1.5608640422103226

Epoch: 6| Step: 8
Training loss: 0.08861970901489258
Validation loss: 1.5214664897611063

Epoch: 6| Step: 9
Training loss: 0.09442409127950668
Validation loss: 1.4995452242512857

Epoch: 6| Step: 10
Training loss: 0.11795349419116974
Validation loss: 1.502769770160798

Epoch: 6| Step: 11
Training loss: 0.07167716324329376
Validation loss: 1.5273440537914154

Epoch: 6| Step: 12
Training loss: 0.10526750981807709
Validation loss: 1.508412762354779

Epoch: 6| Step: 13
Training loss: 0.09795965999364853
Validation loss: 1.5193356339649489

Epoch: 455| Step: 0
Training loss: 0.10315820574760437
Validation loss: 1.4970730773864254

Epoch: 6| Step: 1
Training loss: 0.08284226059913635
Validation loss: 1.4697565981136855

Epoch: 6| Step: 2
Training loss: 0.10002356767654419
Validation loss: 1.4670451405227825

Epoch: 6| Step: 3
Training loss: 0.1008453220129013
Validation loss: 1.4897922392814391

Epoch: 6| Step: 4
Training loss: 0.05599969998002052
Validation loss: 1.4714594938421761

Epoch: 6| Step: 5
Training loss: 0.07155145704746246
Validation loss: 1.4829347043909051

Epoch: 6| Step: 6
Training loss: 0.10427363961935043
Validation loss: 1.4642945412666566

Epoch: 6| Step: 7
Training loss: 0.08543717861175537
Validation loss: 1.4759671098442488

Epoch: 6| Step: 8
Training loss: 0.12210442870855331
Validation loss: 1.4777704426037368

Epoch: 6| Step: 9
Training loss: 0.09654372185468674
Validation loss: 1.5032358143919258

Epoch: 6| Step: 10
Training loss: 0.09935887157917023
Validation loss: 1.4590641875420847

Epoch: 6| Step: 11
Training loss: 0.15501296520233154
Validation loss: 1.4768699599850563

Epoch: 6| Step: 12
Training loss: 0.10771648585796356
Validation loss: 1.4673892157052153

Epoch: 6| Step: 13
Training loss: 0.08533795177936554
Validation loss: 1.4674407025819183

Epoch: 456| Step: 0
Training loss: 0.11924868077039719
Validation loss: 1.459649420553638

Epoch: 6| Step: 1
Training loss: 0.07792213559150696
Validation loss: 1.4781179831873985

Epoch: 6| Step: 2
Training loss: 0.07669386267662048
Validation loss: 1.5011290222085931

Epoch: 6| Step: 3
Training loss: 0.07160543650388718
Validation loss: 1.4544158263873028

Epoch: 6| Step: 4
Training loss: 0.08312825858592987
Validation loss: 1.4615813122000745

Epoch: 6| Step: 5
Training loss: 0.08632759749889374
Validation loss: 1.444919079862615

Epoch: 6| Step: 6
Training loss: 0.13591113686561584
Validation loss: 1.4672410372764833

Epoch: 6| Step: 7
Training loss: 0.07168148458003998
Validation loss: 1.4760902722676594

Epoch: 6| Step: 8
Training loss: 0.10317656397819519
Validation loss: 1.4882694155939165

Epoch: 6| Step: 9
Training loss: 0.0921856090426445
Validation loss: 1.4721010128657024

Epoch: 6| Step: 10
Training loss: 0.09629766643047333
Validation loss: 1.472280244032542

Epoch: 6| Step: 11
Training loss: 0.11746229976415634
Validation loss: 1.462415925918087

Epoch: 6| Step: 12
Training loss: 0.11052650213241577
Validation loss: 1.4865883646472808

Epoch: 6| Step: 13
Training loss: 0.10510087013244629
Validation loss: 1.4811660205164263

Epoch: 457| Step: 0
Training loss: 0.12071458995342255
Validation loss: 1.4841032617835588

Epoch: 6| Step: 1
Training loss: 0.15025125443935394
Validation loss: 1.4802838474191644

Epoch: 6| Step: 2
Training loss: 0.10282842814922333
Validation loss: 1.476525302856199

Epoch: 6| Step: 3
Training loss: 0.0797417163848877
Validation loss: 1.4610486107487832

Epoch: 6| Step: 4
Training loss: 0.09973455965518951
Validation loss: 1.4807096783832838

Epoch: 6| Step: 5
Training loss: 0.10242761671543121
Validation loss: 1.476061354401291

Epoch: 6| Step: 6
Training loss: 0.07186845690011978
Validation loss: 1.5075291049095891

Epoch: 6| Step: 7
Training loss: 0.11458528786897659
Validation loss: 1.4610189724993963

Epoch: 6| Step: 8
Training loss: 0.09147495031356812
Validation loss: 1.5027476318420903

Epoch: 6| Step: 9
Training loss: 0.08310459554195404
Validation loss: 1.4850527791566746

Epoch: 6| Step: 10
Training loss: 0.08462435007095337
Validation loss: 1.4615250966882194

Epoch: 6| Step: 11
Training loss: 0.08178525418043137
Validation loss: 1.4586432685134232

Epoch: 6| Step: 12
Training loss: 0.05522014945745468
Validation loss: 1.477275263878607

Epoch: 6| Step: 13
Training loss: 0.0915236547589302
Validation loss: 1.4807005313134962

Epoch: 458| Step: 0
Training loss: 0.0829772800207138
Validation loss: 1.4584123332013366

Epoch: 6| Step: 1
Training loss: 0.11483050137758255
Validation loss: 1.4915740823233

Epoch: 6| Step: 2
Training loss: 0.0892389565706253
Validation loss: 1.4539131874679236

Epoch: 6| Step: 3
Training loss: 0.06567883491516113
Validation loss: 1.5006946876484861

Epoch: 6| Step: 4
Training loss: 0.17730799317359924
Validation loss: 1.4890079293199765

Epoch: 6| Step: 5
Training loss: 0.07150787115097046
Validation loss: 1.4828765981940812

Epoch: 6| Step: 6
Training loss: 0.05875013396143913
Validation loss: 1.5067394087391515

Epoch: 6| Step: 7
Training loss: 0.05943353846669197
Validation loss: 1.4716104820210447

Epoch: 6| Step: 8
Training loss: 0.11609240621328354
Validation loss: 1.4843049869742444

Epoch: 6| Step: 9
Training loss: 0.17955490946769714
Validation loss: 1.5027560072560464

Epoch: 6| Step: 10
Training loss: 0.08683834224939346
Validation loss: 1.493094762166341

Epoch: 6| Step: 11
Training loss: 0.08301787078380585
Validation loss: 1.5074770873592747

Epoch: 6| Step: 12
Training loss: 0.08223427087068558
Validation loss: 1.4861973947094334

Epoch: 6| Step: 13
Training loss: 0.14101912081241608
Validation loss: 1.5038396568708523

Epoch: 459| Step: 0
Training loss: 0.09107398986816406
Validation loss: 1.4964089323115606

Epoch: 6| Step: 1
Training loss: 0.08394944667816162
Validation loss: 1.4692057486503356

Epoch: 6| Step: 2
Training loss: 0.06281588971614838
Validation loss: 1.4823849457566456

Epoch: 6| Step: 3
Training loss: 0.08188318461179733
Validation loss: 1.459862703918129

Epoch: 6| Step: 4
Training loss: 0.1897355318069458
Validation loss: 1.4774330956961519

Epoch: 6| Step: 5
Training loss: 0.08920088410377502
Validation loss: 1.4789316474750478

Epoch: 6| Step: 6
Training loss: 0.09601901471614838
Validation loss: 1.4346854814919092

Epoch: 6| Step: 7
Training loss: 0.08898098766803741
Validation loss: 1.4771391614790885

Epoch: 6| Step: 8
Training loss: 0.11002697050571442
Validation loss: 1.445832767794209

Epoch: 6| Step: 9
Training loss: 0.1455589234828949
Validation loss: 1.4625545599127328

Epoch: 6| Step: 10
Training loss: 0.11789585649967194
Validation loss: 1.4343000586314867

Epoch: 6| Step: 11
Training loss: 0.13144126534461975
Validation loss: 1.477395829334054

Epoch: 6| Step: 12
Training loss: 0.055535390973091125
Validation loss: 1.4806731811133764

Epoch: 6| Step: 13
Training loss: 0.08010933548212051
Validation loss: 1.4204119046529133

Epoch: 460| Step: 0
Training loss: 0.09828032553195953
Validation loss: 1.4332541740068825

Epoch: 6| Step: 1
Training loss: 0.05324964225292206
Validation loss: 1.4448726523307063

Epoch: 6| Step: 2
Training loss: 0.09233886748552322
Validation loss: 1.449089987303621

Epoch: 6| Step: 3
Training loss: 0.17953059077262878
Validation loss: 1.4787771829994776

Epoch: 6| Step: 4
Training loss: 0.0858193039894104
Validation loss: 1.4605130098199333

Epoch: 6| Step: 5
Training loss: 0.11348985135555267
Validation loss: 1.4407179060802664

Epoch: 6| Step: 6
Training loss: 0.11212275177240372
Validation loss: 1.456704140991293

Epoch: 6| Step: 7
Training loss: 0.0900154560804367
Validation loss: 1.4549312181370233

Epoch: 6| Step: 8
Training loss: 0.13566453754901886
Validation loss: 1.4425462407450522

Epoch: 6| Step: 9
Training loss: 0.09431897103786469
Validation loss: 1.4465065028077813

Epoch: 6| Step: 10
Training loss: 0.10130955278873444
Validation loss: 1.4709401361403927

Epoch: 6| Step: 11
Training loss: 0.0959775373339653
Validation loss: 1.4163730234228156

Epoch: 6| Step: 12
Training loss: 0.07565847039222717
Validation loss: 1.4240880025330411

Epoch: 6| Step: 13
Training loss: 0.15242654085159302
Validation loss: 1.4372734831225487

Epoch: 461| Step: 0
Training loss: 0.1145603284239769
Validation loss: 1.4235972960789998

Epoch: 6| Step: 1
Training loss: 0.1546328067779541
Validation loss: 1.451039816743584

Epoch: 6| Step: 2
Training loss: 0.135825052857399
Validation loss: 1.4680090835017543

Epoch: 6| Step: 3
Training loss: 0.07532573491334915
Validation loss: 1.4624877963014828

Epoch: 6| Step: 4
Training loss: 0.07424012571573257
Validation loss: 1.4838863765039751

Epoch: 6| Step: 5
Training loss: 0.06622591614723206
Validation loss: 1.4986430329661216

Epoch: 6| Step: 6
Training loss: 0.16065669059753418
Validation loss: 1.5120349904542327

Epoch: 6| Step: 7
Training loss: 0.07743796706199646
Validation loss: 1.5013868629291494

Epoch: 6| Step: 8
Training loss: 0.11597763001918793
Validation loss: 1.5041060627147715

Epoch: 6| Step: 9
Training loss: 0.13834059238433838
Validation loss: 1.502248271819084

Epoch: 6| Step: 10
Training loss: 0.1165926456451416
Validation loss: 1.515260293919553

Epoch: 6| Step: 11
Training loss: 0.09633232653141022
Validation loss: 1.4782084226608276

Epoch: 6| Step: 12
Training loss: 0.07407064735889435
Validation loss: 1.4987390131078742

Epoch: 6| Step: 13
Training loss: 0.07253056019544601
Validation loss: 1.457548677280385

Epoch: 462| Step: 0
Training loss: 0.0908384621143341
Validation loss: 1.4538076205920147

Epoch: 6| Step: 1
Training loss: 0.08154751360416412
Validation loss: 1.487491999903033

Epoch: 6| Step: 2
Training loss: 0.09833092242479324
Validation loss: 1.4639548768279373

Epoch: 6| Step: 3
Training loss: 0.1139092743396759
Validation loss: 1.451391564902439

Epoch: 6| Step: 4
Training loss: 0.09439049661159515
Validation loss: 1.462499414720843

Epoch: 6| Step: 5
Training loss: 0.142849862575531
Validation loss: 1.4607531793655888

Epoch: 6| Step: 6
Training loss: 0.08501341193914413
Validation loss: 1.4330979483101958

Epoch: 6| Step: 7
Training loss: 0.1378384232521057
Validation loss: 1.448496821106121

Epoch: 6| Step: 8
Training loss: 0.07275420427322388
Validation loss: 1.4425757264578214

Epoch: 6| Step: 9
Training loss: 0.08042329549789429
Validation loss: 1.4241600369894376

Epoch: 6| Step: 10
Training loss: 0.11614073812961578
Validation loss: 1.4281891610032769

Epoch: 6| Step: 11
Training loss: 0.11911240220069885
Validation loss: 1.4302639986879082

Epoch: 6| Step: 12
Training loss: 0.10525438189506531
Validation loss: 1.4217945734659831

Epoch: 6| Step: 13
Training loss: 0.06483953446149826
Validation loss: 1.4506304430705246

Epoch: 463| Step: 0
Training loss: 0.0820203572511673
Validation loss: 1.47438552559063

Epoch: 6| Step: 1
Training loss: 0.11048978567123413
Validation loss: 1.4806736746141989

Epoch: 6| Step: 2
Training loss: 0.12295515835285187
Validation loss: 1.4918511029212707

Epoch: 6| Step: 3
Training loss: 0.07361821085214615
Validation loss: 1.513078970293845

Epoch: 6| Step: 4
Training loss: 0.14819224178791046
Validation loss: 1.495115158378437

Epoch: 6| Step: 5
Training loss: 0.09461788833141327
Validation loss: 1.481376406966999

Epoch: 6| Step: 6
Training loss: 0.07827900350093842
Validation loss: 1.5117158043769099

Epoch: 6| Step: 7
Training loss: 0.10454273223876953
Validation loss: 1.4833475902516355

Epoch: 6| Step: 8
Training loss: 0.09393436461687088
Validation loss: 1.4909651522995324

Epoch: 6| Step: 9
Training loss: 0.08066533505916595
Validation loss: 1.4831159627565773

Epoch: 6| Step: 10
Training loss: 0.09074828773736954
Validation loss: 1.5025300697613788

Epoch: 6| Step: 11
Training loss: 0.1297808140516281
Validation loss: 1.47861566979398

Epoch: 6| Step: 12
Training loss: 0.046443402767181396
Validation loss: 1.47974181431596

Epoch: 6| Step: 13
Training loss: 0.12399750202894211
Validation loss: 1.5054008999178488

Epoch: 464| Step: 0
Training loss: 0.12702259421348572
Validation loss: 1.503462367160346

Epoch: 6| Step: 1
Training loss: 0.08204232156276703
Validation loss: 1.5225037772168395

Epoch: 6| Step: 2
Training loss: 0.09585601091384888
Validation loss: 1.4953289352437502

Epoch: 6| Step: 3
Training loss: 0.062434121966362
Validation loss: 1.5231084695426367

Epoch: 6| Step: 4
Training loss: 0.05769071727991104
Validation loss: 1.5100573224406089

Epoch: 6| Step: 5
Training loss: 0.14632228016853333
Validation loss: 1.4974158515212357

Epoch: 6| Step: 6
Training loss: 0.06113775074481964
Validation loss: 1.492737740598699

Epoch: 6| Step: 7
Training loss: 0.0892816036939621
Validation loss: 1.4948241710662842

Epoch: 6| Step: 8
Training loss: 0.13224928081035614
Validation loss: 1.490084949360099

Epoch: 6| Step: 9
Training loss: 0.08467523753643036
Validation loss: 1.4939477930786789

Epoch: 6| Step: 10
Training loss: 0.11549782752990723
Validation loss: 1.5146241803323068

Epoch: 6| Step: 11
Training loss: 0.068308025598526
Validation loss: 1.4800859664076118

Epoch: 6| Step: 12
Training loss: 0.09278554469347
Validation loss: 1.4912703908899778

Epoch: 6| Step: 13
Training loss: 0.13400548696517944
Validation loss: 1.4944931153328187

Epoch: 465| Step: 0
Training loss: 0.09404079616069794
Validation loss: 1.4890735418565813

Epoch: 6| Step: 1
Training loss: 0.0833616703748703
Validation loss: 1.4687895480022635

Epoch: 6| Step: 2
Training loss: 0.11598680913448334
Validation loss: 1.4876623820233088

Epoch: 6| Step: 3
Training loss: 0.08976973593235016
Validation loss: 1.4792763135766471

Epoch: 6| Step: 4
Training loss: 0.1008346900343895
Validation loss: 1.4966391094269291

Epoch: 6| Step: 5
Training loss: 0.12685833871364594
Validation loss: 1.491627215057291

Epoch: 6| Step: 6
Training loss: 0.07899057120084763
Validation loss: 1.4762619374900736

Epoch: 6| Step: 7
Training loss: 0.09034290909767151
Validation loss: 1.4597107005375687

Epoch: 6| Step: 8
Training loss: 0.0796816498041153
Validation loss: 1.4961391572029359

Epoch: 6| Step: 9
Training loss: 0.13931944966316223
Validation loss: 1.4881041806231263

Epoch: 6| Step: 10
Training loss: 0.06547331064939499
Validation loss: 1.4939189021305372

Epoch: 6| Step: 11
Training loss: 0.08719400316476822
Validation loss: 1.491950491423248

Epoch: 6| Step: 12
Training loss: 0.0469009131193161
Validation loss: 1.5038649420584402

Epoch: 6| Step: 13
Training loss: 0.07164696604013443
Validation loss: 1.5146081396328506

Epoch: 466| Step: 0
Training loss: 0.09741046279668808
Validation loss: 1.510815268562686

Epoch: 6| Step: 1
Training loss: 0.14466804265975952
Validation loss: 1.507792071629596

Epoch: 6| Step: 2
Training loss: 0.06837262213230133
Validation loss: 1.5230671128919047

Epoch: 6| Step: 3
Training loss: 0.06789018213748932
Validation loss: 1.478080331638295

Epoch: 6| Step: 4
Training loss: 0.0994655191898346
Validation loss: 1.5027436466627224

Epoch: 6| Step: 5
Training loss: 0.07869315147399902
Validation loss: 1.4877082429906374

Epoch: 6| Step: 6
Training loss: 0.052126094698905945
Validation loss: 1.502853633255087

Epoch: 6| Step: 7
Training loss: 0.07198070734739304
Validation loss: 1.4752282109311832

Epoch: 6| Step: 8
Training loss: 0.10207231342792511
Validation loss: 1.506274579673685

Epoch: 6| Step: 9
Training loss: 0.10651227831840515
Validation loss: 1.502948344394725

Epoch: 6| Step: 10
Training loss: 0.0692000463604927
Validation loss: 1.4962128387984408

Epoch: 6| Step: 11
Training loss: 0.1264287382364273
Validation loss: 1.4604169867372

Epoch: 6| Step: 12
Training loss: 0.10519122332334518
Validation loss: 1.4927470132868776

Epoch: 6| Step: 13
Training loss: 0.15921087563037872
Validation loss: 1.4787850251761816

Epoch: 467| Step: 0
Training loss: 0.06072722375392914
Validation loss: 1.4824036654605661

Epoch: 6| Step: 1
Training loss: 0.1423235982656479
Validation loss: 1.4712677027589531

Epoch: 6| Step: 2
Training loss: 0.1056276261806488
Validation loss: 1.4755108766658331

Epoch: 6| Step: 3
Training loss: 0.09068503975868225
Validation loss: 1.4691217202012257

Epoch: 6| Step: 4
Training loss: 0.09968139976263046
Validation loss: 1.5106592652618245

Epoch: 6| Step: 5
Training loss: 0.10528923571109772
Validation loss: 1.4906407479316957

Epoch: 6| Step: 6
Training loss: 0.11159296333789825
Validation loss: 1.4990042749271597

Epoch: 6| Step: 7
Training loss: 0.08440055698156357
Validation loss: 1.5012200801603255

Epoch: 6| Step: 8
Training loss: 0.08694273233413696
Validation loss: 1.508459347550587

Epoch: 6| Step: 9
Training loss: 0.06253818422555923
Validation loss: 1.4801848652542278

Epoch: 6| Step: 10
Training loss: 0.10686488449573517
Validation loss: 1.512484594057965

Epoch: 6| Step: 11
Training loss: 0.08210764825344086
Validation loss: 1.5013907083901026

Epoch: 6| Step: 12
Training loss: 0.07424440234899521
Validation loss: 1.5290627197552753

Epoch: 6| Step: 13
Training loss: 0.11380055546760559
Validation loss: 1.5058531889351465

Epoch: 468| Step: 0
Training loss: 0.09569129347801208
Validation loss: 1.5231343559039536

Epoch: 6| Step: 1
Training loss: 0.0998622477054596
Validation loss: 1.5136329614987938

Epoch: 6| Step: 2
Training loss: 0.09765562415122986
Validation loss: 1.5226083365819787

Epoch: 6| Step: 3
Training loss: 0.09189050644636154
Validation loss: 1.5412818706163796

Epoch: 6| Step: 4
Training loss: 0.0878661647439003
Validation loss: 1.5116799659626459

Epoch: 6| Step: 5
Training loss: 0.07450123131275177
Validation loss: 1.5155573403963478

Epoch: 6| Step: 6
Training loss: 0.13114219903945923
Validation loss: 1.5192447503407795

Epoch: 6| Step: 7
Training loss: 0.05221828818321228
Validation loss: 1.4939741306407477

Epoch: 6| Step: 8
Training loss: 0.10433682799339294
Validation loss: 1.5305254715745167

Epoch: 6| Step: 9
Training loss: 0.04931165277957916
Validation loss: 1.544340996332066

Epoch: 6| Step: 10
Training loss: 0.10046318173408508
Validation loss: 1.5207364892446866

Epoch: 6| Step: 11
Training loss: 0.11006935685873032
Validation loss: 1.5455296757400676

Epoch: 6| Step: 12
Training loss: 0.08787573873996735
Validation loss: 1.5076915282075123

Epoch: 6| Step: 13
Training loss: 0.1130056083202362
Validation loss: 1.5211677781997188

Epoch: 469| Step: 0
Training loss: 0.1277206689119339
Validation loss: 1.5179654872545632

Epoch: 6| Step: 1
Training loss: 0.07841037958860397
Validation loss: 1.509582846395431

Epoch: 6| Step: 2
Training loss: 0.11486199498176575
Validation loss: 1.4903440603645899

Epoch: 6| Step: 3
Training loss: 0.09618616849184036
Validation loss: 1.524216692934754

Epoch: 6| Step: 4
Training loss: 0.12808936834335327
Validation loss: 1.5123943090438843

Epoch: 6| Step: 5
Training loss: 0.1273653209209442
Validation loss: 1.5050443141691145

Epoch: 6| Step: 6
Training loss: 0.07274812459945679
Validation loss: 1.4999125503724622

Epoch: 6| Step: 7
Training loss: 0.12057479470968246
Validation loss: 1.532056579666753

Epoch: 6| Step: 8
Training loss: 0.11049732565879822
Validation loss: 1.5278402720728228

Epoch: 6| Step: 9
Training loss: 0.12312949448823929
Validation loss: 1.5151059768533195

Epoch: 6| Step: 10
Training loss: 0.10993972420692444
Validation loss: 1.5340154145353584

Epoch: 6| Step: 11
Training loss: 0.14175792038440704
Validation loss: 1.5026436954416253

Epoch: 6| Step: 12
Training loss: 0.11249645054340363
Validation loss: 1.4974344481704056

Epoch: 6| Step: 13
Training loss: 0.07955225557088852
Validation loss: 1.4967968015260593

Epoch: 470| Step: 0
Training loss: 0.15882933139801025
Validation loss: 1.4785688820705618

Epoch: 6| Step: 1
Training loss: 0.11111759394407272
Validation loss: 1.4911590904317877

Epoch: 6| Step: 2
Training loss: 0.08661045879125595
Validation loss: 1.4896238452644759

Epoch: 6| Step: 3
Training loss: 0.10000050812959671
Validation loss: 1.5109291153569375

Epoch: 6| Step: 4
Training loss: 0.08889935910701752
Validation loss: 1.4925232882140784

Epoch: 6| Step: 5
Training loss: 0.08669672161340714
Validation loss: 1.486157186569706

Epoch: 6| Step: 6
Training loss: 0.12352438271045685
Validation loss: 1.4601176131156184

Epoch: 6| Step: 7
Training loss: 0.07869599759578705
Validation loss: 1.4976974546268422

Epoch: 6| Step: 8
Training loss: 0.0874929204583168
Validation loss: 1.5035619094807615

Epoch: 6| Step: 9
Training loss: 0.16260969638824463
Validation loss: 1.4861235849318966

Epoch: 6| Step: 10
Training loss: 0.11086052656173706
Validation loss: 1.4954305457812485

Epoch: 6| Step: 11
Training loss: 0.17634102702140808
Validation loss: 1.493221531632126

Epoch: 6| Step: 12
Training loss: 0.107016921043396
Validation loss: 1.5379356197131577

Epoch: 6| Step: 13
Training loss: 0.07452082633972168
Validation loss: 1.492987617369621

Epoch: 471| Step: 0
Training loss: 0.08518540114164352
Validation loss: 1.4718159757634646

Epoch: 6| Step: 1
Training loss: 0.10773269832134247
Validation loss: 1.498224881387526

Epoch: 6| Step: 2
Training loss: 0.12379954010248184
Validation loss: 1.5197680816855481

Epoch: 6| Step: 3
Training loss: 0.14366628229618073
Validation loss: 1.555998384311635

Epoch: 6| Step: 4
Training loss: 0.11903518438339233
Validation loss: 1.518416944370475

Epoch: 6| Step: 5
Training loss: 0.14156466722488403
Validation loss: 1.491925181881074

Epoch: 6| Step: 6
Training loss: 0.11557571589946747
Validation loss: 1.491778940282842

Epoch: 6| Step: 7
Training loss: 0.09614603966474533
Validation loss: 1.469999321045414

Epoch: 6| Step: 8
Training loss: 0.10264305025339127
Validation loss: 1.4423357902034637

Epoch: 6| Step: 9
Training loss: 0.10706827789545059
Validation loss: 1.44862808463394

Epoch: 6| Step: 10
Training loss: 0.20892371237277985
Validation loss: 1.4517354888300742

Epoch: 6| Step: 11
Training loss: 0.24465446174144745
Validation loss: 1.4417553101816485

Epoch: 6| Step: 12
Training loss: 0.1148577407002449
Validation loss: 1.4417243939574047

Epoch: 6| Step: 13
Training loss: 0.09740076959133148
Validation loss: 1.4348172372387302

Epoch: 472| Step: 0
Training loss: 0.11506402492523193
Validation loss: 1.467900247984035

Epoch: 6| Step: 1
Training loss: 0.11895710229873657
Validation loss: 1.5038033300830471

Epoch: 6| Step: 2
Training loss: 0.09848377108573914
Validation loss: 1.5469255165387226

Epoch: 6| Step: 3
Training loss: 0.09519678354263306
Validation loss: 1.53292618772035

Epoch: 6| Step: 4
Training loss: 0.13281649351119995
Validation loss: 1.5560313194028792

Epoch: 6| Step: 5
Training loss: 0.18137258291244507
Validation loss: 1.5363258930944628

Epoch: 6| Step: 6
Training loss: 0.10849110037088394
Validation loss: 1.5446742260327904

Epoch: 6| Step: 7
Training loss: 0.13297756016254425
Validation loss: 1.5376549215726956

Epoch: 6| Step: 8
Training loss: 0.07926739007234573
Validation loss: 1.509356515381926

Epoch: 6| Step: 9
Training loss: 0.08501556515693665
Validation loss: 1.5155157837816464

Epoch: 6| Step: 10
Training loss: 0.11640167236328125
Validation loss: 1.5392179296862694

Epoch: 6| Step: 11
Training loss: 0.15082743763923645
Validation loss: 1.5110309969994329

Epoch: 6| Step: 12
Training loss: 0.16173036396503448
Validation loss: 1.5018985963636828

Epoch: 6| Step: 13
Training loss: 0.12180987000465393
Validation loss: 1.5087591678865495

Epoch: 473| Step: 0
Training loss: 0.07417268306016922
Validation loss: 1.495805045609833

Epoch: 6| Step: 1
Training loss: 0.16669395565986633
Validation loss: 1.4819137588624032

Epoch: 6| Step: 2
Training loss: 0.13100624084472656
Validation loss: 1.4662768469061902

Epoch: 6| Step: 3
Training loss: 0.11888924986124039
Validation loss: 1.4521960237974763

Epoch: 6| Step: 4
Training loss: 0.10420428961515427
Validation loss: 1.464583263602308

Epoch: 6| Step: 5
Training loss: 0.08593908697366714
Validation loss: 1.4369764840731056

Epoch: 6| Step: 6
Training loss: 0.21810272336006165
Validation loss: 1.461997111638387

Epoch: 6| Step: 7
Training loss: 0.1903611272573471
Validation loss: 1.4693526606405936

Epoch: 6| Step: 8
Training loss: 0.16405725479125977
Validation loss: 1.4706029738149335

Epoch: 6| Step: 9
Training loss: 0.12006799131631851
Validation loss: 1.4781186747294601

Epoch: 6| Step: 10
Training loss: 0.09187915921211243
Validation loss: 1.534538467725118

Epoch: 6| Step: 11
Training loss: 0.1412247121334076
Validation loss: 1.5150046092207714

Epoch: 6| Step: 12
Training loss: 0.1489896923303604
Validation loss: 1.5531040558251001

Epoch: 6| Step: 13
Training loss: 0.07813338935375214
Validation loss: 1.5543625393221456

Epoch: 474| Step: 0
Training loss: 0.15865615010261536
Validation loss: 1.5324285902002805

Epoch: 6| Step: 1
Training loss: 0.15186607837677002
Validation loss: 1.5288395215106267

Epoch: 6| Step: 2
Training loss: 0.15511852502822876
Validation loss: 1.5168186861981627

Epoch: 6| Step: 3
Training loss: 0.04480714723467827
Validation loss: 1.5045615575646842

Epoch: 6| Step: 4
Training loss: 0.11581656336784363
Validation loss: 1.495258092880249

Epoch: 6| Step: 5
Training loss: 0.0980895608663559
Validation loss: 1.4679983982475855

Epoch: 6| Step: 6
Training loss: 0.07999348640441895
Validation loss: 1.492497173688745

Epoch: 6| Step: 7
Training loss: 0.0542883425951004
Validation loss: 1.47441440884785

Epoch: 6| Step: 8
Training loss: 0.07174591720104218
Validation loss: 1.4588880013394099

Epoch: 6| Step: 9
Training loss: 0.08812476694583893
Validation loss: 1.4414208832607474

Epoch: 6| Step: 10
Training loss: 0.10663685947656631
Validation loss: 1.426097321253951

Epoch: 6| Step: 11
Training loss: 0.055383987724781036
Validation loss: 1.4253713161714616

Epoch: 6| Step: 12
Training loss: 0.15545473992824554
Validation loss: 1.40690246705086

Epoch: 6| Step: 13
Training loss: 0.07874280959367752
Validation loss: 1.4363213123813752

Epoch: 475| Step: 0
Training loss: 0.07735160738229752
Validation loss: 1.465131837834594

Epoch: 6| Step: 1
Training loss: 0.04860653728246689
Validation loss: 1.475696530393375

Epoch: 6| Step: 2
Training loss: 0.13597960770130157
Validation loss: 1.5067803295709754

Epoch: 6| Step: 3
Training loss: 0.08001360297203064
Validation loss: 1.499933668362197

Epoch: 6| Step: 4
Training loss: 0.08420748263597488
Validation loss: 1.5017594393863474

Epoch: 6| Step: 5
Training loss: 0.10346957296133041
Validation loss: 1.5093500562893447

Epoch: 6| Step: 6
Training loss: 0.08560538291931152
Validation loss: 1.4996986273796327

Epoch: 6| Step: 7
Training loss: 0.10968028008937836
Validation loss: 1.4906044801076253

Epoch: 6| Step: 8
Training loss: 0.08746513724327087
Validation loss: 1.456142234545882

Epoch: 6| Step: 9
Training loss: 0.08494096249341965
Validation loss: 1.4749783303148003

Epoch: 6| Step: 10
Training loss: 0.12084762752056122
Validation loss: 1.4630090049518052

Epoch: 6| Step: 11
Training loss: 0.07847865670919418
Validation loss: 1.444034049587865

Epoch: 6| Step: 12
Training loss: 0.1303812563419342
Validation loss: 1.480834525118592

Epoch: 6| Step: 13
Training loss: 0.09317608177661896
Validation loss: 1.4856464991005518

Epoch: 476| Step: 0
Training loss: 0.14677128195762634
Validation loss: 1.4477033615112305

Epoch: 6| Step: 1
Training loss: 0.08436895161867142
Validation loss: 1.4666942870745094

Epoch: 6| Step: 2
Training loss: 0.1269451379776001
Validation loss: 1.466430269261842

Epoch: 6| Step: 3
Training loss: 0.058804094791412354
Validation loss: 1.4821386709008166

Epoch: 6| Step: 4
Training loss: 0.09299605339765549
Validation loss: 1.485505775738788

Epoch: 6| Step: 5
Training loss: 0.05844613164663315
Validation loss: 1.4863419635321504

Epoch: 6| Step: 6
Training loss: 0.08851274102926254
Validation loss: 1.5129167751599384

Epoch: 6| Step: 7
Training loss: 0.08841804414987564
Validation loss: 1.5213914725088304

Epoch: 6| Step: 8
Training loss: 0.1126340851187706
Validation loss: 1.5255465795916896

Epoch: 6| Step: 9
Training loss: 0.12055086344480515
Validation loss: 1.521355764840239

Epoch: 6| Step: 10
Training loss: 0.09722240269184113
Validation loss: 1.510722388503372

Epoch: 6| Step: 11
Training loss: 0.13700169324874878
Validation loss: 1.4871340772157073

Epoch: 6| Step: 12
Training loss: 0.05180937796831131
Validation loss: 1.482414395578446

Epoch: 6| Step: 13
Training loss: 0.08513128757476807
Validation loss: 1.4688629604155017

Epoch: 477| Step: 0
Training loss: 0.10001233965158463
Validation loss: 1.4568003351970384

Epoch: 6| Step: 1
Training loss: 0.23640763759613037
Validation loss: 1.457342306772868

Epoch: 6| Step: 2
Training loss: 0.19057323038578033
Validation loss: 1.4630599252639278

Epoch: 6| Step: 3
Training loss: 0.04546637833118439
Validation loss: 1.4646960573811685

Epoch: 6| Step: 4
Training loss: 0.0650399774312973
Validation loss: 1.482400845455867

Epoch: 6| Step: 5
Training loss: 0.09233268350362778
Validation loss: 1.494264518060992

Epoch: 6| Step: 6
Training loss: 0.10230319201946259
Validation loss: 1.4913169869812586

Epoch: 6| Step: 7
Training loss: 0.0905597135424614
Validation loss: 1.4933761024987826

Epoch: 6| Step: 8
Training loss: 0.12400858104228973
Validation loss: 1.520372498419977

Epoch: 6| Step: 9
Training loss: 0.1390949785709381
Validation loss: 1.5156542229396042

Epoch: 6| Step: 10
Training loss: 0.10884606838226318
Validation loss: 1.4867275632837766

Epoch: 6| Step: 11
Training loss: 0.08811302483081818
Validation loss: 1.4857171049682043

Epoch: 6| Step: 12
Training loss: 0.08878052234649658
Validation loss: 1.478045686598747

Epoch: 6| Step: 13
Training loss: 0.1132659912109375
Validation loss: 1.4944687889468284

Epoch: 478| Step: 0
Training loss: 0.12371684610843658
Validation loss: 1.5081184320552374

Epoch: 6| Step: 1
Training loss: 0.16275420784950256
Validation loss: 1.4879264600815312

Epoch: 6| Step: 2
Training loss: 0.09757066518068314
Validation loss: 1.4970085172243015

Epoch: 6| Step: 3
Training loss: 0.10020729899406433
Validation loss: 1.489970286687215

Epoch: 6| Step: 4
Training loss: 0.10820572823286057
Validation loss: 1.4820362252573813

Epoch: 6| Step: 5
Training loss: 0.12456904351711273
Validation loss: 1.4927469145867132

Epoch: 6| Step: 6
Training loss: 0.06878568977117538
Validation loss: 1.4726585124128608

Epoch: 6| Step: 7
Training loss: 0.09936144948005676
Validation loss: 1.5016680071430821

Epoch: 6| Step: 8
Training loss: 0.20113877952098846
Validation loss: 1.5032374230764245

Epoch: 6| Step: 9
Training loss: 0.17720672488212585
Validation loss: 1.5204053143019318

Epoch: 6| Step: 10
Training loss: 0.15163974463939667
Validation loss: 1.500946702495698

Epoch: 6| Step: 11
Training loss: 0.08000779896974564
Validation loss: 1.5012919056800105

Epoch: 6| Step: 12
Training loss: 0.0864948257803917
Validation loss: 1.4619341973335511

Epoch: 6| Step: 13
Training loss: 0.15640874207019806
Validation loss: 1.483214762903029

Epoch: 479| Step: 0
Training loss: 0.13004417717456818
Validation loss: 1.4834591163102018

Epoch: 6| Step: 1
Training loss: 0.14374089241027832
Validation loss: 1.5032715669242285

Epoch: 6| Step: 2
Training loss: 0.11180010437965393
Validation loss: 1.499859457374901

Epoch: 6| Step: 3
Training loss: 0.09104140102863312
Validation loss: 1.473898861997871

Epoch: 6| Step: 4
Training loss: 0.08217360079288483
Validation loss: 1.4731095394780558

Epoch: 6| Step: 5
Training loss: 0.16314035654067993
Validation loss: 1.494423097179782

Epoch: 6| Step: 6
Training loss: 0.14921250939369202
Validation loss: 1.5107568053789036

Epoch: 6| Step: 7
Training loss: 0.10612371563911438
Validation loss: 1.5153528259646507

Epoch: 6| Step: 8
Training loss: 0.13954153656959534
Validation loss: 1.5347109917671449

Epoch: 6| Step: 9
Training loss: 0.16085022687911987
Validation loss: 1.468213463342318

Epoch: 6| Step: 10
Training loss: 0.1292269229888916
Validation loss: 1.4825849186989568

Epoch: 6| Step: 11
Training loss: 0.07891769707202911
Validation loss: 1.4905451433632964

Epoch: 6| Step: 12
Training loss: 0.05499250441789627
Validation loss: 1.480408847972911

Epoch: 6| Step: 13
Training loss: 0.10434377193450928
Validation loss: 1.4881524667944959

Epoch: 480| Step: 0
Training loss: 0.1582365334033966
Validation loss: 1.4706473042888026

Epoch: 6| Step: 1
Training loss: 0.09120224416255951
Validation loss: 1.4840534117914015

Epoch: 6| Step: 2
Training loss: 0.08842790871858597
Validation loss: 1.4543540964844406

Epoch: 6| Step: 3
Training loss: 0.08355344086885452
Validation loss: 1.455723101092923

Epoch: 6| Step: 4
Training loss: 0.12690860033035278
Validation loss: 1.4653895196094309

Epoch: 6| Step: 5
Training loss: 0.10995365679264069
Validation loss: 1.4905951946012435

Epoch: 6| Step: 6
Training loss: 0.05986299365758896
Validation loss: 1.4907935921863844

Epoch: 6| Step: 7
Training loss: 0.09565290808677673
Validation loss: 1.458128208755165

Epoch: 6| Step: 8
Training loss: 0.10525362193584442
Validation loss: 1.4886099164203932

Epoch: 6| Step: 9
Training loss: 0.12421993911266327
Validation loss: 1.4756018045128032

Epoch: 6| Step: 10
Training loss: 0.10268111526966095
Validation loss: 1.4800522968333254

Epoch: 6| Step: 11
Training loss: 0.12240587919950485
Validation loss: 1.4356805406590945

Epoch: 6| Step: 12
Training loss: 0.07959224283695221
Validation loss: 1.4468133167553974

Epoch: 6| Step: 13
Training loss: 0.08913910388946533
Validation loss: 1.4634145895640056

Epoch: 481| Step: 0
Training loss: 0.09660232067108154
Validation loss: 1.4648298871132635

Epoch: 6| Step: 1
Training loss: 0.11842906475067139
Validation loss: 1.4928872739115069

Epoch: 6| Step: 2
Training loss: 0.08583858609199524
Validation loss: 1.4858405179874872

Epoch: 6| Step: 3
Training loss: 0.0821438580751419
Validation loss: 1.505309360001677

Epoch: 6| Step: 4
Training loss: 0.09196338057518005
Validation loss: 1.5024125537564677

Epoch: 6| Step: 5
Training loss: 0.1394544541835785
Validation loss: 1.4970105617277083

Epoch: 6| Step: 6
Training loss: 0.06906893104314804
Validation loss: 1.5390286432799472

Epoch: 6| Step: 7
Training loss: 0.10437741875648499
Validation loss: 1.501470253031741

Epoch: 6| Step: 8
Training loss: 0.14149223268032074
Validation loss: 1.4957255368591638

Epoch: 6| Step: 9
Training loss: 0.10476608574390411
Validation loss: 1.5271004784491755

Epoch: 6| Step: 10
Training loss: 0.13707061111927032
Validation loss: 1.5192405344337545

Epoch: 6| Step: 11
Training loss: 0.0915486216545105
Validation loss: 1.507901414748161

Epoch: 6| Step: 12
Training loss: 0.06880899518728256
Validation loss: 1.4999437280880508

Epoch: 6| Step: 13
Training loss: 0.07241523265838623
Validation loss: 1.4939310358416649

Epoch: 482| Step: 0
Training loss: 0.13872335851192474
Validation loss: 1.4847247241645731

Epoch: 6| Step: 1
Training loss: 0.12025746703147888
Validation loss: 1.4679267009099324

Epoch: 6| Step: 2
Training loss: 0.06251337379217148
Validation loss: 1.4908976003687868

Epoch: 6| Step: 3
Training loss: 0.08565998077392578
Validation loss: 1.4825581248088548

Epoch: 6| Step: 4
Training loss: 0.10335074365139008
Validation loss: 1.4749300390161493

Epoch: 6| Step: 5
Training loss: 0.09000441431999207
Validation loss: 1.459134828659796

Epoch: 6| Step: 6
Training loss: 0.08277575671672821
Validation loss: 1.4838215958687566

Epoch: 6| Step: 7
Training loss: 0.07483813166618347
Validation loss: 1.481117006271116

Epoch: 6| Step: 8
Training loss: 0.048513635993003845
Validation loss: 1.5070153820899226

Epoch: 6| Step: 9
Training loss: 0.11935349553823471
Validation loss: 1.508424449351526

Epoch: 6| Step: 10
Training loss: 0.114561066031456
Validation loss: 1.4950226545333862

Epoch: 6| Step: 11
Training loss: 0.06262469291687012
Validation loss: 1.4749416407718454

Epoch: 6| Step: 12
Training loss: 0.07946588099002838
Validation loss: 1.4700302834151893

Epoch: 6| Step: 13
Training loss: 0.07572947442531586
Validation loss: 1.5003479911435036

Epoch: 483| Step: 0
Training loss: 0.0770745724439621
Validation loss: 1.4551292670670377

Epoch: 6| Step: 1
Training loss: 0.08398771286010742
Validation loss: 1.4571949987001316

Epoch: 6| Step: 2
Training loss: 0.08089324086904526
Validation loss: 1.4568950066002466

Epoch: 6| Step: 3
Training loss: 0.11943672597408295
Validation loss: 1.5180960342448244

Epoch: 6| Step: 4
Training loss: 0.07713557034730911
Validation loss: 1.4803607681746125

Epoch: 6| Step: 5
Training loss: 0.1074015200138092
Validation loss: 1.4973241231774772

Epoch: 6| Step: 6
Training loss: 0.06578970700502396
Validation loss: 1.4899906612211657

Epoch: 6| Step: 7
Training loss: 0.09622707962989807
Validation loss: 1.490872283135691

Epoch: 6| Step: 8
Training loss: 0.08409864455461502
Validation loss: 1.5184015074083883

Epoch: 6| Step: 9
Training loss: 0.1211157739162445
Validation loss: 1.5406405810386903

Epoch: 6| Step: 10
Training loss: 0.14247411489486694
Validation loss: 1.5228592606001004

Epoch: 6| Step: 11
Training loss: 0.10648326575756073
Validation loss: 1.5277864651013446

Epoch: 6| Step: 12
Training loss: 0.08642560988664627
Validation loss: 1.53022627933051

Epoch: 6| Step: 13
Training loss: 0.09793678671121597
Validation loss: 1.535000567795128

Epoch: 484| Step: 0
Training loss: 0.08496570587158203
Validation loss: 1.5099335114161174

Epoch: 6| Step: 1
Training loss: 0.08883845806121826
Validation loss: 1.4944063386609476

Epoch: 6| Step: 2
Training loss: 0.05769125372171402
Validation loss: 1.512305498123169

Epoch: 6| Step: 3
Training loss: 0.07791528105735779
Validation loss: 1.5022767192573958

Epoch: 6| Step: 4
Training loss: 0.10891519486904144
Validation loss: 1.489486894299907

Epoch: 6| Step: 5
Training loss: 0.07046937942504883
Validation loss: 1.5177254292272753

Epoch: 6| Step: 6
Training loss: 0.10200990736484528
Validation loss: 1.5479107595259143

Epoch: 6| Step: 7
Training loss: 0.11002739518880844
Validation loss: 1.5425005112924883

Epoch: 6| Step: 8
Training loss: 0.09559594839811325
Validation loss: 1.5257344656093146

Epoch: 6| Step: 9
Training loss: 0.06723795086145401
Validation loss: 1.5492050699008408

Epoch: 6| Step: 10
Training loss: 0.10086025297641754
Validation loss: 1.53505721399861

Epoch: 6| Step: 11
Training loss: 0.07390796393156052
Validation loss: 1.5194399049205165

Epoch: 6| Step: 12
Training loss: 0.06254860013723373
Validation loss: 1.5247734067260579

Epoch: 6| Step: 13
Training loss: 0.08678940683603287
Validation loss: 1.4810497196771766

Epoch: 485| Step: 0
Training loss: 0.06682758033275604
Validation loss: 1.499523796061034

Epoch: 6| Step: 1
Training loss: 0.1261981725692749
Validation loss: 1.5242345602281633

Epoch: 6| Step: 2
Training loss: 0.07210816442966461
Validation loss: 1.4852086472254928

Epoch: 6| Step: 3
Training loss: 0.064935602247715
Validation loss: 1.4916862557011266

Epoch: 6| Step: 4
Training loss: 0.09570305049419403
Validation loss: 1.4846682522886543

Epoch: 6| Step: 5
Training loss: 0.11982783675193787
Validation loss: 1.5009705405081473

Epoch: 6| Step: 6
Training loss: 0.06739529967308044
Validation loss: 1.4668338196251982

Epoch: 6| Step: 7
Training loss: 0.0758373811841011
Validation loss: 1.4655691231450727

Epoch: 6| Step: 8
Training loss: 0.08438341319561005
Validation loss: 1.4812904865511003

Epoch: 6| Step: 9
Training loss: 0.0991133600473404
Validation loss: 1.4842992841556508

Epoch: 6| Step: 10
Training loss: 0.126816064119339
Validation loss: 1.487693182883724

Epoch: 6| Step: 11
Training loss: 0.11222687363624573
Validation loss: 1.482579670926576

Epoch: 6| Step: 12
Training loss: 0.07688279449939728
Validation loss: 1.49679744948623

Epoch: 6| Step: 13
Training loss: 0.15001124143600464
Validation loss: 1.475053955149907

Epoch: 486| Step: 0
Training loss: 0.07576185464859009
Validation loss: 1.4809113766557427

Epoch: 6| Step: 1
Training loss: 0.08848588168621063
Validation loss: 1.5138400652075326

Epoch: 6| Step: 2
Training loss: 0.09258467704057693
Validation loss: 1.489518234806676

Epoch: 6| Step: 3
Training loss: 0.05263572931289673
Validation loss: 1.4853225395243654

Epoch: 6| Step: 4
Training loss: 0.09613922238349915
Validation loss: 1.4898211943205966

Epoch: 6| Step: 5
Training loss: 0.06938248127698898
Validation loss: 1.4833369370429748

Epoch: 6| Step: 6
Training loss: 0.09216655790805817
Validation loss: 1.4816950995434996

Epoch: 6| Step: 7
Training loss: 0.08586034178733826
Validation loss: 1.4555941794508247

Epoch: 6| Step: 8
Training loss: 0.058184780180454254
Validation loss: 1.4570300784162296

Epoch: 6| Step: 9
Training loss: 0.090827576816082
Validation loss: 1.4758684673616964

Epoch: 6| Step: 10
Training loss: 0.08339571207761765
Validation loss: 1.457637543319374

Epoch: 6| Step: 11
Training loss: 0.10745809227228165
Validation loss: 1.4626534433775051

Epoch: 6| Step: 12
Training loss: 0.07307679206132889
Validation loss: 1.4831622569791731

Epoch: 6| Step: 13
Training loss: 0.10302543640136719
Validation loss: 1.485522147147886

Epoch: 487| Step: 0
Training loss: 0.07196065783500671
Validation loss: 1.4978131478832615

Epoch: 6| Step: 1
Training loss: 0.10117799788713455
Validation loss: 1.4976905045970794

Epoch: 6| Step: 2
Training loss: 0.13197600841522217
Validation loss: 1.4702196454489103

Epoch: 6| Step: 3
Training loss: 0.06133217737078667
Validation loss: 1.491449659870517

Epoch: 6| Step: 4
Training loss: 0.057325705885887146
Validation loss: 1.5426069472425727

Epoch: 6| Step: 5
Training loss: 0.06723756343126297
Validation loss: 1.5283534180733465

Epoch: 6| Step: 6
Training loss: 0.09957948327064514
Validation loss: 1.5284553266340686

Epoch: 6| Step: 7
Training loss: 0.11337742954492569
Validation loss: 1.5146477606988722

Epoch: 6| Step: 8
Training loss: 0.10351802408695221
Validation loss: 1.5010321896563295

Epoch: 6| Step: 9
Training loss: 0.0931970626115799
Validation loss: 1.5220393442338513

Epoch: 6| Step: 10
Training loss: 0.08840827643871307
Validation loss: 1.5077948224159978

Epoch: 6| Step: 11
Training loss: 0.123727947473526
Validation loss: 1.4806322269542243

Epoch: 6| Step: 12
Training loss: 0.0816519558429718
Validation loss: 1.4977607252777263

Epoch: 6| Step: 13
Training loss: 0.061826109886169434
Validation loss: 1.4800988269108597

Epoch: 488| Step: 0
Training loss: 0.07177434861660004
Validation loss: 1.4826337291348366

Epoch: 6| Step: 1
Training loss: 0.10728365927934647
Validation loss: 1.4716280455230384

Epoch: 6| Step: 2
Training loss: 0.08799883723258972
Validation loss: 1.4631820615901743

Epoch: 6| Step: 3
Training loss: 0.07904178649187088
Validation loss: 1.4702930245348202

Epoch: 6| Step: 4
Training loss: 0.09062039107084274
Validation loss: 1.4782856830986597

Epoch: 6| Step: 5
Training loss: 0.11987920105457306
Validation loss: 1.4778915682146627

Epoch: 6| Step: 6
Training loss: 0.0874183252453804
Validation loss: 1.465407012611307

Epoch: 6| Step: 7
Training loss: 0.10809154808521271
Validation loss: 1.4871186825536913

Epoch: 6| Step: 8
Training loss: 0.05059858039021492
Validation loss: 1.4708953096020607

Epoch: 6| Step: 9
Training loss: 0.10071690380573273
Validation loss: 1.470070964546614

Epoch: 6| Step: 10
Training loss: 0.13092410564422607
Validation loss: 1.492957592010498

Epoch: 6| Step: 11
Training loss: 0.09835635125637054
Validation loss: 1.464257881205569

Epoch: 6| Step: 12
Training loss: 0.10015957802534103
Validation loss: 1.4645752714526268

Epoch: 6| Step: 13
Training loss: 0.09915300458669662
Validation loss: 1.4739194352139708

Epoch: 489| Step: 0
Training loss: 0.13148939609527588
Validation loss: 1.4783462285995483

Epoch: 6| Step: 1
Training loss: 0.04301205277442932
Validation loss: 1.4577978759683587

Epoch: 6| Step: 2
Training loss: 0.07080448418855667
Validation loss: 1.4759919387038036

Epoch: 6| Step: 3
Training loss: 0.10404999554157257
Validation loss: 1.4926570077096262

Epoch: 6| Step: 4
Training loss: 0.08523954451084137
Validation loss: 1.4831955317528016

Epoch: 6| Step: 5
Training loss: 0.07498691976070404
Validation loss: 1.487367110867654

Epoch: 6| Step: 6
Training loss: 0.07530289888381958
Validation loss: 1.5192958859987156

Epoch: 6| Step: 7
Training loss: 0.048354826867580414
Validation loss: 1.5257197381347738

Epoch: 6| Step: 8
Training loss: 0.07263505458831787
Validation loss: 1.521960098256347

Epoch: 6| Step: 9
Training loss: 0.07958563417196274
Validation loss: 1.5280607041492258

Epoch: 6| Step: 10
Training loss: 0.14062988758087158
Validation loss: 1.5167135782139276

Epoch: 6| Step: 11
Training loss: 0.14993533492088318
Validation loss: 1.5364384933184552

Epoch: 6| Step: 12
Training loss: 0.09133686125278473
Validation loss: 1.5056612799244542

Epoch: 6| Step: 13
Training loss: 0.0853925570845604
Validation loss: 1.5128712243931268

Epoch: 490| Step: 0
Training loss: 0.09188477694988251
Validation loss: 1.5054270554614324

Epoch: 6| Step: 1
Training loss: 0.06280979514122009
Validation loss: 1.481159471696423

Epoch: 6| Step: 2
Training loss: 0.08626750111579895
Validation loss: 1.5063988624080535

Epoch: 6| Step: 3
Training loss: 0.07407166063785553
Validation loss: 1.4961928372742028

Epoch: 6| Step: 4
Training loss: 0.10401167720556259
Validation loss: 1.4964425025447723

Epoch: 6| Step: 5
Training loss: 0.07733333855867386
Validation loss: 1.4765626999639696

Epoch: 6| Step: 6
Training loss: 0.09515442699193954
Validation loss: 1.482756442921136

Epoch: 6| Step: 7
Training loss: 0.13148033618927002
Validation loss: 1.4903085359963038

Epoch: 6| Step: 8
Training loss: 0.10445480793714523
Validation loss: 1.481215003998049

Epoch: 6| Step: 9
Training loss: 0.1216643750667572
Validation loss: 1.4814299075834212

Epoch: 6| Step: 10
Training loss: 0.10448950529098511
Validation loss: 1.4578322672074842

Epoch: 6| Step: 11
Training loss: 0.0857464075088501
Validation loss: 1.4629397558909591

Epoch: 6| Step: 12
Training loss: 0.07617241144180298
Validation loss: 1.4890117632445468

Epoch: 6| Step: 13
Training loss: 0.10360611975193024
Validation loss: 1.4827284838563652

Epoch: 491| Step: 0
Training loss: 0.10055713355541229
Validation loss: 1.492158124523778

Epoch: 6| Step: 1
Training loss: 0.11884946376085281
Validation loss: 1.4749330038665442

Epoch: 6| Step: 2
Training loss: 0.05731349438428879
Validation loss: 1.474621895820864

Epoch: 6| Step: 3
Training loss: 0.03676917031407356
Validation loss: 1.4480137901921426

Epoch: 6| Step: 4
Training loss: 0.06242351233959198
Validation loss: 1.4493813194254392

Epoch: 6| Step: 5
Training loss: 0.07066015899181366
Validation loss: 1.425982027925471

Epoch: 6| Step: 6
Training loss: 0.10193528234958649
Validation loss: 1.500574186284055

Epoch: 6| Step: 7
Training loss: 0.05448836460709572
Validation loss: 1.4844942554350822

Epoch: 6| Step: 8
Training loss: 0.08031830191612244
Validation loss: 1.478552810607418

Epoch: 6| Step: 9
Training loss: 0.06776493042707443
Validation loss: 1.4668387571970622

Epoch: 6| Step: 10
Training loss: 0.08594273030757904
Validation loss: 1.4641075102231835

Epoch: 6| Step: 11
Training loss: 0.11997854709625244
Validation loss: 1.4532120561087003

Epoch: 6| Step: 12
Training loss: 0.08661156892776489
Validation loss: 1.4580741672105686

Epoch: 6| Step: 13
Training loss: 0.09271004796028137
Validation loss: 1.4783398188570493

Epoch: 492| Step: 0
Training loss: 0.08928719162940979
Validation loss: 1.4528046051661174

Epoch: 6| Step: 1
Training loss: 0.10220559686422348
Validation loss: 1.4744144485842796

Epoch: 6| Step: 2
Training loss: 0.0804181694984436
Validation loss: 1.4978886509454379

Epoch: 6| Step: 3
Training loss: 0.0694601982831955
Validation loss: 1.4971900370813185

Epoch: 6| Step: 4
Training loss: 0.09353078901767731
Validation loss: 1.5042371519150273

Epoch: 6| Step: 5
Training loss: 0.11438601464033127
Validation loss: 1.5425955210962603

Epoch: 6| Step: 6
Training loss: 0.10864783823490143
Validation loss: 1.5449733580312421

Epoch: 6| Step: 7
Training loss: 0.10604290664196014
Validation loss: 1.5156361159457956

Epoch: 6| Step: 8
Training loss: 0.11507976055145264
Validation loss: 1.5344137978810135

Epoch: 6| Step: 9
Training loss: 0.11177175492048264
Validation loss: 1.5264860404435026

Epoch: 6| Step: 10
Training loss: 0.0736638680100441
Validation loss: 1.5115686719135573

Epoch: 6| Step: 11
Training loss: 0.07183398306369781
Validation loss: 1.5171672656971922

Epoch: 6| Step: 12
Training loss: 0.10188064724206924
Validation loss: 1.4984333361348798

Epoch: 6| Step: 13
Training loss: 0.1382649540901184
Validation loss: 1.491737086285827

Epoch: 493| Step: 0
Training loss: 0.09644497185945511
Validation loss: 1.5227338229456255

Epoch: 6| Step: 1
Training loss: 0.22762040793895721
Validation loss: 1.505556207831188

Epoch: 6| Step: 2
Training loss: 0.0683039128780365
Validation loss: 1.4883471855553247

Epoch: 6| Step: 3
Training loss: 0.12146393954753876
Validation loss: 1.5069470892670334

Epoch: 6| Step: 4
Training loss: 0.10231999307870865
Validation loss: 1.4653785626093547

Epoch: 6| Step: 5
Training loss: 0.12016603350639343
Validation loss: 1.4650316738313245

Epoch: 6| Step: 6
Training loss: 0.13614249229431152
Validation loss: 1.487047359507571

Epoch: 6| Step: 7
Training loss: 0.06867532432079315
Validation loss: 1.4843701688192223

Epoch: 6| Step: 8
Training loss: 0.08232724666595459
Validation loss: 1.4808964267853768

Epoch: 6| Step: 9
Training loss: 0.08664068579673767
Validation loss: 1.4729433110965195

Epoch: 6| Step: 10
Training loss: 0.08747203648090363
Validation loss: 1.5109817545901063

Epoch: 6| Step: 11
Training loss: 0.11278652399778366
Validation loss: 1.52856162927484

Epoch: 6| Step: 12
Training loss: 0.07681263983249664
Validation loss: 1.5046771931391891

Epoch: 6| Step: 13
Training loss: 0.14603212475776672
Validation loss: 1.5349231291842718

Epoch: 494| Step: 0
Training loss: 0.1396244466304779
Validation loss: 1.514099694067432

Epoch: 6| Step: 1
Training loss: 0.07270176708698273
Validation loss: 1.5059767474410355

Epoch: 6| Step: 2
Training loss: 0.06284083425998688
Validation loss: 1.5531978337995467

Epoch: 6| Step: 3
Training loss: 0.11174541711807251
Validation loss: 1.5524567622010426

Epoch: 6| Step: 4
Training loss: 0.12924125790596008
Validation loss: 1.5520045398384013

Epoch: 6| Step: 5
Training loss: 0.11902777850627899
Validation loss: 1.5218284296733078

Epoch: 6| Step: 6
Training loss: 0.07677304744720459
Validation loss: 1.4910631243900587

Epoch: 6| Step: 7
Training loss: 0.10526017844676971
Validation loss: 1.4842295672303887

Epoch: 6| Step: 8
Training loss: 0.1225491464138031
Validation loss: 1.4939409443127212

Epoch: 6| Step: 9
Training loss: 0.08061547577381134
Validation loss: 1.476785691835547

Epoch: 6| Step: 10
Training loss: 0.06814198940992355
Validation loss: 1.491116310960503

Epoch: 6| Step: 11
Training loss: 0.10499347001314163
Validation loss: 1.499820996997177

Epoch: 6| Step: 12
Training loss: 0.11400289833545685
Validation loss: 1.5332617003430602

Epoch: 6| Step: 13
Training loss: 0.2291012406349182
Validation loss: 1.526711102454893

Epoch: 495| Step: 0
Training loss: 0.05559605360031128
Validation loss: 1.525115079777215

Epoch: 6| Step: 1
Training loss: 0.0689513087272644
Validation loss: 1.5467492713723132

Epoch: 6| Step: 2
Training loss: 0.09991098195314407
Validation loss: 1.5507093526983773

Epoch: 6| Step: 3
Training loss: 0.08319629728794098
Validation loss: 1.57756773694869

Epoch: 6| Step: 4
Training loss: 0.08936197310686111
Validation loss: 1.5652271624534362

Epoch: 6| Step: 5
Training loss: 0.12234886735677719
Validation loss: 1.5541891154422556

Epoch: 6| Step: 6
Training loss: 0.08864044398069382
Validation loss: 1.5546200095966298

Epoch: 6| Step: 7
Training loss: 0.09772388637065887
Validation loss: 1.5443411322050198

Epoch: 6| Step: 8
Training loss: 0.06217335909605026
Validation loss: 1.5588103571245748

Epoch: 6| Step: 9
Training loss: 0.06520568579435349
Validation loss: 1.547635624485631

Epoch: 6| Step: 10
Training loss: 0.08431321382522583
Validation loss: 1.5155965589707898

Epoch: 6| Step: 11
Training loss: 0.12006041407585144
Validation loss: 1.524321286909042

Epoch: 6| Step: 12
Training loss: 0.14415007829666138
Validation loss: 1.5020432049228298

Epoch: 6| Step: 13
Training loss: 0.07586532086133957
Validation loss: 1.5099491195012165

Epoch: 496| Step: 0
Training loss: 0.09043151140213013
Validation loss: 1.5300270447167017

Epoch: 6| Step: 1
Training loss: 0.07398398220539093
Validation loss: 1.4905870627331477

Epoch: 6| Step: 2
Training loss: 0.09065243601799011
Validation loss: 1.5116641380453621

Epoch: 6| Step: 3
Training loss: 0.0844787135720253
Validation loss: 1.5158560827214231

Epoch: 6| Step: 4
Training loss: 0.12824022769927979
Validation loss: 1.5160989222988006

Epoch: 6| Step: 5
Training loss: 0.11315649747848511
Validation loss: 1.5392057344477663

Epoch: 6| Step: 6
Training loss: 0.1671563684940338
Validation loss: 1.526031607581723

Epoch: 6| Step: 7
Training loss: 0.0974738597869873
Validation loss: 1.5159791464446692

Epoch: 6| Step: 8
Training loss: 0.112227663397789
Validation loss: 1.4911085277475336

Epoch: 6| Step: 9
Training loss: 0.08707919716835022
Validation loss: 1.5096844370647142

Epoch: 6| Step: 10
Training loss: 0.055950313806533813
Validation loss: 1.5171006905135287

Epoch: 6| Step: 11
Training loss: 0.07007459551095963
Validation loss: 1.5069667068860864

Epoch: 6| Step: 12
Training loss: 0.04681048542261124
Validation loss: 1.4886380523763678

Epoch: 6| Step: 13
Training loss: 0.07323408126831055
Validation loss: 1.4880456732165428

Epoch: 497| Step: 0
Training loss: 0.09259606897830963
Validation loss: 1.4790080029477355

Epoch: 6| Step: 1
Training loss: 0.07554450631141663
Validation loss: 1.5143939641214186

Epoch: 6| Step: 2
Training loss: 0.057327352464199066
Validation loss: 1.4892416243912072

Epoch: 6| Step: 3
Training loss: 0.139097198843956
Validation loss: 1.4660446836102394

Epoch: 6| Step: 4
Training loss: 0.08492260426282883
Validation loss: 1.4865802705928843

Epoch: 6| Step: 5
Training loss: 0.09015156328678131
Validation loss: 1.5007880400585871

Epoch: 6| Step: 6
Training loss: 0.09171068668365479
Validation loss: 1.4751858480515019

Epoch: 6| Step: 7
Training loss: 0.09194011986255646
Validation loss: 1.508508425886913

Epoch: 6| Step: 8
Training loss: 0.08229593187570572
Validation loss: 1.5186087328900573

Epoch: 6| Step: 9
Training loss: 0.09647762775421143
Validation loss: 1.5506687548852736

Epoch: 6| Step: 10
Training loss: 0.14704374969005585
Validation loss: 1.5611431265390048

Epoch: 6| Step: 11
Training loss: 0.13024432957172394
Validation loss: 1.5621199659121934

Epoch: 6| Step: 12
Training loss: 0.10675540566444397
Validation loss: 1.545593793674182

Epoch: 6| Step: 13
Training loss: 0.03367571160197258
Validation loss: 1.5470842469123103

Epoch: 498| Step: 0
Training loss: 0.09068344533443451
Validation loss: 1.540526085002448

Epoch: 6| Step: 1
Training loss: 0.0884663537144661
Validation loss: 1.5505488598218529

Epoch: 6| Step: 2
Training loss: 0.11499863862991333
Validation loss: 1.5228833049856207

Epoch: 6| Step: 3
Training loss: 0.0777343288064003
Validation loss: 1.542250253820932

Epoch: 6| Step: 4
Training loss: 0.06298837065696716
Validation loss: 1.541331983381702

Epoch: 6| Step: 5
Training loss: 0.08844362944364548
Validation loss: 1.5325905738338348

Epoch: 6| Step: 6
Training loss: 0.12746262550354004
Validation loss: 1.5540571969042543

Epoch: 6| Step: 7
Training loss: 0.05570181831717491
Validation loss: 1.5457523856111752

Epoch: 6| Step: 8
Training loss: 0.11855623871088028
Validation loss: 1.5367823082913634

Epoch: 6| Step: 9
Training loss: 0.07851120829582214
Validation loss: 1.4959045738302252

Epoch: 6| Step: 10
Training loss: 0.13449648022651672
Validation loss: 1.5352172684925858

Epoch: 6| Step: 11
Training loss: 0.0760483369231224
Validation loss: 1.5166997076362692

Epoch: 6| Step: 12
Training loss: 0.10670506954193115
Validation loss: 1.5320784609804872

Epoch: 6| Step: 13
Training loss: 0.115512914955616
Validation loss: 1.4774708222317439

Epoch: 499| Step: 0
Training loss: 0.07925817370414734
Validation loss: 1.4858421894811815

Epoch: 6| Step: 1
Training loss: 0.07696456462144852
Validation loss: 1.463840324391601

Epoch: 6| Step: 2
Training loss: 0.07955586165189743
Validation loss: 1.4640108404621002

Epoch: 6| Step: 3
Training loss: 0.06723456084728241
Validation loss: 1.4540282269959808

Epoch: 6| Step: 4
Training loss: 0.08662570267915726
Validation loss: 1.453012635630946

Epoch: 6| Step: 5
Training loss: 0.11152355372905731
Validation loss: 1.4429949483563822

Epoch: 6| Step: 6
Training loss: 0.09717033058404922
Validation loss: 1.4301521355105984

Epoch: 6| Step: 7
Training loss: 0.13423079252243042
Validation loss: 1.4400039321632796

Epoch: 6| Step: 8
Training loss: 0.09750203788280487
Validation loss: 1.4475591118617723

Epoch: 6| Step: 9
Training loss: 0.05235091596841812
Validation loss: 1.4669356256402948

Epoch: 6| Step: 10
Training loss: 0.07300892472267151
Validation loss: 1.5026627779006958

Epoch: 6| Step: 11
Training loss: 0.11467383801937103
Validation loss: 1.484774927939138

Epoch: 6| Step: 12
Training loss: 0.08070950210094452
Validation loss: 1.5122424069271292

Epoch: 6| Step: 13
Training loss: 0.06951769441366196
Validation loss: 1.5156685165179673

Epoch: 500| Step: 0
Training loss: 0.07542277872562408
Validation loss: 1.522134070755333

Epoch: 6| Step: 1
Training loss: 0.08605240285396576
Validation loss: 1.4901784671250211

Epoch: 6| Step: 2
Training loss: 0.11182735115289688
Validation loss: 1.4964330734745148

Epoch: 6| Step: 3
Training loss: 0.06482736766338348
Validation loss: 1.5124050519799674

Epoch: 6| Step: 4
Training loss: 0.0471109002828598
Validation loss: 1.473763721604501

Epoch: 6| Step: 5
Training loss: 0.10719884932041168
Validation loss: 1.4551979867360925

Epoch: 6| Step: 6
Training loss: 0.08741414546966553
Validation loss: 1.4747952120278471

Epoch: 6| Step: 7
Training loss: 0.0929199829697609
Validation loss: 1.4320924038528113

Epoch: 6| Step: 8
Training loss: 0.05648078769445419
Validation loss: 1.4494393503153196

Epoch: 6| Step: 9
Training loss: 0.1092962771654129
Validation loss: 1.4487193169132355

Epoch: 6| Step: 10
Training loss: 0.09951269626617432
Validation loss: 1.457683991360408

Epoch: 6| Step: 11
Training loss: 0.08294521272182465
Validation loss: 1.45153473782283

Epoch: 6| Step: 12
Training loss: 0.09333135187625885
Validation loss: 1.447723348935445

Epoch: 6| Step: 13
Training loss: 0.1136273443698883
Validation loss: 1.4599262578513033

Epoch: 501| Step: 0
Training loss: 0.06305500119924545
Validation loss: 1.4748546231177546

Epoch: 6| Step: 1
Training loss: 0.09299220144748688
Validation loss: 1.5121579375318301

Epoch: 6| Step: 2
Training loss: 0.11541926860809326
Validation loss: 1.4812515474134875

Epoch: 6| Step: 3
Training loss: 0.08520191162824631
Validation loss: 1.4912175952747304

Epoch: 6| Step: 4
Training loss: 0.10878121852874756
Validation loss: 1.501619735071736

Epoch: 6| Step: 5
Training loss: 0.09413644671440125
Validation loss: 1.5007716789040515

Epoch: 6| Step: 6
Training loss: 0.13601113855838776
Validation loss: 1.5072684595661778

Epoch: 6| Step: 7
Training loss: 0.0798444151878357
Validation loss: 1.5026039679845173

Epoch: 6| Step: 8
Training loss: 0.09003475308418274
Validation loss: 1.4887219116251955

Epoch: 6| Step: 9
Training loss: 0.06501636654138565
Validation loss: 1.4996586268947971

Epoch: 6| Step: 10
Training loss: 0.0721074640750885
Validation loss: 1.4765534952122679

Epoch: 6| Step: 11
Training loss: 0.0953429564833641
Validation loss: 1.485635261381826

Epoch: 6| Step: 12
Training loss: 0.07920417189598083
Validation loss: 1.4704723024881015

Epoch: 6| Step: 13
Training loss: 0.08007580041885376
Validation loss: 1.4718794950874903

Epoch: 502| Step: 0
Training loss: 0.1015431359410286
Validation loss: 1.4975903687938568

Epoch: 6| Step: 1
Training loss: 0.09824583679437637
Validation loss: 1.480223730046262

Epoch: 6| Step: 2
Training loss: 0.08721205592155457
Validation loss: 1.4882333637565694

Epoch: 6| Step: 3
Training loss: 0.13286608457565308
Validation loss: 1.4629500117353214

Epoch: 6| Step: 4
Training loss: 0.0626620352268219
Validation loss: 1.4893124847001926

Epoch: 6| Step: 5
Training loss: 0.09892750531435013
Validation loss: 1.4832453522630917

Epoch: 6| Step: 6
Training loss: 0.11197924613952637
Validation loss: 1.4815574845960062

Epoch: 6| Step: 7
Training loss: 0.07946989685297012
Validation loss: 1.4782783754410282

Epoch: 6| Step: 8
Training loss: 0.0607408806681633
Validation loss: 1.495139043818238

Epoch: 6| Step: 9
Training loss: 0.09272393584251404
Validation loss: 1.4901012246326735

Epoch: 6| Step: 10
Training loss: 0.08113397657871246
Validation loss: 1.4800958953877932

Epoch: 6| Step: 11
Training loss: 0.0948011577129364
Validation loss: 1.4691187309962448

Epoch: 6| Step: 12
Training loss: 0.14547064900398254
Validation loss: 1.4988743079605924

Epoch: 6| Step: 13
Training loss: 0.07927630841732025
Validation loss: 1.5137862736178982

Epoch: 503| Step: 0
Training loss: 0.07195660471916199
Validation loss: 1.5115583558236398

Epoch: 6| Step: 1
Training loss: 0.09699814021587372
Validation loss: 1.4861998481135215

Epoch: 6| Step: 2
Training loss: 0.10458367317914963
Validation loss: 1.4978934769989343

Epoch: 6| Step: 3
Training loss: 0.0962984561920166
Validation loss: 1.5063916085868754

Epoch: 6| Step: 4
Training loss: 0.08401962369680405
Validation loss: 1.4850966494570497

Epoch: 6| Step: 5
Training loss: 0.14846324920654297
Validation loss: 1.4752282839949413

Epoch: 6| Step: 6
Training loss: 0.06995143741369247
Validation loss: 1.5081159466056413

Epoch: 6| Step: 7
Training loss: 0.057400867342948914
Validation loss: 1.4888875240920691

Epoch: 6| Step: 8
Training loss: 0.08903838694095612
Validation loss: 1.4913567817339333

Epoch: 6| Step: 9
Training loss: 0.10134202241897583
Validation loss: 1.479432140627215

Epoch: 6| Step: 10
Training loss: 0.059161607176065445
Validation loss: 1.4996009783078266

Epoch: 6| Step: 11
Training loss: 0.09799221903085709
Validation loss: 1.5083778750511907

Epoch: 6| Step: 12
Training loss: 0.1089937686920166
Validation loss: 1.495090461546375

Epoch: 6| Step: 13
Training loss: 0.058689408004283905
Validation loss: 1.4790491211798884

Epoch: 504| Step: 0
Training loss: 0.12626120448112488
Validation loss: 1.5036530315235097

Epoch: 6| Step: 1
Training loss: 0.07339418679475784
Validation loss: 1.4787225133629256

Epoch: 6| Step: 2
Training loss: 0.07447745651006699
Validation loss: 1.4716203520374913

Epoch: 6| Step: 3
Training loss: 0.10766420513391495
Validation loss: 1.4771486866858698

Epoch: 6| Step: 4
Training loss: 0.08577524125576019
Validation loss: 1.4898916918744323

Epoch: 6| Step: 5
Training loss: 0.0816197544336319
Validation loss: 1.474597002870293

Epoch: 6| Step: 6
Training loss: 0.0670519769191742
Validation loss: 1.4614294382833666

Epoch: 6| Step: 7
Training loss: 0.08247166872024536
Validation loss: 1.4578703744437105

Epoch: 6| Step: 8
Training loss: 0.08238914608955383
Validation loss: 1.4673153213275376

Epoch: 6| Step: 9
Training loss: 0.09784267842769623
Validation loss: 1.4587028552127141

Epoch: 6| Step: 10
Training loss: 0.08194591104984283
Validation loss: 1.4694765011469524

Epoch: 6| Step: 11
Training loss: 0.09929440915584564
Validation loss: 1.4843075762512863

Epoch: 6| Step: 12
Training loss: 0.0892353430390358
Validation loss: 1.4630741425739822

Epoch: 6| Step: 13
Training loss: 0.0660550594329834
Validation loss: 1.4758683917342976

Epoch: 505| Step: 0
Training loss: 0.13777190446853638
Validation loss: 1.5009162810540968

Epoch: 6| Step: 1
Training loss: 0.09097345918416977
Validation loss: 1.5027684255312848

Epoch: 6| Step: 2
Training loss: 0.1259084790945053
Validation loss: 1.499688483053638

Epoch: 6| Step: 3
Training loss: 0.10844340920448303
Validation loss: 1.5029361850471907

Epoch: 6| Step: 4
Training loss: 0.10562736541032791
Validation loss: 1.4938186689089703

Epoch: 6| Step: 5
Training loss: 0.16692966222763062
Validation loss: 1.4966739057212748

Epoch: 6| Step: 6
Training loss: 0.12034615874290466
Validation loss: 1.5165669007967877

Epoch: 6| Step: 7
Training loss: 0.09226971864700317
Validation loss: 1.5076371931260633

Epoch: 6| Step: 8
Training loss: 0.10253285616636276
Validation loss: 1.4954389102997319

Epoch: 6| Step: 9
Training loss: 0.08895456790924072
Validation loss: 1.493692555735188

Epoch: 6| Step: 10
Training loss: 0.09127581864595413
Validation loss: 1.4766960605498283

Epoch: 6| Step: 11
Training loss: 0.07114982604980469
Validation loss: 1.4626092641584334

Epoch: 6| Step: 12
Training loss: 0.08062127977609634
Validation loss: 1.4488048066375077

Epoch: 6| Step: 13
Training loss: 0.17990587651729584
Validation loss: 1.4673147406629337

Epoch: 506| Step: 0
Training loss: 0.12130922079086304
Validation loss: 1.4772221003809283

Epoch: 6| Step: 1
Training loss: 0.11291349679231644
Validation loss: 1.4460644286165956

Epoch: 6| Step: 2
Training loss: 0.12864243984222412
Validation loss: 1.4724857448249735

Epoch: 6| Step: 3
Training loss: 0.08665399998426437
Validation loss: 1.4585730298872916

Epoch: 6| Step: 4
Training loss: 0.07621091604232788
Validation loss: 1.4803398886034567

Epoch: 6| Step: 5
Training loss: 0.12637750804424286
Validation loss: 1.4711428867873324

Epoch: 6| Step: 6
Training loss: 0.09835028648376465
Validation loss: 1.4608602402030781

Epoch: 6| Step: 7
Training loss: 0.09506765007972717
Validation loss: 1.4413355832458825

Epoch: 6| Step: 8
Training loss: 0.1074686050415039
Validation loss: 1.4538659523892146

Epoch: 6| Step: 9
Training loss: 0.07653599977493286
Validation loss: 1.4299439884001208

Epoch: 6| Step: 10
Training loss: 0.07700583338737488
Validation loss: 1.4591014962042532

Epoch: 6| Step: 11
Training loss: 0.07197573781013489
Validation loss: 1.467656776469241

Epoch: 6| Step: 12
Training loss: 0.11605022847652435
Validation loss: 1.491696753809529

Epoch: 6| Step: 13
Training loss: 0.06250273436307907
Validation loss: 1.449224151590819

Epoch: 507| Step: 0
Training loss: 0.10495615750551224
Validation loss: 1.486128382785346

Epoch: 6| Step: 1
Training loss: 0.09212207794189453
Validation loss: 1.4962199426466418

Epoch: 6| Step: 2
Training loss: 0.08004286885261536
Validation loss: 1.5014767339152675

Epoch: 6| Step: 3
Training loss: 0.091295525431633
Validation loss: 1.4963591278240245

Epoch: 6| Step: 4
Training loss: 0.10235973447561264
Validation loss: 1.4997616839665238

Epoch: 6| Step: 5
Training loss: 0.11538759618997574
Validation loss: 1.5101882488496843

Epoch: 6| Step: 6
Training loss: 0.0938354879617691
Validation loss: 1.5271889804511942

Epoch: 6| Step: 7
Training loss: 0.06266587972640991
Validation loss: 1.513207531744434

Epoch: 6| Step: 8
Training loss: 0.17084282636642456
Validation loss: 1.5044854097468878

Epoch: 6| Step: 9
Training loss: 0.09056977927684784
Validation loss: 1.5071827109142015

Epoch: 6| Step: 10
Training loss: 0.0800187885761261
Validation loss: 1.4775478737328642

Epoch: 6| Step: 11
Training loss: 0.14248040318489075
Validation loss: 1.4795062195870183

Epoch: 6| Step: 12
Training loss: 0.08344438672065735
Validation loss: 1.4875298546206566

Epoch: 6| Step: 13
Training loss: 0.07805225998163223
Validation loss: 1.4769514222298898

Epoch: 508| Step: 0
Training loss: 0.1138322651386261
Validation loss: 1.4855001152202647

Epoch: 6| Step: 1
Training loss: 0.10615205764770508
Validation loss: 1.5180840005156815

Epoch: 6| Step: 2
Training loss: 0.15729178488254547
Validation loss: 1.4913242465706282

Epoch: 6| Step: 3
Training loss: 0.12427094578742981
Validation loss: 1.5112849371407622

Epoch: 6| Step: 4
Training loss: 0.09460508823394775
Validation loss: 1.4809202724887478

Epoch: 6| Step: 5
Training loss: 0.07956618070602417
Validation loss: 1.4919701519832815

Epoch: 6| Step: 6
Training loss: 0.09715941548347473
Validation loss: 1.5246066085753902

Epoch: 6| Step: 7
Training loss: 0.09740976244211197
Validation loss: 1.5102771994888142

Epoch: 6| Step: 8
Training loss: 0.04388958215713501
Validation loss: 1.5059556730331913

Epoch: 6| Step: 9
Training loss: 0.0892820730805397
Validation loss: 1.5035138425006662

Epoch: 6| Step: 10
Training loss: 0.08696703612804413
Validation loss: 1.5244154609659666

Epoch: 6| Step: 11
Training loss: 0.11112765967845917
Validation loss: 1.5468574634162329

Epoch: 6| Step: 12
Training loss: 0.09658548980951309
Validation loss: 1.5375229543255222

Epoch: 6| Step: 13
Training loss: 0.08475475758314133
Validation loss: 1.5255454624852827

Epoch: 509| Step: 0
Training loss: 0.0807679072022438
Validation loss: 1.527872504726533

Epoch: 6| Step: 1
Training loss: 0.11319654434919357
Validation loss: 1.5249810821266585

Epoch: 6| Step: 2
Training loss: 0.101310595870018
Validation loss: 1.511906385421753

Epoch: 6| Step: 3
Training loss: 0.15789000689983368
Validation loss: 1.506158010933989

Epoch: 6| Step: 4
Training loss: 0.17592427134513855
Validation loss: 1.4856093609204857

Epoch: 6| Step: 5
Training loss: 0.08547043800354004
Validation loss: 1.4673046924734627

Epoch: 6| Step: 6
Training loss: 0.12343895435333252
Validation loss: 1.4628680995715562

Epoch: 6| Step: 7
Training loss: 0.08278308808803558
Validation loss: 1.4450148062039447

Epoch: 6| Step: 8
Training loss: 0.0784461498260498
Validation loss: 1.4835267977047992

Epoch: 6| Step: 9
Training loss: 0.0787915587425232
Validation loss: 1.4804787597348612

Epoch: 6| Step: 10
Training loss: 0.08548640459775925
Validation loss: 1.472520193746013

Epoch: 6| Step: 11
Training loss: 0.08616067469120026
Validation loss: 1.5011285081986459

Epoch: 6| Step: 12
Training loss: 0.10019981861114502
Validation loss: 1.5100587990976149

Epoch: 6| Step: 13
Training loss: 0.12101507186889648
Validation loss: 1.516874195427023

Epoch: 510| Step: 0
Training loss: 0.10975318402051926
Validation loss: 1.545512307074762

Epoch: 6| Step: 1
Training loss: 0.16897381842136383
Validation loss: 1.52562722211243

Epoch: 6| Step: 2
Training loss: 0.08275221288204193
Validation loss: 1.5491270006343882

Epoch: 6| Step: 3
Training loss: 0.09559385478496552
Validation loss: 1.5502467847639514

Epoch: 6| Step: 4
Training loss: 0.04541225731372833
Validation loss: 1.5379239923210555

Epoch: 6| Step: 5
Training loss: 0.07737796008586884
Validation loss: 1.517638203918293

Epoch: 6| Step: 6
Training loss: 0.09898018836975098
Validation loss: 1.5315752375510432

Epoch: 6| Step: 7
Training loss: 0.086602583527565
Validation loss: 1.5173701752898514

Epoch: 6| Step: 8
Training loss: 0.13195745646953583
Validation loss: 1.543706629865913

Epoch: 6| Step: 9
Training loss: 0.22587984800338745
Validation loss: 1.5154227441357029

Epoch: 6| Step: 10
Training loss: 0.11819063127040863
Validation loss: 1.5049343967950473

Epoch: 6| Step: 11
Training loss: 0.07058579474687576
Validation loss: 1.501159361613694

Epoch: 6| Step: 12
Training loss: 0.1086573600769043
Validation loss: 1.5145075449379541

Epoch: 6| Step: 13
Training loss: 0.07280883193016052
Validation loss: 1.4958292450956119

Epoch: 511| Step: 0
Training loss: 0.10510475933551788
Validation loss: 1.5043714290024133

Epoch: 6| Step: 1
Training loss: 0.10944127291440964
Validation loss: 1.515976022648555

Epoch: 6| Step: 2
Training loss: 0.1383194923400879
Validation loss: 1.5182004667097522

Epoch: 6| Step: 3
Training loss: 0.05416857451200485
Validation loss: 1.5238508793615526

Epoch: 6| Step: 4
Training loss: 0.06928496807813644
Validation loss: 1.519821088801148

Epoch: 6| Step: 5
Training loss: 0.1177729070186615
Validation loss: 1.5235256712923768

Epoch: 6| Step: 6
Training loss: 0.08289413154125214
Validation loss: 1.5169220701340707

Epoch: 6| Step: 7
Training loss: 0.08463463187217712
Validation loss: 1.515530204260221

Epoch: 6| Step: 8
Training loss: 0.08418934792280197
Validation loss: 1.549986739312449

Epoch: 6| Step: 9
Training loss: 0.0770634263753891
Validation loss: 1.5438113827859201

Epoch: 6| Step: 10
Training loss: 0.08740617334842682
Validation loss: 1.5383971455276653

Epoch: 6| Step: 11
Training loss: 0.059921927750110626
Validation loss: 1.5060063844086022

Epoch: 6| Step: 12
Training loss: 0.09794296324253082
Validation loss: 1.5241094891742994

Epoch: 6| Step: 13
Training loss: 0.09296951442956924
Validation loss: 1.50744826562943

Epoch: 512| Step: 0
Training loss: 0.07506678253412247
Validation loss: 1.5116806696820002

Epoch: 6| Step: 1
Training loss: 0.06341623514890671
Validation loss: 1.5054099713602374

Epoch: 6| Step: 2
Training loss: 0.06092740595340729
Validation loss: 1.4899366530038978

Epoch: 6| Step: 3
Training loss: 0.09160648286342621
Validation loss: 1.4537557376328336

Epoch: 6| Step: 4
Training loss: 0.071672722697258
Validation loss: 1.4541355512475456

Epoch: 6| Step: 5
Training loss: 0.1299036145210266
Validation loss: 1.4662464767374017

Epoch: 6| Step: 6
Training loss: 0.11378256976604462
Validation loss: 1.4700268904368083

Epoch: 6| Step: 7
Training loss: 0.09935642778873444
Validation loss: 1.465384328237144

Epoch: 6| Step: 8
Training loss: 0.08464366942644119
Validation loss: 1.4496795259496218

Epoch: 6| Step: 9
Training loss: 0.0868593156337738
Validation loss: 1.4405731872845722

Epoch: 6| Step: 10
Training loss: 0.08827340602874756
Validation loss: 1.4412819954656786

Epoch: 6| Step: 11
Training loss: 0.08982649445533752
Validation loss: 1.421839044940087

Epoch: 6| Step: 12
Training loss: 0.0846792683005333
Validation loss: 1.4220100461795766

Epoch: 6| Step: 13
Training loss: 0.07697226107120514
Validation loss: 1.4140284779251262

Epoch: 513| Step: 0
Training loss: 0.06409475207328796
Validation loss: 1.412144882704622

Epoch: 6| Step: 1
Training loss: 0.0738556832075119
Validation loss: 1.4100201142731534

Epoch: 6| Step: 2
Training loss: 0.09232621639966965
Validation loss: 1.3900144164280226

Epoch: 6| Step: 3
Training loss: 0.1375235617160797
Validation loss: 1.4372138182322185

Epoch: 6| Step: 4
Training loss: 0.12361379712820053
Validation loss: 1.418104403762407

Epoch: 6| Step: 5
Training loss: 0.15933895111083984
Validation loss: 1.4257598218097483

Epoch: 6| Step: 6
Training loss: 0.0769064798951149
Validation loss: 1.4484050735350578

Epoch: 6| Step: 7
Training loss: 0.05787970498204231
Validation loss: 1.4666411633132606

Epoch: 6| Step: 8
Training loss: 0.0857202410697937
Validation loss: 1.4841421765665854

Epoch: 6| Step: 9
Training loss: 0.07377558946609497
Validation loss: 1.4754335764915711

Epoch: 6| Step: 10
Training loss: 0.04776777699589729
Validation loss: 1.4647893213456677

Epoch: 6| Step: 11
Training loss: 0.0728873759508133
Validation loss: 1.4730100131803943

Epoch: 6| Step: 12
Training loss: 0.10960296541452408
Validation loss: 1.4578898927216888

Epoch: 6| Step: 13
Training loss: 0.08946993947029114
Validation loss: 1.4680045830306185

Epoch: 514| Step: 0
Training loss: 0.09634947776794434
Validation loss: 1.484834950457337

Epoch: 6| Step: 1
Training loss: 0.06702068448066711
Validation loss: 1.4609190340965026

Epoch: 6| Step: 2
Training loss: 0.07409273833036423
Validation loss: 1.4660108679084367

Epoch: 6| Step: 3
Training loss: 0.09140215814113617
Validation loss: 1.4671118653589679

Epoch: 6| Step: 4
Training loss: 0.07672526687383652
Validation loss: 1.4815856333701842

Epoch: 6| Step: 5
Training loss: 0.09413500130176544
Validation loss: 1.4810830559781802

Epoch: 6| Step: 6
Training loss: 0.08873961865901947
Validation loss: 1.4783410179999568

Epoch: 6| Step: 7
Training loss: 0.09939931333065033
Validation loss: 1.4795202503922165

Epoch: 6| Step: 8
Training loss: 0.06387956440448761
Validation loss: 1.4715466230146346

Epoch: 6| Step: 9
Training loss: 0.1008000522851944
Validation loss: 1.4689860574660762

Epoch: 6| Step: 10
Training loss: 0.096798837184906
Validation loss: 1.4928654483569566

Epoch: 6| Step: 11
Training loss: 0.05591179430484772
Validation loss: 1.4799610363539828

Epoch: 6| Step: 12
Training loss: 0.11468786001205444
Validation loss: 1.50612808299321

Epoch: 6| Step: 13
Training loss: 0.09312377870082855
Validation loss: 1.486819064745339

Epoch: 515| Step: 0
Training loss: 0.05265308916568756
Validation loss: 1.486217729506954

Epoch: 6| Step: 1
Training loss: 0.13362964987754822
Validation loss: 1.4798249531817693

Epoch: 6| Step: 2
Training loss: 0.06530037522315979
Validation loss: 1.490443132256949

Epoch: 6| Step: 3
Training loss: 0.06686918437480927
Validation loss: 1.50036850988224

Epoch: 6| Step: 4
Training loss: 0.08358143270015717
Validation loss: 1.4872501242545344

Epoch: 6| Step: 5
Training loss: 0.06317158788442612
Validation loss: 1.4771784966991794

Epoch: 6| Step: 6
Training loss: 0.04266712814569473
Validation loss: 1.4858220290112238

Epoch: 6| Step: 7
Training loss: 0.12353192269802094
Validation loss: 1.4666435526263328

Epoch: 6| Step: 8
Training loss: 0.0928243100643158
Validation loss: 1.4508880222997358

Epoch: 6| Step: 9
Training loss: 0.0934998095035553
Validation loss: 1.4356170328714515

Epoch: 6| Step: 10
Training loss: 0.11392819881439209
Validation loss: 1.455261565023853

Epoch: 6| Step: 11
Training loss: 0.0967622622847557
Validation loss: 1.4761381200564805

Epoch: 6| Step: 12
Training loss: 0.09579641371965408
Validation loss: 1.4635854690305647

Epoch: 6| Step: 13
Training loss: 0.07829585671424866
Validation loss: 1.4766991702459191

Epoch: 516| Step: 0
Training loss: 0.1277448982000351
Validation loss: 1.4638915959224905

Epoch: 6| Step: 1
Training loss: 0.09286204725503922
Validation loss: 1.4704662292234358

Epoch: 6| Step: 2
Training loss: 0.08141651749610901
Validation loss: 1.4883498107233355

Epoch: 6| Step: 3
Training loss: 0.07317657023668289
Validation loss: 1.4879259524806854

Epoch: 6| Step: 4
Training loss: 0.09249803423881531
Validation loss: 1.5144134926539596

Epoch: 6| Step: 5
Training loss: 0.10537295788526535
Validation loss: 1.503313632421596

Epoch: 6| Step: 6
Training loss: 0.09294451773166656
Validation loss: 1.4794159896912114

Epoch: 6| Step: 7
Training loss: 0.06934808194637299
Validation loss: 1.4712303607694563

Epoch: 6| Step: 8
Training loss: 0.09545552730560303
Validation loss: 1.45766265930668

Epoch: 6| Step: 9
Training loss: 0.0717768743634224
Validation loss: 1.4628469610726962

Epoch: 6| Step: 10
Training loss: 0.07703989744186401
Validation loss: 1.492456502811883

Epoch: 6| Step: 11
Training loss: 0.07058772444725037
Validation loss: 1.486940691548009

Epoch: 6| Step: 12
Training loss: 0.07463857531547546
Validation loss: 1.4617612477271789

Epoch: 6| Step: 13
Training loss: 0.04659648612141609
Validation loss: 1.4810334860637624

Epoch: 517| Step: 0
Training loss: 0.06481441855430603
Validation loss: 1.48424361085379

Epoch: 6| Step: 1
Training loss: 0.047140948474407196
Validation loss: 1.493062912776906

Epoch: 6| Step: 2
Training loss: 0.05916554480791092
Validation loss: 1.5029252126652708

Epoch: 6| Step: 3
Training loss: 0.07199889421463013
Validation loss: 1.4873270065553728

Epoch: 6| Step: 4
Training loss: 0.0884813666343689
Validation loss: 1.4904367975009385

Epoch: 6| Step: 5
Training loss: 0.05632650479674339
Validation loss: 1.5009835150934034

Epoch: 6| Step: 6
Training loss: 0.06365297734737396
Validation loss: 1.5228788339963524

Epoch: 6| Step: 7
Training loss: 0.0783425122499466
Validation loss: 1.5089005603585193

Epoch: 6| Step: 8
Training loss: 0.08311273157596588
Validation loss: 1.5146335260842436

Epoch: 6| Step: 9
Training loss: 0.06698943674564362
Validation loss: 1.507052367733371

Epoch: 6| Step: 10
Training loss: 0.060322877019643784
Validation loss: 1.4910568767978298

Epoch: 6| Step: 11
Training loss: 0.08765941113233566
Validation loss: 1.4656155019678094

Epoch: 6| Step: 12
Training loss: 0.03420340269804001
Validation loss: 1.47374778280976

Epoch: 6| Step: 13
Training loss: 0.04268604516983032
Validation loss: 1.4782722098852998

Epoch: 518| Step: 0
Training loss: 0.039656862616539
Validation loss: 1.4734253242451658

Epoch: 6| Step: 1
Training loss: 0.06457862257957458
Validation loss: 1.4513424417024017

Epoch: 6| Step: 2
Training loss: 0.09414001554250717
Validation loss: 1.451363923729107

Epoch: 6| Step: 3
Training loss: 0.08306145668029785
Validation loss: 1.4496676178388699

Epoch: 6| Step: 4
Training loss: 0.07911835610866547
Validation loss: 1.4763931446177985

Epoch: 6| Step: 5
Training loss: 0.04879172518849373
Validation loss: 1.476132377501457

Epoch: 6| Step: 6
Training loss: 0.10523070394992828
Validation loss: 1.4417114808995237

Epoch: 6| Step: 7
Training loss: 0.06228529289364815
Validation loss: 1.4923112956426476

Epoch: 6| Step: 8
Training loss: 0.08326243609189987
Validation loss: 1.4768740310463855

Epoch: 6| Step: 9
Training loss: 0.09306120127439499
Validation loss: 1.51568236402286

Epoch: 6| Step: 10
Training loss: 0.07363694906234741
Validation loss: 1.49391403249515

Epoch: 6| Step: 11
Training loss: 0.13075460493564606
Validation loss: 1.5172190435471073

Epoch: 6| Step: 12
Training loss: 0.06859369575977325
Validation loss: 1.4967308537934416

Epoch: 6| Step: 13
Training loss: 0.04289701208472252
Validation loss: 1.5174580171544065

Epoch: 519| Step: 0
Training loss: 0.05662616342306137
Validation loss: 1.511699805977524

Epoch: 6| Step: 1
Training loss: 0.10546770691871643
Validation loss: 1.5090763902151456

Epoch: 6| Step: 2
Training loss: 0.07275262475013733
Validation loss: 1.514409431847193

Epoch: 6| Step: 3
Training loss: 0.07712604105472565
Validation loss: 1.4967397259127708

Epoch: 6| Step: 4
Training loss: 0.10165386646986008
Validation loss: 1.5024803402603313

Epoch: 6| Step: 5
Training loss: 0.04947325587272644
Validation loss: 1.481979570081157

Epoch: 6| Step: 6
Training loss: 0.07992823421955109
Validation loss: 1.5089827109408636

Epoch: 6| Step: 7
Training loss: 0.07949353009462357
Validation loss: 1.503283691662614

Epoch: 6| Step: 8
Training loss: 0.06975864619016647
Validation loss: 1.4717079747107722

Epoch: 6| Step: 9
Training loss: 0.09639952331781387
Validation loss: 1.480262053910122

Epoch: 6| Step: 10
Training loss: 0.06405694037675858
Validation loss: 1.4738832808309985

Epoch: 6| Step: 11
Training loss: 0.06221383437514305
Validation loss: 1.4840345216053787

Epoch: 6| Step: 12
Training loss: 0.043062224984169006
Validation loss: 1.4771500287517425

Epoch: 6| Step: 13
Training loss: 0.07575835287570953
Validation loss: 1.4812433213315985

Epoch: 520| Step: 0
Training loss: 0.055454447865486145
Validation loss: 1.490025379324472

Epoch: 6| Step: 1
Training loss: 0.10138995945453644
Validation loss: 1.508985101535756

Epoch: 6| Step: 2
Training loss: 0.05270069092512131
Validation loss: 1.5177576259900165

Epoch: 6| Step: 3
Training loss: 0.08466921746730804
Validation loss: 1.507235284133624

Epoch: 6| Step: 4
Training loss: 0.07881256192922592
Validation loss: 1.5114170133426625

Epoch: 6| Step: 5
Training loss: 0.07333974540233612
Validation loss: 1.5268377514295681

Epoch: 6| Step: 6
Training loss: 0.10482847690582275
Validation loss: 1.50407814082279

Epoch: 6| Step: 7
Training loss: 0.09262913465499878
Validation loss: 1.5183676904247654

Epoch: 6| Step: 8
Training loss: 0.05454837158322334
Validation loss: 1.5002611567897182

Epoch: 6| Step: 9
Training loss: 0.07075915485620499
Validation loss: 1.5028146159264348

Epoch: 6| Step: 10
Training loss: 0.06028298661112785
Validation loss: 1.482547567736718

Epoch: 6| Step: 11
Training loss: 0.0673736184835434
Validation loss: 1.4654943366204538

Epoch: 6| Step: 12
Training loss: 0.04347093403339386
Validation loss: 1.4327878618753085

Epoch: 6| Step: 13
Training loss: 0.10330846905708313
Validation loss: 1.4632034673485705

Epoch: 521| Step: 0
Training loss: 0.10648234933614731
Validation loss: 1.4704007512779647

Epoch: 6| Step: 1
Training loss: 0.10062634944915771
Validation loss: 1.4255451040883218

Epoch: 6| Step: 2
Training loss: 0.13319289684295654
Validation loss: 1.4457675026309105

Epoch: 6| Step: 3
Training loss: 0.07605341821908951
Validation loss: 1.453857442384125

Epoch: 6| Step: 4
Training loss: 0.0598161481320858
Validation loss: 1.4669737892766153

Epoch: 6| Step: 5
Training loss: 0.040377646684646606
Validation loss: 1.4592405903723933

Epoch: 6| Step: 6
Training loss: 0.06730754673480988
Validation loss: 1.4533791708689865

Epoch: 6| Step: 7
Training loss: 0.06707770377397537
Validation loss: 1.4600119770214122

Epoch: 6| Step: 8
Training loss: 0.1209922507405281
Validation loss: 1.4829774184893536

Epoch: 6| Step: 9
Training loss: 0.06526227295398712
Validation loss: 1.4568748743303361

Epoch: 6| Step: 10
Training loss: 0.09063704311847687
Validation loss: 1.4651065911016157

Epoch: 6| Step: 11
Training loss: 0.06487902998924255
Validation loss: 1.4689029570548766

Epoch: 6| Step: 12
Training loss: 0.08706238865852356
Validation loss: 1.472312154308442

Epoch: 6| Step: 13
Training loss: 0.06981278955936432
Validation loss: 1.4765007162606845

Epoch: 522| Step: 0
Training loss: 0.047007396817207336
Validation loss: 1.4739172484285088

Epoch: 6| Step: 1
Training loss: 0.06849808990955353
Validation loss: 1.4528728223616076

Epoch: 6| Step: 2
Training loss: 0.07503024488687515
Validation loss: 1.445513040788712

Epoch: 6| Step: 3
Training loss: 0.06928078830242157
Validation loss: 1.4594378727738575

Epoch: 6| Step: 4
Training loss: 0.05991867929697037
Validation loss: 1.4404857056115263

Epoch: 6| Step: 5
Training loss: 0.06522390246391296
Validation loss: 1.4423453013102214

Epoch: 6| Step: 6
Training loss: 0.06560531258583069
Validation loss: 1.4699420646954608

Epoch: 6| Step: 7
Training loss: 0.0633251816034317
Validation loss: 1.453363932589049

Epoch: 6| Step: 8
Training loss: 0.05588062107563019
Validation loss: 1.4183206994046447

Epoch: 6| Step: 9
Training loss: 0.13042116165161133
Validation loss: 1.421125131268655

Epoch: 6| Step: 10
Training loss: 0.06777170300483704
Validation loss: 1.4473678834976689

Epoch: 6| Step: 11
Training loss: 0.06337744742631912
Validation loss: 1.4295152054038098

Epoch: 6| Step: 12
Training loss: 0.08031366765499115
Validation loss: 1.4047997606697904

Epoch: 6| Step: 13
Training loss: 0.08638225495815277
Validation loss: 1.4218215910337304

Epoch: 523| Step: 0
Training loss: 0.10876570641994476
Validation loss: 1.4345920329452844

Epoch: 6| Step: 1
Training loss: 0.06570927798748016
Validation loss: 1.4433894964956469

Epoch: 6| Step: 2
Training loss: 0.03824012354016304
Validation loss: 1.4528947799436507

Epoch: 6| Step: 3
Training loss: 0.04692823067307472
Validation loss: 1.44955115549026

Epoch: 6| Step: 4
Training loss: 0.0914166197180748
Validation loss: 1.4672560922561153

Epoch: 6| Step: 5
Training loss: 0.06936442106962204
Validation loss: 1.458211160475208

Epoch: 6| Step: 6
Training loss: 0.0745907723903656
Validation loss: 1.4561187733886063

Epoch: 6| Step: 7
Training loss: 0.07573765516281128
Validation loss: 1.4473378607021865

Epoch: 6| Step: 8
Training loss: 0.07108604162931442
Validation loss: 1.47381131879745

Epoch: 6| Step: 9
Training loss: 0.08141227811574936
Validation loss: 1.430101861235916

Epoch: 6| Step: 10
Training loss: 0.06550979614257812
Validation loss: 1.437390371035504

Epoch: 6| Step: 11
Training loss: 0.07241778820753098
Validation loss: 1.4482787475791028

Epoch: 6| Step: 12
Training loss: 0.0766817256808281
Validation loss: 1.4420777161916096

Epoch: 6| Step: 13
Training loss: 0.029046110808849335
Validation loss: 1.4360890016760877

Epoch: 524| Step: 0
Training loss: 0.03516661375761032
Validation loss: 1.452374259630839

Epoch: 6| Step: 1
Training loss: 0.05283152312040329
Validation loss: 1.4629120557538924

Epoch: 6| Step: 2
Training loss: 0.1238337829709053
Validation loss: 1.4912579085237236

Epoch: 6| Step: 3
Training loss: 0.15218420326709747
Validation loss: 1.5092762516390892

Epoch: 6| Step: 4
Training loss: 0.10163801163434982
Validation loss: 1.5065994877969064

Epoch: 6| Step: 5
Training loss: 0.11310404539108276
Validation loss: 1.4463932693645518

Epoch: 6| Step: 6
Training loss: 0.10063828527927399
Validation loss: 1.513144858421818

Epoch: 6| Step: 7
Training loss: 0.09795945137739182
Validation loss: 1.4908312898810192

Epoch: 6| Step: 8
Training loss: 0.07812948524951935
Validation loss: 1.4510543641223703

Epoch: 6| Step: 9
Training loss: 0.05678242817521095
Validation loss: 1.4561301232666097

Epoch: 6| Step: 10
Training loss: 0.11495058238506317
Validation loss: 1.4696134066068998

Epoch: 6| Step: 11
Training loss: 0.09160701930522919
Validation loss: 1.4624659643378308

Epoch: 6| Step: 12
Training loss: 0.06081956997513771
Validation loss: 1.4394733931428643

Epoch: 6| Step: 13
Training loss: 0.07253172993659973
Validation loss: 1.433862268283803

Epoch: 525| Step: 0
Training loss: 0.11021183431148529
Validation loss: 1.4289183385910527

Epoch: 6| Step: 1
Training loss: 0.05170949921011925
Validation loss: 1.4371982364244358

Epoch: 6| Step: 2
Training loss: 0.10082274675369263
Validation loss: 1.4268762783337665

Epoch: 6| Step: 3
Training loss: 0.08360541611909866
Validation loss: 1.4189938409354097

Epoch: 6| Step: 4
Training loss: 0.052009522914886475
Validation loss: 1.4432760771884714

Epoch: 6| Step: 5
Training loss: 0.08442632853984833
Validation loss: 1.419460601063185

Epoch: 6| Step: 6
Training loss: 0.058154720813035965
Validation loss: 1.4216670823353592

Epoch: 6| Step: 7
Training loss: 0.11387767642736435
Validation loss: 1.4027625591524187

Epoch: 6| Step: 8
Training loss: 0.07893573492765427
Validation loss: 1.4191801458276727

Epoch: 6| Step: 9
Training loss: 0.11642305552959442
Validation loss: 1.4404590206761514

Epoch: 6| Step: 10
Training loss: 0.04124952852725983
Validation loss: 1.444677169604968

Epoch: 6| Step: 11
Training loss: 0.07103501260280609
Validation loss: 1.425591416256402

Epoch: 6| Step: 12
Training loss: 0.06513810157775879
Validation loss: 1.4325560741527106

Epoch: 6| Step: 13
Training loss: 0.08997374027967453
Validation loss: 1.4244002789579413

Epoch: 526| Step: 0
Training loss: 0.10410823673009872
Validation loss: 1.440897076360641

Epoch: 6| Step: 1
Training loss: 0.07708805799484253
Validation loss: 1.4472613552565217

Epoch: 6| Step: 2
Training loss: 0.05904744192957878
Validation loss: 1.4378000395272368

Epoch: 6| Step: 3
Training loss: 0.088838592171669
Validation loss: 1.4302791023767123

Epoch: 6| Step: 4
Training loss: 0.07579000294208527
Validation loss: 1.441301498361813

Epoch: 6| Step: 5
Training loss: 0.06784848123788834
Validation loss: 1.4574549069968603

Epoch: 6| Step: 6
Training loss: 0.051966022700071335
Validation loss: 1.4431593943667669

Epoch: 6| Step: 7
Training loss: 0.057260192930698395
Validation loss: 1.4623468319574993

Epoch: 6| Step: 8
Training loss: 0.057343851774930954
Validation loss: 1.4689320697579333

Epoch: 6| Step: 9
Training loss: 0.07460525631904602
Validation loss: 1.4627489953912713

Epoch: 6| Step: 10
Training loss: 0.09462150931358337
Validation loss: 1.4769869530072777

Epoch: 6| Step: 11
Training loss: 0.07947145402431488
Validation loss: 1.479279862937107

Epoch: 6| Step: 12
Training loss: 0.06636376678943634
Validation loss: 1.4698712543774677

Epoch: 6| Step: 13
Training loss: 0.04026222229003906
Validation loss: 1.4479935502493253

Epoch: 527| Step: 0
Training loss: 0.07384902983903885
Validation loss: 1.4776530996445687

Epoch: 6| Step: 1
Training loss: 0.09962866455316544
Validation loss: 1.4492341337665435

Epoch: 6| Step: 2
Training loss: 0.039988964796066284
Validation loss: 1.4099253236606557

Epoch: 6| Step: 3
Training loss: 0.09384188801050186
Validation loss: 1.4380528644848896

Epoch: 6| Step: 4
Training loss: 0.04949694871902466
Validation loss: 1.4572526178052347

Epoch: 6| Step: 5
Training loss: 0.0965978279709816
Validation loss: 1.4195511956368723

Epoch: 6| Step: 6
Training loss: 0.06508376449346542
Validation loss: 1.4347313962956911

Epoch: 6| Step: 7
Training loss: 0.05847432464361191
Validation loss: 1.4168315138868106

Epoch: 6| Step: 8
Training loss: 0.07161622494459152
Validation loss: 1.4347608140719834

Epoch: 6| Step: 9
Training loss: 0.09337086975574493
Validation loss: 1.4380623012460687

Epoch: 6| Step: 10
Training loss: 0.06486690044403076
Validation loss: 1.434145301900884

Epoch: 6| Step: 11
Training loss: 0.053540945053100586
Validation loss: 1.4306860123911211

Epoch: 6| Step: 12
Training loss: 0.0399542897939682
Validation loss: 1.4500587204451203

Epoch: 6| Step: 13
Training loss: 0.10554133355617523
Validation loss: 1.4487751478789954

Epoch: 528| Step: 0
Training loss: 0.1067977249622345
Validation loss: 1.4439705187274563

Epoch: 6| Step: 1
Training loss: 0.07497699558734894
Validation loss: 1.433170069930374

Epoch: 6| Step: 2
Training loss: 0.10069525241851807
Validation loss: 1.4477667090713338

Epoch: 6| Step: 3
Training loss: 0.0752473771572113
Validation loss: 1.4690550745174449

Epoch: 6| Step: 4
Training loss: 0.06210744008421898
Validation loss: 1.4415433970830773

Epoch: 6| Step: 5
Training loss: 0.07754236459732056
Validation loss: 1.4584172528277162

Epoch: 6| Step: 6
Training loss: 0.09111349284648895
Validation loss: 1.481649633376829

Epoch: 6| Step: 7
Training loss: 0.06039518862962723
Validation loss: 1.4621032079060872

Epoch: 6| Step: 8
Training loss: 0.09350572526454926
Validation loss: 1.4547304402115524

Epoch: 6| Step: 9
Training loss: 0.08991105854511261
Validation loss: 1.4563525363963137

Epoch: 6| Step: 10
Training loss: 0.09219276905059814
Validation loss: 1.4592183161807317

Epoch: 6| Step: 11
Training loss: 0.0551895871758461
Validation loss: 1.449904554633684

Epoch: 6| Step: 12
Training loss: 0.06989039480686188
Validation loss: 1.4509851522343133

Epoch: 6| Step: 13
Training loss: 0.059801120311021805
Validation loss: 1.4451899970731428

Epoch: 529| Step: 0
Training loss: 0.07388471812009811
Validation loss: 1.4701534035385295

Epoch: 6| Step: 1
Training loss: 0.07969896495342255
Validation loss: 1.4575476133695213

Epoch: 6| Step: 2
Training loss: 0.07157304883003235
Validation loss: 1.4480749766031902

Epoch: 6| Step: 3
Training loss: 0.07315048575401306
Validation loss: 1.4865607619285583

Epoch: 6| Step: 4
Training loss: 0.08406791090965271
Validation loss: 1.4824868671355709

Epoch: 6| Step: 5
Training loss: 0.061545826494693756
Validation loss: 1.4843795889167375

Epoch: 6| Step: 6
Training loss: 0.08033721148967743
Validation loss: 1.4860150852511007

Epoch: 6| Step: 7
Training loss: 0.11998028308153152
Validation loss: 1.5029852390289307

Epoch: 6| Step: 8
Training loss: 0.08622127771377563
Validation loss: 1.4816541979389806

Epoch: 6| Step: 9
Training loss: 0.06959334015846252
Validation loss: 1.4746427151464647

Epoch: 6| Step: 10
Training loss: 0.051401399075984955
Validation loss: 1.5001519719759624

Epoch: 6| Step: 11
Training loss: 0.04742409288883209
Validation loss: 1.4714579146395448

Epoch: 6| Step: 12
Training loss: 0.0847059041261673
Validation loss: 1.4825340586323892

Epoch: 6| Step: 13
Training loss: 0.08506517857313156
Validation loss: 1.4802830616633098

Epoch: 530| Step: 0
Training loss: 0.06066602095961571
Validation loss: 1.4979716706019577

Epoch: 6| Step: 1
Training loss: 0.06530971825122833
Validation loss: 1.4970230184575564

Epoch: 6| Step: 2
Training loss: 0.06694293022155762
Validation loss: 1.4554191481682561

Epoch: 6| Step: 3
Training loss: 0.0561605803668499
Validation loss: 1.4587413162313483

Epoch: 6| Step: 4
Training loss: 0.06109096109867096
Validation loss: 1.4702065631907473

Epoch: 6| Step: 5
Training loss: 0.09537733346223831
Validation loss: 1.4824006903556086

Epoch: 6| Step: 6
Training loss: 0.0770559310913086
Validation loss: 1.4827355774500037

Epoch: 6| Step: 7
Training loss: 0.07226360589265823
Validation loss: 1.453665514146128

Epoch: 6| Step: 8
Training loss: 0.06895853579044342
Validation loss: 1.457221387535013

Epoch: 6| Step: 9
Training loss: 0.1019841879606247
Validation loss: 1.467145558326475

Epoch: 6| Step: 10
Training loss: 0.11924152821302414
Validation loss: 1.4648943716479885

Epoch: 6| Step: 11
Training loss: 0.06315215677022934
Validation loss: 1.443667063149073

Epoch: 6| Step: 12
Training loss: 0.04556073993444443
Validation loss: 1.4559533102537996

Epoch: 6| Step: 13
Training loss: 0.054385408759117126
Validation loss: 1.4572076118120583

Epoch: 531| Step: 0
Training loss: 0.0622020959854126
Validation loss: 1.4378601376728346

Epoch: 6| Step: 1
Training loss: 0.06797772645950317
Validation loss: 1.4328795376644339

Epoch: 6| Step: 2
Training loss: 0.06726214289665222
Validation loss: 1.4418451798859464

Epoch: 6| Step: 3
Training loss: 0.059680625796318054
Validation loss: 1.4481895777486986

Epoch: 6| Step: 4
Training loss: 0.07406480610370636
Validation loss: 1.4258722906471581

Epoch: 6| Step: 5
Training loss: 0.06337092816829681
Validation loss: 1.438923103834993

Epoch: 6| Step: 6
Training loss: 0.12379017472267151
Validation loss: 1.4651948239213677

Epoch: 6| Step: 7
Training loss: 0.0828397125005722
Validation loss: 1.4484858692333262

Epoch: 6| Step: 8
Training loss: 0.03519001603126526
Validation loss: 1.4575638142965173

Epoch: 6| Step: 9
Training loss: 0.06605970859527588
Validation loss: 1.438228214940717

Epoch: 6| Step: 10
Training loss: 0.08337832987308502
Validation loss: 1.4479153053734892

Epoch: 6| Step: 11
Training loss: 0.05708257108926773
Validation loss: 1.457233464846047

Epoch: 6| Step: 12
Training loss: 0.0650748461484909
Validation loss: 1.4630437102369083

Epoch: 6| Step: 13
Training loss: 0.06141117587685585
Validation loss: 1.4507709062227638

Epoch: 532| Step: 0
Training loss: 0.08341503888368607
Validation loss: 1.4266858382891583

Epoch: 6| Step: 1
Training loss: 0.07804708182811737
Validation loss: 1.4174422769136326

Epoch: 6| Step: 2
Training loss: 0.0668884813785553
Validation loss: 1.4318502090310539

Epoch: 6| Step: 3
Training loss: 0.0762985348701477
Validation loss: 1.4262877100257463

Epoch: 6| Step: 4
Training loss: 0.09392593801021576
Validation loss: 1.4414875911128135

Epoch: 6| Step: 5
Training loss: 0.09985761344432831
Validation loss: 1.4356497820987497

Epoch: 6| Step: 6
Training loss: 0.08819511532783508
Validation loss: 1.4561980757662045

Epoch: 6| Step: 7
Training loss: 0.06413924694061279
Validation loss: 1.460408627986908

Epoch: 6| Step: 8
Training loss: 0.05327311158180237
Validation loss: 1.4485395525091438

Epoch: 6| Step: 9
Training loss: 0.061871059238910675
Validation loss: 1.458562966315977

Epoch: 6| Step: 10
Training loss: 0.052175916731357574
Validation loss: 1.4564050474474508

Epoch: 6| Step: 11
Training loss: 0.09008154273033142
Validation loss: 1.4604093887472664

Epoch: 6| Step: 12
Training loss: 0.08455047756433487
Validation loss: 1.4826718235528598

Epoch: 6| Step: 13
Training loss: 0.06570462882518768
Validation loss: 1.4460592039169804

Epoch: 533| Step: 0
Training loss: 0.06923627853393555
Validation loss: 1.4731605847676594

Epoch: 6| Step: 1
Training loss: 0.035248029977083206
Validation loss: 1.4620514492834769

Epoch: 6| Step: 2
Training loss: 0.08868864178657532
Validation loss: 1.482288161913554

Epoch: 6| Step: 3
Training loss: 0.09569697082042694
Validation loss: 1.4918069916386758

Epoch: 6| Step: 4
Training loss: 0.09718158841133118
Validation loss: 1.481092591439524

Epoch: 6| Step: 5
Training loss: 0.09412404894828796
Validation loss: 1.4646804614733624

Epoch: 6| Step: 6
Training loss: 0.043924883008003235
Validation loss: 1.4508244683665614

Epoch: 6| Step: 7
Training loss: 0.06962379068136215
Validation loss: 1.4427852040977889

Epoch: 6| Step: 8
Training loss: 0.1031283289194107
Validation loss: 1.430882247545386

Epoch: 6| Step: 9
Training loss: 0.053487200289964676
Validation loss: 1.4397784356148011

Epoch: 6| Step: 10
Training loss: 0.10601969063282013
Validation loss: 1.4438440004984539

Epoch: 6| Step: 11
Training loss: 0.07945141196250916
Validation loss: 1.4381929751365417

Epoch: 6| Step: 12
Training loss: 0.11690530925989151
Validation loss: 1.4257334893749607

Epoch: 6| Step: 13
Training loss: 0.12290734797716141
Validation loss: 1.442381344174826

Epoch: 534| Step: 0
Training loss: 0.06652748584747314
Validation loss: 1.4659296697185886

Epoch: 6| Step: 1
Training loss: 0.07396933436393738
Validation loss: 1.4924297717309767

Epoch: 6| Step: 2
Training loss: 0.04879917949438095
Validation loss: 1.4787098182144987

Epoch: 6| Step: 3
Training loss: 0.07855615764856339
Validation loss: 1.4688082536061604

Epoch: 6| Step: 4
Training loss: 0.0656469389796257
Validation loss: 1.4887818764614802

Epoch: 6| Step: 5
Training loss: 0.05543975532054901
Validation loss: 1.477845517537927

Epoch: 6| Step: 6
Training loss: 0.11247723549604416
Validation loss: 1.4753744102293445

Epoch: 6| Step: 7
Training loss: 0.09514780342578888
Validation loss: 1.4967509764496998

Epoch: 6| Step: 8
Training loss: 0.07072006165981293
Validation loss: 1.505526625981895

Epoch: 6| Step: 9
Training loss: 0.0852942168712616
Validation loss: 1.523110753746443

Epoch: 6| Step: 10
Training loss: 0.11832107603549957
Validation loss: 1.4982664790204776

Epoch: 6| Step: 11
Training loss: 0.0842541754245758
Validation loss: 1.4812503886479202

Epoch: 6| Step: 12
Training loss: 0.13891586661338806
Validation loss: 1.5193305618019515

Epoch: 6| Step: 13
Training loss: 0.08076508343219757
Validation loss: 1.4847317972490865

Epoch: 535| Step: 0
Training loss: 0.050966039299964905
Validation loss: 1.4691578470250612

Epoch: 6| Step: 1
Training loss: 0.07594307512044907
Validation loss: 1.4496954384670462

Epoch: 6| Step: 2
Training loss: 0.07322338223457336
Validation loss: 1.464759272913779

Epoch: 6| Step: 3
Training loss: 0.06575413048267365
Validation loss: 1.459061227818971

Epoch: 6| Step: 4
Training loss: 0.060554005205631256
Validation loss: 1.4607991377512615

Epoch: 6| Step: 5
Training loss: 0.09584644436836243
Validation loss: 1.4616090469462897

Epoch: 6| Step: 6
Training loss: 0.04407137632369995
Validation loss: 1.473781075528873

Epoch: 6| Step: 7
Training loss: 0.1121257096529007
Validation loss: 1.45366447330803

Epoch: 6| Step: 8
Training loss: 0.09289839118719101
Validation loss: 1.4938925094501947

Epoch: 6| Step: 9
Training loss: 0.14085502922534943
Validation loss: 1.48340440821904

Epoch: 6| Step: 10
Training loss: 0.11014536768198013
Validation loss: 1.4784829257636942

Epoch: 6| Step: 11
Training loss: 0.037521395832300186
Validation loss: 1.4830736178223805

Epoch: 6| Step: 12
Training loss: 0.08533976227045059
Validation loss: 1.4677425456303421

Epoch: 6| Step: 13
Training loss: 0.09434095770120621
Validation loss: 1.4544032440390637

Epoch: 536| Step: 0
Training loss: 0.08192382752895355
Validation loss: 1.465248300183204

Epoch: 6| Step: 1
Training loss: 0.0846407487988472
Validation loss: 1.4597097878815026

Epoch: 6| Step: 2
Training loss: 0.10673624277114868
Validation loss: 1.4747694474394604

Epoch: 6| Step: 3
Training loss: 0.09962590038776398
Validation loss: 1.460733646987587

Epoch: 6| Step: 4
Training loss: 0.06550978869199753
Validation loss: 1.4560751427886307

Epoch: 6| Step: 5
Training loss: 0.09222369641065598
Validation loss: 1.473845443417949

Epoch: 6| Step: 6
Training loss: 0.06243596971035004
Validation loss: 1.4755897714245705

Epoch: 6| Step: 7
Training loss: 0.057771388441324234
Validation loss: 1.4663987159729004

Epoch: 6| Step: 8
Training loss: 0.07121545821428299
Validation loss: 1.4664644002914429

Epoch: 6| Step: 9
Training loss: 0.07708238065242767
Validation loss: 1.4764581662352367

Epoch: 6| Step: 10
Training loss: 0.09724773466587067
Validation loss: 1.4595706706405969

Epoch: 6| Step: 11
Training loss: 0.0914694294333458
Validation loss: 1.4676872568745767

Epoch: 6| Step: 12
Training loss: 0.07251157611608505
Validation loss: 1.442944420281277

Epoch: 6| Step: 13
Training loss: 0.06602317839860916
Validation loss: 1.4976906263700096

Epoch: 537| Step: 0
Training loss: 0.05073241889476776
Validation loss: 1.4873770565114997

Epoch: 6| Step: 1
Training loss: 0.0966792181134224
Validation loss: 1.4492805696302844

Epoch: 6| Step: 2
Training loss: 0.06509852409362793
Validation loss: 1.493726759828547

Epoch: 6| Step: 3
Training loss: 0.06152406334877014
Validation loss: 1.485549146129239

Epoch: 6| Step: 4
Training loss: 0.0573953352868557
Validation loss: 1.4511664016272432

Epoch: 6| Step: 5
Training loss: 0.08271137624979019
Validation loss: 1.4577177211802492

Epoch: 6| Step: 6
Training loss: 0.042148053646087646
Validation loss: 1.4852440882754583

Epoch: 6| Step: 7
Training loss: 0.13916310667991638
Validation loss: 1.4767892488869288

Epoch: 6| Step: 8
Training loss: 0.04121449962258339
Validation loss: 1.4536410788054108

Epoch: 6| Step: 9
Training loss: 0.0809895396232605
Validation loss: 1.4445822700377433

Epoch: 6| Step: 10
Training loss: 0.10199553519487381
Validation loss: 1.48496292227058

Epoch: 6| Step: 11
Training loss: 0.10160636901855469
Validation loss: 1.4578379097805227

Epoch: 6| Step: 12
Training loss: 0.08171355724334717
Validation loss: 1.4909892928215764

Epoch: 6| Step: 13
Training loss: 0.08886177837848663
Validation loss: 1.4717186849604371

Epoch: 538| Step: 0
Training loss: 0.10025963932275772
Validation loss: 1.4673439584752566

Epoch: 6| Step: 1
Training loss: 0.11138487607240677
Validation loss: 1.4617507547460578

Epoch: 6| Step: 2
Training loss: 0.08993595093488693
Validation loss: 1.4307242875458093

Epoch: 6| Step: 3
Training loss: 0.06754235923290253
Validation loss: 1.4454214265269618

Epoch: 6| Step: 4
Training loss: 0.1103563904762268
Validation loss: 1.42206141384699

Epoch: 6| Step: 5
Training loss: 0.09022529423236847
Validation loss: 1.437284872096072

Epoch: 6| Step: 6
Training loss: 0.04608815908432007
Validation loss: 1.437444439498327

Epoch: 6| Step: 7
Training loss: 0.08390708267688751
Validation loss: 1.4277814101147395

Epoch: 6| Step: 8
Training loss: 0.08690067380666733
Validation loss: 1.4314849075450693

Epoch: 6| Step: 9
Training loss: 0.08497188985347748
Validation loss: 1.4521328172376078

Epoch: 6| Step: 10
Training loss: 0.06788414716720581
Validation loss: 1.4326665952641477

Epoch: 6| Step: 11
Training loss: 0.07354487478733063
Validation loss: 1.4504271745681763

Epoch: 6| Step: 12
Training loss: 0.06288009136915207
Validation loss: 1.444021745394635

Epoch: 6| Step: 13
Training loss: 0.06316801905632019
Validation loss: 1.4606195508792836

Epoch: 539| Step: 0
Training loss: 0.09440267086029053
Validation loss: 1.465836819782052

Epoch: 6| Step: 1
Training loss: 0.08475462347269058
Validation loss: 1.4665787437910676

Epoch: 6| Step: 2
Training loss: 0.08625930547714233
Validation loss: 1.4676411151885986

Epoch: 6| Step: 3
Training loss: 0.15133851766586304
Validation loss: 1.4592507834075599

Epoch: 6| Step: 4
Training loss: 0.036874767392873764
Validation loss: 1.4759528854841828

Epoch: 6| Step: 5
Training loss: 0.09032385796308517
Validation loss: 1.480188290278117

Epoch: 6| Step: 6
Training loss: 0.036605529487133026
Validation loss: 1.4883521051817044

Epoch: 6| Step: 7
Training loss: 0.1595602035522461
Validation loss: 1.5297555192824333

Epoch: 6| Step: 8
Training loss: 0.11020737886428833
Validation loss: 1.5582442334903184

Epoch: 6| Step: 9
Training loss: 0.09793521463871002
Validation loss: 1.5449619318849297

Epoch: 6| Step: 10
Training loss: 0.09004244953393936
Validation loss: 1.5154658876439577

Epoch: 6| Step: 11
Training loss: 0.05751104652881622
Validation loss: 1.5181797858207458

Epoch: 6| Step: 12
Training loss: 0.08562938868999481
Validation loss: 1.4814170252892278

Epoch: 6| Step: 13
Training loss: 0.05570615828037262
Validation loss: 1.4767591837913758

Epoch: 540| Step: 0
Training loss: 0.08782120048999786
Validation loss: 1.467479480210171

Epoch: 6| Step: 1
Training loss: 0.06279988586902618
Validation loss: 1.479814826801259

Epoch: 6| Step: 2
Training loss: 0.058111049234867096
Validation loss: 1.483378698748927

Epoch: 6| Step: 3
Training loss: 0.09948737919330597
Validation loss: 1.477521420806967

Epoch: 6| Step: 4
Training loss: 0.0803477019071579
Validation loss: 1.4670309828173729

Epoch: 6| Step: 5
Training loss: 0.10181685537099838
Validation loss: 1.480732689621628

Epoch: 6| Step: 6
Training loss: 0.05256336182355881
Validation loss: 1.4487666596648514

Epoch: 6| Step: 7
Training loss: 0.05766841024160385
Validation loss: 1.464175260195168

Epoch: 6| Step: 8
Training loss: 0.12729807198047638
Validation loss: 1.4207226409707019

Epoch: 6| Step: 9
Training loss: 0.06423695385456085
Validation loss: 1.4394677300607004

Epoch: 6| Step: 10
Training loss: 0.07205325365066528
Validation loss: 1.4460205660071423

Epoch: 6| Step: 11
Training loss: 0.06628178060054779
Validation loss: 1.4249459607626802

Epoch: 6| Step: 12
Training loss: 0.06391383707523346
Validation loss: 1.4470365855001635

Epoch: 6| Step: 13
Training loss: 0.11575841903686523
Validation loss: 1.4417124896921136

Epoch: 541| Step: 0
Training loss: 0.06906084716320038
Validation loss: 1.4121224111126316

Epoch: 6| Step: 1
Training loss: 0.10792410373687744
Validation loss: 1.428294853497577

Epoch: 6| Step: 2
Training loss: 0.08599159121513367
Validation loss: 1.4688315878632248

Epoch: 6| Step: 3
Training loss: 0.13688597083091736
Validation loss: 1.4463120429746565

Epoch: 6| Step: 4
Training loss: 0.06516914814710617
Validation loss: 1.4645748715246878

Epoch: 6| Step: 5
Training loss: 0.05885691940784454
Validation loss: 1.4425485954489758

Epoch: 6| Step: 6
Training loss: 0.08799218386411667
Validation loss: 1.4494141686347224

Epoch: 6| Step: 7
Training loss: 0.051725804805755615
Validation loss: 1.442997920897699

Epoch: 6| Step: 8
Training loss: 0.05598251149058342
Validation loss: 1.4414187644117622

Epoch: 6| Step: 9
Training loss: 0.10334497690200806
Validation loss: 1.4572695282197767

Epoch: 6| Step: 10
Training loss: 0.06827013194561005
Validation loss: 1.4253448363273375

Epoch: 6| Step: 11
Training loss: 0.0606083981692791
Validation loss: 1.4298934193067654

Epoch: 6| Step: 12
Training loss: 0.06758884340524673
Validation loss: 1.4191808034014959

Epoch: 6| Step: 13
Training loss: 0.07941455394029617
Validation loss: 1.4473784764607747

Epoch: 542| Step: 0
Training loss: 0.05220396816730499
Validation loss: 1.4196209824213417

Epoch: 6| Step: 1
Training loss: 0.07839226722717285
Validation loss: 1.4375394236656927

Epoch: 6| Step: 2
Training loss: 0.08537471294403076
Validation loss: 1.4402613973104825

Epoch: 6| Step: 3
Training loss: 0.06872500479221344
Validation loss: 1.487637472409074

Epoch: 6| Step: 4
Training loss: 0.08506722003221512
Validation loss: 1.4675897385484429

Epoch: 6| Step: 5
Training loss: 0.11361493170261383
Validation loss: 1.4406708094381517

Epoch: 6| Step: 6
Training loss: 0.08733190596103668
Validation loss: 1.4647224359614874

Epoch: 6| Step: 7
Training loss: 0.08815999329090118
Validation loss: 1.4538966583949264

Epoch: 6| Step: 8
Training loss: 0.08023256063461304
Validation loss: 1.4258916224202802

Epoch: 6| Step: 9
Training loss: 0.10583582520484924
Validation loss: 1.4852540775011944

Epoch: 6| Step: 10
Training loss: 0.06645450741052628
Validation loss: 1.4797962455339329

Epoch: 6| Step: 11
Training loss: 0.07673036307096481
Validation loss: 1.458484847058532

Epoch: 6| Step: 12
Training loss: 0.0432356595993042
Validation loss: 1.4564332192943943

Epoch: 6| Step: 13
Training loss: 0.04999911040067673
Validation loss: 1.4502454086016583

Epoch: 543| Step: 0
Training loss: 0.07273325324058533
Validation loss: 1.4223149463694582

Epoch: 6| Step: 1
Training loss: 0.061010196805000305
Validation loss: 1.434185690777276

Epoch: 6| Step: 2
Training loss: 0.09634276479482651
Validation loss: 1.440002058141975

Epoch: 6| Step: 3
Training loss: 0.06008836627006531
Validation loss: 1.4490327860719414

Epoch: 6| Step: 4
Training loss: 0.062321737408638
Validation loss: 1.457725280074663

Epoch: 6| Step: 5
Training loss: 0.061667077243328094
Validation loss: 1.4201780108995334

Epoch: 6| Step: 6
Training loss: 0.08444844186306
Validation loss: 1.4419446209425568

Epoch: 6| Step: 7
Training loss: 0.076289102435112
Validation loss: 1.4219816910323275

Epoch: 6| Step: 8
Training loss: 0.09074606746435165
Validation loss: 1.4210669417535104

Epoch: 6| Step: 9
Training loss: 0.04044926539063454
Validation loss: 1.4351837109493952

Epoch: 6| Step: 10
Training loss: 0.05347416549921036
Validation loss: 1.4369361387786044

Epoch: 6| Step: 11
Training loss: 0.07084470242261887
Validation loss: 1.4158365880289385

Epoch: 6| Step: 12
Training loss: 0.06130814552307129
Validation loss: 1.4526698858507219

Epoch: 6| Step: 13
Training loss: 0.04273541644215584
Validation loss: 1.4386295336549

Epoch: 544| Step: 0
Training loss: 0.08396066725254059
Validation loss: 1.4397126500324537

Epoch: 6| Step: 1
Training loss: 0.07685807347297668
Validation loss: 1.4317155179157053

Epoch: 6| Step: 2
Training loss: 0.0788143202662468
Validation loss: 1.470090349515279

Epoch: 6| Step: 3
Training loss: 0.07221540808677673
Validation loss: 1.4802455927736016

Epoch: 6| Step: 4
Training loss: 0.0911397635936737
Validation loss: 1.4778657497898224

Epoch: 6| Step: 5
Training loss: 0.04302011430263519
Validation loss: 1.4753074440904843

Epoch: 6| Step: 6
Training loss: 0.06043616309762001
Validation loss: 1.4487581644006955

Epoch: 6| Step: 7
Training loss: 0.05467524379491806
Validation loss: 1.4604144096374512

Epoch: 6| Step: 8
Training loss: 0.05437389761209488
Validation loss: 1.4788351648597307

Epoch: 6| Step: 9
Training loss: 0.07127797603607178
Validation loss: 1.471558742625739

Epoch: 6| Step: 10
Training loss: 0.09196115285158157
Validation loss: 1.463464480574413

Epoch: 6| Step: 11
Training loss: 0.0684874877333641
Validation loss: 1.4608518180026804

Epoch: 6| Step: 12
Training loss: 0.06215042620897293
Validation loss: 1.473042340688808

Epoch: 6| Step: 13
Training loss: 0.03159394487738609
Validation loss: 1.4596081408121253

Epoch: 545| Step: 0
Training loss: 0.056704070419073105
Validation loss: 1.4716792779584085

Epoch: 6| Step: 1
Training loss: 0.0889773815870285
Validation loss: 1.4753931914606402

Epoch: 6| Step: 2
Training loss: 0.05326123908162117
Validation loss: 1.4701059543958275

Epoch: 6| Step: 3
Training loss: 0.04603119194507599
Validation loss: 1.4672433214802896

Epoch: 6| Step: 4
Training loss: 0.04871198162436485
Validation loss: 1.4723746283079988

Epoch: 6| Step: 5
Training loss: 0.09535454958677292
Validation loss: 1.4618586442803825

Epoch: 6| Step: 6
Training loss: 0.10883200168609619
Validation loss: 1.4532133058835102

Epoch: 6| Step: 7
Training loss: 0.10857069492340088
Validation loss: 1.412267558036312

Epoch: 6| Step: 8
Training loss: 0.05803145468235016
Validation loss: 1.4371334878347253

Epoch: 6| Step: 9
Training loss: 0.10541313886642456
Validation loss: 1.4270795378633725

Epoch: 6| Step: 10
Training loss: 0.09335698187351227
Validation loss: 1.4248292888364484

Epoch: 6| Step: 11
Training loss: 0.07603961229324341
Validation loss: 1.4423218606620707

Epoch: 6| Step: 12
Training loss: 0.06260731816291809
Validation loss: 1.4466657689822617

Epoch: 6| Step: 13
Training loss: 0.07352379709482193
Validation loss: 1.4612170054066567

Epoch: 546| Step: 0
Training loss: 0.028650423511862755
Validation loss: 1.4851459944120018

Epoch: 6| Step: 1
Training loss: 0.06531426310539246
Validation loss: 1.4770548087294384

Epoch: 6| Step: 2
Training loss: 0.10681267082691193
Validation loss: 1.4787788839750393

Epoch: 6| Step: 3
Training loss: 0.07292294502258301
Validation loss: 1.4943604212935253

Epoch: 6| Step: 4
Training loss: 0.04991573095321655
Validation loss: 1.5068254278552147

Epoch: 6| Step: 5
Training loss: 0.03728758543729782
Validation loss: 1.4780062642148746

Epoch: 6| Step: 6
Training loss: 0.05073380470275879
Validation loss: 1.4858392682126773

Epoch: 6| Step: 7
Training loss: 0.05374456197023392
Validation loss: 1.4739459663309076

Epoch: 6| Step: 8
Training loss: 0.05562476068735123
Validation loss: 1.4695738669364684

Epoch: 6| Step: 9
Training loss: 0.11102129518985748
Validation loss: 1.4620154788417201

Epoch: 6| Step: 10
Training loss: 0.08425670862197876
Validation loss: 1.4450719100172802

Epoch: 6| Step: 11
Training loss: 0.0613364577293396
Validation loss: 1.4599175863368536

Epoch: 6| Step: 12
Training loss: 0.10136274993419647
Validation loss: 1.454658228863952

Epoch: 6| Step: 13
Training loss: 0.08809161186218262
Validation loss: 1.4635242108375794

Epoch: 547| Step: 0
Training loss: 0.06287126243114471
Validation loss: 1.4670447008584135

Epoch: 6| Step: 1
Training loss: 0.06022100895643234
Validation loss: 1.4536411980147004

Epoch: 6| Step: 2
Training loss: 0.07396639138460159
Validation loss: 1.4876711599288448

Epoch: 6| Step: 3
Training loss: 0.056966204196214676
Validation loss: 1.4939820894631006

Epoch: 6| Step: 4
Training loss: 0.08370670676231384
Validation loss: 1.5083604294766662

Epoch: 6| Step: 5
Training loss: 0.06228083744645119
Validation loss: 1.5167045106169998

Epoch: 6| Step: 6
Training loss: 0.07863384485244751
Validation loss: 1.475235624979901

Epoch: 6| Step: 7
Training loss: 0.08369028568267822
Validation loss: 1.462657477266045

Epoch: 6| Step: 8
Training loss: 0.04457250237464905
Validation loss: 1.4939430734162689

Epoch: 6| Step: 9
Training loss: 0.12514089047908783
Validation loss: 1.4788860967082362

Epoch: 6| Step: 10
Training loss: 0.06576882302761078
Validation loss: 1.459208168009276

Epoch: 6| Step: 11
Training loss: 0.06698663532733917
Validation loss: 1.467976507320199

Epoch: 6| Step: 12
Training loss: 0.07016149908304214
Validation loss: 1.4951011493641844

Epoch: 6| Step: 13
Training loss: 0.05699978768825531
Validation loss: 1.493883611053549

Epoch: 548| Step: 0
Training loss: 0.08193005621433258
Validation loss: 1.5223754503393685

Epoch: 6| Step: 1
Training loss: 0.09830542653799057
Validation loss: 1.5135581980469406

Epoch: 6| Step: 2
Training loss: 0.08162690699100494
Validation loss: 1.4925087139170656

Epoch: 6| Step: 3
Training loss: 0.07579201459884644
Validation loss: 1.4907909618910922

Epoch: 6| Step: 4
Training loss: 0.0729648768901825
Validation loss: 1.465758531324325

Epoch: 6| Step: 5
Training loss: 0.03863988071680069
Validation loss: 1.4822758602839645

Epoch: 6| Step: 6
Training loss: 0.05175487697124481
Validation loss: 1.4760030290131927

Epoch: 6| Step: 7
Training loss: 0.08022265136241913
Validation loss: 1.4695477024201424

Epoch: 6| Step: 8
Training loss: 0.087840735912323
Validation loss: 1.4785867788458382

Epoch: 6| Step: 9
Training loss: 0.061850905418395996
Validation loss: 1.4732592874957668

Epoch: 6| Step: 10
Training loss: 0.10055476427078247
Validation loss: 1.4741444690253145

Epoch: 6| Step: 11
Training loss: 0.09730719029903412
Validation loss: 1.4554448691747521

Epoch: 6| Step: 12
Training loss: 0.04486636817455292
Validation loss: 1.4543337322050525

Epoch: 6| Step: 13
Training loss: 0.05748547613620758
Validation loss: 1.4687168021355905

Epoch: 549| Step: 0
Training loss: 0.06978927552700043
Validation loss: 1.4463420606428576

Epoch: 6| Step: 1
Training loss: 0.0884217768907547
Validation loss: 1.4504599468682402

Epoch: 6| Step: 2
Training loss: 0.07337609678506851
Validation loss: 1.4340710255407518

Epoch: 6| Step: 3
Training loss: 0.09541495889425278
Validation loss: 1.4605008427814772

Epoch: 6| Step: 4
Training loss: 0.07110395282506943
Validation loss: 1.4518773812119679

Epoch: 6| Step: 5
Training loss: 0.06295723468065262
Validation loss: 1.465180294488066

Epoch: 6| Step: 6
Training loss: 0.06465455144643784
Validation loss: 1.4847114086151123

Epoch: 6| Step: 7
Training loss: 0.0686931312084198
Validation loss: 1.4823120050532843

Epoch: 6| Step: 8
Training loss: 0.050954416394233704
Validation loss: 1.4790078901475476

Epoch: 6| Step: 9
Training loss: 0.09200194478034973
Validation loss: 1.4771268034494052

Epoch: 6| Step: 10
Training loss: 0.0590147003531456
Validation loss: 1.4816839489885556

Epoch: 6| Step: 11
Training loss: 0.07024918496608734
Validation loss: 1.4437569290079095

Epoch: 6| Step: 12
Training loss: 0.07635283470153809
Validation loss: 1.4601599503588933

Epoch: 6| Step: 13
Training loss: 0.06982780992984772
Validation loss: 1.4486410643464775

Epoch: 550| Step: 0
Training loss: 0.05821544677019119
Validation loss: 1.4793812433878581

Epoch: 6| Step: 1
Training loss: 0.08830821514129639
Validation loss: 1.453208722094054

Epoch: 6| Step: 2
Training loss: 0.0548999160528183
Validation loss: 1.452849582959247

Epoch: 6| Step: 3
Training loss: 0.10173480212688446
Validation loss: 1.481892051235322

Epoch: 6| Step: 4
Training loss: 0.12452434748411179
Validation loss: 1.4635959812389907

Epoch: 6| Step: 5
Training loss: 0.07106821238994598
Validation loss: 1.4852773169035554

Epoch: 6| Step: 6
Training loss: 0.09585542976856232
Validation loss: 1.4576669380229006

Epoch: 6| Step: 7
Training loss: 0.0595134012401104
Validation loss: 1.4430219422104538

Epoch: 6| Step: 8
Training loss: 0.07142096757888794
Validation loss: 1.480115363674779

Epoch: 6| Step: 9
Training loss: 0.07936348021030426
Validation loss: 1.4790615035641579

Epoch: 6| Step: 10
Training loss: 0.050101280212402344
Validation loss: 1.4573989991218812

Epoch: 6| Step: 11
Training loss: 0.06338533759117126
Validation loss: 1.4691445289119598

Epoch: 6| Step: 12
Training loss: 0.05483517050743103
Validation loss: 1.4663949205029396

Epoch: 6| Step: 13
Training loss: 0.07979762554168701
Validation loss: 1.4605743269766531

Epoch: 551| Step: 0
Training loss: 0.0780956894159317
Validation loss: 1.430051593370335

Epoch: 6| Step: 1
Training loss: 0.08371217548847198
Validation loss: 1.4447836888733732

Epoch: 6| Step: 2
Training loss: 0.051665082573890686
Validation loss: 1.446222892371557

Epoch: 6| Step: 3
Training loss: 0.04401138424873352
Validation loss: 1.4471501957985662

Epoch: 6| Step: 4
Training loss: 0.09338326007127762
Validation loss: 1.4552139812900173

Epoch: 6| Step: 5
Training loss: 0.06322731077671051
Validation loss: 1.4319756172036613

Epoch: 6| Step: 6
Training loss: 0.09061862528324127
Validation loss: 1.4514489263616583

Epoch: 6| Step: 7
Training loss: 0.04895967245101929
Validation loss: 1.4521027611147972

Epoch: 6| Step: 8
Training loss: 0.08598384261131287
Validation loss: 1.4583347587175266

Epoch: 6| Step: 9
Training loss: 0.09894822537899017
Validation loss: 1.4523862228598645

Epoch: 6| Step: 10
Training loss: 0.07113593071699142
Validation loss: 1.473202254182549

Epoch: 6| Step: 11
Training loss: 0.07649139314889908
Validation loss: 1.4673094198267946

Epoch: 6| Step: 12
Training loss: 0.07711297273635864
Validation loss: 1.4563652469265846

Epoch: 6| Step: 13
Training loss: 0.08186132460832596
Validation loss: 1.4519486593943771

Epoch: 552| Step: 0
Training loss: 0.046679459512233734
Validation loss: 1.4359483782963087

Epoch: 6| Step: 1
Training loss: 0.07462126016616821
Validation loss: 1.4558038173183319

Epoch: 6| Step: 2
Training loss: 0.0509236678481102
Validation loss: 1.4524529390437628

Epoch: 6| Step: 3
Training loss: 0.0867803543806076
Validation loss: 1.4790367644320253

Epoch: 6| Step: 4
Training loss: 0.08790723234415054
Validation loss: 1.448802016114676

Epoch: 6| Step: 5
Training loss: 0.0956469252705574
Validation loss: 1.4705168624078073

Epoch: 6| Step: 6
Training loss: 0.04686197265982628
Validation loss: 1.4846674383327525

Epoch: 6| Step: 7
Training loss: 0.0660850927233696
Validation loss: 1.4617668274910218

Epoch: 6| Step: 8
Training loss: 0.058841560035943985
Validation loss: 1.4623515804608662

Epoch: 6| Step: 9
Training loss: 0.08288855105638504
Validation loss: 1.4827442758826799

Epoch: 6| Step: 10
Training loss: 0.03698856383562088
Validation loss: 1.4554550186280282

Epoch: 6| Step: 11
Training loss: 0.062234312295913696
Validation loss: 1.4428304965778063

Epoch: 6| Step: 12
Training loss: 0.06747981905937195
Validation loss: 1.4775886586917344

Epoch: 6| Step: 13
Training loss: 0.03940052539110184
Validation loss: 1.4562540285048946

Epoch: 553| Step: 0
Training loss: 0.09005200117826462
Validation loss: 1.448253289345772

Epoch: 6| Step: 1
Training loss: 0.06507354229688644
Validation loss: 1.4721638874341083

Epoch: 6| Step: 2
Training loss: 0.059955939650535583
Validation loss: 1.4780544504042594

Epoch: 6| Step: 3
Training loss: 0.12426111102104187
Validation loss: 1.447398801003733

Epoch: 6| Step: 4
Training loss: 0.04004599153995514
Validation loss: 1.483791684591642

Epoch: 6| Step: 5
Training loss: 0.04108086973428726
Validation loss: 1.4732894923097344

Epoch: 6| Step: 6
Training loss: 0.07418861240148544
Validation loss: 1.4803407756231164

Epoch: 6| Step: 7
Training loss: 0.059152185916900635
Validation loss: 1.4715075903041388

Epoch: 6| Step: 8
Training loss: 0.06686700135469437
Validation loss: 1.4699410507755895

Epoch: 6| Step: 9
Training loss: 0.10162122547626495
Validation loss: 1.4455417369001655

Epoch: 6| Step: 10
Training loss: 0.06802555918693542
Validation loss: 1.4436392707209433

Epoch: 6| Step: 11
Training loss: 0.0804741382598877
Validation loss: 1.4235087927951608

Epoch: 6| Step: 12
Training loss: 0.06733778864145279
Validation loss: 1.4106595670023272

Epoch: 6| Step: 13
Training loss: 0.15379288792610168
Validation loss: 1.4389128537588223

Epoch: 554| Step: 0
Training loss: 0.10126817971467972
Validation loss: 1.4225673342263827

Epoch: 6| Step: 1
Training loss: 0.03867220878601074
Validation loss: 1.4536103945906445

Epoch: 6| Step: 2
Training loss: 0.07789915800094604
Validation loss: 1.4415254772350352

Epoch: 6| Step: 3
Training loss: 0.052777424454689026
Validation loss: 1.4611720179998746

Epoch: 6| Step: 4
Training loss: 0.05418911203742027
Validation loss: 1.4512323128279818

Epoch: 6| Step: 5
Training loss: 0.11107281595468521
Validation loss: 1.4862473818563646

Epoch: 6| Step: 6
Training loss: 0.07108040899038315
Validation loss: 1.4844674935904882

Epoch: 6| Step: 7
Training loss: 0.06918983906507492
Validation loss: 1.479566945824572

Epoch: 6| Step: 8
Training loss: 0.08561362326145172
Validation loss: 1.4555407672800043

Epoch: 6| Step: 9
Training loss: 0.043035462498664856
Validation loss: 1.4807291082156602

Epoch: 6| Step: 10
Training loss: 0.07766087353229523
Validation loss: 1.4657148456060758

Epoch: 6| Step: 11
Training loss: 0.0420098751783371
Validation loss: 1.448006941426185

Epoch: 6| Step: 12
Training loss: 0.07970568537712097
Validation loss: 1.4996858386583225

Epoch: 6| Step: 13
Training loss: 0.12853409349918365
Validation loss: 1.4750300043372697

Epoch: 555| Step: 0
Training loss: 0.06101103872060776
Validation loss: 1.4698256472105622

Epoch: 6| Step: 1
Training loss: 0.07740014791488647
Validation loss: 1.4945392147187264

Epoch: 6| Step: 2
Training loss: 0.04879417270421982
Validation loss: 1.4406391048944125

Epoch: 6| Step: 3
Training loss: 0.08234326541423798
Validation loss: 1.482147297551555

Epoch: 6| Step: 4
Training loss: 0.056907761842012405
Validation loss: 1.4671328388234621

Epoch: 6| Step: 5
Training loss: 0.12560433149337769
Validation loss: 1.4605351494204613

Epoch: 6| Step: 6
Training loss: 0.04401913657784462
Validation loss: 1.4322119867929848

Epoch: 6| Step: 7
Training loss: 0.05058588832616806
Validation loss: 1.453998561828367

Epoch: 6| Step: 8
Training loss: 0.0734136551618576
Validation loss: 1.4532847994117326

Epoch: 6| Step: 9
Training loss: 0.10393065959215164
Validation loss: 1.4486911783936203

Epoch: 6| Step: 10
Training loss: 0.08382286131381989
Validation loss: 1.4499130813024377

Epoch: 6| Step: 11
Training loss: 0.08460992574691772
Validation loss: 1.4169882253933979

Epoch: 6| Step: 12
Training loss: 0.06850296258926392
Validation loss: 1.4508884004367295

Epoch: 6| Step: 13
Training loss: 0.045123521238565445
Validation loss: 1.4629258609587146

Epoch: 556| Step: 0
Training loss: 0.08515309542417526
Validation loss: 1.4356926929566167

Epoch: 6| Step: 1
Training loss: 0.051245905458927155
Validation loss: 1.4485396710775231

Epoch: 6| Step: 2
Training loss: 0.04053681716322899
Validation loss: 1.4598044182664605

Epoch: 6| Step: 3
Training loss: 0.07525967061519623
Validation loss: 1.4728815209481023

Epoch: 6| Step: 4
Training loss: 0.034158073365688324
Validation loss: 1.4603440620565926

Epoch: 6| Step: 5
Training loss: 0.04912262409925461
Validation loss: 1.4713617781157136

Epoch: 6| Step: 6
Training loss: 0.0811324492096901
Validation loss: 1.4700232513489262

Epoch: 6| Step: 7
Training loss: 0.08874310553073883
Validation loss: 1.4607129571258382

Epoch: 6| Step: 8
Training loss: 0.06477470695972443
Validation loss: 1.4526606785353793

Epoch: 6| Step: 9
Training loss: 0.07442061603069305
Validation loss: 1.4397776229407198

Epoch: 6| Step: 10
Training loss: 0.047943856567144394
Validation loss: 1.4085859688379432

Epoch: 6| Step: 11
Training loss: 0.06597056984901428
Validation loss: 1.4124495008940339

Epoch: 6| Step: 12
Training loss: 0.04266064614057541
Validation loss: 1.4346688011641144

Epoch: 6| Step: 13
Training loss: 0.048174116760492325
Validation loss: 1.4396781882932108

Epoch: 557| Step: 0
Training loss: 0.040580131113529205
Validation loss: 1.4344431892518075

Epoch: 6| Step: 1
Training loss: 0.048843707889318466
Validation loss: 1.4236876810750654

Epoch: 6| Step: 2
Training loss: 0.06427562236785889
Validation loss: 1.4346851687277518

Epoch: 6| Step: 3
Training loss: 0.05531265214085579
Validation loss: 1.45653546497386

Epoch: 6| Step: 4
Training loss: 0.04141780734062195
Validation loss: 1.4361509071883334

Epoch: 6| Step: 5
Training loss: 0.08907154202461243
Validation loss: 1.4646219829077363

Epoch: 6| Step: 6
Training loss: 0.11522291600704193
Validation loss: 1.480127449958555

Epoch: 6| Step: 7
Training loss: 0.0829981341958046
Validation loss: 1.4689293522988596

Epoch: 6| Step: 8
Training loss: 0.0620059072971344
Validation loss: 1.4879924405005671

Epoch: 6| Step: 9
Training loss: 0.05844976007938385
Validation loss: 1.4868517460361603

Epoch: 6| Step: 10
Training loss: 0.08909464627504349
Validation loss: 1.4896104720331007

Epoch: 6| Step: 11
Training loss: 0.10327775031328201
Validation loss: 1.4903238306763351

Epoch: 6| Step: 12
Training loss: 0.06556590646505356
Validation loss: 1.4733867363263202

Epoch: 6| Step: 13
Training loss: 0.14868658781051636
Validation loss: 1.4608842019111878

Epoch: 558| Step: 0
Training loss: 0.0669320672750473
Validation loss: 1.4620639502361257

Epoch: 6| Step: 1
Training loss: 0.057446323335170746
Validation loss: 1.4472623960946196

Epoch: 6| Step: 2
Training loss: 0.062264636158943176
Validation loss: 1.449296247574591

Epoch: 6| Step: 3
Training loss: 0.07411004602909088
Validation loss: 1.4272482254171883

Epoch: 6| Step: 4
Training loss: 0.07502669095993042
Validation loss: 1.4498716708152526

Epoch: 6| Step: 5
Training loss: 0.08580442517995834
Validation loss: 1.4402692997327415

Epoch: 6| Step: 6
Training loss: 0.06911984086036682
Validation loss: 1.4684356694580407

Epoch: 6| Step: 7
Training loss: 0.07238642871379852
Validation loss: 1.4287373429985457

Epoch: 6| Step: 8
Training loss: 0.04851233959197998
Validation loss: 1.4403761330471243

Epoch: 6| Step: 9
Training loss: 0.11262088268995285
Validation loss: 1.4605741436763475

Epoch: 6| Step: 10
Training loss: 0.10333460569381714
Validation loss: 1.4603668284672562

Epoch: 6| Step: 11
Training loss: 0.04935349151492119
Validation loss: 1.4597837450683757

Epoch: 6| Step: 12
Training loss: 0.051862895488739014
Validation loss: 1.4782330784746396

Epoch: 6| Step: 13
Training loss: 0.06946921348571777
Validation loss: 1.4355945112884685

Epoch: 559| Step: 0
Training loss: 0.11044826358556747
Validation loss: 1.4384482265800558

Epoch: 6| Step: 1
Training loss: 0.06599193811416626
Validation loss: 1.4664243216155677

Epoch: 6| Step: 2
Training loss: 0.09532336890697479
Validation loss: 1.4531635404914938

Epoch: 6| Step: 3
Training loss: 0.06369753181934357
Validation loss: 1.4516253676465762

Epoch: 6| Step: 4
Training loss: 0.06923282146453857
Validation loss: 1.4782223688658847

Epoch: 6| Step: 5
Training loss: 0.042454179376363754
Validation loss: 1.465634298580949

Epoch: 6| Step: 6
Training loss: 0.0826772153377533
Validation loss: 1.4768608872608473

Epoch: 6| Step: 7
Training loss: 0.0814419761300087
Validation loss: 1.4665876268058695

Epoch: 6| Step: 8
Training loss: 0.06612794101238251
Validation loss: 1.5145734817750993

Epoch: 6| Step: 9
Training loss: 0.05661185830831528
Validation loss: 1.4963784179379862

Epoch: 6| Step: 10
Training loss: 0.0726199746131897
Validation loss: 1.5071961085001628

Epoch: 6| Step: 11
Training loss: 0.05949226766824722
Validation loss: 1.4860287533011487

Epoch: 6| Step: 12
Training loss: 0.05622167885303497
Validation loss: 1.4736415045235747

Epoch: 6| Step: 13
Training loss: 0.07153938710689545
Validation loss: 1.473591048230407

Epoch: 560| Step: 0
Training loss: 0.0682559460401535
Validation loss: 1.45480130821146

Epoch: 6| Step: 1
Training loss: 0.06490745395421982
Validation loss: 1.429961310919895

Epoch: 6| Step: 2
Training loss: 0.060184285044670105
Validation loss: 1.4142544167016142

Epoch: 6| Step: 3
Training loss: 0.09310632199048996
Validation loss: 1.4381690038147794

Epoch: 6| Step: 4
Training loss: 0.06444293260574341
Validation loss: 1.4218127887736085

Epoch: 6| Step: 5
Training loss: 0.08226269483566284
Validation loss: 1.4164814070988727

Epoch: 6| Step: 6
Training loss: 0.11608835309743881
Validation loss: 1.4342580995252054

Epoch: 6| Step: 7
Training loss: 0.054589737206697464
Validation loss: 1.4612500449662567

Epoch: 6| Step: 8
Training loss: 0.052109118551015854
Validation loss: 1.4362954240973278

Epoch: 6| Step: 9
Training loss: 0.050035782158374786
Validation loss: 1.4561564601877683

Epoch: 6| Step: 10
Training loss: 0.07656766474246979
Validation loss: 1.4632487784149826

Epoch: 6| Step: 11
Training loss: 0.07626552879810333
Validation loss: 1.4382079788433608

Epoch: 6| Step: 12
Training loss: 0.05883895605802536
Validation loss: 1.4902637812399095

Epoch: 6| Step: 13
Training loss: 0.05160105973482132
Validation loss: 1.480762436825742

Epoch: 561| Step: 0
Training loss: 0.05770488828420639
Validation loss: 1.4747895335638395

Epoch: 6| Step: 1
Training loss: 0.09458878636360168
Validation loss: 1.4911772563893309

Epoch: 6| Step: 2
Training loss: 0.05064006894826889
Validation loss: 1.4956651310766897

Epoch: 6| Step: 3
Training loss: 0.0720219761133194
Validation loss: 1.4843931698030042

Epoch: 6| Step: 4
Training loss: 0.053627368062734604
Validation loss: 1.488349114694903

Epoch: 6| Step: 5
Training loss: 0.06061580777168274
Validation loss: 1.4551663949925413

Epoch: 6| Step: 6
Training loss: 0.07707507163286209
Validation loss: 1.452863972674134

Epoch: 6| Step: 7
Training loss: 0.061124108731746674
Validation loss: 1.461623860943702

Epoch: 6| Step: 8
Training loss: 0.046174369752407074
Validation loss: 1.4408624838757258

Epoch: 6| Step: 9
Training loss: 0.054770998656749725
Validation loss: 1.4361906577182073

Epoch: 6| Step: 10
Training loss: 0.0867929458618164
Validation loss: 1.4622813040210354

Epoch: 6| Step: 11
Training loss: 0.11173807084560394
Validation loss: 1.4336077756779169

Epoch: 6| Step: 12
Training loss: 0.06924337148666382
Validation loss: 1.4316566144266436

Epoch: 6| Step: 13
Training loss: 0.05615214630961418
Validation loss: 1.4349833214154808

Epoch: 562| Step: 0
Training loss: 0.058973528444767
Validation loss: 1.4366888256483181

Epoch: 6| Step: 1
Training loss: 0.06202439218759537
Validation loss: 1.4220819165629726

Epoch: 6| Step: 2
Training loss: 0.06745080649852753
Validation loss: 1.43069629515371

Epoch: 6| Step: 3
Training loss: 0.0675356313586235
Validation loss: 1.4389952575006792

Epoch: 6| Step: 4
Training loss: 0.07667762041091919
Validation loss: 1.451692170994256

Epoch: 6| Step: 5
Training loss: 0.1169978678226471
Validation loss: 1.453164703102522

Epoch: 6| Step: 6
Training loss: 0.10860682278871536
Validation loss: 1.4563848036591724

Epoch: 6| Step: 7
Training loss: 0.060961123555898666
Validation loss: 1.4324800570805867

Epoch: 6| Step: 8
Training loss: 0.07428349554538727
Validation loss: 1.475106785374303

Epoch: 6| Step: 9
Training loss: 0.08179454505443573
Validation loss: 1.463964404598359

Epoch: 6| Step: 10
Training loss: 0.1464187055826187
Validation loss: 1.4886107015353378

Epoch: 6| Step: 11
Training loss: 0.053562700748443604
Validation loss: 1.4779954033513223

Epoch: 6| Step: 12
Training loss: 0.061006493866443634
Validation loss: 1.4870017113224152

Epoch: 6| Step: 13
Training loss: 0.08094464242458344
Validation loss: 1.4457324102360716

Epoch: 563| Step: 0
Training loss: 0.043331947177648544
Validation loss: 1.4424676138867614

Epoch: 6| Step: 1
Training loss: 0.0707278698682785
Validation loss: 1.4521936056434468

Epoch: 6| Step: 2
Training loss: 0.0634043961763382
Validation loss: 1.4248248223335511

Epoch: 6| Step: 3
Training loss: 0.042478617280721664
Validation loss: 1.4341143292765464

Epoch: 6| Step: 4
Training loss: 0.0652557983994484
Validation loss: 1.4232612553463186

Epoch: 6| Step: 5
Training loss: 0.09318356215953827
Validation loss: 1.4239934086799622

Epoch: 6| Step: 6
Training loss: 0.0675504133105278
Validation loss: 1.42350306177652

Epoch: 6| Step: 7
Training loss: 0.05817157030105591
Validation loss: 1.4151150359902331

Epoch: 6| Step: 8
Training loss: 0.08828100562095642
Validation loss: 1.4087673528220064

Epoch: 6| Step: 9
Training loss: 0.06970925629138947
Validation loss: 1.4105508250574912

Epoch: 6| Step: 10
Training loss: 0.11749644577503204
Validation loss: 1.436645515503422

Epoch: 6| Step: 11
Training loss: 0.08004890382289886
Validation loss: 1.4556337325803694

Epoch: 6| Step: 12
Training loss: 0.04125497490167618
Validation loss: 1.4487574010766961

Epoch: 6| Step: 13
Training loss: 0.04325272515416145
Validation loss: 1.4679941913133026

Epoch: 564| Step: 0
Training loss: 0.0612628310918808
Validation loss: 1.4445655038279872

Epoch: 6| Step: 1
Training loss: 0.10077115893363953
Validation loss: 1.4702952959204232

Epoch: 6| Step: 2
Training loss: 0.09289014339447021
Validation loss: 1.4448940369390673

Epoch: 6| Step: 3
Training loss: 0.058663509786129
Validation loss: 1.438169361442648

Epoch: 6| Step: 4
Training loss: 0.08109420537948608
Validation loss: 1.4382980664571126

Epoch: 6| Step: 5
Training loss: 0.053140297532081604
Validation loss: 1.4537466764450073

Epoch: 6| Step: 6
Training loss: 0.07919669151306152
Validation loss: 1.432646671930949

Epoch: 6| Step: 7
Training loss: 0.05727463960647583
Validation loss: 1.4201695675491004

Epoch: 6| Step: 8
Training loss: 0.045937757939100266
Validation loss: 1.3930456689608994

Epoch: 6| Step: 9
Training loss: 0.09776602685451508
Validation loss: 1.433723839380408

Epoch: 6| Step: 10
Training loss: 0.09047342836856842
Validation loss: 1.4012401501337688

Epoch: 6| Step: 11
Training loss: 0.07841764390468597
Validation loss: 1.4284886621659802

Epoch: 6| Step: 12
Training loss: 0.056936055421829224
Validation loss: 1.435903145420936

Epoch: 6| Step: 13
Training loss: 0.09065515547990799
Validation loss: 1.4264274874041158

Epoch: 565| Step: 0
Training loss: 0.10844612121582031
Validation loss: 1.4453188206559868

Epoch: 6| Step: 1
Training loss: 0.07905413955450058
Validation loss: 1.4255699496115408

Epoch: 6| Step: 2
Training loss: 0.07448428869247437
Validation loss: 1.4484210097661583

Epoch: 6| Step: 3
Training loss: 0.06501834094524384
Validation loss: 1.436902343585927

Epoch: 6| Step: 4
Training loss: 0.0614829957485199
Validation loss: 1.4291586517005839

Epoch: 6| Step: 5
Training loss: 0.09912393987178802
Validation loss: 1.4339612260941537

Epoch: 6| Step: 6
Training loss: 0.07536384463310242
Validation loss: 1.3957836166504891

Epoch: 6| Step: 7
Training loss: 0.0712742879986763
Validation loss: 1.4275425300803235

Epoch: 6| Step: 8
Training loss: 0.06720434129238129
Validation loss: 1.4527635407704178

Epoch: 6| Step: 9
Training loss: 0.059739887714385986
Validation loss: 1.4340609106966244

Epoch: 6| Step: 10
Training loss: 0.08594480156898499
Validation loss: 1.4378483872259817

Epoch: 6| Step: 11
Training loss: 0.12061402201652527
Validation loss: 1.464103328284397

Epoch: 6| Step: 12
Training loss: 0.05776187777519226
Validation loss: 1.4561315941554245

Epoch: 6| Step: 13
Training loss: 0.07525816559791565
Validation loss: 1.4522857255833124

Epoch: 566| Step: 0
Training loss: 0.09840722382068634
Validation loss: 1.4630030803782965

Epoch: 6| Step: 1
Training loss: 0.08660385757684708
Validation loss: 1.443235719075767

Epoch: 6| Step: 2
Training loss: 0.0638694167137146
Validation loss: 1.4400452260048158

Epoch: 6| Step: 3
Training loss: 0.0711587592959404
Validation loss: 1.461205796528888

Epoch: 6| Step: 4
Training loss: 0.06330516934394836
Validation loss: 1.4526658699076662

Epoch: 6| Step: 5
Training loss: 0.06104952469468117
Validation loss: 1.4414092212594964

Epoch: 6| Step: 6
Training loss: 0.07910631597042084
Validation loss: 1.4297955048981534

Epoch: 6| Step: 7
Training loss: 0.09069271385669708
Validation loss: 1.423150570161881

Epoch: 6| Step: 8
Training loss: 0.07844222337007523
Validation loss: 1.4180191140021048

Epoch: 6| Step: 9
Training loss: 0.046531565487384796
Validation loss: 1.4120590481706845

Epoch: 6| Step: 10
Training loss: 0.06517623364925385
Validation loss: 1.4372869729995728

Epoch: 6| Step: 11
Training loss: 0.05868084356188774
Validation loss: 1.4062977029431252

Epoch: 6| Step: 12
Training loss: 0.05294040963053703
Validation loss: 1.4194061563860985

Epoch: 6| Step: 13
Training loss: 0.06917797029018402
Validation loss: 1.4052128830263693

Epoch: 567| Step: 0
Training loss: 0.07102105021476746
Validation loss: 1.4188750251646964

Epoch: 6| Step: 1
Training loss: 0.09417153149843216
Validation loss: 1.4343276895502561

Epoch: 6| Step: 2
Training loss: 0.0753621906042099
Validation loss: 1.4493532911423714

Epoch: 6| Step: 3
Training loss: 0.05357209965586662
Validation loss: 1.4570892754421438

Epoch: 6| Step: 4
Training loss: 0.06581541895866394
Validation loss: 1.4600321913278231

Epoch: 6| Step: 5
Training loss: 0.04164864867925644
Validation loss: 1.4609184239500312

Epoch: 6| Step: 6
Training loss: 0.05668015778064728
Validation loss: 1.4635286972086916

Epoch: 6| Step: 7
Training loss: 0.06808328628540039
Validation loss: 1.4346169502504411

Epoch: 6| Step: 8
Training loss: 0.06517739593982697
Validation loss: 1.439374682723835

Epoch: 6| Step: 9
Training loss: 0.10362813621759415
Validation loss: 1.4345499841115807

Epoch: 6| Step: 10
Training loss: 0.07856307923793793
Validation loss: 1.4302040453880065

Epoch: 6| Step: 11
Training loss: 0.05053861439228058
Validation loss: 1.434563047142439

Epoch: 6| Step: 12
Training loss: 0.05164403095841408
Validation loss: 1.4696350892384846

Epoch: 6| Step: 13
Training loss: 0.06710807234048843
Validation loss: 1.43525307537407

Epoch: 568| Step: 0
Training loss: 0.04466285929083824
Validation loss: 1.43164945930563

Epoch: 6| Step: 1
Training loss: 0.06279738992452621
Validation loss: 1.4272077083587646

Epoch: 6| Step: 2
Training loss: 0.04478340595960617
Validation loss: 1.4556516870375602

Epoch: 6| Step: 3
Training loss: 0.052335433661937714
Validation loss: 1.4559921321048532

Epoch: 6| Step: 4
Training loss: 0.04687532037496567
Validation loss: 1.4436783175314627

Epoch: 6| Step: 5
Training loss: 0.05585358291864395
Validation loss: 1.4466693221881826

Epoch: 6| Step: 6
Training loss: 0.08498907089233398
Validation loss: 1.4531989071958809

Epoch: 6| Step: 7
Training loss: 0.05954571068286896
Validation loss: 1.4144375016612392

Epoch: 6| Step: 8
Training loss: 0.05543795973062515
Validation loss: 1.4675738914038545

Epoch: 6| Step: 9
Training loss: 0.07844442874193192
Validation loss: 1.4642090118059548

Epoch: 6| Step: 10
Training loss: 0.07076960057020187
Validation loss: 1.4908485963780393

Epoch: 6| Step: 11
Training loss: 0.056802768260240555
Validation loss: 1.4962202349016744

Epoch: 6| Step: 12
Training loss: 0.08571340143680573
Validation loss: 1.4927691669874295

Epoch: 6| Step: 13
Training loss: 0.08755943179130554
Validation loss: 1.504593518472487

Epoch: 569| Step: 0
Training loss: 0.05620940774679184
Validation loss: 1.5181845490650465

Epoch: 6| Step: 1
Training loss: 0.08114570379257202
Validation loss: 1.508812733875808

Epoch: 6| Step: 2
Training loss: 0.06008490175008774
Validation loss: 1.4971344470977783

Epoch: 6| Step: 3
Training loss: 0.055823374539613724
Validation loss: 1.4929918832676385

Epoch: 6| Step: 4
Training loss: 0.055397603660821915
Validation loss: 1.4891358690877115

Epoch: 6| Step: 5
Training loss: 0.06922414153814316
Validation loss: 1.4973066006937334

Epoch: 6| Step: 6
Training loss: 0.04434441402554512
Validation loss: 1.485913739409498

Epoch: 6| Step: 7
Training loss: 0.06413616240024567
Validation loss: 1.4879240464138728

Epoch: 6| Step: 8
Training loss: 0.09386104345321655
Validation loss: 1.4754379910807456

Epoch: 6| Step: 9
Training loss: 0.0551479309797287
Validation loss: 1.5025490765930505

Epoch: 6| Step: 10
Training loss: 0.09236748516559601
Validation loss: 1.476925411532002

Epoch: 6| Step: 11
Training loss: 0.06681055575609207
Validation loss: 1.4546427649836386

Epoch: 6| Step: 12
Training loss: 0.08552910387516022
Validation loss: 1.4812431719995314

Epoch: 6| Step: 13
Training loss: 0.030748525634407997
Validation loss: 1.4747930444696897

Epoch: 570| Step: 0
Training loss: 0.09070853888988495
Validation loss: 1.49113933245341

Epoch: 6| Step: 1
Training loss: 0.05611760914325714
Validation loss: 1.4846242916199468

Epoch: 6| Step: 2
Training loss: 0.06043185666203499
Validation loss: 1.4616165520042501

Epoch: 6| Step: 3
Training loss: 0.0622173473238945
Validation loss: 1.5087678611919444

Epoch: 6| Step: 4
Training loss: 0.06941891461610794
Validation loss: 1.4920043496675388

Epoch: 6| Step: 5
Training loss: 0.09718100726604462
Validation loss: 1.4954686293037989

Epoch: 6| Step: 6
Training loss: 0.06562884151935577
Validation loss: 1.4829480135312645

Epoch: 6| Step: 7
Training loss: 0.048447415232658386
Validation loss: 1.469281426040075

Epoch: 6| Step: 8
Training loss: 0.046755775809288025
Validation loss: 1.4511512902475172

Epoch: 6| Step: 9
Training loss: 0.04329492151737213
Validation loss: 1.4660403472121044

Epoch: 6| Step: 10
Training loss: 0.06337784230709076
Validation loss: 1.4879214827732374

Epoch: 6| Step: 11
Training loss: 0.10497426986694336
Validation loss: 1.4737668652688303

Epoch: 6| Step: 12
Training loss: 0.06695326417684555
Validation loss: 1.474118564718513

Epoch: 6| Step: 13
Training loss: 0.07810815423727036
Validation loss: 1.4817504703357656

Epoch: 571| Step: 0
Training loss: 0.05770514905452728
Validation loss: 1.4731962321906962

Epoch: 6| Step: 1
Training loss: 0.08126906305551529
Validation loss: 1.4196552909830564

Epoch: 6| Step: 2
Training loss: 0.057533301413059235
Validation loss: 1.4122759270411667

Epoch: 6| Step: 3
Training loss: 0.05411006882786751
Validation loss: 1.4255195638184905

Epoch: 6| Step: 4
Training loss: 0.0702778548002243
Validation loss: 1.457011947067835

Epoch: 6| Step: 5
Training loss: 0.07996756583452225
Validation loss: 1.4229978355028297

Epoch: 6| Step: 6
Training loss: 0.07158681750297546
Validation loss: 1.4406080156244256

Epoch: 6| Step: 7
Training loss: 0.05594842880964279
Validation loss: 1.4365858493312713

Epoch: 6| Step: 8
Training loss: 0.03753978759050369
Validation loss: 1.4159619705651396

Epoch: 6| Step: 9
Training loss: 0.050706807523965836
Validation loss: 1.4012357996356102

Epoch: 6| Step: 10
Training loss: 0.06668981164693832
Validation loss: 1.4192816454877135

Epoch: 6| Step: 11
Training loss: 0.05770518630743027
Validation loss: 1.4417222738265991

Epoch: 6| Step: 12
Training loss: 0.0820670798420906
Validation loss: 1.4231627256639543

Epoch: 6| Step: 13
Training loss: 0.06890310347080231
Validation loss: 1.4166018642405027

Epoch: 572| Step: 0
Training loss: 0.05013187602162361
Validation loss: 1.4298542097050657

Epoch: 6| Step: 1
Training loss: 0.04899751394987106
Validation loss: 1.4444284272450272

Epoch: 6| Step: 2
Training loss: 0.05355386435985565
Validation loss: 1.4420050421068746

Epoch: 6| Step: 3
Training loss: 0.048152290284633636
Validation loss: 1.428682191397554

Epoch: 6| Step: 4
Training loss: 0.058436766266822815
Validation loss: 1.425860389586418

Epoch: 6| Step: 5
Training loss: 0.07658896595239639
Validation loss: 1.4338304278671101

Epoch: 6| Step: 6
Training loss: 0.08184070885181427
Validation loss: 1.4380950645733905

Epoch: 6| Step: 7
Training loss: 0.02865990437567234
Validation loss: 1.4444931194346438

Epoch: 6| Step: 8
Training loss: 0.11394284665584564
Validation loss: 1.4673019545052641

Epoch: 6| Step: 9
Training loss: 0.06298171728849411
Validation loss: 1.4684902423171586

Epoch: 6| Step: 10
Training loss: 0.051863133907318115
Validation loss: 1.488735930894011

Epoch: 6| Step: 11
Training loss: 0.10204935818910599
Validation loss: 1.4879434800917102

Epoch: 6| Step: 12
Training loss: 0.054178059101104736
Validation loss: 1.4699628199300458

Epoch: 6| Step: 13
Training loss: 0.0464508943259716
Validation loss: 1.4715324499273812

Epoch: 573| Step: 0
Training loss: 0.0413963682949543
Validation loss: 1.4653707435054164

Epoch: 6| Step: 1
Training loss: 0.0598081536591053
Validation loss: 1.4734253485997517

Epoch: 6| Step: 2
Training loss: 0.0422680489718914
Validation loss: 1.4616204782198834

Epoch: 6| Step: 3
Training loss: 0.09220424294471741
Validation loss: 1.4595302997096893

Epoch: 6| Step: 4
Training loss: 0.043563131242990494
Validation loss: 1.4340402374985397

Epoch: 6| Step: 5
Training loss: 0.061643436551094055
Validation loss: 1.4391209181918894

Epoch: 6| Step: 6
Training loss: 0.047850482165813446
Validation loss: 1.4338438594213097

Epoch: 6| Step: 7
Training loss: 0.08189815282821655
Validation loss: 1.4084343294943533

Epoch: 6| Step: 8
Training loss: 0.0657455176115036
Validation loss: 1.4159915998417845

Epoch: 6| Step: 9
Training loss: 0.02900260128080845
Validation loss: 1.4272763024094284

Epoch: 6| Step: 10
Training loss: 0.08757095038890839
Validation loss: 1.3957722904861614

Epoch: 6| Step: 11
Training loss: 0.11264772713184357
Validation loss: 1.4304523480835782

Epoch: 6| Step: 12
Training loss: 0.05965232849121094
Validation loss: 1.4286799828211467

Epoch: 6| Step: 13
Training loss: 0.06997127085924149
Validation loss: 1.410108184301725

Epoch: 574| Step: 0
Training loss: 0.06951301544904709
Validation loss: 1.4075747305347073

Epoch: 6| Step: 1
Training loss: 0.047240544110536575
Validation loss: 1.4315192699432373

Epoch: 6| Step: 2
Training loss: 0.10763493180274963
Validation loss: 1.4379924381932905

Epoch: 6| Step: 3
Training loss: 0.07771821320056915
Validation loss: 1.4210723561625327

Epoch: 6| Step: 4
Training loss: 0.06063683331012726
Validation loss: 1.4281382727366623

Epoch: 6| Step: 5
Training loss: 0.053627412766218185
Validation loss: 1.4292592720318866

Epoch: 6| Step: 6
Training loss: 0.03611287474632263
Validation loss: 1.45816848867683

Epoch: 6| Step: 7
Training loss: 0.04626602679491043
Validation loss: 1.4459426197954404

Epoch: 6| Step: 8
Training loss: 0.0654250979423523
Validation loss: 1.4615255363525883

Epoch: 6| Step: 9
Training loss: 0.05491435527801514
Validation loss: 1.4631745520458426

Epoch: 6| Step: 10
Training loss: 0.07583846151828766
Validation loss: 1.442244557924168

Epoch: 6| Step: 11
Training loss: 0.07978292554616928
Validation loss: 1.438895534443599

Epoch: 6| Step: 12
Training loss: 0.10961183905601501
Validation loss: 1.4550737911655056

Epoch: 6| Step: 13
Training loss: 0.11924692988395691
Validation loss: 1.459205868423626

Epoch: 575| Step: 0
Training loss: 0.06953728944063187
Validation loss: 1.4459648157960625

Epoch: 6| Step: 1
Training loss: 0.05543486773967743
Validation loss: 1.4411765759991062

Epoch: 6| Step: 2
Training loss: 0.07206431776285172
Validation loss: 1.4560025084403254

Epoch: 6| Step: 3
Training loss: 0.05162249505519867
Validation loss: 1.455250560596425

Epoch: 6| Step: 4
Training loss: 0.06278392672538757
Validation loss: 1.4478828740376297

Epoch: 6| Step: 5
Training loss: 0.12195409089326859
Validation loss: 1.481386637815865

Epoch: 6| Step: 6
Training loss: 0.06920774281024933
Validation loss: 1.4526764968390107

Epoch: 6| Step: 7
Training loss: 0.06193465739488602
Validation loss: 1.4576413580166396

Epoch: 6| Step: 8
Training loss: 0.05129459872841835
Validation loss: 1.4473937185861732

Epoch: 6| Step: 9
Training loss: 0.07901720702648163
Validation loss: 1.4480500221252441

Epoch: 6| Step: 10
Training loss: 0.054995954036712646
Validation loss: 1.4592877831510318

Epoch: 6| Step: 11
Training loss: 0.03566895052790642
Validation loss: 1.4889754915750155

Epoch: 6| Step: 12
Training loss: 0.06301736831665039
Validation loss: 1.4565830781895628

Epoch: 6| Step: 13
Training loss: 0.05631469935178757
Validation loss: 1.4930800519963747

Epoch: 576| Step: 0
Training loss: 0.10497193038463593
Validation loss: 1.484699503068001

Epoch: 6| Step: 1
Training loss: 0.0771036446094513
Validation loss: 1.5154286905001568

Epoch: 6| Step: 2
Training loss: 0.05034838616847992
Validation loss: 1.4977815087123583

Epoch: 6| Step: 3
Training loss: 0.044444650411605835
Validation loss: 1.496573894254623

Epoch: 6| Step: 4
Training loss: 0.06296094506978989
Validation loss: 1.4823763883242043

Epoch: 6| Step: 5
Training loss: 0.06946800649166107
Validation loss: 1.4807589387380948

Epoch: 6| Step: 6
Training loss: 0.053075093775987625
Validation loss: 1.4826457115911669

Epoch: 6| Step: 7
Training loss: 0.07777576148509979
Validation loss: 1.4467801137637066

Epoch: 6| Step: 8
Training loss: 0.06419327110052109
Validation loss: 1.474447274720797

Epoch: 6| Step: 9
Training loss: 0.058258697390556335
Validation loss: 1.4718804846527755

Epoch: 6| Step: 10
Training loss: 0.058375272899866104
Validation loss: 1.4748999662296747

Epoch: 6| Step: 11
Training loss: 0.06903465837240219
Validation loss: 1.5007330243305494

Epoch: 6| Step: 12
Training loss: 0.06346876174211502
Validation loss: 1.491472198117164

Epoch: 6| Step: 13
Training loss: 0.09316280484199524
Validation loss: 1.47388461712868

Epoch: 577| Step: 0
Training loss: 0.08815542608499527
Validation loss: 1.5101073070238995

Epoch: 6| Step: 1
Training loss: 0.050117380917072296
Validation loss: 1.4474625356735722

Epoch: 6| Step: 2
Training loss: 0.05978493019938469
Validation loss: 1.4609374218089606

Epoch: 6| Step: 3
Training loss: 0.06822795420885086
Validation loss: 1.4595690837470434

Epoch: 6| Step: 4
Training loss: 0.037399180233478546
Validation loss: 1.4572298026853991

Epoch: 6| Step: 5
Training loss: 0.06430154293775558
Validation loss: 1.4591561389225784

Epoch: 6| Step: 6
Training loss: 0.08863844722509384
Validation loss: 1.4794598728097894

Epoch: 6| Step: 7
Training loss: 0.17465656995773315
Validation loss: 1.4778709860258206

Epoch: 6| Step: 8
Training loss: 0.10063651949167252
Validation loss: 1.4787526784404632

Epoch: 6| Step: 9
Training loss: 0.10618174076080322
Validation loss: 1.4471393926169283

Epoch: 6| Step: 10
Training loss: 0.06334597617387772
Validation loss: 1.4376120477594354

Epoch: 6| Step: 11
Training loss: 0.11334294080734253
Validation loss: 1.4184202712069276

Epoch: 6| Step: 12
Training loss: 0.0707065612077713
Validation loss: 1.4052683082959985

Epoch: 6| Step: 13
Training loss: 0.06501153856515884
Validation loss: 1.4297498503038961

Epoch: 578| Step: 0
Training loss: 0.04055599868297577
Validation loss: 1.4239874732109807

Epoch: 6| Step: 1
Training loss: 0.10777023434638977
Validation loss: 1.4428668150337793

Epoch: 6| Step: 2
Training loss: 0.0793890580534935
Validation loss: 1.4218025720247658

Epoch: 6| Step: 3
Training loss: 0.0655868649482727
Validation loss: 1.4097464969081264

Epoch: 6| Step: 4
Training loss: 0.05839573219418526
Validation loss: 1.4233303441796252

Epoch: 6| Step: 5
Training loss: 0.06003749370574951
Validation loss: 1.451062443435833

Epoch: 6| Step: 6
Training loss: 0.08862295746803284
Validation loss: 1.4640324275980714

Epoch: 6| Step: 7
Training loss: 0.09496872127056122
Validation loss: 1.4880852776189004

Epoch: 6| Step: 8
Training loss: 0.08669795095920563
Validation loss: 1.4630545300822104

Epoch: 6| Step: 9
Training loss: 0.06855146586894989
Validation loss: 1.5042130831749208

Epoch: 6| Step: 10
Training loss: 0.06808248907327652
Validation loss: 1.477452547960384

Epoch: 6| Step: 11
Training loss: 0.048889342695474625
Validation loss: 1.4718395317754438

Epoch: 6| Step: 12
Training loss: 0.04645319655537605
Validation loss: 1.4518637496937987

Epoch: 6| Step: 13
Training loss: 0.1019592136144638
Validation loss: 1.4649421547048835

Epoch: 579| Step: 0
Training loss: 0.07396095991134644
Validation loss: 1.4645841801038353

Epoch: 6| Step: 1
Training loss: 0.05082112178206444
Validation loss: 1.4626374936872912

Epoch: 6| Step: 2
Training loss: 0.060569584369659424
Validation loss: 1.4389598728508077

Epoch: 6| Step: 3
Training loss: 0.0704999640583992
Validation loss: 1.4529636803493704

Epoch: 6| Step: 4
Training loss: 0.06855517625808716
Validation loss: 1.4426631799308203

Epoch: 6| Step: 5
Training loss: 0.06892997026443481
Validation loss: 1.4617835270461215

Epoch: 6| Step: 6
Training loss: 0.03858093172311783
Validation loss: 1.462411170364708

Epoch: 6| Step: 7
Training loss: 0.06597789376974106
Validation loss: 1.4699434464977634

Epoch: 6| Step: 8
Training loss: 0.0714918002486229
Validation loss: 1.4915727819165876

Epoch: 6| Step: 9
Training loss: 0.06494897603988647
Validation loss: 1.4924026400812211

Epoch: 6| Step: 10
Training loss: 0.05279534310102463
Validation loss: 1.5397594359613234

Epoch: 6| Step: 11
Training loss: 0.08230451494455338
Validation loss: 1.5496215166584137

Epoch: 6| Step: 12
Training loss: 0.10251779854297638
Validation loss: 1.5197158449439592

Epoch: 6| Step: 13
Training loss: 0.0623185969889164
Validation loss: 1.5157482700963174

Epoch: 580| Step: 0
Training loss: 0.046217285096645355
Validation loss: 1.4870252577207421

Epoch: 6| Step: 1
Training loss: 0.04728124290704727
Validation loss: 1.5203375454230974

Epoch: 6| Step: 2
Training loss: 0.09617247432470322
Validation loss: 1.4815278783921273

Epoch: 6| Step: 3
Training loss: 0.09247452765703201
Validation loss: 1.5108825788703015

Epoch: 6| Step: 4
Training loss: 0.08887432515621185
Validation loss: 1.4868190391089326

Epoch: 6| Step: 5
Training loss: 0.07191313803195953
Validation loss: 1.4824231388748332

Epoch: 6| Step: 6
Training loss: 0.0607360377907753
Validation loss: 1.4693461528388403

Epoch: 6| Step: 7
Training loss: 0.06575159728527069
Validation loss: 1.5220812744991754

Epoch: 6| Step: 8
Training loss: 0.05464307963848114
Validation loss: 1.5082060707512723

Epoch: 6| Step: 9
Training loss: 0.05938367545604706
Validation loss: 1.5011223387974564

Epoch: 6| Step: 10
Training loss: 0.07155117392539978
Validation loss: 1.5164877419830651

Epoch: 6| Step: 11
Training loss: 0.061457470059394836
Validation loss: 1.4839643919339744

Epoch: 6| Step: 12
Training loss: 0.061681389808654785
Validation loss: 1.5100646070254746

Epoch: 6| Step: 13
Training loss: 0.04957113042473793
Validation loss: 1.4850269812409596

Epoch: 581| Step: 0
Training loss: 0.04117145389318466
Validation loss: 1.4767210509187432

Epoch: 6| Step: 1
Training loss: 0.043891895562410355
Validation loss: 1.5034365487355057

Epoch: 6| Step: 2
Training loss: 0.07081621885299683
Validation loss: 1.523889482662242

Epoch: 6| Step: 3
Training loss: 0.06960586458444595
Validation loss: 1.528869895524876

Epoch: 6| Step: 4
Training loss: 0.06602475047111511
Validation loss: 1.532584762060514

Epoch: 6| Step: 5
Training loss: 0.07365566492080688
Validation loss: 1.5239599968797417

Epoch: 6| Step: 6
Training loss: 0.0977642834186554
Validation loss: 1.5381103177224436

Epoch: 6| Step: 7
Training loss: 0.09948655217885971
Validation loss: 1.4981496898076867

Epoch: 6| Step: 8
Training loss: 0.07254184782505035
Validation loss: 1.4685331570204867

Epoch: 6| Step: 9
Training loss: 0.08352811634540558
Validation loss: 1.4887760352062922

Epoch: 6| Step: 10
Training loss: 0.08227187395095825
Validation loss: 1.4749154698464177

Epoch: 6| Step: 11
Training loss: 0.09221749007701874
Validation loss: 1.4528624242351902

Epoch: 6| Step: 12
Training loss: 0.08275527507066727
Validation loss: 1.4691456703729526

Epoch: 6| Step: 13
Training loss: 0.09091915190219879
Validation loss: 1.4596380854165683

Epoch: 582| Step: 0
Training loss: 0.06739456951618195
Validation loss: 1.443754352549071

Epoch: 6| Step: 1
Training loss: 0.11900234967470169
Validation loss: 1.488151446465523

Epoch: 6| Step: 2
Training loss: 0.08560463786125183
Validation loss: 1.4940259828362414

Epoch: 6| Step: 3
Training loss: 0.0806194543838501
Validation loss: 1.487545121100641

Epoch: 6| Step: 4
Training loss: 0.05326521396636963
Validation loss: 1.493722827203812

Epoch: 6| Step: 5
Training loss: 0.08610828220844269
Validation loss: 1.5274391584498908

Epoch: 6| Step: 6
Training loss: 0.07432567328214645
Validation loss: 1.5558633060865505

Epoch: 6| Step: 7
Training loss: 0.08264102041721344
Validation loss: 1.5473196544954855

Epoch: 6| Step: 8
Training loss: 0.11466306447982788
Validation loss: 1.54401155184674

Epoch: 6| Step: 9
Training loss: 0.05952383950352669
Validation loss: 1.5096305877931657

Epoch: 6| Step: 10
Training loss: 0.04514900594949722
Validation loss: 1.4809506080483879

Epoch: 6| Step: 11
Training loss: 0.05444539710879326
Validation loss: 1.4552320216291694

Epoch: 6| Step: 12
Training loss: 0.08708593249320984
Validation loss: 1.4790960672081157

Epoch: 6| Step: 13
Training loss: 0.046511486172676086
Validation loss: 1.4673944147684241

Epoch: 583| Step: 0
Training loss: 0.05494570732116699
Validation loss: 1.4404015726940607

Epoch: 6| Step: 1
Training loss: 0.10031147301197052
Validation loss: 1.4208086421412807

Epoch: 6| Step: 2
Training loss: 0.06602869927883148
Validation loss: 1.41930345566042

Epoch: 6| Step: 3
Training loss: 0.05056789517402649
Validation loss: 1.455676281323997

Epoch: 6| Step: 4
Training loss: 0.07420878112316132
Validation loss: 1.4171503948908981

Epoch: 6| Step: 5
Training loss: 0.07680235803127289
Validation loss: 1.4331049009035992

Epoch: 6| Step: 6
Training loss: 0.0403345450758934
Validation loss: 1.4236940722311697

Epoch: 6| Step: 7
Training loss: 0.09168090671300888
Validation loss: 1.4292095797036284

Epoch: 6| Step: 8
Training loss: 0.05706288665533066
Validation loss: 1.4589672844897035

Epoch: 6| Step: 9
Training loss: 0.108803391456604
Validation loss: 1.4629483633143927

Epoch: 6| Step: 10
Training loss: 0.08602821826934814
Validation loss: 1.4532577978667391

Epoch: 6| Step: 11
Training loss: 0.07287684828042984
Validation loss: 1.4749047871558898

Epoch: 6| Step: 12
Training loss: 0.06448785960674286
Validation loss: 1.4883022897986955

Epoch: 6| Step: 13
Training loss: 0.15058034658432007
Validation loss: 1.4754985417089155

Epoch: 584| Step: 0
Training loss: 0.09617586433887482
Validation loss: 1.486827382477381

Epoch: 6| Step: 1
Training loss: 0.06928271055221558
Validation loss: 1.4919912892003213

Epoch: 6| Step: 2
Training loss: 0.055432144552469254
Validation loss: 1.4778479171055618

Epoch: 6| Step: 3
Training loss: 0.09481807053089142
Validation loss: 1.4528701254116592

Epoch: 6| Step: 4
Training loss: 0.06872408837080002
Validation loss: 1.4563928086270568

Epoch: 6| Step: 5
Training loss: 0.06875266134738922
Validation loss: 1.4703680276870728

Epoch: 6| Step: 6
Training loss: 0.07504639029502869
Validation loss: 1.4682869988103067

Epoch: 6| Step: 7
Training loss: 0.06162524223327637
Validation loss: 1.4643783928245626

Epoch: 6| Step: 8
Training loss: 0.07671628892421722
Validation loss: 1.4832300229739117

Epoch: 6| Step: 9
Training loss: 0.15593847632408142
Validation loss: 1.4783500599604782

Epoch: 6| Step: 10
Training loss: 0.064614437520504
Validation loss: 1.468639886507424

Epoch: 6| Step: 11
Training loss: 0.09599824994802475
Validation loss: 1.4751879207549556

Epoch: 6| Step: 12
Training loss: 0.048187822103500366
Validation loss: 1.4812072041214153

Epoch: 6| Step: 13
Training loss: 0.0875723659992218
Validation loss: 1.4764595121465705

Epoch: 585| Step: 0
Training loss: 0.08138236403465271
Validation loss: 1.4647151616311842

Epoch: 6| Step: 1
Training loss: 0.05450114607810974
Validation loss: 1.4568334753795336

Epoch: 6| Step: 2
Training loss: 0.062310442328453064
Validation loss: 1.5012171345372354

Epoch: 6| Step: 3
Training loss: 0.06598368287086487
Validation loss: 1.4805408036837013

Epoch: 6| Step: 4
Training loss: 0.08011806011199951
Validation loss: 1.466144214394272

Epoch: 6| Step: 5
Training loss: 0.041498467326164246
Validation loss: 1.4717069107999083

Epoch: 6| Step: 6
Training loss: 0.07812045514583588
Validation loss: 1.445893544022755

Epoch: 6| Step: 7
Training loss: 0.06213322654366493
Validation loss: 1.46976516836433

Epoch: 6| Step: 8
Training loss: 0.06882257759571075
Validation loss: 1.4597423666266984

Epoch: 6| Step: 9
Training loss: 0.06337707489728928
Validation loss: 1.4463580295603762

Epoch: 6| Step: 10
Training loss: 0.06293337047100067
Validation loss: 1.451140074319737

Epoch: 6| Step: 11
Training loss: 0.08910468220710754
Validation loss: 1.448576129892821

Epoch: 6| Step: 12
Training loss: 0.07643555849790573
Validation loss: 1.4563028966226885

Epoch: 6| Step: 13
Training loss: 0.03067840449512005
Validation loss: 1.4782901181969592

Epoch: 586| Step: 0
Training loss: 0.06722169369459152
Validation loss: 1.4688285499490716

Epoch: 6| Step: 1
Training loss: 0.0725296214222908
Validation loss: 1.4612913445759845

Epoch: 6| Step: 2
Training loss: 0.04694351553916931
Validation loss: 1.4601061600510792

Epoch: 6| Step: 3
Training loss: 0.05941569805145264
Validation loss: 1.4706457289316321

Epoch: 6| Step: 4
Training loss: 0.05850524455308914
Validation loss: 1.445483995381222

Epoch: 6| Step: 5
Training loss: 0.037442516535520554
Validation loss: 1.4544959722026702

Epoch: 6| Step: 6
Training loss: 0.051332734525203705
Validation loss: 1.468523899714152

Epoch: 6| Step: 7
Training loss: 0.07199594378471375
Validation loss: 1.4736205647068639

Epoch: 6| Step: 8
Training loss: 0.05938286706805229
Validation loss: 1.4873749940626082

Epoch: 6| Step: 9
Training loss: 0.05622854828834534
Validation loss: 1.48464737848569

Epoch: 6| Step: 10
Training loss: 0.07613155245780945
Validation loss: 1.468551174286873

Epoch: 6| Step: 11
Training loss: 0.0529271736741066
Validation loss: 1.4901636954276793

Epoch: 6| Step: 12
Training loss: 0.06551755219697952
Validation loss: 1.469359782434279

Epoch: 6| Step: 13
Training loss: 0.16429921984672546
Validation loss: 1.448926911559156

Epoch: 587| Step: 0
Training loss: 0.034616366028785706
Validation loss: 1.4531968203924035

Epoch: 6| Step: 1
Training loss: 0.03658353537321091
Validation loss: 1.457962191233071

Epoch: 6| Step: 2
Training loss: 0.045453064143657684
Validation loss: 1.446778005169284

Epoch: 6| Step: 3
Training loss: 0.06314495205879211
Validation loss: 1.449567840945336

Epoch: 6| Step: 4
Training loss: 0.058393895626068115
Validation loss: 1.4330609972758959

Epoch: 6| Step: 5
Training loss: 0.08029323816299438
Validation loss: 1.434508704370068

Epoch: 6| Step: 6
Training loss: 0.06743563711643219
Validation loss: 1.4386960883294382

Epoch: 6| Step: 7
Training loss: 0.08979842811822891
Validation loss: 1.4318470134530017

Epoch: 6| Step: 8
Training loss: 0.07588420808315277
Validation loss: 1.407585725989393

Epoch: 6| Step: 9
Training loss: 0.06595619022846222
Validation loss: 1.4387497017460484

Epoch: 6| Step: 10
Training loss: 0.062398701906204224
Validation loss: 1.4419687358281945

Epoch: 6| Step: 11
Training loss: 0.07971619814634323
Validation loss: 1.440609464081385

Epoch: 6| Step: 12
Training loss: 0.06063498556613922
Validation loss: 1.4383434569963844

Epoch: 6| Step: 13
Training loss: 0.05243648588657379
Validation loss: 1.453300509401547

Epoch: 588| Step: 0
Training loss: 0.04523277282714844
Validation loss: 1.4606651221552203

Epoch: 6| Step: 1
Training loss: 0.04864121600985527
Validation loss: 1.4473140688352688

Epoch: 6| Step: 2
Training loss: 0.05253002792596817
Validation loss: 1.4484637104054934

Epoch: 6| Step: 3
Training loss: 0.03750912845134735
Validation loss: 1.4791310294981925

Epoch: 6| Step: 4
Training loss: 0.05451824516057968
Validation loss: 1.4506341872676727

Epoch: 6| Step: 5
Training loss: 0.06476438790559769
Validation loss: 1.4621485587089293

Epoch: 6| Step: 6
Training loss: 0.03629013150930405
Validation loss: 1.4622361967640538

Epoch: 6| Step: 7
Training loss: 0.06628616899251938
Validation loss: 1.4434907250506903

Epoch: 6| Step: 8
Training loss: 0.0796687975525856
Validation loss: 1.433554071252064

Epoch: 6| Step: 9
Training loss: 0.08878932148218155
Validation loss: 1.4538194889663367

Epoch: 6| Step: 10
Training loss: 0.07181867957115173
Validation loss: 1.4290483145303623

Epoch: 6| Step: 11
Training loss: 0.12016385793685913
Validation loss: 1.4586320589947444

Epoch: 6| Step: 12
Training loss: 0.049304746091365814
Validation loss: 1.4375406977950886

Epoch: 6| Step: 13
Training loss: 0.07117639482021332
Validation loss: 1.439051107693744

Epoch: 589| Step: 0
Training loss: 0.03634437173604965
Validation loss: 1.4642144435195512

Epoch: 6| Step: 1
Training loss: 0.05651486665010452
Validation loss: 1.4652813929383472

Epoch: 6| Step: 2
Training loss: 0.0637948289513588
Validation loss: 1.4675576533040693

Epoch: 6| Step: 3
Training loss: 0.08690227568149567
Validation loss: 1.4729407538649857

Epoch: 6| Step: 4
Training loss: 0.06425929069519043
Validation loss: 1.4841532450850292

Epoch: 6| Step: 5
Training loss: 0.06725914031267166
Validation loss: 1.4874953839086718

Epoch: 6| Step: 6
Training loss: 0.04794688895344734
Validation loss: 1.4864072017772223

Epoch: 6| Step: 7
Training loss: 0.08830326795578003
Validation loss: 1.4720779106181154

Epoch: 6| Step: 8
Training loss: 0.09142323583364487
Validation loss: 1.473967852131013

Epoch: 6| Step: 9
Training loss: 0.03960058465600014
Validation loss: 1.4689290215892177

Epoch: 6| Step: 10
Training loss: 0.06923647224903107
Validation loss: 1.4495252306743334

Epoch: 6| Step: 11
Training loss: 0.05042658746242523
Validation loss: 1.4322163353684128

Epoch: 6| Step: 12
Training loss: 0.057401999831199646
Validation loss: 1.456926707298525

Epoch: 6| Step: 13
Training loss: 0.05574128404259682
Validation loss: 1.4595196253509932

Epoch: 590| Step: 0
Training loss: 0.05266408249735832
Validation loss: 1.443062413123346

Epoch: 6| Step: 1
Training loss: 0.06951014697551727
Validation loss: 1.4652299419526131

Epoch: 6| Step: 2
Training loss: 0.08237296342849731
Validation loss: 1.452619699380731

Epoch: 6| Step: 3
Training loss: 0.10210477560758591
Validation loss: 1.4302220549634708

Epoch: 6| Step: 4
Training loss: 0.07884524762630463
Validation loss: 1.423274423486443

Epoch: 6| Step: 5
Training loss: 0.11822059750556946
Validation loss: 1.442047651736967

Epoch: 6| Step: 6
Training loss: 0.04752916097640991
Validation loss: 1.4276000633034656

Epoch: 6| Step: 7
Training loss: 0.06675463914871216
Validation loss: 1.450268062212134

Epoch: 6| Step: 8
Training loss: 0.0685824602842331
Validation loss: 1.4470592237287951

Epoch: 6| Step: 9
Training loss: 0.06014521047472954
Validation loss: 1.4495309322111067

Epoch: 6| Step: 10
Training loss: 0.036580316722393036
Validation loss: 1.4501579282104329

Epoch: 6| Step: 11
Training loss: 0.05221869423985481
Validation loss: 1.4821927842273508

Epoch: 6| Step: 12
Training loss: 0.03437904268503189
Validation loss: 1.4427269357506947

Epoch: 6| Step: 13
Training loss: 0.02030680514872074
Validation loss: 1.4520221448713733

Epoch: 591| Step: 0
Training loss: 0.046354345977306366
Validation loss: 1.4406821048387917

Epoch: 6| Step: 1
Training loss: 0.05299276486039162
Validation loss: 1.4329665194275558

Epoch: 6| Step: 2
Training loss: 0.05739894509315491
Validation loss: 1.4129551533729798

Epoch: 6| Step: 3
Training loss: 0.056477732956409454
Validation loss: 1.4111307641511321

Epoch: 6| Step: 4
Training loss: 0.07113459706306458
Validation loss: 1.413141655665572

Epoch: 6| Step: 5
Training loss: 0.08291928470134735
Validation loss: 1.4316959791286017

Epoch: 6| Step: 6
Training loss: 0.04027170687913895
Validation loss: 1.408885621255444

Epoch: 6| Step: 7
Training loss: 0.10502570122480392
Validation loss: 1.4299354328904101

Epoch: 6| Step: 8
Training loss: 0.07095987349748611
Validation loss: 1.4332520525942567

Epoch: 6| Step: 9
Training loss: 0.07020410150289536
Validation loss: 1.4189453535182501

Epoch: 6| Step: 10
Training loss: 0.05395597591996193
Validation loss: 1.4317713232450588

Epoch: 6| Step: 11
Training loss: 0.06603918969631195
Validation loss: 1.440577841574146

Epoch: 6| Step: 12
Training loss: 0.07588396966457367
Validation loss: 1.4406333367029827

Epoch: 6| Step: 13
Training loss: 0.052415650337934494
Validation loss: 1.443081896792176

Epoch: 592| Step: 0
Training loss: 0.04905672371387482
Validation loss: 1.4537084640995148

Epoch: 6| Step: 1
Training loss: 0.039547890424728394
Validation loss: 1.4353771607081096

Epoch: 6| Step: 2
Training loss: 0.05870437249541283
Validation loss: 1.4501859154752506

Epoch: 6| Step: 3
Training loss: 0.07959531247615814
Validation loss: 1.4403458385057346

Epoch: 6| Step: 4
Training loss: 0.058715201914310455
Validation loss: 1.4624583554524246

Epoch: 6| Step: 5
Training loss: 0.06845052540302277
Validation loss: 1.4399033445183949

Epoch: 6| Step: 6
Training loss: 0.06451019644737244
Validation loss: 1.4287367328520744

Epoch: 6| Step: 7
Training loss: 0.06920680403709412
Validation loss: 1.428784562695411

Epoch: 6| Step: 8
Training loss: 0.06840558350086212
Validation loss: 1.4402906856229227

Epoch: 6| Step: 9
Training loss: 0.04744815081357956
Validation loss: 1.4624340162482312

Epoch: 6| Step: 10
Training loss: 0.07331347465515137
Validation loss: 1.4410094112478278

Epoch: 6| Step: 11
Training loss: 0.07006784528493881
Validation loss: 1.4291856147909676

Epoch: 6| Step: 12
Training loss: 0.0900437980890274
Validation loss: 1.473216115787465

Epoch: 6| Step: 13
Training loss: 0.06867519021034241
Validation loss: 1.44831847119075

Epoch: 593| Step: 0
Training loss: 0.07208391278982162
Validation loss: 1.4215145072629374

Epoch: 6| Step: 1
Training loss: 0.06273112446069717
Validation loss: 1.4516927221769929

Epoch: 6| Step: 2
Training loss: 0.03967514634132385
Validation loss: 1.4268758828921984

Epoch: 6| Step: 3
Training loss: 0.05188975855708122
Validation loss: 1.4272696125891902

Epoch: 6| Step: 4
Training loss: 0.058191873133182526
Validation loss: 1.438595070633837

Epoch: 6| Step: 5
Training loss: 0.04507658630609512
Validation loss: 1.4052394000432824

Epoch: 6| Step: 6
Training loss: 0.044754594564437866
Validation loss: 1.4219502031162221

Epoch: 6| Step: 7
Training loss: 0.07785630226135254
Validation loss: 1.4245402537366396

Epoch: 6| Step: 8
Training loss: 0.07939448207616806
Validation loss: 1.4516486935718085

Epoch: 6| Step: 9
Training loss: 0.04377826303243637
Validation loss: 1.4521783603134977

Epoch: 6| Step: 10
Training loss: 0.04428348317742348
Validation loss: 1.4319321135038972

Epoch: 6| Step: 11
Training loss: 0.05195486545562744
Validation loss: 1.430890038449277

Epoch: 6| Step: 12
Training loss: 0.05951196700334549
Validation loss: 1.4463746957881476

Epoch: 6| Step: 13
Training loss: 0.11459898948669434
Validation loss: 1.4353015615094094

Epoch: 594| Step: 0
Training loss: 0.0628129243850708
Validation loss: 1.4551774276200162

Epoch: 6| Step: 1
Training loss: 0.0388483852148056
Validation loss: 1.4360549091010966

Epoch: 6| Step: 2
Training loss: 0.08127947151660919
Validation loss: 1.4626661487804946

Epoch: 6| Step: 3
Training loss: 0.03920406848192215
Validation loss: 1.4401323731227587

Epoch: 6| Step: 4
Training loss: 0.04459524527192116
Validation loss: 1.444911326131513

Epoch: 6| Step: 5
Training loss: 0.041814349591732025
Validation loss: 1.4520039622501661

Epoch: 6| Step: 6
Training loss: 0.0493689700961113
Validation loss: 1.4373743572542745

Epoch: 6| Step: 7
Training loss: 0.030247468501329422
Validation loss: 1.4624265304175756

Epoch: 6| Step: 8
Training loss: 0.06299636512994766
Validation loss: 1.4490409012763732

Epoch: 6| Step: 9
Training loss: 0.03735976666212082
Validation loss: 1.4574722218257126

Epoch: 6| Step: 10
Training loss: 0.05592016130685806
Validation loss: 1.4714353622928742

Epoch: 6| Step: 11
Training loss: 0.08740312606096268
Validation loss: 1.4567856160543298

Epoch: 6| Step: 12
Training loss: 0.05847465619444847
Validation loss: 1.4499118353730889

Epoch: 6| Step: 13
Training loss: 0.04327160492539406
Validation loss: 1.4139658686935261

Epoch: 595| Step: 0
Training loss: 0.038149669766426086
Validation loss: 1.4433793329423474

Epoch: 6| Step: 1
Training loss: 0.04441353678703308
Validation loss: 1.4379454581968245

Epoch: 6| Step: 2
Training loss: 0.05218133702874184
Validation loss: 1.4282263722471011

Epoch: 6| Step: 3
Training loss: 0.06273400038480759
Validation loss: 1.444859399590441

Epoch: 6| Step: 4
Training loss: 0.06428024172782898
Validation loss: 1.4423663231634325

Epoch: 6| Step: 5
Training loss: 0.06986281275749207
Validation loss: 1.4231673107352307

Epoch: 6| Step: 6
Training loss: 0.04584628716111183
Validation loss: 1.4446178943880144

Epoch: 6| Step: 7
Training loss: 0.08508758246898651
Validation loss: 1.4544751964589602

Epoch: 6| Step: 8
Training loss: 0.054997291415929794
Validation loss: 1.4120466786046182

Epoch: 6| Step: 9
Training loss: 0.05130426958203316
Validation loss: 1.4457886795843802

Epoch: 6| Step: 10
Training loss: 0.07521913200616837
Validation loss: 1.4429873330618745

Epoch: 6| Step: 11
Training loss: 0.08404369652271271
Validation loss: 1.4613274374315817

Epoch: 6| Step: 12
Training loss: 0.06538762897253036
Validation loss: 1.4475108654268327

Epoch: 6| Step: 13
Training loss: 0.03513399139046669
Validation loss: 1.4526772486266268

Epoch: 596| Step: 0
Training loss: 0.05326616019010544
Validation loss: 1.4449489783215266

Epoch: 6| Step: 1
Training loss: 0.04122493788599968
Validation loss: 1.455390255938294

Epoch: 6| Step: 2
Training loss: 0.04944455251097679
Validation loss: 1.461643550985603

Epoch: 6| Step: 3
Training loss: 0.057322144508361816
Validation loss: 1.4469464466135988

Epoch: 6| Step: 4
Training loss: 0.08756598830223083
Validation loss: 1.4601647046304518

Epoch: 6| Step: 5
Training loss: 0.09252405166625977
Validation loss: 1.4637905410541001

Epoch: 6| Step: 6
Training loss: 0.06104449927806854
Validation loss: 1.4595076499446746

Epoch: 6| Step: 7
Training loss: 0.062434084713459015
Validation loss: 1.4793234461097307

Epoch: 6| Step: 8
Training loss: 0.040182821452617645
Validation loss: 1.4514101077151556

Epoch: 6| Step: 9
Training loss: 0.0339975506067276
Validation loss: 1.446007054339173

Epoch: 6| Step: 10
Training loss: 0.07754483819007874
Validation loss: 1.455385717012549

Epoch: 6| Step: 11
Training loss: 0.05100300908088684
Validation loss: 1.4358506741062287

Epoch: 6| Step: 12
Training loss: 0.03331025689840317
Validation loss: 1.4651690644602622

Epoch: 6| Step: 13
Training loss: 0.0347013883292675
Validation loss: 1.4265177172999228

Epoch: 597| Step: 0
Training loss: 0.060835644602775574
Validation loss: 1.4433225188204037

Epoch: 6| Step: 1
Training loss: 0.03372381627559662
Validation loss: 1.4368528063579271

Epoch: 6| Step: 2
Training loss: 0.05022647976875305
Validation loss: 1.4470192309348815

Epoch: 6| Step: 3
Training loss: 0.05050770193338394
Validation loss: 1.4479642145095333

Epoch: 6| Step: 4
Training loss: 0.08564438670873642
Validation loss: 1.4575967583605038

Epoch: 6| Step: 5
Training loss: 0.05910144001245499
Validation loss: 1.449357823659015

Epoch: 6| Step: 6
Training loss: 0.05169776827096939
Validation loss: 1.4533382487553421

Epoch: 6| Step: 7
Training loss: 0.06761186569929123
Validation loss: 1.4430313674352502

Epoch: 6| Step: 8
Training loss: 0.0785205215215683
Validation loss: 1.4240339686793666

Epoch: 6| Step: 9
Training loss: 0.08178063482046127
Validation loss: 1.4292221543609456

Epoch: 6| Step: 10
Training loss: 0.05362846702337265
Validation loss: 1.460823074463875

Epoch: 6| Step: 11
Training loss: 0.03481348603963852
Validation loss: 1.4508073509380381

Epoch: 6| Step: 12
Training loss: 0.07325145602226257
Validation loss: 1.4678515234301168

Epoch: 6| Step: 13
Training loss: 0.11426060646772385
Validation loss: 1.473683209829433

Epoch: 598| Step: 0
Training loss: 0.05322498455643654
Validation loss: 1.4660056073178527

Epoch: 6| Step: 1
Training loss: 0.05371840298175812
Validation loss: 1.4329784685565579

Epoch: 6| Step: 2
Training loss: 0.0479910746216774
Validation loss: 1.4363900487140944

Epoch: 6| Step: 3
Training loss: 0.09192859381437302
Validation loss: 1.4241475982050742

Epoch: 6| Step: 4
Training loss: 0.050832267850637436
Validation loss: 1.4597553168573687

Epoch: 6| Step: 5
Training loss: 0.058015041053295135
Validation loss: 1.433617518794152

Epoch: 6| Step: 6
Training loss: 0.049940239638090134
Validation loss: 1.4377834168813561

Epoch: 6| Step: 7
Training loss: 0.04984373226761818
Validation loss: 1.444726287998179

Epoch: 6| Step: 8
Training loss: 0.043591566383838654
Validation loss: 1.4069551383295367

Epoch: 6| Step: 9
Training loss: 0.04018222540616989
Validation loss: 1.4272570033227243

Epoch: 6| Step: 10
Training loss: 0.04239550232887268
Validation loss: 1.4466245264135382

Epoch: 6| Step: 11
Training loss: 0.051278047263622284
Validation loss: 1.4517772357950929

Epoch: 6| Step: 12
Training loss: 0.08454984426498413
Validation loss: 1.4410300485549434

Epoch: 6| Step: 13
Training loss: 0.04173910617828369
Validation loss: 1.45528228821293

Epoch: 599| Step: 0
Training loss: 0.044323474168777466
Validation loss: 1.413455661906991

Epoch: 6| Step: 1
Training loss: 0.06999247521162033
Validation loss: 1.423913642924319

Epoch: 6| Step: 2
Training loss: 0.0587843656539917
Validation loss: 1.4602026631755214

Epoch: 6| Step: 3
Training loss: 0.02286556363105774
Validation loss: 1.4512810540455643

Epoch: 6| Step: 4
Training loss: 0.040224626660346985
Validation loss: 1.4635890876093218

Epoch: 6| Step: 5
Training loss: 0.04025764763355255
Validation loss: 1.4593794076673445

Epoch: 6| Step: 6
Training loss: 0.04734092205762863
Validation loss: 1.44880493674227

Epoch: 6| Step: 7
Training loss: 0.05413571000099182
Validation loss: 1.4594889199861916

Epoch: 6| Step: 8
Training loss: 0.06133481487631798
Validation loss: 1.474475017157934

Epoch: 6| Step: 9
Training loss: 0.06916025280952454
Validation loss: 1.4367146722732052

Epoch: 6| Step: 10
Training loss: 0.05915570259094238
Validation loss: 1.4358624578804098

Epoch: 6| Step: 11
Training loss: 0.06019926071166992
Validation loss: 1.4227340234223234

Epoch: 6| Step: 12
Training loss: 0.03922054171562195
Validation loss: 1.4493588747516755

Epoch: 6| Step: 13
Training loss: 0.0882151648402214
Validation loss: 1.445690748512104

Epoch: 600| Step: 0
Training loss: 0.04591269791126251
Validation loss: 1.4350543073428574

Epoch: 6| Step: 1
Training loss: 0.03259184584021568
Validation loss: 1.4096632144784416

Epoch: 6| Step: 2
Training loss: 0.052152201533317566
Validation loss: 1.4356010831812376

Epoch: 6| Step: 3
Training loss: 0.044882554560899734
Validation loss: 1.432263784511115

Epoch: 6| Step: 4
Training loss: 0.06721527874469757
Validation loss: 1.4282955251714236

Epoch: 6| Step: 5
Training loss: 0.048214592039585114
Validation loss: 1.4283269425874114

Epoch: 6| Step: 6
Training loss: 0.09018568694591522
Validation loss: 1.4309329012388825

Epoch: 6| Step: 7
Training loss: 0.09335917234420776
Validation loss: 1.450425927357007

Epoch: 6| Step: 8
Training loss: 0.07832944393157959
Validation loss: 1.435368069397506

Epoch: 6| Step: 9
Training loss: 0.07429526746273041
Validation loss: 1.4352315920655445

Epoch: 6| Step: 10
Training loss: 0.10503263771533966
Validation loss: 1.4533598166640087

Epoch: 6| Step: 11
Training loss: 0.06888845562934875
Validation loss: 1.442027961054156

Epoch: 6| Step: 12
Training loss: 0.06497757881879807
Validation loss: 1.447510225798494

Epoch: 6| Step: 13
Training loss: 0.0662781149148941
Validation loss: 1.4324907448983961

Epoch: 601| Step: 0
Training loss: 0.05239184945821762
Validation loss: 1.4628643335834626

Epoch: 6| Step: 1
Training loss: 0.054354291409254074
Validation loss: 1.4611506551824591

Epoch: 6| Step: 2
Training loss: 0.08902280032634735
Validation loss: 1.4402092400417532

Epoch: 6| Step: 3
Training loss: 0.06410354375839233
Validation loss: 1.4652008215586345

Epoch: 6| Step: 4
Training loss: 0.039617497473955154
Validation loss: 1.451417366663615

Epoch: 6| Step: 5
Training loss: 0.06518516689538956
Validation loss: 1.4342467272153465

Epoch: 6| Step: 6
Training loss: 0.08329182863235474
Validation loss: 1.429400086402893

Epoch: 6| Step: 7
Training loss: 0.06516598165035248
Validation loss: 1.4304366547574279

Epoch: 6| Step: 8
Training loss: 0.05488494038581848
Validation loss: 1.4322584008657804

Epoch: 6| Step: 9
Training loss: 0.084660105407238
Validation loss: 1.42275309178137

Epoch: 6| Step: 10
Training loss: 0.042660683393478394
Validation loss: 1.4440164732676681

Epoch: 6| Step: 11
Training loss: 0.041766487061977386
Validation loss: 1.431805891375388

Epoch: 6| Step: 12
Training loss: 0.04416900500655174
Validation loss: 1.431307501690362

Epoch: 6| Step: 13
Training loss: 0.05542957782745361
Validation loss: 1.4223481942248601

Epoch: 602| Step: 0
Training loss: 0.05676501616835594
Validation loss: 1.4461542201298538

Epoch: 6| Step: 1
Training loss: 0.04517045617103577
Validation loss: 1.4354889367216377

Epoch: 6| Step: 2
Training loss: 0.06109142303466797
Validation loss: 1.4661446322676956

Epoch: 6| Step: 3
Training loss: 0.09195221215486526
Validation loss: 1.45966342572243

Epoch: 6| Step: 4
Training loss: 0.03955855220556259
Validation loss: 1.4434954684267762

Epoch: 6| Step: 5
Training loss: 0.06290841102600098
Validation loss: 1.4291643506737166

Epoch: 6| Step: 6
Training loss: 0.06026303395628929
Validation loss: 1.4414768770176878

Epoch: 6| Step: 7
Training loss: 0.03727465867996216
Validation loss: 1.4301902786377938

Epoch: 6| Step: 8
Training loss: 0.04871128499507904
Validation loss: 1.4379482461560158

Epoch: 6| Step: 9
Training loss: 0.07900669425725937
Validation loss: 1.4273898498986357

Epoch: 6| Step: 10
Training loss: 0.06267526000738144
Validation loss: 1.4220481418794202

Epoch: 6| Step: 11
Training loss: 0.04878668487071991
Validation loss: 1.4246989232237621

Epoch: 6| Step: 12
Training loss: 0.08582800626754761
Validation loss: 1.4279382715943039

Epoch: 6| Step: 13
Training loss: 0.0689227432012558
Validation loss: 1.4509379351010887

Epoch: 603| Step: 0
Training loss: 0.04995860159397125
Validation loss: 1.448457488449671

Epoch: 6| Step: 1
Training loss: 0.047423020005226135
Validation loss: 1.427657114562168

Epoch: 6| Step: 2
Training loss: 0.08320346474647522
Validation loss: 1.441223813641456

Epoch: 6| Step: 3
Training loss: 0.050145961344242096
Validation loss: 1.4265757318465941

Epoch: 6| Step: 4
Training loss: 0.06257037073373795
Validation loss: 1.4272523926150413

Epoch: 6| Step: 5
Training loss: 0.08075187355279922
Validation loss: 1.4242982915652695

Epoch: 6| Step: 6
Training loss: 0.06716746091842651
Validation loss: 1.407609442228912

Epoch: 6| Step: 7
Training loss: 0.039236199110746384
Validation loss: 1.425139702776427

Epoch: 6| Step: 8
Training loss: 0.04502391070127487
Validation loss: 1.4009589482379217

Epoch: 6| Step: 9
Training loss: 0.05553678050637245
Validation loss: 1.4031847638468589

Epoch: 6| Step: 10
Training loss: 0.06446853280067444
Validation loss: 1.4188892264519968

Epoch: 6| Step: 11
Training loss: 0.035168249160051346
Validation loss: 1.417390618273007

Epoch: 6| Step: 12
Training loss: 0.0808987021446228
Validation loss: 1.4111701339803717

Epoch: 6| Step: 13
Training loss: 0.05045090615749359
Validation loss: 1.4331895074536722

Epoch: 604| Step: 0
Training loss: 0.0655738040804863
Validation loss: 1.4206268281065009

Epoch: 6| Step: 1
Training loss: 0.043463580310344696
Validation loss: 1.4236849341341244

Epoch: 6| Step: 2
Training loss: 0.0601017102599144
Validation loss: 1.4322661712605467

Epoch: 6| Step: 3
Training loss: 0.038035422563552856
Validation loss: 1.4480351594186598

Epoch: 6| Step: 4
Training loss: 0.03734653443098068
Validation loss: 1.4562865598227388

Epoch: 6| Step: 5
Training loss: 0.06369175016880035
Validation loss: 1.4692814670583254

Epoch: 6| Step: 6
Training loss: 0.04082752764225006
Validation loss: 1.4533866989997126

Epoch: 6| Step: 7
Training loss: 0.07162180542945862
Validation loss: 1.45379158630166

Epoch: 6| Step: 8
Training loss: 0.07466229796409607
Validation loss: 1.4468860703129922

Epoch: 6| Step: 9
Training loss: 0.05368606373667717
Validation loss: 1.4431170045688588

Epoch: 6| Step: 10
Training loss: 0.0433574840426445
Validation loss: 1.461556471804137

Epoch: 6| Step: 11
Training loss: 0.11105644702911377
Validation loss: 1.4400212066147917

Epoch: 6| Step: 12
Training loss: 0.0548185259103775
Validation loss: 1.4504800240198772

Epoch: 6| Step: 13
Training loss: 0.04625502601265907
Validation loss: 1.441266554658131

Epoch: 605| Step: 0
Training loss: 0.06594710052013397
Validation loss: 1.457894758511615

Epoch: 6| Step: 1
Training loss: 0.0621260404586792
Validation loss: 1.448462490112551

Epoch: 6| Step: 2
Training loss: 0.0548238568007946
Validation loss: 1.4608986428988877

Epoch: 6| Step: 3
Training loss: 0.07681673765182495
Validation loss: 1.4450053168881325

Epoch: 6| Step: 4
Training loss: 0.06092684715986252
Validation loss: 1.479085046757934

Epoch: 6| Step: 5
Training loss: 0.053547173738479614
Validation loss: 1.473154825548972

Epoch: 6| Step: 6
Training loss: 0.055843669921159744
Validation loss: 1.4452104235208163

Epoch: 6| Step: 7
Training loss: 0.06590740382671356
Validation loss: 1.4881019259011874

Epoch: 6| Step: 8
Training loss: 0.058215074241161346
Validation loss: 1.4637909986639535

Epoch: 6| Step: 9
Training loss: 0.07048451155424118
Validation loss: 1.4824583940608527

Epoch: 6| Step: 10
Training loss: 0.04184072092175484
Validation loss: 1.4713954258990545

Epoch: 6| Step: 11
Training loss: 0.03925402835011482
Validation loss: 1.4851806009969404

Epoch: 6| Step: 12
Training loss: 0.04817664995789528
Validation loss: 1.4864272109923824

Epoch: 6| Step: 13
Training loss: 0.056219592690467834
Validation loss: 1.4646476135458997

Epoch: 606| Step: 0
Training loss: 0.05341268330812454
Validation loss: 1.484611277939171

Epoch: 6| Step: 1
Training loss: 0.043082933872938156
Validation loss: 1.471228289988733

Epoch: 6| Step: 2
Training loss: 0.05485260486602783
Validation loss: 1.4576540365014026

Epoch: 6| Step: 3
Training loss: 0.037498824298381805
Validation loss: 1.4437851777640722

Epoch: 6| Step: 4
Training loss: 0.07035341113805771
Validation loss: 1.4368341366449993

Epoch: 6| Step: 5
Training loss: 0.08582606911659241
Validation loss: 1.4462829097624748

Epoch: 6| Step: 6
Training loss: 0.05598655343055725
Validation loss: 1.417103870581555

Epoch: 6| Step: 7
Training loss: 0.03857653588056564
Validation loss: 1.4359934265895555

Epoch: 6| Step: 8
Training loss: 0.049718551337718964
Validation loss: 1.4386811397408927

Epoch: 6| Step: 9
Training loss: 0.06985888630151749
Validation loss: 1.4375376368081698

Epoch: 6| Step: 10
Training loss: 0.03897751122713089
Validation loss: 1.452881569503456

Epoch: 6| Step: 11
Training loss: 0.060873717069625854
Validation loss: 1.4402421212965442

Epoch: 6| Step: 12
Training loss: 0.06294947862625122
Validation loss: 1.4451522288783905

Epoch: 6| Step: 13
Training loss: 0.06458672881126404
Validation loss: 1.4522066590606526

Epoch: 607| Step: 0
Training loss: 0.043182726949453354
Validation loss: 1.4407363181473107

Epoch: 6| Step: 1
Training loss: 0.05011799931526184
Validation loss: 1.4711012173724431

Epoch: 6| Step: 2
Training loss: 0.03908998519182205
Validation loss: 1.4356788255835091

Epoch: 6| Step: 3
Training loss: 0.04800839722156525
Validation loss: 1.4625638941282868

Epoch: 6| Step: 4
Training loss: 0.0778948962688446
Validation loss: 1.4739127184755059

Epoch: 6| Step: 5
Training loss: 0.06929025053977966
Validation loss: 1.4845466613769531

Epoch: 6| Step: 6
Training loss: 0.09685894101858139
Validation loss: 1.4490730711208877

Epoch: 6| Step: 7
Training loss: 0.08705849200487137
Validation loss: 1.460073048068631

Epoch: 6| Step: 8
Training loss: 0.04306909441947937
Validation loss: 1.449740562387692

Epoch: 6| Step: 9
Training loss: 0.07141652703285217
Validation loss: 1.4296862835525184

Epoch: 6| Step: 10
Training loss: 0.04626474902033806
Validation loss: 1.4496106204166208

Epoch: 6| Step: 11
Training loss: 0.08640289306640625
Validation loss: 1.4488204858636344

Epoch: 6| Step: 12
Training loss: 0.05501294136047363
Validation loss: 1.4607298502358057

Epoch: 6| Step: 13
Training loss: 0.061406154185533524
Validation loss: 1.456650589102058

Epoch: 608| Step: 0
Training loss: 0.04006648063659668
Validation loss: 1.4379856573638095

Epoch: 6| Step: 1
Training loss: 0.031389422714710236
Validation loss: 1.4562235224631526

Epoch: 6| Step: 2
Training loss: 0.06658600270748138
Validation loss: 1.4526376583242928

Epoch: 6| Step: 3
Training loss: 0.11097968369722366
Validation loss: 1.4732418637121878

Epoch: 6| Step: 4
Training loss: 0.07246264815330505
Validation loss: 1.4325693743203276

Epoch: 6| Step: 5
Training loss: 0.052188217639923096
Validation loss: 1.4624257465844512

Epoch: 6| Step: 6
Training loss: 0.05312556028366089
Validation loss: 1.4588799553532754

Epoch: 6| Step: 7
Training loss: 0.07433019578456879
Validation loss: 1.4414826900728288

Epoch: 6| Step: 8
Training loss: 0.05973120778799057
Validation loss: 1.4470742389719973

Epoch: 6| Step: 9
Training loss: 0.036880940198898315
Validation loss: 1.4270585096010597

Epoch: 6| Step: 10
Training loss: 0.08153733611106873
Validation loss: 1.4217203970878356

Epoch: 6| Step: 11
Training loss: 0.032134752720594406
Validation loss: 1.424080853821129

Epoch: 6| Step: 12
Training loss: 0.05819770693778992
Validation loss: 1.4184459467088022

Epoch: 6| Step: 13
Training loss: 0.04854271188378334
Validation loss: 1.4129843634943808

Epoch: 609| Step: 0
Training loss: 0.05833446979522705
Validation loss: 1.4179618140702606

Epoch: 6| Step: 1
Training loss: 0.04415594041347504
Validation loss: 1.4140598876501924

Epoch: 6| Step: 2
Training loss: 0.05288415774703026
Validation loss: 1.4112653898936447

Epoch: 6| Step: 3
Training loss: 0.051497720181941986
Validation loss: 1.4385848827259515

Epoch: 6| Step: 4
Training loss: 0.05576789379119873
Validation loss: 1.4301447047982165

Epoch: 6| Step: 5
Training loss: 0.06110362708568573
Validation loss: 1.4315101844008251

Epoch: 6| Step: 6
Training loss: 0.0377647802233696
Validation loss: 1.4206093421546362

Epoch: 6| Step: 7
Training loss: 0.07984569668769836
Validation loss: 1.4556622812824864

Epoch: 6| Step: 8
Training loss: 0.06034373119473457
Validation loss: 1.438924898383438

Epoch: 6| Step: 9
Training loss: 0.07022878527641296
Validation loss: 1.4275276327645907

Epoch: 6| Step: 10
Training loss: 0.050434622913599014
Validation loss: 1.4423281902907996

Epoch: 6| Step: 11
Training loss: 0.06728240102529526
Validation loss: 1.4457080735955188

Epoch: 6| Step: 12
Training loss: 0.06296341866254807
Validation loss: 1.4309046620963721

Epoch: 6| Step: 13
Training loss: 0.08780279010534286
Validation loss: 1.4443834814974057

Epoch: 610| Step: 0
Training loss: 0.057805947959423065
Validation loss: 1.4356196657303841

Epoch: 6| Step: 1
Training loss: 0.06734432280063629
Validation loss: 1.4726788959195536

Epoch: 6| Step: 2
Training loss: 0.04600302129983902
Validation loss: 1.4269424779440767

Epoch: 6| Step: 3
Training loss: 0.07135139405727386
Validation loss: 1.4085766673088074

Epoch: 6| Step: 4
Training loss: 0.06544680893421173
Validation loss: 1.4202530217427078

Epoch: 6| Step: 5
Training loss: 0.08374190330505371
Validation loss: 1.4084190245597594

Epoch: 6| Step: 6
Training loss: 0.07391080260276794
Validation loss: 1.4196008995015135

Epoch: 6| Step: 7
Training loss: 0.05452539771795273
Validation loss: 1.4324826053393784

Epoch: 6| Step: 8
Training loss: 0.07406466454267502
Validation loss: 1.4172224197336423

Epoch: 6| Step: 9
Training loss: 0.08847388625144958
Validation loss: 1.4062804957871795

Epoch: 6| Step: 10
Training loss: 0.06443198025226593
Validation loss: 1.4258544483492452

Epoch: 6| Step: 11
Training loss: 0.03937182202935219
Validation loss: 1.4365299030016827

Epoch: 6| Step: 12
Training loss: 0.03721640631556511
Validation loss: 1.4377524250297136

Epoch: 6| Step: 13
Training loss: 0.07346349209547043
Validation loss: 1.4466222486188334

Epoch: 611| Step: 0
Training loss: 0.06077183037996292
Validation loss: 1.4462367155218636

Epoch: 6| Step: 1
Training loss: 0.055482082068920135
Validation loss: 1.4615111504831622

Epoch: 6| Step: 2
Training loss: 0.08933573961257935
Validation loss: 1.4524100031903995

Epoch: 6| Step: 3
Training loss: 0.047702111303806305
Validation loss: 1.4486525167701065

Epoch: 6| Step: 4
Training loss: 0.04519985243678093
Validation loss: 1.4520947446105301

Epoch: 6| Step: 5
Training loss: 0.039604343473911285
Validation loss: 1.465810417488057

Epoch: 6| Step: 6
Training loss: 0.07375221699476242
Validation loss: 1.4614344527644496

Epoch: 6| Step: 7
Training loss: 0.06700922548770905
Validation loss: 1.4534566197344052

Epoch: 6| Step: 8
Training loss: 0.05806758999824524
Validation loss: 1.449794848759969

Epoch: 6| Step: 9
Training loss: 0.06669896095991135
Validation loss: 1.4340869226763326

Epoch: 6| Step: 10
Training loss: 0.0848580002784729
Validation loss: 1.4458874297398392

Epoch: 6| Step: 11
Training loss: 0.08522714674472809
Validation loss: 1.4566644635251773

Epoch: 6| Step: 12
Training loss: 0.05367853865027428
Validation loss: 1.441728703437313

Epoch: 6| Step: 13
Training loss: 0.07067114114761353
Validation loss: 1.4412762259924283

Epoch: 612| Step: 0
Training loss: 0.05346354842185974
Validation loss: 1.4082878302502375

Epoch: 6| Step: 1
Training loss: 0.06027033179998398
Validation loss: 1.4327620831868981

Epoch: 6| Step: 2
Training loss: 0.033520471304655075
Validation loss: 1.4263379561003817

Epoch: 6| Step: 3
Training loss: 0.033796221017837524
Validation loss: 1.443644199320065

Epoch: 6| Step: 4
Training loss: 0.07108297199010849
Validation loss: 1.4375118914470877

Epoch: 6| Step: 5
Training loss: 0.06638826429843903
Validation loss: 1.4589892702717935

Epoch: 6| Step: 6
Training loss: 0.09465146064758301
Validation loss: 1.4362799685488465

Epoch: 6| Step: 7
Training loss: 0.052860114723443985
Validation loss: 1.4324773447487944

Epoch: 6| Step: 8
Training loss: 0.060537658631801605
Validation loss: 1.4624723016574819

Epoch: 6| Step: 9
Training loss: 0.05443410202860832
Validation loss: 1.44582796994076

Epoch: 6| Step: 10
Training loss: 0.05071776360273361
Validation loss: 1.4484043204656212

Epoch: 6| Step: 11
Training loss: 0.06709453463554382
Validation loss: 1.4409823661209435

Epoch: 6| Step: 12
Training loss: 0.051233552396297455
Validation loss: 1.4411908580410866

Epoch: 6| Step: 13
Training loss: 0.029882285743951797
Validation loss: 1.4580673299809939

Epoch: 613| Step: 0
Training loss: 0.058331117033958435
Validation loss: 1.4414834053285661

Epoch: 6| Step: 1
Training loss: 0.04220841825008392
Validation loss: 1.4252140111820673

Epoch: 6| Step: 2
Training loss: 0.04221482574939728
Validation loss: 1.4464986029491629

Epoch: 6| Step: 3
Training loss: 0.05474939942359924
Validation loss: 1.439581198077048

Epoch: 6| Step: 4
Training loss: 0.05363479256629944
Validation loss: 1.4648184750669746

Epoch: 6| Step: 5
Training loss: 0.03727501630783081
Validation loss: 1.4540178416877665

Epoch: 6| Step: 6
Training loss: 0.07275927066802979
Validation loss: 1.4712942325940697

Epoch: 6| Step: 7
Training loss: 0.042333029210567474
Validation loss: 1.4482992669587493

Epoch: 6| Step: 8
Training loss: 0.08015496283769608
Validation loss: 1.4443869795850528

Epoch: 6| Step: 9
Training loss: 0.05356183648109436
Validation loss: 1.4480520486831665

Epoch: 6| Step: 10
Training loss: 0.06675603985786438
Validation loss: 1.4379627281619656

Epoch: 6| Step: 11
Training loss: 0.07594709098339081
Validation loss: 1.4435614078275618

Epoch: 6| Step: 12
Training loss: 0.03782058134675026
Validation loss: 1.4256547227982552

Epoch: 6| Step: 13
Training loss: 0.031928617507219315
Validation loss: 1.4156624694024362

Epoch: 614| Step: 0
Training loss: 0.060927554965019226
Validation loss: 1.4147515213617714

Epoch: 6| Step: 1
Training loss: 0.044564761221408844
Validation loss: 1.406808840331211

Epoch: 6| Step: 2
Training loss: 0.055314257740974426
Validation loss: 1.4569341572382117

Epoch: 6| Step: 3
Training loss: 0.057118162512779236
Validation loss: 1.4506377577781677

Epoch: 6| Step: 4
Training loss: 0.08065396547317505
Validation loss: 1.4623136385794608

Epoch: 6| Step: 5
Training loss: 0.037329524755477905
Validation loss: 1.4423894625838085

Epoch: 6| Step: 6
Training loss: 0.052056651562452316
Validation loss: 1.473153091246082

Epoch: 6| Step: 7
Training loss: 0.03330455720424652
Validation loss: 1.4605065814910396

Epoch: 6| Step: 8
Training loss: 0.06388534605503082
Validation loss: 1.4616007676688574

Epoch: 6| Step: 9
Training loss: 0.06591526418924332
Validation loss: 1.439628734383532

Epoch: 6| Step: 10
Training loss: 0.03546250984072685
Validation loss: 1.45902620848789

Epoch: 6| Step: 11
Training loss: 0.08808379620313644
Validation loss: 1.446304121325093

Epoch: 6| Step: 12
Training loss: 0.07994700223207474
Validation loss: 1.453839700709107

Epoch: 6| Step: 13
Training loss: 0.0737868919968605
Validation loss: 1.452680681341438

Epoch: 615| Step: 0
Training loss: 0.06490270793437958
Validation loss: 1.4492435660413516

Epoch: 6| Step: 1
Training loss: 0.07031179219484329
Validation loss: 1.4522326223311885

Epoch: 6| Step: 2
Training loss: 0.08257020264863968
Validation loss: 1.4345282694344879

Epoch: 6| Step: 3
Training loss: 0.07363229990005493
Validation loss: 1.450713352490497

Epoch: 6| Step: 4
Training loss: 0.04181993380188942
Validation loss: 1.4318044570184523

Epoch: 6| Step: 5
Training loss: 0.06826112419366837
Validation loss: 1.436633421528724

Epoch: 6| Step: 6
Training loss: 0.048534829169511795
Validation loss: 1.4292714980340773

Epoch: 6| Step: 7
Training loss: 0.06739383935928345
Validation loss: 1.430146849283608

Epoch: 6| Step: 8
Training loss: 0.0656576007604599
Validation loss: 1.4279930732583488

Epoch: 6| Step: 9
Training loss: 0.05207911506295204
Validation loss: 1.4476939657683014

Epoch: 6| Step: 10
Training loss: 0.0467878133058548
Validation loss: 1.4103941955874044

Epoch: 6| Step: 11
Training loss: 0.0654716044664383
Validation loss: 1.4369268776268087

Epoch: 6| Step: 12
Training loss: 0.04788810759782791
Validation loss: 1.4191045620108163

Epoch: 6| Step: 13
Training loss: 0.06737689673900604
Validation loss: 1.4375525084874963

Epoch: 616| Step: 0
Training loss: 0.0613536536693573
Validation loss: 1.423687623393151

Epoch: 6| Step: 1
Training loss: 0.05083933472633362
Validation loss: 1.4263164125463015

Epoch: 6| Step: 2
Training loss: 0.05555681884288788
Validation loss: 1.4262053389703073

Epoch: 6| Step: 3
Training loss: 0.04010465741157532
Validation loss: 1.4597471157709758

Epoch: 6| Step: 4
Training loss: 0.03413588926196098
Validation loss: 1.4295422646307177

Epoch: 6| Step: 5
Training loss: 0.051459744572639465
Validation loss: 1.4401871901686474

Epoch: 6| Step: 6
Training loss: 0.040405143052339554
Validation loss: 1.4309563829052834

Epoch: 6| Step: 7
Training loss: 0.053050972521305084
Validation loss: 1.4517153334873978

Epoch: 6| Step: 8
Training loss: 0.02602456323802471
Validation loss: 1.4582675541600874

Epoch: 6| Step: 9
Training loss: 0.053030095994472504
Validation loss: 1.4328727376076482

Epoch: 6| Step: 10
Training loss: 0.04291737824678421
Validation loss: 1.4522179432453648

Epoch: 6| Step: 11
Training loss: 0.0691477432847023
Validation loss: 1.446671211591331

Epoch: 6| Step: 12
Training loss: 0.046128012239933014
Validation loss: 1.4369960779784827

Epoch: 6| Step: 13
Training loss: 0.10204559564590454
Validation loss: 1.4355649255937146

Epoch: 617| Step: 0
Training loss: 0.0421929806470871
Validation loss: 1.4418361007526357

Epoch: 6| Step: 1
Training loss: 0.06216035783290863
Validation loss: 1.4249870854039346

Epoch: 6| Step: 2
Training loss: 0.04753372445702553
Validation loss: 1.4244669906554683

Epoch: 6| Step: 3
Training loss: 0.05848868191242218
Validation loss: 1.4255076108440277

Epoch: 6| Step: 4
Training loss: 0.08636809140443802
Validation loss: 1.430088878959738

Epoch: 6| Step: 5
Training loss: 0.05559895932674408
Validation loss: 1.432284616654919

Epoch: 6| Step: 6
Training loss: 0.036093633621931076
Validation loss: 1.3933745532907464

Epoch: 6| Step: 7
Training loss: 0.04492776840925217
Validation loss: 1.423645996278332

Epoch: 6| Step: 8
Training loss: 0.10722073912620544
Validation loss: 1.4106192293987478

Epoch: 6| Step: 9
Training loss: 0.04401557147502899
Validation loss: 1.3999452962670276

Epoch: 6| Step: 10
Training loss: 0.030854644253849983
Validation loss: 1.4193202481474927

Epoch: 6| Step: 11
Training loss: 0.06551861017942429
Validation loss: 1.416018896205451

Epoch: 6| Step: 12
Training loss: 0.040509164333343506
Validation loss: 1.3971353320665256

Epoch: 6| Step: 13
Training loss: 0.06402795761823654
Validation loss: 1.4075797873158609

Epoch: 618| Step: 0
Training loss: 0.0567990317940712
Validation loss: 1.4064283874086154

Epoch: 6| Step: 1
Training loss: 0.055539023131132126
Validation loss: 1.4211758887895973

Epoch: 6| Step: 2
Training loss: 0.044565655291080475
Validation loss: 1.432059787293916

Epoch: 6| Step: 3
Training loss: 0.05574793368577957
Validation loss: 1.3987975735818186

Epoch: 6| Step: 4
Training loss: 0.07731588184833527
Validation loss: 1.423780470766047

Epoch: 6| Step: 5
Training loss: 0.06010840833187103
Validation loss: 1.4176317363656976

Epoch: 6| Step: 6
Training loss: 0.048244938254356384
Validation loss: 1.408970791806457

Epoch: 6| Step: 7
Training loss: 0.05447349324822426
Validation loss: 1.3939685642078359

Epoch: 6| Step: 8
Training loss: 0.028624752536416054
Validation loss: 1.415562295144604

Epoch: 6| Step: 9
Training loss: 0.05366870015859604
Validation loss: 1.3956706818713938

Epoch: 6| Step: 10
Training loss: 0.06049706041812897
Validation loss: 1.428667632482385

Epoch: 6| Step: 11
Training loss: 0.05705040320754051
Validation loss: 1.4124324590929094

Epoch: 6| Step: 12
Training loss: 0.10217614471912384
Validation loss: 1.3941080583039152

Epoch: 6| Step: 13
Training loss: 0.026016579940915108
Validation loss: 1.3857280977310673

Epoch: 619| Step: 0
Training loss: 0.0436672642827034
Validation loss: 1.4005118941748014

Epoch: 6| Step: 1
Training loss: 0.04809442162513733
Validation loss: 1.3808325567553121

Epoch: 6| Step: 2
Training loss: 0.02429862879216671
Validation loss: 1.3810084724938998

Epoch: 6| Step: 3
Training loss: 0.06546017527580261
Validation loss: 1.3944392973376858

Epoch: 6| Step: 4
Training loss: 0.059537723660469055
Validation loss: 1.4114904519050353

Epoch: 6| Step: 5
Training loss: 0.04073544591665268
Validation loss: 1.4235519260488532

Epoch: 6| Step: 6
Training loss: 0.04449149966239929
Validation loss: 1.4355217103035218

Epoch: 6| Step: 7
Training loss: 0.08484137058258057
Validation loss: 1.4230594160736247

Epoch: 6| Step: 8
Training loss: 0.04615289717912674
Validation loss: 1.4046026788732058

Epoch: 6| Step: 9
Training loss: 0.042394403368234634
Validation loss: 1.4199203150246733

Epoch: 6| Step: 10
Training loss: 0.04016933962702751
Validation loss: 1.3950108238445815

Epoch: 6| Step: 11
Training loss: 0.03945568948984146
Validation loss: 1.408690530766723

Epoch: 6| Step: 12
Training loss: 0.0640040785074234
Validation loss: 1.417961339796743

Epoch: 6| Step: 13
Training loss: 0.051224786788225174
Validation loss: 1.4108315078161096

Epoch: 620| Step: 0
Training loss: 0.04679886996746063
Validation loss: 1.4385854223723054

Epoch: 6| Step: 1
Training loss: 0.04050223529338837
Validation loss: 1.3995855931312806

Epoch: 6| Step: 2
Training loss: 0.047012683004140854
Validation loss: 1.4198282841713197

Epoch: 6| Step: 3
Training loss: 0.03615819662809372
Validation loss: 1.4180706444606985

Epoch: 6| Step: 4
Training loss: 0.07669875025749207
Validation loss: 1.4403113549755466

Epoch: 6| Step: 5
Training loss: 0.07022573053836823
Validation loss: 1.4303459685335878

Epoch: 6| Step: 6
Training loss: 0.06832952797412872
Validation loss: 1.434111434926269

Epoch: 6| Step: 7
Training loss: 0.07528986036777496
Validation loss: 1.423212638465307

Epoch: 6| Step: 8
Training loss: 0.032425180077552795
Validation loss: 1.4263482427084317

Epoch: 6| Step: 9
Training loss: 0.05889679118990898
Validation loss: 1.4058378152949835

Epoch: 6| Step: 10
Training loss: 0.05388624966144562
Validation loss: 1.4390289296386063

Epoch: 6| Step: 11
Training loss: 0.051379263401031494
Validation loss: 1.4532228157084475

Epoch: 6| Step: 12
Training loss: 0.0351388081908226
Validation loss: 1.4540235906518915

Epoch: 6| Step: 13
Training loss: 0.04568172246217728
Validation loss: 1.4457510799489997

Epoch: 621| Step: 0
Training loss: 0.03156982362270355
Validation loss: 1.4689008228240474

Epoch: 6| Step: 1
Training loss: 0.042408790439367294
Validation loss: 1.4894297251137354

Epoch: 6| Step: 2
Training loss: 0.05048859864473343
Validation loss: 1.4811902571749944

Epoch: 6| Step: 3
Training loss: 0.04940398037433624
Validation loss: 1.4579389864398586

Epoch: 6| Step: 4
Training loss: 0.07249037176370621
Validation loss: 1.4630128311854538

Epoch: 6| Step: 5
Training loss: 0.0662442073225975
Validation loss: 1.435359827933773

Epoch: 6| Step: 6
Training loss: 0.06283378601074219
Validation loss: 1.4433499741297897

Epoch: 6| Step: 7
Training loss: 0.038392968475818634
Validation loss: 1.4492522029466526

Epoch: 6| Step: 8
Training loss: 0.04489000141620636
Validation loss: 1.4423337956910491

Epoch: 6| Step: 9
Training loss: 0.06843316555023193
Validation loss: 1.453355368747506

Epoch: 6| Step: 10
Training loss: 0.0428922064602375
Validation loss: 1.444262981414795

Epoch: 6| Step: 11
Training loss: 0.05965724587440491
Validation loss: 1.4385160002657162

Epoch: 6| Step: 12
Training loss: 0.051824942231178284
Validation loss: 1.4330721183489727

Epoch: 6| Step: 13
Training loss: 0.04974948614835739
Validation loss: 1.4389055287966164

Epoch: 622| Step: 0
Training loss: 0.04254303127527237
Validation loss: 1.4243349503445368

Epoch: 6| Step: 1
Training loss: 0.10789434611797333
Validation loss: 1.4472487318900324

Epoch: 6| Step: 2
Training loss: 0.0713004320859909
Validation loss: 1.459901568710163

Epoch: 6| Step: 3
Training loss: 0.04787866026163101
Validation loss: 1.4467193272805983

Epoch: 6| Step: 4
Training loss: 0.043930523097515106
Validation loss: 1.4645237179212673

Epoch: 6| Step: 5
Training loss: 0.05370365083217621
Validation loss: 1.465342176857815

Epoch: 6| Step: 6
Training loss: 0.04897933080792427
Validation loss: 1.4577877444605674

Epoch: 6| Step: 7
Training loss: 0.07507007569074631
Validation loss: 1.459564378184657

Epoch: 6| Step: 8
Training loss: 0.04335961490869522
Validation loss: 1.44921044059979

Epoch: 6| Step: 9
Training loss: 0.04303615540266037
Validation loss: 1.4418002501610787

Epoch: 6| Step: 10
Training loss: 0.052199240773916245
Validation loss: 1.451123127373316

Epoch: 6| Step: 11
Training loss: 0.09069052338600159
Validation loss: 1.4337035635466218

Epoch: 6| Step: 12
Training loss: 0.0663258507847786
Validation loss: 1.418638175533664

Epoch: 6| Step: 13
Training loss: 0.04080595076084137
Validation loss: 1.4169185200045187

Epoch: 623| Step: 0
Training loss: 0.06858931481838226
Validation loss: 1.4096997348211144

Epoch: 6| Step: 1
Training loss: 0.05854502692818642
Validation loss: 1.4253544602342831

Epoch: 6| Step: 2
Training loss: 0.053699299693107605
Validation loss: 1.4136369241181241

Epoch: 6| Step: 3
Training loss: 0.06826156377792358
Validation loss: 1.4204626134646836

Epoch: 6| Step: 4
Training loss: 0.033122703433036804
Validation loss: 1.43107372009626

Epoch: 6| Step: 5
Training loss: 0.0845673456788063
Validation loss: 1.446796598613903

Epoch: 6| Step: 6
Training loss: 0.07860398292541504
Validation loss: 1.463621058130777

Epoch: 6| Step: 7
Training loss: 0.09873739629983902
Validation loss: 1.4634731802889096

Epoch: 6| Step: 8
Training loss: 0.07057254016399384
Validation loss: 1.420907461515037

Epoch: 6| Step: 9
Training loss: 0.06712359189987183
Validation loss: 1.4293609780649985

Epoch: 6| Step: 10
Training loss: 0.06800264865159988
Validation loss: 1.4307626107687592

Epoch: 6| Step: 11
Training loss: 0.09285419434309006
Validation loss: 1.443702595208281

Epoch: 6| Step: 12
Training loss: 0.06004013121128082
Validation loss: 1.452352858358814

Epoch: 6| Step: 13
Training loss: 0.11528483033180237
Validation loss: 1.4605800413316297

Epoch: 624| Step: 0
Training loss: 0.06534083932638168
Validation loss: 1.4581515840304795

Epoch: 6| Step: 1
Training loss: 0.052843738347291946
Validation loss: 1.4430299317964943

Epoch: 6| Step: 2
Training loss: 0.0491473451256752
Validation loss: 1.4310572826734154

Epoch: 6| Step: 3
Training loss: 0.060024965554475784
Validation loss: 1.4301855141116726

Epoch: 6| Step: 4
Training loss: 0.06679412722587585
Validation loss: 1.4203258791277487

Epoch: 6| Step: 5
Training loss: 0.12615349888801575
Validation loss: 1.4409775631402129

Epoch: 6| Step: 6
Training loss: 0.06726644188165665
Validation loss: 1.4516357683366345

Epoch: 6| Step: 7
Training loss: 0.08228450268507004
Validation loss: 1.4431457109348749

Epoch: 6| Step: 8
Training loss: 0.04799496382474899
Validation loss: 1.432799099594034

Epoch: 6| Step: 9
Training loss: 0.07586711645126343
Validation loss: 1.4315868218739827

Epoch: 6| Step: 10
Training loss: 0.03156144917011261
Validation loss: 1.4400372325733144

Epoch: 6| Step: 11
Training loss: 0.060920584946870804
Validation loss: 1.4250141946218347

Epoch: 6| Step: 12
Training loss: 0.056413520127534866
Validation loss: 1.4447041929409068

Epoch: 6| Step: 13
Training loss: 0.10206656903028488
Validation loss: 1.41870682021623

Epoch: 625| Step: 0
Training loss: 0.08669324964284897
Validation loss: 1.4206623120974469

Epoch: 6| Step: 1
Training loss: 0.08445227891206741
Validation loss: 1.4125167272424186

Epoch: 6| Step: 2
Training loss: 0.07156325876712799
Validation loss: 1.415406939803913

Epoch: 6| Step: 3
Training loss: 0.05701896548271179
Validation loss: 1.4187822540601094

Epoch: 6| Step: 4
Training loss: 0.05431034415960312
Validation loss: 1.401734745630654

Epoch: 6| Step: 5
Training loss: 0.09421229362487793
Validation loss: 1.3911879101107198

Epoch: 6| Step: 6
Training loss: 0.04493563622236252
Validation loss: 1.3829128614035986

Epoch: 6| Step: 7
Training loss: 0.05085145682096481
Validation loss: 1.400732426233189

Epoch: 6| Step: 8
Training loss: 0.05350017547607422
Validation loss: 1.4139693437084075

Epoch: 6| Step: 9
Training loss: 0.04280480742454529
Validation loss: 1.4328820923323273

Epoch: 6| Step: 10
Training loss: 0.038955412805080414
Validation loss: 1.4161109757679764

Epoch: 6| Step: 11
Training loss: 0.05435051769018173
Validation loss: 1.4301338400892032

Epoch: 6| Step: 12
Training loss: 0.04093209654092789
Validation loss: 1.4266020963268895

Epoch: 6| Step: 13
Training loss: 0.09303571283817291
Validation loss: 1.4307801877298663

Epoch: 626| Step: 0
Training loss: 0.04758961498737335
Validation loss: 1.4293324357719832

Epoch: 6| Step: 1
Training loss: 0.03639703989028931
Validation loss: 1.43436550453145

Epoch: 6| Step: 2
Training loss: 0.050967343151569366
Validation loss: 1.4085706985124977

Epoch: 6| Step: 3
Training loss: 0.078135184943676
Validation loss: 1.4309610077129897

Epoch: 6| Step: 4
Training loss: 0.042034003883600235
Validation loss: 1.4211402067574121

Epoch: 6| Step: 5
Training loss: 0.06520301103591919
Validation loss: 1.4082035999144278

Epoch: 6| Step: 6
Training loss: 0.04893701896071434
Validation loss: 1.4184400894308602

Epoch: 6| Step: 7
Training loss: 0.07185926288366318
Validation loss: 1.4286025519012122

Epoch: 6| Step: 8
Training loss: 0.05443381518125534
Validation loss: 1.4083057923983502

Epoch: 6| Step: 9
Training loss: 0.06295046210289001
Validation loss: 1.447909350036293

Epoch: 6| Step: 10
Training loss: 0.04034847021102905
Validation loss: 1.4151699696817706

Epoch: 6| Step: 11
Training loss: 0.03122614324092865
Validation loss: 1.4228961942016438

Epoch: 6| Step: 12
Training loss: 0.05811329558491707
Validation loss: 1.4467737674713135

Epoch: 6| Step: 13
Training loss: 0.060485534369945526
Validation loss: 1.4312117074125557

Epoch: 627| Step: 0
Training loss: 0.06761743128299713
Validation loss: 1.4551476509340349

Epoch: 6| Step: 1
Training loss: 0.10242786258459091
Validation loss: 1.4473870287659347

Epoch: 6| Step: 2
Training loss: 0.08435111492872238
Validation loss: 1.4954629790398382

Epoch: 6| Step: 3
Training loss: 0.04699086770415306
Validation loss: 1.4863515233480802

Epoch: 6| Step: 4
Training loss: 0.056161049753427505
Validation loss: 1.4684508897924935

Epoch: 6| Step: 5
Training loss: 0.06020067632198334
Validation loss: 1.4698467062365623

Epoch: 6| Step: 6
Training loss: 0.0627533346414566
Validation loss: 1.4735979572419198

Epoch: 6| Step: 7
Training loss: 0.054250579327344894
Validation loss: 1.444048967412723

Epoch: 6| Step: 8
Training loss: 0.04343481734395027
Validation loss: 1.4528422599197717

Epoch: 6| Step: 9
Training loss: 0.04985271021723747
Validation loss: 1.447376307620797

Epoch: 6| Step: 10
Training loss: 0.08159685134887695
Validation loss: 1.4413300560366722

Epoch: 6| Step: 11
Training loss: 0.04529668390750885
Validation loss: 1.4618047706542476

Epoch: 6| Step: 12
Training loss: 0.08754116296768188
Validation loss: 1.4362898606766936

Epoch: 6| Step: 13
Training loss: 0.0842919647693634
Validation loss: 1.4896972820323

Epoch: 628| Step: 0
Training loss: 0.029339458793401718
Validation loss: 1.4772310115957772

Epoch: 6| Step: 1
Training loss: 0.054575853049755096
Validation loss: 1.4527169542927896

Epoch: 6| Step: 2
Training loss: 0.06406406313180923
Validation loss: 1.4328587721752863

Epoch: 6| Step: 3
Training loss: 0.07473629713058472
Validation loss: 1.4311649850619736

Epoch: 6| Step: 4
Training loss: 0.0408562496304512
Validation loss: 1.4398926483687533

Epoch: 6| Step: 5
Training loss: 0.05941750109195709
Validation loss: 1.4304485897864065

Epoch: 6| Step: 6
Training loss: 0.07227969169616699
Validation loss: 1.4491343472593574

Epoch: 6| Step: 7
Training loss: 0.024448484182357788
Validation loss: 1.4193605056373022

Epoch: 6| Step: 8
Training loss: 0.03386439383029938
Validation loss: 1.4246377291217927

Epoch: 6| Step: 9
Training loss: 0.06003279983997345
Validation loss: 1.4323625872212071

Epoch: 6| Step: 10
Training loss: 0.07833415269851685
Validation loss: 1.4275720683477258

Epoch: 6| Step: 11
Training loss: 0.06917979568243027
Validation loss: 1.418174079669419

Epoch: 6| Step: 12
Training loss: 0.06794651597738266
Validation loss: 1.4073686676640664

Epoch: 6| Step: 13
Training loss: 0.08659163862466812
Validation loss: 1.4182967755102343

Epoch: 629| Step: 0
Training loss: 0.053791485726833344
Validation loss: 1.3944571774492982

Epoch: 6| Step: 1
Training loss: 0.07846535742282867
Validation loss: 1.442007633947557

Epoch: 6| Step: 2
Training loss: 0.05836719274520874
Validation loss: 1.4369557839567944

Epoch: 6| Step: 3
Training loss: 0.07515191286802292
Validation loss: 1.4224313241179272

Epoch: 6| Step: 4
Training loss: 0.07977902889251709
Validation loss: 1.4308655095356766

Epoch: 6| Step: 5
Training loss: 0.04337601363658905
Validation loss: 1.4628638016280306

Epoch: 6| Step: 6
Training loss: 0.04344487190246582
Validation loss: 1.4414014893193399

Epoch: 6| Step: 7
Training loss: 0.0443301722407341
Validation loss: 1.4297515448703562

Epoch: 6| Step: 8
Training loss: 0.0473722442984581
Validation loss: 1.4721246598869242

Epoch: 6| Step: 9
Training loss: 0.03175891190767288
Validation loss: 1.4307004341515162

Epoch: 6| Step: 10
Training loss: 0.06065791845321655
Validation loss: 1.4296591948437434

Epoch: 6| Step: 11
Training loss: 0.0838870033621788
Validation loss: 1.4510864288576188

Epoch: 6| Step: 12
Training loss: 0.078799769282341
Validation loss: 1.421209369936297

Epoch: 6| Step: 13
Training loss: 0.05735868960618973
Validation loss: 1.420574975270097

Epoch: 630| Step: 0
Training loss: 0.04461507871747017
Validation loss: 1.4183323075694423

Epoch: 6| Step: 1
Training loss: 0.04765642434358597
Validation loss: 1.4095221065705823

Epoch: 6| Step: 2
Training loss: 0.05499263107776642
Validation loss: 1.4075355286239295

Epoch: 6| Step: 3
Training loss: 0.03969503939151764
Validation loss: 1.400302061470606

Epoch: 6| Step: 4
Training loss: 0.05006636306643486
Validation loss: 1.41949374188659

Epoch: 6| Step: 5
Training loss: 0.07161777466535568
Validation loss: 1.4076029908272527

Epoch: 6| Step: 6
Training loss: 0.05372927337884903
Validation loss: 1.409851989438457

Epoch: 6| Step: 7
Training loss: 0.073009192943573
Validation loss: 1.4183599211836373

Epoch: 6| Step: 8
Training loss: 0.05123105272650719
Validation loss: 1.4226958777314873

Epoch: 6| Step: 9
Training loss: 0.061427660286426544
Validation loss: 1.4279900596987816

Epoch: 6| Step: 10
Training loss: 0.05324342101812363
Validation loss: 1.4564495394306798

Epoch: 6| Step: 11
Training loss: 0.05466000735759735
Validation loss: 1.4491846407613447

Epoch: 6| Step: 12
Training loss: 0.05377382040023804
Validation loss: 1.4666879907731087

Epoch: 6| Step: 13
Training loss: 0.10598365217447281
Validation loss: 1.4583453568079139

Epoch: 631| Step: 0
Training loss: 0.041176892817020416
Validation loss: 1.4554971520618727

Epoch: 6| Step: 1
Training loss: 0.12096136808395386
Validation loss: 1.4728045668653262

Epoch: 6| Step: 2
Training loss: 0.057587772607803345
Validation loss: 1.467156094889487

Epoch: 6| Step: 3
Training loss: 0.04132058843970299
Validation loss: 1.4595117991970432

Epoch: 6| Step: 4
Training loss: 0.04021956026554108
Validation loss: 1.4468123323173934

Epoch: 6| Step: 5
Training loss: 0.04866214841604233
Validation loss: 1.453751919090107

Epoch: 6| Step: 6
Training loss: 0.051873378455638885
Validation loss: 1.4440959217727825

Epoch: 6| Step: 7
Training loss: 0.04999219998717308
Validation loss: 1.4478352095491143

Epoch: 6| Step: 8
Training loss: 0.05465187877416611
Validation loss: 1.442845432989059

Epoch: 6| Step: 9
Training loss: 0.056308940052986145
Validation loss: 1.4302562834114156

Epoch: 6| Step: 10
Training loss: 0.0686177909374237
Validation loss: 1.420989950497945

Epoch: 6| Step: 11
Training loss: 0.06227490305900574
Validation loss: 1.4372165190276278

Epoch: 6| Step: 12
Training loss: 0.05611561983823776
Validation loss: 1.4466398646754604

Epoch: 6| Step: 13
Training loss: 0.05421006679534912
Validation loss: 1.4335558709277902

Epoch: 632| Step: 0
Training loss: 0.07857580482959747
Validation loss: 1.4378496523826354

Epoch: 6| Step: 1
Training loss: 0.055271342396736145
Validation loss: 1.4125894577272478

Epoch: 6| Step: 2
Training loss: 0.05589611083269119
Validation loss: 1.4030633126535723

Epoch: 6| Step: 3
Training loss: 0.07685000449419022
Validation loss: 1.3937662391252414

Epoch: 6| Step: 4
Training loss: 0.05681789666414261
Validation loss: 1.40835948464691

Epoch: 6| Step: 5
Training loss: 0.05555160716176033
Validation loss: 1.417944017276969

Epoch: 6| Step: 6
Training loss: 0.04199809581041336
Validation loss: 1.4051384695114628

Epoch: 6| Step: 7
Training loss: 0.02938736230134964
Validation loss: 1.415409754681331

Epoch: 6| Step: 8
Training loss: 0.06266079843044281
Validation loss: 1.440626641755463

Epoch: 6| Step: 9
Training loss: 0.04971322417259216
Validation loss: 1.4204254554164024

Epoch: 6| Step: 10
Training loss: 0.07769931107759476
Validation loss: 1.421212560387068

Epoch: 6| Step: 11
Training loss: 0.060168638825416565
Validation loss: 1.4307584544663787

Epoch: 6| Step: 12
Training loss: 0.04877719655632973
Validation loss: 1.4101802123490201

Epoch: 6| Step: 13
Training loss: 0.051762983202934265
Validation loss: 1.4369487659905547

Epoch: 633| Step: 0
Training loss: 0.07711571455001831
Validation loss: 1.4279586512555358

Epoch: 6| Step: 1
Training loss: 0.07340851426124573
Validation loss: 1.4376691105545207

Epoch: 6| Step: 2
Training loss: 0.06096990406513214
Validation loss: 1.4337934678600681

Epoch: 6| Step: 3
Training loss: 0.04562082141637802
Validation loss: 1.436400685259091

Epoch: 6| Step: 4
Training loss: 0.03436046466231346
Validation loss: 1.4367574658445132

Epoch: 6| Step: 5
Training loss: 0.052668437361717224
Validation loss: 1.4277266827962731

Epoch: 6| Step: 6
Training loss: 0.06276829540729523
Validation loss: 1.4382761063114289

Epoch: 6| Step: 7
Training loss: 0.03037853166460991
Validation loss: 1.430123358644465

Epoch: 6| Step: 8
Training loss: 0.0909503847360611
Validation loss: 1.44418002072201

Epoch: 6| Step: 9
Training loss: 0.04413187503814697
Validation loss: 1.4369284286293933

Epoch: 6| Step: 10
Training loss: 0.07885809242725372
Validation loss: 1.4095349465647051

Epoch: 6| Step: 11
Training loss: 0.04537251964211464
Validation loss: 1.4339042120082404

Epoch: 6| Step: 12
Training loss: 0.07875469326972961
Validation loss: 1.4432562333281322

Epoch: 6| Step: 13
Training loss: 0.05153464153409004
Validation loss: 1.4365748564402263

Epoch: 634| Step: 0
Training loss: 0.05760348588228226
Validation loss: 1.4445774830797666

Epoch: 6| Step: 1
Training loss: 0.05548739433288574
Validation loss: 1.4376498114678167

Epoch: 6| Step: 2
Training loss: 0.039054982364177704
Validation loss: 1.4533775468026437

Epoch: 6| Step: 3
Training loss: 0.050027504563331604
Validation loss: 1.4396953323195059

Epoch: 6| Step: 4
Training loss: 0.03566548600792885
Validation loss: 1.4432876545895812

Epoch: 6| Step: 5
Training loss: 0.029520226642489433
Validation loss: 1.4358282178960822

Epoch: 6| Step: 6
Training loss: 0.0311387050896883
Validation loss: 1.4384492315271848

Epoch: 6| Step: 7
Training loss: 0.0702761635184288
Validation loss: 1.4505465069124777

Epoch: 6| Step: 8
Training loss: 0.06663716584444046
Validation loss: 1.4365731080373128

Epoch: 6| Step: 9
Training loss: 0.05442829430103302
Validation loss: 1.435874826164656

Epoch: 6| Step: 10
Training loss: 0.07389646023511887
Validation loss: 1.4314353953125656

Epoch: 6| Step: 11
Training loss: 0.0723719671368599
Validation loss: 1.420246599182006

Epoch: 6| Step: 12
Training loss: 0.07034700363874435
Validation loss: 1.4094756803204935

Epoch: 6| Step: 13
Training loss: 0.042649347335100174
Validation loss: 1.4200089016268331

Epoch: 635| Step: 0
Training loss: 0.05771738290786743
Validation loss: 1.4191422097144588

Epoch: 6| Step: 1
Training loss: 0.03510469198226929
Validation loss: 1.4112135966618855

Epoch: 6| Step: 2
Training loss: 0.044990748167037964
Validation loss: 1.3881245736152894

Epoch: 6| Step: 3
Training loss: 0.051792245358228683
Validation loss: 1.3899776230576217

Epoch: 6| Step: 4
Training loss: 0.054173678159713745
Validation loss: 1.4155427050846878

Epoch: 6| Step: 5
Training loss: 0.045299410820007324
Validation loss: 1.4122778555398345

Epoch: 6| Step: 6
Training loss: 0.03218837454915047
Validation loss: 1.406504000386884

Epoch: 6| Step: 7
Training loss: 0.0558161586523056
Validation loss: 1.4090009094566427

Epoch: 6| Step: 8
Training loss: 0.035649918019771576
Validation loss: 1.3873164076958933

Epoch: 6| Step: 9
Training loss: 0.06233552098274231
Validation loss: 1.4171406722837878

Epoch: 6| Step: 10
Training loss: 0.05679624527692795
Validation loss: 1.4169358091969644

Epoch: 6| Step: 11
Training loss: 0.0910249873995781
Validation loss: 1.4267207166200042

Epoch: 6| Step: 12
Training loss: 0.06603090465068817
Validation loss: 1.4329448425641624

Epoch: 6| Step: 13
Training loss: 0.057427406311035156
Validation loss: 1.3982363952103483

Epoch: 636| Step: 0
Training loss: 0.061539679765701294
Validation loss: 1.4050750770876486

Epoch: 6| Step: 1
Training loss: 0.04310674965381622
Validation loss: 1.404200086029627

Epoch: 6| Step: 2
Training loss: 0.030000489205121994
Validation loss: 1.3938010623378139

Epoch: 6| Step: 3
Training loss: 0.05202160030603409
Validation loss: 1.4182150697195401

Epoch: 6| Step: 4
Training loss: 0.060471341013908386
Validation loss: 1.419570343468779

Epoch: 6| Step: 5
Training loss: 0.059458088129758835
Validation loss: 1.4225363539111229

Epoch: 6| Step: 6
Training loss: 0.04798576235771179
Validation loss: 1.4382960511151182

Epoch: 6| Step: 7
Training loss: 0.046320341527462006
Validation loss: 1.4270993727509693

Epoch: 6| Step: 8
Training loss: 0.054313741624355316
Validation loss: 1.4269473091248543

Epoch: 6| Step: 9
Training loss: 0.03602908179163933
Validation loss: 1.450498427114179

Epoch: 6| Step: 10
Training loss: 0.05183827131986618
Validation loss: 1.4324076034689461

Epoch: 6| Step: 11
Training loss: 0.08490855991840363
Validation loss: 1.4466912310610536

Epoch: 6| Step: 12
Training loss: 0.05029040575027466
Validation loss: 1.413079104115886

Epoch: 6| Step: 13
Training loss: 0.03509514033794403
Validation loss: 1.439931236287599

Epoch: 637| Step: 0
Training loss: 0.043228331953287125
Validation loss: 1.423048803883214

Epoch: 6| Step: 1
Training loss: 0.04404641315340996
Validation loss: 1.418300159515873

Epoch: 6| Step: 2
Training loss: 0.07619983702898026
Validation loss: 1.4166763123645578

Epoch: 6| Step: 3
Training loss: 0.0599302276968956
Validation loss: 1.4184170871652582

Epoch: 6| Step: 4
Training loss: 0.04774428531527519
Validation loss: 1.4037670666171658

Epoch: 6| Step: 5
Training loss: 0.07090601325035095
Validation loss: 1.4290073565257493

Epoch: 6| Step: 6
Training loss: 0.040386900305747986
Validation loss: 1.4152348458126027

Epoch: 6| Step: 7
Training loss: 0.0354873463511467
Validation loss: 1.4300117902858283

Epoch: 6| Step: 8
Training loss: 0.07263384759426117
Validation loss: 1.425741357188071

Epoch: 6| Step: 9
Training loss: 0.10080983489751816
Validation loss: 1.4513257927792047

Epoch: 6| Step: 10
Training loss: 0.05900624021887779
Validation loss: 1.4585503467949488

Epoch: 6| Step: 11
Training loss: 0.06553605198860168
Validation loss: 1.439262540109696

Epoch: 6| Step: 12
Training loss: 0.07905666530132294
Validation loss: 1.4397061588943645

Epoch: 6| Step: 13
Training loss: 0.02734968811273575
Validation loss: 1.4141857906054425

Epoch: 638| Step: 0
Training loss: 0.042293623089790344
Validation loss: 1.4226939678192139

Epoch: 6| Step: 1
Training loss: 0.047047313302755356
Validation loss: 1.439164976919851

Epoch: 6| Step: 2
Training loss: 0.049732983112335205
Validation loss: 1.4188418157639042

Epoch: 6| Step: 3
Training loss: 0.06414033472537994
Validation loss: 1.4107261992269946

Epoch: 6| Step: 4
Training loss: 0.0775633156299591
Validation loss: 1.4109212929202664

Epoch: 6| Step: 5
Training loss: 0.04571034014225006
Validation loss: 1.395895315434343

Epoch: 6| Step: 6
Training loss: 0.055546604096889496
Validation loss: 1.406744558324096

Epoch: 6| Step: 7
Training loss: 0.03861121088266373
Validation loss: 1.399586207764123

Epoch: 6| Step: 8
Training loss: 0.06993872672319412
Validation loss: 1.3867362712019233

Epoch: 6| Step: 9
Training loss: 0.08176412433385849
Validation loss: 1.399965586200837

Epoch: 6| Step: 10
Training loss: 0.05410926789045334
Validation loss: 1.420410983024105

Epoch: 6| Step: 11
Training loss: 0.08116907626390457
Validation loss: 1.407643101548636

Epoch: 6| Step: 12
Training loss: 0.06414467096328735
Validation loss: 1.4277018500912575

Epoch: 6| Step: 13
Training loss: 0.05481385067105293
Validation loss: 1.4096395136207662

Epoch: 639| Step: 0
Training loss: 0.05462103337049484
Validation loss: 1.3840580832573675

Epoch: 6| Step: 1
Training loss: 0.057166047394275665
Validation loss: 1.421156785821402

Epoch: 6| Step: 2
Training loss: 0.06816615909337997
Validation loss: 1.423941998071568

Epoch: 6| Step: 3
Training loss: 0.03695884346961975
Validation loss: 1.4311387321000457

Epoch: 6| Step: 4
Training loss: 0.06926396489143372
Validation loss: 1.4408039521145564

Epoch: 6| Step: 5
Training loss: 0.048124223947525024
Validation loss: 1.4532804566044961

Epoch: 6| Step: 6
Training loss: 0.04456116259098053
Validation loss: 1.4841938659708986

Epoch: 6| Step: 7
Training loss: 0.051957495510578156
Validation loss: 1.4630932577194706

Epoch: 6| Step: 8
Training loss: 0.05696350336074829
Validation loss: 1.4861181333500852

Epoch: 6| Step: 9
Training loss: 0.07525359094142914
Validation loss: 1.4955143864436815

Epoch: 6| Step: 10
Training loss: 0.07245202362537384
Validation loss: 1.4860216814984557

Epoch: 6| Step: 11
Training loss: 0.0418052077293396
Validation loss: 1.476258635520935

Epoch: 6| Step: 12
Training loss: 0.07913898676633835
Validation loss: 1.4538736484384025

Epoch: 6| Step: 13
Training loss: 0.04260756075382233
Validation loss: 1.4466043531253774

Epoch: 640| Step: 0
Training loss: 0.07496345043182373
Validation loss: 1.4520557388182609

Epoch: 6| Step: 1
Training loss: 0.05689951777458191
Validation loss: 1.453831317604229

Epoch: 6| Step: 2
Training loss: 0.06616093218326569
Validation loss: 1.4374882431440457

Epoch: 6| Step: 3
Training loss: 0.0352579802274704
Validation loss: 1.4363845317594466

Epoch: 6| Step: 4
Training loss: 0.0541866198182106
Validation loss: 1.4280813022326397

Epoch: 6| Step: 5
Training loss: 0.051997579634189606
Validation loss: 1.4196195448598554

Epoch: 6| Step: 6
Training loss: 0.06312509626150131
Validation loss: 1.4375193208776496

Epoch: 6| Step: 7
Training loss: 0.0649639293551445
Validation loss: 1.4123151456156084

Epoch: 6| Step: 8
Training loss: 0.05477052181959152
Validation loss: 1.402150320750411

Epoch: 6| Step: 9
Training loss: 0.03580232337117195
Validation loss: 1.4440423897517625

Epoch: 6| Step: 10
Training loss: 0.046854667365550995
Validation loss: 1.426342369407736

Epoch: 6| Step: 11
Training loss: 0.09889836609363556
Validation loss: 1.4494901773750142

Epoch: 6| Step: 12
Training loss: 0.059731196612119675
Validation loss: 1.456531798967751

Epoch: 6| Step: 13
Training loss: 0.041015107184648514
Validation loss: 1.4733001955093876

Epoch: 641| Step: 0
Training loss: 0.03939632326364517
Validation loss: 1.4821383389093543

Epoch: 6| Step: 1
Training loss: 0.0713830292224884
Validation loss: 1.4752131456969886

Epoch: 6| Step: 2
Training loss: 0.08065475523471832
Validation loss: 1.4541744673123924

Epoch: 6| Step: 3
Training loss: 0.03793622553348541
Validation loss: 1.453298027797412

Epoch: 6| Step: 4
Training loss: 0.06542764604091644
Validation loss: 1.462519380354112

Epoch: 6| Step: 5
Training loss: 0.0330444797873497
Validation loss: 1.430048845147574

Epoch: 6| Step: 6
Training loss: 0.0639764815568924
Validation loss: 1.4570441733124435

Epoch: 6| Step: 7
Training loss: 0.03394557908177376
Validation loss: 1.4437252436914751

Epoch: 6| Step: 8
Training loss: 0.04993443191051483
Validation loss: 1.452007543656134

Epoch: 6| Step: 9
Training loss: 0.036175087094306946
Validation loss: 1.4561179825054702

Epoch: 6| Step: 10
Training loss: 0.08043555915355682
Validation loss: 1.4268992088174308

Epoch: 6| Step: 11
Training loss: 0.06730829179286957
Validation loss: 1.440835629740069

Epoch: 6| Step: 12
Training loss: 0.05688716471195221
Validation loss: 1.4778766388534217

Epoch: 6| Step: 13
Training loss: 0.04655659943819046
Validation loss: 1.4624911354434105

Epoch: 642| Step: 0
Training loss: 0.04120096564292908
Validation loss: 1.4711252386851976

Epoch: 6| Step: 1
Training loss: 0.05764145031571388
Validation loss: 1.4780604621415496

Epoch: 6| Step: 2
Training loss: 0.046420030295848846
Validation loss: 1.4649727286831025

Epoch: 6| Step: 3
Training loss: 0.056405484676361084
Validation loss: 1.4969788469294065

Epoch: 6| Step: 4
Training loss: 0.03155647963285446
Validation loss: 1.496679417548641

Epoch: 6| Step: 5
Training loss: 0.09595461934804916
Validation loss: 1.4874388120507682

Epoch: 6| Step: 6
Training loss: 0.07415135949850082
Validation loss: 1.468096689511371

Epoch: 6| Step: 7
Training loss: 0.06973770260810852
Validation loss: 1.4817108204287868

Epoch: 6| Step: 8
Training loss: 0.06149672716856003
Validation loss: 1.485486538179459

Epoch: 6| Step: 9
Training loss: 0.07546143978834152
Validation loss: 1.4615162239279798

Epoch: 6| Step: 10
Training loss: 0.06470680236816406
Validation loss: 1.473182447494999

Epoch: 6| Step: 11
Training loss: 0.038676097989082336
Validation loss: 1.4826255434302873

Epoch: 6| Step: 12
Training loss: 0.039587512612342834
Validation loss: 1.4637078687708864

Epoch: 6| Step: 13
Training loss: 0.06529168039560318
Validation loss: 1.4437270638763264

Epoch: 643| Step: 0
Training loss: 0.05497756600379944
Validation loss: 1.4607515617083477

Epoch: 6| Step: 1
Training loss: 0.08794107288122177
Validation loss: 1.4375599007452688

Epoch: 6| Step: 2
Training loss: 0.07018913328647614
Validation loss: 1.4819800238455496

Epoch: 6| Step: 3
Training loss: 0.07405203580856323
Validation loss: 1.478529966005715

Epoch: 6| Step: 4
Training loss: 0.06819524616003036
Validation loss: 1.4448223742105628

Epoch: 6| Step: 5
Training loss: 0.08246805518865585
Validation loss: 1.4451003766828967

Epoch: 6| Step: 6
Training loss: 0.04821768403053284
Validation loss: 1.444224149950089

Epoch: 6| Step: 7
Training loss: 0.08256936073303223
Validation loss: 1.439545887772755

Epoch: 6| Step: 8
Training loss: 0.04456581920385361
Validation loss: 1.4400357315617223

Epoch: 6| Step: 9
Training loss: 0.04268829524517059
Validation loss: 1.4271805978590442

Epoch: 6| Step: 10
Training loss: 0.04715204983949661
Validation loss: 1.4389563504085745

Epoch: 6| Step: 11
Training loss: 0.06570896506309509
Validation loss: 1.4486019457540205

Epoch: 6| Step: 12
Training loss: 0.053140148520469666
Validation loss: 1.43872159014466

Epoch: 6| Step: 13
Training loss: 0.037002310156822205
Validation loss: 1.457568617277248

Epoch: 644| Step: 0
Training loss: 0.05931210517883301
Validation loss: 1.4302766681999288

Epoch: 6| Step: 1
Training loss: 0.05996750295162201
Validation loss: 1.4445514678955078

Epoch: 6| Step: 2
Training loss: 0.06851007044315338
Validation loss: 1.4140001227778773

Epoch: 6| Step: 3
Training loss: 0.0776948481798172
Validation loss: 1.4455872620305708

Epoch: 6| Step: 4
Training loss: 0.07318216562271118
Validation loss: 1.4668317725581508

Epoch: 6| Step: 5
Training loss: 0.05294831097126007
Validation loss: 1.4499083078035744

Epoch: 6| Step: 6
Training loss: 0.08246077597141266
Validation loss: 1.446113395434554

Epoch: 6| Step: 7
Training loss: 0.05309984087944031
Validation loss: 1.444404055995326

Epoch: 6| Step: 8
Training loss: 0.03839201480150223
Validation loss: 1.413115744949669

Epoch: 6| Step: 9
Training loss: 0.04077249765396118
Validation loss: 1.4202277250187372

Epoch: 6| Step: 10
Training loss: 0.06500491499900818
Validation loss: 1.4005024548499816

Epoch: 6| Step: 11
Training loss: 0.05085594952106476
Validation loss: 1.4050984382629395

Epoch: 6| Step: 12
Training loss: 0.07332652807235718
Validation loss: 1.3808222970654886

Epoch: 6| Step: 13
Training loss: 0.07129663974046707
Validation loss: 1.40155339881938

Epoch: 645| Step: 0
Training loss: 0.11146634817123413
Validation loss: 1.3944444758917696

Epoch: 6| Step: 1
Training loss: 0.07961739599704742
Validation loss: 1.4077276343940406

Epoch: 6| Step: 2
Training loss: 0.06435802578926086
Validation loss: 1.4145525193983508

Epoch: 6| Step: 3
Training loss: 0.08392376452684402
Validation loss: 1.434519346042346

Epoch: 6| Step: 4
Training loss: 0.08056322485208511
Validation loss: 1.4112825502631485

Epoch: 6| Step: 5
Training loss: 0.047538451850414276
Validation loss: 1.4214424869065643

Epoch: 6| Step: 6
Training loss: 0.04909931868314743
Validation loss: 1.4514826472087572

Epoch: 6| Step: 7
Training loss: 0.04634873941540718
Validation loss: 1.4662865336223314

Epoch: 6| Step: 8
Training loss: 0.0930950790643692
Validation loss: 1.501265876395728

Epoch: 6| Step: 9
Training loss: 0.09639474749565125
Validation loss: 1.4793463817206762

Epoch: 6| Step: 10
Training loss: 0.08668385446071625
Validation loss: 1.46262490236631

Epoch: 6| Step: 11
Training loss: 0.05293001979589462
Validation loss: 1.4465403947778928

Epoch: 6| Step: 12
Training loss: 0.06363142281770706
Validation loss: 1.4065393478639665

Epoch: 6| Step: 13
Training loss: 0.03563201427459717
Validation loss: 1.3944338906195857

Epoch: 646| Step: 0
Training loss: 0.05218362808227539
Validation loss: 1.4069341331399896

Epoch: 6| Step: 1
Training loss: 0.06349600851535797
Validation loss: 1.3899547194921842

Epoch: 6| Step: 2
Training loss: 0.044333890080451965
Validation loss: 1.400216915274179

Epoch: 6| Step: 3
Training loss: 0.057974133640527725
Validation loss: 1.3761302162242193

Epoch: 6| Step: 4
Training loss: 0.04505757987499237
Validation loss: 1.3930185200065694

Epoch: 6| Step: 5
Training loss: 0.08602935075759888
Validation loss: 1.393939902705531

Epoch: 6| Step: 6
Training loss: 0.0765489861369133
Validation loss: 1.4149605586964598

Epoch: 6| Step: 7
Training loss: 0.05459846556186676
Validation loss: 1.3780975944252425

Epoch: 6| Step: 8
Training loss: 0.046687282621860504
Validation loss: 1.3844193579048238

Epoch: 6| Step: 9
Training loss: 0.03598954528570175
Validation loss: 1.3971922128431258

Epoch: 6| Step: 10
Training loss: 0.05010940879583359
Validation loss: 1.4130441963031728

Epoch: 6| Step: 11
Training loss: 0.06305281072854996
Validation loss: 1.427898694110173

Epoch: 6| Step: 12
Training loss: 0.10283036530017853
Validation loss: 1.4144809361427062

Epoch: 6| Step: 13
Training loss: 0.07730767130851746
Validation loss: 1.4199432890902284

Epoch: 647| Step: 0
Training loss: 0.05875958502292633
Validation loss: 1.427983860815725

Epoch: 6| Step: 1
Training loss: 0.05855882167816162
Validation loss: 1.4402333715910554

Epoch: 6| Step: 2
Training loss: 0.05690485239028931
Validation loss: 1.4334452434252667

Epoch: 6| Step: 3
Training loss: 0.07667573541402817
Validation loss: 1.4448994603208316

Epoch: 6| Step: 4
Training loss: 0.08006690442562103
Validation loss: 1.4235456951202885

Epoch: 6| Step: 5
Training loss: 0.052805542945861816
Validation loss: 1.3827607926502024

Epoch: 6| Step: 6
Training loss: 0.08965611457824707
Validation loss: 1.4080452419096423

Epoch: 6| Step: 7
Training loss: 0.043812498450279236
Validation loss: 1.384570147401543

Epoch: 6| Step: 8
Training loss: 0.040160901844501495
Validation loss: 1.3741348392219954

Epoch: 6| Step: 9
Training loss: 0.05483414605259895
Validation loss: 1.379450656393523

Epoch: 6| Step: 10
Training loss: 0.06832088530063629
Validation loss: 1.400280096197641

Epoch: 6| Step: 11
Training loss: 0.06774057447910309
Validation loss: 1.366175119594861

Epoch: 6| Step: 12
Training loss: 0.08362771570682526
Validation loss: 1.3922427533775248

Epoch: 6| Step: 13
Training loss: 0.07204954326152802
Validation loss: 1.3845662288768317

Epoch: 648| Step: 0
Training loss: 0.04023946821689606
Validation loss: 1.3885796826372865

Epoch: 6| Step: 1
Training loss: 0.05554458126425743
Validation loss: 1.3957838646827205

Epoch: 6| Step: 2
Training loss: 0.043988630175590515
Validation loss: 1.4073468357004144

Epoch: 6| Step: 3
Training loss: 0.04275473207235336
Validation loss: 1.4087414908152756

Epoch: 6| Step: 4
Training loss: 0.06412668526172638
Validation loss: 1.4208750288973573

Epoch: 6| Step: 5
Training loss: 0.06592977046966553
Validation loss: 1.4083576202392578

Epoch: 6| Step: 6
Training loss: 0.0559408962726593
Validation loss: 1.4419890603711527

Epoch: 6| Step: 7
Training loss: 0.09369559586048126
Validation loss: 1.4554607419557468

Epoch: 6| Step: 8
Training loss: 0.061372995376586914
Validation loss: 1.4565211547318326

Epoch: 6| Step: 9
Training loss: 0.05093875154852867
Validation loss: 1.4570745191266459

Epoch: 6| Step: 10
Training loss: 0.06458129733800888
Validation loss: 1.4454760230997556

Epoch: 6| Step: 11
Training loss: 0.04782680422067642
Validation loss: 1.4447138065932899

Epoch: 6| Step: 12
Training loss: 0.0852307453751564
Validation loss: 1.4532406336517745

Epoch: 6| Step: 13
Training loss: 0.13906146585941315
Validation loss: 1.4513404805173156

Epoch: 649| Step: 0
Training loss: 0.08515665680170059
Validation loss: 1.4253294814017512

Epoch: 6| Step: 1
Training loss: 0.07329598814249039
Validation loss: 1.4115643411554315

Epoch: 6| Step: 2
Training loss: 0.06951650977134705
Validation loss: 1.4109104948659097

Epoch: 6| Step: 3
Training loss: 0.09325984120368958
Validation loss: 1.4464924123979384

Epoch: 6| Step: 4
Training loss: 0.12695440649986267
Validation loss: 1.4524602274740896

Epoch: 6| Step: 5
Training loss: 0.1193661093711853
Validation loss: 1.4441368220954813

Epoch: 6| Step: 6
Training loss: 0.0659916028380394
Validation loss: 1.4140568471723987

Epoch: 6| Step: 7
Training loss: 0.05405900627374649
Validation loss: 1.4685921066550798

Epoch: 6| Step: 8
Training loss: 0.057358741760253906
Validation loss: 1.480064989418112

Epoch: 6| Step: 9
Training loss: 0.10977069288492203
Validation loss: 1.4712143085336173

Epoch: 6| Step: 10
Training loss: 0.0639265775680542
Validation loss: 1.504105471795605

Epoch: 6| Step: 11
Training loss: 0.13068008422851562
Validation loss: 1.5412369133323751

Epoch: 6| Step: 12
Training loss: 0.10626185685396194
Validation loss: 1.529532160810245

Epoch: 6| Step: 13
Training loss: 0.12453634291887283
Validation loss: 1.4789974189573718

Epoch: 650| Step: 0
Training loss: 0.0769924521446228
Validation loss: 1.4581995279558244

Epoch: 6| Step: 1
Training loss: 0.04118051379919052
Validation loss: 1.4491924906289706

Epoch: 6| Step: 2
Training loss: 0.04637664556503296
Validation loss: 1.4394304957441104

Epoch: 6| Step: 3
Training loss: 0.05887285992503166
Validation loss: 1.4044212231072046

Epoch: 6| Step: 4
Training loss: 0.048099055886268616
Validation loss: 1.4180917393776677

Epoch: 6| Step: 5
Training loss: 0.08672015368938446
Validation loss: 1.4242564144954886

Epoch: 6| Step: 6
Training loss: 0.05665530636906624
Validation loss: 1.449850093933844

Epoch: 6| Step: 7
Training loss: 0.10580307245254517
Validation loss: 1.433283677665136

Epoch: 6| Step: 8
Training loss: 0.0720769613981247
Validation loss: 1.4149572182727117

Epoch: 6| Step: 9
Training loss: 0.07676038146018982
Validation loss: 1.4283698886953375

Epoch: 6| Step: 10
Training loss: 0.04875458404421806
Validation loss: 1.4317622210389824

Epoch: 6| Step: 11
Training loss: 0.04078831523656845
Validation loss: 1.4632526879669518

Epoch: 6| Step: 12
Training loss: 0.07914235442876816
Validation loss: 1.4561368592323796

Epoch: 6| Step: 13
Training loss: 0.06128519028425217
Validation loss: 1.4678700457337082

Testing loss: 2.0453704489601985
