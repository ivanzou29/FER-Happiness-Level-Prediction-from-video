Epoch: 1| Step: 0
Training loss: 4.217591762542725
Validation loss: 5.2201252701461955

Epoch: 5| Step: 1
Training loss: 5.131639003753662
Validation loss: 5.199908641076857

Epoch: 5| Step: 2
Training loss: 4.812398910522461
Validation loss: 5.184912891798122

Epoch: 5| Step: 3
Training loss: 4.290253639221191
Validation loss: 5.172074953715007

Epoch: 5| Step: 4
Training loss: 5.35830020904541
Validation loss: 5.1584650624182915

Epoch: 5| Step: 5
Training loss: 5.870569229125977
Validation loss: 5.143510008371004

Epoch: 5| Step: 6
Training loss: 4.2599992752075195
Validation loss: 5.126547921088434

Epoch: 5| Step: 7
Training loss: 4.833181858062744
Validation loss: 5.106116264097152

Epoch: 5| Step: 8
Training loss: 5.595685005187988
Validation loss: 5.084137972965036

Epoch: 5| Step: 9
Training loss: 4.9785871505737305
Validation loss: 5.058969133643694

Epoch: 5| Step: 10
Training loss: 4.886905193328857
Validation loss: 5.0296702077311854

Epoch: 2| Step: 0
Training loss: 5.366452217102051
Validation loss: 4.997112858679987

Epoch: 5| Step: 1
Training loss: 4.448009967803955
Validation loss: 4.959251767845564

Epoch: 5| Step: 2
Training loss: 3.594975709915161
Validation loss: 4.9177468925394034

Epoch: 5| Step: 3
Training loss: 4.708431243896484
Validation loss: 4.869843980317475

Epoch: 5| Step: 4
Training loss: 3.271714687347412
Validation loss: 4.816779618622155

Epoch: 5| Step: 5
Training loss: 4.8952131271362305
Validation loss: 4.759971731452532

Epoch: 5| Step: 6
Training loss: 6.108273506164551
Validation loss: 4.698307242444766

Epoch: 5| Step: 7
Training loss: 3.6517651081085205
Validation loss: 4.63526068451584

Epoch: 5| Step: 8
Training loss: 3.3253448009490967
Validation loss: 4.569805278572985

Epoch: 5| Step: 9
Training loss: 4.673148155212402
Validation loss: 4.506108160941832

Epoch: 5| Step: 10
Training loss: 5.97494649887085
Validation loss: 4.441385571674634

Epoch: 3| Step: 0
Training loss: 2.7752931118011475
Validation loss: 4.382397672181488

Epoch: 5| Step: 1
Training loss: 3.0813541412353516
Validation loss: 4.3254468364100305

Epoch: 5| Step: 2
Training loss: 2.9075064659118652
Validation loss: 4.2759752811924105

Epoch: 5| Step: 3
Training loss: 4.693698406219482
Validation loss: 4.236399576228152

Epoch: 5| Step: 4
Training loss: 4.95463752746582
Validation loss: 4.197887692400204

Epoch: 5| Step: 5
Training loss: 3.445063352584839
Validation loss: 4.1585528748009795

Epoch: 5| Step: 6
Training loss: 4.622015953063965
Validation loss: 4.127668432010117

Epoch: 5| Step: 7
Training loss: 4.369211673736572
Validation loss: 4.101478443350843

Epoch: 5| Step: 8
Training loss: 4.443971157073975
Validation loss: 4.076641018672656

Epoch: 5| Step: 9
Training loss: 4.001472473144531
Validation loss: 4.031216439380441

Epoch: 5| Step: 10
Training loss: 4.5851593017578125
Validation loss: 3.987266684091219

Epoch: 4| Step: 0
Training loss: 3.7644901275634766
Validation loss: 3.9742107032447733

Epoch: 5| Step: 1
Training loss: 4.555009365081787
Validation loss: 3.973679386159425

Epoch: 5| Step: 2
Training loss: 3.8558433055877686
Validation loss: 3.949906849092053

Epoch: 5| Step: 3
Training loss: 3.8316597938537598
Validation loss: 3.9327814732828448

Epoch: 5| Step: 4
Training loss: 3.628948211669922
Validation loss: 3.918990986321562

Epoch: 5| Step: 5
Training loss: 3.241989850997925
Validation loss: 3.9066507483041413

Epoch: 5| Step: 6
Training loss: 4.7529072761535645
Validation loss: 3.894548431519539

Epoch: 5| Step: 7
Training loss: 2.890481472015381
Validation loss: 3.8827346473611812

Epoch: 5| Step: 8
Training loss: 4.387176990509033
Validation loss: 3.8702983625473513

Epoch: 5| Step: 9
Training loss: 2.817695140838623
Validation loss: 3.8602036686353784

Epoch: 5| Step: 10
Training loss: 3.8630406856536865
Validation loss: 3.8495272846632105

Epoch: 5| Step: 0
Training loss: 3.8852286338806152
Validation loss: 3.8389575455778386

Epoch: 5| Step: 1
Training loss: 3.5543925762176514
Validation loss: 3.831431758019232

Epoch: 5| Step: 2
Training loss: 3.457521915435791
Validation loss: 3.8258945531742548

Epoch: 5| Step: 3
Training loss: 3.610116481781006
Validation loss: 3.819070062329692

Epoch: 5| Step: 4
Training loss: 4.843354225158691
Validation loss: 3.8033055054244174

Epoch: 5| Step: 5
Training loss: 3.4513721466064453
Validation loss: 3.7894245219487015

Epoch: 5| Step: 6
Training loss: 3.664397716522217
Validation loss: 3.787498486939297

Epoch: 5| Step: 7
Training loss: 3.486953020095825
Validation loss: 3.7760866739416636

Epoch: 5| Step: 8
Training loss: 3.2721047401428223
Validation loss: 3.7605786323547363

Epoch: 5| Step: 9
Training loss: 3.667332410812378
Validation loss: 3.7419495223670878

Epoch: 5| Step: 10
Training loss: 3.6044743061065674
Validation loss: 3.723427972485942

Epoch: 6| Step: 0
Training loss: 3.4437670707702637
Validation loss: 3.750305534690939

Epoch: 5| Step: 1
Training loss: 2.938061475753784
Validation loss: 3.7453705879949752

Epoch: 5| Step: 2
Training loss: 4.017645835876465
Validation loss: 3.7099385620445333

Epoch: 5| Step: 3
Training loss: 4.462275505065918
Validation loss: 3.709578175698557

Epoch: 5| Step: 4
Training loss: 3.630617618560791
Validation loss: 3.665292478376819

Epoch: 5| Step: 5
Training loss: 3.5864975452423096
Validation loss: 3.658537651902886

Epoch: 5| Step: 6
Training loss: 3.4362969398498535
Validation loss: 3.6519098897134104

Epoch: 5| Step: 7
Training loss: 3.3861002922058105
Validation loss: 3.6479925468403804

Epoch: 5| Step: 8
Training loss: 3.408334255218506
Validation loss: 3.6461129547447286

Epoch: 5| Step: 9
Training loss: 2.9331719875335693
Validation loss: 3.6429108932454097

Epoch: 5| Step: 10
Training loss: 4.287018775939941
Validation loss: 3.6316315640685377

Epoch: 7| Step: 0
Training loss: 4.1974873542785645
Validation loss: 3.620842702927128

Epoch: 5| Step: 1
Training loss: 3.972902774810791
Validation loss: 3.6134826393537622

Epoch: 5| Step: 2
Training loss: 4.8022308349609375
Validation loss: 3.606893257428241

Epoch: 5| Step: 3
Training loss: 3.853903293609619
Validation loss: 3.5991685928836947

Epoch: 5| Step: 4
Training loss: 3.093513011932373
Validation loss: 3.5901316058251167

Epoch: 5| Step: 5
Training loss: 3.5990841388702393
Validation loss: 3.5818438017240135

Epoch: 5| Step: 6
Training loss: 2.819286346435547
Validation loss: 3.5746452577652468

Epoch: 5| Step: 7
Training loss: 3.6021270751953125
Validation loss: 3.568111076149889

Epoch: 5| Step: 8
Training loss: 2.5818283557891846
Validation loss: 3.5592504880761586

Epoch: 5| Step: 9
Training loss: 2.695059061050415
Validation loss: 3.5490319113577566

Epoch: 5| Step: 10
Training loss: 3.3744101524353027
Validation loss: 3.5452987353006997

Epoch: 8| Step: 0
Training loss: 3.000854015350342
Validation loss: 3.538600011538434

Epoch: 5| Step: 1
Training loss: 3.9125237464904785
Validation loss: 3.534626668499362

Epoch: 5| Step: 2
Training loss: 3.305751323699951
Validation loss: 3.5265870683936664

Epoch: 5| Step: 3
Training loss: 3.1707146167755127
Validation loss: 3.520395924968104

Epoch: 5| Step: 4
Training loss: 4.0458173751831055
Validation loss: 3.513092561434674

Epoch: 5| Step: 5
Training loss: 3.4888553619384766
Validation loss: 3.5063741181486394

Epoch: 5| Step: 6
Training loss: 2.909879684448242
Validation loss: 3.499318758646647

Epoch: 5| Step: 7
Training loss: 3.881157636642456
Validation loss: 3.4930629627678984

Epoch: 5| Step: 8
Training loss: 3.079892635345459
Validation loss: 3.486904069941531

Epoch: 5| Step: 9
Training loss: 3.1508822441101074
Validation loss: 3.4779212013367684

Epoch: 5| Step: 10
Training loss: 3.9735264778137207
Validation loss: 3.4707300944994857

Epoch: 9| Step: 0
Training loss: 3.355360746383667
Validation loss: 3.4664807960551274

Epoch: 5| Step: 1
Training loss: 3.7073581218719482
Validation loss: 3.4685205900540916

Epoch: 5| Step: 2
Training loss: 2.7150425910949707
Validation loss: 3.456861185771163

Epoch: 5| Step: 3
Training loss: 3.0842621326446533
Validation loss: 3.4464174496230258

Epoch: 5| Step: 4
Training loss: 4.2062087059021
Validation loss: 3.441516358365295

Epoch: 5| Step: 5
Training loss: 3.1324472427368164
Validation loss: 3.437820896025627

Epoch: 5| Step: 6
Training loss: 2.824791669845581
Validation loss: 3.4295790221101496

Epoch: 5| Step: 7
Training loss: 4.017092227935791
Validation loss: 3.421489107993341

Epoch: 5| Step: 8
Training loss: 2.9981861114501953
Validation loss: 3.4163110051103818

Epoch: 5| Step: 9
Training loss: 3.9361870288848877
Validation loss: 3.410393689268379

Epoch: 5| Step: 10
Training loss: 3.1639037132263184
Validation loss: 3.4037585976303264

Epoch: 10| Step: 0
Training loss: 2.889042854309082
Validation loss: 3.399029249786049

Epoch: 5| Step: 1
Training loss: 3.4028141498565674
Validation loss: 3.3940385900517946

Epoch: 5| Step: 2
Training loss: 3.223299503326416
Validation loss: 3.3875474775991132

Epoch: 5| Step: 3
Training loss: 3.831136703491211
Validation loss: 3.378693380663472

Epoch: 5| Step: 4
Training loss: 2.898347854614258
Validation loss: 3.3744956703596216

Epoch: 5| Step: 5
Training loss: 3.471216917037964
Validation loss: 3.368945929311937

Epoch: 5| Step: 6
Training loss: 3.8305580615997314
Validation loss: 3.3621996833432104

Epoch: 5| Step: 7
Training loss: 3.4437661170959473
Validation loss: 3.355654752382668

Epoch: 5| Step: 8
Training loss: 2.7846360206604004
Validation loss: 3.3511957071160756

Epoch: 5| Step: 9
Training loss: 3.847071886062622
Validation loss: 3.34481414159139

Epoch: 5| Step: 10
Training loss: 2.851710557937622
Validation loss: 3.336439494163759

Epoch: 11| Step: 0
Training loss: 3.666098117828369
Validation loss: 3.3340483685975433

Epoch: 5| Step: 1
Training loss: 3.6916801929473877
Validation loss: 3.326489725420552

Epoch: 5| Step: 2
Training loss: 3.243163585662842
Validation loss: 3.3175537252938874

Epoch: 5| Step: 3
Training loss: 3.381298780441284
Validation loss: 3.313827622321344

Epoch: 5| Step: 4
Training loss: 3.129518747329712
Validation loss: 3.307270206430907

Epoch: 5| Step: 5
Training loss: 3.5497384071350098
Validation loss: 3.3040016364025813

Epoch: 5| Step: 6
Training loss: 3.085847854614258
Validation loss: 3.2983886580313406

Epoch: 5| Step: 7
Training loss: 2.94734525680542
Validation loss: 3.2940057067460913

Epoch: 5| Step: 8
Training loss: 3.181375741958618
Validation loss: 3.288594292056176

Epoch: 5| Step: 9
Training loss: 2.866159439086914
Validation loss: 3.280785019679736

Epoch: 5| Step: 10
Training loss: 3.271348237991333
Validation loss: 3.2766236105272846

Epoch: 12| Step: 0
Training loss: 2.623560905456543
Validation loss: 3.27348489915171

Epoch: 5| Step: 1
Training loss: 2.9432826042175293
Validation loss: 3.2677931170309744

Epoch: 5| Step: 2
Training loss: 3.0662472248077393
Validation loss: 3.2644903172728834

Epoch: 5| Step: 3
Training loss: 3.9941208362579346
Validation loss: 3.2693768598700084

Epoch: 5| Step: 4
Training loss: 3.275712251663208
Validation loss: 3.2572772118353073

Epoch: 5| Step: 5
Training loss: 4.182768821716309
Validation loss: 3.2590945074635167

Epoch: 5| Step: 6
Training loss: 3.1381351947784424
Validation loss: 3.246540084961922

Epoch: 5| Step: 7
Training loss: 3.2437584400177
Validation loss: 3.246315151132563

Epoch: 5| Step: 8
Training loss: 3.330134630203247
Validation loss: 3.2429119489526235

Epoch: 5| Step: 9
Training loss: 2.5130183696746826
Validation loss: 3.2388575871785483

Epoch: 5| Step: 10
Training loss: 3.2443294525146484
Validation loss: 3.235543845802225

Epoch: 13| Step: 0
Training loss: 3.4403557777404785
Validation loss: 3.229883619534072

Epoch: 5| Step: 1
Training loss: 3.2281532287597656
Validation loss: 3.2280361575465046

Epoch: 5| Step: 2
Training loss: 2.332693576812744
Validation loss: 3.22490793402477

Epoch: 5| Step: 3
Training loss: 2.528209686279297
Validation loss: 3.2200765943014495

Epoch: 5| Step: 4
Training loss: 3.0525307655334473
Validation loss: 3.2179197085800992

Epoch: 5| Step: 5
Training loss: 2.9798851013183594
Validation loss: 3.216923995684552

Epoch: 5| Step: 6
Training loss: 3.195358991622925
Validation loss: 3.2106569608052573

Epoch: 5| Step: 7
Training loss: 3.3213837146759033
Validation loss: 3.2072921824711624

Epoch: 5| Step: 8
Training loss: 4.245190620422363
Validation loss: 3.2124593104085615

Epoch: 5| Step: 9
Training loss: 3.5323715209960938
Validation loss: 3.1989477116574525

Epoch: 5| Step: 10
Training loss: 3.440214157104492
Validation loss: 3.1992340318618284

Epoch: 14| Step: 0
Training loss: 3.9103102684020996
Validation loss: 3.2071216952416206

Epoch: 5| Step: 1
Training loss: 2.218540668487549
Validation loss: 3.2034852222729753

Epoch: 5| Step: 2
Training loss: 3.4930572509765625
Validation loss: 3.1936619230495986

Epoch: 5| Step: 3
Training loss: 3.141247034072876
Validation loss: 3.178931889995452

Epoch: 5| Step: 4
Training loss: 2.304277181625366
Validation loss: 3.1768539490238314

Epoch: 5| Step: 5
Training loss: 3.67460298538208
Validation loss: 3.1857903183147473

Epoch: 5| Step: 6
Training loss: 2.5032026767730713
Validation loss: 3.1725409338551183

Epoch: 5| Step: 7
Training loss: 2.768892288208008
Validation loss: 3.170283135547433

Epoch: 5| Step: 8
Training loss: 3.7551467418670654
Validation loss: 3.1749497229053127

Epoch: 5| Step: 9
Training loss: 3.723958969116211
Validation loss: 3.1607450951812086

Epoch: 5| Step: 10
Training loss: 3.6011619567871094
Validation loss: 3.157282690848074

Epoch: 15| Step: 0
Training loss: 3.713954448699951
Validation loss: 3.157851283268262

Epoch: 5| Step: 1
Training loss: 2.272355318069458
Validation loss: 3.154630245700959

Epoch: 5| Step: 2
Training loss: 3.3241074085235596
Validation loss: 3.14913272857666

Epoch: 5| Step: 3
Training loss: 2.7863011360168457
Validation loss: 3.148642760451122

Epoch: 5| Step: 4
Training loss: 2.8769309520721436
Validation loss: 3.1600135475076656

Epoch: 5| Step: 5
Training loss: 3.047551155090332
Validation loss: 3.1630979122654086

Epoch: 5| Step: 6
Training loss: 4.297842979431152
Validation loss: 3.1476853406557472

Epoch: 5| Step: 7
Training loss: 2.7663140296936035
Validation loss: 3.138891827675604

Epoch: 5| Step: 8
Training loss: 3.011039972305298
Validation loss: 3.140625999819848

Epoch: 5| Step: 9
Training loss: 3.359626054763794
Validation loss: 3.141143488627608

Epoch: 5| Step: 10
Training loss: 3.3300352096557617
Validation loss: 3.1410594858149046

Epoch: 16| Step: 0
Training loss: 3.3283774852752686
Validation loss: 3.13555637995402

Epoch: 5| Step: 1
Training loss: 3.122296094894409
Validation loss: 3.1263623801610803

Epoch: 5| Step: 2
Training loss: 3.624520778656006
Validation loss: 3.124885441154562

Epoch: 5| Step: 3
Training loss: 3.3780906200408936
Validation loss: 3.117452972678728

Epoch: 5| Step: 4
Training loss: 2.8893043994903564
Validation loss: 3.1111668796949488

Epoch: 5| Step: 5
Training loss: 3.5841593742370605
Validation loss: 3.1107675157567507

Epoch: 5| Step: 6
Training loss: 2.6466116905212402
Validation loss: 3.1096950551514984

Epoch: 5| Step: 7
Training loss: 2.1221985816955566
Validation loss: 3.105631915471887

Epoch: 5| Step: 8
Training loss: 3.28240704536438
Validation loss: 3.105891837868639

Epoch: 5| Step: 9
Training loss: 2.9313480854034424
Validation loss: 3.0982862339224866

Epoch: 5| Step: 10
Training loss: 3.6523635387420654
Validation loss: 3.096091024337276

Epoch: 17| Step: 0
Training loss: 4.243584632873535
Validation loss: 3.091297795695643

Epoch: 5| Step: 1
Training loss: 3.6030421257019043
Validation loss: 3.0890231209416545

Epoch: 5| Step: 2
Training loss: 2.801940441131592
Validation loss: 3.085692318536902

Epoch: 5| Step: 3
Training loss: 2.6329903602600098
Validation loss: 3.0836134623455744

Epoch: 5| Step: 4
Training loss: 2.7893474102020264
Validation loss: 3.0818142685838925

Epoch: 5| Step: 5
Training loss: 2.8046393394470215
Validation loss: 3.0859430451546945

Epoch: 5| Step: 6
Training loss: 3.6306662559509277
Validation loss: 3.08229394881956

Epoch: 5| Step: 7
Training loss: 2.775301694869995
Validation loss: 3.0749018448655323

Epoch: 5| Step: 8
Training loss: 2.7474753856658936
Validation loss: 3.07276645270727

Epoch: 5| Step: 9
Training loss: 2.9434101581573486
Validation loss: 3.067287996251096

Epoch: 5| Step: 10
Training loss: 3.345977783203125
Validation loss: 3.0728149465335313

Epoch: 18| Step: 0
Training loss: 2.3773999214172363
Validation loss: 3.0640985273545787

Epoch: 5| Step: 1
Training loss: 2.952685594558716
Validation loss: 3.065819760804535

Epoch: 5| Step: 2
Training loss: 3.7408604621887207
Validation loss: 3.0659581820170083

Epoch: 5| Step: 3
Training loss: 2.8831992149353027
Validation loss: 3.060496179006433

Epoch: 5| Step: 4
Training loss: 2.509183406829834
Validation loss: 3.055430161055698

Epoch: 5| Step: 5
Training loss: 3.6266422271728516
Validation loss: 3.051912179557226

Epoch: 5| Step: 6
Training loss: 3.1019558906555176
Validation loss: 3.0475381471777476

Epoch: 5| Step: 7
Training loss: 3.3073410987854004
Validation loss: 3.0489498517846547

Epoch: 5| Step: 8
Training loss: 3.227754592895508
Validation loss: 3.046584857407437

Epoch: 5| Step: 9
Training loss: 2.7936432361602783
Validation loss: 3.052287586273686

Epoch: 5| Step: 10
Training loss: 3.5936739444732666
Validation loss: 3.0541517093617427

Epoch: 19| Step: 0
Training loss: 2.5291123390197754
Validation loss: 3.0560723094530005

Epoch: 5| Step: 1
Training loss: 3.1455624103546143
Validation loss: 3.0487186062720513

Epoch: 5| Step: 2
Training loss: 3.405406951904297
Validation loss: 3.0397083400398173

Epoch: 5| Step: 3
Training loss: 3.013759136199951
Validation loss: 3.0356170977315595

Epoch: 5| Step: 4
Training loss: 3.2554469108581543
Validation loss: 3.0347417426365677

Epoch: 5| Step: 5
Training loss: 2.727617025375366
Validation loss: 3.0317479692479616

Epoch: 5| Step: 6
Training loss: 3.6740901470184326
Validation loss: 3.0386695425997496

Epoch: 5| Step: 7
Training loss: 3.7974648475646973
Validation loss: 3.0411202471743346

Epoch: 5| Step: 8
Training loss: 1.7972028255462646
Validation loss: 3.0503485843699467

Epoch: 5| Step: 9
Training loss: 3.76758074760437
Validation loss: 3.0295656163205384

Epoch: 5| Step: 10
Training loss: 2.6924381256103516
Validation loss: 3.028223988830402

Epoch: 20| Step: 0
Training loss: 1.8203227519989014
Validation loss: 3.032572700131324

Epoch: 5| Step: 1
Training loss: 2.8777499198913574
Validation loss: 3.0304630187249955

Epoch: 5| Step: 2
Training loss: 2.903273105621338
Validation loss: 3.035628580277966

Epoch: 5| Step: 3
Training loss: 3.450890064239502
Validation loss: 3.035615449310631

Epoch: 5| Step: 4
Training loss: 3.1672656536102295
Validation loss: 3.0255499962837464

Epoch: 5| Step: 5
Training loss: 3.034078598022461
Validation loss: 3.0221811289428384

Epoch: 5| Step: 6
Training loss: 3.1110317707061768
Validation loss: 3.018581169907765

Epoch: 5| Step: 7
Training loss: 3.781999111175537
Validation loss: 3.016781166035642

Epoch: 5| Step: 8
Training loss: 2.843266010284424
Validation loss: 3.0122297784333587

Epoch: 5| Step: 9
Training loss: 2.9843199253082275
Validation loss: 3.0115408999945528

Epoch: 5| Step: 10
Training loss: 3.9005212783813477
Validation loss: 3.008319736808859

Epoch: 21| Step: 0
Training loss: 2.962920665740967
Validation loss: 3.0074605352135113

Epoch: 5| Step: 1
Training loss: 3.3893535137176514
Validation loss: 3.003428961641045

Epoch: 5| Step: 2
Training loss: 2.006923198699951
Validation loss: 3.003659740571053

Epoch: 5| Step: 3
Training loss: 3.696873903274536
Validation loss: 2.998841457469489

Epoch: 5| Step: 4
Training loss: 3.1550822257995605
Validation loss: 3.003642287305606

Epoch: 5| Step: 5
Training loss: 3.5273499488830566
Validation loss: 2.998137048495713

Epoch: 5| Step: 6
Training loss: 2.9458675384521484
Validation loss: 2.9952806195905133

Epoch: 5| Step: 7
Training loss: 2.8505101203918457
Validation loss: 2.991873630913355

Epoch: 5| Step: 8
Training loss: 3.3627700805664062
Validation loss: 2.9931046065463813

Epoch: 5| Step: 9
Training loss: 2.8438878059387207
Validation loss: 2.995766967855474

Epoch: 5| Step: 10
Training loss: 2.760004997253418
Validation loss: 2.9885428567086496

Epoch: 22| Step: 0
Training loss: 2.8411900997161865
Validation loss: 2.9913402090790453

Epoch: 5| Step: 1
Training loss: 2.520108699798584
Validation loss: 2.9959414697462514

Epoch: 5| Step: 2
Training loss: 4.066804885864258
Validation loss: 3.0006671259480138

Epoch: 5| Step: 3
Training loss: 2.5795912742614746
Validation loss: 2.980645489949052

Epoch: 5| Step: 4
Training loss: 2.4758670330047607
Validation loss: 2.9751322577076573

Epoch: 5| Step: 5
Training loss: 3.341266632080078
Validation loss: 3.0048590449876684

Epoch: 5| Step: 6
Training loss: 2.784653663635254
Validation loss: 2.99306752861187

Epoch: 5| Step: 7
Training loss: 3.1805922985076904
Validation loss: 2.978802393841487

Epoch: 5| Step: 8
Training loss: 2.8913414478302
Validation loss: 2.9868640386930077

Epoch: 5| Step: 9
Training loss: 3.4160053730010986
Validation loss: 2.9965924293764177

Epoch: 5| Step: 10
Training loss: 3.4028444290161133
Validation loss: 2.986652789577361

Epoch: 23| Step: 0
Training loss: 2.5018863677978516
Validation loss: 2.9693324745342298

Epoch: 5| Step: 1
Training loss: 2.713944911956787
Validation loss: 2.963455072013281

Epoch: 5| Step: 2
Training loss: 3.3658549785614014
Validation loss: 2.9603494034018567

Epoch: 5| Step: 3
Training loss: 3.18139386177063
Validation loss: 2.9599024582934637

Epoch: 5| Step: 4
Training loss: 3.1127450466156006
Validation loss: 2.95515916937141

Epoch: 5| Step: 5
Training loss: 3.3017706871032715
Validation loss: 2.9543595698571976

Epoch: 5| Step: 6
Training loss: 2.8924427032470703
Validation loss: 2.9569775724923737

Epoch: 5| Step: 7
Training loss: 2.805610418319702
Validation loss: 2.9696031411488852

Epoch: 5| Step: 8
Training loss: 2.8107972145080566
Validation loss: 2.953415137465282

Epoch: 5| Step: 9
Training loss: 3.385263442993164
Validation loss: 2.9479722463956444

Epoch: 5| Step: 10
Training loss: 3.1819183826446533
Validation loss: 2.944026152292887

Epoch: 24| Step: 0
Training loss: 2.8074028491973877
Validation loss: 2.9467544376209216

Epoch: 5| Step: 1
Training loss: 3.1806721687316895
Validation loss: 3.0079758090357624

Epoch: 5| Step: 2
Training loss: 3.5593254566192627
Validation loss: 2.934331347865443

Epoch: 5| Step: 3
Training loss: 3.209461212158203
Validation loss: 2.9875180670010146

Epoch: 5| Step: 4
Training loss: 1.925534963607788
Validation loss: 2.9728438110761743

Epoch: 5| Step: 5
Training loss: 2.683397054672241
Validation loss: 2.947537583689536

Epoch: 5| Step: 6
Training loss: 2.9636831283569336
Validation loss: 2.9310477472120717

Epoch: 5| Step: 7
Training loss: 3.5099074840545654
Validation loss: 2.9315136401884017

Epoch: 5| Step: 8
Training loss: 2.902953624725342
Validation loss: 2.929276894497615

Epoch: 5| Step: 9
Training loss: 2.6503334045410156
Validation loss: 2.9259410571026545

Epoch: 5| Step: 10
Training loss: 4.021183013916016
Validation loss: 2.925787869320121

Epoch: 25| Step: 0
Training loss: 2.560445547103882
Validation loss: 2.928744449410387

Epoch: 5| Step: 1
Training loss: 2.941006898880005
Validation loss: 2.9245498180389404

Epoch: 5| Step: 2
Training loss: 2.7221591472625732
Validation loss: 2.923201953211138

Epoch: 5| Step: 3
Training loss: 2.5998904705047607
Validation loss: 2.9170667484242427

Epoch: 5| Step: 4
Training loss: 2.886129379272461
Validation loss: 2.918623621745776

Epoch: 5| Step: 5
Training loss: 3.701282024383545
Validation loss: 2.918321248023741

Epoch: 5| Step: 6
Training loss: 3.165134906768799
Validation loss: 2.922108245152299

Epoch: 5| Step: 7
Training loss: 2.4953300952911377
Validation loss: 2.9209145833087224

Epoch: 5| Step: 8
Training loss: 2.424999952316284
Validation loss: 2.931337848786385

Epoch: 5| Step: 9
Training loss: 3.300450086593628
Validation loss: 2.947590840760098

Epoch: 5| Step: 10
Training loss: 4.280936241149902
Validation loss: 2.9322614592890583

Epoch: 26| Step: 0
Training loss: 3.631088972091675
Validation loss: 2.917863166460427

Epoch: 5| Step: 1
Training loss: 2.8587470054626465
Validation loss: 2.910928818487352

Epoch: 5| Step: 2
Training loss: 3.401440143585205
Validation loss: 2.908635103574363

Epoch: 5| Step: 3
Training loss: 3.182992458343506
Validation loss: 2.9072269803734234

Epoch: 5| Step: 4
Training loss: 3.2228102684020996
Validation loss: 2.9051254128897064

Epoch: 5| Step: 5
Training loss: 1.779658317565918
Validation loss: 2.9157875250744563

Epoch: 5| Step: 6
Training loss: 2.3069539070129395
Validation loss: 2.9190381137273644

Epoch: 5| Step: 7
Training loss: 3.4581170082092285
Validation loss: 2.9582016391138874

Epoch: 5| Step: 8
Training loss: 3.540642499923706
Validation loss: 2.933216805099159

Epoch: 5| Step: 9
Training loss: 3.1926796436309814
Validation loss: 2.910249889537852

Epoch: 5| Step: 10
Training loss: 2.206355094909668
Validation loss: 2.899563914986067

Epoch: 27| Step: 0
Training loss: 3.1071057319641113
Validation loss: 2.9025323211505847

Epoch: 5| Step: 1
Training loss: 3.087501049041748
Validation loss: 2.9750304222106934

Epoch: 5| Step: 2
Training loss: 3.184591054916382
Validation loss: 3.1143744632761967

Epoch: 5| Step: 3
Training loss: 4.353250026702881
Validation loss: 3.1795089578115814

Epoch: 5| Step: 4
Training loss: 2.409053325653076
Validation loss: 3.1723354529309016

Epoch: 5| Step: 5
Training loss: 3.635327100753784
Validation loss: 3.162032501671904

Epoch: 5| Step: 6
Training loss: 3.766852855682373
Validation loss: 3.135463135216826

Epoch: 5| Step: 7
Training loss: 2.60794997215271
Validation loss: 3.1000622421182613

Epoch: 5| Step: 8
Training loss: 2.322134017944336
Validation loss: 3.0327512218106176

Epoch: 5| Step: 9
Training loss: 3.3110804557800293
Validation loss: 2.9401211892404864

Epoch: 5| Step: 10
Training loss: 2.221526861190796
Validation loss: 2.946298027551302

Epoch: 28| Step: 0
Training loss: 3.6536355018615723
Validation loss: 3.2221109431277037

Epoch: 5| Step: 1
Training loss: 2.7613110542297363
Validation loss: 3.3751192041622695

Epoch: 5| Step: 2
Training loss: 2.413944959640503
Validation loss: 3.2999287010521017

Epoch: 5| Step: 3
Training loss: 3.0220818519592285
Validation loss: 3.143214112968855

Epoch: 5| Step: 4
Training loss: 2.889366626739502
Validation loss: 2.959275991685929

Epoch: 5| Step: 5
Training loss: 3.8552985191345215
Validation loss: 2.9349174832785003

Epoch: 5| Step: 6
Training loss: 2.9372808933258057
Validation loss: 3.02867611505652

Epoch: 5| Step: 7
Training loss: 3.6147122383117676
Validation loss: 3.0967056930706067

Epoch: 5| Step: 8
Training loss: 2.850745916366577
Validation loss: 3.135792545093003

Epoch: 5| Step: 9
Training loss: 3.328845500946045
Validation loss: 3.149571869962959

Epoch: 5| Step: 10
Training loss: 3.144312620162964
Validation loss: 3.1433573486984416

Epoch: 29| Step: 0
Training loss: 3.536569118499756
Validation loss: 3.135041818823866

Epoch: 5| Step: 1
Training loss: 3.0936169624328613
Validation loss: 3.1143085879664265

Epoch: 5| Step: 2
Training loss: 2.811554431915283
Validation loss: 3.095063550497896

Epoch: 5| Step: 3
Training loss: 3.313523054122925
Validation loss: 3.0864176775819514

Epoch: 5| Step: 4
Training loss: 2.948948383331299
Validation loss: 3.076703953486617

Epoch: 5| Step: 5
Training loss: 2.694138765335083
Validation loss: 3.052634349433325

Epoch: 5| Step: 6
Training loss: 3.477776050567627
Validation loss: 2.972514465291013

Epoch: 5| Step: 7
Training loss: 2.691553831100464
Validation loss: 2.8942253153811217

Epoch: 5| Step: 8
Training loss: 2.477851390838623
Validation loss: 2.9053818512988347

Epoch: 5| Step: 9
Training loss: 3.775721788406372
Validation loss: 2.9245406850691764

Epoch: 5| Step: 10
Training loss: 2.933290719985962
Validation loss: 2.941835388060539

Epoch: 30| Step: 0
Training loss: 3.6323883533477783
Validation loss: 2.9463314625524704

Epoch: 5| Step: 1
Training loss: 2.9455177783966064
Validation loss: 2.9202811564168623

Epoch: 5| Step: 2
Training loss: 2.410343647003174
Validation loss: 2.885032615353984

Epoch: 5| Step: 3
Training loss: 2.6562178134918213
Validation loss: 2.8684931903757076

Epoch: 5| Step: 4
Training loss: 2.72821307182312
Validation loss: 2.8693992527582313

Epoch: 5| Step: 5
Training loss: 2.4068713188171387
Validation loss: 2.8774890386930077

Epoch: 5| Step: 6
Training loss: 2.3216564655303955
Validation loss: 2.90035569026906

Epoch: 5| Step: 7
Training loss: 3.1959047317504883
Validation loss: 2.9193627577956005

Epoch: 5| Step: 8
Training loss: 3.897441864013672
Validation loss: 2.919672494293541

Epoch: 5| Step: 9
Training loss: 3.5038866996765137
Validation loss: 2.892984285149523

Epoch: 5| Step: 10
Training loss: 3.179985761642456
Validation loss: 2.8740900613928355

Epoch: 31| Step: 0
Training loss: 2.6494531631469727
Validation loss: 2.8794870197132068

Epoch: 5| Step: 1
Training loss: 3.0966439247131348
Validation loss: 2.905052618313861

Epoch: 5| Step: 2
Training loss: 3.474735736846924
Validation loss: 2.8948547353026686

Epoch: 5| Step: 3
Training loss: 2.4017341136932373
Validation loss: 2.876129347790954

Epoch: 5| Step: 4
Training loss: 2.3482120037078857
Validation loss: 2.8681541001924904

Epoch: 5| Step: 5
Training loss: 2.8593907356262207
Validation loss: 2.8584292037512666

Epoch: 5| Step: 6
Training loss: 2.4926528930664062
Validation loss: 2.8590959579713884

Epoch: 5| Step: 7
Training loss: 3.5979461669921875
Validation loss: 2.856988542823381

Epoch: 5| Step: 8
Training loss: 3.386044979095459
Validation loss: 2.858091341551914

Epoch: 5| Step: 9
Training loss: 3.413731336593628
Validation loss: 2.857542096927602

Epoch: 5| Step: 10
Training loss: 2.802229642868042
Validation loss: 2.8558096654953493

Epoch: 32| Step: 0
Training loss: 3.443904161453247
Validation loss: 2.855539406499555

Epoch: 5| Step: 1
Training loss: 3.289783477783203
Validation loss: 2.858125473863335

Epoch: 5| Step: 2
Training loss: 2.6399426460266113
Validation loss: 2.8548964454281713

Epoch: 5| Step: 3
Training loss: 2.760418653488159
Validation loss: 2.8529522675339893

Epoch: 5| Step: 4
Training loss: 2.876220703125
Validation loss: 2.8532196219249437

Epoch: 5| Step: 5
Training loss: 2.8258070945739746
Validation loss: 2.853872122303132

Epoch: 5| Step: 6
Training loss: 3.130427598953247
Validation loss: 2.8516208843518327

Epoch: 5| Step: 7
Training loss: 3.1998095512390137
Validation loss: 2.848484690471362

Epoch: 5| Step: 8
Training loss: 2.528005599975586
Validation loss: 2.848759412765503

Epoch: 5| Step: 9
Training loss: 2.925441026687622
Validation loss: 2.8481473333092144

Epoch: 5| Step: 10
Training loss: 2.7338485717773438
Validation loss: 2.8476811583324144

Epoch: 33| Step: 0
Training loss: 2.9424028396606445
Validation loss: 2.8479658326795025

Epoch: 5| Step: 1
Training loss: 3.502269744873047
Validation loss: 2.850193913264941

Epoch: 5| Step: 2
Training loss: 2.473249912261963
Validation loss: 2.851134994978546

Epoch: 5| Step: 3
Training loss: 2.121896743774414
Validation loss: 2.854504482720488

Epoch: 5| Step: 4
Training loss: 3.5731308460235596
Validation loss: 2.855781380848218

Epoch: 5| Step: 5
Training loss: 3.8240623474121094
Validation loss: 2.8504236205931632

Epoch: 5| Step: 6
Training loss: 3.054948091506958
Validation loss: 2.8476092302671043

Epoch: 5| Step: 7
Training loss: 2.5446014404296875
Validation loss: 2.8456873624555525

Epoch: 5| Step: 8
Training loss: 2.9935688972473145
Validation loss: 2.8475411963719193

Epoch: 5| Step: 9
Training loss: 2.5119309425354004
Validation loss: 2.847306018234581

Epoch: 5| Step: 10
Training loss: 2.6425909996032715
Validation loss: 2.840195240512971

Epoch: 34| Step: 0
Training loss: 3.3155789375305176
Validation loss: 2.8377013206481934

Epoch: 5| Step: 1
Training loss: 2.678318500518799
Validation loss: 2.8345624067450084

Epoch: 5| Step: 2
Training loss: 3.4106082916259766
Validation loss: 2.8387325450938237

Epoch: 5| Step: 3
Training loss: 3.5969462394714355
Validation loss: 2.8347456916686027

Epoch: 5| Step: 4
Training loss: 2.2934398651123047
Validation loss: 2.834713015505063

Epoch: 5| Step: 5
Training loss: 3.8418025970458984
Validation loss: 2.83596743306806

Epoch: 5| Step: 6
Training loss: 2.924750566482544
Validation loss: 2.8333363917566117

Epoch: 5| Step: 7
Training loss: 2.6315040588378906
Validation loss: 2.83275294175712

Epoch: 5| Step: 8
Training loss: 2.3482468128204346
Validation loss: 2.8308473069180726

Epoch: 5| Step: 9
Training loss: 2.4438140392303467
Validation loss: 2.8281555714145785

Epoch: 5| Step: 10
Training loss: 2.540834665298462
Validation loss: 2.826605063612743

Epoch: 35| Step: 0
Training loss: 3.0108494758605957
Validation loss: 2.825503421086137

Epoch: 5| Step: 1
Training loss: 2.353168487548828
Validation loss: 2.827067857147545

Epoch: 5| Step: 2
Training loss: 3.7911276817321777
Validation loss: 2.822419610074771

Epoch: 5| Step: 3
Training loss: 2.5322155952453613
Validation loss: 2.8191735770112727

Epoch: 5| Step: 4
Training loss: 2.852651357650757
Validation loss: 2.8160041122026342

Epoch: 5| Step: 5
Training loss: 2.7655646800994873
Validation loss: 2.81724573463522

Epoch: 5| Step: 6
Training loss: 2.584601640701294
Validation loss: 2.8159585204175723

Epoch: 5| Step: 7
Training loss: 2.1651039123535156
Validation loss: 2.814707035659462

Epoch: 5| Step: 8
Training loss: 3.1210777759552
Validation loss: 2.814552476329188

Epoch: 5| Step: 9
Training loss: 3.534653902053833
Validation loss: 2.815051632542764

Epoch: 5| Step: 10
Training loss: 3.3961281776428223
Validation loss: 2.813802901134696

Epoch: 36| Step: 0
Training loss: 3.1339938640594482
Validation loss: 2.8113906409150813

Epoch: 5| Step: 1
Training loss: 2.498347043991089
Validation loss: 2.8088821416260092

Epoch: 5| Step: 2
Training loss: 2.5028252601623535
Validation loss: 2.8064102075433217

Epoch: 5| Step: 3
Training loss: 3.4443306922912598
Validation loss: 2.8074487691284506

Epoch: 5| Step: 4
Training loss: 2.849762439727783
Validation loss: 2.8046926170267086

Epoch: 5| Step: 5
Training loss: 2.5585227012634277
Validation loss: 2.800406473939137

Epoch: 5| Step: 6
Training loss: 3.4878673553466797
Validation loss: 2.8040205688886743

Epoch: 5| Step: 7
Training loss: 2.6939892768859863
Validation loss: 2.8001573060148504

Epoch: 5| Step: 8
Training loss: 2.1946730613708496
Validation loss: 2.798087276438231

Epoch: 5| Step: 9
Training loss: 2.99603271484375
Validation loss: 2.804799974605601

Epoch: 5| Step: 10
Training loss: 3.6172385215759277
Validation loss: 2.8019745990794194

Epoch: 37| Step: 0
Training loss: 2.582174301147461
Validation loss: 2.80414996352247

Epoch: 5| Step: 1
Training loss: 3.037972927093506
Validation loss: 2.7997664149089525

Epoch: 5| Step: 2
Training loss: 3.3127074241638184
Validation loss: 2.797122665630874

Epoch: 5| Step: 3
Training loss: 3.116405963897705
Validation loss: 2.7982751272057973

Epoch: 5| Step: 4
Training loss: 3.496169328689575
Validation loss: 2.7965486306016163

Epoch: 5| Step: 5
Training loss: 2.1309399604797363
Validation loss: 2.7954129044727614

Epoch: 5| Step: 6
Training loss: 3.8177196979522705
Validation loss: 2.792174862277123

Epoch: 5| Step: 7
Training loss: 2.9919486045837402
Validation loss: 2.791462626508487

Epoch: 5| Step: 8
Training loss: 2.119771957397461
Validation loss: 2.785414425275659

Epoch: 5| Step: 9
Training loss: 2.0253047943115234
Validation loss: 2.782503802289245

Epoch: 5| Step: 10
Training loss: 3.196075916290283
Validation loss: 2.7805456807536464

Epoch: 38| Step: 0
Training loss: 2.387676477432251
Validation loss: 2.7798682156429497

Epoch: 5| Step: 1
Training loss: 2.5852856636047363
Validation loss: 2.7803275456992527

Epoch: 5| Step: 2
Training loss: 3.245182514190674
Validation loss: 2.7796673954174085

Epoch: 5| Step: 3
Training loss: 2.730902671813965
Validation loss: 2.77809670407285

Epoch: 5| Step: 4
Training loss: 2.507904291152954
Validation loss: 2.778817097345988

Epoch: 5| Step: 5
Training loss: 3.014160633087158
Validation loss: 2.780075160405969

Epoch: 5| Step: 6
Training loss: 3.0092546939849854
Validation loss: 2.785093281858711

Epoch: 5| Step: 7
Training loss: 2.9287924766540527
Validation loss: 2.7843481084351898

Epoch: 5| Step: 8
Training loss: 3.77821683883667
Validation loss: 2.784065144036406

Epoch: 5| Step: 9
Training loss: 2.8240978717803955
Validation loss: 2.782553493335683

Epoch: 5| Step: 10
Training loss: 2.7166991233825684
Validation loss: 2.7784247372740056

Epoch: 39| Step: 0
Training loss: 3.2902920246124268
Validation loss: 2.773336478458938

Epoch: 5| Step: 1
Training loss: 2.809218168258667
Validation loss: 2.7705219612326673

Epoch: 5| Step: 2
Training loss: 2.6136574745178223
Validation loss: 2.7712884385098695

Epoch: 5| Step: 3
Training loss: 2.265388011932373
Validation loss: 2.769250192949849

Epoch: 5| Step: 4
Training loss: 2.5433924198150635
Validation loss: 2.7753528446279545

Epoch: 5| Step: 5
Training loss: 2.379899263381958
Validation loss: 2.783434078257571

Epoch: 5| Step: 6
Training loss: 3.5620522499084473
Validation loss: 2.765649111040177

Epoch: 5| Step: 7
Training loss: 2.947086811065674
Validation loss: 2.766451874086934

Epoch: 5| Step: 8
Training loss: 3.2663791179656982
Validation loss: 2.7700538378889843

Epoch: 5| Step: 9
Training loss: 2.5068416595458984
Validation loss: 2.7721349680295555

Epoch: 5| Step: 10
Training loss: 3.600421905517578
Validation loss: 2.7769560685721775

Epoch: 40| Step: 0
Training loss: 3.3235607147216797
Validation loss: 2.7848319520232496

Epoch: 5| Step: 1
Training loss: 2.5368099212646484
Validation loss: 2.790128505358132

Epoch: 5| Step: 2
Training loss: 2.743300199508667
Validation loss: 2.7936715028619252

Epoch: 5| Step: 3
Training loss: 2.2064318656921387
Validation loss: 2.7911508672980854

Epoch: 5| Step: 4
Training loss: 3.3276634216308594
Validation loss: 2.786230625644807

Epoch: 5| Step: 5
Training loss: 2.061133861541748
Validation loss: 2.7862719899864605

Epoch: 5| Step: 6
Training loss: 2.9780616760253906
Validation loss: 2.7818305979492846

Epoch: 5| Step: 7
Training loss: 3.279979705810547
Validation loss: 2.779497438861478

Epoch: 5| Step: 8
Training loss: 2.3209357261657715
Validation loss: 2.7712863132517827

Epoch: 5| Step: 9
Training loss: 3.5276827812194824
Validation loss: 2.766872554697016

Epoch: 5| Step: 10
Training loss: 3.51595401763916
Validation loss: 2.762495771531136

Epoch: 41| Step: 0
Training loss: 3.137467861175537
Validation loss: 2.7486435777397564

Epoch: 5| Step: 1
Training loss: 2.0541670322418213
Validation loss: 2.7434615114683747

Epoch: 5| Step: 2
Training loss: 3.08571195602417
Validation loss: 2.7371394993156515

Epoch: 5| Step: 3
Training loss: 3.414285659790039
Validation loss: 2.7342040231150966

Epoch: 5| Step: 4
Training loss: 2.631605625152588
Validation loss: 2.7352579921804447

Epoch: 5| Step: 5
Training loss: 3.0231728553771973
Validation loss: 2.73081188560814

Epoch: 5| Step: 6
Training loss: 3.2189249992370605
Validation loss: 2.727421168358095

Epoch: 5| Step: 7
Training loss: 3.063493490219116
Validation loss: 2.732806490313622

Epoch: 5| Step: 8
Training loss: 2.3889365196228027
Validation loss: 2.733075200870473

Epoch: 5| Step: 9
Training loss: 3.06394624710083
Validation loss: 2.731181195987168

Epoch: 5| Step: 10
Training loss: 2.204739809036255
Validation loss: 2.737340058049848

Epoch: 42| Step: 0
Training loss: 2.1746609210968018
Validation loss: 2.7669249555116058

Epoch: 5| Step: 1
Training loss: 3.389443874359131
Validation loss: 2.840595558125486

Epoch: 5| Step: 2
Training loss: 2.4623818397521973
Validation loss: 2.8239089853020123

Epoch: 5| Step: 3
Training loss: 2.6024956703186035
Validation loss: 2.7986781468955417

Epoch: 5| Step: 4
Training loss: 2.7345547676086426
Validation loss: 2.7409666661293275

Epoch: 5| Step: 5
Training loss: 3.2193214893341064
Validation loss: 2.7222615570150395

Epoch: 5| Step: 6
Training loss: 2.6703038215637207
Validation loss: 2.7285684180516068

Epoch: 5| Step: 7
Training loss: 2.3800697326660156
Validation loss: 2.7348336929916055

Epoch: 5| Step: 8
Training loss: 3.5590548515319824
Validation loss: 2.7455143620890956

Epoch: 5| Step: 9
Training loss: 2.859267473220825
Validation loss: 2.749540500743415

Epoch: 5| Step: 10
Training loss: 3.6178948879241943
Validation loss: 2.7425484118923062

Epoch: 43| Step: 0
Training loss: 2.874861001968384
Validation loss: 2.7353434716501543

Epoch: 5| Step: 1
Training loss: 2.959700107574463
Validation loss: 2.722968416829263

Epoch: 5| Step: 2
Training loss: 2.6518521308898926
Validation loss: 2.724451664955385

Epoch: 5| Step: 3
Training loss: 3.1172139644622803
Validation loss: 2.721559803972962

Epoch: 5| Step: 4
Training loss: 3.438718795776367
Validation loss: 2.718781404597785

Epoch: 5| Step: 5
Training loss: 2.8612303733825684
Validation loss: 2.7181499645274174

Epoch: 5| Step: 6
Training loss: 2.499553918838501
Validation loss: 2.7160116805825183

Epoch: 5| Step: 7
Training loss: 2.4032394886016846
Validation loss: 2.7157802120331795

Epoch: 5| Step: 8
Training loss: 2.9395480155944824
Validation loss: 2.7121693985436552

Epoch: 5| Step: 9
Training loss: 2.2825446128845215
Validation loss: 2.715547502681773

Epoch: 5| Step: 10
Training loss: 3.234156847000122
Validation loss: 2.7179046600095687

Epoch: 44| Step: 0
Training loss: 3.700453519821167
Validation loss: 2.7143668846417497

Epoch: 5| Step: 1
Training loss: 2.831881284713745
Validation loss: 2.716673645921933

Epoch: 5| Step: 2
Training loss: 3.3608596324920654
Validation loss: 2.7147245304558867

Epoch: 5| Step: 3
Training loss: 2.3734335899353027
Validation loss: 2.715330534083869

Epoch: 5| Step: 4
Training loss: 2.515232563018799
Validation loss: 2.7195814476218274

Epoch: 5| Step: 5
Training loss: 3.2587616443634033
Validation loss: 2.722976694824875

Epoch: 5| Step: 6
Training loss: 2.777111053466797
Validation loss: 2.7227171005741244

Epoch: 5| Step: 7
Training loss: 3.482098340988159
Validation loss: 2.724440969446654

Epoch: 5| Step: 8
Training loss: 2.2971653938293457
Validation loss: 2.730285165130451

Epoch: 5| Step: 9
Training loss: 2.2367053031921387
Validation loss: 2.72117418114857

Epoch: 5| Step: 10
Training loss: 2.2384865283966064
Validation loss: 2.712206349577955

Epoch: 45| Step: 0
Training loss: 3.089115619659424
Validation loss: 2.702395623730075

Epoch: 5| Step: 1
Training loss: 3.2715401649475098
Validation loss: 2.7027095722895798

Epoch: 5| Step: 2
Training loss: 3.160846471786499
Validation loss: 2.6998279735606205

Epoch: 5| Step: 3
Training loss: 2.683485269546509
Validation loss: 2.7084592439795054

Epoch: 5| Step: 4
Training loss: 3.049356460571289
Validation loss: 2.710905482692103

Epoch: 5| Step: 5
Training loss: 2.3873493671417236
Validation loss: 2.716963650077902

Epoch: 5| Step: 6
Training loss: 2.5380988121032715
Validation loss: 2.7464579792432886

Epoch: 5| Step: 7
Training loss: 2.700524091720581
Validation loss: 2.8043767226639615

Epoch: 5| Step: 8
Training loss: 2.4272162914276123
Validation loss: 2.8064068696832143

Epoch: 5| Step: 9
Training loss: 3.2883083820343018
Validation loss: 2.760845358653735

Epoch: 5| Step: 10
Training loss: 2.6996238231658936
Validation loss: 2.7025515264080417

Epoch: 46| Step: 0
Training loss: 2.2308456897735596
Validation loss: 2.6969105094991703

Epoch: 5| Step: 1
Training loss: 3.31862211227417
Validation loss: 2.704012606733589

Epoch: 5| Step: 2
Training loss: 3.724984645843506
Validation loss: 2.7132320455325547

Epoch: 5| Step: 3
Training loss: 2.7663469314575195
Validation loss: 2.7261120170675297

Epoch: 5| Step: 4
Training loss: 3.01227068901062
Validation loss: 2.7429483270132415

Epoch: 5| Step: 5
Training loss: 2.4953091144561768
Validation loss: 2.7498639860460834

Epoch: 5| Step: 6
Training loss: 2.482193946838379
Validation loss: 2.7314765068792526

Epoch: 5| Step: 7
Training loss: 2.268613338470459
Validation loss: 2.712613523647349

Epoch: 5| Step: 8
Training loss: 3.5847976207733154
Validation loss: 2.694368541881602

Epoch: 5| Step: 9
Training loss: 2.7837953567504883
Validation loss: 2.690503130676926

Epoch: 5| Step: 10
Training loss: 2.413816213607788
Validation loss: 2.6840616246705413

Epoch: 47| Step: 0
Training loss: 2.9768974781036377
Validation loss: 2.686528995472898

Epoch: 5| Step: 1
Training loss: 2.591928720474243
Validation loss: 2.6919352418632916

Epoch: 5| Step: 2
Training loss: 2.6047861576080322
Validation loss: 2.6969605004915627

Epoch: 5| Step: 3
Training loss: 3.286914825439453
Validation loss: 2.6896243223579983

Epoch: 5| Step: 4
Training loss: 2.2640540599823
Validation loss: 2.685442501498807

Epoch: 5| Step: 5
Training loss: 3.6520323753356934
Validation loss: 2.680252908378519

Epoch: 5| Step: 6
Training loss: 2.0968050956726074
Validation loss: 2.6794605819127892

Epoch: 5| Step: 7
Training loss: 2.775608539581299
Validation loss: 2.6789105323053177

Epoch: 5| Step: 8
Training loss: 3.3314526081085205
Validation loss: 2.685872370196927

Epoch: 5| Step: 9
Training loss: 2.924025058746338
Validation loss: 2.6908773799096384

Epoch: 5| Step: 10
Training loss: 2.4703903198242188
Validation loss: 2.6949954161079983

Epoch: 48| Step: 0
Training loss: 3.182162046432495
Validation loss: 2.7119599106491252

Epoch: 5| Step: 1
Training loss: 3.07494854927063
Validation loss: 2.7248329424089

Epoch: 5| Step: 2
Training loss: 3.4188499450683594
Validation loss: 2.722973108291626

Epoch: 5| Step: 3
Training loss: 2.6371073722839355
Validation loss: 2.696466809959822

Epoch: 5| Step: 4
Training loss: 2.4851889610290527
Validation loss: 2.6777814690784743

Epoch: 5| Step: 5
Training loss: 3.3448500633239746
Validation loss: 2.674051720608947

Epoch: 5| Step: 6
Training loss: 2.4599452018737793
Validation loss: 2.674097332903134

Epoch: 5| Step: 7
Training loss: 2.04001522064209
Validation loss: 2.6754168797564764

Epoch: 5| Step: 8
Training loss: 2.7665927410125732
Validation loss: 2.6786665403714744

Epoch: 5| Step: 9
Training loss: 2.803668975830078
Validation loss: 2.674826216954057

Epoch: 5| Step: 10
Training loss: 2.8188540935516357
Validation loss: 2.675763730079897

Epoch: 49| Step: 0
Training loss: 3.0862321853637695
Validation loss: 2.6775887345754974

Epoch: 5| Step: 1
Training loss: 2.5633349418640137
Validation loss: 2.6766286229574554

Epoch: 5| Step: 2
Training loss: 2.218383312225342
Validation loss: 2.672007273602229

Epoch: 5| Step: 3
Training loss: 2.9519805908203125
Validation loss: 2.6691185812796316

Epoch: 5| Step: 4
Training loss: 2.5435307025909424
Validation loss: 2.6695814081417617

Epoch: 5| Step: 5
Training loss: 2.7988052368164062
Validation loss: 2.666552982022685

Epoch: 5| Step: 6
Training loss: 2.802341938018799
Validation loss: 2.6674505510637836

Epoch: 5| Step: 7
Training loss: 2.467059373855591
Validation loss: 2.6656373854606383

Epoch: 5| Step: 8
Training loss: 2.828336000442505
Validation loss: 2.666602773051108

Epoch: 5| Step: 9
Training loss: 3.701941728591919
Validation loss: 2.6696886606113885

Epoch: 5| Step: 10
Training loss: 2.9730167388916016
Validation loss: 2.659059509154289

Epoch: 50| Step: 0
Training loss: 2.268662929534912
Validation loss: 2.6521968277551795

Epoch: 5| Step: 1
Training loss: 2.8507399559020996
Validation loss: 2.652905910245834

Epoch: 5| Step: 2
Training loss: 2.3712170124053955
Validation loss: 2.6482429965849845

Epoch: 5| Step: 3
Training loss: 2.9503014087677
Validation loss: 2.6447108560992825

Epoch: 5| Step: 4
Training loss: 2.8749706745147705
Validation loss: 2.644953353430635

Epoch: 5| Step: 5
Training loss: 3.359361171722412
Validation loss: 2.643487289387693

Epoch: 5| Step: 6
Training loss: 2.778740406036377
Validation loss: 2.6387818859469507

Epoch: 5| Step: 7
Training loss: 2.9389379024505615
Validation loss: 2.6367608680520007

Epoch: 5| Step: 8
Training loss: 3.1367831230163574
Validation loss: 2.6344817761451966

Epoch: 5| Step: 9
Training loss: 2.134488582611084
Validation loss: 2.6331990354804584

Epoch: 5| Step: 10
Training loss: 3.0453550815582275
Validation loss: 2.6322041224407893

Epoch: 51| Step: 0
Training loss: 2.969489574432373
Validation loss: 2.634757370077154

Epoch: 5| Step: 1
Training loss: 2.5789458751678467
Validation loss: 2.6338130299763014

Epoch: 5| Step: 2
Training loss: 2.655858278274536
Validation loss: 2.6332291992761756

Epoch: 5| Step: 3
Training loss: 3.2426605224609375
Validation loss: 2.6301957843124226

Epoch: 5| Step: 4
Training loss: 1.7807508707046509
Validation loss: 2.627548581810408

Epoch: 5| Step: 5
Training loss: 3.5066840648651123
Validation loss: 2.632391757862542

Epoch: 5| Step: 6
Training loss: 2.7590954303741455
Validation loss: 2.6273839909543275

Epoch: 5| Step: 7
Training loss: 2.4596245288848877
Validation loss: 2.627688648880169

Epoch: 5| Step: 8
Training loss: 3.4207940101623535
Validation loss: 2.6274740208861647

Epoch: 5| Step: 9
Training loss: 2.4424705505371094
Validation loss: 2.6269251915716354

Epoch: 5| Step: 10
Training loss: 2.734832525253296
Validation loss: 2.6274720494465162

Epoch: 52| Step: 0
Training loss: 2.5536582469940186
Validation loss: 2.6299543944738244

Epoch: 5| Step: 1
Training loss: 3.188119411468506
Validation loss: 2.6289421794235066

Epoch: 5| Step: 2
Training loss: 1.9486125707626343
Validation loss: 2.628971371599423

Epoch: 5| Step: 3
Training loss: 2.444129705429077
Validation loss: 2.647479969968078

Epoch: 5| Step: 4
Training loss: 3.0839791297912598
Validation loss: 2.6331557484083277

Epoch: 5| Step: 5
Training loss: 3.5665836334228516
Validation loss: 2.6176744891751196

Epoch: 5| Step: 6
Training loss: 2.8028204441070557
Validation loss: 2.621767387595228

Epoch: 5| Step: 7
Training loss: 2.318817615509033
Validation loss: 2.628374135622414

Epoch: 5| Step: 8
Training loss: 3.0306384563446045
Validation loss: 2.6532781021569365

Epoch: 5| Step: 9
Training loss: 2.824613571166992
Validation loss: 2.6534155466223277

Epoch: 5| Step: 10
Training loss: 2.8746654987335205
Validation loss: 2.62925967349801

Epoch: 53| Step: 0
Training loss: 3.3149826526641846
Validation loss: 2.6291358983644875

Epoch: 5| Step: 1
Training loss: 2.9982829093933105
Validation loss: 2.6195257222780617

Epoch: 5| Step: 2
Training loss: 2.5229897499084473
Validation loss: 2.616389387397356

Epoch: 5| Step: 3
Training loss: 2.2958388328552246
Validation loss: 2.6137874639162453

Epoch: 5| Step: 4
Training loss: 3.311861038208008
Validation loss: 2.614037057404877

Epoch: 5| Step: 5
Training loss: 2.2542076110839844
Validation loss: 2.6178788344065347

Epoch: 5| Step: 6
Training loss: 2.560642957687378
Validation loss: 2.6166905997901835

Epoch: 5| Step: 7
Training loss: 3.1297523975372314
Validation loss: 2.61365867430164

Epoch: 5| Step: 8
Training loss: 2.599806308746338
Validation loss: 2.6155798653120637

Epoch: 5| Step: 9
Training loss: 2.4064950942993164
Validation loss: 2.615430893436555

Epoch: 5| Step: 10
Training loss: 3.144645929336548
Validation loss: 2.615381251099289

Epoch: 54| Step: 0
Training loss: 2.905672311782837
Validation loss: 2.617654687614851

Epoch: 5| Step: 1
Training loss: 3.5419960021972656
Validation loss: 2.611716165337511

Epoch: 5| Step: 2
Training loss: 2.707751512527466
Validation loss: 2.6113488853618665

Epoch: 5| Step: 3
Training loss: 2.655349016189575
Validation loss: 2.611589588144774

Epoch: 5| Step: 4
Training loss: 2.767591714859009
Validation loss: 2.613208842533891

Epoch: 5| Step: 5
Training loss: 2.655536413192749
Validation loss: 2.609658605308943

Epoch: 5| Step: 6
Training loss: 3.3667633533477783
Validation loss: 2.6124187695082797

Epoch: 5| Step: 7
Training loss: 2.412452220916748
Validation loss: 2.6130587747020106

Epoch: 5| Step: 8
Training loss: 2.096053123474121
Validation loss: 2.613063845583188

Epoch: 5| Step: 9
Training loss: 2.7693378925323486
Validation loss: 2.6125942378915767

Epoch: 5| Step: 10
Training loss: 2.553497314453125
Validation loss: 2.611796937963014

Epoch: 55| Step: 0
Training loss: 2.6070008277893066
Validation loss: 2.6086294061394146

Epoch: 5| Step: 1
Training loss: 2.119682788848877
Validation loss: 2.604760995475195

Epoch: 5| Step: 2
Training loss: 2.8627076148986816
Validation loss: 2.6039383539589505

Epoch: 5| Step: 3
Training loss: 2.9598166942596436
Validation loss: 2.608250738472067

Epoch: 5| Step: 4
Training loss: 2.897387981414795
Validation loss: 2.6080580834419496

Epoch: 5| Step: 5
Training loss: 3.1549110412597656
Validation loss: 2.6127105887218187

Epoch: 5| Step: 6
Training loss: 2.2661755084991455
Validation loss: 2.6086855601238947

Epoch: 5| Step: 7
Training loss: 2.527196168899536
Validation loss: 2.6021573825549056

Epoch: 5| Step: 8
Training loss: 3.0152392387390137
Validation loss: 2.603167126255651

Epoch: 5| Step: 9
Training loss: 3.150103807449341
Validation loss: 2.600789446984568

Epoch: 5| Step: 10
Training loss: 2.851771831512451
Validation loss: 2.601309371250932

Epoch: 56| Step: 0
Training loss: 2.7743473052978516
Validation loss: 2.6027084140367407

Epoch: 5| Step: 1
Training loss: 2.7071468830108643
Validation loss: 2.5997842409277476

Epoch: 5| Step: 2
Training loss: 2.248600959777832
Validation loss: 2.60533243866377

Epoch: 5| Step: 3
Training loss: 3.5491700172424316
Validation loss: 2.6112175346702657

Epoch: 5| Step: 4
Training loss: 2.7302651405334473
Validation loss: 2.6091579698747203

Epoch: 5| Step: 5
Training loss: 2.6130943298339844
Validation loss: 2.6006329597965365

Epoch: 5| Step: 6
Training loss: 2.663964033126831
Validation loss: 2.596697968821372

Epoch: 5| Step: 7
Training loss: 2.7342123985290527
Validation loss: 2.5962415715699554

Epoch: 5| Step: 8
Training loss: 2.656050205230713
Validation loss: 2.590095122655233

Epoch: 5| Step: 9
Training loss: 3.217390537261963
Validation loss: 2.5916606687730357

Epoch: 5| Step: 10
Training loss: 2.412735939025879
Validation loss: 2.5934763569985666

Epoch: 57| Step: 0
Training loss: 3.0712828636169434
Validation loss: 2.5939415885556127

Epoch: 5| Step: 1
Training loss: 2.1897501945495605
Validation loss: 2.5908346637602775

Epoch: 5| Step: 2
Training loss: 2.9961628913879395
Validation loss: 2.5896268326749086

Epoch: 5| Step: 3
Training loss: 2.667797803878784
Validation loss: 2.590499734365812

Epoch: 5| Step: 4
Training loss: 2.7286951541900635
Validation loss: 2.5894145811757734

Epoch: 5| Step: 5
Training loss: 2.972743511199951
Validation loss: 2.5878383472401607

Epoch: 5| Step: 6
Training loss: 2.40606689453125
Validation loss: 2.5866128193434847

Epoch: 5| Step: 7
Training loss: 2.967062473297119
Validation loss: 2.588605139845161

Epoch: 5| Step: 8
Training loss: 2.255340337753296
Validation loss: 2.59190034866333

Epoch: 5| Step: 9
Training loss: 2.5979979038238525
Validation loss: 2.588131184219032

Epoch: 5| Step: 10
Training loss: 3.553715467453003
Validation loss: 2.5894966586943595

Epoch: 58| Step: 0
Training loss: 2.0391762256622314
Validation loss: 2.5870265140328357

Epoch: 5| Step: 1
Training loss: 2.4545769691467285
Validation loss: 2.5879120313993065

Epoch: 5| Step: 2
Training loss: 2.4693665504455566
Validation loss: 2.5838063506669897

Epoch: 5| Step: 3
Training loss: 3.0199763774871826
Validation loss: 2.581058886743361

Epoch: 5| Step: 4
Training loss: 3.4503417015075684
Validation loss: 2.5820860657640683

Epoch: 5| Step: 5
Training loss: 2.9921603202819824
Validation loss: 2.580506517041114

Epoch: 5| Step: 6
Training loss: 2.7860333919525146
Validation loss: 2.5807505153840586

Epoch: 5| Step: 7
Training loss: 2.5127456188201904
Validation loss: 2.5790119350597425

Epoch: 5| Step: 8
Training loss: 2.5998008251190186
Validation loss: 2.5805145873818347

Epoch: 5| Step: 9
Training loss: 2.6051697731018066
Validation loss: 2.5795687731876167

Epoch: 5| Step: 10
Training loss: 3.376619338989258
Validation loss: 2.5810834643661336

Epoch: 59| Step: 0
Training loss: 2.39119291305542
Validation loss: 2.5785405302560456

Epoch: 5| Step: 1
Training loss: 3.3926138877868652
Validation loss: 2.576266404121153

Epoch: 5| Step: 2
Training loss: 2.182515859603882
Validation loss: 2.5738813159286336

Epoch: 5| Step: 3
Training loss: 2.1387007236480713
Validation loss: 2.578296297339983

Epoch: 5| Step: 4
Training loss: 3.076291084289551
Validation loss: 2.576864073353429

Epoch: 5| Step: 5
Training loss: 2.7364354133605957
Validation loss: 2.5782860094501125

Epoch: 5| Step: 6
Training loss: 2.794762372970581
Validation loss: 2.5795729493582122

Epoch: 5| Step: 7
Training loss: 2.4521305561065674
Validation loss: 2.57801422508814

Epoch: 5| Step: 8
Training loss: 2.155123710632324
Validation loss: 2.5780981074097338

Epoch: 5| Step: 9
Training loss: 3.5050761699676514
Validation loss: 2.5758489921528804

Epoch: 5| Step: 10
Training loss: 3.503755807876587
Validation loss: 2.575953911709529

Epoch: 60| Step: 0
Training loss: 2.922650098800659
Validation loss: 2.5748087026739634

Epoch: 5| Step: 1
Training loss: 2.2596678733825684
Validation loss: 2.5720009880681194

Epoch: 5| Step: 2
Training loss: 2.9432926177978516
Validation loss: 2.5775386159138014

Epoch: 5| Step: 3
Training loss: 2.362757682800293
Validation loss: 2.578948579808717

Epoch: 5| Step: 4
Training loss: 3.179262638092041
Validation loss: 2.5805685007443993

Epoch: 5| Step: 5
Training loss: 3.4086754322052
Validation loss: 2.573284929798495

Epoch: 5| Step: 6
Training loss: 1.942652940750122
Validation loss: 2.571015193898191

Epoch: 5| Step: 7
Training loss: 2.7809901237487793
Validation loss: 2.5660730843902915

Epoch: 5| Step: 8
Training loss: 3.3833396434783936
Validation loss: 2.5637173806467364

Epoch: 5| Step: 9
Training loss: 2.7989277839660645
Validation loss: 2.566240874669885

Epoch: 5| Step: 10
Training loss: 2.0252225399017334
Validation loss: 2.563409472024569

Epoch: 61| Step: 0
Training loss: 2.6407558917999268
Validation loss: 2.5654265316583778

Epoch: 5| Step: 1
Training loss: 2.882114887237549
Validation loss: 2.5629872275936987

Epoch: 5| Step: 2
Training loss: 2.4847490787506104
Validation loss: 2.5648215329775246

Epoch: 5| Step: 3
Training loss: 2.712313175201416
Validation loss: 2.5649695216968493

Epoch: 5| Step: 4
Training loss: 2.735532760620117
Validation loss: 2.5623779963421565

Epoch: 5| Step: 5
Training loss: 2.7708256244659424
Validation loss: 2.5634223876460904

Epoch: 5| Step: 6
Training loss: 2.6818559169769287
Validation loss: 2.566746509203347

Epoch: 5| Step: 7
Training loss: 2.6492483615875244
Validation loss: 2.5691187740654073

Epoch: 5| Step: 8
Training loss: 2.5510799884796143
Validation loss: 2.567702160086683

Epoch: 5| Step: 9
Training loss: 2.973888635635376
Validation loss: 2.5673150298415974

Epoch: 5| Step: 10
Training loss: 3.033930778503418
Validation loss: 2.5574758847554526

Epoch: 62| Step: 0
Training loss: 2.9596056938171387
Validation loss: 2.557550863553119

Epoch: 5| Step: 1
Training loss: 1.8941659927368164
Validation loss: 2.5575448928340787

Epoch: 5| Step: 2
Training loss: 2.544393301010132
Validation loss: 2.5588715358447005

Epoch: 5| Step: 3
Training loss: 2.02946138381958
Validation loss: 2.556506520958357

Epoch: 5| Step: 4
Training loss: 2.9722182750701904
Validation loss: 2.5539808222042617

Epoch: 5| Step: 5
Training loss: 2.426107406616211
Validation loss: 2.5574890977592877

Epoch: 5| Step: 6
Training loss: 3.2371819019317627
Validation loss: 2.552086276392783

Epoch: 5| Step: 7
Training loss: 3.168440818786621
Validation loss: 2.5535571498255574

Epoch: 5| Step: 8
Training loss: 2.7945754528045654
Validation loss: 2.554168288425733

Epoch: 5| Step: 9
Training loss: 2.98722505569458
Validation loss: 2.5534727137575866

Epoch: 5| Step: 10
Training loss: 3.012385845184326
Validation loss: 2.5549946984937115

Epoch: 63| Step: 0
Training loss: 3.2565300464630127
Validation loss: 2.5601495594106694

Epoch: 5| Step: 1
Training loss: 2.4937407970428467
Validation loss: 2.5661125106196248

Epoch: 5| Step: 2
Training loss: 2.1901307106018066
Validation loss: 2.5592190091327955

Epoch: 5| Step: 3
Training loss: 2.484372854232788
Validation loss: 2.5569076461176716

Epoch: 5| Step: 4
Training loss: 3.092630386352539
Validation loss: 2.5609082688567457

Epoch: 5| Step: 5
Training loss: 2.5179107189178467
Validation loss: 2.551956735631471

Epoch: 5| Step: 6
Training loss: 2.3326659202575684
Validation loss: 2.5468060995942805

Epoch: 5| Step: 7
Training loss: 2.7646942138671875
Validation loss: 2.5493179931435535

Epoch: 5| Step: 8
Training loss: 2.9225001335144043
Validation loss: 2.545704367340252

Epoch: 5| Step: 9
Training loss: 2.928218364715576
Validation loss: 2.5490777261795534

Epoch: 5| Step: 10
Training loss: 2.9907283782958984
Validation loss: 2.549634474580006

Epoch: 64| Step: 0
Training loss: 2.3697311878204346
Validation loss: 2.5516757426723355

Epoch: 5| Step: 1
Training loss: 2.447916269302368
Validation loss: 2.543296592209929

Epoch: 5| Step: 2
Training loss: 2.922802448272705
Validation loss: 2.5417616905704623

Epoch: 5| Step: 3
Training loss: 3.16487193107605
Validation loss: 2.5447052524935816

Epoch: 5| Step: 4
Training loss: 2.8009729385375977
Validation loss: 2.5450257537185506

Epoch: 5| Step: 5
Training loss: 2.9385340213775635
Validation loss: 2.5422939254391577

Epoch: 5| Step: 6
Training loss: 2.74884295463562
Validation loss: 2.5473275928087133

Epoch: 5| Step: 7
Training loss: 3.209620714187622
Validation loss: 2.5540917970800914

Epoch: 5| Step: 8
Training loss: 2.462902307510376
Validation loss: 2.552381221966077

Epoch: 5| Step: 9
Training loss: 2.598217725753784
Validation loss: 2.5524755088231896

Epoch: 5| Step: 10
Training loss: 2.141916275024414
Validation loss: 2.557197375964093

Epoch: 65| Step: 0
Training loss: 2.7012295722961426
Validation loss: 2.5451902010107554

Epoch: 5| Step: 1
Training loss: 3.0608386993408203
Validation loss: 2.540478269259135

Epoch: 5| Step: 2
Training loss: 2.585468292236328
Validation loss: 2.5344364053459576

Epoch: 5| Step: 3
Training loss: 3.3384852409362793
Validation loss: 2.5348507896546395

Epoch: 5| Step: 4
Training loss: 2.7442469596862793
Validation loss: 2.532921434730612

Epoch: 5| Step: 5
Training loss: 2.878857374191284
Validation loss: 2.534156948007563

Epoch: 5| Step: 6
Training loss: 2.786613702774048
Validation loss: 2.537877590425553

Epoch: 5| Step: 7
Training loss: 2.4641451835632324
Validation loss: 2.5335363393188803

Epoch: 5| Step: 8
Training loss: 2.2421581745147705
Validation loss: 2.530017296473185

Epoch: 5| Step: 9
Training loss: 2.8284077644348145
Validation loss: 2.5316965656895793

Epoch: 5| Step: 10
Training loss: 2.1238813400268555
Validation loss: 2.5295779935775267

Epoch: 66| Step: 0
Training loss: 3.335989475250244
Validation loss: 2.5313470978890695

Epoch: 5| Step: 1
Training loss: 3.0004563331604004
Validation loss: 2.542688028786772

Epoch: 5| Step: 2
Training loss: 2.540522813796997
Validation loss: 2.5491859502689813

Epoch: 5| Step: 3
Training loss: 2.076885938644409
Validation loss: 2.5412283917909027

Epoch: 5| Step: 4
Training loss: 3.331354856491089
Validation loss: 2.5467397166836645

Epoch: 5| Step: 5
Training loss: 2.784729480743408
Validation loss: 2.5439557388264644

Epoch: 5| Step: 6
Training loss: 3.0867509841918945
Validation loss: 2.5489611010397635

Epoch: 5| Step: 7
Training loss: 2.5349013805389404
Validation loss: 2.554353011551724

Epoch: 5| Step: 8
Training loss: 2.2073333263397217
Validation loss: 2.534414922037432

Epoch: 5| Step: 9
Training loss: 2.328012466430664
Validation loss: 2.529065878160538

Epoch: 5| Step: 10
Training loss: 2.5445125102996826
Validation loss: 2.5265871453028854

Epoch: 67| Step: 0
Training loss: 2.2221317291259766
Validation loss: 2.5279327310541624

Epoch: 5| Step: 1
Training loss: 3.5262463092803955
Validation loss: 2.5351908642758607

Epoch: 5| Step: 2
Training loss: 2.7672924995422363
Validation loss: 2.537919872550554

Epoch: 5| Step: 3
Training loss: 2.7283687591552734
Validation loss: 2.5422581536795503

Epoch: 5| Step: 4
Training loss: 2.8091719150543213
Validation loss: 2.539882251011428

Epoch: 5| Step: 5
Training loss: 2.4674999713897705
Validation loss: 2.536258984637517

Epoch: 5| Step: 6
Training loss: 3.0857226848602295
Validation loss: 2.535060162185341

Epoch: 5| Step: 7
Training loss: 2.4969849586486816
Validation loss: 2.5317542860584874

Epoch: 5| Step: 8
Training loss: 2.5595829486846924
Validation loss: 2.5307439424658336

Epoch: 5| Step: 9
Training loss: 2.7407288551330566
Validation loss: 2.523159908991988

Epoch: 5| Step: 10
Training loss: 2.4706871509552
Validation loss: 2.522142230823476

Epoch: 68| Step: 0
Training loss: 3.224681854248047
Validation loss: 2.5153127049887054

Epoch: 5| Step: 1
Training loss: 2.345205783843994
Validation loss: 2.5187132076550554

Epoch: 5| Step: 2
Training loss: 2.344656229019165
Validation loss: 2.519643747678367

Epoch: 5| Step: 3
Training loss: 3.1491503715515137
Validation loss: 2.5325756278089298

Epoch: 5| Step: 4
Training loss: 2.4298908710479736
Validation loss: 2.539707981130128

Epoch: 5| Step: 5
Training loss: 2.780906915664673
Validation loss: 2.557249125613961

Epoch: 5| Step: 6
Training loss: 2.6880598068237305
Validation loss: 2.547455838931504

Epoch: 5| Step: 7
Training loss: 2.788978099822998
Validation loss: 2.5266417508484214

Epoch: 5| Step: 8
Training loss: 2.2382922172546387
Validation loss: 2.5186894196335987

Epoch: 5| Step: 9
Training loss: 3.0974738597869873
Validation loss: 2.5117794518829673

Epoch: 5| Step: 10
Training loss: 2.763795852661133
Validation loss: 2.5142673266831266

Epoch: 69| Step: 0
Training loss: 3.0261473655700684
Validation loss: 2.5188133178218717

Epoch: 5| Step: 1
Training loss: 2.907421827316284
Validation loss: 2.520094112683368

Epoch: 5| Step: 2
Training loss: 2.5740528106689453
Validation loss: 2.52681295077006

Epoch: 5| Step: 3
Training loss: 2.756507158279419
Validation loss: 2.556714141240684

Epoch: 5| Step: 4
Training loss: 2.050832748413086
Validation loss: 2.5384935307246383

Epoch: 5| Step: 5
Training loss: 2.9048542976379395
Validation loss: 2.516483852940221

Epoch: 5| Step: 6
Training loss: 3.126180410385132
Validation loss: 2.508934082523469

Epoch: 5| Step: 7
Training loss: 2.5284461975097656
Validation loss: 2.532048325384817

Epoch: 5| Step: 8
Training loss: 2.7990565299987793
Validation loss: 2.556299509540681

Epoch: 5| Step: 9
Training loss: 2.519965887069702
Validation loss: 2.6200152417664886

Epoch: 5| Step: 10
Training loss: 2.841200351715088
Validation loss: 2.615855622035201

Epoch: 70| Step: 0
Training loss: 3.2933297157287598
Validation loss: 2.5911228784950833

Epoch: 5| Step: 1
Training loss: 3.263076066970825
Validation loss: 2.5443888248935824

Epoch: 5| Step: 2
Training loss: 2.802431583404541
Validation loss: 2.5117060702334166

Epoch: 5| Step: 3
Training loss: 2.436075210571289
Validation loss: 2.5069524959851335

Epoch: 5| Step: 4
Training loss: 3.1032252311706543
Validation loss: 2.51539110624662

Epoch: 5| Step: 5
Training loss: 2.6022682189941406
Validation loss: 2.520866594006938

Epoch: 5| Step: 6
Training loss: 2.9912056922912598
Validation loss: 2.5282507506749963

Epoch: 5| Step: 7
Training loss: 2.6909186840057373
Validation loss: 2.566109252232377

Epoch: 5| Step: 8
Training loss: 2.7281272411346436
Validation loss: 2.548441820247199

Epoch: 5| Step: 9
Training loss: 1.942204475402832
Validation loss: 2.5212248217674995

Epoch: 5| Step: 10
Training loss: 2.0912671089172363
Validation loss: 2.515987411622078

Epoch: 71| Step: 0
Training loss: 2.699711322784424
Validation loss: 2.5066719362812657

Epoch: 5| Step: 1
Training loss: 2.483438491821289
Validation loss: 2.500570099840882

Epoch: 5| Step: 2
Training loss: 2.5631155967712402
Validation loss: 2.5070939422935568

Epoch: 5| Step: 3
Training loss: 2.7023303508758545
Validation loss: 2.5381705248227684

Epoch: 5| Step: 4
Training loss: 2.3851158618927
Validation loss: 2.5508170948233655

Epoch: 5| Step: 5
Training loss: 3.322603940963745
Validation loss: 2.54052395461708

Epoch: 5| Step: 6
Training loss: 3.049638271331787
Validation loss: 2.518813722877092

Epoch: 5| Step: 7
Training loss: 2.837043046951294
Validation loss: 2.5010267893473306

Epoch: 5| Step: 8
Training loss: 2.278795003890991
Validation loss: 2.4935232670076433

Epoch: 5| Step: 9
Training loss: 3.0367772579193115
Validation loss: 2.5003709536726757

Epoch: 5| Step: 10
Training loss: 2.3722305297851562
Validation loss: 2.5097245939316286

Epoch: 72| Step: 0
Training loss: 3.0006155967712402
Validation loss: 2.514265165534071

Epoch: 5| Step: 1
Training loss: 2.0199949741363525
Validation loss: 2.5163538481599543

Epoch: 5| Step: 2
Training loss: 3.343367099761963
Validation loss: 2.518555082300658

Epoch: 5| Step: 3
Training loss: 3.0492031574249268
Validation loss: 2.5152619449041222

Epoch: 5| Step: 4
Training loss: 2.330984354019165
Validation loss: 2.515428794327603

Epoch: 5| Step: 5
Training loss: 3.032097339630127
Validation loss: 2.5090310855578353

Epoch: 5| Step: 6
Training loss: 2.7553551197052
Validation loss: 2.5065471613278953

Epoch: 5| Step: 7
Training loss: 2.923766613006592
Validation loss: 2.5056780512614916

Epoch: 5| Step: 8
Training loss: 2.294732093811035
Validation loss: 2.504130635210263

Epoch: 5| Step: 9
Training loss: 2.4899849891662598
Validation loss: 2.500850251925889

Epoch: 5| Step: 10
Training loss: 2.5755233764648438
Validation loss: 2.4968106336491083

Epoch: 73| Step: 0
Training loss: 3.125439167022705
Validation loss: 2.497864592459894

Epoch: 5| Step: 1
Training loss: 2.7714953422546387
Validation loss: 2.4965987820779123

Epoch: 5| Step: 2
Training loss: 1.8814855813980103
Validation loss: 2.517142629110685

Epoch: 5| Step: 3
Training loss: 2.9030988216400146
Validation loss: 2.5343540612087456

Epoch: 5| Step: 4
Training loss: 2.5632376670837402
Validation loss: 2.5496155446575535

Epoch: 5| Step: 5
Training loss: 2.9218008518218994
Validation loss: 2.567160339765651

Epoch: 5| Step: 6
Training loss: 3.188559055328369
Validation loss: 2.5447976332838818

Epoch: 5| Step: 7
Training loss: 2.796598196029663
Validation loss: 2.489250211305516

Epoch: 5| Step: 8
Training loss: 2.956395149230957
Validation loss: 2.488269372652936

Epoch: 5| Step: 9
Training loss: 2.397935628890991
Validation loss: 2.4927960083048832

Epoch: 5| Step: 10
Training loss: 2.237325668334961
Validation loss: 2.496852180009247

Epoch: 74| Step: 0
Training loss: 3.004739284515381
Validation loss: 2.504985832398938

Epoch: 5| Step: 1
Training loss: 2.4710729122161865
Validation loss: 2.499414628551852

Epoch: 5| Step: 2
Training loss: 2.748791217803955
Validation loss: 2.494933469321138

Epoch: 5| Step: 3
Training loss: 2.5169105529785156
Validation loss: 2.4901961229180776

Epoch: 5| Step: 4
Training loss: 2.915764808654785
Validation loss: 2.49205881293102

Epoch: 5| Step: 5
Training loss: 2.8627068996429443
Validation loss: 2.4850587460302536

Epoch: 5| Step: 6
Training loss: 2.5030500888824463
Validation loss: 2.484378481423983

Epoch: 5| Step: 7
Training loss: 2.915912389755249
Validation loss: 2.4849364398628153

Epoch: 5| Step: 8
Training loss: 2.4416604042053223
Validation loss: 2.4822814874751593

Epoch: 5| Step: 9
Training loss: 1.9486873149871826
Validation loss: 2.4895837230067097

Epoch: 5| Step: 10
Training loss: 3.443760871887207
Validation loss: 2.490026788045001

Epoch: 75| Step: 0
Training loss: 2.6679975986480713
Validation loss: 2.48868158812164

Epoch: 5| Step: 1
Training loss: 3.0889387130737305
Validation loss: 2.4909894645854993

Epoch: 5| Step: 2
Training loss: 2.257761001586914
Validation loss: 2.492871005048034

Epoch: 5| Step: 3
Training loss: 2.453068494796753
Validation loss: 2.4919163052753737

Epoch: 5| Step: 4
Training loss: 3.120952844619751
Validation loss: 2.4824839330488637

Epoch: 5| Step: 5
Training loss: 2.9022557735443115
Validation loss: 2.4839837320389284

Epoch: 5| Step: 6
Training loss: 2.2570502758026123
Validation loss: 2.484315615828319

Epoch: 5| Step: 7
Training loss: 2.1062583923339844
Validation loss: 2.4860092439959125

Epoch: 5| Step: 8
Training loss: 2.927417039871216
Validation loss: 2.4850394597617527

Epoch: 5| Step: 9
Training loss: 2.9836843013763428
Validation loss: 2.481712700218283

Epoch: 5| Step: 10
Training loss: 2.8333120346069336
Validation loss: 2.4786859712293072

Testing loss: 2.621020237604777
