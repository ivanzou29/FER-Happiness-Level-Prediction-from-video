Epoch: 1| Step: 0
Training loss: 4.182059288024902
Validation loss: 5.19025791845014

Epoch: 5| Step: 1
Training loss: 4.7487053871154785
Validation loss: 5.171185457578269

Epoch: 5| Step: 2
Training loss: 5.300759792327881
Validation loss: 5.1527961864266345

Epoch: 5| Step: 3
Training loss: 4.060369491577148
Validation loss: 5.134429608621905

Epoch: 5| Step: 4
Training loss: 4.310233116149902
Validation loss: 5.1127074200619935

Epoch: 5| Step: 5
Training loss: 7.111104488372803
Validation loss: 5.088099551457231

Epoch: 5| Step: 6
Training loss: 4.545981407165527
Validation loss: 5.060921633115378

Epoch: 5| Step: 7
Training loss: 4.739312171936035
Validation loss: 5.02993433449858

Epoch: 5| Step: 8
Training loss: 4.647965431213379
Validation loss: 4.994082796958185

Epoch: 5| Step: 9
Training loss: 6.233670711517334
Validation loss: 4.953566166662401

Epoch: 5| Step: 10
Training loss: 3.428786277770996
Validation loss: 4.908219527172786

Epoch: 2| Step: 0
Training loss: 4.042677879333496
Validation loss: 4.8582277041609565

Epoch: 5| Step: 1
Training loss: 5.567559242248535
Validation loss: 4.8027976302690405

Epoch: 5| Step: 2
Training loss: 5.403689384460449
Validation loss: 4.742066214161534

Epoch: 5| Step: 3
Training loss: 5.137997627258301
Validation loss: 4.680990367807368

Epoch: 5| Step: 4
Training loss: 3.990994691848755
Validation loss: 4.616296778443039

Epoch: 5| Step: 5
Training loss: 3.5961239337921143
Validation loss: 4.55132516225179

Epoch: 5| Step: 6
Training loss: 4.847987174987793
Validation loss: 4.487023943214006

Epoch: 5| Step: 7
Training loss: 3.834948778152466
Validation loss: 4.423967412723008

Epoch: 5| Step: 8
Training loss: 4.2592339515686035
Validation loss: 4.367171872046686

Epoch: 5| Step: 9
Training loss: 3.408261775970459
Validation loss: 4.317017642400598

Epoch: 5| Step: 10
Training loss: 3.517282485961914
Validation loss: 4.273607833411104

Epoch: 3| Step: 0
Training loss: 4.5353498458862305
Validation loss: 4.232820631355367

Epoch: 5| Step: 1
Training loss: 3.9489009380340576
Validation loss: 4.1950101134597615

Epoch: 5| Step: 2
Training loss: 4.028273582458496
Validation loss: 4.157298234201247

Epoch: 5| Step: 3
Training loss: 4.440890312194824
Validation loss: 4.117177183910083

Epoch: 5| Step: 4
Training loss: 4.606851100921631
Validation loss: 4.073207739860781

Epoch: 5| Step: 5
Training loss: 3.6923346519470215
Validation loss: 4.029752864632555

Epoch: 5| Step: 6
Training loss: 3.808793544769287
Validation loss: 3.989597920448549

Epoch: 5| Step: 7
Training loss: 4.055482864379883
Validation loss: 3.9487053348172094

Epoch: 5| Step: 8
Training loss: 3.3174827098846436
Validation loss: 3.911741651514525

Epoch: 5| Step: 9
Training loss: 3.5949084758758545
Validation loss: 3.8759481573617585

Epoch: 5| Step: 10
Training loss: 2.4315896034240723
Validation loss: 3.842448406322028

Epoch: 4| Step: 0
Training loss: 3.567981004714966
Validation loss: 3.81084091688997

Epoch: 5| Step: 1
Training loss: 3.6791045665740967
Validation loss: 3.7798291611415085

Epoch: 5| Step: 2
Training loss: 3.50410532951355
Validation loss: 3.7472086901305826

Epoch: 5| Step: 3
Training loss: 3.3967833518981934
Validation loss: 3.7194083429151967

Epoch: 5| Step: 4
Training loss: 3.266040802001953
Validation loss: 3.690933160884406

Epoch: 5| Step: 5
Training loss: 3.7896485328674316
Validation loss: 3.6678175721117245

Epoch: 5| Step: 6
Training loss: 3.3773410320281982
Validation loss: 3.6484053622009935

Epoch: 5| Step: 7
Training loss: 3.5916943550109863
Validation loss: 3.6309508123705463

Epoch: 5| Step: 8
Training loss: 3.1225318908691406
Validation loss: 3.615909702034407

Epoch: 5| Step: 9
Training loss: 4.027499198913574
Validation loss: 3.6011785332874586

Epoch: 5| Step: 10
Training loss: 4.151989459991455
Validation loss: 3.5828725138018207

Epoch: 5| Step: 0
Training loss: 3.7264370918273926
Validation loss: 3.567359724352437

Epoch: 5| Step: 1
Training loss: 3.7345633506774902
Validation loss: 3.552981376647949

Epoch: 5| Step: 2
Training loss: 2.804321765899658
Validation loss: 3.535454547533425

Epoch: 5| Step: 3
Training loss: 3.475736141204834
Validation loss: 3.5245618435644333

Epoch: 5| Step: 4
Training loss: 3.9800000190734863
Validation loss: 3.51412259891469

Epoch: 5| Step: 5
Training loss: 3.9011504650115967
Validation loss: 3.500328997130035

Epoch: 5| Step: 6
Training loss: 3.0105466842651367
Validation loss: 3.4888072834219983

Epoch: 5| Step: 7
Training loss: 3.466548442840576
Validation loss: 3.4729792841019167

Epoch: 5| Step: 8
Training loss: 3.398754119873047
Validation loss: 3.4602620499108427

Epoch: 5| Step: 9
Training loss: 2.645397663116455
Validation loss: 3.4466830940656763

Epoch: 5| Step: 10
Training loss: 3.735659122467041
Validation loss: 3.4353102330238587

Epoch: 6| Step: 0
Training loss: 3.839890241622925
Validation loss: 3.423824458993891

Epoch: 5| Step: 1
Training loss: 3.520170211791992
Validation loss: 3.4151165305927234

Epoch: 5| Step: 2
Training loss: 3.4553496837615967
Validation loss: 3.401359106904717

Epoch: 5| Step: 3
Training loss: 4.39937686920166
Validation loss: 3.3968986900903846

Epoch: 5| Step: 4
Training loss: 2.787205934524536
Validation loss: 3.379722192723264

Epoch: 5| Step: 5
Training loss: 2.4416091442108154
Validation loss: 3.3690398405956965

Epoch: 5| Step: 6
Training loss: 2.7460594177246094
Validation loss: 3.3599350170422624

Epoch: 5| Step: 7
Training loss: 3.2759742736816406
Validation loss: 3.3520021284780195

Epoch: 5| Step: 8
Training loss: 3.810927629470825
Validation loss: 3.342011792685396

Epoch: 5| Step: 9
Training loss: 3.9981002807617188
Validation loss: 3.331481795157156

Epoch: 5| Step: 10
Training loss: 2.2345309257507324
Validation loss: 3.3204116103469685

Epoch: 7| Step: 0
Training loss: 3.225102186203003
Validation loss: 3.3124871048876035

Epoch: 5| Step: 1
Training loss: 3.532052516937256
Validation loss: 3.302270717518304

Epoch: 5| Step: 2
Training loss: 2.3556528091430664
Validation loss: 3.2949770830010854

Epoch: 5| Step: 3
Training loss: 3.740565061569214
Validation loss: 3.2860105294053272

Epoch: 5| Step: 4
Training loss: 3.959712266921997
Validation loss: 3.277277177379977

Epoch: 5| Step: 5
Training loss: 3.2316651344299316
Validation loss: 3.2821041845506236

Epoch: 5| Step: 6
Training loss: 3.6050689220428467
Validation loss: 3.2594075126032673

Epoch: 5| Step: 7
Training loss: 3.5455322265625
Validation loss: 3.2511412379562215

Epoch: 5| Step: 8
Training loss: 2.908961296081543
Validation loss: 3.245248853519399

Epoch: 5| Step: 9
Training loss: 3.4626708030700684
Validation loss: 3.238427480061849

Epoch: 5| Step: 10
Training loss: 2.0149779319763184
Validation loss: 3.2308112472616215

Epoch: 8| Step: 0
Training loss: 2.692866086959839
Validation loss: 3.2213001917767268

Epoch: 5| Step: 1
Training loss: 3.560230255126953
Validation loss: 3.2147467854202434

Epoch: 5| Step: 2
Training loss: 2.863821506500244
Validation loss: 3.2052657347853466

Epoch: 5| Step: 3
Training loss: 3.6767666339874268
Validation loss: 3.1970302084440827

Epoch: 5| Step: 4
Training loss: 3.2171401977539062
Validation loss: 3.18871215081984

Epoch: 5| Step: 5
Training loss: 2.3898072242736816
Validation loss: 3.1794292747333484

Epoch: 5| Step: 6
Training loss: 3.324441432952881
Validation loss: 3.167294443294566

Epoch: 5| Step: 7
Training loss: 3.206937789916992
Validation loss: 3.1495010724631687

Epoch: 5| Step: 8
Training loss: 2.9452779293060303
Validation loss: 3.1380986757175897

Epoch: 5| Step: 9
Training loss: 3.2061123847961426
Validation loss: 3.1300535714754494

Epoch: 5| Step: 10
Training loss: 3.961015224456787
Validation loss: 3.122201370936568

Epoch: 9| Step: 0
Training loss: 3.112936496734619
Validation loss: 3.113075505020798

Epoch: 5| Step: 1
Training loss: 3.9757094383239746
Validation loss: 3.100542429954775

Epoch: 5| Step: 2
Training loss: 2.735250473022461
Validation loss: 3.0912438900240007

Epoch: 5| Step: 3
Training loss: 3.097482204437256
Validation loss: 3.087493327356154

Epoch: 5| Step: 4
Training loss: 3.506204128265381
Validation loss: 3.1179056500875824

Epoch: 5| Step: 5
Training loss: 2.4563753604888916
Validation loss: 3.0642665252890637

Epoch: 5| Step: 6
Training loss: 3.9591259956359863
Validation loss: 3.049989605462679

Epoch: 5| Step: 7
Training loss: 2.7183945178985596
Validation loss: 3.0460488898779756

Epoch: 5| Step: 8
Training loss: 2.524294376373291
Validation loss: 3.046589248923845

Epoch: 5| Step: 9
Training loss: 2.642716884613037
Validation loss: 3.0453671639965427

Epoch: 5| Step: 10
Training loss: 3.514472246170044
Validation loss: 3.030237418349071

Epoch: 10| Step: 0
Training loss: 2.3715980052948
Validation loss: 3.014983853986186

Epoch: 5| Step: 1
Training loss: 2.533909559249878
Validation loss: 3.0121336931823404

Epoch: 5| Step: 2
Training loss: 3.124034881591797
Validation loss: 3.018366080458446

Epoch: 5| Step: 3
Training loss: 2.8049323558807373
Validation loss: 3.008449985134986

Epoch: 5| Step: 4
Training loss: 2.955296754837036
Validation loss: 2.9981052567881923

Epoch: 5| Step: 5
Training loss: 3.349512815475464
Validation loss: 2.9800086277787403

Epoch: 5| Step: 6
Training loss: 2.735283374786377
Validation loss: 2.9661391729949624

Epoch: 5| Step: 7
Training loss: 3.658186674118042
Validation loss: 2.968314498983404

Epoch: 5| Step: 8
Training loss: 2.9438648223876953
Validation loss: 2.957596496869159

Epoch: 5| Step: 9
Training loss: 3.7576515674591064
Validation loss: 2.9512875772291616

Epoch: 5| Step: 10
Training loss: 3.3543429374694824
Validation loss: 2.9405255856052523

Epoch: 11| Step: 0
Training loss: 2.246809482574463
Validation loss: 2.9329366299413864

Epoch: 5| Step: 1
Training loss: 3.47847056388855
Validation loss: 2.9260171228839504

Epoch: 5| Step: 2
Training loss: 2.2278075218200684
Validation loss: 2.91966744904877

Epoch: 5| Step: 3
Training loss: 3.180722713470459
Validation loss: 2.915583731025778

Epoch: 5| Step: 4
Training loss: 3.03320574760437
Validation loss: 2.912838092414282

Epoch: 5| Step: 5
Training loss: 3.895566463470459
Validation loss: 2.9366549522646013

Epoch: 5| Step: 6
Training loss: 2.654200792312622
Validation loss: 2.890330655600435

Epoch: 5| Step: 7
Training loss: 2.6152312755584717
Validation loss: 2.885031569388605

Epoch: 5| Step: 8
Training loss: 3.8477752208709717
Validation loss: 2.885747048162645

Epoch: 5| Step: 9
Training loss: 2.7019059658050537
Validation loss: 2.8810158006606565

Epoch: 5| Step: 10
Training loss: 3.105933666229248
Validation loss: 2.8773734031185025

Epoch: 12| Step: 0
Training loss: 3.782089948654175
Validation loss: 2.8720659696927635

Epoch: 5| Step: 1
Training loss: 2.571082592010498
Validation loss: 2.8630361582643244

Epoch: 5| Step: 2
Training loss: 3.1687464714050293
Validation loss: 2.8558690265942643

Epoch: 5| Step: 3
Training loss: 2.4136693477630615
Validation loss: 2.8577015182023406

Epoch: 5| Step: 4
Training loss: 2.674884080886841
Validation loss: 2.864220824292911

Epoch: 5| Step: 5
Training loss: 2.8874244689941406
Validation loss: 2.8642479758108816

Epoch: 5| Step: 6
Training loss: 3.1706383228302
Validation loss: 2.857900604124992

Epoch: 5| Step: 7
Training loss: 2.7891860008239746
Validation loss: 2.8385782908367854

Epoch: 5| Step: 8
Training loss: 2.7499444484710693
Validation loss: 2.821130170617052

Epoch: 5| Step: 9
Training loss: 3.2492237091064453
Validation loss: 2.812409472721879

Epoch: 5| Step: 10
Training loss: 3.168011426925659
Validation loss: 2.8163510778898835

Epoch: 13| Step: 0
Training loss: 2.0096192359924316
Validation loss: 2.81803039837909

Epoch: 5| Step: 1
Training loss: 2.9798474311828613
Validation loss: 2.819096375537175

Epoch: 5| Step: 2
Training loss: 3.310211658477783
Validation loss: 2.8158647373158443

Epoch: 5| Step: 3
Training loss: 3.4882171154022217
Validation loss: 2.814247920948972

Epoch: 5| Step: 4
Training loss: 3.1346230506896973
Validation loss: 2.8007023257593953

Epoch: 5| Step: 5
Training loss: 2.2541165351867676
Validation loss: 2.7897211044065413

Epoch: 5| Step: 6
Training loss: 2.9299817085266113
Validation loss: 2.78535811362728

Epoch: 5| Step: 7
Training loss: 2.678074359893799
Validation loss: 2.780996281613586

Epoch: 5| Step: 8
Training loss: 2.9921317100524902
Validation loss: 2.7934012489934124

Epoch: 5| Step: 9
Training loss: 3.2086448669433594
Validation loss: 2.784949259091449

Epoch: 5| Step: 10
Training loss: 3.285552501678467
Validation loss: 2.767085265087825

Epoch: 14| Step: 0
Training loss: 3.2708466053009033
Validation loss: 2.7543498803210515

Epoch: 5| Step: 1
Training loss: 2.6619715690612793
Validation loss: 2.7548613445733183

Epoch: 5| Step: 2
Training loss: 3.5528855323791504
Validation loss: 2.7516846682435725

Epoch: 5| Step: 3
Training loss: 2.577408790588379
Validation loss: 2.7529850621377268

Epoch: 5| Step: 4
Training loss: 2.7199885845184326
Validation loss: 2.7471383540861067

Epoch: 5| Step: 5
Training loss: 2.94966983795166
Validation loss: 2.740220585177022

Epoch: 5| Step: 6
Training loss: 2.6980392932891846
Validation loss: 2.733289041826802

Epoch: 5| Step: 7
Training loss: 3.6591873168945312
Validation loss: 2.7338226354250343

Epoch: 5| Step: 8
Training loss: 1.8455474376678467
Validation loss: 2.736009218359506

Epoch: 5| Step: 9
Training loss: 3.0348479747772217
Validation loss: 2.7404369154284076

Epoch: 5| Step: 10
Training loss: 2.8610379695892334
Validation loss: 2.733511709397839

Epoch: 15| Step: 0
Training loss: 2.601104736328125
Validation loss: 2.7237696006733882

Epoch: 5| Step: 1
Training loss: 3.1693856716156006
Validation loss: 2.7162107472778647

Epoch: 5| Step: 2
Training loss: 3.3752334117889404
Validation loss: 2.716755595258487

Epoch: 5| Step: 3
Training loss: 2.8570799827575684
Validation loss: 2.7157360405050297

Epoch: 5| Step: 4
Training loss: 2.9529237747192383
Validation loss: 2.7135106594331804

Epoch: 5| Step: 5
Training loss: 2.6228244304656982
Validation loss: 2.7061902374349613

Epoch: 5| Step: 6
Training loss: 3.0946288108825684
Validation loss: 2.703792610476094

Epoch: 5| Step: 7
Training loss: 2.1989715099334717
Validation loss: 2.7012884206669305

Epoch: 5| Step: 8
Training loss: 2.972043991088867
Validation loss: 2.698519547780355

Epoch: 5| Step: 9
Training loss: 2.9932141304016113
Validation loss: 2.701956841253465

Epoch: 5| Step: 10
Training loss: 2.7537362575531006
Validation loss: 2.7001999373077066

Epoch: 16| Step: 0
Training loss: 3.4394564628601074
Validation loss: 2.700551199656661

Epoch: 5| Step: 1
Training loss: 2.581857204437256
Validation loss: 2.6960786773312475

Epoch: 5| Step: 2
Training loss: 3.3827431201934814
Validation loss: 2.690793909052367

Epoch: 5| Step: 3
Training loss: 2.6225368976593018
Validation loss: 2.687315712692917

Epoch: 5| Step: 4
Training loss: 2.507223606109619
Validation loss: 2.687633065767186

Epoch: 5| Step: 5
Training loss: 2.0860660076141357
Validation loss: 2.6841956723120903

Epoch: 5| Step: 6
Training loss: 3.0705718994140625
Validation loss: 2.684771878744966

Epoch: 5| Step: 7
Training loss: 2.275161027908325
Validation loss: 2.6831294926263953

Epoch: 5| Step: 8
Training loss: 3.1834793090820312
Validation loss: 2.6819860807029148

Epoch: 5| Step: 9
Training loss: 3.4521377086639404
Validation loss: 2.6783904978024062

Epoch: 5| Step: 10
Training loss: 2.84722638130188
Validation loss: 2.6779937833868046

Epoch: 17| Step: 0
Training loss: 3.2572360038757324
Validation loss: 2.67489367915738

Epoch: 5| Step: 1
Training loss: 2.8492960929870605
Validation loss: 2.6744109994621685

Epoch: 5| Step: 2
Training loss: 1.981196403503418
Validation loss: 2.6709171982221704

Epoch: 5| Step: 3
Training loss: 2.5211384296417236
Validation loss: 2.673956701832433

Epoch: 5| Step: 4
Training loss: 3.094473361968994
Validation loss: 2.6850994094725578

Epoch: 5| Step: 5
Training loss: 2.6327812671661377
Validation loss: 2.6621298020885837

Epoch: 5| Step: 6
Training loss: 3.3791556358337402
Validation loss: 2.661600246224352

Epoch: 5| Step: 7
Training loss: 3.1120896339416504
Validation loss: 2.659980712398406

Epoch: 5| Step: 8
Training loss: 3.226595640182495
Validation loss: 2.659770668193858

Epoch: 5| Step: 9
Training loss: 2.309121608734131
Validation loss: 2.6569412446791127

Epoch: 5| Step: 10
Training loss: 2.9186370372772217
Validation loss: 2.6569309490983204

Epoch: 18| Step: 0
Training loss: 2.9128594398498535
Validation loss: 2.6599049670721895

Epoch: 5| Step: 1
Training loss: 3.6657862663269043
Validation loss: 2.660592350908505

Epoch: 5| Step: 2
Training loss: 3.010425567626953
Validation loss: 2.65871024388139

Epoch: 5| Step: 3
Training loss: 3.0377261638641357
Validation loss: 2.653559543753183

Epoch: 5| Step: 4
Training loss: 2.9300689697265625
Validation loss: 2.649006164202126

Epoch: 5| Step: 5
Training loss: 2.918177604675293
Validation loss: 2.6466510782959642

Epoch: 5| Step: 6
Training loss: 2.3229501247406006
Validation loss: 2.643883212920158

Epoch: 5| Step: 7
Training loss: 2.5677528381347656
Validation loss: 2.6669116020202637

Epoch: 5| Step: 8
Training loss: 2.185246467590332
Validation loss: 2.6912059732662734

Epoch: 5| Step: 9
Training loss: 2.4549930095672607
Validation loss: 2.6593688175242436

Epoch: 5| Step: 10
Training loss: 3.268434524536133
Validation loss: 2.6411443243744555

Epoch: 19| Step: 0
Training loss: 2.254395008087158
Validation loss: 2.6387607948754424

Epoch: 5| Step: 1
Training loss: 3.547132968902588
Validation loss: 2.6411152988351803

Epoch: 5| Step: 2
Training loss: 2.4397614002227783
Validation loss: 2.639632781346639

Epoch: 5| Step: 3
Training loss: 2.7813234329223633
Validation loss: 2.6376849579554733

Epoch: 5| Step: 4
Training loss: 2.966703414916992
Validation loss: 2.636509269796392

Epoch: 5| Step: 5
Training loss: 2.5339462757110596
Validation loss: 2.638314513749974

Epoch: 5| Step: 6
Training loss: 2.762148857116699
Validation loss: 2.642158444209765

Epoch: 5| Step: 7
Training loss: 2.4157638549804688
Validation loss: 2.646104642139968

Epoch: 5| Step: 8
Training loss: 3.1386964321136475
Validation loss: 2.64411880893092

Epoch: 5| Step: 9
Training loss: 3.1264500617980957
Validation loss: 2.635188441122732

Epoch: 5| Step: 10
Training loss: 3.185487747192383
Validation loss: 2.6260348135425198

Epoch: 20| Step: 0
Training loss: 3.0726709365844727
Validation loss: 2.6202355251517346

Epoch: 5| Step: 1
Training loss: 2.955801486968994
Validation loss: 2.6178522571440666

Epoch: 5| Step: 2
Training loss: 2.648033380508423
Validation loss: 2.6177039812969904

Epoch: 5| Step: 3
Training loss: 2.633734941482544
Validation loss: 2.6110243797302246

Epoch: 5| Step: 4
Training loss: 3.0272397994995117
Validation loss: 2.614213284625802

Epoch: 5| Step: 5
Training loss: 2.1795525550842285
Validation loss: 2.6136153359566965

Epoch: 5| Step: 6
Training loss: 2.7831315994262695
Validation loss: 2.616635827608006

Epoch: 5| Step: 7
Training loss: 3.013568162918091
Validation loss: 2.626066500140775

Epoch: 5| Step: 8
Training loss: 2.782106399536133
Validation loss: 2.6205357018337456

Epoch: 5| Step: 9
Training loss: 2.669414520263672
Validation loss: 2.6070717175801597

Epoch: 5| Step: 10
Training loss: 3.1790151596069336
Validation loss: 2.6039727298162316

Epoch: 21| Step: 0
Training loss: 2.957035541534424
Validation loss: 2.5975495794767975

Epoch: 5| Step: 1
Training loss: 2.3836851119995117
Validation loss: 2.600963205419561

Epoch: 5| Step: 2
Training loss: 2.99391508102417
Validation loss: 2.6072986920674643

Epoch: 5| Step: 3
Training loss: 2.686957597732544
Validation loss: 2.6085787255276918

Epoch: 5| Step: 4
Training loss: 3.1545939445495605
Validation loss: 2.5885529325854395

Epoch: 5| Step: 5
Training loss: 2.837838649749756
Validation loss: 2.5994863587041057

Epoch: 5| Step: 6
Training loss: 2.1062896251678467
Validation loss: 2.606534109320692

Epoch: 5| Step: 7
Training loss: 2.3893020153045654
Validation loss: 2.592796984539237

Epoch: 5| Step: 8
Training loss: 3.793907880783081
Validation loss: 2.582915034345401

Epoch: 5| Step: 9
Training loss: 2.7708704471588135
Validation loss: 2.581567654045679

Epoch: 5| Step: 10
Training loss: 2.6456596851348877
Validation loss: 2.585594132382383

Epoch: 22| Step: 0
Training loss: 3.2437491416931152
Validation loss: 2.579170573142267

Epoch: 5| Step: 1
Training loss: 3.0679192543029785
Validation loss: 2.572112165471559

Epoch: 5| Step: 2
Training loss: 3.2794837951660156
Validation loss: 2.5721250631475963

Epoch: 5| Step: 3
Training loss: 2.798877000808716
Validation loss: 2.57522564805964

Epoch: 5| Step: 4
Training loss: 2.556528091430664
Validation loss: 2.577419009259952

Epoch: 5| Step: 5
Training loss: 3.5318665504455566
Validation loss: 2.575179515346404

Epoch: 5| Step: 6
Training loss: 2.1911022663116455
Validation loss: 2.5689596694002867

Epoch: 5| Step: 7
Training loss: 2.3292112350463867
Validation loss: 2.5656207864002516

Epoch: 5| Step: 8
Training loss: 2.5333914756774902
Validation loss: 2.5619813267902662

Epoch: 5| Step: 9
Training loss: 2.651104211807251
Validation loss: 2.567064377569383

Epoch: 5| Step: 10
Training loss: 2.359774351119995
Validation loss: 2.595695600714735

Epoch: 23| Step: 0
Training loss: 2.753831624984741
Validation loss: 2.672026088160853

Epoch: 5| Step: 1
Training loss: 2.145667552947998
Validation loss: 2.6994617139139483

Epoch: 5| Step: 2
Training loss: 2.922123432159424
Validation loss: 2.664374287410449

Epoch: 5| Step: 3
Training loss: 2.8571722507476807
Validation loss: 2.552385009745116

Epoch: 5| Step: 4
Training loss: 2.592975616455078
Validation loss: 2.551367462322276

Epoch: 5| Step: 5
Training loss: 3.43394136428833
Validation loss: 2.589164262176842

Epoch: 5| Step: 6
Training loss: 3.1675331592559814
Validation loss: 2.6053054742915656

Epoch: 5| Step: 7
Training loss: 3.417632579803467
Validation loss: 2.620119217903383

Epoch: 5| Step: 8
Training loss: 2.18595552444458
Validation loss: 2.5824681994735554

Epoch: 5| Step: 9
Training loss: 2.867131233215332
Validation loss: 2.559488760527744

Epoch: 5| Step: 10
Training loss: 2.4844281673431396
Validation loss: 2.5478216653229087

Epoch: 24| Step: 0
Training loss: 3.371039628982544
Validation loss: 2.543412982776601

Epoch: 5| Step: 1
Training loss: 2.396470546722412
Validation loss: 2.5374593555286364

Epoch: 5| Step: 2
Training loss: 3.3246092796325684
Validation loss: 2.5462477232820246

Epoch: 5| Step: 3
Training loss: 3.1325488090515137
Validation loss: 2.590189528721635

Epoch: 5| Step: 4
Training loss: 2.7243919372558594
Validation loss: 2.6445930004119873

Epoch: 5| Step: 5
Training loss: 3.181753158569336
Validation loss: 2.5779587684139127

Epoch: 5| Step: 6
Training loss: 2.4446778297424316
Validation loss: 2.5270855247333484

Epoch: 5| Step: 7
Training loss: 2.1269218921661377
Validation loss: 2.5266364902578373

Epoch: 5| Step: 8
Training loss: 1.8297926187515259
Validation loss: 2.523119380397181

Epoch: 5| Step: 9
Training loss: 3.134835720062256
Validation loss: 2.5213152054817445

Epoch: 5| Step: 10
Training loss: 2.8271262645721436
Validation loss: 2.5243779074761177

Epoch: 25| Step: 0
Training loss: 2.870997905731201
Validation loss: 2.518685740809287

Epoch: 5| Step: 1
Training loss: 2.94557523727417
Validation loss: 2.5120878296513713

Epoch: 5| Step: 2
Training loss: 1.8362869024276733
Validation loss: 2.509548274419641

Epoch: 5| Step: 3
Training loss: 2.892181158065796
Validation loss: 2.5113138665435133

Epoch: 5| Step: 4
Training loss: 2.8808484077453613
Validation loss: 2.545455645489436

Epoch: 5| Step: 5
Training loss: 3.082890748977661
Validation loss: 2.5328878536019275

Epoch: 5| Step: 6
Training loss: 2.6319198608398438
Validation loss: 2.525124931848177

Epoch: 5| Step: 7
Training loss: 2.7988169193267822
Validation loss: 2.515858542534613

Epoch: 5| Step: 8
Training loss: 3.0215582847595215
Validation loss: 2.5003068242021786

Epoch: 5| Step: 9
Training loss: 2.9099814891815186
Validation loss: 2.499510834293981

Epoch: 5| Step: 10
Training loss: 2.2883474826812744
Validation loss: 2.4967585994351293

Epoch: 26| Step: 0
Training loss: 2.1871771812438965
Validation loss: 2.4953902229186027

Epoch: 5| Step: 1
Training loss: 2.544241189956665
Validation loss: 2.4932054704235447

Epoch: 5| Step: 2
Training loss: 2.366847515106201
Validation loss: 2.4925504243502052

Epoch: 5| Step: 3
Training loss: 2.942467212677002
Validation loss: 2.490242438931619

Epoch: 5| Step: 4
Training loss: 2.795771837234497
Validation loss: 2.495890725043512

Epoch: 5| Step: 5
Training loss: 2.549898147583008
Validation loss: 2.4924293282211467

Epoch: 5| Step: 6
Training loss: 2.8246524333953857
Validation loss: 2.5264578993602465

Epoch: 5| Step: 7
Training loss: 3.2799923419952393
Validation loss: 2.5548530547849593

Epoch: 5| Step: 8
Training loss: 2.4838976860046387
Validation loss: 2.5507621688227498

Epoch: 5| Step: 9
Training loss: 2.8157572746276855
Validation loss: 2.5079455298762166

Epoch: 5| Step: 10
Training loss: 3.2768869400024414
Validation loss: 2.476393340736307

Epoch: 27| Step: 0
Training loss: 2.4895005226135254
Validation loss: 2.487358723917315

Epoch: 5| Step: 1
Training loss: 2.829390287399292
Validation loss: 2.4997725538028184

Epoch: 5| Step: 2
Training loss: 2.910154104232788
Validation loss: 2.515381120866345

Epoch: 5| Step: 3
Training loss: 2.8534443378448486
Validation loss: 2.527798852612895

Epoch: 5| Step: 4
Training loss: 3.150177001953125
Validation loss: 2.5020197976020073

Epoch: 5| Step: 5
Training loss: 2.3065035343170166
Validation loss: 2.4828964023179907

Epoch: 5| Step: 6
Training loss: 2.7287986278533936
Validation loss: 2.4790118586632515

Epoch: 5| Step: 7
Training loss: 2.482387065887451
Validation loss: 2.4863723606191654

Epoch: 5| Step: 8
Training loss: 3.0538108348846436
Validation loss: 2.511916604093326

Epoch: 5| Step: 9
Training loss: 2.8341755867004395
Validation loss: 2.513417249084801

Epoch: 5| Step: 10
Training loss: 2.4412617683410645
Validation loss: 2.533629345637496

Epoch: 28| Step: 0
Training loss: 2.0332958698272705
Validation loss: 2.5549069989112114

Epoch: 5| Step: 1
Training loss: 2.870323657989502
Validation loss: 2.5462768282941592

Epoch: 5| Step: 2
Training loss: 3.0205960273742676
Validation loss: 2.521424698573287

Epoch: 5| Step: 3
Training loss: 2.6793088912963867
Validation loss: 2.4758999347686768

Epoch: 5| Step: 4
Training loss: 2.8939709663391113
Validation loss: 2.4723595598692536

Epoch: 5| Step: 5
Training loss: 3.123629331588745
Validation loss: 2.4754402022207938

Epoch: 5| Step: 6
Training loss: 2.8116958141326904
Validation loss: 2.4764876673298497

Epoch: 5| Step: 7
Training loss: 2.730346202850342
Validation loss: 2.487400525359697

Epoch: 5| Step: 8
Training loss: 2.4523112773895264
Validation loss: 2.50575227122153

Epoch: 5| Step: 9
Training loss: 2.545374631881714
Validation loss: 2.5089158678567536

Epoch: 5| Step: 10
Training loss: 2.989875078201294
Validation loss: 2.4939354542763

Epoch: 29| Step: 0
Training loss: 2.7817881107330322
Validation loss: 2.465044721480339

Epoch: 5| Step: 1
Training loss: 2.8163113594055176
Validation loss: 2.495967152298138

Epoch: 5| Step: 2
Training loss: 2.5492799282073975
Validation loss: 2.5427838115281958

Epoch: 5| Step: 3
Training loss: 2.9172120094299316
Validation loss: 2.6314765894284813

Epoch: 5| Step: 4
Training loss: 2.775012254714966
Validation loss: 2.593735505175847

Epoch: 5| Step: 5
Training loss: 2.9092581272125244
Validation loss: 2.5293735560550483

Epoch: 5| Step: 6
Training loss: 2.6336758136749268
Validation loss: 2.455225078008508

Epoch: 5| Step: 7
Training loss: 2.5405325889587402
Validation loss: 2.4598177350977415

Epoch: 5| Step: 8
Training loss: 2.169593572616577
Validation loss: 2.4831593446834113

Epoch: 5| Step: 9
Training loss: 3.626452684402466
Validation loss: 2.536633935025943

Epoch: 5| Step: 10
Training loss: 2.358588218688965
Validation loss: 2.4899267253055366

Epoch: 30| Step: 0
Training loss: 2.863862991333008
Validation loss: 2.4713331883953464

Epoch: 5| Step: 1
Training loss: 2.711479663848877
Validation loss: 2.460285771277643

Epoch: 5| Step: 2
Training loss: 2.955387592315674
Validation loss: 2.4520845567026446

Epoch: 5| Step: 3
Training loss: 2.7408382892608643
Validation loss: 2.474100758952479

Epoch: 5| Step: 4
Training loss: 2.943533420562744
Validation loss: 2.521855200490644

Epoch: 5| Step: 5
Training loss: 2.353611707687378
Validation loss: 2.518170065777276

Epoch: 5| Step: 6
Training loss: 2.6098127365112305
Validation loss: 2.505658403519661

Epoch: 5| Step: 7
Training loss: 2.8696179389953613
Validation loss: 2.494493476806148

Epoch: 5| Step: 8
Training loss: 2.051298141479492
Validation loss: 2.475606346643099

Epoch: 5| Step: 9
Training loss: 2.843461275100708
Validation loss: 2.4503038390990226

Epoch: 5| Step: 10
Training loss: 3.047592878341675
Validation loss: 2.4462703427960797

Epoch: 31| Step: 0
Training loss: 2.673035144805908
Validation loss: 2.4441167898075555

Epoch: 5| Step: 1
Training loss: 2.822988986968994
Validation loss: 2.4412939215219147

Epoch: 5| Step: 2
Training loss: 2.7135376930236816
Validation loss: 2.4393321493620514

Epoch: 5| Step: 3
Training loss: 2.9515395164489746
Validation loss: 2.4401075698996104

Epoch: 5| Step: 4
Training loss: 3.157320499420166
Validation loss: 2.4478416417234685

Epoch: 5| Step: 5
Training loss: 2.627558469772339
Validation loss: 2.454468273347424

Epoch: 5| Step: 6
Training loss: 2.7467410564422607
Validation loss: 2.460708056726763

Epoch: 5| Step: 7
Training loss: 2.1929967403411865
Validation loss: 2.4738676945368447

Epoch: 5| Step: 8
Training loss: 2.620647430419922
Validation loss: 2.5201619145690755

Epoch: 5| Step: 9
Training loss: 2.5965373516082764
Validation loss: 2.5772377496124594

Epoch: 5| Step: 10
Training loss: 2.588217258453369
Validation loss: 2.5348866447325675

Epoch: 32| Step: 0
Training loss: 3.4540703296661377
Validation loss: 2.467132394031812

Epoch: 5| Step: 1
Training loss: 2.3082168102264404
Validation loss: 2.4272761652546544

Epoch: 5| Step: 2
Training loss: 2.9339699745178223
Validation loss: 2.437984533207391

Epoch: 5| Step: 3
Training loss: 2.483788251876831
Validation loss: 2.4615425038081344

Epoch: 5| Step: 4
Training loss: 3.077352523803711
Validation loss: 2.4645908776149956

Epoch: 5| Step: 5
Training loss: 2.4460976123809814
Validation loss: 2.4577468390105874

Epoch: 5| Step: 6
Training loss: 2.6382644176483154
Validation loss: 2.446292446505639

Epoch: 5| Step: 7
Training loss: 2.516746997833252
Validation loss: 2.427495459074615

Epoch: 5| Step: 8
Training loss: 2.535184144973755
Validation loss: 2.4287191462773148

Epoch: 5| Step: 9
Training loss: 2.7572357654571533
Validation loss: 2.4314153066245456

Epoch: 5| Step: 10
Training loss: 2.372467041015625
Validation loss: 2.473848025004069

Epoch: 33| Step: 0
Training loss: 3.0845787525177
Validation loss: 2.499968636420465

Epoch: 5| Step: 1
Training loss: 3.410179615020752
Validation loss: 2.528187131368986

Epoch: 5| Step: 2
Training loss: 2.86568546295166
Validation loss: 2.5205985294875277

Epoch: 5| Step: 3
Training loss: 2.6824893951416016
Validation loss: 2.526075311886367

Epoch: 5| Step: 4
Training loss: 2.6020102500915527
Validation loss: 2.49875029184485

Epoch: 5| Step: 5
Training loss: 3.0899248123168945
Validation loss: 2.4684595472069195

Epoch: 5| Step: 6
Training loss: 2.6233267784118652
Validation loss: 2.452667277346375

Epoch: 5| Step: 7
Training loss: 1.947153091430664
Validation loss: 2.4487553822096957

Epoch: 5| Step: 8
Training loss: 1.904044508934021
Validation loss: 2.4462625698376725

Epoch: 5| Step: 9
Training loss: 2.494579792022705
Validation loss: 2.4547235427364225

Epoch: 5| Step: 10
Training loss: 2.9938814640045166
Validation loss: 2.4608767724806264

Epoch: 34| Step: 0
Training loss: 2.3788363933563232
Validation loss: 2.476230452137609

Epoch: 5| Step: 1
Training loss: 3.126816987991333
Validation loss: 2.4800200616159747

Epoch: 5| Step: 2
Training loss: 2.338080644607544
Validation loss: 2.461807740631924

Epoch: 5| Step: 3
Training loss: 3.2509608268737793
Validation loss: 2.4476378040928997

Epoch: 5| Step: 4
Training loss: 2.4400553703308105
Validation loss: 2.4418383259927072

Epoch: 5| Step: 5
Training loss: 3.161790370941162
Validation loss: 2.43700703882402

Epoch: 5| Step: 6
Training loss: 2.5874619483947754
Validation loss: 2.4307916446398665

Epoch: 5| Step: 7
Training loss: 2.4388532638549805
Validation loss: 2.424843280546127

Epoch: 5| Step: 8
Training loss: 2.0590784549713135
Validation loss: 2.423629199304888

Epoch: 5| Step: 9
Training loss: 2.912158966064453
Validation loss: 2.4268219701705442

Epoch: 5| Step: 10
Training loss: 2.7056148052215576
Validation loss: 2.4279202581733785

Epoch: 35| Step: 0
Training loss: 2.8836891651153564
Validation loss: 2.428016108851279

Epoch: 5| Step: 1
Training loss: 2.9139657020568848
Validation loss: 2.4243730985990135

Epoch: 5| Step: 2
Training loss: 2.108532428741455
Validation loss: 2.424502544505622

Epoch: 5| Step: 3
Training loss: 3.147507667541504
Validation loss: 2.4253104579064155

Epoch: 5| Step: 4
Training loss: 2.8393330574035645
Validation loss: 2.4205701889530307

Epoch: 5| Step: 5
Training loss: 2.765925884246826
Validation loss: 2.412542514903571

Epoch: 5| Step: 6
Training loss: 2.472376823425293
Validation loss: 2.411613454100906

Epoch: 5| Step: 7
Training loss: 2.3456249237060547
Validation loss: 2.398535651545371

Epoch: 5| Step: 8
Training loss: 2.693002700805664
Validation loss: 2.3968472198773454

Epoch: 5| Step: 9
Training loss: 2.9759395122528076
Validation loss: 2.3968354194395003

Epoch: 5| Step: 10
Training loss: 1.995720624923706
Validation loss: 2.3943226465614895

Epoch: 36| Step: 0
Training loss: 3.1781513690948486
Validation loss: 2.3890022564959783

Epoch: 5| Step: 1
Training loss: 2.6370089054107666
Validation loss: 2.3873612803797566

Epoch: 5| Step: 2
Training loss: 2.475285053253174
Validation loss: 2.3909310653645504

Epoch: 5| Step: 3
Training loss: 2.3927512168884277
Validation loss: 2.3967327943412204

Epoch: 5| Step: 4
Training loss: 2.881451368331909
Validation loss: 2.39889116953778

Epoch: 5| Step: 5
Training loss: 2.4402496814727783
Validation loss: 2.4108864389440066

Epoch: 5| Step: 6
Training loss: 2.5246365070343018
Validation loss: 2.417184998912196

Epoch: 5| Step: 7
Training loss: 2.3223373889923096
Validation loss: 2.4145504813040457

Epoch: 5| Step: 8
Training loss: 2.789480686187744
Validation loss: 2.4009351627801054

Epoch: 5| Step: 9
Training loss: 2.690608501434326
Validation loss: 2.3898587867777836

Epoch: 5| Step: 10
Training loss: 2.8105227947235107
Validation loss: 2.3799268789188837

Epoch: 37| Step: 0
Training loss: 2.573946475982666
Validation loss: 2.376131196175852

Epoch: 5| Step: 1
Training loss: 2.2899889945983887
Validation loss: 2.378170226209907

Epoch: 5| Step: 2
Training loss: 2.1768808364868164
Validation loss: 2.38119585539705

Epoch: 5| Step: 3
Training loss: 2.9092392921447754
Validation loss: 2.3861199989113757

Epoch: 5| Step: 4
Training loss: 3.202657699584961
Validation loss: 2.393153529013357

Epoch: 5| Step: 5
Training loss: 2.6788697242736816
Validation loss: 2.390263916343771

Epoch: 5| Step: 6
Training loss: 3.327873945236206
Validation loss: 2.383651328343217

Epoch: 5| Step: 7
Training loss: 2.4135613441467285
Validation loss: 2.3704257652323735

Epoch: 5| Step: 8
Training loss: 2.9447240829467773
Validation loss: 2.364697899869693

Epoch: 5| Step: 9
Training loss: 2.370055913925171
Validation loss: 2.3785538058127127

Epoch: 5| Step: 10
Training loss: 2.2093656063079834
Validation loss: 2.422109155244725

Epoch: 38| Step: 0
Training loss: 2.663245439529419
Validation loss: 2.4802661121532483

Epoch: 5| Step: 1
Training loss: 3.4267234802246094
Validation loss: 2.5428684244873705

Epoch: 5| Step: 2
Training loss: 2.7434048652648926
Validation loss: 2.5604394507664505

Epoch: 5| Step: 3
Training loss: 3.248246431350708
Validation loss: 2.4936426916430072

Epoch: 5| Step: 4
Training loss: 2.3581416606903076
Validation loss: 2.4020566965944026

Epoch: 5| Step: 5
Training loss: 2.6089518070220947
Validation loss: 2.371294411279822

Epoch: 5| Step: 6
Training loss: 2.240443468093872
Validation loss: 2.3622358998944684

Epoch: 5| Step: 7
Training loss: 2.552466630935669
Validation loss: 2.361593366951071

Epoch: 5| Step: 8
Training loss: 2.358097791671753
Validation loss: 2.3666625715071157

Epoch: 5| Step: 9
Training loss: 2.3714263439178467
Validation loss: 2.3793629779610583

Epoch: 5| Step: 10
Training loss: 2.7898919582366943
Validation loss: 2.3774670093290267

Epoch: 39| Step: 0
Training loss: 2.4931020736694336
Validation loss: 2.372650565639619

Epoch: 5| Step: 1
Training loss: 3.291569948196411
Validation loss: 2.3676785294727614

Epoch: 5| Step: 2
Training loss: 2.7490291595458984
Validation loss: 2.36592540689694

Epoch: 5| Step: 3
Training loss: 2.5037319660186768
Validation loss: 2.3650564839763026

Epoch: 5| Step: 4
Training loss: 2.543510675430298
Validation loss: 2.3761484443500476

Epoch: 5| Step: 5
Training loss: 2.3940138816833496
Validation loss: 2.3814203559711413

Epoch: 5| Step: 6
Training loss: 2.7150299549102783
Validation loss: 2.3856226295553227

Epoch: 5| Step: 7
Training loss: 2.8728272914886475
Validation loss: 2.4172808431809947

Epoch: 5| Step: 8
Training loss: 2.4877877235412598
Validation loss: 2.4163647467090237

Epoch: 5| Step: 9
Training loss: 2.287149667739868
Validation loss: 2.413156742690712

Epoch: 5| Step: 10
Training loss: 2.5837390422821045
Validation loss: 2.4011292816490255

Epoch: 40| Step: 0
Training loss: 2.2601051330566406
Validation loss: 2.3808086482427453

Epoch: 5| Step: 1
Training loss: 2.607050895690918
Validation loss: 2.3634804525683

Epoch: 5| Step: 2
Training loss: 3.0190906524658203
Validation loss: 2.3545969942564606

Epoch: 5| Step: 3
Training loss: 2.1239864826202393
Validation loss: 2.346984230062013

Epoch: 5| Step: 4
Training loss: 2.6436927318573
Validation loss: 2.3471880958926294

Epoch: 5| Step: 5
Training loss: 2.75530743598938
Validation loss: 2.348467098769321

Epoch: 5| Step: 6
Training loss: 2.254098415374756
Validation loss: 2.3546218154250935

Epoch: 5| Step: 7
Training loss: 2.404553174972534
Validation loss: 2.3665085633595786

Epoch: 5| Step: 8
Training loss: 3.7540066242218018
Validation loss: 2.37582460013769

Epoch: 5| Step: 9
Training loss: 2.6642446517944336
Validation loss: 2.3763676099879767

Epoch: 5| Step: 10
Training loss: 2.205923557281494
Validation loss: 2.3646783469825663

Epoch: 41| Step: 0
Training loss: 3.373764753341675
Validation loss: 2.365098453337146

Epoch: 5| Step: 1
Training loss: 3.2523741722106934
Validation loss: 2.3587785690061507

Epoch: 5| Step: 2
Training loss: 2.253979206085205
Validation loss: 2.3592432416895384

Epoch: 5| Step: 3
Training loss: 2.171738624572754
Validation loss: 2.3716502676727953

Epoch: 5| Step: 4
Training loss: 2.1938347816467285
Validation loss: 2.3718888349430536

Epoch: 5| Step: 5
Training loss: 2.3769233226776123
Validation loss: 2.3906892166342786

Epoch: 5| Step: 6
Training loss: 2.1162543296813965
Validation loss: 2.39963000564165

Epoch: 5| Step: 7
Training loss: 2.7673065662384033
Validation loss: 2.3851066097136466

Epoch: 5| Step: 8
Training loss: 3.084688663482666
Validation loss: 2.3791956670822634

Epoch: 5| Step: 9
Training loss: 2.3661837577819824
Validation loss: 2.3682552460701234

Epoch: 5| Step: 10
Training loss: 2.7815303802490234
Validation loss: 2.360756961248254

Epoch: 42| Step: 0
Training loss: 2.8729474544525146
Validation loss: 2.360521334473805

Epoch: 5| Step: 1
Training loss: 3.2804152965545654
Validation loss: 2.35313013035764

Epoch: 5| Step: 2
Training loss: 2.0077085494995117
Validation loss: 2.3488456920910905

Epoch: 5| Step: 3
Training loss: 2.44321870803833
Validation loss: 2.3498251861141575

Epoch: 5| Step: 4
Training loss: 3.182835817337036
Validation loss: 2.347322092261366

Epoch: 5| Step: 5
Training loss: 2.6531684398651123
Validation loss: 2.3413530754786667

Epoch: 5| Step: 6
Training loss: 2.124016523361206
Validation loss: 2.339098071539274

Epoch: 5| Step: 7
Training loss: 2.632535219192505
Validation loss: 2.3436410709093978

Epoch: 5| Step: 8
Training loss: 2.858760118484497
Validation loss: 2.347803810591339

Epoch: 5| Step: 9
Training loss: 2.6965250968933105
Validation loss: 2.3572296762979157

Epoch: 5| Step: 10
Training loss: 1.8692188262939453
Validation loss: 2.366482957716911

Epoch: 43| Step: 0
Training loss: 2.801365375518799
Validation loss: 2.354315447550948

Epoch: 5| Step: 1
Training loss: 2.9339652061462402
Validation loss: 2.3451005694686726

Epoch: 5| Step: 2
Training loss: 2.8521721363067627
Validation loss: 2.329827659873552

Epoch: 5| Step: 3
Training loss: 2.2303261756896973
Validation loss: 2.3216601315365044

Epoch: 5| Step: 4
Training loss: 3.2080063819885254
Validation loss: 2.326271850575683

Epoch: 5| Step: 5
Training loss: 2.1880042552948
Validation loss: 2.3303399521817445

Epoch: 5| Step: 6
Training loss: 3.1842663288116455
Validation loss: 2.3280524630700388

Epoch: 5| Step: 7
Training loss: 1.861175298690796
Validation loss: 2.3328308623324157

Epoch: 5| Step: 8
Training loss: 2.3960258960723877
Validation loss: 2.335080503135599

Epoch: 5| Step: 9
Training loss: 2.2663354873657227
Validation loss: 2.3296892719884075

Epoch: 5| Step: 10
Training loss: 2.576881170272827
Validation loss: 2.3431693097596527

Epoch: 44| Step: 0
Training loss: 2.840456485748291
Validation loss: 2.3562569515679472

Epoch: 5| Step: 1
Training loss: 2.4196887016296387
Validation loss: 2.3434546891079155

Epoch: 5| Step: 2
Training loss: 3.023252487182617
Validation loss: 2.3122196223146174

Epoch: 5| Step: 3
Training loss: 3.1298978328704834
Validation loss: 2.308822542108515

Epoch: 5| Step: 4
Training loss: 2.2903130054473877
Validation loss: 2.3051906401111233

Epoch: 5| Step: 5
Training loss: 2.809413194656372
Validation loss: 2.3062272610202914

Epoch: 5| Step: 6
Training loss: 2.3268370628356934
Validation loss: 2.3148766615057506

Epoch: 5| Step: 7
Training loss: 1.9961124658584595
Validation loss: 2.3077997315314507

Epoch: 5| Step: 8
Training loss: 2.581791877746582
Validation loss: 2.327288261023901

Epoch: 5| Step: 9
Training loss: 2.3992035388946533
Validation loss: 2.3257558576522337

Epoch: 5| Step: 10
Training loss: 2.567049503326416
Validation loss: 2.3234816148716915

Epoch: 45| Step: 0
Training loss: 3.1352972984313965
Validation loss: 2.319679980636925

Epoch: 5| Step: 1
Training loss: 2.86044979095459
Validation loss: 2.3179749468321442

Epoch: 5| Step: 2
Training loss: 2.1938116550445557
Validation loss: 2.32018756610091

Epoch: 5| Step: 3
Training loss: 2.1580047607421875
Validation loss: 2.317743726955947

Epoch: 5| Step: 4
Training loss: 2.7865841388702393
Validation loss: 2.3134175680016957

Epoch: 5| Step: 5
Training loss: 2.6520915031433105
Validation loss: 2.3209660130162395

Epoch: 5| Step: 6
Training loss: 2.7195544242858887
Validation loss: 2.3332916536638812

Epoch: 5| Step: 7
Training loss: 2.9264461994171143
Validation loss: 2.3537512312653246

Epoch: 5| Step: 8
Training loss: 1.743703842163086
Validation loss: 2.3444234786495084

Epoch: 5| Step: 9
Training loss: 2.222410202026367
Validation loss: 2.3303309332939888

Epoch: 5| Step: 10
Training loss: 2.985623598098755
Validation loss: 2.3158120083552536

Epoch: 46| Step: 0
Training loss: 3.1350584030151367
Validation loss: 2.3042762202601277

Epoch: 5| Step: 1
Training loss: 3.1666226387023926
Validation loss: 2.2976928731446624

Epoch: 5| Step: 2
Training loss: 2.5269925594329834
Validation loss: 2.300236912183864

Epoch: 5| Step: 3
Training loss: 2.5732200145721436
Validation loss: 2.295536054077969

Epoch: 5| Step: 4
Training loss: 2.5804824829101562
Validation loss: 2.295691374809511

Epoch: 5| Step: 5
Training loss: 2.1602959632873535
Validation loss: 2.2963298290006575

Epoch: 5| Step: 6
Training loss: 2.3808701038360596
Validation loss: 2.2992709811015795

Epoch: 5| Step: 7
Training loss: 2.574584484100342
Validation loss: 2.323341700338548

Epoch: 5| Step: 8
Training loss: 1.9662948846817017
Validation loss: 2.3403435291782504

Epoch: 5| Step: 9
Training loss: 2.029674768447876
Validation loss: 2.367521885902651

Epoch: 5| Step: 10
Training loss: 3.3514840602874756
Validation loss: 2.3956496946273313

Epoch: 47| Step: 0
Training loss: 2.268280029296875
Validation loss: 2.392260797562138

Epoch: 5| Step: 1
Training loss: 2.649993658065796
Validation loss: 2.342881010424706

Epoch: 5| Step: 2
Training loss: 2.256923198699951
Validation loss: 2.3156050994832027

Epoch: 5| Step: 3
Training loss: 2.343022108078003
Validation loss: 2.306389429235971

Epoch: 5| Step: 4
Training loss: 2.844802141189575
Validation loss: 2.3017806673562653

Epoch: 5| Step: 5
Training loss: 2.951796293258667
Validation loss: 2.3037809710348807

Epoch: 5| Step: 6
Training loss: 2.2767107486724854
Validation loss: 2.3125890967666463

Epoch: 5| Step: 7
Training loss: 2.931432008743286
Validation loss: 2.329685631618705

Epoch: 5| Step: 8
Training loss: 2.3886120319366455
Validation loss: 2.328330521942467

Epoch: 5| Step: 9
Training loss: 2.958749294281006
Validation loss: 2.3316247335044284

Epoch: 5| Step: 10
Training loss: 2.4010212421417236
Validation loss: 2.3482141648569415

Epoch: 48| Step: 0
Training loss: 2.915325164794922
Validation loss: 2.3834385705250565

Epoch: 5| Step: 1
Training loss: 2.3806822299957275
Validation loss: 2.3918282139685845

Epoch: 5| Step: 2
Training loss: 1.9777908325195312
Validation loss: 2.3645554896323913

Epoch: 5| Step: 3
Training loss: 2.4668967723846436
Validation loss: 2.360817160657657

Epoch: 5| Step: 4
Training loss: 2.3854167461395264
Validation loss: 2.3562862924350205

Epoch: 5| Step: 5
Training loss: 2.426800489425659
Validation loss: 2.350529997579513

Epoch: 5| Step: 6
Training loss: 3.149900197982788
Validation loss: 2.306835295051657

Epoch: 5| Step: 7
Training loss: 2.044891357421875
Validation loss: 2.2738962609280824

Epoch: 5| Step: 8
Training loss: 2.9010748863220215
Validation loss: 2.269940395509043

Epoch: 5| Step: 9
Training loss: 2.0408501625061035
Validation loss: 2.2698626595158733

Epoch: 5| Step: 10
Training loss: 3.7062790393829346
Validation loss: 2.270689713057651

Epoch: 49| Step: 0
Training loss: 2.3458588123321533
Validation loss: 2.2797427279974825

Epoch: 5| Step: 1
Training loss: 2.6000938415527344
Validation loss: 2.28094760705066

Epoch: 5| Step: 2
Training loss: 2.4781851768493652
Validation loss: 2.2696002170603764

Epoch: 5| Step: 3
Training loss: 2.416161298751831
Validation loss: 2.2706944352837017

Epoch: 5| Step: 4
Training loss: 2.704375982284546
Validation loss: 2.265040969335905

Epoch: 5| Step: 5
Training loss: 2.454777240753174
Validation loss: 2.268784838338052

Epoch: 5| Step: 6
Training loss: 2.7325031757354736
Validation loss: 2.2781630075106056

Epoch: 5| Step: 7
Training loss: 2.6086220741271973
Validation loss: 2.2957148346849667

Epoch: 5| Step: 8
Training loss: 2.330811023712158
Validation loss: 2.300087441680252

Epoch: 5| Step: 9
Training loss: 3.063040018081665
Validation loss: 2.2972688392926286

Epoch: 5| Step: 10
Training loss: 2.6183483600616455
Validation loss: 2.2988009375910603

Epoch: 50| Step: 0
Training loss: 2.4437737464904785
Validation loss: 2.288822017690187

Epoch: 5| Step: 1
Training loss: 2.624345302581787
Validation loss: 2.282119899667719

Epoch: 5| Step: 2
Training loss: 2.542280673980713
Validation loss: 2.2756012767873783

Epoch: 5| Step: 3
Training loss: 2.624041795730591
Validation loss: 2.256414064797022

Epoch: 5| Step: 4
Training loss: 2.487762928009033
Validation loss: 2.2496302563657045

Epoch: 5| Step: 5
Training loss: 3.0086097717285156
Validation loss: 2.250273576346777

Epoch: 5| Step: 6
Training loss: 2.5329651832580566
Validation loss: 2.2493828304352297

Epoch: 5| Step: 7
Training loss: 2.3824071884155273
Validation loss: 2.247815660251084

Epoch: 5| Step: 8
Training loss: 2.9730048179626465
Validation loss: 2.246497082453902

Epoch: 5| Step: 9
Training loss: 2.211599588394165
Validation loss: 2.2465155329755557

Epoch: 5| Step: 10
Training loss: 2.318582773208618
Validation loss: 2.2589940024960424

Epoch: 51| Step: 0
Training loss: 2.559077739715576
Validation loss: 2.27407193440263

Epoch: 5| Step: 1
Training loss: 2.557685375213623
Validation loss: 2.278361262813691

Epoch: 5| Step: 2
Training loss: 3.0013716220855713
Validation loss: 2.2721598661074074

Epoch: 5| Step: 3
Training loss: 2.82820200920105
Validation loss: 2.269265785012194

Epoch: 5| Step: 4
Training loss: 2.195651054382324
Validation loss: 2.263762080541221

Epoch: 5| Step: 5
Training loss: 2.589905261993408
Validation loss: 2.2626532072662027

Epoch: 5| Step: 6
Training loss: 2.59934401512146
Validation loss: 2.2583038653096845

Epoch: 5| Step: 7
Training loss: 2.3261704444885254
Validation loss: 2.251840781140071

Epoch: 5| Step: 8
Training loss: 1.8475757837295532
Validation loss: 2.270070581025975

Epoch: 5| Step: 9
Training loss: 3.02656888961792
Validation loss: 2.279469246505409

Epoch: 5| Step: 10
Training loss: 2.3867640495300293
Validation loss: 2.292083619743265

Epoch: 52| Step: 0
Training loss: 2.81134295463562
Validation loss: 2.288333276266693

Epoch: 5| Step: 1
Training loss: 2.08613657951355
Validation loss: 2.2796996139710948

Epoch: 5| Step: 2
Training loss: 3.299603223800659
Validation loss: 2.2655531770439556

Epoch: 5| Step: 3
Training loss: 1.9891153573989868
Validation loss: 2.2503331822733723

Epoch: 5| Step: 4
Training loss: 2.765244245529175
Validation loss: 2.2420630557562715

Epoch: 5| Step: 5
Training loss: 2.3576884269714355
Validation loss: 2.230273772311467

Epoch: 5| Step: 6
Training loss: 2.57658314704895
Validation loss: 2.232554813866974

Epoch: 5| Step: 7
Training loss: 2.354917049407959
Validation loss: 2.2289326639585596

Epoch: 5| Step: 8
Training loss: 2.516266345977783
Validation loss: 2.246557358772524

Epoch: 5| Step: 9
Training loss: 2.3644790649414062
Validation loss: 2.25751502795886

Epoch: 5| Step: 10
Training loss: 2.8576552867889404
Validation loss: 2.261907508296351

Epoch: 53| Step: 0
Training loss: 2.5798823833465576
Validation loss: 2.2820056523046186

Epoch: 5| Step: 1
Training loss: 2.4651944637298584
Validation loss: 2.2937556543657855

Epoch: 5| Step: 2
Training loss: 2.3848845958709717
Validation loss: 2.310320577313823

Epoch: 5| Step: 3
Training loss: 2.223797559738159
Validation loss: 2.290221142512496

Epoch: 5| Step: 4
Training loss: 2.7373924255371094
Validation loss: 2.3004833754672798

Epoch: 5| Step: 5
Training loss: 2.571700096130371
Validation loss: 2.2972913352392053

Epoch: 5| Step: 6
Training loss: 2.613175868988037
Validation loss: 2.2965779740323304

Epoch: 5| Step: 7
Training loss: 2.6652026176452637
Validation loss: 2.2709918893793577

Epoch: 5| Step: 8
Training loss: 2.5056254863739014
Validation loss: 2.2515014025472824

Epoch: 5| Step: 9
Training loss: 2.9928531646728516
Validation loss: 2.231847095233138

Epoch: 5| Step: 10
Training loss: 1.9794647693634033
Validation loss: 2.2270897152603313

Epoch: 54| Step: 0
Training loss: 3.2680060863494873
Validation loss: 2.2358666645583285

Epoch: 5| Step: 1
Training loss: 2.5678439140319824
Validation loss: 2.2380123933156333

Epoch: 5| Step: 2
Training loss: 2.7554688453674316
Validation loss: 2.2449351895240044

Epoch: 5| Step: 3
Training loss: 2.979506492614746
Validation loss: 2.2450726544985207

Epoch: 5| Step: 4
Training loss: 2.610806941986084
Validation loss: 2.2421449038290207

Epoch: 5| Step: 5
Training loss: 2.4055614471435547
Validation loss: 2.2305023516378095

Epoch: 5| Step: 6
Training loss: 2.6917858123779297
Validation loss: 2.2207379764126194

Epoch: 5| Step: 7
Training loss: 2.039973735809326
Validation loss: 2.2212903320148425

Epoch: 5| Step: 8
Training loss: 2.8602023124694824
Validation loss: 2.2145486313809633

Epoch: 5| Step: 9
Training loss: 1.7617095708847046
Validation loss: 2.216424157542567

Epoch: 5| Step: 10
Training loss: 2.064115524291992
Validation loss: 2.2368749995385446

Epoch: 55| Step: 0
Training loss: 3.463409900665283
Validation loss: 2.3172155503303773

Epoch: 5| Step: 1
Training loss: 2.6515023708343506
Validation loss: 2.41099129697328

Epoch: 5| Step: 2
Training loss: 2.7024459838867188
Validation loss: 2.4065784010835873

Epoch: 5| Step: 3
Training loss: 2.5103583335876465
Validation loss: 2.392270311232536

Epoch: 5| Step: 4
Training loss: 2.1774649620056152
Validation loss: 2.327849416322606

Epoch: 5| Step: 5
Training loss: 2.6534836292266846
Validation loss: 2.239580831220073

Epoch: 5| Step: 6
Training loss: 2.630495309829712
Validation loss: 2.201007139298224

Epoch: 5| Step: 7
Training loss: 2.2714426517486572
Validation loss: 2.1969499229103007

Epoch: 5| Step: 8
Training loss: 2.790195941925049
Validation loss: 2.1944437155159573

Epoch: 5| Step: 9
Training loss: 2.2499217987060547
Validation loss: 2.1930784820228495

Epoch: 5| Step: 10
Training loss: 1.903754711151123
Validation loss: 2.197815079842844

Epoch: 56| Step: 0
Training loss: 2.7599828243255615
Validation loss: 2.194252855034285

Epoch: 5| Step: 1
Training loss: 2.5230040550231934
Validation loss: 2.189050277074178

Epoch: 5| Step: 2
Training loss: 2.1646406650543213
Validation loss: 2.1955813182297574

Epoch: 5| Step: 3
Training loss: 2.2388699054718018
Validation loss: 2.205923923882105

Epoch: 5| Step: 4
Training loss: 2.8764004707336426
Validation loss: 2.22581886476086

Epoch: 5| Step: 5
Training loss: 2.619440793991089
Validation loss: 2.228017550642772

Epoch: 5| Step: 6
Training loss: 2.351335287094116
Validation loss: 2.2508835818177912

Epoch: 5| Step: 7
Training loss: 3.1256325244903564
Validation loss: 2.2510107922297653

Epoch: 5| Step: 8
Training loss: 1.9887501001358032
Validation loss: 2.2547641928477953

Epoch: 5| Step: 9
Training loss: 2.784355640411377
Validation loss: 2.2584625469741

Epoch: 5| Step: 10
Training loss: 2.306974411010742
Validation loss: 2.2727137381030666

Epoch: 57| Step: 0
Training loss: 2.814378261566162
Validation loss: 2.2837662273837673

Epoch: 5| Step: 1
Training loss: 1.9524955749511719
Validation loss: 2.26176740020834

Epoch: 5| Step: 2
Training loss: 2.498095750808716
Validation loss: 2.2887353640730663

Epoch: 5| Step: 3
Training loss: 1.8409267663955688
Validation loss: 2.2675093553399526

Epoch: 5| Step: 4
Training loss: 2.457720994949341
Validation loss: 2.2417620548637966

Epoch: 5| Step: 5
Training loss: 3.2850570678710938
Validation loss: 2.229290108526907

Epoch: 5| Step: 6
Training loss: 2.4089207649230957
Validation loss: 2.2068687818383657

Epoch: 5| Step: 7
Training loss: 2.1506505012512207
Validation loss: 2.211460372453095

Epoch: 5| Step: 8
Training loss: 3.3633265495300293
Validation loss: 2.200920884327222

Epoch: 5| Step: 9
Training loss: 2.356693983078003
Validation loss: 2.2008804762235252

Epoch: 5| Step: 10
Training loss: 2.493302822113037
Validation loss: 2.188409854007024

Epoch: 58| Step: 0
Training loss: 2.2731595039367676
Validation loss: 2.181149241744831

Epoch: 5| Step: 1
Training loss: 2.812737226486206
Validation loss: 2.1793015233932005

Epoch: 5| Step: 2
Training loss: 2.9457688331604004
Validation loss: 2.181350487534718

Epoch: 5| Step: 3
Training loss: 2.9066054821014404
Validation loss: 2.1801113056880173

Epoch: 5| Step: 4
Training loss: 2.3963098526000977
Validation loss: 2.184284646023986

Epoch: 5| Step: 5
Training loss: 2.899754047393799
Validation loss: 2.184357270117729

Epoch: 5| Step: 6
Training loss: 1.7932932376861572
Validation loss: 2.187078913052877

Epoch: 5| Step: 7
Training loss: 2.4574828147888184
Validation loss: 2.196951502112932

Epoch: 5| Step: 8
Training loss: 2.1094322204589844
Validation loss: 2.1968333298160183

Epoch: 5| Step: 9
Training loss: 2.8748621940612793
Validation loss: 2.205964506313365

Epoch: 5| Step: 10
Training loss: 1.9876830577850342
Validation loss: 2.214422989917058

Epoch: 59| Step: 0
Training loss: 3.037039279937744
Validation loss: 2.2151199181874595

Epoch: 5| Step: 1
Training loss: 2.2195143699645996
Validation loss: 2.2086726414260043

Epoch: 5| Step: 2
Training loss: 1.968897819519043
Validation loss: 2.2165129902542278

Epoch: 5| Step: 3
Training loss: 1.977455735206604
Validation loss: 2.233333403064359

Epoch: 5| Step: 4
Training loss: 2.6836740970611572
Validation loss: 2.255924173580703

Epoch: 5| Step: 5
Training loss: 2.173861026763916
Validation loss: 2.263496914217549

Epoch: 5| Step: 6
Training loss: 2.6679015159606934
Validation loss: 2.216344628282773

Epoch: 5| Step: 7
Training loss: 3.1579365730285645
Validation loss: 2.180336549717893

Epoch: 5| Step: 8
Training loss: 2.5308103561401367
Validation loss: 2.1713722546895347

Epoch: 5| Step: 9
Training loss: 2.7300164699554443
Validation loss: 2.1638657610903502

Epoch: 5| Step: 10
Training loss: 2.2124783992767334
Validation loss: 2.1691851692814983

Epoch: 60| Step: 0
Training loss: 2.970534324645996
Validation loss: 2.165459099636283

Epoch: 5| Step: 1
Training loss: 2.2388458251953125
Validation loss: 2.1690538570445073

Epoch: 5| Step: 2
Training loss: 2.168073892593384
Validation loss: 2.1750064819089827

Epoch: 5| Step: 3
Training loss: 2.491217613220215
Validation loss: 2.176647227297547

Epoch: 5| Step: 4
Training loss: 2.176588535308838
Validation loss: 2.168713092803955

Epoch: 5| Step: 5
Training loss: 2.0942723751068115
Validation loss: 2.1671695734864924

Epoch: 5| Step: 6
Training loss: 2.6386191844940186
Validation loss: 2.1843466989455687

Epoch: 5| Step: 7
Training loss: 2.4796547889709473
Validation loss: 2.1996170731001

Epoch: 5| Step: 8
Training loss: 2.393406867980957
Validation loss: 2.2039281642565163

Epoch: 5| Step: 9
Training loss: 2.8716893196105957
Validation loss: 2.219515626148511

Epoch: 5| Step: 10
Training loss: 3.1518568992614746
Validation loss: 2.2319176325234036

Epoch: 61| Step: 0
Training loss: 2.5311524868011475
Validation loss: 2.2315792909232517

Epoch: 5| Step: 1
Training loss: 1.9969285726547241
Validation loss: 2.216214026174238

Epoch: 5| Step: 2
Training loss: 2.4118285179138184
Validation loss: 2.1971964631029355

Epoch: 5| Step: 3
Training loss: 2.043325424194336
Validation loss: 2.184103949095613

Epoch: 5| Step: 4
Training loss: 2.8259060382843018
Validation loss: 2.176293526926348

Epoch: 5| Step: 5
Training loss: 3.1009747982025146
Validation loss: 2.1743348926626225

Epoch: 5| Step: 6
Training loss: 2.7041923999786377
Validation loss: 2.166110151557512

Epoch: 5| Step: 7
Training loss: 2.533431053161621
Validation loss: 2.171815026190973

Epoch: 5| Step: 8
Training loss: 1.9947869777679443
Validation loss: 2.1655405157355854

Epoch: 5| Step: 9
Training loss: 2.443239212036133
Validation loss: 2.1722663935794624

Epoch: 5| Step: 10
Training loss: 2.775578737258911
Validation loss: 2.171389146517682

Epoch: 62| Step: 0
Training loss: 2.062464714050293
Validation loss: 2.1758208428659747

Epoch: 5| Step: 1
Training loss: 2.765191078186035
Validation loss: 2.174255806912658

Epoch: 5| Step: 2
Training loss: 2.6273694038391113
Validation loss: 2.1739633262798352

Epoch: 5| Step: 3
Training loss: 2.673557996749878
Validation loss: 2.1689263633502427

Epoch: 5| Step: 4
Training loss: 2.353649139404297
Validation loss: 2.160272181674998

Epoch: 5| Step: 5
Training loss: 3.2001426219940186
Validation loss: 2.1676375122480493

Epoch: 5| Step: 6
Training loss: 2.4158406257629395
Validation loss: 2.169891893222768

Epoch: 5| Step: 7
Training loss: 2.9419314861297607
Validation loss: 2.160599131737986

Epoch: 5| Step: 8
Training loss: 2.329411506652832
Validation loss: 2.1608058098823792

Epoch: 5| Step: 9
Training loss: 2.099961757659912
Validation loss: 2.17686814390203

Epoch: 5| Step: 10
Training loss: 1.646370768547058
Validation loss: 2.18820882099931

Epoch: 63| Step: 0
Training loss: 2.7820353507995605
Validation loss: 2.2325178833417993

Epoch: 5| Step: 1
Training loss: 2.6402812004089355
Validation loss: 2.2368669868797384

Epoch: 5| Step: 2
Training loss: 1.7148860692977905
Validation loss: 2.264112541752477

Epoch: 5| Step: 3
Training loss: 2.786275863647461
Validation loss: 2.263472141758088

Epoch: 5| Step: 4
Training loss: 2.458590030670166
Validation loss: 2.220988804294217

Epoch: 5| Step: 5
Training loss: 2.45641827583313
Validation loss: 2.1970131038337626

Epoch: 5| Step: 6
Training loss: 2.5606298446655273
Validation loss: 2.1802750505426878

Epoch: 5| Step: 7
Training loss: 2.053886890411377
Validation loss: 2.1602552834377495

Epoch: 5| Step: 8
Training loss: 2.7716193199157715
Validation loss: 2.153632725438764

Epoch: 5| Step: 9
Training loss: 2.6132664680480957
Validation loss: 2.15159031139907

Epoch: 5| Step: 10
Training loss: 2.4237184524536133
Validation loss: 2.1452690427021315

Epoch: 64| Step: 0
Training loss: 2.324706554412842
Validation loss: 2.1453736430855206

Epoch: 5| Step: 1
Training loss: 3.069484233856201
Validation loss: 2.142393999202277

Epoch: 5| Step: 2
Training loss: 2.2051303386688232
Validation loss: 2.14309960539623

Epoch: 5| Step: 3
Training loss: 2.0727882385253906
Validation loss: 2.147434421764907

Epoch: 5| Step: 4
Training loss: 2.4697823524475098
Validation loss: 2.1594995042329193

Epoch: 5| Step: 5
Training loss: 2.3010897636413574
Validation loss: 2.1557062736121555

Epoch: 5| Step: 6
Training loss: 2.123443603515625
Validation loss: 2.1845035527342107

Epoch: 5| Step: 7
Training loss: 2.5666122436523438
Validation loss: 2.3206838792370212

Epoch: 5| Step: 8
Training loss: 2.432803153991699
Validation loss: 2.42192776485156

Epoch: 5| Step: 9
Training loss: 2.9709155559539795
Validation loss: 2.4171595470879668

Epoch: 5| Step: 10
Training loss: 2.7914788722991943
Validation loss: 2.3748501577684955

Epoch: 65| Step: 0
Training loss: 2.554461717605591
Validation loss: 2.3187825654142644

Epoch: 5| Step: 1
Training loss: 2.6035420894622803
Validation loss: 2.2591848322140273

Epoch: 5| Step: 2
Training loss: 2.0299527645111084
Validation loss: 2.192743883338026

Epoch: 5| Step: 3
Training loss: 1.4941604137420654
Validation loss: 2.1511328553640716

Epoch: 5| Step: 4
Training loss: 2.4382693767547607
Validation loss: 2.1440678078641175

Epoch: 5| Step: 5
Training loss: 2.864677667617798
Validation loss: 2.144387524615052

Epoch: 5| Step: 6
Training loss: 3.3670825958251953
Validation loss: 2.1417853447698776

Epoch: 5| Step: 7
Training loss: 2.461308240890503
Validation loss: 2.136319283516176

Epoch: 5| Step: 8
Training loss: 2.6428446769714355
Validation loss: 2.137118351074957

Epoch: 5| Step: 9
Training loss: 2.26190185546875
Validation loss: 2.135148838002195

Epoch: 5| Step: 10
Training loss: 2.755964517593384
Validation loss: 2.145325255650346

Epoch: 66| Step: 0
Training loss: 2.343203067779541
Validation loss: 2.1487339209484797

Epoch: 5| Step: 1
Training loss: 2.3731658458709717
Validation loss: 2.1601283332352996

Epoch: 5| Step: 2
Training loss: 2.436997175216675
Validation loss: 2.178095976511637

Epoch: 5| Step: 3
Training loss: 2.7491397857666016
Validation loss: 2.187117850908669

Epoch: 5| Step: 4
Training loss: 2.538499355316162
Validation loss: 2.1857982784189205

Epoch: 5| Step: 5
Training loss: 2.756324052810669
Validation loss: 2.208638829569663

Epoch: 5| Step: 6
Training loss: 2.624809980392456
Validation loss: 2.190906363148843

Epoch: 5| Step: 7
Training loss: 2.486543655395508
Validation loss: 2.166446255099389

Epoch: 5| Step: 8
Training loss: 2.5211477279663086
Validation loss: 2.153010452947309

Epoch: 5| Step: 9
Training loss: 1.8977200984954834
Validation loss: 2.1334839815734536

Epoch: 5| Step: 10
Training loss: 2.382706642150879
Validation loss: 2.1325195322754564

Epoch: 67| Step: 0
Training loss: 2.1697182655334473
Validation loss: 2.12586147041731

Epoch: 5| Step: 1
Training loss: 2.469367504119873
Validation loss: 2.127327065314016

Epoch: 5| Step: 2
Training loss: 2.3305041790008545
Validation loss: 2.123104626132596

Epoch: 5| Step: 3
Training loss: 2.573946714401245
Validation loss: 2.1232867369087796

Epoch: 5| Step: 4
Training loss: 2.547081708908081
Validation loss: 2.1336422530553674

Epoch: 5| Step: 5
Training loss: 2.0937469005584717
Validation loss: 2.1367627484824068

Epoch: 5| Step: 6
Training loss: 1.829453706741333
Validation loss: 2.1464196661467194

Epoch: 5| Step: 7
Training loss: 3.3232924938201904
Validation loss: 2.1675273269735356

Epoch: 5| Step: 8
Training loss: 2.46838641166687
Validation loss: 2.1729701898431264

Epoch: 5| Step: 9
Training loss: 2.2866902351379395
Validation loss: 2.1734482203760455

Epoch: 5| Step: 10
Training loss: 3.0021770000457764
Validation loss: 2.1797317586919314

Epoch: 68| Step: 0
Training loss: 2.09957218170166
Validation loss: 2.1662071674100813

Epoch: 5| Step: 1
Training loss: 2.5866174697875977
Validation loss: 2.1490016624491703

Epoch: 5| Step: 2
Training loss: 2.6885223388671875
Validation loss: 2.140653471792898

Epoch: 5| Step: 3
Training loss: 2.526400089263916
Validation loss: 2.135384036648658

Epoch: 5| Step: 4
Training loss: 2.8263068199157715
Validation loss: 2.1286865985521706

Epoch: 5| Step: 5
Training loss: 2.0281145572662354
Validation loss: 2.1214646395816597

Epoch: 5| Step: 6
Training loss: 3.2675483226776123
Validation loss: 2.1220036757889615

Epoch: 5| Step: 7
Training loss: 2.4889721870422363
Validation loss: 2.1165127831120647

Epoch: 5| Step: 8
Training loss: 1.648000717163086
Validation loss: 2.1254443891586794

Epoch: 5| Step: 9
Training loss: 2.890293836593628
Validation loss: 2.13701957015581

Epoch: 5| Step: 10
Training loss: 1.8931635618209839
Validation loss: 2.1425898972377984

Epoch: 69| Step: 0
Training loss: 2.691319465637207
Validation loss: 2.1613938462349678

Epoch: 5| Step: 1
Training loss: 2.315812587738037
Validation loss: 2.1976031116259995

Epoch: 5| Step: 2
Training loss: 1.9564573764801025
Validation loss: 2.2302846882932927

Epoch: 5| Step: 3
Training loss: 2.7909557819366455
Validation loss: 2.2408101533048894

Epoch: 5| Step: 4
Training loss: 3.0382378101348877
Validation loss: 2.223381753890745

Epoch: 5| Step: 5
Training loss: 1.6737902164459229
Validation loss: 2.154061967326749

Epoch: 5| Step: 6
Training loss: 2.264660120010376
Validation loss: 2.128073387248542

Epoch: 5| Step: 7
Training loss: 3.2253317832946777
Validation loss: 2.118659286088841

Epoch: 5| Step: 8
Training loss: 2.253505229949951
Validation loss: 2.1153501990020915

Epoch: 5| Step: 9
Training loss: 2.43754243850708
Validation loss: 2.125873973292689

Epoch: 5| Step: 10
Training loss: 2.345524549484253
Validation loss: 2.1246141951571227

Epoch: 70| Step: 0
Training loss: 2.6065592765808105
Validation loss: 2.1144115771016767

Epoch: 5| Step: 1
Training loss: 2.7426857948303223
Validation loss: 2.1157429423383487

Epoch: 5| Step: 2
Training loss: 2.557852029800415
Validation loss: 2.1187125457230436

Epoch: 5| Step: 3
Training loss: 2.4752724170684814
Validation loss: 2.128212054570516

Epoch: 5| Step: 4
Training loss: 1.996803879737854
Validation loss: 2.1407923954789356

Epoch: 5| Step: 5
Training loss: 2.794328451156616
Validation loss: 2.1326571305592856

Epoch: 5| Step: 6
Training loss: 2.291285276412964
Validation loss: 2.1295847508215133

Epoch: 5| Step: 7
Training loss: 2.219303607940674
Validation loss: 2.1333509388790337

Epoch: 5| Step: 8
Training loss: 2.3202202320098877
Validation loss: 2.1480172834088727

Epoch: 5| Step: 9
Training loss: 2.2586276531219482
Validation loss: 2.153313100978892

Epoch: 5| Step: 10
Training loss: 2.428895950317383
Validation loss: 2.1690636245153283

Epoch: 71| Step: 0
Training loss: 2.2767956256866455
Validation loss: 2.2129569156195528

Epoch: 5| Step: 1
Training loss: 2.42580509185791
Validation loss: 2.2373914334081833

Epoch: 5| Step: 2
Training loss: 2.9005417823791504
Validation loss: 2.2186573551547144

Epoch: 5| Step: 3
Training loss: 1.7458951473236084
Validation loss: 2.1579178840883317

Epoch: 5| Step: 4
Training loss: 2.7805466651916504
Validation loss: 2.1364909500204106

Epoch: 5| Step: 5
Training loss: 2.138718366622925
Validation loss: 2.1243087963391374

Epoch: 5| Step: 6
Training loss: 2.8480277061462402
Validation loss: 2.118308639013639

Epoch: 5| Step: 7
Training loss: 2.4637911319732666
Validation loss: 2.1027265107759865

Epoch: 5| Step: 8
Training loss: 3.058748483657837
Validation loss: 2.105516291433765

Epoch: 5| Step: 9
Training loss: 2.356956720352173
Validation loss: 2.106684151516166

Epoch: 5| Step: 10
Training loss: 1.7933590412139893
Validation loss: 2.105991227652437

Epoch: 72| Step: 0
Training loss: 2.1853227615356445
Validation loss: 2.109089505287909

Epoch: 5| Step: 1
Training loss: 2.6705052852630615
Validation loss: 2.110337047166722

Epoch: 5| Step: 2
Training loss: 1.8357511758804321
Validation loss: 2.1365901424038793

Epoch: 5| Step: 3
Training loss: 2.299708127975464
Validation loss: 2.1257720775501703

Epoch: 5| Step: 4
Training loss: 2.9192371368408203
Validation loss: 2.1173177585806897

Epoch: 5| Step: 5
Training loss: 2.694537878036499
Validation loss: 2.1136492067767727

Epoch: 5| Step: 6
Training loss: 2.445103406906128
Validation loss: 2.116078233206144

Epoch: 5| Step: 7
Training loss: 2.7904977798461914
Validation loss: 2.1238813246450117

Epoch: 5| Step: 8
Training loss: 2.3270044326782227
Validation loss: 2.1365205216151413

Epoch: 5| Step: 9
Training loss: 2.6157386302948
Validation loss: 2.148787506165043

Epoch: 5| Step: 10
Training loss: 1.8367403745651245
Validation loss: 2.1406814718759186

Epoch: 73| Step: 0
Training loss: 2.384129285812378
Validation loss: 2.1271788074124243

Epoch: 5| Step: 1
Training loss: 2.09213924407959
Validation loss: 2.132147814637871

Epoch: 5| Step: 2
Training loss: 2.73632550239563
Validation loss: 2.1118600778682257

Epoch: 5| Step: 3
Training loss: 2.704212188720703
Validation loss: 2.121841630628032

Epoch: 5| Step: 4
Training loss: 1.792646050453186
Validation loss: 2.102461517498057

Epoch: 5| Step: 5
Training loss: 2.8324832916259766
Validation loss: 2.110408934213782

Epoch: 5| Step: 6
Training loss: 2.5548086166381836
Validation loss: 2.113856556595013

Epoch: 5| Step: 7
Training loss: 2.875462055206299
Validation loss: 2.114640798619998

Epoch: 5| Step: 8
Training loss: 1.832985281944275
Validation loss: 2.1103925089682303

Epoch: 5| Step: 9
Training loss: 2.825471878051758
Validation loss: 2.1067716677983603

Epoch: 5| Step: 10
Training loss: 1.832415223121643
Validation loss: 2.1061950986103346

Epoch: 74| Step: 0
Training loss: 1.9492199420928955
Validation loss: 2.098938662518737

Epoch: 5| Step: 1
Training loss: 2.3242290019989014
Validation loss: 2.100672765444684

Epoch: 5| Step: 2
Training loss: 3.1500344276428223
Validation loss: 2.119421571813604

Epoch: 5| Step: 3
Training loss: 2.0474820137023926
Validation loss: 2.122265838807629

Epoch: 5| Step: 4
Training loss: 2.360487699508667
Validation loss: 2.1175866344923615

Epoch: 5| Step: 5
Training loss: 2.7295594215393066
Validation loss: 2.129866146272229

Epoch: 5| Step: 6
Training loss: 2.333280324935913
Validation loss: 2.118362388303203

Epoch: 5| Step: 7
Training loss: 2.3205065727233887
Validation loss: 2.1104341296739477

Epoch: 5| Step: 8
Training loss: 2.142137050628662
Validation loss: 2.135790850526543

Epoch: 5| Step: 9
Training loss: 2.4388606548309326
Validation loss: 2.134586267573859

Epoch: 5| Step: 10
Training loss: 2.675947666168213
Validation loss: 2.1559761980528473

Epoch: 75| Step: 0
Training loss: 2.5127367973327637
Validation loss: 2.1589842086197226

Epoch: 5| Step: 1
Training loss: 2.861149311065674
Validation loss: 2.188998314642137

Epoch: 5| Step: 2
Training loss: 2.136204719543457
Validation loss: 2.1711712627000708

Epoch: 5| Step: 3
Training loss: 1.7493360042572021
Validation loss: 2.1230267978483632

Epoch: 5| Step: 4
Training loss: 2.7653326988220215
Validation loss: 2.0867690322219685

Epoch: 5| Step: 5
Training loss: 2.423063278198242
Validation loss: 2.0935612135036017

Epoch: 5| Step: 6
Training loss: 2.484933614730835
Validation loss: 2.0896129197971796

Epoch: 5| Step: 7
Training loss: 2.6785950660705566
Validation loss: 2.082952526307875

Epoch: 5| Step: 8
Training loss: 2.3503198623657227
Validation loss: 2.0860198774645404

Epoch: 5| Step: 9
Training loss: 2.2364184856414795
Validation loss: 2.095071764402492

Epoch: 5| Step: 10
Training loss: 2.269024610519409
Validation loss: 2.0874590078989663

Epoch: 76| Step: 0
Training loss: 2.548684597015381
Validation loss: 2.108287221641951

Epoch: 5| Step: 1
Training loss: 2.709932804107666
Validation loss: 2.1227558735878236

Epoch: 5| Step: 2
Training loss: 1.9098678827285767
Validation loss: 2.174490087775774

Epoch: 5| Step: 3
Training loss: 2.9852797985076904
Validation loss: 2.1905978879620953

Epoch: 5| Step: 4
Training loss: 2.2308261394500732
Validation loss: 2.1674058527074833

Epoch: 5| Step: 5
Training loss: 1.6921507120132446
Validation loss: 2.127704199924264

Epoch: 5| Step: 6
Training loss: 2.1570229530334473
Validation loss: 2.1117041598084154

Epoch: 5| Step: 7
Training loss: 2.865823984146118
Validation loss: 2.098926991544744

Epoch: 5| Step: 8
Training loss: 2.3635289669036865
Validation loss: 2.093090752119659

Epoch: 5| Step: 9
Training loss: 2.64668345451355
Validation loss: 2.0915131030544156

Epoch: 5| Step: 10
Training loss: 2.435586929321289
Validation loss: 2.086803590097735

Epoch: 77| Step: 0
Training loss: 2.438204526901245
Validation loss: 2.0916819059720604

Epoch: 5| Step: 1
Training loss: 2.1875059604644775
Validation loss: 2.093000663224087

Epoch: 5| Step: 2
Training loss: 2.07373309135437
Validation loss: 2.0822869628988285

Epoch: 5| Step: 3
Training loss: 2.0786662101745605
Validation loss: 2.099014582172517

Epoch: 5| Step: 4
Training loss: 2.1302599906921387
Validation loss: 2.1358276464605845

Epoch: 5| Step: 5
Training loss: 2.6653456687927246
Validation loss: 2.160275674635364

Epoch: 5| Step: 6
Training loss: 2.707639694213867
Validation loss: 2.145847571793423

Epoch: 5| Step: 7
Training loss: 2.6787822246551514
Validation loss: 2.161471369445965

Epoch: 5| Step: 8
Training loss: 2.7172493934631348
Validation loss: 2.1367209752400718

Epoch: 5| Step: 9
Training loss: 2.404623508453369
Validation loss: 2.1187546227567937

Epoch: 5| Step: 10
Training loss: 2.401278495788574
Validation loss: 2.0902609620043027

Epoch: 78| Step: 0
Training loss: 2.35727596282959
Validation loss: 2.0756459569418304

Epoch: 5| Step: 1
Training loss: 2.741300106048584
Validation loss: 2.0762338894669727

Epoch: 5| Step: 2
Training loss: 2.0834732055664062
Validation loss: 2.0834535270608883

Epoch: 5| Step: 3
Training loss: 2.5914392471313477
Validation loss: 2.0687942145973124

Epoch: 5| Step: 4
Training loss: 2.7741549015045166
Validation loss: 2.078004434544553

Epoch: 5| Step: 5
Training loss: 1.9231126308441162
Validation loss: 2.081507582818308

Epoch: 5| Step: 6
Training loss: 1.940913438796997
Validation loss: 2.11606901819988

Epoch: 5| Step: 7
Training loss: 2.341249465942383
Validation loss: 2.1286532327692997

Epoch: 5| Step: 8
Training loss: 2.66093111038208
Validation loss: 2.1133764379767963

Epoch: 5| Step: 9
Training loss: 2.8719780445098877
Validation loss: 2.1046853552582445

Epoch: 5| Step: 10
Training loss: 2.1222472190856934
Validation loss: 2.0952704401426416

Epoch: 79| Step: 0
Training loss: 2.538637161254883
Validation loss: 2.0981310516275387

Epoch: 5| Step: 1
Training loss: 2.632723331451416
Validation loss: 2.0914874922844673

Epoch: 5| Step: 2
Training loss: 2.6694235801696777
Validation loss: 2.123720730504682

Epoch: 5| Step: 3
Training loss: 2.491520643234253
Validation loss: 2.2004822325962845

Epoch: 5| Step: 4
Training loss: 2.3812413215637207
Validation loss: 2.148109451417

Epoch: 5| Step: 5
Training loss: 2.313261032104492
Validation loss: 2.095980449389386

Epoch: 5| Step: 6
Training loss: 2.129595994949341
Validation loss: 2.0665270461831042

Epoch: 5| Step: 7
Training loss: 2.3133585453033447
Validation loss: 2.0606645435415287

Epoch: 5| Step: 8
Training loss: 2.3742594718933105
Validation loss: 2.0626952468707995

Epoch: 5| Step: 9
Training loss: 2.631683349609375
Validation loss: 2.058820629632601

Epoch: 5| Step: 10
Training loss: 1.879360556602478
Validation loss: 2.055857539176941

Epoch: 80| Step: 0
Training loss: 2.3799242973327637
Validation loss: 2.0601021192407094

Epoch: 5| Step: 1
Training loss: 2.422801971435547
Validation loss: 2.0782798246670793

Epoch: 5| Step: 2
Training loss: 2.6820719242095947
Validation loss: 2.1115224310146865

Epoch: 5| Step: 3
Training loss: 2.8768699169158936
Validation loss: 2.1510241339283604

Epoch: 5| Step: 4
Training loss: 2.2716336250305176
Validation loss: 2.147855007520286

Epoch: 5| Step: 5
Training loss: 2.6369755268096924
Validation loss: 2.1316647580874863

Epoch: 5| Step: 6
Training loss: 2.2318875789642334
Validation loss: 2.0936257967384915

Epoch: 5| Step: 7
Training loss: 2.259610652923584
Validation loss: 2.095814833077051

Epoch: 5| Step: 8
Training loss: 2.2056965827941895
Validation loss: 2.094735207096223

Epoch: 5| Step: 9
Training loss: 1.948656678199768
Validation loss: 2.122270363633351

Epoch: 5| Step: 10
Training loss: 2.39155650138855
Validation loss: 2.1142898785170687

Epoch: 81| Step: 0
Training loss: 2.1896276473999023
Validation loss: 2.0768207580812517

Epoch: 5| Step: 1
Training loss: 3.1495251655578613
Validation loss: 2.062206337528844

Epoch: 5| Step: 2
Training loss: 2.642146587371826
Validation loss: 2.0648437456418107

Epoch: 5| Step: 3
Training loss: 2.2260894775390625
Validation loss: 2.058066120711706

Epoch: 5| Step: 4
Training loss: 2.467698335647583
Validation loss: 2.063991056975498

Epoch: 5| Step: 5
Training loss: 1.686436414718628
Validation loss: 2.0526528819914787

Epoch: 5| Step: 6
Training loss: 2.4549636840820312
Validation loss: 2.0536446430349864

Epoch: 5| Step: 7
Training loss: 2.7488224506378174
Validation loss: 2.0599135198900775

Epoch: 5| Step: 8
Training loss: 2.016462802886963
Validation loss: 2.0887251130996214

Epoch: 5| Step: 9
Training loss: 1.9317128658294678
Validation loss: 2.143962073069747

Epoch: 5| Step: 10
Training loss: 3.00110125541687
Validation loss: 2.192811086613645

Epoch: 82| Step: 0
Training loss: 2.1193549633026123
Validation loss: 2.154530020170314

Epoch: 5| Step: 1
Training loss: 2.874464988708496
Validation loss: 2.076076538332047

Epoch: 5| Step: 2
Training loss: 2.1957242488861084
Validation loss: 2.0463319209314164

Epoch: 5| Step: 3
Training loss: 2.322036027908325
Validation loss: 2.033766919566739

Epoch: 5| Step: 4
Training loss: 2.9341914653778076
Validation loss: 2.0488843225663707

Epoch: 5| Step: 5
Training loss: 2.3587048053741455
Validation loss: 2.053378569182529

Epoch: 5| Step: 6
Training loss: 2.479856014251709
Validation loss: 2.084185943808607

Epoch: 5| Step: 7
Training loss: 2.5699222087860107
Validation loss: 2.069581954709945

Epoch: 5| Step: 8
Training loss: 2.128234386444092
Validation loss: 2.0765949679959204

Epoch: 5| Step: 9
Training loss: 2.4652199745178223
Validation loss: 2.0666273947684997

Epoch: 5| Step: 10
Training loss: 2.1451873779296875
Validation loss: 2.0575671836894047

Epoch: 83| Step: 0
Training loss: 1.8328113555908203
Validation loss: 2.0809888224447928

Epoch: 5| Step: 1
Training loss: 2.740809679031372
Validation loss: 2.1532924226535264

Epoch: 5| Step: 2
Training loss: 1.9503920078277588
Validation loss: 2.21245236550608

Epoch: 5| Step: 3
Training loss: 2.499622344970703
Validation loss: 2.2522795251620713

Epoch: 5| Step: 4
Training loss: 2.713284969329834
Validation loss: 2.2063857919426373

Epoch: 5| Step: 5
Training loss: 2.334461212158203
Validation loss: 2.1632274068811888

Epoch: 5| Step: 6
Training loss: 1.9843069314956665
Validation loss: 2.110620839621431

Epoch: 5| Step: 7
Training loss: 2.622870445251465
Validation loss: 2.0508007285415486

Epoch: 5| Step: 8
Training loss: 2.527350664138794
Validation loss: 2.0244243785899174

Epoch: 5| Step: 9
Training loss: 2.4856715202331543
Validation loss: 2.0190453862631195

Epoch: 5| Step: 10
Training loss: 2.5321261882781982
Validation loss: 2.018401397171841

Epoch: 84| Step: 0
Training loss: 2.2383294105529785
Validation loss: 2.022183358028371

Epoch: 5| Step: 1
Training loss: 2.163759708404541
Validation loss: 2.0312462429846487

Epoch: 5| Step: 2
Training loss: 2.1915676593780518
Validation loss: 2.0607961185516848

Epoch: 5| Step: 3
Training loss: 2.524914264678955
Validation loss: 2.133863477296727

Epoch: 5| Step: 4
Training loss: 1.7793937921524048
Validation loss: 2.126755469588823

Epoch: 5| Step: 5
Training loss: 2.9340763092041016
Validation loss: 2.1224290017158753

Epoch: 5| Step: 6
Training loss: 2.490717649459839
Validation loss: 2.095135232453705

Epoch: 5| Step: 7
Training loss: 2.490180015563965
Validation loss: 2.0580780736861692

Epoch: 5| Step: 8
Training loss: 2.773418664932251
Validation loss: 2.0390681387275778

Epoch: 5| Step: 9
Training loss: 2.0603370666503906
Validation loss: 2.0293243738912765

Epoch: 5| Step: 10
Training loss: 2.371649742126465
Validation loss: 2.0225889836588213

Epoch: 85| Step: 0
Training loss: 2.4390571117401123
Validation loss: 2.010292519805252

Epoch: 5| Step: 1
Training loss: 2.595780611038208
Validation loss: 2.0091486233536915

Epoch: 5| Step: 2
Training loss: 2.4012341499328613
Validation loss: 2.0160452935003463

Epoch: 5| Step: 3
Training loss: 2.427611827850342
Validation loss: 2.019296133390037

Epoch: 5| Step: 4
Training loss: 2.563667058944702
Validation loss: 2.0238115159414147

Epoch: 5| Step: 5
Training loss: 1.4478254318237305
Validation loss: 2.019978297654019

Epoch: 5| Step: 6
Training loss: 2.092071533203125
Validation loss: 2.0156065494783464

Epoch: 5| Step: 7
Training loss: 2.8410446643829346
Validation loss: 2.011652062016149

Epoch: 5| Step: 8
Training loss: 2.5681440830230713
Validation loss: 2.011244197045603

Epoch: 5| Step: 9
Training loss: 2.208930253982544
Validation loss: 2.025585674470471

Epoch: 5| Step: 10
Training loss: 2.4813849925994873
Validation loss: 2.0772610787422425

Epoch: 86| Step: 0
Training loss: 2.44739031791687
Validation loss: 2.126043196647398

Epoch: 5| Step: 1
Training loss: 2.0308988094329834
Validation loss: 2.141092631124681

Epoch: 5| Step: 2
Training loss: 2.0061559677124023
Validation loss: 2.103852597616052

Epoch: 5| Step: 3
Training loss: 2.804280996322632
Validation loss: 2.0951108163402927

Epoch: 5| Step: 4
Training loss: 2.897310256958008
Validation loss: 2.0519691872340378

Epoch: 5| Step: 5
Training loss: 2.2652201652526855
Validation loss: 2.020631964488696

Epoch: 5| Step: 6
Training loss: 2.2818989753723145
Validation loss: 2.016426904227144

Epoch: 5| Step: 7
Training loss: 2.575850009918213
Validation loss: 2.010732953266431

Epoch: 5| Step: 8
Training loss: 2.4092040061950684
Validation loss: 2.009956268854039

Epoch: 5| Step: 9
Training loss: 1.5983234643936157
Validation loss: 2.0113437303932766

Epoch: 5| Step: 10
Training loss: 2.5355348587036133
Validation loss: 2.011696628344956

Epoch: 87| Step: 0
Training loss: 2.4981796741485596
Validation loss: 2.0155901114145913

Epoch: 5| Step: 1
Training loss: 2.4607651233673096
Validation loss: 2.0160567414376045

Epoch: 5| Step: 2
Training loss: 2.1890416145324707
Validation loss: 2.0465866032467095

Epoch: 5| Step: 3
Training loss: 2.3032174110412598
Validation loss: 2.071596558376025

Epoch: 5| Step: 4
Training loss: 2.89727520942688
Validation loss: 2.057641375449396

Epoch: 5| Step: 5
Training loss: 1.4140108823776245
Validation loss: 2.073798474445138

Epoch: 5| Step: 6
Training loss: 2.7583158016204834
Validation loss: 2.0771285167304416

Epoch: 5| Step: 7
Training loss: 2.4438538551330566
Validation loss: 2.0820860824277325

Epoch: 5| Step: 8
Training loss: 2.2256617546081543
Validation loss: 2.086608535499983

Epoch: 5| Step: 9
Training loss: 2.061309576034546
Validation loss: 2.070498917692451

Epoch: 5| Step: 10
Training loss: 2.4929094314575195
Validation loss: 2.0471100614916895

Epoch: 88| Step: 0
Training loss: 1.955325722694397
Validation loss: 2.0522494803192797

Epoch: 5| Step: 1
Training loss: 2.93396258354187
Validation loss: 2.029985007419381

Epoch: 5| Step: 2
Training loss: 2.2056708335876465
Validation loss: 2.0157132738380024

Epoch: 5| Step: 3
Training loss: 2.8233447074890137
Validation loss: 2.018508275349935

Epoch: 5| Step: 4
Training loss: 1.947244644165039
Validation loss: 2.023671163025723

Epoch: 5| Step: 5
Training loss: 2.5639140605926514
Validation loss: 2.0355884669929423

Epoch: 5| Step: 6
Training loss: 2.680872678756714
Validation loss: 2.055612794814571

Epoch: 5| Step: 7
Training loss: 1.7840560674667358
Validation loss: 2.076775432914816

Epoch: 5| Step: 8
Training loss: 2.2659976482391357
Validation loss: 2.115133475231868

Epoch: 5| Step: 9
Training loss: 2.8811001777648926
Validation loss: 2.1250193785595637

Epoch: 5| Step: 10
Training loss: 2.016213893890381
Validation loss: 2.084322408963275

Epoch: 89| Step: 0
Training loss: 2.6161036491394043
Validation loss: 2.027946200422061

Epoch: 5| Step: 1
Training loss: 1.8093299865722656
Validation loss: 1.9951391425184024

Epoch: 5| Step: 2
Training loss: 1.9626868963241577
Validation loss: 2.0079778830210366

Epoch: 5| Step: 3
Training loss: 2.650034189224243
Validation loss: 2.026343919897592

Epoch: 5| Step: 4
Training loss: 2.3425180912017822
Validation loss: 2.02316144974001

Epoch: 5| Step: 5
Training loss: 2.4706380367279053
Validation loss: 2.013759623291672

Epoch: 5| Step: 6
Training loss: 2.1897051334381104
Validation loss: 2.0090429552139772

Epoch: 5| Step: 7
Training loss: 2.2475216388702393
Validation loss: 2.0057226380994244

Epoch: 5| Step: 8
Training loss: 1.7910728454589844
Validation loss: 2.048416737587221

Epoch: 5| Step: 9
Training loss: 3.126436948776245
Validation loss: 2.1451935050308064

Epoch: 5| Step: 10
Training loss: 3.0553102493286133
Validation loss: 2.1959453872455064

Epoch: 90| Step: 0
Training loss: 2.363368511199951
Validation loss: 2.2054966880429174

Epoch: 5| Step: 1
Training loss: 2.403907299041748
Validation loss: 2.1826530605234127

Epoch: 5| Step: 2
Training loss: 2.5975265502929688
Validation loss: 2.108676133617278

Epoch: 5| Step: 3
Training loss: 2.010347843170166
Validation loss: 2.0197230359559417

Epoch: 5| Step: 4
Training loss: 2.42195463180542
Validation loss: 1.9862108397227463

Epoch: 5| Step: 5
Training loss: 2.4232349395751953
Validation loss: 1.980099081993103

Epoch: 5| Step: 6
Training loss: 2.3084912300109863
Validation loss: 1.9950730082809285

Epoch: 5| Step: 7
Training loss: 2.4440340995788574
Validation loss: 1.999827500312559

Epoch: 5| Step: 8
Training loss: 3.038163423538208
Validation loss: 2.0078845793201077

Epoch: 5| Step: 9
Training loss: 2.0494320392608643
Validation loss: 2.022936515910651

Epoch: 5| Step: 10
Training loss: 1.908461570739746
Validation loss: 2.045381510129539

Epoch: 91| Step: 0
Training loss: 2.3031129837036133
Validation loss: 2.0919370638426913

Epoch: 5| Step: 1
Training loss: 2.439687728881836
Validation loss: 2.129537372178929

Epoch: 5| Step: 2
Training loss: 2.5587916374206543
Validation loss: 2.2065064496891473

Epoch: 5| Step: 3
Training loss: 2.9616191387176514
Validation loss: 2.259210478874945

Epoch: 5| Step: 4
Training loss: 2.078368663787842
Validation loss: 2.227631276653659

Epoch: 5| Step: 5
Training loss: 2.982290744781494
Validation loss: 2.1815982326384513

Epoch: 5| Step: 6
Training loss: 2.444465398788452
Validation loss: 2.08439040184021

Epoch: 5| Step: 7
Training loss: 2.0595929622650146
Validation loss: 2.02766514337191

Epoch: 5| Step: 8
Training loss: 1.959934949874878
Validation loss: 2.021036590299299

Epoch: 5| Step: 9
Training loss: 2.5186638832092285
Validation loss: 2.014443633376911

Epoch: 5| Step: 10
Training loss: 1.6780880689620972
Validation loss: 2.004698816166129

Epoch: 92| Step: 0
Training loss: 2.7323946952819824
Validation loss: 2.01146444453988

Epoch: 5| Step: 1
Training loss: 1.9533535242080688
Validation loss: 2.0045419546865646

Epoch: 5| Step: 2
Training loss: 2.2799839973449707
Validation loss: 2.004760572987218

Epoch: 5| Step: 3
Training loss: 2.086077928543091
Validation loss: 1.9952676398779756

Epoch: 5| Step: 4
Training loss: 2.2139816284179688
Validation loss: 1.9941993016068653

Epoch: 5| Step: 5
Training loss: 2.9035592079162598
Validation loss: 1.9993636620941984

Epoch: 5| Step: 6
Training loss: 2.2921626567840576
Validation loss: 2.006706192929258

Epoch: 5| Step: 7
Training loss: 2.627854347229004
Validation loss: 2.0243245286326252

Epoch: 5| Step: 8
Training loss: 2.3755838871002197
Validation loss: 2.026774480778684

Epoch: 5| Step: 9
Training loss: 2.3241214752197266
Validation loss: 2.020983945938849

Epoch: 5| Step: 10
Training loss: 1.746182918548584
Validation loss: 2.0156557136966335

Epoch: 93| Step: 0
Training loss: 2.0332961082458496
Validation loss: 2.0083242770164245

Epoch: 5| Step: 1
Training loss: 2.138607978820801
Validation loss: 2.001614814163536

Epoch: 5| Step: 2
Training loss: 1.9142118692398071
Validation loss: 2.0110571320338915

Epoch: 5| Step: 3
Training loss: 2.395066261291504
Validation loss: 2.028520325178741

Epoch: 5| Step: 4
Training loss: 2.9460256099700928
Validation loss: 2.031651944242498

Epoch: 5| Step: 5
Training loss: 2.03164005279541
Validation loss: 2.0056434549311155

Epoch: 5| Step: 6
Training loss: 2.4271671772003174
Validation loss: 1.9906348797582811

Epoch: 5| Step: 7
Training loss: 2.0617079734802246
Validation loss: 2.001851958613242

Epoch: 5| Step: 8
Training loss: 2.4566569328308105
Validation loss: 1.9804589440745692

Epoch: 5| Step: 9
Training loss: 2.586881399154663
Validation loss: 1.9791799809343071

Epoch: 5| Step: 10
Training loss: 2.5417959690093994
Validation loss: 1.9859959156282487

Epoch: 94| Step: 0
Training loss: 2.420541286468506
Validation loss: 1.986757086169335

Epoch: 5| Step: 1
Training loss: 2.004951000213623
Validation loss: 1.9702650423972838

Epoch: 5| Step: 2
Training loss: 2.5125529766082764
Validation loss: 1.983006537601512

Epoch: 5| Step: 3
Training loss: 2.7039260864257812
Validation loss: 1.9801332924955635

Epoch: 5| Step: 4
Training loss: 1.7595195770263672
Validation loss: 1.9842560470745128

Epoch: 5| Step: 5
Training loss: 2.8305294513702393
Validation loss: 2.024612444703297

Epoch: 5| Step: 6
Training loss: 2.3148999214172363
Validation loss: 2.0526657412129063

Epoch: 5| Step: 7
Training loss: 2.146425247192383
Validation loss: 2.061066278847315

Epoch: 5| Step: 8
Training loss: 2.57346773147583
Validation loss: 2.0425563922492405

Epoch: 5| Step: 9
Training loss: 2.4365711212158203
Validation loss: 1.9992692829460226

Epoch: 5| Step: 10
Training loss: 1.8306615352630615
Validation loss: 1.9805319847599152

Epoch: 95| Step: 0
Training loss: 2.1032683849334717
Validation loss: 1.980227090979135

Epoch: 5| Step: 1
Training loss: 2.504234790802002
Validation loss: 1.9846596999834942

Epoch: 5| Step: 2
Training loss: 2.3882381916046143
Validation loss: 1.983541351492687

Epoch: 5| Step: 3
Training loss: 1.9557125568389893
Validation loss: 1.9819714561585458

Epoch: 5| Step: 4
Training loss: 2.286266803741455
Validation loss: 1.9737355016892957

Epoch: 5| Step: 5
Training loss: 2.233549118041992
Validation loss: 1.9879510300133818

Epoch: 5| Step: 6
Training loss: 2.200702428817749
Validation loss: 1.9878482844239922

Epoch: 5| Step: 7
Training loss: 2.169607639312744
Validation loss: 1.9764183490507063

Epoch: 5| Step: 8
Training loss: 2.4552104473114014
Validation loss: 1.9723531815313524

Epoch: 5| Step: 9
Training loss: 2.846442699432373
Validation loss: 1.9769327525169618

Epoch: 5| Step: 10
Training loss: 2.0865373611450195
Validation loss: 1.965868265398087

Epoch: 96| Step: 0
Training loss: 2.257427215576172
Validation loss: 1.968984293681319

Epoch: 5| Step: 1
Training loss: 1.944981575012207
Validation loss: 1.9848770069819626

Epoch: 5| Step: 2
Training loss: 1.9365835189819336
Validation loss: 1.9916147801183886

Epoch: 5| Step: 3
Training loss: 2.1380608081817627
Validation loss: 2.0208572828641502

Epoch: 5| Step: 4
Training loss: 2.749645709991455
Validation loss: 2.031446510745633

Epoch: 5| Step: 5
Training loss: 3.106510639190674
Validation loss: 2.022757910913037

Epoch: 5| Step: 6
Training loss: 2.127204418182373
Validation loss: 2.0216244471970426

Epoch: 5| Step: 7
Training loss: 2.624781370162964
Validation loss: 2.006136195634001

Epoch: 5| Step: 8
Training loss: 2.1950883865356445
Validation loss: 1.9976785234225694

Epoch: 5| Step: 9
Training loss: 2.4287056922912598
Validation loss: 1.9734498249587191

Epoch: 5| Step: 10
Training loss: 1.834054708480835
Validation loss: 1.9832493720516082

Epoch: 97| Step: 0
Training loss: 3.2114601135253906
Validation loss: 1.9760860012423607

Epoch: 5| Step: 1
Training loss: 2.4053683280944824
Validation loss: 1.9832241458277549

Epoch: 5| Step: 2
Training loss: 2.263319969177246
Validation loss: 1.9740900224254978

Epoch: 5| Step: 3
Training loss: 2.3574891090393066
Validation loss: 1.960200261044246

Epoch: 5| Step: 4
Training loss: 2.4136040210723877
Validation loss: 1.9645589577254428

Epoch: 5| Step: 5
Training loss: 2.7396388053894043
Validation loss: 1.983086552671207

Epoch: 5| Step: 6
Training loss: 1.9431965351104736
Validation loss: 2.023220269910751

Epoch: 5| Step: 7
Training loss: 2.165924072265625
Validation loss: 2.002441498541063

Epoch: 5| Step: 8
Training loss: 1.7903826236724854
Validation loss: 1.9910708371029104

Epoch: 5| Step: 9
Training loss: 1.8696359395980835
Validation loss: 1.9854012535464378

Epoch: 5| Step: 10
Training loss: 2.0242443084716797
Validation loss: 1.9601221994687152

Epoch: 98| Step: 0
Training loss: 2.527432441711426
Validation loss: 1.9385319115013204

Epoch: 5| Step: 1
Training loss: 2.4222235679626465
Validation loss: 1.950376219646905

Epoch: 5| Step: 2
Training loss: 1.872955083847046
Validation loss: 1.964323382223806

Epoch: 5| Step: 3
Training loss: 2.37308669090271
Validation loss: 1.9726551783982145

Epoch: 5| Step: 4
Training loss: 2.9407131671905518
Validation loss: 1.9713306760275235

Epoch: 5| Step: 5
Training loss: 2.957206964492798
Validation loss: 1.9643624956889818

Epoch: 5| Step: 6
Training loss: 2.412760019302368
Validation loss: 1.972144701147592

Epoch: 5| Step: 7
Training loss: 1.6812934875488281
Validation loss: 2.0233353773752847

Epoch: 5| Step: 8
Training loss: 2.2223293781280518
Validation loss: 2.0341874271310787

Epoch: 5| Step: 9
Training loss: 2.1937267780303955
Validation loss: 2.0332706564216205

Epoch: 5| Step: 10
Training loss: 1.8377695083618164
Validation loss: 2.0259293740795505

Epoch: 99| Step: 0
Training loss: 2.381798028945923
Validation loss: 1.995001116106587

Epoch: 5| Step: 1
Training loss: 2.8718676567077637
Validation loss: 1.9637780856060725

Epoch: 5| Step: 2
Training loss: 2.333710193634033
Validation loss: 1.9724474055792696

Epoch: 5| Step: 3
Training loss: 2.0529356002807617
Validation loss: 1.9686417374559628

Epoch: 5| Step: 4
Training loss: 1.9481220245361328
Validation loss: 1.9751623561305385

Epoch: 5| Step: 5
Training loss: 2.510138988494873
Validation loss: 1.9714441940348635

Epoch: 5| Step: 6
Training loss: 2.772862672805786
Validation loss: 1.9859002559415755

Epoch: 5| Step: 7
Training loss: 2.1847262382507324
Validation loss: 1.9883570850536387

Epoch: 5| Step: 8
Training loss: 2.2198374271392822
Validation loss: 1.9798441727956135

Epoch: 5| Step: 9
Training loss: 1.3969732522964478
Validation loss: 1.9716970766744306

Epoch: 5| Step: 10
Training loss: 2.5537328720092773
Validation loss: 1.9893861586047756

Epoch: 100| Step: 0
Training loss: 2.6875851154327393
Validation loss: 2.042061315428826

Epoch: 5| Step: 1
Training loss: 1.9943431615829468
Validation loss: 2.080144407928631

Epoch: 5| Step: 2
Training loss: 2.8957347869873047
Validation loss: 2.0753060284481255

Epoch: 5| Step: 3
Training loss: 2.0713295936584473
Validation loss: 2.034195861508769

Epoch: 5| Step: 4
Training loss: 2.7345776557922363
Validation loss: 1.9947847089459818

Epoch: 5| Step: 5
Training loss: 2.1285290718078613
Validation loss: 1.975413719813029

Epoch: 5| Step: 6
Training loss: 2.2808079719543457
Validation loss: 1.9917964114937732

Epoch: 5| Step: 7
Training loss: 2.5121216773986816
Validation loss: 2.0127699618698447

Epoch: 5| Step: 8
Training loss: 2.2154555320739746
Validation loss: 2.0658441025723695

Epoch: 5| Step: 9
Training loss: 2.3192050457000732
Validation loss: 2.012025643420476

Epoch: 5| Step: 10
Training loss: 1.646763563156128
Validation loss: 1.98814554496478

Testing loss: 2.2537791993882923
