Epoch: 1| Step: 0
Training loss: 5.607662200927734
Validation loss: 5.189337802189653

Epoch: 5| Step: 1
Training loss: 5.451699256896973
Validation loss: 5.16364045809674

Epoch: 5| Step: 2
Training loss: 6.043891906738281
Validation loss: 5.139147061173634

Epoch: 5| Step: 3
Training loss: 3.8283164501190186
Validation loss: 5.113535045295634

Epoch: 5| Step: 4
Training loss: 4.627257347106934
Validation loss: 5.08465035756429

Epoch: 5| Step: 5
Training loss: 4.4564056396484375
Validation loss: 5.052981643266575

Epoch: 5| Step: 6
Training loss: 4.479596138000488
Validation loss: 5.017349386727938

Epoch: 5| Step: 7
Training loss: 4.50223445892334
Validation loss: 4.976958351750528

Epoch: 5| Step: 8
Training loss: 4.9110822677612305
Validation loss: 4.932671946863974

Epoch: 5| Step: 9
Training loss: 4.661592960357666
Validation loss: 4.882887145524384

Epoch: 5| Step: 10
Training loss: 4.565504550933838
Validation loss: 4.829600580276981

Epoch: 2| Step: 0
Training loss: 5.08483362197876
Validation loss: 4.773228101832892

Epoch: 5| Step: 1
Training loss: 4.822999477386475
Validation loss: 4.7129273876067135

Epoch: 5| Step: 2
Training loss: 3.874917507171631
Validation loss: 4.651791387988675

Epoch: 5| Step: 3
Training loss: 4.963320732116699
Validation loss: 4.587072598036899

Epoch: 5| Step: 4
Training loss: 3.9985861778259277
Validation loss: 4.522614868738318

Epoch: 5| Step: 5
Training loss: 3.3446929454803467
Validation loss: 4.45650456541328

Epoch: 5| Step: 6
Training loss: 4.554047107696533
Validation loss: 4.392895647274551

Epoch: 5| Step: 7
Training loss: 4.3797078132629395
Validation loss: 4.331344973656439

Epoch: 5| Step: 8
Training loss: 3.5755691528320312
Validation loss: 4.264233127717049

Epoch: 5| Step: 9
Training loss: 3.7320830821990967
Validation loss: 4.20139713697536

Epoch: 5| Step: 10
Training loss: 4.623341083526611
Validation loss: 4.145604328442645

Epoch: 3| Step: 0
Training loss: 4.799039363861084
Validation loss: 4.094371944345454

Epoch: 5| Step: 1
Training loss: 3.5634593963623047
Validation loss: 4.047907490884104

Epoch: 5| Step: 2
Training loss: 4.2808027267456055
Validation loss: 4.004840345792873

Epoch: 5| Step: 3
Training loss: 4.969900608062744
Validation loss: 3.9630784937130508

Epoch: 5| Step: 4
Training loss: 4.789300441741943
Validation loss: 3.9227636501353276

Epoch: 5| Step: 5
Training loss: 2.9916229248046875
Validation loss: 3.886872278746738

Epoch: 5| Step: 6
Training loss: 3.266831159591675
Validation loss: 3.8603417386290846

Epoch: 5| Step: 7
Training loss: 3.298234224319458
Validation loss: 3.8616140478400776

Epoch: 5| Step: 8
Training loss: 2.330200672149658
Validation loss: 3.8194778401364564

Epoch: 5| Step: 9
Training loss: 2.899467706680298
Validation loss: 3.80133625512482

Epoch: 5| Step: 10
Training loss: 4.53550386428833
Validation loss: 3.783776431955317

Epoch: 4| Step: 0
Training loss: 2.4483840465545654
Validation loss: 3.7661905827060824

Epoch: 5| Step: 1
Training loss: 3.8894569873809814
Validation loss: 3.7445861806151686

Epoch: 5| Step: 2
Training loss: 3.8200085163116455
Validation loss: 3.7187819916714906

Epoch: 5| Step: 3
Training loss: 3.896428346633911
Validation loss: 3.690936883290609

Epoch: 5| Step: 4
Training loss: 3.812129259109497
Validation loss: 3.667396504391906

Epoch: 5| Step: 5
Training loss: 3.6314101219177246
Validation loss: 3.650738690489082

Epoch: 5| Step: 6
Training loss: 4.752483367919922
Validation loss: 3.63623595622278

Epoch: 5| Step: 7
Training loss: 3.781261920928955
Validation loss: 3.620078399617185

Epoch: 5| Step: 8
Training loss: 3.851395845413208
Validation loss: 3.6025738664852676

Epoch: 5| Step: 9
Training loss: 3.168606758117676
Validation loss: 3.5867588468777236

Epoch: 5| Step: 10
Training loss: 2.0019888877868652
Validation loss: 3.5741038168630292

Epoch: 5| Step: 0
Training loss: 2.4690566062927246
Validation loss: 3.566405678308138

Epoch: 5| Step: 1
Training loss: 3.748967409133911
Validation loss: 3.5577045307364514

Epoch: 5| Step: 2
Training loss: 4.382747173309326
Validation loss: 3.5453530639730473

Epoch: 5| Step: 3
Training loss: 3.6765007972717285
Validation loss: 3.53362028573149

Epoch: 5| Step: 4
Training loss: 3.075580358505249
Validation loss: 3.522584246050927

Epoch: 5| Step: 5
Training loss: 3.063361406326294
Validation loss: 3.523010879434565

Epoch: 5| Step: 6
Training loss: 3.5638797283172607
Validation loss: 3.5008216288781937

Epoch: 5| Step: 7
Training loss: 4.006477355957031
Validation loss: 3.4940855272354616

Epoch: 5| Step: 8
Training loss: 3.2135844230651855
Validation loss: 3.4915300159044165

Epoch: 5| Step: 9
Training loss: 3.850489377975464
Validation loss: 3.4877940608609106

Epoch: 5| Step: 10
Training loss: 2.844719648361206
Validation loss: 3.485656028152794

Epoch: 6| Step: 0
Training loss: 3.829805850982666
Validation loss: 3.4787384720258814

Epoch: 5| Step: 1
Training loss: 3.6794357299804688
Validation loss: 3.468262421187534

Epoch: 5| Step: 2
Training loss: 2.9183413982391357
Validation loss: 3.4618060537563857

Epoch: 5| Step: 3
Training loss: 4.013027667999268
Validation loss: 3.448980228875273

Epoch: 5| Step: 4
Training loss: 2.670764446258545
Validation loss: 3.438294695269677

Epoch: 5| Step: 5
Training loss: 3.5738117694854736
Validation loss: 3.432186219000047

Epoch: 5| Step: 6
Training loss: 3.5988667011260986
Validation loss: 3.4225516934548654

Epoch: 5| Step: 7
Training loss: 3.2018368244171143
Validation loss: 3.414008532800982

Epoch: 5| Step: 8
Training loss: 3.285433530807495
Validation loss: 3.4051355392702165

Epoch: 5| Step: 9
Training loss: 2.4099955558776855
Validation loss: 3.3973915807662474

Epoch: 5| Step: 10
Training loss: 4.085753440856934
Validation loss: 3.390093613696355

Epoch: 7| Step: 0
Training loss: 4.477995872497559
Validation loss: 3.381184652287473

Epoch: 5| Step: 1
Training loss: 4.2750468254089355
Validation loss: 3.372577016071607

Epoch: 5| Step: 2
Training loss: 3.2362701892852783
Validation loss: 3.3603682159095682

Epoch: 5| Step: 3
Training loss: 3.4110641479492188
Validation loss: 3.3494628629376813

Epoch: 5| Step: 4
Training loss: 2.1969242095947266
Validation loss: 3.339832459726641

Epoch: 5| Step: 5
Training loss: 3.0593178272247314
Validation loss: 3.3333773894976546

Epoch: 5| Step: 6
Training loss: 3.008513927459717
Validation loss: 3.327861434669905

Epoch: 5| Step: 7
Training loss: 3.478020429611206
Validation loss: 3.323723308501705

Epoch: 5| Step: 8
Training loss: 2.7233262062072754
Validation loss: 3.3164088187679166

Epoch: 5| Step: 9
Training loss: 3.972858428955078
Validation loss: 3.310265084748627

Epoch: 5| Step: 10
Training loss: 2.378660202026367
Validation loss: 3.304107017414544

Epoch: 8| Step: 0
Training loss: 2.6668033599853516
Validation loss: 3.298737833576818

Epoch: 5| Step: 1
Training loss: 3.4439918994903564
Validation loss: 3.2948567687824206

Epoch: 5| Step: 2
Training loss: 4.523275375366211
Validation loss: 3.288945872296569

Epoch: 5| Step: 3
Training loss: 2.9026780128479004
Validation loss: 3.280948474843015

Epoch: 5| Step: 4
Training loss: 2.9540257453918457
Validation loss: 3.274866896290933

Epoch: 5| Step: 5
Training loss: 2.674039125442505
Validation loss: 3.2716252547438427

Epoch: 5| Step: 6
Training loss: 2.669504165649414
Validation loss: 3.2678213478416525

Epoch: 5| Step: 7
Training loss: 3.0211691856384277
Validation loss: 3.260284803246939

Epoch: 5| Step: 8
Training loss: 3.3424899578094482
Validation loss: 3.2539705076525287

Epoch: 5| Step: 9
Training loss: 3.981874465942383
Validation loss: 3.2492248371083248

Epoch: 5| Step: 10
Training loss: 3.621589183807373
Validation loss: 3.2443162138744066

Epoch: 9| Step: 0
Training loss: 3.153383731842041
Validation loss: 3.2416065585228706

Epoch: 5| Step: 1
Training loss: 3.5067977905273438
Validation loss: 3.2357528953142065

Epoch: 5| Step: 2
Training loss: 3.449077606201172
Validation loss: 3.2291914134897213

Epoch: 5| Step: 3
Training loss: 2.3225181102752686
Validation loss: 3.2225915821649695

Epoch: 5| Step: 4
Training loss: 2.443824291229248
Validation loss: 3.2182448576855403

Epoch: 5| Step: 5
Training loss: 3.7456538677215576
Validation loss: 3.2144213671325357

Epoch: 5| Step: 6
Training loss: 3.849086046218872
Validation loss: 3.2087003441267115

Epoch: 5| Step: 7
Training loss: 2.936699151992798
Validation loss: 3.2040322108935286

Epoch: 5| Step: 8
Training loss: 3.2732887268066406
Validation loss: 3.1975525271508003

Epoch: 5| Step: 9
Training loss: 3.3043980598449707
Validation loss: 3.194525246979088

Epoch: 5| Step: 10
Training loss: 3.382535696029663
Validation loss: 3.192045332283102

Epoch: 10| Step: 0
Training loss: 3.811420440673828
Validation loss: 3.1830613459310224

Epoch: 5| Step: 1
Training loss: 3.484333038330078
Validation loss: 3.18061997044471

Epoch: 5| Step: 2
Training loss: 3.702256679534912
Validation loss: 3.1748232021126697

Epoch: 5| Step: 3
Training loss: 2.454643726348877
Validation loss: 3.167084781072473

Epoch: 5| Step: 4
Training loss: 2.911064863204956
Validation loss: 3.164405809935703

Epoch: 5| Step: 5
Training loss: 3.4586691856384277
Validation loss: 3.157132092342582

Epoch: 5| Step: 6
Training loss: 3.013092517852783
Validation loss: 3.151314271393643

Epoch: 5| Step: 7
Training loss: 3.409360408782959
Validation loss: 3.1450878215092484

Epoch: 5| Step: 8
Training loss: 2.9824233055114746
Validation loss: 3.141706294910882

Epoch: 5| Step: 9
Training loss: 2.7156596183776855
Validation loss: 3.145572736699094

Epoch: 5| Step: 10
Training loss: 2.9010977745056152
Validation loss: 3.1387092118622153

Epoch: 11| Step: 0
Training loss: 3.692807674407959
Validation loss: 3.1596966969069613

Epoch: 5| Step: 1
Training loss: 3.104124069213867
Validation loss: 3.1235477488528014

Epoch: 5| Step: 2
Training loss: 3.6789779663085938
Validation loss: 3.1243973752503753

Epoch: 5| Step: 3
Training loss: 2.656175136566162
Validation loss: 3.1253919421985583

Epoch: 5| Step: 4
Training loss: 2.9411232471466064
Validation loss: 3.1263981839661956

Epoch: 5| Step: 5
Training loss: 2.754180669784546
Validation loss: 3.12000080590607

Epoch: 5| Step: 6
Training loss: 3.2900230884552
Validation loss: 3.1194188825545774

Epoch: 5| Step: 7
Training loss: 2.653534412384033
Validation loss: 3.1124607132327173

Epoch: 5| Step: 8
Training loss: 3.407323122024536
Validation loss: 3.1073235337452223

Epoch: 5| Step: 9
Training loss: 3.0889687538146973
Validation loss: 3.101396035122615

Epoch: 5| Step: 10
Training loss: 3.382427453994751
Validation loss: 3.0951561338158062

Epoch: 12| Step: 0
Training loss: 2.720935344696045
Validation loss: 3.091085531378305

Epoch: 5| Step: 1
Training loss: 3.800210475921631
Validation loss: 3.090331615940217

Epoch: 5| Step: 2
Training loss: 2.493833065032959
Validation loss: 3.0902960659355245

Epoch: 5| Step: 3
Training loss: 3.211850643157959
Validation loss: 3.0911611510861303

Epoch: 5| Step: 4
Training loss: 3.2392611503601074
Validation loss: 3.086301993298274

Epoch: 5| Step: 5
Training loss: 3.958996534347534
Validation loss: 3.078510517715126

Epoch: 5| Step: 6
Training loss: 2.39774489402771
Validation loss: 3.0716936280650478

Epoch: 5| Step: 7
Training loss: 2.825998306274414
Validation loss: 3.0667248284944923

Epoch: 5| Step: 8
Training loss: 4.262696266174316
Validation loss: 3.0642927820964525

Epoch: 5| Step: 9
Training loss: 2.6966075897216797
Validation loss: 3.062459635478194

Epoch: 5| Step: 10
Training loss: 2.613738775253296
Validation loss: 3.0578194613097818

Epoch: 13| Step: 0
Training loss: 3.309070587158203
Validation loss: 3.057055063145135

Epoch: 5| Step: 1
Training loss: 2.650470018386841
Validation loss: 3.0535737058167816

Epoch: 5| Step: 2
Training loss: 3.5047993659973145
Validation loss: 3.0505670603885444

Epoch: 5| Step: 3
Training loss: 2.8789923191070557
Validation loss: 3.0487360057010444

Epoch: 5| Step: 4
Training loss: 3.110714912414551
Validation loss: 3.0474748816541446

Epoch: 5| Step: 5
Training loss: 2.8838014602661133
Validation loss: 3.0457879420249694

Epoch: 5| Step: 6
Training loss: 3.103327751159668
Validation loss: 3.045195830765591

Epoch: 5| Step: 7
Training loss: 2.9985549449920654
Validation loss: 3.0376216160353793

Epoch: 5| Step: 8
Training loss: 2.9318108558654785
Validation loss: 3.038003021670926

Epoch: 5| Step: 9
Training loss: 3.107156276702881
Validation loss: 3.0355460771950344

Epoch: 5| Step: 10
Training loss: 3.6758933067321777
Validation loss: 3.033582628414195

Epoch: 14| Step: 0
Training loss: 3.5227108001708984
Validation loss: 3.0326650911761868

Epoch: 5| Step: 1
Training loss: 3.4891464710235596
Validation loss: 3.027716431566464

Epoch: 5| Step: 2
Training loss: 2.2177987098693848
Validation loss: 3.024789728144164

Epoch: 5| Step: 3
Training loss: 3.1122052669525146
Validation loss: 3.023856791116858

Epoch: 5| Step: 4
Training loss: 3.225895643234253
Validation loss: 3.019196364187425

Epoch: 5| Step: 5
Training loss: 2.9773879051208496
Validation loss: 3.017316351654709

Epoch: 5| Step: 6
Training loss: 3.2172036170959473
Validation loss: 3.014463934847104

Epoch: 5| Step: 7
Training loss: 2.6498329639434814
Validation loss: 3.0129717549970074

Epoch: 5| Step: 8
Training loss: 2.775909900665283
Validation loss: 3.0092665764593307

Epoch: 5| Step: 9
Training loss: 3.8760597705841064
Validation loss: 3.0082057727280485

Epoch: 5| Step: 10
Training loss: 2.7315938472747803
Validation loss: 3.0040953800242436

Epoch: 15| Step: 0
Training loss: 3.756563186645508
Validation loss: 3.001416198668941

Epoch: 5| Step: 1
Training loss: 2.551663875579834
Validation loss: 3.0009100206436647

Epoch: 5| Step: 2
Training loss: 3.593179225921631
Validation loss: 2.997669058461343

Epoch: 5| Step: 3
Training loss: 3.2159037590026855
Validation loss: 2.991736888885498

Epoch: 5| Step: 4
Training loss: 2.516436815261841
Validation loss: 2.9905655512245755

Epoch: 5| Step: 5
Training loss: 3.2071290016174316
Validation loss: 2.985459212333925

Epoch: 5| Step: 6
Training loss: 3.8078460693359375
Validation loss: 2.981445297118156

Epoch: 5| Step: 7
Training loss: 2.0633246898651123
Validation loss: 2.9782437611651678

Epoch: 5| Step: 8
Training loss: 3.0037198066711426
Validation loss: 2.97524292238297

Epoch: 5| Step: 9
Training loss: 2.5051262378692627
Validation loss: 2.972584896190192

Epoch: 5| Step: 10
Training loss: 3.5015335083007812
Validation loss: 2.981574376424154

Epoch: 16| Step: 0
Training loss: 3.2285149097442627
Validation loss: 2.96870453639697

Epoch: 5| Step: 1
Training loss: 2.880582332611084
Validation loss: 2.9740194812897713

Epoch: 5| Step: 2
Training loss: 2.9220468997955322
Validation loss: 2.981202769023116

Epoch: 5| Step: 3
Training loss: 3.7669360637664795
Validation loss: 2.974528287046699

Epoch: 5| Step: 4
Training loss: 3.583098888397217
Validation loss: 2.9634992281595864

Epoch: 5| Step: 5
Training loss: 1.9756520986557007
Validation loss: 2.9574463598189817

Epoch: 5| Step: 6
Training loss: 2.4469027519226074
Validation loss: 2.9564440122214695

Epoch: 5| Step: 7
Training loss: 3.594336986541748
Validation loss: 2.9547330615341023

Epoch: 5| Step: 8
Training loss: 2.9680142402648926
Validation loss: 2.9508704446977183

Epoch: 5| Step: 9
Training loss: 3.2953999042510986
Validation loss: 2.9388527126722437

Epoch: 5| Step: 10
Training loss: 2.7360477447509766
Validation loss: 2.930644104557653

Epoch: 17| Step: 0
Training loss: 4.225460052490234
Validation loss: 2.928020505494969

Epoch: 5| Step: 1
Training loss: 2.517796039581299
Validation loss: 2.920677282476938

Epoch: 5| Step: 2
Training loss: 2.9499082565307617
Validation loss: 2.9187263416987594

Epoch: 5| Step: 3
Training loss: 3.1246914863586426
Validation loss: 2.910916523266864

Epoch: 5| Step: 4
Training loss: 3.3209261894226074
Validation loss: 2.9067001060772966

Epoch: 5| Step: 5
Training loss: 3.629438877105713
Validation loss: 2.90190056831606

Epoch: 5| Step: 6
Training loss: 2.3334343433380127
Validation loss: 2.895671788082328

Epoch: 5| Step: 7
Training loss: 2.6862857341766357
Validation loss: 2.8922421598947174

Epoch: 5| Step: 8
Training loss: 2.3594775199890137
Validation loss: 2.8870432915226107

Epoch: 5| Step: 9
Training loss: 2.857757329940796
Validation loss: 2.8814208635719876

Epoch: 5| Step: 10
Training loss: 3.0275330543518066
Validation loss: 2.87640033998797

Epoch: 18| Step: 0
Training loss: 2.820972204208374
Validation loss: 2.87150909567392

Epoch: 5| Step: 1
Training loss: 2.9995057582855225
Validation loss: 2.8675934755673973

Epoch: 5| Step: 2
Training loss: 2.400179624557495
Validation loss: 2.86707498950343

Epoch: 5| Step: 3
Training loss: 2.8741230964660645
Validation loss: 2.8616563043286725

Epoch: 5| Step: 4
Training loss: 3.1993002891540527
Validation loss: 2.855594817028251

Epoch: 5| Step: 5
Training loss: 3.1341006755828857
Validation loss: 2.8527252289556686

Epoch: 5| Step: 6
Training loss: 2.3251283168792725
Validation loss: 2.8502397537231445

Epoch: 5| Step: 7
Training loss: 2.813234329223633
Validation loss: 2.8494546746694915

Epoch: 5| Step: 8
Training loss: 3.50663685798645
Validation loss: 2.849951295442479

Epoch: 5| Step: 9
Training loss: 3.2189228534698486
Validation loss: 2.851511122078024

Epoch: 5| Step: 10
Training loss: 3.4304909706115723
Validation loss: 2.8578875526305167

Epoch: 19| Step: 0
Training loss: 3.2875568866729736
Validation loss: 2.8555390296443814

Epoch: 5| Step: 1
Training loss: 2.4204492568969727
Validation loss: 2.845553116131854

Epoch: 5| Step: 2
Training loss: 2.697584867477417
Validation loss: 2.8519183461384108

Epoch: 5| Step: 3
Training loss: 3.052090644836426
Validation loss: 2.859931307454263

Epoch: 5| Step: 4
Training loss: 2.6466736793518066
Validation loss: 2.8521241910995974

Epoch: 5| Step: 5
Training loss: 3.234830379486084
Validation loss: 2.8479528670669882

Epoch: 5| Step: 6
Training loss: 3.3354530334472656
Validation loss: 2.8456890839402393

Epoch: 5| Step: 7
Training loss: 2.538205623626709
Validation loss: 2.840686741695609

Epoch: 5| Step: 8
Training loss: 3.2505717277526855
Validation loss: 2.8351949978900213

Epoch: 5| Step: 9
Training loss: 3.025651454925537
Validation loss: 2.8361016422189693

Epoch: 5| Step: 10
Training loss: 3.096095561981201
Validation loss: 2.8377347146311114

Epoch: 20| Step: 0
Training loss: 2.715484142303467
Validation loss: 2.836421843497984

Epoch: 5| Step: 1
Training loss: 2.8752360343933105
Validation loss: 2.839243342799525

Epoch: 5| Step: 2
Training loss: 3.038702964782715
Validation loss: 2.8415426438854587

Epoch: 5| Step: 3
Training loss: 2.2662951946258545
Validation loss: 2.8327873496599096

Epoch: 5| Step: 4
Training loss: 2.2080695629119873
Validation loss: 2.832231395988054

Epoch: 5| Step: 5
Training loss: 3.5887088775634766
Validation loss: 2.8251013063615367

Epoch: 5| Step: 6
Training loss: 4.078232288360596
Validation loss: 2.819704714641776

Epoch: 5| Step: 7
Training loss: 2.8144900798797607
Validation loss: 2.816077078542402

Epoch: 5| Step: 8
Training loss: 2.5608067512512207
Validation loss: 2.816386022875386

Epoch: 5| Step: 9
Training loss: 2.6072678565979004
Validation loss: 2.8136571350918023

Epoch: 5| Step: 10
Training loss: 3.800342321395874
Validation loss: 2.8131608732285036

Epoch: 21| Step: 0
Training loss: 3.4854583740234375
Validation loss: 2.8145378405048

Epoch: 5| Step: 1
Training loss: 2.8623502254486084
Validation loss: 2.811689753686228

Epoch: 5| Step: 2
Training loss: 3.2756409645080566
Validation loss: 2.8112692858583186

Epoch: 5| Step: 3
Training loss: 2.3022677898406982
Validation loss: 2.8100867989242717

Epoch: 5| Step: 4
Training loss: 3.073437213897705
Validation loss: 2.8099485264029553

Epoch: 5| Step: 5
Training loss: 2.31469464302063
Validation loss: 2.8102294142528246

Epoch: 5| Step: 6
Training loss: 3.1940460205078125
Validation loss: 2.804776035329347

Epoch: 5| Step: 7
Training loss: 2.5934088230133057
Validation loss: 2.8060033167562177

Epoch: 5| Step: 8
Training loss: 2.8895106315612793
Validation loss: 2.804735475970853

Epoch: 5| Step: 9
Training loss: 3.4710991382598877
Validation loss: 2.8043560161385486

Epoch: 5| Step: 10
Training loss: 2.8535966873168945
Validation loss: 2.8004502865575973

Epoch: 22| Step: 0
Training loss: 2.2182695865631104
Validation loss: 2.7999755285119496

Epoch: 5| Step: 1
Training loss: 3.3585503101348877
Validation loss: 2.800382152680428

Epoch: 5| Step: 2
Training loss: 2.6862874031066895
Validation loss: 2.7971619995691444

Epoch: 5| Step: 3
Training loss: 2.5580945014953613
Validation loss: 2.800555449660106

Epoch: 5| Step: 4
Training loss: 3.797523021697998
Validation loss: 2.798921113373131

Epoch: 5| Step: 5
Training loss: 3.3417649269104004
Validation loss: 2.798377134466684

Epoch: 5| Step: 6
Training loss: 3.4758095741271973
Validation loss: 2.799437353687902

Epoch: 5| Step: 7
Training loss: 2.5739810466766357
Validation loss: 2.798967966469385

Epoch: 5| Step: 8
Training loss: 2.29465913772583
Validation loss: 2.8017953390716226

Epoch: 5| Step: 9
Training loss: 3.3184685707092285
Validation loss: 2.7959690375994612

Epoch: 5| Step: 10
Training loss: 2.5301432609558105
Validation loss: 2.7929622332255044

Epoch: 23| Step: 0
Training loss: 2.592667818069458
Validation loss: 2.8140924463989916

Epoch: 5| Step: 1
Training loss: 2.811920166015625
Validation loss: 2.812017235704648

Epoch: 5| Step: 2
Training loss: 3.322211742401123
Validation loss: 2.8159359988345893

Epoch: 5| Step: 3
Training loss: 2.618074893951416
Validation loss: 2.8126167763945875

Epoch: 5| Step: 4
Training loss: 2.6199748516082764
Validation loss: 2.8149311414328952

Epoch: 5| Step: 5
Training loss: 2.616482734680176
Validation loss: 2.8163097622574016

Epoch: 5| Step: 6
Training loss: 3.427926540374756
Validation loss: 2.8123953573165403

Epoch: 5| Step: 7
Training loss: 3.169166088104248
Validation loss: 2.815778729736164

Epoch: 5| Step: 8
Training loss: 3.2855401039123535
Validation loss: 2.8241430405647523

Epoch: 5| Step: 9
Training loss: 2.5043232440948486
Validation loss: 2.817007657020323

Epoch: 5| Step: 10
Training loss: 3.488231658935547
Validation loss: 2.814109420263639

Epoch: 24| Step: 0
Training loss: 3.1145596504211426
Validation loss: 2.8055841256213445

Epoch: 5| Step: 1
Training loss: 2.411351203918457
Validation loss: 2.799681358439948

Epoch: 5| Step: 2
Training loss: 2.5549254417419434
Validation loss: 2.7976213168072444

Epoch: 5| Step: 3
Training loss: 2.52238392829895
Validation loss: 2.8003103015243367

Epoch: 5| Step: 4
Training loss: 2.8441503047943115
Validation loss: 2.7985275304445656

Epoch: 5| Step: 5
Training loss: 3.062220811843872
Validation loss: 2.797796041734757

Epoch: 5| Step: 6
Training loss: 3.7837090492248535
Validation loss: 2.7968276495574624

Epoch: 5| Step: 7
Training loss: 3.0630576610565186
Validation loss: 2.799003549801406

Epoch: 5| Step: 8
Training loss: 2.277583360671997
Validation loss: 2.8048715437612226

Epoch: 5| Step: 9
Training loss: 3.912583827972412
Validation loss: 2.815043592965731

Epoch: 5| Step: 10
Training loss: 2.6801741123199463
Validation loss: 2.8193648963846187

Epoch: 25| Step: 0
Training loss: 2.670994281768799
Validation loss: 2.8183193950242895

Epoch: 5| Step: 1
Training loss: 3.3595714569091797
Validation loss: 2.8291356512295303

Epoch: 5| Step: 2
Training loss: 3.7929630279541016
Validation loss: 2.827603424749067

Epoch: 5| Step: 3
Training loss: 2.3824429512023926
Validation loss: 2.8273036018494637

Epoch: 5| Step: 4
Training loss: 3.3191885948181152
Validation loss: 2.7955282631740777

Epoch: 5| Step: 5
Training loss: 2.8120579719543457
Validation loss: 2.7935303308630504

Epoch: 5| Step: 6
Training loss: 2.50630521774292
Validation loss: 2.800073157074631

Epoch: 5| Step: 7
Training loss: 2.884617805480957
Validation loss: 2.7790563029627644

Epoch: 5| Step: 8
Training loss: 3.00764536857605
Validation loss: 2.7756579819545952

Epoch: 5| Step: 9
Training loss: 2.4279348850250244
Validation loss: 2.7685137410317697

Epoch: 5| Step: 10
Training loss: 3.070512533187866
Validation loss: 2.7691277304003314

Epoch: 26| Step: 0
Training loss: 3.559091567993164
Validation loss: 2.7638095399384857

Epoch: 5| Step: 1
Training loss: 2.8412423133850098
Validation loss: 2.763681375852195

Epoch: 5| Step: 2
Training loss: 2.274569034576416
Validation loss: 2.7602726310812016

Epoch: 5| Step: 3
Training loss: 3.23095703125
Validation loss: 2.7538526904198433

Epoch: 5| Step: 4
Training loss: 2.877592086791992
Validation loss: 2.75686566804045

Epoch: 5| Step: 5
Training loss: 2.8217365741729736
Validation loss: 2.778172880090693

Epoch: 5| Step: 6
Training loss: 2.7109498977661133
Validation loss: 2.784531383104222

Epoch: 5| Step: 7
Training loss: 2.1696009635925293
Validation loss: 2.790085515668315

Epoch: 5| Step: 8
Training loss: 3.127593755722046
Validation loss: 2.79336949317686

Epoch: 5| Step: 9
Training loss: 3.5293750762939453
Validation loss: 2.794070513017716

Epoch: 5| Step: 10
Training loss: 2.966597557067871
Validation loss: 2.795269928952699

Epoch: 27| Step: 0
Training loss: 3.08398175239563
Validation loss: 2.789871382456954

Epoch: 5| Step: 1
Training loss: 2.3575966358184814
Validation loss: 2.7811258890295543

Epoch: 5| Step: 2
Training loss: 2.912454128265381
Validation loss: 2.775007491470665

Epoch: 5| Step: 3
Training loss: 3.463341474533081
Validation loss: 2.775663637345837

Epoch: 5| Step: 4
Training loss: 3.113163471221924
Validation loss: 2.775044748860021

Epoch: 5| Step: 5
Training loss: 3.0757670402526855
Validation loss: 2.772276004155477

Epoch: 5| Step: 6
Training loss: 3.341245174407959
Validation loss: 2.771980539444954

Epoch: 5| Step: 7
Training loss: 3.1232993602752686
Validation loss: 2.7722428383365756

Epoch: 5| Step: 8
Training loss: 2.8282008171081543
Validation loss: 2.7748749076679187

Epoch: 5| Step: 9
Training loss: 2.0321621894836426
Validation loss: 2.772849526456607

Epoch: 5| Step: 10
Training loss: 2.772881269454956
Validation loss: 2.7741359459456576

Epoch: 28| Step: 0
Training loss: 3.231576442718506
Validation loss: 2.7724666749277422

Epoch: 5| Step: 1
Training loss: 2.5422210693359375
Validation loss: 2.773849597541235

Epoch: 5| Step: 2
Training loss: 2.7874553203582764
Validation loss: 2.773111730493525

Epoch: 5| Step: 3
Training loss: 3.3843605518341064
Validation loss: 2.7702527661477365

Epoch: 5| Step: 4
Training loss: 2.7081990242004395
Validation loss: 2.769635882428897

Epoch: 5| Step: 5
Training loss: 3.349177598953247
Validation loss: 2.765293610993252

Epoch: 5| Step: 6
Training loss: 3.0444936752319336
Validation loss: 2.764202348647579

Epoch: 5| Step: 7
Training loss: 1.8398994207382202
Validation loss: 2.761327066729146

Epoch: 5| Step: 8
Training loss: 2.648437023162842
Validation loss: 2.762739637846588

Epoch: 5| Step: 9
Training loss: 3.530513286590576
Validation loss: 2.7592658330035467

Epoch: 5| Step: 10
Training loss: 3.007412910461426
Validation loss: 2.759207417888026

Epoch: 29| Step: 0
Training loss: 2.3213768005371094
Validation loss: 2.7587597011238016

Epoch: 5| Step: 1
Training loss: 2.0813887119293213
Validation loss: 2.7584060725345405

Epoch: 5| Step: 2
Training loss: 3.2866883277893066
Validation loss: 2.7583895267978793

Epoch: 5| Step: 3
Training loss: 2.851426124572754
Validation loss: 2.758277023992231

Epoch: 5| Step: 4
Training loss: 3.442736864089966
Validation loss: 2.7560444621629614

Epoch: 5| Step: 5
Training loss: 3.2974979877471924
Validation loss: 2.7577114438497894

Epoch: 5| Step: 6
Training loss: 2.7225284576416016
Validation loss: 2.757325477497552

Epoch: 5| Step: 7
Training loss: 3.25093150138855
Validation loss: 2.756850142632761

Epoch: 5| Step: 8
Training loss: 2.7220191955566406
Validation loss: 2.7736029060938026

Epoch: 5| Step: 9
Training loss: 2.687345504760742
Validation loss: 2.752306768971105

Epoch: 5| Step: 10
Training loss: 3.3618428707122803
Validation loss: 2.7506546435817594

Epoch: 30| Step: 0
Training loss: 2.663045883178711
Validation loss: 2.7458366937534784

Epoch: 5| Step: 1
Training loss: 2.674003839492798
Validation loss: 2.747017555339362

Epoch: 5| Step: 2
Training loss: 2.8597018718719482
Validation loss: 2.7457412237762124

Epoch: 5| Step: 3
Training loss: 3.2400550842285156
Validation loss: 2.745252752816805

Epoch: 5| Step: 4
Training loss: 2.185551166534424
Validation loss: 2.7414749104489564

Epoch: 5| Step: 5
Training loss: 2.907693862915039
Validation loss: 2.741657885172034

Epoch: 5| Step: 6
Training loss: 3.4803662300109863
Validation loss: 2.7440963534898657

Epoch: 5| Step: 7
Training loss: 2.521280288696289
Validation loss: 2.7422528459179785

Epoch: 5| Step: 8
Training loss: 3.25093412399292
Validation loss: 2.7351255852689027

Epoch: 5| Step: 9
Training loss: 3.38763427734375
Validation loss: 2.733057821950605

Epoch: 5| Step: 10
Training loss: 2.609689235687256
Validation loss: 2.7322184526792137

Epoch: 31| Step: 0
Training loss: 3.1644530296325684
Validation loss: 2.735054854423769

Epoch: 5| Step: 1
Training loss: 3.483691692352295
Validation loss: 2.729059342415102

Epoch: 5| Step: 2
Training loss: 2.7388691902160645
Validation loss: 2.7317933472253944

Epoch: 5| Step: 3
Training loss: 2.4604692459106445
Validation loss: 2.720416044676176

Epoch: 5| Step: 4
Training loss: 3.57452654838562
Validation loss: 2.7236917480345695

Epoch: 5| Step: 5
Training loss: 3.3473751544952393
Validation loss: 2.774975792054207

Epoch: 5| Step: 6
Training loss: 2.683497428894043
Validation loss: 2.8780017540019047

Epoch: 5| Step: 7
Training loss: 3.1282665729522705
Validation loss: 2.882695641568912

Epoch: 5| Step: 8
Training loss: 2.155522584915161
Validation loss: 2.7648585483592045

Epoch: 5| Step: 9
Training loss: 2.7015814781188965
Validation loss: 2.695912153490128

Epoch: 5| Step: 10
Training loss: 2.4913032054901123
Validation loss: 2.7583390922956568

Epoch: 32| Step: 0
Training loss: 3.2940001487731934
Validation loss: 2.817933374835599

Epoch: 5| Step: 1
Training loss: 3.214977264404297
Validation loss: 2.8349213241249003

Epoch: 5| Step: 2
Training loss: 3.134373426437378
Validation loss: 2.828143127502934

Epoch: 5| Step: 3
Training loss: 2.3692057132720947
Validation loss: 2.7612330759725263

Epoch: 5| Step: 4
Training loss: 3.018606185913086
Validation loss: 2.7128960650454284

Epoch: 5| Step: 5
Training loss: 3.0438640117645264
Validation loss: 2.6936897949505876

Epoch: 5| Step: 6
Training loss: 2.9318342208862305
Validation loss: 2.6914868611161427

Epoch: 5| Step: 7
Training loss: 2.8814313411712646
Validation loss: 2.6997423992362073

Epoch: 5| Step: 8
Training loss: 2.9462673664093018
Validation loss: 2.707387947267102

Epoch: 5| Step: 9
Training loss: 2.8594701290130615
Validation loss: 2.7407139219263548

Epoch: 5| Step: 10
Training loss: 1.9927144050598145
Validation loss: 2.7283854433285293

Epoch: 33| Step: 0
Training loss: 3.3916220664978027
Validation loss: 2.7226811224414456

Epoch: 5| Step: 1
Training loss: 2.6907663345336914
Validation loss: 2.70909785198909

Epoch: 5| Step: 2
Training loss: 3.108605146408081
Validation loss: 2.703830237029701

Epoch: 5| Step: 3
Training loss: 2.9143855571746826
Validation loss: 2.6869880076377624

Epoch: 5| Step: 4
Training loss: 2.9314448833465576
Validation loss: 2.68574079134131

Epoch: 5| Step: 5
Training loss: 2.88862681388855
Validation loss: 2.6806990561946744

Epoch: 5| Step: 6
Training loss: 2.948265552520752
Validation loss: 2.689532544023247

Epoch: 5| Step: 7
Training loss: 2.8510994911193848
Validation loss: 2.7095478939753708

Epoch: 5| Step: 8
Training loss: 1.8861442804336548
Validation loss: 2.7055819624213764

Epoch: 5| Step: 9
Training loss: 3.067692518234253
Validation loss: 2.6938990931357107

Epoch: 5| Step: 10
Training loss: 2.8295698165893555
Validation loss: 2.674740396520143

Epoch: 34| Step: 0
Training loss: 2.9454312324523926
Validation loss: 2.6705785925670336

Epoch: 5| Step: 1
Training loss: 2.4730467796325684
Validation loss: 2.671109481524396

Epoch: 5| Step: 2
Training loss: 3.7766036987304688
Validation loss: 2.6744260531599804

Epoch: 5| Step: 3
Training loss: 2.8485679626464844
Validation loss: 2.675905312261274

Epoch: 5| Step: 4
Training loss: 2.6935973167419434
Validation loss: 2.6782194670810493

Epoch: 5| Step: 5
Training loss: 3.173529624938965
Validation loss: 2.678011971135293

Epoch: 5| Step: 6
Training loss: 2.6444849967956543
Validation loss: 2.677410897388253

Epoch: 5| Step: 7
Training loss: 2.6903598308563232
Validation loss: 2.6762140284302416

Epoch: 5| Step: 8
Training loss: 2.48842191696167
Validation loss: 2.676553805669149

Epoch: 5| Step: 9
Training loss: 2.879423141479492
Validation loss: 2.688391134303103

Epoch: 5| Step: 10
Training loss: 2.7358558177948
Validation loss: 2.680532596444571

Epoch: 35| Step: 0
Training loss: 2.925342082977295
Validation loss: 2.6701800105392293

Epoch: 5| Step: 1
Training loss: 3.293001651763916
Validation loss: 2.6655721561883086

Epoch: 5| Step: 2
Training loss: 2.5071475505828857
Validation loss: 2.663722635597311

Epoch: 5| Step: 3
Training loss: 3.4464125633239746
Validation loss: 2.6632400738295687

Epoch: 5| Step: 4
Training loss: 2.2524683475494385
Validation loss: 2.6584922523908716

Epoch: 5| Step: 5
Training loss: 3.088867664337158
Validation loss: 2.658916768207345

Epoch: 5| Step: 6
Training loss: 3.1488025188446045
Validation loss: 2.659698245345905

Epoch: 5| Step: 7
Training loss: 2.8010201454162598
Validation loss: 2.663659470055693

Epoch: 5| Step: 8
Training loss: 2.4608638286590576
Validation loss: 2.6703859349732757

Epoch: 5| Step: 9
Training loss: 2.7053070068359375
Validation loss: 2.6734591632760982

Epoch: 5| Step: 10
Training loss: 2.540242910385132
Validation loss: 2.6645111166020876

Epoch: 36| Step: 0
Training loss: 2.867109775543213
Validation loss: 2.6571389526449223

Epoch: 5| Step: 1
Training loss: 2.6757214069366455
Validation loss: 2.6557972738819737

Epoch: 5| Step: 2
Training loss: 2.9040369987487793
Validation loss: 2.654208372997981

Epoch: 5| Step: 3
Training loss: 3.599628448486328
Validation loss: 2.6557513411327074

Epoch: 5| Step: 4
Training loss: 2.6502609252929688
Validation loss: 2.653231064478556

Epoch: 5| Step: 5
Training loss: 3.0550332069396973
Validation loss: 2.6540108393597346

Epoch: 5| Step: 6
Training loss: 2.389479875564575
Validation loss: 2.6504227858717724

Epoch: 5| Step: 7
Training loss: 2.9782307147979736
Validation loss: 2.6500759509301957

Epoch: 5| Step: 8
Training loss: 2.49243426322937
Validation loss: 2.650013449371502

Epoch: 5| Step: 9
Training loss: 2.7263617515563965
Validation loss: 2.650927351367089

Epoch: 5| Step: 10
Training loss: 2.7159957885742188
Validation loss: 2.651707882522255

Epoch: 37| Step: 0
Training loss: 2.508573055267334
Validation loss: 2.649658636380267

Epoch: 5| Step: 1
Training loss: 3.0585875511169434
Validation loss: 2.653755890425815

Epoch: 5| Step: 2
Training loss: 3.7956626415252686
Validation loss: 2.6529264937164965

Epoch: 5| Step: 3
Training loss: 2.800654411315918
Validation loss: 2.650097377838627

Epoch: 5| Step: 4
Training loss: 2.4560933113098145
Validation loss: 2.6522704529505905

Epoch: 5| Step: 5
Training loss: 2.9604084491729736
Validation loss: 2.665006611936836

Epoch: 5| Step: 6
Training loss: 2.655194044113159
Validation loss: 2.651484953459873

Epoch: 5| Step: 7
Training loss: 2.962852954864502
Validation loss: 2.646230146449099

Epoch: 5| Step: 8
Training loss: 2.8970088958740234
Validation loss: 2.6437458594640098

Epoch: 5| Step: 9
Training loss: 2.609467029571533
Validation loss: 2.6413584319494103

Epoch: 5| Step: 10
Training loss: 2.1592040061950684
Validation loss: 2.643009785682924

Epoch: 38| Step: 0
Training loss: 1.9961599111557007
Validation loss: 2.644701789784175

Epoch: 5| Step: 1
Training loss: 3.5124473571777344
Validation loss: 2.6439976076925955

Epoch: 5| Step: 2
Training loss: 1.992540955543518
Validation loss: 2.642031313270651

Epoch: 5| Step: 3
Training loss: 2.539828062057495
Validation loss: 2.6416203437312955

Epoch: 5| Step: 4
Training loss: 2.9138123989105225
Validation loss: 2.6377573577306603

Epoch: 5| Step: 5
Training loss: 2.2832815647125244
Validation loss: 2.6346654712512927

Epoch: 5| Step: 6
Training loss: 3.0072364807128906
Validation loss: 2.6361344040081067

Epoch: 5| Step: 7
Training loss: 3.2165329456329346
Validation loss: 2.6367961770744732

Epoch: 5| Step: 8
Training loss: 3.034475088119507
Validation loss: 2.635600256663497

Epoch: 5| Step: 9
Training loss: 3.076803207397461
Validation loss: 2.6341765055092434

Epoch: 5| Step: 10
Training loss: 3.3700201511383057
Validation loss: 2.6415467441722913

Epoch: 39| Step: 0
Training loss: 3.0010011196136475
Validation loss: 2.651028281898909

Epoch: 5| Step: 1
Training loss: 2.6079390048980713
Validation loss: 2.6677146265583653

Epoch: 5| Step: 2
Training loss: 2.543149948120117
Validation loss: 2.637865202401274

Epoch: 5| Step: 3
Training loss: 2.8847708702087402
Validation loss: 2.6346486794051303

Epoch: 5| Step: 4
Training loss: 1.9889558553695679
Validation loss: 2.6572249961155716

Epoch: 5| Step: 5
Training loss: 2.973752498626709
Validation loss: 2.687302566343738

Epoch: 5| Step: 6
Training loss: 2.637904644012451
Validation loss: 2.722667286472936

Epoch: 5| Step: 7
Training loss: 2.7353196144104004
Validation loss: 2.732395689974549

Epoch: 5| Step: 8
Training loss: 3.7083630561828613
Validation loss: 2.755498719471757

Epoch: 5| Step: 9
Training loss: 3.165191173553467
Validation loss: 2.6545079882426927

Epoch: 5| Step: 10
Training loss: 2.923604965209961
Validation loss: 2.6353157668985348

Epoch: 40| Step: 0
Training loss: 2.322035789489746
Validation loss: 2.668818986544045

Epoch: 5| Step: 1
Training loss: 2.0955443382263184
Validation loss: 2.716116892394199

Epoch: 5| Step: 2
Training loss: 2.7746126651763916
Validation loss: 2.7575085445116927

Epoch: 5| Step: 3
Training loss: 3.126389980316162
Validation loss: 2.7438819562235186

Epoch: 5| Step: 4
Training loss: 2.936224937438965
Validation loss: 2.7011359660856185

Epoch: 5| Step: 5
Training loss: 2.745526075363159
Validation loss: 2.6557542252284225

Epoch: 5| Step: 6
Training loss: 3.451988935470581
Validation loss: 2.6336069158328477

Epoch: 5| Step: 7
Training loss: 2.7739224433898926
Validation loss: 2.6432245674953667

Epoch: 5| Step: 8
Training loss: 3.1836206912994385
Validation loss: 2.651701952821465

Epoch: 5| Step: 9
Training loss: 2.3670144081115723
Validation loss: 2.6572201328892864

Epoch: 5| Step: 10
Training loss: 3.5818777084350586
Validation loss: 2.6740723117705314

Epoch: 41| Step: 0
Training loss: 2.6488025188446045
Validation loss: 2.6928361769645446

Epoch: 5| Step: 1
Training loss: 2.453470230102539
Validation loss: 2.6966812149170907

Epoch: 5| Step: 2
Training loss: 3.2034544944763184
Validation loss: 2.688798758291429

Epoch: 5| Step: 3
Training loss: 2.4569404125213623
Validation loss: 2.681038507851221

Epoch: 5| Step: 4
Training loss: 3.659055233001709
Validation loss: 2.6578070963582685

Epoch: 5| Step: 5
Training loss: 2.2326178550720215
Validation loss: 2.6481661770933416

Epoch: 5| Step: 6
Training loss: 2.898275375366211
Validation loss: 2.6363712305663736

Epoch: 5| Step: 7
Training loss: 2.773151397705078
Validation loss: 2.6245493350490445

Epoch: 5| Step: 8
Training loss: 3.056530475616455
Validation loss: 2.616704794668382

Epoch: 5| Step: 9
Training loss: 2.681013584136963
Validation loss: 2.611634805638303

Epoch: 5| Step: 10
Training loss: 2.9656033515930176
Validation loss: 2.6531124089353826

Epoch: 42| Step: 0
Training loss: 2.4953179359436035
Validation loss: 2.6427146645002466

Epoch: 5| Step: 1
Training loss: 3.0254063606262207
Validation loss: 2.619790441246443

Epoch: 5| Step: 2
Training loss: 2.549187183380127
Validation loss: 2.6151630109356296

Epoch: 5| Step: 3
Training loss: 2.097662925720215
Validation loss: 2.6194618901898785

Epoch: 5| Step: 4
Training loss: 2.9063713550567627
Validation loss: 2.6251168481765257

Epoch: 5| Step: 5
Training loss: 2.876579999923706
Validation loss: 2.628185513199017

Epoch: 5| Step: 6
Training loss: 2.6234796047210693
Validation loss: 2.632282478834993

Epoch: 5| Step: 7
Training loss: 3.686286449432373
Validation loss: 2.6250316455800045

Epoch: 5| Step: 8
Training loss: 2.994905948638916
Validation loss: 2.6175433769020984

Epoch: 5| Step: 9
Training loss: 2.9496729373931885
Validation loss: 2.61452914309758

Epoch: 5| Step: 10
Training loss: 2.585329294204712
Validation loss: 2.6224182703161754

Epoch: 43| Step: 0
Training loss: 2.894577980041504
Validation loss: 2.6433218192028742

Epoch: 5| Step: 1
Training loss: 2.603086471557617
Validation loss: 2.6324801521916545

Epoch: 5| Step: 2
Training loss: 3.0672595500946045
Validation loss: 2.6188866028221707

Epoch: 5| Step: 3
Training loss: 2.9751055240631104
Validation loss: 2.6125019288832143

Epoch: 5| Step: 4
Training loss: 1.761754035949707
Validation loss: 2.604061493309595

Epoch: 5| Step: 5
Training loss: 2.6229567527770996
Validation loss: 2.605264509877851

Epoch: 5| Step: 6
Training loss: 3.4281132221221924
Validation loss: 2.607568258880287

Epoch: 5| Step: 7
Training loss: 2.5307679176330566
Validation loss: 2.602785256601149

Epoch: 5| Step: 8
Training loss: 2.8009719848632812
Validation loss: 2.6065532571525982

Epoch: 5| Step: 9
Training loss: 3.3532016277313232
Validation loss: 2.6091224583246375

Epoch: 5| Step: 10
Training loss: 2.6599388122558594
Validation loss: 2.611913460557179

Epoch: 44| Step: 0
Training loss: 2.354077100753784
Validation loss: 2.605188497933008

Epoch: 5| Step: 1
Training loss: 2.688265800476074
Validation loss: 2.6015353228456233

Epoch: 5| Step: 2
Training loss: 3.052659749984741
Validation loss: 2.5940709062801894

Epoch: 5| Step: 3
Training loss: 3.1881093978881836
Validation loss: 2.5985892908547514

Epoch: 5| Step: 4
Training loss: 2.496178150177002
Validation loss: 2.604398645380492

Epoch: 5| Step: 5
Training loss: 3.1751694679260254
Validation loss: 2.600575647046489

Epoch: 5| Step: 6
Training loss: 3.1913094520568848
Validation loss: 2.604907830556234

Epoch: 5| Step: 7
Training loss: 2.8867735862731934
Validation loss: 2.607961562372023

Epoch: 5| Step: 8
Training loss: 2.525785446166992
Validation loss: 2.609276117817048

Epoch: 5| Step: 9
Training loss: 2.1671788692474365
Validation loss: 2.602653375235937

Epoch: 5| Step: 10
Training loss: 2.927927017211914
Validation loss: 2.591361809802312

Epoch: 45| Step: 0
Training loss: 2.12772798538208
Validation loss: 2.580156692894556

Epoch: 5| Step: 1
Training loss: 2.6549580097198486
Validation loss: 2.5815978101504746

Epoch: 5| Step: 2
Training loss: 2.790830612182617
Validation loss: 2.5824633131745043

Epoch: 5| Step: 3
Training loss: 2.593477964401245
Validation loss: 2.580184651959327

Epoch: 5| Step: 4
Training loss: 2.603583574295044
Validation loss: 2.5812255195392075

Epoch: 5| Step: 5
Training loss: 3.330911159515381
Validation loss: 2.5771682518784718

Epoch: 5| Step: 6
Training loss: 2.9525094032287598
Validation loss: 2.577146166114397

Epoch: 5| Step: 7
Training loss: 3.0090508460998535
Validation loss: 2.5791970452954693

Epoch: 5| Step: 8
Training loss: 2.4597156047821045
Validation loss: 2.578827458043252

Epoch: 5| Step: 9
Training loss: 2.7250847816467285
Validation loss: 2.579155928345137

Epoch: 5| Step: 10
Training loss: 3.2100744247436523
Validation loss: 2.578001417139525

Epoch: 46| Step: 0
Training loss: 2.7923927307128906
Validation loss: 2.5789575653691448

Epoch: 5| Step: 1
Training loss: 2.790903329849243
Validation loss: 2.5773979489521315

Epoch: 5| Step: 2
Training loss: 2.3444933891296387
Validation loss: 2.5859011270666636

Epoch: 5| Step: 3
Training loss: 2.0933005809783936
Validation loss: 2.5953040712623188

Epoch: 5| Step: 4
Training loss: 3.1911685466766357
Validation loss: 2.6070515596738426

Epoch: 5| Step: 5
Training loss: 3.671046495437622
Validation loss: 2.605001131693522

Epoch: 5| Step: 6
Training loss: 2.989175319671631
Validation loss: 2.5963329627949703

Epoch: 5| Step: 7
Training loss: 2.1846394538879395
Validation loss: 2.5923063883217434

Epoch: 5| Step: 8
Training loss: 2.912339925765991
Validation loss: 2.580856728297408

Epoch: 5| Step: 9
Training loss: 3.179657459259033
Validation loss: 2.565760133086994

Epoch: 5| Step: 10
Training loss: 2.160804510116577
Validation loss: 2.562866316046766

Epoch: 47| Step: 0
Training loss: 3.2663700580596924
Validation loss: 2.5655960959772908

Epoch: 5| Step: 1
Training loss: 2.492949962615967
Validation loss: 2.5813192116316928

Epoch: 5| Step: 2
Training loss: 2.917475461959839
Validation loss: 2.6203723197342246

Epoch: 5| Step: 3
Training loss: 3.0584774017333984
Validation loss: 2.6140879379805697

Epoch: 5| Step: 4
Training loss: 2.611745834350586
Validation loss: 2.56844804363866

Epoch: 5| Step: 5
Training loss: 2.1572928428649902
Validation loss: 2.563920282548474

Epoch: 5| Step: 6
Training loss: 3.2694334983825684
Validation loss: 2.5795748592704855

Epoch: 5| Step: 7
Training loss: 2.599421977996826
Validation loss: 2.6269001730026735

Epoch: 5| Step: 8
Training loss: 2.6846847534179688
Validation loss: 2.6297107460678264

Epoch: 5| Step: 9
Training loss: 2.743807315826416
Validation loss: 2.642899864463396

Epoch: 5| Step: 10
Training loss: 2.628213405609131
Validation loss: 2.6480527385588615

Epoch: 48| Step: 0
Training loss: 2.857229232788086
Validation loss: 2.631951919165991

Epoch: 5| Step: 1
Training loss: 2.9046552181243896
Validation loss: 2.6022223964814217

Epoch: 5| Step: 2
Training loss: 2.9709665775299072
Validation loss: 2.570441153741652

Epoch: 5| Step: 3
Training loss: 2.3635547161102295
Validation loss: 2.551726464302309

Epoch: 5| Step: 4
Training loss: 2.595977306365967
Validation loss: 2.5521665567992837

Epoch: 5| Step: 5
Training loss: 2.7237401008605957
Validation loss: 2.5616120805022535

Epoch: 5| Step: 6
Training loss: 3.0983619689941406
Validation loss: 2.566989550026514

Epoch: 5| Step: 7
Training loss: 2.580132246017456
Validation loss: 2.5922795495679303

Epoch: 5| Step: 8
Training loss: 2.7603096961975098
Validation loss: 2.60435668371057

Epoch: 5| Step: 9
Training loss: 2.9880757331848145
Validation loss: 2.582186614313433

Epoch: 5| Step: 10
Training loss: 2.5874552726745605
Validation loss: 2.5749775363552954

Epoch: 49| Step: 0
Training loss: 3.13421368598938
Validation loss: 2.562817337692425

Epoch: 5| Step: 1
Training loss: 3.558454990386963
Validation loss: 2.5549990310463855

Epoch: 5| Step: 2
Training loss: 2.595717430114746
Validation loss: 2.5658479916152133

Epoch: 5| Step: 3
Training loss: 2.5440945625305176
Validation loss: 2.601426165591004

Epoch: 5| Step: 4
Training loss: 2.7635788917541504
Validation loss: 2.589314446654371

Epoch: 5| Step: 5
Training loss: 2.5947072505950928
Validation loss: 2.5836106115771877

Epoch: 5| Step: 6
Training loss: 2.3369216918945312
Validation loss: 2.566215422845656

Epoch: 5| Step: 7
Training loss: 2.0438625812530518
Validation loss: 2.5540542499993437

Epoch: 5| Step: 8
Training loss: 2.896217107772827
Validation loss: 2.54922124390961

Epoch: 5| Step: 9
Training loss: 2.209268569946289
Validation loss: 2.549193033608057

Epoch: 5| Step: 10
Training loss: 3.7600326538085938
Validation loss: 2.547375311133682

Epoch: 50| Step: 0
Training loss: 2.298837900161743
Validation loss: 2.550063702367967

Epoch: 5| Step: 1
Training loss: 3.3045382499694824
Validation loss: 2.5486077134327223

Epoch: 5| Step: 2
Training loss: 2.3747541904449463
Validation loss: 2.5462114246942664

Epoch: 5| Step: 3
Training loss: 2.503629446029663
Validation loss: 2.542089782735353

Epoch: 5| Step: 4
Training loss: 2.842771291732788
Validation loss: 2.5459718473495974

Epoch: 5| Step: 5
Training loss: 2.8948395252227783
Validation loss: 2.5415023424292125

Epoch: 5| Step: 6
Training loss: 2.7529072761535645
Validation loss: 2.540816145558511

Epoch: 5| Step: 7
Training loss: 2.610140562057495
Validation loss: 2.54186499503351

Epoch: 5| Step: 8
Training loss: 2.804115056991577
Validation loss: 2.550194930004817

Epoch: 5| Step: 9
Training loss: 2.9116199016571045
Validation loss: 2.5534398786483274

Epoch: 5| Step: 10
Training loss: 2.7483627796173096
Validation loss: 2.5508220041951826

Epoch: 51| Step: 0
Training loss: 3.1200547218322754
Validation loss: 2.557458249471521

Epoch: 5| Step: 1
Training loss: 2.4199352264404297
Validation loss: 2.566223475240892

Epoch: 5| Step: 2
Training loss: 3.1847753524780273
Validation loss: 2.576832115009267

Epoch: 5| Step: 3
Training loss: 2.466609239578247
Validation loss: 2.577712869131437

Epoch: 5| Step: 4
Training loss: 2.753002405166626
Validation loss: 2.546184052703201

Epoch: 5| Step: 5
Training loss: 2.2226309776306152
Validation loss: 2.5347585831919024

Epoch: 5| Step: 6
Training loss: 2.8650448322296143
Validation loss: 2.532971061686034

Epoch: 5| Step: 7
Training loss: 2.4799749851226807
Validation loss: 2.536662663182905

Epoch: 5| Step: 8
Training loss: 2.6632752418518066
Validation loss: 2.5324888114006288

Epoch: 5| Step: 9
Training loss: 2.8021295070648193
Validation loss: 2.53253964454897

Epoch: 5| Step: 10
Training loss: 3.1349539756774902
Validation loss: 2.5344631389905046

Epoch: 52| Step: 0
Training loss: 3.039639472961426
Validation loss: 2.5356364775729436

Epoch: 5| Step: 1
Training loss: 3.350808620452881
Validation loss: 2.530919841540757

Epoch: 5| Step: 2
Training loss: 2.8214917182922363
Validation loss: 2.531413201362856

Epoch: 5| Step: 3
Training loss: 2.5523672103881836
Validation loss: 2.5307405866602415

Epoch: 5| Step: 4
Training loss: 2.44795298576355
Validation loss: 2.5328750815442813

Epoch: 5| Step: 5
Training loss: 3.0981290340423584
Validation loss: 2.530951499938965

Epoch: 5| Step: 6
Training loss: 2.11841082572937
Validation loss: 2.5306844172939176

Epoch: 5| Step: 7
Training loss: 2.3605713844299316
Validation loss: 2.5352217689637215

Epoch: 5| Step: 8
Training loss: 2.7607569694519043
Validation loss: 2.5405543465768137

Epoch: 5| Step: 9
Training loss: 2.792595386505127
Validation loss: 2.544949746900989

Epoch: 5| Step: 10
Training loss: 2.570016622543335
Validation loss: 2.5381192494464178

Epoch: 53| Step: 0
Training loss: 2.8540031909942627
Validation loss: 2.537912291865195

Epoch: 5| Step: 1
Training loss: 2.20595121383667
Validation loss: 2.531547272077171

Epoch: 5| Step: 2
Training loss: 2.2418160438537598
Validation loss: 2.5291446562736266

Epoch: 5| Step: 3
Training loss: 2.23984432220459
Validation loss: 2.526456397066834

Epoch: 5| Step: 4
Training loss: 2.5204617977142334
Validation loss: 2.5216917581455682

Epoch: 5| Step: 5
Training loss: 2.5851030349731445
Validation loss: 2.5245807350322766

Epoch: 5| Step: 6
Training loss: 3.1324210166931152
Validation loss: 2.52347001465418

Epoch: 5| Step: 7
Training loss: 3.394359588623047
Validation loss: 2.5208074815811647

Epoch: 5| Step: 8
Training loss: 3.328500747680664
Validation loss: 2.5226703997581237

Epoch: 5| Step: 9
Training loss: 3.284543991088867
Validation loss: 2.527746877362651

Epoch: 5| Step: 10
Training loss: 1.9452204704284668
Validation loss: 2.5316960503978114

Epoch: 54| Step: 0
Training loss: 2.586306095123291
Validation loss: 2.52807738191338

Epoch: 5| Step: 1
Training loss: 2.841582775115967
Validation loss: 2.5221304662765993

Epoch: 5| Step: 2
Training loss: 2.92923641204834
Validation loss: 2.51370648671222

Epoch: 5| Step: 3
Training loss: 2.668647289276123
Validation loss: 2.513587669659686

Epoch: 5| Step: 4
Training loss: 2.191227436065674
Validation loss: 2.5182151602160547

Epoch: 5| Step: 5
Training loss: 2.4815115928649902
Validation loss: 2.5256424821833128

Epoch: 5| Step: 6
Training loss: 2.6210596561431885
Validation loss: 2.5296414770105833

Epoch: 5| Step: 7
Training loss: 2.8750598430633545
Validation loss: 2.5215107112802486

Epoch: 5| Step: 8
Training loss: 2.7220442295074463
Validation loss: 2.513065994426768

Epoch: 5| Step: 9
Training loss: 2.670156955718994
Validation loss: 2.5093701770228725

Epoch: 5| Step: 10
Training loss: 3.4539449214935303
Validation loss: 2.5112745069688365

Epoch: 55| Step: 0
Training loss: 2.264512062072754
Validation loss: 2.510548258340487

Epoch: 5| Step: 1
Training loss: 2.9413001537323
Validation loss: 2.5053299293723157

Epoch: 5| Step: 2
Training loss: 2.776768445968628
Validation loss: 2.5062505199063208

Epoch: 5| Step: 3
Training loss: 2.754164218902588
Validation loss: 2.505696794038178

Epoch: 5| Step: 4
Training loss: 3.1655917167663574
Validation loss: 2.5033544596805366

Epoch: 5| Step: 5
Training loss: 2.534019947052002
Validation loss: 2.498206318065684

Epoch: 5| Step: 6
Training loss: 2.9614462852478027
Validation loss: 2.500980573315774

Epoch: 5| Step: 7
Training loss: 2.645047426223755
Validation loss: 2.498452437821255

Epoch: 5| Step: 8
Training loss: 2.613415479660034
Validation loss: 2.497764607911469

Epoch: 5| Step: 9
Training loss: 2.537024974822998
Validation loss: 2.4976190982326383

Epoch: 5| Step: 10
Training loss: 2.5237998962402344
Validation loss: 2.4980408709536315

Epoch: 56| Step: 0
Training loss: 2.365446090698242
Validation loss: 2.50032663601701

Epoch: 5| Step: 1
Training loss: 2.1704394817352295
Validation loss: 2.5056170955781014

Epoch: 5| Step: 2
Training loss: 2.4925906658172607
Validation loss: 2.5039675927931264

Epoch: 5| Step: 3
Training loss: 2.7738466262817383
Validation loss: 2.5060142188943844

Epoch: 5| Step: 4
Training loss: 3.085559844970703
Validation loss: 2.503967403083719

Epoch: 5| Step: 5
Training loss: 3.2400527000427246
Validation loss: 2.4959412979823288

Epoch: 5| Step: 6
Training loss: 3.450080156326294
Validation loss: 2.4900970176983903

Epoch: 5| Step: 7
Training loss: 1.6768910884857178
Validation loss: 2.4916645839650142

Epoch: 5| Step: 8
Training loss: 2.449833869934082
Validation loss: 2.491460795043617

Epoch: 5| Step: 9
Training loss: 3.2870025634765625
Validation loss: 2.4907300138986237

Epoch: 5| Step: 10
Training loss: 2.644078493118286
Validation loss: 2.492803371080788

Epoch: 57| Step: 0
Training loss: 2.7593655586242676
Validation loss: 2.493622825991723

Epoch: 5| Step: 1
Training loss: 3.2353477478027344
Validation loss: 2.4966227495542137

Epoch: 5| Step: 2
Training loss: 2.4194161891937256
Validation loss: 2.4974607831688336

Epoch: 5| Step: 3
Training loss: 2.2651867866516113
Validation loss: 2.4933290173930507

Epoch: 5| Step: 4
Training loss: 2.1785778999328613
Validation loss: 2.495226588300479

Epoch: 5| Step: 5
Training loss: 2.379333972930908
Validation loss: 2.4912766513004097

Epoch: 5| Step: 6
Training loss: 3.137892246246338
Validation loss: 2.4873429754728913

Epoch: 5| Step: 7
Training loss: 2.9200751781463623
Validation loss: 2.486599406888408

Epoch: 5| Step: 8
Training loss: 2.988823175430298
Validation loss: 2.4892834745427614

Epoch: 5| Step: 9
Training loss: 2.873119354248047
Validation loss: 2.491066189222438

Epoch: 5| Step: 10
Training loss: 2.5263822078704834
Validation loss: 2.4839556781194543

Epoch: 58| Step: 0
Training loss: 2.2758445739746094
Validation loss: 2.486413094305223

Epoch: 5| Step: 1
Training loss: 2.198232650756836
Validation loss: 2.4857526338228615

Epoch: 5| Step: 2
Training loss: 3.0317766666412354
Validation loss: 2.485077455479612

Epoch: 5| Step: 3
Training loss: 3.0477521419525146
Validation loss: 2.4866684226579565

Epoch: 5| Step: 4
Training loss: 3.3374221324920654
Validation loss: 2.4849290104322534

Epoch: 5| Step: 5
Training loss: 2.6072025299072266
Validation loss: 2.4848320791798253

Epoch: 5| Step: 6
Training loss: 2.4637610912323
Validation loss: 2.4917391577074604

Epoch: 5| Step: 7
Training loss: 2.3858256340026855
Validation loss: 2.4920494018062467

Epoch: 5| Step: 8
Training loss: 3.0115532875061035
Validation loss: 2.4909819787548435

Epoch: 5| Step: 9
Training loss: 2.5768325328826904
Validation loss: 2.4992193944992556

Epoch: 5| Step: 10
Training loss: 2.6316299438476562
Validation loss: 2.4938936669339418

Epoch: 59| Step: 0
Training loss: 3.1036934852600098
Validation loss: 2.48966133722695

Epoch: 5| Step: 1
Training loss: 2.904963731765747
Validation loss: 2.4903795616601103

Epoch: 5| Step: 2
Training loss: 2.3309836387634277
Validation loss: 2.4869863038421958

Epoch: 5| Step: 3
Training loss: 2.1291794776916504
Validation loss: 2.485603899084112

Epoch: 5| Step: 4
Training loss: 2.3663432598114014
Validation loss: 2.48587877263305

Epoch: 5| Step: 5
Training loss: 2.3532567024230957
Validation loss: 2.4827852402963946

Epoch: 5| Step: 6
Training loss: 2.639608860015869
Validation loss: 2.4842702957891647

Epoch: 5| Step: 7
Training loss: 3.293435573577881
Validation loss: 2.4868773875697965

Epoch: 5| Step: 8
Training loss: 3.0441839694976807
Validation loss: 2.492727284790367

Epoch: 5| Step: 9
Training loss: 2.951418399810791
Validation loss: 2.4974982635949248

Epoch: 5| Step: 10
Training loss: 2.3505477905273438
Validation loss: 2.5006374261712514

Epoch: 60| Step: 0
Training loss: 2.9864089488983154
Validation loss: 2.4952943940316477

Epoch: 5| Step: 1
Training loss: 2.8338749408721924
Validation loss: 2.4998943908240205

Epoch: 5| Step: 2
Training loss: 3.116896152496338
Validation loss: 2.509826244846467

Epoch: 5| Step: 3
Training loss: 2.7004857063293457
Validation loss: 2.504584458566481

Epoch: 5| Step: 4
Training loss: 2.8173253536224365
Validation loss: 2.481580077960927

Epoch: 5| Step: 5
Training loss: 2.566295623779297
Validation loss: 2.466058249114662

Epoch: 5| Step: 6
Training loss: 2.3295977115631104
Validation loss: 2.46658306993464

Epoch: 5| Step: 7
Training loss: 2.2206668853759766
Validation loss: 2.473116474766885

Epoch: 5| Step: 8
Training loss: 2.34173583984375
Validation loss: 2.4804180565700737

Epoch: 5| Step: 9
Training loss: 2.487527847290039
Validation loss: 2.482205565257739

Epoch: 5| Step: 10
Training loss: 3.32338809967041
Validation loss: 2.477177794261645

Epoch: 61| Step: 0
Training loss: 2.5804145336151123
Validation loss: 2.4734191227984685

Epoch: 5| Step: 1
Training loss: 2.9367434978485107
Validation loss: 2.4701058864593506

Epoch: 5| Step: 2
Training loss: 2.6920440196990967
Validation loss: 2.462317899991107

Epoch: 5| Step: 3
Training loss: 3.277578353881836
Validation loss: 2.4588917429729173

Epoch: 5| Step: 4
Training loss: 2.60011625289917
Validation loss: 2.456425484790597

Epoch: 5| Step: 5
Training loss: 2.752026081085205
Validation loss: 2.4536826251655497

Epoch: 5| Step: 6
Training loss: 1.9958499670028687
Validation loss: 2.4548261319437334

Epoch: 5| Step: 7
Training loss: 2.3446903228759766
Validation loss: 2.4527248695332515

Epoch: 5| Step: 8
Training loss: 2.51739764213562
Validation loss: 2.4515281287572717

Epoch: 5| Step: 9
Training loss: 3.178022861480713
Validation loss: 2.4654896131125827

Epoch: 5| Step: 10
Training loss: 2.608398199081421
Validation loss: 2.4776619044683312

Epoch: 62| Step: 0
Training loss: 2.6113317012786865
Validation loss: 2.478047440128942

Epoch: 5| Step: 1
Training loss: 2.5624594688415527
Validation loss: 2.4910050079386723

Epoch: 5| Step: 2
Training loss: 2.610722064971924
Validation loss: 2.489926435614145

Epoch: 5| Step: 3
Training loss: 2.864983081817627
Validation loss: 2.4608726552737656

Epoch: 5| Step: 4
Training loss: 2.5612781047821045
Validation loss: 2.451587538565359

Epoch: 5| Step: 5
Training loss: 3.0157527923583984
Validation loss: 2.4450171737260717

Epoch: 5| Step: 6
Training loss: 2.8383984565734863
Validation loss: 2.446499929633192

Epoch: 5| Step: 7
Training loss: 2.455535650253296
Validation loss: 2.44771840495448

Epoch: 5| Step: 8
Training loss: 2.5097579956054688
Validation loss: 2.44594399134318

Epoch: 5| Step: 9
Training loss: 2.4188570976257324
Validation loss: 2.444329095143144

Epoch: 5| Step: 10
Training loss: 2.9532108306884766
Validation loss: 2.4479529165452525

Epoch: 63| Step: 0
Training loss: 2.402134418487549
Validation loss: 2.447765427251016

Epoch: 5| Step: 1
Training loss: 3.2841796875
Validation loss: 2.443034766822733

Epoch: 5| Step: 2
Training loss: 2.1266589164733887
Validation loss: 2.4443111445314143

Epoch: 5| Step: 3
Training loss: 3.265624523162842
Validation loss: 2.4484561181837514

Epoch: 5| Step: 4
Training loss: 2.1205265522003174
Validation loss: 2.4481744753417147

Epoch: 5| Step: 5
Training loss: 2.856401205062866
Validation loss: 2.4604773034331617

Epoch: 5| Step: 6
Training loss: 3.0196874141693115
Validation loss: 2.4694595977824223

Epoch: 5| Step: 7
Training loss: 2.6980509757995605
Validation loss: 2.468968783655474

Epoch: 5| Step: 8
Training loss: 2.625394582748413
Validation loss: 2.478828268666421

Epoch: 5| Step: 9
Training loss: 2.7014317512512207
Validation loss: 2.474957367425324

Epoch: 5| Step: 10
Training loss: 2.2730300426483154
Validation loss: 2.4626884973177345

Epoch: 64| Step: 0
Training loss: 2.656193494796753
Validation loss: 2.454221894664149

Epoch: 5| Step: 1
Training loss: 2.2048943042755127
Validation loss: 2.451701900010468

Epoch: 5| Step: 2
Training loss: 2.069139003753662
Validation loss: 2.445980273267274

Epoch: 5| Step: 3
Training loss: 2.5572643280029297
Validation loss: 2.4441320332147742

Epoch: 5| Step: 4
Training loss: 3.093855619430542
Validation loss: 2.43767362512568

Epoch: 5| Step: 5
Training loss: 2.7802186012268066
Validation loss: 2.438647059984105

Epoch: 5| Step: 6
Training loss: 2.638031005859375
Validation loss: 2.4422259946023264

Epoch: 5| Step: 7
Training loss: 3.128592014312744
Validation loss: 2.4434079354809177

Epoch: 5| Step: 8
Training loss: 2.6721138954162598
Validation loss: 2.4424357183517946

Epoch: 5| Step: 9
Training loss: 3.555330276489258
Validation loss: 2.4395170852702153

Epoch: 5| Step: 10
Training loss: 1.9365010261535645
Validation loss: 2.4377903297383297

Epoch: 65| Step: 0
Training loss: 3.1466851234436035
Validation loss: 2.4399801479872836

Epoch: 5| Step: 1
Training loss: 1.7688325643539429
Validation loss: 2.4352504386696765

Epoch: 5| Step: 2
Training loss: 3.463184356689453
Validation loss: 2.4402244167943157

Epoch: 5| Step: 3
Training loss: 2.473113536834717
Validation loss: 2.446137889739006

Epoch: 5| Step: 4
Training loss: 2.6683385372161865
Validation loss: 2.4581611874283

Epoch: 5| Step: 5
Training loss: 2.4409327507019043
Validation loss: 2.451397970158567

Epoch: 5| Step: 6
Training loss: 3.182997941970825
Validation loss: 2.462428128847512

Epoch: 5| Step: 7
Training loss: 2.5582425594329834
Validation loss: 2.4622483484206663

Epoch: 5| Step: 8
Training loss: 2.1251683235168457
Validation loss: 2.4558901889349825

Epoch: 5| Step: 9
Training loss: 2.252903461456299
Validation loss: 2.4442768814743205

Epoch: 5| Step: 10
Training loss: 3.3423075675964355
Validation loss: 2.437464088521978

Epoch: 66| Step: 0
Training loss: 3.025804042816162
Validation loss: 2.4420902934125674

Epoch: 5| Step: 1
Training loss: 2.6436126232147217
Validation loss: 2.4401246706644693

Epoch: 5| Step: 2
Training loss: 2.9299819469451904
Validation loss: 2.442441801871023

Epoch: 5| Step: 3
Training loss: 2.2439143657684326
Validation loss: 2.440695872870825

Epoch: 5| Step: 4
Training loss: 2.974747657775879
Validation loss: 2.441001581889327

Epoch: 5| Step: 5
Training loss: 2.5313687324523926
Validation loss: 2.4376093110730572

Epoch: 5| Step: 6
Training loss: 1.815173864364624
Validation loss: 2.4390016525022444

Epoch: 5| Step: 7
Training loss: 3.149203300476074
Validation loss: 2.4383337548983994

Epoch: 5| Step: 8
Training loss: 2.7183353900909424
Validation loss: 2.4373319559199835

Epoch: 5| Step: 9
Training loss: 3.009864568710327
Validation loss: 2.4334814856129308

Epoch: 5| Step: 10
Training loss: 2.120079517364502
Validation loss: 2.4371561440088416

Epoch: 67| Step: 0
Training loss: 2.7517402172088623
Validation loss: 2.433029705478299

Epoch: 5| Step: 1
Training loss: 2.9048774242401123
Validation loss: 2.4268556653812365

Epoch: 5| Step: 2
Training loss: 2.3350372314453125
Validation loss: 2.422598805478824

Epoch: 5| Step: 3
Training loss: 2.593421459197998
Validation loss: 2.418707738640488

Epoch: 5| Step: 4
Training loss: 3.603792905807495
Validation loss: 2.416973930533214

Epoch: 5| Step: 5
Training loss: 2.2415316104888916
Validation loss: 2.4186096729770785

Epoch: 5| Step: 6
Training loss: 2.8128254413604736
Validation loss: 2.41885345725603

Epoch: 5| Step: 7
Training loss: 2.17138934135437
Validation loss: 2.422556359280822

Epoch: 5| Step: 8
Training loss: 2.6279351711273193
Validation loss: 2.42065453785722

Epoch: 5| Step: 9
Training loss: 2.380438804626465
Validation loss: 2.420398368630358

Epoch: 5| Step: 10
Training loss: 2.698606252670288
Validation loss: 2.4221534113730154

Epoch: 68| Step: 0
Training loss: 2.780820369720459
Validation loss: 2.4198571379466722

Epoch: 5| Step: 1
Training loss: 2.702512264251709
Validation loss: 2.417315037019791

Epoch: 5| Step: 2
Training loss: 2.3296616077423096
Validation loss: 2.4150389368816088

Epoch: 5| Step: 3
Training loss: 2.4838900566101074
Validation loss: 2.413128593916534

Epoch: 5| Step: 4
Training loss: 2.8874406814575195
Validation loss: 2.422799648777131

Epoch: 5| Step: 5
Training loss: 2.7834086418151855
Validation loss: 2.429554118905016

Epoch: 5| Step: 6
Training loss: 2.9029595851898193
Validation loss: 2.4358441381044287

Epoch: 5| Step: 7
Training loss: 2.547334671020508
Validation loss: 2.434419183320897

Epoch: 5| Step: 8
Training loss: 2.057709217071533
Validation loss: 2.4287886465749433

Epoch: 5| Step: 9
Training loss: 3.145214557647705
Validation loss: 2.4221018334870696

Epoch: 5| Step: 10
Training loss: 2.4717962741851807
Validation loss: 2.412900117135817

Epoch: 69| Step: 0
Training loss: 3.0752501487731934
Validation loss: 2.4205874627636326

Epoch: 5| Step: 1
Training loss: 2.5691514015197754
Validation loss: 2.4210232406534176

Epoch: 5| Step: 2
Training loss: 2.789935827255249
Validation loss: 2.4175169993472356

Epoch: 5| Step: 3
Training loss: 2.8389358520507812
Validation loss: 2.4122302147649948

Epoch: 5| Step: 4
Training loss: 2.482494354248047
Validation loss: 2.404323841935845

Epoch: 5| Step: 5
Training loss: 2.5254502296447754
Validation loss: 2.407668759745936

Epoch: 5| Step: 6
Training loss: 2.3151721954345703
Validation loss: 2.4028355870195615

Epoch: 5| Step: 7
Training loss: 2.827871799468994
Validation loss: 2.407302295008013

Epoch: 5| Step: 8
Training loss: 2.70209002494812
Validation loss: 2.407619014863045

Epoch: 5| Step: 9
Training loss: 2.717996835708618
Validation loss: 2.413237892171388

Epoch: 5| Step: 10
Training loss: 2.155581474304199
Validation loss: 2.4108789197860228

Epoch: 70| Step: 0
Training loss: 2.3599443435668945
Validation loss: 2.402508992020802

Epoch: 5| Step: 1
Training loss: 2.892756938934326
Validation loss: 2.4012670286240114

Epoch: 5| Step: 2
Training loss: 2.756458044052124
Validation loss: 2.3995492817253194

Epoch: 5| Step: 3
Training loss: 2.5350067615509033
Validation loss: 2.4028066024985364

Epoch: 5| Step: 4
Training loss: 2.848870277404785
Validation loss: 2.4004366910585793

Epoch: 5| Step: 5
Training loss: 2.5962018966674805
Validation loss: 2.401777828893354

Epoch: 5| Step: 6
Training loss: 2.225177049636841
Validation loss: 2.404981259376772

Epoch: 5| Step: 7
Training loss: 2.3227970600128174
Validation loss: 2.4025323032051005

Epoch: 5| Step: 8
Training loss: 3.0221359729766846
Validation loss: 2.4038636248598815

Epoch: 5| Step: 9
Training loss: 2.787330150604248
Validation loss: 2.406154468495359

Epoch: 5| Step: 10
Training loss: 2.678900957107544
Validation loss: 2.419424400534681

Epoch: 71| Step: 0
Training loss: 2.7794063091278076
Validation loss: 2.4360082636597338

Epoch: 5| Step: 1
Training loss: 2.4716098308563232
Validation loss: 2.437202912504955

Epoch: 5| Step: 2
Training loss: 2.098228693008423
Validation loss: 2.4321293933417207

Epoch: 5| Step: 3
Training loss: 3.043444871902466
Validation loss: 2.4246683300182386

Epoch: 5| Step: 4
Training loss: 2.811570644378662
Validation loss: 2.420504154697541

Epoch: 5| Step: 5
Training loss: 3.223867893218994
Validation loss: 2.4226419912871493

Epoch: 5| Step: 6
Training loss: 2.2259140014648438
Validation loss: 2.4205491619725383

Epoch: 5| Step: 7
Training loss: 2.6861889362335205
Validation loss: 2.4170128812072096

Epoch: 5| Step: 8
Training loss: 2.4466757774353027
Validation loss: 2.412821149313322

Epoch: 5| Step: 9
Training loss: 2.700282335281372
Validation loss: 2.4126888257201

Epoch: 5| Step: 10
Training loss: 2.502614974975586
Validation loss: 2.4125325961779525

Epoch: 72| Step: 0
Training loss: 3.0558664798736572
Validation loss: 2.415821570222096

Epoch: 5| Step: 1
Training loss: 2.7485852241516113
Validation loss: 2.4164543895311255

Epoch: 5| Step: 2
Training loss: 2.065293550491333
Validation loss: 2.4201555969894573

Epoch: 5| Step: 3
Training loss: 2.58685302734375
Validation loss: 2.4080906375761955

Epoch: 5| Step: 4
Training loss: 3.5782501697540283
Validation loss: 2.392860048560686

Epoch: 5| Step: 5
Training loss: 2.501762866973877
Validation loss: 2.394065305750857

Epoch: 5| Step: 6
Training loss: 2.5034775733947754
Validation loss: 2.39554718489288

Epoch: 5| Step: 7
Training loss: 1.978026032447815
Validation loss: 2.3944508414114676

Epoch: 5| Step: 8
Training loss: 2.9886183738708496
Validation loss: 2.3962023386391262

Epoch: 5| Step: 9
Training loss: 2.432600498199463
Validation loss: 2.3953433370077484

Epoch: 5| Step: 10
Training loss: 2.443439483642578
Validation loss: 2.4021888932874127

Epoch: 73| Step: 0
Training loss: 2.808483600616455
Validation loss: 2.4217904716409664

Epoch: 5| Step: 1
Training loss: 1.9125316143035889
Validation loss: 2.420629575688352

Epoch: 5| Step: 2
Training loss: 3.1200575828552246
Validation loss: 2.429923697184491

Epoch: 5| Step: 3
Training loss: 3.274505138397217
Validation loss: 2.397709165849993

Epoch: 5| Step: 4
Training loss: 2.3446788787841797
Validation loss: 2.3902832654214676

Epoch: 5| Step: 5
Training loss: 2.512085437774658
Validation loss: 2.3813273060706353

Epoch: 5| Step: 6
Training loss: 2.869474411010742
Validation loss: 2.3765046314526628

Epoch: 5| Step: 7
Training loss: 2.5535573959350586
Validation loss: 2.37700992502192

Epoch: 5| Step: 8
Training loss: 2.778935670852661
Validation loss: 2.3763673997694448

Epoch: 5| Step: 9
Training loss: 2.2132058143615723
Validation loss: 2.375250226707869

Epoch: 5| Step: 10
Training loss: 2.457897186279297
Validation loss: 2.3837280401619534

Epoch: 74| Step: 0
Training loss: 3.024061679840088
Validation loss: 2.3898034147036973

Epoch: 5| Step: 1
Training loss: 2.7245566844940186
Validation loss: 2.401332634751515

Epoch: 5| Step: 2
Training loss: 2.969162702560425
Validation loss: 2.4133388021940827

Epoch: 5| Step: 3
Training loss: 2.3214993476867676
Validation loss: 2.40847618861865

Epoch: 5| Step: 4
Training loss: 1.7723230123519897
Validation loss: 2.396162156135805

Epoch: 5| Step: 5
Training loss: 2.4546709060668945
Validation loss: 2.4130930567300446

Epoch: 5| Step: 6
Training loss: 2.699443817138672
Validation loss: 2.4293642531159105

Epoch: 5| Step: 7
Training loss: 2.9249844551086426
Validation loss: 2.405494369486327

Epoch: 5| Step: 8
Training loss: 3.0232114791870117
Validation loss: 2.3996239708315943

Epoch: 5| Step: 9
Training loss: 3.063488483428955
Validation loss: 2.3874466521765596

Epoch: 5| Step: 10
Training loss: 1.7995920181274414
Validation loss: 2.374026939433108

Epoch: 75| Step: 0
Training loss: 2.1697487831115723
Validation loss: 2.3707076093201995

Epoch: 5| Step: 1
Training loss: 2.6510815620422363
Validation loss: 2.3713440920716975

Epoch: 5| Step: 2
Training loss: 3.3926308155059814
Validation loss: 2.3746282797987743

Epoch: 5| Step: 3
Training loss: 2.2953689098358154
Validation loss: 2.3761946821725495

Epoch: 5| Step: 4
Training loss: 2.844635248184204
Validation loss: 2.3817548751831055

Epoch: 5| Step: 5
Training loss: 2.592104434967041
Validation loss: 2.379006924167756

Epoch: 5| Step: 6
Training loss: 2.7621688842773438
Validation loss: 2.376529480821343

Epoch: 5| Step: 7
Training loss: 2.526196241378784
Validation loss: 2.369527059216653

Epoch: 5| Step: 8
Training loss: 2.3414478302001953
Validation loss: 2.367802796825286

Epoch: 5| Step: 9
Training loss: 2.611929178237915
Validation loss: 2.3666292134151665

Epoch: 5| Step: 10
Training loss: 2.7784249782562256
Validation loss: 2.383798317242694

Epoch: 76| Step: 0
Training loss: 2.500948667526245
Validation loss: 2.4191130976523123

Epoch: 5| Step: 1
Training loss: 3.263354539871216
Validation loss: 2.460806103162868

Epoch: 5| Step: 2
Training loss: 2.555957794189453
Validation loss: 2.485205587520394

Epoch: 5| Step: 3
Training loss: 2.1692793369293213
Validation loss: 2.517243028968893

Epoch: 5| Step: 4
Training loss: 2.745736598968506
Validation loss: 2.4853802624569146

Epoch: 5| Step: 5
Training loss: 2.3489949703216553
Validation loss: 2.446562567064839

Epoch: 5| Step: 6
Training loss: 2.3163352012634277
Validation loss: 2.431477318527878

Epoch: 5| Step: 7
Training loss: 2.416050672531128
Validation loss: 2.4037548752241236

Epoch: 5| Step: 8
Training loss: 3.5838394165039062
Validation loss: 2.3823844976322626

Epoch: 5| Step: 9
Training loss: 2.266995906829834
Validation loss: 2.370095117117769

Epoch: 5| Step: 10
Training loss: 2.7141001224517822
Validation loss: 2.3689373770067768

Epoch: 77| Step: 0
Training loss: 2.287686586380005
Validation loss: 2.3730633438274427

Epoch: 5| Step: 1
Training loss: 3.3322455883026123
Validation loss: 2.370893724503056

Epoch: 5| Step: 2
Training loss: 3.0251266956329346
Validation loss: 2.3747310894791798

Epoch: 5| Step: 3
Training loss: 2.398618221282959
Validation loss: 2.3701035591863815

Epoch: 5| Step: 4
Training loss: 2.4711813926696777
Validation loss: 2.362308058687436

Epoch: 5| Step: 5
Training loss: 2.6984853744506836
Validation loss: 2.3610968179600214

Epoch: 5| Step: 6
Training loss: 2.623185157775879
Validation loss: 2.3580842428309943

Epoch: 5| Step: 7
Training loss: 2.216984272003174
Validation loss: 2.3580091461058585

Epoch: 5| Step: 8
Training loss: 2.8395187854766846
Validation loss: 2.367157510531846

Epoch: 5| Step: 9
Training loss: 1.6864960193634033
Validation loss: 2.40878459202346

Epoch: 5| Step: 10
Training loss: 3.3249104022979736
Validation loss: 2.448180998525312

Epoch: 78| Step: 0
Training loss: 2.156872272491455
Validation loss: 2.483945646593648

Epoch: 5| Step: 1
Training loss: 2.898745059967041
Validation loss: 2.488253944663591

Epoch: 5| Step: 2
Training loss: 3.1373417377471924
Validation loss: 2.4260126890674716

Epoch: 5| Step: 3
Training loss: 2.471039295196533
Validation loss: 2.3821038456373316

Epoch: 5| Step: 4
Training loss: 2.1407179832458496
Validation loss: 2.361684432593725

Epoch: 5| Step: 5
Training loss: 2.4645469188690186
Validation loss: 2.3655647641869

Epoch: 5| Step: 6
Training loss: 2.707977533340454
Validation loss: 2.380703433867424

Epoch: 5| Step: 7
Training loss: 2.4634604454040527
Validation loss: 2.389818194091961

Epoch: 5| Step: 8
Training loss: 2.4501137733459473
Validation loss: 2.3938418690876295

Epoch: 5| Step: 9
Training loss: 3.1787686347961426
Validation loss: 2.388741998262303

Epoch: 5| Step: 10
Training loss: 2.993966579437256
Validation loss: 2.3846303134836178

Epoch: 79| Step: 0
Training loss: 2.7771549224853516
Validation loss: 2.382443312675722

Epoch: 5| Step: 1
Training loss: 2.089682102203369
Validation loss: 2.3801684123213573

Epoch: 5| Step: 2
Training loss: 2.7090020179748535
Validation loss: 2.378430187061269

Epoch: 5| Step: 3
Training loss: 2.756967306137085
Validation loss: 2.3702588965815883

Epoch: 5| Step: 4
Training loss: 3.0751805305480957
Validation loss: 2.3656391687290643

Epoch: 5| Step: 5
Training loss: 3.4412903785705566
Validation loss: 2.35744462731064

Epoch: 5| Step: 6
Training loss: 2.5540037155151367
Validation loss: 2.3515364303383777

Epoch: 5| Step: 7
Training loss: 2.362668514251709
Validation loss: 2.3542391100237445

Epoch: 5| Step: 8
Training loss: 2.8758156299591064
Validation loss: 2.3497066523439143

Epoch: 5| Step: 9
Training loss: 2.2486729621887207
Validation loss: 2.3511094739360194

Epoch: 5| Step: 10
Training loss: 1.835898756980896
Validation loss: 2.353425687359225

Epoch: 80| Step: 0
Training loss: 2.4601874351501465
Validation loss: 2.3724607575324272

Epoch: 5| Step: 1
Training loss: 2.470593214035034
Validation loss: 2.3853822113365255

Epoch: 5| Step: 2
Training loss: 2.781451463699341
Validation loss: 2.3838654371999923

Epoch: 5| Step: 3
Training loss: 2.5724692344665527
Validation loss: 2.3799442411750875

Epoch: 5| Step: 4
Training loss: 3.0355238914489746
Validation loss: 2.3660898490618636

Epoch: 5| Step: 5
Training loss: 2.2657759189605713
Validation loss: 2.363431592141428

Epoch: 5| Step: 6
Training loss: 2.9647605419158936
Validation loss: 2.3573253308573077

Epoch: 5| Step: 7
Training loss: 2.2796032428741455
Validation loss: 2.3441319978365334

Epoch: 5| Step: 8
Training loss: 2.7453861236572266
Validation loss: 2.346420100940171

Epoch: 5| Step: 9
Training loss: 2.895963191986084
Validation loss: 2.3495317043796664

Epoch: 5| Step: 10
Training loss: 2.051870822906494
Validation loss: 2.344597854921895

Epoch: 81| Step: 0
Training loss: 2.271714687347412
Validation loss: 2.353347098955544

Epoch: 5| Step: 1
Training loss: 2.2296204566955566
Validation loss: 2.3625903001395603

Epoch: 5| Step: 2
Training loss: 3.238762378692627
Validation loss: 2.3621196439189296

Epoch: 5| Step: 3
Training loss: 2.5240094661712646
Validation loss: 2.36281277543755

Epoch: 5| Step: 4
Training loss: 2.4802067279815674
Validation loss: 2.3585449726350847

Epoch: 5| Step: 5
Training loss: 2.8275935649871826
Validation loss: 2.348792235056559

Epoch: 5| Step: 6
Training loss: 2.1627326011657715
Validation loss: 2.3461181476551998

Epoch: 5| Step: 7
Training loss: 2.505337953567505
Validation loss: 2.3442872314042944

Epoch: 5| Step: 8
Training loss: 3.1254191398620605
Validation loss: 2.3444943620312597

Epoch: 5| Step: 9
Training loss: 2.7836809158325195
Validation loss: 2.3464691049309185

Epoch: 5| Step: 10
Training loss: 2.3821537494659424
Validation loss: 2.350040207626999

Epoch: 82| Step: 0
Training loss: 2.955988883972168
Validation loss: 2.3521711954506497

Epoch: 5| Step: 1
Training loss: 3.2101645469665527
Validation loss: 2.3565349860857894

Epoch: 5| Step: 2
Training loss: 3.5617663860321045
Validation loss: 2.3479032606206913

Epoch: 5| Step: 3
Training loss: 2.499281406402588
Validation loss: 2.343228970804522

Epoch: 5| Step: 4
Training loss: 2.188953399658203
Validation loss: 2.335289506502049

Epoch: 5| Step: 5
Training loss: 2.540468692779541
Validation loss: 2.3359757572092037

Epoch: 5| Step: 6
Training loss: 2.6543242931365967
Validation loss: 2.3349467118581138

Epoch: 5| Step: 7
Training loss: 2.8030903339385986
Validation loss: 2.3341931066205426

Epoch: 5| Step: 8
Training loss: 2.2785282135009766
Validation loss: 2.336456065536827

Epoch: 5| Step: 9
Training loss: 2.4964981079101562
Validation loss: 2.3340188431483444

Epoch: 5| Step: 10
Training loss: 1.0669050216674805
Validation loss: 2.3323241843972156

Epoch: 83| Step: 0
Training loss: 2.3723955154418945
Validation loss: 2.3296340665509625

Epoch: 5| Step: 1
Training loss: 2.770806074142456
Validation loss: 2.3315040296123875

Epoch: 5| Step: 2
Training loss: 2.3827624320983887
Validation loss: 2.3352350137567006

Epoch: 5| Step: 3
Training loss: 3.1503872871398926
Validation loss: 2.3462882913568968

Epoch: 5| Step: 4
Training loss: 1.7984460592269897
Validation loss: 2.346704170268069

Epoch: 5| Step: 5
Training loss: 3.2289047241210938
Validation loss: 2.3516446057186333

Epoch: 5| Step: 6
Training loss: 2.1102077960968018
Validation loss: 2.3580540200715423

Epoch: 5| Step: 7
Training loss: 2.268489360809326
Validation loss: 2.3676101135951217

Epoch: 5| Step: 8
Training loss: 2.5170319080352783
Validation loss: 2.394978574527207

Epoch: 5| Step: 9
Training loss: 2.8533451557159424
Validation loss: 2.4059247560398553

Epoch: 5| Step: 10
Training loss: 3.182332754135132
Validation loss: 2.3726699403537217

Epoch: 84| Step: 0
Training loss: 1.8242111206054688
Validation loss: 2.3484711134305565

Epoch: 5| Step: 1
Training loss: 3.1315841674804688
Validation loss: 2.3391311527580343

Epoch: 5| Step: 2
Training loss: 2.8229429721832275
Validation loss: 2.328524225501604

Epoch: 5| Step: 3
Training loss: 2.8777012825012207
Validation loss: 2.329734807373375

Epoch: 5| Step: 4
Training loss: 2.0798797607421875
Validation loss: 2.329799034262216

Epoch: 5| Step: 5
Training loss: 2.1076996326446533
Validation loss: 2.32757640910405

Epoch: 5| Step: 6
Training loss: 3.2518222332000732
Validation loss: 2.331889357618106

Epoch: 5| Step: 7
Training loss: 1.9892137050628662
Validation loss: 2.3418295896181496

Epoch: 5| Step: 8
Training loss: 3.236645460128784
Validation loss: 2.3603587868393108

Epoch: 5| Step: 9
Training loss: 2.7089571952819824
Validation loss: 2.38791625730453

Epoch: 5| Step: 10
Training loss: 2.5257599353790283
Validation loss: 2.4093297630228023

Epoch: 85| Step: 0
Training loss: 2.9424357414245605
Validation loss: 2.4146416187286377

Epoch: 5| Step: 1
Training loss: 2.800069808959961
Validation loss: 2.3620077538233932

Epoch: 5| Step: 2
Training loss: 2.4586029052734375
Validation loss: 2.3333183437265377

Epoch: 5| Step: 3
Training loss: 2.6578214168548584
Validation loss: 2.322451683782762

Epoch: 5| Step: 4
Training loss: 2.426537036895752
Validation loss: 2.325708138045444

Epoch: 5| Step: 5
Training loss: 2.2091426849365234
Validation loss: 2.3264273494802494

Epoch: 5| Step: 6
Training loss: 2.078997850418091
Validation loss: 2.327534708925473

Epoch: 5| Step: 7
Training loss: 3.003863573074341
Validation loss: 2.327551918645059

Epoch: 5| Step: 8
Training loss: 2.9493565559387207
Validation loss: 2.3240882145461215

Epoch: 5| Step: 9
Training loss: 2.6000638008117676
Validation loss: 2.3245814897680797

Epoch: 5| Step: 10
Training loss: 2.3598060607910156
Validation loss: 2.319669661983367

Epoch: 86| Step: 0
Training loss: 2.293321371078491
Validation loss: 2.3161864806247014

Epoch: 5| Step: 1
Training loss: 2.401430606842041
Validation loss: 2.32098287920798

Epoch: 5| Step: 2
Training loss: 3.11494779586792
Validation loss: 2.3328763720809773

Epoch: 5| Step: 3
Training loss: 2.442096710205078
Validation loss: 2.3537776906003236

Epoch: 5| Step: 4
Training loss: 1.959189772605896
Validation loss: 2.371549157686131

Epoch: 5| Step: 5
Training loss: 2.308717727661133
Validation loss: 2.3653876345644713

Epoch: 5| Step: 6
Training loss: 3.280900478363037
Validation loss: 2.358350302583428

Epoch: 5| Step: 7
Training loss: 2.33912992477417
Validation loss: 2.335842914478753

Epoch: 5| Step: 8
Training loss: 2.777329206466675
Validation loss: 2.326027882996426

Epoch: 5| Step: 9
Training loss: 3.0933804512023926
Validation loss: 2.3289041032073317

Epoch: 5| Step: 10
Training loss: 2.35894775390625
Validation loss: 2.3204761910182174

Epoch: 87| Step: 0
Training loss: 3.075573444366455
Validation loss: 2.323319240282941

Epoch: 5| Step: 1
Training loss: 2.798552989959717
Validation loss: 2.3204333397649948

Epoch: 5| Step: 2
Training loss: 2.3260223865509033
Validation loss: 2.3172496185507825

Epoch: 5| Step: 3
Training loss: 2.9327101707458496
Validation loss: 2.31242645940473

Epoch: 5| Step: 4
Training loss: 2.326411485671997
Validation loss: 2.3140404391032394

Epoch: 5| Step: 5
Training loss: 2.722714900970459
Validation loss: 2.3223740669988815

Epoch: 5| Step: 6
Training loss: 2.534153461456299
Validation loss: 2.322944591122289

Epoch: 5| Step: 7
Training loss: 2.53662109375
Validation loss: 2.3237220266813874

Epoch: 5| Step: 8
Training loss: 2.2495226860046387
Validation loss: 2.3243615345288346

Epoch: 5| Step: 9
Training loss: 2.968366861343384
Validation loss: 2.318854888280233

Epoch: 5| Step: 10
Training loss: 1.7134130001068115
Validation loss: 2.3093203857380855

Epoch: 88| Step: 0
Training loss: 2.507167100906372
Validation loss: 2.3138369334641324

Epoch: 5| Step: 1
Training loss: 2.3506977558135986
Validation loss: 2.314733889795119

Epoch: 5| Step: 2
Training loss: 2.361340045928955
Validation loss: 2.3151371709762083

Epoch: 5| Step: 3
Training loss: 2.7287306785583496
Validation loss: 2.3310383263454644

Epoch: 5| Step: 4
Training loss: 1.9002234935760498
Validation loss: 2.3390535898106073

Epoch: 5| Step: 5
Training loss: 2.5997395515441895
Validation loss: 2.3199019303885837

Epoch: 5| Step: 6
Training loss: 2.7970759868621826
Validation loss: 2.306164151878767

Epoch: 5| Step: 7
Training loss: 2.2154946327209473
Validation loss: 2.304129785107028

Epoch: 5| Step: 8
Training loss: 2.7062745094299316
Validation loss: 2.3009080630476757

Epoch: 5| Step: 9
Training loss: 2.766947031021118
Validation loss: 2.3001428163179787

Epoch: 5| Step: 10
Training loss: 3.454681634902954
Validation loss: 2.3022214956181024

Epoch: 89| Step: 0
Training loss: 3.0655436515808105
Validation loss: 2.2963407398552023

Epoch: 5| Step: 1
Training loss: 2.701817035675049
Validation loss: 2.302310550084678

Epoch: 5| Step: 2
Training loss: 2.7033286094665527
Validation loss: 2.3083268634734617

Epoch: 5| Step: 3
Training loss: 3.025599241256714
Validation loss: 2.3108192951448503

Epoch: 5| Step: 4
Training loss: 2.416257619857788
Validation loss: 2.3183786484502975

Epoch: 5| Step: 5
Training loss: 2.457113027572632
Validation loss: 2.3216138860230804

Epoch: 5| Step: 6
Training loss: 2.5012950897216797
Validation loss: 2.3235457071693997

Epoch: 5| Step: 7
Training loss: 2.335000514984131
Validation loss: 2.322959335901404

Epoch: 5| Step: 8
Training loss: 2.1361663341522217
Validation loss: 2.3227316128310336

Epoch: 5| Step: 9
Training loss: 2.894113063812256
Validation loss: 2.322981285792525

Epoch: 5| Step: 10
Training loss: 1.8459407091140747
Validation loss: 2.3212779978270173

Epoch: 90| Step: 0
Training loss: 2.5591559410095215
Validation loss: 2.3183563729768157

Epoch: 5| Step: 1
Training loss: 2.0226073265075684
Validation loss: 2.3176862808965866

Epoch: 5| Step: 2
Training loss: 2.4866535663604736
Validation loss: 2.312760929907522

Epoch: 5| Step: 3
Training loss: 2.905184507369995
Validation loss: 2.3059677872606503

Epoch: 5| Step: 4
Training loss: 2.5513291358947754
Validation loss: 2.3076709419168453

Epoch: 5| Step: 5
Training loss: 2.199496269226074
Validation loss: 2.3132443171675487

Epoch: 5| Step: 6
Training loss: 2.282555103302002
Validation loss: 2.3139524459838867

Epoch: 5| Step: 7
Training loss: 2.6832950115203857
Validation loss: 2.304037013361531

Epoch: 5| Step: 8
Training loss: 2.537468910217285
Validation loss: 2.297014351814024

Epoch: 5| Step: 9
Training loss: 3.0686423778533936
Validation loss: 2.2920529304012174

Epoch: 5| Step: 10
Training loss: 2.9506900310516357
Validation loss: 2.292436238258116

Epoch: 91| Step: 0
Training loss: 2.5792698860168457
Validation loss: 2.290045643365511

Epoch: 5| Step: 1
Training loss: 2.229647159576416
Validation loss: 2.286486634644129

Epoch: 5| Step: 2
Training loss: 2.34775972366333
Validation loss: 2.2905866151214926

Epoch: 5| Step: 3
Training loss: 2.946770429611206
Validation loss: 2.288030542353148

Epoch: 5| Step: 4
Training loss: 2.402740001678467
Validation loss: 2.289133587191182

Epoch: 5| Step: 5
Training loss: 2.8801989555358887
Validation loss: 2.297325970024191

Epoch: 5| Step: 6
Training loss: 2.5281620025634766
Validation loss: 2.30793002856675

Epoch: 5| Step: 7
Training loss: 2.4633593559265137
Validation loss: 2.3133736272012033

Epoch: 5| Step: 8
Training loss: 3.1437177658081055
Validation loss: 2.3173256894593597

Epoch: 5| Step: 9
Training loss: 1.8976974487304688
Validation loss: 2.308365939765848

Epoch: 5| Step: 10
Training loss: 2.7457284927368164
Validation loss: 2.3124304715023247

Epoch: 92| Step: 0
Training loss: 2.1284067630767822
Validation loss: 2.305975083381899

Epoch: 5| Step: 1
Training loss: 2.7824878692626953
Validation loss: 2.305034816906016

Epoch: 5| Step: 2
Training loss: 2.2181766033172607
Validation loss: 2.2990502221609956

Epoch: 5| Step: 3
Training loss: 2.430691957473755
Validation loss: 2.3006998364643385

Epoch: 5| Step: 4
Training loss: 2.3029370307922363
Validation loss: 2.300664835078742

Epoch: 5| Step: 5
Training loss: 2.6570446491241455
Validation loss: 2.3040282777560654

Epoch: 5| Step: 6
Training loss: 2.27398419380188
Validation loss: 2.3145224637882684

Epoch: 5| Step: 7
Training loss: 2.778480052947998
Validation loss: 2.3214932154583674

Epoch: 5| Step: 8
Training loss: 2.523191452026367
Validation loss: 2.31327288381515

Epoch: 5| Step: 9
Training loss: 2.9774909019470215
Validation loss: 2.3019005073014127

Epoch: 5| Step: 10
Training loss: 3.18391489982605
Validation loss: 2.296955152224469

Epoch: 93| Step: 0
Training loss: 2.5418167114257812
Validation loss: 2.2917665691785913

Epoch: 5| Step: 1
Training loss: 1.9320719242095947
Validation loss: 2.292252330369847

Epoch: 5| Step: 2
Training loss: 2.699632167816162
Validation loss: 2.295596632906186

Epoch: 5| Step: 3
Training loss: 2.6283092498779297
Validation loss: 2.3050936909132105

Epoch: 5| Step: 4
Training loss: 2.555630922317505
Validation loss: 2.31582220139042

Epoch: 5| Step: 5
Training loss: 2.7173237800598145
Validation loss: 2.323882090148105

Epoch: 5| Step: 6
Training loss: 2.2151377201080322
Validation loss: 2.3316308862419537

Epoch: 5| Step: 7
Training loss: 2.454192638397217
Validation loss: 2.289471290444815

Epoch: 5| Step: 8
Training loss: 2.992997884750366
Validation loss: 2.2837077622772544

Epoch: 5| Step: 9
Training loss: 2.7809605598449707
Validation loss: 2.28299464461624

Epoch: 5| Step: 10
Training loss: 2.513362169265747
Validation loss: 2.2801196190618698

Epoch: 94| Step: 0
Training loss: 2.4740214347839355
Validation loss: 2.28612337317518

Epoch: 5| Step: 1
Training loss: 3.1164698600769043
Validation loss: 2.286103520342099

Epoch: 5| Step: 2
Training loss: 2.2157504558563232
Validation loss: 2.2832689464733167

Epoch: 5| Step: 3
Training loss: 2.4790847301483154
Validation loss: 2.275699523187453

Epoch: 5| Step: 4
Training loss: 2.090304136276245
Validation loss: 2.2733937565998366

Epoch: 5| Step: 5
Training loss: 3.0588269233703613
Validation loss: 2.27679778170842

Epoch: 5| Step: 6
Training loss: 3.006267786026001
Validation loss: 2.291547126667474

Epoch: 5| Step: 7
Training loss: 2.5677924156188965
Validation loss: 2.3031464827957975

Epoch: 5| Step: 8
Training loss: 2.213737964630127
Validation loss: 2.306482083053999

Epoch: 5| Step: 9
Training loss: 2.2901968955993652
Validation loss: 2.307429959697108

Epoch: 5| Step: 10
Training loss: 2.604365110397339
Validation loss: 2.282950528206364

Epoch: 95| Step: 0
Training loss: 2.285604238510132
Validation loss: 2.2694804155698387

Epoch: 5| Step: 1
Training loss: 2.493842124938965
Validation loss: 2.2684791190649873

Epoch: 5| Step: 2
Training loss: 2.1207878589630127
Validation loss: 2.2681643527041198

Epoch: 5| Step: 3
Training loss: 2.3337159156799316
Validation loss: 2.2659834405427337

Epoch: 5| Step: 4
Training loss: 2.7760848999023438
Validation loss: 2.274234205163935

Epoch: 5| Step: 5
Training loss: 3.067476511001587
Validation loss: 2.274954157490884

Epoch: 5| Step: 6
Training loss: 2.7138638496398926
Validation loss: 2.276463390678488

Epoch: 5| Step: 7
Training loss: 2.0406410694122314
Validation loss: 2.285078920343871

Epoch: 5| Step: 8
Training loss: 2.9420199394226074
Validation loss: 2.297930622613558

Epoch: 5| Step: 9
Training loss: 2.5458874702453613
Validation loss: 2.283193903584634

Epoch: 5| Step: 10
Training loss: 2.568533182144165
Validation loss: 2.269584676270844

Epoch: 96| Step: 0
Training loss: 2.547661781311035
Validation loss: 2.2645487259793025

Epoch: 5| Step: 1
Training loss: 2.2880680561065674
Validation loss: 2.267260874471357

Epoch: 5| Step: 2
Training loss: 2.761397123336792
Validation loss: 2.263949603162786

Epoch: 5| Step: 3
Training loss: 2.2205405235290527
Validation loss: 2.2543933865844563

Epoch: 5| Step: 4
Training loss: 2.541421890258789
Validation loss: 2.259825914136825

Epoch: 5| Step: 5
Training loss: 2.692627429962158
Validation loss: 2.260734486323531

Epoch: 5| Step: 6
Training loss: 2.1175856590270996
Validation loss: 2.266652745585288

Epoch: 5| Step: 7
Training loss: 2.6480655670166016
Validation loss: 2.2762227673684396

Epoch: 5| Step: 8
Training loss: 2.864377498626709
Validation loss: 2.3125644524892173

Epoch: 5| Step: 9
Training loss: 3.1376736164093018
Validation loss: 2.3382000230973765

Epoch: 5| Step: 10
Training loss: 2.043544054031372
Validation loss: 2.340752186313752

Epoch: 97| Step: 0
Training loss: 2.2855308055877686
Validation loss: 2.2965338973588842

Epoch: 5| Step: 1
Training loss: 2.0754482746124268
Validation loss: 2.2717747726748065

Epoch: 5| Step: 2
Training loss: 2.5078330039978027
Validation loss: 2.259646395201324

Epoch: 5| Step: 3
Training loss: 2.345557689666748
Validation loss: 2.256304294832291

Epoch: 5| Step: 4
Training loss: 2.7352964878082275
Validation loss: 2.2574984796585573

Epoch: 5| Step: 5
Training loss: 2.6394364833831787
Validation loss: 2.2576031787421114

Epoch: 5| Step: 6
Training loss: 3.2291438579559326
Validation loss: 2.2597470821872836

Epoch: 5| Step: 7
Training loss: 2.927396774291992
Validation loss: 2.2536436562897055

Epoch: 5| Step: 8
Training loss: 2.1398231983184814
Validation loss: 2.2560322874335834

Epoch: 5| Step: 9
Training loss: 2.2161755561828613
Validation loss: 2.259321117913851

Epoch: 5| Step: 10
Training loss: 2.6804752349853516
Validation loss: 2.2775881469890638

Epoch: 98| Step: 0
Training loss: 2.8846516609191895
Validation loss: 2.2858809809530936

Epoch: 5| Step: 1
Training loss: 2.2420473098754883
Validation loss: 2.303652089129212

Epoch: 5| Step: 2
Training loss: 2.269230842590332
Validation loss: 2.3084803063382386

Epoch: 5| Step: 3
Training loss: 2.4208168983459473
Validation loss: 2.303171193727883

Epoch: 5| Step: 4
Training loss: 2.4537951946258545
Validation loss: 2.297704986346665

Epoch: 5| Step: 5
Training loss: 2.5804786682128906
Validation loss: 2.279075030357607

Epoch: 5| Step: 6
Training loss: 2.56719708442688
Validation loss: 2.268297254398305

Epoch: 5| Step: 7
Training loss: 2.460590362548828
Validation loss: 2.255503526297949

Epoch: 5| Step: 8
Training loss: 2.3694851398468018
Validation loss: 2.2493781146182807

Epoch: 5| Step: 9
Training loss: 2.792647123336792
Validation loss: 2.2428751786549888

Epoch: 5| Step: 10
Training loss: 2.768821954727173
Validation loss: 2.243273186427291

Epoch: 99| Step: 0
Training loss: 2.7455906867980957
Validation loss: 2.254557794140231

Epoch: 5| Step: 1
Training loss: 2.934345245361328
Validation loss: 2.248082245549848

Epoch: 5| Step: 2
Training loss: 1.9367440938949585
Validation loss: 2.2411653713513444

Epoch: 5| Step: 3
Training loss: 1.7235809564590454
Validation loss: 2.249908031955842

Epoch: 5| Step: 4
Training loss: 2.783247709274292
Validation loss: 2.2775428474590345

Epoch: 5| Step: 5
Training loss: 2.802489757537842
Validation loss: 2.321329475730978

Epoch: 5| Step: 6
Training loss: 2.584890842437744
Validation loss: 2.364550341841995

Epoch: 5| Step: 7
Training loss: 2.845106363296509
Validation loss: 2.4109279776132233

Epoch: 5| Step: 8
Training loss: 2.6352078914642334
Validation loss: 2.38459498523384

Epoch: 5| Step: 9
Training loss: 2.6588597297668457
Validation loss: 2.3255209102425525

Epoch: 5| Step: 10
Training loss: 2.400927782058716
Validation loss: 2.264259115342171

Epoch: 100| Step: 0
Training loss: 2.579932928085327
Validation loss: 2.2442789744305354

Epoch: 5| Step: 1
Training loss: 2.410062313079834
Validation loss: 2.2340472949448453

Epoch: 5| Step: 2
Training loss: 2.258479356765747
Validation loss: 2.235653467075799

Epoch: 5| Step: 3
Training loss: 2.433342456817627
Validation loss: 2.236971137344196

Epoch: 5| Step: 4
Training loss: 2.6309866905212402
Validation loss: 2.2425247187255533

Epoch: 5| Step: 5
Training loss: 2.528993606567383
Validation loss: 2.2405535790228073

Epoch: 5| Step: 6
Training loss: 2.8563637733459473
Validation loss: 2.245379629955497

Epoch: 5| Step: 7
Training loss: 2.907153606414795
Validation loss: 2.238690091717628

Epoch: 5| Step: 8
Training loss: 2.6506428718566895
Validation loss: 2.2363869784980692

Epoch: 5| Step: 9
Training loss: 2.675532341003418
Validation loss: 2.2317057783885668

Epoch: 5| Step: 10
Training loss: 1.9880914688110352
Validation loss: 2.2246881736222135

Epoch: 101| Step: 0
Training loss: 2.7245075702667236
Validation loss: 2.229480460125913

Epoch: 5| Step: 1
Training loss: 2.20361065864563
Validation loss: 2.2393917114503923

Epoch: 5| Step: 2
Training loss: 2.502307415008545
Validation loss: 2.247308172205443

Epoch: 5| Step: 3
Training loss: 2.655559778213501
Validation loss: 2.2583780686060586

Epoch: 5| Step: 4
Training loss: 2.062433958053589
Validation loss: 2.253585215537779

Epoch: 5| Step: 5
Training loss: 2.6496338844299316
Validation loss: 2.2490871849880425

Epoch: 5| Step: 6
Training loss: 2.5030524730682373
Validation loss: 2.2675663937804518

Epoch: 5| Step: 7
Training loss: 2.235426664352417
Validation loss: 2.258132193678169

Epoch: 5| Step: 8
Training loss: 2.583472967147827
Validation loss: 2.262744975346391

Epoch: 5| Step: 9
Training loss: 2.502530097961426
Validation loss: 2.261462987110179

Epoch: 5| Step: 10
Training loss: 3.1302318572998047
Validation loss: 2.241095586489606

Epoch: 102| Step: 0
Training loss: 2.3084847927093506
Validation loss: 2.2368687865554646

Epoch: 5| Step: 1
Training loss: 2.961989641189575
Validation loss: 2.225684537682482

Epoch: 5| Step: 2
Training loss: 2.7506299018859863
Validation loss: 2.222879107280444

Epoch: 5| Step: 3
Training loss: 2.17964243888855
Validation loss: 2.2233188793223393

Epoch: 5| Step: 4
Training loss: 2.393834114074707
Validation loss: 2.2226202282854306

Epoch: 5| Step: 5
Training loss: 2.5650978088378906
Validation loss: 2.220326610790786

Epoch: 5| Step: 6
Training loss: 1.8533260822296143
Validation loss: 2.2230427906077397

Epoch: 5| Step: 7
Training loss: 3.0040555000305176
Validation loss: 2.2337541528927383

Epoch: 5| Step: 8
Training loss: 2.5804641246795654
Validation loss: 2.2307472305913127

Epoch: 5| Step: 9
Training loss: 2.3864808082580566
Validation loss: 2.251562149293961

Epoch: 5| Step: 10
Training loss: 2.7800557613372803
Validation loss: 2.248315659902429

Epoch: 103| Step: 0
Training loss: 2.958472967147827
Validation loss: 2.242794668802651

Epoch: 5| Step: 1
Training loss: 3.1052374839782715
Validation loss: 2.2474248281089206

Epoch: 5| Step: 2
Training loss: 2.0709383487701416
Validation loss: 2.2258090934445782

Epoch: 5| Step: 3
Training loss: 2.6914515495300293
Validation loss: 2.210710928004275

Epoch: 5| Step: 4
Training loss: 2.5219569206237793
Validation loss: 2.2080249350558043

Epoch: 5| Step: 5
Training loss: 2.0369114875793457
Validation loss: 2.207891925688713

Epoch: 5| Step: 6
Training loss: 2.1020920276641846
Validation loss: 2.208885424880571

Epoch: 5| Step: 7
Training loss: 2.582592010498047
Validation loss: 2.2063687245051065

Epoch: 5| Step: 8
Training loss: 2.2254300117492676
Validation loss: 2.2028251540276313

Epoch: 5| Step: 9
Training loss: 2.4171881675720215
Validation loss: 2.203755091595393

Epoch: 5| Step: 10
Training loss: 3.073221206665039
Validation loss: 2.202883581961355

Epoch: 104| Step: 0
Training loss: 2.934584140777588
Validation loss: 2.2032258408043974

Epoch: 5| Step: 1
Training loss: 2.0840954780578613
Validation loss: 2.20960848305815

Epoch: 5| Step: 2
Training loss: 2.764561414718628
Validation loss: 2.2084412600404475

Epoch: 5| Step: 3
Training loss: 2.2564451694488525
Validation loss: 2.2187532378781225

Epoch: 5| Step: 4
Training loss: 1.8406257629394531
Validation loss: 2.2290480880327124

Epoch: 5| Step: 5
Training loss: 2.2600064277648926
Validation loss: 2.244641575762021

Epoch: 5| Step: 6
Training loss: 2.859154224395752
Validation loss: 2.284089797286577

Epoch: 5| Step: 7
Training loss: 2.2927298545837402
Validation loss: 2.261230730241345

Epoch: 5| Step: 8
Training loss: 2.583451509475708
Validation loss: 2.2258503642133487

Epoch: 5| Step: 9
Training loss: 2.8946187496185303
Validation loss: 2.2130256058067403

Epoch: 5| Step: 10
Training loss: 2.785223960876465
Validation loss: 2.206224133891444

Epoch: 105| Step: 0
Training loss: 1.8043102025985718
Validation loss: 2.2053431182779293

Epoch: 5| Step: 1
Training loss: 3.163278102874756
Validation loss: 2.207453394448885

Epoch: 5| Step: 2
Training loss: 2.7940404415130615
Validation loss: 2.2112934499658565

Epoch: 5| Step: 3
Training loss: 2.880781888961792
Validation loss: 2.213618947613624

Epoch: 5| Step: 4
Training loss: 2.4450440406799316
Validation loss: 2.2122334690504175

Epoch: 5| Step: 5
Training loss: 2.225954532623291
Validation loss: 2.217681928347516

Epoch: 5| Step: 6
Training loss: 3.017946243286133
Validation loss: 2.214898145327004

Epoch: 5| Step: 7
Training loss: 2.2053849697113037
Validation loss: 2.205303640775783

Epoch: 5| Step: 8
Training loss: 2.485574960708618
Validation loss: 2.208668884410653

Epoch: 5| Step: 9
Training loss: 2.3654608726501465
Validation loss: 2.2119305313274427

Epoch: 5| Step: 10
Training loss: 2.2174720764160156
Validation loss: 2.2113161753582697

Epoch: 106| Step: 0
Training loss: 2.3698699474334717
Validation loss: 2.2192822028231878

Epoch: 5| Step: 1
Training loss: 2.5138511657714844
Validation loss: 2.2418019079392955

Epoch: 5| Step: 2
Training loss: 2.6481926441192627
Validation loss: 2.269437743771461

Epoch: 5| Step: 3
Training loss: 2.2962398529052734
Validation loss: 2.29456651595331

Epoch: 5| Step: 4
Training loss: 3.016655206680298
Validation loss: 2.315911090502175

Epoch: 5| Step: 5
Training loss: 2.0970778465270996
Validation loss: 2.324165157092515

Epoch: 5| Step: 6
Training loss: 3.088639974594116
Validation loss: 2.317741301751906

Epoch: 5| Step: 7
Training loss: 2.19465970993042
Validation loss: 2.296514989227377

Epoch: 5| Step: 8
Training loss: 2.465670347213745
Validation loss: 2.229548413266418

Epoch: 5| Step: 9
Training loss: 2.3769829273223877
Validation loss: 2.1981419952966834

Epoch: 5| Step: 10
Training loss: 2.5326480865478516
Validation loss: 2.1910545595230593

Epoch: 107| Step: 0
Training loss: 2.4492132663726807
Validation loss: 2.196669199133432

Epoch: 5| Step: 1
Training loss: 2.4876961708068848
Validation loss: 2.1962130479915167

Epoch: 5| Step: 2
Training loss: 2.7198379039764404
Validation loss: 2.2042846192595777

Epoch: 5| Step: 3
Training loss: 2.6856024265289307
Validation loss: 2.208542628954816

Epoch: 5| Step: 4
Training loss: 2.99916410446167
Validation loss: 2.2340918228190434

Epoch: 5| Step: 5
Training loss: 2.610028028488159
Validation loss: 2.2647289511977986

Epoch: 5| Step: 6
Training loss: 1.655991554260254
Validation loss: 2.300667275664627

Epoch: 5| Step: 7
Training loss: 2.43483829498291
Validation loss: 2.3097590349053823

Epoch: 5| Step: 8
Training loss: 2.423208236694336
Validation loss: 2.3131978639992337

Epoch: 5| Step: 9
Training loss: 3.027381181716919
Validation loss: 2.322463768784718

Epoch: 5| Step: 10
Training loss: 2.1512815952301025
Validation loss: 2.296610750177855

Epoch: 108| Step: 0
Training loss: 2.8530640602111816
Validation loss: 2.2540148919628513

Epoch: 5| Step: 1
Training loss: 2.8768727779388428
Validation loss: 2.228540881987541

Epoch: 5| Step: 2
Training loss: 2.283344268798828
Validation loss: 2.2195209303209857

Epoch: 5| Step: 3
Training loss: 2.186466932296753
Validation loss: 2.2091776171038227

Epoch: 5| Step: 4
Training loss: 2.4084274768829346
Validation loss: 2.193746557799719

Epoch: 5| Step: 5
Training loss: 2.0811564922332764
Validation loss: 2.1960326202454103

Epoch: 5| Step: 6
Training loss: 2.386152744293213
Validation loss: 2.2054493042730514

Epoch: 5| Step: 7
Training loss: 2.298283815383911
Validation loss: 2.2107070735705796

Epoch: 5| Step: 8
Training loss: 3.2591145038604736
Validation loss: 2.225000335324195

Epoch: 5| Step: 9
Training loss: 2.2441768646240234
Validation loss: 2.21858077151801

Epoch: 5| Step: 10
Training loss: 2.471954822540283
Validation loss: 2.2177674565263974

Epoch: 109| Step: 0
Training loss: 2.2357707023620605
Validation loss: 2.203417665214949

Epoch: 5| Step: 1
Training loss: 2.4809696674346924
Validation loss: 2.1974237811180855

Epoch: 5| Step: 2
Training loss: 2.4288957118988037
Validation loss: 2.204818207730529

Epoch: 5| Step: 3
Training loss: 2.3246331214904785
Validation loss: 2.2078244173398582

Epoch: 5| Step: 4
Training loss: 2.156165599822998
Validation loss: 2.20102507580993

Epoch: 5| Step: 5
Training loss: 2.3704843521118164
Validation loss: 2.2120960040759017

Epoch: 5| Step: 6
Training loss: 2.9973933696746826
Validation loss: 2.2112179981764926

Epoch: 5| Step: 7
Training loss: 2.4593594074249268
Validation loss: 2.194656491279602

Epoch: 5| Step: 8
Training loss: 2.6376757621765137
Validation loss: 2.19275672717761

Epoch: 5| Step: 9
Training loss: 2.545902967453003
Validation loss: 2.1831505913888254

Epoch: 5| Step: 10
Training loss: 2.6608169078826904
Validation loss: 2.1822533671573927

Epoch: 110| Step: 0
Training loss: 2.461205244064331
Validation loss: 2.1747291959742063

Epoch: 5| Step: 1
Training loss: 2.6922221183776855
Validation loss: 2.173310443919192

Epoch: 5| Step: 2
Training loss: 2.169198989868164
Validation loss: 2.1747894876746723

Epoch: 5| Step: 3
Training loss: 2.33597469329834
Validation loss: 2.1787527325332805

Epoch: 5| Step: 4
Training loss: 2.724621295928955
Validation loss: 2.186086295753397

Epoch: 5| Step: 5
Training loss: 2.4639811515808105
Validation loss: 2.1877862458587973

Epoch: 5| Step: 6
Training loss: 2.0673203468322754
Validation loss: 2.194113682675105

Epoch: 5| Step: 7
Training loss: 2.6231560707092285
Validation loss: 2.204461395099599

Epoch: 5| Step: 8
Training loss: 2.3816170692443848
Validation loss: 2.205586423156082

Epoch: 5| Step: 9
Training loss: 2.7254323959350586
Validation loss: 2.2028212726757093

Epoch: 5| Step: 10
Training loss: 2.653904914855957
Validation loss: 2.2001314111935195

Epoch: 111| Step: 0
Training loss: 2.613312244415283
Validation loss: 2.1927680700056014

Epoch: 5| Step: 1
Training loss: 2.6177725791931152
Validation loss: 2.190170762359455

Epoch: 5| Step: 2
Training loss: 1.890435814857483
Validation loss: 2.187162871001869

Epoch: 5| Step: 3
Training loss: 1.911635160446167
Validation loss: 2.179461722732872

Epoch: 5| Step: 4
Training loss: 2.552839994430542
Validation loss: 2.186535058483001

Epoch: 5| Step: 5
Training loss: 1.8460066318511963
Validation loss: 2.1897774588677192

Epoch: 5| Step: 6
Training loss: 2.606064558029175
Validation loss: 2.1796141029686056

Epoch: 5| Step: 7
Training loss: 2.7971107959747314
Validation loss: 2.1772596079816102

Epoch: 5| Step: 8
Training loss: 2.718498945236206
Validation loss: 2.1716399526083343

Epoch: 5| Step: 9
Training loss: 2.8272769451141357
Validation loss: 2.163281315116472

Epoch: 5| Step: 10
Training loss: 2.7207579612731934
Validation loss: 2.159607985968231

Epoch: 112| Step: 0
Training loss: 1.7657392024993896
Validation loss: 2.158891370219569

Epoch: 5| Step: 1
Training loss: 2.0165762901306152
Validation loss: 2.164529426123506

Epoch: 5| Step: 2
Training loss: 2.6714060306549072
Validation loss: 2.1684680497774513

Epoch: 5| Step: 3
Training loss: 2.5398974418640137
Validation loss: 2.193282358108028

Epoch: 5| Step: 4
Training loss: 2.4830546379089355
Validation loss: 2.1975323666808424

Epoch: 5| Step: 5
Training loss: 2.5990047454833984
Validation loss: 2.195231404355777

Epoch: 5| Step: 6
Training loss: 2.1387057304382324
Validation loss: 2.1717423033970658

Epoch: 5| Step: 7
Training loss: 2.246967077255249
Validation loss: 2.1641038592143724

Epoch: 5| Step: 8
Training loss: 3.072218418121338
Validation loss: 2.160924273152505

Epoch: 5| Step: 9
Training loss: 3.0399460792541504
Validation loss: 2.153315442864613

Epoch: 5| Step: 10
Training loss: 2.445563554763794
Validation loss: 2.1556302578218522

Epoch: 113| Step: 0
Training loss: 2.743338108062744
Validation loss: 2.1516020144185712

Epoch: 5| Step: 1
Training loss: 2.6719555854797363
Validation loss: 2.1475410948517504

Epoch: 5| Step: 2
Training loss: 2.1379642486572266
Validation loss: 2.1499602307555494

Epoch: 5| Step: 3
Training loss: 2.173287868499756
Validation loss: 2.151470358653735

Epoch: 5| Step: 4
Training loss: 2.625572919845581
Validation loss: 2.154711138817572

Epoch: 5| Step: 5
Training loss: 1.9853626489639282
Validation loss: 2.16043835045189

Epoch: 5| Step: 6
Training loss: 2.6465489864349365
Validation loss: 2.176901569930456

Epoch: 5| Step: 7
Training loss: 2.7019004821777344
Validation loss: 2.2052626122710524

Epoch: 5| Step: 8
Training loss: 2.122727632522583
Validation loss: 2.2511465036740868

Epoch: 5| Step: 9
Training loss: 2.2626328468322754
Validation loss: 2.2613550693758073

Epoch: 5| Step: 10
Training loss: 3.1430978775024414
Validation loss: 2.253828158942602

Epoch: 114| Step: 0
Training loss: 3.0654003620147705
Validation loss: 2.2377410152907014

Epoch: 5| Step: 1
Training loss: 2.1446595191955566
Validation loss: 2.189363815451181

Epoch: 5| Step: 2
Training loss: 2.7074503898620605
Validation loss: 2.171171142208961

Epoch: 5| Step: 3
Training loss: 2.614009141921997
Validation loss: 2.1567922740854244

Epoch: 5| Step: 4
Training loss: 2.6136221885681152
Validation loss: 2.1563410464153496

Epoch: 5| Step: 5
Training loss: 2.6179840564727783
Validation loss: 2.157657633545578

Epoch: 5| Step: 6
Training loss: 2.0418078899383545
Validation loss: 2.161203170335421

Epoch: 5| Step: 7
Training loss: 2.3022334575653076
Validation loss: 2.155945019055438

Epoch: 5| Step: 8
Training loss: 2.3367648124694824
Validation loss: 2.154369833648846

Epoch: 5| Step: 9
Training loss: 2.414877414703369
Validation loss: 2.1585789470262426

Epoch: 5| Step: 10
Training loss: 2.3935163021087646
Validation loss: 2.1581448970302457

Epoch: 115| Step: 0
Training loss: 2.770040988922119
Validation loss: 2.156151040907829

Epoch: 5| Step: 1
Training loss: 2.691394090652466
Validation loss: 2.1598363845579085

Epoch: 5| Step: 2
Training loss: 2.320113182067871
Validation loss: 2.160426566677709

Epoch: 5| Step: 3
Training loss: 2.216728925704956
Validation loss: 2.1672340157211467

Epoch: 5| Step: 4
Training loss: 2.5560827255249023
Validation loss: 2.1713853702750257

Epoch: 5| Step: 5
Training loss: 2.737091302871704
Validation loss: 2.1644023003116732

Epoch: 5| Step: 6
Training loss: 2.419529914855957
Validation loss: 2.152017967675322

Epoch: 5| Step: 7
Training loss: 2.108539581298828
Validation loss: 2.15249450232393

Epoch: 5| Step: 8
Training loss: 2.6416192054748535
Validation loss: 2.1533926161386634

Epoch: 5| Step: 9
Training loss: 2.0473411083221436
Validation loss: 2.1488096867838213

Epoch: 5| Step: 10
Training loss: 2.3702666759490967
Validation loss: 2.1469953777969524

Epoch: 116| Step: 0
Training loss: 2.2871623039245605
Validation loss: 2.148115168335617

Epoch: 5| Step: 1
Training loss: 2.2325546741485596
Validation loss: 2.1470988873512513

Epoch: 5| Step: 2
Training loss: 2.4155843257904053
Validation loss: 2.146899095145605

Epoch: 5| Step: 3
Training loss: 2.905879497528076
Validation loss: 2.1471107749528784

Epoch: 5| Step: 4
Training loss: 2.5706050395965576
Validation loss: 2.1429007309739307

Epoch: 5| Step: 5
Training loss: 2.9881701469421387
Validation loss: 2.150147455994801

Epoch: 5| Step: 6
Training loss: 2.154014825820923
Validation loss: 2.1310154391873266

Epoch: 5| Step: 7
Training loss: 2.229356527328491
Validation loss: 2.139459345930366

Epoch: 5| Step: 8
Training loss: 2.487067461013794
Validation loss: 2.1304174546272523

Epoch: 5| Step: 9
Training loss: 2.0128121376037598
Validation loss: 2.12699806562034

Epoch: 5| Step: 10
Training loss: 2.4956767559051514
Validation loss: 2.13004921713183

Epoch: 117| Step: 0
Training loss: 2.820465564727783
Validation loss: 2.1305258786806496

Epoch: 5| Step: 1
Training loss: 2.179469347000122
Validation loss: 2.1355076015636487

Epoch: 5| Step: 2
Training loss: 2.7513957023620605
Validation loss: 2.1346336423709826

Epoch: 5| Step: 3
Training loss: 2.677640914916992
Validation loss: 2.134415506034769

Epoch: 5| Step: 4
Training loss: 2.0812888145446777
Validation loss: 2.1372492133930163

Epoch: 5| Step: 5
Training loss: 2.826667308807373
Validation loss: 2.133989700707056

Epoch: 5| Step: 6
Training loss: 2.2813773155212402
Validation loss: 2.143849601027786

Epoch: 5| Step: 7
Training loss: 2.9151344299316406
Validation loss: 2.1417552591652

Epoch: 5| Step: 8
Training loss: 2.446460008621216
Validation loss: 2.1460278521301928

Epoch: 5| Step: 9
Training loss: 1.931213140487671
Validation loss: 2.1364091339931695

Epoch: 5| Step: 10
Training loss: 1.66933012008667
Validation loss: 2.1334458192189536

Epoch: 118| Step: 0
Training loss: 2.257713794708252
Validation loss: 2.12634939019398

Epoch: 5| Step: 1
Training loss: 1.9782893657684326
Validation loss: 2.1290996356676986

Epoch: 5| Step: 2
Training loss: 2.5756630897521973
Validation loss: 2.1273568791727864

Epoch: 5| Step: 3
Training loss: 2.8293609619140625
Validation loss: 2.1277302952222925

Epoch: 5| Step: 4
Training loss: 2.8613314628601074
Validation loss: 2.1249109006697133

Epoch: 5| Step: 5
Training loss: 2.1048331260681152
Validation loss: 2.122186348002444

Epoch: 5| Step: 6
Training loss: 2.447650194168091
Validation loss: 2.1247066349111576

Epoch: 5| Step: 7
Training loss: 2.36067533493042
Validation loss: 2.1200600106229066

Epoch: 5| Step: 8
Training loss: 2.0828473567962646
Validation loss: 2.1269482105009017

Epoch: 5| Step: 9
Training loss: 2.6451468467712402
Validation loss: 2.1308980923826977

Epoch: 5| Step: 10
Training loss: 2.6175267696380615
Validation loss: 2.1475648559549803

Epoch: 119| Step: 0
Training loss: 1.5232220888137817
Validation loss: 2.144716660181681

Epoch: 5| Step: 1
Training loss: 2.603855848312378
Validation loss: 2.140629078752251

Epoch: 5| Step: 2
Training loss: 2.4776833057403564
Validation loss: 2.1317420262162403

Epoch: 5| Step: 3
Training loss: 3.0259995460510254
Validation loss: 2.130377810488465

Epoch: 5| Step: 4
Training loss: 2.7423415184020996
Validation loss: 2.1316238782739125

Epoch: 5| Step: 5
Training loss: 2.273210048675537
Validation loss: 2.130540919560258

Epoch: 5| Step: 6
Training loss: 2.2818562984466553
Validation loss: 2.127887031083466

Epoch: 5| Step: 7
Training loss: 2.285048723220825
Validation loss: 2.135181168074249

Epoch: 5| Step: 8
Training loss: 1.8707849979400635
Validation loss: 2.1335417198878464

Epoch: 5| Step: 9
Training loss: 2.801708936691284
Validation loss: 2.1336907776453162

Epoch: 5| Step: 10
Training loss: 2.8278491497039795
Validation loss: 2.141778484467537

Epoch: 120| Step: 0
Training loss: 2.780153751373291
Validation loss: 2.1453299804400374

Epoch: 5| Step: 1
Training loss: 1.988080620765686
Validation loss: 2.1515502211868123

Epoch: 5| Step: 2
Training loss: 2.6570773124694824
Validation loss: 2.1479737989364134

Epoch: 5| Step: 3
Training loss: 3.1092281341552734
Validation loss: 2.152532051968318

Epoch: 5| Step: 4
Training loss: 2.1817708015441895
Validation loss: 2.1411306063334146

Epoch: 5| Step: 5
Training loss: 2.152024745941162
Validation loss: 2.1417737827506116

Epoch: 5| Step: 6
Training loss: 2.1392807960510254
Validation loss: 2.1411463675960416

Epoch: 5| Step: 7
Training loss: 2.6394081115722656
Validation loss: 2.1341822788279545

Epoch: 5| Step: 8
Training loss: 2.5266849994659424
Validation loss: 2.1306863600207913

Epoch: 5| Step: 9
Training loss: 2.289930820465088
Validation loss: 2.143843694399762

Epoch: 5| Step: 10
Training loss: 2.1824982166290283
Validation loss: 2.1427199558545182

Epoch: 121| Step: 0
Training loss: 2.375621795654297
Validation loss: 2.1290619142593874

Epoch: 5| Step: 1
Training loss: 2.0436489582061768
Validation loss: 2.1345438752123105

Epoch: 5| Step: 2
Training loss: 2.1023402214050293
Validation loss: 2.1285338811976935

Epoch: 5| Step: 3
Training loss: 2.40954327583313
Validation loss: 2.1386581851590063

Epoch: 5| Step: 4
Training loss: 2.500246524810791
Validation loss: 2.123155386217179

Epoch: 5| Step: 5
Training loss: 2.2129173278808594
Validation loss: 2.1213927679164435

Epoch: 5| Step: 6
Training loss: 2.5995609760284424
Validation loss: 2.118282843661565

Epoch: 5| Step: 7
Training loss: 2.280756950378418
Validation loss: 2.1136437103312504

Epoch: 5| Step: 8
Training loss: 2.5066983699798584
Validation loss: 2.113221392836622

Epoch: 5| Step: 9
Training loss: 2.6702678203582764
Validation loss: 2.1137835428278935

Epoch: 5| Step: 10
Training loss: 2.8877763748168945
Validation loss: 2.1252867867869716

Epoch: 122| Step: 0
Training loss: 2.469733476638794
Validation loss: 2.142183265378398

Epoch: 5| Step: 1
Training loss: 2.617560625076294
Validation loss: 2.1434427974044636

Epoch: 5| Step: 2
Training loss: 1.6463098526000977
Validation loss: 2.1184702060555898

Epoch: 5| Step: 3
Training loss: 2.626007080078125
Validation loss: 2.1126339127940517

Epoch: 5| Step: 4
Training loss: 2.591032028198242
Validation loss: 2.1144763551732546

Epoch: 5| Step: 5
Training loss: 2.503774881362915
Validation loss: 2.11080438347273

Epoch: 5| Step: 6
Training loss: 2.3677468299865723
Validation loss: 2.1055198254123813

Epoch: 5| Step: 7
Training loss: 1.9874998331069946
Validation loss: 2.1139931255771267

Epoch: 5| Step: 8
Training loss: 2.8498165607452393
Validation loss: 2.126388967678111

Epoch: 5| Step: 9
Training loss: 2.5996527671813965
Validation loss: 2.138743555673989

Epoch: 5| Step: 10
Training loss: 2.530834913253784
Validation loss: 2.1365784996299335

Epoch: 123| Step: 0
Training loss: 2.524817705154419
Validation loss: 2.1564760669585197

Epoch: 5| Step: 1
Training loss: 2.439136028289795
Validation loss: 2.1701624675463607

Epoch: 5| Step: 2
Training loss: 2.2716336250305176
Validation loss: 2.1804698385218138

Epoch: 5| Step: 3
Training loss: 2.2288401126861572
Validation loss: 2.1591348109706754

Epoch: 5| Step: 4
Training loss: 2.0714077949523926
Validation loss: 2.138038803172368

Epoch: 5| Step: 5
Training loss: 2.4041965007781982
Validation loss: 2.1272646406645417

Epoch: 5| Step: 6
Training loss: 2.509827136993408
Validation loss: 2.113246283223552

Epoch: 5| Step: 7
Training loss: 2.78783917427063
Validation loss: 2.1057495429951656

Epoch: 5| Step: 8
Training loss: 2.104724645614624
Validation loss: 2.099419552792785

Epoch: 5| Step: 9
Training loss: 3.018639087677002
Validation loss: 2.101526765413182

Epoch: 5| Step: 10
Training loss: 2.2215516567230225
Validation loss: 2.0992631553321757

Epoch: 124| Step: 0
Training loss: 2.626096248626709
Validation loss: 2.0961282509629444

Epoch: 5| Step: 1
Training loss: 2.40132212638855
Validation loss: 2.094343021351804

Epoch: 5| Step: 2
Training loss: 2.1576056480407715
Validation loss: 2.096694548924764

Epoch: 5| Step: 3
Training loss: 2.812781810760498
Validation loss: 2.1000371594582834

Epoch: 5| Step: 4
Training loss: 2.0422115325927734
Validation loss: 2.102769797848117

Epoch: 5| Step: 5
Training loss: 2.6643576622009277
Validation loss: 2.094706545593918

Epoch: 5| Step: 6
Training loss: 2.430786609649658
Validation loss: 2.0913048918529222

Epoch: 5| Step: 7
Training loss: 1.8766921758651733
Validation loss: 2.1011324672288794

Epoch: 5| Step: 8
Training loss: 2.528656482696533
Validation loss: 2.106706947408697

Epoch: 5| Step: 9
Training loss: 2.727692127227783
Validation loss: 2.1106882954156525

Epoch: 5| Step: 10
Training loss: 2.121856451034546
Validation loss: 2.119275262278895

Epoch: 125| Step: 0
Training loss: 2.1782634258270264
Validation loss: 2.132298115761049

Epoch: 5| Step: 1
Training loss: 2.299161434173584
Validation loss: 2.1363212600831063

Epoch: 5| Step: 2
Training loss: 2.32293963432312
Validation loss: 2.137601649889382

Epoch: 5| Step: 3
Training loss: 2.6319823265075684
Validation loss: 2.1229095817894064

Epoch: 5| Step: 4
Training loss: 2.16436505317688
Validation loss: 2.11474448122004

Epoch: 5| Step: 5
Training loss: 2.195096492767334
Validation loss: 2.110467210892708

Epoch: 5| Step: 6
Training loss: 2.317756175994873
Validation loss: 2.102059466864473

Epoch: 5| Step: 7
Training loss: 2.395892381668091
Validation loss: 2.1075014555326073

Epoch: 5| Step: 8
Training loss: 2.8347086906433105
Validation loss: 2.107944578252813

Epoch: 5| Step: 9
Training loss: 2.4601073265075684
Validation loss: 2.114451974950811

Epoch: 5| Step: 10
Training loss: 2.752108097076416
Validation loss: 2.10817543665568

Epoch: 126| Step: 0
Training loss: 2.7705557346343994
Validation loss: 2.111771901448568

Epoch: 5| Step: 1
Training loss: 2.250490427017212
Validation loss: 2.099050880760275

Epoch: 5| Step: 2
Training loss: 2.4870553016662598
Validation loss: 2.0977115349103044

Epoch: 5| Step: 3
Training loss: 2.698157787322998
Validation loss: 2.099681790157031

Epoch: 5| Step: 4
Training loss: 2.6124510765075684
Validation loss: 2.09574314343032

Epoch: 5| Step: 5
Training loss: 2.6886870861053467
Validation loss: 2.099834306265718

Epoch: 5| Step: 6
Training loss: 1.8484547138214111
Validation loss: 2.103027400150094

Epoch: 5| Step: 7
Training loss: 1.7828315496444702
Validation loss: 2.0935806946087907

Epoch: 5| Step: 8
Training loss: 2.772625684738159
Validation loss: 2.0961243106472875

Epoch: 5| Step: 9
Training loss: 2.3434855937957764
Validation loss: 2.1216595557428177

Epoch: 5| Step: 10
Training loss: 2.391738176345825
Validation loss: 2.1458827513520435

Epoch: 127| Step: 0
Training loss: 2.532576560974121
Validation loss: 2.136235078175863

Epoch: 5| Step: 1
Training loss: 2.1351633071899414
Validation loss: 2.130705124588423

Epoch: 5| Step: 2
Training loss: 2.4497742652893066
Validation loss: 2.1001958103590113

Epoch: 5| Step: 3
Training loss: 2.567791700363159
Validation loss: 2.088311097955191

Epoch: 5| Step: 4
Training loss: 2.6891729831695557
Validation loss: 2.0897494900611138

Epoch: 5| Step: 5
Training loss: 2.5086312294006348
Validation loss: 2.1169725759055025

Epoch: 5| Step: 6
Training loss: 2.2036099433898926
Validation loss: 2.1161797469662083

Epoch: 5| Step: 7
Training loss: 2.6911263465881348
Validation loss: 2.115660334146151

Epoch: 5| Step: 8
Training loss: 2.0933892726898193
Validation loss: 2.092455807552543

Epoch: 5| Step: 9
Training loss: 2.321345329284668
Validation loss: 2.0847033454525854

Epoch: 5| Step: 10
Training loss: 2.641075372695923
Validation loss: 2.0814558921321744

Epoch: 128| Step: 0
Training loss: 2.0557093620300293
Validation loss: 2.085853612551125

Epoch: 5| Step: 1
Training loss: 2.403110980987549
Validation loss: 2.092000058902207

Epoch: 5| Step: 2
Training loss: 2.916839599609375
Validation loss: 2.1079686918566303

Epoch: 5| Step: 3
Training loss: 2.1619343757629395
Validation loss: 2.1097157898769585

Epoch: 5| Step: 4
Training loss: 2.518470525741577
Validation loss: 2.096490239584318

Epoch: 5| Step: 5
Training loss: 2.4306952953338623
Validation loss: 2.083909647439116

Epoch: 5| Step: 6
Training loss: 2.076852321624756
Validation loss: 2.0876756970600416

Epoch: 5| Step: 7
Training loss: 2.4682517051696777
Validation loss: 2.0906078328368483

Epoch: 5| Step: 8
Training loss: 2.1599459648132324
Validation loss: 2.093073856446051

Epoch: 5| Step: 9
Training loss: 2.4212863445281982
Validation loss: 2.0964410945933354

Epoch: 5| Step: 10
Training loss: 3.1355602741241455
Validation loss: 2.0936072000893216

Epoch: 129| Step: 0
Training loss: 2.122074604034424
Validation loss: 2.0863737393450994

Epoch: 5| Step: 1
Training loss: 2.6535658836364746
Validation loss: 2.0971685186509164

Epoch: 5| Step: 2
Training loss: 2.959030866622925
Validation loss: 2.1094110460691553

Epoch: 5| Step: 3
Training loss: 2.747345447540283
Validation loss: 2.1356042610701693

Epoch: 5| Step: 4
Training loss: 2.2959582805633545
Validation loss: 2.1319359399939097

Epoch: 5| Step: 5
Training loss: 2.870286703109741
Validation loss: 2.1214525725251887

Epoch: 5| Step: 6
Training loss: 2.1471199989318848
Validation loss: 2.1109112924145115

Epoch: 5| Step: 7
Training loss: 2.0327043533325195
Validation loss: 2.0931542124799503

Epoch: 5| Step: 8
Training loss: 1.7044912576675415
Validation loss: 2.0876419826220443

Epoch: 5| Step: 9
Training loss: 2.3704590797424316
Validation loss: 2.0738102928284676

Epoch: 5| Step: 10
Training loss: 2.4605274200439453
Validation loss: 2.067604987852035

Epoch: 130| Step: 0
Training loss: 2.6119885444641113
Validation loss: 2.068642344526065

Epoch: 5| Step: 1
Training loss: 2.292924404144287
Validation loss: 2.082692507774599

Epoch: 5| Step: 2
Training loss: 2.151204824447632
Validation loss: 2.0872868671212146

Epoch: 5| Step: 3
Training loss: 2.756605863571167
Validation loss: 2.0854108923224994

Epoch: 5| Step: 4
Training loss: 2.9968907833099365
Validation loss: 2.075417157142393

Epoch: 5| Step: 5
Training loss: 2.1312403678894043
Validation loss: 2.0653444464488695

Epoch: 5| Step: 6
Training loss: 2.5602002143859863
Validation loss: 2.0613746361065934

Epoch: 5| Step: 7
Training loss: 2.4411721229553223
Validation loss: 2.0636776083259174

Epoch: 5| Step: 8
Training loss: 2.4809937477111816
Validation loss: 2.0632424252007597

Epoch: 5| Step: 9
Training loss: 1.6225802898406982
Validation loss: 2.0706410715656896

Epoch: 5| Step: 10
Training loss: 2.201953649520874
Validation loss: 2.086665125303371

Epoch: 131| Step: 0
Training loss: 1.9210679531097412
Validation loss: 2.0850274165471396

Epoch: 5| Step: 1
Training loss: 2.4287633895874023
Validation loss: 2.0913456409208235

Epoch: 5| Step: 2
Training loss: 2.2316348552703857
Validation loss: 2.073956112707815

Epoch: 5| Step: 3
Training loss: 2.5180411338806152
Validation loss: 2.071106295431814

Epoch: 5| Step: 4
Training loss: 2.591740846633911
Validation loss: 2.064776961521436

Epoch: 5| Step: 5
Training loss: 2.844219923019409
Validation loss: 2.0567129581205306

Epoch: 5| Step: 6
Training loss: 2.1540374755859375
Validation loss: 2.057539386133994

Epoch: 5| Step: 7
Training loss: 2.4649577140808105
Validation loss: 2.0645991807342856

Epoch: 5| Step: 8
Training loss: 2.4668567180633545
Validation loss: 2.0707157965629333

Epoch: 5| Step: 9
Training loss: 1.819101095199585
Validation loss: 2.0766782094073553

Epoch: 5| Step: 10
Training loss: 2.7916107177734375
Validation loss: 2.058128103133171

Epoch: 132| Step: 0
Training loss: 2.382563591003418
Validation loss: 2.0561045703067573

Epoch: 5| Step: 1
Training loss: 1.907712697982788
Validation loss: 2.058325626516855

Epoch: 5| Step: 2
Training loss: 2.2048637866973877
Validation loss: 2.058110870340819

Epoch: 5| Step: 3
Training loss: 2.2304344177246094
Validation loss: 2.058214690095635

Epoch: 5| Step: 4
Training loss: 2.5061023235321045
Validation loss: 2.0568092100081907

Epoch: 5| Step: 5
Training loss: 2.280588150024414
Validation loss: 2.058818683829359

Epoch: 5| Step: 6
Training loss: 2.5536627769470215
Validation loss: 2.0733067553530455

Epoch: 5| Step: 7
Training loss: 2.2985973358154297
Validation loss: 2.0667664107456

Epoch: 5| Step: 8
Training loss: 2.2262356281280518
Validation loss: 2.071764962647551

Epoch: 5| Step: 9
Training loss: 2.6019599437713623
Validation loss: 2.0690258472196517

Epoch: 5| Step: 10
Training loss: 2.920955181121826
Validation loss: 2.0719267860535653

Epoch: 133| Step: 0
Training loss: 2.324258327484131
Validation loss: 2.079209371279645

Epoch: 5| Step: 1
Training loss: 2.4496216773986816
Validation loss: 2.07102572148846

Epoch: 5| Step: 2
Training loss: 2.257169723510742
Validation loss: 2.082570823290015

Epoch: 5| Step: 3
Training loss: 2.5686230659484863
Validation loss: 2.070003781267392

Epoch: 5| Step: 4
Training loss: 2.0189430713653564
Validation loss: 2.066555044984305

Epoch: 5| Step: 5
Training loss: 1.6844565868377686
Validation loss: 2.0631548217547837

Epoch: 5| Step: 6
Training loss: 2.0391411781311035
Validation loss: 2.071003742115472

Epoch: 5| Step: 7
Training loss: 2.5453357696533203
Validation loss: 2.0735831760591075

Epoch: 5| Step: 8
Training loss: 2.758920192718506
Validation loss: 2.086096466228526

Epoch: 5| Step: 9
Training loss: 2.9770703315734863
Validation loss: 2.0831183643751245

Epoch: 5| Step: 10
Training loss: 2.304771661758423
Validation loss: 2.0794456453733545

Epoch: 134| Step: 0
Training loss: 2.1257967948913574
Validation loss: 2.070074301893993

Epoch: 5| Step: 1
Training loss: 2.181406021118164
Validation loss: 2.0667188705936557

Epoch: 5| Step: 2
Training loss: 2.3048291206359863
Validation loss: 2.061638037363688

Epoch: 5| Step: 3
Training loss: 2.52599835395813
Validation loss: 2.0754062847424577

Epoch: 5| Step: 4
Training loss: 2.370861053466797
Validation loss: 2.0631655800727104

Epoch: 5| Step: 5
Training loss: 2.043657064437866
Validation loss: 2.054387011835652

Epoch: 5| Step: 6
Training loss: 1.9525814056396484
Validation loss: 2.0587734048084547

Epoch: 5| Step: 7
Training loss: 2.7468621730804443
Validation loss: 2.068992821119165

Epoch: 5| Step: 8
Training loss: 2.6910898685455322
Validation loss: 2.0812841230823147

Epoch: 5| Step: 9
Training loss: 2.1960089206695557
Validation loss: 2.090665558333038

Epoch: 5| Step: 10
Training loss: 2.9957234859466553
Validation loss: 2.0819431197258735

Epoch: 135| Step: 0
Training loss: 2.1562607288360596
Validation loss: 2.0904303930139028

Epoch: 5| Step: 1
Training loss: 2.0342183113098145
Validation loss: 2.0851425176025717

Epoch: 5| Step: 2
Training loss: 2.449758291244507
Validation loss: 2.080733322328137

Epoch: 5| Step: 3
Training loss: 2.845754623413086
Validation loss: 2.0540206240069483

Epoch: 5| Step: 4
Training loss: 1.8117763996124268
Validation loss: 2.0406801598046416

Epoch: 5| Step: 5
Training loss: 2.288043260574341
Validation loss: 2.035979995163538

Epoch: 5| Step: 6
Training loss: 2.4514756202697754
Validation loss: 2.0415803001772974

Epoch: 5| Step: 7
Training loss: 2.2454826831817627
Validation loss: 2.0442001460700907

Epoch: 5| Step: 8
Training loss: 2.6198318004608154
Validation loss: 2.0481303045826573

Epoch: 5| Step: 9
Training loss: 2.712104082107544
Validation loss: 2.0598089874431653

Epoch: 5| Step: 10
Training loss: 2.643892765045166
Validation loss: 2.0531764325275215

Epoch: 136| Step: 0
Training loss: 2.3923239707946777
Validation loss: 2.047300100326538

Epoch: 5| Step: 1
Training loss: 2.037083864212036
Validation loss: 2.0648167876787085

Epoch: 5| Step: 2
Training loss: 2.219804525375366
Validation loss: 2.082894366274598

Epoch: 5| Step: 3
Training loss: 2.382296562194824
Validation loss: 2.122062909987665

Epoch: 5| Step: 4
Training loss: 2.334214448928833
Validation loss: 2.1156098945166475

Epoch: 5| Step: 5
Training loss: 2.366389751434326
Validation loss: 2.1309787406716296

Epoch: 5| Step: 6
Training loss: 2.920459270477295
Validation loss: 2.146054703702209

Epoch: 5| Step: 7
Training loss: 1.960881233215332
Validation loss: 2.151637731059905

Epoch: 5| Step: 8
Training loss: 2.287161350250244
Validation loss: 2.142060231137019

Epoch: 5| Step: 9
Training loss: 2.853362560272217
Validation loss: 2.1173804857397593

Epoch: 5| Step: 10
Training loss: 2.4749343395233154
Validation loss: 2.0846123862010177

Epoch: 137| Step: 0
Training loss: 2.3172085285186768
Validation loss: 2.0579114934449554

Epoch: 5| Step: 1
Training loss: 2.5470051765441895
Validation loss: 2.041427763559485

Epoch: 5| Step: 2
Training loss: 2.43272066116333
Validation loss: 2.0378414277107484

Epoch: 5| Step: 3
Training loss: 2.248729705810547
Validation loss: 2.045601962715067

Epoch: 5| Step: 4
Training loss: 2.227736234664917
Validation loss: 2.0515490065338793

Epoch: 5| Step: 5
Training loss: 2.1753578186035156
Validation loss: 2.042749503607391

Epoch: 5| Step: 6
Training loss: 2.217055082321167
Validation loss: 2.0394804221327587

Epoch: 5| Step: 7
Training loss: 2.330444097518921
Validation loss: 2.0389781280230452

Epoch: 5| Step: 8
Training loss: 2.4927878379821777
Validation loss: 2.042783575673257

Epoch: 5| Step: 9
Training loss: 2.6410579681396484
Validation loss: 2.0572471387924685

Epoch: 5| Step: 10
Training loss: 2.174009323120117
Validation loss: 2.058483795453143

Epoch: 138| Step: 0
Training loss: 2.8037526607513428
Validation loss: 2.0650982600386425

Epoch: 5| Step: 1
Training loss: 1.8236210346221924
Validation loss: 2.061061769403437

Epoch: 5| Step: 2
Training loss: 2.5211751461029053
Validation loss: 2.0642183519178823

Epoch: 5| Step: 3
Training loss: 2.0572280883789062
Validation loss: 2.064619884696058

Epoch: 5| Step: 4
Training loss: 2.7086081504821777
Validation loss: 2.0628098210980816

Epoch: 5| Step: 5
Training loss: 2.2275390625
Validation loss: 2.061066923602935

Epoch: 5| Step: 6
Training loss: 2.5695595741271973
Validation loss: 2.0504689165340957

Epoch: 5| Step: 7
Training loss: 2.2743258476257324
Validation loss: 2.0333569870200208

Epoch: 5| Step: 8
Training loss: 2.2004950046539307
Validation loss: 2.030487568147721

Epoch: 5| Step: 9
Training loss: 2.652134418487549
Validation loss: 2.0374224801217355

Epoch: 5| Step: 10
Training loss: 1.8169124126434326
Validation loss: 2.0397469177041003

Epoch: 139| Step: 0
Training loss: 2.6604819297790527
Validation loss: 2.0474618442596926

Epoch: 5| Step: 1
Training loss: 1.9443572759628296
Validation loss: 2.0401703029550533

Epoch: 5| Step: 2
Training loss: 2.441868543624878
Validation loss: 2.0352939328839703

Epoch: 5| Step: 3
Training loss: 2.6220943927764893
Validation loss: 2.0353265218837286

Epoch: 5| Step: 4
Training loss: 2.300950527191162
Validation loss: 2.0379532447425266

Epoch: 5| Step: 5
Training loss: 2.036525011062622
Validation loss: 2.060505695240472

Epoch: 5| Step: 6
Training loss: 1.5390530824661255
Validation loss: 2.053122954983865

Epoch: 5| Step: 7
Training loss: 2.7002174854278564
Validation loss: 2.0385335978641304

Epoch: 5| Step: 8
Training loss: 2.11784291267395
Validation loss: 2.0224174799457675

Epoch: 5| Step: 9
Training loss: 2.554630994796753
Validation loss: 2.0234772172025455

Epoch: 5| Step: 10
Training loss: 2.8018040657043457
Validation loss: 2.0230317872057677

Epoch: 140| Step: 0
Training loss: 2.021238327026367
Validation loss: 2.013905616216762

Epoch: 5| Step: 1
Training loss: 2.642878532409668
Validation loss: 2.0193072852268013

Epoch: 5| Step: 2
Training loss: 2.5463974475860596
Validation loss: 2.0250170333411104

Epoch: 5| Step: 3
Training loss: 2.4358482360839844
Validation loss: 2.0228234183403755

Epoch: 5| Step: 4
Training loss: 2.3105416297912598
Validation loss: 2.0220370215754353

Epoch: 5| Step: 5
Training loss: 2.219007730484009
Validation loss: 2.044669371779247

Epoch: 5| Step: 6
Training loss: 2.3490242958068848
Validation loss: 2.0806683084016204

Epoch: 5| Step: 7
Training loss: 2.5921578407287598
Validation loss: 2.0799131342159805

Epoch: 5| Step: 8
Training loss: 1.603200912475586
Validation loss: 2.0870465027388705

Epoch: 5| Step: 9
Training loss: 2.501378059387207
Validation loss: 2.0794380377697688

Epoch: 5| Step: 10
Training loss: 2.532872438430786
Validation loss: 2.0708468139812513

Epoch: 141| Step: 0
Training loss: 2.326627016067505
Validation loss: 2.056111003762932

Epoch: 5| Step: 1
Training loss: 2.422055721282959
Validation loss: 2.04831802075909

Epoch: 5| Step: 2
Training loss: 2.435279607772827
Validation loss: 2.0604899519233295

Epoch: 5| Step: 3
Training loss: 2.5817863941192627
Validation loss: 2.0490871526861705

Epoch: 5| Step: 4
Training loss: 2.474482774734497
Validation loss: 2.0281684244832685

Epoch: 5| Step: 5
Training loss: 2.245934009552002
Validation loss: 2.0225302967973935

Epoch: 5| Step: 6
Training loss: 2.1173949241638184
Validation loss: 2.0246928532918296

Epoch: 5| Step: 7
Training loss: 1.9851713180541992
Validation loss: 2.019500487594194

Epoch: 5| Step: 8
Training loss: 1.9705537557601929
Validation loss: 2.015400982672168

Epoch: 5| Step: 9
Training loss: 2.7825021743774414
Validation loss: 2.025148839078924

Epoch: 5| Step: 10
Training loss: 2.3306806087493896
Validation loss: 2.0515579664579002

Epoch: 142| Step: 0
Training loss: 2.172269582748413
Validation loss: 2.0630291187635033

Epoch: 5| Step: 1
Training loss: 2.605332851409912
Validation loss: 2.0731252624142553

Epoch: 5| Step: 2
Training loss: 1.9742215871810913
Validation loss: 2.071222412970758

Epoch: 5| Step: 3
Training loss: 2.4351463317871094
Validation loss: 2.069247297061387

Epoch: 5| Step: 4
Training loss: 2.2072126865386963
Validation loss: 2.0401657935111754

Epoch: 5| Step: 5
Training loss: 2.4517757892608643
Validation loss: 2.0287285748348443

Epoch: 5| Step: 6
Training loss: 2.3186697959899902
Validation loss: 2.018002774125786

Epoch: 5| Step: 7
Training loss: 2.4613561630249023
Validation loss: 2.022750776301148

Epoch: 5| Step: 8
Training loss: 2.2495346069335938
Validation loss: 2.0170458465494137

Epoch: 5| Step: 9
Training loss: 2.2325196266174316
Validation loss: 2.006913652984045

Epoch: 5| Step: 10
Training loss: 2.4665822982788086
Validation loss: 2.0030784171114684

Epoch: 143| Step: 0
Training loss: 2.842867136001587
Validation loss: 1.9961990233390563

Epoch: 5| Step: 1
Training loss: 2.5316195487976074
Validation loss: 1.9931215868201306

Epoch: 5| Step: 2
Training loss: 2.5575389862060547
Validation loss: 2.000797511428915

Epoch: 5| Step: 3
Training loss: 2.2574374675750732
Validation loss: 2.0153158198120775

Epoch: 5| Step: 4
Training loss: 2.1334376335144043
Validation loss: 2.0285642505973898

Epoch: 5| Step: 5
Training loss: 2.3911871910095215
Validation loss: 2.0044204291476997

Epoch: 5| Step: 6
Training loss: 2.47890305519104
Validation loss: 1.99962144513284

Epoch: 5| Step: 7
Training loss: 1.8008095026016235
Validation loss: 1.9966493063075568

Epoch: 5| Step: 8
Training loss: 2.1638259887695312
Validation loss: 1.9964105672733758

Epoch: 5| Step: 9
Training loss: 2.319044351577759
Validation loss: 2.00084618086456

Epoch: 5| Step: 10
Training loss: 1.8699791431427002
Validation loss: 2.0023761205775763

Epoch: 144| Step: 0
Training loss: 2.65470027923584
Validation loss: 2.0079980229818695

Epoch: 5| Step: 1
Training loss: 1.5659691095352173
Validation loss: 2.018850480356524

Epoch: 5| Step: 2
Training loss: 1.5603115558624268
Validation loss: 2.0264625856953282

Epoch: 5| Step: 3
Training loss: 2.1386590003967285
Validation loss: 2.022348032202772

Epoch: 5| Step: 4
Training loss: 2.250962018966675
Validation loss: 2.028449494351623

Epoch: 5| Step: 5
Training loss: 2.45778226852417
Validation loss: 2.028041564008241

Epoch: 5| Step: 6
Training loss: 2.264538526535034
Validation loss: 2.0192644826827513

Epoch: 5| Step: 7
Training loss: 2.4134554862976074
Validation loss: 2.0158085899968303

Epoch: 5| Step: 8
Training loss: 2.7096848487854004
Validation loss: 2.011715994086317

Epoch: 5| Step: 9
Training loss: 2.618978977203369
Validation loss: 2.0163452099728327

Epoch: 5| Step: 10
Training loss: 2.798813581466675
Validation loss: 2.015345806716591

Epoch: 145| Step: 0
Training loss: 2.579561233520508
Validation loss: 2.0145694491683797

Epoch: 5| Step: 1
Training loss: 1.8945693969726562
Validation loss: 2.0387761323682723

Epoch: 5| Step: 2
Training loss: 2.1470749378204346
Validation loss: 2.0511945447614117

Epoch: 5| Step: 3
Training loss: 2.4589853286743164
Validation loss: 2.073251825506969

Epoch: 5| Step: 4
Training loss: 2.2801575660705566
Validation loss: 2.0948442669324976

Epoch: 5| Step: 5
Training loss: 2.2181453704833984
Validation loss: 2.095532314751738

Epoch: 5| Step: 6
Training loss: 2.477118968963623
Validation loss: 2.0961915216138287

Epoch: 5| Step: 7
Training loss: 1.8472293615341187
Validation loss: 2.0791065026355047

Epoch: 5| Step: 8
Training loss: 3.321011781692505
Validation loss: 2.0642069462806947

Epoch: 5| Step: 9
Training loss: 1.3520216941833496
Validation loss: 2.0433407624562583

Epoch: 5| Step: 10
Training loss: 2.954446792602539
Validation loss: 2.0268019873608827

Epoch: 146| Step: 0
Training loss: 3.048537015914917
Validation loss: 2.0183476914641676

Epoch: 5| Step: 1
Training loss: 2.0092267990112305
Validation loss: 2.009820133127192

Epoch: 5| Step: 2
Training loss: 3.038477659225464
Validation loss: 2.016639255708264

Epoch: 5| Step: 3
Training loss: 2.2331252098083496
Validation loss: 2.018745988927862

Epoch: 5| Step: 4
Training loss: 2.1681923866271973
Validation loss: 2.0244086827001264

Epoch: 5| Step: 5
Training loss: 2.043966770172119
Validation loss: 2.0249417949748296

Epoch: 5| Step: 6
Training loss: 2.5707848072052
Validation loss: 2.0161350593771985

Epoch: 5| Step: 7
Training loss: 2.7434144020080566
Validation loss: 2.028074127371593

Epoch: 5| Step: 8
Training loss: 1.2509758472442627
Validation loss: 2.024221322869742

Epoch: 5| Step: 9
Training loss: 1.7076956033706665
Validation loss: 2.0428995727210917

Epoch: 5| Step: 10
Training loss: 2.517534017562866
Validation loss: 2.018176560760826

Epoch: 147| Step: 0
Training loss: 2.1701791286468506
Validation loss: 1.998890015386766

Epoch: 5| Step: 1
Training loss: 2.4270431995391846
Validation loss: 2.0013518666708343

Epoch: 5| Step: 2
Training loss: 2.1530585289001465
Validation loss: 1.9993135313833914

Epoch: 5| Step: 3
Training loss: 2.428328037261963
Validation loss: 2.0046445438938756

Epoch: 5| Step: 4
Training loss: 2.0004658699035645
Validation loss: 1.9990242988832536

Epoch: 5| Step: 5
Training loss: 2.62274432182312
Validation loss: 2.0124300833671325

Epoch: 5| Step: 6
Training loss: 2.559659481048584
Validation loss: 2.0113456633783158

Epoch: 5| Step: 7
Training loss: 2.394826889038086
Validation loss: 2.003993388145201

Epoch: 5| Step: 8
Training loss: 1.930454969406128
Validation loss: 2.0064105282547655

Epoch: 5| Step: 9
Training loss: 1.9911092519760132
Validation loss: 2.018190751793564

Epoch: 5| Step: 10
Training loss: 2.5943164825439453
Validation loss: 2.016775761881182

Epoch: 148| Step: 0
Training loss: 2.5254976749420166
Validation loss: 2.050207302134524

Epoch: 5| Step: 1
Training loss: 2.450590133666992
Validation loss: 2.0600457781104633

Epoch: 5| Step: 2
Training loss: 2.5119714736938477
Validation loss: 2.045739136716371

Epoch: 5| Step: 3
Training loss: 2.350992441177368
Validation loss: 2.0672923134219263

Epoch: 5| Step: 4
Training loss: 2.645876884460449
Validation loss: 2.068758685101745

Epoch: 5| Step: 5
Training loss: 2.2247674465179443
Validation loss: 2.087902677956448

Epoch: 5| Step: 6
Training loss: 1.98876953125
Validation loss: 2.0478019893810315

Epoch: 5| Step: 7
Training loss: 2.453350305557251
Validation loss: 2.0371488768567323

Epoch: 5| Step: 8
Training loss: 1.6062568426132202
Validation loss: 2.0103629160952825

Epoch: 5| Step: 9
Training loss: 1.8303782939910889
Validation loss: 1.991664009709512

Epoch: 5| Step: 10
Training loss: 2.3448641300201416
Validation loss: 1.9824589452435892

Epoch: 149| Step: 0
Training loss: 2.1904263496398926
Validation loss: 1.9846202327359108

Epoch: 5| Step: 1
Training loss: 2.689767360687256
Validation loss: 1.986157698016013

Epoch: 5| Step: 2
Training loss: 2.1498122215270996
Validation loss: 1.9937467369981992

Epoch: 5| Step: 3
Training loss: 2.522895097732544
Validation loss: 1.9912665044107745

Epoch: 5| Step: 4
Training loss: 1.9565175771713257
Validation loss: 2.009359940405815

Epoch: 5| Step: 5
Training loss: 2.136791944503784
Validation loss: 2.0150159251305366

Epoch: 5| Step: 6
Training loss: 2.019757032394409
Validation loss: 2.0090827993167344

Epoch: 5| Step: 7
Training loss: 2.205472469329834
Validation loss: 2.013140018268298

Epoch: 5| Step: 8
Training loss: 2.464921236038208
Validation loss: 2.0023081430824856

Epoch: 5| Step: 9
Training loss: 2.1288208961486816
Validation loss: 2.01429481403802

Epoch: 5| Step: 10
Training loss: 2.864128828048706
Validation loss: 2.02427165995362

Epoch: 150| Step: 0
Training loss: 2.2600409984588623
Validation loss: 2.038834314192495

Epoch: 5| Step: 1
Training loss: 1.7301037311553955
Validation loss: 2.024110201866396

Epoch: 5| Step: 2
Training loss: 2.307353973388672
Validation loss: 2.0283112807940413

Epoch: 5| Step: 3
Training loss: 1.86978018283844
Validation loss: 2.0251551302530433

Epoch: 5| Step: 4
Training loss: 1.7983529567718506
Validation loss: 2.064673162275745

Epoch: 5| Step: 5
Training loss: 2.9081156253814697
Validation loss: 2.1113959371402697

Epoch: 5| Step: 6
Training loss: 2.7111105918884277
Validation loss: 2.1271637485873316

Epoch: 5| Step: 7
Training loss: 2.6782150268554688
Validation loss: 2.1499726310853036

Epoch: 5| Step: 8
Training loss: 2.692983388900757
Validation loss: 2.2080726264625468

Epoch: 5| Step: 9
Training loss: 2.125922918319702
Validation loss: 2.1859429959327943

Epoch: 5| Step: 10
Training loss: 2.4951393604278564
Validation loss: 2.119105713341826

Epoch: 151| Step: 0
Training loss: 2.776890754699707
Validation loss: 2.0127859833419963

Epoch: 5| Step: 1
Training loss: 2.204017162322998
Validation loss: 2.0000291434667443

Epoch: 5| Step: 2
Training loss: 2.307966947555542
Validation loss: 1.9915742617781445

Epoch: 5| Step: 3
Training loss: 3.026912212371826
Validation loss: 2.0113515161698863

Epoch: 5| Step: 4
Training loss: 1.6973768472671509
Validation loss: 2.028993260475897

Epoch: 5| Step: 5
Training loss: 1.9326260089874268
Validation loss: 2.035030811063705

Epoch: 5| Step: 6
Training loss: 2.456387519836426
Validation loss: 2.0390419037111345

Epoch: 5| Step: 7
Training loss: 2.5886001586914062
Validation loss: 2.0169964477580082

Epoch: 5| Step: 8
Training loss: 2.3897616863250732
Validation loss: 2.0478178275528776

Epoch: 5| Step: 9
Training loss: 1.912725806236267
Validation loss: 2.0282558779562674

Epoch: 5| Step: 10
Training loss: 2.082442045211792
Validation loss: 2.0272088691752446

Epoch: 152| Step: 0
Training loss: 1.8063039779663086
Validation loss: 2.0082826511834257

Epoch: 5| Step: 1
Training loss: 2.6991677284240723
Validation loss: 1.9796768439713346

Epoch: 5| Step: 2
Training loss: 2.552780866622925
Validation loss: 1.9705611313543012

Epoch: 5| Step: 3
Training loss: 2.2868733406066895
Validation loss: 1.9755349620696037

Epoch: 5| Step: 4
Training loss: 2.544699192047119
Validation loss: 2.0017976222499723

Epoch: 5| Step: 5
Training loss: 2.0094470977783203
Validation loss: 2.064964707179736

Epoch: 5| Step: 6
Training loss: 2.421250581741333
Validation loss: 2.058925063379349

Epoch: 5| Step: 7
Training loss: 1.7180951833724976
Validation loss: 2.039619412473453

Epoch: 5| Step: 8
Training loss: 2.3115437030792236
Validation loss: 1.974152370165753

Epoch: 5| Step: 9
Training loss: 2.481365442276001
Validation loss: 1.9809152977440947

Epoch: 5| Step: 10
Training loss: 2.470520496368408
Validation loss: 1.9804926303125197

Epoch: 153| Step: 0
Training loss: 2.049794912338257
Validation loss: 1.9687013741462462

Epoch: 5| Step: 1
Training loss: 1.9346555471420288
Validation loss: 1.9661194509075535

Epoch: 5| Step: 2
Training loss: 2.337531805038452
Validation loss: 2.0049440912021104

Epoch: 5| Step: 3
Training loss: 2.5738368034362793
Validation loss: 2.052914147735924

Epoch: 5| Step: 4
Training loss: 2.6203174591064453
Validation loss: 2.01642942941317

Epoch: 5| Step: 5
Training loss: 1.9080965518951416
Validation loss: 1.9954567186294063

Epoch: 5| Step: 6
Training loss: 2.0421059131622314
Validation loss: 1.9672788855850056

Epoch: 5| Step: 7
Training loss: 2.7429471015930176
Validation loss: 1.9324981294652468

Epoch: 5| Step: 8
Training loss: 2.2921156883239746
Validation loss: 1.9341852165037585

Epoch: 5| Step: 9
Training loss: 1.8926665782928467
Validation loss: 1.9365722222994732

Epoch: 5| Step: 10
Training loss: 2.4609031677246094
Validation loss: 1.9418309298894738

Epoch: 154| Step: 0
Training loss: 2.263007402420044
Validation loss: 1.943737829885175

Epoch: 5| Step: 1
Training loss: 2.2151598930358887
Validation loss: 1.9540464442263368

Epoch: 5| Step: 2
Training loss: 2.126399517059326
Validation loss: 1.9677764190140592

Epoch: 5| Step: 3
Training loss: 2.090299367904663
Validation loss: 1.9789146659194783

Epoch: 5| Step: 4
Training loss: 2.51289701461792
Validation loss: 1.998733748671829

Epoch: 5| Step: 5
Training loss: 1.8250128030776978
Validation loss: 2.001374634363318

Epoch: 5| Step: 6
Training loss: 2.1056456565856934
Validation loss: 2.0183541326112646

Epoch: 5| Step: 7
Training loss: 2.1185250282287598
Validation loss: 2.0451494057973227

Epoch: 5| Step: 8
Training loss: 2.8851373195648193
Validation loss: 2.0571818915746545

Epoch: 5| Step: 9
Training loss: 2.294715642929077
Validation loss: 2.0473647950797953

Epoch: 5| Step: 10
Training loss: 2.0856101512908936
Validation loss: 2.049012217470395

Epoch: 155| Step: 0
Training loss: 2.0077123641967773
Validation loss: 2.0332844282991145

Epoch: 5| Step: 1
Training loss: 2.1936612129211426
Validation loss: 2.0346814406815397

Epoch: 5| Step: 2
Training loss: 2.123257875442505
Validation loss: 2.0383138759161836

Epoch: 5| Step: 3
Training loss: 2.2752299308776855
Validation loss: 2.046004392767465

Epoch: 5| Step: 4
Training loss: 2.2904727458953857
Validation loss: 2.054395955096009

Epoch: 5| Step: 5
Training loss: 2.5368518829345703
Validation loss: 2.0462304007622505

Epoch: 5| Step: 6
Training loss: 2.3788840770721436
Validation loss: 2.045725626330222

Epoch: 5| Step: 7
Training loss: 2.286893367767334
Validation loss: 2.0488202776960147

Epoch: 5| Step: 8
Training loss: 2.168769359588623
Validation loss: 2.018807747030771

Epoch: 5| Step: 9
Training loss: 1.7331171035766602
Validation loss: 2.0165624439075427

Epoch: 5| Step: 10
Training loss: 2.365481376647949
Validation loss: 2.0107962392991587

Epoch: 156| Step: 0
Training loss: 2.6288094520568848
Validation loss: 2.006934837628436

Epoch: 5| Step: 1
Training loss: 1.2293809652328491
Validation loss: 2.002967384553725

Epoch: 5| Step: 2
Training loss: 2.145643949508667
Validation loss: 2.0072787000286962

Epoch: 5| Step: 3
Training loss: 2.0681331157684326
Validation loss: 1.974956561160344

Epoch: 5| Step: 4
Training loss: 2.4075920581817627
Validation loss: 1.9900448117204892

Epoch: 5| Step: 5
Training loss: 2.050706386566162
Validation loss: 2.008056702152375

Epoch: 5| Step: 6
Training loss: 2.4326159954071045
Validation loss: 1.99464004014128

Epoch: 5| Step: 7
Training loss: 1.8117344379425049
Validation loss: 1.9855274526021813

Epoch: 5| Step: 8
Training loss: 2.806273937225342
Validation loss: 1.967965467001802

Epoch: 5| Step: 9
Training loss: 2.4453392028808594
Validation loss: 1.9653129116181405

Epoch: 5| Step: 10
Training loss: 1.9558868408203125
Validation loss: 1.965339796517485

Epoch: 157| Step: 0
Training loss: 2.434091091156006
Validation loss: 1.9725664584867415

Epoch: 5| Step: 1
Training loss: 2.1685173511505127
Validation loss: 1.9756270980322233

Epoch: 5| Step: 2
Training loss: 2.8200430870056152
Validation loss: 1.9836020905484435

Epoch: 5| Step: 3
Training loss: 1.6956398487091064
Validation loss: 1.9944873163777013

Epoch: 5| Step: 4
Training loss: 2.1478803157806396
Validation loss: 2.0176067775295627

Epoch: 5| Step: 5
Training loss: 2.4398715496063232
Validation loss: 2.0291730396209227

Epoch: 5| Step: 6
Training loss: 1.886188268661499
Validation loss: 2.0298052564744027

Epoch: 5| Step: 7
Training loss: 1.7645832300186157
Validation loss: 2.027345088220412

Epoch: 5| Step: 8
Training loss: 2.143232822418213
Validation loss: 2.0189921291925574

Epoch: 5| Step: 9
Training loss: 2.11256742477417
Validation loss: 2.0240344411583355

Epoch: 5| Step: 10
Training loss: 2.451835870742798
Validation loss: 1.9767941146768548

Epoch: 158| Step: 0
Training loss: 2.2805631160736084
Validation loss: 1.9624001518372567

Epoch: 5| Step: 1
Training loss: 2.2384815216064453
Validation loss: 1.9548775662658036

Epoch: 5| Step: 2
Training loss: 2.3227856159210205
Validation loss: 1.9534494133405789

Epoch: 5| Step: 3
Training loss: 1.301939845085144
Validation loss: 1.9475450336292226

Epoch: 5| Step: 4
Training loss: 2.6532161235809326
Validation loss: 1.9546365609733007

Epoch: 5| Step: 5
Training loss: 1.8086696863174438
Validation loss: 1.9871823569779754

Epoch: 5| Step: 6
Training loss: 2.6141562461853027
Validation loss: 2.02206479349444

Epoch: 5| Step: 7
Training loss: 2.385468006134033
Validation loss: 2.0375623318456833

Epoch: 5| Step: 8
Training loss: 2.131847381591797
Validation loss: 2.073245712505874

Epoch: 5| Step: 9
Training loss: 2.262781858444214
Validation loss: 2.066585449762242

Epoch: 5| Step: 10
Training loss: 2.054184913635254
Validation loss: 2.0119556278310795

Epoch: 159| Step: 0
Training loss: 2.236032485961914
Validation loss: 1.9719852427000641

Epoch: 5| Step: 1
Training loss: 2.048464298248291
Validation loss: 1.9818603120824343

Epoch: 5| Step: 2
Training loss: 2.053040027618408
Validation loss: 1.9887909222674627

Epoch: 5| Step: 3
Training loss: 2.1668004989624023
Validation loss: 1.9642163130544847

Epoch: 5| Step: 4
Training loss: 2.2681236267089844
Validation loss: 1.955786084616056

Epoch: 5| Step: 5
Training loss: 2.2006783485412598
Validation loss: 1.9741947266363329

Epoch: 5| Step: 6
Training loss: 2.1042752265930176
Validation loss: 1.9866970969784645

Epoch: 5| Step: 7
Training loss: 1.7466373443603516
Validation loss: 1.9942014332740539

Epoch: 5| Step: 8
Training loss: 2.0285983085632324
Validation loss: 2.005312103097157

Epoch: 5| Step: 9
Training loss: 2.7282068729400635
Validation loss: 2.0124129813204528

Epoch: 5| Step: 10
Training loss: 2.26995849609375
Validation loss: 1.9777494169050647

Epoch: 160| Step: 0
Training loss: 2.201453685760498
Validation loss: 1.9638743169846073

Epoch: 5| Step: 1
Training loss: 1.9434185028076172
Validation loss: 1.9794008219113914

Epoch: 5| Step: 2
Training loss: 2.4074504375457764
Validation loss: 1.9640882912502493

Epoch: 5| Step: 3
Training loss: 2.923403263092041
Validation loss: 1.964741144129025

Epoch: 5| Step: 4
Training loss: 2.220061779022217
Validation loss: 1.949920969624673

Epoch: 5| Step: 5
Training loss: 2.1460330486297607
Validation loss: 1.961045721525787

Epoch: 5| Step: 6
Training loss: 2.1473352909088135
Validation loss: 1.9680320793582546

Epoch: 5| Step: 7
Training loss: 1.8295772075653076
Validation loss: 1.9871767541413665

Epoch: 5| Step: 8
Training loss: 1.8108818531036377
Validation loss: 2.005709050804056

Epoch: 5| Step: 9
Training loss: 2.0747992992401123
Validation loss: 2.0123645861943564

Epoch: 5| Step: 10
Training loss: 1.8586493730545044
Validation loss: 2.0280229212135397

Epoch: 161| Step: 0
Training loss: 1.5447607040405273
Validation loss: 2.0245066663270355

Epoch: 5| Step: 1
Training loss: 2.309925079345703
Validation loss: 2.02464424538356

Epoch: 5| Step: 2
Training loss: 1.8896583318710327
Validation loss: 2.0033196454407065

Epoch: 5| Step: 3
Training loss: 1.706579566001892
Validation loss: 1.9698705634763163

Epoch: 5| Step: 4
Training loss: 2.3460185527801514
Validation loss: 1.960525002530826

Epoch: 5| Step: 5
Training loss: 2.3085479736328125
Validation loss: 1.9584306260590911

Epoch: 5| Step: 6
Training loss: 1.9978421926498413
Validation loss: 1.9451491884005967

Epoch: 5| Step: 7
Training loss: 2.080261707305908
Validation loss: 1.9474938518257552

Epoch: 5| Step: 8
Training loss: 2.1656877994537354
Validation loss: 1.9368637864307692

Epoch: 5| Step: 9
Training loss: 2.6770737171173096
Validation loss: 1.941646570800453

Epoch: 5| Step: 10
Training loss: 2.716399669647217
Validation loss: 1.952742443289808

Epoch: 162| Step: 0
Training loss: 2.598156452178955
Validation loss: 1.9624397716214579

Epoch: 5| Step: 1
Training loss: 1.7161105871200562
Validation loss: 1.9633947341672835

Epoch: 5| Step: 2
Training loss: 1.7916820049285889
Validation loss: 1.9795215668216828

Epoch: 5| Step: 3
Training loss: 2.2935423851013184
Validation loss: 2.069140698320122

Epoch: 5| Step: 4
Training loss: 2.4212875366210938
Validation loss: 2.1229360411244054

Epoch: 5| Step: 5
Training loss: 2.2004363536834717
Validation loss: 2.167644154640936

Epoch: 5| Step: 6
Training loss: 2.410545825958252
Validation loss: 2.1287234649863294

Epoch: 5| Step: 7
Training loss: 2.43890643119812
Validation loss: 2.0249480380806872

Epoch: 5| Step: 8
Training loss: 1.6950490474700928
Validation loss: 1.9284787870222522

Epoch: 5| Step: 9
Training loss: 2.4698009490966797
Validation loss: 1.980147489937403

Epoch: 5| Step: 10
Training loss: 2.4207346439361572
Validation loss: 1.994800688118063

Epoch: 163| Step: 0
Training loss: 2.0418503284454346
Validation loss: 2.0172217392152354

Epoch: 5| Step: 1
Training loss: 2.4664998054504395
Validation loss: 2.011835836595105

Epoch: 5| Step: 2
Training loss: 2.8498401641845703
Validation loss: 1.966776970894106

Epoch: 5| Step: 3
Training loss: 2.123908519744873
Validation loss: 1.9353294654559063

Epoch: 5| Step: 4
Training loss: 2.245795488357544
Validation loss: 1.9400313579907982

Epoch: 5| Step: 5
Training loss: 1.9960057735443115
Validation loss: 1.971158012267082

Epoch: 5| Step: 6
Training loss: 2.219759464263916
Validation loss: 2.0283376042560866

Epoch: 5| Step: 7
Training loss: 2.484595775604248
Validation loss: 2.0884127386154665

Epoch: 5| Step: 8
Training loss: 2.726882219314575
Validation loss: 2.0805041559280886

Epoch: 5| Step: 9
Training loss: 1.8295437097549438
Validation loss: 2.0613254398427983

Epoch: 5| Step: 10
Training loss: 2.3064699172973633
Validation loss: 2.016368019965387

Epoch: 164| Step: 0
Training loss: 1.6116374731063843
Validation loss: 1.975419141912973

Epoch: 5| Step: 1
Training loss: 2.4649786949157715
Validation loss: 1.9582387273029616

Epoch: 5| Step: 2
Training loss: 2.1064093112945557
Validation loss: 1.9982648895632835

Epoch: 5| Step: 3
Training loss: 2.6532440185546875
Validation loss: 2.0477026688155306

Epoch: 5| Step: 4
Training loss: 2.8333630561828613
Validation loss: 2.141526104301535

Epoch: 5| Step: 5
Training loss: 2.5890724658966064
Validation loss: 2.1817242253211235

Epoch: 5| Step: 6
Training loss: 1.8376758098602295
Validation loss: 2.105370970182521

Epoch: 5| Step: 7
Training loss: 2.3649940490722656
Validation loss: 2.0301794877616306

Epoch: 5| Step: 8
Training loss: 2.2827067375183105
Validation loss: 1.9717178601090626

Epoch: 5| Step: 9
Training loss: 1.8442655801773071
Validation loss: 1.9853882815248223

Epoch: 5| Step: 10
Training loss: 2.0388970375061035
Validation loss: 2.035422675071224

Epoch: 165| Step: 0
Training loss: 2.7062387466430664
Validation loss: 2.0190458310547696

Epoch: 5| Step: 1
Training loss: 2.0246992111206055
Validation loss: 1.998932425693799

Epoch: 5| Step: 2
Training loss: 1.8856052160263062
Validation loss: 1.9494046985462148

Epoch: 5| Step: 3
Training loss: 2.1177706718444824
Validation loss: 1.9199983791638446

Epoch: 5| Step: 4
Training loss: 2.24076247215271
Validation loss: 1.9089670258183633

Epoch: 5| Step: 5
Training loss: 2.124539613723755
Validation loss: 1.9175148458891018

Epoch: 5| Step: 6
Training loss: 2.389946699142456
Validation loss: 1.917705387197515

Epoch: 5| Step: 7
Training loss: 1.9270517826080322
Validation loss: 1.9314734141031902

Epoch: 5| Step: 8
Training loss: 2.7430694103240967
Validation loss: 1.9227209783369494

Epoch: 5| Step: 9
Training loss: 2.1791584491729736
Validation loss: 1.9358808212382819

Epoch: 5| Step: 10
Training loss: 1.9678372144699097
Validation loss: 1.9287711420366842

Epoch: 166| Step: 0
Training loss: 2.2336905002593994
Validation loss: 1.9427776567397579

Epoch: 5| Step: 1
Training loss: 2.5277066230773926
Validation loss: 1.9700175882667623

Epoch: 5| Step: 2
Training loss: 1.6797491312026978
Validation loss: 2.026082484952865

Epoch: 5| Step: 3
Training loss: 2.4242196083068848
Validation loss: 2.0410362289797876

Epoch: 5| Step: 4
Training loss: 1.6006038188934326
Validation loss: 2.014308467988045

Epoch: 5| Step: 5
Training loss: 2.7369327545166016
Validation loss: 1.9770672090591923

Epoch: 5| Step: 6
Training loss: 1.9749866724014282
Validation loss: 1.9543548271220217

Epoch: 5| Step: 7
Training loss: 2.7467331886291504
Validation loss: 1.9618170389565088

Epoch: 5| Step: 8
Training loss: 2.013813018798828
Validation loss: 1.995684076380986

Epoch: 5| Step: 9
Training loss: 1.9766212701797485
Validation loss: 2.0582211786700833

Epoch: 5| Step: 10
Training loss: 2.161545515060425
Validation loss: 2.178789484885431

Epoch: 167| Step: 0
Training loss: 2.3601536750793457
Validation loss: 2.1080743548690632

Epoch: 5| Step: 1
Training loss: 2.1188437938690186
Validation loss: 2.011704050084596

Epoch: 5| Step: 2
Training loss: 2.4114739894866943
Validation loss: 1.9952509223773915

Epoch: 5| Step: 3
Training loss: 1.5499045848846436
Validation loss: 1.9544995971905288

Epoch: 5| Step: 4
Training loss: 2.223090648651123
Validation loss: 1.920483189244424

Epoch: 5| Step: 5
Training loss: 2.2507293224334717
Validation loss: 1.9086286996000557

Epoch: 5| Step: 6
Training loss: 2.0666983127593994
Validation loss: 1.9119853165841871

Epoch: 5| Step: 7
Training loss: 2.2235705852508545
Validation loss: 1.963219460620675

Epoch: 5| Step: 8
Training loss: 2.206289768218994
Validation loss: 2.0713231640477336

Epoch: 5| Step: 9
Training loss: 1.7351537942886353
Validation loss: 2.1120046441273024

Epoch: 5| Step: 10
Training loss: 3.2442569732666016
Validation loss: 2.069038462895219

Epoch: 168| Step: 0
Training loss: 1.2477341890335083
Validation loss: 2.0050821560685352

Epoch: 5| Step: 1
Training loss: 2.399273633956909
Validation loss: 1.9143376081220564

Epoch: 5| Step: 2
Training loss: 2.0216221809387207
Validation loss: 1.8902280997204524

Epoch: 5| Step: 3
Training loss: 2.4492392539978027
Validation loss: 1.903141736984253

Epoch: 5| Step: 4
Training loss: 1.7150367498397827
Validation loss: 1.9306904115984518

Epoch: 5| Step: 5
Training loss: 2.810586929321289
Validation loss: 1.9511877580355572

Epoch: 5| Step: 6
Training loss: 2.643519878387451
Validation loss: 1.9619918818114905

Epoch: 5| Step: 7
Training loss: 2.036912441253662
Validation loss: 1.9707142704276628

Epoch: 5| Step: 8
Training loss: 2.250399112701416
Validation loss: 1.9629946831733949

Epoch: 5| Step: 9
Training loss: 2.229495048522949
Validation loss: 1.962027495907199

Epoch: 5| Step: 10
Training loss: 2.878580093383789
Validation loss: 1.95155619934041

Epoch: 169| Step: 0
Training loss: 1.9530586004257202
Validation loss: 1.9610138349635626

Epoch: 5| Step: 1
Training loss: 2.5031380653381348
Validation loss: 1.9628443500047088

Epoch: 5| Step: 2
Training loss: 2.0694098472595215
Validation loss: 1.9875160007066623

Epoch: 5| Step: 3
Training loss: 2.0481247901916504
Validation loss: 2.0130115414178498

Epoch: 5| Step: 4
Training loss: 2.513503313064575
Validation loss: 2.0330651985701693

Epoch: 5| Step: 5
Training loss: 1.8935598134994507
Validation loss: 2.01693400772669

Epoch: 5| Step: 6
Training loss: 2.6700167655944824
Validation loss: 2.0202921487951793

Epoch: 5| Step: 7
Training loss: 1.9872446060180664
Validation loss: 2.0174469435086815

Epoch: 5| Step: 8
Training loss: 1.8882973194122314
Validation loss: 2.0403421950596634

Epoch: 5| Step: 9
Training loss: 1.996466040611267
Validation loss: 2.073326523585986

Epoch: 5| Step: 10
Training loss: 1.8860132694244385
Validation loss: 2.1089516250036096

Epoch: 170| Step: 0
Training loss: 1.858890175819397
Validation loss: 2.0794756168960244

Epoch: 5| Step: 1
Training loss: 2.523475170135498
Validation loss: 2.0255635579427085

Epoch: 5| Step: 2
Training loss: 1.930916428565979
Validation loss: 1.9815246161594187

Epoch: 5| Step: 3
Training loss: 2.7420754432678223
Validation loss: 1.946580410003662

Epoch: 5| Step: 4
Training loss: 2.0169620513916016
Validation loss: 1.9212750875821678

Epoch: 5| Step: 5
Training loss: 2.428027629852295
Validation loss: 1.9145669885860976

Epoch: 5| Step: 6
Training loss: 1.7215824127197266
Validation loss: 1.936357105931928

Epoch: 5| Step: 7
Training loss: 1.841287612915039
Validation loss: 1.9689301470274567

Epoch: 5| Step: 8
Training loss: 2.4933128356933594
Validation loss: 1.9995298013892224

Epoch: 5| Step: 9
Training loss: 1.5683263540267944
Validation loss: 2.0260996485269196

Epoch: 5| Step: 10
Training loss: 2.3054869174957275
Validation loss: 2.0663534069574006

Epoch: 171| Step: 0
Training loss: 1.8669923543930054
Validation loss: 2.022823727259072

Epoch: 5| Step: 1
Training loss: 2.028535842895508
Validation loss: 2.0427316901504353

Epoch: 5| Step: 2
Training loss: 2.2784430980682373
Validation loss: 2.072511934464978

Epoch: 5| Step: 3
Training loss: 2.296505928039551
Validation loss: 2.148029975993659

Epoch: 5| Step: 4
Training loss: 1.8520586490631104
Validation loss: 2.2058035455724245

Epoch: 5| Step: 5
Training loss: 2.413668155670166
Validation loss: 2.2781799044660342

Epoch: 5| Step: 6
Training loss: 2.2810468673706055
Validation loss: 2.3400040365034536

Epoch: 5| Step: 7
Training loss: 2.996065139770508
Validation loss: 2.354462978660419

Epoch: 5| Step: 8
Training loss: 2.3175208568573
Validation loss: 2.2585558916932795

Epoch: 5| Step: 9
Training loss: 2.355318784713745
Validation loss: 2.1133352236081193

Epoch: 5| Step: 10
Training loss: 1.4093093872070312
Validation loss: 2.0351082791564283

Epoch: 172| Step: 0
Training loss: 2.1527719497680664
Validation loss: 1.9259360913307435

Epoch: 5| Step: 1
Training loss: 2.432509660720825
Validation loss: 1.9072844315600652

Epoch: 5| Step: 2
Training loss: 1.613265037536621
Validation loss: 1.9235700074062552

Epoch: 5| Step: 3
Training loss: 1.9730144739151
Validation loss: 1.922516276759486

Epoch: 5| Step: 4
Training loss: 2.4361119270324707
Validation loss: 1.9322384095961047

Epoch: 5| Step: 5
Training loss: 2.704540729522705
Validation loss: 1.9353518255295292

Epoch: 5| Step: 6
Training loss: 2.5721936225891113
Validation loss: 1.9274735784017911

Epoch: 5| Step: 7
Training loss: 1.8270924091339111
Validation loss: 1.9195937597623436

Epoch: 5| Step: 8
Training loss: 1.7529027462005615
Validation loss: 1.9237781263166858

Epoch: 5| Step: 9
Training loss: 2.930741786956787
Validation loss: 1.9252972782299083

Epoch: 5| Step: 10
Training loss: 1.8532309532165527
Validation loss: 1.9314637068779237

Epoch: 173| Step: 0
Training loss: 2.4412083625793457
Validation loss: 1.9408581743958175

Epoch: 5| Step: 1
Training loss: 2.3698647022247314
Validation loss: 1.9515726873951573

Epoch: 5| Step: 2
Training loss: 1.9623222351074219
Validation loss: 1.9695784866168935

Epoch: 5| Step: 3
Training loss: 2.1375231742858887
Validation loss: 1.9871137757455148

Epoch: 5| Step: 4
Training loss: 1.9732192754745483
Validation loss: 1.9458219056488366

Epoch: 5| Step: 5
Training loss: 2.281552791595459
Validation loss: 1.9487283716919601

Epoch: 5| Step: 6
Training loss: 2.0647225379943848
Validation loss: 1.9251176541851414

Epoch: 5| Step: 7
Training loss: 2.2755565643310547
Validation loss: 1.912078115247911

Epoch: 5| Step: 8
Training loss: 2.0681281089782715
Validation loss: 1.9094556339325444

Epoch: 5| Step: 9
Training loss: 2.2035834789276123
Validation loss: 1.901928678635628

Epoch: 5| Step: 10
Training loss: 2.3340837955474854
Validation loss: 1.893005314693656

Epoch: 174| Step: 0
Training loss: 2.061467170715332
Validation loss: 1.8902005457109021

Epoch: 5| Step: 1
Training loss: 2.0013506412506104
Validation loss: 1.8937448429804977

Epoch: 5| Step: 2
Training loss: 1.9549850225448608
Validation loss: 1.904821740683689

Epoch: 5| Step: 3
Training loss: 2.6263442039489746
Validation loss: 1.91086487103534

Epoch: 5| Step: 4
Training loss: 2.6208455562591553
Validation loss: 1.9116106340962071

Epoch: 5| Step: 5
Training loss: 2.2236740589141846
Validation loss: 1.9253779918916765

Epoch: 5| Step: 6
Training loss: 1.8820879459381104
Validation loss: 1.9384655811453377

Epoch: 5| Step: 7
Training loss: 1.2813026905059814
Validation loss: 1.9772640966599988

Epoch: 5| Step: 8
Training loss: 2.2860350608825684
Validation loss: 2.0035356757461384

Epoch: 5| Step: 9
Training loss: 2.458528995513916
Validation loss: 2.0081151518770444

Epoch: 5| Step: 10
Training loss: 1.8012961149215698
Validation loss: 1.9879757653000534

Epoch: 175| Step: 0
Training loss: 1.917424201965332
Validation loss: 2.0128083536701817

Epoch: 5| Step: 1
Training loss: 2.5415186882019043
Validation loss: 2.000755666404642

Epoch: 5| Step: 2
Training loss: 1.7433542013168335
Validation loss: 2.0221022290568196

Epoch: 5| Step: 3
Training loss: 2.160001277923584
Validation loss: 2.0636084861652826

Epoch: 5| Step: 4
Training loss: 3.0083322525024414
Validation loss: 2.0705544564031784

Epoch: 5| Step: 5
Training loss: 1.3798515796661377
Validation loss: 2.0700681273655226

Epoch: 5| Step: 6
Training loss: 2.3107786178588867
Validation loss: 2.0294538544070337

Epoch: 5| Step: 7
Training loss: 2.2053675651550293
Validation loss: 1.9907133245980868

Epoch: 5| Step: 8
Training loss: 1.803731918334961
Validation loss: 1.9526649187969904

Epoch: 5| Step: 9
Training loss: 1.9979887008666992
Validation loss: 1.949220295875303

Epoch: 5| Step: 10
Training loss: 1.851733684539795
Validation loss: 1.9540139411085395

Epoch: 176| Step: 0
Training loss: 2.4125332832336426
Validation loss: 1.9660072044659687

Epoch: 5| Step: 1
Training loss: 1.7948360443115234
Validation loss: 1.979756591140583

Epoch: 5| Step: 2
Training loss: 2.116232395172119
Validation loss: 1.9880468204457273

Epoch: 5| Step: 3
Training loss: 1.7699826955795288
Validation loss: 1.989876603567472

Epoch: 5| Step: 4
Training loss: 2.0391812324523926
Validation loss: 2.0001651407569967

Epoch: 5| Step: 5
Training loss: 2.671950101852417
Validation loss: 2.013833094668645

Epoch: 5| Step: 6
Training loss: 2.136502742767334
Validation loss: 2.0049509284316853

Epoch: 5| Step: 7
Training loss: 2.275784969329834
Validation loss: 2.0010877834853305

Epoch: 5| Step: 8
Training loss: 1.971430778503418
Validation loss: 1.9927320505983086

Epoch: 5| Step: 9
Training loss: 1.904444932937622
Validation loss: 2.0145802677318616

Epoch: 5| Step: 10
Training loss: 1.6057558059692383
Validation loss: 2.0081330730069067

Epoch: 177| Step: 0
Training loss: 1.9629733562469482
Validation loss: 1.9958430554277153

Epoch: 5| Step: 1
Training loss: 1.9333631992340088
Validation loss: 1.9650915899584371

Epoch: 5| Step: 2
Training loss: 1.658719778060913
Validation loss: 1.9629688160393828

Epoch: 5| Step: 3
Training loss: 2.258479118347168
Validation loss: 1.9596285307279198

Epoch: 5| Step: 4
Training loss: 1.7827262878417969
Validation loss: 1.931641274882901

Epoch: 5| Step: 5
Training loss: 2.488449811935425
Validation loss: 1.9533053136640979

Epoch: 5| Step: 6
Training loss: 2.0766870975494385
Validation loss: 1.947595727059149

Epoch: 5| Step: 7
Training loss: 1.5145323276519775
Validation loss: 1.9748410614587928

Epoch: 5| Step: 8
Training loss: 2.388481855392456
Validation loss: 1.9797503845666045

Epoch: 5| Step: 9
Training loss: 2.261542558670044
Validation loss: 1.9400585479633783

Epoch: 5| Step: 10
Training loss: 2.426316738128662
Validation loss: 1.9452804160374466

Epoch: 178| Step: 0
Training loss: 1.735823392868042
Validation loss: 1.9443285119148992

Epoch: 5| Step: 1
Training loss: 2.8683865070343018
Validation loss: 1.9477834086264334

Epoch: 5| Step: 2
Training loss: 2.4757728576660156
Validation loss: 1.9609426093357865

Epoch: 5| Step: 3
Training loss: 2.3252153396606445
Validation loss: 1.9780698899299867

Epoch: 5| Step: 4
Training loss: 2.5942063331604004
Validation loss: 1.9849779990411573

Epoch: 5| Step: 5
Training loss: 1.8221406936645508
Validation loss: 1.9835080408280896

Epoch: 5| Step: 6
Training loss: 2.123680830001831
Validation loss: 1.9934041859001241

Epoch: 5| Step: 7
Training loss: 1.4326047897338867
Validation loss: 1.9887982286432737

Epoch: 5| Step: 8
Training loss: 1.5732743740081787
Validation loss: 1.996599143551242

Epoch: 5| Step: 9
Training loss: 1.234290361404419
Validation loss: 2.003328559219196

Epoch: 5| Step: 10
Training loss: 2.456266403198242
Validation loss: 2.0418587435958204

Epoch: 179| Step: 0
Training loss: 1.800309181213379
Validation loss: 2.050582173050091

Epoch: 5| Step: 1
Training loss: 2.0950427055358887
Validation loss: 2.049679021681509

Epoch: 5| Step: 2
Training loss: 2.158298969268799
Validation loss: 2.032393194014026

Epoch: 5| Step: 3
Training loss: 2.377516269683838
Validation loss: 2.007051473022789

Epoch: 5| Step: 4
Training loss: 1.7908360958099365
Validation loss: 1.9885902315057733

Epoch: 5| Step: 5
Training loss: 2.1031863689422607
Validation loss: 1.9549480535650765

Epoch: 5| Step: 6
Training loss: 2.668912410736084
Validation loss: 1.9467456571517452

Epoch: 5| Step: 7
Training loss: 2.1218948364257812
Validation loss: 1.9365295492192751

Epoch: 5| Step: 8
Training loss: 1.564367413520813
Validation loss: 1.9656434956417288

Epoch: 5| Step: 9
Training loss: 2.2664456367492676
Validation loss: 1.9687546581350348

Epoch: 5| Step: 10
Training loss: 1.4164724349975586
Validation loss: 1.9710882632963118

Epoch: 180| Step: 0
Training loss: 1.8498042821884155
Validation loss: 1.9834127310783631

Epoch: 5| Step: 1
Training loss: 1.6811535358428955
Validation loss: 1.9908089099391815

Epoch: 5| Step: 2
Training loss: 1.9888980388641357
Validation loss: 2.006631576886741

Epoch: 5| Step: 3
Training loss: 1.6689693927764893
Validation loss: 1.9873397734857374

Epoch: 5| Step: 4
Training loss: 1.702264428138733
Validation loss: 1.993392341880388

Epoch: 5| Step: 5
Training loss: 1.6639964580535889
Validation loss: 1.9850238856448923

Epoch: 5| Step: 6
Training loss: 2.0015673637390137
Validation loss: 2.0074632103725145

Epoch: 5| Step: 7
Training loss: 2.3800618648529053
Validation loss: 2.0346794141236173

Epoch: 5| Step: 8
Training loss: 2.2310657501220703
Validation loss: 2.040799779276694

Epoch: 5| Step: 9
Training loss: 2.9361557960510254
Validation loss: 2.043561491914975

Epoch: 5| Step: 10
Training loss: 2.5996921062469482
Validation loss: 2.0602567118983113

Epoch: 181| Step: 0
Training loss: 1.8776401281356812
Validation loss: 2.031815064850674

Epoch: 5| Step: 1
Training loss: 1.6085535287857056
Validation loss: 2.018061173859463

Epoch: 5| Step: 2
Training loss: 1.4858535528182983
Validation loss: 1.9880209943299652

Epoch: 5| Step: 3
Training loss: 2.211921215057373
Validation loss: 2.0067180971945486

Epoch: 5| Step: 4
Training loss: 2.306727647781372
Validation loss: 1.994215206433368

Epoch: 5| Step: 5
Training loss: 2.129340410232544
Validation loss: 1.9911914153765606

Epoch: 5| Step: 6
Training loss: 1.944877028465271
Validation loss: 1.9832512499183736

Epoch: 5| Step: 7
Training loss: 2.7590503692626953
Validation loss: 1.9971979471944994

Epoch: 5| Step: 8
Training loss: 1.8794902563095093
Validation loss: 2.005292293845966

Epoch: 5| Step: 9
Training loss: 2.2223658561706543
Validation loss: 1.9903251304421374

Epoch: 5| Step: 10
Training loss: 1.6613140106201172
Validation loss: 1.971539315357003

Epoch: 182| Step: 0
Training loss: 2.103044033050537
Validation loss: 1.9563925625175558

Epoch: 5| Step: 1
Training loss: 2.000772714614868
Validation loss: 1.94274995147541

Epoch: 5| Step: 2
Training loss: 2.725123167037964
Validation loss: 1.953524181919713

Epoch: 5| Step: 3
Training loss: 1.994338035583496
Validation loss: 1.9517344262010308

Epoch: 5| Step: 4
Training loss: 1.9480912685394287
Validation loss: 1.9401611025615404

Epoch: 5| Step: 5
Training loss: 2.1595711708068848
Validation loss: 1.9341454441829393

Epoch: 5| Step: 6
Training loss: 1.8698927164077759
Validation loss: 1.9179154339657034

Epoch: 5| Step: 7
Training loss: 1.7857532501220703
Validation loss: 1.9442638120343607

Epoch: 5| Step: 8
Training loss: 2.1817314624786377
Validation loss: 1.948727494926863

Epoch: 5| Step: 9
Training loss: 1.613917589187622
Validation loss: 1.9639975204262683

Epoch: 5| Step: 10
Training loss: 1.8279129266738892
Validation loss: 1.9676774240309192

Epoch: 183| Step: 0
Training loss: 1.2639882564544678
Validation loss: 1.9991560059209024

Epoch: 5| Step: 1
Training loss: 1.6242650747299194
Validation loss: 2.0482086776405253

Epoch: 5| Step: 2
Training loss: 1.882651925086975
Validation loss: 2.0563743883563625

Epoch: 5| Step: 3
Training loss: 1.4850080013275146
Validation loss: 2.118515560703893

Epoch: 5| Step: 4
Training loss: 2.3988842964172363
Validation loss: 2.1262578272050425

Epoch: 5| Step: 5
Training loss: 2.4322290420532227
Validation loss: 2.1564492025683

Epoch: 5| Step: 6
Training loss: 2.425459384918213
Validation loss: 2.1643795069827827

Epoch: 5| Step: 7
Training loss: 2.177220106124878
Validation loss: 2.1713351895732265

Epoch: 5| Step: 8
Training loss: 2.1256251335144043
Validation loss: 2.177662600753128

Epoch: 5| Step: 9
Training loss: 2.1603121757507324
Validation loss: 2.143973106979042

Epoch: 5| Step: 10
Training loss: 2.450693130493164
Validation loss: 2.1023837622775825

Epoch: 184| Step: 0
Training loss: 1.665630578994751
Validation loss: 2.0363114418522006

Epoch: 5| Step: 1
Training loss: 2.178985834121704
Validation loss: 1.9616991448146042

Epoch: 5| Step: 2
Training loss: 2.043774366378784
Validation loss: 1.9420731888022473

Epoch: 5| Step: 3
Training loss: 2.0022945404052734
Validation loss: 1.9425949076170563

Epoch: 5| Step: 4
Training loss: 2.233630657196045
Validation loss: 1.9287466003048805

Epoch: 5| Step: 5
Training loss: 1.7499507665634155
Validation loss: 1.9111564800303469

Epoch: 5| Step: 6
Training loss: 1.8413349390029907
Validation loss: 1.900644104967835

Epoch: 5| Step: 7
Training loss: 2.683911085128784
Validation loss: 1.903390952335891

Epoch: 5| Step: 8
Training loss: 1.7856194972991943
Validation loss: 1.9106866800656883

Epoch: 5| Step: 9
Training loss: 2.0673434734344482
Validation loss: 1.9212655136662145

Epoch: 5| Step: 10
Training loss: 2.0226829051971436
Validation loss: 1.9269243440320414

Epoch: 185| Step: 0
Training loss: 1.8368759155273438
Validation loss: 1.9589360247376144

Epoch: 5| Step: 1
Training loss: 1.9837974309921265
Validation loss: 1.9854640140328357

Epoch: 5| Step: 2
Training loss: 2.260073661804199
Validation loss: 2.0028320615009596

Epoch: 5| Step: 3
Training loss: 1.8466579914093018
Validation loss: 2.002527093374601

Epoch: 5| Step: 4
Training loss: 1.5767463445663452
Validation loss: 2.0112858382604455

Epoch: 5| Step: 5
Training loss: 2.3252739906311035
Validation loss: 2.0192368825276694

Epoch: 5| Step: 6
Training loss: 1.7631012201309204
Validation loss: 2.0248237476553967

Epoch: 5| Step: 7
Training loss: 2.4778971672058105
Validation loss: 2.069141270011984

Epoch: 5| Step: 8
Training loss: 2.167091131210327
Validation loss: 2.0698684364236812

Epoch: 5| Step: 9
Training loss: 1.7314064502716064
Validation loss: 2.050193053419872

Epoch: 5| Step: 10
Training loss: 1.829687237739563
Validation loss: 2.055290263186219

Epoch: 186| Step: 0
Training loss: 1.7184470891952515
Validation loss: 2.034568455911452

Epoch: 5| Step: 1
Training loss: 1.5802085399627686
Validation loss: 2.0506138686210877

Epoch: 5| Step: 2
Training loss: 1.726785659790039
Validation loss: 2.0151961054853214

Epoch: 5| Step: 3
Training loss: 2.0227408409118652
Validation loss: 2.0139072915559173

Epoch: 5| Step: 4
Training loss: 2.107809543609619
Validation loss: 1.9968114450413694

Epoch: 5| Step: 5
Training loss: 2.1201682090759277
Validation loss: 1.9535700095597135

Epoch: 5| Step: 6
Training loss: 1.3654758930206299
Validation loss: 1.9352305140546573

Epoch: 5| Step: 7
Training loss: 2.7601590156555176
Validation loss: 1.9236340932948615

Epoch: 5| Step: 8
Training loss: 1.763423204421997
Validation loss: 1.912741054770767

Epoch: 5| Step: 9
Training loss: 1.9211456775665283
Validation loss: 1.9085414050727763

Epoch: 5| Step: 10
Training loss: 2.545947313308716
Validation loss: 1.9112358477807814

Epoch: 187| Step: 0
Training loss: 1.7082231044769287
Validation loss: 1.924271232338362

Epoch: 5| Step: 1
Training loss: 1.6457338333129883
Validation loss: 1.9357811071539437

Epoch: 5| Step: 2
Training loss: 2.0281479358673096
Validation loss: 1.9400121088950866

Epoch: 5| Step: 3
Training loss: 1.721347451210022
Validation loss: 1.9498298732183312

Epoch: 5| Step: 4
Training loss: 1.793217420578003
Validation loss: 1.9881414072487944

Epoch: 5| Step: 5
Training loss: 2.079235553741455
Validation loss: 2.024558932550492

Epoch: 5| Step: 6
Training loss: 2.2107691764831543
Validation loss: 2.0482887427012124

Epoch: 5| Step: 7
Training loss: 2.1364099979400635
Validation loss: 2.092635908434468

Epoch: 5| Step: 8
Training loss: 1.5544803142547607
Validation loss: 2.090248638583768

Epoch: 5| Step: 9
Training loss: 2.165221929550171
Validation loss: 2.074305348498847

Epoch: 5| Step: 10
Training loss: 2.5796189308166504
Validation loss: 2.0527281966260684

Epoch: 188| Step: 0
Training loss: 1.757144570350647
Validation loss: 2.0201514177424933

Epoch: 5| Step: 1
Training loss: 2.0438382625579834
Validation loss: 1.9701832468791673

Epoch: 5| Step: 2
Training loss: 2.6148836612701416
Validation loss: 1.9668783654448807

Epoch: 5| Step: 3
Training loss: 1.7746860980987549
Validation loss: 1.959518140362155

Epoch: 5| Step: 4
Training loss: 1.8432804346084595
Validation loss: 1.9277504054448937

Epoch: 5| Step: 5
Training loss: 1.8594229221343994
Validation loss: 1.9165597320884786

Epoch: 5| Step: 6
Training loss: 2.0964560508728027
Validation loss: 1.908036983141335

Epoch: 5| Step: 7
Training loss: 2.4211974143981934
Validation loss: 1.9420512312202043

Epoch: 5| Step: 8
Training loss: 1.801993727684021
Validation loss: 1.9463005911919378

Epoch: 5| Step: 9
Training loss: 1.6381765604019165
Validation loss: 1.976331441633163

Epoch: 5| Step: 10
Training loss: 1.6321161985397339
Validation loss: 1.9983340194148402

Epoch: 189| Step: 0
Training loss: 1.7894569635391235
Validation loss: 2.023943540870502

Epoch: 5| Step: 1
Training loss: 2.5064072608947754
Validation loss: 2.0498400401043635

Epoch: 5| Step: 2
Training loss: 2.098336696624756
Validation loss: 2.0495933653205953

Epoch: 5| Step: 3
Training loss: 2.367387533187866
Validation loss: 2.043583837888574

Epoch: 5| Step: 4
Training loss: 1.589135766029358
Validation loss: 2.0133195756584086

Epoch: 5| Step: 5
Training loss: 1.8184354305267334
Validation loss: 1.9909834631027714

Epoch: 5| Step: 6
Training loss: 1.952703833580017
Validation loss: 1.9735392575622888

Epoch: 5| Step: 7
Training loss: 1.8364397287368774
Validation loss: 1.9742404594216296

Epoch: 5| Step: 8
Training loss: 1.6934592723846436
Validation loss: 1.9677715891151017

Epoch: 5| Step: 9
Training loss: 1.3598684072494507
Validation loss: 1.9539057593191824

Epoch: 5| Step: 10
Training loss: 1.9927935600280762
Validation loss: 1.9545882619837278

Epoch: 190| Step: 0
Training loss: 2.460083484649658
Validation loss: 1.9519393341515654

Epoch: 5| Step: 1
Training loss: 1.681700348854065
Validation loss: 1.9460216094088811

Epoch: 5| Step: 2
Training loss: 2.3856475353240967
Validation loss: 1.9417081481666976

Epoch: 5| Step: 3
Training loss: 2.12546968460083
Validation loss: 1.9485351154881139

Epoch: 5| Step: 4
Training loss: 2.085608720779419
Validation loss: 1.9375945880848875

Epoch: 5| Step: 5
Training loss: 1.8643022775650024
Validation loss: 1.9411598328621156

Epoch: 5| Step: 6
Training loss: 1.6986215114593506
Validation loss: 1.954501828839702

Epoch: 5| Step: 7
Training loss: 1.792270302772522
Validation loss: 1.9607545304042038

Epoch: 5| Step: 8
Training loss: 1.260083794593811
Validation loss: 1.9475832523838166

Epoch: 5| Step: 9
Training loss: 1.7680442333221436
Validation loss: 1.9431471978464434

Epoch: 5| Step: 10
Training loss: 1.9410947561264038
Validation loss: 1.9437697702838528

Epoch: 191| Step: 0
Training loss: 1.5352119207382202
Validation loss: 1.9751109256539294

Epoch: 5| Step: 1
Training loss: 2.178433656692505
Validation loss: 2.025361866079351

Epoch: 5| Step: 2
Training loss: 1.5048847198486328
Validation loss: 2.0687939941242175

Epoch: 5| Step: 3
Training loss: 2.1528191566467285
Validation loss: 2.080440669931391

Epoch: 5| Step: 4
Training loss: 1.9012420177459717
Validation loss: 2.063644442507016

Epoch: 5| Step: 5
Training loss: 2.058227062225342
Validation loss: 2.041518921493202

Epoch: 5| Step: 6
Training loss: 2.2503788471221924
Validation loss: 2.0212204661420596

Epoch: 5| Step: 7
Training loss: 2.0735790729522705
Validation loss: 1.979321249069706

Epoch: 5| Step: 8
Training loss: 2.2090771198272705
Validation loss: 1.979569613292653

Epoch: 5| Step: 9
Training loss: 1.8453632593154907
Validation loss: 1.9932549589423723

Epoch: 5| Step: 10
Training loss: 1.4507461786270142
Validation loss: 1.970716453367664

Epoch: 192| Step: 0
Training loss: 2.0781970024108887
Validation loss: 1.9533332035105715

Epoch: 5| Step: 1
Training loss: 2.341735363006592
Validation loss: 1.9398448480072843

Epoch: 5| Step: 2
Training loss: 1.7406669855117798
Validation loss: 1.91730837668142

Epoch: 5| Step: 3
Training loss: 1.5046509504318237
Validation loss: 1.923571522517871

Epoch: 5| Step: 4
Training loss: 2.268134593963623
Validation loss: 1.9069876004290838

Epoch: 5| Step: 5
Training loss: 2.1454548835754395
Validation loss: 1.9276194136629823

Epoch: 5| Step: 6
Training loss: 2.3433187007904053
Validation loss: 1.9402811527252197

Epoch: 5| Step: 7
Training loss: 1.6782852411270142
Validation loss: 1.9381824949736237

Epoch: 5| Step: 8
Training loss: 1.8836748600006104
Validation loss: 1.9415800750896495

Epoch: 5| Step: 9
Training loss: 1.2771755456924438
Validation loss: 1.9763490922989384

Epoch: 5| Step: 10
Training loss: 1.6734503507614136
Validation loss: 1.9970590914449384

Epoch: 193| Step: 0
Training loss: 1.2056081295013428
Validation loss: 2.03759971357161

Epoch: 5| Step: 1
Training loss: 2.0412344932556152
Validation loss: 2.0577062842666463

Epoch: 5| Step: 2
Training loss: 2.466256618499756
Validation loss: 2.1027455663168304

Epoch: 5| Step: 3
Training loss: 1.9284389019012451
Validation loss: 2.0638381691389185

Epoch: 5| Step: 4
Training loss: 1.5833178758621216
Validation loss: 2.0185934125736194

Epoch: 5| Step: 5
Training loss: 1.7868196964263916
Validation loss: 1.9590100780610116

Epoch: 5| Step: 6
Training loss: 1.5722450017929077
Validation loss: 1.939459144428212

Epoch: 5| Step: 7
Training loss: 2.0725722312927246
Validation loss: 1.967437595449468

Epoch: 5| Step: 8
Training loss: 2.1922125816345215
Validation loss: 1.985260344320728

Epoch: 5| Step: 9
Training loss: 1.889431357383728
Validation loss: 2.0127478414966213

Epoch: 5| Step: 10
Training loss: 2.337285280227661
Validation loss: 2.00835334613759

Epoch: 194| Step: 0
Training loss: 1.653039574623108
Validation loss: 1.9779655407833796

Epoch: 5| Step: 1
Training loss: 1.9052956104278564
Validation loss: 1.9644443988800049

Epoch: 5| Step: 2
Training loss: 1.934128999710083
Validation loss: 1.9611437218163603

Epoch: 5| Step: 3
Training loss: 1.4215595722198486
Validation loss: 1.9619896155531689

Epoch: 5| Step: 4
Training loss: 1.6736701726913452
Validation loss: 1.962470914727898

Epoch: 5| Step: 5
Training loss: 1.6716506481170654
Validation loss: 1.9683810049487698

Epoch: 5| Step: 6
Training loss: 2.252647876739502
Validation loss: 1.9406871808472501

Epoch: 5| Step: 7
Training loss: 2.4181325435638428
Validation loss: 1.937796320966495

Epoch: 5| Step: 8
Training loss: 1.8128139972686768
Validation loss: 1.9377649317505539

Epoch: 5| Step: 9
Training loss: 2.0449397563934326
Validation loss: 1.9537306190818868

Epoch: 5| Step: 10
Training loss: 1.832997441291809
Validation loss: 1.9655727724875174

Epoch: 195| Step: 0
Training loss: 1.580836534500122
Validation loss: 1.962001141681466

Epoch: 5| Step: 1
Training loss: 2.196528434753418
Validation loss: 1.9432704115426669

Epoch: 5| Step: 2
Training loss: 1.9657920598983765
Validation loss: 1.9388257547091412

Epoch: 5| Step: 3
Training loss: 1.8058143854141235
Validation loss: 1.941180589378521

Epoch: 5| Step: 4
Training loss: 1.9999580383300781
Validation loss: 1.9419974614215154

Epoch: 5| Step: 5
Training loss: 1.5977691411972046
Validation loss: 1.9441619791010374

Epoch: 5| Step: 6
Training loss: 1.9522438049316406
Validation loss: 1.9471899386375182

Epoch: 5| Step: 7
Training loss: 2.066697597503662
Validation loss: 1.943617856630715

Epoch: 5| Step: 8
Training loss: 1.7984917163848877
Validation loss: 1.9801235045156171

Epoch: 5| Step: 9
Training loss: 1.9542049169540405
Validation loss: 2.001487478133171

Epoch: 5| Step: 10
Training loss: 1.506088376045227
Validation loss: 2.032200869693551

Epoch: 196| Step: 0
Training loss: 2.3765170574188232
Validation loss: 2.077310736461352

Epoch: 5| Step: 1
Training loss: 1.8929885625839233
Validation loss: 2.0784727565703855

Epoch: 5| Step: 2
Training loss: 1.895729422569275
Validation loss: 2.0384180981625795

Epoch: 5| Step: 3
Training loss: 1.3092105388641357
Validation loss: 2.000291588485882

Epoch: 5| Step: 4
Training loss: 1.5288726091384888
Validation loss: 1.95829338283949

Epoch: 5| Step: 5
Training loss: 1.8100471496582031
Validation loss: 1.9416283715155818

Epoch: 5| Step: 6
Training loss: 2.2848873138427734
Validation loss: 1.9483867858045845

Epoch: 5| Step: 7
Training loss: 2.1821091175079346
Validation loss: 1.926756533243323

Epoch: 5| Step: 8
Training loss: 1.8970600366592407
Validation loss: 1.9476698829281716

Epoch: 5| Step: 9
Training loss: 1.9758046865463257
Validation loss: 1.9669952905306252

Epoch: 5| Step: 10
Training loss: 1.6556496620178223
Validation loss: 1.9565478063398791

Epoch: 197| Step: 0
Training loss: 1.5297176837921143
Validation loss: 1.9586570570545812

Epoch: 5| Step: 1
Training loss: 2.0606255531311035
Validation loss: 1.9453110182157127

Epoch: 5| Step: 2
Training loss: 2.1463630199432373
Validation loss: 1.9712403794770599

Epoch: 5| Step: 3
Training loss: 1.976239800453186
Validation loss: 1.9895316695654264

Epoch: 5| Step: 4
Training loss: 2.3918747901916504
Validation loss: 1.9961620915320613

Epoch: 5| Step: 5
Training loss: 1.4000240564346313
Validation loss: 2.003173146196591

Epoch: 5| Step: 6
Training loss: 1.5462337732315063
Validation loss: 2.0101170847492833

Epoch: 5| Step: 7
Training loss: 1.892034888267517
Validation loss: 1.9950198486287107

Epoch: 5| Step: 8
Training loss: 1.904558539390564
Validation loss: 1.993286476340345

Epoch: 5| Step: 9
Training loss: 1.7074205875396729
Validation loss: 1.9804703138207878

Epoch: 5| Step: 10
Training loss: 1.729414939880371
Validation loss: 1.9624219876463695

Epoch: 198| Step: 0
Training loss: 1.6548736095428467
Validation loss: 1.9728833372874925

Epoch: 5| Step: 1
Training loss: 1.6699085235595703
Validation loss: 1.9947102992765364

Epoch: 5| Step: 2
Training loss: 1.842995285987854
Validation loss: 1.9584648237433484

Epoch: 5| Step: 3
Training loss: 1.937842607498169
Validation loss: 1.9428526009282758

Epoch: 5| Step: 4
Training loss: 2.1649868488311768
Validation loss: 1.9398122679802678

Epoch: 5| Step: 5
Training loss: 1.9662525653839111
Validation loss: 1.9305756348435597

Epoch: 5| Step: 6
Training loss: 1.627000093460083
Validation loss: 1.9253973730148808

Epoch: 5| Step: 7
Training loss: 1.7625669240951538
Validation loss: 1.9369549546190488

Epoch: 5| Step: 8
Training loss: 1.7516428232192993
Validation loss: 1.9355324558032456

Epoch: 5| Step: 9
Training loss: 1.7407715320587158
Validation loss: 1.9350522384848645

Epoch: 5| Step: 10
Training loss: 1.8467836380004883
Validation loss: 1.9493510453931746

Epoch: 199| Step: 0
Training loss: 1.6943676471710205
Validation loss: 1.9600323938554334

Epoch: 5| Step: 1
Training loss: 1.6476433277130127
Validation loss: 1.9800503741028488

Epoch: 5| Step: 2
Training loss: 1.8605690002441406
Validation loss: 2.0206718906279533

Epoch: 5| Step: 3
Training loss: 1.6464979648590088
Validation loss: 2.033220293701336

Epoch: 5| Step: 4
Training loss: 1.5475666522979736
Validation loss: 1.973302214376388

Epoch: 5| Step: 5
Training loss: 1.8582162857055664
Validation loss: 1.9504538197671213

Epoch: 5| Step: 6
Training loss: 1.8810813426971436
Validation loss: 1.9220239500845633

Epoch: 5| Step: 7
Training loss: 2.20692777633667
Validation loss: 1.9139891568050589

Epoch: 5| Step: 8
Training loss: 1.515096664428711
Validation loss: 1.9029311210878435

Epoch: 5| Step: 9
Training loss: 1.9073374271392822
Validation loss: 1.9203173191316667

Epoch: 5| Step: 10
Training loss: 2.3301897048950195
Validation loss: 1.9289937262894006

Epoch: 200| Step: 0
Training loss: 1.5258229970932007
Validation loss: 1.9457682217321088

Epoch: 5| Step: 1
Training loss: 2.149925947189331
Validation loss: 1.9924360372686898

Epoch: 5| Step: 2
Training loss: 1.4830443859100342
Validation loss: 2.0135080698997743

Epoch: 5| Step: 3
Training loss: 1.3648669719696045
Validation loss: 2.0218369601875223

Epoch: 5| Step: 4
Training loss: 1.6992985010147095
Validation loss: 2.042319811800475

Epoch: 5| Step: 5
Training loss: 2.2000648975372314
Validation loss: 2.0318024594296693

Epoch: 5| Step: 6
Training loss: 2.5638811588287354
Validation loss: 2.043534732634021

Epoch: 5| Step: 7
Training loss: 1.5138229131698608
Validation loss: 2.034134821225238

Epoch: 5| Step: 8
Training loss: 1.9822791814804077
Validation loss: 2.0006099080526702

Epoch: 5| Step: 9
Training loss: 1.5700881481170654
Validation loss: 1.9621384054101922

Epoch: 5| Step: 10
Training loss: 1.6371498107910156
Validation loss: 1.9299749892245057

Epoch: 201| Step: 0
Training loss: 2.0173254013061523
Validation loss: 1.897289788851174

Epoch: 5| Step: 1
Training loss: 2.052297592163086
Validation loss: 1.8975023838781542

Epoch: 5| Step: 2
Training loss: 1.4870235919952393
Validation loss: 1.8942755858103435

Epoch: 5| Step: 3
Training loss: 2.297449827194214
Validation loss: 1.9061201169926634

Epoch: 5| Step: 4
Training loss: 1.207556128501892
Validation loss: 1.9177500663265106

Epoch: 5| Step: 5
Training loss: 1.7574958801269531
Validation loss: 1.9238252460315663

Epoch: 5| Step: 6
Training loss: 2.1932947635650635
Validation loss: 1.9504777577615553

Epoch: 5| Step: 7
Training loss: 2.374878168106079
Validation loss: 1.9848519986675632

Epoch: 5| Step: 8
Training loss: 1.5549691915512085
Validation loss: 2.0279049847715642

Epoch: 5| Step: 9
Training loss: 0.9708951115608215
Validation loss: 2.0264254359788794

Epoch: 5| Step: 10
Training loss: 2.201978921890259
Validation loss: 2.026669407403597

Epoch: 202| Step: 0
Training loss: 1.8344892263412476
Validation loss: 1.9836844462220387

Epoch: 5| Step: 1
Training loss: 1.5865733623504639
Validation loss: 1.9543658392403715

Epoch: 5| Step: 2
Training loss: 1.903781533241272
Validation loss: 1.9161608155055712

Epoch: 5| Step: 3
Training loss: 1.8097187280654907
Validation loss: 1.9180223339347429

Epoch: 5| Step: 4
Training loss: 1.5721696615219116
Validation loss: 1.9114134298857821

Epoch: 5| Step: 5
Training loss: 1.3577234745025635
Validation loss: 1.8990771616658857

Epoch: 5| Step: 6
Training loss: 2.080744743347168
Validation loss: 1.9048016430229269

Epoch: 5| Step: 7
Training loss: 1.8311811685562134
Validation loss: 1.8960972139912267

Epoch: 5| Step: 8
Training loss: 2.0500502586364746
Validation loss: 1.9163189626509143

Epoch: 5| Step: 9
Training loss: 1.5447458028793335
Validation loss: 1.925397547342444

Epoch: 5| Step: 10
Training loss: 1.9956492185592651
Validation loss: 1.9580996574894074

Epoch: 203| Step: 0
Training loss: 1.5664610862731934
Validation loss: 1.9813358450448642

Epoch: 5| Step: 1
Training loss: 2.0691447257995605
Validation loss: 1.988455472453948

Epoch: 5| Step: 2
Training loss: 1.7515838146209717
Validation loss: 2.0035796626921623

Epoch: 5| Step: 3
Training loss: 1.6839491128921509
Validation loss: 2.0065060456593833

Epoch: 5| Step: 4
Training loss: 2.310748338699341
Validation loss: 2.00007596195385

Epoch: 5| Step: 5
Training loss: 1.7720270156860352
Validation loss: 1.9792145888010662

Epoch: 5| Step: 6
Training loss: 1.6208155155181885
Validation loss: 1.9585125548865205

Epoch: 5| Step: 7
Training loss: 1.9538723230361938
Validation loss: 1.9239457268868723

Epoch: 5| Step: 8
Training loss: 1.503305196762085
Validation loss: 1.9021025934526998

Epoch: 5| Step: 9
Training loss: 1.6247966289520264
Validation loss: 1.9003982390126875

Epoch: 5| Step: 10
Training loss: 1.740663766860962
Validation loss: 1.8911174766479

Epoch: 204| Step: 0
Training loss: 1.824095368385315
Validation loss: 1.8956148509056336

Epoch: 5| Step: 1
Training loss: 1.69651198387146
Validation loss: 1.926757360017428

Epoch: 5| Step: 2
Training loss: 1.8989484310150146
Validation loss: 1.9378998651299426

Epoch: 5| Step: 3
Training loss: 1.8660186529159546
Validation loss: 1.9490202293601087

Epoch: 5| Step: 4
Training loss: 1.433239221572876
Validation loss: 2.006211419259348

Epoch: 5| Step: 5
Training loss: 1.6999499797821045
Validation loss: 2.0068375295208347

Epoch: 5| Step: 6
Training loss: 2.2460265159606934
Validation loss: 2.022035571836656

Epoch: 5| Step: 7
Training loss: 1.9358545541763306
Validation loss: 2.0182428462530977

Epoch: 5| Step: 8
Training loss: 1.9171907901763916
Validation loss: 1.9776393957035516

Epoch: 5| Step: 9
Training loss: 1.513282299041748
Validation loss: 1.9624755485083467

Epoch: 5| Step: 10
Training loss: 1.452109932899475
Validation loss: 1.950557925367868

Epoch: 205| Step: 0
Training loss: 1.2812564373016357
Validation loss: 1.9383231606534732

Epoch: 5| Step: 1
Training loss: 1.6887378692626953
Validation loss: 1.924909273783366

Epoch: 5| Step: 2
Training loss: 2.152991771697998
Validation loss: 1.90483675208143

Epoch: 5| Step: 3
Training loss: 1.9834572076797485
Validation loss: 1.9534675664799188

Epoch: 5| Step: 4
Training loss: 1.8479297161102295
Validation loss: 1.9704864973663

Epoch: 5| Step: 5
Training loss: 1.9329173564910889
Validation loss: 1.9885001362010997

Epoch: 5| Step: 6
Training loss: 1.531612753868103
Validation loss: 1.9917183088999924

Epoch: 5| Step: 7
Training loss: 1.6497821807861328
Validation loss: 1.9760641590241463

Epoch: 5| Step: 8
Training loss: 1.6844943761825562
Validation loss: 1.9696959346853278

Epoch: 5| Step: 9
Training loss: 1.7864326238632202
Validation loss: 1.9437028490087038

Epoch: 5| Step: 10
Training loss: 1.5440727472305298
Validation loss: 1.9518164383467806

Epoch: 206| Step: 0
Training loss: 1.6050151586532593
Validation loss: 1.9417607963726085

Epoch: 5| Step: 1
Training loss: 1.3940260410308838
Validation loss: 1.9273953976169709

Epoch: 5| Step: 2
Training loss: 0.9751529693603516
Validation loss: 1.9343813670578824

Epoch: 5| Step: 3
Training loss: 1.8642009496688843
Validation loss: 1.9549088849816272

Epoch: 5| Step: 4
Training loss: 2.178511142730713
Validation loss: 1.954562262822223

Epoch: 5| Step: 5
Training loss: 2.207054853439331
Validation loss: 1.9501658985691686

Epoch: 5| Step: 6
Training loss: 2.1251883506774902
Validation loss: 1.9693263858877204

Epoch: 5| Step: 7
Training loss: 1.9964542388916016
Validation loss: 1.9662132827184533

Epoch: 5| Step: 8
Training loss: 1.5997731685638428
Validation loss: 1.9671303687557098

Epoch: 5| Step: 9
Training loss: 1.129716157913208
Validation loss: 1.975394251526043

Epoch: 5| Step: 10
Training loss: 1.8909708261489868
Validation loss: 2.0068552827322357

Epoch: 207| Step: 0
Training loss: 1.5601698160171509
Validation loss: 1.9941726769170454

Epoch: 5| Step: 1
Training loss: 1.669593095779419
Validation loss: 1.97210741812183

Epoch: 5| Step: 2
Training loss: 1.665043592453003
Validation loss: 1.976807519953738

Epoch: 5| Step: 3
Training loss: 2.0314536094665527
Validation loss: 1.9621373543175318

Epoch: 5| Step: 4
Training loss: 1.390364408493042
Validation loss: 1.9626095871771536

Epoch: 5| Step: 5
Training loss: 1.0473476648330688
Validation loss: 1.9705815763883694

Epoch: 5| Step: 6
Training loss: 1.7584270238876343
Validation loss: 2.000225854176347

Epoch: 5| Step: 7
Training loss: 2.1438229084014893
Validation loss: 1.9852412246888684

Epoch: 5| Step: 8
Training loss: 2.1899330615997314
Validation loss: 1.9585171886669692

Epoch: 5| Step: 9
Training loss: 1.854327917098999
Validation loss: 1.929111655040454

Epoch: 5| Step: 10
Training loss: 1.8484013080596924
Validation loss: 1.9211567627486361

Epoch: 208| Step: 0
Training loss: 1.8752119541168213
Validation loss: 1.899738375858594

Epoch: 5| Step: 1
Training loss: 1.596505880355835
Validation loss: 1.8882008726878832

Epoch: 5| Step: 2
Training loss: 1.8638108968734741
Validation loss: 1.8943563917631745

Epoch: 5| Step: 3
Training loss: 2.5878546237945557
Validation loss: 1.8999774507296983

Epoch: 5| Step: 4
Training loss: 2.203183650970459
Validation loss: 1.911866376476903

Epoch: 5| Step: 5
Training loss: 0.9175392389297485
Validation loss: 1.9772080836757537

Epoch: 5| Step: 6
Training loss: 1.4419752359390259
Validation loss: 2.03470185495192

Epoch: 5| Step: 7
Training loss: 1.9275553226470947
Validation loss: 2.1008499142944173

Epoch: 5| Step: 8
Training loss: 1.3636085987091064
Validation loss: 2.1005809294280184

Epoch: 5| Step: 9
Training loss: 1.6228606700897217
Validation loss: 2.090941988011842

Epoch: 5| Step: 10
Training loss: 1.968712568283081
Validation loss: 2.0337405717501076

Epoch: 209| Step: 0
Training loss: 1.7891151905059814
Validation loss: 1.9630356911690003

Epoch: 5| Step: 1
Training loss: 1.360471487045288
Validation loss: 1.9107000135606336

Epoch: 5| Step: 2
Training loss: 1.440822958946228
Validation loss: 1.9114397495023665

Epoch: 5| Step: 3
Training loss: 2.1235578060150146
Validation loss: 1.9104466463929863

Epoch: 5| Step: 4
Training loss: 1.1867634057998657
Validation loss: 1.8948294552423621

Epoch: 5| Step: 5
Training loss: 2.282484769821167
Validation loss: 1.923315917291949

Epoch: 5| Step: 6
Training loss: 1.7873035669326782
Validation loss: 1.917408215102329

Epoch: 5| Step: 7
Training loss: 1.3339717388153076
Validation loss: 1.9308440198180497

Epoch: 5| Step: 8
Training loss: 2.7998313903808594
Validation loss: 1.962342954451038

Epoch: 5| Step: 9
Training loss: 1.7682949304580688
Validation loss: 1.9648555555651266

Epoch: 5| Step: 10
Training loss: 1.2811849117279053
Validation loss: 1.9755761597746162

Epoch: 210| Step: 0
Training loss: 1.6721343994140625
Validation loss: 1.9700576445107818

Epoch: 5| Step: 1
Training loss: 1.589752435684204
Validation loss: 1.9614522175122333

Epoch: 5| Step: 2
Training loss: 2.2659335136413574
Validation loss: 1.9558916258555588

Epoch: 5| Step: 3
Training loss: 1.7808353900909424
Validation loss: 1.953174925619556

Epoch: 5| Step: 4
Training loss: 1.5086205005645752
Validation loss: 1.920059334847235

Epoch: 5| Step: 5
Training loss: 2.039785623550415
Validation loss: 1.9396901040948846

Epoch: 5| Step: 6
Training loss: 1.9153587818145752
Validation loss: 1.9236302362975253

Epoch: 5| Step: 7
Training loss: 1.601051926612854
Validation loss: 1.9282162163847236

Epoch: 5| Step: 8
Training loss: 1.5664445161819458
Validation loss: 1.9486199989113757

Epoch: 5| Step: 9
Training loss: 1.068661093711853
Validation loss: 1.9690920499063307

Epoch: 5| Step: 10
Training loss: 1.580278992652893
Validation loss: 1.982556623797263

Epoch: 211| Step: 0
Training loss: 1.3757308721542358
Validation loss: 1.983142634873749

Epoch: 5| Step: 1
Training loss: 1.6451318264007568
Validation loss: 1.9669288512199157

Epoch: 5| Step: 2
Training loss: 1.3663305044174194
Validation loss: 1.9578844526762604

Epoch: 5| Step: 3
Training loss: 1.8960834741592407
Validation loss: 1.9639713277098954

Epoch: 5| Step: 4
Training loss: 2.025496006011963
Validation loss: 1.9653288536174323

Epoch: 5| Step: 5
Training loss: 1.5427913665771484
Validation loss: 1.9945312366690686

Epoch: 5| Step: 6
Training loss: 1.9243173599243164
Validation loss: 1.9733308848514353

Epoch: 5| Step: 7
Training loss: 1.899592399597168
Validation loss: 1.9811455331822878

Epoch: 5| Step: 8
Training loss: 1.6527646780014038
Validation loss: 1.9670651458924817

Epoch: 5| Step: 9
Training loss: 1.647587776184082
Validation loss: 1.9485459789153068

Epoch: 5| Step: 10
Training loss: 1.2546839714050293
Validation loss: 1.9520364269133537

Epoch: 212| Step: 0
Training loss: 1.4216883182525635
Validation loss: 1.9573436808842484

Epoch: 5| Step: 1
Training loss: 1.969657301902771
Validation loss: 1.9615054489463888

Epoch: 5| Step: 2
Training loss: 1.5363878011703491
Validation loss: 1.971026260365722

Epoch: 5| Step: 3
Training loss: 1.7217212915420532
Validation loss: 1.990024535886703

Epoch: 5| Step: 4
Training loss: 1.5823490619659424
Validation loss: 1.9886223539229362

Epoch: 5| Step: 5
Training loss: 1.6540000438690186
Validation loss: 1.9792038561195455

Epoch: 5| Step: 6
Training loss: 2.430446147918701
Validation loss: 1.970336737171296

Epoch: 5| Step: 7
Training loss: 1.5886526107788086
Validation loss: 1.972906498498814

Epoch: 5| Step: 8
Training loss: 1.4120852947235107
Validation loss: 1.983750993205655

Epoch: 5| Step: 9
Training loss: 1.5460340976715088
Validation loss: 1.9799230662725305

Epoch: 5| Step: 10
Training loss: 1.8357652425765991
Validation loss: 1.9531070904065204

Epoch: 213| Step: 0
Training loss: 1.6561486721038818
Validation loss: 1.927543975973642

Epoch: 5| Step: 1
Training loss: 1.547820806503296
Validation loss: 1.892511131942913

Epoch: 5| Step: 2
Training loss: 1.547390341758728
Validation loss: 1.8796978330099454

Epoch: 5| Step: 3
Training loss: 2.1367058753967285
Validation loss: 1.8824299714898551

Epoch: 5| Step: 4
Training loss: 1.6422134637832642
Validation loss: 1.8721614063427012

Epoch: 5| Step: 5
Training loss: 1.6985931396484375
Validation loss: 1.8744724668482298

Epoch: 5| Step: 6
Training loss: 1.9524799585342407
Validation loss: 1.8882800571380123

Epoch: 5| Step: 7
Training loss: 1.6640443801879883
Validation loss: 1.916353456435665

Epoch: 5| Step: 8
Training loss: 1.5324690341949463
Validation loss: 1.9384498801282657

Epoch: 5| Step: 9
Training loss: 1.149967908859253
Validation loss: 1.9840958541439426

Epoch: 5| Step: 10
Training loss: 1.9111605882644653
Validation loss: 2.014648408018133

Epoch: 214| Step: 0
Training loss: 1.3473036289215088
Validation loss: 2.009593133003481

Epoch: 5| Step: 1
Training loss: 1.437471628189087
Validation loss: 2.0269630544929096

Epoch: 5| Step: 2
Training loss: 1.4045307636260986
Validation loss: 2.022480521150815

Epoch: 5| Step: 3
Training loss: 1.5115201473236084
Validation loss: 1.9914470359843264

Epoch: 5| Step: 4
Training loss: 1.7624008655548096
Validation loss: 1.9646827328589656

Epoch: 5| Step: 5
Training loss: 2.2862002849578857
Validation loss: 1.9550343123815392

Epoch: 5| Step: 6
Training loss: 1.4126977920532227
Validation loss: 1.9310619267084266

Epoch: 5| Step: 7
Training loss: 1.9820410013198853
Validation loss: 1.908867682180097

Epoch: 5| Step: 8
Training loss: 2.372509241104126
Validation loss: 1.9220316563883135

Epoch: 5| Step: 9
Training loss: 1.5598825216293335
Validation loss: 1.920567779130833

Epoch: 5| Step: 10
Training loss: 1.4514281749725342
Validation loss: 1.9263339709210139

Epoch: 215| Step: 0
Training loss: 1.7264436483383179
Validation loss: 1.948619725883648

Epoch: 5| Step: 1
Training loss: 1.7626543045043945
Validation loss: 1.950120069647348

Epoch: 5| Step: 2
Training loss: 2.0569491386413574
Validation loss: 1.9525327541494881

Epoch: 5| Step: 3
Training loss: 1.5768195390701294
Validation loss: 1.958852485943866

Epoch: 5| Step: 4
Training loss: 1.6844451427459717
Validation loss: 1.9416416716831986

Epoch: 5| Step: 5
Training loss: 1.455260992050171
Validation loss: 1.9556493118245115

Epoch: 5| Step: 6
Training loss: 1.1283495426177979
Validation loss: 1.9669310738963466

Epoch: 5| Step: 7
Training loss: 1.903437852859497
Validation loss: 1.9771848186369865

Epoch: 5| Step: 8
Training loss: 1.3738267421722412
Validation loss: 1.9651710346180906

Epoch: 5| Step: 9
Training loss: 2.14453387260437
Validation loss: 1.9632945009457168

Epoch: 5| Step: 10
Training loss: 1.1535236835479736
Validation loss: 1.9513925313949585

Epoch: 216| Step: 0
Training loss: 1.651261568069458
Validation loss: 1.9643612318141486

Epoch: 5| Step: 1
Training loss: 1.677973985671997
Validation loss: 1.9523232918913647

Epoch: 5| Step: 2
Training loss: 1.7542569637298584
Validation loss: 1.9696879950902795

Epoch: 5| Step: 3
Training loss: 1.251793622970581
Validation loss: 1.9820274870882753

Epoch: 5| Step: 4
Training loss: 1.910400152206421
Validation loss: 1.9831588255461825

Epoch: 5| Step: 5
Training loss: 1.7235767841339111
Validation loss: 1.9938071402170325

Epoch: 5| Step: 6
Training loss: 1.424533486366272
Validation loss: 1.9703531803623322

Epoch: 5| Step: 7
Training loss: 1.4970608949661255
Validation loss: 1.9609973276815107

Epoch: 5| Step: 8
Training loss: 1.4522929191589355
Validation loss: 1.9203629596259004

Epoch: 5| Step: 9
Training loss: 1.9541963338851929
Validation loss: 1.9107841317371657

Epoch: 5| Step: 10
Training loss: 1.7606366872787476
Validation loss: 1.9049452645804292

Epoch: 217| Step: 0
Training loss: 1.575650930404663
Validation loss: 1.8908236154945948

Epoch: 5| Step: 1
Training loss: 1.5937113761901855
Validation loss: 1.9077919298602688

Epoch: 5| Step: 2
Training loss: 1.5093615055084229
Validation loss: 1.9031358406107912

Epoch: 5| Step: 3
Training loss: 1.611755609512329
Validation loss: 1.8866468168074084

Epoch: 5| Step: 4
Training loss: 1.7211288213729858
Validation loss: 1.935869852701823

Epoch: 5| Step: 5
Training loss: 1.607407569885254
Validation loss: 1.9689435676861835

Epoch: 5| Step: 6
Training loss: 2.1300747394561768
Validation loss: 1.9871845142815703

Epoch: 5| Step: 7
Training loss: 1.159172534942627
Validation loss: 1.9973707493915354

Epoch: 5| Step: 8
Training loss: 1.714024543762207
Validation loss: 2.0114724456623034

Epoch: 5| Step: 9
Training loss: 1.9523992538452148
Validation loss: 2.0066468074757564

Epoch: 5| Step: 10
Training loss: 1.7657768726348877
Validation loss: 1.9724428602444228

Epoch: 218| Step: 0
Training loss: 1.4708659648895264
Validation loss: 1.9487907771141297

Epoch: 5| Step: 1
Training loss: 1.6717653274536133
Validation loss: 1.917627707604439

Epoch: 5| Step: 2
Training loss: 1.5583820343017578
Validation loss: 1.8690651873106598

Epoch: 5| Step: 3
Training loss: 1.9447994232177734
Validation loss: 1.869064578446009

Epoch: 5| Step: 4
Training loss: 1.7573589086532593
Validation loss: 1.8960332178300427

Epoch: 5| Step: 5
Training loss: 1.4623867273330688
Validation loss: 1.9235033694133963

Epoch: 5| Step: 6
Training loss: 1.6747844219207764
Validation loss: 1.9748531362061859

Epoch: 5| Step: 7
Training loss: 1.5324459075927734
Validation loss: 1.9865268584220641

Epoch: 5| Step: 8
Training loss: 1.6120989322662354
Validation loss: 1.9593082192123576

Epoch: 5| Step: 9
Training loss: 2.0980067253112793
Validation loss: 1.9509578392069826

Epoch: 5| Step: 10
Training loss: 1.4103707075119019
Validation loss: 1.9345796979883665

Epoch: 219| Step: 0
Training loss: 1.3215025663375854
Validation loss: 1.9630618851671937

Epoch: 5| Step: 1
Training loss: 2.109332799911499
Validation loss: 2.03015386930076

Epoch: 5| Step: 2
Training loss: 1.5828783512115479
Validation loss: 2.036086146549512

Epoch: 5| Step: 3
Training loss: 1.834946632385254
Validation loss: 2.0388170416637132

Epoch: 5| Step: 4
Training loss: 1.3262426853179932
Validation loss: 2.0034802959811304

Epoch: 5| Step: 5
Training loss: 1.3984113931655884
Validation loss: 2.0176560289116314

Epoch: 5| Step: 6
Training loss: 1.8480408191680908
Validation loss: 2.077443681737428

Epoch: 5| Step: 7
Training loss: 1.9254900217056274
Validation loss: 2.0807618941030195

Epoch: 5| Step: 8
Training loss: 1.9505504369735718
Validation loss: 2.0177899304256646

Epoch: 5| Step: 9
Training loss: 1.4819226264953613
Validation loss: 1.9824599142997497

Epoch: 5| Step: 10
Training loss: 1.7224186658859253
Validation loss: 1.939867026062422

Epoch: 220| Step: 0
Training loss: 1.616333246231079
Validation loss: 1.8987250558791622

Epoch: 5| Step: 1
Training loss: 1.941150426864624
Validation loss: 1.906970352254888

Epoch: 5| Step: 2
Training loss: 2.042990207672119
Validation loss: 1.9409684519613943

Epoch: 5| Step: 3
Training loss: 2.0135624408721924
Validation loss: 1.9626980186790548

Epoch: 5| Step: 4
Training loss: 2.2451272010803223
Validation loss: 1.9590374397975143

Epoch: 5| Step: 5
Training loss: 1.7688277959823608
Validation loss: 1.9435051923157067

Epoch: 5| Step: 6
Training loss: 1.2346179485321045
Validation loss: 1.9403072890414987

Epoch: 5| Step: 7
Training loss: 1.6927350759506226
Validation loss: 1.9091360222908758

Epoch: 5| Step: 8
Training loss: 1.1448153257369995
Validation loss: 1.92283038426471

Epoch: 5| Step: 9
Training loss: 1.2318198680877686
Validation loss: 1.9479251702626545

Epoch: 5| Step: 10
Training loss: 2.035177230834961
Validation loss: 2.0328875241741056

Epoch: 221| Step: 0
Training loss: 1.614977478981018
Validation loss: 2.0624353296013287

Epoch: 5| Step: 1
Training loss: 1.9603404998779297
Validation loss: 2.03941358289411

Epoch: 5| Step: 2
Training loss: 1.4527784585952759
Validation loss: 1.992869218190511

Epoch: 5| Step: 3
Training loss: 1.5784292221069336
Validation loss: 1.9591074041140977

Epoch: 5| Step: 4
Training loss: 1.230669379234314
Validation loss: 1.9476065174225838

Epoch: 5| Step: 5
Training loss: 1.9533212184906006
Validation loss: 1.9357146928387303

Epoch: 5| Step: 6
Training loss: 1.9686129093170166
Validation loss: 1.896377771131454

Epoch: 5| Step: 7
Training loss: 1.379790186882019
Validation loss: 1.8771220740451608

Epoch: 5| Step: 8
Training loss: 1.8247158527374268
Validation loss: 1.8711976723004413

Epoch: 5| Step: 9
Training loss: 1.2175763845443726
Validation loss: 1.881553202547053

Epoch: 5| Step: 10
Training loss: 1.5177582502365112
Validation loss: 1.888653984633825

Epoch: 222| Step: 0
Training loss: 1.1067893505096436
Validation loss: 1.9060352771512923

Epoch: 5| Step: 1
Training loss: 1.0886776447296143
Validation loss: 1.924257311769711

Epoch: 5| Step: 2
Training loss: 1.7164175510406494
Validation loss: 1.94967964003163

Epoch: 5| Step: 3
Training loss: 1.9225441217422485
Validation loss: 1.9573107214384182

Epoch: 5| Step: 4
Training loss: 1.551428198814392
Validation loss: 1.9779297959419988

Epoch: 5| Step: 5
Training loss: 1.6992905139923096
Validation loss: 1.9820935046801003

Epoch: 5| Step: 6
Training loss: 1.8855609893798828
Validation loss: 1.9778251468494374

Epoch: 5| Step: 7
Training loss: 1.6075725555419922
Validation loss: 1.967861008900468

Epoch: 5| Step: 8
Training loss: 0.9339059591293335
Validation loss: 1.9346253436098817

Epoch: 5| Step: 9
Training loss: 1.893103003501892
Validation loss: 1.9404045497217486

Epoch: 5| Step: 10
Training loss: 1.7546977996826172
Validation loss: 1.9260125108944472

Epoch: 223| Step: 0
Training loss: 1.7739193439483643
Validation loss: 1.9239477175538258

Epoch: 5| Step: 1
Training loss: 1.8746674060821533
Validation loss: 1.9163873093102568

Epoch: 5| Step: 2
Training loss: 1.362989902496338
Validation loss: 1.9203695263913882

Epoch: 5| Step: 3
Training loss: 1.5459439754486084
Validation loss: 1.9432446815634286

Epoch: 5| Step: 4
Training loss: 1.8634111881256104
Validation loss: 1.9375377214083107

Epoch: 5| Step: 5
Training loss: 1.5020246505737305
Validation loss: 1.924508358842583

Epoch: 5| Step: 6
Training loss: 1.4351975917816162
Validation loss: 1.9532366683406215

Epoch: 5| Step: 7
Training loss: 1.2354736328125
Validation loss: 1.945797848445113

Epoch: 5| Step: 8
Training loss: 1.622092843055725
Validation loss: 1.9506787305237145

Epoch: 5| Step: 9
Training loss: 1.4105665683746338
Validation loss: 1.9470383044212096

Epoch: 5| Step: 10
Training loss: 1.6109535694122314
Validation loss: 1.9449765823220695

Epoch: 224| Step: 0
Training loss: 1.6782104969024658
Validation loss: 1.9601677335718626

Epoch: 5| Step: 1
Training loss: 1.5369460582733154
Validation loss: 1.944619559472607

Epoch: 5| Step: 2
Training loss: 1.2455499172210693
Validation loss: 1.961320477147256

Epoch: 5| Step: 3
Training loss: 1.7952388525009155
Validation loss: 1.9387748087606123

Epoch: 5| Step: 4
Training loss: 1.529211401939392
Validation loss: 1.9166750497715448

Epoch: 5| Step: 5
Training loss: 1.7086957693099976
Validation loss: 1.912679180022209

Epoch: 5| Step: 6
Training loss: 1.4678083658218384
Validation loss: 1.9132695762060021

Epoch: 5| Step: 7
Training loss: 2.071420669555664
Validation loss: 1.923428529052324

Epoch: 5| Step: 8
Training loss: 1.2238305807113647
Validation loss: 1.9380396540446947

Epoch: 5| Step: 9
Training loss: 1.3220338821411133
Validation loss: 1.948907454808553

Epoch: 5| Step: 10
Training loss: 1.4014719724655151
Validation loss: 1.9489966425844418

Epoch: 225| Step: 0
Training loss: 1.1536318063735962
Validation loss: 1.9723648204598376

Epoch: 5| Step: 1
Training loss: 2.170651912689209
Validation loss: 1.9805558471269504

Epoch: 5| Step: 2
Training loss: 1.7438876628875732
Validation loss: 2.0042774959277083

Epoch: 5| Step: 3
Training loss: 1.5784080028533936
Validation loss: 2.013262238553775

Epoch: 5| Step: 4
Training loss: 1.6679370403289795
Validation loss: 1.9946684529704433

Epoch: 5| Step: 5
Training loss: 0.8419812321662903
Validation loss: 1.9542675543856878

Epoch: 5| Step: 6
Training loss: 1.3188902139663696
Validation loss: 1.951798016025174

Epoch: 5| Step: 7
Training loss: 1.2549388408660889
Validation loss: 1.9705661471172045

Epoch: 5| Step: 8
Training loss: 1.9441410303115845
Validation loss: 1.9555179636965516

Epoch: 5| Step: 9
Training loss: 1.4257893562316895
Validation loss: 1.9628514064255582

Epoch: 5| Step: 10
Training loss: 1.7826128005981445
Validation loss: 1.9553525217117802

Epoch: 226| Step: 0
Training loss: 1.8303139209747314
Validation loss: 1.9582033054803007

Epoch: 5| Step: 1
Training loss: 1.5915182828903198
Validation loss: 1.9436448620211693

Epoch: 5| Step: 2
Training loss: 2.0174050331115723
Validation loss: 1.935389175209948

Epoch: 5| Step: 3
Training loss: 1.946934700012207
Validation loss: 1.9114349272943312

Epoch: 5| Step: 4
Training loss: 1.2572811841964722
Validation loss: 1.9187627530867053

Epoch: 5| Step: 5
Training loss: 1.0325368642807007
Validation loss: 1.9074830214182537

Epoch: 5| Step: 6
Training loss: 1.3553129434585571
Validation loss: 1.915857235590617

Epoch: 5| Step: 7
Training loss: 1.4009850025177002
Validation loss: 1.9516176562155447

Epoch: 5| Step: 8
Training loss: 1.6131179332733154
Validation loss: 1.9685615749769314

Epoch: 5| Step: 9
Training loss: 1.6682393550872803
Validation loss: 1.9700339353212746

Epoch: 5| Step: 10
Training loss: 1.4321647882461548
Validation loss: 1.9519621864441903

Epoch: 227| Step: 0
Training loss: 1.2227007150650024
Validation loss: 1.9330609024211924

Epoch: 5| Step: 1
Training loss: 1.4700506925582886
Validation loss: 1.944187759071268

Epoch: 5| Step: 2
Training loss: 2.033916473388672
Validation loss: 1.9674707381956038

Epoch: 5| Step: 3
Training loss: 1.34225594997406
Validation loss: 1.9745226662646058

Epoch: 5| Step: 4
Training loss: 1.5307865142822266
Validation loss: 1.9687499487271873

Epoch: 5| Step: 5
Training loss: 1.340175986289978
Validation loss: 1.9704695260652931

Epoch: 5| Step: 6
Training loss: 1.659407615661621
Validation loss: 1.9656079071824268

Epoch: 5| Step: 7
Training loss: 1.0581231117248535
Validation loss: 1.9923172894344534

Epoch: 5| Step: 8
Training loss: 2.100780487060547
Validation loss: 1.9905574526838077

Epoch: 5| Step: 9
Training loss: 1.5292640924453735
Validation loss: 1.9717795400209324

Epoch: 5| Step: 10
Training loss: 1.4782358407974243
Validation loss: 1.9659030155469013

Epoch: 228| Step: 0
Training loss: 1.4073150157928467
Validation loss: 1.9678989661637174

Epoch: 5| Step: 1
Training loss: 1.1978552341461182
Validation loss: 1.9652059206398584

Epoch: 5| Step: 2
Training loss: 1.6583633422851562
Validation loss: 1.9490844203579811

Epoch: 5| Step: 3
Training loss: 1.4542080163955688
Validation loss: 1.9488370392912178

Epoch: 5| Step: 4
Training loss: 2.1965837478637695
Validation loss: 1.9533220798738542

Epoch: 5| Step: 5
Training loss: 1.3363959789276123
Validation loss: 1.9454549615101149

Epoch: 5| Step: 6
Training loss: 1.4749218225479126
Validation loss: 1.9591788463695075

Epoch: 5| Step: 7
Training loss: 1.4000587463378906
Validation loss: 1.9553734461466472

Epoch: 5| Step: 8
Training loss: 1.4299548864364624
Validation loss: 1.96474624705571

Epoch: 5| Step: 9
Training loss: 1.2919262647628784
Validation loss: 1.9727200782427223

Epoch: 5| Step: 10
Training loss: 1.5940231084823608
Validation loss: 1.940502235966344

Epoch: 229| Step: 0
Training loss: 1.3615604639053345
Validation loss: 1.9566911305150678

Epoch: 5| Step: 1
Training loss: 1.5734496116638184
Validation loss: 1.930225703024095

Epoch: 5| Step: 2
Training loss: 1.2416106462478638
Validation loss: 1.9256730592379006

Epoch: 5| Step: 3
Training loss: 1.4956893920898438
Validation loss: 1.930294531647877

Epoch: 5| Step: 4
Training loss: 0.9794571995735168
Validation loss: 1.925247480792384

Epoch: 5| Step: 5
Training loss: 1.8432095050811768
Validation loss: 1.9350487416790378

Epoch: 5| Step: 6
Training loss: 1.5126502513885498
Validation loss: 1.9515789157600814

Epoch: 5| Step: 7
Training loss: 1.4627585411071777
Validation loss: 1.9579339745224162

Epoch: 5| Step: 8
Training loss: 1.6721343994140625
Validation loss: 1.9768256423293904

Epoch: 5| Step: 9
Training loss: 1.7986934185028076
Validation loss: 1.9574658716878583

Epoch: 5| Step: 10
Training loss: 1.4326066970825195
Validation loss: 1.9642582939517113

Epoch: 230| Step: 0
Training loss: 1.7856652736663818
Validation loss: 1.9406785952147616

Epoch: 5| Step: 1
Training loss: 1.5328515768051147
Validation loss: 1.9472414037232757

Epoch: 5| Step: 2
Training loss: 1.2076789140701294
Validation loss: 1.9315238409144904

Epoch: 5| Step: 3
Training loss: 1.5232547521591187
Validation loss: 1.9237083106912591

Epoch: 5| Step: 4
Training loss: 1.4796898365020752
Validation loss: 1.9350245998751732

Epoch: 5| Step: 5
Training loss: 1.5217764377593994
Validation loss: 1.935971479262075

Epoch: 5| Step: 6
Training loss: 1.861393690109253
Validation loss: 1.9565089761569936

Epoch: 5| Step: 7
Training loss: 1.5502969026565552
Validation loss: 1.9448269951728083

Epoch: 5| Step: 8
Training loss: 1.1470515727996826
Validation loss: 1.959250614207278

Epoch: 5| Step: 9
Training loss: 1.190239667892456
Validation loss: 1.9761616235138268

Epoch: 5| Step: 10
Training loss: 1.350083589553833
Validation loss: 1.9954679986482025

Epoch: 231| Step: 0
Training loss: 1.2005207538604736
Validation loss: 1.9976158334362892

Epoch: 5| Step: 1
Training loss: 1.4275699853897095
Validation loss: 1.9902398073545067

Epoch: 5| Step: 2
Training loss: 1.4260560274124146
Validation loss: 1.9933056805723457

Epoch: 5| Step: 3
Training loss: 1.347074270248413
Validation loss: 2.001853173778903

Epoch: 5| Step: 4
Training loss: 1.19401216506958
Validation loss: 1.9710847793086883

Epoch: 5| Step: 5
Training loss: 1.511635661125183
Validation loss: 1.9636139997871973

Epoch: 5| Step: 6
Training loss: 1.5069360733032227
Validation loss: 1.968377290233489

Epoch: 5| Step: 7
Training loss: 1.4284273386001587
Validation loss: 1.961393020486319

Epoch: 5| Step: 8
Training loss: 1.362283706665039
Validation loss: 1.958478763539304

Epoch: 5| Step: 9
Training loss: 1.8988456726074219
Validation loss: 1.943579775030895

Epoch: 5| Step: 10
Training loss: 1.92794668674469
Validation loss: 1.9559947790638093

Epoch: 232| Step: 0
Training loss: 1.443561315536499
Validation loss: 1.92364106639739

Epoch: 5| Step: 1
Training loss: 1.2650318145751953
Validation loss: 1.939620388451443

Epoch: 5| Step: 2
Training loss: 1.1531212329864502
Validation loss: 1.933177900570695

Epoch: 5| Step: 3
Training loss: 1.075186014175415
Validation loss: 1.9433828400027366

Epoch: 5| Step: 4
Training loss: 1.6956026554107666
Validation loss: 1.9483156934861214

Epoch: 5| Step: 5
Training loss: 1.1314388513565063
Validation loss: 1.9588131340601111

Epoch: 5| Step: 6
Training loss: 2.0736379623413086
Validation loss: 1.9638703612871067

Epoch: 5| Step: 7
Training loss: 1.759460687637329
Validation loss: 1.9669422513695174

Epoch: 5| Step: 8
Training loss: 1.7527563571929932
Validation loss: 1.9436523337518015

Epoch: 5| Step: 9
Training loss: 1.1620070934295654
Validation loss: 1.9494063623489872

Epoch: 5| Step: 10
Training loss: 1.3616664409637451
Validation loss: 1.9445049019270046

Epoch: 233| Step: 0
Training loss: 1.6410045623779297
Validation loss: 1.9281198055513444

Epoch: 5| Step: 1
Training loss: 1.4526246786117554
Validation loss: 1.9130461600518995

Epoch: 5| Step: 2
Training loss: 1.5457888841629028
Validation loss: 1.878799997350221

Epoch: 5| Step: 3
Training loss: 2.0604774951934814
Validation loss: 1.8773315234850811

Epoch: 5| Step: 4
Training loss: 1.2588245868682861
Validation loss: 1.8883817311256164

Epoch: 5| Step: 5
Training loss: 1.349603533744812
Validation loss: 1.9182820076583533

Epoch: 5| Step: 6
Training loss: 1.397369623184204
Validation loss: 1.9663572413946993

Epoch: 5| Step: 7
Training loss: 1.2127413749694824
Validation loss: 2.0701043246894755

Epoch: 5| Step: 8
Training loss: 1.9962244033813477
Validation loss: 2.1332455809398363

Epoch: 5| Step: 9
Training loss: 1.592591643333435
Validation loss: 2.0719471464874926

Epoch: 5| Step: 10
Training loss: 1.0580699443817139
Validation loss: 2.0156903933453303

Epoch: 234| Step: 0
Training loss: 1.4869381189346313
Validation loss: 1.9593125979105632

Epoch: 5| Step: 1
Training loss: 1.3142473697662354
Validation loss: 1.9397931163029005

Epoch: 5| Step: 2
Training loss: 2.113246202468872
Validation loss: 1.9103228853594871

Epoch: 5| Step: 3
Training loss: 1.2146536111831665
Validation loss: 1.9030409089980587

Epoch: 5| Step: 4
Training loss: 1.7622718811035156
Validation loss: 1.874471906692751

Epoch: 5| Step: 5
Training loss: 0.9680156707763672
Validation loss: 1.8837768505978327

Epoch: 5| Step: 6
Training loss: 1.5886965990066528
Validation loss: 1.8958240606451546

Epoch: 5| Step: 7
Training loss: 1.2564104795455933
Validation loss: 1.9183006619894376

Epoch: 5| Step: 8
Training loss: 2.018144369125366
Validation loss: 1.9220691701417327

Epoch: 5| Step: 9
Training loss: 1.377475380897522
Validation loss: 1.9228354359185824

Epoch: 5| Step: 10
Training loss: 2.106126308441162
Validation loss: 1.9154955058969476

Epoch: 235| Step: 0
Training loss: 1.5403944253921509
Validation loss: 1.9297582744270243

Epoch: 5| Step: 1
Training loss: 1.4560160636901855
Validation loss: 1.949471922330959

Epoch: 5| Step: 2
Training loss: 1.57281494140625
Validation loss: 1.9706863536629626

Epoch: 5| Step: 3
Training loss: 1.8452091217041016
Validation loss: 1.9589254266472274

Epoch: 5| Step: 4
Training loss: 1.4877550601959229
Validation loss: 1.9715040499164211

Epoch: 5| Step: 5
Training loss: 1.393681287765503
Validation loss: 1.9903260341254614

Epoch: 5| Step: 6
Training loss: 1.3984618186950684
Validation loss: 1.9845399369475663

Epoch: 5| Step: 7
Training loss: 1.6075252294540405
Validation loss: 1.9724031045872679

Epoch: 5| Step: 8
Training loss: 1.4983993768692017
Validation loss: 1.9359350614650275

Epoch: 5| Step: 9
Training loss: 1.6656643152236938
Validation loss: 1.9159486139974287

Epoch: 5| Step: 10
Training loss: 1.251900315284729
Validation loss: 1.8954358985347133

Epoch: 236| Step: 0
Training loss: 1.497375726699829
Validation loss: 1.883476420115399

Epoch: 5| Step: 1
Training loss: 1.7150046825408936
Validation loss: 1.902354307072137

Epoch: 5| Step: 2
Training loss: 1.449451208114624
Validation loss: 1.9244762928255144

Epoch: 5| Step: 3
Training loss: 1.4044091701507568
Validation loss: 1.9449085176631968

Epoch: 5| Step: 4
Training loss: 1.1851856708526611
Validation loss: 1.975070652141366

Epoch: 5| Step: 5
Training loss: 1.4084184169769287
Validation loss: 1.9923840261274768

Epoch: 5| Step: 6
Training loss: 1.9441120624542236
Validation loss: 2.032965403731151

Epoch: 5| Step: 7
Training loss: 1.26859712600708
Validation loss: 2.0399811601126068

Epoch: 5| Step: 8
Training loss: 1.6596252918243408
Validation loss: 2.0227675476381854

Epoch: 5| Step: 9
Training loss: 1.2007873058319092
Validation loss: 2.0114670543260473

Epoch: 5| Step: 10
Training loss: 1.3149750232696533
Validation loss: 1.9720654500428068

Epoch: 237| Step: 0
Training loss: 1.3733012676239014
Validation loss: 1.9738096473037556

Epoch: 5| Step: 1
Training loss: 1.0889427661895752
Validation loss: 1.9568962768841816

Epoch: 5| Step: 2
Training loss: 1.7193944454193115
Validation loss: 1.9733240527491416

Epoch: 5| Step: 3
Training loss: 1.5089726448059082
Validation loss: 1.9329573851759716

Epoch: 5| Step: 4
Training loss: 1.4749666452407837
Validation loss: 1.9200291813060801

Epoch: 5| Step: 5
Training loss: 1.0227593183517456
Validation loss: 1.9071749179593978

Epoch: 5| Step: 6
Training loss: 1.9448816776275635
Validation loss: 1.924521961519795

Epoch: 5| Step: 7
Training loss: 1.2735915184020996
Validation loss: 1.9137946059626918

Epoch: 5| Step: 8
Training loss: 1.4102474451065063
Validation loss: 1.927404934360135

Epoch: 5| Step: 9
Training loss: 1.8003199100494385
Validation loss: 1.911815417710171

Epoch: 5| Step: 10
Training loss: 1.1662660837173462
Validation loss: 1.9291619536697224

Epoch: 238| Step: 0
Training loss: 1.6420494318008423
Validation loss: 1.9378180734572872

Epoch: 5| Step: 1
Training loss: 0.9578347206115723
Validation loss: 1.929712636496431

Epoch: 5| Step: 2
Training loss: 1.7319549322128296
Validation loss: 1.9608968803959508

Epoch: 5| Step: 3
Training loss: 1.3574576377868652
Validation loss: 1.9599553615816179

Epoch: 5| Step: 4
Training loss: 1.3614881038665771
Validation loss: 1.9721261326984694

Epoch: 5| Step: 5
Training loss: 1.3518688678741455
Validation loss: 1.9474023285732474

Epoch: 5| Step: 6
Training loss: 1.5058332681655884
Validation loss: 1.980671881347574

Epoch: 5| Step: 7
Training loss: 1.3482487201690674
Validation loss: 1.9491272754566644

Epoch: 5| Step: 8
Training loss: 1.2065989971160889
Validation loss: 1.9585658837390203

Epoch: 5| Step: 9
Training loss: 1.5221790075302124
Validation loss: 1.9506831271674043

Epoch: 5| Step: 10
Training loss: 1.4525238275527954
Validation loss: 1.9562435483419767

Epoch: 239| Step: 0
Training loss: 1.6603456735610962
Validation loss: 1.951459942325469

Epoch: 5| Step: 1
Training loss: 1.2759685516357422
Validation loss: 1.9710755796842678

Epoch: 5| Step: 2
Training loss: 1.2451032400131226
Validation loss: 1.9640897909800212

Epoch: 5| Step: 3
Training loss: 1.6078312397003174
Validation loss: 1.9350158476060437

Epoch: 5| Step: 4
Training loss: 1.317074179649353
Validation loss: 1.932660843736382

Epoch: 5| Step: 5
Training loss: 1.3589212894439697
Validation loss: 1.9599738941397717

Epoch: 5| Step: 6
Training loss: 2.0525460243225098
Validation loss: 1.9601948850898332

Epoch: 5| Step: 7
Training loss: 1.2364318370819092
Validation loss: 1.935122182292323

Epoch: 5| Step: 8
Training loss: 1.6407387256622314
Validation loss: 1.9195549680340676

Epoch: 5| Step: 9
Training loss: 1.5596754550933838
Validation loss: 1.931487475672076

Epoch: 5| Step: 10
Training loss: 0.8418407440185547
Validation loss: 1.9124700933374383

Epoch: 240| Step: 0
Training loss: 1.8597495555877686
Validation loss: 1.9520204118503037

Epoch: 5| Step: 1
Training loss: 1.4646555185317993
Validation loss: 1.9574087255744523

Epoch: 5| Step: 2
Training loss: 0.8433030843734741
Validation loss: 1.9527366084437217

Epoch: 5| Step: 3
Training loss: 1.4156553745269775
Validation loss: 1.9672548053085164

Epoch: 5| Step: 4
Training loss: 1.2330260276794434
Validation loss: 1.9770040435175742

Epoch: 5| Step: 5
Training loss: 1.4002776145935059
Validation loss: 1.9729481025408673

Epoch: 5| Step: 6
Training loss: 1.2070163488388062
Validation loss: 1.9714319167598602

Epoch: 5| Step: 7
Training loss: 1.5385076999664307
Validation loss: 1.9712388118108113

Epoch: 5| Step: 8
Training loss: 1.501889944076538
Validation loss: 1.9389063248070337

Epoch: 5| Step: 9
Training loss: 1.1861841678619385
Validation loss: 1.932811806278844

Epoch: 5| Step: 10
Training loss: 1.745160698890686
Validation loss: 1.9162120178181639

Epoch: 241| Step: 0
Training loss: 1.5798180103302002
Validation loss: 1.9233265935733754

Epoch: 5| Step: 1
Training loss: 1.4685431718826294
Validation loss: 1.9087016672216437

Epoch: 5| Step: 2
Training loss: 1.2032420635223389
Validation loss: 1.9070570827812277

Epoch: 5| Step: 3
Training loss: 1.3115278482437134
Validation loss: 1.9100080997713151

Epoch: 5| Step: 4
Training loss: 1.6981837749481201
Validation loss: 1.9332974905608802

Epoch: 5| Step: 5
Training loss: 1.2047584056854248
Validation loss: 1.92728675693594

Epoch: 5| Step: 6
Training loss: 1.1691935062408447
Validation loss: 1.9495276622874762

Epoch: 5| Step: 7
Training loss: 1.1117833852767944
Validation loss: 1.9442238423132128

Epoch: 5| Step: 8
Training loss: 1.176841378211975
Validation loss: 1.9509826680665374

Epoch: 5| Step: 9
Training loss: 1.539236307144165
Validation loss: 1.9654574522408106

Epoch: 5| Step: 10
Training loss: 1.745912790298462
Validation loss: 1.9647120121986634

Epoch: 242| Step: 0
Training loss: 1.3684529066085815
Validation loss: 1.9788201419256066

Epoch: 5| Step: 1
Training loss: 1.3662302494049072
Validation loss: 1.9582440519845614

Epoch: 5| Step: 2
Training loss: 1.634917974472046
Validation loss: 1.9400533809456775

Epoch: 5| Step: 3
Training loss: 1.5739457607269287
Validation loss: 1.9537012987239386

Epoch: 5| Step: 4
Training loss: 0.6301354169845581
Validation loss: 1.9477335253069479

Epoch: 5| Step: 5
Training loss: 1.4366669654846191
Validation loss: 1.9377197616843767

Epoch: 5| Step: 6
Training loss: 1.2897700071334839
Validation loss: 1.9160550025201613

Epoch: 5| Step: 7
Training loss: 1.5823454856872559
Validation loss: 1.9290254859514133

Epoch: 5| Step: 8
Training loss: 0.9230808019638062
Validation loss: 1.9060608058847406

Epoch: 5| Step: 9
Training loss: 1.3510701656341553
Validation loss: 1.9131159897773498

Epoch: 5| Step: 10
Training loss: 1.9634946584701538
Validation loss: 1.938618322854401

Epoch: 243| Step: 0
Training loss: 1.5237338542938232
Validation loss: 1.934853692208567

Epoch: 5| Step: 1
Training loss: 1.2979681491851807
Validation loss: 1.9484600764448925

Epoch: 5| Step: 2
Training loss: 1.9303805828094482
Validation loss: 1.9538773567445817

Epoch: 5| Step: 3
Training loss: 1.6272140741348267
Validation loss: 1.9430787050595848

Epoch: 5| Step: 4
Training loss: 1.2968616485595703
Validation loss: 1.9302440433092014

Epoch: 5| Step: 5
Training loss: 1.331529140472412
Validation loss: 1.9093516078046573

Epoch: 5| Step: 6
Training loss: 1.3433252573013306
Validation loss: 1.8991189246536584

Epoch: 5| Step: 7
Training loss: 1.0645405054092407
Validation loss: 1.896391225117509

Epoch: 5| Step: 8
Training loss: 1.190130591392517
Validation loss: 1.919051553613396

Epoch: 5| Step: 9
Training loss: 1.154253363609314
Validation loss: 1.9318707335379817

Epoch: 5| Step: 10
Training loss: 1.3690708875656128
Validation loss: 1.9643639031276907

Epoch: 244| Step: 0
Training loss: 1.7832177877426147
Validation loss: 2.0331538595179075

Epoch: 5| Step: 1
Training loss: 1.0420913696289062
Validation loss: 2.034303390851585

Epoch: 5| Step: 2
Training loss: 1.3159006834030151
Validation loss: 2.0114511418086227

Epoch: 5| Step: 3
Training loss: 1.4022243022918701
Validation loss: 1.9794441884563816

Epoch: 5| Step: 4
Training loss: 1.3962262868881226
Validation loss: 1.9203047995926232

Epoch: 5| Step: 5
Training loss: 1.1302560567855835
Validation loss: 1.9066620898503128

Epoch: 5| Step: 6
Training loss: 1.640097975730896
Validation loss: 1.887543846202153

Epoch: 5| Step: 7
Training loss: 1.1139745712280273
Validation loss: 1.8654602407127299

Epoch: 5| Step: 8
Training loss: 1.6238784790039062
Validation loss: 1.8781627980611657

Epoch: 5| Step: 9
Training loss: 1.3471177816390991
Validation loss: 1.876177898017309

Epoch: 5| Step: 10
Training loss: 1.4849200248718262
Validation loss: 1.879975911109678

Epoch: 245| Step: 0
Training loss: 1.5293077230453491
Validation loss: 1.8933962724542106

Epoch: 5| Step: 1
Training loss: 1.5823557376861572
Validation loss: 1.884116058708519

Epoch: 5| Step: 2
Training loss: 0.6436606645584106
Validation loss: 1.8966126954683693

Epoch: 5| Step: 3
Training loss: 1.444604754447937
Validation loss: 1.9128945835175053

Epoch: 5| Step: 4
Training loss: 1.144596815109253
Validation loss: 1.9072431043912006

Epoch: 5| Step: 5
Training loss: 1.440084457397461
Validation loss: 1.9124887527958039

Epoch: 5| Step: 6
Training loss: 1.353281855583191
Validation loss: 1.9186383793430943

Epoch: 5| Step: 7
Training loss: 1.6325124502182007
Validation loss: 1.9094528254642282

Epoch: 5| Step: 8
Training loss: 1.5242774486541748
Validation loss: 1.9075368527443177

Epoch: 5| Step: 9
Training loss: 1.4086107015609741
Validation loss: 1.9367178088875228

Epoch: 5| Step: 10
Training loss: 0.9179849028587341
Validation loss: 1.9197438186214817

Epoch: 246| Step: 0
Training loss: 1.5142980813980103
Validation loss: 1.9233764756110407

Epoch: 5| Step: 1
Training loss: 1.5832908153533936
Validation loss: 1.9422922313854258

Epoch: 5| Step: 2
Training loss: 0.951276957988739
Validation loss: 1.9299199991328742

Epoch: 5| Step: 3
Training loss: 1.3389981985092163
Validation loss: 1.9233194858797136

Epoch: 5| Step: 4
Training loss: 1.30312180519104
Validation loss: 1.9175193053419872

Epoch: 5| Step: 5
Training loss: 1.455413579940796
Validation loss: 1.9232687142587477

Epoch: 5| Step: 6
Training loss: 1.757660150527954
Validation loss: 1.901791803298458

Epoch: 5| Step: 7
Training loss: 1.043127417564392
Validation loss: 1.9075392010391399

Epoch: 5| Step: 8
Training loss: 1.243722915649414
Validation loss: 1.9178986267376972

Epoch: 5| Step: 9
Training loss: 1.3014353513717651
Validation loss: 1.9082768450501144

Epoch: 5| Step: 10
Training loss: 0.9782858490943909
Validation loss: 1.9425957395184426

Epoch: 247| Step: 0
Training loss: 1.603532075881958
Validation loss: 1.95726897639613

Epoch: 5| Step: 1
Training loss: 0.7406931519508362
Validation loss: 1.9754017373566986

Epoch: 5| Step: 2
Training loss: 0.7019561529159546
Validation loss: 1.9432354460480392

Epoch: 5| Step: 3
Training loss: 1.1640390157699585
Validation loss: 1.9405964292505735

Epoch: 5| Step: 4
Training loss: 1.444655418395996
Validation loss: 1.9046815826046852

Epoch: 5| Step: 5
Training loss: 0.9997415542602539
Validation loss: 1.9249617386889715

Epoch: 5| Step: 6
Training loss: 1.6910299062728882
Validation loss: 1.8999152055350683

Epoch: 5| Step: 7
Training loss: 1.3545048236846924
Validation loss: 1.9133585576088197

Epoch: 5| Step: 8
Training loss: 1.6947542428970337
Validation loss: 1.9004214322695168

Epoch: 5| Step: 9
Training loss: 1.8553146123886108
Validation loss: 1.9035410804133261

Epoch: 5| Step: 10
Training loss: 1.1864839792251587
Validation loss: 1.92360346932565

Epoch: 248| Step: 0
Training loss: 1.5129332542419434
Validation loss: 1.9215266089285574

Epoch: 5| Step: 1
Training loss: 1.5489391088485718
Validation loss: 1.9033234901325677

Epoch: 5| Step: 2
Training loss: 0.932699978351593
Validation loss: 1.9097282181503952

Epoch: 5| Step: 3
Training loss: 1.366089105606079
Validation loss: 1.8979421918110182

Epoch: 5| Step: 4
Training loss: 1.7326253652572632
Validation loss: 1.8837397329268917

Epoch: 5| Step: 5
Training loss: 1.5556402206420898
Validation loss: 1.9094581962913595

Epoch: 5| Step: 6
Training loss: 0.6911736130714417
Validation loss: 1.9028797329113047

Epoch: 5| Step: 7
Training loss: 1.2402913570404053
Validation loss: 1.91136505270517

Epoch: 5| Step: 8
Training loss: 1.1133249998092651
Validation loss: 1.9452102184295654

Epoch: 5| Step: 9
Training loss: 1.1078464984893799
Validation loss: 1.9665998207625521

Epoch: 5| Step: 10
Training loss: 1.5043542385101318
Validation loss: 1.9702704016880324

Epoch: 249| Step: 0
Training loss: 1.3006455898284912
Validation loss: 1.9628377473482521

Epoch: 5| Step: 1
Training loss: 1.9104408025741577
Validation loss: 1.9495459448906682

Epoch: 5| Step: 2
Training loss: 1.2087446451187134
Validation loss: 1.915156828459873

Epoch: 5| Step: 3
Training loss: 1.249617338180542
Validation loss: 1.9104755514411516

Epoch: 5| Step: 4
Training loss: 1.084456443786621
Validation loss: 1.9067120385426346

Epoch: 5| Step: 5
Training loss: 1.3616943359375
Validation loss: 1.8915260068831905

Epoch: 5| Step: 6
Training loss: 1.5413365364074707
Validation loss: 1.9487809647795975

Epoch: 5| Step: 7
Training loss: 1.5100865364074707
Validation loss: 1.980970549327071

Epoch: 5| Step: 8
Training loss: 1.0861361026763916
Validation loss: 2.0241785639075824

Epoch: 5| Step: 9
Training loss: 0.8744807243347168
Validation loss: 2.0418346915193784

Epoch: 5| Step: 10
Training loss: 1.1007128953933716
Validation loss: 1.9949457312142977

Epoch: 250| Step: 0
Training loss: 1.1732869148254395
Validation loss: 1.92923604929319

Epoch: 5| Step: 1
Training loss: 1.2940915822982788
Validation loss: 1.8933210988198557

Epoch: 5| Step: 2
Training loss: 1.3990576267242432
Validation loss: 1.8998518477204025

Epoch: 5| Step: 3
Training loss: 1.3313684463500977
Validation loss: 1.8930006078494492

Epoch: 5| Step: 4
Training loss: 1.3481864929199219
Validation loss: 1.888593598078656

Epoch: 5| Step: 5
Training loss: 1.6337753534317017
Validation loss: 1.914454375543902

Epoch: 5| Step: 6
Training loss: 1.282366156578064
Validation loss: 1.9404807244577715

Epoch: 5| Step: 7
Training loss: 0.8599932789802551
Validation loss: 1.9371661973255936

Epoch: 5| Step: 8
Training loss: 1.1247576475143433
Validation loss: 1.9311369952335153

Epoch: 5| Step: 9
Training loss: 1.3536145687103271
Validation loss: 1.9355990168868855

Epoch: 5| Step: 10
Training loss: 1.1047784090042114
Validation loss: 1.9373888687420917

Epoch: 251| Step: 0
Training loss: 1.1815330982208252
Validation loss: 1.9426798615404355

Epoch: 5| Step: 1
Training loss: 1.3870680332183838
Validation loss: 1.9491100542006954

Epoch: 5| Step: 2
Training loss: 1.25288987159729
Validation loss: 1.9174856178222164

Epoch: 5| Step: 3
Training loss: 1.663254976272583
Validation loss: 1.9150560953283822

Epoch: 5| Step: 4
Training loss: 1.0662577152252197
Validation loss: 1.9076051891490977

Epoch: 5| Step: 5
Training loss: 1.2823636531829834
Validation loss: 1.91572158311003

Epoch: 5| Step: 6
Training loss: 1.2337943315505981
Validation loss: 1.9206693608273742

Epoch: 5| Step: 7
Training loss: 1.5035415887832642
Validation loss: 1.9115988310947214

Epoch: 5| Step: 8
Training loss: 1.2286064624786377
Validation loss: 1.9272771868654477

Epoch: 5| Step: 9
Training loss: 1.0143566131591797
Validation loss: 1.915303930159538

Epoch: 5| Step: 10
Training loss: 1.128846287727356
Validation loss: 1.9246623926265265

Epoch: 252| Step: 0
Training loss: 0.9095590710639954
Validation loss: 1.9325957836643342

Epoch: 5| Step: 1
Training loss: 1.1844902038574219
Validation loss: 1.9456738066929642

Epoch: 5| Step: 2
Training loss: 1.1539090871810913
Validation loss: 1.9428535571662329

Epoch: 5| Step: 3
Training loss: 1.0272899866104126
Validation loss: 1.9635958825388262

Epoch: 5| Step: 4
Training loss: 1.457085371017456
Validation loss: 1.9400619870872908

Epoch: 5| Step: 5
Training loss: 0.9402871131896973
Validation loss: 1.9181470204425115

Epoch: 5| Step: 6
Training loss: 1.4973796606063843
Validation loss: 1.9009526032273487

Epoch: 5| Step: 7
Training loss: 0.8566197156906128
Validation loss: 1.8755665235621954

Epoch: 5| Step: 8
Training loss: 1.2281488180160522
Validation loss: 1.8791741286554644

Epoch: 5| Step: 9
Training loss: 1.9439830780029297
Validation loss: 1.8878051721921532

Epoch: 5| Step: 10
Training loss: 1.5188310146331787
Validation loss: 1.892615657980724

Epoch: 253| Step: 0
Training loss: 1.330366611480713
Validation loss: 1.9259853875765236

Epoch: 5| Step: 1
Training loss: 1.5207792520523071
Validation loss: 1.9696308053949827

Epoch: 5| Step: 2
Training loss: 1.2046154737472534
Validation loss: 1.9825030936989734

Epoch: 5| Step: 3
Training loss: 1.2524588108062744
Validation loss: 1.978848256090636

Epoch: 5| Step: 4
Training loss: 1.2476469278335571
Validation loss: 1.9760741123589136

Epoch: 5| Step: 5
Training loss: 0.8597316741943359
Validation loss: 1.9654427266890002

Epoch: 5| Step: 6
Training loss: 1.7109657526016235
Validation loss: 1.9666545583355812

Epoch: 5| Step: 7
Training loss: 1.2700707912445068
Validation loss: 1.969513294517353

Epoch: 5| Step: 8
Training loss: 1.0744853019714355
Validation loss: 1.9629477044587493

Epoch: 5| Step: 9
Training loss: 1.4297319650650024
Validation loss: 1.9663303782863002

Epoch: 5| Step: 10
Training loss: 1.4548537731170654
Validation loss: 1.9290504340202577

Epoch: 254| Step: 0
Training loss: 1.4039320945739746
Validation loss: 1.904347212083878

Epoch: 5| Step: 1
Training loss: 1.0674588680267334
Validation loss: 1.9070660888507802

Epoch: 5| Step: 2
Training loss: 1.2849390506744385
Validation loss: 1.898806341232792

Epoch: 5| Step: 3
Training loss: 0.9301679730415344
Validation loss: 1.892255433144108

Epoch: 5| Step: 4
Training loss: 1.2846568822860718
Validation loss: 1.8882569459176832

Epoch: 5| Step: 5
Training loss: 1.3295542001724243
Validation loss: 1.8937355215831468

Epoch: 5| Step: 6
Training loss: 1.2298076152801514
Validation loss: 1.916337820791429

Epoch: 5| Step: 7
Training loss: 2.083662271499634
Validation loss: 1.9230703564100369

Epoch: 5| Step: 8
Training loss: 1.5482600927352905
Validation loss: 1.9908981246332969

Epoch: 5| Step: 9
Training loss: 0.7346696853637695
Validation loss: 2.0330977926972094

Epoch: 5| Step: 10
Training loss: 0.9763173460960388
Validation loss: 2.063674306356779

Epoch: 255| Step: 0
Training loss: 0.699271559715271
Validation loss: 2.0334328387373235

Epoch: 5| Step: 1
Training loss: 1.0436886548995972
Validation loss: 1.9824085415050547

Epoch: 5| Step: 2
Training loss: 1.3666292428970337
Validation loss: 1.9879880925660491

Epoch: 5| Step: 3
Training loss: 1.1255557537078857
Validation loss: 1.9423848429033834

Epoch: 5| Step: 4
Training loss: 1.700963020324707
Validation loss: 1.9221936246400237

Epoch: 5| Step: 5
Training loss: 1.5308988094329834
Validation loss: 1.9047545438171716

Epoch: 5| Step: 6
Training loss: 1.9878162145614624
Validation loss: 1.9017093553338

Epoch: 5| Step: 7
Training loss: 1.2911176681518555
Validation loss: 1.9079667470788444

Epoch: 5| Step: 8
Training loss: 1.2246688604354858
Validation loss: 1.9102571843772806

Epoch: 5| Step: 9
Training loss: 0.7271662950515747
Validation loss: 1.9487751401880735

Epoch: 5| Step: 10
Training loss: 1.2657822370529175
Validation loss: 1.9703052595097532

Epoch: 256| Step: 0
Training loss: 1.3508307933807373
Validation loss: 2.006874761273784

Epoch: 5| Step: 1
Training loss: 1.250060796737671
Validation loss: 1.9859119064064437

Epoch: 5| Step: 2
Training loss: 1.1334679126739502
Validation loss: 1.9548368018160585

Epoch: 5| Step: 3
Training loss: 1.4490270614624023
Validation loss: 1.9467544760755313

Epoch: 5| Step: 4
Training loss: 0.6885275840759277
Validation loss: 1.8803838222257552

Epoch: 5| Step: 5
Training loss: 1.0754510164260864
Validation loss: 1.871524086562536

Epoch: 5| Step: 6
Training loss: 1.3652738332748413
Validation loss: 1.841155190621653

Epoch: 5| Step: 7
Training loss: 0.8902658224105835
Validation loss: 1.8434007552362257

Epoch: 5| Step: 8
Training loss: 1.282211422920227
Validation loss: 1.8600660844515728

Epoch: 5| Step: 9
Training loss: 1.7484050989151
Validation loss: 1.8883372737515358

Epoch: 5| Step: 10
Training loss: 1.3939220905303955
Validation loss: 1.9376212909657469

Epoch: 257| Step: 0
Training loss: 1.0027756690979004
Validation loss: 1.9266276692831388

Epoch: 5| Step: 1
Training loss: 1.1178308725357056
Validation loss: 1.8903703779302619

Epoch: 5| Step: 2
Training loss: 1.679809808731079
Validation loss: 1.853045234116175

Epoch: 5| Step: 3
Training loss: 1.5991506576538086
Validation loss: 1.8618595279673094

Epoch: 5| Step: 4
Training loss: 1.1886054277420044
Validation loss: 1.8690007220032394

Epoch: 5| Step: 5
Training loss: 1.1613969802856445
Validation loss: 1.8572609373318252

Epoch: 5| Step: 6
Training loss: 0.8399640321731567
Validation loss: 1.876080213054534

Epoch: 5| Step: 7
Training loss: 1.2421905994415283
Validation loss: 1.9052856840113157

Epoch: 5| Step: 8
Training loss: 1.1150907278060913
Validation loss: 1.9061989681695097

Epoch: 5| Step: 9
Training loss: 1.095187783241272
Validation loss: 1.939187265211536

Epoch: 5| Step: 10
Training loss: 1.3008724451065063
Validation loss: 1.9374306535208097

Epoch: 258| Step: 0
Training loss: 1.4136484861373901
Validation loss: 1.9518163319556945

Epoch: 5| Step: 1
Training loss: 1.1992402076721191
Validation loss: 1.9895065420417375

Epoch: 5| Step: 2
Training loss: 1.8275543451309204
Validation loss: 1.9579997190865137

Epoch: 5| Step: 3
Training loss: 1.2591321468353271
Validation loss: 1.9306174350041214

Epoch: 5| Step: 4
Training loss: 1.0475023984909058
Validation loss: 1.9452054962035148

Epoch: 5| Step: 5
Training loss: 1.0059188604354858
Validation loss: 1.922372930793352

Epoch: 5| Step: 6
Training loss: 1.3103777170181274
Validation loss: 1.9135551529545938

Epoch: 5| Step: 7
Training loss: 1.2348780632019043
Validation loss: 1.9210778974717664

Epoch: 5| Step: 8
Training loss: 0.7037416100502014
Validation loss: 1.907355898170061

Epoch: 5| Step: 9
Training loss: 1.6728938817977905
Validation loss: 1.9068450645733905

Epoch: 5| Step: 10
Training loss: 0.7562960982322693
Validation loss: 1.9144860441966722

Epoch: 259| Step: 0
Training loss: 1.3901945352554321
Validation loss: 1.9974217978856896

Epoch: 5| Step: 1
Training loss: 1.1839147806167603
Validation loss: 1.9897941799574002

Epoch: 5| Step: 2
Training loss: 1.1246038675308228
Validation loss: 1.965405036044377

Epoch: 5| Step: 3
Training loss: 1.3687480688095093
Validation loss: 1.9790339700637325

Epoch: 5| Step: 4
Training loss: 0.7484537959098816
Validation loss: 1.937077888878443

Epoch: 5| Step: 5
Training loss: 1.1387791633605957
Validation loss: 1.8862885826377458

Epoch: 5| Step: 6
Training loss: 1.4164910316467285
Validation loss: 1.8874207696607035

Epoch: 5| Step: 7
Training loss: 1.3284540176391602
Validation loss: 1.8660342360055575

Epoch: 5| Step: 8
Training loss: 1.6016038656234741
Validation loss: 1.8679831848349622

Epoch: 5| Step: 9
Training loss: 0.9046844244003296
Validation loss: 1.8547307573338991

Epoch: 5| Step: 10
Training loss: 1.530198097229004
Validation loss: 1.8685717044338104

Epoch: 260| Step: 0
Training loss: 1.7619616985321045
Validation loss: 1.9506748184081046

Epoch: 5| Step: 1
Training loss: 1.4891884326934814
Validation loss: 1.942085289186047

Epoch: 5| Step: 2
Training loss: 0.9744027256965637
Validation loss: 1.9160734953418854

Epoch: 5| Step: 3
Training loss: 0.6486201286315918
Validation loss: 1.8853959280957457

Epoch: 5| Step: 4
Training loss: 0.9269493222236633
Validation loss: 1.8941262223387276

Epoch: 5| Step: 5
Training loss: 1.2194867134094238
Validation loss: 1.9004264557233421

Epoch: 5| Step: 6
Training loss: 1.2774238586425781
Validation loss: 1.9220567916029243

Epoch: 5| Step: 7
Training loss: 1.4829370975494385
Validation loss: 1.9484086857047132

Epoch: 5| Step: 8
Training loss: 1.5098634958267212
Validation loss: 1.9482762749477098

Epoch: 5| Step: 9
Training loss: 0.8233404159545898
Validation loss: 1.9538605495165753

Epoch: 5| Step: 10
Training loss: 1.6385799646377563
Validation loss: 1.96159392018472

Epoch: 261| Step: 0
Training loss: 1.472334623336792
Validation loss: 1.9511959001582155

Epoch: 5| Step: 1
Training loss: 0.92533940076828
Validation loss: 1.9736146029605661

Epoch: 5| Step: 2
Training loss: 1.357121229171753
Validation loss: 1.9430753313085085

Epoch: 5| Step: 3
Training loss: 1.1872659921646118
Validation loss: 1.9148576439067881

Epoch: 5| Step: 4
Training loss: 1.367412805557251
Validation loss: 1.8700870980498612

Epoch: 5| Step: 5
Training loss: 1.0218130350112915
Validation loss: 1.8951607058125157

Epoch: 5| Step: 6
Training loss: 1.2463854551315308
Validation loss: 1.8950543762535177

Epoch: 5| Step: 7
Training loss: 0.9542217254638672
Validation loss: 1.912186941792888

Epoch: 5| Step: 8
Training loss: 1.2493473291397095
Validation loss: 1.937463177147732

Epoch: 5| Step: 9
Training loss: 1.5306419134140015
Validation loss: 1.956051113784954

Epoch: 5| Step: 10
Training loss: 1.0755517482757568
Validation loss: 1.979411312328872

Epoch: 262| Step: 0
Training loss: 1.6640994548797607
Validation loss: 1.9578512112299602

Epoch: 5| Step: 1
Training loss: 0.6478791236877441
Validation loss: 1.9498413019282843

Epoch: 5| Step: 2
Training loss: 1.2278553247451782
Validation loss: 1.9381483062621085

Epoch: 5| Step: 3
Training loss: 1.1153672933578491
Validation loss: 1.9325235582167102

Epoch: 5| Step: 4
Training loss: 1.4451934099197388
Validation loss: 1.9233264487276795

Epoch: 5| Step: 5
Training loss: 1.1817357540130615
Validation loss: 1.9106196844449608

Epoch: 5| Step: 6
Training loss: 0.7975622415542603
Validation loss: 1.9141519761854602

Epoch: 5| Step: 7
Training loss: 1.2870817184448242
Validation loss: 1.919420346137016

Epoch: 5| Step: 8
Training loss: 1.063340425491333
Validation loss: 1.9274006453893517

Epoch: 5| Step: 9
Training loss: 1.0964102745056152
Validation loss: 1.910773487501247

Epoch: 5| Step: 10
Training loss: 1.6860275268554688
Validation loss: 1.9309382797569357

Epoch: 263| Step: 0
Training loss: 0.794237494468689
Validation loss: 1.8866820553297639

Epoch: 5| Step: 1
Training loss: 1.2054640054702759
Validation loss: 1.899063079587875

Epoch: 5| Step: 2
Training loss: 1.2632472515106201
Validation loss: 1.8841165957912323

Epoch: 5| Step: 3
Training loss: 0.9323549270629883
Validation loss: 1.8754151739099973

Epoch: 5| Step: 4
Training loss: 1.1540935039520264
Validation loss: 1.8647070853940901

Epoch: 5| Step: 5
Training loss: 1.0425450801849365
Validation loss: 1.8885153250027729

Epoch: 5| Step: 6
Training loss: 1.2109901905059814
Validation loss: 1.8824684709630988

Epoch: 5| Step: 7
Training loss: 1.5688015222549438
Validation loss: 1.884670070422593

Epoch: 5| Step: 8
Training loss: 1.39169180393219
Validation loss: 1.9067917754573207

Epoch: 5| Step: 9
Training loss: 1.0290697813034058
Validation loss: 1.948949767697242

Epoch: 5| Step: 10
Training loss: 1.2927196025848389
Validation loss: 1.9899727862368348

Epoch: 264| Step: 0
Training loss: 1.0354759693145752
Validation loss: 2.0627625321829193

Epoch: 5| Step: 1
Training loss: 1.01780104637146
Validation loss: 2.1326773653748217

Epoch: 5| Step: 2
Training loss: 0.9787675142288208
Validation loss: 2.143406908999207

Epoch: 5| Step: 3
Training loss: 1.4052019119262695
Validation loss: 2.0721657840154504

Epoch: 5| Step: 4
Training loss: 1.4035247564315796
Validation loss: 1.9840295109697568

Epoch: 5| Step: 5
Training loss: 1.6149864196777344
Validation loss: 1.9065897182751728

Epoch: 5| Step: 6
Training loss: 1.4586155414581299
Validation loss: 1.9029936175192557

Epoch: 5| Step: 7
Training loss: 1.1392627954483032
Validation loss: 1.9261627120356406

Epoch: 5| Step: 8
Training loss: 1.1600807905197144
Validation loss: 1.9142227224124375

Epoch: 5| Step: 9
Training loss: 1.398584246635437
Validation loss: 1.8851394422592656

Epoch: 5| Step: 10
Training loss: 1.3830361366271973
Validation loss: 1.8519811155975505

Epoch: 265| Step: 0
Training loss: 1.5769891738891602
Validation loss: 1.8609920458127094

Epoch: 5| Step: 1
Training loss: 0.9739750027656555
Validation loss: 1.876161334335163

Epoch: 5| Step: 2
Training loss: 1.3629077672958374
Validation loss: 1.8851061251855665

Epoch: 5| Step: 3
Training loss: 1.0263351202011108
Validation loss: 1.856415811405387

Epoch: 5| Step: 4
Training loss: 1.4489600658416748
Validation loss: 1.9008260298800725

Epoch: 5| Step: 5
Training loss: 1.4768974781036377
Validation loss: 1.946753187846112

Epoch: 5| Step: 6
Training loss: 1.0826661586761475
Validation loss: 1.955519417280792

Epoch: 5| Step: 7
Training loss: 0.8772472143173218
Validation loss: 1.9297745150904502

Epoch: 5| Step: 8
Training loss: 0.8259134292602539
Validation loss: 1.925380188931701

Epoch: 5| Step: 9
Training loss: 0.9035745859146118
Validation loss: 1.9119616477720198

Epoch: 5| Step: 10
Training loss: 1.443221092224121
Validation loss: 1.8918116246500323

Epoch: 266| Step: 0
Training loss: 0.7923647165298462
Validation loss: 1.871714033106322

Epoch: 5| Step: 1
Training loss: 1.142021656036377
Validation loss: 1.8524914582570393

Epoch: 5| Step: 2
Training loss: 1.0461288690567017
Validation loss: 1.8469034612819712

Epoch: 5| Step: 3
Training loss: 1.4113470315933228
Validation loss: 1.8475221228855911

Epoch: 5| Step: 4
Training loss: 1.0651938915252686
Validation loss: 1.870428285291118

Epoch: 5| Step: 5
Training loss: 0.7531715631484985
Validation loss: 1.8947714785093903

Epoch: 5| Step: 6
Training loss: 1.0899909734725952
Validation loss: 1.9652284627319665

Epoch: 5| Step: 7
Training loss: 1.3011515140533447
Validation loss: 1.9462436963153142

Epoch: 5| Step: 8
Training loss: 1.4156739711761475
Validation loss: 1.8965652629893313

Epoch: 5| Step: 9
Training loss: 1.6194343566894531
Validation loss: 1.8775505365863923

Epoch: 5| Step: 10
Training loss: 1.5331284999847412
Validation loss: 1.8842425282283495

Epoch: 267| Step: 0
Training loss: 1.0302801132202148
Validation loss: 1.8829524350422684

Epoch: 5| Step: 1
Training loss: 1.4691104888916016
Validation loss: 1.8964236500442668

Epoch: 5| Step: 2
Training loss: 1.5405094623565674
Validation loss: 1.896066504140054

Epoch: 5| Step: 3
Training loss: 0.943074107170105
Validation loss: 1.8879829029883108

Epoch: 5| Step: 4
Training loss: 0.9007652997970581
Validation loss: 1.9445766018282982

Epoch: 5| Step: 5
Training loss: 1.4308748245239258
Validation loss: 2.0341528641280306

Epoch: 5| Step: 6
Training loss: 1.2260937690734863
Validation loss: 2.075944892821773

Epoch: 5| Step: 7
Training loss: 0.6339556574821472
Validation loss: 2.0913087360320555

Epoch: 5| Step: 8
Training loss: 1.8099960088729858
Validation loss: 2.0325708158554567

Epoch: 5| Step: 9
Training loss: 1.1445672512054443
Validation loss: 1.9368159232601043

Epoch: 5| Step: 10
Training loss: 1.2876352071762085
Validation loss: 1.8781574003158077

Epoch: 268| Step: 0
Training loss: 1.2427884340286255
Validation loss: 1.8468622417860134

Epoch: 5| Step: 1
Training loss: 1.1475368738174438
Validation loss: 1.8484182601333947

Epoch: 5| Step: 2
Training loss: 1.200386643409729
Validation loss: 1.8427512491902998

Epoch: 5| Step: 3
Training loss: 1.3287043571472168
Validation loss: 1.8451210785937566

Epoch: 5| Step: 4
Training loss: 1.3982502222061157
Validation loss: 1.8579860630855765

Epoch: 5| Step: 5
Training loss: 1.553436517715454
Validation loss: 1.8868362442139657

Epoch: 5| Step: 6
Training loss: 0.8223344683647156
Validation loss: 1.966616251135385

Epoch: 5| Step: 7
Training loss: 1.16524338722229
Validation loss: 2.054940285221223

Epoch: 5| Step: 8
Training loss: 1.4594792127609253
Validation loss: 2.097138738119474

Epoch: 5| Step: 9
Training loss: 1.3066622018814087
Validation loss: 2.107274119571973

Epoch: 5| Step: 10
Training loss: 0.6244218945503235
Validation loss: 2.0200833325744956

Epoch: 269| Step: 0
Training loss: 1.478525161743164
Validation loss: 1.9655733749430666

Epoch: 5| Step: 1
Training loss: 1.108397364616394
Validation loss: 1.9169989273112307

Epoch: 5| Step: 2
Training loss: 1.2285085916519165
Validation loss: 1.8804046723150438

Epoch: 5| Step: 3
Training loss: 0.9284211993217468
Validation loss: 1.8851191587345575

Epoch: 5| Step: 4
Training loss: 1.186023473739624
Validation loss: 1.8623380353373866

Epoch: 5| Step: 5
Training loss: 0.9410454034805298
Validation loss: 1.8310306072235107

Epoch: 5| Step: 6
Training loss: 1.5940840244293213
Validation loss: 1.836493670299489

Epoch: 5| Step: 7
Training loss: 0.4646962285041809
Validation loss: 1.8367431061242216

Epoch: 5| Step: 8
Training loss: 1.6654398441314697
Validation loss: 1.8924904689993909

Epoch: 5| Step: 9
Training loss: 1.3654658794403076
Validation loss: 1.9284430498717933

Epoch: 5| Step: 10
Training loss: 0.9471336603164673
Validation loss: 1.9056052777074999

Epoch: 270| Step: 0
Training loss: 1.316456913948059
Validation loss: 1.9210489001325382

Epoch: 5| Step: 1
Training loss: 1.2307194471359253
Validation loss: 1.8816278096168273

Epoch: 5| Step: 2
Training loss: 1.1402521133422852
Validation loss: 1.8984356875060706

Epoch: 5| Step: 3
Training loss: 1.165761113166809
Validation loss: 1.8929903789233136

Epoch: 5| Step: 4
Training loss: 0.7609981298446655
Validation loss: 1.8649566237644484

Epoch: 5| Step: 5
Training loss: 1.3154703378677368
Validation loss: 1.8580686302595242

Epoch: 5| Step: 6
Training loss: 1.0944836139678955
Validation loss: 1.8648811309568343

Epoch: 5| Step: 7
Training loss: 1.5449737310409546
Validation loss: 1.864866695096416

Epoch: 5| Step: 8
Training loss: 1.18631911277771
Validation loss: 1.8725819177525018

Epoch: 5| Step: 9
Training loss: 1.1081888675689697
Validation loss: 1.8457057963135421

Epoch: 5| Step: 10
Training loss: 0.886553168296814
Validation loss: 1.848869139148343

Epoch: 271| Step: 0
Training loss: 1.385162591934204
Validation loss: 1.901826084301036

Epoch: 5| Step: 1
Training loss: 0.9038327932357788
Validation loss: 1.934764983833477

Epoch: 5| Step: 2
Training loss: 1.1752796173095703
Validation loss: 1.955918873510053

Epoch: 5| Step: 3
Training loss: 1.1445226669311523
Validation loss: 1.951545189785701

Epoch: 5| Step: 4
Training loss: 1.335938811302185
Validation loss: 1.9466763414362425

Epoch: 5| Step: 5
Training loss: 0.9251852035522461
Validation loss: 1.9158168300505607

Epoch: 5| Step: 6
Training loss: 0.9822966456413269
Validation loss: 1.8713642627962175

Epoch: 5| Step: 7
Training loss: 0.992017388343811
Validation loss: 1.8613005620177074

Epoch: 5| Step: 8
Training loss: 1.393099069595337
Validation loss: 1.8497981794418827

Epoch: 5| Step: 9
Training loss: 1.0942658185958862
Validation loss: 1.8549436792250602

Epoch: 5| Step: 10
Training loss: 1.1554765701293945
Validation loss: 1.8718486357760686

Epoch: 272| Step: 0
Training loss: 0.7098847031593323
Validation loss: 1.88915713115405

Epoch: 5| Step: 1
Training loss: 0.37710627913475037
Validation loss: 1.9073306616916452

Epoch: 5| Step: 2
Training loss: 1.3152568340301514
Validation loss: 1.9321399375956545

Epoch: 5| Step: 3
Training loss: 1.3086013793945312
Validation loss: 1.941341164291546

Epoch: 5| Step: 4
Training loss: 1.4027454853057861
Validation loss: 1.922777880904495

Epoch: 5| Step: 5
Training loss: 1.024566411972046
Validation loss: 1.909652030596169

Epoch: 5| Step: 6
Training loss: 1.509779930114746
Validation loss: 1.914382815361023

Epoch: 5| Step: 7
Training loss: 0.8718302845954895
Validation loss: 1.8891252830464353

Epoch: 5| Step: 8
Training loss: 1.2214312553405762
Validation loss: 1.8911890278580368

Epoch: 5| Step: 9
Training loss: 1.43399977684021
Validation loss: 1.9045922256285144

Epoch: 5| Step: 10
Training loss: 1.0865389108657837
Validation loss: 1.895946600103891

Epoch: 273| Step: 0
Training loss: 0.8399111032485962
Validation loss: 1.8872204865178754

Epoch: 5| Step: 1
Training loss: 0.9077862501144409
Validation loss: 1.8911625672412176

Epoch: 5| Step: 2
Training loss: 1.324356198310852
Validation loss: 1.9188516242529756

Epoch: 5| Step: 3
Training loss: 1.3034322261810303
Validation loss: 1.9186717130804574

Epoch: 5| Step: 4
Training loss: 0.9127599596977234
Validation loss: 1.8800899315905828

Epoch: 5| Step: 5
Training loss: 1.4081623554229736
Validation loss: 1.8690980249835598

Epoch: 5| Step: 6
Training loss: 0.9917224049568176
Validation loss: 1.851341667995658

Epoch: 5| Step: 7
Training loss: 0.5679488778114319
Validation loss: 1.8489294872489026

Epoch: 5| Step: 8
Training loss: 1.1799367666244507
Validation loss: 1.8383660931741037

Epoch: 5| Step: 9
Training loss: 1.0637582540512085
Validation loss: 1.834080812751606

Epoch: 5| Step: 10
Training loss: 1.3697469234466553
Validation loss: 1.822121666323754

Epoch: 274| Step: 0
Training loss: 1.0204296112060547
Validation loss: 1.8300459461827432

Epoch: 5| Step: 1
Training loss: 1.0678220987319946
Validation loss: 1.8446380425524969

Epoch: 5| Step: 2
Training loss: 1.058396339416504
Validation loss: 1.8525539495611703

Epoch: 5| Step: 3
Training loss: 0.7868996858596802
Validation loss: 1.8594950706728044

Epoch: 5| Step: 4
Training loss: 1.268390417098999
Validation loss: 1.8771461209943217

Epoch: 5| Step: 5
Training loss: 1.0754735469818115
Validation loss: 1.9265819262432795

Epoch: 5| Step: 6
Training loss: 0.9921398162841797
Validation loss: 1.912448859983875

Epoch: 5| Step: 7
Training loss: 0.9900798797607422
Validation loss: 1.878274412565334

Epoch: 5| Step: 8
Training loss: 1.2257416248321533
Validation loss: 1.8589725802021642

Epoch: 5| Step: 9
Training loss: 1.2142791748046875
Validation loss: 1.8544250072971467

Epoch: 5| Step: 10
Training loss: 1.1335554122924805
Validation loss: 1.8386194654690322

Epoch: 275| Step: 0
Training loss: 1.2452428340911865
Validation loss: 1.855650358302619

Epoch: 5| Step: 1
Training loss: 1.285869836807251
Validation loss: 1.8400175507350633

Epoch: 5| Step: 2
Training loss: 1.1070648431777954
Validation loss: 1.8465931518103487

Epoch: 5| Step: 3
Training loss: 1.1276867389678955
Validation loss: 1.8721161580854846

Epoch: 5| Step: 4
Training loss: 1.1423137187957764
Validation loss: 1.90980500559653

Epoch: 5| Step: 5
Training loss: 0.7651413679122925
Validation loss: 1.9424272647467993

Epoch: 5| Step: 6
Training loss: 1.064123511314392
Validation loss: 1.9325115578148955

Epoch: 5| Step: 7
Training loss: 1.0447218418121338
Validation loss: 1.9156804469323927

Epoch: 5| Step: 8
Training loss: 1.0425465106964111
Validation loss: 1.877410231098052

Epoch: 5| Step: 9
Training loss: 1.0448321104049683
Validation loss: 1.852642366963048

Epoch: 5| Step: 10
Training loss: 0.7837120890617371
Validation loss: 1.8242731581452072

Epoch: 276| Step: 0
Training loss: 1.2868878841400146
Validation loss: 1.843811450466033

Epoch: 5| Step: 1
Training loss: 1.1262657642364502
Validation loss: 1.8252261787332513

Epoch: 5| Step: 2
Training loss: 0.8212143778800964
Validation loss: 1.8405552294946486

Epoch: 5| Step: 3
Training loss: 1.140641450881958
Validation loss: 1.8676478106488463

Epoch: 5| Step: 4
Training loss: 0.8458281755447388
Validation loss: 1.8972095494629235

Epoch: 5| Step: 5
Training loss: 1.171657919883728
Validation loss: 1.908465628982872

Epoch: 5| Step: 6
Training loss: 0.9363082051277161
Validation loss: 1.9024793755623601

Epoch: 5| Step: 7
Training loss: 1.089689016342163
Validation loss: 1.8994930072497296

Epoch: 5| Step: 8
Training loss: 1.0962055921554565
Validation loss: 1.9168239614014984

Epoch: 5| Step: 9
Training loss: 1.037034273147583
Validation loss: 1.8679632512472009

Epoch: 5| Step: 10
Training loss: 1.141845464706421
Validation loss: 1.8693544557017665

Epoch: 277| Step: 0
Training loss: 0.8631321787834167
Validation loss: 1.8665792570319226

Epoch: 5| Step: 1
Training loss: 0.9705883264541626
Validation loss: 1.857919022601138

Epoch: 5| Step: 2
Training loss: 1.0390827655792236
Validation loss: 1.8549184940194572

Epoch: 5| Step: 3
Training loss: 1.1395556926727295
Validation loss: 1.8553235556489678

Epoch: 5| Step: 4
Training loss: 1.1594123840332031
Validation loss: 1.8571497624920261

Epoch: 5| Step: 5
Training loss: 1.2072360515594482
Validation loss: 1.8667353225010697

Epoch: 5| Step: 6
Training loss: 0.8931831121444702
Validation loss: 1.8759402959577498

Epoch: 5| Step: 7
Training loss: 1.0736758708953857
Validation loss: 1.8756523414324688

Epoch: 5| Step: 8
Training loss: 0.9080663919448853
Validation loss: 1.883072724906347

Epoch: 5| Step: 9
Training loss: 1.276811957359314
Validation loss: 1.9061999551711544

Epoch: 5| Step: 10
Training loss: 0.8549396991729736
Validation loss: 1.9086493663890387

Epoch: 278| Step: 0
Training loss: 0.974503219127655
Validation loss: 1.8308286589960898

Epoch: 5| Step: 1
Training loss: 0.9440988302230835
Validation loss: 1.8201847730144378

Epoch: 5| Step: 2
Training loss: 1.0230727195739746
Validation loss: 1.805340575915511

Epoch: 5| Step: 3
Training loss: 1.1949877738952637
Validation loss: 1.7997698899238341

Epoch: 5| Step: 4
Training loss: 1.0163835287094116
Validation loss: 1.7970424711063344

Epoch: 5| Step: 5
Training loss: 1.3974179029464722
Validation loss: 1.7821508735738776

Epoch: 5| Step: 6
Training loss: 0.9698126912117004
Validation loss: 1.79984240634467

Epoch: 5| Step: 7
Training loss: 0.980307936668396
Validation loss: 1.8009956767482143

Epoch: 5| Step: 8
Training loss: 1.1213619709014893
Validation loss: 1.8319871797356555

Epoch: 5| Step: 9
Training loss: 0.9189704656600952
Validation loss: 1.8957108272019254

Epoch: 5| Step: 10
Training loss: 1.1310224533081055
Validation loss: 1.9250717637359456

Epoch: 279| Step: 0
Training loss: 1.243950366973877
Validation loss: 1.9756021525270195

Epoch: 5| Step: 1
Training loss: 0.6620408296585083
Validation loss: 1.886174665984287

Epoch: 5| Step: 2
Training loss: 1.0135725736618042
Validation loss: 1.8254860062753

Epoch: 5| Step: 3
Training loss: 0.9564811587333679
Validation loss: 1.7956829929864535

Epoch: 5| Step: 4
Training loss: 1.2661770582199097
Validation loss: 1.8157541444224696

Epoch: 5| Step: 5
Training loss: 1.310685396194458
Validation loss: 1.8038149867006528

Epoch: 5| Step: 6
Training loss: 1.1562799215316772
Validation loss: 1.8080201559169318

Epoch: 5| Step: 7
Training loss: 1.3050545454025269
Validation loss: 1.8364289704189505

Epoch: 5| Step: 8
Training loss: 1.6452195644378662
Validation loss: 1.8916792305566932

Epoch: 5| Step: 9
Training loss: 0.8497335314750671
Validation loss: 1.9259887920912875

Epoch: 5| Step: 10
Training loss: 0.7757776975631714
Validation loss: 1.8964029819734636

Epoch: 280| Step: 0
Training loss: 0.8230963945388794
Validation loss: 1.8529833260402884

Epoch: 5| Step: 1
Training loss: 0.9230520129203796
Validation loss: 1.8476698270408056

Epoch: 5| Step: 2
Training loss: 1.0453814268112183
Validation loss: 1.8438180287679036

Epoch: 5| Step: 3
Training loss: 0.6513764262199402
Validation loss: 1.810951808447479

Epoch: 5| Step: 4
Training loss: 1.325641393661499
Validation loss: 1.8028073118579002

Epoch: 5| Step: 5
Training loss: 1.2566039562225342
Validation loss: 1.8051299600191013

Epoch: 5| Step: 6
Training loss: 1.124208688735962
Validation loss: 1.8197353616837533

Epoch: 5| Step: 7
Training loss: 1.3115719556808472
Validation loss: 1.8514094814177482

Epoch: 5| Step: 8
Training loss: 1.2001053094863892
Validation loss: 1.8833229823779034

Epoch: 5| Step: 9
Training loss: 1.100874423980713
Validation loss: 1.9671442342060868

Epoch: 5| Step: 10
Training loss: 0.7322556376457214
Validation loss: 1.9626427081323439

Epoch: 281| Step: 0
Training loss: 0.9876043200492859
Validation loss: 1.9067927842499108

Epoch: 5| Step: 1
Training loss: 1.1533972024917603
Validation loss: 1.8384845718260734

Epoch: 5| Step: 2
Training loss: 0.7924309968948364
Validation loss: 1.826743718116514

Epoch: 5| Step: 3
Training loss: 1.0000802278518677
Validation loss: 1.829917815423781

Epoch: 5| Step: 4
Training loss: 1.299822449684143
Validation loss: 1.8172266175670009

Epoch: 5| Step: 5
Training loss: 0.9988352060317993
Validation loss: 1.8103857745406449

Epoch: 5| Step: 6
Training loss: 1.1602327823638916
Validation loss: 1.8261191998758624

Epoch: 5| Step: 7
Training loss: 1.0735108852386475
Validation loss: 1.8248087308740104

Epoch: 5| Step: 8
Training loss: 1.0622669458389282
Validation loss: 1.8190194881090553

Epoch: 5| Step: 9
Training loss: 0.7903228998184204
Validation loss: 1.836533236247237

Epoch: 5| Step: 10
Training loss: 1.1065731048583984
Validation loss: 1.8829266384083738

Epoch: 282| Step: 0
Training loss: 0.913973331451416
Validation loss: 1.907780123013322

Epoch: 5| Step: 1
Training loss: 1.2348343133926392
Validation loss: 1.8773997086350636

Epoch: 5| Step: 2
Training loss: 1.0797765254974365
Validation loss: 1.846994270560562

Epoch: 5| Step: 3
Training loss: 1.6708272695541382
Validation loss: 1.8441798917708858

Epoch: 5| Step: 4
Training loss: 1.2445948123931885
Validation loss: 1.8388051576511835

Epoch: 5| Step: 5
Training loss: 0.7378157377243042
Validation loss: 1.799617600697343

Epoch: 5| Step: 6
Training loss: 0.9272226095199585
Validation loss: 1.8099615996883762

Epoch: 5| Step: 7
Training loss: 0.8469161987304688
Validation loss: 1.824828186342793

Epoch: 5| Step: 8
Training loss: 1.2579456567764282
Validation loss: 1.899112065633138

Epoch: 5| Step: 9
Training loss: 1.0773651599884033
Validation loss: 1.96517974586897

Epoch: 5| Step: 10
Training loss: 1.1630233526229858
Validation loss: 2.04473965655091

Epoch: 283| Step: 0
Training loss: 0.6934218406677246
Validation loss: 2.009362038745675

Epoch: 5| Step: 1
Training loss: 1.004791021347046
Validation loss: 1.936591104794574

Epoch: 5| Step: 2
Training loss: 1.3667184114456177
Validation loss: 1.9051412446524507

Epoch: 5| Step: 3
Training loss: 1.0782063007354736
Validation loss: 1.8689907263684016

Epoch: 5| Step: 4
Training loss: 1.4572184085845947
Validation loss: 1.877703062949642

Epoch: 5| Step: 5
Training loss: 0.9063366055488586
Validation loss: 1.886427282005228

Epoch: 5| Step: 6
Training loss: 0.6660462617874146
Validation loss: 1.8584021163243118

Epoch: 5| Step: 7
Training loss: 0.9708860516548157
Validation loss: 1.8465687497969596

Epoch: 5| Step: 8
Training loss: 1.041650652885437
Validation loss: 1.8253729856142433

Epoch: 5| Step: 9
Training loss: 1.0344266891479492
Validation loss: 1.8511319980826428

Epoch: 5| Step: 10
Training loss: 1.283912181854248
Validation loss: 1.8903667375605593

Epoch: 284| Step: 0
Training loss: 1.3409172296524048
Validation loss: 1.8864776690800984

Epoch: 5| Step: 1
Training loss: 0.8235724568367004
Validation loss: 1.9261661447504514

Epoch: 5| Step: 2
Training loss: 1.1730365753173828
Validation loss: 1.920432145877551

Epoch: 5| Step: 3
Training loss: 0.6708746552467346
Validation loss: 1.8813283917724446

Epoch: 5| Step: 4
Training loss: 0.9141786694526672
Validation loss: 1.8832934992287749

Epoch: 5| Step: 5
Training loss: 0.7523667216300964
Validation loss: 1.8659440573825632

Epoch: 5| Step: 6
Training loss: 1.2577742338180542
Validation loss: 1.8663199024815713

Epoch: 5| Step: 7
Training loss: 1.4579880237579346
Validation loss: 1.8801552185448267

Epoch: 5| Step: 8
Training loss: 0.8069890737533569
Validation loss: 1.8888900292816984

Epoch: 5| Step: 9
Training loss: 0.9127615094184875
Validation loss: 1.903247239769146

Epoch: 5| Step: 10
Training loss: 1.3051997423171997
Validation loss: 1.9271422547678794

Epoch: 285| Step: 0
Training loss: 1.0940005779266357
Validation loss: 1.932959815507294

Epoch: 5| Step: 1
Training loss: 1.0225253105163574
Validation loss: 1.9472278510370562

Epoch: 5| Step: 2
Training loss: 0.6685541272163391
Validation loss: 1.9240564889805292

Epoch: 5| Step: 3
Training loss: 0.9882356524467468
Validation loss: 1.8787334170392764

Epoch: 5| Step: 4
Training loss: 0.8818087577819824
Validation loss: 1.8225355930225824

Epoch: 5| Step: 5
Training loss: 1.221437692642212
Validation loss: 1.830099872363511

Epoch: 5| Step: 6
Training loss: 1.1801793575286865
Validation loss: 1.7917088949552147

Epoch: 5| Step: 7
Training loss: 1.3832013607025146
Validation loss: 1.7938436231305521

Epoch: 5| Step: 8
Training loss: 0.7955570816993713
Validation loss: 1.816725137413189

Epoch: 5| Step: 9
Training loss: 1.2131223678588867
Validation loss: 1.8028927285184142

Epoch: 5| Step: 10
Training loss: 1.0456187725067139
Validation loss: 1.848500838843725

Epoch: 286| Step: 0
Training loss: 0.8384031057357788
Validation loss: 1.8808185772229267

Epoch: 5| Step: 1
Training loss: 1.126363754272461
Validation loss: 1.914222122520529

Epoch: 5| Step: 2
Training loss: 1.0363805294036865
Validation loss: 1.9038666191921438

Epoch: 5| Step: 3
Training loss: 1.113678216934204
Validation loss: 1.96182160223684

Epoch: 5| Step: 4
Training loss: 0.9599466323852539
Validation loss: 1.9241521743036085

Epoch: 5| Step: 5
Training loss: 0.40616288781166077
Validation loss: 1.908132424918554

Epoch: 5| Step: 6
Training loss: 0.7146594524383545
Validation loss: 1.8569659584312028

Epoch: 5| Step: 7
Training loss: 0.9405044317245483
Validation loss: 1.80630156301683

Epoch: 5| Step: 8
Training loss: 1.1141877174377441
Validation loss: 1.8295046232079948

Epoch: 5| Step: 9
Training loss: 1.3781883716583252
Validation loss: 1.81280670883835

Epoch: 5| Step: 10
Training loss: 1.3361140489578247
Validation loss: 1.8210639517794374

Epoch: 287| Step: 0
Training loss: 1.1589128971099854
Validation loss: 1.8317995532866447

Epoch: 5| Step: 1
Training loss: 0.5822855234146118
Validation loss: 1.864010960825028

Epoch: 5| Step: 2
Training loss: 0.7795839309692383
Validation loss: 1.8543799231129308

Epoch: 5| Step: 3
Training loss: 1.0885002613067627
Validation loss: 1.8630413419456893

Epoch: 5| Step: 4
Training loss: 1.1459581851959229
Validation loss: 1.864023482927712

Epoch: 5| Step: 5
Training loss: 0.775420069694519
Validation loss: 1.8825971080410866

Epoch: 5| Step: 6
Training loss: 0.9317423701286316
Validation loss: 1.8903440211408882

Epoch: 5| Step: 7
Training loss: 0.9817781448364258
Validation loss: 1.8901148483317385

Epoch: 5| Step: 8
Training loss: 1.036523699760437
Validation loss: 1.902516677815427

Epoch: 5| Step: 9
Training loss: 1.1080209016799927
Validation loss: 1.8753828810107323

Epoch: 5| Step: 10
Training loss: 1.047750473022461
Validation loss: 1.884287985422278

Epoch: 288| Step: 0
Training loss: 0.8427985906600952
Validation loss: 1.847618660619182

Epoch: 5| Step: 1
Training loss: 1.0056495666503906
Validation loss: 1.8176322111519434

Epoch: 5| Step: 2
Training loss: 0.9835047721862793
Validation loss: 1.8428824268361574

Epoch: 5| Step: 3
Training loss: 1.2819535732269287
Validation loss: 1.8325804202787337

Epoch: 5| Step: 4
Training loss: 0.6308102011680603
Validation loss: 1.8131528874879241

Epoch: 5| Step: 5
Training loss: 0.8972027897834778
Validation loss: 1.7980263233184814

Epoch: 5| Step: 6
Training loss: 1.0156761407852173
Validation loss: 1.7780063921405422

Epoch: 5| Step: 7
Training loss: 1.2564456462860107
Validation loss: 1.7883070386866087

Epoch: 5| Step: 8
Training loss: 1.1656891107559204
Validation loss: 1.7703189516580233

Epoch: 5| Step: 9
Training loss: 0.8142646551132202
Validation loss: 1.7981046015216458

Epoch: 5| Step: 10
Training loss: 0.7781152129173279
Validation loss: 1.8000311684864823

Epoch: 289| Step: 0
Training loss: 0.9203963279724121
Validation loss: 1.8210207749438543

Epoch: 5| Step: 1
Training loss: 0.9678446650505066
Validation loss: 1.8250589242545507

Epoch: 5| Step: 2
Training loss: 1.1187859773635864
Validation loss: 1.8430907726287842

Epoch: 5| Step: 3
Training loss: 1.2610269784927368
Validation loss: 1.8379873767975838

Epoch: 5| Step: 4
Training loss: 1.0950944423675537
Validation loss: 1.8481846611986879

Epoch: 5| Step: 5
Training loss: 0.8363448977470398
Validation loss: 1.8145828657252814

Epoch: 5| Step: 6
Training loss: 0.9536879658699036
Validation loss: 1.7917249292455695

Epoch: 5| Step: 7
Training loss: 1.0269906520843506
Validation loss: 1.8104418118794758

Epoch: 5| Step: 8
Training loss: 0.7118068337440491
Validation loss: 1.8175421402018557

Epoch: 5| Step: 9
Training loss: 0.9574328660964966
Validation loss: 1.8114423034011677

Epoch: 5| Step: 10
Training loss: 0.5277042388916016
Validation loss: 1.8253524739255187

Epoch: 290| Step: 0
Training loss: 0.732896625995636
Validation loss: 1.8344201362261208

Epoch: 5| Step: 1
Training loss: 0.935336709022522
Validation loss: 1.85641570245066

Epoch: 5| Step: 2
Training loss: 1.3351329565048218
Validation loss: 1.8368063152477305

Epoch: 5| Step: 3
Training loss: 1.0678904056549072
Validation loss: 1.8428855506322717

Epoch: 5| Step: 4
Training loss: 0.9353841543197632
Validation loss: 1.8256552129663446

Epoch: 5| Step: 5
Training loss: 0.846304714679718
Validation loss: 1.785678494361139

Epoch: 5| Step: 6
Training loss: 0.6254936456680298
Validation loss: 1.790648192487737

Epoch: 5| Step: 7
Training loss: 0.9468814134597778
Validation loss: 1.7821356045302523

Epoch: 5| Step: 8
Training loss: 1.0031099319458008
Validation loss: 1.7818345305740193

Epoch: 5| Step: 9
Training loss: 0.8939642906188965
Validation loss: 1.8449062519176032

Epoch: 5| Step: 10
Training loss: 1.1388858556747437
Validation loss: 1.871455741185014

Epoch: 291| Step: 0
Training loss: 1.029759168624878
Validation loss: 1.872003742443618

Epoch: 5| Step: 1
Training loss: 1.168756365776062
Validation loss: 1.8878020919779295

Epoch: 5| Step: 2
Training loss: 1.195688009262085
Validation loss: 1.8464267035966277

Epoch: 5| Step: 3
Training loss: 1.006401538848877
Validation loss: 1.8364240315652662

Epoch: 5| Step: 4
Training loss: 0.9091120958328247
Validation loss: 1.8020942467515186

Epoch: 5| Step: 5
Training loss: 0.8443986177444458
Validation loss: 1.8030588729407198

Epoch: 5| Step: 6
Training loss: 0.7315337061882019
Validation loss: 1.7828782835314352

Epoch: 5| Step: 7
Training loss: 1.033414363861084
Validation loss: 1.808843308879483

Epoch: 5| Step: 8
Training loss: 0.9132852554321289
Validation loss: 1.800711001119306

Epoch: 5| Step: 9
Training loss: 0.8900867700576782
Validation loss: 1.8116183280944824

Epoch: 5| Step: 10
Training loss: 0.7277666926383972
Validation loss: 1.8493191029435845

Epoch: 292| Step: 0
Training loss: 0.758823812007904
Validation loss: 1.8686720248191588

Epoch: 5| Step: 1
Training loss: 1.078091025352478
Validation loss: 1.8971666110459195

Epoch: 5| Step: 2
Training loss: 1.1804931163787842
Validation loss: 1.8995539193512292

Epoch: 5| Step: 3
Training loss: 0.8062869906425476
Validation loss: 1.9194585507915867

Epoch: 5| Step: 4
Training loss: 0.7961925864219666
Validation loss: 1.864180431571058

Epoch: 5| Step: 5
Training loss: 0.9036412239074707
Validation loss: 1.857511358876382

Epoch: 5| Step: 6
Training loss: 0.5883133411407471
Validation loss: 1.8233031765107186

Epoch: 5| Step: 7
Training loss: 1.059253454208374
Validation loss: 1.8221829040076143

Epoch: 5| Step: 8
Training loss: 1.1181789636611938
Validation loss: 1.8192385217194915

Epoch: 5| Step: 9
Training loss: 0.8373454809188843
Validation loss: 1.8380919169354182

Epoch: 5| Step: 10
Training loss: 1.450982689857483
Validation loss: 1.8426128561778734

Epoch: 293| Step: 0
Training loss: 0.8445479273796082
Validation loss: 1.8491183121999104

Epoch: 5| Step: 1
Training loss: 0.6180817484855652
Validation loss: 1.8768011793013541

Epoch: 5| Step: 2
Training loss: 1.012913465499878
Validation loss: 1.8838982889729161

Epoch: 5| Step: 3
Training loss: 0.6499381065368652
Validation loss: 1.900250506657426

Epoch: 5| Step: 4
Training loss: 0.9709723591804504
Validation loss: 1.8862208794522028

Epoch: 5| Step: 5
Training loss: 1.2741845846176147
Validation loss: 1.9247345180921658

Epoch: 5| Step: 6
Training loss: 0.6909105181694031
Validation loss: 1.920900188466554

Epoch: 5| Step: 7
Training loss: 1.1209826469421387
Validation loss: 1.8828428150505148

Epoch: 5| Step: 8
Training loss: 0.9701926112174988
Validation loss: 1.8578375603563042

Epoch: 5| Step: 9
Training loss: 1.0591516494750977
Validation loss: 1.813477687938239

Epoch: 5| Step: 10
Training loss: 1.0246362686157227
Validation loss: 1.7928956785509664

Epoch: 294| Step: 0
Training loss: 1.062516450881958
Validation loss: 1.7863802499668573

Epoch: 5| Step: 1
Training loss: 1.3644921779632568
Validation loss: 1.8091425562417636

Epoch: 5| Step: 2
Training loss: 0.5602036714553833
Validation loss: 1.8290281526504024

Epoch: 5| Step: 3
Training loss: 0.9727357625961304
Validation loss: 1.8716974284059258

Epoch: 5| Step: 4
Training loss: 0.8526474237442017
Validation loss: 1.8498185603849349

Epoch: 5| Step: 5
Training loss: 0.77755206823349
Validation loss: 1.823267186841657

Epoch: 5| Step: 6
Training loss: 1.083512544631958
Validation loss: 1.8067578846408474

Epoch: 5| Step: 7
Training loss: 0.6421377062797546
Validation loss: 1.8279664708722023

Epoch: 5| Step: 8
Training loss: 0.9828449487686157
Validation loss: 1.8577570299948416

Epoch: 5| Step: 9
Training loss: 1.2307963371276855
Validation loss: 1.895255220833645

Epoch: 5| Step: 10
Training loss: 0.7518234252929688
Validation loss: 1.9504022047083864

Epoch: 295| Step: 0
Training loss: 0.909399688243866
Validation loss: 1.946167899716285

Epoch: 5| Step: 1
Training loss: 0.6844253540039062
Validation loss: 1.90835783045779

Epoch: 5| Step: 2
Training loss: 1.0290626287460327
Validation loss: 1.9111568171490905

Epoch: 5| Step: 3
Training loss: 0.580710768699646
Validation loss: 1.8732128540674846

Epoch: 5| Step: 4
Training loss: 0.7528907060623169
Validation loss: 1.8627115193233694

Epoch: 5| Step: 5
Training loss: 0.8035308718681335
Validation loss: 1.8298404844858314

Epoch: 5| Step: 6
Training loss: 1.3361022472381592
Validation loss: 1.8297196536935785

Epoch: 5| Step: 7
Training loss: 0.9879270792007446
Validation loss: 1.7988617791924426

Epoch: 5| Step: 8
Training loss: 0.8583683967590332
Validation loss: 1.815108521010286

Epoch: 5| Step: 9
Training loss: 1.0507452487945557
Validation loss: 1.853552645252597

Epoch: 5| Step: 10
Training loss: 1.1713286638259888
Validation loss: 1.9022259609673613

Epoch: 296| Step: 0
Training loss: 0.44603976607322693
Validation loss: 1.9461319984928254

Epoch: 5| Step: 1
Training loss: 1.1181919574737549
Validation loss: 1.9624525885428152

Epoch: 5| Step: 2
Training loss: 0.8961380124092102
Validation loss: 1.8748779309693204

Epoch: 5| Step: 3
Training loss: 0.7709319591522217
Validation loss: 1.8401281731103056

Epoch: 5| Step: 4
Training loss: 0.9768717885017395
Validation loss: 1.7828342478762391

Epoch: 5| Step: 5
Training loss: 1.1878975629806519
Validation loss: 1.7574949700345275

Epoch: 5| Step: 6
Training loss: 1.2991122007369995
Validation loss: 1.7813492923654535

Epoch: 5| Step: 7
Training loss: 1.0860251188278198
Validation loss: 1.7689086878171532

Epoch: 5| Step: 8
Training loss: 0.7724229097366333
Validation loss: 1.7638058226595643

Epoch: 5| Step: 9
Training loss: 0.8172337412834167
Validation loss: 1.8360809696617948

Epoch: 5| Step: 10
Training loss: 0.971099317073822
Validation loss: 1.867224972735169

Epoch: 297| Step: 0
Training loss: 1.002915382385254
Validation loss: 1.870507578695974

Epoch: 5| Step: 1
Training loss: 1.180519700050354
Validation loss: 1.8773949261634582

Epoch: 5| Step: 2
Training loss: 0.882987380027771
Validation loss: 1.8666582338271602

Epoch: 5| Step: 3
Training loss: 0.7942702770233154
Validation loss: 1.853298120601203

Epoch: 5| Step: 4
Training loss: 1.0192161798477173
Validation loss: 1.8192589500898957

Epoch: 5| Step: 5
Training loss: 1.0895339250564575
Validation loss: 1.8390039705461072

Epoch: 5| Step: 6
Training loss: 0.5568917989730835
Validation loss: 1.8338540728374193

Epoch: 5| Step: 7
Training loss: 0.7898640632629395
Validation loss: 1.8324676341907953

Epoch: 5| Step: 8
Training loss: 0.9923930168151855
Validation loss: 1.8657579973179808

Epoch: 5| Step: 9
Training loss: 0.9609621167182922
Validation loss: 1.9120225726917226

Epoch: 5| Step: 10
Training loss: 0.9570640325546265
Validation loss: 1.9529417304582493

Epoch: 298| Step: 0
Training loss: 0.9769066572189331
Validation loss: 1.994391897673248

Epoch: 5| Step: 1
Training loss: 0.6643693447113037
Validation loss: 1.974229589585335

Epoch: 5| Step: 2
Training loss: 0.983709454536438
Validation loss: 1.9321132090783888

Epoch: 5| Step: 3
Training loss: 1.048089861869812
Validation loss: 1.8941370441067604

Epoch: 5| Step: 4
Training loss: 1.4247061014175415
Validation loss: 1.8655230127355105

Epoch: 5| Step: 5
Training loss: 0.6459581255912781
Validation loss: 1.8170353174209595

Epoch: 5| Step: 6
Training loss: 1.0132461786270142
Validation loss: 1.8026539792296707

Epoch: 5| Step: 7
Training loss: 0.529448390007019
Validation loss: 1.8086949189503987

Epoch: 5| Step: 8
Training loss: 0.627373993396759
Validation loss: 1.8216603891823882

Epoch: 5| Step: 9
Training loss: 0.7997492551803589
Validation loss: 1.8254492090594383

Epoch: 5| Step: 10
Training loss: 1.2324141263961792
Validation loss: 1.8737331410889984

Epoch: 299| Step: 0
Training loss: 1.2708508968353271
Validation loss: 1.880139414982129

Epoch: 5| Step: 1
Training loss: 1.3042746782302856
Validation loss: 1.8565382226820915

Epoch: 5| Step: 2
Training loss: 0.528714656829834
Validation loss: 1.807704379481654

Epoch: 5| Step: 3
Training loss: 0.6212283968925476
Validation loss: 1.772519165469754

Epoch: 5| Step: 4
Training loss: 1.0856480598449707
Validation loss: 1.742568277543591

Epoch: 5| Step: 5
Training loss: 0.7109676599502563
Validation loss: 1.7555723856854182

Epoch: 5| Step: 6
Training loss: 1.0606515407562256
Validation loss: 1.8051320506680397

Epoch: 5| Step: 7
Training loss: 0.9910815954208374
Validation loss: 1.8295590185349988

Epoch: 5| Step: 8
Training loss: 0.43610692024230957
Validation loss: 1.8433171773469577

Epoch: 5| Step: 9
Training loss: 1.0921053886413574
Validation loss: 1.8604898311758553

Epoch: 5| Step: 10
Training loss: 0.8774382472038269
Validation loss: 1.8900333130231468

Epoch: 300| Step: 0
Training loss: 0.8211104273796082
Validation loss: 1.8347767360748783

Epoch: 5| Step: 1
Training loss: 0.5100287199020386
Validation loss: 1.8451659961413311

Epoch: 5| Step: 2
Training loss: 1.1273469924926758
Validation loss: 1.8336244039638068

Epoch: 5| Step: 3
Training loss: 1.2460997104644775
Validation loss: 1.8413161680262575

Epoch: 5| Step: 4
Training loss: 0.7648171186447144
Validation loss: 1.8732210948903074

Epoch: 5| Step: 5
Training loss: 1.0065572261810303
Validation loss: 1.8764104022774646

Epoch: 5| Step: 6
Training loss: 1.0672109127044678
Validation loss: 1.8623300598513695

Epoch: 5| Step: 7
Training loss: 1.134530782699585
Validation loss: 1.8308926628481956

Epoch: 5| Step: 8
Training loss: 0.6330541372299194
Validation loss: 1.7903073128833566

Epoch: 5| Step: 9
Training loss: 0.4963718354701996
Validation loss: 1.8234912298058952

Epoch: 5| Step: 10
Training loss: 0.9330123066902161
Validation loss: 1.8077493765020882

Testing loss: 2.36950511402554
