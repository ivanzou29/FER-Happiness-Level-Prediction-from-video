Epoch: 1| Step: 0
Training loss: 4.9693522453308105
Validation loss: 5.165719673197756

Epoch: 5| Step: 1
Training loss: 4.304080963134766
Validation loss: 5.14260697108443

Epoch: 5| Step: 2
Training loss: 5.142280101776123
Validation loss: 5.119546228839505

Epoch: 5| Step: 3
Training loss: 4.753580570220947
Validation loss: 5.095290322457591

Epoch: 5| Step: 4
Training loss: 4.877721309661865
Validation loss: 5.068475297702256

Epoch: 5| Step: 5
Training loss: 3.7863526344299316
Validation loss: 5.037740445906116

Epoch: 5| Step: 6
Training loss: 6.4311981201171875
Validation loss: 5.001818703066919

Epoch: 5| Step: 7
Training loss: 3.9836673736572266
Validation loss: 4.963129079470071

Epoch: 5| Step: 8
Training loss: 5.075699329376221
Validation loss: 4.921359790268765

Epoch: 5| Step: 9
Training loss: 4.743117332458496
Validation loss: 4.8758630137289725

Epoch: 5| Step: 10
Training loss: 4.894791603088379
Validation loss: 4.826867124085785

Epoch: 2| Step: 0
Training loss: 4.881239891052246
Validation loss: 4.774071160183158

Epoch: 5| Step: 1
Training loss: 4.043037414550781
Validation loss: 4.718956952453942

Epoch: 5| Step: 2
Training loss: 4.528411388397217
Validation loss: 4.66223096334806

Epoch: 5| Step: 3
Training loss: 3.778290271759033
Validation loss: 4.605843446588003

Epoch: 5| Step: 4
Training loss: 4.345632553100586
Validation loss: 4.5471149054906705

Epoch: 5| Step: 5
Training loss: 3.7825474739074707
Validation loss: 4.487621174063734

Epoch: 5| Step: 6
Training loss: 4.395873546600342
Validation loss: 4.4314996657832975

Epoch: 5| Step: 7
Training loss: 4.237736701965332
Validation loss: 4.377065586787398

Epoch: 5| Step: 8
Training loss: 3.1853485107421875
Validation loss: 4.3262805913084295

Epoch: 5| Step: 9
Training loss: 5.646939277648926
Validation loss: 4.277210589378111

Epoch: 5| Step: 10
Training loss: 4.306819438934326
Validation loss: 4.229245534507177

Epoch: 3| Step: 0
Training loss: 3.9694151878356934
Validation loss: 4.17868382956392

Epoch: 5| Step: 1
Training loss: 3.5495457649230957
Validation loss: 4.127925657456921

Epoch: 5| Step: 2
Training loss: 4.64450740814209
Validation loss: 4.07448269731255

Epoch: 5| Step: 3
Training loss: 3.821762800216675
Validation loss: 4.01912340810222

Epoch: 5| Step: 4
Training loss: 3.4949240684509277
Validation loss: 3.971894689785537

Epoch: 5| Step: 5
Training loss: 3.556394100189209
Validation loss: 3.9361728442612516

Epoch: 5| Step: 6
Training loss: 2.93119478225708
Validation loss: 3.9004775888176373

Epoch: 5| Step: 7
Training loss: 4.699301719665527
Validation loss: 3.8698926177076114

Epoch: 5| Step: 8
Training loss: 3.6896510124206543
Validation loss: 3.8442509610165834

Epoch: 5| Step: 9
Training loss: 3.9331040382385254
Validation loss: 3.8230982031873477

Epoch: 5| Step: 10
Training loss: 3.5758626461029053
Validation loss: 3.803713306303947

Epoch: 4| Step: 0
Training loss: 4.0363054275512695
Validation loss: 3.775527728501187

Epoch: 5| Step: 1
Training loss: 3.0546979904174805
Validation loss: 3.74288438212487

Epoch: 5| Step: 2
Training loss: 3.457507610321045
Validation loss: 3.72728992021212

Epoch: 5| Step: 3
Training loss: 3.6086158752441406
Validation loss: 3.695882556258991

Epoch: 5| Step: 4
Training loss: 3.1883130073547363
Validation loss: 3.671995319345946

Epoch: 5| Step: 5
Training loss: 3.2066147327423096
Validation loss: 3.6468716411180395

Epoch: 5| Step: 6
Training loss: 4.0347185134887695
Validation loss: 3.629144360942225

Epoch: 5| Step: 7
Training loss: 2.8461146354675293
Validation loss: 3.600506044203235

Epoch: 5| Step: 8
Training loss: 3.6905746459960938
Validation loss: 3.585511005052956

Epoch: 5| Step: 9
Training loss: 3.9015746116638184
Validation loss: 3.571907489530502

Epoch: 5| Step: 10
Training loss: 4.287107467651367
Validation loss: 3.553596886255408

Epoch: 5| Step: 0
Training loss: 3.5074806213378906
Validation loss: 3.5369105185231855

Epoch: 5| Step: 1
Training loss: 3.159327745437622
Validation loss: 3.526265821149272

Epoch: 5| Step: 2
Training loss: 4.557693958282471
Validation loss: 3.5194241359669673

Epoch: 5| Step: 3
Training loss: 3.987781524658203
Validation loss: 3.5146382085738646

Epoch: 5| Step: 4
Training loss: 2.753006935119629
Validation loss: 3.5058855292617634

Epoch: 5| Step: 5
Training loss: 4.231098175048828
Validation loss: 3.4951505097009803

Epoch: 5| Step: 6
Training loss: 2.5387930870056152
Validation loss: 3.482967089581233

Epoch: 5| Step: 7
Training loss: 3.73380970954895
Validation loss: 3.473250996681952

Epoch: 5| Step: 8
Training loss: 2.4593124389648438
Validation loss: 3.4600270461010676

Epoch: 5| Step: 9
Training loss: 4.012106418609619
Validation loss: 3.451183557510376

Epoch: 5| Step: 10
Training loss: 2.6604459285736084
Validation loss: 3.4457783135034705

Epoch: 6| Step: 0
Training loss: 2.9034206867218018
Validation loss: 3.4400703035375124

Epoch: 5| Step: 1
Training loss: 3.1606194972991943
Validation loss: 3.438579628544469

Epoch: 5| Step: 2
Training loss: 4.450688362121582
Validation loss: 3.4289023722371748

Epoch: 5| Step: 3
Training loss: 2.649724006652832
Validation loss: 3.417707581673899

Epoch: 5| Step: 4
Training loss: 2.9235692024230957
Validation loss: 3.404153198324224

Epoch: 5| Step: 5
Training loss: 3.8277060985565186
Validation loss: 3.3960726440593763

Epoch: 5| Step: 6
Training loss: 3.105311632156372
Validation loss: 3.3865365776964413

Epoch: 5| Step: 7
Training loss: 3.1984574794769287
Validation loss: 3.379402470845048

Epoch: 5| Step: 8
Training loss: 3.4500679969787598
Validation loss: 3.3654766159672893

Epoch: 5| Step: 9
Training loss: 3.3997833728790283
Validation loss: 3.363420614632227

Epoch: 5| Step: 10
Training loss: 3.7681517601013184
Validation loss: 3.3579212234866236

Epoch: 7| Step: 0
Training loss: 3.332569122314453
Validation loss: 3.3467941719998597

Epoch: 5| Step: 1
Training loss: 3.5568385124206543
Validation loss: 3.3298262524348434

Epoch: 5| Step: 2
Training loss: 3.683727264404297
Validation loss: 3.321470283692883

Epoch: 5| Step: 3
Training loss: 3.61006498336792
Validation loss: 3.314893825079805

Epoch: 5| Step: 4
Training loss: 3.202613115310669
Validation loss: 3.30860540943761

Epoch: 5| Step: 5
Training loss: 2.373079299926758
Validation loss: 3.297794444586641

Epoch: 5| Step: 6
Training loss: 2.8634984493255615
Validation loss: 3.281606779303602

Epoch: 5| Step: 7
Training loss: 3.7549891471862793
Validation loss: 3.27406152602165

Epoch: 5| Step: 8
Training loss: 3.5087103843688965
Validation loss: 3.2836210778964463

Epoch: 5| Step: 9
Training loss: 3.492555618286133
Validation loss: 3.2594858215701197

Epoch: 5| Step: 10
Training loss: 2.484196901321411
Validation loss: 3.2527632328771774

Epoch: 8| Step: 0
Training loss: 3.649951934814453
Validation loss: 3.2508046498862644

Epoch: 5| Step: 1
Training loss: 3.028296709060669
Validation loss: 3.2332673380451817

Epoch: 5| Step: 2
Training loss: 3.0841915607452393
Validation loss: 3.22541880607605

Epoch: 5| Step: 3
Training loss: 2.8352408409118652
Validation loss: 3.223484916071738

Epoch: 5| Step: 4
Training loss: 4.080959796905518
Validation loss: 3.2126408776929303

Epoch: 5| Step: 5
Training loss: 2.8541786670684814
Validation loss: 3.2034717964869674

Epoch: 5| Step: 6
Training loss: 2.9896726608276367
Validation loss: 3.1982238343966904

Epoch: 5| Step: 7
Training loss: 3.6086814403533936
Validation loss: 3.1923234334556003

Epoch: 5| Step: 8
Training loss: 2.0683822631835938
Validation loss: 3.1733271434742916

Epoch: 5| Step: 9
Training loss: 3.4529895782470703
Validation loss: 3.168771448955741

Epoch: 5| Step: 10
Training loss: 3.5716805458068848
Validation loss: 3.1635867062435357

Epoch: 9| Step: 0
Training loss: 4.5302300453186035
Validation loss: 3.1509502703143704

Epoch: 5| Step: 1
Training loss: 3.6168301105499268
Validation loss: 3.140121882961642

Epoch: 5| Step: 2
Training loss: 3.612119674682617
Validation loss: 3.1372679997515935

Epoch: 5| Step: 3
Training loss: 3.7265326976776123
Validation loss: 3.1190288118136826

Epoch: 5| Step: 4
Training loss: 2.6115493774414062
Validation loss: 3.113354354776362

Epoch: 5| Step: 5
Training loss: 2.9192111492156982
Validation loss: 3.1191847708917435

Epoch: 5| Step: 6
Training loss: 2.601539134979248
Validation loss: 3.090276559193929

Epoch: 5| Step: 7
Training loss: 2.525522232055664
Validation loss: 3.0929834355590162

Epoch: 5| Step: 8
Training loss: 2.699719190597534
Validation loss: 3.092925415244154

Epoch: 5| Step: 9
Training loss: 2.8422746658325195
Validation loss: 3.0914472815810994

Epoch: 5| Step: 10
Training loss: 2.82353138923645
Validation loss: 3.0717576601172007

Epoch: 10| Step: 0
Training loss: 2.849112033843994
Validation loss: 3.0612913639314714

Epoch: 5| Step: 1
Training loss: 2.98722505569458
Validation loss: 3.058801717655633

Epoch: 5| Step: 2
Training loss: 3.28667950630188
Validation loss: 3.054135645589521

Epoch: 5| Step: 3
Training loss: 3.1482746601104736
Validation loss: 3.0434810115445043

Epoch: 5| Step: 4
Training loss: 3.360490322113037
Validation loss: 3.026543163484143

Epoch: 5| Step: 5
Training loss: 3.010892152786255
Validation loss: 3.008025002735917

Epoch: 5| Step: 6
Training loss: 2.385430335998535
Validation loss: 2.9949313978995047

Epoch: 5| Step: 7
Training loss: 2.9308249950408936
Validation loss: 2.989189068476359

Epoch: 5| Step: 8
Training loss: 2.5662550926208496
Validation loss: 2.986382561345254

Epoch: 5| Step: 9
Training loss: 3.901870012283325
Validation loss: 2.993962169975363

Epoch: 5| Step: 10
Training loss: 3.4879772663116455
Validation loss: 2.9797655613191667

Epoch: 11| Step: 0
Training loss: 2.5044000148773193
Validation loss: 2.9705883226087018

Epoch: 5| Step: 1
Training loss: 2.884779691696167
Validation loss: 2.9903583911157425

Epoch: 5| Step: 2
Training loss: 2.8728065490722656
Validation loss: 2.9736166513094338

Epoch: 5| Step: 3
Training loss: 2.7290053367614746
Validation loss: 2.9606017810042187

Epoch: 5| Step: 4
Training loss: 2.693506956100464
Validation loss: 2.9445229935389694

Epoch: 5| Step: 5
Training loss: 2.2491261959075928
Validation loss: 2.9350807641142156

Epoch: 5| Step: 6
Training loss: 3.4072718620300293
Validation loss: 2.9368438951430784

Epoch: 5| Step: 7
Training loss: 3.206162929534912
Validation loss: 2.949431296317808

Epoch: 5| Step: 8
Training loss: 3.6633687019348145
Validation loss: 2.9486393261981267

Epoch: 5| Step: 9
Training loss: 4.258698463439941
Validation loss: 2.9233655827019804

Epoch: 5| Step: 10
Training loss: 2.793403387069702
Validation loss: 2.9113178919720393

Epoch: 12| Step: 0
Training loss: 2.470120906829834
Validation loss: 2.905460952430643

Epoch: 5| Step: 1
Training loss: 2.8815882205963135
Validation loss: 2.901287083984703

Epoch: 5| Step: 2
Training loss: 2.822718381881714
Validation loss: 2.9008257619796263

Epoch: 5| Step: 3
Training loss: 2.9830586910247803
Validation loss: 2.8948621211513395

Epoch: 5| Step: 4
Training loss: 3.112793445587158
Validation loss: 2.8838202645701747

Epoch: 5| Step: 5
Training loss: 2.9258480072021484
Validation loss: 2.870205648483769

Epoch: 5| Step: 6
Training loss: 2.8786022663116455
Validation loss: 2.858357244922269

Epoch: 5| Step: 7
Training loss: 2.9350802898406982
Validation loss: 2.8465151966259046

Epoch: 5| Step: 8
Training loss: 3.144301652908325
Validation loss: 2.8380775759297032

Epoch: 5| Step: 9
Training loss: 3.467852830886841
Validation loss: 2.839841978524321

Epoch: 5| Step: 10
Training loss: 3.079697370529175
Validation loss: 2.836065851232057

Epoch: 13| Step: 0
Training loss: 2.775473117828369
Validation loss: 2.8210615393935994

Epoch: 5| Step: 1
Training loss: 2.859833240509033
Validation loss: 2.830823149732364

Epoch: 5| Step: 2
Training loss: 2.5084939002990723
Validation loss: 2.803131344497845

Epoch: 5| Step: 3
Training loss: 3.036158323287964
Validation loss: 2.7992362104436403

Epoch: 5| Step: 4
Training loss: 2.9605212211608887
Validation loss: 2.7918136504388626

Epoch: 5| Step: 5
Training loss: 2.5270748138427734
Validation loss: 2.78454924655217

Epoch: 5| Step: 6
Training loss: 2.9792556762695312
Validation loss: 2.7795387955122095

Epoch: 5| Step: 7
Training loss: 2.8928050994873047
Validation loss: 2.779064355358001

Epoch: 5| Step: 8
Training loss: 3.171018362045288
Validation loss: 2.77033632545061

Epoch: 5| Step: 9
Training loss: 3.0128846168518066
Validation loss: 2.765507008439751

Epoch: 5| Step: 10
Training loss: 3.5140905380249023
Validation loss: 2.758677323659261

Epoch: 14| Step: 0
Training loss: 2.4422812461853027
Validation loss: 2.755446252002511

Epoch: 5| Step: 1
Training loss: 2.684380054473877
Validation loss: 2.74879196382338

Epoch: 5| Step: 2
Training loss: 3.077374219894409
Validation loss: 2.7402213747783373

Epoch: 5| Step: 3
Training loss: 2.4826667308807373
Validation loss: 2.7349592178098616

Epoch: 5| Step: 4
Training loss: 3.03123140335083
Validation loss: 2.7277924886313816

Epoch: 5| Step: 5
Training loss: 3.400620937347412
Validation loss: 2.721691234137422

Epoch: 5| Step: 6
Training loss: 2.685422420501709
Validation loss: 2.7147060619887484

Epoch: 5| Step: 7
Training loss: 2.4459853172302246
Validation loss: 2.71230633284456

Epoch: 5| Step: 8
Training loss: 2.9347074031829834
Validation loss: 2.7076349540423323

Epoch: 5| Step: 9
Training loss: 3.0348105430603027
Validation loss: 2.7087526321411133

Epoch: 5| Step: 10
Training loss: 3.568901777267456
Validation loss: 2.6899448082011235

Epoch: 15| Step: 0
Training loss: 2.453092575073242
Validation loss: 2.6879810710107126

Epoch: 5| Step: 1
Training loss: 3.1641182899475098
Validation loss: 2.680778000944404

Epoch: 5| Step: 2
Training loss: 2.59298038482666
Validation loss: 2.680030252343865

Epoch: 5| Step: 3
Training loss: 3.1921989917755127
Validation loss: 2.6840304738731793

Epoch: 5| Step: 4
Training loss: 2.7612133026123047
Validation loss: 2.680376478420791

Epoch: 5| Step: 5
Training loss: 3.199253559112549
Validation loss: 2.6634620620358374

Epoch: 5| Step: 6
Training loss: 3.1221604347229004
Validation loss: 2.694940738780524

Epoch: 5| Step: 7
Training loss: 3.5322940349578857
Validation loss: 2.6470616812347085

Epoch: 5| Step: 8
Training loss: 3.0061254501342773
Validation loss: 2.6607439338520007

Epoch: 5| Step: 9
Training loss: 2.3303587436676025
Validation loss: 2.6839764246376614

Epoch: 5| Step: 10
Training loss: 1.7508878707885742
Validation loss: 2.7115243763052006

Epoch: 16| Step: 0
Training loss: 1.8377994298934937
Validation loss: 2.7573069705758044

Epoch: 5| Step: 1
Training loss: 3.137322187423706
Validation loss: 2.726677317773142

Epoch: 5| Step: 2
Training loss: 2.961167573928833
Validation loss: 2.6549442404059955

Epoch: 5| Step: 3
Training loss: 3.1677134037017822
Validation loss: 2.6470214500222156

Epoch: 5| Step: 4
Training loss: 3.3594717979431152
Validation loss: 2.6350110012997865

Epoch: 5| Step: 5
Training loss: 3.028982162475586
Validation loss: 2.6376992194883284

Epoch: 5| Step: 6
Training loss: 2.865678310394287
Validation loss: 2.6392214349521104

Epoch: 5| Step: 7
Training loss: 2.4365077018737793
Validation loss: 2.647911294814079

Epoch: 5| Step: 8
Training loss: 2.2136764526367188
Validation loss: 2.659217239708029

Epoch: 5| Step: 9
Training loss: 3.1885459423065186
Validation loss: 2.6607033411661782

Epoch: 5| Step: 10
Training loss: 3.087911367416382
Validation loss: 2.6498129906192904

Epoch: 17| Step: 0
Training loss: 3.2397632598876953
Validation loss: 2.6259455014300603

Epoch: 5| Step: 1
Training loss: 2.7605793476104736
Validation loss: 2.616401390362811

Epoch: 5| Step: 2
Training loss: 2.5875027179718018
Validation loss: 2.6147815309545046

Epoch: 5| Step: 3
Training loss: 3.0053443908691406
Validation loss: 2.6176787038003244

Epoch: 5| Step: 4
Training loss: 3.00529408454895
Validation loss: 2.623662112861551

Epoch: 5| Step: 5
Training loss: 2.4051513671875
Validation loss: 2.621853341338455

Epoch: 5| Step: 6
Training loss: 3.163343667984009
Validation loss: 2.6292789136209795

Epoch: 5| Step: 7
Training loss: 2.913760185241699
Validation loss: 2.5989751123612925

Epoch: 5| Step: 8
Training loss: 3.049522876739502
Validation loss: 2.57930689473306

Epoch: 5| Step: 9
Training loss: 1.9851741790771484
Validation loss: 2.5683358946154193

Epoch: 5| Step: 10
Training loss: 2.860663652420044
Validation loss: 2.567082440981301

Epoch: 18| Step: 0
Training loss: 2.471315383911133
Validation loss: 2.56199562421409

Epoch: 5| Step: 1
Training loss: 2.757661819458008
Validation loss: 2.5586524189159436

Epoch: 5| Step: 2
Training loss: 2.887274742126465
Validation loss: 2.55533573191653

Epoch: 5| Step: 3
Training loss: 2.6226067543029785
Validation loss: 2.55605230023784

Epoch: 5| Step: 4
Training loss: 2.772219657897949
Validation loss: 2.555944783713228

Epoch: 5| Step: 5
Training loss: 3.4932548999786377
Validation loss: 2.544813568874072

Epoch: 5| Step: 6
Training loss: 2.558680534362793
Validation loss: 2.539093114996469

Epoch: 5| Step: 7
Training loss: 2.6176342964172363
Validation loss: 2.5354574213745775

Epoch: 5| Step: 8
Training loss: 3.2086424827575684
Validation loss: 2.5377492058661675

Epoch: 5| Step: 9
Training loss: 2.967989206314087
Validation loss: 2.5286824062306392

Epoch: 5| Step: 10
Training loss: 2.0780856609344482
Validation loss: 2.5182398314117105

Epoch: 19| Step: 0
Training loss: 3.084376573562622
Validation loss: 2.5247059842591644

Epoch: 5| Step: 1
Training loss: 2.9116342067718506
Validation loss: 2.522518470723142

Epoch: 5| Step: 2
Training loss: 3.4221019744873047
Validation loss: 2.5247695856196906

Epoch: 5| Step: 3
Training loss: 2.751011371612549
Validation loss: 2.529609398175311

Epoch: 5| Step: 4
Training loss: 2.290592908859253
Validation loss: 2.547944945673789

Epoch: 5| Step: 5
Training loss: 2.8275599479675293
Validation loss: 2.5838320306552354

Epoch: 5| Step: 6
Training loss: 2.1472275257110596
Validation loss: 2.5676545404618785

Epoch: 5| Step: 7
Training loss: 2.7026259899139404
Validation loss: 2.534333534138177

Epoch: 5| Step: 8
Training loss: 2.801459789276123
Validation loss: 2.515047355364728

Epoch: 5| Step: 9
Training loss: 2.280393600463867
Validation loss: 2.5124107945349907

Epoch: 5| Step: 10
Training loss: 3.178023338317871
Validation loss: 2.505292909119719

Epoch: 20| Step: 0
Training loss: 3.263486385345459
Validation loss: 2.506082001552787

Epoch: 5| Step: 1
Training loss: 1.6046955585479736
Validation loss: 2.5056998345159713

Epoch: 5| Step: 2
Training loss: 2.0352165699005127
Validation loss: 2.5682008189539753

Epoch: 5| Step: 3
Training loss: 3.1623668670654297
Validation loss: 2.6112460705541793

Epoch: 5| Step: 4
Training loss: 3.3144569396972656
Validation loss: 2.6002702354103007

Epoch: 5| Step: 5
Training loss: 2.7632384300231934
Validation loss: 2.5830970682123655

Epoch: 5| Step: 6
Training loss: 2.7268567085266113
Validation loss: 2.582946664543562

Epoch: 5| Step: 7
Training loss: 3.00917387008667
Validation loss: 2.5832330078207035

Epoch: 5| Step: 8
Training loss: 3.5047740936279297
Validation loss: 2.5713797538511214

Epoch: 5| Step: 9
Training loss: 2.7052884101867676
Validation loss: 2.561114275327293

Epoch: 5| Step: 10
Training loss: 2.4708642959594727
Validation loss: 2.5458758877169703

Epoch: 21| Step: 0
Training loss: 2.6957714557647705
Validation loss: 2.53625851292764

Epoch: 5| Step: 1
Training loss: 2.7686214447021484
Validation loss: 2.540024208766158

Epoch: 5| Step: 2
Training loss: 3.1629226207733154
Validation loss: 2.5592262360357467

Epoch: 5| Step: 3
Training loss: 3.347759962081909
Validation loss: 2.5512263544144167

Epoch: 5| Step: 4
Training loss: 2.010040283203125
Validation loss: 2.5442567281825568

Epoch: 5| Step: 5
Training loss: 2.6065571308135986
Validation loss: 2.5294397800199446

Epoch: 5| Step: 6
Training loss: 2.238800525665283
Validation loss: 2.524606507311585

Epoch: 5| Step: 7
Training loss: 3.1174654960632324
Validation loss: 2.528725221592893

Epoch: 5| Step: 8
Training loss: 2.609886646270752
Validation loss: 2.5303758318706224

Epoch: 5| Step: 9
Training loss: 2.3836238384246826
Validation loss: 2.524122207395492

Epoch: 5| Step: 10
Training loss: 3.452148914337158
Validation loss: 2.5232790516268824

Epoch: 22| Step: 0
Training loss: 2.6427807807922363
Validation loss: 2.524661869131109

Epoch: 5| Step: 1
Training loss: 2.5473971366882324
Validation loss: 2.513684290711598

Epoch: 5| Step: 2
Training loss: 2.535884380340576
Validation loss: 2.501034927624528

Epoch: 5| Step: 3
Training loss: 2.7832515239715576
Validation loss: 2.4979977915363927

Epoch: 5| Step: 4
Training loss: 2.5176618099212646
Validation loss: 2.4971407741628666

Epoch: 5| Step: 5
Training loss: 3.265927791595459
Validation loss: 2.494484419463783

Epoch: 5| Step: 6
Training loss: 2.436338186264038
Validation loss: 2.489111528601698

Epoch: 5| Step: 7
Training loss: 2.9923205375671387
Validation loss: 2.4844342303532425

Epoch: 5| Step: 8
Training loss: 3.1459124088287354
Validation loss: 2.4864930670748473

Epoch: 5| Step: 9
Training loss: 1.9839626550674438
Validation loss: 2.4872627796665316

Epoch: 5| Step: 10
Training loss: 3.1278727054595947
Validation loss: 2.491904740692467

Epoch: 23| Step: 0
Training loss: 3.2645130157470703
Validation loss: 2.4862205033661215

Epoch: 5| Step: 1
Training loss: 2.39351487159729
Validation loss: 2.47098950160447

Epoch: 5| Step: 2
Training loss: 2.008730173110962
Validation loss: 2.4792800154737247

Epoch: 5| Step: 3
Training loss: 3.1433587074279785
Validation loss: 2.5285877130364858

Epoch: 5| Step: 4
Training loss: 2.773319959640503
Validation loss: 2.5513286052211637

Epoch: 5| Step: 5
Training loss: 2.46529221534729
Validation loss: 2.569309534565095

Epoch: 5| Step: 6
Training loss: 3.5327537059783936
Validation loss: 2.497295718039236

Epoch: 5| Step: 7
Training loss: 2.89935040473938
Validation loss: 2.475278285241896

Epoch: 5| Step: 8
Training loss: 3.089207172393799
Validation loss: 2.564429008832542

Epoch: 5| Step: 9
Training loss: 2.1078007221221924
Validation loss: 2.6045048313756145

Epoch: 5| Step: 10
Training loss: 2.519394874572754
Validation loss: 2.564012909448275

Epoch: 24| Step: 0
Training loss: 2.5942111015319824
Validation loss: 2.5545731565003753

Epoch: 5| Step: 1
Training loss: 2.3213772773742676
Validation loss: 2.4972456655194684

Epoch: 5| Step: 2
Training loss: 2.874976396560669
Validation loss: 2.4563534951979116

Epoch: 5| Step: 3
Training loss: 2.7449755668640137
Validation loss: 2.458331274729903

Epoch: 5| Step: 4
Training loss: 2.507512331008911
Validation loss: 2.4551598897544284

Epoch: 5| Step: 5
Training loss: 2.5801196098327637
Validation loss: 2.459622380554035

Epoch: 5| Step: 6
Training loss: 2.9506306648254395
Validation loss: 2.486645416546893

Epoch: 5| Step: 7
Training loss: 3.0653913021087646
Validation loss: 2.475923261334819

Epoch: 5| Step: 8
Training loss: 2.341421127319336
Validation loss: 2.465828431549893

Epoch: 5| Step: 9
Training loss: 3.2379798889160156
Validation loss: 2.466312987830049

Epoch: 5| Step: 10
Training loss: 2.6683461666107178
Validation loss: 2.4591134901969665

Epoch: 25| Step: 0
Training loss: 3.5092270374298096
Validation loss: 2.4610494721320366

Epoch: 5| Step: 1
Training loss: 2.5428004264831543
Validation loss: 2.4539282424475557

Epoch: 5| Step: 2
Training loss: 2.3438355922698975
Validation loss: 2.4492362519746185

Epoch: 5| Step: 3
Training loss: 2.861898183822632
Validation loss: 2.4394454186962498

Epoch: 5| Step: 4
Training loss: 3.1770029067993164
Validation loss: 2.444107227427985

Epoch: 5| Step: 5
Training loss: 2.436091661453247
Validation loss: 2.444360899668868

Epoch: 5| Step: 6
Training loss: 2.147156000137329
Validation loss: 2.450142352811752

Epoch: 5| Step: 7
Training loss: 2.948219060897827
Validation loss: 2.4537802370645667

Epoch: 5| Step: 8
Training loss: 2.8814260959625244
Validation loss: 2.4554280158012145

Epoch: 5| Step: 9
Training loss: 2.749084949493408
Validation loss: 2.431617098469888

Epoch: 5| Step: 10
Training loss: 1.9356544017791748
Validation loss: 2.4256544984796995

Epoch: 26| Step: 0
Training loss: 2.1169445514678955
Validation loss: 2.4265841207196637

Epoch: 5| Step: 1
Training loss: 2.9578447341918945
Validation loss: 2.449090806386804

Epoch: 5| Step: 2
Training loss: 3.354975461959839
Validation loss: 2.4769634533953924

Epoch: 5| Step: 3
Training loss: 2.4424643516540527
Validation loss: 2.4934039577361076

Epoch: 5| Step: 4
Training loss: 2.666923999786377
Validation loss: 2.4968004893231135

Epoch: 5| Step: 5
Training loss: 2.574460983276367
Validation loss: 2.500966424583107

Epoch: 5| Step: 6
Training loss: 2.5629656314849854
Validation loss: 2.4533700225173787

Epoch: 5| Step: 7
Training loss: 2.304381847381592
Validation loss: 2.41956732350011

Epoch: 5| Step: 8
Training loss: 2.9329171180725098
Validation loss: 2.3991531274651967

Epoch: 5| Step: 9
Training loss: 2.423079252243042
Validation loss: 2.3946278556700675

Epoch: 5| Step: 10
Training loss: 3.18727445602417
Validation loss: 2.4105108809727493

Epoch: 27| Step: 0
Training loss: 2.779672145843506
Validation loss: 2.395567286399103

Epoch: 5| Step: 1
Training loss: 2.7099292278289795
Validation loss: 2.3920323643633115

Epoch: 5| Step: 2
Training loss: 2.9403343200683594
Validation loss: 2.3867002815328617

Epoch: 5| Step: 3
Training loss: 2.8394391536712646
Validation loss: 2.380529724141603

Epoch: 5| Step: 4
Training loss: 2.2711310386657715
Validation loss: 2.382466495677989

Epoch: 5| Step: 5
Training loss: 2.243635416030884
Validation loss: 2.3820677803408716

Epoch: 5| Step: 6
Training loss: 2.704906940460205
Validation loss: 2.3853237859664427

Epoch: 5| Step: 7
Training loss: 3.09855580329895
Validation loss: 2.3875851246618454

Epoch: 5| Step: 8
Training loss: 2.7351644039154053
Validation loss: 2.3970252134466685

Epoch: 5| Step: 9
Training loss: 2.354398250579834
Validation loss: 2.395481158328313

Epoch: 5| Step: 10
Training loss: 2.5773046016693115
Validation loss: 2.3929292027668287

Epoch: 28| Step: 0
Training loss: 3.17490553855896
Validation loss: 2.4212972451281805

Epoch: 5| Step: 1
Training loss: 2.210981845855713
Validation loss: 2.4336728934318788

Epoch: 5| Step: 2
Training loss: 2.9029746055603027
Validation loss: 2.480369198706842

Epoch: 5| Step: 3
Training loss: 1.7902920246124268
Validation loss: 2.479392687479655

Epoch: 5| Step: 4
Training loss: 2.432819128036499
Validation loss: 2.466038809027723

Epoch: 5| Step: 5
Training loss: 3.0448479652404785
Validation loss: 2.4870327365013862

Epoch: 5| Step: 6
Training loss: 2.7888150215148926
Validation loss: 2.440312429140973

Epoch: 5| Step: 7
Training loss: 2.717407703399658
Validation loss: 2.399807386500861

Epoch: 5| Step: 8
Training loss: 3.097024440765381
Validation loss: 2.381940734001898

Epoch: 5| Step: 9
Training loss: 2.8707451820373535
Validation loss: 2.368466851531818

Epoch: 5| Step: 10
Training loss: 2.0291709899902344
Validation loss: 2.3641852460881716

Epoch: 29| Step: 0
Training loss: 1.9047867059707642
Validation loss: 2.357783671348326

Epoch: 5| Step: 1
Training loss: 3.2813210487365723
Validation loss: 2.363457008074689

Epoch: 5| Step: 2
Training loss: 2.994939088821411
Validation loss: 2.3642776038057063

Epoch: 5| Step: 3
Training loss: 3.1121819019317627
Validation loss: 2.358927029435353

Epoch: 5| Step: 4
Training loss: 2.355560779571533
Validation loss: 2.3573360417478826

Epoch: 5| Step: 5
Training loss: 2.834368944168091
Validation loss: 2.3570576867749615

Epoch: 5| Step: 6
Training loss: 2.5138790607452393
Validation loss: 2.3573441531068537

Epoch: 5| Step: 7
Training loss: 1.8090912103652954
Validation loss: 2.3741228580474854

Epoch: 5| Step: 8
Training loss: 2.8692610263824463
Validation loss: 2.3906329857405795

Epoch: 5| Step: 9
Training loss: 2.6314022541046143
Validation loss: 2.3917420474431847

Epoch: 5| Step: 10
Training loss: 2.573598861694336
Validation loss: 2.3800419530560895

Epoch: 30| Step: 0
Training loss: 2.747826337814331
Validation loss: 2.383867617576353

Epoch: 5| Step: 1
Training loss: 2.423743724822998
Validation loss: 2.394728599056121

Epoch: 5| Step: 2
Training loss: 2.018754720687866
Validation loss: 2.395751778797437

Epoch: 5| Step: 3
Training loss: 2.4439380168914795
Validation loss: 2.402319241595525

Epoch: 5| Step: 4
Training loss: 3.1696717739105225
Validation loss: 2.3895017818738054

Epoch: 5| Step: 5
Training loss: 2.22385311126709
Validation loss: 2.3797772622877553

Epoch: 5| Step: 6
Training loss: 2.5981173515319824
Validation loss: 2.383746994438992

Epoch: 5| Step: 7
Training loss: 2.3556740283966064
Validation loss: 2.378977596118886

Epoch: 5| Step: 8
Training loss: 2.8275818824768066
Validation loss: 2.3718726532433623

Epoch: 5| Step: 9
Training loss: 2.7304704189300537
Validation loss: 2.3659180287391908

Epoch: 5| Step: 10
Training loss: 3.397134304046631
Validation loss: 2.3521203994750977

Epoch: 31| Step: 0
Training loss: 2.282348394393921
Validation loss: 2.3410071557567966

Epoch: 5| Step: 1
Training loss: 3.0837883949279785
Validation loss: 2.3357849172366563

Epoch: 5| Step: 2
Training loss: 2.5881898403167725
Validation loss: 2.346655084240821

Epoch: 5| Step: 3
Training loss: 2.3619089126586914
Validation loss: 2.34562341115808

Epoch: 5| Step: 4
Training loss: 3.059674024581909
Validation loss: 2.3416213809802966

Epoch: 5| Step: 5
Training loss: 2.481847047805786
Validation loss: 2.347331980223297

Epoch: 5| Step: 6
Training loss: 2.7219395637512207
Validation loss: 2.3453596202276086

Epoch: 5| Step: 7
Training loss: 2.5243735313415527
Validation loss: 2.3516124166468138

Epoch: 5| Step: 8
Training loss: 2.475236177444458
Validation loss: 2.350735454149144

Epoch: 5| Step: 9
Training loss: 2.3326117992401123
Validation loss: 2.341874281565348

Epoch: 5| Step: 10
Training loss: 2.7492644786834717
Validation loss: 2.346727583997993

Epoch: 32| Step: 0
Training loss: 2.203914165496826
Validation loss: 2.36391863002572

Epoch: 5| Step: 1
Training loss: 2.204810380935669
Validation loss: 2.4011951287587485

Epoch: 5| Step: 2
Training loss: 3.196824312210083
Validation loss: 2.42165086859016

Epoch: 5| Step: 3
Training loss: 2.957324266433716
Validation loss: 2.3812119730057253

Epoch: 5| Step: 4
Training loss: 2.889920711517334
Validation loss: 2.3494661546522573

Epoch: 5| Step: 5
Training loss: 2.078728199005127
Validation loss: 2.3244430865010908

Epoch: 5| Step: 6
Training loss: 2.9889683723449707
Validation loss: 2.318655901057746

Epoch: 5| Step: 7
Training loss: 2.2777633666992188
Validation loss: 2.3271570282597698

Epoch: 5| Step: 8
Training loss: 2.603210687637329
Validation loss: 2.3279899576658845

Epoch: 5| Step: 9
Training loss: 2.4735779762268066
Validation loss: 2.3307080679042365

Epoch: 5| Step: 10
Training loss: 2.8336238861083984
Validation loss: 2.3427705277678785

Epoch: 33| Step: 0
Training loss: 3.067786455154419
Validation loss: 2.343209446117442

Epoch: 5| Step: 1
Training loss: 2.607811450958252
Validation loss: 2.354186801500218

Epoch: 5| Step: 2
Training loss: 3.305060625076294
Validation loss: 2.3621008011602584

Epoch: 5| Step: 3
Training loss: 2.3690383434295654
Validation loss: 2.361610956089471

Epoch: 5| Step: 4
Training loss: 2.354915142059326
Validation loss: 2.3756077417763333

Epoch: 5| Step: 5
Training loss: 2.1366021633148193
Validation loss: 2.3680151636882494

Epoch: 5| Step: 6
Training loss: 2.42621111869812
Validation loss: 2.352689443096038

Epoch: 5| Step: 7
Training loss: 2.010516881942749
Validation loss: 2.3514120399311023

Epoch: 5| Step: 8
Training loss: 2.736044406890869
Validation loss: 2.3480794865597963

Epoch: 5| Step: 9
Training loss: 2.2706732749938965
Validation loss: 2.338267154591058

Epoch: 5| Step: 10
Training loss: 3.3761744499206543
Validation loss: 2.3287505744605936

Epoch: 34| Step: 0
Training loss: 2.6082146167755127
Validation loss: 2.308190002236315

Epoch: 5| Step: 1
Training loss: 2.511169910430908
Validation loss: 2.3029902135172198

Epoch: 5| Step: 2
Training loss: 2.519676685333252
Validation loss: 2.3042060508522937

Epoch: 5| Step: 3
Training loss: 3.3734869956970215
Validation loss: 2.3038805377098823

Epoch: 5| Step: 4
Training loss: 2.57965087890625
Validation loss: 2.306653682903577

Epoch: 5| Step: 5
Training loss: 2.206943988800049
Validation loss: 2.3048454638450377

Epoch: 5| Step: 6
Training loss: 2.4250011444091797
Validation loss: 2.300755477720691

Epoch: 5| Step: 7
Training loss: 3.249415636062622
Validation loss: 2.2946837589304936

Epoch: 5| Step: 8
Training loss: 2.5415492057800293
Validation loss: 2.2917107997402066

Epoch: 5| Step: 9
Training loss: 1.9965393543243408
Validation loss: 2.289906845297865

Epoch: 5| Step: 10
Training loss: 2.4272212982177734
Validation loss: 2.288798298887027

Epoch: 35| Step: 0
Training loss: 3.031318187713623
Validation loss: 2.2910192089696086

Epoch: 5| Step: 1
Training loss: 2.2746312618255615
Validation loss: 2.2917060864868986

Epoch: 5| Step: 2
Training loss: 3.1926827430725098
Validation loss: 2.310362467201807

Epoch: 5| Step: 3
Training loss: 2.8234920501708984
Validation loss: 2.3348636191378356

Epoch: 5| Step: 4
Training loss: 2.6515133380889893
Validation loss: 2.326145133664531

Epoch: 5| Step: 5
Training loss: 2.3117401599884033
Validation loss: 2.3213953523225683

Epoch: 5| Step: 6
Training loss: 2.4096012115478516
Validation loss: 2.295254208708322

Epoch: 5| Step: 7
Training loss: 2.4767096042633057
Validation loss: 2.2842274609432427

Epoch: 5| Step: 8
Training loss: 2.3858633041381836
Validation loss: 2.281432386367552

Epoch: 5| Step: 9
Training loss: 2.2763423919677734
Validation loss: 2.2862638312001384

Epoch: 5| Step: 10
Training loss: 2.670151710510254
Validation loss: 2.2841556508054017

Epoch: 36| Step: 0
Training loss: 3.668752670288086
Validation loss: 2.2857549908340618

Epoch: 5| Step: 1
Training loss: 2.565908908843994
Validation loss: 2.280671537563365

Epoch: 5| Step: 2
Training loss: 2.0169458389282227
Validation loss: 2.2839711122615363

Epoch: 5| Step: 3
Training loss: 3.1667494773864746
Validation loss: 2.2915395767458024

Epoch: 5| Step: 4
Training loss: 2.4740943908691406
Validation loss: 2.3071310545808528

Epoch: 5| Step: 5
Training loss: 2.337669849395752
Validation loss: 2.299819750170554

Epoch: 5| Step: 6
Training loss: 2.793358325958252
Validation loss: 2.295730324201686

Epoch: 5| Step: 7
Training loss: 2.203655958175659
Validation loss: 2.3007702083997827

Epoch: 5| Step: 8
Training loss: 2.379148483276367
Validation loss: 2.2927577751939014

Epoch: 5| Step: 9
Training loss: 2.4011499881744385
Validation loss: 2.2754619095915105

Epoch: 5| Step: 10
Training loss: 2.051218271255493
Validation loss: 2.2766334446527625

Epoch: 37| Step: 0
Training loss: 2.4182960987091064
Validation loss: 2.270297561922381

Epoch: 5| Step: 1
Training loss: 2.378559112548828
Validation loss: 2.2710494456752652

Epoch: 5| Step: 2
Training loss: 3.3243231773376465
Validation loss: 2.27948397462086

Epoch: 5| Step: 3
Training loss: 2.4246997833251953
Validation loss: 2.283161570948939

Epoch: 5| Step: 4
Training loss: 2.2221016883850098
Validation loss: 2.2693082978648524

Epoch: 5| Step: 5
Training loss: 2.6660068035125732
Validation loss: 2.2747217942309637

Epoch: 5| Step: 6
Training loss: 2.9034552574157715
Validation loss: 2.267722475913263

Epoch: 5| Step: 7
Training loss: 2.1451826095581055
Validation loss: 2.270430726389731

Epoch: 5| Step: 8
Training loss: 2.6565499305725098
Validation loss: 2.3074931226750857

Epoch: 5| Step: 9
Training loss: 2.82099986076355
Validation loss: 2.326357126235962

Epoch: 5| Step: 10
Training loss: 2.33479642868042
Validation loss: 2.336966377432628

Epoch: 38| Step: 0
Training loss: 2.947071075439453
Validation loss: 2.3158509013473347

Epoch: 5| Step: 1
Training loss: 2.4729702472686768
Validation loss: 2.288298655581731

Epoch: 5| Step: 2
Training loss: 2.6896839141845703
Validation loss: 2.276942164667191

Epoch: 5| Step: 3
Training loss: 2.6767489910125732
Validation loss: 2.2706986857998754

Epoch: 5| Step: 4
Training loss: 2.468637466430664
Validation loss: 2.2662179623880694

Epoch: 5| Step: 5
Training loss: 2.52248477935791
Validation loss: 2.264317535584973

Epoch: 5| Step: 6
Training loss: 2.603572368621826
Validation loss: 2.2668189746077343

Epoch: 5| Step: 7
Training loss: 2.676325559616089
Validation loss: 2.2676110395821194

Epoch: 5| Step: 8
Training loss: 2.0802929401397705
Validation loss: 2.261174084037863

Epoch: 5| Step: 9
Training loss: 2.5495922565460205
Validation loss: 2.265565885010586

Epoch: 5| Step: 10
Training loss: 2.453791618347168
Validation loss: 2.273625925023069

Epoch: 39| Step: 0
Training loss: 2.3699848651885986
Validation loss: 2.2916887408943585

Epoch: 5| Step: 1
Training loss: 2.659806489944458
Validation loss: 2.332689251950992

Epoch: 5| Step: 2
Training loss: 2.5853514671325684
Validation loss: 2.370004261693647

Epoch: 5| Step: 3
Training loss: 2.7474417686462402
Validation loss: 2.407897513399842

Epoch: 5| Step: 4
Training loss: 3.2182393074035645
Validation loss: 2.394672747581236

Epoch: 5| Step: 5
Training loss: 2.642338752746582
Validation loss: 2.3372287006788355

Epoch: 5| Step: 6
Training loss: 2.37650990486145
Validation loss: 2.2713239346781084

Epoch: 5| Step: 7
Training loss: 2.2785515785217285
Validation loss: 2.2565783813435543

Epoch: 5| Step: 8
Training loss: 2.6004960536956787
Validation loss: 2.254697048535911

Epoch: 5| Step: 9
Training loss: 2.5021510124206543
Validation loss: 2.2534612250584427

Epoch: 5| Step: 10
Training loss: 2.4166131019592285
Validation loss: 2.26239453336244

Epoch: 40| Step: 0
Training loss: 2.5082240104675293
Validation loss: 2.2529856620296353

Epoch: 5| Step: 1
Training loss: 3.3656227588653564
Validation loss: 2.2499166380974556

Epoch: 5| Step: 2
Training loss: 3.158874034881592
Validation loss: 2.253021550434892

Epoch: 5| Step: 3
Training loss: 2.47597074508667
Validation loss: 2.2587764340062297

Epoch: 5| Step: 4
Training loss: 2.089895725250244
Validation loss: 2.2749919493993125

Epoch: 5| Step: 5
Training loss: 1.8615401983261108
Validation loss: 2.291475757475822

Epoch: 5| Step: 6
Training loss: 2.5453457832336426
Validation loss: 2.317654530207316

Epoch: 5| Step: 7
Training loss: 3.026973247528076
Validation loss: 2.3093282074056645

Epoch: 5| Step: 8
Training loss: 2.427889347076416
Validation loss: 2.279692401168167

Epoch: 5| Step: 9
Training loss: 2.3198249340057373
Validation loss: 2.253864680567095

Epoch: 5| Step: 10
Training loss: 2.370284080505371
Validation loss: 2.237202657166348

Epoch: 41| Step: 0
Training loss: 2.374392032623291
Validation loss: 2.2358820771658294

Epoch: 5| Step: 1
Training loss: 2.9719042778015137
Validation loss: 2.23649783801007

Epoch: 5| Step: 2
Training loss: 2.860109329223633
Validation loss: 2.2335448316348496

Epoch: 5| Step: 3
Training loss: 2.811246395111084
Validation loss: 2.23376694802315

Epoch: 5| Step: 4
Training loss: 2.1942379474639893
Validation loss: 2.231647112036264

Epoch: 5| Step: 5
Training loss: 2.597987174987793
Validation loss: 2.237583362928001

Epoch: 5| Step: 6
Training loss: 2.0834808349609375
Validation loss: 2.2431087929715394

Epoch: 5| Step: 7
Training loss: 2.865255832672119
Validation loss: 2.2691921495622203

Epoch: 5| Step: 8
Training loss: 2.0756335258483887
Validation loss: 2.2861599845270955

Epoch: 5| Step: 9
Training loss: 2.202810287475586
Validation loss: 2.3124769067251556

Epoch: 5| Step: 10
Training loss: 3.130308151245117
Validation loss: 2.3119292438671155

Epoch: 42| Step: 0
Training loss: 2.3637211322784424
Validation loss: 2.306264901673922

Epoch: 5| Step: 1
Training loss: 2.8181183338165283
Validation loss: 2.2737526086068924

Epoch: 5| Step: 2
Training loss: 2.5840065479278564
Validation loss: 2.268730161010578

Epoch: 5| Step: 3
Training loss: 2.1960971355438232
Validation loss: 2.238936811365107

Epoch: 5| Step: 4
Training loss: 2.6561553478240967
Validation loss: 2.2234887640963317

Epoch: 5| Step: 5
Training loss: 3.5899574756622314
Validation loss: 2.216700323166386

Epoch: 5| Step: 6
Training loss: 2.2972428798675537
Validation loss: 2.2222610878688034

Epoch: 5| Step: 7
Training loss: 2.575002431869507
Validation loss: 2.22032065801723

Epoch: 5| Step: 8
Training loss: 2.648155689239502
Validation loss: 2.214810299616988

Epoch: 5| Step: 9
Training loss: 2.7047197818756104
Validation loss: 2.215480089187622

Epoch: 5| Step: 10
Training loss: 1.2364572286605835
Validation loss: 2.2172772064003894

Epoch: 43| Step: 0
Training loss: 2.0880067348480225
Validation loss: 2.2183412198097474

Epoch: 5| Step: 1
Training loss: 2.643343210220337
Validation loss: 2.2307126624609834

Epoch: 5| Step: 2
Training loss: 2.537900447845459
Validation loss: 2.2329072529269802

Epoch: 5| Step: 3
Training loss: 2.771399974822998
Validation loss: 2.240380137197433

Epoch: 5| Step: 4
Training loss: 2.161630868911743
Validation loss: 2.2535543698136524

Epoch: 5| Step: 5
Training loss: 2.765490770339966
Validation loss: 2.26403199472735

Epoch: 5| Step: 6
Training loss: 2.3414196968078613
Validation loss: 2.268248127352807

Epoch: 5| Step: 7
Training loss: 2.9502835273742676
Validation loss: 2.2663532610862487

Epoch: 5| Step: 8
Training loss: 1.831062912940979
Validation loss: 2.2480553401413785

Epoch: 5| Step: 9
Training loss: 2.929062604904175
Validation loss: 2.251323979388001

Epoch: 5| Step: 10
Training loss: 2.8135812282562256
Validation loss: 2.265538518146802

Epoch: 44| Step: 0
Training loss: 3.016026258468628
Validation loss: 2.2629955276366203

Epoch: 5| Step: 1
Training loss: 2.4593093395233154
Validation loss: 2.2569665421721754

Epoch: 5| Step: 2
Training loss: 2.6803412437438965
Validation loss: 2.2619542127014487

Epoch: 5| Step: 3
Training loss: 1.9827810525894165
Validation loss: 2.253681690462174

Epoch: 5| Step: 4
Training loss: 2.80751371383667
Validation loss: 2.3005631226365284

Epoch: 5| Step: 5
Training loss: 2.671369791030884
Validation loss: 2.2994248033851705

Epoch: 5| Step: 6
Training loss: 2.4627017974853516
Validation loss: 2.2709530579146517

Epoch: 5| Step: 7
Training loss: 2.9568657875061035
Validation loss: 2.243489021896034

Epoch: 5| Step: 8
Training loss: 2.405092239379883
Validation loss: 2.223441562344951

Epoch: 5| Step: 9
Training loss: 1.7051422595977783
Validation loss: 2.2067125305052726

Epoch: 5| Step: 10
Training loss: 2.7685468196868896
Validation loss: 2.2060110645909465

Epoch: 45| Step: 0
Training loss: 2.6125264167785645
Validation loss: 2.209250383479621

Epoch: 5| Step: 1
Training loss: 2.242183208465576
Validation loss: 2.20221314507146

Epoch: 5| Step: 2
Training loss: 3.140923261642456
Validation loss: 2.2196509312557917

Epoch: 5| Step: 3
Training loss: 2.0424461364746094
Validation loss: 2.194029532453065

Epoch: 5| Step: 4
Training loss: 2.641150712966919
Validation loss: 2.1965488656874625

Epoch: 5| Step: 5
Training loss: 2.581509590148926
Validation loss: 2.20808139411352

Epoch: 5| Step: 6
Training loss: 2.520397186279297
Validation loss: 2.2215689356609056

Epoch: 5| Step: 7
Training loss: 2.7399096488952637
Validation loss: 2.239626620405464

Epoch: 5| Step: 8
Training loss: 2.9422879219055176
Validation loss: 2.262362026399182

Epoch: 5| Step: 9
Training loss: 2.2896642684936523
Validation loss: 2.255721915152765

Epoch: 5| Step: 10
Training loss: 2.0024945735931396
Validation loss: 2.27321183553306

Epoch: 46| Step: 0
Training loss: 2.9139914512634277
Validation loss: 2.2633505777646135

Epoch: 5| Step: 1
Training loss: 2.691100835800171
Validation loss: 2.2362348392445552

Epoch: 5| Step: 2
Training loss: 2.5002858638763428
Validation loss: 2.229354889162125

Epoch: 5| Step: 3
Training loss: 1.9318854808807373
Validation loss: 2.2331416478721042

Epoch: 5| Step: 4
Training loss: 2.786439895629883
Validation loss: 2.214819227495501

Epoch: 5| Step: 5
Training loss: 2.3717074394226074
Validation loss: 2.208896621581047

Epoch: 5| Step: 6
Training loss: 2.237492322921753
Validation loss: 2.206989283202797

Epoch: 5| Step: 7
Training loss: 2.413538694381714
Validation loss: 2.1968201027121594

Epoch: 5| Step: 8
Training loss: 2.499647855758667
Validation loss: 2.1870363579001477

Epoch: 5| Step: 9
Training loss: 2.5255024433135986
Validation loss: 2.17967491252448

Epoch: 5| Step: 10
Training loss: 2.8843634128570557
Validation loss: 2.1833094294353197

Epoch: 47| Step: 0
Training loss: 2.4745638370513916
Validation loss: 2.181551497469666

Epoch: 5| Step: 1
Training loss: 3.04829740524292
Validation loss: 2.191650048378975

Epoch: 5| Step: 2
Training loss: 2.2883098125457764
Validation loss: 2.1898978602501655

Epoch: 5| Step: 3
Training loss: 2.257157564163208
Validation loss: 2.183961445285428

Epoch: 5| Step: 4
Training loss: 2.289691925048828
Validation loss: 2.177396515364288

Epoch: 5| Step: 5
Training loss: 2.2122015953063965
Validation loss: 2.1850138941118793

Epoch: 5| Step: 6
Training loss: 2.345947504043579
Validation loss: 2.186170567748367

Epoch: 5| Step: 7
Training loss: 2.591566562652588
Validation loss: 2.1898258040028233

Epoch: 5| Step: 8
Training loss: 2.150996208190918
Validation loss: 2.2056903505838044

Epoch: 5| Step: 9
Training loss: 2.7350566387176514
Validation loss: 2.2386688878459315

Epoch: 5| Step: 10
Training loss: 3.4307448863983154
Validation loss: 2.2775452726630756

Epoch: 48| Step: 0
Training loss: 2.7644402980804443
Validation loss: 2.267793870741321

Epoch: 5| Step: 1
Training loss: 2.6183362007141113
Validation loss: 2.239283974452685

Epoch: 5| Step: 2
Training loss: 2.547820568084717
Validation loss: 2.21672619927314

Epoch: 5| Step: 3
Training loss: 2.3547725677490234
Validation loss: 2.212613659520303

Epoch: 5| Step: 4
Training loss: 2.349644422531128
Validation loss: 2.2067179115869666

Epoch: 5| Step: 5
Training loss: 2.139721393585205
Validation loss: 2.193305020691246

Epoch: 5| Step: 6
Training loss: 3.1733856201171875
Validation loss: 2.181250769604919

Epoch: 5| Step: 7
Training loss: 1.8705494403839111
Validation loss: 2.17397145558429

Epoch: 5| Step: 8
Training loss: 2.7920947074890137
Validation loss: 2.173751546490577

Epoch: 5| Step: 9
Training loss: 2.1979026794433594
Validation loss: 2.175869910947738

Epoch: 5| Step: 10
Training loss: 2.648426055908203
Validation loss: 2.1813834918442594

Epoch: 49| Step: 0
Training loss: 2.6582398414611816
Validation loss: 2.175747154861368

Epoch: 5| Step: 1
Training loss: 1.9410102367401123
Validation loss: 2.173503621931999

Epoch: 5| Step: 2
Training loss: 3.0346484184265137
Validation loss: 2.166641422497329

Epoch: 5| Step: 3
Training loss: 2.510216236114502
Validation loss: 2.171564825119511

Epoch: 5| Step: 4
Training loss: 2.9260048866271973
Validation loss: 2.1969773410468973

Epoch: 5| Step: 5
Training loss: 2.284592390060425
Validation loss: 2.2025984051407024

Epoch: 5| Step: 6
Training loss: 2.078343391418457
Validation loss: 2.2172215574531147

Epoch: 5| Step: 7
Training loss: 2.3184683322906494
Validation loss: 2.207336897491127

Epoch: 5| Step: 8
Training loss: 2.5196609497070312
Validation loss: 2.1835510653834187

Epoch: 5| Step: 9
Training loss: 2.6914470195770264
Validation loss: 2.1702959460596882

Epoch: 5| Step: 10
Training loss: 2.6307902336120605
Validation loss: 2.1688809676836898

Epoch: 50| Step: 0
Training loss: 2.1950161457061768
Validation loss: 2.1647095910964476

Epoch: 5| Step: 1
Training loss: 2.099343776702881
Validation loss: 2.163030260352678

Epoch: 5| Step: 2
Training loss: 1.6388978958129883
Validation loss: 2.1596950023405013

Epoch: 5| Step: 3
Training loss: 2.9164352416992188
Validation loss: 2.162276521805794

Epoch: 5| Step: 4
Training loss: 2.737403154373169
Validation loss: 2.1594635773730535

Epoch: 5| Step: 5
Training loss: 2.6604228019714355
Validation loss: 2.1575527767981253

Epoch: 5| Step: 6
Training loss: 2.627197742462158
Validation loss: 2.1598495424434705

Epoch: 5| Step: 7
Training loss: 2.329857110977173
Validation loss: 2.1550251565953737

Epoch: 5| Step: 8
Training loss: 2.86452579498291
Validation loss: 2.165912466664468

Epoch: 5| Step: 9
Training loss: 2.9407551288604736
Validation loss: 2.185183416130722

Epoch: 5| Step: 10
Training loss: 2.2494683265686035
Validation loss: 2.1985592739556425

Epoch: 51| Step: 0
Training loss: 2.556023120880127
Validation loss: 2.217763667465538

Epoch: 5| Step: 1
Training loss: 2.4303011894226074
Validation loss: 2.230508937630602

Epoch: 5| Step: 2
Training loss: 2.051001787185669
Validation loss: 2.2160327408903386

Epoch: 5| Step: 3
Training loss: 2.384800672531128
Validation loss: 2.2085022105965564

Epoch: 5| Step: 4
Training loss: 2.5653162002563477
Validation loss: 2.1800008384130334

Epoch: 5| Step: 5
Training loss: 3.309945583343506
Validation loss: 2.1713762783235118

Epoch: 5| Step: 6
Training loss: 2.574429988861084
Validation loss: 2.157136873532367

Epoch: 5| Step: 7
Training loss: 3.2672526836395264
Validation loss: 2.165483428585914

Epoch: 5| Step: 8
Training loss: 1.7155317068099976
Validation loss: 2.168077658581477

Epoch: 5| Step: 9
Training loss: 2.169748067855835
Validation loss: 2.1626791672040055

Epoch: 5| Step: 10
Training loss: 2.2216994762420654
Validation loss: 2.152903195350401

Epoch: 52| Step: 0
Training loss: 2.3981189727783203
Validation loss: 2.150392056793295

Epoch: 5| Step: 1
Training loss: 2.3478877544403076
Validation loss: 2.148336946323354

Epoch: 5| Step: 2
Training loss: 2.342766046524048
Validation loss: 2.155116319656372

Epoch: 5| Step: 3
Training loss: 2.4516243934631348
Validation loss: 2.1561529636383057

Epoch: 5| Step: 4
Training loss: 2.142747640609741
Validation loss: 2.165594372698056

Epoch: 5| Step: 5
Training loss: 2.317657232284546
Validation loss: 2.1742908288073797

Epoch: 5| Step: 6
Training loss: 3.1638407707214355
Validation loss: 2.1898216291140487

Epoch: 5| Step: 7
Training loss: 2.888815402984619
Validation loss: 2.203610817591349

Epoch: 5| Step: 8
Training loss: 2.2585864067077637
Validation loss: 2.1759360554397746

Epoch: 5| Step: 9
Training loss: 2.234612226486206
Validation loss: 2.1578236677313365

Epoch: 5| Step: 10
Training loss: 2.6225624084472656
Validation loss: 2.1603916242558467

Epoch: 53| Step: 0
Training loss: 2.4660401344299316
Validation loss: 2.151512284432688

Epoch: 5| Step: 1
Training loss: 2.184748649597168
Validation loss: 2.1562849039672525

Epoch: 5| Step: 2
Training loss: 2.3498432636260986
Validation loss: 2.1839836835861206

Epoch: 5| Step: 3
Training loss: 2.6845173835754395
Validation loss: 2.217514238049907

Epoch: 5| Step: 4
Training loss: 3.5537662506103516
Validation loss: 2.2532201531112834

Epoch: 5| Step: 5
Training loss: 1.678079605102539
Validation loss: 2.288590097940096

Epoch: 5| Step: 6
Training loss: 2.4597880840301514
Validation loss: 2.3331235557474117

Epoch: 5| Step: 7
Training loss: 2.268204689025879
Validation loss: 2.319791006785567

Epoch: 5| Step: 8
Training loss: 2.4939956665039062
Validation loss: 2.296576343556886

Epoch: 5| Step: 9
Training loss: 2.540116786956787
Validation loss: 2.203610248463128

Epoch: 5| Step: 10
Training loss: 2.739185333251953
Validation loss: 2.153996895718318

Epoch: 54| Step: 0
Training loss: 2.3692402839660645
Validation loss: 2.1374036201866726

Epoch: 5| Step: 1
Training loss: 2.263549327850342
Validation loss: 2.157386246547904

Epoch: 5| Step: 2
Training loss: 2.6681833267211914
Validation loss: 2.157836934571625

Epoch: 5| Step: 3
Training loss: 2.486387252807617
Validation loss: 2.1565193283942437

Epoch: 5| Step: 4
Training loss: 2.7428815364837646
Validation loss: 2.1698120870897846

Epoch: 5| Step: 5
Training loss: 3.0379624366760254
Validation loss: 2.1722714593333583

Epoch: 5| Step: 6
Training loss: 2.0588574409484863
Validation loss: 2.174664319202464

Epoch: 5| Step: 7
Training loss: 2.9428727626800537
Validation loss: 2.186502427183172

Epoch: 5| Step: 8
Training loss: 1.9812250137329102
Validation loss: 2.2357749413418513

Epoch: 5| Step: 9
Training loss: 2.1508896350860596
Validation loss: 2.225864443727719

Epoch: 5| Step: 10
Training loss: 2.9451167583465576
Validation loss: 2.2064972564738285

Epoch: 55| Step: 0
Training loss: 2.4718239307403564
Validation loss: 2.1830255857077976

Epoch: 5| Step: 1
Training loss: 2.8378684520721436
Validation loss: 2.1887190034312587

Epoch: 5| Step: 2
Training loss: 1.786179780960083
Validation loss: 2.168337639941964

Epoch: 5| Step: 3
Training loss: 2.401043653488159
Validation loss: 2.1271685246498353

Epoch: 5| Step: 4
Training loss: 2.467137336730957
Validation loss: 2.104974728758617

Epoch: 5| Step: 5
Training loss: 2.278169631958008
Validation loss: 2.1097015027076966

Epoch: 5| Step: 6
Training loss: 2.6578750610351562
Validation loss: 2.131875302201958

Epoch: 5| Step: 7
Training loss: 3.1602518558502197
Validation loss: 2.1536605178668933

Epoch: 5| Step: 8
Training loss: 2.516826868057251
Validation loss: 2.182515840376577

Epoch: 5| Step: 9
Training loss: 2.331040143966675
Validation loss: 2.1728811007674023

Epoch: 5| Step: 10
Training loss: 2.223809003829956
Validation loss: 2.1982093523907404

Epoch: 56| Step: 0
Training loss: 1.9855000972747803
Validation loss: 2.196909309715353

Epoch: 5| Step: 1
Training loss: 1.96701180934906
Validation loss: 2.1622783753179733

Epoch: 5| Step: 2
Training loss: 2.635897159576416
Validation loss: 2.1301637054771505

Epoch: 5| Step: 3
Training loss: 2.489741802215576
Validation loss: 2.1176067462531467

Epoch: 5| Step: 4
Training loss: 2.5700151920318604
Validation loss: 2.1092669656199794

Epoch: 5| Step: 5
Training loss: 2.0437262058258057
Validation loss: 2.1091261063852618

Epoch: 5| Step: 6
Training loss: 2.81913423538208
Validation loss: 2.112089200686383

Epoch: 5| Step: 7
Training loss: 2.4295501708984375
Validation loss: 2.112564993161027

Epoch: 5| Step: 8
Training loss: 2.2573928833007812
Validation loss: 2.123376008002989

Epoch: 5| Step: 9
Training loss: 3.1202504634857178
Validation loss: 2.1276479510850805

Epoch: 5| Step: 10
Training loss: 2.745105743408203
Validation loss: 2.124703735433599

Epoch: 57| Step: 0
Training loss: 2.2861547470092773
Validation loss: 2.1484943166855843

Epoch: 5| Step: 1
Training loss: 2.6460278034210205
Validation loss: 2.159509079430693

Epoch: 5| Step: 2
Training loss: 3.2688775062561035
Validation loss: 2.1617810572347333

Epoch: 5| Step: 3
Training loss: 2.1011641025543213
Validation loss: 2.1559636285228114

Epoch: 5| Step: 4
Training loss: 2.1192638874053955
Validation loss: 2.166302396405128

Epoch: 5| Step: 5
Training loss: 2.74889874458313
Validation loss: 2.150172648891326

Epoch: 5| Step: 6
Training loss: 1.9251127243041992
Validation loss: 2.134882821831652

Epoch: 5| Step: 7
Training loss: 2.5074610710144043
Validation loss: 2.1297133930267824

Epoch: 5| Step: 8
Training loss: 2.2662463188171387
Validation loss: 2.122698110918845

Epoch: 5| Step: 9
Training loss: 2.468248128890991
Validation loss: 2.121966267144808

Epoch: 5| Step: 10
Training loss: 2.5043141841888428
Validation loss: 2.1210054505255913

Epoch: 58| Step: 0
Training loss: 2.810530424118042
Validation loss: 2.149441188381564

Epoch: 5| Step: 1
Training loss: 2.5399460792541504
Validation loss: 2.133989585343228

Epoch: 5| Step: 2
Training loss: 2.248357057571411
Validation loss: 2.1231008934718307

Epoch: 5| Step: 3
Training loss: 1.740905523300171
Validation loss: 2.116071785649946

Epoch: 5| Step: 4
Training loss: 2.036263942718506
Validation loss: 2.106888594165925

Epoch: 5| Step: 5
Training loss: 2.489093780517578
Validation loss: 2.1033741735642955

Epoch: 5| Step: 6
Training loss: 2.9772801399230957
Validation loss: 2.098701451414375

Epoch: 5| Step: 7
Training loss: 2.3132245540618896
Validation loss: 2.1026403519415084

Epoch: 5| Step: 8
Training loss: 2.7719058990478516
Validation loss: 2.1006234858625676

Epoch: 5| Step: 9
Training loss: 3.1758551597595215
Validation loss: 2.1114396997677383

Epoch: 5| Step: 10
Training loss: 1.6779619455337524
Validation loss: 2.127919671356037

Epoch: 59| Step: 0
Training loss: 2.6729578971862793
Validation loss: 2.1514877247554

Epoch: 5| Step: 1
Training loss: 2.284492015838623
Validation loss: 2.1679866506207373

Epoch: 5| Step: 2
Training loss: 2.579761028289795
Validation loss: 2.147016212504397

Epoch: 5| Step: 3
Training loss: 1.8314216136932373
Validation loss: 2.156218112155955

Epoch: 5| Step: 4
Training loss: 2.348963737487793
Validation loss: 2.127657492955526

Epoch: 5| Step: 5
Training loss: 2.0669407844543457
Validation loss: 2.126421202895462

Epoch: 5| Step: 6
Training loss: 2.2897555828094482
Validation loss: 2.140756614746586

Epoch: 5| Step: 7
Training loss: 3.326221466064453
Validation loss: 2.1426283467200493

Epoch: 5| Step: 8
Training loss: 2.075615882873535
Validation loss: 2.132772530278852

Epoch: 5| Step: 9
Training loss: 2.435093641281128
Validation loss: 2.118474022034676

Epoch: 5| Step: 10
Training loss: 2.7738728523254395
Validation loss: 2.101173089396569

Epoch: 60| Step: 0
Training loss: 2.3300249576568604
Validation loss: 2.0889238029397945

Epoch: 5| Step: 1
Training loss: 2.823775053024292
Validation loss: 2.087335027674193

Epoch: 5| Step: 2
Training loss: 2.286834478378296
Validation loss: 2.0860476557926466

Epoch: 5| Step: 3
Training loss: 2.475215196609497
Validation loss: 2.086573766123864

Epoch: 5| Step: 4
Training loss: 2.859508514404297
Validation loss: 2.091393768146474

Epoch: 5| Step: 5
Training loss: 2.3083739280700684
Validation loss: 2.1050842308229014

Epoch: 5| Step: 6
Training loss: 2.146474838256836
Validation loss: 2.1211168945476575

Epoch: 5| Step: 7
Training loss: 1.9762130975723267
Validation loss: 2.161875218473455

Epoch: 5| Step: 8
Training loss: 2.0473177433013916
Validation loss: 2.147221867756177

Epoch: 5| Step: 9
Training loss: 2.3285136222839355
Validation loss: 2.1176064014434814

Epoch: 5| Step: 10
Training loss: 3.119196891784668
Validation loss: 2.0898633618508615

Epoch: 61| Step: 0
Training loss: 2.4075965881347656
Validation loss: 2.081962036830123

Epoch: 5| Step: 1
Training loss: 2.475569725036621
Validation loss: 2.081490291062222

Epoch: 5| Step: 2
Training loss: 2.200932025909424
Validation loss: 2.0826927474749986

Epoch: 5| Step: 3
Training loss: 2.1306381225585938
Validation loss: 2.081969144523785

Epoch: 5| Step: 4
Training loss: 2.4166035652160645
Validation loss: 2.0975717344591693

Epoch: 5| Step: 5
Training loss: 2.040083646774292
Validation loss: 2.098936434715025

Epoch: 5| Step: 6
Training loss: 2.7822539806365967
Validation loss: 2.107057366319882

Epoch: 5| Step: 7
Training loss: 2.578566074371338
Validation loss: 2.1082052928145214

Epoch: 5| Step: 8
Training loss: 2.7147974967956543
Validation loss: 2.104369545495638

Epoch: 5| Step: 9
Training loss: 2.6341891288757324
Validation loss: 2.0964724556092293

Epoch: 5| Step: 10
Training loss: 1.9182279109954834
Validation loss: 2.097192513045444

Epoch: 62| Step: 0
Training loss: 2.059230327606201
Validation loss: 2.088899827772571

Epoch: 5| Step: 1
Training loss: 2.2348389625549316
Validation loss: 2.079312370669457

Epoch: 5| Step: 2
Training loss: 2.5282745361328125
Validation loss: 2.089273545049852

Epoch: 5| Step: 3
Training loss: 2.7795770168304443
Validation loss: 2.0798161055452082

Epoch: 5| Step: 4
Training loss: 2.9717438220977783
Validation loss: 2.0686138086421515

Epoch: 5| Step: 5
Training loss: 2.5347189903259277
Validation loss: 2.051235701448174

Epoch: 5| Step: 6
Training loss: 2.1289455890655518
Validation loss: 2.063168220622565

Epoch: 5| Step: 7
Training loss: 2.616353750228882
Validation loss: 2.0545386370792182

Epoch: 5| Step: 8
Training loss: 2.4522831439971924
Validation loss: 2.061957226004652

Epoch: 5| Step: 9
Training loss: 2.155238628387451
Validation loss: 2.060529452498241

Epoch: 5| Step: 10
Training loss: 1.724730372428894
Validation loss: 2.05574026671789

Epoch: 63| Step: 0
Training loss: 2.112204074859619
Validation loss: 2.056541686416954

Epoch: 5| Step: 1
Training loss: 2.114408016204834
Validation loss: 2.0495062592209026

Epoch: 5| Step: 2
Training loss: 2.8635575771331787
Validation loss: 2.05080682487898

Epoch: 5| Step: 3
Training loss: 1.9440410137176514
Validation loss: 2.04503644153636

Epoch: 5| Step: 4
Training loss: 2.0291543006896973
Validation loss: 2.055613439570191

Epoch: 5| Step: 5
Training loss: 2.4893901348114014
Validation loss: 2.0891989302891556

Epoch: 5| Step: 6
Training loss: 2.671337604522705
Validation loss: 2.1523120685290267

Epoch: 5| Step: 7
Training loss: 2.14898681640625
Validation loss: 2.1828694933204242

Epoch: 5| Step: 8
Training loss: 2.1466891765594482
Validation loss: 2.1650988824905886

Epoch: 5| Step: 9
Training loss: 3.1568024158477783
Validation loss: 2.13448836470163

Epoch: 5| Step: 10
Training loss: 2.872304677963257
Validation loss: 2.0804690545605076

Epoch: 64| Step: 0
Training loss: 2.7054965496063232
Validation loss: 2.051874345348727

Epoch: 5| Step: 1
Training loss: 2.1082990169525146
Validation loss: 2.0555594992893997

Epoch: 5| Step: 2
Training loss: 2.3666927814483643
Validation loss: 2.0608101788387505

Epoch: 5| Step: 3
Training loss: 2.8318185806274414
Validation loss: 2.0698637347067557

Epoch: 5| Step: 4
Training loss: 2.214698553085327
Validation loss: 2.0674567876323575

Epoch: 5| Step: 5
Training loss: 2.2745718955993652
Validation loss: 2.0604604469832553

Epoch: 5| Step: 6
Training loss: 3.1096158027648926
Validation loss: 2.0505711417044363

Epoch: 5| Step: 7
Training loss: 2.769965887069702
Validation loss: 2.0725876528729676

Epoch: 5| Step: 8
Training loss: 1.9381011724472046
Validation loss: 2.1337490799606487

Epoch: 5| Step: 9
Training loss: 2.0895256996154785
Validation loss: 2.1841181555101947

Epoch: 5| Step: 10
Training loss: 2.2138659954071045
Validation loss: 2.202050285954629

Epoch: 65| Step: 0
Training loss: 2.53027081489563
Validation loss: 2.173453720667029

Epoch: 5| Step: 1
Training loss: 1.9736642837524414
Validation loss: 2.1250841361220165

Epoch: 5| Step: 2
Training loss: 2.3888185024261475
Validation loss: 2.075400460150934

Epoch: 5| Step: 3
Training loss: 1.6125104427337646
Validation loss: 2.044727453621485

Epoch: 5| Step: 4
Training loss: 2.3159782886505127
Validation loss: 2.044221853697172

Epoch: 5| Step: 5
Training loss: 2.346082925796509
Validation loss: 2.056642488766742

Epoch: 5| Step: 6
Training loss: 2.7222046852111816
Validation loss: 2.0579287185463855

Epoch: 5| Step: 7
Training loss: 2.762012004852295
Validation loss: 2.0523550215587822

Epoch: 5| Step: 8
Training loss: 2.353677272796631
Validation loss: 2.0473371064791115

Epoch: 5| Step: 9
Training loss: 2.400602340698242
Validation loss: 2.0550369165276967

Epoch: 5| Step: 10
Training loss: 3.057682514190674
Validation loss: 2.052321510930215

Epoch: 66| Step: 0
Training loss: 2.365020275115967
Validation loss: 2.059504432062949

Epoch: 5| Step: 1
Training loss: 2.5290791988372803
Validation loss: 2.071131947220013

Epoch: 5| Step: 2
Training loss: 1.8360321521759033
Validation loss: 2.10173895025766

Epoch: 5| Step: 3
Training loss: 1.9769521951675415
Validation loss: 2.092573892685675

Epoch: 5| Step: 4
Training loss: 2.524536371231079
Validation loss: 2.092348035945687

Epoch: 5| Step: 5
Training loss: 2.9570794105529785
Validation loss: 2.0724075096909718

Epoch: 5| Step: 6
Training loss: 2.392568349838257
Validation loss: 2.077618355392128

Epoch: 5| Step: 7
Training loss: 2.404226541519165
Validation loss: 2.0815909934300247

Epoch: 5| Step: 8
Training loss: 2.393458843231201
Validation loss: 2.074965068089065

Epoch: 5| Step: 9
Training loss: 2.169833183288574
Validation loss: 2.0629120795957503

Epoch: 5| Step: 10
Training loss: 2.551618814468384
Validation loss: 2.069468839194185

Epoch: 67| Step: 0
Training loss: 2.0323758125305176
Validation loss: 2.0684299212630077

Epoch: 5| Step: 1
Training loss: 2.3602678775787354
Validation loss: 2.0835552959031958

Epoch: 5| Step: 2
Training loss: 2.876511573791504
Validation loss: 2.0841279516937914

Epoch: 5| Step: 3
Training loss: 2.343836545944214
Validation loss: 2.089686780847529

Epoch: 5| Step: 4
Training loss: 2.047973155975342
Validation loss: 2.060275429038591

Epoch: 5| Step: 5
Training loss: 2.0749781131744385
Validation loss: 2.0643979246898363

Epoch: 5| Step: 6
Training loss: 2.2800917625427246
Validation loss: 2.0692719772297847

Epoch: 5| Step: 7
Training loss: 2.837731122970581
Validation loss: 2.0780115153199885

Epoch: 5| Step: 8
Training loss: 2.2729458808898926
Validation loss: 2.0652953270942933

Epoch: 5| Step: 9
Training loss: 2.260455369949341
Validation loss: 2.066850595576789

Epoch: 5| Step: 10
Training loss: 2.535161256790161
Validation loss: 2.0608971413745674

Epoch: 68| Step: 0
Training loss: 2.9592413902282715
Validation loss: 2.039483913811304

Epoch: 5| Step: 1
Training loss: 2.0134856700897217
Validation loss: 2.042207715331867

Epoch: 5| Step: 2
Training loss: 2.4383206367492676
Validation loss: 2.043456695413077

Epoch: 5| Step: 3
Training loss: 2.6611247062683105
Validation loss: 2.0438876998039985

Epoch: 5| Step: 4
Training loss: 2.8419888019561768
Validation loss: 2.045403472838863

Epoch: 5| Step: 5
Training loss: 2.2236297130584717
Validation loss: 2.0524346764369676

Epoch: 5| Step: 6
Training loss: 2.4513955116271973
Validation loss: 2.0704793596780426

Epoch: 5| Step: 7
Training loss: 1.8401505947113037
Validation loss: 2.099779676365596

Epoch: 5| Step: 8
Training loss: 1.712781310081482
Validation loss: 2.111907437283506

Epoch: 5| Step: 9
Training loss: 2.1721158027648926
Validation loss: 2.120900592496318

Epoch: 5| Step: 10
Training loss: 2.7673747539520264
Validation loss: 2.0973725780364005

Epoch: 69| Step: 0
Training loss: 2.021120548248291
Validation loss: 2.0785679381380797

Epoch: 5| Step: 1
Training loss: 1.9320672750473022
Validation loss: 2.0555956466223604

Epoch: 5| Step: 2
Training loss: 2.7856130599975586
Validation loss: 2.0335127281886276

Epoch: 5| Step: 3
Training loss: 2.6584458351135254
Validation loss: 2.0246130868952763

Epoch: 5| Step: 4
Training loss: 3.145179271697998
Validation loss: 2.023114176206691

Epoch: 5| Step: 5
Training loss: 1.3433233499526978
Validation loss: 2.0279409731588056

Epoch: 5| Step: 6
Training loss: 2.1348884105682373
Validation loss: 2.022100892118228

Epoch: 5| Step: 7
Training loss: 2.552220344543457
Validation loss: 2.022552744034798

Epoch: 5| Step: 8
Training loss: 2.1112942695617676
Validation loss: 2.029287104965538

Epoch: 5| Step: 9
Training loss: 2.6850123405456543
Validation loss: 2.0724576993655135

Epoch: 5| Step: 10
Training loss: 2.695150136947632
Validation loss: 2.1122743134857505

Epoch: 70| Step: 0
Training loss: 1.6870924234390259
Validation loss: 2.1272682912888063

Epoch: 5| Step: 1
Training loss: 1.9398975372314453
Validation loss: 2.1335299220136417

Epoch: 5| Step: 2
Training loss: 2.68818998336792
Validation loss: 2.1339173880956506

Epoch: 5| Step: 3
Training loss: 1.9264843463897705
Validation loss: 2.124838544476417

Epoch: 5| Step: 4
Training loss: 2.8127827644348145
Validation loss: 2.0848959184462026

Epoch: 5| Step: 5
Training loss: 2.630201578140259
Validation loss: 2.0668491907017206

Epoch: 5| Step: 6
Training loss: 3.0236785411834717
Validation loss: 2.0374814541109147

Epoch: 5| Step: 7
Training loss: 2.6034505367279053
Validation loss: 2.040438882766231

Epoch: 5| Step: 8
Training loss: 2.0613183975219727
Validation loss: 2.0339451118182112

Epoch: 5| Step: 9
Training loss: 2.354736089706421
Validation loss: 2.036787079226586

Epoch: 5| Step: 10
Training loss: 2.1104578971862793
Validation loss: 2.0440497936741

Epoch: 71| Step: 0
Training loss: 2.3712291717529297
Validation loss: 2.0417453217250046

Epoch: 5| Step: 1
Training loss: 2.6085946559906006
Validation loss: 2.039912349434309

Epoch: 5| Step: 2
Training loss: 1.7082551717758179
Validation loss: 2.0415239975016606

Epoch: 5| Step: 3
Training loss: 2.8476176261901855
Validation loss: 2.051821199796533

Epoch: 5| Step: 4
Training loss: 2.3556666374206543
Validation loss: 2.0501191077693814

Epoch: 5| Step: 5
Training loss: 1.8893911838531494
Validation loss: 2.0430250219119492

Epoch: 5| Step: 6
Training loss: 2.505343198776245
Validation loss: 2.0554938752164125

Epoch: 5| Step: 7
Training loss: 2.170853614807129
Validation loss: 2.0601976327998663

Epoch: 5| Step: 8
Training loss: 1.9198144674301147
Validation loss: 2.0537655609910206

Epoch: 5| Step: 9
Training loss: 2.5658328533172607
Validation loss: 2.0590023597081504

Epoch: 5| Step: 10
Training loss: 2.6869924068450928
Validation loss: 2.0779354136477233

Epoch: 72| Step: 0
Training loss: 2.6600091457366943
Validation loss: 2.086988701615282

Epoch: 5| Step: 1
Training loss: 2.4867043495178223
Validation loss: 2.0864759132426274

Epoch: 5| Step: 2
Training loss: 1.892801284790039
Validation loss: 2.0855275661714616

Epoch: 5| Step: 3
Training loss: 2.635336399078369
Validation loss: 2.0555895015757573

Epoch: 5| Step: 4
Training loss: 2.355271816253662
Validation loss: 2.0517396773061445

Epoch: 5| Step: 5
Training loss: 2.1292777061462402
Validation loss: 2.02797536183429

Epoch: 5| Step: 6
Training loss: 2.0709476470947266
Validation loss: 2.030204075638966

Epoch: 5| Step: 7
Training loss: 2.4166195392608643
Validation loss: 2.032883490285566

Epoch: 5| Step: 8
Training loss: 2.3334145545959473
Validation loss: 2.016394806164567

Epoch: 5| Step: 9
Training loss: 1.6627826690673828
Validation loss: 2.0130041209600305

Epoch: 5| Step: 10
Training loss: 2.956932306289673
Validation loss: 2.006294692716291

Epoch: 73| Step: 0
Training loss: 2.1338868141174316
Validation loss: 2.0137985214110343

Epoch: 5| Step: 1
Training loss: 2.1452040672302246
Validation loss: 2.0153017326067855

Epoch: 5| Step: 2
Training loss: 2.0738096237182617
Validation loss: 2.0283230581591205

Epoch: 5| Step: 3
Training loss: 2.585407018661499
Validation loss: 2.029028989935434

Epoch: 5| Step: 4
Training loss: 2.008234739303589
Validation loss: 2.0497558373276905

Epoch: 5| Step: 5
Training loss: 2.610243558883667
Validation loss: 2.061079763597058

Epoch: 5| Step: 6
Training loss: 2.084892988204956
Validation loss: 2.0638406533066944

Epoch: 5| Step: 7
Training loss: 2.636817455291748
Validation loss: 2.0562639082631757

Epoch: 5| Step: 8
Training loss: 2.2122738361358643
Validation loss: 2.058387089801091

Epoch: 5| Step: 9
Training loss: 2.8414387702941895
Validation loss: 2.044824605347008

Epoch: 5| Step: 10
Training loss: 2.297790288925171
Validation loss: 2.0479768527451383

Epoch: 74| Step: 0
Training loss: 2.4927966594696045
Validation loss: 2.0622942524571575

Epoch: 5| Step: 1
Training loss: 1.8909565210342407
Validation loss: 2.0836798426925496

Epoch: 5| Step: 2
Training loss: 2.074341297149658
Validation loss: 2.084533228669115

Epoch: 5| Step: 3
Training loss: 2.8248000144958496
Validation loss: 2.0528702556446032

Epoch: 5| Step: 4
Training loss: 2.0473837852478027
Validation loss: 2.039775566388202

Epoch: 5| Step: 5
Training loss: 2.018815040588379
Validation loss: 2.020523609653596

Epoch: 5| Step: 6
Training loss: 2.9544997215270996
Validation loss: 2.0167418359428324

Epoch: 5| Step: 7
Training loss: 2.6824846267700195
Validation loss: 2.0203568679030224

Epoch: 5| Step: 8
Training loss: 2.176879405975342
Validation loss: 2.020905938199771

Epoch: 5| Step: 9
Training loss: 2.0593698024749756
Validation loss: 2.0216339352310344

Epoch: 5| Step: 10
Training loss: 2.6067845821380615
Validation loss: 2.048693246738885

Epoch: 75| Step: 0
Training loss: 2.0039782524108887
Validation loss: 2.0969672177427556

Epoch: 5| Step: 1
Training loss: 2.667696475982666
Validation loss: 2.1450500116553357

Epoch: 5| Step: 2
Training loss: 2.20283579826355
Validation loss: 2.1394553415236937

Epoch: 5| Step: 3
Training loss: 2.3351125717163086
Validation loss: 2.108922245681927

Epoch: 5| Step: 4
Training loss: 1.5373499393463135
Validation loss: 2.085640508641479

Epoch: 5| Step: 5
Training loss: 1.9318225383758545
Validation loss: 2.0649978217258247

Epoch: 5| Step: 6
Training loss: 2.823629856109619
Validation loss: 2.0596513132895193

Epoch: 5| Step: 7
Training loss: 2.636939525604248
Validation loss: 2.054264827441144

Epoch: 5| Step: 8
Training loss: 2.5419812202453613
Validation loss: 2.048415345530356

Epoch: 5| Step: 9
Training loss: 2.5592215061187744
Validation loss: 2.0509485634424354

Epoch: 5| Step: 10
Training loss: 2.435079574584961
Validation loss: 2.0851476077110536

Epoch: 76| Step: 0
Training loss: 1.8893749713897705
Validation loss: 2.1311965962891937

Epoch: 5| Step: 1
Training loss: 2.734760284423828
Validation loss: 2.1447614175017162

Epoch: 5| Step: 2
Training loss: 2.247302532196045
Validation loss: 2.170651771688974

Epoch: 5| Step: 3
Training loss: 2.0694146156311035
Validation loss: 2.162888411552675

Epoch: 5| Step: 4
Training loss: 2.931462526321411
Validation loss: 2.1704781478451145

Epoch: 5| Step: 5
Training loss: 2.3701319694519043
Validation loss: 2.129597099878455

Epoch: 5| Step: 6
Training loss: 2.0758767127990723
Validation loss: 2.0488038896232523

Epoch: 5| Step: 7
Training loss: 2.382620096206665
Validation loss: 2.0350714396404963

Epoch: 5| Step: 8
Training loss: 2.5906519889831543
Validation loss: 2.036449133708913

Epoch: 5| Step: 9
Training loss: 2.607451915740967
Validation loss: 2.0643240687667683

Epoch: 5| Step: 10
Training loss: 1.9281392097473145
Validation loss: 2.1691359166176087

Epoch: 77| Step: 0
Training loss: 2.1846556663513184
Validation loss: 2.2717716052968013

Epoch: 5| Step: 1
Training loss: 2.547020673751831
Validation loss: 2.1969674505213255

Epoch: 5| Step: 2
Training loss: 2.5657453536987305
Validation loss: 2.0980064048562

Epoch: 5| Step: 3
Training loss: 3.2135818004608154
Validation loss: 2.025923409769612

Epoch: 5| Step: 4
Training loss: 2.902386426925659
Validation loss: 2.025142074913107

Epoch: 5| Step: 5
Training loss: 1.9282076358795166
Validation loss: 2.0528708939911215

Epoch: 5| Step: 6
Training loss: 1.5458680391311646
Validation loss: 2.0792672711033977

Epoch: 5| Step: 7
Training loss: 2.3687477111816406
Validation loss: 2.105225920677185

Epoch: 5| Step: 8
Training loss: 2.371098041534424
Validation loss: 2.0994952289007043

Epoch: 5| Step: 9
Training loss: 1.8504984378814697
Validation loss: 2.061959861427225

Epoch: 5| Step: 10
Training loss: 2.34562349319458
Validation loss: 2.035826477953183

Epoch: 78| Step: 0
Training loss: 1.7701416015625
Validation loss: 2.0248124599456787

Epoch: 5| Step: 1
Training loss: 2.7132976055145264
Validation loss: 2.0117247719918527

Epoch: 5| Step: 2
Training loss: 2.6611411571502686
Validation loss: 2.014981036545128

Epoch: 5| Step: 3
Training loss: 2.5513086318969727
Validation loss: 2.0089857373186337

Epoch: 5| Step: 4
Training loss: 2.9862942695617676
Validation loss: 2.014841313003212

Epoch: 5| Step: 5
Training loss: 2.1034328937530518
Validation loss: 2.001757983238466

Epoch: 5| Step: 6
Training loss: 3.041527271270752
Validation loss: 2.017401736269715

Epoch: 5| Step: 7
Training loss: 1.8579654693603516
Validation loss: 2.040276454341027

Epoch: 5| Step: 8
Training loss: 2.3079545497894287
Validation loss: 2.0537541809902398

Epoch: 5| Step: 9
Training loss: 1.476340413093567
Validation loss: 2.068292478079437

Epoch: 5| Step: 10
Training loss: 1.8938589096069336
Validation loss: 2.0641240727516914

Epoch: 79| Step: 0
Training loss: 2.269591808319092
Validation loss: 2.032924323953608

Epoch: 5| Step: 1
Training loss: 2.0270063877105713
Validation loss: 2.0255627837232364

Epoch: 5| Step: 2
Training loss: 2.1437315940856934
Validation loss: 2.0147989078234603

Epoch: 5| Step: 3
Training loss: 2.4251859188079834
Validation loss: 2.0045342522282756

Epoch: 5| Step: 4
Training loss: 1.7160365581512451
Validation loss: 2.006651941166129

Epoch: 5| Step: 5
Training loss: 2.517638683319092
Validation loss: 2.006657241493143

Epoch: 5| Step: 6
Training loss: 3.0236916542053223
Validation loss: 2.00522348957677

Epoch: 5| Step: 7
Training loss: 2.0503296852111816
Validation loss: 2.0070344068670787

Epoch: 5| Step: 8
Training loss: 2.3621935844421387
Validation loss: 2.009546977217479

Epoch: 5| Step: 9
Training loss: 2.2727770805358887
Validation loss: 2.0331220947286135

Epoch: 5| Step: 10
Training loss: 2.3571765422821045
Validation loss: 2.0393602360961256

Epoch: 80| Step: 0
Training loss: 1.9015703201293945
Validation loss: 2.0508026692175094

Epoch: 5| Step: 1
Training loss: 2.160250186920166
Validation loss: 2.0370701589891986

Epoch: 5| Step: 2
Training loss: 2.075807571411133
Validation loss: 2.053357134583176

Epoch: 5| Step: 3
Training loss: 2.2003653049468994
Validation loss: 2.052484717420352

Epoch: 5| Step: 4
Training loss: 2.444828748703003
Validation loss: 2.0632903806624876

Epoch: 5| Step: 5
Training loss: 2.386173963546753
Validation loss: 2.0305463908821024

Epoch: 5| Step: 6
Training loss: 2.835618257522583
Validation loss: 2.002971673524508

Epoch: 5| Step: 7
Training loss: 2.1182456016540527
Validation loss: 2.010903840423912

Epoch: 5| Step: 8
Training loss: 2.237704277038574
Validation loss: 2.011695202960763

Epoch: 5| Step: 9
Training loss: 2.4049181938171387
Validation loss: 2.0220413105462187

Epoch: 5| Step: 10
Training loss: 2.4144744873046875
Validation loss: 2.040212506889015

Epoch: 81| Step: 0
Training loss: 1.9850876331329346
Validation loss: 2.075039714895269

Epoch: 5| Step: 1
Training loss: 2.1545958518981934
Validation loss: 2.0917856065175866

Epoch: 5| Step: 2
Training loss: 2.3186802864074707
Validation loss: 2.0829595045376847

Epoch: 5| Step: 3
Training loss: 1.5979342460632324
Validation loss: 2.0498410194150862

Epoch: 5| Step: 4
Training loss: 2.52565336227417
Validation loss: 2.035208079122728

Epoch: 5| Step: 5
Training loss: 2.674656867980957
Validation loss: 2.026213181916104

Epoch: 5| Step: 6
Training loss: 2.5075695514678955
Validation loss: 2.044182003185313

Epoch: 5| Step: 7
Training loss: 2.1692607402801514
Validation loss: 2.0486776162219305

Epoch: 5| Step: 8
Training loss: 2.7568554878234863
Validation loss: 2.09007772578988

Epoch: 5| Step: 9
Training loss: 1.9704049825668335
Validation loss: 2.111440053550146

Epoch: 5| Step: 10
Training loss: 2.328538179397583
Validation loss: 2.11994578120529

Epoch: 82| Step: 0
Training loss: 2.4247848987579346
Validation loss: 2.0729756727013537

Epoch: 5| Step: 1
Training loss: 2.3588085174560547
Validation loss: 2.03650943181848

Epoch: 5| Step: 2
Training loss: 2.280714750289917
Validation loss: 2.0205972040853193

Epoch: 5| Step: 3
Training loss: 3.0172362327575684
Validation loss: 2.0064809245447957

Epoch: 5| Step: 4
Training loss: 2.161404848098755
Validation loss: 1.999860719967914

Epoch: 5| Step: 5
Training loss: 1.6444600820541382
Validation loss: 1.9908632437388103

Epoch: 5| Step: 6
Training loss: 1.9993616342544556
Validation loss: 1.9996934924074399

Epoch: 5| Step: 7
Training loss: 1.7373759746551514
Validation loss: 1.9977203171740296

Epoch: 5| Step: 8
Training loss: 2.1056079864501953
Validation loss: 2.0097762807723014

Epoch: 5| Step: 9
Training loss: 2.9294660091400146
Validation loss: 2.0167827695928593

Epoch: 5| Step: 10
Training loss: 2.2129688262939453
Validation loss: 2.056560283066124

Epoch: 83| Step: 0
Training loss: 2.2384281158447266
Validation loss: 2.103741914995255

Epoch: 5| Step: 1
Training loss: 2.3180766105651855
Validation loss: 2.1427765482215473

Epoch: 5| Step: 2
Training loss: 2.130715847015381
Validation loss: 2.1458629433826735

Epoch: 5| Step: 3
Training loss: 1.9966790676116943
Validation loss: 2.1534114717155375

Epoch: 5| Step: 4
Training loss: 2.617516279220581
Validation loss: 2.145036082113943

Epoch: 5| Step: 5
Training loss: 2.157902240753174
Validation loss: 2.104845511016025

Epoch: 5| Step: 6
Training loss: 2.3410778045654297
Validation loss: 2.067335599212236

Epoch: 5| Step: 7
Training loss: 2.6388962268829346
Validation loss: 2.04936049830529

Epoch: 5| Step: 8
Training loss: 2.3163857460021973
Validation loss: 2.0378577004196825

Epoch: 5| Step: 9
Training loss: 1.9520094394683838
Validation loss: 2.0436738562840286

Epoch: 5| Step: 10
Training loss: 2.366781711578369
Validation loss: 2.025134035336074

Epoch: 84| Step: 0
Training loss: 1.754786729812622
Validation loss: 2.011848385616015

Epoch: 5| Step: 1
Training loss: 2.2402119636535645
Validation loss: 2.0040494498386177

Epoch: 5| Step: 2
Training loss: 1.9154189825057983
Validation loss: 2.009239614650767

Epoch: 5| Step: 3
Training loss: 2.5988709926605225
Validation loss: 2.010643115607641

Epoch: 5| Step: 4
Training loss: 1.8085041046142578
Validation loss: 2.0172279701438

Epoch: 5| Step: 5
Training loss: 2.7753732204437256
Validation loss: 2.028658140090204

Epoch: 5| Step: 6
Training loss: 2.6790661811828613
Validation loss: 2.0272467790111417

Epoch: 5| Step: 7
Training loss: 1.9905647039413452
Validation loss: 2.042480787923259

Epoch: 5| Step: 8
Training loss: 2.6853365898132324
Validation loss: 2.0461901900588826

Epoch: 5| Step: 9
Training loss: 1.9617782831192017
Validation loss: 2.054942992425734

Epoch: 5| Step: 10
Training loss: 2.3542418479919434
Validation loss: 2.0931115022269626

Epoch: 85| Step: 0
Training loss: 2.702665090560913
Validation loss: 2.1092739771771174

Epoch: 5| Step: 1
Training loss: 2.0755841732025146
Validation loss: 2.0891691741122993

Epoch: 5| Step: 2
Training loss: 2.5373988151550293
Validation loss: 2.0709155272412043

Epoch: 5| Step: 3
Training loss: 2.195647716522217
Validation loss: 2.04960463893029

Epoch: 5| Step: 4
Training loss: 2.385258436203003
Validation loss: 2.0382856809964744

Epoch: 5| Step: 5
Training loss: 2.8572800159454346
Validation loss: 2.0376541306895595

Epoch: 5| Step: 6
Training loss: 1.6547515392303467
Validation loss: 2.036684892510855

Epoch: 5| Step: 7
Training loss: 2.1084249019622803
Validation loss: 2.037127499939293

Epoch: 5| Step: 8
Training loss: 2.612955093383789
Validation loss: 2.037343530244725

Epoch: 5| Step: 9
Training loss: 1.903016448020935
Validation loss: 2.0456466354349607

Epoch: 5| Step: 10
Training loss: 1.5251877307891846
Validation loss: 2.0410640188442764

Epoch: 86| Step: 0
Training loss: 2.4503321647644043
Validation loss: 2.0346491234276884

Epoch: 5| Step: 1
Training loss: 2.160459518432617
Validation loss: 2.057260977324619

Epoch: 5| Step: 2
Training loss: 2.0220351219177246
Validation loss: 2.081118732370356

Epoch: 5| Step: 3
Training loss: 2.3918628692626953
Validation loss: 2.0764624162386824

Epoch: 5| Step: 4
Training loss: 1.6963036060333252
Validation loss: 2.092246122257684

Epoch: 5| Step: 5
Training loss: 1.9001766443252563
Validation loss: 2.1178041030001897

Epoch: 5| Step: 6
Training loss: 2.5336146354675293
Validation loss: 2.1181219649571243

Epoch: 5| Step: 7
Training loss: 2.034039258956909
Validation loss: 2.0853708764558196

Epoch: 5| Step: 8
Training loss: 2.82939076423645
Validation loss: 2.047256951691002

Epoch: 5| Step: 9
Training loss: 2.6618492603302
Validation loss: 2.025948885948427

Epoch: 5| Step: 10
Training loss: 1.9057592153549194
Validation loss: 2.0160048033601496

Epoch: 87| Step: 0
Training loss: 2.368478298187256
Validation loss: 2.02010194716915

Epoch: 5| Step: 1
Training loss: 1.9807701110839844
Validation loss: 2.0138184575624365

Epoch: 5| Step: 2
Training loss: 2.4347219467163086
Validation loss: 2.0207618782597203

Epoch: 5| Step: 3
Training loss: 1.9875962734222412
Validation loss: 2.0195597499929447

Epoch: 5| Step: 4
Training loss: 2.063110589981079
Validation loss: 2.0408800878832416

Epoch: 5| Step: 5
Training loss: 2.3960044384002686
Validation loss: 2.0586542544826383

Epoch: 5| Step: 6
Training loss: 2.4876601696014404
Validation loss: 2.0583404905052594

Epoch: 5| Step: 7
Training loss: 2.3441832065582275
Validation loss: 2.05488178037828

Epoch: 5| Step: 8
Training loss: 1.9553943872451782
Validation loss: 2.072844946256248

Epoch: 5| Step: 9
Training loss: 2.4611423015594482
Validation loss: 2.051792936940347

Epoch: 5| Step: 10
Training loss: 2.1315596103668213
Validation loss: 2.0267953949589885

Epoch: 88| Step: 0
Training loss: 2.4419174194335938
Validation loss: 2.033519721800281

Epoch: 5| Step: 1
Training loss: 2.3020708560943604
Validation loss: 2.050154111718619

Epoch: 5| Step: 2
Training loss: 2.024322032928467
Validation loss: 2.0637983058088567

Epoch: 5| Step: 3
Training loss: 2.5513758659362793
Validation loss: 2.0748517385093113

Epoch: 5| Step: 4
Training loss: 1.479418396949768
Validation loss: 2.0669685986734208

Epoch: 5| Step: 5
Training loss: 2.5621113777160645
Validation loss: 2.058904186371834

Epoch: 5| Step: 6
Training loss: 2.205613613128662
Validation loss: 2.053580617391935

Epoch: 5| Step: 7
Training loss: 2.8035783767700195
Validation loss: 2.058979426660845

Epoch: 5| Step: 8
Training loss: 1.5178859233856201
Validation loss: 2.074919605767855

Epoch: 5| Step: 9
Training loss: 2.222008228302002
Validation loss: 2.099279693377915

Epoch: 5| Step: 10
Training loss: 2.473095655441284
Validation loss: 2.167240224858766

Epoch: 89| Step: 0
Training loss: 2.5671324729919434
Validation loss: 2.126891874497937

Epoch: 5| Step: 1
Training loss: 1.7214075326919556
Validation loss: 2.1089449646652385

Epoch: 5| Step: 2
Training loss: 1.8250234127044678
Validation loss: 2.0522885463571034

Epoch: 5| Step: 3
Training loss: 1.7461745738983154
Validation loss: 2.0126290039349626

Epoch: 5| Step: 4
Training loss: 2.5988755226135254
Validation loss: 1.9976563402401504

Epoch: 5| Step: 5
Training loss: 2.713528633117676
Validation loss: 2.015231183780137

Epoch: 5| Step: 6
Training loss: 2.147810697555542
Validation loss: 2.047701751032183

Epoch: 5| Step: 7
Training loss: 2.262712001800537
Validation loss: 2.0772027571996055

Epoch: 5| Step: 8
Training loss: 2.1515517234802246
Validation loss: 2.0669242669177312

Epoch: 5| Step: 9
Training loss: 2.6974005699157715
Validation loss: 2.050335254720462

Epoch: 5| Step: 10
Training loss: 2.1891260147094727
Validation loss: 2.063730675687072

Epoch: 90| Step: 0
Training loss: 2.651564121246338
Validation loss: 2.1161929381790983

Epoch: 5| Step: 1
Training loss: 1.9730689525604248
Validation loss: 2.1870610008957567

Epoch: 5| Step: 2
Training loss: 2.290769338607788
Validation loss: 2.222655204034621

Epoch: 5| Step: 3
Training loss: 2.4257593154907227
Validation loss: 2.2191940738308813

Epoch: 5| Step: 4
Training loss: 1.8878977298736572
Validation loss: 2.1823492178352932

Epoch: 5| Step: 5
Training loss: 2.1848137378692627
Validation loss: 2.157047361455938

Epoch: 5| Step: 6
Training loss: 2.425455093383789
Validation loss: 2.1467732665359334

Epoch: 5| Step: 7
Training loss: 2.133324146270752
Validation loss: 2.133114960885817

Epoch: 5| Step: 8
Training loss: 2.277034044265747
Validation loss: 2.0744938337674705

Epoch: 5| Step: 9
Training loss: 1.931524634361267
Validation loss: 2.0330807675597486

Epoch: 5| Step: 10
Training loss: 2.075847864151001
Validation loss: 2.0302473678383777

Epoch: 91| Step: 0
Training loss: 2.5674610137939453
Validation loss: 2.0202130476633706

Epoch: 5| Step: 1
Training loss: 1.8997137546539307
Validation loss: 2.055707016298848

Epoch: 5| Step: 2
Training loss: 2.220320463180542
Validation loss: 2.058596755868645

Epoch: 5| Step: 3
Training loss: 2.275759220123291
Validation loss: 2.0554749324757564

Epoch: 5| Step: 4
Training loss: 1.5237042903900146
Validation loss: 2.062603665936378

Epoch: 5| Step: 5
Training loss: 2.1842522621154785
Validation loss: 2.075289798039262

Epoch: 5| Step: 6
Training loss: 2.5429935455322266
Validation loss: 2.0779475191588044

Epoch: 5| Step: 7
Training loss: 2.478322982788086
Validation loss: 2.1071902705777075

Epoch: 5| Step: 8
Training loss: 1.9003620147705078
Validation loss: 2.1432456893305623

Epoch: 5| Step: 9
Training loss: 2.6658458709716797
Validation loss: 2.164620466129754

Epoch: 5| Step: 10
Training loss: 2.151848554611206
Validation loss: 2.169163224517658

Epoch: 92| Step: 0
Training loss: 1.9891183376312256
Validation loss: 2.142807565709596

Epoch: 5| Step: 1
Training loss: 1.5434623956680298
Validation loss: 2.1233647997661302

Epoch: 5| Step: 2
Training loss: 2.7284324169158936
Validation loss: 2.081144778959213

Epoch: 5| Step: 3
Training loss: 2.4180045127868652
Validation loss: 2.052984881144698

Epoch: 5| Step: 4
Training loss: 2.1742913722991943
Validation loss: 2.0347978914937666

Epoch: 5| Step: 5
Training loss: 2.207581043243408
Validation loss: 2.032084866236615

Epoch: 5| Step: 6
Training loss: 2.0390000343322754
Validation loss: 2.053515377865043

Epoch: 5| Step: 7
Training loss: 2.145019054412842
Validation loss: 2.064980815815669

Epoch: 5| Step: 8
Training loss: 2.3550541400909424
Validation loss: 2.075025737926524

Epoch: 5| Step: 9
Training loss: 1.71177077293396
Validation loss: 2.1032477296808714

Epoch: 5| Step: 10
Training loss: 2.6208629608154297
Validation loss: 2.1638964247959915

Epoch: 93| Step: 0
Training loss: 2.5113987922668457
Validation loss: 2.1750388747902325

Epoch: 5| Step: 1
Training loss: 2.0037858486175537
Validation loss: 2.132933739692934

Epoch: 5| Step: 2
Training loss: 2.1900603771209717
Validation loss: 2.085176860132525

Epoch: 5| Step: 3
Training loss: 2.1385092735290527
Validation loss: 2.0738694129451627

Epoch: 5| Step: 4
Training loss: 1.7464895248413086
Validation loss: 2.052334638052089

Epoch: 5| Step: 5
Training loss: 2.6658308506011963
Validation loss: 2.051355505502352

Epoch: 5| Step: 6
Training loss: 2.6236119270324707
Validation loss: 2.0453868373747794

Epoch: 5| Step: 7
Training loss: 1.860032320022583
Validation loss: 2.0384462289912726

Epoch: 5| Step: 8
Training loss: 1.4671673774719238
Validation loss: 2.0472662397610244

Epoch: 5| Step: 9
Training loss: 2.407344341278076
Validation loss: 2.0663860664572766

Epoch: 5| Step: 10
Training loss: 1.9743390083312988
Validation loss: 2.1068476451340543

Epoch: 94| Step: 0
Training loss: 2.3900227546691895
Validation loss: 2.116724965392902

Epoch: 5| Step: 1
Training loss: 1.9716663360595703
Validation loss: 2.144651984655729

Epoch: 5| Step: 2
Training loss: 2.423798084259033
Validation loss: 2.1757491416828607

Epoch: 5| Step: 3
Training loss: 2.128549098968506
Validation loss: 2.1829750512235906

Epoch: 5| Step: 4
Training loss: 2.0598762035369873
Validation loss: 2.1540330174148723

Epoch: 5| Step: 5
Training loss: 2.237405300140381
Validation loss: 2.1401230622363347

Epoch: 5| Step: 6
Training loss: 2.31185245513916
Validation loss: 2.106368128971387

Epoch: 5| Step: 7
Training loss: 2.2740061283111572
Validation loss: 2.106662440043624

Epoch: 5| Step: 8
Training loss: 1.8876807689666748
Validation loss: 2.096600471004363

Epoch: 5| Step: 9
Training loss: 1.986684799194336
Validation loss: 2.079650863524406

Epoch: 5| Step: 10
Training loss: 2.019944906234741
Validation loss: 2.0390228866249003

Epoch: 95| Step: 0
Training loss: 2.187335729598999
Validation loss: 2.0316392273031254

Epoch: 5| Step: 1
Training loss: 2.108154773712158
Validation loss: 2.020748464010095

Epoch: 5| Step: 2
Training loss: 1.780117392539978
Validation loss: 2.0163674969826975

Epoch: 5| Step: 3
Training loss: 2.2434000968933105
Validation loss: 2.0156885026603617

Epoch: 5| Step: 4
Training loss: 1.7440048456192017
Validation loss: 2.0176381705909647

Epoch: 5| Step: 5
Training loss: 2.187251329421997
Validation loss: 2.0233801667408278

Epoch: 5| Step: 6
Training loss: 2.531024217605591
Validation loss: 2.027184135170393

Epoch: 5| Step: 7
Training loss: 2.385894775390625
Validation loss: 2.0377189831067155

Epoch: 5| Step: 8
Training loss: 2.068061590194702
Validation loss: 2.052920937538147

Epoch: 5| Step: 9
Training loss: 2.282064437866211
Validation loss: 2.06604947838732

Epoch: 5| Step: 10
Training loss: 2.0994441509246826
Validation loss: 2.0720412320988153

Epoch: 96| Step: 0
Training loss: 2.4782004356384277
Validation loss: 2.076661076596988

Epoch: 5| Step: 1
Training loss: 2.15568208694458
Validation loss: 2.0741090389990036

Epoch: 5| Step: 2
Training loss: 2.137317180633545
Validation loss: 2.0533544222513833

Epoch: 5| Step: 3
Training loss: 1.5787631273269653
Validation loss: 2.05889981280091

Epoch: 5| Step: 4
Training loss: 1.3129136562347412
Validation loss: 2.0406595532612135

Epoch: 5| Step: 5
Training loss: 2.5503945350646973
Validation loss: 2.0270911365427

Epoch: 5| Step: 6
Training loss: 1.9224693775177002
Validation loss: 2.033181252018098

Epoch: 5| Step: 7
Training loss: 2.6195785999298096
Validation loss: 2.028199485553208

Epoch: 5| Step: 8
Training loss: 1.9088051319122314
Validation loss: 2.038827144971458

Epoch: 5| Step: 9
Training loss: 2.3281397819519043
Validation loss: 2.0552443714552027

Epoch: 5| Step: 10
Training loss: 1.9822248220443726
Validation loss: 2.0915140298105057

Epoch: 97| Step: 0
Training loss: 1.8169682025909424
Validation loss: 2.146074859044885

Epoch: 5| Step: 1
Training loss: 1.739752173423767
Validation loss: 2.205676451806099

Epoch: 5| Step: 2
Training loss: 1.9380714893341064
Validation loss: 2.2476404841228197

Epoch: 5| Step: 3
Training loss: 2.4494407176971436
Validation loss: 2.295318026696482

Epoch: 5| Step: 4
Training loss: 1.840122938156128
Validation loss: 2.287558094147713

Epoch: 5| Step: 5
Training loss: 2.0618786811828613
Validation loss: 2.24240275608596

Epoch: 5| Step: 6
Training loss: 2.173018217086792
Validation loss: 2.171113403894568

Epoch: 5| Step: 7
Training loss: 2.9212982654571533
Validation loss: 2.124166264328905

Epoch: 5| Step: 8
Training loss: 1.7356210947036743
Validation loss: 2.0991461866645404

Epoch: 5| Step: 9
Training loss: 2.835707187652588
Validation loss: 2.0653075184873355

Epoch: 5| Step: 10
Training loss: 1.6109565496444702
Validation loss: 2.0244600542130007

Epoch: 98| Step: 0
Training loss: 1.5935051441192627
Validation loss: 2.018244586965089

Epoch: 5| Step: 1
Training loss: 1.758549451828003
Validation loss: 2.014809339277206

Epoch: 5| Step: 2
Training loss: 1.8920466899871826
Validation loss: 2.005408155020847

Epoch: 5| Step: 3
Training loss: 2.3077728748321533
Validation loss: 2.009310209622947

Epoch: 5| Step: 4
Training loss: 2.501744508743286
Validation loss: 2.0020778845715266

Epoch: 5| Step: 5
Training loss: 1.9803369045257568
Validation loss: 2.0091137206682594

Epoch: 5| Step: 6
Training loss: 2.1170601844787598
Validation loss: 2.036950083189113

Epoch: 5| Step: 7
Training loss: 2.5987839698791504
Validation loss: 2.032733686508671

Epoch: 5| Step: 8
Training loss: 2.5023398399353027
Validation loss: 2.0643283269738637

Epoch: 5| Step: 9
Training loss: 2.186976671218872
Validation loss: 2.0768069426218667

Epoch: 5| Step: 10
Training loss: 2.4160306453704834
Validation loss: 2.112326983482607

Epoch: 99| Step: 0
Training loss: 2.7362799644470215
Validation loss: 2.115980435443181

Epoch: 5| Step: 1
Training loss: 1.7906091213226318
Validation loss: 2.103525528343775

Epoch: 5| Step: 2
Training loss: 2.216529130935669
Validation loss: 2.097231254782728

Epoch: 5| Step: 3
Training loss: 2.0995421409606934
Validation loss: 2.0965580914610173

Epoch: 5| Step: 4
Training loss: 2.1963484287261963
Validation loss: 2.093369489075035

Epoch: 5| Step: 5
Training loss: 1.834790825843811
Validation loss: 2.0736427025128434

Epoch: 5| Step: 6
Training loss: 2.4861903190612793
Validation loss: 2.072829249084637

Epoch: 5| Step: 7
Training loss: 1.8450340032577515
Validation loss: 2.0643872701993553

Epoch: 5| Step: 8
Training loss: 1.9277756214141846
Validation loss: 2.087594829579835

Epoch: 5| Step: 9
Training loss: 1.6460520029067993
Validation loss: 2.1020213942373953

Epoch: 5| Step: 10
Training loss: 2.3064117431640625
Validation loss: 2.1243804244584936

Epoch: 100| Step: 0
Training loss: 1.7780227661132812
Validation loss: 2.103867828205068

Epoch: 5| Step: 1
Training loss: 2.1166391372680664
Validation loss: 2.1012877059239212

Epoch: 5| Step: 2
Training loss: 2.0050501823425293
Validation loss: 2.1132784556317072

Epoch: 5| Step: 3
Training loss: 2.4318313598632812
Validation loss: 2.0944367634352816

Epoch: 5| Step: 4
Training loss: 1.776749610900879
Validation loss: 2.086341119581653

Epoch: 5| Step: 5
Training loss: 2.053508758544922
Validation loss: 2.076440591965952

Epoch: 5| Step: 6
Training loss: 1.906302809715271
Validation loss: 2.078180936075026

Epoch: 5| Step: 7
Training loss: 2.267693042755127
Validation loss: 2.0705796416087816

Epoch: 5| Step: 8
Training loss: 2.3409485816955566
Validation loss: 2.0686203997622252

Epoch: 5| Step: 9
Training loss: 1.8511943817138672
Validation loss: 2.070604339722664

Epoch: 5| Step: 10
Training loss: 2.08866286277771
Validation loss: 2.0663455468352123

Epoch: 101| Step: 0
Training loss: 1.9197757244110107
Validation loss: 2.0592977334094305

Epoch: 5| Step: 1
Training loss: 2.3833370208740234
Validation loss: 2.0537609900197675

Epoch: 5| Step: 2
Training loss: 1.3994513750076294
Validation loss: 2.0495385559656287

Epoch: 5| Step: 3
Training loss: 1.980661153793335
Validation loss: 2.037239243907313

Epoch: 5| Step: 4
Training loss: 1.8256511688232422
Validation loss: 2.0424750171681887

Epoch: 5| Step: 5
Training loss: 2.289032459259033
Validation loss: 2.0473991491461314

Epoch: 5| Step: 6
Training loss: 2.0014846324920654
Validation loss: 2.0444210139654015

Epoch: 5| Step: 7
Training loss: 2.198700428009033
Validation loss: 2.0628813646172963

Epoch: 5| Step: 8
Training loss: 1.6583200693130493
Validation loss: 2.0973004038615892

Epoch: 5| Step: 9
Training loss: 1.7201372385025024
Validation loss: 2.1223764855374574

Epoch: 5| Step: 10
Training loss: 3.229998826980591
Validation loss: 2.1606878952313493

Epoch: 102| Step: 0
Training loss: 2.0267014503479004
Validation loss: 2.1760537906359603

Epoch: 5| Step: 1
Training loss: 2.2724335193634033
Validation loss: 2.176430231781416

Epoch: 5| Step: 2
Training loss: 2.064697742462158
Validation loss: 2.1805416153323267

Epoch: 5| Step: 3
Training loss: 2.294208288192749
Validation loss: 2.171255314221946

Epoch: 5| Step: 4
Training loss: 2.060502767562866
Validation loss: 2.150921985667239

Epoch: 5| Step: 5
Training loss: 1.936981201171875
Validation loss: 2.13280156863633

Epoch: 5| Step: 6
Training loss: 1.865573525428772
Validation loss: 2.1038385232289634

Epoch: 5| Step: 7
Training loss: 1.7642717361450195
Validation loss: 2.082733549097533

Epoch: 5| Step: 8
Training loss: 1.7281299829483032
Validation loss: 2.069868585114838

Epoch: 5| Step: 9
Training loss: 2.0332133769989014
Validation loss: 2.0636836559541765

Epoch: 5| Step: 10
Training loss: 2.255035877227783
Validation loss: 2.05906956554741

Epoch: 103| Step: 0
Training loss: 2.295689821243286
Validation loss: 2.052452976985644

Epoch: 5| Step: 1
Training loss: 1.5207898616790771
Validation loss: 2.044249188515448

Epoch: 5| Step: 2
Training loss: 1.8372987508773804
Validation loss: 2.034170107174945

Epoch: 5| Step: 3
Training loss: 1.9892851114273071
Validation loss: 2.0539349535460114

Epoch: 5| Step: 4
Training loss: 2.1695239543914795
Validation loss: 2.0486138430974816

Epoch: 5| Step: 5
Training loss: 2.1256306171417236
Validation loss: 2.04837623206518

Epoch: 5| Step: 6
Training loss: 1.9517145156860352
Validation loss: 2.0606497282622964

Epoch: 5| Step: 7
Training loss: 2.336580991744995
Validation loss: 2.0707693740885746

Epoch: 5| Step: 8
Training loss: 1.8028596639633179
Validation loss: 2.074207005962249

Epoch: 5| Step: 9
Training loss: 1.6232373714447021
Validation loss: 2.0863175930515414

Epoch: 5| Step: 10
Training loss: 2.3912360668182373
Validation loss: 2.105491686892766

Epoch: 104| Step: 0
Training loss: 1.9933967590332031
Validation loss: 2.1123898644601145

Epoch: 5| Step: 1
Training loss: 1.9086745977401733
Validation loss: 2.1015392580339984

Epoch: 5| Step: 2
Training loss: 2.4662017822265625
Validation loss: 2.0924200370747554

Epoch: 5| Step: 3
Training loss: 2.4515814781188965
Validation loss: 2.06659048475245

Epoch: 5| Step: 4
Training loss: 1.8977752923965454
Validation loss: 2.0817874593119465

Epoch: 5| Step: 5
Training loss: 1.566126823425293
Validation loss: 2.0752038724960817

Epoch: 5| Step: 6
Training loss: 1.8266894817352295
Validation loss: 2.0664621912023073

Epoch: 5| Step: 7
Training loss: 1.836769461631775
Validation loss: 2.073805527020526

Epoch: 5| Step: 8
Training loss: 2.1133151054382324
Validation loss: 2.0724586761125954

Epoch: 5| Step: 9
Training loss: 2.3276360034942627
Validation loss: 2.091878802545609

Epoch: 5| Step: 10
Training loss: 1.484358787536621
Validation loss: 2.0866517777084024

Epoch: 105| Step: 0
Training loss: 1.6449871063232422
Validation loss: 2.073698059205086

Epoch: 5| Step: 1
Training loss: 1.8081858158111572
Validation loss: 2.075263028503746

Epoch: 5| Step: 2
Training loss: 2.162595272064209
Validation loss: 2.063735949095859

Epoch: 5| Step: 3
Training loss: 2.0932538509368896
Validation loss: 2.082820823115687

Epoch: 5| Step: 4
Training loss: 1.8405647277832031
Validation loss: 2.0922455864567913

Epoch: 5| Step: 5
Training loss: 2.1516878604888916
Validation loss: 2.091739757086641

Epoch: 5| Step: 6
Training loss: 2.501981019973755
Validation loss: 2.089556191557197

Epoch: 5| Step: 7
Training loss: 1.394273042678833
Validation loss: 2.101611080990043

Epoch: 5| Step: 8
Training loss: 2.3679962158203125
Validation loss: 2.1002468293712986

Epoch: 5| Step: 9
Training loss: 1.7279365062713623
Validation loss: 2.1178159636835896

Epoch: 5| Step: 10
Training loss: 1.787380337715149
Validation loss: 2.1142088623457056

Epoch: 106| Step: 0
Training loss: 1.332208275794983
Validation loss: 2.098381459072072

Epoch: 5| Step: 1
Training loss: 2.318594455718994
Validation loss: 2.084351085847424

Epoch: 5| Step: 2
Training loss: 2.359138011932373
Validation loss: 2.0782981508521625

Epoch: 5| Step: 3
Training loss: 1.907602310180664
Validation loss: 2.085857839994533

Epoch: 5| Step: 4
Training loss: 2.0275115966796875
Validation loss: 2.0786028305689492

Epoch: 5| Step: 5
Training loss: 1.2817213535308838
Validation loss: 2.0690584618558168

Epoch: 5| Step: 6
Training loss: 2.0567727088928223
Validation loss: 2.0668666208944013

Epoch: 5| Step: 7
Training loss: 1.9129714965820312
Validation loss: 2.0850551000205417

Epoch: 5| Step: 8
Training loss: 2.485795021057129
Validation loss: 2.094377084444928

Epoch: 5| Step: 9
Training loss: 1.9652824401855469
Validation loss: 2.087350631272921

Epoch: 5| Step: 10
Training loss: 1.9302235841751099
Validation loss: 2.068491784475183

Epoch: 107| Step: 0
Training loss: 1.8278974294662476
Validation loss: 2.0601945102855725

Epoch: 5| Step: 1
Training loss: 1.882574439048767
Validation loss: 2.071390110959289

Epoch: 5| Step: 2
Training loss: 1.4737387895584106
Validation loss: 2.055646001651723

Epoch: 5| Step: 3
Training loss: 2.216245174407959
Validation loss: 2.045645607415066

Epoch: 5| Step: 4
Training loss: 1.943838357925415
Validation loss: 2.0365222397670952

Epoch: 5| Step: 5
Training loss: 2.0092175006866455
Validation loss: 2.049457811540173

Epoch: 5| Step: 6
Training loss: 2.349050521850586
Validation loss: 2.056724294539421

Epoch: 5| Step: 7
Training loss: 1.6759488582611084
Validation loss: 2.0641276913304485

Epoch: 5| Step: 8
Training loss: 1.9183721542358398
Validation loss: 2.065942023390083

Epoch: 5| Step: 9
Training loss: 1.714146375656128
Validation loss: 2.0689970306170884

Epoch: 5| Step: 10
Training loss: 2.720710277557373
Validation loss: 2.0710696763889764

Epoch: 108| Step: 0
Training loss: 1.9559128284454346
Validation loss: 2.08407619050754

Epoch: 5| Step: 1
Training loss: 1.3798635005950928
Validation loss: 2.1029381034194783

Epoch: 5| Step: 2
Training loss: 1.941241979598999
Validation loss: 2.116901533578032

Epoch: 5| Step: 3
Training loss: 1.9319130182266235
Validation loss: 2.1533616794052945

Epoch: 5| Step: 4
Training loss: 2.287334680557251
Validation loss: 2.1530213150926816

Epoch: 5| Step: 5
Training loss: 1.9253361225128174
Validation loss: 2.1585976449392175

Epoch: 5| Step: 6
Training loss: 1.9145551919937134
Validation loss: 2.174254027746057

Epoch: 5| Step: 7
Training loss: 1.7034027576446533
Validation loss: 2.1516345085636264

Epoch: 5| Step: 8
Training loss: 2.253744125366211
Validation loss: 2.1291056422777075

Epoch: 5| Step: 9
Training loss: 2.483689785003662
Validation loss: 2.096694366906279

Epoch: 5| Step: 10
Training loss: 1.5514674186706543
Validation loss: 2.0596084645999375

Epoch: 109| Step: 0
Training loss: 2.092935085296631
Validation loss: 2.041234882928992

Epoch: 5| Step: 1
Training loss: 1.697186827659607
Validation loss: 2.0195540279470463

Epoch: 5| Step: 2
Training loss: 2.2461228370666504
Validation loss: 2.010630876787247

Epoch: 5| Step: 3
Training loss: 2.293294906616211
Validation loss: 2.013479382761063

Epoch: 5| Step: 4
Training loss: 1.8003482818603516
Validation loss: 2.0522143815153386

Epoch: 5| Step: 5
Training loss: 2.472917079925537
Validation loss: 2.098434084205217

Epoch: 5| Step: 6
Training loss: 2.6027493476867676
Validation loss: 2.1552553343516525

Epoch: 5| Step: 7
Training loss: 1.7405380010604858
Validation loss: 2.1887236692572154

Epoch: 5| Step: 8
Training loss: 1.6352046728134155
Validation loss: 2.1574161052703857

Epoch: 5| Step: 9
Training loss: 1.7053896188735962
Validation loss: 2.131841413436397

Epoch: 5| Step: 10
Training loss: 1.6962592601776123
Validation loss: 2.080592906603249

Epoch: 110| Step: 0
Training loss: 2.0643601417541504
Validation loss: 2.0447035758726058

Epoch: 5| Step: 1
Training loss: 1.7043542861938477
Validation loss: 2.021901730568178

Epoch: 5| Step: 2
Training loss: 1.9378023147583008
Validation loss: 2.060702041913104

Epoch: 5| Step: 3
Training loss: 1.973289132118225
Validation loss: 2.0778385170044436

Epoch: 5| Step: 4
Training loss: 1.7905871868133545
Validation loss: 2.096100737971644

Epoch: 5| Step: 5
Training loss: 1.7745177745819092
Validation loss: 2.0920828350128664

Epoch: 5| Step: 6
Training loss: 2.0201783180236816
Validation loss: 2.0991467557927614

Epoch: 5| Step: 7
Training loss: 1.5927656888961792
Validation loss: 2.094496957717403

Epoch: 5| Step: 8
Training loss: 2.122880458831787
Validation loss: 2.0803778735540246

Epoch: 5| Step: 9
Training loss: 1.9831058979034424
Validation loss: 2.0781966229920745

Epoch: 5| Step: 10
Training loss: 2.4662275314331055
Validation loss: 2.0619857413794405

Epoch: 111| Step: 0
Training loss: 2.1791605949401855
Validation loss: 2.061586554332446

Epoch: 5| Step: 1
Training loss: 1.7056713104248047
Validation loss: 2.046441206368067

Epoch: 5| Step: 2
Training loss: 1.8042818307876587
Validation loss: 2.037507785263882

Epoch: 5| Step: 3
Training loss: 2.528193712234497
Validation loss: 2.0388971028789395

Epoch: 5| Step: 4
Training loss: 2.25085186958313
Validation loss: 2.0460146242572415

Epoch: 5| Step: 5
Training loss: 1.273159384727478
Validation loss: 2.063968978902345

Epoch: 5| Step: 6
Training loss: 1.9598392248153687
Validation loss: 2.068710873203893

Epoch: 5| Step: 7
Training loss: 2.1797447204589844
Validation loss: 2.083728528791858

Epoch: 5| Step: 8
Training loss: 1.5393741130828857
Validation loss: 2.1029350526871218

Epoch: 5| Step: 9
Training loss: 1.9904953241348267
Validation loss: 2.1338289322391635

Epoch: 5| Step: 10
Training loss: 1.9008517265319824
Validation loss: 2.1365030388678274

Epoch: 112| Step: 0
Training loss: 2.0551705360412598
Validation loss: 2.1072470731632684

Epoch: 5| Step: 1
Training loss: 1.3258583545684814
Validation loss: 2.0602499823416434

Epoch: 5| Step: 2
Training loss: 1.356443166732788
Validation loss: 2.0353481487561296

Epoch: 5| Step: 3
Training loss: 1.567160964012146
Validation loss: 2.030887649905297

Epoch: 5| Step: 4
Training loss: 2.3610732555389404
Validation loss: 2.030032180970715

Epoch: 5| Step: 5
Training loss: 2.3618533611297607
Validation loss: 2.0289628018615065

Epoch: 5| Step: 6
Training loss: 1.541307806968689
Validation loss: 2.0405579920737975

Epoch: 5| Step: 7
Training loss: 2.531282663345337
Validation loss: 2.0590174480151107

Epoch: 5| Step: 8
Training loss: 2.0766148567199707
Validation loss: 2.0779037655040784

Epoch: 5| Step: 9
Training loss: 1.936236023902893
Validation loss: 2.0907487510353007

Epoch: 5| Step: 10
Training loss: 1.8298988342285156
Validation loss: 2.085092734265071

Epoch: 113| Step: 0
Training loss: 1.710444688796997
Validation loss: 2.102522532145182

Epoch: 5| Step: 1
Training loss: 1.7172729969024658
Validation loss: 2.1019379272255847

Epoch: 5| Step: 2
Training loss: 1.507102370262146
Validation loss: 2.077482855448159

Epoch: 5| Step: 3
Training loss: 2.5932466983795166
Validation loss: 2.0619293566673034

Epoch: 5| Step: 4
Training loss: 1.616228461265564
Validation loss: 2.0493114981600034

Epoch: 5| Step: 5
Training loss: 1.7592499256134033
Validation loss: 2.0421104456788752

Epoch: 5| Step: 6
Training loss: 1.649397611618042
Validation loss: 2.0321568276292536

Epoch: 5| Step: 7
Training loss: 2.231699228286743
Validation loss: 2.04623411035025

Epoch: 5| Step: 8
Training loss: 2.35280704498291
Validation loss: 2.0441304804176412

Epoch: 5| Step: 9
Training loss: 1.6630346775054932
Validation loss: 2.044351444449476

Epoch: 5| Step: 10
Training loss: 1.7714916467666626
Validation loss: 2.0445384158883044

Epoch: 114| Step: 0
Training loss: 2.4521498680114746
Validation loss: 2.0725090016600904

Epoch: 5| Step: 1
Training loss: 1.8802798986434937
Validation loss: 2.0823836377871934

Epoch: 5| Step: 2
Training loss: 1.5334545373916626
Validation loss: 2.07647672776253

Epoch: 5| Step: 3
Training loss: 1.6901919841766357
Validation loss: 2.0823734178338

Epoch: 5| Step: 4
Training loss: 2.2478129863739014
Validation loss: 2.0685096889413814

Epoch: 5| Step: 5
Training loss: 2.0977885723114014
Validation loss: 2.0484700523396975

Epoch: 5| Step: 6
Training loss: 1.7036645412445068
Validation loss: 2.0284477254395843

Epoch: 5| Step: 7
Training loss: 1.8701575994491577
Validation loss: 2.0238730868985577

Epoch: 5| Step: 8
Training loss: 1.2449109554290771
Validation loss: 2.0200459354667255

Epoch: 5| Step: 9
Training loss: 1.8492801189422607
Validation loss: 2.0189133690249537

Epoch: 5| Step: 10
Training loss: 2.0029702186584473
Validation loss: 2.0359142698267454

Epoch: 115| Step: 0
Training loss: 1.2846378087997437
Validation loss: 2.04619816682672

Epoch: 5| Step: 1
Training loss: 2.2602245807647705
Validation loss: 2.1031685952217347

Epoch: 5| Step: 2
Training loss: 1.8399269580841064
Validation loss: 2.143477903899326

Epoch: 5| Step: 3
Training loss: 1.8795236349105835
Validation loss: 2.1864233157968007

Epoch: 5| Step: 4
Training loss: 2.129443645477295
Validation loss: 2.1997202237447104

Epoch: 5| Step: 5
Training loss: 1.853388786315918
Validation loss: 2.179995488095027

Epoch: 5| Step: 6
Training loss: 1.5901223421096802
Validation loss: 2.1654422718991517

Epoch: 5| Step: 7
Training loss: 2.013032913208008
Validation loss: 2.117433432609804

Epoch: 5| Step: 8
Training loss: 1.9191843271255493
Validation loss: 2.0913351351214993

Epoch: 5| Step: 9
Training loss: 1.6493409872055054
Validation loss: 2.056211834312767

Epoch: 5| Step: 10
Training loss: 2.6730403900146484
Validation loss: 2.0219121556128226

Epoch: 116| Step: 0
Training loss: 1.6977123022079468
Validation loss: 2.006273650353955

Epoch: 5| Step: 1
Training loss: 2.5009002685546875
Validation loss: 2.0120528064748293

Epoch: 5| Step: 2
Training loss: 2.1524417400360107
Validation loss: 2.039562436842149

Epoch: 5| Step: 3
Training loss: 1.9997056722640991
Validation loss: 2.0547892688423075

Epoch: 5| Step: 4
Training loss: 1.7987854480743408
Validation loss: 2.042662189852807

Epoch: 5| Step: 5
Training loss: 1.6063677072525024
Validation loss: 2.03781634248713

Epoch: 5| Step: 6
Training loss: 2.1022696495056152
Validation loss: 2.0389724982682096

Epoch: 5| Step: 7
Training loss: 2.4869332313537598
Validation loss: 2.0421045659690775

Epoch: 5| Step: 8
Training loss: 1.4305683374404907
Validation loss: 2.1098082514219385

Epoch: 5| Step: 9
Training loss: 1.6473138332366943
Validation loss: 2.1422226710986068

Epoch: 5| Step: 10
Training loss: 1.360615849494934
Validation loss: 2.2000095228995047

Epoch: 117| Step: 0
Training loss: 2.0359866619110107
Validation loss: 2.186442341855777

Epoch: 5| Step: 1
Training loss: 2.306913137435913
Validation loss: 2.1776868835572274

Epoch: 5| Step: 2
Training loss: 1.597863793373108
Validation loss: 2.1433410375348982

Epoch: 5| Step: 3
Training loss: 2.2077994346618652
Validation loss: 2.164658315720097

Epoch: 5| Step: 4
Training loss: 2.1792194843292236
Validation loss: 2.1813769545606387

Epoch: 5| Step: 5
Training loss: 1.509850263595581
Validation loss: 2.1807710919328915

Epoch: 5| Step: 6
Training loss: 1.3088597059249878
Validation loss: 2.171271526685325

Epoch: 5| Step: 7
Training loss: 1.936861276626587
Validation loss: 2.11173334429341

Epoch: 5| Step: 8
Training loss: 2.1036875247955322
Validation loss: 2.067552223000475

Epoch: 5| Step: 9
Training loss: 1.9182682037353516
Validation loss: 2.079206828148134

Epoch: 5| Step: 10
Training loss: 1.9383318424224854
Validation loss: 2.070665765834111

Epoch: 118| Step: 0
Training loss: 1.7332866191864014
Validation loss: 2.069083723970639

Epoch: 5| Step: 1
Training loss: 2.213297128677368
Validation loss: 2.066514689435241

Epoch: 5| Step: 2
Training loss: 2.206876039505005
Validation loss: 2.0788016447456936

Epoch: 5| Step: 3
Training loss: 1.7764971256256104
Validation loss: 2.0764995236550607

Epoch: 5| Step: 4
Training loss: 1.874822974205017
Validation loss: 2.0708237489064536

Epoch: 5| Step: 5
Training loss: 1.8948917388916016
Validation loss: 2.06221289660341

Epoch: 5| Step: 6
Training loss: 1.7761156558990479
Validation loss: 2.0574395220766784

Epoch: 5| Step: 7
Training loss: 2.2556674480438232
Validation loss: 2.0752014344738376

Epoch: 5| Step: 8
Training loss: 1.897515892982483
Validation loss: 2.114041179739019

Epoch: 5| Step: 9
Training loss: 1.6605781316757202
Validation loss: 2.120027374195796

Epoch: 5| Step: 10
Training loss: 1.4250982999801636
Validation loss: 2.1607821167156263

Epoch: 119| Step: 0
Training loss: 1.6051037311553955
Validation loss: 2.0982198997210433

Epoch: 5| Step: 1
Training loss: 2.026163339614868
Validation loss: 2.1029486130642634

Epoch: 5| Step: 2
Training loss: 2.138152837753296
Validation loss: 2.1485870063945813

Epoch: 5| Step: 3
Training loss: 2.0796544551849365
Validation loss: 2.1579393340695288

Epoch: 5| Step: 4
Training loss: 1.641299843788147
Validation loss: 2.1781870216451664

Epoch: 5| Step: 5
Training loss: 1.9571529626846313
Validation loss: 2.179462827661986

Epoch: 5| Step: 6
Training loss: 1.5774712562561035
Validation loss: 2.1488561514885194

Epoch: 5| Step: 7
Training loss: 1.682030439376831
Validation loss: 2.0738293611875145

Epoch: 5| Step: 8
Training loss: 1.9280385971069336
Validation loss: 2.0526607715955345

Epoch: 5| Step: 9
Training loss: 2.0002646446228027
Validation loss: 2.068112591261505

Epoch: 5| Step: 10
Training loss: 2.2979674339294434
Validation loss: 2.081353577234412

Epoch: 120| Step: 0
Training loss: 1.8588435649871826
Validation loss: 2.1057261241379606

Epoch: 5| Step: 1
Training loss: 2.0583596229553223
Validation loss: 2.088659868445448

Epoch: 5| Step: 2
Training loss: 1.6490741968154907
Validation loss: 2.0986058994006087

Epoch: 5| Step: 3
Training loss: 2.0571789741516113
Validation loss: 2.083829597760272

Epoch: 5| Step: 4
Training loss: 1.5308574438095093
Validation loss: 2.0879939884267826

Epoch: 5| Step: 5
Training loss: 1.2710285186767578
Validation loss: 2.074210177185715

Epoch: 5| Step: 6
Training loss: 1.917188286781311
Validation loss: 2.08353074648047

Epoch: 5| Step: 7
Training loss: 2.1482555866241455
Validation loss: 2.1114233309222805

Epoch: 5| Step: 8
Training loss: 1.8318240642547607
Validation loss: 2.1435220369728665

Epoch: 5| Step: 9
Training loss: 2.4629273414611816
Validation loss: 2.1636877341936995

Epoch: 5| Step: 10
Training loss: 1.7073887586593628
Validation loss: 2.167701003372028

Epoch: 121| Step: 0
Training loss: 1.6531846523284912
Validation loss: 2.1683983982250257

Epoch: 5| Step: 1
Training loss: 1.5147594213485718
Validation loss: 2.1360344681688535

Epoch: 5| Step: 2
Training loss: 1.2851872444152832
Validation loss: 2.091580225575355

Epoch: 5| Step: 3
Training loss: 1.5658553838729858
Validation loss: 2.091269662303309

Epoch: 5| Step: 4
Training loss: 2.089559555053711
Validation loss: 2.0952477070593063

Epoch: 5| Step: 5
Training loss: 1.6302473545074463
Validation loss: 2.0855231080003964

Epoch: 5| Step: 6
Training loss: 2.173689365386963
Validation loss: 2.081868827983897

Epoch: 5| Step: 7
Training loss: 1.7304792404174805
Validation loss: 2.0582047611154537

Epoch: 5| Step: 8
Training loss: 2.6096200942993164
Validation loss: 2.048796025655603

Epoch: 5| Step: 9
Training loss: 1.9054195880889893
Validation loss: 2.0652787236757177

Epoch: 5| Step: 10
Training loss: 2.4354119300842285
Validation loss: 2.0854893038349767

Epoch: 122| Step: 0
Training loss: 2.1226015090942383
Validation loss: 2.104559733021644

Epoch: 5| Step: 1
Training loss: 1.394789695739746
Validation loss: 2.1087567370424987

Epoch: 5| Step: 2
Training loss: 1.826319932937622
Validation loss: 2.114455869120936

Epoch: 5| Step: 3
Training loss: 2.073981523513794
Validation loss: 2.1218367981654342

Epoch: 5| Step: 4
Training loss: 1.4774912595748901
Validation loss: 2.0927617678078274

Epoch: 5| Step: 5
Training loss: 1.9507042169570923
Validation loss: 2.0570363677958006

Epoch: 5| Step: 6
Training loss: 1.5507924556732178
Validation loss: 2.0468157299103273

Epoch: 5| Step: 7
Training loss: 2.338658332824707
Validation loss: 2.0420529509103424

Epoch: 5| Step: 8
Training loss: 2.240126132965088
Validation loss: 2.059440371810749

Epoch: 5| Step: 9
Training loss: 1.3845545053482056
Validation loss: 2.0673739794761903

Epoch: 5| Step: 10
Training loss: 1.7010939121246338
Validation loss: 2.0750537149367796

Epoch: 123| Step: 0
Training loss: 1.8815839290618896
Validation loss: 2.0863548799227645

Epoch: 5| Step: 1
Training loss: 1.3152015209197998
Validation loss: 2.1254421511004047

Epoch: 5| Step: 2
Training loss: 1.1411139965057373
Validation loss: 2.1345433753023864

Epoch: 5| Step: 3
Training loss: 2.208540439605713
Validation loss: 2.143319567044576

Epoch: 5| Step: 4
Training loss: 1.515826940536499
Validation loss: 2.1564037235834266

Epoch: 5| Step: 5
Training loss: 1.9843467473983765
Validation loss: 2.138018731148012

Epoch: 5| Step: 6
Training loss: 1.2718020677566528
Validation loss: 2.100474287104863

Epoch: 5| Step: 7
Training loss: 2.2351765632629395
Validation loss: 2.104156522340672

Epoch: 5| Step: 8
Training loss: 1.9146945476531982
Validation loss: 2.085000535493256

Epoch: 5| Step: 9
Training loss: 1.909754753112793
Validation loss: 2.069160299916421

Epoch: 5| Step: 10
Training loss: 2.1987087726593018
Validation loss: 2.0605735137898433

Epoch: 124| Step: 0
Training loss: 2.2797188758850098
Validation loss: 2.0379175396375757

Epoch: 5| Step: 1
Training loss: 2.1997194290161133
Validation loss: 2.043922188461468

Epoch: 5| Step: 2
Training loss: 1.6917145252227783
Validation loss: 2.01549127024989

Epoch: 5| Step: 3
Training loss: 1.864792823791504
Validation loss: 2.0319707521828274

Epoch: 5| Step: 4
Training loss: 1.8456385135650635
Validation loss: 2.013718533259566

Epoch: 5| Step: 5
Training loss: 1.5621429681777954
Validation loss: 2.0170454914851854

Epoch: 5| Step: 6
Training loss: 1.8213285207748413
Validation loss: 2.026585663518598

Epoch: 5| Step: 7
Training loss: 1.7993643283843994
Validation loss: 2.031029801214895

Epoch: 5| Step: 8
Training loss: 1.9272491931915283
Validation loss: 2.0602052506580146

Epoch: 5| Step: 9
Training loss: 0.6651548147201538
Validation loss: 2.0760562958255893

Epoch: 5| Step: 10
Training loss: 1.5110639333724976
Validation loss: 2.1140160893881195

Epoch: 125| Step: 0
Training loss: 1.7691013813018799
Validation loss: 2.143587509791056

Epoch: 5| Step: 1
Training loss: 2.1926369667053223
Validation loss: 2.1724702542827976

Epoch: 5| Step: 2
Training loss: 1.4807939529418945
Validation loss: 2.1802542132716023

Epoch: 5| Step: 3
Training loss: 1.659473180770874
Validation loss: 2.14399714111

Epoch: 5| Step: 4
Training loss: 1.553789496421814
Validation loss: 2.127678478917768

Epoch: 5| Step: 5
Training loss: 2.0316498279571533
Validation loss: 2.0915917376036286

Epoch: 5| Step: 6
Training loss: 1.649701714515686
Validation loss: 2.08084616609799

Epoch: 5| Step: 7
Training loss: 2.318430185317993
Validation loss: 2.0604409633144254

Epoch: 5| Step: 8
Training loss: 1.5460087060928345
Validation loss: 2.039212187131246

Epoch: 5| Step: 9
Training loss: 1.5490020513534546
Validation loss: 2.0405676236716648

Epoch: 5| Step: 10
Training loss: 1.4325261116027832
Validation loss: 2.03298089068423

Testing loss: 2.1998613675435386
