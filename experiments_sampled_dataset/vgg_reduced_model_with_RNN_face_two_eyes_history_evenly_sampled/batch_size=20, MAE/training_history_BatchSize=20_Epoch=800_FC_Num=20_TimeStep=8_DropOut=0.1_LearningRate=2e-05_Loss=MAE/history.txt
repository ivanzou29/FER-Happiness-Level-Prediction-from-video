Epoch: 1| Step: 0
Training loss: 4.74199104309082
Validation loss: 5.220109703720257

Epoch: 5| Step: 1
Training loss: 4.584141254425049
Validation loss: 5.202024664930118

Epoch: 5| Step: 2
Training loss: 5.851498603820801
Validation loss: 5.186288546490413

Epoch: 5| Step: 3
Training loss: 4.686002731323242
Validation loss: 5.17144194469657

Epoch: 5| Step: 4
Training loss: 4.114884376525879
Validation loss: 5.154781674826017

Epoch: 5| Step: 5
Training loss: 5.481795310974121
Validation loss: 5.13459437893283

Epoch: 5| Step: 6
Training loss: 4.271682262420654
Validation loss: 5.111094449156074

Epoch: 5| Step: 7
Training loss: 4.936622619628906
Validation loss: 5.083742664706323

Epoch: 5| Step: 8
Training loss: 5.302134037017822
Validation loss: 5.0529275760855725

Epoch: 5| Step: 9
Training loss: 5.176595687866211
Validation loss: 5.017227290779032

Epoch: 5| Step: 10
Training loss: 4.944576263427734
Validation loss: 4.976823160725255

Epoch: 2| Step: 0
Training loss: 4.757028579711914
Validation loss: 4.931782609672957

Epoch: 5| Step: 1
Training loss: 5.375998497009277
Validation loss: 4.883140051236716

Epoch: 5| Step: 2
Training loss: 4.380471229553223
Validation loss: 4.830860419939923

Epoch: 5| Step: 3
Training loss: 4.822742462158203
Validation loss: 4.775156682537448

Epoch: 5| Step: 4
Training loss: 3.911848545074463
Validation loss: 4.717024239160681

Epoch: 5| Step: 5
Training loss: 3.5516579151153564
Validation loss: 4.65719844448951

Epoch: 5| Step: 6
Training loss: 4.314341068267822
Validation loss: 4.59423662513815

Epoch: 5| Step: 7
Training loss: 4.837310791015625
Validation loss: 4.532507352931525

Epoch: 5| Step: 8
Training loss: 5.299991607666016
Validation loss: 4.472986067495039

Epoch: 5| Step: 9
Training loss: 3.364778518676758
Validation loss: 4.41865018106276

Epoch: 5| Step: 10
Training loss: 4.245909214019775
Validation loss: 4.37056839337913

Epoch: 3| Step: 0
Training loss: 4.766655921936035
Validation loss: 4.3275481295841995

Epoch: 5| Step: 1
Training loss: 4.331229209899902
Validation loss: 4.2874285636409635

Epoch: 5| Step: 2
Training loss: 4.131232738494873
Validation loss: 4.2518973709434595

Epoch: 5| Step: 3
Training loss: 4.189808368682861
Validation loss: 4.213231512295303

Epoch: 5| Step: 4
Training loss: 3.0145983695983887
Validation loss: 4.1721990646854525

Epoch: 5| Step: 5
Training loss: 3.480114459991455
Validation loss: 4.130228903985793

Epoch: 5| Step: 6
Training loss: 3.3737690448760986
Validation loss: 4.0960938930511475

Epoch: 5| Step: 7
Training loss: 4.774327278137207
Validation loss: 4.067407310649913

Epoch: 5| Step: 8
Training loss: 3.887892484664917
Validation loss: 4.045321256883683

Epoch: 5| Step: 9
Training loss: 4.870745658874512
Validation loss: 4.027236133493403

Epoch: 5| Step: 10
Training loss: 2.7155649662017822
Validation loss: 4.004210282397526

Epoch: 4| Step: 0
Training loss: 3.3830978870391846
Validation loss: 3.9793695736956853

Epoch: 5| Step: 1
Training loss: 4.2778215408325195
Validation loss: 3.9552105498570267

Epoch: 5| Step: 2
Training loss: 4.543499946594238
Validation loss: 3.9311529462055494

Epoch: 5| Step: 3
Training loss: 3.703273057937622
Validation loss: 3.9021120891776135

Epoch: 5| Step: 4
Training loss: 4.33526086807251
Validation loss: 3.878361666074363

Epoch: 5| Step: 5
Training loss: 3.1630666255950928
Validation loss: 3.857642553185904

Epoch: 5| Step: 6
Training loss: 3.710139036178589
Validation loss: 3.842884971249488

Epoch: 5| Step: 7
Training loss: 4.500472068786621
Validation loss: 3.815300618448565

Epoch: 5| Step: 8
Training loss: 3.881916046142578
Validation loss: 3.789300262287099

Epoch: 5| Step: 9
Training loss: 2.7683732509613037
Validation loss: 3.7773721705200853

Epoch: 5| Step: 10
Training loss: 2.769540548324585
Validation loss: 3.7633025005299556

Epoch: 5| Step: 0
Training loss: 2.763035535812378
Validation loss: 3.7462067245155253

Epoch: 5| Step: 1
Training loss: 3.869335889816284
Validation loss: 3.7343662964400424

Epoch: 5| Step: 2
Training loss: 3.864469528198242
Validation loss: 3.7183899879455566

Epoch: 5| Step: 3
Training loss: 3.7053375244140625
Validation loss: 3.701010811713434

Epoch: 5| Step: 4
Training loss: 3.824779510498047
Validation loss: 3.684718778056483

Epoch: 5| Step: 5
Training loss: 3.0087320804595947
Validation loss: 3.6649263597303823

Epoch: 5| Step: 6
Training loss: 3.960350751876831
Validation loss: 3.6523958072867444

Epoch: 5| Step: 7
Training loss: 3.782081127166748
Validation loss: 3.639657256423786

Epoch: 5| Step: 8
Training loss: 4.494440078735352
Validation loss: 3.627066973716982

Epoch: 5| Step: 9
Training loss: 2.844308376312256
Validation loss: 3.6213515932841966

Epoch: 5| Step: 10
Training loss: 3.1960947513580322
Validation loss: 3.606199220944476

Epoch: 6| Step: 0
Training loss: 3.911479949951172
Validation loss: 3.5943921201972553

Epoch: 5| Step: 1
Training loss: 3.563220977783203
Validation loss: 3.5824838120450258

Epoch: 5| Step: 2
Training loss: 3.919776201248169
Validation loss: 3.5664308276227725

Epoch: 5| Step: 3
Training loss: 3.9461162090301514
Validation loss: 3.5669490701408795

Epoch: 5| Step: 4
Training loss: 3.9361767768859863
Validation loss: 3.550803135800105

Epoch: 5| Step: 5
Training loss: 3.9550278186798096
Validation loss: 3.5453327983938236

Epoch: 5| Step: 6
Training loss: 3.6657721996307373
Validation loss: 3.53931095779583

Epoch: 5| Step: 7
Training loss: 2.8449177742004395
Validation loss: 3.5243388529746764

Epoch: 5| Step: 8
Training loss: 3.745025634765625
Validation loss: 3.505895286478022

Epoch: 5| Step: 9
Training loss: 1.778707504272461
Validation loss: 3.4960261083418325

Epoch: 5| Step: 10
Training loss: 2.873938798904419
Validation loss: 3.491596180905578

Epoch: 7| Step: 0
Training loss: 3.205395460128784
Validation loss: 3.4842767048907537

Epoch: 5| Step: 1
Training loss: 3.5662918090820312
Validation loss: 3.4817370599316013

Epoch: 5| Step: 2
Training loss: 3.059642791748047
Validation loss: 3.470994916013492

Epoch: 5| Step: 3
Training loss: 3.1613950729370117
Validation loss: 3.455761117319907

Epoch: 5| Step: 4
Training loss: 3.860858917236328
Validation loss: 3.439538571142381

Epoch: 5| Step: 5
Training loss: 2.9585492610931396
Validation loss: 3.427019291026618

Epoch: 5| Step: 6
Training loss: 3.880385637283325
Validation loss: 3.4166293221135295

Epoch: 5| Step: 7
Training loss: 2.630951404571533
Validation loss: 3.4082373572934057

Epoch: 5| Step: 8
Training loss: 3.858966112136841
Validation loss: 3.399186511193552

Epoch: 5| Step: 9
Training loss: 3.7933998107910156
Validation loss: 3.388420904836347

Epoch: 5| Step: 10
Training loss: 3.0848727226257324
Validation loss: 3.376928690941103

Epoch: 8| Step: 0
Training loss: 2.579662322998047
Validation loss: 3.3662709907818864

Epoch: 5| Step: 1
Training loss: 3.0062191486358643
Validation loss: 3.3545990015870784

Epoch: 5| Step: 2
Training loss: 3.9687271118164062
Validation loss: 3.34905977659328

Epoch: 5| Step: 3
Training loss: 3.3229897022247314
Validation loss: 3.327917186162805

Epoch: 5| Step: 4
Training loss: 3.3894591331481934
Validation loss: 3.327891698447607

Epoch: 5| Step: 5
Training loss: 2.64680814743042
Validation loss: 3.3398322187444216

Epoch: 5| Step: 6
Training loss: 4.019761085510254
Validation loss: 3.332966578904019

Epoch: 5| Step: 7
Training loss: 3.6545214653015137
Validation loss: 3.3342625043725453

Epoch: 5| Step: 8
Training loss: 3.356133222579956
Validation loss: 3.2970588027790027

Epoch: 5| Step: 9
Training loss: 3.02838134765625
Validation loss: 3.275430181975006

Epoch: 5| Step: 10
Training loss: 3.250004529953003
Validation loss: 3.2741746646101757

Epoch: 9| Step: 0
Training loss: 2.7715587615966797
Validation loss: 3.2741725521702922

Epoch: 5| Step: 1
Training loss: 3.100665330886841
Validation loss: 3.2583121766326246

Epoch: 5| Step: 2
Training loss: 3.052760601043701
Validation loss: 3.2437444963762836

Epoch: 5| Step: 3
Training loss: 3.7295260429382324
Validation loss: 3.237552604367656

Epoch: 5| Step: 4
Training loss: 3.7897422313690186
Validation loss: 3.2275755789972123

Epoch: 5| Step: 5
Training loss: 2.897737503051758
Validation loss: 3.217609408081219

Epoch: 5| Step: 6
Training loss: 3.320827007293701
Validation loss: 3.2091901045973583

Epoch: 5| Step: 7
Training loss: 3.1736083030700684
Validation loss: 3.205022470925444

Epoch: 5| Step: 8
Training loss: 2.7470555305480957
Validation loss: 3.192637587106356

Epoch: 5| Step: 9
Training loss: 3.3104987144470215
Validation loss: 3.1743395072157665

Epoch: 5| Step: 10
Training loss: 3.424844980239868
Validation loss: 3.1693159662267214

Epoch: 10| Step: 0
Training loss: 3.0617594718933105
Validation loss: 3.1677256758495043

Epoch: 5| Step: 1
Training loss: 2.3067898750305176
Validation loss: 3.146576812190394

Epoch: 5| Step: 2
Training loss: 3.231602430343628
Validation loss: 3.1773172040139475

Epoch: 5| Step: 3
Training loss: 4.09178352355957
Validation loss: 3.1373468291374946

Epoch: 5| Step: 4
Training loss: 2.9574687480926514
Validation loss: 3.134714280405352

Epoch: 5| Step: 5
Training loss: 3.1759543418884277
Validation loss: 3.1455072510627007

Epoch: 5| Step: 6
Training loss: 3.982862949371338
Validation loss: 3.1246970648406656

Epoch: 5| Step: 7
Training loss: 2.569627046585083
Validation loss: 3.121776565428703

Epoch: 5| Step: 8
Training loss: 3.103325843811035
Validation loss: 3.112056291231545

Epoch: 5| Step: 9
Training loss: 2.872079610824585
Validation loss: 3.1229259352530203

Epoch: 5| Step: 10
Training loss: 3.457686185836792
Validation loss: 3.1251753991649998

Epoch: 11| Step: 0
Training loss: 2.863654136657715
Validation loss: 3.095491752829603

Epoch: 5| Step: 1
Training loss: 3.906930446624756
Validation loss: 3.1020515811058784

Epoch: 5| Step: 2
Training loss: 2.560910701751709
Validation loss: 3.162549795642976

Epoch: 5| Step: 3
Training loss: 2.692519426345825
Validation loss: 3.088221670478903

Epoch: 5| Step: 4
Training loss: 3.5567221641540527
Validation loss: 3.087844628159718

Epoch: 5| Step: 5
Training loss: 2.53312349319458
Validation loss: 3.1033098825844387

Epoch: 5| Step: 6
Training loss: 2.784299850463867
Validation loss: 3.1783725138633483

Epoch: 5| Step: 7
Training loss: 3.6226820945739746
Validation loss: 3.0940571959300707

Epoch: 5| Step: 8
Training loss: 2.9170708656311035
Validation loss: 3.0686966398710847

Epoch: 5| Step: 9
Training loss: 3.46417498588562
Validation loss: 3.0648066433527137

Epoch: 5| Step: 10
Training loss: 3.5448949337005615
Validation loss: 3.067351056683448

Epoch: 12| Step: 0
Training loss: 2.8393397331237793
Validation loss: 3.0702953261713826

Epoch: 5| Step: 1
Training loss: 3.2473435401916504
Validation loss: 3.0572173544155654

Epoch: 5| Step: 2
Training loss: 3.0746166706085205
Validation loss: 3.0484756141580562

Epoch: 5| Step: 3
Training loss: 3.226102828979492
Validation loss: 3.042412850164598

Epoch: 5| Step: 4
Training loss: 3.5150623321533203
Validation loss: 3.0343588295803277

Epoch: 5| Step: 5
Training loss: 2.9605250358581543
Validation loss: 3.0282777791382163

Epoch: 5| Step: 6
Training loss: 2.4968671798706055
Validation loss: 3.0191116615008284

Epoch: 5| Step: 7
Training loss: 3.3235039710998535
Validation loss: 3.018352593145063

Epoch: 5| Step: 8
Training loss: 2.7928130626678467
Validation loss: 3.013253791357881

Epoch: 5| Step: 9
Training loss: 3.5988287925720215
Validation loss: 3.006883772470618

Epoch: 5| Step: 10
Training loss: 2.804666757583618
Validation loss: 3.0054800510406494

Epoch: 13| Step: 0
Training loss: 2.982311964035034
Validation loss: 2.9968869609217488

Epoch: 5| Step: 1
Training loss: 2.5927913188934326
Validation loss: 2.9879435493100073

Epoch: 5| Step: 2
Training loss: 3.459939956665039
Validation loss: 2.9801091404371363

Epoch: 5| Step: 3
Training loss: 3.188734769821167
Validation loss: 2.9883686188728578

Epoch: 5| Step: 4
Training loss: 2.413830041885376
Validation loss: 2.983844067460747

Epoch: 5| Step: 5
Training loss: 3.163928985595703
Validation loss: 2.9733158311536236

Epoch: 5| Step: 6
Training loss: 2.7908973693847656
Validation loss: 2.9647110354515815

Epoch: 5| Step: 7
Training loss: 3.321962356567383
Validation loss: 2.959686497206329

Epoch: 5| Step: 8
Training loss: 3.690225124359131
Validation loss: 2.956606839292793

Epoch: 5| Step: 9
Training loss: 2.758821487426758
Validation loss: 2.953167159070251

Epoch: 5| Step: 10
Training loss: 3.1192851066589355
Validation loss: 2.9495657003054054

Epoch: 14| Step: 0
Training loss: 2.8249497413635254
Validation loss: 2.9416166120959866

Epoch: 5| Step: 1
Training loss: 2.5648162364959717
Validation loss: 2.9369651963633876

Epoch: 5| Step: 2
Training loss: 2.978628635406494
Validation loss: 2.9328414137645433

Epoch: 5| Step: 3
Training loss: 3.6950161457061768
Validation loss: 2.9322578855740127

Epoch: 5| Step: 4
Training loss: 3.6712241172790527
Validation loss: 2.9257723926216044

Epoch: 5| Step: 5
Training loss: 3.272744655609131
Validation loss: 2.9223093473783104

Epoch: 5| Step: 6
Training loss: 2.3596138954162598
Validation loss: 2.9165962639675347

Epoch: 5| Step: 7
Training loss: 3.05682635307312
Validation loss: 2.9148418852078017

Epoch: 5| Step: 8
Training loss: 3.0112199783325195
Validation loss: 2.912743027492236

Epoch: 5| Step: 9
Training loss: 2.7745614051818848
Validation loss: 2.909016296427737

Epoch: 5| Step: 10
Training loss: 2.939082622528076
Validation loss: 2.902805894933721

Epoch: 15| Step: 0
Training loss: 2.7440123558044434
Validation loss: 2.90089984350307

Epoch: 5| Step: 1
Training loss: 2.7685632705688477
Validation loss: 2.8960860442089778

Epoch: 5| Step: 2
Training loss: 3.064311981201172
Validation loss: 2.8929667549748577

Epoch: 5| Step: 3
Training loss: 3.4271202087402344
Validation loss: 2.8917735879139235

Epoch: 5| Step: 4
Training loss: 2.1839489936828613
Validation loss: 2.8881296188600603

Epoch: 5| Step: 5
Training loss: 2.9616236686706543
Validation loss: 2.8838110739184963

Epoch: 5| Step: 6
Training loss: 1.9758102893829346
Validation loss: 2.8810574059845298

Epoch: 5| Step: 7
Training loss: 3.532031297683716
Validation loss: 2.8838901391593357

Epoch: 5| Step: 8
Training loss: 3.497544527053833
Validation loss: 2.8972551309934227

Epoch: 5| Step: 9
Training loss: 3.2395317554473877
Validation loss: 2.888021453734367

Epoch: 5| Step: 10
Training loss: 3.588547945022583
Validation loss: 2.869688956968246

Epoch: 16| Step: 0
Training loss: 2.856738567352295
Validation loss: 2.864661068044683

Epoch: 5| Step: 1
Training loss: 3.4968390464782715
Validation loss: 2.8641067269027873

Epoch: 5| Step: 2
Training loss: 3.077302932739258
Validation loss: 2.8623952865600586

Epoch: 5| Step: 3
Training loss: 3.0993597507476807
Validation loss: 2.859472051743538

Epoch: 5| Step: 4
Training loss: 2.8752450942993164
Validation loss: 2.856440282637073

Epoch: 5| Step: 5
Training loss: 3.0157735347747803
Validation loss: 2.8551128192614486

Epoch: 5| Step: 6
Training loss: 2.8811252117156982
Validation loss: 2.8508310292356756

Epoch: 5| Step: 7
Training loss: 3.444955348968506
Validation loss: 2.852289620266166

Epoch: 5| Step: 8
Training loss: 2.6549859046936035
Validation loss: 2.8458652393792265

Epoch: 5| Step: 9
Training loss: 2.4541079998016357
Validation loss: 2.8504374668162358

Epoch: 5| Step: 10
Training loss: 2.7594738006591797
Validation loss: 2.8465712249919934

Epoch: 17| Step: 0
Training loss: 2.7496273517608643
Validation loss: 2.8365441419745006

Epoch: 5| Step: 1
Training loss: 3.5876572132110596
Validation loss: 2.8359712836562947

Epoch: 5| Step: 2
Training loss: 2.975637674331665
Validation loss: 2.822749109678371

Epoch: 5| Step: 3
Training loss: 3.0403075218200684
Validation loss: 2.816370940977527

Epoch: 5| Step: 4
Training loss: 3.3176047801971436
Validation loss: 2.8145585162665254

Epoch: 5| Step: 5
Training loss: 2.970767021179199
Validation loss: 2.818808824785294

Epoch: 5| Step: 6
Training loss: 3.3816936016082764
Validation loss: 2.8192551571835756

Epoch: 5| Step: 7
Training loss: 2.6124281883239746
Validation loss: 2.8127353473376204

Epoch: 5| Step: 8
Training loss: 2.8678226470947266
Validation loss: 2.8060248872285247

Epoch: 5| Step: 9
Training loss: 2.3708386421203613
Validation loss: 2.796000767779607

Epoch: 5| Step: 10
Training loss: 2.399035930633545
Validation loss: 2.7857430647778254

Epoch: 18| Step: 0
Training loss: 3.2043204307556152
Validation loss: 2.786160825401224

Epoch: 5| Step: 1
Training loss: 2.9033432006835938
Validation loss: 2.781182163505144

Epoch: 5| Step: 2
Training loss: 1.9189128875732422
Validation loss: 2.8050142770172446

Epoch: 5| Step: 3
Training loss: 3.063185214996338
Validation loss: 2.8014109109037664

Epoch: 5| Step: 4
Training loss: 2.982649803161621
Validation loss: 2.768628528041224

Epoch: 5| Step: 5
Training loss: 3.192148208618164
Validation loss: 2.766810119792979

Epoch: 5| Step: 6
Training loss: 3.6183624267578125
Validation loss: 2.762732357107183

Epoch: 5| Step: 7
Training loss: 3.243999481201172
Validation loss: 2.759920456076181

Epoch: 5| Step: 8
Training loss: 2.61194109916687
Validation loss: 2.7585712504643265

Epoch: 5| Step: 9
Training loss: 2.806021213531494
Validation loss: 2.758822892301826

Epoch: 5| Step: 10
Training loss: 2.415778636932373
Validation loss: 2.756587838613859

Epoch: 19| Step: 0
Training loss: 2.8746750354766846
Validation loss: 2.7606023742306616

Epoch: 5| Step: 1
Training loss: 2.8456966876983643
Validation loss: 2.7784273368056103

Epoch: 5| Step: 2
Training loss: 3.197432279586792
Validation loss: 2.7636755563879527

Epoch: 5| Step: 3
Training loss: 2.619596242904663
Validation loss: 2.7583997018875612

Epoch: 5| Step: 4
Training loss: 2.9144272804260254
Validation loss: 2.749915087094871

Epoch: 5| Step: 5
Training loss: 2.1785056591033936
Validation loss: 2.7363193496581046

Epoch: 5| Step: 6
Training loss: 2.3017873764038086
Validation loss: 2.7371709218589206

Epoch: 5| Step: 7
Training loss: 3.2920658588409424
Validation loss: 2.735450683101531

Epoch: 5| Step: 8
Training loss: 2.9748823642730713
Validation loss: 2.735508067633516

Epoch: 5| Step: 9
Training loss: 3.7031943798065186
Validation loss: 2.7357635472410466

Epoch: 5| Step: 10
Training loss: 3.019301414489746
Validation loss: 2.7345796156955022

Epoch: 20| Step: 0
Training loss: 2.358933210372925
Validation loss: 2.7337307083991265

Epoch: 5| Step: 1
Training loss: 3.0695362091064453
Validation loss: 2.735529638105823

Epoch: 5| Step: 2
Training loss: 3.0124611854553223
Validation loss: 2.735035768119238

Epoch: 5| Step: 3
Training loss: 3.814606189727783
Validation loss: 2.7300815325911327

Epoch: 5| Step: 4
Training loss: 3.148794412612915
Validation loss: 2.7234369580463698

Epoch: 5| Step: 5
Training loss: 3.1280620098114014
Validation loss: 2.7193642944417973

Epoch: 5| Step: 6
Training loss: 2.764225721359253
Validation loss: 2.7118189770688295

Epoch: 5| Step: 7
Training loss: 2.6426639556884766
Validation loss: 2.7179347699688328

Epoch: 5| Step: 8
Training loss: 2.444298267364502
Validation loss: 2.7126785273193033

Epoch: 5| Step: 9
Training loss: 2.824568510055542
Validation loss: 2.707810781335318

Epoch: 5| Step: 10
Training loss: 2.4954919815063477
Validation loss: 2.7012811912003385

Epoch: 21| Step: 0
Training loss: 2.268321990966797
Validation loss: 2.704808173641082

Epoch: 5| Step: 1
Training loss: 2.773388385772705
Validation loss: 2.7038971839412564

Epoch: 5| Step: 2
Training loss: 2.9817540645599365
Validation loss: 2.7029883169358775

Epoch: 5| Step: 3
Training loss: 2.405245065689087
Validation loss: 2.7026708843887493

Epoch: 5| Step: 4
Training loss: 3.6394240856170654
Validation loss: 2.6939535653719338

Epoch: 5| Step: 5
Training loss: 2.4300358295440674
Validation loss: 2.6937822629046697

Epoch: 5| Step: 6
Training loss: 2.71246600151062
Validation loss: 2.690089107841574

Epoch: 5| Step: 7
Training loss: 3.567286252975464
Validation loss: 2.693843477515764

Epoch: 5| Step: 8
Training loss: 3.3000316619873047
Validation loss: 2.688448149670837

Epoch: 5| Step: 9
Training loss: 2.4543309211730957
Validation loss: 2.680799115088678

Epoch: 5| Step: 10
Training loss: 2.996354341506958
Validation loss: 2.6828469922465663

Epoch: 22| Step: 0
Training loss: 3.6344475746154785
Validation loss: 2.6777534561772502

Epoch: 5| Step: 1
Training loss: 2.897043228149414
Validation loss: 2.678008553802326

Epoch: 5| Step: 2
Training loss: 2.8081612586975098
Validation loss: 2.6806029735072965

Epoch: 5| Step: 3
Training loss: 3.2295773029327393
Validation loss: 2.6756013849730134

Epoch: 5| Step: 4
Training loss: 2.6062397956848145
Validation loss: 2.6767360523182857

Epoch: 5| Step: 5
Training loss: 2.9817795753479004
Validation loss: 2.6689484606507006

Epoch: 5| Step: 6
Training loss: 2.7549915313720703
Validation loss: 2.666026084653793

Epoch: 5| Step: 7
Training loss: 2.463714122772217
Validation loss: 2.661617999435753

Epoch: 5| Step: 8
Training loss: 2.4859721660614014
Validation loss: 2.6806189167884087

Epoch: 5| Step: 9
Training loss: 2.7508480548858643
Validation loss: 2.7386539341301046

Epoch: 5| Step: 10
Training loss: 2.753661870956421
Validation loss: 2.732679308101695

Epoch: 23| Step: 0
Training loss: 2.8827271461486816
Validation loss: 2.7282160943554294

Epoch: 5| Step: 1
Training loss: 2.9905571937561035
Validation loss: 2.7192482563757125

Epoch: 5| Step: 2
Training loss: 2.5783534049987793
Validation loss: 2.7116999728705293

Epoch: 5| Step: 3
Training loss: 2.737778663635254
Validation loss: 2.6809657799300326

Epoch: 5| Step: 4
Training loss: 3.467503309249878
Validation loss: 2.672945737838745

Epoch: 5| Step: 5
Training loss: 2.3486735820770264
Validation loss: 2.6552908241107898

Epoch: 5| Step: 6
Training loss: 2.597622871398926
Validation loss: 2.6476812747216996

Epoch: 5| Step: 7
Training loss: 3.4699928760528564
Validation loss: 2.6495670272457983

Epoch: 5| Step: 8
Training loss: 2.7862863540649414
Validation loss: 2.657401910392187

Epoch: 5| Step: 9
Training loss: 2.339296340942383
Validation loss: 2.6540036098931425

Epoch: 5| Step: 10
Training loss: 3.134042739868164
Validation loss: 2.650328684878606

Epoch: 24| Step: 0
Training loss: 2.800748586654663
Validation loss: 2.6725745534384124

Epoch: 5| Step: 1
Training loss: 3.144275426864624
Validation loss: 2.6635834452926472

Epoch: 5| Step: 2
Training loss: 2.0681850910186768
Validation loss: 2.6636851474802983

Epoch: 5| Step: 3
Training loss: 2.6862499713897705
Validation loss: 2.6584134050594863

Epoch: 5| Step: 4
Training loss: 3.2042884826660156
Validation loss: 2.646395739688668

Epoch: 5| Step: 5
Training loss: 2.9735147953033447
Validation loss: 2.6590712737011653

Epoch: 5| Step: 6
Training loss: 2.9191787242889404
Validation loss: 2.654589427414761

Epoch: 5| Step: 7
Training loss: 2.6380975246429443
Validation loss: 2.640186050886749

Epoch: 5| Step: 8
Training loss: 3.1458065509796143
Validation loss: 2.635069303615119

Epoch: 5| Step: 9
Training loss: 3.138126850128174
Validation loss: 2.639766785406297

Epoch: 5| Step: 10
Training loss: 2.3510239124298096
Validation loss: 2.6690747225156395

Epoch: 25| Step: 0
Training loss: 3.0618643760681152
Validation loss: 2.768281131662348

Epoch: 5| Step: 1
Training loss: 2.842163562774658
Validation loss: 2.6817570527394614

Epoch: 5| Step: 2
Training loss: 2.6489086151123047
Validation loss: 2.6506713615950717

Epoch: 5| Step: 3
Training loss: 2.5839569568634033
Validation loss: 2.6255739427381948

Epoch: 5| Step: 4
Training loss: 3.1862683296203613
Validation loss: 2.6120456213592202

Epoch: 5| Step: 5
Training loss: 2.6890645027160645
Validation loss: 2.6265621210939143

Epoch: 5| Step: 6
Training loss: 2.843456268310547
Validation loss: 2.659189929244339

Epoch: 5| Step: 7
Training loss: 3.0977749824523926
Validation loss: 2.646911113492904

Epoch: 5| Step: 8
Training loss: 2.753653049468994
Validation loss: 2.6159552810012654

Epoch: 5| Step: 9
Training loss: 3.026668071746826
Validation loss: 2.6077889678298787

Epoch: 5| Step: 10
Training loss: 2.263798952102661
Validation loss: 2.6374067337282243

Epoch: 26| Step: 0
Training loss: 2.538759708404541
Validation loss: 2.678065235896777

Epoch: 5| Step: 1
Training loss: 2.718129873275757
Validation loss: 2.7020839465561735

Epoch: 5| Step: 2
Training loss: 2.9196150302886963
Validation loss: 2.6530022903155257

Epoch: 5| Step: 3
Training loss: 2.4215452671051025
Validation loss: 2.6137903480119604

Epoch: 5| Step: 4
Training loss: 2.425760269165039
Validation loss: 2.605280089121993

Epoch: 5| Step: 5
Training loss: 3.21916127204895
Validation loss: 2.6033616476161505

Epoch: 5| Step: 6
Training loss: 2.9905598163604736
Validation loss: 2.602569164768342

Epoch: 5| Step: 7
Training loss: 2.5448288917541504
Validation loss: 2.611448162345476

Epoch: 5| Step: 8
Training loss: 3.2210497856140137
Validation loss: 2.603497528260754

Epoch: 5| Step: 9
Training loss: 2.993490219116211
Validation loss: 2.6007075617390294

Epoch: 5| Step: 10
Training loss: 2.7331178188323975
Validation loss: 2.582771824252221

Epoch: 27| Step: 0
Training loss: 2.640587329864502
Validation loss: 2.57392196501455

Epoch: 5| Step: 1
Training loss: 2.542917013168335
Validation loss: 2.5809102212229083

Epoch: 5| Step: 2
Training loss: 3.1712582111358643
Validation loss: 2.5925777932649017

Epoch: 5| Step: 3
Training loss: 2.7942612171173096
Validation loss: 2.5699133565348964

Epoch: 5| Step: 4
Training loss: 2.687494993209839
Validation loss: 2.565297608734459

Epoch: 5| Step: 5
Training loss: 2.0955262184143066
Validation loss: 2.5570588086241033

Epoch: 5| Step: 6
Training loss: 2.631735324859619
Validation loss: 2.5616223863376084

Epoch: 5| Step: 7
Training loss: 3.1480157375335693
Validation loss: 2.5540810605531097

Epoch: 5| Step: 8
Training loss: 2.720499038696289
Validation loss: 2.547038737163749

Epoch: 5| Step: 9
Training loss: 2.863130569458008
Validation loss: 2.554223886100195

Epoch: 5| Step: 10
Training loss: 3.1470088958740234
Validation loss: 2.547493016848

Epoch: 28| Step: 0
Training loss: 3.660041093826294
Validation loss: 2.54587875130356

Epoch: 5| Step: 1
Training loss: 2.8198885917663574
Validation loss: 2.538544054954283

Epoch: 5| Step: 2
Training loss: 2.122614622116089
Validation loss: 2.5345122557814403

Epoch: 5| Step: 3
Training loss: 3.2490952014923096
Validation loss: 2.5279694526426253

Epoch: 5| Step: 4
Training loss: 2.6820194721221924
Validation loss: 2.522432324706867

Epoch: 5| Step: 5
Training loss: 2.835167407989502
Validation loss: 2.5156642903563795

Epoch: 5| Step: 6
Training loss: 2.0269546508789062
Validation loss: 2.528818997003699

Epoch: 5| Step: 7
Training loss: 2.4248015880584717
Validation loss: 2.5717537531288723

Epoch: 5| Step: 8
Training loss: 2.904376983642578
Validation loss: 2.6095139339406

Epoch: 5| Step: 9
Training loss: 2.892056941986084
Validation loss: 2.603121631888933

Epoch: 5| Step: 10
Training loss: 2.7459263801574707
Validation loss: 2.511925715272145

Epoch: 29| Step: 0
Training loss: 2.7932522296905518
Validation loss: 2.5195992505678566

Epoch: 5| Step: 1
Training loss: 3.254289150238037
Validation loss: 2.589718846864598

Epoch: 5| Step: 2
Training loss: 2.772334337234497
Validation loss: 2.622461744534072

Epoch: 5| Step: 3
Training loss: 3.77726674079895
Validation loss: 2.5848914730933403

Epoch: 5| Step: 4
Training loss: 2.611236333847046
Validation loss: 2.517910188244235

Epoch: 5| Step: 5
Training loss: 1.9414430856704712
Validation loss: 2.5078955696475123

Epoch: 5| Step: 6
Training loss: 2.648392677307129
Validation loss: 2.503730573961812

Epoch: 5| Step: 7
Training loss: 2.356677293777466
Validation loss: 2.5122060134846675

Epoch: 5| Step: 8
Training loss: 3.120478630065918
Validation loss: 2.5666497394602787

Epoch: 5| Step: 9
Training loss: 2.2147927284240723
Validation loss: 2.593317036987633

Epoch: 5| Step: 10
Training loss: 2.9791150093078613
Validation loss: 2.5791318288413425

Epoch: 30| Step: 0
Training loss: 2.3574843406677246
Validation loss: 2.5341172987414944

Epoch: 5| Step: 1
Training loss: 2.553004026412964
Validation loss: 2.518509000860235

Epoch: 5| Step: 2
Training loss: 2.6280150413513184
Validation loss: 2.4979452945852794

Epoch: 5| Step: 3
Training loss: 2.5785250663757324
Validation loss: 2.4903956382505354

Epoch: 5| Step: 4
Training loss: 2.2187552452087402
Validation loss: 2.4863370182693645

Epoch: 5| Step: 5
Training loss: 2.9134461879730225
Validation loss: 2.483275482731481

Epoch: 5| Step: 6
Training loss: 3.449538469314575
Validation loss: 2.4833014011383057

Epoch: 5| Step: 7
Training loss: 2.3905181884765625
Validation loss: 2.4807118318414174

Epoch: 5| Step: 8
Training loss: 3.2659740447998047
Validation loss: 2.4824566418124783

Epoch: 5| Step: 9
Training loss: 2.4278221130371094
Validation loss: 2.484223768275271

Epoch: 5| Step: 10
Training loss: 3.0420939922332764
Validation loss: 2.4825437453485306

Epoch: 31| Step: 0
Training loss: 2.9597859382629395
Validation loss: 2.4819412436536563

Epoch: 5| Step: 1
Training loss: 2.06498122215271
Validation loss: 2.4745413718685025

Epoch: 5| Step: 2
Training loss: 2.2520833015441895
Validation loss: 2.4748772087917534

Epoch: 5| Step: 3
Training loss: 2.771404981613159
Validation loss: 2.4836618951571885

Epoch: 5| Step: 4
Training loss: 3.4761428833007812
Validation loss: 2.462051614638298

Epoch: 5| Step: 5
Training loss: 2.7069125175476074
Validation loss: 2.4638718481986754

Epoch: 5| Step: 6
Training loss: 3.0898163318634033
Validation loss: 2.451387902741791

Epoch: 5| Step: 7
Training loss: 1.9112160205841064
Validation loss: 2.452452277624479

Epoch: 5| Step: 8
Training loss: 2.571063280105591
Validation loss: 2.4586078633544264

Epoch: 5| Step: 9
Training loss: 2.6648330688476562
Validation loss: 2.4552463100802515

Epoch: 5| Step: 10
Training loss: 3.213179349899292
Validation loss: 2.4520731510654574

Epoch: 32| Step: 0
Training loss: 3.2365620136260986
Validation loss: 2.46262873372724

Epoch: 5| Step: 1
Training loss: 2.283475875854492
Validation loss: 2.4687419668320687

Epoch: 5| Step: 2
Training loss: 3.0705394744873047
Validation loss: 2.4932413819015666

Epoch: 5| Step: 3
Training loss: 2.6153690814971924
Validation loss: 2.5194332010002545

Epoch: 5| Step: 4
Training loss: 2.5114967823028564
Validation loss: 2.533533368059384

Epoch: 5| Step: 5
Training loss: 2.634040117263794
Validation loss: 2.49786530258835

Epoch: 5| Step: 6
Training loss: 2.536816120147705
Validation loss: 2.472910478550901

Epoch: 5| Step: 7
Training loss: 2.8842976093292236
Validation loss: 2.470983212993991

Epoch: 5| Step: 8
Training loss: 2.441399335861206
Validation loss: 2.469270829231508

Epoch: 5| Step: 9
Training loss: 2.4886443614959717
Validation loss: 2.4691374686456498

Epoch: 5| Step: 10
Training loss: 2.9639484882354736
Validation loss: 2.463162342707316

Epoch: 33| Step: 0
Training loss: 3.0395333766937256
Validation loss: 2.4519769837779384

Epoch: 5| Step: 1
Training loss: 3.086355209350586
Validation loss: 2.4452407795895814

Epoch: 5| Step: 2
Training loss: 2.9726157188415527
Validation loss: 2.4410880047787904

Epoch: 5| Step: 3
Training loss: 3.059382200241089
Validation loss: 2.447166112161452

Epoch: 5| Step: 4
Training loss: 2.6019692420959473
Validation loss: 2.452084756666614

Epoch: 5| Step: 5
Training loss: 2.1910319328308105
Validation loss: 2.4732100066318305

Epoch: 5| Step: 6
Training loss: 2.6687746047973633
Validation loss: 2.4765791431550057

Epoch: 5| Step: 7
Training loss: 2.2407593727111816
Validation loss: 2.466203902357368

Epoch: 5| Step: 8
Training loss: 2.611701250076294
Validation loss: 2.4790915494324057

Epoch: 5| Step: 9
Training loss: 2.8099687099456787
Validation loss: 2.4672755579794607

Epoch: 5| Step: 10
Training loss: 2.0406317710876465
Validation loss: 2.4424666127850934

Epoch: 34| Step: 0
Training loss: 2.234952211380005
Validation loss: 2.4331625558996715

Epoch: 5| Step: 1
Training loss: 3.3591270446777344
Validation loss: 2.4431864369300103

Epoch: 5| Step: 2
Training loss: 3.108604669570923
Validation loss: 2.4562574484015025

Epoch: 5| Step: 3
Training loss: 2.925507068634033
Validation loss: 2.4574648077769945

Epoch: 5| Step: 4
Training loss: 2.4969048500061035
Validation loss: 2.454564958490351

Epoch: 5| Step: 5
Training loss: 2.6252877712249756
Validation loss: 2.4539803817708004

Epoch: 5| Step: 6
Training loss: 3.2451553344726562
Validation loss: 2.4353568220651276

Epoch: 5| Step: 7
Training loss: 2.4841325283050537
Validation loss: 2.429040780631445

Epoch: 5| Step: 8
Training loss: 1.9773883819580078
Validation loss: 2.4419775060428086

Epoch: 5| Step: 9
Training loss: 2.681467056274414
Validation loss: 2.4951870877255677

Epoch: 5| Step: 10
Training loss: 2.397920608520508
Validation loss: 2.530414504389609

Epoch: 35| Step: 0
Training loss: 2.804938554763794
Validation loss: 2.5843456688747612

Epoch: 5| Step: 1
Training loss: 2.4424099922180176
Validation loss: 2.531524286475233

Epoch: 5| Step: 2
Training loss: 2.4360244274139404
Validation loss: 2.474529307375672

Epoch: 5| Step: 3
Training loss: 2.2238802909851074
Validation loss: 2.455684974629392

Epoch: 5| Step: 4
Training loss: 2.642301082611084
Validation loss: 2.455246727953675

Epoch: 5| Step: 5
Training loss: 3.236264705657959
Validation loss: 2.4448732278680287

Epoch: 5| Step: 6
Training loss: 3.1519839763641357
Validation loss: 2.4304181580902426

Epoch: 5| Step: 7
Training loss: 2.0006489753723145
Validation loss: 2.4200085875808552

Epoch: 5| Step: 8
Training loss: 2.4647560119628906
Validation loss: 2.4184127392307406

Epoch: 5| Step: 9
Training loss: 3.444225788116455
Validation loss: 2.42150293883457

Epoch: 5| Step: 10
Training loss: 2.5289859771728516
Validation loss: 2.4259920068966445

Epoch: 36| Step: 0
Training loss: 2.9589526653289795
Validation loss: 2.426693393338111

Epoch: 5| Step: 1
Training loss: 2.3160510063171387
Validation loss: 2.4257341379760415

Epoch: 5| Step: 2
Training loss: 2.383258819580078
Validation loss: 2.4192400824639106

Epoch: 5| Step: 3
Training loss: 2.527829647064209
Validation loss: 2.4270497906592583

Epoch: 5| Step: 4
Training loss: 3.1572518348693848
Validation loss: 2.4274390589806343

Epoch: 5| Step: 5
Training loss: 1.9933967590332031
Validation loss: 2.437063296635946

Epoch: 5| Step: 6
Training loss: 2.257781505584717
Validation loss: 2.4620107450792865

Epoch: 5| Step: 7
Training loss: 3.108959674835205
Validation loss: 2.52185958175249

Epoch: 5| Step: 8
Training loss: 2.9660286903381348
Validation loss: 2.522434955002159

Epoch: 5| Step: 9
Training loss: 2.765982151031494
Validation loss: 2.4755580271444013

Epoch: 5| Step: 10
Training loss: 2.939683675765991
Validation loss: 2.4429077845747753

Epoch: 37| Step: 0
Training loss: 2.968780279159546
Validation loss: 2.4373901864533782

Epoch: 5| Step: 1
Training loss: 2.5673656463623047
Validation loss: 2.4371090781304146

Epoch: 5| Step: 2
Training loss: 2.839097499847412
Validation loss: 2.4414150663601455

Epoch: 5| Step: 3
Training loss: 2.5754029750823975
Validation loss: 2.4289162748603412

Epoch: 5| Step: 4
Training loss: 2.847282648086548
Validation loss: 2.417855073046941

Epoch: 5| Step: 5
Training loss: 2.0714199542999268
Validation loss: 2.417171396234984

Epoch: 5| Step: 6
Training loss: 3.105374336242676
Validation loss: 2.4173219998677573

Epoch: 5| Step: 7
Training loss: 2.783569812774658
Validation loss: 2.4131503746073735

Epoch: 5| Step: 8
Training loss: 2.833085060119629
Validation loss: 2.417228196256904

Epoch: 5| Step: 9
Training loss: 2.652695655822754
Validation loss: 2.416145727198611

Epoch: 5| Step: 10
Training loss: 2.078176498413086
Validation loss: 2.4259543957248813

Epoch: 38| Step: 0
Training loss: 2.559868812561035
Validation loss: 2.4571983865512315

Epoch: 5| Step: 1
Training loss: 2.618983030319214
Validation loss: 2.4775278337540163

Epoch: 5| Step: 2
Training loss: 2.4443907737731934
Validation loss: 2.482019027074178

Epoch: 5| Step: 3
Training loss: 2.044334888458252
Validation loss: 2.4972560687731673

Epoch: 5| Step: 4
Training loss: 2.4993183612823486
Validation loss: 2.499444164255614

Epoch: 5| Step: 5
Training loss: 3.3465874195098877
Validation loss: 2.4758608354035245

Epoch: 5| Step: 6
Training loss: 2.594409942626953
Validation loss: 2.449317083563856

Epoch: 5| Step: 7
Training loss: 3.2684664726257324
Validation loss: 2.3967522498100036

Epoch: 5| Step: 8
Training loss: 2.3570451736450195
Validation loss: 2.404383905472294

Epoch: 5| Step: 9
Training loss: 2.91027569770813
Validation loss: 2.422387961418398

Epoch: 5| Step: 10
Training loss: 2.7788569927215576
Validation loss: 2.4203900291073706

Epoch: 39| Step: 0
Training loss: 2.7547857761383057
Validation loss: 2.419486961057109

Epoch: 5| Step: 1
Training loss: 2.1813080310821533
Validation loss: 2.42018897046325

Epoch: 5| Step: 2
Training loss: 2.5806941986083984
Validation loss: 2.4142667990858837

Epoch: 5| Step: 3
Training loss: 2.779965877532959
Validation loss: 2.4105914843979703

Epoch: 5| Step: 4
Training loss: 2.262803554534912
Validation loss: 2.400173624356588

Epoch: 5| Step: 5
Training loss: 2.5008442401885986
Validation loss: 2.393903447735694

Epoch: 5| Step: 6
Training loss: 2.6153054237365723
Validation loss: 2.38965771531546

Epoch: 5| Step: 7
Training loss: 3.0742392539978027
Validation loss: 2.4083673466918287

Epoch: 5| Step: 8
Training loss: 3.3414230346679688
Validation loss: 2.4342419767892487

Epoch: 5| Step: 9
Training loss: 2.6382598876953125
Validation loss: 2.4473957169440483

Epoch: 5| Step: 10
Training loss: 2.5831801891326904
Validation loss: 2.4513863543028473

Epoch: 40| Step: 0
Training loss: 2.664987325668335
Validation loss: 2.4381993124561925

Epoch: 5| Step: 1
Training loss: 2.6371569633483887
Validation loss: 2.4243425989663727

Epoch: 5| Step: 2
Training loss: 2.5245978832244873
Validation loss: 2.415711666948052

Epoch: 5| Step: 3
Training loss: 2.8076679706573486
Validation loss: 2.394127194599439

Epoch: 5| Step: 4
Training loss: 3.276898145675659
Validation loss: 2.3914518458868868

Epoch: 5| Step: 5
Training loss: 2.4360432624816895
Validation loss: 2.391479610114969

Epoch: 5| Step: 6
Training loss: 2.3595755100250244
Validation loss: 2.388738762947821

Epoch: 5| Step: 7
Training loss: 2.786827802658081
Validation loss: 2.38901614117366

Epoch: 5| Step: 8
Training loss: 2.74493145942688
Validation loss: 2.3868173091642317

Epoch: 5| Step: 9
Training loss: 2.200247287750244
Validation loss: 2.393484555264955

Epoch: 5| Step: 10
Training loss: 2.6447112560272217
Validation loss: 2.3907741859395015

Epoch: 41| Step: 0
Training loss: 2.6242103576660156
Validation loss: 2.3849233504264586

Epoch: 5| Step: 1
Training loss: 2.616856098175049
Validation loss: 2.385796090608002

Epoch: 5| Step: 2
Training loss: 2.3789045810699463
Validation loss: 2.388973464248001

Epoch: 5| Step: 3
Training loss: 3.4384074211120605
Validation loss: 2.38659942278298

Epoch: 5| Step: 4
Training loss: 1.9698652029037476
Validation loss: 2.399279950767435

Epoch: 5| Step: 5
Training loss: 2.3219516277313232
Validation loss: 2.3940113923882924

Epoch: 5| Step: 6
Training loss: 2.3517651557922363
Validation loss: 2.391900280470489

Epoch: 5| Step: 7
Training loss: 2.8350582122802734
Validation loss: 2.3881938867671515

Epoch: 5| Step: 8
Training loss: 2.8038628101348877
Validation loss: 2.385127700785155

Epoch: 5| Step: 9
Training loss: 2.5729284286499023
Validation loss: 2.3878111775203417

Epoch: 5| Step: 10
Training loss: 3.2090508937835693
Validation loss: 2.3951213488014798

Epoch: 42| Step: 0
Training loss: 2.661414384841919
Validation loss: 2.3876525535378406

Epoch: 5| Step: 1
Training loss: 2.115583896636963
Validation loss: 2.397715522396949

Epoch: 5| Step: 2
Training loss: 2.5651984214782715
Validation loss: 2.3905244655506586

Epoch: 5| Step: 3
Training loss: 2.6938376426696777
Validation loss: 2.3915291499066096

Epoch: 5| Step: 4
Training loss: 2.827880382537842
Validation loss: 2.3877942203193583

Epoch: 5| Step: 5
Training loss: 3.083540439605713
Validation loss: 2.388063826868611

Epoch: 5| Step: 6
Training loss: 2.5751090049743652
Validation loss: 2.3960133239787114

Epoch: 5| Step: 7
Training loss: 3.052915096282959
Validation loss: 2.4005058888466126

Epoch: 5| Step: 8
Training loss: 2.2007603645324707
Validation loss: 2.4030006239491124

Epoch: 5| Step: 9
Training loss: 2.44641375541687
Validation loss: 2.3949719449525237

Epoch: 5| Step: 10
Training loss: 2.7284328937530518
Validation loss: 2.3940655569876395

Epoch: 43| Step: 0
Training loss: 2.2084574699401855
Validation loss: 2.388169991072788

Epoch: 5| Step: 1
Training loss: 2.0686066150665283
Validation loss: 2.3953024161759244

Epoch: 5| Step: 2
Training loss: 3.046994686126709
Validation loss: 2.390002750581311

Epoch: 5| Step: 3
Training loss: 2.9549717903137207
Validation loss: 2.3948568451789116

Epoch: 5| Step: 4
Training loss: 2.7020020484924316
Validation loss: 2.3930509064787175

Epoch: 5| Step: 5
Training loss: 2.7524733543395996
Validation loss: 2.3931304818840435

Epoch: 5| Step: 6
Training loss: 2.1311304569244385
Validation loss: 2.3863165814389466

Epoch: 5| Step: 7
Training loss: 2.8402531147003174
Validation loss: 2.377696124456262

Epoch: 5| Step: 8
Training loss: 3.59032940864563
Validation loss: 2.3681403360059186

Epoch: 5| Step: 9
Training loss: 1.8896385431289673
Validation loss: 2.3734900310475338

Epoch: 5| Step: 10
Training loss: 2.7791595458984375
Validation loss: 2.3699907692529822

Epoch: 44| Step: 0
Training loss: 2.4703173637390137
Validation loss: 2.362818289828557

Epoch: 5| Step: 1
Training loss: 2.6992602348327637
Validation loss: 2.3606071420895156

Epoch: 5| Step: 2
Training loss: 2.1050610542297363
Validation loss: 2.3719946287011586

Epoch: 5| Step: 3
Training loss: 2.8118622303009033
Validation loss: 2.4185252087090605

Epoch: 5| Step: 4
Training loss: 3.2041633129119873
Validation loss: 2.4541817044699066

Epoch: 5| Step: 5
Training loss: 2.5953378677368164
Validation loss: 2.4440304002454205

Epoch: 5| Step: 6
Training loss: 3.3900070190429688
Validation loss: 2.451403287149245

Epoch: 5| Step: 7
Training loss: 2.5716240406036377
Validation loss: 2.4048120334584224

Epoch: 5| Step: 8
Training loss: 2.4174933433532715
Validation loss: 2.3995341588092107

Epoch: 5| Step: 9
Training loss: 2.3038010597229004
Validation loss: 2.395621802217217

Epoch: 5| Step: 10
Training loss: 2.3680648803710938
Validation loss: 2.3958765229871197

Epoch: 45| Step: 0
Training loss: 3.2661144733428955
Validation loss: 2.399407430361676

Epoch: 5| Step: 1
Training loss: 2.9202866554260254
Validation loss: 2.4075894535228772

Epoch: 5| Step: 2
Training loss: 2.91650128364563
Validation loss: 2.4218150556728406

Epoch: 5| Step: 3
Training loss: 2.8952012062072754
Validation loss: 2.420074596199938

Epoch: 5| Step: 4
Training loss: 2.740380048751831
Validation loss: 2.4164005197504514

Epoch: 5| Step: 5
Training loss: 2.2733473777770996
Validation loss: 2.4075018205950336

Epoch: 5| Step: 6
Training loss: 3.1900391578674316
Validation loss: 2.382610087753624

Epoch: 5| Step: 7
Training loss: 1.9912006855010986
Validation loss: 2.3772480282732236

Epoch: 5| Step: 8
Training loss: 2.544349193572998
Validation loss: 2.38054217702599

Epoch: 5| Step: 9
Training loss: 2.2218384742736816
Validation loss: 2.37189918692394

Epoch: 5| Step: 10
Training loss: 1.6237199306488037
Validation loss: 2.3635737819056355

Epoch: 46| Step: 0
Training loss: 1.9821122884750366
Validation loss: 2.3632200148797806

Epoch: 5| Step: 1
Training loss: 1.693929672241211
Validation loss: 2.3581895879519883

Epoch: 5| Step: 2
Training loss: 2.5222327709198
Validation loss: 2.359636309326336

Epoch: 5| Step: 3
Training loss: 2.242992877960205
Validation loss: 2.358874685020857

Epoch: 5| Step: 4
Training loss: 2.7821478843688965
Validation loss: 2.365084763496153

Epoch: 5| Step: 5
Training loss: 2.829946756362915
Validation loss: 2.364003599330943

Epoch: 5| Step: 6
Training loss: 2.986888885498047
Validation loss: 2.3660716036314606

Epoch: 5| Step: 7
Training loss: 2.8331408500671387
Validation loss: 2.3599199659080914

Epoch: 5| Step: 8
Training loss: 2.9038944244384766
Validation loss: 2.361636492513841

Epoch: 5| Step: 9
Training loss: 2.847907543182373
Validation loss: 2.3638404710318452

Epoch: 5| Step: 10
Training loss: 3.3970224857330322
Validation loss: 2.3649990917533956

Epoch: 47| Step: 0
Training loss: 2.529087781906128
Validation loss: 2.3691457753540366

Epoch: 5| Step: 1
Training loss: 3.2852249145507812
Validation loss: 2.3815163694402224

Epoch: 5| Step: 2
Training loss: 2.519123077392578
Validation loss: 2.38436996552252

Epoch: 5| Step: 3
Training loss: 2.491410732269287
Validation loss: 2.4083942033911265

Epoch: 5| Step: 4
Training loss: 2.4060215950012207
Validation loss: 2.4008281115562684

Epoch: 5| Step: 5
Training loss: 2.604818344116211
Validation loss: 2.4159164133892266

Epoch: 5| Step: 6
Training loss: 1.997868299484253
Validation loss: 2.412466113285352

Epoch: 5| Step: 7
Training loss: 3.140578031539917
Validation loss: 2.418681801006358

Epoch: 5| Step: 8
Training loss: 2.320195198059082
Validation loss: 2.4083515264654674

Epoch: 5| Step: 9
Training loss: 2.682300567626953
Validation loss: 2.397796533441031

Epoch: 5| Step: 10
Training loss: 2.6437931060791016
Validation loss: 2.414768841958815

Epoch: 48| Step: 0
Training loss: 2.4182918071746826
Validation loss: 2.420312927615258

Epoch: 5| Step: 1
Training loss: 2.8848845958709717
Validation loss: 2.443427224313059

Epoch: 5| Step: 2
Training loss: 2.076763868331909
Validation loss: 2.449637800134638

Epoch: 5| Step: 3
Training loss: 2.858682155609131
Validation loss: 2.44201397895813

Epoch: 5| Step: 4
Training loss: 2.8047502040863037
Validation loss: 2.453874006066271

Epoch: 5| Step: 5
Training loss: 2.1102447509765625
Validation loss: 2.4499507181106077

Epoch: 5| Step: 6
Training loss: 2.5057504177093506
Validation loss: 2.445610269423454

Epoch: 5| Step: 7
Training loss: 2.5462100505828857
Validation loss: 2.428381330223494

Epoch: 5| Step: 8
Training loss: 3.2611641883850098
Validation loss: 2.423024280096895

Epoch: 5| Step: 9
Training loss: 3.04400372505188
Validation loss: 2.4324597697104178

Epoch: 5| Step: 10
Training loss: 2.434901475906372
Validation loss: 2.4307480601854223

Epoch: 49| Step: 0
Training loss: 2.693561553955078
Validation loss: 2.4363754513443157

Epoch: 5| Step: 1
Training loss: 1.5310667753219604
Validation loss: 2.44823149711855

Epoch: 5| Step: 2
Training loss: 2.5109329223632812
Validation loss: 2.423327843348185

Epoch: 5| Step: 3
Training loss: 2.9520721435546875
Validation loss: 2.418921180950698

Epoch: 5| Step: 4
Training loss: 3.4050967693328857
Validation loss: 2.407020976466517

Epoch: 5| Step: 5
Training loss: 3.00671648979187
Validation loss: 2.397597030926776

Epoch: 5| Step: 6
Training loss: 3.151430606842041
Validation loss: 2.3932225909284366

Epoch: 5| Step: 7
Training loss: 2.2542660236358643
Validation loss: 2.3905924058729604

Epoch: 5| Step: 8
Training loss: 2.562727212905884
Validation loss: 2.3907964691039054

Epoch: 5| Step: 9
Training loss: 2.0704376697540283
Validation loss: 2.382143610267229

Epoch: 5| Step: 10
Training loss: 2.6743698120117188
Validation loss: 2.3799263226088656

Epoch: 50| Step: 0
Training loss: 3.113396167755127
Validation loss: 2.3796621061140493

Epoch: 5| Step: 1
Training loss: 2.2620484828948975
Validation loss: 2.373523668576312

Epoch: 5| Step: 2
Training loss: 2.4217848777770996
Validation loss: 2.371062619711763

Epoch: 5| Step: 3
Training loss: 2.569516658782959
Validation loss: 2.373197578614758

Epoch: 5| Step: 4
Training loss: 2.620551824569702
Validation loss: 2.3792198499043784

Epoch: 5| Step: 5
Training loss: 3.0844686031341553
Validation loss: 2.3948867679924093

Epoch: 5| Step: 6
Training loss: 2.2307164669036865
Validation loss: 2.4166452884674072

Epoch: 5| Step: 7
Training loss: 3.0261969566345215
Validation loss: 2.4232308941502727

Epoch: 5| Step: 8
Training loss: 2.042626142501831
Validation loss: 2.4211076382667787

Epoch: 5| Step: 9
Training loss: 3.057769775390625
Validation loss: 2.408980959205217

Epoch: 5| Step: 10
Training loss: 2.1861205101013184
Validation loss: 2.374359146241219

Epoch: 51| Step: 0
Training loss: 1.960303544998169
Validation loss: 2.3356126559677945

Epoch: 5| Step: 1
Training loss: 2.475722074508667
Validation loss: 2.3449819011072957

Epoch: 5| Step: 2
Training loss: 2.277998924255371
Validation loss: 2.349100464133806

Epoch: 5| Step: 3
Training loss: 3.2708849906921387
Validation loss: 2.3464099976324264

Epoch: 5| Step: 4
Training loss: 2.968160629272461
Validation loss: 2.3426085274706603

Epoch: 5| Step: 5
Training loss: 2.9860000610351562
Validation loss: 2.3255492205260904

Epoch: 5| Step: 6
Training loss: 3.1190237998962402
Validation loss: 2.322531274569932

Epoch: 5| Step: 7
Training loss: 2.0651772022247314
Validation loss: 2.3274033659247944

Epoch: 5| Step: 8
Training loss: 2.0408520698547363
Validation loss: 2.3362914298170354

Epoch: 5| Step: 9
Training loss: 2.7367279529571533
Validation loss: 2.3503702430314917

Epoch: 5| Step: 10
Training loss: 2.826205015182495
Validation loss: 2.386147096592893

Epoch: 52| Step: 0
Training loss: 2.8232486248016357
Validation loss: 2.4043333966244935

Epoch: 5| Step: 1
Training loss: 2.183304786682129
Validation loss: 2.416642014698316

Epoch: 5| Step: 2
Training loss: 2.539024829864502
Validation loss: 2.409245626900786

Epoch: 5| Step: 3
Training loss: 3.0722849369049072
Validation loss: 2.3912682225627284

Epoch: 5| Step: 4
Training loss: 2.777494430541992
Validation loss: 2.361452441061697

Epoch: 5| Step: 5
Training loss: 2.7527129650115967
Validation loss: 2.342915445245722

Epoch: 5| Step: 6
Training loss: 2.640376567840576
Validation loss: 2.322052650554206

Epoch: 5| Step: 7
Training loss: 2.6226515769958496
Validation loss: 2.3209244230742097

Epoch: 5| Step: 8
Training loss: 2.5116865634918213
Validation loss: 2.321209562722073

Epoch: 5| Step: 9
Training loss: 2.474487781524658
Validation loss: 2.3272096239110476

Epoch: 5| Step: 10
Training loss: 2.0092527866363525
Validation loss: 2.327474291606616

Epoch: 53| Step: 0
Training loss: 2.486082077026367
Validation loss: 2.3256523327160905

Epoch: 5| Step: 1
Training loss: 3.4672138690948486
Validation loss: 2.3207430249901226

Epoch: 5| Step: 2
Training loss: 2.409086227416992
Validation loss: 2.3109499869808072

Epoch: 5| Step: 3
Training loss: 2.953784465789795
Validation loss: 2.3108400401248725

Epoch: 5| Step: 4
Training loss: 2.780412197113037
Validation loss: 2.3128194424413864

Epoch: 5| Step: 5
Training loss: 2.099334239959717
Validation loss: 2.319815963827154

Epoch: 5| Step: 6
Training loss: 2.6785166263580322
Validation loss: 2.3244346982689312

Epoch: 5| Step: 7
Training loss: 2.6177074909210205
Validation loss: 2.3366583880557807

Epoch: 5| Step: 8
Training loss: 1.9413585662841797
Validation loss: 2.367559268910398

Epoch: 5| Step: 9
Training loss: 2.38248610496521
Validation loss: 2.408702401704686

Epoch: 5| Step: 10
Training loss: 2.912080764770508
Validation loss: 2.439812521780691

Epoch: 54| Step: 0
Training loss: 2.4777634143829346
Validation loss: 2.438267897534114

Epoch: 5| Step: 1
Training loss: 3.090514659881592
Validation loss: 2.4193675671854327

Epoch: 5| Step: 2
Training loss: 1.6693729162216187
Validation loss: 2.364065780434557

Epoch: 5| Step: 3
Training loss: 2.8738956451416016
Validation loss: 2.3296461259165118

Epoch: 5| Step: 4
Training loss: 2.857903003692627
Validation loss: 2.309619449800061

Epoch: 5| Step: 5
Training loss: 2.159130334854126
Validation loss: 2.313090714075232

Epoch: 5| Step: 6
Training loss: 2.611276149749756
Validation loss: 2.304034886821624

Epoch: 5| Step: 7
Training loss: 2.63999605178833
Validation loss: 2.305362832161688

Epoch: 5| Step: 8
Training loss: 3.073653221130371
Validation loss: 2.3095140918608634

Epoch: 5| Step: 9
Training loss: 2.17877197265625
Validation loss: 2.310941698730633

Epoch: 5| Step: 10
Training loss: 2.8752682209014893
Validation loss: 2.309169201440709

Epoch: 55| Step: 0
Training loss: 2.747004508972168
Validation loss: 2.316454356716525

Epoch: 5| Step: 1
Training loss: 2.356321334838867
Validation loss: 2.3172707403859785

Epoch: 5| Step: 2
Training loss: 2.525169849395752
Validation loss: 2.3225985445002073

Epoch: 5| Step: 3
Training loss: 2.9043796062469482
Validation loss: 2.3269950817990046

Epoch: 5| Step: 4
Training loss: 2.6421499252319336
Validation loss: 2.3331566177388674

Epoch: 5| Step: 5
Training loss: 2.810795783996582
Validation loss: 2.344338660599083

Epoch: 5| Step: 6
Training loss: 2.93152117729187
Validation loss: 2.350358724594116

Epoch: 5| Step: 7
Training loss: 2.5820846557617188
Validation loss: 2.371358045967676

Epoch: 5| Step: 8
Training loss: 2.3804354667663574
Validation loss: 2.39305559537744

Epoch: 5| Step: 9
Training loss: 2.012866735458374
Validation loss: 2.3820439384829615

Epoch: 5| Step: 10
Training loss: 2.465456485748291
Validation loss: 2.3648786108980895

Epoch: 56| Step: 0
Training loss: 2.914398670196533
Validation loss: 2.3300758843780844

Epoch: 5| Step: 1
Training loss: 1.6091082096099854
Validation loss: 2.3126136897712626

Epoch: 5| Step: 2
Training loss: 2.428645133972168
Validation loss: 2.2997495448717507

Epoch: 5| Step: 3
Training loss: 2.7384257316589355
Validation loss: 2.3023885373146302

Epoch: 5| Step: 4
Training loss: 2.739011764526367
Validation loss: 2.2977287307862313

Epoch: 5| Step: 5
Training loss: 2.1912364959716797
Validation loss: 2.292408776539628

Epoch: 5| Step: 6
Training loss: 3.1181159019470215
Validation loss: 2.2929577801817205

Epoch: 5| Step: 7
Training loss: 2.7221970558166504
Validation loss: 2.296761125646612

Epoch: 5| Step: 8
Training loss: 2.577676296234131
Validation loss: 2.2954673331270934

Epoch: 5| Step: 9
Training loss: 2.906010866165161
Validation loss: 2.307778207204675

Epoch: 5| Step: 10
Training loss: 2.248953342437744
Validation loss: 2.3051471018022105

Epoch: 57| Step: 0
Training loss: 2.606288433074951
Validation loss: 2.3246568223481536

Epoch: 5| Step: 1
Training loss: 2.1727328300476074
Validation loss: 2.330025234530049

Epoch: 5| Step: 2
Training loss: 2.7563538551330566
Validation loss: 2.3390401409518335

Epoch: 5| Step: 3
Training loss: 2.6337904930114746
Validation loss: 2.349194803545552

Epoch: 5| Step: 4
Training loss: 2.2490909099578857
Validation loss: 2.344900849044964

Epoch: 5| Step: 5
Training loss: 3.1857492923736572
Validation loss: 2.3661949839643253

Epoch: 5| Step: 6
Training loss: 3.1048851013183594
Validation loss: 2.3766028240162838

Epoch: 5| Step: 7
Training loss: 2.7728066444396973
Validation loss: 2.3379799986398346

Epoch: 5| Step: 8
Training loss: 2.3831429481506348
Validation loss: 2.302541971206665

Epoch: 5| Step: 9
Training loss: 2.0574517250061035
Validation loss: 2.2932529462281095

Epoch: 5| Step: 10
Training loss: 2.239027500152588
Validation loss: 2.2800450119920956

Epoch: 58| Step: 0
Training loss: 2.5676472187042236
Validation loss: 2.278264396934099

Epoch: 5| Step: 1
Training loss: 2.915538787841797
Validation loss: 2.2841864375657934

Epoch: 5| Step: 2
Training loss: 3.504379987716675
Validation loss: 2.306302365436349

Epoch: 5| Step: 3
Training loss: 1.9138107299804688
Validation loss: 2.3080263137817383

Epoch: 5| Step: 4
Training loss: 2.054659128189087
Validation loss: 2.295830662532519

Epoch: 5| Step: 5
Training loss: 2.8506500720977783
Validation loss: 2.284208636130056

Epoch: 5| Step: 6
Training loss: 2.7198634147644043
Validation loss: 2.288067809997066

Epoch: 5| Step: 7
Training loss: 2.1216869354248047
Validation loss: 2.2842160527424147

Epoch: 5| Step: 8
Training loss: 2.6379647254943848
Validation loss: 2.2897128161563667

Epoch: 5| Step: 9
Training loss: 2.641756772994995
Validation loss: 2.295743146250325

Epoch: 5| Step: 10
Training loss: 2.520419120788574
Validation loss: 2.2985106078527306

Epoch: 59| Step: 0
Training loss: 2.6270813941955566
Validation loss: 2.3401438882274013

Epoch: 5| Step: 1
Training loss: 2.0127015113830566
Validation loss: 2.3521221504416516

Epoch: 5| Step: 2
Training loss: 2.608625888824463
Validation loss: 2.3653106125452186

Epoch: 5| Step: 3
Training loss: 3.1913630962371826
Validation loss: 2.3976658005868234

Epoch: 5| Step: 4
Training loss: 1.625705361366272
Validation loss: 2.395152461144232

Epoch: 5| Step: 5
Training loss: 3.0002875328063965
Validation loss: 2.377208258516045

Epoch: 5| Step: 6
Training loss: 2.289271593093872
Validation loss: 2.3776458514634

Epoch: 5| Step: 7
Training loss: 2.6939892768859863
Validation loss: 2.3558695957224858

Epoch: 5| Step: 8
Training loss: 2.5443308353424072
Validation loss: 2.3450626968055643

Epoch: 5| Step: 9
Training loss: 2.365355968475342
Validation loss: 2.318438535095543

Epoch: 5| Step: 10
Training loss: 3.3770787715911865
Validation loss: 2.2909066959093978

Epoch: 60| Step: 0
Training loss: 2.0791635513305664
Validation loss: 2.285794993882538

Epoch: 5| Step: 1
Training loss: 2.0845394134521484
Validation loss: 2.2729340009791876

Epoch: 5| Step: 2
Training loss: 2.99481463432312
Validation loss: 2.276352875976152

Epoch: 5| Step: 3
Training loss: 3.032693386077881
Validation loss: 2.279861383540656

Epoch: 5| Step: 4
Training loss: 2.085944652557373
Validation loss: 2.2795427025005384

Epoch: 5| Step: 5
Training loss: 2.3753609657287598
Validation loss: 2.2869242109278196

Epoch: 5| Step: 6
Training loss: 2.8746249675750732
Validation loss: 2.2830010690996723

Epoch: 5| Step: 7
Training loss: 2.41416072845459
Validation loss: 2.2802441607239428

Epoch: 5| Step: 8
Training loss: 2.9094395637512207
Validation loss: 2.2732519231816775

Epoch: 5| Step: 9
Training loss: 2.94368052482605
Validation loss: 2.270238317469115

Epoch: 5| Step: 10
Training loss: 2.581541061401367
Validation loss: 2.265865356691422

Epoch: 61| Step: 0
Training loss: 2.631930351257324
Validation loss: 2.262479951304774

Epoch: 5| Step: 1
Training loss: 2.5461184978485107
Validation loss: 2.280892656695458

Epoch: 5| Step: 2
Training loss: 2.961543083190918
Validation loss: 2.2901375627004974

Epoch: 5| Step: 3
Training loss: 2.9182591438293457
Validation loss: 2.3143490078628703

Epoch: 5| Step: 4
Training loss: 2.2099223136901855
Validation loss: 2.3270759121064217

Epoch: 5| Step: 5
Training loss: 2.8928415775299072
Validation loss: 2.351378816430287

Epoch: 5| Step: 6
Training loss: 2.571895122528076
Validation loss: 2.3767526098476943

Epoch: 5| Step: 7
Training loss: 2.7592825889587402
Validation loss: 2.362658441707652

Epoch: 5| Step: 8
Training loss: 2.224726676940918
Validation loss: 2.316384200126894

Epoch: 5| Step: 9
Training loss: 2.003155469894409
Validation loss: 2.291739894497779

Epoch: 5| Step: 10
Training loss: 2.434530019760132
Validation loss: 2.280956986129925

Epoch: 62| Step: 0
Training loss: 2.7427284717559814
Validation loss: 2.2637543139919156

Epoch: 5| Step: 1
Training loss: 2.0370376110076904
Validation loss: 2.267161638505997

Epoch: 5| Step: 2
Training loss: 2.2070870399475098
Validation loss: 2.2675052406967326

Epoch: 5| Step: 3
Training loss: 2.5300488471984863
Validation loss: 2.2723982821228685

Epoch: 5| Step: 4
Training loss: 2.772409200668335
Validation loss: 2.274588987391482

Epoch: 5| Step: 5
Training loss: 2.9791064262390137
Validation loss: 2.2797706229712373

Epoch: 5| Step: 6
Training loss: 2.8952815532684326
Validation loss: 2.2760387774436706

Epoch: 5| Step: 7
Training loss: 3.633730411529541
Validation loss: 2.2630019111018025

Epoch: 5| Step: 8
Training loss: 2.3749794960021973
Validation loss: 2.2638296516992713

Epoch: 5| Step: 9
Training loss: 1.955451250076294
Validation loss: 2.2651222700713785

Epoch: 5| Step: 10
Training loss: 1.9857696294784546
Validation loss: 2.2655021862317155

Epoch: 63| Step: 0
Training loss: 2.9760327339172363
Validation loss: 2.2778655841786373

Epoch: 5| Step: 1
Training loss: 2.0805881023406982
Validation loss: 2.2941871561029905

Epoch: 5| Step: 2
Training loss: 3.1385293006896973
Validation loss: 2.320701640139344

Epoch: 5| Step: 3
Training loss: 1.8741226196289062
Validation loss: 2.3267513526383268

Epoch: 5| Step: 4
Training loss: 2.856812000274658
Validation loss: 2.354853804393481

Epoch: 5| Step: 5
Training loss: 3.0457634925842285
Validation loss: 2.32334199002994

Epoch: 5| Step: 6
Training loss: 2.70599102973938
Validation loss: 2.3051727792268157

Epoch: 5| Step: 7
Training loss: 3.111870288848877
Validation loss: 2.2853771076407483

Epoch: 5| Step: 8
Training loss: 2.376025676727295
Validation loss: 2.270358529142154

Epoch: 5| Step: 9
Training loss: 2.1044564247131348
Validation loss: 2.273192136518417

Epoch: 5| Step: 10
Training loss: 1.8633310794830322
Validation loss: 2.2691514825308197

Epoch: 64| Step: 0
Training loss: 1.8224294185638428
Validation loss: 2.275406611863003

Epoch: 5| Step: 1
Training loss: 2.8070311546325684
Validation loss: 2.2799078136362056

Epoch: 5| Step: 2
Training loss: 2.33624005317688
Validation loss: 2.278373413188483

Epoch: 5| Step: 3
Training loss: 2.287497043609619
Validation loss: 2.277214757857784

Epoch: 5| Step: 4
Training loss: 2.1776859760284424
Validation loss: 2.2733966086500432

Epoch: 5| Step: 5
Training loss: 2.4855198860168457
Validation loss: 2.3026642850650254

Epoch: 5| Step: 6
Training loss: 2.9342453479766846
Validation loss: 2.2985307580681256

Epoch: 5| Step: 7
Training loss: 3.333420991897583
Validation loss: 2.3076272292803695

Epoch: 5| Step: 8
Training loss: 2.5889275074005127
Validation loss: 2.3042150466672835

Epoch: 5| Step: 9
Training loss: 2.671194553375244
Validation loss: 2.295921710229689

Epoch: 5| Step: 10
Training loss: 2.518296480178833
Validation loss: 2.3016560487849738

Epoch: 65| Step: 0
Training loss: 2.065828800201416
Validation loss: 2.3059762421474663

Epoch: 5| Step: 1
Training loss: 2.619964838027954
Validation loss: 2.353801258148686

Epoch: 5| Step: 2
Training loss: 2.712944507598877
Validation loss: 2.375139210813789

Epoch: 5| Step: 3
Training loss: 2.9472882747650146
Validation loss: 2.38224704803959

Epoch: 5| Step: 4
Training loss: 2.6599297523498535
Validation loss: 2.3630043306658344

Epoch: 5| Step: 5
Training loss: 3.307537078857422
Validation loss: 2.342421608586465

Epoch: 5| Step: 6
Training loss: 2.0704636573791504
Validation loss: 2.306607231017082

Epoch: 5| Step: 7
Training loss: 2.6513657569885254
Validation loss: 2.284068804915233

Epoch: 5| Step: 8
Training loss: 3.007392168045044
Validation loss: 2.2736730255106443

Epoch: 5| Step: 9
Training loss: 2.054069995880127
Validation loss: 2.2659035703187347

Epoch: 5| Step: 10
Training loss: 1.6901042461395264
Validation loss: 2.26227302961452

Epoch: 66| Step: 0
Training loss: 2.8406479358673096
Validation loss: 2.2550521999277096

Epoch: 5| Step: 1
Training loss: 2.7389867305755615
Validation loss: 2.258196779476699

Epoch: 5| Step: 2
Training loss: 2.3339555263519287
Validation loss: 2.255431531577982

Epoch: 5| Step: 3
Training loss: 2.3141028881073
Validation loss: 2.2544502340337282

Epoch: 5| Step: 4
Training loss: 2.3039631843566895
Validation loss: 2.2601123163777013

Epoch: 5| Step: 5
Training loss: 2.377707004547119
Validation loss: 2.2546043421632502

Epoch: 5| Step: 6
Training loss: 2.466416835784912
Validation loss: 2.2526683474099762

Epoch: 5| Step: 7
Training loss: 2.6558375358581543
Validation loss: 2.251326955774779

Epoch: 5| Step: 8
Training loss: 2.2848546504974365
Validation loss: 2.2442392187733806

Epoch: 5| Step: 9
Training loss: 3.1965575218200684
Validation loss: 2.24823946081182

Epoch: 5| Step: 10
Training loss: 2.619802474975586
Validation loss: 2.2448262835061676

Epoch: 67| Step: 0
Training loss: 1.9904314279556274
Validation loss: 2.2514435578418035

Epoch: 5| Step: 1
Training loss: 2.5803627967834473
Validation loss: 2.271163199537544

Epoch: 5| Step: 2
Training loss: 2.6714046001434326
Validation loss: 2.3002077328261508

Epoch: 5| Step: 3
Training loss: 2.4893622398376465
Validation loss: 2.333184963913374

Epoch: 5| Step: 4
Training loss: 2.945382595062256
Validation loss: 2.3401276757640224

Epoch: 5| Step: 5
Training loss: 2.759679079055786
Validation loss: 2.315607411887056

Epoch: 5| Step: 6
Training loss: 2.275911569595337
Validation loss: 2.3570388568344938

Epoch: 5| Step: 7
Training loss: 2.6000256538391113
Validation loss: 2.3904468885032077

Epoch: 5| Step: 8
Training loss: 2.97688627243042
Validation loss: 2.3703116191330778

Epoch: 5| Step: 9
Training loss: 2.394625425338745
Validation loss: 2.341812790081065

Epoch: 5| Step: 10
Training loss: 2.202817678451538
Validation loss: 2.3162007408757366

Epoch: 68| Step: 0
Training loss: 3.0224454402923584
Validation loss: 2.300133251374768

Epoch: 5| Step: 1
Training loss: 2.6950736045837402
Validation loss: 2.295839061019241

Epoch: 5| Step: 2
Training loss: 2.5214407444000244
Validation loss: 2.2794666905556955

Epoch: 5| Step: 3
Training loss: 2.2236266136169434
Validation loss: 2.2601862645918325

Epoch: 5| Step: 4
Training loss: 2.444911479949951
Validation loss: 2.2616943825957594

Epoch: 5| Step: 5
Training loss: 2.8824715614318848
Validation loss: 2.259710019634616

Epoch: 5| Step: 6
Training loss: 2.3010449409484863
Validation loss: 2.255137751179357

Epoch: 5| Step: 7
Training loss: 2.6068263053894043
Validation loss: 2.2576208165896836

Epoch: 5| Step: 8
Training loss: 2.0298125743865967
Validation loss: 2.2648961338945615

Epoch: 5| Step: 9
Training loss: 2.5556640625
Validation loss: 2.2694883782376527

Epoch: 5| Step: 10
Training loss: 2.522345781326294
Validation loss: 2.2664364794249177

Epoch: 69| Step: 0
Training loss: 2.7171459197998047
Validation loss: 2.263154193919192

Epoch: 5| Step: 1
Training loss: 1.6666768789291382
Validation loss: 2.2681983388880247

Epoch: 5| Step: 2
Training loss: 2.8819289207458496
Validation loss: 2.2647931114319833

Epoch: 5| Step: 3
Training loss: 2.7935080528259277
Validation loss: 2.2725385722293647

Epoch: 5| Step: 4
Training loss: 2.870448589324951
Validation loss: 2.2701475709997196

Epoch: 5| Step: 5
Training loss: 2.0272812843322754
Validation loss: 2.2682879406918763

Epoch: 5| Step: 6
Training loss: 2.408747673034668
Validation loss: 2.264650606339978

Epoch: 5| Step: 7
Training loss: 3.5482075214385986
Validation loss: 2.267027980537825

Epoch: 5| Step: 8
Training loss: 2.3487753868103027
Validation loss: 2.26334144479485

Epoch: 5| Step: 9
Training loss: 1.6569658517837524
Validation loss: 2.258860359909714

Epoch: 5| Step: 10
Training loss: 2.7649528980255127
Validation loss: 2.2563214173880954

Epoch: 70| Step: 0
Training loss: 2.498131513595581
Validation loss: 2.2515615083838023

Epoch: 5| Step: 1
Training loss: 2.2356719970703125
Validation loss: 2.246368521003313

Epoch: 5| Step: 2
Training loss: 1.2970999479293823
Validation loss: 2.2503646522439937

Epoch: 5| Step: 3
Training loss: 2.344067335128784
Validation loss: 2.248963527781989

Epoch: 5| Step: 4
Training loss: 1.9717433452606201
Validation loss: 2.2384114752533617

Epoch: 5| Step: 5
Training loss: 2.359041929244995
Validation loss: 2.242474535460113

Epoch: 5| Step: 6
Training loss: 2.7085812091827393
Validation loss: 2.245967734244562

Epoch: 5| Step: 7
Training loss: 3.0187363624572754
Validation loss: 2.261477583198137

Epoch: 5| Step: 8
Training loss: 3.5660624504089355
Validation loss: 2.288079515580208

Epoch: 5| Step: 9
Training loss: 2.5043346881866455
Validation loss: 2.2896791632457445

Epoch: 5| Step: 10
Training loss: 3.1299350261688232
Validation loss: 2.2955342056930705

Epoch: 71| Step: 0
Training loss: 2.95271372795105
Validation loss: 2.3065300577430317

Epoch: 5| Step: 1
Training loss: 2.714015007019043
Validation loss: 2.2664909285883748

Epoch: 5| Step: 2
Training loss: 2.5130932331085205
Validation loss: 2.243769730291059

Epoch: 5| Step: 3
Training loss: 2.247809410095215
Validation loss: 2.2189431805764475

Epoch: 5| Step: 4
Training loss: 2.991189479827881
Validation loss: 2.218203524107574

Epoch: 5| Step: 5
Training loss: 2.5781238079071045
Validation loss: 2.2196472191041514

Epoch: 5| Step: 6
Training loss: 2.2155747413635254
Validation loss: 2.2262751825394167

Epoch: 5| Step: 7
Training loss: 2.6177546977996826
Validation loss: 2.233789463197031

Epoch: 5| Step: 8
Training loss: 2.047062397003174
Validation loss: 2.246804250183926

Epoch: 5| Step: 9
Training loss: 2.375927448272705
Validation loss: 2.259868391098515

Epoch: 5| Step: 10
Training loss: 2.7645859718322754
Validation loss: 2.251613563106906

Epoch: 72| Step: 0
Training loss: 2.5864553451538086
Validation loss: 2.240699404029436

Epoch: 5| Step: 1
Training loss: 3.118077278137207
Validation loss: 2.238563879843681

Epoch: 5| Step: 2
Training loss: 2.34324312210083
Validation loss: 2.257865946779969

Epoch: 5| Step: 3
Training loss: 1.748996376991272
Validation loss: 2.2655151428714877

Epoch: 5| Step: 4
Training loss: 2.601905345916748
Validation loss: 2.2830186454198693

Epoch: 5| Step: 5
Training loss: 2.1076016426086426
Validation loss: 2.3160552363241873

Epoch: 5| Step: 6
Training loss: 2.651630163192749
Validation loss: 2.3194509578007523

Epoch: 5| Step: 7
Training loss: 3.276407241821289
Validation loss: 2.3379203657950125

Epoch: 5| Step: 8
Training loss: 3.0495266914367676
Validation loss: 2.359566573173769

Epoch: 5| Step: 9
Training loss: 2.1255886554718018
Validation loss: 2.3338551213664394

Epoch: 5| Step: 10
Training loss: 2.3678393363952637
Validation loss: 2.3173059609628495

Epoch: 73| Step: 0
Training loss: 2.8640685081481934
Validation loss: 2.298335511197326

Epoch: 5| Step: 1
Training loss: 2.6963729858398438
Validation loss: 2.2804970792544785

Epoch: 5| Step: 2
Training loss: 2.7422454357147217
Validation loss: 2.2873807132885022

Epoch: 5| Step: 3
Training loss: 3.2451682090759277
Validation loss: 2.2806791028668805

Epoch: 5| Step: 4
Training loss: 2.483649730682373
Validation loss: 2.2737162882281887

Epoch: 5| Step: 5
Training loss: 2.6705520153045654
Validation loss: 2.277928075482768

Epoch: 5| Step: 6
Training loss: 2.4120712280273438
Validation loss: 2.2750151772652902

Epoch: 5| Step: 7
Training loss: 2.1115870475769043
Validation loss: 2.290512051633609

Epoch: 5| Step: 8
Training loss: 1.871124029159546
Validation loss: 2.3018405847651984

Epoch: 5| Step: 9
Training loss: 2.567551374435425
Validation loss: 2.3526878472297423

Epoch: 5| Step: 10
Training loss: 2.3528831005096436
Validation loss: 2.3827692693279636

Epoch: 74| Step: 0
Training loss: 2.3717589378356934
Validation loss: 2.407465957826184

Epoch: 5| Step: 1
Training loss: 3.058579683303833
Validation loss: 2.4546190769441667

Epoch: 5| Step: 2
Training loss: 2.458049774169922
Validation loss: 2.3707844467573267

Epoch: 5| Step: 3
Training loss: 2.8863508701324463
Validation loss: 2.2931145519338627

Epoch: 5| Step: 4
Training loss: 1.860202431678772
Validation loss: 2.274515328868743

Epoch: 5| Step: 5
Training loss: 2.3936386108398438
Validation loss: 2.263817079605595

Epoch: 5| Step: 6
Training loss: 2.4222054481506348
Validation loss: 2.2680592024198143

Epoch: 5| Step: 7
Training loss: 2.514174222946167
Validation loss: 2.2794748390874555

Epoch: 5| Step: 8
Training loss: 2.749378204345703
Validation loss: 2.289152240240446

Epoch: 5| Step: 9
Training loss: 3.072378635406494
Validation loss: 2.2975890392898233

Epoch: 5| Step: 10
Training loss: 2.563932418823242
Validation loss: 2.323370587441229

Epoch: 75| Step: 0
Training loss: 2.6711173057556152
Validation loss: 2.353019445173202

Epoch: 5| Step: 1
Training loss: 1.9606208801269531
Validation loss: 2.398980409868302

Epoch: 5| Step: 2
Training loss: 3.128917932510376
Validation loss: 2.3730132092711744

Epoch: 5| Step: 3
Training loss: 2.797048807144165
Validation loss: 2.3376268366331696

Epoch: 5| Step: 4
Training loss: 2.112699270248413
Validation loss: 2.3107256825252245

Epoch: 5| Step: 5
Training loss: 2.595667600631714
Validation loss: 2.2680492106304375

Epoch: 5| Step: 6
Training loss: 2.9944889545440674
Validation loss: 2.2697417966781126

Epoch: 5| Step: 7
Training loss: 2.1056456565856934
Validation loss: 2.2683876304216284

Epoch: 5| Step: 8
Training loss: 3.187105894088745
Validation loss: 2.263951652793474

Epoch: 5| Step: 9
Training loss: 2.523242950439453
Validation loss: 2.2508097028219574

Epoch: 5| Step: 10
Training loss: 2.0310747623443604
Validation loss: 2.239214748464605

Epoch: 76| Step: 0
Training loss: 2.8556900024414062
Validation loss: 2.2364951461874027

Epoch: 5| Step: 1
Training loss: 2.2625343799591064
Validation loss: 2.268946332316245

Epoch: 5| Step: 2
Training loss: 2.5672545433044434
Validation loss: 2.2942696489313597

Epoch: 5| Step: 3
Training loss: 2.132678985595703
Validation loss: 2.3115242014649096

Epoch: 5| Step: 4
Training loss: 1.6804460287094116
Validation loss: 2.387596425189767

Epoch: 5| Step: 5
Training loss: 3.3107197284698486
Validation loss: 2.498633961523733

Epoch: 5| Step: 6
Training loss: 2.4626052379608154
Validation loss: 2.50789305984333

Epoch: 5| Step: 7
Training loss: 2.8722023963928223
Validation loss: 2.403374497608472

Epoch: 5| Step: 8
Training loss: 2.631741762161255
Validation loss: 2.300696729331888

Epoch: 5| Step: 9
Training loss: 2.582850456237793
Validation loss: 2.242901684135519

Epoch: 5| Step: 10
Training loss: 2.6472249031066895
Validation loss: 2.209628987055953

Epoch: 77| Step: 0
Training loss: 2.445321559906006
Validation loss: 2.2097107197648738

Epoch: 5| Step: 1
Training loss: 3.014801502227783
Validation loss: 2.197440993401312

Epoch: 5| Step: 2
Training loss: 2.394674301147461
Validation loss: 2.207189671454891

Epoch: 5| Step: 3
Training loss: 2.2784481048583984
Validation loss: 2.20624182813911

Epoch: 5| Step: 4
Training loss: 2.2748897075653076
Validation loss: 2.1951124411757275

Epoch: 5| Step: 5
Training loss: 2.4524192810058594
Validation loss: 2.183337301336309

Epoch: 5| Step: 6
Training loss: 2.4408020973205566
Validation loss: 2.1982434513748332

Epoch: 5| Step: 7
Training loss: 2.844388484954834
Validation loss: 2.220029633532288

Epoch: 5| Step: 8
Training loss: 2.814105987548828
Validation loss: 2.232194680039601

Epoch: 5| Step: 9
Training loss: 2.2682690620422363
Validation loss: 2.2437328343750327

Epoch: 5| Step: 10
Training loss: 2.2179834842681885
Validation loss: 2.234048371673912

Epoch: 78| Step: 0
Training loss: 2.499647617340088
Validation loss: 2.203452338454544

Epoch: 5| Step: 1
Training loss: 2.399482011795044
Validation loss: 2.174805202791768

Epoch: 5| Step: 2
Training loss: 2.479982852935791
Validation loss: 2.175198742138442

Epoch: 5| Step: 3
Training loss: 3.029083728790283
Validation loss: 2.177376974013544

Epoch: 5| Step: 4
Training loss: 2.161480665206909
Validation loss: 2.1758228425056703

Epoch: 5| Step: 5
Training loss: 2.6068766117095947
Validation loss: 2.1766028276053806

Epoch: 5| Step: 6
Training loss: 2.4669201374053955
Validation loss: 2.183703704546857

Epoch: 5| Step: 7
Training loss: 1.8464469909667969
Validation loss: 2.1851581399158766

Epoch: 5| Step: 8
Training loss: 2.6649601459503174
Validation loss: 2.184186038150582

Epoch: 5| Step: 9
Training loss: 2.6542558670043945
Validation loss: 2.1928972121207946

Epoch: 5| Step: 10
Training loss: 2.3606693744659424
Validation loss: 2.23414901251434

Epoch: 79| Step: 0
Training loss: 2.0546326637268066
Validation loss: 2.2724016866376324

Epoch: 5| Step: 1
Training loss: 2.589527130126953
Validation loss: 2.322365359593463

Epoch: 5| Step: 2
Training loss: 3.185328245162964
Validation loss: 2.4018945719606135

Epoch: 5| Step: 3
Training loss: 2.236518383026123
Validation loss: 2.397224700579079

Epoch: 5| Step: 4
Training loss: 2.860422134399414
Validation loss: 2.4029798815327306

Epoch: 5| Step: 5
Training loss: 2.4750771522521973
Validation loss: 2.2902507448709137

Epoch: 5| Step: 6
Training loss: 2.0510261058807373
Validation loss: 2.245877863258444

Epoch: 5| Step: 7
Training loss: 1.929518461227417
Validation loss: 2.184360788714501

Epoch: 5| Step: 8
Training loss: 2.574800968170166
Validation loss: 2.1758257830014793

Epoch: 5| Step: 9
Training loss: 2.6111834049224854
Validation loss: 2.1800591227828816

Epoch: 5| Step: 10
Training loss: 2.910508155822754
Validation loss: 2.203763977173836

Epoch: 80| Step: 0
Training loss: 2.6504054069519043
Validation loss: 2.219196947672034

Epoch: 5| Step: 1
Training loss: 2.0918707847595215
Validation loss: 2.214339943342311

Epoch: 5| Step: 2
Training loss: 2.2159523963928223
Validation loss: 2.2064491023299513

Epoch: 5| Step: 3
Training loss: 2.8252463340759277
Validation loss: 2.1988228623585035

Epoch: 5| Step: 4
Training loss: 2.053030014038086
Validation loss: 2.1980493171240694

Epoch: 5| Step: 5
Training loss: 1.9939438104629517
Validation loss: 2.1980406674005653

Epoch: 5| Step: 6
Training loss: 2.9690699577331543
Validation loss: 2.20498998190767

Epoch: 5| Step: 7
Training loss: 3.221510410308838
Validation loss: 2.262763343831544

Epoch: 5| Step: 8
Training loss: 2.516528606414795
Validation loss: 2.29397855266448

Epoch: 5| Step: 9
Training loss: 2.629695415496826
Validation loss: 2.285595373440814

Epoch: 5| Step: 10
Training loss: 2.3490874767303467
Validation loss: 2.2679172356923423

Epoch: 81| Step: 0
Training loss: 2.041778802871704
Validation loss: 2.232931178103211

Epoch: 5| Step: 1
Training loss: 2.1510813236236572
Validation loss: 2.1956194844297183

Epoch: 5| Step: 2
Training loss: 2.5961458683013916
Validation loss: 2.17548228592001

Epoch: 5| Step: 3
Training loss: 2.588620185852051
Validation loss: 2.1656682388756865

Epoch: 5| Step: 4
Training loss: 2.5057802200317383
Validation loss: 2.167738917053387

Epoch: 5| Step: 5
Training loss: 2.1322708129882812
Validation loss: 2.16577584000044

Epoch: 5| Step: 6
Training loss: 2.8590190410614014
Validation loss: 2.1630280069125596

Epoch: 5| Step: 7
Training loss: 2.843935966491699
Validation loss: 2.156964131580886

Epoch: 5| Step: 8
Training loss: 2.09991455078125
Validation loss: 2.1682182973431003

Epoch: 5| Step: 9
Training loss: 2.956561326980591
Validation loss: 2.1666812614728044

Epoch: 5| Step: 10
Training loss: 2.4781644344329834
Validation loss: 2.178961325717229

Epoch: 82| Step: 0
Training loss: 2.32993745803833
Validation loss: 2.1837017869436615

Epoch: 5| Step: 1
Training loss: 2.5276613235473633
Validation loss: 2.1871345966093

Epoch: 5| Step: 2
Training loss: 2.4208760261535645
Validation loss: 2.187237621635519

Epoch: 5| Step: 3
Training loss: 2.793949604034424
Validation loss: 2.1882852303084506

Epoch: 5| Step: 4
Training loss: 2.600986957550049
Validation loss: 2.1856285474633657

Epoch: 5| Step: 5
Training loss: 2.2568345069885254
Validation loss: 2.1841802340681835

Epoch: 5| Step: 6
Training loss: 2.667116641998291
Validation loss: 2.1982778759412867

Epoch: 5| Step: 7
Training loss: 2.080296277999878
Validation loss: 2.1924813819187943

Epoch: 5| Step: 8
Training loss: 2.3130908012390137
Validation loss: 2.19890078677926

Epoch: 5| Step: 9
Training loss: 2.5477824211120605
Validation loss: 2.199807454180974

Epoch: 5| Step: 10
Training loss: 2.5772831439971924
Validation loss: 2.21293980075467

Epoch: 83| Step: 0
Training loss: 2.414992570877075
Validation loss: 2.239008826594199

Epoch: 5| Step: 1
Training loss: 2.0522007942199707
Validation loss: 2.274656573931376

Epoch: 5| Step: 2
Training loss: 2.3639938831329346
Validation loss: 2.3204270883273055

Epoch: 5| Step: 3
Training loss: 2.752896785736084
Validation loss: 2.354274175500357

Epoch: 5| Step: 4
Training loss: 2.6171164512634277
Validation loss: 2.369478092398695

Epoch: 5| Step: 5
Training loss: 2.3575961589813232
Validation loss: 2.2731249434973604

Epoch: 5| Step: 6
Training loss: 2.820943593978882
Validation loss: 2.218289247123144

Epoch: 5| Step: 7
Training loss: 2.311159610748291
Validation loss: 2.1735329563899706

Epoch: 5| Step: 8
Training loss: 2.4751620292663574
Validation loss: 2.1678975474449897

Epoch: 5| Step: 9
Training loss: 2.574101686477661
Validation loss: 2.1470200425835064

Epoch: 5| Step: 10
Training loss: 2.336886405944824
Validation loss: 2.141700512619429

Epoch: 84| Step: 0
Training loss: 2.3331570625305176
Validation loss: 2.144282570449255

Epoch: 5| Step: 1
Training loss: 2.752798557281494
Validation loss: 2.1397128540982484

Epoch: 5| Step: 2
Training loss: 2.5843052864074707
Validation loss: 2.1386000315348306

Epoch: 5| Step: 3
Training loss: 2.486053943634033
Validation loss: 2.1430969930464223

Epoch: 5| Step: 4
Training loss: 2.0757455825805664
Validation loss: 2.1446986967517483

Epoch: 5| Step: 5
Training loss: 2.218162775039673
Validation loss: 2.1418822221858527

Epoch: 5| Step: 6
Training loss: 1.9184157848358154
Validation loss: 2.1451346246145104

Epoch: 5| Step: 7
Training loss: 2.120347499847412
Validation loss: 2.1569506327311196

Epoch: 5| Step: 8
Training loss: 3.0263543128967285
Validation loss: 2.151857881135838

Epoch: 5| Step: 9
Training loss: 3.1317782402038574
Validation loss: 2.1576180637523694

Epoch: 5| Step: 10
Training loss: 2.6092772483825684
Validation loss: 2.1702156759077504

Epoch: 85| Step: 0
Training loss: 2.3227181434631348
Validation loss: 2.1877819773971394

Epoch: 5| Step: 1
Training loss: 2.2996418476104736
Validation loss: 2.1864206021831882

Epoch: 5| Step: 2
Training loss: 2.256645679473877
Validation loss: 2.1743791872455227

Epoch: 5| Step: 3
Training loss: 2.6712844371795654
Validation loss: 2.165235819355134

Epoch: 5| Step: 4
Training loss: 2.9302115440368652
Validation loss: 2.172613054193476

Epoch: 5| Step: 5
Training loss: 2.931575059890747
Validation loss: 2.163091637754953

Epoch: 5| Step: 6
Training loss: 2.6461431980133057
Validation loss: 2.166773485881026

Epoch: 5| Step: 7
Training loss: 2.5226001739501953
Validation loss: 2.173288219718523

Epoch: 5| Step: 8
Training loss: 2.0290935039520264
Validation loss: 2.2047895846828336

Epoch: 5| Step: 9
Training loss: 1.511003017425537
Validation loss: 2.223973576740552

Epoch: 5| Step: 10
Training loss: 2.868354320526123
Validation loss: 2.206738797567224

Epoch: 86| Step: 0
Training loss: 2.2418594360351562
Validation loss: 2.1708445651556856

Epoch: 5| Step: 1
Training loss: 2.591665029525757
Validation loss: 2.155817921443652

Epoch: 5| Step: 2
Training loss: 1.8932826519012451
Validation loss: 2.148895558490548

Epoch: 5| Step: 3
Training loss: 2.2752156257629395
Validation loss: 2.146947581280944

Epoch: 5| Step: 4
Training loss: 2.9939754009246826
Validation loss: 2.1432765453092513

Epoch: 5| Step: 5
Training loss: 2.274732828140259
Validation loss: 2.140555238211027

Epoch: 5| Step: 6
Training loss: 2.585806369781494
Validation loss: 2.1574097705143753

Epoch: 5| Step: 7
Training loss: 2.2015292644500732
Validation loss: 2.154034509453722

Epoch: 5| Step: 8
Training loss: 2.2563319206237793
Validation loss: 2.1593788593046126

Epoch: 5| Step: 9
Training loss: 2.901217222213745
Validation loss: 2.1882165093575754

Epoch: 5| Step: 10
Training loss: 2.623810291290283
Validation loss: 2.180860222026866

Epoch: 87| Step: 0
Training loss: 2.104797840118408
Validation loss: 2.1725060837243193

Epoch: 5| Step: 1
Training loss: 2.5581939220428467
Validation loss: 2.1412649334117932

Epoch: 5| Step: 2
Training loss: 2.2708046436309814
Validation loss: 2.129328627740183

Epoch: 5| Step: 3
Training loss: 2.667759418487549
Validation loss: 2.133679936009069

Epoch: 5| Step: 4
Training loss: 2.438469409942627
Validation loss: 2.1231997346365326

Epoch: 5| Step: 5
Training loss: 2.192758798599243
Validation loss: 2.1273057794058197

Epoch: 5| Step: 6
Training loss: 1.9595060348510742
Validation loss: 2.1233552322592786

Epoch: 5| Step: 7
Training loss: 1.9908397197723389
Validation loss: 2.119707784345073

Epoch: 5| Step: 8
Training loss: 3.2158055305480957
Validation loss: 2.1247882355925856

Epoch: 5| Step: 9
Training loss: 3.1809420585632324
Validation loss: 2.1235159635543823

Epoch: 5| Step: 10
Training loss: 2.2213308811187744
Validation loss: 2.1338794551869875

Epoch: 88| Step: 0
Training loss: 2.221592903137207
Validation loss: 2.1410103741512505

Epoch: 5| Step: 1
Training loss: 2.529141902923584
Validation loss: 2.1547787471484114

Epoch: 5| Step: 2
Training loss: 2.533019542694092
Validation loss: 2.1753873081617456

Epoch: 5| Step: 3
Training loss: 2.84934663772583
Validation loss: 2.205869118372599

Epoch: 5| Step: 4
Training loss: 2.0662810802459717
Validation loss: 2.1725648808222946

Epoch: 5| Step: 5
Training loss: 2.563880205154419
Validation loss: 2.1658670607433526

Epoch: 5| Step: 6
Training loss: 2.39754056930542
Validation loss: 2.14326371044241

Epoch: 5| Step: 7
Training loss: 2.0318551063537598
Validation loss: 2.140082402895856

Epoch: 5| Step: 8
Training loss: 2.7675459384918213
Validation loss: 2.1273947813177623

Epoch: 5| Step: 9
Training loss: 1.9948151111602783
Validation loss: 2.1212326736860376

Epoch: 5| Step: 10
Training loss: 2.8882148265838623
Validation loss: 2.1304424244870424

Epoch: 89| Step: 0
Training loss: 2.569960355758667
Validation loss: 2.1389707032070366

Epoch: 5| Step: 1
Training loss: 2.388324737548828
Validation loss: 2.153714697848084

Epoch: 5| Step: 2
Training loss: 1.932798147201538
Validation loss: 2.2141726350271576

Epoch: 5| Step: 3
Training loss: 2.642746686935425
Validation loss: 2.3323339390498337

Epoch: 5| Step: 4
Training loss: 2.593614101409912
Validation loss: 2.307778425114129

Epoch: 5| Step: 5
Training loss: 2.1883327960968018
Validation loss: 2.3288916362229215

Epoch: 5| Step: 6
Training loss: 2.2574238777160645
Validation loss: 2.2500097597798994

Epoch: 5| Step: 7
Training loss: 2.7163774967193604
Validation loss: 2.200790830837783

Epoch: 5| Step: 8
Training loss: 2.708925724029541
Validation loss: 2.1570524631008023

Epoch: 5| Step: 9
Training loss: 2.418180227279663
Validation loss: 2.138060547972238

Epoch: 5| Step: 10
Training loss: 2.375387668609619
Validation loss: 2.131482888293523

Epoch: 90| Step: 0
Training loss: 2.313140392303467
Validation loss: 2.1226652283822336

Epoch: 5| Step: 1
Training loss: 2.7948336601257324
Validation loss: 2.1222133328837733

Epoch: 5| Step: 2
Training loss: 3.209606885910034
Validation loss: 2.136798207477857

Epoch: 5| Step: 3
Training loss: 2.3190865516662598
Validation loss: 2.132961170647734

Epoch: 5| Step: 4
Training loss: 2.6531505584716797
Validation loss: 2.1322375805147233

Epoch: 5| Step: 5
Training loss: 2.6290829181671143
Validation loss: 2.13252523637587

Epoch: 5| Step: 6
Training loss: 2.8919029235839844
Validation loss: 2.1316431158332416

Epoch: 5| Step: 7
Training loss: 2.3179731369018555
Validation loss: 2.134253805683505

Epoch: 5| Step: 8
Training loss: 2.1366639137268066
Validation loss: 2.130857621469805

Epoch: 5| Step: 9
Training loss: 2.241645097732544
Validation loss: 2.1309218637404905

Epoch: 5| Step: 10
Training loss: 1.782041311264038
Validation loss: 2.1599780769758326

Epoch: 91| Step: 0
Training loss: 2.7354791164398193
Validation loss: 2.221340563989455

Epoch: 5| Step: 1
Training loss: 2.924206018447876
Validation loss: 2.18543977122153

Epoch: 5| Step: 2
Training loss: 2.74171781539917
Validation loss: 2.1593920902539323

Epoch: 5| Step: 3
Training loss: 1.8769298791885376
Validation loss: 2.15218456586202

Epoch: 5| Step: 4
Training loss: 2.614905595779419
Validation loss: 2.1522926271602674

Epoch: 5| Step: 5
Training loss: 1.6709434986114502
Validation loss: 2.1478799927619194

Epoch: 5| Step: 6
Training loss: 1.8900830745697021
Validation loss: 2.1797215374567176

Epoch: 5| Step: 7
Training loss: 2.311680793762207
Validation loss: 2.2035334494806107

Epoch: 5| Step: 8
Training loss: 3.1497504711151123
Validation loss: 2.237363388461451

Epoch: 5| Step: 9
Training loss: 2.259061336517334
Validation loss: 2.2393020968283377

Epoch: 5| Step: 10
Training loss: 2.82338809967041
Validation loss: 2.25125156294915

Epoch: 92| Step: 0
Training loss: 2.3424859046936035
Validation loss: 2.265775718996602

Epoch: 5| Step: 1
Training loss: 2.692047595977783
Validation loss: 2.276181269717473

Epoch: 5| Step: 2
Training loss: 2.8187060356140137
Validation loss: 2.261351825088583

Epoch: 5| Step: 3
Training loss: 2.7895288467407227
Validation loss: 2.2105639903776106

Epoch: 5| Step: 4
Training loss: 2.5926613807678223
Validation loss: 2.1809842150698424

Epoch: 5| Step: 5
Training loss: 2.113321304321289
Validation loss: 2.1610045202316774

Epoch: 5| Step: 6
Training loss: 2.274425983428955
Validation loss: 2.1539897611064296

Epoch: 5| Step: 7
Training loss: 2.521439552307129
Validation loss: 2.1517260023342666

Epoch: 5| Step: 8
Training loss: 1.89798104763031
Validation loss: 2.1503033791818926

Epoch: 5| Step: 9
Training loss: 2.4739270210266113
Validation loss: 2.1447138171042166

Epoch: 5| Step: 10
Training loss: 1.796270489692688
Validation loss: 2.1383226199816634

Epoch: 93| Step: 0
Training loss: 2.941323757171631
Validation loss: 2.128393339854415

Epoch: 5| Step: 1
Training loss: 2.4476101398468018
Validation loss: 2.1377323865890503

Epoch: 5| Step: 2
Training loss: 3.039766311645508
Validation loss: 2.140503610334089

Epoch: 5| Step: 3
Training loss: 2.6540541648864746
Validation loss: 2.1346118219437136

Epoch: 5| Step: 4
Training loss: 2.9184112548828125
Validation loss: 2.1223469908519457

Epoch: 5| Step: 5
Training loss: 1.8822021484375
Validation loss: 2.1161587981767553

Epoch: 5| Step: 6
Training loss: 1.7630504369735718
Validation loss: 2.114785619961318

Epoch: 5| Step: 7
Training loss: 2.363473892211914
Validation loss: 2.10679276527897

Epoch: 5| Step: 8
Training loss: 1.6292527914047241
Validation loss: 2.1122216524616366

Epoch: 5| Step: 9
Training loss: 2.3285012245178223
Validation loss: 2.119832638771303

Epoch: 5| Step: 10
Training loss: 2.5709941387176514
Validation loss: 2.1371178370650097

Epoch: 94| Step: 0
Training loss: 2.6890597343444824
Validation loss: 2.1864344535335416

Epoch: 5| Step: 1
Training loss: 2.2822105884552
Validation loss: 2.1957445324108167

Epoch: 5| Step: 2
Training loss: 2.205655813217163
Validation loss: 2.184069086146611

Epoch: 5| Step: 3
Training loss: 2.1887917518615723
Validation loss: 2.147623817125956

Epoch: 5| Step: 4
Training loss: 1.9701656103134155
Validation loss: 2.1374894444660475

Epoch: 5| Step: 5
Training loss: 3.114997148513794
Validation loss: 2.1302353412874284

Epoch: 5| Step: 6
Training loss: 2.7409369945526123
Validation loss: 2.1294724915617254

Epoch: 5| Step: 7
Training loss: 2.6343626976013184
Validation loss: 2.116861037028733

Epoch: 5| Step: 8
Training loss: 2.6247804164886475
Validation loss: 2.10718108248967

Epoch: 5| Step: 9
Training loss: 2.201988935470581
Validation loss: 2.118722446503178

Epoch: 5| Step: 10
Training loss: 1.929413914680481
Validation loss: 2.1168827331194313

Epoch: 95| Step: 0
Training loss: 1.8907814025878906
Validation loss: 2.1213030866397324

Epoch: 5| Step: 1
Training loss: 2.9706318378448486
Validation loss: 2.127367429835822

Epoch: 5| Step: 2
Training loss: 2.797122001647949
Validation loss: 2.126869656706369

Epoch: 5| Step: 3
Training loss: 2.4355521202087402
Validation loss: 2.1291779087435816

Epoch: 5| Step: 4
Training loss: 3.043402910232544
Validation loss: 2.12438706685138

Epoch: 5| Step: 5
Training loss: 2.5169835090637207
Validation loss: 2.1098931579179663

Epoch: 5| Step: 6
Training loss: 2.055405616760254
Validation loss: 2.0991490015419583

Epoch: 5| Step: 7
Training loss: 2.3902807235717773
Validation loss: 2.107290120534999

Epoch: 5| Step: 8
Training loss: 1.9005136489868164
Validation loss: 2.114653669377809

Epoch: 5| Step: 9
Training loss: 1.9254249334335327
Validation loss: 2.1490899773054224

Epoch: 5| Step: 10
Training loss: 2.2158823013305664
Validation loss: 2.169602696613599

Epoch: 96| Step: 0
Training loss: 2.2753689289093018
Validation loss: 2.2061994588503273

Epoch: 5| Step: 1
Training loss: 2.6251778602600098
Validation loss: 2.2261408580246793

Epoch: 5| Step: 2
Training loss: 2.180448532104492
Validation loss: 2.235277332285399

Epoch: 5| Step: 3
Training loss: 2.921671152114868
Validation loss: 2.1883533975129486

Epoch: 5| Step: 4
Training loss: 2.182466506958008
Validation loss: 2.1560374562458327

Epoch: 5| Step: 5
Training loss: 1.5685534477233887
Validation loss: 2.14130602728936

Epoch: 5| Step: 6
Training loss: 2.7617783546447754
Validation loss: 2.1193885546858593

Epoch: 5| Step: 7
Training loss: 2.222567319869995
Validation loss: 2.1073215379509875

Epoch: 5| Step: 8
Training loss: 2.4521825313568115
Validation loss: 2.1059803475615797

Epoch: 5| Step: 9
Training loss: 2.618379592895508
Validation loss: 2.1148623984347106

Epoch: 5| Step: 10
Training loss: 2.5047059059143066
Validation loss: 2.10881789781714

Epoch: 97| Step: 0
Training loss: 1.923680305480957
Validation loss: 2.1260563814511864

Epoch: 5| Step: 1
Training loss: 2.2788162231445312
Validation loss: 2.120213408623972

Epoch: 5| Step: 2
Training loss: 1.9054533243179321
Validation loss: 2.119003754790111

Epoch: 5| Step: 3
Training loss: 2.647651195526123
Validation loss: 2.118915060515045

Epoch: 5| Step: 4
Training loss: 2.617549419403076
Validation loss: 2.1289680901394097

Epoch: 5| Step: 5
Training loss: 2.609386682510376
Validation loss: 2.1272506777958204

Epoch: 5| Step: 6
Training loss: 2.3696036338806152
Validation loss: 2.126373524306923

Epoch: 5| Step: 7
Training loss: 2.4452853202819824
Validation loss: 2.1263424927188503

Epoch: 5| Step: 8
Training loss: 2.3706326484680176
Validation loss: 2.1366788033516175

Epoch: 5| Step: 9
Training loss: 2.546623468399048
Validation loss: 2.1409837174159225

Epoch: 5| Step: 10
Training loss: 2.4429025650024414
Validation loss: 2.1501734461835635

Epoch: 98| Step: 0
Training loss: 2.8743484020233154
Validation loss: 2.1397312379652456

Epoch: 5| Step: 1
Training loss: 2.9993107318878174
Validation loss: 2.1177047670528455

Epoch: 5| Step: 2
Training loss: 2.494372844696045
Validation loss: 2.103780710568992

Epoch: 5| Step: 3
Training loss: 2.213954210281372
Validation loss: 2.0960910486918625

Epoch: 5| Step: 4
Training loss: 2.1021270751953125
Validation loss: 2.0896442603039485

Epoch: 5| Step: 5
Training loss: 2.1262876987457275
Validation loss: 2.105288031280682

Epoch: 5| Step: 6
Training loss: 2.527273416519165
Validation loss: 2.1029304022430093

Epoch: 5| Step: 7
Training loss: 1.8181644678115845
Validation loss: 2.100448368698038

Epoch: 5| Step: 8
Training loss: 2.326162815093994
Validation loss: 2.110576201510686

Epoch: 5| Step: 9
Training loss: 2.784766674041748
Validation loss: 2.123014987155955

Epoch: 5| Step: 10
Training loss: 2.0204994678497314
Validation loss: 2.150305523667284

Epoch: 99| Step: 0
Training loss: 2.463731288909912
Validation loss: 2.179443766993861

Epoch: 5| Step: 1
Training loss: 2.3682072162628174
Validation loss: 2.2111313855776222

Epoch: 5| Step: 2
Training loss: 3.3186912536621094
Validation loss: 2.1960275416733115

Epoch: 5| Step: 3
Training loss: 2.0846357345581055
Validation loss: 2.173951046441191

Epoch: 5| Step: 4
Training loss: 2.606569766998291
Validation loss: 2.151039969536566

Epoch: 5| Step: 5
Training loss: 2.311124086380005
Validation loss: 2.1339034162541872

Epoch: 5| Step: 6
Training loss: 2.311704635620117
Validation loss: 2.09331678318721

Epoch: 5| Step: 7
Training loss: 2.4508862495422363
Validation loss: 2.08207804413252

Epoch: 5| Step: 8
Training loss: 1.7706365585327148
Validation loss: 2.0719266014714397

Epoch: 5| Step: 9
Training loss: 1.9564040899276733
Validation loss: 2.0756257759627474

Epoch: 5| Step: 10
Training loss: 2.460944175720215
Validation loss: 2.0743872298989245

Epoch: 100| Step: 0
Training loss: 1.8220665454864502
Validation loss: 2.0718363843938357

Epoch: 5| Step: 1
Training loss: 2.723878860473633
Validation loss: 2.0968292438855736

Epoch: 5| Step: 2
Training loss: 2.496608018875122
Validation loss: 2.114160865865728

Epoch: 5| Step: 3
Training loss: 2.7417850494384766
Validation loss: 2.162653094978743

Epoch: 5| Step: 4
Training loss: 2.3021159172058105
Validation loss: 2.1521683969805316

Epoch: 5| Step: 5
Training loss: 2.486360549926758
Validation loss: 2.1491445367054274

Epoch: 5| Step: 6
Training loss: 1.9194927215576172
Validation loss: 2.130031798475532

Epoch: 5| Step: 7
Training loss: 2.756840467453003
Validation loss: 2.1019831959919264

Epoch: 5| Step: 8
Training loss: 2.001157283782959
Validation loss: 2.088321549918062

Epoch: 5| Step: 9
Training loss: 2.382882595062256
Validation loss: 2.083987089895433

Epoch: 5| Step: 10
Training loss: 2.407578468322754
Validation loss: 2.0897190724649737

Epoch: 101| Step: 0
Training loss: 2.26367449760437
Validation loss: 2.084628276927497

Epoch: 5| Step: 1
Training loss: 2.6582553386688232
Validation loss: 2.085284351020731

Epoch: 5| Step: 2
Training loss: 2.4259238243103027
Validation loss: 2.0896715118039038

Epoch: 5| Step: 3
Training loss: 2.199369430541992
Validation loss: 2.1048168161863923

Epoch: 5| Step: 4
Training loss: 2.39975643157959
Validation loss: 2.1067268566418718

Epoch: 5| Step: 5
Training loss: 1.7611812353134155
Validation loss: 2.117300646279448

Epoch: 5| Step: 6
Training loss: 2.3204383850097656
Validation loss: 2.1143736236838886

Epoch: 5| Step: 7
Training loss: 2.3770809173583984
Validation loss: 2.118686896498485

Epoch: 5| Step: 8
Training loss: 2.470853328704834
Validation loss: 2.1223779916763306

Epoch: 5| Step: 9
Training loss: 2.64180326461792
Validation loss: 2.1212277386778142

Epoch: 5| Step: 10
Training loss: 2.3893325328826904
Validation loss: 2.1349452746811735

Epoch: 102| Step: 0
Training loss: 2.7745585441589355
Validation loss: 2.1730985128751366

Epoch: 5| Step: 1
Training loss: 2.132221221923828
Validation loss: 2.1740212876309633

Epoch: 5| Step: 2
Training loss: 2.164808750152588
Validation loss: 2.1729890249108754

Epoch: 5| Step: 3
Training loss: 2.5313754081726074
Validation loss: 2.1591325165123068

Epoch: 5| Step: 4
Training loss: 2.317007064819336
Validation loss: 2.136858711960495

Epoch: 5| Step: 5
Training loss: 2.8475801944732666
Validation loss: 2.112485957402055

Epoch: 5| Step: 6
Training loss: 1.7660224437713623
Validation loss: 2.1060563031063286

Epoch: 5| Step: 7
Training loss: 2.7022910118103027
Validation loss: 2.0996516699432046

Epoch: 5| Step: 8
Training loss: 2.1698625087738037
Validation loss: 2.1126136420875468

Epoch: 5| Step: 9
Training loss: 2.21871280670166
Validation loss: 2.1237819169157293

Epoch: 5| Step: 10
Training loss: 2.0825161933898926
Validation loss: 2.137028007097142

Epoch: 103| Step: 0
Training loss: 2.710200309753418
Validation loss: 2.1677611604813607

Epoch: 5| Step: 1
Training loss: 2.4413533210754395
Validation loss: 2.185759962245982

Epoch: 5| Step: 2
Training loss: 2.6084113121032715
Validation loss: 2.168756756731259

Epoch: 5| Step: 3
Training loss: 2.1808743476867676
Validation loss: 2.1520009912470335

Epoch: 5| Step: 4
Training loss: 2.2983882427215576
Validation loss: 2.1468109161623063

Epoch: 5| Step: 5
Training loss: 2.375971555709839
Validation loss: 2.142177662541789

Epoch: 5| Step: 6
Training loss: 2.304255962371826
Validation loss: 2.1498390961718816

Epoch: 5| Step: 7
Training loss: 2.118828296661377
Validation loss: 2.1855549132952126

Epoch: 5| Step: 8
Training loss: 1.7925676107406616
Validation loss: 2.1932638896408903

Epoch: 5| Step: 9
Training loss: 2.4494118690490723
Validation loss: 2.190724224172613

Epoch: 5| Step: 10
Training loss: 2.5280747413635254
Validation loss: 2.147688099133071

Epoch: 104| Step: 0
Training loss: 1.6678613424301147
Validation loss: 2.109902213978511

Epoch: 5| Step: 1
Training loss: 1.9260056018829346
Validation loss: 2.0911184459604244

Epoch: 5| Step: 2
Training loss: 2.6533701419830322
Validation loss: 2.0882991706171343

Epoch: 5| Step: 3
Training loss: 2.590881586074829
Validation loss: 2.0924904936103412

Epoch: 5| Step: 4
Training loss: 1.8881736993789673
Validation loss: 2.1167315462584138

Epoch: 5| Step: 5
Training loss: 2.1340081691741943
Validation loss: 2.110276519611318

Epoch: 5| Step: 6
Training loss: 2.399874210357666
Validation loss: 2.104272296351771

Epoch: 5| Step: 7
Training loss: 2.887878894805908
Validation loss: 2.1171451486567014

Epoch: 5| Step: 8
Training loss: 2.1789867877960205
Validation loss: 2.127164448461225

Epoch: 5| Step: 9
Training loss: 2.3992598056793213
Validation loss: 2.126062103497085

Epoch: 5| Step: 10
Training loss: 2.91675066947937
Validation loss: 2.145878045789657

Epoch: 105| Step: 0
Training loss: 2.6177055835723877
Validation loss: 2.1462494224630375

Epoch: 5| Step: 1
Training loss: 1.6652820110321045
Validation loss: 2.1568856841774395

Epoch: 5| Step: 2
Training loss: 1.7178306579589844
Validation loss: 2.1438454069117063

Epoch: 5| Step: 3
Training loss: 2.3937058448791504
Validation loss: 2.1463818755201114

Epoch: 5| Step: 4
Training loss: 2.0850210189819336
Validation loss: 2.127370339567943

Epoch: 5| Step: 5
Training loss: 2.3084933757781982
Validation loss: 2.0960791598084154

Epoch: 5| Step: 6
Training loss: 2.248197555541992
Validation loss: 2.0915778208804388

Epoch: 5| Step: 7
Training loss: 2.721541166305542
Validation loss: 2.083751365702639

Epoch: 5| Step: 8
Training loss: 2.492356777191162
Validation loss: 2.081764864665206

Epoch: 5| Step: 9
Training loss: 2.139625072479248
Validation loss: 2.079682873141381

Epoch: 5| Step: 10
Training loss: 3.1577460765838623
Validation loss: 2.076981229166831

Epoch: 106| Step: 0
Training loss: 2.5277504920959473
Validation loss: 2.07214407895201

Epoch: 5| Step: 1
Training loss: 2.2805094718933105
Validation loss: 2.087179649260736

Epoch: 5| Step: 2
Training loss: 2.4600625038146973
Validation loss: 2.169293421570973

Epoch: 5| Step: 3
Training loss: 2.706813097000122
Validation loss: 2.292700183007025

Epoch: 5| Step: 4
Training loss: 1.8619273900985718
Validation loss: 2.4606262330086

Epoch: 5| Step: 5
Training loss: 3.0805788040161133
Validation loss: 2.538261103373702

Epoch: 5| Step: 6
Training loss: 2.8579225540161133
Validation loss: 2.470214182330716

Epoch: 5| Step: 7
Training loss: 1.8104089498519897
Validation loss: 2.241816751418575

Epoch: 5| Step: 8
Training loss: 2.282500743865967
Validation loss: 2.0890537769563737

Epoch: 5| Step: 9
Training loss: 2.1077353954315186
Validation loss: 2.080771275745925

Epoch: 5| Step: 10
Training loss: 2.4924674034118652
Validation loss: 2.138235289563415

Epoch: 107| Step: 0
Training loss: 2.1192493438720703
Validation loss: 2.191276196510561

Epoch: 5| Step: 1
Training loss: 2.4702420234680176
Validation loss: 2.2239287386658373

Epoch: 5| Step: 2
Training loss: 2.426417350769043
Validation loss: 2.235233362003039

Epoch: 5| Step: 3
Training loss: 2.596405029296875
Validation loss: 2.2496243189739924

Epoch: 5| Step: 4
Training loss: 2.8345043659210205
Validation loss: 2.238386102901992

Epoch: 5| Step: 5
Training loss: 2.2338364124298096
Validation loss: 2.1817582704687632

Epoch: 5| Step: 6
Training loss: 3.184574842453003
Validation loss: 2.1299879140751337

Epoch: 5| Step: 7
Training loss: 2.1803667545318604
Validation loss: 2.0979755668229956

Epoch: 5| Step: 8
Training loss: 1.9486678838729858
Validation loss: 2.106617763478269

Epoch: 5| Step: 9
Training loss: 1.9666788578033447
Validation loss: 2.148850287160566

Epoch: 5| Step: 10
Training loss: 2.5824453830718994
Validation loss: 2.276270158829228

Epoch: 108| Step: 0
Training loss: 2.5047030448913574
Validation loss: 2.3607107926440496

Epoch: 5| Step: 1
Training loss: 2.313537120819092
Validation loss: 2.3858208425583376

Epoch: 5| Step: 2
Training loss: 2.4966630935668945
Validation loss: 2.374117120619743

Epoch: 5| Step: 3
Training loss: 2.272334575653076
Validation loss: 2.3066715194332983

Epoch: 5| Step: 4
Training loss: 2.8152265548706055
Validation loss: 2.2453065431246193

Epoch: 5| Step: 5
Training loss: 2.7096455097198486
Validation loss: 2.1825733876997426

Epoch: 5| Step: 6
Training loss: 2.510418176651001
Validation loss: 2.128569887530419

Epoch: 5| Step: 7
Training loss: 2.1807894706726074
Validation loss: 2.092078234559746

Epoch: 5| Step: 8
Training loss: 1.3998854160308838
Validation loss: 2.0814199524541057

Epoch: 5| Step: 9
Training loss: 2.875586748123169
Validation loss: 2.0794827963716243

Epoch: 5| Step: 10
Training loss: 2.1740009784698486
Validation loss: 2.0659772606306177

Epoch: 109| Step: 0
Training loss: 3.114812135696411
Validation loss: 2.0619565620217273

Epoch: 5| Step: 1
Training loss: 2.436014175415039
Validation loss: 2.0530267556508384

Epoch: 5| Step: 2
Training loss: 2.1575419902801514
Validation loss: 2.05450108743483

Epoch: 5| Step: 3
Training loss: 2.0796215534210205
Validation loss: 2.044398428291403

Epoch: 5| Step: 4
Training loss: 2.3044991493225098
Validation loss: 2.0492379870466007

Epoch: 5| Step: 5
Training loss: 2.2611358165740967
Validation loss: 2.0493658101686867

Epoch: 5| Step: 6
Training loss: 2.339844226837158
Validation loss: 2.053069567167631

Epoch: 5| Step: 7
Training loss: 2.3733506202697754
Validation loss: 2.056166983419849

Epoch: 5| Step: 8
Training loss: 2.0274994373321533
Validation loss: 2.091358733433549

Epoch: 5| Step: 9
Training loss: 2.295701265335083
Validation loss: 2.1159283499563895

Epoch: 5| Step: 10
Training loss: 2.549927234649658
Validation loss: 2.1358970519035094

Epoch: 110| Step: 0
Training loss: 2.60939621925354
Validation loss: 2.1440209111859723

Epoch: 5| Step: 1
Training loss: 2.615870952606201
Validation loss: 2.149267453019337

Epoch: 5| Step: 2
Training loss: 1.8557689189910889
Validation loss: 2.0998886298107844

Epoch: 5| Step: 3
Training loss: 2.1274075508117676
Validation loss: 2.0643540902804305

Epoch: 5| Step: 4
Training loss: 2.343416690826416
Validation loss: 2.066428945910546

Epoch: 5| Step: 5
Training loss: 2.4226365089416504
Validation loss: 2.0658304076040945

Epoch: 5| Step: 6
Training loss: 2.0269744396209717
Validation loss: 2.0594178643277896

Epoch: 5| Step: 7
Training loss: 2.443042755126953
Validation loss: 2.0764701879152687

Epoch: 5| Step: 8
Training loss: 2.5120880603790283
Validation loss: 2.0962763653006604

Epoch: 5| Step: 9
Training loss: 2.0685596466064453
Validation loss: 2.1072917958741546

Epoch: 5| Step: 10
Training loss: 2.252018690109253
Validation loss: 2.116671880086263

Epoch: 111| Step: 0
Training loss: 2.5628104209899902
Validation loss: 2.120320156056394

Epoch: 5| Step: 1
Training loss: 1.927424669265747
Validation loss: 2.1276007493336997

Epoch: 5| Step: 2
Training loss: 3.0862679481506348
Validation loss: 2.132790328353964

Epoch: 5| Step: 3
Training loss: 1.9691238403320312
Validation loss: 2.1513737734927925

Epoch: 5| Step: 4
Training loss: 2.720951795578003
Validation loss: 2.1455665173069125

Epoch: 5| Step: 5
Training loss: 2.273846387863159
Validation loss: 2.1499423442348355

Epoch: 5| Step: 6
Training loss: 2.516530990600586
Validation loss: 2.149367300412988

Epoch: 5| Step: 7
Training loss: 1.7562803030014038
Validation loss: 2.150691145209856

Epoch: 5| Step: 8
Training loss: 1.8001378774642944
Validation loss: 2.1401268910336237

Epoch: 5| Step: 9
Training loss: 2.356750011444092
Validation loss: 2.134425365796653

Epoch: 5| Step: 10
Training loss: 2.1763014793395996
Validation loss: 2.1220744245795795

Epoch: 112| Step: 0
Training loss: 2.1945652961730957
Validation loss: 2.1100188122000745

Epoch: 5| Step: 1
Training loss: 2.962794065475464
Validation loss: 2.109486549131332

Epoch: 5| Step: 2
Training loss: 2.520615577697754
Validation loss: 2.105675243562268

Epoch: 5| Step: 3
Training loss: 2.394965171813965
Validation loss: 2.1048757183936333

Epoch: 5| Step: 4
Training loss: 1.7254034280776978
Validation loss: 2.0921004151785247

Epoch: 5| Step: 5
Training loss: 1.8281075954437256
Validation loss: 2.071426828702291

Epoch: 5| Step: 6
Training loss: 1.6642906665802002
Validation loss: 2.0598901984512166

Epoch: 5| Step: 7
Training loss: 2.2436461448669434
Validation loss: 2.0560889372261624

Epoch: 5| Step: 8
Training loss: 2.9242703914642334
Validation loss: 2.066524724806509

Epoch: 5| Step: 9
Training loss: 2.4225914478302
Validation loss: 2.0670392077456237

Epoch: 5| Step: 10
Training loss: 2.0486302375793457
Validation loss: 2.083054136204463

Epoch: 113| Step: 0
Training loss: 2.175676107406616
Validation loss: 2.1089899668129544

Epoch: 5| Step: 1
Training loss: 2.081474781036377
Validation loss: 2.12107894497533

Epoch: 5| Step: 2
Training loss: 1.6482210159301758
Validation loss: 2.123348512957173

Epoch: 5| Step: 3
Training loss: 2.3947360515594482
Validation loss: 2.1202231196946997

Epoch: 5| Step: 4
Training loss: 2.582185983657837
Validation loss: 2.123543136863298

Epoch: 5| Step: 5
Training loss: 2.320450782775879
Validation loss: 2.1143219047977078

Epoch: 5| Step: 6
Training loss: 2.5052876472473145
Validation loss: 2.129493381387444

Epoch: 5| Step: 7
Training loss: 2.1625232696533203
Validation loss: 2.1276264934129614

Epoch: 5| Step: 8
Training loss: 2.0996479988098145
Validation loss: 2.1247108315908783

Epoch: 5| Step: 9
Training loss: 2.556734800338745
Validation loss: 2.123938645085981

Epoch: 5| Step: 10
Training loss: 2.149913787841797
Validation loss: 2.1242114343950824

Epoch: 114| Step: 0
Training loss: 1.6713829040527344
Validation loss: 2.121312397782521

Epoch: 5| Step: 1
Training loss: 2.7130041122436523
Validation loss: 2.1203925494224793

Epoch: 5| Step: 2
Training loss: 2.2389209270477295
Validation loss: 2.113186679860597

Epoch: 5| Step: 3
Training loss: 2.2997066974639893
Validation loss: 2.10917749199816

Epoch: 5| Step: 4
Training loss: 2.1822164058685303
Validation loss: 2.099801660865866

Epoch: 5| Step: 5
Training loss: 2.5413577556610107
Validation loss: 2.1147183833583707

Epoch: 5| Step: 6
Training loss: 2.9825093746185303
Validation loss: 2.1144838589493946

Epoch: 5| Step: 7
Training loss: 2.3694708347320557
Validation loss: 2.1191749316389843

Epoch: 5| Step: 8
Training loss: 1.9688260555267334
Validation loss: 2.119214855214601

Epoch: 5| Step: 9
Training loss: 1.9202747344970703
Validation loss: 2.134880817064675

Epoch: 5| Step: 10
Training loss: 1.4481871128082275
Validation loss: 2.1212708629587644

Epoch: 115| Step: 0
Training loss: 1.9551212787628174
Validation loss: 2.127191651252008

Epoch: 5| Step: 1
Training loss: 1.6206798553466797
Validation loss: 2.1248934666315713

Epoch: 5| Step: 2
Training loss: 2.2557029724121094
Validation loss: 2.1272370276912564

Epoch: 5| Step: 3
Training loss: 2.1390645503997803
Validation loss: 2.1279373630400626

Epoch: 5| Step: 4
Training loss: 1.993117094039917
Validation loss: 2.1227228256963913

Epoch: 5| Step: 5
Training loss: 2.486576795578003
Validation loss: 2.1189432092892226

Epoch: 5| Step: 6
Training loss: 2.393540382385254
Validation loss: 2.1063988106225127

Epoch: 5| Step: 7
Training loss: 2.169738292694092
Validation loss: 2.0966407009350356

Epoch: 5| Step: 8
Training loss: 2.5076076984405518
Validation loss: 2.0890156222927954

Epoch: 5| Step: 9
Training loss: 2.974748134613037
Validation loss: 2.087306717390655

Epoch: 5| Step: 10
Training loss: 1.5987478494644165
Validation loss: 2.0855104205428914

Epoch: 116| Step: 0
Training loss: 2.2551355361938477
Validation loss: 2.09291938940684

Epoch: 5| Step: 1
Training loss: 2.4946770668029785
Validation loss: 2.100878361732729

Epoch: 5| Step: 2
Training loss: 2.074410915374756
Validation loss: 2.1141052117911716

Epoch: 5| Step: 3
Training loss: 2.197047233581543
Validation loss: 2.137126530370405

Epoch: 5| Step: 4
Training loss: 1.9463611841201782
Validation loss: 2.1919358699552474

Epoch: 5| Step: 5
Training loss: 1.7742061614990234
Validation loss: 2.2433967564695623

Epoch: 5| Step: 6
Training loss: 2.6219120025634766
Validation loss: 2.2598002585031653

Epoch: 5| Step: 7
Training loss: 2.425572156906128
Validation loss: 2.2113590855752268

Epoch: 5| Step: 8
Training loss: 2.7141051292419434
Validation loss: 2.133117788581438

Epoch: 5| Step: 9
Training loss: 1.989174246788025
Validation loss: 2.1002081158340618

Epoch: 5| Step: 10
Training loss: 1.9958480596542358
Validation loss: 2.082623140786284

Epoch: 117| Step: 0
Training loss: 2.2782044410705566
Validation loss: 2.0881110237490748

Epoch: 5| Step: 1
Training loss: 2.5703682899475098
Validation loss: 2.0809111979699906

Epoch: 5| Step: 2
Training loss: 2.2511491775512695
Validation loss: 2.0853518414241012

Epoch: 5| Step: 3
Training loss: 2.428962469100952
Validation loss: 2.0809104916869954

Epoch: 5| Step: 4
Training loss: 2.4110214710235596
Validation loss: 2.0924116744790027

Epoch: 5| Step: 5
Training loss: 2.0380444526672363
Validation loss: 2.107615286304105

Epoch: 5| Step: 6
Training loss: 2.276401996612549
Validation loss: 2.1439741401262182

Epoch: 5| Step: 7
Training loss: 2.1749730110168457
Validation loss: 2.18159604841663

Epoch: 5| Step: 8
Training loss: 2.245213031768799
Validation loss: 2.205354554678804

Epoch: 5| Step: 9
Training loss: 2.217587947845459
Validation loss: 2.227282883018576

Epoch: 5| Step: 10
Training loss: 1.7009538412094116
Validation loss: 2.2096536031333347

Epoch: 118| Step: 0
Training loss: 1.8803699016571045
Validation loss: 2.148093086417003

Epoch: 5| Step: 1
Training loss: 2.6429190635681152
Validation loss: 2.1023536446273967

Epoch: 5| Step: 2
Training loss: 2.130499839782715
Validation loss: 2.0912847416375273

Epoch: 5| Step: 3
Training loss: 1.919919729232788
Validation loss: 2.1018331512328117

Epoch: 5| Step: 4
Training loss: 2.6137449741363525
Validation loss: 2.1161808659953456

Epoch: 5| Step: 5
Training loss: 2.514580488204956
Validation loss: 2.128430966408022

Epoch: 5| Step: 6
Training loss: 1.8359801769256592
Validation loss: 2.1335091334517284

Epoch: 5| Step: 7
Training loss: 2.2817649841308594
Validation loss: 2.140749157115977

Epoch: 5| Step: 8
Training loss: 2.3124094009399414
Validation loss: 2.1555212518220306

Epoch: 5| Step: 9
Training loss: 2.1975579261779785
Validation loss: 2.1850380089975174

Epoch: 5| Step: 10
Training loss: 2.008366823196411
Validation loss: 2.1777781671093357

Epoch: 119| Step: 0
Training loss: 2.1202118396759033
Validation loss: 2.172341313413394

Epoch: 5| Step: 1
Training loss: 1.6081578731536865
Validation loss: 2.132279631912067

Epoch: 5| Step: 2
Training loss: 3.0337166786193848
Validation loss: 2.122137281202501

Epoch: 5| Step: 3
Training loss: 1.7389522790908813
Validation loss: 2.1044469828246744

Epoch: 5| Step: 4
Training loss: 1.6517524719238281
Validation loss: 2.0993508472237536

Epoch: 5| Step: 5
Training loss: 2.128042459487915
Validation loss: 2.1158356282018844

Epoch: 5| Step: 6
Training loss: 2.451557159423828
Validation loss: 2.0975323056661956

Epoch: 5| Step: 7
Training loss: 2.225802183151245
Validation loss: 2.086523945613574

Epoch: 5| Step: 8
Training loss: 2.4315178394317627
Validation loss: 2.078851845956618

Epoch: 5| Step: 9
Training loss: 1.439034342765808
Validation loss: 2.0789339773116575

Epoch: 5| Step: 10
Training loss: 3.1814115047454834
Validation loss: 2.0931293144020984

Epoch: 120| Step: 0
Training loss: 2.4080076217651367
Validation loss: 2.1119176944096885

Epoch: 5| Step: 1
Training loss: 2.059174060821533
Validation loss: 2.146221970999113

Epoch: 5| Step: 2
Training loss: 1.8056045770645142
Validation loss: 2.1880431303413967

Epoch: 5| Step: 3
Training loss: 1.7610814571380615
Validation loss: 2.220833588671941

Epoch: 5| Step: 4
Training loss: 1.982879638671875
Validation loss: 2.1992990868065947

Epoch: 5| Step: 5
Training loss: 2.4387564659118652
Validation loss: 2.163638796857608

Epoch: 5| Step: 6
Training loss: 1.7565914392471313
Validation loss: 2.125925499905822

Epoch: 5| Step: 7
Training loss: 2.8676953315734863
Validation loss: 2.1117769672024633

Epoch: 5| Step: 8
Training loss: 2.505250930786133
Validation loss: 2.0823131863788893

Epoch: 5| Step: 9
Training loss: 2.404592990875244
Validation loss: 2.0719146882334063

Epoch: 5| Step: 10
Training loss: 1.5578458309173584
Validation loss: 2.0634246333952873

Epoch: 121| Step: 0
Training loss: 2.2465267181396484
Validation loss: 2.067929111501222

Epoch: 5| Step: 1
Training loss: 2.6918113231658936
Validation loss: 2.097278989771361

Epoch: 5| Step: 2
Training loss: 2.5107932090759277
Validation loss: 2.1263282222132527

Epoch: 5| Step: 3
Training loss: 1.9322580099105835
Validation loss: 2.1570230965973227

Epoch: 5| Step: 4
Training loss: 2.0816330909729004
Validation loss: 2.1434509420907624

Epoch: 5| Step: 5
Training loss: 2.0458154678344727
Validation loss: 2.134698132032989

Epoch: 5| Step: 6
Training loss: 2.30275297164917
Validation loss: 2.1427524910178235

Epoch: 5| Step: 7
Training loss: 1.3557722568511963
Validation loss: 2.1492297482746903

Epoch: 5| Step: 8
Training loss: 2.423818588256836
Validation loss: 2.1627685767348095

Epoch: 5| Step: 9
Training loss: 1.5909088850021362
Validation loss: 2.1906209197095645

Epoch: 5| Step: 10
Training loss: 2.3109869956970215
Validation loss: 2.2182529844263548

Epoch: 122| Step: 0
Training loss: 2.6826345920562744
Validation loss: 2.2314068425086235

Epoch: 5| Step: 1
Training loss: 2.691455125808716
Validation loss: 2.2234184626610047

Epoch: 5| Step: 2
Training loss: 1.7897045612335205
Validation loss: 2.1942465433510403

Epoch: 5| Step: 3
Training loss: 1.9529234170913696
Validation loss: 2.1647080554757068

Epoch: 5| Step: 4
Training loss: 2.1448862552642822
Validation loss: 2.1374327149442447

Epoch: 5| Step: 5
Training loss: 2.1280269622802734
Validation loss: 2.1186104307892504

Epoch: 5| Step: 6
Training loss: 2.1570987701416016
Validation loss: 2.084242720757761

Epoch: 5| Step: 7
Training loss: 1.9295566082000732
Validation loss: 2.062699435859598

Epoch: 5| Step: 8
Training loss: 1.7629379034042358
Validation loss: 2.0452088271417925

Epoch: 5| Step: 9
Training loss: 2.1631975173950195
Validation loss: 2.04225581179383

Epoch: 5| Step: 10
Training loss: 2.1411890983581543
Validation loss: 2.052822495019564

Epoch: 123| Step: 0
Training loss: 2.164835214614868
Validation loss: 2.0557915805488505

Epoch: 5| Step: 1
Training loss: 2.3485851287841797
Validation loss: 2.0617771328136487

Epoch: 5| Step: 2
Training loss: 2.6119492053985596
Validation loss: 2.1049434549065045

Epoch: 5| Step: 3
Training loss: 1.4439420700073242
Validation loss: 2.147060207141343

Epoch: 5| Step: 4
Training loss: 2.1048922538757324
Validation loss: 2.1654380060011342

Epoch: 5| Step: 5
Training loss: 2.351294994354248
Validation loss: 2.1896775127739034

Epoch: 5| Step: 6
Training loss: 1.907361388206482
Validation loss: 2.1857507151942097

Epoch: 5| Step: 7
Training loss: 3.0739903450012207
Validation loss: 2.1438522723413285

Epoch: 5| Step: 8
Training loss: 2.057901382446289
Validation loss: 2.1537231758076656

Epoch: 5| Step: 9
Training loss: 1.406646966934204
Validation loss: 2.142410716702861

Epoch: 5| Step: 10
Training loss: 1.7437655925750732
Validation loss: 2.149278420273976

Epoch: 124| Step: 0
Training loss: 2.45800518989563
Validation loss: 2.144493131227391

Epoch: 5| Step: 1
Training loss: 2.195000410079956
Validation loss: 2.141270117093158

Epoch: 5| Step: 2
Training loss: 2.4726667404174805
Validation loss: 2.142686528544272

Epoch: 5| Step: 3
Training loss: 2.289912700653076
Validation loss: 2.1461925955228907

Epoch: 5| Step: 4
Training loss: 1.3371975421905518
Validation loss: 2.126824550731208

Epoch: 5| Step: 5
Training loss: 2.123042106628418
Validation loss: 2.0980948581490466

Epoch: 5| Step: 6
Training loss: 2.436619281768799
Validation loss: 2.0718104083050966

Epoch: 5| Step: 7
Training loss: 2.021250009536743
Validation loss: 2.067956127146239

Epoch: 5| Step: 8
Training loss: 1.9378045797348022
Validation loss: 2.068505599934568

Epoch: 5| Step: 9
Training loss: 1.7845157384872437
Validation loss: 2.072436435248262

Epoch: 5| Step: 10
Training loss: 1.93222177028656
Validation loss: 2.0781990276869906

Epoch: 125| Step: 0
Training loss: 2.344837188720703
Validation loss: 2.0987794194170224

Epoch: 5| Step: 1
Training loss: 1.9505846500396729
Validation loss: 2.115159116765504

Epoch: 5| Step: 2
Training loss: 1.6353607177734375
Validation loss: 2.1307178287095923

Epoch: 5| Step: 3
Training loss: 2.3633034229278564
Validation loss: 2.1376402378082275

Epoch: 5| Step: 4
Training loss: 1.96695077419281
Validation loss: 2.1421703984660487

Epoch: 5| Step: 5
Training loss: 1.190391182899475
Validation loss: 2.1357187686427945

Epoch: 5| Step: 6
Training loss: 2.2245869636535645
Validation loss: 2.102802045883671

Epoch: 5| Step: 7
Training loss: 2.173877477645874
Validation loss: 2.117285668209035

Epoch: 5| Step: 8
Training loss: 2.9442310333251953
Validation loss: 2.141148467217722

Epoch: 5| Step: 9
Training loss: 1.587352991104126
Validation loss: 2.152628166701204

Epoch: 5| Step: 10
Training loss: 2.423604965209961
Validation loss: 2.156723060915547

Epoch: 126| Step: 0
Training loss: 2.5272319316864014
Validation loss: 2.1291769460965226

Epoch: 5| Step: 1
Training loss: 1.9022315740585327
Validation loss: 2.1226790976780716

Epoch: 5| Step: 2
Training loss: 1.0856372117996216
Validation loss: 2.110001588380465

Epoch: 5| Step: 3
Training loss: 2.147810697555542
Validation loss: 2.1041246511602916

Epoch: 5| Step: 4
Training loss: 2.5307352542877197
Validation loss: 2.0846306534223658

Epoch: 5| Step: 5
Training loss: 2.1235244274139404
Validation loss: 2.095806142335297

Epoch: 5| Step: 6
Training loss: 1.7199960947036743
Validation loss: 2.1018066534432034

Epoch: 5| Step: 7
Training loss: 1.7855949401855469
Validation loss: 2.1052867443330827

Epoch: 5| Step: 8
Training loss: 2.667956829071045
Validation loss: 2.156794450616324

Epoch: 5| Step: 9
Training loss: 2.366222858428955
Validation loss: 2.185868804172803

Epoch: 5| Step: 10
Training loss: 1.439239263534546
Validation loss: 2.2022380239220074

Epoch: 127| Step: 0
Training loss: 1.5670894384384155
Validation loss: 2.218074075637325

Epoch: 5| Step: 1
Training loss: 1.995904564857483
Validation loss: 2.1943333213047316

Epoch: 5| Step: 2
Training loss: 2.221844434738159
Validation loss: 2.202481077563378

Epoch: 5| Step: 3
Training loss: 1.9903064966201782
Validation loss: 2.177525338306222

Epoch: 5| Step: 4
Training loss: 2.1061246395111084
Validation loss: 2.1555664641882784

Epoch: 5| Step: 5
Training loss: 1.6364829540252686
Validation loss: 2.1504758993784585

Epoch: 5| Step: 6
Training loss: 2.0452821254730225
Validation loss: 2.1368733400939615

Epoch: 5| Step: 7
Training loss: 2.0683350563049316
Validation loss: 2.1005244613975607

Epoch: 5| Step: 8
Training loss: 2.35927152633667
Validation loss: 2.081422217430607

Epoch: 5| Step: 9
Training loss: 2.357621431350708
Validation loss: 2.060490628724457

Epoch: 5| Step: 10
Training loss: 1.9989100694656372
Validation loss: 2.0571778358951693

Epoch: 128| Step: 0
Training loss: 1.9284801483154297
Validation loss: 2.0576540244522916

Epoch: 5| Step: 1
Training loss: 2.209022283554077
Validation loss: 2.0766521679457797

Epoch: 5| Step: 2
Training loss: 1.4120510816574097
Validation loss: 2.0720595877657653

Epoch: 5| Step: 3
Training loss: 2.3914997577667236
Validation loss: 2.072137245567896

Epoch: 5| Step: 4
Training loss: 2.208636522293091
Validation loss: 2.0496450931795183

Epoch: 5| Step: 5
Training loss: 1.8651437759399414
Validation loss: 2.050598955923511

Epoch: 5| Step: 6
Training loss: 2.742619037628174
Validation loss: 2.0427269012697282

Epoch: 5| Step: 7
Training loss: 2.565279722213745
Validation loss: 2.042846416914335

Epoch: 5| Step: 8
Training loss: 1.8713067770004272
Validation loss: 2.0409881863542783

Epoch: 5| Step: 9
Training loss: 1.9145920276641846
Validation loss: 2.042923281269689

Epoch: 5| Step: 10
Training loss: 1.1336652040481567
Validation loss: 2.064651753312798

Epoch: 129| Step: 0
Training loss: 1.933326005935669
Validation loss: 2.0976624488830566

Epoch: 5| Step: 1
Training loss: 2.3926424980163574
Validation loss: 2.1488606058141237

Epoch: 5| Step: 2
Training loss: 1.7333968877792358
Validation loss: 2.1372326381744875

Epoch: 5| Step: 3
Training loss: 2.2386984825134277
Validation loss: 2.121931008113328

Epoch: 5| Step: 4
Training loss: 1.7100918292999268
Validation loss: 2.109665339992892

Epoch: 5| Step: 5
Training loss: 1.8330142498016357
Validation loss: 2.055433725798002

Epoch: 5| Step: 6
Training loss: 2.0695087909698486
Validation loss: 2.033626881978845

Epoch: 5| Step: 7
Training loss: 1.530390977859497
Validation loss: 2.0309261378421577

Epoch: 5| Step: 8
Training loss: 2.189765453338623
Validation loss: 2.039184874103915

Epoch: 5| Step: 9
Training loss: 1.7010581493377686
Validation loss: 2.0683301789786226

Epoch: 5| Step: 10
Training loss: 3.077864170074463
Validation loss: 2.134365961115847

Epoch: 130| Step: 0
Training loss: 1.4503520727157593
Validation loss: 2.1934595620760353

Epoch: 5| Step: 1
Training loss: 1.9661037921905518
Validation loss: 2.2575477964134625

Epoch: 5| Step: 2
Training loss: 2.002725124359131
Validation loss: 2.2128056300583707

Epoch: 5| Step: 3
Training loss: 2.0692813396453857
Validation loss: 2.149419048781036

Epoch: 5| Step: 4
Training loss: 2.0035929679870605
Validation loss: 2.13731708065156

Epoch: 5| Step: 5
Training loss: 2.115997076034546
Validation loss: 2.1338949831583167

Epoch: 5| Step: 6
Training loss: 2.132591962814331
Validation loss: 2.1076072723634782

Epoch: 5| Step: 7
Training loss: 2.5739738941192627
Validation loss: 2.083445692575106

Epoch: 5| Step: 8
Training loss: 1.9497781991958618
Validation loss: 2.0619636709972093

Epoch: 5| Step: 9
Training loss: 1.9797561168670654
Validation loss: 2.0496421167927403

Epoch: 5| Step: 10
Training loss: 2.215996742248535
Validation loss: 2.032421323560899

Epoch: 131| Step: 0
Training loss: 2.1320712566375732
Validation loss: 2.0283038129088697

Epoch: 5| Step: 1
Training loss: 2.6728713512420654
Validation loss: 2.048976057319231

Epoch: 5| Step: 2
Training loss: 2.2837607860565186
Validation loss: 2.111079695404217

Epoch: 5| Step: 3
Training loss: 1.7103097438812256
Validation loss: 2.140377547151299

Epoch: 5| Step: 4
Training loss: 1.3458836078643799
Validation loss: 2.1581624400231147

Epoch: 5| Step: 5
Training loss: 2.3260931968688965
Validation loss: 2.173239761783231

Epoch: 5| Step: 6
Training loss: 2.0332531929016113
Validation loss: 2.1163123153871104

Epoch: 5| Step: 7
Training loss: 1.676094651222229
Validation loss: 2.0927284327886437

Epoch: 5| Step: 8
Training loss: 2.3164525032043457
Validation loss: 2.092606198403143

Epoch: 5| Step: 9
Training loss: 1.6589123010635376
Validation loss: 2.092982303711676

Epoch: 5| Step: 10
Training loss: 2.0146539211273193
Validation loss: 2.0949915403960855

Epoch: 132| Step: 0
Training loss: 2.2666823863983154
Validation loss: 2.0608147446827223

Epoch: 5| Step: 1
Training loss: 1.8573576211929321
Validation loss: 2.0344974225567234

Epoch: 5| Step: 2
Training loss: 1.9832760095596313
Validation loss: 1.995094754362619

Epoch: 5| Step: 3
Training loss: 1.9849923849105835
Validation loss: 1.9945586471147434

Epoch: 5| Step: 4
Training loss: 2.375075578689575
Validation loss: 1.9746741594806794

Epoch: 5| Step: 5
Training loss: 1.796938180923462
Validation loss: 1.9943275195296093

Epoch: 5| Step: 6
Training loss: 2.3481059074401855
Validation loss: 2.048759009248467

Epoch: 5| Step: 7
Training loss: 1.9684326648712158
Validation loss: 2.0684809915481077

Epoch: 5| Step: 8
Training loss: 1.49002206325531
Validation loss: 2.0687701189389793

Epoch: 5| Step: 9
Training loss: 1.9528319835662842
Validation loss: 2.0971038264612996

Epoch: 5| Step: 10
Training loss: 1.9500267505645752
Validation loss: 2.075854188652449

Epoch: 133| Step: 0
Training loss: 1.1803480386734009
Validation loss: 2.1085860549762683

Epoch: 5| Step: 1
Training loss: 1.6308072805404663
Validation loss: 2.0856675024955504

Epoch: 5| Step: 2
Training loss: 1.9743038415908813
Validation loss: 2.1176819544966503

Epoch: 5| Step: 3
Training loss: 2.664865255355835
Validation loss: 2.1245961701998146

Epoch: 5| Step: 4
Training loss: 2.484417676925659
Validation loss: 2.1630077310787734

Epoch: 5| Step: 5
Training loss: 2.191592216491699
Validation loss: 2.1987891709932716

Epoch: 5| Step: 6
Training loss: 2.339454174041748
Validation loss: 2.2047755359321513

Epoch: 5| Step: 7
Training loss: 1.743778944015503
Validation loss: 2.21073688614753

Epoch: 5| Step: 8
Training loss: 2.110109329223633
Validation loss: 2.161545284332768

Epoch: 5| Step: 9
Training loss: 1.6877450942993164
Validation loss: 2.1234448955905054

Epoch: 5| Step: 10
Training loss: 1.6305607557296753
Validation loss: 2.09389970379491

Epoch: 134| Step: 0
Training loss: 2.0380520820617676
Validation loss: 2.067469209753057

Epoch: 5| Step: 1
Training loss: 2.144207000732422
Validation loss: 2.038593867773651

Epoch: 5| Step: 2
Training loss: 2.0802853107452393
Validation loss: 2.0363776811989407

Epoch: 5| Step: 3
Training loss: 1.6854889392852783
Validation loss: 2.0380592858919533

Epoch: 5| Step: 4
Training loss: 2.4427273273468018
Validation loss: 2.048201694283434

Epoch: 5| Step: 5
Training loss: 1.8952564001083374
Validation loss: 2.033549493358981

Epoch: 5| Step: 6
Training loss: 2.032271146774292
Validation loss: 2.0112934035639607

Epoch: 5| Step: 7
Training loss: 1.7744169235229492
Validation loss: 2.024352455651888

Epoch: 5| Step: 8
Training loss: 1.3223193883895874
Validation loss: 2.0121162347896124

Epoch: 5| Step: 9
Training loss: 1.9047424793243408
Validation loss: 1.9941324341681697

Epoch: 5| Step: 10
Training loss: 2.192490577697754
Validation loss: 2.022352110955023

Epoch: 135| Step: 0
Training loss: 2.0221054553985596
Validation loss: 2.017309752843713

Epoch: 5| Step: 1
Training loss: 1.826902151107788
Validation loss: 2.034487134666853

Epoch: 5| Step: 2
Training loss: 2.0494561195373535
Validation loss: 2.066502330123737

Epoch: 5| Step: 3
Training loss: 2.0892980098724365
Validation loss: 2.087084067765103

Epoch: 5| Step: 4
Training loss: 2.2754323482513428
Validation loss: 2.0811971477282944

Epoch: 5| Step: 5
Training loss: 2.166559934616089
Validation loss: 2.099441910302767

Epoch: 5| Step: 6
Training loss: 2.09628963470459
Validation loss: 2.1049239507285495

Epoch: 5| Step: 7
Training loss: 2.199624538421631
Validation loss: 2.104672613964286

Epoch: 5| Step: 8
Training loss: 1.4864767789840698
Validation loss: 2.1165720519199165

Epoch: 5| Step: 9
Training loss: 1.1087653636932373
Validation loss: 2.129412894607872

Epoch: 5| Step: 10
Training loss: 2.036349296569824
Validation loss: 2.1444207199158205

Epoch: 136| Step: 0
Training loss: 1.5031172037124634
Validation loss: 2.168416298845763

Epoch: 5| Step: 1
Training loss: 1.8162562847137451
Validation loss: 2.179725836682063

Epoch: 5| Step: 2
Training loss: 2.1461522579193115
Validation loss: 2.1872681597227692

Epoch: 5| Step: 3
Training loss: 2.036165952682495
Validation loss: 2.167754122005996

Epoch: 5| Step: 4
Training loss: 1.6864054203033447
Validation loss: 2.1432774400198333

Epoch: 5| Step: 5
Training loss: 1.892327070236206
Validation loss: 2.130357439799975

Epoch: 5| Step: 6
Training loss: 1.6080806255340576
Validation loss: 2.1204588643966185

Epoch: 5| Step: 7
Training loss: 2.004178285598755
Validation loss: 2.131229503180391

Epoch: 5| Step: 8
Training loss: 2.2782645225524902
Validation loss: 2.120627360959207

Epoch: 5| Step: 9
Training loss: 1.827783226966858
Validation loss: 2.1195615747923493

Epoch: 5| Step: 10
Training loss: 2.2370975017547607
Validation loss: 2.1095759227711666

Epoch: 137| Step: 0
Training loss: 1.525241732597351
Validation loss: 2.1210646398605837

Epoch: 5| Step: 1
Training loss: 1.870692491531372
Validation loss: 2.109536632414787

Epoch: 5| Step: 2
Training loss: 2.6250557899475098
Validation loss: 2.1138820776375393

Epoch: 5| Step: 3
Training loss: 1.9818859100341797
Validation loss: 2.123913500898628

Epoch: 5| Step: 4
Training loss: 2.049842357635498
Validation loss: 2.1303885675245717

Epoch: 5| Step: 5
Training loss: 1.7197914123535156
Validation loss: 2.122104666566336

Epoch: 5| Step: 6
Training loss: 1.3542948961257935
Validation loss: 2.1408434785822386

Epoch: 5| Step: 7
Training loss: 2.472705364227295
Validation loss: 2.131627507107232

Epoch: 5| Step: 8
Training loss: 1.9196010828018188
Validation loss: 2.1312559227789603

Epoch: 5| Step: 9
Training loss: 1.5266764163970947
Validation loss: 2.084481639246787

Epoch: 5| Step: 10
Training loss: 1.924048900604248
Validation loss: 2.044469566755397

Epoch: 138| Step: 0
Training loss: 1.9563617706298828
Validation loss: 2.0327361091490714

Epoch: 5| Step: 1
Training loss: 1.7351850271224976
Validation loss: 2.020514572820356

Epoch: 5| Step: 2
Training loss: 1.866620659828186
Validation loss: 1.9994899367773404

Epoch: 5| Step: 3
Training loss: 1.786049246788025
Validation loss: 2.0053716756964244

Epoch: 5| Step: 4
Training loss: 2.146301746368408
Validation loss: 2.061299939309397

Epoch: 5| Step: 5
Training loss: 2.159250020980835
Validation loss: 2.07672252321756

Epoch: 5| Step: 6
Training loss: 2.20219349861145
Validation loss: 2.0292742508713917

Epoch: 5| Step: 7
Training loss: 1.4983867406845093
Validation loss: 2.04755977917743

Epoch: 5| Step: 8
Training loss: 2.0369439125061035
Validation loss: 2.066822951839816

Epoch: 5| Step: 9
Training loss: 1.8946723937988281
Validation loss: 2.0583377397188576

Epoch: 5| Step: 10
Training loss: 1.4691767692565918
Validation loss: 2.011272899566158

Epoch: 139| Step: 0
Training loss: 2.225853681564331
Validation loss: 2.0130140563493133

Epoch: 5| Step: 1
Training loss: 1.524037480354309
Validation loss: 2.011588458091982

Epoch: 5| Step: 2
Training loss: 1.7131083011627197
Validation loss: 2.0241186157349618

Epoch: 5| Step: 3
Training loss: 2.1518006324768066
Validation loss: 2.0482136485397175

Epoch: 5| Step: 4
Training loss: 0.8692189455032349
Validation loss: 2.0670287070735807

Epoch: 5| Step: 5
Training loss: 2.5765652656555176
Validation loss: 2.0927871709228842

Epoch: 5| Step: 6
Training loss: 2.0710532665252686
Validation loss: 2.10788849220481

Epoch: 5| Step: 7
Training loss: 1.7606801986694336
Validation loss: 2.1382750106114212

Epoch: 5| Step: 8
Training loss: 1.9642595052719116
Validation loss: 2.1140478272591867

Epoch: 5| Step: 9
Training loss: 2.1585488319396973
Validation loss: 2.1103510805355605

Epoch: 5| Step: 10
Training loss: 1.3798469305038452
Validation loss: 2.0976665148171048

Epoch: 140| Step: 0
Training loss: 1.6505590677261353
Validation loss: 2.092437823613485

Epoch: 5| Step: 1
Training loss: 2.1437435150146484
Validation loss: 2.0766920607577086

Epoch: 5| Step: 2
Training loss: 1.9409234523773193
Validation loss: 2.0513676725408083

Epoch: 5| Step: 3
Training loss: 1.7795175313949585
Validation loss: 2.0189550204943587

Epoch: 5| Step: 4
Training loss: 1.8445899486541748
Validation loss: 1.9862145608471287

Epoch: 5| Step: 5
Training loss: 1.8195339441299438
Validation loss: 2.0014337057708413

Epoch: 5| Step: 6
Training loss: 1.9282524585723877
Validation loss: 1.9997515293859667

Epoch: 5| Step: 7
Training loss: 1.6789830923080444
Validation loss: 2.0201471108262257

Epoch: 5| Step: 8
Training loss: 1.9773935079574585
Validation loss: 2.0590366830107985

Epoch: 5| Step: 9
Training loss: 2.3677754402160645
Validation loss: 2.1046162407885314

Epoch: 5| Step: 10
Training loss: 1.1419321298599243
Validation loss: 2.145697403979558

Epoch: 141| Step: 0
Training loss: 2.186894178390503
Validation loss: 2.1921024719874063

Epoch: 5| Step: 1
Training loss: 2.429992198944092
Validation loss: 2.23489898250949

Epoch: 5| Step: 2
Training loss: 1.4726279973983765
Validation loss: 2.1079033472204722

Epoch: 5| Step: 3
Training loss: 2.7423300743103027
Validation loss: 2.0111561026624454

Epoch: 5| Step: 4
Training loss: 1.620255470275879
Validation loss: 2.0176261496800247

Epoch: 5| Step: 5
Training loss: 1.7058464288711548
Validation loss: 2.0148154971420125

Epoch: 5| Step: 6
Training loss: 1.8935142755508423
Validation loss: 2.036641009392277

Epoch: 5| Step: 7
Training loss: 2.013274669647217
Validation loss: 2.0563453756352907

Epoch: 5| Step: 8
Training loss: 0.9556368589401245
Validation loss: 2.082374417653648

Epoch: 5| Step: 9
Training loss: 1.8314710855484009
Validation loss: 2.0953722538486605

Epoch: 5| Step: 10
Training loss: 1.9549477100372314
Validation loss: 2.1763916412989297

Epoch: 142| Step: 0
Training loss: 1.7338298559188843
Validation loss: 2.2123709891432073

Epoch: 5| Step: 1
Training loss: 1.7494802474975586
Validation loss: 2.155499226303511

Epoch: 5| Step: 2
Training loss: 2.3465793132781982
Validation loss: 2.1250422962250246

Epoch: 5| Step: 3
Training loss: 1.069092035293579
Validation loss: 2.0891971998317267

Epoch: 5| Step: 4
Training loss: 1.9412133693695068
Validation loss: 2.0750037059989026

Epoch: 5| Step: 5
Training loss: 1.789736032485962
Validation loss: 2.0764749357777257

Epoch: 5| Step: 6
Training loss: 1.9398607015609741
Validation loss: 2.0722719520650883

Epoch: 5| Step: 7
Training loss: 1.7108652591705322
Validation loss: 2.0727196226837816

Epoch: 5| Step: 8
Training loss: 1.7394297122955322
Validation loss: 2.073137249997867

Epoch: 5| Step: 9
Training loss: 2.018308162689209
Validation loss: 2.0418355439298894

Epoch: 5| Step: 10
Training loss: 1.776136875152588
Validation loss: 2.0337522901514524

Epoch: 143| Step: 0
Training loss: 1.7689058780670166
Validation loss: 2.0240995935214463

Epoch: 5| Step: 1
Training loss: 2.2925822734832764
Validation loss: 1.994601885477702

Epoch: 5| Step: 2
Training loss: 2.0862441062927246
Validation loss: 2.0043173656668714

Epoch: 5| Step: 3
Training loss: 1.0877501964569092
Validation loss: 1.9903312101159045

Epoch: 5| Step: 4
Training loss: 1.9990218877792358
Validation loss: 2.0254108175154655

Epoch: 5| Step: 5
Training loss: 1.5061180591583252
Validation loss: 2.0810697001795613

Epoch: 5| Step: 6
Training loss: 1.7375209331512451
Validation loss: 2.14427843657873

Epoch: 5| Step: 7
Training loss: 1.6687854528427124
Validation loss: 2.1759572900751585

Epoch: 5| Step: 8
Training loss: 1.9038851261138916
Validation loss: 2.1167642903584305

Epoch: 5| Step: 9
Training loss: 1.7861769199371338
Validation loss: 2.047435880989157

Epoch: 5| Step: 10
Training loss: 1.9109584093093872
Validation loss: 2.0459021906698904

Epoch: 144| Step: 0
Training loss: 1.8279075622558594
Validation loss: 2.0247872990946614

Epoch: 5| Step: 1
Training loss: 1.549329161643982
Validation loss: 2.0332155048206286

Epoch: 5| Step: 2
Training loss: 1.6297531127929688
Validation loss: 2.0422447881390973

Epoch: 5| Step: 3
Training loss: 2.3646399974823
Validation loss: 2.0355458208309707

Epoch: 5| Step: 4
Training loss: 1.3915684223175049
Validation loss: 2.0200749238332114

Epoch: 5| Step: 5
Training loss: 2.041456699371338
Validation loss: 2.0353189540165726

Epoch: 5| Step: 6
Training loss: 1.916752815246582
Validation loss: 2.0934536610880206

Epoch: 5| Step: 7
Training loss: 1.6337745189666748
Validation loss: 2.1634675841177664

Epoch: 5| Step: 8
Training loss: 1.5776097774505615
Validation loss: 2.179139203922723

Epoch: 5| Step: 9
Training loss: 1.304842233657837
Validation loss: 2.186906683829523

Epoch: 5| Step: 10
Training loss: 2.5972001552581787
Validation loss: 2.1077008785740023

Epoch: 145| Step: 0
Training loss: 1.2243945598602295
Validation loss: 2.0513613916212514

Epoch: 5| Step: 1
Training loss: 1.0419774055480957
Validation loss: 2.0202564449720484

Epoch: 5| Step: 2
Training loss: 1.8516197204589844
Validation loss: 2.019383094644034

Epoch: 5| Step: 3
Training loss: 2.1551613807678223
Validation loss: 2.005168722521874

Epoch: 5| Step: 4
Training loss: 1.6428604125976562
Validation loss: 2.047229664300078

Epoch: 5| Step: 5
Training loss: 1.675233244895935
Validation loss: 2.0232674050074753

Epoch: 5| Step: 6
Training loss: 2.2940356731414795
Validation loss: 2.0262011071687103

Epoch: 5| Step: 7
Training loss: 2.0771756172180176
Validation loss: 2.0291146591145504

Epoch: 5| Step: 8
Training loss: 1.727695107460022
Validation loss: 2.021493158032817

Epoch: 5| Step: 9
Training loss: 2.0210187435150146
Validation loss: 2.0328383394466933

Epoch: 5| Step: 10
Training loss: 1.5237491130828857
Validation loss: 2.0608013368421987

Epoch: 146| Step: 0
Training loss: 2.2905566692352295
Validation loss: 2.0654231732891453

Epoch: 5| Step: 1
Training loss: 1.7743202447891235
Validation loss: 2.114736759534446

Epoch: 5| Step: 2
Training loss: 1.1954314708709717
Validation loss: 2.095770355193846

Epoch: 5| Step: 3
Training loss: 2.2538959980010986
Validation loss: 2.1003121329892065

Epoch: 5| Step: 4
Training loss: 1.34767746925354
Validation loss: 2.095060713829533

Epoch: 5| Step: 5
Training loss: 1.979065179824829
Validation loss: 2.0615794761206514

Epoch: 5| Step: 6
Training loss: 1.5226191282272339
Validation loss: 2.063664592722411

Epoch: 5| Step: 7
Training loss: 1.8847970962524414
Validation loss: 2.0508495774320377

Epoch: 5| Step: 8
Training loss: 1.4248292446136475
Validation loss: 2.0294546516992713

Epoch: 5| Step: 9
Training loss: 1.6386919021606445
Validation loss: 2.0351629385384182

Epoch: 5| Step: 10
Training loss: 1.4639666080474854
Validation loss: 2.0272722090444257

Epoch: 147| Step: 0
Training loss: 2.152904510498047
Validation loss: 2.036579401262345

Epoch: 5| Step: 1
Training loss: 2.241081714630127
Validation loss: 2.044869504949098

Epoch: 5| Step: 2
Training loss: 1.804384469985962
Validation loss: 2.0563726886626212

Epoch: 5| Step: 3
Training loss: 1.6127961874008179
Validation loss: 2.0576189282119914

Epoch: 5| Step: 4
Training loss: 1.5938518047332764
Validation loss: 2.069476601898029

Epoch: 5| Step: 5
Training loss: 1.5990180969238281
Validation loss: 2.046062446409656

Epoch: 5| Step: 6
Training loss: 1.5929312705993652
Validation loss: 2.0355495906645253

Epoch: 5| Step: 7
Training loss: 1.7974464893341064
Validation loss: 2.067191900745515

Epoch: 5| Step: 8
Training loss: 1.7503306865692139
Validation loss: 2.073950065079556

Epoch: 5| Step: 9
Training loss: 1.0297330617904663
Validation loss: 2.0334032889335387

Epoch: 5| Step: 10
Training loss: 1.8403980731964111
Validation loss: 2.0804275646004626

Epoch: 148| Step: 0
Training loss: 1.3571465015411377
Validation loss: 2.0790512920707784

Epoch: 5| Step: 1
Training loss: 1.8124557733535767
Validation loss: 2.058102971764021

Epoch: 5| Step: 2
Training loss: 1.377428412437439
Validation loss: 2.026268172007735

Epoch: 5| Step: 3
Training loss: 2.0858724117279053
Validation loss: 1.992149390200133

Epoch: 5| Step: 4
Training loss: 2.1132001876831055
Validation loss: 1.9905118224441365

Epoch: 5| Step: 5
Training loss: 1.5937087535858154
Validation loss: 1.973039157928959

Epoch: 5| Step: 6
Training loss: 1.5394612550735474
Validation loss: 1.9422584438836703

Epoch: 5| Step: 7
Training loss: 1.3589972257614136
Validation loss: 1.9547085890205957

Epoch: 5| Step: 8
Training loss: 1.731630563735962
Validation loss: 1.9761813045829855

Epoch: 5| Step: 9
Training loss: 2.0152385234832764
Validation loss: 2.0638727321419665

Epoch: 5| Step: 10
Training loss: 1.8991531133651733
Validation loss: 2.1397003819865565

Epoch: 149| Step: 0
Training loss: 1.4471498727798462
Validation loss: 2.1885299631344375

Epoch: 5| Step: 1
Training loss: 1.6268653869628906
Validation loss: 2.2110550890686693

Epoch: 5| Step: 2
Training loss: 1.4978530406951904
Validation loss: 2.2084821219085367

Epoch: 5| Step: 3
Training loss: 2.0287859439849854
Validation loss: 2.1554982662200928

Epoch: 5| Step: 4
Training loss: 1.43584406375885
Validation loss: 2.089025748673306

Epoch: 5| Step: 5
Training loss: 1.8865540027618408
Validation loss: 2.0534027827683317

Epoch: 5| Step: 6
Training loss: 1.538588285446167
Validation loss: 2.0053625388811995

Epoch: 5| Step: 7
Training loss: 1.7515283823013306
Validation loss: 1.9972842995838453

Epoch: 5| Step: 8
Training loss: 1.9796018600463867
Validation loss: 2.0085744883424494

Epoch: 5| Step: 9
Training loss: 1.444786787033081
Validation loss: 2.0133776844188733

Epoch: 5| Step: 10
Training loss: 2.130913257598877
Validation loss: 2.044563535721071

Epoch: 150| Step: 0
Training loss: 1.805639624595642
Validation loss: 2.027821267804792

Epoch: 5| Step: 1
Training loss: 1.2480201721191406
Validation loss: 2.0030831560011833

Epoch: 5| Step: 2
Training loss: 1.293156623840332
Validation loss: 1.9952757999461184

Epoch: 5| Step: 3
Training loss: 1.8692102432250977
Validation loss: 1.964112397163145

Epoch: 5| Step: 4
Training loss: 1.919037103652954
Validation loss: 1.9764391094125726

Epoch: 5| Step: 5
Training loss: 1.411802887916565
Validation loss: 1.9868569015174784

Epoch: 5| Step: 6
Training loss: 2.05462384223938
Validation loss: 1.9763270936986452

Epoch: 5| Step: 7
Training loss: 1.6565887928009033
Validation loss: 1.9781338527638426

Epoch: 5| Step: 8
Training loss: 2.1696066856384277
Validation loss: 2.0191941184382283

Epoch: 5| Step: 9
Training loss: 1.5779082775115967
Validation loss: 2.0489039831264044

Epoch: 5| Step: 10
Training loss: 1.0081474781036377
Validation loss: 2.0956361319429133

Epoch: 151| Step: 0
Training loss: 1.4936777353286743
Validation loss: 2.0997912165939168

Epoch: 5| Step: 1
Training loss: 1.680702805519104
Validation loss: 2.133024054188882

Epoch: 5| Step: 2
Training loss: 2.089000701904297
Validation loss: 2.160726084504076

Epoch: 5| Step: 3
Training loss: 1.62039053440094
Validation loss: 2.12800770677546

Epoch: 5| Step: 4
Training loss: 1.3730154037475586
Validation loss: 2.13247158194101

Epoch: 5| Step: 5
Training loss: 1.8721641302108765
Validation loss: 2.0935332903298

Epoch: 5| Step: 6
Training loss: 2.0926308631896973
Validation loss: 2.036231517791748

Epoch: 5| Step: 7
Training loss: 1.3322409391403198
Validation loss: 1.988188398781643

Epoch: 5| Step: 8
Training loss: 1.6370136737823486
Validation loss: 1.9660740116591096

Epoch: 5| Step: 9
Training loss: 1.6032766103744507
Validation loss: 1.960394021003477

Epoch: 5| Step: 10
Training loss: 1.3814527988433838
Validation loss: 1.9547937903352963

Epoch: 152| Step: 0
Training loss: 1.6852411031723022
Validation loss: 1.974736790503225

Epoch: 5| Step: 1
Training loss: 1.6228382587432861
Validation loss: 1.9582211996919365

Epoch: 5| Step: 2
Training loss: 1.7211440801620483
Validation loss: 1.9599443956087994

Epoch: 5| Step: 3
Training loss: 1.1399867534637451
Validation loss: 1.9937239334147463

Epoch: 5| Step: 4
Training loss: 2.2310125827789307
Validation loss: 2.029883856414467

Epoch: 5| Step: 5
Training loss: 1.6481750011444092
Validation loss: 2.081584345909857

Epoch: 5| Step: 6
Training loss: 1.8602492809295654
Validation loss: 2.1256603387094315

Epoch: 5| Step: 7
Training loss: 1.3140212297439575
Validation loss: 2.0963934890685545

Epoch: 5| Step: 8
Training loss: 1.4087531566619873
Validation loss: 2.0504825794568626

Epoch: 5| Step: 9
Training loss: 1.6790260076522827
Validation loss: 2.0541098861284155

Epoch: 5| Step: 10
Training loss: 1.759577751159668
Validation loss: 2.0043653442013647

Epoch: 153| Step: 0
Training loss: 1.4726142883300781
Validation loss: 2.0107386201940556

Epoch: 5| Step: 1
Training loss: 1.6503379344940186
Validation loss: 1.9989264165201495

Epoch: 5| Step: 2
Training loss: 2.028269052505493
Validation loss: 2.047198345584254

Epoch: 5| Step: 3
Training loss: 1.1500948667526245
Validation loss: 2.1021157592855473

Epoch: 5| Step: 4
Training loss: 1.9002854824066162
Validation loss: 2.061212940882611

Epoch: 5| Step: 5
Training loss: 1.2107475996017456
Validation loss: 2.0237852655431277

Epoch: 5| Step: 6
Training loss: 1.2166715860366821
Validation loss: 1.9807601308309903

Epoch: 5| Step: 7
Training loss: 1.3678823709487915
Validation loss: 2.008856893867575

Epoch: 5| Step: 8
Training loss: 2.149282455444336
Validation loss: 2.039060531123992

Epoch: 5| Step: 9
Training loss: 1.341291069984436
Validation loss: 2.0752832158919303

Epoch: 5| Step: 10
Training loss: 2.6034679412841797
Validation loss: 2.088254027469184

Epoch: 154| Step: 0
Training loss: 1.7327995300292969
Validation loss: 2.087777442829583

Epoch: 5| Step: 1
Training loss: 1.7459640502929688
Validation loss: 2.0890277252402356

Epoch: 5| Step: 2
Training loss: 1.647438406944275
Validation loss: 2.0881870562030422

Epoch: 5| Step: 3
Training loss: 1.8701947927474976
Validation loss: 2.1018711020869594

Epoch: 5| Step: 4
Training loss: 1.1827828884124756
Validation loss: 2.100172701702323

Epoch: 5| Step: 5
Training loss: 1.5176836252212524
Validation loss: 2.085301301812613

Epoch: 5| Step: 6
Training loss: 1.671011209487915
Validation loss: 2.043676427615586

Epoch: 5| Step: 7
Training loss: 1.4841312170028687
Validation loss: 2.0391325732713104

Epoch: 5| Step: 8
Training loss: 1.6650683879852295
Validation loss: 2.0139330574261245

Epoch: 5| Step: 9
Training loss: 1.4805234670639038
Validation loss: 2.0017588869217904

Epoch: 5| Step: 10
Training loss: 1.577083945274353
Validation loss: 1.9963800843043993

Epoch: 155| Step: 0
Training loss: 1.7171560525894165
Validation loss: 2.0162842504439817

Epoch: 5| Step: 1
Training loss: 1.7751789093017578
Validation loss: 2.020978396938693

Epoch: 5| Step: 2
Training loss: 2.048567295074463
Validation loss: 2.056332313886253

Epoch: 5| Step: 3
Training loss: 1.6104949712753296
Validation loss: 2.084703048070272

Epoch: 5| Step: 4
Training loss: 1.6019929647445679
Validation loss: 2.0899994783504035

Epoch: 5| Step: 5
Training loss: 1.6970043182373047
Validation loss: 2.0985480687951528

Epoch: 5| Step: 6
Training loss: 1.8263816833496094
Validation loss: 2.0716918309529624

Epoch: 5| Step: 7
Training loss: 1.1195441484451294
Validation loss: 2.0408294559806905

Epoch: 5| Step: 8
Training loss: 1.1307682991027832
Validation loss: 2.028378773761052

Epoch: 5| Step: 9
Training loss: 1.5957996845245361
Validation loss: 2.0032833058346986

Epoch: 5| Step: 10
Training loss: 1.5107842683792114
Validation loss: 2.003418687851198

Epoch: 156| Step: 0
Training loss: 1.6179091930389404
Validation loss: 2.0080242438982894

Epoch: 5| Step: 1
Training loss: 1.2035443782806396
Validation loss: 1.990340801977342

Epoch: 5| Step: 2
Training loss: 2.5218536853790283
Validation loss: 2.0128496282844135

Epoch: 5| Step: 3
Training loss: 1.088768720626831
Validation loss: 2.04167910545103

Epoch: 5| Step: 4
Training loss: 1.2077000141143799
Validation loss: 2.031596019703855

Epoch: 5| Step: 5
Training loss: 1.4000290632247925
Validation loss: 2.0441021637250016

Epoch: 5| Step: 6
Training loss: 1.4719289541244507
Validation loss: 2.0317971398753505

Epoch: 5| Step: 7
Training loss: 1.377924919128418
Validation loss: 2.0352980206089635

Epoch: 5| Step: 8
Training loss: 1.970407485961914
Validation loss: 2.0274053030116583

Epoch: 5| Step: 9
Training loss: 1.4698326587677002
Validation loss: 1.9998715308404738

Epoch: 5| Step: 10
Training loss: 1.8299559354782104
Validation loss: 2.0190000841694493

Epoch: 157| Step: 0
Training loss: 1.2648570537567139
Validation loss: 2.034580485795134

Epoch: 5| Step: 1
Training loss: 1.9448292255401611
Validation loss: 2.0389190514882407

Epoch: 5| Step: 2
Training loss: 1.7401130199432373
Validation loss: 2.0115226571277907

Epoch: 5| Step: 3
Training loss: 1.7481365203857422
Validation loss: 1.979705100418419

Epoch: 5| Step: 4
Training loss: 1.7056608200073242
Validation loss: 1.9780725663708103

Epoch: 5| Step: 5
Training loss: 1.8909146785736084
Validation loss: 1.9930186861304826

Epoch: 5| Step: 6
Training loss: 1.4082880020141602
Validation loss: 2.0172021260825534

Epoch: 5| Step: 7
Training loss: 1.0748399496078491
Validation loss: 2.030098807427191

Epoch: 5| Step: 8
Training loss: 2.0552754402160645
Validation loss: 2.0419191442510134

Epoch: 5| Step: 9
Training loss: 1.369582176208496
Validation loss: 2.0524302554386917

Epoch: 5| Step: 10
Training loss: 0.8989269137382507
Validation loss: 2.0523188293621106

Epoch: 158| Step: 0
Training loss: 1.5908567905426025
Validation loss: 2.085038605556693

Epoch: 5| Step: 1
Training loss: 1.3972294330596924
Validation loss: 2.102914951180899

Epoch: 5| Step: 2
Training loss: 1.4003123044967651
Validation loss: 2.143018150842318

Epoch: 5| Step: 3
Training loss: 1.9818092584609985
Validation loss: 2.185043973307456

Epoch: 5| Step: 4
Training loss: 1.4958103895187378
Validation loss: 2.2049108961577057

Epoch: 5| Step: 5
Training loss: 1.5373197793960571
Validation loss: 2.1913297612179994

Epoch: 5| Step: 6
Training loss: 2.044351577758789
Validation loss: 2.1533504327138266

Epoch: 5| Step: 7
Training loss: 0.9867555499076843
Validation loss: 2.0968498183834936

Epoch: 5| Step: 8
Training loss: 1.792220115661621
Validation loss: 2.039190879432104

Epoch: 5| Step: 9
Training loss: 1.84384024143219
Validation loss: 2.033188409702752

Epoch: 5| Step: 10
Training loss: 1.129219651222229
Validation loss: 2.0123000350049747

Epoch: 159| Step: 0
Training loss: 1.716233491897583
Validation loss: 2.006951317992262

Epoch: 5| Step: 1
Training loss: 1.4460432529449463
Validation loss: 2.0231897984781573

Epoch: 5| Step: 2
Training loss: 0.8648325800895691
Validation loss: 2.039844464230281

Epoch: 5| Step: 3
Training loss: 1.208279013633728
Validation loss: 2.0404542043644893

Epoch: 5| Step: 4
Training loss: 1.764135718345642
Validation loss: 2.0652667630103325

Epoch: 5| Step: 5
Training loss: 2.1275134086608887
Validation loss: 2.072178174090642

Epoch: 5| Step: 6
Training loss: 1.3393852710723877
Validation loss: 2.0571108479653635

Epoch: 5| Step: 7
Training loss: 1.4753246307373047
Validation loss: 2.04083752119413

Epoch: 5| Step: 8
Training loss: 1.5586820840835571
Validation loss: 2.046511834667575

Epoch: 5| Step: 9
Training loss: 1.6486425399780273
Validation loss: 2.030361147337062

Epoch: 5| Step: 10
Training loss: 1.6475526094436646
Validation loss: 2.000822574861588

Epoch: 160| Step: 0
Training loss: 1.471391201019287
Validation loss: 2.0080966488007577

Epoch: 5| Step: 1
Training loss: 1.4919357299804688
Validation loss: 2.016629660001365

Epoch: 5| Step: 2
Training loss: 1.7485692501068115
Validation loss: 2.016819638590659

Epoch: 5| Step: 3
Training loss: 1.2182929515838623
Validation loss: 2.01861410756265

Epoch: 5| Step: 4
Training loss: 1.3243433237075806
Validation loss: 2.0496349014261717

Epoch: 5| Step: 5
Training loss: 2.2105321884155273
Validation loss: 2.0116632279529365

Epoch: 5| Step: 6
Training loss: 1.2025363445281982
Validation loss: 1.979708510060464

Epoch: 5| Step: 7
Training loss: 1.7388973236083984
Validation loss: 1.9833719345831102

Epoch: 5| Step: 8
Training loss: 1.4525978565216064
Validation loss: 2.0164192004870345

Epoch: 5| Step: 9
Training loss: 1.645803689956665
Validation loss: 2.008088127259285

Epoch: 5| Step: 10
Training loss: 1.0286771059036255
Validation loss: 2.0390539989676526

Epoch: 161| Step: 0
Training loss: 0.6802424192428589
Validation loss: 2.0543288787206015

Epoch: 5| Step: 1
Training loss: 1.5099031925201416
Validation loss: 2.069568439196515

Epoch: 5| Step: 2
Training loss: 0.9901858568191528
Validation loss: 2.0616785005856584

Epoch: 5| Step: 3
Training loss: 1.709450125694275
Validation loss: 2.0825938127374135

Epoch: 5| Step: 4
Training loss: 1.258618950843811
Validation loss: 2.0598800656616048

Epoch: 5| Step: 5
Training loss: 1.0043361186981201
Validation loss: 2.066250789550043

Epoch: 5| Step: 6
Training loss: 2.2907214164733887
Validation loss: 2.072852808942077

Epoch: 5| Step: 7
Training loss: 1.7357771396636963
Validation loss: 2.08175128634258

Epoch: 5| Step: 8
Training loss: 1.7994201183319092
Validation loss: 2.080747991479853

Epoch: 5| Step: 9
Training loss: 2.047581195831299
Validation loss: 2.069980131682529

Epoch: 5| Step: 10
Training loss: 1.2533055543899536
Validation loss: 2.029142636124806

Epoch: 162| Step: 0
Training loss: 1.0544933080673218
Validation loss: 2.0213358966253137

Epoch: 5| Step: 1
Training loss: 1.3327834606170654
Validation loss: 1.994867645284181

Epoch: 5| Step: 2
Training loss: 1.4458554983139038
Validation loss: 1.9984404707467684

Epoch: 5| Step: 3
Training loss: 1.8607765436172485
Validation loss: 1.9941994515798425

Epoch: 5| Step: 4
Training loss: 1.7421249151229858
Validation loss: 2.0103492685543594

Epoch: 5| Step: 5
Training loss: 1.207350730895996
Validation loss: 2.0508192892997497

Epoch: 5| Step: 6
Training loss: 1.2938073873519897
Validation loss: 2.0438527420002925

Epoch: 5| Step: 7
Training loss: 1.5021603107452393
Validation loss: 2.065054678147839

Epoch: 5| Step: 8
Training loss: 1.8585004806518555
Validation loss: 2.0697147013038717

Epoch: 5| Step: 9
Training loss: 1.5552091598510742
Validation loss: 2.0279264552618868

Epoch: 5| Step: 10
Training loss: 1.280168056488037
Validation loss: 2.004422762060678

Epoch: 163| Step: 0
Training loss: 1.7185516357421875
Validation loss: 1.9935786724090576

Epoch: 5| Step: 1
Training loss: 1.8298141956329346
Validation loss: 2.008197944651368

Epoch: 5| Step: 2
Training loss: 1.6088626384735107
Validation loss: 1.9940267788466586

Epoch: 5| Step: 3
Training loss: 1.4711910486221313
Validation loss: 1.9906182007123066

Epoch: 5| Step: 4
Training loss: 1.480457067489624
Validation loss: 2.0044957027640393

Epoch: 5| Step: 5
Training loss: 1.046156883239746
Validation loss: 2.0386955686794814

Epoch: 5| Step: 6
Training loss: 1.2392606735229492
Validation loss: 2.103652231154903

Epoch: 5| Step: 7
Training loss: 1.1083184480667114
Validation loss: 2.1070881364166096

Epoch: 5| Step: 8
Training loss: 2.271139621734619
Validation loss: 2.1173980005325808

Epoch: 5| Step: 9
Training loss: 0.8347511291503906
Validation loss: 2.1603639125823975

Epoch: 5| Step: 10
Training loss: 1.4387483596801758
Validation loss: 2.1689273926519577

Epoch: 164| Step: 0
Training loss: 1.6751644611358643
Validation loss: 2.2001395238343107

Epoch: 5| Step: 1
Training loss: 2.1023354530334473
Validation loss: 2.1989872019778014

Epoch: 5| Step: 2
Training loss: 1.3383320569992065
Validation loss: 2.1854989554292414

Epoch: 5| Step: 3
Training loss: 0.8606626391410828
Validation loss: 2.115923734121425

Epoch: 5| Step: 4
Training loss: 1.643193244934082
Validation loss: 2.068489961726691

Epoch: 5| Step: 5
Training loss: 1.9339752197265625
Validation loss: 2.0263094517492477

Epoch: 5| Step: 6
Training loss: 1.3674380779266357
Validation loss: 1.9874644176934355

Epoch: 5| Step: 7
Training loss: 1.2479215860366821
Validation loss: 1.9931938404678016

Epoch: 5| Step: 8
Training loss: 1.4435876607894897
Validation loss: 1.985758819887715

Epoch: 5| Step: 9
Training loss: 1.4256244897842407
Validation loss: 1.9930312197695497

Epoch: 5| Step: 10
Training loss: 1.1782336235046387
Validation loss: 1.9975999081006615

Epoch: 165| Step: 0
Training loss: 1.5273802280426025
Validation loss: 2.049134692838115

Epoch: 5| Step: 1
Training loss: 2.1161067485809326
Validation loss: 2.080990525983995

Epoch: 5| Step: 2
Training loss: 1.0545730590820312
Validation loss: 2.0700844257108626

Epoch: 5| Step: 3
Training loss: 1.319887399673462
Validation loss: 2.025544351147067

Epoch: 5| Step: 4
Training loss: 1.091626524925232
Validation loss: 2.012680325456845

Epoch: 5| Step: 5
Training loss: 1.7686103582382202
Validation loss: 2.013723655413556

Epoch: 5| Step: 6
Training loss: 1.5000580549240112
Validation loss: 2.0023315375851047

Epoch: 5| Step: 7
Training loss: 1.5166860818862915
Validation loss: 1.9869118095726095

Epoch: 5| Step: 8
Training loss: 1.4610207080841064
Validation loss: 1.9967394105849727

Epoch: 5| Step: 9
Training loss: 1.2636898756027222
Validation loss: 1.9905861052133704

Epoch: 5| Step: 10
Training loss: 1.3313895463943481
Validation loss: 2.0180504604052474

Epoch: 166| Step: 0
Training loss: 1.5621436834335327
Validation loss: 2.0474845927248717

Epoch: 5| Step: 1
Training loss: 1.4005366563796997
Validation loss: 2.065671545203014

Epoch: 5| Step: 2
Training loss: 1.6140859127044678
Validation loss: 2.087000016243227

Epoch: 5| Step: 3
Training loss: 0.7420856356620789
Validation loss: 2.0557001611237884

Epoch: 5| Step: 4
Training loss: 1.8381801843643188
Validation loss: 2.0479182017746793

Epoch: 5| Step: 5
Training loss: 1.8521064519882202
Validation loss: 2.033992418678858

Epoch: 5| Step: 6
Training loss: 1.8531948328018188
Validation loss: 2.0220098277573944

Epoch: 5| Step: 7
Training loss: 0.9331514239311218
Validation loss: 2.0223618066439064

Epoch: 5| Step: 8
Training loss: 0.9966041445732117
Validation loss: 2.042830231369183

Epoch: 5| Step: 9
Training loss: 1.4532935619354248
Validation loss: 2.061335958460326

Epoch: 5| Step: 10
Training loss: 1.3437174558639526
Validation loss: 2.044253885105092

Epoch: 167| Step: 0
Training loss: 1.3432317972183228
Validation loss: 2.0528696583163355

Epoch: 5| Step: 1
Training loss: 1.7429273128509521
Validation loss: 2.0450455680970223

Epoch: 5| Step: 2
Training loss: 1.1502392292022705
Validation loss: 2.0162603855133057

Epoch: 5| Step: 3
Training loss: 1.2905975580215454
Validation loss: 2.023485058097429

Epoch: 5| Step: 4
Training loss: 1.1249535083770752
Validation loss: 2.0413789262053785

Epoch: 5| Step: 5
Training loss: 1.4403455257415771
Validation loss: 2.0341144633549515

Epoch: 5| Step: 6
Training loss: 1.4818859100341797
Validation loss: 2.0232529896561817

Epoch: 5| Step: 7
Training loss: 1.301708459854126
Validation loss: 2.0441779628876717

Epoch: 5| Step: 8
Training loss: 1.3718427419662476
Validation loss: 2.012508156479046

Epoch: 5| Step: 9
Training loss: 1.523245096206665
Validation loss: 2.003774522453226

Epoch: 5| Step: 10
Training loss: 1.6411128044128418
Validation loss: 1.9888957777330953

Epoch: 168| Step: 0
Training loss: 1.2023704051971436
Validation loss: 2.0360969189674623

Epoch: 5| Step: 1
Training loss: 1.5819588899612427
Validation loss: 2.033022940799754

Epoch: 5| Step: 2
Training loss: 1.3964550495147705
Validation loss: 2.044810718105685

Epoch: 5| Step: 3
Training loss: 1.59805166721344
Validation loss: 2.0439910811762654

Epoch: 5| Step: 4
Training loss: 0.8829150199890137
Validation loss: 2.026130582696648

Epoch: 5| Step: 5
Training loss: 1.0398013591766357
Validation loss: 2.004424043880996

Epoch: 5| Step: 6
Training loss: 1.5033502578735352
Validation loss: 2.027770442347373

Epoch: 5| Step: 7
Training loss: 0.8763615489006042
Validation loss: 2.0436089961759505

Epoch: 5| Step: 8
Training loss: 1.5770788192749023
Validation loss: 2.0450302990533973

Epoch: 5| Step: 9
Training loss: 2.3257579803466797
Validation loss: 2.059139387581938

Epoch: 5| Step: 10
Training loss: 1.3816627264022827
Validation loss: 2.0470593911345287

Epoch: 169| Step: 0
Training loss: 0.9307217597961426
Validation loss: 2.0045133431752524

Epoch: 5| Step: 1
Training loss: 1.2967605590820312
Validation loss: 1.9892888774154007

Epoch: 5| Step: 2
Training loss: 1.6778711080551147
Validation loss: 1.993184494715865

Epoch: 5| Step: 3
Training loss: 1.5353505611419678
Validation loss: 2.0170668222570933

Epoch: 5| Step: 4
Training loss: 0.8397420644760132
Validation loss: 2.0685077405744985

Epoch: 5| Step: 5
Training loss: 1.2673447132110596
Validation loss: 2.0993316199189875

Epoch: 5| Step: 6
Training loss: 1.6965967416763306
Validation loss: 2.056106327682413

Epoch: 5| Step: 7
Training loss: 1.5418505668640137
Validation loss: 2.0332215370670443

Epoch: 5| Step: 8
Training loss: 1.2419803142547607
Validation loss: 2.028670157155683

Epoch: 5| Step: 9
Training loss: 1.5934085845947266
Validation loss: 2.0503783931014357

Epoch: 5| Step: 10
Training loss: 1.786163330078125
Validation loss: 2.0512522600030385

Epoch: 170| Step: 0
Training loss: 1.2217174768447876
Validation loss: 2.052439384562995

Epoch: 5| Step: 1
Training loss: 1.1904489994049072
Validation loss: 2.023684240156604

Epoch: 5| Step: 2
Training loss: 0.9970033764839172
Validation loss: 2.028500090363205

Epoch: 5| Step: 3
Training loss: 1.2478206157684326
Validation loss: 2.0296684747101157

Epoch: 5| Step: 4
Training loss: 1.4024754762649536
Validation loss: 2.0270043714072115

Epoch: 5| Step: 5
Training loss: 1.5807063579559326
Validation loss: 2.0007026605708624

Epoch: 5| Step: 6
Training loss: 1.7193657159805298
Validation loss: 1.9849743253441268

Epoch: 5| Step: 7
Training loss: 1.3623840808868408
Validation loss: 1.9906711514278124

Epoch: 5| Step: 8
Training loss: 1.5157215595245361
Validation loss: 2.0208763204595095

Epoch: 5| Step: 9
Training loss: 1.4874908924102783
Validation loss: 2.0234692378710677

Epoch: 5| Step: 10
Training loss: 1.4493780136108398
Validation loss: 2.0248758587785947

Epoch: 171| Step: 0
Training loss: 0.5578252077102661
Validation loss: 2.0214085681464082

Epoch: 5| Step: 1
Training loss: 1.3669960498809814
Validation loss: 2.0344170447318786

Epoch: 5| Step: 2
Training loss: 1.1959401369094849
Validation loss: 2.0468861569640455

Epoch: 5| Step: 3
Training loss: 1.7854830026626587
Validation loss: 2.0354502252353135

Epoch: 5| Step: 4
Training loss: 1.4535123109817505
Validation loss: 2.046969549630278

Epoch: 5| Step: 5
Training loss: 1.4400663375854492
Validation loss: 1.9952984856021019

Epoch: 5| Step: 6
Training loss: 1.4392659664154053
Validation loss: 2.026657123719492

Epoch: 5| Step: 7
Training loss: 1.1095325946807861
Validation loss: 2.0444927266848985

Epoch: 5| Step: 8
Training loss: 1.7498095035552979
Validation loss: 2.0718492436152633

Epoch: 5| Step: 9
Training loss: 1.421605110168457
Validation loss: 2.0674982968197075

Epoch: 5| Step: 10
Training loss: 1.495705246925354
Validation loss: 2.0290502399526615

Epoch: 172| Step: 0
Training loss: 1.463473916053772
Validation loss: 1.9912722815749466

Epoch: 5| Step: 1
Training loss: 1.4113638401031494
Validation loss: 1.9770661092573596

Epoch: 5| Step: 2
Training loss: 1.30484938621521
Validation loss: 1.9770259857177734

Epoch: 5| Step: 3
Training loss: 1.5057947635650635
Validation loss: 2.0043922162825063

Epoch: 5| Step: 4
Training loss: 0.8889942169189453
Validation loss: 2.0011437592967862

Epoch: 5| Step: 5
Training loss: 1.2559127807617188
Validation loss: 2.039943407940608

Epoch: 5| Step: 6
Training loss: 1.6064872741699219
Validation loss: 2.04762666456161

Epoch: 5| Step: 7
Training loss: 1.2724816799163818
Validation loss: 2.064829851991387

Epoch: 5| Step: 8
Training loss: 1.362783432006836
Validation loss: 2.060131137089063

Epoch: 5| Step: 9
Training loss: 1.5481469631195068
Validation loss: 2.008841973479076

Epoch: 5| Step: 10
Training loss: 1.0584096908569336
Validation loss: 1.9941596318316717

Epoch: 173| Step: 0
Training loss: 1.301365613937378
Validation loss: 1.982511858786306

Epoch: 5| Step: 1
Training loss: 1.0518567562103271
Validation loss: 1.9672770423273886

Epoch: 5| Step: 2
Training loss: 1.0350440740585327
Validation loss: 1.9505895453114663

Epoch: 5| Step: 3
Training loss: 1.2069661617279053
Validation loss: 1.9817167815341745

Epoch: 5| Step: 4
Training loss: 1.1952521800994873
Validation loss: 1.9957970521783317

Epoch: 5| Step: 5
Training loss: 0.8163703083992004
Validation loss: 2.01448683328526

Epoch: 5| Step: 6
Training loss: 1.848557710647583
Validation loss: 2.021056621305404

Epoch: 5| Step: 7
Training loss: 1.2379921674728394
Validation loss: 1.996161304494386

Epoch: 5| Step: 8
Training loss: 1.7439628839492798
Validation loss: 1.9967482371996808

Epoch: 5| Step: 9
Training loss: 1.7379086017608643
Validation loss: 1.9917325973510742

Epoch: 5| Step: 10
Training loss: 1.4202632904052734
Validation loss: 1.9944572269275624

Epoch: 174| Step: 0
Training loss: 1.7001283168792725
Validation loss: 1.9871386302414762

Epoch: 5| Step: 1
Training loss: 1.3029037714004517
Validation loss: 1.9833188595310334

Epoch: 5| Step: 2
Training loss: 0.9531220197677612
Validation loss: 1.9534758060209212

Epoch: 5| Step: 3
Training loss: 1.2891581058502197
Validation loss: 1.9628640195374847

Epoch: 5| Step: 4
Training loss: 1.1646933555603027
Validation loss: 1.9913891182150891

Epoch: 5| Step: 5
Training loss: 1.5764272212982178
Validation loss: 1.9799956108934136

Epoch: 5| Step: 6
Training loss: 1.2697010040283203
Validation loss: 1.9843391961948846

Epoch: 5| Step: 7
Training loss: 1.863279104232788
Validation loss: 1.9873031877702283

Epoch: 5| Step: 8
Training loss: 1.614884614944458
Validation loss: 1.9788459757322907

Epoch: 5| Step: 9
Training loss: 0.900438666343689
Validation loss: 2.0038447328793105

Epoch: 5| Step: 10
Training loss: 0.8321177363395691
Validation loss: 2.064835571473645

Epoch: 175| Step: 0
Training loss: 1.5721396207809448
Validation loss: 2.0769229242878575

Epoch: 5| Step: 1
Training loss: 1.4040710926055908
Validation loss: 2.1405204483257827

Epoch: 5| Step: 2
Training loss: 0.7432721853256226
Validation loss: 2.1645120318217943

Epoch: 5| Step: 3
Training loss: 1.3223096132278442
Validation loss: 2.0901505485657723

Epoch: 5| Step: 4
Training loss: 1.5084739923477173
Validation loss: 2.046063479556832

Epoch: 5| Step: 5
Training loss: 1.3570005893707275
Validation loss: 2.05329631733638

Epoch: 5| Step: 6
Training loss: 1.0625629425048828
Validation loss: 2.0319891360498246

Epoch: 5| Step: 7
Training loss: 1.7020162343978882
Validation loss: 2.027997656535077

Epoch: 5| Step: 8
Training loss: 1.4910129308700562
Validation loss: 1.993585478874945

Epoch: 5| Step: 9
Training loss: 0.956550121307373
Validation loss: 1.9671831130981445

Epoch: 5| Step: 10
Training loss: 1.606611728668213
Validation loss: 2.016458844625822

Epoch: 176| Step: 0
Training loss: 1.162125825881958
Validation loss: 2.077585292118852

Epoch: 5| Step: 1
Training loss: 1.0985829830169678
Validation loss: 2.1210293410926737

Epoch: 5| Step: 2
Training loss: 1.950055718421936
Validation loss: 2.1450297832489014

Epoch: 5| Step: 3
Training loss: 1.408976674079895
Validation loss: 2.0618641068858485

Epoch: 5| Step: 4
Training loss: 1.7480170726776123
Validation loss: 2.0137713186202513

Epoch: 5| Step: 5
Training loss: 0.7204983830451965
Validation loss: 2.0369217972601614

Epoch: 5| Step: 6
Training loss: 0.9282617568969727
Validation loss: 2.033560388831682

Epoch: 5| Step: 7
Training loss: 1.0964772701263428
Validation loss: 2.011985312225998

Epoch: 5| Step: 8
Training loss: 1.3968751430511475
Validation loss: 1.9652869573203466

Epoch: 5| Step: 9
Training loss: 1.6952970027923584
Validation loss: 1.9440937119145547

Epoch: 5| Step: 10
Training loss: 1.951165795326233
Validation loss: 1.9324734364786456

Epoch: 177| Step: 0
Training loss: 1.1185405254364014
Validation loss: 1.9744456993636263

Epoch: 5| Step: 1
Training loss: 1.4214072227478027
Validation loss: 2.0925620499477593

Epoch: 5| Step: 2
Training loss: 1.7569633722305298
Validation loss: 2.152299911745133

Epoch: 5| Step: 3
Training loss: 1.6806529760360718
Validation loss: 2.1656994588913454

Epoch: 5| Step: 4
Training loss: 1.3981192111968994
Validation loss: 2.1153987735830326

Epoch: 5| Step: 5
Training loss: 1.396124005317688
Validation loss: 2.060698829671388

Epoch: 5| Step: 6
Training loss: 1.1791213750839233
Validation loss: 2.0283305926989486

Epoch: 5| Step: 7
Training loss: 0.8772951364517212
Validation loss: 2.049513716851511

Epoch: 5| Step: 8
Training loss: 1.1402103900909424
Validation loss: 2.0347970006286458

Epoch: 5| Step: 9
Training loss: 1.3653829097747803
Validation loss: 2.064427762903193

Epoch: 5| Step: 10
Training loss: 1.612256646156311
Validation loss: 2.113815851109002

Epoch: 178| Step: 0
Training loss: 1.3449960947036743
Validation loss: 2.12860627840924

Epoch: 5| Step: 1
Training loss: 0.9655770063400269
Validation loss: 2.137899973059213

Epoch: 5| Step: 2
Training loss: 1.571179747581482
Validation loss: 2.0680132912051294

Epoch: 5| Step: 3
Training loss: 1.2296117544174194
Validation loss: 2.0225510187046503

Epoch: 5| Step: 4
Training loss: 0.9136813879013062
Validation loss: 2.0244585006467757

Epoch: 5| Step: 5
Training loss: 1.6445567607879639
Validation loss: 2.021937753564568

Epoch: 5| Step: 6
Training loss: 1.5678554773330688
Validation loss: 2.012039088433789

Epoch: 5| Step: 7
Training loss: 1.6246557235717773
Validation loss: 1.99911392119623

Epoch: 5| Step: 8
Training loss: 1.4841892719268799
Validation loss: 1.9962411516456193

Epoch: 5| Step: 9
Training loss: 1.189607858657837
Validation loss: 2.0032644297486994

Epoch: 5| Step: 10
Training loss: 1.1713762283325195
Validation loss: 1.9814582486306467

Epoch: 179| Step: 0
Training loss: 1.1416876316070557
Validation loss: 2.037923953866446

Epoch: 5| Step: 1
Training loss: 1.5792591571807861
Validation loss: 2.0475207131396056

Epoch: 5| Step: 2
Training loss: 0.4974418580532074
Validation loss: 2.076952370264197

Epoch: 5| Step: 3
Training loss: 1.6567710638046265
Validation loss: 2.122672966731492

Epoch: 5| Step: 4
Training loss: 1.3786109685897827
Validation loss: 2.1375075206961682

Epoch: 5| Step: 5
Training loss: 1.4037575721740723
Validation loss: 2.2027935699750016

Epoch: 5| Step: 6
Training loss: 1.4993631839752197
Validation loss: 2.155844480760636

Epoch: 5| Step: 7
Training loss: 1.3980406522750854
Validation loss: 2.149378172812923

Epoch: 5| Step: 8
Training loss: 1.466500163078308
Validation loss: 2.0940697744328487

Epoch: 5| Step: 9
Training loss: 1.322359561920166
Validation loss: 2.0653242193242556

Epoch: 5| Step: 10
Training loss: 0.8289114832878113
Validation loss: 2.0360191842561126

Epoch: 180| Step: 0
Training loss: 1.293213129043579
Validation loss: 2.0257672263729956

Epoch: 5| Step: 1
Training loss: 1.3496233224868774
Validation loss: 2.065310234664589

Epoch: 5| Step: 2
Training loss: 1.3467533588409424
Validation loss: 2.0602896149440477

Epoch: 5| Step: 3
Training loss: 1.097194790840149
Validation loss: 2.005701352191228

Epoch: 5| Step: 4
Training loss: 1.4275789260864258
Validation loss: 1.9912751695161224

Epoch: 5| Step: 5
Training loss: 1.5834544897079468
Validation loss: 1.9494583375992314

Epoch: 5| Step: 6
Training loss: 1.1999988555908203
Validation loss: 1.9462309447667931

Epoch: 5| Step: 7
Training loss: 0.8888663053512573
Validation loss: 1.9668774361251502

Epoch: 5| Step: 8
Training loss: 1.6952259540557861
Validation loss: 1.9773229322125834

Epoch: 5| Step: 9
Training loss: 1.2445318698883057
Validation loss: 1.9685007782392605

Epoch: 5| Step: 10
Training loss: 0.9641966223716736
Validation loss: 1.9689973605576383

Epoch: 181| Step: 0
Training loss: 1.6019165515899658
Validation loss: 1.9944685197645617

Epoch: 5| Step: 1
Training loss: 0.6623610258102417
Validation loss: 2.0243322310909146

Epoch: 5| Step: 2
Training loss: 1.330485463142395
Validation loss: 2.0514832363333753

Epoch: 5| Step: 3
Training loss: 1.3856359720230103
Validation loss: 2.0345318778868644

Epoch: 5| Step: 4
Training loss: 1.187325119972229
Validation loss: 2.011655353730725

Epoch: 5| Step: 5
Training loss: 0.9677749872207642
Validation loss: 1.9824360724418395

Epoch: 5| Step: 6
Training loss: 1.2750533819198608
Validation loss: 1.9687799510135446

Epoch: 5| Step: 7
Training loss: 1.4980016946792603
Validation loss: 1.9822715841313845

Epoch: 5| Step: 8
Training loss: 1.8830368518829346
Validation loss: 1.9765210202945176

Epoch: 5| Step: 9
Training loss: 0.9397463798522949
Validation loss: 1.9927065193012197

Epoch: 5| Step: 10
Training loss: 1.1615643501281738
Validation loss: 1.9893966105676466

Epoch: 182| Step: 0
Training loss: 1.3166327476501465
Validation loss: 2.0053754365572365

Epoch: 5| Step: 1
Training loss: 1.0735681056976318
Validation loss: 2.0064936619932934

Epoch: 5| Step: 2
Training loss: 0.9921032190322876
Validation loss: 2.0219678391692457

Epoch: 5| Step: 3
Training loss: 1.6406608819961548
Validation loss: 2.0355855675153833

Epoch: 5| Step: 4
Training loss: 1.2342402935028076
Validation loss: 2.0419179470308366

Epoch: 5| Step: 5
Training loss: 0.9606783986091614
Validation loss: 2.0634522758504397

Epoch: 5| Step: 6
Training loss: 1.2299522161483765
Validation loss: 2.034251877056655

Epoch: 5| Step: 7
Training loss: 1.0932992696762085
Validation loss: 2.0092591675378944

Epoch: 5| Step: 8
Training loss: 1.316053032875061
Validation loss: 1.9888819725282731

Epoch: 5| Step: 9
Training loss: 1.1920161247253418
Validation loss: 2.0022166185481574

Epoch: 5| Step: 10
Training loss: 1.6264151334762573
Validation loss: 2.00518459914833

Epoch: 183| Step: 0
Training loss: 1.1858676671981812
Validation loss: 2.0100656158180645

Epoch: 5| Step: 1
Training loss: 1.8390353918075562
Validation loss: 2.061899576135861

Epoch: 5| Step: 2
Training loss: 1.1905460357666016
Validation loss: 2.0765605972659205

Epoch: 5| Step: 3
Training loss: 0.9336715936660767
Validation loss: 2.0406102570154334

Epoch: 5| Step: 4
Training loss: 1.3827545642852783
Validation loss: 2.0362507732965613

Epoch: 5| Step: 5
Training loss: 1.246347188949585
Validation loss: 2.052941551772497

Epoch: 5| Step: 6
Training loss: 1.7301170825958252
Validation loss: 2.0859799897798927

Epoch: 5| Step: 7
Training loss: 0.6288083791732788
Validation loss: 2.1188944206442883

Epoch: 5| Step: 8
Training loss: 1.3167885541915894
Validation loss: 2.1389734821934856

Epoch: 5| Step: 9
Training loss: 1.3498178720474243
Validation loss: 2.122493406777741

Epoch: 5| Step: 10
Training loss: 1.015641212463379
Validation loss: 2.0890601911852436

Epoch: 184| Step: 0
Training loss: 1.5749502182006836
Validation loss: 2.090149556436846

Epoch: 5| Step: 1
Training loss: 1.122211217880249
Validation loss: 2.0952925143703336

Epoch: 5| Step: 2
Training loss: 1.660317063331604
Validation loss: 2.080342854222944

Epoch: 5| Step: 3
Training loss: 1.1907665729522705
Validation loss: 2.088872763418382

Epoch: 5| Step: 4
Training loss: 1.448622703552246
Validation loss: 2.0744738296795915

Epoch: 5| Step: 5
Training loss: 0.8315089344978333
Validation loss: 2.0785079335653656

Epoch: 5| Step: 6
Training loss: 1.3351068496704102
Validation loss: 2.0969293091886785

Epoch: 5| Step: 7
Training loss: 0.8518368005752563
Validation loss: 2.125957494140953

Epoch: 5| Step: 8
Training loss: 1.0455353260040283
Validation loss: 2.127621228976916

Epoch: 5| Step: 9
Training loss: 1.5362077951431274
Validation loss: 2.1059327958732523

Epoch: 5| Step: 10
Training loss: 1.278615951538086
Validation loss: 2.0791812891601236

Epoch: 185| Step: 0
Training loss: 1.1137527227401733
Validation loss: 2.053339005798422

Epoch: 5| Step: 1
Training loss: 1.1637609004974365
Validation loss: 2.005514931935136

Epoch: 5| Step: 2
Training loss: 1.0464484691619873
Validation loss: 1.9187498361833635

Epoch: 5| Step: 3
Training loss: 0.9947947263717651
Validation loss: 1.9474039949396604

Epoch: 5| Step: 4
Training loss: 1.2324390411376953
Validation loss: 1.9464589344557894

Epoch: 5| Step: 5
Training loss: 1.2770304679870605
Validation loss: 1.986042502105877

Epoch: 5| Step: 6
Training loss: 1.2021417617797852
Validation loss: 2.0048184317927205

Epoch: 5| Step: 7
Training loss: 1.4118646383285522
Validation loss: 2.0140247985880864

Epoch: 5| Step: 8
Training loss: 1.2935843467712402
Validation loss: 2.0843565182019304

Epoch: 5| Step: 9
Training loss: 1.4204477071762085
Validation loss: 2.1180351652124876

Epoch: 5| Step: 10
Training loss: 1.4620294570922852
Validation loss: 2.1419630742842153

Epoch: 186| Step: 0
Training loss: 1.2895550727844238
Validation loss: 2.0903404117912374

Epoch: 5| Step: 1
Training loss: 0.7935363054275513
Validation loss: 2.0290454228719077

Epoch: 5| Step: 2
Training loss: 1.7641994953155518
Validation loss: 2.0007223826582714

Epoch: 5| Step: 3
Training loss: 1.3977841138839722
Validation loss: 1.9701798718462709

Epoch: 5| Step: 4
Training loss: 1.2840526103973389
Validation loss: 1.9760934358002038

Epoch: 5| Step: 5
Training loss: 0.7973931431770325
Validation loss: 1.9937265521736556

Epoch: 5| Step: 6
Training loss: 1.4959520101547241
Validation loss: 2.0276771745374127

Epoch: 5| Step: 7
Training loss: 0.9727193713188171
Validation loss: 2.039135444548822

Epoch: 5| Step: 8
Training loss: 1.3301422595977783
Validation loss: 2.0759956093244654

Epoch: 5| Step: 9
Training loss: 0.9969142079353333
Validation loss: 2.072559766871955

Epoch: 5| Step: 10
Training loss: 1.1374008655548096
Validation loss: 2.0479615888287945

Epoch: 187| Step: 0
Training loss: 1.6501257419586182
Validation loss: 2.0424934074442875

Epoch: 5| Step: 1
Training loss: 1.0483156442642212
Validation loss: 2.0397583079594437

Epoch: 5| Step: 2
Training loss: 1.4472202062606812
Validation loss: 2.029793520127573

Epoch: 5| Step: 3
Training loss: 1.0237258672714233
Validation loss: 2.012179974586733

Epoch: 5| Step: 4
Training loss: 1.458875298500061
Validation loss: 2.024399762512535

Epoch: 5| Step: 5
Training loss: 1.320354700088501
Validation loss: 2.0332058527136363

Epoch: 5| Step: 6
Training loss: 1.1170024871826172
Validation loss: 2.081117994041853

Epoch: 5| Step: 7
Training loss: 1.1440904140472412
Validation loss: 2.0968565863947712

Epoch: 5| Step: 8
Training loss: 0.9989773035049438
Validation loss: 2.0752986669540405

Epoch: 5| Step: 9
Training loss: 0.8252617716789246
Validation loss: 2.0729581976449616

Epoch: 5| Step: 10
Training loss: 1.1545029878616333
Validation loss: 2.051535996057654

Epoch: 188| Step: 0
Training loss: 0.7888728976249695
Validation loss: 2.0582202442230715

Epoch: 5| Step: 1
Training loss: 1.0058752298355103
Validation loss: 2.0421335274173367

Epoch: 5| Step: 2
Training loss: 1.2755793333053589
Validation loss: 2.0077901322354554

Epoch: 5| Step: 3
Training loss: 1.6303104162216187
Validation loss: 1.987404054211032

Epoch: 5| Step: 4
Training loss: 1.2383195161819458
Validation loss: 2.0041574739640757

Epoch: 5| Step: 5
Training loss: 1.45292329788208
Validation loss: 1.9632177737451368

Epoch: 5| Step: 6
Training loss: 1.2102675437927246
Validation loss: 1.950079607707198

Epoch: 5| Step: 7
Training loss: 1.0749882459640503
Validation loss: 1.9477887986808695

Epoch: 5| Step: 8
Training loss: 0.9940940737724304
Validation loss: 1.9408621185569352

Epoch: 5| Step: 9
Training loss: 0.8908918499946594
Validation loss: 1.9670891966871036

Epoch: 5| Step: 10
Training loss: 1.956396222114563
Validation loss: 1.9611844273023709

Epoch: 189| Step: 0
Training loss: 1.0048935413360596
Validation loss: 1.9602260538326797

Epoch: 5| Step: 1
Training loss: 1.5302566289901733
Validation loss: 1.926025285515734

Epoch: 5| Step: 2
Training loss: 1.0831372737884521
Validation loss: 1.9265643281321372

Epoch: 5| Step: 3
Training loss: 0.742606520652771
Validation loss: 1.9270854252640919

Epoch: 5| Step: 4
Training loss: 1.059281587600708
Validation loss: 1.9209062950585478

Epoch: 5| Step: 5
Training loss: 1.2408573627471924
Validation loss: 1.9638494932523338

Epoch: 5| Step: 6
Training loss: 1.1344331502914429
Validation loss: 1.9816023495889479

Epoch: 5| Step: 7
Training loss: 1.4281469583511353
Validation loss: 2.0152006405656055

Epoch: 5| Step: 8
Training loss: 0.7901085615158081
Validation loss: 1.9957742780767462

Epoch: 5| Step: 9
Training loss: 1.2572232484817505
Validation loss: 1.9552729386155323

Epoch: 5| Step: 10
Training loss: 1.3822782039642334
Validation loss: 1.9658913689274942

Epoch: 190| Step: 0
Training loss: 1.1432238817214966
Validation loss: 1.9782471682435723

Epoch: 5| Step: 1
Training loss: 0.7788761258125305
Validation loss: 2.0001978105114353

Epoch: 5| Step: 2
Training loss: 1.0208829641342163
Validation loss: 2.019550620868642

Epoch: 5| Step: 3
Training loss: 1.4087462425231934
Validation loss: 2.030850834743951

Epoch: 5| Step: 4
Training loss: 0.8910788297653198
Validation loss: 2.0279702832621913

Epoch: 5| Step: 5
Training loss: 1.041967749595642
Validation loss: 2.1097846518280687

Epoch: 5| Step: 6
Training loss: 0.9211207628250122
Validation loss: 2.0837312411236506

Epoch: 5| Step: 7
Training loss: 1.2704293727874756
Validation loss: 2.094024873548938

Epoch: 5| Step: 8
Training loss: 1.5290510654449463
Validation loss: 2.0108142488746235

Epoch: 5| Step: 9
Training loss: 1.2848809957504272
Validation loss: 1.9659982509510492

Epoch: 5| Step: 10
Training loss: 1.532537579536438
Validation loss: 1.93679012790803

Epoch: 191| Step: 0
Training loss: 1.4668083190917969
Validation loss: 1.935786542072091

Epoch: 5| Step: 1
Training loss: 1.4278984069824219
Validation loss: 1.9344744810494043

Epoch: 5| Step: 2
Training loss: 1.073155164718628
Validation loss: 1.935703945416276

Epoch: 5| Step: 3
Training loss: 0.6975105404853821
Validation loss: 1.9446537135749735

Epoch: 5| Step: 4
Training loss: 1.317752480506897
Validation loss: 1.9917321781958304

Epoch: 5| Step: 5
Training loss: 1.1857733726501465
Validation loss: 2.0282394604016374

Epoch: 5| Step: 6
Training loss: 1.1457409858703613
Validation loss: 2.0495835555497037

Epoch: 5| Step: 7
Training loss: 0.9193878173828125
Validation loss: 2.052271886538434

Epoch: 5| Step: 8
Training loss: 1.230555534362793
Validation loss: 2.053816854312856

Epoch: 5| Step: 9
Training loss: 0.9234774708747864
Validation loss: 2.0637732167397775

Epoch: 5| Step: 10
Training loss: 1.269018530845642
Validation loss: 2.047913228311846

Epoch: 192| Step: 0
Training loss: 1.0349280834197998
Validation loss: 2.0073506409122097

Epoch: 5| Step: 1
Training loss: 1.3409852981567383
Validation loss: 2.011352677499094

Epoch: 5| Step: 2
Training loss: 1.1950123310089111
Validation loss: 1.9680721580341298

Epoch: 5| Step: 3
Training loss: 1.1036794185638428
Validation loss: 1.937522344691779

Epoch: 5| Step: 4
Training loss: 1.1446313858032227
Validation loss: 1.9326481319242907

Epoch: 5| Step: 5
Training loss: 1.0850473642349243
Validation loss: 1.9602133227932839

Epoch: 5| Step: 6
Training loss: 1.0737731456756592
Validation loss: 1.9793388561535907

Epoch: 5| Step: 7
Training loss: 1.001143455505371
Validation loss: 2.0320585261109056

Epoch: 5| Step: 8
Training loss: 1.3405756950378418
Validation loss: 2.060545277851884

Epoch: 5| Step: 9
Training loss: 0.8675581216812134
Validation loss: 2.117254049547257

Epoch: 5| Step: 10
Training loss: 1.197300672531128
Validation loss: 2.129623851468486

Epoch: 193| Step: 0
Training loss: 1.0918304920196533
Validation loss: 2.167305141366938

Epoch: 5| Step: 1
Training loss: 0.8327739834785461
Validation loss: 2.1599265862536687

Epoch: 5| Step: 2
Training loss: 1.5479902029037476
Validation loss: 2.15167655996097

Epoch: 5| Step: 3
Training loss: 1.3963887691497803
Validation loss: 2.1263629210892545

Epoch: 5| Step: 4
Training loss: 1.0821341276168823
Validation loss: 2.0885589507318314

Epoch: 5| Step: 5
Training loss: 1.0773992538452148
Validation loss: 2.0433257343948528

Epoch: 5| Step: 6
Training loss: 1.350327491760254
Validation loss: 1.9766865737976567

Epoch: 5| Step: 7
Training loss: 0.7290588021278381
Validation loss: 1.9187063786291307

Epoch: 5| Step: 8
Training loss: 0.9575096368789673
Validation loss: 1.9169218770919307

Epoch: 5| Step: 9
Training loss: 1.0974496603012085
Validation loss: 1.9732576800930886

Epoch: 5| Step: 10
Training loss: 1.511418342590332
Validation loss: 1.9724700809806905

Epoch: 194| Step: 0
Training loss: 1.3304331302642822
Validation loss: 1.9977434553125852

Epoch: 5| Step: 1
Training loss: 1.2323752641677856
Validation loss: 2.030495612852035

Epoch: 5| Step: 2
Training loss: 1.1969021558761597
Validation loss: 1.992460835364557

Epoch: 5| Step: 3
Training loss: 0.7676663398742676
Validation loss: 1.9696531616231447

Epoch: 5| Step: 4
Training loss: 0.6800492405891418
Validation loss: 1.9569895344395791

Epoch: 5| Step: 5
Training loss: 0.9431074261665344
Validation loss: 1.98633663628691

Epoch: 5| Step: 6
Training loss: 0.7962058782577515
Validation loss: 1.9820536605773433

Epoch: 5| Step: 7
Training loss: 1.2213295698165894
Validation loss: 1.9921735230312552

Epoch: 5| Step: 8
Training loss: 1.190121054649353
Validation loss: 2.0366868280595347

Epoch: 5| Step: 9
Training loss: 0.9011243581771851
Validation loss: 2.045812681157102

Epoch: 5| Step: 10
Training loss: 1.7676352262496948
Validation loss: 2.063556727542672

Epoch: 195| Step: 0
Training loss: 1.1864111423492432
Validation loss: 2.1013891773839153

Epoch: 5| Step: 1
Training loss: 1.2249457836151123
Validation loss: 2.114315737960159

Epoch: 5| Step: 2
Training loss: 1.1256077289581299
Validation loss: 2.1059407264955583

Epoch: 5| Step: 3
Training loss: 0.711448073387146
Validation loss: 2.065800569390738

Epoch: 5| Step: 4
Training loss: 0.3817184567451477
Validation loss: 2.043619146911047

Epoch: 5| Step: 5
Training loss: 0.9637147784233093
Validation loss: 1.997181797540316

Epoch: 5| Step: 6
Training loss: 1.0749623775482178
Validation loss: 1.9749173246404177

Epoch: 5| Step: 7
Training loss: 1.231179118156433
Validation loss: 1.9278868834177654

Epoch: 5| Step: 8
Training loss: 1.4552724361419678
Validation loss: 1.9464814765478975

Epoch: 5| Step: 9
Training loss: 1.2455490827560425
Validation loss: 1.9377602582336755

Epoch: 5| Step: 10
Training loss: 1.4439451694488525
Validation loss: 1.9820915422131937

Epoch: 196| Step: 0
Training loss: 0.9936092495918274
Validation loss: 1.972057327147453

Epoch: 5| Step: 1
Training loss: 0.5883112549781799
Validation loss: 1.9879190793601416

Epoch: 5| Step: 2
Training loss: 0.9295178651809692
Validation loss: 1.999537653820489

Epoch: 5| Step: 3
Training loss: 1.309699296951294
Validation loss: 1.995640775208832

Epoch: 5| Step: 4
Training loss: 1.4237593412399292
Validation loss: 2.0003085213322795

Epoch: 5| Step: 5
Training loss: 1.0288279056549072
Validation loss: 1.986448049545288

Epoch: 5| Step: 6
Training loss: 0.9694532155990601
Validation loss: 1.9649443113675682

Epoch: 5| Step: 7
Training loss: 0.8670710325241089
Validation loss: 1.9369892920217207

Epoch: 5| Step: 8
Training loss: 0.7847269177436829
Validation loss: 1.9097857488098966

Epoch: 5| Step: 9
Training loss: 1.1391823291778564
Validation loss: 1.8975692384986467

Epoch: 5| Step: 10
Training loss: 1.6426507234573364
Validation loss: 1.8921888207876554

Epoch: 197| Step: 0
Training loss: 1.2873369455337524
Validation loss: 1.8908816806731685

Epoch: 5| Step: 1
Training loss: 1.3737390041351318
Validation loss: 1.9031374685225948

Epoch: 5| Step: 2
Training loss: 1.1211645603179932
Validation loss: 1.9373413055173812

Epoch: 5| Step: 3
Training loss: 1.5095579624176025
Validation loss: 1.9675505084376181

Epoch: 5| Step: 4
Training loss: 0.9334928393363953
Validation loss: 2.043284382871402

Epoch: 5| Step: 5
Training loss: 0.9237555265426636
Validation loss: 2.0744063226125573

Epoch: 5| Step: 6
Training loss: 1.1848385334014893
Validation loss: 2.0960029914814937

Epoch: 5| Step: 7
Training loss: 0.4377852976322174
Validation loss: 2.084526023557109

Epoch: 5| Step: 8
Training loss: 0.9152639508247375
Validation loss: 2.0984293286518385

Epoch: 5| Step: 9
Training loss: 0.9267671704292297
Validation loss: 2.0938697758541314

Epoch: 5| Step: 10
Training loss: 1.0572311878204346
Validation loss: 2.028235504704137

Epoch: 198| Step: 0
Training loss: 1.1662178039550781
Validation loss: 1.983876041186753

Epoch: 5| Step: 1
Training loss: 0.6733201742172241
Validation loss: 1.9159993933093162

Epoch: 5| Step: 2
Training loss: 1.0298125743865967
Validation loss: 1.874210000038147

Epoch: 5| Step: 3
Training loss: 1.0705801248550415
Validation loss: 1.826520594217444

Epoch: 5| Step: 4
Training loss: 1.2003962993621826
Validation loss: 1.823778966421722

Epoch: 5| Step: 5
Training loss: 1.0930378437042236
Validation loss: 1.849511875901171

Epoch: 5| Step: 6
Training loss: 0.9133949279785156
Validation loss: 1.8786646255882837

Epoch: 5| Step: 7
Training loss: 1.1971848011016846
Validation loss: 1.9592752431028633

Epoch: 5| Step: 8
Training loss: 1.0020214319229126
Validation loss: 2.009592028074367

Epoch: 5| Step: 9
Training loss: 1.2758092880249023
Validation loss: 2.0434209121170865

Epoch: 5| Step: 10
Training loss: 1.1749039888381958
Validation loss: 2.1261512592274654

Epoch: 199| Step: 0
Training loss: 1.0942537784576416
Validation loss: 2.142103741245885

Epoch: 5| Step: 1
Training loss: 0.9156455993652344
Validation loss: 2.1334743833029144

Epoch: 5| Step: 2
Training loss: 1.4818799495697021
Validation loss: 2.090191941107473

Epoch: 5| Step: 3
Training loss: 0.8882215619087219
Validation loss: 2.034372966776612

Epoch: 5| Step: 4
Training loss: 0.9450114965438843
Validation loss: 1.9691900373787008

Epoch: 5| Step: 5
Training loss: 1.260399341583252
Validation loss: 1.922493609048987

Epoch: 5| Step: 6
Training loss: 1.1426489353179932
Validation loss: 1.8933118735590289

Epoch: 5| Step: 7
Training loss: 0.8151121139526367
Validation loss: 1.8426094542267502

Epoch: 5| Step: 8
Training loss: 1.1831125020980835
Validation loss: 1.8428889025924027

Epoch: 5| Step: 9
Training loss: 0.6125175952911377
Validation loss: 1.8537314476505402

Epoch: 5| Step: 10
Training loss: 1.2624787092208862
Validation loss: 1.8856014782382595

Epoch: 200| Step: 0
Training loss: 1.1476236581802368
Validation loss: 1.9181095361709595

Epoch: 5| Step: 1
Training loss: 1.2071526050567627
Validation loss: 1.9703643321990967

Epoch: 5| Step: 2
Training loss: 0.9543184041976929
Validation loss: 1.984402778328106

Epoch: 5| Step: 3
Training loss: 0.7661715745925903
Validation loss: 1.9849241984787809

Epoch: 5| Step: 4
Training loss: 0.8741248250007629
Validation loss: 1.9854182799657185

Epoch: 5| Step: 5
Training loss: 0.871685802936554
Validation loss: 1.9724471158878778

Epoch: 5| Step: 6
Training loss: 1.3516438007354736
Validation loss: 1.9815828082382039

Epoch: 5| Step: 7
Training loss: 0.543735682964325
Validation loss: 2.003932160715903

Epoch: 5| Step: 8
Training loss: 1.5902305841445923
Validation loss: 1.967021393519576

Epoch: 5| Step: 9
Training loss: 0.8524810671806335
Validation loss: 1.9318726652412004

Epoch: 5| Step: 10
Training loss: 1.2933855056762695
Validation loss: 1.957060908758512

Epoch: 201| Step: 0
Training loss: 1.4311761856079102
Validation loss: 1.927213353495444

Epoch: 5| Step: 1
Training loss: 0.7783620953559875
Validation loss: 1.9331722515885548

Epoch: 5| Step: 2
Training loss: 0.7958747744560242
Validation loss: 1.9062351860025877

Epoch: 5| Step: 3
Training loss: 0.7638770341873169
Validation loss: 1.9186628018656084

Epoch: 5| Step: 4
Training loss: 0.9276420474052429
Validation loss: 1.9171800100675194

Epoch: 5| Step: 5
Training loss: 1.066150426864624
Validation loss: 1.9664223527395597

Epoch: 5| Step: 6
Training loss: 1.1382008790969849
Validation loss: 2.023481184436429

Epoch: 5| Step: 7
Training loss: 0.6228595972061157
Validation loss: 2.018078698906847

Epoch: 5| Step: 8
Training loss: 1.5005625486373901
Validation loss: 2.0355883106108634

Epoch: 5| Step: 9
Training loss: 1.0232539176940918
Validation loss: 2.0195039856818413

Epoch: 5| Step: 10
Training loss: 1.1636122465133667
Validation loss: 2.0084667590356644

Epoch: 202| Step: 0
Training loss: 1.3327308893203735
Validation loss: 1.9998326891212053

Epoch: 5| Step: 1
Training loss: 0.9531490206718445
Validation loss: 1.9873434433373072

Epoch: 5| Step: 2
Training loss: 1.0082192420959473
Validation loss: 1.9669579844320975

Epoch: 5| Step: 3
Training loss: 1.34274423122406
Validation loss: 1.9633517521683888

Epoch: 5| Step: 4
Training loss: 0.7974704504013062
Validation loss: 1.9865847736276605

Epoch: 5| Step: 5
Training loss: 1.0892606973648071
Validation loss: 1.9850514255544192

Epoch: 5| Step: 6
Training loss: 0.6701980829238892
Validation loss: 2.0200648974346858

Epoch: 5| Step: 7
Training loss: 0.8164952397346497
Validation loss: 2.0441336529229277

Epoch: 5| Step: 8
Training loss: 1.0321128368377686
Validation loss: 2.029419247822095

Epoch: 5| Step: 9
Training loss: 0.9415563344955444
Validation loss: 2.006355586872306

Epoch: 5| Step: 10
Training loss: 0.8200533390045166
Validation loss: 1.982548193265033

Epoch: 203| Step: 0
Training loss: 0.9232254028320312
Validation loss: 1.9751473344782347

Epoch: 5| Step: 1
Training loss: 0.998450756072998
Validation loss: 1.9686658100415302

Epoch: 5| Step: 2
Training loss: 0.4883296489715576
Validation loss: 1.9731677565523373

Epoch: 5| Step: 3
Training loss: 1.644087553024292
Validation loss: 1.9750215033049225

Epoch: 5| Step: 4
Training loss: 0.853485107421875
Validation loss: 1.953249131479571

Epoch: 5| Step: 5
Training loss: 0.7751551270484924
Validation loss: 1.9605985854261665

Epoch: 5| Step: 6
Training loss: 1.0967817306518555
Validation loss: 1.9567510902240712

Epoch: 5| Step: 7
Training loss: 0.9137272834777832
Validation loss: 1.959440218505039

Epoch: 5| Step: 8
Training loss: 1.2442984580993652
Validation loss: 1.973314900552073

Epoch: 5| Step: 9
Training loss: 0.8917362093925476
Validation loss: 1.9617318696873163

Epoch: 5| Step: 10
Training loss: 1.0095547437667847
Validation loss: 2.0000130899490847

Epoch: 204| Step: 0
Training loss: 1.1210315227508545
Validation loss: 2.0234337058118594

Epoch: 5| Step: 1
Training loss: 1.0269997119903564
Validation loss: 2.0230581324587584

Epoch: 5| Step: 2
Training loss: 1.0764553546905518
Validation loss: 1.994031629254741

Epoch: 5| Step: 3
Training loss: 0.9796574711799622
Validation loss: 1.9673796264074181

Epoch: 5| Step: 4
Training loss: 1.1950294971466064
Validation loss: 1.9379335347042288

Epoch: 5| Step: 5
Training loss: 0.8032528758049011
Validation loss: 1.886159643050163

Epoch: 5| Step: 6
Training loss: 0.8479030728340149
Validation loss: 1.892072949358212

Epoch: 5| Step: 7
Training loss: 0.8989882469177246
Validation loss: 1.873013118261932

Epoch: 5| Step: 8
Training loss: 0.9372377395629883
Validation loss: 1.901159401862852

Epoch: 5| Step: 9
Training loss: 1.0008442401885986
Validation loss: 1.9081252992794078

Epoch: 5| Step: 10
Training loss: 0.8515219688415527
Validation loss: 1.9765487717043968

Epoch: 205| Step: 0
Training loss: 1.2040578126907349
Validation loss: 1.9567965140906713

Epoch: 5| Step: 1
Training loss: 1.1073715686798096
Validation loss: 1.9435340396819576

Epoch: 5| Step: 2
Training loss: 0.7500702142715454
Validation loss: 1.9514580080586095

Epoch: 5| Step: 3
Training loss: 0.7945592403411865
Validation loss: 1.9493043332971551

Epoch: 5| Step: 4
Training loss: 0.7071794271469116
Validation loss: 1.948329730700421

Epoch: 5| Step: 5
Training loss: 1.4484460353851318
Validation loss: 1.974305805339608

Epoch: 5| Step: 6
Training loss: 0.9460695385932922
Validation loss: 1.949594477171539

Epoch: 5| Step: 7
Training loss: 1.268818736076355
Validation loss: 1.9666212617710073

Epoch: 5| Step: 8
Training loss: 0.6863476634025574
Validation loss: 1.9657457131211475

Epoch: 5| Step: 9
Training loss: 0.6428118944168091
Validation loss: 1.9486056784147858

Epoch: 5| Step: 10
Training loss: 0.6756071448326111
Validation loss: 1.9765467618101387

Epoch: 206| Step: 0
Training loss: 0.31587547063827515
Validation loss: 1.9711520146298152

Epoch: 5| Step: 1
Training loss: 1.04425048828125
Validation loss: 1.9933014351834533

Epoch: 5| Step: 2
Training loss: 0.5992897748947144
Validation loss: 1.9887334313443912

Epoch: 5| Step: 3
Training loss: 1.3118016719818115
Validation loss: 1.9910383596215198

Epoch: 5| Step: 4
Training loss: 0.8888381123542786
Validation loss: 1.9671843026273994

Epoch: 5| Step: 5
Training loss: 0.5662939548492432
Validation loss: 1.970491737447759

Epoch: 5| Step: 6
Training loss: 1.388372778892517
Validation loss: 1.9704282822147492

Epoch: 5| Step: 7
Training loss: 1.482208251953125
Validation loss: 1.976052321413512

Epoch: 5| Step: 8
Training loss: 0.8458978533744812
Validation loss: 1.9018242666798253

Epoch: 5| Step: 9
Training loss: 1.0256085395812988
Validation loss: 1.8945419326905282

Epoch: 5| Step: 10
Training loss: 0.8142906427383423
Validation loss: 1.8906334292504094

Epoch: 207| Step: 0
Training loss: 0.8957464098930359
Validation loss: 1.9025505358173

Epoch: 5| Step: 1
Training loss: 0.5908414125442505
Validation loss: 1.935422835811492

Epoch: 5| Step: 2
Training loss: 0.9401607513427734
Validation loss: 1.9569099372433079

Epoch: 5| Step: 3
Training loss: 1.3624392747879028
Validation loss: 1.9747545026963758

Epoch: 5| Step: 4
Training loss: 0.8185678720474243
Validation loss: 1.9230084970433226

Epoch: 5| Step: 5
Training loss: 1.069104790687561
Validation loss: 1.9411240034205939

Epoch: 5| Step: 6
Training loss: 1.1608110666275024
Validation loss: 1.9883098128021404

Epoch: 5| Step: 7
Training loss: 1.062740683555603
Validation loss: 1.9762060937061106

Epoch: 5| Step: 8
Training loss: 1.131752610206604
Validation loss: 1.948319870938537

Epoch: 5| Step: 9
Training loss: 0.5066685676574707
Validation loss: 1.9279740561721146

Epoch: 5| Step: 10
Training loss: 0.695806622505188
Validation loss: 1.905882881533715

Epoch: 208| Step: 0
Training loss: 0.6566405892372131
Validation loss: 1.8940384541788409

Epoch: 5| Step: 1
Training loss: 0.7552670240402222
Validation loss: 1.9401745116838844

Epoch: 5| Step: 2
Training loss: 1.4998515844345093
Validation loss: 1.9251861418447187

Epoch: 5| Step: 3
Training loss: 0.9878209829330444
Validation loss: 1.89247134424025

Epoch: 5| Step: 4
Training loss: 1.038102388381958
Validation loss: 1.9064947687169558

Epoch: 5| Step: 5
Training loss: 1.2300021648406982
Validation loss: 1.936866185998404

Epoch: 5| Step: 6
Training loss: 1.0415846109390259
Validation loss: 1.9070851226006784

Epoch: 5| Step: 7
Training loss: 0.8200033903121948
Validation loss: 1.9220047599525862

Epoch: 5| Step: 8
Training loss: 0.6553035378456116
Validation loss: 1.9706919577813917

Epoch: 5| Step: 9
Training loss: 0.7397105097770691
Validation loss: 1.9668600431052587

Epoch: 5| Step: 10
Training loss: 0.6431283354759216
Validation loss: 1.980026875772784

Epoch: 209| Step: 0
Training loss: 0.3564431071281433
Validation loss: 2.001203957424369

Epoch: 5| Step: 1
Training loss: 0.6671368479728699
Validation loss: 2.030236908184585

Epoch: 5| Step: 2
Training loss: 1.1368663311004639
Validation loss: 2.011816114507696

Epoch: 5| Step: 3
Training loss: 0.8738953471183777
Validation loss: 1.9691356612790016

Epoch: 5| Step: 4
Training loss: 1.1844513416290283
Validation loss: 1.9791362695796515

Epoch: 5| Step: 5
Training loss: 1.02432382106781
Validation loss: 1.960826942997594

Epoch: 5| Step: 6
Training loss: 0.7564131617546082
Validation loss: 1.9410538135036346

Epoch: 5| Step: 7
Training loss: 1.19484281539917
Validation loss: 1.95180497887314

Epoch: 5| Step: 8
Training loss: 1.0684478282928467
Validation loss: 1.9074295259291125

Epoch: 5| Step: 9
Training loss: 1.0681126117706299
Validation loss: 1.9104563702819168

Epoch: 5| Step: 10
Training loss: 0.6790772676467896
Validation loss: 1.907860427774409

Epoch: 210| Step: 0
Training loss: 1.0114880800247192
Validation loss: 1.9249634268463298

Epoch: 5| Step: 1
Training loss: 0.8125443458557129
Validation loss: 1.9108025258587253

Epoch: 5| Step: 2
Training loss: 0.8428564071655273
Validation loss: 1.9328459796085153

Epoch: 5| Step: 3
Training loss: 0.8348743319511414
Validation loss: 1.9529031925303961

Epoch: 5| Step: 4
Training loss: 0.9311752319335938
Validation loss: 1.9458656798126877

Epoch: 5| Step: 5
Training loss: 0.9353998899459839
Validation loss: 1.9350810358601231

Epoch: 5| Step: 6
Training loss: 1.3145637512207031
Validation loss: 1.9503090330349502

Epoch: 5| Step: 7
Training loss: 0.5868858098983765
Validation loss: 1.9560577151595906

Epoch: 5| Step: 8
Training loss: 1.039233922958374
Validation loss: 1.9626355914659397

Epoch: 5| Step: 9
Training loss: 0.787324070930481
Validation loss: 1.9655077739428448

Epoch: 5| Step: 10
Training loss: 1.0024254322052002
Validation loss: 1.9651379316083846

Epoch: 211| Step: 0
Training loss: 1.2319412231445312
Validation loss: 1.9971690998282483

Epoch: 5| Step: 1
Training loss: 0.8113482594490051
Validation loss: 2.0094183926941245

Epoch: 5| Step: 2
Training loss: 0.7927243113517761
Validation loss: 2.0324767481896187

Epoch: 5| Step: 3
Training loss: 0.9412462115287781
Validation loss: 2.0179017333574194

Epoch: 5| Step: 4
Training loss: 0.6192198991775513
Validation loss: 2.019917475279941

Epoch: 5| Step: 5
Training loss: 0.9113798141479492
Validation loss: 2.012535418233564

Epoch: 5| Step: 6
Training loss: 1.190108299255371
Validation loss: 2.0003937175196986

Epoch: 5| Step: 7
Training loss: 1.0176095962524414
Validation loss: 1.9626161552244616

Epoch: 5| Step: 8
Training loss: 1.0781667232513428
Validation loss: 1.8914845130776847

Epoch: 5| Step: 9
Training loss: 0.8604555130004883
Validation loss: 1.8960828729855117

Epoch: 5| Step: 10
Training loss: 0.6887800693511963
Validation loss: 1.892279617248043

Epoch: 212| Step: 0
Training loss: 1.0496852397918701
Validation loss: 1.9035632610321045

Epoch: 5| Step: 1
Training loss: 0.4941794276237488
Validation loss: 1.8986659960080219

Epoch: 5| Step: 2
Training loss: 0.736351490020752
Validation loss: 1.881775415071877

Epoch: 5| Step: 3
Training loss: 1.087472915649414
Validation loss: 1.9350797373761413

Epoch: 5| Step: 4
Training loss: 1.2260230779647827
Validation loss: 1.949044148127238

Epoch: 5| Step: 5
Training loss: 0.5471023321151733
Validation loss: 1.9990638609855407

Epoch: 5| Step: 6
Training loss: 0.9968136548995972
Validation loss: 1.9826625085646106

Epoch: 5| Step: 7
Training loss: 1.1651077270507812
Validation loss: 2.0022244376520955

Epoch: 5| Step: 8
Training loss: 0.9283339381217957
Validation loss: 2.017588464162683

Epoch: 5| Step: 9
Training loss: 0.9392444491386414
Validation loss: 2.040547793911349

Epoch: 5| Step: 10
Training loss: 0.946552038192749
Validation loss: 2.046964224948678

Epoch: 213| Step: 0
Training loss: 0.7957049608230591
Validation loss: 1.9876032055065196

Epoch: 5| Step: 1
Training loss: 1.1005301475524902
Validation loss: 1.9508240197294502

Epoch: 5| Step: 2
Training loss: 0.501960277557373
Validation loss: 1.925242349665652

Epoch: 5| Step: 3
Training loss: 1.263083815574646
Validation loss: 1.8976042732115714

Epoch: 5| Step: 4
Training loss: 0.6308238506317139
Validation loss: 1.8898570550385343

Epoch: 5| Step: 5
Training loss: 0.8488057255744934
Validation loss: 1.8988915784384615

Epoch: 5| Step: 6
Training loss: 0.9081661105155945
Validation loss: 1.891415326826034

Epoch: 5| Step: 7
Training loss: 0.8052843809127808
Validation loss: 1.8872330022114578

Epoch: 5| Step: 8
Training loss: 0.8391734957695007
Validation loss: 1.9090203085253317

Epoch: 5| Step: 9
Training loss: 0.9605026245117188
Validation loss: 1.9101556706172165

Epoch: 5| Step: 10
Training loss: 1.082686185836792
Validation loss: 1.9197648302201302

Epoch: 214| Step: 0
Training loss: 0.7429714798927307
Validation loss: 1.9271786469285206

Epoch: 5| Step: 1
Training loss: 0.6480062007904053
Validation loss: 1.9170064644146991

Epoch: 5| Step: 2
Training loss: 0.9812092781066895
Validation loss: 1.9382397103053268

Epoch: 5| Step: 3
Training loss: 0.8497093319892883
Validation loss: 1.889188201196732

Epoch: 5| Step: 4
Training loss: 1.05764901638031
Validation loss: 1.8833114075404342

Epoch: 5| Step: 5
Training loss: 0.7692117094993591
Validation loss: 1.849434438572135

Epoch: 5| Step: 6
Training loss: 0.7919079065322876
Validation loss: 1.8724373963571364

Epoch: 5| Step: 7
Training loss: 1.0469449758529663
Validation loss: 1.870377561097504

Epoch: 5| Step: 8
Training loss: 0.7352497577667236
Validation loss: 1.8787178941952285

Epoch: 5| Step: 9
Training loss: 0.864780068397522
Validation loss: 1.8533666954245618

Epoch: 5| Step: 10
Training loss: 1.0635360479354858
Validation loss: 1.9030203870547715

Epoch: 215| Step: 0
Training loss: 0.9183835983276367
Validation loss: 1.921430504450234

Epoch: 5| Step: 1
Training loss: 1.1372044086456299
Validation loss: 1.941353791503496

Epoch: 5| Step: 2
Training loss: 1.147829294204712
Validation loss: 1.936784267425537

Epoch: 5| Step: 3
Training loss: 0.5176228880882263
Validation loss: 1.9570269507746543

Epoch: 5| Step: 4
Training loss: 0.6726044416427612
Validation loss: 1.956913266130673

Epoch: 5| Step: 5
Training loss: 0.931780219078064
Validation loss: 1.9820419511487406

Epoch: 5| Step: 6
Training loss: 0.6972174644470215
Validation loss: 1.9654616181568434

Epoch: 5| Step: 7
Training loss: 0.8470575213432312
Validation loss: 1.9259511129830473

Epoch: 5| Step: 8
Training loss: 0.7096965312957764
Validation loss: 1.9146364414563743

Epoch: 5| Step: 9
Training loss: 0.9366391897201538
Validation loss: 1.9115088396174933

Epoch: 5| Step: 10
Training loss: 0.8900924324989319
Validation loss: 1.911740997786163

Epoch: 216| Step: 0
Training loss: 0.8756699562072754
Validation loss: 1.8924680935439242

Epoch: 5| Step: 1
Training loss: 0.8353592157363892
Validation loss: 1.8704148543778287

Epoch: 5| Step: 2
Training loss: 0.6623552441596985
Validation loss: 1.8713530725048435

Epoch: 5| Step: 3
Training loss: 0.8553983569145203
Validation loss: 1.8723842277321765

Epoch: 5| Step: 4
Training loss: 0.8049971461296082
Validation loss: 1.8981935029388757

Epoch: 5| Step: 5
Training loss: 0.9957210421562195
Validation loss: 1.8882505611706806

Epoch: 5| Step: 6
Training loss: 1.5146136283874512
Validation loss: 1.9161310721469182

Epoch: 5| Step: 7
Training loss: 0.32022684812545776
Validation loss: 1.953606277383784

Epoch: 5| Step: 8
Training loss: 0.6089608073234558
Validation loss: 1.9668058579967869

Epoch: 5| Step: 9
Training loss: 0.8549882173538208
Validation loss: 1.944156426255421

Epoch: 5| Step: 10
Training loss: 0.8137479424476624
Validation loss: 1.9213086494835474

Epoch: 217| Step: 0
Training loss: 0.8266768455505371
Validation loss: 1.8757906524083947

Epoch: 5| Step: 1
Training loss: 0.4787120819091797
Validation loss: 1.8468436605186873

Epoch: 5| Step: 2
Training loss: 0.8326421976089478
Validation loss: 1.8163646421124857

Epoch: 5| Step: 3
Training loss: 1.1399686336517334
Validation loss: 1.7862273518757155

Epoch: 5| Step: 4
Training loss: 0.9238234758377075
Validation loss: 1.793286782439037

Epoch: 5| Step: 5
Training loss: 0.8633036613464355
Validation loss: 1.765112277000181

Epoch: 5| Step: 6
Training loss: 0.5798867344856262
Validation loss: 1.7924454827462473

Epoch: 5| Step: 7
Training loss: 0.954470157623291
Validation loss: 1.7863064888984925

Epoch: 5| Step: 8
Training loss: 0.6849522590637207
Validation loss: 1.8429728259322464

Epoch: 5| Step: 9
Training loss: 1.0677754878997803
Validation loss: 1.8709011718791018

Epoch: 5| Step: 10
Training loss: 0.9479082822799683
Validation loss: 1.9275385846373856

Epoch: 218| Step: 0
Training loss: 0.37230223417282104
Validation loss: 1.9438547703527636

Epoch: 5| Step: 1
Training loss: 0.926132321357727
Validation loss: 1.956871735152378

Epoch: 5| Step: 2
Training loss: 1.1306053400039673
Validation loss: 1.977048558573569

Epoch: 5| Step: 3
Training loss: 0.9028428792953491
Validation loss: 1.9548596502632223

Epoch: 5| Step: 4
Training loss: 0.803128719329834
Validation loss: 1.9382679705978723

Epoch: 5| Step: 5
Training loss: 0.9260370135307312
Validation loss: 1.9212617694690663

Epoch: 5| Step: 6
Training loss: 0.8355475664138794
Validation loss: 1.9108791223136328

Epoch: 5| Step: 7
Training loss: 0.8300913572311401
Validation loss: 1.85393234222166

Epoch: 5| Step: 8
Training loss: 0.7938605546951294
Validation loss: 1.8364904554941321

Epoch: 5| Step: 9
Training loss: 0.6529840230941772
Validation loss: 1.8151298876731627

Epoch: 5| Step: 10
Training loss: 0.8481404781341553
Validation loss: 1.8153159772196124

Epoch: 219| Step: 0
Training loss: 1.0764816999435425
Validation loss: 1.811287308251986

Epoch: 5| Step: 1
Training loss: 0.8355284929275513
Validation loss: 1.8465466191691737

Epoch: 5| Step: 2
Training loss: 0.9959074854850769
Validation loss: 1.875419157807545

Epoch: 5| Step: 3
Training loss: 0.5282171964645386
Validation loss: 1.9106985945855417

Epoch: 5| Step: 4
Training loss: 0.7014529705047607
Validation loss: 1.9656365122846378

Epoch: 5| Step: 5
Training loss: 0.8000020980834961
Validation loss: 2.011189394099738

Epoch: 5| Step: 6
Training loss: 0.786742091178894
Validation loss: 2.0474042687364804

Epoch: 5| Step: 7
Training loss: 1.2044146060943604
Validation loss: 2.0236296371747087

Epoch: 5| Step: 8
Training loss: 0.527214527130127
Validation loss: 1.979346280456871

Epoch: 5| Step: 9
Training loss: 0.7198277711868286
Validation loss: 1.9640072109878703

Epoch: 5| Step: 10
Training loss: 0.8747106194496155
Validation loss: 1.8951750570727932

Epoch: 220| Step: 0
Training loss: 0.5490332841873169
Validation loss: 1.9030098504917596

Epoch: 5| Step: 1
Training loss: 1.0026066303253174
Validation loss: 1.8874655846626527

Epoch: 5| Step: 2
Training loss: 0.9222834706306458
Validation loss: 1.8189855826798307

Epoch: 5| Step: 3
Training loss: 0.842852771282196
Validation loss: 1.8077958373613254

Epoch: 5| Step: 4
Training loss: 0.36108988523483276
Validation loss: 1.8187769138684837

Epoch: 5| Step: 5
Training loss: 1.0707453489303589
Validation loss: 1.8133752833130539

Epoch: 5| Step: 6
Training loss: 1.073798418045044
Validation loss: 1.8951616851232385

Epoch: 5| Step: 7
Training loss: 0.9858492016792297
Validation loss: 1.9401751692577074

Epoch: 5| Step: 8
Training loss: 0.7154024243354797
Validation loss: 1.9406682752793836

Epoch: 5| Step: 9
Training loss: 0.8011242747306824
Validation loss: 1.9763369790969356

Epoch: 5| Step: 10
Training loss: 1.0364824533462524
Validation loss: 1.9602928969167894

Epoch: 221| Step: 0
Training loss: 0.7511405348777771
Validation loss: 1.9256907611764886

Epoch: 5| Step: 1
Training loss: 0.9174640774726868
Validation loss: 1.9112396470962032

Epoch: 5| Step: 2
Training loss: 0.5239603519439697
Validation loss: 1.8802242843053674

Epoch: 5| Step: 3
Training loss: 0.5943502187728882
Validation loss: 1.881490711242922

Epoch: 5| Step: 4
Training loss: 0.6480656862258911
Validation loss: 1.8764844043280489

Epoch: 5| Step: 5
Training loss: 1.0950819253921509
Validation loss: 1.9158187694447015

Epoch: 5| Step: 6
Training loss: 1.1304903030395508
Validation loss: 1.8850397717568181

Epoch: 5| Step: 7
Training loss: 0.7114189863204956
Validation loss: 1.8726584449891122

Epoch: 5| Step: 8
Training loss: 0.8284786939620972
Validation loss: 1.924183076427829

Epoch: 5| Step: 9
Training loss: 0.675818145275116
Validation loss: 1.9289447492168796

Epoch: 5| Step: 10
Training loss: 0.7801766395568848
Validation loss: 1.9393632796502882

Epoch: 222| Step: 0
Training loss: 0.9076482653617859
Validation loss: 1.9647326213057323

Epoch: 5| Step: 1
Training loss: 1.0635087490081787
Validation loss: 1.9647298192465177

Epoch: 5| Step: 2
Training loss: 0.9022596478462219
Validation loss: 1.9824890436664704

Epoch: 5| Step: 3
Training loss: 1.112301230430603
Validation loss: 1.9866008207362185

Epoch: 5| Step: 4
Training loss: 1.0171763896942139
Validation loss: 1.9364052331575783

Epoch: 5| Step: 5
Training loss: 0.575666069984436
Validation loss: 1.904781569716751

Epoch: 5| Step: 6
Training loss: 0.6342222094535828
Validation loss: 1.8845645535376765

Epoch: 5| Step: 7
Training loss: 0.8651803731918335
Validation loss: 1.8895578563854258

Epoch: 5| Step: 8
Training loss: 0.4112061560153961
Validation loss: 1.909127616113232

Epoch: 5| Step: 9
Training loss: 0.6377225518226624
Validation loss: 1.9542588059620192

Epoch: 5| Step: 10
Training loss: 0.7160540223121643
Validation loss: 1.9912310261880197

Epoch: 223| Step: 0
Training loss: 0.9361173510551453
Validation loss: 1.9900783723400486

Epoch: 5| Step: 1
Training loss: 1.1466505527496338
Validation loss: 2.0016912619272866

Epoch: 5| Step: 2
Training loss: 0.778884768486023
Validation loss: 1.9970867877365441

Epoch: 5| Step: 3
Training loss: 0.5289402604103088
Validation loss: 1.9816915168557117

Epoch: 5| Step: 4
Training loss: 0.7464812397956848
Validation loss: 1.938784832595497

Epoch: 5| Step: 5
Training loss: 0.5672069787979126
Validation loss: 1.8665654915635304

Epoch: 5| Step: 6
Training loss: 0.7168856859207153
Validation loss: 1.8108167943134104

Epoch: 5| Step: 7
Training loss: 0.8988809585571289
Validation loss: 1.8003751782960788

Epoch: 5| Step: 8
Training loss: 0.9281409382820129
Validation loss: 1.8050105520474014

Epoch: 5| Step: 9
Training loss: 0.6706988215446472
Validation loss: 1.7845031715208484

Epoch: 5| Step: 10
Training loss: 0.7542523145675659
Validation loss: 1.8308600328301872

Epoch: 224| Step: 0
Training loss: 0.9414642453193665
Validation loss: 1.8522688932316278

Epoch: 5| Step: 1
Training loss: 0.7504997253417969
Validation loss: 1.9198056164608206

Epoch: 5| Step: 2
Training loss: 0.7788946628570557
Validation loss: 1.9562165147514754

Epoch: 5| Step: 3
Training loss: 0.7231504917144775
Validation loss: 1.9825395666142946

Epoch: 5| Step: 4
Training loss: 0.37486371397972107
Validation loss: 1.9794299717872375

Epoch: 5| Step: 5
Training loss: 0.812846302986145
Validation loss: 1.942871311659454

Epoch: 5| Step: 6
Training loss: 0.8796285390853882
Validation loss: 1.91412732678075

Epoch: 5| Step: 7
Training loss: 0.881705105304718
Validation loss: 1.8851261331189064

Epoch: 5| Step: 8
Training loss: 1.0404249429702759
Validation loss: 1.8921623101798437

Epoch: 5| Step: 9
Training loss: 0.7965189814567566
Validation loss: 1.8532429215728596

Epoch: 5| Step: 10
Training loss: 0.7574712038040161
Validation loss: 1.8489584461335213

Epoch: 225| Step: 0
Training loss: 0.546726405620575
Validation loss: 1.8304020704761628

Epoch: 5| Step: 1
Training loss: 1.1705456972122192
Validation loss: 1.8167374287882159

Epoch: 5| Step: 2
Training loss: 0.6992286443710327
Validation loss: 1.81516695022583

Epoch: 5| Step: 3
Training loss: 0.9645721316337585
Validation loss: 1.8690386741392073

Epoch: 5| Step: 4
Training loss: 0.7718134522438049
Validation loss: 1.9218904305529851

Epoch: 5| Step: 5
Training loss: 0.6081326603889465
Validation loss: 1.924610273812407

Epoch: 5| Step: 6
Training loss: 0.49644726514816284
Validation loss: 1.9307881529613207

Epoch: 5| Step: 7
Training loss: 0.6771947145462036
Validation loss: 1.9066700012453142

Epoch: 5| Step: 8
Training loss: 0.8738616108894348
Validation loss: 1.9567274714028964

Epoch: 5| Step: 9
Training loss: 0.7309222221374512
Validation loss: 1.9542312122160388

Epoch: 5| Step: 10
Training loss: 0.6765236854553223
Validation loss: 1.9647154961862872

Epoch: 226| Step: 0
Training loss: 0.7881284952163696
Validation loss: 1.9507639420929777

Epoch: 5| Step: 1
Training loss: 0.532739520072937
Validation loss: 1.9116584665031844

Epoch: 5| Step: 2
Training loss: 0.49093732237815857
Validation loss: 1.910199062798613

Epoch: 5| Step: 3
Training loss: 0.973910927772522
Validation loss: 1.901612389472223

Epoch: 5| Step: 4
Training loss: 0.5943911075592041
Validation loss: 1.8793641777448757

Epoch: 5| Step: 5
Training loss: 0.8464425802230835
Validation loss: 1.8876732831360192

Epoch: 5| Step: 6
Training loss: 1.1378892660140991
Validation loss: 1.860143623044414

Epoch: 5| Step: 7
Training loss: 0.7456002831459045
Validation loss: 1.8653601395186556

Epoch: 5| Step: 8
Training loss: 0.7021361589431763
Validation loss: 1.8836722912326935

Epoch: 5| Step: 9
Training loss: 0.6795175671577454
Validation loss: 1.873234070757384

Epoch: 5| Step: 10
Training loss: 0.7404014468193054
Validation loss: 1.9174571062928887

Epoch: 227| Step: 0
Training loss: 0.4637226164340973
Validation loss: 1.9210480592584098

Epoch: 5| Step: 1
Training loss: 0.765276312828064
Validation loss: 1.931159278397919

Epoch: 5| Step: 2
Training loss: 0.8587682843208313
Validation loss: 1.9426366718866492

Epoch: 5| Step: 3
Training loss: 1.0952008962631226
Validation loss: 1.9334685123094948

Epoch: 5| Step: 4
Training loss: 0.6159645915031433
Validation loss: 1.9741565130090202

Epoch: 5| Step: 5
Training loss: 0.811123251914978
Validation loss: 1.9284296933040823

Epoch: 5| Step: 6
Training loss: 0.7304596304893494
Validation loss: 1.9561853575450119

Epoch: 5| Step: 7
Training loss: 0.779739260673523
Validation loss: 1.9276500696777015

Epoch: 5| Step: 8
Training loss: 0.8532432317733765
Validation loss: 1.9158087635553012

Epoch: 5| Step: 9
Training loss: 0.5682352781295776
Validation loss: 1.9512507838587607

Epoch: 5| Step: 10
Training loss: 0.760895311832428
Validation loss: 1.9560107697722733

Epoch: 228| Step: 0
Training loss: 0.6938328742980957
Validation loss: 1.9509987023568922

Epoch: 5| Step: 1
Training loss: 0.7433436512947083
Validation loss: 1.949287332514281

Epoch: 5| Step: 2
Training loss: 0.7363441586494446
Validation loss: 1.93068624952788

Epoch: 5| Step: 3
Training loss: 0.48709964752197266
Validation loss: 1.9319576217282204

Epoch: 5| Step: 4
Training loss: 0.8719490766525269
Validation loss: 1.9448720793570242

Epoch: 5| Step: 5
Training loss: 0.8429304957389832
Validation loss: 1.9142061792394167

Epoch: 5| Step: 6
Training loss: 0.8221963047981262
Validation loss: 1.9157847345516246

Epoch: 5| Step: 7
Training loss: 0.6229111552238464
Validation loss: 1.899294102063743

Epoch: 5| Step: 8
Training loss: 0.7119995355606079
Validation loss: 1.9129602024632115

Epoch: 5| Step: 9
Training loss: 1.0105648040771484
Validation loss: 1.9226999411018946

Epoch: 5| Step: 10
Training loss: 1.028275489807129
Validation loss: 1.9356111057343022

Epoch: 229| Step: 0
Training loss: 0.7435897588729858
Validation loss: 1.9408886996648644

Epoch: 5| Step: 1
Training loss: 0.580150306224823
Validation loss: 1.9632938587537376

Epoch: 5| Step: 2
Training loss: 0.6411555409431458
Validation loss: 1.9476866696470527

Epoch: 5| Step: 3
Training loss: 0.6890019178390503
Validation loss: 1.9229004818906066

Epoch: 5| Step: 4
Training loss: 0.904946506023407
Validation loss: 1.9057402867142872

Epoch: 5| Step: 5
Training loss: 0.8142279386520386
Validation loss: 1.9057308678985925

Epoch: 5| Step: 6
Training loss: 0.8604671359062195
Validation loss: 1.9387361875144384

Epoch: 5| Step: 7
Training loss: 0.6355563402175903
Validation loss: 1.9137565615356609

Epoch: 5| Step: 8
Training loss: 0.7915646433830261
Validation loss: 1.950826270605928

Epoch: 5| Step: 9
Training loss: 0.7091909646987915
Validation loss: 1.9262155499509586

Epoch: 5| Step: 10
Training loss: 0.8353018164634705
Validation loss: 1.9298528727664743

Epoch: 230| Step: 0
Training loss: 1.0611615180969238
Validation loss: 1.9107277931705597

Epoch: 5| Step: 1
Training loss: 0.7482555508613586
Validation loss: 1.9333494273565148

Epoch: 5| Step: 2
Training loss: 0.5524321794509888
Validation loss: 1.9518452408493205

Epoch: 5| Step: 3
Training loss: 0.8546659350395203
Validation loss: 1.923207695766162

Epoch: 5| Step: 4
Training loss: 0.4338415563106537
Validation loss: 1.9213823028790054

Epoch: 5| Step: 5
Training loss: 0.7525902390480042
Validation loss: 1.9158801596651795

Epoch: 5| Step: 6
Training loss: 0.8130474090576172
Validation loss: 1.9381555498287242

Epoch: 5| Step: 7
Training loss: 1.0379358530044556
Validation loss: 1.971360505268138

Epoch: 5| Step: 8
Training loss: 1.0111721754074097
Validation loss: 1.9569102820529733

Epoch: 5| Step: 9
Training loss: 0.6016659736633301
Validation loss: 1.9568788261823757

Epoch: 5| Step: 10
Training loss: 0.4690299332141876
Validation loss: 1.9412716409211517

Epoch: 231| Step: 0
Training loss: 0.7501306533813477
Validation loss: 1.9224232166044173

Epoch: 5| Step: 1
Training loss: 0.5663572549819946
Validation loss: 1.9590004464631439

Epoch: 5| Step: 2
Training loss: 0.6172335743904114
Validation loss: 1.9406100319277855

Epoch: 5| Step: 3
Training loss: 0.5862491130828857
Validation loss: 1.9243797794465096

Epoch: 5| Step: 4
Training loss: 0.5605267286300659
Validation loss: 1.95676706042341

Epoch: 5| Step: 5
Training loss: 0.7084394693374634
Validation loss: 1.955253279337319

Epoch: 5| Step: 6
Training loss: 0.5417580008506775
Validation loss: 1.9606442836023146

Epoch: 5| Step: 7
Training loss: 0.9124900698661804
Validation loss: 1.942570371012534

Epoch: 5| Step: 8
Training loss: 0.9565927386283875
Validation loss: 1.9438468538304812

Epoch: 5| Step: 9
Training loss: 1.0232064723968506
Validation loss: 1.9320566308113836

Epoch: 5| Step: 10
Training loss: 0.7431526780128479
Validation loss: 1.9001831239269626

Epoch: 232| Step: 0
Training loss: 0.3236019015312195
Validation loss: 1.8838393918929561

Epoch: 5| Step: 1
Training loss: 0.5835957527160645
Validation loss: 1.83979231567793

Epoch: 5| Step: 2
Training loss: 0.7769614458084106
Validation loss: 1.8167200319228634

Epoch: 5| Step: 3
Training loss: 0.9414507150650024
Validation loss: 1.819678533461786

Epoch: 5| Step: 4
Training loss: 0.6953037977218628
Validation loss: 1.8308512651792137

Epoch: 5| Step: 5
Training loss: 0.632940411567688
Validation loss: 1.873064164192446

Epoch: 5| Step: 6
Training loss: 0.9357556104660034
Validation loss: 1.8802429706819597

Epoch: 5| Step: 7
Training loss: 0.8638544082641602
Validation loss: 1.9050461925486082

Epoch: 5| Step: 8
Training loss: 0.7897237539291382
Validation loss: 1.9722362154273576

Epoch: 5| Step: 9
Training loss: 0.7643870115280151
Validation loss: 2.0405376008761826

Epoch: 5| Step: 10
Training loss: 0.5990344882011414
Validation loss: 2.0232478892931374

Epoch: 233| Step: 0
Training loss: 0.7358976006507874
Validation loss: 2.0032077861088577

Epoch: 5| Step: 1
Training loss: 0.6828346848487854
Validation loss: 1.988565585946524

Epoch: 5| Step: 2
Training loss: 0.9781723022460938
Validation loss: 1.9640757140292917

Epoch: 5| Step: 3
Training loss: 0.30239519476890564
Validation loss: 1.936503005284135

Epoch: 5| Step: 4
Training loss: 0.7092763781547546
Validation loss: 1.8832045729442308

Epoch: 5| Step: 5
Training loss: 0.8657447099685669
Validation loss: 1.8224659914611487

Epoch: 5| Step: 6
Training loss: 0.4907117486000061
Validation loss: 1.8338201315172258

Epoch: 5| Step: 7
Training loss: 0.7109578847885132
Validation loss: 1.8395684560139973

Epoch: 5| Step: 8
Training loss: 0.4939597547054291
Validation loss: 1.8501087952685613

Epoch: 5| Step: 9
Training loss: 0.843904972076416
Validation loss: 1.8320591501010361

Epoch: 5| Step: 10
Training loss: 0.9507050514221191
Validation loss: 1.8448039242016372

Epoch: 234| Step: 0
Training loss: 0.5431817173957825
Validation loss: 1.8662617847483645

Epoch: 5| Step: 1
Training loss: 0.6500346660614014
Validation loss: 1.883041363890453

Epoch: 5| Step: 2
Training loss: 0.7910890579223633
Validation loss: 1.9018537280380086

Epoch: 5| Step: 3
Training loss: 0.6102842688560486
Validation loss: 1.908874750137329

Epoch: 5| Step: 4
Training loss: 0.8336650729179382
Validation loss: 1.9290781200573008

Epoch: 5| Step: 5
Training loss: 0.7927966713905334
Validation loss: 1.917335073153178

Epoch: 5| Step: 6
Training loss: 0.7167435884475708
Validation loss: 1.8667596796507477

Epoch: 5| Step: 7
Training loss: 0.40572303533554077
Validation loss: 1.9066203448080248

Epoch: 5| Step: 8
Training loss: 0.8953496813774109
Validation loss: 1.8643922575058476

Epoch: 5| Step: 9
Training loss: 0.2678419053554535
Validation loss: 1.8500398871719197

Epoch: 5| Step: 10
Training loss: 0.9092557430267334
Validation loss: 1.8125724536116405

Epoch: 235| Step: 0
Training loss: 0.7375606298446655
Validation loss: 1.7973217374535018

Epoch: 5| Step: 1
Training loss: 0.6055644750595093
Validation loss: 1.8283317909445813

Epoch: 5| Step: 2
Training loss: 1.2124249935150146
Validation loss: 1.8307755788167317

Epoch: 5| Step: 3
Training loss: 0.8014167547225952
Validation loss: 1.8548727753341838

Epoch: 5| Step: 4
Training loss: 0.4893621504306793
Validation loss: 1.8805223972566667

Epoch: 5| Step: 5
Training loss: 0.4717097282409668
Validation loss: 1.8935619964394519

Epoch: 5| Step: 6
Training loss: 0.44675907492637634
Validation loss: 1.8928101267865909

Epoch: 5| Step: 7
Training loss: 0.5143393278121948
Validation loss: 1.90958748966135

Epoch: 5| Step: 8
Training loss: 0.6276035308837891
Validation loss: 1.9261963713553645

Epoch: 5| Step: 9
Training loss: 0.8476068377494812
Validation loss: 1.917699049877864

Epoch: 5| Step: 10
Training loss: 0.5295880436897278
Validation loss: 1.903710457586473

Epoch: 236| Step: 0
Training loss: 0.8485798835754395
Validation loss: 1.8672441205670756

Epoch: 5| Step: 1
Training loss: 0.6599970459938049
Validation loss: 1.8852969087580198

Epoch: 5| Step: 2
Training loss: 0.4372921884059906
Validation loss: 1.847058298767254

Epoch: 5| Step: 3
Training loss: 0.7561697959899902
Validation loss: 1.8288341645271546

Epoch: 5| Step: 4
Training loss: 0.8492364883422852
Validation loss: 1.8237661366821618

Epoch: 5| Step: 5
Training loss: 0.5003809332847595
Validation loss: 1.823467464857204

Epoch: 5| Step: 6
Training loss: 0.7335818409919739
Validation loss: 1.8383827209472656

Epoch: 5| Step: 7
Training loss: 0.7851015329360962
Validation loss: 1.8077756999641337

Epoch: 5| Step: 8
Training loss: 0.5735548734664917
Validation loss: 1.8332071458139727

Epoch: 5| Step: 9
Training loss: 0.6577591300010681
Validation loss: 1.8208379681392381

Epoch: 5| Step: 10
Training loss: 0.5033119320869446
Validation loss: 1.8604909143140238

Epoch: 237| Step: 0
Training loss: 0.7192573547363281
Validation loss: 1.884175237788949

Epoch: 5| Step: 1
Training loss: 0.5455478429794312
Validation loss: 1.8733211730116157

Epoch: 5| Step: 2
Training loss: 0.4255661070346832
Validation loss: 1.8874170267453758

Epoch: 5| Step: 3
Training loss: 0.5867050886154175
Validation loss: 1.9098498859713156

Epoch: 5| Step: 4
Training loss: 0.6335356831550598
Validation loss: 1.8814546074918521

Epoch: 5| Step: 5
Training loss: 0.5493378043174744
Validation loss: 1.852686094981368

Epoch: 5| Step: 6
Training loss: 0.31222012639045715
Validation loss: 1.8194245599931287

Epoch: 5| Step: 7
Training loss: 0.8534747958183289
Validation loss: 1.7840123804666663

Epoch: 5| Step: 8
Training loss: 1.0225133895874023
Validation loss: 1.749369905840966

Epoch: 5| Step: 9
Training loss: 0.667255163192749
Validation loss: 1.7462377330308319

Epoch: 5| Step: 10
Training loss: 0.7821415066719055
Validation loss: 1.7436785339027323

Epoch: 238| Step: 0
Training loss: 0.6039506793022156
Validation loss: 1.7612909193961852

Epoch: 5| Step: 1
Training loss: 0.6279276013374329
Validation loss: 1.7715581924684587

Epoch: 5| Step: 2
Training loss: 0.7179169654846191
Validation loss: 1.7821337894726825

Epoch: 5| Step: 3
Training loss: 0.8075698018074036
Validation loss: 1.8509975146221858

Epoch: 5| Step: 4
Training loss: 0.369262158870697
Validation loss: 1.8298704854903682

Epoch: 5| Step: 5
Training loss: 0.8128589391708374
Validation loss: 1.8548224536321496

Epoch: 5| Step: 6
Training loss: 0.5441185832023621
Validation loss: 1.8751162995574295

Epoch: 5| Step: 7
Training loss: 0.7865862846374512
Validation loss: 1.8920044334985877

Epoch: 5| Step: 8
Training loss: 0.6167439222335815
Validation loss: 1.9145139494249899

Epoch: 5| Step: 9
Training loss: 0.6378641128540039
Validation loss: 1.9229659431724138

Epoch: 5| Step: 10
Training loss: 0.6596357822418213
Validation loss: 1.9233129165505851

Epoch: 239| Step: 0
Training loss: 0.8289031982421875
Validation loss: 1.907811551965693

Epoch: 5| Step: 1
Training loss: 0.4863024652004242
Validation loss: 1.8328415770684519

Epoch: 5| Step: 2
Training loss: 0.6791709065437317
Validation loss: 1.8457955109175814

Epoch: 5| Step: 3
Training loss: 0.4143497943878174
Validation loss: 1.8627000675406507

Epoch: 5| Step: 4
Training loss: 0.5534701943397522
Validation loss: 1.8761655476785475

Epoch: 5| Step: 5
Training loss: 0.7174282670021057
Validation loss: 1.914900238795947

Epoch: 5| Step: 6
Training loss: 0.7450793385505676
Validation loss: 1.8857782938147103

Epoch: 5| Step: 7
Training loss: 0.6086521148681641
Validation loss: 1.8726891266402377

Epoch: 5| Step: 8
Training loss: 0.8968585729598999
Validation loss: 1.8838636952061807

Epoch: 5| Step: 9
Training loss: 0.5224721431732178
Validation loss: 1.8671089436418267

Epoch: 5| Step: 10
Training loss: 0.6708545684814453
Validation loss: 1.8808853523705595

Epoch: 240| Step: 0
Training loss: 0.6874648332595825
Validation loss: 1.897674778456329

Epoch: 5| Step: 1
Training loss: 0.9273455739021301
Validation loss: 1.8890461447418376

Epoch: 5| Step: 2
Training loss: 0.6570057272911072
Validation loss: 1.9156787805659796

Epoch: 5| Step: 3
Training loss: 0.40882739424705505
Validation loss: 1.9022402660821074

Epoch: 5| Step: 4
Training loss: 0.6000345349311829
Validation loss: 1.9278340262751426

Epoch: 5| Step: 5
Training loss: 0.5176302194595337
Validation loss: 1.9288456478426534

Epoch: 5| Step: 6
Training loss: 0.47466927766799927
Validation loss: 1.9144420264869608

Epoch: 5| Step: 7
Training loss: 0.695298433303833
Validation loss: 1.9169886945396342

Epoch: 5| Step: 8
Training loss: 0.8029786944389343
Validation loss: 1.8736979999849874

Epoch: 5| Step: 9
Training loss: 0.834145188331604
Validation loss: 1.848148504892985

Epoch: 5| Step: 10
Training loss: 0.48057931661605835
Validation loss: 1.819333521268701

Epoch: 241| Step: 0
Training loss: 0.3949931263923645
Validation loss: 1.8556846239233529

Epoch: 5| Step: 1
Training loss: 0.7784745693206787
Validation loss: 1.8271937088299823

Epoch: 5| Step: 2
Training loss: 0.6137045621871948
Validation loss: 1.8205368685465988

Epoch: 5| Step: 3
Training loss: 0.5643099546432495
Validation loss: 1.815432261395198

Epoch: 5| Step: 4
Training loss: 0.9206985235214233
Validation loss: 1.83817183907314

Epoch: 5| Step: 5
Training loss: 0.5616388320922852
Validation loss: 1.8504050649622434

Epoch: 5| Step: 6
Training loss: 0.3201819360256195
Validation loss: 1.8324017524719238

Epoch: 5| Step: 7
Training loss: 0.6311652660369873
Validation loss: 1.8340859131146503

Epoch: 5| Step: 8
Training loss: 0.5661965012550354
Validation loss: 1.8536662952874297

Epoch: 5| Step: 9
Training loss: 0.7744736671447754
Validation loss: 1.8452973083783222

Epoch: 5| Step: 10
Training loss: 0.6612166166305542
Validation loss: 1.8598750739969232

Epoch: 242| Step: 0
Training loss: 0.6525489687919617
Validation loss: 1.8506253829566381

Epoch: 5| Step: 1
Training loss: 0.8692895174026489
Validation loss: 1.8407576904501965

Epoch: 5| Step: 2
Training loss: 0.83381187915802
Validation loss: 1.8341629043702157

Epoch: 5| Step: 3
Training loss: 0.5302709937095642
Validation loss: 1.8487035933361258

Epoch: 5| Step: 4
Training loss: 0.451075941324234
Validation loss: 1.8697371047030213

Epoch: 5| Step: 5
Training loss: 0.7479223012924194
Validation loss: 1.8680930381180139

Epoch: 5| Step: 6
Training loss: 0.55808025598526
Validation loss: 1.8523246190881217

Epoch: 5| Step: 7
Training loss: 0.34611889719963074
Validation loss: 1.890354371839954

Epoch: 5| Step: 8
Training loss: 0.5357352495193481
Validation loss: 1.85955132848473

Epoch: 5| Step: 9
Training loss: 0.6720412969589233
Validation loss: 1.8478442827860515

Epoch: 5| Step: 10
Training loss: 0.6147404909133911
Validation loss: 1.844920043022402

Epoch: 243| Step: 0
Training loss: 0.3325730562210083
Validation loss: 1.8465475856616933

Epoch: 5| Step: 1
Training loss: 0.6944161653518677
Validation loss: 1.8579869629234396

Epoch: 5| Step: 2
Training loss: 0.4495569169521332
Validation loss: 1.8599781361959313

Epoch: 5| Step: 3
Training loss: 0.5619922876358032
Validation loss: 1.8299676641341178

Epoch: 5| Step: 4
Training loss: 0.8396175503730774
Validation loss: 1.8216794434414114

Epoch: 5| Step: 5
Training loss: 0.47842103242874146
Validation loss: 1.8294529735401113

Epoch: 5| Step: 6
Training loss: 1.0108131170272827
Validation loss: 1.8345021560627928

Epoch: 5| Step: 7
Training loss: 0.3651869297027588
Validation loss: 1.8775451106409873

Epoch: 5| Step: 8
Training loss: 0.8276678323745728
Validation loss: 1.8929154872894287

Epoch: 5| Step: 9
Training loss: 0.6975359916687012
Validation loss: 1.8868506570016184

Epoch: 5| Step: 10
Training loss: 0.5462331771850586
Validation loss: 1.907660577886848

Epoch: 244| Step: 0
Training loss: 0.9192447662353516
Validation loss: 1.9026799099419707

Epoch: 5| Step: 1
Training loss: 0.6164679527282715
Validation loss: 1.8534529978229153

Epoch: 5| Step: 2
Training loss: 0.9433774948120117
Validation loss: 1.812557037158679

Epoch: 5| Step: 3
Training loss: 0.5204467177391052
Validation loss: 1.8105863371203024

Epoch: 5| Step: 4
Training loss: 0.27395787835121155
Validation loss: 1.80573288343286

Epoch: 5| Step: 5
Training loss: 0.6221779584884644
Validation loss: 1.7873213470623057

Epoch: 5| Step: 6
Training loss: 0.4708293080329895
Validation loss: 1.8123371754923174

Epoch: 5| Step: 7
Training loss: 0.19249767065048218
Validation loss: 1.8272881046418221

Epoch: 5| Step: 8
Training loss: 0.9302423596382141
Validation loss: 1.8723712762196858

Epoch: 5| Step: 9
Training loss: 0.7459424138069153
Validation loss: 1.8713242648750223

Epoch: 5| Step: 10
Training loss: 0.40214118361473083
Validation loss: 1.844757446678736

Epoch: 245| Step: 0
Training loss: 0.4783600866794586
Validation loss: 1.854139938149401

Epoch: 5| Step: 1
Training loss: 0.2848552167415619
Validation loss: 1.8550792842782953

Epoch: 5| Step: 2
Training loss: 0.49756306409835815
Validation loss: 1.8487908724815614

Epoch: 5| Step: 3
Training loss: 0.6464179158210754
Validation loss: 1.831895479591944

Epoch: 5| Step: 4
Training loss: 0.7372731566429138
Validation loss: 1.8754715041447712

Epoch: 5| Step: 5
Training loss: 0.7087178230285645
Validation loss: 1.8590718507766724

Epoch: 5| Step: 6
Training loss: 0.7017642259597778
Validation loss: 1.853315431584594

Epoch: 5| Step: 7
Training loss: 0.8381448984146118
Validation loss: 1.8036322388597714

Epoch: 5| Step: 8
Training loss: 0.3956465721130371
Validation loss: 1.8186643379990772

Epoch: 5| Step: 9
Training loss: 0.7614997029304504
Validation loss: 1.8073303404674734

Epoch: 5| Step: 10
Training loss: 0.6178430914878845
Validation loss: 1.8262750833265242

Epoch: 246| Step: 0
Training loss: 0.31699609756469727
Validation loss: 1.858570373186501

Epoch: 5| Step: 1
Training loss: 0.3685230612754822
Validation loss: 1.8617956330699306

Epoch: 5| Step: 2
Training loss: 0.6565424799919128
Validation loss: 1.8617885638308782

Epoch: 5| Step: 3
Training loss: 0.811863899230957
Validation loss: 1.8466820524584862

Epoch: 5| Step: 4
Training loss: 0.6017923951148987
Validation loss: 1.8593976984741867

Epoch: 5| Step: 5
Training loss: 0.6899257302284241
Validation loss: 1.9057958664432648

Epoch: 5| Step: 6
Training loss: 0.7983958125114441
Validation loss: 1.9035810860254432

Epoch: 5| Step: 7
Training loss: 0.7005835771560669
Validation loss: 1.896331702509234

Epoch: 5| Step: 8
Training loss: 0.6017756462097168
Validation loss: 1.8698019212292087

Epoch: 5| Step: 9
Training loss: 0.4032652974128723
Validation loss: 1.8814835138218378

Epoch: 5| Step: 10
Training loss: 0.7253747582435608
Validation loss: 1.7891187514028242

Epoch: 247| Step: 0
Training loss: 0.47607746720314026
Validation loss: 1.7809871960711736

Epoch: 5| Step: 1
Training loss: 0.4774858057498932
Validation loss: 1.7938590357380528

Epoch: 5| Step: 2
Training loss: 0.44228941202163696
Validation loss: 1.779906613852388

Epoch: 5| Step: 3
Training loss: 0.6076172590255737
Validation loss: 1.809343796904369

Epoch: 5| Step: 4
Training loss: 0.7939265370368958
Validation loss: 1.8081211787398144

Epoch: 5| Step: 5
Training loss: 0.6297832131385803
Validation loss: 1.8328423474424629

Epoch: 5| Step: 6
Training loss: 0.9344179034233093
Validation loss: 1.829690044926059

Epoch: 5| Step: 7
Training loss: 0.7033472657203674
Validation loss: 1.8107945226853894

Epoch: 5| Step: 8
Training loss: 0.57618647813797
Validation loss: 1.8387939263415594

Epoch: 5| Step: 9
Training loss: 0.3802958130836487
Validation loss: 1.8643985666254514

Epoch: 5| Step: 10
Training loss: 0.5992820262908936
Validation loss: 1.8746014512995237

Epoch: 248| Step: 0
Training loss: 0.5875924825668335
Validation loss: 1.8796245308332546

Epoch: 5| Step: 1
Training loss: 0.7042316198348999
Validation loss: 1.8596879871942664

Epoch: 5| Step: 2
Training loss: 0.4949328303337097
Validation loss: 1.8580330071910736

Epoch: 5| Step: 3
Training loss: 0.36924368143081665
Validation loss: 1.8602719332582207

Epoch: 5| Step: 4
Training loss: 0.7161957025527954
Validation loss: 1.8562668485026206

Epoch: 5| Step: 5
Training loss: 0.6965945959091187
Validation loss: 1.8505871911202707

Epoch: 5| Step: 6
Training loss: 0.43687528371810913
Validation loss: 1.8883168158992645

Epoch: 5| Step: 7
Training loss: 0.6081260442733765
Validation loss: 1.805658882664096

Epoch: 5| Step: 8
Training loss: 0.34517258405685425
Validation loss: 1.8138474700271443

Epoch: 5| Step: 9
Training loss: 0.638699471950531
Validation loss: 1.7744294315256097

Epoch: 5| Step: 10
Training loss: 0.7251162528991699
Validation loss: 1.8074776972493818

Epoch: 249| Step: 0
Training loss: 0.6073028445243835
Validation loss: 1.797325139404625

Epoch: 5| Step: 1
Training loss: 0.4797496795654297
Validation loss: 1.7934297925682479

Epoch: 5| Step: 2
Training loss: 0.7190850377082825
Validation loss: 1.805579722568553

Epoch: 5| Step: 3
Training loss: 0.3182554543018341
Validation loss: 1.832549043880996

Epoch: 5| Step: 4
Training loss: 0.5791917443275452
Validation loss: 1.8960853071622952

Epoch: 5| Step: 5
Training loss: 0.5742244720458984
Validation loss: 1.9284398030209284

Epoch: 5| Step: 6
Training loss: 0.8248055577278137
Validation loss: 1.9298056453786872

Epoch: 5| Step: 7
Training loss: 0.7489785552024841
Validation loss: 1.9137703084176587

Epoch: 5| Step: 8
Training loss: 0.37915849685668945
Validation loss: 1.8950573359766314

Epoch: 5| Step: 9
Training loss: 0.6824692487716675
Validation loss: 1.873541784542863

Epoch: 5| Step: 10
Training loss: 0.43102869391441345
Validation loss: 1.831359342862201

Epoch: 250| Step: 0
Training loss: 0.7359228730201721
Validation loss: 1.8157590230305989

Epoch: 5| Step: 1
Training loss: 0.589040994644165
Validation loss: 1.8081756637942406

Epoch: 5| Step: 2
Training loss: 0.4735291600227356
Validation loss: 1.8160231074979227

Epoch: 5| Step: 3
Training loss: 0.5230680704116821
Validation loss: 1.7834293560315204

Epoch: 5| Step: 4
Training loss: 0.5320576429367065
Validation loss: 1.8441694987717496

Epoch: 5| Step: 5
Training loss: 0.6520116925239563
Validation loss: 1.856958843046619

Epoch: 5| Step: 6
Training loss: 0.7170199155807495
Validation loss: 1.8542603536318707

Epoch: 5| Step: 7
Training loss: 0.2438444346189499
Validation loss: 1.880927570404545

Epoch: 5| Step: 8
Training loss: 0.6409710049629211
Validation loss: 1.907116727162433

Epoch: 5| Step: 9
Training loss: 0.7819107174873352
Validation loss: 1.8801997810281732

Epoch: 5| Step: 10
Training loss: 0.30388590693473816
Validation loss: 1.8853853184689757

Epoch: 251| Step: 0
Training loss: 0.6490659117698669
Validation loss: 1.8683321578528291

Epoch: 5| Step: 1
Training loss: 0.6370022296905518
Validation loss: 1.8244515260060628

Epoch: 5| Step: 2
Training loss: 0.5235232710838318
Validation loss: 1.8537914701687392

Epoch: 5| Step: 3
Training loss: 0.5587506890296936
Validation loss: 1.8155822125814294

Epoch: 5| Step: 4
Training loss: 0.3611203730106354
Validation loss: 1.837226636948124

Epoch: 5| Step: 5
Training loss: 0.5330983400344849
Validation loss: 1.8147776344771027

Epoch: 5| Step: 6
Training loss: 0.5674294829368591
Validation loss: 1.7944864124380133

Epoch: 5| Step: 7
Training loss: 0.6204473376274109
Validation loss: 1.7963819132056287

Epoch: 5| Step: 8
Training loss: 0.6103348135948181
Validation loss: 1.7861804936521797

Epoch: 5| Step: 9
Training loss: 0.4683729112148285
Validation loss: 1.7953579643721223

Epoch: 5| Step: 10
Training loss: 0.6195164918899536
Validation loss: 1.8151310772024176

Epoch: 252| Step: 0
Training loss: 0.3022897243499756
Validation loss: 1.8444817143101846

Epoch: 5| Step: 1
Training loss: 0.41668277978897095
Validation loss: 1.7987932441055134

Epoch: 5| Step: 2
Training loss: 0.4109784960746765
Validation loss: 1.796776965100278

Epoch: 5| Step: 3
Training loss: 0.8746034502983093
Validation loss: 1.8037863610893168

Epoch: 5| Step: 4
Training loss: 0.8594385385513306
Validation loss: 1.8573680667467014

Epoch: 5| Step: 5
Training loss: 0.694333553314209
Validation loss: 1.85617571748713

Epoch: 5| Step: 6
Training loss: 0.6990319490432739
Validation loss: 1.8281093207738732

Epoch: 5| Step: 7
Training loss: 0.5491689443588257
Validation loss: 1.8004950284957886

Epoch: 5| Step: 8
Training loss: 0.4851754307746887
Validation loss: 1.7949576313777635

Epoch: 5| Step: 9
Training loss: 0.7169334888458252
Validation loss: 1.7890475719205794

Epoch: 5| Step: 10
Training loss: 0.651191234588623
Validation loss: 1.8385022404373332

Epoch: 253| Step: 0
Training loss: 0.796671986579895
Validation loss: 1.830991147666849

Epoch: 5| Step: 1
Training loss: 0.46252530813217163
Validation loss: 1.8197166342889108

Epoch: 5| Step: 2
Training loss: 0.5988287925720215
Validation loss: 1.8491665188984205

Epoch: 5| Step: 3
Training loss: 0.5512805581092834
Validation loss: 1.830491796616585

Epoch: 5| Step: 4
Training loss: 0.6798820495605469
Validation loss: 1.8939514493429532

Epoch: 5| Step: 5
Training loss: 0.45170125365257263
Validation loss: 1.8569962606635144

Epoch: 5| Step: 6
Training loss: 0.5588659048080444
Validation loss: 1.917060709768726

Epoch: 5| Step: 7
Training loss: 0.4933578372001648
Validation loss: 1.9130365925450479

Epoch: 5| Step: 8
Training loss: 0.4861779808998108
Validation loss: 1.9243810240940382

Epoch: 5| Step: 9
Training loss: 0.6521245241165161
Validation loss: 1.9226727947112052

Epoch: 5| Step: 10
Training loss: 0.692003607749939
Validation loss: 1.9147350839389268

Epoch: 254| Step: 0
Training loss: 0.40906062722206116
Validation loss: 1.871827849777796

Epoch: 5| Step: 1
Training loss: 0.30615168809890747
Validation loss: 1.8587772846221924

Epoch: 5| Step: 2
Training loss: 0.6917940378189087
Validation loss: 1.8327600545780633

Epoch: 5| Step: 3
Training loss: 0.6466074585914612
Validation loss: 1.8520985828932894

Epoch: 5| Step: 4
Training loss: 0.587297260761261
Validation loss: 1.8406184963000718

Epoch: 5| Step: 5
Training loss: 0.4360302984714508
Validation loss: 1.8614458601961854

Epoch: 5| Step: 6
Training loss: 0.42750582098960876
Validation loss: 1.875264375440536

Epoch: 5| Step: 7
Training loss: 0.4963630735874176
Validation loss: 1.8685570096456876

Epoch: 5| Step: 8
Training loss: 0.47996360063552856
Validation loss: 1.8452468443942327

Epoch: 5| Step: 9
Training loss: 0.8995033502578735
Validation loss: 1.7935545367579306

Epoch: 5| Step: 10
Training loss: 0.8627351522445679
Validation loss: 1.7790129428268762

Epoch: 255| Step: 0
Training loss: 0.6095916628837585
Validation loss: 1.761419730801736

Epoch: 5| Step: 1
Training loss: 0.5759207606315613
Validation loss: 1.7574029827630648

Epoch: 5| Step: 2
Training loss: 0.3789672255516052
Validation loss: 1.7537817929380684

Epoch: 5| Step: 3
Training loss: 0.5008214712142944
Validation loss: 1.7828202478347286

Epoch: 5| Step: 4
Training loss: 0.3274611532688141
Validation loss: 1.7812305022311468

Epoch: 5| Step: 5
Training loss: 0.5319047570228577
Validation loss: 1.8167784534474856

Epoch: 5| Step: 6
Training loss: 0.4048871397972107
Validation loss: 1.7809457189293318

Epoch: 5| Step: 7
Training loss: 0.702612042427063
Validation loss: 1.8080662783756052

Epoch: 5| Step: 8
Training loss: 0.5411831736564636
Validation loss: 1.821363820824572

Epoch: 5| Step: 9
Training loss: 0.7905595898628235
Validation loss: 1.813691117430246

Epoch: 5| Step: 10
Training loss: 0.7168000340461731
Validation loss: 1.8265134942147039

Epoch: 256| Step: 0
Training loss: 0.5151665806770325
Validation loss: 1.7918457420923377

Epoch: 5| Step: 1
Training loss: 0.4075550138950348
Validation loss: 1.7908010598151916

Epoch: 5| Step: 2
Training loss: 0.5953539609909058
Validation loss: 1.800254460304014

Epoch: 5| Step: 3
Training loss: 0.5379041433334351
Validation loss: 1.8079626098755868

Epoch: 5| Step: 4
Training loss: 0.44033828377723694
Validation loss: 1.8307298947406072

Epoch: 5| Step: 5
Training loss: 0.3000217080116272
Validation loss: 1.8293583047005437

Epoch: 5| Step: 6
Training loss: 0.7377797365188599
Validation loss: 1.8348810326668523

Epoch: 5| Step: 7
Training loss: 0.6854720115661621
Validation loss: 1.8639062989142634

Epoch: 5| Step: 8
Training loss: 0.34098950028419495
Validation loss: 1.888721058445592

Epoch: 5| Step: 9
Training loss: 0.811236560344696
Validation loss: 1.8675913195456229

Epoch: 5| Step: 10
Training loss: 0.6802317500114441
Validation loss: 1.8915758517480665

Epoch: 257| Step: 0
Training loss: 0.6585345268249512
Validation loss: 1.8784142283983127

Epoch: 5| Step: 1
Training loss: 0.4683739244937897
Validation loss: 1.849462680919196

Epoch: 5| Step: 2
Training loss: 0.5587915182113647
Validation loss: 1.8839159152841056

Epoch: 5| Step: 3
Training loss: 0.4975094795227051
Validation loss: 1.8502445169674453

Epoch: 5| Step: 4
Training loss: 0.5526591539382935
Validation loss: 1.8327644243035266

Epoch: 5| Step: 5
Training loss: 0.7105681300163269
Validation loss: 1.8457387749866774

Epoch: 5| Step: 6
Training loss: 0.3072054088115692
Validation loss: 1.8358133531385852

Epoch: 5| Step: 7
Training loss: 0.44540563225746155
Validation loss: 1.8272519150087911

Epoch: 5| Step: 8
Training loss: 0.721923828125
Validation loss: 1.8366252299278014

Epoch: 5| Step: 9
Training loss: 0.30680030584335327
Validation loss: 1.8520223927754227

Epoch: 5| Step: 10
Training loss: 0.6243994235992432
Validation loss: 1.873193766481133

Epoch: 258| Step: 0
Training loss: 0.70838862657547
Validation loss: 1.8771855292781707

Epoch: 5| Step: 1
Training loss: 0.45951777696609497
Validation loss: 1.9043544364231888

Epoch: 5| Step: 2
Training loss: 1.1006662845611572
Validation loss: 1.8995761371427966

Epoch: 5| Step: 3
Training loss: 0.49967002868652344
Validation loss: 1.8572065714866883

Epoch: 5| Step: 4
Training loss: 0.5216421484947205
Validation loss: 1.8393818338712056

Epoch: 5| Step: 5
Training loss: 0.41234707832336426
Validation loss: 1.8350167300111504

Epoch: 5| Step: 6
Training loss: 0.44794121384620667
Validation loss: 1.8431814075798116

Epoch: 5| Step: 7
Training loss: 0.5226317644119263
Validation loss: 1.8208406317618586

Epoch: 5| Step: 8
Training loss: 0.4523450434207916
Validation loss: 1.820737636217507

Epoch: 5| Step: 9
Training loss: 0.30751824378967285
Validation loss: 1.8400861088947584

Epoch: 5| Step: 10
Training loss: 0.4433228075504303
Validation loss: 1.8160926218955749

Epoch: 259| Step: 0
Training loss: 0.6226561665534973
Validation loss: 1.817983204318631

Epoch: 5| Step: 1
Training loss: 0.5019858479499817
Validation loss: 1.819993188304286

Epoch: 5| Step: 2
Training loss: 0.6944566965103149
Validation loss: 1.8670160949871104

Epoch: 5| Step: 3
Training loss: 0.6125897169113159
Validation loss: 1.8539101744210849

Epoch: 5| Step: 4
Training loss: 0.39550870656967163
Validation loss: 1.8600252020743586

Epoch: 5| Step: 5
Training loss: 0.3371413052082062
Validation loss: 1.8485261624859226

Epoch: 5| Step: 6
Training loss: 0.5213244557380676
Validation loss: 1.809212000139298

Epoch: 5| Step: 7
Training loss: 0.7125453948974609
Validation loss: 1.8510923795802618

Epoch: 5| Step: 8
Training loss: 0.4033139646053314
Validation loss: 1.8573192909199705

Epoch: 5| Step: 9
Training loss: 0.5107964873313904
Validation loss: 1.8237660187546925

Epoch: 5| Step: 10
Training loss: 0.7061998844146729
Validation loss: 1.8561282542444044

Epoch: 260| Step: 0
Training loss: 0.536101222038269
Validation loss: 1.8642658290042673

Epoch: 5| Step: 1
Training loss: 0.424885094165802
Validation loss: 1.8543371538962088

Epoch: 5| Step: 2
Training loss: 0.6728618144989014
Validation loss: 1.8557947809978197

Epoch: 5| Step: 3
Training loss: 0.3198370933532715
Validation loss: 1.7998489320919078

Epoch: 5| Step: 4
Training loss: 0.7061895132064819
Validation loss: 1.8063964061839606

Epoch: 5| Step: 5
Training loss: 0.8563499450683594
Validation loss: 1.7825596512004893

Epoch: 5| Step: 6
Training loss: 0.5606662034988403
Validation loss: 1.7426183018633115

Epoch: 5| Step: 7
Training loss: 0.299821674823761
Validation loss: 1.7414601669516614

Epoch: 5| Step: 8
Training loss: 0.795728862285614
Validation loss: 1.753564711539976

Epoch: 5| Step: 9
Training loss: 0.5173985362052917
Validation loss: 1.7470573866239159

Epoch: 5| Step: 10
Training loss: 0.1684466302394867
Validation loss: 1.7833815197790823

Epoch: 261| Step: 0
Training loss: 0.2955550253391266
Validation loss: 1.8276907602945964

Epoch: 5| Step: 1
Training loss: 0.4070448875427246
Validation loss: 1.8154312820844754

Epoch: 5| Step: 2
Training loss: 0.6385473012924194
Validation loss: 1.83892487454158

Epoch: 5| Step: 3
Training loss: 0.5095289945602417
Validation loss: 1.823996893821224

Epoch: 5| Step: 4
Training loss: 0.5016399621963501
Validation loss: 1.8070292677930606

Epoch: 5| Step: 5
Training loss: 0.6644266247749329
Validation loss: 1.7659630339632753

Epoch: 5| Step: 6
Training loss: 0.7501893043518066
Validation loss: 1.7569010437175792

Epoch: 5| Step: 7
Training loss: 0.5934281349182129
Validation loss: 1.7696013553168184

Epoch: 5| Step: 8
Training loss: 0.7003887891769409
Validation loss: 1.7876722633197744

Epoch: 5| Step: 9
Training loss: 0.46992582082748413
Validation loss: 1.7650486038577171

Epoch: 5| Step: 10
Training loss: 0.3046551048755646
Validation loss: 1.8175296783447266

Epoch: 262| Step: 0
Training loss: 0.6341654062271118
Validation loss: 1.869687605929631

Epoch: 5| Step: 1
Training loss: 0.7130186557769775
Validation loss: 1.917190146702592

Epoch: 5| Step: 2
Training loss: 0.40097522735595703
Validation loss: 1.9165697789961291

Epoch: 5| Step: 3
Training loss: 0.49979615211486816
Validation loss: 1.9010341013631513

Epoch: 5| Step: 4
Training loss: 0.46253085136413574
Validation loss: 1.9007836452094458

Epoch: 5| Step: 5
Training loss: 0.5195080041885376
Validation loss: 1.8467331650436565

Epoch: 5| Step: 6
Training loss: 0.21618732810020447
Validation loss: 1.8482753935680594

Epoch: 5| Step: 7
Training loss: 0.36596018075942993
Validation loss: 1.8259724634949879

Epoch: 5| Step: 8
Training loss: 0.6159462928771973
Validation loss: 1.8181128322437246

Epoch: 5| Step: 9
Training loss: 0.764572024345398
Validation loss: 1.8059416035170197

Epoch: 5| Step: 10
Training loss: 0.6206434369087219
Validation loss: 1.7462646192119968

Epoch: 263| Step: 0
Training loss: 0.6448785066604614
Validation loss: 1.786273451261623

Epoch: 5| Step: 1
Training loss: 0.34143245220184326
Validation loss: 1.7635172285059446

Epoch: 5| Step: 2
Training loss: 0.7350836992263794
Validation loss: 1.7801699817821544

Epoch: 5| Step: 3
Training loss: 0.5039125680923462
Validation loss: 1.8181854217283187

Epoch: 5| Step: 4
Training loss: 0.4109683930873871
Validation loss: 1.875309254533501

Epoch: 5| Step: 5
Training loss: 0.5624205470085144
Validation loss: 1.8924022105432325

Epoch: 5| Step: 6
Training loss: 0.6658926010131836
Validation loss: 1.894359915487228

Epoch: 5| Step: 7
Training loss: 0.6796852946281433
Validation loss: 1.8750066705929336

Epoch: 5| Step: 8
Training loss: 0.5705245137214661
Validation loss: 1.8695785819843251

Epoch: 5| Step: 9
Training loss: 0.5221516489982605
Validation loss: 1.8465160605727986

Epoch: 5| Step: 10
Training loss: 0.3493410646915436
Validation loss: 1.8663445147134925

Epoch: 264| Step: 0
Training loss: 0.40829628705978394
Validation loss: 1.8414856579995924

Epoch: 5| Step: 1
Training loss: 0.7538691759109497
Validation loss: 1.8227018156359274

Epoch: 5| Step: 2
Training loss: 0.42474889755249023
Validation loss: 1.8089272514466317

Epoch: 5| Step: 3
Training loss: 0.40870070457458496
Validation loss: 1.8136501748074767

Epoch: 5| Step: 4
Training loss: 0.36304929852485657
Validation loss: 1.8272208347115466

Epoch: 5| Step: 5
Training loss: 0.7495206594467163
Validation loss: 1.8548697758746404

Epoch: 5| Step: 6
Training loss: 0.5338064432144165
Validation loss: 1.851437186682096

Epoch: 5| Step: 7
Training loss: 0.32048720121383667
Validation loss: 1.8877338632460563

Epoch: 5| Step: 8
Training loss: 0.676662027835846
Validation loss: 1.9016542332146757

Epoch: 5| Step: 9
Training loss: 0.6552953720092773
Validation loss: 1.8978817770558019

Epoch: 5| Step: 10
Training loss: 0.5794042348861694
Validation loss: 1.9272059163739603

Epoch: 265| Step: 0
Training loss: 0.7410392761230469
Validation loss: 1.884871470030918

Epoch: 5| Step: 1
Training loss: 0.24594469368457794
Validation loss: 1.8430956204732258

Epoch: 5| Step: 2
Training loss: 0.6127018928527832
Validation loss: 1.789169849887971

Epoch: 5| Step: 3
Training loss: 0.7026208639144897
Validation loss: 1.777627578345678

Epoch: 5| Step: 4
Training loss: 0.7208781242370605
Validation loss: 1.7430485102438158

Epoch: 5| Step: 5
Training loss: 0.3853120803833008
Validation loss: 1.7643363924436672

Epoch: 5| Step: 6
Training loss: 0.4065653681755066
Validation loss: 1.7840437107188727

Epoch: 5| Step: 7
Training loss: 0.2002316415309906
Validation loss: 1.7747538397389073

Epoch: 5| Step: 8
Training loss: 0.484468549489975
Validation loss: 1.8262770034933602

Epoch: 5| Step: 9
Training loss: 0.6253000497817993
Validation loss: 1.858017598429034

Epoch: 5| Step: 10
Training loss: 0.5213854908943176
Validation loss: 1.842600481484526

Epoch: 266| Step: 0
Training loss: 0.4149453639984131
Validation loss: 1.8538576864427136

Epoch: 5| Step: 1
Training loss: 0.4924354553222656
Validation loss: 1.8502435197112381

Epoch: 5| Step: 2
Training loss: 0.5168887376785278
Validation loss: 1.8243745014231691

Epoch: 5| Step: 3
Training loss: 0.44451212882995605
Validation loss: 1.8176066875457764

Epoch: 5| Step: 4
Training loss: 0.512898862361908
Validation loss: 1.7912458630018337

Epoch: 5| Step: 5
Training loss: 0.39658236503601074
Validation loss: 1.7782431648623558

Epoch: 5| Step: 6
Training loss: 0.2687379717826843
Validation loss: 1.7658931747559579

Epoch: 5| Step: 7
Training loss: 0.7754374742507935
Validation loss: 1.7736139810213478

Epoch: 5| Step: 8
Training loss: 0.48586568236351013
Validation loss: 1.7398247846993067

Epoch: 5| Step: 9
Training loss: 0.6633192300796509
Validation loss: 1.7185352784331127

Epoch: 5| Step: 10
Training loss: 0.5357627868652344
Validation loss: 1.726768337270265

Epoch: 267| Step: 0
Training loss: 0.38674479722976685
Validation loss: 1.7503124949752644

Epoch: 5| Step: 1
Training loss: 0.3196871876716614
Validation loss: 1.7516432680109495

Epoch: 5| Step: 2
Training loss: 0.49428945779800415
Validation loss: 1.757635433186767

Epoch: 5| Step: 3
Training loss: 0.7708313465118408
Validation loss: 1.7419593488016436

Epoch: 5| Step: 4
Training loss: 0.7719736695289612
Validation loss: 1.7582959513510428

Epoch: 5| Step: 5
Training loss: 0.6053822040557861
Validation loss: 1.7511780902903566

Epoch: 5| Step: 6
Training loss: 0.409249484539032
Validation loss: 1.7461411106971003

Epoch: 5| Step: 7
Training loss: 0.2940828502178192
Validation loss: 1.7957716462432698

Epoch: 5| Step: 8
Training loss: 0.5205012559890747
Validation loss: 1.8399100701014202

Epoch: 5| Step: 9
Training loss: 0.3223666548728943
Validation loss: 1.8318657926333848

Epoch: 5| Step: 10
Training loss: 0.5359859466552734
Validation loss: 1.8175188738812682

Epoch: 268| Step: 0
Training loss: 0.5587636232376099
Validation loss: 1.8374864260355632

Epoch: 5| Step: 1
Training loss: 0.5202236175537109
Validation loss: 1.8990577843881422

Epoch: 5| Step: 2
Training loss: 0.6601518392562866
Validation loss: 1.8814910650253296

Epoch: 5| Step: 3
Training loss: 0.5114372372627258
Validation loss: 1.8764192724740634

Epoch: 5| Step: 4
Training loss: 0.4696606993675232
Validation loss: 1.8957747567084529

Epoch: 5| Step: 5
Training loss: 0.60601806640625
Validation loss: 1.84720536457595

Epoch: 5| Step: 6
Training loss: 0.5233408212661743
Validation loss: 1.8814203277710946

Epoch: 5| Step: 7
Training loss: 0.4601280093193054
Validation loss: 1.8996546422281573

Epoch: 5| Step: 8
Training loss: 0.5884610414505005
Validation loss: 1.9088350957439792

Epoch: 5| Step: 9
Training loss: 0.5343595743179321
Validation loss: 1.8823030251328663

Epoch: 5| Step: 10
Training loss: 0.6477897763252258
Validation loss: 1.8050987771762315

Epoch: 269| Step: 0
Training loss: 0.3086263835430145
Validation loss: 1.774390447524286

Epoch: 5| Step: 1
Training loss: 0.2601880729198456
Validation loss: 1.7708888233348887

Epoch: 5| Step: 2
Training loss: 0.47611698508262634
Validation loss: 1.806021257113385

Epoch: 5| Step: 3
Training loss: 0.6828407049179077
Validation loss: 1.8444394168033396

Epoch: 5| Step: 4
Training loss: 0.40517276525497437
Validation loss: 1.7692894038333689

Epoch: 5| Step: 5
Training loss: 0.5286017656326294
Validation loss: 1.7346266456829604

Epoch: 5| Step: 6
Training loss: 0.5502867698669434
Validation loss: 1.76588862557565

Epoch: 5| Step: 7
Training loss: 0.5956918001174927
Validation loss: 1.7730871451798307

Epoch: 5| Step: 8
Training loss: 0.7656758427619934
Validation loss: 1.8114853494910783

Epoch: 5| Step: 9
Training loss: 0.57081139087677
Validation loss: 1.86970337488318

Epoch: 5| Step: 10
Training loss: 0.7442799210548401
Validation loss: 1.8920519377595635

Epoch: 270| Step: 0
Training loss: 0.508653998374939
Validation loss: 1.8932123030385664

Epoch: 5| Step: 1
Training loss: 0.6492405533790588
Validation loss: 1.865141760918402

Epoch: 5| Step: 2
Training loss: 0.3754560351371765
Validation loss: 1.8337160848802136

Epoch: 5| Step: 3
Training loss: 0.5249272584915161
Validation loss: 1.8577093232062556

Epoch: 5| Step: 4
Training loss: 0.43278661370277405
Validation loss: 1.8292895542678012

Epoch: 5| Step: 5
Training loss: 0.5718716979026794
Validation loss: 1.8306133567645986

Epoch: 5| Step: 6
Training loss: 0.2756998538970947
Validation loss: 1.8458891504554338

Epoch: 5| Step: 7
Training loss: 0.5656334757804871
Validation loss: 1.840540765434183

Epoch: 5| Step: 8
Training loss: 0.39376169443130493
Validation loss: 1.8151594874679402

Epoch: 5| Step: 9
Training loss: 0.42240118980407715
Validation loss: 1.8136442874067573

Epoch: 5| Step: 10
Training loss: 0.7350466251373291
Validation loss: 1.809061364461017

Epoch: 271| Step: 0
Training loss: 0.6015363931655884
Validation loss: 1.8141252315172585

Epoch: 5| Step: 1
Training loss: 0.6433172821998596
Validation loss: 1.7956706798204811

Epoch: 5| Step: 2
Training loss: 0.37936684489250183
Validation loss: 1.8155983814629175

Epoch: 5| Step: 3
Training loss: 0.3755642771720886
Validation loss: 1.8324051954412972

Epoch: 5| Step: 4
Training loss: 0.699565052986145
Validation loss: 1.85779361186489

Epoch: 5| Step: 5
Training loss: 0.5534831285476685
Validation loss: 1.8704225132542271

Epoch: 5| Step: 6
Training loss: 0.2686067223548889
Validation loss: 1.890067183843223

Epoch: 5| Step: 7
Training loss: 0.576461911201477
Validation loss: 1.903969200708533

Epoch: 5| Step: 8
Training loss: 0.2905244827270508
Validation loss: 1.8619335095087688

Epoch: 5| Step: 9
Training loss: 0.5659124255180359
Validation loss: 1.8438004473204255

Epoch: 5| Step: 10
Training loss: 0.3765956461429596
Validation loss: 1.865090867524506

Epoch: 272| Step: 0
Training loss: 0.32205307483673096
Validation loss: 1.8590553563128236

Epoch: 5| Step: 1
Training loss: 0.6015304327011108
Validation loss: 1.8851294389335058

Epoch: 5| Step: 2
Training loss: 0.23629538714885712
Validation loss: 1.8500696536033385

Epoch: 5| Step: 3
Training loss: 0.5531209111213684
Validation loss: 1.801251599865575

Epoch: 5| Step: 4
Training loss: 0.32051119208335876
Validation loss: 1.7726093389654671

Epoch: 5| Step: 5
Training loss: 0.7983195781707764
Validation loss: 1.8207430070446384

Epoch: 5| Step: 6
Training loss: 0.4708632826805115
Validation loss: 1.858475019854884

Epoch: 5| Step: 7
Training loss: 0.38937485218048096
Validation loss: 1.8738028336596746

Epoch: 5| Step: 8
Training loss: 0.7176310420036316
Validation loss: 1.8547660279017624

Epoch: 5| Step: 9
Training loss: 0.36465898156166077
Validation loss: 1.8104054338188582

Epoch: 5| Step: 10
Training loss: 0.4809466004371643
Validation loss: 1.7882122967832832

Epoch: 273| Step: 0
Training loss: 0.4966806471347809
Validation loss: 1.7860677261506357

Epoch: 5| Step: 1
Training loss: 0.23532715439796448
Validation loss: 1.791809949823605

Epoch: 5| Step: 2
Training loss: 0.450648695230484
Validation loss: 1.808642815518123

Epoch: 5| Step: 3
Training loss: 0.6351016163825989
Validation loss: 1.8307111135093115

Epoch: 5| Step: 4
Training loss: 0.5080274343490601
Validation loss: 1.8334022363026936

Epoch: 5| Step: 5
Training loss: 0.5634440779685974
Validation loss: 1.8420543029744139

Epoch: 5| Step: 6
Training loss: 0.5220213532447815
Validation loss: 1.8686480163246073

Epoch: 5| Step: 7
Training loss: 0.5698919296264648
Validation loss: 1.857945385799613

Epoch: 5| Step: 8
Training loss: 0.36851710081100464
Validation loss: 1.8432783580595447

Epoch: 5| Step: 9
Training loss: 0.42558279633522034
Validation loss: 1.8912038610827537

Epoch: 5| Step: 10
Training loss: 0.5156915187835693
Validation loss: 1.9084427561811221

Epoch: 274| Step: 0
Training loss: 0.4173545241355896
Validation loss: 1.9141508994563934

Epoch: 5| Step: 1
Training loss: 0.4652700424194336
Validation loss: 1.8744423261252783

Epoch: 5| Step: 2
Training loss: 0.3647371530532837
Validation loss: 1.8418976517133816

Epoch: 5| Step: 3
Training loss: 0.3580649495124817
Validation loss: 1.8370445774447532

Epoch: 5| Step: 4
Training loss: 0.4443219304084778
Validation loss: 1.8269223320868708

Epoch: 5| Step: 5
Training loss: 0.45577186346054077
Validation loss: 1.8412432209137948

Epoch: 5| Step: 6
Training loss: 0.3131284713745117
Validation loss: 1.8310055758363457

Epoch: 5| Step: 7
Training loss: 0.6024453043937683
Validation loss: 1.8287366538919427

Epoch: 5| Step: 8
Training loss: 0.40912914276123047
Validation loss: 1.8903762268763717

Epoch: 5| Step: 9
Training loss: 0.5337108373641968
Validation loss: 1.8485754741135465

Epoch: 5| Step: 10
Training loss: 0.618906557559967
Validation loss: 1.8818256457646687

Epoch: 275| Step: 0
Training loss: 0.5048962831497192
Validation loss: 1.886511379672635

Epoch: 5| Step: 1
Training loss: 0.47418633103370667
Validation loss: 1.8525659691902898

Epoch: 5| Step: 2
Training loss: 0.3561207354068756
Validation loss: 1.8751068089597969

Epoch: 5| Step: 3
Training loss: 0.47949615120887756
Validation loss: 1.849730953093498

Epoch: 5| Step: 4
Training loss: 0.18320448696613312
Validation loss: 1.8394012861354376

Epoch: 5| Step: 5
Training loss: 0.6772368550300598
Validation loss: 1.8348835181164485

Epoch: 5| Step: 6
Training loss: 0.4270259737968445
Validation loss: 1.8354171194056028

Epoch: 5| Step: 7
Training loss: 0.6006777882575989
Validation loss: 1.8316045909799554

Epoch: 5| Step: 8
Training loss: 0.5088623762130737
Validation loss: 1.7951013413808679

Epoch: 5| Step: 9
Training loss: 0.3151184320449829
Validation loss: 1.8046781350207586

Epoch: 5| Step: 10
Training loss: 0.3040555417537689
Validation loss: 1.7940371010893135

Epoch: 276| Step: 0
Training loss: 0.4077473282814026
Validation loss: 1.8240894450936267

Epoch: 5| Step: 1
Training loss: 0.3320079743862152
Validation loss: 1.8197343528911631

Epoch: 5| Step: 2
Training loss: 0.3580678701400757
Validation loss: 1.7995198016525598

Epoch: 5| Step: 3
Training loss: 0.4715898931026459
Validation loss: 1.8340305923133768

Epoch: 5| Step: 4
Training loss: 0.5505700707435608
Validation loss: 1.8271838593226608

Epoch: 5| Step: 5
Training loss: 0.48947834968566895
Validation loss: 1.84715268047907

Epoch: 5| Step: 6
Training loss: 0.3935239315032959
Validation loss: 1.787258199466172

Epoch: 5| Step: 7
Training loss: 0.42665427923202515
Validation loss: 1.7920996732609247

Epoch: 5| Step: 8
Training loss: 0.5888079404830933
Validation loss: 1.7908288753160866

Epoch: 5| Step: 9
Training loss: 0.313848078250885
Validation loss: 1.7539260515602686

Epoch: 5| Step: 10
Training loss: 0.448606938123703
Validation loss: 1.7543336832395164

Epoch: 277| Step: 0
Training loss: 0.6091755032539368
Validation loss: 1.7523361239382016

Epoch: 5| Step: 1
Training loss: 0.4341273307800293
Validation loss: 1.7850028776353406

Epoch: 5| Step: 2
Training loss: 0.45709162950515747
Validation loss: 1.7755558772753643

Epoch: 5| Step: 3
Training loss: 0.2677287459373474
Validation loss: 1.8127756195683633

Epoch: 5| Step: 4
Training loss: 0.4061998724937439
Validation loss: 1.7774896916522775

Epoch: 5| Step: 5
Training loss: 0.35914137959480286
Validation loss: 1.8077160402010846

Epoch: 5| Step: 6
Training loss: 0.6158019304275513
Validation loss: 1.8083160026099092

Epoch: 5| Step: 7
Training loss: 0.30750972032546997
Validation loss: 1.844524937291299

Epoch: 5| Step: 8
Training loss: 0.3564775288105011
Validation loss: 1.8461610283902896

Epoch: 5| Step: 9
Training loss: 0.43671971559524536
Validation loss: 1.8753653290451213

Epoch: 5| Step: 10
Training loss: 0.36961206793785095
Validation loss: 1.8504090552688928

Epoch: 278| Step: 0
Training loss: 0.5917149782180786
Validation loss: 1.8085283810092556

Epoch: 5| Step: 1
Training loss: 0.2537497878074646
Validation loss: 1.795553171506492

Epoch: 5| Step: 2
Training loss: 0.42068639397621155
Validation loss: 1.8074324310466807

Epoch: 5| Step: 3
Training loss: 0.48027342557907104
Validation loss: 1.7608102521588724

Epoch: 5| Step: 4
Training loss: 0.5935739278793335
Validation loss: 1.736298240641112

Epoch: 5| Step: 5
Training loss: 0.32002803683280945
Validation loss: 1.7246699833100843

Epoch: 5| Step: 6
Training loss: 0.4053477346897125
Validation loss: 1.7014107101707048

Epoch: 5| Step: 7
Training loss: 0.46061593294143677
Validation loss: 1.7730930159168858

Epoch: 5| Step: 8
Training loss: 0.4212399423122406
Validation loss: 1.7553063079875002

Epoch: 5| Step: 9
Training loss: 0.3850521445274353
Validation loss: 1.8017058244315527

Epoch: 5| Step: 10
Training loss: 0.34004560112953186
Validation loss: 1.8191697071957331

Epoch: 279| Step: 0
Training loss: 0.4138658046722412
Validation loss: 1.8667192574470275

Epoch: 5| Step: 1
Training loss: 0.4527105689048767
Validation loss: 1.8840980145239061

Epoch: 5| Step: 2
Training loss: 0.48895978927612305
Validation loss: 1.8755648187411729

Epoch: 5| Step: 3
Training loss: 0.6625785231590271
Validation loss: 1.875604578243789

Epoch: 5| Step: 4
Training loss: 0.5822353959083557
Validation loss: 1.8590090402992823

Epoch: 5| Step: 5
Training loss: 0.3297231197357178
Validation loss: 1.8040088056236185

Epoch: 5| Step: 6
Training loss: 0.23545801639556885
Validation loss: 1.8309635603299705

Epoch: 5| Step: 7
Training loss: 0.7497493028640747
Validation loss: 1.8288046698416434

Epoch: 5| Step: 8
Training loss: 0.4533917009830475
Validation loss: 1.8208411624354701

Epoch: 5| Step: 9
Training loss: 0.2473682463169098
Validation loss: 1.8249725808379471

Epoch: 5| Step: 10
Training loss: 0.3266197741031647
Validation loss: 1.7929144674731838

Epoch: 280| Step: 0
Training loss: 0.45693907141685486
Validation loss: 1.7740310956073064

Epoch: 5| Step: 1
Training loss: 0.31969720125198364
Validation loss: 1.7490200740034862

Epoch: 5| Step: 2
Training loss: 0.30377620458602905
Validation loss: 1.781636759799014

Epoch: 5| Step: 3
Training loss: 0.39534908533096313
Validation loss: 1.7402814357511458

Epoch: 5| Step: 4
Training loss: 0.46266525983810425
Validation loss: 1.7508766740880988

Epoch: 5| Step: 5
Training loss: 0.4755658507347107
Validation loss: 1.7603398625568678

Epoch: 5| Step: 6
Training loss: 0.44440069794654846
Validation loss: 1.76166166797761

Epoch: 5| Step: 7
Training loss: 0.6013169288635254
Validation loss: 1.749714595015331

Epoch: 5| Step: 8
Training loss: 0.31929415464401245
Validation loss: 1.770368956750439

Epoch: 5| Step: 9
Training loss: 0.6390803456306458
Validation loss: 1.7641562479798512

Epoch: 5| Step: 10
Training loss: 0.23605775833129883
Validation loss: 1.7876173411646197

Epoch: 281| Step: 0
Training loss: 0.5979598164558411
Validation loss: 1.7509192394953903

Epoch: 5| Step: 1
Training loss: 0.4856107831001282
Validation loss: 1.7858320974534558

Epoch: 5| Step: 2
Training loss: 0.28850799798965454
Validation loss: 1.7589293282519105

Epoch: 5| Step: 3
Training loss: 0.532712459564209
Validation loss: 1.7712363184139293

Epoch: 5| Step: 4
Training loss: 0.3253381848335266
Validation loss: 1.7973612944285076

Epoch: 5| Step: 5
Training loss: 0.39030322432518005
Validation loss: 1.828870383642053

Epoch: 5| Step: 6
Training loss: 0.332214891910553
Validation loss: 1.8364336144539617

Epoch: 5| Step: 7
Training loss: 0.2470666617155075
Validation loss: 1.798896440895655

Epoch: 5| Step: 8
Training loss: 0.38573694229125977
Validation loss: 1.7902620018169444

Epoch: 5| Step: 9
Training loss: 0.4520650804042816
Validation loss: 1.7599359161110335

Epoch: 5| Step: 10
Training loss: 0.5744460225105286
Validation loss: 1.7592960942176081

Epoch: 282| Step: 0
Training loss: 0.4281954765319824
Validation loss: 1.7587693275943879

Epoch: 5| Step: 1
Training loss: 0.33130139112472534
Validation loss: 1.7407838426610476

Epoch: 5| Step: 2
Training loss: 0.5683392286300659
Validation loss: 1.7592575960261847

Epoch: 5| Step: 3
Training loss: 0.30775323510169983
Validation loss: 1.7812250416765931

Epoch: 5| Step: 4
Training loss: 0.4860818386077881
Validation loss: 1.8024850532572756

Epoch: 5| Step: 5
Training loss: 0.5111621618270874
Validation loss: 1.8183533222444597

Epoch: 5| Step: 6
Training loss: 0.15790890157222748
Validation loss: 1.8391307861574235

Epoch: 5| Step: 7
Training loss: 0.5077556371688843
Validation loss: 1.866387560803403

Epoch: 5| Step: 8
Training loss: 0.2419506013393402
Validation loss: 1.8824163995763308

Epoch: 5| Step: 9
Training loss: 0.5307872891426086
Validation loss: 1.8840429218866492

Epoch: 5| Step: 10
Training loss: 0.5830138921737671
Validation loss: 1.8495044990252423

Epoch: 283| Step: 0
Training loss: 0.29346659779548645
Validation loss: 1.8166144291559856

Epoch: 5| Step: 1
Training loss: 0.37580424547195435
Validation loss: 1.7950787685250724

Epoch: 5| Step: 2
Training loss: 0.5730603337287903
Validation loss: 1.7749706699002175

Epoch: 5| Step: 3
Training loss: 0.45923298597335815
Validation loss: 1.7450865096943353

Epoch: 5| Step: 4
Training loss: 0.3031267523765564
Validation loss: 1.7267531630813435

Epoch: 5| Step: 5
Training loss: 0.4907386302947998
Validation loss: 1.7093149321053618

Epoch: 5| Step: 6
Training loss: 0.5071429014205933
Validation loss: 1.7390430396603

Epoch: 5| Step: 7
Training loss: 0.2583027780056
Validation loss: 1.7554097701144475

Epoch: 5| Step: 8
Training loss: 0.650384783744812
Validation loss: 1.773527859359659

Epoch: 5| Step: 9
Training loss: 0.2544768452644348
Validation loss: 1.7341541654320174

Epoch: 5| Step: 10
Training loss: 0.2672681510448456
Validation loss: 1.760062712495045

Epoch: 284| Step: 0
Training loss: 0.5612636804580688
Validation loss: 1.7642635414677281

Epoch: 5| Step: 1
Training loss: 0.419625848531723
Validation loss: 1.7803696547785113

Epoch: 5| Step: 2
Training loss: 0.1616450846195221
Validation loss: 1.7651666364362162

Epoch: 5| Step: 3
Training loss: 0.3369547426700592
Validation loss: 1.7542280202270837

Epoch: 5| Step: 4
Training loss: 0.40831026434898376
Validation loss: 1.7659506874699746

Epoch: 5| Step: 5
Training loss: 0.33255118131637573
Validation loss: 1.7752438373463129

Epoch: 5| Step: 6
Training loss: 0.5910319089889526
Validation loss: 1.8497552435885194

Epoch: 5| Step: 7
Training loss: 0.3529384136199951
Validation loss: 1.839279282477594

Epoch: 5| Step: 8
Training loss: 0.7053597569465637
Validation loss: 1.8960919393006193

Epoch: 5| Step: 9
Training loss: 0.28830236196517944
Validation loss: 1.9123516121218282

Epoch: 5| Step: 10
Training loss: 0.39198243618011475
Validation loss: 1.9249535965663132

Epoch: 285| Step: 0
Training loss: 0.34085577726364136
Validation loss: 1.9149928913321546

Epoch: 5| Step: 1
Training loss: 0.7344754338264465
Validation loss: 1.860090471083118

Epoch: 5| Step: 2
Training loss: 0.31323638558387756
Validation loss: 1.8358209133148193

Epoch: 5| Step: 3
Training loss: 0.3188646137714386
Validation loss: 1.8370089505308418

Epoch: 5| Step: 4
Training loss: 0.28202390670776367
Validation loss: 1.8174359542067333

Epoch: 5| Step: 5
Training loss: 0.4272550940513611
Validation loss: 1.7596620475092242

Epoch: 5| Step: 6
Training loss: 0.3069583475589752
Validation loss: 1.7611836284719489

Epoch: 5| Step: 7
Training loss: 0.28624463081359863
Validation loss: 1.7570259519802627

Epoch: 5| Step: 8
Training loss: 0.42388415336608887
Validation loss: 1.7372643434873192

Epoch: 5| Step: 9
Training loss: 0.6847894787788391
Validation loss: 1.7544195164916336

Epoch: 5| Step: 10
Training loss: 0.3148452639579773
Validation loss: 1.7299623822653165

Epoch: 286| Step: 0
Training loss: 0.31120234727859497
Validation loss: 1.708523904123614

Epoch: 5| Step: 1
Training loss: 0.5084365606307983
Validation loss: 1.7127698595805834

Epoch: 5| Step: 2
Training loss: 0.4914481043815613
Validation loss: 1.709836870111445

Epoch: 5| Step: 3
Training loss: 0.23450979590415955
Validation loss: 1.721341283090653

Epoch: 5| Step: 4
Training loss: 0.3227812349796295
Validation loss: 1.7126834879639328

Epoch: 5| Step: 5
Training loss: 0.6478019952774048
Validation loss: 1.70768851746795

Epoch: 5| Step: 6
Training loss: 0.20183470845222473
Validation loss: 1.7413714637038529

Epoch: 5| Step: 7
Training loss: 0.28603047132492065
Validation loss: 1.748114437185308

Epoch: 5| Step: 8
Training loss: 0.558238685131073
Validation loss: 1.7390148588406142

Epoch: 5| Step: 9
Training loss: 0.44860154390335083
Validation loss: 1.774614534070415

Epoch: 5| Step: 10
Training loss: 0.32493191957473755
Validation loss: 1.7677173268410467

Epoch: 287| Step: 0
Training loss: 0.25394028425216675
Validation loss: 1.7669309198215444

Epoch: 5| Step: 1
Training loss: 0.4500046372413635
Validation loss: 1.7166266723345684

Epoch: 5| Step: 2
Training loss: 0.4004685878753662
Validation loss: 1.7420960177657425

Epoch: 5| Step: 3
Training loss: 0.549094557762146
Validation loss: 1.7330654923633864

Epoch: 5| Step: 4
Training loss: 0.2718806266784668
Validation loss: 1.7438479661941528

Epoch: 5| Step: 5
Training loss: 0.30333197116851807
Validation loss: 1.7560202537044403

Epoch: 5| Step: 6
Training loss: 0.3230789303779602
Validation loss: 1.775378470779747

Epoch: 5| Step: 7
Training loss: 0.3312840759754181
Validation loss: 1.7650459709987845

Epoch: 5| Step: 8
Training loss: 0.48613739013671875
Validation loss: 1.7485770281924997

Epoch: 5| Step: 9
Training loss: 0.3574589490890503
Validation loss: 1.7910020735956007

Epoch: 5| Step: 10
Training loss: 0.4351412057876587
Validation loss: 1.827943758297992

Epoch: 288| Step: 0
Training loss: 0.4688551425933838
Validation loss: 1.800365714616673

Epoch: 5| Step: 1
Training loss: 0.2951815724372864
Validation loss: 1.7610805521729171

Epoch: 5| Step: 2
Training loss: 0.2786627411842346
Validation loss: 1.7585873206456502

Epoch: 5| Step: 3
Training loss: 0.22009043395519257
Validation loss: 1.7615067138466785

Epoch: 5| Step: 4
Training loss: 0.40406355261802673
Validation loss: 1.7548467292580554

Epoch: 5| Step: 5
Training loss: 0.45227423310279846
Validation loss: 1.7293002041437293

Epoch: 5| Step: 6
Training loss: 0.3980817198753357
Validation loss: 1.7353372279033865

Epoch: 5| Step: 7
Training loss: 0.8181988000869751
Validation loss: 1.7457133903298327

Epoch: 5| Step: 8
Training loss: 0.3577870726585388
Validation loss: 1.758888021592171

Epoch: 5| Step: 9
Training loss: 0.33280158042907715
Validation loss: 1.7710519644521898

Epoch: 5| Step: 10
Training loss: 0.46478915214538574
Validation loss: 1.7840926916368547

Epoch: 289| Step: 0
Training loss: 0.30499857664108276
Validation loss: 1.8146606030002717

Epoch: 5| Step: 1
Training loss: 0.3322054445743561
Validation loss: 1.88194489735429

Epoch: 5| Step: 2
Training loss: 0.389021098613739
Validation loss: 1.8663860879918581

Epoch: 5| Step: 3
Training loss: 0.4269079267978668
Validation loss: 1.8640374470782537

Epoch: 5| Step: 4
Training loss: 0.35758328437805176
Validation loss: 1.8625475386137604

Epoch: 5| Step: 5
Training loss: 0.44363799691200256
Validation loss: 1.8580720296470068

Epoch: 5| Step: 6
Training loss: 0.4474964141845703
Validation loss: 1.7903819417440763

Epoch: 5| Step: 7
Training loss: 0.3922802209854126
Validation loss: 1.733811536142903

Epoch: 5| Step: 8
Training loss: 0.2908985912799835
Validation loss: 1.709274277892164

Epoch: 5| Step: 9
Training loss: 0.5741168260574341
Validation loss: 1.6910011204340125

Epoch: 5| Step: 10
Training loss: 0.464161217212677
Validation loss: 1.7091711131475305

Epoch: 290| Step: 0
Training loss: 0.330117791891098
Validation loss: 1.6885056700757755

Epoch: 5| Step: 1
Training loss: 0.33520206809043884
Validation loss: 1.7124238514131116

Epoch: 5| Step: 2
Training loss: 0.33014029264450073
Validation loss: 1.7123040896590038

Epoch: 5| Step: 3
Training loss: 0.5340460538864136
Validation loss: 1.7121763960007699

Epoch: 5| Step: 4
Training loss: 0.5844123363494873
Validation loss: 1.7724749144687448

Epoch: 5| Step: 5
Training loss: 0.3976246118545532
Validation loss: 1.8026884653234994

Epoch: 5| Step: 6
Training loss: 0.3529891073703766
Validation loss: 1.790789806714622

Epoch: 5| Step: 7
Training loss: 0.08649005740880966
Validation loss: 1.8479180707726428

Epoch: 5| Step: 8
Training loss: 0.4151883125305176
Validation loss: 1.8528012088550034

Epoch: 5| Step: 9
Training loss: 0.44347184896469116
Validation loss: 1.8168182911411408

Epoch: 5| Step: 10
Training loss: 0.5824338793754578
Validation loss: 1.7904952315873996

Epoch: 291| Step: 0
Training loss: 0.14645738899707794
Validation loss: 1.806115637543381

Epoch: 5| Step: 1
Training loss: 0.53536456823349
Validation loss: 1.750535249710083

Epoch: 5| Step: 2
Training loss: 0.43624797463417053
Validation loss: 1.722927205024227

Epoch: 5| Step: 3
Training loss: 0.4399283528327942
Validation loss: 1.6946325263669413

Epoch: 5| Step: 4
Training loss: 0.2755895256996155
Validation loss: 1.696704674792546

Epoch: 5| Step: 5
Training loss: 0.40735548734664917
Validation loss: 1.7032357774755007

Epoch: 5| Step: 6
Training loss: 0.4801348149776459
Validation loss: 1.727741790074174

Epoch: 5| Step: 7
Training loss: 0.47947368025779724
Validation loss: 1.7085217327199957

Epoch: 5| Step: 8
Training loss: 0.5022057890892029
Validation loss: 1.7001211104854461

Epoch: 5| Step: 9
Training loss: 0.466717392206192
Validation loss: 1.7109313626443186

Epoch: 5| Step: 10
Training loss: 0.33197712898254395
Validation loss: 1.750050619084348

Epoch: 292| Step: 0
Training loss: 0.4426729083061218
Validation loss: 1.7657889384095387

Epoch: 5| Step: 1
Training loss: 0.37608224153518677
Validation loss: 1.8107752005259197

Epoch: 5| Step: 2
Training loss: 0.3369655907154083
Validation loss: 1.8079968716508599

Epoch: 5| Step: 3
Training loss: 0.24433903396129608
Validation loss: 1.8099324562216317

Epoch: 5| Step: 4
Training loss: 0.3225780129432678
Validation loss: 1.7743757693998274

Epoch: 5| Step: 5
Training loss: 0.40790456533432007
Validation loss: 1.8234342272563646

Epoch: 5| Step: 6
Training loss: 0.49432510137557983
Validation loss: 1.7892404346055881

Epoch: 5| Step: 7
Training loss: 0.3806583881378174
Validation loss: 1.7885426205973471

Epoch: 5| Step: 8
Training loss: 0.342385858297348
Validation loss: 1.7652059780654086

Epoch: 5| Step: 9
Training loss: 0.48843079805374146
Validation loss: 1.7733192802757345

Epoch: 5| Step: 10
Training loss: 0.390756756067276
Validation loss: 1.7532393342705184

Epoch: 293| Step: 0
Training loss: 0.32847681641578674
Validation loss: 1.7758327632822015

Epoch: 5| Step: 1
Training loss: 0.4028606414794922
Validation loss: 1.7507998571600965

Epoch: 5| Step: 2
Training loss: 0.4329492151737213
Validation loss: 1.7688041604975218

Epoch: 5| Step: 3
Training loss: 0.26213693618774414
Validation loss: 1.7403305422875188

Epoch: 5| Step: 4
Training loss: 0.35427671670913696
Validation loss: 1.759397522095711

Epoch: 5| Step: 5
Training loss: 0.7322871685028076
Validation loss: 1.7843421095161027

Epoch: 5| Step: 6
Training loss: 0.5073670148849487
Validation loss: 1.7752127250035603

Epoch: 5| Step: 7
Training loss: 0.2729142904281616
Validation loss: 1.80794083943931

Epoch: 5| Step: 8
Training loss: 0.31106826663017273
Validation loss: 1.788825196604575

Epoch: 5| Step: 9
Training loss: 0.3590923547744751
Validation loss: 1.7685043529797626

Epoch: 5| Step: 10
Training loss: 0.12937451899051666
Validation loss: 1.7786422570546467

Epoch: 294| Step: 0
Training loss: 0.2996962070465088
Validation loss: 1.7391671121761363

Epoch: 5| Step: 1
Training loss: 0.47636914253234863
Validation loss: 1.7294228858845209

Epoch: 5| Step: 2
Training loss: 0.3593580424785614
Validation loss: 1.7228851523450626

Epoch: 5| Step: 3
Training loss: 0.3103511929512024
Validation loss: 1.735398861669725

Epoch: 5| Step: 4
Training loss: 0.39547115564346313
Validation loss: 1.740223712818597

Epoch: 5| Step: 5
Training loss: 0.4734954833984375
Validation loss: 1.7285178220400246

Epoch: 5| Step: 6
Training loss: 0.46503621339797974
Validation loss: 1.7119487690669235

Epoch: 5| Step: 7
Training loss: 0.4715442657470703
Validation loss: 1.7579426855169318

Epoch: 5| Step: 8
Training loss: 0.40325871109962463
Validation loss: 1.7614866597678072

Epoch: 5| Step: 9
Training loss: 0.19220198690891266
Validation loss: 1.753486519218773

Epoch: 5| Step: 10
Training loss: 0.22454214096069336
Validation loss: 1.7402647887506792

Epoch: 295| Step: 0
Training loss: 0.37938278913497925
Validation loss: 1.7283829873608005

Epoch: 5| Step: 1
Training loss: 0.2655632793903351
Validation loss: 1.7475945052280222

Epoch: 5| Step: 2
Training loss: 0.3451443314552307
Validation loss: 1.7617627959097586

Epoch: 5| Step: 3
Training loss: 0.32702794671058655
Validation loss: 1.7488811169901202

Epoch: 5| Step: 4
Training loss: 0.35698240995407104
Validation loss: 1.7732088104371102

Epoch: 5| Step: 5
Training loss: 0.4491656422615051
Validation loss: 1.7478773709266417

Epoch: 5| Step: 6
Training loss: 0.377663791179657
Validation loss: 1.7568164576766312

Epoch: 5| Step: 7
Training loss: 0.3944706916809082
Validation loss: 1.7424641219518517

Epoch: 5| Step: 8
Training loss: 0.42867690324783325
Validation loss: 1.7245236301934848

Epoch: 5| Step: 9
Training loss: 0.31950145959854126
Validation loss: 1.7293004835805585

Epoch: 5| Step: 10
Training loss: 0.25845763087272644
Validation loss: 1.733021290071549

Epoch: 296| Step: 0
Training loss: 0.5058533549308777
Validation loss: 1.7195736541542956

Epoch: 5| Step: 1
Training loss: 0.424802303314209
Validation loss: 1.7110908762101205

Epoch: 5| Step: 2
Training loss: 0.41659241914749146
Validation loss: 1.7113347579074163

Epoch: 5| Step: 3
Training loss: 0.4364601969718933
Validation loss: 1.7140723402782152

Epoch: 5| Step: 4
Training loss: 0.42044681310653687
Validation loss: 1.727368911107381

Epoch: 5| Step: 5
Training loss: 0.3221363425254822
Validation loss: 1.7474597064397668

Epoch: 5| Step: 6
Training loss: 0.4363822937011719
Validation loss: 1.7434200522720174

Epoch: 5| Step: 7
Training loss: 0.23108577728271484
Validation loss: 1.7790099984856063

Epoch: 5| Step: 8
Training loss: 0.5714449882507324
Validation loss: 1.801024692032927

Epoch: 5| Step: 9
Training loss: 0.17729543149471283
Validation loss: 1.7624759545890234

Epoch: 5| Step: 10
Training loss: 0.27699029445648193
Validation loss: 1.7893516312363327

Epoch: 297| Step: 0
Training loss: 0.4400516152381897
Validation loss: 1.7729051036219443

Epoch: 5| Step: 1
Training loss: 0.38619834184646606
Validation loss: 1.746744389175087

Epoch: 5| Step: 2
Training loss: 0.3242850601673126
Validation loss: 1.6991751911819621

Epoch: 5| Step: 3
Training loss: 0.2144385278224945
Validation loss: 1.693318272149691

Epoch: 5| Step: 4
Training loss: 0.5142732262611389
Validation loss: 1.7098932548235821

Epoch: 5| Step: 5
Training loss: 0.311273992061615
Validation loss: 1.7203503552303518

Epoch: 5| Step: 6
Training loss: 0.34970396757125854
Validation loss: 1.721974520273106

Epoch: 5| Step: 7
Training loss: 0.3658679723739624
Validation loss: 1.7333633066505514

Epoch: 5| Step: 8
Training loss: 0.39619266986846924
Validation loss: 1.713300633174117

Epoch: 5| Step: 9
Training loss: 0.4600829482078552
Validation loss: 1.6825435956319172

Epoch: 5| Step: 10
Training loss: 0.29844939708709717
Validation loss: 1.6668004489714099

Epoch: 298| Step: 0
Training loss: 0.4176965653896332
Validation loss: 1.69856297585272

Epoch: 5| Step: 1
Training loss: 0.5565773844718933
Validation loss: 1.735418705530064

Epoch: 5| Step: 2
Training loss: 0.23339013755321503
Validation loss: 1.7585076016764487

Epoch: 5| Step: 3
Training loss: 0.2441360503435135
Validation loss: 1.755971872678367

Epoch: 5| Step: 4
Training loss: 0.39771127700805664
Validation loss: 1.7203450843852053

Epoch: 5| Step: 5
Training loss: 0.2950514853000641
Validation loss: 1.723168525644528

Epoch: 5| Step: 6
Training loss: 0.25111550092697144
Validation loss: 1.6778186803222985

Epoch: 5| Step: 7
Training loss: 0.28187546133995056
Validation loss: 1.7019809728027673

Epoch: 5| Step: 8
Training loss: 0.5751551389694214
Validation loss: 1.7073448499043782

Epoch: 5| Step: 9
Training loss: 0.4392150938510895
Validation loss: 1.7209561999126146

Epoch: 5| Step: 10
Training loss: 0.2841276228427887
Validation loss: 1.7291634185339815

Epoch: 299| Step: 0
Training loss: 0.2541526257991791
Validation loss: 1.731949947213614

Epoch: 5| Step: 1
Training loss: 0.3513566851615906
Validation loss: 1.7192530952474123

Epoch: 5| Step: 2
Training loss: 0.2606753706932068
Validation loss: 1.718201583431613

Epoch: 5| Step: 3
Training loss: 0.3148960769176483
Validation loss: 1.7044370828136322

Epoch: 5| Step: 4
Training loss: 0.3216845691204071
Validation loss: 1.7109238127226472

Epoch: 5| Step: 5
Training loss: 0.3445635437965393
Validation loss: 1.760176134365861

Epoch: 5| Step: 6
Training loss: 0.5077096223831177
Validation loss: 1.795012758624169

Epoch: 5| Step: 7
Training loss: 0.4194541573524475
Validation loss: 1.8037536163483896

Epoch: 5| Step: 8
Training loss: 0.3907386362552643
Validation loss: 1.8575003018943212

Epoch: 5| Step: 9
Training loss: 0.4532211720943451
Validation loss: 1.8391428070683633

Epoch: 5| Step: 10
Training loss: 0.3351537585258484
Validation loss: 1.8512193374736334

Epoch: 300| Step: 0
Training loss: 0.2355460226535797
Validation loss: 1.8232918490645706

Epoch: 5| Step: 1
Training loss: 0.29590800404548645
Validation loss: 1.798149852342503

Epoch: 5| Step: 2
Training loss: 0.35197824239730835
Validation loss: 1.7961670878112956

Epoch: 5| Step: 3
Training loss: 0.5152829885482788
Validation loss: 1.7589388380768478

Epoch: 5| Step: 4
Training loss: 0.26522088050842285
Validation loss: 1.7272347352838004

Epoch: 5| Step: 5
Training loss: 0.4630308747291565
Validation loss: 1.7131183788340578

Epoch: 5| Step: 6
Training loss: 0.28620415925979614
Validation loss: 1.6698603168610604

Epoch: 5| Step: 7
Training loss: 0.4766257405281067
Validation loss: 1.6874688440753567

Epoch: 5| Step: 8
Training loss: 0.3155582845211029
Validation loss: 1.677410009086773

Epoch: 5| Step: 9
Training loss: 0.3728415369987488
Validation loss: 1.6972800480422152

Epoch: 5| Step: 10
Training loss: 0.37825483083724976
Validation loss: 1.6951950782088823

Epoch: 301| Step: 0
Training loss: 0.2741581201553345
Validation loss: 1.697428943008505

Epoch: 5| Step: 1
Training loss: 0.2650526762008667
Validation loss: 1.7085299568791543

Epoch: 5| Step: 2
Training loss: 0.4375368654727936
Validation loss: 1.7267166876023816

Epoch: 5| Step: 3
Training loss: 0.23427709937095642
Validation loss: 1.7233475792792536

Epoch: 5| Step: 4
Training loss: 0.3938981890678406
Validation loss: 1.666633657229844

Epoch: 5| Step: 5
Training loss: 0.6221240758895874
Validation loss: 1.6842523236428537

Epoch: 5| Step: 6
Training loss: 0.31161612272262573
Validation loss: 1.674649961533085

Epoch: 5| Step: 7
Training loss: 0.3231346607208252
Validation loss: 1.6837529520834646

Epoch: 5| Step: 8
Training loss: 0.3275323510169983
Validation loss: 1.7020360333945161

Epoch: 5| Step: 9
Training loss: 0.41713768243789673
Validation loss: 1.698237193528042

Epoch: 5| Step: 10
Training loss: 0.395319402217865
Validation loss: 1.6820131271116194

Epoch: 302| Step: 0
Training loss: 0.4053928852081299
Validation loss: 1.6985589765733289

Epoch: 5| Step: 1
Training loss: 0.27185407280921936
Validation loss: 1.7060184799214846

Epoch: 5| Step: 2
Training loss: 0.20836535096168518
Validation loss: 1.6989860919214064

Epoch: 5| Step: 3
Training loss: 0.18240627646446228
Validation loss: 1.7187969210327312

Epoch: 5| Step: 4
Training loss: 0.36631250381469727
Validation loss: 1.721276230709527

Epoch: 5| Step: 5
Training loss: 0.3681359589099884
Validation loss: 1.7102476473777526

Epoch: 5| Step: 6
Training loss: 0.40035781264305115
Validation loss: 1.6747308495224162

Epoch: 5| Step: 7
Training loss: 0.35296759009361267
Validation loss: 1.669800227688205

Epoch: 5| Step: 8
Training loss: 0.3667791485786438
Validation loss: 1.6639832937589256

Epoch: 5| Step: 9
Training loss: 0.5625132918357849
Validation loss: 1.6529046258618754

Epoch: 5| Step: 10
Training loss: 0.40774357318878174
Validation loss: 1.6588002827859694

Epoch: 303| Step: 0
Training loss: 0.33508333563804626
Validation loss: 1.671014290983959

Epoch: 5| Step: 1
Training loss: 0.4406009614467621
Validation loss: 1.6705781887936335

Epoch: 5| Step: 2
Training loss: 0.32914358377456665
Validation loss: 1.6985937651767526

Epoch: 5| Step: 3
Training loss: 0.4607573449611664
Validation loss: 1.7192769383871427

Epoch: 5| Step: 4
Training loss: 0.2337295114994049
Validation loss: 1.7231759384114256

Epoch: 5| Step: 5
Training loss: 0.2954131066799164
Validation loss: 1.7318943854301208

Epoch: 5| Step: 6
Training loss: 0.4374992251396179
Validation loss: 1.7494664910019084

Epoch: 5| Step: 7
Training loss: 0.3963607847690582
Validation loss: 1.780265180013513

Epoch: 5| Step: 8
Training loss: 0.3348044753074646
Validation loss: 1.8104360295880226

Epoch: 5| Step: 9
Training loss: 0.249790221452713
Validation loss: 1.804844078197274

Epoch: 5| Step: 10
Training loss: 0.24201208353042603
Validation loss: 1.7986813232462893

Epoch: 304| Step: 0
Training loss: 0.39177384972572327
Validation loss: 1.7594552475919005

Epoch: 5| Step: 1
Training loss: 0.4225079119205475
Validation loss: 1.713209588681498

Epoch: 5| Step: 2
Training loss: 0.32473239302635193
Validation loss: 1.7008194782400643

Epoch: 5| Step: 3
Training loss: 0.2257061004638672
Validation loss: 1.6938114653351486

Epoch: 5| Step: 4
Training loss: 0.2710498571395874
Validation loss: 1.6754837074587423

Epoch: 5| Step: 5
Training loss: 0.3693665862083435
Validation loss: 1.6740456845170708

Epoch: 5| Step: 6
Training loss: 0.36118197441101074
Validation loss: 1.6570719211332259

Epoch: 5| Step: 7
Training loss: 0.20980533957481384
Validation loss: 1.669606944566132

Epoch: 5| Step: 8
Training loss: 0.21220318973064423
Validation loss: 1.6986599583779611

Epoch: 5| Step: 9
Training loss: 0.31799039244651794
Validation loss: 1.704327929404474

Epoch: 5| Step: 10
Training loss: 0.48341065645217896
Validation loss: 1.681998622032904

Epoch: 305| Step: 0
Training loss: 0.4119628965854645
Validation loss: 1.7035914172408402

Epoch: 5| Step: 1
Training loss: 0.23113706707954407
Validation loss: 1.723797405919721

Epoch: 5| Step: 2
Training loss: 0.3537868857383728
Validation loss: 1.7595965208545807

Epoch: 5| Step: 3
Training loss: 0.38999828696250916
Validation loss: 1.7199453012917632

Epoch: 5| Step: 4
Training loss: 0.34854692220687866
Validation loss: 1.7082052846108713

Epoch: 5| Step: 5
Training loss: 0.2656156122684479
Validation loss: 1.6804965593481576

Epoch: 5| Step: 6
Training loss: 0.24466893076896667
Validation loss: 1.6911157472159273

Epoch: 5| Step: 7
Training loss: 0.4199252724647522
Validation loss: 1.6777422966495636

Epoch: 5| Step: 8
Training loss: 0.27083778381347656
Validation loss: 1.675441913707282

Epoch: 5| Step: 9
Training loss: 0.2872543931007385
Validation loss: 1.6753089850948704

Epoch: 5| Step: 10
Training loss: 0.4857430160045624
Validation loss: 1.7061664699226298

Epoch: 306| Step: 0
Training loss: 0.16579630970954895
Validation loss: 1.7264752144454627

Epoch: 5| Step: 1
Training loss: 0.409615695476532
Validation loss: 1.6956695638677126

Epoch: 5| Step: 2
Training loss: 0.43378275632858276
Validation loss: 1.744964482963726

Epoch: 5| Step: 3
Training loss: 0.3347727656364441
Validation loss: 1.7429839718726374

Epoch: 5| Step: 4
Training loss: 0.23813414573669434
Validation loss: 1.764258510322981

Epoch: 5| Step: 5
Training loss: 0.46019554138183594
Validation loss: 1.7661486043724963

Epoch: 5| Step: 6
Training loss: 0.3176524043083191
Validation loss: 1.764114615737751

Epoch: 5| Step: 7
Training loss: 0.3501858115196228
Validation loss: 1.7403879614286526

Epoch: 5| Step: 8
Training loss: 0.37631672620773315
Validation loss: 1.7207788344352477

Epoch: 5| Step: 9
Training loss: 0.40141773223876953
Validation loss: 1.7243148665274344

Epoch: 5| Step: 10
Training loss: 0.19886024296283722
Validation loss: 1.7103744591436079

Epoch: 307| Step: 0
Training loss: 0.4995267391204834
Validation loss: 1.6797817560934252

Epoch: 5| Step: 1
Training loss: 0.40175992250442505
Validation loss: 1.7074705528956589

Epoch: 5| Step: 2
Training loss: 0.23012590408325195
Validation loss: 1.6721297438426683

Epoch: 5| Step: 3
Training loss: 0.444559246301651
Validation loss: 1.7010206983935448

Epoch: 5| Step: 4
Training loss: 0.3445858359336853
Validation loss: 1.7185644090816539

Epoch: 5| Step: 5
Training loss: 0.37304121255874634
Validation loss: 1.7203274696103987

Epoch: 5| Step: 6
Training loss: 0.12472822517156601
Validation loss: 1.7685931703095794

Epoch: 5| Step: 7
Training loss: 0.25236353278160095
Validation loss: 1.7300481334809334

Epoch: 5| Step: 8
Training loss: 0.3067302107810974
Validation loss: 1.7466434060886342

Epoch: 5| Step: 9
Training loss: 0.256374329328537
Validation loss: 1.7333919245709655

Epoch: 5| Step: 10
Training loss: 0.3320247232913971
Validation loss: 1.719210401658089

Epoch: 308| Step: 0
Training loss: 0.18206456303596497
Validation loss: 1.732427873919087

Epoch: 5| Step: 1
Training loss: 0.4825202524662018
Validation loss: 1.7017048033334876

Epoch: 5| Step: 2
Training loss: 0.2829521596431732
Validation loss: 1.6758745690827728

Epoch: 5| Step: 3
Training loss: 0.27859732508659363
Validation loss: 1.6756306771309144

Epoch: 5| Step: 4
Training loss: 0.35679343342781067
Validation loss: 1.6956852610393236

Epoch: 5| Step: 5
Training loss: 0.3480145335197449
Validation loss: 1.683563619531611

Epoch: 5| Step: 6
Training loss: 0.24619737267494202
Validation loss: 1.6999715822999195

Epoch: 5| Step: 7
Training loss: 0.24815817177295685
Validation loss: 1.7107443732600058

Epoch: 5| Step: 8
Training loss: 0.20318667590618134
Validation loss: 1.744758209874553

Epoch: 5| Step: 9
Training loss: 0.3946063220500946
Validation loss: 1.7809309254410446

Epoch: 5| Step: 10
Training loss: 0.4589846730232239
Validation loss: 1.7759103646842382

Epoch: 309| Step: 0
Training loss: 0.2819216251373291
Validation loss: 1.7499425565042803

Epoch: 5| Step: 1
Training loss: 0.5456553101539612
Validation loss: 1.7366874922988236

Epoch: 5| Step: 2
Training loss: 0.3447117805480957
Validation loss: 1.7251784865574171

Epoch: 5| Step: 3
Training loss: 0.5058116912841797
Validation loss: 1.7138679732558548

Epoch: 5| Step: 4
Training loss: 0.23951730132102966
Validation loss: 1.6894615734777143

Epoch: 5| Step: 5
Training loss: 0.21429911255836487
Validation loss: 1.6673892262161418

Epoch: 5| Step: 6
Training loss: 0.26681530475616455
Validation loss: 1.646617870176992

Epoch: 5| Step: 7
Training loss: 0.4276513159275055
Validation loss: 1.641289136743033

Epoch: 5| Step: 8
Training loss: 0.15445007383823395
Validation loss: 1.6631569375274002

Epoch: 5| Step: 9
Training loss: 0.26393455266952515
Validation loss: 1.6763646628267022

Epoch: 5| Step: 10
Training loss: 0.2544783353805542
Validation loss: 1.6839868304550007

Epoch: 310| Step: 0
Training loss: 0.2496369332075119
Validation loss: 1.6946823161135438

Epoch: 5| Step: 1
Training loss: 0.18974094092845917
Validation loss: 1.6887335290190995

Epoch: 5| Step: 2
Training loss: 0.32833653688430786
Validation loss: 1.7036635362973778

Epoch: 5| Step: 3
Training loss: 0.433637797832489
Validation loss: 1.6966098636709235

Epoch: 5| Step: 4
Training loss: 0.23185256123542786
Validation loss: 1.694548850418419

Epoch: 5| Step: 5
Training loss: 0.1934542953968048
Validation loss: 1.68249677073571

Epoch: 5| Step: 6
Training loss: 0.36789843440055847
Validation loss: 1.6503368077739593

Epoch: 5| Step: 7
Training loss: 0.2609351575374603
Validation loss: 1.6751810786544636

Epoch: 5| Step: 8
Training loss: 0.34325987100601196
Validation loss: 1.6652595586674188

Epoch: 5| Step: 9
Training loss: 0.34405964612960815
Validation loss: 1.6470706475678312

Epoch: 5| Step: 10
Training loss: 0.37012240290641785
Validation loss: 1.6584748760346444

Epoch: 311| Step: 0
Training loss: 0.23722872138023376
Validation loss: 1.6538722976561515

Epoch: 5| Step: 1
Training loss: 0.3441748023033142
Validation loss: 1.654195798340664

Epoch: 5| Step: 2
Training loss: 0.24260330200195312
Validation loss: 1.663426044166729

Epoch: 5| Step: 3
Training loss: 0.2632235884666443
Validation loss: 1.6607846034470426

Epoch: 5| Step: 4
Training loss: 0.3443092405796051
Validation loss: 1.6920263331423524

Epoch: 5| Step: 5
Training loss: 0.35368332266807556
Validation loss: 1.7119956401086622

Epoch: 5| Step: 6
Training loss: 0.49880608916282654
Validation loss: 1.736129887642399

Epoch: 5| Step: 7
Training loss: 0.17671841382980347
Validation loss: 1.7162547406329904

Epoch: 5| Step: 8
Training loss: 0.25957173109054565
Validation loss: 1.7080497152061873

Epoch: 5| Step: 9
Training loss: 0.20166389644145966
Validation loss: 1.712213703381118

Epoch: 5| Step: 10
Training loss: 0.4334156811237335
Validation loss: 1.6977391166071738

Epoch: 312| Step: 0
Training loss: 0.20220132172107697
Validation loss: 1.7043619091792772

Epoch: 5| Step: 1
Training loss: 0.26929062604904175
Validation loss: 1.6814548148903796

Epoch: 5| Step: 2
Training loss: 0.2725427746772766
Validation loss: 1.7120710021706038

Epoch: 5| Step: 3
Training loss: 0.22961997985839844
Validation loss: 1.712994667791551

Epoch: 5| Step: 4
Training loss: 0.43712204694747925
Validation loss: 1.7396519748113488

Epoch: 5| Step: 5
Training loss: 0.37904053926467896
Validation loss: 1.7267169221754997

Epoch: 5| Step: 6
Training loss: 0.1685413420200348
Validation loss: 1.7414198575481292

Epoch: 5| Step: 7
Training loss: 0.2568055987358093
Validation loss: 1.722523029132556

Epoch: 5| Step: 8
Training loss: 0.5182967782020569
Validation loss: 1.720949544701525

Epoch: 5| Step: 9
Training loss: 0.20958001911640167
Validation loss: 1.7247403180727394

Epoch: 5| Step: 10
Training loss: 0.36994242668151855
Validation loss: 1.711164197614116

Epoch: 313| Step: 0
Training loss: 0.36085572838783264
Validation loss: 1.6874368485584055

Epoch: 5| Step: 1
Training loss: 0.1940363645553589
Validation loss: 1.684482382189843

Epoch: 5| Step: 2
Training loss: 0.178371399641037
Validation loss: 1.6455179427259712

Epoch: 5| Step: 3
Training loss: 0.2617659568786621
Validation loss: 1.6642933532755861

Epoch: 5| Step: 4
Training loss: 0.3325156569480896
Validation loss: 1.6586882773266043

Epoch: 5| Step: 5
Training loss: 0.40955883264541626
Validation loss: 1.659837422832366

Epoch: 5| Step: 6
Training loss: 0.3946097791194916
Validation loss: 1.6514498379922682

Epoch: 5| Step: 7
Training loss: 0.31236153841018677
Validation loss: 1.6553507492106447

Epoch: 5| Step: 8
Training loss: 0.5383811593055725
Validation loss: 1.6729751633059593

Epoch: 5| Step: 9
Training loss: 0.23483267426490784
Validation loss: 1.7055437680213683

Epoch: 5| Step: 10
Training loss: 0.33459463715553284
Validation loss: 1.715686116167294

Epoch: 314| Step: 0
Training loss: 0.3054935336112976
Validation loss: 1.681545510086962

Epoch: 5| Step: 1
Training loss: 0.21522048115730286
Validation loss: 1.7003832324858634

Epoch: 5| Step: 2
Training loss: 0.36726534366607666
Validation loss: 1.6998218477413218

Epoch: 5| Step: 3
Training loss: 0.22129854559898376
Validation loss: 1.7479888700669812

Epoch: 5| Step: 4
Training loss: 0.11506111919879913
Validation loss: 1.7104563546437088

Epoch: 5| Step: 5
Training loss: 0.3415072560310364
Validation loss: 1.7095773322607881

Epoch: 5| Step: 6
Training loss: 0.23391711711883545
Validation loss: 1.69043565821904

Epoch: 5| Step: 7
Training loss: 0.33365803956985474
Validation loss: 1.6744191826030772

Epoch: 5| Step: 8
Training loss: 0.28332382440567017
Validation loss: 1.6569922842005247

Epoch: 5| Step: 9
Training loss: 0.5976054668426514
Validation loss: 1.6623701382708806

Epoch: 5| Step: 10
Training loss: 0.22486697137355804
Validation loss: 1.6654826133481917

Epoch: 315| Step: 0
Training loss: 0.21950188279151917
Validation loss: 1.6679205971379434

Epoch: 5| Step: 1
Training loss: 0.3029569089412689
Validation loss: 1.6327912653646162

Epoch: 5| Step: 2
Training loss: 0.19785568118095398
Validation loss: 1.639021275504943

Epoch: 5| Step: 3
Training loss: 0.30359652638435364
Validation loss: 1.673559610561658

Epoch: 5| Step: 4
Training loss: 0.38165995478630066
Validation loss: 1.6829109166258125

Epoch: 5| Step: 5
Training loss: 0.3464387357234955
Validation loss: 1.702334633437536

Epoch: 5| Step: 6
Training loss: 0.2606051564216614
Validation loss: 1.7111010628361856

Epoch: 5| Step: 7
Training loss: 0.1984787881374359
Validation loss: 1.7394942622030936

Epoch: 5| Step: 8
Training loss: 0.2821245491504669
Validation loss: 1.7278790089391893

Epoch: 5| Step: 9
Training loss: 0.36968040466308594
Validation loss: 1.7276041174447665

Epoch: 5| Step: 10
Training loss: 0.46586474776268005
Validation loss: 1.7386847792133209

Epoch: 316| Step: 0
Training loss: 0.2545684278011322
Validation loss: 1.7683495052399174

Epoch: 5| Step: 1
Training loss: 0.44265633821487427
Validation loss: 1.7442770670819026

Epoch: 5| Step: 2
Training loss: 0.2819017767906189
Validation loss: 1.7095578370555755

Epoch: 5| Step: 3
Training loss: 0.30220329761505127
Validation loss: 1.7007198731104534

Epoch: 5| Step: 4
Training loss: 0.2428903579711914
Validation loss: 1.6762410863753288

Epoch: 5| Step: 5
Training loss: 0.36276787519454956
Validation loss: 1.6264990619433823

Epoch: 5| Step: 6
Training loss: 0.42454808950424194
Validation loss: 1.635472600178052

Epoch: 5| Step: 7
Training loss: 0.40216392278671265
Validation loss: 1.6488074756437732

Epoch: 5| Step: 8
Training loss: 0.16141928732395172
Validation loss: 1.661345108221936

Epoch: 5| Step: 9
Training loss: 0.27226823568344116
Validation loss: 1.6517806988890453

Epoch: 5| Step: 10
Training loss: 0.3537682890892029
Validation loss: 1.652449800763079

Epoch: 317| Step: 0
Training loss: 0.3113071024417877
Validation loss: 1.6879306172811857

Epoch: 5| Step: 1
Training loss: 0.34145310521125793
Validation loss: 1.7000325918197632

Epoch: 5| Step: 2
Training loss: 0.23085081577301025
Validation loss: 1.7154599005176174

Epoch: 5| Step: 3
Training loss: 0.37017685174942017
Validation loss: 1.6940272770902163

Epoch: 5| Step: 4
Training loss: 0.30292388796806335
Validation loss: 1.71882507365237

Epoch: 5| Step: 5
Training loss: 0.2539006769657135
Validation loss: 1.6664665822059876

Epoch: 5| Step: 6
Training loss: 0.29825150966644287
Validation loss: 1.6860859983710832

Epoch: 5| Step: 7
Training loss: 0.4508543610572815
Validation loss: 1.6714108156901535

Epoch: 5| Step: 8
Training loss: 0.2807186245918274
Validation loss: 1.6831930004140383

Epoch: 5| Step: 9
Training loss: 0.2827582061290741
Validation loss: 1.6640564715990456

Epoch: 5| Step: 10
Training loss: 0.18642453849315643
Validation loss: 1.6944713592529297

Epoch: 318| Step: 0
Training loss: 0.16228346526622772
Validation loss: 1.7176319001823344

Epoch: 5| Step: 1
Training loss: 0.29780054092407227
Validation loss: 1.7416391846954182

Epoch: 5| Step: 2
Training loss: 0.263397216796875
Validation loss: 1.743622850346309

Epoch: 5| Step: 3
Training loss: 0.33735817670822144
Validation loss: 1.762364419557715

Epoch: 5| Step: 4
Training loss: 0.32980599999427795
Validation loss: 1.7275017538378317

Epoch: 5| Step: 5
Training loss: 0.25333112478256226
Validation loss: 1.7376638535530335

Epoch: 5| Step: 6
Training loss: 0.28407371044158936
Validation loss: 1.7120170926535

Epoch: 5| Step: 7
Training loss: 0.285034716129303
Validation loss: 1.679411111339446

Epoch: 5| Step: 8
Training loss: 0.16080032289028168
Validation loss: 1.6610641543583204

Epoch: 5| Step: 9
Training loss: 0.5196851491928101
Validation loss: 1.652199376013971

Epoch: 5| Step: 10
Training loss: 0.27700716257095337
Validation loss: 1.617292429811211

Epoch: 319| Step: 0
Training loss: 0.18009498715400696
Validation loss: 1.655364695415702

Epoch: 5| Step: 1
Training loss: 0.3240245282649994
Validation loss: 1.6951883287839993

Epoch: 5| Step: 2
Training loss: 0.38414883613586426
Validation loss: 1.7519146908995926

Epoch: 5| Step: 3
Training loss: 0.39260703325271606
Validation loss: 1.7669531478676745

Epoch: 5| Step: 4
Training loss: 0.34572985768318176
Validation loss: 1.729010151278588

Epoch: 5| Step: 5
Training loss: 0.18154028058052063
Validation loss: 1.7289858172016759

Epoch: 5| Step: 6
Training loss: 0.40637463331222534
Validation loss: 1.7118428035448956

Epoch: 5| Step: 7
Training loss: 0.4305892884731293
Validation loss: 1.7856427854107273

Epoch: 5| Step: 8
Training loss: 0.2341034710407257
Validation loss: 1.7607840235515306

Epoch: 5| Step: 9
Training loss: 0.3533109724521637
Validation loss: 1.7627173854458718

Epoch: 5| Step: 10
Training loss: 0.42800208926200867
Validation loss: 1.7292862887023597

Epoch: 320| Step: 0
Training loss: 0.5129123330116272
Validation loss: 1.6479077505809006

Epoch: 5| Step: 1
Training loss: 0.2542637288570404
Validation loss: 1.650732704388198

Epoch: 5| Step: 2
Training loss: 0.40320977568626404
Validation loss: 1.6153096332344958

Epoch: 5| Step: 3
Training loss: 0.3371747136116028
Validation loss: 1.6226440040014123

Epoch: 5| Step: 4
Training loss: 0.2369077205657959
Validation loss: 1.639726564448367

Epoch: 5| Step: 5
Training loss: 0.31380695104599
Validation loss: 1.668179379996433

Epoch: 5| Step: 6
Training loss: 0.4275015890598297
Validation loss: 1.676343479464131

Epoch: 5| Step: 7
Training loss: 0.3917316496372223
Validation loss: 1.6460067123495123

Epoch: 5| Step: 8
Training loss: 0.20495197176933289
Validation loss: 1.6609124714328396

Epoch: 5| Step: 9
Training loss: 0.250101238489151
Validation loss: 1.6720087066773446

Epoch: 5| Step: 10
Training loss: 0.1635541319847107
Validation loss: 1.6720670243745208

Epoch: 321| Step: 0
Training loss: 0.3812407851219177
Validation loss: 1.7190431151338803

Epoch: 5| Step: 1
Training loss: 0.2817038893699646
Validation loss: 1.7098568254901516

Epoch: 5| Step: 2
Training loss: 0.2893465757369995
Validation loss: 1.691832411673761

Epoch: 5| Step: 3
Training loss: 0.1878160536289215
Validation loss: 1.7185434551649197

Epoch: 5| Step: 4
Training loss: 0.33554568886756897
Validation loss: 1.7238355708378617

Epoch: 5| Step: 5
Training loss: 0.21796341240406036
Validation loss: 1.6888025883705384

Epoch: 5| Step: 6
Training loss: 0.2750357985496521
Validation loss: 1.689390524741142

Epoch: 5| Step: 7
Training loss: 0.3097417950630188
Validation loss: 1.6471312212687668

Epoch: 5| Step: 8
Training loss: 0.4903666377067566
Validation loss: 1.6331518427018197

Epoch: 5| Step: 9
Training loss: 0.28384771943092346
Validation loss: 1.6384364328076761

Epoch: 5| Step: 10
Training loss: 0.2445773482322693
Validation loss: 1.6388901138818392

Epoch: 322| Step: 0
Training loss: 0.4718441069126129
Validation loss: 1.6557871526287449

Epoch: 5| Step: 1
Training loss: 0.24312742054462433
Validation loss: 1.6756572178615037

Epoch: 5| Step: 2
Training loss: 0.4119848608970642
Validation loss: 1.7080876968240226

Epoch: 5| Step: 3
Training loss: 0.25950032472610474
Validation loss: 1.6778623968042352

Epoch: 5| Step: 4
Training loss: 0.11811677366495132
Validation loss: 1.6838891660013506

Epoch: 5| Step: 5
Training loss: 0.2423062026500702
Validation loss: 1.6669463906236874

Epoch: 5| Step: 6
Training loss: 0.3106353282928467
Validation loss: 1.6766325555821902

Epoch: 5| Step: 7
Training loss: 0.29769545793533325
Validation loss: 1.6918319963639783

Epoch: 5| Step: 8
Training loss: 0.34775999188423157
Validation loss: 1.731480726631739

Epoch: 5| Step: 9
Training loss: 0.19271673262119293
Validation loss: 1.709586384475872

Epoch: 5| Step: 10
Training loss: 0.28832781314849854
Validation loss: 1.7014327485074279

Epoch: 323| Step: 0
Training loss: 0.2765745520591736
Validation loss: 1.740820918031918

Epoch: 5| Step: 1
Training loss: 0.3521958291530609
Validation loss: 1.7339170132913897

Epoch: 5| Step: 2
Training loss: 0.24489712715148926
Validation loss: 1.7810974095457344

Epoch: 5| Step: 3
Training loss: 0.14116765558719635
Validation loss: 1.7431428124827724

Epoch: 5| Step: 4
Training loss: 0.2818140387535095
Validation loss: 1.6983144860113821

Epoch: 5| Step: 5
Training loss: 0.5133229494094849
Validation loss: 1.7211402270101732

Epoch: 5| Step: 6
Training loss: 0.22585730254650116
Validation loss: 1.7187705911615843

Epoch: 5| Step: 7
Training loss: 0.2025177925825119
Validation loss: 1.7042208217805432

Epoch: 5| Step: 8
Training loss: 0.3523775339126587
Validation loss: 1.7469535463599748

Epoch: 5| Step: 9
Training loss: 0.3638066053390503
Validation loss: 1.7490002224522252

Epoch: 5| Step: 10
Training loss: 0.2964664399623871
Validation loss: 1.7452174989126061

Epoch: 324| Step: 0
Training loss: 0.33689752221107483
Validation loss: 1.7114040082500828

Epoch: 5| Step: 1
Training loss: 0.3369753062725067
Validation loss: 1.707309297336045

Epoch: 5| Step: 2
Training loss: 0.2543947994709015
Validation loss: 1.7018940243669736

Epoch: 5| Step: 3
Training loss: 0.32298746705055237
Validation loss: 1.7300877327560096

Epoch: 5| Step: 4
Training loss: 0.15663500130176544
Validation loss: 1.7085203291267477

Epoch: 5| Step: 5
Training loss: 0.32521095871925354
Validation loss: 1.726861693525827

Epoch: 5| Step: 6
Training loss: 0.3030453622341156
Validation loss: 1.763246650336891

Epoch: 5| Step: 7
Training loss: 0.2579491138458252
Validation loss: 1.7231101477017967

Epoch: 5| Step: 8
Training loss: 0.2336115539073944
Validation loss: 1.7238542149143834

Epoch: 5| Step: 9
Training loss: 0.38558095693588257
Validation loss: 1.6935494574167396

Epoch: 5| Step: 10
Training loss: 0.1855233907699585
Validation loss: 1.655943484716518

Epoch: 325| Step: 0
Training loss: 0.20750752091407776
Validation loss: 1.6514842510223389

Epoch: 5| Step: 1
Training loss: 0.30346935987472534
Validation loss: 1.6328141612391318

Epoch: 5| Step: 2
Training loss: 0.35468149185180664
Validation loss: 1.7087219645900111

Epoch: 5| Step: 3
Training loss: 0.275971919298172
Validation loss: 1.6933042182717273

Epoch: 5| Step: 4
Training loss: 0.18838109076023102
Validation loss: 1.679655821092667

Epoch: 5| Step: 5
Training loss: 0.2414580136537552
Validation loss: 1.7031153094383977

Epoch: 5| Step: 6
Training loss: 0.31744584441185
Validation loss: 1.7380809989026798

Epoch: 5| Step: 7
Training loss: 0.3547656238079071
Validation loss: 1.7635870748950588

Epoch: 5| Step: 8
Training loss: 0.30141717195510864
Validation loss: 1.7795251466894662

Epoch: 5| Step: 9
Training loss: 0.16968248784542084
Validation loss: 1.7669772383987263

Epoch: 5| Step: 10
Training loss: 0.23493847250938416
Validation loss: 1.7184122275280695

Epoch: 326| Step: 0
Training loss: 0.22638633847236633
Validation loss: 1.7145464266500166

Epoch: 5| Step: 1
Training loss: 0.29586493968963623
Validation loss: 1.7120217174612067

Epoch: 5| Step: 2
Training loss: 0.3514426350593567
Validation loss: 1.6787901334865118

Epoch: 5| Step: 3
Training loss: 0.30678433179855347
Validation loss: 1.6260310731908327

Epoch: 5| Step: 4
Training loss: 0.30399560928344727
Validation loss: 1.6411036419612106

Epoch: 5| Step: 5
Training loss: 0.2301669418811798
Validation loss: 1.6489596828337638

Epoch: 5| Step: 6
Training loss: 0.2996293902397156
Validation loss: 1.653385684054385

Epoch: 5| Step: 7
Training loss: 0.3702240586280823
Validation loss: 1.647298538556663

Epoch: 5| Step: 8
Training loss: 0.20158597826957703
Validation loss: 1.6133248677817724

Epoch: 5| Step: 9
Training loss: 0.1981784999370575
Validation loss: 1.653025460499589

Epoch: 5| Step: 10
Training loss: 0.3310455083847046
Validation loss: 1.6818227767944336

Epoch: 327| Step: 0
Training loss: 0.3704553246498108
Validation loss: 1.6857040287345968

Epoch: 5| Step: 1
Training loss: 0.18295827507972717
Validation loss: 1.7182998913590626

Epoch: 5| Step: 2
Training loss: 0.21627092361450195
Validation loss: 1.7301908859642603

Epoch: 5| Step: 3
Training loss: 0.2921013832092285
Validation loss: 1.7595753208283456

Epoch: 5| Step: 4
Training loss: 0.2410314530134201
Validation loss: 1.7685336400103826

Epoch: 5| Step: 5
Training loss: 0.3630099892616272
Validation loss: 1.7440369359908565

Epoch: 5| Step: 6
Training loss: 0.16306066513061523
Validation loss: 1.7137668978783391

Epoch: 5| Step: 7
Training loss: 0.32541143894195557
Validation loss: 1.7171147151659893

Epoch: 5| Step: 8
Training loss: 0.2623037099838257
Validation loss: 1.6907106599500101

Epoch: 5| Step: 9
Training loss: 0.39724835753440857
Validation loss: 1.6940445528235486

Epoch: 5| Step: 10
Training loss: 0.3670600354671478
Validation loss: 1.6612277095035841

Epoch: 328| Step: 0
Training loss: 0.17802341282367706
Validation loss: 1.6729136320852465

Epoch: 5| Step: 1
Training loss: 0.46726828813552856
Validation loss: 1.6628017374264297

Epoch: 5| Step: 2
Training loss: 0.16912034153938293
Validation loss: 1.6954440250191638

Epoch: 5| Step: 3
Training loss: 0.3220491409301758
Validation loss: 1.723978704021823

Epoch: 5| Step: 4
Training loss: 0.3172772228717804
Validation loss: 1.7742599838523454

Epoch: 5| Step: 5
Training loss: 0.2702818512916565
Validation loss: 1.784629475685858

Epoch: 5| Step: 6
Training loss: 0.25860369205474854
Validation loss: 1.759999898172194

Epoch: 5| Step: 7
Training loss: 0.3392108678817749
Validation loss: 1.7535262197576544

Epoch: 5| Step: 8
Training loss: 0.26179298758506775
Validation loss: 1.7272787914481214

Epoch: 5| Step: 9
Training loss: 0.30401411652565
Validation loss: 1.7319179914330924

Epoch: 5| Step: 10
Training loss: 0.41578251123428345
Validation loss: 1.68167802082595

Epoch: 329| Step: 0
Training loss: 0.33430442214012146
Validation loss: 1.6784888121389574

Epoch: 5| Step: 1
Training loss: 0.25901123881340027
Validation loss: 1.6783481823500765

Epoch: 5| Step: 2
Training loss: 0.17487214505672455
Validation loss: 1.729981896697834

Epoch: 5| Step: 3
Training loss: 0.2540358603000641
Validation loss: 1.7358496958209622

Epoch: 5| Step: 4
Training loss: 0.17938287556171417
Validation loss: 1.7823960576006161

Epoch: 5| Step: 5
Training loss: 0.4658295214176178
Validation loss: 1.8024295248011106

Epoch: 5| Step: 6
Training loss: 0.3455229699611664
Validation loss: 1.825510799243886

Epoch: 5| Step: 7
Training loss: 0.18999072909355164
Validation loss: 1.8134861812796643

Epoch: 5| Step: 8
Training loss: 0.3247949481010437
Validation loss: 1.7821524066309775

Epoch: 5| Step: 9
Training loss: 0.2871895730495453
Validation loss: 1.7722654829743087

Epoch: 5| Step: 10
Training loss: 0.2545985281467438
Validation loss: 1.758056875198118

Epoch: 330| Step: 0
Training loss: 0.3097720742225647
Validation loss: 1.7186638719292098

Epoch: 5| Step: 1
Training loss: 0.3455887734889984
Validation loss: 1.7142791619864843

Epoch: 5| Step: 2
Training loss: 0.2574462890625
Validation loss: 1.7102946491651638

Epoch: 5| Step: 3
Training loss: 0.35486310720443726
Validation loss: 1.6798334736977854

Epoch: 5| Step: 4
Training loss: 0.26599130034446716
Validation loss: 1.6618940753321494

Epoch: 5| Step: 5
Training loss: 0.19448763132095337
Validation loss: 1.647435353648278

Epoch: 5| Step: 6
Training loss: 0.29212674498558044
Validation loss: 1.639811356862386

Epoch: 5| Step: 7
Training loss: 0.14007370173931122
Validation loss: 1.658760775801956

Epoch: 5| Step: 8
Training loss: 0.21972505748271942
Validation loss: 1.6634241214362524

Epoch: 5| Step: 9
Training loss: 0.2790391445159912
Validation loss: 1.6570616473433792

Epoch: 5| Step: 10
Training loss: 0.22560295462608337
Validation loss: 1.627943072267758

Epoch: 331| Step: 0
Training loss: 0.2729792594909668
Validation loss: 1.6371207416698497

Epoch: 5| Step: 1
Training loss: 0.26676979660987854
Validation loss: 1.639917512093821

Epoch: 5| Step: 2
Training loss: 0.27741414308547974
Validation loss: 1.667716855643898

Epoch: 5| Step: 3
Training loss: 0.1540529429912567
Validation loss: 1.6634415080470424

Epoch: 5| Step: 4
Training loss: 0.4465702474117279
Validation loss: 1.6456276973088582

Epoch: 5| Step: 5
Training loss: 0.23556479811668396
Validation loss: 1.6428958959476923

Epoch: 5| Step: 6
Training loss: 0.129069522023201
Validation loss: 1.6358584998756327

Epoch: 5| Step: 7
Training loss: 0.15306058526039124
Validation loss: 1.6893215320443595

Epoch: 5| Step: 8
Training loss: 0.20552463829517365
Validation loss: 1.6787292906033096

Epoch: 5| Step: 9
Training loss: 0.26695865392684937
Validation loss: 1.6674501101175945

Epoch: 5| Step: 10
Training loss: 0.22961631417274475
Validation loss: 1.7258535674823228

Epoch: 332| Step: 0
Training loss: 0.2532752454280853
Validation loss: 1.6950409412384033

Epoch: 5| Step: 1
Training loss: 0.19886985421180725
Validation loss: 1.6956053767153012

Epoch: 5| Step: 2
Training loss: 0.30918264389038086
Validation loss: 1.6748247749061995

Epoch: 5| Step: 3
Training loss: 0.13491007685661316
Validation loss: 1.6652726191346363

Epoch: 5| Step: 4
Training loss: 0.2440917044878006
Validation loss: 1.6427434413663802

Epoch: 5| Step: 5
Training loss: 0.23837371170520782
Validation loss: 1.648912109354491

Epoch: 5| Step: 6
Training loss: 0.2502838671207428
Validation loss: 1.6480265971153014

Epoch: 5| Step: 7
Training loss: 0.15160182118415833
Validation loss: 1.6432010794198642

Epoch: 5| Step: 8
Training loss: 0.2614801526069641
Validation loss: 1.6230371959747807

Epoch: 5| Step: 9
Training loss: 0.24369272589683533
Validation loss: 1.6510733404467184

Epoch: 5| Step: 10
Training loss: 0.29437434673309326
Validation loss: 1.6787085892051778

Epoch: 333| Step: 0
Training loss: 0.18553587794303894
Validation loss: 1.64637497163588

Epoch: 5| Step: 1
Training loss: 0.23215222358703613
Validation loss: 1.697211201472949

Epoch: 5| Step: 2
Training loss: 0.13016009330749512
Validation loss: 1.7104066802609352

Epoch: 5| Step: 3
Training loss: 0.31086626648902893
Validation loss: 1.6580653754613732

Epoch: 5| Step: 4
Training loss: 0.2485111653804779
Validation loss: 1.6625026913099392

Epoch: 5| Step: 5
Training loss: 0.38999584317207336
Validation loss: 1.6422175515082575

Epoch: 5| Step: 6
Training loss: 0.2419450283050537
Validation loss: 1.634100176954782

Epoch: 5| Step: 7
Training loss: 0.3068564832210541
Validation loss: 1.6624883746588102

Epoch: 5| Step: 8
Training loss: 0.27247029542922974
Validation loss: 1.6682920327750586

Epoch: 5| Step: 9
Training loss: 0.1915924996137619
Validation loss: 1.667048591439442

Epoch: 5| Step: 10
Training loss: 0.23021869361400604
Validation loss: 1.6951932073921285

Epoch: 334| Step: 0
Training loss: 0.37779802083969116
Validation loss: 1.7033641530621437

Epoch: 5| Step: 1
Training loss: 0.23973724246025085
Validation loss: 1.6646205814935828

Epoch: 5| Step: 2
Training loss: 0.10412769019603729
Validation loss: 1.67005548297718

Epoch: 5| Step: 3
Training loss: 0.30564990639686584
Validation loss: 1.6774880225940416

Epoch: 5| Step: 4
Training loss: 0.3284584581851959
Validation loss: 1.6563756004456551

Epoch: 5| Step: 5
Training loss: 0.21536831557750702
Validation loss: 1.670441061578771

Epoch: 5| Step: 6
Training loss: 0.12162932008504868
Validation loss: 1.6600665546232654

Epoch: 5| Step: 7
Training loss: 0.19998276233673096
Validation loss: 1.650876501555084

Epoch: 5| Step: 8
Training loss: 0.1457417905330658
Validation loss: 1.6597645128926923

Epoch: 5| Step: 9
Training loss: 0.3767387270927429
Validation loss: 1.647460949036383

Epoch: 5| Step: 10
Training loss: 0.24058330059051514
Validation loss: 1.6615311317546393

Epoch: 335| Step: 0
Training loss: 0.1819687783718109
Validation loss: 1.6677759039786555

Epoch: 5| Step: 1
Training loss: 0.2971010208129883
Validation loss: 1.6520411122229792

Epoch: 5| Step: 2
Training loss: 0.19305497407913208
Validation loss: 1.662527358660134

Epoch: 5| Step: 3
Training loss: 0.23433203995227814
Validation loss: 1.7013279225236626

Epoch: 5| Step: 4
Training loss: 0.4574919641017914
Validation loss: 1.6940328254494617

Epoch: 5| Step: 5
Training loss: 0.1464967280626297
Validation loss: 1.6988594429467314

Epoch: 5| Step: 6
Training loss: 0.25798338651657104
Validation loss: 1.7143702840292325

Epoch: 5| Step: 7
Training loss: 0.20523743331432343
Validation loss: 1.7002604302539621

Epoch: 5| Step: 8
Training loss: 0.24668999016284943
Validation loss: 1.6689725960454633

Epoch: 5| Step: 9
Training loss: 0.4165184497833252
Validation loss: 1.6925799667194326

Epoch: 5| Step: 10
Training loss: 0.19433920085430145
Validation loss: 1.6665334175991755

Epoch: 336| Step: 0
Training loss: 0.44041046500205994
Validation loss: 1.661286747583779

Epoch: 5| Step: 1
Training loss: 0.2486192286014557
Validation loss: 1.6999103369251374

Epoch: 5| Step: 2
Training loss: 0.25075405836105347
Validation loss: 1.6804520442921629

Epoch: 5| Step: 3
Training loss: 0.23836001753807068
Validation loss: 1.682377576828003

Epoch: 5| Step: 4
Training loss: 0.2234441488981247
Validation loss: 1.7099986460901075

Epoch: 5| Step: 5
Training loss: 0.1927649974822998
Validation loss: 1.680431506967032

Epoch: 5| Step: 6
Training loss: 0.2280198335647583
Validation loss: 1.7065951106368855

Epoch: 5| Step: 7
Training loss: 0.32902753353118896
Validation loss: 1.7143797477086384

Epoch: 5| Step: 8
Training loss: 0.16772297024726868
Validation loss: 1.706613048430412

Epoch: 5| Step: 9
Training loss: 0.28457099199295044
Validation loss: 1.6953854099396737

Epoch: 5| Step: 10
Training loss: 0.2459583878517151
Validation loss: 1.7180268456858974

Epoch: 337| Step: 0
Training loss: 0.15222930908203125
Validation loss: 1.6675297880685458

Epoch: 5| Step: 1
Training loss: 0.27820885181427
Validation loss: 1.671948068885393

Epoch: 5| Step: 2
Training loss: 0.29882320761680603
Validation loss: 1.6761798679187734

Epoch: 5| Step: 3
Training loss: 0.2994709014892578
Validation loss: 1.671836450535764

Epoch: 5| Step: 4
Training loss: 0.24292869865894318
Validation loss: 1.663663702626382

Epoch: 5| Step: 5
Training loss: 0.1848759949207306
Validation loss: 1.6543451496349868

Epoch: 5| Step: 6
Training loss: 0.34043169021606445
Validation loss: 1.69992499069501

Epoch: 5| Step: 7
Training loss: 0.18930533528327942
Validation loss: 1.719592785322538

Epoch: 5| Step: 8
Training loss: 0.29337278008461
Validation loss: 1.732541186835176

Epoch: 5| Step: 9
Training loss: 0.31277841329574585
Validation loss: 1.722982665543915

Epoch: 5| Step: 10
Training loss: 0.24044014513492584
Validation loss: 1.7288794594426309

Epoch: 338| Step: 0
Training loss: 0.2722722291946411
Validation loss: 1.725796599541941

Epoch: 5| Step: 1
Training loss: 0.2502395510673523
Validation loss: 1.7093044211787563

Epoch: 5| Step: 2
Training loss: 0.35795703530311584
Validation loss: 1.6881350778764295

Epoch: 5| Step: 3
Training loss: 0.26707983016967773
Validation loss: 1.694597432690282

Epoch: 5| Step: 4
Training loss: 0.23882775008678436
Validation loss: 1.6883536615679342

Epoch: 5| Step: 5
Training loss: 0.3007758855819702
Validation loss: 1.6970190104617868

Epoch: 5| Step: 6
Training loss: 0.22206130623817444
Validation loss: 1.6895065384526406

Epoch: 5| Step: 7
Training loss: 0.3607937693595886
Validation loss: 1.665042145277864

Epoch: 5| Step: 8
Training loss: 0.303234726190567
Validation loss: 1.6616084203925183

Epoch: 5| Step: 9
Training loss: 0.19125348329544067
Validation loss: 1.638642854588006

Epoch: 5| Step: 10
Training loss: 0.2633059322834015
Validation loss: 1.653575760062023

Epoch: 339| Step: 0
Training loss: 0.31165164709091187
Validation loss: 1.663387389593227

Epoch: 5| Step: 1
Training loss: 0.34605011343955994
Validation loss: 1.6260087041444675

Epoch: 5| Step: 2
Training loss: 0.221121147274971
Validation loss: 1.6578983453012281

Epoch: 5| Step: 3
Training loss: 0.280865341424942
Validation loss: 1.6634342798622705

Epoch: 5| Step: 4
Training loss: 0.14602366089820862
Validation loss: 1.6593772211382467

Epoch: 5| Step: 5
Training loss: 0.17608916759490967
Validation loss: 1.6642464796702068

Epoch: 5| Step: 6
Training loss: 0.375277042388916
Validation loss: 1.701457674785327

Epoch: 5| Step: 7
Training loss: 0.11879511922597885
Validation loss: 1.6928395161064722

Epoch: 5| Step: 8
Training loss: 0.24000880122184753
Validation loss: 1.6652386611507786

Epoch: 5| Step: 9
Training loss: 0.21410346031188965
Validation loss: 1.635088010500836

Epoch: 5| Step: 10
Training loss: 0.26326924562454224
Validation loss: 1.6216723803550965

Epoch: 340| Step: 0
Training loss: 0.30879080295562744
Validation loss: 1.6248433897572179

Epoch: 5| Step: 1
Training loss: 0.2977123558521271
Validation loss: 1.6386302683943061

Epoch: 5| Step: 2
Training loss: 0.24002699553966522
Validation loss: 1.6236783471158756

Epoch: 5| Step: 3
Training loss: 0.30797770619392395
Validation loss: 1.6334459371464227

Epoch: 5| Step: 4
Training loss: 0.11472459137439728
Validation loss: 1.6745376445913827

Epoch: 5| Step: 5
Training loss: 0.14244648814201355
Validation loss: 1.689704320764029

Epoch: 5| Step: 6
Training loss: 0.2224626988172531
Validation loss: 1.7338300584464945

Epoch: 5| Step: 7
Training loss: 0.18703052401542664
Validation loss: 1.7342823077273626

Epoch: 5| Step: 8
Training loss: 0.17635926604270935
Validation loss: 1.734404589540215

Epoch: 5| Step: 9
Training loss: 0.3581275939941406
Validation loss: 1.7406224371284567

Epoch: 5| Step: 10
Training loss: 0.20948007702827454
Validation loss: 1.7538098904394335

Epoch: 341| Step: 0
Training loss: 0.3324034512042999
Validation loss: 1.7096899331256907

Epoch: 5| Step: 1
Training loss: 0.22828367352485657
Validation loss: 1.7288458449866182

Epoch: 5| Step: 2
Training loss: 0.2000865936279297
Validation loss: 1.7016173178149807

Epoch: 5| Step: 3
Training loss: 0.19245575368404388
Validation loss: 1.663895740303942

Epoch: 5| Step: 4
Training loss: 0.16291695833206177
Validation loss: 1.6301796923401535

Epoch: 5| Step: 5
Training loss: 0.3222864270210266
Validation loss: 1.641081504924323

Epoch: 5| Step: 6
Training loss: 0.17626772820949554
Validation loss: 1.6293784828596218

Epoch: 5| Step: 7
Training loss: 0.31425389647483826
Validation loss: 1.653604870201439

Epoch: 5| Step: 8
Training loss: 0.1354425847530365
Validation loss: 1.6295788634207942

Epoch: 5| Step: 9
Training loss: 0.2371940314769745
Validation loss: 1.647107740884186

Epoch: 5| Step: 10
Training loss: 0.16740407049655914
Validation loss: 1.6477641982416953

Epoch: 342| Step: 0
Training loss: 0.23059716820716858
Validation loss: 1.685149271001098

Epoch: 5| Step: 1
Training loss: 0.31499987840652466
Validation loss: 1.6714395425652946

Epoch: 5| Step: 2
Training loss: 0.24739161133766174
Validation loss: 1.6848973599813317

Epoch: 5| Step: 3
Training loss: 0.24551990628242493
Validation loss: 1.6391209915120115

Epoch: 5| Step: 4
Training loss: 0.2814299762248993
Validation loss: 1.674194828156502

Epoch: 5| Step: 5
Training loss: 0.29803234338760376
Validation loss: 1.6608447028744606

Epoch: 5| Step: 6
Training loss: 0.3133653700351715
Validation loss: 1.6392746394680393

Epoch: 5| Step: 7
Training loss: 0.27800682187080383
Validation loss: 1.6680694767223891

Epoch: 5| Step: 8
Training loss: 0.1264295130968094
Validation loss: 1.640377588169549

Epoch: 5| Step: 9
Training loss: 0.18551521003246307
Validation loss: 1.6717991418735956

Epoch: 5| Step: 10
Training loss: 0.05959814414381981
Validation loss: 1.6761826674143474

Epoch: 343| Step: 0
Training loss: 0.2439996749162674
Validation loss: 1.707327687612144

Epoch: 5| Step: 1
Training loss: 0.17107358574867249
Validation loss: 1.6886221824153778

Epoch: 5| Step: 2
Training loss: 0.23363646864891052
Validation loss: 1.694388392151043

Epoch: 5| Step: 3
Training loss: 0.23037099838256836
Validation loss: 1.6698122165536369

Epoch: 5| Step: 4
Training loss: 0.24291591346263885
Validation loss: 1.6383112771536714

Epoch: 5| Step: 5
Training loss: 0.17211958765983582
Validation loss: 1.6633897981336039

Epoch: 5| Step: 6
Training loss: 0.31161749362945557
Validation loss: 1.6365437699902443

Epoch: 5| Step: 7
Training loss: 0.15910664200782776
Validation loss: 1.6237333115711008

Epoch: 5| Step: 8
Training loss: 0.32711347937583923
Validation loss: 1.6152423402314544

Epoch: 5| Step: 9
Training loss: 0.32232946157455444
Validation loss: 1.6634163670642401

Epoch: 5| Step: 10
Training loss: 0.17499898374080658
Validation loss: 1.665882086241117

Epoch: 344| Step: 0
Training loss: 0.22288823127746582
Validation loss: 1.663297018697185

Epoch: 5| Step: 1
Training loss: 0.23354370892047882
Validation loss: 1.7148579012963079

Epoch: 5| Step: 2
Training loss: 0.3032778203487396
Validation loss: 1.7354796740316576

Epoch: 5| Step: 3
Training loss: 0.30516764521598816
Validation loss: 1.6632710413266254

Epoch: 5| Step: 4
Training loss: 0.1601303219795227
Validation loss: 1.6930332414565548

Epoch: 5| Step: 5
Training loss: 0.2187468707561493
Validation loss: 1.6610411700382028

Epoch: 5| Step: 6
Training loss: 0.36653345823287964
Validation loss: 1.6758869963307534

Epoch: 5| Step: 7
Training loss: 0.2820200026035309
Validation loss: 1.6827902204246932

Epoch: 5| Step: 8
Training loss: 0.2413797676563263
Validation loss: 1.686765154202779

Epoch: 5| Step: 9
Training loss: 0.19444376230239868
Validation loss: 1.6920494494899627

Epoch: 5| Step: 10
Training loss: 0.19988782703876495
Validation loss: 1.6429006527828913

Epoch: 345| Step: 0
Training loss: 0.2834804654121399
Validation loss: 1.65316976142186

Epoch: 5| Step: 1
Training loss: 0.2701272964477539
Validation loss: 1.632975600099051

Epoch: 5| Step: 2
Training loss: 0.20157504081726074
Validation loss: 1.636916729711717

Epoch: 5| Step: 3
Training loss: 0.2114328145980835
Validation loss: 1.6618782704876316

Epoch: 5| Step: 4
Training loss: 0.19357597827911377
Validation loss: 1.6923050572795253

Epoch: 5| Step: 5
Training loss: 0.35881197452545166
Validation loss: 1.6967906618631015

Epoch: 5| Step: 6
Training loss: 0.2936221957206726
Validation loss: 1.6796824932098389

Epoch: 5| Step: 7
Training loss: 0.25531917810440063
Validation loss: 1.718902410999421

Epoch: 5| Step: 8
Training loss: 0.1846531480550766
Validation loss: 1.7652541796366374

Epoch: 5| Step: 9
Training loss: 0.3191623091697693
Validation loss: 1.727078551887184

Epoch: 5| Step: 10
Training loss: 0.20571479201316833
Validation loss: 1.7046623486344532

Epoch: 346| Step: 0
Training loss: 0.20254209637641907
Validation loss: 1.7082576520981327

Epoch: 5| Step: 1
Training loss: 0.2013052999973297
Validation loss: 1.679698577491186

Epoch: 5| Step: 2
Training loss: 0.18909402191638947
Validation loss: 1.6578220552013767

Epoch: 5| Step: 3
Training loss: 0.14166802167892456
Validation loss: 1.6268739238862069

Epoch: 5| Step: 4
Training loss: 0.20313870906829834
Validation loss: 1.6200476500295824

Epoch: 5| Step: 5
Training loss: 0.25801095366477966
Validation loss: 1.6166520477623068

Epoch: 5| Step: 6
Training loss: 0.252075731754303
Validation loss: 1.6214715857659616

Epoch: 5| Step: 7
Training loss: 0.3721662759780884
Validation loss: 1.6602127923760364

Epoch: 5| Step: 8
Training loss: 0.22521135210990906
Validation loss: 1.6508973234443254

Epoch: 5| Step: 9
Training loss: 0.27605342864990234
Validation loss: 1.6715828526404597

Epoch: 5| Step: 10
Training loss: 0.15033599734306335
Validation loss: 1.6554343418408466

Epoch: 347| Step: 0
Training loss: 0.1720692217350006
Validation loss: 1.6808205496880315

Epoch: 5| Step: 1
Training loss: 0.15794691443443298
Validation loss: 1.6809482625735703

Epoch: 5| Step: 2
Training loss: 0.17984291911125183
Validation loss: 1.6432297498949113

Epoch: 5| Step: 3
Training loss: 0.3161613345146179
Validation loss: 1.6635561720017464

Epoch: 5| Step: 4
Training loss: 0.11066754907369614
Validation loss: 1.657172106927441

Epoch: 5| Step: 5
Training loss: 0.2678793966770172
Validation loss: 1.6549488934137488

Epoch: 5| Step: 6
Training loss: 0.2949993908405304
Validation loss: 1.6578295000137822

Epoch: 5| Step: 7
Training loss: 0.230787992477417
Validation loss: 1.684646697454555

Epoch: 5| Step: 8
Training loss: 0.2855345606803894
Validation loss: 1.6952407154985654

Epoch: 5| Step: 9
Training loss: 0.25794705748558044
Validation loss: 1.6890044032886464

Epoch: 5| Step: 10
Training loss: 0.27819037437438965
Validation loss: 1.6713006547702256

Epoch: 348| Step: 0
Training loss: 0.3416478931903839
Validation loss: 1.642004664226245

Epoch: 5| Step: 1
Training loss: 0.18636544048786163
Validation loss: 1.6237631267116917

Epoch: 5| Step: 2
Training loss: 0.14934028685092926
Validation loss: 1.6343738596926454

Epoch: 5| Step: 3
Training loss: 0.26453739404678345
Validation loss: 1.6687891931943997

Epoch: 5| Step: 4
Training loss: 0.29388228058815
Validation loss: 1.6909585332357755

Epoch: 5| Step: 5
Training loss: 0.26295220851898193
Validation loss: 1.6890259904246177

Epoch: 5| Step: 6
Training loss: 0.28039559721946716
Validation loss: 1.6814241556711094

Epoch: 5| Step: 7
Training loss: 0.20654454827308655
Validation loss: 1.6681005108741023

Epoch: 5| Step: 8
Training loss: 0.2155415564775467
Validation loss: 1.6341830991929578

Epoch: 5| Step: 9
Training loss: 0.2312624454498291
Validation loss: 1.661794021565427

Epoch: 5| Step: 10
Training loss: 0.2043333500623703
Validation loss: 1.6713795738835489

Epoch: 349| Step: 0
Training loss: 0.2670983672142029
Validation loss: 1.7105339470730032

Epoch: 5| Step: 1
Training loss: 0.19070303440093994
Validation loss: 1.7094988117935837

Epoch: 5| Step: 2
Training loss: 0.20460382103919983
Validation loss: 1.6912752261725805

Epoch: 5| Step: 3
Training loss: 0.3248768150806427
Validation loss: 1.6791083658895185

Epoch: 5| Step: 4
Training loss: 0.26966923475265503
Validation loss: 1.6469041608995008

Epoch: 5| Step: 5
Training loss: 0.21359781920909882
Validation loss: 1.6647997402375745

Epoch: 5| Step: 6
Training loss: 0.12702925503253937
Validation loss: 1.6746569859084262

Epoch: 5| Step: 7
Training loss: 0.26205307245254517
Validation loss: 1.6324547836857457

Epoch: 5| Step: 8
Training loss: 0.29484859108924866
Validation loss: 1.6453353640853718

Epoch: 5| Step: 9
Training loss: 0.1203911080956459
Validation loss: 1.625851841383083

Epoch: 5| Step: 10
Training loss: 0.1374613493680954
Validation loss: 1.6655578344098982

Epoch: 350| Step: 0
Training loss: 0.25081005692481995
Validation loss: 1.6144579674607964

Epoch: 5| Step: 1
Training loss: 0.18644772469997406
Validation loss: 1.644940153245003

Epoch: 5| Step: 2
Training loss: 0.3031104505062103
Validation loss: 1.6409061877958235

Epoch: 5| Step: 3
Training loss: 0.21413807570934296
Validation loss: 1.6463425120999735

Epoch: 5| Step: 4
Training loss: 0.1943347454071045
Validation loss: 1.6582840168347923

Epoch: 5| Step: 5
Training loss: 0.18256714940071106
Validation loss: 1.6326045823353592

Epoch: 5| Step: 6
Training loss: 0.2583184838294983
Validation loss: 1.6454040337634344

Epoch: 5| Step: 7
Training loss: 0.2691938877105713
Validation loss: 1.692495370423922

Epoch: 5| Step: 8
Training loss: 0.2716827094554901
Validation loss: 1.7182650437919043

Epoch: 5| Step: 9
Training loss: 0.23224735260009766
Validation loss: 1.7285634881706649

Epoch: 5| Step: 10
Training loss: 0.2640226483345032
Validation loss: 1.7659719682508899

Epoch: 351| Step: 0
Training loss: 0.27228841185569763
Validation loss: 1.7397834536849812

Epoch: 5| Step: 1
Training loss: 0.20005321502685547
Validation loss: 1.7107950513080885

Epoch: 5| Step: 2
Training loss: 0.37177568674087524
Validation loss: 1.7017319010150047

Epoch: 5| Step: 3
Training loss: 0.12510959804058075
Validation loss: 1.687444661253242

Epoch: 5| Step: 4
Training loss: 0.15448907017707825
Validation loss: 1.6918635445256387

Epoch: 5| Step: 5
Training loss: 0.21277351677417755
Validation loss: 1.6992903371011057

Epoch: 5| Step: 6
Training loss: 0.16164910793304443
Validation loss: 1.6611999824482908

Epoch: 5| Step: 7
Training loss: 0.24962961673736572
Validation loss: 1.6366561228229153

Epoch: 5| Step: 8
Training loss: 0.2290782928466797
Validation loss: 1.61938492713436

Epoch: 5| Step: 9
Training loss: 0.3087284564971924
Validation loss: 1.6114613112582956

Epoch: 5| Step: 10
Training loss: 0.3438403308391571
Validation loss: 1.597277670778254

Epoch: 352| Step: 0
Training loss: 0.2344096451997757
Validation loss: 1.6258039538578322

Epoch: 5| Step: 1
Training loss: 0.2622528076171875
Validation loss: 1.6195488693893596

Epoch: 5| Step: 2
Training loss: 0.24796542525291443
Validation loss: 1.6283742932863132

Epoch: 5| Step: 3
Training loss: 0.2619155943393707
Validation loss: 1.685294234624473

Epoch: 5| Step: 4
Training loss: 0.1431402713060379
Validation loss: 1.6863546140732304

Epoch: 5| Step: 5
Training loss: 0.2632143497467041
Validation loss: 1.7496652936422696

Epoch: 5| Step: 6
Training loss: 0.2508922219276428
Validation loss: 1.7263359510770409

Epoch: 5| Step: 7
Training loss: 0.22111666202545166
Validation loss: 1.7320973475774128

Epoch: 5| Step: 8
Training loss: 0.2425573617219925
Validation loss: 1.6818009653399069

Epoch: 5| Step: 9
Training loss: 0.22070340812206268
Validation loss: 1.647846926925003

Epoch: 5| Step: 10
Training loss: 0.26931437849998474
Validation loss: 1.6065499615925614

Epoch: 353| Step: 0
Training loss: 0.17637711763381958
Validation loss: 1.5868314863533102

Epoch: 5| Step: 1
Training loss: 0.18022748827934265
Validation loss: 1.6015349652177544

Epoch: 5| Step: 2
Training loss: 0.19084373116493225
Validation loss: 1.6343044196405718

Epoch: 5| Step: 3
Training loss: 0.24438270926475525
Validation loss: 1.6171820779000559

Epoch: 5| Step: 4
Training loss: 0.1671992987394333
Validation loss: 1.5919830106919812

Epoch: 5| Step: 5
Training loss: 0.19766385853290558
Validation loss: 1.5934413248492825

Epoch: 5| Step: 6
Training loss: 0.2655296325683594
Validation loss: 1.6358722538076422

Epoch: 5| Step: 7
Training loss: 0.31017690896987915
Validation loss: 1.6621573586617746

Epoch: 5| Step: 8
Training loss: 0.2098097801208496
Validation loss: 1.6657358279792212

Epoch: 5| Step: 9
Training loss: 0.3138149380683899
Validation loss: 1.710306498312181

Epoch: 5| Step: 10
Training loss: 0.1895991712808609
Validation loss: 1.687241695260489

Epoch: 354| Step: 0
Training loss: 0.31024011969566345
Validation loss: 1.6972717751738846

Epoch: 5| Step: 1
Training loss: 0.22831261157989502
Validation loss: 1.7126847121023363

Epoch: 5| Step: 2
Training loss: 0.1863333284854889
Validation loss: 1.6727126529139857

Epoch: 5| Step: 3
Training loss: 0.14034529030323029
Validation loss: 1.6559271068983181

Epoch: 5| Step: 4
Training loss: 0.21113422513008118
Validation loss: 1.6296650453280377

Epoch: 5| Step: 5
Training loss: 0.16405604779720306
Validation loss: 1.6442110769210323

Epoch: 5| Step: 6
Training loss: 0.2981454133987427
Validation loss: 1.6606848278353292

Epoch: 5| Step: 7
Training loss: 0.25780773162841797
Validation loss: 1.6570951989901963

Epoch: 5| Step: 8
Training loss: 0.12558133900165558
Validation loss: 1.6616738009196457

Epoch: 5| Step: 9
Training loss: 0.21857145428657532
Validation loss: 1.6269542850473875

Epoch: 5| Step: 10
Training loss: 0.25208741426467896
Validation loss: 1.6057062495139338

Epoch: 355| Step: 0
Training loss: 0.16291531920433044
Validation loss: 1.6390522679974955

Epoch: 5| Step: 1
Training loss: 0.2556155025959015
Validation loss: 1.6636050619104856

Epoch: 5| Step: 2
Training loss: 0.22651579976081848
Validation loss: 1.7265982320231776

Epoch: 5| Step: 3
Training loss: 0.3679904341697693
Validation loss: 1.738590807043096

Epoch: 5| Step: 4
Training loss: 0.30163782835006714
Validation loss: 1.6647643850695701

Epoch: 5| Step: 5
Training loss: 0.23017311096191406
Validation loss: 1.6430661011767644

Epoch: 5| Step: 6
Training loss: 0.20019082725048065
Validation loss: 1.6245307806999452

Epoch: 5| Step: 7
Training loss: 0.19253815710544586
Validation loss: 1.6518872027756066

Epoch: 5| Step: 8
Training loss: 0.3731836974620819
Validation loss: 1.6467668907616728

Epoch: 5| Step: 9
Training loss: 0.20371074974536896
Validation loss: 1.6468362833863945

Epoch: 5| Step: 10
Training loss: 0.18638890981674194
Validation loss: 1.649118519598438

Epoch: 356| Step: 0
Training loss: 0.1799807846546173
Validation loss: 1.649390286014926

Epoch: 5| Step: 1
Training loss: 0.22466444969177246
Validation loss: 1.6544993128827823

Epoch: 5| Step: 2
Training loss: 0.2736644744873047
Validation loss: 1.6919956514912267

Epoch: 5| Step: 3
Training loss: 0.33163079619407654
Validation loss: 1.695849927522803

Epoch: 5| Step: 4
Training loss: 0.31289142370224
Validation loss: 1.7167709591568157

Epoch: 5| Step: 5
Training loss: 0.1656990945339203
Validation loss: 1.667534471839987

Epoch: 5| Step: 6
Training loss: 0.12645947933197021
Validation loss: 1.6665310667407127

Epoch: 5| Step: 7
Training loss: 0.23604030907154083
Validation loss: 1.640254726973913

Epoch: 5| Step: 8
Training loss: 0.22055411338806152
Validation loss: 1.6429359976963331

Epoch: 5| Step: 9
Training loss: 0.20774158835411072
Validation loss: 1.6508425820258357

Epoch: 5| Step: 10
Training loss: 0.22327406704425812
Validation loss: 1.654040046917495

Epoch: 357| Step: 0
Training loss: 0.27065980434417725
Validation loss: 1.6117737408607238

Epoch: 5| Step: 1
Training loss: 0.1380755454301834
Validation loss: 1.6250904708780267

Epoch: 5| Step: 2
Training loss: 0.182485893368721
Validation loss: 1.6109498111150597

Epoch: 5| Step: 3
Training loss: 0.17338286340236664
Validation loss: 1.5813445557830155

Epoch: 5| Step: 4
Training loss: 0.14376497268676758
Validation loss: 1.5818072929177234

Epoch: 5| Step: 5
Training loss: 0.12309224903583527
Validation loss: 1.612249933263307

Epoch: 5| Step: 6
Training loss: 0.1923053115606308
Validation loss: 1.6142434740579257

Epoch: 5| Step: 7
Training loss: 0.249978706240654
Validation loss: 1.6273243427276611

Epoch: 5| Step: 8
Training loss: 0.36983340978622437
Validation loss: 1.6126061626659927

Epoch: 5| Step: 9
Training loss: 0.21493956446647644
Validation loss: 1.6163683693896058

Epoch: 5| Step: 10
Training loss: 0.19133436679840088
Validation loss: 1.6232504665210683

Epoch: 358| Step: 0
Training loss: 0.25208476185798645
Validation loss: 1.6326676363586097

Epoch: 5| Step: 1
Training loss: 0.22046005725860596
Validation loss: 1.6537215209776355

Epoch: 5| Step: 2
Training loss: 0.19366590678691864
Validation loss: 1.6433972735558786

Epoch: 5| Step: 3
Training loss: 0.2351246327161789
Validation loss: 1.6532813361895982

Epoch: 5| Step: 4
Training loss: 0.2185264527797699
Validation loss: 1.6280343250561786

Epoch: 5| Step: 5
Training loss: 0.21751704812049866
Validation loss: 1.6123359177702217

Epoch: 5| Step: 6
Training loss: 0.11789476871490479
Validation loss: 1.6178806494641047

Epoch: 5| Step: 7
Training loss: 0.19086170196533203
Validation loss: 1.6162272345635198

Epoch: 5| Step: 8
Training loss: 0.16585858166217804
Validation loss: 1.6634183583721038

Epoch: 5| Step: 9
Training loss: 0.14732542634010315
Validation loss: 1.663398523484507

Epoch: 5| Step: 10
Training loss: 0.1922113299369812
Validation loss: 1.6520938629745154

Epoch: 359| Step: 0
Training loss: 0.1514829397201538
Validation loss: 1.6868329022520332

Epoch: 5| Step: 1
Training loss: 0.27880120277404785
Validation loss: 1.6847755960238877

Epoch: 5| Step: 2
Training loss: 0.1687181442975998
Validation loss: 1.6748353409510788

Epoch: 5| Step: 3
Training loss: 0.2292020320892334
Validation loss: 1.6932571421387375

Epoch: 5| Step: 4
Training loss: 0.16966070234775543
Validation loss: 1.6693231790296492

Epoch: 5| Step: 5
Training loss: 0.17176243662834167
Validation loss: 1.6728438344053043

Epoch: 5| Step: 6
Training loss: 0.18262524902820587
Validation loss: 1.6310948120650424

Epoch: 5| Step: 7
Training loss: 0.2754133343696594
Validation loss: 1.6084533468369515

Epoch: 5| Step: 8
Training loss: 0.13259665668010712
Validation loss: 1.6108684148839725

Epoch: 5| Step: 9
Training loss: 0.363239049911499
Validation loss: 1.597014493839715

Epoch: 5| Step: 10
Training loss: 0.1621563881635666
Validation loss: 1.5988370064766175

Epoch: 360| Step: 0
Training loss: 0.2501660883426666
Validation loss: 1.6147344343123897

Epoch: 5| Step: 1
Training loss: 0.22030219435691833
Validation loss: 1.5887869532390306

Epoch: 5| Step: 2
Training loss: 0.18828798830509186
Validation loss: 1.5510091281706286

Epoch: 5| Step: 3
Training loss: 0.28419438004493713
Validation loss: 1.5407283139485184

Epoch: 5| Step: 4
Training loss: 0.24509474635124207
Validation loss: 1.539789749730018

Epoch: 5| Step: 5
Training loss: 0.1796189546585083
Validation loss: 1.5600260496139526

Epoch: 5| Step: 6
Training loss: 0.16465966403484344
Validation loss: 1.6019315822150118

Epoch: 5| Step: 7
Training loss: 0.3323511481285095
Validation loss: 1.6501260483136742

Epoch: 5| Step: 8
Training loss: 0.20245757699012756
Validation loss: 1.6561307343103553

Epoch: 5| Step: 9
Training loss: 0.2395494431257248
Validation loss: 1.6677667453724851

Epoch: 5| Step: 10
Training loss: 0.2048628181219101
Validation loss: 1.6245905609541043

Epoch: 361| Step: 0
Training loss: 0.22399254143238068
Validation loss: 1.6518697572010819

Epoch: 5| Step: 1
Training loss: 0.22585967183113098
Validation loss: 1.6062967315796883

Epoch: 5| Step: 2
Training loss: 0.26054683327674866
Validation loss: 1.612921671200824

Epoch: 5| Step: 3
Training loss: 0.1775088757276535
Validation loss: 1.645960441199682

Epoch: 5| Step: 4
Training loss: 0.20796005427837372
Validation loss: 1.6252201475122923

Epoch: 5| Step: 5
Training loss: 0.18309520184993744
Validation loss: 1.6405031514424149

Epoch: 5| Step: 6
Training loss: 0.19813691079616547
Validation loss: 1.6263817292387768

Epoch: 5| Step: 7
Training loss: 0.2046929895877838
Validation loss: 1.629330273597471

Epoch: 5| Step: 8
Training loss: 0.22427232563495636
Validation loss: 1.6390595756551272

Epoch: 5| Step: 9
Training loss: 0.22721891105175018
Validation loss: 1.6748953057873635

Epoch: 5| Step: 10
Training loss: 0.23268252611160278
Validation loss: 1.6510121232719832

Epoch: 362| Step: 0
Training loss: 0.2726232409477234
Validation loss: 1.6684312512797694

Epoch: 5| Step: 1
Training loss: 0.26401615142822266
Validation loss: 1.6610967414353484

Epoch: 5| Step: 2
Training loss: 0.26614657044410706
Validation loss: 1.6570682640998595

Epoch: 5| Step: 3
Training loss: 0.2242848426103592
Validation loss: 1.6115137761639011

Epoch: 5| Step: 4
Training loss: 0.17178215086460114
Validation loss: 1.6363847947889758

Epoch: 5| Step: 5
Training loss: 0.18745550513267517
Validation loss: 1.656124040644656

Epoch: 5| Step: 6
Training loss: 0.2150983363389969
Validation loss: 1.6576137337633359

Epoch: 5| Step: 7
Training loss: 0.15332353115081787
Validation loss: 1.6331980728333997

Epoch: 5| Step: 8
Training loss: 0.1802329272031784
Validation loss: 1.6406437017584359

Epoch: 5| Step: 9
Training loss: 0.1461646854877472
Validation loss: 1.63498644931342

Epoch: 5| Step: 10
Training loss: 0.20555850863456726
Validation loss: 1.6307917653873403

Epoch: 363| Step: 0
Training loss: 0.1374790519475937
Validation loss: 1.6237455644915182

Epoch: 5| Step: 1
Training loss: 0.20437070727348328
Validation loss: 1.6349178565445768

Epoch: 5| Step: 2
Training loss: 0.14436502754688263
Validation loss: 1.6267685659470097

Epoch: 5| Step: 3
Training loss: 0.2894546389579773
Validation loss: 1.6597488695575344

Epoch: 5| Step: 4
Training loss: 0.29345715045928955
Validation loss: 1.633713811956426

Epoch: 5| Step: 5
Training loss: 0.2974124550819397
Validation loss: 1.6261809372132825

Epoch: 5| Step: 6
Training loss: 0.2088650017976761
Validation loss: 1.6111773854942733

Epoch: 5| Step: 7
Training loss: 0.21458116173744202
Validation loss: 1.6183538385616836

Epoch: 5| Step: 8
Training loss: 0.1547766923904419
Validation loss: 1.5974919334534676

Epoch: 5| Step: 9
Training loss: 0.13848772644996643
Validation loss: 1.610810205500613

Epoch: 5| Step: 10
Training loss: 0.1621035933494568
Validation loss: 1.5801880154558408

Epoch: 364| Step: 0
Training loss: 0.24096164107322693
Validation loss: 1.591454993012131

Epoch: 5| Step: 1
Training loss: 0.14111614227294922
Validation loss: 1.5287225656611945

Epoch: 5| Step: 2
Training loss: 0.15945501625537872
Validation loss: 1.5670580581952167

Epoch: 5| Step: 3
Training loss: 0.2220221757888794
Validation loss: 1.5226992419970933

Epoch: 5| Step: 4
Training loss: 0.2596881091594696
Validation loss: 1.5568377112829557

Epoch: 5| Step: 5
Training loss: 0.19023999571800232
Validation loss: 1.5532939959597845

Epoch: 5| Step: 6
Training loss: 0.2110559195280075
Validation loss: 1.575729795681533

Epoch: 5| Step: 7
Training loss: 0.19269630312919617
Validation loss: 1.5882932703982118

Epoch: 5| Step: 8
Training loss: 0.18290145695209503
Validation loss: 1.5993435844298332

Epoch: 5| Step: 9
Training loss: 0.20853325724601746
Validation loss: 1.6390686496611564

Epoch: 5| Step: 10
Training loss: 0.22683757543563843
Validation loss: 1.6421611552597375

Epoch: 365| Step: 0
Training loss: 0.2586173713207245
Validation loss: 1.675442627681199

Epoch: 5| Step: 1
Training loss: 0.2528689503669739
Validation loss: 1.6317719951752694

Epoch: 5| Step: 2
Training loss: 0.18689361214637756
Validation loss: 1.626391654373497

Epoch: 5| Step: 3
Training loss: 0.21135644614696503
Validation loss: 1.6171404072033462

Epoch: 5| Step: 4
Training loss: 0.20710206031799316
Validation loss: 1.5880596945362706

Epoch: 5| Step: 5
Training loss: 0.1591508388519287
Validation loss: 1.5524378489422541

Epoch: 5| Step: 6
Training loss: 0.2811988890171051
Validation loss: 1.551786861112041

Epoch: 5| Step: 7
Training loss: 0.33086833357810974
Validation loss: 1.5348859512677757

Epoch: 5| Step: 8
Training loss: 0.15488573908805847
Validation loss: 1.544575434859081

Epoch: 5| Step: 9
Training loss: 0.20068207383155823
Validation loss: 1.5506990878812728

Epoch: 5| Step: 10
Training loss: 0.2277710735797882
Validation loss: 1.6217881620571177

Epoch: 366| Step: 0
Training loss: 0.25366106629371643
Validation loss: 1.6332189536863757

Epoch: 5| Step: 1
Training loss: 0.15715397894382477
Validation loss: 1.61763975697179

Epoch: 5| Step: 2
Training loss: 0.27147772908210754
Validation loss: 1.6070458773643739

Epoch: 5| Step: 3
Training loss: 0.09874182939529419
Validation loss: 1.6052488639790525

Epoch: 5| Step: 4
Training loss: 0.11945077031850815
Validation loss: 1.6231118453446256

Epoch: 5| Step: 5
Training loss: 0.20903806388378143
Validation loss: 1.614661487199927

Epoch: 5| Step: 6
Training loss: 0.20355124771595
Validation loss: 1.5873381681339715

Epoch: 5| Step: 7
Training loss: 0.19218657910823822
Validation loss: 1.5863169572686637

Epoch: 5| Step: 8
Training loss: 0.20355944335460663
Validation loss: 1.6072656839124617

Epoch: 5| Step: 9
Training loss: 0.14844000339508057
Validation loss: 1.604694304927703

Epoch: 5| Step: 10
Training loss: 0.23042897880077362
Validation loss: 1.6086142691232825

Epoch: 367| Step: 0
Training loss: 0.26052919030189514
Validation loss: 1.6251240571339924

Epoch: 5| Step: 1
Training loss: 0.1365939974784851
Validation loss: 1.6522998143267889

Epoch: 5| Step: 2
Training loss: 0.1767040193080902
Validation loss: 1.6521301564349924

Epoch: 5| Step: 3
Training loss: 0.21795973181724548
Validation loss: 1.6483638414772608

Epoch: 5| Step: 4
Training loss: 0.25713109970092773
Validation loss: 1.6538862579612321

Epoch: 5| Step: 5
Training loss: 0.17989389598369598
Validation loss: 1.6277830299510752

Epoch: 5| Step: 6
Training loss: 0.18391449749469757
Validation loss: 1.6201465604125813

Epoch: 5| Step: 7
Training loss: 0.3147766590118408
Validation loss: 1.6200767024870841

Epoch: 5| Step: 8
Training loss: 0.17237749695777893
Validation loss: 1.5975701244928504

Epoch: 5| Step: 9
Training loss: 0.17392536997795105
Validation loss: 1.5957769770776071

Epoch: 5| Step: 10
Training loss: 0.2335250824689865
Validation loss: 1.595751324007588

Epoch: 368| Step: 0
Training loss: 0.19829019904136658
Validation loss: 1.6221337344056816

Epoch: 5| Step: 1
Training loss: 0.169060617685318
Validation loss: 1.6173372178949335

Epoch: 5| Step: 2
Training loss: 0.24742552638053894
Validation loss: 1.6371579503500333

Epoch: 5| Step: 3
Training loss: 0.24726927280426025
Validation loss: 1.6594140145086473

Epoch: 5| Step: 4
Training loss: 0.15653881430625916
Validation loss: 1.6685567517434396

Epoch: 5| Step: 5
Training loss: 0.28149664402008057
Validation loss: 1.6258222544065086

Epoch: 5| Step: 6
Training loss: 0.23671357333660126
Validation loss: 1.6278339124494983

Epoch: 5| Step: 7
Training loss: 0.20344913005828857
Validation loss: 1.559403270803472

Epoch: 5| Step: 8
Training loss: 0.1251770257949829
Validation loss: 1.5907284777651551

Epoch: 5| Step: 9
Training loss: 0.18339204788208008
Validation loss: 1.5752381752896052

Epoch: 5| Step: 10
Training loss: 0.3663608431816101
Validation loss: 1.6317628519509428

Epoch: 369| Step: 0
Training loss: 0.22842641174793243
Validation loss: 1.6308485525910572

Epoch: 5| Step: 1
Training loss: 0.3377057611942291
Validation loss: 1.6609167700172753

Epoch: 5| Step: 2
Training loss: 0.37735170125961304
Validation loss: 1.657171554462884

Epoch: 5| Step: 3
Training loss: 0.1994040310382843
Validation loss: 1.683681058627303

Epoch: 5| Step: 4
Training loss: 0.1598629653453827
Validation loss: 1.692834036324614

Epoch: 5| Step: 5
Training loss: 0.2528541684150696
Validation loss: 1.6565480001511113

Epoch: 5| Step: 6
Training loss: 0.2613656520843506
Validation loss: 1.693361274657711

Epoch: 5| Step: 7
Training loss: 0.24394972622394562
Validation loss: 1.7006535260908064

Epoch: 5| Step: 8
Training loss: 0.2611726224422455
Validation loss: 1.7077873227416829

Epoch: 5| Step: 9
Training loss: 0.24415960907936096
Validation loss: 1.6794543625206075

Epoch: 5| Step: 10
Training loss: 0.1851937174797058
Validation loss: 1.6311268280911189

Epoch: 370| Step: 0
Training loss: 0.16511711478233337
Validation loss: 1.5956154638721096

Epoch: 5| Step: 1
Training loss: 0.16896703839302063
Validation loss: 1.5742300505279212

Epoch: 5| Step: 2
Training loss: 0.3640274405479431
Validation loss: 1.5903710293513473

Epoch: 5| Step: 3
Training loss: 0.2834884524345398
Validation loss: 1.5623054645394767

Epoch: 5| Step: 4
Training loss: 0.27980977296829224
Validation loss: 1.5889871184543898

Epoch: 5| Step: 5
Training loss: 0.25841158628463745
Validation loss: 1.6145732556619952

Epoch: 5| Step: 6
Training loss: 0.14270132780075073
Validation loss: 1.6067926345332977

Epoch: 5| Step: 7
Training loss: 0.23013842105865479
Validation loss: 1.623964512219993

Epoch: 5| Step: 8
Training loss: 0.1985907256603241
Validation loss: 1.6360087753624044

Epoch: 5| Step: 9
Training loss: 0.16776813566684723
Validation loss: 1.6303576384821246

Epoch: 5| Step: 10
Training loss: 0.1260901689529419
Validation loss: 1.6437425536494101

Epoch: 371| Step: 0
Training loss: 0.1582622230052948
Validation loss: 1.6464262457304104

Epoch: 5| Step: 1
Training loss: 0.21225345134735107
Validation loss: 1.6232087919788976

Epoch: 5| Step: 2
Training loss: 0.194568932056427
Validation loss: 1.6356931771001508

Epoch: 5| Step: 3
Training loss: 0.1615549623966217
Validation loss: 1.6478053357011528

Epoch: 5| Step: 4
Training loss: 0.21199700236320496
Validation loss: 1.6410129672737532

Epoch: 5| Step: 5
Training loss: 0.18671463429927826
Validation loss: 1.6034299763300086

Epoch: 5| Step: 6
Training loss: 0.18233242630958557
Validation loss: 1.6241057739462903

Epoch: 5| Step: 7
Training loss: 0.17510375380516052
Validation loss: 1.5986050642946714

Epoch: 5| Step: 8
Training loss: 0.22688183188438416
Validation loss: 1.594637224751134

Epoch: 5| Step: 9
Training loss: 0.19717778265476227
Validation loss: 1.609623944887551

Epoch: 5| Step: 10
Training loss: 0.24263381958007812
Validation loss: 1.5928759241616854

Epoch: 372| Step: 0
Training loss: 0.253723680973053
Validation loss: 1.5638901956619755

Epoch: 5| Step: 1
Training loss: 0.36224010586738586
Validation loss: 1.5918343810624973

Epoch: 5| Step: 2
Training loss: 0.1676574945449829
Validation loss: 1.5933388766422067

Epoch: 5| Step: 3
Training loss: 0.21030303835868835
Validation loss: 1.602661733986229

Epoch: 5| Step: 4
Training loss: 0.21457847952842712
Validation loss: 1.6325205782408356

Epoch: 5| Step: 5
Training loss: 0.19121547043323517
Validation loss: 1.6047733958049486

Epoch: 5| Step: 6
Training loss: 0.1895037591457367
Validation loss: 1.6272324682563863

Epoch: 5| Step: 7
Training loss: 0.13937343657016754
Validation loss: 1.6282978211679766

Epoch: 5| Step: 8
Training loss: 0.10714191198348999
Validation loss: 1.6167762458965342

Epoch: 5| Step: 9
Training loss: 0.21060386300086975
Validation loss: 1.669194229187504

Epoch: 5| Step: 10
Training loss: 0.23556120693683624
Validation loss: 1.6971264193134923

Epoch: 373| Step: 0
Training loss: 0.2108314484357834
Validation loss: 1.6764270297942623

Epoch: 5| Step: 1
Training loss: 0.22945287823677063
Validation loss: 1.6594598780396164

Epoch: 5| Step: 2
Training loss: 0.21327081322669983
Validation loss: 1.6442801977998467

Epoch: 5| Step: 3
Training loss: 0.16461405158042908
Validation loss: 1.6322676135647682

Epoch: 5| Step: 4
Training loss: 0.1637258231639862
Validation loss: 1.6101819302446099

Epoch: 5| Step: 5
Training loss: 0.20516221225261688
Validation loss: 1.611128540449245

Epoch: 5| Step: 6
Training loss: 0.12585626542568207
Validation loss: 1.5952037611315328

Epoch: 5| Step: 7
Training loss: 0.1330908238887787
Validation loss: 1.5741641931636359

Epoch: 5| Step: 8
Training loss: 0.23393383622169495
Validation loss: 1.5984250691629225

Epoch: 5| Step: 9
Training loss: 0.18940146267414093
Validation loss: 1.5676177445278372

Epoch: 5| Step: 10
Training loss: 0.14124563336372375
Validation loss: 1.5809429345592376

Epoch: 374| Step: 0
Training loss: 0.25747618079185486
Validation loss: 1.5824613289166523

Epoch: 5| Step: 1
Training loss: 0.20348095893859863
Validation loss: 1.5785238601828133

Epoch: 5| Step: 2
Training loss: 0.14242739975452423
Validation loss: 1.5840903943584812

Epoch: 5| Step: 3
Training loss: 0.1923358142375946
Validation loss: 1.6390596371825024

Epoch: 5| Step: 4
Training loss: 0.17342901229858398
Validation loss: 1.5843748149051462

Epoch: 5| Step: 5
Training loss: 0.13966521620750427
Validation loss: 1.6168249473776868

Epoch: 5| Step: 6
Training loss: 0.14016368985176086
Validation loss: 1.5920983206841253

Epoch: 5| Step: 7
Training loss: 0.25682729482650757
Validation loss: 1.6311206022898357

Epoch: 5| Step: 8
Training loss: 0.18390406668186188
Validation loss: 1.621899297160487

Epoch: 5| Step: 9
Training loss: 0.21543538570404053
Validation loss: 1.5777833436125068

Epoch: 5| Step: 10
Training loss: 0.2771778106689453
Validation loss: 1.5810654214633408

Epoch: 375| Step: 0
Training loss: 0.20961005985736847
Validation loss: 1.560014569631187

Epoch: 5| Step: 1
Training loss: 0.165511816740036
Validation loss: 1.5619604100463211

Epoch: 5| Step: 2
Training loss: 0.2206985056400299
Validation loss: 1.5729287683322866

Epoch: 5| Step: 3
Training loss: 0.09587247669696808
Validation loss: 1.5693169896320631

Epoch: 5| Step: 4
Training loss: 0.2961774468421936
Validation loss: 1.5856391768301688

Epoch: 5| Step: 5
Training loss: 0.11118324100971222
Validation loss: 1.5805595305658156

Epoch: 5| Step: 6
Training loss: 0.22249798476696014
Validation loss: 1.5432422648194015

Epoch: 5| Step: 7
Training loss: 0.22879281640052795
Validation loss: 1.572383637069374

Epoch: 5| Step: 8
Training loss: 0.1827242076396942
Validation loss: 1.5720235006783598

Epoch: 5| Step: 9
Training loss: 0.22300636768341064
Validation loss: 1.5910598975355907

Epoch: 5| Step: 10
Training loss: 0.2965202033519745
Validation loss: 1.6038217211282382

Epoch: 376| Step: 0
Training loss: 0.1963883936405182
Validation loss: 1.5814976640926894

Epoch: 5| Step: 1
Training loss: 0.27564603090286255
Validation loss: 1.5677018947498773

Epoch: 5| Step: 2
Training loss: 0.15095174312591553
Validation loss: 1.5810412091593589

Epoch: 5| Step: 3
Training loss: 0.14575448632240295
Validation loss: 1.5692674242040163

Epoch: 5| Step: 4
Training loss: 0.17969870567321777
Validation loss: 1.5444377801751579

Epoch: 5| Step: 5
Training loss: 0.26275160908699036
Validation loss: 1.5497804610959944

Epoch: 5| Step: 6
Training loss: 0.303022563457489
Validation loss: 1.6193787231240222

Epoch: 5| Step: 7
Training loss: 0.2028009444475174
Validation loss: 1.6138973723175705

Epoch: 5| Step: 8
Training loss: 0.2001754492521286
Validation loss: 1.6136757737846785

Epoch: 5| Step: 9
Training loss: 0.33201906085014343
Validation loss: 1.649158077855264

Epoch: 5| Step: 10
Training loss: 0.1642993539571762
Validation loss: 1.659439174077844

Epoch: 377| Step: 0
Training loss: 0.20519733428955078
Validation loss: 1.6704470867751746

Epoch: 5| Step: 1
Training loss: 0.2648613750934601
Validation loss: 1.6805204678607244

Epoch: 5| Step: 2
Training loss: 0.24515405297279358
Validation loss: 1.6617093560516194

Epoch: 5| Step: 3
Training loss: 0.28176435828208923
Validation loss: 1.6408508791718432

Epoch: 5| Step: 4
Training loss: 0.18574866652488708
Validation loss: 1.5974796587421047

Epoch: 5| Step: 5
Training loss: 0.1701536774635315
Validation loss: 1.5958095276227562

Epoch: 5| Step: 6
Training loss: 0.09406322240829468
Validation loss: 1.5926713610208163

Epoch: 5| Step: 7
Training loss: 0.2768824100494385
Validation loss: 1.5658720283098118

Epoch: 5| Step: 8
Training loss: 0.2050371617078781
Validation loss: 1.5537628127682594

Epoch: 5| Step: 9
Training loss: 0.20612366497516632
Validation loss: 1.5758387016993698

Epoch: 5| Step: 10
Training loss: 0.23973499238491058
Validation loss: 1.6203423264206096

Epoch: 378| Step: 0
Training loss: 0.17025457322597504
Validation loss: 1.626773356109537

Epoch: 5| Step: 1
Training loss: 0.20466947555541992
Validation loss: 1.6472260605904363

Epoch: 5| Step: 2
Training loss: 0.19436463713645935
Validation loss: 1.641533987496489

Epoch: 5| Step: 3
Training loss: 0.25209468603134155
Validation loss: 1.7254615381199827

Epoch: 5| Step: 4
Training loss: 0.18954002857208252
Validation loss: 1.6713287625261533

Epoch: 5| Step: 5
Training loss: 0.14861202239990234
Validation loss: 1.64501908774017

Epoch: 5| Step: 6
Training loss: 0.15837767720222473
Validation loss: 1.6538880191823488

Epoch: 5| Step: 7
Training loss: 0.2778237462043762
Validation loss: 1.620809575562836

Epoch: 5| Step: 8
Training loss: 0.10085861384868622
Validation loss: 1.57802765856507

Epoch: 5| Step: 9
Training loss: 0.24816055595874786
Validation loss: 1.574018927030666

Epoch: 5| Step: 10
Training loss: 0.1731603741645813
Validation loss: 1.5814056511848205

Epoch: 379| Step: 0
Training loss: 0.180334210395813
Validation loss: 1.6122113273989769

Epoch: 5| Step: 1
Training loss: 0.2637586295604706
Validation loss: 1.6042799462554276

Epoch: 5| Step: 2
Training loss: 0.093990758061409
Validation loss: 1.6134210965966667

Epoch: 5| Step: 3
Training loss: 0.19782425463199615
Validation loss: 1.618094132792565

Epoch: 5| Step: 4
Training loss: 0.21271741390228271
Validation loss: 1.6291040579477947

Epoch: 5| Step: 5
Training loss: 0.16738708317279816
Validation loss: 1.6081117712041384

Epoch: 5| Step: 6
Training loss: 0.22894223034381866
Validation loss: 1.597501500319409

Epoch: 5| Step: 7
Training loss: 0.1587553471326828
Validation loss: 1.606098742895229

Epoch: 5| Step: 8
Training loss: 0.10551352798938751
Validation loss: 1.6215609401784918

Epoch: 5| Step: 9
Training loss: 0.10846762359142303
Validation loss: 1.6104673493293025

Epoch: 5| Step: 10
Training loss: 0.3469853103160858
Validation loss: 1.6289225457816996

Epoch: 380| Step: 0
Training loss: 0.1835973858833313
Validation loss: 1.6578247226694578

Epoch: 5| Step: 1
Training loss: 0.17216652631759644
Validation loss: 1.6523610507288287

Epoch: 5| Step: 2
Training loss: 0.18632249534130096
Validation loss: 1.6328813440056258

Epoch: 5| Step: 3
Training loss: 0.16672348976135254
Validation loss: 1.6117360079160301

Epoch: 5| Step: 4
Training loss: 0.23832306265830994
Validation loss: 1.6033358086821854

Epoch: 5| Step: 5
Training loss: 0.2026858776807785
Validation loss: 1.6278533999637892

Epoch: 5| Step: 6
Training loss: 0.0760195404291153
Validation loss: 1.6418510893339753

Epoch: 5| Step: 7
Training loss: 0.1897447556257248
Validation loss: 1.620652356455403

Epoch: 5| Step: 8
Training loss: 0.2792600691318512
Validation loss: 1.609947367381024

Epoch: 5| Step: 9
Training loss: 0.17522819340229034
Validation loss: 1.6057422238011514

Epoch: 5| Step: 10
Training loss: 0.19573017954826355
Validation loss: 1.59724639051704

Epoch: 381| Step: 0
Training loss: 0.24271810054779053
Validation loss: 1.5923487742741902

Epoch: 5| Step: 1
Training loss: 0.19970156252384186
Validation loss: 1.6059074081400389

Epoch: 5| Step: 2
Training loss: 0.14704690873622894
Validation loss: 1.6380217523985012

Epoch: 5| Step: 3
Training loss: 0.14455869793891907
Validation loss: 1.6486154346055881

Epoch: 5| Step: 4
Training loss: 0.20303404331207275
Validation loss: 1.6792654529694588

Epoch: 5| Step: 5
Training loss: 0.1833292692899704
Validation loss: 1.6591245294899069

Epoch: 5| Step: 6
Training loss: 0.1114533394575119
Validation loss: 1.6732913191600511

Epoch: 5| Step: 7
Training loss: 0.2560090124607086
Validation loss: 1.6617624195673133

Epoch: 5| Step: 8
Training loss: 0.13510222733020782
Validation loss: 1.6592863862232496

Epoch: 5| Step: 9
Training loss: 0.31686657667160034
Validation loss: 1.6583309711948517

Epoch: 5| Step: 10
Training loss: 0.41391393542289734
Validation loss: 1.6420649597721715

Epoch: 382| Step: 0
Training loss: 0.22406749427318573
Validation loss: 1.5955438601073397

Epoch: 5| Step: 1
Training loss: 0.15120288729667664
Validation loss: 1.580450798875542

Epoch: 5| Step: 2
Training loss: 0.25121942162513733
Validation loss: 1.5858320074696695

Epoch: 5| Step: 3
Training loss: 0.1820400357246399
Validation loss: 1.5805673086515037

Epoch: 5| Step: 4
Training loss: 0.1599658727645874
Validation loss: 1.5540483805441088

Epoch: 5| Step: 5
Training loss: 0.17819030582904816
Validation loss: 1.5701675184311406

Epoch: 5| Step: 6
Training loss: 0.14122629165649414
Validation loss: 1.6105021789509764

Epoch: 5| Step: 7
Training loss: 0.3069845736026764
Validation loss: 1.6205260522903935

Epoch: 5| Step: 8
Training loss: 0.07159104198217392
Validation loss: 1.6447380127445344

Epoch: 5| Step: 9
Training loss: 0.22351042926311493
Validation loss: 1.6728777808527793

Epoch: 5| Step: 10
Training loss: 0.24697789549827576
Validation loss: 1.70262731916161

Epoch: 383| Step: 0
Training loss: 0.20028086006641388
Validation loss: 1.6565848935034968

Epoch: 5| Step: 1
Training loss: 0.26685014367103577
Validation loss: 1.6630409558614094

Epoch: 5| Step: 2
Training loss: 0.1309109628200531
Validation loss: 1.6453808565293588

Epoch: 5| Step: 3
Training loss: 0.18852630257606506
Validation loss: 1.597656770419049

Epoch: 5| Step: 4
Training loss: 0.14755554497241974
Validation loss: 1.5883517585774904

Epoch: 5| Step: 5
Training loss: 0.0851304680109024
Validation loss: 1.5741060074939524

Epoch: 5| Step: 6
Training loss: 0.2708515524864197
Validation loss: 1.5606379367971932

Epoch: 5| Step: 7
Training loss: 0.23795971274375916
Validation loss: 1.528019364162158

Epoch: 5| Step: 8
Training loss: 0.15154343843460083
Validation loss: 1.5274408363526868

Epoch: 5| Step: 9
Training loss: 0.2344062328338623
Validation loss: 1.5337610020432422

Epoch: 5| Step: 10
Training loss: 0.177476704120636
Validation loss: 1.5356843689436555

Epoch: 384| Step: 0
Training loss: 0.15198442339897156
Validation loss: 1.5943584929230392

Epoch: 5| Step: 1
Training loss: 0.16443124413490295
Validation loss: 1.6036419073740642

Epoch: 5| Step: 2
Training loss: 0.21166619658470154
Validation loss: 1.6169943207053727

Epoch: 5| Step: 3
Training loss: 0.24316981434822083
Validation loss: 1.6393761904008928

Epoch: 5| Step: 4
Training loss: 0.07229242473840714
Validation loss: 1.619643493365216

Epoch: 5| Step: 5
Training loss: 0.12738636136054993
Validation loss: 1.630542512862913

Epoch: 5| Step: 6
Training loss: 0.1855502426624298
Validation loss: 1.6662350880202426

Epoch: 5| Step: 7
Training loss: 0.3154696822166443
Validation loss: 1.632892180514592

Epoch: 5| Step: 8
Training loss: 0.2453504502773285
Validation loss: 1.6759934156171736

Epoch: 5| Step: 9
Training loss: 0.16775497794151306
Validation loss: 1.6385382606137184

Epoch: 5| Step: 10
Training loss: 0.22572964429855347
Validation loss: 1.617238175484442

Epoch: 385| Step: 0
Training loss: 0.22011911869049072
Validation loss: 1.5836715198332263

Epoch: 5| Step: 1
Training loss: 0.22011414170265198
Validation loss: 1.5550253404084073

Epoch: 5| Step: 2
Training loss: 0.18907853960990906
Validation loss: 1.585789870190364

Epoch: 5| Step: 3
Training loss: 0.20354656875133514
Validation loss: 1.5205719522250596

Epoch: 5| Step: 4
Training loss: 0.20039264857769012
Validation loss: 1.5520556690872356

Epoch: 5| Step: 5
Training loss: 0.19068941473960876
Validation loss: 1.5670722979371265

Epoch: 5| Step: 6
Training loss: 0.19395065307617188
Validation loss: 1.5505320256756199

Epoch: 5| Step: 7
Training loss: 0.24047136306762695
Validation loss: 1.575336794699392

Epoch: 5| Step: 8
Training loss: 0.2071552574634552
Validation loss: 1.5477793191068916

Epoch: 5| Step: 9
Training loss: 0.19176751375198364
Validation loss: 1.5218638707232732

Epoch: 5| Step: 10
Training loss: 0.10298095643520355
Validation loss: 1.519609696121626

Epoch: 386| Step: 0
Training loss: 0.14813736081123352
Validation loss: 1.5083168065676125

Epoch: 5| Step: 1
Training loss: 0.17551705241203308
Validation loss: 1.5296425152850408

Epoch: 5| Step: 2
Training loss: 0.2432081699371338
Validation loss: 1.5797786123009139

Epoch: 5| Step: 3
Training loss: 0.20117267966270447
Validation loss: 1.6030487193856189

Epoch: 5| Step: 4
Training loss: 0.15926730632781982
Validation loss: 1.5931756073428738

Epoch: 5| Step: 5
Training loss: 0.12232010066509247
Validation loss: 1.6093048190557828

Epoch: 5| Step: 6
Training loss: 0.23960673809051514
Validation loss: 1.5898994181745796

Epoch: 5| Step: 7
Training loss: 0.2000257521867752
Validation loss: 1.594119293715364

Epoch: 5| Step: 8
Training loss: 0.18173637986183167
Validation loss: 1.5894834661996493

Epoch: 5| Step: 9
Training loss: 0.13322332501411438
Validation loss: 1.5662289524591098

Epoch: 5| Step: 10
Training loss: 0.13337914645671844
Validation loss: 1.57417510145454

Epoch: 387| Step: 0
Training loss: 0.18443091213703156
Validation loss: 1.5566999514897664

Epoch: 5| Step: 1
Training loss: 0.172154039144516
Validation loss: 1.5555165115223135

Epoch: 5| Step: 2
Training loss: 0.16458632051944733
Validation loss: 1.5407589789359801

Epoch: 5| Step: 3
Training loss: 0.16145506501197815
Validation loss: 1.5393316950849307

Epoch: 5| Step: 4
Training loss: 0.17354580760002136
Validation loss: 1.563608016378136

Epoch: 5| Step: 5
Training loss: 0.2635822892189026
Validation loss: 1.5648188796094669

Epoch: 5| Step: 6
Training loss: 0.191060870885849
Validation loss: 1.5590429690576368

Epoch: 5| Step: 7
Training loss: 0.1678413450717926
Validation loss: 1.5910582542419434

Epoch: 5| Step: 8
Training loss: 0.14712920784950256
Validation loss: 1.5926006827303159

Epoch: 5| Step: 9
Training loss: 0.182557612657547
Validation loss: 1.6128610218724897

Epoch: 5| Step: 10
Training loss: 0.09430306404829025
Validation loss: 1.6355892624906314

Epoch: 388| Step: 0
Training loss: 0.10855977237224579
Validation loss: 1.6616000052421325

Epoch: 5| Step: 1
Training loss: 0.1278577297925949
Validation loss: 1.6793537280892814

Epoch: 5| Step: 2
Training loss: 0.15199097990989685
Validation loss: 1.6683353108744468

Epoch: 5| Step: 3
Training loss: 0.12156319618225098
Validation loss: 1.6908060619907994

Epoch: 5| Step: 4
Training loss: 0.29001516103744507
Validation loss: 1.6744435038617862

Epoch: 5| Step: 5
Training loss: 0.11054831743240356
Validation loss: 1.6728743212197417

Epoch: 5| Step: 6
Training loss: 0.14215850830078125
Validation loss: 1.637746613512757

Epoch: 5| Step: 7
Training loss: 0.196471706032753
Validation loss: 1.604076575207454

Epoch: 5| Step: 8
Training loss: 0.13779103755950928
Validation loss: 1.5781502480147986

Epoch: 5| Step: 9
Training loss: 0.16894294321537018
Validation loss: 1.5898335044102003

Epoch: 5| Step: 10
Training loss: 0.1625259965658188
Validation loss: 1.5722185283578851

Epoch: 389| Step: 0
Training loss: 0.21079614758491516
Validation loss: 1.5682398734554168

Epoch: 5| Step: 1
Training loss: 0.21713416278362274
Validation loss: 1.5782071121277348

Epoch: 5| Step: 2
Training loss: 0.19298055768013
Validation loss: 1.55587125080888

Epoch: 5| Step: 3
Training loss: 0.09462843835353851
Validation loss: 1.549618419780526

Epoch: 5| Step: 4
Training loss: 0.1518089473247528
Validation loss: 1.579286116425709

Epoch: 5| Step: 5
Training loss: 0.12221208959817886
Validation loss: 1.5917693761087233

Epoch: 5| Step: 6
Training loss: 0.2209935486316681
Validation loss: 1.6220021504227833

Epoch: 5| Step: 7
Training loss: 0.2048044502735138
Validation loss: 1.6124779165432017

Epoch: 5| Step: 8
Training loss: 0.1223992109298706
Validation loss: 1.6234763053155714

Epoch: 5| Step: 9
Training loss: 0.1992620974779129
Validation loss: 1.6145460144166024

Epoch: 5| Step: 10
Training loss: 0.13190138339996338
Validation loss: 1.6243910751035135

Epoch: 390| Step: 0
Training loss: 0.2770382761955261
Validation loss: 1.5887580148635372

Epoch: 5| Step: 1
Training loss: 0.14727865159511566
Validation loss: 1.6055093067948536

Epoch: 5| Step: 2
Training loss: 0.12858586013317108
Validation loss: 1.5777947466860536

Epoch: 5| Step: 3
Training loss: 0.14727163314819336
Validation loss: 1.5439509127729683

Epoch: 5| Step: 4
Training loss: 0.15772219002246857
Validation loss: 1.5446559145886412

Epoch: 5| Step: 5
Training loss: 0.1035798192024231
Validation loss: 1.5605343016245032

Epoch: 5| Step: 6
Training loss: 0.19122228026390076
Validation loss: 1.5281957554560837

Epoch: 5| Step: 7
Training loss: 0.1366395652294159
Validation loss: 1.5510630094876854

Epoch: 5| Step: 8
Training loss: 0.1259283423423767
Validation loss: 1.5767891342921923

Epoch: 5| Step: 9
Training loss: 0.09980269521474838
Validation loss: 1.5581212287308068

Epoch: 5| Step: 10
Training loss: 0.1339852660894394
Validation loss: 1.561388886103066

Epoch: 391| Step: 0
Training loss: 0.14378730952739716
Validation loss: 1.5764362671042

Epoch: 5| Step: 1
Training loss: 0.09449073672294617
Validation loss: 1.596301007014449

Epoch: 5| Step: 2
Training loss: 0.14896559715270996
Validation loss: 1.5929718068850938

Epoch: 5| Step: 3
Training loss: 0.09726197272539139
Validation loss: 1.5769041545929448

Epoch: 5| Step: 4
Training loss: 0.12298712879419327
Validation loss: 1.5911547413436316

Epoch: 5| Step: 5
Training loss: 0.16513203084468842
Validation loss: 1.56906371988276

Epoch: 5| Step: 6
Training loss: 0.13050538301467896
Validation loss: 1.5696424233016146

Epoch: 5| Step: 7
Training loss: 0.10692165791988373
Validation loss: 1.5671607191844652

Epoch: 5| Step: 8
Training loss: 0.20587503910064697
Validation loss: 1.5606682710750128

Epoch: 5| Step: 9
Training loss: 0.17140834033489227
Validation loss: 1.5432932171770322

Epoch: 5| Step: 10
Training loss: 0.2979801297187805
Validation loss: 1.5237921745546403

Epoch: 392| Step: 0
Training loss: 0.19517435133457184
Validation loss: 1.5417082213586377

Epoch: 5| Step: 1
Training loss: 0.20371922850608826
Validation loss: 1.53790444584303

Epoch: 5| Step: 2
Training loss: 0.14328444004058838
Validation loss: 1.5481745748109714

Epoch: 5| Step: 3
Training loss: 0.201090008020401
Validation loss: 1.5429627844082412

Epoch: 5| Step: 4
Training loss: 0.12517139315605164
Validation loss: 1.5520960900091356

Epoch: 5| Step: 5
Training loss: 0.12723715603351593
Validation loss: 1.5965183550311672

Epoch: 5| Step: 6
Training loss: 0.16550621390342712
Validation loss: 1.6259493891910841

Epoch: 5| Step: 7
Training loss: 0.15237462520599365
Validation loss: 1.5766887600703905

Epoch: 5| Step: 8
Training loss: 0.22735491394996643
Validation loss: 1.6489499230538645

Epoch: 5| Step: 9
Training loss: 0.14568695425987244
Validation loss: 1.642706844114488

Epoch: 5| Step: 10
Training loss: 0.14415156841278076
Validation loss: 1.6559892367291194

Epoch: 393| Step: 0
Training loss: 0.1359994262456894
Validation loss: 1.6292804056598293

Epoch: 5| Step: 1
Training loss: 0.19711966812610626
Validation loss: 1.592753764121763

Epoch: 5| Step: 2
Training loss: 0.13749292492866516
Validation loss: 1.559664318638463

Epoch: 5| Step: 3
Training loss: 0.14561860263347626
Validation loss: 1.5481454037850904

Epoch: 5| Step: 4
Training loss: 0.23990769684314728
Validation loss: 1.533830765754946

Epoch: 5| Step: 5
Training loss: 0.2752697169780731
Validation loss: 1.5335969707017303

Epoch: 5| Step: 6
Training loss: 0.10569538921117783
Validation loss: 1.525664488474528

Epoch: 5| Step: 7
Training loss: 0.17658153176307678
Validation loss: 1.5325293694773028

Epoch: 5| Step: 8
Training loss: 0.1312151700258255
Validation loss: 1.5567695427966375

Epoch: 5| Step: 9
Training loss: 0.1271839439868927
Validation loss: 1.5735403824877996

Epoch: 5| Step: 10
Training loss: 0.1554778814315796
Validation loss: 1.5677640848262335

Epoch: 394| Step: 0
Training loss: 0.15515545010566711
Validation loss: 1.5871551100925734

Epoch: 5| Step: 1
Training loss: 0.18165503442287445
Validation loss: 1.6103683517825218

Epoch: 5| Step: 2
Training loss: 0.24292314052581787
Validation loss: 1.6297155375121741

Epoch: 5| Step: 3
Training loss: 0.20944161713123322
Validation loss: 1.6294622651992305

Epoch: 5| Step: 4
Training loss: 0.14910201728343964
Validation loss: 1.5955352270474998

Epoch: 5| Step: 5
Training loss: 0.11660107225179672
Validation loss: 1.5813177298474055

Epoch: 5| Step: 6
Training loss: 0.20016582310199738
Validation loss: 1.5577311336353261

Epoch: 5| Step: 7
Training loss: 0.14686837792396545
Validation loss: 1.5369808571313017

Epoch: 5| Step: 8
Training loss: 0.21838748455047607
Validation loss: 1.5478204604118102

Epoch: 5| Step: 9
Training loss: 0.19499434530735016
Validation loss: 1.5417875743681384

Epoch: 5| Step: 10
Training loss: 0.17750166356563568
Validation loss: 1.525329343734249

Epoch: 395| Step: 0
Training loss: 0.2104906588792801
Validation loss: 1.522622714760483

Epoch: 5| Step: 1
Training loss: 0.15242905914783478
Validation loss: 1.5279586020336355

Epoch: 5| Step: 2
Training loss: 0.19096124172210693
Validation loss: 1.5240957788241807

Epoch: 5| Step: 3
Training loss: 0.2215292900800705
Validation loss: 1.5716686479506954

Epoch: 5| Step: 4
Training loss: 0.14794592559337616
Validation loss: 1.5837884282553067

Epoch: 5| Step: 5
Training loss: 0.13056500256061554
Validation loss: 1.5620988235678723

Epoch: 5| Step: 6
Training loss: 0.14133942127227783
Validation loss: 1.55387879443425

Epoch: 5| Step: 7
Training loss: 0.1942930966615677
Validation loss: 1.5776172684084984

Epoch: 5| Step: 8
Training loss: 0.18329891562461853
Validation loss: 1.5712852554936563

Epoch: 5| Step: 9
Training loss: 0.1845420002937317
Validation loss: 1.5744475433903355

Epoch: 5| Step: 10
Training loss: 0.09863701462745667
Validation loss: 1.593557724388697

Epoch: 396| Step: 0
Training loss: 0.2245318442583084
Validation loss: 1.616959669256723

Epoch: 5| Step: 1
Training loss: 0.19173288345336914
Validation loss: 1.6100333057424074

Epoch: 5| Step: 2
Training loss: 0.2853901982307434
Validation loss: 1.5821772672796761

Epoch: 5| Step: 3
Training loss: 0.12579870223999023
Validation loss: 1.55196564684632

Epoch: 5| Step: 4
Training loss: 0.10411468893289566
Validation loss: 1.5486919546640048

Epoch: 5| Step: 5
Training loss: 0.13236647844314575
Validation loss: 1.5807669624205558

Epoch: 5| Step: 6
Training loss: 0.13263128697872162
Validation loss: 1.5925958092494676

Epoch: 5| Step: 7
Training loss: 0.10349683463573456
Validation loss: 1.594637361905908

Epoch: 5| Step: 8
Training loss: 0.10253699123859406
Validation loss: 1.6038332934020667

Epoch: 5| Step: 9
Training loss: 0.13850459456443787
Validation loss: 1.5975131193796794

Epoch: 5| Step: 10
Training loss: 0.13150958716869354
Validation loss: 1.603161512523569

Epoch: 397| Step: 0
Training loss: 0.12880951166152954
Validation loss: 1.59116276233427

Epoch: 5| Step: 1
Training loss: 0.22253385186195374
Validation loss: 1.570293890532627

Epoch: 5| Step: 2
Training loss: 0.18068543076515198
Validation loss: 1.5904868110533683

Epoch: 5| Step: 3
Training loss: 0.2293672114610672
Validation loss: 1.5799659311130483

Epoch: 5| Step: 4
Training loss: 0.1782904714345932
Validation loss: 1.582928958759513

Epoch: 5| Step: 5
Training loss: 0.164175882935524
Validation loss: 1.6070158943053214

Epoch: 5| Step: 6
Training loss: 0.09557849168777466
Validation loss: 1.628901445737449

Epoch: 5| Step: 7
Training loss: 0.1320241391658783
Validation loss: 1.6225312525226223

Epoch: 5| Step: 8
Training loss: 0.17771375179290771
Validation loss: 1.6413534456683743

Epoch: 5| Step: 9
Training loss: 0.13511481881141663
Validation loss: 1.67659842711623

Epoch: 5| Step: 10
Training loss: 0.13832756876945496
Validation loss: 1.6769096851348877

Epoch: 398| Step: 0
Training loss: 0.14849045872688293
Validation loss: 1.6543817532959806

Epoch: 5| Step: 1
Training loss: 0.1626821756362915
Validation loss: 1.6401351241655246

Epoch: 5| Step: 2
Training loss: 0.1286594271659851
Validation loss: 1.6053393553662043

Epoch: 5| Step: 3
Training loss: 0.1488172560930252
Validation loss: 1.5842885791614492

Epoch: 5| Step: 4
Training loss: 0.21562056243419647
Validation loss: 1.5742792775554042

Epoch: 5| Step: 5
Training loss: 0.16113968193531036
Validation loss: 1.5566874986053796

Epoch: 5| Step: 6
Training loss: 0.10771854221820831
Validation loss: 1.5663653445500199

Epoch: 5| Step: 7
Training loss: 0.162371426820755
Validation loss: 1.5556915575458157

Epoch: 5| Step: 8
Training loss: 0.16072505712509155
Validation loss: 1.5736962492747972

Epoch: 5| Step: 9
Training loss: 0.16256971657276154
Validation loss: 1.585576076661387

Epoch: 5| Step: 10
Training loss: 0.10927494615316391
Validation loss: 1.5517336245506042

Epoch: 399| Step: 0
Training loss: 0.15669122338294983
Validation loss: 1.571725490272686

Epoch: 5| Step: 1
Training loss: 0.1560184508562088
Validation loss: 1.5666110554049093

Epoch: 5| Step: 2
Training loss: 0.16301229596138
Validation loss: 1.5569163874913288

Epoch: 5| Step: 3
Training loss: 0.09374401718378067
Validation loss: 1.5609612016267673

Epoch: 5| Step: 4
Training loss: 0.14864419400691986
Validation loss: 1.581233093815465

Epoch: 5| Step: 5
Training loss: 0.14324845373630524
Validation loss: 1.5785160910698675

Epoch: 5| Step: 6
Training loss: 0.1779596507549286
Validation loss: 1.578708150053537

Epoch: 5| Step: 7
Training loss: 0.08682924509048462
Validation loss: 1.5891501339532996

Epoch: 5| Step: 8
Training loss: 0.17901763319969177
Validation loss: 1.6106572010183846

Epoch: 5| Step: 9
Training loss: 0.14049863815307617
Validation loss: 1.5827527789659397

Epoch: 5| Step: 10
Training loss: 0.16866371035575867
Validation loss: 1.5744002775479389

Epoch: 400| Step: 0
Training loss: 0.15160956978797913
Validation loss: 1.5664156624065932

Epoch: 5| Step: 1
Training loss: 0.11294522136449814
Validation loss: 1.5721354407648886

Epoch: 5| Step: 2
Training loss: 0.1476222574710846
Validation loss: 1.5496360249416803

Epoch: 5| Step: 3
Training loss: 0.13943466544151306
Validation loss: 1.5744487540696257

Epoch: 5| Step: 4
Training loss: 0.13791093230247498
Validation loss: 1.5742983715508574

Epoch: 5| Step: 5
Training loss: 0.17708201706409454
Validation loss: 1.5710310961610527

Epoch: 5| Step: 6
Training loss: 0.16803090274333954
Validation loss: 1.5802637082274242

Epoch: 5| Step: 7
Training loss: 0.11303982883691788
Validation loss: 1.5947733104869883

Epoch: 5| Step: 8
Training loss: 0.17622408270835876
Validation loss: 1.5740614603924494

Epoch: 5| Step: 9
Training loss: 0.16550284624099731
Validation loss: 1.5823718040220198

Epoch: 5| Step: 10
Training loss: 0.11394480615854263
Validation loss: 1.5930623380086755

Epoch: 401| Step: 0
Training loss: 0.18734589219093323
Validation loss: 1.5840538573521439

Epoch: 5| Step: 1
Training loss: 0.1178305596113205
Validation loss: 1.5805197954177856

Epoch: 5| Step: 2
Training loss: 0.12669925391674042
Validation loss: 1.5603775452542048

Epoch: 5| Step: 3
Training loss: 0.1517949402332306
Validation loss: 1.5593694666380524

Epoch: 5| Step: 4
Training loss: 0.17380915582180023
Validation loss: 1.5691823767077537

Epoch: 5| Step: 5
Training loss: 0.0903392881155014
Validation loss: 1.5495341375309934

Epoch: 5| Step: 6
Training loss: 0.2223573625087738
Validation loss: 1.563760051804204

Epoch: 5| Step: 7
Training loss: 0.12440095841884613
Validation loss: 1.566858595417392

Epoch: 5| Step: 8
Training loss: 0.1116294264793396
Validation loss: 1.5864280974993141

Epoch: 5| Step: 9
Training loss: 0.30488961935043335
Validation loss: 1.599596578587768

Epoch: 5| Step: 10
Training loss: 0.20992650091648102
Validation loss: 1.5885410719020392

Epoch: 402| Step: 0
Training loss: 0.16685721278190613
Validation loss: 1.6124507509252077

Epoch: 5| Step: 1
Training loss: 0.15719065070152283
Validation loss: 1.6023955165698964

Epoch: 5| Step: 2
Training loss: 0.21899819374084473
Validation loss: 1.59518164332195

Epoch: 5| Step: 3
Training loss: 0.16104856133460999
Validation loss: 1.6166953553435623

Epoch: 5| Step: 4
Training loss: 0.131938174366951
Validation loss: 1.6113565121927569

Epoch: 5| Step: 5
Training loss: 0.2053181678056717
Validation loss: 1.6203885770613147

Epoch: 5| Step: 6
Training loss: 0.12102379649877548
Validation loss: 1.6452871804596276

Epoch: 5| Step: 7
Training loss: 0.1337670385837555
Validation loss: 1.5949365579953758

Epoch: 5| Step: 8
Training loss: 0.16689953207969666
Validation loss: 1.596306647023847

Epoch: 5| Step: 9
Training loss: 0.11853210628032684
Validation loss: 1.5940269295887282

Epoch: 5| Step: 10
Training loss: 0.18165932595729828
Validation loss: 1.5816724223475302

Epoch: 403| Step: 0
Training loss: 0.19366589188575745
Validation loss: 1.5826637655176141

Epoch: 5| Step: 1
Training loss: 0.08042055368423462
Validation loss: 1.5581097256752752

Epoch: 5| Step: 2
Training loss: 0.154922217130661
Validation loss: 1.5851343985526793

Epoch: 5| Step: 3
Training loss: 0.1567765772342682
Validation loss: 1.5724580826297883

Epoch: 5| Step: 4
Training loss: 0.13489748537540436
Validation loss: 1.5855816025887766

Epoch: 5| Step: 5
Training loss: 0.12367043644189835
Validation loss: 1.5662494513296312

Epoch: 5| Step: 6
Training loss: 0.10902391374111176
Validation loss: 1.589131598831505

Epoch: 5| Step: 7
Training loss: 0.11026470363140106
Validation loss: 1.5631289751298967

Epoch: 5| Step: 8
Training loss: 0.13970348238945007
Validation loss: 1.5946051036157916

Epoch: 5| Step: 9
Training loss: 0.17003433406352997
Validation loss: 1.5727149158395746

Epoch: 5| Step: 10
Training loss: 0.15970303118228912
Validation loss: 1.5767447563909716

Epoch: 404| Step: 0
Training loss: 0.10352694988250732
Validation loss: 1.574684590421697

Epoch: 5| Step: 1
Training loss: 0.12126803398132324
Validation loss: 1.5540014441295336

Epoch: 5| Step: 2
Training loss: 0.1625024974346161
Validation loss: 1.5587917156116937

Epoch: 5| Step: 3
Training loss: 0.19408681988716125
Validation loss: 1.5440416259150351

Epoch: 5| Step: 4
Training loss: 0.20143790543079376
Validation loss: 1.55760786866629

Epoch: 5| Step: 5
Training loss: 0.1817779839038849
Validation loss: 1.5508486981032996

Epoch: 5| Step: 6
Training loss: 0.1306842863559723
Validation loss: 1.535079098516895

Epoch: 5| Step: 7
Training loss: 0.1380724012851715
Validation loss: 1.5401165921200988

Epoch: 5| Step: 8
Training loss: 0.0830717533826828
Validation loss: 1.5607787075863089

Epoch: 5| Step: 9
Training loss: 0.1637830287218094
Validation loss: 1.5728159591715822

Epoch: 5| Step: 10
Training loss: 0.19762840867042542
Validation loss: 1.5922774294371247

Epoch: 405| Step: 0
Training loss: 0.09684380143880844
Validation loss: 1.6102987835484166

Epoch: 5| Step: 1
Training loss: 0.13158968091011047
Validation loss: 1.6481748703987367

Epoch: 5| Step: 2
Training loss: 0.17916572093963623
Validation loss: 1.6513836287683057

Epoch: 5| Step: 3
Training loss: 0.21073968708515167
Validation loss: 1.6283060876272057

Epoch: 5| Step: 4
Training loss: 0.20661287009716034
Validation loss: 1.6131616433461506

Epoch: 5| Step: 5
Training loss: 0.13775359094142914
Validation loss: 1.6017911972538117

Epoch: 5| Step: 6
Training loss: 0.1637038141489029
Validation loss: 1.5749650418117482

Epoch: 5| Step: 7
Training loss: 0.11526737362146378
Validation loss: 1.5441585971463112

Epoch: 5| Step: 8
Training loss: 0.22137203812599182
Validation loss: 1.5657006232969222

Epoch: 5| Step: 9
Training loss: 0.11943157017230988
Validation loss: 1.5521287841181601

Epoch: 5| Step: 10
Training loss: 0.18341469764709473
Validation loss: 1.5646731930394326

Epoch: 406| Step: 0
Training loss: 0.18620212376117706
Validation loss: 1.591020748179446

Epoch: 5| Step: 1
Training loss: 0.11128946393728256
Validation loss: 1.5850471001799389

Epoch: 5| Step: 2
Training loss: 0.21038571000099182
Validation loss: 1.6143604299073577

Epoch: 5| Step: 3
Training loss: 0.23480252921581268
Validation loss: 1.5988034791843866

Epoch: 5| Step: 4
Training loss: 0.10076765716075897
Validation loss: 1.5953848823424308

Epoch: 5| Step: 5
Training loss: 0.16749849915504456
Validation loss: 1.5677044814632786

Epoch: 5| Step: 6
Training loss: 0.17924492061138153
Validation loss: 1.5903041567853702

Epoch: 5| Step: 7
Training loss: 0.10944731533527374
Validation loss: 1.5796476769190964

Epoch: 5| Step: 8
Training loss: 0.12887147068977356
Validation loss: 1.5416376065182429

Epoch: 5| Step: 9
Training loss: 0.12861470878124237
Validation loss: 1.5604088242335985

Epoch: 5| Step: 10
Training loss: 0.1323048174381256
Validation loss: 1.6024512424263904

Epoch: 407| Step: 0
Training loss: 0.17696157097816467
Validation loss: 1.6105735609608312

Epoch: 5| Step: 1
Training loss: 0.13469341397285461
Validation loss: 1.5926202843266148

Epoch: 5| Step: 2
Training loss: 0.17356416583061218
Validation loss: 1.606276983855873

Epoch: 5| Step: 3
Training loss: 0.1250757873058319
Validation loss: 1.6179111619149484

Epoch: 5| Step: 4
Training loss: 0.14333125948905945
Validation loss: 1.6182172567613664

Epoch: 5| Step: 5
Training loss: 0.1286657601594925
Validation loss: 1.600367836413845

Epoch: 5| Step: 6
Training loss: 0.10895152390003204
Validation loss: 1.5896867270110755

Epoch: 5| Step: 7
Training loss: 0.17482051253318787
Validation loss: 1.5877678291772002

Epoch: 5| Step: 8
Training loss: 0.11726373434066772
Validation loss: 1.577774167060852

Epoch: 5| Step: 9
Training loss: 0.1026073694229126
Validation loss: 1.5826463635249803

Epoch: 5| Step: 10
Training loss: 0.12144383043050766
Validation loss: 1.583628184051924

Epoch: 408| Step: 0
Training loss: 0.10272800922393799
Validation loss: 1.591404225236626

Epoch: 5| Step: 1
Training loss: 0.17957910895347595
Validation loss: 1.5843391751730314

Epoch: 5| Step: 2
Training loss: 0.10475587844848633
Validation loss: 1.6145163556580902

Epoch: 5| Step: 3
Training loss: 0.121035635471344
Validation loss: 1.6072908697589752

Epoch: 5| Step: 4
Training loss: 0.12120997905731201
Validation loss: 1.5757290970894597

Epoch: 5| Step: 5
Training loss: 0.15620368719100952
Validation loss: 1.612999951967629

Epoch: 5| Step: 6
Training loss: 0.16226477921009064
Validation loss: 1.610529911133551

Epoch: 5| Step: 7
Training loss: 0.20672324299812317
Validation loss: 1.5916617211475168

Epoch: 5| Step: 8
Training loss: 0.08793485164642334
Validation loss: 1.6155695594767088

Epoch: 5| Step: 9
Training loss: 0.1258707493543625
Validation loss: 1.5833709662960422

Epoch: 5| Step: 10
Training loss: 0.1442956179380417
Validation loss: 1.6274470001138666

Epoch: 409| Step: 0
Training loss: 0.16531173884868622
Validation loss: 1.5948339072606896

Epoch: 5| Step: 1
Training loss: 0.12051073461771011
Validation loss: 1.6078758855019846

Epoch: 5| Step: 2
Training loss: 0.20918652415275574
Validation loss: 1.6115974803124704

Epoch: 5| Step: 3
Training loss: 0.15578222274780273
Validation loss: 1.606999970251514

Epoch: 5| Step: 4
Training loss: 0.20943406224250793
Validation loss: 1.579542076715859

Epoch: 5| Step: 5
Training loss: 0.09795387834310532
Validation loss: 1.5986917762346164

Epoch: 5| Step: 6
Training loss: 0.08380110561847687
Validation loss: 1.5886568734722752

Epoch: 5| Step: 7
Training loss: 0.11478149890899658
Validation loss: 1.6267166317150157

Epoch: 5| Step: 8
Training loss: 0.16941078007221222
Validation loss: 1.5926718314488728

Epoch: 5| Step: 9
Training loss: 0.134379580616951
Validation loss: 1.6241993647749706

Epoch: 5| Step: 10
Training loss: 0.15300430357456207
Validation loss: 1.6195847283127487

Epoch: 410| Step: 0
Training loss: 0.22986240684986115
Validation loss: 1.6338752187708372

Epoch: 5| Step: 1
Training loss: 0.14046594500541687
Validation loss: 1.6267240098727647

Epoch: 5| Step: 2
Training loss: 0.20159442722797394
Validation loss: 1.6054797454546856

Epoch: 5| Step: 3
Training loss: 0.11599260568618774
Validation loss: 1.5608761252895478

Epoch: 5| Step: 4
Training loss: 0.12304961681365967
Validation loss: 1.5582034408405263

Epoch: 5| Step: 5
Training loss: 0.18171919882297516
Validation loss: 1.5564261418516918

Epoch: 5| Step: 6
Training loss: 0.16832929849624634
Validation loss: 1.5475309587294055

Epoch: 5| Step: 7
Training loss: 0.12109081447124481
Validation loss: 1.5519795110148769

Epoch: 5| Step: 8
Training loss: 0.20956480503082275
Validation loss: 1.5772385558774393

Epoch: 5| Step: 9
Training loss: 0.14458535611629486
Validation loss: 1.5474153116185179

Epoch: 5| Step: 10
Training loss: 0.17237845063209534
Validation loss: 1.5345918593868133

Epoch: 411| Step: 0
Training loss: 0.20449844002723694
Validation loss: 1.5353657084126626

Epoch: 5| Step: 1
Training loss: 0.083463154733181
Validation loss: 1.5480852473166682

Epoch: 5| Step: 2
Training loss: 0.15092207491397858
Validation loss: 1.5571882564534423

Epoch: 5| Step: 3
Training loss: 0.14630554616451263
Validation loss: 1.5677750918173021

Epoch: 5| Step: 4
Training loss: 0.17151829600334167
Validation loss: 1.5357048408959502

Epoch: 5| Step: 5
Training loss: 0.11796003580093384
Validation loss: 1.5381550237696657

Epoch: 5| Step: 6
Training loss: 0.17193491756916046
Validation loss: 1.5881077551072644

Epoch: 5| Step: 7
Training loss: 0.11049063503742218
Validation loss: 1.5711638401913386

Epoch: 5| Step: 8
Training loss: 0.16415245831012726
Validation loss: 1.5742907049835368

Epoch: 5| Step: 9
Training loss: 0.11611167341470718
Validation loss: 1.5566949972542383

Epoch: 5| Step: 10
Training loss: 0.16347719728946686
Validation loss: 1.566817775849373

Epoch: 412| Step: 0
Training loss: 0.1977786421775818
Validation loss: 1.5723158787655573

Epoch: 5| Step: 1
Training loss: 0.12488043308258057
Validation loss: 1.5593545411222725

Epoch: 5| Step: 2
Training loss: 0.15900181233882904
Validation loss: 1.5651802632116503

Epoch: 5| Step: 3
Training loss: 0.16098056733608246
Validation loss: 1.592397916701532

Epoch: 5| Step: 4
Training loss: 0.241509348154068
Validation loss: 1.5926019004596177

Epoch: 5| Step: 5
Training loss: 0.13360488414764404
Validation loss: 1.614148615508951

Epoch: 5| Step: 6
Training loss: 0.1961001604795456
Validation loss: 1.5747134198424637

Epoch: 5| Step: 7
Training loss: 0.13866779208183289
Validation loss: 1.6120715295114825

Epoch: 5| Step: 8
Training loss: 0.1641843616962433
Validation loss: 1.5803974187502297

Epoch: 5| Step: 9
Training loss: 0.09083741158246994
Validation loss: 1.5621508936728201

Epoch: 5| Step: 10
Training loss: 0.10206174850463867
Validation loss: 1.5733920579315515

Epoch: 413| Step: 0
Training loss: 0.12147904932498932
Validation loss: 1.5685070432642454

Epoch: 5| Step: 1
Training loss: 0.09661432355642319
Validation loss: 1.5597096015048284

Epoch: 5| Step: 2
Training loss: 0.11350320279598236
Validation loss: 1.557141868017053

Epoch: 5| Step: 3
Training loss: 0.17665943503379822
Validation loss: 1.5624520829928819

Epoch: 5| Step: 4
Training loss: 0.2259967029094696
Validation loss: 1.5580974791639595

Epoch: 5| Step: 5
Training loss: 0.12419585138559341
Validation loss: 1.5506847930210892

Epoch: 5| Step: 6
Training loss: 0.1355256736278534
Validation loss: 1.5378767623696277

Epoch: 5| Step: 7
Training loss: 0.09210781753063202
Validation loss: 1.521557625903878

Epoch: 5| Step: 8
Training loss: 0.07475769519805908
Validation loss: 1.5448275278973322

Epoch: 5| Step: 9
Training loss: 0.11252768337726593
Validation loss: 1.5550753288371588

Epoch: 5| Step: 10
Training loss: 0.2142372578382492
Validation loss: 1.5326081052903207

Epoch: 414| Step: 0
Training loss: 0.2065085470676422
Validation loss: 1.5651496623152046

Epoch: 5| Step: 1
Training loss: 0.20267820358276367
Validation loss: 1.5702019160793674

Epoch: 5| Step: 2
Training loss: 0.17543622851371765
Validation loss: 1.5739433470592703

Epoch: 5| Step: 3
Training loss: 0.11618169397115707
Validation loss: 1.535845810367215

Epoch: 5| Step: 4
Training loss: 0.15099294483661652
Validation loss: 1.5671465781427198

Epoch: 5| Step: 5
Training loss: 0.12630219757556915
Validation loss: 1.580655743998866

Epoch: 5| Step: 6
Training loss: 0.17525584995746613
Validation loss: 1.5600640850682412

Epoch: 5| Step: 7
Training loss: 0.1146429032087326
Validation loss: 1.5888018928548342

Epoch: 5| Step: 8
Training loss: 0.10764117538928986
Validation loss: 1.582531129160235

Epoch: 5| Step: 9
Training loss: 0.09733526408672333
Validation loss: 1.5894532588220411

Epoch: 5| Step: 10
Training loss: 0.14681178331375122
Validation loss: 1.5779933070623746

Epoch: 415| Step: 0
Training loss: 0.11279497295618057
Validation loss: 1.5682193104938795

Epoch: 5| Step: 1
Training loss: 0.10940483957529068
Validation loss: 1.583686528667327

Epoch: 5| Step: 2
Training loss: 0.19102530181407928
Validation loss: 1.543338160361013

Epoch: 5| Step: 3
Training loss: 0.08658701181411743
Validation loss: 1.5694851131849392

Epoch: 5| Step: 4
Training loss: 0.16559498012065887
Validation loss: 1.5533982117970784

Epoch: 5| Step: 5
Training loss: 0.10311026871204376
Validation loss: 1.5386887064544104

Epoch: 5| Step: 6
Training loss: 0.11653926223516464
Validation loss: 1.5394598566075808

Epoch: 5| Step: 7
Training loss: 0.14142270386219025
Validation loss: 1.551902283904373

Epoch: 5| Step: 8
Training loss: 0.11596214771270752
Validation loss: 1.5437811369537024

Epoch: 5| Step: 9
Training loss: 0.16850952804088593
Validation loss: 1.5626400363060735

Epoch: 5| Step: 10
Training loss: 0.10345561057329178
Validation loss: 1.580019804739183

Epoch: 416| Step: 0
Training loss: 0.10167624801397324
Validation loss: 1.5624722319264566

Epoch: 5| Step: 1
Training loss: 0.1317664086818695
Validation loss: 1.551068982770366

Epoch: 5| Step: 2
Training loss: 0.12519113719463348
Validation loss: 1.5487461782270862

Epoch: 5| Step: 3
Training loss: 0.16407687962055206
Validation loss: 1.5428593754768372

Epoch: 5| Step: 4
Training loss: 0.11357004940509796
Validation loss: 1.5514704373575026

Epoch: 5| Step: 5
Training loss: 0.11433140933513641
Validation loss: 1.5662686824798584

Epoch: 5| Step: 6
Training loss: 0.0991993248462677
Validation loss: 1.608529374163638

Epoch: 5| Step: 7
Training loss: 0.16429220139980316
Validation loss: 1.5451562032904675

Epoch: 5| Step: 8
Training loss: 0.10271817445755005
Validation loss: 1.5522147891342

Epoch: 5| Step: 9
Training loss: 0.10131337493658066
Validation loss: 1.573421815390228

Epoch: 5| Step: 10
Training loss: 0.18057575821876526
Validation loss: 1.5725128548119658

Epoch: 417| Step: 0
Training loss: 0.13989336788654327
Validation loss: 1.5514966698103054

Epoch: 5| Step: 1
Training loss: 0.139746755361557
Validation loss: 1.548599285464133

Epoch: 5| Step: 2
Training loss: 0.07401099056005478
Validation loss: 1.542957155935226

Epoch: 5| Step: 3
Training loss: 0.09001995623111725
Validation loss: 1.527753491555491

Epoch: 5| Step: 4
Training loss: 0.09396212548017502
Validation loss: 1.5368043222735006

Epoch: 5| Step: 5
Training loss: 0.1991562396287918
Validation loss: 1.5217193313824233

Epoch: 5| Step: 6
Training loss: 0.11619876325130463
Validation loss: 1.5369217299645948

Epoch: 5| Step: 7
Training loss: 0.10319049656391144
Validation loss: 1.540964707251518

Epoch: 5| Step: 8
Training loss: 0.1747685819864273
Validation loss: 1.5803464061470442

Epoch: 5| Step: 9
Training loss: 0.15272271633148193
Validation loss: 1.5492773216257814

Epoch: 5| Step: 10
Training loss: 0.11341909319162369
Validation loss: 1.5769387945052116

Epoch: 418| Step: 0
Training loss: 0.05943257734179497
Validation loss: 1.5389678978150891

Epoch: 5| Step: 1
Training loss: 0.23931026458740234
Validation loss: 1.5585238702835575

Epoch: 5| Step: 2
Training loss: 0.1296090930700302
Validation loss: 1.5794361560575423

Epoch: 5| Step: 3
Training loss: 0.08361335843801498
Validation loss: 1.5501997406764696

Epoch: 5| Step: 4
Training loss: 0.10973825305700302
Validation loss: 1.5324700224784114

Epoch: 5| Step: 5
Training loss: 0.18059596419334412
Validation loss: 1.536566480513542

Epoch: 5| Step: 6
Training loss: 0.10588598251342773
Validation loss: 1.5186561845964002

Epoch: 5| Step: 7
Training loss: 0.16028891503810883
Validation loss: 1.4970596637777103

Epoch: 5| Step: 8
Training loss: 0.13634426891803741
Validation loss: 1.5425642228895617

Epoch: 5| Step: 9
Training loss: 0.08731873333454132
Validation loss: 1.5441365370186426

Epoch: 5| Step: 10
Training loss: 0.12801851332187653
Validation loss: 1.5395686869980187

Epoch: 419| Step: 0
Training loss: 0.14191830158233643
Validation loss: 1.5631822693732478

Epoch: 5| Step: 1
Training loss: 0.1621379405260086
Validation loss: 1.594846889536868

Epoch: 5| Step: 2
Training loss: 0.1590176671743393
Validation loss: 1.583723706583823

Epoch: 5| Step: 3
Training loss: 0.16479316353797913
Validation loss: 1.5828766630541893

Epoch: 5| Step: 4
Training loss: 0.18255911767482758
Validation loss: 1.59348814974549

Epoch: 5| Step: 5
Training loss: 0.11877177655696869
Validation loss: 1.580311466288823

Epoch: 5| Step: 6
Training loss: 0.11361054331064224
Validation loss: 1.5486654735380603

Epoch: 5| Step: 7
Training loss: 0.13990184664726257
Validation loss: 1.510753567500781

Epoch: 5| Step: 8
Training loss: 0.08118843287229538
Validation loss: 1.5352631858600083

Epoch: 5| Step: 9
Training loss: 0.10412738472223282
Validation loss: 1.5502853688373361

Epoch: 5| Step: 10
Training loss: 0.08601733297109604
Validation loss: 1.5290054326416345

Epoch: 420| Step: 0
Training loss: 0.16402378678321838
Validation loss: 1.5212782736747497

Epoch: 5| Step: 1
Training loss: 0.15049462020397186
Validation loss: 1.5486341509767758

Epoch: 5| Step: 2
Training loss: 0.1158171147108078
Validation loss: 1.562455669526131

Epoch: 5| Step: 3
Training loss: 0.1630699336528778
Validation loss: 1.5983568096673617

Epoch: 5| Step: 4
Training loss: 0.12596462666988373
Validation loss: 1.5643445138008363

Epoch: 5| Step: 5
Training loss: 0.11986707150936127
Validation loss: 1.5846971170876616

Epoch: 5| Step: 6
Training loss: 0.1267111599445343
Validation loss: 1.5997683117466588

Epoch: 5| Step: 7
Training loss: 0.09774129092693329
Validation loss: 1.6018314694845548

Epoch: 5| Step: 8
Training loss: 0.13623054325580597
Validation loss: 1.5875008542050597

Epoch: 5| Step: 9
Training loss: 0.2189958393573761
Validation loss: 1.629374760453419

Epoch: 5| Step: 10
Training loss: 0.1595093160867691
Validation loss: 1.6228410851570867

Epoch: 421| Step: 0
Training loss: 0.2504902184009552
Validation loss: 1.6197251446785466

Epoch: 5| Step: 1
Training loss: 0.13646253943443298
Validation loss: 1.599380672618907

Epoch: 5| Step: 2
Training loss: 0.147230863571167
Validation loss: 1.6278940054678148

Epoch: 5| Step: 3
Training loss: 0.1445014625787735
Validation loss: 1.6216631371487853

Epoch: 5| Step: 4
Training loss: 0.13609255850315094
Validation loss: 1.5905286240321335

Epoch: 5| Step: 5
Training loss: 0.1303655356168747
Validation loss: 1.5759090018528763

Epoch: 5| Step: 6
Training loss: 0.16808748245239258
Validation loss: 1.576180778523927

Epoch: 5| Step: 7
Training loss: 0.11498598754405975
Validation loss: 1.5889373992079048

Epoch: 5| Step: 8
Training loss: 0.08379576355218887
Validation loss: 1.565845044710303

Epoch: 5| Step: 9
Training loss: 0.14792859554290771
Validation loss: 1.5599408418901506

Epoch: 5| Step: 10
Training loss: 0.17490264773368835
Validation loss: 1.57711152620213

Epoch: 422| Step: 0
Training loss: 0.15192757546901703
Validation loss: 1.581050037055887

Epoch: 5| Step: 1
Training loss: 0.12156198173761368
Validation loss: 1.5441856243277108

Epoch: 5| Step: 2
Training loss: 0.1249687448143959
Validation loss: 1.561491794483636

Epoch: 5| Step: 3
Training loss: 0.10874338448047638
Validation loss: 1.6027609648243073

Epoch: 5| Step: 4
Training loss: 0.1632576733827591
Validation loss: 1.5773344629554338

Epoch: 5| Step: 5
Training loss: 0.14433033764362335
Validation loss: 1.544696823243172

Epoch: 5| Step: 6
Training loss: 0.17051644623279572
Validation loss: 1.5590989833237023

Epoch: 5| Step: 7
Training loss: 0.1842806190252304
Validation loss: 1.5333042901049379

Epoch: 5| Step: 8
Training loss: 0.13507245481014252
Validation loss: 1.5521598349335373

Epoch: 5| Step: 9
Training loss: 0.1075148731470108
Validation loss: 1.5370410693589078

Epoch: 5| Step: 10
Training loss: 0.17895351350307465
Validation loss: 1.560289357298164

Epoch: 423| Step: 0
Training loss: 0.1518857777118683
Validation loss: 1.5629629781169276

Epoch: 5| Step: 1
Training loss: 0.1394791603088379
Validation loss: 1.5970482992869552

Epoch: 5| Step: 2
Training loss: 0.13254816830158234
Validation loss: 1.5605519471629974

Epoch: 5| Step: 3
Training loss: 0.16109153628349304
Validation loss: 1.579252286623883

Epoch: 5| Step: 4
Training loss: 0.09745727479457855
Validation loss: 1.5575441391237321

Epoch: 5| Step: 5
Training loss: 0.1682685911655426
Validation loss: 1.5644928960389988

Epoch: 5| Step: 6
Training loss: 0.09537366777658463
Validation loss: 1.5684177221790436

Epoch: 5| Step: 7
Training loss: 0.1642327606678009
Validation loss: 1.5566216104774064

Epoch: 5| Step: 8
Training loss: 0.12864436209201813
Validation loss: 1.5813392311014154

Epoch: 5| Step: 9
Training loss: 0.15759210288524628
Validation loss: 1.5855392294545327

Epoch: 5| Step: 10
Training loss: 0.11025211215019226
Validation loss: 1.563072730136174

Epoch: 424| Step: 0
Training loss: 0.20111119747161865
Validation loss: 1.5744826870579873

Epoch: 5| Step: 1
Training loss: 0.10297133773565292
Validation loss: 1.5673331560627106

Epoch: 5| Step: 2
Training loss: 0.1260242909193039
Validation loss: 1.5378843686913932

Epoch: 5| Step: 3
Training loss: 0.2032640427350998
Validation loss: 1.5572785882539646

Epoch: 5| Step: 4
Training loss: 0.14093492925167084
Validation loss: 1.5656529344538206

Epoch: 5| Step: 5
Training loss: 0.11087000370025635
Validation loss: 1.5779869338517547

Epoch: 5| Step: 6
Training loss: 0.17807582020759583
Validation loss: 1.5691386525348952

Epoch: 5| Step: 7
Training loss: 0.11351640522480011
Validation loss: 1.5493046109394362

Epoch: 5| Step: 8
Training loss: 0.13099153339862823
Validation loss: 1.5644051874837568

Epoch: 5| Step: 9
Training loss: 0.16710704565048218
Validation loss: 1.5553941265229256

Epoch: 5| Step: 10
Training loss: 0.10133965313434601
Validation loss: 1.5546608291646486

Epoch: 425| Step: 0
Training loss: 0.1274520456790924
Validation loss: 1.5822597139625139

Epoch: 5| Step: 1
Training loss: 0.12362790107727051
Validation loss: 1.5620113136947795

Epoch: 5| Step: 2
Training loss: 0.11664654314517975
Validation loss: 1.5902526481177217

Epoch: 5| Step: 3
Training loss: 0.1635313332080841
Validation loss: 1.5918621106814312

Epoch: 5| Step: 4
Training loss: 0.1663428694009781
Validation loss: 1.5857667128245037

Epoch: 5| Step: 5
Training loss: 0.14303627610206604
Validation loss: 1.5637159373170586

Epoch: 5| Step: 6
Training loss: 0.15872102975845337
Validation loss: 1.5526886114510157

Epoch: 5| Step: 7
Training loss: 0.13998661935329437
Validation loss: 1.5583582116711525

Epoch: 5| Step: 8
Training loss: 0.14220210909843445
Validation loss: 1.5338861416744929

Epoch: 5| Step: 9
Training loss: 0.13506992161273956
Validation loss: 1.5474455779598606

Epoch: 5| Step: 10
Training loss: 0.11502420157194138
Validation loss: 1.5578085414824947

Epoch: 426| Step: 0
Training loss: 0.10976538807153702
Validation loss: 1.5720123129506265

Epoch: 5| Step: 1
Training loss: 0.16829600930213928
Validation loss: 1.5455817868632655

Epoch: 5| Step: 2
Training loss: 0.11394667625427246
Validation loss: 1.584593221705447

Epoch: 5| Step: 3
Training loss: 0.06220037490129471
Validation loss: 1.558914480670806

Epoch: 5| Step: 4
Training loss: 0.11816255748271942
Validation loss: 1.5825042570790937

Epoch: 5| Step: 5
Training loss: 0.1686168760061264
Validation loss: 1.5893461652981338

Epoch: 5| Step: 6
Training loss: 0.1775640845298767
Validation loss: 1.6021796099601253

Epoch: 5| Step: 7
Training loss: 0.15681388974189758
Validation loss: 1.610510641528714

Epoch: 5| Step: 8
Training loss: 0.15413214266300201
Validation loss: 1.5931733615936772

Epoch: 5| Step: 9
Training loss: 0.08812933415174484
Validation loss: 1.600180620788246

Epoch: 5| Step: 10
Training loss: 0.10642237961292267
Validation loss: 1.612609556926194

Epoch: 427| Step: 0
Training loss: 0.1364605724811554
Validation loss: 1.5847679748330066

Epoch: 5| Step: 1
Training loss: 0.11678221076726913
Validation loss: 1.5818121228166806

Epoch: 5| Step: 2
Training loss: 0.15190961956977844
Validation loss: 1.5992450111655778

Epoch: 5| Step: 3
Training loss: 0.09092111140489578
Validation loss: 1.572195517119541

Epoch: 5| Step: 4
Training loss: 0.1374843418598175
Validation loss: 1.5490201391199583

Epoch: 5| Step: 5
Training loss: 0.1404011994600296
Validation loss: 1.547622303808889

Epoch: 5| Step: 6
Training loss: 0.09420311450958252
Validation loss: 1.546435591354165

Epoch: 5| Step: 7
Training loss: 0.1620393693447113
Validation loss: 1.5296632564196022

Epoch: 5| Step: 8
Training loss: 0.13885067403316498
Validation loss: 1.506187092873358

Epoch: 5| Step: 9
Training loss: 0.14236775040626526
Validation loss: 1.533906062444051

Epoch: 5| Step: 10
Training loss: 0.10177705436944962
Validation loss: 1.5620634325088993

Epoch: 428| Step: 0
Training loss: 0.19541458785533905
Validation loss: 1.5384043762760777

Epoch: 5| Step: 1
Training loss: 0.17461903393268585
Validation loss: 1.5804435181361374

Epoch: 5| Step: 2
Training loss: 0.13928651809692383
Validation loss: 1.5939269565766858

Epoch: 5| Step: 3
Training loss: 0.185076043009758
Validation loss: 1.6031930087715067

Epoch: 5| Step: 4
Training loss: 0.14407093822956085
Validation loss: 1.6108722289403279

Epoch: 5| Step: 5
Training loss: 0.12390308082103729
Validation loss: 1.606253558589566

Epoch: 5| Step: 6
Training loss: 0.09288986027240753
Validation loss: 1.5972921515023837

Epoch: 5| Step: 7
Training loss: 0.08751218020915985
Validation loss: 1.616714418575328

Epoch: 5| Step: 8
Training loss: 0.11496531963348389
Validation loss: 1.5898986913824593

Epoch: 5| Step: 9
Training loss: 0.11774692684412003
Validation loss: 1.5977933932376165

Epoch: 5| Step: 10
Training loss: 0.13997182250022888
Validation loss: 1.5927682320276897

Epoch: 429| Step: 0
Training loss: 0.10584082454442978
Validation loss: 1.5974119145383117

Epoch: 5| Step: 1
Training loss: 0.15941612422466278
Validation loss: 1.5894985596338909

Epoch: 5| Step: 2
Training loss: 0.0816151350736618
Validation loss: 1.60533619055184

Epoch: 5| Step: 3
Training loss: 0.08528192341327667
Validation loss: 1.608037329489185

Epoch: 5| Step: 4
Training loss: 0.11817779392004013
Validation loss: 1.608232363577812

Epoch: 5| Step: 5
Training loss: 0.074367955327034
Validation loss: 1.6288481367531644

Epoch: 5| Step: 6
Training loss: 0.15350016951560974
Validation loss: 1.6211326545284641

Epoch: 5| Step: 7
Training loss: 0.14728419482707977
Validation loss: 1.639880132931535

Epoch: 5| Step: 8
Training loss: 0.12600234150886536
Validation loss: 1.604128537639495

Epoch: 5| Step: 9
Training loss: 0.10507204383611679
Validation loss: 1.5888915702860842

Epoch: 5| Step: 10
Training loss: 0.11453014612197876
Validation loss: 1.567262085535193

Epoch: 430| Step: 0
Training loss: 0.12957024574279785
Validation loss: 1.532173994407859

Epoch: 5| Step: 1
Training loss: 0.1560034453868866
Validation loss: 1.549514030897489

Epoch: 5| Step: 2
Training loss: 0.11490247398614883
Validation loss: 1.548268715540568

Epoch: 5| Step: 3
Training loss: 0.12126374244689941
Validation loss: 1.5353895855206314

Epoch: 5| Step: 4
Training loss: 0.12970997393131256
Validation loss: 1.5369507779357254

Epoch: 5| Step: 5
Training loss: 0.1877330243587494
Validation loss: 1.5452857196971934

Epoch: 5| Step: 6
Training loss: 0.08452713489532471
Validation loss: 1.545102389909888

Epoch: 5| Step: 7
Training loss: 0.08585035800933838
Validation loss: 1.573756129510941

Epoch: 5| Step: 8
Training loss: 0.11260584741830826
Validation loss: 1.5606705821970457

Epoch: 5| Step: 9
Training loss: 0.12919023633003235
Validation loss: 1.5704905089511667

Epoch: 5| Step: 10
Training loss: 0.17106479406356812
Validation loss: 1.6030749300474763

Epoch: 431| Step: 0
Training loss: 0.13221831619739532
Validation loss: 1.6070730077323092

Epoch: 5| Step: 1
Training loss: 0.18581703305244446
Validation loss: 1.6112329806050947

Epoch: 5| Step: 2
Training loss: 0.18356075882911682
Validation loss: 1.6182923880956506

Epoch: 5| Step: 3
Training loss: 0.1006714478135109
Validation loss: 1.5957693387103338

Epoch: 5| Step: 4
Training loss: 0.09332378953695297
Validation loss: 1.5521944389548352

Epoch: 5| Step: 5
Training loss: 0.11111867427825928
Validation loss: 1.58342404519358

Epoch: 5| Step: 6
Training loss: 0.10769100487232208
Validation loss: 1.5498313955081406

Epoch: 5| Step: 7
Training loss: 0.08445674926042557
Validation loss: 1.5285813295713035

Epoch: 5| Step: 8
Training loss: 0.08075739443302155
Validation loss: 1.542264639690358

Epoch: 5| Step: 9
Training loss: 0.08891291916370392
Validation loss: 1.5248181217460222

Epoch: 5| Step: 10
Training loss: 0.1157168373465538
Validation loss: 1.5573416807318246

Epoch: 432| Step: 0
Training loss: 0.19110682606697083
Validation loss: 1.5926714353663947

Epoch: 5| Step: 1
Training loss: 0.14841529726982117
Validation loss: 1.601424829934233

Epoch: 5| Step: 2
Training loss: 0.16725534200668335
Validation loss: 1.5908509531328756

Epoch: 5| Step: 3
Training loss: 0.11868099868297577
Validation loss: 1.6204803169414561

Epoch: 5| Step: 4
Training loss: 0.1031857579946518
Validation loss: 1.5930890806259648

Epoch: 5| Step: 5
Training loss: 0.11167310178279877
Validation loss: 1.5939064192515549

Epoch: 5| Step: 6
Training loss: 0.08817266672849655
Validation loss: 1.5996404578608852

Epoch: 5| Step: 7
Training loss: 0.11596111208200455
Validation loss: 1.5715653050330378

Epoch: 5| Step: 8
Training loss: 0.08811468631029129
Validation loss: 1.5736625053549325

Epoch: 5| Step: 9
Training loss: 0.09266486018896103
Validation loss: 1.5541810976561679

Epoch: 5| Step: 10
Training loss: 0.1011899784207344
Validation loss: 1.5494639001866823

Epoch: 433| Step: 0
Training loss: 0.10923759639263153
Validation loss: 1.5542727965180592

Epoch: 5| Step: 1
Training loss: 0.15291257202625275
Validation loss: 1.5313794318065848

Epoch: 5| Step: 2
Training loss: 0.13210973143577576
Validation loss: 1.5565256495629587

Epoch: 5| Step: 3
Training loss: 0.07789391279220581
Validation loss: 1.5492245625424128

Epoch: 5| Step: 4
Training loss: 0.1569749414920807
Validation loss: 1.5598853249703684

Epoch: 5| Step: 5
Training loss: 0.11740875244140625
Validation loss: 1.573021186295376

Epoch: 5| Step: 6
Training loss: 0.1341392993927002
Validation loss: 1.5616486123813096

Epoch: 5| Step: 7
Training loss: 0.15716493129730225
Validation loss: 1.5875314442060326

Epoch: 5| Step: 8
Training loss: 0.14644049108028412
Validation loss: 1.5916692851692118

Epoch: 5| Step: 9
Training loss: 0.13641934096813202
Validation loss: 1.5806049390505719

Epoch: 5| Step: 10
Training loss: 0.11605560034513474
Validation loss: 1.5566814304679952

Epoch: 434| Step: 0
Training loss: 0.12418297678232193
Validation loss: 1.5508045329842517

Epoch: 5| Step: 1
Training loss: 0.1261378675699234
Validation loss: 1.5180793654534124

Epoch: 5| Step: 2
Training loss: 0.08562310039997101
Validation loss: 1.5362109779029764

Epoch: 5| Step: 3
Training loss: 0.15645775198936462
Validation loss: 1.5602741997729066

Epoch: 5| Step: 4
Training loss: 0.0912383496761322
Validation loss: 1.5483688192982827

Epoch: 5| Step: 5
Training loss: 0.09858132153749466
Validation loss: 1.5775542643762404

Epoch: 5| Step: 6
Training loss: 0.10621742159128189
Validation loss: 1.5931951909936883

Epoch: 5| Step: 7
Training loss: 0.0905488058924675
Validation loss: 1.587031187549714

Epoch: 5| Step: 8
Training loss: 0.17932233214378357
Validation loss: 1.5965941721393215

Epoch: 5| Step: 9
Training loss: 0.13160577416419983
Validation loss: 1.6186678319848993

Epoch: 5| Step: 10
Training loss: 0.10242150723934174
Validation loss: 1.6054573751265002

Epoch: 435| Step: 0
Training loss: 0.09853440523147583
Validation loss: 1.6253936418922998

Epoch: 5| Step: 1
Training loss: 0.14159941673278809
Validation loss: 1.6142538926934684

Epoch: 5| Step: 2
Training loss: 0.08434096723794937
Validation loss: 1.5975194105537989

Epoch: 5| Step: 3
Training loss: 0.11702641099691391
Validation loss: 1.580570129938023

Epoch: 5| Step: 4
Training loss: 0.11857908964157104
Validation loss: 1.5726923763111074

Epoch: 5| Step: 5
Training loss: 0.1950686126947403
Validation loss: 1.5945811848486624

Epoch: 5| Step: 6
Training loss: 0.07257365435361862
Validation loss: 1.5968666845752346

Epoch: 5| Step: 7
Training loss: 0.12972280383110046
Validation loss: 1.552132418078761

Epoch: 5| Step: 8
Training loss: 0.1385580152273178
Validation loss: 1.5752794370856336

Epoch: 5| Step: 9
Training loss: 0.07878754287958145
Validation loss: 1.5446601478002404

Epoch: 5| Step: 10
Training loss: 0.17563626170158386
Validation loss: 1.5428166120283064

Epoch: 436| Step: 0
Training loss: 0.08810797333717346
Validation loss: 1.556200610694065

Epoch: 5| Step: 1
Training loss: 0.13738808035850525
Validation loss: 1.5585848657033776

Epoch: 5| Step: 2
Training loss: 0.11051330715417862
Validation loss: 1.5652355583765174

Epoch: 5| Step: 3
Training loss: 0.10912065207958221
Validation loss: 1.6084810726104244

Epoch: 5| Step: 4
Training loss: 0.11749480664730072
Validation loss: 1.5992351898583033

Epoch: 5| Step: 5
Training loss: 0.14158307015895844
Validation loss: 1.5834638482780867

Epoch: 5| Step: 6
Training loss: 0.11191215366125107
Validation loss: 1.5960757168390418

Epoch: 5| Step: 7
Training loss: 0.21859359741210938
Validation loss: 1.5904781626116844

Epoch: 5| Step: 8
Training loss: 0.07616133987903595
Validation loss: 1.5917696055545603

Epoch: 5| Step: 9
Training loss: 0.12168588489294052
Validation loss: 1.5771880149841309

Epoch: 5| Step: 10
Training loss: 0.10510920733213425
Validation loss: 1.5715857308398011

Epoch: 437| Step: 0
Training loss: 0.11353347450494766
Validation loss: 1.5507138512467826

Epoch: 5| Step: 1
Training loss: 0.12514205276966095
Validation loss: 1.5438900711715862

Epoch: 5| Step: 2
Training loss: 0.1601533591747284
Validation loss: 1.5501317497222655

Epoch: 5| Step: 3
Training loss: 0.13532429933547974
Validation loss: 1.552357385235448

Epoch: 5| Step: 4
Training loss: 0.15246114134788513
Validation loss: 1.5758984165806924

Epoch: 5| Step: 5
Training loss: 0.12319862842559814
Validation loss: 1.5475943101349698

Epoch: 5| Step: 6
Training loss: 0.1323867291212082
Validation loss: 1.5890821359490837

Epoch: 5| Step: 7
Training loss: 0.10333943367004395
Validation loss: 1.582547547996685

Epoch: 5| Step: 8
Training loss: 0.11503584682941437
Validation loss: 1.6008535738914245

Epoch: 5| Step: 9
Training loss: 0.10940394550561905
Validation loss: 1.6229902377692602

Epoch: 5| Step: 10
Training loss: 0.15685535967350006
Validation loss: 1.6008684417252899

Epoch: 438| Step: 0
Training loss: 0.1264180839061737
Validation loss: 1.6015881428154566

Epoch: 5| Step: 1
Training loss: 0.14771121740341187
Validation loss: 1.6338943025117278

Epoch: 5| Step: 2
Training loss: 0.07775633037090302
Validation loss: 1.5876298668564006

Epoch: 5| Step: 3
Training loss: 0.08938433229923248
Validation loss: 1.5899782078240507

Epoch: 5| Step: 4
Training loss: 0.1211959570646286
Validation loss: 1.5904093891061761

Epoch: 5| Step: 5
Training loss: 0.08328632265329361
Validation loss: 1.5542298824556413

Epoch: 5| Step: 6
Training loss: 0.1285317838191986
Validation loss: 1.5455261545796548

Epoch: 5| Step: 7
Training loss: 0.16974619030952454
Validation loss: 1.5406609690317543

Epoch: 5| Step: 8
Training loss: 0.1349438726902008
Validation loss: 1.5278507163447719

Epoch: 5| Step: 9
Training loss: 0.1165599599480629
Validation loss: 1.5408034234918573

Epoch: 5| Step: 10
Training loss: 0.09764841943979263
Validation loss: 1.5346969058436732

Epoch: 439| Step: 0
Training loss: 0.1553545743227005
Validation loss: 1.5304635801622946

Epoch: 5| Step: 1
Training loss: 0.06345248222351074
Validation loss: 1.58004581287343

Epoch: 5| Step: 2
Training loss: 0.10043749958276749
Validation loss: 1.5584635567921463

Epoch: 5| Step: 3
Training loss: 0.1130184680223465
Validation loss: 1.5664390415273688

Epoch: 5| Step: 4
Training loss: 0.1069871187210083
Validation loss: 1.5929775263673516

Epoch: 5| Step: 5
Training loss: 0.12268451601266861
Validation loss: 1.5636631083744827

Epoch: 5| Step: 6
Training loss: 0.13013243675231934
Validation loss: 1.5602303153725081

Epoch: 5| Step: 7
Training loss: 0.11545003950595856
Validation loss: 1.538149969552153

Epoch: 5| Step: 8
Training loss: 0.1027471199631691
Validation loss: 1.5236525061309978

Epoch: 5| Step: 9
Training loss: 0.13409575819969177
Validation loss: 1.5263584288217689

Epoch: 5| Step: 10
Training loss: 0.15142548084259033
Validation loss: 1.5317094018382411

Epoch: 440| Step: 0
Training loss: 0.18389643728733063
Validation loss: 1.5400495465083788

Epoch: 5| Step: 1
Training loss: 0.1863308846950531
Validation loss: 1.523213372435621

Epoch: 5| Step: 2
Training loss: 0.11359532177448273
Validation loss: 1.5199356976375784

Epoch: 5| Step: 3
Training loss: 0.0946936309337616
Validation loss: 1.5069609303628244

Epoch: 5| Step: 4
Training loss: 0.101750947535038
Validation loss: 1.5426732891349382

Epoch: 5| Step: 5
Training loss: 0.11821787059307098
Validation loss: 1.5530971211771811

Epoch: 5| Step: 6
Training loss: 0.21096959710121155
Validation loss: 1.5847386301204722

Epoch: 5| Step: 7
Training loss: 0.1824379712343216
Validation loss: 1.6248479133011193

Epoch: 5| Step: 8
Training loss: 0.11031482368707657
Validation loss: 1.631395374574969

Epoch: 5| Step: 9
Training loss: 0.09582336246967316
Validation loss: 1.6178407810067619

Epoch: 5| Step: 10
Training loss: 0.10492587089538574
Validation loss: 1.6375508167410409

Epoch: 441| Step: 0
Training loss: 0.10083451122045517
Validation loss: 1.6376824866059005

Epoch: 5| Step: 1
Training loss: 0.13867123425006866
Validation loss: 1.6274895027119627

Epoch: 5| Step: 2
Training loss: 0.11690919101238251
Validation loss: 1.6219811747151036

Epoch: 5| Step: 3
Training loss: 0.16343550384044647
Validation loss: 1.62135491448064

Epoch: 5| Step: 4
Training loss: 0.12247178703546524
Validation loss: 1.5918388764063518

Epoch: 5| Step: 5
Training loss: 0.20272445678710938
Validation loss: 1.5632250308990479

Epoch: 5| Step: 6
Training loss: 0.11842849105596542
Validation loss: 1.5685239838015648

Epoch: 5| Step: 7
Training loss: 0.12833943963050842
Validation loss: 1.546999523716588

Epoch: 5| Step: 8
Training loss: 0.13949672877788544
Validation loss: 1.5995338475832375

Epoch: 5| Step: 9
Training loss: 0.12008659541606903
Validation loss: 1.5738630371709024

Epoch: 5| Step: 10
Training loss: 0.12033302336931229
Validation loss: 1.6012226407245924

Epoch: 442| Step: 0
Training loss: 0.09377407282590866
Validation loss: 1.5940345525741577

Epoch: 5| Step: 1
Training loss: 0.1030970960855484
Validation loss: 1.5919732829575897

Epoch: 5| Step: 2
Training loss: 0.1497407853603363
Validation loss: 1.6102798318350187

Epoch: 5| Step: 3
Training loss: 0.16549204289913177
Validation loss: 1.6025360053585422

Epoch: 5| Step: 4
Training loss: 0.09776558727025986
Validation loss: 1.5936713955735649

Epoch: 5| Step: 5
Training loss: 0.13689064979553223
Validation loss: 1.5912731270636282

Epoch: 5| Step: 6
Training loss: 0.12480098009109497
Validation loss: 1.550863976119667

Epoch: 5| Step: 7
Training loss: 0.1475537270307541
Validation loss: 1.5572957633644022

Epoch: 5| Step: 8
Training loss: 0.14791253209114075
Validation loss: 1.54716270841578

Epoch: 5| Step: 9
Training loss: 0.10236859321594238
Validation loss: 1.5403413003490818

Epoch: 5| Step: 10
Training loss: 0.11425798386335373
Validation loss: 1.5176928902185092

Epoch: 443| Step: 0
Training loss: 0.07917346060276031
Validation loss: 1.5178116226709017

Epoch: 5| Step: 1
Training loss: 0.1031203493475914
Validation loss: 1.5256084524175173

Epoch: 5| Step: 2
Training loss: 0.13335421681404114
Validation loss: 1.5210462872700026

Epoch: 5| Step: 3
Training loss: 0.09966927766799927
Validation loss: 1.5450618869514876

Epoch: 5| Step: 4
Training loss: 0.11926732957363129
Validation loss: 1.5451134712465349

Epoch: 5| Step: 5
Training loss: 0.14240309596061707
Validation loss: 1.5499207537661317

Epoch: 5| Step: 6
Training loss: 0.12492980062961578
Validation loss: 1.566273118859978

Epoch: 5| Step: 7
Training loss: 0.17303822934627533
Validation loss: 1.5563507387715

Epoch: 5| Step: 8
Training loss: 0.08900786936283112
Validation loss: 1.5440888045936503

Epoch: 5| Step: 9
Training loss: 0.0767625942826271
Validation loss: 1.560313981066468

Epoch: 5| Step: 10
Training loss: 0.12220851331949234
Validation loss: 1.5824759160318682

Epoch: 444| Step: 0
Training loss: 0.15938107669353485
Validation loss: 1.5578671642529067

Epoch: 5| Step: 1
Training loss: 0.07505463063716888
Validation loss: 1.5394073884974244

Epoch: 5| Step: 2
Training loss: 0.12313820421695709
Validation loss: 1.5176471984514626

Epoch: 5| Step: 3
Training loss: 0.09394203126430511
Validation loss: 1.5246685730513705

Epoch: 5| Step: 4
Training loss: 0.1372929811477661
Validation loss: 1.523054640780213

Epoch: 5| Step: 5
Training loss: 0.13059034943580627
Validation loss: 1.5025228056856381

Epoch: 5| Step: 6
Training loss: 0.1503429114818573
Validation loss: 1.504648042622433

Epoch: 5| Step: 7
Training loss: 0.13798469305038452
Validation loss: 1.516505378548817

Epoch: 5| Step: 8
Training loss: 0.10032135248184204
Validation loss: 1.5294704129618983

Epoch: 5| Step: 9
Training loss: 0.05429703742265701
Validation loss: 1.5394299004667549

Epoch: 5| Step: 10
Training loss: 0.08035951852798462
Validation loss: 1.5546812934260215

Epoch: 445| Step: 0
Training loss: 0.1492728888988495
Validation loss: 1.5696910030098372

Epoch: 5| Step: 1
Training loss: 0.09291621297597885
Validation loss: 1.5499955197816253

Epoch: 5| Step: 2
Training loss: 0.10878288745880127
Validation loss: 1.5474507911230928

Epoch: 5| Step: 3
Training loss: 0.14248743653297424
Validation loss: 1.534348222517198

Epoch: 5| Step: 4
Training loss: 0.09028960764408112
Validation loss: 1.532194132445961

Epoch: 5| Step: 5
Training loss: 0.09613735228776932
Validation loss: 1.5092865190198343

Epoch: 5| Step: 6
Training loss: 0.0767768993973732
Validation loss: 1.5197141388411164

Epoch: 5| Step: 7
Training loss: 0.10598130524158478
Validation loss: 1.522515667382107

Epoch: 5| Step: 8
Training loss: 0.07779915630817413
Validation loss: 1.5310297473784416

Epoch: 5| Step: 9
Training loss: 0.13384230434894562
Validation loss: 1.53490501001317

Epoch: 5| Step: 10
Training loss: 0.07601537555456161
Validation loss: 1.5233498952722038

Epoch: 446| Step: 0
Training loss: 0.11110293865203857
Validation loss: 1.552759966542644

Epoch: 5| Step: 1
Training loss: 0.16787031292915344
Validation loss: 1.5575604259326894

Epoch: 5| Step: 2
Training loss: 0.13612893223762512
Validation loss: 1.5688732349744408

Epoch: 5| Step: 3
Training loss: 0.08290749788284302
Validation loss: 1.526196760516013

Epoch: 5| Step: 4
Training loss: 0.14514529705047607
Validation loss: 1.5627506650904173

Epoch: 5| Step: 5
Training loss: 0.09143976122140884
Validation loss: 1.540048413379218

Epoch: 5| Step: 6
Training loss: 0.07200188934803009
Validation loss: 1.5351734981741956

Epoch: 5| Step: 7
Training loss: 0.08460386097431183
Validation loss: 1.5148709019025166

Epoch: 5| Step: 8
Training loss: 0.10954871028661728
Validation loss: 1.5101218685027091

Epoch: 5| Step: 9
Training loss: 0.1634610891342163
Validation loss: 1.5453264162104616

Epoch: 5| Step: 10
Training loss: 0.11893892288208008
Validation loss: 1.565349519252777

Epoch: 447| Step: 0
Training loss: 0.0894244834780693
Validation loss: 1.5796169298951344

Epoch: 5| Step: 1
Training loss: 0.07536465674638748
Validation loss: 1.5675276966505154

Epoch: 5| Step: 2
Training loss: 0.19486351311206818
Validation loss: 1.5648615270532586

Epoch: 5| Step: 3
Training loss: 0.13996459543704987
Validation loss: 1.566060140568723

Epoch: 5| Step: 4
Training loss: 0.09779393672943115
Validation loss: 1.5479818851717058

Epoch: 5| Step: 5
Training loss: 0.12456592172384262
Validation loss: 1.545615674347006

Epoch: 5| Step: 6
Training loss: 0.08537086099386215
Validation loss: 1.5639102074407762

Epoch: 5| Step: 7
Training loss: 0.15243960916996002
Validation loss: 1.562417495635248

Epoch: 5| Step: 8
Training loss: 0.13772940635681152
Validation loss: 1.5605366191556376

Epoch: 5| Step: 9
Training loss: 0.13562825322151184
Validation loss: 1.5407625193236976

Epoch: 5| Step: 10
Training loss: 0.08511675149202347
Validation loss: 1.577055577308901

Epoch: 448| Step: 0
Training loss: 0.11109007894992828
Validation loss: 1.5581463883000035

Epoch: 5| Step: 1
Training loss: 0.08813410997390747
Validation loss: 1.542335307726296

Epoch: 5| Step: 2
Training loss: 0.14924678206443787
Validation loss: 1.5684696243655296

Epoch: 5| Step: 3
Training loss: 0.0853738859295845
Validation loss: 1.572884480158488

Epoch: 5| Step: 4
Training loss: 0.08793356269598007
Validation loss: 1.5753716935393631

Epoch: 5| Step: 5
Training loss: 0.12918920814990997
Validation loss: 1.5619046521443192

Epoch: 5| Step: 6
Training loss: 0.13695114850997925
Validation loss: 1.5802254253818142

Epoch: 5| Step: 7
Training loss: 0.07205632328987122
Validation loss: 1.5699854871278167

Epoch: 5| Step: 8
Training loss: 0.09751369804143906
Validation loss: 1.5598079773687548

Epoch: 5| Step: 9
Training loss: 0.13686609268188477
Validation loss: 1.5742552613699308

Epoch: 5| Step: 10
Training loss: 0.12284671515226364
Validation loss: 1.5670002865534958

Epoch: 449| Step: 0
Training loss: 0.07619240134954453
Validation loss: 1.5844610647488666

Epoch: 5| Step: 1
Training loss: 0.15106534957885742
Validation loss: 1.5820952974339968

Epoch: 5| Step: 2
Training loss: 0.06056932359933853
Validation loss: 1.6027398417072911

Epoch: 5| Step: 3
Training loss: 0.11005657911300659
Validation loss: 1.5955665316632999

Epoch: 5| Step: 4
Training loss: 0.1794167309999466
Validation loss: 1.5632527233451925

Epoch: 5| Step: 5
Training loss: 0.12344291061162949
Validation loss: 1.552991469701131

Epoch: 5| Step: 6
Training loss: 0.09811210632324219
Validation loss: 1.5484596888224285

Epoch: 5| Step: 7
Training loss: 0.13346192240715027
Validation loss: 1.5122016655501498

Epoch: 5| Step: 8
Training loss: 0.11003424972295761
Validation loss: 1.524897208777807

Epoch: 5| Step: 9
Training loss: 0.18583254516124725
Validation loss: 1.516165796146598

Epoch: 5| Step: 10
Training loss: 0.14801962673664093
Validation loss: 1.5273175880473147

Epoch: 450| Step: 0
Training loss: 0.09924982488155365
Validation loss: 1.5237615095671786

Epoch: 5| Step: 1
Training loss: 0.15882837772369385
Validation loss: 1.5144817534313406

Epoch: 5| Step: 2
Training loss: 0.11577759683132172
Validation loss: 1.533243957386222

Epoch: 5| Step: 3
Training loss: 0.11614657938480377
Validation loss: 1.5418566093649915

Epoch: 5| Step: 4
Training loss: 0.13245169818401337
Validation loss: 1.5670173834728938

Epoch: 5| Step: 5
Training loss: 0.13891425728797913
Validation loss: 1.5577102438096078

Epoch: 5| Step: 6
Training loss: 0.1727619767189026
Validation loss: 1.598837100690411

Epoch: 5| Step: 7
Training loss: 0.12097456306219101
Validation loss: 1.5849507854830833

Epoch: 5| Step: 8
Training loss: 0.12616415321826935
Validation loss: 1.6056174116749917

Epoch: 5| Step: 9
Training loss: 0.1222950667142868
Validation loss: 1.6064177456722464

Epoch: 5| Step: 10
Training loss: 0.0926949605345726
Validation loss: 1.585164080383957

Epoch: 451| Step: 0
Training loss: 0.10612137615680695
Validation loss: 1.5722252168963033

Epoch: 5| Step: 1
Training loss: 0.11748701333999634
Validation loss: 1.5700993640448457

Epoch: 5| Step: 2
Training loss: 0.06127019599080086
Validation loss: 1.5654138006189817

Epoch: 5| Step: 3
Training loss: 0.06301642954349518
Validation loss: 1.574349105999034

Epoch: 5| Step: 4
Training loss: 0.1570039689540863
Validation loss: 1.5794582354125155

Epoch: 5| Step: 5
Training loss: 0.13299544155597687
Validation loss: 1.5599482700388918

Epoch: 5| Step: 6
Training loss: 0.17628470063209534
Validation loss: 1.6065976568447646

Epoch: 5| Step: 7
Training loss: 0.1036398857831955
Validation loss: 1.5716196170417212

Epoch: 5| Step: 8
Training loss: 0.12545208632946014
Validation loss: 1.5736417539658085

Epoch: 5| Step: 9
Training loss: 0.1379489153623581
Validation loss: 1.5803073285728373

Epoch: 5| Step: 10
Training loss: 0.1409144401550293
Validation loss: 1.603145348128452

Epoch: 452| Step: 0
Training loss: 0.12587526440620422
Validation loss: 1.5840911865234375

Epoch: 5| Step: 1
Training loss: 0.14087939262390137
Validation loss: 1.6031423871235182

Epoch: 5| Step: 2
Training loss: 0.2560317814350128
Validation loss: 1.6221854071463309

Epoch: 5| Step: 3
Training loss: 0.13480965793132782
Validation loss: 1.6290063114576443

Epoch: 5| Step: 4
Training loss: 0.16153690218925476
Validation loss: 1.6108751758452384

Epoch: 5| Step: 5
Training loss: 0.12651395797729492
Validation loss: 1.5811321427745204

Epoch: 5| Step: 6
Training loss: 0.10363782942295074
Validation loss: 1.5441289268514162

Epoch: 5| Step: 7
Training loss: 0.1168142780661583
Validation loss: 1.5083523591359456

Epoch: 5| Step: 8
Training loss: 0.15407124161720276
Validation loss: 1.5283331268577165

Epoch: 5| Step: 9
Training loss: 0.11648450046777725
Validation loss: 1.529975265584966

Epoch: 5| Step: 10
Training loss: 0.12367997318506241
Validation loss: 1.5353488755482498

Epoch: 453| Step: 0
Training loss: 0.14722976088523865
Validation loss: 1.5741397565410984

Epoch: 5| Step: 1
Training loss: 0.08429430425167084
Validation loss: 1.5540700856075491

Epoch: 5| Step: 2
Training loss: 0.1824219524860382
Validation loss: 1.5872207367292015

Epoch: 5| Step: 3
Training loss: 0.1858341544866562
Validation loss: 1.6037506416279783

Epoch: 5| Step: 4
Training loss: 0.1612410545349121
Validation loss: 1.570153082570722

Epoch: 5| Step: 5
Training loss: 0.1748885214328766
Validation loss: 1.5946489546888618

Epoch: 5| Step: 6
Training loss: 0.11641167104244232
Validation loss: 1.5958642158457028

Epoch: 5| Step: 7
Training loss: 0.10181043297052383
Validation loss: 1.5858474572499592

Epoch: 5| Step: 8
Training loss: 0.09565602242946625
Validation loss: 1.5943532361779162

Epoch: 5| Step: 9
Training loss: 0.16889362037181854
Validation loss: 1.5966230643692838

Epoch: 5| Step: 10
Training loss: 0.10006169974803925
Validation loss: 1.5543426108616654

Epoch: 454| Step: 0
Training loss: 0.10250435769557953
Validation loss: 1.5262297417527886

Epoch: 5| Step: 1
Training loss: 0.1758566051721573
Validation loss: 1.4965916788706215

Epoch: 5| Step: 2
Training loss: 0.13572850823402405
Validation loss: 1.510615852571303

Epoch: 5| Step: 3
Training loss: 0.12454555183649063
Validation loss: 1.49147976598432

Epoch: 5| Step: 4
Training loss: 0.10467884689569473
Validation loss: 1.5113511239328692

Epoch: 5| Step: 5
Training loss: 0.11829714477062225
Validation loss: 1.5254658947708786

Epoch: 5| Step: 6
Training loss: 0.13034014403820038
Validation loss: 1.5083964101729854

Epoch: 5| Step: 7
Training loss: 0.11134711652994156
Validation loss: 1.518197677468741

Epoch: 5| Step: 8
Training loss: 0.12342388927936554
Validation loss: 1.5409942262916154

Epoch: 5| Step: 9
Training loss: 0.11709083616733551
Validation loss: 1.530415810564513

Epoch: 5| Step: 10
Training loss: 0.13513459265232086
Validation loss: 1.5479379674439788

Epoch: 455| Step: 0
Training loss: 0.057727813720703125
Validation loss: 1.5805109752121793

Epoch: 5| Step: 1
Training loss: 0.1097891554236412
Validation loss: 1.5839163667412215

Epoch: 5| Step: 2
Training loss: 0.19330108165740967
Validation loss: 1.571527127296694

Epoch: 5| Step: 3
Training loss: 0.16427548229694366
Validation loss: 1.588216871343633

Epoch: 5| Step: 4
Training loss: 0.15132755041122437
Validation loss: 1.5779254590311358

Epoch: 5| Step: 5
Training loss: 0.1055261641740799
Validation loss: 1.5793073305519678

Epoch: 5| Step: 6
Training loss: 0.0922420546412468
Validation loss: 1.560454523691567

Epoch: 5| Step: 7
Training loss: 0.15812988579273224
Validation loss: 1.6056112909829745

Epoch: 5| Step: 8
Training loss: 0.0767831802368164
Validation loss: 1.610454866963048

Epoch: 5| Step: 9
Training loss: 0.1352977454662323
Validation loss: 1.5947753972904657

Epoch: 5| Step: 10
Training loss: 0.1190270259976387
Validation loss: 1.5504544524736301

Epoch: 456| Step: 0
Training loss: 0.0981801375746727
Validation loss: 1.576727246725431

Epoch: 5| Step: 1
Training loss: 0.12358343601226807
Validation loss: 1.5871556997299194

Epoch: 5| Step: 2
Training loss: 0.14057493209838867
Validation loss: 1.560830258554028

Epoch: 5| Step: 3
Training loss: 0.13567259907722473
Validation loss: 1.5574115476300638

Epoch: 5| Step: 4
Training loss: 0.1599101722240448
Validation loss: 1.6005002349935553

Epoch: 5| Step: 5
Training loss: 0.09847234934568405
Validation loss: 1.5492826905301822

Epoch: 5| Step: 6
Training loss: 0.08481043577194214
Validation loss: 1.5290036662932365

Epoch: 5| Step: 7
Training loss: 0.09146076440811157
Validation loss: 1.5377690945902178

Epoch: 5| Step: 8
Training loss: 0.11903856694698334
Validation loss: 1.556806174657678

Epoch: 5| Step: 9
Training loss: 0.07856836915016174
Validation loss: 1.55852517133118

Epoch: 5| Step: 10
Training loss: 0.10287255793809891
Validation loss: 1.5515917680596794

Epoch: 457| Step: 0
Training loss: 0.14951731264591217
Validation loss: 1.5600626263567197

Epoch: 5| Step: 1
Training loss: 0.10257987678050995
Validation loss: 1.5868015238033828

Epoch: 5| Step: 2
Training loss: 0.12312408536672592
Validation loss: 1.5521108232518679

Epoch: 5| Step: 3
Training loss: 0.09787067025899887
Validation loss: 1.5619878384374803

Epoch: 5| Step: 4
Training loss: 0.10375852882862091
Validation loss: 1.5615198368667274

Epoch: 5| Step: 5
Training loss: 0.16143080592155457
Validation loss: 1.5248870593245312

Epoch: 5| Step: 6
Training loss: 0.09600482136011124
Validation loss: 1.543890255753712

Epoch: 5| Step: 7
Training loss: 0.09332471340894699
Validation loss: 1.5153496060320126

Epoch: 5| Step: 8
Training loss: 0.11130531132221222
Validation loss: 1.538140845555131

Epoch: 5| Step: 9
Training loss: 0.12214479595422745
Validation loss: 1.5449641225158528

Epoch: 5| Step: 10
Training loss: 0.17225277423858643
Validation loss: 1.5254177553679353

Epoch: 458| Step: 0
Training loss: 0.1436464488506317
Validation loss: 1.551705487312809

Epoch: 5| Step: 1
Training loss: 0.13603509962558746
Validation loss: 1.555593011199787

Epoch: 5| Step: 2
Training loss: 0.12283454090356827
Validation loss: 1.5655971547608734

Epoch: 5| Step: 3
Training loss: 0.13036254048347473
Validation loss: 1.5903869495596936

Epoch: 5| Step: 4
Training loss: 0.09975066781044006
Validation loss: 1.557108586834323

Epoch: 5| Step: 5
Training loss: 0.086096853017807
Validation loss: 1.5657626326366136

Epoch: 5| Step: 6
Training loss: 0.1530621498823166
Validation loss: 1.5734900928312732

Epoch: 5| Step: 7
Training loss: 0.09090565145015717
Validation loss: 1.5823386305121965

Epoch: 5| Step: 8
Training loss: 0.11561362445354462
Validation loss: 1.5767839339471632

Epoch: 5| Step: 9
Training loss: 0.07272744178771973
Validation loss: 1.5505356468180174

Epoch: 5| Step: 10
Training loss: 0.09301645308732986
Validation loss: 1.5965667886118735

Epoch: 459| Step: 0
Training loss: 0.09832660853862762
Validation loss: 1.5583869193189888

Epoch: 5| Step: 1
Training loss: 0.12879763543605804
Validation loss: 1.5539712354701052

Epoch: 5| Step: 2
Training loss: 0.10844218730926514
Validation loss: 1.5534228227471794

Epoch: 5| Step: 3
Training loss: 0.06771210581064224
Validation loss: 1.5629657596670172

Epoch: 5| Step: 4
Training loss: 0.12429018318653107
Validation loss: 1.5620354529350036

Epoch: 5| Step: 5
Training loss: 0.06317494809627533
Validation loss: 1.5542149953944708

Epoch: 5| Step: 6
Training loss: 0.10205364227294922
Validation loss: 1.525607451315849

Epoch: 5| Step: 7
Training loss: 0.11298622936010361
Validation loss: 1.5255464687142322

Epoch: 5| Step: 8
Training loss: 0.08417711406946182
Validation loss: 1.5566618750172276

Epoch: 5| Step: 9
Training loss: 0.14234724640846252
Validation loss: 1.5461124143292826

Epoch: 5| Step: 10
Training loss: 0.13108937442302704
Validation loss: 1.5260393004263602

Epoch: 460| Step: 0
Training loss: 0.10332473367452621
Validation loss: 1.5681363754375006

Epoch: 5| Step: 1
Training loss: 0.10055508464574814
Validation loss: 1.520172171695258

Epoch: 5| Step: 2
Training loss: 0.09187813848257065
Validation loss: 1.5300988330635974

Epoch: 5| Step: 3
Training loss: 0.07696984708309174
Validation loss: 1.5556621064421952

Epoch: 5| Step: 4
Training loss: 0.08844123780727386
Validation loss: 1.5616681556547842

Epoch: 5| Step: 5
Training loss: 0.1814679205417633
Validation loss: 1.545767125263009

Epoch: 5| Step: 6
Training loss: 0.0787205845117569
Validation loss: 1.5365351656431794

Epoch: 5| Step: 7
Training loss: 0.11269567906856537
Validation loss: 1.5326848517182052

Epoch: 5| Step: 8
Training loss: 0.11891040951013565
Validation loss: 1.530697884098176

Epoch: 5| Step: 9
Training loss: 0.10122412443161011
Validation loss: 1.5469340111619683

Epoch: 5| Step: 10
Training loss: 0.05613992363214493
Validation loss: 1.5385353795943721

Epoch: 461| Step: 0
Training loss: 0.15495634078979492
Validation loss: 1.561694864303835

Epoch: 5| Step: 1
Training loss: 0.0911228209733963
Validation loss: 1.5393967666933615

Epoch: 5| Step: 2
Training loss: 0.1506788432598114
Validation loss: 1.5653834317320137

Epoch: 5| Step: 3
Training loss: 0.07835458219051361
Validation loss: 1.5620098652378205

Epoch: 5| Step: 4
Training loss: 0.06610332429409027
Validation loss: 1.6058080465562883

Epoch: 5| Step: 5
Training loss: 0.07253380119800568
Validation loss: 1.581467160614588

Epoch: 5| Step: 6
Training loss: 0.08154816180467606
Validation loss: 1.6006431233498357

Epoch: 5| Step: 7
Training loss: 0.11192504316568375
Validation loss: 1.5843443921817246

Epoch: 5| Step: 8
Training loss: 0.10610876977443695
Validation loss: 1.568961324230317

Epoch: 5| Step: 9
Training loss: 0.10687069594860077
Validation loss: 1.5701447045931252

Epoch: 5| Step: 10
Training loss: 0.11873430013656616
Validation loss: 1.5341263381383752

Epoch: 462| Step: 0
Training loss: 0.09248852729797363
Validation loss: 1.574017358082597

Epoch: 5| Step: 1
Training loss: 0.07713907957077026
Validation loss: 1.5287214197138304

Epoch: 5| Step: 2
Training loss: 0.11779715865850449
Validation loss: 1.5214113811010956

Epoch: 5| Step: 3
Training loss: 0.1329103410243988
Validation loss: 1.563081757996672

Epoch: 5| Step: 4
Training loss: 0.06804052740335464
Validation loss: 1.5630845869741132

Epoch: 5| Step: 5
Training loss: 0.10979845374822617
Validation loss: 1.5183897659342775

Epoch: 5| Step: 6
Training loss: 0.1254328340291977
Validation loss: 1.519426187520386

Epoch: 5| Step: 7
Training loss: 0.07252434641122818
Validation loss: 1.53334669656651

Epoch: 5| Step: 8
Training loss: 0.07335632294416428
Validation loss: 1.5272205619401829

Epoch: 5| Step: 9
Training loss: 0.07209399342536926
Validation loss: 1.522840831869392

Epoch: 5| Step: 10
Training loss: 0.1383056342601776
Validation loss: 1.5138293466260355

Epoch: 463| Step: 0
Training loss: 0.08447539806365967
Validation loss: 1.5424540145422823

Epoch: 5| Step: 1
Training loss: 0.08771376311779022
Validation loss: 1.5413872324010378

Epoch: 5| Step: 2
Training loss: 0.06450197845697403
Validation loss: 1.5248812603694137

Epoch: 5| Step: 3
Training loss: 0.08528624475002289
Validation loss: 1.5467191101402364

Epoch: 5| Step: 4
Training loss: 0.06840286403894424
Validation loss: 1.553343967724872

Epoch: 5| Step: 5
Training loss: 0.10507650673389435
Validation loss: 1.54934516901611

Epoch: 5| Step: 6
Training loss: 0.08321775496006012
Validation loss: 1.5519301955417921

Epoch: 5| Step: 7
Training loss: 0.11190767586231232
Validation loss: 1.5654460307090514

Epoch: 5| Step: 8
Training loss: 0.08603969216346741
Validation loss: 1.5421771913446405

Epoch: 5| Step: 9
Training loss: 0.09889321774244308
Validation loss: 1.5422887981578868

Epoch: 5| Step: 10
Training loss: 0.13603435456752777
Validation loss: 1.5239951213200886

Epoch: 464| Step: 0
Training loss: 0.061936765909194946
Validation loss: 1.5262493677036737

Epoch: 5| Step: 1
Training loss: 0.08051762729883194
Validation loss: 1.5480915013179983

Epoch: 5| Step: 2
Training loss: 0.10238993167877197
Validation loss: 1.521060497530045

Epoch: 5| Step: 3
Training loss: 0.11630105972290039
Validation loss: 1.5441472748274445

Epoch: 5| Step: 4
Training loss: 0.07154940068721771
Validation loss: 1.5504469269065446

Epoch: 5| Step: 5
Training loss: 0.09857990592718124
Validation loss: 1.5370400951754661

Epoch: 5| Step: 6
Training loss: 0.08875292539596558
Validation loss: 1.5525115754014702

Epoch: 5| Step: 7
Training loss: 0.11580751091241837
Validation loss: 1.548630520861636

Epoch: 5| Step: 8
Training loss: 0.09549113363027573
Validation loss: 1.5852010211636942

Epoch: 5| Step: 9
Training loss: 0.14209966361522675
Validation loss: 1.6079749868762108

Epoch: 5| Step: 10
Training loss: 0.14677102863788605
Validation loss: 1.5972096394467097

Epoch: 465| Step: 0
Training loss: 0.08592154830694199
Validation loss: 1.5889568662130704

Epoch: 5| Step: 1
Training loss: 0.06194658949971199
Validation loss: 1.6119868704067764

Epoch: 5| Step: 2
Training loss: 0.14068713784217834
Validation loss: 1.5675528690379152

Epoch: 5| Step: 3
Training loss: 0.11092555522918701
Validation loss: 1.619858713560207

Epoch: 5| Step: 4
Training loss: 0.10584287345409393
Validation loss: 1.6052273011976672

Epoch: 5| Step: 5
Training loss: 0.10488846153020859
Validation loss: 1.6048978990124119

Epoch: 5| Step: 6
Training loss: 0.09632865339517593
Validation loss: 1.6139909913462978

Epoch: 5| Step: 7
Training loss: 0.13735510408878326
Validation loss: 1.6211572206148537

Epoch: 5| Step: 8
Training loss: 0.0720820277929306
Validation loss: 1.6030001012227868

Epoch: 5| Step: 9
Training loss: 0.11509981006383896
Validation loss: 1.5979520633656492

Epoch: 5| Step: 10
Training loss: 0.0782603770494461
Validation loss: 1.6137771529536094

Epoch: 466| Step: 0
Training loss: 0.07149408757686615
Validation loss: 1.6302919721090665

Epoch: 5| Step: 1
Training loss: 0.09567960351705551
Validation loss: 1.60314691323106

Epoch: 5| Step: 2
Training loss: 0.12966085970401764
Validation loss: 1.606584825823384

Epoch: 5| Step: 3
Training loss: 0.1746710240840912
Validation loss: 1.5875392203689904

Epoch: 5| Step: 4
Training loss: 0.1585497111082077
Validation loss: 1.554393078691216

Epoch: 5| Step: 5
Training loss: 0.1526208072900772
Validation loss: 1.5359797541813185

Epoch: 5| Step: 6
Training loss: 0.10413824021816254
Validation loss: 1.538360982812861

Epoch: 5| Step: 7
Training loss: 0.09193304926156998
Validation loss: 1.553066107534593

Epoch: 5| Step: 8
Training loss: 0.09466817229986191
Validation loss: 1.5592044553449076

Epoch: 5| Step: 9
Training loss: 0.13029393553733826
Validation loss: 1.5723385657033613

Epoch: 5| Step: 10
Training loss: 0.08747873455286026
Validation loss: 1.5884737353171072

Epoch: 467| Step: 0
Training loss: 0.07825030386447906
Validation loss: 1.5879215309696812

Epoch: 5| Step: 1
Training loss: 0.2043478935956955
Validation loss: 1.6257895026155698

Epoch: 5| Step: 2
Training loss: 0.07051897048950195
Validation loss: 1.5921030249646915

Epoch: 5| Step: 3
Training loss: 0.15503063797950745
Validation loss: 1.6060065428415935

Epoch: 5| Step: 4
Training loss: 0.10684902966022491
Validation loss: 1.609052691408383

Epoch: 5| Step: 5
Training loss: 0.08371096104383469
Validation loss: 1.5670137097758632

Epoch: 5| Step: 6
Training loss: 0.09823592007160187
Validation loss: 1.5699181172155565

Epoch: 5| Step: 7
Training loss: 0.1355900913476944
Validation loss: 1.569798772053052

Epoch: 5| Step: 8
Training loss: 0.08054031431674957
Validation loss: 1.555195052136657

Epoch: 5| Step: 9
Training loss: 0.0792689397931099
Validation loss: 1.5433875783797233

Epoch: 5| Step: 10
Training loss: 0.16056765615940094
Validation loss: 1.5409035169950096

Epoch: 468| Step: 0
Training loss: 0.10533823817968369
Validation loss: 1.5303774585006058

Epoch: 5| Step: 1
Training loss: 0.18820860981941223
Validation loss: 1.5412532514141453

Epoch: 5| Step: 2
Training loss: 0.14504772424697876
Validation loss: 1.5362494594307357

Epoch: 5| Step: 3
Training loss: 0.1346513330936432
Validation loss: 1.5181967494308308

Epoch: 5| Step: 4
Training loss: 0.08860304206609726
Validation loss: 1.5591900861391457

Epoch: 5| Step: 5
Training loss: 0.10614965111017227
Validation loss: 1.5462189233431252

Epoch: 5| Step: 6
Training loss: 0.1358058750629425
Validation loss: 1.5595819642466884

Epoch: 5| Step: 7
Training loss: 0.09596247971057892
Validation loss: 1.5715844868331827

Epoch: 5| Step: 8
Training loss: 0.07670923322439194
Validation loss: 1.589319868754315

Epoch: 5| Step: 9
Training loss: 0.07712456583976746
Validation loss: 1.5633824781704975

Epoch: 5| Step: 10
Training loss: 0.13252535462379456
Validation loss: 1.574088728556069

Epoch: 469| Step: 0
Training loss: 0.12000279128551483
Validation loss: 1.5491643554420882

Epoch: 5| Step: 1
Training loss: 0.11894752085208893
Validation loss: 1.5633358135018298

Epoch: 5| Step: 2
Training loss: 0.1102375015616417
Validation loss: 1.590793212254842

Epoch: 5| Step: 3
Training loss: 0.09749246388673782
Validation loss: 1.5663762759136897

Epoch: 5| Step: 4
Training loss: 0.06526751816272736
Validation loss: 1.5673701244015847

Epoch: 5| Step: 5
Training loss: 0.09240280091762543
Validation loss: 1.5565781926596036

Epoch: 5| Step: 6
Training loss: 0.07491965591907501
Validation loss: 1.5564390587550339

Epoch: 5| Step: 7
Training loss: 0.0886826142668724
Validation loss: 1.55373768268093

Epoch: 5| Step: 8
Training loss: 0.11939515918493271
Validation loss: 1.5344340775602607

Epoch: 5| Step: 9
Training loss: 0.14192798733711243
Validation loss: 1.5702700179110292

Epoch: 5| Step: 10
Training loss: 0.07785475254058838
Validation loss: 1.5963683000174902

Epoch: 470| Step: 0
Training loss: 0.08872635662555695
Validation loss: 1.5807171931830786

Epoch: 5| Step: 1
Training loss: 0.08997286856174469
Validation loss: 1.582271965601111

Epoch: 5| Step: 2
Training loss: 0.15061922371387482
Validation loss: 1.5378362389021023

Epoch: 5| Step: 3
Training loss: 0.10218264907598495
Validation loss: 1.5177894881976548

Epoch: 5| Step: 4
Training loss: 0.11406470835208893
Validation loss: 1.502344557034072

Epoch: 5| Step: 5
Training loss: 0.08382712304592133
Validation loss: 1.526124087713098

Epoch: 5| Step: 6
Training loss: 0.12349021434783936
Validation loss: 1.5075561718274189

Epoch: 5| Step: 7
Training loss: 0.13170607388019562
Validation loss: 1.5239234355188185

Epoch: 5| Step: 8
Training loss: 0.13765652477741241
Validation loss: 1.5061387105654644

Epoch: 5| Step: 9
Training loss: 0.08521869033575058
Validation loss: 1.5327376524607341

Epoch: 5| Step: 10
Training loss: 0.08938528597354889
Validation loss: 1.5334626897688834

Epoch: 471| Step: 0
Training loss: 0.05856132507324219
Validation loss: 1.5493215591676774

Epoch: 5| Step: 1
Training loss: 0.11537792533636093
Validation loss: 1.5579869170342722

Epoch: 5| Step: 2
Training loss: 0.1405750811100006
Validation loss: 1.5901360857871272

Epoch: 5| Step: 3
Training loss: 0.1932951956987381
Validation loss: 1.5970016500001312

Epoch: 5| Step: 4
Training loss: 0.041547298431396484
Validation loss: 1.5918788474093202

Epoch: 5| Step: 5
Training loss: 0.08136777579784393
Validation loss: 1.578524826675333

Epoch: 5| Step: 6
Training loss: 0.09482807666063309
Validation loss: 1.5320771791601693

Epoch: 5| Step: 7
Training loss: 0.08223038911819458
Validation loss: 1.5311219551229989

Epoch: 5| Step: 8
Training loss: 0.06937997043132782
Validation loss: 1.5270982198817755

Epoch: 5| Step: 9
Training loss: 0.12744662165641785
Validation loss: 1.5379986429727206

Epoch: 5| Step: 10
Training loss: 0.09800735116004944
Validation loss: 1.5416805628807313

Epoch: 472| Step: 0
Training loss: 0.14632296562194824
Validation loss: 1.5368044440464308

Epoch: 5| Step: 1
Training loss: 0.09314920008182526
Validation loss: 1.5612103887783584

Epoch: 5| Step: 2
Training loss: 0.0800568237900734
Validation loss: 1.5464394182287238

Epoch: 5| Step: 3
Training loss: 0.131510391831398
Validation loss: 1.5472488544320548

Epoch: 5| Step: 4
Training loss: 0.07056735455989838
Validation loss: 1.547804045420821

Epoch: 5| Step: 5
Training loss: 0.10753791034221649
Validation loss: 1.5757763462681924

Epoch: 5| Step: 6
Training loss: 0.10564224421977997
Validation loss: 1.5555789957764328

Epoch: 5| Step: 7
Training loss: 0.12610474228858948
Validation loss: 1.5960842486350768

Epoch: 5| Step: 8
Training loss: 0.08790957927703857
Validation loss: 1.5361015540297314

Epoch: 5| Step: 9
Training loss: 0.1553100049495697
Validation loss: 1.5188696128065868

Epoch: 5| Step: 10
Training loss: 0.07482660561800003
Validation loss: 1.5168175389689784

Epoch: 473| Step: 0
Training loss: 0.13323742151260376
Validation loss: 1.516716105963594

Epoch: 5| Step: 1
Training loss: 0.10571763664484024
Validation loss: 1.5237730626137025

Epoch: 5| Step: 2
Training loss: 0.16133466362953186
Validation loss: 1.5570945047563123

Epoch: 5| Step: 3
Training loss: 0.13399115204811096
Validation loss: 1.5368476734366467

Epoch: 5| Step: 4
Training loss: 0.1900588423013687
Validation loss: 1.5348460571740263

Epoch: 5| Step: 5
Training loss: 0.06729955971240997
Validation loss: 1.5520656986903119

Epoch: 5| Step: 6
Training loss: 0.07159314304590225
Validation loss: 1.5429270472577823

Epoch: 5| Step: 7
Training loss: 0.08817276358604431
Validation loss: 1.5484300915912916

Epoch: 5| Step: 8
Training loss: 0.08118624985218048
Validation loss: 1.5555105350350822

Epoch: 5| Step: 9
Training loss: 0.12031290680170059
Validation loss: 1.577306137290052

Epoch: 5| Step: 10
Training loss: 0.12219667434692383
Validation loss: 1.5982415772253467

Epoch: 474| Step: 0
Training loss: 0.09036396443843842
Validation loss: 1.603040692626789

Epoch: 5| Step: 1
Training loss: 0.09741602092981339
Validation loss: 1.6085283922892746

Epoch: 5| Step: 2
Training loss: 0.09344934672117233
Validation loss: 1.5999848227347098

Epoch: 5| Step: 3
Training loss: 0.1260090172290802
Validation loss: 1.582259403761997

Epoch: 5| Step: 4
Training loss: 0.13211491703987122
Validation loss: 1.5618592872414538

Epoch: 5| Step: 5
Training loss: 0.07059434801340103
Validation loss: 1.5332816326490013

Epoch: 5| Step: 6
Training loss: 0.11473013460636139
Validation loss: 1.5485787596753848

Epoch: 5| Step: 7
Training loss: 0.12086693197488785
Validation loss: 1.5203492103084442

Epoch: 5| Step: 8
Training loss: 0.0954764261841774
Validation loss: 1.49319532609755

Epoch: 5| Step: 9
Training loss: 0.10106714069843292
Validation loss: 1.5289330174846034

Epoch: 5| Step: 10
Training loss: 0.09611921012401581
Validation loss: 1.5233937335270706

Epoch: 475| Step: 0
Training loss: 0.0767986923456192
Validation loss: 1.5263199011484783

Epoch: 5| Step: 1
Training loss: 0.09667663276195526
Validation loss: 1.5169296674830939

Epoch: 5| Step: 2
Training loss: 0.10274428129196167
Validation loss: 1.505179976904264

Epoch: 5| Step: 3
Training loss: 0.10543880611658096
Validation loss: 1.5039022584115305

Epoch: 5| Step: 4
Training loss: 0.06744283437728882
Validation loss: 1.5332298778718518

Epoch: 5| Step: 5
Training loss: 0.05614330247044563
Validation loss: 1.5228177475672897

Epoch: 5| Step: 6
Training loss: 0.09962525963783264
Validation loss: 1.5457790628556283

Epoch: 5| Step: 7
Training loss: 0.07590804994106293
Validation loss: 1.5713506411480647

Epoch: 5| Step: 8
Training loss: 0.12157710641622543
Validation loss: 1.5781061392958446

Epoch: 5| Step: 9
Training loss: 0.13097064197063446
Validation loss: 1.571523085717232

Epoch: 5| Step: 10
Training loss: 0.14294709265232086
Validation loss: 1.5728080221401748

Epoch: 476| Step: 0
Training loss: 0.0751844197511673
Validation loss: 1.5509071388552267

Epoch: 5| Step: 1
Training loss: 0.1152443066239357
Validation loss: 1.541429570926133

Epoch: 5| Step: 2
Training loss: 0.10076342523097992
Validation loss: 1.5536690553029378

Epoch: 5| Step: 3
Training loss: 0.10027740150690079
Validation loss: 1.5163425104592436

Epoch: 5| Step: 4
Training loss: 0.08104795962572098
Validation loss: 1.5148284800591008

Epoch: 5| Step: 5
Training loss: 0.10752184689044952
Validation loss: 1.541799904197775

Epoch: 5| Step: 6
Training loss: 0.14956332743167877
Validation loss: 1.5431429186174948

Epoch: 5| Step: 7
Training loss: 0.034363098442554474
Validation loss: 1.5032071522487107

Epoch: 5| Step: 8
Training loss: 0.09138458967208862
Validation loss: 1.5396130059355049

Epoch: 5| Step: 9
Training loss: 0.12264542281627655
Validation loss: 1.5658113110450007

Epoch: 5| Step: 10
Training loss: 0.11118267476558685
Validation loss: 1.546024707055861

Epoch: 477| Step: 0
Training loss: 0.07299211621284485
Validation loss: 1.5430283059356034

Epoch: 5| Step: 1
Training loss: 0.1165301650762558
Validation loss: 1.5242045310235792

Epoch: 5| Step: 2
Training loss: 0.07984644919633865
Validation loss: 1.4886118417145104

Epoch: 5| Step: 3
Training loss: 0.06428997218608856
Validation loss: 1.5441506754967473

Epoch: 5| Step: 4
Training loss: 0.09153491258621216
Validation loss: 1.5268656079487135

Epoch: 5| Step: 5
Training loss: 0.09536104649305344
Validation loss: 1.5427946249643962

Epoch: 5| Step: 6
Training loss: 0.13231755793094635
Validation loss: 1.543309978259507

Epoch: 5| Step: 7
Training loss: 0.10301896184682846
Validation loss: 1.5309167574810725

Epoch: 5| Step: 8
Training loss: 0.08964463323354721
Validation loss: 1.511316531447954

Epoch: 5| Step: 9
Training loss: 0.10314621031284332
Validation loss: 1.5351729777551466

Epoch: 5| Step: 10
Training loss: 0.08184705674648285
Validation loss: 1.5199017960538146

Epoch: 478| Step: 0
Training loss: 0.05539017170667648
Validation loss: 1.5709115792346258

Epoch: 5| Step: 1
Training loss: 0.11579219251871109
Validation loss: 1.5507786786684425

Epoch: 5| Step: 2
Training loss: 0.10014347732067108
Validation loss: 1.5588612735912364

Epoch: 5| Step: 3
Training loss: 0.12686710059642792
Validation loss: 1.5735400402417747

Epoch: 5| Step: 4
Training loss: 0.09465529024600983
Validation loss: 1.5634387680279311

Epoch: 5| Step: 5
Training loss: 0.07366697490215302
Validation loss: 1.6015726097168461

Epoch: 5| Step: 6
Training loss: 0.09851120412349701
Validation loss: 1.6248857808369461

Epoch: 5| Step: 7
Training loss: 0.06809286028146744
Validation loss: 1.5719509560574767

Epoch: 5| Step: 8
Training loss: 0.1328744888305664
Validation loss: 1.592940257441613

Epoch: 5| Step: 9
Training loss: 0.11654307693243027
Validation loss: 1.596401224854172

Epoch: 5| Step: 10
Training loss: 0.14953108131885529
Validation loss: 1.5756100313637846

Epoch: 479| Step: 0
Training loss: 0.06384524703025818
Validation loss: 1.5899825762676936

Epoch: 5| Step: 1
Training loss: 0.07573074847459793
Validation loss: 1.572504940853324

Epoch: 5| Step: 2
Training loss: 0.07224190980195999
Validation loss: 1.5680017073949177

Epoch: 5| Step: 3
Training loss: 0.09593282639980316
Validation loss: 1.564883985827046

Epoch: 5| Step: 4
Training loss: 0.05525561422109604
Validation loss: 1.581807274972239

Epoch: 5| Step: 5
Training loss: 0.11862971633672714
Validation loss: 1.55697129618737

Epoch: 5| Step: 6
Training loss: 0.04204436391592026
Validation loss: 1.536565044874786

Epoch: 5| Step: 7
Training loss: 0.07058460265398026
Validation loss: 1.5467605642093125

Epoch: 5| Step: 8
Training loss: 0.08376247435808182
Validation loss: 1.544196141663418

Epoch: 5| Step: 9
Training loss: 0.13703171908855438
Validation loss: 1.5484341652162614

Epoch: 5| Step: 10
Training loss: 0.09079702943563461
Validation loss: 1.530356034155815

Epoch: 480| Step: 0
Training loss: 0.09444339573383331
Validation loss: 1.5299170529970558

Epoch: 5| Step: 1
Training loss: 0.07742665708065033
Validation loss: 1.4995567414068407

Epoch: 5| Step: 2
Training loss: 0.12361167371273041
Validation loss: 1.5244591864206458

Epoch: 5| Step: 3
Training loss: 0.138130784034729
Validation loss: 1.540626746352001

Epoch: 5| Step: 4
Training loss: 0.10320524126291275
Validation loss: 1.554369016360211

Epoch: 5| Step: 5
Training loss: 0.11000370979309082
Validation loss: 1.5450812949929187

Epoch: 5| Step: 6
Training loss: 0.08968508988618851
Validation loss: 1.5294994038920249

Epoch: 5| Step: 7
Training loss: 0.07860786467790604
Validation loss: 1.5465023504790438

Epoch: 5| Step: 8
Training loss: 0.11902357637882233
Validation loss: 1.5304188138695174

Epoch: 5| Step: 9
Training loss: 0.053533174097537994
Validation loss: 1.500458276400002

Epoch: 5| Step: 10
Training loss: 0.11847437173128128
Validation loss: 1.503307689902603

Epoch: 481| Step: 0
Training loss: 0.07766019552946091
Validation loss: 1.4980457111071515

Epoch: 5| Step: 1
Training loss: 0.1344216912984848
Validation loss: 1.510855979816888

Epoch: 5| Step: 2
Training loss: 0.04883330315351486
Validation loss: 1.5103365016239945

Epoch: 5| Step: 3
Training loss: 0.06586004793643951
Validation loss: 1.5127506076648671

Epoch: 5| Step: 4
Training loss: 0.08837445080280304
Validation loss: 1.5035229068930431

Epoch: 5| Step: 5
Training loss: 0.08315931260585785
Validation loss: 1.5513882188386814

Epoch: 5| Step: 6
Training loss: 0.11132226884365082
Validation loss: 1.5156121305240098

Epoch: 5| Step: 7
Training loss: 0.07077324390411377
Validation loss: 1.5395597257921774

Epoch: 5| Step: 8
Training loss: 0.10439612716436386
Validation loss: 1.549609858502624

Epoch: 5| Step: 9
Training loss: 0.07206417620182037
Validation loss: 1.5428283752933625

Epoch: 5| Step: 10
Training loss: 0.13882310688495636
Validation loss: 1.5281708971146615

Epoch: 482| Step: 0
Training loss: 0.11446017026901245
Validation loss: 1.5080279842499764

Epoch: 5| Step: 1
Training loss: 0.10035552829504013
Validation loss: 1.4783779850570105

Epoch: 5| Step: 2
Training loss: 0.11094236373901367
Validation loss: 1.5117030746193343

Epoch: 5| Step: 3
Training loss: 0.07449027895927429
Validation loss: 1.4872628770848757

Epoch: 5| Step: 4
Training loss: 0.09106821566820145
Validation loss: 1.532849528456247

Epoch: 5| Step: 5
Training loss: 0.1432054489850998
Validation loss: 1.5230261100235807

Epoch: 5| Step: 6
Training loss: 0.07551488280296326
Validation loss: 1.5357149326673118

Epoch: 5| Step: 7
Training loss: 0.08172523230314255
Validation loss: 1.535049533331266

Epoch: 5| Step: 8
Training loss: 0.09360122680664062
Validation loss: 1.5376642903973978

Epoch: 5| Step: 9
Training loss: 0.09037797152996063
Validation loss: 1.5423316776111562

Epoch: 5| Step: 10
Training loss: 0.10839816182851791
Validation loss: 1.558512068563892

Epoch: 483| Step: 0
Training loss: 0.10571946203708649
Validation loss: 1.5840995478373703

Epoch: 5| Step: 1
Training loss: 0.12845386564731598
Validation loss: 1.5701766142281153

Epoch: 5| Step: 2
Training loss: 0.0820428729057312
Validation loss: 1.5408843268630326

Epoch: 5| Step: 3
Training loss: 0.11017666012048721
Validation loss: 1.5412014466460033

Epoch: 5| Step: 4
Training loss: 0.08937951177358627
Validation loss: 1.5326922144941104

Epoch: 5| Step: 5
Training loss: 0.07722294330596924
Validation loss: 1.5259141588723788

Epoch: 5| Step: 6
Training loss: 0.07194171100854874
Validation loss: 1.504603346188863

Epoch: 5| Step: 7
Training loss: 0.08088958263397217
Validation loss: 1.512396212547056

Epoch: 5| Step: 8
Training loss: 0.09748818725347519
Validation loss: 1.5154885976545271

Epoch: 5| Step: 9
Training loss: 0.0691872090101242
Validation loss: 1.512503296457311

Epoch: 5| Step: 10
Training loss: 0.08522795140743256
Validation loss: 1.514432462312842

Epoch: 484| Step: 0
Training loss: 0.07804598659276962
Validation loss: 1.5323038844652073

Epoch: 5| Step: 1
Training loss: 0.04688567668199539
Validation loss: 1.5362542354932396

Epoch: 5| Step: 2
Training loss: 0.07555455714464188
Validation loss: 1.5202204194120181

Epoch: 5| Step: 3
Training loss: 0.10829246044158936
Validation loss: 1.5218051915527673

Epoch: 5| Step: 4
Training loss: 0.08282096683979034
Validation loss: 1.519848544110534

Epoch: 5| Step: 5
Training loss: 0.11033699661493301
Validation loss: 1.5371053577751241

Epoch: 5| Step: 6
Training loss: 0.05946235731244087
Validation loss: 1.5181902858518785

Epoch: 5| Step: 7
Training loss: 0.07817254960536957
Validation loss: 1.5290380306141351

Epoch: 5| Step: 8
Training loss: 0.11992426216602325
Validation loss: 1.5133702357610066

Epoch: 5| Step: 9
Training loss: 0.07565996050834656
Validation loss: 1.524062410477669

Epoch: 5| Step: 10
Training loss: 0.09008996188640594
Validation loss: 1.5421079230564896

Epoch: 485| Step: 0
Training loss: 0.0974460020661354
Validation loss: 1.5195946103783065

Epoch: 5| Step: 1
Training loss: 0.11724428087472916
Validation loss: 1.502533567849026

Epoch: 5| Step: 2
Training loss: 0.09420089423656464
Validation loss: 1.5258563333942043

Epoch: 5| Step: 3
Training loss: 0.07854514569044113
Validation loss: 1.5220121408021579

Epoch: 5| Step: 4
Training loss: 0.07383398711681366
Validation loss: 1.5309237523745465

Epoch: 5| Step: 5
Training loss: 0.0744311511516571
Validation loss: 1.5087561440724198

Epoch: 5| Step: 6
Training loss: 0.06976910680532455
Validation loss: 1.50706055343792

Epoch: 5| Step: 7
Training loss: 0.04154273495078087
Validation loss: 1.5306369758421374

Epoch: 5| Step: 8
Training loss: 0.07735840976238251
Validation loss: 1.5217365218747048

Epoch: 5| Step: 9
Training loss: 0.11671160161495209
Validation loss: 1.5402857411292292

Epoch: 5| Step: 10
Training loss: 0.10000091791152954
Validation loss: 1.5365702170197681

Epoch: 486| Step: 0
Training loss: 0.06918539106845856
Validation loss: 1.5262678291208

Epoch: 5| Step: 1
Training loss: 0.06474000215530396
Validation loss: 1.5285211468255648

Epoch: 5| Step: 2
Training loss: 0.09212984144687653
Validation loss: 1.5107488298928866

Epoch: 5| Step: 3
Training loss: 0.08326130360364914
Validation loss: 1.5179714989918534

Epoch: 5| Step: 4
Training loss: 0.10257333517074585
Validation loss: 1.5733311599300754

Epoch: 5| Step: 5
Training loss: 0.1093725934624672
Validation loss: 1.5471563621233868

Epoch: 5| Step: 6
Training loss: 0.06871558725833893
Validation loss: 1.5708257306006648

Epoch: 5| Step: 7
Training loss: 0.06645628809928894
Validation loss: 1.5634609819740377

Epoch: 5| Step: 8
Training loss: 0.0831599310040474
Validation loss: 1.5574010610580444

Epoch: 5| Step: 9
Training loss: 0.08409706503152847
Validation loss: 1.5445351895465647

Epoch: 5| Step: 10
Training loss: 0.10331279039382935
Validation loss: 1.5551061681521836

Epoch: 487| Step: 0
Training loss: 0.07885206490755081
Validation loss: 1.5235524728734007

Epoch: 5| Step: 1
Training loss: 0.13809213042259216
Validation loss: 1.536741420786868

Epoch: 5| Step: 2
Training loss: 0.11528823524713516
Validation loss: 1.5466473000023955

Epoch: 5| Step: 3
Training loss: 0.0714501440525055
Validation loss: 1.536614324456902

Epoch: 5| Step: 4
Training loss: 0.13486893475055695
Validation loss: 1.534571647644043

Epoch: 5| Step: 5
Training loss: 0.07462131977081299
Validation loss: 1.5466119666253366

Epoch: 5| Step: 6
Training loss: 0.09007126837968826
Validation loss: 1.532537212935827

Epoch: 5| Step: 7
Training loss: 0.08720070868730545
Validation loss: 1.550781903728362

Epoch: 5| Step: 8
Training loss: 0.08676022291183472
Validation loss: 1.5839386986147972

Epoch: 5| Step: 9
Training loss: 0.08467394858598709
Validation loss: 1.5965074839130524

Epoch: 5| Step: 10
Training loss: 0.09286346286535263
Validation loss: 1.5703098466319423

Epoch: 488| Step: 0
Training loss: 0.09026536345481873
Validation loss: 1.5417773723602295

Epoch: 5| Step: 1
Training loss: 0.06789486110210419
Validation loss: 1.5348962404394662

Epoch: 5| Step: 2
Training loss: 0.13048966228961945
Validation loss: 1.520958100595782

Epoch: 5| Step: 3
Training loss: 0.1093708723783493
Validation loss: 1.5241172134235341

Epoch: 5| Step: 4
Training loss: 0.08410440385341644
Validation loss: 1.5177261214102469

Epoch: 5| Step: 5
Training loss: 0.08586598187685013
Validation loss: 1.5371577630760849

Epoch: 5| Step: 6
Training loss: 0.08607129752635956
Validation loss: 1.5230562815102198

Epoch: 5| Step: 7
Training loss: 0.0889340490102768
Validation loss: 1.5143362552888933

Epoch: 5| Step: 8
Training loss: 0.04597190022468567
Validation loss: 1.5358596091629357

Epoch: 5| Step: 9
Training loss: 0.10973723977804184
Validation loss: 1.5038836899624075

Epoch: 5| Step: 10
Training loss: 0.10837866365909576
Validation loss: 1.4996713976706229

Epoch: 489| Step: 0
Training loss: 0.09117331355810165
Validation loss: 1.4893716522442397

Epoch: 5| Step: 1
Training loss: 0.10227987915277481
Validation loss: 1.495110793780255

Epoch: 5| Step: 2
Training loss: 0.1372293084859848
Validation loss: 1.519741064758711

Epoch: 5| Step: 3
Training loss: 0.08854902535676956
Validation loss: 1.490228614499492

Epoch: 5| Step: 4
Training loss: 0.11135430634021759
Validation loss: 1.5014579039747997

Epoch: 5| Step: 5
Training loss: 0.06599525362253189
Validation loss: 1.5332466991998817

Epoch: 5| Step: 6
Training loss: 0.0794147327542305
Validation loss: 1.513404735954859

Epoch: 5| Step: 7
Training loss: 0.13444775342941284
Validation loss: 1.5437985991918912

Epoch: 5| Step: 8
Training loss: 0.07770393788814545
Validation loss: 1.5634734630584717

Epoch: 5| Step: 9
Training loss: 0.08683031797409058
Validation loss: 1.537770830174928

Epoch: 5| Step: 10
Training loss: 0.07353323698043823
Validation loss: 1.532398417431821

Epoch: 490| Step: 0
Training loss: 0.08121069520711899
Validation loss: 1.5346751200255526

Epoch: 5| Step: 1
Training loss: 0.05589129775762558
Validation loss: 1.5431368453528291

Epoch: 5| Step: 2
Training loss: 0.05384153872728348
Validation loss: 1.5320651633765108

Epoch: 5| Step: 3
Training loss: 0.10914285480976105
Validation loss: 1.5168825118772444

Epoch: 5| Step: 4
Training loss: 0.06775765120983124
Validation loss: 1.5308724116253596

Epoch: 5| Step: 5
Training loss: 0.07340119779109955
Validation loss: 1.5256015177695983

Epoch: 5| Step: 6
Training loss: 0.07277068495750427
Validation loss: 1.534003270569668

Epoch: 5| Step: 7
Training loss: 0.09409835189580917
Validation loss: 1.5214752035756265

Epoch: 5| Step: 8
Training loss: 0.12251076847314835
Validation loss: 1.5183885764050227

Epoch: 5| Step: 9
Training loss: 0.0932723879814148
Validation loss: 1.5296250299740863

Epoch: 5| Step: 10
Training loss: 0.08248089253902435
Validation loss: 1.5294383148993216

Epoch: 491| Step: 0
Training loss: 0.11410228908061981
Validation loss: 1.5490152579481884

Epoch: 5| Step: 1
Training loss: 0.10469160974025726
Validation loss: 1.547935667858329

Epoch: 5| Step: 2
Training loss: 0.07600243389606476
Validation loss: 1.56560524945618

Epoch: 5| Step: 3
Training loss: 0.15385708212852478
Validation loss: 1.548609733581543

Epoch: 5| Step: 4
Training loss: 0.06381696462631226
Validation loss: 1.5825415952231294

Epoch: 5| Step: 5
Training loss: 0.0537264347076416
Validation loss: 1.5696965802100398

Epoch: 5| Step: 6
Training loss: 0.08482682704925537
Validation loss: 1.5858377730974587

Epoch: 5| Step: 7
Training loss: 0.07905890792608261
Validation loss: 1.6140670109820623

Epoch: 5| Step: 8
Training loss: 0.12906914949417114
Validation loss: 1.615962657877194

Epoch: 5| Step: 9
Training loss: 0.10182064771652222
Validation loss: 1.5864887840004378

Epoch: 5| Step: 10
Training loss: 0.057049546390771866
Validation loss: 1.574104695550857

Epoch: 492| Step: 0
Training loss: 0.0953138917684555
Validation loss: 1.5602394585968347

Epoch: 5| Step: 1
Training loss: 0.07309840619564056
Validation loss: 1.539432393607273

Epoch: 5| Step: 2
Training loss: 0.08673840016126633
Validation loss: 1.5344816471940728

Epoch: 5| Step: 3
Training loss: 0.1363796889781952
Validation loss: 1.5259721638053976

Epoch: 5| Step: 4
Training loss: 0.10365281999111176
Validation loss: 1.5183402005062308

Epoch: 5| Step: 5
Training loss: 0.09551100432872772
Validation loss: 1.505433774763538

Epoch: 5| Step: 6
Training loss: 0.07911459356546402
Validation loss: 1.5341524513818885

Epoch: 5| Step: 7
Training loss: 0.0696718692779541
Validation loss: 1.5191646416982014

Epoch: 5| Step: 8
Training loss: 0.06798063963651657
Validation loss: 1.530328118672935

Epoch: 5| Step: 9
Training loss: 0.0847110003232956
Validation loss: 1.5391007174727738

Epoch: 5| Step: 10
Training loss: 0.08144561201334
Validation loss: 1.54748829590377

Epoch: 493| Step: 0
Training loss: 0.11655162274837494
Validation loss: 1.5467008884235094

Epoch: 5| Step: 1
Training loss: 0.06651739031076431
Validation loss: 1.4933147955966253

Epoch: 5| Step: 2
Training loss: 0.09062770754098892
Validation loss: 1.5196483032677763

Epoch: 5| Step: 3
Training loss: 0.09455075860023499
Validation loss: 1.503145638332572

Epoch: 5| Step: 4
Training loss: 0.08058253675699234
Validation loss: 1.5267653939544514

Epoch: 5| Step: 5
Training loss: 0.07903581857681274
Validation loss: 1.5447389374497116

Epoch: 5| Step: 6
Training loss: 0.05346704646945
Validation loss: 1.5255040558435584

Epoch: 5| Step: 7
Training loss: 0.06529006361961365
Validation loss: 1.5392778047951319

Epoch: 5| Step: 8
Training loss: 0.08973415940999985
Validation loss: 1.566964889085421

Epoch: 5| Step: 9
Training loss: 0.09983279556035995
Validation loss: 1.5669666849156862

Epoch: 5| Step: 10
Training loss: 0.04822676628828049
Validation loss: 1.5554281896160496

Epoch: 494| Step: 0
Training loss: 0.09673898667097092
Validation loss: 1.5815595913958806

Epoch: 5| Step: 1
Training loss: 0.07835429906845093
Validation loss: 1.5840530433962423

Epoch: 5| Step: 2
Training loss: 0.06622198969125748
Validation loss: 1.5805918785833544

Epoch: 5| Step: 3
Training loss: 0.07019803673028946
Validation loss: 1.5492249650339927

Epoch: 5| Step: 4
Training loss: 0.1707754135131836
Validation loss: 1.5592579546795096

Epoch: 5| Step: 5
Training loss: 0.0851299911737442
Validation loss: 1.535914969700639

Epoch: 5| Step: 6
Training loss: 0.07088004797697067
Validation loss: 1.525038473067745

Epoch: 5| Step: 7
Training loss: 0.08578813076019287
Validation loss: 1.525562519668251

Epoch: 5| Step: 8
Training loss: 0.046906352043151855
Validation loss: 1.5446562023573025

Epoch: 5| Step: 9
Training loss: 0.09388160705566406
Validation loss: 1.527954879627433

Epoch: 5| Step: 10
Training loss: 0.078752800822258
Validation loss: 1.521815574297341

Epoch: 495| Step: 0
Training loss: 0.06989910453557968
Validation loss: 1.5153596785760695

Epoch: 5| Step: 1
Training loss: 0.08303681015968323
Validation loss: 1.5061840857228925

Epoch: 5| Step: 2
Training loss: 0.11950743198394775
Validation loss: 1.5109111929452548

Epoch: 5| Step: 3
Training loss: 0.09400969743728638
Validation loss: 1.5173004878464567

Epoch: 5| Step: 4
Training loss: 0.11498266458511353
Validation loss: 1.5009826755010953

Epoch: 5| Step: 5
Training loss: 0.0872279554605484
Validation loss: 1.5352152086073352

Epoch: 5| Step: 6
Training loss: 0.0645291656255722
Validation loss: 1.5417506989612375

Epoch: 5| Step: 7
Training loss: 0.06594564765691757
Validation loss: 1.5183715794676094

Epoch: 5| Step: 8
Training loss: 0.10641644150018692
Validation loss: 1.5093511099456458

Epoch: 5| Step: 9
Training loss: 0.07598935067653656
Validation loss: 1.5050900379816692

Epoch: 5| Step: 10
Training loss: 0.07925516366958618
Validation loss: 1.5159167410224996

Epoch: 496| Step: 0
Training loss: 0.061546266078948975
Validation loss: 1.5220258261567803

Epoch: 5| Step: 1
Training loss: 0.08822254836559296
Validation loss: 1.4999184249549784

Epoch: 5| Step: 2
Training loss: 0.09652198851108551
Validation loss: 1.489325466976371

Epoch: 5| Step: 3
Training loss: 0.14039456844329834
Validation loss: 1.4664951857700144

Epoch: 5| Step: 4
Training loss: 0.11009590327739716
Validation loss: 1.4746788714521675

Epoch: 5| Step: 5
Training loss: 0.04622754827141762
Validation loss: 1.4605684940532973

Epoch: 5| Step: 6
Training loss: 0.059160687029361725
Validation loss: 1.4909281282014744

Epoch: 5| Step: 7
Training loss: 0.03918382152915001
Validation loss: 1.4944264837490615

Epoch: 5| Step: 8
Training loss: 0.08920976519584656
Validation loss: 1.502531559236588

Epoch: 5| Step: 9
Training loss: 0.08164701610803604
Validation loss: 1.526009234048987

Epoch: 5| Step: 10
Training loss: 0.0832892581820488
Validation loss: 1.5269812281413744

Epoch: 497| Step: 0
Training loss: 0.09291728585958481
Validation loss: 1.5721619244544738

Epoch: 5| Step: 1
Training loss: 0.1321367621421814
Validation loss: 1.5526531960374566

Epoch: 5| Step: 2
Training loss: 0.09807083010673523
Validation loss: 1.5766672754800448

Epoch: 5| Step: 3
Training loss: 0.12306465953588486
Validation loss: 1.5643210616163028

Epoch: 5| Step: 4
Training loss: 0.1366981863975525
Validation loss: 1.5536499113164923

Epoch: 5| Step: 5
Training loss: 0.09980815649032593
Validation loss: 1.5765493505744523

Epoch: 5| Step: 6
Training loss: 0.12092812359333038
Validation loss: 1.530561944489838

Epoch: 5| Step: 7
Training loss: 0.08651046454906464
Validation loss: 1.5450248179897186

Epoch: 5| Step: 8
Training loss: 0.0997321829199791
Validation loss: 1.5332738161087036

Epoch: 5| Step: 9
Training loss: 0.06966827809810638
Validation loss: 1.5200373370160338

Epoch: 5| Step: 10
Training loss: 0.09118224680423737
Validation loss: 1.532362158580493

Epoch: 498| Step: 0
Training loss: 0.10758671909570694
Validation loss: 1.5368310174634379

Epoch: 5| Step: 1
Training loss: 0.09453342854976654
Validation loss: 1.52815261707511

Epoch: 5| Step: 2
Training loss: 0.09423937648534775
Validation loss: 1.5431055586825135

Epoch: 5| Step: 3
Training loss: 0.06415486335754395
Validation loss: 1.5249717722656906

Epoch: 5| Step: 4
Training loss: 0.08864511549472809
Validation loss: 1.5417145516282769

Epoch: 5| Step: 5
Training loss: 0.11401710659265518
Validation loss: 1.5291409518129082

Epoch: 5| Step: 6
Training loss: 0.10545296967029572
Validation loss: 1.5813107798176427

Epoch: 5| Step: 7
Training loss: 0.10410591214895248
Validation loss: 1.5714850656447872

Epoch: 5| Step: 8
Training loss: 0.059257954359054565
Validation loss: 1.5793368047283542

Epoch: 5| Step: 9
Training loss: 0.0730578750371933
Validation loss: 1.5865982424828313

Epoch: 5| Step: 10
Training loss: 0.08807215839624405
Validation loss: 1.6020482868276618

Epoch: 499| Step: 0
Training loss: 0.09553379565477371
Validation loss: 1.5786725308305474

Epoch: 5| Step: 1
Training loss: 0.06038770079612732
Validation loss: 1.5420290347068542

Epoch: 5| Step: 2
Training loss: 0.12365677207708359
Validation loss: 1.5182383406546809

Epoch: 5| Step: 3
Training loss: 0.07279787957668304
Validation loss: 1.5153916112838253

Epoch: 5| Step: 4
Training loss: 0.10734374821186066
Validation loss: 1.5253133991713166

Epoch: 5| Step: 5
Training loss: 0.09191711992025375
Validation loss: 1.5346228781566824

Epoch: 5| Step: 6
Training loss: 0.11246039718389511
Validation loss: 1.5568526867897279

Epoch: 5| Step: 7
Training loss: 0.116915762424469
Validation loss: 1.5763993417063067

Epoch: 5| Step: 8
Training loss: 0.11375550925731659
Validation loss: 1.5509802916998505

Epoch: 5| Step: 9
Training loss: 0.07402254641056061
Validation loss: 1.5637345570389942

Epoch: 5| Step: 10
Training loss: 0.15269479155540466
Validation loss: 1.5766650476763326

Epoch: 500| Step: 0
Training loss: 0.08973487466573715
Validation loss: 1.5362844896572891

Epoch: 5| Step: 1
Training loss: 0.06892247498035431
Validation loss: 1.5298523973393183

Epoch: 5| Step: 2
Training loss: 0.1173628568649292
Validation loss: 1.5353588775921894

Epoch: 5| Step: 3
Training loss: 0.11134542524814606
Validation loss: 1.5413740078608196

Epoch: 5| Step: 4
Training loss: 0.10628683865070343
Validation loss: 1.5116773984765495

Epoch: 5| Step: 5
Training loss: 0.1685841828584671
Validation loss: 1.4899768842163907

Epoch: 5| Step: 6
Training loss: 0.07934308052062988
Validation loss: 1.5266257486035746

Epoch: 5| Step: 7
Training loss: 0.10139290243387222
Validation loss: 1.5410447389848771

Epoch: 5| Step: 8
Training loss: 0.12211166322231293
Validation loss: 1.5632330973943074

Epoch: 5| Step: 9
Training loss: 0.12443225085735321
Validation loss: 1.5750278452391266

Epoch: 5| Step: 10
Training loss: 0.09747227281332016
Validation loss: 1.5987492171666955

Epoch: 501| Step: 0
Training loss: 0.05705461651086807
Validation loss: 1.6046694247953353

Epoch: 5| Step: 1
Training loss: 0.089204341173172
Validation loss: 1.6012847942690696

Epoch: 5| Step: 2
Training loss: 0.08431138098239899
Validation loss: 1.6032076676686604

Epoch: 5| Step: 3
Training loss: 0.05684841796755791
Validation loss: 1.5676868115701983

Epoch: 5| Step: 4
Training loss: 0.13200044631958008
Validation loss: 1.574559163021785

Epoch: 5| Step: 5
Training loss: 0.053002260625362396
Validation loss: 1.5477534673547233

Epoch: 5| Step: 6
Training loss: 0.10413167625665665
Validation loss: 1.541469717538485

Epoch: 5| Step: 7
Training loss: 0.09077689796686172
Validation loss: 1.517937449998753

Epoch: 5| Step: 8
Training loss: 0.119432233273983
Validation loss: 1.524065012572914

Epoch: 5| Step: 9
Training loss: 0.08134929090738297
Validation loss: 1.5185510907121884

Epoch: 5| Step: 10
Training loss: 0.08606740832328796
Validation loss: 1.5122760880377986

Epoch: 502| Step: 0
Training loss: 0.10911986976861954
Validation loss: 1.5133174081002512

Epoch: 5| Step: 1
Training loss: 0.11687292903661728
Validation loss: 1.5240053028188727

Epoch: 5| Step: 2
Training loss: 0.10239250957965851
Validation loss: 1.5234186803140948

Epoch: 5| Step: 3
Training loss: 0.12175197899341583
Validation loss: 1.5317603721413562

Epoch: 5| Step: 4
Training loss: 0.11346454918384552
Validation loss: 1.5504650556912987

Epoch: 5| Step: 5
Training loss: 0.0741204172372818
Validation loss: 1.5305190676002092

Epoch: 5| Step: 6
Training loss: 0.04289858788251877
Validation loss: 1.543361568963656

Epoch: 5| Step: 7
Training loss: 0.07929950952529907
Validation loss: 1.5701307609517088

Epoch: 5| Step: 8
Training loss: 0.1249973401427269
Validation loss: 1.5470449847559775

Epoch: 5| Step: 9
Training loss: 0.09235966205596924
Validation loss: 1.5673989621541833

Epoch: 5| Step: 10
Training loss: 0.09973916411399841
Validation loss: 1.5213157848645282

Epoch: 503| Step: 0
Training loss: 0.0870416909456253
Validation loss: 1.5228558099398048

Epoch: 5| Step: 1
Training loss: 0.10898421704769135
Validation loss: 1.5331852230974423

Epoch: 5| Step: 2
Training loss: 0.08614896237850189
Validation loss: 1.56302898417237

Epoch: 5| Step: 3
Training loss: 0.08161450922489166
Validation loss: 1.5738178273682952

Epoch: 5| Step: 4
Training loss: 0.12196304649114609
Validation loss: 1.5621038534307992

Epoch: 5| Step: 5
Training loss: 0.1430741846561432
Validation loss: 1.5674833059310913

Epoch: 5| Step: 6
Training loss: 0.10957811772823334
Validation loss: 1.5941339026215255

Epoch: 5| Step: 7
Training loss: 0.09008427709341049
Validation loss: 1.587722025250876

Epoch: 5| Step: 8
Training loss: 0.07613915205001831
Validation loss: 1.5847336258939517

Epoch: 5| Step: 9
Training loss: 0.12630796432495117
Validation loss: 1.5609311096129879

Epoch: 5| Step: 10
Training loss: 0.06642644107341766
Validation loss: 1.5866835258340324

Epoch: 504| Step: 0
Training loss: 0.12220245599746704
Validation loss: 1.5620901853807512

Epoch: 5| Step: 1
Training loss: 0.06827307492494583
Validation loss: 1.5716300433681858

Epoch: 5| Step: 2
Training loss: 0.11794016510248184
Validation loss: 1.5461380725265832

Epoch: 5| Step: 3
Training loss: 0.10133783519268036
Validation loss: 1.5694714899986022

Epoch: 5| Step: 4
Training loss: 0.10396041721105576
Validation loss: 1.5644957506528465

Epoch: 5| Step: 5
Training loss: 0.10607042163610458
Validation loss: 1.5286832060865176

Epoch: 5| Step: 6
Training loss: 0.12719880044460297
Validation loss: 1.562516281681676

Epoch: 5| Step: 7
Training loss: 0.10804302990436554
Validation loss: 1.5600601216798187

Epoch: 5| Step: 8
Training loss: 0.09762443602085114
Validation loss: 1.5386407349699287

Epoch: 5| Step: 9
Training loss: 0.057053662836551666
Validation loss: 1.5663751081753803

Epoch: 5| Step: 10
Training loss: 0.12946075201034546
Validation loss: 1.5551062591614262

Epoch: 505| Step: 0
Training loss: 0.05602200701832771
Validation loss: 1.5389505586316508

Epoch: 5| Step: 1
Training loss: 0.0771544799208641
Validation loss: 1.5493168074597594

Epoch: 5| Step: 2
Training loss: 0.10051421821117401
Validation loss: 1.5913164936086184

Epoch: 5| Step: 3
Training loss: 0.07449130713939667
Validation loss: 1.5745729541265836

Epoch: 5| Step: 4
Training loss: 0.09514642506837845
Validation loss: 1.5328463995328514

Epoch: 5| Step: 5
Training loss: 0.09014932811260223
Validation loss: 1.5537563011210451

Epoch: 5| Step: 6
Training loss: 0.07569271326065063
Validation loss: 1.524731602720035

Epoch: 5| Step: 7
Training loss: 0.06350149214267731
Validation loss: 1.5382786591847737

Epoch: 5| Step: 8
Training loss: 0.10182566940784454
Validation loss: 1.5324459633519572

Epoch: 5| Step: 9
Training loss: 0.07626403868198395
Validation loss: 1.516970178132416

Epoch: 5| Step: 10
Training loss: 0.10684079676866531
Validation loss: 1.5388267322253155

Epoch: 506| Step: 0
Training loss: 0.06105996295809746
Validation loss: 1.535378397151988

Epoch: 5| Step: 1
Training loss: 0.05188041925430298
Validation loss: 1.5344571874987694

Epoch: 5| Step: 2
Training loss: 0.06545113027095795
Validation loss: 1.546025465893489

Epoch: 5| Step: 3
Training loss: 0.0493229441344738
Validation loss: 1.5809627784195768

Epoch: 5| Step: 4
Training loss: 0.11446446180343628
Validation loss: 1.5318497867994412

Epoch: 5| Step: 5
Training loss: 0.10729119926691055
Validation loss: 1.5196537535677674

Epoch: 5| Step: 6
Training loss: 0.0963730439543724
Validation loss: 1.530035759813042

Epoch: 5| Step: 7
Training loss: 0.10637763887643814
Validation loss: 1.5095704883657477

Epoch: 5| Step: 8
Training loss: 0.037451840937137604
Validation loss: 1.4869627760302635

Epoch: 5| Step: 9
Training loss: 0.04308142513036728
Validation loss: 1.5103722003198439

Epoch: 5| Step: 10
Training loss: 0.09247087687253952
Validation loss: 1.5182447600108322

Epoch: 507| Step: 0
Training loss: 0.09295233339071274
Validation loss: 1.5335446301326956

Epoch: 5| Step: 1
Training loss: 0.06816979497671127
Validation loss: 1.5196215503959245

Epoch: 5| Step: 2
Training loss: 0.05255531147122383
Validation loss: 1.5359077940705002

Epoch: 5| Step: 3
Training loss: 0.06366805732250214
Validation loss: 1.5161876191375077

Epoch: 5| Step: 4
Training loss: 0.11873547732830048
Validation loss: 1.5397159719979892

Epoch: 5| Step: 5
Training loss: 0.09650737047195435
Validation loss: 1.5594550698034224

Epoch: 5| Step: 6
Training loss: 0.08538813143968582
Validation loss: 1.5651567418088195

Epoch: 5| Step: 7
Training loss: 0.09976701438426971
Validation loss: 1.5553508317598732

Epoch: 5| Step: 8
Training loss: 0.12157011032104492
Validation loss: 1.5821715375428558

Epoch: 5| Step: 9
Training loss: 0.05505209416151047
Validation loss: 1.5264205830071562

Epoch: 5| Step: 10
Training loss: 0.06636802107095718
Validation loss: 1.5049624994236936

Epoch: 508| Step: 0
Training loss: 0.07834113389253616
Validation loss: 1.519078964828163

Epoch: 5| Step: 1
Training loss: 0.08027322590351105
Validation loss: 1.530685649123243

Epoch: 5| Step: 2
Training loss: 0.08901315182447433
Validation loss: 1.5270289759482107

Epoch: 5| Step: 3
Training loss: 0.14169345796108246
Validation loss: 1.4750246822193105

Epoch: 5| Step: 4
Training loss: 0.07880431413650513
Validation loss: 1.5077013559238885

Epoch: 5| Step: 5
Training loss: 0.11052920669317245
Validation loss: 1.4966748606774114

Epoch: 5| Step: 6
Training loss: 0.05854713171720505
Validation loss: 1.4853542376590032

Epoch: 5| Step: 7
Training loss: 0.13418832421302795
Validation loss: 1.473046814882627

Epoch: 5| Step: 8
Training loss: 0.06927429139614105
Validation loss: 1.474934095977455

Epoch: 5| Step: 9
Training loss: 0.06530176103115082
Validation loss: 1.5044974543715035

Epoch: 5| Step: 10
Training loss: 0.06601088494062424
Validation loss: 1.500542873977333

Epoch: 509| Step: 0
Training loss: 0.10718420892953873
Validation loss: 1.4905340145992976

Epoch: 5| Step: 1
Training loss: 0.10961451381444931
Validation loss: 1.483152840727119

Epoch: 5| Step: 2
Training loss: 0.13004255294799805
Validation loss: 1.5110738738890617

Epoch: 5| Step: 3
Training loss: 0.09064511954784393
Validation loss: 1.4962424821751092

Epoch: 5| Step: 4
Training loss: 0.08352158963680267
Validation loss: 1.506470602045777

Epoch: 5| Step: 5
Training loss: 0.08637449145317078
Validation loss: 1.4905244522197272

Epoch: 5| Step: 6
Training loss: 0.0845467820763588
Validation loss: 1.499265783576555

Epoch: 5| Step: 7
Training loss: 0.09559589624404907
Validation loss: 1.4827775404017458

Epoch: 5| Step: 8
Training loss: 0.08683176338672638
Validation loss: 1.4920637722938292

Epoch: 5| Step: 9
Training loss: 0.10919499397277832
Validation loss: 1.5155445157840688

Epoch: 5| Step: 10
Training loss: 0.08333797752857208
Validation loss: 1.5106227039009013

Epoch: 510| Step: 0
Training loss: 0.1320219188928604
Validation loss: 1.5167681247957292

Epoch: 5| Step: 1
Training loss: 0.1022433266043663
Validation loss: 1.5243070458853116

Epoch: 5| Step: 2
Training loss: 0.08497728407382965
Validation loss: 1.5512445178083194

Epoch: 5| Step: 3
Training loss: 0.17395734786987305
Validation loss: 1.5478506370257306

Epoch: 5| Step: 4
Training loss: 0.08589913696050644
Validation loss: 1.5378341540213554

Epoch: 5| Step: 5
Training loss: 0.058085549622774124
Validation loss: 1.5173597265315313

Epoch: 5| Step: 6
Training loss: 0.06244794279336929
Validation loss: 1.5309219475715392

Epoch: 5| Step: 7
Training loss: 0.08898179978132248
Validation loss: 1.5019995986774404

Epoch: 5| Step: 8
Training loss: 0.07439171522855759
Validation loss: 1.5007199330996441

Epoch: 5| Step: 9
Training loss: 0.09222275763750076
Validation loss: 1.5377202662088538

Epoch: 5| Step: 10
Training loss: 0.18814614415168762
Validation loss: 1.5102525359840804

Epoch: 511| Step: 0
Training loss: 0.07657751441001892
Validation loss: 1.5044987663145988

Epoch: 5| Step: 1
Training loss: 0.13403746485710144
Validation loss: 1.5359691855727986

Epoch: 5| Step: 2
Training loss: 0.10235589742660522
Validation loss: 1.5314065435881257

Epoch: 5| Step: 3
Training loss: 0.06637584418058395
Validation loss: 1.537576183196037

Epoch: 5| Step: 4
Training loss: 0.110517218708992
Validation loss: 1.5271437924395326

Epoch: 5| Step: 5
Training loss: 0.07993102818727493
Validation loss: 1.5620469752178396

Epoch: 5| Step: 6
Training loss: 0.08099327981472015
Validation loss: 1.5538040091914516

Epoch: 5| Step: 7
Training loss: 0.11909294128417969
Validation loss: 1.5536470759299494

Epoch: 5| Step: 8
Training loss: 0.07366223633289337
Validation loss: 1.5503324667612712

Epoch: 5| Step: 9
Training loss: 0.07336051017045975
Validation loss: 1.5341393127236316

Epoch: 5| Step: 10
Training loss: 0.07546352595090866
Validation loss: 1.5289406590564276

Epoch: 512| Step: 0
Training loss: 0.08439916372299194
Validation loss: 1.5454530523669334

Epoch: 5| Step: 1
Training loss: 0.08255596458911896
Validation loss: 1.5217032240283104

Epoch: 5| Step: 2
Training loss: 0.09962423145771027
Validation loss: 1.5570664046913065

Epoch: 5| Step: 3
Training loss: 0.08127272129058838
Validation loss: 1.5671020938504128

Epoch: 5| Step: 4
Training loss: 0.10172146558761597
Validation loss: 1.570256115287863

Epoch: 5| Step: 5
Training loss: 0.10869555175304413
Validation loss: 1.5602553416323919

Epoch: 5| Step: 6
Training loss: 0.15131598711013794
Validation loss: 1.5465894065877444

Epoch: 5| Step: 7
Training loss: 0.0656934604048729
Validation loss: 1.5200644129066057

Epoch: 5| Step: 8
Training loss: 0.050190459936857224
Validation loss: 1.5147649844487507

Epoch: 5| Step: 9
Training loss: 0.09074542671442032
Validation loss: 1.5125038264900126

Epoch: 5| Step: 10
Training loss: 0.05243639275431633
Validation loss: 1.5197064953465615

Epoch: 513| Step: 0
Training loss: 0.056479256600141525
Validation loss: 1.512705404912272

Epoch: 5| Step: 1
Training loss: 0.06769253313541412
Validation loss: 1.5130890005378312

Epoch: 5| Step: 2
Training loss: 0.07408298552036285
Validation loss: 1.5024237716069786

Epoch: 5| Step: 3
Training loss: 0.13160587847232819
Validation loss: 1.5067167006513125

Epoch: 5| Step: 4
Training loss: 0.07406170666217804
Validation loss: 1.525563673306537

Epoch: 5| Step: 5
Training loss: 0.07433760166168213
Validation loss: 1.5147571050992577

Epoch: 5| Step: 6
Training loss: 0.09802547842264175
Validation loss: 1.5283612025681363

Epoch: 5| Step: 7
Training loss: 0.12267392873764038
Validation loss: 1.5478803227024693

Epoch: 5| Step: 8
Training loss: 0.07823421061038971
Validation loss: 1.5483143842348488

Epoch: 5| Step: 9
Training loss: 0.11202146857976913
Validation loss: 1.551283105727165

Epoch: 5| Step: 10
Training loss: 0.06671442836523056
Validation loss: 1.5625793728777158

Epoch: 514| Step: 0
Training loss: 0.08283142745494843
Validation loss: 1.5827639026026572

Epoch: 5| Step: 1
Training loss: 0.047164298593997955
Validation loss: 1.5740052179623676

Epoch: 5| Step: 2
Training loss: 0.12345592677593231
Validation loss: 1.5878551313954015

Epoch: 5| Step: 3
Training loss: 0.05860058590769768
Validation loss: 1.593235646524737

Epoch: 5| Step: 4
Training loss: 0.1047641783952713
Validation loss: 1.5850088480980165

Epoch: 5| Step: 5
Training loss: 0.07611220329999924
Validation loss: 1.5761219378440612

Epoch: 5| Step: 6
Training loss: 0.10245728492736816
Validation loss: 1.591387528245167

Epoch: 5| Step: 7
Training loss: 0.05914067104458809
Validation loss: 1.5668339421672206

Epoch: 5| Step: 8
Training loss: 0.1058177575469017
Validation loss: 1.57914860017838

Epoch: 5| Step: 9
Training loss: 0.05617569759488106
Validation loss: 1.5728237878891729

Epoch: 5| Step: 10
Training loss: 0.07067990303039551
Validation loss: 1.545551553849251

Epoch: 515| Step: 0
Training loss: 0.048061974346637726
Validation loss: 1.5408982384589411

Epoch: 5| Step: 1
Training loss: 0.07909245043992996
Validation loss: 1.552524180822475

Epoch: 5| Step: 2
Training loss: 0.09012793004512787
Validation loss: 1.536559102355793

Epoch: 5| Step: 3
Training loss: 0.10651735961437225
Validation loss: 1.5148870214339225

Epoch: 5| Step: 4
Training loss: 0.08317766338586807
Validation loss: 1.5309490221802906

Epoch: 5| Step: 5
Training loss: 0.10992100089788437
Validation loss: 1.5194570479854461

Epoch: 5| Step: 6
Training loss: 0.08226503431797028
Validation loss: 1.500503873312345

Epoch: 5| Step: 7
Training loss: 0.04708530753850937
Validation loss: 1.4935660541698497

Epoch: 5| Step: 8
Training loss: 0.0928017795085907
Validation loss: 1.4969276907623454

Epoch: 5| Step: 9
Training loss: 0.06953056156635284
Validation loss: 1.49943995347587

Epoch: 5| Step: 10
Training loss: 0.07773636281490326
Validation loss: 1.5049315767903482

Epoch: 516| Step: 0
Training loss: 0.065962053835392
Validation loss: 1.4740713142579602

Epoch: 5| Step: 1
Training loss: 0.07501302659511566
Validation loss: 1.5208344869716193

Epoch: 5| Step: 2
Training loss: 0.10874668508768082
Validation loss: 1.5482991498003724

Epoch: 5| Step: 3
Training loss: 0.07866843789815903
Validation loss: 1.5566579013742425

Epoch: 5| Step: 4
Training loss: 0.08592713624238968
Validation loss: 1.5900111441971154

Epoch: 5| Step: 5
Training loss: 0.09387314319610596
Validation loss: 1.557659742652729

Epoch: 5| Step: 6
Training loss: 0.0863257348537445
Validation loss: 1.553748555080865

Epoch: 5| Step: 7
Training loss: 0.04691702127456665
Validation loss: 1.5231023526960803

Epoch: 5| Step: 8
Training loss: 0.056668829172849655
Validation loss: 1.5162681507807907

Epoch: 5| Step: 9
Training loss: 0.07453000545501709
Validation loss: 1.5161795795604747

Epoch: 5| Step: 10
Training loss: 0.06802336126565933
Validation loss: 1.5313854653348205

Epoch: 517| Step: 0
Training loss: 0.07747912406921387
Validation loss: 1.535936104354038

Epoch: 5| Step: 1
Training loss: 0.08473125845193863
Validation loss: 1.5349702347991288

Epoch: 5| Step: 2
Training loss: 0.08010619878768921
Validation loss: 1.5075117516261276

Epoch: 5| Step: 3
Training loss: 0.06646320223808289
Validation loss: 1.510434127623035

Epoch: 5| Step: 4
Training loss: 0.08298121392726898
Validation loss: 1.5029693803479593

Epoch: 5| Step: 5
Training loss: 0.05192223936319351
Validation loss: 1.499387143760599

Epoch: 5| Step: 6
Training loss: 0.06343147903680801
Validation loss: 1.53033612620446

Epoch: 5| Step: 7
Training loss: 0.0907900482416153
Validation loss: 1.5571090123986686

Epoch: 5| Step: 8
Training loss: 0.07865846902132034
Validation loss: 1.5558418073961813

Epoch: 5| Step: 9
Training loss: 0.09583165496587753
Validation loss: 1.5389704127465524

Epoch: 5| Step: 10
Training loss: 0.07084248960018158
Validation loss: 1.532681772785802

Epoch: 518| Step: 0
Training loss: 0.060049355030059814
Validation loss: 1.519291450259506

Epoch: 5| Step: 1
Training loss: 0.05977655202150345
Validation loss: 1.5332270565853323

Epoch: 5| Step: 2
Training loss: 0.06409870833158493
Validation loss: 1.5115190321399319

Epoch: 5| Step: 3
Training loss: 0.07381094247102737
Validation loss: 1.554926282616072

Epoch: 5| Step: 4
Training loss: 0.08684374392032623
Validation loss: 1.5508304706183813

Epoch: 5| Step: 5
Training loss: 0.08854906260967255
Validation loss: 1.5434229438022902

Epoch: 5| Step: 6
Training loss: 0.061284907162189484
Validation loss: 1.5219523996435187

Epoch: 5| Step: 7
Training loss: 0.12628673017024994
Validation loss: 1.5340716582472607

Epoch: 5| Step: 8
Training loss: 0.0557713620364666
Validation loss: 1.4977001675995447

Epoch: 5| Step: 9
Training loss: 0.04902585595846176
Validation loss: 1.5333166686437463

Epoch: 5| Step: 10
Training loss: 0.03950415924191475
Validation loss: 1.5338585684376378

Epoch: 519| Step: 0
Training loss: 0.0560779795050621
Validation loss: 1.5525681229047879

Epoch: 5| Step: 1
Training loss: 0.09783235192298889
Validation loss: 1.5418059582351356

Epoch: 5| Step: 2
Training loss: 0.1040194034576416
Validation loss: 1.5621201838216474

Epoch: 5| Step: 3
Training loss: 0.06631477922201157
Validation loss: 1.569228651703045

Epoch: 5| Step: 4
Training loss: 0.05859031528234482
Validation loss: 1.54816847719172

Epoch: 5| Step: 5
Training loss: 0.07003545016050339
Validation loss: 1.5401644091452322

Epoch: 5| Step: 6
Training loss: 0.08646957576274872
Validation loss: 1.5689326319643246

Epoch: 5| Step: 7
Training loss: 0.04739215597510338
Validation loss: 1.5319868274914321

Epoch: 5| Step: 8
Training loss: 0.09101174026727676
Validation loss: 1.538362435115281

Epoch: 5| Step: 9
Training loss: 0.07262171804904938
Validation loss: 1.5140484558638705

Epoch: 5| Step: 10
Training loss: 0.05943484976887703
Validation loss: 1.5028625303699124

Epoch: 520| Step: 0
Training loss: 0.05743824690580368
Validation loss: 1.5258262003621748

Epoch: 5| Step: 1
Training loss: 0.06970513612031937
Validation loss: 1.5402511640261578

Epoch: 5| Step: 2
Training loss: 0.08911868184804916
Validation loss: 1.5239442394625755

Epoch: 5| Step: 3
Training loss: 0.06469177454710007
Validation loss: 1.515698221422011

Epoch: 5| Step: 4
Training loss: 0.0485248789191246
Validation loss: 1.5184522162201584

Epoch: 5| Step: 5
Training loss: 0.06185455992817879
Validation loss: 1.5030481892247354

Epoch: 5| Step: 6
Training loss: 0.06556055694818497
Validation loss: 1.5286590040370982

Epoch: 5| Step: 7
Training loss: 0.08642947673797607
Validation loss: 1.5326299680176603

Epoch: 5| Step: 8
Training loss: 0.0866309404373169
Validation loss: 1.523262195689704

Epoch: 5| Step: 9
Training loss: 0.10575659573078156
Validation loss: 1.5278684439197663

Epoch: 5| Step: 10
Training loss: 0.08049213886260986
Validation loss: 1.5295528211901266

Epoch: 521| Step: 0
Training loss: 0.07068222016096115
Validation loss: 1.5197777446880136

Epoch: 5| Step: 1
Training loss: 0.08091256767511368
Validation loss: 1.5208194537829327

Epoch: 5| Step: 2
Training loss: 0.04953461140394211
Validation loss: 1.5346418465337446

Epoch: 5| Step: 3
Training loss: 0.0649237111210823
Validation loss: 1.504216291571176

Epoch: 5| Step: 4
Training loss: 0.10182908922433853
Validation loss: 1.5382097844154603

Epoch: 5| Step: 5
Training loss: 0.07509428262710571
Validation loss: 1.551562855320592

Epoch: 5| Step: 6
Training loss: 0.06279237568378448
Validation loss: 1.5357937248804236

Epoch: 5| Step: 7
Training loss: 0.08649592101573944
Validation loss: 1.5462060641216975

Epoch: 5| Step: 8
Training loss: 0.05325573682785034
Validation loss: 1.5691138736663326

Epoch: 5| Step: 9
Training loss: 0.0600893497467041
Validation loss: 1.5645762630688247

Epoch: 5| Step: 10
Training loss: 0.09822671860456467
Validation loss: 1.5808475709730578

Epoch: 522| Step: 0
Training loss: 0.102996326982975
Validation loss: 1.5548409441465973

Epoch: 5| Step: 1
Training loss: 0.05770479515194893
Validation loss: 1.5773544170523202

Epoch: 5| Step: 2
Training loss: 0.061855755746364594
Validation loss: 1.5756780165497974

Epoch: 5| Step: 3
Training loss: 0.05905186012387276
Validation loss: 1.5295256158357025

Epoch: 5| Step: 4
Training loss: 0.07599248737096786
Validation loss: 1.5557811837042532

Epoch: 5| Step: 5
Training loss: 0.10268115997314453
Validation loss: 1.5303973818338046

Epoch: 5| Step: 6
Training loss: 0.07720056921243668
Validation loss: 1.5531248930961854

Epoch: 5| Step: 7
Training loss: 0.07848452031612396
Validation loss: 1.5265085261355165

Epoch: 5| Step: 8
Training loss: 0.04803764820098877
Validation loss: 1.5225884401670067

Epoch: 5| Step: 9
Training loss: 0.05639401823282242
Validation loss: 1.5450164515485045

Epoch: 5| Step: 10
Training loss: 0.07119745016098022
Validation loss: 1.5568707450743644

Epoch: 523| Step: 0
Training loss: 0.07352133095264435
Validation loss: 1.5513649025271017

Epoch: 5| Step: 1
Training loss: 0.0901855006814003
Validation loss: 1.5170773254927767

Epoch: 5| Step: 2
Training loss: 0.10703454911708832
Validation loss: 1.5185790036314277

Epoch: 5| Step: 3
Training loss: 0.08957483619451523
Validation loss: 1.525767603228169

Epoch: 5| Step: 4
Training loss: 0.10904522240161896
Validation loss: 1.5317687719098982

Epoch: 5| Step: 5
Training loss: 0.06422404944896698
Validation loss: 1.5120581644837574

Epoch: 5| Step: 6
Training loss: 0.09281933307647705
Validation loss: 1.5138844751542615

Epoch: 5| Step: 7
Training loss: 0.06016470864415169
Validation loss: 1.532431133331791

Epoch: 5| Step: 8
Training loss: 0.04864274337887764
Validation loss: 1.50927718224064

Epoch: 5| Step: 9
Training loss: 0.05606444552540779
Validation loss: 1.537660680791383

Epoch: 5| Step: 10
Training loss: 0.09615734219551086
Validation loss: 1.5641741694942597

Epoch: 524| Step: 0
Training loss: 0.1393205225467682
Validation loss: 1.572198962652555

Epoch: 5| Step: 1
Training loss: 0.11590196192264557
Validation loss: 1.5450737655803721

Epoch: 5| Step: 2
Training loss: 0.058737725019454956
Validation loss: 1.5236321700516569

Epoch: 5| Step: 3
Training loss: 0.07186514884233475
Validation loss: 1.5050326342223792

Epoch: 5| Step: 4
Training loss: 0.08726310729980469
Validation loss: 1.5137752243267593

Epoch: 5| Step: 5
Training loss: 0.1257360726594925
Validation loss: 1.5197593576164656

Epoch: 5| Step: 6
Training loss: 0.09630472958087921
Validation loss: 1.5009457577941239

Epoch: 5| Step: 7
Training loss: 0.098772332072258
Validation loss: 1.471059810730719

Epoch: 5| Step: 8
Training loss: 0.09032387286424637
Validation loss: 1.4828735372071624

Epoch: 5| Step: 9
Training loss: 0.12285493314266205
Validation loss: 1.4732286891629618

Epoch: 5| Step: 10
Training loss: 0.07519763708114624
Validation loss: 1.4747177554715065

Epoch: 525| Step: 0
Training loss: 0.07519595324993134
Validation loss: 1.4725731034432687

Epoch: 5| Step: 1
Training loss: 0.06686043739318848
Validation loss: 1.5273154730437903

Epoch: 5| Step: 2
Training loss: 0.0698360949754715
Validation loss: 1.53072178235618

Epoch: 5| Step: 3
Training loss: 0.1258157193660736
Validation loss: 1.517812680172664

Epoch: 5| Step: 4
Training loss: 0.07068236917257309
Validation loss: 1.5382962919050647

Epoch: 5| Step: 5
Training loss: 0.0680544376373291
Validation loss: 1.5699315148015176

Epoch: 5| Step: 6
Training loss: 0.09951094537973404
Validation loss: 1.5815549024971582

Epoch: 5| Step: 7
Training loss: 0.10152001678943634
Validation loss: 1.5674327227377123

Epoch: 5| Step: 8
Training loss: 0.08237823843955994
Validation loss: 1.5618226784531788

Epoch: 5| Step: 9
Training loss: 0.08772467076778412
Validation loss: 1.5700439253161032

Epoch: 5| Step: 10
Training loss: 0.10361450910568237
Validation loss: 1.5658095184192862

Epoch: 526| Step: 0
Training loss: 0.07831811159849167
Validation loss: 1.5405613491612096

Epoch: 5| Step: 1
Training loss: 0.0744180679321289
Validation loss: 1.549546257783008

Epoch: 5| Step: 2
Training loss: 0.1273351013660431
Validation loss: 1.5450772008588236

Epoch: 5| Step: 3
Training loss: 0.16208119690418243
Validation loss: 1.5829165020296652

Epoch: 5| Step: 4
Training loss: 0.1254350244998932
Validation loss: 1.5895024166312268

Epoch: 5| Step: 5
Training loss: 0.11556670814752579
Validation loss: 1.562283415948191

Epoch: 5| Step: 6
Training loss: 0.08474560081958771
Validation loss: 1.5525209237170476

Epoch: 5| Step: 7
Training loss: 0.08941041678190231
Validation loss: 1.5700498659123656

Epoch: 5| Step: 8
Training loss: 0.12266997992992401
Validation loss: 1.5673606267539404

Epoch: 5| Step: 9
Training loss: 0.09005579352378845
Validation loss: 1.593426207060455

Epoch: 5| Step: 10
Training loss: 0.06936920434236526
Validation loss: 1.6144155879174509

Epoch: 527| Step: 0
Training loss: 0.12910667061805725
Validation loss: 1.5987084616896927

Epoch: 5| Step: 1
Training loss: 0.13006892800331116
Validation loss: 1.6254143740541191

Epoch: 5| Step: 2
Training loss: 0.16374510526657104
Validation loss: 1.5507060289382935

Epoch: 5| Step: 3
Training loss: 0.06075970083475113
Validation loss: 1.5388940124101536

Epoch: 5| Step: 4
Training loss: 0.07133013010025024
Validation loss: 1.5299542129680674

Epoch: 5| Step: 5
Training loss: 0.10805201530456543
Validation loss: 1.5600521090210124

Epoch: 5| Step: 6
Training loss: 0.10412962734699249
Validation loss: 1.5382572233036

Epoch: 5| Step: 7
Training loss: 0.10392715036869049
Validation loss: 1.5152392579663185

Epoch: 5| Step: 8
Training loss: 0.06780607998371124
Validation loss: 1.500143503630033

Epoch: 5| Step: 9
Training loss: 0.10105971992015839
Validation loss: 1.4763723823332018

Epoch: 5| Step: 10
Training loss: 0.06054387241601944
Validation loss: 1.496029148819626

Epoch: 528| Step: 0
Training loss: 0.07291015237569809
Validation loss: 1.5066145350856166

Epoch: 5| Step: 1
Training loss: 0.0940069779753685
Validation loss: 1.4750274970967283

Epoch: 5| Step: 2
Training loss: 0.07027161866426468
Validation loss: 1.4582289982867498

Epoch: 5| Step: 3
Training loss: 0.10180026292800903
Validation loss: 1.4853579100742136

Epoch: 5| Step: 4
Training loss: 0.08057969808578491
Validation loss: 1.503153783018871

Epoch: 5| Step: 5
Training loss: 0.09273627400398254
Validation loss: 1.5166607505531722

Epoch: 5| Step: 6
Training loss: 0.07845412194728851
Validation loss: 1.5107726666235155

Epoch: 5| Step: 7
Training loss: 0.09706036001443863
Validation loss: 1.526582811468391

Epoch: 5| Step: 8
Training loss: 0.12485049664974213
Validation loss: 1.5213482277367705

Epoch: 5| Step: 9
Training loss: 0.05833573266863823
Validation loss: 1.5168035696911555

Epoch: 5| Step: 10
Training loss: 0.06877914071083069
Validation loss: 1.5124462817304878

Epoch: 529| Step: 0
Training loss: 0.10172832012176514
Validation loss: 1.4989439809835086

Epoch: 5| Step: 1
Training loss: 0.05909610539674759
Validation loss: 1.5029290087761418

Epoch: 5| Step: 2
Training loss: 0.09175919741392136
Validation loss: 1.4865946487713886

Epoch: 5| Step: 3
Training loss: 0.08440212905406952
Validation loss: 1.5153749053196242

Epoch: 5| Step: 4
Training loss: 0.07067838311195374
Validation loss: 1.5023727839992893

Epoch: 5| Step: 5
Training loss: 0.10131168365478516
Validation loss: 1.5284193638832337

Epoch: 5| Step: 6
Training loss: 0.057723261415958405
Validation loss: 1.4934193998254754

Epoch: 5| Step: 7
Training loss: 0.12953007221221924
Validation loss: 1.5604313535075034

Epoch: 5| Step: 8
Training loss: 0.05447802692651749
Validation loss: 1.5084484982234176

Epoch: 5| Step: 9
Training loss: 0.06332091987133026
Validation loss: 1.5029672730353572

Epoch: 5| Step: 10
Training loss: 0.1076742485165596
Validation loss: 1.5103150157518284

Epoch: 530| Step: 0
Training loss: 0.07610134035348892
Validation loss: 1.517555812353729

Epoch: 5| Step: 1
Training loss: 0.07737255841493607
Validation loss: 1.498655919105776

Epoch: 5| Step: 2
Training loss: 0.06258544325828552
Validation loss: 1.493738942248847

Epoch: 5| Step: 3
Training loss: 0.0741933137178421
Validation loss: 1.4791399176402757

Epoch: 5| Step: 4
Training loss: 0.07253675162792206
Validation loss: 1.5027955732037943

Epoch: 5| Step: 5
Training loss: 0.09788919240236282
Validation loss: 1.4828333726493261

Epoch: 5| Step: 6
Training loss: 0.102605439722538
Validation loss: 1.4802270512427054

Epoch: 5| Step: 7
Training loss: 0.07642658799886703
Validation loss: 1.5179895867583573

Epoch: 5| Step: 8
Training loss: 0.09903901070356369
Validation loss: 1.4961180571586854

Epoch: 5| Step: 9
Training loss: 0.132818341255188
Validation loss: 1.5349562527031027

Epoch: 5| Step: 10
Training loss: 0.08802945166826248
Validation loss: 1.5199955573645971

Epoch: 531| Step: 0
Training loss: 0.0699455514550209
Validation loss: 1.5388641101057812

Epoch: 5| Step: 1
Training loss: 0.07035242766141891
Validation loss: 1.5214313736525915

Epoch: 5| Step: 2
Training loss: 0.05902246758341789
Validation loss: 1.5241952730763344

Epoch: 5| Step: 3
Training loss: 0.054262202233076096
Validation loss: 1.5240068307486914

Epoch: 5| Step: 4
Training loss: 0.09620879590511322
Validation loss: 1.5032632261194208

Epoch: 5| Step: 5
Training loss: 0.1097692996263504
Validation loss: 1.5253846017263268

Epoch: 5| Step: 6
Training loss: 0.1264403611421585
Validation loss: 1.5346477787981752

Epoch: 5| Step: 7
Training loss: 0.09264626353979111
Validation loss: 1.5360151055038616

Epoch: 5| Step: 8
Training loss: 0.15726760029792786
Validation loss: 1.5376042217336676

Epoch: 5| Step: 9
Training loss: 0.10276834666728973
Validation loss: 1.568688400330082

Epoch: 5| Step: 10
Training loss: 0.12719348073005676
Validation loss: 1.5251096320408646

Epoch: 532| Step: 0
Training loss: 0.10522480309009552
Validation loss: 1.5245975089329544

Epoch: 5| Step: 1
Training loss: 0.0677029937505722
Validation loss: 1.5207285791315057

Epoch: 5| Step: 2
Training loss: 0.06866093724966049
Validation loss: 1.5243977628728396

Epoch: 5| Step: 3
Training loss: 0.10070274770259857
Validation loss: 1.5131067031173295

Epoch: 5| Step: 4
Training loss: 0.09505961835384369
Validation loss: 1.4925336043039958

Epoch: 5| Step: 5
Training loss: 0.09621042013168335
Validation loss: 1.4966268488155898

Epoch: 5| Step: 6
Training loss: 0.10017712414264679
Validation loss: 1.4956733039630357

Epoch: 5| Step: 7
Training loss: 0.13296177983283997
Validation loss: 1.4676491022109985

Epoch: 5| Step: 8
Training loss: 0.05809207633137703
Validation loss: 1.5193719222981443

Epoch: 5| Step: 9
Training loss: 0.07226213067770004
Validation loss: 1.5093259631946523

Epoch: 5| Step: 10
Training loss: 0.10929044336080551
Validation loss: 1.5554437560419883

Epoch: 533| Step: 0
Training loss: 0.10107274353504181
Validation loss: 1.5748113791147869

Epoch: 5| Step: 1
Training loss: 0.12791311740875244
Validation loss: 1.5688020631831179

Epoch: 5| Step: 2
Training loss: 0.1168217882514
Validation loss: 1.574190757607901

Epoch: 5| Step: 3
Training loss: 0.09361885488033295
Validation loss: 1.583205734529803

Epoch: 5| Step: 4
Training loss: 0.09703366458415985
Validation loss: 1.5542681678648917

Epoch: 5| Step: 5
Training loss: 0.06859192997217178
Validation loss: 1.5335418831917547

Epoch: 5| Step: 6
Training loss: 0.07668236643075943
Validation loss: 1.5317050833855905

Epoch: 5| Step: 7
Training loss: 0.10247138887643814
Validation loss: 1.511413505000453

Epoch: 5| Step: 8
Training loss: 0.12187246978282928
Validation loss: 1.5271648386473298

Epoch: 5| Step: 9
Training loss: 0.0982830598950386
Validation loss: 1.5097135882223807

Epoch: 5| Step: 10
Training loss: 0.10602317005395889
Validation loss: 1.5347261300650976

Epoch: 534| Step: 0
Training loss: 0.0812331885099411
Validation loss: 1.5452524795327136

Epoch: 5| Step: 1
Training loss: 0.0750993862748146
Validation loss: 1.5331336452114968

Epoch: 5| Step: 2
Training loss: 0.04753542318940163
Validation loss: 1.5572256772748885

Epoch: 5| Step: 3
Training loss: 0.06785266846418381
Validation loss: 1.5444928881942586

Epoch: 5| Step: 4
Training loss: 0.060236118733882904
Validation loss: 1.5430798107577908

Epoch: 5| Step: 5
Training loss: 0.06491243839263916
Validation loss: 1.5237538570998816

Epoch: 5| Step: 6
Training loss: 0.11214432865381241
Validation loss: 1.5194548996545936

Epoch: 5| Step: 7
Training loss: 0.06656638532876968
Validation loss: 1.5167275808190788

Epoch: 5| Step: 8
Training loss: 0.09931173175573349
Validation loss: 1.4858233390315887

Epoch: 5| Step: 9
Training loss: 0.10952041298151016
Validation loss: 1.5360595128869499

Epoch: 5| Step: 10
Training loss: 0.10493199527263641
Validation loss: 1.4984354524202244

Epoch: 535| Step: 0
Training loss: 0.05339222401380539
Validation loss: 1.5151731711561962

Epoch: 5| Step: 1
Training loss: 0.1029050350189209
Validation loss: 1.5129298471635388

Epoch: 5| Step: 2
Training loss: 0.10438833385705948
Validation loss: 1.5030729591205556

Epoch: 5| Step: 3
Training loss: 0.08162783086299896
Validation loss: 1.5177784824884066

Epoch: 5| Step: 4
Training loss: 0.093610979616642
Validation loss: 1.506546361472017

Epoch: 5| Step: 5
Training loss: 0.085501529276371
Validation loss: 1.543309634731662

Epoch: 5| Step: 6
Training loss: 0.10618951171636581
Validation loss: 1.5328220718650407

Epoch: 5| Step: 7
Training loss: 0.10604295879602432
Validation loss: 1.5424278987351285

Epoch: 5| Step: 8
Training loss: 0.07728302478790283
Validation loss: 1.5393976191038727

Epoch: 5| Step: 9
Training loss: 0.11022236198186874
Validation loss: 1.5504504762670046

Epoch: 5| Step: 10
Training loss: 0.04702618718147278
Validation loss: 1.5461246557133173

Epoch: 536| Step: 0
Training loss: 0.06437954306602478
Validation loss: 1.5643064052827897

Epoch: 5| Step: 1
Training loss: 0.09757139533758163
Validation loss: 1.5907470282687937

Epoch: 5| Step: 2
Training loss: 0.11430777609348297
Validation loss: 1.5671664848122546

Epoch: 5| Step: 3
Training loss: 0.1041603535413742
Validation loss: 1.568653125916758

Epoch: 5| Step: 4
Training loss: 0.10367480665445328
Validation loss: 1.5507644209810483

Epoch: 5| Step: 5
Training loss: 0.057772617787122726
Validation loss: 1.5668127222727704

Epoch: 5| Step: 6
Training loss: 0.0855620950460434
Validation loss: 1.5468475408451532

Epoch: 5| Step: 7
Training loss: 0.09792686998844147
Validation loss: 1.5623565578973422

Epoch: 5| Step: 8
Training loss: 0.11279342323541641
Validation loss: 1.547152446162316

Epoch: 5| Step: 9
Training loss: 0.07370119541883469
Validation loss: 1.524532889807096

Epoch: 5| Step: 10
Training loss: 0.12617655098438263
Validation loss: 1.5238837157526324

Epoch: 537| Step: 0
Training loss: 0.09583629667758942
Validation loss: 1.5515950161923644

Epoch: 5| Step: 1
Training loss: 0.12137103080749512
Validation loss: 1.5553687567351966

Epoch: 5| Step: 2
Training loss: 0.0821215957403183
Validation loss: 1.566192215488803

Epoch: 5| Step: 3
Training loss: 0.1378418505191803
Validation loss: 1.5676375127607776

Epoch: 5| Step: 4
Training loss: 0.10001987218856812
Validation loss: 1.5805229256230016

Epoch: 5| Step: 5
Training loss: 0.06534677743911743
Validation loss: 1.5599880756870392

Epoch: 5| Step: 6
Training loss: 0.1098674088716507
Validation loss: 1.5741899859520696

Epoch: 5| Step: 7
Training loss: 0.09830983728170395
Validation loss: 1.6086035697690901

Epoch: 5| Step: 8
Training loss: 0.08808888494968414
Validation loss: 1.5880519446506296

Epoch: 5| Step: 9
Training loss: 0.08996196836233139
Validation loss: 1.6058473189671834

Epoch: 5| Step: 10
Training loss: 0.10038954019546509
Validation loss: 1.5908571468886508

Epoch: 538| Step: 0
Training loss: 0.09333852678537369
Validation loss: 1.5717114005037534

Epoch: 5| Step: 1
Training loss: 0.09061901271343231
Validation loss: 1.5440819571095128

Epoch: 5| Step: 2
Training loss: 0.062407929450273514
Validation loss: 1.5464055550995695

Epoch: 5| Step: 3
Training loss: 0.08542346954345703
Validation loss: 1.5568832184678765

Epoch: 5| Step: 4
Training loss: 0.062366437166929245
Validation loss: 1.5491472610863306

Epoch: 5| Step: 5
Training loss: 0.10750027745962143
Validation loss: 1.5713172112741778

Epoch: 5| Step: 6
Training loss: 0.06426430493593216
Validation loss: 1.5596096413109892

Epoch: 5| Step: 7
Training loss: 0.05134185403585434
Validation loss: 1.5311315392935148

Epoch: 5| Step: 8
Training loss: 0.09411770105361938
Validation loss: 1.5402336376969532

Epoch: 5| Step: 9
Training loss: 0.13653434813022614
Validation loss: 1.5164717922928512

Epoch: 5| Step: 10
Training loss: 0.09414410591125488
Validation loss: 1.5328340748304963

Epoch: 539| Step: 0
Training loss: 0.10698892921209335
Validation loss: 1.5261828655837684

Epoch: 5| Step: 1
Training loss: 0.11326529830694199
Validation loss: 1.53137469227596

Epoch: 5| Step: 2
Training loss: 0.11211857944726944
Validation loss: 1.500980346433578

Epoch: 5| Step: 3
Training loss: 0.06084615737199783
Validation loss: 1.5077714868771133

Epoch: 5| Step: 4
Training loss: 0.06323125213384628
Validation loss: 1.4937125687958093

Epoch: 5| Step: 5
Training loss: 0.09456118941307068
Validation loss: 1.4841305876290927

Epoch: 5| Step: 6
Training loss: 0.14450131356716156
Validation loss: 1.4984070921456942

Epoch: 5| Step: 7
Training loss: 0.11858495324850082
Validation loss: 1.5043747296897314

Epoch: 5| Step: 8
Training loss: 0.10064816474914551
Validation loss: 1.5009171815328701

Epoch: 5| Step: 9
Training loss: 0.12248092889785767
Validation loss: 1.4740212450745285

Epoch: 5| Step: 10
Training loss: 0.07323488593101501
Validation loss: 1.5068854785734607

Epoch: 540| Step: 0
Training loss: 0.07542119920253754
Validation loss: 1.48307700439166

Epoch: 5| Step: 1
Training loss: 0.0507417730987072
Validation loss: 1.5150796187821256

Epoch: 5| Step: 2
Training loss: 0.11223921924829483
Validation loss: 1.547652639368529

Epoch: 5| Step: 3
Training loss: 0.07774544507265091
Validation loss: 1.5623151474101569

Epoch: 5| Step: 4
Training loss: 0.09237249940633774
Validation loss: 1.5537176670566681

Epoch: 5| Step: 5
Training loss: 0.0730084776878357
Validation loss: 1.5711565863701604

Epoch: 5| Step: 6
Training loss: 0.06078321486711502
Validation loss: 1.5637041932793074

Epoch: 5| Step: 7
Training loss: 0.08225163072347641
Validation loss: 1.5933870359133648

Epoch: 5| Step: 8
Training loss: 0.1748611032962799
Validation loss: 1.5850223469477829

Epoch: 5| Step: 9
Training loss: 0.062033046036958694
Validation loss: 1.5814563035964966

Epoch: 5| Step: 10
Training loss: 0.09555698931217194
Validation loss: 1.5213464370337866

Epoch: 541| Step: 0
Training loss: 0.08778687566518784
Validation loss: 1.5161145169247863

Epoch: 5| Step: 1
Training loss: 0.09405864030122757
Validation loss: 1.5103301284133748

Epoch: 5| Step: 2
Training loss: 0.05644913762807846
Validation loss: 1.5272606111341906

Epoch: 5| Step: 3
Training loss: 0.11431382596492767
Validation loss: 1.5176973240349882

Epoch: 5| Step: 4
Training loss: 0.08064888417720795
Validation loss: 1.514120073728664

Epoch: 5| Step: 5
Training loss: 0.0927005186676979
Validation loss: 1.513256271680196

Epoch: 5| Step: 6
Training loss: 0.1079959124326706
Validation loss: 1.5491590756241993

Epoch: 5| Step: 7
Training loss: 0.12186803668737411
Validation loss: 1.5314855075651599

Epoch: 5| Step: 8
Training loss: 0.08919080346822739
Validation loss: 1.5406949065064872

Epoch: 5| Step: 9
Training loss: 0.07331029325723648
Validation loss: 1.5441096585283998

Epoch: 5| Step: 10
Training loss: 0.13286784291267395
Validation loss: 1.531872913401614

Epoch: 542| Step: 0
Training loss: 0.21184797585010529
Validation loss: 1.5509628326662126

Epoch: 5| Step: 1
Training loss: 0.12437562644481659
Validation loss: 1.5595595413638699

Epoch: 5| Step: 2
Training loss: 0.08920742571353912
Validation loss: 1.5263623768283474

Epoch: 5| Step: 3
Training loss: 0.0770149752497673
Validation loss: 1.5228376439822617

Epoch: 5| Step: 4
Training loss: 0.1225348487496376
Validation loss: 1.5261421934250863

Epoch: 5| Step: 5
Training loss: 0.08995870500802994
Validation loss: 1.5657183393355338

Epoch: 5| Step: 6
Training loss: 0.10310204327106476
Validation loss: 1.5639816407234437

Epoch: 5| Step: 7
Training loss: 0.1870325654745102
Validation loss: 1.5386331876118977

Epoch: 5| Step: 8
Training loss: 0.0812198668718338
Validation loss: 1.516219917164054

Epoch: 5| Step: 9
Training loss: 0.10964999347925186
Validation loss: 1.5165894057161065

Epoch: 5| Step: 10
Training loss: 0.1785934418439865
Validation loss: 1.5007410267347931

Epoch: 543| Step: 0
Training loss: 0.11735143512487411
Validation loss: 1.4851408081669961

Epoch: 5| Step: 1
Training loss: 0.10105916112661362
Validation loss: 1.5163818110701859

Epoch: 5| Step: 2
Training loss: 0.07237190753221512
Validation loss: 1.5597874669618503

Epoch: 5| Step: 3
Training loss: 0.1379958987236023
Validation loss: 1.5689429800997499

Epoch: 5| Step: 4
Training loss: 0.1411631852388382
Validation loss: 1.5571476156993578

Epoch: 5| Step: 5
Training loss: 0.05746016651391983
Validation loss: 1.5890204342462684

Epoch: 5| Step: 6
Training loss: 0.10012427717447281
Validation loss: 1.5837508978382233

Epoch: 5| Step: 7
Training loss: 0.11991441249847412
Validation loss: 1.5748970367575204

Epoch: 5| Step: 8
Training loss: 0.1361711621284485
Validation loss: 1.5789089382335704

Epoch: 5| Step: 9
Training loss: 0.15285900235176086
Validation loss: 1.5716957533231346

Epoch: 5| Step: 10
Training loss: 0.07227413356304169
Validation loss: 1.5595394783122565

Epoch: 544| Step: 0
Training loss: 0.09112057834863663
Validation loss: 1.5680392672938686

Epoch: 5| Step: 1
Training loss: 0.07497278600931168
Validation loss: 1.56435630782958

Epoch: 5| Step: 2
Training loss: 0.09051140397787094
Validation loss: 1.5349742686876686

Epoch: 5| Step: 3
Training loss: 0.0991276353597641
Validation loss: 1.521520831251657

Epoch: 5| Step: 4
Training loss: 0.0866554006934166
Validation loss: 1.513937283587712

Epoch: 5| Step: 5
Training loss: 0.09005027264356613
Validation loss: 1.5047814615311161

Epoch: 5| Step: 6
Training loss: 0.07910000532865524
Validation loss: 1.482403894906403

Epoch: 5| Step: 7
Training loss: 0.14056523144245148
Validation loss: 1.4993375129597162

Epoch: 5| Step: 8
Training loss: 0.12045519053936005
Validation loss: 1.5102150132579188

Epoch: 5| Step: 9
Training loss: 0.09525229781866074
Validation loss: 1.5120378604499243

Epoch: 5| Step: 10
Training loss: 0.13551898300647736
Validation loss: 1.5224027044029647

Epoch: 545| Step: 0
Training loss: 0.14625689387321472
Validation loss: 1.5127087023950392

Epoch: 5| Step: 1
Training loss: 0.057082127779722214
Validation loss: 1.5198873307115288

Epoch: 5| Step: 2
Training loss: 0.1445600837469101
Validation loss: 1.52800872248988

Epoch: 5| Step: 3
Training loss: 0.05347714573144913
Validation loss: 1.5292569860335319

Epoch: 5| Step: 4
Training loss: 0.08661763370037079
Validation loss: 1.5188735659404466

Epoch: 5| Step: 5
Training loss: 0.05294381454586983
Validation loss: 1.5316606971525377

Epoch: 5| Step: 6
Training loss: 0.06507648527622223
Validation loss: 1.5642017087628763

Epoch: 5| Step: 7
Training loss: 0.10692137479782104
Validation loss: 1.5965176910482428

Epoch: 5| Step: 8
Training loss: 0.09269347786903381
Validation loss: 1.5748971123849191

Epoch: 5| Step: 9
Training loss: 0.09360943734645844
Validation loss: 1.5701834360758464

Epoch: 5| Step: 10
Training loss: 0.07222028076648712
Validation loss: 1.5739839525632962

Epoch: 546| Step: 0
Training loss: 0.05543091148138046
Validation loss: 1.5481785881903865

Epoch: 5| Step: 1
Training loss: 0.08191992342472076
Validation loss: 1.5312263414423952

Epoch: 5| Step: 2
Training loss: 0.11101128160953522
Validation loss: 1.5618182279730355

Epoch: 5| Step: 3
Training loss: 0.10065446048974991
Validation loss: 1.54231926830866

Epoch: 5| Step: 4
Training loss: 0.06914079934358597
Validation loss: 1.5649433200077345

Epoch: 5| Step: 5
Training loss: 0.10181820392608643
Validation loss: 1.5303076415933587

Epoch: 5| Step: 6
Training loss: 0.10180727392435074
Validation loss: 1.5292312470815514

Epoch: 5| Step: 7
Training loss: 0.059112049639225006
Validation loss: 1.5389819093929824

Epoch: 5| Step: 8
Training loss: 0.08180147409439087
Validation loss: 1.5201423552728468

Epoch: 5| Step: 9
Training loss: 0.05460308864712715
Validation loss: 1.5200590677158807

Epoch: 5| Step: 10
Training loss: 0.0636247992515564
Validation loss: 1.5220440562053392

Epoch: 547| Step: 0
Training loss: 0.1292973756790161
Validation loss: 1.5382001810176398

Epoch: 5| Step: 1
Training loss: 0.1130027323961258
Validation loss: 1.5551547709331717

Epoch: 5| Step: 2
Training loss: 0.09071949124336243
Validation loss: 1.553441325823466

Epoch: 5| Step: 3
Training loss: 0.07013321667909622
Validation loss: 1.541894273091388

Epoch: 5| Step: 4
Training loss: 0.15259075164794922
Validation loss: 1.531471365241594

Epoch: 5| Step: 5
Training loss: 0.11534354835748672
Validation loss: 1.5328529432255735

Epoch: 5| Step: 6
Training loss: 0.06441903114318848
Validation loss: 1.500651805631576

Epoch: 5| Step: 7
Training loss: 0.07908960431814194
Validation loss: 1.514435081071751

Epoch: 5| Step: 8
Training loss: 0.07791423052549362
Validation loss: 1.487708745464202

Epoch: 5| Step: 9
Training loss: 0.0963023453950882
Validation loss: 1.5259126706789898

Epoch: 5| Step: 10
Training loss: 0.08542460203170776
Validation loss: 1.530462073382511

Epoch: 548| Step: 0
Training loss: 0.08140698820352554
Validation loss: 1.5382739869497155

Epoch: 5| Step: 1
Training loss: 0.055824171751737595
Validation loss: 1.5569235868351434

Epoch: 5| Step: 2
Training loss: 0.10810878127813339
Validation loss: 1.5370686079866143

Epoch: 5| Step: 3
Training loss: 0.08062455803155899
Validation loss: 1.5586178918038645

Epoch: 5| Step: 4
Training loss: 0.08686377108097076
Validation loss: 1.5630473372756795

Epoch: 5| Step: 5
Training loss: 0.08462178707122803
Validation loss: 1.5806465482199064

Epoch: 5| Step: 6
Training loss: 0.06541379541158676
Validation loss: 1.573784512858237

Epoch: 5| Step: 7
Training loss: 0.09119908511638641
Validation loss: 1.5690547086859261

Epoch: 5| Step: 8
Training loss: 0.08550408482551575
Validation loss: 1.5612861738410047

Epoch: 5| Step: 9
Training loss: 0.06824220716953278
Validation loss: 1.5529992118958504

Epoch: 5| Step: 10
Training loss: 0.12703485786914825
Validation loss: 1.5491263289605417

Epoch: 549| Step: 0
Training loss: 0.09239798784255981
Validation loss: 1.5187389055887859

Epoch: 5| Step: 1
Training loss: 0.13360655307769775
Validation loss: 1.5349265119080902

Epoch: 5| Step: 2
Training loss: 0.12123604118824005
Validation loss: 1.5453130788700555

Epoch: 5| Step: 3
Training loss: 0.07634691148996353
Validation loss: 1.4939805589696413

Epoch: 5| Step: 4
Training loss: 0.11612628400325775
Validation loss: 1.537669490742427

Epoch: 5| Step: 5
Training loss: 0.09448140859603882
Validation loss: 1.5528524280876241

Epoch: 5| Step: 6
Training loss: 0.049739640206098557
Validation loss: 1.5506051522429272

Epoch: 5| Step: 7
Training loss: 0.0755196139216423
Validation loss: 1.5421381599159651

Epoch: 5| Step: 8
Training loss: 0.05442757532000542
Validation loss: 1.5290842594638947

Epoch: 5| Step: 9
Training loss: 0.06502896547317505
Validation loss: 1.5236334063673531

Epoch: 5| Step: 10
Training loss: 0.05500273033976555
Validation loss: 1.5273098612344393

Epoch: 550| Step: 0
Training loss: 0.05160282179713249
Validation loss: 1.52786676473515

Epoch: 5| Step: 1
Training loss: 0.10318207740783691
Validation loss: 1.5272134029737083

Epoch: 5| Step: 2
Training loss: 0.05600538104772568
Validation loss: 1.526426597308087

Epoch: 5| Step: 3
Training loss: 0.06256792694330215
Validation loss: 1.5111626348187845

Epoch: 5| Step: 4
Training loss: 0.07592161744832993
Validation loss: 1.5528960702239827

Epoch: 5| Step: 5
Training loss: 0.08451654016971588
Validation loss: 1.5379201071236723

Epoch: 5| Step: 6
Training loss: 0.07951507717370987
Validation loss: 1.509056911673597

Epoch: 5| Step: 7
Training loss: 0.10620657354593277
Validation loss: 1.536301682072301

Epoch: 5| Step: 8
Training loss: 0.07703126966953278
Validation loss: 1.55013269634657

Epoch: 5| Step: 9
Training loss: 0.0755634605884552
Validation loss: 1.5312970402420207

Epoch: 5| Step: 10
Training loss: 0.07446087896823883
Validation loss: 1.5349747942339989

Epoch: 551| Step: 0
Training loss: 0.06878161430358887
Validation loss: 1.5372303660197923

Epoch: 5| Step: 1
Training loss: 0.06194502115249634
Validation loss: 1.5196437822875155

Epoch: 5| Step: 2
Training loss: 0.08131999522447586
Validation loss: 1.539343375031666

Epoch: 5| Step: 3
Training loss: 0.08033063262701035
Validation loss: 1.5274430295472503

Epoch: 5| Step: 4
Training loss: 0.05385596677660942
Validation loss: 1.5437843863682081

Epoch: 5| Step: 5
Training loss: 0.0597413070499897
Validation loss: 1.5748268532496628

Epoch: 5| Step: 6
Training loss: 0.06374099105596542
Validation loss: 1.5576201331230901

Epoch: 5| Step: 7
Training loss: 0.07494966685771942
Validation loss: 1.564940829430857

Epoch: 5| Step: 8
Training loss: 0.08657605201005936
Validation loss: 1.5554289510173183

Epoch: 5| Step: 9
Training loss: 0.10107602924108505
Validation loss: 1.555586350861416

Epoch: 5| Step: 10
Training loss: 0.07043673098087311
Validation loss: 1.5572271116318241

Epoch: 552| Step: 0
Training loss: 0.1035042554140091
Validation loss: 1.5459010985589796

Epoch: 5| Step: 1
Training loss: 0.08479828387498856
Validation loss: 1.5726143288356003

Epoch: 5| Step: 2
Training loss: 0.03600646182894707
Validation loss: 1.5646568959759128

Epoch: 5| Step: 3
Training loss: 0.10109321773052216
Validation loss: 1.5513134964050785

Epoch: 5| Step: 4
Training loss: 0.05845829099416733
Validation loss: 1.5250718157778504

Epoch: 5| Step: 5
Training loss: 0.07375027984380722
Validation loss: 1.537664799280064

Epoch: 5| Step: 6
Training loss: 0.06104116514325142
Validation loss: 1.5566367282662341

Epoch: 5| Step: 7
Training loss: 0.09027472883462906
Validation loss: 1.5298423536362187

Epoch: 5| Step: 8
Training loss: 0.06062769889831543
Validation loss: 1.5320651941401984

Epoch: 5| Step: 9
Training loss: 0.04565700516104698
Validation loss: 1.5325705915369012

Epoch: 5| Step: 10
Training loss: 0.11201547086238861
Validation loss: 1.524700540368275

Epoch: 553| Step: 0
Training loss: 0.055111318826675415
Validation loss: 1.540601183009404

Epoch: 5| Step: 1
Training loss: 0.08161725103855133
Validation loss: 1.5430651787788636

Epoch: 5| Step: 2
Training loss: 0.0985901802778244
Validation loss: 1.5434241141042402

Epoch: 5| Step: 3
Training loss: 0.07870154082775116
Validation loss: 1.5550106827930739

Epoch: 5| Step: 4
Training loss: 0.09148483723402023
Validation loss: 1.547491023617406

Epoch: 5| Step: 5
Training loss: 0.05208326503634453
Validation loss: 1.5442811301959458

Epoch: 5| Step: 6
Training loss: 0.08608848601579666
Validation loss: 1.539428130272896

Epoch: 5| Step: 7
Training loss: 0.05026165395975113
Validation loss: 1.5831138177584576

Epoch: 5| Step: 8
Training loss: 0.13003487884998322
Validation loss: 1.5729845903253044

Epoch: 5| Step: 9
Training loss: 0.09851881116628647
Validation loss: 1.542318396670844

Epoch: 5| Step: 10
Training loss: 0.10058260709047318
Validation loss: 1.548386703255356

Epoch: 554| Step: 0
Training loss: 0.06220824643969536
Validation loss: 1.5460599109690676

Epoch: 5| Step: 1
Training loss: 0.06163492053747177
Validation loss: 1.532607691262358

Epoch: 5| Step: 2
Training loss: 0.06843610852956772
Validation loss: 1.557079070357866

Epoch: 5| Step: 3
Training loss: 0.08785450458526611
Validation loss: 1.5169058051160587

Epoch: 5| Step: 4
Training loss: 0.07699743658304214
Validation loss: 1.5635842623249177

Epoch: 5| Step: 5
Training loss: 0.05734211206436157
Validation loss: 1.5429477871105235

Epoch: 5| Step: 6
Training loss: 0.09738102555274963
Validation loss: 1.5809748929033998

Epoch: 5| Step: 7
Training loss: 0.062125314027071
Validation loss: 1.6039245743905344

Epoch: 5| Step: 8
Training loss: 0.09917118400335312
Validation loss: 1.597590841272826

Epoch: 5| Step: 9
Training loss: 0.10127715766429901
Validation loss: 1.6274505212742796

Epoch: 5| Step: 10
Training loss: 0.1394466906785965
Validation loss: 1.5621851362207884

Epoch: 555| Step: 0
Training loss: 0.09430847316980362
Validation loss: 1.5755710294169765

Epoch: 5| Step: 1
Training loss: 0.058557260781526566
Validation loss: 1.571491418346282

Epoch: 5| Step: 2
Training loss: 0.0639694482088089
Validation loss: 1.5347043532197193

Epoch: 5| Step: 3
Training loss: 0.09076831489801407
Validation loss: 1.564066727956136

Epoch: 5| Step: 4
Training loss: 0.1113896369934082
Validation loss: 1.584026050823991

Epoch: 5| Step: 5
Training loss: 0.10467705875635147
Validation loss: 1.5850226571482997

Epoch: 5| Step: 6
Training loss: 0.14464633166790009
Validation loss: 1.5507843789233957

Epoch: 5| Step: 7
Training loss: 0.08206753432750702
Validation loss: 1.5177556263503207

Epoch: 5| Step: 8
Training loss: 0.08710278570652008
Validation loss: 1.5343876807920394

Epoch: 5| Step: 9
Training loss: 0.05274268984794617
Validation loss: 1.5508029255815732

Epoch: 5| Step: 10
Training loss: 0.07860630005598068
Validation loss: 1.560151800032585

Epoch: 556| Step: 0
Training loss: 0.07771513611078262
Validation loss: 1.5638275761758127

Epoch: 5| Step: 1
Training loss: 0.05703152343630791
Validation loss: 1.5666772562970397

Epoch: 5| Step: 2
Training loss: 0.07562311738729477
Validation loss: 1.576205160028191

Epoch: 5| Step: 3
Training loss: 0.07152368128299713
Validation loss: 1.5723739080531622

Epoch: 5| Step: 4
Training loss: 0.0643017515540123
Validation loss: 1.5688059637623448

Epoch: 5| Step: 5
Training loss: 0.05835464596748352
Validation loss: 1.5805977377840268

Epoch: 5| Step: 6
Training loss: 0.06725822389125824
Validation loss: 1.5540200997424383

Epoch: 5| Step: 7
Training loss: 0.06249891594052315
Validation loss: 1.548025191471141

Epoch: 5| Step: 8
Training loss: 0.08981851488351822
Validation loss: 1.5386316468638759

Epoch: 5| Step: 9
Training loss: 0.1516622006893158
Validation loss: 1.5501210766453897

Epoch: 5| Step: 10
Training loss: 0.1767570823431015
Validation loss: 1.5224464208849016

Epoch: 557| Step: 0
Training loss: 0.0816975086927414
Validation loss: 1.526867130751251

Epoch: 5| Step: 1
Training loss: 0.04701492190361023
Validation loss: 1.521527970990827

Epoch: 5| Step: 2
Training loss: 0.07227826118469238
Validation loss: 1.5547165447665798

Epoch: 5| Step: 3
Training loss: 0.098081573843956
Validation loss: 1.5578722864068963

Epoch: 5| Step: 4
Training loss: 0.08108238875865936
Validation loss: 1.5894313512309906

Epoch: 5| Step: 5
Training loss: 0.10327911376953125
Validation loss: 1.5861717167721

Epoch: 5| Step: 6
Training loss: 0.1347222626209259
Validation loss: 1.586148718351959

Epoch: 5| Step: 7
Training loss: 0.10955395549535751
Validation loss: 1.557982139689948

Epoch: 5| Step: 8
Training loss: 0.11623325198888779
Validation loss: 1.5304735822062339

Epoch: 5| Step: 9
Training loss: 0.11297349631786346
Validation loss: 1.5401510064319899

Epoch: 5| Step: 10
Training loss: 0.05309023708105087
Validation loss: 1.5213536216366677

Epoch: 558| Step: 0
Training loss: 0.1107756495475769
Validation loss: 1.5343614842302056

Epoch: 5| Step: 1
Training loss: 0.11232032626867294
Validation loss: 1.5304913815631662

Epoch: 5| Step: 2
Training loss: 0.09002065658569336
Validation loss: 1.474972435223159

Epoch: 5| Step: 3
Training loss: 0.08496300876140594
Validation loss: 1.4950046231669765

Epoch: 5| Step: 4
Training loss: 0.07468202710151672
Validation loss: 1.4744571524281656

Epoch: 5| Step: 5
Training loss: 0.06686709821224213
Validation loss: 1.5080188089801418

Epoch: 5| Step: 6
Training loss: 0.0571664460003376
Validation loss: 1.5184583997213712

Epoch: 5| Step: 7
Training loss: 0.08342880010604858
Validation loss: 1.5464755258252543

Epoch: 5| Step: 8
Training loss: 0.06427743285894394
Validation loss: 1.55466031002742

Epoch: 5| Step: 9
Training loss: 0.11221738904714584
Validation loss: 1.5566593402175493

Epoch: 5| Step: 10
Training loss: 0.09810387343168259
Validation loss: 1.557569638375313

Epoch: 559| Step: 0
Training loss: 0.08021201938390732
Validation loss: 1.5601308743158977

Epoch: 5| Step: 1
Training loss: 0.11951243877410889
Validation loss: 1.578945141966625

Epoch: 5| Step: 2
Training loss: 0.06327760219573975
Validation loss: 1.5841778657769645

Epoch: 5| Step: 3
Training loss: 0.062955342233181
Validation loss: 1.5345024690833142

Epoch: 5| Step: 4
Training loss: 0.07524674385786057
Validation loss: 1.547677501555412

Epoch: 5| Step: 5
Training loss: 0.05958135053515434
Validation loss: 1.500482105439709

Epoch: 5| Step: 6
Training loss: 0.07232647389173508
Validation loss: 1.520745926005866

Epoch: 5| Step: 7
Training loss: 0.06324981898069382
Validation loss: 1.5076750042617961

Epoch: 5| Step: 8
Training loss: 0.07411011308431625
Validation loss: 1.5004589185919812

Epoch: 5| Step: 9
Training loss: 0.11716959625482559
Validation loss: 1.524100742032451

Epoch: 5| Step: 10
Training loss: 0.10107601433992386
Validation loss: 1.5134636881530925

Epoch: 560| Step: 0
Training loss: 0.06939516961574554
Validation loss: 1.5465375595195319

Epoch: 5| Step: 1
Training loss: 0.10345591604709625
Validation loss: 1.5378469728654431

Epoch: 5| Step: 2
Training loss: 0.06406258046627045
Validation loss: 1.5507855915254163

Epoch: 5| Step: 3
Training loss: 0.06390403211116791
Validation loss: 1.5240027391782371

Epoch: 5| Step: 4
Training loss: 0.05625290796160698
Validation loss: 1.555928603295357

Epoch: 5| Step: 5
Training loss: 0.10066141933202744
Validation loss: 1.5297937476506798

Epoch: 5| Step: 6
Training loss: 0.08559634536504745
Validation loss: 1.498353401819865

Epoch: 5| Step: 7
Training loss: 0.08033450692892075
Validation loss: 1.5251172383626301

Epoch: 5| Step: 8
Training loss: 0.11512341350317001
Validation loss: 1.4971111705226283

Epoch: 5| Step: 9
Training loss: 0.07671274989843369
Validation loss: 1.493387532490556

Epoch: 5| Step: 10
Training loss: 0.06805451214313507
Validation loss: 1.4726176838721

Epoch: 561| Step: 0
Training loss: 0.05962507799267769
Validation loss: 1.5012146497285495

Epoch: 5| Step: 1
Training loss: 0.08704689145088196
Validation loss: 1.496210063657453

Epoch: 5| Step: 2
Training loss: 0.09484420716762543
Validation loss: 1.4999739905839324

Epoch: 5| Step: 3
Training loss: 0.061646509915590286
Validation loss: 1.5154167631621003

Epoch: 5| Step: 4
Training loss: 0.05805705860257149
Validation loss: 1.517388310483707

Epoch: 5| Step: 5
Training loss: 0.11488485336303711
Validation loss: 1.52055956984079

Epoch: 5| Step: 6
Training loss: 0.0749252513051033
Validation loss: 1.5104116393673805

Epoch: 5| Step: 7
Training loss: 0.09165366739034653
Validation loss: 1.526296175936217

Epoch: 5| Step: 8
Training loss: 0.053884755820035934
Validation loss: 1.5240522097515803

Epoch: 5| Step: 9
Training loss: 0.08391079306602478
Validation loss: 1.5355237709578646

Epoch: 5| Step: 10
Training loss: 0.059837132692337036
Validation loss: 1.5089738151078582

Epoch: 562| Step: 0
Training loss: 0.06355263292789459
Validation loss: 1.504944286679709

Epoch: 5| Step: 1
Training loss: 0.11222074925899506
Validation loss: 1.5121201084506126

Epoch: 5| Step: 2
Training loss: 0.05976750701665878
Validation loss: 1.5314622309900099

Epoch: 5| Step: 3
Training loss: 0.08723440021276474
Validation loss: 1.497266214380982

Epoch: 5| Step: 4
Training loss: 0.047097787261009216
Validation loss: 1.5086364002637966

Epoch: 5| Step: 5
Training loss: 0.09149754047393799
Validation loss: 1.5272976941959833

Epoch: 5| Step: 6
Training loss: 0.04907575994729996
Validation loss: 1.5315292701926282

Epoch: 5| Step: 7
Training loss: 0.08475800603628159
Validation loss: 1.5274420784365745

Epoch: 5| Step: 8
Training loss: 0.06980409473180771
Validation loss: 1.5303783532111876

Epoch: 5| Step: 9
Training loss: 0.06407914310693741
Validation loss: 1.5522693895524549

Epoch: 5| Step: 10
Training loss: 0.03590241074562073
Validation loss: 1.5552874906088716

Epoch: 563| Step: 0
Training loss: 0.059641312807798386
Validation loss: 1.561667424376293

Epoch: 5| Step: 1
Training loss: 0.05747462064027786
Validation loss: 1.5471812922467467

Epoch: 5| Step: 2
Training loss: 0.03584516793489456
Validation loss: 1.5795753079075967

Epoch: 5| Step: 3
Training loss: 0.08370397984981537
Validation loss: 1.5683011643348201

Epoch: 5| Step: 4
Training loss: 0.10499401390552521
Validation loss: 1.5451237334999988

Epoch: 5| Step: 5
Training loss: 0.10377924144268036
Validation loss: 1.5261614335480558

Epoch: 5| Step: 6
Training loss: 0.06585154682397842
Validation loss: 1.5101103475016933

Epoch: 5| Step: 7
Training loss: 0.08060479164123535
Validation loss: 1.5388045003337245

Epoch: 5| Step: 8
Training loss: 0.07331770658493042
Validation loss: 1.5248213275786369

Epoch: 5| Step: 9
Training loss: 0.06432293355464935
Validation loss: 1.5156501429055327

Epoch: 5| Step: 10
Training loss: 0.11474829912185669
Validation loss: 1.5200360603229974

Epoch: 564| Step: 0
Training loss: 0.05053936317563057
Validation loss: 1.504554339634475

Epoch: 5| Step: 1
Training loss: 0.07714424282312393
Validation loss: 1.5393567956903929

Epoch: 5| Step: 2
Training loss: 0.06267940253019333
Validation loss: 1.5300959899861326

Epoch: 5| Step: 3
Training loss: 0.0707416832447052
Validation loss: 1.5456753635919223

Epoch: 5| Step: 4
Training loss: 0.08396690338850021
Validation loss: 1.5750465944249143

Epoch: 5| Step: 5
Training loss: 0.08136188983917236
Validation loss: 1.5601767275923042

Epoch: 5| Step: 6
Training loss: 0.07664097845554352
Validation loss: 1.5470430030617663

Epoch: 5| Step: 7
Training loss: 0.05143364146351814
Validation loss: 1.5204947686964465

Epoch: 5| Step: 8
Training loss: 0.0638851523399353
Validation loss: 1.5376000904267835

Epoch: 5| Step: 9
Training loss: 0.04854300245642662
Validation loss: 1.5151869032972602

Epoch: 5| Step: 10
Training loss: 0.06872189790010452
Validation loss: 1.521867722593328

Epoch: 565| Step: 0
Training loss: 0.06869221478700638
Validation loss: 1.513285215182971

Epoch: 5| Step: 1
Training loss: 0.06701035052537918
Validation loss: 1.5252132543953516

Epoch: 5| Step: 2
Training loss: 0.08260079473257065
Validation loss: 1.5213154285184798

Epoch: 5| Step: 3
Training loss: 0.05549055337905884
Validation loss: 1.5370067755381267

Epoch: 5| Step: 4
Training loss: 0.0586758628487587
Validation loss: 1.5486676436598583

Epoch: 5| Step: 5
Training loss: 0.053237877786159515
Validation loss: 1.5507827087115216

Epoch: 5| Step: 6
Training loss: 0.11083237826824188
Validation loss: 1.5266397627451087

Epoch: 5| Step: 7
Training loss: 0.06931310892105103
Validation loss: 1.5451288876994964

Epoch: 5| Step: 8
Training loss: 0.05314837768673897
Validation loss: 1.5336961438578944

Epoch: 5| Step: 9
Training loss: 0.05459079146385193
Validation loss: 1.5152704805456183

Epoch: 5| Step: 10
Training loss: 0.07579045742750168
Validation loss: 1.5140545265648955

Epoch: 566| Step: 0
Training loss: 0.06182418391108513
Validation loss: 1.517772234896178

Epoch: 5| Step: 1
Training loss: 0.07763093709945679
Validation loss: 1.515116504443589

Epoch: 5| Step: 2
Training loss: 0.08369852602481842
Validation loss: 1.5115795584135159

Epoch: 5| Step: 3
Training loss: 0.041051141917705536
Validation loss: 1.4981472953673332

Epoch: 5| Step: 4
Training loss: 0.08925966173410416
Validation loss: 1.49108382450637

Epoch: 5| Step: 5
Training loss: 0.06504719704389572
Validation loss: 1.4810972495745587

Epoch: 5| Step: 6
Training loss: 0.14448091387748718
Validation loss: 1.488362249507699

Epoch: 5| Step: 7
Training loss: 0.07566896826028824
Validation loss: 1.4978816893792921

Epoch: 5| Step: 8
Training loss: 0.04508242756128311
Validation loss: 1.5206597287167785

Epoch: 5| Step: 9
Training loss: 0.13074101507663727
Validation loss: 1.5324816947342248

Epoch: 5| Step: 10
Training loss: 0.07094642519950867
Validation loss: 1.5287802283481886

Epoch: 567| Step: 0
Training loss: 0.09125299006700516
Validation loss: 1.5447844087436635

Epoch: 5| Step: 1
Training loss: 0.05017342418432236
Validation loss: 1.5515109864614343

Epoch: 5| Step: 2
Training loss: 0.0790160596370697
Validation loss: 1.5461660046731271

Epoch: 5| Step: 3
Training loss: 0.1134478822350502
Validation loss: 1.515540639559428

Epoch: 5| Step: 4
Training loss: 0.06221994012594223
Validation loss: 1.5041845370364446

Epoch: 5| Step: 5
Training loss: 0.07917134463787079
Validation loss: 1.4842480715884958

Epoch: 5| Step: 6
Training loss: 0.055627964437007904
Validation loss: 1.4901276762767504

Epoch: 5| Step: 7
Training loss: 0.07384596765041351
Validation loss: 1.481595593114053

Epoch: 5| Step: 8
Training loss: 0.06900732219219208
Validation loss: 1.5149617733493927

Epoch: 5| Step: 9
Training loss: 0.054960496723651886
Validation loss: 1.4828879717857606

Epoch: 5| Step: 10
Training loss: 0.09276020526885986
Validation loss: 1.497695944642508

Epoch: 568| Step: 0
Training loss: 0.060854751616716385
Validation loss: 1.533671038125151

Epoch: 5| Step: 1
Training loss: 0.06319748610258102
Validation loss: 1.50687571366628

Epoch: 5| Step: 2
Training loss: 0.07659962028265
Validation loss: 1.5395643685453682

Epoch: 5| Step: 3
Training loss: 0.07783231884241104
Validation loss: 1.5489767802658903

Epoch: 5| Step: 4
Training loss: 0.05416238307952881
Validation loss: 1.5283235785781697

Epoch: 5| Step: 5
Training loss: 0.08894739300012589
Validation loss: 1.5777491625919138

Epoch: 5| Step: 6
Training loss: 0.061227232217788696
Validation loss: 1.5428226224837764

Epoch: 5| Step: 7
Training loss: 0.10788192600011826
Validation loss: 1.5382437206083728

Epoch: 5| Step: 8
Training loss: 0.08299559354782104
Validation loss: 1.5024069778380855

Epoch: 5| Step: 9
Training loss: 0.09694517403841019
Validation loss: 1.5016343811506867

Epoch: 5| Step: 10
Training loss: 0.051452167332172394
Validation loss: 1.5119312911905267

Epoch: 569| Step: 0
Training loss: 0.05081397294998169
Validation loss: 1.5018850885411745

Epoch: 5| Step: 1
Training loss: 0.06165339797735214
Validation loss: 1.495736337477161

Epoch: 5| Step: 2
Training loss: 0.06582003831863403
Validation loss: 1.4829482224679762

Epoch: 5| Step: 3
Training loss: 0.06802663207054138
Validation loss: 1.4872812276245446

Epoch: 5| Step: 4
Training loss: 0.05834167078137398
Validation loss: 1.4900419545430008

Epoch: 5| Step: 5
Training loss: 0.08764462172985077
Validation loss: 1.509983657508768

Epoch: 5| Step: 6
Training loss: 0.07729272544384003
Validation loss: 1.5171646828292518

Epoch: 5| Step: 7
Training loss: 0.05531221628189087
Validation loss: 1.5308747073655486

Epoch: 5| Step: 8
Training loss: 0.0932658389210701
Validation loss: 1.531746313136111

Epoch: 5| Step: 9
Training loss: 0.05445796251296997
Validation loss: 1.5406301906031947

Epoch: 5| Step: 10
Training loss: 0.07198657840490341
Validation loss: 1.5197720476376113

Epoch: 570| Step: 0
Training loss: 0.08152122050523758
Validation loss: 1.53092328194649

Epoch: 5| Step: 1
Training loss: 0.11896469444036484
Validation loss: 1.5143942268945838

Epoch: 5| Step: 2
Training loss: 0.0489552803337574
Validation loss: 1.4995265699202014

Epoch: 5| Step: 3
Training loss: 0.06365875899791718
Validation loss: 1.4691444122663109

Epoch: 5| Step: 4
Training loss: 0.06558994948863983
Validation loss: 1.4880515477990592

Epoch: 5| Step: 5
Training loss: 0.08151843398809433
Validation loss: 1.5111850307833763

Epoch: 5| Step: 6
Training loss: 0.07237271219491959
Validation loss: 1.5233005298081266

Epoch: 5| Step: 7
Training loss: 0.08152306079864502
Validation loss: 1.5107081756796887

Epoch: 5| Step: 8
Training loss: 0.08447647839784622
Validation loss: 1.5184343893040892

Epoch: 5| Step: 9
Training loss: 0.05454002693295479
Validation loss: 1.5197690071598176

Epoch: 5| Step: 10
Training loss: 0.07743991166353226
Validation loss: 1.5509613355000813

Epoch: 571| Step: 0
Training loss: 0.08983159065246582
Validation loss: 1.5518069523637013

Epoch: 5| Step: 1
Training loss: 0.09311104565858841
Validation loss: 1.55106125339385

Epoch: 5| Step: 2
Training loss: 0.076871357858181
Validation loss: 1.5804765096274755

Epoch: 5| Step: 3
Training loss: 0.08941324800252914
Validation loss: 1.5655084303630296

Epoch: 5| Step: 4
Training loss: 0.08692377060651779
Validation loss: 1.5927160113088545

Epoch: 5| Step: 5
Training loss: 0.06621669232845306
Validation loss: 1.5757807762392106

Epoch: 5| Step: 6
Training loss: 0.09070412814617157
Validation loss: 1.5635609780588458

Epoch: 5| Step: 7
Training loss: 0.10595693439245224
Validation loss: 1.548784408518063

Epoch: 5| Step: 8
Training loss: 0.06786123663187027
Validation loss: 1.549458352468347

Epoch: 5| Step: 9
Training loss: 0.06756393611431122
Validation loss: 1.5332688445686011

Epoch: 5| Step: 10
Training loss: 0.05080246925354004
Validation loss: 1.5244311235284294

Epoch: 572| Step: 0
Training loss: 0.10892359912395477
Validation loss: 1.5156272495946577

Epoch: 5| Step: 1
Training loss: 0.11581814289093018
Validation loss: 1.528482880643619

Epoch: 5| Step: 2
Training loss: 0.09049995243549347
Validation loss: 1.536292818284804

Epoch: 5| Step: 3
Training loss: 0.059648048132658005
Validation loss: 1.526931812686305

Epoch: 5| Step: 4
Training loss: 0.05070991441607475
Validation loss: 1.5468278264486661

Epoch: 5| Step: 5
Training loss: 0.05705012008547783
Validation loss: 1.5373510942664197

Epoch: 5| Step: 6
Training loss: 0.06432309746742249
Validation loss: 1.5472426119671072

Epoch: 5| Step: 7
Training loss: 0.06077023595571518
Validation loss: 1.5454930784881755

Epoch: 5| Step: 8
Training loss: 0.09403769671916962
Validation loss: 1.5581824779510498

Epoch: 5| Step: 9
Training loss: 0.0743725597858429
Validation loss: 1.5637634108143468

Epoch: 5| Step: 10
Training loss: 0.15863074362277985
Validation loss: 1.5966476317374938

Epoch: 573| Step: 0
Training loss: 0.10190954059362411
Validation loss: 1.5736084727830784

Epoch: 5| Step: 1
Training loss: 0.07235169410705566
Validation loss: 1.5455839980033137

Epoch: 5| Step: 2
Training loss: 0.10942620038986206
Validation loss: 1.5387476208389446

Epoch: 5| Step: 3
Training loss: 0.06175540015101433
Validation loss: 1.5037860485815233

Epoch: 5| Step: 4
Training loss: 0.05446314811706543
Validation loss: 1.5112584406329739

Epoch: 5| Step: 5
Training loss: 0.06388502568006516
Validation loss: 1.5334362342793455

Epoch: 5| Step: 6
Training loss: 0.0808175578713417
Validation loss: 1.5042415754769438

Epoch: 5| Step: 7
Training loss: 0.08021081984043121
Validation loss: 1.4952299569242744

Epoch: 5| Step: 8
Training loss: 0.06546130776405334
Validation loss: 1.5075664174172185

Epoch: 5| Step: 9
Training loss: 0.09292056411504745
Validation loss: 1.5179807562981882

Epoch: 5| Step: 10
Training loss: 0.06611906737089157
Validation loss: 1.5389747132537186

Epoch: 574| Step: 0
Training loss: 0.09603819996118546
Validation loss: 1.5352442802921418

Epoch: 5| Step: 1
Training loss: 0.12938368320465088
Validation loss: 1.5781391820599955

Epoch: 5| Step: 2
Training loss: 0.09462189674377441
Validation loss: 1.5882906260028962

Epoch: 5| Step: 3
Training loss: 0.07137046754360199
Validation loss: 1.5861409889754428

Epoch: 5| Step: 4
Training loss: 0.07240045070648193
Validation loss: 1.5869040681469826

Epoch: 5| Step: 5
Training loss: 0.07058940827846527
Validation loss: 1.5559480549186788

Epoch: 5| Step: 6
Training loss: 0.0686267614364624
Validation loss: 1.5249065417115406

Epoch: 5| Step: 7
Training loss: 0.06919937580823898
Validation loss: 1.5210117332396969

Epoch: 5| Step: 8
Training loss: 0.05769670754671097
Validation loss: 1.5270587180250434

Epoch: 5| Step: 9
Training loss: 0.0635889545083046
Validation loss: 1.5003766372639646

Epoch: 5| Step: 10
Training loss: 0.06510445475578308
Validation loss: 1.4867147373896774

Epoch: 575| Step: 0
Training loss: 0.05852781608700752
Validation loss: 1.502063790957133

Epoch: 5| Step: 1
Training loss: 0.07471928745508194
Validation loss: 1.5058002984651955

Epoch: 5| Step: 2
Training loss: 0.07584208995103836
Validation loss: 1.5079580186515726

Epoch: 5| Step: 3
Training loss: 0.051056839525699615
Validation loss: 1.5030762739078973

Epoch: 5| Step: 4
Training loss: 0.07884843647480011
Validation loss: 1.5053599278132122

Epoch: 5| Step: 5
Training loss: 0.0783831924200058
Validation loss: 1.5322330228744014

Epoch: 5| Step: 6
Training loss: 0.09230558574199677
Validation loss: 1.5144560042247976

Epoch: 5| Step: 7
Training loss: 0.07939423620700836
Validation loss: 1.5398413019795572

Epoch: 5| Step: 8
Training loss: 0.07251162827014923
Validation loss: 1.5448387886888237

Epoch: 5| Step: 9
Training loss: 0.11665590852499008
Validation loss: 1.5267019348759805

Epoch: 5| Step: 10
Training loss: 0.08094009011983871
Validation loss: 1.5346036995610883

Epoch: 576| Step: 0
Training loss: 0.046291373670101166
Validation loss: 1.5275527559300905

Epoch: 5| Step: 1
Training loss: 0.07926920056343079
Validation loss: 1.523919654148881

Epoch: 5| Step: 2
Training loss: 0.049926865845918655
Validation loss: 1.4856726661805184

Epoch: 5| Step: 3
Training loss: 0.07070554047822952
Validation loss: 1.507583664309594

Epoch: 5| Step: 4
Training loss: 0.057069409638643265
Validation loss: 1.489994324663634

Epoch: 5| Step: 5
Training loss: 0.06803222745656967
Validation loss: 1.5046791081787438

Epoch: 5| Step: 6
Training loss: 0.07837261259555817
Validation loss: 1.4856873289231332

Epoch: 5| Step: 7
Training loss: 0.04061000421643257
Validation loss: 1.4929927138872043

Epoch: 5| Step: 8
Training loss: 0.053592562675476074
Validation loss: 1.5100299248131372

Epoch: 5| Step: 9
Training loss: 0.06877215206623077
Validation loss: 1.5089917381604512

Epoch: 5| Step: 10
Training loss: 0.10322632640600204
Validation loss: 1.5043049499552736

Epoch: 577| Step: 0
Training loss: 0.06379537284374237
Validation loss: 1.4866435925165813

Epoch: 5| Step: 1
Training loss: 0.04302772134542465
Validation loss: 1.4791644439902356

Epoch: 5| Step: 2
Training loss: 0.06090472266077995
Validation loss: 1.4856621283356861

Epoch: 5| Step: 3
Training loss: 0.08091680705547333
Validation loss: 1.445091519304501

Epoch: 5| Step: 4
Training loss: 0.10478980839252472
Validation loss: 1.4510202048927225

Epoch: 5| Step: 5
Training loss: 0.09274674952030182
Validation loss: 1.5009701136619813

Epoch: 5| Step: 6
Training loss: 0.10443095862865448
Validation loss: 1.4676902576159405

Epoch: 5| Step: 7
Training loss: 0.07792580872774124
Validation loss: 1.4736879487191477

Epoch: 5| Step: 8
Training loss: 0.10120312869548798
Validation loss: 1.4752673910510155

Epoch: 5| Step: 9
Training loss: 0.07902006059885025
Validation loss: 1.4780577049460462

Epoch: 5| Step: 10
Training loss: 0.057340409606695175
Validation loss: 1.493303983442245

Epoch: 578| Step: 0
Training loss: 0.07019507884979248
Validation loss: 1.5081379657150598

Epoch: 5| Step: 1
Training loss: 0.0782836452126503
Validation loss: 1.4724281641744799

Epoch: 5| Step: 2
Training loss: 0.05655444413423538
Validation loss: 1.511587465963056

Epoch: 5| Step: 3
Training loss: 0.04602411389350891
Validation loss: 1.5269772826984365

Epoch: 5| Step: 4
Training loss: 0.057639263570308685
Validation loss: 1.5391494266448482

Epoch: 5| Step: 5
Training loss: 0.08440466225147247
Validation loss: 1.5668975409641062

Epoch: 5| Step: 6
Training loss: 0.07936791330575943
Validation loss: 1.585987106446297

Epoch: 5| Step: 7
Training loss: 0.12780039012432098
Validation loss: 1.5673786606839908

Epoch: 5| Step: 8
Training loss: 0.07828251272439957
Validation loss: 1.5999078186609412

Epoch: 5| Step: 9
Training loss: 0.09059745073318481
Validation loss: 1.5714852374087098

Epoch: 5| Step: 10
Training loss: 0.04660913348197937
Validation loss: 1.5707792005231302

Epoch: 579| Step: 0
Training loss: 0.07869589328765869
Validation loss: 1.5611362829003284

Epoch: 5| Step: 1
Training loss: 0.08422461897134781
Validation loss: 1.543985120711788

Epoch: 5| Step: 2
Training loss: 0.08562727272510529
Validation loss: 1.5239376355242986

Epoch: 5| Step: 3
Training loss: 0.0763172060251236
Validation loss: 1.5330865754876086

Epoch: 5| Step: 4
Training loss: 0.10443141311407089
Validation loss: 1.5337401795130905

Epoch: 5| Step: 5
Training loss: 0.0654912143945694
Validation loss: 1.5310168330387404

Epoch: 5| Step: 6
Training loss: 0.0644620731472969
Validation loss: 1.5448669297720796

Epoch: 5| Step: 7
Training loss: 0.07761599123477936
Validation loss: 1.551582872226674

Epoch: 5| Step: 8
Training loss: 0.05025641992688179
Validation loss: 1.5415706025656832

Epoch: 5| Step: 9
Training loss: 0.0739336833357811
Validation loss: 1.5685007700356104

Epoch: 5| Step: 10
Training loss: 0.08546468615531921
Validation loss: 1.5410910575620589

Epoch: 580| Step: 0
Training loss: 0.10646925121545792
Validation loss: 1.564318158293283

Epoch: 5| Step: 1
Training loss: 0.05750912427902222
Validation loss: 1.557281248031124

Epoch: 5| Step: 2
Training loss: 0.04362720996141434
Validation loss: 1.550420247098451

Epoch: 5| Step: 3
Training loss: 0.09007811546325684
Validation loss: 1.5607542196909587

Epoch: 5| Step: 4
Training loss: 0.08022303879261017
Validation loss: 1.5712432810055312

Epoch: 5| Step: 5
Training loss: 0.04853339493274689
Validation loss: 1.5482839128022552

Epoch: 5| Step: 6
Training loss: 0.10216301679611206
Validation loss: 1.5662584394536994

Epoch: 5| Step: 7
Training loss: 0.05760741978883743
Validation loss: 1.5465133625973937

Epoch: 5| Step: 8
Training loss: 0.05169117450714111
Validation loss: 1.5372624557505372

Epoch: 5| Step: 9
Training loss: 0.09883026778697968
Validation loss: 1.53062573043249

Epoch: 5| Step: 10
Training loss: 0.0734497681260109
Validation loss: 1.510335503085967

Epoch: 581| Step: 0
Training loss: 0.0972423329949379
Validation loss: 1.4958551545296945

Epoch: 5| Step: 1
Training loss: 0.08746238797903061
Validation loss: 1.505311732651085

Epoch: 5| Step: 2
Training loss: 0.0645960345864296
Validation loss: 1.5023105875138314

Epoch: 5| Step: 3
Training loss: 0.04769349843263626
Validation loss: 1.5042053896893737

Epoch: 5| Step: 4
Training loss: 0.07395630329847336
Validation loss: 1.477518791793495

Epoch: 5| Step: 5
Training loss: 0.08641351759433746
Validation loss: 1.5061683936785626

Epoch: 5| Step: 6
Training loss: 0.06616000831127167
Validation loss: 1.5119308976716892

Epoch: 5| Step: 7
Training loss: 0.07204543054103851
Validation loss: 1.5246480511080833

Epoch: 5| Step: 8
Training loss: 0.08088139444589615
Validation loss: 1.5362671626511442

Epoch: 5| Step: 9
Training loss: 0.07002133131027222
Validation loss: 1.555608002088403

Epoch: 5| Step: 10
Training loss: 0.06280473619699478
Validation loss: 1.525195840866335

Epoch: 582| Step: 0
Training loss: 0.057012803852558136
Validation loss: 1.528985906672734

Epoch: 5| Step: 1
Training loss: 0.09187668561935425
Validation loss: 1.5016058350122103

Epoch: 5| Step: 2
Training loss: 0.05038157105445862
Validation loss: 1.4947900900276758

Epoch: 5| Step: 3
Training loss: 0.08777058124542236
Validation loss: 1.4773289388225925

Epoch: 5| Step: 4
Training loss: 0.0812280923128128
Validation loss: 1.5014331597153858

Epoch: 5| Step: 5
Training loss: 0.0854896530508995
Validation loss: 1.5070533957532657

Epoch: 5| Step: 6
Training loss: 0.10068376362323761
Validation loss: 1.5261640907615743

Epoch: 5| Step: 7
Training loss: 0.07666896283626556
Validation loss: 1.5217658883781844

Epoch: 5| Step: 8
Training loss: 0.039984606206417084
Validation loss: 1.521634385149966

Epoch: 5| Step: 9
Training loss: 0.08294591307640076
Validation loss: 1.5016645795555525

Epoch: 5| Step: 10
Training loss: 0.11985109746456146
Validation loss: 1.526586405692562

Epoch: 583| Step: 0
Training loss: 0.090224489569664
Validation loss: 1.5297956261583554

Epoch: 5| Step: 1
Training loss: 0.103917695581913
Validation loss: 1.5425728982494724

Epoch: 5| Step: 2
Training loss: 0.09644223749637604
Validation loss: 1.5621533009313768

Epoch: 5| Step: 3
Training loss: 0.06906305253505707
Validation loss: 1.541006593294041

Epoch: 5| Step: 4
Training loss: 0.09961708635091782
Validation loss: 1.5279523275231803

Epoch: 5| Step: 5
Training loss: 0.0635155439376831
Validation loss: 1.52924733649018

Epoch: 5| Step: 6
Training loss: 0.08137794584035873
Validation loss: 1.5151311710316648

Epoch: 5| Step: 7
Training loss: 0.05159822851419449
Validation loss: 1.5338986493566984

Epoch: 5| Step: 8
Training loss: 0.05795571953058243
Validation loss: 1.5103315909703572

Epoch: 5| Step: 9
Training loss: 0.0676034614443779
Validation loss: 1.4856525236560452

Epoch: 5| Step: 10
Training loss: 0.08388031274080276
Validation loss: 1.4923208516131166

Epoch: 584| Step: 0
Training loss: 0.0584179162979126
Validation loss: 1.4972808950690812

Epoch: 5| Step: 1
Training loss: 0.03844137489795685
Validation loss: 1.475504716237386

Epoch: 5| Step: 2
Training loss: 0.06965608894824982
Validation loss: 1.5069739972391436

Epoch: 5| Step: 3
Training loss: 0.08732687681913376
Validation loss: 1.5036022586207236

Epoch: 5| Step: 4
Training loss: 0.09613732993602753
Validation loss: 1.490699496320499

Epoch: 5| Step: 5
Training loss: 0.09001202881336212
Validation loss: 1.5076219016505825

Epoch: 5| Step: 6
Training loss: 0.11239321529865265
Validation loss: 1.506166700393923

Epoch: 5| Step: 7
Training loss: 0.07380235195159912
Validation loss: 1.4951223416994976

Epoch: 5| Step: 8
Training loss: 0.08996209502220154
Validation loss: 1.4814977222873318

Epoch: 5| Step: 9
Training loss: 0.06967910379171371
Validation loss: 1.495050331597687

Epoch: 5| Step: 10
Training loss: 0.06255313754081726
Validation loss: 1.4720113533799366

Epoch: 585| Step: 0
Training loss: 0.07739894092082977
Validation loss: 1.4941579039378832

Epoch: 5| Step: 1
Training loss: 0.053387485444545746
Validation loss: 1.4937663206490137

Epoch: 5| Step: 2
Training loss: 0.10371652990579605
Validation loss: 1.4981331581710486

Epoch: 5| Step: 3
Training loss: 0.060423970222473145
Validation loss: 1.4926431332865069

Epoch: 5| Step: 4
Training loss: 0.09853430092334747
Validation loss: 1.510487994199158

Epoch: 5| Step: 5
Training loss: 0.10042580217123032
Validation loss: 1.5194438106270247

Epoch: 5| Step: 6
Training loss: 0.10449932515621185
Validation loss: 1.526744402864928

Epoch: 5| Step: 7
Training loss: 0.0766616016626358
Validation loss: 1.5364399033208047

Epoch: 5| Step: 8
Training loss: 0.062016189098358154
Validation loss: 1.5158046855721423

Epoch: 5| Step: 9
Training loss: 0.06083182245492935
Validation loss: 1.5323923710853822

Epoch: 5| Step: 10
Training loss: 0.12815971672534943
Validation loss: 1.5726691804906374

Epoch: 586| Step: 0
Training loss: 0.13357888162136078
Validation loss: 1.6028058336627098

Epoch: 5| Step: 1
Training loss: 0.08242157846689224
Validation loss: 1.5467236939296927

Epoch: 5| Step: 2
Training loss: 0.07713170349597931
Validation loss: 1.54226480889064

Epoch: 5| Step: 3
Training loss: 0.07636868953704834
Validation loss: 1.4989174085278665

Epoch: 5| Step: 4
Training loss: 0.10266084969043732
Validation loss: 1.4904211426293978

Epoch: 5| Step: 5
Training loss: 0.1765071451663971
Validation loss: 1.5135028695547452

Epoch: 5| Step: 6
Training loss: 0.14650477468967438
Validation loss: 1.5321890090101509

Epoch: 5| Step: 7
Training loss: 0.13602270185947418
Validation loss: 1.5124659820269513

Epoch: 5| Step: 8
Training loss: 0.08921052515506744
Validation loss: 1.4949954991699548

Epoch: 5| Step: 9
Training loss: 0.08239670097827911
Validation loss: 1.495804690545605

Epoch: 5| Step: 10
Training loss: 0.0668257400393486
Validation loss: 1.5004805057279524

Epoch: 587| Step: 0
Training loss: 0.09107472747564316
Validation loss: 1.544259936578812

Epoch: 5| Step: 1
Training loss: 0.06542874127626419
Validation loss: 1.566132636480434

Epoch: 5| Step: 2
Training loss: 0.06187041476368904
Validation loss: 1.5658084243856452

Epoch: 5| Step: 3
Training loss: 0.11471790075302124
Validation loss: 1.57107207082933

Epoch: 5| Step: 4
Training loss: 0.08390024304389954
Validation loss: 1.560278977758141

Epoch: 5| Step: 5
Training loss: 0.11050581932067871
Validation loss: 1.5809237739091277

Epoch: 5| Step: 6
Training loss: 0.08512875437736511
Validation loss: 1.5854901556045777

Epoch: 5| Step: 7
Training loss: 0.10263445228338242
Validation loss: 1.5834792890856344

Epoch: 5| Step: 8
Training loss: 0.0661410242319107
Validation loss: 1.5656985134206793

Epoch: 5| Step: 9
Training loss: 0.051656853407621384
Validation loss: 1.5597401754830473

Epoch: 5| Step: 10
Training loss: 0.05563695356249809
Validation loss: 1.5466686846107565

Epoch: 588| Step: 0
Training loss: 0.12158381938934326
Validation loss: 1.5207198486533215

Epoch: 5| Step: 1
Training loss: 0.09063266962766647
Validation loss: 1.5248734079381472

Epoch: 5| Step: 2
Training loss: 0.09815642237663269
Validation loss: 1.5409146419135473

Epoch: 5| Step: 3
Training loss: 0.08090437948703766
Validation loss: 1.4925172790404289

Epoch: 5| Step: 4
Training loss: 0.08926593512296677
Validation loss: 1.5110929896754604

Epoch: 5| Step: 5
Training loss: 0.06961800903081894
Validation loss: 1.5076532145982147

Epoch: 5| Step: 6
Training loss: 0.06901951879262924
Validation loss: 1.5242747055586947

Epoch: 5| Step: 7
Training loss: 0.0623711422085762
Validation loss: 1.560659250905437

Epoch: 5| Step: 8
Training loss: 0.12650355696678162
Validation loss: 1.6026741804615143

Epoch: 5| Step: 9
Training loss: 0.11916564404964447
Validation loss: 1.5807003423731814

Epoch: 5| Step: 10
Training loss: 0.06249573081731796
Validation loss: 1.624903226411471

Epoch: 589| Step: 0
Training loss: 0.11507491767406464
Validation loss: 1.5897122941991335

Epoch: 5| Step: 1
Training loss: 0.06470801681280136
Validation loss: 1.5826567719059605

Epoch: 5| Step: 2
Training loss: 0.06561953574419022
Validation loss: 1.5617007318363394

Epoch: 5| Step: 3
Training loss: 0.05639965459704399
Validation loss: 1.5268588463465373

Epoch: 5| Step: 4
Training loss: 0.07563170790672302
Validation loss: 1.5109546428085656

Epoch: 5| Step: 5
Training loss: 0.07782896608114243
Validation loss: 1.504974922185303

Epoch: 5| Step: 6
Training loss: 0.10351727902889252
Validation loss: 1.513460320811118

Epoch: 5| Step: 7
Training loss: 0.1040285974740982
Validation loss: 1.4940022262193824

Epoch: 5| Step: 8
Training loss: 0.135277658700943
Validation loss: 1.4871741469188402

Epoch: 5| Step: 9
Training loss: 0.08344884216785431
Validation loss: 1.4874024621901973

Epoch: 5| Step: 10
Training loss: 0.08102414757013321
Validation loss: 1.5059955709724016

Epoch: 590| Step: 0
Training loss: 0.07323458045721054
Validation loss: 1.5179180227300173

Epoch: 5| Step: 1
Training loss: 0.08399634063243866
Validation loss: 1.5211592169218167

Epoch: 5| Step: 2
Training loss: 0.04697862267494202
Validation loss: 1.526259046728893

Epoch: 5| Step: 3
Training loss: 0.06379395723342896
Validation loss: 1.5101651299384333

Epoch: 5| Step: 4
Training loss: 0.08982396870851517
Validation loss: 1.5405194669641473

Epoch: 5| Step: 5
Training loss: 0.05330124497413635
Validation loss: 1.545810120080107

Epoch: 5| Step: 6
Training loss: 0.08518721908330917
Validation loss: 1.5521972833141204

Epoch: 5| Step: 7
Training loss: 0.09273064881563187
Validation loss: 1.5643052131898942

Epoch: 5| Step: 8
Training loss: 0.06262628734111786
Validation loss: 1.5701416641153314

Epoch: 5| Step: 9
Training loss: 0.10257010161876678
Validation loss: 1.5417571766402132

Epoch: 5| Step: 10
Training loss: 0.07880102097988129
Validation loss: 1.5617840597706456

Epoch: 591| Step: 0
Training loss: 0.09399517625570297
Validation loss: 1.5364464867499568

Epoch: 5| Step: 1
Training loss: 0.06114133447408676
Validation loss: 1.518812817911948

Epoch: 5| Step: 2
Training loss: 0.08440829068422318
Validation loss: 1.4993785722281343

Epoch: 5| Step: 3
Training loss: 0.037065424025058746
Validation loss: 1.529572609932192

Epoch: 5| Step: 4
Training loss: 0.07777301967144012
Validation loss: 1.5143105804279287

Epoch: 5| Step: 5
Training loss: 0.10314208269119263
Validation loss: 1.4983277167043378

Epoch: 5| Step: 6
Training loss: 0.07628823071718216
Validation loss: 1.5307003637795806

Epoch: 5| Step: 7
Training loss: 0.047684378921985626
Validation loss: 1.5139912738594958

Epoch: 5| Step: 8
Training loss: 0.057224441319704056
Validation loss: 1.531458805966121

Epoch: 5| Step: 9
Training loss: 0.07134942710399628
Validation loss: 1.5268413732128758

Epoch: 5| Step: 10
Training loss: 0.05129236355423927
Validation loss: 1.5454883216529764

Epoch: 592| Step: 0
Training loss: 0.044507257640361786
Validation loss: 1.517316605455132

Epoch: 5| Step: 1
Training loss: 0.10254497826099396
Validation loss: 1.5157457000465804

Epoch: 5| Step: 2
Training loss: 0.04337672144174576
Validation loss: 1.5280166710576704

Epoch: 5| Step: 3
Training loss: 0.09700201451778412
Validation loss: 1.5354116155255226

Epoch: 5| Step: 4
Training loss: 0.04604455828666687
Validation loss: 1.5076409911596647

Epoch: 5| Step: 5
Training loss: 0.08836118876934052
Validation loss: 1.4917016183176348

Epoch: 5| Step: 6
Training loss: 0.08601199090480804
Validation loss: 1.506516941132084

Epoch: 5| Step: 7
Training loss: 0.07232388854026794
Validation loss: 1.5270563895984361

Epoch: 5| Step: 8
Training loss: 0.06748244911432266
Validation loss: 1.5233325471160233

Epoch: 5| Step: 9
Training loss: 0.05143715813755989
Validation loss: 1.5290199684840378

Epoch: 5| Step: 10
Training loss: 0.05332627892494202
Validation loss: 1.5560998455170663

Epoch: 593| Step: 0
Training loss: 0.058609217405319214
Validation loss: 1.5492194852521342

Epoch: 5| Step: 1
Training loss: 0.05893361568450928
Validation loss: 1.5615436569336922

Epoch: 5| Step: 2
Training loss: 0.05843942239880562
Validation loss: 1.5542225248070174

Epoch: 5| Step: 3
Training loss: 0.08237294107675552
Validation loss: 1.5479516931759414

Epoch: 5| Step: 4
Training loss: 0.06979326158761978
Validation loss: 1.5285969523973362

Epoch: 5| Step: 5
Training loss: 0.09318804740905762
Validation loss: 1.5608363049004668

Epoch: 5| Step: 6
Training loss: 0.09511461108922958
Validation loss: 1.5657346158899286

Epoch: 5| Step: 7
Training loss: 0.11991938203573227
Validation loss: 1.5724101393453536

Epoch: 5| Step: 8
Training loss: 0.06741838157176971
Validation loss: 1.5600774621450773

Epoch: 5| Step: 9
Training loss: 0.04740464687347412
Validation loss: 1.5467731978303643

Epoch: 5| Step: 10
Training loss: 0.08709347248077393
Validation loss: 1.5241487974761634

Epoch: 594| Step: 0
Training loss: 0.1081136018037796
Validation loss: 1.5049473521529988

Epoch: 5| Step: 1
Training loss: 0.045320115983486176
Validation loss: 1.4991785839039793

Epoch: 5| Step: 2
Training loss: 0.08347342908382416
Validation loss: 1.4964557283668107

Epoch: 5| Step: 3
Training loss: 0.05191937834024429
Validation loss: 1.5189629370166409

Epoch: 5| Step: 4
Training loss: 0.045353200286626816
Validation loss: 1.5125364103624899

Epoch: 5| Step: 5
Training loss: 0.0955599844455719
Validation loss: 1.5414458026168167

Epoch: 5| Step: 6
Training loss: 0.054558467119932175
Validation loss: 1.5479573549762848

Epoch: 5| Step: 7
Training loss: 0.057942140847444534
Validation loss: 1.5246690498885287

Epoch: 5| Step: 8
Training loss: 0.09171036630868912
Validation loss: 1.553012450536092

Epoch: 5| Step: 9
Training loss: 0.07439247518777847
Validation loss: 1.5593608912601267

Epoch: 5| Step: 10
Training loss: 0.09063997119665146
Validation loss: 1.5519464515870618

Epoch: 595| Step: 0
Training loss: 0.0885721743106842
Validation loss: 1.5803457306277366

Epoch: 5| Step: 1
Training loss: 0.08306656777858734
Validation loss: 1.5654734834547965

Epoch: 5| Step: 2
Training loss: 0.04376925900578499
Validation loss: 1.5239829049315503

Epoch: 5| Step: 3
Training loss: 0.11481593549251556
Validation loss: 1.5095374122742684

Epoch: 5| Step: 4
Training loss: 0.0894043818116188
Validation loss: 1.501220400615405

Epoch: 5| Step: 5
Training loss: 0.08125439286231995
Validation loss: 1.4964446688211093

Epoch: 5| Step: 6
Training loss: 0.0858483761548996
Validation loss: 1.4868290744802004

Epoch: 5| Step: 7
Training loss: 0.07176418602466583
Validation loss: 1.5190493086332917

Epoch: 5| Step: 8
Training loss: 0.07774386554956436
Validation loss: 1.499849183585054

Epoch: 5| Step: 9
Training loss: 0.08871172368526459
Validation loss: 1.4902758213781542

Epoch: 5| Step: 10
Training loss: 0.09231030941009521
Validation loss: 1.5095138690804923

Epoch: 596| Step: 0
Training loss: 0.05970216915011406
Validation loss: 1.4951338370641072

Epoch: 5| Step: 1
Training loss: 0.058326948434114456
Validation loss: 1.5095829194591892

Epoch: 5| Step: 2
Training loss: 0.05778123810887337
Validation loss: 1.4809544086456299

Epoch: 5| Step: 3
Training loss: 0.04657710716128349
Validation loss: 1.504140607772335

Epoch: 5| Step: 4
Training loss: 0.08899728208780289
Validation loss: 1.5102677601639942

Epoch: 5| Step: 5
Training loss: 0.09937237203121185
Validation loss: 1.4949829962945753

Epoch: 5| Step: 6
Training loss: 0.06015975400805473
Validation loss: 1.4851328839537918

Epoch: 5| Step: 7
Training loss: 0.07948146015405655
Validation loss: 1.4920097679220221

Epoch: 5| Step: 8
Training loss: 0.06906620413064957
Validation loss: 1.4844573697736185

Epoch: 5| Step: 9
Training loss: 0.09261717647314072
Validation loss: 1.4720244202562558

Epoch: 5| Step: 10
Training loss: 0.07052411884069443
Validation loss: 1.5050285580337688

Epoch: 597| Step: 0
Training loss: 0.10134081542491913
Validation loss: 1.5036624836665329

Epoch: 5| Step: 1
Training loss: 0.07775139808654785
Validation loss: 1.5060436315433954

Epoch: 5| Step: 2
Training loss: 0.07093238830566406
Validation loss: 1.4870486400460685

Epoch: 5| Step: 3
Training loss: 0.055367361754179
Validation loss: 1.499322150343208

Epoch: 5| Step: 4
Training loss: 0.05231800675392151
Validation loss: 1.4896572328382922

Epoch: 5| Step: 5
Training loss: 0.0912586897611618
Validation loss: 1.51783662713984

Epoch: 5| Step: 6
Training loss: 0.06524159014225006
Validation loss: 1.5386458763512232

Epoch: 5| Step: 7
Training loss: 0.08662144839763641
Validation loss: 1.5005488511054748

Epoch: 5| Step: 8
Training loss: 0.054874807596206665
Validation loss: 1.555893676255339

Epoch: 5| Step: 9
Training loss: 0.04358694702386856
Validation loss: 1.565855368491142

Epoch: 5| Step: 10
Training loss: 0.06456568092107773
Validation loss: 1.5450863248558455

Epoch: 598| Step: 0
Training loss: 0.04709725081920624
Validation loss: 1.5342581310579855

Epoch: 5| Step: 1
Training loss: 0.04587293416261673
Validation loss: 1.5511666420967347

Epoch: 5| Step: 2
Training loss: 0.0695343017578125
Validation loss: 1.5141554885013129

Epoch: 5| Step: 3
Training loss: 0.06361319124698639
Validation loss: 1.5238254467646282

Epoch: 5| Step: 4
Training loss: 0.07459446042776108
Validation loss: 1.517619509850779

Epoch: 5| Step: 5
Training loss: 0.08241091668605804
Validation loss: 1.5199788462731145

Epoch: 5| Step: 6
Training loss: 0.08075306564569473
Validation loss: 1.5244916446747319

Epoch: 5| Step: 7
Training loss: 0.06176818534731865
Validation loss: 1.5180604534764444

Epoch: 5| Step: 8
Training loss: 0.08607473224401474
Validation loss: 1.5360877052430184

Epoch: 5| Step: 9
Training loss: 0.05834655836224556
Validation loss: 1.5420767953318935

Epoch: 5| Step: 10
Training loss: 0.10776624828577042
Validation loss: 1.5206634972685127

Epoch: 599| Step: 0
Training loss: 0.044679444283246994
Validation loss: 1.5115630242132372

Epoch: 5| Step: 1
Training loss: 0.07778499275445938
Validation loss: 1.5365256571000623

Epoch: 5| Step: 2
Training loss: 0.06681434065103531
Validation loss: 1.5439935826486157

Epoch: 5| Step: 3
Training loss: 0.08841676265001297
Validation loss: 1.546632452677655

Epoch: 5| Step: 4
Training loss: 0.08331293612718582
Validation loss: 1.5598525847158125

Epoch: 5| Step: 5
Training loss: 0.061535902321338654
Validation loss: 1.5484208817123084

Epoch: 5| Step: 6
Training loss: 0.053592748939991
Validation loss: 1.5421356975391347

Epoch: 5| Step: 7
Training loss: 0.061252981424331665
Validation loss: 1.5419409685237433

Epoch: 5| Step: 8
Training loss: 0.06285572052001953
Validation loss: 1.5424789139019546

Epoch: 5| Step: 9
Training loss: 0.0387880764901638
Validation loss: 1.527950838047971

Epoch: 5| Step: 10
Training loss: 0.04558708518743515
Validation loss: 1.5115298289124683

Epoch: 600| Step: 0
Training loss: 0.04665780067443848
Validation loss: 1.527448640074781

Epoch: 5| Step: 1
Training loss: 0.07012127339839935
Validation loss: 1.4930096774972894

Epoch: 5| Step: 2
Training loss: 0.06714435666799545
Validation loss: 1.5211154555761686

Epoch: 5| Step: 3
Training loss: 0.03546712547540665
Validation loss: 1.4889028995267806

Epoch: 5| Step: 4
Training loss: 0.04084508866071701
Validation loss: 1.4925547415210354

Epoch: 5| Step: 5
Training loss: 0.046097271144390106
Validation loss: 1.5188118770558348

Epoch: 5| Step: 6
Training loss: 0.058390915393829346
Validation loss: 1.4962268683218187

Epoch: 5| Step: 7
Training loss: 0.06520428508520126
Validation loss: 1.4910025327436385

Epoch: 5| Step: 8
Training loss: 0.08480606973171234
Validation loss: 1.5061910767709055

Epoch: 5| Step: 9
Training loss: 0.07229678332805634
Validation loss: 1.4696594169062953

Epoch: 5| Step: 10
Training loss: 0.04076024889945984
Validation loss: 1.494611886239821

Epoch: 601| Step: 0
Training loss: 0.05046631023287773
Validation loss: 1.4895981845035349

Epoch: 5| Step: 1
Training loss: 0.04685766622424126
Validation loss: 1.4805740361572595

Epoch: 5| Step: 2
Training loss: 0.0602237693965435
Validation loss: 1.480338123536879

Epoch: 5| Step: 3
Training loss: 0.06229259818792343
Validation loss: 1.481106311403295

Epoch: 5| Step: 4
Training loss: 0.0761701688170433
Validation loss: 1.5415371464144798

Epoch: 5| Step: 5
Training loss: 0.06109992787241936
Validation loss: 1.5092996499871696

Epoch: 5| Step: 6
Training loss: 0.054581575095653534
Validation loss: 1.5123073631717312

Epoch: 5| Step: 7
Training loss: 0.10792291164398193
Validation loss: 1.5222108646105694

Epoch: 5| Step: 8
Training loss: 0.07643978297710419
Validation loss: 1.4959886561157882

Epoch: 5| Step: 9
Training loss: 0.07648491114377975
Validation loss: 1.514963217960891

Epoch: 5| Step: 10
Training loss: 0.061403997242450714
Validation loss: 1.5134846446334675

Epoch: 602| Step: 0
Training loss: 0.04093152657151222
Validation loss: 1.5347100611655944

Epoch: 5| Step: 1
Training loss: 0.06715036928653717
Validation loss: 1.5462007445673789

Epoch: 5| Step: 2
Training loss: 0.058384429663419724
Validation loss: 1.555563296041181

Epoch: 5| Step: 3
Training loss: 0.060636747628450394
Validation loss: 1.5438602201400264

Epoch: 5| Step: 4
Training loss: 0.06508957594633102
Validation loss: 1.5473069933152968

Epoch: 5| Step: 5
Training loss: 0.08033599704504013
Validation loss: 1.5488078478843934

Epoch: 5| Step: 6
Training loss: 0.037951238453388214
Validation loss: 1.51579192889634

Epoch: 5| Step: 7
Training loss: 0.05568753555417061
Validation loss: 1.5209551754818167

Epoch: 5| Step: 8
Training loss: 0.03302805498242378
Validation loss: 1.54273191062353

Epoch: 5| Step: 9
Training loss: 0.05508978292346001
Validation loss: 1.5139244000116985

Epoch: 5| Step: 10
Training loss: 0.07190268486738205
Validation loss: 1.5343728385945803

Epoch: 603| Step: 0
Training loss: 0.06963281333446503
Validation loss: 1.531805306352595

Epoch: 5| Step: 1
Training loss: 0.05341898649930954
Validation loss: 1.545186879814312

Epoch: 5| Step: 2
Training loss: 0.07294055074453354
Validation loss: 1.5276749762155677

Epoch: 5| Step: 3
Training loss: 0.043145470321178436
Validation loss: 1.5280798878721011

Epoch: 5| Step: 4
Training loss: 0.07262003421783447
Validation loss: 1.5379442476457166

Epoch: 5| Step: 5
Training loss: 0.05171394348144531
Validation loss: 1.5517590404838644

Epoch: 5| Step: 6
Training loss: 0.053793907165527344
Validation loss: 1.5364177714111984

Epoch: 5| Step: 7
Training loss: 0.08417270332574844
Validation loss: 1.519534537869115

Epoch: 5| Step: 8
Training loss: 0.06331296265125275
Validation loss: 1.526115197007374

Epoch: 5| Step: 9
Training loss: 0.0732957050204277
Validation loss: 1.5003521685959191

Epoch: 5| Step: 10
Training loss: 0.05732550472021103
Validation loss: 1.5317564728439494

Epoch: 604| Step: 0
Training loss: 0.07229124009609222
Validation loss: 1.5227028080212173

Epoch: 5| Step: 1
Training loss: 0.06901168078184128
Validation loss: 1.4964681158783615

Epoch: 5| Step: 2
Training loss: 0.045359693467617035
Validation loss: 1.4881543369703396

Epoch: 5| Step: 3
Training loss: 0.07141177356243134
Validation loss: 1.4920856004120202

Epoch: 5| Step: 4
Training loss: 0.07825375348329544
Validation loss: 1.4908480849317325

Epoch: 5| Step: 5
Training loss: 0.05180075019598007
Validation loss: 1.4930771243187688

Epoch: 5| Step: 6
Training loss: 0.04275069385766983
Validation loss: 1.4910222958492976

Epoch: 5| Step: 7
Training loss: 0.05609816312789917
Validation loss: 1.5043082980699436

Epoch: 5| Step: 8
Training loss: 0.06835963577032089
Validation loss: 1.5011525718114709

Epoch: 5| Step: 9
Training loss: 0.05970964953303337
Validation loss: 1.5008506351901638

Epoch: 5| Step: 10
Training loss: 0.08968900144100189
Validation loss: 1.5156033282638879

Epoch: 605| Step: 0
Training loss: 0.06347097456455231
Validation loss: 1.4976192071873655

Epoch: 5| Step: 1
Training loss: 0.09503964334726334
Validation loss: 1.544371658755887

Epoch: 5| Step: 2
Training loss: 0.08062990009784698
Validation loss: 1.5194336804010535

Epoch: 5| Step: 3
Training loss: 0.07579279690980911
Validation loss: 1.515394426161243

Epoch: 5| Step: 4
Training loss: 0.04976861923933029
Validation loss: 1.519481799935782

Epoch: 5| Step: 5
Training loss: 0.044591642916202545
Validation loss: 1.499786328243953

Epoch: 5| Step: 6
Training loss: 0.048005472868680954
Validation loss: 1.5105444872251121

Epoch: 5| Step: 7
Training loss: 0.07748754322528839
Validation loss: 1.4967603222016366

Epoch: 5| Step: 8
Training loss: 0.07143427431583405
Validation loss: 1.5011467600381503

Epoch: 5| Step: 9
Training loss: 0.06132466346025467
Validation loss: 1.512558788381597

Epoch: 5| Step: 10
Training loss: 0.040132179856300354
Validation loss: 1.4960320444517239

Epoch: 606| Step: 0
Training loss: 0.06057988479733467
Validation loss: 1.5192170361036896

Epoch: 5| Step: 1
Training loss: 0.06091642379760742
Validation loss: 1.5357393295534196

Epoch: 5| Step: 2
Training loss: 0.051239319145679474
Validation loss: 1.5143555107937063

Epoch: 5| Step: 3
Training loss: 0.08173181861639023
Validation loss: 1.5227146135863436

Epoch: 5| Step: 4
Training loss: 0.05479168891906738
Validation loss: 1.502816770666389

Epoch: 5| Step: 5
Training loss: 0.04979373887181282
Validation loss: 1.4978365654586463

Epoch: 5| Step: 6
Training loss: 0.04354189336299896
Validation loss: 1.492118308621068

Epoch: 5| Step: 7
Training loss: 0.05501062795519829
Validation loss: 1.5051802358319681

Epoch: 5| Step: 8
Training loss: 0.07209773361682892
Validation loss: 1.5117779662532191

Epoch: 5| Step: 9
Training loss: 0.06787826120853424
Validation loss: 1.5285855595783522

Epoch: 5| Step: 10
Training loss: 0.07767493277788162
Validation loss: 1.5213244807335637

Epoch: 607| Step: 0
Training loss: 0.052842725068330765
Validation loss: 1.5146816122916438

Epoch: 5| Step: 1
Training loss: 0.10993283987045288
Validation loss: 1.503977035963407

Epoch: 5| Step: 2
Training loss: 0.07616928964853287
Validation loss: 1.5157166040071877

Epoch: 5| Step: 3
Training loss: 0.0710737481713295
Validation loss: 1.523481926610393

Epoch: 5| Step: 4
Training loss: 0.05136605352163315
Validation loss: 1.552138811798506

Epoch: 5| Step: 5
Training loss: 0.05718923732638359
Validation loss: 1.5538074149880359

Epoch: 5| Step: 6
Training loss: 0.05878932401537895
Validation loss: 1.5615105141875565

Epoch: 5| Step: 7
Training loss: 0.039442241191864014
Validation loss: 1.5322888666583645

Epoch: 5| Step: 8
Training loss: 0.05851566791534424
Validation loss: 1.547910262179631

Epoch: 5| Step: 9
Training loss: 0.07590600103139877
Validation loss: 1.518044174358409

Epoch: 5| Step: 10
Training loss: 0.035783082246780396
Validation loss: 1.5079580917153308

Epoch: 608| Step: 0
Training loss: 0.06156958267092705
Validation loss: 1.5151804333092065

Epoch: 5| Step: 1
Training loss: 0.06541047245264053
Validation loss: 1.554989718621777

Epoch: 5| Step: 2
Training loss: 0.09953803569078445
Validation loss: 1.5436301449293732

Epoch: 5| Step: 3
Training loss: 0.0393088161945343
Validation loss: 1.5363819804242862

Epoch: 5| Step: 4
Training loss: 0.07339271157979965
Validation loss: 1.5583013244854507

Epoch: 5| Step: 5
Training loss: 0.08248063176870346
Validation loss: 1.5522944363214637

Epoch: 5| Step: 6
Training loss: 0.05136497691273689
Validation loss: 1.5201548363572808

Epoch: 5| Step: 7
Training loss: 0.07047495245933533
Validation loss: 1.5520126973429034

Epoch: 5| Step: 8
Training loss: 0.08393637835979462
Validation loss: 1.5475462559730775

Epoch: 5| Step: 9
Training loss: 0.06810168921947479
Validation loss: 1.5458745623147616

Epoch: 5| Step: 10
Training loss: 0.10308998823165894
Validation loss: 1.5504906228793565

Epoch: 609| Step: 0
Training loss: 0.05638277530670166
Validation loss: 1.5405903618822816

Epoch: 5| Step: 1
Training loss: 0.0504889078438282
Validation loss: 1.5056865792120657

Epoch: 5| Step: 2
Training loss: 0.08723421394824982
Validation loss: 1.5185569435037591

Epoch: 5| Step: 3
Training loss: 0.08147285133600235
Validation loss: 1.5018026290401336

Epoch: 5| Step: 4
Training loss: 0.08206401765346527
Validation loss: 1.5191218558178152

Epoch: 5| Step: 5
Training loss: 0.08215071260929108
Validation loss: 1.534271409434657

Epoch: 5| Step: 6
Training loss: 0.07230708748102188
Validation loss: 1.5335126717885335

Epoch: 5| Step: 7
Training loss: 0.08095691353082657
Validation loss: 1.5401283233396468

Epoch: 5| Step: 8
Training loss: 0.054495859891176224
Validation loss: 1.5214647541763962

Epoch: 5| Step: 9
Training loss: 0.05145733430981636
Validation loss: 1.5557165504783712

Epoch: 5| Step: 10
Training loss: 0.03644883632659912
Validation loss: 1.5481158430858324

Epoch: 610| Step: 0
Training loss: 0.07093532383441925
Validation loss: 1.5301286853769773

Epoch: 5| Step: 1
Training loss: 0.057408273220062256
Validation loss: 1.5429631176815237

Epoch: 5| Step: 2
Training loss: 0.06363002210855484
Validation loss: 1.5500059852036097

Epoch: 5| Step: 3
Training loss: 0.09472878277301788
Validation loss: 1.543563844055258

Epoch: 5| Step: 4
Training loss: 0.08543846011161804
Validation loss: 1.5372665184800343

Epoch: 5| Step: 5
Training loss: 0.061113178730010986
Validation loss: 1.5182445433831984

Epoch: 5| Step: 6
Training loss: 0.08912099897861481
Validation loss: 1.5388545297807263

Epoch: 5| Step: 7
Training loss: 0.08083094656467438
Validation loss: 1.5145023779202533

Epoch: 5| Step: 8
Training loss: 0.04498175531625748
Validation loss: 1.5381800769477763

Epoch: 5| Step: 9
Training loss: 0.09986861795186996
Validation loss: 1.526617157843805

Epoch: 5| Step: 10
Training loss: 0.06245868280529976
Validation loss: 1.5110809110826062

Epoch: 611| Step: 0
Training loss: 0.0382530651986599
Validation loss: 1.5047319819850307

Epoch: 5| Step: 1
Training loss: 0.08426415175199509
Validation loss: 1.524754681894856

Epoch: 5| Step: 2
Training loss: 0.08358060568571091
Validation loss: 1.541855058362407

Epoch: 5| Step: 3
Training loss: 0.05595071241259575
Validation loss: 1.5514521483452088

Epoch: 5| Step: 4
Training loss: 0.09643097966909409
Validation loss: 1.537521432804805

Epoch: 5| Step: 5
Training loss: 0.04561064764857292
Validation loss: 1.5274586651914863

Epoch: 5| Step: 6
Training loss: 0.08004054427146912
Validation loss: 1.5403315751783309

Epoch: 5| Step: 7
Training loss: 0.062227994203567505
Validation loss: 1.5369949110092656

Epoch: 5| Step: 8
Training loss: 0.06994138658046722
Validation loss: 1.505713378229449

Epoch: 5| Step: 9
Training loss: 0.06753087043762207
Validation loss: 1.5219957123520553

Epoch: 5| Step: 10
Training loss: 0.03772597759962082
Validation loss: 1.5082633508149015

Epoch: 612| Step: 0
Training loss: 0.046293485909700394
Validation loss: 1.5237591817814817

Epoch: 5| Step: 1
Training loss: 0.04989582672715187
Validation loss: 1.5385538570342525

Epoch: 5| Step: 2
Training loss: 0.03983721137046814
Validation loss: 1.517506105925447

Epoch: 5| Step: 3
Training loss: 0.06893197447061539
Validation loss: 1.5130590629834

Epoch: 5| Step: 4
Training loss: 0.08476131409406662
Validation loss: 1.518977540795521

Epoch: 5| Step: 5
Training loss: 0.07102087140083313
Validation loss: 1.5037261311725905

Epoch: 5| Step: 6
Training loss: 0.0506107434630394
Validation loss: 1.4999622657734861

Epoch: 5| Step: 7
Training loss: 0.045572470873594284
Validation loss: 1.511948823928833

Epoch: 5| Step: 8
Training loss: 0.048933472484350204
Validation loss: 1.5238950355078584

Epoch: 5| Step: 9
Training loss: 0.0649905800819397
Validation loss: 1.5166997448090584

Epoch: 5| Step: 10
Training loss: 0.07794171571731567
Validation loss: 1.4923627543193039

Epoch: 613| Step: 0
Training loss: 0.050340455025434494
Validation loss: 1.493950443883096

Epoch: 5| Step: 1
Training loss: 0.05046619102358818
Validation loss: 1.5063535398052585

Epoch: 5| Step: 2
Training loss: 0.05954551696777344
Validation loss: 1.4813797448271064

Epoch: 5| Step: 3
Training loss: 0.04854271560907364
Validation loss: 1.4974102653482908

Epoch: 5| Step: 4
Training loss: 0.04543496295809746
Validation loss: 1.5146863345176942

Epoch: 5| Step: 5
Training loss: 0.061136115342378616
Validation loss: 1.4962915015477005

Epoch: 5| Step: 6
Training loss: 0.04453552886843681
Validation loss: 1.4930987127365605

Epoch: 5| Step: 7
Training loss: 0.04455970972776413
Validation loss: 1.5467445440189813

Epoch: 5| Step: 8
Training loss: 0.06403400748968124
Validation loss: 1.520459346873786

Epoch: 5| Step: 9
Training loss: 0.04380388930439949
Validation loss: 1.5372744651250942

Epoch: 5| Step: 10
Training loss: 0.088335320353508
Validation loss: 1.5278795073109288

Epoch: 614| Step: 0
Training loss: 0.059810418635606766
Validation loss: 1.5421243124110724

Epoch: 5| Step: 1
Training loss: 0.057247500866651535
Validation loss: 1.5295368138179983

Epoch: 5| Step: 2
Training loss: 0.060446418821811676
Validation loss: 1.5165762055304743

Epoch: 5| Step: 3
Training loss: 0.05133456736803055
Validation loss: 1.4899183563006821

Epoch: 5| Step: 4
Training loss: 0.05128809064626694
Validation loss: 1.496830831291855

Epoch: 5| Step: 5
Training loss: 0.0713137835264206
Validation loss: 1.4716922685664187

Epoch: 5| Step: 6
Training loss: 0.03543020039796829
Validation loss: 1.4923989195977487

Epoch: 5| Step: 7
Training loss: 0.03611592948436737
Validation loss: 1.4816186299888037

Epoch: 5| Step: 8
Training loss: 0.04789455980062485
Validation loss: 1.4947461697363085

Epoch: 5| Step: 9
Training loss: 0.0641707107424736
Validation loss: 1.4785307953434605

Epoch: 5| Step: 10
Training loss: 0.03994603455066681
Validation loss: 1.473538088542159

Epoch: 615| Step: 0
Training loss: 0.04275791719555855
Validation loss: 1.47170211679192

Epoch: 5| Step: 1
Training loss: 0.07840584218502045
Validation loss: 1.5013806461006083

Epoch: 5| Step: 2
Training loss: 0.06505993008613586
Validation loss: 1.4834227087677165

Epoch: 5| Step: 3
Training loss: 0.11734552681446075
Validation loss: 1.4900434055636007

Epoch: 5| Step: 4
Training loss: 0.0771900862455368
Validation loss: 1.4489745183657574

Epoch: 5| Step: 5
Training loss: 0.06636966019868851
Validation loss: 1.4745567267940891

Epoch: 5| Step: 6
Training loss: 0.05518041178584099
Validation loss: 1.457358173144761

Epoch: 5| Step: 7
Training loss: 0.07634790241718292
Validation loss: 1.4649296691340785

Epoch: 5| Step: 8
Training loss: 0.08151078969240189
Validation loss: 1.4870960315068562

Epoch: 5| Step: 9
Training loss: 0.08420015871524811
Validation loss: 1.4660685177772277

Epoch: 5| Step: 10
Training loss: 0.06131816655397415
Validation loss: 1.4696944439282982

Epoch: 616| Step: 0
Training loss: 0.0691649541258812
Validation loss: 1.4706711717831191

Epoch: 5| Step: 1
Training loss: 0.06815232336521149
Validation loss: 1.4914238170910907

Epoch: 5| Step: 2
Training loss: 0.04436693340539932
Validation loss: 1.514819698949014

Epoch: 5| Step: 3
Training loss: 0.06602916121482849
Validation loss: 1.4956843212086668

Epoch: 5| Step: 4
Training loss: 0.10447518527507782
Validation loss: 1.485345362335123

Epoch: 5| Step: 5
Training loss: 0.04182533174753189
Validation loss: 1.4722622632980347

Epoch: 5| Step: 6
Training loss: 0.09130673110485077
Validation loss: 1.536185601706146

Epoch: 5| Step: 7
Training loss: 0.08047760277986526
Validation loss: 1.4945006370544434

Epoch: 5| Step: 8
Training loss: 0.05209808424115181
Validation loss: 1.492207714306411

Epoch: 5| Step: 9
Training loss: 0.08129432052373886
Validation loss: 1.4789138775999828

Epoch: 5| Step: 10
Training loss: 0.042694706469774246
Validation loss: 1.5184138116016184

Epoch: 617| Step: 0
Training loss: 0.051305901259183884
Validation loss: 1.5015403263030513

Epoch: 5| Step: 1
Training loss: 0.08431435376405716
Validation loss: 1.5132219881139777

Epoch: 5| Step: 2
Training loss: 0.09464375674724579
Validation loss: 1.5172443248892342

Epoch: 5| Step: 3
Training loss: 0.053777288645505905
Validation loss: 1.5033716104363883

Epoch: 5| Step: 4
Training loss: 0.059910912066698074
Validation loss: 1.5172868146691272

Epoch: 5| Step: 5
Training loss: 0.07212633639574051
Validation loss: 1.5262069086874686

Epoch: 5| Step: 6
Training loss: 0.06557707488536835
Validation loss: 1.5103599794449345

Epoch: 5| Step: 7
Training loss: 0.06908269226551056
Validation loss: 1.5105136607282905

Epoch: 5| Step: 8
Training loss: 0.052174150943756104
Validation loss: 1.5279054769905664

Epoch: 5| Step: 9
Training loss: 0.06258808076381683
Validation loss: 1.5323654169677405

Epoch: 5| Step: 10
Training loss: 0.05254267528653145
Validation loss: 1.5120757882313063

Epoch: 618| Step: 0
Training loss: 0.04021882265806198
Validation loss: 1.5134266602095736

Epoch: 5| Step: 1
Training loss: 0.042817123234272
Validation loss: 1.518440870828526

Epoch: 5| Step: 2
Training loss: 0.07666907459497452
Validation loss: 1.5299371775760446

Epoch: 5| Step: 3
Training loss: 0.05163506418466568
Validation loss: 1.5266016362815775

Epoch: 5| Step: 4
Training loss: 0.07275229692459106
Validation loss: 1.5397552931180565

Epoch: 5| Step: 5
Training loss: 0.04700081795454025
Validation loss: 1.5438838645976076

Epoch: 5| Step: 6
Training loss: 0.0981118306517601
Validation loss: 1.554021334135404

Epoch: 5| Step: 7
Training loss: 0.06300974637269974
Validation loss: 1.5445964695304952

Epoch: 5| Step: 8
Training loss: 0.08849386870861053
Validation loss: 1.5750899968608734

Epoch: 5| Step: 9
Training loss: 0.08333446085453033
Validation loss: 1.5671358685339651

Epoch: 5| Step: 10
Training loss: 0.04798576235771179
Validation loss: 1.559529698023232

Epoch: 619| Step: 0
Training loss: 0.06434498727321625
Validation loss: 1.538293905155633

Epoch: 5| Step: 1
Training loss: 0.04972132295370102
Validation loss: 1.5426219406948294

Epoch: 5| Step: 2
Training loss: 0.0674230232834816
Validation loss: 1.5486524242867705

Epoch: 5| Step: 3
Training loss: 0.08202224969863892
Validation loss: 1.5340664168839813

Epoch: 5| Step: 4
Training loss: 0.05908840894699097
Validation loss: 1.540744384129842

Epoch: 5| Step: 5
Training loss: 0.09635918587446213
Validation loss: 1.5417966137650192

Epoch: 5| Step: 6
Training loss: 0.06720638275146484
Validation loss: 1.5579135020573933

Epoch: 5| Step: 7
Training loss: 0.10429593175649643
Validation loss: 1.542159176641895

Epoch: 5| Step: 8
Training loss: 0.03233838081359863
Validation loss: 1.5169072279366114

Epoch: 5| Step: 9
Training loss: 0.07891471683979034
Validation loss: 1.531933630666425

Epoch: 5| Step: 10
Training loss: 0.0452880933880806
Validation loss: 1.5190106937962193

Epoch: 620| Step: 0
Training loss: 0.0503200888633728
Validation loss: 1.518595942886927

Epoch: 5| Step: 1
Training loss: 0.029346179217100143
Validation loss: 1.493795939671096

Epoch: 5| Step: 2
Training loss: 0.06181727722287178
Validation loss: 1.4969741375215593

Epoch: 5| Step: 3
Training loss: 0.042927730828523636
Validation loss: 1.4958517641149542

Epoch: 5| Step: 4
Training loss: 0.06414242088794708
Validation loss: 1.5030006349727671

Epoch: 5| Step: 5
Training loss: 0.05700713396072388
Validation loss: 1.4927720267285582

Epoch: 5| Step: 6
Training loss: 0.05370881408452988
Validation loss: 1.4720621942191996

Epoch: 5| Step: 7
Training loss: 0.05943824723362923
Validation loss: 1.481782199234091

Epoch: 5| Step: 8
Training loss: 0.03320177271962166
Validation loss: 1.4833471992964387

Epoch: 5| Step: 9
Training loss: 0.0699896365404129
Validation loss: 1.4706503454075064

Epoch: 5| Step: 10
Training loss: 0.04839565232396126
Validation loss: 1.4724603558099398

Epoch: 621| Step: 0
Training loss: 0.05422510951757431
Validation loss: 1.487146226308679

Epoch: 5| Step: 1
Training loss: 0.05952467396855354
Validation loss: 1.474712469244516

Epoch: 5| Step: 2
Training loss: 0.04259752109646797
Validation loss: 1.4753905701380905

Epoch: 5| Step: 3
Training loss: 0.0739254429936409
Validation loss: 1.4780240699809084

Epoch: 5| Step: 4
Training loss: 0.055488426238298416
Validation loss: 1.4860174207277195

Epoch: 5| Step: 5
Training loss: 0.036245398223400116
Validation loss: 1.4929121181529055

Epoch: 5| Step: 6
Training loss: 0.06941942125558853
Validation loss: 1.4616167827319073

Epoch: 5| Step: 7
Training loss: 0.04244770109653473
Validation loss: 1.5002679222373552

Epoch: 5| Step: 8
Training loss: 0.08589821308851242
Validation loss: 1.5038715575331

Epoch: 5| Step: 9
Training loss: 0.08188092708587646
Validation loss: 1.5079872659457627

Epoch: 5| Step: 10
Training loss: 0.04244937747716904
Validation loss: 1.5167373495717202

Epoch: 622| Step: 0
Training loss: 0.08674351871013641
Validation loss: 1.521127828987696

Epoch: 5| Step: 1
Training loss: 0.056597840040922165
Validation loss: 1.53542572452176

Epoch: 5| Step: 2
Training loss: 0.07549969106912613
Validation loss: 1.5002298637103009

Epoch: 5| Step: 3
Training loss: 0.0565921887755394
Validation loss: 1.4767101400641984

Epoch: 5| Step: 4
Training loss: 0.07580998539924622
Validation loss: 1.5081713699525403

Epoch: 5| Step: 5
Training loss: 0.07944298535585403
Validation loss: 1.4881127213919034

Epoch: 5| Step: 6
Training loss: 0.036739010363817215
Validation loss: 1.488117862773198

Epoch: 5| Step: 7
Training loss: 0.04063142091035843
Validation loss: 1.4729729749823128

Epoch: 5| Step: 8
Training loss: 0.02989063784480095
Validation loss: 1.4469626795861028

Epoch: 5| Step: 9
Training loss: 0.09357322752475739
Validation loss: 1.4766061408545381

Epoch: 5| Step: 10
Training loss: 0.05218096077442169
Validation loss: 1.486076578017204

Epoch: 623| Step: 0
Training loss: 0.034974269568920135
Validation loss: 1.488316770522825

Epoch: 5| Step: 1
Training loss: 0.11898704618215561
Validation loss: 1.4775112572536673

Epoch: 5| Step: 2
Training loss: 0.045931726694107056
Validation loss: 1.4612466314787507

Epoch: 5| Step: 3
Training loss: 0.06725268065929413
Validation loss: 1.4907003551401117

Epoch: 5| Step: 4
Training loss: 0.07816166430711746
Validation loss: 1.4890388647715251

Epoch: 5| Step: 5
Training loss: 0.05226787179708481
Validation loss: 1.485429815066758

Epoch: 5| Step: 6
Training loss: 0.02966507151722908
Validation loss: 1.4681097051148773

Epoch: 5| Step: 7
Training loss: 0.06289234012365341
Validation loss: 1.4996819976837403

Epoch: 5| Step: 8
Training loss: 0.06360620260238647
Validation loss: 1.503645836666066

Epoch: 5| Step: 9
Training loss: 0.08416236191987991
Validation loss: 1.5087191571471512

Epoch: 5| Step: 10
Training loss: 0.0835694670677185
Validation loss: 1.5174479535830918

Epoch: 624| Step: 0
Training loss: 0.043905407190322876
Validation loss: 1.490202803765574

Epoch: 5| Step: 1
Training loss: 0.05209103971719742
Validation loss: 1.5088717476014168

Epoch: 5| Step: 2
Training loss: 0.043728429824113846
Validation loss: 1.5031568132421023

Epoch: 5| Step: 3
Training loss: 0.10800860077142715
Validation loss: 1.5129063988244662

Epoch: 5| Step: 4
Training loss: 0.04171338677406311
Validation loss: 1.5078570060832526

Epoch: 5| Step: 5
Training loss: 0.05307899788022041
Validation loss: 1.4791949205501105

Epoch: 5| Step: 6
Training loss: 0.05178412050008774
Validation loss: 1.4883699673478321

Epoch: 5| Step: 7
Training loss: 0.056839216500520706
Validation loss: 1.4890219075705415

Epoch: 5| Step: 8
Training loss: 0.07480843365192413
Validation loss: 1.490730175407984

Epoch: 5| Step: 9
Training loss: 0.04458349198102951
Validation loss: 1.4569959127774803

Epoch: 5| Step: 10
Training loss: 0.04676837846636772
Validation loss: 1.4672927510353826

Epoch: 625| Step: 0
Training loss: 0.054491616785526276
Validation loss: 1.460549904454139

Epoch: 5| Step: 1
Training loss: 0.06233633682131767
Validation loss: 1.473220222739763

Epoch: 5| Step: 2
Training loss: 0.045386772602796555
Validation loss: 1.4545728109216178

Epoch: 5| Step: 3
Training loss: 0.04738814756274223
Validation loss: 1.4923933744430542

Epoch: 5| Step: 4
Training loss: 0.05583130195736885
Validation loss: 1.4869830313549246

Epoch: 5| Step: 5
Training loss: 0.11098019778728485
Validation loss: 1.5002018924682372

Epoch: 5| Step: 6
Training loss: 0.0840008482336998
Validation loss: 1.502862000337211

Epoch: 5| Step: 7
Training loss: 0.08690942823886871
Validation loss: 1.4982482976810907

Epoch: 5| Step: 8
Training loss: 0.05475379154086113
Validation loss: 1.496135155359904

Epoch: 5| Step: 9
Training loss: 0.06553871929645538
Validation loss: 1.4823111616155153

Epoch: 5| Step: 10
Training loss: 0.04181251302361488
Validation loss: 1.486208910583168

Epoch: 626| Step: 0
Training loss: 0.0630967766046524
Validation loss: 1.475789854603429

Epoch: 5| Step: 1
Training loss: 0.05028712749481201
Validation loss: 1.494603580044162

Epoch: 5| Step: 2
Training loss: 0.06241121143102646
Validation loss: 1.4952545499288907

Epoch: 5| Step: 3
Training loss: 0.07735501229763031
Validation loss: 1.520953284155938

Epoch: 5| Step: 4
Training loss: 0.07534851878881454
Validation loss: 1.4843925711929158

Epoch: 5| Step: 5
Training loss: 0.07535284757614136
Validation loss: 1.4964447559848908

Epoch: 5| Step: 6
Training loss: 0.06810522824525833
Validation loss: 1.5032834135076052

Epoch: 5| Step: 7
Training loss: 0.08126592636108398
Validation loss: 1.4922648322197698

Epoch: 5| Step: 8
Training loss: 0.06399133801460266
Validation loss: 1.4851407312577771

Epoch: 5| Step: 9
Training loss: 0.038435786962509155
Validation loss: 1.4733648479625743

Epoch: 5| Step: 10
Training loss: 0.06999469548463821
Validation loss: 1.4965834899615216

Epoch: 627| Step: 0
Training loss: 0.041664350777864456
Validation loss: 1.4884065178132826

Epoch: 5| Step: 1
Training loss: 0.04823530092835426
Validation loss: 1.502264912410449

Epoch: 5| Step: 2
Training loss: 0.07784682512283325
Validation loss: 1.5146123234943678

Epoch: 5| Step: 3
Training loss: 0.06416763365268707
Validation loss: 1.534153898557027

Epoch: 5| Step: 4
Training loss: 0.06923862546682358
Validation loss: 1.5118670796835294

Epoch: 5| Step: 5
Training loss: 0.07378430664539337
Validation loss: 1.5229147159925072

Epoch: 5| Step: 6
Training loss: 0.07927524298429489
Validation loss: 1.5073050375907653

Epoch: 5| Step: 7
Training loss: 0.05634498596191406
Validation loss: 1.4852282430536003

Epoch: 5| Step: 8
Training loss: 0.08493145555257797
Validation loss: 1.4798541081848966

Epoch: 5| Step: 9
Training loss: 0.06713927537202835
Validation loss: 1.519956583617836

Epoch: 5| Step: 10
Training loss: 0.05002625659108162
Validation loss: 1.4997148065156833

Epoch: 628| Step: 0
Training loss: 0.0628693699836731
Validation loss: 1.5111915437124108

Epoch: 5| Step: 1
Training loss: 0.05999695509672165
Validation loss: 1.5338160062348971

Epoch: 5| Step: 2
Training loss: 0.07664667814970016
Validation loss: 1.525610100838446

Epoch: 5| Step: 3
Training loss: 0.13711875677108765
Validation loss: 1.5472758021405948

Epoch: 5| Step: 4
Training loss: 0.08560667186975479
Validation loss: 1.5256593637568976

Epoch: 5| Step: 5
Training loss: 0.04987138882279396
Validation loss: 1.5430229056266047

Epoch: 5| Step: 6
Training loss: 0.08349653333425522
Validation loss: 1.5500131691655805

Epoch: 5| Step: 7
Training loss: 0.0577363595366478
Validation loss: 1.499806841534953

Epoch: 5| Step: 8
Training loss: 0.06016073375940323
Validation loss: 1.4990653735335155

Epoch: 5| Step: 9
Training loss: 0.11599073559045792
Validation loss: 1.5137050318461593

Epoch: 5| Step: 10
Training loss: 0.060328397899866104
Validation loss: 1.5264163773546937

Epoch: 629| Step: 0
Training loss: 0.08689597994089127
Validation loss: 1.4929207063490344

Epoch: 5| Step: 1
Training loss: 0.09216651320457458
Validation loss: 1.5260819991429646

Epoch: 5| Step: 2
Training loss: 0.06126449629664421
Validation loss: 1.5557394566074494

Epoch: 5| Step: 3
Training loss: 0.10982295125722885
Validation loss: 1.5580118510030931

Epoch: 5| Step: 4
Training loss: 0.13179314136505127
Validation loss: 1.5735159920107933

Epoch: 5| Step: 5
Training loss: 0.11814526468515396
Validation loss: 1.5665362291438605

Epoch: 5| Step: 6
Training loss: 0.06228926032781601
Validation loss: 1.5373722519925845

Epoch: 5| Step: 7
Training loss: 0.07826978713274002
Validation loss: 1.534803666094298

Epoch: 5| Step: 8
Training loss: 0.060788560658693314
Validation loss: 1.5350608466773905

Epoch: 5| Step: 9
Training loss: 0.04431835561990738
Validation loss: 1.5386104071012108

Epoch: 5| Step: 10
Training loss: 0.053649384528398514
Validation loss: 1.5338583812918714

Epoch: 630| Step: 0
Training loss: 0.07068221271038055
Validation loss: 1.524583892155719

Epoch: 5| Step: 1
Training loss: 0.03699817880988121
Validation loss: 1.496313174565633

Epoch: 5| Step: 2
Training loss: 0.061482083052396774
Validation loss: 1.4942606238908664

Epoch: 5| Step: 3
Training loss: 0.10744768381118774
Validation loss: 1.482413653404482

Epoch: 5| Step: 4
Training loss: 0.0617716908454895
Validation loss: 1.4912008431649977

Epoch: 5| Step: 5
Training loss: 0.042244672775268555
Validation loss: 1.4880579158823977

Epoch: 5| Step: 6
Training loss: 0.07124924659729004
Validation loss: 1.488847932507915

Epoch: 5| Step: 7
Training loss: 0.08077265322208405
Validation loss: 1.4705476837773477

Epoch: 5| Step: 8
Training loss: 0.07638620585203171
Validation loss: 1.4638224032617384

Epoch: 5| Step: 9
Training loss: 0.08270923793315887
Validation loss: 1.4686105123130224

Epoch: 5| Step: 10
Training loss: 0.0941709354519844
Validation loss: 1.4764383005839523

Epoch: 631| Step: 0
Training loss: 0.07087495177984238
Validation loss: 1.486278321153374

Epoch: 5| Step: 1
Training loss: 0.07801251113414764
Validation loss: 1.4956551982510475

Epoch: 5| Step: 2
Training loss: 0.09800458699464798
Validation loss: 1.4987714008618427

Epoch: 5| Step: 3
Training loss: 0.045962680131196976
Validation loss: 1.4793395521820232

Epoch: 5| Step: 4
Training loss: 0.08311744779348373
Validation loss: 1.5126976531039003

Epoch: 5| Step: 5
Training loss: 0.03978169709444046
Validation loss: 1.4933212944256362

Epoch: 5| Step: 6
Training loss: 0.03993941470980644
Validation loss: 1.5088971558437552

Epoch: 5| Step: 7
Training loss: 0.0653943121433258
Validation loss: 1.5101643570007817

Epoch: 5| Step: 8
Training loss: 0.05570362135767937
Validation loss: 1.551055053228973

Epoch: 5| Step: 9
Training loss: 0.10563423484563828
Validation loss: 1.5510816317732616

Epoch: 5| Step: 10
Training loss: 0.08743531256914139
Validation loss: 1.5078945236821328

Epoch: 632| Step: 0
Training loss: 0.08210913836956024
Validation loss: 1.5094419743425103

Epoch: 5| Step: 1
Training loss: 0.06049836426973343
Validation loss: 1.4789453591069868

Epoch: 5| Step: 2
Training loss: 0.05727415159344673
Validation loss: 1.51342406324161

Epoch: 5| Step: 3
Training loss: 0.11619776487350464
Validation loss: 1.548639617940431

Epoch: 5| Step: 4
Training loss: 0.061091769486665726
Validation loss: 1.569397743030261

Epoch: 5| Step: 5
Training loss: 0.09666313230991364
Validation loss: 1.587111339774183

Epoch: 5| Step: 6
Training loss: 0.08031865954399109
Validation loss: 1.551862556447265

Epoch: 5| Step: 7
Training loss: 0.05741320922970772
Validation loss: 1.5235189737812165

Epoch: 5| Step: 8
Training loss: 0.10361967980861664
Validation loss: 1.55480327657474

Epoch: 5| Step: 9
Training loss: 0.04266798123717308
Validation loss: 1.5525207275985389

Epoch: 5| Step: 10
Training loss: 0.0667867362499237
Validation loss: 1.5577061528800635

Epoch: 633| Step: 0
Training loss: 0.0875316932797432
Validation loss: 1.5741374069644558

Epoch: 5| Step: 1
Training loss: 0.15259520709514618
Validation loss: 1.5710412276688444

Epoch: 5| Step: 2
Training loss: 0.09224236756563187
Validation loss: 1.5811557795411797

Epoch: 5| Step: 3
Training loss: 0.08235678821802139
Validation loss: 1.5416173601663241

Epoch: 5| Step: 4
Training loss: 0.05047857016324997
Validation loss: 1.5321864735695623

Epoch: 5| Step: 5
Training loss: 0.07964824140071869
Validation loss: 1.5102923941868607

Epoch: 5| Step: 6
Training loss: 0.07249985635280609
Validation loss: 1.5049229488577893

Epoch: 5| Step: 7
Training loss: 0.08748777955770493
Validation loss: 1.5533923256781794

Epoch: 5| Step: 8
Training loss: 0.06595172733068466
Validation loss: 1.5255889687486874

Epoch: 5| Step: 9
Training loss: 0.05235327035188675
Validation loss: 1.4978705298516057

Epoch: 5| Step: 10
Training loss: 0.09206040948629379
Validation loss: 1.4986665723144368

Epoch: 634| Step: 0
Training loss: 0.07053301483392715
Validation loss: 1.4837246171889766

Epoch: 5| Step: 1
Training loss: 0.06039471551775932
Validation loss: 1.4861351123420141

Epoch: 5| Step: 2
Training loss: 0.043843332678079605
Validation loss: 1.5128106314648864

Epoch: 5| Step: 3
Training loss: 0.0663844496011734
Validation loss: 1.4966865585696312

Epoch: 5| Step: 4
Training loss: 0.06950607150793076
Validation loss: 1.5015680687401884

Epoch: 5| Step: 5
Training loss: 0.07732407748699188
Validation loss: 1.527339417447326

Epoch: 5| Step: 6
Training loss: 0.09583961218595505
Validation loss: 1.4790900112480245

Epoch: 5| Step: 7
Training loss: 0.05112184211611748
Validation loss: 1.5110402978876585

Epoch: 5| Step: 8
Training loss: 0.09935291111469269
Validation loss: 1.4725513330069921

Epoch: 5| Step: 9
Training loss: 0.08125557750463486
Validation loss: 1.4799396786638486

Epoch: 5| Step: 10
Training loss: 0.06723432242870331
Validation loss: 1.507020127388739

Epoch: 635| Step: 0
Training loss: 0.05976882576942444
Validation loss: 1.4984396978091168

Epoch: 5| Step: 1
Training loss: 0.07512061297893524
Validation loss: 1.5389908629079019

Epoch: 5| Step: 2
Training loss: 0.04088778793811798
Validation loss: 1.551332845482775

Epoch: 5| Step: 3
Training loss: 0.1041729673743248
Validation loss: 1.5722373993166032

Epoch: 5| Step: 4
Training loss: 0.09660713374614716
Validation loss: 1.5934737292669152

Epoch: 5| Step: 5
Training loss: 0.1106758713722229
Validation loss: 1.5722258360155168

Epoch: 5| Step: 6
Training loss: 0.11327151209115982
Validation loss: 1.5644683863527031

Epoch: 5| Step: 7
Training loss: 0.08206924796104431
Validation loss: 1.536126793071788

Epoch: 5| Step: 8
Training loss: 0.04842175543308258
Validation loss: 1.5162576347269037

Epoch: 5| Step: 9
Training loss: 0.05301413685083389
Validation loss: 1.5160365399493967

Epoch: 5| Step: 10
Training loss: 0.05741168558597565
Validation loss: 1.517074881061431

Epoch: 636| Step: 0
Training loss: 0.07650098949670792
Validation loss: 1.5085495479645268

Epoch: 5| Step: 1
Training loss: 0.08843116462230682
Validation loss: 1.5086958997993059

Epoch: 5| Step: 2
Training loss: 0.10335175693035126
Validation loss: 1.493987073180496

Epoch: 5| Step: 3
Training loss: 0.07261953502893448
Validation loss: 1.497550533663842

Epoch: 5| Step: 4
Training loss: 0.04445730149745941
Validation loss: 1.4796291910192019

Epoch: 5| Step: 5
Training loss: 0.059615910053253174
Validation loss: 1.4790717683812624

Epoch: 5| Step: 6
Training loss: 0.08947388827800751
Validation loss: 1.5360381603240967

Epoch: 5| Step: 7
Training loss: 0.07835328578948975
Validation loss: 1.5236843542386127

Epoch: 5| Step: 8
Training loss: 0.09671086072921753
Validation loss: 1.5237105392640637

Epoch: 5| Step: 9
Training loss: 0.09467153996229172
Validation loss: 1.5223175889702254

Epoch: 5| Step: 10
Training loss: 0.09344504028558731
Validation loss: 1.5236093959500712

Epoch: 637| Step: 0
Training loss: 0.06721220910549164
Validation loss: 1.504292731644005

Epoch: 5| Step: 1
Training loss: 0.0676812008023262
Validation loss: 1.5104128506875807

Epoch: 5| Step: 2
Training loss: 0.05153189226984978
Validation loss: 1.5046011094124085

Epoch: 5| Step: 3
Training loss: 0.07999280095100403
Validation loss: 1.4898516772895731

Epoch: 5| Step: 4
Training loss: 0.05032265931367874
Validation loss: 1.477424015281021

Epoch: 5| Step: 5
Training loss: 0.07905632257461548
Validation loss: 1.4759911926843787

Epoch: 5| Step: 6
Training loss: 0.08342792093753815
Validation loss: 1.4624304233058807

Epoch: 5| Step: 7
Training loss: 0.06878973543643951
Validation loss: 1.4811673728368615

Epoch: 5| Step: 8
Training loss: 0.05108297988772392
Validation loss: 1.465276446393741

Epoch: 5| Step: 9
Training loss: 0.08062846958637238
Validation loss: 1.4721899160774805

Epoch: 5| Step: 10
Training loss: 0.06305798143148422
Validation loss: 1.4824748680155764

Epoch: 638| Step: 0
Training loss: 0.047255393117666245
Validation loss: 1.4886137708540885

Epoch: 5| Step: 1
Training loss: 0.07615920901298523
Validation loss: 1.506884756908622

Epoch: 5| Step: 2
Training loss: 0.049220528453588486
Validation loss: 1.4868839261352376

Epoch: 5| Step: 3
Training loss: 0.04721904918551445
Validation loss: 1.4946023712876022

Epoch: 5| Step: 4
Training loss: 0.07378929853439331
Validation loss: 1.4923149103759437

Epoch: 5| Step: 5
Training loss: 0.08619561046361923
Validation loss: 1.4923346401542745

Epoch: 5| Step: 6
Training loss: 0.09349557757377625
Validation loss: 1.501665993403363

Epoch: 5| Step: 7
Training loss: 0.04024878889322281
Validation loss: 1.5063672565644788

Epoch: 5| Step: 8
Training loss: 0.0548502616584301
Validation loss: 1.4927670519839051

Epoch: 5| Step: 9
Training loss: 0.05924045294523239
Validation loss: 1.49800701807904

Epoch: 5| Step: 10
Training loss: 0.06260724365711212
Validation loss: 1.514100096559012

Epoch: 639| Step: 0
Training loss: 0.04983986169099808
Validation loss: 1.534524611247483

Epoch: 5| Step: 1
Training loss: 0.05815395712852478
Validation loss: 1.5338401307341873

Epoch: 5| Step: 2
Training loss: 0.09683118760585785
Validation loss: 1.5282549306910524

Epoch: 5| Step: 3
Training loss: 0.08340097963809967
Validation loss: 1.5097257911518056

Epoch: 5| Step: 4
Training loss: 0.06382883340120316
Validation loss: 1.5116000675385999

Epoch: 5| Step: 5
Training loss: 0.06052316352725029
Validation loss: 1.527483432523666

Epoch: 5| Step: 6
Training loss: 0.07789143174886703
Validation loss: 1.5294248596314461

Epoch: 5| Step: 7
Training loss: 0.051926564425230026
Validation loss: 1.5231573479149931

Epoch: 5| Step: 8
Training loss: 0.04421477019786835
Validation loss: 1.5228361660434353

Epoch: 5| Step: 9
Training loss: 0.09024109691381454
Validation loss: 1.5162467174632575

Epoch: 5| Step: 10
Training loss: 0.04380722716450691
Validation loss: 1.5298523620892597

Epoch: 640| Step: 0
Training loss: 0.04439329355955124
Validation loss: 1.5003092442789385

Epoch: 5| Step: 1
Training loss: 0.05081229284405708
Validation loss: 1.525899148756458

Epoch: 5| Step: 2
Training loss: 0.0849093645811081
Validation loss: 1.5129749005840671

Epoch: 5| Step: 3
Training loss: 0.04894469305872917
Validation loss: 1.4869867588884087

Epoch: 5| Step: 4
Training loss: 0.11176633834838867
Validation loss: 1.5050997105977868

Epoch: 5| Step: 5
Training loss: 0.06644196808338165
Validation loss: 1.5022257771543277

Epoch: 5| Step: 6
Training loss: 0.08766195923089981
Validation loss: 1.4811595293783373

Epoch: 5| Step: 7
Training loss: 0.09207269549369812
Validation loss: 1.4769632829132902

Epoch: 5| Step: 8
Training loss: 0.043450918048620224
Validation loss: 1.5113863175915134

Epoch: 5| Step: 9
Training loss: 0.05513954162597656
Validation loss: 1.5324460370566255

Epoch: 5| Step: 10
Training loss: 0.04299314320087433
Validation loss: 1.5309832954919467

Epoch: 641| Step: 0
Training loss: 0.06648589670658112
Validation loss: 1.5395373708458358

Epoch: 5| Step: 1
Training loss: 0.06364480406045914
Validation loss: 1.5361515629676081

Epoch: 5| Step: 2
Training loss: 0.09079726785421371
Validation loss: 1.5418148963682112

Epoch: 5| Step: 3
Training loss: 0.07805763185024261
Validation loss: 1.5715310394123037

Epoch: 5| Step: 4
Training loss: 0.06248240917921066
Validation loss: 1.5652544229261336

Epoch: 5| Step: 5
Training loss: 0.06131990626454353
Validation loss: 1.5511081359719718

Epoch: 5| Step: 6
Training loss: 0.03931383043527603
Validation loss: 1.5367215423173801

Epoch: 5| Step: 7
Training loss: 0.0426521971821785
Validation loss: 1.5221145422227922

Epoch: 5| Step: 8
Training loss: 0.06513480842113495
Validation loss: 1.5305066762431976

Epoch: 5| Step: 9
Training loss: 0.044600050896406174
Validation loss: 1.5097340332564486

Epoch: 5| Step: 10
Training loss: 0.11178954690694809
Validation loss: 1.5221652561618435

Epoch: 642| Step: 0
Training loss: 0.04890919849276543
Validation loss: 1.5132219387638954

Epoch: 5| Step: 1
Training loss: 0.09522228688001633
Validation loss: 1.529669528366417

Epoch: 5| Step: 2
Training loss: 0.07526490837335587
Validation loss: 1.5280511552287686

Epoch: 5| Step: 3
Training loss: 0.07152928411960602
Validation loss: 1.4826317512860863

Epoch: 5| Step: 4
Training loss: 0.0789070576429367
Validation loss: 1.4922389009947419

Epoch: 5| Step: 5
Training loss: 0.03827274963259697
Validation loss: 1.5012206697976718

Epoch: 5| Step: 6
Training loss: 0.06392301619052887
Validation loss: 1.5056596853399788

Epoch: 5| Step: 7
Training loss: 0.05467768758535385
Validation loss: 1.488728218181159

Epoch: 5| Step: 8
Training loss: 0.06711013615131378
Validation loss: 1.4932030465013237

Epoch: 5| Step: 9
Training loss: 0.08637551218271255
Validation loss: 1.5049009553847774

Epoch: 5| Step: 10
Training loss: 0.06262337416410446
Validation loss: 1.4887808151142572

Epoch: 643| Step: 0
Training loss: 0.03202676400542259
Validation loss: 1.508601648833162

Epoch: 5| Step: 1
Training loss: 0.06616206467151642
Validation loss: 1.51144778343939

Epoch: 5| Step: 2
Training loss: 0.07768629491329193
Validation loss: 1.522716208170819

Epoch: 5| Step: 3
Training loss: 0.055198825895786285
Validation loss: 1.5293292665994296

Epoch: 5| Step: 4
Training loss: 0.07057210803031921
Validation loss: 1.547938339171871

Epoch: 5| Step: 5
Training loss: 0.052025001496076584
Validation loss: 1.5394341676465926

Epoch: 5| Step: 6
Training loss: 0.05298420786857605
Validation loss: 1.5493495041324246

Epoch: 5| Step: 7
Training loss: 0.08504655212163925
Validation loss: 1.553398282297196

Epoch: 5| Step: 8
Training loss: 0.06793493777513504
Validation loss: 1.5777020467224943

Epoch: 5| Step: 9
Training loss: 0.06975437700748444
Validation loss: 1.5926702496826008

Epoch: 5| Step: 10
Training loss: 0.05969718098640442
Validation loss: 1.5725010582195815

Epoch: 644| Step: 0
Training loss: 0.07783837616443634
Validation loss: 1.5850394528399232

Epoch: 5| Step: 1
Training loss: 0.06760238111019135
Validation loss: 1.597149883547137

Epoch: 5| Step: 2
Training loss: 0.06500516831874847
Validation loss: 1.5940206332873272

Epoch: 5| Step: 3
Training loss: 0.07752399146556854
Validation loss: 1.5758935379725632

Epoch: 5| Step: 4
Training loss: 0.06782498210668564
Validation loss: 1.5339105308696788

Epoch: 5| Step: 5
Training loss: 0.062103282660245895
Validation loss: 1.53033310110851

Epoch: 5| Step: 6
Training loss: 0.0819924920797348
Validation loss: 1.520685007495265

Epoch: 5| Step: 7
Training loss: 0.08105462044477463
Validation loss: 1.5183323890932146

Epoch: 5| Step: 8
Training loss: 0.07107289135456085
Validation loss: 1.5081168938708562

Epoch: 5| Step: 9
Training loss: 0.06523819267749786
Validation loss: 1.5239209910874725

Epoch: 5| Step: 10
Training loss: 0.07966038584709167
Validation loss: 1.5352794367779967

Epoch: 645| Step: 0
Training loss: 0.06447911262512207
Validation loss: 1.490986518962409

Epoch: 5| Step: 1
Training loss: 0.06170067936182022
Validation loss: 1.493039076046277

Epoch: 5| Step: 2
Training loss: 0.041421957314014435
Validation loss: 1.4886713335590978

Epoch: 5| Step: 3
Training loss: 0.04423834756016731
Validation loss: 1.516414011678388

Epoch: 5| Step: 4
Training loss: 0.06318077445030212
Validation loss: 1.4844860620396112

Epoch: 5| Step: 5
Training loss: 0.09532566368579865
Validation loss: 1.5131358254340388

Epoch: 5| Step: 6
Training loss: 0.0643608421087265
Validation loss: 1.4829129583092147

Epoch: 5| Step: 7
Training loss: 0.06015680357813835
Validation loss: 1.4695064701059812

Epoch: 5| Step: 8
Training loss: 0.06506584584712982
Validation loss: 1.462042389377471

Epoch: 5| Step: 9
Training loss: 0.06331849843263626
Validation loss: 1.445651989470246

Epoch: 5| Step: 10
Training loss: 0.0758940577507019
Validation loss: 1.467109102074818

Epoch: 646| Step: 0
Training loss: 0.08354891836643219
Validation loss: 1.4450212973420338

Epoch: 5| Step: 1
Training loss: 0.07162405550479889
Validation loss: 1.4605819461166218

Epoch: 5| Step: 2
Training loss: 0.04228801652789116
Validation loss: 1.4573909531357467

Epoch: 5| Step: 3
Training loss: 0.0539168044924736
Validation loss: 1.4702534829416583

Epoch: 5| Step: 4
Training loss: 0.04877933859825134
Validation loss: 1.4570311666816793

Epoch: 5| Step: 5
Training loss: 0.0456395149230957
Validation loss: 1.495079924983363

Epoch: 5| Step: 6
Training loss: 0.06610629707574844
Validation loss: 1.475969999067245

Epoch: 5| Step: 7
Training loss: 0.056757569313049316
Validation loss: 1.4950582429926882

Epoch: 5| Step: 8
Training loss: 0.07130773365497589
Validation loss: 1.5126092164747176

Epoch: 5| Step: 9
Training loss: 0.11460882425308228
Validation loss: 1.5199493432557711

Epoch: 5| Step: 10
Training loss: 0.06080980971455574
Validation loss: 1.4954873406758873

Epoch: 647| Step: 0
Training loss: 0.06378239393234253
Validation loss: 1.4926122273168256

Epoch: 5| Step: 1
Training loss: 0.05257336050271988
Validation loss: 1.4932532374576857

Epoch: 5| Step: 2
Training loss: 0.062476545572280884
Validation loss: 1.50396635711834

Epoch: 5| Step: 3
Training loss: 0.03919653594493866
Validation loss: 1.4855393812220583

Epoch: 5| Step: 4
Training loss: 0.0429111011326313
Validation loss: 1.465128388456119

Epoch: 5| Step: 5
Training loss: 0.05451475828886032
Validation loss: 1.4618186502046482

Epoch: 5| Step: 6
Training loss: 0.06526079028844833
Validation loss: 1.458613782800654

Epoch: 5| Step: 7
Training loss: 0.039559077471494675
Validation loss: 1.4642534191890428

Epoch: 5| Step: 8
Training loss: 0.07583393156528473
Validation loss: 1.4623320807692826

Epoch: 5| Step: 9
Training loss: 0.03817043453454971
Validation loss: 1.4633450315844627

Epoch: 5| Step: 10
Training loss: 0.0502193346619606
Validation loss: 1.484381865429622

Epoch: 648| Step: 0
Training loss: 0.04039299115538597
Validation loss: 1.4755061262397355

Epoch: 5| Step: 1
Training loss: 0.08858416229486465
Validation loss: 1.476024345685077

Epoch: 5| Step: 2
Training loss: 0.04500007629394531
Validation loss: 1.5070822290194932

Epoch: 5| Step: 3
Training loss: 0.0518139973282814
Validation loss: 1.4814863615138556

Epoch: 5| Step: 4
Training loss: 0.06326071918010712
Validation loss: 1.478495108183994

Epoch: 5| Step: 5
Training loss: 0.05264822393655777
Validation loss: 1.4945608787639166

Epoch: 5| Step: 6
Training loss: 0.047945376485586166
Validation loss: 1.489464029189079

Epoch: 5| Step: 7
Training loss: 0.04102524369955063
Validation loss: 1.4883550636229976

Epoch: 5| Step: 8
Training loss: 0.08531159162521362
Validation loss: 1.5055632873248028

Epoch: 5| Step: 9
Training loss: 0.053495921194553375
Validation loss: 1.4816829280186725

Epoch: 5| Step: 10
Training loss: 0.04780658707022667
Validation loss: 1.4790667474910777

Epoch: 649| Step: 0
Training loss: 0.05732760578393936
Validation loss: 1.5101002948258513

Epoch: 5| Step: 1
Training loss: 0.041625697165727615
Validation loss: 1.484037365964664

Epoch: 5| Step: 2
Training loss: 0.09096411615610123
Validation loss: 1.4781196989038938

Epoch: 5| Step: 3
Training loss: 0.03827163949608803
Validation loss: 1.5013430631288918

Epoch: 5| Step: 4
Training loss: 0.06578551232814789
Validation loss: 1.5068860688517172

Epoch: 5| Step: 5
Training loss: 0.06373751908540726
Validation loss: 1.5061459848957677

Epoch: 5| Step: 6
Training loss: 0.06356189399957657
Validation loss: 1.493558128674825

Epoch: 5| Step: 7
Training loss: 0.061626214534044266
Validation loss: 1.4855966567993164

Epoch: 5| Step: 8
Training loss: 0.03888792544603348
Validation loss: 1.4833537301709574

Epoch: 5| Step: 9
Training loss: 0.05261177942156792
Validation loss: 1.5068776748513664

Epoch: 5| Step: 10
Training loss: 0.05942811071872711
Validation loss: 1.4959759789128457

Epoch: 650| Step: 0
Training loss: 0.07882334291934967
Validation loss: 1.4967827425208142

Epoch: 5| Step: 1
Training loss: 0.07191146165132523
Validation loss: 1.5283509198055472

Epoch: 5| Step: 2
Training loss: 0.035823285579681396
Validation loss: 1.4985501054794557

Epoch: 5| Step: 3
Training loss: 0.07650169730186462
Validation loss: 1.5010006132946219

Epoch: 5| Step: 4
Training loss: 0.0398513525724411
Validation loss: 1.4831778733961043

Epoch: 5| Step: 5
Training loss: 0.06088258698582649
Validation loss: 1.5029299669368292

Epoch: 5| Step: 6
Training loss: 0.05795697495341301
Validation loss: 1.4705001705436296

Epoch: 5| Step: 7
Training loss: 0.0461556501686573
Validation loss: 1.4982758580997426

Epoch: 5| Step: 8
Training loss: 0.06714273989200592
Validation loss: 1.4768215892135457

Epoch: 5| Step: 9
Training loss: 0.04140757769346237
Validation loss: 1.4873082599332255

Epoch: 5| Step: 10
Training loss: 0.04800919070839882
Validation loss: 1.48328826760733

Epoch: 651| Step: 0
Training loss: 0.07130087912082672
Validation loss: 1.5090552324889808

Epoch: 5| Step: 1
Training loss: 0.056394897401332855
Validation loss: 1.5072629362024286

Epoch: 5| Step: 2
Training loss: 0.03536362200975418
Validation loss: 1.490546291874301

Epoch: 5| Step: 3
Training loss: 0.04480734467506409
Validation loss: 1.5047291042984172

Epoch: 5| Step: 4
Training loss: 0.04003150761127472
Validation loss: 1.505360561032449

Epoch: 5| Step: 5
Training loss: 0.055138926953077316
Validation loss: 1.4914739760019446

Epoch: 5| Step: 6
Training loss: 0.054182350635528564
Validation loss: 1.5019042838004328

Epoch: 5| Step: 7
Training loss: 0.07016646862030029
Validation loss: 1.4992650875481226

Epoch: 5| Step: 8
Training loss: 0.05924038961529732
Validation loss: 1.5284380630780292

Epoch: 5| Step: 9
Training loss: 0.08292721211910248
Validation loss: 1.5313681671696324

Epoch: 5| Step: 10
Training loss: 0.06312724947929382
Validation loss: 1.5195587508140072

Epoch: 652| Step: 0
Training loss: 0.05198206380009651
Validation loss: 1.491753912741138

Epoch: 5| Step: 1
Training loss: 0.04445008933544159
Validation loss: 1.4964327177693766

Epoch: 5| Step: 2
Training loss: 0.04292227700352669
Validation loss: 1.4835107486735108

Epoch: 5| Step: 3
Training loss: 0.0491366982460022
Validation loss: 1.472113396531792

Epoch: 5| Step: 4
Training loss: 0.044699132442474365
Validation loss: 1.5057691002404818

Epoch: 5| Step: 5
Training loss: 0.06402693688869476
Validation loss: 1.495198679226701

Epoch: 5| Step: 6
Training loss: 0.050383467227220535
Validation loss: 1.469761549785573

Epoch: 5| Step: 7
Training loss: 0.07087164372205734
Validation loss: 1.4857224354179956

Epoch: 5| Step: 8
Training loss: 0.10228732973337173
Validation loss: 1.459805041231135

Epoch: 5| Step: 9
Training loss: 0.05868222564458847
Validation loss: 1.4949945134501303

Epoch: 5| Step: 10
Training loss: 0.07523071765899658
Validation loss: 1.4856280383243357

Epoch: 653| Step: 0
Training loss: 0.054682157933712006
Validation loss: 1.5346620903220227

Epoch: 5| Step: 1
Training loss: 0.07441043853759766
Validation loss: 1.5416684945424397

Epoch: 5| Step: 2
Training loss: 0.09762082993984222
Validation loss: 1.547655600373463

Epoch: 5| Step: 3
Training loss: 0.0658661276102066
Validation loss: 1.5493921567034978

Epoch: 5| Step: 4
Training loss: 0.07765991240739822
Validation loss: 1.4808100615778277

Epoch: 5| Step: 5
Training loss: 0.03804399445652962
Validation loss: 1.4545871275727467

Epoch: 5| Step: 6
Training loss: 0.040966372936964035
Validation loss: 1.4722725255514986

Epoch: 5| Step: 7
Training loss: 0.11434521526098251
Validation loss: 1.4973892499041814

Epoch: 5| Step: 8
Training loss: 0.11763894557952881
Validation loss: 1.507275471123316

Epoch: 5| Step: 9
Training loss: 0.09648866951465607
Validation loss: 1.5176852787694624

Epoch: 5| Step: 10
Training loss: 0.06894395500421524
Validation loss: 1.5032507834895965

Epoch: 654| Step: 0
Training loss: 0.08915604650974274
Validation loss: 1.47873955516405

Epoch: 5| Step: 1
Training loss: 0.05947432667016983
Validation loss: 1.4906630323779198

Epoch: 5| Step: 2
Training loss: 0.07552076131105423
Validation loss: 1.4857243107211204

Epoch: 5| Step: 3
Training loss: 0.05719407647848129
Validation loss: 1.4687512536202707

Epoch: 5| Step: 4
Training loss: 0.053929317742586136
Validation loss: 1.4936258536513134

Epoch: 5| Step: 5
Training loss: 0.08386306464672089
Validation loss: 1.5007336960043958

Epoch: 5| Step: 6
Training loss: 0.08485740423202515
Validation loss: 1.490097245862407

Epoch: 5| Step: 7
Training loss: 0.08306027948856354
Validation loss: 1.511107825463818

Epoch: 5| Step: 8
Training loss: 0.051351748406887054
Validation loss: 1.502187014907919

Epoch: 5| Step: 9
Training loss: 0.05983378738164902
Validation loss: 1.5150332271411855

Epoch: 5| Step: 10
Training loss: 0.08706600964069366
Validation loss: 1.5359250576265397

Epoch: 655| Step: 0
Training loss: 0.07612314075231552
Validation loss: 1.5326553147326234

Epoch: 5| Step: 1
Training loss: 0.07981645315885544
Validation loss: 1.530295757837193

Epoch: 5| Step: 2
Training loss: 0.08653497695922852
Validation loss: 1.5156980086398382

Epoch: 5| Step: 3
Training loss: 0.03529971465468407
Validation loss: 1.4886247483632897

Epoch: 5| Step: 4
Training loss: 0.09605585038661957
Validation loss: 1.4823349457915111

Epoch: 5| Step: 5
Training loss: 0.059752363711595535
Validation loss: 1.4791748010984032

Epoch: 5| Step: 6
Training loss: 0.08083613961935043
Validation loss: 1.4761439959208171

Epoch: 5| Step: 7
Training loss: 0.083408884704113
Validation loss: 1.4723192709748463

Epoch: 5| Step: 8
Training loss: 0.07077096402645111
Validation loss: 1.4645175549291796

Epoch: 5| Step: 9
Training loss: 0.07691767811775208
Validation loss: 1.4817551630799488

Epoch: 5| Step: 10
Training loss: 0.059325963258743286
Validation loss: 1.492398453015153

Epoch: 656| Step: 0
Training loss: 0.06654218584299088
Validation loss: 1.4770407958697247

Epoch: 5| Step: 1
Training loss: 0.04853653535246849
Validation loss: 1.4824188037585186

Epoch: 5| Step: 2
Training loss: 0.05085515230894089
Validation loss: 1.4776996592039704

Epoch: 5| Step: 3
Training loss: 0.05097203701734543
Validation loss: 1.5152297148140528

Epoch: 5| Step: 4
Training loss: 0.04518134519457817
Validation loss: 1.4746658161122312

Epoch: 5| Step: 5
Training loss: 0.059917252510786057
Validation loss: 1.4773214273555304

Epoch: 5| Step: 6
Training loss: 0.07805652916431427
Validation loss: 1.4937621778057468

Epoch: 5| Step: 7
Training loss: 0.05637981742620468
Validation loss: 1.4807461282258392

Epoch: 5| Step: 8
Training loss: 0.039934784173965454
Validation loss: 1.486597070129969

Epoch: 5| Step: 9
Training loss: 0.06929580867290497
Validation loss: 1.505522725402668

Epoch: 5| Step: 10
Training loss: 0.05494222044944763
Validation loss: 1.5211610242884646

Epoch: 657| Step: 0
Training loss: 0.03151959925889969
Validation loss: 1.5147788409263856

Epoch: 5| Step: 1
Training loss: 0.04470700025558472
Validation loss: 1.5398816190740114

Epoch: 5| Step: 2
Training loss: 0.06750531494617462
Validation loss: 1.5447630754081152

Epoch: 5| Step: 3
Training loss: 0.0608590729534626
Validation loss: 1.5266568609463271

Epoch: 5| Step: 4
Training loss: 0.05624431371688843
Validation loss: 1.514240748138838

Epoch: 5| Step: 5
Training loss: 0.06831827014684677
Validation loss: 1.5343478956530172

Epoch: 5| Step: 6
Training loss: 0.03436708450317383
Validation loss: 1.5300298839487054

Epoch: 5| Step: 7
Training loss: 0.05878835916519165
Validation loss: 1.518822116236533

Epoch: 5| Step: 8
Training loss: 0.06890533864498138
Validation loss: 1.5379094526331911

Epoch: 5| Step: 9
Training loss: 0.0527825728058815
Validation loss: 1.520013984813485

Epoch: 5| Step: 10
Training loss: 0.08382834494113922
Validation loss: 1.5326727628707886

Epoch: 658| Step: 0
Training loss: 0.052986275404691696
Validation loss: 1.531928143193645

Epoch: 5| Step: 1
Training loss: 0.048029422760009766
Validation loss: 1.5264394475567726

Epoch: 5| Step: 2
Training loss: 0.046219099313020706
Validation loss: 1.5021640177695983

Epoch: 5| Step: 3
Training loss: 0.06512825191020966
Validation loss: 1.529932148994938

Epoch: 5| Step: 4
Training loss: 0.07012169063091278
Validation loss: 1.5146299863374362

Epoch: 5| Step: 5
Training loss: 0.05769902467727661
Validation loss: 1.513420831772589

Epoch: 5| Step: 6
Training loss: 0.07318605482578278
Validation loss: 1.5008313835308116

Epoch: 5| Step: 7
Training loss: 0.06192146986722946
Validation loss: 1.5060484640059932

Epoch: 5| Step: 8
Training loss: 0.040893156081438065
Validation loss: 1.4865209864031883

Epoch: 5| Step: 9
Training loss: 0.06432604044675827
Validation loss: 1.5180300538257887

Epoch: 5| Step: 10
Training loss: 0.07395833730697632
Validation loss: 1.504785414664976

Epoch: 659| Step: 0
Training loss: 0.05733983591198921
Validation loss: 1.4942523926816962

Epoch: 5| Step: 1
Training loss: 0.03509160131216049
Validation loss: 1.4821771485831148

Epoch: 5| Step: 2
Training loss: 0.07270072400569916
Validation loss: 1.4633832349572131

Epoch: 5| Step: 3
Training loss: 0.05608534812927246
Validation loss: 1.4817699873319237

Epoch: 5| Step: 4
Training loss: 0.07347003370523453
Validation loss: 1.4725654791760188

Epoch: 5| Step: 5
Training loss: 0.06454925239086151
Validation loss: 1.490835105219195

Epoch: 5| Step: 6
Training loss: 0.052992213517427444
Validation loss: 1.4855146561899493

Epoch: 5| Step: 7
Training loss: 0.05432368069887161
Validation loss: 1.515678910798924

Epoch: 5| Step: 8
Training loss: 0.05041535943746567
Validation loss: 1.5383109815659062

Epoch: 5| Step: 9
Training loss: 0.04698767885565758
Validation loss: 1.5279027781178873

Epoch: 5| Step: 10
Training loss: 0.07626241445541382
Validation loss: 1.515925927828717

Epoch: 660| Step: 0
Training loss: 0.047184210270643234
Validation loss: 1.5126625632727018

Epoch: 5| Step: 1
Training loss: 0.05701450631022453
Validation loss: 1.487050348712552

Epoch: 5| Step: 2
Training loss: 0.050866782665252686
Validation loss: 1.4827581938876901

Epoch: 5| Step: 3
Training loss: 0.051064420491456985
Validation loss: 1.4923399776540778

Epoch: 5| Step: 4
Training loss: 0.05051978677511215
Validation loss: 1.4622835882248417

Epoch: 5| Step: 5
Training loss: 0.10620341449975967
Validation loss: 1.4637329873218332

Epoch: 5| Step: 6
Training loss: 0.09573973715305328
Validation loss: 1.4622221134042228

Epoch: 5| Step: 7
Training loss: 0.07368756830692291
Validation loss: 1.4793961477536026

Epoch: 5| Step: 8
Training loss: 0.0603305920958519
Validation loss: 1.494237256947384

Epoch: 5| Step: 9
Training loss: 0.06504873931407928
Validation loss: 1.4982150767439155

Epoch: 5| Step: 10
Training loss: 0.07123173028230667
Validation loss: 1.512123773174901

Epoch: 661| Step: 0
Training loss: 0.05659160763025284
Validation loss: 1.5222388723845124

Epoch: 5| Step: 1
Training loss: 0.06684155762195587
Validation loss: 1.4987724698999876

Epoch: 5| Step: 2
Training loss: 0.10254504531621933
Validation loss: 1.4730532502615323

Epoch: 5| Step: 3
Training loss: 0.05103869363665581
Validation loss: 1.4793790777524312

Epoch: 5| Step: 4
Training loss: 0.05532104894518852
Validation loss: 1.5044293890717209

Epoch: 5| Step: 5
Training loss: 0.07190792262554169
Validation loss: 1.519129724912746

Epoch: 5| Step: 6
Training loss: 0.06142381951212883
Validation loss: 1.48641711665738

Epoch: 5| Step: 7
Training loss: 0.04911849647760391
Validation loss: 1.4886371269020984

Epoch: 5| Step: 8
Training loss: 0.04907553270459175
Validation loss: 1.4873773526119929

Epoch: 5| Step: 9
Training loss: 0.04653456062078476
Validation loss: 1.4837575702257053

Epoch: 5| Step: 10
Training loss: 0.05371849238872528
Validation loss: 1.4903637081064203

Epoch: 662| Step: 0
Training loss: 0.06850967556238174
Validation loss: 1.4792485192257872

Epoch: 5| Step: 1
Training loss: 0.0522209033370018
Validation loss: 1.5022897579336678

Epoch: 5| Step: 2
Training loss: 0.0495089516043663
Validation loss: 1.4919429876471078

Epoch: 5| Step: 3
Training loss: 0.11469089984893799
Validation loss: 1.4696241847930416

Epoch: 5| Step: 4
Training loss: 0.05159430950880051
Validation loss: 1.4818198924423547

Epoch: 5| Step: 5
Training loss: 0.05630644038319588
Validation loss: 1.4818656098458074

Epoch: 5| Step: 6
Training loss: 0.04422401636838913
Validation loss: 1.45971005962741

Epoch: 5| Step: 7
Training loss: 0.060558147728443146
Validation loss: 1.4883179626157206

Epoch: 5| Step: 8
Training loss: 0.06659205257892609
Validation loss: 1.5117486356407084

Epoch: 5| Step: 9
Training loss: 0.07178322225809097
Validation loss: 1.537932397216879

Epoch: 5| Step: 10
Training loss: 0.13715991377830505
Validation loss: 1.5429762396761166

Epoch: 663| Step: 0
Training loss: 0.08575870096683502
Validation loss: 1.5091961090282728

Epoch: 5| Step: 1
Training loss: 0.0495944619178772
Validation loss: 1.4952755551184378

Epoch: 5| Step: 2
Training loss: 0.07357953488826752
Validation loss: 1.4887085851802622

Epoch: 5| Step: 3
Training loss: 0.04365912452340126
Validation loss: 1.4652602044484948

Epoch: 5| Step: 4
Training loss: 0.058719731867313385
Validation loss: 1.472135055449701

Epoch: 5| Step: 5
Training loss: 0.09664871543645859
Validation loss: 1.4801414435909641

Epoch: 5| Step: 6
Training loss: 0.08741927146911621
Validation loss: 1.4877327642133158

Epoch: 5| Step: 7
Training loss: 0.060884781181812286
Validation loss: 1.4902571157742572

Epoch: 5| Step: 8
Training loss: 0.04760507494211197
Validation loss: 1.4656867686138357

Epoch: 5| Step: 9
Training loss: 0.08521164953708649
Validation loss: 1.4926209680495723

Epoch: 5| Step: 10
Training loss: 0.10006200522184372
Validation loss: 1.479211143268052

Epoch: 664| Step: 0
Training loss: 0.06291510909795761
Validation loss: 1.4792061595506565

Epoch: 5| Step: 1
Training loss: 0.05790676921606064
Validation loss: 1.472995734983875

Epoch: 5| Step: 2
Training loss: 0.10904242843389511
Validation loss: 1.4831398648600425

Epoch: 5| Step: 3
Training loss: 0.07319556921720505
Validation loss: 1.487874480344916

Epoch: 5| Step: 4
Training loss: 0.08354461193084717
Validation loss: 1.4787016043099024

Epoch: 5| Step: 5
Training loss: 0.04858456924557686
Validation loss: 1.4745091712603005

Epoch: 5| Step: 6
Training loss: 0.05591791868209839
Validation loss: 1.4839494125817412

Epoch: 5| Step: 7
Training loss: 0.03833867982029915
Validation loss: 1.4900252921606905

Epoch: 5| Step: 8
Training loss: 0.051379669457674026
Validation loss: 1.4766419420960128

Epoch: 5| Step: 9
Training loss: 0.06061214953660965
Validation loss: 1.4472674541575934

Epoch: 5| Step: 10
Training loss: 0.04840235784649849
Validation loss: 1.4652576831079298

Epoch: 665| Step: 0
Training loss: 0.059435147792100906
Validation loss: 1.4655129166059597

Epoch: 5| Step: 1
Training loss: 0.064444899559021
Validation loss: 1.4576922014195433

Epoch: 5| Step: 2
Training loss: 0.06619186699390411
Validation loss: 1.4622543088851436

Epoch: 5| Step: 3
Training loss: 0.05390677601099014
Validation loss: 1.4693580981223815

Epoch: 5| Step: 4
Training loss: 0.053672246634960175
Validation loss: 1.4855531825814197

Epoch: 5| Step: 5
Training loss: 0.05442154407501221
Validation loss: 1.4797121914484168

Epoch: 5| Step: 6
Training loss: 0.054493676871061325
Validation loss: 1.4817918244228567

Epoch: 5| Step: 7
Training loss: 0.08422892540693283
Validation loss: 1.4899353570835565

Epoch: 5| Step: 8
Training loss: 0.04458747059106827
Validation loss: 1.4984737737204439

Epoch: 5| Step: 9
Training loss: 0.041550468653440475
Validation loss: 1.4853520957372521

Epoch: 5| Step: 10
Training loss: 0.052306484431028366
Validation loss: 1.4952925353921869

Epoch: 666| Step: 0
Training loss: 0.05455464869737625
Validation loss: 1.501606297749345

Epoch: 5| Step: 1
Training loss: 0.033396027982234955
Validation loss: 1.4918911405788955

Epoch: 5| Step: 2
Training loss: 0.0579962320625782
Validation loss: 1.5127934512271677

Epoch: 5| Step: 3
Training loss: 0.040749143809080124
Validation loss: 1.505461169827369

Epoch: 5| Step: 4
Training loss: 0.06587652117013931
Validation loss: 1.4986776523692633

Epoch: 5| Step: 5
Training loss: 0.07088569551706314
Validation loss: 1.50755440163356

Epoch: 5| Step: 6
Training loss: 0.057658351957798004
Validation loss: 1.4998031611083655

Epoch: 5| Step: 7
Training loss: 0.055340755730867386
Validation loss: 1.5062379811399726

Epoch: 5| Step: 8
Training loss: 0.06334501504898071
Validation loss: 1.5291650474712413

Epoch: 5| Step: 9
Training loss: 0.0599680170416832
Validation loss: 1.531541214194349

Epoch: 5| Step: 10
Training loss: 0.10310529172420502
Validation loss: 1.5281745490207468

Epoch: 667| Step: 0
Training loss: 0.0645810216665268
Validation loss: 1.552623366796842

Epoch: 5| Step: 1
Training loss: 0.1069028377532959
Validation loss: 1.5535181286514446

Epoch: 5| Step: 2
Training loss: 0.0736175924539566
Validation loss: 1.5600269033062844

Epoch: 5| Step: 3
Training loss: 0.06543643772602081
Validation loss: 1.529621139649422

Epoch: 5| Step: 4
Training loss: 0.07762960344552994
Validation loss: 1.5386161304289294

Epoch: 5| Step: 5
Training loss: 0.056327175348997116
Validation loss: 1.5302675218992337

Epoch: 5| Step: 6
Training loss: 0.058993954211473465
Validation loss: 1.5170459798587266

Epoch: 5| Step: 7
Training loss: 0.057518720626831055
Validation loss: 1.4952330166293728

Epoch: 5| Step: 8
Training loss: 0.06610806286334991
Validation loss: 1.4965045990482453

Epoch: 5| Step: 9
Training loss: 0.07657629251480103
Validation loss: 1.4909665482018584

Epoch: 5| Step: 10
Training loss: 0.08728572726249695
Validation loss: 1.5111772296249226

Epoch: 668| Step: 0
Training loss: 0.061495911329984665
Validation loss: 1.5039588853877077

Epoch: 5| Step: 1
Training loss: 0.06444507837295532
Validation loss: 1.506106489448137

Epoch: 5| Step: 2
Training loss: 0.03969726711511612
Validation loss: 1.5269217209149433

Epoch: 5| Step: 3
Training loss: 0.06804382801055908
Validation loss: 1.510808849847445

Epoch: 5| Step: 4
Training loss: 0.07311873137950897
Validation loss: 1.5248974497600267

Epoch: 5| Step: 5
Training loss: 0.062121547758579254
Validation loss: 1.5362186508793985

Epoch: 5| Step: 6
Training loss: 0.040564410388469696
Validation loss: 1.5212186959482008

Epoch: 5| Step: 7
Training loss: 0.050918687134981155
Validation loss: 1.5252281183837562

Epoch: 5| Step: 8
Training loss: 0.09402229636907578
Validation loss: 1.4971423302927325

Epoch: 5| Step: 9
Training loss: 0.06362228095531464
Validation loss: 1.5018050061759127

Epoch: 5| Step: 10
Training loss: 0.05255061388015747
Validation loss: 1.4972754011871994

Epoch: 669| Step: 0
Training loss: 0.0774242952466011
Validation loss: 1.4939973226157568

Epoch: 5| Step: 1
Training loss: 0.035487446933984756
Validation loss: 1.5105565978634743

Epoch: 5| Step: 2
Training loss: 0.07361994683742523
Validation loss: 1.5110657368936846

Epoch: 5| Step: 3
Training loss: 0.09346885979175568
Validation loss: 1.504991969754619

Epoch: 5| Step: 4
Training loss: 0.05967780202627182
Validation loss: 1.475115950389575

Epoch: 5| Step: 5
Training loss: 0.04141610488295555
Validation loss: 1.5088156487352105

Epoch: 5| Step: 6
Training loss: 0.065837562084198
Validation loss: 1.500030320177796

Epoch: 5| Step: 7
Training loss: 0.07624302804470062
Validation loss: 1.4950242401451193

Epoch: 5| Step: 8
Training loss: 0.062135569751262665
Validation loss: 1.516004773878282

Epoch: 5| Step: 9
Training loss: 0.05936858803033829
Validation loss: 1.5331529648073259

Epoch: 5| Step: 10
Training loss: 0.06849832087755203
Validation loss: 1.5085388319466704

Epoch: 670| Step: 0
Training loss: 0.06887593120336533
Validation loss: 1.5181353553648917

Epoch: 5| Step: 1
Training loss: 0.09597842395305634
Validation loss: 1.52795329529752

Epoch: 5| Step: 2
Training loss: 0.07160012423992157
Validation loss: 1.5141811524668047

Epoch: 5| Step: 3
Training loss: 0.07736989110708237
Validation loss: 1.5291022575029762

Epoch: 5| Step: 4
Training loss: 0.048922158777713776
Validation loss: 1.521937620255255

Epoch: 5| Step: 5
Training loss: 0.05142942816019058
Validation loss: 1.5197170652369016

Epoch: 5| Step: 6
Training loss: 0.04750590771436691
Validation loss: 1.5210594541283065

Epoch: 5| Step: 7
Training loss: 0.05632193759083748
Validation loss: 1.5383965276902722

Epoch: 5| Step: 8
Training loss: 0.04426960274577141
Validation loss: 1.5300666939827703

Epoch: 5| Step: 9
Training loss: 0.05054116249084473
Validation loss: 1.5336421048769386

Epoch: 5| Step: 10
Training loss: 0.05104399845004082
Validation loss: 1.5349832760390414

Epoch: 671| Step: 0
Training loss: 0.07730493694543839
Validation loss: 1.5078112258706042

Epoch: 5| Step: 1
Training loss: 0.069840207695961
Validation loss: 1.5139760407068397

Epoch: 5| Step: 2
Training loss: 0.036404237151145935
Validation loss: 1.5103573453041814

Epoch: 5| Step: 3
Training loss: 0.05296402424573898
Validation loss: 1.5186170365220757

Epoch: 5| Step: 4
Training loss: 0.08256508409976959
Validation loss: 1.496337221514794

Epoch: 5| Step: 5
Training loss: 0.057588160037994385
Validation loss: 1.502328891907969

Epoch: 5| Step: 6
Training loss: 0.06879479438066483
Validation loss: 1.5107198543446039

Epoch: 5| Step: 7
Training loss: 0.07535179704427719
Validation loss: 1.5298115040666314

Epoch: 5| Step: 8
Training loss: 0.058477066457271576
Validation loss: 1.5316666121123939

Epoch: 5| Step: 9
Training loss: 0.07276362925767899
Validation loss: 1.5531681981138004

Epoch: 5| Step: 10
Training loss: 0.07697153091430664
Validation loss: 1.5301171695032427

Epoch: 672| Step: 0
Training loss: 0.05546654388308525
Validation loss: 1.533905036987797

Epoch: 5| Step: 1
Training loss: 0.034582871943712234
Validation loss: 1.52339143137778

Epoch: 5| Step: 2
Training loss: 0.044808279722929
Validation loss: 1.5276523187596311

Epoch: 5| Step: 3
Training loss: 0.04874105006456375
Validation loss: 1.5366870075143793

Epoch: 5| Step: 4
Training loss: 0.042414724826812744
Validation loss: 1.5261612348659064

Epoch: 5| Step: 5
Training loss: 0.06325697153806686
Validation loss: 1.5027305644045594

Epoch: 5| Step: 6
Training loss: 0.06508344411849976
Validation loss: 1.5410051025370115

Epoch: 5| Step: 7
Training loss: 0.07456780225038528
Validation loss: 1.528575478061553

Epoch: 5| Step: 8
Training loss: 0.07070399075746536
Validation loss: 1.52973642528698

Epoch: 5| Step: 9
Training loss: 0.06033237650990486
Validation loss: 1.513993775972756

Epoch: 5| Step: 10
Training loss: 0.06224614754319191
Validation loss: 1.5306565364201863

Epoch: 673| Step: 0
Training loss: 0.05175354331731796
Validation loss: 1.5273060862736036

Epoch: 5| Step: 1
Training loss: 0.05866987630724907
Validation loss: 1.5315989999360935

Epoch: 5| Step: 2
Training loss: 0.08747600018978119
Validation loss: 1.5458700938891339

Epoch: 5| Step: 3
Training loss: 0.058301664888858795
Validation loss: 1.5324352992478238

Epoch: 5| Step: 4
Training loss: 0.040333058685064316
Validation loss: 1.4977969085016558

Epoch: 5| Step: 5
Training loss: 0.05547972768545151
Validation loss: 1.5223063217696322

Epoch: 5| Step: 6
Training loss: 0.08783682435750961
Validation loss: 1.4876338551121373

Epoch: 5| Step: 7
Training loss: 0.04738765209913254
Validation loss: 1.4953626176362396

Epoch: 5| Step: 8
Training loss: 0.03765109181404114
Validation loss: 1.4725221177583099

Epoch: 5| Step: 9
Training loss: 0.050670020282268524
Validation loss: 1.4496551713635843

Epoch: 5| Step: 10
Training loss: 0.08918215334415436
Validation loss: 1.4741668572989843

Epoch: 674| Step: 0
Training loss: 0.0774315893650055
Validation loss: 1.458358520461667

Epoch: 5| Step: 1
Training loss: 0.06252641975879669
Validation loss: 1.4659144916842062

Epoch: 5| Step: 2
Training loss: 0.07354636490345001
Validation loss: 1.4798555332486347

Epoch: 5| Step: 3
Training loss: 0.07767631113529205
Validation loss: 1.496378731343054

Epoch: 5| Step: 4
Training loss: 0.04866278916597366
Validation loss: 1.5010718357178472

Epoch: 5| Step: 5
Training loss: 0.09416589885950089
Validation loss: 1.5163393264175744

Epoch: 5| Step: 6
Training loss: 0.13745741546154022
Validation loss: 1.5398284235308248

Epoch: 5| Step: 7
Training loss: 0.05565181374549866
Validation loss: 1.5367523726596628

Epoch: 5| Step: 8
Training loss: 0.059160877019166946
Validation loss: 1.505363400264453

Epoch: 5| Step: 9
Training loss: 0.05179423838853836
Validation loss: 1.5060416139582151

Epoch: 5| Step: 10
Training loss: 0.07076434791088104
Validation loss: 1.4932710560419227

Epoch: 675| Step: 0
Training loss: 0.041819456964731216
Validation loss: 1.475315829759003

Epoch: 5| Step: 1
Training loss: 0.06959403306245804
Validation loss: 1.4708007202353528

Epoch: 5| Step: 2
Training loss: 0.08108111470937729
Validation loss: 1.4680456858809277

Epoch: 5| Step: 3
Training loss: 0.0464802049100399
Validation loss: 1.4910832669145317

Epoch: 5| Step: 4
Training loss: 0.11886496841907501
Validation loss: 1.5011025590281333

Epoch: 5| Step: 5
Training loss: 0.04906899482011795
Validation loss: 1.4889147063737274

Epoch: 5| Step: 6
Training loss: 0.05134407430887222
Validation loss: 1.5138065994426768

Epoch: 5| Step: 7
Training loss: 0.07731135934591293
Validation loss: 1.5340697508986278

Epoch: 5| Step: 8
Training loss: 0.08589322119951248
Validation loss: 1.540460596802414

Epoch: 5| Step: 9
Training loss: 0.07861743867397308
Validation loss: 1.5502705894490725

Epoch: 5| Step: 10
Training loss: 0.10058528184890747
Validation loss: 1.559110991416439

Epoch: 676| Step: 0
Training loss: 0.08962880820035934
Validation loss: 1.5287826163794405

Epoch: 5| Step: 1
Training loss: 0.05212510749697685
Validation loss: 1.5365045327012257

Epoch: 5| Step: 2
Training loss: 0.0957455039024353
Validation loss: 1.5125189776061683

Epoch: 5| Step: 3
Training loss: 0.06711981445550919
Validation loss: 1.5558539718709967

Epoch: 5| Step: 4
Training loss: 0.049234770238399506
Validation loss: 1.5572679042816162

Epoch: 5| Step: 5
Training loss: 0.04873763769865036
Validation loss: 1.571407933388987

Epoch: 5| Step: 6
Training loss: 0.07189279794692993
Validation loss: 1.5814765832757438

Epoch: 5| Step: 7
Training loss: 0.07928819954395294
Validation loss: 1.5920877636119883

Epoch: 5| Step: 8
Training loss: 0.08681889623403549
Validation loss: 1.561918766267838

Epoch: 5| Step: 9
Training loss: 0.06502307206392288
Validation loss: 1.5546682150133195

Epoch: 5| Step: 10
Training loss: 0.08458510041236877
Validation loss: 1.5428273895735383

Epoch: 677| Step: 0
Training loss: 0.08875951915979385
Validation loss: 1.5602763224673528

Epoch: 5| Step: 1
Training loss: 0.06934496015310287
Validation loss: 1.557199731949837

Epoch: 5| Step: 2
Training loss: 0.062483035027980804
Validation loss: 1.5507147517255557

Epoch: 5| Step: 3
Training loss: 0.06161341816186905
Validation loss: 1.5541970473463818

Epoch: 5| Step: 4
Training loss: 0.08122867345809937
Validation loss: 1.5283802965635895

Epoch: 5| Step: 5
Training loss: 0.10401256382465363
Validation loss: 1.5846146165683705

Epoch: 5| Step: 6
Training loss: 0.08776342123746872
Validation loss: 1.5553814102244634

Epoch: 5| Step: 7
Training loss: 0.05762002617120743
Validation loss: 1.5633340215170255

Epoch: 5| Step: 8
Training loss: 0.058246027678251266
Validation loss: 1.5529931758039741

Epoch: 5| Step: 9
Training loss: 0.051456987857818604
Validation loss: 1.5646208422158354

Epoch: 5| Step: 10
Training loss: 0.08952340483665466
Validation loss: 1.5380069594229422

Epoch: 678| Step: 0
Training loss: 0.08604083210229874
Validation loss: 1.5388237584021784

Epoch: 5| Step: 1
Training loss: 0.07760490477085114
Validation loss: 1.531649967675568

Epoch: 5| Step: 2
Training loss: 0.11437420547008514
Validation loss: 1.5511192942178378

Epoch: 5| Step: 3
Training loss: 0.04963342100381851
Validation loss: 1.557890958683465

Epoch: 5| Step: 4
Training loss: 0.05523183196783066
Validation loss: 1.5533220485974384

Epoch: 5| Step: 5
Training loss: 0.08523992449045181
Validation loss: 1.553954082150613

Epoch: 5| Step: 6
Training loss: 0.10232260078191757
Validation loss: 1.5778981203673987

Epoch: 5| Step: 7
Training loss: 0.09435934573411942
Validation loss: 1.5794072574184788

Epoch: 5| Step: 8
Training loss: 0.05432010814547539
Validation loss: 1.5804510821578324

Epoch: 5| Step: 9
Training loss: 0.08148987591266632
Validation loss: 1.5928656670355028

Epoch: 5| Step: 10
Training loss: 0.051708489656448364
Validation loss: 1.565688584440498

Epoch: 679| Step: 0
Training loss: 0.04961678385734558
Validation loss: 1.5653217761747298

Epoch: 5| Step: 1
Training loss: 0.07170940935611725
Validation loss: 1.5478284935797415

Epoch: 5| Step: 2
Training loss: 0.04998703673481941
Validation loss: 1.54927384725181

Epoch: 5| Step: 3
Training loss: 0.06357254832983017
Validation loss: 1.5433773148444392

Epoch: 5| Step: 4
Training loss: 0.047469787299633026
Validation loss: 1.522755176790299

Epoch: 5| Step: 5
Training loss: 0.08546044677495956
Validation loss: 1.513872427325095

Epoch: 5| Step: 6
Training loss: 0.039711207151412964
Validation loss: 1.521748827349755

Epoch: 5| Step: 7
Training loss: 0.06327985227108002
Validation loss: 1.5072897288107103

Epoch: 5| Step: 8
Training loss: 0.09588895738124847
Validation loss: 1.5160856054675194

Epoch: 5| Step: 9
Training loss: 0.06808457523584366
Validation loss: 1.5139077568566928

Epoch: 5| Step: 10
Training loss: 0.028227007016539574
Validation loss: 1.5353288906876759

Epoch: 680| Step: 0
Training loss: 0.08781804889440536
Validation loss: 1.5393405422087638

Epoch: 5| Step: 1
Training loss: 0.07852329313755035
Validation loss: 1.5405985437413698

Epoch: 5| Step: 2
Training loss: 0.06548550724983215
Validation loss: 1.5455292155665736

Epoch: 5| Step: 3
Training loss: 0.06928422302007675
Validation loss: 1.5360861157858243

Epoch: 5| Step: 4
Training loss: 0.06509514153003693
Validation loss: 1.537382577055244

Epoch: 5| Step: 5
Training loss: 0.07327127456665039
Validation loss: 1.514058506616982

Epoch: 5| Step: 6
Training loss: 0.05525717884302139
Validation loss: 1.4816606711315852

Epoch: 5| Step: 7
Training loss: 0.05961190536618233
Validation loss: 1.4977352183352235

Epoch: 5| Step: 8
Training loss: 0.04429738596081734
Validation loss: 1.49628786886892

Epoch: 5| Step: 9
Training loss: 0.04241042211651802
Validation loss: 1.5192940382547275

Epoch: 5| Step: 10
Training loss: 0.07459291815757751
Validation loss: 1.5412313720231414

Epoch: 681| Step: 0
Training loss: 0.065731480717659
Validation loss: 1.5054622478382562

Epoch: 5| Step: 1
Training loss: 0.06317146122455597
Validation loss: 1.5039756938975344

Epoch: 5| Step: 2
Training loss: 0.09982022643089294
Validation loss: 1.519540798279547

Epoch: 5| Step: 3
Training loss: 0.040427401661872864
Validation loss: 1.5250303136405123

Epoch: 5| Step: 4
Training loss: 0.053735245019197464
Validation loss: 1.5400542174616167

Epoch: 5| Step: 5
Training loss: 0.06322501599788666
Validation loss: 1.5238121850516206

Epoch: 5| Step: 6
Training loss: 0.05767844244837761
Validation loss: 1.5340536768718431

Epoch: 5| Step: 7
Training loss: 0.04867418482899666
Validation loss: 1.5222126937681628

Epoch: 5| Step: 8
Training loss: 0.03137848526239395
Validation loss: 1.5029623982726887

Epoch: 5| Step: 9
Training loss: 0.05261063575744629
Validation loss: 1.5207128608098595

Epoch: 5| Step: 10
Training loss: 0.05464255064725876
Validation loss: 1.5271567977884764

Epoch: 682| Step: 0
Training loss: 0.04160729795694351
Validation loss: 1.4955921019277265

Epoch: 5| Step: 1
Training loss: 0.054366450756788254
Validation loss: 1.5020538299314437

Epoch: 5| Step: 2
Training loss: 0.0573689267039299
Validation loss: 1.4883803334287418

Epoch: 5| Step: 3
Training loss: 0.07144711166620255
Validation loss: 1.4875905693218272

Epoch: 5| Step: 4
Training loss: 0.046284936368465424
Validation loss: 1.505647172210037

Epoch: 5| Step: 5
Training loss: 0.03742412477731705
Validation loss: 1.5101396268413914

Epoch: 5| Step: 6
Training loss: 0.05666236951947212
Validation loss: 1.5166029443023026

Epoch: 5| Step: 7
Training loss: 0.060550130903720856
Validation loss: 1.5330136386297082

Epoch: 5| Step: 8
Training loss: 0.06610113382339478
Validation loss: 1.5258371317258446

Epoch: 5| Step: 9
Training loss: 0.06220501661300659
Validation loss: 1.519721104252723

Epoch: 5| Step: 10
Training loss: 0.05167153477668762
Validation loss: 1.5079351637953071

Epoch: 683| Step: 0
Training loss: 0.076413094997406
Validation loss: 1.5001542696388819

Epoch: 5| Step: 1
Training loss: 0.054515641182661057
Validation loss: 1.5117525298108336

Epoch: 5| Step: 2
Training loss: 0.07846981287002563
Validation loss: 1.473324929514239

Epoch: 5| Step: 3
Training loss: 0.052147917449474335
Validation loss: 1.4948507765287995

Epoch: 5| Step: 4
Training loss: 0.0761069506406784
Validation loss: 1.479828848633715

Epoch: 5| Step: 5
Training loss: 0.05870768427848816
Validation loss: 1.4832146116482314

Epoch: 5| Step: 6
Training loss: 0.06764213740825653
Validation loss: 1.478591307517021

Epoch: 5| Step: 7
Training loss: 0.05230500549077988
Validation loss: 1.4853463096003379

Epoch: 5| Step: 8
Training loss: 0.10002472251653671
Validation loss: 1.4899668629451464

Epoch: 5| Step: 9
Training loss: 0.05348923057317734
Validation loss: 1.4991992558202436

Epoch: 5| Step: 10
Training loss: 0.043368689715862274
Validation loss: 1.4838729167497287

Epoch: 684| Step: 0
Training loss: 0.039866454899311066
Validation loss: 1.480615218480428

Epoch: 5| Step: 1
Training loss: 0.0616464726626873
Validation loss: 1.5134765794200282

Epoch: 5| Step: 2
Training loss: 0.06043952703475952
Validation loss: 1.4914826808437225

Epoch: 5| Step: 3
Training loss: 0.04128788784146309
Validation loss: 1.492044851344119

Epoch: 5| Step: 4
Training loss: 0.07345733791589737
Validation loss: 1.5155953655960739

Epoch: 5| Step: 5
Training loss: 0.04906168952584267
Validation loss: 1.4819855741275254

Epoch: 5| Step: 6
Training loss: 0.10465161502361298
Validation loss: 1.4721037136611117

Epoch: 5| Step: 7
Training loss: 0.07461373507976532
Validation loss: 1.4807534256289083

Epoch: 5| Step: 8
Training loss: 0.03704007714986801
Validation loss: 1.5060970155141686

Epoch: 5| Step: 9
Training loss: 0.06400389969348907
Validation loss: 1.4801159007574922

Epoch: 5| Step: 10
Training loss: 0.04844382777810097
Validation loss: 1.5037348783144386

Epoch: 685| Step: 0
Training loss: 0.076737180352211
Validation loss: 1.485936846784366

Epoch: 5| Step: 1
Training loss: 0.060031481087207794
Validation loss: 1.5420935461598058

Epoch: 5| Step: 2
Training loss: 0.06112898513674736
Validation loss: 1.53121216066422

Epoch: 5| Step: 3
Training loss: 0.05930391699075699
Validation loss: 1.5274144981497078

Epoch: 5| Step: 4
Training loss: 0.06382323801517487
Validation loss: 1.5198343620505383

Epoch: 5| Step: 5
Training loss: 0.06603027880191803
Validation loss: 1.510450416995633

Epoch: 5| Step: 6
Training loss: 0.09703622758388519
Validation loss: 1.4641799772939375

Epoch: 5| Step: 7
Training loss: 0.03591886907815933
Validation loss: 1.4307373544221282

Epoch: 5| Step: 8
Training loss: 0.07273177057504654
Validation loss: 1.4435771383265013

Epoch: 5| Step: 9
Training loss: 0.06396706402301788
Validation loss: 1.4196254591788016

Epoch: 5| Step: 10
Training loss: 0.06078225001692772
Validation loss: 1.4597835733044533

Epoch: 686| Step: 0
Training loss: 0.07679086923599243
Validation loss: 1.4696338638182609

Epoch: 5| Step: 1
Training loss: 0.10511324554681778
Validation loss: 1.4871164675681823

Epoch: 5| Step: 2
Training loss: 0.09429235011339188
Validation loss: 1.4755760546653502

Epoch: 5| Step: 3
Training loss: 0.06788664311170578
Validation loss: 1.507380062533963

Epoch: 5| Step: 4
Training loss: 0.0623575858771801
Validation loss: 1.502245295432306

Epoch: 5| Step: 5
Training loss: 0.03938214108347893
Validation loss: 1.5053924924583846

Epoch: 5| Step: 6
Training loss: 0.08214734494686127
Validation loss: 1.5388770898183186

Epoch: 5| Step: 7
Training loss: 0.051861923187971115
Validation loss: 1.496102270259652

Epoch: 5| Step: 8
Training loss: 0.07316061109304428
Validation loss: 1.5260098852137083

Epoch: 5| Step: 9
Training loss: 0.038569800555706024
Validation loss: 1.516032039478261

Epoch: 5| Step: 10
Training loss: 0.046840865164995193
Validation loss: 1.515979084917294

Epoch: 687| Step: 0
Training loss: 0.08261425048112869
Validation loss: 1.4887286578455279

Epoch: 5| Step: 1
Training loss: 0.07547853887081146
Validation loss: 1.4839884017103462

Epoch: 5| Step: 2
Training loss: 0.11067471653223038
Validation loss: 1.47859529782367

Epoch: 5| Step: 3
Training loss: 0.06770965456962585
Validation loss: 1.4978734524019304

Epoch: 5| Step: 4
Training loss: 0.08747926354408264
Validation loss: 1.5137032206340502

Epoch: 5| Step: 5
Training loss: 0.06901033967733383
Validation loss: 1.4812623634133288

Epoch: 5| Step: 6
Training loss: 0.0550331249833107
Validation loss: 1.48882806557481

Epoch: 5| Step: 7
Training loss: 0.07272897660732269
Validation loss: 1.5045800439773067

Epoch: 5| Step: 8
Training loss: 0.10998523235321045
Validation loss: 1.5254347555098995

Epoch: 5| Step: 9
Training loss: 0.08406033366918564
Validation loss: 1.5488772533273185

Epoch: 5| Step: 10
Training loss: 0.09359332174062729
Validation loss: 1.5462561499687932

Epoch: 688| Step: 0
Training loss: 0.05821431800723076
Validation loss: 1.539451164584006

Epoch: 5| Step: 1
Training loss: 0.04329811409115791
Validation loss: 1.528929848824778

Epoch: 5| Step: 2
Training loss: 0.06903283298015594
Validation loss: 1.5227287597553705

Epoch: 5| Step: 3
Training loss: 0.06916903704404831
Validation loss: 1.5052807177266767

Epoch: 5| Step: 4
Training loss: 0.09366699308156967
Validation loss: 1.4763119387370285

Epoch: 5| Step: 5
Training loss: 0.06949719041585922
Validation loss: 1.5091705860630158

Epoch: 5| Step: 6
Training loss: 0.043634701520204544
Validation loss: 1.4601979396676505

Epoch: 5| Step: 7
Training loss: 0.045034490525722504
Validation loss: 1.4912044476437312

Epoch: 5| Step: 8
Training loss: 0.06755663454532623
Validation loss: 1.4960650218430387

Epoch: 5| Step: 9
Training loss: 0.07289409637451172
Validation loss: 1.511652345298439

Epoch: 5| Step: 10
Training loss: 0.06562794744968414
Validation loss: 1.50898330186003

Epoch: 689| Step: 0
Training loss: 0.05441312864422798
Validation loss: 1.5062641084835093

Epoch: 5| Step: 1
Training loss: 0.07418440282344818
Validation loss: 1.4843663092582458

Epoch: 5| Step: 2
Training loss: 0.0467744842171669
Validation loss: 1.5038708602228472

Epoch: 5| Step: 3
Training loss: 0.055196624249219894
Validation loss: 1.4999754582681963

Epoch: 5| Step: 4
Training loss: 0.06690537929534912
Validation loss: 1.5052440461292063

Epoch: 5| Step: 5
Training loss: 0.049365948885679245
Validation loss: 1.4923858668214531

Epoch: 5| Step: 6
Training loss: 0.05579765886068344
Validation loss: 1.4881829830908007

Epoch: 5| Step: 7
Training loss: 0.056995637714862823
Validation loss: 1.5075482437687535

Epoch: 5| Step: 8
Training loss: 0.06283518671989441
Validation loss: 1.5052456689137284

Epoch: 5| Step: 9
Training loss: 0.04491712525486946
Validation loss: 1.521192544250078

Epoch: 5| Step: 10
Training loss: 0.04238073155283928
Validation loss: 1.504217197818141

Epoch: 690| Step: 0
Training loss: 0.05679235979914665
Validation loss: 1.5132270602769748

Epoch: 5| Step: 1
Training loss: 0.04727717116475105
Validation loss: 1.5184138974835795

Epoch: 5| Step: 2
Training loss: 0.06449319422245026
Validation loss: 1.5142095601686867

Epoch: 5| Step: 3
Training loss: 0.0603158101439476
Validation loss: 1.5141110349726934

Epoch: 5| Step: 4
Training loss: 0.02706838771700859
Validation loss: 1.5072945574278473

Epoch: 5| Step: 5
Training loss: 0.08226358145475388
Validation loss: 1.5286868285107356

Epoch: 5| Step: 6
Training loss: 0.04572558403015137
Validation loss: 1.5115753707065378

Epoch: 5| Step: 7
Training loss: 0.052706025540828705
Validation loss: 1.510901076819307

Epoch: 5| Step: 8
Training loss: 0.05688319355249405
Validation loss: 1.4899627316382624

Epoch: 5| Step: 9
Training loss: 0.06953703612089157
Validation loss: 1.4829269865507722

Epoch: 5| Step: 10
Training loss: 0.08296532928943634
Validation loss: 1.489435242068383

Epoch: 691| Step: 0
Training loss: 0.0605301633477211
Validation loss: 1.5159513963166105

Epoch: 5| Step: 1
Training loss: 0.07516996562480927
Validation loss: 1.5217721103340067

Epoch: 5| Step: 2
Training loss: 0.05293344333767891
Validation loss: 1.490798722031296

Epoch: 5| Step: 3
Training loss: 0.06449856609106064
Validation loss: 1.4942526496866697

Epoch: 5| Step: 4
Training loss: 0.06122429296374321
Validation loss: 1.4995455421427244

Epoch: 5| Step: 5
Training loss: 0.08093880116939545
Validation loss: 1.5197343755793828

Epoch: 5| Step: 6
Training loss: 0.05351104214787483
Validation loss: 1.5231314057944922

Epoch: 5| Step: 7
Training loss: 0.04672163724899292
Validation loss: 1.5326702928030362

Epoch: 5| Step: 8
Training loss: 0.06696034967899323
Validation loss: 1.5187147394303353

Epoch: 5| Step: 9
Training loss: 0.07874689251184464
Validation loss: 1.5294708321171422

Epoch: 5| Step: 10
Training loss: 0.09318196028470993
Validation loss: 1.5166297369105841

Epoch: 692| Step: 0
Training loss: 0.05288586765527725
Validation loss: 1.5055805342171782

Epoch: 5| Step: 1
Training loss: 0.05876003950834274
Validation loss: 1.5038270245316208

Epoch: 5| Step: 2
Training loss: 0.03308644890785217
Validation loss: 1.5305431389039563

Epoch: 5| Step: 3
Training loss: 0.06236600875854492
Validation loss: 1.5123983519051665

Epoch: 5| Step: 4
Training loss: 0.07548801600933075
Validation loss: 1.5071357052813295

Epoch: 5| Step: 5
Training loss: 0.046600453555583954
Validation loss: 1.5002394030171056

Epoch: 5| Step: 6
Training loss: 0.06670932471752167
Validation loss: 1.4893265507554496

Epoch: 5| Step: 7
Training loss: 0.08477877825498581
Validation loss: 1.4621051364047553

Epoch: 5| Step: 8
Training loss: 0.05082935839891434
Validation loss: 1.494370077245979

Epoch: 5| Step: 9
Training loss: 0.03904636949300766
Validation loss: 1.498381446766597

Epoch: 5| Step: 10
Training loss: 0.0552450492978096
Validation loss: 1.4911522775567987

Epoch: 693| Step: 0
Training loss: 0.04358888417482376
Validation loss: 1.508032428321018

Epoch: 5| Step: 1
Training loss: 0.04654167965054512
Validation loss: 1.5149031659608245

Epoch: 5| Step: 2
Training loss: 0.02715633437037468
Validation loss: 1.4876198050796345

Epoch: 5| Step: 3
Training loss: 0.05008123070001602
Validation loss: 1.504195072317636

Epoch: 5| Step: 4
Training loss: 0.08567987382411957
Validation loss: 1.4701008489055019

Epoch: 5| Step: 5
Training loss: 0.07564044743776321
Validation loss: 1.4972878617625083

Epoch: 5| Step: 6
Training loss: 0.031695570796728134
Validation loss: 1.4875129512561265

Epoch: 5| Step: 7
Training loss: 0.04282934218645096
Validation loss: 1.4746637600724415

Epoch: 5| Step: 8
Training loss: 0.052283190190792084
Validation loss: 1.4840898385611914

Epoch: 5| Step: 9
Training loss: 0.05134998634457588
Validation loss: 1.474835165085331

Epoch: 5| Step: 10
Training loss: 0.051872387528419495
Validation loss: 1.4988871530819965

Epoch: 694| Step: 0
Training loss: 0.05263442546129227
Validation loss: 1.4612578345883278

Epoch: 5| Step: 1
Training loss: 0.05568405240774155
Validation loss: 1.5131044605726838

Epoch: 5| Step: 2
Training loss: 0.03788788989186287
Validation loss: 1.5036885981918664

Epoch: 5| Step: 3
Training loss: 0.056554727256298065
Validation loss: 1.5492611879943519

Epoch: 5| Step: 4
Training loss: 0.09202633798122406
Validation loss: 1.5417111317316692

Epoch: 5| Step: 5
Training loss: 0.10156223922967911
Validation loss: 1.563863403053694

Epoch: 5| Step: 6
Training loss: 0.04953109472990036
Validation loss: 1.5567082205126364

Epoch: 5| Step: 7
Training loss: 0.07399693131446838
Validation loss: 1.5711326445302656

Epoch: 5| Step: 8
Training loss: 0.04553157836198807
Validation loss: 1.5634685447139125

Epoch: 5| Step: 9
Training loss: 0.03556118160486221
Validation loss: 1.5535761342253736

Epoch: 5| Step: 10
Training loss: 0.07015109062194824
Validation loss: 1.5536118476621565

Epoch: 695| Step: 0
Training loss: 0.0611652247607708
Validation loss: 1.52248852996416

Epoch: 5| Step: 1
Training loss: 0.050621967762708664
Validation loss: 1.5427105984380167

Epoch: 5| Step: 2
Training loss: 0.05033118650317192
Validation loss: 1.5309999245469288

Epoch: 5| Step: 3
Training loss: 0.07093123346567154
Validation loss: 1.5254288168363674

Epoch: 5| Step: 4
Training loss: 0.07153788954019547
Validation loss: 1.5248366517405356

Epoch: 5| Step: 5
Training loss: 0.08226053416728973
Validation loss: 1.5012923959762818

Epoch: 5| Step: 6
Training loss: 0.06901437044143677
Validation loss: 1.5224451518827868

Epoch: 5| Step: 7
Training loss: 0.058608222752809525
Validation loss: 1.523811767178197

Epoch: 5| Step: 8
Training loss: 0.08248871564865112
Validation loss: 1.5489054636288715

Epoch: 5| Step: 9
Training loss: 0.06533968448638916
Validation loss: 1.5445915037585842

Epoch: 5| Step: 10
Training loss: 0.07111514359712601
Validation loss: 1.548722808079053

Epoch: 696| Step: 0
Training loss: 0.08173082768917084
Validation loss: 1.5455180265570199

Epoch: 5| Step: 1
Training loss: 0.045052092522382736
Validation loss: 1.5352297790588871

Epoch: 5| Step: 2
Training loss: 0.06072867661714554
Validation loss: 1.5245389656354023

Epoch: 5| Step: 3
Training loss: 0.05792055279016495
Validation loss: 1.50590968003837

Epoch: 5| Step: 4
Training loss: 0.07843901216983795
Validation loss: 1.48333780611715

Epoch: 5| Step: 5
Training loss: 0.0645306259393692
Validation loss: 1.4977599113218245

Epoch: 5| Step: 6
Training loss: 0.08858157694339752
Validation loss: 1.4991261971894132

Epoch: 5| Step: 7
Training loss: 0.09462164342403412
Validation loss: 1.4720338038218919

Epoch: 5| Step: 8
Training loss: 0.03209151700139046
Validation loss: 1.4821370135071457

Epoch: 5| Step: 9
Training loss: 0.07008441537618637
Validation loss: 1.4832065284893077

Epoch: 5| Step: 10
Training loss: 0.05586618930101395
Validation loss: 1.4952399705045967

Epoch: 697| Step: 0
Training loss: 0.04356364160776138
Validation loss: 1.4928392267996264

Epoch: 5| Step: 1
Training loss: 0.057022176682949066
Validation loss: 1.5088982203955292

Epoch: 5| Step: 2
Training loss: 0.08347193896770477
Validation loss: 1.4923495323427263

Epoch: 5| Step: 3
Training loss: 0.07258254289627075
Validation loss: 1.5035426219304402

Epoch: 5| Step: 4
Training loss: 0.05922198295593262
Validation loss: 1.5150059730775896

Epoch: 5| Step: 5
Training loss: 0.031216686591506004
Validation loss: 1.5050653437132477

Epoch: 5| Step: 6
Training loss: 0.038843315094709396
Validation loss: 1.5119464692249094

Epoch: 5| Step: 7
Training loss: 0.06733512878417969
Validation loss: 1.4858560395497147

Epoch: 5| Step: 8
Training loss: 0.04818220064043999
Validation loss: 1.5040379608831098

Epoch: 5| Step: 9
Training loss: 0.05636637657880783
Validation loss: 1.508397230537989

Epoch: 5| Step: 10
Training loss: 0.03317305073142052
Validation loss: 1.51913288716347

Epoch: 698| Step: 0
Training loss: 0.04445139691233635
Validation loss: 1.5363271877329836

Epoch: 5| Step: 1
Training loss: 0.04696056991815567
Validation loss: 1.5301562919411609

Epoch: 5| Step: 2
Training loss: 0.05679231882095337
Validation loss: 1.538653330136371

Epoch: 5| Step: 3
Training loss: 0.06467664241790771
Validation loss: 1.525092847885624

Epoch: 5| Step: 4
Training loss: 0.0769713819026947
Validation loss: 1.5412560406551565

Epoch: 5| Step: 5
Training loss: 0.06554581224918365
Validation loss: 1.541059773455384

Epoch: 5| Step: 6
Training loss: 0.05028839036822319
Validation loss: 1.5394153723152735

Epoch: 5| Step: 7
Training loss: 0.08958860486745834
Validation loss: 1.512286562432525

Epoch: 5| Step: 8
Training loss: 0.05774754285812378
Validation loss: 1.5075403605737994

Epoch: 5| Step: 9
Training loss: 0.074479840695858
Validation loss: 1.512280882045787

Epoch: 5| Step: 10
Training loss: 0.0594586618244648
Validation loss: 1.525526132634891

Epoch: 699| Step: 0
Training loss: 0.044255226850509644
Validation loss: 1.517738885776971

Epoch: 5| Step: 1
Training loss: 0.08108387887477875
Validation loss: 1.5178032280296407

Epoch: 5| Step: 2
Training loss: 0.05663159489631653
Validation loss: 1.5202780000625118

Epoch: 5| Step: 3
Training loss: 0.06004130095243454
Validation loss: 1.5285973215615878

Epoch: 5| Step: 4
Training loss: 0.059244416654109955
Validation loss: 1.5411336204057098

Epoch: 5| Step: 5
Training loss: 0.05299334600567818
Validation loss: 1.5278012547441708

Epoch: 5| Step: 6
Training loss: 0.0404818169772625
Validation loss: 1.5350824133042367

Epoch: 5| Step: 7
Training loss: 0.0839242935180664
Validation loss: 1.5370501638740621

Epoch: 5| Step: 8
Training loss: 0.04691539704799652
Validation loss: 1.5342412853753695

Epoch: 5| Step: 9
Training loss: 0.0695362538099289
Validation loss: 1.5419319265632219

Epoch: 5| Step: 10
Training loss: 0.07259698957204819
Validation loss: 1.536353418903966

Epoch: 700| Step: 0
Training loss: 0.0422392375767231
Validation loss: 1.5430045794415217

Epoch: 5| Step: 1
Training loss: 0.043071139603853226
Validation loss: 1.539080786448653

Epoch: 5| Step: 2
Training loss: 0.06964701414108276
Validation loss: 1.5231626879784368

Epoch: 5| Step: 3
Training loss: 0.059297263622283936
Validation loss: 1.540753956763975

Epoch: 5| Step: 4
Training loss: 0.03926823288202286
Validation loss: 1.5361359414233957

Epoch: 5| Step: 5
Training loss: 0.0674695149064064
Validation loss: 1.5336632869576896

Epoch: 5| Step: 6
Training loss: 0.060693301260471344
Validation loss: 1.5379599845537575

Epoch: 5| Step: 7
Training loss: 0.04890834540128708
Validation loss: 1.5382285041193808

Epoch: 5| Step: 8
Training loss: 0.07107286155223846
Validation loss: 1.493678125002051

Epoch: 5| Step: 9
Training loss: 0.09234581887722015
Validation loss: 1.5195481418281473

Epoch: 5| Step: 10
Training loss: 0.0643424317240715
Validation loss: 1.520988719437712

Epoch: 701| Step: 0
Training loss: 0.05006713792681694
Validation loss: 1.4996962431938416

Epoch: 5| Step: 1
Training loss: 0.0562894232571125
Validation loss: 1.4920055327876922

Epoch: 5| Step: 2
Training loss: 0.04538189247250557
Validation loss: 1.4955820588655369

Epoch: 5| Step: 3
Training loss: 0.0478939488530159
Validation loss: 1.4831704990838164

Epoch: 5| Step: 4
Training loss: 0.06377822160720825
Validation loss: 1.502564222581925

Epoch: 5| Step: 5
Training loss: 0.05403662845492363
Validation loss: 1.52703256376328

Epoch: 5| Step: 6
Training loss: 0.0417289175093174
Validation loss: 1.495002720945625

Epoch: 5| Step: 7
Training loss: 0.07134585082530975
Validation loss: 1.493755300839742

Epoch: 5| Step: 8
Training loss: 0.07333938777446747
Validation loss: 1.5066720811269616

Epoch: 5| Step: 9
Training loss: 0.055767666548490524
Validation loss: 1.5025232953409995

Epoch: 5| Step: 10
Training loss: 0.08306469023227692
Validation loss: 1.5041616283437258

Epoch: 702| Step: 0
Training loss: 0.029698383063077927
Validation loss: 1.5094391158832017

Epoch: 5| Step: 1
Training loss: 0.04560158774256706
Validation loss: 1.516730398260137

Epoch: 5| Step: 2
Training loss: 0.07486274838447571
Validation loss: 1.501417668916846

Epoch: 5| Step: 3
Training loss: 0.10468969494104385
Validation loss: 1.519760880419003

Epoch: 5| Step: 4
Training loss: 0.039012033492326736
Validation loss: 1.5188548398274246

Epoch: 5| Step: 5
Training loss: 0.03922059386968613
Validation loss: 1.5100929185908327

Epoch: 5| Step: 6
Training loss: 0.05406982824206352
Validation loss: 1.512049853160817

Epoch: 5| Step: 7
Training loss: 0.043236829340457916
Validation loss: 1.5146112211288945

Epoch: 5| Step: 8
Training loss: 0.10936424881219864
Validation loss: 1.4885138324511948

Epoch: 5| Step: 9
Training loss: 0.05484170839190483
Validation loss: 1.4835315647945608

Epoch: 5| Step: 10
Training loss: 0.07930124551057816
Validation loss: 1.489244987887721

Epoch: 703| Step: 0
Training loss: 0.08045893162488937
Validation loss: 1.4775512013384091

Epoch: 5| Step: 1
Training loss: 0.032521408051252365
Validation loss: 1.4972944669826056

Epoch: 5| Step: 2
Training loss: 0.04965587332844734
Validation loss: 1.4922521729623117

Epoch: 5| Step: 3
Training loss: 0.061434246599674225
Validation loss: 1.5041019531988329

Epoch: 5| Step: 4
Training loss: 0.0771043673157692
Validation loss: 1.5183575396896691

Epoch: 5| Step: 5
Training loss: 0.06544940918684006
Validation loss: 1.525913502580376

Epoch: 5| Step: 6
Training loss: 0.06369796395301819
Validation loss: 1.5030255958598147

Epoch: 5| Step: 7
Training loss: 0.035990167409181595
Validation loss: 1.4970011108665056

Epoch: 5| Step: 8
Training loss: 0.04967070370912552
Validation loss: 1.481561109583865

Epoch: 5| Step: 9
Training loss: 0.05829714611172676
Validation loss: 1.4785856713530838

Epoch: 5| Step: 10
Training loss: 0.0450117327272892
Validation loss: 1.4724908926153695

Epoch: 704| Step: 0
Training loss: 0.04181518405675888
Validation loss: 1.4846594846376808

Epoch: 5| Step: 1
Training loss: 0.05263053625822067
Validation loss: 1.492038619133734

Epoch: 5| Step: 2
Training loss: 0.03966453671455383
Validation loss: 1.5143852208250312

Epoch: 5| Step: 3
Training loss: 0.05311984941363335
Validation loss: 1.4955759420189807

Epoch: 5| Step: 4
Training loss: 0.059131503105163574
Validation loss: 1.5063878400351411

Epoch: 5| Step: 5
Training loss: 0.0726311057806015
Validation loss: 1.502903752429511

Epoch: 5| Step: 6
Training loss: 0.04537438228726387
Validation loss: 1.5149629064785537

Epoch: 5| Step: 7
Training loss: 0.054587654769420624
Validation loss: 1.4993683381747174

Epoch: 5| Step: 8
Training loss: 0.06600947678089142
Validation loss: 1.483112064740991

Epoch: 5| Step: 9
Training loss: 0.06358800083398819
Validation loss: 1.454802341358636

Epoch: 5| Step: 10
Training loss: 0.0781569704413414
Validation loss: 1.4782810711091565

Epoch: 705| Step: 0
Training loss: 0.06195485591888428
Validation loss: 1.4731678270524549

Epoch: 5| Step: 1
Training loss: 0.0773661658167839
Validation loss: 1.4890873009158718

Epoch: 5| Step: 2
Training loss: 0.055855073034763336
Validation loss: 1.4604065302879579

Epoch: 5| Step: 3
Training loss: 0.05742167681455612
Validation loss: 1.485775586097471

Epoch: 5| Step: 4
Training loss: 0.08777342736721039
Validation loss: 1.4600691417212128

Epoch: 5| Step: 5
Training loss: 0.030703824013471603
Validation loss: 1.4928900631525184

Epoch: 5| Step: 6
Training loss: 0.07005228847265244
Validation loss: 1.4864157117823118

Epoch: 5| Step: 7
Training loss: 0.04889937490224838
Validation loss: 1.48919718111715

Epoch: 5| Step: 8
Training loss: 0.08246682584285736
Validation loss: 1.495682442060081

Epoch: 5| Step: 9
Training loss: 0.04641483351588249
Validation loss: 1.5050833430341495

Epoch: 5| Step: 10
Training loss: 0.05596575140953064
Validation loss: 1.4800289362989447

Epoch: 706| Step: 0
Training loss: 0.04986398667097092
Validation loss: 1.4930986358273415

Epoch: 5| Step: 1
Training loss: 0.05463290214538574
Validation loss: 1.4883331675683298

Epoch: 5| Step: 2
Training loss: 0.042045604437589645
Validation loss: 1.4642482483258812

Epoch: 5| Step: 3
Training loss: 0.06214017793536186
Validation loss: 1.470747806692636

Epoch: 5| Step: 4
Training loss: 0.06748215854167938
Validation loss: 1.458652743729212

Epoch: 5| Step: 5
Training loss: 0.04354159161448479
Validation loss: 1.4700339340394544

Epoch: 5| Step: 6
Training loss: 0.04471258819103241
Validation loss: 1.4449879610410301

Epoch: 5| Step: 7
Training loss: 0.06019355729222298
Validation loss: 1.4843351123153523

Epoch: 5| Step: 8
Training loss: 0.06273343414068222
Validation loss: 1.452895119626035

Epoch: 5| Step: 9
Training loss: 0.06380333006381989
Validation loss: 1.471621254438995

Epoch: 5| Step: 10
Training loss: 0.04457999765872955
Validation loss: 1.4826783326364332

Epoch: 707| Step: 0
Training loss: 0.03913950175046921
Validation loss: 1.4842490662810623

Epoch: 5| Step: 1
Training loss: 0.0499042384326458
Validation loss: 1.49449832465059

Epoch: 5| Step: 2
Training loss: 0.07936537265777588
Validation loss: 1.510249098141988

Epoch: 5| Step: 3
Training loss: 0.04337547719478607
Validation loss: 1.4898728106611518

Epoch: 5| Step: 4
Training loss: 0.05244738981127739
Validation loss: 1.4863480073149486

Epoch: 5| Step: 5
Training loss: 0.04610227793455124
Validation loss: 1.4879127740859985

Epoch: 5| Step: 6
Training loss: 0.05938684195280075
Validation loss: 1.4895851124999344

Epoch: 5| Step: 7
Training loss: 0.062439512461423874
Validation loss: 1.5127118223456926

Epoch: 5| Step: 8
Training loss: 0.06250109523534775
Validation loss: 1.5082119805838472

Epoch: 5| Step: 9
Training loss: 0.032656438648700714
Validation loss: 1.5016238612513388

Epoch: 5| Step: 10
Training loss: 0.05642703175544739
Validation loss: 1.5187284779805008

Epoch: 708| Step: 0
Training loss: 0.0598335787653923
Validation loss: 1.4996665780262282

Epoch: 5| Step: 1
Training loss: 0.06506092846393585
Validation loss: 1.512933990647716

Epoch: 5| Step: 2
Training loss: 0.07558310031890869
Validation loss: 1.4949363816169001

Epoch: 5| Step: 3
Training loss: 0.038918204605579376
Validation loss: 1.4938305295923704

Epoch: 5| Step: 4
Training loss: 0.058513034135103226
Validation loss: 1.5102571184917162

Epoch: 5| Step: 5
Training loss: 0.05190972238779068
Validation loss: 1.4854458083388626

Epoch: 5| Step: 6
Training loss: 0.05317334458231926
Validation loss: 1.4897935441745225

Epoch: 5| Step: 7
Training loss: 0.07532797008752823
Validation loss: 1.5033718719277331

Epoch: 5| Step: 8
Training loss: 0.055908918380737305
Validation loss: 1.4828274403848956

Epoch: 5| Step: 9
Training loss: 0.080199234187603
Validation loss: 1.5035105559133715

Epoch: 5| Step: 10
Training loss: 0.03815468028187752
Validation loss: 1.5080493034855011

Epoch: 709| Step: 0
Training loss: 0.055332083255052567
Validation loss: 1.4892349576437345

Epoch: 5| Step: 1
Training loss: 0.06616591662168503
Validation loss: 1.4929072497993388

Epoch: 5| Step: 2
Training loss: 0.08350364863872528
Validation loss: 1.482371776334701

Epoch: 5| Step: 3
Training loss: 0.02742518112063408
Validation loss: 1.4767310170717136

Epoch: 5| Step: 4
Training loss: 0.04898481443524361
Validation loss: 1.4619487139486498

Epoch: 5| Step: 5
Training loss: 0.045649003237485886
Validation loss: 1.4667193530708231

Epoch: 5| Step: 6
Training loss: 0.09852010011672974
Validation loss: 1.4513516195358769

Epoch: 5| Step: 7
Training loss: 0.058512937277555466
Validation loss: 1.4469086957234207

Epoch: 5| Step: 8
Training loss: 0.06811307370662689
Validation loss: 1.4315518820157616

Epoch: 5| Step: 9
Training loss: 0.06875653564929962
Validation loss: 1.4361697717379498

Epoch: 5| Step: 10
Training loss: 0.04185790941119194
Validation loss: 1.4435920003921754

Epoch: 710| Step: 0
Training loss: 0.06445880234241486
Validation loss: 1.4654548834728938

Epoch: 5| Step: 1
Training loss: 0.0751120001077652
Validation loss: 1.4896893783282208

Epoch: 5| Step: 2
Training loss: 0.05282899737358093
Validation loss: 1.47763374159413

Epoch: 5| Step: 3
Training loss: 0.04838832467794418
Validation loss: 1.4815035635425198

Epoch: 5| Step: 4
Training loss: 0.08774618804454803
Validation loss: 1.4983073190976215

Epoch: 5| Step: 5
Training loss: 0.06679484248161316
Validation loss: 1.5109022445576166

Epoch: 5| Step: 6
Training loss: 0.062277089804410934
Validation loss: 1.515634987943916

Epoch: 5| Step: 7
Training loss: 0.07713322341442108
Validation loss: 1.5136420829321748

Epoch: 5| Step: 8
Training loss: 0.04982161521911621
Validation loss: 1.5047620842533727

Epoch: 5| Step: 9
Training loss: 0.044125717133283615
Validation loss: 1.5048090373316119

Epoch: 5| Step: 10
Training loss: 0.051051147282123566
Validation loss: 1.4825333972131052

Epoch: 711| Step: 0
Training loss: 0.10040713846683502
Validation loss: 1.4826487033597884

Epoch: 5| Step: 1
Training loss: 0.06174471229314804
Validation loss: 1.4922506373415712

Epoch: 5| Step: 2
Training loss: 0.04857172444462776
Validation loss: 1.5156285121876707

Epoch: 5| Step: 3
Training loss: 0.06101546436548233
Validation loss: 1.5062534745021532

Epoch: 5| Step: 4
Training loss: 0.07978310436010361
Validation loss: 1.5023027107279787

Epoch: 5| Step: 5
Training loss: 0.07228387892246246
Validation loss: 1.5424114888714207

Epoch: 5| Step: 6
Training loss: 0.05489734560251236
Validation loss: 1.5142732807385024

Epoch: 5| Step: 7
Training loss: 0.05228535085916519
Validation loss: 1.544567608705131

Epoch: 5| Step: 8
Training loss: 0.08703196048736572
Validation loss: 1.519048003740208

Epoch: 5| Step: 9
Training loss: 0.06280945986509323
Validation loss: 1.522601209661012

Epoch: 5| Step: 10
Training loss: 0.038199227303266525
Validation loss: 1.5086129852520522

Epoch: 712| Step: 0
Training loss: 0.04554985836148262
Validation loss: 1.5009520053863525

Epoch: 5| Step: 1
Training loss: 0.039603784680366516
Validation loss: 1.4771431184584094

Epoch: 5| Step: 2
Training loss: 0.08721442520618439
Validation loss: 1.5188303878230434

Epoch: 5| Step: 3
Training loss: 0.05429797247052193
Validation loss: 1.5110661252852409

Epoch: 5| Step: 4
Training loss: 0.05273302644491196
Validation loss: 1.467105120740911

Epoch: 5| Step: 5
Training loss: 0.03665195778012276
Validation loss: 1.4911193860474454

Epoch: 5| Step: 6
Training loss: 0.057390861213207245
Validation loss: 1.485142223296627

Epoch: 5| Step: 7
Training loss: 0.07773702591657639
Validation loss: 1.4723389405076222

Epoch: 5| Step: 8
Training loss: 0.06830531358718872
Validation loss: 1.5119508094685052

Epoch: 5| Step: 9
Training loss: 0.03553321212530136
Validation loss: 1.505262049295569

Epoch: 5| Step: 10
Training loss: 0.036867134273052216
Validation loss: 1.5055736213602045

Epoch: 713| Step: 0
Training loss: 0.05002272129058838
Validation loss: 1.5337741503151514

Epoch: 5| Step: 1
Training loss: 0.04502296820282936
Validation loss: 1.5093227996621081

Epoch: 5| Step: 2
Training loss: 0.046195048838853836
Validation loss: 1.4845166731906194

Epoch: 5| Step: 3
Training loss: 0.06628608703613281
Validation loss: 1.536718051920655

Epoch: 5| Step: 4
Training loss: 0.049557141959667206
Validation loss: 1.5029102986858738

Epoch: 5| Step: 5
Training loss: 0.04573977738618851
Validation loss: 1.523917628231869

Epoch: 5| Step: 6
Training loss: 0.06750587373971939
Validation loss: 1.527538331606055

Epoch: 5| Step: 7
Training loss: 0.04425981268286705
Validation loss: 1.5190775855895011

Epoch: 5| Step: 8
Training loss: 0.04376181215047836
Validation loss: 1.5427588480775074

Epoch: 5| Step: 9
Training loss: 0.04756157472729683
Validation loss: 1.5515796484485749

Epoch: 5| Step: 10
Training loss: 0.04278005287051201
Validation loss: 1.554273622010344

Epoch: 714| Step: 0
Training loss: 0.07364709675312042
Validation loss: 1.5419861706354285

Epoch: 5| Step: 1
Training loss: 0.03765364736318588
Validation loss: 1.524996635734394

Epoch: 5| Step: 2
Training loss: 0.0441826693713665
Validation loss: 1.5325592128179406

Epoch: 5| Step: 3
Training loss: 0.04716061055660248
Validation loss: 1.534847012130163

Epoch: 5| Step: 4
Training loss: 0.054791200906038284
Validation loss: 1.5284773085706977

Epoch: 5| Step: 5
Training loss: 0.04216055944561958
Validation loss: 1.5346933680195962

Epoch: 5| Step: 6
Training loss: 0.058591604232788086
Validation loss: 1.5382917619520617

Epoch: 5| Step: 7
Training loss: 0.04377488046884537
Validation loss: 1.5228713827748452

Epoch: 5| Step: 8
Training loss: 0.05351109057664871
Validation loss: 1.5182246059499762

Epoch: 5| Step: 9
Training loss: 0.04480000585317612
Validation loss: 1.5362770486903448

Epoch: 5| Step: 10
Training loss: 0.10897006094455719
Validation loss: 1.529322919025216

Epoch: 715| Step: 0
Training loss: 0.040097612887620926
Validation loss: 1.5212547484264578

Epoch: 5| Step: 1
Training loss: 0.04576950520277023
Validation loss: 1.5326066927243305

Epoch: 5| Step: 2
Training loss: 0.05717368796467781
Validation loss: 1.4950668568252234

Epoch: 5| Step: 3
Training loss: 0.038462478667497635
Validation loss: 1.5086839724612493

Epoch: 5| Step: 4
Training loss: 0.06852226704359055
Validation loss: 1.5113044310641546

Epoch: 5| Step: 5
Training loss: 0.053453266620635986
Validation loss: 1.5056106134127545

Epoch: 5| Step: 6
Training loss: 0.031261395663022995
Validation loss: 1.4986283356143582

Epoch: 5| Step: 7
Training loss: 0.04095885530114174
Validation loss: 1.5044300863819737

Epoch: 5| Step: 8
Training loss: 0.047207754105329514
Validation loss: 1.5081856084126297

Epoch: 5| Step: 9
Training loss: 0.04612250253558159
Validation loss: 1.5075178787272463

Epoch: 5| Step: 10
Training loss: 0.057062506675720215
Validation loss: 1.4988627267140213

Epoch: 716| Step: 0
Training loss: 0.039155520498752594
Validation loss: 1.496310011033089

Epoch: 5| Step: 1
Training loss: 0.057161975651979446
Validation loss: 1.5110993513496973

Epoch: 5| Step: 2
Training loss: 0.056483447551727295
Validation loss: 1.5075499107760768

Epoch: 5| Step: 3
Training loss: 0.05443236976861954
Validation loss: 1.5134431187824537

Epoch: 5| Step: 4
Training loss: 0.06127174571156502
Validation loss: 1.512735443730508

Epoch: 5| Step: 5
Training loss: 0.07826317846775055
Validation loss: 1.516076971125859

Epoch: 5| Step: 6
Training loss: 0.0513349287211895
Validation loss: 1.4976020628406155

Epoch: 5| Step: 7
Training loss: 0.04646863788366318
Validation loss: 1.4845966600602674

Epoch: 5| Step: 8
Training loss: 0.06704998761415482
Validation loss: 1.4866798564951906

Epoch: 5| Step: 9
Training loss: 0.043941084295511246
Validation loss: 1.476158977836691

Epoch: 5| Step: 10
Training loss: 0.054840415716171265
Validation loss: 1.4969600144252981

Epoch: 717| Step: 0
Training loss: 0.03299415856599808
Validation loss: 1.4921972674708213

Epoch: 5| Step: 1
Training loss: 0.06844768673181534
Validation loss: 1.500607386712105

Epoch: 5| Step: 2
Training loss: 0.058338772505521774
Validation loss: 1.5181489029238302

Epoch: 5| Step: 3
Training loss: 0.04591960459947586
Validation loss: 1.512565157746756

Epoch: 5| Step: 4
Training loss: 0.05114291235804558
Validation loss: 1.5426469182455411

Epoch: 5| Step: 5
Training loss: 0.058630239218473434
Validation loss: 1.5527827137260026

Epoch: 5| Step: 6
Training loss: 0.040272489190101624
Validation loss: 1.558051820724241

Epoch: 5| Step: 7
Training loss: 0.05245119333267212
Validation loss: 1.527390048068057

Epoch: 5| Step: 8
Training loss: 0.08456642925739288
Validation loss: 1.537599253398116

Epoch: 5| Step: 9
Training loss: 0.05094967037439346
Validation loss: 1.5307196494071715

Epoch: 5| Step: 10
Training loss: 0.06261830031871796
Validation loss: 1.5269036626303067

Epoch: 718| Step: 0
Training loss: 0.05124109983444214
Validation loss: 1.508087629913002

Epoch: 5| Step: 1
Training loss: 0.052103541791439056
Validation loss: 1.5064917789992465

Epoch: 5| Step: 2
Training loss: 0.0716276541352272
Validation loss: 1.4830499797739007

Epoch: 5| Step: 3
Training loss: 0.07093299925327301
Validation loss: 1.492377818271678

Epoch: 5| Step: 4
Training loss: 0.08310464769601822
Validation loss: 1.4980280501868135

Epoch: 5| Step: 5
Training loss: 0.06096585839986801
Validation loss: 1.5219562412590109

Epoch: 5| Step: 6
Training loss: 0.07876239717006683
Validation loss: 1.4988154313897575

Epoch: 5| Step: 7
Training loss: 0.0380917489528656
Validation loss: 1.5115222007997575

Epoch: 5| Step: 8
Training loss: 0.030347442254424095
Validation loss: 1.5163009999900736

Epoch: 5| Step: 9
Training loss: 0.04351331293582916
Validation loss: 1.5188889785479474

Epoch: 5| Step: 10
Training loss: 0.0596771314740181
Validation loss: 1.5389662429850588

Epoch: 719| Step: 0
Training loss: 0.0566064827144146
Validation loss: 1.5570599058622956

Epoch: 5| Step: 1
Training loss: 0.09402529895305634
Validation loss: 1.54407073092717

Epoch: 5| Step: 2
Training loss: 0.049559708684682846
Validation loss: 1.532938882868777

Epoch: 5| Step: 3
Training loss: 0.056634146720170975
Validation loss: 1.5271025998618013

Epoch: 5| Step: 4
Training loss: 0.0639301985502243
Validation loss: 1.5269319370228758

Epoch: 5| Step: 5
Training loss: 0.05120652914047241
Validation loss: 1.5038781883896037

Epoch: 5| Step: 6
Training loss: 0.04803913086652756
Validation loss: 1.5099642199854697

Epoch: 5| Step: 7
Training loss: 0.04925673082470894
Validation loss: 1.5049231680490638

Epoch: 5| Step: 8
Training loss: 0.058156996965408325
Validation loss: 1.5040574201973536

Epoch: 5| Step: 9
Training loss: 0.05901273339986801
Validation loss: 1.5210334216394732

Epoch: 5| Step: 10
Training loss: 0.04703989624977112
Validation loss: 1.5020832137394977

Epoch: 720| Step: 0
Training loss: 0.03968058153986931
Validation loss: 1.4725613388963925

Epoch: 5| Step: 1
Training loss: 0.05971735715866089
Validation loss: 1.5250402829980338

Epoch: 5| Step: 2
Training loss: 0.0444062277674675
Validation loss: 1.5073283769751107

Epoch: 5| Step: 3
Training loss: 0.05344226956367493
Validation loss: 1.5138712352321995

Epoch: 5| Step: 4
Training loss: 0.070841945707798
Validation loss: 1.5031556660129177

Epoch: 5| Step: 5
Training loss: 0.04766804352402687
Validation loss: 1.5300360007952618

Epoch: 5| Step: 6
Training loss: 0.05075366422533989
Validation loss: 1.5281484409045147

Epoch: 5| Step: 7
Training loss: 0.0735219269990921
Validation loss: 1.5244530465013237

Epoch: 5| Step: 8
Training loss: 0.04994475841522217
Validation loss: 1.5287835290355067

Epoch: 5| Step: 9
Training loss: 0.04428056627511978
Validation loss: 1.538248687021194

Epoch: 5| Step: 10
Training loss: 0.07186094671487808
Validation loss: 1.552411134525012

Epoch: 721| Step: 0
Training loss: 0.06335975229740143
Validation loss: 1.5390417473290556

Epoch: 5| Step: 1
Training loss: 0.0497676245868206
Validation loss: 1.500652688805775

Epoch: 5| Step: 2
Training loss: 0.06770104169845581
Validation loss: 1.5010793696167648

Epoch: 5| Step: 3
Training loss: 0.03918512910604477
Validation loss: 1.487317305739208

Epoch: 5| Step: 4
Training loss: 0.05102436617016792
Validation loss: 1.4954767919355823

Epoch: 5| Step: 5
Training loss: 0.05877086520195007
Validation loss: 1.4894809851082422

Epoch: 5| Step: 6
Training loss: 0.05986567586660385
Validation loss: 1.4731844420074134

Epoch: 5| Step: 7
Training loss: 0.06319398432970047
Validation loss: 1.4850923771499305

Epoch: 5| Step: 8
Training loss: 0.06607820093631744
Validation loss: 1.4903780939758464

Epoch: 5| Step: 9
Training loss: 0.059965066611766815
Validation loss: 1.5052487529734129

Epoch: 5| Step: 10
Training loss: 0.07749953120946884
Validation loss: 1.49904425298014

Epoch: 722| Step: 0
Training loss: 0.041663654148578644
Validation loss: 1.4929235596810617

Epoch: 5| Step: 1
Training loss: 0.054651498794555664
Validation loss: 1.4914382029605169

Epoch: 5| Step: 2
Training loss: 0.04603806138038635
Validation loss: 1.4929730699908348

Epoch: 5| Step: 3
Training loss: 0.042707737535238266
Validation loss: 1.4947461710181287

Epoch: 5| Step: 4
Training loss: 0.05666137859225273
Validation loss: 1.5088255572062668

Epoch: 5| Step: 5
Training loss: 0.042104773223400116
Validation loss: 1.4998466789081533

Epoch: 5| Step: 6
Training loss: 0.06417816132307053
Validation loss: 1.503187951221261

Epoch: 5| Step: 7
Training loss: 0.05290709063410759
Validation loss: 1.4963004089170886

Epoch: 5| Step: 8
Training loss: 0.04677115008234978
Validation loss: 1.483467068723453

Epoch: 5| Step: 9
Training loss: 0.04766657203435898
Validation loss: 1.4977102433481524

Epoch: 5| Step: 10
Training loss: 0.08131510019302368
Validation loss: 1.51992666721344

Epoch: 723| Step: 0
Training loss: 0.041390594094991684
Validation loss: 1.5205756977040281

Epoch: 5| Step: 1
Training loss: 0.05533485487103462
Validation loss: 1.5002288497904295

Epoch: 5| Step: 2
Training loss: 0.07480213046073914
Validation loss: 1.4954907471133816

Epoch: 5| Step: 3
Training loss: 0.05248812958598137
Validation loss: 1.491162685937779

Epoch: 5| Step: 4
Training loss: 0.04848590865731239
Validation loss: 1.498845149112004

Epoch: 5| Step: 5
Training loss: 0.07399533689022064
Validation loss: 1.4956849646824661

Epoch: 5| Step: 6
Training loss: 0.05371718481183052
Validation loss: 1.4955261817542456

Epoch: 5| Step: 7
Training loss: 0.03391345590353012
Validation loss: 1.5004042745918356

Epoch: 5| Step: 8
Training loss: 0.0416853129863739
Validation loss: 1.4956338674791398

Epoch: 5| Step: 9
Training loss: 0.06384244561195374
Validation loss: 1.4929767385605843

Epoch: 5| Step: 10
Training loss: 0.042622990906238556
Validation loss: 1.5027303926406368

Epoch: 724| Step: 0
Training loss: 0.03302630037069321
Validation loss: 1.5159424248562063

Epoch: 5| Step: 1
Training loss: 0.07093914598226547
Validation loss: 1.5161143925882155

Epoch: 5| Step: 2
Training loss: 0.03732563555240631
Validation loss: 1.5087970072223293

Epoch: 5| Step: 3
Training loss: 0.0443306639790535
Validation loss: 1.538593929301026

Epoch: 5| Step: 4
Training loss: 0.04888090118765831
Validation loss: 1.5093374354864961

Epoch: 5| Step: 5
Training loss: 0.048026055097579956
Validation loss: 1.5073152844623854

Epoch: 5| Step: 6
Training loss: 0.048399318009614944
Validation loss: 1.510274403838701

Epoch: 5| Step: 7
Training loss: 0.03552677482366562
Validation loss: 1.5131913538902038

Epoch: 5| Step: 8
Training loss: 0.03612542524933815
Validation loss: 1.5020349987091557

Epoch: 5| Step: 9
Training loss: 0.056575655937194824
Validation loss: 1.4945442253543484

Epoch: 5| Step: 10
Training loss: 0.07682520896196365
Validation loss: 1.5146176609941708

Epoch: 725| Step: 0
Training loss: 0.04668460041284561
Validation loss: 1.515482086007313

Epoch: 5| Step: 1
Training loss: 0.02825230360031128
Validation loss: 1.5238223345048967

Epoch: 5| Step: 2
Training loss: 0.05068245530128479
Validation loss: 1.5367417502146896

Epoch: 5| Step: 3
Training loss: 0.07839031517505646
Validation loss: 1.5364934231645317

Epoch: 5| Step: 4
Training loss: 0.0504118986427784
Validation loss: 1.5192961385173183

Epoch: 5| Step: 5
Training loss: 0.04546451196074486
Validation loss: 1.540664102441521

Epoch: 5| Step: 6
Training loss: 0.04274690896272659
Validation loss: 1.519221245601613

Epoch: 5| Step: 7
Training loss: 0.045698367059230804
Validation loss: 1.4965319864211544

Epoch: 5| Step: 8
Training loss: 0.06133952736854553
Validation loss: 1.514021065927321

Epoch: 5| Step: 9
Training loss: 0.06329226493835449
Validation loss: 1.5255388790561306

Epoch: 5| Step: 10
Training loss: 0.04726715385913849
Validation loss: 1.4854399388836277

Epoch: 726| Step: 0
Training loss: 0.031894512474536896
Validation loss: 1.5028653298654864

Epoch: 5| Step: 1
Training loss: 0.0692654699087143
Validation loss: 1.4970346458496586

Epoch: 5| Step: 2
Training loss: 0.10042867809534073
Validation loss: 1.522109559787217

Epoch: 5| Step: 3
Training loss: 0.08563215285539627
Validation loss: 1.5224537554607596

Epoch: 5| Step: 4
Training loss: 0.05464519187808037
Validation loss: 1.5089618813607

Epoch: 5| Step: 5
Training loss: 0.038835544139146805
Validation loss: 1.4891070460760465

Epoch: 5| Step: 6
Training loss: 0.05686354637145996
Validation loss: 1.4849224513576877

Epoch: 5| Step: 7
Training loss: 0.04508102685213089
Validation loss: 1.5083600474942116

Epoch: 5| Step: 8
Training loss: 0.06321724504232407
Validation loss: 1.4990758665146366

Epoch: 5| Step: 9
Training loss: 0.0601213276386261
Validation loss: 1.5415227887451008

Epoch: 5| Step: 10
Training loss: 0.08344291150569916
Validation loss: 1.552274061787513

Epoch: 727| Step: 0
Training loss: 0.07332555949687958
Validation loss: 1.529489545411961

Epoch: 5| Step: 1
Training loss: 0.054388921707868576
Validation loss: 1.5085142530420774

Epoch: 5| Step: 2
Training loss: 0.04183056950569153
Validation loss: 1.4969333410263062

Epoch: 5| Step: 3
Training loss: 0.050784189254045486
Validation loss: 1.4976770929110947

Epoch: 5| Step: 4
Training loss: 0.041432201862335205
Validation loss: 1.4974210313571397

Epoch: 5| Step: 5
Training loss: 0.047182269394397736
Validation loss: 1.5041873839593702

Epoch: 5| Step: 6
Training loss: 0.08605630695819855
Validation loss: 1.5009900728861492

Epoch: 5| Step: 7
Training loss: 0.06762105971574783
Validation loss: 1.517491344482668

Epoch: 5| Step: 8
Training loss: 0.06902291625738144
Validation loss: 1.5098786084882674

Epoch: 5| Step: 9
Training loss: 0.04559004679322243
Validation loss: 1.4889895672439246

Epoch: 5| Step: 10
Training loss: 0.036391355097293854
Validation loss: 1.4910667186142297

Epoch: 728| Step: 0
Training loss: 0.05970329791307449
Validation loss: 1.4704615698065808

Epoch: 5| Step: 1
Training loss: 0.04416043311357498
Validation loss: 1.483336042332393

Epoch: 5| Step: 2
Training loss: 0.08199547231197357
Validation loss: 1.4844731015543784

Epoch: 5| Step: 3
Training loss: 0.05718229338526726
Validation loss: 1.48070691990596

Epoch: 5| Step: 4
Training loss: 0.06508418172597885
Validation loss: 1.4784302224395096

Epoch: 5| Step: 5
Training loss: 0.05848078057169914
Validation loss: 1.4777194799915436

Epoch: 5| Step: 6
Training loss: 0.0496709831058979
Validation loss: 1.4711764576614543

Epoch: 5| Step: 7
Training loss: 0.0731741338968277
Validation loss: 1.4886141259183165

Epoch: 5| Step: 8
Training loss: 0.036147430539131165
Validation loss: 1.5029709749324347

Epoch: 5| Step: 9
Training loss: 0.06634551286697388
Validation loss: 1.5183871984481812

Epoch: 5| Step: 10
Training loss: 0.07381094992160797
Validation loss: 1.5143082757149973

Epoch: 729| Step: 0
Training loss: 0.07264654338359833
Validation loss: 1.495924001098961

Epoch: 5| Step: 1
Training loss: 0.08368920534849167
Validation loss: 1.4872289780647523

Epoch: 5| Step: 2
Training loss: 0.05554245039820671
Validation loss: 1.4757972173793341

Epoch: 5| Step: 3
Training loss: 0.06613020598888397
Validation loss: 1.4568413034562142

Epoch: 5| Step: 4
Training loss: 0.06913064420223236
Validation loss: 1.4613340003516084

Epoch: 5| Step: 5
Training loss: 0.06225021556019783
Validation loss: 1.4461890753879343

Epoch: 5| Step: 6
Training loss: 0.058015376329422
Validation loss: 1.4524130616136777

Epoch: 5| Step: 7
Training loss: 0.042433012276887894
Validation loss: 1.4459431594417942

Epoch: 5| Step: 8
Training loss: 0.07214564830064774
Validation loss: 1.4679665732127365

Epoch: 5| Step: 9
Training loss: 0.049413710832595825
Validation loss: 1.4665885086982482

Epoch: 5| Step: 10
Training loss: 0.05157121643424034
Validation loss: 1.478120707696484

Epoch: 730| Step: 0
Training loss: 0.06816759705543518
Validation loss: 1.4967746157799997

Epoch: 5| Step: 1
Training loss: 0.04737268388271332
Validation loss: 1.4939552673729517

Epoch: 5| Step: 2
Training loss: 0.04560969024896622
Validation loss: 1.5059401463436823

Epoch: 5| Step: 3
Training loss: 0.060218535363674164
Validation loss: 1.4959412556822582

Epoch: 5| Step: 4
Training loss: 0.11039774119853973
Validation loss: 1.4887105341880553

Epoch: 5| Step: 5
Training loss: 0.027692411094903946
Validation loss: 1.5132225982604488

Epoch: 5| Step: 6
Training loss: 0.05446742847561836
Validation loss: 1.4849764627795066

Epoch: 5| Step: 7
Training loss: 0.05368759483098984
Validation loss: 1.4951649519705004

Epoch: 5| Step: 8
Training loss: 0.05072862654924393
Validation loss: 1.4864082426153205

Epoch: 5| Step: 9
Training loss: 0.05760716646909714
Validation loss: 1.458679142818656

Epoch: 5| Step: 10
Training loss: 0.06347749382257462
Validation loss: 1.4827215017810944

Epoch: 731| Step: 0
Training loss: 0.04006073623895645
Validation loss: 1.4836899247220767

Epoch: 5| Step: 1
Training loss: 0.06544215977191925
Validation loss: 1.4825217467482372

Epoch: 5| Step: 2
Training loss: 0.0319761224091053
Validation loss: 1.4660960333321684

Epoch: 5| Step: 3
Training loss: 0.03478042408823967
Validation loss: 1.4784696422597414

Epoch: 5| Step: 4
Training loss: 0.042809486389160156
Validation loss: 1.4693286649642452

Epoch: 5| Step: 5
Training loss: 0.041111040860414505
Validation loss: 1.4887481697144047

Epoch: 5| Step: 6
Training loss: 0.0435994528234005
Validation loss: 1.4930645637614752

Epoch: 5| Step: 7
Training loss: 0.07405903935432434
Validation loss: 1.5071463764354747

Epoch: 5| Step: 8
Training loss: 0.04109608009457588
Validation loss: 1.4890665681131425

Epoch: 5| Step: 9
Training loss: 0.07576525956392288
Validation loss: 1.4898020323886667

Epoch: 5| Step: 10
Training loss: 0.03477190434932709
Validation loss: 1.5039332489813528

Epoch: 732| Step: 0
Training loss: 0.05294498801231384
Validation loss: 1.5115740299224854

Epoch: 5| Step: 1
Training loss: 0.07281135022640228
Validation loss: 1.5042830718460904

Epoch: 5| Step: 2
Training loss: 0.047980546951293945
Validation loss: 1.511897881825765

Epoch: 5| Step: 3
Training loss: 0.04136594757437706
Validation loss: 1.5018833580837454

Epoch: 5| Step: 4
Training loss: 0.06880170106887817
Validation loss: 1.493631096296413

Epoch: 5| Step: 5
Training loss: 0.058507658541202545
Validation loss: 1.4984712421253163

Epoch: 5| Step: 6
Training loss: 0.06260207295417786
Validation loss: 1.5091031341142551

Epoch: 5| Step: 7
Training loss: 0.05221802741289139
Validation loss: 1.49955411623883

Epoch: 5| Step: 8
Training loss: 0.04004398733377457
Validation loss: 1.4773384563384517

Epoch: 5| Step: 9
Training loss: 0.04505325108766556
Validation loss: 1.4936646620432537

Epoch: 5| Step: 10
Training loss: 0.03551348298788071
Validation loss: 1.4835047978226856

Epoch: 733| Step: 0
Training loss: 0.04039023816585541
Validation loss: 1.4961947292409918

Epoch: 5| Step: 1
Training loss: 0.07190774381160736
Validation loss: 1.482614181374991

Epoch: 5| Step: 2
Training loss: 0.055662430822849274
Validation loss: 1.487622646875279

Epoch: 5| Step: 3
Training loss: 0.03884582966566086
Validation loss: 1.493446066815366

Epoch: 5| Step: 4
Training loss: 0.060810089111328125
Validation loss: 1.5118549280269171

Epoch: 5| Step: 5
Training loss: 0.03408723697066307
Validation loss: 1.5069866667511642

Epoch: 5| Step: 6
Training loss: 0.033375851809978485
Validation loss: 1.493519006236907

Epoch: 5| Step: 7
Training loss: 0.027182742953300476
Validation loss: 1.5113670736230829

Epoch: 5| Step: 8
Training loss: 0.048232316970825195
Validation loss: 1.5135999097619006

Epoch: 5| Step: 9
Training loss: 0.045221470296382904
Validation loss: 1.5152596068638626

Epoch: 5| Step: 10
Training loss: 0.08244882524013519
Validation loss: 1.5429732414983934

Epoch: 734| Step: 0
Training loss: 0.04050659388303757
Validation loss: 1.5180324380115797

Epoch: 5| Step: 1
Training loss: 0.03266040235757828
Validation loss: 1.54140341794619

Epoch: 5| Step: 2
Training loss: 0.04173595458269119
Validation loss: 1.5353215548299974

Epoch: 5| Step: 3
Training loss: 0.0326605848968029
Validation loss: 1.526347711522092

Epoch: 5| Step: 4
Training loss: 0.0767742171883583
Validation loss: 1.5433272110518588

Epoch: 5| Step: 5
Training loss: 0.060353197157382965
Validation loss: 1.547758219062641

Epoch: 5| Step: 6
Training loss: 0.048246923834085464
Validation loss: 1.5372120885438816

Epoch: 5| Step: 7
Training loss: 0.05247526243329048
Validation loss: 1.5440332479374383

Epoch: 5| Step: 8
Training loss: 0.05297283083200455
Validation loss: 1.5330640257045787

Epoch: 5| Step: 9
Training loss: 0.04388663172721863
Validation loss: 1.5582388895814137

Epoch: 5| Step: 10
Training loss: 0.03570815548300743
Validation loss: 1.5147072871526082

Epoch: 735| Step: 0
Training loss: 0.04968642443418503
Validation loss: 1.5102485341410483

Epoch: 5| Step: 1
Training loss: 0.0389368049800396
Validation loss: 1.5053545403224167

Epoch: 5| Step: 2
Training loss: 0.049769558012485504
Validation loss: 1.5358515683040823

Epoch: 5| Step: 3
Training loss: 0.05661413073539734
Validation loss: 1.5169853343758533

Epoch: 5| Step: 4
Training loss: 0.038230277597904205
Validation loss: 1.5126774772520988

Epoch: 5| Step: 5
Training loss: 0.08635691553354263
Validation loss: 1.5104994581591698

Epoch: 5| Step: 6
Training loss: 0.07072720676660538
Validation loss: 1.4844383360237203

Epoch: 5| Step: 7
Training loss: 0.05443481355905533
Validation loss: 1.5145561310552782

Epoch: 5| Step: 8
Training loss: 0.03971103951334953
Validation loss: 1.4998130490702968

Epoch: 5| Step: 9
Training loss: 0.04984141141176224
Validation loss: 1.5223981552226569

Epoch: 5| Step: 10
Training loss: 0.04967372491955757
Validation loss: 1.5285357172771166

Epoch: 736| Step: 0
Training loss: 0.07496006786823273
Validation loss: 1.5066060584078553

Epoch: 5| Step: 1
Training loss: 0.052901022136211395
Validation loss: 1.5090350297189528

Epoch: 5| Step: 2
Training loss: 0.04591674357652664
Validation loss: 1.5271321176200785

Epoch: 5| Step: 3
Training loss: 0.07976061850786209
Validation loss: 1.5045330883354269

Epoch: 5| Step: 4
Training loss: 0.051570989191532135
Validation loss: 1.5108416721385012

Epoch: 5| Step: 5
Training loss: 0.050792742520570755
Validation loss: 1.5009544446904173

Epoch: 5| Step: 6
Training loss: 0.03442066162824631
Validation loss: 1.516876703949385

Epoch: 5| Step: 7
Training loss: 0.059643905609846115
Validation loss: 1.5100527719784809

Epoch: 5| Step: 8
Training loss: 0.06498261541128159
Validation loss: 1.4989794710631013

Epoch: 5| Step: 9
Training loss: 0.07115180045366287
Validation loss: 1.5218607699999245

Epoch: 5| Step: 10
Training loss: 0.03936009481549263
Validation loss: 1.5301963565170125

Epoch: 737| Step: 0
Training loss: 0.03983313962817192
Validation loss: 1.5068514257348993

Epoch: 5| Step: 1
Training loss: 0.05637223273515701
Validation loss: 1.5023707420595231

Epoch: 5| Step: 2
Training loss: 0.05824796482920647
Validation loss: 1.5304582240760967

Epoch: 5| Step: 3
Training loss: 0.03616626560688019
Validation loss: 1.507264139831707

Epoch: 5| Step: 4
Training loss: 0.05158209800720215
Validation loss: 1.5066166616255237

Epoch: 5| Step: 5
Training loss: 0.06456423550844193
Validation loss: 1.5201986964030931

Epoch: 5| Step: 6
Training loss: 0.036288779228925705
Validation loss: 1.5176908393060007

Epoch: 5| Step: 7
Training loss: 0.06592219322919846
Validation loss: 1.4952620005094877

Epoch: 5| Step: 8
Training loss: 0.055916737765073776
Validation loss: 1.5015655038177327

Epoch: 5| Step: 9
Training loss: 0.045884761959314346
Validation loss: 1.518908498107746

Epoch: 5| Step: 10
Training loss: 0.059421077370643616
Validation loss: 1.5061231813123148

Epoch: 738| Step: 0
Training loss: 0.07374399155378342
Validation loss: 1.529338316250873

Epoch: 5| Step: 1
Training loss: 0.04424750804901123
Validation loss: 1.509594831415402

Epoch: 5| Step: 2
Training loss: 0.05156688019633293
Validation loss: 1.5218756403974307

Epoch: 5| Step: 3
Training loss: 0.04701640456914902
Validation loss: 1.5112899605945875

Epoch: 5| Step: 4
Training loss: 0.04005308821797371
Validation loss: 1.552347654937416

Epoch: 5| Step: 5
Training loss: 0.05171992629766464
Validation loss: 1.5561145146687825

Epoch: 5| Step: 6
Training loss: 0.06095106527209282
Validation loss: 1.5445200858577606

Epoch: 5| Step: 7
Training loss: 0.0520196333527565
Validation loss: 1.5148391864633048

Epoch: 5| Step: 8
Training loss: 0.037345465272665024
Validation loss: 1.5330851462579542

Epoch: 5| Step: 9
Training loss: 0.03724290430545807
Validation loss: 1.5253897610531058

Epoch: 5| Step: 10
Training loss: 0.048322636634111404
Validation loss: 1.5108108840962893

Epoch: 739| Step: 0
Training loss: 0.03122163750231266
Validation loss: 1.4917870042144612

Epoch: 5| Step: 1
Training loss: 0.04305177181959152
Validation loss: 1.4951002213262743

Epoch: 5| Step: 2
Training loss: 0.04017781466245651
Validation loss: 1.4877791609815372

Epoch: 5| Step: 3
Training loss: 0.062059421092271805
Validation loss: 1.4953358711734894

Epoch: 5| Step: 4
Training loss: 0.05344144254922867
Validation loss: 1.5123166153507848

Epoch: 5| Step: 5
Training loss: 0.039698176085948944
Validation loss: 1.4903552173286356

Epoch: 5| Step: 6
Training loss: 0.050651706755161285
Validation loss: 1.4941142848742905

Epoch: 5| Step: 7
Training loss: 0.05628932639956474
Validation loss: 1.4979651230637745

Epoch: 5| Step: 8
Training loss: 0.06578850746154785
Validation loss: 1.4764911346538092

Epoch: 5| Step: 9
Training loss: 0.0670623779296875
Validation loss: 1.4774723591343049

Epoch: 5| Step: 10
Training loss: 0.04890032485127449
Validation loss: 1.5078278818438131

Epoch: 740| Step: 0
Training loss: 0.04670451954007149
Validation loss: 1.490445694615764

Epoch: 5| Step: 1
Training loss: 0.059547025710344315
Validation loss: 1.4890102647965955

Epoch: 5| Step: 2
Training loss: 0.07933823764324188
Validation loss: 1.540133392137866

Epoch: 5| Step: 3
Training loss: 0.031244318932294846
Validation loss: 1.5136419444955804

Epoch: 5| Step: 4
Training loss: 0.042114175856113434
Validation loss: 1.5038418308381112

Epoch: 5| Step: 5
Training loss: 0.03491897135972977
Validation loss: 1.4864238013503372

Epoch: 5| Step: 6
Training loss: 0.049571145325899124
Validation loss: 1.4823074577957072

Epoch: 5| Step: 7
Training loss: 0.08409933745861053
Validation loss: 1.5017237778632873

Epoch: 5| Step: 8
Training loss: 0.05963575839996338
Validation loss: 1.5024333448820217

Epoch: 5| Step: 9
Training loss: 0.05660729855298996
Validation loss: 1.486929573038573

Epoch: 5| Step: 10
Training loss: 0.06080563738942146
Validation loss: 1.488878124503679

Epoch: 741| Step: 0
Training loss: 0.0657433569431305
Validation loss: 1.4863231733281126

Epoch: 5| Step: 1
Training loss: 0.06471361219882965
Validation loss: 1.5004157738019062

Epoch: 5| Step: 2
Training loss: 0.05724127218127251
Validation loss: 1.4845959319863269

Epoch: 5| Step: 3
Training loss: 0.04314972460269928
Validation loss: 1.4957209787061136

Epoch: 5| Step: 4
Training loss: 0.02686876617372036
Validation loss: 1.5105420966302194

Epoch: 5| Step: 5
Training loss: 0.07564955204725266
Validation loss: 1.5058820491196008

Epoch: 5| Step: 6
Training loss: 0.0519985668361187
Validation loss: 1.464255694420107

Epoch: 5| Step: 7
Training loss: 0.03369884565472603
Validation loss: 1.4904362046590416

Epoch: 5| Step: 8
Training loss: 0.05907835438847542
Validation loss: 1.4686358474916028

Epoch: 5| Step: 9
Training loss: 0.03440694883465767
Validation loss: 1.467537779961863

Epoch: 5| Step: 10
Training loss: 0.0680694654583931
Validation loss: 1.4718491505551081

Epoch: 742| Step: 0
Training loss: 0.06283210963010788
Validation loss: 1.4616409181266703

Epoch: 5| Step: 1
Training loss: 0.037858545780181885
Validation loss: 1.4704191950700616

Epoch: 5| Step: 2
Training loss: 0.049115460366010666
Validation loss: 1.4872296894750288

Epoch: 5| Step: 3
Training loss: 0.04100817069411278
Validation loss: 1.4910655310077052

Epoch: 5| Step: 4
Training loss: 0.05728333070874214
Validation loss: 1.4834008857768068

Epoch: 5| Step: 5
Training loss: 0.05517669767141342
Validation loss: 1.4832358065471853

Epoch: 5| Step: 6
Training loss: 0.053921379148960114
Validation loss: 1.4700878102292296

Epoch: 5| Step: 7
Training loss: 0.043769679963588715
Validation loss: 1.4594799959531395

Epoch: 5| Step: 8
Training loss: 0.060411762446165085
Validation loss: 1.4768275394234607

Epoch: 5| Step: 9
Training loss: 0.054484784603118896
Validation loss: 1.4716210006385722

Epoch: 5| Step: 10
Training loss: 0.04431586712598801
Validation loss: 1.466182711303875

Epoch: 743| Step: 0
Training loss: 0.03183882310986519
Validation loss: 1.5005013763263662

Epoch: 5| Step: 1
Training loss: 0.057436734437942505
Validation loss: 1.5247007634050103

Epoch: 5| Step: 2
Training loss: 0.07165969908237457
Validation loss: 1.501348066073592

Epoch: 5| Step: 3
Training loss: 0.045359961688518524
Validation loss: 1.4889808111293341

Epoch: 5| Step: 4
Training loss: 0.059303682297468185
Validation loss: 1.5091009652742775

Epoch: 5| Step: 5
Training loss: 0.05884445831179619
Validation loss: 1.4814401634277836

Epoch: 5| Step: 6
Training loss: 0.06658843159675598
Validation loss: 1.48530416206647

Epoch: 5| Step: 7
Training loss: 0.07575152814388275
Validation loss: 1.5060952119929816

Epoch: 5| Step: 8
Training loss: 0.058228813111782074
Validation loss: 1.4895716354411135

Epoch: 5| Step: 9
Training loss: 0.046379201114177704
Validation loss: 1.5011682677012619

Epoch: 5| Step: 10
Training loss: 0.09231197834014893
Validation loss: 1.5237492861286286

Epoch: 744| Step: 0
Training loss: 0.05499681830406189
Validation loss: 1.5102892255270353

Epoch: 5| Step: 1
Training loss: 0.04436202719807625
Validation loss: 1.5189109540754748

Epoch: 5| Step: 2
Training loss: 0.052226774394512177
Validation loss: 1.5422805111895326

Epoch: 5| Step: 3
Training loss: 0.06076660007238388
Validation loss: 1.551556703223977

Epoch: 5| Step: 4
Training loss: 0.08687131851911545
Validation loss: 1.5379406688033894

Epoch: 5| Step: 5
Training loss: 0.08827196061611176
Validation loss: 1.570921944033715

Epoch: 5| Step: 6
Training loss: 0.08556433767080307
Validation loss: 1.5539418920393913

Epoch: 5| Step: 7
Training loss: 0.045910175889730453
Validation loss: 1.5488607332270632

Epoch: 5| Step: 8
Training loss: 0.05278845503926277
Validation loss: 1.5202838015812699

Epoch: 5| Step: 9
Training loss: 0.04487225413322449
Validation loss: 1.5184838541092411

Epoch: 5| Step: 10
Training loss: 0.044463418424129486
Validation loss: 1.5405015125069568

Epoch: 745| Step: 0
Training loss: 0.0879075676202774
Validation loss: 1.521633671176049

Epoch: 5| Step: 1
Training loss: 0.05521435663104057
Validation loss: 1.5248817910430252

Epoch: 5| Step: 2
Training loss: 0.08063143491744995
Validation loss: 1.5407476386716288

Epoch: 5| Step: 3
Training loss: 0.05800516530871391
Validation loss: 1.5257708436699324

Epoch: 5| Step: 4
Training loss: 0.08697126060724258
Validation loss: 1.5230777577687336

Epoch: 5| Step: 5
Training loss: 0.043025147169828415
Validation loss: 1.4915854994968702

Epoch: 5| Step: 6
Training loss: 0.06239143759012222
Validation loss: 1.4776280977392708

Epoch: 5| Step: 7
Training loss: 0.042753010988235474
Validation loss: 1.4730546859002882

Epoch: 5| Step: 8
Training loss: 0.05384410545229912
Validation loss: 1.4543241262435913

Epoch: 5| Step: 9
Training loss: 0.06414346396923065
Validation loss: 1.440440406081497

Epoch: 5| Step: 10
Training loss: 0.08443722128868103
Validation loss: 1.4618728250585578

Epoch: 746| Step: 0
Training loss: 0.06703108549118042
Validation loss: 1.4627393112387708

Epoch: 5| Step: 1
Training loss: 0.06163067743182182
Validation loss: 1.455249644735808

Epoch: 5| Step: 2
Training loss: 0.07188490778207779
Validation loss: 1.4655746247178765

Epoch: 5| Step: 3
Training loss: 0.04166247695684433
Validation loss: 1.4610165165316673

Epoch: 5| Step: 4
Training loss: 0.042315661907196045
Validation loss: 1.503176111687896

Epoch: 5| Step: 5
Training loss: 0.05389542505145073
Validation loss: 1.4914788276918474

Epoch: 5| Step: 6
Training loss: 0.055548954755067825
Validation loss: 1.4991646389807425

Epoch: 5| Step: 7
Training loss: 0.04953967407345772
Validation loss: 1.5134378646009712

Epoch: 5| Step: 8
Training loss: 0.07560096681118011
Validation loss: 1.4883788913808844

Epoch: 5| Step: 9
Training loss: 0.05681600421667099
Validation loss: 1.5125751815816408

Epoch: 5| Step: 10
Training loss: 0.05247812718153
Validation loss: 1.50936088895285

Epoch: 747| Step: 0
Training loss: 0.04232945293188095
Validation loss: 1.5043435051877012

Epoch: 5| Step: 1
Training loss: 0.060177236795425415
Validation loss: 1.4965283011877408

Epoch: 5| Step: 2
Training loss: 0.0681254118680954
Validation loss: 1.513862999536658

Epoch: 5| Step: 3
Training loss: 0.04449469968676567
Validation loss: 1.5187002766516902

Epoch: 5| Step: 4
Training loss: 0.09846903383731842
Validation loss: 1.5310845746788928

Epoch: 5| Step: 5
Training loss: 0.06661920994520187
Validation loss: 1.5553952750339304

Epoch: 5| Step: 6
Training loss: 0.06141599267721176
Validation loss: 1.512931590439171

Epoch: 5| Step: 7
Training loss: 0.06347803771495819
Validation loss: 1.5138164412590764

Epoch: 5| Step: 8
Training loss: 0.0295114703476429
Validation loss: 1.519542158290904

Epoch: 5| Step: 9
Training loss: 0.05729718133807182
Validation loss: 1.5481781677533222

Epoch: 5| Step: 10
Training loss: 0.07088050991296768
Validation loss: 1.5551398069627824

Epoch: 748| Step: 0
Training loss: 0.07213284820318222
Validation loss: 1.5329031393092165

Epoch: 5| Step: 1
Training loss: 0.04987471550703049
Validation loss: 1.508225155133073

Epoch: 5| Step: 2
Training loss: 0.08581800758838654
Validation loss: 1.5182427821620819

Epoch: 5| Step: 3
Training loss: 0.05674226954579353
Validation loss: 1.505735719075767

Epoch: 5| Step: 4
Training loss: 0.06647578626871109
Validation loss: 1.5026334703609507

Epoch: 5| Step: 5
Training loss: 0.07533708214759827
Validation loss: 1.5143467123790453

Epoch: 5| Step: 6
Training loss: 0.055426716804504395
Validation loss: 1.5421048479695474

Epoch: 5| Step: 7
Training loss: 0.07377826422452927
Validation loss: 1.563966021742872

Epoch: 5| Step: 8
Training loss: 0.09887682646512985
Validation loss: 1.5734482324251564

Epoch: 5| Step: 9
Training loss: 0.07753928750753403
Validation loss: 1.5584687084280036

Epoch: 5| Step: 10
Training loss: 0.0719226524233818
Validation loss: 1.529723136655746

Epoch: 749| Step: 0
Training loss: 0.05053076893091202
Validation loss: 1.5049842096144153

Epoch: 5| Step: 1
Training loss: 0.05400346964597702
Validation loss: 1.5048556789275138

Epoch: 5| Step: 2
Training loss: 0.05921991914510727
Validation loss: 1.5241259298016947

Epoch: 5| Step: 3
Training loss: 0.06952027976512909
Validation loss: 1.5040767711977805

Epoch: 5| Step: 4
Training loss: 0.06847402453422546
Validation loss: 1.5182949266126078

Epoch: 5| Step: 5
Training loss: 0.06046515703201294
Validation loss: 1.5074298330532607

Epoch: 5| Step: 6
Training loss: 0.06802229583263397
Validation loss: 1.505198081334432

Epoch: 5| Step: 7
Training loss: 0.024730708450078964
Validation loss: 1.510983310719972

Epoch: 5| Step: 8
Training loss: 0.04207988828420639
Validation loss: 1.486135559697305

Epoch: 5| Step: 9
Training loss: 0.04187755659222603
Validation loss: 1.4961944741587485

Epoch: 5| Step: 10
Training loss: 0.047309160232543945
Validation loss: 1.5030802885691326

Epoch: 750| Step: 0
Training loss: 0.04034882038831711
Validation loss: 1.5054630720487205

Epoch: 5| Step: 1
Training loss: 0.04503603279590607
Validation loss: 1.492191308288164

Epoch: 5| Step: 2
Training loss: 0.0750826820731163
Validation loss: 1.517411663968076

Epoch: 5| Step: 3
Training loss: 0.07817208766937256
Validation loss: 1.4939637017506424

Epoch: 5| Step: 4
Training loss: 0.04517057165503502
Validation loss: 1.482607150590548

Epoch: 5| Step: 5
Training loss: 0.058062680065631866
Validation loss: 1.4862432351676367

Epoch: 5| Step: 6
Training loss: 0.05325274541974068
Validation loss: 1.4709074625404932

Epoch: 5| Step: 7
Training loss: 0.055675290524959564
Validation loss: 1.5182899018769622

Epoch: 5| Step: 8
Training loss: 0.05320063233375549
Validation loss: 1.5092298317981023

Epoch: 5| Step: 9
Training loss: 0.05205919221043587
Validation loss: 1.5041736325910013

Epoch: 5| Step: 10
Training loss: 0.047410979866981506
Validation loss: 1.5091340323930145

Epoch: 751| Step: 0
Training loss: 0.04619499295949936
Validation loss: 1.5337646661266204

Epoch: 5| Step: 1
Training loss: 0.03875138983130455
Validation loss: 1.4960904403399395

Epoch: 5| Step: 2
Training loss: 0.055264007300138474
Validation loss: 1.5090986092885335

Epoch: 5| Step: 3
Training loss: 0.043965525925159454
Validation loss: 1.4792055942678963

Epoch: 5| Step: 4
Training loss: 0.06881459802389145
Validation loss: 1.4729953350559357

Epoch: 5| Step: 5
Training loss: 0.034159790724515915
Validation loss: 1.4689767399141866

Epoch: 5| Step: 6
Training loss: 0.06040779501199722
Validation loss: 1.471625042218034

Epoch: 5| Step: 7
Training loss: 0.060569167137145996
Validation loss: 1.4634433036209435

Epoch: 5| Step: 8
Training loss: 0.06787595897912979
Validation loss: 1.4620637470676052

Epoch: 5| Step: 9
Training loss: 0.02534632384777069
Validation loss: 1.4546988125770324

Epoch: 5| Step: 10
Training loss: 0.03751770034432411
Validation loss: 1.4718660949378886

Epoch: 752| Step: 0
Training loss: 0.049045629799366
Validation loss: 1.482694100308162

Epoch: 5| Step: 1
Training loss: 0.05308983474969864
Validation loss: 1.4717009420035987

Epoch: 5| Step: 2
Training loss: 0.06752151995897293
Validation loss: 1.4901030819903138

Epoch: 5| Step: 3
Training loss: 0.05314423888921738
Validation loss: 1.4686701746397122

Epoch: 5| Step: 4
Training loss: 0.0576971061527729
Validation loss: 1.4385706513158736

Epoch: 5| Step: 5
Training loss: 0.04114571958780289
Validation loss: 1.4696462385116085

Epoch: 5| Step: 6
Training loss: 0.05879737809300423
Validation loss: 1.4568483130906218

Epoch: 5| Step: 7
Training loss: 0.04077930748462677
Validation loss: 1.4494194612708142

Epoch: 5| Step: 8
Training loss: 0.06363973766565323
Validation loss: 1.43578492441485

Epoch: 5| Step: 9
Training loss: 0.04140458256006241
Validation loss: 1.4838661173338532

Epoch: 5| Step: 10
Training loss: 0.03863302618265152
Validation loss: 1.4499454165017733

Epoch: 753| Step: 0
Training loss: 0.07390666753053665
Validation loss: 1.4605430056971889

Epoch: 5| Step: 1
Training loss: 0.04113957658410072
Validation loss: 1.4718860426256735

Epoch: 5| Step: 2
Training loss: 0.06385942548513412
Validation loss: 1.4810075324068788

Epoch: 5| Step: 3
Training loss: 0.07262160629034042
Validation loss: 1.4939482840158607

Epoch: 5| Step: 4
Training loss: 0.04662860184907913
Validation loss: 1.483037781971757

Epoch: 5| Step: 5
Training loss: 0.05528806522488594
Validation loss: 1.4800509611765544

Epoch: 5| Step: 6
Training loss: 0.03554929420351982
Validation loss: 1.4660933658640871

Epoch: 5| Step: 7
Training loss: 0.05057147890329361
Validation loss: 1.4864877180386615

Epoch: 5| Step: 8
Training loss: 0.04269121587276459
Validation loss: 1.4865271352952527

Epoch: 5| Step: 9
Training loss: 0.0361286997795105
Validation loss: 1.4587006209999003

Epoch: 5| Step: 10
Training loss: 0.05589931458234787
Validation loss: 1.4926755607769053

Epoch: 754| Step: 0
Training loss: 0.06130275875329971
Validation loss: 1.488867828922887

Epoch: 5| Step: 1
Training loss: 0.04592076316475868
Validation loss: 1.5222236648682625

Epoch: 5| Step: 2
Training loss: 0.04729146137833595
Validation loss: 1.4999162022785475

Epoch: 5| Step: 3
Training loss: 0.04862907901406288
Validation loss: 1.5046899613513742

Epoch: 5| Step: 4
Training loss: 0.0675317794084549
Validation loss: 1.4849857989177908

Epoch: 5| Step: 5
Training loss: 0.04687698185443878
Validation loss: 1.4940315228636547

Epoch: 5| Step: 6
Training loss: 0.06240158528089523
Validation loss: 1.5076726239214662

Epoch: 5| Step: 7
Training loss: 0.0446135476231575
Validation loss: 1.4849369372090986

Epoch: 5| Step: 8
Training loss: 0.03438236191868782
Validation loss: 1.4870031905430618

Epoch: 5| Step: 9
Training loss: 0.05912882089614868
Validation loss: 1.4886760942397579

Epoch: 5| Step: 10
Training loss: 0.06785348802804947
Validation loss: 1.4979540378816667

Epoch: 755| Step: 0
Training loss: 0.05545501038432121
Validation loss: 1.5101921032833796

Epoch: 5| Step: 1
Training loss: 0.04088783264160156
Validation loss: 1.4917170334887762

Epoch: 5| Step: 2
Training loss: 0.04204094409942627
Validation loss: 1.480209142931046

Epoch: 5| Step: 3
Training loss: 0.0656561478972435
Validation loss: 1.4963189863389539

Epoch: 5| Step: 4
Training loss: 0.051081348210573196
Validation loss: 1.4743252031264766

Epoch: 5| Step: 5
Training loss: 0.03981607407331467
Validation loss: 1.482545095105325

Epoch: 5| Step: 6
Training loss: 0.032789260149002075
Validation loss: 1.4923854848389984

Epoch: 5| Step: 7
Training loss: 0.05569702386856079
Validation loss: 1.4930019455571328

Epoch: 5| Step: 8
Training loss: 0.05630442500114441
Validation loss: 1.4871819506409347

Epoch: 5| Step: 9
Training loss: 0.05231998488306999
Validation loss: 1.5225966092078917

Epoch: 5| Step: 10
Training loss: 0.03822266310453415
Validation loss: 1.543551714189591

Epoch: 756| Step: 0
Training loss: 0.04139913246035576
Validation loss: 1.5203381212808753

Epoch: 5| Step: 1
Training loss: 0.03840995579957962
Validation loss: 1.5234458202956824

Epoch: 5| Step: 2
Training loss: 0.0578310489654541
Validation loss: 1.5284754319857525

Epoch: 5| Step: 3
Training loss: 0.05365701764822006
Validation loss: 1.5083767880675614

Epoch: 5| Step: 4
Training loss: 0.060027170926332474
Validation loss: 1.4936766996178577

Epoch: 5| Step: 5
Training loss: 0.0660533681511879
Validation loss: 1.5138330626231369

Epoch: 5| Step: 6
Training loss: 0.03926721215248108
Validation loss: 1.5054542300521687

Epoch: 5| Step: 7
Training loss: 0.07167936861515045
Validation loss: 1.5296536530217817

Epoch: 5| Step: 8
Training loss: 0.03702453151345253
Validation loss: 1.5310326109650314

Epoch: 5| Step: 9
Training loss: 0.07217390090227127
Validation loss: 1.5016945446691206

Epoch: 5| Step: 10
Training loss: 0.08228408545255661
Validation loss: 1.4989366839008946

Epoch: 757| Step: 0
Training loss: 0.05106257647275925
Validation loss: 1.4832390892890193

Epoch: 5| Step: 1
Training loss: 0.04529593512415886
Validation loss: 1.511360281257219

Epoch: 5| Step: 2
Training loss: 0.06111735850572586
Validation loss: 1.5190796121474235

Epoch: 5| Step: 3
Training loss: 0.04416671767830849
Validation loss: 1.5298942058317122

Epoch: 5| Step: 4
Training loss: 0.0722028985619545
Validation loss: 1.5599398382248417

Epoch: 5| Step: 5
Training loss: 0.08254550397396088
Validation loss: 1.5757216368952105

Epoch: 5| Step: 6
Training loss: 0.0748467668890953
Validation loss: 1.540075808443049

Epoch: 5| Step: 7
Training loss: 0.08129893243312836
Validation loss: 1.4892072241793397

Epoch: 5| Step: 8
Training loss: 0.08813457190990448
Validation loss: 1.4896567290829075

Epoch: 5| Step: 9
Training loss: 0.07201134413480759
Validation loss: 1.484984427370051

Epoch: 5| Step: 10
Training loss: 0.07020875811576843
Validation loss: 1.5321627227208947

Epoch: 758| Step: 0
Training loss: 0.0833529606461525
Validation loss: 1.530024690012778

Epoch: 5| Step: 1
Training loss: 0.10488004982471466
Validation loss: 1.5294094483057659

Epoch: 5| Step: 2
Training loss: 0.056187890470027924
Validation loss: 1.495065837778071

Epoch: 5| Step: 3
Training loss: 0.047745347023010254
Validation loss: 1.5014049404410905

Epoch: 5| Step: 4
Training loss: 0.061345361173152924
Validation loss: 1.5178076938916278

Epoch: 5| Step: 5
Training loss: 0.045616500079631805
Validation loss: 1.5123940513980003

Epoch: 5| Step: 6
Training loss: 0.06478280574083328
Validation loss: 1.5490701096032256

Epoch: 5| Step: 7
Training loss: 0.08922986686229706
Validation loss: 1.5890223300585182

Epoch: 5| Step: 8
Training loss: 0.07774979621171951
Validation loss: 1.5864974234693794

Epoch: 5| Step: 9
Training loss: 0.0709039717912674
Validation loss: 1.591568644328784

Epoch: 5| Step: 10
Training loss: 0.06347408145666122
Validation loss: 1.5572802789749638

Epoch: 759| Step: 0
Training loss: 0.08325850963592529
Validation loss: 1.559027507740964

Epoch: 5| Step: 1
Training loss: 0.05776413157582283
Validation loss: 1.5298662108759726

Epoch: 5| Step: 2
Training loss: 0.04872184991836548
Validation loss: 1.5325998093492241

Epoch: 5| Step: 3
Training loss: 0.05811639502644539
Validation loss: 1.5179662114830428

Epoch: 5| Step: 4
Training loss: 0.07842537760734558
Validation loss: 1.5068829982511458

Epoch: 5| Step: 5
Training loss: 0.04573569819331169
Validation loss: 1.494603487753099

Epoch: 5| Step: 6
Training loss: 0.04662739485502243
Validation loss: 1.5194997864384805

Epoch: 5| Step: 7
Training loss: 0.049129895865917206
Validation loss: 1.51284590331457

Epoch: 5| Step: 8
Training loss: 0.052740227431058884
Validation loss: 1.5077925946122857

Epoch: 5| Step: 9
Training loss: 0.055765509605407715
Validation loss: 1.5054225780630623

Epoch: 5| Step: 10
Training loss: 0.051844216883182526
Validation loss: 1.5077874532309912

Epoch: 760| Step: 0
Training loss: 0.059976428747177124
Validation loss: 1.5186331323398057

Epoch: 5| Step: 1
Training loss: 0.07382701337337494
Validation loss: 1.5090997680541007

Epoch: 5| Step: 2
Training loss: 0.049779947847127914
Validation loss: 1.528594211865497

Epoch: 5| Step: 3
Training loss: 0.03361346945166588
Validation loss: 1.5117445850885043

Epoch: 5| Step: 4
Training loss: 0.07012786716222763
Validation loss: 1.4847885940664558

Epoch: 5| Step: 5
Training loss: 0.032541222870349884
Validation loss: 1.479658648531924

Epoch: 5| Step: 6
Training loss: 0.05957106500864029
Validation loss: 1.472863067862808

Epoch: 5| Step: 7
Training loss: 0.06112591177225113
Validation loss: 1.4727486718085505

Epoch: 5| Step: 8
Training loss: 0.05639253929257393
Validation loss: 1.4776277144749959

Epoch: 5| Step: 9
Training loss: 0.04712515324354172
Validation loss: 1.4719346710430679

Epoch: 5| Step: 10
Training loss: 0.03736833482980728
Validation loss: 1.4565110142512987

Epoch: 761| Step: 0
Training loss: 0.04130032658576965
Validation loss: 1.4767138829795263

Epoch: 5| Step: 1
Training loss: 0.059838391840457916
Validation loss: 1.466365897527305

Epoch: 5| Step: 2
Training loss: 0.06268012523651123
Validation loss: 1.4661481566326593

Epoch: 5| Step: 3
Training loss: 0.039712343364953995
Validation loss: 1.4921870334174043

Epoch: 5| Step: 4
Training loss: 0.05838656425476074
Validation loss: 1.4721447549840456

Epoch: 5| Step: 5
Training loss: 0.03718339279294014
Validation loss: 1.448694423962665

Epoch: 5| Step: 6
Training loss: 0.06640742719173431
Validation loss: 1.468617235460589

Epoch: 5| Step: 7
Training loss: 0.03454086184501648
Validation loss: 1.4735253023844894

Epoch: 5| Step: 8
Training loss: 0.04268072918057442
Validation loss: 1.4728382043941046

Epoch: 5| Step: 9
Training loss: 0.06833444535732269
Validation loss: 1.4851789205305037

Epoch: 5| Step: 10
Training loss: 0.033068299293518066
Validation loss: 1.4875558537821616

Epoch: 762| Step: 0
Training loss: 0.0448337122797966
Validation loss: 1.4744443970341836

Epoch: 5| Step: 1
Training loss: 0.06510338932275772
Validation loss: 1.5086441129766486

Epoch: 5| Step: 2
Training loss: 0.039586376398801804
Validation loss: 1.497038693838222

Epoch: 5| Step: 3
Training loss: 0.039944492280483246
Validation loss: 1.4986523787180583

Epoch: 5| Step: 4
Training loss: 0.043690722435712814
Validation loss: 1.5083875245945428

Epoch: 5| Step: 5
Training loss: 0.04159435257315636
Validation loss: 1.51540704055499

Epoch: 5| Step: 6
Training loss: 0.058569151908159256
Validation loss: 1.5111109787417996

Epoch: 5| Step: 7
Training loss: 0.05286046117544174
Validation loss: 1.5107547121663247

Epoch: 5| Step: 8
Training loss: 0.05954263359308243
Validation loss: 1.5114991613613662

Epoch: 5| Step: 9
Training loss: 0.05023224279284477
Validation loss: 1.5365848566896172

Epoch: 5| Step: 10
Training loss: 0.03547433018684387
Validation loss: 1.5145747020680418

Epoch: 763| Step: 0
Training loss: 0.05043119192123413
Validation loss: 1.5163067643360426

Epoch: 5| Step: 1
Training loss: 0.06169121339917183
Validation loss: 1.5126641642662786

Epoch: 5| Step: 2
Training loss: 0.06552562862634659
Validation loss: 1.5094455903576267

Epoch: 5| Step: 3
Training loss: 0.04715564474463463
Validation loss: 1.5258293151855469

Epoch: 5| Step: 4
Training loss: 0.03994779661297798
Validation loss: 1.5195376424379246

Epoch: 5| Step: 5
Training loss: 0.031723517924547195
Validation loss: 1.4991648889357043

Epoch: 5| Step: 6
Training loss: 0.03699507191777229
Validation loss: 1.5062477300243993

Epoch: 5| Step: 7
Training loss: 0.04203469678759575
Validation loss: 1.5033280990457023

Epoch: 5| Step: 8
Training loss: 0.07585131376981735
Validation loss: 1.4813111430855208

Epoch: 5| Step: 9
Training loss: 0.03071267530322075
Validation loss: 1.4848726475110618

Epoch: 5| Step: 10
Training loss: 0.036066509783267975
Validation loss: 1.4819489243210002

Epoch: 764| Step: 0
Training loss: 0.0553152933716774
Validation loss: 1.4848302737359078

Epoch: 5| Step: 1
Training loss: 0.07108373194932938
Validation loss: 1.498484331433491

Epoch: 5| Step: 2
Training loss: 0.03243213891983032
Validation loss: 1.483577336034467

Epoch: 5| Step: 3
Training loss: 0.04217575490474701
Validation loss: 1.4914298647193498

Epoch: 5| Step: 4
Training loss: 0.04603729397058487
Validation loss: 1.484385746781544

Epoch: 5| Step: 5
Training loss: 0.040230873972177505
Validation loss: 1.5091512623012706

Epoch: 5| Step: 6
Training loss: 0.04266750067472458
Validation loss: 1.4914975384230256

Epoch: 5| Step: 7
Training loss: 0.041070833802223206
Validation loss: 1.5054008396722938

Epoch: 5| Step: 8
Training loss: 0.06133432313799858
Validation loss: 1.474314337135643

Epoch: 5| Step: 9
Training loss: 0.048109471797943115
Validation loss: 1.5150696410927722

Epoch: 5| Step: 10
Training loss: 0.035028815269470215
Validation loss: 1.4979912465618503

Epoch: 765| Step: 0
Training loss: 0.055500589311122894
Validation loss: 1.502355194860889

Epoch: 5| Step: 1
Training loss: 0.032706502825021744
Validation loss: 1.4939015155197473

Epoch: 5| Step: 2
Training loss: 0.031764354556798935
Validation loss: 1.4867494016565301

Epoch: 5| Step: 3
Training loss: 0.037292398512363434
Validation loss: 1.4812484736083655

Epoch: 5| Step: 4
Training loss: 0.03858132287859917
Validation loss: 1.4685668560766405

Epoch: 5| Step: 5
Training loss: 0.03899047523736954
Validation loss: 1.491917431995433

Epoch: 5| Step: 6
Training loss: 0.053061384707689285
Validation loss: 1.4697793940062165

Epoch: 5| Step: 7
Training loss: 0.06704975664615631
Validation loss: 1.4957643606329476

Epoch: 5| Step: 8
Training loss: 0.04285867139697075
Validation loss: 1.4995693211914392

Epoch: 5| Step: 9
Training loss: 0.03216059133410454
Validation loss: 1.5120942528529833

Epoch: 5| Step: 10
Training loss: 0.0393802784383297
Validation loss: 1.5380593358829457

Epoch: 766| Step: 0
Training loss: 0.06607197225093842
Validation loss: 1.538842692811002

Epoch: 5| Step: 1
Training loss: 0.0425979308784008
Validation loss: 1.5242559108682858

Epoch: 5| Step: 2
Training loss: 0.04599594697356224
Validation loss: 1.5156250640910158

Epoch: 5| Step: 3
Training loss: 0.03180883079767227
Validation loss: 1.5171265832839473

Epoch: 5| Step: 4
Training loss: 0.04315859079360962
Validation loss: 1.5019858960182435

Epoch: 5| Step: 5
Training loss: 0.03500626981258392
Validation loss: 1.4983143575729863

Epoch: 5| Step: 6
Training loss: 0.05029059201478958
Validation loss: 1.4904971763651857

Epoch: 5| Step: 7
Training loss: 0.03198273479938507
Validation loss: 1.4972344829190163

Epoch: 5| Step: 8
Training loss: 0.06012413650751114
Validation loss: 1.495515359986213

Epoch: 5| Step: 9
Training loss: 0.03237482160329819
Validation loss: 1.48841526046876

Epoch: 5| Step: 10
Training loss: 0.06397488713264465
Validation loss: 1.4974194803545553

Epoch: 767| Step: 0
Training loss: 0.0486011877655983
Validation loss: 1.4983934612684353

Epoch: 5| Step: 1
Training loss: 0.03868725523352623
Validation loss: 1.4912601876002487

Epoch: 5| Step: 2
Training loss: 0.06737402826547623
Validation loss: 1.4937191188976329

Epoch: 5| Step: 3
Training loss: 0.027117421850562096
Validation loss: 1.5001747057002077

Epoch: 5| Step: 4
Training loss: 0.0457582101225853
Validation loss: 1.4934440864029752

Epoch: 5| Step: 5
Training loss: 0.04648790508508682
Validation loss: 1.5071288142153012

Epoch: 5| Step: 6
Training loss: 0.0583767369389534
Validation loss: 1.4755689879899383

Epoch: 5| Step: 7
Training loss: 0.04365510493516922
Validation loss: 1.5166446816536687

Epoch: 5| Step: 8
Training loss: 0.02489466778934002
Validation loss: 1.4878781713465208

Epoch: 5| Step: 9
Training loss: 0.033860888332128525
Validation loss: 1.4993570927650697

Epoch: 5| Step: 10
Training loss: 0.062430690973997116
Validation loss: 1.4965319620665682

Epoch: 768| Step: 0
Training loss: 0.03484515845775604
Validation loss: 1.507637514862963

Epoch: 5| Step: 1
Training loss: 0.04417729377746582
Validation loss: 1.4678820563900856

Epoch: 5| Step: 2
Training loss: 0.03666801378130913
Validation loss: 1.4948645253335275

Epoch: 5| Step: 3
Training loss: 0.03712975233793259
Validation loss: 1.4830399610662972

Epoch: 5| Step: 4
Training loss: 0.05518918111920357
Validation loss: 1.4756659307787496

Epoch: 5| Step: 5
Training loss: 0.052249014377593994
Validation loss: 1.4855777307223248

Epoch: 5| Step: 6
Training loss: 0.05132105201482773
Validation loss: 1.4854293318204983

Epoch: 5| Step: 7
Training loss: 0.04126263037323952
Validation loss: 1.48545850476911

Epoch: 5| Step: 8
Training loss: 0.05011402815580368
Validation loss: 1.4800450032757175

Epoch: 5| Step: 9
Training loss: 0.04483230039477348
Validation loss: 1.4782070517539978

Epoch: 5| Step: 10
Training loss: 0.06401941925287247
Validation loss: 1.4666619711024786

Epoch: 769| Step: 0
Training loss: 0.056106459349393845
Validation loss: 1.4636571291954286

Epoch: 5| Step: 1
Training loss: 0.04645145684480667
Validation loss: 1.481789683782926

Epoch: 5| Step: 2
Training loss: 0.09202470630407333
Validation loss: 1.505303931492631

Epoch: 5| Step: 3
Training loss: 0.0668654516339302
Validation loss: 1.4774985390324746

Epoch: 5| Step: 4
Training loss: 0.05875181406736374
Validation loss: 1.4830521819412068

Epoch: 5| Step: 5
Training loss: 0.05165816470980644
Validation loss: 1.4869598688617829

Epoch: 5| Step: 6
Training loss: 0.06022563576698303
Validation loss: 1.5091817789180304

Epoch: 5| Step: 7
Training loss: 0.05824778228998184
Validation loss: 1.5006699972255255

Epoch: 5| Step: 8
Training loss: 0.03258133679628372
Validation loss: 1.5256984259492608

Epoch: 5| Step: 9
Training loss: 0.056458957493305206
Validation loss: 1.506222322422971

Epoch: 5| Step: 10
Training loss: 0.06988243013620377
Validation loss: 1.5324378808339436

Epoch: 770| Step: 0
Training loss: 0.07575616240501404
Validation loss: 1.5296069088802542

Epoch: 5| Step: 1
Training loss: 0.05552329868078232
Validation loss: 1.4994172357743787

Epoch: 5| Step: 2
Training loss: 0.047413427382707596
Validation loss: 1.4884087436942643

Epoch: 5| Step: 3
Training loss: 0.07199827581644058
Validation loss: 1.4921464958498556

Epoch: 5| Step: 4
Training loss: 0.06222035735845566
Validation loss: 1.4908647575686056

Epoch: 5| Step: 5
Training loss: 0.056195128709077835
Validation loss: 1.5370929984636204

Epoch: 5| Step: 6
Training loss: 0.0458163321018219
Validation loss: 1.5224309095772364

Epoch: 5| Step: 7
Training loss: 0.08556762337684631
Validation loss: 1.5361118060286327

Epoch: 5| Step: 8
Training loss: 0.05950278043746948
Validation loss: 1.5484676194447342

Epoch: 5| Step: 9
Training loss: 0.04170200973749161
Validation loss: 1.508556382630461

Epoch: 5| Step: 10
Training loss: 0.03329987823963165
Validation loss: 1.499294186151156

Epoch: 771| Step: 0
Training loss: 0.058251820504665375
Validation loss: 1.5085516052861367

Epoch: 5| Step: 1
Training loss: 0.0589674636721611
Validation loss: 1.5108755019403273

Epoch: 5| Step: 2
Training loss: 0.040223054587841034
Validation loss: 1.4896251302893444

Epoch: 5| Step: 3
Training loss: 0.042434174567461014
Validation loss: 1.4985755669173373

Epoch: 5| Step: 4
Training loss: 0.044706083834171295
Validation loss: 1.4658298966705159

Epoch: 5| Step: 5
Training loss: 0.05133765935897827
Validation loss: 1.4930654507811352

Epoch: 5| Step: 6
Training loss: 0.054919976741075516
Validation loss: 1.4944812751585437

Epoch: 5| Step: 7
Training loss: 0.05438830703496933
Validation loss: 1.4790761368249052

Epoch: 5| Step: 8
Training loss: 0.070381760597229
Validation loss: 1.512013211045214

Epoch: 5| Step: 9
Training loss: 0.09545248746871948
Validation loss: 1.5011321934320594

Epoch: 5| Step: 10
Training loss: 0.042120084166526794
Validation loss: 1.4873305001566488

Epoch: 772| Step: 0
Training loss: 0.04917113110423088
Validation loss: 1.4817780884363319

Epoch: 5| Step: 1
Training loss: 0.036822833120822906
Validation loss: 1.5215442834361907

Epoch: 5| Step: 2
Training loss: 0.043836988508701324
Validation loss: 1.494139197052166

Epoch: 5| Step: 3
Training loss: 0.061310090124607086
Validation loss: 1.4748341921837098

Epoch: 5| Step: 4
Training loss: 0.042884472757577896
Validation loss: 1.4747571765735585

Epoch: 5| Step: 5
Training loss: 0.06252908706665039
Validation loss: 1.4768938543975993

Epoch: 5| Step: 6
Training loss: 0.044782012701034546
Validation loss: 1.4421867785915252

Epoch: 5| Step: 7
Training loss: 0.059170544147491455
Validation loss: 1.476971480154222

Epoch: 5| Step: 8
Training loss: 0.05617945268750191
Validation loss: 1.4526432867973083

Epoch: 5| Step: 9
Training loss: 0.034135956317186356
Validation loss: 1.4575555247645224

Epoch: 5| Step: 10
Training loss: 0.044306930154561996
Validation loss: 1.48197728203189

Epoch: 773| Step: 0
Training loss: 0.048448823392391205
Validation loss: 1.4880847075293142

Epoch: 5| Step: 1
Training loss: 0.0462346114218235
Validation loss: 1.5028808142549248

Epoch: 5| Step: 2
Training loss: 0.03694409877061844
Validation loss: 1.4987550268891037

Epoch: 5| Step: 3
Training loss: 0.057092685252428055
Validation loss: 1.4941902865645706

Epoch: 5| Step: 4
Training loss: 0.049101997166872025
Validation loss: 1.4861390321485457

Epoch: 5| Step: 5
Training loss: 0.04640422761440277
Validation loss: 1.4992618227517733

Epoch: 5| Step: 6
Training loss: 0.04609140008687973
Validation loss: 1.4742576370957077

Epoch: 5| Step: 7
Training loss: 0.0478334054350853
Validation loss: 1.4852285987587386

Epoch: 5| Step: 8
Training loss: 0.04813721776008606
Validation loss: 1.5017046813041932

Epoch: 5| Step: 9
Training loss: 0.04315543919801712
Validation loss: 1.4832024285870213

Epoch: 5| Step: 10
Training loss: 0.03928683325648308
Validation loss: 1.4987962861214914

Epoch: 774| Step: 0
Training loss: 0.03910980373620987
Validation loss: 1.47579607143197

Epoch: 5| Step: 1
Training loss: 0.054233331233263016
Validation loss: 1.48084339275155

Epoch: 5| Step: 2
Training loss: 0.02245922014117241
Validation loss: 1.5058726597857732

Epoch: 5| Step: 3
Training loss: 0.05217992514371872
Validation loss: 1.4993073184003112

Epoch: 5| Step: 4
Training loss: 0.06422709673643112
Validation loss: 1.4902305731209375

Epoch: 5| Step: 5
Training loss: 0.05399977043271065
Validation loss: 1.4909435536271782

Epoch: 5| Step: 6
Training loss: 0.036105263978242874
Validation loss: 1.4960656640350178

Epoch: 5| Step: 7
Training loss: 0.05322934314608574
Validation loss: 1.5022381044203235

Epoch: 5| Step: 8
Training loss: 0.04800436645746231
Validation loss: 1.489080773886814

Epoch: 5| Step: 9
Training loss: 0.05739274621009827
Validation loss: 1.4904486210115495

Epoch: 5| Step: 10
Training loss: 0.04162895679473877
Validation loss: 1.5110994885044713

Epoch: 775| Step: 0
Training loss: 0.05773899704217911
Validation loss: 1.4857379941530124

Epoch: 5| Step: 1
Training loss: 0.043847694993019104
Validation loss: 1.4986068176966842

Epoch: 5| Step: 2
Training loss: 0.050022322684526443
Validation loss: 1.4798841937895744

Epoch: 5| Step: 3
Training loss: 0.047652605921030045
Validation loss: 1.4950079469270603

Epoch: 5| Step: 4
Training loss: 0.0758945569396019
Validation loss: 1.497858880668558

Epoch: 5| Step: 5
Training loss: 0.06654850393533707
Validation loss: 1.487462575717639

Epoch: 5| Step: 6
Training loss: 0.042823828756809235
Validation loss: 1.501899891002204

Epoch: 5| Step: 7
Training loss: 0.08054332435131073
Validation loss: 1.499036007030036

Epoch: 5| Step: 8
Training loss: 0.036424845457077026
Validation loss: 1.4877202844107023

Epoch: 5| Step: 9
Training loss: 0.045378427952528
Validation loss: 1.4999262722589637

Epoch: 5| Step: 10
Training loss: 0.03298535570502281
Validation loss: 1.5218792012942735

Epoch: 776| Step: 0
Training loss: 0.07014995813369751
Validation loss: 1.5426745209642636

Epoch: 5| Step: 1
Training loss: 0.06686081737279892
Validation loss: 1.4992471766728226

Epoch: 5| Step: 2
Training loss: 0.037212785333395004
Validation loss: 1.5351053425060806

Epoch: 5| Step: 3
Training loss: 0.03768884390592575
Validation loss: 1.5153284201058008

Epoch: 5| Step: 4
Training loss: 0.049237530678510666
Validation loss: 1.4938289708988641

Epoch: 5| Step: 5
Training loss: 0.034193553030490875
Validation loss: 1.4993384397158058

Epoch: 5| Step: 6
Training loss: 0.05080951005220413
Validation loss: 1.5103397971840316

Epoch: 5| Step: 7
Training loss: 0.04635275527834892
Validation loss: 1.4885300000508626

Epoch: 5| Step: 8
Training loss: 0.049257442355155945
Validation loss: 1.4871307258964868

Epoch: 5| Step: 9
Training loss: 0.059225451201200485
Validation loss: 1.4868658922051872

Epoch: 5| Step: 10
Training loss: 0.043638426810503006
Validation loss: 1.4726335310166883

Epoch: 777| Step: 0
Training loss: 0.048840638250112534
Validation loss: 1.4846168910303423

Epoch: 5| Step: 1
Training loss: 0.04370010644197464
Validation loss: 1.5124317420426237

Epoch: 5| Step: 2
Training loss: 0.0492064468562603
Validation loss: 1.4936187049394012

Epoch: 5| Step: 3
Training loss: 0.056703727692365646
Validation loss: 1.481424371401469

Epoch: 5| Step: 4
Training loss: 0.043912582099437714
Validation loss: 1.4817687555025982

Epoch: 5| Step: 5
Training loss: 0.0480932854115963
Validation loss: 1.4858079982060257

Epoch: 5| Step: 6
Training loss: 0.062314294278621674
Validation loss: 1.4654173133193806

Epoch: 5| Step: 7
Training loss: 0.04021285101771355
Validation loss: 1.4636894413219985

Epoch: 5| Step: 8
Training loss: 0.030236374586820602
Validation loss: 1.4608992043361868

Epoch: 5| Step: 9
Training loss: 0.06967853009700775
Validation loss: 1.4673292495871102

Epoch: 5| Step: 10
Training loss: 0.02524431422352791
Validation loss: 1.4702064298814344

Epoch: 778| Step: 0
Training loss: 0.059462547302246094
Validation loss: 1.4745616169386013

Epoch: 5| Step: 1
Training loss: 0.043590836226940155
Validation loss: 1.4936886833560081

Epoch: 5| Step: 2
Training loss: 0.027565855532884598
Validation loss: 1.4820002189246557

Epoch: 5| Step: 3
Training loss: 0.056845713406801224
Validation loss: 1.4844624560366395

Epoch: 5| Step: 4
Training loss: 0.03330525755882263
Validation loss: 1.504830938513561

Epoch: 5| Step: 5
Training loss: 0.037596311420202255
Validation loss: 1.4932858905484598

Epoch: 5| Step: 6
Training loss: 0.05753452703356743
Validation loss: 1.4872383789349628

Epoch: 5| Step: 7
Training loss: 0.05559704452753067
Validation loss: 1.4868508859347271

Epoch: 5| Step: 8
Training loss: 0.05059302970767021
Validation loss: 1.4809461729500883

Epoch: 5| Step: 9
Training loss: 0.04992218688130379
Validation loss: 1.480772687542823

Epoch: 5| Step: 10
Training loss: 0.03370315209031105
Validation loss: 1.488708003874748

Epoch: 779| Step: 0
Training loss: 0.04099087044596672
Validation loss: 1.4887477377409577

Epoch: 5| Step: 1
Training loss: 0.036595504730939865
Validation loss: 1.4904555351503435

Epoch: 5| Step: 2
Training loss: 0.058359384536743164
Validation loss: 1.5178601395699285

Epoch: 5| Step: 3
Training loss: 0.05229129642248154
Validation loss: 1.4884487377699984

Epoch: 5| Step: 4
Training loss: 0.056383103132247925
Validation loss: 1.5015012192469772

Epoch: 5| Step: 5
Training loss: 0.04478677734732628
Validation loss: 1.5096566125910769

Epoch: 5| Step: 6
Training loss: 0.03871265798807144
Validation loss: 1.5111284204708633

Epoch: 5| Step: 7
Training loss: 0.06734172254800797
Validation loss: 1.5153373659297984

Epoch: 5| Step: 8
Training loss: 0.05209038779139519
Validation loss: 1.499699023462111

Epoch: 5| Step: 9
Training loss: 0.04987543076276779
Validation loss: 1.4855093673993183

Epoch: 5| Step: 10
Training loss: 0.03314630314707756
Validation loss: 1.48933058656672

Epoch: 780| Step: 0
Training loss: 0.03265412524342537
Validation loss: 1.4990097963681785

Epoch: 5| Step: 1
Training loss: 0.025875026360154152
Validation loss: 1.4701337481057772

Epoch: 5| Step: 2
Training loss: 0.03283306583762169
Validation loss: 1.4943241368057907

Epoch: 5| Step: 3
Training loss: 0.0673176571726799
Validation loss: 1.4998958033900107

Epoch: 5| Step: 4
Training loss: 0.055932819843292236
Validation loss: 1.4971358269773505

Epoch: 5| Step: 5
Training loss: 0.04138476774096489
Validation loss: 1.4966153675510037

Epoch: 5| Step: 6
Training loss: 0.05599348619580269
Validation loss: 1.506889074079452

Epoch: 5| Step: 7
Training loss: 0.05614667013287544
Validation loss: 1.5071849233360701

Epoch: 5| Step: 8
Training loss: 0.0349690243601799
Validation loss: 1.4832133952007498

Epoch: 5| Step: 9
Training loss: 0.02641041949391365
Validation loss: 1.4832407389917681

Epoch: 5| Step: 10
Training loss: 0.03971689194440842
Validation loss: 1.487398838484159

Epoch: 781| Step: 0
Training loss: 0.043446291238069534
Validation loss: 1.4739814650627874

Epoch: 5| Step: 1
Training loss: 0.03776613995432854
Validation loss: 1.470188679233674

Epoch: 5| Step: 2
Training loss: 0.023597845807671547
Validation loss: 1.4699269930521648

Epoch: 5| Step: 3
Training loss: 0.025750532746315002
Validation loss: 1.448146850832047

Epoch: 5| Step: 4
Training loss: 0.03900052607059479
Validation loss: 1.4642360261691514

Epoch: 5| Step: 5
Training loss: 0.07052483409643173
Validation loss: 1.4514073941015428

Epoch: 5| Step: 6
Training loss: 0.04838409274816513
Validation loss: 1.4700649963912142

Epoch: 5| Step: 7
Training loss: 0.044457413256168365
Validation loss: 1.4627118110656738

Epoch: 5| Step: 8
Training loss: 0.06051212549209595
Validation loss: 1.4682123135494929

Epoch: 5| Step: 9
Training loss: 0.04091991111636162
Validation loss: 1.4594352911877375

Epoch: 5| Step: 10
Training loss: 0.04100955277681351
Validation loss: 1.4789173808149112

Epoch: 782| Step: 0
Training loss: 0.0542340986430645
Validation loss: 1.4853341451255224

Epoch: 5| Step: 1
Training loss: 0.04737452417612076
Validation loss: 1.4953286211977723

Epoch: 5| Step: 2
Training loss: 0.04226500540971756
Validation loss: 1.490348990245532

Epoch: 5| Step: 3
Training loss: 0.04380562901496887
Validation loss: 1.495805521806081

Epoch: 5| Step: 4
Training loss: 0.04131961986422539
Validation loss: 1.5016754660555112

Epoch: 5| Step: 5
Training loss: 0.055697251111269
Validation loss: 1.496373503438888

Epoch: 5| Step: 6
Training loss: 0.047460492700338364
Validation loss: 1.4545211215173044

Epoch: 5| Step: 7
Training loss: 0.038059499114751816
Validation loss: 1.470860569707809

Epoch: 5| Step: 8
Training loss: 0.03839541971683502
Validation loss: 1.4571547944058654

Epoch: 5| Step: 9
Training loss: 0.03360826522111893
Validation loss: 1.4806970755259197

Epoch: 5| Step: 10
Training loss: 0.06932404637336731
Validation loss: 1.499610589396569

Epoch: 783| Step: 0
Training loss: 0.04533909633755684
Validation loss: 1.5069139285754132

Epoch: 5| Step: 1
Training loss: 0.04971366003155708
Validation loss: 1.4722656229490876

Epoch: 5| Step: 2
Training loss: 0.053417421877384186
Validation loss: 1.4850004193603352

Epoch: 5| Step: 3
Training loss: 0.040721386671066284
Validation loss: 1.4797674109858852

Epoch: 5| Step: 4
Training loss: 0.03676743805408478
Validation loss: 1.4822782124242475

Epoch: 5| Step: 5
Training loss: 0.043260253965854645
Validation loss: 1.4636343525302025

Epoch: 5| Step: 6
Training loss: 0.048926737159490585
Validation loss: 1.4855383442294212

Epoch: 5| Step: 7
Training loss: 0.03312832862138748
Validation loss: 1.4705344041188557

Epoch: 5| Step: 8
Training loss: 0.038863055408000946
Validation loss: 1.467218614393665

Epoch: 5| Step: 9
Training loss: 0.06361491978168488
Validation loss: 1.4757604919454104

Epoch: 5| Step: 10
Training loss: 0.04701143130660057
Validation loss: 1.4739913953247892

Epoch: 784| Step: 0
Training loss: 0.06879488378763199
Validation loss: 1.5006767498549594

Epoch: 5| Step: 1
Training loss: 0.03833144158124924
Validation loss: 1.4631818673943962

Epoch: 5| Step: 2
Training loss: 0.056232113391160965
Validation loss: 1.463870721478616

Epoch: 5| Step: 3
Training loss: 0.043219346553087234
Validation loss: 1.4754852364140172

Epoch: 5| Step: 4
Training loss: 0.0404621846973896
Validation loss: 1.468183672556313

Epoch: 5| Step: 5
Training loss: 0.04731881618499756
Validation loss: 1.4758086140437792

Epoch: 5| Step: 6
Training loss: 0.052328646183013916
Validation loss: 1.4693855662499704

Epoch: 5| Step: 7
Training loss: 0.06660375744104385
Validation loss: 1.467417126060814

Epoch: 5| Step: 8
Training loss: 0.039792921394109726
Validation loss: 1.4699343699280933

Epoch: 5| Step: 9
Training loss: 0.04923892766237259
Validation loss: 1.4580031338558401

Epoch: 5| Step: 10
Training loss: 0.04409198462963104
Validation loss: 1.474572334238278

Epoch: 785| Step: 0
Training loss: 0.04663451761007309
Validation loss: 1.4875568779565955

Epoch: 5| Step: 1
Training loss: 0.04100975766777992
Validation loss: 1.4675883118824293

Epoch: 5| Step: 2
Training loss: 0.07839982956647873
Validation loss: 1.4906588292890979

Epoch: 5| Step: 3
Training loss: 0.040314603596925735
Validation loss: 1.478258623871752

Epoch: 5| Step: 4
Training loss: 0.06067240983247757
Validation loss: 1.4718233385393698

Epoch: 5| Step: 5
Training loss: 0.0512467697262764
Validation loss: 1.4790963421585739

Epoch: 5| Step: 6
Training loss: 0.06431801617145538
Validation loss: 1.4861449041674215

Epoch: 5| Step: 7
Training loss: 0.04812317341566086
Validation loss: 1.4946146562535276

Epoch: 5| Step: 8
Training loss: 0.06321938335895538
Validation loss: 1.5120340098616898

Epoch: 5| Step: 9
Training loss: 0.036637015640735626
Validation loss: 1.4727372424576872

Epoch: 5| Step: 10
Training loss: 0.0713469460606575
Validation loss: 1.4998907927543885

Epoch: 786| Step: 0
Training loss: 0.040767788887023926
Validation loss: 1.4913155699288974

Epoch: 5| Step: 1
Training loss: 0.040337808430194855
Validation loss: 1.462920077385441

Epoch: 5| Step: 2
Training loss: 0.05854281783103943
Validation loss: 1.479217480587703

Epoch: 5| Step: 3
Training loss: 0.03949357196688652
Validation loss: 1.4727853267423567

Epoch: 5| Step: 4
Training loss: 0.04142802581191063
Validation loss: 1.4667257160268805

Epoch: 5| Step: 5
Training loss: 0.07065034657716751
Validation loss: 1.4331424185024795

Epoch: 5| Step: 6
Training loss: 0.05078817158937454
Validation loss: 1.4902248997842111

Epoch: 5| Step: 7
Training loss: 0.055290259420871735
Validation loss: 1.4853381213321482

Epoch: 5| Step: 8
Training loss: 0.07663178443908691
Validation loss: 1.5038251428193943

Epoch: 5| Step: 9
Training loss: 0.04792306199669838
Validation loss: 1.4896009199080928

Epoch: 5| Step: 10
Training loss: 0.03779751434922218
Validation loss: 1.4909576510870328

Epoch: 787| Step: 0
Training loss: 0.041747745126485825
Validation loss: 1.5078738645840717

Epoch: 5| Step: 1
Training loss: 0.04658389091491699
Validation loss: 1.526429021230308

Epoch: 5| Step: 2
Training loss: 0.048329927027225494
Validation loss: 1.5312364614138039

Epoch: 5| Step: 3
Training loss: 0.03760773688554764
Validation loss: 1.5353432675843597

Epoch: 5| Step: 4
Training loss: 0.0476108118891716
Validation loss: 1.543441104632552

Epoch: 5| Step: 5
Training loss: 0.053330279886722565
Validation loss: 1.5044500853425713

Epoch: 5| Step: 6
Training loss: 0.0564332976937294
Validation loss: 1.5223870854223929

Epoch: 5| Step: 7
Training loss: 0.07249877601861954
Validation loss: 1.5007048037744337

Epoch: 5| Step: 8
Training loss: 0.06178675964474678
Validation loss: 1.5116445300399617

Epoch: 5| Step: 9
Training loss: 0.03320913761854172
Validation loss: 1.497630790997577

Epoch: 5| Step: 10
Training loss: 0.05057787895202637
Validation loss: 1.5049646439090851

Epoch: 788| Step: 0
Training loss: 0.03279934078454971
Validation loss: 1.485211144852382

Epoch: 5| Step: 1
Training loss: 0.05848798155784607
Validation loss: 1.4837888351050756

Epoch: 5| Step: 2
Training loss: 0.044379930943250656
Validation loss: 1.4662836546538978

Epoch: 5| Step: 3
Training loss: 0.0464714840054512
Validation loss: 1.481523875267275

Epoch: 5| Step: 4
Training loss: 0.03686533495783806
Validation loss: 1.4914014800902335

Epoch: 5| Step: 5
Training loss: 0.02685651183128357
Validation loss: 1.4851124504561066

Epoch: 5| Step: 6
Training loss: 0.04840552806854248
Validation loss: 1.4674885798526067

Epoch: 5| Step: 7
Training loss: 0.05121016502380371
Validation loss: 1.513929223501554

Epoch: 5| Step: 8
Training loss: 0.05284997075796127
Validation loss: 1.5094126911573513

Epoch: 5| Step: 9
Training loss: 0.056993912905454636
Validation loss: 1.5115504194331426

Epoch: 5| Step: 10
Training loss: 0.03788788989186287
Validation loss: 1.5081103758145404

Epoch: 789| Step: 0
Training loss: 0.03582923486828804
Validation loss: 1.5222394286945302

Epoch: 5| Step: 1
Training loss: 0.03173820301890373
Validation loss: 1.508464745295945

Epoch: 5| Step: 2
Training loss: 0.04348095506429672
Validation loss: 1.5168382134488834

Epoch: 5| Step: 3
Training loss: 0.05481589585542679
Validation loss: 1.5215907148135606

Epoch: 5| Step: 4
Training loss: 0.03528245538473129
Validation loss: 1.503313914422066

Epoch: 5| Step: 5
Training loss: 0.03743830695748329
Validation loss: 1.4937703994012648

Epoch: 5| Step: 6
Training loss: 0.045936841517686844
Validation loss: 1.5148604569896575

Epoch: 5| Step: 7
Training loss: 0.04484943300485611
Validation loss: 1.5178937847896288

Epoch: 5| Step: 8
Training loss: 0.049958597868680954
Validation loss: 1.4928468664487202

Epoch: 5| Step: 9
Training loss: 0.06219370290637016
Validation loss: 1.5000672442938692

Epoch: 5| Step: 10
Training loss: 0.029347160831093788
Validation loss: 1.4776909748713176

Epoch: 790| Step: 0
Training loss: 0.047218382358551025
Validation loss: 1.4858216008832377

Epoch: 5| Step: 1
Training loss: 0.040942274034023285
Validation loss: 1.4866304410401212

Epoch: 5| Step: 2
Training loss: 0.03825453296303749
Validation loss: 1.4766604451722996

Epoch: 5| Step: 3
Training loss: 0.03389664366841316
Validation loss: 1.45507743922613

Epoch: 5| Step: 4
Training loss: 0.045698702335357666
Validation loss: 1.4753369567214802

Epoch: 5| Step: 5
Training loss: 0.04294661432504654
Validation loss: 1.4709404540318314

Epoch: 5| Step: 6
Training loss: 0.04601076990365982
Validation loss: 1.462324277047188

Epoch: 5| Step: 7
Training loss: 0.04196213185787201
Validation loss: 1.451192759698437

Epoch: 5| Step: 8
Training loss: 0.05224703624844551
Validation loss: 1.4490859662332842

Epoch: 5| Step: 9
Training loss: 0.04956874996423721
Validation loss: 1.4645244395861061

Epoch: 5| Step: 10
Training loss: 0.0677882507443428
Validation loss: 1.4495692547931467

Epoch: 791| Step: 0
Training loss: 0.032413549721241
Validation loss: 1.4622819013493036

Epoch: 5| Step: 1
Training loss: 0.055423349142074585
Validation loss: 1.4461728039608206

Epoch: 5| Step: 2
Training loss: 0.030442362651228905
Validation loss: 1.4617822259984992

Epoch: 5| Step: 3
Training loss: 0.0449211560189724
Validation loss: 1.4764818978565994

Epoch: 5| Step: 4
Training loss: 0.05062277242541313
Validation loss: 1.4717715401803293

Epoch: 5| Step: 5
Training loss: 0.07468203455209732
Validation loss: 1.471480219594894

Epoch: 5| Step: 6
Training loss: 0.04281042888760567
Validation loss: 1.4800970092896493

Epoch: 5| Step: 7
Training loss: 0.03961338847875595
Validation loss: 1.4592681431001233

Epoch: 5| Step: 8
Training loss: 0.04265453666448593
Validation loss: 1.4754868732985629

Epoch: 5| Step: 9
Training loss: 0.0595722496509552
Validation loss: 1.4915417823740231

Epoch: 5| Step: 10
Training loss: 0.03338221088051796
Validation loss: 1.4833834850659935

Epoch: 792| Step: 0
Training loss: 0.0377700999379158
Validation loss: 1.488165610580034

Epoch: 5| Step: 1
Training loss: 0.053356509655714035
Validation loss: 1.498853547598726

Epoch: 5| Step: 2
Training loss: 0.048379626125097275
Validation loss: 1.5113133230516989

Epoch: 5| Step: 3
Training loss: 0.07386408001184464
Validation loss: 1.5104500773132488

Epoch: 5| Step: 4
Training loss: 0.03111128881573677
Validation loss: 1.4816546760579592

Epoch: 5| Step: 5
Training loss: 0.06029500439763069
Validation loss: 1.4778155947244296

Epoch: 5| Step: 6
Training loss: 0.040659088641405106
Validation loss: 1.474516963446012

Epoch: 5| Step: 7
Training loss: 0.0338347889482975
Validation loss: 1.4549709135486233

Epoch: 5| Step: 8
Training loss: 0.05556405335664749
Validation loss: 1.4649583383273053

Epoch: 5| Step: 9
Training loss: 0.05246018245816231
Validation loss: 1.457675330100521

Epoch: 5| Step: 10
Training loss: 0.03784976899623871
Validation loss: 1.4599485365293359

Epoch: 793| Step: 0
Training loss: 0.04084036871790886
Validation loss: 1.4681860631512058

Epoch: 5| Step: 1
Training loss: 0.04768221825361252
Validation loss: 1.4902751240679013

Epoch: 5| Step: 2
Training loss: 0.0307976845651865
Validation loss: 1.506843864276845

Epoch: 5| Step: 3
Training loss: 0.046934887766838074
Validation loss: 1.5111556886344828

Epoch: 5| Step: 4
Training loss: 0.0348329022526741
Validation loss: 1.5109263004795197

Epoch: 5| Step: 5
Training loss: 0.045460719615221024
Validation loss: 1.513162462942062

Epoch: 5| Step: 6
Training loss: 0.0625341534614563
Validation loss: 1.4984389863988405

Epoch: 5| Step: 7
Training loss: 0.042214345186948776
Validation loss: 1.519166636210616

Epoch: 5| Step: 8
Training loss: 0.043877292424440384
Validation loss: 1.4893239172556068

Epoch: 5| Step: 9
Training loss: 0.050340913236141205
Validation loss: 1.5039218920533375

Epoch: 5| Step: 10
Training loss: 0.05380313843488693
Validation loss: 1.4664577995577166

Epoch: 794| Step: 0
Training loss: 0.06722889840602875
Validation loss: 1.4704036123009139

Epoch: 5| Step: 1
Training loss: 0.06917045265436172
Validation loss: 1.4910405848615913

Epoch: 5| Step: 2
Training loss: 0.04092198610305786
Validation loss: 1.4571405828640025

Epoch: 5| Step: 3
Training loss: 0.04639919102191925
Validation loss: 1.4670117721762708

Epoch: 5| Step: 4
Training loss: 0.04800308868288994
Validation loss: 1.463294002317613

Epoch: 5| Step: 5
Training loss: 0.049743928015232086
Validation loss: 1.4734429479927145

Epoch: 5| Step: 6
Training loss: 0.044620685279369354
Validation loss: 1.5002762784240067

Epoch: 5| Step: 7
Training loss: 0.045726221054792404
Validation loss: 1.5169952351559874

Epoch: 5| Step: 8
Training loss: 0.05954626202583313
Validation loss: 1.4997378421086136

Epoch: 5| Step: 9
Training loss: 0.07759016007184982
Validation loss: 1.4994496773648005

Epoch: 5| Step: 10
Training loss: 0.023727677762508392
Validation loss: 1.495071970006471

Epoch: 795| Step: 0
Training loss: 0.048230111598968506
Validation loss: 1.5021708793537591

Epoch: 5| Step: 1
Training loss: 0.04302331060171127
Validation loss: 1.5068906693048374

Epoch: 5| Step: 2
Training loss: 0.042577940970659256
Validation loss: 1.4747651994869273

Epoch: 5| Step: 3
Training loss: 0.04119713976979256
Validation loss: 1.4885379832278016

Epoch: 5| Step: 4
Training loss: 0.042825233191251755
Validation loss: 1.499625531576013

Epoch: 5| Step: 5
Training loss: 0.047616127878427505
Validation loss: 1.4617200948858773

Epoch: 5| Step: 6
Training loss: 0.055902160704135895
Validation loss: 1.4844051432865921

Epoch: 5| Step: 7
Training loss: 0.03821888566017151
Validation loss: 1.475485614551011

Epoch: 5| Step: 8
Training loss: 0.04372021555900574
Validation loss: 1.4933612474831202

Epoch: 5| Step: 9
Training loss: 0.04814290255308151
Validation loss: 1.4882747345073248

Epoch: 5| Step: 10
Training loss: 0.058311548084020615
Validation loss: 1.4790263445146623

Epoch: 796| Step: 0
Training loss: 0.03229234740138054
Validation loss: 1.463898665161543

Epoch: 5| Step: 1
Training loss: 0.0372360423207283
Validation loss: 1.4871616773707892

Epoch: 5| Step: 2
Training loss: 0.05005452781915665
Validation loss: 1.4686627182909238

Epoch: 5| Step: 3
Training loss: 0.0439351424574852
Validation loss: 1.4817527077531303

Epoch: 5| Step: 4
Training loss: 0.01743929460644722
Validation loss: 1.4735651964782386

Epoch: 5| Step: 5
Training loss: 0.048286665230989456
Validation loss: 1.4806144622064406

Epoch: 5| Step: 6
Training loss: 0.04184938967227936
Validation loss: 1.482190324414161

Epoch: 5| Step: 7
Training loss: 0.04801519215106964
Validation loss: 1.4685462033876808

Epoch: 5| Step: 8
Training loss: 0.06493818759918213
Validation loss: 1.4772238603202246

Epoch: 5| Step: 9
Training loss: 0.03359648585319519
Validation loss: 1.476769660108833

Epoch: 5| Step: 10
Training loss: 0.03662319853901863
Validation loss: 1.4979268645727506

Epoch: 797| Step: 0
Training loss: 0.027287578210234642
Validation loss: 1.4952616979998927

Epoch: 5| Step: 1
Training loss: 0.03738357871770859
Validation loss: 1.4965238301984725

Epoch: 5| Step: 2
Training loss: 0.07654678076505661
Validation loss: 1.498797324395949

Epoch: 5| Step: 3
Training loss: 0.03544687107205391
Validation loss: 1.49279526997638

Epoch: 5| Step: 4
Training loss: 0.056995175778865814
Validation loss: 1.4907572089984853

Epoch: 5| Step: 5
Training loss: 0.02699987031519413
Validation loss: 1.493232222013576

Epoch: 5| Step: 6
Training loss: 0.03053189441561699
Validation loss: 1.5061306261247205

Epoch: 5| Step: 7
Training loss: 0.039766114205121994
Validation loss: 1.5224380787982736

Epoch: 5| Step: 8
Training loss: 0.06287826597690582
Validation loss: 1.5205082867735176

Epoch: 5| Step: 9
Training loss: 0.04933980852365494
Validation loss: 1.520551162381326

Epoch: 5| Step: 10
Training loss: 0.048091888427734375
Validation loss: 1.5019568986790155

Epoch: 798| Step: 0
Training loss: 0.06157275289297104
Validation loss: 1.5377417789992465

Epoch: 5| Step: 1
Training loss: 0.03153199702501297
Validation loss: 1.513158328430627

Epoch: 5| Step: 2
Training loss: 0.045247633010149
Validation loss: 1.507929653249761

Epoch: 5| Step: 3
Training loss: 0.05655667930841446
Validation loss: 1.4927783640482093

Epoch: 5| Step: 4
Training loss: 0.033811792731285095
Validation loss: 1.4896612949268793

Epoch: 5| Step: 5
Training loss: 0.0769955962896347
Validation loss: 1.46902419418417

Epoch: 5| Step: 6
Training loss: 0.04433821141719818
Validation loss: 1.4764391536353736

Epoch: 5| Step: 7
Training loss: 0.07143326103687286
Validation loss: 1.4558728292424192

Epoch: 5| Step: 8
Training loss: 0.04688498377799988
Validation loss: 1.45759202331625

Epoch: 5| Step: 9
Training loss: 0.05188196897506714
Validation loss: 1.4489379749503186

Epoch: 5| Step: 10
Training loss: 0.03933697193861008
Validation loss: 1.4466282911198114

Epoch: 799| Step: 0
Training loss: 0.04224614053964615
Validation loss: 1.4587254062775643

Epoch: 5| Step: 1
Training loss: 0.06328830868005753
Validation loss: 1.476881830923019

Epoch: 5| Step: 2
Training loss: 0.07830290496349335
Validation loss: 1.4604089798465851

Epoch: 5| Step: 3
Training loss: 0.04627138748764992
Validation loss: 1.4601015301160916

Epoch: 5| Step: 4
Training loss: 0.0583389587700367
Validation loss: 1.4667890238505539

Epoch: 5| Step: 5
Training loss: 0.05363427847623825
Validation loss: 1.4695588927115164

Epoch: 5| Step: 6
Training loss: 0.059776246547698975
Validation loss: 1.4614665303179013

Epoch: 5| Step: 7
Training loss: 0.0514032244682312
Validation loss: 1.4594620658505348

Epoch: 5| Step: 8
Training loss: 0.045210108160972595
Validation loss: 1.455485713097357

Epoch: 5| Step: 9
Training loss: 0.028765806928277016
Validation loss: 1.4527405410684564

Epoch: 5| Step: 10
Training loss: 0.0360049307346344
Validation loss: 1.4444915697138796

Epoch: 800| Step: 0
Training loss: 0.036311060190200806
Validation loss: 1.4703814605230927

Epoch: 5| Step: 1
Training loss: 0.032170943915843964
Validation loss: 1.4520032264853036

Epoch: 5| Step: 2
Training loss: 0.04521780461072922
Validation loss: 1.4437729235618346

Epoch: 5| Step: 3
Training loss: 0.05416066199541092
Validation loss: 1.4577953418095906

Epoch: 5| Step: 4
Training loss: 0.04078267142176628
Validation loss: 1.442777951558431

Epoch: 5| Step: 5
Training loss: 0.04650047421455383
Validation loss: 1.4761443779032717

Epoch: 5| Step: 6
Training loss: 0.0559215247631073
Validation loss: 1.4744558065168318

Epoch: 5| Step: 7
Training loss: 0.04454401880502701
Validation loss: 1.472257238562389

Epoch: 5| Step: 8
Training loss: 0.035353176295757294
Validation loss: 1.5024148648785007

Epoch: 5| Step: 9
Training loss: 0.032331667840480804
Validation loss: 1.485951054480768

Epoch: 5| Step: 10
Training loss: 0.046447765082120895
Validation loss: 1.5047925749132711

Testing loss: 2.1473266416125827
