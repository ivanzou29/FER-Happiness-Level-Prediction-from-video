Epoch: 1| Step: 0
Training loss: 5.067682266235352
Validation loss: 5.210633580402662

Epoch: 5| Step: 1
Training loss: 5.066442012786865
Validation loss: 5.198778055047476

Epoch: 5| Step: 2
Training loss: 5.158234596252441
Validation loss: 5.186221040705199

Epoch: 5| Step: 3
Training loss: 5.481273174285889
Validation loss: 5.172066129663939

Epoch: 5| Step: 4
Training loss: 4.880722999572754
Validation loss: 5.155418580578219

Epoch: 5| Step: 5
Training loss: 4.4815239906311035
Validation loss: 5.136182379978959

Epoch: 5| Step: 6
Training loss: 4.725240230560303
Validation loss: 5.1139243392534155

Epoch: 5| Step: 7
Training loss: 4.711063385009766
Validation loss: 5.088673317304221

Epoch: 5| Step: 8
Training loss: 4.3224029541015625
Validation loss: 5.059461034754271

Epoch: 5| Step: 9
Training loss: 4.518240928649902
Validation loss: 5.027375841653475

Epoch: 5| Step: 10
Training loss: 5.809931755065918
Validation loss: 4.99062567885204

Epoch: 2| Step: 0
Training loss: 4.772253513336182
Validation loss: 4.949646867731566

Epoch: 5| Step: 1
Training loss: 4.568626403808594
Validation loss: 4.904951926200621

Epoch: 5| Step: 2
Training loss: 4.9626641273498535
Validation loss: 4.855468165489935

Epoch: 5| Step: 3
Training loss: 4.675682067871094
Validation loss: 4.804319689350743

Epoch: 5| Step: 4
Training loss: 4.169865131378174
Validation loss: 4.747678797732117

Epoch: 5| Step: 5
Training loss: 4.521252155303955
Validation loss: 4.691602471054241

Epoch: 5| Step: 6
Training loss: 3.9466986656188965
Validation loss: 4.634898324166575

Epoch: 5| Step: 7
Training loss: 4.583091735839844
Validation loss: 4.577804996121314

Epoch: 5| Step: 8
Training loss: 4.452853202819824
Validation loss: 4.521093353148429

Epoch: 5| Step: 9
Training loss: 4.944357872009277
Validation loss: 4.462507560688962

Epoch: 5| Step: 10
Training loss: 3.462752103805542
Validation loss: 4.401961993145687

Epoch: 3| Step: 0
Training loss: 5.111254692077637
Validation loss: 4.342958614390383

Epoch: 5| Step: 1
Training loss: 3.723891496658325
Validation loss: 4.2775383508333595

Epoch: 5| Step: 2
Training loss: 3.7888762950897217
Validation loss: 4.212756279976137

Epoch: 5| Step: 3
Training loss: 4.268474578857422
Validation loss: 4.1495813400514665

Epoch: 5| Step: 4
Training loss: 2.296743869781494
Validation loss: 4.088583894955215

Epoch: 5| Step: 5
Training loss: 4.237934589385986
Validation loss: 4.037152592853833

Epoch: 5| Step: 6
Training loss: 2.668330192565918
Validation loss: 3.991351758280108

Epoch: 5| Step: 7
Training loss: 6.160242557525635
Validation loss: 3.9505499306545464

Epoch: 5| Step: 8
Training loss: 3.390450954437256
Validation loss: 3.9132755033431517

Epoch: 5| Step: 9
Training loss: 4.217825889587402
Validation loss: 3.877928408243323

Epoch: 5| Step: 10
Training loss: 2.987828254699707
Validation loss: 3.847093100188881

Epoch: 4| Step: 0
Training loss: 2.9462413787841797
Validation loss: 3.8209198239029094

Epoch: 5| Step: 1
Training loss: 3.657433032989502
Validation loss: 3.796430254495272

Epoch: 5| Step: 2
Training loss: 3.099003314971924
Validation loss: 3.776610435978059

Epoch: 5| Step: 3
Training loss: 3.4731850624084473
Validation loss: 3.760045418175318

Epoch: 5| Step: 4
Training loss: 3.5021462440490723
Validation loss: 3.7439848325585805

Epoch: 5| Step: 5
Training loss: 3.6959221363067627
Validation loss: 3.7275667754552697

Epoch: 5| Step: 6
Training loss: 3.2507262229919434
Validation loss: 3.7119714624138287

Epoch: 5| Step: 7
Training loss: 4.812069892883301
Validation loss: 3.693350330475838

Epoch: 5| Step: 8
Training loss: 3.6196670532226562
Validation loss: 3.6717289211929485

Epoch: 5| Step: 9
Training loss: 3.8319880962371826
Validation loss: 3.6567687526825936

Epoch: 5| Step: 10
Training loss: 4.047730445861816
Validation loss: 3.645130093379687

Epoch: 5| Step: 0
Training loss: 4.153170585632324
Validation loss: 3.625116845612885

Epoch: 5| Step: 1
Training loss: 3.8801727294921875
Validation loss: 3.6074975075260287

Epoch: 5| Step: 2
Training loss: 3.1410202980041504
Validation loss: 3.600561603423088

Epoch: 5| Step: 3
Training loss: 3.227461338043213
Validation loss: 3.5909456642725135

Epoch: 5| Step: 4
Training loss: 2.776883602142334
Validation loss: 3.5813016532569804

Epoch: 5| Step: 5
Training loss: 3.446977138519287
Validation loss: 3.5698545107277493

Epoch: 5| Step: 6
Training loss: 4.636502742767334
Validation loss: 3.5569287141164145

Epoch: 5| Step: 7
Training loss: 3.8310863971710205
Validation loss: 3.5442002614339194

Epoch: 5| Step: 8
Training loss: 3.0254852771759033
Validation loss: 3.5335663364779566

Epoch: 5| Step: 9
Training loss: 3.5533859729766846
Validation loss: 3.525608806199925

Epoch: 5| Step: 10
Training loss: 2.653341293334961
Validation loss: 3.5185295022943968

Epoch: 6| Step: 0
Training loss: 3.028036594390869
Validation loss: 3.5293293153086016

Epoch: 5| Step: 1
Training loss: 3.0479187965393066
Validation loss: 3.5046585016353156

Epoch: 5| Step: 2
Training loss: 3.9026031494140625
Validation loss: 3.4882041485078874

Epoch: 5| Step: 3
Training loss: 4.120228290557861
Validation loss: 3.478397318111953

Epoch: 5| Step: 4
Training loss: 3.580418109893799
Validation loss: 3.4649017574966594

Epoch: 5| Step: 5
Training loss: 3.1177544593811035
Validation loss: 3.448102056339223

Epoch: 5| Step: 6
Training loss: 2.7307209968566895
Validation loss: 3.4431833272339194

Epoch: 5| Step: 7
Training loss: 3.5901451110839844
Validation loss: 3.4270987843954437

Epoch: 5| Step: 8
Training loss: 3.7929673194885254
Validation loss: 3.412131024945167

Epoch: 5| Step: 9
Training loss: 3.5613365173339844
Validation loss: 3.3984282401300248

Epoch: 5| Step: 10
Training loss: 2.7530879974365234
Validation loss: 3.3857824289670555

Epoch: 7| Step: 0
Training loss: 4.318985939025879
Validation loss: 3.371906252317531

Epoch: 5| Step: 1
Training loss: 3.14897084236145
Validation loss: 3.3589313927517144

Epoch: 5| Step: 2
Training loss: 3.176805257797241
Validation loss: 3.3289691504611763

Epoch: 5| Step: 3
Training loss: 3.4109673500061035
Validation loss: 3.3124359423114407

Epoch: 5| Step: 4
Training loss: 3.614396333694458
Validation loss: 3.2989297195147445

Epoch: 5| Step: 5
Training loss: 3.3701815605163574
Validation loss: 3.2862707184207056

Epoch: 5| Step: 6
Training loss: 2.935084104537964
Validation loss: 3.262927888542093

Epoch: 5| Step: 7
Training loss: 3.239255428314209
Validation loss: 3.253250270761469

Epoch: 5| Step: 8
Training loss: 3.0486228466033936
Validation loss: 3.248239735121368

Epoch: 5| Step: 9
Training loss: 2.991206169128418
Validation loss: 3.231907929143598

Epoch: 5| Step: 10
Training loss: 2.5778770446777344
Validation loss: 3.2204349271712767

Epoch: 8| Step: 0
Training loss: 2.744579792022705
Validation loss: 3.221303483491303

Epoch: 5| Step: 1
Training loss: 3.5412955284118652
Validation loss: 3.2022665777514057

Epoch: 5| Step: 2
Training loss: 3.2589828968048096
Validation loss: 3.204670067756407

Epoch: 5| Step: 3
Training loss: 2.8961880207061768
Validation loss: 3.1842280741660827

Epoch: 5| Step: 4
Training loss: 3.1506876945495605
Validation loss: 3.1786901233016804

Epoch: 5| Step: 5
Training loss: 2.8104605674743652
Validation loss: 3.170853373824909

Epoch: 5| Step: 6
Training loss: 3.744668483734131
Validation loss: 3.164816810238746

Epoch: 5| Step: 7
Training loss: 3.5551822185516357
Validation loss: 3.1577272184433474

Epoch: 5| Step: 8
Training loss: 3.029613733291626
Validation loss: 3.151496897461594

Epoch: 5| Step: 9
Training loss: 3.522153854370117
Validation loss: 3.132910907909434

Epoch: 5| Step: 10
Training loss: 2.627988338470459
Validation loss: 3.141673667456514

Epoch: 9| Step: 0
Training loss: 2.6054978370666504
Validation loss: 3.1610120342623804

Epoch: 5| Step: 1
Training loss: 3.531313419342041
Validation loss: 3.1229141322515344

Epoch: 5| Step: 2
Training loss: 2.4605939388275146
Validation loss: 3.125467018414569

Epoch: 5| Step: 3
Training loss: 3.4797744750976562
Validation loss: 3.1585548795679563

Epoch: 5| Step: 4
Training loss: 2.8447365760803223
Validation loss: 3.1701443426070677

Epoch: 5| Step: 5
Training loss: 3.9662563800811768
Validation loss: 3.1270802687573176

Epoch: 5| Step: 6
Training loss: 2.6121158599853516
Validation loss: 3.1252462966467744

Epoch: 5| Step: 7
Training loss: 2.979611873626709
Validation loss: 3.1287573358064056

Epoch: 5| Step: 8
Training loss: 3.7012248039245605
Validation loss: 3.1268315571610645

Epoch: 5| Step: 9
Training loss: 3.48799204826355
Validation loss: 3.1190735319609284

Epoch: 5| Step: 10
Training loss: 3.0144011974334717
Validation loss: 3.1136244932810464

Epoch: 10| Step: 0
Training loss: 3.333636522293091
Validation loss: 3.1091115807974212

Epoch: 5| Step: 1
Training loss: 3.1441264152526855
Validation loss: 3.106171715644098

Epoch: 5| Step: 2
Training loss: 3.001671552658081
Validation loss: 3.1004632480682863

Epoch: 5| Step: 3
Training loss: 2.652942657470703
Validation loss: 3.092455079478602

Epoch: 5| Step: 4
Training loss: 3.4336814880371094
Validation loss: 3.0886153559530936

Epoch: 5| Step: 5
Training loss: 3.996387481689453
Validation loss: 3.0736774398434545

Epoch: 5| Step: 6
Training loss: 2.8392066955566406
Validation loss: 3.064507479308754

Epoch: 5| Step: 7
Training loss: 3.6015594005584717
Validation loss: 3.0556294994969524

Epoch: 5| Step: 8
Training loss: 3.038349151611328
Validation loss: 3.0483981127380044

Epoch: 5| Step: 9
Training loss: 2.7797179222106934
Validation loss: 3.0460816301325315

Epoch: 5| Step: 10
Training loss: 2.339592695236206
Validation loss: 3.037284879274266

Epoch: 11| Step: 0
Training loss: 3.5895252227783203
Validation loss: 3.0383763377384474

Epoch: 5| Step: 1
Training loss: 3.3071951866149902
Validation loss: 3.0324109959345993

Epoch: 5| Step: 2
Training loss: 3.6632227897644043
Validation loss: 3.029639933698921

Epoch: 5| Step: 3
Training loss: 2.898165464401245
Validation loss: 3.0220202425474763

Epoch: 5| Step: 4
Training loss: 2.8188416957855225
Validation loss: 3.0160490466702368

Epoch: 5| Step: 5
Training loss: 3.021501064300537
Validation loss: 3.0136609359454085

Epoch: 5| Step: 6
Training loss: 2.43291974067688
Validation loss: 3.010079106976909

Epoch: 5| Step: 7
Training loss: 3.1434850692749023
Validation loss: 3.0087223411888204

Epoch: 5| Step: 8
Training loss: 3.262350559234619
Validation loss: 3.0100167951276227

Epoch: 5| Step: 9
Training loss: 2.80535888671875
Validation loss: 3.006147220570554

Epoch: 5| Step: 10
Training loss: 2.848355293273926
Validation loss: 3.004579826067853

Epoch: 12| Step: 0
Training loss: 3.237814426422119
Validation loss: 2.9987638842674995

Epoch: 5| Step: 1
Training loss: 3.0576417446136475
Validation loss: 2.9954060995450584

Epoch: 5| Step: 2
Training loss: 3.0671608448028564
Validation loss: 2.9919834418963362

Epoch: 5| Step: 3
Training loss: 3.1422441005706787
Validation loss: 2.987074080333915

Epoch: 5| Step: 4
Training loss: 3.198543071746826
Validation loss: 2.9876203947169806

Epoch: 5| Step: 5
Training loss: 2.322167158126831
Validation loss: 2.986738238283383

Epoch: 5| Step: 6
Training loss: 2.942936420440674
Validation loss: 2.993590539501559

Epoch: 5| Step: 7
Training loss: 4.2314066886901855
Validation loss: 3.017629454212804

Epoch: 5| Step: 8
Training loss: 2.656642198562622
Validation loss: 2.9805976395965903

Epoch: 5| Step: 9
Training loss: 2.6396970748901367
Validation loss: 2.985009131893035

Epoch: 5| Step: 10
Training loss: 3.1962807178497314
Validation loss: 2.9933454990386963

Epoch: 13| Step: 0
Training loss: 3.8063712120056152
Validation loss: 2.990709166372976

Epoch: 5| Step: 1
Training loss: 2.2920966148376465
Validation loss: 2.9762345052534536

Epoch: 5| Step: 2
Training loss: 2.860321521759033
Validation loss: 2.972862599998392

Epoch: 5| Step: 3
Training loss: 3.1222457885742188
Validation loss: 2.9701382703678583

Epoch: 5| Step: 4
Training loss: 3.68463397026062
Validation loss: 2.965290936090613

Epoch: 5| Step: 5
Training loss: 3.588759183883667
Validation loss: 2.9563550487641366

Epoch: 5| Step: 6
Training loss: 2.77510142326355
Validation loss: 2.944170667279151

Epoch: 5| Step: 7
Training loss: 2.9332327842712402
Validation loss: 2.9475875977546937

Epoch: 5| Step: 8
Training loss: 3.334825038909912
Validation loss: 2.9451563845398607

Epoch: 5| Step: 9
Training loss: 2.7899527549743652
Validation loss: 2.936799262159614

Epoch: 5| Step: 10
Training loss: 2.0670595169067383
Validation loss: 2.93462134176685

Epoch: 14| Step: 0
Training loss: 3.72407865524292
Validation loss: 2.927952758727535

Epoch: 5| Step: 1
Training loss: 3.3426353931427
Validation loss: 2.9264273540948027

Epoch: 5| Step: 2
Training loss: 2.9764888286590576
Validation loss: 2.9250869007520777

Epoch: 5| Step: 3
Training loss: 2.816582202911377
Validation loss: 2.9258597179125716

Epoch: 5| Step: 4
Training loss: 3.4461658000946045
Validation loss: 2.9239254279803206

Epoch: 5| Step: 5
Training loss: 2.7042393684387207
Validation loss: 2.9182777994422504

Epoch: 5| Step: 6
Training loss: 2.8496811389923096
Validation loss: 2.9138871290350474

Epoch: 5| Step: 7
Training loss: 2.92441725730896
Validation loss: 2.916320093216435

Epoch: 5| Step: 8
Training loss: 2.871387004852295
Validation loss: 2.915387445880521

Epoch: 5| Step: 9
Training loss: 2.0428359508514404
Validation loss: 2.915137847264608

Epoch: 5| Step: 10
Training loss: 3.5226383209228516
Validation loss: 2.9141874005717616

Epoch: 15| Step: 0
Training loss: 3.0613389015197754
Validation loss: 2.9112093038456415

Epoch: 5| Step: 1
Training loss: 2.6406545639038086
Validation loss: 2.906590200239612

Epoch: 5| Step: 2
Training loss: 2.779560089111328
Validation loss: 2.905374585941274

Epoch: 5| Step: 3
Training loss: 3.5037758350372314
Validation loss: 2.901625315348307

Epoch: 5| Step: 4
Training loss: 2.835998058319092
Validation loss: 2.9025535198949997

Epoch: 5| Step: 5
Training loss: 2.722043514251709
Validation loss: 2.9027348743971957

Epoch: 5| Step: 6
Training loss: 3.5007271766662598
Validation loss: 2.90407209755272

Epoch: 5| Step: 7
Training loss: 3.6428005695343018
Validation loss: 2.9019161552511235

Epoch: 5| Step: 8
Training loss: 2.6419010162353516
Validation loss: 2.9026302752956266

Epoch: 5| Step: 9
Training loss: 2.538067579269409
Validation loss: 2.9009295304616294

Epoch: 5| Step: 10
Training loss: 3.160038709640503
Validation loss: 2.8996127792584

Epoch: 16| Step: 0
Training loss: 2.2236990928649902
Validation loss: 2.8942165682392735

Epoch: 5| Step: 1
Training loss: 3.554354190826416
Validation loss: 2.8946331239515737

Epoch: 5| Step: 2
Training loss: 3.088954448699951
Validation loss: 2.8966352349968365

Epoch: 5| Step: 3
Training loss: 3.2610583305358887
Validation loss: 2.8905979741004204

Epoch: 5| Step: 4
Training loss: 1.9762513637542725
Validation loss: 2.885900956328197

Epoch: 5| Step: 5
Training loss: 3.2252914905548096
Validation loss: 2.8815583900738786

Epoch: 5| Step: 6
Training loss: 2.7518603801727295
Validation loss: 2.8804405914839877

Epoch: 5| Step: 7
Training loss: 3.497223377227783
Validation loss: 2.8824213166390695

Epoch: 5| Step: 8
Training loss: 3.227519989013672
Validation loss: 2.8813120216451664

Epoch: 5| Step: 9
Training loss: 2.9617953300476074
Validation loss: 2.8782480891032884

Epoch: 5| Step: 10
Training loss: 3.108743667602539
Validation loss: 2.8746604150341404

Epoch: 17| Step: 0
Training loss: 2.5712122917175293
Validation loss: 2.8705559289583595

Epoch: 5| Step: 1
Training loss: 3.0124733448028564
Validation loss: 2.8698533170966694

Epoch: 5| Step: 2
Training loss: 2.3096375465393066
Validation loss: 2.868726107382005

Epoch: 5| Step: 3
Training loss: 3.1371617317199707
Validation loss: 2.8681319195737123

Epoch: 5| Step: 4
Training loss: 2.948237895965576
Validation loss: 2.8759840919125463

Epoch: 5| Step: 5
Training loss: 2.8333115577697754
Validation loss: 2.8754588147645355

Epoch: 5| Step: 6
Training loss: 3.4632492065429688
Validation loss: 2.872253361568656

Epoch: 5| Step: 7
Training loss: 3.04740834236145
Validation loss: 2.870083039806735

Epoch: 5| Step: 8
Training loss: 2.5971028804779053
Validation loss: 2.86527245788164

Epoch: 5| Step: 9
Training loss: 3.2606265544891357
Validation loss: 2.860541030924807

Epoch: 5| Step: 10
Training loss: 3.6671040058135986
Validation loss: 2.8621649152489117

Epoch: 18| Step: 0
Training loss: 2.8940556049346924
Validation loss: 2.860617137724353

Epoch: 5| Step: 1
Training loss: 2.9878056049346924
Validation loss: 2.8558032358846357

Epoch: 5| Step: 2
Training loss: 2.322209119796753
Validation loss: 2.855280381377025

Epoch: 5| Step: 3
Training loss: 2.960484743118286
Validation loss: 2.8542241357987925

Epoch: 5| Step: 4
Training loss: 3.0825843811035156
Validation loss: 2.855908493841848

Epoch: 5| Step: 5
Training loss: 2.698497772216797
Validation loss: 2.850082782007033

Epoch: 5| Step: 6
Training loss: 2.847158908843994
Validation loss: 2.8535146867075274

Epoch: 5| Step: 7
Training loss: 3.151292085647583
Validation loss: 2.8506573989827144

Epoch: 5| Step: 8
Training loss: 3.612611770629883
Validation loss: 2.849247770924722

Epoch: 5| Step: 9
Training loss: 2.433232545852661
Validation loss: 2.8501018042205484

Epoch: 5| Step: 10
Training loss: 3.718193292617798
Validation loss: 2.8460716098867436

Epoch: 19| Step: 0
Training loss: 3.3874714374542236
Validation loss: 2.8461847356570664

Epoch: 5| Step: 1
Training loss: 3.011904716491699
Validation loss: 2.8434641258690947

Epoch: 5| Step: 2
Training loss: 3.3620810508728027
Validation loss: 2.8437049414521907

Epoch: 5| Step: 3
Training loss: 3.153233051300049
Validation loss: 2.8427147326930875

Epoch: 5| Step: 4
Training loss: 3.170332193374634
Validation loss: 2.8455657164255777

Epoch: 5| Step: 5
Training loss: 3.3922271728515625
Validation loss: 2.8488375602229947

Epoch: 5| Step: 6
Training loss: 2.7075066566467285
Validation loss: 2.8577128123211604

Epoch: 5| Step: 7
Training loss: 2.912384510040283
Validation loss: 2.8666871722026537

Epoch: 5| Step: 8
Training loss: 2.7313551902770996
Validation loss: 2.8610169438905615

Epoch: 5| Step: 9
Training loss: 2.267322540283203
Validation loss: 2.8531119644000964

Epoch: 5| Step: 10
Training loss: 2.354992151260376
Validation loss: 2.8405618821420977

Epoch: 20| Step: 0
Training loss: 3.0112478733062744
Validation loss: 2.837200467304517

Epoch: 5| Step: 1
Training loss: 2.5809292793273926
Validation loss: 2.8442534554389214

Epoch: 5| Step: 2
Training loss: 2.6238417625427246
Validation loss: 2.8557547292401715

Epoch: 5| Step: 3
Training loss: 2.671332836151123
Validation loss: 2.839260026972781

Epoch: 5| Step: 4
Training loss: 2.876000165939331
Validation loss: 2.8468928003823883

Epoch: 5| Step: 5
Training loss: 3.0796337127685547
Validation loss: 2.8436269939586682

Epoch: 5| Step: 6
Training loss: 3.2267673015594482
Validation loss: 2.8366182106797413

Epoch: 5| Step: 7
Training loss: 2.8011817932128906
Validation loss: 2.8312261771130305

Epoch: 5| Step: 8
Training loss: 2.0678884983062744
Validation loss: 2.8389787622677383

Epoch: 5| Step: 9
Training loss: 3.757668972015381
Validation loss: 2.858705638557352

Epoch: 5| Step: 10
Training loss: 3.987276077270508
Validation loss: 2.8434099766515915

Epoch: 21| Step: 0
Training loss: 2.9240167140960693
Validation loss: 2.8339132493542087

Epoch: 5| Step: 1
Training loss: 2.705718517303467
Validation loss: 2.8280555843025126

Epoch: 5| Step: 2
Training loss: 3.0605132579803467
Validation loss: 2.826903802092357

Epoch: 5| Step: 3
Training loss: 2.8932652473449707
Validation loss: 2.8280401537495274

Epoch: 5| Step: 4
Training loss: 2.68733549118042
Validation loss: 2.8279650313879854

Epoch: 5| Step: 5
Training loss: 3.3670654296875
Validation loss: 2.824915442415463

Epoch: 5| Step: 6
Training loss: 2.68009614944458
Validation loss: 2.825467817244991

Epoch: 5| Step: 7
Training loss: 3.545485734939575
Validation loss: 2.822921314547139

Epoch: 5| Step: 8
Training loss: 2.6043002605438232
Validation loss: 2.8217020573154574

Epoch: 5| Step: 9
Training loss: 2.5271944999694824
Validation loss: 2.8213348824490785

Epoch: 5| Step: 10
Training loss: 3.5043797492980957
Validation loss: 2.821835051300705

Epoch: 22| Step: 0
Training loss: 2.8274521827697754
Validation loss: 2.8217842296887468

Epoch: 5| Step: 1
Training loss: 2.4476962089538574
Validation loss: 2.8230423030032905

Epoch: 5| Step: 2
Training loss: 2.9546425342559814
Validation loss: 2.8213703657991145

Epoch: 5| Step: 3
Training loss: 2.909148693084717
Validation loss: 2.8147034850171817

Epoch: 5| Step: 4
Training loss: 3.466778516769409
Validation loss: 2.8146263296886156

Epoch: 5| Step: 5
Training loss: 2.9878177642822266
Validation loss: 2.8152857826602076

Epoch: 5| Step: 6
Training loss: 2.653250217437744
Validation loss: 2.8154488712228756

Epoch: 5| Step: 7
Training loss: 3.047675609588623
Validation loss: 2.8150949708877073

Epoch: 5| Step: 8
Training loss: 3.312222719192505
Validation loss: 2.815585888842101

Epoch: 5| Step: 9
Training loss: 2.7525484561920166
Validation loss: 2.812093791141305

Epoch: 5| Step: 10
Training loss: 2.9184999465942383
Validation loss: 2.814932423253213

Epoch: 23| Step: 0
Training loss: 2.9245784282684326
Validation loss: 2.8122241471403386

Epoch: 5| Step: 1
Training loss: 3.394064426422119
Validation loss: 2.805684704934397

Epoch: 5| Step: 2
Training loss: 2.776639461517334
Validation loss: 2.8156860541271906

Epoch: 5| Step: 3
Training loss: 2.9701037406921387
Validation loss: 2.809345004379108

Epoch: 5| Step: 4
Training loss: 2.82694935798645
Validation loss: 2.810080564150246

Epoch: 5| Step: 5
Training loss: 2.5977492332458496
Validation loss: 2.806567884260608

Epoch: 5| Step: 6
Training loss: 2.5571177005767822
Validation loss: 2.8048891328996226

Epoch: 5| Step: 7
Training loss: 3.338784694671631
Validation loss: 2.798512963838475

Epoch: 5| Step: 8
Training loss: 3.0173563957214355
Validation loss: 2.794543625206076

Epoch: 5| Step: 9
Training loss: 2.765817165374756
Validation loss: 2.7926718393961587

Epoch: 5| Step: 10
Training loss: 3.003918170928955
Validation loss: 2.796681232349847

Epoch: 24| Step: 0
Training loss: 2.8983917236328125
Validation loss: 2.79343686052548

Epoch: 5| Step: 1
Training loss: 2.446568489074707
Validation loss: 2.791819062284244

Epoch: 5| Step: 2
Training loss: 3.400886058807373
Validation loss: 2.788963028179702

Epoch: 5| Step: 3
Training loss: 2.819013833999634
Validation loss: 2.789056872808805

Epoch: 5| Step: 4
Training loss: 2.4670865535736084
Validation loss: 2.785712580527029

Epoch: 5| Step: 5
Training loss: 3.4199318885803223
Validation loss: 2.785386500820037

Epoch: 5| Step: 6
Training loss: 4.028563022613525
Validation loss: 2.785340614216302

Epoch: 5| Step: 7
Training loss: 3.1323559284210205
Validation loss: 2.784386868117958

Epoch: 5| Step: 8
Training loss: 3.2719993591308594
Validation loss: 2.7841875117312194

Epoch: 5| Step: 9
Training loss: 2.1879680156707764
Validation loss: 2.7846309549065045

Epoch: 5| Step: 10
Training loss: 1.8095619678497314
Validation loss: 2.7838797902548187

Epoch: 25| Step: 0
Training loss: 3.5278778076171875
Validation loss: 2.7932773636233423

Epoch: 5| Step: 1
Training loss: 2.2335734367370605
Validation loss: 2.8153433902289278

Epoch: 5| Step: 2
Training loss: 3.314289093017578
Validation loss: 2.8836301680534118

Epoch: 5| Step: 3
Training loss: 2.6643855571746826
Validation loss: 2.8341183944415023

Epoch: 5| Step: 4
Training loss: 3.167891025543213
Validation loss: 2.7942652599785918

Epoch: 5| Step: 5
Training loss: 3.1930978298187256
Validation loss: 2.784621356635965

Epoch: 5| Step: 6
Training loss: 3.1372389793395996
Validation loss: 2.793109796380484

Epoch: 5| Step: 7
Training loss: 3.5538010597229004
Validation loss: 2.7891479358878186

Epoch: 5| Step: 8
Training loss: 2.3864502906799316
Validation loss: 2.787763339216991

Epoch: 5| Step: 9
Training loss: 2.2907814979553223
Validation loss: 2.816638628641764

Epoch: 5| Step: 10
Training loss: 2.8622074127197266
Validation loss: 2.856732263359972

Epoch: 26| Step: 0
Training loss: 2.8861019611358643
Validation loss: 2.8092077188594367

Epoch: 5| Step: 1
Training loss: 2.858757495880127
Validation loss: 2.7899393984066543

Epoch: 5| Step: 2
Training loss: 3.321881055831909
Validation loss: 2.783287348285798

Epoch: 5| Step: 3
Training loss: 2.2955875396728516
Validation loss: 2.7786024642247025

Epoch: 5| Step: 4
Training loss: 2.5288443565368652
Validation loss: 2.782391819902646

Epoch: 5| Step: 5
Training loss: 3.636606216430664
Validation loss: 2.7812258146142446

Epoch: 5| Step: 6
Training loss: 3.3168137073516846
Validation loss: 2.7787971394036406

Epoch: 5| Step: 7
Training loss: 2.996968984603882
Validation loss: 2.777156135087372

Epoch: 5| Step: 8
Training loss: 2.3966469764709473
Validation loss: 2.7783928814754693

Epoch: 5| Step: 9
Training loss: 3.6212334632873535
Validation loss: 2.7751640478769937

Epoch: 5| Step: 10
Training loss: 1.9735307693481445
Validation loss: 2.7756210424566783

Epoch: 27| Step: 0
Training loss: 2.350641965866089
Validation loss: 2.7786353377885717

Epoch: 5| Step: 1
Training loss: 3.366558790206909
Validation loss: 2.7731775519668416

Epoch: 5| Step: 2
Training loss: 2.8251523971557617
Validation loss: 2.7714552520423807

Epoch: 5| Step: 3
Training loss: 2.421966314315796
Validation loss: 2.766626642596337

Epoch: 5| Step: 4
Training loss: 2.841825246810913
Validation loss: 2.7673526528061076

Epoch: 5| Step: 5
Training loss: 2.6387743949890137
Validation loss: 2.7619115973031647

Epoch: 5| Step: 6
Training loss: 2.7270491123199463
Validation loss: 2.763312114182339

Epoch: 5| Step: 7
Training loss: 2.7519421577453613
Validation loss: 2.7626130068173973

Epoch: 5| Step: 8
Training loss: 3.243093967437744
Validation loss: 2.7626146654928885

Epoch: 5| Step: 9
Training loss: 3.067180871963501
Validation loss: 2.761809205496183

Epoch: 5| Step: 10
Training loss: 3.768890857696533
Validation loss: 2.7594271423996135

Epoch: 28| Step: 0
Training loss: 2.9021477699279785
Validation loss: 2.758960131675966

Epoch: 5| Step: 1
Training loss: 2.8543624877929688
Validation loss: 2.7601151825279318

Epoch: 5| Step: 2
Training loss: 2.6103923320770264
Validation loss: 2.758803790615451

Epoch: 5| Step: 3
Training loss: 3.235307216644287
Validation loss: 2.758983628724211

Epoch: 5| Step: 4
Training loss: 3.290076494216919
Validation loss: 2.7602348686546407

Epoch: 5| Step: 5
Training loss: 2.9083569049835205
Validation loss: 2.7612328580630723

Epoch: 5| Step: 6
Training loss: 2.10412335395813
Validation loss: 2.761325200398763

Epoch: 5| Step: 7
Training loss: 3.036172866821289
Validation loss: 2.7590471057481665

Epoch: 5| Step: 8
Training loss: 2.8060526847839355
Validation loss: 2.760365357962988

Epoch: 5| Step: 9
Training loss: 3.54868745803833
Validation loss: 2.755478569256362

Epoch: 5| Step: 10
Training loss: 2.398627281188965
Validation loss: 2.7534691056897564

Epoch: 29| Step: 0
Training loss: 3.465482711791992
Validation loss: 2.751976748948456

Epoch: 5| Step: 1
Training loss: 3.2868645191192627
Validation loss: 2.7506439326911845

Epoch: 5| Step: 2
Training loss: 2.902512550354004
Validation loss: 2.748938580994965

Epoch: 5| Step: 3
Training loss: 2.5084547996520996
Validation loss: 2.7474880936325237

Epoch: 5| Step: 4
Training loss: 3.40846586227417
Validation loss: 2.749719783823977

Epoch: 5| Step: 5
Training loss: 3.016594409942627
Validation loss: 2.749543318184473

Epoch: 5| Step: 6
Training loss: 1.8491966724395752
Validation loss: 2.7476816664459887

Epoch: 5| Step: 7
Training loss: 2.174320697784424
Validation loss: 2.7464347295863654

Epoch: 5| Step: 8
Training loss: 2.2112314701080322
Validation loss: 2.7462977747763357

Epoch: 5| Step: 9
Training loss: 3.486387252807617
Validation loss: 2.7459073066711426

Epoch: 5| Step: 10
Training loss: 3.4959163665771484
Validation loss: 2.7449860418996503

Epoch: 30| Step: 0
Training loss: 3.056438446044922
Validation loss: 2.745427413653302

Epoch: 5| Step: 1
Training loss: 2.511032819747925
Validation loss: 2.743763703171925

Epoch: 5| Step: 2
Training loss: 2.340280055999756
Validation loss: 2.7432044244581655

Epoch: 5| Step: 3
Training loss: 2.5127503871917725
Validation loss: 2.747124315589987

Epoch: 5| Step: 4
Training loss: 2.6961042881011963
Validation loss: 2.7425041660185783

Epoch: 5| Step: 5
Training loss: 3.187563896179199
Validation loss: 2.73984041008898

Epoch: 5| Step: 6
Training loss: 2.660893201828003
Validation loss: 2.7370796690705004

Epoch: 5| Step: 7
Training loss: 4.003506660461426
Validation loss: 2.7357076547479116

Epoch: 5| Step: 8
Training loss: 3.0313632488250732
Validation loss: 2.7374968836384435

Epoch: 5| Step: 9
Training loss: 2.864530324935913
Validation loss: 2.7366725526830202

Epoch: 5| Step: 10
Training loss: 2.7502379417419434
Validation loss: 2.738859622709213

Epoch: 31| Step: 0
Training loss: 3.549147367477417
Validation loss: 2.737782314259519

Epoch: 5| Step: 1
Training loss: 2.801755905151367
Validation loss: 2.7403856579975416

Epoch: 5| Step: 2
Training loss: 3.5510287284851074
Validation loss: 2.7338015494808072

Epoch: 5| Step: 3
Training loss: 2.998241901397705
Validation loss: 2.7324964589970087

Epoch: 5| Step: 4
Training loss: 3.3149142265319824
Validation loss: 2.735196949333273

Epoch: 5| Step: 5
Training loss: 2.3883697986602783
Validation loss: 2.7343608845946608

Epoch: 5| Step: 6
Training loss: 2.6531636714935303
Validation loss: 2.735258307508243

Epoch: 5| Step: 7
Training loss: 2.0632877349853516
Validation loss: 2.7384587462230394

Epoch: 5| Step: 8
Training loss: 3.4304091930389404
Validation loss: 2.7402100870686192

Epoch: 5| Step: 9
Training loss: 1.9550790786743164
Validation loss: 2.7370933819842596

Epoch: 5| Step: 10
Training loss: 2.8887970447540283
Validation loss: 2.736598012267902

Epoch: 32| Step: 0
Training loss: 3.1639657020568848
Validation loss: 2.730331536262266

Epoch: 5| Step: 1
Training loss: 2.893807888031006
Validation loss: 2.731634465597009

Epoch: 5| Step: 2
Training loss: 2.952578067779541
Validation loss: 2.72849226767017

Epoch: 5| Step: 3
Training loss: 2.600457191467285
Validation loss: 2.727526746770387

Epoch: 5| Step: 4
Training loss: 2.9912185668945312
Validation loss: 2.7266905512861026

Epoch: 5| Step: 5
Training loss: 3.1320390701293945
Validation loss: 2.7244890095085226

Epoch: 5| Step: 6
Training loss: 2.575197696685791
Validation loss: 2.732250375132407

Epoch: 5| Step: 7
Training loss: 2.606663465499878
Validation loss: 2.739680092821839

Epoch: 5| Step: 8
Training loss: 2.9084668159484863
Validation loss: 2.740685934661537

Epoch: 5| Step: 9
Training loss: 2.7165520191192627
Validation loss: 2.730210204278269

Epoch: 5| Step: 10
Training loss: 2.9413607120513916
Validation loss: 2.7234934581223356

Epoch: 33| Step: 0
Training loss: 1.858511209487915
Validation loss: 2.71941481098052

Epoch: 5| Step: 1
Training loss: 3.1361916065216064
Validation loss: 2.7192643739843882

Epoch: 5| Step: 2
Training loss: 3.543505907058716
Validation loss: 2.718840194004838

Epoch: 5| Step: 3
Training loss: 2.395010232925415
Validation loss: 2.7167043121912147

Epoch: 5| Step: 4
Training loss: 2.69765567779541
Validation loss: 2.715313160291282

Epoch: 5| Step: 5
Training loss: 3.069561719894409
Validation loss: 2.7183940692614486

Epoch: 5| Step: 6
Training loss: 2.444758653640747
Validation loss: 2.720255159562634

Epoch: 5| Step: 7
Training loss: 3.040100574493408
Validation loss: 2.7161273212843042

Epoch: 5| Step: 8
Training loss: 2.9792988300323486
Validation loss: 2.7136155251533753

Epoch: 5| Step: 9
Training loss: 3.2441248893737793
Validation loss: 2.7127899700595486

Epoch: 5| Step: 10
Training loss: 2.993354320526123
Validation loss: 2.7111247149846887

Epoch: 34| Step: 0
Training loss: 2.5923609733581543
Validation loss: 2.7131835952881844

Epoch: 5| Step: 1
Training loss: 2.6873669624328613
Validation loss: 2.7102416279495403

Epoch: 5| Step: 2
Training loss: 2.679874897003174
Validation loss: 2.709172921795999

Epoch: 5| Step: 3
Training loss: 3.0890774726867676
Validation loss: 2.7093118980366695

Epoch: 5| Step: 4
Training loss: 2.6474573612213135
Validation loss: 2.708247400099231

Epoch: 5| Step: 5
Training loss: 3.032073497772217
Validation loss: 2.70720499561679

Epoch: 5| Step: 6
Training loss: 2.46181583404541
Validation loss: 2.709798989757415

Epoch: 5| Step: 7
Training loss: 2.9005820751190186
Validation loss: 2.712221642976166

Epoch: 5| Step: 8
Training loss: 3.4249587059020996
Validation loss: 2.7046456336975098

Epoch: 5| Step: 9
Training loss: 2.924755811691284
Validation loss: 2.7041746775309243

Epoch: 5| Step: 10
Training loss: 2.8817341327667236
Validation loss: 2.7027773395661385

Epoch: 35| Step: 0
Training loss: 3.2817935943603516
Validation loss: 2.700397665782641

Epoch: 5| Step: 1
Training loss: 3.473043918609619
Validation loss: 2.7024051938005673

Epoch: 5| Step: 2
Training loss: 3.2641830444335938
Validation loss: 2.701094647889496

Epoch: 5| Step: 3
Training loss: 3.6959826946258545
Validation loss: 2.7063032555323776

Epoch: 5| Step: 4
Training loss: 3.201539993286133
Validation loss: 2.7040615543242423

Epoch: 5| Step: 5
Training loss: 2.7624077796936035
Validation loss: 2.7057019818213677

Epoch: 5| Step: 6
Training loss: 2.3582491874694824
Validation loss: 2.701732845716579

Epoch: 5| Step: 7
Training loss: 2.6177005767822266
Validation loss: 2.6997002991296912

Epoch: 5| Step: 8
Training loss: 2.386540412902832
Validation loss: 2.6962445807713333

Epoch: 5| Step: 9
Training loss: 1.7926231622695923
Validation loss: 2.69497864220732

Epoch: 5| Step: 10
Training loss: 2.2370097637176514
Validation loss: 2.6918664875850884

Epoch: 36| Step: 0
Training loss: 3.5783982276916504
Validation loss: 2.6926711938714467

Epoch: 5| Step: 1
Training loss: 2.997589588165283
Validation loss: 2.6916551718147854

Epoch: 5| Step: 2
Training loss: 2.7023816108703613
Validation loss: 2.692712512067569

Epoch: 5| Step: 3
Training loss: 2.464585065841675
Validation loss: 2.6948832952848045

Epoch: 5| Step: 4
Training loss: 3.5455710887908936
Validation loss: 2.7037425502654044

Epoch: 5| Step: 5
Training loss: 2.872833728790283
Validation loss: 2.7127675035948395

Epoch: 5| Step: 6
Training loss: 2.3319146633148193
Validation loss: 2.719911052334693

Epoch: 5| Step: 7
Training loss: 2.6056768894195557
Validation loss: 2.7249674386875604

Epoch: 5| Step: 8
Training loss: 2.402503252029419
Validation loss: 2.7318195143053607

Epoch: 5| Step: 9
Training loss: 2.6515703201293945
Validation loss: 2.7782673425571893

Epoch: 5| Step: 10
Training loss: 3.16127872467041
Validation loss: 2.811434443278979

Epoch: 37| Step: 0
Training loss: 3.310166835784912
Validation loss: 2.807876912496423

Epoch: 5| Step: 1
Training loss: 2.865377426147461
Validation loss: 2.737161867080196

Epoch: 5| Step: 2
Training loss: 2.5130209922790527
Validation loss: 2.7045116668106406

Epoch: 5| Step: 3
Training loss: 2.4571340084075928
Validation loss: 2.711116511334655

Epoch: 5| Step: 4
Training loss: 3.3082191944122314
Validation loss: 2.765092808713195

Epoch: 5| Step: 5
Training loss: 3.3303451538085938
Validation loss: 2.721361021841726

Epoch: 5| Step: 6
Training loss: 2.8156371116638184
Validation loss: 2.6925776953338296

Epoch: 5| Step: 7
Training loss: 2.3476576805114746
Validation loss: 2.693856221373363

Epoch: 5| Step: 8
Training loss: 3.0843029022216797
Validation loss: 2.686956674821915

Epoch: 5| Step: 9
Training loss: 2.7575175762176514
Validation loss: 2.690564017142019

Epoch: 5| Step: 10
Training loss: 2.547478199005127
Validation loss: 2.7012986034475346

Epoch: 38| Step: 0
Training loss: 2.6956546306610107
Validation loss: 2.709217520170314

Epoch: 5| Step: 1
Training loss: 2.426316022872925
Validation loss: 2.7077312674573673

Epoch: 5| Step: 2
Training loss: 2.407785415649414
Validation loss: 2.7245723611565045

Epoch: 5| Step: 3
Training loss: 3.6318252086639404
Validation loss: 2.7408186133189867

Epoch: 5| Step: 4
Training loss: 2.632610559463501
Validation loss: 2.7240760557113157

Epoch: 5| Step: 5
Training loss: 2.790853977203369
Validation loss: 2.6948803060798237

Epoch: 5| Step: 6
Training loss: 2.3493432998657227
Validation loss: 2.6785230457141833

Epoch: 5| Step: 7
Training loss: 3.501319169998169
Validation loss: 2.6727361602167927

Epoch: 5| Step: 8
Training loss: 2.630526304244995
Validation loss: 2.677806738884218

Epoch: 5| Step: 9
Training loss: 2.797553539276123
Validation loss: 2.682812588189238

Epoch: 5| Step: 10
Training loss: 3.3386058807373047
Validation loss: 2.685791859062769

Epoch: 39| Step: 0
Training loss: 3.2493882179260254
Validation loss: 2.6898095479575534

Epoch: 5| Step: 1
Training loss: 2.01243257522583
Validation loss: 2.686272713445848

Epoch: 5| Step: 2
Training loss: 2.3854644298553467
Validation loss: 2.686059800527429

Epoch: 5| Step: 3
Training loss: 3.3447184562683105
Validation loss: 2.696840486218852

Epoch: 5| Step: 4
Training loss: 2.2908411026000977
Validation loss: 2.6753535373236543

Epoch: 5| Step: 5
Training loss: 2.7259280681610107
Validation loss: 2.672226094430493

Epoch: 5| Step: 6
Training loss: 2.4796736240386963
Validation loss: 2.685605741316272

Epoch: 5| Step: 7
Training loss: 3.7255806922912598
Validation loss: 2.713196077654439

Epoch: 5| Step: 8
Training loss: 3.115844488143921
Validation loss: 2.720276068615657

Epoch: 5| Step: 9
Training loss: 2.679311513900757
Validation loss: 2.6918907447527816

Epoch: 5| Step: 10
Training loss: 3.1786742210388184
Validation loss: 2.682731064417029

Epoch: 40| Step: 0
Training loss: 2.007384777069092
Validation loss: 2.6787991446833455

Epoch: 5| Step: 1
Training loss: 3.4778316020965576
Validation loss: 2.6760639093255483

Epoch: 5| Step: 2
Training loss: 3.2782135009765625
Validation loss: 2.6759444129082466

Epoch: 5| Step: 3
Training loss: 2.4273617267608643
Validation loss: 2.6630663435946227

Epoch: 5| Step: 4
Training loss: 3.2292685508728027
Validation loss: 2.658655605008525

Epoch: 5| Step: 5
Training loss: 3.3401272296905518
Validation loss: 2.659896263512232

Epoch: 5| Step: 6
Training loss: 2.3656725883483887
Validation loss: 2.657209534798899

Epoch: 5| Step: 7
Training loss: 2.7465317249298096
Validation loss: 2.659051743886804

Epoch: 5| Step: 8
Training loss: 2.688180446624756
Validation loss: 2.657856213149204

Epoch: 5| Step: 9
Training loss: 2.7541775703430176
Validation loss: 2.655993269335839

Epoch: 5| Step: 10
Training loss: 2.5648257732391357
Validation loss: 2.656639188848516

Epoch: 41| Step: 0
Training loss: 3.135234832763672
Validation loss: 2.6583255080766577

Epoch: 5| Step: 1
Training loss: 2.8472797870635986
Validation loss: 2.661209080808906

Epoch: 5| Step: 2
Training loss: 2.0847113132476807
Validation loss: 2.6611737282045427

Epoch: 5| Step: 3
Training loss: 3.0210070610046387
Validation loss: 2.6600356178898967

Epoch: 5| Step: 4
Training loss: 3.086733818054199
Validation loss: 2.661873394443143

Epoch: 5| Step: 5
Training loss: 2.590869188308716
Validation loss: 2.66031837719743

Epoch: 5| Step: 6
Training loss: 2.8077707290649414
Validation loss: 2.6536359402441208

Epoch: 5| Step: 7
Training loss: 3.5434508323669434
Validation loss: 2.6445192675436697

Epoch: 5| Step: 8
Training loss: 2.0490124225616455
Validation loss: 2.643843550835886

Epoch: 5| Step: 9
Training loss: 2.4716315269470215
Validation loss: 2.6481908316253335

Epoch: 5| Step: 10
Training loss: 3.251349687576294
Validation loss: 2.6533507634234685

Epoch: 42| Step: 0
Training loss: 2.432830333709717
Validation loss: 2.6498180153549358

Epoch: 5| Step: 1
Training loss: 2.7402138710021973
Validation loss: 2.647992836531772

Epoch: 5| Step: 2
Training loss: 3.091423511505127
Validation loss: 2.6421694447917323

Epoch: 5| Step: 3
Training loss: 2.8175957202911377
Validation loss: 2.6438254335875153

Epoch: 5| Step: 4
Training loss: 2.4292399883270264
Validation loss: 2.641018639328659

Epoch: 5| Step: 5
Training loss: 3.239987850189209
Validation loss: 2.6407122868363575

Epoch: 5| Step: 6
Training loss: 3.2377922534942627
Validation loss: 2.6383238915474183

Epoch: 5| Step: 7
Training loss: 3.1353390216827393
Validation loss: 2.6388738463001866

Epoch: 5| Step: 8
Training loss: 2.043393611907959
Validation loss: 2.6378918488820395

Epoch: 5| Step: 9
Training loss: 2.726656436920166
Validation loss: 2.635915205042849

Epoch: 5| Step: 10
Training loss: 2.8834023475646973
Validation loss: 2.6345559909779537

Epoch: 43| Step: 0
Training loss: 3.1852450370788574
Validation loss: 2.639281672816123

Epoch: 5| Step: 1
Training loss: 2.257965087890625
Validation loss: 2.6418555859596498

Epoch: 5| Step: 2
Training loss: 3.015953540802002
Validation loss: 2.6442726683873

Epoch: 5| Step: 3
Training loss: 2.0917434692382812
Validation loss: 2.6510045451502644

Epoch: 5| Step: 4
Training loss: 2.5531005859375
Validation loss: 2.6634729421266945

Epoch: 5| Step: 5
Training loss: 2.337582588195801
Validation loss: 2.6571384655532015

Epoch: 5| Step: 6
Training loss: 3.1001534461975098
Validation loss: 2.642815802686958

Epoch: 5| Step: 7
Training loss: 3.0191097259521484
Validation loss: 2.6375103483917894

Epoch: 5| Step: 8
Training loss: 3.1386327743530273
Validation loss: 2.6361105800956808

Epoch: 5| Step: 9
Training loss: 2.637444496154785
Validation loss: 2.632157874363725

Epoch: 5| Step: 10
Training loss: 3.4703102111816406
Validation loss: 2.6320035944702806

Epoch: 44| Step: 0
Training loss: 2.191462755203247
Validation loss: 2.632028595093758

Epoch: 5| Step: 1
Training loss: 2.6914682388305664
Validation loss: 2.6287182095230266

Epoch: 5| Step: 2
Training loss: 2.6254661083221436
Validation loss: 2.628348619707169

Epoch: 5| Step: 3
Training loss: 3.2392477989196777
Validation loss: 2.625778603297408

Epoch: 5| Step: 4
Training loss: 2.320746898651123
Validation loss: 2.6238324719090618

Epoch: 5| Step: 5
Training loss: 3.0425076484680176
Validation loss: 2.6261767213062575

Epoch: 5| Step: 6
Training loss: 2.4237122535705566
Validation loss: 2.629587168334633

Epoch: 5| Step: 7
Training loss: 2.7398266792297363
Validation loss: 2.6247702388353247

Epoch: 5| Step: 8
Training loss: 3.5650100708007812
Validation loss: 2.625936485105945

Epoch: 5| Step: 9
Training loss: 3.0264649391174316
Validation loss: 2.6240834497636363

Epoch: 5| Step: 10
Training loss: 2.7591986656188965
Validation loss: 2.6253898759042062

Epoch: 45| Step: 0
Training loss: 2.040632724761963
Validation loss: 2.615507738564604

Epoch: 5| Step: 1
Training loss: 2.519756555557251
Validation loss: 2.614889398697884

Epoch: 5| Step: 2
Training loss: 3.22802472114563
Validation loss: 2.6148156273749565

Epoch: 5| Step: 3
Training loss: 3.206763505935669
Validation loss: 2.6135986722925657

Epoch: 5| Step: 4
Training loss: 3.4178307056427
Validation loss: 2.611140786960561

Epoch: 5| Step: 5
Training loss: 2.5172619819641113
Validation loss: 2.613318302298105

Epoch: 5| Step: 6
Training loss: 2.2659881114959717
Validation loss: 2.6077398536025838

Epoch: 5| Step: 7
Training loss: 3.1279008388519287
Validation loss: 2.6185196138197377

Epoch: 5| Step: 8
Training loss: 2.923064708709717
Validation loss: 2.6177372009523454

Epoch: 5| Step: 9
Training loss: 2.4040629863739014
Validation loss: 2.6246304460751113

Epoch: 5| Step: 10
Training loss: 2.920745372772217
Validation loss: 2.6237221071797032

Epoch: 46| Step: 0
Training loss: 2.7536749839782715
Validation loss: 2.616546574459281

Epoch: 5| Step: 1
Training loss: 2.4925484657287598
Validation loss: 2.608683893757482

Epoch: 5| Step: 2
Training loss: 3.2109596729278564
Validation loss: 2.6099395700680312

Epoch: 5| Step: 3
Training loss: 2.136674642562866
Validation loss: 2.6124139985730572

Epoch: 5| Step: 4
Training loss: 2.6683127880096436
Validation loss: 2.6151719067686345

Epoch: 5| Step: 5
Training loss: 2.469562292098999
Validation loss: 2.6161903745384625

Epoch: 5| Step: 6
Training loss: 3.0691332817077637
Validation loss: 2.6164564599273024

Epoch: 5| Step: 7
Training loss: 2.419574499130249
Validation loss: 2.6147109590550905

Epoch: 5| Step: 8
Training loss: 3.1963601112365723
Validation loss: 2.6132211890271915

Epoch: 5| Step: 9
Training loss: 3.046268939971924
Validation loss: 2.610357351200555

Epoch: 5| Step: 10
Training loss: 3.162635564804077
Validation loss: 2.6077722375110914

Epoch: 47| Step: 0
Training loss: 2.760366916656494
Validation loss: 2.6076036525029007

Epoch: 5| Step: 1
Training loss: 3.137676239013672
Validation loss: 2.6020153696819017

Epoch: 5| Step: 2
Training loss: 2.7849631309509277
Validation loss: 2.60018426628523

Epoch: 5| Step: 3
Training loss: 2.8144001960754395
Validation loss: 2.600501298904419

Epoch: 5| Step: 4
Training loss: 2.752746105194092
Validation loss: 2.6078394689867572

Epoch: 5| Step: 5
Training loss: 2.6688003540039062
Validation loss: 2.62061063192224

Epoch: 5| Step: 6
Training loss: 2.5758233070373535
Validation loss: 2.613379893764373

Epoch: 5| Step: 7
Training loss: 2.5366628170013428
Validation loss: 2.6135379024731216

Epoch: 5| Step: 8
Training loss: 2.330876111984253
Validation loss: 2.6041896215049167

Epoch: 5| Step: 9
Training loss: 3.4390902519226074
Validation loss: 2.5963889116881997

Epoch: 5| Step: 10
Training loss: 2.637113571166992
Validation loss: 2.5976770641983196

Epoch: 48| Step: 0
Training loss: 3.0381617546081543
Validation loss: 2.595159125584428

Epoch: 5| Step: 1
Training loss: 2.6360669136047363
Validation loss: 2.596789941992811

Epoch: 5| Step: 2
Training loss: 2.480562210083008
Validation loss: 2.600454999554542

Epoch: 5| Step: 3
Training loss: 3.3203208446502686
Validation loss: 2.601020477151358

Epoch: 5| Step: 4
Training loss: 2.9967269897460938
Validation loss: 2.602415733439948

Epoch: 5| Step: 5
Training loss: 2.6488544940948486
Validation loss: 2.5984911687912478

Epoch: 5| Step: 6
Training loss: 2.5739612579345703
Validation loss: 2.598329705576743

Epoch: 5| Step: 7
Training loss: 3.1492111682891846
Validation loss: 2.5954479581566265

Epoch: 5| Step: 8
Training loss: 2.8831534385681152
Validation loss: 2.5900353154828473

Epoch: 5| Step: 9
Training loss: 2.1160788536071777
Validation loss: 2.593581804665186

Epoch: 5| Step: 10
Training loss: 2.4936635494232178
Validation loss: 2.6018889642530874

Epoch: 49| Step: 0
Training loss: 2.1084511280059814
Validation loss: 2.6112745423470773

Epoch: 5| Step: 1
Training loss: 2.742023229598999
Validation loss: 2.6242376758206274

Epoch: 5| Step: 2
Training loss: 2.7404425144195557
Validation loss: 2.6309474847650014

Epoch: 5| Step: 3
Training loss: 2.201526641845703
Validation loss: 2.63832430172992

Epoch: 5| Step: 4
Training loss: 3.240147352218628
Validation loss: 2.697948089209936

Epoch: 5| Step: 5
Training loss: 2.874498128890991
Validation loss: 2.714154822852022

Epoch: 5| Step: 6
Training loss: 3.2385661602020264
Validation loss: 2.7429629064375356

Epoch: 5| Step: 7
Training loss: 3.3873355388641357
Validation loss: 2.6541145873326126

Epoch: 5| Step: 8
Training loss: 2.5265398025512695
Validation loss: 2.5986024231039067

Epoch: 5| Step: 9
Training loss: 3.03841233253479
Validation loss: 2.588223470154629

Epoch: 5| Step: 10
Training loss: 2.642146110534668
Validation loss: 2.623955483077675

Epoch: 50| Step: 0
Training loss: 3.098386526107788
Validation loss: 2.734882124008671

Epoch: 5| Step: 1
Training loss: 2.2436490058898926
Validation loss: 2.7959093919364353

Epoch: 5| Step: 2
Training loss: 2.803255796432495
Validation loss: 2.8434187289207213

Epoch: 5| Step: 3
Training loss: 2.8314640522003174
Validation loss: 2.8446529142318235

Epoch: 5| Step: 4
Training loss: 3.6096854209899902
Validation loss: 2.8229869309292046

Epoch: 5| Step: 5
Training loss: 2.924964427947998
Validation loss: 2.759191628425352

Epoch: 5| Step: 6
Training loss: 2.4368388652801514
Validation loss: 2.7240777169504473

Epoch: 5| Step: 7
Training loss: 3.2445170879364014
Validation loss: 2.702517586369668

Epoch: 5| Step: 8
Training loss: 2.621016263961792
Validation loss: 2.6829736130211943

Epoch: 5| Step: 9
Training loss: 3.185555934906006
Validation loss: 2.651114430478824

Epoch: 5| Step: 10
Training loss: 2.5906295776367188
Validation loss: 2.600687385887228

Epoch: 51| Step: 0
Training loss: 2.7977638244628906
Validation loss: 2.6003266765225317

Epoch: 5| Step: 1
Training loss: 2.8825550079345703
Validation loss: 2.613428069699195

Epoch: 5| Step: 2
Training loss: 2.6795225143432617
Validation loss: 2.6211945062042563

Epoch: 5| Step: 3
Training loss: 2.0359296798706055
Validation loss: 2.647898284337854

Epoch: 5| Step: 4
Training loss: 2.6025800704956055
Validation loss: 2.662896051201769

Epoch: 5| Step: 5
Training loss: 2.438786268234253
Validation loss: 2.6449401583722842

Epoch: 5| Step: 6
Training loss: 2.4778170585632324
Validation loss: 2.6359048735710884

Epoch: 5| Step: 7
Training loss: 3.0036892890930176
Validation loss: 2.6104409566489597

Epoch: 5| Step: 8
Training loss: 2.6228487491607666
Validation loss: 2.585694351503926

Epoch: 5| Step: 9
Training loss: 3.4187583923339844
Validation loss: 2.5763445259422384

Epoch: 5| Step: 10
Training loss: 3.6113219261169434
Validation loss: 2.5697828800447526

Epoch: 52| Step: 0
Training loss: 3.3536376953125
Validation loss: 2.5645214639684206

Epoch: 5| Step: 1
Training loss: 2.5557303428649902
Validation loss: 2.5668383721382386

Epoch: 5| Step: 2
Training loss: 2.3274142742156982
Validation loss: 2.566517342803299

Epoch: 5| Step: 3
Training loss: 2.6742196083068848
Validation loss: 2.565687169310867

Epoch: 5| Step: 4
Training loss: 3.394078016281128
Validation loss: 2.5643511254300355

Epoch: 5| Step: 5
Training loss: 2.547217845916748
Validation loss: 2.5623062913135817

Epoch: 5| Step: 6
Training loss: 2.351128339767456
Validation loss: 2.5619478764072543

Epoch: 5| Step: 7
Training loss: 2.9289002418518066
Validation loss: 2.561909278233846

Epoch: 5| Step: 8
Training loss: 2.0776286125183105
Validation loss: 2.5607715422107327

Epoch: 5| Step: 9
Training loss: 2.807138442993164
Validation loss: 2.5677732472778647

Epoch: 5| Step: 10
Training loss: 3.2173078060150146
Validation loss: 2.5639113380062963

Epoch: 53| Step: 0
Training loss: 2.6356201171875
Validation loss: 2.5583377140824513

Epoch: 5| Step: 1
Training loss: 2.3045966625213623
Validation loss: 2.555780659439743

Epoch: 5| Step: 2
Training loss: 2.6857125759124756
Validation loss: 2.5564559967287126

Epoch: 5| Step: 3
Training loss: 2.7631161212921143
Validation loss: 2.5543568390671925

Epoch: 5| Step: 4
Training loss: 3.201342821121216
Validation loss: 2.55906738773469

Epoch: 5| Step: 5
Training loss: 2.906156063079834
Validation loss: 2.561136217527492

Epoch: 5| Step: 6
Training loss: 3.4072463512420654
Validation loss: 2.5583168383567565

Epoch: 5| Step: 7
Training loss: 3.1379477977752686
Validation loss: 2.564209673994331

Epoch: 5| Step: 8
Training loss: 2.27426815032959
Validation loss: 2.563559047637447

Epoch: 5| Step: 9
Training loss: 2.2573153972625732
Validation loss: 2.5713386202371247

Epoch: 5| Step: 10
Training loss: 2.4102578163146973
Validation loss: 2.571476028811547

Epoch: 54| Step: 0
Training loss: 2.757747173309326
Validation loss: 2.572496985876432

Epoch: 5| Step: 1
Training loss: 2.0660483837127686
Validation loss: 2.5734946368842997

Epoch: 5| Step: 2
Training loss: 3.7134933471679688
Validation loss: 2.565526395715693

Epoch: 5| Step: 3
Training loss: 2.618474245071411
Validation loss: 2.5582905815493677

Epoch: 5| Step: 4
Training loss: 2.918964385986328
Validation loss: 2.5557523209561586

Epoch: 5| Step: 5
Training loss: 3.1182093620300293
Validation loss: 2.5534574857322117

Epoch: 5| Step: 6
Training loss: 3.166839122772217
Validation loss: 2.548370991983721

Epoch: 5| Step: 7
Training loss: 2.3012969493865967
Validation loss: 2.5482854227865896

Epoch: 5| Step: 8
Training loss: 2.400576591491699
Validation loss: 2.544996110341882

Epoch: 5| Step: 9
Training loss: 2.8637020587921143
Validation loss: 2.5428511634949715

Epoch: 5| Step: 10
Training loss: 1.9713720083236694
Validation loss: 2.54163892551135

Epoch: 55| Step: 0
Training loss: 2.1988065242767334
Validation loss: 2.543384510983703

Epoch: 5| Step: 1
Training loss: 3.428607225418091
Validation loss: 2.5415932414352254

Epoch: 5| Step: 2
Training loss: 2.762732982635498
Validation loss: 2.5396181921805105

Epoch: 5| Step: 3
Training loss: 2.6951098442077637
Validation loss: 2.539813144232637

Epoch: 5| Step: 4
Training loss: 2.428065776824951
Validation loss: 2.538553235351398

Epoch: 5| Step: 5
Training loss: 2.3383102416992188
Validation loss: 2.5347336569140033

Epoch: 5| Step: 6
Training loss: 3.064330577850342
Validation loss: 2.5366949035275366

Epoch: 5| Step: 7
Training loss: 2.593202829360962
Validation loss: 2.536696260975253

Epoch: 5| Step: 8
Training loss: 2.353487253189087
Validation loss: 2.539205438347273

Epoch: 5| Step: 9
Training loss: 2.363327980041504
Validation loss: 2.5435127827429

Epoch: 5| Step: 10
Training loss: 3.8904764652252197
Validation loss: 2.5456884791774135

Epoch: 56| Step: 0
Training loss: 2.900024890899658
Validation loss: 2.5491395996462916

Epoch: 5| Step: 1
Training loss: 2.5457658767700195
Validation loss: 2.5448647878503285

Epoch: 5| Step: 2
Training loss: 1.839320421218872
Validation loss: 2.542803784852387

Epoch: 5| Step: 3
Training loss: 2.835315227508545
Validation loss: 2.532773825430101

Epoch: 5| Step: 4
Training loss: 2.7016477584838867
Validation loss: 2.530403429462064

Epoch: 5| Step: 5
Training loss: 3.1934800148010254
Validation loss: 2.527044924356604

Epoch: 5| Step: 6
Training loss: 2.896115303039551
Validation loss: 2.5293732535454536

Epoch: 5| Step: 7
Training loss: 2.6818244457244873
Validation loss: 2.5269861990405666

Epoch: 5| Step: 8
Training loss: 3.285449266433716
Validation loss: 2.5274774694955475

Epoch: 5| Step: 9
Training loss: 1.960749864578247
Validation loss: 2.526738944874015

Epoch: 5| Step: 10
Training loss: 3.0817930698394775
Validation loss: 2.526445705403564

Epoch: 57| Step: 0
Training loss: 2.633674144744873
Validation loss: 2.5255241317133748

Epoch: 5| Step: 1
Training loss: 3.050293207168579
Validation loss: 2.525549598919448

Epoch: 5| Step: 2
Training loss: 3.053016185760498
Validation loss: 2.5258218755004225

Epoch: 5| Step: 3
Training loss: 2.5312235355377197
Validation loss: 2.5234180740130845

Epoch: 5| Step: 4
Training loss: 3.117649555206299
Validation loss: 2.5249901586963284

Epoch: 5| Step: 5
Training loss: 2.601032257080078
Validation loss: 2.5229667643065095

Epoch: 5| Step: 6
Training loss: 2.411593198776245
Validation loss: 2.525719911821427

Epoch: 5| Step: 7
Training loss: 2.5410728454589844
Validation loss: 2.5235259686746905

Epoch: 5| Step: 8
Training loss: 2.999197006225586
Validation loss: 2.5231838610864457

Epoch: 5| Step: 9
Training loss: 2.3598833084106445
Validation loss: 2.528668439516457

Epoch: 5| Step: 10
Training loss: 2.532130718231201
Validation loss: 2.5270726757664836

Epoch: 58| Step: 0
Training loss: 3.2363171577453613
Validation loss: 2.5248892102190243

Epoch: 5| Step: 1
Training loss: 2.824974536895752
Validation loss: 2.525642889802174

Epoch: 5| Step: 2
Training loss: 2.212787628173828
Validation loss: 2.519583502123433

Epoch: 5| Step: 3
Training loss: 2.755939245223999
Validation loss: 2.5169449262721564

Epoch: 5| Step: 4
Training loss: 2.268582582473755
Validation loss: 2.518343187147571

Epoch: 5| Step: 5
Training loss: 2.279545307159424
Validation loss: 2.515640838171846

Epoch: 5| Step: 6
Training loss: 2.450023889541626
Validation loss: 2.516585744837279

Epoch: 5| Step: 7
Training loss: 2.93792986869812
Validation loss: 2.5209122191193285

Epoch: 5| Step: 8
Training loss: 3.4930825233459473
Validation loss: 2.526236113681588

Epoch: 5| Step: 9
Training loss: 2.728850841522217
Validation loss: 2.5428983216644614

Epoch: 5| Step: 10
Training loss: 2.617142677307129
Validation loss: 2.535392289520592

Epoch: 59| Step: 0
Training loss: 2.4830288887023926
Validation loss: 2.534821999970303

Epoch: 5| Step: 1
Training loss: 2.525808811187744
Validation loss: 2.5224774217092865

Epoch: 5| Step: 2
Training loss: 2.4378342628479004
Validation loss: 2.512616665132584

Epoch: 5| Step: 3
Training loss: 2.7609474658966064
Validation loss: 2.513536273792226

Epoch: 5| Step: 4
Training loss: 2.533957004547119
Validation loss: 2.5214490377774803

Epoch: 5| Step: 5
Training loss: 2.946836471557617
Validation loss: 2.5202530686573317

Epoch: 5| Step: 6
Training loss: 2.634822130203247
Validation loss: 2.5207268550831783

Epoch: 5| Step: 7
Training loss: 3.26188325881958
Validation loss: 2.5224336629272788

Epoch: 5| Step: 8
Training loss: 3.2718186378479004
Validation loss: 2.5178161564693657

Epoch: 5| Step: 9
Training loss: 2.396232843399048
Validation loss: 2.511505047480265

Epoch: 5| Step: 10
Training loss: 2.58663010597229
Validation loss: 2.5102288953719603

Epoch: 60| Step: 0
Training loss: 3.1180167198181152
Validation loss: 2.511486050903156

Epoch: 5| Step: 1
Training loss: 2.854321002960205
Validation loss: 2.519490985460179

Epoch: 5| Step: 2
Training loss: 2.30859375
Validation loss: 2.5334312608165126

Epoch: 5| Step: 3
Training loss: 2.878861665725708
Validation loss: 2.541310405218473

Epoch: 5| Step: 4
Training loss: 2.545116901397705
Validation loss: 2.5508401880982103

Epoch: 5| Step: 5
Training loss: 2.158641815185547
Validation loss: 2.5557545731144566

Epoch: 5| Step: 6
Training loss: 2.9716289043426514
Validation loss: 2.5414620958348757

Epoch: 5| Step: 7
Training loss: 3.247650146484375
Validation loss: 2.5448282226439445

Epoch: 5| Step: 8
Training loss: 2.576906681060791
Validation loss: 2.532953610984228

Epoch: 5| Step: 9
Training loss: 2.6499295234680176
Validation loss: 2.516075018913515

Epoch: 5| Step: 10
Training loss: 2.4958322048187256
Validation loss: 2.5397016694468837

Epoch: 61| Step: 0
Training loss: 2.703634262084961
Validation loss: 2.595871489535096

Epoch: 5| Step: 1
Training loss: 2.8933215141296387
Validation loss: 2.617959301958802

Epoch: 5| Step: 2
Training loss: 2.971531391143799
Validation loss: 2.624815451201572

Epoch: 5| Step: 3
Training loss: 3.5233893394470215
Validation loss: 2.627675164130426

Epoch: 5| Step: 4
Training loss: 2.4968743324279785
Validation loss: 2.6350557547743603

Epoch: 5| Step: 5
Training loss: 2.3265810012817383
Validation loss: 2.6287724100133425

Epoch: 5| Step: 6
Training loss: 3.029066324234009
Validation loss: 2.634295235397995

Epoch: 5| Step: 7
Training loss: 2.9002556800842285
Validation loss: 2.611582689387824

Epoch: 5| Step: 8
Training loss: 2.863524913787842
Validation loss: 2.6018370300210933

Epoch: 5| Step: 9
Training loss: 2.597395420074463
Validation loss: 2.5931840301841818

Epoch: 5| Step: 10
Training loss: 2.147172689437866
Validation loss: 2.5886130332946777

Epoch: 62| Step: 0
Training loss: 2.094663143157959
Validation loss: 2.576415438805857

Epoch: 5| Step: 1
Training loss: 1.96286141872406
Validation loss: 2.5733300793555474

Epoch: 5| Step: 2
Training loss: 3.012045383453369
Validation loss: 2.551958291761337

Epoch: 5| Step: 3
Training loss: 2.4029364585876465
Validation loss: 2.5269901188470985

Epoch: 5| Step: 4
Training loss: 3.337174892425537
Validation loss: 2.531858446777508

Epoch: 5| Step: 5
Training loss: 2.6498403549194336
Validation loss: 2.5347521202538603

Epoch: 5| Step: 6
Training loss: 2.412982940673828
Validation loss: 2.538975513109597

Epoch: 5| Step: 7
Training loss: 2.1327946186065674
Validation loss: 2.5240007677385883

Epoch: 5| Step: 8
Training loss: 3.385554552078247
Validation loss: 2.523977159171976

Epoch: 5| Step: 9
Training loss: 3.039754629135132
Validation loss: 2.5061350304593324

Epoch: 5| Step: 10
Training loss: 3.6337568759918213
Validation loss: 2.495006584352063

Epoch: 63| Step: 0
Training loss: 3.340320110321045
Validation loss: 2.4967219393740416

Epoch: 5| Step: 1
Training loss: 1.9138683080673218
Validation loss: 2.4984138473387687

Epoch: 5| Step: 2
Training loss: 3.155679702758789
Validation loss: 2.4976441629471315

Epoch: 5| Step: 3
Training loss: 3.3203163146972656
Validation loss: 2.5024261359245545

Epoch: 5| Step: 4
Training loss: 2.31972074508667
Validation loss: 2.5117468090467554

Epoch: 5| Step: 5
Training loss: 2.5322906970977783
Validation loss: 2.55050370770116

Epoch: 5| Step: 6
Training loss: 1.8955695629119873
Validation loss: 2.5144285386608494

Epoch: 5| Step: 7
Training loss: 3.1414954662323
Validation loss: 2.5143407339690835

Epoch: 5| Step: 8
Training loss: 2.8477954864501953
Validation loss: 2.4944417912472963

Epoch: 5| Step: 9
Training loss: 2.594907283782959
Validation loss: 2.488661268705963

Epoch: 5| Step: 10
Training loss: 2.7594542503356934
Validation loss: 2.484930694744151

Epoch: 64| Step: 0
Training loss: 2.3158302307128906
Validation loss: 2.4802710471614713

Epoch: 5| Step: 1
Training loss: 2.605804920196533
Validation loss: 2.4773964343532437

Epoch: 5| Step: 2
Training loss: 3.1727402210235596
Validation loss: 2.480643838964483

Epoch: 5| Step: 3
Training loss: 2.1875576972961426
Validation loss: 2.4758690941718315

Epoch: 5| Step: 4
Training loss: 2.6053786277770996
Validation loss: 2.4778462122845393

Epoch: 5| Step: 5
Training loss: 3.200427293777466
Validation loss: 2.4784028248120378

Epoch: 5| Step: 6
Training loss: 2.3453927040100098
Validation loss: 2.4733183922306186

Epoch: 5| Step: 7
Training loss: 2.384326934814453
Validation loss: 2.479972936773813

Epoch: 5| Step: 8
Training loss: 2.7411460876464844
Validation loss: 2.4658093888272523

Epoch: 5| Step: 9
Training loss: 2.8349645137786865
Validation loss: 2.4669617094019407

Epoch: 5| Step: 10
Training loss: 3.2775626182556152
Validation loss: 2.4683922721493627

Epoch: 65| Step: 0
Training loss: 2.810274600982666
Validation loss: 2.4679337316943752

Epoch: 5| Step: 1
Training loss: 2.626044750213623
Validation loss: 2.4634328990854244

Epoch: 5| Step: 2
Training loss: 2.4266715049743652
Validation loss: 2.4580027723825104

Epoch: 5| Step: 3
Training loss: 2.0023298263549805
Validation loss: 2.464623639660497

Epoch: 5| Step: 4
Training loss: 2.787566661834717
Validation loss: 2.4672825515911145

Epoch: 5| Step: 5
Training loss: 2.755324602127075
Validation loss: 2.467360806721513

Epoch: 5| Step: 6
Training loss: 3.0765128135681152
Validation loss: 2.469200050959023

Epoch: 5| Step: 7
Training loss: 2.30546236038208
Validation loss: 2.4691224905752365

Epoch: 5| Step: 8
Training loss: 2.6135668754577637
Validation loss: 2.4685816380285446

Epoch: 5| Step: 9
Training loss: 3.288417100906372
Validation loss: 2.473123099214287

Epoch: 5| Step: 10
Training loss: 2.885514259338379
Validation loss: 2.469454808901715

Epoch: 66| Step: 0
Training loss: 2.764697551727295
Validation loss: 2.4652838501878964

Epoch: 5| Step: 1
Training loss: 1.9151664972305298
Validation loss: 2.4640616883513746

Epoch: 5| Step: 2
Training loss: 2.0398032665252686
Validation loss: 2.462777315929372

Epoch: 5| Step: 3
Training loss: 2.7451846599578857
Validation loss: 2.460410541103732

Epoch: 5| Step: 4
Training loss: 3.0247983932495117
Validation loss: 2.464627055711644

Epoch: 5| Step: 5
Training loss: 2.9559504985809326
Validation loss: 2.4656328155148413

Epoch: 5| Step: 6
Training loss: 2.722147226333618
Validation loss: 2.472394497163834

Epoch: 5| Step: 7
Training loss: 2.263051986694336
Validation loss: 2.4797587112713884

Epoch: 5| Step: 8
Training loss: 2.881495475769043
Validation loss: 2.4856163917049283

Epoch: 5| Step: 9
Training loss: 3.4499268531799316
Validation loss: 2.4640850764448925

Epoch: 5| Step: 10
Training loss: 2.712899684906006
Validation loss: 2.454656506097445

Epoch: 67| Step: 0
Training loss: 2.6469407081604004
Validation loss: 2.4513021515261744

Epoch: 5| Step: 1
Training loss: 2.3598179817199707
Validation loss: 2.4539427808535996

Epoch: 5| Step: 2
Training loss: 2.8790392875671387
Validation loss: 2.4521644935813

Epoch: 5| Step: 3
Training loss: 2.818401336669922
Validation loss: 2.461180063986009

Epoch: 5| Step: 4
Training loss: 2.8772120475769043
Validation loss: 2.4618862957082768

Epoch: 5| Step: 5
Training loss: 2.579331874847412
Validation loss: 2.467296797742126

Epoch: 5| Step: 6
Training loss: 2.9160895347595215
Validation loss: 2.4621776970483924

Epoch: 5| Step: 7
Training loss: 2.208181381225586
Validation loss: 2.4533779134032545

Epoch: 5| Step: 8
Training loss: 2.485774517059326
Validation loss: 2.4557716205555904

Epoch: 5| Step: 9
Training loss: 2.4753823280334473
Validation loss: 2.461050582188432

Epoch: 5| Step: 10
Training loss: 3.2667884826660156
Validation loss: 2.477881157270042

Epoch: 68| Step: 0
Training loss: 2.447202444076538
Validation loss: 2.4773115522118023

Epoch: 5| Step: 1
Training loss: 2.0875630378723145
Validation loss: 2.5068160436486684

Epoch: 5| Step: 2
Training loss: 2.6429731845855713
Validation loss: 2.525385954046762

Epoch: 5| Step: 3
Training loss: 2.2358367443084717
Validation loss: 2.4960101060969855

Epoch: 5| Step: 4
Training loss: 3.349205493927002
Validation loss: 2.467156615308536

Epoch: 5| Step: 5
Training loss: 3.4854912757873535
Validation loss: 2.4591592281095442

Epoch: 5| Step: 6
Training loss: 3.078993558883667
Validation loss: 2.452008165338988

Epoch: 5| Step: 7
Training loss: 2.0760695934295654
Validation loss: 2.4476240963064213

Epoch: 5| Step: 8
Training loss: 2.648409843444824
Validation loss: 2.4456220262794086

Epoch: 5| Step: 9
Training loss: 2.635929584503174
Validation loss: 2.4461495799403035

Epoch: 5| Step: 10
Training loss: 2.6170706748962402
Validation loss: 2.4539143936608427

Epoch: 69| Step: 0
Training loss: 2.694023609161377
Validation loss: 2.4634519930808776

Epoch: 5| Step: 1
Training loss: 2.2519447803497314
Validation loss: 2.473460187194168

Epoch: 5| Step: 2
Training loss: 2.3597912788391113
Validation loss: 2.607951056572699

Epoch: 5| Step: 3
Training loss: 2.7082433700561523
Validation loss: 2.610943753232238

Epoch: 5| Step: 4
Training loss: 2.3395795822143555
Validation loss: 2.581548560050226

Epoch: 5| Step: 5
Training loss: 3.0465874671936035
Validation loss: 2.625610113143921

Epoch: 5| Step: 6
Training loss: 3.155731201171875
Validation loss: 2.6653036609772713

Epoch: 5| Step: 7
Training loss: 3.043231248855591
Validation loss: 2.673264585515504

Epoch: 5| Step: 8
Training loss: 3.1491265296936035
Validation loss: 2.6668633517398628

Epoch: 5| Step: 9
Training loss: 2.7623467445373535
Validation loss: 2.640256643295288

Epoch: 5| Step: 10
Training loss: 2.942643404006958
Validation loss: 2.6224849198454168

Epoch: 70| Step: 0
Training loss: 2.549086093902588
Validation loss: 2.616276546191144

Epoch: 5| Step: 1
Training loss: 2.9943313598632812
Validation loss: 2.607482176955028

Epoch: 5| Step: 2
Training loss: 2.4212727546691895
Validation loss: 2.5980236043212233

Epoch: 5| Step: 3
Training loss: 2.828735828399658
Validation loss: 2.5785079848381782

Epoch: 5| Step: 4
Training loss: 2.8692357540130615
Validation loss: 2.566530922407745

Epoch: 5| Step: 5
Training loss: 2.7528128623962402
Validation loss: 2.5427457183919926

Epoch: 5| Step: 6
Training loss: 2.294323444366455
Validation loss: 2.4814665650808685

Epoch: 5| Step: 7
Training loss: 2.1613705158233643
Validation loss: 2.456759860438685

Epoch: 5| Step: 8
Training loss: 3.2505462169647217
Validation loss: 2.4539630874510734

Epoch: 5| Step: 9
Training loss: 2.716341733932495
Validation loss: 2.4542354255594234

Epoch: 5| Step: 10
Training loss: 3.1217098236083984
Validation loss: 2.4780732200991724

Epoch: 71| Step: 0
Training loss: 2.930752754211426
Validation loss: 2.4885206119988554

Epoch: 5| Step: 1
Training loss: 2.1112170219421387
Validation loss: 2.5121113100359516

Epoch: 5| Step: 2
Training loss: 3.274869441986084
Validation loss: 2.49614901696482

Epoch: 5| Step: 3
Training loss: 1.8745876550674438
Validation loss: 2.478762193392682

Epoch: 5| Step: 4
Training loss: 2.8174357414245605
Validation loss: 2.486554168885754

Epoch: 5| Step: 5
Training loss: 3.1497721672058105
Validation loss: 2.4648136567044

Epoch: 5| Step: 6
Training loss: 3.5138726234436035
Validation loss: 2.4431984168227

Epoch: 5| Step: 7
Training loss: 2.5436291694641113
Validation loss: 2.427463654548891

Epoch: 5| Step: 8
Training loss: 2.746917486190796
Validation loss: 2.426534645019039

Epoch: 5| Step: 9
Training loss: 1.9650723934173584
Validation loss: 2.424018459935342

Epoch: 5| Step: 10
Training loss: 2.376364231109619
Validation loss: 2.4208434115174

Epoch: 72| Step: 0
Training loss: 3.129340648651123
Validation loss: 2.462299349487469

Epoch: 5| Step: 1
Training loss: 1.9440422058105469
Validation loss: 2.431858067871422

Epoch: 5| Step: 2
Training loss: 2.167811155319214
Validation loss: 2.434923833416354

Epoch: 5| Step: 3
Training loss: 2.600773334503174
Validation loss: 2.454620994547362

Epoch: 5| Step: 4
Training loss: 2.8405749797821045
Validation loss: 2.45850637907623

Epoch: 5| Step: 5
Training loss: 2.875234603881836
Validation loss: 2.4785863789178992

Epoch: 5| Step: 6
Training loss: 2.8467259407043457
Validation loss: 2.4718274403643865

Epoch: 5| Step: 7
Training loss: 3.040910243988037
Validation loss: 2.449718685560329

Epoch: 5| Step: 8
Training loss: 2.21785044670105
Validation loss: 2.434269689744519

Epoch: 5| Step: 9
Training loss: 2.9137039184570312
Validation loss: 2.4269848228782736

Epoch: 5| Step: 10
Training loss: 2.713449478149414
Validation loss: 2.4201602115426013

Epoch: 73| Step: 0
Training loss: 2.9815564155578613
Validation loss: 2.4138007779275217

Epoch: 5| Step: 1
Training loss: 2.9084904193878174
Validation loss: 2.4112312921913723

Epoch: 5| Step: 2
Training loss: 3.0001461505889893
Validation loss: 2.414440180665703

Epoch: 5| Step: 3
Training loss: 3.3144614696502686
Validation loss: 2.41425230169809

Epoch: 5| Step: 4
Training loss: 2.030900239944458
Validation loss: 2.4124982113479287

Epoch: 5| Step: 5
Training loss: 1.8312675952911377
Validation loss: 2.4114730435033

Epoch: 5| Step: 6
Training loss: 2.4221534729003906
Validation loss: 2.4174690938765004

Epoch: 5| Step: 7
Training loss: 2.3662257194519043
Validation loss: 2.4348047241087882

Epoch: 5| Step: 8
Training loss: 3.094170093536377
Validation loss: 2.4446576795270367

Epoch: 5| Step: 9
Training loss: 2.513859272003174
Validation loss: 2.4275514002769225

Epoch: 5| Step: 10
Training loss: 2.7080588340759277
Validation loss: 2.413589354484312

Epoch: 74| Step: 0
Training loss: 2.72322416305542
Validation loss: 2.409466020522579

Epoch: 5| Step: 1
Training loss: 2.311338424682617
Validation loss: 2.404381018812938

Epoch: 5| Step: 2
Training loss: 2.5446670055389404
Validation loss: 2.405048524179766

Epoch: 5| Step: 3
Training loss: 2.0491108894348145
Validation loss: 2.4022829391623057

Epoch: 5| Step: 4
Training loss: 2.4320082664489746
Validation loss: 2.400213800450807

Epoch: 5| Step: 5
Training loss: 3.1052961349487305
Validation loss: 2.397409026340772

Epoch: 5| Step: 6
Training loss: 2.3036227226257324
Validation loss: 2.397914168655231

Epoch: 5| Step: 7
Training loss: 3.139789342880249
Validation loss: 2.3951164714751707

Epoch: 5| Step: 8
Training loss: 2.701207160949707
Validation loss: 2.396039708968132

Epoch: 5| Step: 9
Training loss: 3.449704647064209
Validation loss: 2.3991511739710325

Epoch: 5| Step: 10
Training loss: 2.252593517303467
Validation loss: 2.4032962879826947

Epoch: 75| Step: 0
Training loss: 2.4846794605255127
Validation loss: 2.3990228150480535

Epoch: 5| Step: 1
Training loss: 2.3006978034973145
Validation loss: 2.4113837929182154

Epoch: 5| Step: 2
Training loss: 2.4979195594787598
Validation loss: 2.408820354810325

Epoch: 5| Step: 3
Training loss: 2.4000518321990967
Validation loss: 2.3989556015178723

Epoch: 5| Step: 4
Training loss: 2.7759852409362793
Validation loss: 2.3877276835903043

Epoch: 5| Step: 5
Training loss: 2.5718209743499756
Validation loss: 2.3924519990080144

Epoch: 5| Step: 6
Training loss: 3.1309056282043457
Validation loss: 2.3927976239112114

Epoch: 5| Step: 7
Training loss: 2.1324238777160645
Validation loss: 2.3918503022963002

Epoch: 5| Step: 8
Training loss: 3.1003003120422363
Validation loss: 2.3945741422714724

Epoch: 5| Step: 9
Training loss: 3.069810628890991
Validation loss: 2.3971041325599916

Epoch: 5| Step: 10
Training loss: 2.5394487380981445
Validation loss: 2.391070647906232

Epoch: 76| Step: 0
Training loss: 2.811126708984375
Validation loss: 2.3905938876572477

Epoch: 5| Step: 1
Training loss: 2.3788504600524902
Validation loss: 2.390243281600296

Epoch: 5| Step: 2
Training loss: 2.655917167663574
Validation loss: 2.3936328657211794

Epoch: 5| Step: 3
Training loss: 2.135561466217041
Validation loss: 2.3998128086008053

Epoch: 5| Step: 4
Training loss: 3.986321210861206
Validation loss: 2.3922833742633944

Epoch: 5| Step: 5
Training loss: 2.7644619941711426
Validation loss: 2.3915365229370775

Epoch: 5| Step: 6
Training loss: 2.6932132244110107
Validation loss: 2.3907760240698375

Epoch: 5| Step: 7
Training loss: 2.2734780311584473
Validation loss: 2.3936812006017214

Epoch: 5| Step: 8
Training loss: 2.5889196395874023
Validation loss: 2.392765892449246

Epoch: 5| Step: 9
Training loss: 2.393256425857544
Validation loss: 2.3932976748353694

Epoch: 5| Step: 10
Training loss: 2.1595218181610107
Validation loss: 2.396424501172958

Epoch: 77| Step: 0
Training loss: 2.484424352645874
Validation loss: 2.412292834251158

Epoch: 5| Step: 1
Training loss: 2.6225552558898926
Validation loss: 2.429870959251158

Epoch: 5| Step: 2
Training loss: 2.494046211242676
Validation loss: 2.4328093118565057

Epoch: 5| Step: 3
Training loss: 2.183098316192627
Validation loss: 2.39927912271151

Epoch: 5| Step: 4
Training loss: 2.5780739784240723
Validation loss: 2.386350288186022

Epoch: 5| Step: 5
Training loss: 3.252192735671997
Validation loss: 2.3810446800724154

Epoch: 5| Step: 6
Training loss: 3.0424256324768066
Validation loss: 2.3769414963260775

Epoch: 5| Step: 7
Training loss: 2.9041590690612793
Validation loss: 2.3803289974889448

Epoch: 5| Step: 8
Training loss: 3.0233101844787598
Validation loss: 2.3886069302917807

Epoch: 5| Step: 9
Training loss: 2.25947642326355
Validation loss: 2.4006958110358125

Epoch: 5| Step: 10
Training loss: 2.168903350830078
Validation loss: 2.4086464528114564

Epoch: 78| Step: 0
Training loss: 2.2468957901000977
Validation loss: 2.412868474119453

Epoch: 5| Step: 1
Training loss: 2.3113396167755127
Validation loss: 2.4116016562267015

Epoch: 5| Step: 2
Training loss: 3.100774049758911
Validation loss: 2.406001721659014

Epoch: 5| Step: 3
Training loss: 2.000100612640381
Validation loss: 2.388415482736403

Epoch: 5| Step: 4
Training loss: 2.4298839569091797
Validation loss: 2.3824626168897076

Epoch: 5| Step: 5
Training loss: 2.8258109092712402
Validation loss: 2.3762797232597106

Epoch: 5| Step: 6
Training loss: 2.5250353813171387
Validation loss: 2.372587929489792

Epoch: 5| Step: 7
Training loss: 2.4105029106140137
Validation loss: 2.3730758697755876

Epoch: 5| Step: 8
Training loss: 3.0268571376800537
Validation loss: 2.3745720155777468

Epoch: 5| Step: 9
Training loss: 3.5341384410858154
Validation loss: 2.3737341832089167

Epoch: 5| Step: 10
Training loss: 2.710981607437134
Validation loss: 2.376099799268989

Epoch: 79| Step: 0
Training loss: 2.7972378730773926
Validation loss: 2.3868666284827778

Epoch: 5| Step: 1
Training loss: 2.1887950897216797
Validation loss: 2.3867904986104658

Epoch: 5| Step: 2
Training loss: 2.5974605083465576
Validation loss: 2.386781284886022

Epoch: 5| Step: 3
Training loss: 2.42950701713562
Validation loss: 2.392134689515637

Epoch: 5| Step: 4
Training loss: 3.227478504180908
Validation loss: 2.390466159389865

Epoch: 5| Step: 5
Training loss: 2.6324758529663086
Validation loss: 2.391791994853686

Epoch: 5| Step: 6
Training loss: 2.691016435623169
Validation loss: 2.3897509318526073

Epoch: 5| Step: 7
Training loss: 2.8756659030914307
Validation loss: 2.3709448563155306

Epoch: 5| Step: 8
Training loss: 2.474294662475586
Validation loss: 2.3646374543507895

Epoch: 5| Step: 9
Training loss: 2.369373321533203
Validation loss: 2.3672019717513875

Epoch: 5| Step: 10
Training loss: 2.7156174182891846
Validation loss: 2.3656410581322125

Epoch: 80| Step: 0
Training loss: 3.2731223106384277
Validation loss: 2.363441300648515

Epoch: 5| Step: 1
Training loss: 2.8459830284118652
Validation loss: 2.365206221098541

Epoch: 5| Step: 2
Training loss: 2.642169952392578
Validation loss: 2.364153015998102

Epoch: 5| Step: 3
Training loss: 2.511620283126831
Validation loss: 2.362815046823153

Epoch: 5| Step: 4
Training loss: 2.19282603263855
Validation loss: 2.3662327925364175

Epoch: 5| Step: 5
Training loss: 2.6397361755371094
Validation loss: 2.3642277999590804

Epoch: 5| Step: 6
Training loss: 2.2978930473327637
Validation loss: 2.3658571525286605

Epoch: 5| Step: 7
Training loss: 2.521860122680664
Validation loss: 2.362788713106545

Epoch: 5| Step: 8
Training loss: 2.383141040802002
Validation loss: 2.370483006200483

Epoch: 5| Step: 9
Training loss: 2.3709356784820557
Validation loss: 2.388088651882705

Epoch: 5| Step: 10
Training loss: 3.2639355659484863
Validation loss: 2.408916416988578

Epoch: 81| Step: 0
Training loss: 2.978203296661377
Validation loss: 2.4095852323757705

Epoch: 5| Step: 1
Training loss: 2.0416793823242188
Validation loss: 2.3942549279941026

Epoch: 5| Step: 2
Training loss: 2.6313955783843994
Validation loss: 2.377467119565574

Epoch: 5| Step: 3
Training loss: 2.9705991744995117
Validation loss: 2.361401242594565

Epoch: 5| Step: 4
Training loss: 2.062574863433838
Validation loss: 2.3602508601321968

Epoch: 5| Step: 5
Training loss: 2.7818410396575928
Validation loss: 2.3561704953511557

Epoch: 5| Step: 6
Training loss: 2.823970079421997
Validation loss: 2.3615195161552838

Epoch: 5| Step: 7
Training loss: 2.863417863845825
Validation loss: 2.358240448018556

Epoch: 5| Step: 8
Training loss: 2.370837450027466
Validation loss: 2.3628238478014545

Epoch: 5| Step: 9
Training loss: 2.439725875854492
Validation loss: 2.35828875085359

Epoch: 5| Step: 10
Training loss: 2.960075616836548
Validation loss: 2.356618127515239

Epoch: 82| Step: 0
Training loss: 2.1619653701782227
Validation loss: 2.358534577072308

Epoch: 5| Step: 1
Training loss: 2.6102232933044434
Validation loss: 2.361321190352081

Epoch: 5| Step: 2
Training loss: 2.9922149181365967
Validation loss: 2.3652497696620163

Epoch: 5| Step: 3
Training loss: 2.5907397270202637
Validation loss: 2.368159447946856

Epoch: 5| Step: 4
Training loss: 2.8293752670288086
Validation loss: 2.379189488708332

Epoch: 5| Step: 5
Training loss: 2.92421293258667
Validation loss: 2.3796937670758975

Epoch: 5| Step: 6
Training loss: 2.059250593185425
Validation loss: 2.379810066633327

Epoch: 5| Step: 7
Training loss: 2.475003719329834
Validation loss: 2.3743540830509637

Epoch: 5| Step: 8
Training loss: 2.6120333671569824
Validation loss: 2.3818853080913587

Epoch: 5| Step: 9
Training loss: 2.8211939334869385
Validation loss: 2.385288635889689

Epoch: 5| Step: 10
Training loss: 2.854445457458496
Validation loss: 2.380581248191095

Epoch: 83| Step: 0
Training loss: 3.1634976863861084
Validation loss: 2.3706635608468005

Epoch: 5| Step: 1
Training loss: 2.121184825897217
Validation loss: 2.358072659020783

Epoch: 5| Step: 2
Training loss: 2.473461389541626
Validation loss: 2.3570417691302556

Epoch: 5| Step: 3
Training loss: 2.538698434829712
Validation loss: 2.3550910154978433

Epoch: 5| Step: 4
Training loss: 2.7355635166168213
Validation loss: 2.352864738433592

Epoch: 5| Step: 5
Training loss: 2.938356876373291
Validation loss: 2.353115450951361

Epoch: 5| Step: 6
Training loss: 2.6723828315734863
Validation loss: 2.353116591771444

Epoch: 5| Step: 7
Training loss: 2.5048136711120605
Validation loss: 2.3559058250919467

Epoch: 5| Step: 8
Training loss: 2.752340316772461
Validation loss: 2.3500825102611254

Epoch: 5| Step: 9
Training loss: 2.4862279891967773
Validation loss: 2.3478198077089045

Epoch: 5| Step: 10
Training loss: 2.384523391723633
Validation loss: 2.3470870653788247

Epoch: 84| Step: 0
Training loss: 3.725947141647339
Validation loss: 2.352619486470376

Epoch: 5| Step: 1
Training loss: 2.652350902557373
Validation loss: 2.350485260768603

Epoch: 5| Step: 2
Training loss: 2.5856430530548096
Validation loss: 2.351533487278928

Epoch: 5| Step: 3
Training loss: 2.624716281890869
Validation loss: 2.3521310744747037

Epoch: 5| Step: 4
Training loss: 2.1448981761932373
Validation loss: 2.350561313731696

Epoch: 5| Step: 5
Training loss: 2.6570374965667725
Validation loss: 2.3550659046378186

Epoch: 5| Step: 6
Training loss: 1.8727209568023682
Validation loss: 2.3687232155953684

Epoch: 5| Step: 7
Training loss: 2.007124662399292
Validation loss: 2.384121856381816

Epoch: 5| Step: 8
Training loss: 2.569312334060669
Validation loss: 2.4206546788574546

Epoch: 5| Step: 9
Training loss: 3.17402982711792
Validation loss: 2.431714234813567

Epoch: 5| Step: 10
Training loss: 2.8003952503204346
Validation loss: 2.41468055530261

Epoch: 85| Step: 0
Training loss: 2.429499864578247
Validation loss: 2.3825199834762083

Epoch: 5| Step: 1
Training loss: 2.6483776569366455
Validation loss: 2.3688390742066088

Epoch: 5| Step: 2
Training loss: 2.4556403160095215
Validation loss: 2.3615516488270094

Epoch: 5| Step: 3
Training loss: 3.3500428199768066
Validation loss: 2.3609807978394213

Epoch: 5| Step: 4
Training loss: 2.6243808269500732
Validation loss: 2.360678865063575

Epoch: 5| Step: 5
Training loss: 2.604674816131592
Validation loss: 2.362948586863856

Epoch: 5| Step: 6
Training loss: 2.5811235904693604
Validation loss: 2.361594882062686

Epoch: 5| Step: 7
Training loss: 2.5547115802764893
Validation loss: 2.3535517518238356

Epoch: 5| Step: 8
Training loss: 2.3002517223358154
Validation loss: 2.350376175295922

Epoch: 5| Step: 9
Training loss: 2.6010444164276123
Validation loss: 2.3477511405944824

Epoch: 5| Step: 10
Training loss: 2.394680976867676
Validation loss: 2.3493157996926257

Epoch: 86| Step: 0
Training loss: 2.1509768962860107
Validation loss: 2.3509504923256497

Epoch: 5| Step: 1
Training loss: 2.9747977256774902
Validation loss: 2.3477009701472458

Epoch: 5| Step: 2
Training loss: 2.8704066276550293
Validation loss: 2.347838804286013

Epoch: 5| Step: 3
Training loss: 2.3439583778381348
Validation loss: 2.3504226002641904

Epoch: 5| Step: 4
Training loss: 3.05005145072937
Validation loss: 2.3539226696055424

Epoch: 5| Step: 5
Training loss: 2.5957109928131104
Validation loss: 2.355489521898249

Epoch: 5| Step: 6
Training loss: 2.614386796951294
Validation loss: 2.3630015542430263

Epoch: 5| Step: 7
Training loss: 2.254451274871826
Validation loss: 2.354970253923888

Epoch: 5| Step: 8
Training loss: 2.8438830375671387
Validation loss: 2.362426309175389

Epoch: 5| Step: 9
Training loss: 2.5304760932922363
Validation loss: 2.3567629552656606

Epoch: 5| Step: 10
Training loss: 2.3611035346984863
Validation loss: 2.3485581836392804

Epoch: 87| Step: 0
Training loss: 2.826946973800659
Validation loss: 2.3419859563150713

Epoch: 5| Step: 1
Training loss: 2.0546038150787354
Validation loss: 2.337666501281082

Epoch: 5| Step: 2
Training loss: 2.5612730979919434
Validation loss: 2.3373147620949695

Epoch: 5| Step: 3
Training loss: 2.8758726119995117
Validation loss: 2.3359156013816915

Epoch: 5| Step: 4
Training loss: 2.5032715797424316
Validation loss: 2.330120107179047

Epoch: 5| Step: 5
Training loss: 2.7628333568573
Validation loss: 2.329270283381144

Epoch: 5| Step: 6
Training loss: 2.124725818634033
Validation loss: 2.3292849345873763

Epoch: 5| Step: 7
Training loss: 2.115670919418335
Validation loss: 2.328046719233195

Epoch: 5| Step: 8
Training loss: 2.927048444747925
Validation loss: 2.3292363305245676

Epoch: 5| Step: 9
Training loss: 2.3699498176574707
Validation loss: 2.325750179188226

Epoch: 5| Step: 10
Training loss: 3.484940528869629
Validation loss: 2.33809317568297

Epoch: 88| Step: 0
Training loss: 2.1531386375427246
Validation loss: 2.3335738925523657

Epoch: 5| Step: 1
Training loss: 2.7556538581848145
Validation loss: 2.337224309162427

Epoch: 5| Step: 2
Training loss: 2.0866129398345947
Validation loss: 2.3484518553621028

Epoch: 5| Step: 3
Training loss: 2.7444908618927
Validation loss: 2.3547631514969694

Epoch: 5| Step: 4
Training loss: 2.7850468158721924
Validation loss: 2.370884067268782

Epoch: 5| Step: 5
Training loss: 2.935581922531128
Validation loss: 2.3600113084239345

Epoch: 5| Step: 6
Training loss: 1.9988149404525757
Validation loss: 2.3467257535585793

Epoch: 5| Step: 7
Training loss: 2.8482089042663574
Validation loss: 2.3477664865473264

Epoch: 5| Step: 8
Training loss: 2.752619504928589
Validation loss: 2.3376643632047918

Epoch: 5| Step: 9
Training loss: 2.802816152572632
Validation loss: 2.332351420515327

Epoch: 5| Step: 10
Training loss: 2.592385768890381
Validation loss: 2.318391026989106

Epoch: 89| Step: 0
Training loss: 2.1331372261047363
Validation loss: 2.313861605941608

Epoch: 5| Step: 1
Training loss: 2.3361833095550537
Validation loss: 2.3155683753310994

Epoch: 5| Step: 2
Training loss: 2.5027918815612793
Validation loss: 2.318313434559812

Epoch: 5| Step: 3
Training loss: 2.256539821624756
Validation loss: 2.321502803474344

Epoch: 5| Step: 4
Training loss: 2.553448438644409
Validation loss: 2.3270878689263457

Epoch: 5| Step: 5
Training loss: 2.5938773155212402
Validation loss: 2.3478933867587837

Epoch: 5| Step: 6
Training loss: 3.4777019023895264
Validation loss: 2.3750877585462344

Epoch: 5| Step: 7
Training loss: 2.5292649269104004
Validation loss: 2.3781846902703725

Epoch: 5| Step: 8
Training loss: 2.495410442352295
Validation loss: 2.343054002331149

Epoch: 5| Step: 9
Training loss: 2.862643003463745
Validation loss: 2.3206303119659424

Epoch: 5| Step: 10
Training loss: 2.933959722518921
Validation loss: 2.3149670977746286

Epoch: 90| Step: 0
Training loss: 2.783383846282959
Validation loss: 2.317186819609775

Epoch: 5| Step: 1
Training loss: 3.038461446762085
Validation loss: 2.31715900410888

Epoch: 5| Step: 2
Training loss: 2.230435848236084
Validation loss: 2.3146136832493607

Epoch: 5| Step: 3
Training loss: 1.775041937828064
Validation loss: 2.314091705506848

Epoch: 5| Step: 4
Training loss: 2.274109363555908
Validation loss: 2.3142789243369974

Epoch: 5| Step: 5
Training loss: 2.3639323711395264
Validation loss: 2.3111613796603296

Epoch: 5| Step: 6
Training loss: 3.1314711570739746
Validation loss: 2.3132899897072905

Epoch: 5| Step: 7
Training loss: 2.823131561279297
Validation loss: 2.308025844635502

Epoch: 5| Step: 8
Training loss: 2.721446990966797
Validation loss: 2.3083781401316323

Epoch: 5| Step: 9
Training loss: 2.7722129821777344
Validation loss: 2.3117598282393588

Epoch: 5| Step: 10
Training loss: 2.6161341667175293
Validation loss: 2.3135467677988033

Epoch: 91| Step: 0
Training loss: 1.918562650680542
Validation loss: 2.313297607565439

Epoch: 5| Step: 1
Training loss: 2.432760000228882
Validation loss: 2.3149879132547686

Epoch: 5| Step: 2
Training loss: 2.2314443588256836
Validation loss: 2.3188020003739225

Epoch: 5| Step: 3
Training loss: 2.181102752685547
Validation loss: 2.3222328898727254

Epoch: 5| Step: 4
Training loss: 2.5735974311828613
Validation loss: 2.306430366731459

Epoch: 5| Step: 5
Training loss: 2.7354769706726074
Validation loss: 2.30349632745148

Epoch: 5| Step: 6
Training loss: 3.1863274574279785
Validation loss: 2.301330333114952

Epoch: 5| Step: 7
Training loss: 3.1115496158599854
Validation loss: 2.2993608264512915

Epoch: 5| Step: 8
Training loss: 2.672274589538574
Validation loss: 2.302849772155926

Epoch: 5| Step: 9
Training loss: 3.1482882499694824
Validation loss: 2.2999785612988215

Epoch: 5| Step: 10
Training loss: 2.092348098754883
Validation loss: 2.3056207267186974

Epoch: 92| Step: 0
Training loss: 2.722391366958618
Validation loss: 2.3099223311229418

Epoch: 5| Step: 1
Training loss: 2.5572116374969482
Validation loss: 2.317637622997325

Epoch: 5| Step: 2
Training loss: 2.2916035652160645
Validation loss: 2.328786457738569

Epoch: 5| Step: 3
Training loss: 2.21380615234375
Validation loss: 2.3402341514505367

Epoch: 5| Step: 4
Training loss: 2.9342682361602783
Validation loss: 2.354264474684192

Epoch: 5| Step: 5
Training loss: 2.4158148765563965
Validation loss: 2.3377276671830045

Epoch: 5| Step: 6
Training loss: 3.060310125350952
Validation loss: 2.3213721911112466

Epoch: 5| Step: 7
Training loss: 2.3952698707580566
Validation loss: 2.3051062655705277

Epoch: 5| Step: 8
Training loss: 2.746168375015259
Validation loss: 2.300131341462494

Epoch: 5| Step: 9
Training loss: 2.592350482940674
Validation loss: 2.297497900583411

Epoch: 5| Step: 10
Training loss: 2.3883180618286133
Validation loss: 2.294326315643967

Epoch: 93| Step: 0
Training loss: 2.3085289001464844
Validation loss: 2.297950972792923

Epoch: 5| Step: 1
Training loss: 2.5674710273742676
Validation loss: 2.295819579914052

Epoch: 5| Step: 2
Training loss: 2.9026901721954346
Validation loss: 2.2989478623995216

Epoch: 5| Step: 3
Training loss: 1.9599506855010986
Validation loss: 2.2973484095706733

Epoch: 5| Step: 4
Training loss: 2.8620336055755615
Validation loss: 2.307032310834495

Epoch: 5| Step: 5
Training loss: 2.542266368865967
Validation loss: 2.313865694948422

Epoch: 5| Step: 6
Training loss: 2.9124577045440674
Validation loss: 2.3069932127511628

Epoch: 5| Step: 7
Training loss: 2.387268543243408
Validation loss: 2.2999191643089376

Epoch: 5| Step: 8
Training loss: 2.652310848236084
Validation loss: 2.2987314834389636

Epoch: 5| Step: 9
Training loss: 2.4815471172332764
Validation loss: 2.2859870772207938

Epoch: 5| Step: 10
Training loss: 2.6639819145202637
Validation loss: 2.2915757753515757

Epoch: 94| Step: 0
Training loss: 1.8385826349258423
Validation loss: 2.2931909420156993

Epoch: 5| Step: 1
Training loss: 2.682816743850708
Validation loss: 2.3040535911437003

Epoch: 5| Step: 2
Training loss: 2.7791993618011475
Validation loss: 2.3215366948035454

Epoch: 5| Step: 3
Training loss: 2.356151580810547
Validation loss: 2.321654091599167

Epoch: 5| Step: 4
Training loss: 3.0891623497009277
Validation loss: 2.3304954985136628

Epoch: 5| Step: 5
Training loss: 1.9251199960708618
Validation loss: 2.318875143604894

Epoch: 5| Step: 6
Training loss: 2.547107219696045
Validation loss: 2.3017250209726314

Epoch: 5| Step: 7
Training loss: 2.7522034645080566
Validation loss: 2.2914396691065964

Epoch: 5| Step: 8
Training loss: 2.418494701385498
Validation loss: 2.298107662508565

Epoch: 5| Step: 9
Training loss: 2.8258299827575684
Validation loss: 2.2926342461698797

Epoch: 5| Step: 10
Training loss: 2.970829725265503
Validation loss: 2.2834831463393344

Epoch: 95| Step: 0
Training loss: 3.2025961875915527
Validation loss: 2.283336547113234

Epoch: 5| Step: 1
Training loss: 2.4750800132751465
Validation loss: 2.2848615005452144

Epoch: 5| Step: 2
Training loss: 2.292881488800049
Validation loss: 2.2798212984556794

Epoch: 5| Step: 3
Training loss: 2.3054683208465576
Validation loss: 2.278421542977774

Epoch: 5| Step: 4
Training loss: 2.1455416679382324
Validation loss: 2.2848002884977605

Epoch: 5| Step: 5
Training loss: 2.6758787631988525
Validation loss: 2.2899989133240073

Epoch: 5| Step: 6
Training loss: 2.4072887897491455
Validation loss: 2.300876416185851

Epoch: 5| Step: 7
Training loss: 2.542725086212158
Validation loss: 2.301495402090011

Epoch: 5| Step: 8
Training loss: 2.2636451721191406
Validation loss: 2.3137128788937806

Epoch: 5| Step: 9
Training loss: 2.303969144821167
Validation loss: 2.3079917635968936

Epoch: 5| Step: 10
Training loss: 3.794727087020874
Validation loss: 2.3014034532731578

Epoch: 96| Step: 0
Training loss: 2.478834629058838
Validation loss: 2.2931220813464095

Epoch: 5| Step: 1
Training loss: 2.447650909423828
Validation loss: 2.290882597687424

Epoch: 5| Step: 2
Training loss: 2.9752702713012695
Validation loss: 2.286471756555701

Epoch: 5| Step: 3
Training loss: 2.5843899250030518
Validation loss: 2.2871546309481383

Epoch: 5| Step: 4
Training loss: 2.0197482109069824
Validation loss: 2.275843140899494

Epoch: 5| Step: 5
Training loss: 2.4850823879241943
Validation loss: 2.2783547537301176

Epoch: 5| Step: 6
Training loss: 2.7267041206359863
Validation loss: 2.275067585770802

Epoch: 5| Step: 7
Training loss: 2.5829625129699707
Validation loss: 2.2758521187689995

Epoch: 5| Step: 8
Training loss: 2.6683459281921387
Validation loss: 2.28168382183198

Epoch: 5| Step: 9
Training loss: 2.189232349395752
Validation loss: 2.2786211300921697

Epoch: 5| Step: 10
Training loss: 2.9350903034210205
Validation loss: 2.279799134500565

Epoch: 97| Step: 0
Training loss: 2.8626515865325928
Validation loss: 2.2843788259772846

Epoch: 5| Step: 1
Training loss: 2.6903393268585205
Validation loss: 2.2776816583448842

Epoch: 5| Step: 2
Training loss: 2.8349838256835938
Validation loss: 2.2762639189279206

Epoch: 5| Step: 3
Training loss: 2.080846071243286
Validation loss: 2.2756947791704567

Epoch: 5| Step: 4
Training loss: 3.206317901611328
Validation loss: 2.2815491230257097

Epoch: 5| Step: 5
Training loss: 1.9972079992294312
Validation loss: 2.2894344688743673

Epoch: 5| Step: 6
Training loss: 2.799706220626831
Validation loss: 2.2949087337781022

Epoch: 5| Step: 7
Training loss: 2.2060387134552
Validation loss: 2.2915957999485794

Epoch: 5| Step: 8
Training loss: 2.3742032051086426
Validation loss: 2.3006342790460073

Epoch: 5| Step: 9
Training loss: 2.5143730640411377
Validation loss: 2.290421111609346

Epoch: 5| Step: 10
Training loss: 2.4000535011291504
Validation loss: 2.2792621556148736

Epoch: 98| Step: 0
Training loss: 2.5540452003479004
Validation loss: 2.2704426857732956

Epoch: 5| Step: 1
Training loss: 2.606607675552368
Validation loss: 2.2665376176116285

Epoch: 5| Step: 2
Training loss: 2.344649076461792
Validation loss: 2.259795455522435

Epoch: 5| Step: 3
Training loss: 2.0444724559783936
Validation loss: 2.2621983148718394

Epoch: 5| Step: 4
Training loss: 2.6607108116149902
Validation loss: 2.2656139032815092

Epoch: 5| Step: 5
Training loss: 3.211339235305786
Validation loss: 2.264496454628565

Epoch: 5| Step: 6
Training loss: 2.86671781539917
Validation loss: 2.2679658756461194

Epoch: 5| Step: 7
Training loss: 2.404588222503662
Validation loss: 2.2627549338084396

Epoch: 5| Step: 8
Training loss: 2.223198413848877
Validation loss: 2.2591815815177014

Epoch: 5| Step: 9
Training loss: 1.8624197244644165
Validation loss: 2.26170894792003

Epoch: 5| Step: 10
Training loss: 3.3868439197540283
Validation loss: 2.27395865865933

Epoch: 99| Step: 0
Training loss: 2.6996688842773438
Validation loss: 2.2914720709605882

Epoch: 5| Step: 1
Training loss: 2.68703293800354
Validation loss: 2.3201750888619372

Epoch: 5| Step: 2
Training loss: 2.9887044429779053
Validation loss: 2.333842856909639

Epoch: 5| Step: 3
Training loss: 2.783841609954834
Validation loss: 2.330480767834571

Epoch: 5| Step: 4
Training loss: 2.350717544555664
Validation loss: 2.313537625856297

Epoch: 5| Step: 5
Training loss: 2.2614924907684326
Validation loss: 2.3021093581312444

Epoch: 5| Step: 6
Training loss: 2.657742738723755
Validation loss: 2.283697510278353

Epoch: 5| Step: 7
Training loss: 3.0208709239959717
Validation loss: 2.2659740012179137

Epoch: 5| Step: 8
Training loss: 2.44517183303833
Validation loss: 2.2566721516270793

Epoch: 5| Step: 9
Training loss: 1.8612651824951172
Validation loss: 2.2588371871620097

Epoch: 5| Step: 10
Training loss: 2.1545588970184326
Validation loss: 2.2678271929423013

Epoch: 100| Step: 0
Training loss: 2.0385570526123047
Validation loss: 2.2668538785749868

Epoch: 5| Step: 1
Training loss: 2.6226859092712402
Validation loss: 2.269272683769144

Epoch: 5| Step: 2
Training loss: 2.3104822635650635
Validation loss: 2.271791051792842

Epoch: 5| Step: 3
Training loss: 2.617077350616455
Validation loss: 2.264625313461468

Epoch: 5| Step: 4
Training loss: 2.3119423389434814
Validation loss: 2.275187838462091

Epoch: 5| Step: 5
Training loss: 2.5154929161071777
Validation loss: 2.2833110568343953

Epoch: 5| Step: 6
Training loss: 2.903839111328125
Validation loss: 2.286632281477733

Epoch: 5| Step: 7
Training loss: 2.599830389022827
Validation loss: 2.272051949654856

Epoch: 5| Step: 8
Training loss: 2.1279139518737793
Validation loss: 2.2849724318391536

Epoch: 5| Step: 9
Training loss: 3.2464871406555176
Validation loss: 2.288109912667223

Epoch: 5| Step: 10
Training loss: 2.5751233100891113
Validation loss: 2.2933162181608138

Epoch: 101| Step: 0
Training loss: 2.1025197505950928
Validation loss: 2.285611214176301

Epoch: 5| Step: 1
Training loss: 2.727823495864868
Validation loss: 2.269530896217592

Epoch: 5| Step: 2
Training loss: 2.685743808746338
Validation loss: 2.2534277054571334

Epoch: 5| Step: 3
Training loss: 2.3265981674194336
Validation loss: 2.243080131469234

Epoch: 5| Step: 4
Training loss: 2.3625035285949707
Validation loss: 2.2465580817191833

Epoch: 5| Step: 5
Training loss: 2.8294832706451416
Validation loss: 2.251076154811408

Epoch: 5| Step: 6
Training loss: 2.384096145629883
Validation loss: 2.2498837517153834

Epoch: 5| Step: 7
Training loss: 2.938664197921753
Validation loss: 2.248074200845534

Epoch: 5| Step: 8
Training loss: 2.7504684925079346
Validation loss: 2.2485329925373034

Epoch: 5| Step: 9
Training loss: 1.9661632776260376
Validation loss: 2.2620214595589587

Epoch: 5| Step: 10
Training loss: 2.838047742843628
Validation loss: 2.2840827152293217

Epoch: 102| Step: 0
Training loss: 2.271153211593628
Validation loss: 2.2851992627625823

Epoch: 5| Step: 1
Training loss: 2.334582567214966
Validation loss: 2.27784606974612

Epoch: 5| Step: 2
Training loss: 2.4690051078796387
Validation loss: 2.2763813977600424

Epoch: 5| Step: 3
Training loss: 2.858292818069458
Validation loss: 2.2859645774287563

Epoch: 5| Step: 4
Training loss: 2.4273290634155273
Validation loss: 2.259144475383143

Epoch: 5| Step: 5
Training loss: 2.4282848834991455
Validation loss: 2.2460671958102973

Epoch: 5| Step: 6
Training loss: 2.8186516761779785
Validation loss: 2.2436740167679323

Epoch: 5| Step: 7
Training loss: 2.508075714111328
Validation loss: 2.234383906087568

Epoch: 5| Step: 8
Training loss: 2.4440581798553467
Validation loss: 2.2304507916973484

Epoch: 5| Step: 9
Training loss: 3.280879259109497
Validation loss: 2.2320518314197497

Epoch: 5| Step: 10
Training loss: 1.9258489608764648
Validation loss: 2.238474048593993

Epoch: 103| Step: 0
Training loss: 3.066380262374878
Validation loss: 2.2324779546389015

Epoch: 5| Step: 1
Training loss: 2.9950759410858154
Validation loss: 2.2355872943837154

Epoch: 5| Step: 2
Training loss: 2.2048048973083496
Validation loss: 2.2372564295286774

Epoch: 5| Step: 3
Training loss: 2.2882721424102783
Validation loss: 2.2340404756607546

Epoch: 5| Step: 4
Training loss: 2.6402838230133057
Validation loss: 2.2345463486127954

Epoch: 5| Step: 5
Training loss: 2.4674439430236816
Validation loss: 2.23990463185054

Epoch: 5| Step: 6
Training loss: 2.326936960220337
Validation loss: 2.2301853728550736

Epoch: 5| Step: 7
Training loss: 2.4652719497680664
Validation loss: 2.236902226683914

Epoch: 5| Step: 8
Training loss: 2.816800832748413
Validation loss: 2.253938418562694

Epoch: 5| Step: 9
Training loss: 2.314368486404419
Validation loss: 2.2731126892951226

Epoch: 5| Step: 10
Training loss: 2.1109912395477295
Validation loss: 2.275625753146346

Epoch: 104| Step: 0
Training loss: 2.193885326385498
Validation loss: 2.2841548765859296

Epoch: 5| Step: 1
Training loss: 2.9491093158721924
Validation loss: 2.263937411769744

Epoch: 5| Step: 2
Training loss: 2.1216542720794678
Validation loss: 2.262105639262866

Epoch: 5| Step: 3
Training loss: 2.989023208618164
Validation loss: 2.2587776440446095

Epoch: 5| Step: 4
Training loss: 2.3171029090881348
Validation loss: 2.247112852270885

Epoch: 5| Step: 5
Training loss: 1.925378441810608
Validation loss: 2.2399794209387993

Epoch: 5| Step: 6
Training loss: 2.824629306793213
Validation loss: 2.236776646747384

Epoch: 5| Step: 7
Training loss: 2.5562820434570312
Validation loss: 2.229408420542235

Epoch: 5| Step: 8
Training loss: 2.4381561279296875
Validation loss: 2.2359576917463735

Epoch: 5| Step: 9
Training loss: 2.796717882156372
Validation loss: 2.237634297340147

Epoch: 5| Step: 10
Training loss: 2.630192995071411
Validation loss: 2.2499249494203957

Epoch: 105| Step: 0
Training loss: 2.360414981842041
Validation loss: 2.253349757963611

Epoch: 5| Step: 1
Training loss: 2.2355332374572754
Validation loss: 2.2710964910445677

Epoch: 5| Step: 2
Training loss: 2.862689971923828
Validation loss: 2.2654194062755955

Epoch: 5| Step: 3
Training loss: 2.6310875415802
Validation loss: 2.258006129213559

Epoch: 5| Step: 4
Training loss: 2.521838426589966
Validation loss: 2.25113558512862

Epoch: 5| Step: 5
Training loss: 2.5950310230255127
Validation loss: 2.2412200563697406

Epoch: 5| Step: 6
Training loss: 2.3409030437469482
Validation loss: 2.238123097727376

Epoch: 5| Step: 7
Training loss: 2.870436191558838
Validation loss: 2.236201419625231

Epoch: 5| Step: 8
Training loss: 2.666180372238159
Validation loss: 2.232784955732284

Epoch: 5| Step: 9
Training loss: 2.010267734527588
Validation loss: 2.2304369044560257

Epoch: 5| Step: 10
Training loss: 2.4634737968444824
Validation loss: 2.2338159327865927

Epoch: 106| Step: 0
Training loss: 2.3839564323425293
Validation loss: 2.22977622478239

Epoch: 5| Step: 1
Training loss: 2.726160764694214
Validation loss: 2.228812727876889

Epoch: 5| Step: 2
Training loss: 3.204888105392456
Validation loss: 2.234469877776279

Epoch: 5| Step: 3
Training loss: 2.7566447257995605
Validation loss: 2.233150161722655

Epoch: 5| Step: 4
Training loss: 2.3182058334350586
Validation loss: 2.2332744213842575

Epoch: 5| Step: 5
Training loss: 1.9137388467788696
Validation loss: 2.2292797001459266

Epoch: 5| Step: 6
Training loss: 1.8358005285263062
Validation loss: 2.226195699425154

Epoch: 5| Step: 7
Training loss: 3.338099718093872
Validation loss: 2.2252603807756977

Epoch: 5| Step: 8
Training loss: 2.4536314010620117
Validation loss: 2.2242521393683647

Epoch: 5| Step: 9
Training loss: 2.210087776184082
Validation loss: 2.218989395326184

Epoch: 5| Step: 10
Training loss: 2.2784512042999268
Validation loss: 2.2297488874004734

Epoch: 107| Step: 0
Training loss: 3.0699450969696045
Validation loss: 2.2401907854182745

Epoch: 5| Step: 1
Training loss: 2.845139980316162
Validation loss: 2.2593385980975245

Epoch: 5| Step: 2
Training loss: 2.0327553749084473
Validation loss: 2.2683888584054928

Epoch: 5| Step: 3
Training loss: 2.731776475906372
Validation loss: 2.262744079353989

Epoch: 5| Step: 4
Training loss: 2.594155788421631
Validation loss: 2.2514807126855336

Epoch: 5| Step: 5
Training loss: 2.4947621822357178
Validation loss: 2.2360758935251543

Epoch: 5| Step: 6
Training loss: 2.542156457901001
Validation loss: 2.221103396466983

Epoch: 5| Step: 7
Training loss: 2.475656032562256
Validation loss: 2.218180510305589

Epoch: 5| Step: 8
Training loss: 1.985975980758667
Validation loss: 2.2232001596881497

Epoch: 5| Step: 9
Training loss: 2.099801778793335
Validation loss: 2.2171764117415234

Epoch: 5| Step: 10
Training loss: 2.667908191680908
Validation loss: 2.21569638611168

Epoch: 108| Step: 0
Training loss: 2.6392149925231934
Validation loss: 2.217242108878269

Epoch: 5| Step: 1
Training loss: 1.9672677516937256
Validation loss: 2.2159929954877464

Epoch: 5| Step: 2
Training loss: 2.4696335792541504
Validation loss: 2.2146124955146544

Epoch: 5| Step: 3
Training loss: 2.6814119815826416
Validation loss: 2.223004223198019

Epoch: 5| Step: 4
Training loss: 2.812053680419922
Validation loss: 2.226933563909223

Epoch: 5| Step: 5
Training loss: 2.4557747840881348
Validation loss: 2.2490056612158336

Epoch: 5| Step: 6
Training loss: 2.566242218017578
Validation loss: 2.2293323393790954

Epoch: 5| Step: 7
Training loss: 2.2928030490875244
Validation loss: 2.2191134422056136

Epoch: 5| Step: 8
Training loss: 2.1372876167297363
Validation loss: 2.21153845325593

Epoch: 5| Step: 9
Training loss: 2.6006131172180176
Validation loss: 2.211740263046757

Epoch: 5| Step: 10
Training loss: 2.8414981365203857
Validation loss: 2.210297002587267

Epoch: 109| Step: 0
Training loss: 2.3639233112335205
Validation loss: 2.2164958651347826

Epoch: 5| Step: 1
Training loss: 1.724713921546936
Validation loss: 2.2241779552992953

Epoch: 5| Step: 2
Training loss: 2.66633677482605
Validation loss: 2.2316559899237847

Epoch: 5| Step: 3
Training loss: 2.70595121383667
Validation loss: 2.2455119215032107

Epoch: 5| Step: 4
Training loss: 2.9971699714660645
Validation loss: 2.2319211703474804

Epoch: 5| Step: 5
Training loss: 2.457493543624878
Validation loss: 2.2268908049470637

Epoch: 5| Step: 6
Training loss: 2.284496307373047
Validation loss: 2.210507239064863

Epoch: 5| Step: 7
Training loss: 2.4751577377319336
Validation loss: 2.203796539255368

Epoch: 5| Step: 8
Training loss: 2.7481255531311035
Validation loss: 2.199162480651691

Epoch: 5| Step: 9
Training loss: 2.4025120735168457
Validation loss: 2.2059702539956696

Epoch: 5| Step: 10
Training loss: 2.5704874992370605
Validation loss: 2.2009829680124917

Epoch: 110| Step: 0
Training loss: 2.1162056922912598
Validation loss: 2.1951632063875914

Epoch: 5| Step: 1
Training loss: 2.3650288581848145
Validation loss: 2.200894424992223

Epoch: 5| Step: 2
Training loss: 2.1437675952911377
Validation loss: 2.198550990832749

Epoch: 5| Step: 3
Training loss: 2.9095187187194824
Validation loss: 2.1916631088461926

Epoch: 5| Step: 4
Training loss: 2.4026103019714355
Validation loss: 2.1919126023528395

Epoch: 5| Step: 5
Training loss: 2.625373363494873
Validation loss: 2.194608388408538

Epoch: 5| Step: 6
Training loss: 2.352051258087158
Validation loss: 2.1962304833114787

Epoch: 5| Step: 7
Training loss: 2.643871784210205
Validation loss: 2.2037940896967405

Epoch: 5| Step: 8
Training loss: 3.11515212059021
Validation loss: 2.2172226944277362

Epoch: 5| Step: 9
Training loss: 2.3938703536987305
Validation loss: 2.2381022489199074

Epoch: 5| Step: 10
Training loss: 2.1563923358917236
Validation loss: 2.27018924426007

Epoch: 111| Step: 0
Training loss: 2.8948163986206055
Validation loss: 2.266624063573858

Epoch: 5| Step: 1
Training loss: 2.1697752475738525
Validation loss: 2.2441075514721613

Epoch: 5| Step: 2
Training loss: 2.4231667518615723
Validation loss: 2.21699430096534

Epoch: 5| Step: 3
Training loss: 1.8240020275115967
Validation loss: 2.2028832820154007

Epoch: 5| Step: 4
Training loss: 2.3001067638397217
Validation loss: 2.197969618663993

Epoch: 5| Step: 5
Training loss: 2.590851068496704
Validation loss: 2.1882265101196947

Epoch: 5| Step: 6
Training loss: 2.537745952606201
Validation loss: 2.1859149727770077

Epoch: 5| Step: 7
Training loss: 2.68361234664917
Validation loss: 2.18930487222569

Epoch: 5| Step: 8
Training loss: 3.013019561767578
Validation loss: 2.184791200904436

Epoch: 5| Step: 9
Training loss: 2.5389599800109863
Validation loss: 2.1920333959723033

Epoch: 5| Step: 10
Training loss: 2.4858765602111816
Validation loss: 2.2101740580733105

Epoch: 112| Step: 0
Training loss: 2.649106979370117
Validation loss: 2.2109604753473753

Epoch: 5| Step: 1
Training loss: 2.8739266395568848
Validation loss: 2.2113518548268143

Epoch: 5| Step: 2
Training loss: 2.6483845710754395
Validation loss: 2.207873462348856

Epoch: 5| Step: 3
Training loss: 2.6436386108398438
Validation loss: 2.2058325300934496

Epoch: 5| Step: 4
Training loss: 3.218667984008789
Validation loss: 2.1969037414878927

Epoch: 5| Step: 5
Training loss: 2.3816006183624268
Validation loss: 2.189653150496944

Epoch: 5| Step: 6
Training loss: 1.7719637155532837
Validation loss: 2.195070510269493

Epoch: 5| Step: 7
Training loss: 2.0560827255249023
Validation loss: 2.194679937055034

Epoch: 5| Step: 8
Training loss: 2.3237051963806152
Validation loss: 2.193099352621263

Epoch: 5| Step: 9
Training loss: 2.2705047130584717
Validation loss: 2.184151969930177

Epoch: 5| Step: 10
Training loss: 2.2008512020111084
Validation loss: 2.1816846452733523

Epoch: 113| Step: 0
Training loss: 2.2613110542297363
Validation loss: 2.1834495682870187

Epoch: 5| Step: 1
Training loss: 2.1484005451202393
Validation loss: 2.182484121732814

Epoch: 5| Step: 2
Training loss: 2.0665557384490967
Validation loss: 2.186358813316591

Epoch: 5| Step: 3
Training loss: 2.698833703994751
Validation loss: 2.1869962292332805

Epoch: 5| Step: 4
Training loss: 2.5700719356536865
Validation loss: 2.193568019456761

Epoch: 5| Step: 5
Training loss: 2.3718154430389404
Validation loss: 2.1961578810086815

Epoch: 5| Step: 6
Training loss: 2.1870224475860596
Validation loss: 2.1882557971503145

Epoch: 5| Step: 7
Training loss: 2.726047992706299
Validation loss: 2.1859819773704774

Epoch: 5| Step: 8
Training loss: 2.948633909225464
Validation loss: 2.1953755783778366

Epoch: 5| Step: 9
Training loss: 2.586136817932129
Validation loss: 2.1929804842959166

Epoch: 5| Step: 10
Training loss: 2.487046003341675
Validation loss: 2.1799906043596167

Epoch: 114| Step: 0
Training loss: 2.3307483196258545
Validation loss: 2.167786552060035

Epoch: 5| Step: 1
Training loss: 3.0805234909057617
Validation loss: 2.159995568695889

Epoch: 5| Step: 2
Training loss: 2.536829948425293
Validation loss: 2.1707215488597913

Epoch: 5| Step: 3
Training loss: 2.268197536468506
Validation loss: 2.1634027496460946

Epoch: 5| Step: 4
Training loss: 2.5297279357910156
Validation loss: 2.1632105945259013

Epoch: 5| Step: 5
Training loss: 2.313004732131958
Validation loss: 2.1585354753719863

Epoch: 5| Step: 6
Training loss: 2.809506893157959
Validation loss: 2.160078058960617

Epoch: 5| Step: 7
Training loss: 2.33119535446167
Validation loss: 2.155115601836994

Epoch: 5| Step: 8
Training loss: 1.892976999282837
Validation loss: 2.161943543341852

Epoch: 5| Step: 9
Training loss: 2.666637897491455
Validation loss: 2.1743677892992572

Epoch: 5| Step: 10
Training loss: 2.311558723449707
Validation loss: 2.2045572547502417

Epoch: 115| Step: 0
Training loss: 1.9349359273910522
Validation loss: 2.2243209064647718

Epoch: 5| Step: 1
Training loss: 2.4430744647979736
Validation loss: 2.245347971557289

Epoch: 5| Step: 2
Training loss: 2.493521213531494
Validation loss: 2.242934657681373

Epoch: 5| Step: 3
Training loss: 2.4399971961975098
Validation loss: 2.227264763206564

Epoch: 5| Step: 4
Training loss: 2.57432222366333
Validation loss: 2.2111199350767237

Epoch: 5| Step: 5
Training loss: 2.5561840534210205
Validation loss: 2.1904006734971078

Epoch: 5| Step: 6
Training loss: 2.1742517948150635
Validation loss: 2.1683790478655087

Epoch: 5| Step: 7
Training loss: 2.693197250366211
Validation loss: 2.160310645257273

Epoch: 5| Step: 8
Training loss: 2.6700661182403564
Validation loss: 2.1531796275928454

Epoch: 5| Step: 9
Training loss: 2.606600761413574
Validation loss: 2.1573697367022113

Epoch: 5| Step: 10
Training loss: 2.540773630142212
Validation loss: 2.1550494163267073

Epoch: 116| Step: 0
Training loss: 2.1139750480651855
Validation loss: 2.1594489710305327

Epoch: 5| Step: 1
Training loss: 2.364208698272705
Validation loss: 2.1557384819112797

Epoch: 5| Step: 2
Training loss: 2.5693371295928955
Validation loss: 2.1442937363860426

Epoch: 5| Step: 3
Training loss: 2.8591742515563965
Validation loss: 2.154045779217956

Epoch: 5| Step: 4
Training loss: 2.3086342811584473
Validation loss: 2.164971523387458

Epoch: 5| Step: 5
Training loss: 2.3179614543914795
Validation loss: 2.1689025279014342

Epoch: 5| Step: 6
Training loss: 2.8327810764312744
Validation loss: 2.1682370811380367

Epoch: 5| Step: 7
Training loss: 2.666701316833496
Validation loss: 2.175873197535033

Epoch: 5| Step: 8
Training loss: 2.011354923248291
Validation loss: 2.1721256343267297

Epoch: 5| Step: 9
Training loss: 2.043999433517456
Validation loss: 2.163892415262038

Epoch: 5| Step: 10
Training loss: 2.881788492202759
Validation loss: 2.159910078971617

Epoch: 117| Step: 0
Training loss: 2.2581863403320312
Validation loss: 2.1456721662193217

Epoch: 5| Step: 1
Training loss: 2.0079307556152344
Validation loss: 2.1506675840705953

Epoch: 5| Step: 2
Training loss: 2.441955089569092
Validation loss: 2.15357300543016

Epoch: 5| Step: 3
Training loss: 2.527127742767334
Validation loss: 2.1530626922525387

Epoch: 5| Step: 4
Training loss: 2.4366865158081055
Validation loss: 2.1526114402278775

Epoch: 5| Step: 5
Training loss: 2.6729750633239746
Validation loss: 2.15531543121543

Epoch: 5| Step: 6
Training loss: 2.351519823074341
Validation loss: 2.1563335618665143

Epoch: 5| Step: 7
Training loss: 2.5317373275756836
Validation loss: 2.1562861242601947

Epoch: 5| Step: 8
Training loss: 2.4434971809387207
Validation loss: 2.166035852124614

Epoch: 5| Step: 9
Training loss: 2.576838254928589
Validation loss: 2.177607395315683

Epoch: 5| Step: 10
Training loss: 2.564678907394409
Validation loss: 2.181208065761033

Epoch: 118| Step: 0
Training loss: 2.1360549926757812
Validation loss: 2.1833486736461682

Epoch: 5| Step: 1
Training loss: 3.3016059398651123
Validation loss: 2.180526469343452

Epoch: 5| Step: 2
Training loss: 2.053269147872925
Validation loss: 2.178856506142565

Epoch: 5| Step: 3
Training loss: 2.4168860912323
Validation loss: 2.157411236916819

Epoch: 5| Step: 4
Training loss: 2.495483875274658
Validation loss: 2.1541444793824227

Epoch: 5| Step: 5
Training loss: 2.4479501247406006
Validation loss: 2.151596979428363

Epoch: 5| Step: 6
Training loss: 1.8922134637832642
Validation loss: 2.1584277537561234

Epoch: 5| Step: 7
Training loss: 2.2834858894348145
Validation loss: 2.159331721644248

Epoch: 5| Step: 8
Training loss: 2.7708182334899902
Validation loss: 2.163183181516586

Epoch: 5| Step: 9
Training loss: 2.938045024871826
Validation loss: 2.1653610173092095

Epoch: 5| Step: 10
Training loss: 1.8804192543029785
Validation loss: 2.1543218628052743

Epoch: 119| Step: 0
Training loss: 2.2870266437530518
Validation loss: 2.1471550708175986

Epoch: 5| Step: 1
Training loss: 2.2795305252075195
Validation loss: 2.1494482614660777

Epoch: 5| Step: 2
Training loss: 2.3548007011413574
Validation loss: 2.1479069109885924

Epoch: 5| Step: 3
Training loss: 2.5093994140625
Validation loss: 2.1522214951053744

Epoch: 5| Step: 4
Training loss: 1.8438794612884521
Validation loss: 2.1558159218039563

Epoch: 5| Step: 5
Training loss: 2.033160924911499
Validation loss: 2.1622440943153958

Epoch: 5| Step: 6
Training loss: 2.425877094268799
Validation loss: 2.167172965183053

Epoch: 5| Step: 7
Training loss: 3.4713950157165527
Validation loss: 2.1698561868359967

Epoch: 5| Step: 8
Training loss: 2.5755980014801025
Validation loss: 2.168666878054219

Epoch: 5| Step: 9
Training loss: 2.589168071746826
Validation loss: 2.156119341491371

Epoch: 5| Step: 10
Training loss: 2.251572608947754
Validation loss: 2.167685049836354

Epoch: 120| Step: 0
Training loss: 1.7258212566375732
Validation loss: 2.153570081598015

Epoch: 5| Step: 1
Training loss: 2.691321611404419
Validation loss: 2.154830836480664

Epoch: 5| Step: 2
Training loss: 3.225409984588623
Validation loss: 2.1508431947359474

Epoch: 5| Step: 3
Training loss: 1.8404680490493774
Validation loss: 2.150980311055337

Epoch: 5| Step: 4
Training loss: 2.798790693283081
Validation loss: 2.149468918000498

Epoch: 5| Step: 5
Training loss: 2.557650566101074
Validation loss: 2.1490685632151942

Epoch: 5| Step: 6
Training loss: 1.6239932775497437
Validation loss: 2.14535108945703

Epoch: 5| Step: 7
Training loss: 2.6545348167419434
Validation loss: 2.1503386766679826

Epoch: 5| Step: 8
Training loss: 2.065793991088867
Validation loss: 2.153958443672426

Epoch: 5| Step: 9
Training loss: 2.696725845336914
Validation loss: 2.145042832179736

Epoch: 5| Step: 10
Training loss: 2.713413715362549
Validation loss: 2.150983795042961

Epoch: 121| Step: 0
Training loss: 2.328137159347534
Validation loss: 2.1479715711327008

Epoch: 5| Step: 1
Training loss: 2.2415730953216553
Validation loss: 2.155492815920102

Epoch: 5| Step: 2
Training loss: 2.500774621963501
Validation loss: 2.157595129423244

Epoch: 5| Step: 3
Training loss: 2.9861221313476562
Validation loss: 2.1563786998871834

Epoch: 5| Step: 4
Training loss: 2.336641788482666
Validation loss: 2.1486547711074993

Epoch: 5| Step: 5
Training loss: 1.9522138833999634
Validation loss: 2.146943502528693

Epoch: 5| Step: 6
Training loss: 2.1030664443969727
Validation loss: 2.1350092682787167

Epoch: 5| Step: 7
Training loss: 2.513772487640381
Validation loss: 2.129425210337485

Epoch: 5| Step: 8
Training loss: 2.9002840518951416
Validation loss: 2.1255279189796856

Epoch: 5| Step: 9
Training loss: 2.054068088531494
Validation loss: 2.1366372954460884

Epoch: 5| Step: 10
Training loss: 2.5130455493927
Validation loss: 2.1342032968357043

Epoch: 122| Step: 0
Training loss: 2.860011339187622
Validation loss: 2.1423749308432303

Epoch: 5| Step: 1
Training loss: 1.8127200603485107
Validation loss: 2.161551493470387

Epoch: 5| Step: 2
Training loss: 2.727024555206299
Validation loss: 2.155730062915433

Epoch: 5| Step: 3
Training loss: 2.215832233428955
Validation loss: 2.1411286964211413

Epoch: 5| Step: 4
Training loss: 2.3312571048736572
Validation loss: 2.1278702264191

Epoch: 5| Step: 5
Training loss: 2.4749388694763184
Validation loss: 2.1218729890802854

Epoch: 5| Step: 6
Training loss: 2.3375773429870605
Validation loss: 2.1265262249977357

Epoch: 5| Step: 7
Training loss: 1.8062143325805664
Validation loss: 2.1237496201710035

Epoch: 5| Step: 8
Training loss: 2.7697877883911133
Validation loss: 2.13014849411544

Epoch: 5| Step: 9
Training loss: 2.444859266281128
Validation loss: 2.1288412437644055

Epoch: 5| Step: 10
Training loss: 2.786292552947998
Validation loss: 2.1226714567471574

Epoch: 123| Step: 0
Training loss: 2.089500665664673
Validation loss: 2.1263896137155514

Epoch: 5| Step: 1
Training loss: 2.1102473735809326
Validation loss: 2.1365344139837448

Epoch: 5| Step: 2
Training loss: 2.4602599143981934
Validation loss: 2.133045715670432

Epoch: 5| Step: 3
Training loss: 2.0320887565612793
Validation loss: 2.141506323250391

Epoch: 5| Step: 4
Training loss: 2.200606107711792
Validation loss: 2.1545787998425063

Epoch: 5| Step: 5
Training loss: 2.5812032222747803
Validation loss: 2.162483507587064

Epoch: 5| Step: 6
Training loss: 2.3946402072906494
Validation loss: 2.1524469672992663

Epoch: 5| Step: 7
Training loss: 2.1894965171813965
Validation loss: 2.1415242456620738

Epoch: 5| Step: 8
Training loss: 2.1434643268585205
Validation loss: 2.1374974122611423

Epoch: 5| Step: 9
Training loss: 2.9556379318237305
Validation loss: 2.132163869437351

Epoch: 5| Step: 10
Training loss: 3.352804183959961
Validation loss: 2.1269430588650446

Epoch: 124| Step: 0
Training loss: 2.725656032562256
Validation loss: 2.1224174832785003

Epoch: 5| Step: 1
Training loss: 2.728356122970581
Validation loss: 2.117464091188164

Epoch: 5| Step: 2
Training loss: 1.9175399541854858
Validation loss: 2.1189275069903304

Epoch: 5| Step: 3
Training loss: 2.6650469303131104
Validation loss: 2.1203254012651342

Epoch: 5| Step: 4
Training loss: 3.104588747024536
Validation loss: 2.135007378875568

Epoch: 5| Step: 5
Training loss: 2.152763605117798
Validation loss: 2.1475123820766324

Epoch: 5| Step: 6
Training loss: 2.627814531326294
Validation loss: 2.1506458520889282

Epoch: 5| Step: 7
Training loss: 1.8632924556732178
Validation loss: 2.158085646167878

Epoch: 5| Step: 8
Training loss: 1.9957844018936157
Validation loss: 2.1451012716498425

Epoch: 5| Step: 9
Training loss: 2.3471992015838623
Validation loss: 2.138706777685432

Epoch: 5| Step: 10
Training loss: 2.283656358718872
Validation loss: 2.1197872982230237

Epoch: 125| Step: 0
Training loss: 2.4889018535614014
Validation loss: 2.1167665796895183

Epoch: 5| Step: 1
Training loss: 2.1450552940368652
Validation loss: 2.1074183038485947

Epoch: 5| Step: 2
Training loss: 2.2238495349884033
Validation loss: 2.1170512809548327

Epoch: 5| Step: 3
Training loss: 1.9516147375106812
Validation loss: 2.1037723300277547

Epoch: 5| Step: 4
Training loss: 2.990605115890503
Validation loss: 2.1044287989216466

Epoch: 5| Step: 5
Training loss: 2.2514922618865967
Validation loss: 2.100971244996594

Epoch: 5| Step: 6
Training loss: 2.269636869430542
Validation loss: 2.1105220266567764

Epoch: 5| Step: 7
Training loss: 2.5450081825256348
Validation loss: 2.109568547177058

Epoch: 5| Step: 8
Training loss: 2.5844886302948
Validation loss: 2.110595956925423

Epoch: 5| Step: 9
Training loss: 2.4757819175720215
Validation loss: 2.1231526379944174

Epoch: 5| Step: 10
Training loss: 2.3239026069641113
Validation loss: 2.1510950980647916

Epoch: 126| Step: 0
Training loss: 2.3382456302642822
Validation loss: 2.176930809533724

Epoch: 5| Step: 1
Training loss: 2.2808680534362793
Validation loss: 2.1797237037330546

Epoch: 5| Step: 2
Training loss: 2.475795269012451
Validation loss: 2.141167425340222

Epoch: 5| Step: 3
Training loss: 2.686262845993042
Validation loss: 2.116957046652353

Epoch: 5| Step: 4
Training loss: 2.6239519119262695
Validation loss: 2.1123378135824717

Epoch: 5| Step: 5
Training loss: 2.6524670124053955
Validation loss: 2.1207923966069377

Epoch: 5| Step: 6
Training loss: 1.8801075220108032
Validation loss: 2.114386098359221

Epoch: 5| Step: 7
Training loss: 2.8726444244384766
Validation loss: 2.1541349298210553

Epoch: 5| Step: 8
Training loss: 2.738185167312622
Validation loss: 2.182708401833811

Epoch: 5| Step: 9
Training loss: 2.054464340209961
Validation loss: 2.1680495713346746

Epoch: 5| Step: 10
Training loss: 2.056598424911499
Validation loss: 2.1579327685858614

Epoch: 127| Step: 0
Training loss: 2.0490658283233643
Validation loss: 2.1371535049971713

Epoch: 5| Step: 1
Training loss: 2.2927777767181396
Validation loss: 2.1310838550649662

Epoch: 5| Step: 2
Training loss: 2.318131923675537
Validation loss: 2.1531904948654996

Epoch: 5| Step: 3
Training loss: 2.4122314453125
Validation loss: 2.159922267801018

Epoch: 5| Step: 4
Training loss: 2.440330982208252
Validation loss: 2.150512836312735

Epoch: 5| Step: 5
Training loss: 2.492832660675049
Validation loss: 2.1470326531317925

Epoch: 5| Step: 6
Training loss: 2.432466745376587
Validation loss: 2.123488956882108

Epoch: 5| Step: 7
Training loss: 2.848259210586548
Validation loss: 2.1031398106646795

Epoch: 5| Step: 8
Training loss: 2.212740659713745
Validation loss: 2.100429488766578

Epoch: 5| Step: 9
Training loss: 2.141197919845581
Validation loss: 2.0899958328534196

Epoch: 5| Step: 10
Training loss: 2.8371522426605225
Validation loss: 2.0946481458602415

Epoch: 128| Step: 0
Training loss: 2.735860824584961
Validation loss: 2.1003424685488463

Epoch: 5| Step: 1
Training loss: 1.8837034702301025
Validation loss: 2.108649574300294

Epoch: 5| Step: 2
Training loss: 2.4180476665496826
Validation loss: 2.1113149824962822

Epoch: 5| Step: 3
Training loss: 1.9537286758422852
Validation loss: 2.1038083004695114

Epoch: 5| Step: 4
Training loss: 2.582763433456421
Validation loss: 2.123861397466352

Epoch: 5| Step: 5
Training loss: 2.5256853103637695
Validation loss: 2.144988230479661

Epoch: 5| Step: 6
Training loss: 3.1129403114318848
Validation loss: 2.1660664671210834

Epoch: 5| Step: 7
Training loss: 2.2609469890594482
Validation loss: 2.173034485950265

Epoch: 5| Step: 8
Training loss: 2.4847559928894043
Validation loss: 2.1800983208481983

Epoch: 5| Step: 9
Training loss: 2.3381402492523193
Validation loss: 2.152494039586795

Epoch: 5| Step: 10
Training loss: 2.305332899093628
Validation loss: 2.1257833665417087

Epoch: 129| Step: 0
Training loss: 2.1005756855010986
Validation loss: 2.098996736670053

Epoch: 5| Step: 1
Training loss: 2.768477201461792
Validation loss: 2.085195915673369

Epoch: 5| Step: 2
Training loss: 2.0851516723632812
Validation loss: 2.0970479929318993

Epoch: 5| Step: 3
Training loss: 2.824502468109131
Validation loss: 2.1025800628046833

Epoch: 5| Step: 4
Training loss: 2.6474099159240723
Validation loss: 2.128864812594588

Epoch: 5| Step: 5
Training loss: 2.1610846519470215
Validation loss: 2.1833686956795315

Epoch: 5| Step: 6
Training loss: 2.8478221893310547
Validation loss: 2.2174665774068525

Epoch: 5| Step: 7
Training loss: 2.889859914779663
Validation loss: 2.210667728095926

Epoch: 5| Step: 8
Training loss: 2.0224623680114746
Validation loss: 2.1636712871572024

Epoch: 5| Step: 9
Training loss: 1.838884711265564
Validation loss: 2.1226538765814995

Epoch: 5| Step: 10
Training loss: 2.572641611099243
Validation loss: 2.1023618328955864

Epoch: 130| Step: 0
Training loss: 1.7642244100570679
Validation loss: 2.107848600674701

Epoch: 5| Step: 1
Training loss: 2.717573881149292
Validation loss: 2.1073968179764284

Epoch: 5| Step: 2
Training loss: 2.346693515777588
Validation loss: 2.1233231162512176

Epoch: 5| Step: 3
Training loss: 1.8708372116088867
Validation loss: 2.119877028208907

Epoch: 5| Step: 4
Training loss: 2.793067455291748
Validation loss: 2.119888919655995

Epoch: 5| Step: 5
Training loss: 2.4092631340026855
Validation loss: 2.115319385323473

Epoch: 5| Step: 6
Training loss: 2.66563081741333
Validation loss: 2.111483948205107

Epoch: 5| Step: 7
Training loss: 2.6804256439208984
Validation loss: 2.1257040167367585

Epoch: 5| Step: 8
Training loss: 2.051339626312256
Validation loss: 2.104720487389513

Epoch: 5| Step: 9
Training loss: 2.4343037605285645
Validation loss: 2.0938481053998395

Epoch: 5| Step: 10
Training loss: 2.718169927597046
Validation loss: 2.0819901856043006

Epoch: 131| Step: 0
Training loss: 2.250807046890259
Validation loss: 2.080611485306935

Epoch: 5| Step: 1
Training loss: 2.952089309692383
Validation loss: 2.083146519558404

Epoch: 5| Step: 2
Training loss: 2.0888049602508545
Validation loss: 2.084878008852723

Epoch: 5| Step: 3
Training loss: 2.0893537998199463
Validation loss: 2.0788160947061356

Epoch: 5| Step: 4
Training loss: 3.4403839111328125
Validation loss: 2.0726997339597313

Epoch: 5| Step: 5
Training loss: 2.3257036209106445
Validation loss: 2.05906436263874

Epoch: 5| Step: 6
Training loss: 1.9057703018188477
Validation loss: 2.0643654548993675

Epoch: 5| Step: 7
Training loss: 1.9538596868515015
Validation loss: 2.0546143298508017

Epoch: 5| Step: 8
Training loss: 2.0914626121520996
Validation loss: 2.0560024810093704

Epoch: 5| Step: 9
Training loss: 2.1820759773254395
Validation loss: 2.0642248943287838

Epoch: 5| Step: 10
Training loss: 2.8677639961242676
Validation loss: 2.0557406461367043

Epoch: 132| Step: 0
Training loss: 2.5273070335388184
Validation loss: 2.0640816598810177

Epoch: 5| Step: 1
Training loss: 2.1350936889648438
Validation loss: 2.054791381282191

Epoch: 5| Step: 2
Training loss: 2.073249340057373
Validation loss: 2.0622228358381536

Epoch: 5| Step: 3
Training loss: 2.34779691696167
Validation loss: 2.061682606256136

Epoch: 5| Step: 4
Training loss: 3.005927324295044
Validation loss: 2.060400770556542

Epoch: 5| Step: 5
Training loss: 2.4975991249084473
Validation loss: 2.0625952443768902

Epoch: 5| Step: 6
Training loss: 1.8763738870620728
Validation loss: 2.0671000326833417

Epoch: 5| Step: 7
Training loss: 2.5853912830352783
Validation loss: 2.0863369382837766

Epoch: 5| Step: 8
Training loss: 1.84358811378479
Validation loss: 2.0876769506803123

Epoch: 5| Step: 9
Training loss: 2.3412158489227295
Validation loss: 2.0794952428469093

Epoch: 5| Step: 10
Training loss: 2.7428040504455566
Validation loss: 2.0606652305972193

Epoch: 133| Step: 0
Training loss: 2.3660571575164795
Validation loss: 2.0518100953871206

Epoch: 5| Step: 1
Training loss: 2.0636439323425293
Validation loss: 2.057721837874382

Epoch: 5| Step: 2
Training loss: 2.4470455646514893
Validation loss: 2.0555868123167302

Epoch: 5| Step: 3
Training loss: 2.3957297801971436
Validation loss: 2.0607168443741335

Epoch: 5| Step: 4
Training loss: 1.9111697673797607
Validation loss: 2.055318711906351

Epoch: 5| Step: 5
Training loss: 3.14020037651062
Validation loss: 2.0600585117134997

Epoch: 5| Step: 6
Training loss: 2.0285723209381104
Validation loss: 2.0602969866926952

Epoch: 5| Step: 7
Training loss: 2.410226345062256
Validation loss: 2.0761323282795567

Epoch: 5| Step: 8
Training loss: 2.283078908920288
Validation loss: 2.0757651713586625

Epoch: 5| Step: 9
Training loss: 2.2967000007629395
Validation loss: 2.0792357613963466

Epoch: 5| Step: 10
Training loss: 2.4342732429504395
Validation loss: 2.092274720950793

Epoch: 134| Step: 0
Training loss: 2.5811660289764404
Validation loss: 2.096237820963706

Epoch: 5| Step: 1
Training loss: 1.9893468618392944
Validation loss: 2.090064125676309

Epoch: 5| Step: 2
Training loss: 2.710218667984009
Validation loss: 2.0775659315047728

Epoch: 5| Step: 3
Training loss: 2.4068329334259033
Validation loss: 2.06738797567224

Epoch: 5| Step: 4
Training loss: 2.7499592304229736
Validation loss: 2.060470211890436

Epoch: 5| Step: 5
Training loss: 2.7972567081451416
Validation loss: 2.0613243400409655

Epoch: 5| Step: 6
Training loss: 2.051149368286133
Validation loss: 2.0580231451219126

Epoch: 5| Step: 7
Training loss: 2.1492061614990234
Validation loss: 2.055142705158521

Epoch: 5| Step: 8
Training loss: 2.279120683670044
Validation loss: 2.0590010612241683

Epoch: 5| Step: 9
Training loss: 2.2042653560638428
Validation loss: 2.05560500391068

Epoch: 5| Step: 10
Training loss: 1.681524395942688
Validation loss: 2.060976711652612

Epoch: 135| Step: 0
Training loss: 2.10862398147583
Validation loss: 2.0704623422315045

Epoch: 5| Step: 1
Training loss: 2.2383742332458496
Validation loss: 2.0752937370730984

Epoch: 5| Step: 2
Training loss: 2.337562084197998
Validation loss: 2.0758828206728865

Epoch: 5| Step: 3
Training loss: 2.5677151679992676
Validation loss: 2.086982309177358

Epoch: 5| Step: 4
Training loss: 2.1418418884277344
Validation loss: 2.0800011491262786

Epoch: 5| Step: 5
Training loss: 2.0273053646087646
Validation loss: 2.0758158212066977

Epoch: 5| Step: 6
Training loss: 2.473531723022461
Validation loss: 2.079857490395987

Epoch: 5| Step: 7
Training loss: 2.8877453804016113
Validation loss: 2.0868930957650624

Epoch: 5| Step: 8
Training loss: 2.6574432849884033
Validation loss: 2.077805026885002

Epoch: 5| Step: 9
Training loss: 2.368732452392578
Validation loss: 2.080438256263733

Epoch: 5| Step: 10
Training loss: 1.7799772024154663
Validation loss: 2.0711434310482395

Epoch: 136| Step: 0
Training loss: 2.69789457321167
Validation loss: 2.073156677266603

Epoch: 5| Step: 1
Training loss: 1.9761196374893188
Validation loss: 2.0680109480375886

Epoch: 5| Step: 2
Training loss: 2.2475457191467285
Validation loss: 2.0663422358933317

Epoch: 5| Step: 3
Training loss: 2.5072314739227295
Validation loss: 2.060950397163309

Epoch: 5| Step: 4
Training loss: 2.6689720153808594
Validation loss: 2.054582872698384

Epoch: 5| Step: 5
Training loss: 2.7893824577331543
Validation loss: 2.057188819813472

Epoch: 5| Step: 6
Training loss: 1.4915982484817505
Validation loss: 2.061188465805464

Epoch: 5| Step: 7
Training loss: 1.8737539052963257
Validation loss: 2.050360124598267

Epoch: 5| Step: 8
Training loss: 2.3145649433135986
Validation loss: 2.0518820439615557

Epoch: 5| Step: 9
Training loss: 2.3337459564208984
Validation loss: 2.052832866227755

Epoch: 5| Step: 10
Training loss: 2.709577798843384
Validation loss: 2.048709561747889

Epoch: 137| Step: 0
Training loss: 2.7957615852355957
Validation loss: 2.058797687612554

Epoch: 5| Step: 1
Training loss: 2.5125327110290527
Validation loss: 2.054111862695345

Epoch: 5| Step: 2
Training loss: 2.062283515930176
Validation loss: 2.061951441149558

Epoch: 5| Step: 3
Training loss: 1.8648265600204468
Validation loss: 2.067512127660936

Epoch: 5| Step: 4
Training loss: 2.232819080352783
Validation loss: 2.067047888232816

Epoch: 5| Step: 5
Training loss: 2.544161558151245
Validation loss: 2.059223093012328

Epoch: 5| Step: 6
Training loss: 2.5128893852233887
Validation loss: 2.0748253663380942

Epoch: 5| Step: 7
Training loss: 2.443082094192505
Validation loss: 2.0807387546826432

Epoch: 5| Step: 8
Training loss: 2.6765332221984863
Validation loss: 2.082145763981727

Epoch: 5| Step: 9
Training loss: 2.2884602546691895
Validation loss: 2.0914215913382908

Epoch: 5| Step: 10
Training loss: 2.029820680618286
Validation loss: 2.1003798489929526

Epoch: 138| Step: 0
Training loss: 2.3450703620910645
Validation loss: 2.104949382043654

Epoch: 5| Step: 1
Training loss: 2.494035482406616
Validation loss: 2.0857871886222594

Epoch: 5| Step: 2
Training loss: 2.3468146324157715
Validation loss: 2.0500086148579917

Epoch: 5| Step: 3
Training loss: 2.1665947437286377
Validation loss: 2.0463108606235956

Epoch: 5| Step: 4
Training loss: 2.1225533485412598
Validation loss: 2.0530896417556272

Epoch: 5| Step: 5
Training loss: 2.4119856357574463
Validation loss: 2.0487170142512166

Epoch: 5| Step: 6
Training loss: 2.3492374420166016
Validation loss: 2.0810617285390056

Epoch: 5| Step: 7
Training loss: 2.465096950531006
Validation loss: 2.106293991047849

Epoch: 5| Step: 8
Training loss: 2.3089635372161865
Validation loss: 2.1183900653675036

Epoch: 5| Step: 9
Training loss: 2.4675188064575195
Validation loss: 2.1055093093584945

Epoch: 5| Step: 10
Training loss: 2.16196608543396
Validation loss: 2.0639710862149476

Epoch: 139| Step: 0
Training loss: 2.548788547515869
Validation loss: 2.0570707295530584

Epoch: 5| Step: 1
Training loss: 2.2943830490112305
Validation loss: 2.045724002263879

Epoch: 5| Step: 2
Training loss: 2.861114025115967
Validation loss: 2.0413677589867705

Epoch: 5| Step: 3
Training loss: 1.2056838274002075
Validation loss: 2.0545238500000327

Epoch: 5| Step: 4
Training loss: 2.385488986968994
Validation loss: 2.0568115249756844

Epoch: 5| Step: 5
Training loss: 2.0373122692108154
Validation loss: 2.0606161984064246

Epoch: 5| Step: 6
Training loss: 2.281480073928833
Validation loss: 2.072256700966948

Epoch: 5| Step: 7
Training loss: 2.388101100921631
Validation loss: 2.0870936198901107

Epoch: 5| Step: 8
Training loss: 2.166898727416992
Validation loss: 2.0790334414410334

Epoch: 5| Step: 9
Training loss: 2.4056413173675537
Validation loss: 2.053958741567468

Epoch: 5| Step: 10
Training loss: 3.236071825027466
Validation loss: 2.0654497300424883

Epoch: 140| Step: 0
Training loss: 2.2232720851898193
Validation loss: 2.0571612209402104

Epoch: 5| Step: 1
Training loss: 2.2816975116729736
Validation loss: 2.06251766861126

Epoch: 5| Step: 2
Training loss: 1.9230352640151978
Validation loss: 2.0407942302765383

Epoch: 5| Step: 3
Training loss: 2.3608200550079346
Validation loss: 2.0414088131279073

Epoch: 5| Step: 4
Training loss: 2.090406894683838
Validation loss: 2.042258967635452

Epoch: 5| Step: 5
Training loss: 1.8007444143295288
Validation loss: 2.041632548455269

Epoch: 5| Step: 6
Training loss: 2.360271453857422
Validation loss: 2.032617279278335

Epoch: 5| Step: 7
Training loss: 2.73197603225708
Validation loss: 2.030299284124887

Epoch: 5| Step: 8
Training loss: 2.848245143890381
Validation loss: 2.0312790101574314

Epoch: 5| Step: 9
Training loss: 1.9117610454559326
Validation loss: 2.025881382726854

Epoch: 5| Step: 10
Training loss: 3.052086353302002
Validation loss: 2.020119119715947

Epoch: 141| Step: 0
Training loss: 1.5434484481811523
Validation loss: 2.028196960367182

Epoch: 5| Step: 1
Training loss: 2.218905448913574
Validation loss: 2.0333311942315873

Epoch: 5| Step: 2
Training loss: 2.517021417617798
Validation loss: 2.052956017114783

Epoch: 5| Step: 3
Training loss: 1.5154863595962524
Validation loss: 2.065160233487365

Epoch: 5| Step: 4
Training loss: 2.7192652225494385
Validation loss: 2.0621372474137174

Epoch: 5| Step: 5
Training loss: 2.6383872032165527
Validation loss: 2.0698861845078005

Epoch: 5| Step: 6
Training loss: 2.4645609855651855
Validation loss: 2.067166360475684

Epoch: 5| Step: 7
Training loss: 2.5953307151794434
Validation loss: 2.069935788390457

Epoch: 5| Step: 8
Training loss: 1.6700252294540405
Validation loss: 2.071931815916492

Epoch: 5| Step: 9
Training loss: 3.251671552658081
Validation loss: 2.077607544519568

Epoch: 5| Step: 10
Training loss: 2.4936366081237793
Validation loss: 2.0828458955211024

Epoch: 142| Step: 0
Training loss: 2.13269305229187
Validation loss: 2.086910864358307

Epoch: 5| Step: 1
Training loss: 2.945261240005493
Validation loss: 2.085909729362816

Epoch: 5| Step: 2
Training loss: 2.352699041366577
Validation loss: 2.0975438394854145

Epoch: 5| Step: 3
Training loss: 3.2101612091064453
Validation loss: 2.0925550640270276

Epoch: 5| Step: 4
Training loss: 1.9346420764923096
Validation loss: 2.100014651975324

Epoch: 5| Step: 5
Training loss: 2.3339004516601562
Validation loss: 2.0811119335953907

Epoch: 5| Step: 6
Training loss: 2.843407154083252
Validation loss: 2.0753757671643327

Epoch: 5| Step: 7
Training loss: 2.106916904449463
Validation loss: 2.07353868920316

Epoch: 5| Step: 8
Training loss: 2.5349841117858887
Validation loss: 2.0786776747754825

Epoch: 5| Step: 9
Training loss: 1.7226636409759521
Validation loss: 2.091752249707458

Epoch: 5| Step: 10
Training loss: 1.7564111948013306
Validation loss: 2.102227921126991

Epoch: 143| Step: 0
Training loss: 2.4583353996276855
Validation loss: 2.088780910738053

Epoch: 5| Step: 1
Training loss: 1.8806571960449219
Validation loss: 2.0856610318665862

Epoch: 5| Step: 2
Training loss: 1.7073137760162354
Validation loss: 2.06717332460547

Epoch: 5| Step: 3
Training loss: 1.624582052230835
Validation loss: 2.059586460872363

Epoch: 5| Step: 4
Training loss: 2.135462522506714
Validation loss: 2.059192395979358

Epoch: 5| Step: 5
Training loss: 2.7750773429870605
Validation loss: 2.068482728414638

Epoch: 5| Step: 6
Training loss: 3.1527743339538574
Validation loss: 2.073937128948909

Epoch: 5| Step: 7
Training loss: 2.5749306678771973
Validation loss: 2.07087585362055

Epoch: 5| Step: 8
Training loss: 2.396271228790283
Validation loss: 2.066746216948314

Epoch: 5| Step: 9
Training loss: 2.4500985145568848
Validation loss: 2.07034384563405

Epoch: 5| Step: 10
Training loss: 2.4939146041870117
Validation loss: 2.0771731804775935

Epoch: 144| Step: 0
Training loss: 2.7487711906433105
Validation loss: 2.0733845439008487

Epoch: 5| Step: 1
Training loss: 2.363966703414917
Validation loss: 2.077954330751973

Epoch: 5| Step: 2
Training loss: 3.276514768600464
Validation loss: 2.082862497657858

Epoch: 5| Step: 3
Training loss: 1.6704957485198975
Validation loss: 2.0855112767988637

Epoch: 5| Step: 4
Training loss: 2.751544237136841
Validation loss: 2.0951959010093444

Epoch: 5| Step: 5
Training loss: 2.095808744430542
Validation loss: 2.100837745974141

Epoch: 5| Step: 6
Training loss: 1.389715552330017
Validation loss: 2.0869505431062434

Epoch: 5| Step: 7
Training loss: 2.169003963470459
Validation loss: 2.09151626658696

Epoch: 5| Step: 8
Training loss: 2.4511241912841797
Validation loss: 2.073233078884822

Epoch: 5| Step: 9
Training loss: 2.41969633102417
Validation loss: 2.0708164348397204

Epoch: 5| Step: 10
Training loss: 2.3417880535125732
Validation loss: 2.0597855019313034

Epoch: 145| Step: 0
Training loss: 2.4096240997314453
Validation loss: 2.057051576593871

Epoch: 5| Step: 1
Training loss: 1.9308280944824219
Validation loss: 2.0594628754482476

Epoch: 5| Step: 2
Training loss: 2.1180100440979004
Validation loss: 2.047904219678653

Epoch: 5| Step: 3
Training loss: 2.404879093170166
Validation loss: 2.0482512571478404

Epoch: 5| Step: 4
Training loss: 2.2874579429626465
Validation loss: 2.040783815486457

Epoch: 5| Step: 5
Training loss: 3.0126471519470215
Validation loss: 2.046030500883697

Epoch: 5| Step: 6
Training loss: 2.222294807434082
Validation loss: 2.042773424938161

Epoch: 5| Step: 7
Training loss: 2.557164192199707
Validation loss: 2.043690058492845

Epoch: 5| Step: 8
Training loss: 2.1195971965789795
Validation loss: 2.0362013616869525

Epoch: 5| Step: 9
Training loss: 1.9582195281982422
Validation loss: 2.022386126620795

Epoch: 5| Step: 10
Training loss: 2.546710968017578
Validation loss: 2.027318041811707

Epoch: 146| Step: 0
Training loss: 2.083224058151245
Validation loss: 2.041478439043927

Epoch: 5| Step: 1
Training loss: 2.658045768737793
Validation loss: 2.0241486898032566

Epoch: 5| Step: 2
Training loss: 1.830588698387146
Validation loss: 2.0273936115285403

Epoch: 5| Step: 3
Training loss: 1.6811386346817017
Validation loss: 2.024435809863511

Epoch: 5| Step: 4
Training loss: 2.069044589996338
Validation loss: 2.0202603545240176

Epoch: 5| Step: 5
Training loss: 2.321302890777588
Validation loss: 2.03121284515627

Epoch: 5| Step: 6
Training loss: 2.5023884773254395
Validation loss: 2.0420250790093535

Epoch: 5| Step: 7
Training loss: 2.7161929607391357
Validation loss: 2.0524635148304764

Epoch: 5| Step: 8
Training loss: 3.0726168155670166
Validation loss: 2.0389806634636334

Epoch: 5| Step: 9
Training loss: 1.6267391443252563
Validation loss: 2.0324647785514913

Epoch: 5| Step: 10
Training loss: 2.721217632293701
Validation loss: 2.030330208040053

Epoch: 147| Step: 0
Training loss: 2.378342390060425
Validation loss: 2.027237889587238

Epoch: 5| Step: 1
Training loss: 1.9154783487319946
Validation loss: 2.0270544841725338

Epoch: 5| Step: 2
Training loss: 2.7213187217712402
Validation loss: 2.0198485902560654

Epoch: 5| Step: 3
Training loss: 1.8185451030731201
Validation loss: 2.0119468499255437

Epoch: 5| Step: 4
Training loss: 1.738979697227478
Validation loss: 2.0126245816548667

Epoch: 5| Step: 5
Training loss: 2.5584092140197754
Validation loss: 2.003425551999

Epoch: 5| Step: 6
Training loss: 1.6770226955413818
Validation loss: 2.009333397752495

Epoch: 5| Step: 7
Training loss: 2.7243638038635254
Validation loss: 2.010778829615603

Epoch: 5| Step: 8
Training loss: 2.956040143966675
Validation loss: 2.013806553297145

Epoch: 5| Step: 9
Training loss: 2.6154186725616455
Validation loss: 2.017474459063622

Epoch: 5| Step: 10
Training loss: 1.7565088272094727
Validation loss: 2.0149911039619037

Epoch: 148| Step: 0
Training loss: 1.8528738021850586
Validation loss: 2.0160394522451583

Epoch: 5| Step: 1
Training loss: 2.2448811531066895
Validation loss: 2.0047033320191088

Epoch: 5| Step: 2
Training loss: 2.270106792449951
Validation loss: 2.008467294836557

Epoch: 5| Step: 3
Training loss: 1.9446626901626587
Validation loss: 2.004082302893362

Epoch: 5| Step: 4
Training loss: 1.873533010482788
Validation loss: 2.007661704094179

Epoch: 5| Step: 5
Training loss: 2.697571277618408
Validation loss: 2.006779734806348

Epoch: 5| Step: 6
Training loss: 2.5450825691223145
Validation loss: 2.0019304188348914

Epoch: 5| Step: 7
Training loss: 2.463318347930908
Validation loss: 2.0016132426518265

Epoch: 5| Step: 8
Training loss: 1.9672787189483643
Validation loss: 2.003078406856906

Epoch: 5| Step: 9
Training loss: 2.8448727130889893
Validation loss: 1.9898758011479531

Epoch: 5| Step: 10
Training loss: 2.3835270404815674
Validation loss: 1.9838222970244705

Epoch: 149| Step: 0
Training loss: 1.9349479675292969
Validation loss: 1.9806883527386574

Epoch: 5| Step: 1
Training loss: 2.527111768722534
Validation loss: 1.996379788203906

Epoch: 5| Step: 2
Training loss: 2.2535643577575684
Validation loss: 1.9966607209174865

Epoch: 5| Step: 3
Training loss: 1.8742330074310303
Validation loss: 1.9927194528682257

Epoch: 5| Step: 4
Training loss: 2.273144245147705
Validation loss: 1.9982286191755725

Epoch: 5| Step: 5
Training loss: 2.0312037467956543
Validation loss: 2.0025796390348867

Epoch: 5| Step: 6
Training loss: 2.232128143310547
Validation loss: 2.0057451853188137

Epoch: 5| Step: 7
Training loss: 2.1866331100463867
Validation loss: 2.0055992705847627

Epoch: 5| Step: 8
Training loss: 2.2836360931396484
Validation loss: 2.0087860399676907

Epoch: 5| Step: 9
Training loss: 2.648648500442505
Validation loss: 2.016877761451147

Epoch: 5| Step: 10
Training loss: 2.6421470642089844
Validation loss: 2.015355366532521

Epoch: 150| Step: 0
Training loss: 2.8104677200317383
Validation loss: 2.0252524793788953

Epoch: 5| Step: 1
Training loss: 2.522747039794922
Validation loss: 2.0112075856936875

Epoch: 5| Step: 2
Training loss: 1.5431544780731201
Validation loss: 2.030796120243688

Epoch: 5| Step: 3
Training loss: 2.1182684898376465
Validation loss: 2.051491901438723

Epoch: 5| Step: 4
Training loss: 1.4946022033691406
Validation loss: 2.059172858474075

Epoch: 5| Step: 5
Training loss: 3.153374195098877
Validation loss: 2.076052996420091

Epoch: 5| Step: 6
Training loss: 2.577040433883667
Validation loss: 2.074473682270255

Epoch: 5| Step: 7
Training loss: 2.1565940380096436
Validation loss: 2.0666260437298845

Epoch: 5| Step: 8
Training loss: 2.2355542182922363
Validation loss: 2.0585587165688954

Epoch: 5| Step: 9
Training loss: 2.663311719894409
Validation loss: 2.0335438533495833

Epoch: 5| Step: 10
Training loss: 1.8564252853393555
Validation loss: 2.026732325553894

Epoch: 151| Step: 0
Training loss: 2.0682003498077393
Validation loss: 2.039098428141686

Epoch: 5| Step: 1
Training loss: 2.2633657455444336
Validation loss: 2.0152807466445433

Epoch: 5| Step: 2
Training loss: 2.2778255939483643
Validation loss: 2.012822658784928

Epoch: 5| Step: 3
Training loss: 2.6942646503448486
Validation loss: 2.0122228873673307

Epoch: 5| Step: 4
Training loss: 2.016101360321045
Validation loss: 2.021777186342465

Epoch: 5| Step: 5
Training loss: 2.3491721153259277
Validation loss: 2.0156455347614903

Epoch: 5| Step: 6
Training loss: 1.7416073083877563
Validation loss: 2.0191095772609917

Epoch: 5| Step: 7
Training loss: 2.562875986099243
Validation loss: 2.0165429986933225

Epoch: 5| Step: 8
Training loss: 1.7474949359893799
Validation loss: 2.007058364088817

Epoch: 5| Step: 9
Training loss: 2.8493175506591797
Validation loss: 1.9957372706423524

Epoch: 5| Step: 10
Training loss: 2.4863674640655518
Validation loss: 1.99790120509363

Epoch: 152| Step: 0
Training loss: 2.5930519104003906
Validation loss: 2.015464803223969

Epoch: 5| Step: 1
Training loss: 2.587763547897339
Validation loss: 2.015179741767145

Epoch: 5| Step: 2
Training loss: 1.7330868244171143
Validation loss: 2.0381363566203783

Epoch: 5| Step: 3
Training loss: 2.4172677993774414
Validation loss: 2.027761035068061

Epoch: 5| Step: 4
Training loss: 2.8425872325897217
Validation loss: 2.0087880203800816

Epoch: 5| Step: 5
Training loss: 2.4596076011657715
Validation loss: 2.0037872637471845

Epoch: 5| Step: 6
Training loss: 2.109731674194336
Validation loss: 2.0011262188675585

Epoch: 5| Step: 7
Training loss: 2.1941354274749756
Validation loss: 2.0030209402884207

Epoch: 5| Step: 8
Training loss: 1.8931219577789307
Validation loss: 2.0265801927094818

Epoch: 5| Step: 9
Training loss: 2.2642016410827637
Validation loss: 2.0343664307748117

Epoch: 5| Step: 10
Training loss: 1.940105676651001
Validation loss: 2.0255246008596113

Epoch: 153| Step: 0
Training loss: 1.9590619802474976
Validation loss: 2.0127265466156827

Epoch: 5| Step: 1
Training loss: 2.54844331741333
Validation loss: 2.0005491677150933

Epoch: 5| Step: 2
Training loss: 2.6451210975646973
Validation loss: 1.9926319660678986

Epoch: 5| Step: 3
Training loss: 2.0177369117736816
Validation loss: 2.008437228459184

Epoch: 5| Step: 4
Training loss: 2.1780846118927
Validation loss: 2.0146011960121895

Epoch: 5| Step: 5
Training loss: 2.5042786598205566
Validation loss: 2.0138232861795733

Epoch: 5| Step: 6
Training loss: 2.324965476989746
Validation loss: 2.0164793755418513

Epoch: 5| Step: 7
Training loss: 1.6984758377075195
Validation loss: 2.020808281437043

Epoch: 5| Step: 8
Training loss: 2.2470130920410156
Validation loss: 2.0138442670145342

Epoch: 5| Step: 9
Training loss: 2.3980352878570557
Validation loss: 2.0133729775746665

Epoch: 5| Step: 10
Training loss: 2.102308988571167
Validation loss: 2.017256713682605

Epoch: 154| Step: 0
Training loss: 2.306882858276367
Validation loss: 2.0124109393806866

Epoch: 5| Step: 1
Training loss: 2.275664806365967
Validation loss: 2.0195147939907607

Epoch: 5| Step: 2
Training loss: 2.4710891246795654
Validation loss: 2.0120223978514313

Epoch: 5| Step: 3
Training loss: 2.3773486614227295
Validation loss: 2.017342746898692

Epoch: 5| Step: 4
Training loss: 2.2296433448791504
Validation loss: 2.0031711516841764

Epoch: 5| Step: 5
Training loss: 2.107187509536743
Validation loss: 2.0067495671651696

Epoch: 5| Step: 6
Training loss: 2.103189468383789
Validation loss: 2.0126523997194026

Epoch: 5| Step: 7
Training loss: 2.262877941131592
Validation loss: 2.014308806388609

Epoch: 5| Step: 8
Training loss: 2.5172059535980225
Validation loss: 2.014150898943665

Epoch: 5| Step: 9
Training loss: 1.8060382604599
Validation loss: 2.0176601474003126

Epoch: 5| Step: 10
Training loss: 2.034837245941162
Validation loss: 2.0217681674547094

Epoch: 155| Step: 0
Training loss: 2.1444506645202637
Validation loss: 2.022069236283661

Epoch: 5| Step: 1
Training loss: 2.168320655822754
Validation loss: 2.0185394697291876

Epoch: 5| Step: 2
Training loss: 2.2139456272125244
Validation loss: 2.0283228633224324

Epoch: 5| Step: 3
Training loss: 1.9611005783081055
Validation loss: 2.0187775422168035

Epoch: 5| Step: 4
Training loss: 1.8283398151397705
Validation loss: 2.008463695485105

Epoch: 5| Step: 5
Training loss: 2.1907496452331543
Validation loss: 2.013782217938413

Epoch: 5| Step: 6
Training loss: 2.269254684448242
Validation loss: 2.0129733495814826

Epoch: 5| Step: 7
Training loss: 2.265781879425049
Validation loss: 2.013757851815993

Epoch: 5| Step: 8
Training loss: 2.4010586738586426
Validation loss: 2.0039854972593245

Epoch: 5| Step: 9
Training loss: 2.8177330493927
Validation loss: 2.0234611931667534

Epoch: 5| Step: 10
Training loss: 2.334333658218384
Validation loss: 2.0085857363157373

Epoch: 156| Step: 0
Training loss: 1.9271694421768188
Validation loss: 2.0188828552922895

Epoch: 5| Step: 1
Training loss: 2.071838855743408
Validation loss: 2.0056471773373183

Epoch: 5| Step: 2
Training loss: 2.195080280303955
Validation loss: 2.0140537561908847

Epoch: 5| Step: 3
Training loss: 2.0443787574768066
Validation loss: 2.009615577677245

Epoch: 5| Step: 4
Training loss: 1.9778826236724854
Validation loss: 1.9939981583626039

Epoch: 5| Step: 5
Training loss: 2.37206768989563
Validation loss: 2.0025139957345943

Epoch: 5| Step: 6
Training loss: 2.6858181953430176
Validation loss: 1.9978496233622234

Epoch: 5| Step: 7
Training loss: 1.6593382358551025
Validation loss: 2.001163100683561

Epoch: 5| Step: 8
Training loss: 2.5002803802490234
Validation loss: 1.9998580025088402

Epoch: 5| Step: 9
Training loss: 2.2875983715057373
Validation loss: 2.0081393449537215

Epoch: 5| Step: 10
Training loss: 2.820098876953125
Validation loss: 2.0142716182175504

Epoch: 157| Step: 0
Training loss: 2.45011568069458
Validation loss: 2.0024695665605607

Epoch: 5| Step: 1
Training loss: 1.9686075448989868
Validation loss: 2.0219631451432423

Epoch: 5| Step: 2
Training loss: 2.1743476390838623
Validation loss: 2.027772847042289

Epoch: 5| Step: 3
Training loss: 2.305884838104248
Validation loss: 2.0510542674731185

Epoch: 5| Step: 4
Training loss: 2.275599718093872
Validation loss: 2.03742875078673

Epoch: 5| Step: 5
Training loss: 2.0746660232543945
Validation loss: 2.0315935380997194

Epoch: 5| Step: 6
Training loss: 2.165616273880005
Validation loss: 2.0293430794951735

Epoch: 5| Step: 7
Training loss: 2.410062313079834
Validation loss: 2.0215285490917903

Epoch: 5| Step: 8
Training loss: 1.9985374212265015
Validation loss: 2.0200068822471042

Epoch: 5| Step: 9
Training loss: 1.90716552734375
Validation loss: 2.0239436498252292

Epoch: 5| Step: 10
Training loss: 2.7245969772338867
Validation loss: 2.023545765107678

Epoch: 158| Step: 0
Training loss: 1.7481231689453125
Validation loss: 2.0109814315713863

Epoch: 5| Step: 1
Training loss: 2.3276889324188232
Validation loss: 2.0020102941861717

Epoch: 5| Step: 2
Training loss: 1.8609535694122314
Validation loss: 2.006130769688596

Epoch: 5| Step: 3
Training loss: 3.0584359169006348
Validation loss: 2.0545421261941232

Epoch: 5| Step: 4
Training loss: 2.551231622695923
Validation loss: 1.9821563561757405

Epoch: 5| Step: 5
Training loss: 2.1822071075439453
Validation loss: 1.9571688732793253

Epoch: 5| Step: 6
Training loss: 2.7262444496154785
Validation loss: 1.9442095295075448

Epoch: 5| Step: 7
Training loss: 2.169454574584961
Validation loss: 1.9517535958238827

Epoch: 5| Step: 8
Training loss: 2.3409829139709473
Validation loss: 1.9694145187254875

Epoch: 5| Step: 9
Training loss: 1.7869136333465576
Validation loss: 1.9835869958323817

Epoch: 5| Step: 10
Training loss: 2.245269298553467
Validation loss: 2.00172818476154

Epoch: 159| Step: 0
Training loss: 2.609525680541992
Validation loss: 2.006820624874484

Epoch: 5| Step: 1
Training loss: 2.4679112434387207
Validation loss: 2.012649974515361

Epoch: 5| Step: 2
Training loss: 2.0406553745269775
Validation loss: 1.9973241513775242

Epoch: 5| Step: 3
Training loss: 2.033665895462036
Validation loss: 1.9792959062002038

Epoch: 5| Step: 4
Training loss: 1.9167864322662354
Validation loss: 1.9708113439621464

Epoch: 5| Step: 5
Training loss: 2.2314400672912598
Validation loss: 1.9575646295342395

Epoch: 5| Step: 6
Training loss: 2.5032076835632324
Validation loss: 1.953460685668453

Epoch: 5| Step: 7
Training loss: 1.861016035079956
Validation loss: 1.9581564152112572

Epoch: 5| Step: 8
Training loss: 2.4756383895874023
Validation loss: 1.9561813108382686

Epoch: 5| Step: 9
Training loss: 2.3223915100097656
Validation loss: 1.9514354608392204

Epoch: 5| Step: 10
Training loss: 2.7754006385803223
Validation loss: 1.9550548009974982

Epoch: 160| Step: 0
Training loss: 2.069065809249878
Validation loss: 1.9553689725937382

Epoch: 5| Step: 1
Training loss: 2.9237091541290283
Validation loss: 1.9496557046008367

Epoch: 5| Step: 2
Training loss: 2.3337717056274414
Validation loss: 1.9528731043620775

Epoch: 5| Step: 3
Training loss: 2.6159451007843018
Validation loss: 1.9559463365103609

Epoch: 5| Step: 4
Training loss: 1.8852428197860718
Validation loss: 1.957627809175881

Epoch: 5| Step: 5
Training loss: 2.6733360290527344
Validation loss: 1.9628288643334502

Epoch: 5| Step: 6
Training loss: 2.1733551025390625
Validation loss: 1.97011197510586

Epoch: 5| Step: 7
Training loss: 2.137700080871582
Validation loss: 1.9748064318010885

Epoch: 5| Step: 8
Training loss: 2.448887586593628
Validation loss: 1.9929172403068953

Epoch: 5| Step: 9
Training loss: 1.9956096410751343
Validation loss: 2.004256177974004

Epoch: 5| Step: 10
Training loss: 1.7497217655181885
Validation loss: 1.9968762923312444

Epoch: 161| Step: 0
Training loss: 2.0335559844970703
Validation loss: 2.0315321542883433

Epoch: 5| Step: 1
Training loss: 2.0325422286987305
Validation loss: 2.0587556413424912

Epoch: 5| Step: 2
Training loss: 2.4155991077423096
Validation loss: 2.0943070304009224

Epoch: 5| Step: 3
Training loss: 2.3024821281433105
Validation loss: 2.0853840561323267

Epoch: 5| Step: 4
Training loss: 2.036728620529175
Validation loss: 2.0762617165042507

Epoch: 5| Step: 5
Training loss: 2.3893704414367676
Validation loss: 2.0506514862019527

Epoch: 5| Step: 6
Training loss: 2.491286039352417
Validation loss: 2.036323485835906

Epoch: 5| Step: 7
Training loss: 2.5949149131774902
Validation loss: 2.0279625179947063

Epoch: 5| Step: 8
Training loss: 2.567779064178467
Validation loss: 2.026986639986756

Epoch: 5| Step: 9
Training loss: 2.1093523502349854
Validation loss: 2.0166804495678154

Epoch: 5| Step: 10
Training loss: 1.7723628282546997
Validation loss: 2.0018804906516947

Epoch: 162| Step: 0
Training loss: 2.363356828689575
Validation loss: 2.001459014031195

Epoch: 5| Step: 1
Training loss: 2.136472702026367
Validation loss: 1.994500252508348

Epoch: 5| Step: 2
Training loss: 2.2858941555023193
Validation loss: 2.0120283724159322

Epoch: 5| Step: 3
Training loss: 1.411056399345398
Validation loss: 2.0096771127434185

Epoch: 5| Step: 4
Training loss: 2.1428160667419434
Validation loss: 1.9973392435299453

Epoch: 5| Step: 5
Training loss: 2.29664945602417
Validation loss: 1.9828519193075036

Epoch: 5| Step: 6
Training loss: 2.4335720539093018
Validation loss: 1.9676009583216842

Epoch: 5| Step: 7
Training loss: 2.278151273727417
Validation loss: 1.9672247312402213

Epoch: 5| Step: 8
Training loss: 2.438098192214966
Validation loss: 1.9622635713187597

Epoch: 5| Step: 9
Training loss: 2.113848924636841
Validation loss: 1.9438312592044953

Epoch: 5| Step: 10
Training loss: 2.9212639331817627
Validation loss: 1.9425654693316388

Epoch: 163| Step: 0
Training loss: 2.044088363647461
Validation loss: 1.9461218926214403

Epoch: 5| Step: 1
Training loss: 2.7048473358154297
Validation loss: 1.9493982766264228

Epoch: 5| Step: 2
Training loss: 1.7876942157745361
Validation loss: 1.9496037588324597

Epoch: 5| Step: 3
Training loss: 2.630441188812256
Validation loss: 1.9472879261098883

Epoch: 5| Step: 4
Training loss: 1.9078216552734375
Validation loss: 1.9450449225723103

Epoch: 5| Step: 5
Training loss: 2.6241676807403564
Validation loss: 1.9492126075170373

Epoch: 5| Step: 6
Training loss: 1.5259233713150024
Validation loss: 1.9644173165803314

Epoch: 5| Step: 7
Training loss: 2.502265214920044
Validation loss: 1.9772819793352516

Epoch: 5| Step: 8
Training loss: 2.9111034870147705
Validation loss: 1.978090319582211

Epoch: 5| Step: 9
Training loss: 2.206264019012451
Validation loss: 1.97771837634425

Epoch: 5| Step: 10
Training loss: 1.8729091882705688
Validation loss: 1.965091771976922

Epoch: 164| Step: 0
Training loss: 2.339054584503174
Validation loss: 1.9545795725237938

Epoch: 5| Step: 1
Training loss: 1.6563775539398193
Validation loss: 1.9514155016150525

Epoch: 5| Step: 2
Training loss: 2.506826400756836
Validation loss: 1.9517810293423232

Epoch: 5| Step: 3
Training loss: 1.9840997457504272
Validation loss: 1.9534414558000461

Epoch: 5| Step: 4
Training loss: 2.5413899421691895
Validation loss: 1.9619659775046892

Epoch: 5| Step: 5
Training loss: 1.9298416376113892
Validation loss: 1.9630355809324531

Epoch: 5| Step: 6
Training loss: 2.2083609104156494
Validation loss: 1.9519589972752396

Epoch: 5| Step: 7
Training loss: 2.6683850288391113
Validation loss: 1.9475384758364769

Epoch: 5| Step: 8
Training loss: 2.0794527530670166
Validation loss: 1.9508620872292468

Epoch: 5| Step: 9
Training loss: 2.129581928253174
Validation loss: 1.950930828689247

Epoch: 5| Step: 10
Training loss: 2.551074981689453
Validation loss: 1.9493014325377762

Epoch: 165| Step: 0
Training loss: 2.092864751815796
Validation loss: 1.9568166437969412

Epoch: 5| Step: 1
Training loss: 2.207890272140503
Validation loss: 1.95880986157284

Epoch: 5| Step: 2
Training loss: 2.233715534210205
Validation loss: 1.9534989813322663

Epoch: 5| Step: 3
Training loss: 1.9624723196029663
Validation loss: 1.9622445055233535

Epoch: 5| Step: 4
Training loss: 2.4847006797790527
Validation loss: 1.964319839272448

Epoch: 5| Step: 5
Training loss: 1.3704863786697388
Validation loss: 1.96481583451712

Epoch: 5| Step: 6
Training loss: 1.993647575378418
Validation loss: 1.9680421313931864

Epoch: 5| Step: 7
Training loss: 2.3420827388763428
Validation loss: 1.9629787501468454

Epoch: 5| Step: 8
Training loss: 2.6734814643859863
Validation loss: 1.9812597613180838

Epoch: 5| Step: 9
Training loss: 2.253291606903076
Validation loss: 1.9966195373124973

Epoch: 5| Step: 10
Training loss: 2.728003740310669
Validation loss: 2.0027035244049562

Epoch: 166| Step: 0
Training loss: 2.1191506385803223
Validation loss: 2.0029327125959497

Epoch: 5| Step: 1
Training loss: 2.7445993423461914
Validation loss: 2.0104057494030205

Epoch: 5| Step: 2
Training loss: 2.0361216068267822
Validation loss: 2.0158455756402787

Epoch: 5| Step: 3
Training loss: 1.9702351093292236
Validation loss: 2.0250000389673377

Epoch: 5| Step: 4
Training loss: 2.093247890472412
Validation loss: 2.019429709321709

Epoch: 5| Step: 5
Training loss: 2.1770148277282715
Validation loss: 2.015297992255098

Epoch: 5| Step: 6
Training loss: 2.038774013519287
Validation loss: 2.0255687364967923

Epoch: 5| Step: 7
Training loss: 1.8481776714324951
Validation loss: 2.0355795416780698

Epoch: 5| Step: 8
Training loss: 2.3598105907440186
Validation loss: 2.0288747907966695

Epoch: 5| Step: 9
Training loss: 2.340763568878174
Validation loss: 2.0310450882040043

Epoch: 5| Step: 10
Training loss: 2.4701452255249023
Validation loss: 2.0128590163364204

Epoch: 167| Step: 0
Training loss: 1.6933257579803467
Validation loss: 2.0050361617918937

Epoch: 5| Step: 1
Training loss: 2.6297287940979004
Validation loss: 1.9943249430707706

Epoch: 5| Step: 2
Training loss: 2.2142345905303955
Validation loss: 2.008666593541381

Epoch: 5| Step: 3
Training loss: 2.590360641479492
Validation loss: 2.010585561875374

Epoch: 5| Step: 4
Training loss: 2.6324379444122314
Validation loss: 2.0145879663446897

Epoch: 5| Step: 5
Training loss: 2.391446113586426
Validation loss: 2.0127767209083802

Epoch: 5| Step: 6
Training loss: 2.073326587677002
Validation loss: 2.005304521129977

Epoch: 5| Step: 7
Training loss: 1.9812126159667969
Validation loss: 1.9979561246851438

Epoch: 5| Step: 8
Training loss: 2.0202090740203857
Validation loss: 1.990327699210054

Epoch: 5| Step: 9
Training loss: 1.9964935779571533
Validation loss: 1.9892782754795526

Epoch: 5| Step: 10
Training loss: 1.8495969772338867
Validation loss: 1.9824111718003468

Epoch: 168| Step: 0
Training loss: 1.9412829875946045
Validation loss: 1.9720206927227717

Epoch: 5| Step: 1
Training loss: 1.7580091953277588
Validation loss: 1.9831979146567724

Epoch: 5| Step: 2
Training loss: 1.8626941442489624
Validation loss: 1.9927201181329706

Epoch: 5| Step: 3
Training loss: 2.546143054962158
Validation loss: 1.999251324643371

Epoch: 5| Step: 4
Training loss: 2.812927484512329
Validation loss: 2.0004004252854215

Epoch: 5| Step: 5
Training loss: 1.4783222675323486
Validation loss: 2.0137487047462055

Epoch: 5| Step: 6
Training loss: 2.2867393493652344
Validation loss: 2.014692319336758

Epoch: 5| Step: 7
Training loss: 2.59891939163208
Validation loss: 2.0164051337908675

Epoch: 5| Step: 8
Training loss: 2.2413387298583984
Validation loss: 2.020544418724634

Epoch: 5| Step: 9
Training loss: 2.1158971786499023
Validation loss: 2.018626441237747

Epoch: 5| Step: 10
Training loss: 2.531989574432373
Validation loss: 2.0143230666396437

Epoch: 169| Step: 0
Training loss: 3.3676934242248535
Validation loss: 2.0062558548424834

Epoch: 5| Step: 1
Training loss: 1.89113450050354
Validation loss: 2.004922036201723

Epoch: 5| Step: 2
Training loss: 2.177517890930176
Validation loss: 2.021917732813025

Epoch: 5| Step: 3
Training loss: 2.082540273666382
Validation loss: 2.0143332583929903

Epoch: 5| Step: 4
Training loss: 2.0780181884765625
Validation loss: 2.036315615459155

Epoch: 5| Step: 5
Training loss: 1.868330955505371
Validation loss: 2.0355591491986345

Epoch: 5| Step: 6
Training loss: 2.051809549331665
Validation loss: 2.0346655332913963

Epoch: 5| Step: 7
Training loss: 3.003201961517334
Validation loss: 2.061721109574841

Epoch: 5| Step: 8
Training loss: 2.1169729232788086
Validation loss: 2.0947789710055114

Epoch: 5| Step: 9
Training loss: 2.0436158180236816
Validation loss: 2.0850698768451648

Epoch: 5| Step: 10
Training loss: 2.110261917114258
Validation loss: 2.0612266012417373

Epoch: 170| Step: 0
Training loss: 2.2526047229766846
Validation loss: 2.0535151714919717

Epoch: 5| Step: 1
Training loss: 2.264819622039795
Validation loss: 2.043917464953597

Epoch: 5| Step: 2
Training loss: 1.8583247661590576
Validation loss: 2.0339268151149956

Epoch: 5| Step: 3
Training loss: 1.9087064266204834
Validation loss: 2.0259377597480692

Epoch: 5| Step: 4
Training loss: 1.958702802658081
Validation loss: 2.0298647342189664

Epoch: 5| Step: 5
Training loss: 2.829792022705078
Validation loss: 2.026255638368668

Epoch: 5| Step: 6
Training loss: 2.3132474422454834
Validation loss: 2.0252206838259132

Epoch: 5| Step: 7
Training loss: 2.6667373180389404
Validation loss: 2.0189728070330877

Epoch: 5| Step: 8
Training loss: 2.861361503601074
Validation loss: 2.019159481089602

Epoch: 5| Step: 9
Training loss: 2.0072906017303467
Validation loss: 2.0013577168987644

Epoch: 5| Step: 10
Training loss: 1.647316575050354
Validation loss: 1.996500160104485

Epoch: 171| Step: 0
Training loss: 2.4259183406829834
Validation loss: 2.013918933048043

Epoch: 5| Step: 1
Training loss: 2.5825085639953613
Validation loss: 2.0064835856037755

Epoch: 5| Step: 2
Training loss: 2.335911273956299
Validation loss: 2.010701835796397

Epoch: 5| Step: 3
Training loss: 2.2853856086730957
Validation loss: 2.020032294334904

Epoch: 5| Step: 4
Training loss: 1.6711452007293701
Validation loss: 2.0081843471014373

Epoch: 5| Step: 5
Training loss: 1.8216129541397095
Validation loss: 2.009020854068059

Epoch: 5| Step: 6
Training loss: 1.9625869989395142
Validation loss: 2.002997317621785

Epoch: 5| Step: 7
Training loss: 2.7585325241088867
Validation loss: 1.9874488615220594

Epoch: 5| Step: 8
Training loss: 1.7877066135406494
Validation loss: 1.9867708785559541

Epoch: 5| Step: 9
Training loss: 2.15470814704895
Validation loss: 1.9844325921868766

Epoch: 5| Step: 10
Training loss: 2.571000576019287
Validation loss: 1.9866736447939308

Epoch: 172| Step: 0
Training loss: 2.5562171936035156
Validation loss: 1.9858921638099096

Epoch: 5| Step: 1
Training loss: 2.073187828063965
Validation loss: 1.9913973398106073

Epoch: 5| Step: 2
Training loss: 2.8453147411346436
Validation loss: 1.9968673900891376

Epoch: 5| Step: 3
Training loss: 2.241556406021118
Validation loss: 2.0057461056658017

Epoch: 5| Step: 4
Training loss: 1.4722522497177124
Validation loss: 2.008764551531884

Epoch: 5| Step: 5
Training loss: 1.6730482578277588
Validation loss: 2.017945865149139

Epoch: 5| Step: 6
Training loss: 2.0129969120025635
Validation loss: 2.0123321612675986

Epoch: 5| Step: 7
Training loss: 1.9395831823349
Validation loss: 2.0222742557525635

Epoch: 5| Step: 8
Training loss: 2.480731248855591
Validation loss: 2.0204665942858626

Epoch: 5| Step: 9
Training loss: 2.453101634979248
Validation loss: 2.0091729523033224

Epoch: 5| Step: 10
Training loss: 2.6630630493164062
Validation loss: 1.9961257775624592

Epoch: 173| Step: 0
Training loss: 2.958336353302002
Validation loss: 1.979083748273952

Epoch: 5| Step: 1
Training loss: 2.1473312377929688
Validation loss: 1.968936727892968

Epoch: 5| Step: 2
Training loss: 3.669160842895508
Validation loss: 1.9678700764973958

Epoch: 5| Step: 3
Training loss: 2.125488758087158
Validation loss: 1.9570527051084785

Epoch: 5| Step: 4
Training loss: 1.6924095153808594
Validation loss: 1.9614853423128846

Epoch: 5| Step: 5
Training loss: 1.797922134399414
Validation loss: 1.9631096804013817

Epoch: 5| Step: 6
Training loss: 1.989760160446167
Validation loss: 1.9499395521738196

Epoch: 5| Step: 7
Training loss: 1.8204152584075928
Validation loss: 1.9610203004652453

Epoch: 5| Step: 8
Training loss: 1.89639413356781
Validation loss: 1.9622609999872023

Epoch: 5| Step: 9
Training loss: 1.8718678951263428
Validation loss: 1.9717391639627435

Epoch: 5| Step: 10
Training loss: 2.1503262519836426
Validation loss: 1.967603915481157

Epoch: 174| Step: 0
Training loss: 1.5282567739486694
Validation loss: 1.9663720361648067

Epoch: 5| Step: 1
Training loss: 2.2698874473571777
Validation loss: 1.9739852284872403

Epoch: 5| Step: 2
Training loss: 2.2977702617645264
Validation loss: 1.9777477159295032

Epoch: 5| Step: 3
Training loss: 1.8333057165145874
Validation loss: 1.9633957032234437

Epoch: 5| Step: 4
Training loss: 1.6643352508544922
Validation loss: 1.9731621229520409

Epoch: 5| Step: 5
Training loss: 2.6235172748565674
Validation loss: 1.960595933339929

Epoch: 5| Step: 6
Training loss: 2.4638946056365967
Validation loss: 1.9435525901855961

Epoch: 5| Step: 7
Training loss: 2.62320613861084
Validation loss: 1.9475668681565153

Epoch: 5| Step: 8
Training loss: 1.9371942281723022
Validation loss: 1.9419608859605686

Epoch: 5| Step: 9
Training loss: 2.3453760147094727
Validation loss: 1.9400597464653753

Epoch: 5| Step: 10
Training loss: 2.184232711791992
Validation loss: 1.944327888950225

Epoch: 175| Step: 0
Training loss: 2.2777297496795654
Validation loss: 1.9715301682872157

Epoch: 5| Step: 1
Training loss: 2.0404810905456543
Validation loss: 1.9871100584665935

Epoch: 5| Step: 2
Training loss: 1.9542019367218018
Validation loss: 2.0064522374060845

Epoch: 5| Step: 3
Training loss: 1.615348219871521
Validation loss: 2.0284611807074597

Epoch: 5| Step: 4
Training loss: 2.5663275718688965
Validation loss: 1.977238998618177

Epoch: 5| Step: 5
Training loss: 3.0159034729003906
Validation loss: 1.9729095710221158

Epoch: 5| Step: 6
Training loss: 2.121591567993164
Validation loss: 1.9831320470379246

Epoch: 5| Step: 7
Training loss: 1.8576856851577759
Validation loss: 1.990387862728488

Epoch: 5| Step: 8
Training loss: 2.6631503105163574
Validation loss: 2.0002636114756265

Epoch: 5| Step: 9
Training loss: 2.2231764793395996
Validation loss: 2.011863159876998

Epoch: 5| Step: 10
Training loss: 1.4645373821258545
Validation loss: 2.0204045836643507

Epoch: 176| Step: 0
Training loss: 3.0326669216156006
Validation loss: 1.9995696993284329

Epoch: 5| Step: 1
Training loss: 2.0241637229919434
Validation loss: 2.0019213589288856

Epoch: 5| Step: 2
Training loss: 2.025299072265625
Validation loss: 1.9900415123149913

Epoch: 5| Step: 3
Training loss: 1.5612428188323975
Validation loss: 1.984840436648297

Epoch: 5| Step: 4
Training loss: 2.0242719650268555
Validation loss: 2.0161736613960675

Epoch: 5| Step: 5
Training loss: 2.6729576587677
Validation loss: 2.0293321622315275

Epoch: 5| Step: 6
Training loss: 1.8093522787094116
Validation loss: 2.052207218703403

Epoch: 5| Step: 7
Training loss: 2.300032138824463
Validation loss: 2.0459545530298704

Epoch: 5| Step: 8
Training loss: 2.258737087249756
Validation loss: 2.015599207211566

Epoch: 5| Step: 9
Training loss: 2.081080913543701
Validation loss: 2.011410400431643

Epoch: 5| Step: 10
Training loss: 1.9027687311172485
Validation loss: 1.9890019098917644

Epoch: 177| Step: 0
Training loss: 2.3422296047210693
Validation loss: 1.967604519218527

Epoch: 5| Step: 1
Training loss: 2.2348713874816895
Validation loss: 1.9899150094678324

Epoch: 5| Step: 2
Training loss: 2.442701816558838
Validation loss: 1.9821906166691934

Epoch: 5| Step: 3
Training loss: 1.7674896717071533
Validation loss: 1.9904448729689403

Epoch: 5| Step: 4
Training loss: 2.556614875793457
Validation loss: 1.9816541223115818

Epoch: 5| Step: 5
Training loss: 2.1353583335876465
Validation loss: 1.966083788102673

Epoch: 5| Step: 6
Training loss: 2.100440502166748
Validation loss: 1.9640199779182352

Epoch: 5| Step: 7
Training loss: 2.4495110511779785
Validation loss: 1.9543493819493118

Epoch: 5| Step: 8
Training loss: 1.6512371301651
Validation loss: 1.9321376175008795

Epoch: 5| Step: 9
Training loss: 1.7916415929794312
Validation loss: 1.9628204094466342

Epoch: 5| Step: 10
Training loss: 2.50077486038208
Validation loss: 1.9873999305950698

Epoch: 178| Step: 0
Training loss: 2.4878251552581787
Validation loss: 2.012762895194433

Epoch: 5| Step: 1
Training loss: 2.037140369415283
Validation loss: 2.037022758555669

Epoch: 5| Step: 2
Training loss: 1.703678846359253
Validation loss: 2.0267286172477146

Epoch: 5| Step: 3
Training loss: 2.5357701778411865
Validation loss: 2.0404138334335817

Epoch: 5| Step: 4
Training loss: 2.8019988536834717
Validation loss: 2.029586368991483

Epoch: 5| Step: 5
Training loss: 2.474020004272461
Validation loss: 2.0112375431163336

Epoch: 5| Step: 6
Training loss: 1.471306562423706
Validation loss: 2.0073990270655644

Epoch: 5| Step: 7
Training loss: 1.9466798305511475
Validation loss: 2.0158430017450804

Epoch: 5| Step: 8
Training loss: 1.8253164291381836
Validation loss: 2.046214001153105

Epoch: 5| Step: 9
Training loss: 2.237208843231201
Validation loss: 2.0516897939866587

Epoch: 5| Step: 10
Training loss: 2.2422425746917725
Validation loss: 2.0820704429380354

Epoch: 179| Step: 0
Training loss: 2.158090114593506
Validation loss: 2.0948385013047086

Epoch: 5| Step: 1
Training loss: 3.00166916847229
Validation loss: 2.0793231353964856

Epoch: 5| Step: 2
Training loss: 2.5620481967926025
Validation loss: 2.0799504095508206

Epoch: 5| Step: 3
Training loss: 1.969618558883667
Validation loss: 2.1158499563893964

Epoch: 5| Step: 4
Training loss: 1.297495722770691
Validation loss: 2.120168860240649

Epoch: 5| Step: 5
Training loss: 1.7561423778533936
Validation loss: 2.102191840448687

Epoch: 5| Step: 6
Training loss: 2.0277304649353027
Validation loss: 2.0883822697465138

Epoch: 5| Step: 7
Training loss: 2.4302990436553955
Validation loss: 2.071087693655363

Epoch: 5| Step: 8
Training loss: 1.9531338214874268
Validation loss: 2.0763102885215514

Epoch: 5| Step: 9
Training loss: 2.348914623260498
Validation loss: 2.068455816597067

Epoch: 5| Step: 10
Training loss: 2.735234260559082
Validation loss: 2.055461093943606

Epoch: 180| Step: 0
Training loss: 2.4916398525238037
Validation loss: 2.0362614559870895

Epoch: 5| Step: 1
Training loss: 2.052821397781372
Validation loss: 2.0153427880297423

Epoch: 5| Step: 2
Training loss: 2.1018898487091064
Validation loss: 2.0079752399075415

Epoch: 5| Step: 3
Training loss: 2.3857226371765137
Validation loss: 1.9637948953977196

Epoch: 5| Step: 4
Training loss: 2.6157028675079346
Validation loss: 1.9610150975565757

Epoch: 5| Step: 5
Training loss: 1.9238075017929077
Validation loss: 1.9587841136481172

Epoch: 5| Step: 6
Training loss: 2.4575417041778564
Validation loss: 1.9596065077730405

Epoch: 5| Step: 7
Training loss: 1.636553168296814
Validation loss: 1.9428664971423406

Epoch: 5| Step: 8
Training loss: 2.193673610687256
Validation loss: 1.9459785107643373

Epoch: 5| Step: 9
Training loss: 1.5142266750335693
Validation loss: 1.9400130241147933

Epoch: 5| Step: 10
Training loss: 2.4935286045074463
Validation loss: 1.9578507561837473

Epoch: 181| Step: 0
Training loss: 2.2733216285705566
Validation loss: 1.9766672221563195

Epoch: 5| Step: 1
Training loss: 1.9070827960968018
Validation loss: 1.9985825066925378

Epoch: 5| Step: 2
Training loss: 2.6938018798828125
Validation loss: 2.015798355943413

Epoch: 5| Step: 3
Training loss: 1.4879107475280762
Validation loss: 2.009247326081799

Epoch: 5| Step: 4
Training loss: 2.001204013824463
Validation loss: 1.9999216653967415

Epoch: 5| Step: 5
Training loss: 2.1559176445007324
Validation loss: 1.9846933823759838

Epoch: 5| Step: 6
Training loss: 2.4625935554504395
Validation loss: 1.9504441548419256

Epoch: 5| Step: 7
Training loss: 2.2437350749969482
Validation loss: 1.953714911655713

Epoch: 5| Step: 8
Training loss: 2.152650833129883
Validation loss: 1.9513477215202906

Epoch: 5| Step: 9
Training loss: 2.0269031524658203
Validation loss: 1.972991584449686

Epoch: 5| Step: 10
Training loss: 2.561535120010376
Validation loss: 1.9763314993150773

Epoch: 182| Step: 0
Training loss: 1.9905061721801758
Validation loss: 1.9824650672174269

Epoch: 5| Step: 1
Training loss: 2.2358829975128174
Validation loss: 1.9795078808261501

Epoch: 5| Step: 2
Training loss: 2.2354438304901123
Validation loss: 1.9863697969785301

Epoch: 5| Step: 3
Training loss: 1.7431166172027588
Validation loss: 1.9810859234102312

Epoch: 5| Step: 4
Training loss: 2.1532928943634033
Validation loss: 1.9825416482904905

Epoch: 5| Step: 5
Training loss: 2.4802682399749756
Validation loss: 1.9941001912598968

Epoch: 5| Step: 6
Training loss: 2.0120596885681152
Validation loss: 2.030879726973913

Epoch: 5| Step: 7
Training loss: 2.3411993980407715
Validation loss: 2.030441309816094

Epoch: 5| Step: 8
Training loss: 1.6971896886825562
Validation loss: 2.0352858740796327

Epoch: 5| Step: 9
Training loss: 1.8506495952606201
Validation loss: 2.04261375242664

Epoch: 5| Step: 10
Training loss: 3.0532138347625732
Validation loss: 2.0430683000113374

Epoch: 183| Step: 0
Training loss: 2.481825351715088
Validation loss: 2.018124685492567

Epoch: 5| Step: 1
Training loss: 2.4343857765197754
Validation loss: 2.0103203532516316

Epoch: 5| Step: 2
Training loss: 2.1449406147003174
Validation loss: 2.0138358172549995

Epoch: 5| Step: 3
Training loss: 2.128427505493164
Validation loss: 2.0249095245074202

Epoch: 5| Step: 4
Training loss: 2.1515214443206787
Validation loss: 2.031297993916337

Epoch: 5| Step: 5
Training loss: 1.9982719421386719
Validation loss: 2.0335723635970906

Epoch: 5| Step: 6
Training loss: 1.2760473489761353
Validation loss: 2.0362804333368936

Epoch: 5| Step: 7
Training loss: 2.235130786895752
Validation loss: 2.055082295530586

Epoch: 5| Step: 8
Training loss: 2.285360813140869
Validation loss: 2.0521390643171085

Epoch: 5| Step: 9
Training loss: 1.7643966674804688
Validation loss: 2.0280468694625364

Epoch: 5| Step: 10
Training loss: 2.8368189334869385
Validation loss: 2.0130850038220807

Epoch: 184| Step: 0
Training loss: 2.4968247413635254
Validation loss: 1.989588955397247

Epoch: 5| Step: 1
Training loss: 2.4588282108306885
Validation loss: 1.968892474328318

Epoch: 5| Step: 2
Training loss: 2.657306671142578
Validation loss: 1.9661521091256091

Epoch: 5| Step: 3
Training loss: 1.6536400318145752
Validation loss: 1.9482468815260037

Epoch: 5| Step: 4
Training loss: 2.4101402759552
Validation loss: 1.9486851269199001

Epoch: 5| Step: 5
Training loss: 1.6375230550765991
Validation loss: 1.9508036105863509

Epoch: 5| Step: 6
Training loss: 2.3687405586242676
Validation loss: 1.9770915662088702

Epoch: 5| Step: 7
Training loss: 1.8849130868911743
Validation loss: 1.961045011397331

Epoch: 5| Step: 8
Training loss: 1.405371904373169
Validation loss: 1.9680017181622085

Epoch: 5| Step: 9
Training loss: 2.224318027496338
Validation loss: 1.9800167904105237

Epoch: 5| Step: 10
Training loss: 1.8127049207687378
Validation loss: 1.9687379367889897

Epoch: 185| Step: 0
Training loss: 2.304661273956299
Validation loss: 1.9904245714987479

Epoch: 5| Step: 1
Training loss: 2.443782329559326
Validation loss: 1.9866729910655687

Epoch: 5| Step: 2
Training loss: 2.3465514183044434
Validation loss: 2.001666704813639

Epoch: 5| Step: 3
Training loss: 2.017565965652466
Validation loss: 2.01984183121753

Epoch: 5| Step: 4
Training loss: 2.357034683227539
Validation loss: 2.0130737648215344

Epoch: 5| Step: 5
Training loss: 2.356959819793701
Validation loss: 2.0331488552913872

Epoch: 5| Step: 6
Training loss: 1.501578688621521
Validation loss: 2.0386540735921552

Epoch: 5| Step: 7
Training loss: 2.039522647857666
Validation loss: 2.0382799730505994

Epoch: 5| Step: 8
Training loss: 1.7687530517578125
Validation loss: 2.0329130721348587

Epoch: 5| Step: 9
Training loss: 2.0551180839538574
Validation loss: 2.047020883970363

Epoch: 5| Step: 10
Training loss: 2.034977912902832
Validation loss: 2.0345048263508785

Epoch: 186| Step: 0
Training loss: 2.016688823699951
Validation loss: 2.0380873449387087

Epoch: 5| Step: 1
Training loss: 2.214043378829956
Validation loss: 1.9877749540472542

Epoch: 5| Step: 2
Training loss: 2.6884891986846924
Validation loss: 1.9768699035849622

Epoch: 5| Step: 3
Training loss: 1.6938822269439697
Validation loss: 1.972661102971723

Epoch: 5| Step: 4
Training loss: 2.150019407272339
Validation loss: 1.9741980568055184

Epoch: 5| Step: 5
Training loss: 2.983013153076172
Validation loss: 1.960651300286734

Epoch: 5| Step: 6
Training loss: 2.1077301502227783
Validation loss: 1.954516577464278

Epoch: 5| Step: 7
Training loss: 1.6801799535751343
Validation loss: 1.9377901682289698

Epoch: 5| Step: 8
Training loss: 2.22329044342041
Validation loss: 1.9538310573947044

Epoch: 5| Step: 9
Training loss: 1.9922199249267578
Validation loss: 1.969299945780026

Epoch: 5| Step: 10
Training loss: 1.107424020767212
Validation loss: 1.982537446483489

Epoch: 187| Step: 0
Training loss: 2.3268942832946777
Validation loss: 1.9989706213756273

Epoch: 5| Step: 1
Training loss: 2.7447495460510254
Validation loss: 1.999824595707719

Epoch: 5| Step: 2
Training loss: 2.594651699066162
Validation loss: 2.003601711283448

Epoch: 5| Step: 3
Training loss: 1.9094692468643188
Validation loss: 1.9959533740115423

Epoch: 5| Step: 4
Training loss: 1.416990041732788
Validation loss: 1.9825706635752032

Epoch: 5| Step: 5
Training loss: 1.4208052158355713
Validation loss: 1.9881720901817403

Epoch: 5| Step: 6
Training loss: 2.1868929862976074
Validation loss: 1.9913347921063822

Epoch: 5| Step: 7
Training loss: 1.5257742404937744
Validation loss: 2.0178459793008785

Epoch: 5| Step: 8
Training loss: 1.8806228637695312
Validation loss: 2.0183167406307754

Epoch: 5| Step: 9
Training loss: 2.5513501167297363
Validation loss: 2.019431734597811

Epoch: 5| Step: 10
Training loss: 2.290201187133789
Validation loss: 2.0434788580863708

Epoch: 188| Step: 0
Training loss: 2.3817849159240723
Validation loss: 2.044739733460129

Epoch: 5| Step: 1
Training loss: 2.281148910522461
Validation loss: 2.034717329086796

Epoch: 5| Step: 2
Training loss: 1.6473100185394287
Validation loss: 2.031191133683728

Epoch: 5| Step: 3
Training loss: 2.46809720993042
Validation loss: 2.0164500346747776

Epoch: 5| Step: 4
Training loss: 1.9884107112884521
Validation loss: 2.0204329541934434

Epoch: 5| Step: 5
Training loss: 2.1650636196136475
Validation loss: 2.0252311357887844

Epoch: 5| Step: 6
Training loss: 2.400207042694092
Validation loss: 2.1158756209957983

Epoch: 5| Step: 7
Training loss: 2.1326370239257812
Validation loss: 2.129846483148554

Epoch: 5| Step: 8
Training loss: 1.8638429641723633
Validation loss: 2.1320651987547516

Epoch: 5| Step: 9
Training loss: 1.690563440322876
Validation loss: 2.0960761603488716

Epoch: 5| Step: 10
Training loss: 2.2606542110443115
Validation loss: 2.0586082268786687

Epoch: 189| Step: 0
Training loss: 1.9148699045181274
Validation loss: 2.0354718162167456

Epoch: 5| Step: 1
Training loss: 1.5464895963668823
Validation loss: 1.9999100418501004

Epoch: 5| Step: 2
Training loss: 2.1100547313690186
Validation loss: 1.987074068797532

Epoch: 5| Step: 3
Training loss: 1.9406883716583252
Validation loss: 1.9519845362632506

Epoch: 5| Step: 4
Training loss: 2.3268277645111084
Validation loss: 1.9727156290443995

Epoch: 5| Step: 5
Training loss: 2.6289937496185303
Validation loss: 1.9508166300353182

Epoch: 5| Step: 6
Training loss: 2.5412065982818604
Validation loss: 1.946853240331014

Epoch: 5| Step: 7
Training loss: 2.155266523361206
Validation loss: 1.9609038291438934

Epoch: 5| Step: 8
Training loss: 1.489056944847107
Validation loss: 1.9563763321086924

Epoch: 5| Step: 9
Training loss: 2.313993453979492
Validation loss: 1.9502292243383264

Epoch: 5| Step: 10
Training loss: 2.169254779815674
Validation loss: 1.9573259507456133

Epoch: 190| Step: 0
Training loss: 2.1965787410736084
Validation loss: 1.9623834958640478

Epoch: 5| Step: 1
Training loss: 2.019083261489868
Validation loss: 1.985575940019341

Epoch: 5| Step: 2
Training loss: 2.0270419120788574
Validation loss: 2.028816733309018

Epoch: 5| Step: 3
Training loss: 1.9546676874160767
Validation loss: 2.062702355846282

Epoch: 5| Step: 4
Training loss: 2.078918695449829
Validation loss: 2.0487629611005067

Epoch: 5| Step: 5
Training loss: 1.8979657888412476
Validation loss: 2.0338850790454495

Epoch: 5| Step: 6
Training loss: 2.414942979812622
Validation loss: 1.997408115735618

Epoch: 5| Step: 7
Training loss: 2.068632125854492
Validation loss: 1.9855132615694435

Epoch: 5| Step: 8
Training loss: 1.7092050313949585
Validation loss: 1.9796642334230485

Epoch: 5| Step: 9
Training loss: 2.35278058052063
Validation loss: 2.0056844616449006

Epoch: 5| Step: 10
Training loss: 2.0710031986236572
Validation loss: 2.021445307680356

Epoch: 191| Step: 0
Training loss: 2.150736093521118
Validation loss: 2.0309355592214935

Epoch: 5| Step: 1
Training loss: 2.067486524581909
Validation loss: 2.010722403885216

Epoch: 5| Step: 2
Training loss: 1.7822176218032837
Validation loss: 2.0139169449447305

Epoch: 5| Step: 3
Training loss: 2.1072628498077393
Validation loss: 2.0006635022419754

Epoch: 5| Step: 4
Training loss: 2.117009401321411
Validation loss: 1.9932964040387062

Epoch: 5| Step: 5
Training loss: 2.507845640182495
Validation loss: 1.9950169235147455

Epoch: 5| Step: 6
Training loss: 2.1777987480163574
Validation loss: 1.9948032184313702

Epoch: 5| Step: 7
Training loss: 1.5689637660980225
Validation loss: 1.977503938059653

Epoch: 5| Step: 8
Training loss: 2.0744411945343018
Validation loss: 1.9849212451647686

Epoch: 5| Step: 9
Training loss: 2.3696556091308594
Validation loss: 1.9875118950361848

Epoch: 5| Step: 10
Training loss: 1.283834457397461
Validation loss: 1.989434346075981

Epoch: 192| Step: 0
Training loss: 1.5960139036178589
Validation loss: 1.9889384315859886

Epoch: 5| Step: 1
Training loss: 2.3761987686157227
Validation loss: 1.9684991554547382

Epoch: 5| Step: 2
Training loss: 2.41163969039917
Validation loss: 1.9851133092757194

Epoch: 5| Step: 3
Training loss: 2.7504138946533203
Validation loss: 1.9867970199995144

Epoch: 5| Step: 4
Training loss: 1.846337080001831
Validation loss: 2.009296066017561

Epoch: 5| Step: 5
Training loss: 2.1607749462127686
Validation loss: 2.0258849102963685

Epoch: 5| Step: 6
Training loss: 2.043673038482666
Validation loss: 2.034841773330524

Epoch: 5| Step: 7
Training loss: 1.4009798765182495
Validation loss: 2.0348395942359843

Epoch: 5| Step: 8
Training loss: 2.6256277561187744
Validation loss: 2.017468531926473

Epoch: 5| Step: 9
Training loss: 2.151380777359009
Validation loss: 1.9795457804074852

Epoch: 5| Step: 10
Training loss: 1.572631597518921
Validation loss: 1.969586956885553

Epoch: 193| Step: 0
Training loss: 1.776855230331421
Validation loss: 1.970886645778533

Epoch: 5| Step: 1
Training loss: 2.3770077228546143
Validation loss: 1.9828976328654955

Epoch: 5| Step: 2
Training loss: 1.6202118396759033
Validation loss: 1.9751451194927256

Epoch: 5| Step: 3
Training loss: 2.194927215576172
Validation loss: 2.017403671818395

Epoch: 5| Step: 4
Training loss: 2.866117477416992
Validation loss: 2.0639591140131794

Epoch: 5| Step: 5
Training loss: 2.0475542545318604
Validation loss: 2.0630881427436747

Epoch: 5| Step: 6
Training loss: 1.8238540887832642
Validation loss: 2.0454140145291566

Epoch: 5| Step: 7
Training loss: 1.821091651916504
Validation loss: 2.005258434562273

Epoch: 5| Step: 8
Training loss: 2.7274959087371826
Validation loss: 1.9568218479874313

Epoch: 5| Step: 9
Training loss: 1.3270477056503296
Validation loss: 1.9396509906297088

Epoch: 5| Step: 10
Training loss: 1.646907091140747
Validation loss: 1.9429085818670129

Epoch: 194| Step: 0
Training loss: 1.743626356124878
Validation loss: 1.9367298669712518

Epoch: 5| Step: 1
Training loss: 2.0636775493621826
Validation loss: 1.9368905944208945

Epoch: 5| Step: 2
Training loss: 1.9355312585830688
Validation loss: 1.9371117097075268

Epoch: 5| Step: 3
Training loss: 1.9502474069595337
Validation loss: 1.928036089866392

Epoch: 5| Step: 4
Training loss: 1.6807596683502197
Validation loss: 1.9288009840955016

Epoch: 5| Step: 5
Training loss: 2.778421401977539
Validation loss: 1.9282223678404284

Epoch: 5| Step: 6
Training loss: 2.1675217151641846
Validation loss: 1.929726028955111

Epoch: 5| Step: 7
Training loss: 2.0198798179626465
Validation loss: 1.945725134623948

Epoch: 5| Step: 8
Training loss: 1.5213565826416016
Validation loss: 1.9525159059032318

Epoch: 5| Step: 9
Training loss: 2.6277270317077637
Validation loss: 1.9756248689466906

Epoch: 5| Step: 10
Training loss: 1.8489367961883545
Validation loss: 1.9662000440782117

Epoch: 195| Step: 0
Training loss: 2.332629680633545
Validation loss: 1.9862483265579387

Epoch: 5| Step: 1
Training loss: 1.4610847234725952
Validation loss: 1.990973327749519

Epoch: 5| Step: 2
Training loss: 1.8953107595443726
Validation loss: 1.9877054319586804

Epoch: 5| Step: 3
Training loss: 1.9470323324203491
Validation loss: 2.006350049408533

Epoch: 5| Step: 4
Training loss: 2.118145704269409
Validation loss: 1.9998207015375937

Epoch: 5| Step: 5
Training loss: 1.5934909582138062
Validation loss: 2.003047985415305

Epoch: 5| Step: 6
Training loss: 1.9211641550064087
Validation loss: 1.9761056002750192

Epoch: 5| Step: 7
Training loss: 2.118560791015625
Validation loss: 1.9542894735131213

Epoch: 5| Step: 8
Training loss: 2.4813778400421143
Validation loss: 1.9619618769614928

Epoch: 5| Step: 9
Training loss: 1.7877881526947021
Validation loss: 1.9548508608213035

Epoch: 5| Step: 10
Training loss: 2.5374956130981445
Validation loss: 1.9584415830591673

Epoch: 196| Step: 0
Training loss: 2.325303316116333
Validation loss: 1.9591668882677633

Epoch: 5| Step: 1
Training loss: 2.1982789039611816
Validation loss: 1.9622098015200706

Epoch: 5| Step: 2
Training loss: 1.9763495922088623
Validation loss: 1.9635272769517795

Epoch: 5| Step: 3
Training loss: 1.9932845830917358
Validation loss: 1.9797188453776862

Epoch: 5| Step: 4
Training loss: 2.2066116333007812
Validation loss: 1.9909845757228073

Epoch: 5| Step: 5
Training loss: 2.079956293106079
Validation loss: 1.9989282482413835

Epoch: 5| Step: 6
Training loss: 1.5437475442886353
Validation loss: 1.996917773318547

Epoch: 5| Step: 7
Training loss: 1.5867418050765991
Validation loss: 1.993772255477085

Epoch: 5| Step: 8
Training loss: 2.322808027267456
Validation loss: 2.0090106033509776

Epoch: 5| Step: 9
Training loss: 1.9344412088394165
Validation loss: 2.0010810180376937

Epoch: 5| Step: 10
Training loss: 2.0399277210235596
Validation loss: 1.9918919865803053

Epoch: 197| Step: 0
Training loss: 2.0265612602233887
Validation loss: 1.9762586393663961

Epoch: 5| Step: 1
Training loss: 2.3127923011779785
Validation loss: 1.979793671638735

Epoch: 5| Step: 2
Training loss: 2.49661922454834
Validation loss: 1.9736494915459746

Epoch: 5| Step: 3
Training loss: 2.1223952770233154
Validation loss: 1.9781297253024193

Epoch: 5| Step: 4
Training loss: 1.4150859117507935
Validation loss: 1.996951392901841

Epoch: 5| Step: 5
Training loss: 2.1113059520721436
Validation loss: 1.9781721266367103

Epoch: 5| Step: 6
Training loss: 1.7650445699691772
Validation loss: 1.9977658205134894

Epoch: 5| Step: 7
Training loss: 1.400400161743164
Validation loss: 2.0053040340382564

Epoch: 5| Step: 8
Training loss: 1.869882583618164
Validation loss: 2.0089845631712224

Epoch: 5| Step: 9
Training loss: 2.119537830352783
Validation loss: 2.0367945676208823

Epoch: 5| Step: 10
Training loss: 2.383345127105713
Validation loss: 2.04306960105896

Epoch: 198| Step: 0
Training loss: 2.7257494926452637
Validation loss: 2.034943378099831

Epoch: 5| Step: 1
Training loss: 2.7593798637390137
Validation loss: 2.002411405245463

Epoch: 5| Step: 2
Training loss: 1.285576581954956
Validation loss: 1.9634543695757467

Epoch: 5| Step: 3
Training loss: 1.9446239471435547
Validation loss: 1.9719369642196163

Epoch: 5| Step: 4
Training loss: 1.7327293157577515
Validation loss: 1.95561921211981

Epoch: 5| Step: 5
Training loss: 2.007617235183716
Validation loss: 1.9715108589459491

Epoch: 5| Step: 6
Training loss: 1.4868417978286743
Validation loss: 1.9671555924159225

Epoch: 5| Step: 7
Training loss: 1.826305627822876
Validation loss: 1.9905464239017938

Epoch: 5| Step: 8
Training loss: 2.605910301208496
Validation loss: 2.0128611287763043

Epoch: 5| Step: 9
Training loss: 1.8816821575164795
Validation loss: 2.05556579302716

Epoch: 5| Step: 10
Training loss: 2.122532606124878
Validation loss: 2.07377351227627

Epoch: 199| Step: 0
Training loss: 2.755466938018799
Validation loss: 2.0279880416008735

Epoch: 5| Step: 1
Training loss: 1.8761554956436157
Validation loss: 2.027871463888435

Epoch: 5| Step: 2
Training loss: 1.4925236701965332
Validation loss: 1.9881386295441659

Epoch: 5| Step: 3
Training loss: 1.5244486331939697
Validation loss: 1.9703384471196

Epoch: 5| Step: 4
Training loss: 1.7432132959365845
Validation loss: 1.9620403089830953

Epoch: 5| Step: 5
Training loss: 1.5319281816482544
Validation loss: 1.9363380709002096

Epoch: 5| Step: 6
Training loss: 2.2814762592315674
Validation loss: 1.946987368727243

Epoch: 5| Step: 7
Training loss: 1.824852705001831
Validation loss: 1.9518689288887927

Epoch: 5| Step: 8
Training loss: 1.7207931280136108
Validation loss: 1.9474629253469489

Epoch: 5| Step: 9
Training loss: 2.2793374061584473
Validation loss: 1.9662485558499572

Epoch: 5| Step: 10
Training loss: 2.7582969665527344
Validation loss: 1.962037201850645

Epoch: 200| Step: 0
Training loss: 2.255950927734375
Validation loss: 1.9805460565833635

Epoch: 5| Step: 1
Training loss: 1.4518520832061768
Validation loss: 1.9921708863268617

Epoch: 5| Step: 2
Training loss: 1.8547958135604858
Validation loss: 1.9997588075617307

Epoch: 5| Step: 3
Training loss: 2.0009307861328125
Validation loss: 2.0051329366622435

Epoch: 5| Step: 4
Training loss: 2.425687313079834
Validation loss: 2.015348005038436

Epoch: 5| Step: 5
Training loss: 1.7556642293930054
Validation loss: 2.0293928833417993

Epoch: 5| Step: 6
Training loss: 2.0974395275115967
Validation loss: 2.0217189045362574

Epoch: 5| Step: 7
Training loss: 1.9731025695800781
Validation loss: 1.997816962580527

Epoch: 5| Step: 8
Training loss: 1.8578494787216187
Validation loss: 2.008727968380015

Epoch: 5| Step: 9
Training loss: 1.6360257863998413
Validation loss: 1.9791962882523895

Epoch: 5| Step: 10
Training loss: 2.1270804405212402
Validation loss: 1.9742810239074051

Epoch: 201| Step: 0
Training loss: 1.3643255233764648
Validation loss: 1.9630895660769554

Epoch: 5| Step: 1
Training loss: 1.8064028024673462
Validation loss: 1.9690455864834528

Epoch: 5| Step: 2
Training loss: 1.5265480279922485
Validation loss: 1.972310696878741

Epoch: 5| Step: 3
Training loss: 2.263288974761963
Validation loss: 2.013602695157451

Epoch: 5| Step: 4
Training loss: 1.931039810180664
Validation loss: 2.0208291879264255

Epoch: 5| Step: 5
Training loss: 2.2302613258361816
Validation loss: 2.003651201084096

Epoch: 5| Step: 6
Training loss: 2.0724101066589355
Validation loss: 2.0078921189872165

Epoch: 5| Step: 7
Training loss: 1.582863450050354
Validation loss: 2.002125870796942

Epoch: 5| Step: 8
Training loss: 3.224910259246826
Validation loss: 2.0084541177236908

Epoch: 5| Step: 9
Training loss: 1.544109582901001
Validation loss: 1.985669583402654

Epoch: 5| Step: 10
Training loss: 1.7583626508712769
Validation loss: 1.9841694806211738

Epoch: 202| Step: 0
Training loss: 1.6395021677017212
Validation loss: 1.9696396473915345

Epoch: 5| Step: 1
Training loss: 1.8740129470825195
Validation loss: 1.9687751454691733

Epoch: 5| Step: 2
Training loss: 2.1378073692321777
Validation loss: 1.9595870433315155

Epoch: 5| Step: 3
Training loss: 1.5741815567016602
Validation loss: 2.0218564823109615

Epoch: 5| Step: 4
Training loss: 2.7522799968719482
Validation loss: 2.0575531272478003

Epoch: 5| Step: 5
Training loss: 1.2747100591659546
Validation loss: 2.0229583504379436

Epoch: 5| Step: 6
Training loss: 2.683279037475586
Validation loss: 2.009526296328473

Epoch: 5| Step: 7
Training loss: 1.7767692804336548
Validation loss: 1.9721592164808703

Epoch: 5| Step: 8
Training loss: 2.045278549194336
Validation loss: 1.9442888870034167

Epoch: 5| Step: 9
Training loss: 1.910748839378357
Validation loss: 1.9397149829454319

Epoch: 5| Step: 10
Training loss: 1.9364873170852661
Validation loss: 1.927906172249907

Epoch: 203| Step: 0
Training loss: 2.089127779006958
Validation loss: 1.9243252751647786

Epoch: 5| Step: 1
Training loss: 2.0179927349090576
Validation loss: 1.9387201288694977

Epoch: 5| Step: 2
Training loss: 1.8854749202728271
Validation loss: 1.9613176853426042

Epoch: 5| Step: 3
Training loss: 1.4008821249008179
Validation loss: 1.9497165526113203

Epoch: 5| Step: 4
Training loss: 2.0017874240875244
Validation loss: 1.982882950895576

Epoch: 5| Step: 5
Training loss: 2.1263158321380615
Validation loss: 1.9669382597810479

Epoch: 5| Step: 6
Training loss: 2.7548394203186035
Validation loss: 1.9564360367354525

Epoch: 5| Step: 7
Training loss: 1.4385980367660522
Validation loss: 1.968796827459848

Epoch: 5| Step: 8
Training loss: 1.284793734550476
Validation loss: 1.9732871581149358

Epoch: 5| Step: 9
Training loss: 1.9317729473114014
Validation loss: 1.957809761006345

Epoch: 5| Step: 10
Training loss: 2.137606382369995
Validation loss: 1.9693702446517123

Epoch: 204| Step: 0
Training loss: 1.8567959070205688
Validation loss: 1.9662556507254159

Epoch: 5| Step: 1
Training loss: 1.5148680210113525
Validation loss: 1.9524615169853292

Epoch: 5| Step: 2
Training loss: 2.4972944259643555
Validation loss: 1.9239154143999981

Epoch: 5| Step: 3
Training loss: 2.2294716835021973
Validation loss: 1.91054355969993

Epoch: 5| Step: 4
Training loss: 2.142138719558716
Validation loss: 1.914112739665534

Epoch: 5| Step: 5
Training loss: 1.5975830554962158
Validation loss: 1.9095901866112985

Epoch: 5| Step: 6
Training loss: 1.5918811559677124
Validation loss: 1.9178861661623883

Epoch: 5| Step: 7
Training loss: 1.7033350467681885
Validation loss: 1.9278241806132819

Epoch: 5| Step: 8
Training loss: 1.7495536804199219
Validation loss: 1.9704724563065397

Epoch: 5| Step: 9
Training loss: 1.784796953201294
Validation loss: 1.9809863644261514

Epoch: 5| Step: 10
Training loss: 2.417388677597046
Validation loss: 2.015358142955329

Epoch: 205| Step: 0
Training loss: 2.0086700916290283
Validation loss: 2.0321163208253923

Epoch: 5| Step: 1
Training loss: 1.707151174545288
Validation loss: 2.0585143143130886

Epoch: 5| Step: 2
Training loss: 2.621236801147461
Validation loss: 2.077009839396323

Epoch: 5| Step: 3
Training loss: 1.7287877798080444
Validation loss: 2.060855321986701

Epoch: 5| Step: 4
Training loss: 1.9894342422485352
Validation loss: 2.0823268608380388

Epoch: 5| Step: 5
Training loss: 1.8073720932006836
Validation loss: 2.033590453927235

Epoch: 5| Step: 6
Training loss: 1.9478181600570679
Validation loss: 1.9981172764173118

Epoch: 5| Step: 7
Training loss: 2.222761631011963
Validation loss: 1.9770138596975675

Epoch: 5| Step: 8
Training loss: 1.6413406133651733
Validation loss: 1.9617474873860676

Epoch: 5| Step: 9
Training loss: 2.0860435962677
Validation loss: 1.9511133381115493

Epoch: 5| Step: 10
Training loss: 1.8523544073104858
Validation loss: 1.9438555009903447

Epoch: 206| Step: 0
Training loss: 1.9459784030914307
Validation loss: 1.934858693871447

Epoch: 5| Step: 1
Training loss: 2.4227490425109863
Validation loss: 1.98180878034202

Epoch: 5| Step: 2
Training loss: 2.0637168884277344
Validation loss: 2.014874539067668

Epoch: 5| Step: 3
Training loss: 2.1835782527923584
Validation loss: 2.0277666122682634

Epoch: 5| Step: 4
Training loss: 1.5248510837554932
Validation loss: 2.0179643605345037

Epoch: 5| Step: 5
Training loss: 1.5516293048858643
Validation loss: 1.960605049646029

Epoch: 5| Step: 6
Training loss: 2.0330939292907715
Validation loss: 1.9209256569544475

Epoch: 5| Step: 7
Training loss: 1.9445924758911133
Validation loss: 1.8903139560453353

Epoch: 5| Step: 8
Training loss: 1.6613521575927734
Validation loss: 1.893732068359211

Epoch: 5| Step: 9
Training loss: 2.4485714435577393
Validation loss: 1.8920470258241058

Epoch: 5| Step: 10
Training loss: 1.7695435285568237
Validation loss: 1.8953997447926512

Epoch: 207| Step: 0
Training loss: 1.8557937145233154
Validation loss: 1.9118442509763984

Epoch: 5| Step: 1
Training loss: 2.4349710941314697
Validation loss: 1.943534617782921

Epoch: 5| Step: 2
Training loss: 1.9616912603378296
Validation loss: 1.949235672591835

Epoch: 5| Step: 3
Training loss: 1.712741494178772
Validation loss: 2.000486454656047

Epoch: 5| Step: 4
Training loss: 1.7491512298583984
Validation loss: 2.01525886853536

Epoch: 5| Step: 5
Training loss: 2.2278175354003906
Validation loss: 2.037817934507965

Epoch: 5| Step: 6
Training loss: 1.6162950992584229
Validation loss: 2.0256765452764367

Epoch: 5| Step: 7
Training loss: 2.1038997173309326
Validation loss: 2.0082916380256735

Epoch: 5| Step: 8
Training loss: 1.2184369564056396
Validation loss: 1.967115004857381

Epoch: 5| Step: 9
Training loss: 1.8139899969100952
Validation loss: 1.991537796553745

Epoch: 5| Step: 10
Training loss: 2.028139591217041
Validation loss: 1.9759649589497557

Epoch: 208| Step: 0
Training loss: 2.2179954051971436
Validation loss: 2.0304986148752193

Epoch: 5| Step: 1
Training loss: 1.4287569522857666
Validation loss: 2.034803062356928

Epoch: 5| Step: 2
Training loss: 1.7000936269760132
Validation loss: 2.0350295830798406

Epoch: 5| Step: 3
Training loss: 2.13020396232605
Validation loss: 2.018881236353228

Epoch: 5| Step: 4
Training loss: 1.6690117120742798
Validation loss: 1.9548826730379494

Epoch: 5| Step: 5
Training loss: 1.9715194702148438
Validation loss: 1.9349161501853698

Epoch: 5| Step: 6
Training loss: 2.301527738571167
Validation loss: 1.9263352091594408

Epoch: 5| Step: 7
Training loss: 1.3646868467330933
Validation loss: 1.920876754227505

Epoch: 5| Step: 8
Training loss: 2.1204190254211426
Validation loss: 1.9237481829940632

Epoch: 5| Step: 9
Training loss: 2.0621981620788574
Validation loss: 1.9177900924477527

Epoch: 5| Step: 10
Training loss: 1.8038665056228638
Validation loss: 1.9615206154443885

Epoch: 209| Step: 0
Training loss: 1.7579694986343384
Validation loss: 2.009064241122174

Epoch: 5| Step: 1
Training loss: 1.5327262878417969
Validation loss: 2.0025817232747234

Epoch: 5| Step: 2
Training loss: 2.128347873687744
Validation loss: 1.9994957818779895

Epoch: 5| Step: 3
Training loss: 2.263798475265503
Validation loss: 1.994978243304837

Epoch: 5| Step: 4
Training loss: 1.9032392501831055
Validation loss: 1.992464352679509

Epoch: 5| Step: 5
Training loss: 1.8853803873062134
Validation loss: 2.0016213232471096

Epoch: 5| Step: 6
Training loss: 1.4504492282867432
Validation loss: 2.0107605995670443

Epoch: 5| Step: 7
Training loss: 2.273918628692627
Validation loss: 2.0213002184385895

Epoch: 5| Step: 8
Training loss: 1.1928967237472534
Validation loss: 2.0074002140311786

Epoch: 5| Step: 9
Training loss: 1.5996536016464233
Validation loss: 2.0168070870061077

Epoch: 5| Step: 10
Training loss: 2.660768508911133
Validation loss: 1.9962825018872496

Epoch: 210| Step: 0
Training loss: 1.3821529150009155
Validation loss: 1.9968531042016961

Epoch: 5| Step: 1
Training loss: 1.8599687814712524
Validation loss: 1.9984369508681759

Epoch: 5| Step: 2
Training loss: 1.630048394203186
Validation loss: 1.9804195844998924

Epoch: 5| Step: 3
Training loss: 1.292948842048645
Validation loss: 1.9814824429891442

Epoch: 5| Step: 4
Training loss: 2.569044589996338
Validation loss: 1.9618590134446339

Epoch: 5| Step: 5
Training loss: 1.8507198095321655
Validation loss: 1.9464904531355827

Epoch: 5| Step: 6
Training loss: 2.110320568084717
Validation loss: 1.9486373214311496

Epoch: 5| Step: 7
Training loss: 2.0466532707214355
Validation loss: 1.9364385092130272

Epoch: 5| Step: 8
Training loss: 1.911492109298706
Validation loss: 1.941919288327617

Epoch: 5| Step: 9
Training loss: 1.7500584125518799
Validation loss: 1.9669854051323348

Epoch: 5| Step: 10
Training loss: 1.8904467821121216
Validation loss: 1.975734801702602

Epoch: 211| Step: 0
Training loss: 2.2393345832824707
Validation loss: 1.9581134421851045

Epoch: 5| Step: 1
Training loss: 2.170592784881592
Validation loss: 1.9567414304261566

Epoch: 5| Step: 2
Training loss: 1.313640832901001
Validation loss: 1.9774276479598014

Epoch: 5| Step: 3
Training loss: 1.9080638885498047
Validation loss: 1.9716618522520988

Epoch: 5| Step: 4
Training loss: 1.5821863412857056
Validation loss: 1.965743052062168

Epoch: 5| Step: 5
Training loss: 1.4921905994415283
Validation loss: 1.9678275508265342

Epoch: 5| Step: 6
Training loss: 1.9189544916152954
Validation loss: 1.959256972036054

Epoch: 5| Step: 7
Training loss: 2.4806275367736816
Validation loss: 1.972467924958916

Epoch: 5| Step: 8
Training loss: 1.6376876831054688
Validation loss: 1.9711609758356565

Epoch: 5| Step: 9
Training loss: 1.7322990894317627
Validation loss: 1.9976075926134664

Epoch: 5| Step: 10
Training loss: 1.6898891925811768
Validation loss: 2.0051842530568442

Epoch: 212| Step: 0
Training loss: 2.408886671066284
Validation loss: 2.0091370613344255

Epoch: 5| Step: 1
Training loss: 1.5650228261947632
Validation loss: 2.0152013788941088

Epoch: 5| Step: 2
Training loss: 1.6723438501358032
Validation loss: 2.0156819781949444

Epoch: 5| Step: 3
Training loss: 1.234339714050293
Validation loss: 2.009633369343255

Epoch: 5| Step: 4
Training loss: 2.316706895828247
Validation loss: 1.9962763773497714

Epoch: 5| Step: 5
Training loss: 2.044541835784912
Validation loss: 2.0089255250910276

Epoch: 5| Step: 6
Training loss: 1.6696078777313232
Validation loss: 2.037788075785483

Epoch: 5| Step: 7
Training loss: 1.5835552215576172
Validation loss: 2.0738028736524683

Epoch: 5| Step: 8
Training loss: 2.577868938446045
Validation loss: 2.130253602099675

Epoch: 5| Step: 9
Training loss: 1.1015026569366455
Validation loss: 2.0930614945709065

Epoch: 5| Step: 10
Training loss: 2.30033540725708
Validation loss: 2.029092765623523

Epoch: 213| Step: 0
Training loss: 1.87346613407135
Validation loss: 1.949076376935487

Epoch: 5| Step: 1
Training loss: 1.8381468057632446
Validation loss: 1.9207151961582962

Epoch: 5| Step: 2
Training loss: 2.373375415802002
Validation loss: 1.8965422607237292

Epoch: 5| Step: 3
Training loss: 1.8569557666778564
Validation loss: 1.8918276089493946

Epoch: 5| Step: 4
Training loss: 2.072190761566162
Validation loss: 1.8884222379294775

Epoch: 5| Step: 5
Training loss: 1.4681726694107056
Validation loss: 1.9088780969701789

Epoch: 5| Step: 6
Training loss: 1.8775560855865479
Validation loss: 1.9278762494364092

Epoch: 5| Step: 7
Training loss: 1.6050455570220947
Validation loss: 1.9710865430934454

Epoch: 5| Step: 8
Training loss: 2.155402421951294
Validation loss: 1.9986517788261495

Epoch: 5| Step: 9
Training loss: 1.9915202856063843
Validation loss: 2.0364661114190215

Epoch: 5| Step: 10
Training loss: 2.115565538406372
Validation loss: 2.0181259314219155

Epoch: 214| Step: 0
Training loss: 1.2811508178710938
Validation loss: 1.993967338274884

Epoch: 5| Step: 1
Training loss: 2.0009028911590576
Validation loss: 1.9435322284698486

Epoch: 5| Step: 2
Training loss: 1.7871555089950562
Validation loss: 1.9216659171606905

Epoch: 5| Step: 3
Training loss: 1.9089000225067139
Validation loss: 1.9141288213832404

Epoch: 5| Step: 4
Training loss: 1.6802995204925537
Validation loss: 1.9266413796332575

Epoch: 5| Step: 5
Training loss: 2.1033124923706055
Validation loss: 1.9235280982909664

Epoch: 5| Step: 6
Training loss: 2.638427972793579
Validation loss: 1.9254096349080403

Epoch: 5| Step: 7
Training loss: 1.9049437046051025
Validation loss: 1.9327549190931423

Epoch: 5| Step: 8
Training loss: 1.254764199256897
Validation loss: 1.9512857660170524

Epoch: 5| Step: 9
Training loss: 2.1366236209869385
Validation loss: 1.962502702589958

Epoch: 5| Step: 10
Training loss: 2.02693247795105
Validation loss: 2.002279939190034

Epoch: 215| Step: 0
Training loss: 2.232788562774658
Validation loss: 2.0114912243299585

Epoch: 5| Step: 1
Training loss: 1.9835180044174194
Validation loss: 2.0171216380211616

Epoch: 5| Step: 2
Training loss: 1.6469895839691162
Validation loss: 2.045293322173498

Epoch: 5| Step: 3
Training loss: 1.921164870262146
Validation loss: 2.019173664431418

Epoch: 5| Step: 4
Training loss: 1.8024790287017822
Validation loss: 1.969281332467192

Epoch: 5| Step: 5
Training loss: 2.305943012237549
Validation loss: 1.9357361229517127

Epoch: 5| Step: 6
Training loss: 2.097123622894287
Validation loss: 1.9002526703701224

Epoch: 5| Step: 7
Training loss: 1.1460379362106323
Validation loss: 1.897432686180197

Epoch: 5| Step: 8
Training loss: 1.4928576946258545
Validation loss: 1.9224851080166396

Epoch: 5| Step: 9
Training loss: 1.7739381790161133
Validation loss: 1.951787369225615

Epoch: 5| Step: 10
Training loss: 1.9415903091430664
Validation loss: 1.9686023650630828

Epoch: 216| Step: 0
Training loss: 1.9260553121566772
Validation loss: 1.9805524413303663

Epoch: 5| Step: 1
Training loss: 1.8429090976715088
Validation loss: 1.9845737359857047

Epoch: 5| Step: 2
Training loss: 1.1477152109146118
Validation loss: 1.9662165898148731

Epoch: 5| Step: 3
Training loss: 1.8538930416107178
Validation loss: 1.9609068670580465

Epoch: 5| Step: 4
Training loss: 2.170372486114502
Validation loss: 1.945251000824795

Epoch: 5| Step: 5
Training loss: 2.389589786529541
Validation loss: 1.964800198872884

Epoch: 5| Step: 6
Training loss: 1.5321556329727173
Validation loss: 1.9581474155508063

Epoch: 5| Step: 7
Training loss: 2.0919747352600098
Validation loss: 1.9517541316247755

Epoch: 5| Step: 8
Training loss: 1.8570289611816406
Validation loss: 1.9321908758532615

Epoch: 5| Step: 9
Training loss: 1.3648475408554077
Validation loss: 1.9416324400132703

Epoch: 5| Step: 10
Training loss: 1.676778793334961
Validation loss: 1.9380365456304243

Epoch: 217| Step: 0
Training loss: 1.8295475244522095
Validation loss: 1.9538276887709094

Epoch: 5| Step: 1
Training loss: 2.0250611305236816
Validation loss: 1.9667248251617595

Epoch: 5| Step: 2
Training loss: 1.9692285060882568
Validation loss: 1.9603688345160535

Epoch: 5| Step: 3
Training loss: 1.3087115287780762
Validation loss: 1.9573735908795429

Epoch: 5| Step: 4
Training loss: 2.398545742034912
Validation loss: 1.9427971711722754

Epoch: 5| Step: 5
Training loss: 1.5324362516403198
Validation loss: 1.9634713485676756

Epoch: 5| Step: 6
Training loss: 1.8852970600128174
Validation loss: 1.959571712760515

Epoch: 5| Step: 7
Training loss: 1.4232757091522217
Validation loss: 1.982937205222345

Epoch: 5| Step: 8
Training loss: 1.7415310144424438
Validation loss: 2.0143885868851856

Epoch: 5| Step: 9
Training loss: 1.6413100957870483
Validation loss: 2.0287483558859876

Epoch: 5| Step: 10
Training loss: 2.1345832347869873
Validation loss: 2.005382642951063

Epoch: 218| Step: 0
Training loss: 2.1124043464660645
Validation loss: 1.9594719858579739

Epoch: 5| Step: 1
Training loss: 1.5767674446105957
Validation loss: 1.9283590778227775

Epoch: 5| Step: 2
Training loss: 1.9205131530761719
Validation loss: 1.9131313626484205

Epoch: 5| Step: 3
Training loss: 1.939314842224121
Validation loss: 1.9238871015528196

Epoch: 5| Step: 4
Training loss: 1.5158579349517822
Validation loss: 1.9222926670505154

Epoch: 5| Step: 5
Training loss: 1.7448402643203735
Validation loss: 1.9279894059704197

Epoch: 5| Step: 6
Training loss: 1.4642778635025024
Validation loss: 1.9650269272506877

Epoch: 5| Step: 7
Training loss: 1.6835664510726929
Validation loss: 1.9731083992988832

Epoch: 5| Step: 8
Training loss: 1.407654047012329
Validation loss: 1.9874552090962727

Epoch: 5| Step: 9
Training loss: 2.500007152557373
Validation loss: 1.9815105494632517

Epoch: 5| Step: 10
Training loss: 1.4194910526275635
Validation loss: 1.9505528224411832

Epoch: 219| Step: 0
Training loss: 2.055417537689209
Validation loss: 1.9647891623999483

Epoch: 5| Step: 1
Training loss: 1.8504688739776611
Validation loss: 1.9631891788974885

Epoch: 5| Step: 2
Training loss: 1.6661176681518555
Validation loss: 1.9399739016768753

Epoch: 5| Step: 3
Training loss: 1.6167014837265015
Validation loss: 1.9510524657464796

Epoch: 5| Step: 4
Training loss: 1.4614559412002563
Validation loss: 1.958391426711954

Epoch: 5| Step: 5
Training loss: 2.3482613563537598
Validation loss: 1.9599996074553458

Epoch: 5| Step: 6
Training loss: 1.857499361038208
Validation loss: 1.9816396210783271

Epoch: 5| Step: 7
Training loss: 1.8043676614761353
Validation loss: 1.9702754930783344

Epoch: 5| Step: 8
Training loss: 1.4990793466567993
Validation loss: 1.9385168462671258

Epoch: 5| Step: 9
Training loss: 1.694528579711914
Validation loss: 1.957024061551658

Epoch: 5| Step: 10
Training loss: 1.49396550655365
Validation loss: 1.9541779166908675

Epoch: 220| Step: 0
Training loss: 1.7628778219223022
Validation loss: 1.9625254805370043

Epoch: 5| Step: 1
Training loss: 1.4146254062652588
Validation loss: 1.9382026477526593

Epoch: 5| Step: 2
Training loss: 2.198239803314209
Validation loss: 1.9663527652781496

Epoch: 5| Step: 3
Training loss: 2.092045307159424
Validation loss: 1.9530647262450187

Epoch: 5| Step: 4
Training loss: 1.7058067321777344
Validation loss: 1.9867270454283683

Epoch: 5| Step: 5
Training loss: 1.8117914199829102
Validation loss: 2.0038276000689437

Epoch: 5| Step: 6
Training loss: 1.4146251678466797
Validation loss: 2.012555178775582

Epoch: 5| Step: 7
Training loss: 2.1549441814422607
Validation loss: 2.021511290663032

Epoch: 5| Step: 8
Training loss: 1.5141575336456299
Validation loss: 2.0305898522817962

Epoch: 5| Step: 9
Training loss: 1.4484375715255737
Validation loss: 2.0107839492059525

Epoch: 5| Step: 10
Training loss: 1.6244546175003052
Validation loss: 2.045478497782061

Epoch: 221| Step: 0
Training loss: 1.870784044265747
Validation loss: 2.026480115869994

Epoch: 5| Step: 1
Training loss: 2.000020980834961
Validation loss: 1.9970038552438059

Epoch: 5| Step: 2
Training loss: 1.42019522190094
Validation loss: 1.9912717701286398

Epoch: 5| Step: 3
Training loss: 1.6186182498931885
Validation loss: 1.9898079825985817

Epoch: 5| Step: 4
Training loss: 2.114738941192627
Validation loss: 1.982184971532514

Epoch: 5| Step: 5
Training loss: 1.8660576343536377
Validation loss: 1.994315557582404

Epoch: 5| Step: 6
Training loss: 1.6308403015136719
Validation loss: 1.9833176379562707

Epoch: 5| Step: 7
Training loss: 1.4793049097061157
Validation loss: 1.9504348757446452

Epoch: 5| Step: 8
Training loss: 1.6424872875213623
Validation loss: 1.9231724136619157

Epoch: 5| Step: 9
Training loss: 1.8279845714569092
Validation loss: 1.9178236428127493

Epoch: 5| Step: 10
Training loss: 2.183849811553955
Validation loss: 1.8943221556243075

Epoch: 222| Step: 0
Training loss: 1.433645248413086
Validation loss: 1.9047013072557346

Epoch: 5| Step: 1
Training loss: 1.6977373361587524
Validation loss: 1.9390966712787587

Epoch: 5| Step: 2
Training loss: 1.7345123291015625
Validation loss: 1.9794105560548845

Epoch: 5| Step: 3
Training loss: 1.816382646560669
Validation loss: 2.008310671775572

Epoch: 5| Step: 4
Training loss: 2.3067240715026855
Validation loss: 2.01630207543732

Epoch: 5| Step: 5
Training loss: 2.0098729133605957
Validation loss: 1.9843538999557495

Epoch: 5| Step: 6
Training loss: 1.706758737564087
Validation loss: 1.972416332972947

Epoch: 5| Step: 7
Training loss: 1.816699743270874
Validation loss: 1.9719925798395628

Epoch: 5| Step: 8
Training loss: 1.7427276372909546
Validation loss: 1.956885737757529

Epoch: 5| Step: 9
Training loss: 0.6465436816215515
Validation loss: 1.9662034537202568

Epoch: 5| Step: 10
Training loss: 2.6175575256347656
Validation loss: 1.9969959464124454

Epoch: 223| Step: 0
Training loss: 1.5314007997512817
Validation loss: 2.019623492353706

Epoch: 5| Step: 1
Training loss: 1.7151330709457397
Validation loss: 2.0391920240976478

Epoch: 5| Step: 2
Training loss: 1.447078824043274
Validation loss: 2.0055625797599874

Epoch: 5| Step: 3
Training loss: 1.608697533607483
Validation loss: 2.006879693718367

Epoch: 5| Step: 4
Training loss: 1.5942832231521606
Validation loss: 1.9935878758789392

Epoch: 5| Step: 5
Training loss: 1.9419984817504883
Validation loss: 1.9770732002873574

Epoch: 5| Step: 6
Training loss: 2.093040943145752
Validation loss: 1.970105658295334

Epoch: 5| Step: 7
Training loss: 1.603890061378479
Validation loss: 1.9567332601034513

Epoch: 5| Step: 8
Training loss: 1.516576886177063
Validation loss: 1.9520830569728729

Epoch: 5| Step: 9
Training loss: 2.083768606185913
Validation loss: 1.9465925539693525

Epoch: 5| Step: 10
Training loss: 1.7690553665161133
Validation loss: 1.967104709276589

Epoch: 224| Step: 0
Training loss: 1.6322729587554932
Validation loss: 1.9836299496312295

Epoch: 5| Step: 1
Training loss: 2.237609386444092
Validation loss: 1.9891782037673458

Epoch: 5| Step: 2
Training loss: 1.9453818798065186
Validation loss: 1.9699138159392982

Epoch: 5| Step: 3
Training loss: 1.3711931705474854
Validation loss: 1.9290009993378834

Epoch: 5| Step: 4
Training loss: 1.3739712238311768
Validation loss: 1.9093191482687508

Epoch: 5| Step: 5
Training loss: 2.185939311981201
Validation loss: 1.8979441094142135

Epoch: 5| Step: 6
Training loss: 1.3794094324111938
Validation loss: 1.8927219311396282

Epoch: 5| Step: 7
Training loss: 1.9179073572158813
Validation loss: 1.9091673281884962

Epoch: 5| Step: 8
Training loss: 1.0469988584518433
Validation loss: 1.9198662516891316

Epoch: 5| Step: 9
Training loss: 2.23244571685791
Validation loss: 1.9541556219900809

Epoch: 5| Step: 10
Training loss: 2.0322091579437256
Validation loss: 1.9694739054608088

Epoch: 225| Step: 0
Training loss: 1.8755295276641846
Validation loss: 2.0011454935996764

Epoch: 5| Step: 1
Training loss: 1.8614181280136108
Validation loss: 2.0104922363834996

Epoch: 5| Step: 2
Training loss: 2.2602806091308594
Validation loss: 2.019429091484316

Epoch: 5| Step: 3
Training loss: 1.3620766401290894
Validation loss: 2.000081664772444

Epoch: 5| Step: 4
Training loss: 1.5575178861618042
Validation loss: 1.9730966039883193

Epoch: 5| Step: 5
Training loss: 1.947363257408142
Validation loss: 1.9598510162804716

Epoch: 5| Step: 6
Training loss: 1.6511497497558594
Validation loss: 1.9542048656812279

Epoch: 5| Step: 7
Training loss: 1.3354089260101318
Validation loss: 1.9711232493000646

Epoch: 5| Step: 8
Training loss: 1.3562039136886597
Validation loss: 1.9929519827647875

Epoch: 5| Step: 9
Training loss: 1.2030980587005615
Validation loss: 1.9727645407440841

Epoch: 5| Step: 10
Training loss: 2.653242826461792
Validation loss: 1.9967558563396495

Epoch: 226| Step: 0
Training loss: 1.8985683917999268
Validation loss: 1.9877559420883015

Epoch: 5| Step: 1
Training loss: 1.9834718704223633
Validation loss: 1.9745577612230856

Epoch: 5| Step: 2
Training loss: 1.2512856721878052
Validation loss: 1.9674498893881356

Epoch: 5| Step: 3
Training loss: 1.3967087268829346
Validation loss: 1.969338632399036

Epoch: 5| Step: 4
Training loss: 1.99823796749115
Validation loss: 1.979087293788951

Epoch: 5| Step: 5
Training loss: 1.7822906970977783
Validation loss: 1.964310965230388

Epoch: 5| Step: 6
Training loss: 1.8398230075836182
Validation loss: 1.9527927444827171

Epoch: 5| Step: 7
Training loss: 1.7273929119110107
Validation loss: 1.9540516766168738

Epoch: 5| Step: 8
Training loss: 1.6361844539642334
Validation loss: 1.952393808672505

Epoch: 5| Step: 9
Training loss: 1.7688068151474
Validation loss: 1.9875374635060628

Epoch: 5| Step: 10
Training loss: 1.5483349561691284
Validation loss: 2.0381578514652867

Epoch: 227| Step: 0
Training loss: 1.7015972137451172
Validation loss: 2.0309389227180072

Epoch: 5| Step: 1
Training loss: 1.513408899307251
Validation loss: 2.014724123862482

Epoch: 5| Step: 2
Training loss: 1.42868971824646
Validation loss: 1.9636968540888962

Epoch: 5| Step: 3
Training loss: 2.1032767295837402
Validation loss: 1.9418221032747658

Epoch: 5| Step: 4
Training loss: 1.5076630115509033
Validation loss: 1.912842446757901

Epoch: 5| Step: 5
Training loss: 1.7631733417510986
Validation loss: 1.898537355084573

Epoch: 5| Step: 6
Training loss: 1.6493396759033203
Validation loss: 1.9230804186995312

Epoch: 5| Step: 7
Training loss: 2.038966655731201
Validation loss: 1.9471471745480773

Epoch: 5| Step: 8
Training loss: 1.245011568069458
Validation loss: 1.9801209857386928

Epoch: 5| Step: 9
Training loss: 1.9577772617340088
Validation loss: 1.9499808524244575

Epoch: 5| Step: 10
Training loss: 1.8443478345870972
Validation loss: 1.9476383129755657

Epoch: 228| Step: 0
Training loss: 1.1169040203094482
Validation loss: 1.9663370347792102

Epoch: 5| Step: 1
Training loss: 1.5319141149520874
Validation loss: 1.9598716753785328

Epoch: 5| Step: 2
Training loss: 2.1709086894989014
Validation loss: 1.987027560510943

Epoch: 5| Step: 3
Training loss: 2.077301025390625
Validation loss: 1.9945211897614181

Epoch: 5| Step: 4
Training loss: 2.148104429244995
Validation loss: 1.982953973995742

Epoch: 5| Step: 5
Training loss: 1.6196054220199585
Validation loss: 1.9804501751417756

Epoch: 5| Step: 6
Training loss: 1.1485564708709717
Validation loss: 1.9589484660856185

Epoch: 5| Step: 7
Training loss: 1.4782918691635132
Validation loss: 1.9377707499329762

Epoch: 5| Step: 8
Training loss: 1.1125568151474
Validation loss: 1.9342826053660402

Epoch: 5| Step: 9
Training loss: 2.4920217990875244
Validation loss: 1.936450304523591

Epoch: 5| Step: 10
Training loss: 1.5479298830032349
Validation loss: 1.9371926271787254

Epoch: 229| Step: 0
Training loss: 1.3362610340118408
Validation loss: 1.9222689162018478

Epoch: 5| Step: 1
Training loss: 1.3056747913360596
Validation loss: 1.9285324414571126

Epoch: 5| Step: 2
Training loss: 1.8291889429092407
Validation loss: 1.9919987160672423

Epoch: 5| Step: 3
Training loss: 1.5089390277862549
Validation loss: 2.049241347979474

Epoch: 5| Step: 4
Training loss: 1.9100288152694702
Validation loss: 2.070891813565326

Epoch: 5| Step: 5
Training loss: 1.9634552001953125
Validation loss: 2.0298584174084406

Epoch: 5| Step: 6
Training loss: 1.5999902486801147
Validation loss: 1.9941534752486854

Epoch: 5| Step: 7
Training loss: 2.368145227432251
Validation loss: 1.9336656549925446

Epoch: 5| Step: 8
Training loss: 1.4805934429168701
Validation loss: 1.892178056060627

Epoch: 5| Step: 9
Training loss: 1.9334628582000732
Validation loss: 1.8880923794161888

Epoch: 5| Step: 10
Training loss: 1.573423981666565
Validation loss: 1.8935615144750124

Epoch: 230| Step: 0
Training loss: 1.8011070489883423
Validation loss: 1.887806418121502

Epoch: 5| Step: 1
Training loss: 1.3221913576126099
Validation loss: 1.912382464255056

Epoch: 5| Step: 2
Training loss: 1.9122817516326904
Validation loss: 1.945855184267926

Epoch: 5| Step: 3
Training loss: 1.5450242757797241
Validation loss: 1.9798382302766204

Epoch: 5| Step: 4
Training loss: 1.52382493019104
Validation loss: 2.0145411504212247

Epoch: 5| Step: 5
Training loss: 1.643977165222168
Validation loss: 2.0085364490427

Epoch: 5| Step: 6
Training loss: 1.4862010478973389
Validation loss: 1.9951475551051479

Epoch: 5| Step: 7
Training loss: 1.7188217639923096
Validation loss: 1.9337538801213747

Epoch: 5| Step: 8
Training loss: 1.7213016748428345
Validation loss: 1.9043564565720097

Epoch: 5| Step: 9
Training loss: 1.8307949304580688
Validation loss: 1.908241118154218

Epoch: 5| Step: 10
Training loss: 1.9168250560760498
Validation loss: 1.9160824911568755

Epoch: 231| Step: 0
Training loss: 1.2435110807418823
Validation loss: 1.9279149809191305

Epoch: 5| Step: 1
Training loss: 1.1379178762435913
Validation loss: 1.9803423291893416

Epoch: 5| Step: 2
Training loss: 1.046434998512268
Validation loss: 2.0490525332830285

Epoch: 5| Step: 3
Training loss: 1.7989625930786133
Validation loss: 2.0787420401009182

Epoch: 5| Step: 4
Training loss: 2.3267009258270264
Validation loss: 2.0604877266832577

Epoch: 5| Step: 5
Training loss: 1.6175378561019897
Validation loss: 1.9924765440725511

Epoch: 5| Step: 6
Training loss: 1.8596432209014893
Validation loss: 1.9218104629106418

Epoch: 5| Step: 7
Training loss: 2.402198076248169
Validation loss: 1.8817496274107246

Epoch: 5| Step: 8
Training loss: 2.0462348461151123
Validation loss: 1.849717519616568

Epoch: 5| Step: 9
Training loss: 1.9845187664031982
Validation loss: 1.858068427731914

Epoch: 5| Step: 10
Training loss: 1.5767841339111328
Validation loss: 1.875376824409731

Epoch: 232| Step: 0
Training loss: 2.1441774368286133
Validation loss: 1.9071596437884915

Epoch: 5| Step: 1
Training loss: 1.6936155557632446
Validation loss: 1.9554851901146673

Epoch: 5| Step: 2
Training loss: 2.04180908203125
Validation loss: 1.9727444879470333

Epoch: 5| Step: 3
Training loss: 1.9097483158111572
Validation loss: 1.998409084094468

Epoch: 5| Step: 4
Training loss: 1.9405485391616821
Validation loss: 1.982524195025044

Epoch: 5| Step: 5
Training loss: 0.998155951499939
Validation loss: 1.9439928429101103

Epoch: 5| Step: 6
Training loss: 2.067699432373047
Validation loss: 1.9028369534400202

Epoch: 5| Step: 7
Training loss: 1.0809510946273804
Validation loss: 1.8630066507606096

Epoch: 5| Step: 8
Training loss: 1.3607656955718994
Validation loss: 1.842016081656179

Epoch: 5| Step: 9
Training loss: 1.8386166095733643
Validation loss: 1.8512305598105154

Epoch: 5| Step: 10
Training loss: 1.7494176626205444
Validation loss: 1.861128745540496

Epoch: 233| Step: 0
Training loss: 1.8024402856826782
Validation loss: 1.8822723755272486

Epoch: 5| Step: 1
Training loss: 1.8414642810821533
Validation loss: 1.9217164875358663

Epoch: 5| Step: 2
Training loss: 1.4065344333648682
Validation loss: 1.9513981726861769

Epoch: 5| Step: 3
Training loss: 1.5962069034576416
Validation loss: 1.9634975925568612

Epoch: 5| Step: 4
Training loss: 1.30605149269104
Validation loss: 2.032251715660095

Epoch: 5| Step: 5
Training loss: 1.7094812393188477
Validation loss: 2.045073296434136

Epoch: 5| Step: 6
Training loss: 1.2743260860443115
Validation loss: 2.076588535821566

Epoch: 5| Step: 7
Training loss: 2.0313117504119873
Validation loss: 2.0560875067146878

Epoch: 5| Step: 8
Training loss: 2.1082053184509277
Validation loss: 2.0406443367722216

Epoch: 5| Step: 9
Training loss: 1.6288259029388428
Validation loss: 2.012465028352635

Epoch: 5| Step: 10
Training loss: 1.2042230367660522
Validation loss: 1.927086712211691

Epoch: 234| Step: 0
Training loss: 1.8021042346954346
Validation loss: 1.886594274992584

Epoch: 5| Step: 1
Training loss: 1.3642758131027222
Validation loss: 1.9036812218286658

Epoch: 5| Step: 2
Training loss: 1.7827398777008057
Validation loss: 1.8884841934327157

Epoch: 5| Step: 3
Training loss: 2.0934231281280518
Validation loss: 1.8688927619687972

Epoch: 5| Step: 4
Training loss: 1.959165334701538
Validation loss: 1.882995270913647

Epoch: 5| Step: 5
Training loss: 1.9120327234268188
Validation loss: 1.932976677853574

Epoch: 5| Step: 6
Training loss: 2.208585023880005
Validation loss: 2.0039271526439215

Epoch: 5| Step: 7
Training loss: 1.3717186450958252
Validation loss: 2.0607490949733283

Epoch: 5| Step: 8
Training loss: 1.577843427658081
Validation loss: 2.0840824650179957

Epoch: 5| Step: 9
Training loss: 1.8892580270767212
Validation loss: 2.0548671945448844

Epoch: 5| Step: 10
Training loss: 1.2539407014846802
Validation loss: 1.991699925032995

Epoch: 235| Step: 0
Training loss: 1.66571044921875
Validation loss: 1.9396993857558056

Epoch: 5| Step: 1
Training loss: 1.887554407119751
Validation loss: 1.9228336964884112

Epoch: 5| Step: 2
Training loss: 1.4522968530654907
Validation loss: 1.878935792112863

Epoch: 5| Step: 3
Training loss: 1.1471608877182007
Validation loss: 1.8687653592837754

Epoch: 5| Step: 4
Training loss: 1.861169457435608
Validation loss: 1.867348935014458

Epoch: 5| Step: 5
Training loss: 2.207306385040283
Validation loss: 1.8908316922444168

Epoch: 5| Step: 6
Training loss: 1.3361642360687256
Validation loss: 1.9239877936660603

Epoch: 5| Step: 7
Training loss: 1.5433218479156494
Validation loss: 1.9775053788256902

Epoch: 5| Step: 8
Training loss: 1.6498130559921265
Validation loss: 2.0201318853644916

Epoch: 5| Step: 9
Training loss: 1.710544228553772
Validation loss: 2.05465337281586

Epoch: 5| Step: 10
Training loss: 1.7916117906570435
Validation loss: 2.1178523212350826

Epoch: 236| Step: 0
Training loss: 1.9785531759262085
Validation loss: 2.1156514665131927

Epoch: 5| Step: 1
Training loss: 1.2027384042739868
Validation loss: 2.0606639077586513

Epoch: 5| Step: 2
Training loss: 1.5821233987808228
Validation loss: 2.0260670608089817

Epoch: 5| Step: 3
Training loss: 1.3361527919769287
Validation loss: 1.9956765777321273

Epoch: 5| Step: 4
Training loss: 1.6454479694366455
Validation loss: 1.9997541942904073

Epoch: 5| Step: 5
Training loss: 1.8821563720703125
Validation loss: 1.985036761529984

Epoch: 5| Step: 6
Training loss: 1.694432258605957
Validation loss: 1.9654625961857457

Epoch: 5| Step: 7
Training loss: 2.0123443603515625
Validation loss: 1.9594544351741832

Epoch: 5| Step: 8
Training loss: 1.3977400064468384
Validation loss: 1.94650323032051

Epoch: 5| Step: 9
Training loss: 1.7454131841659546
Validation loss: 1.9376801560001988

Epoch: 5| Step: 10
Training loss: 1.57219660282135
Validation loss: 1.9170199568553636

Epoch: 237| Step: 0
Training loss: 1.6112306118011475
Validation loss: 1.9243896776630032

Epoch: 5| Step: 1
Training loss: 1.6642687320709229
Validation loss: 1.9311415610774871

Epoch: 5| Step: 2
Training loss: 1.0650577545166016
Validation loss: 1.9361430521934264

Epoch: 5| Step: 3
Training loss: 1.3078386783599854
Validation loss: 1.9546080622621762

Epoch: 5| Step: 4
Training loss: 1.4049160480499268
Validation loss: 1.9375914027613979

Epoch: 5| Step: 5
Training loss: 1.7132103443145752
Validation loss: 1.9466693503882295

Epoch: 5| Step: 6
Training loss: 1.7288299798965454
Validation loss: 1.952054169870192

Epoch: 5| Step: 7
Training loss: 1.6369603872299194
Validation loss: 1.961551115077029

Epoch: 5| Step: 8
Training loss: 1.783948302268982
Validation loss: 1.9665412723377187

Epoch: 5| Step: 9
Training loss: 2.2620432376861572
Validation loss: 1.9563852279416976

Epoch: 5| Step: 10
Training loss: 1.6518183946609497
Validation loss: 1.9793566324377572

Epoch: 238| Step: 0
Training loss: 1.7628965377807617
Validation loss: 1.9672934765456824

Epoch: 5| Step: 1
Training loss: 1.7052326202392578
Validation loss: 1.9597105979919434

Epoch: 5| Step: 2
Training loss: 1.6247361898422241
Validation loss: 1.9525735634629444

Epoch: 5| Step: 3
Training loss: 2.1357979774475098
Validation loss: 1.958236309789842

Epoch: 5| Step: 4
Training loss: 1.7539914846420288
Validation loss: 1.9575152256155526

Epoch: 5| Step: 5
Training loss: 1.1293721199035645
Validation loss: 1.9866696737145866

Epoch: 5| Step: 6
Training loss: 2.0436620712280273
Validation loss: 2.0144848387728453

Epoch: 5| Step: 7
Training loss: 1.1905957460403442
Validation loss: 1.9748460426125476

Epoch: 5| Step: 8
Training loss: 1.3484508991241455
Validation loss: 1.9723876663433608

Epoch: 5| Step: 9
Training loss: 1.3493764400482178
Validation loss: 1.9327206021995955

Epoch: 5| Step: 10
Training loss: 1.560516119003296
Validation loss: 1.9129705108622068

Epoch: 239| Step: 0
Training loss: 2.5004990100860596
Validation loss: 1.915402994360975

Epoch: 5| Step: 1
Training loss: 1.0954382419586182
Validation loss: 1.9031948492091189

Epoch: 5| Step: 2
Training loss: 1.7031867504119873
Validation loss: 1.911946286437332

Epoch: 5| Step: 3
Training loss: 2.4325058460235596
Validation loss: 1.8952009190795243

Epoch: 5| Step: 4
Training loss: 1.3805235624313354
Validation loss: 1.9211141511958132

Epoch: 5| Step: 5
Training loss: 1.6926038265228271
Validation loss: 1.9333355016605829

Epoch: 5| Step: 6
Training loss: 1.3615524768829346
Validation loss: 1.9588598564106932

Epoch: 5| Step: 7
Training loss: 1.3451499938964844
Validation loss: 1.9576761440564228

Epoch: 5| Step: 8
Training loss: 1.1832860708236694
Validation loss: 1.9359542887697938

Epoch: 5| Step: 9
Training loss: 1.2560956478118896
Validation loss: 1.9175780947490404

Epoch: 5| Step: 10
Training loss: 1.3981664180755615
Validation loss: 1.9087120371480142

Epoch: 240| Step: 0
Training loss: 1.7019622325897217
Validation loss: 1.9273055984127907

Epoch: 5| Step: 1
Training loss: 1.1959211826324463
Validation loss: 1.9491947158690421

Epoch: 5| Step: 2
Training loss: 1.1811277866363525
Validation loss: 1.9668152268214891

Epoch: 5| Step: 3
Training loss: 1.4496647119522095
Validation loss: 2.007537408541608

Epoch: 5| Step: 4
Training loss: 1.9296090602874756
Validation loss: 2.06563070384405

Epoch: 5| Step: 5
Training loss: 1.5351002216339111
Validation loss: 2.050846461326845

Epoch: 5| Step: 6
Training loss: 1.6575263738632202
Validation loss: 2.0758676810931136

Epoch: 5| Step: 7
Training loss: 1.7347233295440674
Validation loss: 2.105222943008587

Epoch: 5| Step: 8
Training loss: 2.175370931625366
Validation loss: 2.1130517939085602

Epoch: 5| Step: 9
Training loss: 1.7861850261688232
Validation loss: 2.0723621973427395

Epoch: 5| Step: 10
Training loss: 1.4723726511001587
Validation loss: 2.044616142908732

Epoch: 241| Step: 0
Training loss: 1.154599666595459
Validation loss: 1.9935310450933312

Epoch: 5| Step: 1
Training loss: 1.6355797052383423
Validation loss: 1.9340787831173147

Epoch: 5| Step: 2
Training loss: 1.9070014953613281
Validation loss: 1.909278449191842

Epoch: 5| Step: 3
Training loss: 1.5952386856079102
Validation loss: 1.9206861962554276

Epoch: 5| Step: 4
Training loss: 1.3081203699111938
Validation loss: 1.911337362822666

Epoch: 5| Step: 5
Training loss: 1.7149425745010376
Validation loss: 1.924604146711288

Epoch: 5| Step: 6
Training loss: 1.4267604351043701
Validation loss: 1.9386964075026973

Epoch: 5| Step: 7
Training loss: 1.576926589012146
Validation loss: 1.980404858948082

Epoch: 5| Step: 8
Training loss: 2.485264301300049
Validation loss: 2.0275135860648206

Epoch: 5| Step: 9
Training loss: 1.1754512786865234
Validation loss: 2.082770956459866

Epoch: 5| Step: 10
Training loss: 2.154249906539917
Validation loss: 2.10646378865806

Epoch: 242| Step: 0
Training loss: 1.3407303094863892
Validation loss: 2.1062473071518766

Epoch: 5| Step: 1
Training loss: 1.6193653345108032
Validation loss: 2.0820292106238742

Epoch: 5| Step: 2
Training loss: 1.5585577487945557
Validation loss: 1.987049230965235

Epoch: 5| Step: 3
Training loss: 1.7228577136993408
Validation loss: 1.9176741697454964

Epoch: 5| Step: 4
Training loss: 1.7889591455459595
Validation loss: 1.8832955078412128

Epoch: 5| Step: 5
Training loss: 1.1246448755264282
Validation loss: 1.866807799185476

Epoch: 5| Step: 6
Training loss: 1.8557164669036865
Validation loss: 1.8743228912353516

Epoch: 5| Step: 7
Training loss: 1.3852596282958984
Validation loss: 1.8802280528571016

Epoch: 5| Step: 8
Training loss: 2.430938243865967
Validation loss: 1.8939684167984994

Epoch: 5| Step: 9
Training loss: 1.9749202728271484
Validation loss: 1.912867340990292

Epoch: 5| Step: 10
Training loss: 1.4002238512039185
Validation loss: 1.9418443979755524

Epoch: 243| Step: 0
Training loss: 1.5646107196807861
Validation loss: 1.9829154706770373

Epoch: 5| Step: 1
Training loss: 2.218626022338867
Validation loss: 1.9961330275381766

Epoch: 5| Step: 2
Training loss: 1.2570937871932983
Validation loss: 1.9869623491840978

Epoch: 5| Step: 3
Training loss: 1.3390815258026123
Validation loss: 2.013903346112979

Epoch: 5| Step: 4
Training loss: 1.5077447891235352
Validation loss: 1.9971574070633098

Epoch: 5| Step: 5
Training loss: 1.5578762292861938
Validation loss: 1.943316444273918

Epoch: 5| Step: 6
Training loss: 1.9835050106048584
Validation loss: 1.9021963868089902

Epoch: 5| Step: 7
Training loss: 0.9948858022689819
Validation loss: 1.8816788811837473

Epoch: 5| Step: 8
Training loss: 2.329900026321411
Validation loss: 1.858149205484698

Epoch: 5| Step: 9
Training loss: 1.3680833578109741
Validation loss: 1.868208207109923

Epoch: 5| Step: 10
Training loss: 1.8954986333847046
Validation loss: 1.8629990598206878

Epoch: 244| Step: 0
Training loss: 1.6762521266937256
Validation loss: 1.871423141930693

Epoch: 5| Step: 1
Training loss: 1.4305928945541382
Validation loss: 1.8927525243451517

Epoch: 5| Step: 2
Training loss: 1.312185525894165
Validation loss: 1.9207489054690126

Epoch: 5| Step: 3
Training loss: 1.1591851711273193
Validation loss: 1.9754200186780704

Epoch: 5| Step: 4
Training loss: 1.3897291421890259
Validation loss: 2.0407038927078247

Epoch: 5| Step: 5
Training loss: 1.7572816610336304
Validation loss: 2.0390813735223587

Epoch: 5| Step: 6
Training loss: 1.3521192073822021
Validation loss: 2.032551280913814

Epoch: 5| Step: 7
Training loss: 2.3581466674804688
Validation loss: 2.0015909582056026

Epoch: 5| Step: 8
Training loss: 1.6331994533538818
Validation loss: 1.9564918164283998

Epoch: 5| Step: 9
Training loss: 1.497195839881897
Validation loss: 1.9164127585708455

Epoch: 5| Step: 10
Training loss: 1.7074042558670044
Validation loss: 1.9246304547914894

Epoch: 245| Step: 0
Training loss: 1.5945045948028564
Validation loss: 1.9549616844423356

Epoch: 5| Step: 1
Training loss: 1.7557661533355713
Validation loss: 1.975401755302183

Epoch: 5| Step: 2
Training loss: 1.555917739868164
Validation loss: 2.008742565749794

Epoch: 5| Step: 3
Training loss: 1.108749508857727
Validation loss: 1.9996589435044156

Epoch: 5| Step: 4
Training loss: 1.5752967596054077
Validation loss: 1.975049723861038

Epoch: 5| Step: 5
Training loss: 1.1336307525634766
Validation loss: 1.9346047460391957

Epoch: 5| Step: 6
Training loss: 1.7133687734603882
Validation loss: 1.9145327486017698

Epoch: 5| Step: 7
Training loss: 1.6352983713150024
Validation loss: 1.8868561508835002

Epoch: 5| Step: 8
Training loss: 1.1528849601745605
Validation loss: 1.8949053902779855

Epoch: 5| Step: 9
Training loss: 1.7435576915740967
Validation loss: 1.916764646448115

Epoch: 5| Step: 10
Training loss: 2.0678727626800537
Validation loss: 1.9129705377804336

Epoch: 246| Step: 0
Training loss: 1.542548656463623
Validation loss: 1.9092441271710139

Epoch: 5| Step: 1
Training loss: 1.4867489337921143
Validation loss: 1.8965107625530613

Epoch: 5| Step: 2
Training loss: 1.7323402166366577
Validation loss: 1.859076415338824

Epoch: 5| Step: 3
Training loss: 1.35885751247406
Validation loss: 1.8753635780785674

Epoch: 5| Step: 4
Training loss: 1.562239170074463
Validation loss: 1.8985817201675907

Epoch: 5| Step: 5
Training loss: 1.2675772905349731
Validation loss: 1.9366664514746716

Epoch: 5| Step: 6
Training loss: 1.7998079061508179
Validation loss: 2.006105576792071

Epoch: 5| Step: 7
Training loss: 1.493668794631958
Validation loss: 2.0451636416937715

Epoch: 5| Step: 8
Training loss: 1.8910220861434937
Validation loss: 2.052922446240661

Epoch: 5| Step: 9
Training loss: 1.4746782779693604
Validation loss: 1.988213251995784

Epoch: 5| Step: 10
Training loss: 1.4858043193817139
Validation loss: 1.9719715195317422

Epoch: 247| Step: 0
Training loss: 1.3483701944351196
Validation loss: 1.9640163888213455

Epoch: 5| Step: 1
Training loss: 1.5154333114624023
Validation loss: 1.9832948305273568

Epoch: 5| Step: 2
Training loss: 1.8639652729034424
Validation loss: 1.977651229468725

Epoch: 5| Step: 3
Training loss: 1.6318517923355103
Validation loss: 1.9913147444366126

Epoch: 5| Step: 4
Training loss: 1.9032999277114868
Validation loss: 1.9717966792404011

Epoch: 5| Step: 5
Training loss: 1.041640043258667
Validation loss: 1.985439068527632

Epoch: 5| Step: 6
Training loss: 1.9506314992904663
Validation loss: 1.9979777733484905

Epoch: 5| Step: 7
Training loss: 1.6113321781158447
Validation loss: 1.9685235779772523

Epoch: 5| Step: 8
Training loss: 1.1676843166351318
Validation loss: 1.9250860470597462

Epoch: 5| Step: 9
Training loss: 1.7982765436172485
Validation loss: 1.894415770807574

Epoch: 5| Step: 10
Training loss: 0.9385093450546265
Validation loss: 1.856582078882443

Epoch: 248| Step: 0
Training loss: 1.6891883611679077
Validation loss: 1.830728619329391

Epoch: 5| Step: 1
Training loss: 1.5491834878921509
Validation loss: 1.8053043388551282

Epoch: 5| Step: 2
Training loss: 1.4647142887115479
Validation loss: 1.8139177124987367

Epoch: 5| Step: 3
Training loss: 1.7595014572143555
Validation loss: 1.810457609033072

Epoch: 5| Step: 4
Training loss: 1.2777509689331055
Validation loss: 1.8069486618041992

Epoch: 5| Step: 5
Training loss: 1.1697180271148682
Validation loss: 1.8571534182435723

Epoch: 5| Step: 6
Training loss: 1.4263389110565186
Validation loss: 1.9134761684684343

Epoch: 5| Step: 7
Training loss: 1.7951514720916748
Validation loss: 1.981935880517447

Epoch: 5| Step: 8
Training loss: 1.527822732925415
Validation loss: 2.004547780559909

Epoch: 5| Step: 9
Training loss: 1.5527852773666382
Validation loss: 2.0419539059362104

Epoch: 5| Step: 10
Training loss: 2.220836639404297
Validation loss: 2.069789735219812

Epoch: 249| Step: 0
Training loss: 1.5603090524673462
Validation loss: 2.061816869243499

Epoch: 5| Step: 1
Training loss: 1.4411907196044922
Validation loss: 2.046735435403803

Epoch: 5| Step: 2
Training loss: 2.075112819671631
Validation loss: 2.016667705710216

Epoch: 5| Step: 3
Training loss: 1.0662921667099
Validation loss: 1.9539563989126554

Epoch: 5| Step: 4
Training loss: 1.8216712474822998
Validation loss: 1.9078763684918802

Epoch: 5| Step: 5
Training loss: 1.6411828994750977
Validation loss: 1.8919743799394177

Epoch: 5| Step: 6
Training loss: 1.3610851764678955
Validation loss: 1.880692878077107

Epoch: 5| Step: 7
Training loss: 1.5967966318130493
Validation loss: 1.899055257920296

Epoch: 5| Step: 8
Training loss: 1.8857345581054688
Validation loss: 1.8936796367809337

Epoch: 5| Step: 9
Training loss: 1.2555978298187256
Validation loss: 1.9480806140489475

Epoch: 5| Step: 10
Training loss: 1.1715011596679688
Validation loss: 2.0037744263167023

Epoch: 250| Step: 0
Training loss: 1.3109885454177856
Validation loss: 2.0270010079106977

Epoch: 5| Step: 1
Training loss: 1.6577991247177124
Validation loss: 2.05231035652981

Epoch: 5| Step: 2
Training loss: 1.4850741624832153
Validation loss: 2.0221866599975096

Epoch: 5| Step: 3
Training loss: 1.4624813795089722
Validation loss: 1.964055388204513

Epoch: 5| Step: 4
Training loss: 1.6146392822265625
Validation loss: 1.9284552463921167

Epoch: 5| Step: 5
Training loss: 1.8029944896697998
Validation loss: 1.8926914686797767

Epoch: 5| Step: 6
Training loss: 1.3960338830947876
Validation loss: 1.887775851834205

Epoch: 5| Step: 7
Training loss: 1.4194637537002563
Validation loss: 1.9084798789793445

Epoch: 5| Step: 8
Training loss: 1.6347049474716187
Validation loss: 1.9512558406399143

Epoch: 5| Step: 9
Training loss: 1.4561569690704346
Validation loss: 2.016620397567749

Epoch: 5| Step: 10
Training loss: 1.5549440383911133
Validation loss: 2.063202201679189

Epoch: 251| Step: 0
Training loss: 1.3635005950927734
Validation loss: 2.083156639529813

Epoch: 5| Step: 1
Training loss: 1.394906759262085
Validation loss: 2.0282195691139466

Epoch: 5| Step: 2
Training loss: 1.7664295434951782
Validation loss: 1.9631917092107958

Epoch: 5| Step: 3
Training loss: 1.6242129802703857
Validation loss: 1.9090413713967929

Epoch: 5| Step: 4
Training loss: 1.6711963415145874
Validation loss: 1.9003555928507159

Epoch: 5| Step: 5
Training loss: 1.5872838497161865
Validation loss: 1.8822800241490847

Epoch: 5| Step: 6
Training loss: 1.5383689403533936
Validation loss: 1.8791814747677054

Epoch: 5| Step: 7
Training loss: 1.7343000173568726
Validation loss: 1.9038630429134573

Epoch: 5| Step: 8
Training loss: 1.5196880102157593
Validation loss: 1.9864359773615354

Epoch: 5| Step: 9
Training loss: 1.4326045513153076
Validation loss: 2.0189277997580906

Epoch: 5| Step: 10
Training loss: 1.6894458532333374
Validation loss: 2.043569832719782

Epoch: 252| Step: 0
Training loss: 1.5098650455474854
Validation loss: 2.0658322431707896

Epoch: 5| Step: 1
Training loss: 1.6211698055267334
Validation loss: 2.0713468777236117

Epoch: 5| Step: 2
Training loss: 1.5594069957733154
Validation loss: 2.028327283038888

Epoch: 5| Step: 3
Training loss: 1.979269027709961
Validation loss: 2.0175097783406577

Epoch: 5| Step: 4
Training loss: 1.1243691444396973
Validation loss: 1.9721815970636183

Epoch: 5| Step: 5
Training loss: 1.4205840826034546
Validation loss: 1.9470954069527246

Epoch: 5| Step: 6
Training loss: 1.7561419010162354
Validation loss: 1.9033060330216602

Epoch: 5| Step: 7
Training loss: 1.5344336032867432
Validation loss: 1.8984893291227278

Epoch: 5| Step: 8
Training loss: 2.0265088081359863
Validation loss: 1.9017384667550363

Epoch: 5| Step: 9
Training loss: 1.2664949893951416
Validation loss: 1.8877740739494242

Epoch: 5| Step: 10
Training loss: 1.3475979566574097
Validation loss: 1.8954972336369176

Epoch: 253| Step: 0
Training loss: 1.3883835077285767
Validation loss: 1.9200370645010343

Epoch: 5| Step: 1
Training loss: 1.9386825561523438
Validation loss: 1.9475483484165643

Epoch: 5| Step: 2
Training loss: 1.06217360496521
Validation loss: 1.9580354972552227

Epoch: 5| Step: 3
Training loss: 1.7654869556427002
Validation loss: 1.971058737847113

Epoch: 5| Step: 4
Training loss: 1.64792799949646
Validation loss: 1.9849342633319158

Epoch: 5| Step: 5
Training loss: 1.2950584888458252
Validation loss: 2.0078118488352787

Epoch: 5| Step: 6
Training loss: 1.1101045608520508
Validation loss: 2.0041562587984147

Epoch: 5| Step: 7
Training loss: 1.5214786529541016
Validation loss: 1.937631840346962

Epoch: 5| Step: 8
Training loss: 1.49258291721344
Validation loss: 1.8995259154227473

Epoch: 5| Step: 9
Training loss: 1.3300405740737915
Validation loss: 1.8895407863842544

Epoch: 5| Step: 10
Training loss: 1.8312674760818481
Validation loss: 1.891097181586809

Epoch: 254| Step: 0
Training loss: 1.3046132326126099
Validation loss: 1.8765247893589798

Epoch: 5| Step: 1
Training loss: 1.0361096858978271
Validation loss: 1.8751873354757986

Epoch: 5| Step: 2
Training loss: 1.4522138833999634
Validation loss: 1.8788628411549393

Epoch: 5| Step: 3
Training loss: 1.2354609966278076
Validation loss: 1.9269713483830935

Epoch: 5| Step: 4
Training loss: 1.557263731956482
Validation loss: 1.949526499676448

Epoch: 5| Step: 5
Training loss: 2.3042023181915283
Validation loss: 2.012520187644548

Epoch: 5| Step: 6
Training loss: 1.672796607017517
Validation loss: 2.0429284880238194

Epoch: 5| Step: 7
Training loss: 1.9568989276885986
Validation loss: 2.039479363349176

Epoch: 5| Step: 8
Training loss: 1.4804036617279053
Validation loss: 2.0262344588515577

Epoch: 5| Step: 9
Training loss: 1.4143447875976562
Validation loss: 1.9894963284974456

Epoch: 5| Step: 10
Training loss: 1.2794996500015259
Validation loss: 1.9555902327260664

Epoch: 255| Step: 0
Training loss: 1.8088312149047852
Validation loss: 1.9021519460985739

Epoch: 5| Step: 1
Training loss: 0.757820725440979
Validation loss: 1.881018061791697

Epoch: 5| Step: 2
Training loss: 1.5106315612792969
Validation loss: 1.8791870891406972

Epoch: 5| Step: 3
Training loss: 2.0649683475494385
Validation loss: 1.8865879492093158

Epoch: 5| Step: 4
Training loss: 1.1577661037445068
Validation loss: 1.9015370722739928

Epoch: 5| Step: 5
Training loss: 1.8370964527130127
Validation loss: 1.8912793077448362

Epoch: 5| Step: 6
Training loss: 1.3225207328796387
Validation loss: 1.924113876076155

Epoch: 5| Step: 7
Training loss: 1.0608636140823364
Validation loss: 1.9754129763572448

Epoch: 5| Step: 8
Training loss: 1.6261266469955444
Validation loss: 2.0001822851037465

Epoch: 5| Step: 9
Training loss: 1.2340896129608154
Validation loss: 2.0067437054008566

Epoch: 5| Step: 10
Training loss: 1.69375741481781
Validation loss: 2.012228601722307

Epoch: 256| Step: 0
Training loss: 1.9626004695892334
Validation loss: 1.9909285422294372

Epoch: 5| Step: 1
Training loss: 1.211478590965271
Validation loss: 1.9496002427993282

Epoch: 5| Step: 2
Training loss: 1.341772198677063
Validation loss: 1.9282370946740592

Epoch: 5| Step: 3
Training loss: 1.3018810749053955
Validation loss: 1.9281873087729178

Epoch: 5| Step: 4
Training loss: 1.3211443424224854
Validation loss: 1.91957127663397

Epoch: 5| Step: 5
Training loss: 1.0158066749572754
Validation loss: 1.9096041481981996

Epoch: 5| Step: 6
Training loss: 1.6584441661834717
Validation loss: 1.9195018852910688

Epoch: 5| Step: 7
Training loss: 1.8902270793914795
Validation loss: 1.9426665177909277

Epoch: 5| Step: 8
Training loss: 1.2716867923736572
Validation loss: 1.9656911691029866

Epoch: 5| Step: 9
Training loss: 1.679496169090271
Validation loss: 1.9855315890363467

Epoch: 5| Step: 10
Training loss: 1.222514033317566
Validation loss: 1.9902519167110484

Epoch: 257| Step: 0
Training loss: 1.4081794023513794
Validation loss: 1.9859433225406113

Epoch: 5| Step: 1
Training loss: 1.6908401250839233
Validation loss: 1.9931134485429334

Epoch: 5| Step: 2
Training loss: 1.4986785650253296
Validation loss: 1.9748094594606789

Epoch: 5| Step: 3
Training loss: 1.4075253009796143
Validation loss: 1.9364499238229567

Epoch: 5| Step: 4
Training loss: 1.730116605758667
Validation loss: 1.9325806658755067

Epoch: 5| Step: 5
Training loss: 0.9419090151786804
Validation loss: 1.928128533465888

Epoch: 5| Step: 6
Training loss: 1.8007268905639648
Validation loss: 1.9741242880462317

Epoch: 5| Step: 7
Training loss: 1.4919757843017578
Validation loss: 1.9868908415558517

Epoch: 5| Step: 8
Training loss: 1.4841227531433105
Validation loss: 2.024696429570516

Epoch: 5| Step: 9
Training loss: 1.2714147567749023
Validation loss: 2.042003693119172

Epoch: 5| Step: 10
Training loss: 1.2702064514160156
Validation loss: 2.063361642181232

Epoch: 258| Step: 0
Training loss: 1.217801809310913
Validation loss: 2.021307215895704

Epoch: 5| Step: 1
Training loss: 1.5937193632125854
Validation loss: 2.0112990974098124

Epoch: 5| Step: 2
Training loss: 1.004450798034668
Validation loss: 1.9852066706585627

Epoch: 5| Step: 3
Training loss: 1.3548070192337036
Validation loss: 1.9806212045813119

Epoch: 5| Step: 4
Training loss: 1.5936200618743896
Validation loss: 1.9637885452598653

Epoch: 5| Step: 5
Training loss: 1.464339017868042
Validation loss: 1.9421593835276942

Epoch: 5| Step: 6
Training loss: 1.0437871217727661
Validation loss: 1.9303538184012137

Epoch: 5| Step: 7
Training loss: 2.2251226902008057
Validation loss: 1.9225356976191204

Epoch: 5| Step: 8
Training loss: 1.8730484247207642
Validation loss: 1.9175549450741018

Epoch: 5| Step: 9
Training loss: 1.146120309829712
Validation loss: 1.9129823779547086

Epoch: 5| Step: 10
Training loss: 0.7449294328689575
Validation loss: 1.943698683092671

Epoch: 259| Step: 0
Training loss: 1.8363158702850342
Validation loss: 1.972221154038624

Epoch: 5| Step: 1
Training loss: 1.2253128290176392
Validation loss: 1.9963416155948435

Epoch: 5| Step: 2
Training loss: 1.429455041885376
Validation loss: 2.014476531295366

Epoch: 5| Step: 3
Training loss: 1.6266685724258423
Validation loss: 1.990833705471408

Epoch: 5| Step: 4
Training loss: 1.6738132238388062
Validation loss: 1.9681257765780213

Epoch: 5| Step: 5
Training loss: 1.913429617881775
Validation loss: 1.9509410576153827

Epoch: 5| Step: 6
Training loss: 0.43583613634109497
Validation loss: 1.9335594536155782

Epoch: 5| Step: 7
Training loss: 1.3042333126068115
Validation loss: 1.9139287343589209

Epoch: 5| Step: 8
Training loss: 1.4495967626571655
Validation loss: 1.9169403506863503

Epoch: 5| Step: 9
Training loss: 1.4701473712921143
Validation loss: 1.9404528115385322

Epoch: 5| Step: 10
Training loss: 1.126147985458374
Validation loss: 1.9841487484593545

Epoch: 260| Step: 0
Training loss: 1.2010571956634521
Validation loss: 1.9851656036992227

Epoch: 5| Step: 1
Training loss: 0.772661566734314
Validation loss: 2.0047059366779942

Epoch: 5| Step: 2
Training loss: 1.4320284128189087
Validation loss: 2.0040866995370514

Epoch: 5| Step: 3
Training loss: 1.7980493307113647
Validation loss: 2.011346822143883

Epoch: 5| Step: 4
Training loss: 1.1699628829956055
Validation loss: 1.9844421673846502

Epoch: 5| Step: 5
Training loss: 1.5211645364761353
Validation loss: 1.927517924257504

Epoch: 5| Step: 6
Training loss: 1.4745278358459473
Validation loss: 1.8917734033317977

Epoch: 5| Step: 7
Training loss: 1.6164528131484985
Validation loss: 1.8752711370427122

Epoch: 5| Step: 8
Training loss: 1.6518844366073608
Validation loss: 1.8713386930445188

Epoch: 5| Step: 9
Training loss: 1.2110167741775513
Validation loss: 1.8962137878582042

Epoch: 5| Step: 10
Training loss: 1.6801214218139648
Validation loss: 1.9067285355701242

Epoch: 261| Step: 0
Training loss: 1.799340844154358
Validation loss: 1.9387878384641422

Epoch: 5| Step: 1
Training loss: 1.6250501871109009
Validation loss: 1.9742758658624464

Epoch: 5| Step: 2
Training loss: 1.9135814905166626
Validation loss: 2.0153075341255433

Epoch: 5| Step: 3
Training loss: 1.2597050666809082
Validation loss: 2.0351154804229736

Epoch: 5| Step: 4
Training loss: 1.4723461866378784
Validation loss: 2.017034307602913

Epoch: 5| Step: 5
Training loss: 0.8725055456161499
Validation loss: 1.9782205038173224

Epoch: 5| Step: 6
Training loss: 0.9825214147567749
Validation loss: 1.958671223732733

Epoch: 5| Step: 7
Training loss: 1.341507911682129
Validation loss: 1.9444118084446076

Epoch: 5| Step: 8
Training loss: 0.9176910519599915
Validation loss: 1.9109196791084864

Epoch: 5| Step: 9
Training loss: 1.500109314918518
Validation loss: 1.8956071804928523

Epoch: 5| Step: 10
Training loss: 1.318512201309204
Validation loss: 1.8850622920579807

Epoch: 262| Step: 0
Training loss: 1.139620065689087
Validation loss: 1.8865709714992072

Epoch: 5| Step: 1
Training loss: 1.5849850177764893
Validation loss: 1.906300119174424

Epoch: 5| Step: 2
Training loss: 1.482161045074463
Validation loss: 1.926997592372279

Epoch: 5| Step: 3
Training loss: 1.4115368127822876
Validation loss: 1.9587475894599833

Epoch: 5| Step: 4
Training loss: 1.0460152626037598
Validation loss: 2.002548110100531

Epoch: 5| Step: 5
Training loss: 1.3022369146347046
Validation loss: 2.0015909658965243

Epoch: 5| Step: 6
Training loss: 1.8084537982940674
Validation loss: 1.9811345082457348

Epoch: 5| Step: 7
Training loss: 1.3481876850128174
Validation loss: 1.9860124934104182

Epoch: 5| Step: 8
Training loss: 1.235859990119934
Validation loss: 1.966830406137692

Epoch: 5| Step: 9
Training loss: 1.3077127933502197
Validation loss: 1.9736934092737013

Epoch: 5| Step: 10
Training loss: 1.28465735912323
Validation loss: 1.972960647716317

Epoch: 263| Step: 0
Training loss: 1.0840392112731934
Validation loss: 1.9122497830339658

Epoch: 5| Step: 1
Training loss: 1.2090017795562744
Validation loss: 1.889165251485763

Epoch: 5| Step: 2
Training loss: 1.3793065547943115
Validation loss: 1.8926184228671494

Epoch: 5| Step: 3
Training loss: 1.6989167928695679
Validation loss: 1.8895524471036849

Epoch: 5| Step: 4
Training loss: 1.3926645517349243
Validation loss: 1.8861677954273839

Epoch: 5| Step: 5
Training loss: 1.7883110046386719
Validation loss: 1.8969406350966422

Epoch: 5| Step: 6
Training loss: 1.9042764902114868
Validation loss: 1.904866180112285

Epoch: 5| Step: 7
Training loss: 1.5364375114440918
Validation loss: 1.9222071773262435

Epoch: 5| Step: 8
Training loss: 0.8665326237678528
Validation loss: 1.9098485022462823

Epoch: 5| Step: 9
Training loss: 1.2340326309204102
Validation loss: 1.9219321640588904

Epoch: 5| Step: 10
Training loss: 1.025963544845581
Validation loss: 1.8980678499385875

Epoch: 264| Step: 0
Training loss: 1.3858829736709595
Validation loss: 1.8998401216281358

Epoch: 5| Step: 1
Training loss: 1.3786661624908447
Validation loss: 1.8967592780308058

Epoch: 5| Step: 2
Training loss: 1.0947641134262085
Validation loss: 1.9244993297002648

Epoch: 5| Step: 3
Training loss: 1.3102105855941772
Validation loss: 1.9503035865804201

Epoch: 5| Step: 4
Training loss: 1.3600314855575562
Validation loss: 2.003137493646273

Epoch: 5| Step: 5
Training loss: 1.2621772289276123
Validation loss: 1.9964537799999278

Epoch: 5| Step: 6
Training loss: 1.800605058670044
Validation loss: 1.9935314604031142

Epoch: 5| Step: 7
Training loss: 1.490983009338379
Validation loss: 2.0082837227852113

Epoch: 5| Step: 8
Training loss: 1.0068001747131348
Validation loss: 1.9872612235366658

Epoch: 5| Step: 9
Training loss: 1.4726132154464722
Validation loss: 1.9768011108521493

Epoch: 5| Step: 10
Training loss: 1.065322995185852
Validation loss: 1.9094548071584394

Epoch: 265| Step: 0
Training loss: 2.2020912170410156
Validation loss: 1.895539188897738

Epoch: 5| Step: 1
Training loss: 1.0267037153244019
Validation loss: 1.8865789392943024

Epoch: 5| Step: 2
Training loss: 1.4337430000305176
Validation loss: 1.897855604848554

Epoch: 5| Step: 3
Training loss: 1.2244236469268799
Validation loss: 1.8903332987139303

Epoch: 5| Step: 4
Training loss: 1.3804007768630981
Validation loss: 1.948284674716252

Epoch: 5| Step: 5
Training loss: 1.3839092254638672
Validation loss: 2.021719491609963

Epoch: 5| Step: 6
Training loss: 1.5513666868209839
Validation loss: 2.0939331426415393

Epoch: 5| Step: 7
Training loss: 1.6086208820343018
Validation loss: 2.0941643740541194

Epoch: 5| Step: 8
Training loss: 1.0225355625152588
Validation loss: 2.104543734622258

Epoch: 5| Step: 9
Training loss: 0.9981732368469238
Validation loss: 2.0675634850737867

Epoch: 5| Step: 10
Training loss: 1.4888536930084229
Validation loss: 1.9676291865687217

Epoch: 266| Step: 0
Training loss: 1.6587889194488525
Validation loss: 1.8880000216986543

Epoch: 5| Step: 1
Training loss: 1.9182758331298828
Validation loss: 1.8807279166354929

Epoch: 5| Step: 2
Training loss: 2.0340375900268555
Validation loss: 1.886645991315124

Epoch: 5| Step: 3
Training loss: 1.2248713970184326
Validation loss: 1.8800023422446301

Epoch: 5| Step: 4
Training loss: 1.2105802297592163
Validation loss: 1.9115908056177118

Epoch: 5| Step: 5
Training loss: 1.1391633749008179
Validation loss: 1.9179330846314788

Epoch: 5| Step: 6
Training loss: 1.0795047283172607
Validation loss: 1.9697124650401454

Epoch: 5| Step: 7
Training loss: 1.1082565784454346
Validation loss: 1.988668905791416

Epoch: 5| Step: 8
Training loss: 1.1222918033599854
Validation loss: 1.9660665450557586

Epoch: 5| Step: 9
Training loss: 1.471071720123291
Validation loss: 1.9334690404194657

Epoch: 5| Step: 10
Training loss: 1.5656033754348755
Validation loss: 1.9100681633077643

Epoch: 267| Step: 0
Training loss: 1.5726163387298584
Validation loss: 1.88610924572073

Epoch: 5| Step: 1
Training loss: 1.1326123476028442
Validation loss: 1.8765923130896784

Epoch: 5| Step: 2
Training loss: 1.6457732915878296
Validation loss: 1.852163739101861

Epoch: 5| Step: 3
Training loss: 1.2136681079864502
Validation loss: 1.8278313067651564

Epoch: 5| Step: 4
Training loss: 1.7442805767059326
Validation loss: 1.8319634160687845

Epoch: 5| Step: 5
Training loss: 0.9388052225112915
Validation loss: 1.8423311710357666

Epoch: 5| Step: 6
Training loss: 1.3303275108337402
Validation loss: 1.8464518618840042

Epoch: 5| Step: 7
Training loss: 1.6043293476104736
Validation loss: 1.8616464573849913

Epoch: 5| Step: 8
Training loss: 0.995536208152771
Validation loss: 1.8758964897483907

Epoch: 5| Step: 9
Training loss: 1.441476821899414
Validation loss: 1.9185666371417303

Epoch: 5| Step: 10
Training loss: 1.017648696899414
Validation loss: 1.982026743632491

Epoch: 268| Step: 0
Training loss: 1.1937909126281738
Validation loss: 2.032489874029672

Epoch: 5| Step: 1
Training loss: 1.5233408212661743
Validation loss: 2.05494374229062

Epoch: 5| Step: 2
Training loss: 1.436151385307312
Validation loss: 2.0285483303890435

Epoch: 5| Step: 3
Training loss: 1.7303149700164795
Validation loss: 1.9839322054257957

Epoch: 5| Step: 4
Training loss: 1.1632108688354492
Validation loss: 1.903784885201403

Epoch: 5| Step: 5
Training loss: 1.133608102798462
Validation loss: 1.8950168919819657

Epoch: 5| Step: 6
Training loss: 1.8445167541503906
Validation loss: 1.8777684934677616

Epoch: 5| Step: 7
Training loss: 1.3027193546295166
Validation loss: 1.9040641400121874

Epoch: 5| Step: 8
Training loss: 1.1563642024993896
Validation loss: 1.9155963082467355

Epoch: 5| Step: 9
Training loss: 1.3437821865081787
Validation loss: 1.9378872174088673

Epoch: 5| Step: 10
Training loss: 1.0843294858932495
Validation loss: 1.955689784019224

Epoch: 269| Step: 0
Training loss: 1.2905337810516357
Validation loss: 1.9644507618360623

Epoch: 5| Step: 1
Training loss: 1.119721531867981
Validation loss: 1.925761047229972

Epoch: 5| Step: 2
Training loss: 1.4172736406326294
Validation loss: 1.890455784336213

Epoch: 5| Step: 3
Training loss: 1.1815240383148193
Validation loss: 1.9015836228606522

Epoch: 5| Step: 4
Training loss: 1.2686671018600464
Validation loss: 1.9160235851041731

Epoch: 5| Step: 5
Training loss: 1.2652136087417603
Validation loss: 1.9165609754541868

Epoch: 5| Step: 6
Training loss: 1.281980037689209
Validation loss: 1.9321082894520094

Epoch: 5| Step: 7
Training loss: 1.3662242889404297
Validation loss: 1.9258476918743503

Epoch: 5| Step: 8
Training loss: 1.46013605594635
Validation loss: 1.9238435324802194

Epoch: 5| Step: 9
Training loss: 1.4483853578567505
Validation loss: 1.9307492868874663

Epoch: 5| Step: 10
Training loss: 1.2586679458618164
Validation loss: 1.9506477899448846

Epoch: 270| Step: 0
Training loss: 1.177633285522461
Validation loss: 1.9494297273697392

Epoch: 5| Step: 1
Training loss: 1.140619158744812
Validation loss: 1.924321941150132

Epoch: 5| Step: 2
Training loss: 1.2243626117706299
Validation loss: 1.9010065973445933

Epoch: 5| Step: 3
Training loss: 1.6354570388793945
Validation loss: 1.8773244170732395

Epoch: 5| Step: 4
Training loss: 1.6161651611328125
Validation loss: 1.842643355810514

Epoch: 5| Step: 5
Training loss: 1.2000548839569092
Validation loss: 1.8278707893945838

Epoch: 5| Step: 6
Training loss: 1.4740369319915771
Validation loss: 1.838622720010819

Epoch: 5| Step: 7
Training loss: 1.4663817882537842
Validation loss: 1.867360174015004

Epoch: 5| Step: 8
Training loss: 1.2121121883392334
Validation loss: 1.8941569930763655

Epoch: 5| Step: 9
Training loss: 1.155460000038147
Validation loss: 1.9508310005229006

Epoch: 5| Step: 10
Training loss: 1.2101476192474365
Validation loss: 1.9627841877680954

Epoch: 271| Step: 0
Training loss: 1.203283667564392
Validation loss: 1.962575609965991

Epoch: 5| Step: 1
Training loss: 1.7114273309707642
Validation loss: 1.9507005753055695

Epoch: 5| Step: 2
Training loss: 1.0460882186889648
Validation loss: 1.9381999187572028

Epoch: 5| Step: 3
Training loss: 1.5274547338485718
Validation loss: 1.9309978613289454

Epoch: 5| Step: 4
Training loss: 0.936914324760437
Validation loss: 1.9287764000636276

Epoch: 5| Step: 5
Training loss: 1.8934013843536377
Validation loss: 1.9326851342314033

Epoch: 5| Step: 6
Training loss: 1.1580981016159058
Validation loss: 1.9237085132188694

Epoch: 5| Step: 7
Training loss: 0.9182478189468384
Validation loss: 1.927362403561992

Epoch: 5| Step: 8
Training loss: 1.452622890472412
Validation loss: 1.9359027378020748

Epoch: 5| Step: 9
Training loss: 1.3210153579711914
Validation loss: 1.9378110324182818

Epoch: 5| Step: 10
Training loss: 1.2943081855773926
Validation loss: 1.9203207710737824

Epoch: 272| Step: 0
Training loss: 1.0377566814422607
Validation loss: 1.9184361170696955

Epoch: 5| Step: 1
Training loss: 1.3669036626815796
Validation loss: 1.9472316849616267

Epoch: 5| Step: 2
Training loss: 1.3484264612197876
Validation loss: 1.9465288244267946

Epoch: 5| Step: 3
Training loss: 0.9600114822387695
Validation loss: 1.929159971975511

Epoch: 5| Step: 4
Training loss: 1.707772970199585
Validation loss: 1.92844134248713

Epoch: 5| Step: 5
Training loss: 1.0579010248184204
Validation loss: 1.9171357103573379

Epoch: 5| Step: 6
Training loss: 1.736398458480835
Validation loss: 1.8913550710165372

Epoch: 5| Step: 7
Training loss: 1.0201404094696045
Validation loss: 1.8837824201071134

Epoch: 5| Step: 8
Training loss: 1.2718199491500854
Validation loss: 1.8864794687558246

Epoch: 5| Step: 9
Training loss: 0.8866756558418274
Validation loss: 1.9035383321905648

Epoch: 5| Step: 10
Training loss: 1.7878061532974243
Validation loss: 1.914576179237776

Epoch: 273| Step: 0
Training loss: 1.562233805656433
Validation loss: 1.9260485120998916

Epoch: 5| Step: 1
Training loss: 1.664014458656311
Validation loss: 1.9473285418684765

Epoch: 5| Step: 2
Training loss: 1.3465125560760498
Validation loss: 1.955299086468194

Epoch: 5| Step: 3
Training loss: 1.0104930400848389
Validation loss: 1.953420364728538

Epoch: 5| Step: 4
Training loss: 1.563143014907837
Validation loss: 1.9679011657673826

Epoch: 5| Step: 5
Training loss: 1.278939962387085
Validation loss: 1.9255724504429808

Epoch: 5| Step: 6
Training loss: 1.0938851833343506
Validation loss: 1.8931955868198025

Epoch: 5| Step: 7
Training loss: 0.7753437161445618
Validation loss: 1.8483694022701633

Epoch: 5| Step: 8
Training loss: 0.7474719882011414
Validation loss: 1.8409979189595869

Epoch: 5| Step: 9
Training loss: 1.1471970081329346
Validation loss: 1.8719348497288202

Epoch: 5| Step: 10
Training loss: 1.792354702949524
Validation loss: 1.9249735878359886

Epoch: 274| Step: 0
Training loss: 1.077419638633728
Validation loss: 1.9724034045332222

Epoch: 5| Step: 1
Training loss: 1.3722835779190063
Validation loss: 2.01504445973263

Epoch: 5| Step: 2
Training loss: 1.764014482498169
Validation loss: 2.0275331286973852

Epoch: 5| Step: 3
Training loss: 1.6413456201553345
Validation loss: 1.9579096917183167

Epoch: 5| Step: 4
Training loss: 0.4914465844631195
Validation loss: 1.8778268239831413

Epoch: 5| Step: 5
Training loss: 1.6595001220703125
Validation loss: 1.8475293459430817

Epoch: 5| Step: 6
Training loss: 0.8749822378158569
Validation loss: 1.816417226227381

Epoch: 5| Step: 7
Training loss: 1.0311342477798462
Validation loss: 1.8261529066229378

Epoch: 5| Step: 8
Training loss: 1.4925909042358398
Validation loss: 1.8373559533908803

Epoch: 5| Step: 9
Training loss: 1.5696282386779785
Validation loss: 1.8784492105566046

Epoch: 5| Step: 10
Training loss: 1.1756716966629028
Validation loss: 1.9292589156858382

Epoch: 275| Step: 0
Training loss: 1.015647053718567
Validation loss: 1.9724743596969112

Epoch: 5| Step: 1
Training loss: 1.2109047174453735
Validation loss: 2.030605396916789

Epoch: 5| Step: 2
Training loss: 1.5117769241333008
Validation loss: 2.008014222627045

Epoch: 5| Step: 3
Training loss: 1.5850950479507446
Validation loss: 1.9934603039936354

Epoch: 5| Step: 4
Training loss: 0.9255861043930054
Validation loss: 1.9839410025586364

Epoch: 5| Step: 5
Training loss: 1.1912065744400024
Validation loss: 1.947726131767355

Epoch: 5| Step: 6
Training loss: 1.6458946466445923
Validation loss: 1.9379835603057698

Epoch: 5| Step: 7
Training loss: 1.0734548568725586
Validation loss: 1.9173059360955351

Epoch: 5| Step: 8
Training loss: 1.2026429176330566
Validation loss: 1.9362345882641372

Epoch: 5| Step: 9
Training loss: 1.0746337175369263
Validation loss: 1.9068102580244823

Epoch: 5| Step: 10
Training loss: 1.3491460084915161
Validation loss: 1.9354258993620514

Epoch: 276| Step: 0
Training loss: 0.857880711555481
Validation loss: 1.9503360538072483

Epoch: 5| Step: 1
Training loss: 1.51897394657135
Validation loss: 1.9604551010234381

Epoch: 5| Step: 2
Training loss: 1.4476563930511475
Validation loss: 1.926103938010431

Epoch: 5| Step: 3
Training loss: 1.3380850553512573
Validation loss: 1.9007034481212657

Epoch: 5| Step: 4
Training loss: 1.18727707862854
Validation loss: 1.8894197607553134

Epoch: 5| Step: 5
Training loss: 1.5391162633895874
Validation loss: 1.873221835782451

Epoch: 5| Step: 6
Training loss: 1.1716264486312866
Validation loss: 1.8865341704378846

Epoch: 5| Step: 7
Training loss: 1.1165359020233154
Validation loss: 1.888693368563088

Epoch: 5| Step: 8
Training loss: 0.8575118184089661
Validation loss: 1.9053591425700853

Epoch: 5| Step: 9
Training loss: 1.171342134475708
Validation loss: 1.9163099796541276

Epoch: 5| Step: 10
Training loss: 1.6575591564178467
Validation loss: 1.9155234572707966

Epoch: 277| Step: 0
Training loss: 1.1316468715667725
Validation loss: 1.9020861912799139

Epoch: 5| Step: 1
Training loss: 1.2313750982284546
Validation loss: 1.8893180226766935

Epoch: 5| Step: 2
Training loss: 1.5876567363739014
Validation loss: 1.8756724672932779

Epoch: 5| Step: 3
Training loss: 0.6689427495002747
Validation loss: 1.8606994613524406

Epoch: 5| Step: 4
Training loss: 1.0615688562393188
Validation loss: 1.8695961377953971

Epoch: 5| Step: 5
Training loss: 1.4316693544387817
Validation loss: 1.877775324288235

Epoch: 5| Step: 6
Training loss: 1.3702343702316284
Validation loss: 1.8843742788478892

Epoch: 5| Step: 7
Training loss: 1.559780240058899
Validation loss: 1.8958474807841803

Epoch: 5| Step: 8
Training loss: 1.0418230295181274
Validation loss: 1.9092363183216383

Epoch: 5| Step: 9
Training loss: 1.2529642581939697
Validation loss: 1.9366252473605576

Epoch: 5| Step: 10
Training loss: 1.055352807044983
Validation loss: 1.9655026928071053

Epoch: 278| Step: 0
Training loss: 1.754356026649475
Validation loss: 1.9627491940734207

Epoch: 5| Step: 1
Training loss: 0.8539889454841614
Validation loss: 1.9676467116161058

Epoch: 5| Step: 2
Training loss: 0.9517175555229187
Validation loss: 1.9750413510107225

Epoch: 5| Step: 3
Training loss: 0.9669479131698608
Validation loss: 1.9539181378579908

Epoch: 5| Step: 4
Training loss: 1.3526537418365479
Validation loss: 1.935512597842883

Epoch: 5| Step: 5
Training loss: 0.890191376209259
Validation loss: 1.9211534287339898

Epoch: 5| Step: 6
Training loss: 1.269352674484253
Validation loss: 1.8678733841065438

Epoch: 5| Step: 7
Training loss: 0.7681086659431458
Validation loss: 1.8676668238896195

Epoch: 5| Step: 8
Training loss: 1.8303664922714233
Validation loss: 1.8432047931096887

Epoch: 5| Step: 9
Training loss: 1.5704593658447266
Validation loss: 1.8466917096927602

Epoch: 5| Step: 10
Training loss: 1.1838877201080322
Validation loss: 1.8525687622767624

Epoch: 279| Step: 0
Training loss: 0.888411819934845
Validation loss: 1.855455272941179

Epoch: 5| Step: 1
Training loss: 0.9774438738822937
Validation loss: 1.835405904759643

Epoch: 5| Step: 2
Training loss: 1.554426670074463
Validation loss: 1.8601126491382558

Epoch: 5| Step: 3
Training loss: 0.8277546167373657
Validation loss: 1.8593259678092053

Epoch: 5| Step: 4
Training loss: 1.4392659664154053
Validation loss: 1.8927296579525035

Epoch: 5| Step: 5
Training loss: 0.9642497897148132
Validation loss: 1.9207959098200644

Epoch: 5| Step: 6
Training loss: 1.4734559059143066
Validation loss: 1.9146751421754078

Epoch: 5| Step: 7
Training loss: 1.0224716663360596
Validation loss: 1.9196512532490555

Epoch: 5| Step: 8
Training loss: 1.4471465349197388
Validation loss: 1.906280566287297

Epoch: 5| Step: 9
Training loss: 1.1727430820465088
Validation loss: 1.8777249692588724

Epoch: 5| Step: 10
Training loss: 1.3473045825958252
Validation loss: 1.8607374263066117

Epoch: 280| Step: 0
Training loss: 1.011565923690796
Validation loss: 1.8494499165524718

Epoch: 5| Step: 1
Training loss: 1.107550859451294
Validation loss: 1.8407875030271468

Epoch: 5| Step: 2
Training loss: 1.172349214553833
Validation loss: 1.839429420809592

Epoch: 5| Step: 3
Training loss: 1.086751937866211
Validation loss: 1.8438392223850373

Epoch: 5| Step: 4
Training loss: 1.1238276958465576
Validation loss: 1.8420868176285938

Epoch: 5| Step: 5
Training loss: 1.1497315168380737
Validation loss: 1.850885328426156

Epoch: 5| Step: 6
Training loss: 1.0992871522903442
Validation loss: 1.8548449316332418

Epoch: 5| Step: 7
Training loss: 1.362736701965332
Validation loss: 1.8891437156226045

Epoch: 5| Step: 8
Training loss: 1.3003212213516235
Validation loss: 1.8584879418855071

Epoch: 5| Step: 9
Training loss: 1.0884554386138916
Validation loss: 1.870097005239097

Epoch: 5| Step: 10
Training loss: 1.4063490629196167
Validation loss: 1.8430218247957126

Epoch: 281| Step: 0
Training loss: 1.2365666627883911
Validation loss: 1.8292975335992792

Epoch: 5| Step: 1
Training loss: 0.9416438341140747
Validation loss: 1.8427246693641908

Epoch: 5| Step: 2
Training loss: 0.8953119516372681
Validation loss: 1.8563374409111597

Epoch: 5| Step: 3
Training loss: 1.3385727405548096
Validation loss: 1.8591540231499621

Epoch: 5| Step: 4
Training loss: 0.9091924428939819
Validation loss: 1.8914167458011257

Epoch: 5| Step: 5
Training loss: 1.1432653665542603
Validation loss: 1.8849072879360569

Epoch: 5| Step: 6
Training loss: 1.3939844369888306
Validation loss: 1.8984159884914276

Epoch: 5| Step: 7
Training loss: 1.1469570398330688
Validation loss: 1.9363279752833868

Epoch: 5| Step: 8
Training loss: 0.9837985038757324
Validation loss: 1.9471372122405677

Epoch: 5| Step: 9
Training loss: 1.595045566558838
Validation loss: 1.9289723314264768

Epoch: 5| Step: 10
Training loss: 1.221400499343872
Validation loss: 1.9338317942875687

Epoch: 282| Step: 0
Training loss: 1.7178865671157837
Validation loss: 1.9161369416021532

Epoch: 5| Step: 1
Training loss: 1.4900931119918823
Validation loss: 1.9204585834216046

Epoch: 5| Step: 2
Training loss: 1.017066478729248
Validation loss: 1.8917224868651359

Epoch: 5| Step: 3
Training loss: 1.56742262840271
Validation loss: 1.8969635194347751

Epoch: 5| Step: 4
Training loss: 0.985507607460022
Validation loss: 1.8789096545147639

Epoch: 5| Step: 5
Training loss: 0.7056944966316223
Validation loss: 1.8676675340180755

Epoch: 5| Step: 6
Training loss: 1.0069077014923096
Validation loss: 1.8445603616776005

Epoch: 5| Step: 7
Training loss: 0.9263385534286499
Validation loss: 1.8494070550446868

Epoch: 5| Step: 8
Training loss: 1.4106210470199585
Validation loss: 1.89999569103282

Epoch: 5| Step: 9
Training loss: 0.8670161962509155
Validation loss: 1.9209981413297756

Epoch: 5| Step: 10
Training loss: 0.8830979466438293
Validation loss: 1.9074527563587311

Epoch: 283| Step: 0
Training loss: 1.337976336479187
Validation loss: 1.8753633473509101

Epoch: 5| Step: 1
Training loss: 1.0006020069122314
Validation loss: 1.840394220044536

Epoch: 5| Step: 2
Training loss: 0.9210336804389954
Validation loss: 1.8491463276647753

Epoch: 5| Step: 3
Training loss: 1.4092129468917847
Validation loss: 1.8496853702811784

Epoch: 5| Step: 4
Training loss: 1.3112022876739502
Validation loss: 1.8667580863480926

Epoch: 5| Step: 5
Training loss: 1.2011123895645142
Validation loss: 1.8881885851583173

Epoch: 5| Step: 6
Training loss: 1.296217679977417
Validation loss: 1.8810702293149886

Epoch: 5| Step: 7
Training loss: 0.8043496012687683
Validation loss: 1.8713866485062467

Epoch: 5| Step: 8
Training loss: 1.524665117263794
Validation loss: 1.8558873297065817

Epoch: 5| Step: 9
Training loss: 0.9910123944282532
Validation loss: 1.8289401787583546

Epoch: 5| Step: 10
Training loss: 0.7534002661705017
Validation loss: 1.8256955646699475

Epoch: 284| Step: 0
Training loss: 1.0270150899887085
Validation loss: 1.806309675657621

Epoch: 5| Step: 1
Training loss: 1.0295007228851318
Validation loss: 1.8550561461397397

Epoch: 5| Step: 2
Training loss: 1.1916732788085938
Validation loss: 1.8535709772058713

Epoch: 5| Step: 3
Training loss: 0.999748706817627
Validation loss: 1.8645477051376014

Epoch: 5| Step: 4
Training loss: 1.1665613651275635
Validation loss: 1.8875689762894825

Epoch: 5| Step: 5
Training loss: 0.9786542654037476
Validation loss: 1.882307619176885

Epoch: 5| Step: 6
Training loss: 1.3575717210769653
Validation loss: 1.8872135493063158

Epoch: 5| Step: 7
Training loss: 0.9022029638290405
Validation loss: 1.8923830524567635

Epoch: 5| Step: 8
Training loss: 1.4609328508377075
Validation loss: 1.9030489024295603

Epoch: 5| Step: 9
Training loss: 1.2574400901794434
Validation loss: 1.8924022297705374

Epoch: 5| Step: 10
Training loss: 0.8814828991889954
Validation loss: 1.8734755836507326

Epoch: 285| Step: 0
Training loss: 1.2777092456817627
Validation loss: 1.8598770659456971

Epoch: 5| Step: 1
Training loss: 1.3058643341064453
Validation loss: 1.8503777980804443

Epoch: 5| Step: 2
Training loss: 0.6572641134262085
Validation loss: 1.8511318545187674

Epoch: 5| Step: 3
Training loss: 1.037144660949707
Validation loss: 1.8801263654103844

Epoch: 5| Step: 4
Training loss: 1.1614806652069092
Validation loss: 1.906823540246615

Epoch: 5| Step: 5
Training loss: 1.3343158960342407
Validation loss: 1.8872677895330614

Epoch: 5| Step: 6
Training loss: 1.3405870199203491
Validation loss: 1.8851651555748397

Epoch: 5| Step: 7
Training loss: 0.7631271481513977
Validation loss: 1.8668192458409134

Epoch: 5| Step: 8
Training loss: 0.9246085286140442
Validation loss: 1.839991687446512

Epoch: 5| Step: 9
Training loss: 1.0083250999450684
Validation loss: 1.8383922987086798

Epoch: 5| Step: 10
Training loss: 1.6565380096435547
Validation loss: 1.8429661425211097

Epoch: 286| Step: 0
Training loss: 0.9172977209091187
Validation loss: 1.8508267941013459

Epoch: 5| Step: 1
Training loss: 1.0077931880950928
Validation loss: 1.8858922784046461

Epoch: 5| Step: 2
Training loss: 1.2185194492340088
Validation loss: 1.9116940511170255

Epoch: 5| Step: 3
Training loss: 0.826804518699646
Validation loss: 1.9669292985752065

Epoch: 5| Step: 4
Training loss: 1.416152000427246
Validation loss: 1.9705297549565632

Epoch: 5| Step: 5
Training loss: 1.4400750398635864
Validation loss: 1.9878449670730098

Epoch: 5| Step: 6
Training loss: 1.5405957698822021
Validation loss: 1.9565938826530211

Epoch: 5| Step: 7
Training loss: 0.8725242614746094
Validation loss: 1.8987870267642442

Epoch: 5| Step: 8
Training loss: 1.1067438125610352
Validation loss: 1.8588075714726602

Epoch: 5| Step: 9
Training loss: 1.1199699640274048
Validation loss: 1.8385640792949225

Epoch: 5| Step: 10
Training loss: 1.1812739372253418
Validation loss: 1.8341499669577486

Epoch: 287| Step: 0
Training loss: 1.4088659286499023
Validation loss: 1.8479578725753292

Epoch: 5| Step: 1
Training loss: 1.1079059839248657
Validation loss: 1.857361009044032

Epoch: 5| Step: 2
Training loss: 1.4642341136932373
Validation loss: 1.9027222100124563

Epoch: 5| Step: 3
Training loss: 0.9672166109085083
Validation loss: 1.9603380900557323

Epoch: 5| Step: 4
Training loss: 1.1462945938110352
Validation loss: 2.009015102540293

Epoch: 5| Step: 5
Training loss: 0.9174238443374634
Validation loss: 2.0461851384050105

Epoch: 5| Step: 6
Training loss: 1.1874725818634033
Validation loss: 1.9900386564193233

Epoch: 5| Step: 7
Training loss: 0.9067425727844238
Validation loss: 1.917860077273461

Epoch: 5| Step: 8
Training loss: 1.2611321210861206
Validation loss: 1.8404441636095765

Epoch: 5| Step: 9
Training loss: 1.1827061176300049
Validation loss: 1.8116661194832093

Epoch: 5| Step: 10
Training loss: 1.1755613088607788
Validation loss: 1.8027645477684595

Epoch: 288| Step: 0
Training loss: 0.8932315111160278
Validation loss: 1.779949257450719

Epoch: 5| Step: 1
Training loss: 1.3050824403762817
Validation loss: 1.7873841998397664

Epoch: 5| Step: 2
Training loss: 0.9475818872451782
Validation loss: 1.8250622544237363

Epoch: 5| Step: 3
Training loss: 1.5871431827545166
Validation loss: 1.8951497539397208

Epoch: 5| Step: 4
Training loss: 1.575461983680725
Validation loss: 1.9547114231253182

Epoch: 5| Step: 5
Training loss: 1.2074695825576782
Validation loss: 1.9567636994905369

Epoch: 5| Step: 6
Training loss: 1.0139018297195435
Validation loss: 1.9530973485721055

Epoch: 5| Step: 7
Training loss: 1.1347243785858154
Validation loss: 1.9209789101795485

Epoch: 5| Step: 8
Training loss: 1.4629579782485962
Validation loss: 1.8571445967561455

Epoch: 5| Step: 9
Training loss: 0.8458408117294312
Validation loss: 1.8229358606441046

Epoch: 5| Step: 10
Training loss: 1.366981863975525
Validation loss: 1.8326046313008955

Epoch: 289| Step: 0
Training loss: 1.132269263267517
Validation loss: 1.8305133940071188

Epoch: 5| Step: 1
Training loss: 1.0989922285079956
Validation loss: 1.813931857385943

Epoch: 5| Step: 2
Training loss: 1.5285786390304565
Validation loss: 1.8302042663738292

Epoch: 5| Step: 3
Training loss: 1.3707685470581055
Validation loss: 1.8730425950019591

Epoch: 5| Step: 4
Training loss: 1.086520791053772
Validation loss: 1.9160783572863507

Epoch: 5| Step: 5
Training loss: 0.7874687314033508
Validation loss: 1.953996604488742

Epoch: 5| Step: 6
Training loss: 1.225935935974121
Validation loss: 1.9850552261516612

Epoch: 5| Step: 7
Training loss: 1.2965679168701172
Validation loss: 1.9629806036590247

Epoch: 5| Step: 8
Training loss: 0.9189903140068054
Validation loss: 1.9043559874257734

Epoch: 5| Step: 9
Training loss: 1.271923303604126
Validation loss: 1.8612425288846415

Epoch: 5| Step: 10
Training loss: 1.4755953550338745
Validation loss: 1.834475609564012

Epoch: 290| Step: 0
Training loss: 0.9963051080703735
Validation loss: 1.8343295205023982

Epoch: 5| Step: 1
Training loss: 1.0547523498535156
Validation loss: 1.8266468689005861

Epoch: 5| Step: 2
Training loss: 0.6584947109222412
Validation loss: 1.8505837609691005

Epoch: 5| Step: 3
Training loss: 0.5793073773384094
Validation loss: 1.8805265759909024

Epoch: 5| Step: 4
Training loss: 1.1447410583496094
Validation loss: 1.9311051458440802

Epoch: 5| Step: 5
Training loss: 1.195956826210022
Validation loss: 1.9825553996588594

Epoch: 5| Step: 6
Training loss: 1.1877399682998657
Validation loss: 2.020808776219686

Epoch: 5| Step: 7
Training loss: 1.2186849117279053
Validation loss: 2.0126315034845823

Epoch: 5| Step: 8
Training loss: 1.6424862146377563
Validation loss: 1.992069467421501

Epoch: 5| Step: 9
Training loss: 1.4584002494812012
Validation loss: 1.9399866827072636

Epoch: 5| Step: 10
Training loss: 1.239976167678833
Validation loss: 1.8869811540008874

Epoch: 291| Step: 0
Training loss: 1.7314001321792603
Validation loss: 1.827036649950089

Epoch: 5| Step: 1
Training loss: 1.6831505298614502
Validation loss: 1.8134762574267644

Epoch: 5| Step: 2
Training loss: 0.7998118996620178
Validation loss: 1.796656689336223

Epoch: 5| Step: 3
Training loss: 0.7811726331710815
Validation loss: 1.7797615989562003

Epoch: 5| Step: 4
Training loss: 1.471360445022583
Validation loss: 1.7879065377737886

Epoch: 5| Step: 5
Training loss: 1.4780404567718506
Validation loss: 1.8188349700743152

Epoch: 5| Step: 6
Training loss: 0.8422331809997559
Validation loss: 1.8613753370059434

Epoch: 5| Step: 7
Training loss: 0.833112895488739
Validation loss: 1.8832512542765627

Epoch: 5| Step: 8
Training loss: 0.7263969779014587
Validation loss: 1.8927360657722718

Epoch: 5| Step: 9
Training loss: 1.0598530769348145
Validation loss: 1.8888927903226627

Epoch: 5| Step: 10
Training loss: 1.2792677879333496
Validation loss: 1.8654527894912227

Epoch: 292| Step: 0
Training loss: 1.1147701740264893
Validation loss: 1.861037262024418

Epoch: 5| Step: 1
Training loss: 1.0587520599365234
Validation loss: 1.8668006799554313

Epoch: 5| Step: 2
Training loss: 1.2278916835784912
Validation loss: 1.8548830068239601

Epoch: 5| Step: 3
Training loss: 1.3792927265167236
Validation loss: 1.865500997471553

Epoch: 5| Step: 4
Training loss: 1.4119117259979248
Validation loss: 1.8690129774872974

Epoch: 5| Step: 5
Training loss: 1.1898940801620483
Validation loss: 1.8871406227029779

Epoch: 5| Step: 6
Training loss: 0.672150731086731
Validation loss: 1.8886698958694295

Epoch: 5| Step: 7
Training loss: 0.5790698528289795
Validation loss: 1.9159590018692838

Epoch: 5| Step: 8
Training loss: 1.198487639427185
Validation loss: 1.906495487818154

Epoch: 5| Step: 9
Training loss: 1.1972596645355225
Validation loss: 1.8838839620672247

Epoch: 5| Step: 10
Training loss: 1.0839067697525024
Validation loss: 1.866139865690662

Epoch: 293| Step: 0
Training loss: 0.9303253293037415
Validation loss: 1.8525354836576728

Epoch: 5| Step: 1
Training loss: 1.007771372795105
Validation loss: 1.8397297807919082

Epoch: 5| Step: 2
Training loss: 1.1205090284347534
Validation loss: 1.8389334371013026

Epoch: 5| Step: 3
Training loss: 1.0759936571121216
Validation loss: 1.8277685872970089

Epoch: 5| Step: 4
Training loss: 1.1754300594329834
Validation loss: 1.8188019862738989

Epoch: 5| Step: 5
Training loss: 1.0739171504974365
Validation loss: 1.8265973432089693

Epoch: 5| Step: 6
Training loss: 1.0836398601531982
Validation loss: 1.84687388584178

Epoch: 5| Step: 7
Training loss: 1.301217794418335
Validation loss: 1.8618807972118419

Epoch: 5| Step: 8
Training loss: 0.8964815139770508
Validation loss: 1.872330964252513

Epoch: 5| Step: 9
Training loss: 1.2696211338043213
Validation loss: 1.876059760329544

Epoch: 5| Step: 10
Training loss: 0.9701773524284363
Validation loss: 1.8892012244911605

Epoch: 294| Step: 0
Training loss: 1.2436277866363525
Validation loss: 1.8975071419951737

Epoch: 5| Step: 1
Training loss: 1.3881362676620483
Validation loss: 1.886072886887417

Epoch: 5| Step: 2
Training loss: 0.6543200612068176
Validation loss: 1.8891366553562943

Epoch: 5| Step: 3
Training loss: 0.8597885370254517
Validation loss: 1.8994774920966035

Epoch: 5| Step: 4
Training loss: 1.146036148071289
Validation loss: 1.9001186727195658

Epoch: 5| Step: 5
Training loss: 1.0973925590515137
Validation loss: 1.8880173954912411

Epoch: 5| Step: 6
Training loss: 0.9799382090568542
Validation loss: 1.8814534717990505

Epoch: 5| Step: 7
Training loss: 0.6485618352890015
Validation loss: 1.8819108996340024

Epoch: 5| Step: 8
Training loss: 1.165306806564331
Validation loss: 1.8692295410299813

Epoch: 5| Step: 9
Training loss: 1.0791022777557373
Validation loss: 1.868706230194338

Epoch: 5| Step: 10
Training loss: 1.43808913230896
Validation loss: 1.8644819862099105

Epoch: 295| Step: 0
Training loss: 0.8554374575614929
Validation loss: 1.8413283889011671

Epoch: 5| Step: 1
Training loss: 1.572539210319519
Validation loss: 1.850274129580426

Epoch: 5| Step: 2
Training loss: 0.5624715685844421
Validation loss: 1.8617951126508816

Epoch: 5| Step: 3
Training loss: 1.249721646308899
Validation loss: 1.8470011295810822

Epoch: 5| Step: 4
Training loss: 1.0603389739990234
Validation loss: 1.851203437774412

Epoch: 5| Step: 5
Training loss: 1.0023642778396606
Validation loss: 1.8501057599180488

Epoch: 5| Step: 6
Training loss: 1.3830931186676025
Validation loss: 1.8676306291293072

Epoch: 5| Step: 7
Training loss: 0.7316427230834961
Validation loss: 1.82473297016595

Epoch: 5| Step: 8
Training loss: 0.9431637525558472
Validation loss: 1.8177277221474597

Epoch: 5| Step: 9
Training loss: 1.0882513523101807
Validation loss: 1.8019283022931827

Epoch: 5| Step: 10
Training loss: 1.2655596733093262
Validation loss: 1.7777856011544504

Epoch: 296| Step: 0
Training loss: 0.8862705230712891
Validation loss: 1.7800945415291736

Epoch: 5| Step: 1
Training loss: 1.1178075075149536
Validation loss: 1.7959804381093671

Epoch: 5| Step: 2
Training loss: 0.7892228364944458
Validation loss: 1.8146616694747761

Epoch: 5| Step: 3
Training loss: 1.2130216360092163
Validation loss: 1.8344040096447032

Epoch: 5| Step: 4
Training loss: 1.2653074264526367
Validation loss: 1.8353354853968467

Epoch: 5| Step: 5
Training loss: 1.1492499113082886
Validation loss: 1.853053262156825

Epoch: 5| Step: 6
Training loss: 0.6618009805679321
Validation loss: 1.8459463888599026

Epoch: 5| Step: 7
Training loss: 1.3681998252868652
Validation loss: 1.8293438765310472

Epoch: 5| Step: 8
Training loss: 1.270689606666565
Validation loss: 1.851817504052193

Epoch: 5| Step: 9
Training loss: 0.9017387628555298
Validation loss: 1.8622044414602301

Epoch: 5| Step: 10
Training loss: 1.0525983572006226
Validation loss: 1.8829408307229318

Epoch: 297| Step: 0
Training loss: 0.9467870593070984
Validation loss: 1.8982213799671461

Epoch: 5| Step: 1
Training loss: 0.7716888785362244
Validation loss: 1.8834117920167985

Epoch: 5| Step: 2
Training loss: 0.9725736379623413
Validation loss: 1.8968855591230496

Epoch: 5| Step: 3
Training loss: 0.9398280382156372
Validation loss: 1.8829316234075895

Epoch: 5| Step: 4
Training loss: 1.099984884262085
Validation loss: 1.8762403662486742

Epoch: 5| Step: 5
Training loss: 1.3153517246246338
Validation loss: 1.865430175617177

Epoch: 5| Step: 6
Training loss: 1.400996208190918
Validation loss: 1.8309814827416533

Epoch: 5| Step: 7
Training loss: 0.5739407539367676
Validation loss: 1.805430035437307

Epoch: 5| Step: 8
Training loss: 0.9107605218887329
Validation loss: 1.8166879812876384

Epoch: 5| Step: 9
Training loss: 1.5906426906585693
Validation loss: 1.8065921542465047

Epoch: 5| Step: 10
Training loss: 0.7718115448951721
Validation loss: 1.85671135815241

Epoch: 298| Step: 0
Training loss: 1.278540849685669
Validation loss: 1.8712931781686761

Epoch: 5| Step: 1
Training loss: 1.3164538145065308
Validation loss: 1.8536535514298307

Epoch: 5| Step: 2
Training loss: 0.5585380792617798
Validation loss: 1.8096569571443784

Epoch: 5| Step: 3
Training loss: 0.8143364191055298
Validation loss: 1.78174380845921

Epoch: 5| Step: 4
Training loss: 1.0786383152008057
Validation loss: 1.8119314306525773

Epoch: 5| Step: 5
Training loss: 0.6946833729743958
Validation loss: 1.7950278738493561

Epoch: 5| Step: 6
Training loss: 1.2799142599105835
Validation loss: 1.8314929534030218

Epoch: 5| Step: 7
Training loss: 1.1647396087646484
Validation loss: 1.866055324513425

Epoch: 5| Step: 8
Training loss: 0.7703428268432617
Validation loss: 1.9240560198342929

Epoch: 5| Step: 9
Training loss: 1.4223709106445312
Validation loss: 1.9636586814798334

Epoch: 5| Step: 10
Training loss: 1.2022619247436523
Validation loss: 1.946179452762809

Epoch: 299| Step: 0
Training loss: 1.0314639806747437
Validation loss: 1.9015974537018807

Epoch: 5| Step: 1
Training loss: 1.618222951889038
Validation loss: 1.842060076293125

Epoch: 5| Step: 2
Training loss: 0.8910320997238159
Validation loss: 1.818030370179043

Epoch: 5| Step: 3
Training loss: 1.2156285047531128
Validation loss: 1.8153125855230516

Epoch: 5| Step: 4
Training loss: 1.1780345439910889
Validation loss: 1.8337473971869356

Epoch: 5| Step: 5
Training loss: 0.8748466372489929
Validation loss: 1.8102162627763645

Epoch: 5| Step: 6
Training loss: 0.6087237596511841
Validation loss: 1.8131071572662683

Epoch: 5| Step: 7
Training loss: 1.071463942527771
Validation loss: 1.848800156706123

Epoch: 5| Step: 8
Training loss: 1.0454353094100952
Validation loss: 1.919372340684296

Epoch: 5| Step: 9
Training loss: 0.9738079905509949
Validation loss: 1.9262653512339438

Epoch: 5| Step: 10
Training loss: 1.2447621822357178
Validation loss: 1.8691545853050806

Epoch: 300| Step: 0
Training loss: 0.7951545715332031
Validation loss: 1.8056647982648624

Epoch: 5| Step: 1
Training loss: 1.1307058334350586
Validation loss: 1.7696923389229724

Epoch: 5| Step: 2
Training loss: 0.8966789245605469
Validation loss: 1.7803182576292305

Epoch: 5| Step: 3
Training loss: 1.0485074520111084
Validation loss: 1.8179174264272053

Epoch: 5| Step: 4
Training loss: 1.5397804975509644
Validation loss: 1.8892915415507492

Epoch: 5| Step: 5
Training loss: 1.000048279762268
Validation loss: 1.9204078823007562

Epoch: 5| Step: 6
Training loss: 0.9185258150100708
Validation loss: 1.9035846943496375

Epoch: 5| Step: 7
Training loss: 1.106199860572815
Validation loss: 1.885083568993435

Epoch: 5| Step: 8
Training loss: 0.9859522581100464
Validation loss: 1.8622859370323919

Epoch: 5| Step: 9
Training loss: 0.8510209918022156
Validation loss: 1.865464941147835

Epoch: 5| Step: 10
Training loss: 1.4268728494644165
Validation loss: 1.8434824584632792

Epoch: 301| Step: 0
Training loss: 1.117086410522461
Validation loss: 1.8597496126287727

Epoch: 5| Step: 1
Training loss: 0.6138797998428345
Validation loss: 1.874307463246007

Epoch: 5| Step: 2
Training loss: 0.9464360475540161
Validation loss: 1.875284961474839

Epoch: 5| Step: 3
Training loss: 0.8113535642623901
Validation loss: 1.8863624090789466

Epoch: 5| Step: 4
Training loss: 1.2350199222564697
Validation loss: 1.8425432135981898

Epoch: 5| Step: 5
Training loss: 1.1529479026794434
Validation loss: 1.822127164051097

Epoch: 5| Step: 6
Training loss: 0.996243953704834
Validation loss: 1.7814124373979465

Epoch: 5| Step: 7
Training loss: 1.0718014240264893
Validation loss: 1.7899299680545766

Epoch: 5| Step: 8
Training loss: 1.5193403959274292
Validation loss: 1.801967692631547

Epoch: 5| Step: 9
Training loss: 0.7186692357063293
Validation loss: 1.795173878310829

Epoch: 5| Step: 10
Training loss: 1.1045432090759277
Validation loss: 1.8218981091694166

Epoch: 302| Step: 0
Training loss: 0.7316821217536926
Validation loss: 1.8299171232408094

Epoch: 5| Step: 1
Training loss: 1.5774732828140259
Validation loss: 1.8549609914902718

Epoch: 5| Step: 2
Training loss: 1.136754035949707
Validation loss: 1.8589338705103884

Epoch: 5| Step: 3
Training loss: 0.9869719743728638
Validation loss: 1.8410419123147124

Epoch: 5| Step: 4
Training loss: 0.6221179366111755
Validation loss: 1.8623395466035413

Epoch: 5| Step: 5
Training loss: 1.414902687072754
Validation loss: 1.8808026262508926

Epoch: 5| Step: 6
Training loss: 0.8436065912246704
Validation loss: 1.8775627241339734

Epoch: 5| Step: 7
Training loss: 1.2524402141571045
Validation loss: 1.8713135437298847

Epoch: 5| Step: 8
Training loss: 0.7938147783279419
Validation loss: 1.8580526433965212

Epoch: 5| Step: 9
Training loss: 0.9513934254646301
Validation loss: 1.869933824385366

Epoch: 5| Step: 10
Training loss: 0.6695046424865723
Validation loss: 1.8566514189525316

Epoch: 303| Step: 0
Training loss: 1.1099735498428345
Validation loss: 1.8373040512043943

Epoch: 5| Step: 1
Training loss: 1.1050727367401123
Validation loss: 1.818326198926536

Epoch: 5| Step: 2
Training loss: 1.0082263946533203
Validation loss: 1.8168108296650711

Epoch: 5| Step: 3
Training loss: 0.9012935757637024
Validation loss: 1.802825076605684

Epoch: 5| Step: 4
Training loss: 0.8245220184326172
Validation loss: 1.7956433898659163

Epoch: 5| Step: 5
Training loss: 0.9153329730033875
Validation loss: 1.7972724360804404

Epoch: 5| Step: 6
Training loss: 0.6287596821784973
Validation loss: 1.815224350139659

Epoch: 5| Step: 7
Training loss: 1.1700550317764282
Validation loss: 1.8371162850369689

Epoch: 5| Step: 8
Training loss: 1.040130615234375
Validation loss: 1.8886251385493944

Epoch: 5| Step: 9
Training loss: 1.2462241649627686
Validation loss: 1.9156259208597162

Epoch: 5| Step: 10
Training loss: 0.6108291745185852
Validation loss: 1.8988042339201896

Epoch: 304| Step: 0
Training loss: 0.603121280670166
Validation loss: 1.916563872368105

Epoch: 5| Step: 1
Training loss: 1.3528105020523071
Validation loss: 1.9079493579044138

Epoch: 5| Step: 2
Training loss: 1.1030869483947754
Validation loss: 1.877070391049949

Epoch: 5| Step: 3
Training loss: 1.0107834339141846
Validation loss: 1.8547440857015631

Epoch: 5| Step: 4
Training loss: 0.7680734395980835
Validation loss: 1.8015856460858417

Epoch: 5| Step: 5
Training loss: 0.966183066368103
Validation loss: 1.7973135427762104

Epoch: 5| Step: 6
Training loss: 1.0270700454711914
Validation loss: 1.7841016092608053

Epoch: 5| Step: 7
Training loss: 1.1892940998077393
Validation loss: 1.7971755176462152

Epoch: 5| Step: 8
Training loss: 0.6075440645217896
Validation loss: 1.8093217649767477

Epoch: 5| Step: 9
Training loss: 1.1142313480377197
Validation loss: 1.8553218405733827

Epoch: 5| Step: 10
Training loss: 1.074675440788269
Validation loss: 1.8471778515846498

Epoch: 305| Step: 0
Training loss: 1.1322860717773438
Validation loss: 1.8636107983127717

Epoch: 5| Step: 1
Training loss: 0.5686548948287964
Validation loss: 1.839053464192216

Epoch: 5| Step: 2
Training loss: 0.8646844029426575
Validation loss: 1.8137508310297483

Epoch: 5| Step: 3
Training loss: 1.0574299097061157
Validation loss: 1.819282498410953

Epoch: 5| Step: 4
Training loss: 0.6631394624710083
Validation loss: 1.8229420095361688

Epoch: 5| Step: 5
Training loss: 1.0041383504867554
Validation loss: 1.8319731450849963

Epoch: 5| Step: 6
Training loss: 1.1727979183197021
Validation loss: 1.8511263529459636

Epoch: 5| Step: 7
Training loss: 1.2906181812286377
Validation loss: 1.8501709840630973

Epoch: 5| Step: 8
Training loss: 0.9172428250312805
Validation loss: 1.8560748343826623

Epoch: 5| Step: 9
Training loss: 0.9529433250427246
Validation loss: 1.8448509420118024

Epoch: 5| Step: 10
Training loss: 0.8686531782150269
Validation loss: 1.8198756479447888

Epoch: 306| Step: 0
Training loss: 1.0260298252105713
Validation loss: 1.7835340397332304

Epoch: 5| Step: 1
Training loss: 1.1390835046768188
Validation loss: 1.7588720821565198

Epoch: 5| Step: 2
Training loss: 1.018775224685669
Validation loss: 1.759678299709033

Epoch: 5| Step: 3
Training loss: 1.0548244714736938
Validation loss: 1.7575793650842482

Epoch: 5| Step: 4
Training loss: 1.0362460613250732
Validation loss: 1.7761065139565417

Epoch: 5| Step: 5
Training loss: 1.1023980379104614
Validation loss: 1.816523463495316

Epoch: 5| Step: 6
Training loss: 0.6933682560920715
Validation loss: 1.8526335557301838

Epoch: 5| Step: 7
Training loss: 0.8629621267318726
Validation loss: 1.898049964699694

Epoch: 5| Step: 8
Training loss: 1.1278141736984253
Validation loss: 1.8901982025433612

Epoch: 5| Step: 9
Training loss: 1.1582592725753784
Validation loss: 1.8718477474745883

Epoch: 5| Step: 10
Training loss: 0.5840274691581726
Validation loss: 1.860539331231066

Epoch: 307| Step: 0
Training loss: 0.8684471249580383
Validation loss: 1.826105248543524

Epoch: 5| Step: 1
Training loss: 1.198117733001709
Validation loss: 1.8145191900191768

Epoch: 5| Step: 2
Training loss: 1.1271612644195557
Validation loss: 1.8055392260192542

Epoch: 5| Step: 3
Training loss: 1.1253362894058228
Validation loss: 1.8067734177394579

Epoch: 5| Step: 4
Training loss: 0.7570578455924988
Validation loss: 1.819269000843007

Epoch: 5| Step: 5
Training loss: 0.9704230427742004
Validation loss: 1.8782444987245785

Epoch: 5| Step: 6
Training loss: 0.9986017346382141
Validation loss: 1.9330665937034033

Epoch: 5| Step: 7
Training loss: 1.000763177871704
Validation loss: 1.9485261414640693

Epoch: 5| Step: 8
Training loss: 0.9668356776237488
Validation loss: 1.8740752397045013

Epoch: 5| Step: 9
Training loss: 0.94316166639328
Validation loss: 1.8057664555888022

Epoch: 5| Step: 10
Training loss: 1.121985912322998
Validation loss: 1.7780375326833417

Epoch: 308| Step: 0
Training loss: 1.1146214008331299
Validation loss: 1.7635898718269922

Epoch: 5| Step: 1
Training loss: 1.16226065158844
Validation loss: 1.759020754086074

Epoch: 5| Step: 2
Training loss: 1.0442562103271484
Validation loss: 1.7847277310586744

Epoch: 5| Step: 3
Training loss: 1.0293443202972412
Validation loss: 1.8324453958901026

Epoch: 5| Step: 4
Training loss: 1.0630754232406616
Validation loss: 1.86169578823992

Epoch: 5| Step: 5
Training loss: 0.688069224357605
Validation loss: 1.8954791407431326

Epoch: 5| Step: 6
Training loss: 1.0040881633758545
Validation loss: 1.901042438322498

Epoch: 5| Step: 7
Training loss: 0.8840556144714355
Validation loss: 1.8730172521324568

Epoch: 5| Step: 8
Training loss: 0.9489651918411255
Validation loss: 1.8369199486188992

Epoch: 5| Step: 9
Training loss: 0.6068750023841858
Validation loss: 1.7954476353942708

Epoch: 5| Step: 10
Training loss: 1.3436899185180664
Validation loss: 1.7654502455906202

Epoch: 309| Step: 0
Training loss: 1.011829137802124
Validation loss: 1.768038393348776

Epoch: 5| Step: 1
Training loss: 1.2909553050994873
Validation loss: 1.778871343981835

Epoch: 5| Step: 2
Training loss: 0.7899966835975647
Validation loss: 1.800869059819047

Epoch: 5| Step: 3
Training loss: 0.8067221641540527
Validation loss: 1.8463558932786346

Epoch: 5| Step: 4
Training loss: 0.6530293226242065
Validation loss: 1.8731261453320902

Epoch: 5| Step: 5
Training loss: 1.1754705905914307
Validation loss: 1.9022193993291547

Epoch: 5| Step: 6
Training loss: 0.9443553686141968
Validation loss: 1.859920536318133

Epoch: 5| Step: 7
Training loss: 1.0211745500564575
Validation loss: 1.8712763094132947

Epoch: 5| Step: 8
Training loss: 0.9987083673477173
Validation loss: 1.8394277595704602

Epoch: 5| Step: 9
Training loss: 1.245812177658081
Validation loss: 1.8173713901991486

Epoch: 5| Step: 10
Training loss: 0.6895195245742798
Validation loss: 1.8478205652647122

Epoch: 310| Step: 0
Training loss: 1.1766685247421265
Validation loss: 1.8326540531650666

Epoch: 5| Step: 1
Training loss: 1.1256616115570068
Validation loss: 1.8298981933183567

Epoch: 5| Step: 2
Training loss: 0.5641353130340576
Validation loss: 1.8088923333793558

Epoch: 5| Step: 3
Training loss: 1.0020437240600586
Validation loss: 1.8387281510137743

Epoch: 5| Step: 4
Training loss: 1.0246061086654663
Validation loss: 1.8288142219666512

Epoch: 5| Step: 5
Training loss: 1.2204780578613281
Validation loss: 1.8193659000499274

Epoch: 5| Step: 6
Training loss: 0.9028381109237671
Validation loss: 1.8196831082785

Epoch: 5| Step: 7
Training loss: 0.9713464975357056
Validation loss: 1.7955663998921711

Epoch: 5| Step: 8
Training loss: 1.331070899963379
Validation loss: 1.8050639026908464

Epoch: 5| Step: 9
Training loss: 0.5141867995262146
Validation loss: 1.80386536095732

Epoch: 5| Step: 10
Training loss: 0.6980441808700562
Validation loss: 1.814822558433779

Epoch: 311| Step: 0
Training loss: 0.46668586134910583
Validation loss: 1.8304383626548193

Epoch: 5| Step: 1
Training loss: 0.5159565210342407
Validation loss: 1.8536635188646213

Epoch: 5| Step: 2
Training loss: 1.1429548263549805
Validation loss: 1.8660713062491467

Epoch: 5| Step: 3
Training loss: 1.5171749591827393
Validation loss: 1.8984934770932762

Epoch: 5| Step: 4
Training loss: 0.7961360812187195
Validation loss: 1.9069052716737152

Epoch: 5| Step: 5
Training loss: 1.1792824268341064
Validation loss: 1.8935444175556142

Epoch: 5| Step: 6
Training loss: 0.7040833234786987
Validation loss: 1.8462636445158271

Epoch: 5| Step: 7
Training loss: 1.0741691589355469
Validation loss: 1.8009352786566621

Epoch: 5| Step: 8
Training loss: 1.0009100437164307
Validation loss: 1.792255384947664

Epoch: 5| Step: 9
Training loss: 0.6690561175346375
Validation loss: 1.7568510258069603

Epoch: 5| Step: 10
Training loss: 1.0312438011169434
Validation loss: 1.7763090877122776

Epoch: 312| Step: 0
Training loss: 0.7892429232597351
Validation loss: 1.7776149011427356

Epoch: 5| Step: 1
Training loss: 0.7359527945518494
Validation loss: 1.806345844781527

Epoch: 5| Step: 2
Training loss: 1.0871647596359253
Validation loss: 1.8174822522747902

Epoch: 5| Step: 3
Training loss: 0.7134144306182861
Validation loss: 1.823286505155666

Epoch: 5| Step: 4
Training loss: 0.7560076713562012
Validation loss: 1.81441919906165

Epoch: 5| Step: 5
Training loss: 1.0411146879196167
Validation loss: 1.8282026014020365

Epoch: 5| Step: 6
Training loss: 0.6066304445266724
Validation loss: 1.8387574252261911

Epoch: 5| Step: 7
Training loss: 0.5823432803153992
Validation loss: 1.839768144392198

Epoch: 5| Step: 8
Training loss: 0.7739212512969971
Validation loss: 1.856782668380327

Epoch: 5| Step: 9
Training loss: 1.828249216079712
Validation loss: 1.8430668384798112

Epoch: 5| Step: 10
Training loss: 1.161633014678955
Validation loss: 1.8273485770789526

Epoch: 313| Step: 0
Training loss: 1.0098161697387695
Validation loss: 1.8009034869491414

Epoch: 5| Step: 1
Training loss: 1.061768889427185
Validation loss: 1.7874648929924093

Epoch: 5| Step: 2
Training loss: 0.7692351341247559
Validation loss: 1.7685227753013693

Epoch: 5| Step: 3
Training loss: 1.1504865884780884
Validation loss: 1.7768320242563884

Epoch: 5| Step: 4
Training loss: 1.0944209098815918
Validation loss: 1.787193803377049

Epoch: 5| Step: 5
Training loss: 1.1727135181427002
Validation loss: 1.8033984297065324

Epoch: 5| Step: 6
Training loss: 0.798784613609314
Validation loss: 1.8391752845497542

Epoch: 5| Step: 7
Training loss: 0.6246058940887451
Validation loss: 1.8671222079184748

Epoch: 5| Step: 8
Training loss: 0.5735235214233398
Validation loss: 1.8752086418931202

Epoch: 5| Step: 9
Training loss: 0.8929182887077332
Validation loss: 1.818962889332925

Epoch: 5| Step: 10
Training loss: 0.6228809356689453
Validation loss: 1.7899320202489053

Epoch: 314| Step: 0
Training loss: 1.2867963314056396
Validation loss: 1.7735584500015422

Epoch: 5| Step: 1
Training loss: 1.0975228548049927
Validation loss: 1.773998786044377

Epoch: 5| Step: 2
Training loss: 0.7109799981117249
Validation loss: 1.778386221137098

Epoch: 5| Step: 3
Training loss: 0.724970817565918
Validation loss: 1.7785186139486169

Epoch: 5| Step: 4
Training loss: 0.9849036335945129
Validation loss: 1.799712727146764

Epoch: 5| Step: 5
Training loss: 0.7323850393295288
Validation loss: 1.8250955714974353

Epoch: 5| Step: 6
Training loss: 0.8777108192443848
Validation loss: 1.8343847272216633

Epoch: 5| Step: 7
Training loss: 0.8388320207595825
Validation loss: 1.8674838030210106

Epoch: 5| Step: 8
Training loss: 1.0275341272354126
Validation loss: 1.9217697779337566

Epoch: 5| Step: 9
Training loss: 0.8524316549301147
Validation loss: 1.9102203974159815

Epoch: 5| Step: 10
Training loss: 0.6911116242408752
Validation loss: 1.9186201210944884

Epoch: 315| Step: 0
Training loss: 0.7472301721572876
Validation loss: 1.9101489218332435

Epoch: 5| Step: 1
Training loss: 0.7377107739448547
Validation loss: 1.913846303057927

Epoch: 5| Step: 2
Training loss: 1.177074909210205
Validation loss: 1.8986904723669893

Epoch: 5| Step: 3
Training loss: 0.8268088102340698
Validation loss: 1.8445849918550061

Epoch: 5| Step: 4
Training loss: 0.6494749188423157
Validation loss: 1.7963713304970854

Epoch: 5| Step: 5
Training loss: 0.9092434048652649
Validation loss: 1.7521961978686753

Epoch: 5| Step: 6
Training loss: 1.1880441904067993
Validation loss: 1.758650443887198

Epoch: 5| Step: 7
Training loss: 1.0270326137542725
Validation loss: 1.766597399147608

Epoch: 5| Step: 8
Training loss: 1.0453031063079834
Validation loss: 1.7939670111543389

Epoch: 5| Step: 9
Training loss: 0.691656231880188
Validation loss: 1.8446592041241225

Epoch: 5| Step: 10
Training loss: 1.1495726108551025
Validation loss: 1.873892670036644

Epoch: 316| Step: 0
Training loss: 0.9004391431808472
Validation loss: 1.8597675267086233

Epoch: 5| Step: 1
Training loss: 0.9709392786026001
Validation loss: 1.816343270322328

Epoch: 5| Step: 2
Training loss: 0.6721820831298828
Validation loss: 1.801928820148591

Epoch: 5| Step: 3
Training loss: 0.6952239274978638
Validation loss: 1.8023903985177316

Epoch: 5| Step: 4
Training loss: 1.5104972124099731
Validation loss: 1.8228711902454335

Epoch: 5| Step: 5
Training loss: 0.7661691308021545
Validation loss: 1.8145743147019417

Epoch: 5| Step: 6
Training loss: 0.828464150428772
Validation loss: 1.8302287081236481

Epoch: 5| Step: 7
Training loss: 0.8090887069702148
Validation loss: 1.8276656853255404

Epoch: 5| Step: 8
Training loss: 0.7472735643386841
Validation loss: 1.8228442643278389

Epoch: 5| Step: 9
Training loss: 1.1358745098114014
Validation loss: 1.8120417171908962

Epoch: 5| Step: 10
Training loss: 0.6365723013877869
Validation loss: 1.814575941331925

Epoch: 317| Step: 0
Training loss: 0.8426402807235718
Validation loss: 1.7977309585899435

Epoch: 5| Step: 1
Training loss: 1.4815465211868286
Validation loss: 1.7971977136468376

Epoch: 5| Step: 2
Training loss: 0.5500263571739197
Validation loss: 1.8021510993280718

Epoch: 5| Step: 3
Training loss: 1.305992841720581
Validation loss: 1.760089506385147

Epoch: 5| Step: 4
Training loss: 0.4274594187736511
Validation loss: 1.7910039065986552

Epoch: 5| Step: 5
Training loss: 0.8772727847099304
Validation loss: 1.7896732437995173

Epoch: 5| Step: 6
Training loss: 1.149867296218872
Validation loss: 1.7892855521171325

Epoch: 5| Step: 7
Training loss: 1.0681262016296387
Validation loss: 1.7700874715723016

Epoch: 5| Step: 8
Training loss: 0.8430536985397339
Validation loss: 1.820560041294303

Epoch: 5| Step: 9
Training loss: 0.6374305486679077
Validation loss: 1.8432096024995208

Epoch: 5| Step: 10
Training loss: 0.3858135938644409
Validation loss: 1.8852849134834864

Epoch: 318| Step: 0
Training loss: 0.5350984334945679
Validation loss: 1.857052218529486

Epoch: 5| Step: 1
Training loss: 0.5380730628967285
Validation loss: 1.879012382158669

Epoch: 5| Step: 2
Training loss: 0.5608289837837219
Validation loss: 1.8515754489488498

Epoch: 5| Step: 3
Training loss: 1.0412800312042236
Validation loss: 1.850563556917252

Epoch: 5| Step: 4
Training loss: 1.5020661354064941
Validation loss: 1.8515308903109642

Epoch: 5| Step: 5
Training loss: 1.1108561754226685
Validation loss: 1.8200457634464386

Epoch: 5| Step: 6
Training loss: 1.0061845779418945
Validation loss: 1.8009885177817395

Epoch: 5| Step: 7
Training loss: 0.829906165599823
Validation loss: 1.7960784614727061

Epoch: 5| Step: 8
Training loss: 0.7782648801803589
Validation loss: 1.7972084001828266

Epoch: 5| Step: 9
Training loss: 0.6931651830673218
Validation loss: 1.7813089406618507

Epoch: 5| Step: 10
Training loss: 0.7551387548446655
Validation loss: 1.7950987392856228

Epoch: 319| Step: 0
Training loss: 0.8611810803413391
Validation loss: 1.7978731034904398

Epoch: 5| Step: 1
Training loss: 0.5283164978027344
Validation loss: 1.7992411710882699

Epoch: 5| Step: 2
Training loss: 0.9139481782913208
Validation loss: 1.7967159748077393

Epoch: 5| Step: 3
Training loss: 0.7454492449760437
Validation loss: 1.8007079901233796

Epoch: 5| Step: 4
Training loss: 0.7183948755264282
Validation loss: 1.7914154952572239

Epoch: 5| Step: 5
Training loss: 0.6635026335716248
Validation loss: 1.773549840014468

Epoch: 5| Step: 6
Training loss: 0.7627456784248352
Validation loss: 1.779073046099755

Epoch: 5| Step: 7
Training loss: 0.7693212032318115
Validation loss: 1.77863960753205

Epoch: 5| Step: 8
Training loss: 1.052971601486206
Validation loss: 1.7830358397576116

Epoch: 5| Step: 9
Training loss: 1.304530143737793
Validation loss: 1.8055659763274654

Epoch: 5| Step: 10
Training loss: 0.9590218663215637
Validation loss: 1.8204736299412225

Epoch: 320| Step: 0
Training loss: 0.8614511489868164
Validation loss: 1.7881850555378904

Epoch: 5| Step: 1
Training loss: 0.8109917640686035
Validation loss: 1.7924216793429466

Epoch: 5| Step: 2
Training loss: 0.7241870760917664
Validation loss: 1.8195191493598364

Epoch: 5| Step: 3
Training loss: 1.2263977527618408
Validation loss: 1.8217417732361825

Epoch: 5| Step: 4
Training loss: 0.6310479640960693
Validation loss: 1.8322115405913322

Epoch: 5| Step: 5
Training loss: 0.951210618019104
Validation loss: 1.8452873691435783

Epoch: 5| Step: 6
Training loss: 0.6789053082466125
Validation loss: 1.845096190770467

Epoch: 5| Step: 7
Training loss: 1.2054522037506104
Validation loss: 1.8367773871267996

Epoch: 5| Step: 8
Training loss: 0.5792657732963562
Validation loss: 1.8037953440861036

Epoch: 5| Step: 9
Training loss: 0.8366590738296509
Validation loss: 1.7665665611144035

Epoch: 5| Step: 10
Training loss: 0.6502504944801331
Validation loss: 1.7634976653642551

Epoch: 321| Step: 0
Training loss: 0.9338896870613098
Validation loss: 1.7490783032550608

Epoch: 5| Step: 1
Training loss: 0.8489705324172974
Validation loss: 1.7306867799451273

Epoch: 5| Step: 2
Training loss: 0.6545732617378235
Validation loss: 1.7526155928129792

Epoch: 5| Step: 3
Training loss: 1.2229423522949219
Validation loss: 1.7946165979549449

Epoch: 5| Step: 4
Training loss: 0.41811805963516235
Validation loss: 1.8360307370462725

Epoch: 5| Step: 5
Training loss: 1.10481595993042
Validation loss: 1.8492806265431065

Epoch: 5| Step: 6
Training loss: 0.9385117292404175
Validation loss: 1.831843779933068

Epoch: 5| Step: 7
Training loss: 0.9179449081420898
Validation loss: 1.8302403598703363

Epoch: 5| Step: 8
Training loss: 0.6787654757499695
Validation loss: 1.7976600123989968

Epoch: 5| Step: 9
Training loss: 0.8271234631538391
Validation loss: 1.7945212151414605

Epoch: 5| Step: 10
Training loss: 0.8340435028076172
Validation loss: 1.776779515768892

Epoch: 322| Step: 0
Training loss: 0.8920841217041016
Validation loss: 1.768533117027693

Epoch: 5| Step: 1
Training loss: 1.1969406604766846
Validation loss: 1.7828931975108322

Epoch: 5| Step: 2
Training loss: 0.8080422282218933
Validation loss: 1.786886179318992

Epoch: 5| Step: 3
Training loss: 0.675787091255188
Validation loss: 1.7540636190804102

Epoch: 5| Step: 4
Training loss: 0.8405746221542358
Validation loss: 1.7906541029612224

Epoch: 5| Step: 5
Training loss: 0.915823757648468
Validation loss: 1.7998740519246748

Epoch: 5| Step: 6
Training loss: 0.7695701718330383
Validation loss: 1.8139969482216785

Epoch: 5| Step: 7
Training loss: 0.5927238464355469
Validation loss: 1.7939846387473486

Epoch: 5| Step: 8
Training loss: 0.840657114982605
Validation loss: 1.8337602525629022

Epoch: 5| Step: 9
Training loss: 0.6288333535194397
Validation loss: 1.8261702265790714

Epoch: 5| Step: 10
Training loss: 0.9324609041213989
Validation loss: 1.7775423578036729

Epoch: 323| Step: 0
Training loss: 0.625707745552063
Validation loss: 1.7908310890197754

Epoch: 5| Step: 1
Training loss: 0.8653127551078796
Validation loss: 1.7943482809169318

Epoch: 5| Step: 2
Training loss: 0.9453493356704712
Validation loss: 1.8006476535592029

Epoch: 5| Step: 3
Training loss: 0.46139436960220337
Validation loss: 1.8243893384933472

Epoch: 5| Step: 4
Training loss: 0.6820233464241028
Validation loss: 1.8354510671348983

Epoch: 5| Step: 5
Training loss: 1.0439592599868774
Validation loss: 1.821377787538754

Epoch: 5| Step: 6
Training loss: 0.5860503911972046
Validation loss: 1.8031922027628908

Epoch: 5| Step: 7
Training loss: 1.1191229820251465
Validation loss: 1.7879726143293484

Epoch: 5| Step: 8
Training loss: 0.9658635258674622
Validation loss: 1.7584358594750846

Epoch: 5| Step: 9
Training loss: 0.8714500665664673
Validation loss: 1.7343783032509588

Epoch: 5| Step: 10
Training loss: 0.846030056476593
Validation loss: 1.7291392690391951

Epoch: 324| Step: 0
Training loss: 0.5974773168563843
Validation loss: 1.7786532038001603

Epoch: 5| Step: 1
Training loss: 0.8191264867782593
Validation loss: 1.7957284886349913

Epoch: 5| Step: 2
Training loss: 0.7094055414199829
Validation loss: 1.8458302975982748

Epoch: 5| Step: 3
Training loss: 0.8542789220809937
Validation loss: 1.8798481572058894

Epoch: 5| Step: 4
Training loss: 1.0775766372680664
Validation loss: 1.848541316165719

Epoch: 5| Step: 5
Training loss: 0.8977037668228149
Validation loss: 1.8130530324033511

Epoch: 5| Step: 6
Training loss: 0.9296029806137085
Validation loss: 1.7510705404384161

Epoch: 5| Step: 7
Training loss: 0.9199166297912598
Validation loss: 1.766748091225983

Epoch: 5| Step: 8
Training loss: 1.0805740356445312
Validation loss: 1.7697182470752346

Epoch: 5| Step: 9
Training loss: 0.7928420901298523
Validation loss: 1.7767123035205308

Epoch: 5| Step: 10
Training loss: 0.42524465918540955
Validation loss: 1.7679867077899236

Epoch: 325| Step: 0
Training loss: 0.758955180644989
Validation loss: 1.8404853061963153

Epoch: 5| Step: 1
Training loss: 1.0896697044372559
Validation loss: 1.9184540676814255

Epoch: 5| Step: 2
Training loss: 0.8857053518295288
Validation loss: 1.9384018823664675

Epoch: 5| Step: 3
Training loss: 0.8668010830879211
Validation loss: 1.897307098552745

Epoch: 5| Step: 4
Training loss: 0.7266215085983276
Validation loss: 1.8168660517661803

Epoch: 5| Step: 5
Training loss: 0.633663535118103
Validation loss: 1.7683267465201757

Epoch: 5| Step: 6
Training loss: 1.2003045082092285
Validation loss: 1.7492216530666556

Epoch: 5| Step: 7
Training loss: 0.9558102488517761
Validation loss: 1.7602614523262106

Epoch: 5| Step: 8
Training loss: 1.401039481163025
Validation loss: 1.7640706313553678

Epoch: 5| Step: 9
Training loss: 0.6954237222671509
Validation loss: 1.7857575903656662

Epoch: 5| Step: 10
Training loss: 1.0183250904083252
Validation loss: 1.8366662058778989

Epoch: 326| Step: 0
Training loss: 1.5516237020492554
Validation loss: 1.8925034897301787

Epoch: 5| Step: 1
Training loss: 0.6213194131851196
Validation loss: 1.9610411120999245

Epoch: 5| Step: 2
Training loss: 1.2337806224822998
Validation loss: 1.9400579852442588

Epoch: 5| Step: 3
Training loss: 0.9627628326416016
Validation loss: 1.863258796353494

Epoch: 5| Step: 4
Training loss: 0.6986842155456543
Validation loss: 1.7806078093026274

Epoch: 5| Step: 5
Training loss: 0.8383258581161499
Validation loss: 1.7481980157154862

Epoch: 5| Step: 6
Training loss: 0.8494589924812317
Validation loss: 1.7601619241058186

Epoch: 5| Step: 7
Training loss: 0.7201082110404968
Validation loss: 1.7717417517016012

Epoch: 5| Step: 8
Training loss: 0.815008282661438
Validation loss: 1.795873800913493

Epoch: 5| Step: 9
Training loss: 0.7495298385620117
Validation loss: 1.8359721168395011

Epoch: 5| Step: 10
Training loss: 0.6390664577484131
Validation loss: 1.8786937421368015

Epoch: 327| Step: 0
Training loss: 1.0877519845962524
Validation loss: 1.9228826556154477

Epoch: 5| Step: 1
Training loss: 0.6366745233535767
Validation loss: 1.9244495937901158

Epoch: 5| Step: 2
Training loss: 0.7016347050666809
Validation loss: 1.885177130340248

Epoch: 5| Step: 3
Training loss: 0.9382500648498535
Validation loss: 1.8491423988855014

Epoch: 5| Step: 4
Training loss: 0.9484189748764038
Validation loss: 1.8358702326333651

Epoch: 5| Step: 5
Training loss: 0.724637508392334
Validation loss: 1.8210638799974996

Epoch: 5| Step: 6
Training loss: 0.6819771528244019
Validation loss: 1.805358168899372

Epoch: 5| Step: 7
Training loss: 0.7406680583953857
Validation loss: 1.8243454194838

Epoch: 5| Step: 8
Training loss: 0.7817181348800659
Validation loss: 1.8381898121167255

Epoch: 5| Step: 9
Training loss: 0.6980307102203369
Validation loss: 1.8639450047605781

Epoch: 5| Step: 10
Training loss: 1.002369999885559
Validation loss: 1.8183323003912484

Epoch: 328| Step: 0
Training loss: 0.7915158271789551
Validation loss: 1.77580657569311

Epoch: 5| Step: 1
Training loss: 0.8647669553756714
Validation loss: 1.7822830882123721

Epoch: 5| Step: 2
Training loss: 0.9431561231613159
Validation loss: 1.751591323524393

Epoch: 5| Step: 3
Training loss: 0.6282855272293091
Validation loss: 1.7576471169789631

Epoch: 5| Step: 4
Training loss: 0.850798487663269
Validation loss: 1.7860173794531053

Epoch: 5| Step: 5
Training loss: 1.1339784860610962
Validation loss: 1.7989994018308577

Epoch: 5| Step: 6
Training loss: 0.7700289487838745
Validation loss: 1.791950156611781

Epoch: 5| Step: 7
Training loss: 0.8003727197647095
Validation loss: 1.7867699335980158

Epoch: 5| Step: 8
Training loss: 0.41258907318115234
Validation loss: 1.7860369656675605

Epoch: 5| Step: 9
Training loss: 0.9003499746322632
Validation loss: 1.7572639629405031

Epoch: 5| Step: 10
Training loss: 0.5888257622718811
Validation loss: 1.7458794270792315

Epoch: 329| Step: 0
Training loss: 0.7138064503669739
Validation loss: 1.7237346620969876

Epoch: 5| Step: 1
Training loss: 0.7631557583808899
Validation loss: 1.733367532812139

Epoch: 5| Step: 2
Training loss: 0.9517498016357422
Validation loss: 1.7348902225494385

Epoch: 5| Step: 3
Training loss: 0.5336788296699524
Validation loss: 1.7350513986361924

Epoch: 5| Step: 4
Training loss: 0.8718999624252319
Validation loss: 1.7396301441295172

Epoch: 5| Step: 5
Training loss: 0.796751856803894
Validation loss: 1.774440937144782

Epoch: 5| Step: 6
Training loss: 0.6760714054107666
Validation loss: 1.7974808382731613

Epoch: 5| Step: 7
Training loss: 0.9519366025924683
Validation loss: 1.827536290691745

Epoch: 5| Step: 8
Training loss: 0.5648616552352905
Validation loss: 1.8138971418462775

Epoch: 5| Step: 9
Training loss: 0.8777448534965515
Validation loss: 1.8030893700097197

Epoch: 5| Step: 10
Training loss: 0.8780031800270081
Validation loss: 1.7976016870108984

Epoch: 330| Step: 0
Training loss: 0.9801728129386902
Validation loss: 1.7826886638518302

Epoch: 5| Step: 1
Training loss: 0.7810490727424622
Validation loss: 1.8007010029208275

Epoch: 5| Step: 2
Training loss: 0.8606233596801758
Validation loss: 1.7588157974263674

Epoch: 5| Step: 3
Training loss: 0.8203099966049194
Validation loss: 1.742308516656199

Epoch: 5| Step: 4
Training loss: 0.6749309301376343
Validation loss: 1.7300475887072984

Epoch: 5| Step: 5
Training loss: 0.5188767910003662
Validation loss: 1.726257913856096

Epoch: 5| Step: 6
Training loss: 0.8689098358154297
Validation loss: 1.7524636227597472

Epoch: 5| Step: 7
Training loss: 0.7068257331848145
Validation loss: 1.7460132324567406

Epoch: 5| Step: 8
Training loss: 0.9905716180801392
Validation loss: 1.7533906006043958

Epoch: 5| Step: 9
Training loss: 0.6998777985572815
Validation loss: 1.767451601643716

Epoch: 5| Step: 10
Training loss: 0.5219744443893433
Validation loss: 1.784227039224358

Epoch: 331| Step: 0
Training loss: 0.7509341239929199
Validation loss: 1.8326261569094915

Epoch: 5| Step: 1
Training loss: 0.7072809934616089
Validation loss: 1.866036145917831

Epoch: 5| Step: 2
Training loss: 0.9121385812759399
Validation loss: 1.8333055383415633

Epoch: 5| Step: 3
Training loss: 0.5870307683944702
Validation loss: 1.7867571974313388

Epoch: 5| Step: 4
Training loss: 0.34878820180892944
Validation loss: 1.7587124186177407

Epoch: 5| Step: 5
Training loss: 0.5801496505737305
Validation loss: 1.74249864650029

Epoch: 5| Step: 6
Training loss: 0.7417482733726501
Validation loss: 1.739232959285859

Epoch: 5| Step: 7
Training loss: 0.7658230066299438
Validation loss: 1.715322462461328

Epoch: 5| Step: 8
Training loss: 1.1060609817504883
Validation loss: 1.732433065291374

Epoch: 5| Step: 9
Training loss: 0.9547715187072754
Validation loss: 1.7242359243413454

Epoch: 5| Step: 10
Training loss: 0.8827246427536011
Validation loss: 1.7416111051395375

Epoch: 332| Step: 0
Training loss: 0.46129003167152405
Validation loss: 1.7449164685382639

Epoch: 5| Step: 1
Training loss: 0.7516049146652222
Validation loss: 1.7375145727588284

Epoch: 5| Step: 2
Training loss: 0.49207964539527893
Validation loss: 1.7699940127711142

Epoch: 5| Step: 3
Training loss: 0.7709223628044128
Validation loss: 1.7886372445732035

Epoch: 5| Step: 4
Training loss: 0.5414021611213684
Validation loss: 1.8182438394074798

Epoch: 5| Step: 5
Training loss: 1.0423628091812134
Validation loss: 1.803894792833636

Epoch: 5| Step: 6
Training loss: 0.9534971117973328
Validation loss: 1.7942620323550316

Epoch: 5| Step: 7
Training loss: 1.0728918313980103
Validation loss: 1.7893607872788624

Epoch: 5| Step: 8
Training loss: 0.8036812543869019
Validation loss: 1.7649302405695761

Epoch: 5| Step: 9
Training loss: 0.6322735548019409
Validation loss: 1.745966939515965

Epoch: 5| Step: 10
Training loss: 0.6141805052757263
Validation loss: 1.7498109456031554

Epoch: 333| Step: 0
Training loss: 1.1800814867019653
Validation loss: 1.73794521311278

Epoch: 5| Step: 1
Training loss: 0.5202745795249939
Validation loss: 1.7433305017409786

Epoch: 5| Step: 2
Training loss: 0.3993898928165436
Validation loss: 1.763850683807045

Epoch: 5| Step: 3
Training loss: 0.5139094591140747
Validation loss: 1.823877001321444

Epoch: 5| Step: 4
Training loss: 0.8679682016372681
Validation loss: 1.8747694287248837

Epoch: 5| Step: 5
Training loss: 0.9124920964241028
Validation loss: 1.873390559227236

Epoch: 5| Step: 6
Training loss: 1.6238664388656616
Validation loss: 1.8266667448064333

Epoch: 5| Step: 7
Training loss: 0.4471798539161682
Validation loss: 1.7763443416164768

Epoch: 5| Step: 8
Training loss: 0.6613587737083435
Validation loss: 1.7358439968478294

Epoch: 5| Step: 9
Training loss: 0.5833034515380859
Validation loss: 1.7316815648027646

Epoch: 5| Step: 10
Training loss: 0.6665924787521362
Validation loss: 1.6906596486286452

Epoch: 334| Step: 0
Training loss: 0.5633093118667603
Validation loss: 1.701186700533795

Epoch: 5| Step: 1
Training loss: 0.7392388582229614
Validation loss: 1.6930488963280954

Epoch: 5| Step: 2
Training loss: 0.6851445436477661
Validation loss: 1.7262075139630226

Epoch: 5| Step: 3
Training loss: 1.1026360988616943
Validation loss: 1.7521785177210325

Epoch: 5| Step: 4
Training loss: 1.254443883895874
Validation loss: 1.7623432464497064

Epoch: 5| Step: 5
Training loss: 0.47600847482681274
Validation loss: 1.775742708995778

Epoch: 5| Step: 6
Training loss: 0.972626805305481
Validation loss: 1.808993875339467

Epoch: 5| Step: 7
Training loss: 0.5952005386352539
Validation loss: 1.806190566350055

Epoch: 5| Step: 8
Training loss: 0.502691924571991
Validation loss: 1.7679513936401696

Epoch: 5| Step: 9
Training loss: 0.6350714564323425
Validation loss: 1.7556513009532806

Epoch: 5| Step: 10
Training loss: 0.7172549962997437
Validation loss: 1.7523625999368646

Epoch: 335| Step: 0
Training loss: 0.6448753476142883
Validation loss: 1.738643769294985

Epoch: 5| Step: 1
Training loss: 0.7921810150146484
Validation loss: 1.7493523282389487

Epoch: 5| Step: 2
Training loss: 0.7838281393051147
Validation loss: 1.7336358716410976

Epoch: 5| Step: 3
Training loss: 0.3901122212409973
Validation loss: 1.7229301544927782

Epoch: 5| Step: 4
Training loss: 0.6033971905708313
Validation loss: 1.7514608367796867

Epoch: 5| Step: 5
Training loss: 0.7695428729057312
Validation loss: 1.748581660691128

Epoch: 5| Step: 6
Training loss: 0.9688962697982788
Validation loss: 1.716656929703169

Epoch: 5| Step: 7
Training loss: 0.8982455134391785
Validation loss: 1.7223343182635564

Epoch: 5| Step: 8
Training loss: 0.48481646180152893
Validation loss: 1.7215158823997743

Epoch: 5| Step: 9
Training loss: 1.1632263660430908
Validation loss: 1.7244145331844207

Epoch: 5| Step: 10
Training loss: 0.5950696468353271
Validation loss: 1.743644199063701

Epoch: 336| Step: 0
Training loss: 0.8487126231193542
Validation loss: 1.7490055227792392

Epoch: 5| Step: 1
Training loss: 0.7377036809921265
Validation loss: 1.781606779303602

Epoch: 5| Step: 2
Training loss: 0.577933669090271
Validation loss: 1.782573810187719

Epoch: 5| Step: 3
Training loss: 0.7554236650466919
Validation loss: 1.7447721932523994

Epoch: 5| Step: 4
Training loss: 0.5298019051551819
Validation loss: 1.75262451171875

Epoch: 5| Step: 5
Training loss: 0.7213199138641357
Validation loss: 1.7382877142198625

Epoch: 5| Step: 6
Training loss: 0.581337034702301
Validation loss: 1.753488052275873

Epoch: 5| Step: 7
Training loss: 1.1258041858673096
Validation loss: 1.7487975487145044

Epoch: 5| Step: 8
Training loss: 0.9182518720626831
Validation loss: 1.7428058744758688

Epoch: 5| Step: 9
Training loss: 0.7131423950195312
Validation loss: 1.7330829430651922

Epoch: 5| Step: 10
Training loss: 0.5041226744651794
Validation loss: 1.75464492459451

Epoch: 337| Step: 0
Training loss: 0.9387749433517456
Validation loss: 1.7818494535261584

Epoch: 5| Step: 1
Training loss: 0.608862042427063
Validation loss: 1.768498061805643

Epoch: 5| Step: 2
Training loss: 0.9586885571479797
Validation loss: 1.779686858577113

Epoch: 5| Step: 3
Training loss: 0.8184054493904114
Validation loss: 1.7612327503901657

Epoch: 5| Step: 4
Training loss: 0.5174937844276428
Validation loss: 1.7518285551378805

Epoch: 5| Step: 5
Training loss: 0.34575432538986206
Validation loss: 1.7235169077432284

Epoch: 5| Step: 6
Training loss: 0.6102523803710938
Validation loss: 1.7286274843318488

Epoch: 5| Step: 7
Training loss: 0.7490547895431519
Validation loss: 1.7329357503562846

Epoch: 5| Step: 8
Training loss: 0.6920663118362427
Validation loss: 1.7306731695769935

Epoch: 5| Step: 9
Training loss: 0.7949520349502563
Validation loss: 1.7488512428857947

Epoch: 5| Step: 10
Training loss: 0.7882736325263977
Validation loss: 1.762444560245801

Epoch: 338| Step: 0
Training loss: 0.6223967671394348
Validation loss: 1.793741560751392

Epoch: 5| Step: 1
Training loss: 0.6606938242912292
Validation loss: 1.8053669198866813

Epoch: 5| Step: 2
Training loss: 0.5980797410011292
Validation loss: 1.801710162111508

Epoch: 5| Step: 3
Training loss: 0.5860507488250732
Validation loss: 1.8034863330984627

Epoch: 5| Step: 4
Training loss: 0.5040532350540161
Validation loss: 1.7991600921077113

Epoch: 5| Step: 5
Training loss: 0.6544095277786255
Validation loss: 1.7746815425093456

Epoch: 5| Step: 6
Training loss: 0.9327734708786011
Validation loss: 1.731359826621189

Epoch: 5| Step: 7
Training loss: 0.5433393716812134
Validation loss: 1.6763721396846156

Epoch: 5| Step: 8
Training loss: 0.5799951553344727
Validation loss: 1.6784057886369768

Epoch: 5| Step: 9
Training loss: 1.3138099908828735
Validation loss: 1.690194696508428

Epoch: 5| Step: 10
Training loss: 0.8722246885299683
Validation loss: 1.697266303082948

Epoch: 339| Step: 0
Training loss: 0.43577417731285095
Validation loss: 1.735432101834205

Epoch: 5| Step: 1
Training loss: 0.5766589641571045
Validation loss: 1.7458524396342616

Epoch: 5| Step: 2
Training loss: 0.45171046257019043
Validation loss: 1.7925529838890157

Epoch: 5| Step: 3
Training loss: 0.9470073580741882
Validation loss: 1.7652957900877921

Epoch: 5| Step: 4
Training loss: 0.6955278515815735
Validation loss: 1.7264894926419823

Epoch: 5| Step: 5
Training loss: 0.7734007239341736
Validation loss: 1.7173421357267646

Epoch: 5| Step: 6
Training loss: 0.4725187420845032
Validation loss: 1.7107123867157967

Epoch: 5| Step: 7
Training loss: 0.8780558705329895
Validation loss: 1.7148178867114487

Epoch: 5| Step: 8
Training loss: 0.9240776896476746
Validation loss: 1.7250083518284622

Epoch: 5| Step: 9
Training loss: 1.339073896408081
Validation loss: 1.7397657825100807

Epoch: 5| Step: 10
Training loss: 0.4458582401275635
Validation loss: 1.7356366149840816

Epoch: 340| Step: 0
Training loss: 0.5323476791381836
Validation loss: 1.7633451672010525

Epoch: 5| Step: 1
Training loss: 0.5619126558303833
Validation loss: 1.7873634740870485

Epoch: 5| Step: 2
Training loss: 0.5456998348236084
Validation loss: 1.7867350732126543

Epoch: 5| Step: 3
Training loss: 0.4951985478401184
Validation loss: 1.7805415994377547

Epoch: 5| Step: 4
Training loss: 0.7107173204421997
Validation loss: 1.7621053841806227

Epoch: 5| Step: 5
Training loss: 0.8339313268661499
Validation loss: 1.7309667295025242

Epoch: 5| Step: 6
Training loss: 0.7647320032119751
Validation loss: 1.7149629515986289

Epoch: 5| Step: 7
Training loss: 0.7990875244140625
Validation loss: 1.7115384173649613

Epoch: 5| Step: 8
Training loss: 1.078151822090149
Validation loss: 1.7470918598995413

Epoch: 5| Step: 9
Training loss: 0.4809848666191101
Validation loss: 1.743223673553877

Epoch: 5| Step: 10
Training loss: 0.8558246493339539
Validation loss: 1.7493567543645059

Epoch: 341| Step: 0
Training loss: 0.5121850967407227
Validation loss: 1.7673627099683207

Epoch: 5| Step: 1
Training loss: 1.2471227645874023
Validation loss: 1.7313994310235465

Epoch: 5| Step: 2
Training loss: 0.5564673542976379
Validation loss: 1.7499691337667487

Epoch: 5| Step: 3
Training loss: 0.681250274181366
Validation loss: 1.754593349272205

Epoch: 5| Step: 4
Training loss: 0.7948065400123596
Validation loss: 1.770602064747964

Epoch: 5| Step: 5
Training loss: 0.3615555167198181
Validation loss: 1.8145408643189298

Epoch: 5| Step: 6
Training loss: 0.5128269195556641
Validation loss: 1.8240676567118654

Epoch: 5| Step: 7
Training loss: 0.7857415080070496
Validation loss: 1.7941042082284087

Epoch: 5| Step: 8
Training loss: 0.5550094842910767
Validation loss: 1.7906082625030189

Epoch: 5| Step: 9
Training loss: 0.7617933750152588
Validation loss: 1.7360996610374861

Epoch: 5| Step: 10
Training loss: 0.8785014152526855
Validation loss: 1.7005948148747927

Epoch: 342| Step: 0
Training loss: 0.5815600156784058
Validation loss: 1.6805569766670145

Epoch: 5| Step: 1
Training loss: 0.5305624604225159
Validation loss: 1.6828178295525171

Epoch: 5| Step: 2
Training loss: 0.7665008306503296
Validation loss: 1.6707569668369908

Epoch: 5| Step: 3
Training loss: 0.7499549388885498
Validation loss: 1.688800246484818

Epoch: 5| Step: 4
Training loss: 0.7595282793045044
Validation loss: 1.7810389854574715

Epoch: 5| Step: 5
Training loss: 1.1812647581100464
Validation loss: 1.818084744996922

Epoch: 5| Step: 6
Training loss: 0.8792446255683899
Validation loss: 1.8403648112409858

Epoch: 5| Step: 7
Training loss: 0.7613597512245178
Validation loss: 1.8126441676129577

Epoch: 5| Step: 8
Training loss: 0.5298067331314087
Validation loss: 1.7647852718189199

Epoch: 5| Step: 9
Training loss: 0.8145845532417297
Validation loss: 1.7086700624035251

Epoch: 5| Step: 10
Training loss: 0.6782126426696777
Validation loss: 1.724347496545443

Epoch: 343| Step: 0
Training loss: 0.5657760500907898
Validation loss: 1.7068495570972402

Epoch: 5| Step: 1
Training loss: 0.366019070148468
Validation loss: 1.7410579227632093

Epoch: 5| Step: 2
Training loss: 0.5904755592346191
Validation loss: 1.7641526101737894

Epoch: 5| Step: 3
Training loss: 0.43304139375686646
Validation loss: 1.8196650243574573

Epoch: 5| Step: 4
Training loss: 1.2648308277130127
Validation loss: 1.8261353251754597

Epoch: 5| Step: 5
Training loss: 0.815540611743927
Validation loss: 1.758815598744218

Epoch: 5| Step: 6
Training loss: 0.9644652605056763
Validation loss: 1.6946802023918397

Epoch: 5| Step: 7
Training loss: 0.4628140926361084
Validation loss: 1.688513986525997

Epoch: 5| Step: 8
Training loss: 0.9929231405258179
Validation loss: 1.6838689504131195

Epoch: 5| Step: 9
Training loss: 0.7121605277061462
Validation loss: 1.678454928500678

Epoch: 5| Step: 10
Training loss: 0.7033331990242004
Validation loss: 1.6826086172493555

Epoch: 344| Step: 0
Training loss: 0.7227371335029602
Validation loss: 1.7043103095023864

Epoch: 5| Step: 1
Training loss: 0.8155332803726196
Validation loss: 1.7130682340232275

Epoch: 5| Step: 2
Training loss: 0.8249146342277527
Validation loss: 1.7706067869740147

Epoch: 5| Step: 3
Training loss: 0.9529860615730286
Validation loss: 1.756666060416929

Epoch: 5| Step: 4
Training loss: 0.40406370162963867
Validation loss: 1.7317265848959646

Epoch: 5| Step: 5
Training loss: 1.116309404373169
Validation loss: 1.72148778746205

Epoch: 5| Step: 6
Training loss: 0.5385481119155884
Validation loss: 1.6929568770111247

Epoch: 5| Step: 7
Training loss: 0.6544331908226013
Validation loss: 1.7298182108068978

Epoch: 5| Step: 8
Training loss: 0.6987028121948242
Validation loss: 1.735502464796907

Epoch: 5| Step: 9
Training loss: 0.5586137175559998
Validation loss: 1.7579127973125828

Epoch: 5| Step: 10
Training loss: 0.4982321262359619
Validation loss: 1.8143565757300264

Epoch: 345| Step: 0
Training loss: 0.770332932472229
Validation loss: 1.8383178967301563

Epoch: 5| Step: 1
Training loss: 0.5211182832717896
Validation loss: 1.8287272261035057

Epoch: 5| Step: 2
Training loss: 0.7699942588806152
Validation loss: 1.8069740585101548

Epoch: 5| Step: 3
Training loss: 0.7565485835075378
Validation loss: 1.7983216252378238

Epoch: 5| Step: 4
Training loss: 0.9136564135551453
Validation loss: 1.8006768585533224

Epoch: 5| Step: 5
Training loss: 0.4906715750694275
Validation loss: 1.776357299538069

Epoch: 5| Step: 6
Training loss: 0.6062667965888977
Validation loss: 1.7482248429329164

Epoch: 5| Step: 7
Training loss: 0.6346893310546875
Validation loss: 1.7204879509505404

Epoch: 5| Step: 8
Training loss: 0.7790176868438721
Validation loss: 1.697712141980407

Epoch: 5| Step: 9
Training loss: 0.8863059878349304
Validation loss: 1.7073609303402644

Epoch: 5| Step: 10
Training loss: 0.4356152415275574
Validation loss: 1.696111326576561

Epoch: 346| Step: 0
Training loss: 0.7578830718994141
Validation loss: 1.6871077719555105

Epoch: 5| Step: 1
Training loss: 0.518944263458252
Validation loss: 1.687920557555332

Epoch: 5| Step: 2
Training loss: 0.7165875434875488
Validation loss: 1.7246375994015766

Epoch: 5| Step: 3
Training loss: 0.5607432126998901
Validation loss: 1.7420434823600195

Epoch: 5| Step: 4
Training loss: 0.8951848745346069
Validation loss: 1.7390045837689472

Epoch: 5| Step: 5
Training loss: 0.9729284048080444
Validation loss: 1.7365282517607494

Epoch: 5| Step: 6
Training loss: 0.6278986930847168
Validation loss: 1.7241392597075431

Epoch: 5| Step: 7
Training loss: 0.6894745826721191
Validation loss: 1.7434199792082592

Epoch: 5| Step: 8
Training loss: 0.37721702456474304
Validation loss: 1.706493959631971

Epoch: 5| Step: 9
Training loss: 0.4095454812049866
Validation loss: 1.7348960753410094

Epoch: 5| Step: 10
Training loss: 0.6549711227416992
Validation loss: 1.756824383171656

Epoch: 347| Step: 0
Training loss: 0.9314994812011719
Validation loss: 1.7461347695319884

Epoch: 5| Step: 1
Training loss: 0.7002716064453125
Validation loss: 1.7271145261744016

Epoch: 5| Step: 2
Training loss: 0.5214249491691589
Validation loss: 1.6750831360458045

Epoch: 5| Step: 3
Training loss: 0.6957465410232544
Validation loss: 1.670941178516675

Epoch: 5| Step: 4
Training loss: 0.7194798588752747
Validation loss: 1.6970705595067752

Epoch: 5| Step: 5
Training loss: 0.40664181113243103
Validation loss: 1.6834867526126165

Epoch: 5| Step: 6
Training loss: 0.5680116415023804
Validation loss: 1.7098703948400353

Epoch: 5| Step: 7
Training loss: 0.6242538690567017
Validation loss: 1.735127515690301

Epoch: 5| Step: 8
Training loss: 0.6611596345901489
Validation loss: 1.7695336598221973

Epoch: 5| Step: 9
Training loss: 0.8392741084098816
Validation loss: 1.789165844199478

Epoch: 5| Step: 10
Training loss: 0.4566662907600403
Validation loss: 1.778736219611219

Epoch: 348| Step: 0
Training loss: 0.7015290260314941
Validation loss: 1.744492910241568

Epoch: 5| Step: 1
Training loss: 0.6360498666763306
Validation loss: 1.7607642117366995

Epoch: 5| Step: 2
Training loss: 0.5199583172798157
Validation loss: 1.758153397549865

Epoch: 5| Step: 3
Training loss: 0.5789872407913208
Validation loss: 1.763493222575034

Epoch: 5| Step: 4
Training loss: 0.4734775424003601
Validation loss: 1.7767838073033158

Epoch: 5| Step: 5
Training loss: 0.8033354878425598
Validation loss: 1.7307588208106257

Epoch: 5| Step: 6
Training loss: 0.7526136040687561
Validation loss: 1.6833477430446173

Epoch: 5| Step: 7
Training loss: 0.37689870595932007
Validation loss: 1.6814277915544407

Epoch: 5| Step: 8
Training loss: 0.732205331325531
Validation loss: 1.687013433825585

Epoch: 5| Step: 9
Training loss: 0.8978092074394226
Validation loss: 1.6805420383330314

Epoch: 5| Step: 10
Training loss: 0.67685866355896
Validation loss: 1.712130304305784

Epoch: 349| Step: 0
Training loss: 0.7205149531364441
Validation loss: 1.7531923299194665

Epoch: 5| Step: 1
Training loss: 0.6006642580032349
Validation loss: 1.7892148674175303

Epoch: 5| Step: 2
Training loss: 0.5901535749435425
Validation loss: 1.8139978775414087

Epoch: 5| Step: 3
Training loss: 1.0484340190887451
Validation loss: 1.781217421254804

Epoch: 5| Step: 4
Training loss: 0.38470587134361267
Validation loss: 1.7456708441498459

Epoch: 5| Step: 5
Training loss: 0.5541413426399231
Validation loss: 1.7281791010210592

Epoch: 5| Step: 6
Training loss: 0.46543264389038086
Validation loss: 1.696033998202252

Epoch: 5| Step: 7
Training loss: 0.7031450271606445
Validation loss: 1.6672648332452262

Epoch: 5| Step: 8
Training loss: 0.39595288038253784
Validation loss: 1.66866849571146

Epoch: 5| Step: 9
Training loss: 0.6823863983154297
Validation loss: 1.6639527800262615

Epoch: 5| Step: 10
Training loss: 1.1320199966430664
Validation loss: 1.6666293003225838

Epoch: 350| Step: 0
Training loss: 0.4786784052848816
Validation loss: 1.6987470273048646

Epoch: 5| Step: 1
Training loss: 1.0485502481460571
Validation loss: 1.7589351977071455

Epoch: 5| Step: 2
Training loss: 0.49933886528015137
Validation loss: 1.7772039751852713

Epoch: 5| Step: 3
Training loss: 0.9237500429153442
Validation loss: 1.7857264728956326

Epoch: 5| Step: 4
Training loss: 0.49643412232398987
Validation loss: 1.7411222868068243

Epoch: 5| Step: 5
Training loss: 0.5191034078598022
Validation loss: 1.7093588536785496

Epoch: 5| Step: 6
Training loss: 0.667881429195404
Validation loss: 1.6930183351680796

Epoch: 5| Step: 7
Training loss: 0.6230891942977905
Validation loss: 1.7134437407216718

Epoch: 5| Step: 8
Training loss: 0.6861662864685059
Validation loss: 1.6869924869588626

Epoch: 5| Step: 9
Training loss: 0.577328085899353
Validation loss: 1.7142840149582073

Epoch: 5| Step: 10
Training loss: 0.6648303270339966
Validation loss: 1.7241399647087179

Epoch: 351| Step: 0
Training loss: 0.6257209777832031
Validation loss: 1.8013480645354076

Epoch: 5| Step: 1
Training loss: 0.9468835592269897
Validation loss: 1.7890208164850872

Epoch: 5| Step: 2
Training loss: 0.5754188299179077
Validation loss: 1.7482999614489976

Epoch: 5| Step: 3
Training loss: 0.7452243566513062
Validation loss: 1.6811799900506132

Epoch: 5| Step: 4
Training loss: 0.5953279733657837
Validation loss: 1.6867566749613772

Epoch: 5| Step: 5
Training loss: 0.3446975648403168
Validation loss: 1.679245465545244

Epoch: 5| Step: 6
Training loss: 0.4905855059623718
Validation loss: 1.6801875739969232

Epoch: 5| Step: 7
Training loss: 0.725554883480072
Validation loss: 1.6974723044262137

Epoch: 5| Step: 8
Training loss: 0.5509928464889526
Validation loss: 1.7215842636682654

Epoch: 5| Step: 9
Training loss: 0.8971688151359558
Validation loss: 1.766776927055851

Epoch: 5| Step: 10
Training loss: 0.6288905739784241
Validation loss: 1.7497972621712634

Epoch: 352| Step: 0
Training loss: 0.4416562020778656
Validation loss: 1.733119180125575

Epoch: 5| Step: 1
Training loss: 0.435890257358551
Validation loss: 1.6968368227763841

Epoch: 5| Step: 2
Training loss: 0.7839312553405762
Validation loss: 1.6833642477630286

Epoch: 5| Step: 3
Training loss: 0.9208956956863403
Validation loss: 1.694191704514206

Epoch: 5| Step: 4
Training loss: 0.6927374005317688
Validation loss: 1.682656967511741

Epoch: 5| Step: 5
Training loss: 0.4704103469848633
Validation loss: 1.6988586456544938

Epoch: 5| Step: 6
Training loss: 0.9630451202392578
Validation loss: 1.7140855699457147

Epoch: 5| Step: 7
Training loss: 0.5984411239624023
Validation loss: 1.7469805248322026

Epoch: 5| Step: 8
Training loss: 0.7421994805335999
Validation loss: 1.761016902103219

Epoch: 5| Step: 9
Training loss: 0.6172157526016235
Validation loss: 1.7524468988500617

Epoch: 5| Step: 10
Training loss: 0.21244379878044128
Validation loss: 1.7312487350997103

Epoch: 353| Step: 0
Training loss: 0.6355530023574829
Validation loss: 1.6847534128414687

Epoch: 5| Step: 1
Training loss: 0.47664833068847656
Validation loss: 1.6635056862267115

Epoch: 5| Step: 2
Training loss: 0.6542060971260071
Validation loss: 1.6437613425716278

Epoch: 5| Step: 3
Training loss: 1.2104177474975586
Validation loss: 1.6266120274861653

Epoch: 5| Step: 4
Training loss: 0.7805387377738953
Validation loss: 1.656810123433349

Epoch: 5| Step: 5
Training loss: 0.5206643342971802
Validation loss: 1.6704608137889574

Epoch: 5| Step: 6
Training loss: 0.6192180514335632
Validation loss: 1.7203353053780013

Epoch: 5| Step: 7
Training loss: 0.7029814720153809
Validation loss: 1.7315420553248415

Epoch: 5| Step: 8
Training loss: 0.4332578778266907
Validation loss: 1.7292952588809434

Epoch: 5| Step: 9
Training loss: 0.5311228632926941
Validation loss: 1.7052574042351014

Epoch: 5| Step: 10
Training loss: 0.37422433495521545
Validation loss: 1.739343071496615

Epoch: 354| Step: 0
Training loss: 0.5381957292556763
Validation loss: 1.7185541250372445

Epoch: 5| Step: 1
Training loss: 0.6709368228912354
Validation loss: 1.7037114033135035

Epoch: 5| Step: 2
Training loss: 0.6032038927078247
Validation loss: 1.7050155721684939

Epoch: 5| Step: 3
Training loss: 0.47302332520484924
Validation loss: 1.7158548466620906

Epoch: 5| Step: 4
Training loss: 0.7813984155654907
Validation loss: 1.728934153433769

Epoch: 5| Step: 5
Training loss: 0.33133062720298767
Validation loss: 1.7219931464041434

Epoch: 5| Step: 6
Training loss: 0.7471046447753906
Validation loss: 1.6966154985530402

Epoch: 5| Step: 7
Training loss: 0.5356317758560181
Validation loss: 1.676444016477113

Epoch: 5| Step: 8
Training loss: 0.6448397636413574
Validation loss: 1.7000309754443426

Epoch: 5| Step: 9
Training loss: 0.919884204864502
Validation loss: 1.6816258238207908

Epoch: 5| Step: 10
Training loss: 0.5994744300842285
Validation loss: 1.7116757874847741

Epoch: 355| Step: 0
Training loss: 0.6430194973945618
Validation loss: 1.7293899302841516

Epoch: 5| Step: 1
Training loss: 0.3157976269721985
Validation loss: 1.7332323930596794

Epoch: 5| Step: 2
Training loss: 0.5612970590591431
Validation loss: 1.7164219130751908

Epoch: 5| Step: 3
Training loss: 0.9322742223739624
Validation loss: 1.7477603125315841

Epoch: 5| Step: 4
Training loss: 1.0248643159866333
Validation loss: 1.74041913401696

Epoch: 5| Step: 5
Training loss: 0.5205198526382446
Validation loss: 1.7294030740696897

Epoch: 5| Step: 6
Training loss: 0.4874113202095032
Validation loss: 1.6988872366566812

Epoch: 5| Step: 7
Training loss: 0.4436160922050476
Validation loss: 1.6903978329832836

Epoch: 5| Step: 8
Training loss: 0.6569241881370544
Validation loss: 1.6489110415981663

Epoch: 5| Step: 9
Training loss: 0.7456092238426208
Validation loss: 1.649291205149825

Epoch: 5| Step: 10
Training loss: 0.37739798426628113
Validation loss: 1.6476855342106154

Epoch: 356| Step: 0
Training loss: 0.5881568193435669
Validation loss: 1.6620282614102928

Epoch: 5| Step: 1
Training loss: 0.611526608467102
Validation loss: 1.7136972091531242

Epoch: 5| Step: 2
Training loss: 0.3773406445980072
Validation loss: 1.7263793612039218

Epoch: 5| Step: 3
Training loss: 0.7298694849014282
Validation loss: 1.7438087489015313

Epoch: 5| Step: 4
Training loss: 0.7855316400527954
Validation loss: 1.739379499548225

Epoch: 5| Step: 5
Training loss: 0.7365740537643433
Validation loss: 1.7049491315759637

Epoch: 5| Step: 6
Training loss: 0.5369474291801453
Validation loss: 1.6725334800699705

Epoch: 5| Step: 7
Training loss: 0.5985013246536255
Validation loss: 1.684283468031114

Epoch: 5| Step: 8
Training loss: 0.5658397674560547
Validation loss: 1.6845783059315016

Epoch: 5| Step: 9
Training loss: 0.7077283263206482
Validation loss: 1.6739702070913007

Epoch: 5| Step: 10
Training loss: 0.5207298398017883
Validation loss: 1.7130542237271544

Epoch: 357| Step: 0
Training loss: 0.44035378098487854
Validation loss: 1.730294668546287

Epoch: 5| Step: 1
Training loss: 0.8115648031234741
Validation loss: 1.7662331673406786

Epoch: 5| Step: 2
Training loss: 0.6533621549606323
Validation loss: 1.7422532522550194

Epoch: 5| Step: 3
Training loss: 0.5790508389472961
Validation loss: 1.706216445533178

Epoch: 5| Step: 4
Training loss: 0.7748411297798157
Validation loss: 1.6777939181174002

Epoch: 5| Step: 5
Training loss: 0.5925870537757874
Validation loss: 1.652308879360076

Epoch: 5| Step: 6
Training loss: 0.6135724782943726
Validation loss: 1.6808816309898131

Epoch: 5| Step: 7
Training loss: 0.42244261503219604
Validation loss: 1.6972364828150759

Epoch: 5| Step: 8
Training loss: 0.787590503692627
Validation loss: 1.7023550528351978

Epoch: 5| Step: 9
Training loss: 0.29481106996536255
Validation loss: 1.712351946420567

Epoch: 5| Step: 10
Training loss: 0.611822247505188
Validation loss: 1.7080545015232538

Epoch: 358| Step: 0
Training loss: 0.716923177242279
Validation loss: 1.7232665631078905

Epoch: 5| Step: 1
Training loss: 0.49177154898643494
Validation loss: 1.7097903605430358

Epoch: 5| Step: 2
Training loss: 0.38009220361709595
Validation loss: 1.7280164572500414

Epoch: 5| Step: 3
Training loss: 0.2847917973995209
Validation loss: 1.6996190676125147

Epoch: 5| Step: 4
Training loss: 0.6354225277900696
Validation loss: 1.696439709714664

Epoch: 5| Step: 5
Training loss: 0.6616030931472778
Validation loss: 1.671088041797761

Epoch: 5| Step: 6
Training loss: 0.6440695524215698
Validation loss: 1.651216059602717

Epoch: 5| Step: 7
Training loss: 0.6837436556816101
Validation loss: 1.6975850232185856

Epoch: 5| Step: 8
Training loss: 0.6383305788040161
Validation loss: 1.7179781416411042

Epoch: 5| Step: 9
Training loss: 0.6974417567253113
Validation loss: 1.7323577968023156

Epoch: 5| Step: 10
Training loss: 0.596520721912384
Validation loss: 1.7407248686718684

Epoch: 359| Step: 0
Training loss: 0.5196050405502319
Validation loss: 1.7127113444830782

Epoch: 5| Step: 1
Training loss: 0.45938840508461
Validation loss: 1.6957579158967542

Epoch: 5| Step: 2
Training loss: 0.8928612470626831
Validation loss: 1.6827313566720614

Epoch: 5| Step: 3
Training loss: 0.26525333523750305
Validation loss: 1.6669714168835712

Epoch: 5| Step: 4
Training loss: 0.7157028317451477
Validation loss: 1.6810824589062763

Epoch: 5| Step: 5
Training loss: 0.3421407639980316
Validation loss: 1.6932922870882097

Epoch: 5| Step: 6
Training loss: 0.4278629422187805
Validation loss: 1.7146643054100774

Epoch: 5| Step: 7
Training loss: 0.4774557650089264
Validation loss: 1.6856504037816038

Epoch: 5| Step: 8
Training loss: 0.5499582290649414
Validation loss: 1.6621009534405125

Epoch: 5| Step: 9
Training loss: 0.8594375848770142
Validation loss: 1.6669504642486572

Epoch: 5| Step: 10
Training loss: 0.7759715914726257
Validation loss: 1.6804300572282524

Epoch: 360| Step: 0
Training loss: 0.28139933943748474
Validation loss: 1.6616423835036576

Epoch: 5| Step: 1
Training loss: 1.040816307067871
Validation loss: 1.6613531433125979

Epoch: 5| Step: 2
Training loss: 0.45591235160827637
Validation loss: 1.6605085198597243

Epoch: 5| Step: 3
Training loss: 0.5009501576423645
Validation loss: 1.6752963809556858

Epoch: 5| Step: 4
Training loss: 0.26761728525161743
Validation loss: 1.6859236507005588

Epoch: 5| Step: 5
Training loss: 0.8235895037651062
Validation loss: 1.7107067749064455

Epoch: 5| Step: 6
Training loss: 0.4560062885284424
Validation loss: 1.702628053644652

Epoch: 5| Step: 7
Training loss: 0.43592387437820435
Validation loss: 1.702183154321486

Epoch: 5| Step: 8
Training loss: 0.8458321690559387
Validation loss: 1.695487021118082

Epoch: 5| Step: 9
Training loss: 0.7807338833808899
Validation loss: 1.661815821483571

Epoch: 5| Step: 10
Training loss: 0.49510401487350464
Validation loss: 1.6772015043484267

Epoch: 361| Step: 0
Training loss: 0.6534445285797119
Validation loss: 1.6920378233796807

Epoch: 5| Step: 1
Training loss: 0.7535346746444702
Validation loss: 1.6748425806722333

Epoch: 5| Step: 2
Training loss: 0.36146363615989685
Validation loss: 1.7193140957945137

Epoch: 5| Step: 3
Training loss: 0.43913698196411133
Validation loss: 1.7031222146044496

Epoch: 5| Step: 4
Training loss: 0.6223713159561157
Validation loss: 1.7005651048434678

Epoch: 5| Step: 5
Training loss: 0.42983102798461914
Validation loss: 1.698626382376558

Epoch: 5| Step: 6
Training loss: 0.5135748982429504
Validation loss: 1.6774900267201085

Epoch: 5| Step: 7
Training loss: 0.42794689536094666
Validation loss: 1.676256973256347

Epoch: 5| Step: 8
Training loss: 0.7739068269729614
Validation loss: 1.6618432665383944

Epoch: 5| Step: 9
Training loss: 0.8170364499092102
Validation loss: 1.664526903501121

Epoch: 5| Step: 10
Training loss: 0.537865936756134
Validation loss: 1.644016274841883

Epoch: 362| Step: 0
Training loss: 0.640803337097168
Validation loss: 1.695212443669637

Epoch: 5| Step: 1
Training loss: 0.6947922706604004
Validation loss: 1.7012050651734876

Epoch: 5| Step: 2
Training loss: 0.6728549003601074
Validation loss: 1.688353911522896

Epoch: 5| Step: 3
Training loss: 0.3819691240787506
Validation loss: 1.672407196414086

Epoch: 5| Step: 4
Training loss: 0.7310020327568054
Validation loss: 1.6795154938133814

Epoch: 5| Step: 5
Training loss: 0.28774183988571167
Validation loss: 1.6763427026810185

Epoch: 5| Step: 6
Training loss: 0.48536476492881775
Validation loss: 1.707979256106961

Epoch: 5| Step: 7
Training loss: 0.7190701961517334
Validation loss: 1.6933655559375722

Epoch: 5| Step: 8
Training loss: 0.6415461301803589
Validation loss: 1.7286439634138537

Epoch: 5| Step: 9
Training loss: 0.5635648965835571
Validation loss: 1.7224639487522904

Epoch: 5| Step: 10
Training loss: 0.4698733389377594
Validation loss: 1.7079723112044796

Epoch: 363| Step: 0
Training loss: 0.6760997772216797
Validation loss: 1.6874533417404338

Epoch: 5| Step: 1
Training loss: 0.4503358006477356
Validation loss: 1.6690530892341369

Epoch: 5| Step: 2
Training loss: 0.6386234760284424
Validation loss: 1.6561141565281858

Epoch: 5| Step: 3
Training loss: 0.39194220304489136
Validation loss: 1.643253355897883

Epoch: 5| Step: 4
Training loss: 0.705052375793457
Validation loss: 1.6873709155667214

Epoch: 5| Step: 5
Training loss: 0.49102792143821716
Validation loss: 1.7091076015144266

Epoch: 5| Step: 6
Training loss: 0.7297340631484985
Validation loss: 1.7466918024965512

Epoch: 5| Step: 7
Training loss: 0.4396304488182068
Validation loss: 1.7631391107395131

Epoch: 5| Step: 8
Training loss: 0.6220751404762268
Validation loss: 1.7437664795947332

Epoch: 5| Step: 9
Training loss: 0.8022375106811523
Validation loss: 1.74919726387147

Epoch: 5| Step: 10
Training loss: 0.5360545516014099
Validation loss: 1.7208435484158096

Epoch: 364| Step: 0
Training loss: 0.46043387055397034
Validation loss: 1.6995437222142373

Epoch: 5| Step: 1
Training loss: 0.5562937259674072
Validation loss: 1.682979635013047

Epoch: 5| Step: 2
Training loss: 0.5388106107711792
Validation loss: 1.663267340711368

Epoch: 5| Step: 3
Training loss: 0.48895329236984253
Validation loss: 1.6638443034182313

Epoch: 5| Step: 4
Training loss: 0.8691712617874146
Validation loss: 1.657290175396909

Epoch: 5| Step: 5
Training loss: 0.4099845886230469
Validation loss: 1.6721998709504322

Epoch: 5| Step: 6
Training loss: 0.3471315801143646
Validation loss: 1.6643333435058594

Epoch: 5| Step: 7
Training loss: 0.583358883857727
Validation loss: 1.6672410465055896

Epoch: 5| Step: 8
Training loss: 0.7287128567695618
Validation loss: 1.661030283538244

Epoch: 5| Step: 9
Training loss: 0.7577845454216003
Validation loss: 1.6476096748023905

Epoch: 5| Step: 10
Training loss: 0.432388037443161
Validation loss: 1.6040180870281753

Epoch: 365| Step: 0
Training loss: 0.4069649577140808
Validation loss: 1.6199184912507252

Epoch: 5| Step: 1
Training loss: 0.5835199952125549
Validation loss: 1.610851276305414

Epoch: 5| Step: 2
Training loss: 0.6404983997344971
Validation loss: 1.6371990660185456

Epoch: 5| Step: 3
Training loss: 0.47043079137802124
Validation loss: 1.6607916419224074

Epoch: 5| Step: 4
Training loss: 0.3970642685890198
Validation loss: 1.701194776001797

Epoch: 5| Step: 5
Training loss: 0.5503778457641602
Validation loss: 1.7041775770084833

Epoch: 5| Step: 6
Training loss: 0.4954417645931244
Validation loss: 1.7331242048612205

Epoch: 5| Step: 7
Training loss: 0.3805363178253174
Validation loss: 1.7246588814643122

Epoch: 5| Step: 8
Training loss: 0.809099018573761
Validation loss: 1.6942641183894167

Epoch: 5| Step: 9
Training loss: 0.531360924243927
Validation loss: 1.6753249053032166

Epoch: 5| Step: 10
Training loss: 0.7359962463378906
Validation loss: 1.65710864784897

Epoch: 366| Step: 0
Training loss: 0.5429690480232239
Validation loss: 1.6503291315929864

Epoch: 5| Step: 1
Training loss: 0.4652908444404602
Validation loss: 1.6425862376407911

Epoch: 5| Step: 2
Training loss: 0.6525198221206665
Validation loss: 1.6720464075765302

Epoch: 5| Step: 3
Training loss: 0.4226887822151184
Validation loss: 1.689481762147719

Epoch: 5| Step: 4
Training loss: 0.485068142414093
Validation loss: 1.6954528849612

Epoch: 5| Step: 5
Training loss: 0.32788801193237305
Validation loss: 1.681049826324627

Epoch: 5| Step: 6
Training loss: 0.7818676233291626
Validation loss: 1.6780709605063162

Epoch: 5| Step: 7
Training loss: 0.642023503780365
Validation loss: 1.6394141258731965

Epoch: 5| Step: 8
Training loss: 0.550980806350708
Validation loss: 1.6641701549612067

Epoch: 5| Step: 9
Training loss: 0.437957227230072
Validation loss: 1.6711273834269533

Epoch: 5| Step: 10
Training loss: 0.7358317375183105
Validation loss: 1.6716136124826246

Epoch: 367| Step: 0
Training loss: 0.8132198452949524
Validation loss: 1.6642128664960143

Epoch: 5| Step: 1
Training loss: 0.5463858842849731
Validation loss: 1.6669704811547392

Epoch: 5| Step: 2
Training loss: 0.6293815970420837
Validation loss: 1.6766178338758406

Epoch: 5| Step: 3
Training loss: 0.38545194268226624
Validation loss: 1.6817358680950698

Epoch: 5| Step: 4
Training loss: 0.6199072003364563
Validation loss: 1.6769035593155892

Epoch: 5| Step: 5
Training loss: 0.4436244070529938
Validation loss: 1.677489665246779

Epoch: 5| Step: 6
Training loss: 0.1862243413925171
Validation loss: 1.6860244504867061

Epoch: 5| Step: 7
Training loss: 0.550344705581665
Validation loss: 1.6874093663307927

Epoch: 5| Step: 8
Training loss: 0.5080739259719849
Validation loss: 1.660820129097149

Epoch: 5| Step: 9
Training loss: 0.6031938791275024
Validation loss: 1.6297800579378683

Epoch: 5| Step: 10
Training loss: 0.5105692744255066
Validation loss: 1.6362110030266546

Epoch: 368| Step: 0
Training loss: 0.6212207674980164
Validation loss: 1.625820134275703

Epoch: 5| Step: 1
Training loss: 0.6210178136825562
Validation loss: 1.6506791768535491

Epoch: 5| Step: 2
Training loss: 0.7916765809059143
Validation loss: 1.6475309864167245

Epoch: 5| Step: 3
Training loss: 0.33336901664733887
Validation loss: 1.6722637594387095

Epoch: 5| Step: 4
Training loss: 0.41818007826805115
Validation loss: 1.6583093315042474

Epoch: 5| Step: 5
Training loss: 0.6718139052391052
Validation loss: 1.6357940768682828

Epoch: 5| Step: 6
Training loss: 0.4756118655204773
Validation loss: 1.6383563139105355

Epoch: 5| Step: 7
Training loss: 0.705157458782196
Validation loss: 1.6557757508370183

Epoch: 5| Step: 8
Training loss: 0.46567636728286743
Validation loss: 1.6366076661694435

Epoch: 5| Step: 9
Training loss: 0.47807517647743225
Validation loss: 1.6536829843316028

Epoch: 5| Step: 10
Training loss: 0.3046969771385193
Validation loss: 1.713800399534164

Epoch: 369| Step: 0
Training loss: 0.39591801166534424
Validation loss: 1.6988839539148475

Epoch: 5| Step: 1
Training loss: 0.7433391809463501
Validation loss: 1.7169451277743104

Epoch: 5| Step: 2
Training loss: 0.27325981855392456
Validation loss: 1.672658645978538

Epoch: 5| Step: 3
Training loss: 0.6968360543251038
Validation loss: 1.6336106984846053

Epoch: 5| Step: 4
Training loss: 0.45138654112815857
Validation loss: 1.6347607669009958

Epoch: 5| Step: 5
Training loss: 0.6168906092643738
Validation loss: 1.6443255421935872

Epoch: 5| Step: 6
Training loss: 0.6262756586074829
Validation loss: 1.655877249215239

Epoch: 5| Step: 7
Training loss: 0.6551797986030579
Validation loss: 1.6648876513204267

Epoch: 5| Step: 8
Training loss: 0.4089205265045166
Validation loss: 1.6740272275863155

Epoch: 5| Step: 9
Training loss: 0.37880805134773254
Validation loss: 1.6875518278409076

Epoch: 5| Step: 10
Training loss: 0.5474860072135925
Validation loss: 1.6925446038605065

Epoch: 370| Step: 0
Training loss: 0.660372257232666
Validation loss: 1.6719982290780673

Epoch: 5| Step: 1
Training loss: 0.39502885937690735
Validation loss: 1.6594332777043825

Epoch: 5| Step: 2
Training loss: 0.6007795333862305
Validation loss: 1.616109545512866

Epoch: 5| Step: 3
Training loss: 0.30541932582855225
Validation loss: 1.6248607994407736

Epoch: 5| Step: 4
Training loss: 0.45243096351623535
Validation loss: 1.5792079189772248

Epoch: 5| Step: 5
Training loss: 0.5821345448493958
Validation loss: 1.607424602713636

Epoch: 5| Step: 6
Training loss: 0.8394087553024292
Validation loss: 1.5848696167751024

Epoch: 5| Step: 7
Training loss: 0.48056966066360474
Validation loss: 1.6117387458842287

Epoch: 5| Step: 8
Training loss: 0.6739121675491333
Validation loss: 1.6847794107211533

Epoch: 5| Step: 9
Training loss: 0.5642683506011963
Validation loss: 1.7132274694340204

Epoch: 5| Step: 10
Training loss: 0.6524887084960938
Validation loss: 1.7151724253931353

Epoch: 371| Step: 0
Training loss: 0.4492563307285309
Validation loss: 1.6830263342908633

Epoch: 5| Step: 1
Training loss: 0.5447938442230225
Validation loss: 1.6336551558586858

Epoch: 5| Step: 2
Training loss: 0.8421038389205933
Validation loss: 1.6436493550577471

Epoch: 5| Step: 3
Training loss: 0.6728366613388062
Validation loss: 1.6345130916564696

Epoch: 5| Step: 4
Training loss: 0.7027851343154907
Validation loss: 1.6102161420288907

Epoch: 5| Step: 5
Training loss: 0.5227624177932739
Validation loss: 1.5834130151297456

Epoch: 5| Step: 6
Training loss: 0.3503411114215851
Validation loss: 1.6085240687093427

Epoch: 5| Step: 7
Training loss: 0.4463379979133606
Validation loss: 1.6429092332880983

Epoch: 5| Step: 8
Training loss: 0.43406814336776733
Validation loss: 1.6835484325244863

Epoch: 5| Step: 9
Training loss: 0.5347698330879211
Validation loss: 1.7038056555614676

Epoch: 5| Step: 10
Training loss: 0.4608941972255707
Validation loss: 1.7325367876278457

Epoch: 372| Step: 0
Training loss: 0.5968846678733826
Validation loss: 1.66705620801577

Epoch: 5| Step: 1
Training loss: 0.4887252748012543
Validation loss: 1.6066216281665269

Epoch: 5| Step: 2
Training loss: 0.5389198064804077
Validation loss: 1.6001723210016887

Epoch: 5| Step: 3
Training loss: 0.5280888676643372
Validation loss: 1.583517889822683

Epoch: 5| Step: 4
Training loss: 0.42908674478530884
Validation loss: 1.5906522209926317

Epoch: 5| Step: 5
Training loss: 0.5509042143821716
Validation loss: 1.601300016526253

Epoch: 5| Step: 6
Training loss: 0.5697349309921265
Validation loss: 1.6082188237097956

Epoch: 5| Step: 7
Training loss: 0.8434852361679077
Validation loss: 1.6224402599437262

Epoch: 5| Step: 8
Training loss: 0.5445994734764099
Validation loss: 1.6580200246585313

Epoch: 5| Step: 9
Training loss: 0.535888671875
Validation loss: 1.7101324591585385

Epoch: 5| Step: 10
Training loss: 0.38416364789009094
Validation loss: 1.7110509564799647

Epoch: 373| Step: 0
Training loss: 0.44947510957717896
Validation loss: 1.708714836387224

Epoch: 5| Step: 1
Training loss: 0.5418489575386047
Validation loss: 1.6738654631440357

Epoch: 5| Step: 2
Training loss: 0.39840254187583923
Validation loss: 1.635435168461133

Epoch: 5| Step: 3
Training loss: 0.6349148750305176
Validation loss: 1.6314372657447733

Epoch: 5| Step: 4
Training loss: 0.4391118586063385
Validation loss: 1.6360271617930422

Epoch: 5| Step: 5
Training loss: 0.6101438403129578
Validation loss: 1.634311406843124

Epoch: 5| Step: 6
Training loss: 0.44008001685142517
Validation loss: 1.6257384925760248

Epoch: 5| Step: 7
Training loss: 0.4302414357662201
Validation loss: 1.636422537988232

Epoch: 5| Step: 8
Training loss: 0.600517749786377
Validation loss: 1.6648066216899502

Epoch: 5| Step: 9
Training loss: 0.5723062753677368
Validation loss: 1.6762421900226223

Epoch: 5| Step: 10
Training loss: 0.7433878779411316
Validation loss: 1.6925637337469286

Epoch: 374| Step: 0
Training loss: 0.6419435739517212
Validation loss: 1.6586496278803835

Epoch: 5| Step: 1
Training loss: 0.4161376953125
Validation loss: 1.6468616006194905

Epoch: 5| Step: 2
Training loss: 0.35686197876930237
Validation loss: 1.6116715733722975

Epoch: 5| Step: 3
Training loss: 0.40559467673301697
Validation loss: 1.6004717042369228

Epoch: 5| Step: 4
Training loss: 0.392688125371933
Validation loss: 1.6044624236322218

Epoch: 5| Step: 5
Training loss: 0.5468544960021973
Validation loss: 1.6494086750092045

Epoch: 5| Step: 6
Training loss: 0.9671198725700378
Validation loss: 1.6363178299319359

Epoch: 5| Step: 7
Training loss: 0.5573204755783081
Validation loss: 1.6604494843431699

Epoch: 5| Step: 8
Training loss: 0.29730290174484253
Validation loss: 1.6451499398036669

Epoch: 5| Step: 9
Training loss: 0.3982992172241211
Validation loss: 1.6669714796927668

Epoch: 5| Step: 10
Training loss: 0.5296414494514465
Validation loss: 1.6452326082414197

Epoch: 375| Step: 0
Training loss: 0.5462387800216675
Validation loss: 1.6672443241201422

Epoch: 5| Step: 1
Training loss: 0.501674473285675
Validation loss: 1.660722501816288

Epoch: 5| Step: 2
Training loss: 0.590155303478241
Validation loss: 1.6695010418532996

Epoch: 5| Step: 3
Training loss: 0.5224651098251343
Validation loss: 1.621603831168144

Epoch: 5| Step: 4
Training loss: 0.45330172777175903
Validation loss: 1.6009585729209326

Epoch: 5| Step: 5
Training loss: 0.3287656307220459
Validation loss: 1.6235689847700057

Epoch: 5| Step: 6
Training loss: 0.5813449621200562
Validation loss: 1.634891583714434

Epoch: 5| Step: 7
Training loss: 0.29181987047195435
Validation loss: 1.6366333564122517

Epoch: 5| Step: 8
Training loss: 0.6684626936912537
Validation loss: 1.6457168415028562

Epoch: 5| Step: 9
Training loss: 0.46657198667526245
Validation loss: 1.6828646390668807

Epoch: 5| Step: 10
Training loss: 0.6008339524269104
Validation loss: 1.7358708625198693

Epoch: 376| Step: 0
Training loss: 0.4660056531429291
Validation loss: 1.7779575855501237

Epoch: 5| Step: 1
Training loss: 0.7020949125289917
Validation loss: 1.7625824969301942

Epoch: 5| Step: 2
Training loss: 0.4738301634788513
Validation loss: 1.7213500507416264

Epoch: 5| Step: 3
Training loss: 0.33123907446861267
Validation loss: 1.6754091426890383

Epoch: 5| Step: 4
Training loss: 0.48294147849082947
Validation loss: 1.6252516700375466

Epoch: 5| Step: 5
Training loss: 0.4499763548374176
Validation loss: 1.6138486990364649

Epoch: 5| Step: 6
Training loss: 0.6250340938568115
Validation loss: 1.6425598257331437

Epoch: 5| Step: 7
Training loss: 0.8681601285934448
Validation loss: 1.6322387277439077

Epoch: 5| Step: 8
Training loss: 0.33368343114852905
Validation loss: 1.6512986895858601

Epoch: 5| Step: 9
Training loss: 0.5869545936584473
Validation loss: 1.7231907844543457

Epoch: 5| Step: 10
Training loss: 0.5789752006530762
Validation loss: 1.7677635428726033

Epoch: 377| Step: 0
Training loss: 0.5685293674468994
Validation loss: 1.7803776751282394

Epoch: 5| Step: 1
Training loss: 1.0465114116668701
Validation loss: 1.7561754654812556

Epoch: 5| Step: 2
Training loss: 0.40168213844299316
Validation loss: 1.6922351878176454

Epoch: 5| Step: 3
Training loss: 0.43308180570602417
Validation loss: 1.6794798258812196

Epoch: 5| Step: 4
Training loss: 0.31585657596588135
Validation loss: 1.6492117758720153

Epoch: 5| Step: 5
Training loss: 0.5745909214019775
Validation loss: 1.6620239365485407

Epoch: 5| Step: 6
Training loss: 0.25885209441185
Validation loss: 1.6692155791867165

Epoch: 5| Step: 7
Training loss: 0.5584355592727661
Validation loss: 1.6866207648349065

Epoch: 5| Step: 8
Training loss: 0.6115787625312805
Validation loss: 1.7349071502685547

Epoch: 5| Step: 9
Training loss: 0.5287173986434937
Validation loss: 1.7079715805668985

Epoch: 5| Step: 10
Training loss: 0.433760404586792
Validation loss: 1.6724547801479217

Epoch: 378| Step: 0
Training loss: 0.447523832321167
Validation loss: 1.6244047021353116

Epoch: 5| Step: 1
Training loss: 0.5131412744522095
Validation loss: 1.6094714210879417

Epoch: 5| Step: 2
Training loss: 0.8642063140869141
Validation loss: 1.6249526136664934

Epoch: 5| Step: 3
Training loss: 0.4446171224117279
Validation loss: 1.6340655626789216

Epoch: 5| Step: 4
Training loss: 0.6253107190132141
Validation loss: 1.6440945312541018

Epoch: 5| Step: 5
Training loss: 0.6517394185066223
Validation loss: 1.655714810535472

Epoch: 5| Step: 6
Training loss: 0.25661391019821167
Validation loss: 1.6534983111966042

Epoch: 5| Step: 7
Training loss: 0.47327035665512085
Validation loss: 1.6442219852119364

Epoch: 5| Step: 8
Training loss: 0.3301471173763275
Validation loss: 1.6669792385511502

Epoch: 5| Step: 9
Training loss: 0.3613864481449127
Validation loss: 1.6802607479915823

Epoch: 5| Step: 10
Training loss: 0.40055161714553833
Validation loss: 1.7066238323847454

Epoch: 379| Step: 0
Training loss: 0.39109769463539124
Validation loss: 1.6841422024593558

Epoch: 5| Step: 1
Training loss: 0.46353036165237427
Validation loss: 1.6587028657236407

Epoch: 5| Step: 2
Training loss: 0.5481336712837219
Validation loss: 1.5949873424345447

Epoch: 5| Step: 3
Training loss: 0.6038259863853455
Validation loss: 1.5976483924414522

Epoch: 5| Step: 4
Training loss: 0.5584375262260437
Validation loss: 1.5903766180879326

Epoch: 5| Step: 5
Training loss: 0.8630039095878601
Validation loss: 1.6098124301561745

Epoch: 5| Step: 6
Training loss: 0.47064509987831116
Validation loss: 1.6022960242404733

Epoch: 5| Step: 7
Training loss: 0.5162636637687683
Validation loss: 1.6101026970853087

Epoch: 5| Step: 8
Training loss: 0.3655717968940735
Validation loss: 1.6509732200253395

Epoch: 5| Step: 9
Training loss: 0.5044847130775452
Validation loss: 1.7164148592179822

Epoch: 5| Step: 10
Training loss: 0.3444787263870239
Validation loss: 1.7419813935474684

Epoch: 380| Step: 0
Training loss: 0.5069757699966431
Validation loss: 1.7743623487411007

Epoch: 5| Step: 1
Training loss: 0.454420804977417
Validation loss: 1.7505859867219002

Epoch: 5| Step: 2
Training loss: 0.44138914346694946
Validation loss: 1.6811560123197493

Epoch: 5| Step: 3
Training loss: 0.5633863210678101
Validation loss: 1.6713671838083575

Epoch: 5| Step: 4
Training loss: 0.5162332057952881
Validation loss: 1.6524615518508419

Epoch: 5| Step: 5
Training loss: 0.574167013168335
Validation loss: 1.628429574351157

Epoch: 5| Step: 6
Training loss: 0.5012950897216797
Validation loss: 1.6418912564554522

Epoch: 5| Step: 7
Training loss: 0.4164394438266754
Validation loss: 1.6202893231504707

Epoch: 5| Step: 8
Training loss: 0.3196934163570404
Validation loss: 1.633711418797893

Epoch: 5| Step: 9
Training loss: 0.8845860362052917
Validation loss: 1.643733646280022

Epoch: 5| Step: 10
Training loss: 0.40305063128471375
Validation loss: 1.6426970035799089

Epoch: 381| Step: 0
Training loss: 0.712319552898407
Validation loss: 1.6258951976735105

Epoch: 5| Step: 1
Training loss: 0.35307788848876953
Validation loss: 1.6336928849579186

Epoch: 5| Step: 2
Training loss: 0.34420686960220337
Validation loss: 1.6491910373010943

Epoch: 5| Step: 3
Training loss: 0.4079194664955139
Validation loss: 1.655777579994612

Epoch: 5| Step: 4
Training loss: 0.6688359379768372
Validation loss: 1.6806986344757902

Epoch: 5| Step: 5
Training loss: 0.48406773805618286
Validation loss: 1.710305824074694

Epoch: 5| Step: 6
Training loss: 0.3805091381072998
Validation loss: 1.7429087572200324

Epoch: 5| Step: 7
Training loss: 0.20142678916454315
Validation loss: 1.727927871929702

Epoch: 5| Step: 8
Training loss: 0.6129477024078369
Validation loss: 1.7160376553894372

Epoch: 5| Step: 9
Training loss: 0.6221716403961182
Validation loss: 1.705707287275663

Epoch: 5| Step: 10
Training loss: 0.6802009344100952
Validation loss: 1.689716592911751

Epoch: 382| Step: 0
Training loss: 0.4991607069969177
Validation loss: 1.6980756610952399

Epoch: 5| Step: 1
Training loss: 0.7821658253669739
Validation loss: 1.664684473827321

Epoch: 5| Step: 2
Training loss: 0.46278858184814453
Validation loss: 1.657358297737696

Epoch: 5| Step: 3
Training loss: 0.4031417965888977
Validation loss: 1.6593529280795847

Epoch: 5| Step: 4
Training loss: 0.23733949661254883
Validation loss: 1.6497589067746234

Epoch: 5| Step: 5
Training loss: 0.2986671030521393
Validation loss: 1.6744254840317594

Epoch: 5| Step: 6
Training loss: 0.5018584728240967
Validation loss: 1.7114702527241041

Epoch: 5| Step: 7
Training loss: 0.38271254301071167
Validation loss: 1.7131919143020466

Epoch: 5| Step: 8
Training loss: 0.5659424662590027
Validation loss: 1.7104372247572868

Epoch: 5| Step: 9
Training loss: 0.5905517339706421
Validation loss: 1.6988469016167425

Epoch: 5| Step: 10
Training loss: 0.45830512046813965
Validation loss: 1.672512763289995

Epoch: 383| Step: 0
Training loss: 0.39156657457351685
Validation loss: 1.6517105281993907

Epoch: 5| Step: 1
Training loss: 0.32297688722610474
Validation loss: 1.6240681345744798

Epoch: 5| Step: 2
Training loss: 0.33868274092674255
Validation loss: 1.6306123220792381

Epoch: 5| Step: 3
Training loss: 0.37264102697372437
Validation loss: 1.624225652346047

Epoch: 5| Step: 4
Training loss: 0.4006168246269226
Validation loss: 1.6422776227356286

Epoch: 5| Step: 5
Training loss: 0.4755217432975769
Validation loss: 1.6393195749610983

Epoch: 5| Step: 6
Training loss: 0.3884207010269165
Validation loss: 1.6689118736533708

Epoch: 5| Step: 7
Training loss: 0.5440060496330261
Validation loss: 1.6973648173834688

Epoch: 5| Step: 8
Training loss: 0.6908539533615112
Validation loss: 1.6794245178981493

Epoch: 5| Step: 9
Training loss: 0.7081302404403687
Validation loss: 1.665000977054719

Epoch: 5| Step: 10
Training loss: 0.3454579710960388
Validation loss: 1.676323156202993

Epoch: 384| Step: 0
Training loss: 0.1843406707048416
Validation loss: 1.6357573283615934

Epoch: 5| Step: 1
Training loss: 0.4498705267906189
Validation loss: 1.6356324636808006

Epoch: 5| Step: 2
Training loss: 0.4766181409358978
Validation loss: 1.6383925842982467

Epoch: 5| Step: 3
Training loss: 0.605523407459259
Validation loss: 1.6550808888609692

Epoch: 5| Step: 4
Training loss: 0.47520914673805237
Validation loss: 1.6519836225817282

Epoch: 5| Step: 5
Training loss: 0.5615882277488708
Validation loss: 1.709491987382212

Epoch: 5| Step: 6
Training loss: 0.4444725513458252
Validation loss: 1.6851319382267613

Epoch: 5| Step: 7
Training loss: 0.3440466523170471
Validation loss: 1.6306167905048659

Epoch: 5| Step: 8
Training loss: 0.6595415472984314
Validation loss: 1.6189679522668161

Epoch: 5| Step: 9
Training loss: 0.6881164312362671
Validation loss: 1.615364969417613

Epoch: 5| Step: 10
Training loss: 0.32092928886413574
Validation loss: 1.6482701788666427

Epoch: 385| Step: 0
Training loss: 0.6357474327087402
Validation loss: 1.6398749005409978

Epoch: 5| Step: 1
Training loss: 0.4498887062072754
Validation loss: 1.6467418862927345

Epoch: 5| Step: 2
Training loss: 0.4808792173862457
Validation loss: 1.652508012710079

Epoch: 5| Step: 3
Training loss: 0.4853751063346863
Validation loss: 1.5932912852174492

Epoch: 5| Step: 4
Training loss: 0.390354722738266
Validation loss: 1.6136269146396267

Epoch: 5| Step: 5
Training loss: 0.44310569763183594
Validation loss: 1.6306265272119993

Epoch: 5| Step: 6
Training loss: 0.4687801003456116
Validation loss: 1.620642105738322

Epoch: 5| Step: 7
Training loss: 0.4195329248905182
Validation loss: 1.5966836015383403

Epoch: 5| Step: 8
Training loss: 0.5120474696159363
Validation loss: 1.6122508882194437

Epoch: 5| Step: 9
Training loss: 0.42557382583618164
Validation loss: 1.6240928455065655

Epoch: 5| Step: 10
Training loss: 0.4439390301704407
Validation loss: 1.659025337106438

Epoch: 386| Step: 0
Training loss: 0.3968666195869446
Validation loss: 1.7076551170759304

Epoch: 5| Step: 1
Training loss: 0.3090711236000061
Validation loss: 1.7319286523326751

Epoch: 5| Step: 2
Training loss: 0.47167477011680603
Validation loss: 1.7081688020818977

Epoch: 5| Step: 3
Training loss: 0.2586102783679962
Validation loss: 1.6590408343140797

Epoch: 5| Step: 4
Training loss: 0.5698053240776062
Validation loss: 1.6627892140419251

Epoch: 5| Step: 5
Training loss: 0.7766193151473999
Validation loss: 1.6559329455898655

Epoch: 5| Step: 6
Training loss: 0.4366208612918854
Validation loss: 1.6699866389715543

Epoch: 5| Step: 7
Training loss: 0.4867119789123535
Validation loss: 1.672528402779692

Epoch: 5| Step: 8
Training loss: 0.6594274640083313
Validation loss: 1.6734410357731644

Epoch: 5| Step: 9
Training loss: 0.24480703473091125
Validation loss: 1.653240446121462

Epoch: 5| Step: 10
Training loss: 0.3180490732192993
Validation loss: 1.6725348118812806

Epoch: 387| Step: 0
Training loss: 0.5603121519088745
Validation loss: 1.7027813247455064

Epoch: 5| Step: 1
Training loss: 0.3912509083747864
Validation loss: 1.6774172090714978

Epoch: 5| Step: 2
Training loss: 0.38386741280555725
Validation loss: 1.633885883515881

Epoch: 5| Step: 3
Training loss: 0.3053990304470062
Validation loss: 1.6380228816822011

Epoch: 5| Step: 4
Training loss: 0.3520579934120178
Validation loss: 1.6415521585813133

Epoch: 5| Step: 5
Training loss: 0.43740859627723694
Validation loss: 1.6631666973072996

Epoch: 5| Step: 6
Training loss: 0.3674614727497101
Validation loss: 1.7092178201162687

Epoch: 5| Step: 7
Training loss: 0.6453741192817688
Validation loss: 1.6711922230259064

Epoch: 5| Step: 8
Training loss: 0.18772265315055847
Validation loss: 1.6548939135766798

Epoch: 5| Step: 9
Training loss: 0.7299847602844238
Validation loss: 1.657332694658669

Epoch: 5| Step: 10
Training loss: 0.47548338770866394
Validation loss: 1.6518186830705213

Epoch: 388| Step: 0
Training loss: 0.35819947719573975
Validation loss: 1.6485807113750006

Epoch: 5| Step: 1
Training loss: 0.40482258796691895
Validation loss: 1.653546820404709

Epoch: 5| Step: 2
Training loss: 0.34064310789108276
Validation loss: 1.6587373543811101

Epoch: 5| Step: 3
Training loss: 0.33653193712234497
Validation loss: 1.685957638166284

Epoch: 5| Step: 4
Training loss: 0.41398176550865173
Validation loss: 1.6981985517727431

Epoch: 5| Step: 5
Training loss: 0.7309406995773315
Validation loss: 1.6836079346236361

Epoch: 5| Step: 6
Training loss: 0.49977535009384155
Validation loss: 1.7039671662033244

Epoch: 5| Step: 7
Training loss: 0.3587193191051483
Validation loss: 1.6924599588558238

Epoch: 5| Step: 8
Training loss: 0.4932442605495453
Validation loss: 1.7090994914372761

Epoch: 5| Step: 9
Training loss: 0.6200581192970276
Validation loss: 1.6837470531463623

Epoch: 5| Step: 10
Training loss: 0.3492789566516876
Validation loss: 1.6669593370088966

Epoch: 389| Step: 0
Training loss: 0.4009835124015808
Validation loss: 1.6448800076720536

Epoch: 5| Step: 1
Training loss: 0.42228689789772034
Validation loss: 1.6687805639800204

Epoch: 5| Step: 2
Training loss: 0.42534008622169495
Validation loss: 1.6692359524388467

Epoch: 5| Step: 3
Training loss: 0.5493731498718262
Validation loss: 1.6576177368881881

Epoch: 5| Step: 4
Training loss: 0.38070759177207947
Validation loss: 1.6406700662387315

Epoch: 5| Step: 5
Training loss: 0.5829038023948669
Validation loss: 1.647634519043789

Epoch: 5| Step: 6
Training loss: 0.3618527054786682
Validation loss: 1.6268608185552782

Epoch: 5| Step: 7
Training loss: 0.37593895196914673
Validation loss: 1.6022846480851531

Epoch: 5| Step: 8
Training loss: 0.6690975427627563
Validation loss: 1.619127929851573

Epoch: 5| Step: 9
Training loss: 0.31089892983436584
Validation loss: 1.6307787420929118

Epoch: 5| Step: 10
Training loss: 0.3104424774646759
Validation loss: 1.6470757645945395

Epoch: 390| Step: 0
Training loss: 0.36580148339271545
Validation loss: 1.6382804596295921

Epoch: 5| Step: 1
Training loss: 0.36187517642974854
Validation loss: 1.6277265317978398

Epoch: 5| Step: 2
Training loss: 0.4957403540611267
Validation loss: 1.6555233322164065

Epoch: 5| Step: 3
Training loss: 0.3999131917953491
Validation loss: 1.6527751363733763

Epoch: 5| Step: 4
Training loss: 0.4839448928833008
Validation loss: 1.6705660204733572

Epoch: 5| Step: 5
Training loss: 0.3215830326080322
Validation loss: 1.6778682111411967

Epoch: 5| Step: 6
Training loss: 0.617174506187439
Validation loss: 1.6557427696002427

Epoch: 5| Step: 7
Training loss: 0.5525890588760376
Validation loss: 1.6552156427855134

Epoch: 5| Step: 8
Training loss: 0.38037508726119995
Validation loss: 1.6385961450556272

Epoch: 5| Step: 9
Training loss: 0.4741494059562683
Validation loss: 1.6360444894400976

Epoch: 5| Step: 10
Training loss: 0.27807551622390747
Validation loss: 1.6401997215004378

Epoch: 391| Step: 0
Training loss: 0.3928240239620209
Validation loss: 1.6349279701068837

Epoch: 5| Step: 1
Training loss: 0.33839550614356995
Validation loss: 1.6524926154844222

Epoch: 5| Step: 2
Training loss: 0.5078171491622925
Validation loss: 1.634718164320915

Epoch: 5| Step: 3
Training loss: 0.33875903487205505
Validation loss: 1.6390074209500385

Epoch: 5| Step: 4
Training loss: 0.34093230962753296
Validation loss: 1.6563530532262658

Epoch: 5| Step: 5
Training loss: 0.20195579528808594
Validation loss: 1.6442955193981048

Epoch: 5| Step: 6
Training loss: 0.8457096219062805
Validation loss: 1.6339450420871857

Epoch: 5| Step: 7
Training loss: 0.4996151924133301
Validation loss: 1.6264436398783038

Epoch: 5| Step: 8
Training loss: 0.41858553886413574
Validation loss: 1.645398828932034

Epoch: 5| Step: 9
Training loss: 0.3943319022655487
Validation loss: 1.651880362982391

Epoch: 5| Step: 10
Training loss: 0.3718484342098236
Validation loss: 1.6658248363002655

Epoch: 392| Step: 0
Training loss: 0.4852670729160309
Validation loss: 1.6806215688746462

Epoch: 5| Step: 1
Training loss: 0.2133609503507614
Validation loss: 1.7151887724476476

Epoch: 5| Step: 2
Training loss: 0.37591710686683655
Validation loss: 1.7432612885711014

Epoch: 5| Step: 3
Training loss: 0.3921164870262146
Validation loss: 1.7063559473201793

Epoch: 5| Step: 4
Training loss: 0.2834377884864807
Validation loss: 1.6579821673772668

Epoch: 5| Step: 5
Training loss: 0.47791367769241333
Validation loss: 1.641053694550709

Epoch: 5| Step: 6
Training loss: 0.3470720052719116
Validation loss: 1.649315022653149

Epoch: 5| Step: 7
Training loss: 0.4376160204410553
Validation loss: 1.6479240963535924

Epoch: 5| Step: 8
Training loss: 0.5422924160957336
Validation loss: 1.6497754050839333

Epoch: 5| Step: 9
Training loss: 0.3788999915122986
Validation loss: 1.6329974384718045

Epoch: 5| Step: 10
Training loss: 0.5245048403739929
Validation loss: 1.6526627681588615

Epoch: 393| Step: 0
Training loss: 0.3276410698890686
Validation loss: 1.6269398575188012

Epoch: 5| Step: 1
Training loss: 0.3716103434562683
Validation loss: 1.624830170344281

Epoch: 5| Step: 2
Training loss: 0.3071824014186859
Validation loss: 1.6329811965265582

Epoch: 5| Step: 3
Training loss: 0.1453491896390915
Validation loss: 1.6286694401053972

Epoch: 5| Step: 4
Training loss: 0.5560551881790161
Validation loss: 1.6273615872988136

Epoch: 5| Step: 5
Training loss: 0.33891454339027405
Validation loss: 1.6371018989111787

Epoch: 5| Step: 6
Training loss: 0.21849629282951355
Validation loss: 1.6512848997628817

Epoch: 5| Step: 7
Training loss: 0.5013915300369263
Validation loss: 1.647115925306915

Epoch: 5| Step: 8
Training loss: 0.6518592834472656
Validation loss: 1.6422531886767315

Epoch: 5| Step: 9
Training loss: 0.51059889793396
Validation loss: 1.6542783783328148

Epoch: 5| Step: 10
Training loss: 0.4612795114517212
Validation loss: 1.6365245849855485

Epoch: 394| Step: 0
Training loss: 0.3701213598251343
Validation loss: 1.660204764335386

Epoch: 5| Step: 1
Training loss: 0.5030576586723328
Validation loss: 1.6957256345338718

Epoch: 5| Step: 2
Training loss: 0.4146840572357178
Validation loss: 1.7246768756579327

Epoch: 5| Step: 3
Training loss: 0.5657781362533569
Validation loss: 1.7606223475548528

Epoch: 5| Step: 4
Training loss: 0.40866619348526
Validation loss: 1.8020775036145282

Epoch: 5| Step: 5
Training loss: 0.4084894061088562
Validation loss: 1.734445975672814

Epoch: 5| Step: 6
Training loss: 0.4937489926815033
Validation loss: 1.6769145765612203

Epoch: 5| Step: 7
Training loss: 0.3369905948638916
Validation loss: 1.6641513224570983

Epoch: 5| Step: 8
Training loss: 0.4365948736667633
Validation loss: 1.6306716652326687

Epoch: 5| Step: 9
Training loss: 0.10974059998989105
Validation loss: 1.6171018103117585

Epoch: 5| Step: 10
Training loss: 0.5450115203857422
Validation loss: 1.6071550333371727

Epoch: 395| Step: 0
Training loss: 0.3693763017654419
Validation loss: 1.6132640248985701

Epoch: 5| Step: 1
Training loss: 0.5072528719902039
Validation loss: 1.6222732682381906

Epoch: 5| Step: 2
Training loss: 0.6312265396118164
Validation loss: 1.6277146659871584

Epoch: 5| Step: 3
Training loss: 0.3352733254432678
Validation loss: 1.622569038021949

Epoch: 5| Step: 4
Training loss: 0.240940660238266
Validation loss: 1.626011303676072

Epoch: 5| Step: 5
Training loss: 0.33114510774612427
Validation loss: 1.6171884216288084

Epoch: 5| Step: 6
Training loss: 0.476911723613739
Validation loss: 1.615348926154516

Epoch: 5| Step: 7
Training loss: 0.3004578649997711
Validation loss: 1.642271186715813

Epoch: 5| Step: 8
Training loss: 0.6016397476196289
Validation loss: 1.6722392318069295

Epoch: 5| Step: 9
Training loss: 0.3285995125770569
Validation loss: 1.6662871747888544

Epoch: 5| Step: 10
Training loss: 0.35634368658065796
Validation loss: 1.6920390564908263

Epoch: 396| Step: 0
Training loss: 0.5234470963478088
Validation loss: 1.676324103468208

Epoch: 5| Step: 1
Training loss: 0.3567151427268982
Validation loss: 1.6350966499697777

Epoch: 5| Step: 2
Training loss: 0.45872145891189575
Validation loss: 1.6000297338731828

Epoch: 5| Step: 3
Training loss: 0.611487090587616
Validation loss: 1.6133354453630344

Epoch: 5| Step: 4
Training loss: 0.3490765690803528
Validation loss: 1.5722936866103963

Epoch: 5| Step: 5
Training loss: 0.21525487303733826
Validation loss: 1.580710208544167

Epoch: 5| Step: 6
Training loss: 0.3247062563896179
Validation loss: 1.5827755017947125

Epoch: 5| Step: 7
Training loss: 0.2476322203874588
Validation loss: 1.6155551556617982

Epoch: 5| Step: 8
Training loss: 0.3093833327293396
Validation loss: 1.6471777013553086

Epoch: 5| Step: 9
Training loss: 0.47444087266921997
Validation loss: 1.671536353967523

Epoch: 5| Step: 10
Training loss: 0.4485057592391968
Validation loss: 1.6359923565259544

Epoch: 397| Step: 0
Training loss: 0.39612603187561035
Validation loss: 1.6208189584875619

Epoch: 5| Step: 1
Training loss: 0.3054478168487549
Validation loss: 1.6211566963503439

Epoch: 5| Step: 2
Training loss: 0.3177061975002289
Validation loss: 1.6214658201381724

Epoch: 5| Step: 3
Training loss: 0.2637944221496582
Validation loss: 1.6043924875156854

Epoch: 5| Step: 4
Training loss: 0.6234896779060364
Validation loss: 1.6157566565339283

Epoch: 5| Step: 5
Training loss: 0.45963525772094727
Validation loss: 1.6055467538936163

Epoch: 5| Step: 6
Training loss: 0.4820718765258789
Validation loss: 1.6125630678669098

Epoch: 5| Step: 7
Training loss: 0.3299344480037689
Validation loss: 1.649520529213772

Epoch: 5| Step: 8
Training loss: 0.30418938398361206
Validation loss: 1.648309491013968

Epoch: 5| Step: 9
Training loss: 0.40239301323890686
Validation loss: 1.6644001801808674

Epoch: 5| Step: 10
Training loss: 0.32709527015686035
Validation loss: 1.66867660450679

Epoch: 398| Step: 0
Training loss: 0.27579548954963684
Validation loss: 1.6365086019680064

Epoch: 5| Step: 1
Training loss: 0.4845479130744934
Validation loss: 1.6250136238272472

Epoch: 5| Step: 2
Training loss: 0.2997444272041321
Validation loss: 1.597116765155587

Epoch: 5| Step: 3
Training loss: 0.35994046926498413
Validation loss: 1.5999455785238614

Epoch: 5| Step: 4
Training loss: 0.622380793094635
Validation loss: 1.5765579785070112

Epoch: 5| Step: 5
Training loss: 0.1225360855460167
Validation loss: 1.5836519791233925

Epoch: 5| Step: 6
Training loss: 0.47207874059677124
Validation loss: 1.6042770262687438

Epoch: 5| Step: 7
Training loss: 0.5150133967399597
Validation loss: 1.6338662716650194

Epoch: 5| Step: 8
Training loss: 0.4993709921836853
Validation loss: 1.7031553470960228

Epoch: 5| Step: 9
Training loss: 0.27764663100242615
Validation loss: 1.6747117503996818

Epoch: 5| Step: 10
Training loss: 0.5377289056777954
Validation loss: 1.6182879517155309

Epoch: 399| Step: 0
Training loss: 0.3902949392795563
Validation loss: 1.594238228695367

Epoch: 5| Step: 1
Training loss: 0.40278738737106323
Validation loss: 1.5928011978826215

Epoch: 5| Step: 2
Training loss: 0.3340183198451996
Validation loss: 1.5888844741288053

Epoch: 5| Step: 3
Training loss: 0.26092132925987244
Validation loss: 1.5900777591172086

Epoch: 5| Step: 4
Training loss: 0.30448421835899353
Validation loss: 1.6030295330991027

Epoch: 5| Step: 5
Training loss: 0.26741498708724976
Validation loss: 1.592786536421827

Epoch: 5| Step: 6
Training loss: 0.6235007047653198
Validation loss: 1.6154383023579915

Epoch: 5| Step: 7
Training loss: 0.4019436836242676
Validation loss: 1.6259035359146774

Epoch: 5| Step: 8
Training loss: 0.41791027784347534
Validation loss: 1.6164003700338385

Epoch: 5| Step: 9
Training loss: 0.3514164090156555
Validation loss: 1.6252778601902786

Epoch: 5| Step: 10
Training loss: 0.49721628427505493
Validation loss: 1.618105193620087

Epoch: 400| Step: 0
Training loss: 0.28007811307907104
Validation loss: 1.639135314572242

Epoch: 5| Step: 1
Training loss: 0.4462265968322754
Validation loss: 1.6435093238789549

Epoch: 5| Step: 2
Training loss: 0.45164185762405396
Validation loss: 1.6391538573849587

Epoch: 5| Step: 3
Training loss: 0.2862025797367096
Validation loss: 1.6185695599484187

Epoch: 5| Step: 4
Training loss: 0.2875157296657562
Validation loss: 1.615106769787368

Epoch: 5| Step: 5
Training loss: 0.526017963886261
Validation loss: 1.622163116291005

Epoch: 5| Step: 6
Training loss: 0.4421171545982361
Validation loss: 1.615826177340682

Epoch: 5| Step: 7
Training loss: 0.27758195996284485
Validation loss: 1.6016573418853104

Epoch: 5| Step: 8
Training loss: 0.6123948693275452
Validation loss: 1.624498535228032

Epoch: 5| Step: 9
Training loss: 0.31507474184036255
Validation loss: 1.6155363539213776

Epoch: 5| Step: 10
Training loss: 0.36559394001960754
Validation loss: 1.6627358454529957

Epoch: 401| Step: 0
Training loss: 0.18689218163490295
Validation loss: 1.6710630052833146

Epoch: 5| Step: 1
Training loss: 0.5179447531700134
Validation loss: 1.6540808331581853

Epoch: 5| Step: 2
Training loss: 0.48867231607437134
Validation loss: 1.6200299198909471

Epoch: 5| Step: 3
Training loss: 0.34279900789260864
Validation loss: 1.630667027606759

Epoch: 5| Step: 4
Training loss: 0.2314838469028473
Validation loss: 1.6244292451489357

Epoch: 5| Step: 5
Training loss: 0.6707690954208374
Validation loss: 1.6272189155701668

Epoch: 5| Step: 6
Training loss: 0.42203488945961
Validation loss: 1.6471202078685965

Epoch: 5| Step: 7
Training loss: 0.3456045985221863
Validation loss: 1.652856303799537

Epoch: 5| Step: 8
Training loss: 0.51591557264328
Validation loss: 1.6440373595042894

Epoch: 5| Step: 9
Training loss: 0.32110828161239624
Validation loss: 1.6298714222446564

Epoch: 5| Step: 10
Training loss: 0.26228857040405273
Validation loss: 1.6117009937122304

Epoch: 402| Step: 0
Training loss: 0.3875783085823059
Validation loss: 1.6055977921332083

Epoch: 5| Step: 1
Training loss: 0.2946001887321472
Validation loss: 1.602170705795288

Epoch: 5| Step: 2
Training loss: 0.4362970292568207
Validation loss: 1.6198547963173158

Epoch: 5| Step: 3
Training loss: 0.2878759503364563
Validation loss: 1.6259338086651218

Epoch: 5| Step: 4
Training loss: 0.4840736389160156
Validation loss: 1.633827155636203

Epoch: 5| Step: 5
Training loss: 0.43774542212486267
Validation loss: 1.6574002337712113

Epoch: 5| Step: 6
Training loss: 0.27158427238464355
Validation loss: 1.6369762689836564

Epoch: 5| Step: 7
Training loss: 0.34353289008140564
Validation loss: 1.627727372671968

Epoch: 5| Step: 8
Training loss: 0.466761976480484
Validation loss: 1.6387605923478321

Epoch: 5| Step: 9
Training loss: 0.5494055151939392
Validation loss: 1.6374691173594484

Epoch: 5| Step: 10
Training loss: 0.25620031356811523
Validation loss: 1.6363146458902667

Epoch: 403| Step: 0
Training loss: 0.5436205863952637
Validation loss: 1.6906918876914567

Epoch: 5| Step: 1
Training loss: 0.3631470203399658
Validation loss: 1.6604256373579784

Epoch: 5| Step: 2
Training loss: 0.3997136950492859
Validation loss: 1.7062547745243195

Epoch: 5| Step: 3
Training loss: 0.19561561942100525
Validation loss: 1.6474190219756095

Epoch: 5| Step: 4
Training loss: 0.2424018830060959
Validation loss: 1.6397087215095438

Epoch: 5| Step: 5
Training loss: 0.4678865075111389
Validation loss: 1.602368616288708

Epoch: 5| Step: 6
Training loss: 0.2213972508907318
Validation loss: 1.590681295241079

Epoch: 5| Step: 7
Training loss: 0.3597026467323303
Validation loss: 1.5718874399380018

Epoch: 5| Step: 8
Training loss: 0.4284968972206116
Validation loss: 1.5747933823575255

Epoch: 5| Step: 9
Training loss: 0.49964386224746704
Validation loss: 1.5891589041679137

Epoch: 5| Step: 10
Training loss: 0.5023710131645203
Validation loss: 1.6109978639951317

Epoch: 404| Step: 0
Training loss: 0.3657238483428955
Validation loss: 1.6206892523714291

Epoch: 5| Step: 1
Training loss: 0.34819430112838745
Validation loss: 1.6236475795827887

Epoch: 5| Step: 2
Training loss: 0.38069477677345276
Validation loss: 1.6766027929962322

Epoch: 5| Step: 3
Training loss: 0.4255011975765228
Validation loss: 1.6588838254251788

Epoch: 5| Step: 4
Training loss: 0.28238359093666077
Validation loss: 1.6456792418674757

Epoch: 5| Step: 5
Training loss: 0.46608424186706543
Validation loss: 1.6138892019948652

Epoch: 5| Step: 6
Training loss: 0.3354915976524353
Validation loss: 1.6289012380825576

Epoch: 5| Step: 7
Training loss: 0.2925706207752228
Validation loss: 1.621656383237531

Epoch: 5| Step: 8
Training loss: 0.3322499692440033
Validation loss: 1.622212565073403

Epoch: 5| Step: 9
Training loss: 0.2684749960899353
Validation loss: 1.6069600684668428

Epoch: 5| Step: 10
Training loss: 0.7089083790779114
Validation loss: 1.6196441112026092

Epoch: 405| Step: 0
Training loss: 0.6214157938957214
Validation loss: 1.597217954615111

Epoch: 5| Step: 1
Training loss: 0.2234162986278534
Validation loss: 1.5982625663921397

Epoch: 5| Step: 2
Training loss: 0.29971566796302795
Validation loss: 1.6054938108690324

Epoch: 5| Step: 3
Training loss: 0.25548720359802246
Validation loss: 1.5944888296947684

Epoch: 5| Step: 4
Training loss: 0.30730193853378296
Validation loss: 1.567639099654331

Epoch: 5| Step: 5
Training loss: 0.40029945969581604
Validation loss: 1.5896323675750403

Epoch: 5| Step: 6
Training loss: 0.3376128375530243
Validation loss: 1.5717267990112305

Epoch: 5| Step: 7
Training loss: 0.3568015396595001
Validation loss: 1.5758951197388351

Epoch: 5| Step: 8
Training loss: 0.5345475077629089
Validation loss: 1.56101272695808

Epoch: 5| Step: 9
Training loss: 0.3139621317386627
Validation loss: 1.577534398724956

Epoch: 5| Step: 10
Training loss: 0.4170113503932953
Validation loss: 1.5697771285169868

Epoch: 406| Step: 0
Training loss: 0.2481028139591217
Validation loss: 1.5634769444824548

Epoch: 5| Step: 1
Training loss: 0.30422818660736084
Validation loss: 1.5705748988736061

Epoch: 5| Step: 2
Training loss: 0.23640041053295135
Validation loss: 1.5499427985119563

Epoch: 5| Step: 3
Training loss: 0.3572763204574585
Validation loss: 1.598664838780639

Epoch: 5| Step: 4
Training loss: 0.4622679650783539
Validation loss: 1.5921857075024677

Epoch: 5| Step: 5
Training loss: 0.28519105911254883
Validation loss: 1.5988124865357594

Epoch: 5| Step: 6
Training loss: 0.49783071875572205
Validation loss: 1.6063671618379571

Epoch: 5| Step: 7
Training loss: 0.4837791919708252
Validation loss: 1.6218561921068417

Epoch: 5| Step: 8
Training loss: 0.6103634834289551
Validation loss: 1.6198012200734948

Epoch: 5| Step: 9
Training loss: 0.19863297045230865
Validation loss: 1.6281633812894103

Epoch: 5| Step: 10
Training loss: 0.5614564418792725
Validation loss: 1.6365779240926106

Epoch: 407| Step: 0
Training loss: 0.18729206919670105
Validation loss: 1.6009035187382852

Epoch: 5| Step: 1
Training loss: 0.5183753371238708
Validation loss: 1.614029046027891

Epoch: 5| Step: 2
Training loss: 0.30620142817497253
Validation loss: 1.6679437903947727

Epoch: 5| Step: 3
Training loss: 0.40480923652648926
Validation loss: 1.6559846260214364

Epoch: 5| Step: 4
Training loss: 0.21944451332092285
Validation loss: 1.6297623239537722

Epoch: 5| Step: 5
Training loss: 0.3742617964744568
Validation loss: 1.6341207335072179

Epoch: 5| Step: 6
Training loss: 0.41100579500198364
Validation loss: 1.6018661247786654

Epoch: 5| Step: 7
Training loss: 0.4394497275352478
Validation loss: 1.5617187907618861

Epoch: 5| Step: 8
Training loss: 0.5332577228546143
Validation loss: 1.56687960573422

Epoch: 5| Step: 9
Training loss: 0.3627621829509735
Validation loss: 1.5516253658520278

Epoch: 5| Step: 10
Training loss: 0.36844760179519653
Validation loss: 1.5486476664902062

Epoch: 408| Step: 0
Training loss: 0.35860034823417664
Validation loss: 1.5798365326337918

Epoch: 5| Step: 1
Training loss: 0.3877982497215271
Validation loss: 1.5741660902577062

Epoch: 5| Step: 2
Training loss: 0.5750114917755127
Validation loss: 1.6146393450357581

Epoch: 5| Step: 3
Training loss: 0.3152680993080139
Validation loss: 1.6008008333944506

Epoch: 5| Step: 4
Training loss: 0.3414398729801178
Validation loss: 1.5903641485398816

Epoch: 5| Step: 5
Training loss: 0.30578240752220154
Validation loss: 1.60912993133709

Epoch: 5| Step: 6
Training loss: 0.3057937026023865
Validation loss: 1.6379865215670677

Epoch: 5| Step: 7
Training loss: 0.47203636169433594
Validation loss: 1.6643669528345908

Epoch: 5| Step: 8
Training loss: 0.6081217527389526
Validation loss: 1.6703373462923112

Epoch: 5| Step: 9
Training loss: 0.3893772065639496
Validation loss: 1.6459619832295243

Epoch: 5| Step: 10
Training loss: 0.3069363236427307
Validation loss: 1.6297830112518803

Epoch: 409| Step: 0
Training loss: 0.3739055097103119
Validation loss: 1.6235456620493243

Epoch: 5| Step: 1
Training loss: 0.3569754958152771
Validation loss: 1.6522613494626937

Epoch: 5| Step: 2
Training loss: 0.2693738639354706
Validation loss: 1.6303989759055517

Epoch: 5| Step: 3
Training loss: 0.31689220666885376
Validation loss: 1.659474411318379

Epoch: 5| Step: 4
Training loss: 0.36223769187927246
Validation loss: 1.6413521625662362

Epoch: 5| Step: 5
Training loss: 0.35150957107543945
Validation loss: 1.6287289870682584

Epoch: 5| Step: 6
Training loss: 0.3448256850242615
Validation loss: 1.6198589532606062

Epoch: 5| Step: 7
Training loss: 0.4426356256008148
Validation loss: 1.6054493586222331

Epoch: 5| Step: 8
Training loss: 0.4513493478298187
Validation loss: 1.5770972377510482

Epoch: 5| Step: 9
Training loss: 0.5011347532272339
Validation loss: 1.5834316194698375

Epoch: 5| Step: 10
Training loss: 0.23258984088897705
Validation loss: 1.6063226781865603

Epoch: 410| Step: 0
Training loss: 0.21092119812965393
Validation loss: 1.6529452800750732

Epoch: 5| Step: 1
Training loss: 0.31267601251602173
Validation loss: 1.6791881662543102

Epoch: 5| Step: 2
Training loss: 0.3586200773715973
Validation loss: 1.6822363766290809

Epoch: 5| Step: 3
Training loss: 0.3385181128978729
Validation loss: 1.6820327530625045

Epoch: 5| Step: 4
Training loss: 0.4005917012691498
Validation loss: 1.6494535861476776

Epoch: 5| Step: 5
Training loss: 0.34430623054504395
Validation loss: 1.5749032920406711

Epoch: 5| Step: 6
Training loss: 0.3500841557979584
Validation loss: 1.5529438603308894

Epoch: 5| Step: 7
Training loss: 0.3493386209011078
Validation loss: 1.5639945127630746

Epoch: 5| Step: 8
Training loss: 0.4331362843513489
Validation loss: 1.5612827834262644

Epoch: 5| Step: 9
Training loss: 0.44321221113204956
Validation loss: 1.5603926758612356

Epoch: 5| Step: 10
Training loss: 0.5951895713806152
Validation loss: 1.5814048205652544

Epoch: 411| Step: 0
Training loss: 0.3110582232475281
Validation loss: 1.6065598982636646

Epoch: 5| Step: 1
Training loss: 0.5877987146377563
Validation loss: 1.6021788671452513

Epoch: 5| Step: 2
Training loss: 0.3419126272201538
Validation loss: 1.6642515659332275

Epoch: 5| Step: 3
Training loss: 0.26160863041877747
Validation loss: 1.6477933468357209

Epoch: 5| Step: 4
Training loss: 0.3559516966342926
Validation loss: 1.6554043075089813

Epoch: 5| Step: 5
Training loss: 0.3007839620113373
Validation loss: 1.6232086625150455

Epoch: 5| Step: 6
Training loss: 0.40219563245773315
Validation loss: 1.62164459946335

Epoch: 5| Step: 7
Training loss: 0.6169928312301636
Validation loss: 1.6292648661521174

Epoch: 5| Step: 8
Training loss: 0.576731264591217
Validation loss: 1.6490684478513655

Epoch: 5| Step: 9
Training loss: 0.21406793594360352
Validation loss: 1.6960850018326954

Epoch: 5| Step: 10
Training loss: 0.28268444538116455
Validation loss: 1.68566721100961

Epoch: 412| Step: 0
Training loss: 0.22297248244285583
Validation loss: 1.687823082811089

Epoch: 5| Step: 1
Training loss: 0.6336574554443359
Validation loss: 1.6839474183256908

Epoch: 5| Step: 2
Training loss: 0.41690587997436523
Validation loss: 1.6534665041072394

Epoch: 5| Step: 3
Training loss: 0.2647647559642792
Validation loss: 1.6300776722610637

Epoch: 5| Step: 4
Training loss: 0.3307117521762848
Validation loss: 1.616665864503512

Epoch: 5| Step: 5
Training loss: 0.18269817531108856
Validation loss: 1.6324372778656662

Epoch: 5| Step: 6
Training loss: 0.7197640538215637
Validation loss: 1.598831707431424

Epoch: 5| Step: 7
Training loss: 0.2758985757827759
Validation loss: 1.5918474607570197

Epoch: 5| Step: 8
Training loss: 0.3377230763435364
Validation loss: 1.5696558567785448

Epoch: 5| Step: 9
Training loss: 0.2923136353492737
Validation loss: 1.5869920292208273

Epoch: 5| Step: 10
Training loss: 0.15318533778190613
Validation loss: 1.5791524161574662

Epoch: 413| Step: 0
Training loss: 0.5122852325439453
Validation loss: 1.5814318618466776

Epoch: 5| Step: 1
Training loss: 0.32516390085220337
Validation loss: 1.6010532725241877

Epoch: 5| Step: 2
Training loss: 0.27579474449157715
Validation loss: 1.5909466897287676

Epoch: 5| Step: 3
Training loss: 0.39252349734306335
Validation loss: 1.5928360339133971

Epoch: 5| Step: 4
Training loss: 0.3239452838897705
Validation loss: 1.5662385597023913

Epoch: 5| Step: 5
Training loss: 0.1783599853515625
Validation loss: 1.6024766096504786

Epoch: 5| Step: 6
Training loss: 0.44132328033447266
Validation loss: 1.606013221125449

Epoch: 5| Step: 7
Training loss: 0.3519478440284729
Validation loss: 1.5924754860580608

Epoch: 5| Step: 8
Training loss: 0.1424696445465088
Validation loss: 1.645739600222598

Epoch: 5| Step: 9
Training loss: 0.2935085892677307
Validation loss: 1.690114172556067

Epoch: 5| Step: 10
Training loss: 0.40047934651374817
Validation loss: 1.7188853961165234

Epoch: 414| Step: 0
Training loss: 0.343293160200119
Validation loss: 1.675194469831323

Epoch: 5| Step: 1
Training loss: 0.5543286204338074
Validation loss: 1.6255715777797084

Epoch: 5| Step: 2
Training loss: 0.30907946825027466
Validation loss: 1.61392298693298

Epoch: 5| Step: 3
Training loss: 0.13283753395080566
Validation loss: 1.6226231577575847

Epoch: 5| Step: 4
Training loss: 0.3179846405982971
Validation loss: 1.6144864610446397

Epoch: 5| Step: 5
Training loss: 0.5639989972114563
Validation loss: 1.6489891788010955

Epoch: 5| Step: 6
Training loss: 0.2995789349079132
Validation loss: 1.6374975289067915

Epoch: 5| Step: 7
Training loss: 0.3482831120491028
Validation loss: 1.6320354143778484

Epoch: 5| Step: 8
Training loss: 0.38484877347946167
Validation loss: 1.6221152851658482

Epoch: 5| Step: 9
Training loss: 0.3357534110546112
Validation loss: 1.6108641060449744

Epoch: 5| Step: 10
Training loss: 0.3041577935218811
Validation loss: 1.623782883408249

Epoch: 415| Step: 0
Training loss: 0.24007458984851837
Validation loss: 1.59518910607984

Epoch: 5| Step: 1
Training loss: 0.5195884704589844
Validation loss: 1.6127466745274042

Epoch: 5| Step: 2
Training loss: 0.2664183974266052
Validation loss: 1.6328268153693086

Epoch: 5| Step: 3
Training loss: 0.299791157245636
Validation loss: 1.6132341033668929

Epoch: 5| Step: 4
Training loss: 0.24992039799690247
Validation loss: 1.6079293310001332

Epoch: 5| Step: 5
Training loss: 0.3978322148323059
Validation loss: 1.5802900765531807

Epoch: 5| Step: 6
Training loss: 0.5261983871459961
Validation loss: 1.564760713167088

Epoch: 5| Step: 7
Training loss: 0.2624717354774475
Validation loss: 1.5660088728832942

Epoch: 5| Step: 8
Training loss: 0.49263492226600647
Validation loss: 1.5711374769928634

Epoch: 5| Step: 9
Training loss: 0.3249052166938782
Validation loss: 1.5737929331359042

Epoch: 5| Step: 10
Training loss: 0.2395763397216797
Validation loss: 1.5693516974808068

Epoch: 416| Step: 0
Training loss: 0.18082885444164276
Validation loss: 1.6176136309100735

Epoch: 5| Step: 1
Training loss: 0.38185518980026245
Validation loss: 1.6366502367040163

Epoch: 5| Step: 2
Training loss: 0.3616427779197693
Validation loss: 1.6774775251265495

Epoch: 5| Step: 3
Training loss: 0.2597239911556244
Validation loss: 1.6197247377005957

Epoch: 5| Step: 4
Training loss: 0.2371542900800705
Validation loss: 1.614421938055305

Epoch: 5| Step: 5
Training loss: 0.22713729739189148
Validation loss: 1.5817235477509037

Epoch: 5| Step: 6
Training loss: 0.27187812328338623
Validation loss: 1.563570334065345

Epoch: 5| Step: 7
Training loss: 0.47732672095298767
Validation loss: 1.5839138018187655

Epoch: 5| Step: 8
Training loss: 0.6423236131668091
Validation loss: 1.5783541907546341

Epoch: 5| Step: 9
Training loss: 0.41439515352249146
Validation loss: 1.5922099441610358

Epoch: 5| Step: 10
Training loss: 0.33478713035583496
Validation loss: 1.5993287089050456

Epoch: 417| Step: 0
Training loss: 0.1858537793159485
Validation loss: 1.6116030664854153

Epoch: 5| Step: 1
Training loss: 0.29419341683387756
Validation loss: 1.5952738510665072

Epoch: 5| Step: 2
Training loss: 0.27511709928512573
Validation loss: 1.6021798169741066

Epoch: 5| Step: 3
Training loss: 0.395696222782135
Validation loss: 1.5827271938323975

Epoch: 5| Step: 4
Training loss: 0.3248937129974365
Validation loss: 1.5810169833962635

Epoch: 5| Step: 5
Training loss: 0.32373112440109253
Validation loss: 1.5869996598971787

Epoch: 5| Step: 6
Training loss: 0.2799763083457947
Validation loss: 1.5843988810816119

Epoch: 5| Step: 7
Training loss: 0.3004436790943146
Validation loss: 1.6031169865721016

Epoch: 5| Step: 8
Training loss: 0.49183201789855957
Validation loss: 1.5713424644162577

Epoch: 5| Step: 9
Training loss: 0.2640362083911896
Validation loss: 1.59436813733911

Epoch: 5| Step: 10
Training loss: 0.5016204714775085
Validation loss: 1.5803055340243923

Epoch: 418| Step: 0
Training loss: 0.28875023126602173
Validation loss: 1.5960141176818519

Epoch: 5| Step: 1
Training loss: 0.4016534686088562
Validation loss: 1.5736274770511094

Epoch: 5| Step: 2
Training loss: 0.29751941561698914
Validation loss: 1.5454094563761065

Epoch: 5| Step: 3
Training loss: 0.32148152589797974
Validation loss: 1.5683007586386897

Epoch: 5| Step: 4
Training loss: 0.14888381958007812
Validation loss: 1.547777920640925

Epoch: 5| Step: 5
Training loss: 0.3756592869758606
Validation loss: 1.5762944465042443

Epoch: 5| Step: 6
Training loss: 0.24046559631824493
Validation loss: 1.5676075091926

Epoch: 5| Step: 7
Training loss: 0.3075716495513916
Validation loss: 1.618719789289659

Epoch: 5| Step: 8
Training loss: 0.49767446517944336
Validation loss: 1.5849931598991476

Epoch: 5| Step: 9
Training loss: 0.44117411971092224
Validation loss: 1.6291096031024892

Epoch: 5| Step: 10
Training loss: 0.20691433548927307
Validation loss: 1.6426803578612625

Epoch: 419| Step: 0
Training loss: 0.21141588687896729
Validation loss: 1.635884481091653

Epoch: 5| Step: 1
Training loss: 0.4119853973388672
Validation loss: 1.636224744140461

Epoch: 5| Step: 2
Training loss: 0.2802736759185791
Validation loss: 1.6637667981527184

Epoch: 5| Step: 3
Training loss: 0.27188336849212646
Validation loss: 1.6751580469069942

Epoch: 5| Step: 4
Training loss: 0.3091670870780945
Validation loss: 1.680221470453406

Epoch: 5| Step: 5
Training loss: 0.3049267828464508
Validation loss: 1.627587818330334

Epoch: 5| Step: 6
Training loss: 0.29324978590011597
Validation loss: 1.6002225722036054

Epoch: 5| Step: 7
Training loss: 0.3511671721935272
Validation loss: 1.5817540204653175

Epoch: 5| Step: 8
Training loss: 0.5303838849067688
Validation loss: 1.5615458437191543

Epoch: 5| Step: 9
Training loss: 0.2556665539741516
Validation loss: 1.5295211294645905

Epoch: 5| Step: 10
Training loss: 0.21141228079795837
Validation loss: 1.5535580047997095

Epoch: 420| Step: 0
Training loss: 0.3830152153968811
Validation loss: 1.535976218920882

Epoch: 5| Step: 1
Training loss: 0.3272467255592346
Validation loss: 1.5476304882316179

Epoch: 5| Step: 2
Training loss: 0.17584392428398132
Validation loss: 1.5393978895679596

Epoch: 5| Step: 3
Training loss: 0.23552870750427246
Validation loss: 1.5425640254892328

Epoch: 5| Step: 4
Training loss: 0.35075682401657104
Validation loss: 1.5214380384773336

Epoch: 5| Step: 5
Training loss: 0.271271288394928
Validation loss: 1.541640386786512

Epoch: 5| Step: 6
Training loss: 0.2657804489135742
Validation loss: 1.5316548232109315

Epoch: 5| Step: 7
Training loss: 0.22935917973518372
Validation loss: 1.5264528630882181

Epoch: 5| Step: 8
Training loss: 0.1733933836221695
Validation loss: 1.5792994473570137

Epoch: 5| Step: 9
Training loss: 0.6207084059715271
Validation loss: 1.5788405338923137

Epoch: 5| Step: 10
Training loss: 0.35990437865257263
Validation loss: 1.5834556471916936

Epoch: 421| Step: 0
Training loss: 0.2722198963165283
Validation loss: 1.5873806015137704

Epoch: 5| Step: 1
Training loss: 0.31292563676834106
Validation loss: 1.568941516260947

Epoch: 5| Step: 2
Training loss: 0.3157680630683899
Validation loss: 1.5924809754535716

Epoch: 5| Step: 3
Training loss: 0.27684783935546875
Validation loss: 1.5678802177470217

Epoch: 5| Step: 4
Training loss: 0.2771800756454468
Validation loss: 1.6085532993398688

Epoch: 5| Step: 5
Training loss: 0.3486746847629547
Validation loss: 1.6018122133388315

Epoch: 5| Step: 6
Training loss: 0.298542320728302
Validation loss: 1.6161580457482287

Epoch: 5| Step: 7
Training loss: 0.34142833948135376
Validation loss: 1.6230319558933217

Epoch: 5| Step: 8
Training loss: 0.3563970923423767
Validation loss: 1.622367512795233

Epoch: 5| Step: 9
Training loss: 0.3192567229270935
Validation loss: 1.583706473791471

Epoch: 5| Step: 10
Training loss: 0.33567899465560913
Validation loss: 1.6058750652497815

Epoch: 422| Step: 0
Training loss: 0.2955363094806671
Validation loss: 1.5857013822883688

Epoch: 5| Step: 1
Training loss: 0.24174530804157257
Validation loss: 1.5747546585657264

Epoch: 5| Step: 2
Training loss: 0.278800904750824
Validation loss: 1.5719811993260537

Epoch: 5| Step: 3
Training loss: 0.3048202097415924
Validation loss: 1.5703983960613128

Epoch: 5| Step: 4
Training loss: 0.4282776415348053
Validation loss: 1.571533674834877

Epoch: 5| Step: 5
Training loss: 0.20939931273460388
Validation loss: 1.553990581984161

Epoch: 5| Step: 6
Training loss: 0.3817995488643646
Validation loss: 1.5809699143132856

Epoch: 5| Step: 7
Training loss: 0.4946015775203705
Validation loss: 1.5549351912672802

Epoch: 5| Step: 8
Training loss: 0.09665288031101227
Validation loss: 1.5632302786714287

Epoch: 5| Step: 9
Training loss: 0.26851886510849
Validation loss: 1.5592117873571252

Epoch: 5| Step: 10
Training loss: 0.21094518899917603
Validation loss: 1.571107345242654

Epoch: 423| Step: 0
Training loss: 0.1722983568906784
Validation loss: 1.5509996196275115

Epoch: 5| Step: 1
Training loss: 0.29300999641418457
Validation loss: 1.566747506459554

Epoch: 5| Step: 2
Training loss: 0.2635781168937683
Validation loss: 1.5253541392664756

Epoch: 5| Step: 3
Training loss: 0.2172967493534088
Validation loss: 1.5932117200666858

Epoch: 5| Step: 4
Training loss: 0.13789044320583344
Validation loss: 1.5438862551925003

Epoch: 5| Step: 5
Training loss: 0.3676654100418091
Validation loss: 1.553222567804398

Epoch: 5| Step: 6
Training loss: 0.4409324526786804
Validation loss: 1.531826537783428

Epoch: 5| Step: 7
Training loss: 0.20354437828063965
Validation loss: 1.5476717179821384

Epoch: 5| Step: 8
Training loss: 0.3964456617832184
Validation loss: 1.5170427112169163

Epoch: 5| Step: 9
Training loss: 0.4219841957092285
Validation loss: 1.5417132018714823

Epoch: 5| Step: 10
Training loss: 0.5284380912780762
Validation loss: 1.5197189366945656

Epoch: 424| Step: 0
Training loss: 0.27534738183021545
Validation loss: 1.5853140584884151

Epoch: 5| Step: 1
Training loss: 0.13624456524848938
Validation loss: 1.5889415638421172

Epoch: 5| Step: 2
Training loss: 0.21867160499095917
Validation loss: 1.6392430079880582

Epoch: 5| Step: 3
Training loss: 0.31386280059814453
Validation loss: 1.6657835680951354

Epoch: 5| Step: 4
Training loss: 0.3855810761451721
Validation loss: 1.6249067065536336

Epoch: 5| Step: 5
Training loss: 0.27786558866500854
Validation loss: 1.6189139299495245

Epoch: 5| Step: 6
Training loss: 0.24399173259735107
Validation loss: 1.6092383207813385

Epoch: 5| Step: 7
Training loss: 0.40882959961891174
Validation loss: 1.6157404209977837

Epoch: 5| Step: 8
Training loss: 0.2748033404350281
Validation loss: 1.6059086015147548

Epoch: 5| Step: 9
Training loss: 0.5313563942909241
Validation loss: 1.5873213929514731

Epoch: 5| Step: 10
Training loss: 0.2184705138206482
Validation loss: 1.5809221344609414

Epoch: 425| Step: 0
Training loss: 0.20845885574817657
Validation loss: 1.6347208138435119

Epoch: 5| Step: 1
Training loss: 0.28933578729629517
Validation loss: 1.6218356663180935

Epoch: 5| Step: 2
Training loss: 0.2438783347606659
Validation loss: 1.608008292413527

Epoch: 5| Step: 3
Training loss: 0.33316102623939514
Validation loss: 1.5775900104994416

Epoch: 5| Step: 4
Training loss: 0.2680554986000061
Validation loss: 1.5513681519416072

Epoch: 5| Step: 5
Training loss: 0.4079643189907074
Validation loss: 1.5098792577302584

Epoch: 5| Step: 6
Training loss: 0.3097385764122009
Validation loss: 1.5129262913939774

Epoch: 5| Step: 7
Training loss: 0.2946038246154785
Validation loss: 1.5222199604075441

Epoch: 5| Step: 8
Training loss: 0.48995858430862427
Validation loss: 1.5229004493323706

Epoch: 5| Step: 9
Training loss: 0.3464024066925049
Validation loss: 1.5689491155327007

Epoch: 5| Step: 10
Training loss: 0.26603490114212036
Validation loss: 1.6009638565842823

Epoch: 426| Step: 0
Training loss: 0.1361609250307083
Validation loss: 1.612374855626014

Epoch: 5| Step: 1
Training loss: 0.25173133611679077
Validation loss: 1.5666529260655886

Epoch: 5| Step: 2
Training loss: 0.3024347424507141
Validation loss: 1.5739053705687165

Epoch: 5| Step: 3
Training loss: 0.5470200777053833
Validation loss: 1.6035431674731675

Epoch: 5| Step: 4
Training loss: 0.41161131858825684
Validation loss: 1.5758128537926623

Epoch: 5| Step: 5
Training loss: 0.28545498847961426
Validation loss: 1.5947373605543567

Epoch: 5| Step: 6
Training loss: 0.24109987914562225
Validation loss: 1.596950154791596

Epoch: 5| Step: 7
Training loss: 0.39682769775390625
Validation loss: 1.586743950843811

Epoch: 5| Step: 8
Training loss: 0.30530044436454773
Validation loss: 1.5964334357169367

Epoch: 5| Step: 9
Training loss: 0.2661845088005066
Validation loss: 1.5574608618213284

Epoch: 5| Step: 10
Training loss: 0.2859967350959778
Validation loss: 1.5868632203789168

Epoch: 427| Step: 0
Training loss: 0.4021003246307373
Validation loss: 1.580319122601581

Epoch: 5| Step: 1
Training loss: 0.39118289947509766
Validation loss: 1.613857638451361

Epoch: 5| Step: 2
Training loss: 0.30447158217430115
Validation loss: 1.6178238596967471

Epoch: 5| Step: 3
Training loss: 0.21482804417610168
Validation loss: 1.6038981765829108

Epoch: 5| Step: 4
Training loss: 0.28482478857040405
Validation loss: 1.6108247298066334

Epoch: 5| Step: 5
Training loss: 0.2987913489341736
Validation loss: 1.61015389427062

Epoch: 5| Step: 6
Training loss: 0.1775510460138321
Validation loss: 1.5822684816134873

Epoch: 5| Step: 7
Training loss: 0.2695029675960541
Validation loss: 1.5645657444512973

Epoch: 5| Step: 8
Training loss: 0.33679431676864624
Validation loss: 1.5942979064039005

Epoch: 5| Step: 9
Training loss: 0.34856653213500977
Validation loss: 1.6089979461444321

Epoch: 5| Step: 10
Training loss: 0.36152246594429016
Validation loss: 1.6140554720355618

Epoch: 428| Step: 0
Training loss: 0.3691744804382324
Validation loss: 1.6153770159649592

Epoch: 5| Step: 1
Training loss: 0.24962982535362244
Validation loss: 1.653729377254363

Epoch: 5| Step: 2
Training loss: 0.3455215096473694
Validation loss: 1.681263707017386

Epoch: 5| Step: 3
Training loss: 0.29475393891334534
Validation loss: 1.6830538267730384

Epoch: 5| Step: 4
Training loss: 0.3712788224220276
Validation loss: 1.650370874712544

Epoch: 5| Step: 5
Training loss: 0.16468185186386108
Validation loss: 1.6081834775145336

Epoch: 5| Step: 6
Training loss: 0.40604084730148315
Validation loss: 1.5901544709359445

Epoch: 5| Step: 7
Training loss: 0.1723959892988205
Validation loss: 1.5355307094512447

Epoch: 5| Step: 8
Training loss: 0.5390726923942566
Validation loss: 1.5140108613557712

Epoch: 5| Step: 9
Training loss: 0.1919030398130417
Validation loss: 1.532241198324388

Epoch: 5| Step: 10
Training loss: 0.3134029507637024
Validation loss: 1.5427486114604498

Epoch: 429| Step: 0
Training loss: 0.3519764244556427
Validation loss: 1.5202123439440163

Epoch: 5| Step: 1
Training loss: 0.3213188052177429
Validation loss: 1.5455235794026365

Epoch: 5| Step: 2
Training loss: 0.42472466826438904
Validation loss: 1.5870667683180941

Epoch: 5| Step: 3
Training loss: 0.18507394194602966
Validation loss: 1.560542401447091

Epoch: 5| Step: 4
Training loss: 0.5470666885375977
Validation loss: 1.5576882375183927

Epoch: 5| Step: 5
Training loss: 0.16874729096889496
Validation loss: 1.592035230769906

Epoch: 5| Step: 6
Training loss: 0.1990835964679718
Validation loss: 1.6264781067448277

Epoch: 5| Step: 7
Training loss: 0.23289422690868378
Validation loss: 1.6574076811472576

Epoch: 5| Step: 8
Training loss: 0.1701972335577011
Validation loss: 1.6655340784339494

Epoch: 5| Step: 9
Training loss: 0.40755733847618103
Validation loss: 1.6817980274077384

Epoch: 5| Step: 10
Training loss: 0.23212797939777374
Validation loss: 1.663367509841919

Epoch: 430| Step: 0
Training loss: 0.257060706615448
Validation loss: 1.6147471807336296

Epoch: 5| Step: 1
Training loss: 0.33893120288848877
Validation loss: 1.634361893899979

Epoch: 5| Step: 2
Training loss: 0.30752748250961304
Validation loss: 1.5972255006913216

Epoch: 5| Step: 3
Training loss: 0.29134804010391235
Validation loss: 1.6179525390748055

Epoch: 5| Step: 4
Training loss: 0.3165118992328644
Validation loss: 1.6145361495274368

Epoch: 5| Step: 5
Training loss: 0.34715622663497925
Validation loss: 1.6657226380481516

Epoch: 5| Step: 6
Training loss: 0.361622154712677
Validation loss: 1.6501008682353522

Epoch: 5| Step: 7
Training loss: 0.4826698303222656
Validation loss: 1.6325366330403153

Epoch: 5| Step: 8
Training loss: 0.269903302192688
Validation loss: 1.592161291389055

Epoch: 5| Step: 9
Training loss: 0.24463555216789246
Validation loss: 1.5851702869579356

Epoch: 5| Step: 10
Training loss: 0.33064666390419006
Validation loss: 1.541803368958094

Epoch: 431| Step: 0
Training loss: 0.32601264119148254
Validation loss: 1.5591143677311559

Epoch: 5| Step: 1
Training loss: 0.34002771973609924
Validation loss: 1.5453536420740106

Epoch: 5| Step: 2
Training loss: 0.27415114641189575
Validation loss: 1.5546581514420048

Epoch: 5| Step: 3
Training loss: 0.37452250719070435
Validation loss: 1.584416756065943

Epoch: 5| Step: 4
Training loss: 0.4535728394985199
Validation loss: 1.5750733498604066

Epoch: 5| Step: 5
Training loss: 0.2428002804517746
Validation loss: 1.5973709385882142

Epoch: 5| Step: 6
Training loss: 0.30532538890838623
Validation loss: 1.6105077958876086

Epoch: 5| Step: 7
Training loss: 0.2891594171524048
Validation loss: 1.6593457575767272

Epoch: 5| Step: 8
Training loss: 0.3190283179283142
Validation loss: 1.6951641344255017

Epoch: 5| Step: 9
Training loss: 0.21648740768432617
Validation loss: 1.7054726436573973

Epoch: 5| Step: 10
Training loss: 0.12888307869434357
Validation loss: 1.6822779640074699

Epoch: 432| Step: 0
Training loss: 0.28007763624191284
Validation loss: 1.6437745196844942

Epoch: 5| Step: 1
Training loss: 0.3133203089237213
Validation loss: 1.6216784241378948

Epoch: 5| Step: 2
Training loss: 0.26384738087654114
Validation loss: 1.6212588125659573

Epoch: 5| Step: 3
Training loss: 0.31377506256103516
Validation loss: 1.59445317458081

Epoch: 5| Step: 4
Training loss: 0.3109667897224426
Validation loss: 1.5992217666359358

Epoch: 5| Step: 5
Training loss: 0.27644792199134827
Validation loss: 1.6123993730032316

Epoch: 5| Step: 6
Training loss: 0.3386470675468445
Validation loss: 1.634816103084113

Epoch: 5| Step: 7
Training loss: 0.36426636576652527
Validation loss: 1.6753053639524726

Epoch: 5| Step: 8
Training loss: 0.2541041672229767
Validation loss: 1.6748068307035713

Epoch: 5| Step: 9
Training loss: 0.34270089864730835
Validation loss: 1.6774932222981607

Epoch: 5| Step: 10
Training loss: 0.19522812962532043
Validation loss: 1.6449690557295276

Epoch: 433| Step: 0
Training loss: 0.20806053280830383
Validation loss: 1.6582714716593425

Epoch: 5| Step: 1
Training loss: 0.4755937457084656
Validation loss: 1.6534856711664507

Epoch: 5| Step: 2
Training loss: 0.2863818407058716
Validation loss: 1.5685570643794151

Epoch: 5| Step: 3
Training loss: 0.41876810789108276
Validation loss: 1.5529532368465135

Epoch: 5| Step: 4
Training loss: 0.2662448287010193
Validation loss: 1.5366837042634205

Epoch: 5| Step: 5
Training loss: 0.18289832770824432
Validation loss: 1.542716524934256

Epoch: 5| Step: 6
Training loss: 0.1971745789051056
Validation loss: 1.5470040636036986

Epoch: 5| Step: 7
Training loss: 0.3462802767753601
Validation loss: 1.5502097068294403

Epoch: 5| Step: 8
Training loss: 0.09471062570810318
Validation loss: 1.577070733552338

Epoch: 5| Step: 9
Training loss: 0.2506362199783325
Validation loss: 1.602325149120823

Epoch: 5| Step: 10
Training loss: 0.47040414810180664
Validation loss: 1.5900927243694183

Epoch: 434| Step: 0
Training loss: 0.4590080678462982
Validation loss: 1.5500337026452506

Epoch: 5| Step: 1
Training loss: 0.2914998531341553
Validation loss: 1.5199911299572195

Epoch: 5| Step: 2
Training loss: 0.2650209069252014
Validation loss: 1.533590139881257

Epoch: 5| Step: 3
Training loss: 0.14360982179641724
Validation loss: 1.5485403345477196

Epoch: 5| Step: 4
Training loss: 0.3815287947654724
Validation loss: 1.5656096358453073

Epoch: 5| Step: 5
Training loss: 0.13570109009742737
Validation loss: 1.5648125717716832

Epoch: 5| Step: 6
Training loss: 0.1821933537721634
Validation loss: 1.5564323843166392

Epoch: 5| Step: 7
Training loss: 0.33610954880714417
Validation loss: 1.585747104819103

Epoch: 5| Step: 8
Training loss: 0.1928536593914032
Validation loss: 1.57936994747449

Epoch: 5| Step: 9
Training loss: 0.379311740398407
Validation loss: 1.6131570005929599

Epoch: 5| Step: 10
Training loss: 0.2307395339012146
Validation loss: 1.5463964875026415

Epoch: 435| Step: 0
Training loss: 0.13154658675193787
Validation loss: 1.5570795113040554

Epoch: 5| Step: 1
Training loss: 0.2651544213294983
Validation loss: 1.5371573458435714

Epoch: 5| Step: 2
Training loss: 0.2675403654575348
Validation loss: 1.5256044992836573

Epoch: 5| Step: 3
Training loss: 0.3837573230266571
Validation loss: 1.523066875755146

Epoch: 5| Step: 4
Training loss: 0.36108559370040894
Validation loss: 1.5256738098718787

Epoch: 5| Step: 5
Training loss: 0.27829617261886597
Validation loss: 1.536235241479771

Epoch: 5| Step: 6
Training loss: 0.15232659876346588
Validation loss: 1.5433883974629063

Epoch: 5| Step: 7
Training loss: 0.2003938853740692
Validation loss: 1.5839683086641374

Epoch: 5| Step: 8
Training loss: 0.3384961485862732
Validation loss: 1.5692364400432957

Epoch: 5| Step: 9
Training loss: 0.41942939162254333
Validation loss: 1.5828038902692898

Epoch: 5| Step: 10
Training loss: 0.1922261267900467
Validation loss: 1.5697862307230632

Epoch: 436| Step: 0
Training loss: 0.30928847193717957
Validation loss: 1.556274878081455

Epoch: 5| Step: 1
Training loss: 0.29858464002609253
Validation loss: 1.555014535944949

Epoch: 5| Step: 2
Training loss: 0.2021629810333252
Validation loss: 1.5662675903689476

Epoch: 5| Step: 3
Training loss: 0.4512217938899994
Validation loss: 1.5485063618229282

Epoch: 5| Step: 4
Training loss: 0.25473958253860474
Validation loss: 1.5661547196808683

Epoch: 5| Step: 5
Training loss: 0.22600455582141876
Validation loss: 1.599342127000132

Epoch: 5| Step: 6
Training loss: 0.15674439072608948
Validation loss: 1.599669151408698

Epoch: 5| Step: 7
Training loss: 0.21612200140953064
Validation loss: 1.6412243163713844

Epoch: 5| Step: 8
Training loss: 0.3019343912601471
Validation loss: 1.6008906466986543

Epoch: 5| Step: 9
Training loss: 0.3285368084907532
Validation loss: 1.5879262275593256

Epoch: 5| Step: 10
Training loss: 0.28759148716926575
Validation loss: 1.5894553328073153

Epoch: 437| Step: 0
Training loss: 0.14266875386238098
Validation loss: 1.5577174143124652

Epoch: 5| Step: 1
Training loss: 0.2744539976119995
Validation loss: 1.5362061377494567

Epoch: 5| Step: 2
Training loss: 0.24446554481983185
Validation loss: 1.5117775163342875

Epoch: 5| Step: 3
Training loss: 0.24246644973754883
Validation loss: 1.5350657611764886

Epoch: 5| Step: 4
Training loss: 0.21708908677101135
Validation loss: 1.557015811243365

Epoch: 5| Step: 5
Training loss: 0.23487448692321777
Validation loss: 1.56419728584187

Epoch: 5| Step: 6
Training loss: 0.27588680386543274
Validation loss: 1.6185586093574442

Epoch: 5| Step: 7
Training loss: 0.21994929015636444
Validation loss: 1.6580719793996503

Epoch: 5| Step: 8
Training loss: 0.37979066371917725
Validation loss: 1.6588465000993462

Epoch: 5| Step: 9
Training loss: 0.4574510455131531
Validation loss: 1.6267501897709344

Epoch: 5| Step: 10
Training loss: 0.16193541884422302
Validation loss: 1.6129651928460726

Epoch: 438| Step: 0
Training loss: 0.14641831815242767
Validation loss: 1.630940039952596

Epoch: 5| Step: 1
Training loss: 0.17535655200481415
Validation loss: 1.5936155460214103

Epoch: 5| Step: 2
Training loss: 0.6029933094978333
Validation loss: 1.5605819789312219

Epoch: 5| Step: 3
Training loss: 0.3001682162284851
Validation loss: 1.5595098246810257

Epoch: 5| Step: 4
Training loss: 0.12626227736473083
Validation loss: 1.5671538665730467

Epoch: 5| Step: 5
Training loss: 0.2966448664665222
Validation loss: 1.5592798545796385

Epoch: 5| Step: 6
Training loss: 0.21694155037403107
Validation loss: 1.5778015954520113

Epoch: 5| Step: 7
Training loss: 0.3263701796531677
Validation loss: 1.6062478839710195

Epoch: 5| Step: 8
Training loss: 0.18190816044807434
Validation loss: 1.5926552575121644

Epoch: 5| Step: 9
Training loss: 0.2990662455558777
Validation loss: 1.5915838031358616

Epoch: 5| Step: 10
Training loss: 0.3022420406341553
Validation loss: 1.5587656959410636

Epoch: 439| Step: 0
Training loss: 0.1646420657634735
Validation loss: 1.5183198541723273

Epoch: 5| Step: 1
Training loss: 0.3744126260280609
Validation loss: 1.537842781313004

Epoch: 5| Step: 2
Training loss: 0.31134188175201416
Validation loss: 1.5376927198902253

Epoch: 5| Step: 3
Training loss: 0.1457958072423935
Validation loss: 1.5237441703837404

Epoch: 5| Step: 4
Training loss: 0.245382159948349
Validation loss: 1.529669254056869

Epoch: 5| Step: 5
Training loss: 0.23812437057495117
Validation loss: 1.560369440945246

Epoch: 5| Step: 6
Training loss: 0.2574734389781952
Validation loss: 1.576056021516041

Epoch: 5| Step: 7
Training loss: 0.2956385910511017
Validation loss: 1.5503334768356816

Epoch: 5| Step: 8
Training loss: 0.20409122109413147
Validation loss: 1.5367871971540554

Epoch: 5| Step: 9
Training loss: 0.4319504201412201
Validation loss: 1.5529367039280553

Epoch: 5| Step: 10
Training loss: 0.29575401544570923
Validation loss: 1.5574486255645752

Epoch: 440| Step: 0
Training loss: 0.2530655264854431
Validation loss: 1.5722521005138275

Epoch: 5| Step: 1
Training loss: 0.41532841324806213
Validation loss: 1.5907027593222998

Epoch: 5| Step: 2
Training loss: 0.11854919046163559
Validation loss: 1.5950785324137697

Epoch: 5| Step: 3
Training loss: 0.262103408575058
Validation loss: 1.6042754573206748

Epoch: 5| Step: 4
Training loss: 0.33810701966285706
Validation loss: 1.633706505580615

Epoch: 5| Step: 5
Training loss: 0.20020799338817596
Validation loss: 1.6056967512253792

Epoch: 5| Step: 6
Training loss: 0.2494475543498993
Validation loss: 1.5970836403549358

Epoch: 5| Step: 7
Training loss: 0.3732311725616455
Validation loss: 1.5611349933890886

Epoch: 5| Step: 8
Training loss: 0.22686012089252472
Validation loss: 1.5530553992076586

Epoch: 5| Step: 9
Training loss: 0.1597510129213333
Validation loss: 1.563711671419041

Epoch: 5| Step: 10
Training loss: 0.3336388170719147
Validation loss: 1.518311362112722

Epoch: 441| Step: 0
Training loss: 0.2800386846065521
Validation loss: 1.5412438659257786

Epoch: 5| Step: 1
Training loss: 0.15739817917346954
Validation loss: 1.5198543776748001

Epoch: 5| Step: 2
Training loss: 0.19973380863666534
Validation loss: 1.5372495632017813

Epoch: 5| Step: 3
Training loss: 0.24802613258361816
Validation loss: 1.5367302407500565

Epoch: 5| Step: 4
Training loss: 0.38445502519607544
Validation loss: 1.5186735327525804

Epoch: 5| Step: 5
Training loss: 0.20719289779663086
Validation loss: 1.5957889749157814

Epoch: 5| Step: 6
Training loss: 0.14494897425174713
Validation loss: 1.6450325622353503

Epoch: 5| Step: 7
Training loss: 0.43179669976234436
Validation loss: 1.6550143482864543

Epoch: 5| Step: 8
Training loss: 0.3586968779563904
Validation loss: 1.6427229521095112

Epoch: 5| Step: 9
Training loss: 0.2938481271266937
Validation loss: 1.6399148869258102

Epoch: 5| Step: 10
Training loss: 0.12936009466648102
Validation loss: 1.6197807865758096

Epoch: 442| Step: 0
Training loss: 0.2516106963157654
Validation loss: 1.5679075743562432

Epoch: 5| Step: 1
Training loss: 0.2589283287525177
Validation loss: 1.531089569932671

Epoch: 5| Step: 2
Training loss: 0.13442574441432953
Validation loss: 1.546477433173887

Epoch: 5| Step: 3
Training loss: 0.2115277796983719
Validation loss: 1.530618361247483

Epoch: 5| Step: 4
Training loss: 0.2926444411277771
Validation loss: 1.5269114073886667

Epoch: 5| Step: 5
Training loss: 0.201639324426651
Validation loss: 1.5354280382074335

Epoch: 5| Step: 6
Training loss: 0.2453945130109787
Validation loss: 1.532687822977702

Epoch: 5| Step: 7
Training loss: 0.3967292010784149
Validation loss: 1.5261901924687047

Epoch: 5| Step: 8
Training loss: 0.27338674664497375
Validation loss: 1.5470653580081077

Epoch: 5| Step: 9
Training loss: 0.35119158029556274
Validation loss: 1.5527436707609443

Epoch: 5| Step: 10
Training loss: 0.18083269894123077
Validation loss: 1.5466221852969098

Epoch: 443| Step: 0
Training loss: 0.27543801069259644
Validation loss: 1.5526852658999863

Epoch: 5| Step: 1
Training loss: 0.17723599076271057
Validation loss: 1.5470910546600178

Epoch: 5| Step: 2
Training loss: 0.24977099895477295
Validation loss: 1.5229016247616018

Epoch: 5| Step: 3
Training loss: 0.20432476699352264
Validation loss: 1.532523287239895

Epoch: 5| Step: 4
Training loss: 0.14845290780067444
Validation loss: 1.5363305589204193

Epoch: 5| Step: 5
Training loss: 0.12955880165100098
Validation loss: 1.5355944671938497

Epoch: 5| Step: 6
Training loss: 0.28179264068603516
Validation loss: 1.5642226229431808

Epoch: 5| Step: 7
Training loss: 0.36344456672668457
Validation loss: 1.5330304791850429

Epoch: 5| Step: 8
Training loss: 0.32635927200317383
Validation loss: 1.5693857182738602

Epoch: 5| Step: 9
Training loss: 0.26334699988365173
Validation loss: 1.5282932942913425

Epoch: 5| Step: 10
Training loss: 0.31735771894454956
Validation loss: 1.5796110501853369

Epoch: 444| Step: 0
Training loss: 0.3278381824493408
Validation loss: 1.5477408644973591

Epoch: 5| Step: 1
Training loss: 0.29892832040786743
Validation loss: 1.5716044172163932

Epoch: 5| Step: 2
Training loss: 0.25977447628974915
Validation loss: 1.532974104727468

Epoch: 5| Step: 3
Training loss: 0.21310143172740936
Validation loss: 1.543752057577974

Epoch: 5| Step: 4
Training loss: 0.19925817847251892
Validation loss: 1.5454468060565252

Epoch: 5| Step: 5
Training loss: 0.215133935213089
Validation loss: 1.5408226572057253

Epoch: 5| Step: 6
Training loss: 0.19194452464580536
Validation loss: 1.5262045373198807

Epoch: 5| Step: 7
Training loss: 0.23692286014556885
Validation loss: 1.5523136008170344

Epoch: 5| Step: 8
Training loss: 0.13744059205055237
Validation loss: 1.5565785413147302

Epoch: 5| Step: 9
Training loss: 0.1833321750164032
Validation loss: 1.6003643992126628

Epoch: 5| Step: 10
Training loss: 0.3368063271045685
Validation loss: 1.6386235196103331

Epoch: 445| Step: 0
Training loss: 0.4976842999458313
Validation loss: 1.6713308044659194

Epoch: 5| Step: 1
Training loss: 0.26974016427993774
Validation loss: 1.6732451351740028

Epoch: 5| Step: 2
Training loss: 0.18268737196922302
Validation loss: 1.6047142244154406

Epoch: 5| Step: 3
Training loss: 0.244000643491745
Validation loss: 1.5697038301857569

Epoch: 5| Step: 4
Training loss: 0.3947984278202057
Validation loss: 1.5566279490788777

Epoch: 5| Step: 5
Training loss: 0.2895611524581909
Validation loss: 1.5302193062279814

Epoch: 5| Step: 6
Training loss: 0.3106834888458252
Validation loss: 1.5182996462750178

Epoch: 5| Step: 7
Training loss: 0.22620324790477753
Validation loss: 1.540020723496714

Epoch: 5| Step: 8
Training loss: 0.22144842147827148
Validation loss: 1.557397061778653

Epoch: 5| Step: 9
Training loss: 0.2718949019908905
Validation loss: 1.5700387134346911

Epoch: 5| Step: 10
Training loss: 0.19069643318653107
Validation loss: 1.5449637495061403

Epoch: 446| Step: 0
Training loss: 0.16257843375205994
Validation loss: 1.5211741911467684

Epoch: 5| Step: 1
Training loss: 0.266952782869339
Validation loss: 1.5156576659089775

Epoch: 5| Step: 2
Training loss: 0.2908555567264557
Validation loss: 1.5225501150213263

Epoch: 5| Step: 3
Training loss: 0.4634284973144531
Validation loss: 1.5435916941653016

Epoch: 5| Step: 4
Training loss: 0.34555476903915405
Validation loss: 1.517719889199862

Epoch: 5| Step: 5
Training loss: 0.19552066922187805
Validation loss: 1.5229053548587266

Epoch: 5| Step: 6
Training loss: 0.2534516453742981
Validation loss: 1.5211089913563063

Epoch: 5| Step: 7
Training loss: 0.23515582084655762
Validation loss: 1.597593178031265

Epoch: 5| Step: 8
Training loss: 0.31042686104774475
Validation loss: 1.6185085183830672

Epoch: 5| Step: 9
Training loss: 0.21327367424964905
Validation loss: 1.6042642849747852

Epoch: 5| Step: 10
Training loss: 0.30065369606018066
Validation loss: 1.596953304865027

Epoch: 447| Step: 0
Training loss: 0.24777869880199432
Validation loss: 1.5670645429242043

Epoch: 5| Step: 1
Training loss: 0.22073335945606232
Validation loss: 1.5265615012056084

Epoch: 5| Step: 2
Training loss: 0.31508320569992065
Validation loss: 1.5567497463636502

Epoch: 5| Step: 3
Training loss: 0.2763753831386566
Validation loss: 1.54376018944607

Epoch: 5| Step: 4
Training loss: 0.2154448926448822
Validation loss: 1.5386582548900316

Epoch: 5| Step: 5
Training loss: 0.32844308018684387
Validation loss: 1.5696524535456011

Epoch: 5| Step: 6
Training loss: 0.18117834627628326
Validation loss: 1.5790832042694092

Epoch: 5| Step: 7
Training loss: 0.19624993205070496
Validation loss: 1.5802847544352214

Epoch: 5| Step: 8
Training loss: 0.308951199054718
Validation loss: 1.6214360934431835

Epoch: 5| Step: 9
Training loss: 0.36455631256103516
Validation loss: 1.6303044198661722

Epoch: 5| Step: 10
Training loss: 0.2861784100532532
Validation loss: 1.6166912342912407

Epoch: 448| Step: 0
Training loss: 0.20360705256462097
Validation loss: 1.5781031129180745

Epoch: 5| Step: 1
Training loss: 0.2539721131324768
Validation loss: 1.5641159396017752

Epoch: 5| Step: 2
Training loss: 0.36841922998428345
Validation loss: 1.5385534494153914

Epoch: 5| Step: 3
Training loss: 0.22683577239513397
Validation loss: 1.5361594077079528

Epoch: 5| Step: 4
Training loss: 0.2446843385696411
Validation loss: 1.5186631576989287

Epoch: 5| Step: 5
Training loss: 0.22597317397594452
Validation loss: 1.526403852688369

Epoch: 5| Step: 6
Training loss: 0.22603559494018555
Validation loss: 1.5228766228563042

Epoch: 5| Step: 7
Training loss: 0.16982445120811462
Validation loss: 1.5555549552363734

Epoch: 5| Step: 8
Training loss: 0.22682872414588928
Validation loss: 1.5358381271362305

Epoch: 5| Step: 9
Training loss: 0.35606127977371216
Validation loss: 1.5193267342864827

Epoch: 5| Step: 10
Training loss: 0.21634528040885925
Validation loss: 1.5688913560682727

Epoch: 449| Step: 0
Training loss: 0.2845121920108795
Validation loss: 1.51972742619053

Epoch: 5| Step: 1
Training loss: 0.1902882307767868
Validation loss: 1.5006765729637557

Epoch: 5| Step: 2
Training loss: 0.436767041683197
Validation loss: 1.4897606257469422

Epoch: 5| Step: 3
Training loss: 0.18220092356204987
Validation loss: 1.5061734107232863

Epoch: 5| Step: 4
Training loss: 0.18218408524990082
Validation loss: 1.5138776327974053

Epoch: 5| Step: 5
Training loss: 0.3196173310279846
Validation loss: 1.5419904070515786

Epoch: 5| Step: 6
Training loss: 0.21568748354911804
Validation loss: 1.5619715785467496

Epoch: 5| Step: 7
Training loss: 0.17697376012802124
Validation loss: 1.5586825686116372

Epoch: 5| Step: 8
Training loss: 0.14747101068496704
Validation loss: 1.5525718254427756

Epoch: 5| Step: 9
Training loss: 0.22052745521068573
Validation loss: 1.57464978771825

Epoch: 5| Step: 10
Training loss: 0.3944591283798218
Validation loss: 1.5757273204864994

Epoch: 450| Step: 0
Training loss: 0.20435836911201477
Validation loss: 1.5638116252037786

Epoch: 5| Step: 1
Training loss: 0.28659293055534363
Validation loss: 1.5354393541171987

Epoch: 5| Step: 2
Training loss: 0.1385851353406906
Validation loss: 1.4970105809550132

Epoch: 5| Step: 3
Training loss: 0.22332820296287537
Validation loss: 1.5102203930577924

Epoch: 5| Step: 4
Training loss: 0.3587873876094818
Validation loss: 1.50833503020707

Epoch: 5| Step: 5
Training loss: 0.4268539845943451
Validation loss: 1.5133913524689213

Epoch: 5| Step: 6
Training loss: 0.15244828164577484
Validation loss: 1.5153882836782804

Epoch: 5| Step: 7
Training loss: 0.16493508219718933
Validation loss: 1.5857733603446715

Epoch: 5| Step: 8
Training loss: 0.3262297809123993
Validation loss: 1.5972185301524338

Epoch: 5| Step: 9
Training loss: 0.15659230947494507
Validation loss: 1.5977871033453173

Epoch: 5| Step: 10
Training loss: 0.28679558634757996
Validation loss: 1.5772094752198906

Epoch: 451| Step: 0
Training loss: 0.28369882702827454
Validation loss: 1.5436423452951575

Epoch: 5| Step: 1
Training loss: 0.38605478405952454
Validation loss: 1.557715558236645

Epoch: 5| Step: 2
Training loss: 0.2837355434894562
Validation loss: 1.583976012404247

Epoch: 5| Step: 3
Training loss: 0.2559630870819092
Validation loss: 1.56408614753395

Epoch: 5| Step: 4
Training loss: 0.2712039649486542
Validation loss: 1.5648606464427004

Epoch: 5| Step: 5
Training loss: 0.36401796340942383
Validation loss: 1.5631195076050297

Epoch: 5| Step: 6
Training loss: 0.12317240238189697
Validation loss: 1.554467111505488

Epoch: 5| Step: 7
Training loss: 0.23289020359516144
Validation loss: 1.5917171073216263

Epoch: 5| Step: 8
Training loss: 0.1730818748474121
Validation loss: 1.5416537177178167

Epoch: 5| Step: 9
Training loss: 0.13227711617946625
Validation loss: 1.5822067786288518

Epoch: 5| Step: 10
Training loss: 0.2040722519159317
Validation loss: 1.5392552165574924

Epoch: 452| Step: 0
Training loss: 0.20993933081626892
Validation loss: 1.5420529406557801

Epoch: 5| Step: 1
Training loss: 0.2634512782096863
Validation loss: 1.5360746191393944

Epoch: 5| Step: 2
Training loss: 0.23760247230529785
Validation loss: 1.5047883538789646

Epoch: 5| Step: 3
Training loss: 0.2997906804084778
Validation loss: 1.4963264875514533

Epoch: 5| Step: 4
Training loss: 0.24807389080524445
Validation loss: 1.5044713251052364

Epoch: 5| Step: 5
Training loss: 0.18789145350456238
Validation loss: 1.4876974410908197

Epoch: 5| Step: 6
Training loss: 0.21928784251213074
Validation loss: 1.5026934992882512

Epoch: 5| Step: 7
Training loss: 0.27712124586105347
Validation loss: 1.5174116729408182

Epoch: 5| Step: 8
Training loss: 0.1949407160282135
Validation loss: 1.5066226541355092

Epoch: 5| Step: 9
Training loss: 0.1918947994709015
Validation loss: 1.5224967425869358

Epoch: 5| Step: 10
Training loss: 0.20007583498954773
Validation loss: 1.4844832407530917

Epoch: 453| Step: 0
Training loss: 0.2139979898929596
Validation loss: 1.5068387780138242

Epoch: 5| Step: 1
Training loss: 0.1757238805294037
Validation loss: 1.5276249249776204

Epoch: 5| Step: 2
Training loss: 0.08599888533353806
Validation loss: 1.5451704802051667

Epoch: 5| Step: 3
Training loss: 0.35884103178977966
Validation loss: 1.5213703417008924

Epoch: 5| Step: 4
Training loss: 0.19065365195274353
Validation loss: 1.5066786940379808

Epoch: 5| Step: 5
Training loss: 0.1501864492893219
Validation loss: 1.5090031880204395

Epoch: 5| Step: 6
Training loss: 0.3097856640815735
Validation loss: 1.5439805112859255

Epoch: 5| Step: 7
Training loss: 0.3233689069747925
Validation loss: 1.5061992535027124

Epoch: 5| Step: 8
Training loss: 0.08358581364154816
Validation loss: 1.5110530237997732

Epoch: 5| Step: 9
Training loss: 0.20545653998851776
Validation loss: 1.533209172628259

Epoch: 5| Step: 10
Training loss: 0.25579193234443665
Validation loss: 1.521749261886843

Epoch: 454| Step: 0
Training loss: 0.3244216740131378
Validation loss: 1.550213804808996

Epoch: 5| Step: 1
Training loss: 0.23797158896923065
Validation loss: 1.5438458599070066

Epoch: 5| Step: 2
Training loss: 0.11042992025613785
Validation loss: 1.5364423515976116

Epoch: 5| Step: 3
Training loss: 0.14762023091316223
Validation loss: 1.514023365512971

Epoch: 5| Step: 4
Training loss: 0.13281802833080292
Validation loss: 1.5253216784487489

Epoch: 5| Step: 5
Training loss: 0.17540714144706726
Validation loss: 1.518431091821322

Epoch: 5| Step: 6
Training loss: 0.19403383135795593
Validation loss: 1.5375992303253503

Epoch: 5| Step: 7
Training loss: 0.1884738951921463
Validation loss: 1.5203866997072775

Epoch: 5| Step: 8
Training loss: 0.4662277102470398
Validation loss: 1.5038691598881957

Epoch: 5| Step: 9
Training loss: 0.13453848659992218
Validation loss: 1.50286360966262

Epoch: 5| Step: 10
Training loss: 0.3659151792526245
Validation loss: 1.5071297563532347

Epoch: 455| Step: 0
Training loss: 0.1634860336780548
Validation loss: 1.4909618464849328

Epoch: 5| Step: 1
Training loss: 0.19212669134140015
Validation loss: 1.4997542212086339

Epoch: 5| Step: 2
Training loss: 0.28462666273117065
Validation loss: 1.4950861136118572

Epoch: 5| Step: 3
Training loss: 0.32245132327079773
Validation loss: 1.5078193641478015

Epoch: 5| Step: 4
Training loss: 0.2516863942146301
Validation loss: 1.508805162163191

Epoch: 5| Step: 5
Training loss: 0.18618328869342804
Validation loss: 1.5073810726083734

Epoch: 5| Step: 6
Training loss: 0.21666355431079865
Validation loss: 1.5512037302858086

Epoch: 5| Step: 7
Training loss: 0.28845471143722534
Validation loss: 1.5786227436475857

Epoch: 5| Step: 8
Training loss: 0.2665962874889374
Validation loss: 1.6057008466412943

Epoch: 5| Step: 9
Training loss: 0.23215433955192566
Validation loss: 1.6050096211894866

Epoch: 5| Step: 10
Training loss: 0.2117297202348709
Validation loss: 1.5782892806555635

Epoch: 456| Step: 0
Training loss: 0.3127690255641937
Validation loss: 1.5702594800661969

Epoch: 5| Step: 1
Training loss: 0.2048637419939041
Validation loss: 1.5657552531970444

Epoch: 5| Step: 2
Training loss: 0.21922950446605682
Validation loss: 1.548075270909135

Epoch: 5| Step: 3
Training loss: 0.27207010984420776
Validation loss: 1.5568288885137087

Epoch: 5| Step: 4
Training loss: 0.18911683559417725
Validation loss: 1.5340727477945306

Epoch: 5| Step: 5
Training loss: 0.20729398727416992
Validation loss: 1.5700756760053738

Epoch: 5| Step: 6
Training loss: 0.2055869996547699
Validation loss: 1.5503959867262072

Epoch: 5| Step: 7
Training loss: 0.16544683277606964
Validation loss: 1.5604468443060433

Epoch: 5| Step: 8
Training loss: 0.21182218194007874
Validation loss: 1.490633508210541

Epoch: 5| Step: 9
Training loss: 0.24661986529827118
Validation loss: 1.4885581859978296

Epoch: 5| Step: 10
Training loss: 0.14954985678195953
Validation loss: 1.474979946049311

Epoch: 457| Step: 0
Training loss: 0.19045419991016388
Validation loss: 1.469967592787999

Epoch: 5| Step: 1
Training loss: 0.22381272912025452
Validation loss: 1.4666976672346874

Epoch: 5| Step: 2
Training loss: 0.148825541138649
Validation loss: 1.4949556807036042

Epoch: 5| Step: 3
Training loss: 0.21125169098377228
Validation loss: 1.4864245794152702

Epoch: 5| Step: 4
Training loss: 0.17893128097057343
Validation loss: 1.4833015370112594

Epoch: 5| Step: 5
Training loss: 0.18783709406852722
Validation loss: 1.4551567223764235

Epoch: 5| Step: 6
Training loss: 0.1413607895374298
Validation loss: 1.4605156952334988

Epoch: 5| Step: 7
Training loss: 0.2512682378292084
Validation loss: 1.4515549944293114

Epoch: 5| Step: 8
Training loss: 0.3538759648799896
Validation loss: 1.4660043472884803

Epoch: 5| Step: 9
Training loss: 0.2052479237318039
Validation loss: 1.477964610181829

Epoch: 5| Step: 10
Training loss: 0.22145867347717285
Validation loss: 1.4857902501219062

Epoch: 458| Step: 0
Training loss: 0.15279868245124817
Validation loss: 1.4923876280425696

Epoch: 5| Step: 1
Training loss: 0.27409231662750244
Validation loss: 1.559314658564906

Epoch: 5| Step: 2
Training loss: 0.28784695267677307
Validation loss: 1.5665036606532272

Epoch: 5| Step: 3
Training loss: 0.2399718016386032
Validation loss: 1.5690241846986996

Epoch: 5| Step: 4
Training loss: 0.18323113024234772
Validation loss: 1.5070641553530129

Epoch: 5| Step: 5
Training loss: 0.20473730564117432
Validation loss: 1.5161352093501756

Epoch: 5| Step: 6
Training loss: 0.1713547557592392
Validation loss: 1.505482159635072

Epoch: 5| Step: 7
Training loss: 0.10513901710510254
Validation loss: 1.5303957167492117

Epoch: 5| Step: 8
Training loss: 0.2867732048034668
Validation loss: 1.4819216561573807

Epoch: 5| Step: 9
Training loss: 0.4018532633781433
Validation loss: 1.5173768593418984

Epoch: 5| Step: 10
Training loss: 0.13202035427093506
Validation loss: 1.5407194796428885

Epoch: 459| Step: 0
Training loss: 0.13167455792427063
Validation loss: 1.515147788550264

Epoch: 5| Step: 1
Training loss: 0.2052467167377472
Validation loss: 1.5306809397153958

Epoch: 5| Step: 2
Training loss: 0.27166852355003357
Validation loss: 1.4966619591559134

Epoch: 5| Step: 3
Training loss: 0.3085126578807831
Validation loss: 1.4879338433665614

Epoch: 5| Step: 4
Training loss: 0.18248805403709412
Validation loss: 1.4895730262161584

Epoch: 5| Step: 5
Training loss: 0.20650239288806915
Validation loss: 1.5175345341364543

Epoch: 5| Step: 6
Training loss: 0.12178361415863037
Validation loss: 1.4952668156675113

Epoch: 5| Step: 7
Training loss: 0.1428169310092926
Validation loss: 1.4990177077631797

Epoch: 5| Step: 8
Training loss: 0.29322633147239685
Validation loss: 1.5231561712039414

Epoch: 5| Step: 9
Training loss: 0.3425045907497406
Validation loss: 1.5251711664661285

Epoch: 5| Step: 10
Training loss: 0.2563009560108185
Validation loss: 1.5297865534341464

Epoch: 460| Step: 0
Training loss: 0.4193990230560303
Validation loss: 1.5667459003386959

Epoch: 5| Step: 1
Training loss: 0.20441678166389465
Validation loss: 1.5505446259693434

Epoch: 5| Step: 2
Training loss: 0.12575502693653107
Validation loss: 1.5473059044089368

Epoch: 5| Step: 3
Training loss: 0.24303534626960754
Validation loss: 1.5290125480262182

Epoch: 5| Step: 4
Training loss: 0.326759934425354
Validation loss: 1.5653388134894832

Epoch: 5| Step: 5
Training loss: 0.2529217004776001
Validation loss: 1.5373973923344766

Epoch: 5| Step: 6
Training loss: 0.21655336022377014
Validation loss: 1.5255031521602342

Epoch: 5| Step: 7
Training loss: 0.223104327917099
Validation loss: 1.51515325807756

Epoch: 5| Step: 8
Training loss: 0.13996461033821106
Validation loss: 1.5237460136413574

Epoch: 5| Step: 9
Training loss: 0.18834875524044037
Validation loss: 1.508575213852749

Epoch: 5| Step: 10
Training loss: 0.30679774284362793
Validation loss: 1.4941612905071628

Epoch: 461| Step: 0
Training loss: 0.18769694864749908
Validation loss: 1.5232721067244006

Epoch: 5| Step: 1
Training loss: 0.23993900418281555
Validation loss: 1.489726399862638

Epoch: 5| Step: 2
Training loss: 0.17671796679496765
Validation loss: 1.4890974337054836

Epoch: 5| Step: 3
Training loss: 0.41599756479263306
Validation loss: 1.4967367860578722

Epoch: 5| Step: 4
Training loss: 0.20481738448143005
Validation loss: 1.5077230436827547

Epoch: 5| Step: 5
Training loss: 0.192461758852005
Validation loss: 1.5082865671444965

Epoch: 5| Step: 6
Training loss: 0.31696516275405884
Validation loss: 1.5051818265709827

Epoch: 5| Step: 7
Training loss: 0.12065736949443817
Validation loss: 1.5196197417474562

Epoch: 5| Step: 8
Training loss: 0.13501164317131042
Validation loss: 1.522655604988016

Epoch: 5| Step: 9
Training loss: 0.10439908504486084
Validation loss: 1.5159903277633011

Epoch: 5| Step: 10
Training loss: 0.351705402135849
Validation loss: 1.515430332511984

Epoch: 462| Step: 0
Training loss: 0.14430192112922668
Validation loss: 1.5204031903256652

Epoch: 5| Step: 1
Training loss: 0.24417993426322937
Validation loss: 1.5400086666948052

Epoch: 5| Step: 2
Training loss: 0.3928074836730957
Validation loss: 1.556603963657092

Epoch: 5| Step: 3
Training loss: 0.23871824145317078
Validation loss: 1.5483829898218955

Epoch: 5| Step: 4
Training loss: 0.27700623869895935
Validation loss: 1.5207001637387019

Epoch: 5| Step: 5
Training loss: 0.17964068055152893
Validation loss: 1.497779869264172

Epoch: 5| Step: 6
Training loss: 0.1984892040491104
Validation loss: 1.4837321607015466

Epoch: 5| Step: 7
Training loss: 0.18143939971923828
Validation loss: 1.4957591666970202

Epoch: 5| Step: 8
Training loss: 0.3527170419692993
Validation loss: 1.5073204642982894

Epoch: 5| Step: 9
Training loss: 0.12462528049945831
Validation loss: 1.5125367654267179

Epoch: 5| Step: 10
Training loss: 0.16467058658599854
Validation loss: 1.5095766225168783

Epoch: 463| Step: 0
Training loss: 0.20912694931030273
Validation loss: 1.4869816296844072

Epoch: 5| Step: 1
Training loss: 0.3541586995124817
Validation loss: 1.4903489530727427

Epoch: 5| Step: 2
Training loss: 0.2619364261627197
Validation loss: 1.5124587576876405

Epoch: 5| Step: 3
Training loss: 0.11770826578140259
Validation loss: 1.567629724420527

Epoch: 5| Step: 4
Training loss: 0.3106158375740051
Validation loss: 1.587138686128842

Epoch: 5| Step: 5
Training loss: 0.20391015708446503
Validation loss: 1.548534656083712

Epoch: 5| Step: 6
Training loss: 0.43609705567359924
Validation loss: 1.5394371965880036

Epoch: 5| Step: 7
Training loss: 0.17338424921035767
Validation loss: 1.5276050131808045

Epoch: 5| Step: 8
Training loss: 0.15025436878204346
Validation loss: 1.5636773852891819

Epoch: 5| Step: 9
Training loss: 0.20632490515708923
Validation loss: 1.5224447750276136

Epoch: 5| Step: 10
Training loss: 0.22997213900089264
Validation loss: 1.5865485514363935

Epoch: 464| Step: 0
Training loss: 0.22769737243652344
Validation loss: 1.590208730389995

Epoch: 5| Step: 1
Training loss: 0.2090299129486084
Validation loss: 1.617950653517118

Epoch: 5| Step: 2
Training loss: 0.3756179213523865
Validation loss: 1.6203154671576716

Epoch: 5| Step: 3
Training loss: 0.22552387416362762
Validation loss: 1.6386634252404655

Epoch: 5| Step: 4
Training loss: 0.28232449293136597
Validation loss: 1.6230440767862464

Epoch: 5| Step: 5
Training loss: 0.20374496281147003
Validation loss: 1.5734528969692927

Epoch: 5| Step: 6
Training loss: 0.20334598422050476
Validation loss: 1.5442078869829896

Epoch: 5| Step: 7
Training loss: 0.17515914142131805
Validation loss: 1.523715494781412

Epoch: 5| Step: 8
Training loss: 0.2678530812263489
Validation loss: 1.5051795500580982

Epoch: 5| Step: 9
Training loss: 0.16875723004341125
Validation loss: 1.4887250931032243

Epoch: 5| Step: 10
Training loss: 0.2577369511127472
Validation loss: 1.4631881149866248

Epoch: 465| Step: 0
Training loss: 0.18255497515201569
Validation loss: 1.473301831112113

Epoch: 5| Step: 1
Training loss: 0.27798086404800415
Validation loss: 1.4522220473135672

Epoch: 5| Step: 2
Training loss: 0.17557910084724426
Validation loss: 1.4642499441741614

Epoch: 5| Step: 3
Training loss: 0.2817487418651581
Validation loss: 1.4416012699886034

Epoch: 5| Step: 4
Training loss: 0.16557565331459045
Validation loss: 1.4680183126080422

Epoch: 5| Step: 5
Training loss: 0.2422941029071808
Validation loss: 1.5424874008342784

Epoch: 5| Step: 6
Training loss: 0.25294557213783264
Validation loss: 1.576607669553449

Epoch: 5| Step: 7
Training loss: 0.2220498025417328
Validation loss: 1.574129585296877

Epoch: 5| Step: 8
Training loss: 0.23162809014320374
Validation loss: 1.5499756336212158

Epoch: 5| Step: 9
Training loss: 0.2148575335741043
Validation loss: 1.5410653314282816

Epoch: 5| Step: 10
Training loss: 0.2601448595523834
Validation loss: 1.4988771587289789

Epoch: 466| Step: 0
Training loss: 0.19307959079742432
Validation loss: 1.491373977353496

Epoch: 5| Step: 1
Training loss: 0.15233835577964783
Validation loss: 1.4790945732465355

Epoch: 5| Step: 2
Training loss: 0.15028616786003113
Validation loss: 1.4816001333216184

Epoch: 5| Step: 3
Training loss: 0.13561546802520752
Validation loss: 1.480746228207824

Epoch: 5| Step: 4
Training loss: 0.30414193868637085
Validation loss: 1.491722059506242

Epoch: 5| Step: 5
Training loss: 0.1835285723209381
Validation loss: 1.5149041247624222

Epoch: 5| Step: 6
Training loss: 0.1696646511554718
Validation loss: 1.5208857418388448

Epoch: 5| Step: 7
Training loss: 0.2154746949672699
Validation loss: 1.5353931521856656

Epoch: 5| Step: 8
Training loss: 0.39507779479026794
Validation loss: 1.512436802669238

Epoch: 5| Step: 9
Training loss: 0.2508115768432617
Validation loss: 1.5099788481189358

Epoch: 5| Step: 10
Training loss: 0.1919376254081726
Validation loss: 1.501635992398826

Epoch: 467| Step: 0
Training loss: 0.2496529370546341
Validation loss: 1.4656933302520423

Epoch: 5| Step: 1
Training loss: 0.1471250057220459
Validation loss: 1.4834140141805012

Epoch: 5| Step: 2
Training loss: 0.08635812252759933
Validation loss: 1.4903027242229832

Epoch: 5| Step: 3
Training loss: 0.3085630536079407
Validation loss: 1.496463776916586

Epoch: 5| Step: 4
Training loss: 0.22762207686901093
Validation loss: 1.4886908505552559

Epoch: 5| Step: 5
Training loss: 0.16861186921596527
Validation loss: 1.4713826346141037

Epoch: 5| Step: 6
Training loss: 0.19882217049598694
Validation loss: 1.4949448993129115

Epoch: 5| Step: 7
Training loss: 0.15520437061786652
Validation loss: 1.5050292130439513

Epoch: 5| Step: 8
Training loss: 0.2344191074371338
Validation loss: 1.5209851316226426

Epoch: 5| Step: 9
Training loss: 0.33375316858291626
Validation loss: 1.5172911799082192

Epoch: 5| Step: 10
Training loss: 0.23921430110931396
Validation loss: 1.5387872957414197

Epoch: 468| Step: 0
Training loss: 0.2094002217054367
Validation loss: 1.5511102855846446

Epoch: 5| Step: 1
Training loss: 0.15110667049884796
Validation loss: 1.5195364003540368

Epoch: 5| Step: 2
Training loss: 0.1370088905096054
Validation loss: 1.544659310771573

Epoch: 5| Step: 3
Training loss: 0.20971088111400604
Validation loss: 1.5393873927413777

Epoch: 5| Step: 4
Training loss: 0.22589127719402313
Validation loss: 1.5569681057365992

Epoch: 5| Step: 5
Training loss: 0.17779262363910675
Validation loss: 1.5200356462950348

Epoch: 5| Step: 6
Training loss: 0.3095986247062683
Validation loss: 1.5310422393583483

Epoch: 5| Step: 7
Training loss: 0.20644064247608185
Validation loss: 1.5864853294946815

Epoch: 5| Step: 8
Training loss: 0.23379477858543396
Validation loss: 1.6339718513591315

Epoch: 5| Step: 9
Training loss: 0.36025336384773254
Validation loss: 1.6276825807427848

Epoch: 5| Step: 10
Training loss: 0.3563918173313141
Validation loss: 1.6101362346321024

Epoch: 469| Step: 0
Training loss: 0.20472243428230286
Validation loss: 1.5530588934498448

Epoch: 5| Step: 1
Training loss: 0.21105635166168213
Validation loss: 1.4751175834286598

Epoch: 5| Step: 2
Training loss: 0.26842349767684937
Validation loss: 1.4759071706443705

Epoch: 5| Step: 3
Training loss: 0.2610532343387604
Validation loss: 1.4938120675343338

Epoch: 5| Step: 4
Training loss: 0.3835875689983368
Validation loss: 1.5329464879087222

Epoch: 5| Step: 5
Training loss: 0.30138567090034485
Validation loss: 1.4952569982056976

Epoch: 5| Step: 6
Training loss: 0.17985817790031433
Validation loss: 1.514753516002368

Epoch: 5| Step: 7
Training loss: 0.3854214549064636
Validation loss: 1.4894992895023798

Epoch: 5| Step: 8
Training loss: 0.3947373032569885
Validation loss: 1.5081418791124899

Epoch: 5| Step: 9
Training loss: 0.24196787178516388
Validation loss: 1.5887415870543449

Epoch: 5| Step: 10
Training loss: 0.29191553592681885
Validation loss: 1.6492950775290047

Epoch: 470| Step: 0
Training loss: 0.35468345880508423
Validation loss: 1.6899868480620845

Epoch: 5| Step: 1
Training loss: 0.2398630678653717
Validation loss: 1.6071995894114177

Epoch: 5| Step: 2
Training loss: 0.31214791536331177
Validation loss: 1.6054160107848465

Epoch: 5| Step: 3
Training loss: 0.2624194920063019
Validation loss: 1.5834366826600925

Epoch: 5| Step: 4
Training loss: 0.1760992705821991
Validation loss: 1.5498070537403066

Epoch: 5| Step: 5
Training loss: 0.2802680432796478
Validation loss: 1.5410393470077104

Epoch: 5| Step: 6
Training loss: 0.27438992261886597
Validation loss: 1.5412620216287591

Epoch: 5| Step: 7
Training loss: 0.3294474482536316
Validation loss: 1.5357090093756234

Epoch: 5| Step: 8
Training loss: 0.22868165373802185
Validation loss: 1.523666961218721

Epoch: 5| Step: 9
Training loss: 0.19557705521583557
Validation loss: 1.5187463837285196

Epoch: 5| Step: 10
Training loss: 0.18138134479522705
Validation loss: 1.5458766004090667

Epoch: 471| Step: 0
Training loss: 0.12063460052013397
Validation loss: 1.5867719996360041

Epoch: 5| Step: 1
Training loss: 0.14675526320934296
Validation loss: 1.6086123694655716

Epoch: 5| Step: 2
Training loss: 0.24664826691150665
Validation loss: 1.640880479607531

Epoch: 5| Step: 3
Training loss: 0.2328234612941742
Validation loss: 1.626404546922253

Epoch: 5| Step: 4
Training loss: 0.293374627828598
Validation loss: 1.6069093032549786

Epoch: 5| Step: 5
Training loss: 0.1923123300075531
Validation loss: 1.557607755866102

Epoch: 5| Step: 6
Training loss: 0.16580665111541748
Validation loss: 1.5369442393702846

Epoch: 5| Step: 7
Training loss: 0.23434238135814667
Validation loss: 1.5388913013601815

Epoch: 5| Step: 8
Training loss: 0.29111534357070923
Validation loss: 1.5243150034258444

Epoch: 5| Step: 9
Training loss: 0.13587318360805511
Validation loss: 1.535101516272432

Epoch: 5| Step: 10
Training loss: 0.20607073605060577
Validation loss: 1.5215535227970411

Epoch: 472| Step: 0
Training loss: 0.24697311222553253
Validation loss: 1.4993483411368502

Epoch: 5| Step: 1
Training loss: 0.11806619167327881
Validation loss: 1.5069100408143894

Epoch: 5| Step: 2
Training loss: 0.32855114340782166
Validation loss: 1.5260631403615397

Epoch: 5| Step: 3
Training loss: 0.16521668434143066
Validation loss: 1.5618135352288522

Epoch: 5| Step: 4
Training loss: 0.20918503403663635
Validation loss: 1.5577121601309827

Epoch: 5| Step: 5
Training loss: 0.17032891511917114
Validation loss: 1.5285646338616647

Epoch: 5| Step: 6
Training loss: 0.14463961124420166
Validation loss: 1.5097724891478015

Epoch: 5| Step: 7
Training loss: 0.2841159701347351
Validation loss: 1.521981095754972

Epoch: 5| Step: 8
Training loss: 0.2057712972164154
Validation loss: 1.5234291963679816

Epoch: 5| Step: 9
Training loss: 0.24080440402030945
Validation loss: 1.5225731275414909

Epoch: 5| Step: 10
Training loss: 0.28514423966407776
Validation loss: 1.5372545411509853

Epoch: 473| Step: 0
Training loss: 0.20754294097423553
Validation loss: 1.5521561958456551

Epoch: 5| Step: 1
Training loss: 0.27099609375
Validation loss: 1.5191866710621824

Epoch: 5| Step: 2
Training loss: 0.18196024000644684
Validation loss: 1.5185986603460004

Epoch: 5| Step: 3
Training loss: 0.13724704086780548
Validation loss: 1.4786189788131303

Epoch: 5| Step: 4
Training loss: 0.17227689921855927
Validation loss: 1.4808694739495554

Epoch: 5| Step: 5
Training loss: 0.18840405344963074
Validation loss: 1.4899851852847683

Epoch: 5| Step: 6
Training loss: 0.33388790488243103
Validation loss: 1.5039028031851656

Epoch: 5| Step: 7
Training loss: 0.15524229407310486
Validation loss: 1.515548038226302

Epoch: 5| Step: 8
Training loss: 0.2073482722043991
Validation loss: 1.4963644281510384

Epoch: 5| Step: 9
Training loss: 0.15068098902702332
Validation loss: 1.5207831654497372

Epoch: 5| Step: 10
Training loss: 0.18774661421775818
Validation loss: 1.4837435394205072

Epoch: 474| Step: 0
Training loss: 0.3122944235801697
Validation loss: 1.526843451684521

Epoch: 5| Step: 1
Training loss: 0.14217911660671234
Validation loss: 1.5253789514623664

Epoch: 5| Step: 2
Training loss: 0.2527603209018707
Validation loss: 1.508484983956942

Epoch: 5| Step: 3
Training loss: 0.16630807518959045
Validation loss: 1.5186235597056728

Epoch: 5| Step: 4
Training loss: 0.12240203469991684
Validation loss: 1.5342003696708268

Epoch: 5| Step: 5
Training loss: 0.18464159965515137
Validation loss: 1.5276023418672624

Epoch: 5| Step: 6
Training loss: 0.207821324467659
Validation loss: 1.5401374319548249

Epoch: 5| Step: 7
Training loss: 0.18359783291816711
Validation loss: 1.5282902256135018

Epoch: 5| Step: 8
Training loss: 0.19413171708583832
Validation loss: 1.5521693768039826

Epoch: 5| Step: 9
Training loss: 0.2344016283750534
Validation loss: 1.5391858072691067

Epoch: 5| Step: 10
Training loss: 0.12180668115615845
Validation loss: 1.5265341337009142

Epoch: 475| Step: 0
Training loss: 0.11200252920389175
Validation loss: 1.5035256749840193

Epoch: 5| Step: 1
Training loss: 0.2114146202802658
Validation loss: 1.4911298610830819

Epoch: 5| Step: 2
Training loss: 0.19506968557834625
Validation loss: 1.4845813884530017

Epoch: 5| Step: 3
Training loss: 0.17141368985176086
Validation loss: 1.462367175727762

Epoch: 5| Step: 4
Training loss: 0.2645406126976013
Validation loss: 1.5173165144458893

Epoch: 5| Step: 5
Training loss: 0.16590516269207
Validation loss: 1.5059722367153372

Epoch: 5| Step: 6
Training loss: 0.31199002265930176
Validation loss: 1.537079595750378

Epoch: 5| Step: 7
Training loss: 0.14575950801372528
Validation loss: 1.5622909427970968

Epoch: 5| Step: 8
Training loss: 0.20622022449970245
Validation loss: 1.5923841768695461

Epoch: 5| Step: 9
Training loss: 0.18514399230480194
Validation loss: 1.5748707376500612

Epoch: 5| Step: 10
Training loss: 0.23256659507751465
Validation loss: 1.5995853254871983

Epoch: 476| Step: 0
Training loss: 0.2301398515701294
Validation loss: 1.5945971191570323

Epoch: 5| Step: 1
Training loss: 0.11988961696624756
Validation loss: 1.546984326454901

Epoch: 5| Step: 2
Training loss: 0.2937689423561096
Validation loss: 1.5200523894320253

Epoch: 5| Step: 3
Training loss: 0.17509199678897858
Validation loss: 1.504867083282881

Epoch: 5| Step: 4
Training loss: 0.1779724806547165
Validation loss: 1.5063585107044508

Epoch: 5| Step: 5
Training loss: 0.19436590373516083
Validation loss: 1.5201644935915548

Epoch: 5| Step: 6
Training loss: 0.1325940638780594
Validation loss: 1.5333401362101238

Epoch: 5| Step: 7
Training loss: 0.20588107407093048
Validation loss: 1.5175158605780652

Epoch: 5| Step: 8
Training loss: 0.22792968153953552
Validation loss: 1.5080945543063584

Epoch: 5| Step: 9
Training loss: 0.2693396806716919
Validation loss: 1.4890434357427782

Epoch: 5| Step: 10
Training loss: 0.2074224203824997
Validation loss: 1.49627169229651

Epoch: 477| Step: 0
Training loss: 0.18059256672859192
Validation loss: 1.4884494786621423

Epoch: 5| Step: 1
Training loss: 0.13044080138206482
Validation loss: 1.4754196520774596

Epoch: 5| Step: 2
Training loss: 0.2032535821199417
Validation loss: 1.466585724584518

Epoch: 5| Step: 3
Training loss: 0.20621749758720398
Validation loss: 1.4939296354529679

Epoch: 5| Step: 4
Training loss: 0.2449566125869751
Validation loss: 1.488417956136888

Epoch: 5| Step: 5
Training loss: 0.1730504333972931
Validation loss: 1.4556728627092095

Epoch: 5| Step: 6
Training loss: 0.13249246776103973
Validation loss: 1.4912874211547196

Epoch: 5| Step: 7
Training loss: 0.19845812022686005
Validation loss: 1.4745506112293532

Epoch: 5| Step: 8
Training loss: 0.1902683824300766
Validation loss: 1.4558928884485716

Epoch: 5| Step: 9
Training loss: 0.18944308161735535
Validation loss: 1.474112860618099

Epoch: 5| Step: 10
Training loss: 0.4320076107978821
Validation loss: 1.4715695714437833

Epoch: 478| Step: 0
Training loss: 0.06710823625326157
Validation loss: 1.4714502493540447

Epoch: 5| Step: 1
Training loss: 0.18252339959144592
Validation loss: 1.4590043662696757

Epoch: 5| Step: 2
Training loss: 0.18578660488128662
Validation loss: 1.4707862536112468

Epoch: 5| Step: 3
Training loss: 0.16259093582630157
Validation loss: 1.4673815734924809

Epoch: 5| Step: 4
Training loss: 0.21759851276874542
Validation loss: 1.4915997853843115

Epoch: 5| Step: 5
Training loss: 0.1271875947713852
Validation loss: 1.5052634234069495

Epoch: 5| Step: 6
Training loss: 0.14498820900917053
Validation loss: 1.5517496498682166

Epoch: 5| Step: 7
Training loss: 0.19202463328838348
Validation loss: 1.5347881060774609

Epoch: 5| Step: 8
Training loss: 0.3630976676940918
Validation loss: 1.5398863207909368

Epoch: 5| Step: 9
Training loss: 0.10292600095272064
Validation loss: 1.5248484053919393

Epoch: 5| Step: 10
Training loss: 0.20711688697338104
Validation loss: 1.5126796832648657

Epoch: 479| Step: 0
Training loss: 0.08669153600931168
Validation loss: 1.4965851499188332

Epoch: 5| Step: 1
Training loss: 0.07619403302669525
Validation loss: 1.4915494252276678

Epoch: 5| Step: 2
Training loss: 0.2642154395580292
Validation loss: 1.4820080521286174

Epoch: 5| Step: 3
Training loss: 0.2329854965209961
Validation loss: 1.4476102161151108

Epoch: 5| Step: 4
Training loss: 0.18751797080039978
Validation loss: 1.4678498929546726

Epoch: 5| Step: 5
Training loss: 0.12896934151649475
Validation loss: 1.461531041770853

Epoch: 5| Step: 6
Training loss: 0.18866121768951416
Validation loss: 1.4606013862035607

Epoch: 5| Step: 7
Training loss: 0.15987162292003632
Validation loss: 1.4586604551602436

Epoch: 5| Step: 8
Training loss: 0.13038477301597595
Validation loss: 1.4737230513685493

Epoch: 5| Step: 9
Training loss: 0.18782342970371246
Validation loss: 1.455084349519463

Epoch: 5| Step: 10
Training loss: 0.27571573853492737
Validation loss: 1.4504298753635858

Epoch: 480| Step: 0
Training loss: 0.14139656722545624
Validation loss: 1.450859450524853

Epoch: 5| Step: 1
Training loss: 0.13782340288162231
Validation loss: 1.4517851503946448

Epoch: 5| Step: 2
Training loss: 0.13406649231910706
Validation loss: 1.4537444704322404

Epoch: 5| Step: 3
Training loss: 0.11178608238697052
Validation loss: 1.4521364781164354

Epoch: 5| Step: 4
Training loss: 0.169484943151474
Validation loss: 1.4564420888500829

Epoch: 5| Step: 5
Training loss: 0.2066815346479416
Validation loss: 1.4468546246969571

Epoch: 5| Step: 6
Training loss: 0.28393638134002686
Validation loss: 1.4762507113077308

Epoch: 5| Step: 7
Training loss: 0.1451011449098587
Validation loss: 1.4708537875965078

Epoch: 5| Step: 8
Training loss: 0.22120144963264465
Validation loss: 1.4608379422977407

Epoch: 5| Step: 9
Training loss: 0.11445622146129608
Validation loss: 1.4665720610208408

Epoch: 5| Step: 10
Training loss: 0.18268680572509766
Validation loss: 1.499641392820625

Epoch: 481| Step: 0
Training loss: 0.10570278018712997
Validation loss: 1.5276007934283184

Epoch: 5| Step: 1
Training loss: 0.14698752760887146
Validation loss: 1.4819536260379258

Epoch: 5| Step: 2
Training loss: 0.18387660384178162
Validation loss: 1.4846930170571933

Epoch: 5| Step: 3
Training loss: 0.14225785434246063
Validation loss: 1.4967583776802145

Epoch: 5| Step: 4
Training loss: 0.19773979485034943
Validation loss: 1.4802858996134933

Epoch: 5| Step: 5
Training loss: 0.1626008301973343
Validation loss: 1.5084816896787254

Epoch: 5| Step: 6
Training loss: 0.2649994194507599
Validation loss: 1.5004841268703502

Epoch: 5| Step: 7
Training loss: 0.27726686000823975
Validation loss: 1.5479519399263526

Epoch: 5| Step: 8
Training loss: 0.11108021438121796
Validation loss: 1.5509031177848898

Epoch: 5| Step: 9
Training loss: 0.30742883682250977
Validation loss: 1.6045701926754368

Epoch: 5| Step: 10
Training loss: 0.19955791532993317
Validation loss: 1.6124188771811865

Epoch: 482| Step: 0
Training loss: 0.23043498396873474
Validation loss: 1.5354002227065384

Epoch: 5| Step: 1
Training loss: 0.17111189663410187
Validation loss: 1.4452610605506486

Epoch: 5| Step: 2
Training loss: 0.2988416850566864
Validation loss: 1.4774748612475652

Epoch: 5| Step: 3
Training loss: 0.20849354565143585
Validation loss: 1.4690449955642864

Epoch: 5| Step: 4
Training loss: 0.28688544034957886
Validation loss: 1.4727935355196717

Epoch: 5| Step: 5
Training loss: 0.17876717448234558
Validation loss: 1.453426613602587

Epoch: 5| Step: 6
Training loss: 0.13171085715293884
Validation loss: 1.4791182561587262

Epoch: 5| Step: 7
Training loss: 0.2055548131465912
Validation loss: 1.518906327985948

Epoch: 5| Step: 8
Training loss: 0.14875677227973938
Validation loss: 1.5102747871029762

Epoch: 5| Step: 9
Training loss: 0.30242881178855896
Validation loss: 1.5856827997392224

Epoch: 5| Step: 10
Training loss: 0.1858440339565277
Validation loss: 1.6398038723135506

Epoch: 483| Step: 0
Training loss: 0.22753775119781494
Validation loss: 1.638240510417569

Epoch: 5| Step: 1
Training loss: 0.17126597464084625
Validation loss: 1.6273785432179768

Epoch: 5| Step: 2
Training loss: 0.16676871478557587
Validation loss: 1.5968883114476358

Epoch: 5| Step: 3
Training loss: 0.23025532066822052
Validation loss: 1.572104646313575

Epoch: 5| Step: 4
Training loss: 0.22745370864868164
Validation loss: 1.5565335071215065

Epoch: 5| Step: 5
Training loss: 0.1562868356704712
Validation loss: 1.5490553943059777

Epoch: 5| Step: 6
Training loss: 0.0944833979010582
Validation loss: 1.5246300505053612

Epoch: 5| Step: 7
Training loss: 0.26975154876708984
Validation loss: 1.5364462765314246

Epoch: 5| Step: 8
Training loss: 0.26150354743003845
Validation loss: 1.5369384570788311

Epoch: 5| Step: 9
Training loss: 0.1993902623653412
Validation loss: 1.536133308564463

Epoch: 5| Step: 10
Training loss: 0.16232751309871674
Validation loss: 1.5605853872914468

Epoch: 484| Step: 0
Training loss: 0.14652405679225922
Validation loss: 1.5366470615069072

Epoch: 5| Step: 1
Training loss: 0.20989331603050232
Validation loss: 1.547723679132359

Epoch: 5| Step: 2
Training loss: 0.18513408303260803
Validation loss: 1.5130935317726546

Epoch: 5| Step: 3
Training loss: 0.11253829300403595
Validation loss: 1.5030353402578702

Epoch: 5| Step: 4
Training loss: 0.27430564165115356
Validation loss: 1.481974978600779

Epoch: 5| Step: 5
Training loss: 0.1774933785200119
Validation loss: 1.468144182235964

Epoch: 5| Step: 6
Training loss: 0.13465392589569092
Validation loss: 1.4794808215992425

Epoch: 5| Step: 7
Training loss: 0.3734693229198456
Validation loss: 1.4742772053646784

Epoch: 5| Step: 8
Training loss: 0.17228345572948456
Validation loss: 1.5158554072021155

Epoch: 5| Step: 9
Training loss: 0.11225523799657822
Validation loss: 1.4941374691583778

Epoch: 5| Step: 10
Training loss: 0.2006845772266388
Validation loss: 1.585242599569341

Epoch: 485| Step: 0
Training loss: 0.23605510592460632
Validation loss: 1.6227826238960348

Epoch: 5| Step: 1
Training loss: 0.23759880661964417
Validation loss: 1.6095120009555612

Epoch: 5| Step: 2
Training loss: 0.16440236568450928
Validation loss: 1.5975389865136915

Epoch: 5| Step: 3
Training loss: 0.10459218919277191
Validation loss: 1.5293346399902015

Epoch: 5| Step: 4
Training loss: 0.14439712464809418
Validation loss: 1.4901702923159446

Epoch: 5| Step: 5
Training loss: 0.22353991866111755
Validation loss: 1.491811861274063

Epoch: 5| Step: 6
Training loss: 0.316850483417511
Validation loss: 1.497298849526272

Epoch: 5| Step: 7
Training loss: 0.40536659955978394
Validation loss: 1.488702074173958

Epoch: 5| Step: 8
Training loss: 0.2137213945388794
Validation loss: 1.4785182194043232

Epoch: 5| Step: 9
Training loss: 0.10515318065881729
Validation loss: 1.5072783603463122

Epoch: 5| Step: 10
Training loss: 0.29156410694122314
Validation loss: 1.5394983406989806

Epoch: 486| Step: 0
Training loss: 0.1367897242307663
Validation loss: 1.5377706776383102

Epoch: 5| Step: 1
Training loss: 0.22574882209300995
Validation loss: 1.5868947531587334

Epoch: 5| Step: 2
Training loss: 0.15518450736999512
Validation loss: 1.5545480905040618

Epoch: 5| Step: 3
Training loss: 0.15069617331027985
Validation loss: 1.502229586724312

Epoch: 5| Step: 4
Training loss: 0.2100096493959427
Validation loss: 1.492772646488682

Epoch: 5| Step: 5
Training loss: 0.17538681626319885
Validation loss: 1.4897165452280352

Epoch: 5| Step: 6
Training loss: 0.16404502093791962
Validation loss: 1.4648206733888196

Epoch: 5| Step: 7
Training loss: 0.16594290733337402
Validation loss: 1.4599128615471624

Epoch: 5| Step: 8
Training loss: 0.3636600375175476
Validation loss: 1.4752766893756004

Epoch: 5| Step: 9
Training loss: 0.1175759881734848
Validation loss: 1.463849433647689

Epoch: 5| Step: 10
Training loss: 0.16544893383979797
Validation loss: 1.4841713110605876

Epoch: 487| Step: 0
Training loss: 0.20338980853557587
Validation loss: 1.5312984297352452

Epoch: 5| Step: 1
Training loss: 0.13958409428596497
Validation loss: 1.5107854668812086

Epoch: 5| Step: 2
Training loss: 0.07926950603723526
Validation loss: 1.5083928197942755

Epoch: 5| Step: 3
Training loss: 0.12547875940799713
Validation loss: 1.4777352092086629

Epoch: 5| Step: 4
Training loss: 0.20627529919147491
Validation loss: 1.4968362034008067

Epoch: 5| Step: 5
Training loss: 0.2704208493232727
Validation loss: 1.4949202204263339

Epoch: 5| Step: 6
Training loss: 0.14914089441299438
Validation loss: 1.493951726985234

Epoch: 5| Step: 7
Training loss: 0.19105401635169983
Validation loss: 1.4980446510417487

Epoch: 5| Step: 8
Training loss: 0.14017745852470398
Validation loss: 1.5036942920377177

Epoch: 5| Step: 9
Training loss: 0.20600676536560059
Validation loss: 1.5119130188418972

Epoch: 5| Step: 10
Training loss: 0.08890765905380249
Validation loss: 1.5399849799371534

Epoch: 488| Step: 0
Training loss: 0.20448076725006104
Validation loss: 1.5296572549368745

Epoch: 5| Step: 1
Training loss: 0.17345163226127625
Validation loss: 1.528704894486294

Epoch: 5| Step: 2
Training loss: 0.10887473821640015
Validation loss: 1.4729899526924215

Epoch: 5| Step: 3
Training loss: 0.11326687037944794
Validation loss: 1.5040535439727127

Epoch: 5| Step: 4
Training loss: 0.08991704136133194
Validation loss: 1.4811265122505926

Epoch: 5| Step: 5
Training loss: 0.15559044480323792
Validation loss: 1.4875125603009296

Epoch: 5| Step: 6
Training loss: 0.13706310093402863
Validation loss: 1.5027832831105878

Epoch: 5| Step: 7
Training loss: 0.22271029651165009
Validation loss: 1.4595910567109303

Epoch: 5| Step: 8
Training loss: 0.3348831534385681
Validation loss: 1.4495740955875767

Epoch: 5| Step: 9
Training loss: 0.20500239729881287
Validation loss: 1.440227972563877

Epoch: 5| Step: 10
Training loss: 0.11743064224720001
Validation loss: 1.4853544542866368

Epoch: 489| Step: 0
Training loss: 0.18090179562568665
Validation loss: 1.4858729647051903

Epoch: 5| Step: 1
Training loss: 0.14661984145641327
Validation loss: 1.4704188928809216

Epoch: 5| Step: 2
Training loss: 0.18628402054309845
Validation loss: 1.4775194634673416

Epoch: 5| Step: 3
Training loss: 0.12908773124217987
Validation loss: 1.4775313965735897

Epoch: 5| Step: 4
Training loss: 0.10074695199728012
Validation loss: 1.47221835454305

Epoch: 5| Step: 5
Training loss: 0.2638927698135376
Validation loss: 1.4928328926845262

Epoch: 5| Step: 6
Training loss: 0.1799892634153366
Validation loss: 1.4667704182286416

Epoch: 5| Step: 7
Training loss: 0.12562498450279236
Validation loss: 1.495579178615283

Epoch: 5| Step: 8
Training loss: 0.17542271316051483
Validation loss: 1.5114231135255547

Epoch: 5| Step: 9
Training loss: 0.09525789320468903
Validation loss: 1.497129278798257

Epoch: 5| Step: 10
Training loss: 0.17913663387298584
Validation loss: 1.5071906133364605

Epoch: 490| Step: 0
Training loss: 0.1238340362906456
Validation loss: 1.5028038396630237

Epoch: 5| Step: 1
Training loss: 0.19441933929920197
Validation loss: 1.5175096373404227

Epoch: 5| Step: 2
Training loss: 0.1456637680530548
Validation loss: 1.540852181373104

Epoch: 5| Step: 3
Training loss: 0.12779542803764343
Validation loss: 1.5202735604778412

Epoch: 5| Step: 4
Training loss: 0.12763801217079163
Validation loss: 1.5167689105515838

Epoch: 5| Step: 5
Training loss: 0.14280465245246887
Validation loss: 1.507340588877278

Epoch: 5| Step: 6
Training loss: 0.13090968132019043
Validation loss: 1.5121930388994114

Epoch: 5| Step: 7
Training loss: 0.23429366946220398
Validation loss: 1.4850285232708018

Epoch: 5| Step: 8
Training loss: 0.08400609344244003
Validation loss: 1.4679982457109677

Epoch: 5| Step: 9
Training loss: 0.25207582116127014
Validation loss: 1.4709446699388566

Epoch: 5| Step: 10
Training loss: 0.10892211645841599
Validation loss: 1.4725725843060402

Epoch: 491| Step: 0
Training loss: 0.132626473903656
Validation loss: 1.484402246372674

Epoch: 5| Step: 1
Training loss: 0.1165076345205307
Validation loss: 1.5035484106309953

Epoch: 5| Step: 2
Training loss: 0.2621755003929138
Validation loss: 1.5500318478512507

Epoch: 5| Step: 3
Training loss: 0.20017245411872864
Validation loss: 1.52742394708818

Epoch: 5| Step: 4
Training loss: 0.1894671618938446
Validation loss: 1.5076371021168207

Epoch: 5| Step: 5
Training loss: 0.1318308413028717
Validation loss: 1.4930807364884244

Epoch: 5| Step: 6
Training loss: 0.13684168457984924
Validation loss: 1.5177490531757314

Epoch: 5| Step: 7
Training loss: 0.15286487340927124
Validation loss: 1.5091780603572886

Epoch: 5| Step: 8
Training loss: 0.2452239990234375
Validation loss: 1.5364391919105285

Epoch: 5| Step: 9
Training loss: 0.08130989968776703
Validation loss: 1.538611428712004

Epoch: 5| Step: 10
Training loss: 0.1278691589832306
Validation loss: 1.5716732714765815

Epoch: 492| Step: 0
Training loss: 0.21360032260417938
Validation loss: 1.567282102441275

Epoch: 5| Step: 1
Training loss: 0.085008904337883
Validation loss: 1.5788734215562061

Epoch: 5| Step: 2
Training loss: 0.12258145958185196
Validation loss: 1.534475621356759

Epoch: 5| Step: 3
Training loss: 0.14080336689949036
Validation loss: 1.5356476281278877

Epoch: 5| Step: 4
Training loss: 0.21350626647472382
Validation loss: 1.5432699790564917

Epoch: 5| Step: 5
Training loss: 0.12834294140338898
Validation loss: 1.4965134782175864

Epoch: 5| Step: 6
Training loss: 0.0863865539431572
Validation loss: 1.4960664600454352

Epoch: 5| Step: 7
Training loss: 0.1112472265958786
Validation loss: 1.480074148024282

Epoch: 5| Step: 8
Training loss: 0.21704871952533722
Validation loss: 1.4650680980374735

Epoch: 5| Step: 9
Training loss: 0.21512000262737274
Validation loss: 1.4816662182090103

Epoch: 5| Step: 10
Training loss: 0.15835720300674438
Validation loss: 1.5095193655260148

Epoch: 493| Step: 0
Training loss: 0.16217775642871857
Validation loss: 1.4925700349192466

Epoch: 5| Step: 1
Training loss: 0.21794863045215607
Validation loss: 1.4929707691233645

Epoch: 5| Step: 2
Training loss: 0.08413441479206085
Validation loss: 1.4874342154431086

Epoch: 5| Step: 3
Training loss: 0.09478878974914551
Validation loss: 1.4794726781947638

Epoch: 5| Step: 4
Training loss: 0.10839362442493439
Validation loss: 1.4859500879882483

Epoch: 5| Step: 5
Training loss: 0.11798908561468124
Validation loss: 1.4796287757094189

Epoch: 5| Step: 6
Training loss: 0.2132687121629715
Validation loss: 1.5018671892022575

Epoch: 5| Step: 7
Training loss: 0.18654665350914001
Validation loss: 1.5360376360595867

Epoch: 5| Step: 8
Training loss: 0.15112842619419098
Validation loss: 1.5423081472355833

Epoch: 5| Step: 9
Training loss: 0.19848163425922394
Validation loss: 1.5554780908810195

Epoch: 5| Step: 10
Training loss: 0.08609563112258911
Validation loss: 1.5422080345051263

Epoch: 494| Step: 0
Training loss: 0.06307919323444366
Validation loss: 1.510081498853622

Epoch: 5| Step: 1
Training loss: 0.1480175256729126
Validation loss: 1.5035074833900697

Epoch: 5| Step: 2
Training loss: 0.15118788182735443
Validation loss: 1.4867701286910682

Epoch: 5| Step: 3
Training loss: 0.10111091285943985
Validation loss: 1.5019131040060392

Epoch: 5| Step: 4
Training loss: 0.1571573168039322
Validation loss: 1.5011207621584657

Epoch: 5| Step: 5
Training loss: 0.2679195702075958
Validation loss: 1.479341749222048

Epoch: 5| Step: 6
Training loss: 0.10602553188800812
Validation loss: 1.4951966321596535

Epoch: 5| Step: 7
Training loss: 0.22536113858222961
Validation loss: 1.5065378219850603

Epoch: 5| Step: 8
Training loss: 0.11903230845928192
Validation loss: 1.481015157955949

Epoch: 5| Step: 9
Training loss: 0.12132225930690765
Validation loss: 1.501189742037045

Epoch: 5| Step: 10
Training loss: 0.10663291811943054
Validation loss: 1.526259587657067

Epoch: 495| Step: 0
Training loss: 0.16211654245853424
Validation loss: 1.5089932923675866

Epoch: 5| Step: 1
Training loss: 0.14477550983428955
Validation loss: 1.518628538295787

Epoch: 5| Step: 2
Training loss: 0.10396143049001694
Validation loss: 1.4881428210966048

Epoch: 5| Step: 3
Training loss: 0.14803652465343475
Validation loss: 1.4857274498990787

Epoch: 5| Step: 4
Training loss: 0.1550627052783966
Validation loss: 1.4489931060421852

Epoch: 5| Step: 5
Training loss: 0.10901667922735214
Validation loss: 1.4753326895416423

Epoch: 5| Step: 6
Training loss: 0.08497577905654907
Validation loss: 1.4917872272511965

Epoch: 5| Step: 7
Training loss: 0.11096428334712982
Validation loss: 1.5090524727298367

Epoch: 5| Step: 8
Training loss: 0.21126608550548553
Validation loss: 1.5030743575865222

Epoch: 5| Step: 9
Training loss: 0.2769484221935272
Validation loss: 1.511977449540169

Epoch: 5| Step: 10
Training loss: 0.18583469092845917
Validation loss: 1.5395991597124326

Epoch: 496| Step: 0
Training loss: 0.1331625133752823
Validation loss: 1.5721111912881174

Epoch: 5| Step: 1
Training loss: 0.1599278450012207
Validation loss: 1.5402908325195312

Epoch: 5| Step: 2
Training loss: 0.2109605371952057
Validation loss: 1.5231438888016569

Epoch: 5| Step: 3
Training loss: 0.17310380935668945
Validation loss: 1.5076647253446682

Epoch: 5| Step: 4
Training loss: 0.20847001671791077
Validation loss: 1.4863215223435433

Epoch: 5| Step: 5
Training loss: 0.11057746410369873
Validation loss: 1.4997773093561972

Epoch: 5| Step: 6
Training loss: 0.19599968194961548
Validation loss: 1.4900385795101043

Epoch: 5| Step: 7
Training loss: 0.15113547444343567
Validation loss: 1.4920314114580873

Epoch: 5| Step: 8
Training loss: 0.1188521608710289
Validation loss: 1.5065660348502539

Epoch: 5| Step: 9
Training loss: 0.13246479630470276
Validation loss: 1.50575682937458

Epoch: 5| Step: 10
Training loss: 0.1376950442790985
Validation loss: 1.5042972436515234

Epoch: 497| Step: 0
Training loss: 0.1365637481212616
Validation loss: 1.4781239724928332

Epoch: 5| Step: 1
Training loss: 0.3150401711463928
Validation loss: 1.5080244297622352

Epoch: 5| Step: 2
Training loss: 0.11337929964065552
Validation loss: 1.4602138688487392

Epoch: 5| Step: 3
Training loss: 0.12425170838832855
Validation loss: 1.466928469237461

Epoch: 5| Step: 4
Training loss: 0.08052544295787811
Validation loss: 1.5009665181559901

Epoch: 5| Step: 5
Training loss: 0.14817821979522705
Validation loss: 1.4967576431971725

Epoch: 5| Step: 6
Training loss: 0.19322629272937775
Validation loss: 1.5168648548023675

Epoch: 5| Step: 7
Training loss: 0.07188813388347626
Validation loss: 1.4983329285857498

Epoch: 5| Step: 8
Training loss: 0.1650283932685852
Validation loss: 1.49497571363244

Epoch: 5| Step: 9
Training loss: 0.1278531700372696
Validation loss: 1.4781586252233034

Epoch: 5| Step: 10
Training loss: 0.13588249683380127
Validation loss: 1.4967678387959797

Epoch: 498| Step: 0
Training loss: 0.15953680872917175
Validation loss: 1.4991063161562848

Epoch: 5| Step: 1
Training loss: 0.16843782365322113
Validation loss: 1.4967465413514005

Epoch: 5| Step: 2
Training loss: 0.11277111619710922
Validation loss: 1.5001992589683943

Epoch: 5| Step: 3
Training loss: 0.1449536234140396
Validation loss: 1.5290450152530466

Epoch: 5| Step: 4
Training loss: 0.17938540875911713
Validation loss: 1.5396800195017168

Epoch: 5| Step: 5
Training loss: 0.1978466808795929
Validation loss: 1.5646542964443084

Epoch: 5| Step: 6
Training loss: 0.176548033952713
Validation loss: 1.6053741785787767

Epoch: 5| Step: 7
Training loss: 0.20230114459991455
Validation loss: 1.5901748429062545

Epoch: 5| Step: 8
Training loss: 0.1221795529127121
Validation loss: 1.5696541058119906

Epoch: 5| Step: 9
Training loss: 0.34226900339126587
Validation loss: 1.5631606425008466

Epoch: 5| Step: 10
Training loss: 0.09645327925682068
Validation loss: 1.5297845986581617

Epoch: 499| Step: 0
Training loss: 0.15852968394756317
Validation loss: 1.4818745249061174

Epoch: 5| Step: 1
Training loss: 0.11058330535888672
Validation loss: 1.4784368058686614

Epoch: 5| Step: 2
Training loss: 0.24615705013275146
Validation loss: 1.4759910478386828

Epoch: 5| Step: 3
Training loss: 0.1251734048128128
Validation loss: 1.4496069057013399

Epoch: 5| Step: 4
Training loss: 0.15163056552410126
Validation loss: 1.4627883876523664

Epoch: 5| Step: 5
Training loss: 0.15702968835830688
Validation loss: 1.51336540842569

Epoch: 5| Step: 6
Training loss: 0.2104337513446808
Validation loss: 1.5002991742985223

Epoch: 5| Step: 7
Training loss: 0.33912578225135803
Validation loss: 1.5066759676061652

Epoch: 5| Step: 8
Training loss: 0.16176947951316833
Validation loss: 1.4911254798212359

Epoch: 5| Step: 9
Training loss: 0.1508060097694397
Validation loss: 1.4703243278688

Epoch: 5| Step: 10
Training loss: 0.14777062833309174
Validation loss: 1.4838651239231069

Epoch: 500| Step: 0
Training loss: 0.2497241050004959
Validation loss: 1.4967041887262815

Epoch: 5| Step: 1
Training loss: 0.1475270837545395
Validation loss: 1.505128420809264

Epoch: 5| Step: 2
Training loss: 0.12866131961345673
Validation loss: 1.5483319964460147

Epoch: 5| Step: 3
Training loss: 0.1868119239807129
Validation loss: 1.5354641137584564

Epoch: 5| Step: 4
Training loss: 0.19847612082958221
Validation loss: 1.533845470797631

Epoch: 5| Step: 5
Training loss: 0.09474401921033859
Validation loss: 1.5277436664027553

Epoch: 5| Step: 6
Training loss: 0.18633660674095154
Validation loss: 1.517601195202079

Epoch: 5| Step: 7
Training loss: 0.11279395967721939
Validation loss: 1.5020183901632986

Epoch: 5| Step: 8
Training loss: 0.10949152708053589
Validation loss: 1.4903702492355018

Epoch: 5| Step: 9
Training loss: 0.17612610757350922
Validation loss: 1.5167157393629833

Epoch: 5| Step: 10
Training loss: 0.17845773696899414
Validation loss: 1.4804913023466706

Epoch: 501| Step: 0
Training loss: 0.1477297991514206
Validation loss: 1.467709328538628

Epoch: 5| Step: 1
Training loss: 0.18511979281902313
Validation loss: 1.4394485232650593

Epoch: 5| Step: 2
Training loss: 0.1264149397611618
Validation loss: 1.456976290672056

Epoch: 5| Step: 3
Training loss: 0.14846600592136383
Validation loss: 1.4746471925448346

Epoch: 5| Step: 4
Training loss: 0.15127505362033844
Validation loss: 1.466677769537895

Epoch: 5| Step: 5
Training loss: 0.28112566471099854
Validation loss: 1.4732205098675144

Epoch: 5| Step: 6
Training loss: 0.265532910823822
Validation loss: 1.4830717348283338

Epoch: 5| Step: 7
Training loss: 0.10712740570306778
Validation loss: 1.4998294025339105

Epoch: 5| Step: 8
Training loss: 0.14026252925395966
Validation loss: 1.56203285724886

Epoch: 5| Step: 9
Training loss: 0.2216208279132843
Validation loss: 1.5680834618947839

Epoch: 5| Step: 10
Training loss: 0.15699125826358795
Validation loss: 1.5373612238514809

Epoch: 502| Step: 0
Training loss: 0.22361811995506287
Validation loss: 1.4873840796050204

Epoch: 5| Step: 1
Training loss: 0.13960620760917664
Validation loss: 1.4847303500739477

Epoch: 5| Step: 2
Training loss: 0.1309802234172821
Validation loss: 1.4715693099524385

Epoch: 5| Step: 3
Training loss: 0.26858586072921753
Validation loss: 1.4568683947286298

Epoch: 5| Step: 4
Training loss: 0.22602638602256775
Validation loss: 1.4627205774348269

Epoch: 5| Step: 5
Training loss: 0.22424912452697754
Validation loss: 1.4909896055857341

Epoch: 5| Step: 6
Training loss: 0.19053097069263458
Validation loss: 1.4739735177768174

Epoch: 5| Step: 7
Training loss: 0.14157220721244812
Validation loss: 1.4724827069108204

Epoch: 5| Step: 8
Training loss: 0.1739681214094162
Validation loss: 1.4727087033692228

Epoch: 5| Step: 9
Training loss: 0.21383972465991974
Validation loss: 1.4740397199507682

Epoch: 5| Step: 10
Training loss: 0.1135396659374237
Validation loss: 1.5122529140082739

Epoch: 503| Step: 0
Training loss: 0.20194080471992493
Validation loss: 1.5178030703657417

Epoch: 5| Step: 1
Training loss: 0.16145989298820496
Validation loss: 1.5784283414963753

Epoch: 5| Step: 2
Training loss: 0.16535192728042603
Validation loss: 1.6084764208844913

Epoch: 5| Step: 3
Training loss: 0.22631821036338806
Validation loss: 1.6067280154074393

Epoch: 5| Step: 4
Training loss: 0.15298844873905182
Validation loss: 1.590002231700446

Epoch: 5| Step: 5
Training loss: 0.23863878846168518
Validation loss: 1.5331483733269475

Epoch: 5| Step: 6
Training loss: 0.23576898872852325
Validation loss: 1.5143092716893842

Epoch: 5| Step: 7
Training loss: 0.20428431034088135
Validation loss: 1.4881826126447288

Epoch: 5| Step: 8
Training loss: 0.1904357671737671
Validation loss: 1.4729660621253393

Epoch: 5| Step: 9
Training loss: 0.21716062724590302
Validation loss: 1.4791793041331793

Epoch: 5| Step: 10
Training loss: 0.17166605591773987
Validation loss: 1.4790119035269624

Epoch: 504| Step: 0
Training loss: 0.19973447918891907
Validation loss: 1.5113116323306997

Epoch: 5| Step: 1
Training loss: 0.23734906315803528
Validation loss: 1.4860337741913334

Epoch: 5| Step: 2
Training loss: 0.2219821959733963
Validation loss: 1.5216488524149823

Epoch: 5| Step: 3
Training loss: 0.19945740699768066
Validation loss: 1.5184588522039435

Epoch: 5| Step: 4
Training loss: 0.1483580321073532
Validation loss: 1.5223734763360792

Epoch: 5| Step: 5
Training loss: 0.09113369882106781
Validation loss: 1.4854150151693692

Epoch: 5| Step: 6
Training loss: 0.11148693412542343
Validation loss: 1.4792149041288642

Epoch: 5| Step: 7
Training loss: 0.12446025758981705
Validation loss: 1.4471332898703955

Epoch: 5| Step: 8
Training loss: 0.1811562478542328
Validation loss: 1.4618809864085207

Epoch: 5| Step: 9
Training loss: 0.22449155151844025
Validation loss: 1.46745119812668

Epoch: 5| Step: 10
Training loss: 0.162959486246109
Validation loss: 1.497052639402369

Epoch: 505| Step: 0
Training loss: 0.1307186335325241
Validation loss: 1.472749553700929

Epoch: 5| Step: 1
Training loss: 0.11683128029108047
Validation loss: 1.5145281957041832

Epoch: 5| Step: 2
Training loss: 0.2390308827161789
Validation loss: 1.5438056222854122

Epoch: 5| Step: 3
Training loss: 0.17895367741584778
Validation loss: 1.524800301879965

Epoch: 5| Step: 4
Training loss: 0.08107991516590118
Validation loss: 1.538081854261378

Epoch: 5| Step: 5
Training loss: 0.13458773493766785
Validation loss: 1.5536279152798396

Epoch: 5| Step: 6
Training loss: 0.2323930710554123
Validation loss: 1.4836975553984284

Epoch: 5| Step: 7
Training loss: 0.11617457866668701
Validation loss: 1.5222214345009095

Epoch: 5| Step: 8
Training loss: 0.14890022575855255
Validation loss: 1.4944233573893064

Epoch: 5| Step: 9
Training loss: 0.2820931077003479
Validation loss: 1.4761364203627392

Epoch: 5| Step: 10
Training loss: 0.13153624534606934
Validation loss: 1.4620403641013688

Epoch: 506| Step: 0
Training loss: 0.17168104648590088
Validation loss: 1.4736893100123252

Epoch: 5| Step: 1
Training loss: 0.13142986595630646
Validation loss: 1.4722442626953125

Epoch: 5| Step: 2
Training loss: 0.16258136928081512
Validation loss: 1.4701783323800692

Epoch: 5| Step: 3
Training loss: 0.14381243288516998
Validation loss: 1.4929526070112824

Epoch: 5| Step: 4
Training loss: 0.17546594142913818
Validation loss: 1.4757189109761228

Epoch: 5| Step: 5
Training loss: 0.10195569694042206
Validation loss: 1.4874521173456663

Epoch: 5| Step: 6
Training loss: 0.15207837522029877
Validation loss: 1.4835277116426857

Epoch: 5| Step: 7
Training loss: 0.09492748975753784
Validation loss: 1.5290089012474142

Epoch: 5| Step: 8
Training loss: 0.3151944577693939
Validation loss: 1.471260864247558

Epoch: 5| Step: 9
Training loss: 0.15895284712314606
Validation loss: 1.4912337628743981

Epoch: 5| Step: 10
Training loss: 0.1316806972026825
Validation loss: 1.479101623258283

Epoch: 507| Step: 0
Training loss: 0.19132594764232635
Validation loss: 1.4801587545743553

Epoch: 5| Step: 1
Training loss: 0.07244940847158432
Validation loss: 1.477131917912473

Epoch: 5| Step: 2
Training loss: 0.08176742494106293
Validation loss: 1.4641802951853762

Epoch: 5| Step: 3
Training loss: 0.17258308827877045
Validation loss: 1.4584392270734232

Epoch: 5| Step: 4
Training loss: 0.119123674929142
Validation loss: 1.4500143861257901

Epoch: 5| Step: 5
Training loss: 0.23734398186206818
Validation loss: 1.4533912289527156

Epoch: 5| Step: 6
Training loss: 0.14347153902053833
Validation loss: 1.4629778631271855

Epoch: 5| Step: 7
Training loss: 0.13933899998664856
Validation loss: 1.4398512891543809

Epoch: 5| Step: 8
Training loss: 0.08774325996637344
Validation loss: 1.4502674264292563

Epoch: 5| Step: 9
Training loss: 0.2577812671661377
Validation loss: 1.4426287912553357

Epoch: 5| Step: 10
Training loss: 0.2903445363044739
Validation loss: 1.4236973062638314

Epoch: 508| Step: 0
Training loss: 0.16903527081012726
Validation loss: 1.427851470567847

Epoch: 5| Step: 1
Training loss: 0.1794205605983734
Validation loss: 1.4423685343034807

Epoch: 5| Step: 2
Training loss: 0.20474930107593536
Validation loss: 1.4389663934707642

Epoch: 5| Step: 3
Training loss: 0.147183358669281
Validation loss: 1.4635824336800525

Epoch: 5| Step: 4
Training loss: 0.2046271562576294
Validation loss: 1.502212583377797

Epoch: 5| Step: 5
Training loss: 0.13789914548397064
Validation loss: 1.4964064321210306

Epoch: 5| Step: 6
Training loss: 0.21175405383110046
Validation loss: 1.5262725583968624

Epoch: 5| Step: 7
Training loss: 0.1523178368806839
Validation loss: 1.486719887743714

Epoch: 5| Step: 8
Training loss: 0.10838949680328369
Validation loss: 1.438016927370461

Epoch: 5| Step: 9
Training loss: 0.1376340389251709
Validation loss: 1.4620818835432812

Epoch: 5| Step: 10
Training loss: 0.14880762994289398
Validation loss: 1.4670345308960124

Epoch: 509| Step: 0
Training loss: 0.14331893622875214
Validation loss: 1.484588433337468

Epoch: 5| Step: 1
Training loss: 0.14705082774162292
Validation loss: 1.5161945422490437

Epoch: 5| Step: 2
Training loss: 0.09935862571001053
Validation loss: 1.504625234552609

Epoch: 5| Step: 3
Training loss: 0.15803197026252747
Validation loss: 1.493161718050639

Epoch: 5| Step: 4
Training loss: 0.10070475190877914
Validation loss: 1.5090801728669034

Epoch: 5| Step: 5
Training loss: 0.11829235404729843
Validation loss: 1.5005772716255599

Epoch: 5| Step: 6
Training loss: 0.24419574439525604
Validation loss: 1.4929787856276318

Epoch: 5| Step: 7
Training loss: 0.17633339762687683
Validation loss: 1.465393934198605

Epoch: 5| Step: 8
Training loss: 0.07272341102361679
Validation loss: 1.4991158439267067

Epoch: 5| Step: 9
Training loss: 0.14325083792209625
Validation loss: 1.4837175133407756

Epoch: 5| Step: 10
Training loss: 0.203303724527359
Validation loss: 1.5111628578555198

Epoch: 510| Step: 0
Training loss: 0.16041389107704163
Validation loss: 1.5152149764440392

Epoch: 5| Step: 1
Training loss: 0.07920674979686737
Validation loss: 1.4961161318645682

Epoch: 5| Step: 2
Training loss: 0.1380651891231537
Validation loss: 1.4997310446154686

Epoch: 5| Step: 3
Training loss: 0.14284715056419373
Validation loss: 1.4650804868308447

Epoch: 5| Step: 4
Training loss: 0.10931382328271866
Validation loss: 1.4591589307272306

Epoch: 5| Step: 5
Training loss: 0.10819512605667114
Validation loss: 1.4812335070743357

Epoch: 5| Step: 6
Training loss: 0.20542724430561066
Validation loss: 1.459965508471253

Epoch: 5| Step: 7
Training loss: 0.12605738639831543
Validation loss: 1.470075495781437

Epoch: 5| Step: 8
Training loss: 0.14206412434577942
Validation loss: 1.4818873443911154

Epoch: 5| Step: 9
Training loss: 0.21274085342884064
Validation loss: 1.4718356786235687

Epoch: 5| Step: 10
Training loss: 0.11757247149944305
Validation loss: 1.465939269270948

Epoch: 511| Step: 0
Training loss: 0.09785189479589462
Validation loss: 1.4498088680287844

Epoch: 5| Step: 1
Training loss: 0.18245342373847961
Validation loss: 1.4680423890390704

Epoch: 5| Step: 2
Training loss: 0.18524080514907837
Validation loss: 1.433104553530293

Epoch: 5| Step: 3
Training loss: 0.080286905169487
Validation loss: 1.4491942979956185

Epoch: 5| Step: 4
Training loss: 0.0889713317155838
Validation loss: 1.4838077740002704

Epoch: 5| Step: 5
Training loss: 0.09933739900588989
Validation loss: 1.4648587549886396

Epoch: 5| Step: 6
Training loss: 0.18422257900238037
Validation loss: 1.4825955911349225

Epoch: 5| Step: 7
Training loss: 0.09801380336284637
Validation loss: 1.4539454713944466

Epoch: 5| Step: 8
Training loss: 0.22253187000751495
Validation loss: 1.4876383350741478

Epoch: 5| Step: 9
Training loss: 0.15178519487380981
Validation loss: 1.464249990319693

Epoch: 5| Step: 10
Training loss: 0.15280437469482422
Validation loss: 1.479558531956006

Epoch: 512| Step: 0
Training loss: 0.1392846554517746
Validation loss: 1.4729972180499826

Epoch: 5| Step: 1
Training loss: 0.12958702445030212
Validation loss: 1.4925758684835126

Epoch: 5| Step: 2
Training loss: 0.1609220802783966
Validation loss: 1.544101474105671

Epoch: 5| Step: 3
Training loss: 0.20382198691368103
Validation loss: 1.5662891262321061

Epoch: 5| Step: 4
Training loss: 0.2228100597858429
Validation loss: 1.517354925473531

Epoch: 5| Step: 5
Training loss: 0.10637382417917252
Validation loss: 1.5207607605124032

Epoch: 5| Step: 6
Training loss: 0.14419977366924286
Validation loss: 1.4973757113179853

Epoch: 5| Step: 7
Training loss: 0.19264540076255798
Validation loss: 1.4969930917985979

Epoch: 5| Step: 8
Training loss: 0.17126795649528503
Validation loss: 1.4742433153172976

Epoch: 5| Step: 9
Training loss: 0.1689472198486328
Validation loss: 1.5042364520411338

Epoch: 5| Step: 10
Training loss: 0.12721605598926544
Validation loss: 1.4820563735500458

Epoch: 513| Step: 0
Training loss: 0.1440962702035904
Validation loss: 1.4824143327692503

Epoch: 5| Step: 1
Training loss: 0.14948132634162903
Validation loss: 1.4897699086896834

Epoch: 5| Step: 2
Training loss: 0.09946072101593018
Validation loss: 1.4973368644714355

Epoch: 5| Step: 3
Training loss: 0.18966026604175568
Validation loss: 1.5315717535634195

Epoch: 5| Step: 4
Training loss: 0.2184440791606903
Validation loss: 1.5463802955483879

Epoch: 5| Step: 5
Training loss: 0.2702595591545105
Validation loss: 1.5899155332196144

Epoch: 5| Step: 6
Training loss: 0.29759150743484497
Validation loss: 1.5720968861733713

Epoch: 5| Step: 7
Training loss: 0.09510228037834167
Validation loss: 1.4910754606287966

Epoch: 5| Step: 8
Training loss: 0.1396544873714447
Validation loss: 1.4809307161197867

Epoch: 5| Step: 9
Training loss: 0.15726104378700256
Validation loss: 1.4645103792990408

Epoch: 5| Step: 10
Training loss: 0.10692845284938812
Validation loss: 1.4815405620041715

Epoch: 514| Step: 0
Training loss: 0.28511470556259155
Validation loss: 1.4766583032505487

Epoch: 5| Step: 1
Training loss: 0.1798812299966812
Validation loss: 1.472128466893268

Epoch: 5| Step: 2
Training loss: 0.18237611651420593
Validation loss: 1.4783991024058352

Epoch: 5| Step: 3
Training loss: 0.13835634291172028
Validation loss: 1.4823310900759954

Epoch: 5| Step: 4
Training loss: 0.1771744191646576
Validation loss: 1.4889249442726054

Epoch: 5| Step: 5
Training loss: 0.11585988849401474
Validation loss: 1.4791321972365021

Epoch: 5| Step: 6
Training loss: 0.07241744548082352
Validation loss: 1.4941474122385825

Epoch: 5| Step: 7
Training loss: 0.1531217098236084
Validation loss: 1.4974636582918064

Epoch: 5| Step: 8
Training loss: 0.06326248496770859
Validation loss: 1.4835589701129543

Epoch: 5| Step: 9
Training loss: 0.12481210380792618
Validation loss: 1.5087021538006362

Epoch: 5| Step: 10
Training loss: 0.21581332385540009
Validation loss: 1.481909401955143

Epoch: 515| Step: 0
Training loss: 0.2025190144777298
Validation loss: 1.5055569653869958

Epoch: 5| Step: 1
Training loss: 0.10229320824146271
Validation loss: 1.4658669848595896

Epoch: 5| Step: 2
Training loss: 0.10278141498565674
Validation loss: 1.4776358117339432

Epoch: 5| Step: 3
Training loss: 0.11401426792144775
Validation loss: 1.4828568068883752

Epoch: 5| Step: 4
Training loss: 0.20703494548797607
Validation loss: 1.4920627442739343

Epoch: 5| Step: 5
Training loss: 0.13309060037136078
Validation loss: 1.4832419374937653

Epoch: 5| Step: 6
Training loss: 0.15435117483139038
Validation loss: 1.4708992306904127

Epoch: 5| Step: 7
Training loss: 0.11668962240219116
Validation loss: 1.4513096873478224

Epoch: 5| Step: 8
Training loss: 0.07561322301626205
Validation loss: 1.4791213850821219

Epoch: 5| Step: 9
Training loss: 0.12887156009674072
Validation loss: 1.500622026381954

Epoch: 5| Step: 10
Training loss: 0.1770988255739212
Validation loss: 1.463365581727797

Epoch: 516| Step: 0
Training loss: 0.13104839622974396
Validation loss: 1.480605165163676

Epoch: 5| Step: 1
Training loss: 0.11216509342193604
Validation loss: 1.4700191738784953

Epoch: 5| Step: 2
Training loss: 0.24278542399406433
Validation loss: 1.4715479573895853

Epoch: 5| Step: 3
Training loss: 0.1381286382675171
Validation loss: 1.467643840338594

Epoch: 5| Step: 4
Training loss: 0.21289777755737305
Validation loss: 1.4720495644436087

Epoch: 5| Step: 5
Training loss: 0.1634480506181717
Validation loss: 1.4776317816908642

Epoch: 5| Step: 6
Training loss: 0.09444814175367355
Validation loss: 1.4593089254953528

Epoch: 5| Step: 7
Training loss: 0.13812170922756195
Validation loss: 1.482655300888964

Epoch: 5| Step: 8
Training loss: 0.1024971753358841
Validation loss: 1.4621902524784047

Epoch: 5| Step: 9
Training loss: 0.1519489586353302
Validation loss: 1.4769712019992132

Epoch: 5| Step: 10
Training loss: 0.11346537619829178
Validation loss: 1.4673331078662668

Epoch: 517| Step: 0
Training loss: 0.14499644935131073
Validation loss: 1.4707667609696746

Epoch: 5| Step: 1
Training loss: 0.1440207064151764
Validation loss: 1.4673536285277335

Epoch: 5| Step: 2
Training loss: 0.15469802916049957
Validation loss: 1.4655561959871681

Epoch: 5| Step: 3
Training loss: 0.09079760313034058
Validation loss: 1.4467695079823977

Epoch: 5| Step: 4
Training loss: 0.10560984909534454
Validation loss: 1.4591292796596405

Epoch: 5| Step: 5
Training loss: 0.23100726306438446
Validation loss: 1.4387307359326271

Epoch: 5| Step: 6
Training loss: 0.11466071754693985
Validation loss: 1.4847234500351774

Epoch: 5| Step: 7
Training loss: 0.10774147510528564
Validation loss: 1.4824661195919078

Epoch: 5| Step: 8
Training loss: 0.1597689837217331
Validation loss: 1.4695333062961538

Epoch: 5| Step: 9
Training loss: 0.16706421971321106
Validation loss: 1.4805753769413117

Epoch: 5| Step: 10
Training loss: 0.12252926826477051
Validation loss: 1.4983169583864109

Epoch: 518| Step: 0
Training loss: 0.17718994617462158
Validation loss: 1.4950394258704236

Epoch: 5| Step: 1
Training loss: 0.14160743355751038
Validation loss: 1.5111998088898198

Epoch: 5| Step: 2
Training loss: 0.13265341520309448
Validation loss: 1.49114026049132

Epoch: 5| Step: 3
Training loss: 0.07018058001995087
Validation loss: 1.4903979403998262

Epoch: 5| Step: 4
Training loss: 0.20902636647224426
Validation loss: 1.4881486354335662

Epoch: 5| Step: 5
Training loss: 0.1485968977212906
Validation loss: 1.4970185577228505

Epoch: 5| Step: 6
Training loss: 0.09671817719936371
Validation loss: 1.4954169501540482

Epoch: 5| Step: 7
Training loss: 0.18065932393074036
Validation loss: 1.4742485195077875

Epoch: 5| Step: 8
Training loss: 0.11394784599542618
Validation loss: 1.480296855331749

Epoch: 5| Step: 9
Training loss: 0.11152257025241852
Validation loss: 1.4600119975305372

Epoch: 5| Step: 10
Training loss: 0.1470797210931778
Validation loss: 1.484770760741285

Epoch: 519| Step: 0
Training loss: 0.12853768467903137
Validation loss: 1.5128584805355276

Epoch: 5| Step: 1
Training loss: 0.19554123282432556
Validation loss: 1.536812836124051

Epoch: 5| Step: 2
Training loss: 0.15183401107788086
Validation loss: 1.4879421187985329

Epoch: 5| Step: 3
Training loss: 0.1466900110244751
Validation loss: 1.5070664357113581

Epoch: 5| Step: 4
Training loss: 0.10867166519165039
Validation loss: 1.4776738330882082

Epoch: 5| Step: 5
Training loss: 0.2577684819698334
Validation loss: 1.4437327436221543

Epoch: 5| Step: 6
Training loss: 0.1796688288450241
Validation loss: 1.4488225354943225

Epoch: 5| Step: 7
Training loss: 0.13686560094356537
Validation loss: 1.4344109828754137

Epoch: 5| Step: 8
Training loss: 0.12606360018253326
Validation loss: 1.4788418316072034

Epoch: 5| Step: 9
Training loss: 0.10029707103967667
Validation loss: 1.46626462218582

Epoch: 5| Step: 10
Training loss: 0.12046749144792557
Validation loss: 1.488344721896674

Epoch: 520| Step: 0
Training loss: 0.1467321366071701
Validation loss: 1.5094878801735498

Epoch: 5| Step: 1
Training loss: 0.23077797889709473
Validation loss: 1.5245110578434442

Epoch: 5| Step: 2
Training loss: 0.22135131061077118
Validation loss: 1.4767030554433023

Epoch: 5| Step: 3
Training loss: 0.09292767941951752
Validation loss: 1.4454462335955711

Epoch: 5| Step: 4
Training loss: 0.13277119398117065
Validation loss: 1.472819007853026

Epoch: 5| Step: 5
Training loss: 0.12264182418584824
Validation loss: 1.4848862399337113

Epoch: 5| Step: 6
Training loss: 0.1558331698179245
Validation loss: 1.4951011391096218

Epoch: 5| Step: 7
Training loss: 0.08628463745117188
Validation loss: 1.5035885495524253

Epoch: 5| Step: 8
Training loss: 0.17734107375144958
Validation loss: 1.4909199245514408

Epoch: 5| Step: 9
Training loss: 0.12084585428237915
Validation loss: 1.491081735139252

Epoch: 5| Step: 10
Training loss: 0.0782117024064064
Validation loss: 1.5037761875378188

Epoch: 521| Step: 0
Training loss: 0.19860926270484924
Validation loss: 1.5232171012509255

Epoch: 5| Step: 1
Training loss: 0.10054472833871841
Validation loss: 1.5156602680042226

Epoch: 5| Step: 2
Training loss: 0.07610855251550674
Validation loss: 1.5043894206323931

Epoch: 5| Step: 3
Training loss: 0.15293094515800476
Validation loss: 1.478514773871309

Epoch: 5| Step: 4
Training loss: 0.0956074446439743
Validation loss: 1.4979401608949066

Epoch: 5| Step: 5
Training loss: 0.11321568489074707
Validation loss: 1.4818275231187061

Epoch: 5| Step: 6
Training loss: 0.1719534695148468
Validation loss: 1.476566764616197

Epoch: 5| Step: 7
Training loss: 0.17353203892707825
Validation loss: 1.4612033764521282

Epoch: 5| Step: 8
Training loss: 0.16354352235794067
Validation loss: 1.4689244326724802

Epoch: 5| Step: 9
Training loss: 0.09913638979196548
Validation loss: 1.4647085717929307

Epoch: 5| Step: 10
Training loss: 0.15635040402412415
Validation loss: 1.4751804015969718

Epoch: 522| Step: 0
Training loss: 0.13504162430763245
Validation loss: 1.461073597272237

Epoch: 5| Step: 1
Training loss: 0.10728715360164642
Validation loss: 1.4648192646682903

Epoch: 5| Step: 2
Training loss: 0.098646380007267
Validation loss: 1.4778141744675175

Epoch: 5| Step: 3
Training loss: 0.11838467419147491
Validation loss: 1.4669875419268044

Epoch: 5| Step: 4
Training loss: 0.17167839407920837
Validation loss: 1.4761057669116604

Epoch: 5| Step: 5
Training loss: 0.18004974722862244
Validation loss: 1.452576865432083

Epoch: 5| Step: 6
Training loss: 0.22101876139640808
Validation loss: 1.4550903510021906

Epoch: 5| Step: 7
Training loss: 0.10739965736865997
Validation loss: 1.4466191850682741

Epoch: 5| Step: 8
Training loss: 0.148561030626297
Validation loss: 1.4379323682477396

Epoch: 5| Step: 9
Training loss: 0.074578657746315
Validation loss: 1.4801959414635935

Epoch: 5| Step: 10
Training loss: 0.16427114605903625
Validation loss: 1.4675576827859367

Epoch: 523| Step: 0
Training loss: 0.05989070609211922
Validation loss: 1.496846156735574

Epoch: 5| Step: 1
Training loss: 0.12487000226974487
Validation loss: 1.4769112525447723

Epoch: 5| Step: 2
Training loss: 0.13797615468502045
Validation loss: 1.4664879819398284

Epoch: 5| Step: 3
Training loss: 0.09708727151155472
Validation loss: 1.4947104466858732

Epoch: 5| Step: 4
Training loss: 0.067083939909935
Validation loss: 1.4713738144084971

Epoch: 5| Step: 5
Training loss: 0.12428047508001328
Validation loss: 1.4425848863458122

Epoch: 5| Step: 6
Training loss: 0.1609189510345459
Validation loss: 1.4544809313230618

Epoch: 5| Step: 7
Training loss: 0.19048063457012177
Validation loss: 1.456652948933263

Epoch: 5| Step: 8
Training loss: 0.11647319793701172
Validation loss: 1.457323364032212

Epoch: 5| Step: 9
Training loss: 0.10770740360021591
Validation loss: 1.4734183075607463

Epoch: 5| Step: 10
Training loss: 0.18669044971466064
Validation loss: 1.4531058201225855

Epoch: 524| Step: 0
Training loss: 0.0634407252073288
Validation loss: 1.4543994716418687

Epoch: 5| Step: 1
Training loss: 0.0741531103849411
Validation loss: 1.4424161218827771

Epoch: 5| Step: 2
Training loss: 0.1912042200565338
Validation loss: 1.4583934494244155

Epoch: 5| Step: 3
Training loss: 0.10698831081390381
Validation loss: 1.462355080471244

Epoch: 5| Step: 4
Training loss: 0.11098325252532959
Validation loss: 1.463633043791658

Epoch: 5| Step: 5
Training loss: 0.10340476036071777
Validation loss: 1.4754736128673758

Epoch: 5| Step: 6
Training loss: 0.07610853016376495
Validation loss: 1.4795691967010498

Epoch: 5| Step: 7
Training loss: 0.12880876660346985
Validation loss: 1.508970561847892

Epoch: 5| Step: 8
Training loss: 0.16917338967323303
Validation loss: 1.5340576389784455

Epoch: 5| Step: 9
Training loss: 0.1673327386379242
Validation loss: 1.5368915398915608

Epoch: 5| Step: 10
Training loss: 0.24970299005508423
Validation loss: 1.5002747645942114

Epoch: 525| Step: 0
Training loss: 0.11206457763910294
Validation loss: 1.5034024318059285

Epoch: 5| Step: 1
Training loss: 0.15010665357112885
Validation loss: 1.4745258586381071

Epoch: 5| Step: 2
Training loss: 0.1217179074883461
Validation loss: 1.4920945090632285

Epoch: 5| Step: 3
Training loss: 0.15463539958000183
Validation loss: 1.4905428950504591

Epoch: 5| Step: 4
Training loss: 0.1910814344882965
Validation loss: 1.484278118738564

Epoch: 5| Step: 5
Training loss: 0.14054110646247864
Validation loss: 1.4838673927450692

Epoch: 5| Step: 6
Training loss: 0.22990548610687256
Validation loss: 1.4823050755326466

Epoch: 5| Step: 7
Training loss: 0.11309449374675751
Validation loss: 1.514304264899223

Epoch: 5| Step: 8
Training loss: 0.12755072116851807
Validation loss: 1.4971214532852173

Epoch: 5| Step: 9
Training loss: 0.12543199956417084
Validation loss: 1.5236503462637625

Epoch: 5| Step: 10
Training loss: 0.10348493605852127
Validation loss: 1.5362170883404311

Epoch: 526| Step: 0
Training loss: 0.09924156963825226
Validation loss: 1.5117354098186697

Epoch: 5| Step: 1
Training loss: 0.13759151101112366
Validation loss: 1.5371407026885657

Epoch: 5| Step: 2
Training loss: 0.17417141795158386
Validation loss: 1.514243552761693

Epoch: 5| Step: 3
Training loss: 0.1391778290271759
Validation loss: 1.508205976537479

Epoch: 5| Step: 4
Training loss: 0.10138025134801865
Validation loss: 1.4882081631691224

Epoch: 5| Step: 5
Training loss: 0.1317604035139084
Validation loss: 1.4983553732595136

Epoch: 5| Step: 6
Training loss: 0.1086149662733078
Validation loss: 1.4600490318831576

Epoch: 5| Step: 7
Training loss: 0.1215154156088829
Validation loss: 1.46745482824182

Epoch: 5| Step: 8
Training loss: 0.15981918573379517
Validation loss: 1.4609453972949777

Epoch: 5| Step: 9
Training loss: 0.21236400306224823
Validation loss: 1.4735825651435441

Epoch: 5| Step: 10
Training loss: 0.11575629562139511
Validation loss: 1.4653021238183463

Epoch: 527| Step: 0
Training loss: 0.09882926195859909
Validation loss: 1.5186655316301572

Epoch: 5| Step: 1
Training loss: 0.1614573895931244
Validation loss: 1.502587628620927

Epoch: 5| Step: 2
Training loss: 0.12051429599523544
Validation loss: 1.5037491629200597

Epoch: 5| Step: 3
Training loss: 0.16713668406009674
Validation loss: 1.5032234332894767

Epoch: 5| Step: 4
Training loss: 0.13293656706809998
Validation loss: 1.481128127344193

Epoch: 5| Step: 5
Training loss: 0.10352256149053574
Validation loss: 1.471723238627116

Epoch: 5| Step: 6
Training loss: 0.09439212828874588
Validation loss: 1.464843068071591

Epoch: 5| Step: 7
Training loss: 0.07446669042110443
Validation loss: 1.4888635155975178

Epoch: 5| Step: 8
Training loss: 0.12180785834789276
Validation loss: 1.465471302309344

Epoch: 5| Step: 9
Training loss: 0.1556113064289093
Validation loss: 1.4772191573214788

Epoch: 5| Step: 10
Training loss: 0.10825353115797043
Validation loss: 1.5081609628533805

Epoch: 528| Step: 0
Training loss: 0.1948917955160141
Validation loss: 1.5029274430326236

Epoch: 5| Step: 1
Training loss: 0.10919779539108276
Validation loss: 1.4860982459078553

Epoch: 5| Step: 2
Training loss: 0.09083540737628937
Validation loss: 1.4694248745518346

Epoch: 5| Step: 3
Training loss: 0.07886388897895813
Validation loss: 1.4354162011095273

Epoch: 5| Step: 4
Training loss: 0.07201573997735977
Validation loss: 1.4595028815730926

Epoch: 5| Step: 5
Training loss: 0.13239195942878723
Validation loss: 1.4668130656724334

Epoch: 5| Step: 6
Training loss: 0.10887289047241211
Validation loss: 1.4432500857178883

Epoch: 5| Step: 7
Training loss: 0.1308005154132843
Validation loss: 1.472152797124719

Epoch: 5| Step: 8
Training loss: 0.15804970264434814
Validation loss: 1.4670468504710863

Epoch: 5| Step: 9
Training loss: 0.21587486565113068
Validation loss: 1.4836588700612385

Epoch: 5| Step: 10
Training loss: 0.10797153413295746
Validation loss: 1.5053766876138666

Epoch: 529| Step: 0
Training loss: 0.08095423877239227
Validation loss: 1.5107604034485356

Epoch: 5| Step: 1
Training loss: 0.08828093856573105
Validation loss: 1.5289337763222315

Epoch: 5| Step: 2
Training loss: 0.09755314141511917
Validation loss: 1.5301445863580192

Epoch: 5| Step: 3
Training loss: 0.12370063364505768
Validation loss: 1.5179040752431399

Epoch: 5| Step: 4
Training loss: 0.2544786334037781
Validation loss: 1.5117168772605158

Epoch: 5| Step: 5
Training loss: 0.10418758541345596
Validation loss: 1.5193455219268799

Epoch: 5| Step: 6
Training loss: 0.20765379071235657
Validation loss: 1.489677445862883

Epoch: 5| Step: 7
Training loss: 0.12084956467151642
Validation loss: 1.5013136857299394

Epoch: 5| Step: 8
Training loss: 0.14017777144908905
Validation loss: 1.5247181948795114

Epoch: 5| Step: 9
Training loss: 0.10064699500799179
Validation loss: 1.528009945346463

Epoch: 5| Step: 10
Training loss: 0.10935166478157043
Validation loss: 1.5489862042088662

Epoch: 530| Step: 0
Training loss: 0.06953833252191544
Validation loss: 1.5174936491955993

Epoch: 5| Step: 1
Training loss: 0.08498401194810867
Validation loss: 1.500736044299218

Epoch: 5| Step: 2
Training loss: 0.11955716460943222
Validation loss: 1.5049085745247461

Epoch: 5| Step: 3
Training loss: 0.1105237603187561
Validation loss: 1.470350291139336

Epoch: 5| Step: 4
Training loss: 0.1036040335893631
Validation loss: 1.4699771288902528

Epoch: 5| Step: 5
Training loss: 0.09471221268177032
Validation loss: 1.4635005791982014

Epoch: 5| Step: 6
Training loss: 0.10040684044361115
Validation loss: 1.4959736229271017

Epoch: 5| Step: 7
Training loss: 0.0783558338880539
Validation loss: 1.4802030812027633

Epoch: 5| Step: 8
Training loss: 0.18117208778858185
Validation loss: 1.4852940433768815

Epoch: 5| Step: 9
Training loss: 0.12577342987060547
Validation loss: 1.4938583002295545

Epoch: 5| Step: 10
Training loss: 0.1812635064125061
Validation loss: 1.5075524391666535

Epoch: 531| Step: 0
Training loss: 0.0583781823515892
Validation loss: 1.508081260547843

Epoch: 5| Step: 1
Training loss: 0.14683423936367035
Validation loss: 1.5151801686133108

Epoch: 5| Step: 2
Training loss: 0.09453439712524414
Validation loss: 1.539761899619974

Epoch: 5| Step: 3
Training loss: 0.09531285613775253
Validation loss: 1.530162792051992

Epoch: 5| Step: 4
Training loss: 0.14624696969985962
Validation loss: 1.5211062174971386

Epoch: 5| Step: 5
Training loss: 0.1417696326971054
Validation loss: 1.517031023579259

Epoch: 5| Step: 6
Training loss: 0.11791442334651947
Validation loss: 1.4935261575124597

Epoch: 5| Step: 7
Training loss: 0.15344427525997162
Validation loss: 1.505101664091951

Epoch: 5| Step: 8
Training loss: 0.09372343122959137
Validation loss: 1.5020439586331766

Epoch: 5| Step: 9
Training loss: 0.2193458527326584
Validation loss: 1.4857864636246876

Epoch: 5| Step: 10
Training loss: 0.12168511003255844
Validation loss: 1.479518457125592

Epoch: 532| Step: 0
Training loss: 0.07714547961950302
Validation loss: 1.4718580912518244

Epoch: 5| Step: 1
Training loss: 0.2423674613237381
Validation loss: 1.4795386688683623

Epoch: 5| Step: 2
Training loss: 0.06753474473953247
Validation loss: 1.4669236983022382

Epoch: 5| Step: 3
Training loss: 0.08682175725698471
Validation loss: 1.477112256070619

Epoch: 5| Step: 4
Training loss: 0.07407087832689285
Validation loss: 1.4736877628552016

Epoch: 5| Step: 5
Training loss: 0.08734912425279617
Validation loss: 1.4795104688213718

Epoch: 5| Step: 6
Training loss: 0.10347415506839752
Validation loss: 1.4785735991693312

Epoch: 5| Step: 7
Training loss: 0.14637038111686707
Validation loss: 1.4787962116220945

Epoch: 5| Step: 8
Training loss: 0.09519786387681961
Validation loss: 1.4855085880525651

Epoch: 5| Step: 9
Training loss: 0.14792409539222717
Validation loss: 1.4912806778184828

Epoch: 5| Step: 10
Training loss: 0.13610821962356567
Validation loss: 1.4831212412926458

Epoch: 533| Step: 0
Training loss: 0.1316317915916443
Validation loss: 1.5058326541736562

Epoch: 5| Step: 1
Training loss: 0.08522357046604156
Validation loss: 1.4865098166209396

Epoch: 5| Step: 2
Training loss: 0.13820451498031616
Validation loss: 1.5064117703386533

Epoch: 5| Step: 3
Training loss: 0.1945568323135376
Validation loss: 1.5105534856037428

Epoch: 5| Step: 4
Training loss: 0.10235254466533661
Validation loss: 1.5006252463145922

Epoch: 5| Step: 5
Training loss: 0.08867786079645157
Validation loss: 1.5102660194520028

Epoch: 5| Step: 6
Training loss: 0.04960743710398674
Validation loss: 1.503048312279486

Epoch: 5| Step: 7
Training loss: 0.16090376675128937
Validation loss: 1.5274710379621035

Epoch: 5| Step: 8
Training loss: 0.06268622726202011
Validation loss: 1.48952059079242

Epoch: 5| Step: 9
Training loss: 0.09242086112499237
Validation loss: 1.4998038430367746

Epoch: 5| Step: 10
Training loss: 0.18940789997577667
Validation loss: 1.5055911002620574

Epoch: 534| Step: 0
Training loss: 0.11181923002004623
Validation loss: 1.4818749786705099

Epoch: 5| Step: 1
Training loss: 0.11819718033075333
Validation loss: 1.4699182702649025

Epoch: 5| Step: 2
Training loss: 0.104685939848423
Validation loss: 1.4777614583251297

Epoch: 5| Step: 3
Training loss: 0.11895797401666641
Validation loss: 1.466024221912507

Epoch: 5| Step: 4
Training loss: 0.18936112523078918
Validation loss: 1.4888704694727415

Epoch: 5| Step: 5
Training loss: 0.14800961315631866
Validation loss: 1.5129093649566814

Epoch: 5| Step: 6
Training loss: 0.07165613025426865
Validation loss: 1.52320570330466

Epoch: 5| Step: 7
Training loss: 0.1024886816740036
Validation loss: 1.5520844408260879

Epoch: 5| Step: 8
Training loss: 0.08317048102617264
Validation loss: 1.5208524465560913

Epoch: 5| Step: 9
Training loss: 0.11005165427923203
Validation loss: 1.5046460961782804

Epoch: 5| Step: 10
Training loss: 0.0894855484366417
Validation loss: 1.5095199577270015

Epoch: 535| Step: 0
Training loss: 0.23883473873138428
Validation loss: 1.489995744920546

Epoch: 5| Step: 1
Training loss: 0.09114862978458405
Validation loss: 1.4936051663532053

Epoch: 5| Step: 2
Training loss: 0.0749276652932167
Validation loss: 1.497925946789403

Epoch: 5| Step: 3
Training loss: 0.1323893964290619
Validation loss: 1.490087124609178

Epoch: 5| Step: 4
Training loss: 0.17533062398433685
Validation loss: 1.4895705971666562

Epoch: 5| Step: 5
Training loss: 0.105282261967659
Validation loss: 1.5130036979593255

Epoch: 5| Step: 6
Training loss: 0.0951244980096817
Validation loss: 1.5066731629833099

Epoch: 5| Step: 7
Training loss: 0.10570615530014038
Validation loss: 1.532976040276148

Epoch: 5| Step: 8
Training loss: 0.07778099924325943
Validation loss: 1.5184521111108924

Epoch: 5| Step: 9
Training loss: 0.09739663451910019
Validation loss: 1.52118803352438

Epoch: 5| Step: 10
Training loss: 0.11140789836645126
Validation loss: 1.5561047497616018

Epoch: 536| Step: 0
Training loss: 0.09121529757976532
Validation loss: 1.5336101811419252

Epoch: 5| Step: 1
Training loss: 0.12913689017295837
Validation loss: 1.5468592400191932

Epoch: 5| Step: 2
Training loss: 0.07338976860046387
Validation loss: 1.5110709821024249

Epoch: 5| Step: 3
Training loss: 0.14248397946357727
Validation loss: 1.5283928712209065

Epoch: 5| Step: 4
Training loss: 0.1712651252746582
Validation loss: 1.5188836013117144

Epoch: 5| Step: 5
Training loss: 0.1921975165605545
Validation loss: 1.5235394880335817

Epoch: 5| Step: 6
Training loss: 0.08450768887996674
Validation loss: 1.559923315560946

Epoch: 5| Step: 7
Training loss: 0.11657653748989105
Validation loss: 1.5829865176190612

Epoch: 5| Step: 8
Training loss: 0.1083427220582962
Validation loss: 1.5470975765617945

Epoch: 5| Step: 9
Training loss: 0.1330026090145111
Validation loss: 1.5204794842709777

Epoch: 5| Step: 10
Training loss: 0.06852816790342331
Validation loss: 1.4782845192058112

Epoch: 537| Step: 0
Training loss: 0.12248311191797256
Validation loss: 1.4605956039121073

Epoch: 5| Step: 1
Training loss: 0.1200934648513794
Validation loss: 1.4565579968114053

Epoch: 5| Step: 2
Training loss: 0.1345595121383667
Validation loss: 1.442292965868468

Epoch: 5| Step: 3
Training loss: 0.09680907428264618
Validation loss: 1.4543769244224793

Epoch: 5| Step: 4
Training loss: 0.08659309893846512
Validation loss: 1.4510577058279386

Epoch: 5| Step: 5
Training loss: 0.09687209874391556
Validation loss: 1.4594328864928214

Epoch: 5| Step: 6
Training loss: 0.11269360780715942
Validation loss: 1.4695434339584843

Epoch: 5| Step: 7
Training loss: 0.17237325012683868
Validation loss: 1.469033936018585

Epoch: 5| Step: 8
Training loss: 0.1995471566915512
Validation loss: 1.4631502653962822

Epoch: 5| Step: 9
Training loss: 0.09867745637893677
Validation loss: 1.4368322087872414

Epoch: 5| Step: 10
Training loss: 0.13211214542388916
Validation loss: 1.4795505692881923

Epoch: 538| Step: 0
Training loss: 0.22506694495677948
Validation loss: 1.4860358424084161

Epoch: 5| Step: 1
Training loss: 0.04510163515806198
Validation loss: 1.5278031467109598

Epoch: 5| Step: 2
Training loss: 0.07037012279033661
Validation loss: 1.5432535717564244

Epoch: 5| Step: 3
Training loss: 0.10920961201190948
Validation loss: 1.5400809446970622

Epoch: 5| Step: 4
Training loss: 0.08009978383779526
Validation loss: 1.5517932548317859

Epoch: 5| Step: 5
Training loss: 0.07678684592247009
Validation loss: 1.5336333205623012

Epoch: 5| Step: 6
Training loss: 0.1635982096195221
Validation loss: 1.5133254297317997

Epoch: 5| Step: 7
Training loss: 0.18201902508735657
Validation loss: 1.4850836992263794

Epoch: 5| Step: 8
Training loss: 0.09090186655521393
Validation loss: 1.470967205621863

Epoch: 5| Step: 9
Training loss: 0.11305336654186249
Validation loss: 1.4790576632304857

Epoch: 5| Step: 10
Training loss: 0.07638891041278839
Validation loss: 1.477294562965311

Epoch: 539| Step: 0
Training loss: 0.08268861472606659
Validation loss: 1.477292853017007

Epoch: 5| Step: 1
Training loss: 0.19294342398643494
Validation loss: 1.4509079302510908

Epoch: 5| Step: 2
Training loss: 0.08574114739894867
Validation loss: 1.4618441251016432

Epoch: 5| Step: 3
Training loss: 0.0847572386264801
Validation loss: 1.4934932993304344

Epoch: 5| Step: 4
Training loss: 0.09681983292102814
Validation loss: 1.4554370475071732

Epoch: 5| Step: 5
Training loss: 0.09340986609458923
Validation loss: 1.4618935777295021

Epoch: 5| Step: 6
Training loss: 0.11245381832122803
Validation loss: 1.4468328773334462

Epoch: 5| Step: 7
Training loss: 0.19330254197120667
Validation loss: 1.457208671877461

Epoch: 5| Step: 8
Training loss: 0.058494746685028076
Validation loss: 1.4490178913198493

Epoch: 5| Step: 9
Training loss: 0.10279359668493271
Validation loss: 1.4356547106978714

Epoch: 5| Step: 10
Training loss: 0.1292022317647934
Validation loss: 1.441782155344563

Epoch: 540| Step: 0
Training loss: 0.16837023198604584
Validation loss: 1.4430691324254519

Epoch: 5| Step: 1
Training loss: 0.15848985314369202
Validation loss: 1.4406456088507047

Epoch: 5| Step: 2
Training loss: 0.23960557579994202
Validation loss: 1.4697442849477131

Epoch: 5| Step: 3
Training loss: 0.14532062411308289
Validation loss: 1.498837189007831

Epoch: 5| Step: 4
Training loss: 0.15688343346118927
Validation loss: 1.4982116324927217

Epoch: 5| Step: 5
Training loss: 0.07521409541368484
Validation loss: 1.4469194886504964

Epoch: 5| Step: 6
Training loss: 0.08995741605758667
Validation loss: 1.4661585630909089

Epoch: 5| Step: 7
Training loss: 0.10460667312145233
Validation loss: 1.4475205207383761

Epoch: 5| Step: 8
Training loss: 0.049990590661764145
Validation loss: 1.4522819262678905

Epoch: 5| Step: 9
Training loss: 0.08465055376291275
Validation loss: 1.4483429642133816

Epoch: 5| Step: 10
Training loss: 0.09988032281398773
Validation loss: 1.4496362837412025

Epoch: 541| Step: 0
Training loss: 0.12750355899333954
Validation loss: 1.473240089672868

Epoch: 5| Step: 1
Training loss: 0.1413036286830902
Validation loss: 1.4928986359668035

Epoch: 5| Step: 2
Training loss: 0.21906080842018127
Validation loss: 1.4986093403190694

Epoch: 5| Step: 3
Training loss: 0.19657571613788605
Validation loss: 1.5161626563277295

Epoch: 5| Step: 4
Training loss: 0.10353843867778778
Validation loss: 1.5179625275314494

Epoch: 5| Step: 5
Training loss: 0.043752506375312805
Validation loss: 1.4914856469759377

Epoch: 5| Step: 6
Training loss: 0.10271760076284409
Validation loss: 1.5306486006705993

Epoch: 5| Step: 7
Training loss: 0.077494777739048
Validation loss: 1.541940809578024

Epoch: 5| Step: 8
Training loss: 0.12172883749008179
Validation loss: 1.546233541222029

Epoch: 5| Step: 9
Training loss: 0.24982266128063202
Validation loss: 1.5647078457699026

Epoch: 5| Step: 10
Training loss: 0.28522536158561707
Validation loss: 1.5395212032461678

Epoch: 542| Step: 0
Training loss: 0.1485646814107895
Validation loss: 1.520182877458552

Epoch: 5| Step: 1
Training loss: 0.28649061918258667
Validation loss: 1.5038631693009408

Epoch: 5| Step: 2
Training loss: 0.0995391234755516
Validation loss: 1.5087606496708368

Epoch: 5| Step: 3
Training loss: 0.12497077137231827
Validation loss: 1.5170418613700456

Epoch: 5| Step: 4
Training loss: 0.09393863379955292
Validation loss: 1.528466232361332

Epoch: 5| Step: 5
Training loss: 0.1586199700832367
Validation loss: 1.5304032192435315

Epoch: 5| Step: 6
Training loss: 0.14781783521175385
Validation loss: 1.505983773098197

Epoch: 5| Step: 7
Training loss: 0.10265856981277466
Validation loss: 1.5066208557416034

Epoch: 5| Step: 8
Training loss: 0.15975573658943176
Validation loss: 1.469882906124156

Epoch: 5| Step: 9
Training loss: 0.14497801661491394
Validation loss: 1.4758587588546097

Epoch: 5| Step: 10
Training loss: 0.0721578449010849
Validation loss: 1.4501480671667284

Epoch: 543| Step: 0
Training loss: 0.05284803360700607
Validation loss: 1.471185189421459

Epoch: 5| Step: 1
Training loss: 0.12185327708721161
Validation loss: 1.4438889757279427

Epoch: 5| Step: 2
Training loss: 0.13913044333457947
Validation loss: 1.4578089573050057

Epoch: 5| Step: 3
Training loss: 0.12853555381298065
Validation loss: 1.4698469767006495

Epoch: 5| Step: 4
Training loss: 0.07101121544837952
Validation loss: 1.4493011031099545

Epoch: 5| Step: 5
Training loss: 0.15173114836215973
Validation loss: 1.4392592868497294

Epoch: 5| Step: 6
Training loss: 0.15249621868133545
Validation loss: 1.4443243729170931

Epoch: 5| Step: 7
Training loss: 0.08933934569358826
Validation loss: 1.451639054923929

Epoch: 5| Step: 8
Training loss: 0.09963740408420563
Validation loss: 1.4941553236335836

Epoch: 5| Step: 9
Training loss: 0.09111425280570984
Validation loss: 1.4678132957027805

Epoch: 5| Step: 10
Training loss: 0.11463172733783722
Validation loss: 1.4694476223761035

Epoch: 544| Step: 0
Training loss: 0.10258231312036514
Validation loss: 1.4718359131966867

Epoch: 5| Step: 1
Training loss: 0.08082187175750732
Validation loss: 1.4895997752425492

Epoch: 5| Step: 2
Training loss: 0.06896109879016876
Validation loss: 1.4632191106837282

Epoch: 5| Step: 3
Training loss: 0.15144352614879608
Validation loss: 1.4788756652544903

Epoch: 5| Step: 4
Training loss: 0.1543923020362854
Validation loss: 1.473656427475714

Epoch: 5| Step: 5
Training loss: 0.1263365000486374
Validation loss: 1.462246182144329

Epoch: 5| Step: 6
Training loss: 0.17522172629833221
Validation loss: 1.4289307709663146

Epoch: 5| Step: 7
Training loss: 0.08149446547031403
Validation loss: 1.4231045771670598

Epoch: 5| Step: 8
Training loss: 0.10122574865818024
Validation loss: 1.4545205677709272

Epoch: 5| Step: 9
Training loss: 0.08619096875190735
Validation loss: 1.459126712173544

Epoch: 5| Step: 10
Training loss: 0.12550631165504456
Validation loss: 1.4590560351648638

Epoch: 545| Step: 0
Training loss: 0.08064732700586319
Validation loss: 1.4597027519697785

Epoch: 5| Step: 1
Training loss: 0.1488625854253769
Validation loss: 1.43101905879154

Epoch: 5| Step: 2
Training loss: 0.09679538011550903
Validation loss: 1.4234904537918747

Epoch: 5| Step: 3
Training loss: 0.13432608544826508
Validation loss: 1.4505144421772291

Epoch: 5| Step: 4
Training loss: 0.0661548376083374
Validation loss: 1.4194839539066437

Epoch: 5| Step: 5
Training loss: 0.1086951345205307
Validation loss: 1.4314811614251906

Epoch: 5| Step: 6
Training loss: 0.13652658462524414
Validation loss: 1.4453021031554028

Epoch: 5| Step: 7
Training loss: 0.1302487999200821
Validation loss: 1.4684220642171881

Epoch: 5| Step: 8
Training loss: 0.1800840049982071
Validation loss: 1.4641929505973734

Epoch: 5| Step: 9
Training loss: 0.0725373774766922
Validation loss: 1.472151085894595

Epoch: 5| Step: 10
Training loss: 0.1860344558954239
Validation loss: 1.4925934755673973

Epoch: 546| Step: 0
Training loss: 0.0783749669790268
Validation loss: 1.4914249938021424

Epoch: 5| Step: 1
Training loss: 0.1689060479402542
Validation loss: 1.4940873205020864

Epoch: 5| Step: 2
Training loss: 0.09721549600362778
Validation loss: 1.489321162623744

Epoch: 5| Step: 3
Training loss: 0.09708981215953827
Validation loss: 1.4603534411358576

Epoch: 5| Step: 4
Training loss: 0.08663532882928848
Validation loss: 1.43333984703146

Epoch: 5| Step: 5
Training loss: 0.10509733110666275
Validation loss: 1.460689160131639

Epoch: 5| Step: 6
Training loss: 0.12568441033363342
Validation loss: 1.4769595297433997

Epoch: 5| Step: 7
Training loss: 0.1369064450263977
Validation loss: 1.4560380443449943

Epoch: 5| Step: 8
Training loss: 0.12883391976356506
Validation loss: 1.4800850537515455

Epoch: 5| Step: 9
Training loss: 0.08040835708379745
Validation loss: 1.4701532625382947

Epoch: 5| Step: 10
Training loss: 0.13432514667510986
Validation loss: 1.4741909004026843

Epoch: 547| Step: 0
Training loss: 0.107718326151371
Validation loss: 1.4715300195960588

Epoch: 5| Step: 1
Training loss: 0.13497599959373474
Validation loss: 1.4580305071287258

Epoch: 5| Step: 2
Training loss: 0.07200824469327927
Validation loss: 1.4730119128381052

Epoch: 5| Step: 3
Training loss: 0.07072103023529053
Validation loss: 1.4886833660064205

Epoch: 5| Step: 4
Training loss: 0.12852731347084045
Validation loss: 1.4817581548485705

Epoch: 5| Step: 5
Training loss: 0.16704228520393372
Validation loss: 1.4479463843889133

Epoch: 5| Step: 6
Training loss: 0.13236089050769806
Validation loss: 1.4554291373939925

Epoch: 5| Step: 7
Training loss: 0.08101755380630493
Validation loss: 1.461798628171285

Epoch: 5| Step: 8
Training loss: 0.09633956104516983
Validation loss: 1.4626171717079737

Epoch: 5| Step: 9
Training loss: 0.1489477902650833
Validation loss: 1.4400873184204102

Epoch: 5| Step: 10
Training loss: 0.08282660692930222
Validation loss: 1.4591685430977934

Epoch: 548| Step: 0
Training loss: 0.11112110316753387
Validation loss: 1.431882236593513

Epoch: 5| Step: 1
Training loss: 0.16604912281036377
Validation loss: 1.4222408552323618

Epoch: 5| Step: 2
Training loss: 0.0827942043542862
Validation loss: 1.4430642409991192

Epoch: 5| Step: 3
Training loss: 0.10119817405939102
Validation loss: 1.4349258074196436

Epoch: 5| Step: 4
Training loss: 0.11499712616205215
Validation loss: 1.423860481990281

Epoch: 5| Step: 5
Training loss: 0.11641788482666016
Validation loss: 1.4380136228376819

Epoch: 5| Step: 6
Training loss: 0.12308822572231293
Validation loss: 1.446420645201078

Epoch: 5| Step: 7
Training loss: 0.06748686730861664
Validation loss: 1.4754518937039118

Epoch: 5| Step: 8
Training loss: 0.16049376130104065
Validation loss: 1.4635695808677263

Epoch: 5| Step: 9
Training loss: 0.05587565898895264
Validation loss: 1.497041497179257

Epoch: 5| Step: 10
Training loss: 0.07763058692216873
Validation loss: 1.4727939482658141

Epoch: 549| Step: 0
Training loss: 0.07923392951488495
Validation loss: 1.492999739544366

Epoch: 5| Step: 1
Training loss: 0.10751385986804962
Validation loss: 1.503143193901226

Epoch: 5| Step: 2
Training loss: 0.16123315691947937
Validation loss: 1.5038419288973655

Epoch: 5| Step: 3
Training loss: 0.08928460627794266
Validation loss: 1.4998241214342014

Epoch: 5| Step: 4
Training loss: 0.09738472104072571
Validation loss: 1.4884327867979645

Epoch: 5| Step: 5
Training loss: 0.14831973612308502
Validation loss: 1.4640101386654762

Epoch: 5| Step: 6
Training loss: 0.10185444355010986
Validation loss: 1.4656035810388544

Epoch: 5| Step: 7
Training loss: 0.18051382899284363
Validation loss: 1.453718780189432

Epoch: 5| Step: 8
Training loss: 0.10562826693058014
Validation loss: 1.4603825333297893

Epoch: 5| Step: 9
Training loss: 0.10473625361919403
Validation loss: 1.4690080022299161

Epoch: 5| Step: 10
Training loss: 0.10401104390621185
Validation loss: 1.4641111486701555

Epoch: 550| Step: 0
Training loss: 0.13271689414978027
Validation loss: 1.4702805447322067

Epoch: 5| Step: 1
Training loss: 0.11848275363445282
Validation loss: 1.5003518827499882

Epoch: 5| Step: 2
Training loss: 0.19836612045764923
Validation loss: 1.5289523281076902

Epoch: 5| Step: 3
Training loss: 0.1099560484290123
Validation loss: 1.4980533712653703

Epoch: 5| Step: 4
Training loss: 0.08806862682104111
Validation loss: 1.4693273792984665

Epoch: 5| Step: 5
Training loss: 0.10709550231695175
Validation loss: 1.4391028227344635

Epoch: 5| Step: 6
Training loss: 0.12329111248254776
Validation loss: 1.4343854381192116

Epoch: 5| Step: 7
Training loss: 0.1360951066017151
Validation loss: 1.4556267466596378

Epoch: 5| Step: 8
Training loss: 0.20614823698997498
Validation loss: 1.4283894031278548

Epoch: 5| Step: 9
Training loss: 0.07346627116203308
Validation loss: 1.4617498952855346

Epoch: 5| Step: 10
Training loss: 0.08888818323612213
Validation loss: 1.466233048387753

Epoch: 551| Step: 0
Training loss: 0.12978240847587585
Validation loss: 1.4978058543256534

Epoch: 5| Step: 1
Training loss: 0.1139281764626503
Validation loss: 1.5373474718422018

Epoch: 5| Step: 2
Training loss: 0.12851932644844055
Validation loss: 1.5201403043603385

Epoch: 5| Step: 3
Training loss: 0.08323582261800766
Validation loss: 1.5224457684383597

Epoch: 5| Step: 4
Training loss: 0.09648291021585464
Validation loss: 1.5496628797182472

Epoch: 5| Step: 5
Training loss: 0.22763285040855408
Validation loss: 1.51784719574836

Epoch: 5| Step: 6
Training loss: 0.1024651899933815
Validation loss: 1.5012818177541096

Epoch: 5| Step: 7
Training loss: 0.1011820062994957
Validation loss: 1.4990792633384786

Epoch: 5| Step: 8
Training loss: 0.1158810630440712
Validation loss: 1.5034587921634797

Epoch: 5| Step: 9
Training loss: 0.1055339127779007
Validation loss: 1.4815679583498227

Epoch: 5| Step: 10
Training loss: 0.0866432785987854
Validation loss: 1.462419254805452

Epoch: 552| Step: 0
Training loss: 0.1329733431339264
Validation loss: 1.4783015545978342

Epoch: 5| Step: 1
Training loss: 0.09166701138019562
Validation loss: 1.4791953973872687

Epoch: 5| Step: 2
Training loss: 0.11010696738958359
Validation loss: 1.4488815069198608

Epoch: 5| Step: 3
Training loss: 0.10039837658405304
Validation loss: 1.4505744858454632

Epoch: 5| Step: 4
Training loss: 0.06871990114450455
Validation loss: 1.4831310305544125

Epoch: 5| Step: 5
Training loss: 0.055113304406404495
Validation loss: 1.4546392233141008

Epoch: 5| Step: 6
Training loss: 0.11812716722488403
Validation loss: 1.4439137494692238

Epoch: 5| Step: 7
Training loss: 0.0750124454498291
Validation loss: 1.4331647503760554

Epoch: 5| Step: 8
Training loss: 0.1033448725938797
Validation loss: 1.4456829165899625

Epoch: 5| Step: 9
Training loss: 0.09015675634145737
Validation loss: 1.4719789976714759

Epoch: 5| Step: 10
Training loss: 0.22525916993618011
Validation loss: 1.4839012071650515

Epoch: 553| Step: 0
Training loss: 0.10045485198497772
Validation loss: 1.4765474937295402

Epoch: 5| Step: 1
Training loss: 0.11344826221466064
Validation loss: 1.4717045842960317

Epoch: 5| Step: 2
Training loss: 0.10373371839523315
Validation loss: 1.4712246259053547

Epoch: 5| Step: 3
Training loss: 0.11173959821462631
Validation loss: 1.4596249634219753

Epoch: 5| Step: 4
Training loss: 0.12625423073768616
Validation loss: 1.4486354563825874

Epoch: 5| Step: 5
Training loss: 0.07862479984760284
Validation loss: 1.4485813917652253

Epoch: 5| Step: 6
Training loss: 0.09565136581659317
Validation loss: 1.4553170216980802

Epoch: 5| Step: 7
Training loss: 0.09048592299222946
Validation loss: 1.4841118320342033

Epoch: 5| Step: 8
Training loss: 0.09372718632221222
Validation loss: 1.4845291312022875

Epoch: 5| Step: 9
Training loss: 0.17766545712947845
Validation loss: 1.4773389062573832

Epoch: 5| Step: 10
Training loss: 0.12566021084785461
Validation loss: 1.5101850737807572

Epoch: 554| Step: 0
Training loss: 0.07628314942121506
Validation loss: 1.5025111257389028

Epoch: 5| Step: 1
Training loss: 0.09521464258432388
Validation loss: 1.4816200220456688

Epoch: 5| Step: 2
Training loss: 0.11091933399438858
Validation loss: 1.4785342767674436

Epoch: 5| Step: 3
Training loss: 0.07138312608003616
Validation loss: 1.4738782592999038

Epoch: 5| Step: 4
Training loss: 0.15456853806972504
Validation loss: 1.4608737845574655

Epoch: 5| Step: 5
Training loss: 0.09704262018203735
Validation loss: 1.4490590973566937

Epoch: 5| Step: 6
Training loss: 0.10604719817638397
Validation loss: 1.4205661140462404

Epoch: 5| Step: 7
Training loss: 0.11039751768112183
Validation loss: 1.4543196988362137

Epoch: 5| Step: 8
Training loss: 0.10890773683786392
Validation loss: 1.4446552959821557

Epoch: 5| Step: 9
Training loss: 0.0973394438624382
Validation loss: 1.4549195228084442

Epoch: 5| Step: 10
Training loss: 0.07910356670618057
Validation loss: 1.4831833736870879

Epoch: 555| Step: 0
Training loss: 0.09928514808416367
Validation loss: 1.4730949363400858

Epoch: 5| Step: 1
Training loss: 0.09628968685865402
Validation loss: 1.4618753053808724

Epoch: 5| Step: 2
Training loss: 0.09298357367515564
Validation loss: 1.4642703071717293

Epoch: 5| Step: 3
Training loss: 0.06547899544239044
Validation loss: 1.462180181216168

Epoch: 5| Step: 4
Training loss: 0.08520914614200592
Validation loss: 1.4277482981322913

Epoch: 5| Step: 5
Training loss: 0.1575770378112793
Validation loss: 1.4415582905533493

Epoch: 5| Step: 6
Training loss: 0.16495636105537415
Validation loss: 1.459496267380253

Epoch: 5| Step: 7
Training loss: 0.08873645961284637
Validation loss: 1.4675979332257343

Epoch: 5| Step: 8
Training loss: 0.10871537774801254
Validation loss: 1.456451742879806

Epoch: 5| Step: 9
Training loss: 0.12021397054195404
Validation loss: 1.4625565134068972

Epoch: 5| Step: 10
Training loss: 0.15548817813396454
Validation loss: 1.4591638670172742

Epoch: 556| Step: 0
Training loss: 0.10856517404317856
Validation loss: 1.4550104551417853

Epoch: 5| Step: 1
Training loss: 0.09043143689632416
Validation loss: 1.4606526256889425

Epoch: 5| Step: 2
Training loss: 0.12154237180948257
Validation loss: 1.465523685178449

Epoch: 5| Step: 3
Training loss: 0.14685186743736267
Validation loss: 1.4626369130226873

Epoch: 5| Step: 4
Training loss: 0.12687870860099792
Validation loss: 1.4561719240680817

Epoch: 5| Step: 5
Training loss: 0.10576726496219635
Validation loss: 1.4570846032070857

Epoch: 5| Step: 6
Training loss: 0.11114691197872162
Validation loss: 1.4618436662099694

Epoch: 5| Step: 7
Training loss: 0.07337488234043121
Validation loss: 1.4615592546360467

Epoch: 5| Step: 8
Training loss: 0.16256007552146912
Validation loss: 1.5178446205713416

Epoch: 5| Step: 9
Training loss: 0.12392978370189667
Validation loss: 1.5187533350401028

Epoch: 5| Step: 10
Training loss: 0.11972099542617798
Validation loss: 1.513935609530377

Epoch: 557| Step: 0
Training loss: 0.17664101719856262
Validation loss: 1.4746505803959344

Epoch: 5| Step: 1
Training loss: 0.09183764457702637
Validation loss: 1.4514478611689743

Epoch: 5| Step: 2
Training loss: 0.1271488219499588
Validation loss: 1.4134023086999052

Epoch: 5| Step: 3
Training loss: 0.1416214257478714
Validation loss: 1.4000627956082743

Epoch: 5| Step: 4
Training loss: 0.14324434101581573
Validation loss: 1.3892712157259706

Epoch: 5| Step: 5
Training loss: 0.16342517733573914
Validation loss: 1.3683767600726056

Epoch: 5| Step: 6
Training loss: 0.11858026683330536
Validation loss: 1.4018688189086093

Epoch: 5| Step: 7
Training loss: 0.10051188617944717
Validation loss: 1.4061872600227274

Epoch: 5| Step: 8
Training loss: 0.0801185593008995
Validation loss: 1.4140060749105228

Epoch: 5| Step: 9
Training loss: 0.07731080800294876
Validation loss: 1.4582563087504397

Epoch: 5| Step: 10
Training loss: 0.11309439688920975
Validation loss: 1.4649380394207534

Epoch: 558| Step: 0
Training loss: 0.12746313214302063
Validation loss: 1.4767519812430105

Epoch: 5| Step: 1
Training loss: 0.11823870986700058
Validation loss: 1.5047546407227874

Epoch: 5| Step: 2
Training loss: 0.10113237798213959
Validation loss: 1.4630873062277352

Epoch: 5| Step: 3
Training loss: 0.06356795132160187
Validation loss: 1.4442752932989469

Epoch: 5| Step: 4
Training loss: 0.10344585031270981
Validation loss: 1.4405813909346057

Epoch: 5| Step: 5
Training loss: 0.12821464240550995
Validation loss: 1.4315173113217918

Epoch: 5| Step: 6
Training loss: 0.11936172097921371
Validation loss: 1.4256756356967393

Epoch: 5| Step: 7
Training loss: 0.11930976808071136
Validation loss: 1.426989254131112

Epoch: 5| Step: 8
Training loss: 0.06295835971832275
Validation loss: 1.4100882584048855

Epoch: 5| Step: 9
Training loss: 0.08976306021213531
Validation loss: 1.4296056301363054

Epoch: 5| Step: 10
Training loss: 0.07916973531246185
Validation loss: 1.4185398970880816

Epoch: 559| Step: 0
Training loss: 0.10994338989257812
Validation loss: 1.4222253163655598

Epoch: 5| Step: 1
Training loss: 0.09185422211885452
Validation loss: 1.4233415953574642

Epoch: 5| Step: 2
Training loss: 0.10324016958475113
Validation loss: 1.4170657780862623

Epoch: 5| Step: 3
Training loss: 0.06652027368545532
Validation loss: 1.4048827745581185

Epoch: 5| Step: 4
Training loss: 0.24183860421180725
Validation loss: 1.398082531908507

Epoch: 5| Step: 5
Training loss: 0.07998485863208771
Validation loss: 1.410947593309546

Epoch: 5| Step: 6
Training loss: 0.09059564769268036
Validation loss: 1.4259784772831907

Epoch: 5| Step: 7
Training loss: 0.11925189197063446
Validation loss: 1.4332653899346628

Epoch: 5| Step: 8
Training loss: 0.17228011786937714
Validation loss: 1.4340150189656082

Epoch: 5| Step: 9
Training loss: 0.11141280084848404
Validation loss: 1.4351349133317188

Epoch: 5| Step: 10
Training loss: 0.12656967341899872
Validation loss: 1.4633402785947245

Epoch: 560| Step: 0
Training loss: 0.08026663959026337
Validation loss: 1.4480795398835213

Epoch: 5| Step: 1
Training loss: 0.1330977976322174
Validation loss: 1.4693825308994581

Epoch: 5| Step: 2
Training loss: 0.12420527637004852
Validation loss: 1.4755238038237377

Epoch: 5| Step: 3
Training loss: 0.0749339908361435
Validation loss: 1.4862262177210983

Epoch: 5| Step: 4
Training loss: 0.08093742281198502
Validation loss: 1.5131198539528796

Epoch: 5| Step: 5
Training loss: 0.11917533725500107
Validation loss: 1.4768672091986543

Epoch: 5| Step: 6
Training loss: 0.09971725195646286
Validation loss: 1.4548677949495212

Epoch: 5| Step: 7
Training loss: 0.20569677650928497
Validation loss: 1.44527066651211

Epoch: 5| Step: 8
Training loss: 0.07535384595394135
Validation loss: 1.4368547008883568

Epoch: 5| Step: 9
Training loss: 0.07261621206998825
Validation loss: 1.4610988888689267

Epoch: 5| Step: 10
Training loss: 0.048801545053720474
Validation loss: 1.4260674907315163

Epoch: 561| Step: 0
Training loss: 0.12060000747442245
Validation loss: 1.4543002779765795

Epoch: 5| Step: 1
Training loss: 0.10260846465826035
Validation loss: 1.4516879957850262

Epoch: 5| Step: 2
Training loss: 0.1045512706041336
Validation loss: 1.453056554640493

Epoch: 5| Step: 3
Training loss: 0.10665072500705719
Validation loss: 1.416722047713495

Epoch: 5| Step: 4
Training loss: 0.0698876827955246
Validation loss: 1.4106667695506927

Epoch: 5| Step: 5
Training loss: 0.07162521034479141
Validation loss: 1.4287091532061178

Epoch: 5| Step: 6
Training loss: 0.07981704920530319
Validation loss: 1.4428331569958759

Epoch: 5| Step: 7
Training loss: 0.07415607571601868
Validation loss: 1.4405939143191102

Epoch: 5| Step: 8
Training loss: 0.05762949585914612
Validation loss: 1.443604580817684

Epoch: 5| Step: 9
Training loss: 0.10095731168985367
Validation loss: 1.4467781884695894

Epoch: 5| Step: 10
Training loss: 0.19434189796447754
Validation loss: 1.4419543999497608

Epoch: 562| Step: 0
Training loss: 0.04238927364349365
Validation loss: 1.457286295070443

Epoch: 5| Step: 1
Training loss: 0.13710010051727295
Validation loss: 1.4587171744274836

Epoch: 5| Step: 2
Training loss: 0.055494606494903564
Validation loss: 1.463541583348346

Epoch: 5| Step: 3
Training loss: 0.15646813809871674
Validation loss: 1.455166224510439

Epoch: 5| Step: 4
Training loss: 0.08006051927804947
Validation loss: 1.4604455296711256

Epoch: 5| Step: 5
Training loss: 0.12201792001724243
Validation loss: 1.4588580785259124

Epoch: 5| Step: 6
Training loss: 0.09899330884218216
Validation loss: 1.4522698233204503

Epoch: 5| Step: 7
Training loss: 0.15041260421276093
Validation loss: 1.4613754108387937

Epoch: 5| Step: 8
Training loss: 0.09900771081447601
Validation loss: 1.4539972146352131

Epoch: 5| Step: 9
Training loss: 0.05538324639201164
Validation loss: 1.428856844543129

Epoch: 5| Step: 10
Training loss: 0.08845476806163788
Validation loss: 1.421717696933336

Epoch: 563| Step: 0
Training loss: 0.10240960121154785
Validation loss: 1.433716836796012

Epoch: 5| Step: 1
Training loss: 0.15483346581459045
Validation loss: 1.4482915824459446

Epoch: 5| Step: 2
Training loss: 0.043277475982904434
Validation loss: 1.4539299600867814

Epoch: 5| Step: 3
Training loss: 0.08979139477014542
Validation loss: 1.464535500413628

Epoch: 5| Step: 4
Training loss: 0.08163779973983765
Validation loss: 1.4709814120364446

Epoch: 5| Step: 5
Training loss: 0.13991037011146545
Validation loss: 1.4557404005399315

Epoch: 5| Step: 6
Training loss: 0.08727679401636124
Validation loss: 1.4573343556414369

Epoch: 5| Step: 7
Training loss: 0.12833985686302185
Validation loss: 1.442193313311505

Epoch: 5| Step: 8
Training loss: 0.11904863268136978
Validation loss: 1.4256856236406552

Epoch: 5| Step: 9
Training loss: 0.06110252067446709
Validation loss: 1.4411648729796052

Epoch: 5| Step: 10
Training loss: 0.12062579393386841
Validation loss: 1.4634611670688917

Epoch: 564| Step: 0
Training loss: 0.16920223832130432
Validation loss: 1.4833679583764845

Epoch: 5| Step: 1
Training loss: 0.09511382132768631
Validation loss: 1.4843847213252899

Epoch: 5| Step: 2
Training loss: 0.06691724807024002
Validation loss: 1.44964781115132

Epoch: 5| Step: 3
Training loss: 0.10689766705036163
Validation loss: 1.4492523260014032

Epoch: 5| Step: 4
Training loss: 0.0767403095960617
Validation loss: 1.4145271162832938

Epoch: 5| Step: 5
Training loss: 0.1489305943250656
Validation loss: 1.41803099519463

Epoch: 5| Step: 6
Training loss: 0.09048245847225189
Validation loss: 1.389710812158482

Epoch: 5| Step: 7
Training loss: 0.1512143909931183
Validation loss: 1.41500182818341

Epoch: 5| Step: 8
Training loss: 0.09409872442483902
Validation loss: 1.4054967728994225

Epoch: 5| Step: 9
Training loss: 0.059221286326646805
Validation loss: 1.4458409586260397

Epoch: 5| Step: 10
Training loss: 0.06294161081314087
Validation loss: 1.4503321237461542

Epoch: 565| Step: 0
Training loss: 0.03747890517115593
Validation loss: 1.458738926918276

Epoch: 5| Step: 1
Training loss: 0.152080237865448
Validation loss: 1.4810144542365946

Epoch: 5| Step: 2
Training loss: 0.12388404458761215
Validation loss: 1.4671613042072584

Epoch: 5| Step: 3
Training loss: 0.07924123108386993
Validation loss: 1.4618795482061242

Epoch: 5| Step: 4
Training loss: 0.06431814283132553
Validation loss: 1.459311705763622

Epoch: 5| Step: 5
Training loss: 0.04771901294589043
Validation loss: 1.4543809865110664

Epoch: 5| Step: 6
Training loss: 0.11477913707494736
Validation loss: 1.4618168800107894

Epoch: 5| Step: 7
Training loss: 0.052095603197813034
Validation loss: 1.4366850487647518

Epoch: 5| Step: 8
Training loss: 0.10514874756336212
Validation loss: 1.424121766962031

Epoch: 5| Step: 9
Training loss: 0.1706353724002838
Validation loss: 1.4389131133274367

Epoch: 5| Step: 10
Training loss: 0.10084500163793564
Validation loss: 1.4251559126761653

Epoch: 566| Step: 0
Training loss: 0.0958227664232254
Validation loss: 1.4275016861577188

Epoch: 5| Step: 1
Training loss: 0.11926387250423431
Validation loss: 1.4127374925921041

Epoch: 5| Step: 2
Training loss: 0.10378167778253555
Validation loss: 1.4202447514380179

Epoch: 5| Step: 3
Training loss: 0.2216462790966034
Validation loss: 1.4345130035954137

Epoch: 5| Step: 4
Training loss: 0.12386941909790039
Validation loss: 1.4321338104945358

Epoch: 5| Step: 5
Training loss: 0.08853765577077866
Validation loss: 1.4391520651437903

Epoch: 5| Step: 6
Training loss: 0.07497565448284149
Validation loss: 1.4702352054657475

Epoch: 5| Step: 7
Training loss: 0.10738597065210342
Validation loss: 1.4527961374610983

Epoch: 5| Step: 8
Training loss: 0.09095095098018646
Validation loss: 1.4612196696701871

Epoch: 5| Step: 9
Training loss: 0.067029669880867
Validation loss: 1.4520892097103981

Epoch: 5| Step: 10
Training loss: 0.10781914740800858
Validation loss: 1.4537923195028817

Epoch: 567| Step: 0
Training loss: 0.09022996574640274
Validation loss: 1.429746603453031

Epoch: 5| Step: 1
Training loss: 0.09254659712314606
Validation loss: 1.4254381938647198

Epoch: 5| Step: 2
Training loss: 0.056618981063365936
Validation loss: 1.437568591487023

Epoch: 5| Step: 3
Training loss: 0.07135001569986343
Validation loss: 1.431671154114508

Epoch: 5| Step: 4
Training loss: 0.09052426367998123
Validation loss: 1.4511366896731879

Epoch: 5| Step: 5
Training loss: 0.1341261863708496
Validation loss: 1.4666985196451987

Epoch: 5| Step: 6
Training loss: 0.10773739963769913
Validation loss: 1.49990088324393

Epoch: 5| Step: 7
Training loss: 0.1370212584733963
Validation loss: 1.4847524435289445

Epoch: 5| Step: 8
Training loss: 0.05568437650799751
Validation loss: 1.469524888582127

Epoch: 5| Step: 9
Training loss: 0.06976504623889923
Validation loss: 1.4700782299041748

Epoch: 5| Step: 10
Training loss: 0.12455655634403229
Validation loss: 1.4578693823147846

Epoch: 568| Step: 0
Training loss: 0.12368921935558319
Validation loss: 1.4483127927267423

Epoch: 5| Step: 1
Training loss: 0.09941165149211884
Validation loss: 1.430992259774157

Epoch: 5| Step: 2
Training loss: 0.08368799835443497
Validation loss: 1.4421158221460157

Epoch: 5| Step: 3
Training loss: 0.08992453664541245
Validation loss: 1.4421138160972184

Epoch: 5| Step: 4
Training loss: 0.07380072772502899
Validation loss: 1.4493404985756002

Epoch: 5| Step: 5
Training loss: 0.07316543906927109
Validation loss: 1.4718295438315279

Epoch: 5| Step: 6
Training loss: 0.11004333198070526
Validation loss: 1.4795993515240249

Epoch: 5| Step: 7
Training loss: 0.1659940630197525
Validation loss: 1.4575622709848548

Epoch: 5| Step: 8
Training loss: 0.08120967447757721
Validation loss: 1.4600831475309146

Epoch: 5| Step: 9
Training loss: 0.06679898500442505
Validation loss: 1.4494975164372434

Epoch: 5| Step: 10
Training loss: 0.11726396530866623
Validation loss: 1.4774607932695778

Epoch: 569| Step: 0
Training loss: 0.0926770567893982
Validation loss: 1.4547142123663297

Epoch: 5| Step: 1
Training loss: 0.1431974470615387
Validation loss: 1.4419814719948718

Epoch: 5| Step: 2
Training loss: 0.06561186909675598
Validation loss: 1.459398195307742

Epoch: 5| Step: 3
Training loss: 0.12938730418682098
Validation loss: 1.4462608624530096

Epoch: 5| Step: 4
Training loss: 0.1000870019197464
Validation loss: 1.4718239076675907

Epoch: 5| Step: 5
Training loss: 0.12544865906238556
Validation loss: 1.4530044217263498

Epoch: 5| Step: 6
Training loss: 0.08114717900753021
Validation loss: 1.480267833637935

Epoch: 5| Step: 7
Training loss: 0.14089521765708923
Validation loss: 1.4793948383741482

Epoch: 5| Step: 8
Training loss: 0.08393113315105438
Validation loss: 1.4806056913509165

Epoch: 5| Step: 9
Training loss: 0.09411974251270294
Validation loss: 1.4641294037142107

Epoch: 5| Step: 10
Training loss: 0.05290839076042175
Validation loss: 1.4547386925707582

Epoch: 570| Step: 0
Training loss: 0.12851224839687347
Validation loss: 1.4387439322727982

Epoch: 5| Step: 1
Training loss: 0.12794628739356995
Validation loss: 1.4316733549999934

Epoch: 5| Step: 2
Training loss: 0.11416467279195786
Validation loss: 1.3979907548555763

Epoch: 5| Step: 3
Training loss: 0.08463521301746368
Validation loss: 1.3989805893231464

Epoch: 5| Step: 4
Training loss: 0.056581683456897736
Validation loss: 1.3893581026343889

Epoch: 5| Step: 5
Training loss: 0.06403382867574692
Validation loss: 1.4108392577017508

Epoch: 5| Step: 6
Training loss: 0.1763535737991333
Validation loss: 1.403112983190885

Epoch: 5| Step: 7
Training loss: 0.10024621337652206
Validation loss: 1.404987096786499

Epoch: 5| Step: 8
Training loss: 0.09466168284416199
Validation loss: 1.415656200019262

Epoch: 5| Step: 9
Training loss: 0.055975399911403656
Validation loss: 1.4135635238821789

Epoch: 5| Step: 10
Training loss: 0.08778975903987885
Validation loss: 1.4233672336865497

Epoch: 571| Step: 0
Training loss: 0.05990647152066231
Validation loss: 1.411117261455905

Epoch: 5| Step: 1
Training loss: 0.07200855016708374
Validation loss: 1.4290461437676543

Epoch: 5| Step: 2
Training loss: 0.07371560484170914
Validation loss: 1.4317569463483748

Epoch: 5| Step: 3
Training loss: 0.11230006068944931
Validation loss: 1.4015634662361556

Epoch: 5| Step: 4
Training loss: 0.10063471645116806
Validation loss: 1.419422362440376

Epoch: 5| Step: 5
Training loss: 0.08684944361448288
Validation loss: 1.4064526275921894

Epoch: 5| Step: 6
Training loss: 0.2081821858882904
Validation loss: 1.4253698074689476

Epoch: 5| Step: 7
Training loss: 0.0723327174782753
Validation loss: 1.401451467185892

Epoch: 5| Step: 8
Training loss: 0.07919609546661377
Validation loss: 1.4033299364069456

Epoch: 5| Step: 9
Training loss: 0.11008936166763306
Validation loss: 1.4213631819653254

Epoch: 5| Step: 10
Training loss: 0.07891204208135605
Validation loss: 1.4480458562092116

Epoch: 572| Step: 0
Training loss: 0.06183991953730583
Validation loss: 1.422531194584344

Epoch: 5| Step: 1
Training loss: 0.09718217700719833
Validation loss: 1.4578317211520286

Epoch: 5| Step: 2
Training loss: 0.09155397117137909
Validation loss: 1.4735572940559798

Epoch: 5| Step: 3
Training loss: 0.13125556707382202
Validation loss: 1.426732119693551

Epoch: 5| Step: 4
Training loss: 0.07791624963283539
Validation loss: 1.4656388682703818

Epoch: 5| Step: 5
Training loss: 0.06970538944005966
Validation loss: 1.4451249619965911

Epoch: 5| Step: 6
Training loss: 0.10774294286966324
Validation loss: 1.4642746692062707

Epoch: 5| Step: 7
Training loss: 0.17360877990722656
Validation loss: 1.4639158377083399

Epoch: 5| Step: 8
Training loss: 0.0646173432469368
Validation loss: 1.4329141391220914

Epoch: 5| Step: 9
Training loss: 0.05199028179049492
Validation loss: 1.4466404825128534

Epoch: 5| Step: 10
Training loss: 0.1185353621840477
Validation loss: 1.4472730787851478

Epoch: 573| Step: 0
Training loss: 0.16046246886253357
Validation loss: 1.47559287599338

Epoch: 5| Step: 1
Training loss: 0.10561356693506241
Validation loss: 1.4579835527686662

Epoch: 5| Step: 2
Training loss: 0.07003660500049591
Validation loss: 1.4603187884053876

Epoch: 5| Step: 3
Training loss: 0.06126401573419571
Validation loss: 1.4312437413841166

Epoch: 5| Step: 4
Training loss: 0.1255333423614502
Validation loss: 1.4424696558265275

Epoch: 5| Step: 5
Training loss: 0.07717807590961456
Validation loss: 1.4086987510804208

Epoch: 5| Step: 6
Training loss: 0.10233650356531143
Validation loss: 1.4361877031223749

Epoch: 5| Step: 7
Training loss: 0.12502847611904144
Validation loss: 1.4279132966072328

Epoch: 5| Step: 8
Training loss: 0.06830216199159622
Validation loss: 1.4229115760454567

Epoch: 5| Step: 9
Training loss: 0.05345636606216431
Validation loss: 1.4438026502568235

Epoch: 5| Step: 10
Training loss: 0.09885179251432419
Validation loss: 1.4438604065167007

Epoch: 574| Step: 0
Training loss: 0.15919658541679382
Validation loss: 1.4522338733878186

Epoch: 5| Step: 1
Training loss: 0.036987174302339554
Validation loss: 1.436020854980715

Epoch: 5| Step: 2
Training loss: 0.10004734992980957
Validation loss: 1.4672337501279769

Epoch: 5| Step: 3
Training loss: 0.09469132870435715
Validation loss: 1.4679015797953452

Epoch: 5| Step: 4
Training loss: 0.10106251388788223
Validation loss: 1.4570329202118741

Epoch: 5| Step: 5
Training loss: 0.05133315175771713
Validation loss: 1.4312790991157613

Epoch: 5| Step: 6
Training loss: 0.05658493563532829
Validation loss: 1.423958259244119

Epoch: 5| Step: 7
Training loss: 0.09070838242769241
Validation loss: 1.4142537719459944

Epoch: 5| Step: 8
Training loss: 0.08636236935853958
Validation loss: 1.3838347670852498

Epoch: 5| Step: 9
Training loss: 0.1207931786775589
Validation loss: 1.4084597870867739

Epoch: 5| Step: 10
Training loss: 0.08659404516220093
Validation loss: 1.4094468124451176

Epoch: 575| Step: 0
Training loss: 0.13100388646125793
Validation loss: 1.4100675762340587

Epoch: 5| Step: 1
Training loss: 0.09122483432292938
Validation loss: 1.3679452660263225

Epoch: 5| Step: 2
Training loss: 0.08960679918527603
Validation loss: 1.4295129237636444

Epoch: 5| Step: 3
Training loss: 0.11622996628284454
Validation loss: 1.4257114420654953

Epoch: 5| Step: 4
Training loss: 0.09291400760412216
Validation loss: 1.4409121826130857

Epoch: 5| Step: 5
Training loss: 0.11598315089941025
Validation loss: 1.4357911348342896

Epoch: 5| Step: 6
Training loss: 0.06255199015140533
Validation loss: 1.4395944751718992

Epoch: 5| Step: 7
Training loss: 0.10558585822582245
Validation loss: 1.4353343927732078

Epoch: 5| Step: 8
Training loss: 0.09229495376348495
Validation loss: 1.4239304463068645

Epoch: 5| Step: 9
Training loss: 0.08936329185962677
Validation loss: 1.4186066978721208

Epoch: 5| Step: 10
Training loss: 0.05037069320678711
Validation loss: 1.4265560219364781

Epoch: 576| Step: 0
Training loss: 0.13306692242622375
Validation loss: 1.4333629197971796

Epoch: 5| Step: 1
Training loss: 0.06611292064189911
Validation loss: 1.4555426771922777

Epoch: 5| Step: 2
Training loss: 0.0668642669916153
Validation loss: 1.4562369033854494

Epoch: 5| Step: 3
Training loss: 0.06321188807487488
Validation loss: 1.4351648278133844

Epoch: 5| Step: 4
Training loss: 0.09183812886476517
Validation loss: 1.4617368969866025

Epoch: 5| Step: 5
Training loss: 0.11636967957019806
Validation loss: 1.448442102760397

Epoch: 5| Step: 6
Training loss: 0.0656479224562645
Validation loss: 1.4436888271762478

Epoch: 5| Step: 7
Training loss: 0.09255632013082504
Validation loss: 1.4278414576284346

Epoch: 5| Step: 8
Training loss: 0.05487623065710068
Validation loss: 1.4538986631619033

Epoch: 5| Step: 9
Training loss: 0.1237894669175148
Validation loss: 1.4416348805991552

Epoch: 5| Step: 10
Training loss: 0.11358687281608582
Validation loss: 1.4410267376130628

Epoch: 577| Step: 0
Training loss: 0.09436524659395218
Validation loss: 1.4508753502240745

Epoch: 5| Step: 1
Training loss: 0.09449448436498642
Validation loss: 1.459051307811532

Epoch: 5| Step: 2
Training loss: 0.07272713631391525
Validation loss: 1.4493896320302

Epoch: 5| Step: 3
Training loss: 0.053540777415037155
Validation loss: 1.465872606282593

Epoch: 5| Step: 4
Training loss: 0.14897650480270386
Validation loss: 1.4517250625036096

Epoch: 5| Step: 5
Training loss: 0.08525816351175308
Validation loss: 1.451603590801198

Epoch: 5| Step: 6
Training loss: 0.10052476078271866
Validation loss: 1.461673664790328

Epoch: 5| Step: 7
Training loss: 0.0859123021364212
Validation loss: 1.4520934038264777

Epoch: 5| Step: 8
Training loss: 0.11970832198858261
Validation loss: 1.4909171237740466

Epoch: 5| Step: 9
Training loss: 0.054876815527677536
Validation loss: 1.4850402532085296

Epoch: 5| Step: 10
Training loss: 0.1670922487974167
Validation loss: 1.4935154414946032

Epoch: 578| Step: 0
Training loss: 0.0900714322924614
Validation loss: 1.4754607023731354

Epoch: 5| Step: 1
Training loss: 0.06215839833021164
Validation loss: 1.4620530118224442

Epoch: 5| Step: 2
Training loss: 0.10082080215215683
Validation loss: 1.469213802327392

Epoch: 5| Step: 3
Training loss: 0.13010446727275848
Validation loss: 1.4629899212109145

Epoch: 5| Step: 4
Training loss: 0.05882332846522331
Validation loss: 1.46411245804961

Epoch: 5| Step: 5
Training loss: 0.08353990316390991
Validation loss: 1.4518873781286261

Epoch: 5| Step: 6
Training loss: 0.10583384335041046
Validation loss: 1.4614465595573507

Epoch: 5| Step: 7
Training loss: 0.12840282917022705
Validation loss: 1.4762874508416781

Epoch: 5| Step: 8
Training loss: 0.09666856378316879
Validation loss: 1.4528720789058234

Epoch: 5| Step: 9
Training loss: 0.09261943399906158
Validation loss: 1.4499867821252475

Epoch: 5| Step: 10
Training loss: 0.07054285705089569
Validation loss: 1.4623485944604362

Epoch: 579| Step: 0
Training loss: 0.06967319548130035
Validation loss: 1.4285540901204592

Epoch: 5| Step: 1
Training loss: 0.10873124748468399
Validation loss: 1.4554194301687262

Epoch: 5| Step: 2
Training loss: 0.19221369922161102
Validation loss: 1.44151375755187

Epoch: 5| Step: 3
Training loss: 0.09088881313800812
Validation loss: 1.4350243794020785

Epoch: 5| Step: 4
Training loss: 0.07335591316223145
Validation loss: 1.451147581941338

Epoch: 5| Step: 5
Training loss: 0.18020352721214294
Validation loss: 1.4649706681569417

Epoch: 5| Step: 6
Training loss: 0.13766634464263916
Validation loss: 1.4510160825585807

Epoch: 5| Step: 7
Training loss: 0.07390183210372925
Validation loss: 1.4642099885530369

Epoch: 5| Step: 8
Training loss: 0.07757057249546051
Validation loss: 1.4393711538725003

Epoch: 5| Step: 9
Training loss: 0.09500933438539505
Validation loss: 1.4449398158698954

Epoch: 5| Step: 10
Training loss: 0.08698221296072006
Validation loss: 1.4743308700541014

Epoch: 580| Step: 0
Training loss: 0.07136138528585434
Validation loss: 1.4779384302836593

Epoch: 5| Step: 1
Training loss: 0.08932864665985107
Validation loss: 1.4652483937560872

Epoch: 5| Step: 2
Training loss: 0.059965234249830246
Validation loss: 1.4560937958378946

Epoch: 5| Step: 3
Training loss: 0.09568717330694199
Validation loss: 1.442071915954672

Epoch: 5| Step: 4
Training loss: 0.0977172702550888
Validation loss: 1.426831672268529

Epoch: 5| Step: 5
Training loss: 0.1129908561706543
Validation loss: 1.4226965814508417

Epoch: 5| Step: 6
Training loss: 0.09973212331533432
Validation loss: 1.4559517393830002

Epoch: 5| Step: 7
Training loss: 0.1505408138036728
Validation loss: 1.4215664491858533

Epoch: 5| Step: 8
Training loss: 0.057586394250392914
Validation loss: 1.430114875557602

Epoch: 5| Step: 9
Training loss: 0.07444293797016144
Validation loss: 1.4468790895195418

Epoch: 5| Step: 10
Training loss: 0.046263135969638824
Validation loss: 1.4474179795993272

Epoch: 581| Step: 0
Training loss: 0.1226838082075119
Validation loss: 1.4866845236029675

Epoch: 5| Step: 1
Training loss: 0.11684755980968475
Validation loss: 1.478134270637266

Epoch: 5| Step: 2
Training loss: 0.1092299371957779
Validation loss: 1.434850988849517

Epoch: 5| Step: 3
Training loss: 0.17595085501670837
Validation loss: 1.4545055897005144

Epoch: 5| Step: 4
Training loss: 0.08996818214654922
Validation loss: 1.4750089671022149

Epoch: 5| Step: 5
Training loss: 0.10616222769021988
Validation loss: 1.4790369336323073

Epoch: 5| Step: 6
Training loss: 0.07447422295808792
Validation loss: 1.4934571430247316

Epoch: 5| Step: 7
Training loss: 0.10644535720348358
Validation loss: 1.4910769795858732

Epoch: 5| Step: 8
Training loss: 0.07129843533039093
Validation loss: 1.4706067577485116

Epoch: 5| Step: 9
Training loss: 0.16672547161579132
Validation loss: 1.4629813483966294

Epoch: 5| Step: 10
Training loss: 0.05947915092110634
Validation loss: 1.4331332945054578

Epoch: 582| Step: 0
Training loss: 0.053965043276548386
Validation loss: 1.4281068886480024

Epoch: 5| Step: 1
Training loss: 0.07891125977039337
Validation loss: 1.4136848988071564

Epoch: 5| Step: 2
Training loss: 0.09001846611499786
Validation loss: 1.3990624399595364

Epoch: 5| Step: 3
Training loss: 0.175375834107399
Validation loss: 1.3826715330923758

Epoch: 5| Step: 4
Training loss: 0.07807429134845734
Validation loss: 1.401948078345227

Epoch: 5| Step: 5
Training loss: 0.09392423182725906
Validation loss: 1.3979042345477688

Epoch: 5| Step: 6
Training loss: 0.12554514408111572
Validation loss: 1.405928962974138

Epoch: 5| Step: 7
Training loss: 0.1465994119644165
Validation loss: 1.4255014452882993

Epoch: 5| Step: 8
Training loss: 0.10472835600376129
Validation loss: 1.4357098635806833

Epoch: 5| Step: 9
Training loss: 0.05780665948987007
Validation loss: 1.404732895153825

Epoch: 5| Step: 10
Training loss: 0.07404272258281708
Validation loss: 1.4137137134869893

Epoch: 583| Step: 0
Training loss: 0.08138515800237656
Validation loss: 1.4215642303548834

Epoch: 5| Step: 1
Training loss: 0.05218398571014404
Validation loss: 1.4266843385593866

Epoch: 5| Step: 2
Training loss: 0.05559217929840088
Validation loss: 1.4445629196782266

Epoch: 5| Step: 3
Training loss: 0.08022816479206085
Validation loss: 1.43688549277603

Epoch: 5| Step: 4
Training loss: 0.07816587388515472
Validation loss: 1.4568482797632936

Epoch: 5| Step: 5
Training loss: 0.11394451558589935
Validation loss: 1.4574573578373078

Epoch: 5| Step: 6
Training loss: 0.07221072167158127
Validation loss: 1.4403548061206777

Epoch: 5| Step: 7
Training loss: 0.0523080937564373
Validation loss: 1.467540241056873

Epoch: 5| Step: 8
Training loss: 0.16353262960910797
Validation loss: 1.4360249324511456

Epoch: 5| Step: 9
Training loss: 0.14960166811943054
Validation loss: 1.4576098239550026

Epoch: 5| Step: 10
Training loss: 0.05072137713432312
Validation loss: 1.4667022946060344

Epoch: 584| Step: 0
Training loss: 0.12064103037118912
Validation loss: 1.4431025744766317

Epoch: 5| Step: 1
Training loss: 0.10321793705224991
Validation loss: 1.426155053159242

Epoch: 5| Step: 2
Training loss: 0.0770985409617424
Validation loss: 1.4306858175544328

Epoch: 5| Step: 3
Training loss: 0.18455404043197632
Validation loss: 1.459983483437569

Epoch: 5| Step: 4
Training loss: 0.09795292466878891
Validation loss: 1.469063038467079

Epoch: 5| Step: 5
Training loss: 0.07754881680011749
Validation loss: 1.464313563480172

Epoch: 5| Step: 6
Training loss: 0.07666797935962677
Validation loss: 1.4779226703028525

Epoch: 5| Step: 7
Training loss: 0.056995414197444916
Validation loss: 1.4521663470934796

Epoch: 5| Step: 8
Training loss: 0.08256419003009796
Validation loss: 1.469660428903436

Epoch: 5| Step: 9
Training loss: 0.1517011821269989
Validation loss: 1.466721104037377

Epoch: 5| Step: 10
Training loss: 0.09991361945867538
Validation loss: 1.449845112780089

Epoch: 585| Step: 0
Training loss: 0.115633025765419
Validation loss: 1.4515842430053219

Epoch: 5| Step: 1
Training loss: 0.07995535433292389
Validation loss: 1.4549351405071955

Epoch: 5| Step: 2
Training loss: 0.07840045541524887
Validation loss: 1.476283270825622

Epoch: 5| Step: 3
Training loss: 0.07192318886518478
Validation loss: 1.4643376809294506

Epoch: 5| Step: 4
Training loss: 0.1751837134361267
Validation loss: 1.4643594257293209

Epoch: 5| Step: 5
Training loss: 0.08526572585105896
Validation loss: 1.4639826795106292

Epoch: 5| Step: 6
Training loss: 0.11731237173080444
Validation loss: 1.441669629466149

Epoch: 5| Step: 7
Training loss: 0.09282448142766953
Validation loss: 1.4707333541685534

Epoch: 5| Step: 8
Training loss: 0.1284855157136917
Validation loss: 1.423803868473217

Epoch: 5| Step: 9
Training loss: 0.07834886014461517
Validation loss: 1.4887388137079054

Epoch: 5| Step: 10
Training loss: 0.09533174335956573
Validation loss: 1.4977606496503275

Epoch: 586| Step: 0
Training loss: 0.13914187252521515
Validation loss: 1.4839090301144509

Epoch: 5| Step: 1
Training loss: 0.061079639941453934
Validation loss: 1.477203134567507

Epoch: 5| Step: 2
Training loss: 0.0713142454624176
Validation loss: 1.4858374082913963

Epoch: 5| Step: 3
Training loss: 0.060708753764629364
Validation loss: 1.4402024761963916

Epoch: 5| Step: 4
Training loss: 0.05188264697790146
Validation loss: 1.4272644865897395

Epoch: 5| Step: 5
Training loss: 0.12735383212566376
Validation loss: 1.4230711229385868

Epoch: 5| Step: 6
Training loss: 0.05643955618143082
Validation loss: 1.414046945110444

Epoch: 5| Step: 7
Training loss: 0.13358981907367706
Validation loss: 1.4139784407872025

Epoch: 5| Step: 8
Training loss: 0.09775787591934204
Validation loss: 1.4490879081910657

Epoch: 5| Step: 9
Training loss: 0.11007404327392578
Validation loss: 1.4239336739304245

Epoch: 5| Step: 10
Training loss: 0.06282179057598114
Validation loss: 1.4557927577726302

Epoch: 587| Step: 0
Training loss: 0.10799121856689453
Validation loss: 1.4187470084877425

Epoch: 5| Step: 1
Training loss: 0.14945438504219055
Validation loss: 1.4351951242775045

Epoch: 5| Step: 2
Training loss: 0.06940872967243195
Validation loss: 1.409150892688382

Epoch: 5| Step: 3
Training loss: 0.07349957525730133
Validation loss: 1.4228319468036774

Epoch: 5| Step: 4
Training loss: 0.10771045833826065
Validation loss: 1.4240609907334851

Epoch: 5| Step: 5
Training loss: 0.10010568797588348
Validation loss: 1.4473080365888533

Epoch: 5| Step: 6
Training loss: 0.09436759352684021
Validation loss: 1.4521363858253724

Epoch: 5| Step: 7
Training loss: 0.03592774644494057
Validation loss: 1.4506315082632086

Epoch: 5| Step: 8
Training loss: 0.06474779546260834
Validation loss: 1.4854086816951793

Epoch: 5| Step: 9
Training loss: 0.10644322633743286
Validation loss: 1.4768389463424683

Epoch: 5| Step: 10
Training loss: 0.11490243673324585
Validation loss: 1.471887832046837

Epoch: 588| Step: 0
Training loss: 0.06828022003173828
Validation loss: 1.4754022321393412

Epoch: 5| Step: 1
Training loss: 0.09208314120769501
Validation loss: 1.4663672601023028

Epoch: 5| Step: 2
Training loss: 0.12380605936050415
Validation loss: 1.4594404556417977

Epoch: 5| Step: 3
Training loss: 0.16751980781555176
Validation loss: 1.4597781877363882

Epoch: 5| Step: 4
Training loss: 0.08562595397233963
Validation loss: 1.4575456265480287

Epoch: 5| Step: 5
Training loss: 0.08047480136156082
Validation loss: 1.4559947688092467

Epoch: 5| Step: 6
Training loss: 0.10623966157436371
Validation loss: 1.4710741940365042

Epoch: 5| Step: 7
Training loss: 0.08010567724704742
Validation loss: 1.4398212650770783

Epoch: 5| Step: 8
Training loss: 0.10509133338928223
Validation loss: 1.4607772096510856

Epoch: 5| Step: 9
Training loss: 0.12324468791484833
Validation loss: 1.4595454328803605

Epoch: 5| Step: 10
Training loss: 0.11893920600414276
Validation loss: 1.4305301968769362

Epoch: 589| Step: 0
Training loss: 0.08061075210571289
Validation loss: 1.4272132855589672

Epoch: 5| Step: 1
Training loss: 0.09736347198486328
Validation loss: 1.4158439020956717

Epoch: 5| Step: 2
Training loss: 0.06049598380923271
Validation loss: 1.4156473862227572

Epoch: 5| Step: 3
Training loss: 0.13774314522743225
Validation loss: 1.4265153613141788

Epoch: 5| Step: 4
Training loss: 0.16826072335243225
Validation loss: 1.4208824878097863

Epoch: 5| Step: 5
Training loss: 0.06057854741811752
Validation loss: 1.4290259999613608

Epoch: 5| Step: 6
Training loss: 0.06465384364128113
Validation loss: 1.4186453639820058

Epoch: 5| Step: 7
Training loss: 0.07023146748542786
Validation loss: 1.4489843518503251

Epoch: 5| Step: 8
Training loss: 0.16777992248535156
Validation loss: 1.4542023968952957

Epoch: 5| Step: 9
Training loss: 0.058483172208070755
Validation loss: 1.4543413923632713

Epoch: 5| Step: 10
Training loss: 0.05665456876158714
Validation loss: 1.4386524615749237

Epoch: 590| Step: 0
Training loss: 0.043011195957660675
Validation loss: 1.432190288138646

Epoch: 5| Step: 1
Training loss: 0.10335983335971832
Validation loss: 1.4539064104839037

Epoch: 5| Step: 2
Training loss: 0.15347920358181
Validation loss: 1.4378359228052118

Epoch: 5| Step: 3
Training loss: 0.08940602838993073
Validation loss: 1.4441485187058807

Epoch: 5| Step: 4
Training loss: 0.08693023771047592
Validation loss: 1.4364076660525413

Epoch: 5| Step: 5
Training loss: 0.07785560190677643
Validation loss: 1.4625163193671935

Epoch: 5| Step: 6
Training loss: 0.10071295499801636
Validation loss: 1.455577842650875

Epoch: 5| Step: 7
Training loss: 0.07332377135753632
Validation loss: 1.4589292797991025

Epoch: 5| Step: 8
Training loss: 0.06688638776540756
Validation loss: 1.446238886925482

Epoch: 5| Step: 9
Training loss: 0.07454197853803635
Validation loss: 1.4499442865771632

Epoch: 5| Step: 10
Training loss: 0.05835198611021042
Validation loss: 1.4416305512510321

Epoch: 591| Step: 0
Training loss: 0.10740190744400024
Validation loss: 1.4771002005505305

Epoch: 5| Step: 1
Training loss: 0.10754875838756561
Validation loss: 1.477823233091703

Epoch: 5| Step: 2
Training loss: 0.06258635222911835
Validation loss: 1.465873625970656

Epoch: 5| Step: 3
Training loss: 0.08281766623258591
Validation loss: 1.4685488311193322

Epoch: 5| Step: 4
Training loss: 0.08467335999011993
Validation loss: 1.443460988742049

Epoch: 5| Step: 5
Training loss: 0.08610595762729645
Validation loss: 1.4636778062389744

Epoch: 5| Step: 6
Training loss: 0.11847539246082306
Validation loss: 1.4512338369123396

Epoch: 5| Step: 7
Training loss: 0.08110358566045761
Validation loss: 1.4690206422600696

Epoch: 5| Step: 8
Training loss: 0.07145946472883224
Validation loss: 1.4735133878646358

Epoch: 5| Step: 9
Training loss: 0.11032731831073761
Validation loss: 1.4760072500474992

Epoch: 5| Step: 10
Training loss: 0.0659383162856102
Validation loss: 1.474046600762234

Epoch: 592| Step: 0
Training loss: 0.11056628078222275
Validation loss: 1.4601705766493274

Epoch: 5| Step: 1
Training loss: 0.08828116953372955
Validation loss: 1.4634415513725691

Epoch: 5| Step: 2
Training loss: 0.08886003494262695
Validation loss: 1.4423250472673805

Epoch: 5| Step: 3
Training loss: 0.10332181304693222
Validation loss: 1.4602435942619079

Epoch: 5| Step: 4
Training loss: 0.08164368569850922
Validation loss: 1.413067961251864

Epoch: 5| Step: 5
Training loss: 0.07900680601596832
Validation loss: 1.4247198681677542

Epoch: 5| Step: 6
Training loss: 0.0785583108663559
Validation loss: 1.4374993539625598

Epoch: 5| Step: 7
Training loss: 0.07311450690031052
Validation loss: 1.4467923615568428

Epoch: 5| Step: 8
Training loss: 0.06807250529527664
Validation loss: 1.4156984654805993

Epoch: 5| Step: 9
Training loss: 0.13024044036865234
Validation loss: 1.4260614213123117

Epoch: 5| Step: 10
Training loss: 0.1035107970237732
Validation loss: 1.4154590566953023

Epoch: 593| Step: 0
Training loss: 0.1174636259675026
Validation loss: 1.4021055339485087

Epoch: 5| Step: 1
Training loss: 0.10622875392436981
Validation loss: 1.4057782209047707

Epoch: 5| Step: 2
Training loss: 0.0690988227725029
Validation loss: 1.4126537602434877

Epoch: 5| Step: 3
Training loss: 0.08889792114496231
Validation loss: 1.4428129298712618

Epoch: 5| Step: 4
Training loss: 0.09171570092439651
Validation loss: 1.4233939622038154

Epoch: 5| Step: 5
Training loss: 0.06422489881515503
Validation loss: 1.4308223314182733

Epoch: 5| Step: 6
Training loss: 0.0847654789686203
Validation loss: 1.4353091832130187

Epoch: 5| Step: 7
Training loss: 0.03272734582424164
Validation loss: 1.4634599416486678

Epoch: 5| Step: 8
Training loss: 0.09491456300020218
Validation loss: 1.4490779766472437

Epoch: 5| Step: 9
Training loss: 0.1577770709991455
Validation loss: 1.4687692414047897

Epoch: 5| Step: 10
Training loss: 0.13940636813640594
Validation loss: 1.478038667350687

Epoch: 594| Step: 0
Training loss: 0.08435235917568207
Validation loss: 1.503927856363276

Epoch: 5| Step: 1
Training loss: 0.07555107027292252
Validation loss: 1.4429382701073923

Epoch: 5| Step: 2
Training loss: 0.1310649961233139
Validation loss: 1.47359481165486

Epoch: 5| Step: 3
Training loss: 0.06215304136276245
Validation loss: 1.4723660843346709

Epoch: 5| Step: 4
Training loss: 0.10349953174591064
Validation loss: 1.456898154750947

Epoch: 5| Step: 5
Training loss: 0.11373038589954376
Validation loss: 1.4190909362608386

Epoch: 5| Step: 6
Training loss: 0.11058785766363144
Validation loss: 1.4090404638680079

Epoch: 5| Step: 7
Training loss: 0.06297573447227478
Validation loss: 1.4042236189688406

Epoch: 5| Step: 8
Training loss: 0.0621318593621254
Validation loss: 1.4191275924764655

Epoch: 5| Step: 9
Training loss: 0.10640089213848114
Validation loss: 1.412205171841447

Epoch: 5| Step: 10
Training loss: 0.08462783694267273
Validation loss: 1.4230579394166187

Epoch: 595| Step: 0
Training loss: 0.0630088821053505
Validation loss: 1.4213678542003836

Epoch: 5| Step: 1
Training loss: 0.1212657243013382
Validation loss: 1.4161778085975236

Epoch: 5| Step: 2
Training loss: 0.10749197006225586
Validation loss: 1.4351714990472282

Epoch: 5| Step: 3
Training loss: 0.1493738293647766
Validation loss: 1.406687166101189

Epoch: 5| Step: 4
Training loss: 0.060365062206983566
Validation loss: 1.4177847594343207

Epoch: 5| Step: 5
Training loss: 0.09271702915430069
Validation loss: 1.4214157929984472

Epoch: 5| Step: 6
Training loss: 0.06938942521810532
Validation loss: 1.4311888307653449

Epoch: 5| Step: 7
Training loss: 0.10320615768432617
Validation loss: 1.4350396151183753

Epoch: 5| Step: 8
Training loss: 0.07632984220981598
Validation loss: 1.413672262622464

Epoch: 5| Step: 9
Training loss: 0.04908285662531853
Validation loss: 1.4358763053853025

Epoch: 5| Step: 10
Training loss: 0.1160593032836914
Validation loss: 1.4477346430542648

Epoch: 596| Step: 0
Training loss: 0.09125934541225433
Validation loss: 1.4567390103493967

Epoch: 5| Step: 1
Training loss: 0.06795748323202133
Validation loss: 1.484123456862665

Epoch: 5| Step: 2
Training loss: 0.09542109072208405
Validation loss: 1.4848642913244103

Epoch: 5| Step: 3
Training loss: 0.08765526860952377
Validation loss: 1.4890878969623196

Epoch: 5| Step: 4
Training loss: 0.11034846305847168
Validation loss: 1.4720189712380851

Epoch: 5| Step: 5
Training loss: 0.14554540812969208
Validation loss: 1.459352594549938

Epoch: 5| Step: 6
Training loss: 0.06137757748365402
Validation loss: 1.4728916140012844

Epoch: 5| Step: 7
Training loss: 0.1042749434709549
Validation loss: 1.4671032210832

Epoch: 5| Step: 8
Training loss: 0.1173647865653038
Validation loss: 1.4600536528454031

Epoch: 5| Step: 9
Training loss: 0.09266257286071777
Validation loss: 1.4770336022941015

Epoch: 5| Step: 10
Training loss: 0.07925474643707275
Validation loss: 1.4498922645404775

Epoch: 597| Step: 0
Training loss: 0.14692804217338562
Validation loss: 1.447699011013072

Epoch: 5| Step: 1
Training loss: 0.09577952325344086
Validation loss: 1.4453240210010159

Epoch: 5| Step: 2
Training loss: 0.10448206961154938
Validation loss: 1.429792820766408

Epoch: 5| Step: 3
Training loss: 0.0955987200140953
Validation loss: 1.4176986730226906

Epoch: 5| Step: 4
Training loss: 0.09169813245534897
Validation loss: 1.4070403601533623

Epoch: 5| Step: 5
Training loss: 0.0926695317029953
Validation loss: 1.4093333098196215

Epoch: 5| Step: 6
Training loss: 0.09517060220241547
Validation loss: 1.4224443647169298

Epoch: 5| Step: 7
Training loss: 0.06427415460348129
Validation loss: 1.4350121405816847

Epoch: 5| Step: 8
Training loss: 0.06058310344815254
Validation loss: 1.4167785003621092

Epoch: 5| Step: 9
Training loss: 0.08271370828151703
Validation loss: 1.4284590598075622

Epoch: 5| Step: 10
Training loss: 0.08341657370328903
Validation loss: 1.43015359422212

Epoch: 598| Step: 0
Training loss: 0.05640460178256035
Validation loss: 1.4385984097757647

Epoch: 5| Step: 1
Training loss: 0.06536351144313812
Validation loss: 1.4203136031345656

Epoch: 5| Step: 2
Training loss: 0.06332623958587646
Validation loss: 1.413555977165058

Epoch: 5| Step: 3
Training loss: 0.07486234605312347
Validation loss: 1.420820564352056

Epoch: 5| Step: 4
Training loss: 0.12714768946170807
Validation loss: 1.4367242102981896

Epoch: 5| Step: 5
Training loss: 0.08839775621891022
Validation loss: 1.4316324572409354

Epoch: 5| Step: 6
Training loss: 0.07239766418933868
Validation loss: 1.439056513130024

Epoch: 5| Step: 7
Training loss: 0.09612695127725601
Validation loss: 1.4322729008172148

Epoch: 5| Step: 8
Training loss: 0.05461174249649048
Validation loss: 1.447342804683152

Epoch: 5| Step: 9
Training loss: 0.08611190319061279
Validation loss: 1.4376028532622962

Epoch: 5| Step: 10
Training loss: 0.05348316207528114
Validation loss: 1.4504906028829596

Epoch: 599| Step: 0
Training loss: 0.11256615817546844
Validation loss: 1.4592034810332841

Epoch: 5| Step: 1
Training loss: 0.06620100885629654
Validation loss: 1.4260870500277447

Epoch: 5| Step: 2
Training loss: 0.05480414628982544
Validation loss: 1.4382672668785177

Epoch: 5| Step: 3
Training loss: 0.07200002670288086
Validation loss: 1.4485852564534833

Epoch: 5| Step: 4
Training loss: 0.06445904076099396
Validation loss: 1.4420056144396465

Epoch: 5| Step: 5
Training loss: 0.11123605072498322
Validation loss: 1.4431455507073352

Epoch: 5| Step: 6
Training loss: 0.07313863188028336
Validation loss: 1.4505477977055374

Epoch: 5| Step: 7
Training loss: 0.07237233221530914
Validation loss: 1.4281308548424834

Epoch: 5| Step: 8
Training loss: 0.12733715772628784
Validation loss: 1.4418651596192391

Epoch: 5| Step: 9
Training loss: 0.12116950750350952
Validation loss: 1.4163185550320534

Epoch: 5| Step: 10
Training loss: 0.10269514471292496
Validation loss: 1.4020120354108914

Epoch: 600| Step: 0
Training loss: 0.11285040527582169
Validation loss: 1.4054711813567786

Epoch: 5| Step: 1
Training loss: 0.06621883064508438
Validation loss: 1.4039878768305625

Epoch: 5| Step: 2
Training loss: 0.10950364172458649
Validation loss: 1.3913212091692033

Epoch: 5| Step: 3
Training loss: 0.08525247126817703
Validation loss: 1.4299127497980673

Epoch: 5| Step: 4
Training loss: 0.10941009223461151
Validation loss: 1.4356681236656763

Epoch: 5| Step: 5
Training loss: 0.03533574566245079
Validation loss: 1.415931499132546

Epoch: 5| Step: 6
Training loss: 0.04687436297535896
Validation loss: 1.452143672973879

Epoch: 5| Step: 7
Training loss: 0.11257638782262802
Validation loss: 1.4622556894056258

Epoch: 5| Step: 8
Training loss: 0.05446792393922806
Validation loss: 1.4594931076931696

Epoch: 5| Step: 9
Training loss: 0.08165474981069565
Validation loss: 1.4558017561512608

Epoch: 5| Step: 10
Training loss: 0.12153489142656326
Validation loss: 1.4400058484846545

Epoch: 601| Step: 0
Training loss: 0.07034305483102798
Validation loss: 1.439077590742419

Epoch: 5| Step: 1
Training loss: 0.14119717478752136
Validation loss: 1.427124354788052

Epoch: 5| Step: 2
Training loss: 0.06972615420818329
Validation loss: 1.4086887926183722

Epoch: 5| Step: 3
Training loss: 0.07211494445800781
Validation loss: 1.4136552169758787

Epoch: 5| Step: 4
Training loss: 0.10362943261861801
Validation loss: 1.3966950716510895

Epoch: 5| Step: 5
Training loss: 0.1115400418639183
Validation loss: 1.4268483987418554

Epoch: 5| Step: 6
Training loss: 0.08321239054203033
Validation loss: 1.4401990546975085

Epoch: 5| Step: 7
Training loss: 0.08061616122722626
Validation loss: 1.4568736066100418

Epoch: 5| Step: 8
Training loss: 0.08432398736476898
Validation loss: 1.4325717700425016

Epoch: 5| Step: 9
Training loss: 0.07465587556362152
Validation loss: 1.4171675892286404

Epoch: 5| Step: 10
Training loss: 0.08428007364273071
Validation loss: 1.39525887145791

Epoch: 602| Step: 0
Training loss: 0.04689404368400574
Validation loss: 1.3928674741457867

Epoch: 5| Step: 1
Training loss: 0.06037425994873047
Validation loss: 1.388826935522018

Epoch: 5| Step: 2
Training loss: 0.10776908695697784
Validation loss: 1.3820051095818962

Epoch: 5| Step: 3
Training loss: 0.11163272708654404
Validation loss: 1.355664373085063

Epoch: 5| Step: 4
Training loss: 0.13967470824718475
Validation loss: 1.3722542601246988

Epoch: 5| Step: 5
Training loss: 0.09640638530254364
Validation loss: 1.392650705511852

Epoch: 5| Step: 6
Training loss: 0.0585259385406971
Validation loss: 1.4034083850922123

Epoch: 5| Step: 7
Training loss: 0.06729993224143982
Validation loss: 1.3908046317356888

Epoch: 5| Step: 8
Training loss: 0.11647845804691315
Validation loss: 1.419259198250309

Epoch: 5| Step: 9
Training loss: 0.12341423332691193
Validation loss: 1.4532476291861585

Epoch: 5| Step: 10
Training loss: 0.049840718507766724
Validation loss: 1.4559785909550165

Epoch: 603| Step: 0
Training loss: 0.07498796284198761
Validation loss: 1.4671292292174472

Epoch: 5| Step: 1
Training loss: 0.08757118880748749
Validation loss: 1.4435279805173156

Epoch: 5| Step: 2
Training loss: 0.0653742328286171
Validation loss: 1.4292442939614738

Epoch: 5| Step: 3
Training loss: 0.07264425605535507
Validation loss: 1.4246860293931858

Epoch: 5| Step: 4
Training loss: 0.08861806988716125
Validation loss: 1.4288311017456876

Epoch: 5| Step: 5
Training loss: 0.16550345718860626
Validation loss: 1.4333039022261096

Epoch: 5| Step: 6
Training loss: 0.09049937129020691
Validation loss: 1.4187068452117264

Epoch: 5| Step: 7
Training loss: 0.09029240906238556
Validation loss: 1.3907957077026367

Epoch: 5| Step: 8
Training loss: 0.07840541750192642
Validation loss: 1.400635564199058

Epoch: 5| Step: 9
Training loss: 0.11176049709320068
Validation loss: 1.4228563808625745

Epoch: 5| Step: 10
Training loss: 0.06726189702749252
Validation loss: 1.4198630920020483

Epoch: 604| Step: 0
Training loss: 0.04874333739280701
Validation loss: 1.4067735287450975

Epoch: 5| Step: 1
Training loss: 0.12842455506324768
Validation loss: 1.4548916329619705

Epoch: 5| Step: 2
Training loss: 0.05411217734217644
Validation loss: 1.4342206101263724

Epoch: 5| Step: 3
Training loss: 0.047388188540935516
Validation loss: 1.4363737426778322

Epoch: 5| Step: 4
Training loss: 0.05701892450451851
Validation loss: 1.43165276768387

Epoch: 5| Step: 5
Training loss: 0.1158243864774704
Validation loss: 1.408587759540927

Epoch: 5| Step: 6
Training loss: 0.10370519012212753
Validation loss: 1.4205652507402564

Epoch: 5| Step: 7
Training loss: 0.1126910001039505
Validation loss: 1.4122661377794

Epoch: 5| Step: 8
Training loss: 0.07664110511541367
Validation loss: 1.4066721072760962

Epoch: 5| Step: 9
Training loss: 0.05928053706884384
Validation loss: 1.421770413716634

Epoch: 5| Step: 10
Training loss: 0.06732379645109177
Validation loss: 1.4290971691890428

Epoch: 605| Step: 0
Training loss: 0.06273666769266129
Validation loss: 1.4253322206517702

Epoch: 5| Step: 1
Training loss: 0.10956788063049316
Validation loss: 1.4433466542151667

Epoch: 5| Step: 2
Training loss: 0.07486440241336823
Validation loss: 1.4422146363924908

Epoch: 5| Step: 3
Training loss: 0.09892002493143082
Validation loss: 1.443817405290501

Epoch: 5| Step: 4
Training loss: 0.0800512284040451
Validation loss: 1.4440683126449585

Epoch: 5| Step: 5
Training loss: 0.07658414542675018
Validation loss: 1.4206417081176594

Epoch: 5| Step: 6
Training loss: 0.08334179222583771
Validation loss: 1.4349224708413566

Epoch: 5| Step: 7
Training loss: 0.0840684175491333
Validation loss: 1.4091165245220225

Epoch: 5| Step: 8
Training loss: 0.06898672878742218
Validation loss: 1.4136560963046165

Epoch: 5| Step: 9
Training loss: 0.09491666406393051
Validation loss: 1.4156146254590762

Epoch: 5| Step: 10
Training loss: 0.10476487129926682
Validation loss: 1.4350951092858468

Epoch: 606| Step: 0
Training loss: 0.058751463890075684
Validation loss: 1.4539278623878316

Epoch: 5| Step: 1
Training loss: 0.0427204966545105
Validation loss: 1.4618644541309727

Epoch: 5| Step: 2
Training loss: 0.12555649876594543
Validation loss: 1.4520425860599806

Epoch: 5| Step: 3
Training loss: 0.07888734340667725
Validation loss: 1.457915453500645

Epoch: 5| Step: 4
Training loss: 0.07845431566238403
Validation loss: 1.4596745006499752

Epoch: 5| Step: 5
Training loss: 0.07773689925670624
Validation loss: 1.4285407220163653

Epoch: 5| Step: 6
Training loss: 0.07263801246881485
Validation loss: 1.4398918664583595

Epoch: 5| Step: 7
Training loss: 0.1069263219833374
Validation loss: 1.449218439158573

Epoch: 5| Step: 8
Training loss: 0.10195030272006989
Validation loss: 1.444592498963879

Epoch: 5| Step: 9
Training loss: 0.06589800864458084
Validation loss: 1.4418017075907799

Epoch: 5| Step: 10
Training loss: 0.0726286917924881
Validation loss: 1.4573235947598693

Epoch: 607| Step: 0
Training loss: 0.08478774130344391
Validation loss: 1.4297928579391972

Epoch: 5| Step: 1
Training loss: 0.07204225659370422
Validation loss: 1.4567435633751653

Epoch: 5| Step: 2
Training loss: 0.14098040759563446
Validation loss: 1.4522452918432092

Epoch: 5| Step: 3
Training loss: 0.06104891374707222
Validation loss: 1.4576186287787654

Epoch: 5| Step: 4
Training loss: 0.03749042749404907
Validation loss: 1.465890008916137

Epoch: 5| Step: 5
Training loss: 0.06254023313522339
Validation loss: 1.439078660421474

Epoch: 5| Step: 6
Training loss: 0.04438776895403862
Validation loss: 1.4452691232004473

Epoch: 5| Step: 7
Training loss: 0.049191612750291824
Validation loss: 1.443710465585032

Epoch: 5| Step: 8
Training loss: 0.06631346046924591
Validation loss: 1.4563400001936062

Epoch: 5| Step: 9
Training loss: 0.1387767195701599
Validation loss: 1.451239619203793

Epoch: 5| Step: 10
Training loss: 0.09021835774183273
Validation loss: 1.4468000768333353

Epoch: 608| Step: 0
Training loss: 0.053535234183073044
Validation loss: 1.460732416440082

Epoch: 5| Step: 1
Training loss: 0.09374472498893738
Validation loss: 1.4738043380039993

Epoch: 5| Step: 2
Training loss: 0.10470012575387955
Validation loss: 1.4630450176936325

Epoch: 5| Step: 3
Training loss: 0.11311624199151993
Validation loss: 1.4594269484601996

Epoch: 5| Step: 4
Training loss: 0.08333295583724976
Validation loss: 1.4820597774238997

Epoch: 5| Step: 5
Training loss: 0.046331681311130524
Validation loss: 1.4703940197985659

Epoch: 5| Step: 6
Training loss: 0.08516398072242737
Validation loss: 1.4636104247903312

Epoch: 5| Step: 7
Training loss: 0.11656641960144043
Validation loss: 1.4578403452391266

Epoch: 5| Step: 8
Training loss: 0.06466397643089294
Validation loss: 1.435655399035382

Epoch: 5| Step: 9
Training loss: 0.07042644917964935
Validation loss: 1.4457922917540356

Epoch: 5| Step: 10
Training loss: 0.07331915944814682
Validation loss: 1.4372074283579344

Epoch: 609| Step: 0
Training loss: 0.11761225759983063
Validation loss: 1.4420440805855619

Epoch: 5| Step: 1
Training loss: 0.039193592965602875
Validation loss: 1.4482253956538376

Epoch: 5| Step: 2
Training loss: 0.05952554941177368
Validation loss: 1.4697521681426673

Epoch: 5| Step: 3
Training loss: 0.08457577228546143
Validation loss: 1.4755116329398206

Epoch: 5| Step: 4
Training loss: 0.06472405046224594
Validation loss: 1.4621032989153298

Epoch: 5| Step: 5
Training loss: 0.0618758499622345
Validation loss: 1.454080399646554

Epoch: 5| Step: 6
Training loss: 0.14741787314414978
Validation loss: 1.4548592080352127

Epoch: 5| Step: 7
Training loss: 0.09186466038227081
Validation loss: 1.4317561413652153

Epoch: 5| Step: 8
Training loss: 0.09189123660326004
Validation loss: 1.450648764128326

Epoch: 5| Step: 9
Training loss: 0.09966824948787689
Validation loss: 1.421635748237692

Epoch: 5| Step: 10
Training loss: 0.06031615659594536
Validation loss: 1.4423218555347894

Epoch: 610| Step: 0
Training loss: 0.06516028940677643
Validation loss: 1.4249701064120057

Epoch: 5| Step: 1
Training loss: 0.07665951550006866
Validation loss: 1.4481408467856787

Epoch: 5| Step: 2
Training loss: 0.12191052734851837
Validation loss: 1.4562462658010504

Epoch: 5| Step: 3
Training loss: 0.1220252737402916
Validation loss: 1.4655978000292214

Epoch: 5| Step: 4
Training loss: 0.061683785170316696
Validation loss: 1.4330295414052985

Epoch: 5| Step: 5
Training loss: 0.07280929386615753
Validation loss: 1.4201358223474154

Epoch: 5| Step: 6
Training loss: 0.0606999509036541
Validation loss: 1.4016456206639607

Epoch: 5| Step: 7
Training loss: 0.11298152059316635
Validation loss: 1.3872942860408495

Epoch: 5| Step: 8
Training loss: 0.13777726888656616
Validation loss: 1.4063995307491672

Epoch: 5| Step: 9
Training loss: 0.07593648880720139
Validation loss: 1.4240760828859063

Epoch: 5| Step: 10
Training loss: 0.054736215621232986
Validation loss: 1.4413340418569502

Epoch: 611| Step: 0
Training loss: 0.05472790077328682
Validation loss: 1.4456049357691119

Epoch: 5| Step: 1
Training loss: 0.09077413380146027
Validation loss: 1.5018999499659385

Epoch: 5| Step: 2
Training loss: 0.10730364173650742
Validation loss: 1.4916921854019165

Epoch: 5| Step: 3
Training loss: 0.10767762362957001
Validation loss: 1.4879143468795284

Epoch: 5| Step: 4
Training loss: 0.06577559560537338
Validation loss: 1.4513092271743282

Epoch: 5| Step: 5
Training loss: 0.0720137506723404
Validation loss: 1.4720700979232788

Epoch: 5| Step: 6
Training loss: 0.08863933384418488
Validation loss: 1.4425331469505065

Epoch: 5| Step: 7
Training loss: 0.08856658637523651
Validation loss: 1.4355511947344708

Epoch: 5| Step: 8
Training loss: 0.10901319980621338
Validation loss: 1.4249874481590845

Epoch: 5| Step: 9
Training loss: 0.06801550090312958
Validation loss: 1.445073083523781

Epoch: 5| Step: 10
Training loss: 0.07660232484340668
Validation loss: 1.4162920559606245

Epoch: 612| Step: 0
Training loss: 0.0695597380399704
Validation loss: 1.4140932418966805

Epoch: 5| Step: 1
Training loss: 0.08117973804473877
Validation loss: 1.4363035348153883

Epoch: 5| Step: 2
Training loss: 0.09597988426685333
Validation loss: 1.40370011842379

Epoch: 5| Step: 3
Training loss: 0.12364276498556137
Validation loss: 1.4270909947733725

Epoch: 5| Step: 4
Training loss: 0.08365068584680557
Validation loss: 1.4199435813452608

Epoch: 5| Step: 5
Training loss: 0.09509597718715668
Validation loss: 1.4181178872303297

Epoch: 5| Step: 6
Training loss: 0.07244548201560974
Validation loss: 1.4214143650506132

Epoch: 5| Step: 7
Training loss: 0.08308036625385284
Validation loss: 1.4229219100808586

Epoch: 5| Step: 8
Training loss: 0.09179352223873138
Validation loss: 1.3965279735544676

Epoch: 5| Step: 9
Training loss: 0.03787783905863762
Validation loss: 1.4038727603932863

Epoch: 5| Step: 10
Training loss: 0.04523327201604843
Validation loss: 1.4117881392919889

Epoch: 613| Step: 0
Training loss: 0.0358608178794384
Validation loss: 1.4260726622355882

Epoch: 5| Step: 1
Training loss: 0.09560894966125488
Validation loss: 1.445224246671123

Epoch: 5| Step: 2
Training loss: 0.11208796501159668
Validation loss: 1.4462320599504697

Epoch: 5| Step: 3
Training loss: 0.0778212696313858
Validation loss: 1.431188517360277

Epoch: 5| Step: 4
Training loss: 0.10359907150268555
Validation loss: 1.4518422119079097

Epoch: 5| Step: 5
Training loss: 0.11268581449985504
Validation loss: 1.4486153228308565

Epoch: 5| Step: 6
Training loss: 0.09598435461521149
Validation loss: 1.4629251380120554

Epoch: 5| Step: 7
Training loss: 0.06260561943054199
Validation loss: 1.4296461882129792

Epoch: 5| Step: 8
Training loss: 0.0676027163863182
Validation loss: 1.3972476605446107

Epoch: 5| Step: 9
Training loss: 0.053406573832035065
Validation loss: 1.4093983122097549

Epoch: 5| Step: 10
Training loss: 0.15337011218070984
Validation loss: 1.4041936730825773

Epoch: 614| Step: 0
Training loss: 0.07566658407449722
Validation loss: 1.379605048446245

Epoch: 5| Step: 1
Training loss: 0.11001791059970856
Validation loss: 1.3892892022286691

Epoch: 5| Step: 2
Training loss: 0.09449939429759979
Validation loss: 1.3988603686773649

Epoch: 5| Step: 3
Training loss: 0.12350010871887207
Validation loss: 1.4435051064337454

Epoch: 5| Step: 4
Training loss: 0.05110293626785278
Validation loss: 1.4634688387634933

Epoch: 5| Step: 5
Training loss: 0.08100593090057373
Validation loss: 1.4309794261891355

Epoch: 5| Step: 6
Training loss: 0.05489494279026985
Validation loss: 1.4054165027474845

Epoch: 5| Step: 7
Training loss: 0.11572937667369843
Validation loss: 1.416335025141316

Epoch: 5| Step: 8
Training loss: 0.08750494569540024
Validation loss: 1.3929332097371419

Epoch: 5| Step: 9
Training loss: 0.059602826833724976
Validation loss: 1.4110459217461206

Epoch: 5| Step: 10
Training loss: 0.1395494043827057
Validation loss: 1.3909330303950975

Epoch: 615| Step: 0
Training loss: 0.101934053003788
Validation loss: 1.4155552066782469

Epoch: 5| Step: 1
Training loss: 0.09422571957111359
Validation loss: 1.4179364308234184

Epoch: 5| Step: 2
Training loss: 0.09496212005615234
Validation loss: 1.4269852304971347

Epoch: 5| Step: 3
Training loss: 0.03101370297372341
Validation loss: 1.3787810930641748

Epoch: 5| Step: 4
Training loss: 0.06444407999515533
Validation loss: 1.3935238597213582

Epoch: 5| Step: 5
Training loss: 0.07461364567279816
Validation loss: 1.3703286878524288

Epoch: 5| Step: 6
Training loss: 0.11919935792684555
Validation loss: 1.3513060051907775

Epoch: 5| Step: 7
Training loss: 0.12489970028400421
Validation loss: 1.3574846470227806

Epoch: 5| Step: 8
Training loss: 0.08043692260980606
Validation loss: 1.3726382608054786

Epoch: 5| Step: 9
Training loss: 0.10927138477563858
Validation loss: 1.4081512356317172

Epoch: 5| Step: 10
Training loss: 0.07996765524148941
Validation loss: 1.4029510790301907

Epoch: 616| Step: 0
Training loss: 0.078895702958107
Validation loss: 1.4147361324679466

Epoch: 5| Step: 1
Training loss: 0.06813453137874603
Validation loss: 1.4280008705713416

Epoch: 5| Step: 2
Training loss: 0.10699760913848877
Validation loss: 1.4186807787546547

Epoch: 5| Step: 3
Training loss: 0.09040588140487671
Validation loss: 1.4212781677963913

Epoch: 5| Step: 4
Training loss: 0.08321432769298553
Validation loss: 1.423392093309792

Epoch: 5| Step: 5
Training loss: 0.07350761443376541
Validation loss: 1.4266586066574178

Epoch: 5| Step: 6
Training loss: 0.08209720999002457
Validation loss: 1.4214986408910444

Epoch: 5| Step: 7
Training loss: 0.06604760140180588
Validation loss: 1.4297712554213822

Epoch: 5| Step: 8
Training loss: 0.08525622636079788
Validation loss: 1.4211865766074068

Epoch: 5| Step: 9
Training loss: 0.09183026850223541
Validation loss: 1.4263757710815759

Epoch: 5| Step: 10
Training loss: 0.07200350612401962
Validation loss: 1.4402341317105036

Epoch: 617| Step: 0
Training loss: 0.07079021632671356
Validation loss: 1.446650456356746

Epoch: 5| Step: 1
Training loss: 0.12934449315071106
Validation loss: 1.414211521866501

Epoch: 5| Step: 2
Training loss: 0.09566499292850494
Validation loss: 1.4045257324813514

Epoch: 5| Step: 3
Training loss: 0.07954622805118561
Validation loss: 1.4021375833019134

Epoch: 5| Step: 4
Training loss: 0.08589644730091095
Validation loss: 1.3871138300946964

Epoch: 5| Step: 5
Training loss: 0.10421063005924225
Validation loss: 1.3740063123805548

Epoch: 5| Step: 6
Training loss: 0.10657913982868195
Validation loss: 1.379089532359954

Epoch: 5| Step: 7
Training loss: 0.08131811767816544
Validation loss: 1.3616211786065051

Epoch: 5| Step: 8
Training loss: 0.09969780594110489
Validation loss: 1.3597456691085652

Epoch: 5| Step: 9
Training loss: 0.08259065449237823
Validation loss: 1.3905864774539907

Epoch: 5| Step: 10
Training loss: 0.07555077224969864
Validation loss: 1.3935356652864845

Epoch: 618| Step: 0
Training loss: 0.07791386544704437
Validation loss: 1.4147699417606476

Epoch: 5| Step: 1
Training loss: 0.1049538403749466
Validation loss: 1.4067984793775825

Epoch: 5| Step: 2
Training loss: 0.11270058155059814
Validation loss: 1.4211368009608278

Epoch: 5| Step: 3
Training loss: 0.10715143382549286
Validation loss: 1.393380106136363

Epoch: 5| Step: 4
Training loss: 0.08532331883907318
Validation loss: 1.4007672545730427

Epoch: 5| Step: 5
Training loss: 0.07702548056840897
Validation loss: 1.3693398044955345

Epoch: 5| Step: 6
Training loss: 0.10211332142353058
Validation loss: 1.3721442350777246

Epoch: 5| Step: 7
Training loss: 0.07061383128166199
Validation loss: 1.3648916957198933

Epoch: 5| Step: 8
Training loss: 0.08794127404689789
Validation loss: 1.3616906673677507

Epoch: 5| Step: 9
Training loss: 0.07949849963188171
Validation loss: 1.3769795497258503

Epoch: 5| Step: 10
Training loss: 0.08814101666212082
Validation loss: 1.3721051363534824

Epoch: 619| Step: 0
Training loss: 0.11237648874521255
Validation loss: 1.4000745716915335

Epoch: 5| Step: 1
Training loss: 0.08975270390510559
Validation loss: 1.41903728823508

Epoch: 5| Step: 2
Training loss: 0.0836317241191864
Validation loss: 1.4236657677158233

Epoch: 5| Step: 3
Training loss: 0.07283826172351837
Validation loss: 1.445594132587474

Epoch: 5| Step: 4
Training loss: 0.0798032358288765
Validation loss: 1.4666176995923441

Epoch: 5| Step: 5
Training loss: 0.06237081438302994
Validation loss: 1.457029970743323

Epoch: 5| Step: 6
Training loss: 0.07620196044445038
Validation loss: 1.495709906342209

Epoch: 5| Step: 7
Training loss: 0.1218407154083252
Validation loss: 1.4733310886608657

Epoch: 5| Step: 8
Training loss: 0.15415945649147034
Validation loss: 1.4792753381113852

Epoch: 5| Step: 9
Training loss: 0.06805646419525146
Validation loss: 1.473683020120026

Epoch: 5| Step: 10
Training loss: 0.10454531759023666
Validation loss: 1.4490275100995136

Epoch: 620| Step: 0
Training loss: 0.12312798202037811
Validation loss: 1.4649424014552948

Epoch: 5| Step: 1
Training loss: 0.1299840211868286
Validation loss: 1.46245527011092

Epoch: 5| Step: 2
Training loss: 0.0481165312230587
Validation loss: 1.450715975094867

Epoch: 5| Step: 3
Training loss: 0.08208062499761581
Validation loss: 1.432241242419007

Epoch: 5| Step: 4
Training loss: 0.049774039536714554
Validation loss: 1.4201992634804017

Epoch: 5| Step: 5
Training loss: 0.0857304185628891
Validation loss: 1.402997475798412

Epoch: 5| Step: 6
Training loss: 0.126577228307724
Validation loss: 1.4321991141124437

Epoch: 5| Step: 7
Training loss: 0.041971366852521896
Validation loss: 1.3947856259602371

Epoch: 5| Step: 8
Training loss: 0.0871836245059967
Validation loss: 1.393113543910365

Epoch: 5| Step: 9
Training loss: 0.12245172262191772
Validation loss: 1.3722116729264617

Epoch: 5| Step: 10
Training loss: 0.10105084627866745
Validation loss: 1.3768040210969987

Epoch: 621| Step: 0
Training loss: 0.042810045182704926
Validation loss: 1.381865878258982

Epoch: 5| Step: 1
Training loss: 0.089958056807518
Validation loss: 1.3930189788982432

Epoch: 5| Step: 2
Training loss: 0.09107774496078491
Validation loss: 1.3924191703078568

Epoch: 5| Step: 3
Training loss: 0.09141671657562256
Validation loss: 1.4160289764404297

Epoch: 5| Step: 4
Training loss: 0.10937733948230743
Validation loss: 1.4082361619959596

Epoch: 5| Step: 5
Training loss: 0.07270924746990204
Validation loss: 1.4162559624641173

Epoch: 5| Step: 6
Training loss: 0.09622297435998917
Validation loss: 1.4108201944699852

Epoch: 5| Step: 7
Training loss: 0.09572882205247879
Validation loss: 1.4123456785755772

Epoch: 5| Step: 8
Training loss: 0.1355070322751999
Validation loss: 1.4130816318655526

Epoch: 5| Step: 9
Training loss: 0.07552500069141388
Validation loss: 1.4404610985068864

Epoch: 5| Step: 10
Training loss: 0.08524058014154434
Validation loss: 1.445495056849654

Epoch: 622| Step: 0
Training loss: 0.059509050101041794
Validation loss: 1.4469130462215793

Epoch: 5| Step: 1
Training loss: 0.12605026364326477
Validation loss: 1.4417929533989198

Epoch: 5| Step: 2
Training loss: 0.06570033729076385
Validation loss: 1.4181652069091797

Epoch: 5| Step: 3
Training loss: 0.06098676845431328
Validation loss: 1.3909083213857425

Epoch: 5| Step: 4
Training loss: 0.060965098440647125
Validation loss: 1.3988093227468512

Epoch: 5| Step: 5
Training loss: 0.07733909785747528
Validation loss: 1.4040984556239138

Epoch: 5| Step: 6
Training loss: 0.11863896995782852
Validation loss: 1.3867669733621741

Epoch: 5| Step: 7
Training loss: 0.12938359379768372
Validation loss: 1.3874913261782738

Epoch: 5| Step: 8
Training loss: 0.09811736643314362
Validation loss: 1.3917984834281347

Epoch: 5| Step: 9
Training loss: 0.07560816407203674
Validation loss: 1.3779595385315597

Epoch: 5| Step: 10
Training loss: 0.05084598809480667
Validation loss: 1.4006444023501488

Epoch: 623| Step: 0
Training loss: 0.1023762971162796
Validation loss: 1.4107277694568838

Epoch: 5| Step: 1
Training loss: 0.08473654091358185
Validation loss: 1.424771015362073

Epoch: 5| Step: 2
Training loss: 0.09880741685628891
Validation loss: 1.4628703440389326

Epoch: 5| Step: 3
Training loss: 0.13845625519752502
Validation loss: 1.4802843281017837

Epoch: 5| Step: 4
Training loss: 0.06108303740620613
Validation loss: 1.4751225979097429

Epoch: 5| Step: 5
Training loss: 0.09055633097887039
Validation loss: 1.4427137156968475

Epoch: 5| Step: 6
Training loss: 0.0601717010140419
Validation loss: 1.4462885766900995

Epoch: 5| Step: 7
Training loss: 0.09445612877607346
Validation loss: 1.4367489186666345

Epoch: 5| Step: 8
Training loss: 0.06197851896286011
Validation loss: 1.4488701820373535

Epoch: 5| Step: 9
Training loss: 0.07973774522542953
Validation loss: 1.45107356450891

Epoch: 5| Step: 10
Training loss: 0.08637373894453049
Validation loss: 1.4501562400530743

Epoch: 624| Step: 0
Training loss: 0.05634722113609314
Validation loss: 1.436052257014859

Epoch: 5| Step: 1
Training loss: 0.10820560157299042
Validation loss: 1.4487389236368158

Epoch: 5| Step: 2
Training loss: 0.08903981000185013
Validation loss: 1.451174554004464

Epoch: 5| Step: 3
Training loss: 0.06426093727350235
Validation loss: 1.4716582067551152

Epoch: 5| Step: 4
Training loss: 0.06873272359371185
Validation loss: 1.4752184947331746

Epoch: 5| Step: 5
Training loss: 0.05908302217721939
Validation loss: 1.458013839619134

Epoch: 5| Step: 6
Training loss: 0.06512624770402908
Validation loss: 1.4395949122726277

Epoch: 5| Step: 7
Training loss: 0.06460617482662201
Validation loss: 1.4002757008357714

Epoch: 5| Step: 8
Training loss: 0.09205441176891327
Validation loss: 1.3918907283454813

Epoch: 5| Step: 9
Training loss: 0.09511750936508179
Validation loss: 1.4060271965560092

Epoch: 5| Step: 10
Training loss: 0.11117929220199585
Validation loss: 1.388847747156697

Epoch: 625| Step: 0
Training loss: 0.06168978288769722
Validation loss: 1.3970002435868787

Epoch: 5| Step: 1
Training loss: 0.08071421086788177
Validation loss: 1.392006439547385

Epoch: 5| Step: 2
Training loss: 0.0799529105424881
Validation loss: 1.4199428340440154

Epoch: 5| Step: 3
Training loss: 0.08332423865795135
Validation loss: 1.4184590892125202

Epoch: 5| Step: 4
Training loss: 0.09906475245952606
Validation loss: 1.4277204967314197

Epoch: 5| Step: 5
Training loss: 0.11772777885198593
Validation loss: 1.4212210011738602

Epoch: 5| Step: 6
Training loss: 0.04756074771285057
Validation loss: 1.3989536044418172

Epoch: 5| Step: 7
Training loss: 0.062254440039396286
Validation loss: 1.4147517713167335

Epoch: 5| Step: 8
Training loss: 0.09968283027410507
Validation loss: 1.4263389181065302

Epoch: 5| Step: 9
Training loss: 0.0565204918384552
Validation loss: 1.4269602978101341

Epoch: 5| Step: 10
Training loss: 0.0624176487326622
Validation loss: 1.4408900776217062

Epoch: 626| Step: 0
Training loss: 0.11984653770923615
Validation loss: 1.4384867170805573

Epoch: 5| Step: 1
Training loss: 0.07395150512456894
Validation loss: 1.4363968115980907

Epoch: 5| Step: 2
Training loss: 0.10355784744024277
Validation loss: 1.4410677340722853

Epoch: 5| Step: 3
Training loss: 0.11346860975027084
Validation loss: 1.4312904034891436

Epoch: 5| Step: 4
Training loss: 0.053001631051301956
Validation loss: 1.43465817359186

Epoch: 5| Step: 5
Training loss: 0.06180927902460098
Validation loss: 1.4256094617228354

Epoch: 5| Step: 6
Training loss: 0.07431428879499435
Validation loss: 1.4232615809286795

Epoch: 5| Step: 7
Training loss: 0.06309740245342255
Validation loss: 1.4015632258948458

Epoch: 5| Step: 8
Training loss: 0.07015607506036758
Validation loss: 1.4253667426365677

Epoch: 5| Step: 9
Training loss: 0.053022600710392
Validation loss: 1.391931285140335

Epoch: 5| Step: 10
Training loss: 0.06673309206962585
Validation loss: 1.3869260011180755

Epoch: 627| Step: 0
Training loss: 0.08667882531881332
Validation loss: 1.3925916046224616

Epoch: 5| Step: 1
Training loss: 0.09320712834596634
Validation loss: 1.3914473736157982

Epoch: 5| Step: 2
Training loss: 0.07640298455953598
Validation loss: 1.3971795458947458

Epoch: 5| Step: 3
Training loss: 0.06847786903381348
Validation loss: 1.4135867472617858

Epoch: 5| Step: 4
Training loss: 0.05318794772028923
Validation loss: 1.4205891022118189

Epoch: 5| Step: 5
Training loss: 0.05811157077550888
Validation loss: 1.412215043139714

Epoch: 5| Step: 6
Training loss: 0.05311398580670357
Validation loss: 1.4235037167867024

Epoch: 5| Step: 7
Training loss: 0.060973040759563446
Validation loss: 1.3979818692771337

Epoch: 5| Step: 8
Training loss: 0.12870213389396667
Validation loss: 1.4379211805200065

Epoch: 5| Step: 9
Training loss: 0.10514511168003082
Validation loss: 1.4288898385981077

Epoch: 5| Step: 10
Training loss: 0.08077985048294067
Validation loss: 1.4264199169733192

Epoch: 628| Step: 0
Training loss: 0.04691224545240402
Validation loss: 1.4162082736210158

Epoch: 5| Step: 1
Training loss: 0.10276199877262115
Validation loss: 1.4410050812587942

Epoch: 5| Step: 2
Training loss: 0.053562093526124954
Validation loss: 1.4223748560874694

Epoch: 5| Step: 3
Training loss: 0.06473079323768616
Validation loss: 1.4303109030569754

Epoch: 5| Step: 4
Training loss: 0.11195393651723862
Validation loss: 1.4205658820367628

Epoch: 5| Step: 5
Training loss: 0.06640445441007614
Validation loss: 1.4007135847563386

Epoch: 5| Step: 6
Training loss: 0.09691666811704636
Validation loss: 1.3997582902190506

Epoch: 5| Step: 7
Training loss: 0.08628559857606888
Validation loss: 1.4204570413917623

Epoch: 5| Step: 8
Training loss: 0.06929570436477661
Validation loss: 1.3880613478281165

Epoch: 5| Step: 9
Training loss: 0.1103019118309021
Validation loss: 1.3865585891149377

Epoch: 5| Step: 10
Training loss: 0.06911297142505646
Validation loss: 1.3944535281068535

Epoch: 629| Step: 0
Training loss: 0.06448513269424438
Validation loss: 1.3845867597928612

Epoch: 5| Step: 1
Training loss: 0.035420916974544525
Validation loss: 1.4019443245344265

Epoch: 5| Step: 2
Training loss: 0.05061360448598862
Validation loss: 1.3922561868544547

Epoch: 5| Step: 3
Training loss: 0.07673543691635132
Validation loss: 1.4275855056701168

Epoch: 5| Step: 4
Training loss: 0.06619890034198761
Validation loss: 1.4231494331872592

Epoch: 5| Step: 5
Training loss: 0.13025398552417755
Validation loss: 1.42377572226268

Epoch: 5| Step: 6
Training loss: 0.0883355513215065
Validation loss: 1.4304108273598455

Epoch: 5| Step: 7
Training loss: 0.09379194676876068
Validation loss: 1.4261897994625954

Epoch: 5| Step: 8
Training loss: 0.10967962443828583
Validation loss: 1.4042886598135835

Epoch: 5| Step: 9
Training loss: 0.08376798778772354
Validation loss: 1.3839881817499797

Epoch: 5| Step: 10
Training loss: 0.05292053148150444
Validation loss: 1.3995538847420805

Epoch: 630| Step: 0
Training loss: 0.06904488056898117
Validation loss: 1.3902991997298373

Epoch: 5| Step: 1
Training loss: 0.08674763143062592
Validation loss: 1.386505057734828

Epoch: 5| Step: 2
Training loss: 0.05801147222518921
Validation loss: 1.3840563643363215

Epoch: 5| Step: 3
Training loss: 0.0690382719039917
Validation loss: 1.3797435760498047

Epoch: 5| Step: 4
Training loss: 0.07522136718034744
Validation loss: 1.4052283097338933

Epoch: 5| Step: 5
Training loss: 0.09384800493717194
Validation loss: 1.4292091996439042

Epoch: 5| Step: 6
Training loss: 0.09712357819080353
Validation loss: 1.4243103111943891

Epoch: 5| Step: 7
Training loss: 0.1163264736533165
Validation loss: 1.437392234802246

Epoch: 5| Step: 8
Training loss: 0.09554965794086456
Validation loss: 1.4095748598857591

Epoch: 5| Step: 9
Training loss: 0.08218900859355927
Validation loss: 1.3832308938426356

Epoch: 5| Step: 10
Training loss: 0.05112069845199585
Validation loss: 1.3748338119958037

Epoch: 631| Step: 0
Training loss: 0.09145863354206085
Validation loss: 1.3684337036584013

Epoch: 5| Step: 1
Training loss: 0.08177164942026138
Validation loss: 1.3621105468401344

Epoch: 5| Step: 2
Training loss: 0.08533553779125214
Validation loss: 1.3789386544176327

Epoch: 5| Step: 3
Training loss: 0.09696483612060547
Validation loss: 1.3788540376129972

Epoch: 5| Step: 4
Training loss: 0.08400902897119522
Validation loss: 1.3864339128617318

Epoch: 5| Step: 5
Training loss: 0.06960320472717285
Validation loss: 1.4214866917620423

Epoch: 5| Step: 6
Training loss: 0.0778423473238945
Validation loss: 1.4481589922340967

Epoch: 5| Step: 7
Training loss: 0.16502287983894348
Validation loss: 1.4799020495466007

Epoch: 5| Step: 8
Training loss: 0.10354539006948471
Validation loss: 1.503848143803176

Epoch: 5| Step: 9
Training loss: 0.12474343925714493
Validation loss: 1.470651686832469

Epoch: 5| Step: 10
Training loss: 0.05691312998533249
Validation loss: 1.426161168723978

Epoch: 632| Step: 0
Training loss: 0.06701598316431046
Validation loss: 1.4253841753928893

Epoch: 5| Step: 1
Training loss: 0.1010647788643837
Validation loss: 1.389195139690112

Epoch: 5| Step: 2
Training loss: 0.17291635274887085
Validation loss: 1.4053536768882506

Epoch: 5| Step: 3
Training loss: 0.08392516523599625
Validation loss: 1.40339683845479

Epoch: 5| Step: 4
Training loss: 0.07664300501346588
Validation loss: 1.4135098995700959

Epoch: 5| Step: 5
Training loss: 0.10049109160900116
Validation loss: 1.4108074531760266

Epoch: 5| Step: 6
Training loss: 0.08860979974269867
Validation loss: 1.4433493614196777

Epoch: 5| Step: 7
Training loss: 0.08732741326093674
Validation loss: 1.45726429775197

Epoch: 5| Step: 8
Training loss: 0.1069362610578537
Validation loss: 1.4620863288961432

Epoch: 5| Step: 9
Training loss: 0.09807062894105911
Validation loss: 1.4319995128980247

Epoch: 5| Step: 10
Training loss: 0.09345877915620804
Validation loss: 1.4162249616397324

Epoch: 633| Step: 0
Training loss: 0.06595706939697266
Validation loss: 1.412689567894064

Epoch: 5| Step: 1
Training loss: 0.12128105014562607
Validation loss: 1.4266020892768778

Epoch: 5| Step: 2
Training loss: 0.07950196415185928
Validation loss: 1.424622420341738

Epoch: 5| Step: 3
Training loss: 0.07931321859359741
Validation loss: 1.411017462771426

Epoch: 5| Step: 4
Training loss: 0.08336451649665833
Validation loss: 1.4069274638288765

Epoch: 5| Step: 5
Training loss: 0.12269449234008789
Validation loss: 1.4317935512911888

Epoch: 5| Step: 6
Training loss: 0.06414578855037689
Validation loss: 1.428014410439358

Epoch: 5| Step: 7
Training loss: 0.059637703001499176
Validation loss: 1.4528180194157425

Epoch: 5| Step: 8
Training loss: 0.0625268965959549
Validation loss: 1.4066999650770617

Epoch: 5| Step: 9
Training loss: 0.06362096220254898
Validation loss: 1.4087540539362098

Epoch: 5| Step: 10
Training loss: 0.09722373634576797
Validation loss: 1.4028117848980812

Epoch: 634| Step: 0
Training loss: 0.08755489438772202
Validation loss: 1.397922520996422

Epoch: 5| Step: 1
Training loss: 0.11341200023889542
Validation loss: 1.3984228295664634

Epoch: 5| Step: 2
Training loss: 0.03861681744456291
Validation loss: 1.4021749054231951

Epoch: 5| Step: 3
Training loss: 0.05911155417561531
Validation loss: 1.4172787512502363

Epoch: 5| Step: 4
Training loss: 0.07615828514099121
Validation loss: 1.415142337481181

Epoch: 5| Step: 5
Training loss: 0.0486002117395401
Validation loss: 1.406764958494453

Epoch: 5| Step: 6
Training loss: 0.03725183755159378
Validation loss: 1.3976445851787445

Epoch: 5| Step: 7
Training loss: 0.08662116527557373
Validation loss: 1.4141094300054735

Epoch: 5| Step: 8
Training loss: 0.08328010141849518
Validation loss: 1.3644424747395258

Epoch: 5| Step: 9
Training loss: 0.06060754135251045
Validation loss: 1.3572155147470453

Epoch: 5| Step: 10
Training loss: 0.1368733048439026
Validation loss: 1.3805121503850466

Epoch: 635| Step: 0
Training loss: 0.0474756583571434
Validation loss: 1.3878113774843113

Epoch: 5| Step: 1
Training loss: 0.06719182431697845
Validation loss: 1.3602467775344849

Epoch: 5| Step: 2
Training loss: 0.060432069003582
Validation loss: 1.3677623643670032

Epoch: 5| Step: 3
Training loss: 0.08998247981071472
Validation loss: 1.3770564743267593

Epoch: 5| Step: 4
Training loss: 0.10207340866327286
Validation loss: 1.386955919445202

Epoch: 5| Step: 5
Training loss: 0.049198247492313385
Validation loss: 1.3848745822906494

Epoch: 5| Step: 6
Training loss: 0.06171710416674614
Validation loss: 1.4130213734924153

Epoch: 5| Step: 7
Training loss: 0.08563510328531265
Validation loss: 1.389059070617922

Epoch: 5| Step: 8
Training loss: 0.04258066788315773
Validation loss: 1.3880310648231096

Epoch: 5| Step: 9
Training loss: 0.05757956579327583
Validation loss: 1.4064813839491976

Epoch: 5| Step: 10
Training loss: 0.06167063117027283
Validation loss: 1.3995714802895822

Epoch: 636| Step: 0
Training loss: 0.09737147390842438
Validation loss: 1.3994014070880028

Epoch: 5| Step: 1
Training loss: 0.08308295905590057
Validation loss: 1.3670106011052285

Epoch: 5| Step: 2
Training loss: 0.07181272655725479
Validation loss: 1.3963205814361572

Epoch: 5| Step: 3
Training loss: 0.066277876496315
Validation loss: 1.4080290243189821

Epoch: 5| Step: 4
Training loss: 0.10351385176181793
Validation loss: 1.4188633772634691

Epoch: 5| Step: 5
Training loss: 0.05731397122144699
Validation loss: 1.429865615342253

Epoch: 5| Step: 6
Training loss: 0.04711516946554184
Validation loss: 1.4146901266549223

Epoch: 5| Step: 7
Training loss: 0.06703247129917145
Validation loss: 1.4223510398659656

Epoch: 5| Step: 8
Training loss: 0.046479254961013794
Validation loss: 1.4258035036825365

Epoch: 5| Step: 9
Training loss: 0.0768633708357811
Validation loss: 1.4312090578899588

Epoch: 5| Step: 10
Training loss: 0.12813763320446014
Validation loss: 1.4238381206348378

Epoch: 637| Step: 0
Training loss: 0.09242792427539825
Validation loss: 1.4052311271749518

Epoch: 5| Step: 1
Training loss: 0.08160380274057388
Validation loss: 1.4107427866228166

Epoch: 5| Step: 2
Training loss: 0.06189680099487305
Validation loss: 1.4249889478888562

Epoch: 5| Step: 3
Training loss: 0.06577277183532715
Validation loss: 1.4049419754294938

Epoch: 5| Step: 4
Training loss: 0.06044715642929077
Validation loss: 1.392517605776428

Epoch: 5| Step: 5
Training loss: 0.05344633013010025
Validation loss: 1.4093058134919854

Epoch: 5| Step: 6
Training loss: 0.09420491755008698
Validation loss: 1.3931757070684945

Epoch: 5| Step: 7
Training loss: 0.08842391520738602
Validation loss: 1.3864434637049192

Epoch: 5| Step: 8
Training loss: 0.07252001762390137
Validation loss: 1.3943543575143302

Epoch: 5| Step: 9
Training loss: 0.09929091483354568
Validation loss: 1.4140878736331899

Epoch: 5| Step: 10
Training loss: 0.05549072474241257
Validation loss: 1.4071610730181459

Epoch: 638| Step: 0
Training loss: 0.05431132763624191
Validation loss: 1.3896182365314935

Epoch: 5| Step: 1
Training loss: 0.10391336679458618
Validation loss: 1.423418862204398

Epoch: 5| Step: 2
Training loss: 0.08875156193971634
Validation loss: 1.4351388100654847

Epoch: 5| Step: 3
Training loss: 0.10907281935214996
Validation loss: 1.3950314649971582

Epoch: 5| Step: 4
Training loss: 0.08324296772480011
Validation loss: 1.4165605665535055

Epoch: 5| Step: 5
Training loss: 0.0772925466299057
Validation loss: 1.395933904955464

Epoch: 5| Step: 6
Training loss: 0.08584091067314148
Validation loss: 1.4234315810665008

Epoch: 5| Step: 7
Training loss: 0.057740986347198486
Validation loss: 1.4235031194584344

Epoch: 5| Step: 8
Training loss: 0.07994991540908813
Validation loss: 1.4218591349099272

Epoch: 5| Step: 9
Training loss: 0.059610515832901
Validation loss: 1.391293519286699

Epoch: 5| Step: 10
Training loss: 0.07264873385429382
Validation loss: 1.4034588849672707

Epoch: 639| Step: 0
Training loss: 0.062525674700737
Validation loss: 1.4177493305616482

Epoch: 5| Step: 1
Training loss: 0.060397982597351074
Validation loss: 1.4054479393907773

Epoch: 5| Step: 2
Training loss: 0.08207205682992935
Validation loss: 1.4115187685976747

Epoch: 5| Step: 3
Training loss: 0.0944850891828537
Validation loss: 1.3804851437127719

Epoch: 5| Step: 4
Training loss: 0.07450556755065918
Validation loss: 1.3560473508732294

Epoch: 5| Step: 5
Training loss: 0.07397810369729996
Validation loss: 1.3659852755967008

Epoch: 5| Step: 6
Training loss: 0.14002516865730286
Validation loss: 1.376964283245866

Epoch: 5| Step: 7
Training loss: 0.1386841982603073
Validation loss: 1.3698287920285297

Epoch: 5| Step: 8
Training loss: 0.1086311936378479
Validation loss: 1.3662867828082013

Epoch: 5| Step: 9
Training loss: 0.09001708775758743
Validation loss: 1.3925469870208411

Epoch: 5| Step: 10
Training loss: 0.0647948831319809
Validation loss: 1.368938381953906

Epoch: 640| Step: 0
Training loss: 0.08266325294971466
Validation loss: 1.392105725503737

Epoch: 5| Step: 1
Training loss: 0.060610972344875336
Validation loss: 1.4069355521150815

Epoch: 5| Step: 2
Training loss: 0.10696563869714737
Validation loss: 1.4479707940932243

Epoch: 5| Step: 3
Training loss: 0.08873089402914047
Validation loss: 1.4498414980467929

Epoch: 5| Step: 4
Training loss: 0.07982940971851349
Validation loss: 1.4622674629252443

Epoch: 5| Step: 5
Training loss: 0.07510149478912354
Validation loss: 1.4349023193441413

Epoch: 5| Step: 6
Training loss: 0.09768322855234146
Validation loss: 1.4551184702945013

Epoch: 5| Step: 7
Training loss: 0.06415523588657379
Validation loss: 1.4468264977137248

Epoch: 5| Step: 8
Training loss: 0.0899149626493454
Validation loss: 1.448700879209785

Epoch: 5| Step: 9
Training loss: 0.0939749926328659
Validation loss: 1.4433610657209992

Epoch: 5| Step: 10
Training loss: 0.15614795684814453
Validation loss: 1.4488731609877719

Epoch: 641| Step: 0
Training loss: 0.06586702167987823
Validation loss: 1.421785859651463

Epoch: 5| Step: 1
Training loss: 0.08850681781768799
Validation loss: 1.4261200274190595

Epoch: 5| Step: 2
Training loss: 0.04463952034711838
Validation loss: 1.4447319148689188

Epoch: 5| Step: 3
Training loss: 0.07249392569065094
Validation loss: 1.4456903267932195

Epoch: 5| Step: 4
Training loss: 0.12771184742450714
Validation loss: 1.4448524905789284

Epoch: 5| Step: 5
Training loss: 0.038614172488451004
Validation loss: 1.4097224140679965

Epoch: 5| Step: 6
Training loss: 0.07808060199022293
Validation loss: 1.3907864555235832

Epoch: 5| Step: 7
Training loss: 0.09034956991672516
Validation loss: 1.3917216780365154

Epoch: 5| Step: 8
Training loss: 0.11589257419109344
Validation loss: 1.3737838896371986

Epoch: 5| Step: 9
Training loss: 0.06369154900312424
Validation loss: 1.3685061162517917

Epoch: 5| Step: 10
Training loss: 0.05164164677262306
Validation loss: 1.393168193037792

Epoch: 642| Step: 0
Training loss: 0.06220192462205887
Validation loss: 1.3648491815854145

Epoch: 5| Step: 1
Training loss: 0.11447076499462128
Validation loss: 1.3949336723614765

Epoch: 5| Step: 2
Training loss: 0.07438203692436218
Validation loss: 1.3921902359172862

Epoch: 5| Step: 3
Training loss: 0.06680554151535034
Validation loss: 1.3789227162638018

Epoch: 5| Step: 4
Training loss: 0.05462312698364258
Validation loss: 1.3648794338267336

Epoch: 5| Step: 5
Training loss: 0.046123214066028595
Validation loss: 1.4047782997931204

Epoch: 5| Step: 6
Training loss: 0.09707849472761154
Validation loss: 1.3875684443340506

Epoch: 5| Step: 7
Training loss: 0.07332363724708557
Validation loss: 1.3737559613361154

Epoch: 5| Step: 8
Training loss: 0.07864925265312195
Validation loss: 1.3602330479570615

Epoch: 5| Step: 9
Training loss: 0.0914919525384903
Validation loss: 1.3943373990315262

Epoch: 5| Step: 10
Training loss: 0.11553455889225006
Validation loss: 1.3711860500356203

Epoch: 643| Step: 0
Training loss: 0.09385671466588974
Validation loss: 1.3862209512341408

Epoch: 5| Step: 1
Training loss: 0.06600209325551987
Validation loss: 1.419914178309902

Epoch: 5| Step: 2
Training loss: 0.09708432853221893
Validation loss: 1.4111130506761613

Epoch: 5| Step: 3
Training loss: 0.06194310262799263
Validation loss: 1.4256143390491445

Epoch: 5| Step: 4
Training loss: 0.07014039158821106
Validation loss: 1.4067066395154564

Epoch: 5| Step: 5
Training loss: 0.06025473028421402
Validation loss: 1.4135242476258227

Epoch: 5| Step: 6
Training loss: 0.048046477138996124
Validation loss: 1.4155660957418463

Epoch: 5| Step: 7
Training loss: 0.09432736039161682
Validation loss: 1.4059077488478793

Epoch: 5| Step: 8
Training loss: 0.06148897483944893
Validation loss: 1.4074423063185908

Epoch: 5| Step: 9
Training loss: 0.06477277725934982
Validation loss: 1.3818619020523564

Epoch: 5| Step: 10
Training loss: 0.06555230170488358
Validation loss: 1.3845704909293883

Epoch: 644| Step: 0
Training loss: 0.07359857857227325
Validation loss: 1.3859745917781707

Epoch: 5| Step: 1
Training loss: 0.05055063217878342
Validation loss: 1.3803791653725408

Epoch: 5| Step: 2
Training loss: 0.04499459266662598
Validation loss: 1.3886209040559747

Epoch: 5| Step: 3
Training loss: 0.051924239844083786
Validation loss: 1.3937025518827542

Epoch: 5| Step: 4
Training loss: 0.040797159075737
Validation loss: 1.4317034675228981

Epoch: 5| Step: 5
Training loss: 0.05679702013731003
Validation loss: 1.4023258455338017

Epoch: 5| Step: 6
Training loss: 0.08029462397098541
Validation loss: 1.4050263301018746

Epoch: 5| Step: 7
Training loss: 0.0693388357758522
Validation loss: 1.4183407316925705

Epoch: 5| Step: 8
Training loss: 0.05119476839900017
Validation loss: 1.4248001678015596

Epoch: 5| Step: 9
Training loss: 0.07443352788686752
Validation loss: 1.431677972116778

Epoch: 5| Step: 10
Training loss: 0.08801552653312683
Validation loss: 1.4334760635129866

Epoch: 645| Step: 0
Training loss: 0.05745963379740715
Validation loss: 1.4285399567696355

Epoch: 5| Step: 1
Training loss: 0.05051324516534805
Validation loss: 1.4428570091083486

Epoch: 5| Step: 2
Training loss: 0.050863027572631836
Validation loss: 1.4292524001931632

Epoch: 5| Step: 3
Training loss: 0.059007011353969574
Validation loss: 1.4055141941193612

Epoch: 5| Step: 4
Training loss: 0.05958648771047592
Validation loss: 1.4061986566871725

Epoch: 5| Step: 5
Training loss: 0.06422740966081619
Validation loss: 1.3878970863998576

Epoch: 5| Step: 6
Training loss: 0.07193741202354431
Validation loss: 1.3999053124458558

Epoch: 5| Step: 7
Training loss: 0.08102111518383026
Validation loss: 1.3931454355998705

Epoch: 5| Step: 8
Training loss: 0.057128362357616425
Validation loss: 1.4043974978949434

Epoch: 5| Step: 9
Training loss: 0.07923191785812378
Validation loss: 1.4038274454814132

Epoch: 5| Step: 10
Training loss: 0.0576520599424839
Validation loss: 1.4258907610370266

Epoch: 646| Step: 0
Training loss: 0.04194324091076851
Validation loss: 1.4034371132491736

Epoch: 5| Step: 1
Training loss: 0.05902065709233284
Validation loss: 1.3938943429659771

Epoch: 5| Step: 2
Training loss: 0.06483080983161926
Validation loss: 1.3762118354920418

Epoch: 5| Step: 3
Training loss: 0.040868669748306274
Validation loss: 1.4064162444042903

Epoch: 5| Step: 4
Training loss: 0.06794023513793945
Validation loss: 1.4042104360877827

Epoch: 5| Step: 5
Training loss: 0.0867910161614418
Validation loss: 1.3900360394549627

Epoch: 5| Step: 6
Training loss: 0.08477595448493958
Validation loss: 1.3875591203730593

Epoch: 5| Step: 7
Training loss: 0.05737484619021416
Validation loss: 1.3944446476556922

Epoch: 5| Step: 8
Training loss: 0.06660483777523041
Validation loss: 1.3684462212747144

Epoch: 5| Step: 9
Training loss: 0.06967779248952866
Validation loss: 1.397424263338889

Epoch: 5| Step: 10
Training loss: 0.05677300691604614
Validation loss: 1.3860925666747554

Epoch: 647| Step: 0
Training loss: 0.04701972007751465
Validation loss: 1.385852208701513

Epoch: 5| Step: 1
Training loss: 0.05644945055246353
Validation loss: 1.3982178626521942

Epoch: 5| Step: 2
Training loss: 0.044891536235809326
Validation loss: 1.3647589914260372

Epoch: 5| Step: 3
Training loss: 0.08557187765836716
Validation loss: 1.41081666433683

Epoch: 5| Step: 4
Training loss: 0.07304475456476212
Validation loss: 1.3925471767302482

Epoch: 5| Step: 5
Training loss: 0.04833446815609932
Validation loss: 1.371537015002261

Epoch: 5| Step: 6
Training loss: 0.0447070486843586
Validation loss: 1.357232306593208

Epoch: 5| Step: 7
Training loss: 0.06950568407773972
Validation loss: 1.348713590252784

Epoch: 5| Step: 8
Training loss: 0.0710107609629631
Validation loss: 1.3672013244321268

Epoch: 5| Step: 9
Training loss: 0.05019192770123482
Validation loss: 1.3796480778724916

Epoch: 5| Step: 10
Training loss: 0.11685004830360413
Validation loss: 1.3751879661313948

Epoch: 648| Step: 0
Training loss: 0.03104681335389614
Validation loss: 1.3888285583065403

Epoch: 5| Step: 1
Training loss: 0.05219504237174988
Validation loss: 1.3820359835060694

Epoch: 5| Step: 2
Training loss: 0.04723716527223587
Validation loss: 1.365058204179169

Epoch: 5| Step: 3
Training loss: 0.08135898411273956
Validation loss: 1.4112742325311065

Epoch: 5| Step: 4
Training loss: 0.07339200377464294
Validation loss: 1.4274683447294338

Epoch: 5| Step: 5
Training loss: 0.04392078518867493
Validation loss: 1.398066415581652

Epoch: 5| Step: 6
Training loss: 0.06068097800016403
Validation loss: 1.3857991131403113

Epoch: 5| Step: 7
Training loss: 0.08884867280721664
Validation loss: 1.3675921886197981

Epoch: 5| Step: 8
Training loss: 0.08006586134433746
Validation loss: 1.3913076154647335

Epoch: 5| Step: 9
Training loss: 0.06695129722356796
Validation loss: 1.3733273872765162

Epoch: 5| Step: 10
Training loss: 0.10226434469223022
Validation loss: 1.3696606556574504

Epoch: 649| Step: 0
Training loss: 0.11012053489685059
Validation loss: 1.3867188422910628

Epoch: 5| Step: 1
Training loss: 0.04138235002756119
Validation loss: 1.409392838836998

Epoch: 5| Step: 2
Training loss: 0.07090507447719574
Validation loss: 1.4487949737938501

Epoch: 5| Step: 3
Training loss: 0.07491889595985413
Validation loss: 1.4901169064224407

Epoch: 5| Step: 4
Training loss: 0.10905315726995468
Validation loss: 1.4880755242481027

Epoch: 5| Step: 5
Training loss: 0.07320544868707657
Validation loss: 1.4371989324528684

Epoch: 5| Step: 6
Training loss: 0.06618577241897583
Validation loss: 1.3924651767617913

Epoch: 5| Step: 7
Training loss: 0.07164056599140167
Validation loss: 1.3887635783482624

Epoch: 5| Step: 8
Training loss: 0.06898520886898041
Validation loss: 1.3697087713467178

Epoch: 5| Step: 9
Training loss: 0.11952416598796844
Validation loss: 1.3595667398104103

Epoch: 5| Step: 10
Training loss: 0.06564516574144363
Validation loss: 1.3537564912149984

Epoch: 650| Step: 0
Training loss: 0.05250956863164902
Validation loss: 1.367626791359276

Epoch: 5| Step: 1
Training loss: 0.05967022106051445
Validation loss: 1.3442133966312613

Epoch: 5| Step: 2
Training loss: 0.08272124826908112
Validation loss: 1.3544755533177366

Epoch: 5| Step: 3
Training loss: 0.06375156342983246
Validation loss: 1.3470594575328212

Epoch: 5| Step: 4
Training loss: 0.043845582753419876
Validation loss: 1.3487327326369543

Epoch: 5| Step: 5
Training loss: 0.03323550894856453
Validation loss: 1.3378097280379264

Epoch: 5| Step: 6
Training loss: 0.0751703679561615
Validation loss: 1.3738450388754568

Epoch: 5| Step: 7
Training loss: 0.08775608241558075
Validation loss: 1.3338066800948112

Epoch: 5| Step: 8
Training loss: 0.10730230808258057
Validation loss: 1.3487683508985786

Epoch: 5| Step: 9
Training loss: 0.05099926143884659
Validation loss: 1.3363047889483872

Epoch: 5| Step: 10
Training loss: 0.05698983743786812
Validation loss: 1.3415697697670228

Epoch: 651| Step: 0
Training loss: 0.06316618621349335
Validation loss: 1.3415428682040142

Epoch: 5| Step: 1
Training loss: 0.04298107698559761
Validation loss: 1.3642196116908905

Epoch: 5| Step: 2
Training loss: 0.07371779531240463
Validation loss: 1.3411819319571219

Epoch: 5| Step: 3
Training loss: 0.08549763262271881
Validation loss: 1.3673021216546335

Epoch: 5| Step: 4
Training loss: 0.047085005789995193
Validation loss: 1.3727833968336864

Epoch: 5| Step: 5
Training loss: 0.050008624792099
Validation loss: 1.3862528313872635

Epoch: 5| Step: 6
Training loss: 0.11828675121068954
Validation loss: 1.4046324414591635

Epoch: 5| Step: 7
Training loss: 0.06635583192110062
Validation loss: 1.3858145808660856

Epoch: 5| Step: 8
Training loss: 0.05218105763196945
Validation loss: 1.3963750030404778

Epoch: 5| Step: 9
Training loss: 0.03864225745201111
Validation loss: 1.4303337284313735

Epoch: 5| Step: 10
Training loss: 0.04981258511543274
Validation loss: 1.4188211028293898

Epoch: 652| Step: 0
Training loss: 0.09427239745855331
Validation loss: 1.4290023317901037

Epoch: 5| Step: 1
Training loss: 0.0482565201818943
Validation loss: 1.417699299191916

Epoch: 5| Step: 2
Training loss: 0.10894057899713516
Validation loss: 1.4016796542752175

Epoch: 5| Step: 3
Training loss: 0.043325841426849365
Validation loss: 1.4008303778145903

Epoch: 5| Step: 4
Training loss: 0.037387505173683167
Validation loss: 1.4043913092664493

Epoch: 5| Step: 5
Training loss: 0.05582084506750107
Validation loss: 1.3992917909417102

Epoch: 5| Step: 6
Training loss: 0.0841454416513443
Validation loss: 1.3982694187471945

Epoch: 5| Step: 7
Training loss: 0.07463090866804123
Validation loss: 1.3617752598178001

Epoch: 5| Step: 8
Training loss: 0.05575614050030708
Validation loss: 1.3959295249754382

Epoch: 5| Step: 9
Training loss: 0.06763707101345062
Validation loss: 1.3932933025462653

Epoch: 5| Step: 10
Training loss: 0.06591440737247467
Validation loss: 1.3957948671874179

Epoch: 653| Step: 0
Training loss: 0.07439732551574707
Validation loss: 1.4273245296170634

Epoch: 5| Step: 1
Training loss: 0.1019025593996048
Validation loss: 1.4017113549734956

Epoch: 5| Step: 2
Training loss: 0.1032983809709549
Validation loss: 1.4049767242964877

Epoch: 5| Step: 3
Training loss: 0.056181084364652634
Validation loss: 1.4128076978909072

Epoch: 5| Step: 4
Training loss: 0.057128556072711945
Validation loss: 1.3989094329136673

Epoch: 5| Step: 5
Training loss: 0.05022187903523445
Validation loss: 1.421318600254674

Epoch: 5| Step: 6
Training loss: 0.06831728667020798
Validation loss: 1.4118612017682803

Epoch: 5| Step: 7
Training loss: 0.06314972788095474
Validation loss: 1.394863490135439

Epoch: 5| Step: 8
Training loss: 0.09109213203191757
Validation loss: 1.375215199685866

Epoch: 5| Step: 9
Training loss: 0.08695578575134277
Validation loss: 1.3817796790471641

Epoch: 5| Step: 10
Training loss: 0.04294518381357193
Validation loss: 1.3472035341365363

Epoch: 654| Step: 0
Training loss: 0.07698643952608109
Validation loss: 1.3715008920238865

Epoch: 5| Step: 1
Training loss: 0.08332431316375732
Validation loss: 1.3754763513483026

Epoch: 5| Step: 2
Training loss: 0.04434465244412422
Validation loss: 1.3698697000421503

Epoch: 5| Step: 3
Training loss: 0.0500103160738945
Validation loss: 1.3599545160929363

Epoch: 5| Step: 4
Training loss: 0.10179678350687027
Validation loss: 1.3494252876568866

Epoch: 5| Step: 5
Training loss: 0.07611469179391861
Validation loss: 1.3464763843885033

Epoch: 5| Step: 6
Training loss: 0.08087984472513199
Validation loss: 1.3480596196266912

Epoch: 5| Step: 7
Training loss: 0.07763625681400299
Validation loss: 1.379592768607601

Epoch: 5| Step: 8
Training loss: 0.10017894208431244
Validation loss: 1.3911694954800349

Epoch: 5| Step: 9
Training loss: 0.0854261964559555
Validation loss: 1.3900410039450533

Epoch: 5| Step: 10
Training loss: 0.058390822261571884
Validation loss: 1.393679710485602

Epoch: 655| Step: 0
Training loss: 0.07383549213409424
Validation loss: 1.3758541204596078

Epoch: 5| Step: 1
Training loss: 0.08615589141845703
Validation loss: 1.420465902615619

Epoch: 5| Step: 2
Training loss: 0.11742760986089706
Validation loss: 1.402713410315975

Epoch: 5| Step: 3
Training loss: 0.11054782569408417
Validation loss: 1.420780792031237

Epoch: 5| Step: 4
Training loss: 0.0713718831539154
Validation loss: 1.3738356879962388

Epoch: 5| Step: 5
Training loss: 0.05494223162531853
Validation loss: 1.3793541885191394

Epoch: 5| Step: 6
Training loss: 0.11850440502166748
Validation loss: 1.3931425425314135

Epoch: 5| Step: 7
Training loss: 0.0789317861199379
Validation loss: 1.3964175434522732

Epoch: 5| Step: 8
Training loss: 0.06427030265331268
Validation loss: 1.3793697408450547

Epoch: 5| Step: 9
Training loss: 0.04491056129336357
Validation loss: 1.3778240514057938

Epoch: 5| Step: 10
Training loss: 0.06557948887348175
Validation loss: 1.378441600389378

Epoch: 656| Step: 0
Training loss: 0.07752170413732529
Validation loss: 1.3824610351234354

Epoch: 5| Step: 1
Training loss: 0.09176528453826904
Validation loss: 1.355238982426223

Epoch: 5| Step: 2
Training loss: 0.06529086828231812
Validation loss: 1.3703463308272823

Epoch: 5| Step: 3
Training loss: 0.1301824152469635
Validation loss: 1.3653594293901998

Epoch: 5| Step: 4
Training loss: 0.06778286397457123
Validation loss: 1.3871063993823143

Epoch: 5| Step: 5
Training loss: 0.07305959612131119
Validation loss: 1.370756797893073

Epoch: 5| Step: 6
Training loss: 0.06671447306871414
Validation loss: 1.380093636051301

Epoch: 5| Step: 7
Training loss: 0.05142362788319588
Validation loss: 1.3999640839074248

Epoch: 5| Step: 8
Training loss: 0.0810168981552124
Validation loss: 1.4376829926685621

Epoch: 5| Step: 9
Training loss: 0.09044018387794495
Validation loss: 1.453644432047362

Epoch: 5| Step: 10
Training loss: 0.07429679483175278
Validation loss: 1.4541730166122477

Epoch: 657| Step: 0
Training loss: 0.10532549768686295
Validation loss: 1.460125534765182

Epoch: 5| Step: 1
Training loss: 0.09935265779495239
Validation loss: 1.42974938243948

Epoch: 5| Step: 2
Training loss: 0.07920685410499573
Validation loss: 1.3943653157962266

Epoch: 5| Step: 3
Training loss: 0.06400936841964722
Validation loss: 1.4032876094182332

Epoch: 5| Step: 4
Training loss: 0.07668007165193558
Validation loss: 1.3816293426739272

Epoch: 5| Step: 5
Training loss: 0.06371603906154633
Validation loss: 1.376178893991696

Epoch: 5| Step: 6
Training loss: 0.05554521083831787
Validation loss: 1.3788233277618245

Epoch: 5| Step: 7
Training loss: 0.05309966951608658
Validation loss: 1.3682452017261135

Epoch: 5| Step: 8
Training loss: 0.08762167394161224
Validation loss: 1.3492898735948788

Epoch: 5| Step: 9
Training loss: 0.04495139792561531
Validation loss: 1.3564875305339854

Epoch: 5| Step: 10
Training loss: 0.06209968030452728
Validation loss: 1.3439398234890354

Epoch: 658| Step: 0
Training loss: 0.05353258177638054
Validation loss: 1.3633080913174538

Epoch: 5| Step: 1
Training loss: 0.04378127306699753
Validation loss: 1.3672539969926238

Epoch: 5| Step: 2
Training loss: 0.04631032422184944
Validation loss: 1.3568130898219284

Epoch: 5| Step: 3
Training loss: 0.07291620969772339
Validation loss: 1.3603141692376906

Epoch: 5| Step: 4
Training loss: 0.048196714371442795
Validation loss: 1.3644667306253988

Epoch: 5| Step: 5
Training loss: 0.08156035095453262
Validation loss: 1.3699472117167648

Epoch: 5| Step: 6
Training loss: 0.06753090023994446
Validation loss: 1.3523349902963127

Epoch: 5| Step: 7
Training loss: 0.07987753301858902
Validation loss: 1.3674817572357834

Epoch: 5| Step: 8
Training loss: 0.07477189600467682
Validation loss: 1.3854022333698888

Epoch: 5| Step: 9
Training loss: 0.13327424228191376
Validation loss: 1.3768445266190397

Epoch: 5| Step: 10
Training loss: 0.0539671890437603
Validation loss: 1.403190956961724

Epoch: 659| Step: 0
Training loss: 0.0735517293214798
Validation loss: 1.4172624567503571

Epoch: 5| Step: 1
Training loss: 0.10061304271221161
Validation loss: 1.4072886333670667

Epoch: 5| Step: 2
Training loss: 0.06156979128718376
Validation loss: 1.3809148162923834

Epoch: 5| Step: 3
Training loss: 0.06948599964380264
Validation loss: 1.3706577131825108

Epoch: 5| Step: 4
Training loss: 0.08955639600753784
Validation loss: 1.354485232342956

Epoch: 5| Step: 5
Training loss: 0.04947091266512871
Validation loss: 1.351393985491927

Epoch: 5| Step: 6
Training loss: 0.07591649144887924
Validation loss: 1.3559994543752363

Epoch: 5| Step: 7
Training loss: 0.06710068881511688
Validation loss: 1.3593623881698937

Epoch: 5| Step: 8
Training loss: 0.062264394015073776
Validation loss: 1.35234921978366

Epoch: 5| Step: 9
Training loss: 0.05912269279360771
Validation loss: 1.353462157710906

Epoch: 5| Step: 10
Training loss: 0.07262913137674332
Validation loss: 1.3600851079469085

Epoch: 660| Step: 0
Training loss: 0.05272345617413521
Validation loss: 1.3926390588924449

Epoch: 5| Step: 1
Training loss: 0.06887493282556534
Validation loss: 1.3695689494250922

Epoch: 5| Step: 2
Training loss: 0.11979712545871735
Validation loss: 1.4070211136212913

Epoch: 5| Step: 3
Training loss: 0.09309147298336029
Validation loss: 1.41056389065199

Epoch: 5| Step: 4
Training loss: 0.07755634933710098
Validation loss: 1.4200467928763358

Epoch: 5| Step: 5
Training loss: 0.07112700492143631
Validation loss: 1.421205762893923

Epoch: 5| Step: 6
Training loss: 0.03801792114973068
Validation loss: 1.4297991119405276

Epoch: 5| Step: 7
Training loss: 0.06385621428489685
Validation loss: 1.414300957033711

Epoch: 5| Step: 8
Training loss: 0.07395177334547043
Validation loss: 1.4012654071213098

Epoch: 5| Step: 9
Training loss: 0.07123684138059616
Validation loss: 1.4002099165352442

Epoch: 5| Step: 10
Training loss: 0.03497205674648285
Validation loss: 1.389736997183933

Epoch: 661| Step: 0
Training loss: 0.06316326558589935
Validation loss: 1.3963495698026431

Epoch: 5| Step: 1
Training loss: 0.05615486949682236
Validation loss: 1.390266501775352

Epoch: 5| Step: 2
Training loss: 0.08045973628759384
Validation loss: 1.4100421218461887

Epoch: 5| Step: 3
Training loss: 0.05292615294456482
Validation loss: 1.3838068054568382

Epoch: 5| Step: 4
Training loss: 0.04985479265451431
Validation loss: 1.367690590120131

Epoch: 5| Step: 5
Training loss: 0.04271773621439934
Validation loss: 1.3673207875221007

Epoch: 5| Step: 6
Training loss: 0.037928078323602676
Validation loss: 1.379001308512944

Epoch: 5| Step: 7
Training loss: 0.06097670644521713
Validation loss: 1.3667997929357714

Epoch: 5| Step: 8
Training loss: 0.11572406440973282
Validation loss: 1.3649870823788386

Epoch: 5| Step: 9
Training loss: 0.1155620589852333
Validation loss: 1.3553022735862321

Epoch: 5| Step: 10
Training loss: 0.10306178033351898
Validation loss: 1.371096347608874

Epoch: 662| Step: 0
Training loss: 0.05657187104225159
Validation loss: 1.3976163069407146

Epoch: 5| Step: 1
Training loss: 0.039225559681653976
Validation loss: 1.4042256647540676

Epoch: 5| Step: 2
Training loss: 0.1283724009990692
Validation loss: 1.4227135059654072

Epoch: 5| Step: 3
Training loss: 0.10112061351537704
Validation loss: 1.4598205948388705

Epoch: 5| Step: 4
Training loss: 0.0973249301314354
Validation loss: 1.466400251593641

Epoch: 5| Step: 5
Training loss: 0.07356376200914383
Validation loss: 1.45101067455866

Epoch: 5| Step: 6
Training loss: 0.12696577608585358
Validation loss: 1.4500573950429116

Epoch: 5| Step: 7
Training loss: 0.08854257315397263
Validation loss: 1.4589097602393037

Epoch: 5| Step: 8
Training loss: 0.09041295945644379
Validation loss: 1.4319218768868396

Epoch: 5| Step: 9
Training loss: 0.06344399601221085
Validation loss: 1.4231635793562858

Epoch: 5| Step: 10
Training loss: 0.15430085361003876
Validation loss: 1.4279658538039013

Epoch: 663| Step: 0
Training loss: 0.10192570835351944
Validation loss: 1.4098631899843934

Epoch: 5| Step: 1
Training loss: 0.08154287189245224
Validation loss: 1.398347916141633

Epoch: 5| Step: 2
Training loss: 0.08729615062475204
Validation loss: 1.3865585448921367

Epoch: 5| Step: 3
Training loss: 0.09232650697231293
Validation loss: 1.388231199274781

Epoch: 5| Step: 4
Training loss: 0.11462362855672836
Validation loss: 1.4062726907832648

Epoch: 5| Step: 5
Training loss: 0.08031992614269257
Validation loss: 1.3795734426026702

Epoch: 5| Step: 6
Training loss: 0.058723755180835724
Validation loss: 1.3634601933981783

Epoch: 5| Step: 7
Training loss: 0.06559936702251434
Validation loss: 1.3858015114261257

Epoch: 5| Step: 8
Training loss: 0.08200820535421371
Validation loss: 1.3647556228022422

Epoch: 5| Step: 9
Training loss: 0.15530426800251007
Validation loss: 1.390324237526104

Epoch: 5| Step: 10
Training loss: 0.10156720876693726
Validation loss: 1.3906800413644442

Epoch: 664| Step: 0
Training loss: 0.08235814422369003
Validation loss: 1.4041478864608272

Epoch: 5| Step: 1
Training loss: 0.11984100192785263
Validation loss: 1.4184164924006308

Epoch: 5| Step: 2
Training loss: 0.06789042055606842
Validation loss: 1.4235838600384292

Epoch: 5| Step: 3
Training loss: 0.04735856503248215
Validation loss: 1.4146209250214279

Epoch: 5| Step: 4
Training loss: 0.07709760963916779
Validation loss: 1.4052589484440383

Epoch: 5| Step: 5
Training loss: 0.10379114001989365
Validation loss: 1.4459525603120045

Epoch: 5| Step: 6
Training loss: 0.06218787282705307
Validation loss: 1.4561155073104366

Epoch: 5| Step: 7
Training loss: 0.14592576026916504
Validation loss: 1.4820515212192331

Epoch: 5| Step: 8
Training loss: 0.0854729488492012
Validation loss: 1.4576425475458945

Epoch: 5| Step: 9
Training loss: 0.07515668869018555
Validation loss: 1.4466587958797332

Epoch: 5| Step: 10
Training loss: 0.08579360693693161
Validation loss: 1.4579481232550837

Epoch: 665| Step: 0
Training loss: 0.06268282234668732
Validation loss: 1.4516494081866356

Epoch: 5| Step: 1
Training loss: 0.0905211940407753
Validation loss: 1.4468795048293246

Epoch: 5| Step: 2
Training loss: 0.08568884432315826
Validation loss: 1.4479033216353385

Epoch: 5| Step: 3
Training loss: 0.058839101344347
Validation loss: 1.4442854735159105

Epoch: 5| Step: 4
Training loss: 0.07486285269260406
Validation loss: 1.4664217349021667

Epoch: 5| Step: 5
Training loss: 0.12729887664318085
Validation loss: 1.4505763899895452

Epoch: 5| Step: 6
Training loss: 0.10264866054058075
Validation loss: 1.45648544321778

Epoch: 5| Step: 7
Training loss: 0.08026645332574844
Validation loss: 1.4466714609053828

Epoch: 5| Step: 8
Training loss: 0.07038397341966629
Validation loss: 1.4350566094921482

Epoch: 5| Step: 9
Training loss: 0.06487652659416199
Validation loss: 1.4220831291649931

Epoch: 5| Step: 10
Training loss: 0.05714406818151474
Validation loss: 1.396214836387224

Epoch: 666| Step: 0
Training loss: 0.047358881682157516
Validation loss: 1.3851580440357167

Epoch: 5| Step: 1
Training loss: 0.08318663388490677
Validation loss: 1.3857411652482965

Epoch: 5| Step: 2
Training loss: 0.1170819029211998
Validation loss: 1.3991809698843187

Epoch: 5| Step: 3
Training loss: 0.054450977593660355
Validation loss: 1.3994001880768807

Epoch: 5| Step: 4
Training loss: 0.08132578432559967
Validation loss: 1.395426704037574

Epoch: 5| Step: 5
Training loss: 0.04928010329604149
Validation loss: 1.3926838918398785

Epoch: 5| Step: 6
Training loss: 0.09808538109064102
Validation loss: 1.4013744708030456

Epoch: 5| Step: 7
Training loss: 0.08754613250494003
Validation loss: 1.4156122553733088

Epoch: 5| Step: 8
Training loss: 0.07894809544086456
Validation loss: 1.3850229876015776

Epoch: 5| Step: 9
Training loss: 0.08554770052433014
Validation loss: 1.4059492266306313

Epoch: 5| Step: 10
Training loss: 0.08378833532333374
Validation loss: 1.3919212510508876

Epoch: 667| Step: 0
Training loss: 0.0593646876513958
Validation loss: 1.39322950250359

Epoch: 5| Step: 1
Training loss: 0.11039721965789795
Validation loss: 1.4098717756168817

Epoch: 5| Step: 2
Training loss: 0.080295130610466
Validation loss: 1.4298381625965078

Epoch: 5| Step: 3
Training loss: 0.07167405635118484
Validation loss: 1.4433065640029086

Epoch: 5| Step: 4
Training loss: 0.08250705897808075
Validation loss: 1.4444292642736947

Epoch: 5| Step: 5
Training loss: 0.05883406475186348
Validation loss: 1.4074723669277724

Epoch: 5| Step: 6
Training loss: 0.05265790969133377
Validation loss: 1.395795472206608

Epoch: 5| Step: 7
Training loss: 0.08840248733758926
Validation loss: 1.3966694275538127

Epoch: 5| Step: 8
Training loss: 0.05900362879037857
Validation loss: 1.3953525584231141

Epoch: 5| Step: 9
Training loss: 0.03611094132065773
Validation loss: 1.3954643652003298

Epoch: 5| Step: 10
Training loss: 0.0951259583234787
Validation loss: 1.3832775264657953

Epoch: 668| Step: 0
Training loss: 0.0677415281534195
Validation loss: 1.383150718545401

Epoch: 5| Step: 1
Training loss: 0.05512882024049759
Validation loss: 1.3895987387626403

Epoch: 5| Step: 2
Training loss: 0.07211130857467651
Validation loss: 1.4125379420095874

Epoch: 5| Step: 3
Training loss: 0.05327141284942627
Validation loss: 1.4256314539140271

Epoch: 5| Step: 4
Training loss: 0.05140174180269241
Validation loss: 1.4181722389754428

Epoch: 5| Step: 5
Training loss: 0.07984606176614761
Validation loss: 1.4276925671485163

Epoch: 5| Step: 6
Training loss: 0.04681741073727608
Validation loss: 1.4106639598005561

Epoch: 5| Step: 7
Training loss: 0.05200690031051636
Validation loss: 1.4165330202348771

Epoch: 5| Step: 8
Training loss: 0.0819474309682846
Validation loss: 1.4110074729047797

Epoch: 5| Step: 9
Training loss: 0.08147408813238144
Validation loss: 1.4120705742989816

Epoch: 5| Step: 10
Training loss: 0.12456725537776947
Validation loss: 1.4120028608588762

Epoch: 669| Step: 0
Training loss: 0.10751961171627045
Validation loss: 1.4164699162206342

Epoch: 5| Step: 1
Training loss: 0.08081131428480148
Validation loss: 1.4153969031508251

Epoch: 5| Step: 2
Training loss: 0.04296845570206642
Validation loss: 1.4499045648882467

Epoch: 5| Step: 3
Training loss: 0.11799140274524689
Validation loss: 1.466916315017208

Epoch: 5| Step: 4
Training loss: 0.1013849526643753
Validation loss: 1.4587470985228015

Epoch: 5| Step: 5
Training loss: 0.0583447590470314
Validation loss: 1.4506534209815405

Epoch: 5| Step: 6
Training loss: 0.06936027854681015
Validation loss: 1.4397855971449165

Epoch: 5| Step: 7
Training loss: 0.1083465963602066
Validation loss: 1.4063996980267186

Epoch: 5| Step: 8
Training loss: 0.08401305973529816
Validation loss: 1.4107723947494262

Epoch: 5| Step: 9
Training loss: 0.06000013276934624
Validation loss: 1.4057365643080844

Epoch: 5| Step: 10
Training loss: 0.0561562143266201
Validation loss: 1.4144532590784051

Epoch: 670| Step: 0
Training loss: 0.06705967336893082
Validation loss: 1.3969064668942524

Epoch: 5| Step: 1
Training loss: 0.0762283205986023
Validation loss: 1.4212229905589935

Epoch: 5| Step: 2
Training loss: 0.06417486071586609
Validation loss: 1.3937837667362665

Epoch: 5| Step: 3
Training loss: 0.07329125702381134
Validation loss: 1.4016824755617368

Epoch: 5| Step: 4
Training loss: 0.08241541683673859
Validation loss: 1.3899578843065488

Epoch: 5| Step: 5
Training loss: 0.03767858445644379
Validation loss: 1.4020212222171087

Epoch: 5| Step: 6
Training loss: 0.061622701585292816
Validation loss: 1.3937945910679397

Epoch: 5| Step: 7
Training loss: 0.06917025148868561
Validation loss: 1.3815760670169708

Epoch: 5| Step: 8
Training loss: 0.08119846880435944
Validation loss: 1.3671003375002133

Epoch: 5| Step: 9
Training loss: 0.0523107647895813
Validation loss: 1.3877987682178456

Epoch: 5| Step: 10
Training loss: 0.08749078214168549
Validation loss: 1.37597664325468

Epoch: 671| Step: 0
Training loss: 0.062041737139225006
Validation loss: 1.383976815849222

Epoch: 5| Step: 1
Training loss: 0.06762097775936127
Validation loss: 1.3875575732159358

Epoch: 5| Step: 2
Training loss: 0.08766903728246689
Validation loss: 1.415354327488971

Epoch: 5| Step: 3
Training loss: 0.05675293132662773
Validation loss: 1.412499700823138

Epoch: 5| Step: 4
Training loss: 0.05107656866312027
Validation loss: 1.403197092394675

Epoch: 5| Step: 5
Training loss: 0.04790227860212326
Validation loss: 1.4112552186494232

Epoch: 5| Step: 6
Training loss: 0.08116491883993149
Validation loss: 1.4002563543217157

Epoch: 5| Step: 7
Training loss: 0.09832914173603058
Validation loss: 1.3967559888798704

Epoch: 5| Step: 8
Training loss: 0.0884552150964737
Validation loss: 1.4207636041025962

Epoch: 5| Step: 9
Training loss: 0.09834989160299301
Validation loss: 1.4073273302406393

Epoch: 5| Step: 10
Training loss: 0.0715850368142128
Validation loss: 1.407124924403365

Epoch: 672| Step: 0
Training loss: 0.04648100584745407
Validation loss: 1.3968481056151851

Epoch: 5| Step: 1
Training loss: 0.05458966642618179
Validation loss: 1.395162679815805

Epoch: 5| Step: 2
Training loss: 0.06687893718481064
Validation loss: 1.4000112459223757

Epoch: 5| Step: 3
Training loss: 0.04623562842607498
Validation loss: 1.425807749071429

Epoch: 5| Step: 4
Training loss: 0.062168825417757034
Validation loss: 1.4116286180352653

Epoch: 5| Step: 5
Training loss: 0.04151616245508194
Validation loss: 1.4003841159164265

Epoch: 5| Step: 6
Training loss: 0.05119144916534424
Validation loss: 1.3982925004856561

Epoch: 5| Step: 7
Training loss: 0.045459095388650894
Validation loss: 1.428716767218805

Epoch: 5| Step: 8
Training loss: 0.05446138232946396
Validation loss: 1.456946845977537

Epoch: 5| Step: 9
Training loss: 0.07157231867313385
Validation loss: 1.4348357659514233

Epoch: 5| Step: 10
Training loss: 0.08650261908769608
Validation loss: 1.4671532159210534

Epoch: 673| Step: 0
Training loss: 0.062018878757953644
Validation loss: 1.4531450758698166

Epoch: 5| Step: 1
Training loss: 0.060829006135463715
Validation loss: 1.4345682846602572

Epoch: 5| Step: 2
Training loss: 0.08393551409244537
Validation loss: 1.3974484051427534

Epoch: 5| Step: 3
Training loss: 0.056703973561525345
Validation loss: 1.404649349950975

Epoch: 5| Step: 4
Training loss: 0.05953487008810043
Validation loss: 1.3949071207354147

Epoch: 5| Step: 5
Training loss: 0.08520858734846115
Validation loss: 1.4045748864450762

Epoch: 5| Step: 6
Training loss: 0.059755612164735794
Validation loss: 1.4058666985522035

Epoch: 5| Step: 7
Training loss: 0.05699640512466431
Validation loss: 1.3913772670171594

Epoch: 5| Step: 8
Training loss: 0.05963166430592537
Validation loss: 1.4203913045185868

Epoch: 5| Step: 9
Training loss: 0.050085436552762985
Validation loss: 1.4097046159928845

Epoch: 5| Step: 10
Training loss: 0.0402468740940094
Validation loss: 1.4242878421660392

Epoch: 674| Step: 0
Training loss: 0.08358792960643768
Validation loss: 1.4073930440410491

Epoch: 5| Step: 1
Training loss: 0.07350613176822662
Validation loss: 1.4139409667702132

Epoch: 5| Step: 2
Training loss: 0.07199545949697495
Validation loss: 1.3942062303584108

Epoch: 5| Step: 3
Training loss: 0.05053781718015671
Validation loss: 1.3992064672131692

Epoch: 5| Step: 4
Training loss: 0.04455777630209923
Validation loss: 1.4015785532612954

Epoch: 5| Step: 5
Training loss: 0.053411759436130524
Validation loss: 1.3874596421436598

Epoch: 5| Step: 6
Training loss: 0.04739448428153992
Validation loss: 1.378317856019543

Epoch: 5| Step: 7
Training loss: 0.061613529920578
Validation loss: 1.3755589005767659

Epoch: 5| Step: 8
Training loss: 0.06425078958272934
Validation loss: 1.3706600922410206

Epoch: 5| Step: 9
Training loss: 0.06434992700815201
Validation loss: 1.3817344583490843

Epoch: 5| Step: 10
Training loss: 0.052822574973106384
Validation loss: 1.4109393601776452

Epoch: 675| Step: 0
Training loss: 0.0390651598572731
Validation loss: 1.3875025241605696

Epoch: 5| Step: 1
Training loss: 0.09409995377063751
Validation loss: 1.3877287526284494

Epoch: 5| Step: 2
Training loss: 0.05050096660852432
Validation loss: 1.37195715724781

Epoch: 5| Step: 3
Training loss: 0.06632691621780396
Validation loss: 1.3918542579938007

Epoch: 5| Step: 4
Training loss: 0.08284921944141388
Validation loss: 1.3773673324174778

Epoch: 5| Step: 5
Training loss: 0.039128322154283524
Validation loss: 1.391407944822824

Epoch: 5| Step: 6
Training loss: 0.05620903894305229
Validation loss: 1.3846997484084098

Epoch: 5| Step: 7
Training loss: 0.04384986311197281
Validation loss: 1.41311994419303

Epoch: 5| Step: 8
Training loss: 0.07435376942157745
Validation loss: 1.4003132722711051

Epoch: 5| Step: 9
Training loss: 0.07377028465270996
Validation loss: 1.4076078143171085

Epoch: 5| Step: 10
Training loss: 0.08237039297819138
Validation loss: 1.387361644416727

Epoch: 676| Step: 0
Training loss: 0.03681686520576477
Validation loss: 1.3907169308713687

Epoch: 5| Step: 1
Training loss: 0.06231112405657768
Validation loss: 1.4114729025030648

Epoch: 5| Step: 2
Training loss: 0.05882565304636955
Validation loss: 1.4154347655593709

Epoch: 5| Step: 3
Training loss: 0.06055617332458496
Validation loss: 1.403972473195804

Epoch: 5| Step: 4
Training loss: 0.07219977676868439
Validation loss: 1.3977649045246903

Epoch: 5| Step: 5
Training loss: 0.034717388451099396
Validation loss: 1.408682265589314

Epoch: 5| Step: 6
Training loss: 0.054622210562229156
Validation loss: 1.3741634738060735

Epoch: 5| Step: 7
Training loss: 0.04004637151956558
Validation loss: 1.3887129150411135

Epoch: 5| Step: 8
Training loss: 0.075905442237854
Validation loss: 1.3853002581545102

Epoch: 5| Step: 9
Training loss: 0.06869354099035263
Validation loss: 1.3816167045665044

Epoch: 5| Step: 10
Training loss: 0.10006825625896454
Validation loss: 1.37443676558874

Epoch: 677| Step: 0
Training loss: 0.06258432567119598
Validation loss: 1.3601244265033352

Epoch: 5| Step: 1
Training loss: 0.042588137090206146
Validation loss: 1.366882106309296

Epoch: 5| Step: 2
Training loss: 0.05849894881248474
Validation loss: 1.380140882666393

Epoch: 5| Step: 3
Training loss: 0.08035992085933685
Validation loss: 1.4071602680349862

Epoch: 5| Step: 4
Training loss: 0.06893249601125717
Validation loss: 1.3965504310464347

Epoch: 5| Step: 5
Training loss: 0.04784689098596573
Validation loss: 1.3933061489494898

Epoch: 5| Step: 6
Training loss: 0.06772817671298981
Validation loss: 1.3550400631402129

Epoch: 5| Step: 7
Training loss: 0.07492854446172714
Validation loss: 1.3853805206155265

Epoch: 5| Step: 8
Training loss: 0.05612341687083244
Validation loss: 1.3871865477613223

Epoch: 5| Step: 9
Training loss: 0.05805964395403862
Validation loss: 1.3898677210653982

Epoch: 5| Step: 10
Training loss: 0.044107262045145035
Validation loss: 1.4179791788901053

Epoch: 678| Step: 0
Training loss: 0.050627898424863815
Validation loss: 1.433839113481583

Epoch: 5| Step: 1
Training loss: 0.04702390357851982
Validation loss: 1.448855782067904

Epoch: 5| Step: 2
Training loss: 0.07154758274555206
Validation loss: 1.4640290237242175

Epoch: 5| Step: 3
Training loss: 0.07610394060611725
Validation loss: 1.449978204183681

Epoch: 5| Step: 4
Training loss: 0.09603516012430191
Validation loss: 1.4173609646417762

Epoch: 5| Step: 5
Training loss: 0.06148982048034668
Validation loss: 1.4187726128485896

Epoch: 5| Step: 6
Training loss: 0.06321952491998672
Validation loss: 1.406373470060287

Epoch: 5| Step: 7
Training loss: 0.06480985879898071
Validation loss: 1.3920500227200088

Epoch: 5| Step: 8
Training loss: 0.05608542636036873
Validation loss: 1.3541569761050645

Epoch: 5| Step: 9
Training loss: 0.06808455288410187
Validation loss: 1.3474904516691804

Epoch: 5| Step: 10
Training loss: 0.07467368990182877
Validation loss: 1.3457810289116316

Epoch: 679| Step: 0
Training loss: 0.051854975521564484
Validation loss: 1.3687477842453988

Epoch: 5| Step: 1
Training loss: 0.04124017804861069
Validation loss: 1.3587508060598885

Epoch: 5| Step: 2
Training loss: 0.06564896553754807
Validation loss: 1.3494594404774327

Epoch: 5| Step: 3
Training loss: 0.06700602918863297
Validation loss: 1.341110937057003

Epoch: 5| Step: 4
Training loss: 0.06876164674758911
Validation loss: 1.375417947769165

Epoch: 5| Step: 5
Training loss: 0.07768309116363525
Validation loss: 1.386013409142853

Epoch: 5| Step: 6
Training loss: 0.11390713602304459
Validation loss: 1.4084117438203545

Epoch: 5| Step: 7
Training loss: 0.06779425591230392
Validation loss: 1.4058604676236388

Epoch: 5| Step: 8
Training loss: 0.08102981746196747
Validation loss: 1.4002063671747844

Epoch: 5| Step: 9
Training loss: 0.10912386327981949
Validation loss: 1.3811805927625267

Epoch: 5| Step: 10
Training loss: 0.12502603232860565
Validation loss: 1.386787647842079

Epoch: 680| Step: 0
Training loss: 0.07044980674982071
Validation loss: 1.4154794933975383

Epoch: 5| Step: 1
Training loss: 0.04698668420314789
Validation loss: 1.4472299929588073

Epoch: 5| Step: 2
Training loss: 0.09646175801753998
Validation loss: 1.4733678666494225

Epoch: 5| Step: 3
Training loss: 0.13518765568733215
Validation loss: 1.4946414354026958

Epoch: 5| Step: 4
Training loss: 0.05827667564153671
Validation loss: 1.4578560603562223

Epoch: 5| Step: 5
Training loss: 0.07175986468791962
Validation loss: 1.4407951049907233

Epoch: 5| Step: 6
Training loss: 0.0714610144495964
Validation loss: 1.396508300817141

Epoch: 5| Step: 7
Training loss: 0.08313784003257751
Validation loss: 1.378120804345736

Epoch: 5| Step: 8
Training loss: 0.11095266044139862
Validation loss: 1.3421766129873132

Epoch: 5| Step: 9
Training loss: 0.06602923572063446
Validation loss: 1.3525112655854994

Epoch: 5| Step: 10
Training loss: 0.1541256308555603
Validation loss: 1.3487128951857168

Epoch: 681| Step: 0
Training loss: 0.055851198732852936
Validation loss: 1.336928347105621

Epoch: 5| Step: 1
Training loss: 0.07541102170944214
Validation loss: 1.34113508911543

Epoch: 5| Step: 2
Training loss: 0.0746656209230423
Validation loss: 1.3576480919314968

Epoch: 5| Step: 3
Training loss: 0.07879183441400528
Validation loss: 1.372046539860387

Epoch: 5| Step: 4
Training loss: 0.07317058742046356
Validation loss: 1.3859869882624636

Epoch: 5| Step: 5
Training loss: 0.06344886124134064
Validation loss: 1.3994305672184113

Epoch: 5| Step: 6
Training loss: 0.11648444831371307
Validation loss: 1.4168539636878557

Epoch: 5| Step: 7
Training loss: 0.05479688569903374
Validation loss: 1.43911410403508

Epoch: 5| Step: 8
Training loss: 0.05114276334643364
Validation loss: 1.4474729235454271

Epoch: 5| Step: 9
Training loss: 0.054013561457395554
Validation loss: 1.4713617986248386

Epoch: 5| Step: 10
Training loss: 0.0933459922671318
Validation loss: 1.453679834642718

Epoch: 682| Step: 0
Training loss: 0.07485736161470413
Validation loss: 1.4659746942981597

Epoch: 5| Step: 1
Training loss: 0.07815857976675034
Validation loss: 1.472873632625867

Epoch: 5| Step: 2
Training loss: 0.08053591102361679
Validation loss: 1.4587244808032949

Epoch: 5| Step: 3
Training loss: 0.07517483085393906
Validation loss: 1.4665723013621506

Epoch: 5| Step: 4
Training loss: 0.11735747009515762
Validation loss: 1.455214915737029

Epoch: 5| Step: 5
Training loss: 0.07903624325990677
Validation loss: 1.4680400881716

Epoch: 5| Step: 6
Training loss: 0.14169296622276306
Validation loss: 1.4820594056960075

Epoch: 5| Step: 7
Training loss: 0.0636305958032608
Validation loss: 1.4366461628226823

Epoch: 5| Step: 8
Training loss: 0.0430883951485157
Validation loss: 1.4041227320189118

Epoch: 5| Step: 9
Training loss: 0.05016461759805679
Validation loss: 1.3890382666741647

Epoch: 5| Step: 10
Training loss: 0.0645361840724945
Validation loss: 1.374153539698611

Epoch: 683| Step: 0
Training loss: 0.0436118021607399
Validation loss: 1.3529657369018884

Epoch: 5| Step: 1
Training loss: 0.09629158675670624
Validation loss: 1.3374854492884811

Epoch: 5| Step: 2
Training loss: 0.09102135896682739
Validation loss: 1.3686790761127268

Epoch: 5| Step: 3
Training loss: 0.05310887098312378
Validation loss: 1.369163328601468

Epoch: 5| Step: 4
Training loss: 0.05456579849123955
Validation loss: 1.3661661712072228

Epoch: 5| Step: 5
Training loss: 0.08150728791952133
Validation loss: 1.3742459589435208

Epoch: 5| Step: 6
Training loss: 0.0986647978425026
Validation loss: 1.3695256517779442

Epoch: 5| Step: 7
Training loss: 0.06502417474985123
Validation loss: 1.3770742762473323

Epoch: 5| Step: 8
Training loss: 0.06259967386722565
Validation loss: 1.3951807829641527

Epoch: 5| Step: 9
Training loss: 0.06163376569747925
Validation loss: 1.3940892527180333

Epoch: 5| Step: 10
Training loss: 0.037772707641124725
Validation loss: 1.395111414694017

Epoch: 684| Step: 0
Training loss: 0.06428982317447662
Validation loss: 1.3939740901352258

Epoch: 5| Step: 1
Training loss: 0.06276509165763855
Validation loss: 1.4009168442859445

Epoch: 5| Step: 2
Training loss: 0.05918501690030098
Validation loss: 1.398541529973348

Epoch: 5| Step: 3
Training loss: 0.049556829035282135
Validation loss: 1.392386737690177

Epoch: 5| Step: 4
Training loss: 0.03958930820226669
Validation loss: 1.4191823992677914

Epoch: 5| Step: 5
Training loss: 0.06860329210758209
Validation loss: 1.4263132150455187

Epoch: 5| Step: 6
Training loss: 0.057926345616579056
Validation loss: 1.429893857689314

Epoch: 5| Step: 7
Training loss: 0.07269644737243652
Validation loss: 1.4420236426015054

Epoch: 5| Step: 8
Training loss: 0.07900120317935944
Validation loss: 1.4231827041154266

Epoch: 5| Step: 9
Training loss: 0.06754190474748611
Validation loss: 1.4061291410077004

Epoch: 5| Step: 10
Training loss: 0.0871172547340393
Validation loss: 1.4013444697985085

Epoch: 685| Step: 0
Training loss: 0.036164816468954086
Validation loss: 1.3966953805697861

Epoch: 5| Step: 1
Training loss: 0.06014544889330864
Validation loss: 1.3897452841522873

Epoch: 5| Step: 2
Training loss: 0.051855385303497314
Validation loss: 1.3905416573247602

Epoch: 5| Step: 3
Training loss: 0.06516556441783905
Validation loss: 1.3886878644266436

Epoch: 5| Step: 4
Training loss: 0.0801699161529541
Validation loss: 1.4047990659231782

Epoch: 5| Step: 5
Training loss: 0.0714239627122879
Validation loss: 1.380084664590897

Epoch: 5| Step: 6
Training loss: 0.04150060936808586
Validation loss: 1.3868949592754405

Epoch: 5| Step: 7
Training loss: 0.05921865254640579
Validation loss: 1.3917981168275237

Epoch: 5| Step: 8
Training loss: 0.04500920698046684
Validation loss: 1.4338095380413918

Epoch: 5| Step: 9
Training loss: 0.06610958278179169
Validation loss: 1.4307986587606452

Epoch: 5| Step: 10
Training loss: 0.052383750677108765
Validation loss: 1.4317324879348918

Epoch: 686| Step: 0
Training loss: 0.08470772951841354
Validation loss: 1.4357637064431303

Epoch: 5| Step: 1
Training loss: 0.07257945835590363
Validation loss: 1.443570319042411

Epoch: 5| Step: 2
Training loss: 0.06646841764450073
Validation loss: 1.4269707100365752

Epoch: 5| Step: 3
Training loss: 0.04507724195718765
Validation loss: 1.4000343084335327

Epoch: 5| Step: 4
Training loss: 0.0592464879155159
Validation loss: 1.4239269892374675

Epoch: 5| Step: 5
Training loss: 0.05479489639401436
Validation loss: 1.4286490486514183

Epoch: 5| Step: 6
Training loss: 0.049617357552051544
Validation loss: 1.4157344051586684

Epoch: 5| Step: 7
Training loss: 0.07555102556943893
Validation loss: 1.4022237882819226

Epoch: 5| Step: 8
Training loss: 0.04992661997675896
Validation loss: 1.4177849376073448

Epoch: 5| Step: 9
Training loss: 0.12197031825780869
Validation loss: 1.4592341325616325

Epoch: 5| Step: 10
Training loss: 0.038707002997398376
Validation loss: 1.4580532735393894

Epoch: 687| Step: 0
Training loss: 0.04762207344174385
Validation loss: 1.4458735976167905

Epoch: 5| Step: 1
Training loss: 0.11366094648838043
Validation loss: 1.4577673641584252

Epoch: 5| Step: 2
Training loss: 0.06019357591867447
Validation loss: 1.4413800957382366

Epoch: 5| Step: 3
Training loss: 0.06746897846460342
Validation loss: 1.4086297289017709

Epoch: 5| Step: 4
Training loss: 0.03666878119111061
Validation loss: 1.404927327427813

Epoch: 5| Step: 5
Training loss: 0.05013740807771683
Validation loss: 1.3923363865062754

Epoch: 5| Step: 6
Training loss: 0.07134617865085602
Validation loss: 1.3614288196768811

Epoch: 5| Step: 7
Training loss: 0.09265460819005966
Validation loss: 1.3896032437201469

Epoch: 5| Step: 8
Training loss: 0.061064064502716064
Validation loss: 1.3657200964548255

Epoch: 5| Step: 9
Training loss: 0.12065163999795914
Validation loss: 1.3637197479124992

Epoch: 5| Step: 10
Training loss: 0.05794517323374748
Validation loss: 1.404158846024544

Epoch: 688| Step: 0
Training loss: 0.053671397268772125
Validation loss: 1.3961865953219834

Epoch: 5| Step: 1
Training loss: 0.0969766154885292
Validation loss: 1.4072042562628304

Epoch: 5| Step: 2
Training loss: 0.0807204470038414
Validation loss: 1.4145084017066545

Epoch: 5| Step: 3
Training loss: 0.045227598398923874
Validation loss: 1.4049187296180314

Epoch: 5| Step: 4
Training loss: 0.05322675034403801
Validation loss: 1.3882441033599198

Epoch: 5| Step: 5
Training loss: 0.054235659539699554
Validation loss: 1.3854612573500602

Epoch: 5| Step: 6
Training loss: 0.03529741242527962
Validation loss: 1.3886967666687504

Epoch: 5| Step: 7
Training loss: 0.0872768759727478
Validation loss: 1.3836334597679876

Epoch: 5| Step: 8
Training loss: 0.10212095826864243
Validation loss: 1.3601082704400504

Epoch: 5| Step: 9
Training loss: 0.07910832017660141
Validation loss: 1.3456929973376694

Epoch: 5| Step: 10
Training loss: 0.07169333845376968
Validation loss: 1.3758285404533468

Epoch: 689| Step: 0
Training loss: 0.047678135335445404
Validation loss: 1.3439269040220527

Epoch: 5| Step: 1
Training loss: 0.04558005928993225
Validation loss: 1.3417001129478536

Epoch: 5| Step: 2
Training loss: 0.06118590757250786
Validation loss: 1.323401766438638

Epoch: 5| Step: 3
Training loss: 0.07154439389705658
Validation loss: 1.3187291891344133

Epoch: 5| Step: 4
Training loss: 0.08917222917079926
Validation loss: 1.3438245916879306

Epoch: 5| Step: 5
Training loss: 0.061464935541152954
Validation loss: 1.3699982063744658

Epoch: 5| Step: 6
Training loss: 0.07426951080560684
Validation loss: 1.3620966608806322

Epoch: 5| Step: 7
Training loss: 0.051079146564006805
Validation loss: 1.3748415875178512

Epoch: 5| Step: 8
Training loss: 0.13313797116279602
Validation loss: 1.3537579928675005

Epoch: 5| Step: 9
Training loss: 0.08199696987867355
Validation loss: 1.363632785376682

Epoch: 5| Step: 10
Training loss: 0.07676182687282562
Validation loss: 1.381955631958541

Epoch: 690| Step: 0
Training loss: 0.04426787421107292
Validation loss: 1.3782637016747588

Epoch: 5| Step: 1
Training loss: 0.07323187589645386
Validation loss: 1.397808253124196

Epoch: 5| Step: 2
Training loss: 0.07450808584690094
Validation loss: 1.432372486719521

Epoch: 5| Step: 3
Training loss: 0.08768831193447113
Validation loss: 1.4378043143979964

Epoch: 5| Step: 4
Training loss: 0.09041712433099747
Validation loss: 1.4267184554889638

Epoch: 5| Step: 5
Training loss: 0.09199656546115875
Validation loss: 1.4214665620557723

Epoch: 5| Step: 6
Training loss: 0.06209327653050423
Validation loss: 1.4020043265435003

Epoch: 5| Step: 7
Training loss: 0.070646733045578
Validation loss: 1.3945365349451702

Epoch: 5| Step: 8
Training loss: 0.05905262380838394
Validation loss: 1.4174497242896789

Epoch: 5| Step: 9
Training loss: 0.060546111315488815
Validation loss: 1.4014971128074072

Epoch: 5| Step: 10
Training loss: 0.07803386449813843
Validation loss: 1.4195467951477214

Epoch: 691| Step: 0
Training loss: 0.03586934134364128
Validation loss: 1.4331933170236566

Epoch: 5| Step: 1
Training loss: 0.04823245853185654
Validation loss: 1.434056503798372

Epoch: 5| Step: 2
Training loss: 0.06604856997728348
Validation loss: 1.4326199793046521

Epoch: 5| Step: 3
Training loss: 0.0723586305975914
Validation loss: 1.4332965753411735

Epoch: 5| Step: 4
Training loss: 0.09717492759227753
Validation loss: 1.4274629918477868

Epoch: 5| Step: 5
Training loss: 0.06431732326745987
Validation loss: 1.4300985784940823

Epoch: 5| Step: 6
Training loss: 0.07047350704669952
Validation loss: 1.4123495971002886

Epoch: 5| Step: 7
Training loss: 0.06243539974093437
Validation loss: 1.405662425102726

Epoch: 5| Step: 8
Training loss: 0.05811180919408798
Validation loss: 1.3928745587666829

Epoch: 5| Step: 9
Training loss: 0.05668351799249649
Validation loss: 1.3838123454842517

Epoch: 5| Step: 10
Training loss: 0.04320001229643822
Validation loss: 1.3734416756578671

Epoch: 692| Step: 0
Training loss: 0.05546167492866516
Validation loss: 1.3673385240698372

Epoch: 5| Step: 1
Training loss: 0.09455414116382599
Validation loss: 1.385159339956058

Epoch: 5| Step: 2
Training loss: 0.07282008975744247
Validation loss: 1.3572485741748606

Epoch: 5| Step: 3
Training loss: 0.04090823978185654
Validation loss: 1.3803696017111502

Epoch: 5| Step: 4
Training loss: 0.07000449299812317
Validation loss: 1.3676532904307048

Epoch: 5| Step: 5
Training loss: 0.05386843532323837
Validation loss: 1.3863917198232425

Epoch: 5| Step: 6
Training loss: 0.037316810339689255
Validation loss: 1.3777461442896115

Epoch: 5| Step: 7
Training loss: 0.07111258804798126
Validation loss: 1.3593152492277083

Epoch: 5| Step: 8
Training loss: 0.04369393363595009
Validation loss: 1.380600506259549

Epoch: 5| Step: 9
Training loss: 0.07393364608287811
Validation loss: 1.380877390984566

Epoch: 5| Step: 10
Training loss: 0.06067291274666786
Validation loss: 1.3661322914144045

Epoch: 693| Step: 0
Training loss: 0.0543830581009388
Validation loss: 1.3769568576607654

Epoch: 5| Step: 1
Training loss: 0.03549845144152641
Validation loss: 1.3847959964506087

Epoch: 5| Step: 2
Training loss: 0.05502508208155632
Validation loss: 1.3693283450218938

Epoch: 5| Step: 3
Training loss: 0.03237924724817276
Validation loss: 1.3783097728606193

Epoch: 5| Step: 4
Training loss: 0.0507308728992939
Validation loss: 1.365369221215607

Epoch: 5| Step: 5
Training loss: 0.08314094692468643
Validation loss: 1.354905988580437

Epoch: 5| Step: 6
Training loss: 0.04348013550043106
Validation loss: 1.3654130722886773

Epoch: 5| Step: 7
Training loss: 0.06974034756422043
Validation loss: 1.371584023839684

Epoch: 5| Step: 8
Training loss: 0.05539917200803757
Validation loss: 1.3902672977857693

Epoch: 5| Step: 9
Training loss: 0.10241439193487167
Validation loss: 1.3826500356838267

Epoch: 5| Step: 10
Training loss: 0.03470207750797272
Validation loss: 1.3734012428791291

Epoch: 694| Step: 0
Training loss: 0.03828384727239609
Validation loss: 1.3731175827723678

Epoch: 5| Step: 1
Training loss: 0.038341622799634933
Validation loss: 1.3436917143483316

Epoch: 5| Step: 2
Training loss: 0.10441412031650543
Validation loss: 1.3839530726914764

Epoch: 5| Step: 3
Training loss: 0.061712127178907394
Validation loss: 1.3579801961939821

Epoch: 5| Step: 4
Training loss: 0.05269206687808037
Validation loss: 1.3703096528207102

Epoch: 5| Step: 5
Training loss: 0.05096108838915825
Validation loss: 1.3828404308647237

Epoch: 5| Step: 6
Training loss: 0.0476737841963768
Validation loss: 1.3682610886071318

Epoch: 5| Step: 7
Training loss: 0.06631704419851303
Validation loss: 1.3730980657762097

Epoch: 5| Step: 8
Training loss: 0.056888479739427567
Validation loss: 1.3777645185429563

Epoch: 5| Step: 9
Training loss: 0.047443024814128876
Validation loss: 1.3866775074312765

Epoch: 5| Step: 10
Training loss: 0.08873825520277023
Validation loss: 1.3588209780313636

Epoch: 695| Step: 0
Training loss: 0.058353446424007416
Validation loss: 1.3801603060896679

Epoch: 5| Step: 1
Training loss: 0.038964834064245224
Validation loss: 1.3935239904670305

Epoch: 5| Step: 2
Training loss: 0.04388516768813133
Validation loss: 1.3781349774329894

Epoch: 5| Step: 3
Training loss: 0.044684022665023804
Validation loss: 1.3928755726865543

Epoch: 5| Step: 4
Training loss: 0.05677042156457901
Validation loss: 1.3682067189165341

Epoch: 5| Step: 5
Training loss: 0.06518788635730743
Validation loss: 1.3931615961495267

Epoch: 5| Step: 6
Training loss: 0.047031499445438385
Validation loss: 1.3672305704444967

Epoch: 5| Step: 7
Training loss: 0.07560303807258606
Validation loss: 1.3702488073738672

Epoch: 5| Step: 8
Training loss: 0.028349241241812706
Validation loss: 1.3647205425846962

Epoch: 5| Step: 9
Training loss: 0.09659181535243988
Validation loss: 1.3702436877835182

Epoch: 5| Step: 10
Training loss: 0.037481583654880524
Validation loss: 1.3560542496301795

Epoch: 696| Step: 0
Training loss: 0.06758201122283936
Validation loss: 1.360914478378911

Epoch: 5| Step: 1
Training loss: 0.03603295236825943
Validation loss: 1.3555961872941704

Epoch: 5| Step: 2
Training loss: 0.0705007016658783
Validation loss: 1.37670773331837

Epoch: 5| Step: 3
Training loss: 0.029919076710939407
Validation loss: 1.368453033508793

Epoch: 5| Step: 4
Training loss: 0.039705775678157806
Validation loss: 1.3490181917785316

Epoch: 5| Step: 5
Training loss: 0.09924637526273727
Validation loss: 1.3860564052417714

Epoch: 5| Step: 6
Training loss: 0.050395816564559937
Validation loss: 1.3699546783201155

Epoch: 5| Step: 7
Training loss: 0.05834905058145523
Validation loss: 1.352171551796698

Epoch: 5| Step: 8
Training loss: 0.05675759166479111
Validation loss: 1.3752600762151903

Epoch: 5| Step: 9
Training loss: 0.039768118411302567
Validation loss: 1.380575115962695

Epoch: 5| Step: 10
Training loss: 0.03259236738085747
Validation loss: 1.354029409347042

Epoch: 697| Step: 0
Training loss: 0.05263859033584595
Validation loss: 1.3639388609957952

Epoch: 5| Step: 1
Training loss: 0.0492543950676918
Validation loss: 1.3511459506968015

Epoch: 5| Step: 2
Training loss: 0.07081467658281326
Validation loss: 1.3811838614043368

Epoch: 5| Step: 3
Training loss: 0.06393826752901077
Validation loss: 1.3786517445759108

Epoch: 5| Step: 4
Training loss: 0.039773598313331604
Validation loss: 1.3790007175937775

Epoch: 5| Step: 5
Training loss: 0.04708016663789749
Validation loss: 1.3774748668875745

Epoch: 5| Step: 6
Training loss: 0.044466130435466766
Validation loss: 1.376712719599406

Epoch: 5| Step: 7
Training loss: 0.053906869143247604
Validation loss: 1.3894412761093469

Epoch: 5| Step: 8
Training loss: 0.059277843683958054
Validation loss: 1.3777359941954255

Epoch: 5| Step: 9
Training loss: 0.06721378117799759
Validation loss: 1.3875804588358889

Epoch: 5| Step: 10
Training loss: 0.08571093529462814
Validation loss: 1.3707724079009025

Epoch: 698| Step: 0
Training loss: 0.03822541981935501
Validation loss: 1.3846863854315974

Epoch: 5| Step: 1
Training loss: 0.0563909113407135
Validation loss: 1.3794410536366124

Epoch: 5| Step: 2
Training loss: 0.08181367814540863
Validation loss: 1.3691566259630266

Epoch: 5| Step: 3
Training loss: 0.07267031073570251
Validation loss: 1.3882248132459578

Epoch: 5| Step: 4
Training loss: 0.06595142185688019
Validation loss: 1.3612799157378495

Epoch: 5| Step: 5
Training loss: 0.0711044892668724
Validation loss: 1.3966368481677065

Epoch: 5| Step: 6
Training loss: 0.0625542402267456
Validation loss: 1.3787283256489744

Epoch: 5| Step: 7
Training loss: 0.03436299413442612
Validation loss: 1.3897414938096078

Epoch: 5| Step: 8
Training loss: 0.06762039661407471
Validation loss: 1.424507987114691

Epoch: 5| Step: 9
Training loss: 0.10902905464172363
Validation loss: 1.416083896672854

Epoch: 5| Step: 10
Training loss: 0.0946529358625412
Validation loss: 1.4026099270389927

Epoch: 699| Step: 0
Training loss: 0.08929363638162613
Validation loss: 1.3809697730566866

Epoch: 5| Step: 1
Training loss: 0.08291159570217133
Validation loss: 1.3687464126976587

Epoch: 5| Step: 2
Training loss: 0.09119777381420135
Validation loss: 1.4009417987638904

Epoch: 5| Step: 3
Training loss: 0.07235033065080643
Validation loss: 1.3709873813454823

Epoch: 5| Step: 4
Training loss: 0.07372687757015228
Validation loss: 1.3781409904520998

Epoch: 5| Step: 5
Training loss: 0.029303213581442833
Validation loss: 1.3699697294542867

Epoch: 5| Step: 6
Training loss: 0.05981289595365524
Validation loss: 1.3664716418071459

Epoch: 5| Step: 7
Training loss: 0.08996131271123886
Validation loss: 1.3508681417793356

Epoch: 5| Step: 8
Training loss: 0.07234533876180649
Validation loss: 1.3766751289367676

Epoch: 5| Step: 9
Training loss: 0.06808047741651535
Validation loss: 1.3752845077104465

Epoch: 5| Step: 10
Training loss: 0.12037002295255661
Validation loss: 1.3618594523399108

Epoch: 700| Step: 0
Training loss: 0.03590599447488785
Validation loss: 1.3478663659864856

Epoch: 5| Step: 1
Training loss: 0.06623782217502594
Validation loss: 1.3660901349077943

Epoch: 5| Step: 2
Training loss: 0.12557971477508545
Validation loss: 1.364048993715676

Epoch: 5| Step: 3
Training loss: 0.11527009308338165
Validation loss: 1.3812571103854845

Epoch: 5| Step: 4
Training loss: 0.06239807605743408
Validation loss: 1.380367095752429

Epoch: 5| Step: 5
Training loss: 0.0392739400267601
Validation loss: 1.3807721163636895

Epoch: 5| Step: 6
Training loss: 0.052429310977458954
Validation loss: 1.3704498711452688

Epoch: 5| Step: 7
Training loss: 0.062321413308382034
Validation loss: 1.3886552459450179

Epoch: 5| Step: 8
Training loss: 0.08221860229969025
Validation loss: 1.3682280637884652

Epoch: 5| Step: 9
Training loss: 0.09187041223049164
Validation loss: 1.377668410219172

Epoch: 5| Step: 10
Training loss: 0.05392860248684883
Validation loss: 1.3793372018362886

Epoch: 701| Step: 0
Training loss: 0.05066709965467453
Validation loss: 1.3713703085017461

Epoch: 5| Step: 1
Training loss: 0.05793122202157974
Validation loss: 1.3663235172148673

Epoch: 5| Step: 2
Training loss: 0.06531842052936554
Validation loss: 1.4051813540920135

Epoch: 5| Step: 3
Training loss: 0.09549681097269058
Validation loss: 1.3783556876644012

Epoch: 5| Step: 4
Training loss: 0.07968361675739288
Validation loss: 1.36844648597061

Epoch: 5| Step: 5
Training loss: 0.09011401236057281
Validation loss: 1.389175199693249

Epoch: 5| Step: 6
Training loss: 0.0542178638279438
Validation loss: 1.3663069778873074

Epoch: 5| Step: 7
Training loss: 0.04213687404990196
Validation loss: 1.3753663468104538

Epoch: 5| Step: 8
Training loss: 0.07396698743104935
Validation loss: 1.3630988392778622

Epoch: 5| Step: 9
Training loss: 0.051904063671827316
Validation loss: 1.35522662696018

Epoch: 5| Step: 10
Training loss: 0.056907009333372116
Validation loss: 1.353979573454908

Epoch: 702| Step: 0
Training loss: 0.06475383043289185
Validation loss: 1.3498512660303423

Epoch: 5| Step: 1
Training loss: 0.08768156170845032
Validation loss: 1.3573919086046116

Epoch: 5| Step: 2
Training loss: 0.08406294882297516
Validation loss: 1.3387475488006428

Epoch: 5| Step: 3
Training loss: 0.06246434524655342
Validation loss: 1.3671313998519734

Epoch: 5| Step: 4
Training loss: 0.0701877698302269
Validation loss: 1.3589464567040885

Epoch: 5| Step: 5
Training loss: 0.047225408256053925
Validation loss: 1.3705399728590442

Epoch: 5| Step: 6
Training loss: 0.06601498275995255
Validation loss: 1.3850582838058472

Epoch: 5| Step: 7
Training loss: 0.04004644602537155
Validation loss: 1.4068913113686345

Epoch: 5| Step: 8
Training loss: 0.07331524044275284
Validation loss: 1.3883196487221667

Epoch: 5| Step: 9
Training loss: 0.05404107645153999
Validation loss: 1.394742368369974

Epoch: 5| Step: 10
Training loss: 0.09185872972011566
Validation loss: 1.3760614837369611

Epoch: 703| Step: 0
Training loss: 0.06216172128915787
Validation loss: 1.3774669529289327

Epoch: 5| Step: 1
Training loss: 0.053110916167497635
Validation loss: 1.3905815039911578

Epoch: 5| Step: 2
Training loss: 0.043077077716588974
Validation loss: 1.3455925756885159

Epoch: 5| Step: 3
Training loss: 0.08065901696681976
Validation loss: 1.3650287453846266

Epoch: 5| Step: 4
Training loss: 0.06772154569625854
Validation loss: 1.3795922155021338

Epoch: 5| Step: 5
Training loss: 0.06631715595722198
Validation loss: 1.3595135276035597

Epoch: 5| Step: 6
Training loss: 0.09133671969175339
Validation loss: 1.355834311054599

Epoch: 5| Step: 7
Training loss: 0.06215775012969971
Validation loss: 1.3575628906167962

Epoch: 5| Step: 8
Training loss: 0.09025169909000397
Validation loss: 1.3519664964368265

Epoch: 5| Step: 9
Training loss: 0.060775481164455414
Validation loss: 1.356725884381161

Epoch: 5| Step: 10
Training loss: 0.0932266116142273
Validation loss: 1.370216582411079

Epoch: 704| Step: 0
Training loss: 0.06587038934230804
Validation loss: 1.3629568969049761

Epoch: 5| Step: 1
Training loss: 0.0876293033361435
Validation loss: 1.4066725213040587

Epoch: 5| Step: 2
Training loss: 0.0985870212316513
Validation loss: 1.40911300464343

Epoch: 5| Step: 3
Training loss: 0.06272599846124649
Validation loss: 1.3886862070329729

Epoch: 5| Step: 4
Training loss: 0.061131130903959274
Validation loss: 1.3748498385952366

Epoch: 5| Step: 5
Training loss: 0.07344578951597214
Validation loss: 1.358938318426891

Epoch: 5| Step: 6
Training loss: 0.0820692777633667
Validation loss: 1.3604676646571006

Epoch: 5| Step: 7
Training loss: 0.050237517803907394
Validation loss: 1.3307729421123382

Epoch: 5| Step: 8
Training loss: 0.06382373720407486
Validation loss: 1.3335743642622424

Epoch: 5| Step: 9
Training loss: 0.04202332720160484
Validation loss: 1.356385410472911

Epoch: 5| Step: 10
Training loss: 0.05417192727327347
Validation loss: 1.3405288265597435

Epoch: 705| Step: 0
Training loss: 0.057519953697919846
Validation loss: 1.341384736440515

Epoch: 5| Step: 1
Training loss: 0.06666487455368042
Validation loss: 1.3479662326074415

Epoch: 5| Step: 2
Training loss: 0.06134698539972305
Validation loss: 1.357324182346303

Epoch: 5| Step: 3
Training loss: 0.052033841609954834
Validation loss: 1.3317611294407998

Epoch: 5| Step: 4
Training loss: 0.05611000582575798
Validation loss: 1.357477189392172

Epoch: 5| Step: 5
Training loss: 0.08839207887649536
Validation loss: 1.334923186609822

Epoch: 5| Step: 6
Training loss: 0.04713672399520874
Validation loss: 1.3601922527436288

Epoch: 5| Step: 7
Training loss: 0.060731399804353714
Validation loss: 1.3633616278248448

Epoch: 5| Step: 8
Training loss: 0.037114813923835754
Validation loss: 1.3711374216182257

Epoch: 5| Step: 9
Training loss: 0.034784141927957535
Validation loss: 1.3838619609032907

Epoch: 5| Step: 10
Training loss: 0.05020475387573242
Validation loss: 1.3753243261767971

Epoch: 706| Step: 0
Training loss: 0.042626503854990005
Validation loss: 1.4124408383523264

Epoch: 5| Step: 1
Training loss: 0.06568311154842377
Validation loss: 1.3990313263349636

Epoch: 5| Step: 2
Training loss: 0.07936272025108337
Validation loss: 1.4093707069273917

Epoch: 5| Step: 3
Training loss: 0.06598719209432602
Validation loss: 1.4093895881406722

Epoch: 5| Step: 4
Training loss: 0.056185849010944366
Validation loss: 1.3880859703146002

Epoch: 5| Step: 5
Training loss: 0.05144224315881729
Validation loss: 1.372146015526146

Epoch: 5| Step: 6
Training loss: 0.05642590671777725
Validation loss: 1.3764212131500244

Epoch: 5| Step: 7
Training loss: 0.09497765451669693
Validation loss: 1.3778308488989388

Epoch: 5| Step: 8
Training loss: 0.060854800045490265
Validation loss: 1.3614494582658172

Epoch: 5| Step: 9
Training loss: 0.054041631519794464
Validation loss: 1.3597228674478428

Epoch: 5| Step: 10
Training loss: 0.08376864343881607
Validation loss: 1.3539403907714351

Epoch: 707| Step: 0
Training loss: 0.04322480410337448
Validation loss: 1.3550836796401649

Epoch: 5| Step: 1
Training loss: 0.07688165456056595
Validation loss: 1.313999318948356

Epoch: 5| Step: 2
Training loss: 0.07176786661148071
Validation loss: 1.3372068917879494

Epoch: 5| Step: 3
Training loss: 0.07415246963500977
Validation loss: 1.331390303950156

Epoch: 5| Step: 4
Training loss: 0.04103589057922363
Validation loss: 1.3305389009496218

Epoch: 5| Step: 5
Training loss: 0.08810823410749435
Validation loss: 1.316191522024011

Epoch: 5| Step: 6
Training loss: 0.07059627771377563
Validation loss: 1.3546438486345354

Epoch: 5| Step: 7
Training loss: 0.06104458495974541
Validation loss: 1.3659326799454228

Epoch: 5| Step: 8
Training loss: 0.05745166540145874
Validation loss: 1.3585097661582373

Epoch: 5| Step: 9
Training loss: 0.036880139261484146
Validation loss: 1.3789901694943827

Epoch: 5| Step: 10
Training loss: 0.04552311450242996
Validation loss: 1.4124085710894676

Epoch: 708| Step: 0
Training loss: 0.04213744029402733
Validation loss: 1.4103061332497546

Epoch: 5| Step: 1
Training loss: 0.05894218757748604
Validation loss: 1.4135932281453123

Epoch: 5| Step: 2
Training loss: 0.05326080322265625
Validation loss: 1.379190227036835

Epoch: 5| Step: 3
Training loss: 0.1037985235452652
Validation loss: 1.387842446245173

Epoch: 5| Step: 4
Training loss: 0.043981872498989105
Validation loss: 1.39050294987617

Epoch: 5| Step: 5
Training loss: 0.048993490636348724
Validation loss: 1.3747420631429201

Epoch: 5| Step: 6
Training loss: 0.04430660977959633
Validation loss: 1.3589467425500192

Epoch: 5| Step: 7
Training loss: 0.05468054860830307
Validation loss: 1.3626070227674258

Epoch: 5| Step: 8
Training loss: 0.06550784409046173
Validation loss: 1.3509095497028802

Epoch: 5| Step: 9
Training loss: 0.043717917054891586
Validation loss: 1.3415092665662047

Epoch: 5| Step: 10
Training loss: 0.08606074750423431
Validation loss: 1.3192718259749874

Epoch: 709| Step: 0
Training loss: 0.04737617447972298
Validation loss: 1.3462111706374793

Epoch: 5| Step: 1
Training loss: 0.08194084465503693
Validation loss: 1.3322963772281524

Epoch: 5| Step: 2
Training loss: 0.06399230659008026
Validation loss: 1.3315562727630779

Epoch: 5| Step: 3
Training loss: 0.06020697206258774
Validation loss: 1.3336834215348767

Epoch: 5| Step: 4
Training loss: 0.0536130890250206
Validation loss: 1.3217199496043626

Epoch: 5| Step: 5
Training loss: 0.037854500114917755
Validation loss: 1.325668728479775

Epoch: 5| Step: 6
Training loss: 0.06999043375253677
Validation loss: 1.3377266032721407

Epoch: 5| Step: 7
Training loss: 0.08295838534832001
Validation loss: 1.3182432818156418

Epoch: 5| Step: 8
Training loss: 0.061866987496614456
Validation loss: 1.3451671715705626

Epoch: 5| Step: 9
Training loss: 0.06510786712169647
Validation loss: 1.3468868950361848

Epoch: 5| Step: 10
Training loss: 0.05464501306414604
Validation loss: 1.3322376743439706

Epoch: 710| Step: 0
Training loss: 0.05632396787405014
Validation loss: 1.328176449703914

Epoch: 5| Step: 1
Training loss: 0.0687488541007042
Validation loss: 1.3237124918609537

Epoch: 5| Step: 2
Training loss: 0.079862579703331
Validation loss: 1.3318467358107209

Epoch: 5| Step: 3
Training loss: 0.06761930137872696
Validation loss: 1.3654474519914197

Epoch: 5| Step: 4
Training loss: 0.054751016199588776
Validation loss: 1.3689425594063216

Epoch: 5| Step: 5
Training loss: 0.04377589002251625
Validation loss: 1.3681734223519602

Epoch: 5| Step: 6
Training loss: 0.05750624090433121
Validation loss: 1.3945401727512319

Epoch: 5| Step: 7
Training loss: 0.04193633049726486
Validation loss: 1.3692419452051963

Epoch: 5| Step: 8
Training loss: 0.07406406104564667
Validation loss: 1.3818285298603836

Epoch: 5| Step: 9
Training loss: 0.033332061022520065
Validation loss: 1.3497978961595924

Epoch: 5| Step: 10
Training loss: 0.053706493228673935
Validation loss: 1.3516874492809337

Epoch: 711| Step: 0
Training loss: 0.04604435712099075
Validation loss: 1.3606711767053092

Epoch: 5| Step: 1
Training loss: 0.051302097737789154
Validation loss: 1.3440599390255508

Epoch: 5| Step: 2
Training loss: 0.10854621231555939
Validation loss: 1.365065622073348

Epoch: 5| Step: 3
Training loss: 0.07493065297603607
Validation loss: 1.3521622278357064

Epoch: 5| Step: 4
Training loss: 0.05200536921620369
Validation loss: 1.3536403896988078

Epoch: 5| Step: 5
Training loss: 0.03831921145319939
Validation loss: 1.3604729893387004

Epoch: 5| Step: 6
Training loss: 0.058716244995594025
Validation loss: 1.368534735454026

Epoch: 5| Step: 7
Training loss: 0.06023538112640381
Validation loss: 1.3837942884814354

Epoch: 5| Step: 8
Training loss: 0.040750883519649506
Validation loss: 1.38263008030512

Epoch: 5| Step: 9
Training loss: 0.05912666395306587
Validation loss: 1.4066690539800992

Epoch: 5| Step: 10
Training loss: 0.05418417602777481
Validation loss: 1.3712911900653635

Epoch: 712| Step: 0
Training loss: 0.057413555681705475
Validation loss: 1.412811307496922

Epoch: 5| Step: 1
Training loss: 0.05911462381482124
Validation loss: 1.3830012095871793

Epoch: 5| Step: 2
Training loss: 0.06187872961163521
Validation loss: 1.3900199641463578

Epoch: 5| Step: 3
Training loss: 0.06380480527877808
Validation loss: 1.3773052859049972

Epoch: 5| Step: 4
Training loss: 0.07689986377954483
Validation loss: 1.392657809360053

Epoch: 5| Step: 5
Training loss: 0.05865379422903061
Validation loss: 1.3536952118719778

Epoch: 5| Step: 6
Training loss: 0.08184920251369476
Validation loss: 1.3514768542141042

Epoch: 5| Step: 7
Training loss: 0.048784803599119186
Validation loss: 1.3714273181012882

Epoch: 5| Step: 8
Training loss: 0.04851546511054039
Validation loss: 1.3600690364837646

Epoch: 5| Step: 9
Training loss: 0.05227907374501228
Validation loss: 1.3541689201067852

Epoch: 5| Step: 10
Training loss: 0.06004813313484192
Validation loss: 1.3490824622492636

Epoch: 713| Step: 0
Training loss: 0.053179215639829636
Validation loss: 1.3451820842681392

Epoch: 5| Step: 1
Training loss: 0.04887263476848602
Validation loss: 1.3479886247265724

Epoch: 5| Step: 2
Training loss: 0.044079311192035675
Validation loss: 1.3443592799607145

Epoch: 5| Step: 3
Training loss: 0.06980349868535995
Validation loss: 1.34948661891363

Epoch: 5| Step: 4
Training loss: 0.06150396913290024
Validation loss: 1.3485035742482832

Epoch: 5| Step: 5
Training loss: 0.052789151668548584
Validation loss: 1.3536124626795452

Epoch: 5| Step: 6
Training loss: 0.044760871678590775
Validation loss: 1.3463703983573503

Epoch: 5| Step: 7
Training loss: 0.05323426052927971
Validation loss: 1.3540269264610865

Epoch: 5| Step: 8
Training loss: 0.07388941943645477
Validation loss: 1.3746899661197458

Epoch: 5| Step: 9
Training loss: 0.06666243076324463
Validation loss: 1.370238281065418

Epoch: 5| Step: 10
Training loss: 0.08267976343631744
Validation loss: 1.3778521386525964

Epoch: 714| Step: 0
Training loss: 0.061663221567869186
Validation loss: 1.3875397841135662

Epoch: 5| Step: 1
Training loss: 0.072559654712677
Validation loss: 1.3937291304270427

Epoch: 5| Step: 2
Training loss: 0.04683031514286995
Validation loss: 1.40380714144758

Epoch: 5| Step: 3
Training loss: 0.0700615718960762
Validation loss: 1.4182418008004465

Epoch: 5| Step: 4
Training loss: 0.06258264929056168
Validation loss: 1.3943947835635113

Epoch: 5| Step: 5
Training loss: 0.07322316616773605
Validation loss: 1.3943326768054758

Epoch: 5| Step: 6
Training loss: 0.04321715235710144
Validation loss: 1.4028046015770204

Epoch: 5| Step: 7
Training loss: 0.08438445627689362
Validation loss: 1.3791456440443635

Epoch: 5| Step: 8
Training loss: 0.040213990956544876
Validation loss: 1.388148985883241

Epoch: 5| Step: 9
Training loss: 0.10450935363769531
Validation loss: 1.3804642936234832

Epoch: 5| Step: 10
Training loss: 0.08808717876672745
Validation loss: 1.384886436564948

Epoch: 715| Step: 0
Training loss: 0.06805354356765747
Validation loss: 1.3758567546003608

Epoch: 5| Step: 1
Training loss: 0.03136410564184189
Validation loss: 1.391325771167714

Epoch: 5| Step: 2
Training loss: 0.05194054916501045
Validation loss: 1.3741390852517978

Epoch: 5| Step: 3
Training loss: 0.07781918346881866
Validation loss: 1.3725651259063392

Epoch: 5| Step: 4
Training loss: 0.05320584028959274
Validation loss: 1.366170185868458

Epoch: 5| Step: 5
Training loss: 0.05920017883181572
Validation loss: 1.3559224374832646

Epoch: 5| Step: 6
Training loss: 0.06272659450769424
Validation loss: 1.3403869726324593

Epoch: 5| Step: 7
Training loss: 0.06853143870830536
Validation loss: 1.3207460359860492

Epoch: 5| Step: 8
Training loss: 0.0748884454369545
Validation loss: 1.3494453148175312

Epoch: 5| Step: 9
Training loss: 0.09375279396772385
Validation loss: 1.3639350911622405

Epoch: 5| Step: 10
Training loss: 0.09699041396379471
Validation loss: 1.3480852547512259

Epoch: 716| Step: 0
Training loss: 0.04646024480462074
Validation loss: 1.3539657515864219

Epoch: 5| Step: 1
Training loss: 0.032141633331775665
Validation loss: 1.3474048350446968

Epoch: 5| Step: 2
Training loss: 0.05895869806408882
Validation loss: 1.3576326511239494

Epoch: 5| Step: 3
Training loss: 0.07963764667510986
Validation loss: 1.366659729711471

Epoch: 5| Step: 4
Training loss: 0.04152924567461014
Validation loss: 1.339749309324449

Epoch: 5| Step: 5
Training loss: 0.06631684303283691
Validation loss: 1.3334634611683507

Epoch: 5| Step: 6
Training loss: 0.04120125621557236
Validation loss: 1.3479439327793736

Epoch: 5| Step: 7
Training loss: 0.04151798412203789
Validation loss: 1.3366348307619813

Epoch: 5| Step: 8
Training loss: 0.047265056520700455
Validation loss: 1.3478082495350991

Epoch: 5| Step: 9
Training loss: 0.04829493165016174
Validation loss: 1.3401302176137124

Epoch: 5| Step: 10
Training loss: 0.04275985807180405
Validation loss: 1.3823772027928343

Epoch: 717| Step: 0
Training loss: 0.0676286593079567
Validation loss: 1.380386963967354

Epoch: 5| Step: 1
Training loss: 0.04194981977343559
Validation loss: 1.369058705145313

Epoch: 5| Step: 2
Training loss: 0.08132315427064896
Validation loss: 1.3810108592433314

Epoch: 5| Step: 3
Training loss: 0.08389078080654144
Validation loss: 1.3940593696409656

Epoch: 5| Step: 4
Training loss: 0.04308605566620827
Validation loss: 1.376783727317728

Epoch: 5| Step: 5
Training loss: 0.051350630819797516
Validation loss: 1.3796782467954902

Epoch: 5| Step: 6
Training loss: 0.04811675101518631
Validation loss: 1.3546967352590253

Epoch: 5| Step: 7
Training loss: 0.061032313853502274
Validation loss: 1.3550452647670623

Epoch: 5| Step: 8
Training loss: 0.07632218301296234
Validation loss: 1.3795326435437767

Epoch: 5| Step: 9
Training loss: 0.05276469513773918
Validation loss: 1.34376823389402

Epoch: 5| Step: 10
Training loss: 0.07817772030830383
Validation loss: 1.380744812309101

Epoch: 718| Step: 0
Training loss: 0.08513738214969635
Validation loss: 1.3488259171285937

Epoch: 5| Step: 1
Training loss: 0.03808888792991638
Validation loss: 1.3587448071408015

Epoch: 5| Step: 2
Training loss: 0.04336448758840561
Validation loss: 1.3663690282452492

Epoch: 5| Step: 3
Training loss: 0.04508519545197487
Validation loss: 1.3642335155958771

Epoch: 5| Step: 4
Training loss: 0.0529777891933918
Validation loss: 1.3321227770979687

Epoch: 5| Step: 5
Training loss: 0.08151479810476303
Validation loss: 1.3729528207932749

Epoch: 5| Step: 6
Training loss: 0.06278987228870392
Validation loss: 1.3603160637681202

Epoch: 5| Step: 7
Training loss: 0.04556291550397873
Validation loss: 1.3904510005827873

Epoch: 5| Step: 8
Training loss: 0.09081967175006866
Validation loss: 1.4079530239105225

Epoch: 5| Step: 9
Training loss: 0.049085937440395355
Validation loss: 1.3384104941480903

Epoch: 5| Step: 10
Training loss: 0.06233065947890282
Validation loss: 1.344497614009406

Epoch: 719| Step: 0
Training loss: 0.04168560355901718
Validation loss: 1.3515779959258212

Epoch: 5| Step: 1
Training loss: 0.05852685496211052
Validation loss: 1.3495020436984237

Epoch: 5| Step: 2
Training loss: 0.05449856445193291
Validation loss: 1.363860817365749

Epoch: 5| Step: 3
Training loss: 0.05551748722791672
Validation loss: 1.342707150725908

Epoch: 5| Step: 4
Training loss: 0.08621872216463089
Validation loss: 1.3375309154551516

Epoch: 5| Step: 5
Training loss: 0.05531039088964462
Validation loss: 1.3554961912093624

Epoch: 5| Step: 6
Training loss: 0.052822478115558624
Validation loss: 1.346060695186738

Epoch: 5| Step: 7
Training loss: 0.04275766760110855
Validation loss: 1.3575425654329278

Epoch: 5| Step: 8
Training loss: 0.09005572646856308
Validation loss: 1.3533518006724696

Epoch: 5| Step: 9
Training loss: 0.0654207170009613
Validation loss: 1.3670428376043997

Epoch: 5| Step: 10
Training loss: 0.08506936579942703
Validation loss: 1.3689087693409254

Epoch: 720| Step: 0
Training loss: 0.04379844665527344
Validation loss: 1.3613234296921761

Epoch: 5| Step: 1
Training loss: 0.03846471756696701
Validation loss: 1.349018673742971

Epoch: 5| Step: 2
Training loss: 0.041402123868465424
Validation loss: 1.3496863457464403

Epoch: 5| Step: 3
Training loss: 0.04254726320505142
Validation loss: 1.343649555918991

Epoch: 5| Step: 4
Training loss: 0.11432354152202606
Validation loss: 1.3563857719462404

Epoch: 5| Step: 5
Training loss: 0.09547874331474304
Validation loss: 1.3818576233361357

Epoch: 5| Step: 6
Training loss: 0.06801865249872208
Validation loss: 1.371123677940779

Epoch: 5| Step: 7
Training loss: 0.049614496529102325
Validation loss: 1.4037772295295552

Epoch: 5| Step: 8
Training loss: 0.064824178814888
Validation loss: 1.3922719673443866

Epoch: 5| Step: 9
Training loss: 0.0641615092754364
Validation loss: 1.3729805356712752

Epoch: 5| Step: 10
Training loss: 0.05817839503288269
Validation loss: 1.3966206799271286

Epoch: 721| Step: 0
Training loss: 0.08840304613113403
Validation loss: 1.3789649676251154

Epoch: 5| Step: 1
Training loss: 0.06886719912290573
Validation loss: 1.3947000131812146

Epoch: 5| Step: 2
Training loss: 0.05698220059275627
Validation loss: 1.3670073439998012

Epoch: 5| Step: 3
Training loss: 0.04540633037686348
Validation loss: 1.363129913166005

Epoch: 5| Step: 4
Training loss: 0.06046446040272713
Validation loss: 1.367377438852864

Epoch: 5| Step: 5
Training loss: 0.046310581266880035
Validation loss: 1.3552888324183803

Epoch: 5| Step: 6
Training loss: 0.07856442034244537
Validation loss: 1.343650141069966

Epoch: 5| Step: 7
Training loss: 0.047936130315065384
Validation loss: 1.3665006942646478

Epoch: 5| Step: 8
Training loss: 0.0430443175137043
Validation loss: 1.319519938961152

Epoch: 5| Step: 9
Training loss: 0.0564807765185833
Validation loss: 1.3451026831903765

Epoch: 5| Step: 10
Training loss: 0.10858503729104996
Validation loss: 1.3639074845980572

Epoch: 722| Step: 0
Training loss: 0.07394446432590485
Validation loss: 1.390061261833355

Epoch: 5| Step: 1
Training loss: 0.1298997402191162
Validation loss: 1.4080813283561378

Epoch: 5| Step: 2
Training loss: 0.10243654251098633
Validation loss: 1.4162243130386516

Epoch: 5| Step: 3
Training loss: 0.060780562460422516
Validation loss: 1.3982125430978753

Epoch: 5| Step: 4
Training loss: 0.059231895953416824
Validation loss: 1.4057448858855872

Epoch: 5| Step: 5
Training loss: 0.05064602941274643
Validation loss: 1.3602496295846918

Epoch: 5| Step: 6
Training loss: 0.10191039741039276
Validation loss: 1.3798932195991598

Epoch: 5| Step: 7
Training loss: 0.07668166607618332
Validation loss: 1.3717308685343752

Epoch: 5| Step: 8
Training loss: 0.10575999319553375
Validation loss: 1.3785222704692552

Epoch: 5| Step: 9
Training loss: 0.06216083839535713
Validation loss: 1.3588182144267584

Epoch: 5| Step: 10
Training loss: 0.038610849529504776
Validation loss: 1.3696812231053588

Epoch: 723| Step: 0
Training loss: 0.053959231823682785
Validation loss: 1.3836797129723333

Epoch: 5| Step: 1
Training loss: 0.04525201767683029
Validation loss: 1.4167346672345233

Epoch: 5| Step: 2
Training loss: 0.1034066453576088
Validation loss: 1.4236135277696835

Epoch: 5| Step: 3
Training loss: 0.1272144317626953
Validation loss: 1.3964342417255524

Epoch: 5| Step: 4
Training loss: 0.07970529794692993
Validation loss: 1.3890072632861394

Epoch: 5| Step: 5
Training loss: 0.064865842461586
Validation loss: 1.3488794719019244

Epoch: 5| Step: 6
Training loss: 0.07182835042476654
Validation loss: 1.3403126731995614

Epoch: 5| Step: 7
Training loss: 0.06949181854724884
Validation loss: 1.3454695491380588

Epoch: 5| Step: 8
Training loss: 0.054930925369262695
Validation loss: 1.3429612254583707

Epoch: 5| Step: 9
Training loss: 0.05821465328335762
Validation loss: 1.3462478531304227

Epoch: 5| Step: 10
Training loss: 0.018301233649253845
Validation loss: 1.3381586767012073

Epoch: 724| Step: 0
Training loss: 0.053087472915649414
Validation loss: 1.330957962620643

Epoch: 5| Step: 1
Training loss: 0.04348026588559151
Validation loss: 1.3307578204780497

Epoch: 5| Step: 2
Training loss: 0.06839929521083832
Validation loss: 1.3525384792717554

Epoch: 5| Step: 3
Training loss: 0.06066455692052841
Validation loss: 1.3857708028567735

Epoch: 5| Step: 4
Training loss: 0.08958831429481506
Validation loss: 1.375300678514665

Epoch: 5| Step: 5
Training loss: 0.04989141225814819
Validation loss: 1.3737249028298162

Epoch: 5| Step: 6
Training loss: 0.07354816049337387
Validation loss: 1.3860317891643894

Epoch: 5| Step: 7
Training loss: 0.10540349781513214
Validation loss: 1.368184769025413

Epoch: 5| Step: 8
Training loss: 0.08812318742275238
Validation loss: 1.362201085654638

Epoch: 5| Step: 9
Training loss: 0.05596575886011124
Validation loss: 1.3675931269122708

Epoch: 5| Step: 10
Training loss: 0.09087067097425461
Validation loss: 1.3515986165692728

Epoch: 725| Step: 0
Training loss: 0.10444937646389008
Validation loss: 1.3717875070469354

Epoch: 5| Step: 1
Training loss: 0.06424929201602936
Validation loss: 1.360063842547837

Epoch: 5| Step: 2
Training loss: 0.049842268228530884
Validation loss: 1.3594261087397093

Epoch: 5| Step: 3
Training loss: 0.04146096110343933
Validation loss: 1.3568886621024019

Epoch: 5| Step: 4
Training loss: 0.10428911447525024
Validation loss: 1.3922524772664553

Epoch: 5| Step: 5
Training loss: 0.06597641110420227
Validation loss: 1.3819390804536882

Epoch: 5| Step: 6
Training loss: 0.08786425739526749
Validation loss: 1.3687184318419425

Epoch: 5| Step: 7
Training loss: 0.07534605264663696
Validation loss: 1.3565233381845618

Epoch: 5| Step: 8
Training loss: 0.08289890736341476
Validation loss: 1.353923015697028

Epoch: 5| Step: 9
Training loss: 0.061254341155290604
Validation loss: 1.3563207182832944

Epoch: 5| Step: 10
Training loss: 0.05097925662994385
Validation loss: 1.3623137294605214

Epoch: 726| Step: 0
Training loss: 0.08286131173372269
Validation loss: 1.3641417013701571

Epoch: 5| Step: 1
Training loss: 0.08662214130163193
Validation loss: 1.3736020999570047

Epoch: 5| Step: 2
Training loss: 0.0891922190785408
Validation loss: 1.363921784585522

Epoch: 5| Step: 3
Training loss: 0.04834585636854172
Validation loss: 1.3902311466073478

Epoch: 5| Step: 4
Training loss: 0.06032343953847885
Validation loss: 1.351139735150081

Epoch: 5| Step: 5
Training loss: 0.09695309400558472
Validation loss: 1.3757419086271716

Epoch: 5| Step: 6
Training loss: 0.10950269550085068
Validation loss: 1.4097893648250128

Epoch: 5| Step: 7
Training loss: 0.07635577023029327
Validation loss: 1.3888857287745322

Epoch: 5| Step: 8
Training loss: 0.05697634071111679
Validation loss: 1.3729268838000555

Epoch: 5| Step: 9
Training loss: 0.07808761298656464
Validation loss: 1.356768226110807

Epoch: 5| Step: 10
Training loss: 0.04275677725672722
Validation loss: 1.3660252107087003

Epoch: 727| Step: 0
Training loss: 0.04905807599425316
Validation loss: 1.339998032457085

Epoch: 5| Step: 1
Training loss: 0.08764369040727615
Validation loss: 1.3393019565971949

Epoch: 5| Step: 2
Training loss: 0.08802881836891174
Validation loss: 1.3692815919076242

Epoch: 5| Step: 3
Training loss: 0.07902085781097412
Validation loss: 1.3426810605551607

Epoch: 5| Step: 4
Training loss: 0.05551533028483391
Validation loss: 1.3464770111986386

Epoch: 5| Step: 5
Training loss: 0.04559920355677605
Validation loss: 1.3610566469930834

Epoch: 5| Step: 6
Training loss: 0.07943934947252274
Validation loss: 1.3795186883659774

Epoch: 5| Step: 7
Training loss: 0.06218589469790459
Validation loss: 1.37838956873904

Epoch: 5| Step: 8
Training loss: 0.08408753573894501
Validation loss: 1.3958254155292307

Epoch: 5| Step: 9
Training loss: 0.048973191529512405
Validation loss: 1.3984460087232693

Epoch: 5| Step: 10
Training loss: 0.04167322441935539
Validation loss: 1.35581450821251

Epoch: 728| Step: 0
Training loss: 0.06325467675924301
Validation loss: 1.3491877618656363

Epoch: 5| Step: 1
Training loss: 0.05193976312875748
Validation loss: 1.3534184925017818

Epoch: 5| Step: 2
Training loss: 0.059780053794384
Validation loss: 1.3596075132328977

Epoch: 5| Step: 3
Training loss: 0.055893152952194214
Validation loss: 1.3449208082691315

Epoch: 5| Step: 4
Training loss: 0.07443521916866302
Validation loss: 1.3290090022548553

Epoch: 5| Step: 5
Training loss: 0.0750366598367691
Validation loss: 1.3525193904035835

Epoch: 5| Step: 6
Training loss: 0.06817007064819336
Validation loss: 1.3595486020529142

Epoch: 5| Step: 7
Training loss: 0.05305831879377365
Validation loss: 1.353500138046921

Epoch: 5| Step: 8
Training loss: 0.0427711084485054
Validation loss: 1.3403282575709845

Epoch: 5| Step: 9
Training loss: 0.06249740719795227
Validation loss: 1.3421387339151034

Epoch: 5| Step: 10
Training loss: 0.07000758498907089
Validation loss: 1.3269448690516974

Epoch: 729| Step: 0
Training loss: 0.05020939186215401
Validation loss: 1.327296007064081

Epoch: 5| Step: 1
Training loss: 0.06688181310892105
Validation loss: 1.32307909124641

Epoch: 5| Step: 2
Training loss: 0.09860282391309738
Validation loss: 1.3088965249317948

Epoch: 5| Step: 3
Training loss: 0.025862952694296837
Validation loss: 1.3198159522907709

Epoch: 5| Step: 4
Training loss: 0.05200789496302605
Validation loss: 1.327562359071547

Epoch: 5| Step: 5
Training loss: 0.06433980166912079
Validation loss: 1.3253850616434568

Epoch: 5| Step: 6
Training loss: 0.05569460988044739
Validation loss: 1.3210957268232941

Epoch: 5| Step: 7
Training loss: 0.0616363063454628
Validation loss: 1.3392052073632517

Epoch: 5| Step: 8
Training loss: 0.059970010071992874
Validation loss: 1.3476190054288475

Epoch: 5| Step: 9
Training loss: 0.03446555882692337
Validation loss: 1.330349337670111

Epoch: 5| Step: 10
Training loss: 0.0348036028444767
Validation loss: 1.3537625683251249

Epoch: 730| Step: 0
Training loss: 0.04023539274930954
Validation loss: 1.346728899145639

Epoch: 5| Step: 1
Training loss: 0.10001496225595474
Validation loss: 1.3492945009662258

Epoch: 5| Step: 2
Training loss: 0.03813454508781433
Validation loss: 1.353817678266956

Epoch: 5| Step: 3
Training loss: 0.05835691839456558
Validation loss: 1.3507248278587096

Epoch: 5| Step: 4
Training loss: 0.04519601911306381
Validation loss: 1.380864301035481

Epoch: 5| Step: 5
Training loss: 0.04704878106713295
Validation loss: 1.3542826009053055

Epoch: 5| Step: 6
Training loss: 0.07343332469463348
Validation loss: 1.3683311477784188

Epoch: 5| Step: 7
Training loss: 0.030239015817642212
Validation loss: 1.3560426427472023

Epoch: 5| Step: 8
Training loss: 0.06478725373744965
Validation loss: 1.3564472160031718

Epoch: 5| Step: 9
Training loss: 0.04879218712449074
Validation loss: 1.350602469136638

Epoch: 5| Step: 10
Training loss: 0.08123616874217987
Validation loss: 1.3407070149657547

Epoch: 731| Step: 0
Training loss: 0.08276277035474777
Validation loss: 1.3571140817416611

Epoch: 5| Step: 1
Training loss: 0.0711037740111351
Validation loss: 1.3615323753767117

Epoch: 5| Step: 2
Training loss: 0.08055174350738525
Validation loss: 1.361593125968851

Epoch: 5| Step: 3
Training loss: 0.056388843804597855
Validation loss: 1.3632285056575653

Epoch: 5| Step: 4
Training loss: 0.05085165053606033
Validation loss: 1.3682259603213238

Epoch: 5| Step: 5
Training loss: 0.0877610594034195
Validation loss: 1.3821661177501883

Epoch: 5| Step: 6
Training loss: 0.04229588061571121
Validation loss: 1.3603033096559587

Epoch: 5| Step: 7
Training loss: 0.054785050451755524
Validation loss: 1.35208006828062

Epoch: 5| Step: 8
Training loss: 0.0455332025885582
Validation loss: 1.3576440997021173

Epoch: 5| Step: 9
Training loss: 0.04737014323472977
Validation loss: 1.3575038999639533

Epoch: 5| Step: 10
Training loss: 0.06329432874917984
Validation loss: 1.3248796578376525

Epoch: 732| Step: 0
Training loss: 0.05866352468729019
Validation loss: 1.3386661621832079

Epoch: 5| Step: 1
Training loss: 0.07962658256292343
Validation loss: 1.3353885835216892

Epoch: 5| Step: 2
Training loss: 0.06208978220820427
Validation loss: 1.337059518342377

Epoch: 5| Step: 3
Training loss: 0.0548599436879158
Validation loss: 1.3432048008006106

Epoch: 5| Step: 4
Training loss: 0.03567611426115036
Validation loss: 1.336809181397961

Epoch: 5| Step: 5
Training loss: 0.06336206197738647
Validation loss: 1.3683643430791876

Epoch: 5| Step: 6
Training loss: 0.08339227735996246
Validation loss: 1.361330315630923

Epoch: 5| Step: 7
Training loss: 0.045740626752376556
Validation loss: 1.3392923333311593

Epoch: 5| Step: 8
Training loss: 0.051475249230861664
Validation loss: 1.3499559849821112

Epoch: 5| Step: 9
Training loss: 0.04926437884569168
Validation loss: 1.339903364899338

Epoch: 5| Step: 10
Training loss: 0.06698420643806458
Validation loss: 1.3397811715320875

Epoch: 733| Step: 0
Training loss: 0.0752352625131607
Validation loss: 1.3360542020490092

Epoch: 5| Step: 1
Training loss: 0.043660543859004974
Validation loss: 1.3492478369384684

Epoch: 5| Step: 2
Training loss: 0.044941164553165436
Validation loss: 1.3321269840322516

Epoch: 5| Step: 3
Training loss: 0.061719976365566254
Validation loss: 1.344905040597403

Epoch: 5| Step: 4
Training loss: 0.08336980640888214
Validation loss: 1.3513313980512722

Epoch: 5| Step: 5
Training loss: 0.07452638447284698
Validation loss: 1.3721371786568755

Epoch: 5| Step: 6
Training loss: 0.06719350814819336
Validation loss: 1.4086288688003377

Epoch: 5| Step: 7
Training loss: 0.05000459402799606
Validation loss: 1.391061677727648

Epoch: 5| Step: 8
Training loss: 0.04791181907057762
Validation loss: 1.3580025255039174

Epoch: 5| Step: 9
Training loss: 0.058855049312114716
Validation loss: 1.3578481866467385

Epoch: 5| Step: 10
Training loss: 0.057568516582250595
Validation loss: 1.3508985106663038

Epoch: 734| Step: 0
Training loss: 0.06837525218725204
Validation loss: 1.3356459640687512

Epoch: 5| Step: 1
Training loss: 0.03914014995098114
Validation loss: 1.349919742153537

Epoch: 5| Step: 2
Training loss: 0.08802572637796402
Validation loss: 1.3514293765509

Epoch: 5| Step: 3
Training loss: 0.03508390858769417
Validation loss: 1.3355549086806595

Epoch: 5| Step: 4
Training loss: 0.05142970010638237
Validation loss: 1.336195021547297

Epoch: 5| Step: 5
Training loss: 0.05524618178606033
Validation loss: 1.3396310383273708

Epoch: 5| Step: 6
Training loss: 0.05940169841051102
Validation loss: 1.3398219718728015

Epoch: 5| Step: 7
Training loss: 0.09288233518600464
Validation loss: 1.345660137873824

Epoch: 5| Step: 8
Training loss: 0.06533251702785492
Validation loss: 1.3364247096482145

Epoch: 5| Step: 9
Training loss: 0.03407789394259453
Validation loss: 1.34189695953041

Epoch: 5| Step: 10
Training loss: 0.05297704041004181
Validation loss: 1.3406176272258963

Epoch: 735| Step: 0
Training loss: 0.03800908476114273
Validation loss: 1.3420836951142998

Epoch: 5| Step: 1
Training loss: 0.04933829978108406
Validation loss: 1.3306745803484352

Epoch: 5| Step: 2
Training loss: 0.0894019678235054
Validation loss: 1.329125560739989

Epoch: 5| Step: 3
Training loss: 0.04769309237599373
Validation loss: 1.3258210882063834

Epoch: 5| Step: 4
Training loss: 0.06093667075037956
Validation loss: 1.3799075618866952

Epoch: 5| Step: 5
Training loss: 0.06632305681705475
Validation loss: 1.335694048994331

Epoch: 5| Step: 6
Training loss: 0.06442483514547348
Validation loss: 1.3593734643792594

Epoch: 5| Step: 7
Training loss: 0.048573803156614304
Validation loss: 1.3594131969636487

Epoch: 5| Step: 8
Training loss: 0.04977055639028549
Validation loss: 1.3563614468420706

Epoch: 5| Step: 9
Training loss: 0.04399367421865463
Validation loss: 1.3520688318437146

Epoch: 5| Step: 10
Training loss: 0.045127227902412415
Validation loss: 1.3509040237754903

Epoch: 736| Step: 0
Training loss: 0.062131065875291824
Validation loss: 1.3593122959136963

Epoch: 5| Step: 1
Training loss: 0.060466181486845016
Validation loss: 1.3599145809809368

Epoch: 5| Step: 2
Training loss: 0.04038385674357414
Validation loss: 1.333664612103534

Epoch: 5| Step: 3
Training loss: 0.044672977179288864
Validation loss: 1.3339193610734836

Epoch: 5| Step: 4
Training loss: 0.06940270960330963
Validation loss: 1.3377013078299902

Epoch: 5| Step: 5
Training loss: 0.05551779270172119
Validation loss: 1.3409638943210724

Epoch: 5| Step: 6
Training loss: 0.043795593082904816
Validation loss: 1.3409906805202525

Epoch: 5| Step: 7
Training loss: 0.08739881217479706
Validation loss: 1.3296206215376496

Epoch: 5| Step: 8
Training loss: 0.052769679576158524
Validation loss: 1.3266578874280375

Epoch: 5| Step: 9
Training loss: 0.06864573061466217
Validation loss: 1.3255912078324186

Epoch: 5| Step: 10
Training loss: 0.06780607253313065
Validation loss: 1.3449025692478302

Epoch: 737| Step: 0
Training loss: 0.04850147292017937
Validation loss: 1.3487352504525134

Epoch: 5| Step: 1
Training loss: 0.03970992565155029
Validation loss: 1.3516190257123721

Epoch: 5| Step: 2
Training loss: 0.05468197539448738
Validation loss: 1.3666680692344584

Epoch: 5| Step: 3
Training loss: 0.06481437385082245
Validation loss: 1.3722648171968357

Epoch: 5| Step: 4
Training loss: 0.04693728685379028
Validation loss: 1.3562220335006714

Epoch: 5| Step: 5
Training loss: 0.03198765963315964
Validation loss: 1.3599418991355485

Epoch: 5| Step: 6
Training loss: 0.08555490523576736
Validation loss: 1.3721141533185077

Epoch: 5| Step: 7
Training loss: 0.06756146997213364
Validation loss: 1.3725514283744238

Epoch: 5| Step: 8
Training loss: 0.03573713079094887
Validation loss: 1.353020796211817

Epoch: 5| Step: 9
Training loss: 0.06651334464550018
Validation loss: 1.3574034180692447

Epoch: 5| Step: 10
Training loss: 0.04615559056401253
Validation loss: 1.3708582757621683

Epoch: 738| Step: 0
Training loss: 0.04618234187364578
Validation loss: 1.3686393589101813

Epoch: 5| Step: 1
Training loss: 0.07372593879699707
Validation loss: 1.3454336812419276

Epoch: 5| Step: 2
Training loss: 0.030716082081198692
Validation loss: 1.3537766952668466

Epoch: 5| Step: 3
Training loss: 0.06930366158485413
Validation loss: 1.355402502962338

Epoch: 5| Step: 4
Training loss: 0.05115082114934921
Validation loss: 1.34441243192201

Epoch: 5| Step: 5
Training loss: 0.049287594854831696
Validation loss: 1.3657566526884675

Epoch: 5| Step: 6
Training loss: 0.04883050173521042
Validation loss: 1.3736688257545553

Epoch: 5| Step: 7
Training loss: 0.05384879186749458
Validation loss: 1.3295947659400202

Epoch: 5| Step: 8
Training loss: 0.05536903068423271
Validation loss: 1.354076043252022

Epoch: 5| Step: 9
Training loss: 0.03947930037975311
Validation loss: 1.3472796537542855

Epoch: 5| Step: 10
Training loss: 0.06953024119138718
Validation loss: 1.3380316970168904

Epoch: 739| Step: 0
Training loss: 0.05853218585252762
Validation loss: 1.3599301063886253

Epoch: 5| Step: 1
Training loss: 0.043379008769989014
Validation loss: 1.3675577114987116

Epoch: 5| Step: 2
Training loss: 0.06570716202259064
Validation loss: 1.3748733125707155

Epoch: 5| Step: 3
Training loss: 0.03483084961771965
Validation loss: 1.3586780742932392

Epoch: 5| Step: 4
Training loss: 0.04146634042263031
Validation loss: 1.3829655608823221

Epoch: 5| Step: 5
Training loss: 0.0670732706785202
Validation loss: 1.3744189303408387

Epoch: 5| Step: 6
Training loss: 0.07637239992618561
Validation loss: 1.4019458652824484

Epoch: 5| Step: 7
Training loss: 0.06760619580745697
Validation loss: 1.405429805478742

Epoch: 5| Step: 8
Training loss: 0.05375408008694649
Validation loss: 1.3946384704241188

Epoch: 5| Step: 9
Training loss: 0.066753089427948
Validation loss: 1.384807114960045

Epoch: 5| Step: 10
Training loss: 0.04270096495747566
Validation loss: 1.3847106477265716

Epoch: 740| Step: 0
Training loss: 0.053913794457912445
Validation loss: 1.3674574154679493

Epoch: 5| Step: 1
Training loss: 0.053789712488651276
Validation loss: 1.3880266835612636

Epoch: 5| Step: 2
Training loss: 0.06445088237524033
Validation loss: 1.3758954745466991

Epoch: 5| Step: 3
Training loss: 0.06316928565502167
Validation loss: 1.3821244432080177

Epoch: 5| Step: 4
Training loss: 0.09759486466646194
Validation loss: 1.3577403945307578

Epoch: 5| Step: 5
Training loss: 0.059329111129045486
Validation loss: 1.3829479653348205

Epoch: 5| Step: 6
Training loss: 0.04793795943260193
Validation loss: 1.3846347825501555

Epoch: 5| Step: 7
Training loss: 0.0555981770157814
Validation loss: 1.3865551589637675

Epoch: 5| Step: 8
Training loss: 0.05359376594424248
Validation loss: 1.3805583253983529

Epoch: 5| Step: 9
Training loss: 0.05314134806394577
Validation loss: 1.3783605367906633

Epoch: 5| Step: 10
Training loss: 0.06873685121536255
Validation loss: 1.4127292863784298

Epoch: 741| Step: 0
Training loss: 0.03812454268336296
Validation loss: 1.453686519335675

Epoch: 5| Step: 1
Training loss: 0.07587560266256332
Validation loss: 1.4348232002668484

Epoch: 5| Step: 2
Training loss: 0.06937920302152634
Validation loss: 1.4314731397936422

Epoch: 5| Step: 3
Training loss: 0.09791442006826401
Validation loss: 1.4389533714581562

Epoch: 5| Step: 4
Training loss: 0.05127342417836189
Validation loss: 1.4059985190309503

Epoch: 5| Step: 5
Training loss: 0.06942170858383179
Validation loss: 1.3945700583919403

Epoch: 5| Step: 6
Training loss: 0.0637829452753067
Validation loss: 1.3876844708637526

Epoch: 5| Step: 7
Training loss: 0.05018464848399162
Validation loss: 1.377484510021825

Epoch: 5| Step: 8
Training loss: 0.06597000360488892
Validation loss: 1.372742558038363

Epoch: 5| Step: 9
Training loss: 0.067222461104393
Validation loss: 1.3535712726654545

Epoch: 5| Step: 10
Training loss: 0.0653066486120224
Validation loss: 1.3809103459440253

Epoch: 742| Step: 0
Training loss: 0.06189848110079765
Validation loss: 1.3631832292003017

Epoch: 5| Step: 1
Training loss: 0.054666467010974884
Validation loss: 1.3531953647572508

Epoch: 5| Step: 2
Training loss: 0.0823674350976944
Validation loss: 1.355294046863433

Epoch: 5| Step: 3
Training loss: 0.05590854957699776
Validation loss: 1.371092737361949

Epoch: 5| Step: 4
Training loss: 0.07787872850894928
Validation loss: 1.333355930543715

Epoch: 5| Step: 5
Training loss: 0.07567483931779861
Validation loss: 1.3609440326690674

Epoch: 5| Step: 6
Training loss: 0.04094554856419563
Validation loss: 1.368216952969951

Epoch: 5| Step: 7
Training loss: 0.03445214778184891
Validation loss: 1.3426048403145165

Epoch: 5| Step: 8
Training loss: 0.03864961117506027
Validation loss: 1.3690319471461798

Epoch: 5| Step: 9
Training loss: 0.05861424654722214
Validation loss: 1.3432277831979977

Epoch: 5| Step: 10
Training loss: 0.06063767895102501
Validation loss: 1.3659831900750437

Epoch: 743| Step: 0
Training loss: 0.05780031532049179
Validation loss: 1.3476966529764154

Epoch: 5| Step: 1
Training loss: 0.02997770346701145
Validation loss: 1.3540843097112512

Epoch: 5| Step: 2
Training loss: 0.05498586967587471
Validation loss: 1.367257014397652

Epoch: 5| Step: 3
Training loss: 0.0403808131814003
Validation loss: 1.3427201253111645

Epoch: 5| Step: 4
Training loss: 0.04960424825549126
Validation loss: 1.3586397453020977

Epoch: 5| Step: 5
Training loss: 0.045959800481796265
Validation loss: 1.3598433476622387

Epoch: 5| Step: 6
Training loss: 0.04360102862119675
Validation loss: 1.3927908507726525

Epoch: 5| Step: 7
Training loss: 0.04619183391332626
Validation loss: 1.3682377799864738

Epoch: 5| Step: 8
Training loss: 0.07386984676122665
Validation loss: 1.370220197144375

Epoch: 5| Step: 9
Training loss: 0.045175861567258835
Validation loss: 1.3831972101683259

Epoch: 5| Step: 10
Training loss: 0.06683967262506485
Validation loss: 1.369264312969741

Epoch: 744| Step: 0
Training loss: 0.04905743524432182
Validation loss: 1.3747131939857238

Epoch: 5| Step: 1
Training loss: 0.063410684466362
Validation loss: 1.393994669760427

Epoch: 5| Step: 2
Training loss: 0.046524565666913986
Validation loss: 1.3781667909314554

Epoch: 5| Step: 3
Training loss: 0.04542331397533417
Validation loss: 1.3677041056335613

Epoch: 5| Step: 4
Training loss: 0.03790168836712837
Validation loss: 1.3616330046807565

Epoch: 5| Step: 5
Training loss: 0.030301040038466454
Validation loss: 1.3648704328844625

Epoch: 5| Step: 6
Training loss: 0.031520865857601166
Validation loss: 1.3586919435890772

Epoch: 5| Step: 7
Training loss: 0.08553791791200638
Validation loss: 1.3481223467857606

Epoch: 5| Step: 8
Training loss: 0.06945886462926865
Validation loss: 1.3696472683260519

Epoch: 5| Step: 9
Training loss: 0.10851214826107025
Validation loss: 1.3476948007460563

Epoch: 5| Step: 10
Training loss: 0.03877285122871399
Validation loss: 1.3585329735150902

Epoch: 745| Step: 0
Training loss: 0.054010987281799316
Validation loss: 1.3487016154873757

Epoch: 5| Step: 1
Training loss: 0.046124450862407684
Validation loss: 1.3434604534538843

Epoch: 5| Step: 2
Training loss: 0.07161132991313934
Validation loss: 1.3381758992389967

Epoch: 5| Step: 3
Training loss: 0.03558705374598503
Validation loss: 1.3572536501833188

Epoch: 5| Step: 4
Training loss: 0.04057701677083969
Validation loss: 1.3580565914030998

Epoch: 5| Step: 5
Training loss: 0.04688604548573494
Validation loss: 1.3831297684741277

Epoch: 5| Step: 6
Training loss: 0.07104823738336563
Validation loss: 1.367748046434054

Epoch: 5| Step: 7
Training loss: 0.05621988698840141
Validation loss: 1.356890602778363

Epoch: 5| Step: 8
Training loss: 0.03976466506719589
Validation loss: 1.3469454831974481

Epoch: 5| Step: 9
Training loss: 0.06885634362697601
Validation loss: 1.3704023591933712

Epoch: 5| Step: 10
Training loss: 0.050622809678316116
Validation loss: 1.3778614869681738

Epoch: 746| Step: 0
Training loss: 0.04327787831425667
Validation loss: 1.3613161502345916

Epoch: 5| Step: 1
Training loss: 0.042888056486845016
Validation loss: 1.3791187219722296

Epoch: 5| Step: 2
Training loss: 0.0628703311085701
Validation loss: 1.359021347056153

Epoch: 5| Step: 3
Training loss: 0.03479257598519325
Validation loss: 1.3844574625774095

Epoch: 5| Step: 4
Training loss: 0.03252164274454117
Validation loss: 1.3654610341595066

Epoch: 5| Step: 5
Training loss: 0.05616873502731323
Validation loss: 1.3892883780182048

Epoch: 5| Step: 6
Training loss: 0.06619653850793839
Validation loss: 1.402009182078864

Epoch: 5| Step: 7
Training loss: 0.07203109562397003
Validation loss: 1.399573258174363

Epoch: 5| Step: 8
Training loss: 0.02976294420659542
Validation loss: 1.3844428882803967

Epoch: 5| Step: 9
Training loss: 0.030870502814650536
Validation loss: 1.3739361275908768

Epoch: 5| Step: 10
Training loss: 0.04205838590860367
Validation loss: 1.3710785168473438

Epoch: 747| Step: 0
Training loss: 0.05066443607211113
Validation loss: 1.356691598892212

Epoch: 5| Step: 1
Training loss: 0.041871942579746246
Validation loss: 1.3578929003848825

Epoch: 5| Step: 2
Training loss: 0.05739947035908699
Validation loss: 1.3588991248479454

Epoch: 5| Step: 3
Training loss: 0.046952299773693085
Validation loss: 1.347505775831079

Epoch: 5| Step: 4
Training loss: 0.04514004662632942
Validation loss: 1.3461676073330704

Epoch: 5| Step: 5
Training loss: 0.06768093258142471
Validation loss: 1.3338612651312223

Epoch: 5| Step: 6
Training loss: 0.059198301285505295
Validation loss: 1.362418866926624

Epoch: 5| Step: 7
Training loss: 0.03881477564573288
Validation loss: 1.3600216860412269

Epoch: 5| Step: 8
Training loss: 0.061565183103084564
Validation loss: 1.3611771804030224

Epoch: 5| Step: 9
Training loss: 0.038732267916202545
Validation loss: 1.3881268796100412

Epoch: 5| Step: 10
Training loss: 0.08069800585508347
Validation loss: 1.394687492360351

Epoch: 748| Step: 0
Training loss: 0.07186336815357208
Validation loss: 1.405686863007084

Epoch: 5| Step: 1
Training loss: 0.0635066032409668
Validation loss: 1.4106556766776628

Epoch: 5| Step: 2
Training loss: 0.04630447179079056
Validation loss: 1.3920079533771803

Epoch: 5| Step: 3
Training loss: 0.07391241937875748
Validation loss: 1.3565848751734662

Epoch: 5| Step: 4
Training loss: 0.03743346035480499
Validation loss: 1.3492762850176903

Epoch: 5| Step: 5
Training loss: 0.0552685372531414
Validation loss: 1.3574103193898355

Epoch: 5| Step: 6
Training loss: 0.05487434193491936
Validation loss: 1.3425632279406312

Epoch: 5| Step: 7
Training loss: 0.049692001193761826
Validation loss: 1.3632808936539518

Epoch: 5| Step: 8
Training loss: 0.057227473706007004
Validation loss: 1.3314055268482496

Epoch: 5| Step: 9
Training loss: 0.06144561246037483
Validation loss: 1.337885779719199

Epoch: 5| Step: 10
Training loss: 0.04593326896429062
Validation loss: 1.3575910560546383

Epoch: 749| Step: 0
Training loss: 0.06530728191137314
Validation loss: 1.354723520176385

Epoch: 5| Step: 1
Training loss: 0.06166887283325195
Validation loss: 1.353803667970883

Epoch: 5| Step: 2
Training loss: 0.052189119160175323
Validation loss: 1.3719890726509916

Epoch: 5| Step: 3
Training loss: 0.05982905626296997
Validation loss: 1.365217884381612

Epoch: 5| Step: 4
Training loss: 0.04441016912460327
Validation loss: 1.3741537922172136

Epoch: 5| Step: 5
Training loss: 0.0544828362762928
Validation loss: 1.3583056401180964

Epoch: 5| Step: 6
Training loss: 0.03000115230679512
Validation loss: 1.370267560405116

Epoch: 5| Step: 7
Training loss: 0.07010810077190399
Validation loss: 1.388231860694065

Epoch: 5| Step: 8
Training loss: 0.06845157593488693
Validation loss: 1.3846758809140933

Epoch: 5| Step: 9
Training loss: 0.04246862977743149
Validation loss: 1.389607980687131

Epoch: 5| Step: 10
Training loss: 0.033172957599163055
Validation loss: 1.3904939082361036

Epoch: 750| Step: 0
Training loss: 0.03694199025630951
Validation loss: 1.3622420398137902

Epoch: 5| Step: 1
Training loss: 0.04387305676937103
Validation loss: 1.3760329972031295

Epoch: 5| Step: 2
Training loss: 0.03032926842570305
Validation loss: 1.3720237696042625

Epoch: 5| Step: 3
Training loss: 0.027427995577454567
Validation loss: 1.3683516607489636

Epoch: 5| Step: 4
Training loss: 0.05013929679989815
Validation loss: 1.3803056311863724

Epoch: 5| Step: 5
Training loss: 0.055971771478652954
Validation loss: 1.4045743762805898

Epoch: 5| Step: 6
Training loss: 0.048993486911058426
Validation loss: 1.4033021542333788

Epoch: 5| Step: 7
Training loss: 0.06021628528833389
Validation loss: 1.3766745828813123

Epoch: 5| Step: 8
Training loss: 0.029826059937477112
Validation loss: 1.3718148777561803

Epoch: 5| Step: 9
Training loss: 0.066790372133255
Validation loss: 1.3739911381916334

Epoch: 5| Step: 10
Training loss: 0.06025558337569237
Validation loss: 1.3757479818918372

Testing loss: 2.14288059870402
