Epoch: 1| Step: 0
Training loss: 3.6704094409942627
Validation loss: 5.19242206183813

Epoch: 5| Step: 1
Training loss: 4.909542083740234
Validation loss: 5.1653774374274795

Epoch: 5| Step: 2
Training loss: 5.26423978805542
Validation loss: 5.1394332711414625

Epoch: 5| Step: 3
Training loss: 5.06632137298584
Validation loss: 5.1135319432904645

Epoch: 5| Step: 4
Training loss: 4.868134021759033
Validation loss: 5.085265569789435

Epoch: 5| Step: 5
Training loss: 4.2846999168396
Validation loss: 5.054613615876885

Epoch: 5| Step: 6
Training loss: 5.372757911682129
Validation loss: 5.020249448796754

Epoch: 5| Step: 7
Training loss: 4.935868263244629
Validation loss: 4.982102870941162

Epoch: 5| Step: 8
Training loss: 4.6766486167907715
Validation loss: 4.939657762486448

Epoch: 5| Step: 9
Training loss: 5.542301177978516
Validation loss: 4.89302433177989

Epoch: 5| Step: 10
Training loss: 4.552611351013184
Validation loss: 4.840950273698376

Epoch: 2| Step: 0
Training loss: 4.511983394622803
Validation loss: 4.785791133039741

Epoch: 5| Step: 1
Training loss: 5.111177921295166
Validation loss: 4.724012362059726

Epoch: 5| Step: 2
Training loss: 4.140230178833008
Validation loss: 4.66184498161398

Epoch: 5| Step: 3
Training loss: 3.001229763031006
Validation loss: 4.59268020814465

Epoch: 5| Step: 4
Training loss: 5.007948398590088
Validation loss: 4.521568165030531

Epoch: 5| Step: 5
Training loss: 3.5769176483154297
Validation loss: 4.448734719266174

Epoch: 5| Step: 6
Training loss: 4.620896339416504
Validation loss: 4.378395290784939

Epoch: 5| Step: 7
Training loss: 4.46877908706665
Validation loss: 4.31590626829414

Epoch: 5| Step: 8
Training loss: 4.687302589416504
Validation loss: 4.257055636375181

Epoch: 5| Step: 9
Training loss: 3.5005099773406982
Validation loss: 4.201278707032563

Epoch: 5| Step: 10
Training loss: 4.267397403717041
Validation loss: 4.151062514192315

Epoch: 3| Step: 0
Training loss: 3.0153565406799316
Validation loss: 4.105900341464627

Epoch: 5| Step: 1
Training loss: 4.157606601715088
Validation loss: 4.068668883333924

Epoch: 5| Step: 2
Training loss: 3.5159218311309814
Validation loss: 4.030629963003179

Epoch: 5| Step: 3
Training loss: 4.609737873077393
Validation loss: 3.993550480052989

Epoch: 5| Step: 4
Training loss: 3.579188585281372
Validation loss: 3.9544749567585606

Epoch: 5| Step: 5
Training loss: 4.930423736572266
Validation loss: 3.9229604813360397

Epoch: 5| Step: 6
Training loss: 3.5983567237854004
Validation loss: 3.893726815459549

Epoch: 5| Step: 7
Training loss: 3.3709864616394043
Validation loss: 3.8664368019309094

Epoch: 5| Step: 8
Training loss: 3.4259066581726074
Validation loss: 3.8385622116827194

Epoch: 5| Step: 9
Training loss: 3.1595346927642822
Validation loss: 3.8120754508561987

Epoch: 5| Step: 10
Training loss: 4.489406585693359
Validation loss: 3.787420498427524

Epoch: 4| Step: 0
Training loss: 3.261106491088867
Validation loss: 3.760651860185849

Epoch: 5| Step: 1
Training loss: 3.403618335723877
Validation loss: 3.7321721661475395

Epoch: 5| Step: 2
Training loss: 3.8408145904541016
Validation loss: 3.704155563026346

Epoch: 5| Step: 3
Training loss: 3.0456881523132324
Validation loss: 3.6787125602845223

Epoch: 5| Step: 4
Training loss: 2.850590229034424
Validation loss: 3.654894618577855

Epoch: 5| Step: 5
Training loss: 3.6378345489501953
Validation loss: 3.6437349704004105

Epoch: 5| Step: 6
Training loss: 3.733044385910034
Validation loss: 3.620890486624933

Epoch: 5| Step: 7
Training loss: 4.621512413024902
Validation loss: 3.590849386748447

Epoch: 5| Step: 8
Training loss: 3.3390674591064453
Validation loss: 3.5705299377441406

Epoch: 5| Step: 9
Training loss: 3.9435291290283203
Validation loss: 3.544343302326818

Epoch: 5| Step: 10
Training loss: 3.4888157844543457
Validation loss: 3.5151805646957888

Epoch: 5| Step: 0
Training loss: 3.8161568641662598
Validation loss: 3.50065492814587

Epoch: 5| Step: 1
Training loss: 2.524988889694214
Validation loss: 3.4831355566619546

Epoch: 5| Step: 2
Training loss: 3.3780388832092285
Validation loss: 3.4779632886250815

Epoch: 5| Step: 3
Training loss: 3.058763027191162
Validation loss: 3.4623810732236473

Epoch: 5| Step: 4
Training loss: 3.0984199047088623
Validation loss: 3.4567773726678666

Epoch: 5| Step: 5
Training loss: 4.231044292449951
Validation loss: 3.446468758326705

Epoch: 5| Step: 6
Training loss: 3.518244981765747
Validation loss: 3.4274186036920034

Epoch: 5| Step: 7
Training loss: 3.403820753097534
Validation loss: 3.4113617994452037

Epoch: 5| Step: 8
Training loss: 3.5831809043884277
Validation loss: 3.3955745133020545

Epoch: 5| Step: 9
Training loss: 3.6136741638183594
Validation loss: 3.385700536030595

Epoch: 5| Step: 10
Training loss: 2.868274450302124
Validation loss: 3.361623574328679

Epoch: 6| Step: 0
Training loss: 3.0965161323547363
Validation loss: 3.350496812533307

Epoch: 5| Step: 1
Training loss: 4.2982258796691895
Validation loss: 3.3404599851177585

Epoch: 5| Step: 2
Training loss: 3.1780171394348145
Validation loss: 3.3255498947635775

Epoch: 5| Step: 3
Training loss: 3.727506637573242
Validation loss: 3.326293283893216

Epoch: 5| Step: 4
Training loss: 2.947288751602173
Validation loss: 3.3176444012631654

Epoch: 5| Step: 5
Training loss: 2.8434247970581055
Validation loss: 3.3011006437322146

Epoch: 5| Step: 6
Training loss: 3.4039509296417236
Validation loss: 3.282462412311185

Epoch: 5| Step: 7
Training loss: 3.2731845378875732
Validation loss: 3.2680358707263903

Epoch: 5| Step: 8
Training loss: 3.5306155681610107
Validation loss: 3.260926395334223

Epoch: 5| Step: 9
Training loss: 2.148282527923584
Validation loss: 3.2479285963119997

Epoch: 5| Step: 10
Training loss: 3.570659875869751
Validation loss: 3.2437074774055072

Epoch: 7| Step: 0
Training loss: 2.573823928833008
Validation loss: 3.225689564981768

Epoch: 5| Step: 1
Training loss: 3.324620485305786
Validation loss: 3.2177927109502975

Epoch: 5| Step: 2
Training loss: 3.1950366497039795
Validation loss: 3.204546405423072

Epoch: 5| Step: 3
Training loss: 2.8229012489318848
Validation loss: 3.2144451397721485

Epoch: 5| Step: 4
Training loss: 2.599226713180542
Validation loss: 3.2078559731924408

Epoch: 5| Step: 5
Training loss: 3.805943012237549
Validation loss: 3.1967533967828237

Epoch: 5| Step: 6
Training loss: 3.419451951980591
Validation loss: 3.172048604616555

Epoch: 5| Step: 7
Training loss: 3.5624489784240723
Validation loss: 3.1597228255323184

Epoch: 5| Step: 8
Training loss: 2.268697738647461
Validation loss: 3.1502584103615052

Epoch: 5| Step: 9
Training loss: 3.41741681098938
Validation loss: 3.1532558574471423

Epoch: 5| Step: 10
Training loss: 4.204725742340088
Validation loss: 3.130942775357154

Epoch: 8| Step: 0
Training loss: 3.3557333946228027
Validation loss: 3.126773882937688

Epoch: 5| Step: 1
Training loss: 2.751905918121338
Validation loss: 3.1302154423088155

Epoch: 5| Step: 2
Training loss: 2.3519721031188965
Validation loss: 3.1259389949101273

Epoch: 5| Step: 3
Training loss: 2.969085693359375
Validation loss: 3.1192245714126097

Epoch: 5| Step: 4
Training loss: 3.0234973430633545
Validation loss: 3.1031475528593986

Epoch: 5| Step: 5
Training loss: 4.081719398498535
Validation loss: 3.0897490542422057

Epoch: 5| Step: 6
Training loss: 2.957061290740967
Validation loss: 3.079000373040476

Epoch: 5| Step: 7
Training loss: 2.8382887840270996
Validation loss: 3.0756813377462406

Epoch: 5| Step: 8
Training loss: 4.294798851013184
Validation loss: 3.0752962943046325

Epoch: 5| Step: 9
Training loss: 2.76265287399292
Validation loss: 3.0644163931569746

Epoch: 5| Step: 10
Training loss: 3.0029921531677246
Validation loss: 3.058495854818693

Epoch: 9| Step: 0
Training loss: 3.2726006507873535
Validation loss: 3.04172638411163

Epoch: 5| Step: 1
Training loss: 2.4587371349334717
Validation loss: 3.0286066788499073

Epoch: 5| Step: 2
Training loss: 2.058135986328125
Validation loss: 3.0245190179476173

Epoch: 5| Step: 3
Training loss: 3.7751641273498535
Validation loss: 3.0360802014668784

Epoch: 5| Step: 4
Training loss: 2.7359089851379395
Validation loss: 3.0423735521172963

Epoch: 5| Step: 5
Training loss: 3.7054076194763184
Validation loss: 3.013924834548786

Epoch: 5| Step: 6
Training loss: 3.515571117401123
Validation loss: 2.9964939189213577

Epoch: 5| Step: 7
Training loss: 2.9441452026367188
Validation loss: 2.9840794763257428

Epoch: 5| Step: 8
Training loss: 4.018481254577637
Validation loss: 2.982663218693067

Epoch: 5| Step: 9
Training loss: 2.262181520462036
Validation loss: 2.983648471934821

Epoch: 5| Step: 10
Training loss: 3.0373430252075195
Validation loss: 2.9789168706504245

Epoch: 10| Step: 0
Training loss: 2.8834705352783203
Validation loss: 2.9700866001908497

Epoch: 5| Step: 1
Training loss: 3.208113193511963
Validation loss: 2.9612468288790796

Epoch: 5| Step: 2
Training loss: 4.132462978363037
Validation loss: 2.9497113945663616

Epoch: 5| Step: 3
Training loss: 3.479764938354492
Validation loss: 2.9430844117236394

Epoch: 5| Step: 4
Training loss: 2.3426103591918945
Validation loss: 2.936729161970077

Epoch: 5| Step: 5
Training loss: 2.5930168628692627
Validation loss: 2.927475929260254

Epoch: 5| Step: 6
Training loss: 3.5082411766052246
Validation loss: 2.9296247318226802

Epoch: 5| Step: 7
Training loss: 2.7600045204162598
Validation loss: 2.9250189873480026

Epoch: 5| Step: 8
Training loss: 2.6119301319122314
Validation loss: 2.912841348237889

Epoch: 5| Step: 9
Training loss: 2.7728917598724365
Validation loss: 2.910454814152051

Epoch: 5| Step: 10
Training loss: 2.8612940311431885
Validation loss: 2.902276897943148

Epoch: 11| Step: 0
Training loss: 2.9080593585968018
Validation loss: 2.8944918955526044

Epoch: 5| Step: 1
Training loss: 3.033903121948242
Validation loss: 2.8980483239696873

Epoch: 5| Step: 2
Training loss: 2.947828531265259
Validation loss: 2.8943163502600884

Epoch: 5| Step: 3
Training loss: 3.0769643783569336
Validation loss: 2.918534814670522

Epoch: 5| Step: 4
Training loss: 3.489093780517578
Validation loss: 2.8737876005070184

Epoch: 5| Step: 5
Training loss: 4.0363450050354
Validation loss: 2.872383620149346

Epoch: 5| Step: 6
Training loss: 2.197417974472046
Validation loss: 2.8755430611230994

Epoch: 5| Step: 7
Training loss: 2.496375322341919
Validation loss: 2.882297162086733

Epoch: 5| Step: 8
Training loss: 2.893280029296875
Validation loss: 2.8716546258618756

Epoch: 5| Step: 9
Training loss: 2.7641429901123047
Validation loss: 2.8618829814336633

Epoch: 5| Step: 10
Training loss: 2.94409441947937
Validation loss: 2.8536314810475996

Epoch: 12| Step: 0
Training loss: 2.6230359077453613
Validation loss: 2.848958146187567

Epoch: 5| Step: 1
Training loss: 2.35442852973938
Validation loss: 2.849687450675554

Epoch: 5| Step: 2
Training loss: 2.8312582969665527
Validation loss: 2.8542498875689764

Epoch: 5| Step: 3
Training loss: 3.278799533843994
Validation loss: 2.85414473472103

Epoch: 5| Step: 4
Training loss: 3.055086612701416
Validation loss: 2.870185854614422

Epoch: 5| Step: 5
Training loss: 3.80615496635437
Validation loss: 2.8317389513856623

Epoch: 5| Step: 6
Training loss: 2.6620121002197266
Validation loss: 2.8268814574005785

Epoch: 5| Step: 7
Training loss: 3.1679599285125732
Validation loss: 2.8332062690488753

Epoch: 5| Step: 8
Training loss: 3.3101532459259033
Validation loss: 2.830283047050558

Epoch: 5| Step: 9
Training loss: 2.7134346961975098
Validation loss: 2.8251141937830115

Epoch: 5| Step: 10
Training loss: 2.6738240718841553
Validation loss: 2.812420937322801

Epoch: 13| Step: 0
Training loss: 2.468461275100708
Validation loss: 2.8069165316961144

Epoch: 5| Step: 1
Training loss: 3.116161823272705
Validation loss: 2.804981526508126

Epoch: 5| Step: 2
Training loss: 2.7461447715759277
Validation loss: 2.820718806277039

Epoch: 5| Step: 3
Training loss: 3.3417935371398926
Validation loss: 2.8294753464319373

Epoch: 5| Step: 4
Training loss: 2.8090555667877197
Validation loss: 2.807045977602723

Epoch: 5| Step: 5
Training loss: 3.5043082237243652
Validation loss: 2.8090978437854397

Epoch: 5| Step: 6
Training loss: 3.4966399669647217
Validation loss: 2.8060767522422214

Epoch: 5| Step: 7
Training loss: 2.6433451175689697
Validation loss: 2.785704279458651

Epoch: 5| Step: 8
Training loss: 2.4434401988983154
Validation loss: 2.7944441123675277

Epoch: 5| Step: 9
Training loss: 2.3194849491119385
Validation loss: 2.7944487730662027

Epoch: 5| Step: 10
Training loss: 3.3743858337402344
Validation loss: 2.7883221821118425

Epoch: 14| Step: 0
Training loss: 2.7337698936462402
Validation loss: 2.7827940166637464

Epoch: 5| Step: 1
Training loss: 3.3616416454315186
Validation loss: 2.77449369430542

Epoch: 5| Step: 2
Training loss: 3.17030668258667
Validation loss: 2.764390806997976

Epoch: 5| Step: 3
Training loss: 3.348879337310791
Validation loss: 2.7677775454777542

Epoch: 5| Step: 4
Training loss: 2.7197890281677246
Validation loss: 2.773362503256849

Epoch: 5| Step: 5
Training loss: 2.199385166168213
Validation loss: 2.7870726995570685

Epoch: 5| Step: 6
Training loss: 2.6541588306427
Validation loss: 2.7815679170752086

Epoch: 5| Step: 7
Training loss: 2.336594581604004
Validation loss: 2.767104297555903

Epoch: 5| Step: 8
Training loss: 3.132925033569336
Validation loss: 2.7581316322408695

Epoch: 5| Step: 9
Training loss: 3.472806453704834
Validation loss: 2.747384571260022

Epoch: 5| Step: 10
Training loss: 2.893132209777832
Validation loss: 2.7491509709306943

Epoch: 15| Step: 0
Training loss: 2.4819703102111816
Validation loss: 2.749390955894224

Epoch: 5| Step: 1
Training loss: 3.026078224182129
Validation loss: 2.7508459783369497

Epoch: 5| Step: 2
Training loss: 2.6883959770202637
Validation loss: 2.7494202531794065

Epoch: 5| Step: 3
Training loss: 2.3460822105407715
Validation loss: 2.7439042111878753

Epoch: 5| Step: 4
Training loss: 2.619576930999756
Validation loss: 2.740200665689284

Epoch: 5| Step: 5
Training loss: 2.7636988162994385
Validation loss: 2.743815693804013

Epoch: 5| Step: 6
Training loss: 3.4773621559143066
Validation loss: 2.7419985955761326

Epoch: 5| Step: 7
Training loss: 2.9153366088867188
Validation loss: 2.7413776638687297

Epoch: 5| Step: 8
Training loss: 3.987229585647583
Validation loss: 2.7394933495470273

Epoch: 5| Step: 9
Training loss: 2.9470937252044678
Validation loss: 2.735217532803935

Epoch: 5| Step: 10
Training loss: 2.527942180633545
Validation loss: 2.7349560747864428

Epoch: 16| Step: 0
Training loss: 3.2313156127929688
Validation loss: 2.7349198146532943

Epoch: 5| Step: 1
Training loss: 1.9609686136245728
Validation loss: 2.730364312407791

Epoch: 5| Step: 2
Training loss: 2.7759902477264404
Validation loss: 2.724891698488625

Epoch: 5| Step: 3
Training loss: 3.2315545082092285
Validation loss: 2.7185299934879428

Epoch: 5| Step: 4
Training loss: 2.3484110832214355
Validation loss: 2.7235659937704764

Epoch: 5| Step: 5
Training loss: 3.2539496421813965
Validation loss: 2.7238377883870113

Epoch: 5| Step: 6
Training loss: 2.3650567531585693
Validation loss: 2.7286439787956978

Epoch: 5| Step: 7
Training loss: 3.424091339111328
Validation loss: 2.7263941444376463

Epoch: 5| Step: 8
Training loss: 3.7064852714538574
Validation loss: 2.7231271625846944

Epoch: 5| Step: 9
Training loss: 3.1028530597686768
Validation loss: 2.71978102191802

Epoch: 5| Step: 10
Training loss: 2.240964412689209
Validation loss: 2.713524623583722

Epoch: 17| Step: 0
Training loss: 3.1843981742858887
Validation loss: 2.711293093619808

Epoch: 5| Step: 1
Training loss: 2.1883461475372314
Validation loss: 2.7115623386957313

Epoch: 5| Step: 2
Training loss: 2.3580496311187744
Validation loss: 2.7112339235121206

Epoch: 5| Step: 3
Training loss: 3.2372405529022217
Validation loss: 2.714148659859934

Epoch: 5| Step: 4
Training loss: 3.8299522399902344
Validation loss: 2.7092591485669537

Epoch: 5| Step: 5
Training loss: 2.216719388961792
Validation loss: 2.7038572757474837

Epoch: 5| Step: 6
Training loss: 2.7792675495147705
Validation loss: 2.7020771682903333

Epoch: 5| Step: 7
Training loss: 2.822394371032715
Validation loss: 2.6989875403783654

Epoch: 5| Step: 8
Training loss: 2.6102449893951416
Validation loss: 2.6990419587781354

Epoch: 5| Step: 9
Training loss: 3.4294447898864746
Validation loss: 2.6995430300312657

Epoch: 5| Step: 10
Training loss: 2.9124481678009033
Validation loss: 2.6936307184157835

Epoch: 18| Step: 0
Training loss: 2.672362804412842
Validation loss: 2.6866203738797094

Epoch: 5| Step: 1
Training loss: 2.7439117431640625
Validation loss: 2.6937711725952806

Epoch: 5| Step: 2
Training loss: 2.8239097595214844
Validation loss: 2.691174581486692

Epoch: 5| Step: 3
Training loss: 2.930046558380127
Validation loss: 2.68480561881937

Epoch: 5| Step: 4
Training loss: 3.0029540061950684
Validation loss: 2.6819370280029955

Epoch: 5| Step: 5
Training loss: 2.892120838165283
Validation loss: 2.683291930024342

Epoch: 5| Step: 6
Training loss: 3.19162654876709
Validation loss: 2.6788460029068815

Epoch: 5| Step: 7
Training loss: 2.926659345626831
Validation loss: 2.678764412480016

Epoch: 5| Step: 8
Training loss: 2.8318357467651367
Validation loss: 2.6838640859050136

Epoch: 5| Step: 9
Training loss: 2.4278078079223633
Validation loss: 2.6771054088428454

Epoch: 5| Step: 10
Training loss: 3.002673387527466
Validation loss: 2.6762395007635957

Epoch: 19| Step: 0
Training loss: 2.813742160797119
Validation loss: 2.6767082111809843

Epoch: 5| Step: 1
Training loss: 3.115076780319214
Validation loss: 2.6745779001584618

Epoch: 5| Step: 2
Training loss: 2.2647626399993896
Validation loss: 2.6834906455009215

Epoch: 5| Step: 3
Training loss: 2.5743298530578613
Validation loss: 2.7111078462293072

Epoch: 5| Step: 4
Training loss: 3.4960579872131348
Validation loss: 2.725160273172522

Epoch: 5| Step: 5
Training loss: 2.870065212249756
Validation loss: 2.724503894006052

Epoch: 5| Step: 6
Training loss: 3.188530683517456
Validation loss: 2.7064361623538438

Epoch: 5| Step: 7
Training loss: 3.1479032039642334
Validation loss: 2.684102107119817

Epoch: 5| Step: 8
Training loss: 2.790010929107666
Validation loss: 2.6693576907598846

Epoch: 5| Step: 9
Training loss: 2.595738410949707
Validation loss: 2.66293760525283

Epoch: 5| Step: 10
Training loss: 2.6068663597106934
Validation loss: 2.6719606768700386

Epoch: 20| Step: 0
Training loss: 2.9472153186798096
Validation loss: 2.703797765957412

Epoch: 5| Step: 1
Training loss: 2.657057523727417
Validation loss: 2.7226005420889905

Epoch: 5| Step: 2
Training loss: 2.6807894706726074
Validation loss: 2.6911973696883007

Epoch: 5| Step: 3
Training loss: 2.6823723316192627
Validation loss: 2.679337804035474

Epoch: 5| Step: 4
Training loss: 3.0480923652648926
Validation loss: 2.6652402057442615

Epoch: 5| Step: 5
Training loss: 2.757981777191162
Validation loss: 2.669158420255107

Epoch: 5| Step: 6
Training loss: 3.48956298828125
Validation loss: 2.6705227359648673

Epoch: 5| Step: 7
Training loss: 3.461695432662964
Validation loss: 2.671455362791656

Epoch: 5| Step: 8
Training loss: 2.4460251331329346
Validation loss: 2.6942986288378314

Epoch: 5| Step: 9
Training loss: 2.4708962440490723
Validation loss: 2.7180760060587237

Epoch: 5| Step: 10
Training loss: 2.7759029865264893
Validation loss: 2.7272909892502653

Epoch: 21| Step: 0
Training loss: 2.5229506492614746
Validation loss: 2.7289143480280393

Epoch: 5| Step: 1
Training loss: 3.121915340423584
Validation loss: 2.7118103863090597

Epoch: 5| Step: 2
Training loss: 2.432602882385254
Validation loss: 2.6645204687631256

Epoch: 5| Step: 3
Training loss: 3.33125376701355
Validation loss: 2.671221056292134

Epoch: 5| Step: 4
Training loss: 3.020559787750244
Validation loss: 2.6688417311637633

Epoch: 5| Step: 5
Training loss: 3.5027871131896973
Validation loss: 2.6614039585154545

Epoch: 5| Step: 6
Training loss: 2.32245135307312
Validation loss: 2.6567759565127793

Epoch: 5| Step: 7
Training loss: 2.757136821746826
Validation loss: 2.6494935712506695

Epoch: 5| Step: 8
Training loss: 2.8539299964904785
Validation loss: 2.6453269630350094

Epoch: 5| Step: 9
Training loss: 2.875825881958008
Validation loss: 2.644981430422875

Epoch: 5| Step: 10
Training loss: 2.416175603866577
Validation loss: 2.6510482500958186

Epoch: 22| Step: 0
Training loss: 3.419978618621826
Validation loss: 2.6775526744063183

Epoch: 5| Step: 1
Training loss: 2.981253147125244
Validation loss: 2.6999132505027195

Epoch: 5| Step: 2
Training loss: 2.682227849960327
Validation loss: 2.677196546267438

Epoch: 5| Step: 3
Training loss: 2.658430576324463
Validation loss: 2.6448332084122526

Epoch: 5| Step: 4
Training loss: 2.2567780017852783
Validation loss: 2.6345108580845658

Epoch: 5| Step: 5
Training loss: 1.9906470775604248
Validation loss: 2.6389389999451174

Epoch: 5| Step: 6
Training loss: 4.0075531005859375
Validation loss: 2.6521219412485757

Epoch: 5| Step: 7
Training loss: 3.61164927482605
Validation loss: 2.6598877996526737

Epoch: 5| Step: 8
Training loss: 2.5405092239379883
Validation loss: 2.6476674336259083

Epoch: 5| Step: 9
Training loss: 2.667675733566284
Validation loss: 2.6380403221294446

Epoch: 5| Step: 10
Training loss: 2.3211190700531006
Validation loss: 2.6307935458357616

Epoch: 23| Step: 0
Training loss: 2.6813454627990723
Validation loss: 2.629231906706287

Epoch: 5| Step: 1
Training loss: 2.1011674404144287
Validation loss: 2.6309337333966325

Epoch: 5| Step: 2
Training loss: 3.170051097869873
Validation loss: 2.6273037797661236

Epoch: 5| Step: 3
Training loss: 2.773314952850342
Validation loss: 2.636243748408492

Epoch: 5| Step: 4
Training loss: 2.879232883453369
Validation loss: 2.6391492941046275

Epoch: 5| Step: 5
Training loss: 3.580465316772461
Validation loss: 2.630076700641263

Epoch: 5| Step: 6
Training loss: 2.7831032276153564
Validation loss: 2.6282720899069183

Epoch: 5| Step: 7
Training loss: 3.0394158363342285
Validation loss: 2.623845807967647

Epoch: 5| Step: 8
Training loss: 2.673582077026367
Validation loss: 2.6211602175107567

Epoch: 5| Step: 9
Training loss: 2.6162610054016113
Validation loss: 2.6255259642037014

Epoch: 5| Step: 10
Training loss: 2.702659845352173
Validation loss: 2.6222973869692896

Epoch: 24| Step: 0
Training loss: 3.8254170417785645
Validation loss: 2.623604877020723

Epoch: 5| Step: 1
Training loss: 2.7756824493408203
Validation loss: 2.624638834307271

Epoch: 5| Step: 2
Training loss: 2.682129383087158
Validation loss: 2.6252478322675152

Epoch: 5| Step: 3
Training loss: 2.9572112560272217
Validation loss: 2.678010759815093

Epoch: 5| Step: 4
Training loss: 2.7906956672668457
Validation loss: 2.64533624469593

Epoch: 5| Step: 5
Training loss: 2.441953659057617
Validation loss: 2.6214652394735687

Epoch: 5| Step: 6
Training loss: 2.6196014881134033
Validation loss: 2.6193920438007643

Epoch: 5| Step: 7
Training loss: 2.861997127532959
Validation loss: 2.6170877769429195

Epoch: 5| Step: 8
Training loss: 2.510923385620117
Validation loss: 2.622906484911519

Epoch: 5| Step: 9
Training loss: 3.2589027881622314
Validation loss: 2.6339760480388517

Epoch: 5| Step: 10
Training loss: 2.1892614364624023
Validation loss: 2.6398468376487814

Epoch: 25| Step: 0
Training loss: 2.6857657432556152
Validation loss: 2.6595354644201135

Epoch: 5| Step: 1
Training loss: 3.566516876220703
Validation loss: 2.6402543411459973

Epoch: 5| Step: 2
Training loss: 2.7359771728515625
Validation loss: 2.6286905760406167

Epoch: 5| Step: 3
Training loss: 3.023817777633667
Validation loss: 2.6230621901891564

Epoch: 5| Step: 4
Training loss: 2.353559970855713
Validation loss: 2.6156467827417518

Epoch: 5| Step: 5
Training loss: 2.645395278930664
Validation loss: 2.6090009007402646

Epoch: 5| Step: 6
Training loss: 2.1953859329223633
Validation loss: 2.6031534620510635

Epoch: 5| Step: 7
Training loss: 2.705442190170288
Validation loss: 2.6121437870046145

Epoch: 5| Step: 8
Training loss: 2.5326170921325684
Validation loss: 2.649490894809846

Epoch: 5| Step: 9
Training loss: 3.2827422618865967
Validation loss: 2.642158046845467

Epoch: 5| Step: 10
Training loss: 3.220149517059326
Validation loss: 2.661004361285958

Epoch: 26| Step: 0
Training loss: 3.1101107597351074
Validation loss: 2.69529834101277

Epoch: 5| Step: 1
Training loss: 2.660839080810547
Validation loss: 2.6410261841230493

Epoch: 5| Step: 2
Training loss: 2.9084277153015137
Validation loss: 2.609623829523722

Epoch: 5| Step: 3
Training loss: 2.699228525161743
Validation loss: 2.6077318370983167

Epoch: 5| Step: 4
Training loss: 2.2894959449768066
Validation loss: 2.6149206802409184

Epoch: 5| Step: 5
Training loss: 2.546421527862549
Validation loss: 2.6265796179412515

Epoch: 5| Step: 6
Training loss: 2.8794541358947754
Validation loss: 2.6481045907543552

Epoch: 5| Step: 7
Training loss: 2.739488124847412
Validation loss: 2.6621712356485348

Epoch: 5| Step: 8
Training loss: 2.816272497177124
Validation loss: 2.657995475235806

Epoch: 5| Step: 9
Training loss: 3.3657031059265137
Validation loss: 2.641980778786444

Epoch: 5| Step: 10
Training loss: 3.1671600341796875
Validation loss: 2.6224419481010846

Epoch: 27| Step: 0
Training loss: 2.846020460128784
Validation loss: 2.614432934791811

Epoch: 5| Step: 1
Training loss: 3.6585094928741455
Validation loss: 2.6082245790830223

Epoch: 5| Step: 2
Training loss: 2.5724222660064697
Validation loss: 2.6055479613683556

Epoch: 5| Step: 3
Training loss: 2.572503089904785
Validation loss: 2.634043872997325

Epoch: 5| Step: 4
Training loss: 2.6378862857818604
Validation loss: 2.6490164444010746

Epoch: 5| Step: 5
Training loss: 3.4058456420898438
Validation loss: 2.6334412815750285

Epoch: 5| Step: 6
Training loss: 2.3785829544067383
Validation loss: 2.5988750150126796

Epoch: 5| Step: 7
Training loss: 2.6264660358428955
Validation loss: 2.5867046976602204

Epoch: 5| Step: 8
Training loss: 2.6939804553985596
Validation loss: 2.5894293195457867

Epoch: 5| Step: 9
Training loss: 2.6842474937438965
Validation loss: 2.6304808662783716

Epoch: 5| Step: 10
Training loss: 2.600254535675049
Validation loss: 2.6047068283122075

Epoch: 28| Step: 0
Training loss: 2.8037657737731934
Validation loss: 2.6151018783610356

Epoch: 5| Step: 1
Training loss: 2.6320338249206543
Validation loss: 2.592667815505817

Epoch: 5| Step: 2
Training loss: 2.4510200023651123
Validation loss: 2.585739361342563

Epoch: 5| Step: 3
Training loss: 3.1896812915802
Validation loss: 2.580508465407997

Epoch: 5| Step: 4
Training loss: 3.104461193084717
Validation loss: 2.5772737456906225

Epoch: 5| Step: 5
Training loss: 2.5401453971862793
Validation loss: 2.5750184212961504

Epoch: 5| Step: 6
Training loss: 2.6633787155151367
Validation loss: 2.573008901329451

Epoch: 5| Step: 7
Training loss: 3.0612499713897705
Validation loss: 2.5748137812460623

Epoch: 5| Step: 8
Training loss: 2.7102510929107666
Validation loss: 2.5822025806673112

Epoch: 5| Step: 9
Training loss: 2.1543049812316895
Validation loss: 2.602782372505434

Epoch: 5| Step: 10
Training loss: 3.3374183177948
Validation loss: 2.594561025660525

Epoch: 29| Step: 0
Training loss: 2.9009509086608887
Validation loss: 2.5776138972210627

Epoch: 5| Step: 1
Training loss: 3.1019160747528076
Validation loss: 2.569479824394308

Epoch: 5| Step: 2
Training loss: 3.142906665802002
Validation loss: 2.564537904595816

Epoch: 5| Step: 3
Training loss: 3.149426221847534
Validation loss: 2.570252077553862

Epoch: 5| Step: 4
Training loss: 2.6528303623199463
Validation loss: 2.5734384290633665

Epoch: 5| Step: 5
Training loss: 2.419781446456909
Validation loss: 2.5658508321290374

Epoch: 5| Step: 6
Training loss: 2.777672290802002
Validation loss: 2.564136497436031

Epoch: 5| Step: 7
Training loss: 2.420996904373169
Validation loss: 2.5604250738697667

Epoch: 5| Step: 8
Training loss: 2.990159273147583
Validation loss: 2.5560140917378087

Epoch: 5| Step: 9
Training loss: 1.9137237071990967
Validation loss: 2.551531518659284

Epoch: 5| Step: 10
Training loss: 2.9474902153015137
Validation loss: 2.562010852239465

Epoch: 30| Step: 0
Training loss: 3.256357192993164
Validation loss: 2.589298681546283

Epoch: 5| Step: 1
Training loss: 2.8015782833099365
Validation loss: 2.592787336277705

Epoch: 5| Step: 2
Training loss: 2.408116340637207
Validation loss: 2.558406736261101

Epoch: 5| Step: 3
Training loss: 3.606667995452881
Validation loss: 2.5542899511193715

Epoch: 5| Step: 4
Training loss: 2.006300687789917
Validation loss: 2.551732006893363

Epoch: 5| Step: 5
Training loss: 2.2026729583740234
Validation loss: 2.558997869491577

Epoch: 5| Step: 6
Training loss: 3.303873062133789
Validation loss: 2.55875071402519

Epoch: 5| Step: 7
Training loss: 1.9970744848251343
Validation loss: 2.5656478122998307

Epoch: 5| Step: 8
Training loss: 2.5609049797058105
Validation loss: 2.562097285383491

Epoch: 5| Step: 9
Training loss: 2.97922945022583
Validation loss: 2.5627272718696186

Epoch: 5| Step: 10
Training loss: 3.4425101280212402
Validation loss: 2.5622759788267073

Epoch: 31| Step: 0
Training loss: 2.882058620452881
Validation loss: 2.5674635953800653

Epoch: 5| Step: 1
Training loss: 3.27892804145813
Validation loss: 2.561089636177145

Epoch: 5| Step: 2
Training loss: 3.1620583534240723
Validation loss: 2.5479618759565454

Epoch: 5| Step: 3
Training loss: 2.2485833168029785
Validation loss: 2.539114994387473

Epoch: 5| Step: 4
Training loss: 2.381762742996216
Validation loss: 2.544212782254783

Epoch: 5| Step: 5
Training loss: 2.9944469928741455
Validation loss: 2.5622126569030104

Epoch: 5| Step: 6
Training loss: 3.0701048374176025
Validation loss: 2.577285223109748

Epoch: 5| Step: 7
Training loss: 2.4178924560546875
Validation loss: 2.5829090020989858

Epoch: 5| Step: 8
Training loss: 2.7137484550476074
Validation loss: 2.5863398941614295

Epoch: 5| Step: 9
Training loss: 2.818394899368286
Validation loss: 2.5444300174713135

Epoch: 5| Step: 10
Training loss: 2.203909158706665
Validation loss: 2.5361263034164265

Epoch: 32| Step: 0
Training loss: 2.821575403213501
Validation loss: 2.5360626712922127

Epoch: 5| Step: 1
Training loss: 2.612605094909668
Validation loss: 2.5433260061407603

Epoch: 5| Step: 2
Training loss: 2.873502731323242
Validation loss: 2.5382023703667427

Epoch: 5| Step: 3
Training loss: 2.645036458969116
Validation loss: 2.5316970168903308

Epoch: 5| Step: 4
Training loss: 2.594104766845703
Validation loss: 2.526341158856628

Epoch: 5| Step: 5
Training loss: 2.408691883087158
Validation loss: 2.5322439491107898

Epoch: 5| Step: 6
Training loss: 2.4192099571228027
Validation loss: 2.533974955158849

Epoch: 5| Step: 7
Training loss: 3.541273593902588
Validation loss: 2.545755465825399

Epoch: 5| Step: 8
Training loss: 2.545811891555786
Validation loss: 2.5967138082750383

Epoch: 5| Step: 9
Training loss: 3.0671889781951904
Validation loss: 2.6316232719729022

Epoch: 5| Step: 10
Training loss: 2.853226661682129
Validation loss: 2.6249267311506372

Epoch: 33| Step: 0
Training loss: 2.7408947944641113
Validation loss: 2.6098698672427925

Epoch: 5| Step: 1
Training loss: 3.2106614112854004
Validation loss: 2.609059561965286

Epoch: 5| Step: 2
Training loss: 2.0299251079559326
Validation loss: 2.6111867376553115

Epoch: 5| Step: 3
Training loss: 2.2686431407928467
Validation loss: 2.5995540772714922

Epoch: 5| Step: 4
Training loss: 3.2293190956115723
Validation loss: 2.593682999251991

Epoch: 5| Step: 5
Training loss: 3.4601428508758545
Validation loss: 2.592750895407892

Epoch: 5| Step: 6
Training loss: 2.9281320571899414
Validation loss: 2.5843164126078286

Epoch: 5| Step: 7
Training loss: 2.624713182449341
Validation loss: 2.593696645511094

Epoch: 5| Step: 8
Training loss: 2.2437045574188232
Validation loss: 2.597178730913388

Epoch: 5| Step: 9
Training loss: 2.670182704925537
Validation loss: 2.5953314509443057

Epoch: 5| Step: 10
Training loss: 3.2335622310638428
Validation loss: 2.591487084665606

Epoch: 34| Step: 0
Training loss: 3.4794106483459473
Validation loss: 2.586389790299118

Epoch: 5| Step: 1
Training loss: 2.9418282508850098
Validation loss: 2.5829544144292034

Epoch: 5| Step: 2
Training loss: 2.699796199798584
Validation loss: 2.583623114452567

Epoch: 5| Step: 3
Training loss: 2.298687696456909
Validation loss: 2.5872704854575534

Epoch: 5| Step: 4
Training loss: 3.120645046234131
Validation loss: 2.598880772949547

Epoch: 5| Step: 5
Training loss: 2.8415117263793945
Validation loss: 2.6096760637016705

Epoch: 5| Step: 6
Training loss: 2.700134038925171
Validation loss: 2.601145105977212

Epoch: 5| Step: 7
Training loss: 2.7088749408721924
Validation loss: 2.594493140456497

Epoch: 5| Step: 8
Training loss: 2.2317676544189453
Validation loss: 2.5936908106650076

Epoch: 5| Step: 9
Training loss: 2.837132453918457
Validation loss: 2.5904593595894436

Epoch: 5| Step: 10
Training loss: 2.5063090324401855
Validation loss: 2.5792948251129477

Epoch: 35| Step: 0
Training loss: 2.7645809650421143
Validation loss: 2.5747937899763866

Epoch: 5| Step: 1
Training loss: 2.4297373294830322
Validation loss: 2.5732264954556703

Epoch: 5| Step: 2
Training loss: 3.038451671600342
Validation loss: 2.572890450877528

Epoch: 5| Step: 3
Training loss: 2.4894919395446777
Validation loss: 2.5731884689741236

Epoch: 5| Step: 4
Training loss: 2.910839796066284
Validation loss: 2.5657202377114245

Epoch: 5| Step: 5
Training loss: 3.160339117050171
Validation loss: 2.5583515397963987

Epoch: 5| Step: 6
Training loss: 2.5978121757507324
Validation loss: 2.5560539307132846

Epoch: 5| Step: 7
Training loss: 2.7404041290283203
Validation loss: 2.537324772086195

Epoch: 5| Step: 8
Training loss: 2.223609447479248
Validation loss: 2.53025141069966

Epoch: 5| Step: 9
Training loss: 3.2463531494140625
Validation loss: 2.5169845550291

Epoch: 5| Step: 10
Training loss: 2.6266415119171143
Validation loss: 2.5167510022399244

Epoch: 36| Step: 0
Training loss: 2.8916640281677246
Validation loss: 2.5209395142011743

Epoch: 5| Step: 1
Training loss: 3.0625014305114746
Validation loss: 2.5220251544829337

Epoch: 5| Step: 2
Training loss: 2.4951069355010986
Validation loss: 2.5009210391711165

Epoch: 5| Step: 3
Training loss: 2.1828713417053223
Validation loss: 2.5107329583937124

Epoch: 5| Step: 4
Training loss: 2.6523454189300537
Validation loss: 2.504299920092347

Epoch: 5| Step: 5
Training loss: 2.5835185050964355
Validation loss: 2.495164135450958

Epoch: 5| Step: 6
Training loss: 3.1215732097625732
Validation loss: 2.4921577540777062

Epoch: 5| Step: 7
Training loss: 2.4615230560302734
Validation loss: 2.489989826756139

Epoch: 5| Step: 8
Training loss: 3.577737331390381
Validation loss: 2.4937332471211753

Epoch: 5| Step: 9
Training loss: 2.465294361114502
Validation loss: 2.4942566220478346

Epoch: 5| Step: 10
Training loss: 2.3331458568573
Validation loss: 2.4934434172927693

Epoch: 37| Step: 0
Training loss: 2.270202875137329
Validation loss: 2.4983204462194957

Epoch: 5| Step: 1
Training loss: 3.0281872749328613
Validation loss: 2.5133828988639255

Epoch: 5| Step: 2
Training loss: 2.4572668075561523
Validation loss: 2.551635721678375

Epoch: 5| Step: 3
Training loss: 2.620950698852539
Validation loss: 2.5580690317256476

Epoch: 5| Step: 4
Training loss: 2.9239823818206787
Validation loss: 2.554072049356276

Epoch: 5| Step: 5
Training loss: 2.5525593757629395
Validation loss: 2.5750965738809235

Epoch: 5| Step: 6
Training loss: 2.912428140640259
Validation loss: 2.5261376186083724

Epoch: 5| Step: 7
Training loss: 2.889766216278076
Validation loss: 2.4900501774203394

Epoch: 5| Step: 8
Training loss: 2.3945858478546143
Validation loss: 2.498859595226985

Epoch: 5| Step: 9
Training loss: 3.3000385761260986
Validation loss: 2.5189030016622236

Epoch: 5| Step: 10
Training loss: 2.453162431716919
Validation loss: 2.537882685661316

Epoch: 38| Step: 0
Training loss: 2.409604787826538
Validation loss: 2.581402512006862

Epoch: 5| Step: 1
Training loss: 2.7749080657958984
Validation loss: 2.6188039805299494

Epoch: 5| Step: 2
Training loss: 3.0088870525360107
Validation loss: 2.571464205300936

Epoch: 5| Step: 3
Training loss: 2.977536916732788
Validation loss: 2.5342780595184653

Epoch: 5| Step: 4
Training loss: 2.1999542713165283
Validation loss: 2.5113868277559996

Epoch: 5| Step: 5
Training loss: 2.441478967666626
Validation loss: 2.51092860006517

Epoch: 5| Step: 6
Training loss: 2.8629579544067383
Validation loss: 2.5426128679706204

Epoch: 5| Step: 7
Training loss: 2.373462677001953
Validation loss: 2.5548297448824813

Epoch: 5| Step: 8
Training loss: 3.0538249015808105
Validation loss: 2.564759385201239

Epoch: 5| Step: 9
Training loss: 2.644178867340088
Validation loss: 2.5922911090235554

Epoch: 5| Step: 10
Training loss: 3.5653674602508545
Validation loss: 2.5415548380985054

Epoch: 39| Step: 0
Training loss: 2.938629150390625
Validation loss: 2.4902632172389696

Epoch: 5| Step: 1
Training loss: 2.7084219455718994
Validation loss: 2.485340649081815

Epoch: 5| Step: 2
Training loss: 2.6404826641082764
Validation loss: 2.490753976247644

Epoch: 5| Step: 3
Training loss: 2.6106057167053223
Validation loss: 2.4946430267826205

Epoch: 5| Step: 4
Training loss: 3.0413317680358887
Validation loss: 2.4982228407295803

Epoch: 5| Step: 5
Training loss: 2.1896042823791504
Validation loss: 2.494820894733552

Epoch: 5| Step: 6
Training loss: 2.7381844520568848
Validation loss: 2.4961155563272457

Epoch: 5| Step: 7
Training loss: 2.4231925010681152
Validation loss: 2.487577910064369

Epoch: 5| Step: 8
Training loss: 3.040799617767334
Validation loss: 2.4873999370041715

Epoch: 5| Step: 9
Training loss: 2.711601972579956
Validation loss: 2.4780340784339496

Epoch: 5| Step: 10
Training loss: 2.8074443340301514
Validation loss: 2.4871086253914783

Epoch: 40| Step: 0
Training loss: 2.8627820014953613
Validation loss: 2.5021053796173423

Epoch: 5| Step: 1
Training loss: 2.3924803733825684
Validation loss: 2.5164147884615007

Epoch: 5| Step: 2
Training loss: 2.5296950340270996
Validation loss: 2.526083489899994

Epoch: 5| Step: 3
Training loss: 2.7075657844543457
Validation loss: 2.49213662967887

Epoch: 5| Step: 4
Training loss: 2.415821075439453
Validation loss: 2.4722972941654984

Epoch: 5| Step: 5
Training loss: 3.0650722980499268
Validation loss: 2.4692555730060866

Epoch: 5| Step: 6
Training loss: 2.342388153076172
Validation loss: 2.461422489535424

Epoch: 5| Step: 7
Training loss: 2.8047828674316406
Validation loss: 2.4711158608877533

Epoch: 5| Step: 8
Training loss: 2.5234692096710205
Validation loss: 2.471118378382857

Epoch: 5| Step: 9
Training loss: 3.328451156616211
Validation loss: 2.4750884040709464

Epoch: 5| Step: 10
Training loss: 2.6612064838409424
Validation loss: 2.474017212467809

Epoch: 41| Step: 0
Training loss: 2.458244800567627
Validation loss: 2.474463774311927

Epoch: 5| Step: 1
Training loss: 2.5676522254943848
Validation loss: 2.4789443810780845

Epoch: 5| Step: 2
Training loss: 2.607267379760742
Validation loss: 2.4784990843906196

Epoch: 5| Step: 3
Training loss: 2.670492649078369
Validation loss: 2.493153441336847

Epoch: 5| Step: 4
Training loss: 3.139841318130493
Validation loss: 2.4877715469688497

Epoch: 5| Step: 5
Training loss: 3.0677990913391113
Validation loss: 2.479357998858216

Epoch: 5| Step: 6
Training loss: 2.518465757369995
Validation loss: 2.476952357958722

Epoch: 5| Step: 7
Training loss: 2.6154308319091797
Validation loss: 2.4637903295537478

Epoch: 5| Step: 8
Training loss: 2.4955031871795654
Validation loss: 2.460426776639877

Epoch: 5| Step: 9
Training loss: 3.005591869354248
Validation loss: 2.46041876269925

Epoch: 5| Step: 10
Training loss: 2.5229454040527344
Validation loss: 2.4597059193477837

Epoch: 42| Step: 0
Training loss: 2.5529274940490723
Validation loss: 2.4550209840138755

Epoch: 5| Step: 1
Training loss: 2.09022855758667
Validation loss: 2.453886596105432

Epoch: 5| Step: 2
Training loss: 3.1444106101989746
Validation loss: 2.4622533846926946

Epoch: 5| Step: 3
Training loss: 3.1125457286834717
Validation loss: 2.4766801787960913

Epoch: 5| Step: 4
Training loss: 2.874382495880127
Validation loss: 2.4868677764810543

Epoch: 5| Step: 5
Training loss: 2.6882922649383545
Validation loss: 2.515180303204444

Epoch: 5| Step: 6
Training loss: 2.687152147293091
Validation loss: 2.489372040635796

Epoch: 5| Step: 7
Training loss: 2.207078456878662
Validation loss: 2.460701286151845

Epoch: 5| Step: 8
Training loss: 2.9141924381256104
Validation loss: 2.4522379726491947

Epoch: 5| Step: 9
Training loss: 3.0831806659698486
Validation loss: 2.4473288520689933

Epoch: 5| Step: 10
Training loss: 2.2374048233032227
Validation loss: 2.444374410055017

Epoch: 43| Step: 0
Training loss: 2.901621103286743
Validation loss: 2.448255081330576

Epoch: 5| Step: 1
Training loss: 2.0715854167938232
Validation loss: 2.449732765074699

Epoch: 5| Step: 2
Training loss: 2.2895984649658203
Validation loss: 2.4459672358728226

Epoch: 5| Step: 3
Training loss: 3.364551544189453
Validation loss: 2.445050298526723

Epoch: 5| Step: 4
Training loss: 2.7240519523620605
Validation loss: 2.445062909075009

Epoch: 5| Step: 5
Training loss: 2.9441397190093994
Validation loss: 2.4456525361666115

Epoch: 5| Step: 6
Training loss: 2.8610355854034424
Validation loss: 2.4543445033411824

Epoch: 5| Step: 7
Training loss: 2.8456356525421143
Validation loss: 2.473368590877902

Epoch: 5| Step: 8
Training loss: 1.8925673961639404
Validation loss: 2.4961555734757455

Epoch: 5| Step: 9
Training loss: 2.814379930496216
Validation loss: 2.5075440047889628

Epoch: 5| Step: 10
Training loss: 2.76735782623291
Validation loss: 2.488196711386404

Epoch: 44| Step: 0
Training loss: 2.5382747650146484
Validation loss: 2.474387263738981

Epoch: 5| Step: 1
Training loss: 2.9710495471954346
Validation loss: 2.469779796497796

Epoch: 5| Step: 2
Training loss: 2.830944061279297
Validation loss: 2.471248495963312

Epoch: 5| Step: 3
Training loss: 2.386888265609741
Validation loss: 2.462614861867761

Epoch: 5| Step: 4
Training loss: 2.5794425010681152
Validation loss: 2.455751968968299

Epoch: 5| Step: 5
Training loss: 2.441164970397949
Validation loss: 2.452334806483279

Epoch: 5| Step: 6
Training loss: 2.1810264587402344
Validation loss: 2.448584077178791

Epoch: 5| Step: 7
Training loss: 2.310866117477417
Validation loss: 2.4475585363244496

Epoch: 5| Step: 8
Training loss: 3.1239781379699707
Validation loss: 2.449371871127877

Epoch: 5| Step: 9
Training loss: 3.3052220344543457
Validation loss: 2.4497897522423857

Epoch: 5| Step: 10
Training loss: 2.826082229614258
Validation loss: 2.4565376389411187

Epoch: 45| Step: 0
Training loss: 2.634030342102051
Validation loss: 2.4524809416904243

Epoch: 5| Step: 1
Training loss: 3.3132827281951904
Validation loss: 2.459963817750254

Epoch: 5| Step: 2
Training loss: 2.5729756355285645
Validation loss: 2.4551320332352833

Epoch: 5| Step: 3
Training loss: 2.539715528488159
Validation loss: 2.440225475577898

Epoch: 5| Step: 4
Training loss: 2.2884469032287598
Validation loss: 2.4420761985163533

Epoch: 5| Step: 5
Training loss: 2.4306857585906982
Validation loss: 2.4416136741638184

Epoch: 5| Step: 6
Training loss: 3.405062198638916
Validation loss: 2.434411477017146

Epoch: 5| Step: 7
Training loss: 2.7868285179138184
Validation loss: 2.431061867744692

Epoch: 5| Step: 8
Training loss: 2.442798137664795
Validation loss: 2.435235100407754

Epoch: 5| Step: 9
Training loss: 1.996778130531311
Validation loss: 2.4266022546316988

Epoch: 5| Step: 10
Training loss: 3.000743865966797
Validation loss: 2.4328837804896857

Epoch: 46| Step: 0
Training loss: 2.2772819995880127
Validation loss: 2.4315376179192656

Epoch: 5| Step: 1
Training loss: 2.2150542736053467
Validation loss: 2.43532867329095

Epoch: 5| Step: 2
Training loss: 3.0678718090057373
Validation loss: 2.431702483084894

Epoch: 5| Step: 3
Training loss: 2.750192880630493
Validation loss: 2.42870617681934

Epoch: 5| Step: 4
Training loss: 2.965320587158203
Validation loss: 2.430832060434485

Epoch: 5| Step: 5
Training loss: 2.4830422401428223
Validation loss: 2.433165324631558

Epoch: 5| Step: 6
Training loss: 2.332761526107788
Validation loss: 2.4472877415277625

Epoch: 5| Step: 7
Training loss: 2.572678804397583
Validation loss: 2.4748444967372443

Epoch: 5| Step: 8
Training loss: 2.908514976501465
Validation loss: 2.503864954876643

Epoch: 5| Step: 9
Training loss: 3.2320549488067627
Validation loss: 2.5226339883701776

Epoch: 5| Step: 10
Training loss: 2.424248695373535
Validation loss: 2.5256716359046196

Epoch: 47| Step: 0
Training loss: 2.935666561126709
Validation loss: 2.4980353027261715

Epoch: 5| Step: 1
Training loss: 2.431715488433838
Validation loss: 2.456044207337082

Epoch: 5| Step: 2
Training loss: 3.4689605236053467
Validation loss: 2.438415155615858

Epoch: 5| Step: 3
Training loss: 2.94993257522583
Validation loss: 2.4358909924825034

Epoch: 5| Step: 4
Training loss: 2.5779614448547363
Validation loss: 2.4329042050146286

Epoch: 5| Step: 5
Training loss: 2.5640079975128174
Validation loss: 2.423976023991903

Epoch: 5| Step: 6
Training loss: 3.2205567359924316
Validation loss: 2.42106895549323

Epoch: 5| Step: 7
Training loss: 2.3111846446990967
Validation loss: 2.429254280623569

Epoch: 5| Step: 8
Training loss: 1.7103118896484375
Validation loss: 2.4311851506592124

Epoch: 5| Step: 9
Training loss: 2.8675122261047363
Validation loss: 2.448369997803883

Epoch: 5| Step: 10
Training loss: 2.2668039798736572
Validation loss: 2.4552139774445565

Epoch: 48| Step: 0
Training loss: 2.7100822925567627
Validation loss: 2.476092858981061

Epoch: 5| Step: 1
Training loss: 3.036909580230713
Validation loss: 2.480927816001318

Epoch: 5| Step: 2
Training loss: 2.6993536949157715
Validation loss: 2.4340736865997314

Epoch: 5| Step: 3
Training loss: 3.154811143875122
Validation loss: 2.424004227884354

Epoch: 5| Step: 4
Training loss: 2.0035157203674316
Validation loss: 2.4178008392292965

Epoch: 5| Step: 5
Training loss: 2.6011862754821777
Validation loss: 2.4186469995847313

Epoch: 5| Step: 6
Training loss: 2.358818531036377
Validation loss: 2.4142829756582938

Epoch: 5| Step: 7
Training loss: 2.508945941925049
Validation loss: 2.4236969819632908

Epoch: 5| Step: 8
Training loss: 2.9449782371520996
Validation loss: 2.431086794022591

Epoch: 5| Step: 9
Training loss: 2.4410171508789062
Validation loss: 2.43669621662427

Epoch: 5| Step: 10
Training loss: 2.9158387184143066
Validation loss: 2.4520522855943248

Epoch: 49| Step: 0
Training loss: 2.900376796722412
Validation loss: 2.4931874147025486

Epoch: 5| Step: 1
Training loss: 2.7553908824920654
Validation loss: 2.4776110085107947

Epoch: 5| Step: 2
Training loss: 2.3877670764923096
Validation loss: 2.4264817853127756

Epoch: 5| Step: 3
Training loss: 2.4025485515594482
Validation loss: 2.4145593848279727

Epoch: 5| Step: 4
Training loss: 3.094571590423584
Validation loss: 2.4112990325497043

Epoch: 5| Step: 5
Training loss: 2.8362576961517334
Validation loss: 2.409085689052459

Epoch: 5| Step: 6
Training loss: 3.083662986755371
Validation loss: 2.4065985115625526

Epoch: 5| Step: 7
Training loss: 2.1816840171813965
Validation loss: 2.404557906171327

Epoch: 5| Step: 8
Training loss: 2.9497148990631104
Validation loss: 2.4045629629524807

Epoch: 5| Step: 9
Training loss: 2.1749634742736816
Validation loss: 2.406816631235102

Epoch: 5| Step: 10
Training loss: 2.440061092376709
Validation loss: 2.406011648075555

Epoch: 50| Step: 0
Training loss: 3.050243616104126
Validation loss: 2.40133233480556

Epoch: 5| Step: 1
Training loss: 2.6587986946105957
Validation loss: 2.4044987078635924

Epoch: 5| Step: 2
Training loss: 2.562192916870117
Validation loss: 2.4174732649198143

Epoch: 5| Step: 3
Training loss: 3.0857930183410645
Validation loss: 2.4265058553347023

Epoch: 5| Step: 4
Training loss: 2.674229860305786
Validation loss: 2.428172520411912

Epoch: 5| Step: 5
Training loss: 2.457124710083008
Validation loss: 2.439216467642015

Epoch: 5| Step: 6
Training loss: 2.600632905960083
Validation loss: 2.4414977309524373

Epoch: 5| Step: 7
Training loss: 2.1278767585754395
Validation loss: 2.447763168683616

Epoch: 5| Step: 8
Training loss: 2.1920928955078125
Validation loss: 2.4216809029220254

Epoch: 5| Step: 9
Training loss: 3.0694327354431152
Validation loss: 2.413343842311572

Epoch: 5| Step: 10
Training loss: 2.8622384071350098
Validation loss: 2.4032285367288897

Epoch: 51| Step: 0
Training loss: 2.1800708770751953
Validation loss: 2.3993283164116646

Epoch: 5| Step: 1
Training loss: 2.7219557762145996
Validation loss: 2.397746188666231

Epoch: 5| Step: 2
Training loss: 2.321824550628662
Validation loss: 2.3958231479890886

Epoch: 5| Step: 3
Training loss: 2.6141116619110107
Validation loss: 2.4022298013010333

Epoch: 5| Step: 4
Training loss: 2.30643367767334
Validation loss: 2.4026158650716147

Epoch: 5| Step: 5
Training loss: 2.225076675415039
Validation loss: 2.400677099022814

Epoch: 5| Step: 6
Training loss: 3.6983895301818848
Validation loss: 2.3975223661750875

Epoch: 5| Step: 7
Training loss: 3.0723366737365723
Validation loss: 2.400951885407971

Epoch: 5| Step: 8
Training loss: 2.873105049133301
Validation loss: 2.4136511023326586

Epoch: 5| Step: 9
Training loss: 2.695568799972534
Validation loss: 2.4242719475940993

Epoch: 5| Step: 10
Training loss: 2.463303327560425
Validation loss: 2.4344348112742105

Epoch: 52| Step: 0
Training loss: 2.643458843231201
Validation loss: 2.481795841647733

Epoch: 5| Step: 1
Training loss: 2.40745210647583
Validation loss: 2.507392269308849

Epoch: 5| Step: 2
Training loss: 3.1681618690490723
Validation loss: 2.5103787017124954

Epoch: 5| Step: 3
Training loss: 2.7773239612579346
Validation loss: 2.47396094055586

Epoch: 5| Step: 4
Training loss: 2.5438685417175293
Validation loss: 2.44592612020431

Epoch: 5| Step: 5
Training loss: 2.7401487827301025
Validation loss: 2.4132587473879576

Epoch: 5| Step: 6
Training loss: 2.425553798675537
Validation loss: 2.398927104088568

Epoch: 5| Step: 7
Training loss: 2.5239548683166504
Validation loss: 2.3923436723729616

Epoch: 5| Step: 8
Training loss: 2.099616527557373
Validation loss: 2.389226726306382

Epoch: 5| Step: 9
Training loss: 2.9099514484405518
Validation loss: 2.3933799036087526

Epoch: 5| Step: 10
Training loss: 3.0651917457580566
Validation loss: 2.396756761817522

Epoch: 53| Step: 0
Training loss: 2.7346460819244385
Validation loss: 2.3987990502388246

Epoch: 5| Step: 1
Training loss: 2.682799816131592
Validation loss: 2.4126268689350416

Epoch: 5| Step: 2
Training loss: 2.7807788848876953
Validation loss: 2.4571786362637758

Epoch: 5| Step: 3
Training loss: 3.588074207305908
Validation loss: 2.5123466676281345

Epoch: 5| Step: 4
Training loss: 2.4802236557006836
Validation loss: 2.5243189104141726

Epoch: 5| Step: 5
Training loss: 2.7853641510009766
Validation loss: 2.5270365745790544

Epoch: 5| Step: 6
Training loss: 1.5668175220489502
Validation loss: 2.5317238940987536

Epoch: 5| Step: 7
Training loss: 2.457663059234619
Validation loss: 2.5382519332311486

Epoch: 5| Step: 8
Training loss: 3.081759214401245
Validation loss: 2.5128486438464095

Epoch: 5| Step: 9
Training loss: 2.8286967277526855
Validation loss: 2.4913644380466913

Epoch: 5| Step: 10
Training loss: 2.638017416000366
Validation loss: 2.47948395821356

Epoch: 54| Step: 0
Training loss: 2.403017044067383
Validation loss: 2.461594976404662

Epoch: 5| Step: 1
Training loss: 2.556095600128174
Validation loss: 2.4601849791824177

Epoch: 5| Step: 2
Training loss: 3.360051393508911
Validation loss: 2.4657533937884915

Epoch: 5| Step: 3
Training loss: 2.341508150100708
Validation loss: 2.466253213984992

Epoch: 5| Step: 4
Training loss: 2.7680771350860596
Validation loss: 2.459557928064818

Epoch: 5| Step: 5
Training loss: 2.5552210807800293
Validation loss: 2.402652414896155

Epoch: 5| Step: 6
Training loss: 2.638634204864502
Validation loss: 2.3846451338901313

Epoch: 5| Step: 7
Training loss: 2.3806328773498535
Validation loss: 2.382215174295569

Epoch: 5| Step: 8
Training loss: 2.601497173309326
Validation loss: 2.382754538648872

Epoch: 5| Step: 9
Training loss: 3.0411603450775146
Validation loss: 2.412364431606826

Epoch: 5| Step: 10
Training loss: 2.4267594814300537
Validation loss: 2.496983569155457

Epoch: 55| Step: 0
Training loss: 2.6825013160705566
Validation loss: 2.5810250800143004

Epoch: 5| Step: 1
Training loss: 2.8219199180603027
Validation loss: 2.596479974767213

Epoch: 5| Step: 2
Training loss: 2.662158966064453
Validation loss: 2.5786272812915105

Epoch: 5| Step: 3
Training loss: 3.159619092941284
Validation loss: 2.5356384861853813

Epoch: 5| Step: 4
Training loss: 2.410490036010742
Validation loss: 2.4865787772722143

Epoch: 5| Step: 5
Training loss: 2.277799129486084
Validation loss: 2.4089425276684504

Epoch: 5| Step: 6
Training loss: 2.7970261573791504
Validation loss: 2.3810746849224134

Epoch: 5| Step: 7
Training loss: 2.866248369216919
Validation loss: 2.3807225970811743

Epoch: 5| Step: 8
Training loss: 2.1882567405700684
Validation loss: 2.3808809018904165

Epoch: 5| Step: 9
Training loss: 2.897247791290283
Validation loss: 2.3757318399285756

Epoch: 5| Step: 10
Training loss: 2.824366331100464
Validation loss: 2.376508871714274

Epoch: 56| Step: 0
Training loss: 2.457937479019165
Validation loss: 2.377531377218103

Epoch: 5| Step: 1
Training loss: 2.2909722328186035
Validation loss: 2.3760379258022515

Epoch: 5| Step: 2
Training loss: 2.9538490772247314
Validation loss: 2.3757504365777455

Epoch: 5| Step: 3
Training loss: 2.657680034637451
Validation loss: 2.376303388226417

Epoch: 5| Step: 4
Training loss: 2.2353572845458984
Validation loss: 2.3770974938587477

Epoch: 5| Step: 5
Training loss: 2.7685189247131348
Validation loss: 2.384394548272574

Epoch: 5| Step: 6
Training loss: 3.2151520252227783
Validation loss: 2.4013446223351265

Epoch: 5| Step: 7
Training loss: 3.170456647872925
Validation loss: 2.403985518281178

Epoch: 5| Step: 8
Training loss: 2.5948398113250732
Validation loss: 2.4113559774173203

Epoch: 5| Step: 9
Training loss: 2.212160587310791
Validation loss: 2.404765272653231

Epoch: 5| Step: 10
Training loss: 2.4750607013702393
Validation loss: 2.3907093514678297

Epoch: 57| Step: 0
Training loss: 2.5289509296417236
Validation loss: 2.3794665080244823

Epoch: 5| Step: 1
Training loss: 2.161069393157959
Validation loss: 2.372954225027433

Epoch: 5| Step: 2
Training loss: 2.1813275814056396
Validation loss: 2.3713491347528275

Epoch: 5| Step: 3
Training loss: 2.5697097778320312
Validation loss: 2.385686925662461

Epoch: 5| Step: 4
Training loss: 2.9691600799560547
Validation loss: 2.3898133436838784

Epoch: 5| Step: 5
Training loss: 3.729830503463745
Validation loss: 2.4037768686971357

Epoch: 5| Step: 6
Training loss: 1.9345859289169312
Validation loss: 2.3895801472407516

Epoch: 5| Step: 7
Training loss: 2.5792396068573
Validation loss: 2.390861508666828

Epoch: 5| Step: 8
Training loss: 2.7798843383789062
Validation loss: 2.4016459731645483

Epoch: 5| Step: 9
Training loss: 2.424339532852173
Validation loss: 2.3866342036954817

Epoch: 5| Step: 10
Training loss: 3.1941356658935547
Validation loss: 2.3612300042183167

Epoch: 58| Step: 0
Training loss: 2.3395471572875977
Validation loss: 2.3652178574633855

Epoch: 5| Step: 1
Training loss: 2.871023654937744
Validation loss: 2.3699248939432125

Epoch: 5| Step: 2
Training loss: 2.7251410484313965
Validation loss: 2.3791129691626436

Epoch: 5| Step: 3
Training loss: 2.1893067359924316
Validation loss: 2.3784877074662076

Epoch: 5| Step: 4
Training loss: 3.272404432296753
Validation loss: 2.3714277590474775

Epoch: 5| Step: 5
Training loss: 2.7238903045654297
Validation loss: 2.363458292458647

Epoch: 5| Step: 6
Training loss: 2.877263307571411
Validation loss: 2.3509061977427494

Epoch: 5| Step: 7
Training loss: 2.2006287574768066
Validation loss: 2.346951038606705

Epoch: 5| Step: 8
Training loss: 2.257009744644165
Validation loss: 2.3497306377657

Epoch: 5| Step: 9
Training loss: 2.405895233154297
Validation loss: 2.359063838117866

Epoch: 5| Step: 10
Training loss: 3.1936583518981934
Validation loss: 2.374390527766238

Epoch: 59| Step: 0
Training loss: 2.076531171798706
Validation loss: 2.398151628432735

Epoch: 5| Step: 1
Training loss: 2.524451494216919
Validation loss: 2.429586692522931

Epoch: 5| Step: 2
Training loss: 2.9553849697113037
Validation loss: 2.4047379852623068

Epoch: 5| Step: 3
Training loss: 3.1578240394592285
Validation loss: 2.387112720038301

Epoch: 5| Step: 4
Training loss: 2.9063847064971924
Validation loss: 2.3550279422472884

Epoch: 5| Step: 5
Training loss: 3.3212101459503174
Validation loss: 2.3468524845697547

Epoch: 5| Step: 6
Training loss: 2.1814475059509277
Validation loss: 2.340222740686068

Epoch: 5| Step: 7
Training loss: 2.5688693523406982
Validation loss: 2.342510938644409

Epoch: 5| Step: 8
Training loss: 2.5968689918518066
Validation loss: 2.345743130612117

Epoch: 5| Step: 9
Training loss: 2.1538829803466797
Validation loss: 2.347060044606527

Epoch: 5| Step: 10
Training loss: 2.430375576019287
Validation loss: 2.348490861154372

Epoch: 60| Step: 0
Training loss: 2.458077907562256
Validation loss: 2.3513646330884708

Epoch: 5| Step: 1
Training loss: 2.8379886150360107
Validation loss: 2.343405380043932

Epoch: 5| Step: 2
Training loss: 2.782604217529297
Validation loss: 2.346798937807801

Epoch: 5| Step: 3
Training loss: 3.052638530731201
Validation loss: 2.3465816820821455

Epoch: 5| Step: 4
Training loss: 2.662928342819214
Validation loss: 2.344123940314016

Epoch: 5| Step: 5
Training loss: 2.6141722202301025
Validation loss: 2.3449950218200684

Epoch: 5| Step: 6
Training loss: 1.8505775928497314
Validation loss: 2.348135568762338

Epoch: 5| Step: 7
Training loss: 2.7582640647888184
Validation loss: 2.3481223826767295

Epoch: 5| Step: 8
Training loss: 2.776003837585449
Validation loss: 2.364405773019278

Epoch: 5| Step: 9
Training loss: 3.2545437812805176
Validation loss: 2.377497410261503

Epoch: 5| Step: 10
Training loss: 1.6437008380889893
Validation loss: 2.3877138194217475

Epoch: 61| Step: 0
Training loss: 2.6525001525878906
Validation loss: 2.371437131717641

Epoch: 5| Step: 1
Training loss: 3.005748748779297
Validation loss: 2.3428774931097545

Epoch: 5| Step: 2
Training loss: 2.9731624126434326
Validation loss: 2.331417529813705

Epoch: 5| Step: 3
Training loss: 2.407348155975342
Validation loss: 2.3338009260034047

Epoch: 5| Step: 4
Training loss: 2.2180237770080566
Validation loss: 2.330207937507219

Epoch: 5| Step: 5
Training loss: 2.766993284225464
Validation loss: 2.3287942306969756

Epoch: 5| Step: 6
Training loss: 3.208387851715088
Validation loss: 2.3313737453952914

Epoch: 5| Step: 7
Training loss: 2.5771279335021973
Validation loss: 2.3312959055746756

Epoch: 5| Step: 8
Training loss: 2.9890530109405518
Validation loss: 2.330387205205938

Epoch: 5| Step: 9
Training loss: 1.9525429010391235
Validation loss: 2.3368976218726045

Epoch: 5| Step: 10
Training loss: 1.9387339353561401
Validation loss: 2.351261551662158

Epoch: 62| Step: 0
Training loss: 2.6784756183624268
Validation loss: 2.352391891582038

Epoch: 5| Step: 1
Training loss: 2.6246390342712402
Validation loss: 2.36190442885122

Epoch: 5| Step: 2
Training loss: 2.9318337440490723
Validation loss: 2.3766393353862147

Epoch: 5| Step: 3
Training loss: 1.9919170141220093
Validation loss: 2.3758902652289278

Epoch: 5| Step: 4
Training loss: 2.6970419883728027
Validation loss: 2.3573330140882924

Epoch: 5| Step: 5
Training loss: 2.340449810028076
Validation loss: 2.372744716623778

Epoch: 5| Step: 6
Training loss: 2.3349485397338867
Validation loss: 2.363828718021352

Epoch: 5| Step: 7
Training loss: 3.1136105060577393
Validation loss: 2.3663197666086178

Epoch: 5| Step: 8
Training loss: 2.824108839035034
Validation loss: 2.336400783190163

Epoch: 5| Step: 9
Training loss: 2.6919503211975098
Validation loss: 2.331985722305954

Epoch: 5| Step: 10
Training loss: 2.4536142349243164
Validation loss: 2.3262814655098865

Epoch: 63| Step: 0
Training loss: 2.743473768234253
Validation loss: 2.326447715041458

Epoch: 5| Step: 1
Training loss: 2.474424362182617
Validation loss: 2.333702938531035

Epoch: 5| Step: 2
Training loss: 2.3285880088806152
Validation loss: 2.332144119406259

Epoch: 5| Step: 3
Training loss: 2.7075111865997314
Validation loss: 2.3425481575791554

Epoch: 5| Step: 4
Training loss: 3.3085849285125732
Validation loss: 2.346156161318543

Epoch: 5| Step: 5
Training loss: 2.4132440090179443
Validation loss: 2.345513730920771

Epoch: 5| Step: 6
Training loss: 2.6364941596984863
Validation loss: 2.343697750440208

Epoch: 5| Step: 7
Training loss: 2.4890475273132324
Validation loss: 2.337354847179946

Epoch: 5| Step: 8
Training loss: 2.7702794075012207
Validation loss: 2.330982462052376

Epoch: 5| Step: 9
Training loss: 2.1044936180114746
Validation loss: 2.3351442352417977

Epoch: 5| Step: 10
Training loss: 2.69512677192688
Validation loss: 2.319817312302128

Epoch: 64| Step: 0
Training loss: 2.5070176124572754
Validation loss: 2.3185411140482914

Epoch: 5| Step: 1
Training loss: 2.7673287391662598
Validation loss: 2.3194838031645744

Epoch: 5| Step: 2
Training loss: 2.089186191558838
Validation loss: 2.315955679903748

Epoch: 5| Step: 3
Training loss: 2.091886043548584
Validation loss: 2.3188171566173597

Epoch: 5| Step: 4
Training loss: 2.501763105392456
Validation loss: 2.323002661428144

Epoch: 5| Step: 5
Training loss: 2.4077892303466797
Validation loss: 2.360699761298395

Epoch: 5| Step: 6
Training loss: 2.962359666824341
Validation loss: 2.384408131722481

Epoch: 5| Step: 7
Training loss: 3.216658115386963
Validation loss: 2.4037200763661373

Epoch: 5| Step: 8
Training loss: 2.130254030227661
Validation loss: 2.406538640299151

Epoch: 5| Step: 9
Training loss: 3.37347674369812
Validation loss: 2.4047547668539067

Epoch: 5| Step: 10
Training loss: 2.8210537433624268
Validation loss: 2.4114133337492585

Epoch: 65| Step: 0
Training loss: 2.8286871910095215
Validation loss: 2.3983934822902886

Epoch: 5| Step: 1
Training loss: 2.282597780227661
Validation loss: 2.383913283706993

Epoch: 5| Step: 2
Training loss: 2.193420886993408
Validation loss: 2.3702232683858564

Epoch: 5| Step: 3
Training loss: 2.8875768184661865
Validation loss: 2.3709772068967103

Epoch: 5| Step: 4
Training loss: 2.1930413246154785
Validation loss: 2.357286132791991

Epoch: 5| Step: 5
Training loss: 3.4787418842315674
Validation loss: 2.370319861237721

Epoch: 5| Step: 6
Training loss: 2.56418514251709
Validation loss: 2.378442797609555

Epoch: 5| Step: 7
Training loss: 2.080658197402954
Validation loss: 2.380801411085231

Epoch: 5| Step: 8
Training loss: 2.3973228931427
Validation loss: 2.3894491375133557

Epoch: 5| Step: 9
Training loss: 3.331608295440674
Validation loss: 2.376110715250815

Epoch: 5| Step: 10
Training loss: 2.622285842895508
Validation loss: 2.349284541222357

Epoch: 66| Step: 0
Training loss: 3.0474331378936768
Validation loss: 2.3426311695447533

Epoch: 5| Step: 1
Training loss: 2.425741195678711
Validation loss: 2.3251102278309483

Epoch: 5| Step: 2
Training loss: 2.222834825515747
Validation loss: 2.326133538317937

Epoch: 5| Step: 3
Training loss: 2.437997341156006
Validation loss: 2.3357232898794194

Epoch: 5| Step: 4
Training loss: 2.612948179244995
Validation loss: 2.336127455516528

Epoch: 5| Step: 5
Training loss: 2.971666097640991
Validation loss: 2.3348530082292456

Epoch: 5| Step: 6
Training loss: 2.9372189044952393
Validation loss: 2.337009458131688

Epoch: 5| Step: 7
Training loss: 2.862755060195923
Validation loss: 2.3311763040481077

Epoch: 5| Step: 8
Training loss: 2.729066848754883
Validation loss: 2.324328737874185

Epoch: 5| Step: 9
Training loss: 2.3861477375030518
Validation loss: 2.3228466946591615

Epoch: 5| Step: 10
Training loss: 2.189505100250244
Validation loss: 2.3118640633039576

Epoch: 67| Step: 0
Training loss: 2.3961100578308105
Validation loss: 2.308610931519539

Epoch: 5| Step: 1
Training loss: 2.330763339996338
Validation loss: 2.311867270418393

Epoch: 5| Step: 2
Training loss: 2.887267589569092
Validation loss: 2.338052062578099

Epoch: 5| Step: 3
Training loss: 2.641021728515625
Validation loss: 2.3758797273840955

Epoch: 5| Step: 4
Training loss: 2.5041255950927734
Validation loss: 2.390040495062387

Epoch: 5| Step: 5
Training loss: 2.321906566619873
Validation loss: 2.388225765638454

Epoch: 5| Step: 6
Training loss: 3.2563414573669434
Validation loss: 2.3866934981397403

Epoch: 5| Step: 7
Training loss: 2.6714377403259277
Validation loss: 2.352947986254128

Epoch: 5| Step: 8
Training loss: 2.4476218223571777
Validation loss: 2.3270357808759137

Epoch: 5| Step: 9
Training loss: 3.0639548301696777
Validation loss: 2.315947312180714

Epoch: 5| Step: 10
Training loss: 2.11772084236145
Validation loss: 2.299934576916438

Epoch: 68| Step: 0
Training loss: 2.5455288887023926
Validation loss: 2.294503376048098

Epoch: 5| Step: 1
Training loss: 2.680464744567871
Validation loss: 2.296710446316709

Epoch: 5| Step: 2
Training loss: 2.5293071269989014
Validation loss: 2.305309610982095

Epoch: 5| Step: 3
Training loss: 3.0153138637542725
Validation loss: 2.3157862668396323

Epoch: 5| Step: 4
Training loss: 2.8043103218078613
Validation loss: 2.3169611551428355

Epoch: 5| Step: 5
Training loss: 2.716951847076416
Validation loss: 2.31918429815641

Epoch: 5| Step: 6
Training loss: 2.3653669357299805
Validation loss: 2.31724779323865

Epoch: 5| Step: 7
Training loss: 1.8522008657455444
Validation loss: 2.311018720749886

Epoch: 5| Step: 8
Training loss: 2.688443660736084
Validation loss: 2.297501266643565

Epoch: 5| Step: 9
Training loss: 2.6330249309539795
Validation loss: 2.2850238225793325

Epoch: 5| Step: 10
Training loss: 3.027567148208618
Validation loss: 2.2895211019823627

Epoch: 69| Step: 0
Training loss: 2.44045352935791
Validation loss: 2.3128455556848997

Epoch: 5| Step: 1
Training loss: 2.8008077144622803
Validation loss: 2.3375348480798865

Epoch: 5| Step: 2
Training loss: 3.2587904930114746
Validation loss: 2.321608894614763

Epoch: 5| Step: 3
Training loss: 2.8106536865234375
Validation loss: 2.3175869321310394

Epoch: 5| Step: 4
Training loss: 3.075584888458252
Validation loss: 2.2960249121471117

Epoch: 5| Step: 5
Training loss: 2.368734836578369
Validation loss: 2.295758387093903

Epoch: 5| Step: 6
Training loss: 2.4780423641204834
Validation loss: 2.2869738609560075

Epoch: 5| Step: 7
Training loss: 2.766758441925049
Validation loss: 2.2831740558788343

Epoch: 5| Step: 8
Training loss: 1.92246413230896
Validation loss: 2.282806137556671

Epoch: 5| Step: 9
Training loss: 1.8258793354034424
Validation loss: 2.2814011189245407

Epoch: 5| Step: 10
Training loss: 2.7097396850585938
Validation loss: 2.278781698596093

Epoch: 70| Step: 0
Training loss: 2.1612210273742676
Validation loss: 2.283733155137749

Epoch: 5| Step: 1
Training loss: 2.941014051437378
Validation loss: 2.2871883351315736

Epoch: 5| Step: 2
Training loss: 2.5524849891662598
Validation loss: 2.294598123078705

Epoch: 5| Step: 3
Training loss: 2.593095302581787
Validation loss: 2.3039528375030844

Epoch: 5| Step: 4
Training loss: 2.7161712646484375
Validation loss: 2.300847548310475

Epoch: 5| Step: 5
Training loss: 3.0162625312805176
Validation loss: 2.312042764438096

Epoch: 5| Step: 6
Training loss: 2.3587093353271484
Validation loss: 2.304313508413171

Epoch: 5| Step: 7
Training loss: 2.531043529510498
Validation loss: 2.306250943932482

Epoch: 5| Step: 8
Training loss: 1.9496285915374756
Validation loss: 2.292486757360479

Epoch: 5| Step: 9
Training loss: 2.864471435546875
Validation loss: 2.3067498360910723

Epoch: 5| Step: 10
Training loss: 2.8647825717926025
Validation loss: 2.326544696284879

Epoch: 71| Step: 0
Training loss: 2.2980170249938965
Validation loss: 2.3306775349442677

Epoch: 5| Step: 1
Training loss: 1.9531587362289429
Validation loss: 2.3453793782059864

Epoch: 5| Step: 2
Training loss: 2.85982084274292
Validation loss: 2.3562573220140193

Epoch: 5| Step: 3
Training loss: 2.7345786094665527
Validation loss: 2.3969758992554038

Epoch: 5| Step: 4
Training loss: 2.6967005729675293
Validation loss: 2.465622837825488

Epoch: 5| Step: 5
Training loss: 2.3497114181518555
Validation loss: 2.426100992387341

Epoch: 5| Step: 6
Training loss: 2.7308220863342285
Validation loss: 2.3611036756987214

Epoch: 5| Step: 7
Training loss: 2.8725473880767822
Validation loss: 2.334733445157287

Epoch: 5| Step: 8
Training loss: 2.195905923843384
Validation loss: 2.314647869397235

Epoch: 5| Step: 9
Training loss: 3.09318208694458
Validation loss: 2.307045787893316

Epoch: 5| Step: 10
Training loss: 2.960383176803589
Validation loss: 2.307570906095607

Epoch: 72| Step: 0
Training loss: 2.6645100116729736
Validation loss: 2.2995110801471177

Epoch: 5| Step: 1
Training loss: 2.0242552757263184
Validation loss: 2.2993227897151822

Epoch: 5| Step: 2
Training loss: 2.7715067863464355
Validation loss: 2.298176642387144

Epoch: 5| Step: 3
Training loss: 2.6775972843170166
Validation loss: 2.319141516121485

Epoch: 5| Step: 4
Training loss: 3.272524356842041
Validation loss: 2.323445189383722

Epoch: 5| Step: 5
Training loss: 2.179574489593506
Validation loss: 2.3060806361577844

Epoch: 5| Step: 6
Training loss: 3.323453903198242
Validation loss: 2.2947766832126084

Epoch: 5| Step: 7
Training loss: 2.12890362739563
Validation loss: 2.292603245345495

Epoch: 5| Step: 8
Training loss: 2.662289619445801
Validation loss: 2.2919358668788785

Epoch: 5| Step: 9
Training loss: 2.1540424823760986
Validation loss: 2.2872813683684154

Epoch: 5| Step: 10
Training loss: 2.6359329223632812
Validation loss: 2.2907716510116414

Epoch: 73| Step: 0
Training loss: 2.6277363300323486
Validation loss: 2.290988752918859

Epoch: 5| Step: 1
Training loss: 2.029139995574951
Validation loss: 2.2990479264208066

Epoch: 5| Step: 2
Training loss: 2.2590856552124023
Validation loss: 2.3045325868873188

Epoch: 5| Step: 3
Training loss: 2.461071014404297
Validation loss: 2.3102506514518493

Epoch: 5| Step: 4
Training loss: 2.85608172416687
Validation loss: 2.3203225058894

Epoch: 5| Step: 5
Training loss: 2.6282382011413574
Validation loss: 2.308866649545649

Epoch: 5| Step: 6
Training loss: 2.283564329147339
Validation loss: 2.2956414017626035

Epoch: 5| Step: 7
Training loss: 2.4055404663085938
Validation loss: 2.2790454741447204

Epoch: 5| Step: 8
Training loss: 2.8376452922821045
Validation loss: 2.272631763130106

Epoch: 5| Step: 9
Training loss: 2.8852405548095703
Validation loss: 2.2817883696607364

Epoch: 5| Step: 10
Training loss: 3.011679172515869
Validation loss: 2.298072532940936

Epoch: 74| Step: 0
Training loss: 2.7818942070007324
Validation loss: 2.3020707561123754

Epoch: 5| Step: 1
Training loss: 3.0387651920318604
Validation loss: 2.3291225253894763

Epoch: 5| Step: 2
Training loss: 2.3911383152008057
Validation loss: 2.268052395953927

Epoch: 5| Step: 3
Training loss: 2.1731553077697754
Validation loss: 2.2701376868832495

Epoch: 5| Step: 4
Training loss: 3.0363609790802
Validation loss: 2.28541547765014

Epoch: 5| Step: 5
Training loss: 3.1966500282287598
Validation loss: 2.308930886689053

Epoch: 5| Step: 6
Training loss: 2.1330621242523193
Validation loss: 2.314868334800966

Epoch: 5| Step: 7
Training loss: 2.723172664642334
Validation loss: 2.2620525847199144

Epoch: 5| Step: 8
Training loss: 2.4374213218688965
Validation loss: 2.2660282811810895

Epoch: 5| Step: 9
Training loss: 2.191788911819458
Validation loss: 2.263130300788469

Epoch: 5| Step: 10
Training loss: 2.32600998878479
Validation loss: 2.2566020258011354

Epoch: 75| Step: 0
Training loss: 3.038933753967285
Validation loss: 2.259356221845073

Epoch: 5| Step: 1
Training loss: 2.1682655811309814
Validation loss: 2.2625398969137542

Epoch: 5| Step: 2
Training loss: 2.74566912651062
Validation loss: 2.2594497767827844

Epoch: 5| Step: 3
Training loss: 2.8428053855895996
Validation loss: 2.261379603416689

Epoch: 5| Step: 4
Training loss: 2.0477283000946045
Validation loss: 2.2662640438284924

Epoch: 5| Step: 5
Training loss: 2.4336726665496826
Validation loss: 2.262354075267751

Epoch: 5| Step: 6
Training loss: 2.108797550201416
Validation loss: 2.2606788553217405

Epoch: 5| Step: 7
Training loss: 2.558877468109131
Validation loss: 2.2842095667316067

Epoch: 5| Step: 8
Training loss: 3.1329541206359863
Validation loss: 2.278800223463325

Epoch: 5| Step: 9
Training loss: 2.520617961883545
Validation loss: 2.283673450510989

Epoch: 5| Step: 10
Training loss: 2.557249069213867
Validation loss: 2.280781617728613

Epoch: 76| Step: 0
Training loss: 2.841710329055786
Validation loss: 2.289278230359477

Epoch: 5| Step: 1
Training loss: 2.7548587322235107
Validation loss: 2.2888541811256

Epoch: 5| Step: 2
Training loss: 2.4297401905059814
Validation loss: 2.2778646369134226

Epoch: 5| Step: 3
Training loss: 3.1470510959625244
Validation loss: 2.270761933377994

Epoch: 5| Step: 4
Training loss: 2.452517509460449
Validation loss: 2.270332069807155

Epoch: 5| Step: 5
Training loss: 2.6166560649871826
Validation loss: 2.273748569591071

Epoch: 5| Step: 6
Training loss: 2.5151705741882324
Validation loss: 2.259923285053622

Epoch: 5| Step: 7
Training loss: 2.028442859649658
Validation loss: 2.264570008042038

Epoch: 5| Step: 8
Training loss: 2.3821098804473877
Validation loss: 2.2626975979856265

Epoch: 5| Step: 9
Training loss: 2.890045642852783
Validation loss: 2.2565606768413256

Epoch: 5| Step: 10
Training loss: 1.9075223207473755
Validation loss: 2.2595776973232145

Epoch: 77| Step: 0
Training loss: 2.8106765747070312
Validation loss: 2.2539108876259095

Epoch: 5| Step: 1
Training loss: 2.768038511276245
Validation loss: 2.2560479871688353

Epoch: 5| Step: 2
Training loss: 1.791433572769165
Validation loss: 2.2628329979476107

Epoch: 5| Step: 3
Training loss: 2.204300880432129
Validation loss: 2.276306603544502

Epoch: 5| Step: 4
Training loss: 2.070286512374878
Validation loss: 2.27449627589154

Epoch: 5| Step: 5
Training loss: 2.996574878692627
Validation loss: 2.2738299574903262

Epoch: 5| Step: 6
Training loss: 2.8260321617126465
Validation loss: 2.2682981593634493

Epoch: 5| Step: 7
Training loss: 2.1324050426483154
Validation loss: 2.2562947837255334

Epoch: 5| Step: 8
Training loss: 2.3780651092529297
Validation loss: 2.2552232050126597

Epoch: 5| Step: 9
Training loss: 2.6949543952941895
Validation loss: 2.2483872059852845

Epoch: 5| Step: 10
Training loss: 3.3402223587036133
Validation loss: 2.263679681285735

Epoch: 78| Step: 0
Training loss: 2.9188599586486816
Validation loss: 2.285431538858721

Epoch: 5| Step: 1
Training loss: 2.6233742237091064
Validation loss: 2.3070615107013333

Epoch: 5| Step: 2
Training loss: 2.541140556335449
Validation loss: 2.3027285145175074

Epoch: 5| Step: 3
Training loss: 2.257122039794922
Validation loss: 2.363194852746943

Epoch: 5| Step: 4
Training loss: 2.6433403491973877
Validation loss: 2.473429951616513

Epoch: 5| Step: 5
Training loss: 2.4401473999023438
Validation loss: 2.471460588516728

Epoch: 5| Step: 6
Training loss: 3.068542003631592
Validation loss: 2.3922720814263947

Epoch: 5| Step: 7
Training loss: 2.56093692779541
Validation loss: 2.308003789635115

Epoch: 5| Step: 8
Training loss: 2.7452564239501953
Validation loss: 2.2874643802642822

Epoch: 5| Step: 9
Training loss: 1.8724238872528076
Validation loss: 2.280229135226178

Epoch: 5| Step: 10
Training loss: 2.587139129638672
Validation loss: 2.279444889355731

Epoch: 79| Step: 0
Training loss: 3.0842719078063965
Validation loss: 2.2639748306684595

Epoch: 5| Step: 1
Training loss: 2.8600997924804688
Validation loss: 2.28089762503101

Epoch: 5| Step: 2
Training loss: 2.665573835372925
Validation loss: 2.2771503950959895

Epoch: 5| Step: 3
Training loss: 2.444819688796997
Validation loss: 2.2804835611774075

Epoch: 5| Step: 4
Training loss: 2.6225059032440186
Validation loss: 2.2813662277754916

Epoch: 5| Step: 5
Training loss: 2.8285155296325684
Validation loss: 2.2765370440739456

Epoch: 5| Step: 6
Training loss: 2.373108386993408
Validation loss: 2.2736745034494708

Epoch: 5| Step: 7
Training loss: 2.8750317096710205
Validation loss: 2.273381325506395

Epoch: 5| Step: 8
Training loss: 2.3532485961914062
Validation loss: 2.290688971037506

Epoch: 5| Step: 9
Training loss: 2.385444164276123
Validation loss: 2.30709134891469

Epoch: 5| Step: 10
Training loss: 1.5581773519515991
Validation loss: 2.310997860406035

Epoch: 80| Step: 0
Training loss: 2.694218397140503
Validation loss: 2.3394130455550326

Epoch: 5| Step: 1
Training loss: 2.8239147663116455
Validation loss: 2.341044495182653

Epoch: 5| Step: 2
Training loss: 2.5461976528167725
Validation loss: 2.3485508067633516

Epoch: 5| Step: 3
Training loss: 1.6746656894683838
Validation loss: 2.3193638042737077

Epoch: 5| Step: 4
Training loss: 3.413236141204834
Validation loss: 2.303506351286365

Epoch: 5| Step: 5
Training loss: 2.939497470855713
Validation loss: 2.2732571786449802

Epoch: 5| Step: 6
Training loss: 2.5068976879119873
Validation loss: 2.2741061410596295

Epoch: 5| Step: 7
Training loss: 2.227931499481201
Validation loss: 2.283800612213791

Epoch: 5| Step: 8
Training loss: 2.200286865234375
Validation loss: 2.287530142773864

Epoch: 5| Step: 9
Training loss: 2.8181099891662598
Validation loss: 2.2897540061704573

Epoch: 5| Step: 10
Training loss: 2.588113784790039
Validation loss: 2.293268544699556

Epoch: 81| Step: 0
Training loss: 2.9979960918426514
Validation loss: 2.2825666473757837

Epoch: 5| Step: 1
Training loss: 3.0546975135803223
Validation loss: 2.282791809369159

Epoch: 5| Step: 2
Training loss: 2.556806802749634
Validation loss: 2.2749175205025622

Epoch: 5| Step: 3
Training loss: 2.3547415733337402
Validation loss: 2.2670311338158062

Epoch: 5| Step: 4
Training loss: 2.406132221221924
Validation loss: 2.265716762952907

Epoch: 5| Step: 5
Training loss: 2.529165506362915
Validation loss: 2.2801444709941907

Epoch: 5| Step: 6
Training loss: 1.9924938678741455
Validation loss: 2.2979932241542365

Epoch: 5| Step: 7
Training loss: 2.314479351043701
Validation loss: 2.3144238379693802

Epoch: 5| Step: 8
Training loss: 2.3627591133117676
Validation loss: 2.337010737388365

Epoch: 5| Step: 9
Training loss: 2.9374537467956543
Validation loss: 2.3236977336227254

Epoch: 5| Step: 10
Training loss: 2.74529767036438
Validation loss: 2.292819232069036

Epoch: 82| Step: 0
Training loss: 2.296412944793701
Validation loss: 2.2665702886478876

Epoch: 5| Step: 1
Training loss: 2.0302717685699463
Validation loss: 2.257105376130791

Epoch: 5| Step: 2
Training loss: 3.0226070880889893
Validation loss: 2.260189373006103

Epoch: 5| Step: 3
Training loss: 2.0352392196655273
Validation loss: 2.266243116829985

Epoch: 5| Step: 4
Training loss: 2.8690662384033203
Validation loss: 2.2669102466234596

Epoch: 5| Step: 5
Training loss: 2.652113676071167
Validation loss: 2.270426745055824

Epoch: 5| Step: 6
Training loss: 2.6802895069122314
Validation loss: 2.2596356458561395

Epoch: 5| Step: 7
Training loss: 2.7039599418640137
Validation loss: 2.249052072084078

Epoch: 5| Step: 8
Training loss: 1.963834524154663
Validation loss: 2.2432796186016453

Epoch: 5| Step: 9
Training loss: 2.6960721015930176
Validation loss: 2.245432110242946

Epoch: 5| Step: 10
Training loss: 3.1726419925689697
Validation loss: 2.2499069039539625

Epoch: 83| Step: 0
Training loss: 3.171948194503784
Validation loss: 2.2563273496525262

Epoch: 5| Step: 1
Training loss: 2.656254291534424
Validation loss: 2.2423996092170797

Epoch: 5| Step: 2
Training loss: 2.56708025932312
Validation loss: 2.234390377998352

Epoch: 5| Step: 3
Training loss: 2.702040195465088
Validation loss: 2.224523654548071

Epoch: 5| Step: 4
Training loss: 2.4477951526641846
Validation loss: 2.2157101169709237

Epoch: 5| Step: 5
Training loss: 2.7376692295074463
Validation loss: 2.2026651931065384

Epoch: 5| Step: 6
Training loss: 2.1285362243652344
Validation loss: 2.201229462059595

Epoch: 5| Step: 7
Training loss: 2.5322482585906982
Validation loss: 2.2126899252655687

Epoch: 5| Step: 8
Training loss: 1.3990228176116943
Validation loss: 2.220479138435856

Epoch: 5| Step: 9
Training loss: 2.8250980377197266
Validation loss: 2.231159915206253

Epoch: 5| Step: 10
Training loss: 2.7469418048858643
Validation loss: 2.2560895232744116

Epoch: 84| Step: 0
Training loss: 2.05464243888855
Validation loss: 2.2655857993710424

Epoch: 5| Step: 1
Training loss: 2.4383692741394043
Validation loss: 2.3030440063886743

Epoch: 5| Step: 2
Training loss: 2.495513439178467
Validation loss: 2.303872195623254

Epoch: 5| Step: 3
Training loss: 2.312838077545166
Validation loss: 2.286913694873933

Epoch: 5| Step: 4
Training loss: 2.453906297683716
Validation loss: 2.2686317838648313

Epoch: 5| Step: 5
Training loss: 2.174553394317627
Validation loss: 2.2665416399637857

Epoch: 5| Step: 6
Training loss: 3.2214245796203613
Validation loss: 2.2450998880529918

Epoch: 5| Step: 7
Training loss: 2.8432445526123047
Validation loss: 2.227455246833063

Epoch: 5| Step: 8
Training loss: 2.719374895095825
Validation loss: 2.2201477096926783

Epoch: 5| Step: 9
Training loss: 2.4120352268218994
Validation loss: 2.2057530828701553

Epoch: 5| Step: 10
Training loss: 2.7141687870025635
Validation loss: 2.209763357716222

Epoch: 85| Step: 0
Training loss: 3.000370979309082
Validation loss: 2.20464926381265

Epoch: 5| Step: 1
Training loss: 3.0049614906311035
Validation loss: 2.208836217080393

Epoch: 5| Step: 2
Training loss: 2.846912384033203
Validation loss: 2.2065358546472367

Epoch: 5| Step: 3
Training loss: 2.2241501808166504
Validation loss: 2.210830210357584

Epoch: 5| Step: 4
Training loss: 2.1319122314453125
Validation loss: 2.2109500092844807

Epoch: 5| Step: 5
Training loss: 2.239062547683716
Validation loss: 2.2077424244214128

Epoch: 5| Step: 6
Training loss: 2.549271821975708
Validation loss: 2.2023694822865147

Epoch: 5| Step: 7
Training loss: 2.7087321281433105
Validation loss: 2.1981209529343473

Epoch: 5| Step: 8
Training loss: 2.586503744125366
Validation loss: 2.221307249479396

Epoch: 5| Step: 9
Training loss: 2.234607219696045
Validation loss: 2.2637023259234685

Epoch: 5| Step: 10
Training loss: 2.0781054496765137
Validation loss: 2.3663675144154537

Epoch: 86| Step: 0
Training loss: 2.936673164367676
Validation loss: 2.503198331402194

Epoch: 5| Step: 1
Training loss: 3.1782913208007812
Validation loss: 2.5622416439876763

Epoch: 5| Step: 2
Training loss: 2.3762364387512207
Validation loss: 2.598662009803198

Epoch: 5| Step: 3
Training loss: 3.4434943199157715
Validation loss: 2.4886325815672516

Epoch: 5| Step: 4
Training loss: 2.184218168258667
Validation loss: 2.359453965258855

Epoch: 5| Step: 5
Training loss: 2.1833226680755615
Validation loss: 2.2644695261473298

Epoch: 5| Step: 6
Training loss: 2.378220796585083
Validation loss: 2.210345063158261

Epoch: 5| Step: 7
Training loss: 2.5845179557800293
Validation loss: 2.1994447118492535

Epoch: 5| Step: 8
Training loss: 2.36930513381958
Validation loss: 2.198171777109946

Epoch: 5| Step: 9
Training loss: 2.5998847484588623
Validation loss: 2.215350943226968

Epoch: 5| Step: 10
Training loss: 2.327162027359009
Validation loss: 2.2312824726104736

Epoch: 87| Step: 0
Training loss: 2.6493420600891113
Validation loss: 2.248071906387165

Epoch: 5| Step: 1
Training loss: 2.1320273876190186
Validation loss: 2.2846353925684446

Epoch: 5| Step: 2
Training loss: 2.178194761276245
Validation loss: 2.2926702037934334

Epoch: 5| Step: 3
Training loss: 2.903862714767456
Validation loss: 2.2970930504542526

Epoch: 5| Step: 4
Training loss: 2.2088170051574707
Validation loss: 2.249060243688604

Epoch: 5| Step: 5
Training loss: 2.296495199203491
Validation loss: 2.223391286788448

Epoch: 5| Step: 6
Training loss: 3.021078586578369
Validation loss: 2.2036059825651106

Epoch: 5| Step: 7
Training loss: 1.827426552772522
Validation loss: 2.2007892593260734

Epoch: 5| Step: 8
Training loss: 3.2380053997039795
Validation loss: 2.191097326176141

Epoch: 5| Step: 9
Training loss: 2.8975493907928467
Validation loss: 2.189458885500508

Epoch: 5| Step: 10
Training loss: 2.4273273944854736
Validation loss: 2.194036494019211

Epoch: 88| Step: 0
Training loss: 2.3084616661071777
Validation loss: 2.1991571123882006

Epoch: 5| Step: 1
Training loss: 2.2565534114837646
Validation loss: 2.200380817536385

Epoch: 5| Step: 2
Training loss: 3.0352015495300293
Validation loss: 2.2004096405480498

Epoch: 5| Step: 3
Training loss: 2.4855551719665527
Validation loss: 2.197739931844896

Epoch: 5| Step: 4
Training loss: 2.7815918922424316
Validation loss: 2.190764711749169

Epoch: 5| Step: 5
Training loss: 2.1380858421325684
Validation loss: 2.21218018890709

Epoch: 5| Step: 6
Training loss: 2.9151597023010254
Validation loss: 2.228256138422156

Epoch: 5| Step: 7
Training loss: 2.6017026901245117
Validation loss: 2.2310951473892375

Epoch: 5| Step: 8
Training loss: 2.6883671283721924
Validation loss: 2.2116024430080126

Epoch: 5| Step: 9
Training loss: 1.7265119552612305
Validation loss: 2.199020246023773

Epoch: 5| Step: 10
Training loss: 2.6571481227874756
Validation loss: 2.1909233959772254

Epoch: 89| Step: 0
Training loss: 2.8904449939727783
Validation loss: 2.1882899281799153

Epoch: 5| Step: 1
Training loss: 2.180318832397461
Validation loss: 2.181107462093394

Epoch: 5| Step: 2
Training loss: 2.611818552017212
Validation loss: 2.1858996422060075

Epoch: 5| Step: 3
Training loss: 2.623521327972412
Validation loss: 2.1909677674693446

Epoch: 5| Step: 4
Training loss: 3.2125229835510254
Validation loss: 2.1960450039115003

Epoch: 5| Step: 5
Training loss: 2.0081276893615723
Validation loss: 2.206095205840244

Epoch: 5| Step: 6
Training loss: 2.308809757232666
Validation loss: 2.2111365820771907

Epoch: 5| Step: 7
Training loss: 2.258751392364502
Validation loss: 2.222370707860557

Epoch: 5| Step: 8
Training loss: 2.241642713546753
Validation loss: 2.217514984069332

Epoch: 5| Step: 9
Training loss: 2.1647696495056152
Validation loss: 2.2471744629644577

Epoch: 5| Step: 10
Training loss: 3.1510353088378906
Validation loss: 2.2509602808183238

Epoch: 90| Step: 0
Training loss: 2.1528940200805664
Validation loss: 2.245651957809284

Epoch: 5| Step: 1
Training loss: 2.8331634998321533
Validation loss: 2.2280886147611882

Epoch: 5| Step: 2
Training loss: 2.1722521781921387
Validation loss: 2.2105626790754256

Epoch: 5| Step: 3
Training loss: 2.7440104484558105
Validation loss: 2.210182987233644

Epoch: 5| Step: 4
Training loss: 2.8581109046936035
Validation loss: 2.21824509866776

Epoch: 5| Step: 5
Training loss: 2.247230052947998
Validation loss: 2.208284498542868

Epoch: 5| Step: 6
Training loss: 2.2168612480163574
Validation loss: 2.2093755506700083

Epoch: 5| Step: 7
Training loss: 2.6413753032684326
Validation loss: 2.210794820580431

Epoch: 5| Step: 8
Training loss: 1.8602190017700195
Validation loss: 2.21833102421094

Epoch: 5| Step: 9
Training loss: 2.9668517112731934
Validation loss: 2.207402047290597

Epoch: 5| Step: 10
Training loss: 2.724782705307007
Validation loss: 2.1971932636794222

Epoch: 91| Step: 0
Training loss: 2.4912307262420654
Validation loss: 2.18742299079895

Epoch: 5| Step: 1
Training loss: 2.4292259216308594
Validation loss: 2.1740422338567753

Epoch: 5| Step: 2
Training loss: 2.2224202156066895
Validation loss: 2.1677197743487615

Epoch: 5| Step: 3
Training loss: 2.6561853885650635
Validation loss: 2.175714797871087

Epoch: 5| Step: 4
Training loss: 2.188650608062744
Validation loss: 2.17215633392334

Epoch: 5| Step: 5
Training loss: 2.748819351196289
Validation loss: 2.1739449180582517

Epoch: 5| Step: 6
Training loss: 2.7758469581604004
Validation loss: 2.1816136837005615

Epoch: 5| Step: 7
Training loss: 2.6375510692596436
Validation loss: 2.1847617831281436

Epoch: 5| Step: 8
Training loss: 1.9800821542739868
Validation loss: 2.19033444184129

Epoch: 5| Step: 9
Training loss: 2.572031021118164
Validation loss: 2.2019162357494397

Epoch: 5| Step: 10
Training loss: 2.6464579105377197
Validation loss: 2.2023155740512315

Epoch: 92| Step: 0
Training loss: 2.8016715049743652
Validation loss: 2.1962072541636806

Epoch: 5| Step: 1
Training loss: 2.4460766315460205
Validation loss: 2.1990252182047856

Epoch: 5| Step: 2
Training loss: 2.0744824409484863
Validation loss: 2.2007881390151156

Epoch: 5| Step: 3
Training loss: 2.359221935272217
Validation loss: 2.2287728209649362

Epoch: 5| Step: 4
Training loss: 2.510545253753662
Validation loss: 2.233275149458198

Epoch: 5| Step: 5
Training loss: 2.208649158477783
Validation loss: 2.200366738022015

Epoch: 5| Step: 6
Training loss: 2.396712064743042
Validation loss: 2.195761175565822

Epoch: 5| Step: 7
Training loss: 3.192046642303467
Validation loss: 2.181440930212698

Epoch: 5| Step: 8
Training loss: 2.3080379962921143
Validation loss: 2.1662838510287705

Epoch: 5| Step: 9
Training loss: 2.269829273223877
Validation loss: 2.1755156235028337

Epoch: 5| Step: 10
Training loss: 2.7960875034332275
Validation loss: 2.1739315063722673

Epoch: 93| Step: 0
Training loss: 2.082451343536377
Validation loss: 2.16697084775535

Epoch: 5| Step: 1
Training loss: 2.26735520362854
Validation loss: 2.1757834342218216

Epoch: 5| Step: 2
Training loss: 2.703791379928589
Validation loss: 2.179742831055836

Epoch: 5| Step: 3
Training loss: 2.714627504348755
Validation loss: 2.1931010189876763

Epoch: 5| Step: 4
Training loss: 2.970019817352295
Validation loss: 2.1968023700098835

Epoch: 5| Step: 5
Training loss: 2.4138760566711426
Validation loss: 2.2063221598184235

Epoch: 5| Step: 6
Training loss: 2.114215135574341
Validation loss: 2.189977991965509

Epoch: 5| Step: 7
Training loss: 2.322913646697998
Validation loss: 2.183294052718788

Epoch: 5| Step: 8
Training loss: 2.7180094718933105
Validation loss: 2.1935845523752193

Epoch: 5| Step: 9
Training loss: 2.4140701293945312
Validation loss: 2.2044921895509124

Epoch: 5| Step: 10
Training loss: 2.4896769523620605
Validation loss: 2.1987461018305954

Epoch: 94| Step: 0
Training loss: 2.509965419769287
Validation loss: 2.1823402527839906

Epoch: 5| Step: 1
Training loss: 3.3713901042938232
Validation loss: 2.173641081779234

Epoch: 5| Step: 2
Training loss: 2.2873282432556152
Validation loss: 2.161991693640268

Epoch: 5| Step: 3
Training loss: 2.4002232551574707
Validation loss: 2.153771951634397

Epoch: 5| Step: 4
Training loss: 2.833913803100586
Validation loss: 2.162273778710314

Epoch: 5| Step: 5
Training loss: 2.3833465576171875
Validation loss: 2.142529146645659

Epoch: 5| Step: 6
Training loss: 1.8830865621566772
Validation loss: 2.156696378543813

Epoch: 5| Step: 7
Training loss: 2.498138904571533
Validation loss: 2.1416259632315686

Epoch: 5| Step: 8
Training loss: 2.631922960281372
Validation loss: 2.1433158830929826

Epoch: 5| Step: 9
Training loss: 2.1726157665252686
Validation loss: 2.1511175196657897

Epoch: 5| Step: 10
Training loss: 2.1425037384033203
Validation loss: 2.1608188408677296

Epoch: 95| Step: 0
Training loss: 1.785272240638733
Validation loss: 2.1712687374443136

Epoch: 5| Step: 1
Training loss: 2.820091724395752
Validation loss: 2.1911175917553645

Epoch: 5| Step: 2
Training loss: 2.159719467163086
Validation loss: 2.196285475966751

Epoch: 5| Step: 3
Training loss: 2.640458583831787
Validation loss: 2.214299160947082

Epoch: 5| Step: 4
Training loss: 2.5772271156311035
Validation loss: 2.2070774416769705

Epoch: 5| Step: 5
Training loss: 2.520247459411621
Validation loss: 2.1930177698853197

Epoch: 5| Step: 6
Training loss: 2.6366820335388184
Validation loss: 2.196538920043617

Epoch: 5| Step: 7
Training loss: 2.4508190155029297
Validation loss: 2.1708329005907943

Epoch: 5| Step: 8
Training loss: 2.3423373699188232
Validation loss: 2.1527165341120895

Epoch: 5| Step: 9
Training loss: 2.101820468902588
Validation loss: 2.153801119455727

Epoch: 5| Step: 10
Training loss: 3.1889710426330566
Validation loss: 2.149499603497085

Epoch: 96| Step: 0
Training loss: 2.705148220062256
Validation loss: 2.1469201387897616

Epoch: 5| Step: 1
Training loss: 2.7092444896698
Validation loss: 2.1424375041838615

Epoch: 5| Step: 2
Training loss: 2.3209915161132812
Validation loss: 2.147448388479089

Epoch: 5| Step: 3
Training loss: 2.7718429565429688
Validation loss: 2.144038135005582

Epoch: 5| Step: 4
Training loss: 2.656669855117798
Validation loss: 2.1526327594634025

Epoch: 5| Step: 5
Training loss: 1.872610330581665
Validation loss: 2.144058100638851

Epoch: 5| Step: 6
Training loss: 2.860755443572998
Validation loss: 2.1467409544093634

Epoch: 5| Step: 7
Training loss: 1.8750622272491455
Validation loss: 2.1474976898521505

Epoch: 5| Step: 8
Training loss: 2.350706100463867
Validation loss: 2.1530842217065955

Epoch: 5| Step: 9
Training loss: 2.3036880493164062
Validation loss: 2.1798341428079913

Epoch: 5| Step: 10
Training loss: 2.6463518142700195
Validation loss: 2.1994360749439528

Epoch: 97| Step: 0
Training loss: 2.7028748989105225
Validation loss: 2.2150426539041663

Epoch: 5| Step: 1
Training loss: 1.3610992431640625
Validation loss: 2.2141615498450493

Epoch: 5| Step: 2
Training loss: 2.7223973274230957
Validation loss: 2.2032320140510477

Epoch: 5| Step: 3
Training loss: 2.5963802337646484
Validation loss: 2.2059849974929646

Epoch: 5| Step: 4
Training loss: 3.1501095294952393
Validation loss: 2.1931105941854496

Epoch: 5| Step: 5
Training loss: 2.4382381439208984
Validation loss: 2.168586256683514

Epoch: 5| Step: 6
Training loss: 2.577911853790283
Validation loss: 2.1469846797245804

Epoch: 5| Step: 7
Training loss: 1.990224838256836
Validation loss: 2.1484500720936763

Epoch: 5| Step: 8
Training loss: 2.2591395378112793
Validation loss: 2.1373708965957805

Epoch: 5| Step: 9
Training loss: 2.2464773654937744
Validation loss: 2.1399635884069625

Epoch: 5| Step: 10
Training loss: 3.1446051597595215
Validation loss: 2.1351078364156906

Epoch: 98| Step: 0
Training loss: 2.2434444427490234
Validation loss: 2.1418304033176874

Epoch: 5| Step: 1
Training loss: 2.3368306159973145
Validation loss: 2.145877557416116

Epoch: 5| Step: 2
Training loss: 2.4599621295928955
Validation loss: 2.1392261187235513

Epoch: 5| Step: 3
Training loss: 1.7069752216339111
Validation loss: 2.1372390857306858

Epoch: 5| Step: 4
Training loss: 2.1150059700012207
Validation loss: 2.137008087609404

Epoch: 5| Step: 5
Training loss: 2.4172470569610596
Validation loss: 2.14630320507993

Epoch: 5| Step: 6
Training loss: 3.07090163230896
Validation loss: 2.1454360638895342

Epoch: 5| Step: 7
Training loss: 3.1634318828582764
Validation loss: 2.150362362143814

Epoch: 5| Step: 8
Training loss: 2.4038031101226807
Validation loss: 2.1693902220777286

Epoch: 5| Step: 9
Training loss: 2.333446741104126
Validation loss: 2.1903163489475044

Epoch: 5| Step: 10
Training loss: 2.5457370281219482
Validation loss: 2.2391931446649695

Epoch: 99| Step: 0
Training loss: 3.1046061515808105
Validation loss: 2.2722922884007937

Epoch: 5| Step: 1
Training loss: 2.1682868003845215
Validation loss: 2.259302613555744

Epoch: 5| Step: 2
Training loss: 1.8998721837997437
Validation loss: 2.2279053221466723

Epoch: 5| Step: 3
Training loss: 2.3301053047180176
Validation loss: 2.2021240188229467

Epoch: 5| Step: 4
Training loss: 2.60215163230896
Validation loss: 2.2171763168868197

Epoch: 5| Step: 5
Training loss: 2.220836639404297
Validation loss: 2.181640250708467

Epoch: 5| Step: 6
Training loss: 2.6036934852600098
Validation loss: 2.1737467473553074

Epoch: 5| Step: 7
Training loss: 2.5016932487487793
Validation loss: 2.1439936263586885

Epoch: 5| Step: 8
Training loss: 2.1859607696533203
Validation loss: 2.143219224868282

Epoch: 5| Step: 9
Training loss: 3.1162314414978027
Validation loss: 2.1447128044661654

Epoch: 5| Step: 10
Training loss: 2.2361037731170654
Validation loss: 2.1353299784403976

Epoch: 100| Step: 0
Training loss: 2.159179210662842
Validation loss: 2.1421294340523342

Epoch: 5| Step: 1
Training loss: 2.4775490760803223
Validation loss: 2.13789366650325

Epoch: 5| Step: 2
Training loss: 2.4538211822509766
Validation loss: 2.140107298410067

Epoch: 5| Step: 3
Training loss: 2.610124349594116
Validation loss: 2.139247909668953

Epoch: 5| Step: 4
Training loss: 2.3262953758239746
Validation loss: 2.1303775707880654

Epoch: 5| Step: 5
Training loss: 2.5056703090667725
Validation loss: 2.1285267453039847

Epoch: 5| Step: 6
Training loss: 2.194672107696533
Validation loss: 2.1411689609609623

Epoch: 5| Step: 7
Training loss: 2.4930317401885986
Validation loss: 2.1477357879761727

Epoch: 5| Step: 8
Training loss: 2.460116386413574
Validation loss: 2.1768079714108537

Epoch: 5| Step: 9
Training loss: 2.306090831756592
Validation loss: 2.227679035996878

Epoch: 5| Step: 10
Training loss: 3.0518887042999268
Validation loss: 2.2598559856414795

Epoch: 101| Step: 0
Training loss: 2.203333616256714
Validation loss: 2.2386710989859795

Epoch: 5| Step: 1
Training loss: 2.512993097305298
Validation loss: 2.1997386563208794

Epoch: 5| Step: 2
Training loss: 2.6908652782440186
Validation loss: 2.1688575039627733

Epoch: 5| Step: 3
Training loss: 2.4047646522521973
Validation loss: 2.146865862672047

Epoch: 5| Step: 4
Training loss: 2.8324851989746094
Validation loss: 2.1362997357563307

Epoch: 5| Step: 5
Training loss: 2.2324252128601074
Validation loss: 2.130576044000605

Epoch: 5| Step: 6
Training loss: 2.395103931427002
Validation loss: 2.12771939205867

Epoch: 5| Step: 7
Training loss: 2.260119676589966
Validation loss: 2.134962789473995

Epoch: 5| Step: 8
Training loss: 2.2702126502990723
Validation loss: 2.128961190100639

Epoch: 5| Step: 9
Training loss: 2.3615365028381348
Validation loss: 2.134976786951865

Epoch: 5| Step: 10
Training loss: 2.5946877002716064
Validation loss: 2.121865418649489

Epoch: 102| Step: 0
Training loss: 3.1698694229125977
Validation loss: 2.12569099087869

Epoch: 5| Step: 1
Training loss: 1.8414024114608765
Validation loss: 2.12090164871626

Epoch: 5| Step: 2
Training loss: 2.6267335414886475
Validation loss: 2.134100562782698

Epoch: 5| Step: 3
Training loss: 2.138533353805542
Validation loss: 2.1196733828513854

Epoch: 5| Step: 4
Training loss: 2.708364963531494
Validation loss: 2.1237412050206173

Epoch: 5| Step: 5
Training loss: 2.1542859077453613
Validation loss: 2.1218533836385256

Epoch: 5| Step: 6
Training loss: 2.7027132511138916
Validation loss: 2.1211980799193024

Epoch: 5| Step: 7
Training loss: 2.298983097076416
Validation loss: 2.1213036993498444

Epoch: 5| Step: 8
Training loss: 2.68721866607666
Validation loss: 2.153033233457996

Epoch: 5| Step: 9
Training loss: 2.2119433879852295
Validation loss: 2.182273144363075

Epoch: 5| Step: 10
Training loss: 2.417365550994873
Validation loss: 2.274407022742815

Epoch: 103| Step: 0
Training loss: 2.0267844200134277
Validation loss: 2.289741386649429

Epoch: 5| Step: 1
Training loss: 1.7418311834335327
Validation loss: 2.2907682593150804

Epoch: 5| Step: 2
Training loss: 3.6420273780822754
Validation loss: 2.3145306776928645

Epoch: 5| Step: 3
Training loss: 1.716365098953247
Validation loss: 2.245245910459949

Epoch: 5| Step: 4
Training loss: 2.528006076812744
Validation loss: 2.1590998890579387

Epoch: 5| Step: 5
Training loss: 2.461977005004883
Validation loss: 2.1195646127065024

Epoch: 5| Step: 6
Training loss: 2.3221099376678467
Validation loss: 2.110964434121245

Epoch: 5| Step: 7
Training loss: 2.6708743572235107
Validation loss: 2.117455977265553

Epoch: 5| Step: 8
Training loss: 2.527829885482788
Validation loss: 2.1265948280211417

Epoch: 5| Step: 9
Training loss: 2.6582798957824707
Validation loss: 2.125212123317103

Epoch: 5| Step: 10
Training loss: 2.4891462326049805
Validation loss: 2.1315704161121

Epoch: 104| Step: 0
Training loss: 2.4720559120178223
Validation loss: 2.119882318281358

Epoch: 5| Step: 1
Training loss: 2.3232643604278564
Validation loss: 2.116810178243986

Epoch: 5| Step: 2
Training loss: 2.3570384979248047
Validation loss: 2.1125193462576917

Epoch: 5| Step: 3
Training loss: 2.85184907913208
Validation loss: 2.1194394326979116

Epoch: 5| Step: 4
Training loss: 1.7457034587860107
Validation loss: 2.1397854653737878

Epoch: 5| Step: 5
Training loss: 1.8651071786880493
Validation loss: 2.151107197166771

Epoch: 5| Step: 6
Training loss: 2.659656286239624
Validation loss: 2.186227221642771

Epoch: 5| Step: 7
Training loss: 3.1323373317718506
Validation loss: 2.1933504740397134

Epoch: 5| Step: 8
Training loss: 2.6324551105499268
Validation loss: 2.197278053529801

Epoch: 5| Step: 9
Training loss: 2.282679557800293
Validation loss: 2.176331220134612

Epoch: 5| Step: 10
Training loss: 2.4776673316955566
Validation loss: 2.127857595361689

Epoch: 105| Step: 0
Training loss: 3.1629624366760254
Validation loss: 2.116032131256596

Epoch: 5| Step: 1
Training loss: 1.908951997756958
Validation loss: 2.092416765869305

Epoch: 5| Step: 2
Training loss: 2.205399990081787
Validation loss: 2.0971429578719603

Epoch: 5| Step: 3
Training loss: 2.1273903846740723
Validation loss: 2.119211999318933

Epoch: 5| Step: 4
Training loss: 2.5307161808013916
Validation loss: 2.12802880553789

Epoch: 5| Step: 5
Training loss: 2.463784694671631
Validation loss: 2.129121054885208

Epoch: 5| Step: 6
Training loss: 2.6668777465820312
Validation loss: 2.1158900542925765

Epoch: 5| Step: 7
Training loss: 2.0064523220062256
Validation loss: 2.101531474821029

Epoch: 5| Step: 8
Training loss: 2.117771863937378
Validation loss: 2.095574750695177

Epoch: 5| Step: 9
Training loss: 3.0068836212158203
Validation loss: 2.1089441417365946

Epoch: 5| Step: 10
Training loss: 2.8929264545440674
Validation loss: 2.1194777463072088

Epoch: 106| Step: 0
Training loss: 2.3721718788146973
Validation loss: 2.142834460863503

Epoch: 5| Step: 1
Training loss: 1.9379692077636719
Validation loss: 2.1770652827396186

Epoch: 5| Step: 2
Training loss: 2.7211947441101074
Validation loss: 2.2128576565814275

Epoch: 5| Step: 3
Training loss: 2.116928815841675
Validation loss: 2.222654345215008

Epoch: 5| Step: 4
Training loss: 2.3958494663238525
Validation loss: 2.223152874618448

Epoch: 5| Step: 5
Training loss: 2.3572583198547363
Validation loss: 2.2091241113601194

Epoch: 5| Step: 6
Training loss: 2.3576722145080566
Validation loss: 2.1704829251894386

Epoch: 5| Step: 7
Training loss: 2.4069132804870605
Validation loss: 2.1385188974359983

Epoch: 5| Step: 8
Training loss: 2.383617401123047
Validation loss: 2.1191580705745245

Epoch: 5| Step: 9
Training loss: 2.9478373527526855
Validation loss: 2.1036722685701106

Epoch: 5| Step: 10
Training loss: 2.5155625343322754
Validation loss: 2.095498913077898

Epoch: 107| Step: 0
Training loss: 2.1283390522003174
Validation loss: 2.1065984233733146

Epoch: 5| Step: 1
Training loss: 2.6010165214538574
Validation loss: 2.1025625736482683

Epoch: 5| Step: 2
Training loss: 2.2094337940216064
Validation loss: 2.1114493006019184

Epoch: 5| Step: 3
Training loss: 2.4268739223480225
Validation loss: 2.1144778831030733

Epoch: 5| Step: 4
Training loss: 3.003528118133545
Validation loss: 2.107450695448024

Epoch: 5| Step: 5
Training loss: 2.6797330379486084
Validation loss: 2.107559842448081

Epoch: 5| Step: 6
Training loss: 2.4641988277435303
Validation loss: 2.0981230325596307

Epoch: 5| Step: 7
Training loss: 1.9851906299591064
Validation loss: 2.1066658509674894

Epoch: 5| Step: 8
Training loss: 2.6610851287841797
Validation loss: 2.1117060902298137

Epoch: 5| Step: 9
Training loss: 2.498187303543091
Validation loss: 2.1179566614089476

Epoch: 5| Step: 10
Training loss: 2.0092055797576904
Validation loss: 2.115374767652122

Epoch: 108| Step: 0
Training loss: 2.076507091522217
Validation loss: 2.1212519548272573

Epoch: 5| Step: 1
Training loss: 2.1670749187469482
Validation loss: 2.1291764410593177

Epoch: 5| Step: 2
Training loss: 2.178762197494507
Validation loss: 2.1396701438452608

Epoch: 5| Step: 3
Training loss: 2.653949022293091
Validation loss: 2.1487743828886297

Epoch: 5| Step: 4
Training loss: 2.780911684036255
Validation loss: 2.185191749244608

Epoch: 5| Step: 5
Training loss: 2.630066394805908
Validation loss: 2.199034490892964

Epoch: 5| Step: 6
Training loss: 2.330477237701416
Validation loss: 2.200577382118471

Epoch: 5| Step: 7
Training loss: 2.8174691200256348
Validation loss: 2.1867072428426435

Epoch: 5| Step: 8
Training loss: 2.325228452682495
Validation loss: 2.1645537473822154

Epoch: 5| Step: 9
Training loss: 2.4786012172698975
Validation loss: 2.153044351967432

Epoch: 5| Step: 10
Training loss: 1.9538657665252686
Validation loss: 2.1184391949766423

Epoch: 109| Step: 0
Training loss: 2.06217885017395
Validation loss: 2.1006316497761715

Epoch: 5| Step: 1
Training loss: 2.479811191558838
Validation loss: 2.0999095619365735

Epoch: 5| Step: 2
Training loss: 2.2472450733184814
Validation loss: 2.1012707961502897

Epoch: 5| Step: 3
Training loss: 1.8940250873565674
Validation loss: 2.0942940455611034

Epoch: 5| Step: 4
Training loss: 2.320784091949463
Validation loss: 2.094708009432721

Epoch: 5| Step: 5
Training loss: 2.820073127746582
Validation loss: 2.094611703708608

Epoch: 5| Step: 6
Training loss: 3.0503430366516113
Validation loss: 2.0960575611360612

Epoch: 5| Step: 7
Training loss: 2.2474687099456787
Validation loss: 2.123313752553796

Epoch: 5| Step: 8
Training loss: 2.5600929260253906
Validation loss: 2.1366474807903333

Epoch: 5| Step: 9
Training loss: 2.2876124382019043
Validation loss: 2.1370376040858607

Epoch: 5| Step: 10
Training loss: 2.433319568634033
Validation loss: 2.156141998947308

Epoch: 110| Step: 0
Training loss: 2.0512683391571045
Validation loss: 2.1459034412137923

Epoch: 5| Step: 1
Training loss: 2.4130349159240723
Validation loss: 2.1424376003203855

Epoch: 5| Step: 2
Training loss: 2.1481785774230957
Validation loss: 2.142905837746077

Epoch: 5| Step: 3
Training loss: 2.378119707107544
Validation loss: 2.107969137930101

Epoch: 5| Step: 4
Training loss: 2.805797576904297
Validation loss: 2.0930637467292046

Epoch: 5| Step: 5
Training loss: 2.580400228500366
Validation loss: 2.08852110626877

Epoch: 5| Step: 6
Training loss: 2.1914138793945312
Validation loss: 2.085162349926528

Epoch: 5| Step: 7
Training loss: 2.163550615310669
Validation loss: 2.0812769820613246

Epoch: 5| Step: 8
Training loss: 2.607133388519287
Validation loss: 2.0895915877434517

Epoch: 5| Step: 9
Training loss: 2.5981662273406982
Validation loss: 2.086114122021583

Epoch: 5| Step: 10
Training loss: 2.2611725330352783
Validation loss: 2.075326645246116

Epoch: 111| Step: 0
Training loss: 2.3546969890594482
Validation loss: 2.114601908191558

Epoch: 5| Step: 1
Training loss: 2.80767560005188
Validation loss: 2.1024978237767376

Epoch: 5| Step: 2
Training loss: 2.288569927215576
Validation loss: 2.128509134374639

Epoch: 5| Step: 3
Training loss: 2.0212771892547607
Validation loss: 2.1245373731018393

Epoch: 5| Step: 4
Training loss: 2.125072717666626
Validation loss: 2.1000936646615305

Epoch: 5| Step: 5
Training loss: 1.5172996520996094
Validation loss: 2.0842948241900374

Epoch: 5| Step: 6
Training loss: 2.736124038696289
Validation loss: 2.0867785638378513

Epoch: 5| Step: 7
Training loss: 2.8794808387756348
Validation loss: 2.080732100753374

Epoch: 5| Step: 8
Training loss: 2.3204407691955566
Validation loss: 2.0986107882633003

Epoch: 5| Step: 9
Training loss: 2.8175978660583496
Validation loss: 2.1387078531326784

Epoch: 5| Step: 10
Training loss: 2.4589805603027344
Validation loss: 2.1422442543891167

Epoch: 112| Step: 0
Training loss: 2.513536214828491
Validation loss: 2.11892653921599

Epoch: 5| Step: 1
Training loss: 2.446498394012451
Validation loss: 2.104944941818073

Epoch: 5| Step: 2
Training loss: 2.286931276321411
Validation loss: 2.1032972489633868

Epoch: 5| Step: 3
Training loss: 2.362308979034424
Validation loss: 2.0853716365752684

Epoch: 5| Step: 4
Training loss: 2.204340696334839
Validation loss: 2.081879746529364

Epoch: 5| Step: 5
Training loss: 2.082935333251953
Validation loss: 2.0922649265617452

Epoch: 5| Step: 6
Training loss: 2.6630146503448486
Validation loss: 2.1264803050666727

Epoch: 5| Step: 7
Training loss: 2.4069583415985107
Validation loss: 2.1231507178275817

Epoch: 5| Step: 8
Training loss: 2.652891159057617
Validation loss: 2.1585113566408873

Epoch: 5| Step: 9
Training loss: 1.9070756435394287
Validation loss: 2.1454377597378147

Epoch: 5| Step: 10
Training loss: 2.4834792613983154
Validation loss: 2.1397476606471564

Epoch: 113| Step: 0
Training loss: 2.6903913021087646
Validation loss: 2.0903076279547905

Epoch: 5| Step: 1
Training loss: 2.2134451866149902
Validation loss: 2.0667090467227403

Epoch: 5| Step: 2
Training loss: 2.6498336791992188
Validation loss: 2.078613788850846

Epoch: 5| Step: 3
Training loss: 2.9858367443084717
Validation loss: 2.0711415865088023

Epoch: 5| Step: 4
Training loss: 2.642777919769287
Validation loss: 2.071708421553335

Epoch: 5| Step: 5
Training loss: 1.3888914585113525
Validation loss: 2.078045542522143

Epoch: 5| Step: 6
Training loss: 2.7586300373077393
Validation loss: 2.08142549632698

Epoch: 5| Step: 7
Training loss: 2.653916358947754
Validation loss: 2.0785332854076097

Epoch: 5| Step: 8
Training loss: 1.9753608703613281
Validation loss: 2.0773753337962653

Epoch: 5| Step: 9
Training loss: 1.7877670526504517
Validation loss: 2.094678214801255

Epoch: 5| Step: 10
Training loss: 2.6307411193847656
Validation loss: 2.142055801166001

Epoch: 114| Step: 0
Training loss: 2.332681655883789
Validation loss: 2.163975505418675

Epoch: 5| Step: 1
Training loss: 1.930503487586975
Validation loss: 2.1389996031279206

Epoch: 5| Step: 2
Training loss: 2.6395461559295654
Validation loss: 2.1198926177076114

Epoch: 5| Step: 3
Training loss: 2.962193250656128
Validation loss: 2.110546624788674

Epoch: 5| Step: 4
Training loss: 1.8997986316680908
Validation loss: 2.106992503648163

Epoch: 5| Step: 5
Training loss: 2.328014373779297
Validation loss: 2.1010425565063313

Epoch: 5| Step: 6
Training loss: 2.484673023223877
Validation loss: 2.1015164211232173

Epoch: 5| Step: 7
Training loss: 2.445578098297119
Validation loss: 2.0873974933419177

Epoch: 5| Step: 8
Training loss: 2.4941341876983643
Validation loss: 2.0756567524325464

Epoch: 5| Step: 9
Training loss: 1.7821712493896484
Validation loss: 2.0930713171600015

Epoch: 5| Step: 10
Training loss: 2.7430431842803955
Validation loss: 2.074050066291645

Epoch: 115| Step: 0
Training loss: 2.2979233264923096
Validation loss: 2.0845427141394666

Epoch: 5| Step: 1
Training loss: 2.268364667892456
Validation loss: 2.0690402036072104

Epoch: 5| Step: 2
Training loss: 2.422813892364502
Validation loss: 2.082447877494238

Epoch: 5| Step: 3
Training loss: 1.9798473119735718
Validation loss: 2.0764086631036576

Epoch: 5| Step: 4
Training loss: 2.8052725791931152
Validation loss: 2.074139864214005

Epoch: 5| Step: 5
Training loss: 2.174607515335083
Validation loss: 2.1087831194682787

Epoch: 5| Step: 6
Training loss: 2.7854561805725098
Validation loss: 2.1186104884711643

Epoch: 5| Step: 7
Training loss: 2.612494945526123
Validation loss: 2.117196911124773

Epoch: 5| Step: 8
Training loss: 1.9908027648925781
Validation loss: 2.119804537424477

Epoch: 5| Step: 9
Training loss: 2.0022449493408203
Validation loss: 2.1164714597886607

Epoch: 5| Step: 10
Training loss: 2.626208782196045
Validation loss: 2.0884802238915556

Epoch: 116| Step: 0
Training loss: 2.6839511394500732
Validation loss: 2.0784008554233018

Epoch: 5| Step: 1
Training loss: 1.7061569690704346
Validation loss: 2.0676688519857263

Epoch: 5| Step: 2
Training loss: 2.555377244949341
Validation loss: 2.0614280290501092

Epoch: 5| Step: 3
Training loss: 2.0629944801330566
Validation loss: 2.075412422098139

Epoch: 5| Step: 4
Training loss: 2.2262470722198486
Validation loss: 2.0775830079150457

Epoch: 5| Step: 5
Training loss: 2.7230112552642822
Validation loss: 2.085941408270149

Epoch: 5| Step: 6
Training loss: 2.832061290740967
Validation loss: 2.090922758143435

Epoch: 5| Step: 7
Training loss: 2.661561965942383
Validation loss: 2.1036960053187546

Epoch: 5| Step: 8
Training loss: 2.498722553253174
Validation loss: 2.112132050657785

Epoch: 5| Step: 9
Training loss: 1.7336994409561157
Validation loss: 2.1178270680930025

Epoch: 5| Step: 10
Training loss: 1.9978742599487305
Validation loss: 2.1260895165064

Epoch: 117| Step: 0
Training loss: 1.9576003551483154
Validation loss: 2.092887068307528

Epoch: 5| Step: 1
Training loss: 2.715696096420288
Validation loss: 2.0705052703939457

Epoch: 5| Step: 2
Training loss: 2.260948657989502
Validation loss: 2.075284437466693

Epoch: 5| Step: 3
Training loss: 2.6189515590667725
Validation loss: 2.072734122635216

Epoch: 5| Step: 4
Training loss: 2.6455821990966797
Validation loss: 2.0651891795537805

Epoch: 5| Step: 5
Training loss: 1.8896806240081787
Validation loss: 2.0540834831935104

Epoch: 5| Step: 6
Training loss: 2.2089645862579346
Validation loss: 2.059176598825762

Epoch: 5| Step: 7
Training loss: 2.5028557777404785
Validation loss: 2.0648990549067014

Epoch: 5| Step: 8
Training loss: 1.9726369380950928
Validation loss: 2.0637089744690926

Epoch: 5| Step: 9
Training loss: 2.3524880409240723
Validation loss: 2.100355960989511

Epoch: 5| Step: 10
Training loss: 2.4753341674804688
Validation loss: 2.1220513184865317

Epoch: 118| Step: 0
Training loss: 2.9688618183135986
Validation loss: 2.1038963563980593

Epoch: 5| Step: 1
Training loss: 3.055222272872925
Validation loss: 2.0640233344929193

Epoch: 5| Step: 2
Training loss: 1.9430630207061768
Validation loss: 2.053602527546626

Epoch: 5| Step: 3
Training loss: 1.7724529504776
Validation loss: 2.049239020193777

Epoch: 5| Step: 4
Training loss: 2.19431734085083
Validation loss: 2.044555684571625

Epoch: 5| Step: 5
Training loss: 2.7509119510650635
Validation loss: 2.0406769449992845

Epoch: 5| Step: 6
Training loss: 2.438645839691162
Validation loss: 2.04418348240596

Epoch: 5| Step: 7
Training loss: 2.461627960205078
Validation loss: 2.062366600959532

Epoch: 5| Step: 8
Training loss: 2.1554787158966064
Validation loss: 2.094029011264924

Epoch: 5| Step: 9
Training loss: 1.6197656393051147
Validation loss: 2.1112818564138105

Epoch: 5| Step: 10
Training loss: 2.524693489074707
Validation loss: 2.074942088896228

Epoch: 119| Step: 0
Training loss: 2.7608768939971924
Validation loss: 2.0532202669369277

Epoch: 5| Step: 1
Training loss: 2.4893569946289062
Validation loss: 2.052294320957635

Epoch: 5| Step: 2
Training loss: 2.3610177040100098
Validation loss: 2.05252028793417

Epoch: 5| Step: 3
Training loss: 2.1454482078552246
Validation loss: 2.040546122417655

Epoch: 5| Step: 4
Training loss: 2.915271520614624
Validation loss: 2.0407696667537896

Epoch: 5| Step: 5
Training loss: 2.295753002166748
Validation loss: 2.0439502039263324

Epoch: 5| Step: 6
Training loss: 1.5218255519866943
Validation loss: 2.0748432169678392

Epoch: 5| Step: 7
Training loss: 2.316467523574829
Validation loss: 2.115454778876356

Epoch: 5| Step: 8
Training loss: 2.439263343811035
Validation loss: 2.1629654310082875

Epoch: 5| Step: 9
Training loss: 2.418086528778076
Validation loss: 2.126033344576436

Epoch: 5| Step: 10
Training loss: 1.9416306018829346
Validation loss: 2.0887075739522136

Epoch: 120| Step: 0
Training loss: 2.720797300338745
Validation loss: 2.070322564853135

Epoch: 5| Step: 1
Training loss: 2.4739954471588135
Validation loss: 2.043961642890848

Epoch: 5| Step: 2
Training loss: 1.4486719369888306
Validation loss: 2.053659264759351

Epoch: 5| Step: 3
Training loss: 2.3372676372528076
Validation loss: 2.059648367666429

Epoch: 5| Step: 4
Training loss: 2.571746826171875
Validation loss: 2.0568331646662887

Epoch: 5| Step: 5
Training loss: 2.114692449569702
Validation loss: 2.063285986582438

Epoch: 5| Step: 6
Training loss: 2.0134568214416504
Validation loss: 2.0949044676237207

Epoch: 5| Step: 7
Training loss: 2.949622869491577
Validation loss: 2.0857189291266987

Epoch: 5| Step: 8
Training loss: 1.864013433456421
Validation loss: 2.0822678381396877

Epoch: 5| Step: 9
Training loss: 2.538151979446411
Validation loss: 2.0650851829077608

Epoch: 5| Step: 10
Training loss: 2.3036911487579346
Validation loss: 2.0429507365790744

Epoch: 121| Step: 0
Training loss: 1.9809373617172241
Validation loss: 2.049709232904578

Epoch: 5| Step: 1
Training loss: 2.1574296951293945
Validation loss: 2.0522655428096814

Epoch: 5| Step: 2
Training loss: 2.86163330078125
Validation loss: 2.0476269927076114

Epoch: 5| Step: 3
Training loss: 1.9957090616226196
Validation loss: 2.0797512249280046

Epoch: 5| Step: 4
Training loss: 2.7229037284851074
Validation loss: 2.097782006827734

Epoch: 5| Step: 5
Training loss: 1.795276403427124
Validation loss: 2.1332222761646396

Epoch: 5| Step: 6
Training loss: 2.0775837898254395
Validation loss: 2.120559154018279

Epoch: 5| Step: 7
Training loss: 2.4961676597595215
Validation loss: 2.115171863186744

Epoch: 5| Step: 8
Training loss: 2.4746527671813965
Validation loss: 2.074010859253586

Epoch: 5| Step: 9
Training loss: 2.186699390411377
Validation loss: 2.0645765232783493

Epoch: 5| Step: 10
Training loss: 2.7706663608551025
Validation loss: 2.0603324802972938

Epoch: 122| Step: 0
Training loss: 1.8297199010849
Validation loss: 2.0581843006995415

Epoch: 5| Step: 1
Training loss: 2.7312183380126953
Validation loss: 2.0527575887659544

Epoch: 5| Step: 2
Training loss: 2.921431541442871
Validation loss: 2.057481263273506

Epoch: 5| Step: 3
Training loss: 2.5832648277282715
Validation loss: 2.0489408021332114

Epoch: 5| Step: 4
Training loss: 2.3496885299682617
Validation loss: 2.0356597105662027

Epoch: 5| Step: 5
Training loss: 1.6110140085220337
Validation loss: 2.042559431445214

Epoch: 5| Step: 6
Training loss: 2.5034446716308594
Validation loss: 2.050384485593406

Epoch: 5| Step: 7
Training loss: 1.9233554601669312
Validation loss: 2.0899121620321788

Epoch: 5| Step: 8
Training loss: 2.3327529430389404
Validation loss: 2.1060364836005756

Epoch: 5| Step: 9
Training loss: 2.363258123397827
Validation loss: 2.113596272724931

Epoch: 5| Step: 10
Training loss: 2.0620620250701904
Validation loss: 2.097205062066355

Epoch: 123| Step: 0
Training loss: 2.543534517288208
Validation loss: 2.0971069669210785

Epoch: 5| Step: 1
Training loss: 1.83816659450531
Validation loss: 2.0975824530406664

Epoch: 5| Step: 2
Training loss: 2.125645875930786
Validation loss: 2.0834866608342817

Epoch: 5| Step: 3
Training loss: 2.2334446907043457
Validation loss: 2.0607043209896294

Epoch: 5| Step: 4
Training loss: 2.5465993881225586
Validation loss: 2.0629833167599094

Epoch: 5| Step: 5
Training loss: 1.9333076477050781
Validation loss: 2.0649054575991888

Epoch: 5| Step: 6
Training loss: 3.2797107696533203
Validation loss: 2.0537522762052474

Epoch: 5| Step: 7
Training loss: 2.8530564308166504
Validation loss: 2.0638683636983237

Epoch: 5| Step: 8
Training loss: 1.8405771255493164
Validation loss: 2.065598205853534

Epoch: 5| Step: 9
Training loss: 1.9065964221954346
Validation loss: 2.090202804534666

Epoch: 5| Step: 10
Training loss: 2.0282175540924072
Validation loss: 2.1048156574208248

Epoch: 124| Step: 0
Training loss: 1.3308820724487305
Validation loss: 2.0806383112425446

Epoch: 5| Step: 1
Training loss: 2.5151479244232178
Validation loss: 2.0637819818271104

Epoch: 5| Step: 2
Training loss: 1.9907604455947876
Validation loss: 2.0527529229399977

Epoch: 5| Step: 3
Training loss: 1.97176992893219
Validation loss: 2.0448535821771108

Epoch: 5| Step: 4
Training loss: 1.8795429468154907
Validation loss: 2.0412392782908615

Epoch: 5| Step: 5
Training loss: 2.479884386062622
Validation loss: 2.0562108242383568

Epoch: 5| Step: 6
Training loss: 2.986098289489746
Validation loss: 2.047010943453799

Epoch: 5| Step: 7
Training loss: 2.3156113624572754
Validation loss: 2.049401206354941

Epoch: 5| Step: 8
Training loss: 3.1967427730560303
Validation loss: 2.0255167843193136

Epoch: 5| Step: 9
Training loss: 1.7858359813690186
Validation loss: 2.024363492124824

Epoch: 5| Step: 10
Training loss: 2.678864002227783
Validation loss: 2.0383843632154566

Epoch: 125| Step: 0
Training loss: 1.6968845129013062
Validation loss: 2.0729772660040084

Epoch: 5| Step: 1
Training loss: 2.5779318809509277
Validation loss: 2.0885523519208355

Epoch: 5| Step: 2
Training loss: 2.009464740753174
Validation loss: 2.1131119587088145

Epoch: 5| Step: 3
Training loss: 2.215078353881836
Validation loss: 2.117235661834799

Epoch: 5| Step: 4
Training loss: 2.5283706188201904
Validation loss: 2.1077973381165536

Epoch: 5| Step: 5
Training loss: 1.8906638622283936
Validation loss: 2.0918842182364514

Epoch: 5| Step: 6
Training loss: 2.119467258453369
Validation loss: 2.0492173869122743

Epoch: 5| Step: 7
Training loss: 2.395299196243286
Validation loss: 2.03091920832152

Epoch: 5| Step: 8
Training loss: 2.3918778896331787
Validation loss: 2.021319199633855

Epoch: 5| Step: 9
Training loss: 2.6581547260284424
Validation loss: 2.0376305887776036

Epoch: 5| Step: 10
Training loss: 2.522675037384033
Validation loss: 2.0447197344995316

Epoch: 126| Step: 0
Training loss: 1.8060626983642578
Validation loss: 2.040678043519297

Epoch: 5| Step: 1
Training loss: 2.4404938220977783
Validation loss: 2.037287135278025

Epoch: 5| Step: 2
Training loss: 1.9919742345809937
Validation loss: 2.039354802459799

Epoch: 5| Step: 3
Training loss: 2.6852123737335205
Validation loss: 2.0523404075253393

Epoch: 5| Step: 4
Training loss: 2.2740979194641113
Validation loss: 2.0995314569883448

Epoch: 5| Step: 5
Training loss: 2.4832563400268555
Validation loss: 2.1043993452543854

Epoch: 5| Step: 6
Training loss: 1.898497223854065
Validation loss: 2.078560257470736

Epoch: 5| Step: 7
Training loss: 2.21897554397583
Validation loss: 2.045907202587333

Epoch: 5| Step: 8
Training loss: 2.415515422821045
Validation loss: 2.0260032582026657

Epoch: 5| Step: 9
Training loss: 2.138495683670044
Validation loss: 2.0136868684522566

Epoch: 5| Step: 10
Training loss: 2.427800416946411
Validation loss: 2.0310439307202577

Epoch: 127| Step: 0
Training loss: 2.5382983684539795
Validation loss: 2.019851717897641

Epoch: 5| Step: 1
Training loss: 2.510108470916748
Validation loss: 2.036832240320021

Epoch: 5| Step: 2
Training loss: 1.7767584323883057
Validation loss: 2.043053924396474

Epoch: 5| Step: 3
Training loss: 2.173729658126831
Validation loss: 2.038813983240435

Epoch: 5| Step: 4
Training loss: 2.0853610038757324
Validation loss: 2.033818471816278

Epoch: 5| Step: 5
Training loss: 2.1518709659576416
Validation loss: 2.0320820423864547

Epoch: 5| Step: 6
Training loss: 2.3834197521209717
Validation loss: 2.03599089576352

Epoch: 5| Step: 7
Training loss: 2.0407936573028564
Validation loss: 2.037858065738473

Epoch: 5| Step: 8
Training loss: 2.6465771198272705
Validation loss: 2.044380398206813

Epoch: 5| Step: 9
Training loss: 1.6453450918197632
Validation loss: 2.065774343347037

Epoch: 5| Step: 10
Training loss: 2.645209550857544
Validation loss: 2.0971207080348844

Epoch: 128| Step: 0
Training loss: 1.847355604171753
Validation loss: 2.1145586864922636

Epoch: 5| Step: 1
Training loss: 2.5128655433654785
Validation loss: 2.1130517387902863

Epoch: 5| Step: 2
Training loss: 2.05128812789917
Validation loss: 2.0989401289211806

Epoch: 5| Step: 3
Training loss: 1.8536239862442017
Validation loss: 2.094741754634406

Epoch: 5| Step: 4
Training loss: 2.146519899368286
Validation loss: 2.114533648695997

Epoch: 5| Step: 5
Training loss: 2.495826005935669
Validation loss: 2.127673751564436

Epoch: 5| Step: 6
Training loss: 3.050384998321533
Validation loss: 2.129040793706012

Epoch: 5| Step: 7
Training loss: 2.0754470825195312
Validation loss: 2.119151658909295

Epoch: 5| Step: 8
Training loss: 2.7501330375671387
Validation loss: 2.075769132183444

Epoch: 5| Step: 9
Training loss: 2.2914607524871826
Validation loss: 2.0554185349454164

Epoch: 5| Step: 10
Training loss: 1.5099955797195435
Validation loss: 2.0460126963994836

Epoch: 129| Step: 0
Training loss: 2.3580784797668457
Validation loss: 2.0369235161812074

Epoch: 5| Step: 1
Training loss: 2.4857125282287598
Validation loss: 2.044005678546044

Epoch: 5| Step: 2
Training loss: 2.387836217880249
Validation loss: 2.036334340290357

Epoch: 5| Step: 3
Training loss: 2.08628511428833
Validation loss: 2.0557839601270613

Epoch: 5| Step: 4
Training loss: 2.080188512802124
Validation loss: 2.065505099552934

Epoch: 5| Step: 5
Training loss: 2.347672939300537
Validation loss: 2.1017956733703613

Epoch: 5| Step: 6
Training loss: 2.1458444595336914
Validation loss: 2.095888158326508

Epoch: 5| Step: 7
Training loss: 2.1333584785461426
Validation loss: 2.082998985885292

Epoch: 5| Step: 8
Training loss: 1.4897722005844116
Validation loss: 2.0679060515537055

Epoch: 5| Step: 9
Training loss: 2.2640881538391113
Validation loss: 2.065979339743173

Epoch: 5| Step: 10
Training loss: 2.9819626808166504
Validation loss: 2.055681250428641

Epoch: 130| Step: 0
Training loss: 2.720231771469116
Validation loss: 2.0658559030102146

Epoch: 5| Step: 1
Training loss: 1.6932672262191772
Validation loss: 2.0517169852410593

Epoch: 5| Step: 2
Training loss: 2.5535879135131836
Validation loss: 2.050815636111844

Epoch: 5| Step: 3
Training loss: 2.204054594039917
Validation loss: 2.061024042867845

Epoch: 5| Step: 4
Training loss: 2.067134380340576
Validation loss: 2.0658333455362627

Epoch: 5| Step: 5
Training loss: 1.9809343814849854
Validation loss: 2.0671492545835433

Epoch: 5| Step: 6
Training loss: 1.9090770483016968
Validation loss: 2.084166711376559

Epoch: 5| Step: 7
Training loss: 2.890587568283081
Validation loss: 2.1054890078883015

Epoch: 5| Step: 8
Training loss: 2.274280548095703
Validation loss: 2.1429520114775626

Epoch: 5| Step: 9
Training loss: 1.896280288696289
Validation loss: 2.1617824903098484

Epoch: 5| Step: 10
Training loss: 2.152876377105713
Validation loss: 2.152493417903941

Epoch: 131| Step: 0
Training loss: 2.2595572471618652
Validation loss: 2.15295252876897

Epoch: 5| Step: 1
Training loss: 2.72365140914917
Validation loss: 2.1236257527464177

Epoch: 5| Step: 2
Training loss: 2.490107536315918
Validation loss: 2.0690228169964207

Epoch: 5| Step: 3
Training loss: 1.722520112991333
Validation loss: 2.0594721096818165

Epoch: 5| Step: 4
Training loss: 2.5240321159362793
Validation loss: 2.0708542664845786

Epoch: 5| Step: 5
Training loss: 2.3345415592193604
Validation loss: 2.0563067518254763

Epoch: 5| Step: 6
Training loss: 2.4685842990875244
Validation loss: 2.0621325918423232

Epoch: 5| Step: 7
Training loss: 1.951158881187439
Validation loss: 2.0354481563773206

Epoch: 5| Step: 8
Training loss: 2.101327419281006
Validation loss: 2.043907832073909

Epoch: 5| Step: 9
Training loss: 1.9822362661361694
Validation loss: 2.076885231079594

Epoch: 5| Step: 10
Training loss: 2.0216352939605713
Validation loss: 2.137705490153323

Epoch: 132| Step: 0
Training loss: 1.8410940170288086
Validation loss: 2.2250965244026593

Epoch: 5| Step: 1
Training loss: 2.1914234161376953
Validation loss: 2.272529561032531

Epoch: 5| Step: 2
Training loss: 2.3632023334503174
Validation loss: 2.2507337549681306

Epoch: 5| Step: 3
Training loss: 3.0118651390075684
Validation loss: 2.1964277631493023

Epoch: 5| Step: 4
Training loss: 2.273632526397705
Validation loss: 2.1211391392574517

Epoch: 5| Step: 5
Training loss: 2.1651198863983154
Validation loss: 2.0491898367481847

Epoch: 5| Step: 6
Training loss: 2.164057970046997
Validation loss: 2.026642043103454

Epoch: 5| Step: 7
Training loss: 2.228574514389038
Validation loss: 2.0398087629707913

Epoch: 5| Step: 8
Training loss: 1.7507193088531494
Validation loss: 2.0491617148922336

Epoch: 5| Step: 9
Training loss: 2.9408411979675293
Validation loss: 2.062081475411692

Epoch: 5| Step: 10
Training loss: 2.156376600265503
Validation loss: 2.083984826200752

Epoch: 133| Step: 0
Training loss: 2.383021593093872
Validation loss: 2.0877274851645193

Epoch: 5| Step: 1
Training loss: 2.2535510063171387
Validation loss: 2.077890287163437

Epoch: 5| Step: 2
Training loss: 1.7052175998687744
Validation loss: 2.0743397640925583

Epoch: 5| Step: 3
Training loss: 1.7330138683319092
Validation loss: 2.049613905209367

Epoch: 5| Step: 4
Training loss: 2.5500309467315674
Validation loss: 2.0834602412357124

Epoch: 5| Step: 5
Training loss: 2.156292676925659
Validation loss: 2.131698464834562

Epoch: 5| Step: 6
Training loss: 2.2231040000915527
Validation loss: 2.1742711067199707

Epoch: 5| Step: 7
Training loss: 2.78464674949646
Validation loss: 2.185611829962782

Epoch: 5| Step: 8
Training loss: 1.9754759073257446
Validation loss: 2.135088279683103

Epoch: 5| Step: 9
Training loss: 2.4380712509155273
Validation loss: 2.1166741130172566

Epoch: 5| Step: 10
Training loss: 2.2746365070343018
Validation loss: 2.1047460020229383

Epoch: 134| Step: 0
Training loss: 2.306358575820923
Validation loss: 2.0572472644108597

Epoch: 5| Step: 1
Training loss: 1.857418417930603
Validation loss: 2.0619052456271265

Epoch: 5| Step: 2
Training loss: 2.12563157081604
Validation loss: 2.0494388457267516

Epoch: 5| Step: 3
Training loss: 2.4669690132141113
Validation loss: 2.0599201751011673

Epoch: 5| Step: 4
Training loss: 2.1153512001037598
Validation loss: 2.0676587679052867

Epoch: 5| Step: 5
Training loss: 1.894073486328125
Validation loss: 2.063671955498316

Epoch: 5| Step: 6
Training loss: 2.287370204925537
Validation loss: 2.0754876905871975

Epoch: 5| Step: 7
Training loss: 2.275083065032959
Validation loss: 2.089949820631294

Epoch: 5| Step: 8
Training loss: 2.5519561767578125
Validation loss: 2.1227190289446103

Epoch: 5| Step: 9
Training loss: 1.690734624862671
Validation loss: 2.1495188564382572

Epoch: 5| Step: 10
Training loss: 2.476031541824341
Validation loss: 2.2302663838991554

Epoch: 135| Step: 0
Training loss: 2.3264830112457275
Validation loss: 2.258201576048328

Epoch: 5| Step: 1
Training loss: 2.2406387329101562
Validation loss: 2.18428865555794

Epoch: 5| Step: 2
Training loss: 2.191746950149536
Validation loss: 2.1239745193912136

Epoch: 5| Step: 3
Training loss: 1.9510501623153687
Validation loss: 2.092895976958736

Epoch: 5| Step: 4
Training loss: 2.12035870552063
Validation loss: 2.0784539817481913

Epoch: 5| Step: 5
Training loss: 2.560647487640381
Validation loss: 2.0710946180487193

Epoch: 5| Step: 6
Training loss: 2.122332811355591
Validation loss: 2.055147168456867

Epoch: 5| Step: 7
Training loss: 1.6351211071014404
Validation loss: 2.0459993782863823

Epoch: 5| Step: 8
Training loss: 2.4880974292755127
Validation loss: 2.06598372228684

Epoch: 5| Step: 9
Training loss: 2.4664313793182373
Validation loss: 2.1021215172224146

Epoch: 5| Step: 10
Training loss: 2.3259479999542236
Validation loss: 2.1465112393902195

Epoch: 136| Step: 0
Training loss: 1.4309489727020264
Validation loss: 2.1937809464752034

Epoch: 5| Step: 1
Training loss: 2.43048095703125
Validation loss: 2.248344131695327

Epoch: 5| Step: 2
Training loss: 2.564563274383545
Validation loss: 2.3104096792077504

Epoch: 5| Step: 3
Training loss: 2.5243828296661377
Validation loss: 2.2860643402222665

Epoch: 5| Step: 4
Training loss: 2.052189588546753
Validation loss: 2.237099414230675

Epoch: 5| Step: 5
Training loss: 2.1690549850463867
Validation loss: 2.1719987059152253

Epoch: 5| Step: 6
Training loss: 2.1266770362854004
Validation loss: 2.1062387676649195

Epoch: 5| Step: 7
Training loss: 1.9395780563354492
Validation loss: 2.083731289832823

Epoch: 5| Step: 8
Training loss: 2.4753241539001465
Validation loss: 2.085073386469195

Epoch: 5| Step: 9
Training loss: 2.300166368484497
Validation loss: 2.0896644797376407

Epoch: 5| Step: 10
Training loss: 2.593026876449585
Validation loss: 2.093852722516624

Epoch: 137| Step: 0
Training loss: 2.473595380783081
Validation loss: 2.1036648468304704

Epoch: 5| Step: 1
Training loss: 1.758432149887085
Validation loss: 2.115690956833542

Epoch: 5| Step: 2
Training loss: 1.2851628065109253
Validation loss: 2.109491184193601

Epoch: 5| Step: 3
Training loss: 2.2929775714874268
Validation loss: 2.1591243948987735

Epoch: 5| Step: 4
Training loss: 2.0721640586853027
Validation loss: 2.243782720258159

Epoch: 5| Step: 5
Training loss: 2.509705066680908
Validation loss: 2.4346992097875124

Epoch: 5| Step: 6
Training loss: 3.27606201171875
Validation loss: 2.381401249157485

Epoch: 5| Step: 7
Training loss: 1.906272530555725
Validation loss: 2.29395729239269

Epoch: 5| Step: 8
Training loss: 2.0839450359344482
Validation loss: 2.1771636137398342

Epoch: 5| Step: 9
Training loss: 3.0659618377685547
Validation loss: 2.154456374465778

Epoch: 5| Step: 10
Training loss: 2.0198848247528076
Validation loss: 2.131495319386964

Epoch: 138| Step: 0
Training loss: 2.5721356868743896
Validation loss: 2.1332512081310315

Epoch: 5| Step: 1
Training loss: 2.487710952758789
Validation loss: 2.1445235103689213

Epoch: 5| Step: 2
Training loss: 2.46047043800354
Validation loss: 2.1350743360416864

Epoch: 5| Step: 3
Training loss: 2.4867191314697266
Validation loss: 2.1465146874868744

Epoch: 5| Step: 4
Training loss: 2.6221091747283936
Validation loss: 2.126626523592139

Epoch: 5| Step: 5
Training loss: 2.492743492126465
Validation loss: 2.0789663278928368

Epoch: 5| Step: 6
Training loss: 1.8860056400299072
Validation loss: 2.06916626550818

Epoch: 5| Step: 7
Training loss: 1.378273606300354
Validation loss: 2.047709253526503

Epoch: 5| Step: 8
Training loss: 2.00484037399292
Validation loss: 2.040231935439571

Epoch: 5| Step: 9
Training loss: 1.9913368225097656
Validation loss: 2.04522902734818

Epoch: 5| Step: 10
Training loss: 1.6038172245025635
Validation loss: 2.0637754419798493

Epoch: 139| Step: 0
Training loss: 1.5523195266723633
Validation loss: 2.0660849232827463

Epoch: 5| Step: 1
Training loss: 2.4037585258483887
Validation loss: 2.061068614323934

Epoch: 5| Step: 2
Training loss: 2.4966063499450684
Validation loss: 2.0486933890209404

Epoch: 5| Step: 3
Training loss: 2.0663256645202637
Validation loss: 2.0446932238917195

Epoch: 5| Step: 4
Training loss: 2.3656318187713623
Validation loss: 2.0759623935145717

Epoch: 5| Step: 5
Training loss: 2.153214693069458
Validation loss: 2.088696502870129

Epoch: 5| Step: 6
Training loss: 1.5161088705062866
Validation loss: 2.114300040788548

Epoch: 5| Step: 7
Training loss: 1.9814074039459229
Validation loss: 2.1015341615164154

Epoch: 5| Step: 8
Training loss: 1.8771425485610962
Validation loss: 2.103426120614493

Epoch: 5| Step: 9
Training loss: 2.4487156867980957
Validation loss: 2.1344579368509273

Epoch: 5| Step: 10
Training loss: 2.6381239891052246
Validation loss: 2.17904475427443

Epoch: 140| Step: 0
Training loss: 2.441521406173706
Validation loss: 2.1435071729844615

Epoch: 5| Step: 1
Training loss: 1.9109891653060913
Validation loss: 2.144702431976154

Epoch: 5| Step: 2
Training loss: 1.8113434314727783
Validation loss: 2.150726492686938

Epoch: 5| Step: 3
Training loss: 2.166367530822754
Validation loss: 2.133944442195277

Epoch: 5| Step: 4
Training loss: 2.231607675552368
Validation loss: 2.1166392667319185

Epoch: 5| Step: 5
Training loss: 2.131364583969116
Validation loss: 2.1191873050505117

Epoch: 5| Step: 6
Training loss: 2.3182711601257324
Validation loss: 2.1176450470442414

Epoch: 5| Step: 7
Training loss: 2.551438570022583
Validation loss: 2.123628741951399

Epoch: 5| Step: 8
Training loss: 2.0484023094177246
Validation loss: 2.093270355655301

Epoch: 5| Step: 9
Training loss: 2.3337020874023438
Validation loss: 2.077564354865782

Epoch: 5| Step: 10
Training loss: 1.1270225048065186
Validation loss: 2.0885010637262815

Epoch: 141| Step: 0
Training loss: 2.3851559162139893
Validation loss: 2.078502574274617

Epoch: 5| Step: 1
Training loss: 2.1369552612304688
Validation loss: 2.067922656254102

Epoch: 5| Step: 2
Training loss: 1.8958238363265991
Validation loss: 2.0695070938397477

Epoch: 5| Step: 3
Training loss: 1.6177196502685547
Validation loss: 2.0589881007389357

Epoch: 5| Step: 4
Training loss: 2.559858560562134
Validation loss: 2.0759569342418382

Epoch: 5| Step: 5
Training loss: 2.262218952178955
Validation loss: 2.077102284277639

Epoch: 5| Step: 6
Training loss: 2.0902342796325684
Validation loss: 2.0781556598601805

Epoch: 5| Step: 7
Training loss: 1.661256194114685
Validation loss: 2.0898557850109634

Epoch: 5| Step: 8
Training loss: 1.477684736251831
Validation loss: 2.1025891586016585

Epoch: 5| Step: 9
Training loss: 2.5157315731048584
Validation loss: 2.101839623143596

Epoch: 5| Step: 10
Training loss: 2.370389938354492
Validation loss: 2.0975659483222553

Epoch: 142| Step: 0
Training loss: 2.4613258838653564
Validation loss: 2.0907102092619865

Epoch: 5| Step: 1
Training loss: 2.1634411811828613
Validation loss: 2.1120087638978036

Epoch: 5| Step: 2
Training loss: 1.9595752954483032
Validation loss: 2.13023365441189

Epoch: 5| Step: 3
Training loss: 1.9953582286834717
Validation loss: 2.1629188214578936

Epoch: 5| Step: 4
Training loss: 2.0858683586120605
Validation loss: 2.1945265595630934

Epoch: 5| Step: 5
Training loss: 2.583383560180664
Validation loss: 2.1811015862290577

Epoch: 5| Step: 6
Training loss: 2.1248021125793457
Validation loss: 2.1347912831973006

Epoch: 5| Step: 7
Training loss: 2.3277571201324463
Validation loss: 2.1099707439381588

Epoch: 5| Step: 8
Training loss: 1.4499657154083252
Validation loss: 2.0756077433145173

Epoch: 5| Step: 9
Training loss: 2.188438892364502
Validation loss: 2.078249041752149

Epoch: 5| Step: 10
Training loss: 1.756667137145996
Validation loss: 2.0805726564058693

Epoch: 143| Step: 0
Training loss: 1.9954452514648438
Validation loss: 2.089840817195113

Epoch: 5| Step: 1
Training loss: 2.0077390670776367
Validation loss: 2.0770561387462

Epoch: 5| Step: 2
Training loss: 1.9704395532608032
Validation loss: 2.1088561293899373

Epoch: 5| Step: 3
Training loss: 2.880502223968506
Validation loss: 2.1289240544842136

Epoch: 5| Step: 4
Training loss: 1.7477664947509766
Validation loss: 2.1398651830611692

Epoch: 5| Step: 5
Training loss: 2.355794668197632
Validation loss: 2.17299626463203

Epoch: 5| Step: 6
Training loss: 1.8690130710601807
Validation loss: 2.177428171198855

Epoch: 5| Step: 7
Training loss: 2.6602942943573
Validation loss: 2.1534646621314426

Epoch: 5| Step: 8
Training loss: 1.807409644126892
Validation loss: 2.1316159386788645

Epoch: 5| Step: 9
Training loss: 1.9297106266021729
Validation loss: 2.0966827151595906

Epoch: 5| Step: 10
Training loss: 1.5461941957473755
Validation loss: 2.062966545422872

Epoch: 144| Step: 0
Training loss: 2.4923534393310547
Validation loss: 2.03704434569164

Epoch: 5| Step: 1
Training loss: 1.5769298076629639
Validation loss: 2.0124673990793127

Epoch: 5| Step: 2
Training loss: 2.4601001739501953
Validation loss: 2.0066567262013755

Epoch: 5| Step: 3
Training loss: 2.01644229888916
Validation loss: 2.028680711664179

Epoch: 5| Step: 4
Training loss: 1.545011043548584
Validation loss: 2.0266816564785537

Epoch: 5| Step: 5
Training loss: 2.2585818767547607
Validation loss: 2.0383445883309967

Epoch: 5| Step: 6
Training loss: 2.303290843963623
Validation loss: 2.0781973485023744

Epoch: 5| Step: 7
Training loss: 1.8901493549346924
Validation loss: 2.111449092947027

Epoch: 5| Step: 8
Training loss: 1.8242031335830688
Validation loss: 2.128784156614734

Epoch: 5| Step: 9
Training loss: 2.0963025093078613
Validation loss: 2.125049029627154

Epoch: 5| Step: 10
Training loss: 2.2568905353546143
Validation loss: 2.1112565199534097

Epoch: 145| Step: 0
Training loss: 1.82228684425354
Validation loss: 2.090524515798015

Epoch: 5| Step: 1
Training loss: 1.4781612157821655
Validation loss: 2.065371531312184

Epoch: 5| Step: 2
Training loss: 1.6892766952514648
Validation loss: 2.0580023770691245

Epoch: 5| Step: 3
Training loss: 2.297546148300171
Validation loss: 2.0559141071893836

Epoch: 5| Step: 4
Training loss: 1.8929497003555298
Validation loss: 2.0629627986620833

Epoch: 5| Step: 5
Training loss: 1.8151658773422241
Validation loss: 2.058105371331656

Epoch: 5| Step: 6
Training loss: 2.6311984062194824
Validation loss: 2.0711933207768265

Epoch: 5| Step: 7
Training loss: 2.2047133445739746
Validation loss: 2.068316312246425

Epoch: 5| Step: 8
Training loss: 2.7704215049743652
Validation loss: 2.0803511629822435

Epoch: 5| Step: 9
Training loss: 1.6203035116195679
Validation loss: 2.094567346316512

Epoch: 5| Step: 10
Training loss: 2.0004751682281494
Validation loss: 2.1102443190031153

Epoch: 146| Step: 0
Training loss: 2.2039942741394043
Validation loss: 2.1050798098246255

Epoch: 5| Step: 1
Training loss: 2.0478978157043457
Validation loss: 2.1351766714485745

Epoch: 5| Step: 2
Training loss: 2.2971885204315186
Validation loss: 2.1264285810532106

Epoch: 5| Step: 3
Training loss: 1.9532912969589233
Validation loss: 2.1263251355899278

Epoch: 5| Step: 4
Training loss: 1.9380600452423096
Validation loss: 2.1193601239112114

Epoch: 5| Step: 5
Training loss: 2.3003883361816406
Validation loss: 2.092112454034949

Epoch: 5| Step: 6
Training loss: 1.947718620300293
Validation loss: 2.0656160539196384

Epoch: 5| Step: 7
Training loss: 1.9928390979766846
Validation loss: 2.06734904678919

Epoch: 5| Step: 8
Training loss: 1.102545142173767
Validation loss: 2.0717371509921167

Epoch: 5| Step: 9
Training loss: 1.9002466201782227
Validation loss: 2.078307710668092

Epoch: 5| Step: 10
Training loss: 2.4120090007781982
Validation loss: 2.079178005136469

Epoch: 147| Step: 0
Training loss: 1.714068055152893
Validation loss: 2.1102319725098146

Epoch: 5| Step: 1
Training loss: 2.6675329208374023
Validation loss: 2.1319277824894076

Epoch: 5| Step: 2
Training loss: 2.2992825508117676
Validation loss: 2.1290202756081857

Epoch: 5| Step: 3
Training loss: 1.6002557277679443
Validation loss: 2.1392129031560754

Epoch: 5| Step: 4
Training loss: 2.5230538845062256
Validation loss: 2.1406263305294897

Epoch: 5| Step: 5
Training loss: 2.1148457527160645
Validation loss: 2.1598785692645657

Epoch: 5| Step: 6
Training loss: 1.8334598541259766
Validation loss: 2.1556626648031254

Epoch: 5| Step: 7
Training loss: 1.701473593711853
Validation loss: 2.1509369778376755

Epoch: 5| Step: 8
Training loss: 2.138199806213379
Validation loss: 2.1189827816460722

Epoch: 5| Step: 9
Training loss: 1.5606553554534912
Validation loss: 2.10433381090882

Epoch: 5| Step: 10
Training loss: 1.7533763647079468
Validation loss: 2.0981817271119807

Epoch: 148| Step: 0
Training loss: 2.0992202758789062
Validation loss: 2.1058099474958194

Epoch: 5| Step: 1
Training loss: 2.6742055416107178
Validation loss: 2.0828795407408025

Epoch: 5| Step: 2
Training loss: 2.2323455810546875
Validation loss: 2.068173900727303

Epoch: 5| Step: 3
Training loss: 2.1620798110961914
Validation loss: 2.07596605823886

Epoch: 5| Step: 4
Training loss: 1.5694220066070557
Validation loss: 2.0869566202163696

Epoch: 5| Step: 5
Training loss: 2.1254725456237793
Validation loss: 2.0948458666442544

Epoch: 5| Step: 6
Training loss: 1.9841206073760986
Validation loss: 2.1086392428285334

Epoch: 5| Step: 7
Training loss: 1.5711264610290527
Validation loss: 2.1638051412438832

Epoch: 5| Step: 8
Training loss: 1.3454880714416504
Validation loss: 2.193526875588202

Epoch: 5| Step: 9
Training loss: 1.6145093441009521
Validation loss: 2.21787501406926

Epoch: 5| Step: 10
Training loss: 2.5081565380096436
Validation loss: 2.213030356232838

Epoch: 149| Step: 0
Training loss: 1.8015880584716797
Validation loss: 2.184742722460019

Epoch: 5| Step: 1
Training loss: 2.3507561683654785
Validation loss: 2.121403476243378

Epoch: 5| Step: 2
Training loss: 1.7960809469223022
Validation loss: 2.068283070800125

Epoch: 5| Step: 3
Training loss: 1.9997198581695557
Validation loss: 2.0512640988954933

Epoch: 5| Step: 4
Training loss: 2.0028254985809326
Validation loss: 2.0399657423778246

Epoch: 5| Step: 5
Training loss: 2.2165639400482178
Validation loss: 2.0339399050640803

Epoch: 5| Step: 6
Training loss: 1.7971513271331787
Validation loss: 2.037840497109198

Epoch: 5| Step: 7
Training loss: 2.531095504760742
Validation loss: 2.0527064492625575

Epoch: 5| Step: 8
Training loss: 2.3438937664031982
Validation loss: 2.0486393051762737

Epoch: 5| Step: 9
Training loss: 1.3017759323120117
Validation loss: 2.0707395743298274

Epoch: 5| Step: 10
Training loss: 2.091737747192383
Validation loss: 2.0956671750673683

Epoch: 150| Step: 0
Training loss: 2.7437891960144043
Validation loss: 2.126646485379947

Epoch: 5| Step: 1
Training loss: 1.9931367635726929
Validation loss: 2.145818066853349

Epoch: 5| Step: 2
Training loss: 2.031327247619629
Validation loss: 2.163574610987017

Epoch: 5| Step: 3
Training loss: 2.037001848220825
Validation loss: 2.1684943347848873

Epoch: 5| Step: 4
Training loss: 2.3992180824279785
Validation loss: 2.199790390588904

Epoch: 5| Step: 5
Training loss: 1.6519620418548584
Validation loss: 2.180123221489691

Epoch: 5| Step: 6
Training loss: 1.6857677698135376
Validation loss: 2.1587574763964583

Epoch: 5| Step: 7
Training loss: 1.9468759298324585
Validation loss: 2.146821880853304

Epoch: 5| Step: 8
Training loss: 1.3056278228759766
Validation loss: 2.1219055960255284

Epoch: 5| Step: 9
Training loss: 1.439653992652893
Validation loss: 2.1016038630598333

Epoch: 5| Step: 10
Training loss: 2.5200250148773193
Validation loss: 2.097622552225667

Epoch: 151| Step: 0
Training loss: 2.1470656394958496
Validation loss: 2.093952335337157

Epoch: 5| Step: 1
Training loss: 2.3582146167755127
Validation loss: 2.097777940893686

Epoch: 5| Step: 2
Training loss: 1.601251244544983
Validation loss: 2.0866620053527174

Epoch: 5| Step: 3
Training loss: 2.172747850418091
Validation loss: 2.090684128063981

Epoch: 5| Step: 4
Training loss: 1.6039035320281982
Validation loss: 2.1052194513300413

Epoch: 5| Step: 5
Training loss: 2.6389758586883545
Validation loss: 2.1062983492369294

Epoch: 5| Step: 6
Training loss: 1.9742295742034912
Validation loss: 2.120568270324379

Epoch: 5| Step: 7
Training loss: 1.7203114032745361
Validation loss: 2.0899812688109694

Epoch: 5| Step: 8
Training loss: 1.703237771987915
Validation loss: 2.080161920157812

Epoch: 5| Step: 9
Training loss: 1.563593864440918
Validation loss: 2.0884391851322626

Epoch: 5| Step: 10
Training loss: 1.8838211297988892
Validation loss: 2.06904274161144

Epoch: 152| Step: 0
Training loss: 1.9048395156860352
Validation loss: 2.066920557329732

Epoch: 5| Step: 1
Training loss: 1.1924210786819458
Validation loss: 2.0509075541650095

Epoch: 5| Step: 2
Training loss: 1.8675899505615234
Validation loss: 2.084476601692938

Epoch: 5| Step: 3
Training loss: 1.8414385318756104
Validation loss: 2.075279717804283

Epoch: 5| Step: 4
Training loss: 1.8943687677383423
Validation loss: 2.0676962637132212

Epoch: 5| Step: 5
Training loss: 1.3884481191635132
Validation loss: 2.072015357273881

Epoch: 5| Step: 6
Training loss: 1.9791291952133179
Validation loss: 2.079950168568601

Epoch: 5| Step: 7
Training loss: 2.11798357963562
Validation loss: 2.0758489793346775

Epoch: 5| Step: 8
Training loss: 2.170813798904419
Validation loss: 2.0786175394570954

Epoch: 5| Step: 9
Training loss: 2.2317728996276855
Validation loss: 2.09937197162259

Epoch: 5| Step: 10
Training loss: 2.6724395751953125
Validation loss: 2.1024933681693128

Epoch: 153| Step: 0
Training loss: 2.025944948196411
Validation loss: 2.1077246127590055

Epoch: 5| Step: 1
Training loss: 2.5696749687194824
Validation loss: 2.1340049915416266

Epoch: 5| Step: 2
Training loss: 1.6661052703857422
Validation loss: 2.1187853684989353

Epoch: 5| Step: 3
Training loss: 1.7392860651016235
Validation loss: 2.1072588197646605

Epoch: 5| Step: 4
Training loss: 1.9942731857299805
Validation loss: 2.0912641171486146

Epoch: 5| Step: 5
Training loss: 2.030808925628662
Validation loss: 2.0988028100741807

Epoch: 5| Step: 6
Training loss: 1.8408291339874268
Validation loss: 2.097634538527458

Epoch: 5| Step: 7
Training loss: 1.506605863571167
Validation loss: 2.0846522623492825

Epoch: 5| Step: 8
Training loss: 1.7112691402435303
Validation loss: 2.07336849294683

Epoch: 5| Step: 9
Training loss: 2.0315611362457275
Validation loss: 2.069872316493783

Epoch: 5| Step: 10
Training loss: 2.2274930477142334
Validation loss: 2.074490631780317

Epoch: 154| Step: 0
Training loss: 2.2000365257263184
Validation loss: 2.0649823911728395

Epoch: 5| Step: 1
Training loss: 1.717430830001831
Validation loss: 2.0919410528675204

Epoch: 5| Step: 2
Training loss: 1.787517786026001
Validation loss: 2.0901915693795807

Epoch: 5| Step: 3
Training loss: 1.4777723550796509
Validation loss: 2.098552632075484

Epoch: 5| Step: 4
Training loss: 1.3312524557113647
Validation loss: 2.1035936494027414

Epoch: 5| Step: 5
Training loss: 2.0401253700256348
Validation loss: 2.113524498478059

Epoch: 5| Step: 6
Training loss: 2.1039981842041016
Validation loss: 2.110506707622159

Epoch: 5| Step: 7
Training loss: 1.3161883354187012
Validation loss: 2.1016571983214347

Epoch: 5| Step: 8
Training loss: 2.9433789253234863
Validation loss: 2.0910295645395913

Epoch: 5| Step: 9
Training loss: 1.634853720664978
Validation loss: 2.068136315191946

Epoch: 5| Step: 10
Training loss: 2.2737600803375244
Validation loss: 2.054135222588816

Epoch: 155| Step: 0
Training loss: 2.3724570274353027
Validation loss: 2.0693052532852336

Epoch: 5| Step: 1
Training loss: 1.911783218383789
Validation loss: 2.067430042451428

Epoch: 5| Step: 2
Training loss: 2.1795542240142822
Validation loss: 2.084729620205459

Epoch: 5| Step: 3
Training loss: 1.1655018329620361
Validation loss: 2.0794527210215086

Epoch: 5| Step: 4
Training loss: 2.392641544342041
Validation loss: 2.089977938641784

Epoch: 5| Step: 5
Training loss: 2.2608225345611572
Validation loss: 2.093431488160164

Epoch: 5| Step: 6
Training loss: 1.5302491188049316
Validation loss: 2.1281801103263773

Epoch: 5| Step: 7
Training loss: 1.6654484272003174
Validation loss: 2.1476616500526347

Epoch: 5| Step: 8
Training loss: 2.66275691986084
Validation loss: 2.1522319316864014

Epoch: 5| Step: 9
Training loss: 1.3548296689987183
Validation loss: 2.141008029701889

Epoch: 5| Step: 10
Training loss: 1.095715880393982
Validation loss: 2.119130383255661

Epoch: 156| Step: 0
Training loss: 2.313131809234619
Validation loss: 2.1013856908326507

Epoch: 5| Step: 1
Training loss: 1.4639084339141846
Validation loss: 2.085161203979164

Epoch: 5| Step: 2
Training loss: 1.9805138111114502
Validation loss: 2.0966151042651107

Epoch: 5| Step: 3
Training loss: 1.3798587322235107
Validation loss: 2.09478166795546

Epoch: 5| Step: 4
Training loss: 1.9793710708618164
Validation loss: 2.081818478081816

Epoch: 5| Step: 5
Training loss: 1.8029813766479492
Validation loss: 2.0747420044355493

Epoch: 5| Step: 6
Training loss: 1.866467833518982
Validation loss: 2.073268844235328

Epoch: 5| Step: 7
Training loss: 2.2399706840515137
Validation loss: 2.060921408796823

Epoch: 5| Step: 8
Training loss: 2.046384334564209
Validation loss: 2.0731510603299705

Epoch: 5| Step: 9
Training loss: 1.6626501083374023
Validation loss: 2.0873040640225975

Epoch: 5| Step: 10
Training loss: 1.6656444072723389
Validation loss: 2.106549868019678

Epoch: 157| Step: 0
Training loss: 1.641035795211792
Validation loss: 2.1071940058021137

Epoch: 5| Step: 1
Training loss: 2.371333599090576
Validation loss: 2.0580875104473484

Epoch: 5| Step: 2
Training loss: 1.472109079360962
Validation loss: 2.048410825831916

Epoch: 5| Step: 3
Training loss: 2.060999631881714
Validation loss: 2.0453318216467418

Epoch: 5| Step: 4
Training loss: 1.3808454275131226
Validation loss: 2.0450500237044467

Epoch: 5| Step: 5
Training loss: 2.175459384918213
Validation loss: 2.0450010658592306

Epoch: 5| Step: 6
Training loss: 1.1870763301849365
Validation loss: 2.0697464455840406

Epoch: 5| Step: 7
Training loss: 1.6879997253417969
Validation loss: 2.0805554441226426

Epoch: 5| Step: 8
Training loss: 2.077385187149048
Validation loss: 2.091359010306738

Epoch: 5| Step: 9
Training loss: 2.2197208404541016
Validation loss: 2.097119305723457

Epoch: 5| Step: 10
Training loss: 2.1283481121063232
Validation loss: 2.1186510183477916

Epoch: 158| Step: 0
Training loss: 1.4219156503677368
Validation loss: 2.1258366313031924

Epoch: 5| Step: 1
Training loss: 1.3413642644882202
Validation loss: 2.1618196169535318

Epoch: 5| Step: 2
Training loss: 1.6340421438217163
Validation loss: 2.1562624413480043

Epoch: 5| Step: 3
Training loss: 1.7307322025299072
Validation loss: 2.1510156252050914

Epoch: 5| Step: 4
Training loss: 1.782372236251831
Validation loss: 2.126923414968675

Epoch: 5| Step: 5
Training loss: 2.4382872581481934
Validation loss: 2.114608400611467

Epoch: 5| Step: 6
Training loss: 1.9769456386566162
Validation loss: 2.0616124983756774

Epoch: 5| Step: 7
Training loss: 1.5625728368759155
Validation loss: 2.057399892037915

Epoch: 5| Step: 8
Training loss: 1.8635705709457397
Validation loss: 2.054612572475146

Epoch: 5| Step: 9
Training loss: 2.207547187805176
Validation loss: 2.0461075036756453

Epoch: 5| Step: 10
Training loss: 2.2197792530059814
Validation loss: 2.04885390240659

Epoch: 159| Step: 0
Training loss: 1.647392988204956
Validation loss: 2.0520575995086343

Epoch: 5| Step: 1
Training loss: 1.8990615606307983
Validation loss: 2.064777446049516

Epoch: 5| Step: 2
Training loss: 1.5809924602508545
Validation loss: 2.0827238495631883

Epoch: 5| Step: 3
Training loss: 1.7262006998062134
Validation loss: 2.0887348216067076

Epoch: 5| Step: 4
Training loss: 2.084796190261841
Validation loss: 2.0909327230145855

Epoch: 5| Step: 5
Training loss: 1.6637245416641235
Validation loss: 2.100479887377831

Epoch: 5| Step: 6
Training loss: 1.3675451278686523
Validation loss: 2.0913945449295865

Epoch: 5| Step: 7
Training loss: 1.4862538576126099
Validation loss: 2.0869504520970006

Epoch: 5| Step: 8
Training loss: 1.990654706954956
Validation loss: 2.0836176974799043

Epoch: 5| Step: 9
Training loss: 2.031322956085205
Validation loss: 2.0791823428164244

Epoch: 5| Step: 10
Training loss: 2.6725690364837646
Validation loss: 2.0980855675153833

Epoch: 160| Step: 0
Training loss: 2.057161808013916
Validation loss: 2.104517326560072

Epoch: 5| Step: 1
Training loss: 1.705004096031189
Validation loss: 2.090249561494397

Epoch: 5| Step: 2
Training loss: 1.5837923288345337
Validation loss: 2.0971004450193016

Epoch: 5| Step: 3
Training loss: 2.1677722930908203
Validation loss: 2.076996849429223

Epoch: 5| Step: 4
Training loss: 2.1441843509674072
Validation loss: 2.096599704475813

Epoch: 5| Step: 5
Training loss: 1.504366397857666
Validation loss: 2.0697070655002388

Epoch: 5| Step: 6
Training loss: 1.8101050853729248
Validation loss: 2.0520505853878555

Epoch: 5| Step: 7
Training loss: 2.065328598022461
Validation loss: 2.0471794720618957

Epoch: 5| Step: 8
Training loss: 1.1487418413162231
Validation loss: 2.05068560313153

Epoch: 5| Step: 9
Training loss: 1.7301088571548462
Validation loss: 2.054463240408128

Epoch: 5| Step: 10
Training loss: 2.105801820755005
Validation loss: 2.0738265027282057

Epoch: 161| Step: 0
Training loss: 1.7716079950332642
Validation loss: 2.075366853385843

Epoch: 5| Step: 1
Training loss: 1.9498714208602905
Validation loss: 2.0803422927856445

Epoch: 5| Step: 2
Training loss: 1.8730659484863281
Validation loss: 2.0643314392335954

Epoch: 5| Step: 3
Training loss: 2.106271982192993
Validation loss: 2.075857062493601

Epoch: 5| Step: 4
Training loss: 1.7850443124771118
Validation loss: 2.0555138357224

Epoch: 5| Step: 5
Training loss: 0.966823399066925
Validation loss: 2.0595538564907607

Epoch: 5| Step: 6
Training loss: 1.7353270053863525
Validation loss: 2.0380760956836004

Epoch: 5| Step: 7
Training loss: 2.0207183361053467
Validation loss: 2.053935076600762

Epoch: 5| Step: 8
Training loss: 1.85433030128479
Validation loss: 2.0754677352084907

Epoch: 5| Step: 9
Training loss: 1.94140625
Validation loss: 2.076832971265239

Epoch: 5| Step: 10
Training loss: 1.6405284404754639
Validation loss: 2.0867214715608986

Epoch: 162| Step: 0
Training loss: 1.822717308998108
Validation loss: 2.0871954194961058

Epoch: 5| Step: 1
Training loss: 2.146127939224243
Validation loss: 2.082663269453151

Epoch: 5| Step: 2
Training loss: 1.5978540182113647
Validation loss: 2.0736643729671353

Epoch: 5| Step: 3
Training loss: 1.5797898769378662
Validation loss: 2.10617256933643

Epoch: 5| Step: 4
Training loss: 1.8991920948028564
Validation loss: 2.0822493568543465

Epoch: 5| Step: 5
Training loss: 1.6423832178115845
Validation loss: 2.0838278749937653

Epoch: 5| Step: 6
Training loss: 2.0163838863372803
Validation loss: 2.083642171275231

Epoch: 5| Step: 7
Training loss: 2.1199545860290527
Validation loss: 2.081914331323357

Epoch: 5| Step: 8
Training loss: 1.7553281784057617
Validation loss: 2.0876140235572733

Epoch: 5| Step: 9
Training loss: 1.5094283819198608
Validation loss: 2.1130567571168304

Epoch: 5| Step: 10
Training loss: 1.6525439023971558
Validation loss: 2.107441794487738

Epoch: 163| Step: 0
Training loss: 1.9157047271728516
Validation loss: 2.0832637843265327

Epoch: 5| Step: 1
Training loss: 1.626436471939087
Validation loss: 2.0366788025825255

Epoch: 5| Step: 2
Training loss: 1.684743881225586
Validation loss: 2.004292445798074

Epoch: 5| Step: 3
Training loss: 1.6167774200439453
Validation loss: 2.00576005699814

Epoch: 5| Step: 4
Training loss: 2.331029176712036
Validation loss: 2.000857291683074

Epoch: 5| Step: 5
Training loss: 1.939186692237854
Validation loss: 2.0021058487635788

Epoch: 5| Step: 6
Training loss: 1.3834733963012695
Validation loss: 2.022575036171944

Epoch: 5| Step: 7
Training loss: 1.5821127891540527
Validation loss: 2.031209115059145

Epoch: 5| Step: 8
Training loss: 2.0304436683654785
Validation loss: 2.049765230506979

Epoch: 5| Step: 9
Training loss: 1.3706107139587402
Validation loss: 2.043920010648748

Epoch: 5| Step: 10
Training loss: 1.882459282875061
Validation loss: 2.0560378566865

Epoch: 164| Step: 0
Training loss: 1.7994104623794556
Validation loss: 2.050643556861467

Epoch: 5| Step: 1
Training loss: 1.9274898767471313
Validation loss: 2.0962861430260444

Epoch: 5| Step: 2
Training loss: 2.0957558155059814
Validation loss: 2.0718338592078096

Epoch: 5| Step: 3
Training loss: 1.6955296993255615
Validation loss: 2.0726085644896313

Epoch: 5| Step: 4
Training loss: 1.4957871437072754
Validation loss: 2.0658084936039423

Epoch: 5| Step: 5
Training loss: 1.2718394994735718
Validation loss: 2.0519529414433304

Epoch: 5| Step: 6
Training loss: 1.7529407739639282
Validation loss: 2.0508427235387985

Epoch: 5| Step: 7
Training loss: 1.6382369995117188
Validation loss: 2.045225953543058

Epoch: 5| Step: 8
Training loss: 2.0693771839141846
Validation loss: 2.0570646511611117

Epoch: 5| Step: 9
Training loss: 1.684769868850708
Validation loss: 2.039374442510707

Epoch: 5| Step: 10
Training loss: 1.6318782567977905
Validation loss: 2.028539434556038

Epoch: 165| Step: 0
Training loss: 1.947725534439087
Validation loss: 2.0443573638957035

Epoch: 5| Step: 1
Training loss: 1.607904076576233
Validation loss: 2.0415167398350214

Epoch: 5| Step: 2
Training loss: 1.8254921436309814
Validation loss: 2.05867854497766

Epoch: 5| Step: 3
Training loss: 1.5856187343597412
Validation loss: 2.0752132015843547

Epoch: 5| Step: 4
Training loss: 1.3257296085357666
Validation loss: 2.0583717861483173

Epoch: 5| Step: 5
Training loss: 2.184990644454956
Validation loss: 2.06593003067919

Epoch: 5| Step: 6
Training loss: 1.1509466171264648
Validation loss: 2.065127065104823

Epoch: 5| Step: 7
Training loss: 1.6650596857070923
Validation loss: 2.0481124103710218

Epoch: 5| Step: 8
Training loss: 1.8413883447647095
Validation loss: 2.05385576012314

Epoch: 5| Step: 9
Training loss: 1.6727653741836548
Validation loss: 2.0614162106667795

Epoch: 5| Step: 10
Training loss: 1.9678878784179688
Validation loss: 2.07334908875086

Epoch: 166| Step: 0
Training loss: 2.1356537342071533
Validation loss: 2.0714134785436813

Epoch: 5| Step: 1
Training loss: 1.5140306949615479
Validation loss: 2.068045316203948

Epoch: 5| Step: 2
Training loss: 2.1496376991271973
Validation loss: 2.0872035693096858

Epoch: 5| Step: 3
Training loss: 1.7117855548858643
Validation loss: 2.073040387963736

Epoch: 5| Step: 4
Training loss: 2.1309516429901123
Validation loss: 2.057248624422217

Epoch: 5| Step: 5
Training loss: 1.6049531698226929
Validation loss: 2.02888346615658

Epoch: 5| Step: 6
Training loss: 1.1607121229171753
Validation loss: 2.0280872878207954

Epoch: 5| Step: 7
Training loss: 1.716409683227539
Validation loss: 2.023040868902719

Epoch: 5| Step: 8
Training loss: 1.94106924533844
Validation loss: 2.0367985694639144

Epoch: 5| Step: 9
Training loss: 1.2741585969924927
Validation loss: 2.0415096129140546

Epoch: 5| Step: 10
Training loss: 1.2314943075180054
Validation loss: 2.0391249297767557

Epoch: 167| Step: 0
Training loss: 1.7862545251846313
Validation loss: 2.0361620533850884

Epoch: 5| Step: 1
Training loss: 1.5583490133285522
Validation loss: 2.048115813603965

Epoch: 5| Step: 2
Training loss: 1.3836610317230225
Validation loss: 2.0591844538206696

Epoch: 5| Step: 3
Training loss: 1.363720178604126
Validation loss: 2.0450866594109485

Epoch: 5| Step: 4
Training loss: 1.540676474571228
Validation loss: 2.0390626461275163

Epoch: 5| Step: 5
Training loss: 2.3981494903564453
Validation loss: 2.031779864782928

Epoch: 5| Step: 6
Training loss: 2.055778980255127
Validation loss: 2.0186100852104927

Epoch: 5| Step: 7
Training loss: 1.4182389974594116
Validation loss: 2.014857444711911

Epoch: 5| Step: 8
Training loss: 1.7156559228897095
Validation loss: 2.01575400880588

Epoch: 5| Step: 9
Training loss: 1.6471267938613892
Validation loss: 2.0121542484529558

Epoch: 5| Step: 10
Training loss: 1.518576741218567
Validation loss: 2.0144840389169674

Epoch: 168| Step: 0
Training loss: 1.8929338455200195
Validation loss: 2.0242346512374056

Epoch: 5| Step: 1
Training loss: 1.9262397289276123
Validation loss: 2.01265440705002

Epoch: 5| Step: 2
Training loss: 1.4104816913604736
Validation loss: 2.0085840430310977

Epoch: 5| Step: 3
Training loss: 1.5791367292404175
Validation loss: 1.9956681087452879

Epoch: 5| Step: 4
Training loss: 1.4434082508087158
Validation loss: 1.991049958813575

Epoch: 5| Step: 5
Training loss: 1.7045953273773193
Validation loss: 2.0169993510810276

Epoch: 5| Step: 6
Training loss: 1.432227373123169
Validation loss: 2.0180167536581717

Epoch: 5| Step: 7
Training loss: 1.5710641145706177
Validation loss: 2.0146034122795187

Epoch: 5| Step: 8
Training loss: 1.5362255573272705
Validation loss: 2.03812530989288

Epoch: 5| Step: 9
Training loss: 1.8282268047332764
Validation loss: 2.04303373829011

Epoch: 5| Step: 10
Training loss: 2.069418430328369
Validation loss: 2.072871449173138

Epoch: 169| Step: 0
Training loss: 1.6994037628173828
Validation loss: 2.1222937158358994

Epoch: 5| Step: 1
Training loss: 1.5876245498657227
Validation loss: 2.1485688814552883

Epoch: 5| Step: 2
Training loss: 1.6671756505966187
Validation loss: 2.157107819793045

Epoch: 5| Step: 3
Training loss: 2.1348140239715576
Validation loss: 2.1502122814937303

Epoch: 5| Step: 4
Training loss: 1.3111793994903564
Validation loss: 2.0986980853542203

Epoch: 5| Step: 5
Training loss: 1.5727885961532593
Validation loss: 2.078809607413507

Epoch: 5| Step: 6
Training loss: 2.255488872528076
Validation loss: 2.0440618748305948

Epoch: 5| Step: 7
Training loss: 1.754962682723999
Validation loss: 2.0113298046973442

Epoch: 5| Step: 8
Training loss: 1.4223030805587769
Validation loss: 2.0164556734023558

Epoch: 5| Step: 9
Training loss: 1.678689956665039
Validation loss: 2.0075583329764743

Epoch: 5| Step: 10
Training loss: 1.4055477380752563
Validation loss: 2.0362912634367585

Epoch: 170| Step: 0
Training loss: 1.939801812171936
Validation loss: 2.0699280564503004

Epoch: 5| Step: 1
Training loss: 1.4851233959197998
Validation loss: 2.062763567893736

Epoch: 5| Step: 2
Training loss: 1.332037329673767
Validation loss: 2.019966552334447

Epoch: 5| Step: 3
Training loss: 1.6516001224517822
Validation loss: 2.003417215039653

Epoch: 5| Step: 4
Training loss: 1.890750527381897
Validation loss: 1.9928432562017953

Epoch: 5| Step: 5
Training loss: 1.581542730331421
Validation loss: 2.0017781693448304

Epoch: 5| Step: 6
Training loss: 1.6497948169708252
Validation loss: 2.0108641180940854

Epoch: 5| Step: 7
Training loss: 1.625391960144043
Validation loss: 2.0328457663136144

Epoch: 5| Step: 8
Training loss: 1.7361385822296143
Validation loss: 2.063891295463808

Epoch: 5| Step: 9
Training loss: 1.6408430337905884
Validation loss: 2.097984578019829

Epoch: 5| Step: 10
Training loss: 1.598516821861267
Validation loss: 2.133696654791473

Epoch: 171| Step: 0
Training loss: 2.5823864936828613
Validation loss: 2.1478323757007556

Epoch: 5| Step: 1
Training loss: 1.4811506271362305
Validation loss: 2.163634072067917

Epoch: 5| Step: 2
Training loss: 1.7609379291534424
Validation loss: 2.149662370322853

Epoch: 5| Step: 3
Training loss: 1.1326591968536377
Validation loss: 2.1133831111333703

Epoch: 5| Step: 4
Training loss: 1.7974376678466797
Validation loss: 2.0930180216348298

Epoch: 5| Step: 5
Training loss: 1.6342060565948486
Validation loss: 2.0675142401008197

Epoch: 5| Step: 6
Training loss: 1.8229001760482788
Validation loss: 2.042879481469431

Epoch: 5| Step: 7
Training loss: 1.5414329767227173
Validation loss: 2.023197898300745

Epoch: 5| Step: 8
Training loss: 1.2493953704833984
Validation loss: 2.014106224941951

Epoch: 5| Step: 9
Training loss: 1.4220366477966309
Validation loss: 1.9843638686723606

Epoch: 5| Step: 10
Training loss: 1.6329748630523682
Validation loss: 1.987979555642733

Epoch: 172| Step: 0
Training loss: 1.8815094232559204
Validation loss: 1.9942655819718555

Epoch: 5| Step: 1
Training loss: 1.754852294921875
Validation loss: 1.9991022873950262

Epoch: 5| Step: 2
Training loss: 2.0417189598083496
Validation loss: 2.0309011346550396

Epoch: 5| Step: 3
Training loss: 1.5896258354187012
Validation loss: 2.0511667574605634

Epoch: 5| Step: 4
Training loss: 1.2157931327819824
Validation loss: 2.0597321564151394

Epoch: 5| Step: 5
Training loss: 2.018850803375244
Validation loss: 2.036518484033564

Epoch: 5| Step: 6
Training loss: 1.1305184364318848
Validation loss: 2.0264209598623295

Epoch: 5| Step: 7
Training loss: 1.5483105182647705
Validation loss: 2.0062559932790776

Epoch: 5| Step: 8
Training loss: 1.589517593383789
Validation loss: 1.9982591239354943

Epoch: 5| Step: 9
Training loss: 1.565061092376709
Validation loss: 1.9938670947987547

Epoch: 5| Step: 10
Training loss: 1.4322940111160278
Validation loss: 2.0184692336666967

Epoch: 173| Step: 0
Training loss: 1.5051560401916504
Validation loss: 2.026345617027693

Epoch: 5| Step: 1
Training loss: 1.632555603981018
Validation loss: 2.0398655924745785

Epoch: 5| Step: 2
Training loss: 1.6966110467910767
Validation loss: 2.049311640442059

Epoch: 5| Step: 3
Training loss: 1.827837586402893
Validation loss: 2.0541846008710962

Epoch: 5| Step: 4
Training loss: 1.6565078496932983
Validation loss: 2.0528330059461695

Epoch: 5| Step: 5
Training loss: 1.5443542003631592
Validation loss: 2.0511303511998986

Epoch: 5| Step: 6
Training loss: 1.3904085159301758
Validation loss: 2.0414546484588296

Epoch: 5| Step: 7
Training loss: 1.337425708770752
Validation loss: 2.054674889451714

Epoch: 5| Step: 8
Training loss: 1.4006927013397217
Validation loss: 2.0566580103289698

Epoch: 5| Step: 9
Training loss: 1.6384341716766357
Validation loss: 2.074902444757441

Epoch: 5| Step: 10
Training loss: 2.2193567752838135
Validation loss: 2.0365547813395017

Epoch: 174| Step: 0
Training loss: 2.033484697341919
Validation loss: 2.030120195881013

Epoch: 5| Step: 1
Training loss: 1.486956000328064
Validation loss: 2.004698502120151

Epoch: 5| Step: 2
Training loss: 1.387587547302246
Validation loss: 1.9846692136538926

Epoch: 5| Step: 3
Training loss: 2.0447726249694824
Validation loss: 2.0016778912595523

Epoch: 5| Step: 4
Training loss: 1.3866158723831177
Validation loss: 1.9794675983408445

Epoch: 5| Step: 5
Training loss: 1.5392775535583496
Validation loss: 1.9844936350340485

Epoch: 5| Step: 6
Training loss: 1.6788444519042969
Validation loss: 1.9935230952437206

Epoch: 5| Step: 7
Training loss: 1.361724615097046
Validation loss: 1.9959404545445596

Epoch: 5| Step: 8
Training loss: 1.4761945009231567
Validation loss: 1.9920167461518319

Epoch: 5| Step: 9
Training loss: 1.063852071762085
Validation loss: 1.993714032634612

Epoch: 5| Step: 10
Training loss: 1.879847526550293
Validation loss: 2.0268031909901607

Epoch: 175| Step: 0
Training loss: 2.238901376724243
Validation loss: 2.035336245772659

Epoch: 5| Step: 1
Training loss: 1.603374719619751
Validation loss: 2.0476908632504043

Epoch: 5| Step: 2
Training loss: 1.395199179649353
Validation loss: 2.0519516903867006

Epoch: 5| Step: 3
Training loss: 1.4118751287460327
Validation loss: 2.0682909732223838

Epoch: 5| Step: 4
Training loss: 1.6876475811004639
Validation loss: 2.0938190490968767

Epoch: 5| Step: 5
Training loss: 1.4492853879928589
Validation loss: 2.088042894999186

Epoch: 5| Step: 6
Training loss: 1.5830806493759155
Validation loss: 2.069686597393405

Epoch: 5| Step: 7
Training loss: 1.6498792171478271
Validation loss: 2.053195067631301

Epoch: 5| Step: 8
Training loss: 0.9101835489273071
Validation loss: 2.043980153658057

Epoch: 5| Step: 9
Training loss: 1.3156497478485107
Validation loss: 2.0337078238046296

Epoch: 5| Step: 10
Training loss: 1.8848953247070312
Validation loss: 2.0401190557787494

Epoch: 176| Step: 0
Training loss: 1.6862157583236694
Validation loss: 2.025913089834234

Epoch: 5| Step: 1
Training loss: 1.4192883968353271
Validation loss: 1.9957661641541349

Epoch: 5| Step: 2
Training loss: 1.4834259748458862
Validation loss: 1.982858714237008

Epoch: 5| Step: 3
Training loss: 1.8654502630233765
Validation loss: 1.9734657041488155

Epoch: 5| Step: 4
Training loss: 1.6996721029281616
Validation loss: 1.961057283545053

Epoch: 5| Step: 5
Training loss: 1.6090431213378906
Validation loss: 1.99202851838963

Epoch: 5| Step: 6
Training loss: 1.5719953775405884
Validation loss: 2.001755452925159

Epoch: 5| Step: 7
Training loss: 1.1860599517822266
Validation loss: 2.0340707020093034

Epoch: 5| Step: 8
Training loss: 1.498199701309204
Validation loss: 2.029625554238596

Epoch: 5| Step: 9
Training loss: 1.3381000757217407
Validation loss: 2.0362462023253083

Epoch: 5| Step: 10
Training loss: 1.8182752132415771
Validation loss: 2.0572536158305343

Epoch: 177| Step: 0
Training loss: 1.4048912525177002
Validation loss: 2.0586456867956344

Epoch: 5| Step: 1
Training loss: 1.892215371131897
Validation loss: 2.0736754555856027

Epoch: 5| Step: 2
Training loss: 1.4842877388000488
Validation loss: 2.0514788448169665

Epoch: 5| Step: 3
Training loss: 1.6431020498275757
Validation loss: 2.048722482496692

Epoch: 5| Step: 4
Training loss: 1.19834303855896
Validation loss: 2.043025844840593

Epoch: 5| Step: 5
Training loss: 1.2212646007537842
Validation loss: 2.014656277113063

Epoch: 5| Step: 6
Training loss: 1.7100902795791626
Validation loss: 2.0180088973814443

Epoch: 5| Step: 7
Training loss: 1.5727646350860596
Validation loss: 2.0094583906153196

Epoch: 5| Step: 8
Training loss: 2.2223196029663086
Validation loss: 2.025159743524367

Epoch: 5| Step: 9
Training loss: 0.8734156489372253
Validation loss: 2.0190607924615183

Epoch: 5| Step: 10
Training loss: 1.8260307312011719
Validation loss: 2.0329647294936644

Epoch: 178| Step: 0
Training loss: 2.0318567752838135
Validation loss: 2.0498283819485734

Epoch: 5| Step: 1
Training loss: 1.4938522577285767
Validation loss: 2.040553528775451

Epoch: 5| Step: 2
Training loss: 1.363743782043457
Validation loss: 2.052931950938317

Epoch: 5| Step: 3
Training loss: 1.9808166027069092
Validation loss: 2.050713146886518

Epoch: 5| Step: 4
Training loss: 1.2493722438812256
Validation loss: 2.06390356632971

Epoch: 5| Step: 5
Training loss: 1.5986783504486084
Validation loss: 2.060627791189378

Epoch: 5| Step: 6
Training loss: 1.5562816858291626
Validation loss: 2.0475348887904996

Epoch: 5| Step: 7
Training loss: 1.4645971059799194
Validation loss: 2.042092784758537

Epoch: 5| Step: 8
Training loss: 1.653870940208435
Validation loss: 2.0135035566104356

Epoch: 5| Step: 9
Training loss: 1.2113264799118042
Validation loss: 2.0000210115986485

Epoch: 5| Step: 10
Training loss: 1.456263542175293
Validation loss: 1.9770365427899104

Epoch: 179| Step: 0
Training loss: 1.5238032341003418
Validation loss: 1.973982721246699

Epoch: 5| Step: 1
Training loss: 1.125794768333435
Validation loss: 1.989908032519843

Epoch: 5| Step: 2
Training loss: 1.9593868255615234
Validation loss: 2.002244390467162

Epoch: 5| Step: 3
Training loss: 2.234109878540039
Validation loss: 1.964449926089215

Epoch: 5| Step: 4
Training loss: 1.3648040294647217
Validation loss: 1.9791364157071678

Epoch: 5| Step: 5
Training loss: 1.4566545486450195
Validation loss: 1.979062113710629

Epoch: 5| Step: 6
Training loss: 1.5055395364761353
Validation loss: 2.008435926129741

Epoch: 5| Step: 7
Training loss: 1.2066900730133057
Validation loss: 2.045978548706219

Epoch: 5| Step: 8
Training loss: 1.8491971492767334
Validation loss: 2.072361669232768

Epoch: 5| Step: 9
Training loss: 1.5639569759368896
Validation loss: 2.013455330684621

Epoch: 5| Step: 10
Training loss: 0.8569715023040771
Validation loss: 2.0126052415499123

Epoch: 180| Step: 0
Training loss: 1.3379712104797363
Validation loss: 2.009974000274494

Epoch: 5| Step: 1
Training loss: 1.7369766235351562
Validation loss: 2.001275835498687

Epoch: 5| Step: 2
Training loss: 1.6204248666763306
Validation loss: 2.0090128093637447

Epoch: 5| Step: 3
Training loss: 1.0927762985229492
Validation loss: 2.029322857497841

Epoch: 5| Step: 4
Training loss: 1.5070302486419678
Validation loss: 2.015453933387674

Epoch: 5| Step: 5
Training loss: 1.5275218486785889
Validation loss: 2.0129765977141676

Epoch: 5| Step: 6
Training loss: 1.5520660877227783
Validation loss: 2.014695546960318

Epoch: 5| Step: 7
Training loss: 1.701629638671875
Validation loss: 1.9955302528155747

Epoch: 5| Step: 8
Training loss: 1.5958162546157837
Validation loss: 2.0012835841025076

Epoch: 5| Step: 9
Training loss: 1.6200387477874756
Validation loss: 1.9890163649794876

Epoch: 5| Step: 10
Training loss: 1.1380383968353271
Validation loss: 2.0012931400729763

Epoch: 181| Step: 0
Training loss: 1.7444738149642944
Validation loss: 1.988583008448283

Epoch: 5| Step: 1
Training loss: 1.0531492233276367
Validation loss: 1.9886958599090576

Epoch: 5| Step: 2
Training loss: 1.515882968902588
Validation loss: 2.019230341398588

Epoch: 5| Step: 3
Training loss: 1.6584552526474
Validation loss: 2.0767085520170068

Epoch: 5| Step: 4
Training loss: 1.5401146411895752
Validation loss: 2.103202868533391

Epoch: 5| Step: 5
Training loss: 1.8580694198608398
Validation loss: 2.127698493260209

Epoch: 5| Step: 6
Training loss: 1.4293463230133057
Validation loss: 2.1529827246101956

Epoch: 5| Step: 7
Training loss: 1.3968298435211182
Validation loss: 2.1206865105577695

Epoch: 5| Step: 8
Training loss: 1.7095792293548584
Validation loss: 2.092592789280799

Epoch: 5| Step: 9
Training loss: 1.2327712774276733
Validation loss: 2.045277945456966

Epoch: 5| Step: 10
Training loss: 1.262253999710083
Validation loss: 2.019898727375974

Epoch: 182| Step: 0
Training loss: 1.8574529886245728
Validation loss: 1.999430582087527

Epoch: 5| Step: 1
Training loss: 1.4519705772399902
Validation loss: 1.9675326885715607

Epoch: 5| Step: 2
Training loss: 1.553560495376587
Validation loss: 1.9676321706464213

Epoch: 5| Step: 3
Training loss: 1.3799679279327393
Validation loss: 1.9850395623073782

Epoch: 5| Step: 4
Training loss: 0.8314579129219055
Validation loss: 1.9967938238574612

Epoch: 5| Step: 5
Training loss: 1.7676560878753662
Validation loss: 2.0379538638617403

Epoch: 5| Step: 6
Training loss: 1.8710079193115234
Validation loss: 2.0596471909553773

Epoch: 5| Step: 7
Training loss: 2.04305100440979
Validation loss: 2.057841463755536

Epoch: 5| Step: 8
Training loss: 1.543997049331665
Validation loss: 2.0602711567314724

Epoch: 5| Step: 9
Training loss: 0.6531339883804321
Validation loss: 2.0518106722062632

Epoch: 5| Step: 10
Training loss: 1.1213340759277344
Validation loss: 2.024682967893539

Epoch: 183| Step: 0
Training loss: 1.508711576461792
Validation loss: 2.0434608023653746

Epoch: 5| Step: 1
Training loss: 1.6595484018325806
Validation loss: 2.0362376730929137

Epoch: 5| Step: 2
Training loss: 0.8484875559806824
Validation loss: 2.0341306553092053

Epoch: 5| Step: 3
Training loss: 1.4828341007232666
Validation loss: 2.015688573160479

Epoch: 5| Step: 4
Training loss: 1.7737948894500732
Validation loss: 2.0142191353664605

Epoch: 5| Step: 5
Training loss: 1.0881134271621704
Validation loss: 1.9967119078482352

Epoch: 5| Step: 6
Training loss: 1.2436662912368774
Validation loss: 1.979075372859996

Epoch: 5| Step: 7
Training loss: 1.6909366846084595
Validation loss: 2.034262172637447

Epoch: 5| Step: 8
Training loss: 1.818942666053772
Validation loss: 2.068230798167567

Epoch: 5| Step: 9
Training loss: 1.457878589630127
Validation loss: 2.0778225775687926

Epoch: 5| Step: 10
Training loss: 1.4661948680877686
Validation loss: 2.0478848206099642

Epoch: 184| Step: 0
Training loss: 1.4386122226715088
Validation loss: 2.032869804290033

Epoch: 5| Step: 1
Training loss: 1.8227627277374268
Validation loss: 2.0096615898993706

Epoch: 5| Step: 2
Training loss: 1.5450226068496704
Validation loss: 1.978044673960696

Epoch: 5| Step: 3
Training loss: 1.292030692100525
Validation loss: 1.966893075614847

Epoch: 5| Step: 4
Training loss: 1.4422403573989868
Validation loss: 1.9667559080226447

Epoch: 5| Step: 5
Training loss: 1.3155677318572998
Validation loss: 1.9650148550669353

Epoch: 5| Step: 6
Training loss: 1.3134976625442505
Validation loss: 1.9941682507914882

Epoch: 5| Step: 7
Training loss: 1.2452147006988525
Validation loss: 2.0072302946480374

Epoch: 5| Step: 8
Training loss: 1.137727975845337
Validation loss: 2.061660408973694

Epoch: 5| Step: 9
Training loss: 1.8677135705947876
Validation loss: 2.068135720427318

Epoch: 5| Step: 10
Training loss: 1.6761478185653687
Validation loss: 2.0841789835242817

Epoch: 185| Step: 0
Training loss: 1.5758740901947021
Validation loss: 2.0851341652613815

Epoch: 5| Step: 1
Training loss: 1.7692852020263672
Validation loss: 2.0242887748185026

Epoch: 5| Step: 2
Training loss: 1.5963313579559326
Validation loss: 2.016916880043604

Epoch: 5| Step: 3
Training loss: 1.4814136028289795
Validation loss: 2.0038042273572696

Epoch: 5| Step: 4
Training loss: 0.9985092878341675
Validation loss: 1.9931447864860616

Epoch: 5| Step: 5
Training loss: 1.5983883142471313
Validation loss: 2.0029294670269056

Epoch: 5| Step: 6
Training loss: 1.436257243156433
Validation loss: 2.0117214956591205

Epoch: 5| Step: 7
Training loss: 0.9200948476791382
Validation loss: 1.993467753933322

Epoch: 5| Step: 8
Training loss: 1.1094045639038086
Validation loss: 1.9894645547354093

Epoch: 5| Step: 9
Training loss: 1.636227011680603
Validation loss: 1.9909711025094474

Epoch: 5| Step: 10
Training loss: 1.6123533248901367
Validation loss: 1.9657099554615636

Epoch: 186| Step: 0
Training loss: 1.1339197158813477
Validation loss: 1.9818385570280013

Epoch: 5| Step: 1
Training loss: 1.7075456380844116
Validation loss: 1.9796818071796047

Epoch: 5| Step: 2
Training loss: 1.3397796154022217
Validation loss: 1.990630119077621

Epoch: 5| Step: 3
Training loss: 1.2731420993804932
Validation loss: 2.0233240563382386

Epoch: 5| Step: 4
Training loss: 1.5359280109405518
Validation loss: 2.031477406460752

Epoch: 5| Step: 5
Training loss: 1.9107627868652344
Validation loss: 2.023133864966772

Epoch: 5| Step: 6
Training loss: 1.470382571220398
Validation loss: 2.0412364723861858

Epoch: 5| Step: 7
Training loss: 1.1163694858551025
Validation loss: 2.02163194071862

Epoch: 5| Step: 8
Training loss: 1.1844043731689453
Validation loss: 2.0062866595483597

Epoch: 5| Step: 9
Training loss: 1.3908398151397705
Validation loss: 2.015113748529906

Epoch: 5| Step: 10
Training loss: 1.6658344268798828
Validation loss: 2.028434794436219

Epoch: 187| Step: 0
Training loss: 1.300107479095459
Validation loss: 1.9876367481805945

Epoch: 5| Step: 1
Training loss: 1.0883110761642456
Validation loss: 1.9958709363014466

Epoch: 5| Step: 2
Training loss: 2.1607108116149902
Validation loss: 1.990612014647453

Epoch: 5| Step: 3
Training loss: 1.483262300491333
Validation loss: 1.9948654097895469

Epoch: 5| Step: 4
Training loss: 1.1699955463409424
Validation loss: 1.997534332736846

Epoch: 5| Step: 5
Training loss: 1.1095097064971924
Validation loss: 2.0000812802263486

Epoch: 5| Step: 6
Training loss: 1.3683768510818481
Validation loss: 1.9553583027214132

Epoch: 5| Step: 7
Training loss: 1.7455421686172485
Validation loss: 1.9586626457911667

Epoch: 5| Step: 8
Training loss: 1.0825130939483643
Validation loss: 1.9393919911435855

Epoch: 5| Step: 9
Training loss: 1.6729463338851929
Validation loss: 1.9325570252633864

Epoch: 5| Step: 10
Training loss: 1.7221542596817017
Validation loss: 1.9732531501400856

Epoch: 188| Step: 0
Training loss: 1.8391094207763672
Validation loss: 1.9869516870026946

Epoch: 5| Step: 1
Training loss: 1.7976582050323486
Validation loss: 2.015974478055072

Epoch: 5| Step: 2
Training loss: 1.5115714073181152
Validation loss: 1.9999876329975743

Epoch: 5| Step: 3
Training loss: 1.5677764415740967
Validation loss: 1.9854030198948358

Epoch: 5| Step: 4
Training loss: 1.082471251487732
Validation loss: 1.993775911228631

Epoch: 5| Step: 5
Training loss: 1.3969625234603882
Validation loss: 2.0070411120691607

Epoch: 5| Step: 6
Training loss: 1.121463418006897
Validation loss: 2.006393850490611

Epoch: 5| Step: 7
Training loss: 0.9659067392349243
Validation loss: 2.008697784075173

Epoch: 5| Step: 8
Training loss: 1.5391275882720947
Validation loss: 2.0008544550147107

Epoch: 5| Step: 9
Training loss: 1.2599668502807617
Validation loss: 1.9791024807960755

Epoch: 5| Step: 10
Training loss: 1.5287714004516602
Validation loss: 1.9899303951571066

Epoch: 189| Step: 0
Training loss: 1.191825032234192
Validation loss: 1.9989514504709551

Epoch: 5| Step: 1
Training loss: 1.5716044902801514
Validation loss: 1.9908915514587073

Epoch: 5| Step: 2
Training loss: 1.3990094661712646
Validation loss: 2.012867340477564

Epoch: 5| Step: 3
Training loss: 1.15049147605896
Validation loss: 1.998376105421333

Epoch: 5| Step: 4
Training loss: 1.001617670059204
Validation loss: 1.987092287309708

Epoch: 5| Step: 5
Training loss: 1.583554983139038
Validation loss: 2.037710041128179

Epoch: 5| Step: 6
Training loss: 1.0142402648925781
Validation loss: 2.069258748844106

Epoch: 5| Step: 7
Training loss: 1.801748514175415
Validation loss: 2.0890758383658623

Epoch: 5| Step: 8
Training loss: 1.4579646587371826
Validation loss: 2.1115705133766256

Epoch: 5| Step: 9
Training loss: 1.5560603141784668
Validation loss: 2.059054272149199

Epoch: 5| Step: 10
Training loss: 1.8837839365005493
Validation loss: 1.9781717895179667

Epoch: 190| Step: 0
Training loss: 1.4610989093780518
Validation loss: 1.9429363422496344

Epoch: 5| Step: 1
Training loss: 1.2192949056625366
Validation loss: 1.9314587680242394

Epoch: 5| Step: 2
Training loss: 1.380448341369629
Validation loss: 1.9467167290308143

Epoch: 5| Step: 3
Training loss: 1.2838404178619385
Validation loss: 1.927567817831552

Epoch: 5| Step: 4
Training loss: 1.1522223949432373
Validation loss: 1.953805241533505

Epoch: 5| Step: 5
Training loss: 1.773229956626892
Validation loss: 1.9675834717289094

Epoch: 5| Step: 6
Training loss: 1.226330280303955
Validation loss: 2.0000157804899317

Epoch: 5| Step: 7
Training loss: 1.6004241704940796
Validation loss: 2.0170614052844305

Epoch: 5| Step: 8
Training loss: 1.39365816116333
Validation loss: 2.0427556012266423

Epoch: 5| Step: 9
Training loss: 1.2766830921173096
Validation loss: 2.0551039941849245

Epoch: 5| Step: 10
Training loss: 1.4076194763183594
Validation loss: 2.0745749858117875

Epoch: 191| Step: 0
Training loss: 1.5564329624176025
Validation loss: 2.0482120257551952

Epoch: 5| Step: 1
Training loss: 1.0850675106048584
Validation loss: 1.9980501513327322

Epoch: 5| Step: 2
Training loss: 1.1221344470977783
Validation loss: 1.9851017049563828

Epoch: 5| Step: 3
Training loss: 1.5049002170562744
Validation loss: 1.9582623397150347

Epoch: 5| Step: 4
Training loss: 0.9901917576789856
Validation loss: 1.973054075753817

Epoch: 5| Step: 5
Training loss: 1.2562363147735596
Validation loss: 1.9621962103792416

Epoch: 5| Step: 6
Training loss: 1.699865698814392
Validation loss: 1.9605145556952364

Epoch: 5| Step: 7
Training loss: 1.4015371799468994
Validation loss: 1.9592791680366761

Epoch: 5| Step: 8
Training loss: 1.942514181137085
Validation loss: 1.9504594520855976

Epoch: 5| Step: 9
Training loss: 1.2073739767074585
Validation loss: 1.9791783325133785

Epoch: 5| Step: 10
Training loss: 0.9490313529968262
Validation loss: 1.9868951330902755

Epoch: 192| Step: 0
Training loss: 0.9671101570129395
Validation loss: 1.9821567073945077

Epoch: 5| Step: 1
Training loss: 1.1801121234893799
Validation loss: 2.0085542471178117

Epoch: 5| Step: 2
Training loss: 1.471034049987793
Validation loss: 1.9981029290024952

Epoch: 5| Step: 3
Training loss: 1.2351572513580322
Validation loss: 2.0029896125998548

Epoch: 5| Step: 4
Training loss: 1.6416330337524414
Validation loss: 1.977916185573865

Epoch: 5| Step: 5
Training loss: 1.969822883605957
Validation loss: 1.981142864432386

Epoch: 5| Step: 6
Training loss: 1.6562879085540771
Validation loss: 1.9844215595594017

Epoch: 5| Step: 7
Training loss: 1.300811529159546
Validation loss: 1.9697561469129337

Epoch: 5| Step: 8
Training loss: 1.3151185512542725
Validation loss: 1.9686106302404915

Epoch: 5| Step: 9
Training loss: 0.6777969598770142
Validation loss: 1.9769958142311341

Epoch: 5| Step: 10
Training loss: 1.2695618867874146
Validation loss: 1.9824207162344327

Epoch: 193| Step: 0
Training loss: 1.0411057472229004
Validation loss: 2.017114195772397

Epoch: 5| Step: 1
Training loss: 1.0553392171859741
Validation loss: 2.0323445373965847

Epoch: 5| Step: 2
Training loss: 1.7557796239852905
Validation loss: 2.075635926697844

Epoch: 5| Step: 3
Training loss: 0.9782969355583191
Validation loss: 2.0501706190006708

Epoch: 5| Step: 4
Training loss: 1.5560729503631592
Validation loss: 2.030610410116052

Epoch: 5| Step: 5
Training loss: 1.3745100498199463
Validation loss: 2.0367776822018366

Epoch: 5| Step: 6
Training loss: 1.400869607925415
Validation loss: 2.041565728443925

Epoch: 5| Step: 7
Training loss: 1.4963926076889038
Validation loss: 1.9889676981074835

Epoch: 5| Step: 8
Training loss: 1.2783973217010498
Validation loss: 1.9792306577005694

Epoch: 5| Step: 9
Training loss: 1.255380392074585
Validation loss: 1.965645552963339

Epoch: 5| Step: 10
Training loss: 1.8646485805511475
Validation loss: 1.956994286147497

Epoch: 194| Step: 0
Training loss: 1.4439857006072998
Validation loss: 1.9615750338441582

Epoch: 5| Step: 1
Training loss: 1.2369105815887451
Validation loss: 2.009521057528834

Epoch: 5| Step: 2
Training loss: 1.5211982727050781
Validation loss: 2.045455273761544

Epoch: 5| Step: 3
Training loss: 1.5223639011383057
Validation loss: 2.0569008319608626

Epoch: 5| Step: 4
Training loss: 0.8872219324111938
Validation loss: 2.0631112052548315

Epoch: 5| Step: 5
Training loss: 1.2504253387451172
Validation loss: 2.0680068962035643

Epoch: 5| Step: 6
Training loss: 1.7976977825164795
Validation loss: 2.0716447984018633

Epoch: 5| Step: 7
Training loss: 0.8948551416397095
Validation loss: 2.03658018830002

Epoch: 5| Step: 8
Training loss: 1.0990955829620361
Validation loss: 2.013210795258963

Epoch: 5| Step: 9
Training loss: 1.3165147304534912
Validation loss: 2.0009259741793395

Epoch: 5| Step: 10
Training loss: 1.7097482681274414
Validation loss: 2.0037482912822435

Epoch: 195| Step: 0
Training loss: 0.8729443550109863
Validation loss: 1.9788236156586678

Epoch: 5| Step: 1
Training loss: 1.790459394454956
Validation loss: 1.9713679898169734

Epoch: 5| Step: 2
Training loss: 1.1489685773849487
Validation loss: 1.9567638827908425

Epoch: 5| Step: 3
Training loss: 1.7430518865585327
Validation loss: 1.982507953079798

Epoch: 5| Step: 4
Training loss: 1.1281296014785767
Validation loss: 1.9864107011466898

Epoch: 5| Step: 5
Training loss: 1.1925493478775024
Validation loss: 2.0016706194928897

Epoch: 5| Step: 6
Training loss: 1.4607387781143188
Validation loss: 2.0118535949337866

Epoch: 5| Step: 7
Training loss: 1.1668118238449097
Validation loss: 1.9989972781109553

Epoch: 5| Step: 8
Training loss: 1.1832447052001953
Validation loss: 1.980291429386344

Epoch: 5| Step: 9
Training loss: 1.028735876083374
Validation loss: 1.9623437966069868

Epoch: 5| Step: 10
Training loss: 1.6318159103393555
Validation loss: 1.984628959368634

Epoch: 196| Step: 0
Training loss: 0.8839000463485718
Validation loss: 2.0003819132363923

Epoch: 5| Step: 1
Training loss: 1.3790313005447388
Validation loss: 1.9747862380038026

Epoch: 5| Step: 2
Training loss: 1.1711890697479248
Validation loss: 2.015510892355314

Epoch: 5| Step: 3
Training loss: 1.751787543296814
Validation loss: 2.048004432391095

Epoch: 5| Step: 4
Training loss: 0.9918987154960632
Validation loss: 2.0704153891532653

Epoch: 5| Step: 5
Training loss: 1.5509147644042969
Validation loss: 2.08539483880484

Epoch: 5| Step: 6
Training loss: 1.4758923053741455
Validation loss: 2.074363903332782

Epoch: 5| Step: 7
Training loss: 1.2359111309051514
Validation loss: 2.092441926720322

Epoch: 5| Step: 8
Training loss: 1.3554346561431885
Validation loss: 2.053858659600699

Epoch: 5| Step: 9
Training loss: 0.6886225938796997
Validation loss: 2.0199507615899526

Epoch: 5| Step: 10
Training loss: 1.7164939641952515
Validation loss: 1.976422727748912

Epoch: 197| Step: 0
Training loss: 1.3305046558380127
Validation loss: 1.9890267554149832

Epoch: 5| Step: 1
Training loss: 1.7218835353851318
Validation loss: 1.9818748633066814

Epoch: 5| Step: 2
Training loss: 0.9993900060653687
Validation loss: 1.9567471499084144

Epoch: 5| Step: 3
Training loss: 1.382836937904358
Validation loss: 1.9523705679883239

Epoch: 5| Step: 4
Training loss: 1.3582932949066162
Validation loss: 1.9369227245289793

Epoch: 5| Step: 5
Training loss: 0.8457655906677246
Validation loss: 1.9532796259849303

Epoch: 5| Step: 6
Training loss: 1.5107908248901367
Validation loss: 1.9357025520775908

Epoch: 5| Step: 7
Training loss: 1.4623329639434814
Validation loss: 1.9797048671271211

Epoch: 5| Step: 8
Training loss: 1.1798969507217407
Validation loss: 1.9622386194044543

Epoch: 5| Step: 9
Training loss: 1.0290040969848633
Validation loss: 1.981792466614836

Epoch: 5| Step: 10
Training loss: 1.2620946168899536
Validation loss: 1.968215755237046

Epoch: 198| Step: 0
Training loss: 1.8518129587173462
Validation loss: 1.9456243309923398

Epoch: 5| Step: 1
Training loss: 0.7270396947860718
Validation loss: 1.9538260647045669

Epoch: 5| Step: 2
Training loss: 1.212499976158142
Validation loss: 1.9720128825915757

Epoch: 5| Step: 3
Training loss: 0.9734768867492676
Validation loss: 2.005657301154188

Epoch: 5| Step: 4
Training loss: 1.3458913564682007
Validation loss: 2.03942399127509

Epoch: 5| Step: 5
Training loss: 1.0413299798965454
Validation loss: 2.023243640058784

Epoch: 5| Step: 6
Training loss: 1.1694141626358032
Validation loss: 2.00162229230327

Epoch: 5| Step: 7
Training loss: 1.0083062648773193
Validation loss: 2.013134079594766

Epoch: 5| Step: 8
Training loss: 1.5446652173995972
Validation loss: 1.9909621284854027

Epoch: 5| Step: 9
Training loss: 1.779428482055664
Validation loss: 1.983306533546858

Epoch: 5| Step: 10
Training loss: 1.3301609754562378
Validation loss: 1.9651767746094735

Epoch: 199| Step: 0
Training loss: 1.2300158739089966
Validation loss: 1.9438213635516424

Epoch: 5| Step: 1
Training loss: 1.4512903690338135
Validation loss: 1.934660933351004

Epoch: 5| Step: 2
Training loss: 0.8367703557014465
Validation loss: 1.9274111537523166

Epoch: 5| Step: 3
Training loss: 1.0832812786102295
Validation loss: 1.9793926131340764

Epoch: 5| Step: 4
Training loss: 1.5163582563400269
Validation loss: 2.0037003332568752

Epoch: 5| Step: 5
Training loss: 0.9814376831054688
Validation loss: 2.021703759829203

Epoch: 5| Step: 6
Training loss: 1.464293122291565
Validation loss: 2.013465819820281

Epoch: 5| Step: 7
Training loss: 1.1357591152191162
Validation loss: 1.9863903791673723

Epoch: 5| Step: 8
Training loss: 1.43842351436615
Validation loss: 1.9862459628812728

Epoch: 5| Step: 9
Training loss: 1.1060664653778076
Validation loss: 1.9556439743247083

Epoch: 5| Step: 10
Training loss: 1.7201894521713257
Validation loss: 1.9336678622871317

Epoch: 200| Step: 0
Training loss: 1.243695616722107
Validation loss: 1.9496656848538307

Epoch: 5| Step: 1
Training loss: 0.8237550854682922
Validation loss: 1.9702661550173195

Epoch: 5| Step: 2
Training loss: 1.5361557006835938
Validation loss: 1.934721649333995

Epoch: 5| Step: 3
Training loss: 1.5448858737945557
Validation loss: 1.9736651194992887

Epoch: 5| Step: 4
Training loss: 1.2827566862106323
Validation loss: 1.9671254798930178

Epoch: 5| Step: 5
Training loss: 0.8768927454948425
Validation loss: 1.9806459642225696

Epoch: 5| Step: 6
Training loss: 1.2305686473846436
Validation loss: 1.9764054898292787

Epoch: 5| Step: 7
Training loss: 1.3731189966201782
Validation loss: 1.994007877124253

Epoch: 5| Step: 8
Training loss: 1.3154261112213135
Validation loss: 2.0005746477393695

Epoch: 5| Step: 9
Training loss: 1.5935795307159424
Validation loss: 2.0345685988344173

Epoch: 5| Step: 10
Training loss: 1.022231936454773
Validation loss: 2.0228054767013877

Epoch: 201| Step: 0
Training loss: 1.3001463413238525
Validation loss: 2.017016885101154

Epoch: 5| Step: 1
Training loss: 1.3963291645050049
Validation loss: 2.0247928250220513

Epoch: 5| Step: 2
Training loss: 1.2397468090057373
Validation loss: 1.9965516931267195

Epoch: 5| Step: 3
Training loss: 1.2934038639068604
Validation loss: 1.9977393534875685

Epoch: 5| Step: 4
Training loss: 1.712837815284729
Validation loss: 2.0220310188108876

Epoch: 5| Step: 5
Training loss: 1.0651746988296509
Validation loss: 2.0090946151364233

Epoch: 5| Step: 6
Training loss: 1.3672329187393188
Validation loss: 1.9780560001250236

Epoch: 5| Step: 7
Training loss: 1.1771985292434692
Validation loss: 1.953084994387883

Epoch: 5| Step: 8
Training loss: 1.2856851816177368
Validation loss: 1.9416122013522732

Epoch: 5| Step: 9
Training loss: 1.1297767162322998
Validation loss: 1.914773941040039

Epoch: 5| Step: 10
Training loss: 0.9350690245628357
Validation loss: 1.9557520458775182

Epoch: 202| Step: 0
Training loss: 1.3629794120788574
Validation loss: 1.9720780208546629

Epoch: 5| Step: 1
Training loss: 1.2174962759017944
Validation loss: 1.9693984293168592

Epoch: 5| Step: 2
Training loss: 1.2542999982833862
Validation loss: 1.9869150038688415

Epoch: 5| Step: 3
Training loss: 0.8627492189407349
Validation loss: 2.011366921086465

Epoch: 5| Step: 4
Training loss: 1.1901201009750366
Validation loss: 1.9922666575319024

Epoch: 5| Step: 5
Training loss: 1.6157983541488647
Validation loss: 1.9955129777231524

Epoch: 5| Step: 6
Training loss: 1.0575511455535889
Validation loss: 2.01850478623503

Epoch: 5| Step: 7
Training loss: 0.7809947729110718
Validation loss: 1.9983576446451166

Epoch: 5| Step: 8
Training loss: 1.1869966983795166
Validation loss: 1.9953307515831404

Epoch: 5| Step: 9
Training loss: 1.398363471031189
Validation loss: 2.012091798167075

Epoch: 5| Step: 10
Training loss: 1.5896968841552734
Validation loss: 1.979719526024275

Epoch: 203| Step: 0
Training loss: 1.3466461896896362
Validation loss: 1.9631508473427064

Epoch: 5| Step: 1
Training loss: 1.2533506155014038
Validation loss: 1.9252484742031302

Epoch: 5| Step: 2
Training loss: 1.2674163579940796
Validation loss: 1.916373009322792

Epoch: 5| Step: 3
Training loss: 1.2109580039978027
Validation loss: 1.8972392607760686

Epoch: 5| Step: 4
Training loss: 1.3404700756072998
Validation loss: 1.8947670613565752

Epoch: 5| Step: 5
Training loss: 1.1377296447753906
Validation loss: 1.888751358114263

Epoch: 5| Step: 6
Training loss: 1.4100619554519653
Validation loss: 1.8718911063286565

Epoch: 5| Step: 7
Training loss: 0.739505410194397
Validation loss: 1.9089263485323997

Epoch: 5| Step: 8
Training loss: 1.4534498453140259
Validation loss: 1.9086774215903333

Epoch: 5| Step: 9
Training loss: 1.0559899806976318
Validation loss: 1.9343023928262855

Epoch: 5| Step: 10
Training loss: 1.155058741569519
Validation loss: 1.9691059025385047

Epoch: 204| Step: 0
Training loss: 1.4405635595321655
Validation loss: 2.0066226797719158

Epoch: 5| Step: 1
Training loss: 0.9327726364135742
Validation loss: 1.97177743270833

Epoch: 5| Step: 2
Training loss: 1.158821940422058
Validation loss: 1.977937444563835

Epoch: 5| Step: 3
Training loss: 1.3244998455047607
Validation loss: 1.9749742323352444

Epoch: 5| Step: 4
Training loss: 1.2603626251220703
Validation loss: 1.9745414116049325

Epoch: 5| Step: 5
Training loss: 1.2328161001205444
Validation loss: 1.9949894989690473

Epoch: 5| Step: 6
Training loss: 1.3184345960617065
Validation loss: 1.9738089217934558

Epoch: 5| Step: 7
Training loss: 1.0757455825805664
Validation loss: 1.9945938356461064

Epoch: 5| Step: 8
Training loss: 1.119450330734253
Validation loss: 1.9926982207964825

Epoch: 5| Step: 9
Training loss: 1.4038875102996826
Validation loss: 1.979341865867697

Epoch: 5| Step: 10
Training loss: 0.898672342300415
Validation loss: 1.9665102510042087

Epoch: 205| Step: 0
Training loss: 1.2901270389556885
Validation loss: 1.9621820180646834

Epoch: 5| Step: 1
Training loss: 1.2843124866485596
Validation loss: 2.0049433041644353

Epoch: 5| Step: 2
Training loss: 0.9898586273193359
Validation loss: 1.962170026635611

Epoch: 5| Step: 3
Training loss: 0.9774711728096008
Validation loss: 1.9712199805885233

Epoch: 5| Step: 4
Training loss: 1.2770448923110962
Validation loss: 1.9430440113108645

Epoch: 5| Step: 5
Training loss: 1.1028436422348022
Validation loss: 1.9390496182185348

Epoch: 5| Step: 6
Training loss: 1.3068710565567017
Validation loss: 1.9627569157590148

Epoch: 5| Step: 7
Training loss: 1.0619709491729736
Validation loss: 1.9680039651932255

Epoch: 5| Step: 8
Training loss: 0.8443973660469055
Validation loss: 1.9580106440410818

Epoch: 5| Step: 9
Training loss: 1.6229841709136963
Validation loss: 1.925711493338308

Epoch: 5| Step: 10
Training loss: 1.2483469247817993
Validation loss: 1.9530406985231625

Epoch: 206| Step: 0
Training loss: 1.4117425680160522
Validation loss: 1.9359768129164172

Epoch: 5| Step: 1
Training loss: 0.7190650701522827
Validation loss: 1.940915673009811

Epoch: 5| Step: 2
Training loss: 1.5160449743270874
Validation loss: 1.923749840387734

Epoch: 5| Step: 3
Training loss: 1.668460488319397
Validation loss: 1.9046556001068444

Epoch: 5| Step: 4
Training loss: 1.1621496677398682
Validation loss: 1.9055671332984843

Epoch: 5| Step: 5
Training loss: 0.7055040597915649
Validation loss: 1.9187366424068328

Epoch: 5| Step: 6
Training loss: 1.0658161640167236
Validation loss: 1.9534379705306022

Epoch: 5| Step: 7
Training loss: 1.0278353691101074
Validation loss: 1.959755551430487

Epoch: 5| Step: 8
Training loss: 1.2543742656707764
Validation loss: 1.989919929094212

Epoch: 5| Step: 9
Training loss: 1.155766487121582
Validation loss: 1.9778299588029102

Epoch: 5| Step: 10
Training loss: 1.0730804204940796
Validation loss: 1.987998067691762

Epoch: 207| Step: 0
Training loss: 1.0652644634246826
Validation loss: 2.0112224804457797

Epoch: 5| Step: 1
Training loss: 1.0721560716629028
Validation loss: 2.0017135656008156

Epoch: 5| Step: 2
Training loss: 1.0301650762557983
Validation loss: 1.9920115163249354

Epoch: 5| Step: 3
Training loss: 0.749148964881897
Validation loss: 1.9857142022860947

Epoch: 5| Step: 4
Training loss: 0.8389506340026855
Validation loss: 1.9631163612488778

Epoch: 5| Step: 5
Training loss: 1.7337239980697632
Validation loss: 1.9567408741161387

Epoch: 5| Step: 6
Training loss: 1.4033863544464111
Validation loss: 1.949732167746431

Epoch: 5| Step: 7
Training loss: 1.4432213306427002
Validation loss: 1.9205016987298125

Epoch: 5| Step: 8
Training loss: 1.133305311203003
Validation loss: 1.9702440410531976

Epoch: 5| Step: 9
Training loss: 1.0474650859832764
Validation loss: 1.9620671759369552

Epoch: 5| Step: 10
Training loss: 1.1916590929031372
Validation loss: 1.968240487960077

Epoch: 208| Step: 0
Training loss: 1.227062463760376
Validation loss: 1.9523460788111533

Epoch: 5| Step: 1
Training loss: 1.5803662538528442
Validation loss: 1.9537375229661182

Epoch: 5| Step: 2
Training loss: 1.3150606155395508
Validation loss: 1.9208498385644728

Epoch: 5| Step: 3
Training loss: 0.8753520846366882
Validation loss: 1.8995753693324264

Epoch: 5| Step: 4
Training loss: 0.938663125038147
Validation loss: 1.8902848279604347

Epoch: 5| Step: 5
Training loss: 0.9404226541519165
Validation loss: 1.8848578519718622

Epoch: 5| Step: 6
Training loss: 1.2364637851715088
Validation loss: 1.8987726626857635

Epoch: 5| Step: 7
Training loss: 1.17876398563385
Validation loss: 1.8926560699298818

Epoch: 5| Step: 8
Training loss: 0.9855338931083679
Validation loss: 1.9024238406970937

Epoch: 5| Step: 9
Training loss: 1.1277309656143188
Validation loss: 1.9405937758825158

Epoch: 5| Step: 10
Training loss: 1.5359872579574585
Validation loss: 1.9244822250899447

Epoch: 209| Step: 0
Training loss: 1.1471035480499268
Validation loss: 1.946493071894492

Epoch: 5| Step: 1
Training loss: 1.1708784103393555
Validation loss: 1.965801969651253

Epoch: 5| Step: 2
Training loss: 1.4014486074447632
Validation loss: 1.951461991956157

Epoch: 5| Step: 3
Training loss: 1.4233849048614502
Validation loss: 1.9775156744064823

Epoch: 5| Step: 4
Training loss: 1.2156040668487549
Validation loss: 1.9716793837085846

Epoch: 5| Step: 5
Training loss: 1.284320592880249
Validation loss: 1.9667270183563232

Epoch: 5| Step: 6
Training loss: 0.9143456220626831
Validation loss: 1.9629158589147753

Epoch: 5| Step: 7
Training loss: 1.2230592966079712
Validation loss: 1.9759015626804803

Epoch: 5| Step: 8
Training loss: 1.2258377075195312
Validation loss: 1.948100733500655

Epoch: 5| Step: 9
Training loss: 0.8540931940078735
Validation loss: 1.9352670241427679

Epoch: 5| Step: 10
Training loss: 1.0434890985488892
Validation loss: 1.9488238467965076

Epoch: 210| Step: 0
Training loss: 1.476020097732544
Validation loss: 1.9349336367781445

Epoch: 5| Step: 1
Training loss: 1.1303503513336182
Validation loss: 1.957845559684179

Epoch: 5| Step: 2
Training loss: 1.1338651180267334
Validation loss: 1.9566605296186221

Epoch: 5| Step: 3
Training loss: 1.1516737937927246
Validation loss: 1.9720799717851865

Epoch: 5| Step: 4
Training loss: 1.3314144611358643
Validation loss: 1.935748182317262

Epoch: 5| Step: 5
Training loss: 0.8496543169021606
Validation loss: 1.93329115580487

Epoch: 5| Step: 6
Training loss: 1.5760000944137573
Validation loss: 1.9998152358557588

Epoch: 5| Step: 7
Training loss: 0.9349963068962097
Validation loss: 1.946165733439948

Epoch: 5| Step: 8
Training loss: 1.1367751359939575
Validation loss: 1.9830502053742767

Epoch: 5| Step: 9
Training loss: 1.11572265625
Validation loss: 1.951254206319009

Epoch: 5| Step: 10
Training loss: 0.9534182548522949
Validation loss: 1.9249676542897378

Epoch: 211| Step: 0
Training loss: 1.0989216566085815
Validation loss: 1.9100665789778515

Epoch: 5| Step: 1
Training loss: 1.1373400688171387
Validation loss: 1.9116062387343375

Epoch: 5| Step: 2
Training loss: 1.3798717260360718
Validation loss: 1.8919154982413016

Epoch: 5| Step: 3
Training loss: 1.356929898262024
Validation loss: 1.9234683154731669

Epoch: 5| Step: 4
Training loss: 0.8141384124755859
Validation loss: 1.9505430504839907

Epoch: 5| Step: 5
Training loss: 1.100102186203003
Validation loss: 1.9621399756400817

Epoch: 5| Step: 6
Training loss: 1.5552074909210205
Validation loss: 1.9911105107235652

Epoch: 5| Step: 7
Training loss: 1.4053431749343872
Validation loss: 2.0298995753770233

Epoch: 5| Step: 8
Training loss: 1.1717113256454468
Validation loss: 1.9734400638969996

Epoch: 5| Step: 9
Training loss: 0.8014955520629883
Validation loss: 1.93708638862897

Epoch: 5| Step: 10
Training loss: 1.0711774826049805
Validation loss: 1.9443069093970842

Epoch: 212| Step: 0
Training loss: 1.0092426538467407
Validation loss: 1.9176289484065066

Epoch: 5| Step: 1
Training loss: 0.8804357647895813
Validation loss: 1.906537978879867

Epoch: 5| Step: 2
Training loss: 0.8730469942092896
Validation loss: 1.9082286819334953

Epoch: 5| Step: 3
Training loss: 1.213165521621704
Validation loss: 1.9158513007625457

Epoch: 5| Step: 4
Training loss: 1.265021562576294
Validation loss: 1.9233087006435599

Epoch: 5| Step: 5
Training loss: 0.9453668594360352
Validation loss: 1.9245020766412058

Epoch: 5| Step: 6
Training loss: 1.0671672821044922
Validation loss: 1.9503869677102694

Epoch: 5| Step: 7
Training loss: 1.6022628545761108
Validation loss: 1.9627958113147366

Epoch: 5| Step: 8
Training loss: 0.9876832962036133
Validation loss: 1.98222444903466

Epoch: 5| Step: 9
Training loss: 1.1228004693984985
Validation loss: 1.9667709924841439

Epoch: 5| Step: 10
Training loss: 1.3950035572052002
Validation loss: 1.9565698203220163

Epoch: 213| Step: 0
Training loss: 0.9298766851425171
Validation loss: 1.9419029989550192

Epoch: 5| Step: 1
Training loss: 0.9310757517814636
Validation loss: 1.955016823225124

Epoch: 5| Step: 2
Training loss: 1.2155792713165283
Validation loss: 1.9260714759108841

Epoch: 5| Step: 3
Training loss: 0.9523522257804871
Validation loss: 1.919215771459764

Epoch: 5| Step: 4
Training loss: 1.0984652042388916
Validation loss: 1.8983444001085015

Epoch: 5| Step: 5
Training loss: 1.1440651416778564
Validation loss: 1.9342602042741672

Epoch: 5| Step: 6
Training loss: 1.0036518573760986
Validation loss: 1.928171960256433

Epoch: 5| Step: 7
Training loss: 0.9761236310005188
Validation loss: 1.9465215462510304

Epoch: 5| Step: 8
Training loss: 1.1431310176849365
Validation loss: 1.942398476344283

Epoch: 5| Step: 9
Training loss: 1.0675253868103027
Validation loss: 1.9925335466220815

Epoch: 5| Step: 10
Training loss: 1.7988097667694092
Validation loss: 2.0243524043790755

Epoch: 214| Step: 0
Training loss: 0.9823805093765259
Validation loss: 1.976175049299835

Epoch: 5| Step: 1
Training loss: 0.9356648325920105
Validation loss: 1.9583298442184285

Epoch: 5| Step: 2
Training loss: 1.1988413333892822
Validation loss: 1.9452718406595209

Epoch: 5| Step: 3
Training loss: 1.464252233505249
Validation loss: 1.9493674437204997

Epoch: 5| Step: 4
Training loss: 1.143423318862915
Validation loss: 1.9066078932054582

Epoch: 5| Step: 5
Training loss: 0.9954622387886047
Validation loss: 1.8997083633176741

Epoch: 5| Step: 6
Training loss: 1.0535904169082642
Validation loss: 1.8800115803236603

Epoch: 5| Step: 7
Training loss: 1.4493460655212402
Validation loss: 1.8723864016994354

Epoch: 5| Step: 8
Training loss: 0.7056905031204224
Validation loss: 1.8884660582388602

Epoch: 5| Step: 9
Training loss: 1.158754587173462
Validation loss: 1.9303925703930598

Epoch: 5| Step: 10
Training loss: 1.1312839984893799
Validation loss: 1.9548604219190535

Epoch: 215| Step: 0
Training loss: 0.810827374458313
Validation loss: 1.999084589301899

Epoch: 5| Step: 1
Training loss: 1.117353081703186
Validation loss: 2.0079601169914327

Epoch: 5| Step: 2
Training loss: 1.1634811162948608
Validation loss: 2.0085254689698577

Epoch: 5| Step: 3
Training loss: 1.0749170780181885
Validation loss: 2.009003693057645

Epoch: 5| Step: 4
Training loss: 0.9023467302322388
Validation loss: 1.9520396417187107

Epoch: 5| Step: 5
Training loss: 0.9518172144889832
Validation loss: 1.9168835968099616

Epoch: 5| Step: 6
Training loss: 1.3556053638458252
Validation loss: 1.9237119023517897

Epoch: 5| Step: 7
Training loss: 1.482710599899292
Validation loss: 1.8951688453715334

Epoch: 5| Step: 8
Training loss: 0.8360574841499329
Validation loss: 1.8921620166429909

Epoch: 5| Step: 9
Training loss: 1.3242875337600708
Validation loss: 1.878826500267111

Epoch: 5| Step: 10
Training loss: 1.34354567527771
Validation loss: 1.8664767703702372

Epoch: 216| Step: 0
Training loss: 1.0419222116470337
Validation loss: 1.911889406942552

Epoch: 5| Step: 1
Training loss: 1.3221980333328247
Validation loss: 1.9251656288741736

Epoch: 5| Step: 2
Training loss: 1.4625829458236694
Validation loss: 1.991936094017439

Epoch: 5| Step: 3
Training loss: 0.7950242757797241
Validation loss: 2.0343336610383886

Epoch: 5| Step: 4
Training loss: 0.8941303491592407
Validation loss: 2.0281298340007825

Epoch: 5| Step: 5
Training loss: 1.0543264150619507
Validation loss: 2.0271224565403436

Epoch: 5| Step: 6
Training loss: 1.1543792486190796
Validation loss: 2.0004019339879355

Epoch: 5| Step: 7
Training loss: 0.6433232426643372
Validation loss: 1.9476884885500836

Epoch: 5| Step: 8
Training loss: 0.798653244972229
Validation loss: 1.9188020652340305

Epoch: 5| Step: 9
Training loss: 1.0492370128631592
Validation loss: 1.911377614544284

Epoch: 5| Step: 10
Training loss: 1.9683983325958252
Validation loss: 1.8988491181404359

Epoch: 217| Step: 0
Training loss: 0.5193266868591309
Validation loss: 1.9260062940659062

Epoch: 5| Step: 1
Training loss: 1.1951353549957275
Validation loss: 1.913870511516448

Epoch: 5| Step: 2
Training loss: 1.2244079113006592
Validation loss: 1.9378024788313015

Epoch: 5| Step: 3
Training loss: 1.7149410247802734
Validation loss: 1.9601741119097638

Epoch: 5| Step: 4
Training loss: 1.321083664894104
Validation loss: 1.95903492102059

Epoch: 5| Step: 5
Training loss: 0.4818445146083832
Validation loss: 1.989420046088516

Epoch: 5| Step: 6
Training loss: 1.343984842300415
Validation loss: 1.9920587155126757

Epoch: 5| Step: 7
Training loss: 1.0492825508117676
Validation loss: 2.023978348701231

Epoch: 5| Step: 8
Training loss: 0.7941182851791382
Validation loss: 2.017002172367547

Epoch: 5| Step: 9
Training loss: 1.350501298904419
Validation loss: 2.004980574371994

Epoch: 5| Step: 10
Training loss: 1.0565098524093628
Validation loss: 1.9618360098972116

Epoch: 218| Step: 0
Training loss: 1.2887287139892578
Validation loss: 1.948861619477631

Epoch: 5| Step: 1
Training loss: 1.0566602945327759
Validation loss: 1.9164770726234681

Epoch: 5| Step: 2
Training loss: 1.083601713180542
Validation loss: 1.8997756973389657

Epoch: 5| Step: 3
Training loss: 0.8063791990280151
Validation loss: 1.8713021073290097

Epoch: 5| Step: 4
Training loss: 1.1356713771820068
Validation loss: 1.8770455621903943

Epoch: 5| Step: 5
Training loss: 0.7504078149795532
Validation loss: 1.874954036487046

Epoch: 5| Step: 6
Training loss: 1.1016604900360107
Validation loss: 1.9031922086592643

Epoch: 5| Step: 7
Training loss: 1.0163946151733398
Validation loss: 1.9360101440901398

Epoch: 5| Step: 8
Training loss: 1.1315054893493652
Validation loss: 1.935750429348279

Epoch: 5| Step: 9
Training loss: 1.2110915184020996
Validation loss: 1.9508768230356195

Epoch: 5| Step: 10
Training loss: 1.2579439878463745
Validation loss: 1.9407593075947096

Epoch: 219| Step: 0
Training loss: 1.0261238813400269
Validation loss: 1.9530565713041572

Epoch: 5| Step: 1
Training loss: 1.1393821239471436
Validation loss: 1.9557287718660088

Epoch: 5| Step: 2
Training loss: 0.8571920394897461
Validation loss: 1.983197372446778

Epoch: 5| Step: 3
Training loss: 0.6073933839797974
Validation loss: 1.9648127350755917

Epoch: 5| Step: 4
Training loss: 1.3194483518600464
Validation loss: 1.9428245072723718

Epoch: 5| Step: 5
Training loss: 0.9668720364570618
Validation loss: 1.92808319932671

Epoch: 5| Step: 6
Training loss: 1.3201547861099243
Validation loss: 1.9563518942043345

Epoch: 5| Step: 7
Training loss: 0.8653203845024109
Validation loss: 1.9283151280495427

Epoch: 5| Step: 8
Training loss: 1.2872610092163086
Validation loss: 1.9227769938848351

Epoch: 5| Step: 9
Training loss: 1.1005795001983643
Validation loss: 1.9008708282183575

Epoch: 5| Step: 10
Training loss: 1.187931776046753
Validation loss: 1.9358835579246603

Epoch: 220| Step: 0
Training loss: 0.9085184931755066
Validation loss: 1.9181027796960646

Epoch: 5| Step: 1
Training loss: 1.393660545349121
Validation loss: 1.9093668537755166

Epoch: 5| Step: 2
Training loss: 0.6854540109634399
Validation loss: 1.8853387396822694

Epoch: 5| Step: 3
Training loss: 0.7204014658927917
Validation loss: 1.9032603899637859

Epoch: 5| Step: 4
Training loss: 1.0239160060882568
Validation loss: 1.9053182127655193

Epoch: 5| Step: 5
Training loss: 1.0502135753631592
Validation loss: 1.8994256322101881

Epoch: 5| Step: 6
Training loss: 0.7597240209579468
Validation loss: 1.9230579265984156

Epoch: 5| Step: 7
Training loss: 1.3624801635742188
Validation loss: 1.9133755609553347

Epoch: 5| Step: 8
Training loss: 1.6343116760253906
Validation loss: 1.9522656497134958

Epoch: 5| Step: 9
Training loss: 1.131500482559204
Validation loss: 1.941293647212367

Epoch: 5| Step: 10
Training loss: 1.005767822265625
Validation loss: 1.9455889104514994

Epoch: 221| Step: 0
Training loss: 1.3253027200698853
Validation loss: 1.9662743255656252

Epoch: 5| Step: 1
Training loss: 0.7145455479621887
Validation loss: 1.9502624901392127

Epoch: 5| Step: 2
Training loss: 0.7271082401275635
Validation loss: 1.929862024963543

Epoch: 5| Step: 3
Training loss: 1.2052971124649048
Validation loss: 1.9501469109648017

Epoch: 5| Step: 4
Training loss: 1.166824221611023
Validation loss: 1.9044195477680494

Epoch: 5| Step: 5
Training loss: 0.9566730260848999
Validation loss: 1.9171916207959574

Epoch: 5| Step: 6
Training loss: 0.8733220100402832
Validation loss: 1.8841887930388093

Epoch: 5| Step: 7
Training loss: 0.87193763256073
Validation loss: 1.8830170631408691

Epoch: 5| Step: 8
Training loss: 1.3278870582580566
Validation loss: 1.908351388028873

Epoch: 5| Step: 9
Training loss: 1.1560578346252441
Validation loss: 1.8828209805232223

Epoch: 5| Step: 10
Training loss: 0.8787189722061157
Validation loss: 1.9348157887817712

Epoch: 222| Step: 0
Training loss: 0.8649614453315735
Validation loss: 1.9240454037984211

Epoch: 5| Step: 1
Training loss: 1.1825945377349854
Validation loss: 1.8797603371322795

Epoch: 5| Step: 2
Training loss: 1.32810640335083
Validation loss: 1.8691580269926338

Epoch: 5| Step: 3
Training loss: 0.7254573702812195
Validation loss: 1.9028139704017228

Epoch: 5| Step: 4
Training loss: 1.4529974460601807
Validation loss: 1.9193514905950075

Epoch: 5| Step: 5
Training loss: 1.5097968578338623
Validation loss: 1.9670652343380837

Epoch: 5| Step: 6
Training loss: 1.0437724590301514
Validation loss: 1.9679336047941638

Epoch: 5| Step: 7
Training loss: 0.5316444635391235
Validation loss: 1.962830267926698

Epoch: 5| Step: 8
Training loss: 1.3223865032196045
Validation loss: 1.939418618397046

Epoch: 5| Step: 9
Training loss: 0.7172349691390991
Validation loss: 1.9495097680758404

Epoch: 5| Step: 10
Training loss: 0.6213717460632324
Validation loss: 1.9300536596646873

Epoch: 223| Step: 0
Training loss: 1.5233739614486694
Validation loss: 1.8969794550249655

Epoch: 5| Step: 1
Training loss: 0.6472138166427612
Validation loss: 1.893198674724948

Epoch: 5| Step: 2
Training loss: 1.0544894933700562
Validation loss: 1.892533984235538

Epoch: 5| Step: 3
Training loss: 1.1288551092147827
Validation loss: 1.9092543753244544

Epoch: 5| Step: 4
Training loss: 0.49329739809036255
Validation loss: 1.9006490476669804

Epoch: 5| Step: 5
Training loss: 1.0756486654281616
Validation loss: 1.9803397719578077

Epoch: 5| Step: 6
Training loss: 1.0610805749893188
Validation loss: 2.014053144762593

Epoch: 5| Step: 7
Training loss: 1.2711641788482666
Validation loss: 1.9974334573233

Epoch: 5| Step: 8
Training loss: 0.7440373301506042
Validation loss: 1.9586182896808912

Epoch: 5| Step: 9
Training loss: 1.3199481964111328
Validation loss: 1.914511763921348

Epoch: 5| Step: 10
Training loss: 1.2795580625534058
Validation loss: 1.9060195979251657

Epoch: 224| Step: 0
Training loss: 1.067347764968872
Validation loss: 1.8826299059775569

Epoch: 5| Step: 1
Training loss: 1.3497555255889893
Validation loss: 1.8717499676571097

Epoch: 5| Step: 2
Training loss: 0.6193877458572388
Validation loss: 1.8771150932517102

Epoch: 5| Step: 3
Training loss: 1.1813751459121704
Validation loss: 1.8889115318175285

Epoch: 5| Step: 4
Training loss: 1.1174424886703491
Validation loss: 1.9210335734069988

Epoch: 5| Step: 5
Training loss: 0.7630014419555664
Validation loss: 1.9633885147751018

Epoch: 5| Step: 6
Training loss: 1.0966160297393799
Validation loss: 1.988336286237163

Epoch: 5| Step: 7
Training loss: 1.0551468133926392
Validation loss: 2.0018600417721655

Epoch: 5| Step: 8
Training loss: 1.262764573097229
Validation loss: 2.0242938790270077

Epoch: 5| Step: 9
Training loss: 0.8225296139717102
Validation loss: 1.990228452990132

Epoch: 5| Step: 10
Training loss: 0.868718147277832
Validation loss: 1.9519494092592629

Epoch: 225| Step: 0
Training loss: 1.1328566074371338
Validation loss: 1.9033571827796198

Epoch: 5| Step: 1
Training loss: 1.4652756452560425
Validation loss: 1.8968105623798985

Epoch: 5| Step: 2
Training loss: 0.9292335510253906
Validation loss: 1.8696464492428688

Epoch: 5| Step: 3
Training loss: 0.6169832944869995
Validation loss: 1.8818103395482546

Epoch: 5| Step: 4
Training loss: 0.953579306602478
Validation loss: 1.8786996897830759

Epoch: 5| Step: 5
Training loss: 1.025536298751831
Validation loss: 1.8920026107500958

Epoch: 5| Step: 6
Training loss: 1.1134580373764038
Validation loss: 1.893665195793234

Epoch: 5| Step: 7
Training loss: 0.9269384145736694
Validation loss: 1.910325602818561

Epoch: 5| Step: 8
Training loss: 0.9598788022994995
Validation loss: 1.9362234864183652

Epoch: 5| Step: 9
Training loss: 0.9595886468887329
Validation loss: 1.9640456476519186

Epoch: 5| Step: 10
Training loss: 1.0764557123184204
Validation loss: 1.984661627841252

Epoch: 226| Step: 0
Training loss: 1.2698538303375244
Validation loss: 1.9858122410312775

Epoch: 5| Step: 1
Training loss: 0.6133241653442383
Validation loss: 1.9753086105469735

Epoch: 5| Step: 2
Training loss: 1.2996165752410889
Validation loss: 1.9675593196704824

Epoch: 5| Step: 3
Training loss: 1.2178289890289307
Validation loss: 1.9183994954632175

Epoch: 5| Step: 4
Training loss: 0.8539239168167114
Validation loss: 1.9197367032368977

Epoch: 5| Step: 5
Training loss: 0.799547553062439
Validation loss: 1.9184085412691998

Epoch: 5| Step: 6
Training loss: 0.9240680932998657
Validation loss: 1.8998045306051932

Epoch: 5| Step: 7
Training loss: 1.2656233310699463
Validation loss: 1.916239277009041

Epoch: 5| Step: 8
Training loss: 0.7897597551345825
Validation loss: 1.9128903163376676

Epoch: 5| Step: 9
Training loss: 1.1717780828475952
Validation loss: 1.9346434352218465

Epoch: 5| Step: 10
Training loss: 0.8380179405212402
Validation loss: 1.9287147086153749

Epoch: 227| Step: 0
Training loss: 0.9104529619216919
Validation loss: 1.912659348980073

Epoch: 5| Step: 1
Training loss: 0.8955252766609192
Validation loss: 1.889006515984894

Epoch: 5| Step: 2
Training loss: 1.167999267578125
Validation loss: 1.8839936397408927

Epoch: 5| Step: 3
Training loss: 0.9022008180618286
Validation loss: 1.8513501972280524

Epoch: 5| Step: 4
Training loss: 0.6725677251815796
Validation loss: 1.8478843576164656

Epoch: 5| Step: 5
Training loss: 1.4506769180297852
Validation loss: 1.854052892295263

Epoch: 5| Step: 6
Training loss: 1.541800618171692
Validation loss: 1.8755741888476956

Epoch: 5| Step: 7
Training loss: 1.0963109731674194
Validation loss: 1.8769710884299329

Epoch: 5| Step: 8
Training loss: 0.48918095231056213
Validation loss: 1.911564039927657

Epoch: 5| Step: 9
Training loss: 0.7365544438362122
Validation loss: 1.9241687713130828

Epoch: 5| Step: 10
Training loss: 0.9909093379974365
Validation loss: 1.889206160781204

Epoch: 228| Step: 0
Training loss: 1.1134101152420044
Validation loss: 1.9122800814208163

Epoch: 5| Step: 1
Training loss: 1.0191962718963623
Validation loss: 1.8782918145579677

Epoch: 5| Step: 2
Training loss: 1.096540093421936
Validation loss: 1.9019663449256652

Epoch: 5| Step: 3
Training loss: 1.256161093711853
Validation loss: 1.8923731414220666

Epoch: 5| Step: 4
Training loss: 0.9309943318367004
Validation loss: 1.904350738371572

Epoch: 5| Step: 5
Training loss: 0.6568906903266907
Validation loss: 1.9244712232261576

Epoch: 5| Step: 6
Training loss: 0.624762237071991
Validation loss: 1.9125542179230721

Epoch: 5| Step: 7
Training loss: 1.2175687551498413
Validation loss: 1.9546119346413562

Epoch: 5| Step: 8
Training loss: 0.8726757168769836
Validation loss: 1.9101655073063348

Epoch: 5| Step: 9
Training loss: 0.9232550859451294
Validation loss: 1.9112043380737305

Epoch: 5| Step: 10
Training loss: 1.1270276308059692
Validation loss: 1.9047740531224076

Epoch: 229| Step: 0
Training loss: 0.9301068186759949
Validation loss: 1.9127334689581266

Epoch: 5| Step: 1
Training loss: 1.1189451217651367
Validation loss: 1.9108343842209026

Epoch: 5| Step: 2
Training loss: 0.74673992395401
Validation loss: 1.8952288512260682

Epoch: 5| Step: 3
Training loss: 0.617824137210846
Validation loss: 1.876362475015784

Epoch: 5| Step: 4
Training loss: 0.6342881321907043
Validation loss: 1.8709618096710534

Epoch: 5| Step: 5
Training loss: 0.5185455083847046
Validation loss: 1.8785924667953162

Epoch: 5| Step: 6
Training loss: 1.7474992275238037
Validation loss: 1.9115003360215055

Epoch: 5| Step: 7
Training loss: 1.0866703987121582
Validation loss: 1.9344952555112942

Epoch: 5| Step: 8
Training loss: 1.1639769077301025
Validation loss: 1.983091357574668

Epoch: 5| Step: 9
Training loss: 1.4100233316421509
Validation loss: 1.9585630342524538

Epoch: 5| Step: 10
Training loss: 0.8715112805366516
Validation loss: 1.9286255028940016

Epoch: 230| Step: 0
Training loss: 0.5805703401565552
Validation loss: 1.926530635485085

Epoch: 5| Step: 1
Training loss: 0.9974023699760437
Validation loss: 1.9298906531385196

Epoch: 5| Step: 2
Training loss: 0.5584076642990112
Validation loss: 1.9291208790194603

Epoch: 5| Step: 3
Training loss: 0.7405964732170105
Validation loss: 1.9146962294014551

Epoch: 5| Step: 4
Training loss: 0.7394664883613586
Validation loss: 1.9029781626116844

Epoch: 5| Step: 5
Training loss: 1.2803679704666138
Validation loss: 1.921741363822773

Epoch: 5| Step: 6
Training loss: 1.1609680652618408
Validation loss: 1.8995690679037442

Epoch: 5| Step: 7
Training loss: 1.4683743715286255
Validation loss: 1.8960495225844844

Epoch: 5| Step: 8
Training loss: 1.4485143423080444
Validation loss: 1.9177646675417501

Epoch: 5| Step: 9
Training loss: 0.9061238169670105
Validation loss: 1.889833241380671

Epoch: 5| Step: 10
Training loss: 0.8021717667579651
Validation loss: 1.8870522476011706

Epoch: 231| Step: 0
Training loss: 1.4042117595672607
Validation loss: 1.8755953311920166

Epoch: 5| Step: 1
Training loss: 1.011569619178772
Validation loss: 1.8847531657065115

Epoch: 5| Step: 2
Training loss: 0.7746376991271973
Validation loss: 1.878925879796346

Epoch: 5| Step: 3
Training loss: 1.0327937602996826
Validation loss: 1.8785996014072048

Epoch: 5| Step: 4
Training loss: 1.0953342914581299
Validation loss: 1.8719416459401448

Epoch: 5| Step: 5
Training loss: 1.204534888267517
Validation loss: 1.8710915170690066

Epoch: 5| Step: 6
Training loss: 0.8755881190299988
Validation loss: 1.8809983448315692

Epoch: 5| Step: 7
Training loss: 0.7085546255111694
Validation loss: 1.8744896868223786

Epoch: 5| Step: 8
Training loss: 0.9105368852615356
Validation loss: 1.8709319842759

Epoch: 5| Step: 9
Training loss: 0.7239970564842224
Validation loss: 1.864942967250783

Epoch: 5| Step: 10
Training loss: 0.8543468117713928
Validation loss: 1.8807419897407613

Epoch: 232| Step: 0
Training loss: 0.9567133784294128
Validation loss: 1.8565610608746927

Epoch: 5| Step: 1
Training loss: 0.48098641633987427
Validation loss: 1.8656537045714676

Epoch: 5| Step: 2
Training loss: 0.9025602340698242
Validation loss: 1.8852797426203245

Epoch: 5| Step: 3
Training loss: 1.029900312423706
Validation loss: 1.8615961933648715

Epoch: 5| Step: 4
Training loss: 0.8941122889518738
Validation loss: 1.8794705508857645

Epoch: 5| Step: 5
Training loss: 0.783871054649353
Validation loss: 1.8841595726628457

Epoch: 5| Step: 6
Training loss: 1.0423741340637207
Validation loss: 1.8757980318479641

Epoch: 5| Step: 7
Training loss: 0.7153602838516235
Validation loss: 1.8440394017004198

Epoch: 5| Step: 8
Training loss: 1.2309716939926147
Validation loss: 1.8639903196724512

Epoch: 5| Step: 9
Training loss: 0.7910552024841309
Validation loss: 1.8733542516667356

Epoch: 5| Step: 10
Training loss: 1.443677544593811
Validation loss: 1.888406663812617

Epoch: 233| Step: 0
Training loss: 0.8951511383056641
Validation loss: 1.8661813120688162

Epoch: 5| Step: 1
Training loss: 1.177372694015503
Validation loss: 1.849451329118462

Epoch: 5| Step: 2
Training loss: 0.7264396548271179
Validation loss: 1.862796959056649

Epoch: 5| Step: 3
Training loss: 0.5642629861831665
Validation loss: 1.8695940791919667

Epoch: 5| Step: 4
Training loss: 0.6522570848464966
Validation loss: 1.8379384035705237

Epoch: 5| Step: 5
Training loss: 0.7773886919021606
Validation loss: 1.8496717714494275

Epoch: 5| Step: 6
Training loss: 1.2921744585037231
Validation loss: 1.8501092003237816

Epoch: 5| Step: 7
Training loss: 0.6708449721336365
Validation loss: 1.8890142056249803

Epoch: 5| Step: 8
Training loss: 1.3868478536605835
Validation loss: 1.9021426016284573

Epoch: 5| Step: 9
Training loss: 1.3054910898208618
Validation loss: 1.911017458925965

Epoch: 5| Step: 10
Training loss: 0.6809217929840088
Validation loss: 1.9178767037648026

Epoch: 234| Step: 0
Training loss: 1.5411326885223389
Validation loss: 1.9361455466157647

Epoch: 5| Step: 1
Training loss: 0.9424365162849426
Validation loss: 1.93361182238466

Epoch: 5| Step: 2
Training loss: 0.787283182144165
Validation loss: 1.911781495617282

Epoch: 5| Step: 3
Training loss: 0.5390434265136719
Validation loss: 1.881425525552483

Epoch: 5| Step: 4
Training loss: 1.1223951578140259
Validation loss: 1.9241002400716145

Epoch: 5| Step: 5
Training loss: 0.6787158846855164
Validation loss: 1.8931212091958651

Epoch: 5| Step: 6
Training loss: 0.834359347820282
Validation loss: 1.8728941589273431

Epoch: 5| Step: 7
Training loss: 0.8494081497192383
Validation loss: 1.8739713917496383

Epoch: 5| Step: 8
Training loss: 1.0278886556625366
Validation loss: 1.876268575268407

Epoch: 5| Step: 9
Training loss: 0.9694470167160034
Validation loss: 1.8846114784158685

Epoch: 5| Step: 10
Training loss: 0.6964922547340393
Validation loss: 1.8791639317748368

Epoch: 235| Step: 0
Training loss: 0.8872048258781433
Validation loss: 1.8844909437241093

Epoch: 5| Step: 1
Training loss: 1.2281641960144043
Validation loss: 1.8894278772415654

Epoch: 5| Step: 2
Training loss: 1.1849026679992676
Validation loss: 1.90290791116735

Epoch: 5| Step: 3
Training loss: 0.7632125020027161
Validation loss: 1.8985187622808641

Epoch: 5| Step: 4
Training loss: 0.6815915107727051
Validation loss: 1.8713900773755965

Epoch: 5| Step: 5
Training loss: 0.883063018321991
Validation loss: 1.8739403204251361

Epoch: 5| Step: 6
Training loss: 1.0156348943710327
Validation loss: 1.8781359016254384

Epoch: 5| Step: 7
Training loss: 1.0712053775787354
Validation loss: 1.8511738533614783

Epoch: 5| Step: 8
Training loss: 0.46592432260513306
Validation loss: 1.846447463958494

Epoch: 5| Step: 9
Training loss: 1.094867467880249
Validation loss: 1.8452148796409689

Epoch: 5| Step: 10
Training loss: 0.65102618932724
Validation loss: 1.8403169531976022

Epoch: 236| Step: 0
Training loss: 0.9215787649154663
Validation loss: 1.8158541763982465

Epoch: 5| Step: 1
Training loss: 1.1946687698364258
Validation loss: 1.8341758571645266

Epoch: 5| Step: 2
Training loss: 0.44069433212280273
Validation loss: 1.8230557762166506

Epoch: 5| Step: 3
Training loss: 0.7877307534217834
Validation loss: 1.850478538902857

Epoch: 5| Step: 4
Training loss: 0.92431640625
Validation loss: 1.8508773285855529

Epoch: 5| Step: 5
Training loss: 0.9553804397583008
Validation loss: 1.8386676055128857

Epoch: 5| Step: 6
Training loss: 0.8931363821029663
Validation loss: 1.8612377130857078

Epoch: 5| Step: 7
Training loss: 0.8641478419303894
Validation loss: 1.8153019156507266

Epoch: 5| Step: 8
Training loss: 0.9622679948806763
Validation loss: 1.8548519572904032

Epoch: 5| Step: 9
Training loss: 1.253594160079956
Validation loss: 1.8391589323679607

Epoch: 5| Step: 10
Training loss: 0.6370849609375
Validation loss: 1.859399478922608

Epoch: 237| Step: 0
Training loss: 1.0229383707046509
Validation loss: 1.854731390553136

Epoch: 5| Step: 1
Training loss: 1.0781974792480469
Validation loss: 1.8830533399376819

Epoch: 5| Step: 2
Training loss: 0.6698845028877258
Validation loss: 1.8712303958913332

Epoch: 5| Step: 3
Training loss: 0.6822443008422852
Validation loss: 1.8890180985132854

Epoch: 5| Step: 4
Training loss: 1.2395579814910889
Validation loss: 1.8902281163841166

Epoch: 5| Step: 5
Training loss: 0.5139821767807007
Validation loss: 1.92051524372511

Epoch: 5| Step: 6
Training loss: 1.097341537475586
Validation loss: 1.9069128959409651

Epoch: 5| Step: 7
Training loss: 0.7654247283935547
Validation loss: 1.922554664714362

Epoch: 5| Step: 8
Training loss: 0.8095036745071411
Validation loss: 1.8846415024931713

Epoch: 5| Step: 9
Training loss: 0.8081588745117188
Validation loss: 1.8769163367568806

Epoch: 5| Step: 10
Training loss: 1.294859766960144
Validation loss: 1.8967099920395882

Epoch: 238| Step: 0
Training loss: 0.6502965092658997
Validation loss: 1.8805977811095536

Epoch: 5| Step: 1
Training loss: 1.1548258066177368
Validation loss: 1.8722746667041574

Epoch: 5| Step: 2
Training loss: 0.7142837643623352
Validation loss: 1.8353961154978762

Epoch: 5| Step: 3
Training loss: 0.8228873014450073
Validation loss: 1.8744771121650614

Epoch: 5| Step: 4
Training loss: 0.9626239538192749
Validation loss: 1.890258248134326

Epoch: 5| Step: 5
Training loss: 0.7058115601539612
Validation loss: 1.9159143201766475

Epoch: 5| Step: 6
Training loss: 0.8076174855232239
Validation loss: 1.9323788214755315

Epoch: 5| Step: 7
Training loss: 1.3481379747390747
Validation loss: 1.940949119547362

Epoch: 5| Step: 8
Training loss: 0.9488118886947632
Validation loss: 1.8941477549973356

Epoch: 5| Step: 9
Training loss: 0.834250271320343
Validation loss: 1.894946546964748

Epoch: 5| Step: 10
Training loss: 1.0494462251663208
Validation loss: 1.8758830767805859

Epoch: 239| Step: 0
Training loss: 0.7480483055114746
Validation loss: 1.8783622800662954

Epoch: 5| Step: 1
Training loss: 0.9363740682601929
Validation loss: 1.8680608400734522

Epoch: 5| Step: 2
Training loss: 0.9915453791618347
Validation loss: 1.853599912376814

Epoch: 5| Step: 3
Training loss: 0.6687024831771851
Validation loss: 1.8712284449608094

Epoch: 5| Step: 4
Training loss: 0.6734067797660828
Validation loss: 1.870167201565158

Epoch: 5| Step: 5
Training loss: 1.2757794857025146
Validation loss: 1.8955673210082515

Epoch: 5| Step: 6
Training loss: 0.9275792837142944
Validation loss: 1.9343198935190837

Epoch: 5| Step: 7
Training loss: 0.9929771423339844
Validation loss: 1.9336357373063282

Epoch: 5| Step: 8
Training loss: 0.7575329542160034
Validation loss: 1.9167159372760403

Epoch: 5| Step: 9
Training loss: 1.028770923614502
Validation loss: 1.9734926300664102

Epoch: 5| Step: 10
Training loss: 0.9719729423522949
Validation loss: 1.9361089378274896

Epoch: 240| Step: 0
Training loss: 0.6269643902778625
Validation loss: 1.9530438018101517

Epoch: 5| Step: 1
Training loss: 1.398381233215332
Validation loss: 1.9324405424056514

Epoch: 5| Step: 2
Training loss: 0.6135886311531067
Validation loss: 1.876476349369172

Epoch: 5| Step: 3
Training loss: 1.2969398498535156
Validation loss: 1.8418700156673309

Epoch: 5| Step: 4
Training loss: 0.7404429316520691
Validation loss: 1.8377027691051524

Epoch: 5| Step: 5
Training loss: 1.2485759258270264
Validation loss: 1.8282518925205353

Epoch: 5| Step: 6
Training loss: 0.8960318565368652
Validation loss: 1.8239545335051834

Epoch: 5| Step: 7
Training loss: 0.7978394627571106
Validation loss: 1.8558676460737824

Epoch: 5| Step: 8
Training loss: 0.5742012858390808
Validation loss: 1.8941164990907073

Epoch: 5| Step: 9
Training loss: 0.913784384727478
Validation loss: 1.888057699767492

Epoch: 5| Step: 10
Training loss: 1.1111843585968018
Validation loss: 1.9181683858235676

Epoch: 241| Step: 0
Training loss: 0.6365553140640259
Validation loss: 1.9296684277954923

Epoch: 5| Step: 1
Training loss: 1.1654446125030518
Validation loss: 1.9087316118260866

Epoch: 5| Step: 2
Training loss: 1.4425426721572876
Validation loss: 1.9095963073033158

Epoch: 5| Step: 3
Training loss: 0.7843228578567505
Validation loss: 1.90653238373418

Epoch: 5| Step: 4
Training loss: 0.9124307632446289
Validation loss: 1.9032765639725553

Epoch: 5| Step: 5
Training loss: 0.8009875416755676
Validation loss: 1.888768421706333

Epoch: 5| Step: 6
Training loss: 0.9286052584648132
Validation loss: 1.8812126510886735

Epoch: 5| Step: 7
Training loss: 0.5311124920845032
Validation loss: 1.8644274332190072

Epoch: 5| Step: 8
Training loss: 0.8012488484382629
Validation loss: 1.8342893354354366

Epoch: 5| Step: 9
Training loss: 1.0158289670944214
Validation loss: 1.802716601279474

Epoch: 5| Step: 10
Training loss: 0.8308542966842651
Validation loss: 1.8177732780415525

Epoch: 242| Step: 0
Training loss: 0.8545078039169312
Validation loss: 1.816478640802445

Epoch: 5| Step: 1
Training loss: 0.452684223651886
Validation loss: 1.8463694382739324

Epoch: 5| Step: 2
Training loss: 0.6993616819381714
Validation loss: 1.820243416293975

Epoch: 5| Step: 3
Training loss: 0.7096573114395142
Validation loss: 1.7990019141986806

Epoch: 5| Step: 4
Training loss: 1.4392595291137695
Validation loss: 1.8071355358246834

Epoch: 5| Step: 5
Training loss: 0.6552702188491821
Validation loss: 1.8119533113254014

Epoch: 5| Step: 6
Training loss: 0.9415186643600464
Validation loss: 1.8296307953455115

Epoch: 5| Step: 7
Training loss: 1.3470975160598755
Validation loss: 1.8169512159080916

Epoch: 5| Step: 8
Training loss: 1.157662034034729
Validation loss: 1.800187110900879

Epoch: 5| Step: 9
Training loss: 0.734513521194458
Validation loss: 1.808767775053619

Epoch: 5| Step: 10
Training loss: 0.7283017635345459
Validation loss: 1.8329613375407394

Epoch: 243| Step: 0
Training loss: 0.8814308047294617
Validation loss: 1.8401420270242999

Epoch: 5| Step: 1
Training loss: 0.9037807583808899
Validation loss: 1.8514715497211744

Epoch: 5| Step: 2
Training loss: 0.7085100412368774
Validation loss: 1.8353506236947992

Epoch: 5| Step: 3
Training loss: 0.8613605499267578
Validation loss: 1.8373480894232308

Epoch: 5| Step: 4
Training loss: 0.8360716700553894
Validation loss: 1.8241423419726792

Epoch: 5| Step: 5
Training loss: 1.2280757427215576
Validation loss: 1.8326307804353776

Epoch: 5| Step: 6
Training loss: 0.9094236493110657
Validation loss: 1.846332916649439

Epoch: 5| Step: 7
Training loss: 0.5041065812110901
Validation loss: 1.844385277840399

Epoch: 5| Step: 8
Training loss: 0.6390398740768433
Validation loss: 1.8185036272130988

Epoch: 5| Step: 9
Training loss: 1.270393967628479
Validation loss: 1.8438885916945755

Epoch: 5| Step: 10
Training loss: 0.7390525937080383
Validation loss: 1.8359419850892917

Epoch: 244| Step: 0
Training loss: 1.1352169513702393
Validation loss: 1.8688089142563522

Epoch: 5| Step: 1
Training loss: 0.8492788076400757
Validation loss: 1.8443761461524553

Epoch: 5| Step: 2
Training loss: 0.5313133001327515
Validation loss: 1.830362731410611

Epoch: 5| Step: 3
Training loss: 0.8119829297065735
Validation loss: 1.8429729118142077

Epoch: 5| Step: 4
Training loss: 0.8173044919967651
Validation loss: 1.838154891485809

Epoch: 5| Step: 5
Training loss: 1.0884977579116821
Validation loss: 1.8533290291345248

Epoch: 5| Step: 6
Training loss: 1.1526964902877808
Validation loss: 1.8583281681101809

Epoch: 5| Step: 7
Training loss: 0.5714529156684875
Validation loss: 1.828106023932016

Epoch: 5| Step: 8
Training loss: 0.6392524242401123
Validation loss: 1.7922658638287616

Epoch: 5| Step: 9
Training loss: 0.9737555384635925
Validation loss: 1.7761837256852018

Epoch: 5| Step: 10
Training loss: 0.9225297570228577
Validation loss: 1.7858932684826594

Epoch: 245| Step: 0
Training loss: 0.6391153931617737
Validation loss: 1.7851935637894498

Epoch: 5| Step: 1
Training loss: 1.0038862228393555
Validation loss: 1.8310205218612507

Epoch: 5| Step: 2
Training loss: 0.9771803021430969
Validation loss: 1.8709437372863933

Epoch: 5| Step: 3
Training loss: 0.8335675001144409
Validation loss: 1.8470734729561755

Epoch: 5| Step: 4
Training loss: 1.1544866561889648
Validation loss: 1.8930800243090558

Epoch: 5| Step: 5
Training loss: 0.7848697900772095
Validation loss: 1.882712838470295

Epoch: 5| Step: 6
Training loss: 0.8867167234420776
Validation loss: 1.8977768908264816

Epoch: 5| Step: 7
Training loss: 0.669741153717041
Validation loss: 1.941620239647486

Epoch: 5| Step: 8
Training loss: 1.0578635931015015
Validation loss: 1.9562065588530673

Epoch: 5| Step: 9
Training loss: 1.1920136213302612
Validation loss: 1.9687600725440568

Epoch: 5| Step: 10
Training loss: 0.6593412756919861
Validation loss: 1.9416840973720755

Epoch: 246| Step: 0
Training loss: 0.7256008982658386
Validation loss: 1.8831376029599098

Epoch: 5| Step: 1
Training loss: 0.7459637522697449
Validation loss: 1.8475609312775314

Epoch: 5| Step: 2
Training loss: 0.6921648979187012
Validation loss: 1.8184488563127414

Epoch: 5| Step: 3
Training loss: 1.1049805879592896
Validation loss: 1.8129624782070037

Epoch: 5| Step: 4
Training loss: 0.7894235253334045
Validation loss: 1.8193726129429315

Epoch: 5| Step: 5
Training loss: 1.1668450832366943
Validation loss: 1.8334083287946639

Epoch: 5| Step: 6
Training loss: 0.7031855583190918
Validation loss: 1.8452318650419994

Epoch: 5| Step: 7
Training loss: 0.5956407785415649
Validation loss: 1.8427555727702316

Epoch: 5| Step: 8
Training loss: 0.8658695220947266
Validation loss: 1.8828630652478946

Epoch: 5| Step: 9
Training loss: 1.3259119987487793
Validation loss: 1.8851337817407423

Epoch: 5| Step: 10
Training loss: 0.9889097809791565
Validation loss: 1.887523878005243

Epoch: 247| Step: 0
Training loss: 0.9281058311462402
Validation loss: 1.8602504153405466

Epoch: 5| Step: 1
Training loss: 0.911906898021698
Validation loss: 1.8663779240782543

Epoch: 5| Step: 2
Training loss: 0.6992526650428772
Validation loss: 1.8403193463561356

Epoch: 5| Step: 3
Training loss: 0.9977130889892578
Validation loss: 1.8156882204035276

Epoch: 5| Step: 4
Training loss: 0.6141940951347351
Validation loss: 1.844786000508134

Epoch: 5| Step: 5
Training loss: 0.9341942071914673
Validation loss: 1.7953426056010748

Epoch: 5| Step: 6
Training loss: 0.8143434524536133
Validation loss: 1.791680129625464

Epoch: 5| Step: 7
Training loss: 1.0893491506576538
Validation loss: 1.7740362600613666

Epoch: 5| Step: 8
Training loss: 1.2275164127349854
Validation loss: 1.7949889475299465

Epoch: 5| Step: 9
Training loss: 0.5864018201828003
Validation loss: 1.8029227564411778

Epoch: 5| Step: 10
Training loss: 0.6570841073989868
Validation loss: 1.8388799903213338

Epoch: 248| Step: 0
Training loss: 1.3254868984222412
Validation loss: 1.8127691540666806

Epoch: 5| Step: 1
Training loss: 0.5638545751571655
Validation loss: 1.8049685109046198

Epoch: 5| Step: 2
Training loss: 0.7217462658882141
Validation loss: 1.7748784301101521

Epoch: 5| Step: 3
Training loss: 0.6689914464950562
Validation loss: 1.801135092653254

Epoch: 5| Step: 4
Training loss: 0.9696964025497437
Validation loss: 1.7595359484354656

Epoch: 5| Step: 5
Training loss: 1.0324733257293701
Validation loss: 1.82236724258751

Epoch: 5| Step: 6
Training loss: 0.6796948313713074
Validation loss: 1.8368580597703175

Epoch: 5| Step: 7
Training loss: 1.4582242965698242
Validation loss: 1.8650641172162947

Epoch: 5| Step: 8
Training loss: 0.8570876121520996
Validation loss: 1.8786349732388732

Epoch: 5| Step: 9
Training loss: 0.6818210482597351
Validation loss: 1.8653008373834754

Epoch: 5| Step: 10
Training loss: 0.4738699495792389
Validation loss: 1.8869824101847987

Epoch: 249| Step: 0
Training loss: 0.5030214190483093
Validation loss: 1.8798133775752077

Epoch: 5| Step: 1
Training loss: 0.9411705136299133
Validation loss: 1.8915598238668134

Epoch: 5| Step: 2
Training loss: 1.1340000629425049
Validation loss: 1.8943512157727314

Epoch: 5| Step: 3
Training loss: 1.1284749507904053
Validation loss: 1.885789817379367

Epoch: 5| Step: 4
Training loss: 1.0362980365753174
Validation loss: 1.8934315981403473

Epoch: 5| Step: 5
Training loss: 0.7270967960357666
Validation loss: 1.885575452158528

Epoch: 5| Step: 6
Training loss: 0.8405996561050415
Validation loss: 1.8873031113737373

Epoch: 5| Step: 7
Training loss: 0.9304782748222351
Validation loss: 1.8328462621217132

Epoch: 5| Step: 8
Training loss: 0.7824856042861938
Validation loss: 1.8311495780944824

Epoch: 5| Step: 9
Training loss: 0.6452277302742004
Validation loss: 1.8533590019390147

Epoch: 5| Step: 10
Training loss: 0.6597676277160645
Validation loss: 1.8197240701285742

Epoch: 250| Step: 0
Training loss: 0.9755755662918091
Validation loss: 1.8207828062836842

Epoch: 5| Step: 1
Training loss: 1.0283796787261963
Validation loss: 1.8454129452346473

Epoch: 5| Step: 2
Training loss: 0.43665680289268494
Validation loss: 1.8715220215500041

Epoch: 5| Step: 3
Training loss: 0.6757044792175293
Validation loss: 1.8741727157305645

Epoch: 5| Step: 4
Training loss: 0.8278042078018188
Validation loss: 1.8458107261247532

Epoch: 5| Step: 5
Training loss: 1.120356798171997
Validation loss: 1.8360987145413634

Epoch: 5| Step: 6
Training loss: 0.7444950342178345
Validation loss: 1.8263216736496135

Epoch: 5| Step: 7
Training loss: 0.7179020643234253
Validation loss: 1.8185920689695625

Epoch: 5| Step: 8
Training loss: 0.9476690292358398
Validation loss: 1.800409770780994

Epoch: 5| Step: 9
Training loss: 0.5121763944625854
Validation loss: 1.8268997284673876

Epoch: 5| Step: 10
Training loss: 1.004810094833374
Validation loss: 1.829521684236424

Epoch: 251| Step: 0
Training loss: 0.7164837718009949
Validation loss: 1.8562608688108382

Epoch: 5| Step: 1
Training loss: 0.6776469349861145
Validation loss: 1.892300646792176

Epoch: 5| Step: 2
Training loss: 1.0946601629257202
Validation loss: 1.8990732956958074

Epoch: 5| Step: 3
Training loss: 0.8726245164871216
Validation loss: 1.885481201192384

Epoch: 5| Step: 4
Training loss: 0.5243642926216125
Validation loss: 1.8800046879758117

Epoch: 5| Step: 5
Training loss: 0.7432198524475098
Validation loss: 1.8670540432776175

Epoch: 5| Step: 6
Training loss: 1.0348546504974365
Validation loss: 1.8512404246996808

Epoch: 5| Step: 7
Training loss: 0.9184690713882446
Validation loss: 1.8174005528931976

Epoch: 5| Step: 8
Training loss: 0.935573935508728
Validation loss: 1.82305690421853

Epoch: 5| Step: 9
Training loss: 0.8958320617675781
Validation loss: 1.7998958608155609

Epoch: 5| Step: 10
Training loss: 0.6945589184761047
Validation loss: 1.8318273457147742

Epoch: 252| Step: 0
Training loss: 0.7155117392539978
Validation loss: 1.8346799958136775

Epoch: 5| Step: 1
Training loss: 0.7948468327522278
Validation loss: 1.870645126988811

Epoch: 5| Step: 2
Training loss: 1.3096086978912354
Validation loss: 1.8839082692259101

Epoch: 5| Step: 3
Training loss: 0.5432517528533936
Validation loss: 1.896393996413036

Epoch: 5| Step: 4
Training loss: 0.8164966702461243
Validation loss: 1.864593199504319

Epoch: 5| Step: 5
Training loss: 0.7513565421104431
Validation loss: 1.8785148410386936

Epoch: 5| Step: 6
Training loss: 0.9239590764045715
Validation loss: 1.834179880798504

Epoch: 5| Step: 7
Training loss: 0.37771496176719666
Validation loss: 1.8101151425351378

Epoch: 5| Step: 8
Training loss: 0.9730206727981567
Validation loss: 1.7537552989939207

Epoch: 5| Step: 9
Training loss: 0.7492192983627319
Validation loss: 1.8064118521187895

Epoch: 5| Step: 10
Training loss: 0.9103072285652161
Validation loss: 1.7842309731309132

Epoch: 253| Step: 0
Training loss: 0.8634659051895142
Validation loss: 1.7745511378011396

Epoch: 5| Step: 1
Training loss: 0.41162747144699097
Validation loss: 1.7645558657184723

Epoch: 5| Step: 2
Training loss: 0.9696843028068542
Validation loss: 1.7841669750469986

Epoch: 5| Step: 3
Training loss: 0.9854243993759155
Validation loss: 1.7910496547657957

Epoch: 5| Step: 4
Training loss: 0.5454217791557312
Validation loss: 1.801633463110975

Epoch: 5| Step: 5
Training loss: 0.7582401633262634
Validation loss: 1.8409372452766664

Epoch: 5| Step: 6
Training loss: 1.0522230863571167
Validation loss: 1.8503378668139059

Epoch: 5| Step: 7
Training loss: 0.7740809321403503
Validation loss: 1.823936950775885

Epoch: 5| Step: 8
Training loss: 0.5996439456939697
Validation loss: 1.8347443316572456

Epoch: 5| Step: 9
Training loss: 0.7514344453811646
Validation loss: 1.8465672808308755

Epoch: 5| Step: 10
Training loss: 1.3008992671966553
Validation loss: 1.8302359478448027

Epoch: 254| Step: 0
Training loss: 0.428730309009552
Validation loss: 1.8434545122167116

Epoch: 5| Step: 1
Training loss: 0.7826875448226929
Validation loss: 1.8037935905559088

Epoch: 5| Step: 2
Training loss: 1.0519399642944336
Validation loss: 1.8393098820922196

Epoch: 5| Step: 3
Training loss: 0.7102614641189575
Validation loss: 1.8356946860590289

Epoch: 5| Step: 4
Training loss: 0.5187505483627319
Validation loss: 1.811989793213465

Epoch: 5| Step: 5
Training loss: 1.2035011053085327
Validation loss: 1.8582200017026675

Epoch: 5| Step: 6
Training loss: 0.9353551864624023
Validation loss: 1.8656765735277565

Epoch: 5| Step: 7
Training loss: 0.49462348222732544
Validation loss: 1.861906668191315

Epoch: 5| Step: 8
Training loss: 0.6440976858139038
Validation loss: 1.865788072668096

Epoch: 5| Step: 9
Training loss: 1.4226897954940796
Validation loss: 1.841477083903487

Epoch: 5| Step: 10
Training loss: 0.5399383306503296
Validation loss: 1.8369883824420232

Epoch: 255| Step: 0
Training loss: 0.828907310962677
Validation loss: 1.832328091385544

Epoch: 5| Step: 1
Training loss: 0.7651385068893433
Validation loss: 1.8267727616012737

Epoch: 5| Step: 2
Training loss: 1.0175786018371582
Validation loss: 1.8215281450620262

Epoch: 5| Step: 3
Training loss: 0.7276177406311035
Validation loss: 1.8077915124995734

Epoch: 5| Step: 4
Training loss: 0.8549561500549316
Validation loss: 1.8275555795238865

Epoch: 5| Step: 5
Training loss: 0.7863118052482605
Validation loss: 1.8420260952365013

Epoch: 5| Step: 6
Training loss: 0.5784952044487
Validation loss: 1.863161128054383

Epoch: 5| Step: 7
Training loss: 0.8235637545585632
Validation loss: 1.8956297200213197

Epoch: 5| Step: 8
Training loss: 0.7692369818687439
Validation loss: 1.9041528368508944

Epoch: 5| Step: 9
Training loss: 1.0742765665054321
Validation loss: 1.9225531906209967

Epoch: 5| Step: 10
Training loss: 0.5134302377700806
Validation loss: 1.906932892337922

Epoch: 256| Step: 0
Training loss: 0.47108373045921326
Validation loss: 1.8693476505176996

Epoch: 5| Step: 1
Training loss: 0.6367557644844055
Validation loss: 1.8701923688252766

Epoch: 5| Step: 2
Training loss: 1.2633168697357178
Validation loss: 1.8265722900308587

Epoch: 5| Step: 3
Training loss: 0.8183795809745789
Validation loss: 1.8005644659842215

Epoch: 5| Step: 4
Training loss: 0.7919831871986389
Validation loss: 1.7818416677495486

Epoch: 5| Step: 5
Training loss: 0.5480242967605591
Validation loss: 1.795551315430672

Epoch: 5| Step: 6
Training loss: 0.5948692560195923
Validation loss: 1.785708717120591

Epoch: 5| Step: 7
Training loss: 0.8604691624641418
Validation loss: 1.8082935367861102

Epoch: 5| Step: 8
Training loss: 0.6404390931129456
Validation loss: 1.831521544405209

Epoch: 5| Step: 9
Training loss: 0.8161536455154419
Validation loss: 1.8546361295125817

Epoch: 5| Step: 10
Training loss: 1.0021930932998657
Validation loss: 1.8459880441747687

Epoch: 257| Step: 0
Training loss: 0.5640593767166138
Validation loss: 1.8461300467932096

Epoch: 5| Step: 1
Training loss: 0.678789496421814
Validation loss: 1.820338632470818

Epoch: 5| Step: 2
Training loss: 1.0813392400741577
Validation loss: 1.8362036007706837

Epoch: 5| Step: 3
Training loss: 0.7119017839431763
Validation loss: 1.8257371879393054

Epoch: 5| Step: 4
Training loss: 0.6916149258613586
Validation loss: 1.835457190390556

Epoch: 5| Step: 5
Training loss: 1.1253122091293335
Validation loss: 1.809386368720762

Epoch: 5| Step: 6
Training loss: 0.6362273693084717
Validation loss: 1.796414183032128

Epoch: 5| Step: 7
Training loss: 0.7882059812545776
Validation loss: 1.7983738824885378

Epoch: 5| Step: 8
Training loss: 1.0141772031784058
Validation loss: 1.7863207286404026

Epoch: 5| Step: 9
Training loss: 0.7925571799278259
Validation loss: 1.8138341839595506

Epoch: 5| Step: 10
Training loss: 0.3494477868080139
Validation loss: 1.811545116927034

Epoch: 258| Step: 0
Training loss: 0.7657142877578735
Validation loss: 1.7999579496281122

Epoch: 5| Step: 1
Training loss: 0.8985453844070435
Validation loss: 1.8337895575390066

Epoch: 5| Step: 2
Training loss: 1.0623400211334229
Validation loss: 1.812181358696312

Epoch: 5| Step: 3
Training loss: 0.750091552734375
Validation loss: 1.85262547257126

Epoch: 5| Step: 4
Training loss: 0.6797536611557007
Validation loss: 1.8434685340491674

Epoch: 5| Step: 5
Training loss: 0.778503954410553
Validation loss: 1.8537088619765414

Epoch: 5| Step: 6
Training loss: 0.821144700050354
Validation loss: 1.8655084499748804

Epoch: 5| Step: 7
Training loss: 0.4571622312068939
Validation loss: 1.8701604822630524

Epoch: 5| Step: 8
Training loss: 0.7530128359794617
Validation loss: 1.8297052396241056

Epoch: 5| Step: 9
Training loss: 0.8241376876831055
Validation loss: 1.8030910056124452

Epoch: 5| Step: 10
Training loss: 0.8221163749694824
Validation loss: 1.8370166581164125

Epoch: 259| Step: 0
Training loss: 1.015377163887024
Validation loss: 1.8126269822479577

Epoch: 5| Step: 1
Training loss: 0.8686574697494507
Validation loss: 1.7994938486365861

Epoch: 5| Step: 2
Training loss: 0.8330094218254089
Validation loss: 1.809178743311154

Epoch: 5| Step: 3
Training loss: 0.4772595465183258
Validation loss: 1.8372536064476095

Epoch: 5| Step: 4
Training loss: 0.6120105981826782
Validation loss: 1.831228099843507

Epoch: 5| Step: 5
Training loss: 0.7226777672767639
Validation loss: 1.8328446944554646

Epoch: 5| Step: 6
Training loss: 0.8639701008796692
Validation loss: 1.838109283037083

Epoch: 5| Step: 7
Training loss: 0.41784635186195374
Validation loss: 1.8638730856680101

Epoch: 5| Step: 8
Training loss: 0.895587146282196
Validation loss: 1.8738584390250586

Epoch: 5| Step: 9
Training loss: 0.939906895160675
Validation loss: 1.866508763323548

Epoch: 5| Step: 10
Training loss: 0.8196956515312195
Validation loss: 1.860875642427834

Epoch: 260| Step: 0
Training loss: 0.34889116883277893
Validation loss: 1.8524750958206833

Epoch: 5| Step: 1
Training loss: 0.6998850107192993
Validation loss: 1.8511588547819404

Epoch: 5| Step: 2
Training loss: 0.750231146812439
Validation loss: 1.8380187954953922

Epoch: 5| Step: 3
Training loss: 0.6340357661247253
Validation loss: 1.8394462523921844

Epoch: 5| Step: 4
Training loss: 0.6275202631950378
Validation loss: 1.8193662499868741

Epoch: 5| Step: 5
Training loss: 0.7706102132797241
Validation loss: 1.8443232326097385

Epoch: 5| Step: 6
Training loss: 0.5755028128623962
Validation loss: 1.8049618864572177

Epoch: 5| Step: 7
Training loss: 0.9533465504646301
Validation loss: 1.8235102699648948

Epoch: 5| Step: 8
Training loss: 0.9166959524154663
Validation loss: 1.821066749993191

Epoch: 5| Step: 9
Training loss: 0.39458441734313965
Validation loss: 1.8301261791618921

Epoch: 5| Step: 10
Training loss: 1.5001654624938965
Validation loss: 1.8459150124621648

Epoch: 261| Step: 0
Training loss: 0.678244411945343
Validation loss: 1.8237465004767142

Epoch: 5| Step: 1
Training loss: 0.5399554371833801
Validation loss: 1.8100960126487158

Epoch: 5| Step: 2
Training loss: 0.8270748853683472
Validation loss: 1.823731755697599

Epoch: 5| Step: 3
Training loss: 0.5114456415176392
Validation loss: 1.810921061423517

Epoch: 5| Step: 4
Training loss: 0.8692260980606079
Validation loss: 1.8099906111276278

Epoch: 5| Step: 5
Training loss: 0.8004573583602905
Validation loss: 1.82225114299405

Epoch: 5| Step: 6
Training loss: 0.6653687357902527
Validation loss: 1.7930203445496098

Epoch: 5| Step: 7
Training loss: 1.0680896043777466
Validation loss: 1.7973189905125608

Epoch: 5| Step: 8
Training loss: 0.6557365655899048
Validation loss: 1.782261792049613

Epoch: 5| Step: 9
Training loss: 0.9765467643737793
Validation loss: 1.7655772060476325

Epoch: 5| Step: 10
Training loss: 0.6815274357795715
Validation loss: 1.7514882395344396

Epoch: 262| Step: 0
Training loss: 0.7748199701309204
Validation loss: 1.7878463742553548

Epoch: 5| Step: 1
Training loss: 0.8925784826278687
Validation loss: 1.7894375067885204

Epoch: 5| Step: 2
Training loss: 0.6110299825668335
Validation loss: 1.8291054291109885

Epoch: 5| Step: 3
Training loss: 0.789483904838562
Validation loss: 1.8759374938985354

Epoch: 5| Step: 4
Training loss: 0.8990891575813293
Validation loss: 1.869977242203169

Epoch: 5| Step: 5
Training loss: 0.7498306035995483
Validation loss: 1.864305865380072

Epoch: 5| Step: 6
Training loss: 0.5577977895736694
Validation loss: 1.8264974804334744

Epoch: 5| Step: 7
Training loss: 1.0160175561904907
Validation loss: 1.8195368295074792

Epoch: 5| Step: 8
Training loss: 0.7505858540534973
Validation loss: 1.7978137000914542

Epoch: 5| Step: 9
Training loss: 0.7547990679740906
Validation loss: 1.8119710248003724

Epoch: 5| Step: 10
Training loss: 0.7639133334159851
Validation loss: 1.8510072974748508

Epoch: 263| Step: 0
Training loss: 0.736348032951355
Validation loss: 1.8478499868864655

Epoch: 5| Step: 1
Training loss: 0.7503432035446167
Validation loss: 1.8306435205603158

Epoch: 5| Step: 2
Training loss: 0.6395121812820435
Validation loss: 1.8059630240163496

Epoch: 5| Step: 3
Training loss: 0.41547471284866333
Validation loss: 1.8149596234803558

Epoch: 5| Step: 4
Training loss: 1.455025315284729
Validation loss: 1.8185676374743063

Epoch: 5| Step: 5
Training loss: 0.5953273773193359
Validation loss: 1.8628354226389239

Epoch: 5| Step: 6
Training loss: 0.41259703040122986
Validation loss: 1.8495503907562585

Epoch: 5| Step: 7
Training loss: 0.6939465999603271
Validation loss: 1.8405741901807888

Epoch: 5| Step: 8
Training loss: 1.0746290683746338
Validation loss: 1.833929684854323

Epoch: 5| Step: 9
Training loss: 0.8912509083747864
Validation loss: 1.83320616650325

Epoch: 5| Step: 10
Training loss: 0.6906645894050598
Validation loss: 1.8399572551891368

Epoch: 264| Step: 0
Training loss: 0.5845111012458801
Validation loss: 1.8541571247962214

Epoch: 5| Step: 1
Training loss: 0.6780627965927124
Validation loss: 1.8414290284597745

Epoch: 5| Step: 2
Training loss: 1.0492558479309082
Validation loss: 1.8553667273572696

Epoch: 5| Step: 3
Training loss: 0.3003130555152893
Validation loss: 1.8783900955671906

Epoch: 5| Step: 4
Training loss: 0.5451720952987671
Validation loss: 1.8723809795994912

Epoch: 5| Step: 5
Training loss: 0.7610451579093933
Validation loss: 1.8553158813907253

Epoch: 5| Step: 6
Training loss: 1.1370885372161865
Validation loss: 1.8592614563562537

Epoch: 5| Step: 7
Training loss: 0.6130157709121704
Validation loss: 1.8754333501221032

Epoch: 5| Step: 8
Training loss: 0.830523669719696
Validation loss: 1.8332422920452651

Epoch: 5| Step: 9
Training loss: 0.795472264289856
Validation loss: 1.8221057461154075

Epoch: 5| Step: 10
Training loss: 0.8416466116905212
Validation loss: 1.8046998029114099

Epoch: 265| Step: 0
Training loss: 0.5413622856140137
Validation loss: 1.814562282254619

Epoch: 5| Step: 1
Training loss: 0.5399933457374573
Validation loss: 1.8326890109687723

Epoch: 5| Step: 2
Training loss: 0.7615489959716797
Validation loss: 1.7897913814872823

Epoch: 5| Step: 3
Training loss: 0.547802746295929
Validation loss: 1.819248728854682

Epoch: 5| Step: 4
Training loss: 0.8013229370117188
Validation loss: 1.8224316489311956

Epoch: 5| Step: 5
Training loss: 0.669105052947998
Validation loss: 1.7990446705971994

Epoch: 5| Step: 6
Training loss: 0.7589802145957947
Validation loss: 1.7863460176734514

Epoch: 5| Step: 7
Training loss: 0.893298327922821
Validation loss: 1.8274118605480398

Epoch: 5| Step: 8
Training loss: 0.8196437954902649
Validation loss: 1.847908757066214

Epoch: 5| Step: 9
Training loss: 0.5799218416213989
Validation loss: 1.8049248085227063

Epoch: 5| Step: 10
Training loss: 0.9445587396621704
Validation loss: 1.8013319558994745

Epoch: 266| Step: 0
Training loss: 0.7127736210823059
Validation loss: 1.8007572671418548

Epoch: 5| Step: 1
Training loss: 1.0505521297454834
Validation loss: 1.8400028982470114

Epoch: 5| Step: 2
Training loss: 0.5799294114112854
Validation loss: 1.8423414845620432

Epoch: 5| Step: 3
Training loss: 0.8473218679428101
Validation loss: 1.8669841058792607

Epoch: 5| Step: 4
Training loss: 0.44612687826156616
Validation loss: 1.8542144080644012

Epoch: 5| Step: 5
Training loss: 0.7321379780769348
Validation loss: 1.87763415357118

Epoch: 5| Step: 6
Training loss: 0.8456156849861145
Validation loss: 1.8615594346036193

Epoch: 5| Step: 7
Training loss: 0.4637385308742523
Validation loss: 1.839502038494233

Epoch: 5| Step: 8
Training loss: 0.5535557270050049
Validation loss: 1.8440297483116068

Epoch: 5| Step: 9
Training loss: 0.45993319153785706
Validation loss: 1.816632581013505

Epoch: 5| Step: 10
Training loss: 1.0722875595092773
Validation loss: 1.8441667992581603

Epoch: 267| Step: 0
Training loss: 0.55353182554245
Validation loss: 1.8111339640873734

Epoch: 5| Step: 1
Training loss: 0.6117926836013794
Validation loss: 1.8197849463391047

Epoch: 5| Step: 2
Training loss: 0.7226675748825073
Validation loss: 1.8364977336698962

Epoch: 5| Step: 3
Training loss: 0.989368736743927
Validation loss: 1.8783519370581514

Epoch: 5| Step: 4
Training loss: 0.8899866938591003
Validation loss: 1.8953848936224496

Epoch: 5| Step: 5
Training loss: 0.48259466886520386
Validation loss: 1.8324481389855827

Epoch: 5| Step: 6
Training loss: 0.5299059748649597
Validation loss: 1.8082663935999717

Epoch: 5| Step: 7
Training loss: 0.7627370357513428
Validation loss: 1.812367759725099

Epoch: 5| Step: 8
Training loss: 1.1101925373077393
Validation loss: 1.795202552631337

Epoch: 5| Step: 9
Training loss: 0.5921576023101807
Validation loss: 1.7584361850574453

Epoch: 5| Step: 10
Training loss: 0.6453108787536621
Validation loss: 1.8247449949223509

Epoch: 268| Step: 0
Training loss: 0.4834853708744049
Validation loss: 1.8137218131813952

Epoch: 5| Step: 1
Training loss: 0.6874632835388184
Validation loss: 1.8248497862969675

Epoch: 5| Step: 2
Training loss: 0.7005574703216553
Validation loss: 1.8343649359159573

Epoch: 5| Step: 3
Training loss: 0.6511957049369812
Validation loss: 1.850261257540795

Epoch: 5| Step: 4
Training loss: 0.9249167442321777
Validation loss: 1.8717113733291626

Epoch: 5| Step: 5
Training loss: 0.6569398641586304
Validation loss: 1.8299217890667658

Epoch: 5| Step: 6
Training loss: 0.724037230014801
Validation loss: 1.8562899302410822

Epoch: 5| Step: 7
Training loss: 0.5472344756126404
Validation loss: 1.849379398489511

Epoch: 5| Step: 8
Training loss: 0.45831775665283203
Validation loss: 1.8147555474312074

Epoch: 5| Step: 9
Training loss: 1.3534431457519531
Validation loss: 1.8061423019696308

Epoch: 5| Step: 10
Training loss: 0.5001319646835327
Validation loss: 1.810019927640115

Epoch: 269| Step: 0
Training loss: 0.6803334951400757
Validation loss: 1.7771463894074964

Epoch: 5| Step: 1
Training loss: 0.475322425365448
Validation loss: 1.7985320885976155

Epoch: 5| Step: 2
Training loss: 1.038815975189209
Validation loss: 1.806729785857662

Epoch: 5| Step: 3
Training loss: 0.9451724886894226
Validation loss: 1.8332483614644697

Epoch: 5| Step: 4
Training loss: 0.45016321539878845
Validation loss: 1.8305758173747728

Epoch: 5| Step: 5
Training loss: 0.6444815397262573
Validation loss: 1.8687791157794256

Epoch: 5| Step: 6
Training loss: 0.775402843952179
Validation loss: 1.8310247121318695

Epoch: 5| Step: 7
Training loss: 0.8002622723579407
Validation loss: 1.8581163088480632

Epoch: 5| Step: 8
Training loss: 0.6127320528030396
Validation loss: 1.812605365630119

Epoch: 5| Step: 9
Training loss: 0.5763528943061829
Validation loss: 1.789803599798551

Epoch: 5| Step: 10
Training loss: 0.551525354385376
Validation loss: 1.8001549782291535

Epoch: 270| Step: 0
Training loss: 0.5684423446655273
Validation loss: 1.7767199982878983

Epoch: 5| Step: 1
Training loss: 0.581803023815155
Validation loss: 1.7872835666902605

Epoch: 5| Step: 2
Training loss: 0.3106727600097656
Validation loss: 1.8094684744393954

Epoch: 5| Step: 3
Training loss: 0.6143949627876282
Validation loss: 1.7941335785773493

Epoch: 5| Step: 4
Training loss: 0.7357304096221924
Validation loss: 1.8094277843352287

Epoch: 5| Step: 5
Training loss: 0.8161085247993469
Validation loss: 1.8285937719447638

Epoch: 5| Step: 6
Training loss: 0.8865659832954407
Validation loss: 1.825613840933769

Epoch: 5| Step: 7
Training loss: 0.767276406288147
Validation loss: 1.8391430429233018

Epoch: 5| Step: 8
Training loss: 0.8372980952262878
Validation loss: 1.8615694187020744

Epoch: 5| Step: 9
Training loss: 0.752528190612793
Validation loss: 1.8502890012597526

Epoch: 5| Step: 10
Training loss: 0.9664931297302246
Validation loss: 1.7913206661901167

Epoch: 271| Step: 0
Training loss: 0.6264663338661194
Validation loss: 1.8570836846546461

Epoch: 5| Step: 1
Training loss: 0.5697993040084839
Validation loss: 1.8365606031110209

Epoch: 5| Step: 2
Training loss: 1.0715864896774292
Validation loss: 1.8504232591198337

Epoch: 5| Step: 3
Training loss: 0.42714300751686096
Validation loss: 1.87957089947116

Epoch: 5| Step: 4
Training loss: 0.6271998882293701
Validation loss: 1.8726241293773855

Epoch: 5| Step: 5
Training loss: 0.6434496641159058
Validation loss: 1.8579747112848426

Epoch: 5| Step: 6
Training loss: 0.7013434171676636
Validation loss: 1.883211975456566

Epoch: 5| Step: 7
Training loss: 0.9134811162948608
Validation loss: 1.885564863040883

Epoch: 5| Step: 8
Training loss: 0.6843577027320862
Validation loss: 1.8930084551534345

Epoch: 5| Step: 9
Training loss: 0.549726128578186
Validation loss: 1.8700234210619362

Epoch: 5| Step: 10
Training loss: 0.9126241207122803
Validation loss: 1.8871446348005725

Epoch: 272| Step: 0
Training loss: 0.6323081254959106
Validation loss: 1.8965080732940345

Epoch: 5| Step: 1
Training loss: 0.7129758596420288
Validation loss: 1.8960408767064412

Epoch: 5| Step: 2
Training loss: 0.5247671604156494
Validation loss: 1.8790752746725594

Epoch: 5| Step: 3
Training loss: 0.5641618967056274
Validation loss: 1.8055935662279847

Epoch: 5| Step: 4
Training loss: 0.9778486490249634
Validation loss: 1.8607202896507837

Epoch: 5| Step: 5
Training loss: 0.9481433629989624
Validation loss: 1.8476581317122265

Epoch: 5| Step: 6
Training loss: 0.7060127258300781
Validation loss: 1.8501519797950663

Epoch: 5| Step: 7
Training loss: 0.9178007245063782
Validation loss: 1.8626829193484398

Epoch: 5| Step: 8
Training loss: 0.3873630166053772
Validation loss: 1.8208030218719153

Epoch: 5| Step: 9
Training loss: 0.3438922166824341
Validation loss: 1.8418963609203216

Epoch: 5| Step: 10
Training loss: 0.8199652433395386
Validation loss: 1.8236838450995825

Epoch: 273| Step: 0
Training loss: 0.38305729627609253
Validation loss: 1.8089163739194152

Epoch: 5| Step: 1
Training loss: 0.6941329836845398
Validation loss: 1.8001531221533333

Epoch: 5| Step: 2
Training loss: 0.6670127511024475
Validation loss: 1.809729637638215

Epoch: 5| Step: 3
Training loss: 0.4580985903739929
Validation loss: 1.8060133662275089

Epoch: 5| Step: 4
Training loss: 0.503618061542511
Validation loss: 1.8046570542038127

Epoch: 5| Step: 5
Training loss: 0.814774215221405
Validation loss: 1.8237376392528575

Epoch: 5| Step: 6
Training loss: 0.3936825692653656
Validation loss: 1.8097768470805178

Epoch: 5| Step: 7
Training loss: 0.6691393256187439
Validation loss: 1.796936987548746

Epoch: 5| Step: 8
Training loss: 0.6115067601203918
Validation loss: 1.813255568986298

Epoch: 5| Step: 9
Training loss: 0.899641215801239
Validation loss: 1.8547945740402385

Epoch: 5| Step: 10
Training loss: 1.268856406211853
Validation loss: 1.8564297153103737

Epoch: 274| Step: 0
Training loss: 0.7375949621200562
Validation loss: 1.8353647339728572

Epoch: 5| Step: 1
Training loss: 0.6676818132400513
Validation loss: 1.8478684630445255

Epoch: 5| Step: 2
Training loss: 1.020844578742981
Validation loss: 1.8640330235163372

Epoch: 5| Step: 3
Training loss: 0.5602405667304993
Validation loss: 1.8811888310217089

Epoch: 5| Step: 4
Training loss: 0.5442336797714233
Validation loss: 1.8944928030813895

Epoch: 5| Step: 5
Training loss: 0.5170081257820129
Validation loss: 1.8832810232716222

Epoch: 5| Step: 6
Training loss: 0.7356325387954712
Validation loss: 1.842106790952785

Epoch: 5| Step: 7
Training loss: 0.8006330728530884
Validation loss: 1.7963226918251283

Epoch: 5| Step: 8
Training loss: 0.5739086866378784
Validation loss: 1.814785280535298

Epoch: 5| Step: 9
Training loss: 0.6198918223381042
Validation loss: 1.7710634367440337

Epoch: 5| Step: 10
Training loss: 0.6368988156318665
Validation loss: 1.7746384977012553

Epoch: 275| Step: 0
Training loss: 0.755025327205658
Validation loss: 1.7687035811844694

Epoch: 5| Step: 1
Training loss: 0.6990304589271545
Validation loss: 1.7519159611835275

Epoch: 5| Step: 2
Training loss: 0.4432199001312256
Validation loss: 1.7530536113246795

Epoch: 5| Step: 3
Training loss: 0.6346416473388672
Validation loss: 1.7791919259614841

Epoch: 5| Step: 4
Training loss: 0.4543134570121765
Validation loss: 1.8475511125338975

Epoch: 5| Step: 5
Training loss: 0.6631020903587341
Validation loss: 1.8830346189519411

Epoch: 5| Step: 6
Training loss: 0.7619847059249878
Validation loss: 1.93552355868842

Epoch: 5| Step: 7
Training loss: 0.9151932001113892
Validation loss: 1.9624835419398483

Epoch: 5| Step: 8
Training loss: 0.8685269355773926
Validation loss: 1.9410295640268633

Epoch: 5| Step: 9
Training loss: 0.46540728211402893
Validation loss: 1.8953137795130413

Epoch: 5| Step: 10
Training loss: 1.0626367330551147
Validation loss: 1.8125979682450652

Epoch: 276| Step: 0
Training loss: 0.4991718828678131
Validation loss: 1.8290403273797804

Epoch: 5| Step: 1
Training loss: 0.96723473072052
Validation loss: 1.8027532113495695

Epoch: 5| Step: 2
Training loss: 0.8240720629692078
Validation loss: 1.8335545985929427

Epoch: 5| Step: 3
Training loss: 1.073352575302124
Validation loss: 1.838126459429341

Epoch: 5| Step: 4
Training loss: 0.5800917148590088
Validation loss: 1.8538955450057983

Epoch: 5| Step: 5
Training loss: 0.5920791625976562
Validation loss: 1.8759250025595389

Epoch: 5| Step: 6
Training loss: 0.41542330384254456
Validation loss: 1.8819364296492709

Epoch: 5| Step: 7
Training loss: 0.9410392045974731
Validation loss: 1.856176689106931

Epoch: 5| Step: 8
Training loss: 0.5341339111328125
Validation loss: 1.835585416004222

Epoch: 5| Step: 9
Training loss: 0.47971582412719727
Validation loss: 1.828992978219063

Epoch: 5| Step: 10
Training loss: 0.7575795650482178
Validation loss: 1.7947962642997823

Epoch: 277| Step: 0
Training loss: 0.727133572101593
Validation loss: 1.7729405517219214

Epoch: 5| Step: 1
Training loss: 0.8935174942016602
Validation loss: 1.7727060369265977

Epoch: 5| Step: 2
Training loss: 0.5667279362678528
Validation loss: 1.7623898111363894

Epoch: 5| Step: 3
Training loss: 0.5625072717666626
Validation loss: 1.792494479046073

Epoch: 5| Step: 4
Training loss: 0.5123454928398132
Validation loss: 1.7957758031865603

Epoch: 5| Step: 5
Training loss: 0.7897551655769348
Validation loss: 1.8449370732871435

Epoch: 5| Step: 6
Training loss: 0.5002133250236511
Validation loss: 1.8681173247675742

Epoch: 5| Step: 7
Training loss: 0.44857221841812134
Validation loss: 1.8593289134322957

Epoch: 5| Step: 8
Training loss: 0.7634279727935791
Validation loss: 1.8718891374526485

Epoch: 5| Step: 9
Training loss: 0.6428542733192444
Validation loss: 1.8538572531874462

Epoch: 5| Step: 10
Training loss: 0.8467364311218262
Validation loss: 1.8480083352775984

Epoch: 278| Step: 0
Training loss: 1.0567257404327393
Validation loss: 1.8612464333093295

Epoch: 5| Step: 1
Training loss: 0.5756096839904785
Validation loss: 1.8438600276106147

Epoch: 5| Step: 2
Training loss: 0.18261048197746277
Validation loss: 1.8209092463216474

Epoch: 5| Step: 3
Training loss: 0.8095701336860657
Validation loss: 1.821386533398782

Epoch: 5| Step: 4
Training loss: 0.5963553190231323
Validation loss: 1.767993816765406

Epoch: 5| Step: 5
Training loss: 0.5486389398574829
Validation loss: 1.8093746964649489

Epoch: 5| Step: 6
Training loss: 0.4161311984062195
Validation loss: 1.8341689058529433

Epoch: 5| Step: 7
Training loss: 0.5301650762557983
Validation loss: 1.8430703686129661

Epoch: 5| Step: 8
Training loss: 0.7278262376785278
Validation loss: 1.8439908348104006

Epoch: 5| Step: 9
Training loss: 0.8572912216186523
Validation loss: 1.8670272904057656

Epoch: 5| Step: 10
Training loss: 1.0060240030288696
Validation loss: 1.8562797243877123

Epoch: 279| Step: 0
Training loss: 0.5524770617485046
Validation loss: 1.8580587499885148

Epoch: 5| Step: 1
Training loss: 1.0768941640853882
Validation loss: 1.9050053550351052

Epoch: 5| Step: 2
Training loss: 0.5881824493408203
Validation loss: 1.8637177021272722

Epoch: 5| Step: 3
Training loss: 0.7640310525894165
Validation loss: 1.8830716045953895

Epoch: 5| Step: 4
Training loss: 0.6752524375915527
Validation loss: 1.8647694151888612

Epoch: 5| Step: 5
Training loss: 0.5197889804840088
Validation loss: 1.8837175856354416

Epoch: 5| Step: 6
Training loss: 0.37565290927886963
Validation loss: 1.8505233590320875

Epoch: 5| Step: 7
Training loss: 0.4862744212150574
Validation loss: 1.892916916519083

Epoch: 5| Step: 8
Training loss: 0.7557785511016846
Validation loss: 1.8547127349402315

Epoch: 5| Step: 9
Training loss: 0.8041430711746216
Validation loss: 1.8362148807894798

Epoch: 5| Step: 10
Training loss: 0.4771954119205475
Validation loss: 1.8108145979142958

Epoch: 280| Step: 0
Training loss: 0.6953940987586975
Validation loss: 1.8599129005145

Epoch: 5| Step: 1
Training loss: 0.6187139749526978
Validation loss: 1.8297450106631044

Epoch: 5| Step: 2
Training loss: 0.7753798365592957
Validation loss: 1.8299240450705252

Epoch: 5| Step: 3
Training loss: 0.6422500014305115
Validation loss: 1.823595763534628

Epoch: 5| Step: 4
Training loss: 0.35280224680900574
Validation loss: 1.8279157351422053

Epoch: 5| Step: 5
Training loss: 0.605829119682312
Validation loss: 1.820511092421829

Epoch: 5| Step: 6
Training loss: 0.7261190414428711
Validation loss: 1.817847926129577

Epoch: 5| Step: 7
Training loss: 0.47678786516189575
Validation loss: 1.834217297133579

Epoch: 5| Step: 8
Training loss: 0.6379164457321167
Validation loss: 1.8293577419814242

Epoch: 5| Step: 9
Training loss: 0.6186875104904175
Validation loss: 1.8212611072806901

Epoch: 5| Step: 10
Training loss: 0.7284486293792725
Validation loss: 1.850108047967316

Epoch: 281| Step: 0
Training loss: 0.5683631896972656
Validation loss: 1.85609685092844

Epoch: 5| Step: 1
Training loss: 0.826572597026825
Validation loss: 1.817031701405843

Epoch: 5| Step: 2
Training loss: 0.21338042616844177
Validation loss: 1.8409141417472594

Epoch: 5| Step: 3
Training loss: 0.6800833940505981
Validation loss: 1.8344532674358738

Epoch: 5| Step: 4
Training loss: 1.0170694589614868
Validation loss: 1.8524504323159494

Epoch: 5| Step: 5
Training loss: 0.7007327079772949
Validation loss: 1.8444595311277656

Epoch: 5| Step: 6
Training loss: 0.748846173286438
Validation loss: 1.8569601325578586

Epoch: 5| Step: 7
Training loss: 0.3495313227176666
Validation loss: 1.8467978726151169

Epoch: 5| Step: 8
Training loss: 0.8498897552490234
Validation loss: 1.8421721778890139

Epoch: 5| Step: 9
Training loss: 0.3695922791957855
Validation loss: 1.8311701128559728

Epoch: 5| Step: 10
Training loss: 0.7844947576522827
Validation loss: 1.8025752421348327

Epoch: 282| Step: 0
Training loss: 0.6405150890350342
Validation loss: 1.787605703517955

Epoch: 5| Step: 1
Training loss: 0.5706782341003418
Validation loss: 1.8059919854646087

Epoch: 5| Step: 2
Training loss: 0.9653066396713257
Validation loss: 1.8107488001546552

Epoch: 5| Step: 3
Training loss: 0.5571971535682678
Validation loss: 1.8132227787407496

Epoch: 5| Step: 4
Training loss: 0.4994736611843109
Validation loss: 1.8261676603747952

Epoch: 5| Step: 5
Training loss: 0.6832391619682312
Validation loss: 1.8257663993425266

Epoch: 5| Step: 6
Training loss: 0.7288658022880554
Validation loss: 1.8125432998903337

Epoch: 5| Step: 7
Training loss: 0.5404866933822632
Validation loss: 1.8288019459734681

Epoch: 5| Step: 8
Training loss: 0.6535205841064453
Validation loss: 1.8053997037231282

Epoch: 5| Step: 9
Training loss: 0.6871454119682312
Validation loss: 1.822303943736579

Epoch: 5| Step: 10
Training loss: 0.4338391125202179
Validation loss: 1.805101900972346

Epoch: 283| Step: 0
Training loss: 0.48350316286087036
Validation loss: 1.8028839198491906

Epoch: 5| Step: 1
Training loss: 0.5496280193328857
Validation loss: 1.809597869073191

Epoch: 5| Step: 2
Training loss: 0.8873840570449829
Validation loss: 1.760444861586376

Epoch: 5| Step: 3
Training loss: 0.523394763469696
Validation loss: 1.801747319518879

Epoch: 5| Step: 4
Training loss: 0.5033113956451416
Validation loss: 1.8300046459321053

Epoch: 5| Step: 5
Training loss: 0.7179694771766663
Validation loss: 1.8464675372646702

Epoch: 5| Step: 6
Training loss: 0.8600746989250183
Validation loss: 1.8700538335307952

Epoch: 5| Step: 7
Training loss: 0.6107107400894165
Validation loss: 1.8637936012719267

Epoch: 5| Step: 8
Training loss: 0.47775667905807495
Validation loss: 1.8450957677697624

Epoch: 5| Step: 9
Training loss: 0.5988425016403198
Validation loss: 1.8084616699526388

Epoch: 5| Step: 10
Training loss: 0.4929516613483429
Validation loss: 1.8333332487331924

Epoch: 284| Step: 0
Training loss: 0.5732361674308777
Validation loss: 1.8145254209477415

Epoch: 5| Step: 1
Training loss: 0.8291423916816711
Validation loss: 1.8416867640710646

Epoch: 5| Step: 2
Training loss: 0.7400490045547485
Validation loss: 1.8299026181620937

Epoch: 5| Step: 3
Training loss: 0.4941665232181549
Validation loss: 1.8826874943189724

Epoch: 5| Step: 4
Training loss: 0.6783713102340698
Validation loss: 1.8768904324500792

Epoch: 5| Step: 5
Training loss: 0.8081279993057251
Validation loss: 1.8698932637450516

Epoch: 5| Step: 6
Training loss: 0.6023759245872498
Validation loss: 1.8680522928955734

Epoch: 5| Step: 7
Training loss: 0.5583801865577698
Validation loss: 1.864170103944758

Epoch: 5| Step: 8
Training loss: 0.4811326563358307
Validation loss: 1.866367906652471

Epoch: 5| Step: 9
Training loss: 0.3220476508140564
Validation loss: 1.8328868445529733

Epoch: 5| Step: 10
Training loss: 0.6736527681350708
Validation loss: 1.8191680177565543

Epoch: 285| Step: 0
Training loss: 0.5238903760910034
Validation loss: 1.8149874607721965

Epoch: 5| Step: 1
Training loss: 0.5192731618881226
Validation loss: 1.809173668584516

Epoch: 5| Step: 2
Training loss: 0.8792707324028015
Validation loss: 1.8416362001049904

Epoch: 5| Step: 3
Training loss: 0.618766188621521
Validation loss: 1.8123319700200071

Epoch: 5| Step: 4
Training loss: 0.34050798416137695
Validation loss: 1.8214956278442054

Epoch: 5| Step: 5
Training loss: 0.35524100065231323
Validation loss: 1.842008972680697

Epoch: 5| Step: 6
Training loss: 0.755261242389679
Validation loss: 1.844519284463698

Epoch: 5| Step: 7
Training loss: 0.8557995557785034
Validation loss: 1.8526483505002913

Epoch: 5| Step: 8
Training loss: 0.5506638288497925
Validation loss: 1.8141331339395175

Epoch: 5| Step: 9
Training loss: 0.6476222276687622
Validation loss: 1.845488961024951

Epoch: 5| Step: 10
Training loss: 0.9338052272796631
Validation loss: 1.8051613569259644

Epoch: 286| Step: 0
Training loss: 0.45309966802597046
Validation loss: 1.804953412343097

Epoch: 5| Step: 1
Training loss: 0.48415088653564453
Validation loss: 1.7623714247057516

Epoch: 5| Step: 2
Training loss: 0.7911248803138733
Validation loss: 1.7536055580262215

Epoch: 5| Step: 3
Training loss: 0.7979918122291565
Validation loss: 1.7407943228239655

Epoch: 5| Step: 4
Training loss: 0.9486011266708374
Validation loss: 1.7504199089542511

Epoch: 5| Step: 5
Training loss: 0.3437606990337372
Validation loss: 1.743297420522218

Epoch: 5| Step: 6
Training loss: 0.5376031398773193
Validation loss: 1.7701851578168972

Epoch: 5| Step: 7
Training loss: 0.5853594541549683
Validation loss: 1.8081442758601198

Epoch: 5| Step: 8
Training loss: 0.48017698526382446
Validation loss: 1.8156812793465071

Epoch: 5| Step: 9
Training loss: 0.6926563382148743
Validation loss: 1.8580813074624667

Epoch: 5| Step: 10
Training loss: 0.8462211489677429
Validation loss: 1.9097628875445294

Epoch: 287| Step: 0
Training loss: 0.50438392162323
Validation loss: 1.8661837167637323

Epoch: 5| Step: 1
Training loss: 0.8319476246833801
Validation loss: 1.8512765246052896

Epoch: 5| Step: 2
Training loss: 0.4639633297920227
Validation loss: 1.8371581364703435

Epoch: 5| Step: 3
Training loss: 0.4381182789802551
Validation loss: 1.7804831099766556

Epoch: 5| Step: 4
Training loss: 0.8079999685287476
Validation loss: 1.7610646922101256

Epoch: 5| Step: 5
Training loss: 0.5299318432807922
Validation loss: 1.7547742295008835

Epoch: 5| Step: 6
Training loss: 0.7722000479698181
Validation loss: 1.7548463947029525

Epoch: 5| Step: 7
Training loss: 0.9263675808906555
Validation loss: 1.7539559013100081

Epoch: 5| Step: 8
Training loss: 0.432203471660614
Validation loss: 1.7893672566260062

Epoch: 5| Step: 9
Training loss: 0.8156968355178833
Validation loss: 1.806004080721127

Epoch: 5| Step: 10
Training loss: 0.6236029863357544
Validation loss: 1.7883212425375496

Epoch: 288| Step: 0
Training loss: 0.8571810722351074
Validation loss: 1.8217292165243497

Epoch: 5| Step: 1
Training loss: 0.6018968820571899
Validation loss: 1.8355552124720749

Epoch: 5| Step: 2
Training loss: 0.5194936990737915
Validation loss: 1.8579932271793325

Epoch: 5| Step: 3
Training loss: 0.5530146360397339
Validation loss: 1.8885347304805633

Epoch: 5| Step: 4
Training loss: 0.6769036054611206
Validation loss: 1.8717723123488887

Epoch: 5| Step: 5
Training loss: 0.7283933758735657
Validation loss: 1.880499735955269

Epoch: 5| Step: 6
Training loss: 0.5572757124900818
Validation loss: 1.8368655391918716

Epoch: 5| Step: 7
Training loss: 0.863717257976532
Validation loss: 1.8636094216377503

Epoch: 5| Step: 8
Training loss: 0.562616765499115
Validation loss: 1.8485875796246272

Epoch: 5| Step: 9
Training loss: 0.41079217195510864
Validation loss: 1.824221658450301

Epoch: 5| Step: 10
Training loss: 0.602016270160675
Validation loss: 1.8260349022444857

Epoch: 289| Step: 0
Training loss: 0.3984390199184418
Validation loss: 1.7913335574570524

Epoch: 5| Step: 1
Training loss: 0.20423023402690887
Validation loss: 1.8009285221817672

Epoch: 5| Step: 2
Training loss: 0.809348464012146
Validation loss: 1.8198266618995256

Epoch: 5| Step: 3
Training loss: 0.683121919631958
Validation loss: 1.8595317717521422

Epoch: 5| Step: 4
Training loss: 0.49735379219055176
Validation loss: 1.9035404254031438

Epoch: 5| Step: 5
Training loss: 0.6612728238105774
Validation loss: 1.8631849519668087

Epoch: 5| Step: 6
Training loss: 0.8831896781921387
Validation loss: 1.8944257856697164

Epoch: 5| Step: 7
Training loss: 0.5130525827407837
Validation loss: 1.8395367976157897

Epoch: 5| Step: 8
Training loss: 0.5581492185592651
Validation loss: 1.8956613598331329

Epoch: 5| Step: 9
Training loss: 0.8310419321060181
Validation loss: 1.8410844443946757

Epoch: 5| Step: 10
Training loss: 0.6290125250816345
Validation loss: 1.8221738992198822

Epoch: 290| Step: 0
Training loss: 0.8267562985420227
Validation loss: 1.8289450394209994

Epoch: 5| Step: 1
Training loss: 0.6935837268829346
Validation loss: 1.7944097019010974

Epoch: 5| Step: 2
Training loss: 0.4643518924713135
Validation loss: 1.8136962485569779

Epoch: 5| Step: 3
Training loss: 0.6343504190444946
Validation loss: 1.8021697036681636

Epoch: 5| Step: 4
Training loss: 0.6260358095169067
Validation loss: 1.786103258850754

Epoch: 5| Step: 5
Training loss: 0.5276566743850708
Validation loss: 1.7811852283375238

Epoch: 5| Step: 6
Training loss: 0.41766977310180664
Validation loss: 1.7879696097425235

Epoch: 5| Step: 7
Training loss: 0.5164657831192017
Validation loss: 1.8096213340759277

Epoch: 5| Step: 8
Training loss: 0.5779867172241211
Validation loss: 1.7770031049687376

Epoch: 5| Step: 9
Training loss: 0.8015807271003723
Validation loss: 1.7903376138338478

Epoch: 5| Step: 10
Training loss: 0.4874887466430664
Validation loss: 1.8286618225036129

Epoch: 291| Step: 0
Training loss: 0.6103180646896362
Validation loss: 1.8423129076598792

Epoch: 5| Step: 1
Training loss: 0.28468242287635803
Validation loss: 1.862874807850007

Epoch: 5| Step: 2
Training loss: 0.6950641870498657
Validation loss: 1.8698203525235575

Epoch: 5| Step: 3
Training loss: 0.8158496618270874
Validation loss: 1.855656849440708

Epoch: 5| Step: 4
Training loss: 0.47204723954200745
Validation loss: 1.8268255751620057

Epoch: 5| Step: 5
Training loss: 0.5445282459259033
Validation loss: 1.7965811990922498

Epoch: 5| Step: 6
Training loss: 0.8824933767318726
Validation loss: 1.8208684946901055

Epoch: 5| Step: 7
Training loss: 0.6850172877311707
Validation loss: 1.7863487043688375

Epoch: 5| Step: 8
Training loss: 0.3594300448894501
Validation loss: 1.8095133663505636

Epoch: 5| Step: 9
Training loss: 0.8418936729431152
Validation loss: 1.789085590711204

Epoch: 5| Step: 10
Training loss: 0.3115948438644409
Validation loss: 1.7821146262589322

Epoch: 292| Step: 0
Training loss: 0.6577338576316833
Validation loss: 1.801105140357889

Epoch: 5| Step: 1
Training loss: 0.5805612206459045
Validation loss: 1.8136131327639344

Epoch: 5| Step: 2
Training loss: 0.498739629983902
Validation loss: 1.8402345949603665

Epoch: 5| Step: 3
Training loss: 0.6681197881698608
Validation loss: 1.8218548285063876

Epoch: 5| Step: 4
Training loss: 0.6488285660743713
Validation loss: 1.830924243055364

Epoch: 5| Step: 5
Training loss: 0.670208752155304
Validation loss: 1.8097294735652145

Epoch: 5| Step: 6
Training loss: 0.4957253038883209
Validation loss: 1.816033006996237

Epoch: 5| Step: 7
Training loss: 0.39978116750717163
Validation loss: 1.805035929526052

Epoch: 5| Step: 8
Training loss: 0.6214180588722229
Validation loss: 1.8032149986554218

Epoch: 5| Step: 9
Training loss: 0.5192854404449463
Validation loss: 1.8069797023650138

Epoch: 5| Step: 10
Training loss: 0.5986856818199158
Validation loss: 1.7508165861970635

Epoch: 293| Step: 0
Training loss: 0.6419174075126648
Validation loss: 1.7926391529780563

Epoch: 5| Step: 1
Training loss: 0.5500520467758179
Validation loss: 1.7539378840436217

Epoch: 5| Step: 2
Training loss: 0.880017876625061
Validation loss: 1.8013420540799376

Epoch: 5| Step: 3
Training loss: 0.5770717859268188
Validation loss: 1.8141564053873862

Epoch: 5| Step: 4
Training loss: 0.415985643863678
Validation loss: 1.8039636240210584

Epoch: 5| Step: 5
Training loss: 0.3880898356437683
Validation loss: 1.7934470356151622

Epoch: 5| Step: 6
Training loss: 0.5902090668678284
Validation loss: 1.8081507503345449

Epoch: 5| Step: 7
Training loss: 0.6847522854804993
Validation loss: 1.834696364659135

Epoch: 5| Step: 8
Training loss: 0.29611849784851074
Validation loss: 1.8100846505934192

Epoch: 5| Step: 9
Training loss: 0.5903538465499878
Validation loss: 1.7930180411184988

Epoch: 5| Step: 10
Training loss: 0.6299742460250854
Validation loss: 1.784286251632116

Epoch: 294| Step: 0
Training loss: 0.45214763283729553
Validation loss: 1.7954912698397072

Epoch: 5| Step: 1
Training loss: 0.749356210231781
Validation loss: 1.7974283079947195

Epoch: 5| Step: 2
Training loss: 0.6612730026245117
Validation loss: 1.7649504561578073

Epoch: 5| Step: 3
Training loss: 0.5334233045578003
Validation loss: 1.8037213458809802

Epoch: 5| Step: 4
Training loss: 0.648511528968811
Validation loss: 1.7909785291200042

Epoch: 5| Step: 5
Training loss: 0.5562918782234192
Validation loss: 1.8524049892220447

Epoch: 5| Step: 6
Training loss: 0.39903610944747925
Validation loss: 1.8929125814027683

Epoch: 5| Step: 7
Training loss: 0.31384915113449097
Validation loss: 1.9205160858810588

Epoch: 5| Step: 8
Training loss: 0.7054124474525452
Validation loss: 1.893956333078364

Epoch: 5| Step: 9
Training loss: 0.7148001790046692
Validation loss: 1.870122976200555

Epoch: 5| Step: 10
Training loss: 0.7280963659286499
Validation loss: 1.8568313173068467

Epoch: 295| Step: 0
Training loss: 0.4085381031036377
Validation loss: 1.812206035019249

Epoch: 5| Step: 1
Training loss: 0.4848375916481018
Validation loss: 1.79008012945934

Epoch: 5| Step: 2
Training loss: 0.7835402488708496
Validation loss: 1.8229514578337311

Epoch: 5| Step: 3
Training loss: 0.4571912884712219
Validation loss: 1.7991267647794498

Epoch: 5| Step: 4
Training loss: 0.5703459978103638
Validation loss: 1.7938979441119778

Epoch: 5| Step: 5
Training loss: 0.8416444659233093
Validation loss: 1.8309882892075406

Epoch: 5| Step: 6
Training loss: 0.39126914739608765
Validation loss: 1.8280186037863455

Epoch: 5| Step: 7
Training loss: 0.4786694049835205
Validation loss: 1.8054943264171641

Epoch: 5| Step: 8
Training loss: 0.8411766290664673
Validation loss: 1.8303689008118005

Epoch: 5| Step: 9
Training loss: 0.27658897638320923
Validation loss: 1.8491679160825667

Epoch: 5| Step: 10
Training loss: 0.6935312151908875
Validation loss: 1.864861221723659

Epoch: 296| Step: 0
Training loss: 0.6216416358947754
Validation loss: 1.8738282560020365

Epoch: 5| Step: 1
Training loss: 0.4382099509239197
Validation loss: 1.8836090359636533

Epoch: 5| Step: 2
Training loss: 0.5983855128288269
Validation loss: 1.8632690739888016

Epoch: 5| Step: 3
Training loss: 0.6745163798332214
Validation loss: 1.8674794948229225

Epoch: 5| Step: 4
Training loss: 0.41965121030807495
Validation loss: 1.8052235380295785

Epoch: 5| Step: 5
Training loss: 0.6222925186157227
Validation loss: 1.8124602558792278

Epoch: 5| Step: 6
Training loss: 0.6226962208747864
Validation loss: 1.774808435029881

Epoch: 5| Step: 7
Training loss: 0.4707542955875397
Validation loss: 1.7665639192827287

Epoch: 5| Step: 8
Training loss: 0.6814635992050171
Validation loss: 1.7950044883194791

Epoch: 5| Step: 9
Training loss: 0.4690024256706238
Validation loss: 1.7733572029298352

Epoch: 5| Step: 10
Training loss: 0.6721858382225037
Validation loss: 1.7589992541138844

Epoch: 297| Step: 0
Training loss: 0.5920323729515076
Validation loss: 1.7935094564191756

Epoch: 5| Step: 1
Training loss: 0.4381358027458191
Validation loss: 1.7778694463032547

Epoch: 5| Step: 2
Training loss: 0.4960728585720062
Validation loss: 1.7832913443606386

Epoch: 5| Step: 3
Training loss: 0.5121510624885559
Validation loss: 1.8164075600203646

Epoch: 5| Step: 4
Training loss: 0.9733117818832397
Validation loss: 1.8087453560162616

Epoch: 5| Step: 5
Training loss: 0.3902559280395508
Validation loss: 1.8446674039286952

Epoch: 5| Step: 6
Training loss: 0.4228908121585846
Validation loss: 1.8392127354939778

Epoch: 5| Step: 7
Training loss: 0.3577423691749573
Validation loss: 1.8181675685349332

Epoch: 5| Step: 8
Training loss: 0.6500429511070251
Validation loss: 1.8202082726263231

Epoch: 5| Step: 9
Training loss: 0.5576087236404419
Validation loss: 1.861569990393936

Epoch: 5| Step: 10
Training loss: 0.7887690663337708
Validation loss: 1.8334584671963927

Epoch: 298| Step: 0
Training loss: 0.990088164806366
Validation loss: 1.8514924228832286

Epoch: 5| Step: 1
Training loss: 0.5905992388725281
Validation loss: 1.8455570923384799

Epoch: 5| Step: 2
Training loss: 0.3676151633262634
Validation loss: 1.843475918616018

Epoch: 5| Step: 3
Training loss: 0.5612371563911438
Validation loss: 1.8283167116103634

Epoch: 5| Step: 4
Training loss: 0.5450863242149353
Validation loss: 1.819222173383159

Epoch: 5| Step: 5
Training loss: 0.5377459526062012
Validation loss: 1.8160960328194402

Epoch: 5| Step: 6
Training loss: 0.7789884805679321
Validation loss: 1.8121027408107635

Epoch: 5| Step: 7
Training loss: 0.42384999990463257
Validation loss: 1.792767979765451

Epoch: 5| Step: 8
Training loss: 0.3628055155277252
Validation loss: 1.8079810129698886

Epoch: 5| Step: 9
Training loss: 0.26634910702705383
Validation loss: 1.822157031746321

Epoch: 5| Step: 10
Training loss: 0.41081488132476807
Validation loss: 1.7928388157198507

Epoch: 299| Step: 0
Training loss: 0.3098347783088684
Validation loss: 1.8348226188331522

Epoch: 5| Step: 1
Training loss: 0.5090668201446533
Validation loss: 1.8271360499884493

Epoch: 5| Step: 2
Training loss: 0.5953118205070496
Validation loss: 1.8184224456869147

Epoch: 5| Step: 3
Training loss: 0.8810052871704102
Validation loss: 1.79815657677189

Epoch: 5| Step: 4
Training loss: 0.7183001637458801
Validation loss: 1.786692186068463

Epoch: 5| Step: 5
Training loss: 0.4253741204738617
Validation loss: 1.8049804343972156

Epoch: 5| Step: 6
Training loss: 0.4417235255241394
Validation loss: 1.7666074281097741

Epoch: 5| Step: 7
Training loss: 0.44502678513526917
Validation loss: 1.7770369796342746

Epoch: 5| Step: 8
Training loss: 0.4482816755771637
Validation loss: 1.7849534775621148

Epoch: 5| Step: 9
Training loss: 0.7780044674873352
Validation loss: 1.7858283641517803

Epoch: 5| Step: 10
Training loss: 0.6412146687507629
Validation loss: 1.7921065720178748

Epoch: 300| Step: 0
Training loss: 0.6681367754936218
Validation loss: 1.7812627951304119

Epoch: 5| Step: 1
Training loss: 0.5896004438400269
Validation loss: 1.8150463129884453

Epoch: 5| Step: 2
Training loss: 0.510012149810791
Validation loss: 1.7858596335175216

Epoch: 5| Step: 3
Training loss: 0.5208615064620972
Validation loss: 1.8479183617458548

Epoch: 5| Step: 4
Training loss: 0.5787833333015442
Validation loss: 1.8400561886449014

Epoch: 5| Step: 5
Training loss: 0.5274251699447632
Validation loss: 1.843349846460486

Epoch: 5| Step: 6
Training loss: 0.4592142701148987
Validation loss: 1.8406832141260947

Epoch: 5| Step: 7
Training loss: 0.2833324074745178
Validation loss: 1.8226363838359874

Epoch: 5| Step: 8
Training loss: 0.33291131258010864
Validation loss: 1.8087974235575686

Epoch: 5| Step: 9
Training loss: 0.7687511444091797
Validation loss: 1.8338373630277571

Epoch: 5| Step: 10
Training loss: 0.5547840595245361
Validation loss: 1.8112903615479827

Epoch: 301| Step: 0
Training loss: 0.6523202061653137
Validation loss: 1.7833376981878792

Epoch: 5| Step: 1
Training loss: 0.41030606627464294
Validation loss: 1.7824385140531807

Epoch: 5| Step: 2
Training loss: 0.4538136422634125
Validation loss: 1.8052019226935603

Epoch: 5| Step: 3
Training loss: 0.25553464889526367
Validation loss: 1.7995440831748388

Epoch: 5| Step: 4
Training loss: 0.7466189861297607
Validation loss: 1.8018930291616788

Epoch: 5| Step: 5
Training loss: 0.7482418417930603
Validation loss: 1.7942431895963606

Epoch: 5| Step: 6
Training loss: 0.6784871220588684
Validation loss: 1.8089041363808416

Epoch: 5| Step: 7
Training loss: 0.6067887544631958
Validation loss: 1.8202833796060214

Epoch: 5| Step: 8
Training loss: 0.3086593747138977
Validation loss: 1.804293144133783

Epoch: 5| Step: 9
Training loss: 0.46105241775512695
Validation loss: 1.8159809676549767

Epoch: 5| Step: 10
Training loss: 0.661873996257782
Validation loss: 1.7969072429082726

Epoch: 302| Step: 0
Training loss: 0.7123769521713257
Validation loss: 1.804599432535069

Epoch: 5| Step: 1
Training loss: 0.3896103799343109
Validation loss: 1.7910466988881428

Epoch: 5| Step: 2
Training loss: 0.4069541096687317
Validation loss: 1.7762455414700251

Epoch: 5| Step: 3
Training loss: 0.7311415672302246
Validation loss: 1.7711233118528962

Epoch: 5| Step: 4
Training loss: 0.5843490362167358
Validation loss: 1.7955210952348606

Epoch: 5| Step: 5
Training loss: 0.4474378526210785
Validation loss: 1.770534884545111

Epoch: 5| Step: 6
Training loss: 0.6015254855155945
Validation loss: 1.7750113753862278

Epoch: 5| Step: 7
Training loss: 0.4583917558193207
Validation loss: 1.823418189120549

Epoch: 5| Step: 8
Training loss: 0.4426037669181824
Validation loss: 1.8203916421500586

Epoch: 5| Step: 9
Training loss: 0.46687251329421997
Validation loss: 1.8641749223073323

Epoch: 5| Step: 10
Training loss: 0.6285991072654724
Validation loss: 1.8923842471132997

Epoch: 303| Step: 0
Training loss: 0.3700275123119354
Validation loss: 1.8918831938056535

Epoch: 5| Step: 1
Training loss: 0.5771805047988892
Validation loss: 1.8548965633556407

Epoch: 5| Step: 2
Training loss: 0.858044445514679
Validation loss: 1.8278048922938686

Epoch: 5| Step: 3
Training loss: 0.47766390442848206
Validation loss: 1.8029977672843522

Epoch: 5| Step: 4
Training loss: 0.4360803961753845
Validation loss: 1.8209640505493327

Epoch: 5| Step: 5
Training loss: 0.6880992650985718
Validation loss: 1.7730417046495663

Epoch: 5| Step: 6
Training loss: 0.7868603467941284
Validation loss: 1.7696865899588472

Epoch: 5| Step: 7
Training loss: 0.2975277900695801
Validation loss: 1.802376090839345

Epoch: 5| Step: 8
Training loss: 0.6606365442276001
Validation loss: 1.8018989896261564

Epoch: 5| Step: 9
Training loss: 0.16522152721881866
Validation loss: 1.7831622451864264

Epoch: 5| Step: 10
Training loss: 0.4131741225719452
Validation loss: 1.803640869355971

Epoch: 304| Step: 0
Training loss: 0.4494803547859192
Validation loss: 1.8248099768033592

Epoch: 5| Step: 1
Training loss: 0.4025364816188812
Validation loss: 1.846479965794471

Epoch: 5| Step: 2
Training loss: 0.4349624514579773
Validation loss: 1.8615902264912922

Epoch: 5| Step: 3
Training loss: 0.7551838159561157
Validation loss: 1.865472597460593

Epoch: 5| Step: 4
Training loss: 0.5290430784225464
Validation loss: 1.823462076084588

Epoch: 5| Step: 5
Training loss: 0.6691017150878906
Validation loss: 1.8004197882067772

Epoch: 5| Step: 6
Training loss: 0.57697594165802
Validation loss: 1.7927658711710284

Epoch: 5| Step: 7
Training loss: 0.5454509854316711
Validation loss: 1.7747822730771956

Epoch: 5| Step: 8
Training loss: 0.48700180649757385
Validation loss: 1.7578080879744662

Epoch: 5| Step: 9
Training loss: 0.3736169934272766
Validation loss: 1.7577068190420828

Epoch: 5| Step: 10
Training loss: 0.6229788661003113
Validation loss: 1.7672880144529446

Epoch: 305| Step: 0
Training loss: 0.7310352325439453
Validation loss: 1.810295690772354

Epoch: 5| Step: 1
Training loss: 0.4903729557991028
Validation loss: 1.8130584583487561

Epoch: 5| Step: 2
Training loss: 0.6624189615249634
Validation loss: 1.8525728038562241

Epoch: 5| Step: 3
Training loss: 0.6113401055335999
Validation loss: 1.8569822439583399

Epoch: 5| Step: 4
Training loss: 0.42581772804260254
Validation loss: 1.9027065192499468

Epoch: 5| Step: 5
Training loss: 0.5020915865898132
Validation loss: 1.8707331649718746

Epoch: 5| Step: 6
Training loss: 0.5911558866500854
Validation loss: 1.8569620475974133

Epoch: 5| Step: 7
Training loss: 0.39627617597579956
Validation loss: 1.810429326949581

Epoch: 5| Step: 8
Training loss: 0.3972215950489044
Validation loss: 1.8266394881791965

Epoch: 5| Step: 9
Training loss: 0.7576361894607544
Validation loss: 1.8176775299092776

Epoch: 5| Step: 10
Training loss: 0.3008923828601837
Validation loss: 1.7834547399192728

Epoch: 306| Step: 0
Training loss: 0.4814368188381195
Validation loss: 1.7618327768900062

Epoch: 5| Step: 1
Training loss: 0.561951756477356
Validation loss: 1.7928105400454613

Epoch: 5| Step: 2
Training loss: 0.4617190957069397
Validation loss: 1.7583153427288096

Epoch: 5| Step: 3
Training loss: 0.6104432940483093
Validation loss: 1.8058044102884108

Epoch: 5| Step: 4
Training loss: 0.4081507623195648
Validation loss: 1.8120197608906736

Epoch: 5| Step: 5
Training loss: 0.6525874137878418
Validation loss: 1.844740242086431

Epoch: 5| Step: 6
Training loss: 0.3996279835700989
Validation loss: 1.8297193793840305

Epoch: 5| Step: 7
Training loss: 0.47167474031448364
Validation loss: 1.819822997175237

Epoch: 5| Step: 8
Training loss: 0.7953745722770691
Validation loss: 1.831486395610276

Epoch: 5| Step: 9
Training loss: 0.5754011869430542
Validation loss: 1.8567635884848974

Epoch: 5| Step: 10
Training loss: 0.46582552790641785
Validation loss: 1.8743195392752205

Epoch: 307| Step: 0
Training loss: 0.5346289873123169
Validation loss: 1.8792050858979583

Epoch: 5| Step: 1
Training loss: 0.5255147218704224
Validation loss: 1.816105241416603

Epoch: 5| Step: 2
Training loss: 0.39077630639076233
Validation loss: 1.8253110224200833

Epoch: 5| Step: 3
Training loss: 0.2884838283061981
Validation loss: 1.784369844262318

Epoch: 5| Step: 4
Training loss: 0.7230437994003296
Validation loss: 1.7618565700387443

Epoch: 5| Step: 5
Training loss: 0.7974338531494141
Validation loss: 1.7426498730977376

Epoch: 5| Step: 6
Training loss: 0.44965848326683044
Validation loss: 1.7724100812788932

Epoch: 5| Step: 7
Training loss: 0.4842618405818939
Validation loss: 1.7825067440668743

Epoch: 5| Step: 8
Training loss: 0.3777206540107727
Validation loss: 1.783679025147551

Epoch: 5| Step: 9
Training loss: 0.5657473802566528
Validation loss: 1.8017182414249708

Epoch: 5| Step: 10
Training loss: 0.7078983187675476
Validation loss: 1.8138811947197042

Epoch: 308| Step: 0
Training loss: 0.35456952452659607
Validation loss: 1.7730203302957679

Epoch: 5| Step: 1
Training loss: 0.3167342245578766
Validation loss: 1.8101917505264282

Epoch: 5| Step: 2
Training loss: 0.40543192625045776
Validation loss: 1.830895431580082

Epoch: 5| Step: 3
Training loss: 0.820976734161377
Validation loss: 1.8070135578032462

Epoch: 5| Step: 4
Training loss: 0.6402027606964111
Validation loss: 1.8120122814691195

Epoch: 5| Step: 5
Training loss: 0.6555168628692627
Validation loss: 1.7972818587415962

Epoch: 5| Step: 6
Training loss: 0.5835400223731995
Validation loss: 1.8007943835309757

Epoch: 5| Step: 7
Training loss: 0.7196548581123352
Validation loss: 1.83866084519253

Epoch: 5| Step: 8
Training loss: 0.2824121415615082
Validation loss: 1.8103814971062444

Epoch: 5| Step: 9
Training loss: 0.7247046232223511
Validation loss: 1.8152168976363314

Epoch: 5| Step: 10
Training loss: 0.13182172179222107
Validation loss: 1.810370360651324

Epoch: 309| Step: 0
Training loss: 0.5018378496170044
Validation loss: 1.8350566356412825

Epoch: 5| Step: 1
Training loss: 0.5158640146255493
Validation loss: 1.7854479435951478

Epoch: 5| Step: 2
Training loss: 0.3826930522918701
Validation loss: 1.782391768629833

Epoch: 5| Step: 3
Training loss: 0.38499516248703003
Validation loss: 1.7930744630034252

Epoch: 5| Step: 4
Training loss: 0.5851955413818359
Validation loss: 1.7887601185870428

Epoch: 5| Step: 5
Training loss: 0.4543279707431793
Validation loss: 1.764650014138991

Epoch: 5| Step: 6
Training loss: 0.5556787252426147
Validation loss: 1.7406458265037947

Epoch: 5| Step: 7
Training loss: 0.6031926274299622
Validation loss: 1.7199586604231147

Epoch: 5| Step: 8
Training loss: 0.7314242720603943
Validation loss: 1.6908898789395568

Epoch: 5| Step: 9
Training loss: 0.5449821352958679
Validation loss: 1.739172052311641

Epoch: 5| Step: 10
Training loss: 0.5602400302886963
Validation loss: 1.7442272145261046

Epoch: 310| Step: 0
Training loss: 0.47622567415237427
Validation loss: 1.7451507776014266

Epoch: 5| Step: 1
Training loss: 0.37075871229171753
Validation loss: 1.7692007915948027

Epoch: 5| Step: 2
Training loss: 0.4587215781211853
Validation loss: 1.7475222784985778

Epoch: 5| Step: 3
Training loss: 0.3936103284358978
Validation loss: 1.7542102900884484

Epoch: 5| Step: 4
Training loss: 0.6720460653305054
Validation loss: 1.7860535101224018

Epoch: 5| Step: 5
Training loss: 0.42916765809059143
Validation loss: 1.7534356424885411

Epoch: 5| Step: 6
Training loss: 0.4645724892616272
Validation loss: 1.7537411220612065

Epoch: 5| Step: 7
Training loss: 0.648032546043396
Validation loss: 1.772789482147463

Epoch: 5| Step: 8
Training loss: 0.4350700378417969
Validation loss: 1.7603717619372952

Epoch: 5| Step: 9
Training loss: 0.6401270031929016
Validation loss: 1.759428180674071

Epoch: 5| Step: 10
Training loss: 0.3855676054954529
Validation loss: 1.7457762969437467

Epoch: 311| Step: 0
Training loss: 0.6734189391136169
Validation loss: 1.7691237439391434

Epoch: 5| Step: 1
Training loss: 0.4227243959903717
Validation loss: 1.7524405461485668

Epoch: 5| Step: 2
Training loss: 0.4363512396812439
Validation loss: 1.7947669900873655

Epoch: 5| Step: 3
Training loss: 0.5247859358787537
Validation loss: 1.752612688208139

Epoch: 5| Step: 4
Training loss: 0.3414389491081238
Validation loss: 1.7863045187406643

Epoch: 5| Step: 5
Training loss: 0.2022046595811844
Validation loss: 1.788389664824291

Epoch: 5| Step: 6
Training loss: 0.5446816086769104
Validation loss: 1.8298698881621003

Epoch: 5| Step: 7
Training loss: 0.5741811990737915
Validation loss: 1.8497938468892088

Epoch: 5| Step: 8
Training loss: 0.9900862574577332
Validation loss: 1.8817302052692702

Epoch: 5| Step: 9
Training loss: 0.559691846370697
Validation loss: 1.85095077688976

Epoch: 5| Step: 10
Training loss: 0.2741648256778717
Validation loss: 1.8461846907933552

Epoch: 312| Step: 0
Training loss: 0.34840065240859985
Validation loss: 1.844541177954725

Epoch: 5| Step: 1
Training loss: 0.6798331141471863
Validation loss: 1.8302493915762952

Epoch: 5| Step: 2
Training loss: 0.5065600275993347
Validation loss: 1.807265543168591

Epoch: 5| Step: 3
Training loss: 0.38021889328956604
Validation loss: 1.8071978143466416

Epoch: 5| Step: 4
Training loss: 0.6467448472976685
Validation loss: 1.7908511033622168

Epoch: 5| Step: 5
Training loss: 0.6314672231674194
Validation loss: 1.7906797316766554

Epoch: 5| Step: 6
Training loss: 0.7765456438064575
Validation loss: 1.781907526395654

Epoch: 5| Step: 7
Training loss: 0.5714482665061951
Validation loss: 1.7688991856831375

Epoch: 5| Step: 8
Training loss: 0.16312181949615479
Validation loss: 1.7907281562846193

Epoch: 5| Step: 9
Training loss: 0.40074166655540466
Validation loss: 1.788972600813835

Epoch: 5| Step: 10
Training loss: 0.37348702549934387
Validation loss: 1.7884058311421385

Epoch: 313| Step: 0
Training loss: 0.34803909063339233
Validation loss: 1.7808320573581162

Epoch: 5| Step: 1
Training loss: 0.7996797561645508
Validation loss: 1.7691577544776342

Epoch: 5| Step: 2
Training loss: 0.4382020831108093
Validation loss: 1.7825916223628546

Epoch: 5| Step: 3
Training loss: 0.3716142177581787
Validation loss: 1.8225627201859669

Epoch: 5| Step: 4
Training loss: 0.6079405546188354
Validation loss: 1.7510719119861562

Epoch: 5| Step: 5
Training loss: 0.38534682989120483
Validation loss: 1.7480389687322802

Epoch: 5| Step: 6
Training loss: 0.44362229108810425
Validation loss: 1.7831725535854217

Epoch: 5| Step: 7
Training loss: 0.5042161345481873
Validation loss: 1.743784999334684

Epoch: 5| Step: 8
Training loss: 0.4708921015262604
Validation loss: 1.7344112037330546

Epoch: 5| Step: 9
Training loss: 0.43273288011550903
Validation loss: 1.7165907224019368

Epoch: 5| Step: 10
Training loss: 0.5097618699073792
Validation loss: 1.719866168114447

Epoch: 314| Step: 0
Training loss: 0.38128861784935
Validation loss: 1.7397797992152553

Epoch: 5| Step: 1
Training loss: 0.5566810965538025
Validation loss: 1.734196662902832

Epoch: 5| Step: 2
Training loss: 0.2414226531982422
Validation loss: 1.7371838720895911

Epoch: 5| Step: 3
Training loss: 0.3051840662956238
Validation loss: 1.7000387407118274

Epoch: 5| Step: 4
Training loss: 0.39013925194740295
Validation loss: 1.683656992450837

Epoch: 5| Step: 5
Training loss: 0.4617179334163666
Validation loss: 1.698812262986296

Epoch: 5| Step: 6
Training loss: 0.6916530728340149
Validation loss: 1.6995492853144163

Epoch: 5| Step: 7
Training loss: 0.44298499822616577
Validation loss: 1.6911889173651253

Epoch: 5| Step: 8
Training loss: 0.6568822264671326
Validation loss: 1.7040650447209675

Epoch: 5| Step: 9
Training loss: 0.6014147996902466
Validation loss: 1.6916297571633452

Epoch: 5| Step: 10
Training loss: 0.42763710021972656
Validation loss: 1.6417756208809473

Epoch: 315| Step: 0
Training loss: 0.6409469842910767
Validation loss: 1.718110656225553

Epoch: 5| Step: 1
Training loss: 0.5256636738777161
Validation loss: 1.7061457659608574

Epoch: 5| Step: 2
Training loss: 0.4566512107849121
Validation loss: 1.709506070742043

Epoch: 5| Step: 3
Training loss: 0.4384132921695709
Validation loss: 1.7432696306577293

Epoch: 5| Step: 4
Training loss: 0.48480740189552307
Validation loss: 1.75953971826902

Epoch: 5| Step: 5
Training loss: 0.48151326179504395
Validation loss: 1.7418599897815334

Epoch: 5| Step: 6
Training loss: 0.6041077375411987
Validation loss: 1.7395616064789474

Epoch: 5| Step: 7
Training loss: 0.3476502001285553
Validation loss: 1.7516366794545164

Epoch: 5| Step: 8
Training loss: 0.34294089674949646
Validation loss: 1.7532741433830672

Epoch: 5| Step: 9
Training loss: 0.588299572467804
Validation loss: 1.7382078606595275

Epoch: 5| Step: 10
Training loss: 0.3484051525592804
Validation loss: 1.7421693314788163

Epoch: 316| Step: 0
Training loss: 0.4740176200866699
Validation loss: 1.7638026283633323

Epoch: 5| Step: 1
Training loss: 0.26474323868751526
Validation loss: 1.7998883929303897

Epoch: 5| Step: 2
Training loss: 0.5795822143554688
Validation loss: 1.8349343999739616

Epoch: 5| Step: 3
Training loss: 0.31877413392066956
Validation loss: 1.8170472985954695

Epoch: 5| Step: 4
Training loss: 0.2903687357902527
Validation loss: 1.8425681180851434

Epoch: 5| Step: 5
Training loss: 0.4568096697330475
Validation loss: 1.853950927334447

Epoch: 5| Step: 6
Training loss: 0.6540959477424622
Validation loss: 1.80989920836623

Epoch: 5| Step: 7
Training loss: 0.5071712136268616
Validation loss: 1.8312834872994372

Epoch: 5| Step: 8
Training loss: 0.3772655129432678
Validation loss: 1.788644670158304

Epoch: 5| Step: 9
Training loss: 0.6611210703849792
Validation loss: 1.7519158727379256

Epoch: 5| Step: 10
Training loss: 0.5635673999786377
Validation loss: 1.7232698984043573

Epoch: 317| Step: 0
Training loss: 0.4072117209434509
Validation loss: 1.7717970750665153

Epoch: 5| Step: 1
Training loss: 0.3676994740962982
Validation loss: 1.7640132288778982

Epoch: 5| Step: 2
Training loss: 0.5787310600280762
Validation loss: 1.7499256659579534

Epoch: 5| Step: 3
Training loss: 0.268327534198761
Validation loss: 1.7443497309120752

Epoch: 5| Step: 4
Training loss: 0.1944640427827835
Validation loss: 1.7779562140023837

Epoch: 5| Step: 5
Training loss: 0.5017549395561218
Validation loss: 1.7703407272215812

Epoch: 5| Step: 6
Training loss: 0.49740415811538696
Validation loss: 1.7635963668105423

Epoch: 5| Step: 7
Training loss: 0.695184588432312
Validation loss: 1.7702625284912765

Epoch: 5| Step: 8
Training loss: 0.30617836117744446
Validation loss: 1.7906100185968543

Epoch: 5| Step: 9
Training loss: 0.5873324871063232
Validation loss: 1.7852585969432708

Epoch: 5| Step: 10
Training loss: 0.6606234908103943
Validation loss: 1.7878033473927488

Epoch: 318| Step: 0
Training loss: 0.42314067482948303
Validation loss: 1.7387625799384168

Epoch: 5| Step: 1
Training loss: 0.30086302757263184
Validation loss: 1.7493093821310228

Epoch: 5| Step: 2
Training loss: 0.6732208728790283
Validation loss: 1.7464042850719985

Epoch: 5| Step: 3
Training loss: 0.4014872610569
Validation loss: 1.735659477531269

Epoch: 5| Step: 4
Training loss: 0.46746397018432617
Validation loss: 1.723822905171302

Epoch: 5| Step: 5
Training loss: 0.4307790696620941
Validation loss: 1.7067072968329153

Epoch: 5| Step: 6
Training loss: 0.3168017268180847
Validation loss: 1.7318526288514495

Epoch: 5| Step: 7
Training loss: 0.32354050874710083
Validation loss: 1.7235780672360492

Epoch: 5| Step: 8
Training loss: 0.43153756856918335
Validation loss: 1.7296479722504974

Epoch: 5| Step: 9
Training loss: 0.3985805809497833
Validation loss: 1.7253636544750584

Epoch: 5| Step: 10
Training loss: 0.8409431576728821
Validation loss: 1.7700251763866794

Epoch: 319| Step: 0
Training loss: 0.26094403862953186
Validation loss: 1.726066889301423

Epoch: 5| Step: 1
Training loss: 0.7833514213562012
Validation loss: 1.7551280836905203

Epoch: 5| Step: 2
Training loss: 0.35194191336631775
Validation loss: 1.7518784153846003

Epoch: 5| Step: 3
Training loss: 0.4936237335205078
Validation loss: 1.758737079558834

Epoch: 5| Step: 4
Training loss: 0.5009970664978027
Validation loss: 1.7339006495732132

Epoch: 5| Step: 5
Training loss: 0.468162477016449
Validation loss: 1.7482784230221984

Epoch: 5| Step: 6
Training loss: 0.2827710509300232
Validation loss: 1.7368156743305985

Epoch: 5| Step: 7
Training loss: 0.3883088529109955
Validation loss: 1.729597125002133

Epoch: 5| Step: 8
Training loss: 0.40155282616615295
Validation loss: 1.7535546915505522

Epoch: 5| Step: 9
Training loss: 0.5864259004592896
Validation loss: 1.7479984606465986

Epoch: 5| Step: 10
Training loss: 0.7002063989639282
Validation loss: 1.7677814870752313

Epoch: 320| Step: 0
Training loss: 0.5053022503852844
Validation loss: 1.7921644744052683

Epoch: 5| Step: 1
Training loss: 0.38242292404174805
Validation loss: 1.764799496178986

Epoch: 5| Step: 2
Training loss: 0.440957635641098
Validation loss: 1.7500244276497954

Epoch: 5| Step: 3
Training loss: 0.4315696656703949
Validation loss: 1.7657481611415904

Epoch: 5| Step: 4
Training loss: 0.7293881773948669
Validation loss: 1.7439189187942012

Epoch: 5| Step: 5
Training loss: 0.5187435150146484
Validation loss: 1.7852425357346893

Epoch: 5| Step: 6
Training loss: 0.39712095260620117
Validation loss: 1.765918412516194

Epoch: 5| Step: 7
Training loss: 0.35449403524398804
Validation loss: 1.7803594143159929

Epoch: 5| Step: 8
Training loss: 0.46934065222740173
Validation loss: 1.789093126532852

Epoch: 5| Step: 9
Training loss: 0.5141797661781311
Validation loss: 1.76522199825574

Epoch: 5| Step: 10
Training loss: 0.22433090209960938
Validation loss: 1.7805094475387244

Epoch: 321| Step: 0
Training loss: 0.6384874582290649
Validation loss: 1.7974287245863227

Epoch: 5| Step: 1
Training loss: 0.41531437635421753
Validation loss: 1.778864001715055

Epoch: 5| Step: 2
Training loss: 0.5240057706832886
Validation loss: 1.8053164148843417

Epoch: 5| Step: 3
Training loss: 0.5604879260063171
Validation loss: 1.7920576872364167

Epoch: 5| Step: 4
Training loss: 0.3478267192840576
Validation loss: 1.7857551292706562

Epoch: 5| Step: 5
Training loss: 0.3792320489883423
Validation loss: 1.753045210274317

Epoch: 5| Step: 6
Training loss: 0.6098801493644714
Validation loss: 1.7617653390412689

Epoch: 5| Step: 7
Training loss: 0.3710711598396301
Validation loss: 1.7321837076576807

Epoch: 5| Step: 8
Training loss: 0.3049641251564026
Validation loss: 1.7459360335462837

Epoch: 5| Step: 9
Training loss: 0.5113947987556458
Validation loss: 1.757310616072788

Epoch: 5| Step: 10
Training loss: 0.5510717630386353
Validation loss: 1.7567374654995498

Epoch: 322| Step: 0
Training loss: 0.4142612814903259
Validation loss: 1.7557368291321622

Epoch: 5| Step: 1
Training loss: 0.5864119529724121
Validation loss: 1.7589104355022471

Epoch: 5| Step: 2
Training loss: 0.2431124746799469
Validation loss: 1.781402330244741

Epoch: 5| Step: 3
Training loss: 0.6151435971260071
Validation loss: 1.800168873161398

Epoch: 5| Step: 4
Training loss: 0.7560062408447266
Validation loss: 1.7985024759846349

Epoch: 5| Step: 5
Training loss: 0.2561587691307068
Validation loss: 1.8017409873265091

Epoch: 5| Step: 6
Training loss: 0.2563045620918274
Validation loss: 1.771524570321524

Epoch: 5| Step: 7
Training loss: 0.5516639351844788
Validation loss: 1.7474235744886502

Epoch: 5| Step: 8
Training loss: 0.4703351855278015
Validation loss: 1.7339681694584508

Epoch: 5| Step: 9
Training loss: 0.3000813126564026
Validation loss: 1.7409304393235074

Epoch: 5| Step: 10
Training loss: 0.5372350811958313
Validation loss: 1.735889716814923

Epoch: 323| Step: 0
Training loss: 0.21374380588531494
Validation loss: 1.7819456054318337

Epoch: 5| Step: 1
Training loss: 0.5287941694259644
Validation loss: 1.7829128273071781

Epoch: 5| Step: 2
Training loss: 0.5273202061653137
Validation loss: 1.7913398178674842

Epoch: 5| Step: 3
Training loss: 0.4486057758331299
Validation loss: 1.7538095084569787

Epoch: 5| Step: 4
Training loss: 0.3937337398529053
Validation loss: 1.7586023756252822

Epoch: 5| Step: 5
Training loss: 0.9049969911575317
Validation loss: 1.771631125480898

Epoch: 5| Step: 6
Training loss: 0.17785677313804626
Validation loss: 1.7909551410264866

Epoch: 5| Step: 7
Training loss: 0.24430370330810547
Validation loss: 1.7550190725634176

Epoch: 5| Step: 8
Training loss: 0.3956393003463745
Validation loss: 1.7867054708542363

Epoch: 5| Step: 9
Training loss: 0.26749593019485474
Validation loss: 1.7635364186379217

Epoch: 5| Step: 10
Training loss: 0.6413246393203735
Validation loss: 1.7327301963683097

Epoch: 324| Step: 0
Training loss: 0.4886646270751953
Validation loss: 1.7350031598921745

Epoch: 5| Step: 1
Training loss: 0.5208559036254883
Validation loss: 1.763303811832141

Epoch: 5| Step: 2
Training loss: 0.6840823292732239
Validation loss: 1.7528309655445877

Epoch: 5| Step: 3
Training loss: 0.2913002669811249
Validation loss: 1.7760649675964026

Epoch: 5| Step: 4
Training loss: 0.4169389307498932
Validation loss: 1.7845730538009315

Epoch: 5| Step: 5
Training loss: 0.2927561402320862
Validation loss: 1.7997673955014957

Epoch: 5| Step: 6
Training loss: 0.36309927701950073
Validation loss: 1.7631892965685936

Epoch: 5| Step: 7
Training loss: 0.34159374237060547
Validation loss: 1.7629829734884284

Epoch: 5| Step: 8
Training loss: 0.6094310283660889
Validation loss: 1.7610337477858349

Epoch: 5| Step: 9
Training loss: 0.37704142928123474
Validation loss: 1.7772002438063264

Epoch: 5| Step: 10
Training loss: 0.4224870800971985
Validation loss: 1.738900843486991

Epoch: 325| Step: 0
Training loss: 0.32440051436424255
Validation loss: 1.7794934806003366

Epoch: 5| Step: 1
Training loss: 0.5732752084732056
Validation loss: 1.764563896322763

Epoch: 5| Step: 2
Training loss: 0.6313503384590149
Validation loss: 1.7546465935245636

Epoch: 5| Step: 3
Training loss: 0.5048284530639648
Validation loss: 1.7372677467202629

Epoch: 5| Step: 4
Training loss: 0.4871353507041931
Validation loss: 1.7109883036664737

Epoch: 5| Step: 5
Training loss: 0.3801489472389221
Validation loss: 1.730093466338291

Epoch: 5| Step: 6
Training loss: 0.2437770813703537
Validation loss: 1.714604398255707

Epoch: 5| Step: 7
Training loss: 0.29249081015586853
Validation loss: 1.7313942960513535

Epoch: 5| Step: 8
Training loss: 0.6140130758285522
Validation loss: 1.7275047481700938

Epoch: 5| Step: 9
Training loss: 0.31523603200912476
Validation loss: 1.7666512202191096

Epoch: 5| Step: 10
Training loss: 0.2770625948905945
Validation loss: 1.7438293169903498

Epoch: 326| Step: 0
Training loss: 0.2565193772315979
Validation loss: 1.7555613620306856

Epoch: 5| Step: 1
Training loss: 0.20268197357654572
Validation loss: 1.76307467491396

Epoch: 5| Step: 2
Training loss: 0.4719774127006531
Validation loss: 1.8142765811694566

Epoch: 5| Step: 3
Training loss: 0.43007510900497437
Validation loss: 1.7573831542845695

Epoch: 5| Step: 4
Training loss: 0.660681426525116
Validation loss: 1.8065091025444768

Epoch: 5| Step: 5
Training loss: 0.4509263038635254
Validation loss: 1.8067822071813768

Epoch: 5| Step: 6
Training loss: 0.3599146008491516
Validation loss: 1.7993184417806647

Epoch: 5| Step: 7
Training loss: 0.6226695775985718
Validation loss: 1.7847601880309403

Epoch: 5| Step: 8
Training loss: 0.43420371413230896
Validation loss: 1.8166910063835882

Epoch: 5| Step: 9
Training loss: 0.4565180242061615
Validation loss: 1.7719497091026717

Epoch: 5| Step: 10
Training loss: 0.23166869580745697
Validation loss: 1.746194048594403

Epoch: 327| Step: 0
Training loss: 0.37161341309547424
Validation loss: 1.727946368596887

Epoch: 5| Step: 1
Training loss: 0.3483421206474304
Validation loss: 1.7446975849008048

Epoch: 5| Step: 2
Training loss: 0.2398734986782074
Validation loss: 1.7277583678563435

Epoch: 5| Step: 3
Training loss: 0.776814341545105
Validation loss: 1.7068749755941413

Epoch: 5| Step: 4
Training loss: 0.47336846590042114
Validation loss: 1.746388768637052

Epoch: 5| Step: 5
Training loss: 0.32409876585006714
Validation loss: 1.7396405102104269

Epoch: 5| Step: 6
Training loss: 0.5035945177078247
Validation loss: 1.741632705093712

Epoch: 5| Step: 7
Training loss: 0.3440861105918884
Validation loss: 1.7911162068766933

Epoch: 5| Step: 8
Training loss: 0.4674224853515625
Validation loss: 1.7513402354332708

Epoch: 5| Step: 9
Training loss: 0.44377565383911133
Validation loss: 1.765838591001367

Epoch: 5| Step: 10
Training loss: 0.35034480690956116
Validation loss: 1.7861096756432646

Epoch: 328| Step: 0
Training loss: 0.406141996383667
Validation loss: 1.767985583633505

Epoch: 5| Step: 1
Training loss: 0.2648874819278717
Validation loss: 1.7956629876167542

Epoch: 5| Step: 2
Training loss: 0.4009520411491394
Validation loss: 1.760638419017997

Epoch: 5| Step: 3
Training loss: 0.35600605607032776
Validation loss: 1.7463151921508133

Epoch: 5| Step: 4
Training loss: 0.5568541288375854
Validation loss: 1.750836423648301

Epoch: 5| Step: 5
Training loss: 0.37101882696151733
Validation loss: 1.727046428188201

Epoch: 5| Step: 6
Training loss: 0.3900296688079834
Validation loss: 1.7596843845100814

Epoch: 5| Step: 7
Training loss: 0.45647621154785156
Validation loss: 1.7552625530509538

Epoch: 5| Step: 8
Training loss: 0.436868280172348
Validation loss: 1.7872843486006542

Epoch: 5| Step: 9
Training loss: 0.5227847099304199
Validation loss: 1.769780126951074

Epoch: 5| Step: 10
Training loss: 0.4864438474178314
Validation loss: 1.8165496087843371

Epoch: 329| Step: 0
Training loss: 0.20151245594024658
Validation loss: 1.7858757242079704

Epoch: 5| Step: 1
Training loss: 0.20799586176872253
Validation loss: 1.8223039027183288

Epoch: 5| Step: 2
Training loss: 0.3584499955177307
Validation loss: 1.7707865058734853

Epoch: 5| Step: 3
Training loss: 0.3853514492511749
Validation loss: 1.7739199130765853

Epoch: 5| Step: 4
Training loss: 0.6416130065917969
Validation loss: 1.7465896632081719

Epoch: 5| Step: 5
Training loss: 0.5462039709091187
Validation loss: 1.7555710692559519

Epoch: 5| Step: 6
Training loss: 0.4244183599948883
Validation loss: 1.718944582887875

Epoch: 5| Step: 7
Training loss: 0.4073560833930969
Validation loss: 1.738375904739544

Epoch: 5| Step: 8
Training loss: 0.44883614778518677
Validation loss: 1.7222101137202273

Epoch: 5| Step: 9
Training loss: 0.43916407227516174
Validation loss: 1.6964236485060824

Epoch: 5| Step: 10
Training loss: 0.5015532374382019
Validation loss: 1.7159196292200396

Epoch: 330| Step: 0
Training loss: 0.31471574306488037
Validation loss: 1.7146904865900676

Epoch: 5| Step: 1
Training loss: 0.3488110899925232
Validation loss: 1.7172665121734783

Epoch: 5| Step: 2
Training loss: 0.6314746737480164
Validation loss: 1.7403905968512259

Epoch: 5| Step: 3
Training loss: 0.25821739435195923
Validation loss: 1.7087717415184103

Epoch: 5| Step: 4
Training loss: 0.3319268524646759
Validation loss: 1.73920004470374

Epoch: 5| Step: 5
Training loss: 0.5844700932502747
Validation loss: 1.7161408111613283

Epoch: 5| Step: 6
Training loss: 0.32039162516593933
Validation loss: 1.7297191466054609

Epoch: 5| Step: 7
Training loss: 0.24059848487377167
Validation loss: 1.7306223236104494

Epoch: 5| Step: 8
Training loss: 0.33274728059768677
Validation loss: 1.7424097253430275

Epoch: 5| Step: 9
Training loss: 0.5570980310440063
Validation loss: 1.7546725029586463

Epoch: 5| Step: 10
Training loss: 0.41950175166130066
Validation loss: 1.7836959259484404

Epoch: 331| Step: 0
Training loss: 0.27249208092689514
Validation loss: 1.7688781317844187

Epoch: 5| Step: 1
Training loss: 0.5564912557601929
Validation loss: 1.7810925899013397

Epoch: 5| Step: 2
Training loss: 0.4441536068916321
Validation loss: 1.8034037338790072

Epoch: 5| Step: 3
Training loss: 0.34965771436691284
Validation loss: 1.7948717391619118

Epoch: 5| Step: 4
Training loss: 0.6819559335708618
Validation loss: 1.7634553858028945

Epoch: 5| Step: 5
Training loss: 0.3487412929534912
Validation loss: 1.772003658356205

Epoch: 5| Step: 6
Training loss: 0.22795414924621582
Validation loss: 1.7803167976358885

Epoch: 5| Step: 7
Training loss: 0.47551679611206055
Validation loss: 1.755644489360112

Epoch: 5| Step: 8
Training loss: 0.20973575115203857
Validation loss: 1.7413017980514034

Epoch: 5| Step: 9
Training loss: 0.467926025390625
Validation loss: 1.720667839050293

Epoch: 5| Step: 10
Training loss: 0.26422426104545593
Validation loss: 1.726795417647208

Epoch: 332| Step: 0
Training loss: 0.17355839908123016
Validation loss: 1.7428985667485062

Epoch: 5| Step: 1
Training loss: 0.33578699827194214
Validation loss: 1.7543694575627644

Epoch: 5| Step: 2
Training loss: 0.5508313179016113
Validation loss: 1.7495533625284831

Epoch: 5| Step: 3
Training loss: 0.49519243836402893
Validation loss: 1.7466970143779632

Epoch: 5| Step: 4
Training loss: 0.35759925842285156
Validation loss: 1.7665907362455964

Epoch: 5| Step: 5
Training loss: 0.6016719341278076
Validation loss: 1.7542188372663272

Epoch: 5| Step: 6
Training loss: 0.46494022011756897
Validation loss: 1.7603555635739399

Epoch: 5| Step: 7
Training loss: 0.4055134654045105
Validation loss: 1.756172667267502

Epoch: 5| Step: 8
Training loss: 0.26846784353256226
Validation loss: 1.7708225186153124

Epoch: 5| Step: 9
Training loss: 0.3036280572414398
Validation loss: 1.7628381713744132

Epoch: 5| Step: 10
Training loss: 0.44080430269241333
Validation loss: 1.726101420258963

Epoch: 333| Step: 0
Training loss: 0.3359411358833313
Validation loss: 1.767985620806294

Epoch: 5| Step: 1
Training loss: 0.19698120653629303
Validation loss: 1.7654337370267479

Epoch: 5| Step: 2
Training loss: 0.3310891389846802
Validation loss: 1.7764765601004324

Epoch: 5| Step: 3
Training loss: 0.5396342873573303
Validation loss: 1.7910154583633586

Epoch: 5| Step: 4
Training loss: 0.4948345124721527
Validation loss: 1.8015982117704166

Epoch: 5| Step: 5
Training loss: 0.5292282104492188
Validation loss: 1.7924383609525618

Epoch: 5| Step: 6
Training loss: 0.26597607135772705
Validation loss: 1.7657980329246932

Epoch: 5| Step: 7
Training loss: 0.41293954849243164
Validation loss: 1.7556263836481238

Epoch: 5| Step: 8
Training loss: 0.3378596603870392
Validation loss: 1.7283738479819348

Epoch: 5| Step: 9
Training loss: 0.5757369995117188
Validation loss: 1.7193265525243615

Epoch: 5| Step: 10
Training loss: 0.3088037371635437
Validation loss: 1.7339914152699132

Epoch: 334| Step: 0
Training loss: 0.45640039443969727
Validation loss: 1.6799316816432501

Epoch: 5| Step: 1
Training loss: 0.4221228063106537
Validation loss: 1.716479778289795

Epoch: 5| Step: 2
Training loss: 0.35302311182022095
Validation loss: 1.7010767126596102

Epoch: 5| Step: 3
Training loss: 0.27903640270233154
Validation loss: 1.7102639572594756

Epoch: 5| Step: 4
Training loss: 0.6532867550849915
Validation loss: 1.7129162396154096

Epoch: 5| Step: 5
Training loss: 0.47481316328048706
Validation loss: 1.7240879407493017

Epoch: 5| Step: 6
Training loss: 0.2263900339603424
Validation loss: 1.6713058769062001

Epoch: 5| Step: 7
Training loss: 0.3666563630104065
Validation loss: 1.7131818891853414

Epoch: 5| Step: 8
Training loss: 0.37788933515548706
Validation loss: 1.6881182834666262

Epoch: 5| Step: 9
Training loss: 0.2167043387889862
Validation loss: 1.6985416860990628

Epoch: 5| Step: 10
Training loss: 0.5761770009994507
Validation loss: 1.7040614363967732

Epoch: 335| Step: 0
Training loss: 0.6488020420074463
Validation loss: 1.6889812100318171

Epoch: 5| Step: 1
Training loss: 0.43393367528915405
Validation loss: 1.7376963143707604

Epoch: 5| Step: 2
Training loss: 0.314374178647995
Validation loss: 1.731100134952094

Epoch: 5| Step: 3
Training loss: 0.3209500312805176
Validation loss: 1.7386605047410535

Epoch: 5| Step: 4
Training loss: 0.41253939270973206
Validation loss: 1.7281750722598004

Epoch: 5| Step: 5
Training loss: 0.3612813949584961
Validation loss: 1.7530724194742018

Epoch: 5| Step: 6
Training loss: 0.4620599150657654
Validation loss: 1.7113179365793865

Epoch: 5| Step: 7
Training loss: 0.4213981628417969
Validation loss: 1.7468372262934202

Epoch: 5| Step: 8
Training loss: 0.39733177423477173
Validation loss: 1.7390056335797874

Epoch: 5| Step: 9
Training loss: 0.32396793365478516
Validation loss: 1.74372665087382

Epoch: 5| Step: 10
Training loss: 0.26386550068855286
Validation loss: 1.7783266293105258

Epoch: 336| Step: 0
Training loss: 0.39356347918510437
Validation loss: 1.7578575905933176

Epoch: 5| Step: 1
Training loss: 0.20482893288135529
Validation loss: 1.7168168790878788

Epoch: 5| Step: 2
Training loss: 0.5277864336967468
Validation loss: 1.710833150853393

Epoch: 5| Step: 3
Training loss: 0.3911364674568176
Validation loss: 1.7013362517920874

Epoch: 5| Step: 4
Training loss: 0.40389490127563477
Validation loss: 1.72698208209007

Epoch: 5| Step: 5
Training loss: 0.33848053216934204
Validation loss: 1.7326207468586583

Epoch: 5| Step: 6
Training loss: 0.29364436864852905
Validation loss: 1.787544346624805

Epoch: 5| Step: 7
Training loss: 0.39998817443847656
Validation loss: 1.7798426702458372

Epoch: 5| Step: 8
Training loss: 0.2535265386104584
Validation loss: 1.7431862520915207

Epoch: 5| Step: 9
Training loss: 0.4224519729614258
Validation loss: 1.7402056224884526

Epoch: 5| Step: 10
Training loss: 0.622238278388977
Validation loss: 1.7098781588257

Epoch: 337| Step: 0
Training loss: 0.2593170702457428
Validation loss: 1.7353787050452283

Epoch: 5| Step: 1
Training loss: 0.3936257064342499
Validation loss: 1.733420346372871

Epoch: 5| Step: 2
Training loss: 0.22860965132713318
Validation loss: 1.6876070627602198

Epoch: 5| Step: 3
Training loss: 0.48251110315322876
Validation loss: 1.7242634911690988

Epoch: 5| Step: 4
Training loss: 0.3402023911476135
Validation loss: 1.725375093439574

Epoch: 5| Step: 5
Training loss: 0.44985875487327576
Validation loss: 1.708716461735387

Epoch: 5| Step: 6
Training loss: 0.3264704942703247
Validation loss: 1.7570796858879827

Epoch: 5| Step: 7
Training loss: 0.3788473904132843
Validation loss: 1.7554402184742752

Epoch: 5| Step: 8
Training loss: 0.5737903118133545
Validation loss: 1.7121161466003747

Epoch: 5| Step: 9
Training loss: 0.4249180853366852
Validation loss: 1.7255210556009764

Epoch: 5| Step: 10
Training loss: 0.2756817638874054
Validation loss: 1.6918595760099349

Epoch: 338| Step: 0
Training loss: 0.573572039604187
Validation loss: 1.7631636345258324

Epoch: 5| Step: 1
Training loss: 0.5924214720726013
Validation loss: 1.7099640330960673

Epoch: 5| Step: 2
Training loss: 0.246293306350708
Validation loss: 1.6949831862603464

Epoch: 5| Step: 3
Training loss: 0.4064740240573883
Validation loss: 1.7254498748369114

Epoch: 5| Step: 4
Training loss: 0.36107632517814636
Validation loss: 1.7105832881824945

Epoch: 5| Step: 5
Training loss: 0.3488512933254242
Validation loss: 1.7453044050483293

Epoch: 5| Step: 6
Training loss: 0.41115155816078186
Validation loss: 1.7226613567721458

Epoch: 5| Step: 7
Training loss: 0.345550537109375
Validation loss: 1.7653557459513347

Epoch: 5| Step: 8
Training loss: 0.30424264073371887
Validation loss: 1.7592624336160638

Epoch: 5| Step: 9
Training loss: 0.311477392911911
Validation loss: 1.7363805219691286

Epoch: 5| Step: 10
Training loss: 0.2213038057088852
Validation loss: 1.7353146358202862

Epoch: 339| Step: 0
Training loss: 0.3693981468677521
Validation loss: 1.7314311022399573

Epoch: 5| Step: 1
Training loss: 0.3924815058708191
Validation loss: 1.7351838888660553

Epoch: 5| Step: 2
Training loss: 0.5632085800170898
Validation loss: 1.7164577412348923

Epoch: 5| Step: 3
Training loss: 0.4156270921230316
Validation loss: 1.72199684445576

Epoch: 5| Step: 4
Training loss: 0.28873175382614136
Validation loss: 1.7012405767235705

Epoch: 5| Step: 5
Training loss: 0.36663803458213806
Validation loss: 1.7267432725557716

Epoch: 5| Step: 6
Training loss: 0.1653234362602234
Validation loss: 1.6993932570180585

Epoch: 5| Step: 7
Training loss: 0.5942993760108948
Validation loss: 1.6807129126723095

Epoch: 5| Step: 8
Training loss: 0.2096918523311615
Validation loss: 1.6942885383482902

Epoch: 5| Step: 9
Training loss: 0.5644047856330872
Validation loss: 1.689423817460255

Epoch: 5| Step: 10
Training loss: 0.3196512758731842
Validation loss: 1.7175601361900248

Epoch: 340| Step: 0
Training loss: 0.44443216919898987
Validation loss: 1.6613320599320114

Epoch: 5| Step: 1
Training loss: 0.28680017590522766
Validation loss: 1.7102514607931978

Epoch: 5| Step: 2
Training loss: 0.46324270963668823
Validation loss: 1.7010555523698048

Epoch: 5| Step: 3
Training loss: 0.4021379351615906
Validation loss: 1.70685871442159

Epoch: 5| Step: 4
Training loss: 0.4398190379142761
Validation loss: 1.713326008089127

Epoch: 5| Step: 5
Training loss: 0.4055265784263611
Validation loss: 1.7436372080156881

Epoch: 5| Step: 6
Training loss: 0.5898704528808594
Validation loss: 1.7684737508014967

Epoch: 5| Step: 7
Training loss: 0.2575797438621521
Validation loss: 1.7507706508841565

Epoch: 5| Step: 8
Training loss: 0.46176090836524963
Validation loss: 1.7950184473427393

Epoch: 5| Step: 9
Training loss: 0.3038718104362488
Validation loss: 1.7813805034083705

Epoch: 5| Step: 10
Training loss: 0.25446128845214844
Validation loss: 1.760721086173929

Epoch: 341| Step: 0
Training loss: 0.3162640631198883
Validation loss: 1.7402754727230276

Epoch: 5| Step: 1
Training loss: 0.2006545066833496
Validation loss: 1.7393457146101101

Epoch: 5| Step: 2
Training loss: 0.18980613350868225
Validation loss: 1.7383938938058832

Epoch: 5| Step: 3
Training loss: 0.27525871992111206
Validation loss: 1.7166309920690392

Epoch: 5| Step: 4
Training loss: 0.4952200949192047
Validation loss: 1.6934773127237956

Epoch: 5| Step: 5
Training loss: 0.31905272603034973
Validation loss: 1.693471852169242

Epoch: 5| Step: 6
Training loss: 0.6513509750366211
Validation loss: 1.694381517748679

Epoch: 5| Step: 7
Training loss: 0.40531492233276367
Validation loss: 1.6897114835759646

Epoch: 5| Step: 8
Training loss: 0.19071362912654877
Validation loss: 1.6743349772627636

Epoch: 5| Step: 9
Training loss: 0.31327253580093384
Validation loss: 1.6818881573215607

Epoch: 5| Step: 10
Training loss: 0.6443926095962524
Validation loss: 1.6950794548116705

Epoch: 342| Step: 0
Training loss: 0.24890613555908203
Validation loss: 1.6697906627449939

Epoch: 5| Step: 1
Training loss: 0.38288840651512146
Validation loss: 1.672501721689778

Epoch: 5| Step: 2
Training loss: 0.46678122878074646
Validation loss: 1.7051816601907053

Epoch: 5| Step: 3
Training loss: 0.5263019800186157
Validation loss: 1.6782033161450458

Epoch: 5| Step: 4
Training loss: 0.23389573395252228
Validation loss: 1.674314611701555

Epoch: 5| Step: 5
Training loss: 0.376269668340683
Validation loss: 1.6807296776002454

Epoch: 5| Step: 6
Training loss: 0.28646954894065857
Validation loss: 1.678571040912341

Epoch: 5| Step: 7
Training loss: 0.3913763165473938
Validation loss: 1.6428379281874625

Epoch: 5| Step: 8
Training loss: 0.4769449234008789
Validation loss: 1.6656385634535102

Epoch: 5| Step: 9
Training loss: 0.28380298614501953
Validation loss: 1.6524898172706686

Epoch: 5| Step: 10
Training loss: 0.43524399399757385
Validation loss: 1.675383198645807

Epoch: 343| Step: 0
Training loss: 0.14323332905769348
Validation loss: 1.6818810816734069

Epoch: 5| Step: 1
Training loss: 0.5229726433753967
Validation loss: 1.691199726955865

Epoch: 5| Step: 2
Training loss: 0.5425480604171753
Validation loss: 1.712513114816399

Epoch: 5| Step: 3
Training loss: 0.6339585781097412
Validation loss: 1.6880470821934361

Epoch: 5| Step: 4
Training loss: 0.34970754384994507
Validation loss: 1.7045263410896383

Epoch: 5| Step: 5
Training loss: 0.40942201018333435
Validation loss: 1.6390839520321097

Epoch: 5| Step: 6
Training loss: 0.3465423882007599
Validation loss: 1.6394637759013841

Epoch: 5| Step: 7
Training loss: 0.262822687625885
Validation loss: 1.6403243874990812

Epoch: 5| Step: 8
Training loss: 0.36295807361602783
Validation loss: 1.626036838818622

Epoch: 5| Step: 9
Training loss: 0.22050948441028595
Validation loss: 1.665717504357779

Epoch: 5| Step: 10
Training loss: 0.3824614882469177
Validation loss: 1.6911539851978261

Epoch: 344| Step: 0
Training loss: 0.6104636788368225
Validation loss: 1.6860785484313965

Epoch: 5| Step: 1
Training loss: 0.3124874532222748
Validation loss: 1.7323358456293743

Epoch: 5| Step: 2
Training loss: 0.4222947955131531
Validation loss: 1.7283435636951077

Epoch: 5| Step: 3
Training loss: 0.3764875531196594
Validation loss: 1.7215142737152755

Epoch: 5| Step: 4
Training loss: 0.3360736072063446
Validation loss: 1.7244682670921407

Epoch: 5| Step: 5
Training loss: 0.24477311968803406
Validation loss: 1.7304051281303487

Epoch: 5| Step: 6
Training loss: 0.36488857865333557
Validation loss: 1.7225683581444524

Epoch: 5| Step: 7
Training loss: 0.4075332581996918
Validation loss: 1.7153046105497627

Epoch: 5| Step: 8
Training loss: 0.2674576938152313
Validation loss: 1.692272234988469

Epoch: 5| Step: 9
Training loss: 0.4191480576992035
Validation loss: 1.6716842484730545

Epoch: 5| Step: 10
Training loss: 0.41073209047317505
Validation loss: 1.6488559207608622

Epoch: 345| Step: 0
Training loss: 0.5759775638580322
Validation loss: 1.6344814467173752

Epoch: 5| Step: 1
Training loss: 0.35544049739837646
Validation loss: 1.6747342091734692

Epoch: 5| Step: 2
Training loss: 0.21369019150733948
Validation loss: 1.670224597377162

Epoch: 5| Step: 3
Training loss: 0.2658035159111023
Validation loss: 1.6969250338051909

Epoch: 5| Step: 4
Training loss: 0.5880739688873291
Validation loss: 1.7316813276660057

Epoch: 5| Step: 5
Training loss: 0.3420812487602234
Validation loss: 1.6972589582525275

Epoch: 5| Step: 6
Training loss: 0.28777846693992615
Validation loss: 1.7117974527420536

Epoch: 5| Step: 7
Training loss: 0.3959064185619354
Validation loss: 1.7685664597377981

Epoch: 5| Step: 8
Training loss: 0.4775818884372711
Validation loss: 1.7325868683476602

Epoch: 5| Step: 9
Training loss: 0.5476190447807312
Validation loss: 1.738370559548819

Epoch: 5| Step: 10
Training loss: 0.18790903687477112
Validation loss: 1.6975036603148266

Epoch: 346| Step: 0
Training loss: 0.35940247774124146
Validation loss: 1.6941769212804816

Epoch: 5| Step: 1
Training loss: 0.32503536343574524
Validation loss: 1.7039564565945697

Epoch: 5| Step: 2
Training loss: 0.2822083532810211
Validation loss: 1.7157085159773469

Epoch: 5| Step: 3
Training loss: 0.5408308506011963
Validation loss: 1.7026375365513626

Epoch: 5| Step: 4
Training loss: 0.36300545930862427
Validation loss: 1.7192514660537883

Epoch: 5| Step: 5
Training loss: 0.38567087054252625
Validation loss: 1.7210270935489285

Epoch: 5| Step: 6
Training loss: 0.38751235604286194
Validation loss: 1.7023060039807392

Epoch: 5| Step: 7
Training loss: 0.309206485748291
Validation loss: 1.6863616897213844

Epoch: 5| Step: 8
Training loss: 0.3638254702091217
Validation loss: 1.686624603886758

Epoch: 5| Step: 9
Training loss: 0.3201526999473572
Validation loss: 1.710426994549331

Epoch: 5| Step: 10
Training loss: 0.41795551776885986
Validation loss: 1.7310172421957857

Epoch: 347| Step: 0
Training loss: 0.27764663100242615
Validation loss: 1.7226351653375933

Epoch: 5| Step: 1
Training loss: 0.49600473046302795
Validation loss: 1.7279205873448362

Epoch: 5| Step: 2
Training loss: 0.25811833143234253
Validation loss: 1.7152249377260926

Epoch: 5| Step: 3
Training loss: 0.32759666442871094
Validation loss: 1.7144369630403415

Epoch: 5| Step: 4
Training loss: 0.3545227646827698
Validation loss: 1.7105989635631602

Epoch: 5| Step: 5
Training loss: 0.2611376643180847
Validation loss: 1.7191136101240754

Epoch: 5| Step: 6
Training loss: 0.42585545778274536
Validation loss: 1.6941596243971138

Epoch: 5| Step: 7
Training loss: 0.34328681230545044
Validation loss: 1.7091965624081191

Epoch: 5| Step: 8
Training loss: 0.428571879863739
Validation loss: 1.6935847805392357

Epoch: 5| Step: 9
Training loss: 0.35697463154792786
Validation loss: 1.6904612933435748

Epoch: 5| Step: 10
Training loss: 0.22207124531269073
Validation loss: 1.6867630045901063

Epoch: 348| Step: 0
Training loss: 0.3145903944969177
Validation loss: 1.645688464564662

Epoch: 5| Step: 1
Training loss: 0.33429521322250366
Validation loss: 1.6705430233350365

Epoch: 5| Step: 2
Training loss: 0.7063295841217041
Validation loss: 1.6643889616894465

Epoch: 5| Step: 3
Training loss: 0.15242362022399902
Validation loss: 1.6674547926072152

Epoch: 5| Step: 4
Training loss: 0.32830268144607544
Validation loss: 1.6716636021931965

Epoch: 5| Step: 5
Training loss: 0.4134112298488617
Validation loss: 1.7161632648078344

Epoch: 5| Step: 6
Training loss: 0.3337717056274414
Validation loss: 1.7226956582838489

Epoch: 5| Step: 7
Training loss: 0.3459196388721466
Validation loss: 1.713209552149619

Epoch: 5| Step: 8
Training loss: 0.31102457642555237
Validation loss: 1.7187165880715976

Epoch: 5| Step: 9
Training loss: 0.39162588119506836
Validation loss: 1.720023610258615

Epoch: 5| Step: 10
Training loss: 0.3863481879234314
Validation loss: 1.713897398723069

Epoch: 349| Step: 0
Training loss: 0.2859434485435486
Validation loss: 1.7222528906278713

Epoch: 5| Step: 1
Training loss: 0.2554783523082733
Validation loss: 1.718415206478488

Epoch: 5| Step: 2
Training loss: 0.288339763879776
Validation loss: 1.6980037279026483

Epoch: 5| Step: 3
Training loss: 0.27091148495674133
Validation loss: 1.6421009122684438

Epoch: 5| Step: 4
Training loss: 0.3559999167919159
Validation loss: 1.6694573048622376

Epoch: 5| Step: 5
Training loss: 0.43946295976638794
Validation loss: 1.6420865776718303

Epoch: 5| Step: 6
Training loss: 0.6440853476524353
Validation loss: 1.652251447400739

Epoch: 5| Step: 7
Training loss: 0.1544666439294815
Validation loss: 1.6718519118524366

Epoch: 5| Step: 8
Training loss: 0.4391555190086365
Validation loss: 1.6608508120300949

Epoch: 5| Step: 9
Training loss: 0.39979979395866394
Validation loss: 1.6800828697860881

Epoch: 5| Step: 10
Training loss: 0.3835979402065277
Validation loss: 1.666224778339427

Epoch: 350| Step: 0
Training loss: 0.2947908639907837
Validation loss: 1.6933828079572288

Epoch: 5| Step: 1
Training loss: 0.29699021577835083
Validation loss: 1.7165824905518563

Epoch: 5| Step: 2
Training loss: 0.3143264055252075
Validation loss: 1.7113044056841122

Epoch: 5| Step: 3
Training loss: 0.3523736000061035
Validation loss: 1.6760347530406008

Epoch: 5| Step: 4
Training loss: 0.37256380915641785
Validation loss: 1.7014126739194315

Epoch: 5| Step: 5
Training loss: 0.26992619037628174
Validation loss: 1.6785615900511384

Epoch: 5| Step: 6
Training loss: 0.35376060009002686
Validation loss: 1.67097762579559

Epoch: 5| Step: 7
Training loss: 0.3469708561897278
Validation loss: 1.659891838668495

Epoch: 5| Step: 8
Training loss: 0.6047645807266235
Validation loss: 1.662057908632422

Epoch: 5| Step: 9
Training loss: 0.2802818715572357
Validation loss: 1.6792133444099016

Epoch: 5| Step: 10
Training loss: 0.3968258202075958
Validation loss: 1.6867085502993675

Epoch: 351| Step: 0
Training loss: 0.28019052743911743
Validation loss: 1.6782469185449744

Epoch: 5| Step: 1
Training loss: 0.4581947326660156
Validation loss: 1.6604664184713875

Epoch: 5| Step: 2
Training loss: 0.33235350251197815
Validation loss: 1.7064079353886266

Epoch: 5| Step: 3
Training loss: 0.429431676864624
Validation loss: 1.698379119237264

Epoch: 5| Step: 4
Training loss: 0.3149952292442322
Validation loss: 1.7194085390337053

Epoch: 5| Step: 5
Training loss: 0.3698905408382416
Validation loss: 1.70388557962192

Epoch: 5| Step: 6
Training loss: 0.2698673903942108
Validation loss: 1.7330067696109894

Epoch: 5| Step: 7
Training loss: 0.3384043276309967
Validation loss: 1.7261781769414102

Epoch: 5| Step: 8
Training loss: 0.4937012791633606
Validation loss: 1.7278124068372993

Epoch: 5| Step: 9
Training loss: 0.30184459686279297
Validation loss: 1.729815665111747

Epoch: 5| Step: 10
Training loss: 0.2934165298938751
Validation loss: 1.7154257041151806

Epoch: 352| Step: 0
Training loss: 0.3959406018257141
Validation loss: 1.7362108102408789

Epoch: 5| Step: 1
Training loss: 0.3299868106842041
Validation loss: 1.7131817776669738

Epoch: 5| Step: 2
Training loss: 0.5713943243026733
Validation loss: 1.6972546692817443

Epoch: 5| Step: 3
Training loss: 0.300776869058609
Validation loss: 1.6973354765163955

Epoch: 5| Step: 4
Training loss: 0.3694736361503601
Validation loss: 1.6748381442921136

Epoch: 5| Step: 5
Training loss: 0.341086208820343
Validation loss: 1.7063852484508226

Epoch: 5| Step: 6
Training loss: 0.3192211389541626
Validation loss: 1.7050185344552482

Epoch: 5| Step: 7
Training loss: 0.27459877729415894
Validation loss: 1.6737721543158255

Epoch: 5| Step: 8
Training loss: 0.4094638228416443
Validation loss: 1.6945155923084547

Epoch: 5| Step: 9
Training loss: 0.19184213876724243
Validation loss: 1.7055247329896497

Epoch: 5| Step: 10
Training loss: 0.18388700485229492
Validation loss: 1.6915834552498275

Epoch: 353| Step: 0
Training loss: 0.10927609354257584
Validation loss: 1.6845728889588387

Epoch: 5| Step: 1
Training loss: 0.47020721435546875
Validation loss: 1.6847233016003844

Epoch: 5| Step: 2
Training loss: 0.4705377221107483
Validation loss: 1.6737237950806976

Epoch: 5| Step: 3
Training loss: 0.3399152159690857
Validation loss: 1.6862484626872565

Epoch: 5| Step: 4
Training loss: 0.3641257882118225
Validation loss: 1.7092030779007943

Epoch: 5| Step: 5
Training loss: 0.30045586824417114
Validation loss: 1.7226588213315575

Epoch: 5| Step: 6
Training loss: 0.6573240756988525
Validation loss: 1.681275821501209

Epoch: 5| Step: 7
Training loss: 0.3572936952114105
Validation loss: 1.6903984072387859

Epoch: 5| Step: 8
Training loss: 0.24708108603954315
Validation loss: 1.699634345628882

Epoch: 5| Step: 9
Training loss: 0.3329879641532898
Validation loss: 1.7221362462607763

Epoch: 5| Step: 10
Training loss: 0.32308828830718994
Validation loss: 1.7179008107031546

Epoch: 354| Step: 0
Training loss: 0.33200526237487793
Validation loss: 1.7303087788243448

Epoch: 5| Step: 1
Training loss: 0.37287622690200806
Validation loss: 1.7145235282118603

Epoch: 5| Step: 2
Training loss: 0.2351064682006836
Validation loss: 1.729451653777912

Epoch: 5| Step: 3
Training loss: 0.5279117822647095
Validation loss: 1.723129036605999

Epoch: 5| Step: 4
Training loss: 0.31837621331214905
Validation loss: 1.6814662218093872

Epoch: 5| Step: 5
Training loss: 0.43089938163757324
Validation loss: 1.6830436029741842

Epoch: 5| Step: 6
Training loss: 0.4236980080604553
Validation loss: 1.6440013352260794

Epoch: 5| Step: 7
Training loss: 0.29333871603012085
Validation loss: 1.6888587590186828

Epoch: 5| Step: 8
Training loss: 0.3205307126045227
Validation loss: 1.679235718583548

Epoch: 5| Step: 9
Training loss: 0.36234238743782043
Validation loss: 1.6358118890434183

Epoch: 5| Step: 10
Training loss: 0.4014955163002014
Validation loss: 1.6187592757645475

Epoch: 355| Step: 0
Training loss: 0.30608993768692017
Validation loss: 1.603649495750345

Epoch: 5| Step: 1
Training loss: 0.3497505187988281
Validation loss: 1.6286917040424962

Epoch: 5| Step: 2
Training loss: 0.3011308014392853
Validation loss: 1.6512210074291434

Epoch: 5| Step: 3
Training loss: 0.3634548783302307
Validation loss: 1.6482150195747294

Epoch: 5| Step: 4
Training loss: 0.5315742492675781
Validation loss: 1.6593788593046126

Epoch: 5| Step: 5
Training loss: 0.2737291753292084
Validation loss: 1.666371432042891

Epoch: 5| Step: 6
Training loss: 0.3333877623081207
Validation loss: 1.6471982335531583

Epoch: 5| Step: 7
Training loss: 0.45089808106422424
Validation loss: 1.632414687064386

Epoch: 5| Step: 8
Training loss: 0.6026300191879272
Validation loss: 1.6564920704851869

Epoch: 5| Step: 9
Training loss: 0.3137442469596863
Validation loss: 1.6792534730767692

Epoch: 5| Step: 10
Training loss: 0.23502004146575928
Validation loss: 1.660503871979252

Epoch: 356| Step: 0
Training loss: 0.29418590664863586
Validation loss: 1.686963099946258

Epoch: 5| Step: 1
Training loss: 0.48976293206214905
Validation loss: 1.705239934305991

Epoch: 5| Step: 2
Training loss: 0.383643239736557
Validation loss: 1.6879720252047303

Epoch: 5| Step: 3
Training loss: 0.5341533422470093
Validation loss: 1.7035363040944582

Epoch: 5| Step: 4
Training loss: 0.39290955662727356
Validation loss: 1.7046593466112692

Epoch: 5| Step: 5
Training loss: 0.30326494574546814
Validation loss: 1.6835100022695397

Epoch: 5| Step: 6
Training loss: 0.4573514461517334
Validation loss: 1.6881984215910717

Epoch: 5| Step: 7
Training loss: 0.2802068293094635
Validation loss: 1.6728816416955763

Epoch: 5| Step: 8
Training loss: 0.2913934588432312
Validation loss: 1.682879206954792

Epoch: 5| Step: 9
Training loss: 0.376789391040802
Validation loss: 1.714759083204372

Epoch: 5| Step: 10
Training loss: 0.27192962169647217
Validation loss: 1.6955832826193942

Epoch: 357| Step: 0
Training loss: 0.27516111731529236
Validation loss: 1.6957524271421536

Epoch: 5| Step: 1
Training loss: 0.39328595995903015
Validation loss: 1.7202968135956795

Epoch: 5| Step: 2
Training loss: 0.17318855226039886
Validation loss: 1.7023213345517394

Epoch: 5| Step: 3
Training loss: 0.4051227569580078
Validation loss: 1.6691101289564563

Epoch: 5| Step: 4
Training loss: 0.5377010107040405
Validation loss: 1.6764648934846282

Epoch: 5| Step: 5
Training loss: 0.4341803193092346
Validation loss: 1.68717921164728

Epoch: 5| Step: 6
Training loss: 0.3062453866004944
Validation loss: 1.7039246828325334

Epoch: 5| Step: 7
Training loss: 0.21524953842163086
Validation loss: 1.7003363358077181

Epoch: 5| Step: 8
Training loss: 0.34851449728012085
Validation loss: 1.6729741711770334

Epoch: 5| Step: 9
Training loss: 0.346684992313385
Validation loss: 1.661240707161606

Epoch: 5| Step: 10
Training loss: 0.36468443274497986
Validation loss: 1.6686368014222832

Epoch: 358| Step: 0
Training loss: 0.2323266565799713
Validation loss: 1.6716719763253325

Epoch: 5| Step: 1
Training loss: 0.44181832671165466
Validation loss: 1.6462993198825466

Epoch: 5| Step: 2
Training loss: 0.38587531447410583
Validation loss: 1.6582636987009356

Epoch: 5| Step: 3
Training loss: 0.3077802062034607
Validation loss: 1.668285217336429

Epoch: 5| Step: 4
Training loss: 0.26259034872055054
Validation loss: 1.6807491420417704

Epoch: 5| Step: 5
Training loss: 0.48118385672569275
Validation loss: 1.6935162851887364

Epoch: 5| Step: 6
Training loss: 0.30551743507385254
Validation loss: 1.7040407990896573

Epoch: 5| Step: 7
Training loss: 0.24249610304832458
Validation loss: 1.7262854319746777

Epoch: 5| Step: 8
Training loss: 0.36189812421798706
Validation loss: 1.7295246072994765

Epoch: 5| Step: 9
Training loss: 0.29641926288604736
Validation loss: 1.6953992702627694

Epoch: 5| Step: 10
Training loss: 0.2935582101345062
Validation loss: 1.6988597377654044

Epoch: 359| Step: 0
Training loss: 0.30159619450569153
Validation loss: 1.6599014446299563

Epoch: 5| Step: 1
Training loss: 0.26195651292800903
Validation loss: 1.6922757702489053

Epoch: 5| Step: 2
Training loss: 0.19109079241752625
Validation loss: 1.6303111045591292

Epoch: 5| Step: 3
Training loss: 0.35814180970191956
Validation loss: 1.6299719156757477

Epoch: 5| Step: 4
Training loss: 0.3075801730155945
Validation loss: 1.6608453412209787

Epoch: 5| Step: 5
Training loss: 0.3026791512966156
Validation loss: 1.6522935052071848

Epoch: 5| Step: 6
Training loss: 0.6352192163467407
Validation loss: 1.64856477450299

Epoch: 5| Step: 7
Training loss: 0.3457457423210144
Validation loss: 1.6785914116008307

Epoch: 5| Step: 8
Training loss: 0.2612264156341553
Validation loss: 1.712597556011651

Epoch: 5| Step: 9
Training loss: 0.3302653729915619
Validation loss: 1.712899374705489

Epoch: 5| Step: 10
Training loss: 0.29795074462890625
Validation loss: 1.7468046206299976

Epoch: 360| Step: 0
Training loss: 0.31515002250671387
Validation loss: 1.73427903011281

Epoch: 5| Step: 1
Training loss: 0.24796350300312042
Validation loss: 1.7089127596988474

Epoch: 5| Step: 2
Training loss: 0.20077809691429138
Validation loss: 1.705185644088253

Epoch: 5| Step: 3
Training loss: 0.3399070203304291
Validation loss: 1.6292781342742264

Epoch: 5| Step: 4
Training loss: 0.4318045675754547
Validation loss: 1.6620128257300264

Epoch: 5| Step: 5
Training loss: 0.14031025767326355
Validation loss: 1.6719700264674362

Epoch: 5| Step: 6
Training loss: 0.47990816831588745
Validation loss: 1.6805117143097745

Epoch: 5| Step: 7
Training loss: 0.47575873136520386
Validation loss: 1.6698251975479947

Epoch: 5| Step: 8
Training loss: 0.2232547253370285
Validation loss: 1.6637245211549985

Epoch: 5| Step: 9
Training loss: 0.39900311827659607
Validation loss: 1.6992922893134497

Epoch: 5| Step: 10
Training loss: 0.269634485244751
Validation loss: 1.6611779248842629

Epoch: 361| Step: 0
Training loss: 0.4276026785373688
Validation loss: 1.6703087078627719

Epoch: 5| Step: 1
Training loss: 0.24422629177570343
Validation loss: 1.6959464780745968

Epoch: 5| Step: 2
Training loss: 0.23671814799308777
Validation loss: 1.725451571967012

Epoch: 5| Step: 3
Training loss: 0.2319234162569046
Validation loss: 1.6846749500561786

Epoch: 5| Step: 4
Training loss: 0.44030308723449707
Validation loss: 1.7134919051201112

Epoch: 5| Step: 5
Training loss: 0.4078586995601654
Validation loss: 1.6701409310422919

Epoch: 5| Step: 6
Training loss: 0.18503610789775848
Validation loss: 1.6792327998786845

Epoch: 5| Step: 7
Training loss: 0.5028393864631653
Validation loss: 1.6754742078883673

Epoch: 5| Step: 8
Training loss: 0.2575380206108093
Validation loss: 1.6523223410370529

Epoch: 5| Step: 9
Training loss: 0.2920380234718323
Validation loss: 1.6870711657308763

Epoch: 5| Step: 10
Training loss: 0.2803492844104767
Validation loss: 1.6771486613058275

Epoch: 362| Step: 0
Training loss: 0.2789771556854248
Validation loss: 1.6954919368990007

Epoch: 5| Step: 1
Training loss: 0.24643352627754211
Validation loss: 1.6792651184143559

Epoch: 5| Step: 2
Training loss: 0.4901910424232483
Validation loss: 1.705235178752612

Epoch: 5| Step: 3
Training loss: 0.2394597828388214
Validation loss: 1.675482298738213

Epoch: 5| Step: 4
Training loss: 0.21270132064819336
Validation loss: 1.6920491841531569

Epoch: 5| Step: 5
Training loss: 0.24499507248401642
Validation loss: 1.704531782416887

Epoch: 5| Step: 6
Training loss: 0.38427114486694336
Validation loss: 1.71089776485197

Epoch: 5| Step: 7
Training loss: 0.4476791322231293
Validation loss: 1.700109492066086

Epoch: 5| Step: 8
Training loss: 0.37467530369758606
Validation loss: 1.700375283918073

Epoch: 5| Step: 9
Training loss: 0.20452193915843964
Validation loss: 1.6995986533421341

Epoch: 5| Step: 10
Training loss: 0.3993997573852539
Validation loss: 1.6582793510088356

Epoch: 363| Step: 0
Training loss: 0.2903291881084442
Validation loss: 1.6784135705681258

Epoch: 5| Step: 1
Training loss: 0.4043505787849426
Validation loss: 1.6882031092079737

Epoch: 5| Step: 2
Training loss: 0.44213876128196716
Validation loss: 1.651929465673303

Epoch: 5| Step: 3
Training loss: 0.21341443061828613
Validation loss: 1.6654276155656385

Epoch: 5| Step: 4
Training loss: 0.33360278606414795
Validation loss: 1.6847427788601126

Epoch: 5| Step: 5
Training loss: 0.18751361966133118
Validation loss: 1.662997082997394

Epoch: 5| Step: 6
Training loss: 0.48093047738075256
Validation loss: 1.663502352212065

Epoch: 5| Step: 7
Training loss: 0.2040759027004242
Validation loss: 1.696857390865203

Epoch: 5| Step: 8
Training loss: 0.32413727045059204
Validation loss: 1.6990287201378935

Epoch: 5| Step: 9
Training loss: 0.2218742072582245
Validation loss: 1.7277425514754428

Epoch: 5| Step: 10
Training loss: 0.258602499961853
Validation loss: 1.7310949217888616

Epoch: 364| Step: 0
Training loss: 0.5564079880714417
Validation loss: 1.7376793148697063

Epoch: 5| Step: 1
Training loss: 0.4402078092098236
Validation loss: 1.7349254341535671

Epoch: 5| Step: 2
Training loss: 0.2719278335571289
Validation loss: 1.7279226267209618

Epoch: 5| Step: 3
Training loss: 0.3129463791847229
Validation loss: 1.7538127578714842

Epoch: 5| Step: 4
Training loss: 0.17966586351394653
Validation loss: 1.7499337350168536

Epoch: 5| Step: 5
Training loss: 0.42399078607559204
Validation loss: 1.6958073185336204

Epoch: 5| Step: 6
Training loss: 0.17766742408275604
Validation loss: 1.7086162464593047

Epoch: 5| Step: 7
Training loss: 0.22421236336231232
Validation loss: 1.7148624453493344

Epoch: 5| Step: 8
Training loss: 0.42160043120384216
Validation loss: 1.7108737807120047

Epoch: 5| Step: 9
Training loss: 0.2668395936489105
Validation loss: 1.6588593580389535

Epoch: 5| Step: 10
Training loss: 0.21224425733089447
Validation loss: 1.6946852591729933

Epoch: 365| Step: 0
Training loss: 0.3562582731246948
Validation loss: 1.6489406401111233

Epoch: 5| Step: 1
Training loss: 0.4566882252693176
Validation loss: 1.648690228821129

Epoch: 5| Step: 2
Training loss: 0.20893296599388123
Validation loss: 1.660663620118172

Epoch: 5| Step: 3
Training loss: 0.3843851685523987
Validation loss: 1.7312346581489808

Epoch: 5| Step: 4
Training loss: 0.23815396428108215
Validation loss: 1.688428662156546

Epoch: 5| Step: 5
Training loss: 0.39793476462364197
Validation loss: 1.7000150885633243

Epoch: 5| Step: 6
Training loss: 0.13442280888557434
Validation loss: 1.7113983195315126

Epoch: 5| Step: 7
Training loss: 0.2706717252731323
Validation loss: 1.7112783501225133

Epoch: 5| Step: 8
Training loss: 0.24905462563037872
Validation loss: 1.7291831367759294

Epoch: 5| Step: 9
Training loss: 0.31531277298927307
Validation loss: 1.718034025161497

Epoch: 5| Step: 10
Training loss: 0.47752100229263306
Validation loss: 1.6905723182103967

Epoch: 366| Step: 0
Training loss: 0.3141394257545471
Validation loss: 1.7284259450051092

Epoch: 5| Step: 1
Training loss: 0.38065868616104126
Validation loss: 1.7196187896113242

Epoch: 5| Step: 2
Training loss: 0.21065440773963928
Validation loss: 1.6916571022361837

Epoch: 5| Step: 3
Training loss: 0.35491013526916504
Validation loss: 1.7170520187706075

Epoch: 5| Step: 4
Training loss: 0.40425047278404236
Validation loss: 1.7317535441408876

Epoch: 5| Step: 5
Training loss: 0.2286161482334137
Validation loss: 1.7314015126997424

Epoch: 5| Step: 6
Training loss: 0.24346128106117249
Validation loss: 1.7139095221796343

Epoch: 5| Step: 7
Training loss: 0.2679346203804016
Validation loss: 1.7375400156103156

Epoch: 5| Step: 8
Training loss: 0.3145800232887268
Validation loss: 1.742263565781296

Epoch: 5| Step: 9
Training loss: 0.5952133536338806
Validation loss: 1.7291379282551427

Epoch: 5| Step: 10
Training loss: 0.4078344404697418
Validation loss: 1.7392081804172967

Epoch: 367| Step: 0
Training loss: 0.19573113322257996
Validation loss: 1.7108570414204751

Epoch: 5| Step: 1
Training loss: 0.37285012006759644
Validation loss: 1.707176095695906

Epoch: 5| Step: 2
Training loss: 0.23022174835205078
Validation loss: 1.664187741535966

Epoch: 5| Step: 3
Training loss: 0.3446822166442871
Validation loss: 1.6894757875832178

Epoch: 5| Step: 4
Training loss: 0.31587931513786316
Validation loss: 1.7127380268548125

Epoch: 5| Step: 5
Training loss: 0.28530973196029663
Validation loss: 1.6824592454459077

Epoch: 5| Step: 6
Training loss: 0.3924531042575836
Validation loss: 1.728518304004464

Epoch: 5| Step: 7
Training loss: 0.4590388238430023
Validation loss: 1.6688945748472725

Epoch: 5| Step: 8
Training loss: 0.26930394768714905
Validation loss: 1.6815226770216418

Epoch: 5| Step: 9
Training loss: 0.5357317924499512
Validation loss: 1.6718591079917005

Epoch: 5| Step: 10
Training loss: 0.2606981098651886
Validation loss: 1.7000088025164861

Epoch: 368| Step: 0
Training loss: 0.3125889301300049
Validation loss: 1.7208330015982352

Epoch: 5| Step: 1
Training loss: 0.2388673573732376
Validation loss: 1.6896943969111289

Epoch: 5| Step: 2
Training loss: 0.3127623200416565
Validation loss: 1.689140683861189

Epoch: 5| Step: 3
Training loss: 0.3889993727207184
Validation loss: 1.7010346317803988

Epoch: 5| Step: 4
Training loss: 0.20166078209877014
Validation loss: 1.6762642360502673

Epoch: 5| Step: 5
Training loss: 0.15800291299819946
Validation loss: 1.708450641683353

Epoch: 5| Step: 6
Training loss: 0.3774533271789551
Validation loss: 1.7111430014333417

Epoch: 5| Step: 7
Training loss: 0.5261147022247314
Validation loss: 1.6967920282835602

Epoch: 5| Step: 8
Training loss: 0.46867427229881287
Validation loss: 1.7343875105663011

Epoch: 5| Step: 9
Training loss: 0.24820026755332947
Validation loss: 1.7098954454545052

Epoch: 5| Step: 10
Training loss: 0.3408879041671753
Validation loss: 1.756113172859274

Epoch: 369| Step: 0
Training loss: 0.43542614579200745
Validation loss: 1.7480339568148378

Epoch: 5| Step: 1
Training loss: 0.5158692598342896
Validation loss: 1.7631640998266076

Epoch: 5| Step: 2
Training loss: 0.20804551243782043
Validation loss: 1.77742124372913

Epoch: 5| Step: 3
Training loss: 0.3218556344509125
Validation loss: 1.7522008290854834

Epoch: 5| Step: 4
Training loss: 0.0960414856672287
Validation loss: 1.718874595498526

Epoch: 5| Step: 5
Training loss: 0.3852235674858093
Validation loss: 1.6729702193249938

Epoch: 5| Step: 6
Training loss: 0.27002575993537903
Validation loss: 1.6899615500562934

Epoch: 5| Step: 7
Training loss: 0.29831141233444214
Validation loss: 1.6433135847891531

Epoch: 5| Step: 8
Training loss: 0.33490315079689026
Validation loss: 1.6378465583247523

Epoch: 5| Step: 9
Training loss: 0.2584855556488037
Validation loss: 1.629094191776809

Epoch: 5| Step: 10
Training loss: 0.294889897108078
Validation loss: 1.6313765984709545

Epoch: 370| Step: 0
Training loss: 0.2917180359363556
Validation loss: 1.6316980104292593

Epoch: 5| Step: 1
Training loss: 0.21995823085308075
Validation loss: 1.6479340445610784

Epoch: 5| Step: 2
Training loss: 0.31797438859939575
Validation loss: 1.633646749681042

Epoch: 5| Step: 3
Training loss: 0.46247634291648865
Validation loss: 1.67940092086792

Epoch: 5| Step: 4
Training loss: 0.39924857020378113
Validation loss: 1.6580683928664013

Epoch: 5| Step: 5
Training loss: 0.2771153450012207
Validation loss: 1.6789099631770965

Epoch: 5| Step: 6
Training loss: 0.2857430577278137
Validation loss: 1.6261228028164114

Epoch: 5| Step: 7
Training loss: 0.31785598397254944
Validation loss: 1.6215659520959342

Epoch: 5| Step: 8
Training loss: 0.34118178486824036
Validation loss: 1.6346346216817056

Epoch: 5| Step: 9
Training loss: 0.2853264808654785
Validation loss: 1.622920419580193

Epoch: 5| Step: 10
Training loss: 0.20493187010288239
Validation loss: 1.649898886680603

Epoch: 371| Step: 0
Training loss: 0.28121376037597656
Validation loss: 1.587534599406745

Epoch: 5| Step: 1
Training loss: 0.33548009395599365
Validation loss: 1.6190378307014384

Epoch: 5| Step: 2
Training loss: 0.284330278635025
Validation loss: 1.6028278976358392

Epoch: 5| Step: 3
Training loss: 0.28088656067848206
Validation loss: 1.6217242312687699

Epoch: 5| Step: 4
Training loss: 0.16504932940006256
Validation loss: 1.6396103982002503

Epoch: 5| Step: 5
Training loss: 0.18208172917366028
Validation loss: 1.6790765306001068

Epoch: 5| Step: 6
Training loss: 0.3752569556236267
Validation loss: 1.6872954958228654

Epoch: 5| Step: 7
Training loss: 0.5252121686935425
Validation loss: 1.7092630414552585

Epoch: 5| Step: 8
Training loss: 0.33307304978370667
Validation loss: 1.7182132262055592

Epoch: 5| Step: 9
Training loss: 0.39851704239845276
Validation loss: 1.6890389739826162

Epoch: 5| Step: 10
Training loss: 0.1775551289319992
Validation loss: 1.6658610208060152

Epoch: 372| Step: 0
Training loss: 0.2345019280910492
Validation loss: 1.6854348759497366

Epoch: 5| Step: 1
Training loss: 0.23936514556407928
Validation loss: 1.668901280690265

Epoch: 5| Step: 2
Training loss: 0.551167368888855
Validation loss: 1.6663875772107033

Epoch: 5| Step: 3
Training loss: 0.3651943802833557
Validation loss: 1.661965908542756

Epoch: 5| Step: 4
Training loss: 0.32044199109077454
Validation loss: 1.6554155990641604

Epoch: 5| Step: 5
Training loss: 0.24998262524604797
Validation loss: 1.64225015717168

Epoch: 5| Step: 6
Training loss: 0.2898769974708557
Validation loss: 1.6341519714683614

Epoch: 5| Step: 7
Training loss: 0.3096725344657898
Validation loss: 1.6325683004112654

Epoch: 5| Step: 8
Training loss: 0.16264359652996063
Validation loss: 1.63888680934906

Epoch: 5| Step: 9
Training loss: 0.23854336142539978
Validation loss: 1.6812426479913856

Epoch: 5| Step: 10
Training loss: 0.241017684340477
Validation loss: 1.6743305139644171

Epoch: 373| Step: 0
Training loss: 0.26741737127304077
Validation loss: 1.6756560520459247

Epoch: 5| Step: 1
Training loss: 0.22513103485107422
Validation loss: 1.6622266513045116

Epoch: 5| Step: 2
Training loss: 0.15021264553070068
Validation loss: 1.6521374640926239

Epoch: 5| Step: 3
Training loss: 0.23307207226753235
Validation loss: 1.655133783176381

Epoch: 5| Step: 4
Training loss: 0.3926112949848175
Validation loss: 1.6566006650206864

Epoch: 5| Step: 5
Training loss: 0.22860905528068542
Validation loss: 1.6676881787597493

Epoch: 5| Step: 6
Training loss: 0.3606906533241272
Validation loss: 1.6418622975708337

Epoch: 5| Step: 7
Training loss: 0.5394713282585144
Validation loss: 1.6749216254039476

Epoch: 5| Step: 8
Training loss: 0.21670953929424286
Validation loss: 1.6241712659917853

Epoch: 5| Step: 9
Training loss: 0.20364360511302948
Validation loss: 1.6381819696836575

Epoch: 5| Step: 10
Training loss: 0.39455968141555786
Validation loss: 1.6049555270902571

Epoch: 374| Step: 0
Training loss: 0.33757105469703674
Validation loss: 1.6360118171220184

Epoch: 5| Step: 1
Training loss: 0.3138028681278229
Validation loss: 1.6304491668619134

Epoch: 5| Step: 2
Training loss: 0.29086217284202576
Validation loss: 1.6407899266930037

Epoch: 5| Step: 3
Training loss: 0.2895035147666931
Validation loss: 1.6328203396130634

Epoch: 5| Step: 4
Training loss: 0.33629947900772095
Validation loss: 1.622972414057742

Epoch: 5| Step: 5
Training loss: 0.24104423820972443
Validation loss: 1.633840976222869

Epoch: 5| Step: 6
Training loss: 0.2281237095594406
Validation loss: 1.6395551389263523

Epoch: 5| Step: 7
Training loss: 0.32679876685142517
Validation loss: 1.6317696853350567

Epoch: 5| Step: 8
Training loss: 0.1252332180738449
Validation loss: 1.6239947183157808

Epoch: 5| Step: 9
Training loss: 0.3934708833694458
Validation loss: 1.6364375263132074

Epoch: 5| Step: 10
Training loss: 0.2578509449958801
Validation loss: 1.5859030626153434

Epoch: 375| Step: 0
Training loss: 0.47496992349624634
Validation loss: 1.608641009176931

Epoch: 5| Step: 1
Training loss: 0.30786290764808655
Validation loss: 1.6015383940871044

Epoch: 5| Step: 2
Training loss: 0.2672939598560333
Validation loss: 1.5933867910856843

Epoch: 5| Step: 3
Training loss: 0.16879577934741974
Validation loss: 1.6117029856610041

Epoch: 5| Step: 4
Training loss: 0.31055450439453125
Validation loss: 1.60794714830255

Epoch: 5| Step: 5
Training loss: 0.30327266454696655
Validation loss: 1.611294702817035

Epoch: 5| Step: 6
Training loss: 0.201419398188591
Validation loss: 1.6308672146130634

Epoch: 5| Step: 7
Training loss: 0.2879684865474701
Validation loss: 1.659755140222529

Epoch: 5| Step: 8
Training loss: 0.200439453125
Validation loss: 1.6721927683840516

Epoch: 5| Step: 9
Training loss: 0.3402952551841736
Validation loss: 1.6761096959472985

Epoch: 5| Step: 10
Training loss: 0.16266083717346191
Validation loss: 1.6960052238997592

Epoch: 376| Step: 0
Training loss: 0.43696698546409607
Validation loss: 1.6907773953612133

Epoch: 5| Step: 1
Training loss: 0.18372496962547302
Validation loss: 1.6751018416497014

Epoch: 5| Step: 2
Training loss: 0.39416223764419556
Validation loss: 1.6809274073570006

Epoch: 5| Step: 3
Training loss: 0.2073582410812378
Validation loss: 1.6937276201863443

Epoch: 5| Step: 4
Training loss: 0.24555334448814392
Validation loss: 1.6930911079529793

Epoch: 5| Step: 5
Training loss: 0.27273499965667725
Validation loss: 1.705895677689583

Epoch: 5| Step: 6
Training loss: 0.27024969458580017
Validation loss: 1.6922060776782293

Epoch: 5| Step: 7
Training loss: 0.1854671835899353
Validation loss: 1.6956673155548752

Epoch: 5| Step: 8
Training loss: 0.3731473684310913
Validation loss: 1.6351203649274764

Epoch: 5| Step: 9
Training loss: 0.3146840035915375
Validation loss: 1.6423925353634743

Epoch: 5| Step: 10
Training loss: 0.260811984539032
Validation loss: 1.6280167448905207

Epoch: 377| Step: 0
Training loss: 0.30721625685691833
Validation loss: 1.6155577577570432

Epoch: 5| Step: 1
Training loss: 0.2295302152633667
Validation loss: 1.6462814891210167

Epoch: 5| Step: 2
Training loss: 0.3985966145992279
Validation loss: 1.6792625073463685

Epoch: 5| Step: 3
Training loss: 0.27928465604782104
Validation loss: 1.6904063404247325

Epoch: 5| Step: 4
Training loss: 0.28140345215797424
Validation loss: 1.7074902788285287

Epoch: 5| Step: 5
Training loss: 0.20809467136859894
Validation loss: 1.692816008803665

Epoch: 5| Step: 6
Training loss: 0.5436003804206848
Validation loss: 1.7090391548730994

Epoch: 5| Step: 7
Training loss: 0.17272162437438965
Validation loss: 1.692026480551689

Epoch: 5| Step: 8
Training loss: 0.27843475341796875
Validation loss: 1.6604905141297208

Epoch: 5| Step: 9
Training loss: 0.18204033374786377
Validation loss: 1.6479408292360203

Epoch: 5| Step: 10
Training loss: 0.15644589066505432
Validation loss: 1.6625783879269835

Epoch: 378| Step: 0
Training loss: 0.19239133596420288
Validation loss: 1.6290824195390106

Epoch: 5| Step: 1
Training loss: 0.42443975806236267
Validation loss: 1.619634359754542

Epoch: 5| Step: 2
Training loss: 0.12451819330453873
Validation loss: 1.6496367249437558

Epoch: 5| Step: 3
Training loss: 0.3149297833442688
Validation loss: 1.6327372674019105

Epoch: 5| Step: 4
Training loss: 0.21860018372535706
Validation loss: 1.6562182134197605

Epoch: 5| Step: 5
Training loss: 0.5620501637458801
Validation loss: 1.6739808641454226

Epoch: 5| Step: 6
Training loss: 0.1799752414226532
Validation loss: 1.661520045290711

Epoch: 5| Step: 7
Training loss: 0.2415994107723236
Validation loss: 1.6971092557394376

Epoch: 5| Step: 8
Training loss: 0.22859518229961395
Validation loss: 1.6711593366438342

Epoch: 5| Step: 9
Training loss: 0.20748206973075867
Validation loss: 1.641164723262992

Epoch: 5| Step: 10
Training loss: 0.3374471366405487
Validation loss: 1.6470781039166194

Epoch: 379| Step: 0
Training loss: 0.26676422357559204
Validation loss: 1.6647998517559421

Epoch: 5| Step: 1
Training loss: 0.40447577834129333
Validation loss: 1.6403714187683598

Epoch: 5| Step: 2
Training loss: 0.25990229845046997
Validation loss: 1.6329908204335037

Epoch: 5| Step: 3
Training loss: 0.29473811388015747
Validation loss: 1.6361866497224378

Epoch: 5| Step: 4
Training loss: 0.2880920469760895
Validation loss: 1.6216798559311898

Epoch: 5| Step: 5
Training loss: 0.28747397661209106
Validation loss: 1.6190946050869521

Epoch: 5| Step: 6
Training loss: 0.1802043616771698
Validation loss: 1.6091448478801276

Epoch: 5| Step: 7
Training loss: 0.25894877314567566
Validation loss: 1.5902340130139423

Epoch: 5| Step: 8
Training loss: 0.2954319715499878
Validation loss: 1.6275706265562324

Epoch: 5| Step: 9
Training loss: 0.14138726890087128
Validation loss: 1.642146122071051

Epoch: 5| Step: 10
Training loss: 0.4496909976005554
Validation loss: 1.6180914781426872

Epoch: 380| Step: 0
Training loss: 0.384418785572052
Validation loss: 1.6497869850486837

Epoch: 5| Step: 1
Training loss: 0.419424831867218
Validation loss: 1.6522131812187932

Epoch: 5| Step: 2
Training loss: 0.31243354082107544
Validation loss: 1.6468863192424978

Epoch: 5| Step: 3
Training loss: 0.3469747006893158
Validation loss: 1.6633420977541196

Epoch: 5| Step: 4
Training loss: 0.1804046481847763
Validation loss: 1.6393342441128147

Epoch: 5| Step: 5
Training loss: 0.4561171531677246
Validation loss: 1.661010503768921

Epoch: 5| Step: 6
Training loss: 0.1749161332845688
Validation loss: 1.66402478115533

Epoch: 5| Step: 7
Training loss: 0.24880418181419373
Validation loss: 1.6612760072113366

Epoch: 5| Step: 8
Training loss: 0.17026396095752716
Validation loss: 1.6885323473202285

Epoch: 5| Step: 9
Training loss: 0.18925631046295166
Validation loss: 1.6440854239207443

Epoch: 5| Step: 10
Training loss: 0.19006328284740448
Validation loss: 1.6522540879505936

Epoch: 381| Step: 0
Training loss: 0.2598823606967926
Validation loss: 1.6561005576964347

Epoch: 5| Step: 1
Training loss: 0.3751268982887268
Validation loss: 1.6795288708902174

Epoch: 5| Step: 2
Training loss: 0.28774815797805786
Validation loss: 1.6895757170133694

Epoch: 5| Step: 3
Training loss: 0.2913885712623596
Validation loss: 1.653250244355971

Epoch: 5| Step: 4
Training loss: 0.34997695684432983
Validation loss: 1.6418257105735041

Epoch: 5| Step: 5
Training loss: 0.4001200795173645
Validation loss: 1.6735311285141976

Epoch: 5| Step: 6
Training loss: 0.260700523853302
Validation loss: 1.6648011015307518

Epoch: 5| Step: 7
Training loss: 0.3252946436405182
Validation loss: 1.6799114968187066

Epoch: 5| Step: 8
Training loss: 0.3239421546459198
Validation loss: 1.6353992236557828

Epoch: 5| Step: 9
Training loss: 0.22001028060913086
Validation loss: 1.629454057703736

Epoch: 5| Step: 10
Training loss: 0.30984559655189514
Validation loss: 1.58602064142945

Epoch: 382| Step: 0
Training loss: 0.2338143140077591
Validation loss: 1.601820856012324

Epoch: 5| Step: 1
Training loss: 0.25635048747062683
Validation loss: 1.5773567576562204

Epoch: 5| Step: 2
Training loss: 0.4607349932193756
Validation loss: 1.5953490670009325

Epoch: 5| Step: 3
Training loss: 0.32135722041130066
Validation loss: 1.6034773754817184

Epoch: 5| Step: 4
Training loss: 0.21273931860923767
Validation loss: 1.6005250946167977

Epoch: 5| Step: 5
Training loss: 0.16414055228233337
Validation loss: 1.6339209079742432

Epoch: 5| Step: 6
Training loss: 0.2586483359336853
Validation loss: 1.622501286127234

Epoch: 5| Step: 7
Training loss: 0.40067481994628906
Validation loss: 1.6460805028997443

Epoch: 5| Step: 8
Training loss: 0.30159828066825867
Validation loss: 1.6780320085505003

Epoch: 5| Step: 9
Training loss: 0.24954083561897278
Validation loss: 1.6423601540186072

Epoch: 5| Step: 10
Training loss: 0.2835739254951477
Validation loss: 1.6450923886350406

Epoch: 383| Step: 0
Training loss: 0.13397179543972015
Validation loss: 1.6222481689145487

Epoch: 5| Step: 1
Training loss: 0.26184552907943726
Validation loss: 1.6033198064373386

Epoch: 5| Step: 2
Training loss: 0.49389904737472534
Validation loss: 1.6370345712989889

Epoch: 5| Step: 3
Training loss: 0.2681984007358551
Validation loss: 1.600063621356923

Epoch: 5| Step: 4
Training loss: 0.27141982316970825
Validation loss: 1.6229245496052567

Epoch: 5| Step: 5
Training loss: 0.3271176517009735
Validation loss: 1.609725203565372

Epoch: 5| Step: 6
Training loss: 0.43654149770736694
Validation loss: 1.6219356495846984

Epoch: 5| Step: 7
Training loss: 0.22533926367759705
Validation loss: 1.6530626640524915

Epoch: 5| Step: 8
Training loss: 0.19755437970161438
Validation loss: 1.6734862814667404

Epoch: 5| Step: 9
Training loss: 0.2540038228034973
Validation loss: 1.6704017423814344

Epoch: 5| Step: 10
Training loss: 0.24746201932430267
Validation loss: 1.6803887236502864

Epoch: 384| Step: 0
Training loss: 0.36689645051956177
Validation loss: 1.6380605902723087

Epoch: 5| Step: 1
Training loss: 0.25091445446014404
Validation loss: 1.6235586891892135

Epoch: 5| Step: 2
Training loss: 0.33229321241378784
Validation loss: 1.6256649468534736

Epoch: 5| Step: 3
Training loss: 0.34653061628341675
Validation loss: 1.5983080889589043

Epoch: 5| Step: 4
Training loss: 0.20224623382091522
Validation loss: 1.5927157280265645

Epoch: 5| Step: 5
Training loss: 0.18320924043655396
Validation loss: 1.5972793371446672

Epoch: 5| Step: 6
Training loss: 0.1861579418182373
Validation loss: 1.573721384489408

Epoch: 5| Step: 7
Training loss: 0.1759689599275589
Validation loss: 1.6056685011873963

Epoch: 5| Step: 8
Training loss: 0.41806721687316895
Validation loss: 1.6090736824979064

Epoch: 5| Step: 9
Training loss: 0.36205464601516724
Validation loss: 1.6249591522319342

Epoch: 5| Step: 10
Training loss: 0.2166747748851776
Validation loss: 1.6031008971634733

Epoch: 385| Step: 0
Training loss: 0.48718395829200745
Validation loss: 1.6400982359404206

Epoch: 5| Step: 1
Training loss: 0.13574466109275818
Validation loss: 1.6460652864107521

Epoch: 5| Step: 2
Training loss: 0.1904403120279312
Validation loss: 1.6145821630313832

Epoch: 5| Step: 3
Training loss: 0.3418545126914978
Validation loss: 1.5947038781258367

Epoch: 5| Step: 4
Training loss: 0.1827498972415924
Validation loss: 1.608143018138024

Epoch: 5| Step: 5
Training loss: 0.32837140560150146
Validation loss: 1.621148915701015

Epoch: 5| Step: 6
Training loss: 0.4310030937194824
Validation loss: 1.6241713557192075

Epoch: 5| Step: 7
Training loss: 0.2784115672111511
Validation loss: 1.6131262240871307

Epoch: 5| Step: 8
Training loss: 0.25833791494369507
Validation loss: 1.6210052095433718

Epoch: 5| Step: 9
Training loss: 0.19728055596351624
Validation loss: 1.6083459354216052

Epoch: 5| Step: 10
Training loss: 0.15109312534332275
Validation loss: 1.6149622189101351

Epoch: 386| Step: 0
Training loss: 0.24768798053264618
Validation loss: 1.5775310929103563

Epoch: 5| Step: 1
Training loss: 0.2576308250427246
Validation loss: 1.5475465943736415

Epoch: 5| Step: 2
Training loss: 0.5446291565895081
Validation loss: 1.588836149502826

Epoch: 5| Step: 3
Training loss: 0.15022389590740204
Validation loss: 1.577243907477266

Epoch: 5| Step: 4
Training loss: 0.3203398585319519
Validation loss: 1.599519270722584

Epoch: 5| Step: 5
Training loss: 0.26319897174835205
Validation loss: 1.6117858655991093

Epoch: 5| Step: 6
Training loss: 0.3034209609031677
Validation loss: 1.6169244589344147

Epoch: 5| Step: 7
Training loss: 0.28595227003097534
Validation loss: 1.58499002328483

Epoch: 5| Step: 8
Training loss: 0.3047167658805847
Validation loss: 1.5712262404862272

Epoch: 5| Step: 9
Training loss: 0.24301838874816895
Validation loss: 1.594084451275487

Epoch: 5| Step: 10
Training loss: 0.11948798596858978
Validation loss: 1.5950769045019662

Epoch: 387| Step: 0
Training loss: 0.15265531837940216
Validation loss: 1.5876167999800814

Epoch: 5| Step: 1
Training loss: 0.1631728708744049
Validation loss: 1.6000978748003643

Epoch: 5| Step: 2
Training loss: 0.2656063139438629
Validation loss: 1.608831819667611

Epoch: 5| Step: 3
Training loss: 0.33843564987182617
Validation loss: 1.6137886842091878

Epoch: 5| Step: 4
Training loss: 0.3863452672958374
Validation loss: 1.6212317482117684

Epoch: 5| Step: 5
Training loss: 0.35183054208755493
Validation loss: 1.6202766792748564

Epoch: 5| Step: 6
Training loss: 0.2725569009780884
Validation loss: 1.5963880618413289

Epoch: 5| Step: 7
Training loss: 0.29716387391090393
Validation loss: 1.6366654647293912

Epoch: 5| Step: 8
Training loss: 0.2221771776676178
Validation loss: 1.623367940225909

Epoch: 5| Step: 9
Training loss: 0.2945103049278259
Validation loss: 1.628309033250296

Epoch: 5| Step: 10
Training loss: 0.29931509494781494
Validation loss: 1.6556352210301224

Epoch: 388| Step: 0
Training loss: 0.2782493233680725
Validation loss: 1.6340786705734909

Epoch: 5| Step: 1
Training loss: 0.2233649492263794
Validation loss: 1.633179606929902

Epoch: 5| Step: 2
Training loss: 0.4121984839439392
Validation loss: 1.6100620967085644

Epoch: 5| Step: 3
Training loss: 0.23765623569488525
Validation loss: 1.6411834083577639

Epoch: 5| Step: 4
Training loss: 0.3490419387817383
Validation loss: 1.5947199380525978

Epoch: 5| Step: 5
Training loss: 0.3731381297111511
Validation loss: 1.5991246495195615

Epoch: 5| Step: 6
Training loss: 0.262764573097229
Validation loss: 1.5996297597885132

Epoch: 5| Step: 7
Training loss: 0.2305375635623932
Validation loss: 1.5483021043962049

Epoch: 5| Step: 8
Training loss: 0.3487188220024109
Validation loss: 1.5925885785010554

Epoch: 5| Step: 9
Training loss: 0.26845067739486694
Validation loss: 1.5627709780969927

Epoch: 5| Step: 10
Training loss: 0.24259935319423676
Validation loss: 1.5765064518938783

Epoch: 389| Step: 0
Training loss: 0.37176018953323364
Validation loss: 1.5613136842686643

Epoch: 5| Step: 1
Training loss: 0.39377787709236145
Validation loss: 1.5477278155665244

Epoch: 5| Step: 2
Training loss: 0.3628770709037781
Validation loss: 1.5345358746026152

Epoch: 5| Step: 3
Training loss: 0.18574722111225128
Validation loss: 1.5691093334587671

Epoch: 5| Step: 4
Training loss: 0.17528632283210754
Validation loss: 1.5230568852475894

Epoch: 5| Step: 5
Training loss: 0.29463183879852295
Validation loss: 1.5642834068626486

Epoch: 5| Step: 6
Training loss: 0.18982598185539246
Validation loss: 1.5895381319907405

Epoch: 5| Step: 7
Training loss: 0.19913135468959808
Validation loss: 1.6295496532993932

Epoch: 5| Step: 8
Training loss: 0.1577623337507248
Validation loss: 1.6350214353171728

Epoch: 5| Step: 9
Training loss: 0.2641366124153137
Validation loss: 1.6300820932593396

Epoch: 5| Step: 10
Training loss: 0.29931190609931946
Validation loss: 1.6261636787845242

Epoch: 390| Step: 0
Training loss: 0.3165380656719208
Validation loss: 1.6473100826304445

Epoch: 5| Step: 1
Training loss: 0.4367451071739197
Validation loss: 1.6165188948313396

Epoch: 5| Step: 2
Training loss: 0.3066774308681488
Validation loss: 1.6272466695436867

Epoch: 5| Step: 3
Training loss: 0.20961534976959229
Validation loss: 1.6169923441384428

Epoch: 5| Step: 4
Training loss: 0.2128221094608307
Validation loss: 1.6313715122079337

Epoch: 5| Step: 5
Training loss: 0.2184855192899704
Validation loss: 1.6144858701254732

Epoch: 5| Step: 6
Training loss: 0.2700963616371155
Validation loss: 1.5913552494459255

Epoch: 5| Step: 7
Training loss: 0.2825240194797516
Validation loss: 1.5913198212141633

Epoch: 5| Step: 8
Training loss: 0.28830939531326294
Validation loss: 1.604910086559993

Epoch: 5| Step: 9
Training loss: 0.41884058713912964
Validation loss: 1.5622014025206208

Epoch: 5| Step: 10
Training loss: 0.18665409088134766
Validation loss: 1.586868373296594

Epoch: 391| Step: 0
Training loss: 0.24149255454540253
Validation loss: 1.6052668709908762

Epoch: 5| Step: 1
Training loss: 0.3153945803642273
Validation loss: 1.622678005567161

Epoch: 5| Step: 2
Training loss: 0.4033704698085785
Validation loss: 1.6367010044795212

Epoch: 5| Step: 3
Training loss: 0.26199769973754883
Validation loss: 1.6687113315828386

Epoch: 5| Step: 4
Training loss: 0.2159731686115265
Validation loss: 1.6690217641092115

Epoch: 5| Step: 5
Training loss: 0.3647587299346924
Validation loss: 1.6260555790316673

Epoch: 5| Step: 6
Training loss: 0.2331506758928299
Validation loss: 1.6599978099587143

Epoch: 5| Step: 7
Training loss: 0.25132790207862854
Validation loss: 1.6349691883210213

Epoch: 5| Step: 8
Training loss: 0.21313300728797913
Validation loss: 1.6212631681913972

Epoch: 5| Step: 9
Training loss: 0.20316000282764435
Validation loss: 1.624708407668657

Epoch: 5| Step: 10
Training loss: 0.4807358384132385
Validation loss: 1.592468265564211

Epoch: 392| Step: 0
Training loss: 0.20351186394691467
Validation loss: 1.5887260706193986

Epoch: 5| Step: 1
Training loss: 0.3263658285140991
Validation loss: 1.6266824532580633

Epoch: 5| Step: 2
Training loss: 0.3559902012348175
Validation loss: 1.5970055031520065

Epoch: 5| Step: 3
Training loss: 0.4279495179653168
Validation loss: 1.5990868563293128

Epoch: 5| Step: 4
Training loss: 0.30203190445899963
Validation loss: 1.5871114384743474

Epoch: 5| Step: 5
Training loss: 0.20652098953723907
Validation loss: 1.5770479043324788

Epoch: 5| Step: 6
Training loss: 0.26994213461875916
Validation loss: 1.610009742039506

Epoch: 5| Step: 7
Training loss: 0.12775570154190063
Validation loss: 1.6089911742876934

Epoch: 5| Step: 8
Training loss: 0.16674771904945374
Validation loss: 1.6174822930366761

Epoch: 5| Step: 9
Training loss: 0.247138112783432
Validation loss: 1.6586025286746282

Epoch: 5| Step: 10
Training loss: 0.36546623706817627
Validation loss: 1.6660014262763403

Epoch: 393| Step: 0
Training loss: 0.30942511558532715
Validation loss: 1.6697200241909231

Epoch: 5| Step: 1
Training loss: 0.17280319333076477
Validation loss: 1.6353918365252915

Epoch: 5| Step: 2
Training loss: 0.37798118591308594
Validation loss: 1.6183812208073114

Epoch: 5| Step: 3
Training loss: 0.1685805767774582
Validation loss: 1.5869965848102365

Epoch: 5| Step: 4
Training loss: 0.2672780454158783
Validation loss: 1.5944682731423327

Epoch: 5| Step: 5
Training loss: 0.31600451469421387
Validation loss: 1.6026111277200843

Epoch: 5| Step: 6
Training loss: 0.3342236876487732
Validation loss: 1.5977686887146325

Epoch: 5| Step: 7
Training loss: 0.1430962085723877
Validation loss: 1.6067357473475958

Epoch: 5| Step: 8
Training loss: 0.19880057871341705
Validation loss: 1.6164853329299598

Epoch: 5| Step: 9
Training loss: 0.29486992955207825
Validation loss: 1.6270453968355734

Epoch: 5| Step: 10
Training loss: 0.26721125841140747
Validation loss: 1.6399049528183476

Epoch: 394| Step: 0
Training loss: 0.33577218651771545
Validation loss: 1.6327257822918635

Epoch: 5| Step: 1
Training loss: 0.3287833333015442
Validation loss: 1.6501996401817567

Epoch: 5| Step: 2
Training loss: 0.248247891664505
Validation loss: 1.5940460684478923

Epoch: 5| Step: 3
Training loss: 0.31584247946739197
Validation loss: 1.585488583451958

Epoch: 5| Step: 4
Training loss: 0.236000657081604
Validation loss: 1.6048228509964482

Epoch: 5| Step: 5
Training loss: 0.36147141456604004
Validation loss: 1.575703961874849

Epoch: 5| Step: 6
Training loss: 0.32288858294487
Validation loss: 1.5410413998429493

Epoch: 5| Step: 7
Training loss: 0.5138438940048218
Validation loss: 1.5531978555904922

Epoch: 5| Step: 8
Training loss: 0.24712924659252167
Validation loss: 1.5437378357815486

Epoch: 5| Step: 9
Training loss: 0.15769264101982117
Validation loss: 1.508701423163055

Epoch: 5| Step: 10
Training loss: 0.27054283022880554
Validation loss: 1.5450579043357604

Epoch: 395| Step: 0
Training loss: 0.34161168336868286
Validation loss: 1.5499079663266417

Epoch: 5| Step: 1
Training loss: 0.13333594799041748
Validation loss: 1.6023987723935036

Epoch: 5| Step: 2
Training loss: 0.29839134216308594
Validation loss: 1.6390320280546784

Epoch: 5| Step: 3
Training loss: 0.25058066844940186
Validation loss: 1.6491025545263802

Epoch: 5| Step: 4
Training loss: 0.25075989961624146
Validation loss: 1.647814678889449

Epoch: 5| Step: 5
Training loss: 0.17169471085071564
Validation loss: 1.6218359188366962

Epoch: 5| Step: 6
Training loss: 0.3988252282142639
Validation loss: 1.6535870593081239

Epoch: 5| Step: 7
Training loss: 0.20248007774353027
Validation loss: 1.6236353138441681

Epoch: 5| Step: 8
Training loss: 0.20390009880065918
Validation loss: 1.6170084361107118

Epoch: 5| Step: 9
Training loss: 0.3024851381778717
Validation loss: 1.5849844332664245

Epoch: 5| Step: 10
Training loss: 0.4032895863056183
Validation loss: 1.579142879414302

Epoch: 396| Step: 0
Training loss: 0.411231130361557
Validation loss: 1.5970731678829397

Epoch: 5| Step: 1
Training loss: 0.33724650740623474
Validation loss: 1.6018788993999522

Epoch: 5| Step: 2
Training loss: 0.2608327865600586
Validation loss: 1.606905302693767

Epoch: 5| Step: 3
Training loss: 0.18935570120811462
Validation loss: 1.5935661997846378

Epoch: 5| Step: 4
Training loss: 0.16096612811088562
Validation loss: 1.5911506311867827

Epoch: 5| Step: 5
Training loss: 0.12702250480651855
Validation loss: 1.5711103895659089

Epoch: 5| Step: 6
Training loss: 0.224919393658638
Validation loss: 1.567702870215139

Epoch: 5| Step: 7
Training loss: 0.29676273465156555
Validation loss: 1.5790198374820013

Epoch: 5| Step: 8
Training loss: 0.27179598808288574
Validation loss: 1.5783010400751585

Epoch: 5| Step: 9
Training loss: 0.2148619145154953
Validation loss: 1.6041240794684297

Epoch: 5| Step: 10
Training loss: 0.2560770809650421
Validation loss: 1.573147343051049

Epoch: 397| Step: 0
Training loss: 0.18087518215179443
Validation loss: 1.6190130979784074

Epoch: 5| Step: 1
Training loss: 0.2394198179244995
Validation loss: 1.630102228092891

Epoch: 5| Step: 2
Training loss: 0.2442033290863037
Validation loss: 1.583761267764594

Epoch: 5| Step: 3
Training loss: 0.2202928513288498
Validation loss: 1.609927132565488

Epoch: 5| Step: 4
Training loss: 0.1700313240289688
Validation loss: 1.5896604073944913

Epoch: 5| Step: 5
Training loss: 0.21903088688850403
Validation loss: 1.56683204379133

Epoch: 5| Step: 6
Training loss: 0.1820262372493744
Validation loss: 1.579555703747657

Epoch: 5| Step: 7
Training loss: 0.3384581208229065
Validation loss: 1.5912740307469522

Epoch: 5| Step: 8
Training loss: 0.2995055317878723
Validation loss: 1.5884238237975745

Epoch: 5| Step: 9
Training loss: 0.3456568717956543
Validation loss: 1.560709411098111

Epoch: 5| Step: 10
Training loss: 0.32423555850982666
Validation loss: 1.5681374765211535

Epoch: 398| Step: 0
Training loss: 0.3042970299720764
Validation loss: 1.5791315237681072

Epoch: 5| Step: 1
Training loss: 0.18870191276073456
Validation loss: 1.581545893863965

Epoch: 5| Step: 2
Training loss: 0.2907020151615143
Validation loss: 1.5651297146274197

Epoch: 5| Step: 3
Training loss: 0.18558433651924133
Validation loss: 1.5751560682891517

Epoch: 5| Step: 4
Training loss: 0.15806113183498383
Validation loss: 1.5639637439481673

Epoch: 5| Step: 5
Training loss: 0.3731687068939209
Validation loss: 1.5547837775240663

Epoch: 5| Step: 6
Training loss: 0.17931407690048218
Validation loss: 1.528195502937481

Epoch: 5| Step: 7
Training loss: 0.2464645355939865
Validation loss: 1.5784535113201346

Epoch: 5| Step: 8
Training loss: 0.22658105194568634
Validation loss: 1.5630346421272523

Epoch: 5| Step: 9
Training loss: 0.24500957131385803
Validation loss: 1.5465747246178247

Epoch: 5| Step: 10
Training loss: 0.4018827974796295
Validation loss: 1.5920457993784258

Epoch: 399| Step: 0
Training loss: 0.257927268743515
Validation loss: 1.5893731937613538

Epoch: 5| Step: 1
Training loss: 0.23326411843299866
Validation loss: 1.649267509419431

Epoch: 5| Step: 2
Training loss: 0.21670110523700714
Validation loss: 1.6372698705683473

Epoch: 5| Step: 3
Training loss: 0.10916785895824432
Validation loss: 1.6284568079056279

Epoch: 5| Step: 4
Training loss: 0.2540836036205292
Validation loss: 1.6026469917707546

Epoch: 5| Step: 5
Training loss: 0.21211743354797363
Validation loss: 1.6023770045208674

Epoch: 5| Step: 6
Training loss: 0.3144727349281311
Validation loss: 1.5872459014256795

Epoch: 5| Step: 7
Training loss: 0.32783085107803345
Validation loss: 1.5901329478909891

Epoch: 5| Step: 8
Training loss: 0.3018457293510437
Validation loss: 1.5853222582929878

Epoch: 5| Step: 9
Training loss: 0.34411102533340454
Validation loss: 1.6161598236330095

Epoch: 5| Step: 10
Training loss: 0.36893534660339355
Validation loss: 1.590036411439219

Epoch: 400| Step: 0
Training loss: 0.3540758490562439
Validation loss: 1.6112178615344468

Epoch: 5| Step: 1
Training loss: 0.3422605097293854
Validation loss: 1.5843348887658888

Epoch: 5| Step: 2
Training loss: 0.18925589323043823
Validation loss: 1.5723682629164828

Epoch: 5| Step: 3
Training loss: 0.21004006266593933
Validation loss: 1.6023199173711962

Epoch: 5| Step: 4
Training loss: 0.24417755007743835
Validation loss: 1.6282977891224686

Epoch: 5| Step: 5
Training loss: 0.1491771638393402
Validation loss: 1.6488841400351575

Epoch: 5| Step: 6
Training loss: 0.38911470770835876
Validation loss: 1.6188361375562605

Epoch: 5| Step: 7
Training loss: 0.3130336403846741
Validation loss: 1.627555921513547

Epoch: 5| Step: 8
Training loss: 0.2406233847141266
Validation loss: 1.6242003030674432

Epoch: 5| Step: 9
Training loss: 0.13549986481666565
Validation loss: 1.6207466074215469

Epoch: 5| Step: 10
Training loss: 0.3207271695137024
Validation loss: 1.6003730194542998

Epoch: 401| Step: 0
Training loss: 0.2264266461133957
Validation loss: 1.5880814854816725

Epoch: 5| Step: 1
Training loss: 0.3693074584007263
Validation loss: 1.6346532067944926

Epoch: 5| Step: 2
Training loss: 0.4288102686405182
Validation loss: 1.656929809560058

Epoch: 5| Step: 3
Training loss: 0.35703957080841064
Validation loss: 1.6682906984001078

Epoch: 5| Step: 4
Training loss: 0.24134770035743713
Validation loss: 1.6178280333037018

Epoch: 5| Step: 5
Training loss: 0.22677841782569885
Validation loss: 1.613693937178581

Epoch: 5| Step: 6
Training loss: 0.15130721032619476
Validation loss: 1.5927675654811244

Epoch: 5| Step: 7
Training loss: 0.45951566100120544
Validation loss: 1.6388251576372372

Epoch: 5| Step: 8
Training loss: 0.3502799868583679
Validation loss: 1.6262510092027727

Epoch: 5| Step: 9
Training loss: 0.1853598952293396
Validation loss: 1.6458720007250387

Epoch: 5| Step: 10
Training loss: 0.24196313321590424
Validation loss: 1.6367768138967536

Epoch: 402| Step: 0
Training loss: 0.2314598560333252
Validation loss: 1.5905087494081067

Epoch: 5| Step: 1
Training loss: 0.21542906761169434
Validation loss: 1.5894140658840057

Epoch: 5| Step: 2
Training loss: 0.36915791034698486
Validation loss: 1.562766840381007

Epoch: 5| Step: 3
Training loss: 0.30597272515296936
Validation loss: 1.5550903299803376

Epoch: 5| Step: 4
Training loss: 0.2267584502696991
Validation loss: 1.5841101061913274

Epoch: 5| Step: 5
Training loss: 0.23249396681785583
Validation loss: 1.5532502794778476

Epoch: 5| Step: 6
Training loss: 0.4389118254184723
Validation loss: 1.566170980212509

Epoch: 5| Step: 7
Training loss: 0.23896487057209015
Validation loss: 1.5961206510502806

Epoch: 5| Step: 8
Training loss: 0.1464119702577591
Validation loss: 1.6225755778692101

Epoch: 5| Step: 9
Training loss: 0.20477637648582458
Validation loss: 1.6087324593656807

Epoch: 5| Step: 10
Training loss: 0.31587138772010803
Validation loss: 1.6210052697889266

Epoch: 403| Step: 0
Training loss: 0.22779643535614014
Validation loss: 1.5958737647661598

Epoch: 5| Step: 1
Training loss: 0.12112455070018768
Validation loss: 1.6025852772497362

Epoch: 5| Step: 2
Training loss: 0.38805538415908813
Validation loss: 1.5840616046741445

Epoch: 5| Step: 3
Training loss: 0.33230060338974
Validation loss: 1.601109690563653

Epoch: 5| Step: 4
Training loss: 0.16228239238262177
Validation loss: 1.568661576958113

Epoch: 5| Step: 5
Training loss: 0.2260848581790924
Validation loss: 1.6069744274180422

Epoch: 5| Step: 6
Training loss: 0.25970882177352905
Validation loss: 1.570625949931401

Epoch: 5| Step: 7
Training loss: 0.24462799727916718
Validation loss: 1.5741530310723089

Epoch: 5| Step: 8
Training loss: 0.3198632597923279
Validation loss: 1.5824371473763579

Epoch: 5| Step: 9
Training loss: 0.26008161902427673
Validation loss: 1.582197391858665

Epoch: 5| Step: 10
Training loss: 0.3559166193008423
Validation loss: 1.5683059230927499

Epoch: 404| Step: 0
Training loss: 0.21942353248596191
Validation loss: 1.581925279350691

Epoch: 5| Step: 1
Training loss: 0.15903648734092712
Validation loss: 1.5726783160240418

Epoch: 5| Step: 2
Training loss: 0.4508138597011566
Validation loss: 1.5394856173505065

Epoch: 5| Step: 3
Training loss: 0.16641245782375336
Validation loss: 1.560272502642806

Epoch: 5| Step: 4
Training loss: 0.2299051284790039
Validation loss: 1.5645534915308799

Epoch: 5| Step: 5
Training loss: 0.22266845405101776
Validation loss: 1.5467382477175804

Epoch: 5| Step: 6
Training loss: 0.21794359385967255
Validation loss: 1.5808200682363203

Epoch: 5| Step: 7
Training loss: 0.16613492369651794
Validation loss: 1.56555050675587

Epoch: 5| Step: 8
Training loss: 0.3221830725669861
Validation loss: 1.5734376304893083

Epoch: 5| Step: 9
Training loss: 0.2149970978498459
Validation loss: 1.5992396852021575

Epoch: 5| Step: 10
Training loss: 0.33454370498657227
Validation loss: 1.5818733951096893

Epoch: 405| Step: 0
Training loss: 0.12895457446575165
Validation loss: 1.6070077624372257

Epoch: 5| Step: 1
Training loss: 0.1701541244983673
Validation loss: 1.5684665979877594

Epoch: 5| Step: 2
Training loss: 0.3656327724456787
Validation loss: 1.5865199899160733

Epoch: 5| Step: 3
Training loss: 0.1163920983672142
Validation loss: 1.598333506173985

Epoch: 5| Step: 4
Training loss: 0.34982457756996155
Validation loss: 1.5874475740617322

Epoch: 5| Step: 5
Training loss: 0.2352765053510666
Validation loss: 1.5678827852331183

Epoch: 5| Step: 6
Training loss: 0.30446672439575195
Validation loss: 1.5501741170883179

Epoch: 5| Step: 7
Training loss: 0.22786465287208557
Validation loss: 1.568329418859174

Epoch: 5| Step: 8
Training loss: 0.3390231728553772
Validation loss: 1.574342841743141

Epoch: 5| Step: 9
Training loss: 0.18490377068519592
Validation loss: 1.5883243391590733

Epoch: 5| Step: 10
Training loss: 0.30028435587882996
Validation loss: 1.6013579355773104

Epoch: 406| Step: 0
Training loss: 0.24960990250110626
Validation loss: 1.5964516042381205

Epoch: 5| Step: 1
Training loss: 0.24772968888282776
Validation loss: 1.5764375540517992

Epoch: 5| Step: 2
Training loss: 0.2838417887687683
Validation loss: 1.587859615202873

Epoch: 5| Step: 3
Training loss: 0.3512633740901947
Validation loss: 1.577834460043138

Epoch: 5| Step: 4
Training loss: 0.17962804436683655
Validation loss: 1.5842566823446622

Epoch: 5| Step: 5
Training loss: 0.19360573589801788
Validation loss: 1.599662930734696

Epoch: 5| Step: 6
Training loss: 0.2116013467311859
Validation loss: 1.55345106381242

Epoch: 5| Step: 7
Training loss: 0.255160391330719
Validation loss: 1.5627730482368059

Epoch: 5| Step: 8
Training loss: 0.2042533904314041
Validation loss: 1.5611823361407045

Epoch: 5| Step: 9
Training loss: 0.21323156356811523
Validation loss: 1.540667292892292

Epoch: 5| Step: 10
Training loss: 0.23944412171840668
Validation loss: 1.523398394225746

Epoch: 407| Step: 0
Training loss: 0.11861052364110947
Validation loss: 1.529068366173775

Epoch: 5| Step: 1
Training loss: 0.2600724399089813
Validation loss: 1.5569489053500596

Epoch: 5| Step: 2
Training loss: 0.29228559136390686
Validation loss: 1.5493297576904297

Epoch: 5| Step: 3
Training loss: 0.25177058577537537
Validation loss: 1.556542077372151

Epoch: 5| Step: 4
Training loss: 0.21273088455200195
Validation loss: 1.585453699993831

Epoch: 5| Step: 5
Training loss: 0.28173500299453735
Validation loss: 1.5960960503547423

Epoch: 5| Step: 6
Training loss: 0.24705903232097626
Validation loss: 1.5977532350888817

Epoch: 5| Step: 7
Training loss: 0.35440221428871155
Validation loss: 1.573603404465542

Epoch: 5| Step: 8
Training loss: 0.12372425943613052
Validation loss: 1.594099401145853

Epoch: 5| Step: 9
Training loss: 0.35776811838150024
Validation loss: 1.5905849472168954

Epoch: 5| Step: 10
Training loss: 0.17092739045619965
Validation loss: 1.576326020302311

Epoch: 408| Step: 0
Training loss: 0.3438074588775635
Validation loss: 1.5967586155860656

Epoch: 5| Step: 1
Training loss: 0.20191602408885956
Validation loss: 1.5802930119217082

Epoch: 5| Step: 2
Training loss: 0.1407923847436905
Validation loss: 1.56853138759572

Epoch: 5| Step: 3
Training loss: 0.17956797778606415
Validation loss: 1.5602764057856735

Epoch: 5| Step: 4
Training loss: 0.2218761146068573
Validation loss: 1.5410312183441655

Epoch: 5| Step: 5
Training loss: 0.2110590934753418
Validation loss: 1.5191937646558207

Epoch: 5| Step: 6
Training loss: 0.1623874008655548
Validation loss: 1.5244931726045505

Epoch: 5| Step: 7
Training loss: 0.2682422697544098
Validation loss: 1.5487087606101908

Epoch: 5| Step: 8
Training loss: 0.20887550711631775
Validation loss: 1.5181214181325768

Epoch: 5| Step: 9
Training loss: 0.2526850402355194
Validation loss: 1.5241364625192457

Epoch: 5| Step: 10
Training loss: 0.27344387769699097
Validation loss: 1.5504205995990383

Epoch: 409| Step: 0
Training loss: 0.33905526995658875
Validation loss: 1.5782617356187554

Epoch: 5| Step: 1
Training loss: 0.1707611232995987
Validation loss: 1.57794044222883

Epoch: 5| Step: 2
Training loss: 0.17488647997379303
Validation loss: 1.5651234554988083

Epoch: 5| Step: 3
Training loss: 0.24339178204536438
Validation loss: 1.566016741978225

Epoch: 5| Step: 4
Training loss: 0.13699102401733398
Validation loss: 1.5505413598911737

Epoch: 5| Step: 5
Training loss: 0.48312798142433167
Validation loss: 1.547015002337835

Epoch: 5| Step: 6
Training loss: 0.18416820466518402
Validation loss: 1.5748928541778235

Epoch: 5| Step: 7
Training loss: 0.2539295554161072
Validation loss: 1.5552602967908304

Epoch: 5| Step: 8
Training loss: 0.13451720774173737
Validation loss: 1.5348355847020303

Epoch: 5| Step: 9
Training loss: 0.19378188252449036
Validation loss: 1.554403293517328

Epoch: 5| Step: 10
Training loss: 0.28090381622314453
Validation loss: 1.5496536813756472

Epoch: 410| Step: 0
Training loss: 0.21000656485557556
Validation loss: 1.5377467050347278

Epoch: 5| Step: 1
Training loss: 0.23009788990020752
Validation loss: 1.5600015578731414

Epoch: 5| Step: 2
Training loss: 0.15261541306972504
Validation loss: 1.5800268009144773

Epoch: 5| Step: 3
Training loss: 0.4109860360622406
Validation loss: 1.5968493851282264

Epoch: 5| Step: 4
Training loss: 0.29766225814819336
Validation loss: 1.609040960188835

Epoch: 5| Step: 5
Training loss: 0.2691992521286011
Validation loss: 1.589634914552012

Epoch: 5| Step: 6
Training loss: 0.24343952536582947
Validation loss: 1.6359616530838834

Epoch: 5| Step: 7
Training loss: 0.1777183711528778
Validation loss: 1.6096249716256255

Epoch: 5| Step: 8
Training loss: 0.08167336881160736
Validation loss: 1.5878224142136113

Epoch: 5| Step: 9
Training loss: 0.2186775952577591
Validation loss: 1.5764425057236866

Epoch: 5| Step: 10
Training loss: 0.3634546399116516
Validation loss: 1.5628920588442075

Epoch: 411| Step: 0
Training loss: 0.27364203333854675
Validation loss: 1.5449671194117556

Epoch: 5| Step: 1
Training loss: 0.19344623386859894
Validation loss: 1.5381491863599388

Epoch: 5| Step: 2
Training loss: 0.14119932055473328
Validation loss: 1.5379150708516438

Epoch: 5| Step: 3
Training loss: 0.22894883155822754
Validation loss: 1.5233967868230676

Epoch: 5| Step: 4
Training loss: 0.24069707095623016
Validation loss: 1.5325104459639518

Epoch: 5| Step: 5
Training loss: 0.3197369873523712
Validation loss: 1.5271282798500472

Epoch: 5| Step: 6
Training loss: 0.18393097817897797
Validation loss: 1.5264981357000207

Epoch: 5| Step: 7
Training loss: 0.47152966260910034
Validation loss: 1.5181030022200717

Epoch: 5| Step: 8
Training loss: 0.2461405247449875
Validation loss: 1.547553950740445

Epoch: 5| Step: 9
Training loss: 0.11940117925405502
Validation loss: 1.5397810910337715

Epoch: 5| Step: 10
Training loss: 0.20137116312980652
Validation loss: 1.563284727834886

Epoch: 412| Step: 0
Training loss: 0.23348894715309143
Validation loss: 1.566764844361172

Epoch: 5| Step: 1
Training loss: 0.2965455651283264
Validation loss: 1.5993441791944607

Epoch: 5| Step: 2
Training loss: 0.1982124298810959
Validation loss: 1.6100059952787174

Epoch: 5| Step: 3
Training loss: 0.3799198865890503
Validation loss: 1.6250215102267522

Epoch: 5| Step: 4
Training loss: 0.1345352828502655
Validation loss: 1.6170464510558753

Epoch: 5| Step: 5
Training loss: 0.21424062550067902
Validation loss: 1.5992927679451563

Epoch: 5| Step: 6
Training loss: 0.28400811553001404
Validation loss: 1.5699643268380115

Epoch: 5| Step: 7
Training loss: 0.2003088891506195
Validation loss: 1.5665592506367674

Epoch: 5| Step: 8
Training loss: 0.1948908269405365
Validation loss: 1.5374573481980192

Epoch: 5| Step: 9
Training loss: 0.10297757387161255
Validation loss: 1.5617947629702988

Epoch: 5| Step: 10
Training loss: 0.20987717807292938
Validation loss: 1.5541988342039046

Epoch: 413| Step: 0
Training loss: 0.22565272450447083
Validation loss: 1.5555160122532998

Epoch: 5| Step: 1
Training loss: 0.13516540825366974
Validation loss: 1.5491454332105574

Epoch: 5| Step: 2
Training loss: 0.16112849116325378
Validation loss: 1.5794940968995452

Epoch: 5| Step: 3
Training loss: 0.2874780595302582
Validation loss: 1.578768381508448

Epoch: 5| Step: 4
Training loss: 0.27709197998046875
Validation loss: 1.5992921924078336

Epoch: 5| Step: 5
Training loss: 0.3986574709415436
Validation loss: 1.5507402381589335

Epoch: 5| Step: 6
Training loss: 0.0872710794210434
Validation loss: 1.5233672498374857

Epoch: 5| Step: 7
Training loss: 0.167160302400589
Validation loss: 1.5166809981869114

Epoch: 5| Step: 8
Training loss: 0.23478582501411438
Validation loss: 1.5259491948671238

Epoch: 5| Step: 9
Training loss: 0.20067910850048065
Validation loss: 1.542614794546558

Epoch: 5| Step: 10
Training loss: 0.3425687849521637
Validation loss: 1.5718148754489036

Epoch: 414| Step: 0
Training loss: 0.2924831211566925
Validation loss: 1.5849688206949542

Epoch: 5| Step: 1
Training loss: 0.1679377555847168
Validation loss: 1.547386903916636

Epoch: 5| Step: 2
Training loss: 0.26955217123031616
Validation loss: 1.6092218301629508

Epoch: 5| Step: 3
Training loss: 0.2984984517097473
Validation loss: 1.5853875247381066

Epoch: 5| Step: 4
Training loss: 0.18911926448345184
Validation loss: 1.5922349909300446

Epoch: 5| Step: 5
Training loss: 0.22345320880413055
Validation loss: 1.554492099310762

Epoch: 5| Step: 6
Training loss: 0.18604056537151337
Validation loss: 1.5436017756821008

Epoch: 5| Step: 7
Training loss: 0.1806817352771759
Validation loss: 1.5567894020388204

Epoch: 5| Step: 8
Training loss: 0.15629878640174866
Validation loss: 1.5303188216301702

Epoch: 5| Step: 9
Training loss: 0.18644562363624573
Validation loss: 1.5289439514119139

Epoch: 5| Step: 10
Training loss: 0.2609911561012268
Validation loss: 1.5111552412791918

Epoch: 415| Step: 0
Training loss: 0.2786232531070709
Validation loss: 1.5231644607359363

Epoch: 5| Step: 1
Training loss: 0.274848073720932
Validation loss: 1.52028327731676

Epoch: 5| Step: 2
Training loss: 0.2198503464460373
Validation loss: 1.5564320818070443

Epoch: 5| Step: 3
Training loss: 0.2915906608104706
Validation loss: 1.5406836796832342

Epoch: 5| Step: 4
Training loss: 0.16221363842487335
Validation loss: 1.5634558329018213

Epoch: 5| Step: 5
Training loss: 0.20988258719444275
Validation loss: 1.5806184686640257

Epoch: 5| Step: 6
Training loss: 0.11758027225732803
Validation loss: 1.59925970339006

Epoch: 5| Step: 7
Training loss: 0.25880590081214905
Validation loss: 1.6172261802099084

Epoch: 5| Step: 8
Training loss: 0.2502579689025879
Validation loss: 1.5876800142308718

Epoch: 5| Step: 9
Training loss: 0.30835241079330444
Validation loss: 1.5945367749019335

Epoch: 5| Step: 10
Training loss: 0.14175987243652344
Validation loss: 1.601196890236229

Epoch: 416| Step: 0
Training loss: 0.22190313041210175
Validation loss: 1.5742910203113352

Epoch: 5| Step: 1
Training loss: 0.127794548869133
Validation loss: 1.570511370576838

Epoch: 5| Step: 2
Training loss: 0.26289087533950806
Validation loss: 1.584481317509887

Epoch: 5| Step: 3
Training loss: 0.20154985785484314
Validation loss: 1.5608230931784517

Epoch: 5| Step: 4
Training loss: 0.22433574497699738
Validation loss: 1.555742189448367

Epoch: 5| Step: 5
Training loss: 0.09591543674468994
Validation loss: 1.5691858953045261

Epoch: 5| Step: 6
Training loss: 0.20040979981422424
Validation loss: 1.532103507749496

Epoch: 5| Step: 7
Training loss: 0.16246691346168518
Validation loss: 1.5689892973951114

Epoch: 5| Step: 8
Training loss: 0.11605168879032135
Validation loss: 1.5465982332024524

Epoch: 5| Step: 9
Training loss: 0.26277321577072144
Validation loss: 1.5591992896090272

Epoch: 5| Step: 10
Training loss: 0.27120736241340637
Validation loss: 1.536089870237535

Epoch: 417| Step: 0
Training loss: 0.23450343310832977
Validation loss: 1.5312733727116739

Epoch: 5| Step: 1
Training loss: 0.12035534530878067
Validation loss: 1.5338909203006375

Epoch: 5| Step: 2
Training loss: 0.16918687522411346
Validation loss: 1.5061510839769918

Epoch: 5| Step: 3
Training loss: 0.1918693631887436
Validation loss: 1.511139682544175

Epoch: 5| Step: 4
Training loss: 0.11302793025970459
Validation loss: 1.505100396371657

Epoch: 5| Step: 5
Training loss: 0.39386191964149475
Validation loss: 1.5299163210776545

Epoch: 5| Step: 6
Training loss: 0.2312576025724411
Validation loss: 1.546751106939008

Epoch: 5| Step: 7
Training loss: 0.21919187903404236
Validation loss: 1.5533913540583786

Epoch: 5| Step: 8
Training loss: 0.21586552262306213
Validation loss: 1.559548815091451

Epoch: 5| Step: 9
Training loss: 0.18682816624641418
Validation loss: 1.5779864211236276

Epoch: 5| Step: 10
Training loss: 0.2072402685880661
Validation loss: 1.5535018623516124

Epoch: 418| Step: 0
Training loss: 0.18708562850952148
Validation loss: 1.5580154285635999

Epoch: 5| Step: 1
Training loss: 0.3565223813056946
Validation loss: 1.5841648194097704

Epoch: 5| Step: 2
Training loss: 0.23944100737571716
Validation loss: 1.54043242239183

Epoch: 5| Step: 3
Training loss: 0.13863208889961243
Validation loss: 1.5358562482300626

Epoch: 5| Step: 4
Training loss: 0.20849379897117615
Validation loss: 1.5483432713375296

Epoch: 5| Step: 5
Training loss: 0.20173712074756622
Validation loss: 1.5447213842022804

Epoch: 5| Step: 6
Training loss: 0.17602619528770447
Validation loss: 1.504430140218427

Epoch: 5| Step: 7
Training loss: 0.2601291835308075
Validation loss: 1.5237489541371663

Epoch: 5| Step: 8
Training loss: 0.20527005195617676
Validation loss: 1.5362363720452914

Epoch: 5| Step: 9
Training loss: 0.11833138763904572
Validation loss: 1.551111162349742

Epoch: 5| Step: 10
Training loss: 0.20443958044052124
Validation loss: 1.5487842572632657

Epoch: 419| Step: 0
Training loss: 0.2356683313846588
Validation loss: 1.5760785174626175

Epoch: 5| Step: 1
Training loss: 0.24445600807666779
Validation loss: 1.5435049790208057

Epoch: 5| Step: 2
Training loss: 0.2717518210411072
Validation loss: 1.519222431285407

Epoch: 5| Step: 3
Training loss: 0.20600156486034393
Validation loss: 1.5622371512074624

Epoch: 5| Step: 4
Training loss: 0.16791638731956482
Validation loss: 1.553816303130119

Epoch: 5| Step: 5
Training loss: 0.16845469176769257
Validation loss: 1.556769274896191

Epoch: 5| Step: 6
Training loss: 0.22321811318397522
Validation loss: 1.562480063848598

Epoch: 5| Step: 7
Training loss: 0.29583269357681274
Validation loss: 1.5610660468378375

Epoch: 5| Step: 8
Training loss: 0.10338985919952393
Validation loss: 1.569518184149137

Epoch: 5| Step: 9
Training loss: 0.2270740568637848
Validation loss: 1.5498686093156055

Epoch: 5| Step: 10
Training loss: 0.1400042623281479
Validation loss: 1.5564645157065442

Epoch: 420| Step: 0
Training loss: 0.07956431061029434
Validation loss: 1.5524897254923338

Epoch: 5| Step: 1
Training loss: 0.1517690122127533
Validation loss: 1.5658383074627127

Epoch: 5| Step: 2
Training loss: 0.2055111676454544
Validation loss: 1.5597663887085453

Epoch: 5| Step: 3
Training loss: 0.22550249099731445
Validation loss: 1.5588293921562932

Epoch: 5| Step: 4
Training loss: 0.20522892475128174
Validation loss: 1.5609106632970995

Epoch: 5| Step: 5
Training loss: 0.2257818728685379
Validation loss: 1.5618875398430774

Epoch: 5| Step: 6
Training loss: 0.16048063337802887
Validation loss: 1.5733875856604627

Epoch: 5| Step: 7
Training loss: 0.24373097717761993
Validation loss: 1.5256366691281718

Epoch: 5| Step: 8
Training loss: 0.16103556752204895
Validation loss: 1.5370961081597112

Epoch: 5| Step: 9
Training loss: 0.32567328214645386
Validation loss: 1.51269692631178

Epoch: 5| Step: 10
Training loss: 0.2871641218662262
Validation loss: 1.503656215565179

Epoch: 421| Step: 0
Training loss: 0.20433178544044495
Validation loss: 1.5371784933151738

Epoch: 5| Step: 1
Training loss: 0.12780353426933289
Validation loss: 1.5172575801931403

Epoch: 5| Step: 2
Training loss: 0.30977046489715576
Validation loss: 1.545028676268875

Epoch: 5| Step: 3
Training loss: 0.2699194550514221
Validation loss: 1.5352071587757399

Epoch: 5| Step: 4
Training loss: 0.17748966813087463
Validation loss: 1.5539568265279133

Epoch: 5| Step: 5
Training loss: 0.2018149197101593
Validation loss: 1.5644482502373316

Epoch: 5| Step: 6
Training loss: 0.20888447761535645
Validation loss: 1.5405628790137589

Epoch: 5| Step: 7
Training loss: 0.11595427989959717
Validation loss: 1.5617649247569423

Epoch: 5| Step: 8
Training loss: 0.28717875480651855
Validation loss: 1.5631114923825828

Epoch: 5| Step: 9
Training loss: 0.1826966106891632
Validation loss: 1.5747861477636522

Epoch: 5| Step: 10
Training loss: 0.249869704246521
Validation loss: 1.5349184697674167

Epoch: 422| Step: 0
Training loss: 0.1726500689983368
Validation loss: 1.5574331206660117

Epoch: 5| Step: 1
Training loss: 0.20106597244739532
Validation loss: 1.5250759586211173

Epoch: 5| Step: 2
Training loss: 0.1815015971660614
Validation loss: 1.543340584283234

Epoch: 5| Step: 3
Training loss: 0.222813218832016
Validation loss: 1.594021907416723

Epoch: 5| Step: 4
Training loss: 0.22501960396766663
Validation loss: 1.512252244898068

Epoch: 5| Step: 5
Training loss: 0.2131715714931488
Validation loss: 1.543878424552179

Epoch: 5| Step: 6
Training loss: 0.2663955092430115
Validation loss: 1.532433961027412

Epoch: 5| Step: 7
Training loss: 0.1992138922214508
Validation loss: 1.5369729258680855

Epoch: 5| Step: 8
Training loss: 0.17410336434841156
Validation loss: 1.534043785064451

Epoch: 5| Step: 9
Training loss: 0.19039638340473175
Validation loss: 1.5160966868041663

Epoch: 5| Step: 10
Training loss: 0.36858317255973816
Validation loss: 1.5136452451828988

Epoch: 423| Step: 0
Training loss: 0.2254883348941803
Validation loss: 1.4784147867592432

Epoch: 5| Step: 1
Training loss: 0.2549320459365845
Validation loss: 1.5046296209417365

Epoch: 5| Step: 2
Training loss: 0.20059745013713837
Validation loss: 1.4795798037641792

Epoch: 5| Step: 3
Training loss: 0.18011972308158875
Validation loss: 1.5431444785928214

Epoch: 5| Step: 4
Training loss: 0.16999368369579315
Validation loss: 1.5296249799830939

Epoch: 5| Step: 5
Training loss: 0.267038494348526
Validation loss: 1.5348667252448298

Epoch: 5| Step: 6
Training loss: 0.18051044642925262
Validation loss: 1.5309669651010984

Epoch: 5| Step: 7
Training loss: 0.14714877307415009
Validation loss: 1.512934184843494

Epoch: 5| Step: 8
Training loss: 0.14889301359653473
Validation loss: 1.5347741034723097

Epoch: 5| Step: 9
Training loss: 0.2653457820415497
Validation loss: 1.513348307660831

Epoch: 5| Step: 10
Training loss: 0.3407905697822571
Validation loss: 1.5131496972935174

Epoch: 424| Step: 0
Training loss: 0.1236017495393753
Validation loss: 1.5100267471805695

Epoch: 5| Step: 1
Training loss: 0.15367434918880463
Validation loss: 1.5016341940049203

Epoch: 5| Step: 2
Training loss: 0.17284390330314636
Validation loss: 1.5290659794243433

Epoch: 5| Step: 3
Training loss: 0.1960349678993225
Validation loss: 1.4943310676082489

Epoch: 5| Step: 4
Training loss: 0.11446018517017365
Validation loss: 1.508685432454591

Epoch: 5| Step: 5
Training loss: 0.17684510350227356
Validation loss: 1.5204904720347414

Epoch: 5| Step: 6
Training loss: 0.18009717762470245
Validation loss: 1.5338794749270204

Epoch: 5| Step: 7
Training loss: 0.38032299280166626
Validation loss: 1.5319947504228162

Epoch: 5| Step: 8
Training loss: 0.2749514579772949
Validation loss: 1.4882099577175674

Epoch: 5| Step: 9
Training loss: 0.2470664530992508
Validation loss: 1.4983117952141711

Epoch: 5| Step: 10
Training loss: 0.1513822227716446
Validation loss: 1.5082620228490522

Epoch: 425| Step: 0
Training loss: 0.2719402015209198
Validation loss: 1.4899958000388196

Epoch: 5| Step: 1
Training loss: 0.2829133868217468
Validation loss: 1.4914366891307216

Epoch: 5| Step: 2
Training loss: 0.14372800290584564
Validation loss: 1.4746942827778478

Epoch: 5| Step: 3
Training loss: 0.15397335588932037
Validation loss: 1.4720758763692712

Epoch: 5| Step: 4
Training loss: 0.27747398614883423
Validation loss: 1.4971404639623498

Epoch: 5| Step: 5
Training loss: 0.20539748668670654
Validation loss: 1.5104400188692155

Epoch: 5| Step: 6
Training loss: 0.2885085940361023
Validation loss: 1.5080381772851432

Epoch: 5| Step: 7
Training loss: 0.23910407721996307
Validation loss: 1.509970490650464

Epoch: 5| Step: 8
Training loss: 0.23805943131446838
Validation loss: 1.543057059728971

Epoch: 5| Step: 9
Training loss: 0.2595967650413513
Validation loss: 1.5557707932687574

Epoch: 5| Step: 10
Training loss: 0.18122726678848267
Validation loss: 1.5765540023003854

Epoch: 426| Step: 0
Training loss: 0.2157924622297287
Validation loss: 1.5695939628026818

Epoch: 5| Step: 1
Training loss: 0.1925853043794632
Validation loss: 1.5636370041037118

Epoch: 5| Step: 2
Training loss: 0.1334836333990097
Validation loss: 1.5450960577175181

Epoch: 5| Step: 3
Training loss: 0.20765765011310577
Validation loss: 1.5057357626576577

Epoch: 5| Step: 4
Training loss: 0.12420050799846649
Validation loss: 1.5058690629979616

Epoch: 5| Step: 5
Training loss: 0.18492896854877472
Validation loss: 1.481058511682736

Epoch: 5| Step: 6
Training loss: 0.2619699537754059
Validation loss: 1.4867476276172105

Epoch: 5| Step: 7
Training loss: 0.2664225697517395
Validation loss: 1.4857503188553678

Epoch: 5| Step: 8
Training loss: 0.30072635412216187
Validation loss: 1.5082013478843115

Epoch: 5| Step: 9
Training loss: 0.24978061020374298
Validation loss: 1.5043931276567521

Epoch: 5| Step: 10
Training loss: 0.12486018985509872
Validation loss: 1.491559406762482

Epoch: 427| Step: 0
Training loss: 0.34622639417648315
Validation loss: 1.505386285884406

Epoch: 5| Step: 1
Training loss: 0.15957801043987274
Validation loss: 1.5287581387386526

Epoch: 5| Step: 2
Training loss: 0.22628168761730194
Validation loss: 1.5248385219163791

Epoch: 5| Step: 3
Training loss: 0.21836474537849426
Validation loss: 1.5705194447630195

Epoch: 5| Step: 4
Training loss: 0.25312262773513794
Validation loss: 1.5213583643718431

Epoch: 5| Step: 5
Training loss: 0.18295931816101074
Validation loss: 1.5581685637915006

Epoch: 5| Step: 6
Training loss: 0.1778971552848816
Validation loss: 1.5369973772315568

Epoch: 5| Step: 7
Training loss: 0.2266770601272583
Validation loss: 1.5707947297762799

Epoch: 5| Step: 8
Training loss: 0.21565011143684387
Validation loss: 1.5312670661557106

Epoch: 5| Step: 9
Training loss: 0.3751004636287689
Validation loss: 1.584808082990749

Epoch: 5| Step: 10
Training loss: 0.11526568979024887
Validation loss: 1.5421081794205533

Epoch: 428| Step: 0
Training loss: 0.2851284444332123
Validation loss: 1.5521364096672303

Epoch: 5| Step: 1
Training loss: 0.13870397210121155
Validation loss: 1.5869974064570602

Epoch: 5| Step: 2
Training loss: 0.268197625875473
Validation loss: 1.5732581089901667

Epoch: 5| Step: 3
Training loss: 0.17130516469478607
Validation loss: 1.5692149849348171

Epoch: 5| Step: 4
Training loss: 0.22974562644958496
Validation loss: 1.6020533923179872

Epoch: 5| Step: 5
Training loss: 0.19333487749099731
Validation loss: 1.605359044126285

Epoch: 5| Step: 6
Training loss: 0.25561970472335815
Validation loss: 1.5975426473925192

Epoch: 5| Step: 7
Training loss: 0.16720429062843323
Validation loss: 1.583310955314226

Epoch: 5| Step: 8
Training loss: 0.22776420414447784
Validation loss: 1.5803640401491554

Epoch: 5| Step: 9
Training loss: 0.27634763717651367
Validation loss: 1.5693292912616525

Epoch: 5| Step: 10
Training loss: 0.21592268347740173
Validation loss: 1.57136574996415

Epoch: 429| Step: 0
Training loss: 0.3524898886680603
Validation loss: 1.558771501946193

Epoch: 5| Step: 1
Training loss: 0.3409685492515564
Validation loss: 1.5430411343933434

Epoch: 5| Step: 2
Training loss: 0.35758262872695923
Validation loss: 1.5391009289731261

Epoch: 5| Step: 3
Training loss: 0.14367444813251495
Validation loss: 1.5096210523318219

Epoch: 5| Step: 4
Training loss: 0.28508564829826355
Validation loss: 1.5135229877246323

Epoch: 5| Step: 5
Training loss: 0.19004669785499573
Validation loss: 1.5101768829489266

Epoch: 5| Step: 6
Training loss: 0.2010018527507782
Validation loss: 1.5095307083540066

Epoch: 5| Step: 7
Training loss: 0.09235601127147675
Validation loss: 1.5068853414186867

Epoch: 5| Step: 8
Training loss: 0.24698106944561005
Validation loss: 1.5025354784022096

Epoch: 5| Step: 9
Training loss: 0.1307353526353836
Validation loss: 1.5069492965616205

Epoch: 5| Step: 10
Training loss: 0.173826664686203
Validation loss: 1.525145875510349

Epoch: 430| Step: 0
Training loss: 0.24908867478370667
Validation loss: 1.501654630066246

Epoch: 5| Step: 1
Training loss: 0.2029499113559723
Validation loss: 1.5196743998476254

Epoch: 5| Step: 2
Training loss: 0.2212398499250412
Validation loss: 1.5310203285627468

Epoch: 5| Step: 3
Training loss: 0.1276680827140808
Validation loss: 1.5687558522788427

Epoch: 5| Step: 4
Training loss: 0.22578346729278564
Validation loss: 1.538734688553759

Epoch: 5| Step: 5
Training loss: 0.20324751734733582
Validation loss: 1.5591162975116442

Epoch: 5| Step: 6
Training loss: 0.33519411087036133
Validation loss: 1.564279693429188

Epoch: 5| Step: 7
Training loss: 0.20198488235473633
Validation loss: 1.5631341177930114

Epoch: 5| Step: 8
Training loss: 0.11754028499126434
Validation loss: 1.560556588634368

Epoch: 5| Step: 9
Training loss: 0.175556018948555
Validation loss: 1.5665102287005352

Epoch: 5| Step: 10
Training loss: 0.24320799112319946
Validation loss: 1.541619776397623

Epoch: 431| Step: 0
Training loss: 0.3133695125579834
Validation loss: 1.5070778298121628

Epoch: 5| Step: 1
Training loss: 0.15031103789806366
Validation loss: 1.538726282376115

Epoch: 5| Step: 2
Training loss: 0.1687946319580078
Validation loss: 1.5145427603875437

Epoch: 5| Step: 3
Training loss: 0.23594585061073303
Validation loss: 1.4971722902790192

Epoch: 5| Step: 4
Training loss: 0.1978682577610016
Validation loss: 1.506796899662223

Epoch: 5| Step: 5
Training loss: 0.141843780875206
Validation loss: 1.4760664406643118

Epoch: 5| Step: 6
Training loss: 0.20046767592430115
Validation loss: 1.4844337240342171

Epoch: 5| Step: 7
Training loss: 0.22703389823436737
Validation loss: 1.4850984170872679

Epoch: 5| Step: 8
Training loss: 0.08298085629940033
Validation loss: 1.469293544369359

Epoch: 5| Step: 9
Training loss: 0.2060735523700714
Validation loss: 1.4798913463469474

Epoch: 5| Step: 10
Training loss: 0.21547842025756836
Validation loss: 1.4586297209544847

Epoch: 432| Step: 0
Training loss: 0.3139176368713379
Validation loss: 1.4679669846770584

Epoch: 5| Step: 1
Training loss: 0.20465347170829773
Validation loss: 1.471155483235595

Epoch: 5| Step: 2
Training loss: 0.161121666431427
Validation loss: 1.4766363097775368

Epoch: 5| Step: 3
Training loss: 0.2675623297691345
Validation loss: 1.478331131319846

Epoch: 5| Step: 4
Training loss: 0.2281792163848877
Validation loss: 1.4541449021267634

Epoch: 5| Step: 5
Training loss: 0.19006600975990295
Validation loss: 1.4650348771002986

Epoch: 5| Step: 6
Training loss: 0.20830444991588593
Validation loss: 1.49440005517775

Epoch: 5| Step: 7
Training loss: 0.08818474411964417
Validation loss: 1.4892450994060886

Epoch: 5| Step: 8
Training loss: 0.10025382041931152
Validation loss: 1.5163491131157003

Epoch: 5| Step: 9
Training loss: 0.1139364019036293
Validation loss: 1.5360662834618681

Epoch: 5| Step: 10
Training loss: 0.23423759639263153
Validation loss: 1.5774776615122312

Epoch: 433| Step: 0
Training loss: 0.14863599836826324
Validation loss: 1.576954132767134

Epoch: 5| Step: 1
Training loss: 0.12506911158561707
Validation loss: 1.5460985565698275

Epoch: 5| Step: 2
Training loss: 0.3259860873222351
Validation loss: 1.5495589304995794

Epoch: 5| Step: 3
Training loss: 0.16714200377464294
Validation loss: 1.5075928626521942

Epoch: 5| Step: 4
Training loss: 0.25613629817962646
Validation loss: 1.5140101409727527

Epoch: 5| Step: 5
Training loss: 0.14176180958747864
Validation loss: 1.5025160197288758

Epoch: 5| Step: 6
Training loss: 0.24233607947826385
Validation loss: 1.4685742790981005

Epoch: 5| Step: 7
Training loss: 0.1953146904706955
Validation loss: 1.48971599917258

Epoch: 5| Step: 8
Training loss: 0.2036500871181488
Validation loss: 1.4881146953951927

Epoch: 5| Step: 9
Training loss: 0.21922338008880615
Validation loss: 1.4951874671443817

Epoch: 5| Step: 10
Training loss: 0.2628343403339386
Validation loss: 1.51887426453252

Epoch: 434| Step: 0
Training loss: 0.26098954677581787
Validation loss: 1.5365580051176009

Epoch: 5| Step: 1
Training loss: 0.2532827854156494
Validation loss: 1.5012542201626686

Epoch: 5| Step: 2
Training loss: 0.24037131667137146
Validation loss: 1.5315889184192946

Epoch: 5| Step: 3
Training loss: 0.1843506544828415
Validation loss: 1.5248860518137615

Epoch: 5| Step: 4
Training loss: 0.2389306277036667
Validation loss: 1.5531206746255197

Epoch: 5| Step: 5
Training loss: 0.24851052463054657
Validation loss: 1.5270095307339904

Epoch: 5| Step: 6
Training loss: 0.23175457119941711
Validation loss: 1.504878233837825

Epoch: 5| Step: 7
Training loss: 0.1575806885957718
Validation loss: 1.5057755657421645

Epoch: 5| Step: 8
Training loss: 0.16356177628040314
Validation loss: 1.4680693969931653

Epoch: 5| Step: 9
Training loss: 0.14730127155780792
Validation loss: 1.490572460236088

Epoch: 5| Step: 10
Training loss: 0.20270824432373047
Validation loss: 1.4876215509189072

Epoch: 435| Step: 0
Training loss: 0.1208246499300003
Validation loss: 1.4875300930392357

Epoch: 5| Step: 1
Training loss: 0.22548428177833557
Validation loss: 1.5076808352624216

Epoch: 5| Step: 2
Training loss: 0.18022342026233673
Validation loss: 1.4990385219614992

Epoch: 5| Step: 3
Training loss: 0.16991287469863892
Validation loss: 1.5218646103335964

Epoch: 5| Step: 4
Training loss: 0.17216646671295166
Validation loss: 1.5418788989384968

Epoch: 5| Step: 5
Training loss: 0.3034534156322479
Validation loss: 1.5359643377283567

Epoch: 5| Step: 6
Training loss: 0.23184628784656525
Validation loss: 1.5569424911211895

Epoch: 5| Step: 7
Training loss: 0.21041643619537354
Validation loss: 1.4901191803716844

Epoch: 5| Step: 8
Training loss: 0.18101683259010315
Validation loss: 1.5246644532808693

Epoch: 5| Step: 9
Training loss: 0.2601955235004425
Validation loss: 1.5274143007493788

Epoch: 5| Step: 10
Training loss: 0.30112284421920776
Validation loss: 1.5716528302879744

Epoch: 436| Step: 0
Training loss: 0.3799510598182678
Validation loss: 1.5370218837133018

Epoch: 5| Step: 1
Training loss: 0.22174498438835144
Validation loss: 1.519722838555613

Epoch: 5| Step: 2
Training loss: 0.17731687426567078
Validation loss: 1.5129126823076637

Epoch: 5| Step: 3
Training loss: 0.3198978006839752
Validation loss: 1.4978345337734427

Epoch: 5| Step: 4
Training loss: 0.0793006420135498
Validation loss: 1.5242878749806394

Epoch: 5| Step: 5
Training loss: 0.18635991215705872
Validation loss: 1.4789206507385417

Epoch: 5| Step: 6
Training loss: 0.16698578000068665
Validation loss: 1.4728899719894573

Epoch: 5| Step: 7
Training loss: 0.13661053776741028
Validation loss: 1.4832602303515199

Epoch: 5| Step: 8
Training loss: 0.15589025616645813
Validation loss: 1.495339851225576

Epoch: 5| Step: 9
Training loss: 0.26437023282051086
Validation loss: 1.4901529230097288

Epoch: 5| Step: 10
Training loss: 0.1479562520980835
Validation loss: 1.4874482808574554

Epoch: 437| Step: 0
Training loss: 0.14960482716560364
Validation loss: 1.5184501396712435

Epoch: 5| Step: 1
Training loss: 0.24342608451843262
Validation loss: 1.5095583322227641

Epoch: 5| Step: 2
Training loss: 0.12824943661689758
Validation loss: 1.53646263640414

Epoch: 5| Step: 3
Training loss: 0.22805719077587128
Validation loss: 1.5197736742675945

Epoch: 5| Step: 4
Training loss: 0.2595594525337219
Validation loss: 1.5240724214943506

Epoch: 5| Step: 5
Training loss: 0.15714068710803986
Validation loss: 1.5409273793620448

Epoch: 5| Step: 6
Training loss: 0.20441298186779022
Validation loss: 1.5252183701402398

Epoch: 5| Step: 7
Training loss: 0.21341177821159363
Validation loss: 1.4998290308060185

Epoch: 5| Step: 8
Training loss: 0.2897334694862366
Validation loss: 1.5088609803107478

Epoch: 5| Step: 9
Training loss: 0.1831718385219574
Validation loss: 1.5281890451267202

Epoch: 5| Step: 10
Training loss: 0.23998038470745087
Validation loss: 1.5071714911409604

Epoch: 438| Step: 0
Training loss: 0.13925954699516296
Validation loss: 1.4734472113270913

Epoch: 5| Step: 1
Training loss: 0.19025780260562897
Validation loss: 1.4920543996236657

Epoch: 5| Step: 2
Training loss: 0.23365578055381775
Validation loss: 1.4874265757940148

Epoch: 5| Step: 3
Training loss: 0.16770820319652557
Validation loss: 1.48483952014677

Epoch: 5| Step: 4
Training loss: 0.1834934502840042
Validation loss: 1.5031213709103164

Epoch: 5| Step: 5
Training loss: 0.34028300642967224
Validation loss: 1.491300945640892

Epoch: 5| Step: 6
Training loss: 0.09833098948001862
Validation loss: 1.4994039061248943

Epoch: 5| Step: 7
Training loss: 0.19990986585617065
Validation loss: 1.51813736525915

Epoch: 5| Step: 8
Training loss: 0.18015655875205994
Validation loss: 1.5222458249779158

Epoch: 5| Step: 9
Training loss: 0.26323026418685913
Validation loss: 1.5336421933225406

Epoch: 5| Step: 10
Training loss: 0.1762882024049759
Validation loss: 1.474775670677103

Epoch: 439| Step: 0
Training loss: 0.15415087342262268
Validation loss: 1.4909254568879322

Epoch: 5| Step: 1
Training loss: 0.10542985051870346
Validation loss: 1.4823180167905745

Epoch: 5| Step: 2
Training loss: 0.20805291831493378
Validation loss: 1.4666585383876678

Epoch: 5| Step: 3
Training loss: 0.26364457607269287
Validation loss: 1.492801498341304

Epoch: 5| Step: 4
Training loss: 0.2616412043571472
Validation loss: 1.472461321020639

Epoch: 5| Step: 5
Training loss: 0.17965905368328094
Validation loss: 1.4610364488376084

Epoch: 5| Step: 6
Training loss: 0.3080064654350281
Validation loss: 1.451242619945157

Epoch: 5| Step: 7
Training loss: 0.1270052194595337
Validation loss: 1.4320120516643728

Epoch: 5| Step: 8
Training loss: 0.15617677569389343
Validation loss: 1.4577192093736382

Epoch: 5| Step: 9
Training loss: 0.17232371866703033
Validation loss: 1.4397570971519715

Epoch: 5| Step: 10
Training loss: 0.09278684109449387
Validation loss: 1.4282891340153192

Epoch: 440| Step: 0
Training loss: 0.13594366610050201
Validation loss: 1.4521396275489562

Epoch: 5| Step: 1
Training loss: 0.2400292456150055
Validation loss: 1.4699115291718514

Epoch: 5| Step: 2
Training loss: 0.16438665986061096
Validation loss: 1.4673236582868843

Epoch: 5| Step: 3
Training loss: 0.14721384644508362
Validation loss: 1.4801515148532005

Epoch: 5| Step: 4
Training loss: 0.15881554782390594
Validation loss: 1.4672272333534815

Epoch: 5| Step: 5
Training loss: 0.18585975468158722
Validation loss: 1.4432869777884534

Epoch: 5| Step: 6
Training loss: 0.20359113812446594
Validation loss: 1.4688980387103172

Epoch: 5| Step: 7
Training loss: 0.13012248277664185
Validation loss: 1.5036744545864802

Epoch: 5| Step: 8
Training loss: 0.1618364453315735
Validation loss: 1.5230779109462615

Epoch: 5| Step: 9
Training loss: 0.1519431471824646
Validation loss: 1.4826483444500995

Epoch: 5| Step: 10
Training loss: 0.16923655569553375
Validation loss: 1.5003354703226397

Epoch: 441| Step: 0
Training loss: 0.11118592321872711
Validation loss: 1.5331259389077463

Epoch: 5| Step: 1
Training loss: 0.1269429326057434
Validation loss: 1.5379938976739043

Epoch: 5| Step: 2
Training loss: 0.15418659150600433
Validation loss: 1.5289643028730988

Epoch: 5| Step: 3
Training loss: 0.14060507714748383
Validation loss: 1.521338120583565

Epoch: 5| Step: 4
Training loss: 0.14067813754081726
Validation loss: 1.557103726171678

Epoch: 5| Step: 5
Training loss: 0.11596944183111191
Validation loss: 1.5437950344495877

Epoch: 5| Step: 6
Training loss: 0.2903708517551422
Validation loss: 1.5420011205057944

Epoch: 5| Step: 7
Training loss: 0.1854742467403412
Validation loss: 1.537006470464891

Epoch: 5| Step: 8
Training loss: 0.22400136291980743
Validation loss: 1.5021343487565235

Epoch: 5| Step: 9
Training loss: 0.25715821981430054
Validation loss: 1.5428278548743135

Epoch: 5| Step: 10
Training loss: 0.1796829104423523
Validation loss: 1.5152094940985403

Epoch: 442| Step: 0
Training loss: 0.22313623130321503
Validation loss: 1.5167672826397804

Epoch: 5| Step: 1
Training loss: 0.12405575811862946
Validation loss: 1.5215526293682795

Epoch: 5| Step: 2
Training loss: 0.20854923129081726
Validation loss: 1.5169315876499299

Epoch: 5| Step: 3
Training loss: 0.1484471559524536
Validation loss: 1.5515343835276942

Epoch: 5| Step: 4
Training loss: 0.22490644454956055
Validation loss: 1.5071203029283913

Epoch: 5| Step: 5
Training loss: 0.17583400011062622
Validation loss: 1.4969128203648392

Epoch: 5| Step: 6
Training loss: 0.23156492412090302
Validation loss: 1.519685504257038

Epoch: 5| Step: 7
Training loss: 0.20926132798194885
Validation loss: 1.511410891368825

Epoch: 5| Step: 8
Training loss: 0.10533636808395386
Validation loss: 1.5063865953876125

Epoch: 5| Step: 9
Training loss: 0.2878434360027313
Validation loss: 1.510532397095875

Epoch: 5| Step: 10
Training loss: 0.16811177134513855
Validation loss: 1.4943844336335377

Epoch: 443| Step: 0
Training loss: 0.3034779131412506
Validation loss: 1.4875302686486194

Epoch: 5| Step: 1
Training loss: 0.22177958488464355
Validation loss: 1.5070798294518584

Epoch: 5| Step: 2
Training loss: 0.1400528848171234
Validation loss: 1.4871810956667828

Epoch: 5| Step: 3
Training loss: 0.1414283961057663
Validation loss: 1.5156820974042338

Epoch: 5| Step: 4
Training loss: 0.1739112138748169
Validation loss: 1.5210959552436747

Epoch: 5| Step: 5
Training loss: 0.18347367644309998
Validation loss: 1.5056036339011243

Epoch: 5| Step: 6
Training loss: 0.14822213351726532
Validation loss: 1.5019009331221223

Epoch: 5| Step: 7
Training loss: 0.2404748946428299
Validation loss: 1.5164651050362536

Epoch: 5| Step: 8
Training loss: 0.2742907404899597
Validation loss: 1.5088059158735379

Epoch: 5| Step: 9
Training loss: 0.11848083883523941
Validation loss: 1.5069264224780503

Epoch: 5| Step: 10
Training loss: 0.21200579404830933
Validation loss: 1.4686701067032353

Epoch: 444| Step: 0
Training loss: 0.11590929329395294
Validation loss: 1.4594794960432156

Epoch: 5| Step: 1
Training loss: 0.24719353020191193
Validation loss: 1.4755592782010314

Epoch: 5| Step: 2
Training loss: 0.13590234518051147
Validation loss: 1.4691714099658433

Epoch: 5| Step: 3
Training loss: 0.16165931522846222
Validation loss: 1.4709786176681519

Epoch: 5| Step: 4
Training loss: 0.09853489696979523
Validation loss: 1.5030137620946413

Epoch: 5| Step: 5
Training loss: 0.16365085542201996
Validation loss: 1.476439332449308

Epoch: 5| Step: 6
Training loss: 0.3411429822444916
Validation loss: 1.4646889368693035

Epoch: 5| Step: 7
Training loss: 0.17827336490154266
Validation loss: 1.4801053372762536

Epoch: 5| Step: 8
Training loss: 0.28764820098876953
Validation loss: 1.4768786212449432

Epoch: 5| Step: 9
Training loss: 0.23803798854351044
Validation loss: 1.4514754869604622

Epoch: 5| Step: 10
Training loss: 0.2283979207277298
Validation loss: 1.4719041355194584

Epoch: 445| Step: 0
Training loss: 0.2857509255409241
Validation loss: 1.4702995566911594

Epoch: 5| Step: 1
Training loss: 0.16008511185646057
Validation loss: 1.466455336539976

Epoch: 5| Step: 2
Training loss: 0.13196314871311188
Validation loss: 1.4796311701497724

Epoch: 5| Step: 3
Training loss: 0.11571762710809708
Validation loss: 1.4866553384770629

Epoch: 5| Step: 4
Training loss: 0.24144263565540314
Validation loss: 1.4826765867971605

Epoch: 5| Step: 5
Training loss: 0.22269663214683533
Validation loss: 1.5185642460341096

Epoch: 5| Step: 6
Training loss: 0.17759743332862854
Validation loss: 1.5585657896534089

Epoch: 5| Step: 7
Training loss: 0.20007947087287903
Validation loss: 1.535358202072882

Epoch: 5| Step: 8
Training loss: 0.17714457213878632
Validation loss: 1.5594018582374818

Epoch: 5| Step: 9
Training loss: 0.1657559871673584
Validation loss: 1.542420635941208

Epoch: 5| Step: 10
Training loss: 0.2668403685092926
Validation loss: 1.5188268538444274

Epoch: 446| Step: 0
Training loss: 0.1907692849636078
Validation loss: 1.497332634464387

Epoch: 5| Step: 1
Training loss: 0.14752206206321716
Validation loss: 1.5133732954661052

Epoch: 5| Step: 2
Training loss: 0.21248312294483185
Validation loss: 1.4580573125552105

Epoch: 5| Step: 3
Training loss: 0.2104782611131668
Validation loss: 1.490521119486901

Epoch: 5| Step: 4
Training loss: 0.1292295604944229
Validation loss: 1.479690235148194

Epoch: 5| Step: 5
Training loss: 0.1869312822818756
Validation loss: 1.4737254611907467

Epoch: 5| Step: 6
Training loss: 0.20257453620433807
Validation loss: 1.4758726807050808

Epoch: 5| Step: 7
Training loss: 0.23904088139533997
Validation loss: 1.4927671776022962

Epoch: 5| Step: 8
Training loss: 0.17530357837677002
Validation loss: 1.4713782418158747

Epoch: 5| Step: 9
Training loss: 0.12262263149023056
Validation loss: 1.4360295803316179

Epoch: 5| Step: 10
Training loss: 0.11266449093818665
Validation loss: 1.4347149556682957

Epoch: 447| Step: 0
Training loss: 0.13668079674243927
Validation loss: 1.4667290699097417

Epoch: 5| Step: 1
Training loss: 0.1485365480184555
Validation loss: 1.4423170628086213

Epoch: 5| Step: 2
Training loss: 0.17680847644805908
Validation loss: 1.5062551767595354

Epoch: 5| Step: 3
Training loss: 0.23451578617095947
Validation loss: 1.5201574371707054

Epoch: 5| Step: 4
Training loss: 0.16277630627155304
Validation loss: 1.511105018277322

Epoch: 5| Step: 5
Training loss: 0.1969415843486786
Validation loss: 1.4760958481860418

Epoch: 5| Step: 6
Training loss: 0.15893599390983582
Validation loss: 1.510856129789865

Epoch: 5| Step: 7
Training loss: 0.2147209644317627
Validation loss: 1.4876171709388815

Epoch: 5| Step: 8
Training loss: 0.1924356073141098
Validation loss: 1.485648262885309

Epoch: 5| Step: 9
Training loss: 0.12170207500457764
Validation loss: 1.4954764381531747

Epoch: 5| Step: 10
Training loss: 0.294952392578125
Validation loss: 1.5111406028911631

Epoch: 448| Step: 0
Training loss: 0.20883052051067352
Validation loss: 1.4774465637822305

Epoch: 5| Step: 1
Training loss: 0.17311987280845642
Validation loss: 1.5258837438398791

Epoch: 5| Step: 2
Training loss: 0.19861803948879242
Validation loss: 1.4889211052207536

Epoch: 5| Step: 3
Training loss: 0.15408846735954285
Validation loss: 1.5107056767709794

Epoch: 5| Step: 4
Training loss: 0.11092539876699448
Validation loss: 1.5097304544141215

Epoch: 5| Step: 5
Training loss: 0.22347387671470642
Validation loss: 1.5190748104485132

Epoch: 5| Step: 6
Training loss: 0.16481122374534607
Validation loss: 1.5194856146330475

Epoch: 5| Step: 7
Training loss: 0.1531202495098114
Validation loss: 1.5240162700735114

Epoch: 5| Step: 8
Training loss: 0.2969661056995392
Validation loss: 1.5481429266673263

Epoch: 5| Step: 9
Training loss: 0.20789265632629395
Validation loss: 1.5415425633871427

Epoch: 5| Step: 10
Training loss: 0.23559688031673431
Validation loss: 1.5277215101385628

Epoch: 449| Step: 0
Training loss: 0.14476270973682404
Validation loss: 1.5467339920741257

Epoch: 5| Step: 1
Training loss: 0.14367525279521942
Validation loss: 1.4897820385553504

Epoch: 5| Step: 2
Training loss: 0.12424693256616592
Validation loss: 1.4851437627628286

Epoch: 5| Step: 3
Training loss: 0.14165250957012177
Validation loss: 1.4759558785346247

Epoch: 5| Step: 4
Training loss: 0.17231252789497375
Validation loss: 1.4747081392554826

Epoch: 5| Step: 5
Training loss: 0.1957491934299469
Validation loss: 1.450636080516282

Epoch: 5| Step: 6
Training loss: 0.11457584798336029
Validation loss: 1.4848615366925475

Epoch: 5| Step: 7
Training loss: 0.24987833201885223
Validation loss: 1.478320344801872

Epoch: 5| Step: 8
Training loss: 0.24952931702136993
Validation loss: 1.471793415725872

Epoch: 5| Step: 9
Training loss: 0.18038678169250488
Validation loss: 1.464802372840143

Epoch: 5| Step: 10
Training loss: 0.19527757167816162
Validation loss: 1.4556144565664313

Epoch: 450| Step: 0
Training loss: 0.26524633169174194
Validation loss: 1.4266822812377766

Epoch: 5| Step: 1
Training loss: 0.19353513419628143
Validation loss: 1.4493220647176106

Epoch: 5| Step: 2
Training loss: 0.16234689950942993
Validation loss: 1.4574026882007558

Epoch: 5| Step: 3
Training loss: 0.11923613399267197
Validation loss: 1.4854293587387248

Epoch: 5| Step: 4
Training loss: 0.2035369873046875
Validation loss: 1.4777729101078485

Epoch: 5| Step: 5
Training loss: 0.197474405169487
Validation loss: 1.4696236233557425

Epoch: 5| Step: 6
Training loss: 0.13192827999591827
Validation loss: 1.462519134244611

Epoch: 5| Step: 7
Training loss: 0.16862936317920685
Validation loss: 1.498095949490865

Epoch: 5| Step: 8
Training loss: 0.24370494484901428
Validation loss: 1.492158301414982

Epoch: 5| Step: 9
Training loss: 0.1788340061903
Validation loss: 1.4834043031097741

Epoch: 5| Step: 10
Training loss: 0.12895378470420837
Validation loss: 1.4770094553629558

Testing loss: 2.2073586781819663
